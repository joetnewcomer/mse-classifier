question_id,title,body,tags
4582085,"If you write down all the numbers from 1 to n, how many digits would you have written down?","I've seen the question for numbers like 50, 100 or 1000, but not for $n$ . Although I found a formula that might be the answer, but I don't know the name of it or the proof for it. I couldn't find it anywhere on internet as well. Here it is: $$d\times(n+1) - \frac{10^d - 1}{9}$$ $d$ is the number of digits $n$ has. For example, for $n = 16$ : Answer: $\displaystyle2\times (16 + 1) - \frac{10^2 - 1}{9} = 34 - 11 = 23$ Also: $12345678910111213141516\rightarrow 23 \text{ digits}$ Looking forward for replies! Thanks! Edit 1: For those who also want to know how $d$ is calculated: $d = \lfloor\log_{10}n\rfloor + 1$","['number-theory', 'combinatorics', 'discrete-mathematics', 'decimal-expansion']"
4582099,Find limit of trigonometric function with indeterminacy,"Find limit of the given function: $$\lim_{x\rightarrow0} \frac{(4^{\arcsin(x^2)} - 1)(\sqrt[10]{1 - \arctan(3x^2)} - 1)}{(1-\cos\tan6x)\ln(1-\sqrt{\sin x^2})}
$$ I tried putting 0 instead of x $$\lim_{x\rightarrow0} \frac{(4^{\arcsin(x^2)} - 1)(\sqrt[10]{1 - \arctan(3x^2)} - 1)}{(1-\cos\tan6x)\ln(1-\sqrt{\sin x^2})}
=
\frac{(4^{\arcsin(0)} - 1)(\sqrt[10]{1 - \arctan(0)} - 1)}{(1-\cos\tan0)\ln(1-\sqrt{\sin 0})}
=
\frac{(1 - 1)(\sqrt[10]{1 - 0} - 1)}{(1-1)\ln(1-\sqrt{0})}
=
\frac{0*0}{0*0}
=
\frac{0}{0}
$$ But as you can see at $0$ there is limit Indeterminacy ( $0/0$ ). How to play around and solve it?","['limits', 'calculus', 'linear-algebra', 'trigonometry']"
4582149,Can Carathéodory's Extension Lemma be proven without use of the Carathéodory's Restriction Lemma?,"Either the Extension Lemma or the Restriction Lemma below may be used to directly construct the Lebesgue measure, yet the only proof I know of the former lemma uses the latter. Can the Extension Lemma be proven without use of the Restriction Lemma ? Carathéodory's Extension Lemma: let $\mu_0:\Sigma_0\to [0,\infty]$ be a pre-measure on the algebra $\Sigma_0$ of $X$ . Then $\mu_0$ can be extended to a measure $$\mu:\Sigma\to[0,\infty]$$ where $\Sigma:=\sigma(\Sigma_0)$ and $\mu|_{\Sigma_0}=\mu_0$ . Furhermore, if $\mu_0$ is finite, then the extension $\mu$ is unique. Carathéodory's Restriction Lemma: let $\mu^*:2^X\to [0,\infty]$ be an outer measure on the power set $2^X$ of $X$ . Then $\mu^*$ can be restricted to a measure $$\mu:\Sigma\to[0,\infty]$$ where $\Sigma := \Big\{ C \in 2^X : C \text{ is Caratheodory measurable} \Big\}$ and $\mu := \mu^*|_{\Sigma}$ . Note: I've never seen the 'Restriction Lemma' named as such, but I find the name appropriate.","['alternative-proof', 'measure-theory', 'lebesgue-measure', 'outer-measure']"
4582183,Literature containing the process of solving $ f''(x)+ae^{bx}f(x)=0 $,"I tried to solve the following ODE using infinite summs, but failed: $$ f''(x)+ae^{bx}f(x)=0 \tag1$$ From a comment in this post, I found out that the solution of the above equation contains a linear combination of the Bessel functions. That means that there is a good probability that this equation is solved in detail in some literature. My question is, does equation $(1)$ have a specific name? I want to google it so I can go through the process of solving it. If not, is there any other way I can find some literature that goes through this problem?","['ordinary-differential-equations', 'bessel-functions']"
4582200,Proving two graphs are isomorphic assuming no knowledge on paths and degrees,"I was requested to show the following graphs are not isomorphic. I started studying graph theory literally half an hour ago, and I'm supposed to be able to show this without any knowledge of degrees and paths (since this problem comes immediately after defifining what a graph is, what an isomorphism is, and what a subgraph is). I had to use a totally intuitive conception of paths to find a way to prove this. Again, I have zero formal knowledge on paths so my notation, terminology, etc., might be quite off. However, I'm mostly concerned with whether I'm understanding the core ideas of subgraphs and isomorphisms right. Here's the answer as I wrote it. $\text{Answer.}$ Observation . There exists at least a subgraph $G'_1$ of $G_1$ with a $3-$ element subset $V_1'$ of $V_1$ such that $v'_i$ exists in two different edges $e_k, e_j \in E'_1$ . Note. This is my brute way of saying that in $G_1$ one can start at a point $v_i$ with the possibility of returning to it following a path of $3$ vertices. No such subgraph $G'_2 \subset G_2$ satisfies this same property. Trying to mean: it is impossible to return to any initial $v_i \in V_2$ through a path of $3$ vertices (one must take at least a $4$ -vertices path). Answer . We know (I skip the theorem) any isomorphism $\alpha$ between two graphs will map a subgraph to an isomorphic subgraph. However, the previous observation shows there are $3-$ element subgraphs of $G_1$ that can not be appropriately mapped to an isomorphic subgraph of $G_2$ . Then the graphs are not isomorphic. $\text{Side note}$ . I alternatively considered to state that there are subgraphs of $3$ elements of $G_1$ that have $3$ edges, with no subgraphs of $3$ elements of $G_2$ satisfying that property. But it seemed like I was saying the same thing in different words. I'm not only concerend about whether the statements themselves are correct or not, but also about whether even being true they are enough to prove what is requested. Thanks in advance.","['graph-theory', 'elementary-number-theory', 'graph-isomorphism', 'discrete-mathematics']"
4582217,Localization of a differential ring,"I am reading Asymptotic Differential Algebra and Model Theory of Transseries and on p. 200 there is a claim/explanation of Localization: $R$ is a differential ring and $A$ its multiplicative subset, $0 \notin A$ .
Then there is a unique derivation on $A^{-1} R$ making $A^{-1} R$ into
a differential ring where the natural map $r \mapsto r / 1: R
\rightarrow A^{-1} R$ is a morphism of differential rings; it is given
by $$ (r / a)^{\prime}=\left(r^{\prime} a-r a^{\prime}\right) / a^2
> \quad \text { for } r \in R, a \in A, $$ and we always consider $A^{-1} R$ as a differential ring in this way. In particular, if $R$ is a differential integral domain (that is, a differential ring whose
underlying ring is an integral domain), then the derivation $\partial$ of $R$ extends uniquely to a derivation on the fraction field of $R$ . My question is why is the last sentence true? I cannot come up witha proof for it. EDIT I'm also trying to see why the given derivation actually meets the criteria stated in the first sentence. The only thing that springs to my mind is universal property of commutative rings (that they use earlier in the book for localization), namely that for every ring morphism $\phi: A \rightarrow B$ into a commutative ring $B$ with $\phi(S) \subseteq B^{\times}$ there is a unique ring morphism $\phi^{\prime}: S^{-1} A \rightarrow B$ such that $\phi=\phi^{\prime} \circ \iota$ , but I don't see how I could apply it here sicne $R$ a differential algebra.","['localization', 'field-theory', 'ring-theory', 'abstract-algebra', 'group-theory']"
4582280,prove there are infinitely many positive integers $n$ so that $n$ and $\lfloor a_1 n \rfloor +\cdots + \lfloor a_k n\rfloor$ are coprime,"Let $a_1,\cdots, a_k$ be positive real numbers of which at least one is not an integer. Prove that there are infinitely many positive integers $n$ so that $n$ and $\lfloor a_1 n \rfloor +\cdots + \lfloor a_k n\rfloor$ are coprime. Some basic properties of gcds could be useful: $\gcd(a+kb,b) = \gcd(a,b)$ for an integers $a,k,b$ , if $a | bc,$ then $a/d | c,$ where $d = \gcd(a,b).$ If $\gcd(a,c)=\gcd(b,c)=1$ , then $\gcd(ab,c)=1$ . There's also the fact that (though this is most likely not useful for the given problem) $\lfloor x\rfloor + \cdots + \lfloor x+(n-1)/n\rfloor = \lfloor nx\rfloor$ for any real number x and positive integer $n$ . Indeed if $\dfrac{i}n \leq x-\lfloor x\rfloor < \dfrac{i+1}n,$ then $\lfloor x+\dfrac{k}n\rfloor =\lfloor x\rfloor$ for $0\leq k\leq n-i-1$ (since then $\lfloor x\rfloor + (i+k)/n \leq x+\dfrac{k}n < \lfloor x\rfloor + \dfrac{i+k+1}n$ and for $n-i\leq k\leq n-1,$ it equals $\lfloor x\rfloor$ . But $n\lfloor x\rfloor + i\leq nx< n\lfloor x\rfloor + i+ 1,$ so $\lfloor nx\rfloor = n\lfloor x\rfloor + i,$ from which the result follows. If $a_1, \cdots, a_k$ are all integers, then clearly the two given numbers are not coprime for any $n>1.$ I think a proof by contradiction could be useful. Suppose WLOG that $a_1$ is not an integer. First consider the case where $a_1 = \dfrac{p}q, \gcd(p,q)=1, q > 1,p > 0.$ Then $ a_1 n$ is an integer if and only if n is a multiple of $q$ . Otherwise, $\lfloor a_1 n\rfloor = a_1 n - \dfrac{p n\mod q}{q}.$ I'm not sure if it's true that for a sequence of prime numbers $p_n$ going to infinity, $\dfrac{\lfloor a_1 n \rfloor +\cdots + \lfloor a_k n\rfloor }{p_n}$ is a rational sequence converging to $a_1+\cdots + a_k$ . I know that if $(a_n)$ is a convergent sequence of real numbers, then $(\dfrac{a_1+\cdots + a_n}n)$ converges to the same value as $(a_n)$ .","['contest-math', 'divisibility', 'elementary-number-theory', 'sequences-and-series', 'prime-numbers']"
4582297,Why do we prefer the Schauder basis over the Hamel basis in functional analysis?,"Our functional analysis instructor mentioned in the class that the Hamel basis is not so important in the context of Banach spaces. Instead, we prefer the Schauder basis. However, he did not specify the reason why it is so. I tried to think about it myself, but could not find a satisfactory answer. Can someone illustrate why the Hamel basis is not important in the context of Banach spaces, and what motivated mathematicians to work with the Schauder basis?","['hamel-basis', 'banach-spaces', 'schauder-basis', 'functional-analysis']"
4582308,Solving functional equations with antiderivatives as input : $f(F^{-1}(x)) = 1 - \frac{1}{f(x)}$,"I want to solve below equation by relation $F(x) =\int{f(x)}$ , where $F^{-1}(x)$ is $F(x)$ 's inverse function. $$f(F^{-1}(x)) = 1 - \frac{1}{f(x)}$$ $f(x)$ is probably not an elementary function. Is there a general approach to determining the features of these function? Maybe it is a fairly naive relation to get the function itself, so it's okay to get only the constraints on the function. Input of antiderivative is also same as input of original function, because of it is $\mathbf{R}$ to $\mathbf{R}$ function. Also this equation can be reduced into ordinary differential equation form, $$f'(x) = f(x)(1-f(x))^2 f'(f^{-1}(\frac{1}{1-f(x)}))$$","['functional-equations', 'ordinary-differential-equations']"
4582346,Stolz-Cesaro converse theorem proof - possible mistake?,"The Converse Stolz-Cesaro theorem states that if $(b_n)_n$ is strictly monotone and divergent and: $$ \lim_{n \to \infty}\frac{b_n}{b_{n+1}} = B \in \mathbb{R} \setminus
\{1\} , \,\,\,\,\, \lim_{n \to \infty}\frac{a_n}{b_n} = L\in\mathbb{R}\cup\{\pm\infty\} \,\,
\implies \,\,\lim_{n \to \infty} \frac{a_{n+1} - a_n}{b_{n+1} - b_n} = L $$ In every book/article/internet post I found the following proof which is clearly true if $L\in\mathbb{R}$ : $$\frac{a_{n+1} - a_n}{b_{n+1} - b_n} \left(1 - \frac{b_n}{b_{n+1}} \right) = \frac{a_{n+1}}{b_{n+1}} - \frac{a_n}{b_{n+1}} = \frac{a_{n+1}}{b_{n+1}} - \frac{a_n}{b_{n}} \frac{b_n}{b_{n+1}}$$ and, hence, $$\frac{a_{n+1} - a_n}{b_{n+1} - b_n} =  \left(1 - \frac{b_n}{b_{n+1}} \right)^{-1} \left(\frac{a_{n+1}}{b_{n+1}} - \frac{a_n}{b_{n}} \frac{b_n}{b_{n+1}} \right)$$ Since $B \neq 1$ , the limit on the RHS exists and $$\lim_{n \to \infty} \frac{a_{n+1} - a_n}{b_{n+1} - b_n} = (1- B)^{-1}(L - L B) = L$$ My question is: What if $L=+\infty$ ? Does the same result hold? Because the last relation might be false for $B>0$ ...","['limits', 'sequences-and-series', 'real-analysis']"
4582378,"If $(a_n)_n,\ (b_n)_n,$ are positive convex decreasing sequences, $\sum a_n$ converges and $\sum b_n$ diverges, then $\ \frac{a_n}{b_n}\to 0.$","Defintition: A real sequence $\ (x_n)_n\ $ is convex if $\ x_n - x_{n+1} \geq x_{n+1} - x_{n+2}\quad \forall\ n\in\mathbb{N}. $ Continuing on from this question here , Proposition $\ 3:\ $ If $\ (a_n)_n,\ (b_n)_n,\ $ are positive convex decreasing sequences, $\ \displaystyle\sum  a_n \ $ converges and $\ \displaystyle\sum  b_n \ $ diverges, then $\ \frac{a_n}{b_n}\to 0.\ $ In the previous question, counter-examples were found if either $\ (a_n)_n,\ $ or $\ (b_n)_n,\ $ were not required to be convex (but were required to be decreasing), so requiring them both to be convex is a follow-up question I cannot resist investigating. If the proposition is false, then $\ \frac{a_n}{b_n} = c>0\ $ for infinitely many $\ n.\ $ (We may assume WLOG that $\ c=1,\ $ since $\ \displaystyle\sum  a_n \ $ converges $\ \iff \displaystyle\sum \lambda a_n \ $ converges). But in order for $\ \displaystyle\sum  a_n \ $ to converge and $\ \displaystyle\sum  b_n \ $ diverge, we need $\ a_n \ll b_n\ $ for most $\ n,\ $ meaning, I think , that for all $\varepsilon > 0$ , $$\lim_{n\to\infty} \left( \frac{ \text{ The number of integers } \leq n \text{ with } \frac{a_n}{b_n} < \varepsilon }{n} \right) = 1.$$ I know as the question asker, I get to decide what is meant by "" $\ll$ "". But I'm not sure what I want this to mean rigorously, but maybe the definition above is appropriate? I suspect these two facts are at odds with one another, although I don't know how to make this rigorous.","['convergence-divergence', 'sequences-and-series', 'examples-counterexamples', 'real-analysis']"
4582470,Mean and variance of a probability distribution.,"I am confused between mean and variance of a statistical data and the probability distribution. Are both of them different to each-other? as in its simple form, the mean is given in terms of the sum of variables and its frequency divided by total no. of frequency. But when it comes to probability distribution, the mean is computed in totally different way and there is no concept of frequency etc. If both mean represents the same thing then can we conclude that the statistical variable is replaced by random variable and its frequency is substituted by the probability of accurance of the random variable ?","['statistics', 'means', 'probability']"
4582476,First Fundamental Theorem of Calculus Domain,"Suppose $F:[-1,4]\to\Bbb R$ , $F(x):=\int_{-3}^{2x^4+x^2+1}{e^{-t}}$ , $x \in [-1,4]$ . I want to find a formula for the derivative without the integral symbol. So I know how to do this by splitting the integral up to give: $F(x):=\int_{0}^{2x^4+x^2+1}{e^{-t}} =\int_{0}^{2x^4+x^2+1}{e^{-t}} +  \int_{-3}^{0}{e^{-t}}$ . Then the second integral has derivative $0$ and then you define a composite function for the first integral with upper limit $x$ and a function mapping $x$ to $2x^4+x^2+1$ . My question is that I know I have a problem because I need to prove the functions are continuous on $[-1,4]$ but the lower limit $-3$ is outside the domain. So what do I do ? Do I say the integral can't be evaluated since $-3$ is outside the domain, or do I split the $\int_{-3}^{0}{e^{-t}} = \int_{-1}^{0}{e^{-t}}+\int_{-3}^{-1}{e^{-t}}$ and ignore the $\int_{-3}^{-1}{e^{-t}}$ ? Cheers.","['integration', 'calculus', 'definite-integrals', 'derivatives']"
4582526,"Which random variables are representable via the transformation of a $[0,1]$-valued uniform random variable?","Which random variables are representable via the transformation of a $[0,1]$ -valued uniform random variable? Let me be more specific about what I'm looking for, reformulating the problem in the language of measure theory. Suppose $(\mathcal{X},\mathcal{F})$ is a measurable space. Let $\mathcal{B}$ be the family of Borel subsets of $[0,1]$ and let $\mu_L \colon \mathcal{B} \to [0,1]$ be the Lebesgue measure. Are there any fairly general sufficient conditions on the measurable space $(\mathcal{X},\mathcal{F})$ which guarantee that for every probability measure $\mu \colon \mathcal{F} \to [0,1]$ there exists a measurable function $\varphi$ from $\big([0,1],\mathcal{B}\big)$ to $(\mathcal{X},\mathcal{F})$ for which $$\forall F \in \mathcal{F}\;, \qquad \mu[F] = \mu_L\big[\varphi^{-1}(F)\big] \;?$$ (here, $\varphi^{-1}(F):= \{ u \in [0,1] \mid \varphi(u)\in F\}$ ). The idea is then that, if $(\Omega,\mathcal G,\mathbb{P})$ is a probability space, then whatever random variable $X\colon \Omega \to \mathcal{X}$ we may choose, the distribution $\mathbb{P}_X$ of $X$ is the same as the distribution $\mathbb{P}_{\varphi(U)}$ of $\varphi(U)$ for some measurable map $\varphi \colon [0,1] \to \mathcal{X}$ , where $U\colon \Omega \to [0,1]$ is any uniform $[0,1]$ -valued random variable. I'm aware that the result is true for $\mathcal{X} = \mathbb{R}$ and $\mathcal{F} = \mathcal{B}_\mathbb{R}$ , where $\mathcal{B}_\mathbb{R}$ is the family of Borel subsets of $\mathbb{R}$ , but I'm wondering if there are general enough conditions holding in basically every practical case (maybe something like being $(\mathcal{X},\mathcal{F})$ be the Borel measurable space generated by a nicely behaved metric, for example) under which the result holds. References are very welcome.","['measure-theory', 'probability-theory']"
4582566,Verify that $abc^2x^2+c(3a^2+b^2)x+3a^2-ab+b^2=0$ has real roots,"As the title states, the goal is to verify that the quadratic equation: $abc^2x^2+c(3a^2+b^2)x+3a^2-ab+b^2=0$ has real roots. This problem comes from an interschool mathematics contest for High-schoolers, here's my (brute force) attempt: Since we need to verify that the roots are rational, we need to prove that the discriminant of this equation (which I'll denote with $D$ ) is greater than $0$ . In other words: $D=B^2-4AC>0$ where $B=c(3a^2+b^2)$ , $A=abc^2$ and $C=3a^2-ab+b^2$ Therefore: $D=[c(3a^2+b^2)]^2-4(abc^2)(3a^2-ab+b^2)$ $D=[c^2(9a^4+6a^2b^2+b^4)]+[c^2(-12a^3b+4a^2b^2-4ab^3)]$ $D=c^2(9a^4+10a^2b^2+b^4-12a^3b-4ab^3)$ I'm not quite sure where to proceed from here. And this certainly does not prove that the roots are real as this expression can be negative. Is there a way to proceed from here? Are there any better or alternative ways to answer this? Please share your approaches!","['contest-math', 'algebra-precalculus', 'quadratics']"
4582718,A weird theorem of existence,"Im struggling with a problem which seems to be an application of implicit theorem function. It's really hard for me and I would love some help. Let $F: \mathbb{R}^2 \to \mathbb{R}$ a $C^1$ function. Suppose that : $\bullet$ $\forall x \in \mathbb{R}$ , $\lim\limits_{u \rightarrow -\infty} F(x,u) = -\infty$ . $\bullet$ $\forall x \in \mathbb{R}$ , $\lim\limits_{u \rightarrow +\infty} F(x,u) = +\infty$ . $\bullet$ $\forall K \in \mathbb{R}$ , $\exists C \in \mathbb{R}$ , $\forall (x,u) \in \mathbb{R}^2$ , $-K \leq F(x,u) \leq K$ $\implies$ $-C \leq u \leq C$ . $\bullet$ $\exists M \in \mathbb{R}$ , $\forall (x,u) \in \mathbb{R}^2$ , $F(x,u)=M$ $\implies$ $\partial_uF(x,u) \neq 0$ . Then exists $\nu : \mathbb{R} \to \mathbb{R}$ a $C^1$ function such that : $\forall x \in \mathbb{R}$ , $F(x,\nu(x))=M$ . In my opinion we have to apply implicit theorem function to show existence, and compacity to show definition (by hypothesis 3 we can have totally bounded, and completeness leads to compactness), but i have absolutely no clue how to write a proof.","['implicit-function-theorem', 'analysis']"
4582748,Unital $C^\ast$-algebra $\mathcal{A}$ with positive elements $\mathcal{A}$.,"We are given a unital $C^\ast$ -algebra $\mathcal{A}$ where the positive elements of $\mathcal{A}$ are defined to be self-adjoint $A\in\mathcal{A}$ with $\sigma(A)\subseteq[0;+\infty[$ . Denoting the collection of positive elements $\mathcal{A}_+$ and set $\mathcal{A}_-=\{A|-A\in\mathcal{A}_+\}$ . In the following I want to show that $\mathcal{A}_{-} \cap \mathcal{A}_{+}=\{0\}$ . Idea: We have $\sigma(A)\subseteq[0;+\infty[$ and also $\sigma(-A)\subseteq[0;+\infty[$ . Now this implies that $\sigma(A)=\{0\}$ which holds if $A=0$ and therefore one can conclude that $\mathcal{A}_+\cap\mathcal{A}_-=\{0\}$ . Am I on the right track? If no, then how can one actually show $\mathcal{A}_{-} \cap \mathcal{A}_{+}=\{0\}$ ?","['c-star-algebras', 'functional-calculus', 'operator-algebras', 'self-adjoint-operators', 'functional-analysis']"
4582799,$1$-forms integrating to integers and circle-valued maps,"I'm looking for a reference for the following. Fix a connected, closed differentiable manifold $M$ .
Let $d\theta$ be the angle form $S^1$ . On one hand, given a differentiable map $f : M \to S^1$ , we get a closed $1$ -form $f^*(d\theta)$ ; this $1$ -form has the property that it integrates to an integer on any closed path. On the other hand, given a closed $1$ -form $\omega$ on $M$ with the property that it integrates to an integer on any closed path, one can get a differentiable map $f : M \to S^1$ as follows: pick $x \in M$ arbitrarily, and for all $y \in M$ , pick any path $p : [0,1] \to M$ from $x$ to $y$ and let $$
    f(y) = \left(\int_0^1 \omega_{p(t)}(p'(t)) dt\right) \mod \mathbb{Z},
$$ where $\mod \mathbb{Z}$ refers to the fact that I am defining $S^1 = \mathbb{R}/\mathbb{Z}$ . This defines a bijection between the set of closed $1$ -forms of $M$ that integrate to an integer on any closed path, on one hand, and the set of differentiable maps $M \to S^1$ modulo rotations of $S^1$ , on the other hand.","['reference-request', 'differential-forms', 'differential-geometry']"
4582822,"Embedding of Picard functor into $\text{Hom}_k(-,\text{Pic}(X/k))$","$\DeclareMathOperator\Hom{Hom}\DeclareMathOperator\Pic{Pic}\DeclareMathOperator\Spec{Spec}\DeclareMathOperator\pr{pr}$ Let $X$ be an algebraic variety $X$ , that is proper over $k$ (here a variety is a scheme $X/k$ such that $\overline{X}= X \times \Spec(\overline{k})$ is irreducible
and reduced). We consider the Picard functor given for any $k$ scheme $S$ by $$ \mathcal{Pic}_{X/k}(S) :=    \\
 \{ \mathcal{M} \text{ invertible sheaf 
on } X \times_k S \} / \{ \text{ inv. sheaves of the form }
p^*_S(\mathcal{K}) \text{ for } \mathcal{K} \text{ invertible on }
S \}. $$ It is known that this functor is not always representable, but almost;
that means precisely there exists a $k$ -scheme $\Pic(X/k)$ representing the associated
functor $\text{Hom}( \ , \Pic(X/k))$ which contains the
Picard functor $\mathcal{Pic}_{X/k}$ in the sense that for any $k$ -scheme $S$ there is a functorial
inclusion $$ \iota_S: \mathcal{Pic}_{X/k}(S) \hookrightarrow \Hom_k(S,\Pic(X/k)).  $$ In general that's a proper inclusion.
The equality only holds if $X \times_k S$ admits a section over $S$ . My question if there is a way to write down explicitly the map $\iota_S$ , ie given a class $[\mathcal{L}]$ of an invertible sheaf $\mathcal{L}$ on $X \times S$ , what is the morphism $\iota_S([\mathcal{L}]): S \to \Pic(X/k)$ on $k$ -rational points of $S$ ? The most natural way to associate to $[\mathcal{L}]$ a map from $S$ to the Picard group on level of $k$ rational point is perhaps via $s \mapsto [\mathcal{L} \vert _{X \times s}]$ . This is of couse welldefined and the construction is so ""canonical"", that it suggests that's the only possible way how $\iota_S$ could like. But I can't find a strictly formal argument why $\iota_S$ is defined in that way? The question is closely related to this one","['algebraic-geometry', 'picard-scheme']"
4582906,Sequence of bounded Lebesgue integrals equals a finite integral,"I'm struggling to answer the following question. I've been given an increasing sequence of measurable functions $\left(f_n\right)_{n \in \mathbb{Z}^{+}}$ with each $f_n: S \rightarrow \mathbb{R}_{+}$ defined on $S \subseteq \mathbb{R}$ . $\lambda$ is the Lebesgue measure, and we assume that $\left(\int_S f_n d \lambda\right)_{n \in \mathbb{Z}^{+}}$ is bounded. We need to show that $\left(f_n\right)_{n \in \mathbb{Z}^{+}}$ converges pointwise on $S$ to a non-negative measurable function $f$ on $S$ which is finite almost everywhere (i.e. the Lebesgue measure of the subset where $f$ is not finite is equal to zero), and also that $$
\lim _{n \rightarrow \infty} \int_S f_n d \lambda=\int_S f d \lambda<\infty.
$$ Anyone know how to answer this? Thanks in advance!","['measure-theory', 'lebesgue-integral']"
4582909,What is the intrinsic distance of an open and dense subset of the plane?,"Let $U \subseteq \mathbb{R}^2$ be an open, connected, dense subset of $\mathbb{R}^2$ . Consider $U$ as a Riemannian submanifold of $\mathbb{R}^2$ (with the Euclidean metric), and let $d_U$ be the intrinsic distance induced on $U$ , i.e. the distance between any two points $p,q \in U$ is the infimum of lengths of paths connecting $p,q$ that stay inside $U$ . Does $d_U$ equal the Euclidean distance, or can it be larger for some pairs of points? This is asking whether we can maneuver around the points in $\mathbb{R}^2 \setminus U$ , with arbitrarily low ""cost"" in length, no matter how ""ugly/nasty $ $ U$ is. Of course, if $U$ is the entire plane after excluding a finite number of points, the answer is positive (and easy).","['riemannian-geometry', 'metric-spaces', 'optimization', 'general-topology', 'differential-geometry']"
4582913,Counting ordered triples whose product is at most $n$,"There is a classical question in discrete math such a kind  that Let $a\times b \times c =24 $ then , how many possible $(a,b,c)$ triples are there where $a,b,c \in Z^+$ The answer is the following $x_1+x_2+x_3 =3$ and $y_1+y_2+y_3 =1$ , then $$\binom{3+3-1}{3}\binom{3+1-1}{1}=30$$ Now , i want to turn this question to this one such that Let $a\times b \times c < 24 $ then , how many possible $(a,b,c)$ triples are there where $a,b,c \in Z^+$ In first hand , it thought to add another integer $d$ such that $d >1 $ and $a\times b \times c \times d = 24 $ Now , i must do the same calculation like in triple case and subtract the cases where $d=1$ from the total.For example , $$\binom{4+3-1}{2}\binom{4+1-1}{1}-\binom{3+3-1}{3}\binom{3+1-1}{1}=60-30 =30$$ However , my logic is wrong ,i saw it for small case such as $a \times b \times c =6$ . Do you have any suggestion or solution for my problem except for computer programming ? B.T.W My question is not only specific for $24$ , i chose it because it is easy to handle , but it could be any other number such as $678$ etc. So , i am looking for the solution which can handle large numbers","['elementary-number-theory', 'combinatorics', 'discrete-mathematics', 'inequality', 'problem-solving']"
4582922,Proving that these solutions are formally solving these differential equations: $x'' = -\text{sgn}(x')$ and $y'' = \sqrt{|y'|}$,"Please take a look also to the comments section, here, and in other people answers, since there are extended what are my apprehensions about the validity of the found answers. I have found these two solutions to the following differential equations by playing on Wolfram-Alpha, and I would like to prove that they are formally solutions of each equation: $$x'' = -\text{sgn}(x'),\quad \,x(0)=2,\,x'(0)=-2 \quad \Rightarrow \quad x(t) = \frac{1}{2}\left(1-\frac{t}{2}+\left|1-\frac{t}{2} \right|\right)^2\quad\text{(Eq. 1)}$$ $$y'' = \sqrt{|y'|},\quad \,y(0)=\frac{2}{3},\,y'(0)=-1 \quad \Rightarrow \quad y(t) = \frac{1}{12}\left(1-\frac{t}{2}+\left|1-\frac{t}{2} \right|\right)^3\quad\text{(Eq. 2)}$$ Notice that Wolfram-Alpha don't show close-form solutions for neither these equations as can be seen here and here . The following notation is going to be used: $\text{sgn}(t)$ is the Sign function , which fulfills that $\frac{\partial}{\partial t}\left(|t| \right) = \text{sgn}(t)$ and $\frac{\partial}{\partial t}\left(\text{sgn}(t) \right) = 2\ \delta(t)$ $\theta(t)$ is the Heaviside step function that fulfills $\frac{\partial}{\partial t}\left(\theta(t) \right) = \delta(t)$ and $\theta(t) = \frac{1}{2}\left(1+\text{sgn}(t) \right)$ $\delta(t)$ is the Dirac delta function that fulfills $\int_{-\infty}^\infty f(t)\delta(t)\,dt=f(0)$ with $\int_{-\infty}^\infty \delta(t)\,dt=1$ These definitions could be problematic, as it will reviewed later. Motivation Recently I figure out that no non-piecewise power series could have a finite extinction time due the Identity theorem , and found on this paper that a differential equation could have a solution  that achieve a finite extinction time if and only if its nonlinear and have a singular solutions , so it must fail to fulfill uniqueness of solutions, but luckily the paper explains that within the initial conditions time and the finite extinction time uniqueness is still hold. Since my intuition tells that classic mechanics system should achieve a finite extinction time where the movement due the system dynamics dies (as opposite of random thermal noise, which nature is external to the system dynamics as it were a random forcing force), so I started to look for some physics' examples, without finding many (I even tried to made them as in here and here ), and those I found ( here ) were quite hard to understand ( at least for me, I'm an electrician, nor a physicists neither a mathematician ). But a few days ago, someone in a Youtube comment named @siguc explains me the following: ""How about the motion of a brick on a horizontal surface with constant friction between the brick and the surface? Assuming the brick moves along the surface at $t=0$ , it'll stop eventually. Newton's law: $x''=-k\ g\ \text{sgn}(x')$ , where $g$ is $9.8\,\frac{m}{s^2}$ and $k$ is the friction coef."". So I started to googling about this problem founding terms as Coulomb damping and the Stribeck curve , but the only place I found the same brick problem was in this Wiki page and no close-form solutions were shown. Since the system were simple enough to be understood by me, I start by trying to see if I could find a solution to the simplest case by myself, so assuming here that $k\ g = 1$ , I got the $\text{(Eq. 1)}$ . Later I will explain why I choose those arbitrary initial conditions. What I have done so far On previous question I have found: In this question another person (@KBS) proves on his answer that the solution I found could be formally a solution to $$u' = -\text{sgn}(u) \sqrt{|u|},\quad \,u(0)=1 \quad \Rightarrow \quad u(t) = \frac{1}{4}\left(1-\frac{t}{2}+\left|1-\frac{t}{2} \right|\right)^2\qquad\text{(Eq. 3)}$$ Later I found here that for a positive finite extinction time $T>0$ and a positive initial conditions $v(0)>0$ that determines $T(v(0))$ , one can have that: $$\begin{array}{r c l} v' = -\text{sgn}(v) \sqrt[n]{|v|},\quad \,v(0)>0 \quad \Rightarrow \quad v(t) & = & \left[\frac{n-1}{n}\left(T-t\right)\right]^{\frac{n}{n-1}}\theta\left(T-t\right) \\ &\overset{!}{\equiv}& v(0)\cdot \left[\frac{1}{2}\left(1-\frac{t}{T}+\left|1-\frac{t}{T} \right|\right)\right]^{\frac{n}{n-1}}, \\ & & v(0) =  \left[\frac{n-1}{n}\cdot T\right]^{\frac{n}{n-1}}\qquad\text{(Eq. 4)} \end{array}$$ I have found these results in a laissez-faire way and not $100\%$ rigorously: I know that some definitions at the beginning have issues in the edge points, like the Heaviside function having or not a transition value of $1/2$ at $t=0$ , which I have ignored, so I am using things like $\theta(t) = (\theta(t))^n$ which have some weird consequences, as in (Eq. 4) where the exclamation point is evidenced on the equivalence could be flawed. I have preferred the version with the absolute value function trying to be as far as possible of having derivatives of the Dirac Delta function $\delta'(t)$ which I don't know how to handle them. Also has the consequence that if I evaluate the differential equation some issues happened at these edge points , like the rising of Dirac delta functions which broke the differential equation equality, but since it only happened on a zero-measure point, and the solutions doesn't have those problems, I believe they are valid as solutions. With this laissez-faire approach I was able to just test some solutions of the form $x(t) = a\cdot(T-t)^b$ similar to the found for (Eq. 3) and (Eq. 4) and made them fit the differential equation, since from the mentioned paper I believe beforehand that there was an existent singular solution that could achieve a finite extinction time. Since these special functions $\delta(t),\,\text{sgn}(t),\,\theta(t)$ are in reality distributions, which theory I know almost nothing, I would like to know if its possible to prove in a rigorous way they are indeed solutions of those differential equations. BONUS TRACK: Do you believe it is possible to find a general solution for $x''=-k\ g\ \text{sgn}(x')$ using (Eq. 1)? At first I was concern about having an initial condition for the speed $x'(0)<0$ , but I think now it makes sense since the system starts with an initial speed $|x'(0)|$ but through its dynamics it must start loosing speed immediately since friction is the only external force present in the sliding brick system. PS: on other question like this people have attacked the intuition of having solutions that achieve a finite ending time, being valid opinions, please keep it out of the discussion here, since I am trying to explore these kind of solutions as alternative - instead, feel free to extend the discussion in the mentioned question which is more suitable for it. Added later About my worries, as example, in Wikipedia the Heaviside step function is defines as $\theta(0)=\frac{1}{2}$ which could generate issues since I have assumed as true that $\theta(t)=(\theta(t))^n$ . Also, I am using that $$\frac{1}{2}\left(x +|x|\right) = \frac{1}{2}|x|\left(1+\frac{x}{|x|}\right) = \frac{1}{2}|x|\left(1+\text{sgn(x)}\right)=|x|\ \theta(x)$$ , but if instead I take as factor the other term I get: $$\frac{1}{2}\left(x +|x|\right) = \frac{1}{2}x\left(1+\frac{|x|}{x}\right) = \frac{1}{2}x\left(1+\frac{1}{\text{sgn(x)}}\right)$$ And since in Wikipedia defined the sign function as having $\text{sgn}(0) = 0$ then the term $\frac{1}{\text{sgn(x)}}$ hidden a division by zero, which is obviously a big issue.
These are examples of why I am worried about the validity, this sames issues also made struggles with the definitions at the beginning. Hope you could elaborate why is not a problem if it really is not. An attempt for the bonus track If I used the assumption than $kg>0$ , which make sense with the physics problem the equation is coming from, and I used the change of variable $x' = kg z$ , the equation could become: $$\begin{array}{rcl}
-\frac{x''}{kg} & = & \text{sgn}(x') \\
\iff -\frac{kgz'}{kg} & = & \text{sgn}(kg\ z) = \frac{kg\ z}{|kg\ z|} \overset{\text{since}\ kg>0}{=}\frac{kg\ z}{|kg|\ |z|} =\frac{z}{|z|} = \text{sgn}(z) \\
\Rightarrow z' & = & -\text{sgn}(z) \quad\text{which is equivalent to (Eq. 1)}\end{array}$$ With this, we have that the answer to: $$x''=-k\ g\ \text{sgn}(x'), \quad x(0) = 2kg,\,\,x'(0)=-2kg \Rightarrow x(t) = \frac{kg}{2}\left(1-\frac{t}{2}+\left|1-\frac{t}{2} \right|\right)^2$$ So for a general finite extinction time $T>0$ and constants such as $kg>0$ then an answer could be: $$ \begin{array}{l} x''=-k\ g\ \text{sgn}(x'), \qquad x(0) = T^2\frac{kg}{2}>0,\,\,x'(0)=-Tkg<0 \\ \Rightarrow x(t) = T^2\frac{kg}{8}\left(1-\frac{t}{T}+\left|1-\frac{t}{T} \right|\right)^2 = \frac{kg}{2}\left(T-t\right)^2\theta(T-t) \quad \text{(Eq. 6)} \end{array}$$ Does (Ec. 6) make sense-full as closed-form solution for the problem? I have used that $s(t) = \int -(T-t)\ dt\cdot\theta(T-t) = \left[\frac{1}{2}(T-t)^2 + C_0\right]\theta(T-t)$ such as: $$s'(t) = -(T-t)\theta(T-t)\quad + \underbrace{\left[\frac{1}{2}(T-t)^2 + C_0\right]\delta(T-t)}_{C_0 \equiv 0,\,\text{so all the expression could be zero by}\,x\delta(x) = 0}$$ It is still a general solution? Another example of the weird issues I have found, is that if in Wolfram Alpha, as example, I try to solve the equation (Eq. 1) with the founded solution of (Eq. 6) as: $$\frac{1}{kg}\frac{\partial^2}{\partial t^2}\left(\frac{kg}{2}\left(T-t\right)^2\theta(T-t)\right)+\text{sgn}\left(\frac{\partial}{\partial t}\left(\frac{kg}{2}\left(T-t\right)^2\theta(T-t)\right)\right)$$ I will find a mess as is shown here . But if instead I solve the less rigorous equation: $$\left(\frac{1}{kg}\frac{\partial^2}{\partial t^2}\left(\frac{kg}{2}\left(T-t\right)^2\right)+\text{sgn}\left(\frac{\partial}{\partial t}\left(\frac{kg}{2}\left(T-t\right)^2\right)\right)\right)\cdot\theta(T-t)$$ it shows now that the proposed solution solves the equation (except in one isolated point $t=T$ , which is also werid), and I find strange how and why the $\theta(t)$ function can cross through operations as it where a ghost (hope you understand what I am trying to say). Any source to some place where these properties are explain will be fantastic, Thanks.","['ordinary-differential-equations', 'distribution-theory', 'singular-solution', 'finite-duration', 'mathematical-physics']"
4582938,Perfect Groups with faithful complex irreps,Is it true that a perfect finite group $ G $ has a faithful complex irrep if and only if the center of $ G $ is cyclic? The corresponding fact is true for quasisimple finite $ G $ Does every quasisimple finite group have a faithful complex irrep? And certainly it is necessary to have cyclic center for a finite group to have a faithful complex irrep. So the question is really: Does every perfect group with cyclic center have a faithful complex irrep? An example of a non perfect group with cyclic center which has no faithful complex irrep is given here https://mathoverflow.net/q/57129/387190,"['representation-theory', 'group-theory', 'finite-groups']"
4582953,Really dumb clarification on logarithm domain.,"I have the inequality $$\log(1+3x) \geq \log(4x-10)$$ Where $\log$ is meant in base $10$ .\
Now, checking the respective domains, I found the whole domain is $$\Omega: x > \frac{5}{2}$$ So I can exponentiate, comparing the two arguments. Yet I was wondering: if I apply log property, moving to the left all the terms, then I have $$\log\left(\dfrac{1+3x}{4x-10}\right) \geq 0$$ But now the domain changes, reading $$\Omega: x\in (-\infty, -1/3) \cup (5/2, +\infty)$$ Which one is correct? I am confused on this thing.","['calculus', 'analysis', 'logarithms']"
4582964,Easy limit using Ɛ-δ proof,"There is a very simple limit that I can prove using L'Hôpital's rule and other techniques, but I can't really do it using the definition of $\epsilon-\delta$ . $$
\lim_{x\rightarrow 0}\frac{e^{x} -1}{x} =1
$$ Please help! I've been stuck with this for a few weeks. I've even asked some old teachers of mine, and nobody was able to solve it. Thanks in advance! EDIT As asked, I'm going to show you how far I got. I'm sure I made mistakes, but like I said, I'm really at a loss with this limit. Thanks. $$
\lim _{x\rightarrow 0}\frac{e^{x} -1}{x} =1\ \ \Longleftrightarrow \ \ \forall \epsilon  >0\ \ \exists \delta  >0\ \ ||\ \ 0< |x|< \delta \ \ \Rightarrow \ \ \left| \frac{e^{x} -1}{x} -1\right| < \epsilon 
$$ $$
\left| \frac{e^{x} -1}{x}\right| -| 1| \leqslant \left| \frac{e^{x} -1}{x} -1\right| < \epsilon \ \ \Rightarrow \ \ \left| \frac{e^{x} -1}{x}\right| < \epsilon +1
$$ $$
\frac{\left| e^{x} -1\right|}{| x| } = \left| \frac{e^{x} -1}{x}\right| < \epsilon +1
$$ If $\delta \leqslant 1$ then: $$
-1< x< 1
$$ $$
e^{-1} < e^{x} < e
$$ $$
e^{-1} -1< e^{x} -1< e-1
$$ $$
-( e-1) < e^{-1} -1< e^{x} -1< e-1
$$ $$
\left| e^{x} -1\right| < e-1
$$ So now: $$
\frac{\left| e^{x} -1\right| }{| x| } < \frac{e-1}{| x| } < \epsilon +1\ \ \Longrightarrow \ \frac{e-1}{\epsilon +1} < | x| < \delta < 1
$$ As you can see, the last part is a contradiction, so clearly there's something I'm doing wrong here. Thanks.","['functions', 'limits-without-lhopital', 'analysis', 'epsilon-delta']"
4583014,"Which rectangles can be tiled with triangles $T_n$, when only two orientations are allowed?","This question is a generalization of another question asked here: Which rectangles can be tiled with L-trominos, when only two orientations are allowed? A triangle $T_n$ is a polyomino with columns on the same base with lengths $1,2,3,\cdots,n$ with area $n(n+1)/2$ . If we only allow two orientations (copies of the tile and a 180-degree rotated copies), what $a \times b$ rectangles can be tiled for $n \geq 2$ ? Below is the tile set for $T_3$ . Since two tiles from the set can form $n \times (n + 1)$ and $(n = 1) \times n$ rectangles, we can tile all rectangles tileable by these, that include rectangles of the form $an \times b(n + 1)$ and $a(n + 1) \times bn$ (for integers $a$ and $b$ ), and a lot of others, for example, $n(n+1) \times (2n + 1)$ . In fact, all rectangles with area divisible by $n(n + 1)$ if they are large enough... see https://mathoverflow.net/questions/285018/what-rectangles-can-a-set-of-rectangles-tile ). (This is an example of a tiling of $n(n+1) \times (2n + 1)$ for $n = 3$ .) But can we tile any others ? Can we tile rectangles that are not tileable by copies of $n \times (n + 1)$ and $(n + 1) \times n$ rectangles? Can we tile rectangles with area divisible by $n(n+1)/2$ but not divisible by $n(n+1)$ ? In the special case linked above (for $T_2$ ), the answer is ""no"". The technique used there uses group theory and is quite sophisticated; I do not understand it well enough to know whether it applies. If it does it would be a very nice example that could help illuminate that technique. If not, it would be interesting to know of another way to tackle this problem. (This question about triangular tilings is related but possibly much more difficult: Are the only polyominoes that can tile triangles right trominoes? )","['polyomino', 'group-theory', 'combinatorics', 'tiling']"
4583036,show that $(n/a_n)$ takes every positive integer value,"Suppose $(a_n)$ is a nondecreasing sequence of positive integers with $\lim\limits_{n\to\infty} \dfrac{a_n}n=0$ . Show that $(n/a_n)$ takes every positive integer value. It turns out that the above implies the following: for every positive integer k, there is an integer N so that there are exactly $N$ primes less than $kN.$ Edit: The latter claim follows since $\pi(n)$ is a nondecreasing sequence of integers that is asymptotically logarithmic in $n$ (though this is very nontrivial to prove) $$\lim_n\frac{\pi(n)}{n}=0$$ implies that $n/\pi(n)$ takes any positive integer value. I'm not sure how to prove the second fact. Let $k$ be a positive integer and choose $n$ with $n/a_n = k$ . Suppose for a contradiction that there does not exist an integer $N$ so that there are exactly $N$ primes less than $kN$ . Let $m$ be a positive integer. We want to find n with $n/a_n = m\Leftrightarrow 1/m = a_n/n$ . It might be useful to consider the finite set $\{k : \dfrac{a_{mk}}{mk}\ge 1/m\}$ for each positive integer m. It is finite since $\lim\limits_{n\to\infty} \dfrac{a_n}n = 0$ . $a_n$ is nondecreasing. If $a_n$ is bounded, then since it is nondecreasing, it is eventually constant and equal to say, $d$ . Then for large enough k $kd/a_k = k$ so all integers $\ge k$ can be attained. For integers $<k$ , pick the first $n$ so that $n \ge a_n$ ; there must exist such an n since $\lim\limits_{n\to\infty} a_n/n = 0.$ Then note that $n = a_n$ as if $n > a_n$ , the only way $n-1 \leq a_{n-1} = a_n - s< n-s$ for some $s\ge 0$ is if $s < 0,$ a contradiction. So $1$ is definitely attained. In light of the above, we consider the smallest $k$ so that $\dfrac{a_{mk}}{mk} \ge \dfrac{1}m.$ If $a_{mk} > k,$ then $a_{mk-k} = a_{mk} - s$ for some $s\ge 0$ and by minimality, $k = 1$ or $a_{m(k-1)} \leq k-1$ . The latter implies $k-1 \leq a_{m(k-1)} < k-s$ , which is clearly impossible. Hence the former must occur, so $a_m > 1.$ This doesn't seem to lead to a contradiction though.","['contest-math', 'elementary-number-theory', 'calculus', 'sequences-and-series', 'limits']"
4583104,Verify that $\sin(\frac{A}{2})\sin(\frac{B}{2})\sin(\frac{C}{2})\le\frac{1}{8}$ in a general triangle $\triangle ABC$,"So, this problem is inspired by a contest preparation problem I saw back in Japan, and it is as follows: In a general triangle $\triangle ABC$ , show that $\sin(\frac{A}{2})\sin(\frac{B}{2})\sin(\frac{C}{2})\le\frac{1}{8}$ Now, while I still haven't figured out a geometric interpretation of this inequality, here is my attempt to prove this: Recall that: $$\sin^2(\frac{A}{2})=\frac{(1-\cos(A))}{2}$$ $$\sin^2(\frac{A}{2})=\frac{1}{2}(1-\frac{b^2+c^2-a^2}{2bc})$$ $$\sin^2(\frac{A}{2})=\frac{1}{2}(\frac{a^2-b^2-c^2+2bc}{2bc})$$ $$\sin^2(\frac{A}{2})=\frac{a^2-(b-c)^2}{4bc}$$ Now, obviously $\frac{a^2-(b-c)^2}{4bc} \le \frac{a^2}{4bc}$ , therefore: $$\sin^2(\frac{A}{2}) \le \frac{a^2}{4bc}$$ $$\sin(\frac{A}{2}) \le \frac{a}{2\sqrt{bc}}$$ This can be done for $\sin(\frac{A}{2}), \sin(\frac{B}{2})$ and $\sin(\frac{C}{2})$ . $$\sin(\frac{A}{2}) \le \frac{a}{2\sqrt{bc}}$$ $$\sin(\frac{B}{2}) \le \frac{b}{2\sqrt{ac}}$$ $$\sin(\frac{C}{2}) \le \frac{c}{2\sqrt{ab}}$$ Therefore: $$\sin(\frac{A}{2})\sin(\frac{B}{2})\sin(\frac{C}{2}) \le (\frac{a}{2\sqrt{bc}})(\frac{b}{2\sqrt{ac}})(\frac{c}{2\sqrt{ab}})$$ $$\sin(\frac{A}{2})\sin(\frac{B}{2})\sin(\frac{C}{2}) \le \frac{abc}{8abc}$$ $$\sin(\frac{A}{2})\sin(\frac{B}{2})\sin(\frac{C}{2}) \le \frac{1}{8}$$ However I'm not sure if this is correct or if it is, I don't think this brute force approach is good. Are there any better options to prove this inequality? Please share your answers!","['contest-math', 'euclidean-geometry', 'inequality', 'geometry', 'trigonometry']"
4583106,Average Distance of the Sample Mean from the True Mean?,"This is a question I have been thinking of: Suppose I have a Normal Distribution with a specific mean (e.g. ""a"") and standard deviation (e.g. ""b"") - if I draw ""n"" random numbers from this distribution and take the mean of these ""n"" numbers : on average, how close will this mean be from ""a""? For example, using the R programming language, I tried to run this simulation: set.seed(123)
results = list()

for (i in 1:1000)

{

#  n = 100, a = 5, b = 5
sample_i =  rnorm(100, 5, 5)
mean_i = mean(sample_i)
difference_i = abs(5 - mean_i)
results[[i]] = data.frame(i,difference_i)
}

final = do.call(rbind.data.frame, results)
plot(density(final$difference_i), main = ""Spread of Errors : n = 100, a = 5, b = 5"") I can now show this for n = 1000: results = list()

for (i in 1:1000)

{

#  n = 1000, a = 5, b = 5
sample_i =  rnorm(100, 5, 5)
mean_i = mean(sample_i)
difference_i = abs(5 - mean_i)
results[[i]] = data.frame(i,difference_i)
}

final = do.call(rbind.data.frame, results)
plot(density(final$difference_i), main = ""Spread of Errors : n = 1000, a = 5, b = 5"") My Question: In general, given a specific probability distribution -  is there some mathematical formula which shows on average, how far the mean from a sample of size ""n"" will deviate from the true mean of this specific probability distribution? Thanks! EDIT - NOTE: As a concrete example : Consider 1000 random draws from a Normal Distribution with Mean=a and Standard_Deviation = b : On average, what will be the expected difference between the mean of these 1000 random draws and the true mean (i.e. ""a"")? Consider 1000 random draws from a Poisson Distribution with the Rate_Parameter = ""lambda: : On average, what will be the expected difference between the Rate Parameter calculated from these 1000 random draws and the true Rate Parameter (i.e. ""lambda"")? In general, for ""n"" random draws from some general probability distribution - how will the mean calculated from these ""n"" random draws differ from the true mean of this distribution (on average)? Is there a mathematical formula that can be used to describe this relationship? (e.g. via Central Limit Theorem)","['statistics', 'probability']"
4583122,prove each $a_i$ and $b_j$ equals 0 or 1,"Let $r,s\ge 1$ be integers and $a_0,a_1,\cdots, a_{r-1}, b_0,b_!,\cdots, b_{s-1}$ be real nonnegative numbers such that $(a_0 + a_1x+a_2x^2+\cdots + a_{r-1}x^{r-1} +x^r) (b_0 + b_1x+\cdots + x^s)= 1+x+x^2 + \cdots + x^{r+s}$ . Prove that each $a_i$ and each $b_j$ equals 0 or 1. Note that $a_0b_0 = 1$ and $a_0b_1+a_1b_0 = 1$ implies that $a_0,b_0\leq 1\Rightarrow a_0 = b_0 = 1.$ Clearly $r=s$ is impossible as otherwise the coefficient of $x^r$ is at least $a_0+b_0 = 2$ . WLOG (the other case is similar), assume $r < s$ . Also the coefficient of $x^k$ in the final product is equal to $\sum_{i=0}^k a_i b_{k-i},$ where $a_i = 0$ for $i > r, a_r=1, b_i = 0$ for $i > s, b_s=1$ . All the $a_i$ 's and $b_j$ 's have magnitude at most 1 but even given $a_0=b_0=1$ , I'm not sure how to prove $a_1, b_1$ are both either 0 or 1. It could be useful to use some sort of inequalities (e.g. if $a_i\leq M_i$ for all i and $\sum_{i=1}^{r-1} a_i = \sum_{i=1}^{r-1} M_i,$ then $a_i = M_i$ for all i).","['contest-math', 'algebra-precalculus', 'polynomials', 'divisibility']"
4583141,Determine sample size so that it guarantees that the length of the confidence interval is less than $\frac{\sigma}{4}$,"Suposing $\sigma^2$ unkown, find the minimum value for n that gurantees with a probability of 90% that the 95% confidence interval for $\mu$ is of a length no more than $\frac{\sigma}{4}$ Ive been trying to figure this one out using the method to find confidence intervals for sample means, but i get stuck on how to implement the 90% probability i used that when $\sigma^2$ is uknown the confidence interval is given by: $P(\overline{X}-t^{1-\alpha/2}_{n-1}\frac{S}{\sqrt{n}}<\mu<\overline{X}+t^{1-\alpha/2}_{n-1}\frac{S}{\sqrt{n}})=1-\alpha$ and from there i get that the inequality for the length of the interval will be given by: $2t^{0.975}_{n-1}\frac{S}{\sqrt{n}}<\frac{\sigma}{4}$ (using $\alpha =.05$ ) but i dont know how to proceed from here because i need to achieve: $P(2t^{0.975}_{n-1}\frac{S}{\sqrt{n}}<\frac{\sigma}{4})=.9$","['statistical-inference', 'statistics', 'probability']"
4583156,How to compare $E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}]$ and $\frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]}$?,"I have a set of random variables $X_{i}\sim N(\mu_{i},\sigma_{i}^{2}), i\in[1,L]$ , now I want to calculate the following expectation $$E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}]$$ and compare it with $$\frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]}$$ My guess is $$E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}] \geq \frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]}$$ but I have no clues to solve this problem. Can anyone provide me with some hints to solve this problem? Thank you!","['expected-value', 'probability', 'random-variables']"
4583193,Exploring the continuous nowhere differentiable function $g(x) = \sum_{n=0}^{\infty} \frac{\cos {2^n x}}{2^n}$,"I am self-learning Real Analysis from the text Understanding Analysis by Stephen Abbott. I would like someone to verify if my proof for the below exercise problem on a continuous nowhere differentiable function is correct. [Abbott 6.4.3] (a) Show that: \begin{equation*}
g( x) =\sum _{n=0}^{\infty }\frac{\cos\left( 2^{n} x\right)}{2^{n}}
\end{equation*} is continuous on all of $\displaystyle \mathbf{R}$ . Proof. Since, $\displaystyle ( \exists M_{n})$ such that \begin{equation*}
|g_{n}( x) |=\left| \frac{\cos\left( 2^{n} x\right)}{2^{n}}\right| \leq \frac{1}{2^{n}} =M_{n}
\end{equation*} and $\displaystyle \sum _{n=1}^{\infty } M_{n}$ converges, by the Weierstrass M-Test, $\displaystyle \sum _{n=1}^{\infty } g_{n}$ converges uniformly on $\displaystyle \mathbf{R}$ . Since each $\displaystyle g_{n}( x)$ is continuous on $\displaystyle \mathbf{R}$ , by the term-by-term Continuity theorem, $\displaystyle \sum _{n=1}^{\infty } g_{n}( x)$ is continuous on $\displaystyle \mathbf{R}$ . (b) The function $\displaystyle g$ was cited in section 5.4 as an example of a continuous nowhere differentiable function. What happens if we try to use the theorem 6.4.3 to explore whether $\displaystyle g$ is differentiable? Proof. Let \begin{equation*}
g_{n}( x) =\frac{\cos\left( 2^{n} x\right)}{2^{n}}
\end{equation*} So, \begin{equation*}
g_{n} '( x) =-\sin\left( 2^{n} x\right)
\end{equation*} Since $\displaystyle g$ is nowhere differentiable, by the contrapositive of the term-by-term differentiability theorem, we have that: If $\displaystyle g$ is not differentiable on $\displaystyle A$ , then either $\displaystyle \sum g_{n}( x)$ converges NOT pointwise for all $\displaystyle x\in A$ , or $\displaystyle \sum g_{n} '( x)$ converges NOT uniformly on $\displaystyle A$ . Since $\displaystyle \sum g_{n}$ converges uniformly on $\displaystyle \mathbf{R}$ , the only possibility is that $\displaystyle \sum _{n=1}^{\infty } g_{n} '=\sum -\sin\left( 2^{n} x\right)$ does not converge uniformly on $\displaystyle \mathbf{R}$ . The question I have is, are we actually required prove this result? And how to go about proving it anyway? Does the below check out? If a function $\sum h_n$ is uniformly convergent on $A$ , it is uniformly convergent $(\forall S) \subseteq A$ . If $(\exists S \subseteq A)$ where $\sum h_n$ converges NOT uniformly, then $\sum h_n$ converges NOT uniformly on $A$ . Consider the point $x_0 = \frac{\pi}{3}$ . The sequence $g_n'(x_0)=(-1)^n \frac{\sqrt{3}}{2}$ . Thus, $\lim g_n'(x_0) \neq 0$ . Consequently, by the $n$ th term test, $\sum g_n'(x_0)$ does not converge pointwise on any interval containing $x_0 = \frac{\pi}{3}$ . Therefore, $\sum g_n'$ converges NOT uniformly on $\mathbf{R}$ .","['sequence-of-function', 'real-analysis', 'solution-verification', 'uniform-convergence', 'sequences-and-series']"
4583205,"ZFC ""Model"" vs ""Universe"" vs ...?","This question has to do with clarifying a basic matter of terminology: What's the right word to denote ""a collection of sets that satisfies the axioms of ZFC""? The word ""model"" is sometimes used, but the exact meaning ascribed to that word seems inconsistent. Section 3.2 of this article says a model of ZFC has to be a set , and $V$ , being ""too large"" to be a set (Cantor's paradox), is a proper class and therefore, strictly speaking, is disqualified from being a model of ZFC On the other hand, this article describes Godel's constructible hierarchy $L$ as ""an inner model of ZFC"" even though $L$ is a proper class and not a set (as far as I know, since it contains all the ordinals). So it's not entirely clear to me what the accepted convention is, whether the word ""model"" is intended to apply to proper classes, or only to sets . I also see the word ""universe"" being used to describe ""a collection of sets that satisfies the axioms of ZFC"", so perhaps ""universe"" is an alternative that pertains regardless of whether the collection is a set or a proper class. So, to summarize: Is there a term to denote ""a collection of sets that satisfies the axioms of ZFC"" regardless of whether that collection is a set or a proper class? (model? or universe? or something else?) Is there an agreed-upon distinction between ""model"" and ""universe""? Does a ""model"" have to be a set ? Addendum: For what it's worth, if I were to take a semi-educated guess at what the answer to this question might be, I would venture that it works something like this: After you've laid down your axioms (in this case ZFC), you establish the existence of a universe of sets, which is the collection of ""all the sets"" under consideration (a collection which of course obeys the ZFC axioms). An algebra analogy might be establishing that your ""universe of numbers"" is the complex numbers, a collection of mathematical objects which satisfies the field axioms. A model , on the other hand, is a subclass of some existing universe that also obeys the axioms (if you look just at the model and ignore the rest of universe, you find that the model is a ""smaller"" collection of sets which also obeys the axioms). The algebra analogy would be taking a subset of the complex numbers, for example the rational numbers $\mathbb{Q}$ , and noting that $\mathbb{Q}$ is also a field (obeys the field axioms). Presumably you can also define a model to be the entire universe A model can be a set or a proper class (so, I'm hypothesizing that this article actually is mistaken when it says that a model has to be a set ). A given model can be ""reinterpreted"" as the entire universe (in the case where you want to work in a ""smaller"" sub-universe, i.e. you want to ignore parts of your original universe by assuming they don't exist). However, I'm by no means certain that this guess is correct. Still hoping someone can provide further clarification.","['elementary-set-theory', 'terminology']"
4583225,"$(X,\mu)$ is a measure space. Show that, $L^\infty(X;\mu)$ is either finite dimensional or non-separable.","Suppose $L^\infty(X;\mu)$ is not finite dimensional. We have to prove it is non-separable. Suppose not i.e. $L^\infty(X,\mu)$ is separable. Then $\mathcal{F}=\{f\in L^\infty(X;\mu):\  \text{Range}(f)\subseteq\{0,1\}\}=\{\chi_A:\ A\text{ is measurable}\}$ is separable in $\lVert\cdot\rVert_\infty$ norm. I have proved that for $f,g\in\mathcal{F}$ with $f\ne g$ , we have $\lVert f-g\rVert_\infty=1$ . Hence, $\mathcal{F}$ is discrete space. As $\mathcal{F}$ is separable, $\mathcal{F}$ should be countable. From here, I want to prove $L^\infty(X;\mu)$ is finite dimensional. Usually the cardinality of the set $\{f:X\to\Bbb{C}:\ \text{Range}(f)\subseteq\{0,1\}\}$ is $2^{|X|}$ but when we consider the functions as member of $L^\infty$ , two distict maps $f,g$ (as set theoretic) may be equal more specifically, $\chi_A=\chi_B\iff \mu(A\triangle B)=0$ . Can anyone help me complete the proof? Thanks for your help in advance.","['measure-theory', 'normed-spaces', 'real-analysis', 'lp-spaces', 'functional-analysis']"
4583242,Mixture density neural network prediction bias,"I am not totally sure if this belongs here, but I thought it would be the best place to get an answer. I am using a mixture density network (MDN) to make some predictions. My model is very simple with one hidden layer only with 10 nodes (the details of the network shouldn't matter for my question but I can provide more if needed). Also my MDN has only one gaussian component which basically mean that my MDN predicts for each input a mean and standard deviation of a Gaussian from which to sample the output. During the training I am basically minimizing the log-likelihood between the prediction and the expected output: $$log(\sigma(x_{in})) + \frac{(y_{real}-\mu(x_{in}))^2}{2\sigma(x_{in})^2}$$ where $\sigma(x_{in})$ and $\mu(x_{in})$ are predicted by the network and are functions of the input. The network seems to be training well i.e. the loss goes down and I am attaching below 2 histograms I obtained after training the network and trying it on new data. The first one is a histogram of $\frac{dy}{\mu(x_{in})}$ , where $dy = y_{real}-\mu(x_{in})$ . The second histogram shows $\frac{dy}{\sigma(x_{in})}$ . Based on these it seems like the network is doing pretty well (the data has Gaussian noise added to it). However when I try to compute the mean and the error on the mean for $dy$ I get: $$\frac{\sum_i{\frac{dy_i}{\sigma_i^2}}}{\sum_i{1/\sigma_i^2}} = -0.000172 $$ and $$\sqrt{\frac{1}{\sum_i{1/\sigma_i^2}}} = 0.000003$$ where the sum is over all the data points I test the MDN on. This means that my predictions are biased by -0.000172. However, I am not sure why that is the case, as the MDN should easily notice that and add 0.000172 to all the $\mu$ predictions. I tried training several MDN's with lots of different parameters and I get the same result i.e. the result is biased (not always by the same amount or direction). Am I missing something or missinterpreting the results? Shouldn't the mean of my errors be consistent with zero and shouldn't simply adding that bias (0.000172 in this case) solve the issue? Any insight would be really appreciated.","['statistics', 'neural-networks']"
4583258,How to use Metropolis-Hastings algorithm for discrete case,"I came across this question that is quite confusing for me. So far, I've dealt or seen many examples of MH and Gibbs sampling for continuous case and haven't really thought about them for discrete case. Q : Estimate the marginal distribution of X with a Gibbs sampler. $X|n,y\sim Bim(n,y)\\y\sim Beta(2,4)\,\,\, , \,\,n\sim Poi(16)$ (y and n are independent) I derived joint posterior distribution and each full conditional distribution for each parameter.(I'm not sure about them. There might be some mistakes) (0) $P(X,n,y)\propto P(X|n,y)P(n)P(y)\propto \Large\binom{n}{x}\large y^x(1-y)^{n-x}*y(1-y)^3*\Large\frac{16^n}{n! }$ (1) $X|n,y\sim Bim(n,y)$ (2) $y|X,n\propto \large y^{x+2-1}(1-y)^{n-x+4-1}\sim Beta(x+2, n-x+4)$ (3) $n|X,y\propto \Large\binom{n}{x}\large(1-y)^{n-x}\Large\frac{16^n}{n!} \sim ?$ I don't think I can tell which distributions (3) is. Since I can't think of any distributions, I'm gonna use Metropolis-Hastings algorithm. Then I need proposal distribution which has at least the same support of n.(Since 'n' comes from Poisson distribution, it can take 0,1,2,...) So my question is... (1)What kind of proposal distribution should I use? (Binomial? Poisson? or some discrete distributions?) (2)Does discrete case have the same MH-algorithm steps with continuous case? I mean calculating the ratio, comparing with 1 and deciding whether to accept or not. Any help would be really appreciated:)","['conditional-probability', 'statistics', 'bayesian', 'probability']"
4583292,Find a positive decreasing twice differentiable convex function $f$ such that $\int_1^{\infty}\frac{(f'(x))^2}{f(x)}dx=\infty$.,"Reopening this question: Does there exist a positive, decreasing, twice differentiable convex function such that $\int_1^{\infty}\frac{(f'(x))^2}{f(x)}dx=\infty$? My trial: I tried some simple $f(x)$ like monomials or exponentials, that did not work (of course I may have overlooked smth). So I thought of being more systematic and try to define: $$g(x)=\frac{f'(x)^2}{f(x)}$$ where $g(x)>0$ from the hypothesis. I tried than to express $f$ as a function of $g$ like this: $$f'^2=fg$$ $$f'=-\sqrt{f}\sqrt{g} \ (\text{take negative square root})$$ $$f'/\sqrt{f}=-\sqrt{g} \ (\text{divide by non-zero function})$$ and integrating from $1$ to $x$ : $$\sqrt{f(x)}=\sqrt{f(1)}-\frac{1}{2}\int_1^{x}\sqrt{g(x)}dx$$ so now we should find a positive $g(x)$ s.t.: $$\int_1^{+\infty}\sqrt{g(x)}dx <\infty,\int_1^{+\infty}g(x)dx =\infty $$ , or prove that such a $g$ does not exist but since it is very easy to make errors with such manipulations (taking square roots, divisions by $f$ ) I stopped here... moreover, maybe I am overcomplicating things...","['integration', 'convergence-divergence', 'real-analysis']"
4583324,Calculation of $\int_{-\infty}^\infty {\cos x\over a^2-x^2}\ dx$ using residue theorem,"Compute the integral using Residue theorem: $$\int_{-\infty}^\infty {\cos x\over a^2-x^2}\ dx\quad a>0.$$ My attempt: Choose the contour $$\Gamma = \{Re^{i\theta}:0\leq\theta\leq\pi\}\cup [-R,-a-\epsilon]\cup\{-a+\epsilon e^{i\theta}:0\leq\theta\leq\pi\}\cup[-a+\epsilon,a-\epsilon]\cup\{a+\epsilon e^{i\theta}:0\leq\theta\leq\pi\}\cup[a+\epsilon, R]$$ Denote the three upper half circle $C_R$ , $C_{\epsilon_1}$ and $C_{\epsilon_2}$ . The function ${e^{iz}\over a^2-z^2}$ is analytic on and inside of $\Gamma$ so by Cauchy theorem, the integral over $\Gamma$ is zero. \begin{align*}
\int_{C_R}{e^{iz}\over a^2-z^2}\ dz & = \int_0^{\pi}{e^{i(Re^{i\theta})}\over a^2-R^2e^{2i\theta}}iRe^{i\theta}\ d\theta\\
& \leq\int_0^\pi{R\over R^2-a^2}e^{-R\sin\theta}\ d\theta\\
& = 2\int_0^{\pi/2}{R\over R^2-a^2}e^{-R\sin\theta}\ d\theta\\
&\leq 2\int_0^{\pi/2}{R\over R^2- a^2} e^{-R(2\theta/\pi)}\ d\theta\\
& = {2R\over R^2-a^2}\left(-{\pi\over 2R}\right)(e^{-R}-1)\to 0\quad R\to\infty.\\
\int_{C_{\epsilon_2}}{e^{iz}\over a^2-z^2}\ dz & = \int_0^{\pi}{e^{i(a+\epsilon e^{i\theta})}\over a^2 - (a+\epsilon e^{i\theta})^2} i \epsilon e^{i\theta}\ d\theta\\
& = \int_0^{\pi}{e^{ia+i\epsilon\cos\theta}e^{-\epsilon\sin\theta}\over -2a\epsilon e^{i\theta} - \epsilon^2 e^{2i\theta}}i\epsilon e^{i\theta}\ d\theta\\
& = \int_{0}^\pi - i{e^{ia+i\epsilon\cos\theta}e^{-\epsilon\sin\theta} -1\over 2a+\epsilon e^{i\theta}} - i{1\over 2a+\epsilon e^{i\theta}}\ d\theta\\
\end{align*} Note that \begin{align*}
\left|{e^{ia+i\epsilon\cos\theta}e^{-\epsilon\sin\theta} -1\over 2a+\epsilon e^{i\theta}}\right|& \leq {1-e^{-\epsilon\sin\theta}\over 2a-\epsilon}\\
\int_0^{\pi}{1-e^{-\epsilon\sin\theta}\over 2a-\epsilon}\ d\theta & = {2\over 2a-\epsilon}\int_0^{\pi/2}1-e^{-\epsilon\sin\theta}\ d\theta\\
&\leq{2\over 2a-\epsilon}\int_0^{\pi/2}1-e^{-\epsilon}\ d\theta\to 0\quad\epsilon\to 0\\
\end{align*} Hence, $$ \int_{0}^\pi - i{e^{ia+i\epsilon\cos\theta}e^{-\epsilon\sin\theta} -1\over 2a+\epsilon e^{i\theta}} - i{1\over 2a+\epsilon e^{i\theta}}\ d\theta = -i\int_0^{\pi}{1\over 2a}\ d\theta = -{i\pi\over 2a}\quad\epsilon\to 0$$ Similarly, we can compute the integral over $C_{\epsilon_1}$ \begin{align*}
\int_{\epsilon_1}{e^{iz}\over a^2-z^2}\ dz & = \int_0^{\pi}{e^{i(-a+\epsilon e^{i\theta})}\over a^2- (-a+\epsilon e^{i\theta})^2} i\epsilon e^{i\theta}\ d\theta\\
& = \int_0^\pi i{e^{i(-a+\epsilon\cos\theta)}e^{-\epsilon\sin\theta}-1\over 2a-\epsilon e^{i\theta}}\ d\theta + \int_0^{\pi}i{1\over 2a-\epsilon e^{i\theta}}\ d\theta\to {i\pi\over 2a}\quad \epsilon\to 0\\
\end{align*} So the integral is $0$ ? I can't find the error here. Please help. By the way, the contour containing the poles by reflecting $C_{\epsilon_1}$ and $C_{\epsilon_2}$ will give the same calculation except that residue appears now. But they cancel each other $$\int_{-\infty}^\infty{\cos x\over a^2-x^2}\ dx = \operatorname{Re}\left[2\pi i\operatorname{Res}\left({e^{iz}\over a^2-z^2}, z = \pm a\right)\right] = 0.$$ N.B. The integration is interpreted as $$\int_{-\infty}^\infty = \lim_{R\to\infty,\epsilon\to 0+}\left(\int_{-R}^{-a-\epsilon}+\int_{-a+\epsilon}^{a-\epsilon}+\int_{a+\epsilon}^R\right).$$","['complex-analysis', 'residue-calculus']"
4583365,Is $\Vert\cdot\Vert_{L^2}$ Fréchet differentiable as a function on the Sobolev Space $H^1(\mathbb{R})$?,"Consider the function $\Vert\cdot\Vert_{L^2}:H^1(\mathbb{R})\to \mathbb{R}$ and a point $0\neq f\in H^1(\mathbb{R})$ . Is $\Vert\cdot\Vert_{L^2}$ Fréchet differentiable w.r.t. to the norm $\Vert\cdot\Vert_{H^1}$ ? I.e. is there a bounded linear operator $A:H^1(\mathbb{R})\to \mathbb{R}$ , s.t. \begin{equation}
     \lim_{\Vert g\Vert_{H^1}\to 0} \frac{\left\lvert  \Vert f+g\Vert_{L^2} - \Vert f\Vert_{L^2} - Ag\right\rvert}{\Vert g\Vert_{H^1}} = 0?
\end{equation}","['sobolev-spaces', 'derivatives', 'real-analysis']"
4583366,"If $\phi=\frac12(1+\sqrt5)$ and $n=\frac11+\frac1{1+\phi}+\frac1{1+\phi+\phi^2}+\cdots$, then evaluate $\lfloor2n\rfloor+\lceil2n\rceil$","The question is Given that $\phi=\frac{1+\sqrt{5}}{2}$ . Let $$n=\frac{1}{1}+\frac{1}{1+\phi}+\frac{1}{1+\phi+\phi^2}+\frac{1}{1+\phi+\phi^2+\phi^3}+\dots$$ The value of $\lfloor2n\rfloor+\lceil2n\rceil$ is $\dots$ I tried to find a general pattern that might exist for the first few terms but was unable to find a pattern that might simplify the problem. Any help would be appreciated, thanks.","['contest-math', 'algebra-precalculus', 'golden-ratio', 'sequences-and-series']"
4583385,Is this function differentiable on $\mathbb{R}$?,"Here is my prood to see if this function is differentiable over $\mathbb{R}$ . $$f(x) = \vert x\vert x$$ \begin{equation*}
\begin{split}
\lim_{h\to 0} \dfrac{(x+h)\vert x+h \vert - x\vert x \vert}{h} & = \lim_{h\to 0} \dfrac{x\vert x+h \vert + h \vert x + h\vert - x\vert x \vert }{h}
\\\\
& = \lim_{h\to 0} \dfrac{x\vert x \vert + x\vert h\vert + h \vert x \vert + h\vert h \vert - x\vert x \vert}{h}
\\\\
& =  \lim_{h\to 0} x \dfrac{\vert h \vert}{h} + \vert x \vert + \vert h \vert
\end{split}
\end{equation*} Now the last term is zero. The middle term is just $\vert x \vert $ and the first one now depends on the direction: $$\lim_{h\to 0^+} x \dfrac{\vert h \vert}{h} = x$$ $$\lim_{h\to 0^-} x \dfrac{\vert h \vert}{h} = -x$$ Consequently, the limits are different (here $x$ can be whatever number), hence the function exhibits an angular point at every $x$ in the domain. This concludes the function is not differentiable in $\mathbb{R}$ . Now it looks weird to me, maybe I'm right or perhaps I'm wrong. Asking you for help in case!","['absolute-value', 'proof-writing', 'solution-verification', 'limits', 'derivatives']"
4583412,Trace of log of matrix,"How to prove that $$\operatorname{Tr}(\log B) = \sum_i \log b_i \tag{1}$$ where the $b_i$ are the eigenvalues of matrix $B$ ? Question background: This question arises from quantum field theory in particle physics. Where $B$ is $i\not\partial - m$ in continuous Hilbert space(this space of four dimensional spacetime). And $\not\partial=\partial_{\mu}\gamma^{\mu}$ , $\gamma^{\mu}$ is four dimensional Dirac Gamma matrix , there also a four dimensional identity matrix with $m$ . You can specify this as each point in Hilbert space, there is a four dimensional matrix， or each element of B is a four dimensional matrix in Hilbert space; About logarithm of matrix definition, I use Peskin and Schroeder’s QFT book, they define the logarithm of matrix as Taylor series expansion. Below is my navie attempt (sorry for my insufficient math knowledge), suppose $B$ can be diagonalized as: $$B = U^{-1}\Lambda U \tag{2}$$ where $U$ is some unitary matrix and $\Lambda$ is diagonal matrix. Then $$\operatorname{Tr} (\log B) = \operatorname{Tr} (\log (U^{-1}\Lambda U)) \tag{3}$$ I expect that $$ \operatorname{Tr} (\log (U^{-1}\Lambda U)) = \operatorname{Tr} (\log (\Lambda)) \tag{4}$$ But how to proceed from ( $3$ )?","['matrices', 'linear-algebra']"
4583516,Find all the real solutions of $(1+x^2)(1+x^4)=4x^3$.,"As title suggests, the question is to find all the real roots to the polynomial: $$(1+x^2)(1+x^4)=4x^3$$ This problem was asked in the Kettering University Math Olympiad a few years back, it's an interesting problem with many different ways to approach it. I'm going to share my own approach here, please make sure to let me know if there are any mistakes in mine or if anything can be improved, and share your own methods too! Here's my approach for the problem: $$(1+x^2)(1+x^4)=4x^3$$ Divide by $x^3$ on both sides: $$\frac{1+x^2}{x}\cdot\frac{1+x^4}{x^2}=4$$ $$\left(x+\frac{1}{x}\right)\left(x^2+\frac{1}{x^2}\right)=4$$ Now we can set $y=x+\frac{1}{x}$ , thus, $y^2-2=x^2+\frac{1}{x^2}$ $$y(y^2-2)=4$$ $$y^3-2y-4=0$$ $$y^3-8-2y+4=0$$ $$(y-2)(y^2+2y+4)-2(y-2)=0$$ $$(y-2)(y^2+2y+2)=0$$ Now obviously, since we need to find real solutions, the term $(y^2+2y+2)$ will need to be rejected, as it can easily be checked that it yields no real roots. [Alternatively, we can set $y^2+2y+2=0$ and observe that $(y+1)^2=-1$ , thus this term yields no real solution] Therefore: $$y=2$$ $$x+\frac{1}{x}=2$$ $$\frac{x^2+1}{x}=2$$ $$x^2-2x+1=0$$ $$(x-1)^2=0$$ Therefore, $x=1$ is our only real solution.","['contest-math', 'algebra-precalculus', 'solution-verification', 'polynomials']"
4583530,How to solve $\cos^{40}x-\sin^{40}x=1$ for real and imaginary solutions,"Solve : $$\cos^{40}x-\sin^{40}x=1$$ I found by induction that $\sin(x)=0$ satisfy the equation so $$x=n\pi$$ must be the solution but there should be more solutions real or imaginary , how to find them ?","['trigonometry', 'complex-numbers']"
4583585,Linear approximation of $\sqrt[7]{e}$,"I need to find a linear approximation $\sqrt[7]{e}$ . I know that for $x_0 = a + \Delta x$ $$
f(x_0) \approx f(a)+f'(a)\cdot \Delta x
$$ Thus my inital function is $f(x) = \sqrt[7]{x}$ and $e = 1 + (e - 1)$ , so $$
f(e) \approx \sqrt[7]{1} + \frac{1}{7}1^{\frac{-6}{7}}\cdot(e - 1) = \frac{6}{7} + \frac{e}{7} \approx 1.2455.
$$ However, I can't say that I'm entirely pleased by the result. Even though one could argue that $f(x) = \sqrt[7]{x}$ grows in such slow manner that approximating $f(e)$ by $f(1)$ is good enough for linear approximation, I'm not convinced. So I started to wonder: does there exist a function $g(x): f(g(x)) = \sqrt[7]{g(x)}$ and $f(g(c)) = \sqrt[7]{g(c)}= \sqrt[7]{e}$ that could provide a more precise approximation?","['approximation', 'linear-approximation', 'derivatives', 'taylor-expansion']"
4583612,Example of a dense open subset that is not of the form $U \cup {\sim} U$ for $U$ regular,"If $U\subseteq X$ is an open set in a topological space $X$ , let $\newcommand{\negation}{\mathop{\sim}}\negation U$ denote the largest open set $V$ such that $V\cap U = \varnothing$ (i.e., the set of points having a neighborhood disjoint from $U$ , i.e., the interior of the complement of $U$ , i.e., the complement of the closure of $U$ ). Note that $U$ is dense iff $\negation U = \varnothing$ , or equivalently, $(\negation\negation U) = X$ .  At the other extreme, open sets such that $(\negation\negation U) = U$ (equivalently, those of the form $\negation V$ for some $V$ open) are known as “regular” open sets. Clearly, every open set of the form $U \cup \negation U$ is dense.  Also, every dense open set is of this form (just take $U$ to be the set itself).  But can we do this with $U$ regular?  In other words: Question: Is there an example of a dense open set in $X = \mathbb{R}^n$ that is not of the form $U \cup (\negation U)$ for $U$ regular open?  (Equivalently, not of the form $(\negation V) \cup (\negation\negation V)$ for $V$ open.)  Or is every dense open set of this form?",['general-topology']
4583624,Niche topics (preferably in number theory) that a high school student could find some results in?,"my teacher recently asked me to come up with a math project to be submitted to a competition, and I have a hard time coming up with ideas. I've recently been solving number theory problems and one concept that caught my attention was Vieta Jumping. I was thinking to generalize the types of expressions usually found in olympiad problems that require Vieta Jumping. I want to find conditions such that expressions like $$ ax^2+by^2+cz^2+dw^2...\over A\cdot xyzw...$$ are integers and when they are, I want to find the values they can take. Apart from this maybe another interesting topic could be the applications of higher (but not too high) math on high school olympiad problems. If you could give any insights as to what might be a suitable research area I'd very much appreciate it. Thanks. Note: I can give examples of past projects if it would help put things into perspective.","['contest-math', 'number-theory', 'soft-question', 'discrete-mathematics']"
4583685,"Interpreting tail events and their ""dependence"" on finite r.v.'s","Let $X_1,X_2...$ be random variables defined on the same sample space. Let $$\mathcal{F}_n = \sigma(X_n,X_{n+1}...), \mathcal{F} = \bigcap_n\mathcal{F_n}$$ where the latter is the tail $\sigma$ -field. I am trying to understand what we mean when we say that a tail event $A \in \mathcal{F}$ does not depend on any finite set $\{X_1...X_n\}$ . From a previous answer , this is my ""intuitive"" understanding: If $A \in \mathcal{F}$ , then for all $n \in \mathbb{N}$ , $A \in \mathcal{F_n}$ . But since $\mathcal{F_n} \subset \mathcal{F_1}$ , we see that ""omitting"" the first $n-1$ $X_i$ 's does not affect our event being in $\mathcal{F}$ . Thus, if we think about the $\sigma$ -fields as ""current knowledge"" about our space, we see that this ""current knowledge"" is not ""dependent"" on $X_1 ... X_{n-1}$ . However, I am not sure how this can be made rigorous. In particular, (i) is the term ""dependent"" being used here comparable to how we speak of independence of events and random variables? What is the mathematical definition of dependent here? Or is just ""dependent"" in an intuitive sense? (ii) What justifies seeing the $\sigma$ -field as our ""current knowledge"" about the space? I know that $\sigma(X_n,X_{n+1}...)$ is the collection of sets $[\omega \in \Omega : X(\omega) \in B]$ , where $X = (X_n,X_{n+1}...)$ and $B$ is a Borel set in $\mathbb{R^{\mathbb{N}}} $ . I suppose this is linked to the view of a $\sigma-$ field as a set of events, but what do we mean by ""current knowledge"" (iii) Finally, how can I view (i) and (ii) together? In math, what does it mean for our current knowledge -the $\sigma$ -field $\sigma(X)$ - to not ""depend"" on $X_1...X_n$ ? If it helps for you to explain, I suppose a helpful and simple example to think might be the event $\{\omega \in \Omega: \sum X_i(\omega) < \infty\}$ - I understand why this does not ""depend"" on the value that finitely many $X_i$ take from an analysis perspective, but now I am trying to understand it from this probability theory perspective.","['measure-theory', 'probability-theory', 'probability']"
4583689,Finding the pointwise limit of a sequence of elementary functions defined by n * the characteristic function.,"I basically want to find the limit of the following sequence: $f_n = nX_{[0, 1/n]}$ $X := 1$ if $x \in [0, 1/n], x = 0$ otherwise. When I look at this function, my first thought is that the limit approaches infinity and therefore doesn't exist, since even though x would have to be closer and closer to 0 for the function to not equal 0, n*1 = n. However, according to the problem description, a limit f should exist. I'm afraid my understanding of this topic is still very basic so if someone could help explain, I'd appreciate it.","['lebesgue-measure', 'real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
4583695,Explain $\Bbb Q$ is a dense set,"This is approximately my explanation for 14-year-old students in saying that $\Bbb Q$ is a dense set. In contrast to the set $\Bbb N$ and the set $\Bbb Z$ , between any two rationals another rational is always included, and thus we can say that between two rationals infinite rationals are included. For example, let us put the numbers $0$ and $1$ on the straight line. Now let us denote on the line a rational number between $0$ and $1$ , for example, their half. Now we indicate on the line a rational number between $0$ and $\frac 12$ , for example, their half. I will obtain the sequence $0, \frac 14, \frac 12$ .
Now we indicate on the line a rational number between $0$ and $\frac 14$ , for example, their half $\frac 18$ . Considering to always divide by $\dfrac{1}{2^n}$ with $n\in\Bbb N$ the fraction $\dfrac{1}{2^n}$ with the large $n$ the points in the subdivision will all accumulate toward $0$ (zero becomes an accumulation point). For this reason we can say that the set $\Bbb Q$ is a DENSE set. By this expression we mean an ordered set in which, given any INTERVAL, THERE IS AT LEAST ONE ELEMENT INSIDE it. Is there another easy explanation to give my students or is the one I have given enough?","['elementary-set-theory', 'arithmetic', 'education']"
4583703,Show that distribution doesn't belong to Exponential Family,"Let $X$ be distributed by the following density function $$f_X(x;\gamma)=\frac{1}{\pi((x-\gamma)^2+1)}, \ \ \ \ \ x,\gamma\in\mathbb{R}$$ Then we want to show that $\{f_X(x;\gamma): \gamma\in\mathbb{R}\}$ is not a one dimensional exponential family. We have that if there exists $h:\mathbb{R}\to\mathbb{R}_+,g:\mathbb{R}\to\mathbb{R}_+,
\eta:\mathbb{R}\to\mathbb{R}$ and $T:\mathbb{R}\to\mathbb{R}$ such that $$f_X(x;\gamma)=h(x)g(\gamma)\exp(\eta(\gamma)T(x))$$ then $\{f_X(x;\gamma): \gamma\in\mathbb{R}\}$ is a one dimensional exponential family. But I can't seem to show that this distribution doesn't belong to the exponential family. Any help is greatly appreciated.","['statistics', 'probability-theory', 'probability']"
4583737,Trig and de Moivre's theorem,"A) Use de Moivre's theorem to prove that $\cos^4\theta = 8\cos^4\theta - 8\cos^2\theta + 1$ B) Therefore deduce that $\cos(\pi/8) = \left(\frac{2 + \sqrt{2}}{4}\right)^{1/2}$ C) and write down an expression for $\cos(3\pi/8)$ . I have proved the first part of the question but I am not sure where to go from there. My attempt de Moivre's theorem states that $(\cos x +i\sin x)^n = \cos nx + i\sin nx$ using this and $\cos ^2θ + \sin ^2θ =1$ , I did the following: \begin{align}
\cos 4θ + i\sin 4θ &= (\cos θ +i\sin θ)^4 + \cos 4θ + 4i\cos ^3θ\sin θ - 6\cos ^2θ\sin ^2θ-4i\cos θ\sin 3θ+\sin ^4θ\\
\cos 4θ &= \cos ^4θ -6\cos ^2θ\sin ^2θ +\sin ^4θ\\
\cos 4θ &= \cos ^4θ - 6\cos ^2θ(1-\cos ^2θ) + (1-\cos ^2θ)^2\\
\cos 4θ &= \cos ^4θ - 6\cos ^2θ + 6\cos ^4θ +1 - 2\cos ^2θ + \cos ^θ\\
\cos 4θ &= 8\cos ^4θ -8\cos ^2θ +1
\end{align}",['trigonometry']
4583766,What is the geometric intuition for the basic trigonometric Fourier integrals?,"What is the geometric intuition for the trigonometric Fourier integrals? For example, can someone help me understand the geometry of : $\int_{-\pi}^{\pi}cos^2(x)dx = \pi$ and $\int_{-\pi}^{\pi}sin^2(x)dx = \pi$ ? Why should the area under these graphs over any interval of length $2\pi$ to be $\pi$ ? Also, I'd like to understand the geometetric intuition of the orthogonality of the set of triginometric functions $\{cos(1x),sin(1x),cos(2x),sin(2x),...\}$ wrt to the inner product $(f,g) = \int_{-\pi}^{\pi}f(x)g(x)dx$ i.e.: $\int_{-\pi}^{\pi}cos(nx)sin(mx)dx = 0 \text{ for all } m,n$ $\int_{-\pi}^{\pi}cos(nx)cos(mx)dx = 0 \text{ when } m \neq n$ What is the geometric understanding of why the areas under these graphs on any interval of length $2\pi$ is zero? Thank you!!!","['integration', 'fourier-analysis', 'geometry', 'calculus', 'trigonometry']"
4583776,Meromorphic section of a given line bundle over a compact Riemann surface,"Let $\Sigma$ be a compact Riemann surface and $L \to \Sigma$ be a given(!) line bundle, with $c_1(L) \geq N(P)  > 0  $ where $N(P)$ , depending on $P$ as soon to be explained, is an integer as large as you desire, but also fixed. I want to know wether $L$ admits a meromorphic section with exactly $P$ poles, counting multiplicity. If you can prescribe them, it would be even better, but it is no must. I am aware of the fact that you can come up with a meromorphic section having at least $1$ pole (not necesarrily simple) at a prescribed point (see Forster, lectures on Riemann surfaces theorem 29.16). That being said, we can pick $P$ distinct points, say $a_1,...,a_P \in \Sigma$ , which would then give sections $s_i: \Sigma \to L$ having a pole precisely at $a_i$ (order unnknown, might be double or triple) and define $$
s=\sum_{i=1}^P s_i
$$ which gives me a meromorphic section with at least $P$ poles. In this case, the information on the chern class would just yield the number of zeroes $N$ via the formula $N-P=\langle c_1(L), \Sigma \rangle$ , a completely worthless information for my purpose. I am aware of many closeley related theorems (e.g. Riemann Roch, which only gives me meromorphic functions/Holomorphic section) and the ""pole problem"" is solveable in the complex plane. I feel like this should be a well-studied problem, since thanks to my chern class/degree of my line bundle being high enough (say higher than genus of $\Sigma$ plus some correction term) I should be able to deduce it from a known theorem. I am grateful for any reference/hint anyone could give me.","['complex-analysis', 'complex-geometry', 'algebraic-geometry', 'differential-geometry']"
4583820,A question on properties of a limit function.,"Suppose $f_n: A \rightarrow \mathbb{R^+}$ is an increasing sequence of measurable functions where $A \subseteq \mathbb{R}$ and suppose the sequence $ \left( \int_A f_n d \mu \right)_{n \in \mathbb{N}} $ is bounded. Let $ f : A \rightarrow [0 , \infty] $ be defined by $f(x) = \sup\{ f_n(x) \mid n \in \mathbb{N} \}$ . I want to show that $f_n \rightarrow f $ pointwise, and also I want to show that $f$ is finite almost everywhere. For the first bit, let $x \in A$ and let $\varepsilon > 0$ . If $f(x) = \infty$ then $\lim_{n \rightarrow \infty}f_n(x) = \infty$ . If not, then by definition of supremum there is $ n_0 \in \mathbb{N}$ such that $f(x) - \varepsilon < f_{n_0}(x).$ Since $f_n$ is increasing this gives $| f(x) - f_n(x) | < \varepsilon $ for all $n \geq n_0$ . Thus $f_n \rightarrow f$ pointwise. To show $f$ is finite almost everywhere, first I show that each $f_n$ is finite almost everywhere. Fix $n \in \mathbb{N}$ and for $j \in \mathbb{N}$ let $E_j = \{ x \in A \mid f_n(x) \geq j \}$ . Then from other results, we have that $\mu\left( E_j\right) \leq \frac{1}{j} \int_E f_n d \mu $ . By assumption $\int_A f_n d \mu $ is bounded and so $\lim_{j \rightarrow \infty}\mu(E_j) = 0$ . Note also that $f_n^{-1}\left( \{ \infty \} \right) = \bigcap_{j = 1}^\infty E_j$ . Since $(E_j)_{j \in \mathbb{N}}$ is decreasing and $\mu(E_1) < \infty$ , we have that $\mu\left( f_n^{-1}\left( \{ \infty \} \right) \right) = \mu\left( \bigcap_{j = 1}^\infty E_j \right) = \lim_{j \rightarrow \infty}\mu(E_j) = 0$ . Thus each $f_n$ is finite almost everywhere. And on this part I am stuck, not sure how to show that $f$ is also finite almost everywhere. I suspect I should have to use the fact the sequence $\left( \int_A f_n d \mu \right)_{n \in \mathbb{N}} $ is bounded.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
4583954,a question on lexicographic order and change of indices,"Consider a vector of components which are listed in lexicographic order: $\boldsymbol{z} = (z_{1,2},z_{1,3},\ldots,z_{1,K}, z_{2,3},z_{2,4},\ldots,z_{2,K},\ldots,z_{i,i+1},z_{i,i+2},\ldots,z_{i,K},\ldots,z_{K-1,K})'$ and $z_{k,l} = -z_{l,k}$ for $k<l$ . Now suppose indices $(i,j)$ are interchanged in $\boldsymbol{z}$ and the resulting vector is denoted by $\boldsymbol{z}_{ij}$ . I have verified that there is an orthogonal matrix say $\mathrm{H}$ with unit vectors such that $\mathrm{H}\boldsymbol{z} = \boldsymbol{z}_{ij}$ . For example let $K=4$ then \begin{equation}
\boldsymbol{z} = \begin{bmatrix}z_{12}\\
z_{13}\\
z_{14}\\
z_{23}\\
z_{24}\\
z_{34}
\end{bmatrix}
\end{equation} and after interchanging $1$ and $2$ we get \begin{equation}
\boldsymbol{z}_{12} = \begin{bmatrix}z_{21}\\
z_{23}\\
z_{24}\\
z_{13}\\
z_{14}\\
z_{34}
\end{bmatrix}
\end{equation} Next \begin{equation}
\boldsymbol{z}_{12} = \begin{bmatrix}
-1 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 1 & 0\\
0 & 1 & 0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 1\\
\end{bmatrix}
\boldsymbol{z} = \mathrm{H}\boldsymbol{z}
\end{equation} It can be noted that $ \mathrm{H}$ is symmetric and orthogonal. Is there any way to express the $\mathrm{H}$ matrix in a compact form in general when indices $i$ and $j$ are interchanged?","['matrices', 'combinatorics', 'discrete-mathematics']"
4583994,Averaging Distances - Valid Comparasions?,"As we know, there are many different ways to compare the level of similarity between two strings of text (e.g. https://en.wikipedia.org/wiki/String_metric ). I have often found myself confused as to which of metrics are better suited for different problems (e.g. a certain metric might say that two strings are very similar, but a different metric might say that the same two strings are very different) - this led me to the following idea: For a given problem, perhaps I could try to take the average for multiple metrics and get a more ""balanced"" metric - is this a mathematically valid approach?? As an example, I simulated this dataset in R: set.seed(123)

myFun <- function(n = 5000) {
  a <- do.call(paste0, replicate(5, sample(LETTERS, n, TRUE), FALSE))
  paste0(a, sprintf(""%04d"", sample(9999, n, TRUE)), sample(LETTERS, n, TRUE))
}

col1 = myFun(10)
col2 = myFun(10)
col3 = myFun(10)
col4 = myFun(10)

example = data.frame(col1, col2, col3, col4)

         col1       col2       col3       col4
1  ONHGW1599P VTYUV6387G LPTDH0712U KYIQF7684P
2  SVZUU4237T RVNEL9039J NMYTN9644I ATIZR2378Q
3  NYGLG3937F QYCHT7281E SSPLU5370G YZEQQ5509U
4  CZJOU4089K BNNSN9175F YXXVM3501G SGWZE4213M
5  JEIJF2907H DYGJQ4715P GTVQB3069Z JYNUY9271U
6  RSSMY0294V MWCRN0151X VOKJK8720J UWNGT9433H
7  VYDGB8469V ECWJV6810U ZGPTM4055X VZFUC7826U
8  KYNIE0041G VHVLC9830W IDTKN9761V MTAZY1706G
9  EIQIH8508P SPZBH8174K GAHYF0473W KXZIN7879T
10 TCKJL7391Q YLOJN6911D BHCWY6098Z KYJTA9065R Suppose I am interested in comparing all possible comparisons between (col1,col2) and (col3,col4). The R programming language is able to evaluate the following distance metrics: method = c(""osa"", ""lv"", ""dl"", ""hamming"", ""lcs"", ""qgram"", ""cosine"", ""jaccard"", ""jw"",""soundex"") I wrote this loop that can calculate all these metrics for all possible combinations: method = c(""osa"", ""lv"", ""dl"", ""hamming"", ""lcs"", ""qgram"", ""cosine"", ""jaccard"", ""jw"",""soundex"")

library(stringdist)

results = list()

for (i in 1:length(method))

{

method_i = method[i]
name_1_i = paste0(""col1_col_2"", method_i)
 name_2_i = paste0(""col3_col_4"", method_i)

p1_i = stringdistmatrix(col1, col2, method =  method_i, useNames = ""string"") %>%
            as_tibble(rownames = ""a"") %>%
            pivot_longer(-1, names_to = ""b"", values_to = name_1_i)

p2_i = stringdistmatrix(col3, col4, method =  method_i, useNames = ""string"") %>%
            as_tibble(rownames = ""a"") %>%
            pivot_longer(-1, names_to = ""b"", values_to = name_2_i)

p1_i = p1_i[,3]
p2_i = p2_i[,3]

final_i = cbind(p1_i, p2_i)

results[[i]] = final_i
}

final = do.call(cbind.data.frame, results)
final = cbind(col1,col2, col3,col4, final) I can now proceed to take these averages as follows and append them to the original data: average_col1_col2_dist = (final $col1_col_2osa  + final$ col1_col_2lv + final $col1_col_2dl      + final$ col1_col_2hamming + final $col1_col_2lcs +     final$ col1_col_2qgram  + final $col1_col_2cosine    + final$ col1_col_2jaccard + final $col1_col_2jw   + final$ col1_col_2soundex)/10

 average_col3_col4_dist =  ( final $col3_col_4osa     +    final$ col3_col_4lv       +     final $col3_col_4dl  +     final$ col3_col_4hamming +  final $col3_col_4lcs +  final$ col3_col_4qgram  +   final $col3_col_4cosine +    final$ col3_col_4jaccard  +    final $col3_col_4jw     +   final$ col3_col_4soundex)/10

final = data.frame( col1, col2, col3, col4, average_col1_col2_dist,  average_col3_col4_dist)

        col1       col2       col3       col4 average_col1_col2_dist average_col3_col4_dist
1 ONHGW1599P VTYUV6387G LPTDH0712U KYIQF7684P               7.985784               7.728889
2 SVZUU4237T RVNEL9039J NMYTN9644I ATIZR2378Q               6.692500               7.310131
3 NYGLG3937F QYCHT7281E SSPLU5370G YZEQQ5509U               7.523311               7.123930
4 CZJOU4089K BNNSN9175F YXXVM3501G SGWZE4213M               6.471213               7.338889
5 JEIJF2907H DYGJQ4715P GTVQB3069Z JYNUY9271U               6.276818               6.181671
6 RSSMY0294V MWCRN0151X VOKJK8720J UWNGT9433H               6.578095               7.313864 Now my question - is this approach that I have outlined mathematically valid? I know that you can take the average of any set of measurements, but the resulting average might not always be ""logical"" (e.g. measurements in different units). Inspecting the results, I see that ""qgram distances"" appear to be significantly larger than ""cosine distances"" - this makes me think that perhaps I might be able to ""normalize"" each column (e.g. final = scale(final) ) - but again, I am not sure if this is a mathematically valid approach. Does anyone have any ideas if it is mathematically valid to compare the average of multiple string metrics? Thank you!","['average', 'statistics', 'means']"
4583999,Definition of the formal $L^2$-adjoint $T^*$ of a linear operator $T:C^\infty(T^*M\odot T^*M)\to C^\infty(M)$,"Let $(M,g)$ be a Riemannian manifold, $C^\infty(T^*M\odot T^*M)$ the space of all smooth symmetric $2$ -tensor fields on $M$ , and $C^\infty(M)$ the space of all smooth functions on $M$ . I'd like to know the definition of the formal $L^2$ -adjoint $T^*$ of a linear operator $T:C^\infty(T^*M\odot T^*M)\to C^\infty(M)$ . For a concrete example of $T$ , one can see Linearization of scalar curvature: $DR|_g(h)=-\Delta_g(\mathrm{tr}_g h)+\mathrm{div}_g(\mathrm{div}_g h)-\langle\mathrm{Ric}_g,h\rangle_g$ to know about the linearized scalar curvature. In a linear algebra course or a functional analysis course, it is a standard practice to define the adjoint of a linear operator between inner product spaces, but somehow I didn't find too much reference on formal adjoints . So far, I've got only one example: given a closed manifold, we know the gradient operator $\mathrm{grad}$ and $-\mathrm{div}$ are the formal adjoints of each other in the sense that $$\int_M\langle\mathrm{grad}f,X\rangle_g dV_g=\int_M f(-\mathrm{div}X) dV_g\tag{1}$$ for every $f\in C^\infty(M)$ and every smooth vector field $X$ in $\mathfrak{X}(M)$ . How about $T^*$ ? By analogy with the previous example and my experience of ordinary adjoint operators, it seems like I have to find a linear operator $T^*$ that goes from $C^\infty(M)$ to $C^\infty(T^*M\odot T^*M)$ and satisfies $$\langle T(A),f\rangle_{L^2}=\langle A,T^*(f)\rangle_\color{red}{?}\tag{2}$$ for every $A\in C^\infty(T^*M\odot T^*M)$ and every $f\in C^\infty(M)$ . Having learned the Lebesgue space $L^p(M)$ , I don't feel pressured about the $L^2$ bracket in (2), but what should I do with the mysterious bracket in the same equation? Is that an inner product of covariant $2$ -tensor fields? Much is appreciated if someone could offer an authoritative reference that clearly defines the formal adjoint of a mapping between spaces of smooth sections of vector bundles. Thank you.","['curvature', 'adjoint-operators', 'riemannian-geometry', 'differential-geometry']"
4584003,The admissible exponents of Strichartz estimate,"The Strichartz estimate for the Schrodinger equation is well-known: $$
\|e^{it\Delta} u_0\|_{L^p_t L^q_x} \le C \|u_0\|_{L^2_x},
$$ where the exponent $p,q \in [2,\infty]$ satisfy $$
\frac{2}{p}+\frac{d}{q} = \frac{d}{2}, \quad (p,q,d) \neq (2,\infty,2).
$$ I wonder whether we can replace $L^2$ -norm of the R.H.S. to $L^r$ -norm.
More precisely, I would like to know if we get an estimate like the following: $$
\|e^{it\Delta} u_0\|_{L^p_t L^q_x} \le C \|u_0\|_{L^r_x}.
$$ The above estimate is invariant with respect to the scaling when $(p,q,r)$ satisfies $$
\frac{2}{p}+\frac{d}{q} = \frac{d}{r}.
$$","['harmonic-analysis', 'real-analysis', 'calculus', 'functional-analysis', 'partial-differential-equations']"
4584026,How can I prove that this matrix is idempotent?,"I have the following matrix $$A=\begin{equation}
\begin{pmatrix}
0 & a & -b\\
-a & 0 & c\\
b & -c & 0
\end{pmatrix}
\end{equation}$$ I have to prove that $M=A^2+I$ is idempotent knowing that $a^2+b^2+c^2=1$ . I can calculate M  using brute force as $$M=
 \left( \begin{array}{ccc}
0 & a & -b \\
-a & 0 & c \\
b &-c & 0
\end{array} \right)
%
\left( \begin{array}{ccc}
0 & a & -b \\
-a & 0 & c \\
b &-c & 0
\end{array} \right)
+
%
\left( \begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array} \right)
$$ I obtain $$ M=\left( \begin{array}{ccc}
c^2 & bc & ac \\
bc & b^2 & ab \\
ac & ab & a^2
\end{array} \right)$$ I have tried to solve this by brute force, but I cannot prove that $M=M^2$ , that is what I need to show that $M$ is idempotent since my result by brute force contains too many terms to simplify. Can someone explain to me how to do it?","['matrices', 'proof-writing', 'idempotents', 'products']"
4584102,"In the card game bridge, the 52 cards are dealt out equally to 4 players","I misunderstand conditional probability as in this problem In the card game bridge, the 52 cards are dealt out equally to 4 players—called East,
West, North, and South. If North and South have a total of 8 spades among them,
what is the probability that East has 3 of the remaining 5 spades? My calculation is. Let  E denote:"" East has 3 of the remaining 5 spades"" and F:"" North and South have a total of 8 spades among them"". Since $  P(E|F)= \frac {P(EF)}  {P(F)} $ For $P(F)= \frac {{13 \choose 8}  * {39 \choose 18}} {{52 \choose 26}}$ =0,161 And $P(EF)= \frac {{13 \choose 8}*{39 \choose 18}*{5 \choose 3}*{18 \choose 10}}{{52\choose 26}*{26 \choose 13}}$ =0,32.
But the answer is 0,339. What is wrong with my calculation?","['combinatorics', 'card-games', 'probability']"
4584128,4th moment of the sample mean estimator,"I got a following setup: $(X_i)_{i \geq 1}$ are iid random variables with values in $\mathbb{R}$ and finite second moment. By the weak law of large numbers: $\sqrt{n}(\bar{X} - E(X))$ converges in distribution to $N(0, Var(X))$ , so we could deploy the delta method with a transformation $g(x) = x^4$ , implying that $\sqrt{n}g(\bar{X} - E(X))$ should be normally distributed. I was trying to convince myself about it: $$
\sqrt{n}g(\bar{X} - E(X)) = \sqrt{n}(\bar{X} - E(X))^4 = \sqrt{n}(Var(\bar{X}))^2 = \sqrt{n} \text{Var}(X)^2 \to \infty \text{ for } n \to \infty$$ so $\sqrt{n}g(\bar{X} - E(X))$ can't be normally distributed Am I right? If I am, why does the delta method doesn't work in this case? Thanks!","['delta-method', 'statistics', 'asymptotics', 'probability']"
4584162,Semisimplificity of restriction of representations over finite fields,"Let $G$ be a finite group, and $H$ a Sylow $p$ -subgroup of $G$ . Suppose $V$ is a semisimple finite-dimensional representation of $G$ over $\mathbb{F}_p$ where $\mathbb{F}_p$ is a finite field of order $p$ . Question: Is the restriction $\text{Res}^{G}_{H}V$ of $V$ to $H$ semisimple? This is the inverse of ploblem A representation is semisimple if its restriction to a subgroup of index prime to ${\rm Char}(F)$ is semisimple . Note that it is true if $H$ is normal in $G$ by Clifford's Theorem. Any comments and reference would be highly appreciated.","['finite-fields', 'representation-theory', 'finite-groups', 'sylow-theory', 'group-theory']"
4584205,$\Bbb Z$ $\times$ $\Bbb N$ Countably Infinite,"I want to do this using an infinite grid as it seems easiest to me but I am open to other suggestions as well to improve my understanding. My attempt: $$\begin{array}{c | c | c | c | c}
(0,0) & (1,0) & (-1,0) & (2,0) & (-2,0).....\\ \hline (0,1) & (1,1) & (-1,1) & (2,1) & (-2,1).....\\ \hline (0,2) & (1,2) & (-1,2) & (2,2) & (-2,2)..... \\ \hline (0,3) & (1,3) & (-1,3) & (2,3) & (-2,3).....
\end{array}$$ $$\begin{array}{c | c | c | c | c}
1 & 3 & 6 & 10 & 15.....\\ \hline 2 & 5 & 9 & 14 & 20.....\\ \hline 4 & 8 & 13 & 19 & 26..... \\ \hline 7 & 12 & 18 & 25 & 33.....
\end{array}$$ The columns also extend down by an infinite amount. I then tried to create a bijection from $\Bbb N$ $->$ $\Bbb Z$ $\times$ $\Bbb N$ by starting from the top left at $(0,0)$ , and then preceding up each diagonal from bottom left to top right. So $1$ maps to $(0,0)$ , $2$ maps to $(0,1)$ , $3$ maps to $(1,0)$ and so on. This creates a bijection $f$ : $\Bbb N$ $->$ $\Bbb Z$ $\times$ $\Bbb N$ in which each natural number maps to the pair ( $a,b)$ in the grid above. I then explained why this is both injective and surjective to give a bijection.","['elementary-set-theory', 'infinity', 'combinatorics', 'analysis']"
4584225,How to switch a sum and an integral with a summation variable in its upper bound?,"Recently, I looked at some problems in which the order of summation and integration were reversed to arrive at a solution. I believe the process could be summed up (excuse the pun) in this way: $$\left.\sum_{n=a}^{b} \int_c^d  f(x,n) \ dx= \int_c^d \sum_{i=a}^{b} f(x,n) \ dx \qquad \right| \ a,b \in \mathbb{N}, c,d \in \mathbb{R}\ \forall\ a<b, c<d $$ where $f(x, n)$ is a function with $x$ and $n$ inputs and satisfies the respective theorems needed to permit the exchange in order of discrete and continuous sums, to begin with (dominated convergence theorem, monotone convergence theorem, etc.). However, this led me to ponder on how the order of a sum and an integral with its upper bound as this sum's summation variable may be exchanged (now that I have typed it - it probably sounds a bit like nonsense) Perhaps my question should be as follows: $$\left.\sum_{n=a}^{b} \int_c^n f(x,n)\ dx = \int_?^? \sum_{n=?}^{?} f(x,n) \ dx \qquad \right| \ c \in \mathbb{R}, a,b \in \mathbb{N}, c ≤ a $$ (although c = a may introduce redundancy on the first term of the first expression) If it is possible to express the first expression in such a form, please could you tell me? It would be much appreciated. Thank you :)","['integration', 'calculus', 'analysis']"
4584232,"Right triangle $\triangle ABC$, $D$ lies on $AB$, inscribed in a circle of radius $9$. Find the measure of $CD$","I saw this mathematical puzzle on an Instagram post today. As title suggests, we have a right angled triangle inscribed in a circle with radius $D$ and some angles. The goal is to find the length of $CD$ . I'll share my approach as an answer below. I'm not quite sure if my answer is correct, so please feel free to point out any faults in my approach and/or post your own approaches too!","['euclidean-geometry', 'circles', 'geometry', 'solution-verification', 'trigonometry']"
4584289,"Family of finite groups ""universal with respect to epimorphisms""","The Cayley theorem states that every group is isomorphic to a permutation group. This can be rephrased as follows: for each finite group $G$ there is a positive integer $n$ and a monomorphism from $G$ to $S_n$ . Therefore the family $(S_n)_{n=1}^{\infty}$ is universal in the sense that any group is isomorphic to a subgroup of some family member. Can we find a family with similar property, but with ""epi"" instead of ""mono""? Ie., is there a reasonable family of finite groups, such that every finite group is a quotient group of some family member? (By ""reasonable"" I mean something ""smaller"" than the family of all finite groups and not constructed specifically for our purpose.)","['group-homomorphism', 'group-theory', 'finite-groups']"
4584294,Find the value of: $\sqrt[3]{a+b}+\sqrt[3]{b+c}+\sqrt[3]{a+c}$,"Let $a,b,c$ be roots of the cubic $$x^3-x^2-2x+1=0$$ Then, find the value of: $$\sqrt[3]{a+b}+\sqrt[3]{b+c}+\sqrt[3]{a+c}$$ My attempt. I used the substitutions $$a+b=x^3, b+c=y^3, a+c=z^3$$ $$x^3+y^3+z^3=2(a+b+c)=2$$ Then I used the identity $$x^3+y^3+z^3=(x+y+z)^3-3(x+y+z)(xy+yz+xz)+3xyz$$ But I stuck here. I can not simplify $$xy+yz+xz$$","['contest-math', 'cubics', 'roots', 'radicals', 'algebra-precalculus']"
4584303,Combinatorial Interpretation of a partition identity,"I am working on the book "" Number Theory in the Spirit of Ramanujan "" by Bruce Berndt. In Exercise $1.3.7$ : He wants us to prove that $$
np\left(n\right) = \sum_{j = 0}^{n - 1}p\left(j\right)\sigma\left(n - j\right)
$$ where $p(n)$ is the number of partitions of $n$ and $\sigma(n)$ is the sum of divisors of $n$ . I did solve the exercise by following his hints. However, I could not find any combinatoric explanation of the identity. Is there any combinatorial explanation for this identity? Thanks in advance. The solution provided in the book: STEP1: Let's start with the identity $F(q) := \sum_{n=0}^{\infty}p(n)q^n=\frac{1}{(q;q)_\infty}$ where $p(n)$ is the number of partitions of $n$ and $(q;q)_\infty := (1-q)(1-q^2)(1-q^3).. $ . STEP2: Take logarithm of both sides and differentiate to get: $$\frac{\sum_{n=0}^{\infty}np(n)q^{n-1}}{\sum_{n=0}^{\infty}p(n)q^n} = \frac{1}{1-q} + \frac{2q}{1-q^2} + \frac{3q^2}{1-q^3} + ... = \sum_{n=1}^{\infty}\frac{nq^{n-1}}{1-q^n} $$ STEP3: Expand the geometric series in the right hand side to get: $$\sum_{n=1}^{\infty}nq^{n-1}\sum_{m=0}^{\infty} q^{nm} = \sum_{n=1}^{\infty}\sigma(n)q^{n-1}$$ where $\sigma(n) = \sum_{d|n} d$ . STEP4: Now, cross-multiplying each sides and equating the coefficients of $q^n$ s in both sides gives the desired result.","['integer-partitions', 'number-theory', 'q-series', 'combinatorial-proofs']"
4584395,"Prove that for any nonsingular complex matrix $A$ and for any positive integer $k$, the equation $X^k = A$ has a solution","Prove that for any nonsingular complex matrix $A$ and for any positive integer $k$ , the equation $X^k = A$ has a solution. Any tips or solution?","['matrices', 'matrix-equations', 'proof-writing', 'linear-algebra']"
4584425,Maximum symmetry metric on Cayley Plane $ F_4/Spin(9) $,"The maximum symmetry metric on real projective space $ \mathbb{RP}^n $ is the round metric. The maximum symmetry metric on complex projective space $ \mathbb{CP}^n $ is the Fubini-Study metric. https://mathoverflow.net/questions/433847/maximum-symmetry-metric-on-mathbbcpn Let $ M $ be a compact connected manifold. The degree of symmetry of $ M $ , denoted $ N(M) $ , is the maximum of the dimensions of the isometry groups of all possible Riemannian structures on $ M $ . See for example https://www.ams.org/journals/tran/1969-146-00/S0002-9947-1969-0250340-1/S0002-9947-1969-0250340-1.pdf Two metrics are considered to be equivalent if they are isometric up to a constant multiple. I'm interested in manifolds $ M $ for which there is a unique up to equivalence metric with isometry group of dimension $ N(M) $ . Is the pushforward of the biinvariant metric of $ F_4 $ onto the Cayley projective plane $$
\mathbb{OP}^2 \cong F_4/Spin(9)
$$ a maximum symmetry metric in this sense?","['symmetric-spaces', 'lie-groups', 'riemannian-geometry', 'differential-geometry']"
4584449,Proof by induction factorial [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question For $m, n ∈ \Bbb N, m ≥ 1$ , let $S(m, n)$ be the number of solutions to the equation: $x_1 + x_2 + \cdots + x_m = n$ , where $x_i ∈ \Bbb N$ for $i = 1, \ldots , m$ .
Using induction, prove that for all, $m, n \in\Bbb N, m ≥ 1$ , $$S(m, n) = \frac{(n + m − 1)!}{(m − 1)!\,n!}$$ I am unable to solve this question, any contribution is highly appreciated.","['induction', 'discrete-mathematics', 'recreational-mathematics']"
4584535,Sets and cartesian product question,"I have the sets $S = \big\{1,2,3,4,5\big\}$ and $A\subseteq S \times S$ given by $A = \big\{(1, 1), (2, 1), (2, 4), (3, 2), (3, 4), (3, 5), (4, 1), (4, 4), (5, 2), (5, 4), (5, 5)\big\}$ . I want to find the number of sets $B \subseteq S \times S$ such that $A\subseteq B$ and $B$ is a reflexive relation. The part that confuses me is in this case, what does a reflexive relation look like? How wold I go about counting them? Would I use combinations?","['combinatorics', 'discrete-mathematics']"
4584537,Diophantine equation ${x ^ 2}+{y ^ 2}+{z ^ 2}={m ^ 2}+{n ^ 2} $ has infinite solutions. What is its general solution formula?,"Diophantine equation ${x ^ 2}+{y ^ 2}+{z ^ 2}={m ^ 2}+{n ^ 2} $ has infinite solutions. For examples, $\begin{array}{l}
{1^2}+ {3^2} + {4^2}  = {1^2} + {5^2}\\
{1^2} + {2^2} + {6^2} = {4^2} + {5^2}\\
{322^2} + {562^2} + {597^2} = {601^2} + {644^2}\\
{938^2} + {1063^2} + {4722^2} = {536^2} + {4901^2}\\
 \vdots 
\end{array}$ What is its general solution formula? How to get the general solution formula?","['computational-mathematics', 'number-theory', 'discrete-mathematics', 'diophantine-equations']"
4584550,Why is a multivariable function satisfying the following conditions exact?,"I read this section in the book ""Mathematics Methods for Physics and Engineering"" Determining whether a differential containing many variable $x_1,x_2,...,x_n$ exact is a simple extension of the above. A differential containing many variables can be written in general as $$df=\Sigma^n_{i=1}g_i(x_1,x_2,...,x_n)dx_i$$ and the function will be exact if $\frac{\partial g_i}{\partial x_j}=\frac{\partial g_j}{\partial x_i}$ for all pairs of i and n. I can understand the situation when there are only two variables in the function, but when there are many variables, I am a bit confused about why this condition is already necessary  to prove that the function is exact, instead of requiring all partial derivatives of the function to be equal.","['multivariable-calculus', 'partial-differential-equations']"
4584578,"What is a set of generators for $PSL(2,p)$ for $p$ prime?","What is a set of generators for $PSL(2,p)$ when $p$ is prime, in particular when $p$ is a Mersenne prime? I know that for $p=7=2^3-1$ , we can view $PSL(2,7)$ as the group of linear fractional transformations and the generators are $k\mapsto -1/k$ , $k\mapsto k+1$ , and $k\mapsto 2k$ . This works because the quadratic residues modulo 7 are powers of 2, $\{1,2,4\}$ . How does this generalize, for example to $p=31$ ?","['finite-fields', 'projective-geometry', 'discrete-mathematics']"
4584599,Why does an inverse function's range have to be its entire codomain?,"(Noob question.) I'm working through Khan Academy, and one of the criteria that Sal mentioned for a function to be invertible is that its range must be equal to its entire codomain, which means that one of the criteria is that the function must be surjective. So for a function like $f(x)=e^x$ which is a mapping from ℝ^1 to ℝ^1, does it mean that $e^x$ is not invertible because the image (range) of $e^x$ is not the entire codomain ℝ^1? For example, $e^x$ can never equal a negative number, and so automatically we know that $e^x$ does not span its codomain (the function's range is smaller than the codomain), which is  ℝ^1. However, we know that $e^x$ does have an inverse , and that inverse is $\ln\left(x\right)$ . Does this go against what the definition of a function being invertible? What am I getting wrong here? Help would be appreciated.","['functions', 'inverse']"
4584649,How to prove $\sum_{k=0}^n {n\choose k} \frac{(-1)^{k-1}}{2k-1} = 1+ \sum_{k=0}^{n-1} \frac{4^k (k!)^2}{(2k+1)!} = \frac{4^n (n!)^2}{(2n)!}$?,"In doing a calculation for my research I need a simple formula for the integral: $$ I = 1 + \int_0^1 \frac{1-(1-x^2)^n}{x^2} dx$$ for natural $n$ . Expanding the factor $(1-x^2)^n$ using the binomial theorem and integrating gives: $$ I = \sum_{k=0}^n {n\choose k} \frac{(-1)^{k-1}}{2k-1}.$$ Alternatively, the integrand can be rewritten as a geometric sum: $$ \frac{1-(1-x^2)^n}{x^2} = \sum_{k=0}^{n-1} (1-x^2)^k $$ and then each term in this sum can be integrated (and manipulated to give a beta function). The result gives: $$ I =  1+ \sum_{k=0}^{n-1} \frac{4^k (k!)^2}{(2k+1)!}. $$ In order to match to the result I expected from this calculation I need it to be true that: $$ I = \frac{4^n (n!)^2}{(2n)!} $$ and checking for values of $n < 100$ numerically these formulae do match and so I think this is correct. However, I don't know how to prove that either of my sum expressions or my initial integral expression for $I$ are equal to this final simple result. How can I show that $I$ is given by this final formula?","['summation', 'combinatorics', 'induction', 'discrete-mathematics']"
4584675,intuition for $\lim_{n \to \infty} f_n'(x) \ne f'(x)$ (Tom Apostol's exercise $11.7.18$),"Let $f_n(x) = \frac{\sin nx}{n}$ and $f(x) = \lim_{n \to \infty} f_n(x)$ . Therefore, for all fixed $x$ , $f(x) = 0$ The derivatives are then (for all fixed $x$ ): $f_n'(x) = \cos nx$ and $f'(x) = 0$ . I understand that numerically $\lim_{n \to \infty} f_n'(0) = 1 \ne 0 = f'(0)$ , but I don't know how to understand that intuitively. I guess the simplest thing to say is that information about $n$ is lost in $f(x)$ , so it cannot cancel out in the derivative, like it did in the $f_n'(x)$ . Or even simpler, to just say that the two are simply two different functions. I'm looking forward to get a better explanation. Clarification, after seeing Jyrki's answer: $f_n'(0)=1$ always. If $f_n$ for higher $n$ becomes flatter at 0, why is $f_n'(0)$ also not approaching $0$ as $n \to \infty$ ? If $f_n(0)$ does not become flat with higher $n$ s (e.g. but it just oscillates with a higher frequency), then why is $f'(0)$ also not different from $0$ ?","['limits', 'convergence-divergence', 'pointwise-convergence']"
4584731,Prove that $\tan(x)-\tan(3x)-\tan(\pi/2-3x)+\tan(\pi/2-x)=4\cos(4x)/\sin(6x).$,"I have been working on it but haven't managed to prove it. This is $(b)$ part of the question. In part $(a)$ , I have proved that $\tan(y)+\cot(y)=\frac{2}{\sin(2y)}$ . My steps are as follows: \begin{equation*}
LHS=\tan(x)-\tan(3x)-\tan\left(\frac{\pi}{2}-3x\right)+\tan\left(\frac{\pi}{2}-x\right)
= \tan(x)-\tan(3x)-\cot(3x)+\cot(x)
=\tan(x)+\cot(x)-(\tan(3x)+\cot(3x))
=\frac{2}{\sin(2x)}-\frac{2}{\sin(6x)}.
\end{equation*} And I don't know how to continue to prove it to be $\frac{4\cos(4x)}{\sin(6x)}$ . Hope you can help","['trigonometry', 'solution-verification']"
4584743,What distribution has this pdf and CDF?,"I am using the following probability distribution function defined for $x \in [0, \infty)$ with $\alpha>0$ : $$ f(x\mid\alpha)= \frac{\alpha}{(x+\alpha)^2}$$ the CDF is $$ F(x\mid\alpha)= \frac{x}{x+\alpha}$$ does this distribution have a name? Has it been studied?","['cumulative-distribution-functions', 'probability-distributions', 'probability-theory', 'density-function']"
4584841,prove two identities regarding chebyshev polynomials and derivatives,"The source of this problem is putnam and beyond #198, so I tagged it under contest-math. Let $T_n(x)$ be the sequence of polynomials defined by $T_0(x) = 1, T_1(x)=x, T_n(x)=2xT_{n-1}(x)-T_{n-2}(x)$ for $n\ge 2.$ Let $U_n(x)$ be the sequence of polynomials defined by $U_0(x)=1, U_1(x)=2x, U_n(x)=2xU_{n-1}(x)-U_{n-2}(x)$ for $n\ge 2$ . For $n\ge 1,$ prove the following identities: $\dfrac{T_n(x)}{\sqrt{1-x^2}} = \dfrac{(-1)^n}{1\cdot 3\cdots (2n-1)}\dfrac{d^n}{dx^n}(1-x^2)^{n-1/2}$ $U_n(x) \sqrt{1-x^2} = \dfrac{(-1)^n(n+1)}{1\cdot 3\cdots (2n+1)} \dfrac{d^n}{dx^n} (1-x^2)^{n+1/2}$ It is known that $\cos (n\theta) = T_n(\cos \theta)$ for all $n\ge 0$ (e.g. by induction using the fact that $\cos(n\theta)$ is a polynomial of $\cos \theta$ and that the polynomial expressing $\cos (n\theta)$ as a polynomial of $\cos \theta$ and $T_n$ agree at infinitely many points) and $\dfrac{\sin ((n+1)\theta)}{\sin (\theta)} = U_n(x)$ for $n\ge 0$ . I think one possible approach is to show that the two expressions on each side of the first identity have the same recurrence relation and base case. When $n=1,$ equality holds in both cases. For the left-hand side (LHS), we have the recurrence $T_n(x)/\sqrt{1-x^2} = 2x\dfrac{T_{n-1}(x)} {\sqrt{1-x^2}} - \dfrac{T_{n-2}}{\sqrt{1-x^2}}.$ In other words, if $a_n$ denotes the LHS, then $a_n(x) = 2xa_{n-1}(x)-a_{n-2}(x).$ Then we have $\begin{align*}\dfrac{d^{n+1}}{dx^{n+1}} (1-x^2)^{n+1-1/2} &= \dfrac{d^n}{dx^n} (n+1-1/2)(1-x^2)^{n-1/2}(-2x)\\
&= \dfrac{d^n}{dx^n} -(2n+1) x (1-x^2)^{n-1/2}\\
&= \dfrac{d^{n-1}}{dx^{n-1}} (-(2n+1) (1-x^2)^{n-1/2} -(2n+1)x\dfrac{d}{dx}(1-x^2)^{n-1/2})\\
&= -(2n+1)\dfrac{d^{n-1}}{dx^{n-1}} (1-x^2)^{n-1/2}
\end{align*}$ We need to show that if $t_n(x)$ denotes the right-hand side, then $t_n(x)= 2xt_{n-1}(x) - a_{n-2}(x).$ For the second identity, it could be useful to differentiate both sides and use the fact that if two functions have the same initial conditions and the same derivative, then they must be equal. We have for $|x|<1$ that $(1-x^2)^{n+1/2} = \sum_{i=0}^\infty {n+1/2\choose i} (-x^2)^i.$ Here, for a real number x and integer $j\ge 0$ , ${x\choose j} := \dfrac{x(x-1)\cdots (x-j+1)}{j!}.$ Let $u_n(x)$ denote the RHS of the second identity. Again it may be useful to prove that $u_n(x)$ satisfies the same recurrence relation as the LHS, but I'm not sure about the details for this. Note that $-xU_{n-1}(x) + 2(1-x^2) U'_{n-1}(x)=-nT_n(x),$ which can be shown by showing that both sides equal each other whenever $x=\cos \theta$ for some $\theta\in [0,2\pi)$ .","['contest-math', 'recurrence-relations', 'calculus', 'polynomials', 'derivatives']"
4584863,When does the Fourier transform of a measure vanish at a point?,"Given a finite Borel measure $\mu$ on $\mathbf{R}$ , consider its Fourier transform which is defined as: $$\hat{\mu}(\xi) = \int_{\mathbf{R}} e^{2\pi i x \xi} \, d\mu(x). $$ Two questions about this: Suppose that $\int_{\mathbf{R}} x^n \, d\mu(x) = 0$ for some $n \geq 1$ . Can we show that there exists a $\xi \in \mathbf{R}$ such that $\hat{\mu}(\xi) = 0$ ? More generally, is there a sufficient condition we can place on the measure $\mu$ that ensures that there exists a point $\xi \in \mathbf{R}$ such that $\hat{\mu}(\xi)=0$ ? For example, is there some multiplicative function $f(x)$ such that if $\int_{\mathbf{R}} f(x) \, d\mu(x) = 0$ , then there must exist $\xi \in \mathbf{R}$ such that $\hat{\mu}(\xi)=0$ ?","['measure-theory', 'fourier-analysis', 'real-analysis']"
4584873,Is it possible for a convex function that is not strictly convex to be nowhere linear?,"We say that a function $f\colon (a,b)\to \mathbb{R}$ , where $-\infty\leq a<b\leq +\infty$ , is convex (resp. strictly convex) if for all $x,y\in (a,b)$ with $x<y$ and for every $t\in (0,1)$ it holds that $f(tx+(1-t)y)\leq tf(x)+(1-t)f(y)$ $\Big($ resp. $f(tx+(1-t)y)< tf(x)+(1-t)f(y)\Big)$ . The simplest example of a convex function that is not stricly convex is a linear function $f(x)=\alpha x+\beta$ on any interval. However, linear functions do not exhaust all variants, since the function $f(x)=|x|$ on interval $(-1,1)$ is convex but not strictly convex. At the same time, this function is piecewise linear, so, in particular, linear at ""almost every"" neighborhood. My question is as follows: can a convex function $f$ that is not stricly convex be nowhere linear, that is, have the property that for every $x_0\in (a,b)$ and for every $\delta>0$ the function $f\big|_{(x_0-\delta,x_0+\delta)\cap (a,b)}$ is not linear, i.e. there is no $\alpha,\beta\in \mathbb{R}$ such that $f(x)=\alpha x+\beta$ for every $x\in (x_0-\delta,x_0+\delta)\cap (a,b)$ ?","['examples-counterexamples', 'real-analysis', 'calculus', 'functions', 'convex-analysis']"
4584932,non-linear system of a ODE,"Let $$y'=A(t)y(t)+b(t,y(t)), \qquad y(0)=y_0$$ and $U:=U_\epsilon(0)$ so that there exists $C\geq 0$ with $\|b(t,y)\|\leq C\|y\|$ for all $y\in U$ , $t \in \mathbb R$ and $y^TA(t)y\leq -\lambda \|y\|^2$ for all $t \in \mathbb R$ and a $\lambda>C$ . Prove that $y_0\in U \implies y(t) \in U$ for all $t>0$ . I tried to show $\|y(t)-0\| = \|y_0 + \int_0^t y'(s)ds\| \leq \dots \leq \epsilon$ but this does not lead to the goal.","['analysis', 'ordinary-differential-equations', 'real-analysis']"
4584945,"What's the ""best"" place for working in Manifolds/Surfaces?","I'm study Differential Geometry and I'm thinking about a pharese that my professor saying in a class: ""Talking about manifolds, working in the domain of a parametrization is better than working in contradomain of a parametrization, i.e, directly on manifold"".
I not understand what his did mean. For instance, in some books of literature(cf Do Carmo, Differential Geometry of Curves and Surfaces ), the Gauss Map is defined on manifold, i.e, let $M \subset R^3$ , the Gauss map is defined by $$
N: M \to S^2
$$ In other books, for exemple in Kühnel, Differential Geometry , the Gauss Map is defined on domain of parametrization: Let $f: U \to R^3$ a surface element (a parametrization), the Gauss $$
\nu: U \to S^2
$$ is defined by the formula $$
\nu(u,v) = \frac{f_u \times f_v}{|f_u \times f_v |}
$$ I observe that, the definition of Do Carmo, is more geometric than the definition of Kühnel, the formula for Gauss map in Coordinates in Do Carmo, depends of points on Surface, $$
N(p) = \frac{f_u \times f_v}{|f_u \times f_v |}(p)
$$ Discussion Considering that, $f: U \to R^3$ , is a parameterization, that is, if $M$ is a manifold in $R^3$ , $f$ is a homeomorphism of $U$ on $M$ , whose derivative of $f$ is injective, then, study in $M$ , wouldn't that be the same as studying in $U$ (topologycally speaking)? The only thing I can see right away is that studying in $M$ ​​seems to be more ""Geometric"" than studying in $U$ . Now, studying in $U$ seems to be independent of the parameterization (or of the chart), that is, it seems that it is something more general.
Another thing I realized is about the definition of a tangent plane to a manifold. For example, the tangent plane is defined to be a vector space that contains all vectors tangent to a surface. But, let's analyze the concept of ""tangent vector"". In some books, the tangent vector to a manifold is defined to be a tangent vector to a curve $a: I \to U$ , such that $a'(t)$ is a vector whose property is to be tangent to a at $t$ when it is translated by $a(t)$ , that is, the vector $v = a'(t) +a(t)$ is tangent(geometrically speaking) to the curve $a$ at $t$ . In this way, if $f$ is the parameterization of the surface, the derivative of the curve $f(a(t))$ is tangent to the surface in the same sense that I just explained in the case of the curve $a$ .
Where am I going with this? Well, my question is the following: if $a'$ and $b'$ are tangent vectors to the curves $a: I \to U$ and $b: J \to U$ , such that $\{a', b'\}$ span the tangent space $T_pU$ , ​​where $p$ is a point of $U$ , we know that $Df$ is an isomorphism of vector spaces, so $Df(TpU)$ is the tangent space to $M$ , that is, it is isomorphic to $T_{f(p)}M$ . Thus, it seems to me that nothing is lost, from an algebraic point of view, working on the variety (in the co-domain) than working on the domain. The conclusion I reached: It seems to me, that there are no topological, or algebraic differences, working in the codomain or in the domain. The only clear difference is that when working in the codomain, things become more geometric than when working in the domain. Could clarify for me, this sentence? Perhaps an example will make the difference between what you told me clearer for me. Something came to my mind, in the case, let's say, ""the philosophy"" of analysis on manifods , I mean, when dealing with an abstract manifold, throughout the course, we always worked in $R^n$ , we took the information obtained in $R^n$ to the variety across the charts, then we take notes and bring to manifold again.","['manifolds', 'differential-geometry']"
4584950,Solving a typical calculus question without using calculus.,"Alright the question is this: Find all values of $f(x)$ in range $<-1;3>$ ; $f(x) = 4^x - 2^{x+1} - 8$ . Now usually when approaching these types of questions I would just take the derivative and look for local minimums/maximums and calculate values at the range boundaries, but we haven't been taught the derivative for exponentials in school yet, so I wasn't able to answer this on a test. At home I was able to find the derivative and the question becomes TRIVIALLY easy, but without it I am simply stuck. Is there a way to reasonably approach this without derivatives or some guessing and checking?","['functions', 'exponential-function']"
4584970,"Understanding the space $D^{1,2}(\mathbb{R}^N)$","I have seem the following definition $$D^{1,2}(\mathbb{R}^N) := \{u \in L^{2^*}(\mathbb{R}^N) : |\nabla u| \in L^2(\mathbb{R}^N)\}.$$ I would like a reference that deals with this space deeply. I know this space is related with the best Sobolev constant. Specifically I'd like to know: a) How this space was born? b) This space has a norm or an inner product? I know this space is nonempty, because from Brezis (Functional Analysis, Theorem 9.9) that exists a constant $c > 0$ such that $$
\qquad |u|_{L^{2^*}(\mathbb{R}^N)} \leq c \, \|\nabla u \|_{L^{2}(\mathbb{R}^N)},\; \forall u \in W^{1,2}(\mathbb{R}^N).
$$ So, $W^{1,2}(\mathbb{R}^N) \subset D^{1,2}(\mathbb{R}^N)$ (is it right?) I need to understand this space very well and so far I haven't found any reference with this. Any help or reference is very welcome.","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
4585021,How to solve a differential equation of this form?,"Please consider a differential equation of the form: $$ (ax + by + c) dx + (ex + fy + g) dy = 0 $$ For the special case of $c = g = 0$ , then this equation is homogenous and I know how to solve it. Normally, I would solve this equation by setting up the following system of
equations: \begin{align*}
ax + by + c &= 0 \\
ex + fy + g &= 0 
\end{align*} Assuming that this set of equations of a unique solution, I know how to solve differential equation of this form. However, I how do I solve a differential equation of this form when the above system of differential equations does not have a unique solution? I am thinking the correct substitution is: $$ z = ax + by $$ which gives me: \begin{align*}
dz &= a\, dx \\
dz &= b\, dy 
\end{align*} Do I have this right?",['ordinary-differential-equations']
4585029,How many ways to place plus and minus signs in front of numbers from 0 to 12 so that the sum is divisible by 5?,"This question is from an old NIMO contest. Find the number of ways a series of + and − signs can be inserted between the numbers 0, 1, 2, · · ·, 12 such that the value of the resulting expression is divisible by 5. A computer program seems to indicate that the answer is 816. Approach: Reduce the problem to mod 5. There are three copies of 0,1,2 and two copies of 3,4. Now suppose there are exactly $x_i$ plus signs for copy $i$ . We see that for the sum to be divisible by 5, we must have $\sum ix_i =$ 4 mod 5. Now I was planning to crunch it out or use generating functions, but it looks complicated. Suggestions?","['contest-math', 'combinatorics']"
4585030,Why can't I use the form $\frac1{x^2+1}$ from the derivative of $\arctan(x)$ to convert the integral form in this situation?,"In the question that solves the integral $\displaystyle\int\frac1{6x^2 + 36x + 78} \,\mathrm{d}x$ , I first tried to solve it by changing the denominator in a form of $\dfrac1{x^2 + 1}$ to apply $\;\arctan(x)$ . $\dfrac1{6\!\cdot\!\left(x^2 + 6x + 13\right)}=\dfrac16\!\cdot\!\dfrac1{(x + 3)^2 + 2^2}$ Now, in order to make it in a form of $\;\dfrac1{x^2 + 1}\;,\;$ I divide everything by $\,2^2$ : $=\dfrac16\!\cdot\!\dfrac1{\left(\frac{x+3}2\right)^2+1}\!\cdot\!\dfrac1{2^2}
=\dfrac1{24}\!\cdot\!\dfrac1{\left(\frac{x+3}2\right)^2+1}$ Then assume that $\;u=\dfrac{x+3}2\;,\;$ I thought I can apply arctan to get rid of the integral form: $\dfrac1{24}\!\cdot\!\arctan\left(\dfrac{x+3}2\right)+c\;.$ But the correct answer is $\;\dfrac1{12}\!\cdot\!\arctan\left(\dfrac{x+3}2\right) + c\;,\;$ not $\;\dfrac1{24}\,.$ The answer also explained to use $\;\dfrac1{x^2 + k^2} = \left[\dfrac1k\!\cdot\!\arctan\left(\dfrac xk\right)\right]’$ (derivative), but I wonder why I cannot use the form of $\;\dfrac1{x^2 + 1}\;,\;$ which is the only equation I have known.","['integration', 'trigonometry', 'derivatives']"
4585070,Hard triple Integral $\int_{0}^{1}\int_{0}^{1}\int_{0}^{1}\frac{1}{2-zx^{2}-zy^{2}}dxdydz=\ln(2^{G})$,How do prove this triple integral? $$\int_{0}^{1}\int_{0}^{1}\int_{0}^{1}\frac{1}{2-zx^{2}-zy^{2}}dxdydz=\ln(2^{G})$$ where G is Catalan's constant. As my try I only reach to this hard single integral: $$\int _0^1\frac{\operatorname{Li}_2\left(\frac{1+x^2}{2}\right)}{1+x^2}dx=G\ln \left(2\right)$$,['integration']
4585184,Can a self-inverse function y=f(x) always be written as an equation that is symmetric with respect to x and y?,"For example, y=x/(x-1) is easily shown to be self-inverse, since f(f(x)) = x. For another approach, cross-multiply and rearrange terms to get xy = x+y.  Since the expression is symmetric with respect to x and y, it must be self-inverse, since an equation that gives y in terms of x will also give x in terms of y.  Is it always possible, at least in theory, to use this second approach to show that a function is self-inverse?","['functions', 'inverse']"
4585204,What different ways are there to construct the Lebesgue measure?,"I have recently learned of different approaches (which I've included below) to constructing the Lebesgue measure, and I'm somewhat startled by how much each approach can illuminate the theory as a whole. Are there still others approaches to defining the Lebesgue measure? If so, what are their benefits and disadvantages? Where may I read about them? $$\textbf{First Approach}$$ Starting with the premeasure $\mu$ defined only on boxes, and extending it into a measure through the follwing theorem: Carathéodory's Extension Lemma: let $\mu_0:\Sigma_0\to [0,\infty]$ be a pre-measure on the algebra $\Sigma_0$ of $X$ . Then $\mu_0$ can be extended to a measure $$\mu:\Sigma\to[0,\infty]$$ where $\Sigma:=\sigma(\Sigma_0)$ and $\mu|_{\Sigma_0}=\mu_0$ . Furhermore, if $\mu_0$ is finite, then the extension $\mu$ is unique. This approach is used in Williams' Probability with Martingales (PWM). It is worth mentioning that -excluding the proof of the theorem above- this is the simplest construction I know of. However, both of the proofs I know of the theorem above (one found at the end of PWT, and the other one found here ) first use the pre-measure to construct an outer measure $\mu^*$ and then restrict the outer measure to Lebesgue measurable sets. $$\textbf{Second Approach}$$ Parting from the outer Lebesgue measure $\mu^*$ and restricting it through the following theorem: Carathéodory's Restriction Lemma: let $\mu^*:2^X\to [0,\infty]$ be an outer measure on the power set $2^X$ of $X$ . Then $\mu^*$ can be restricted to a measure $$\mu:\Sigma\to[0,\infty]$$ where $\Sigma := \Big\{ C \in 2^X : C \text{ is Caratheodory measurable} \Big\}$ and $\mu := \mu^*|_{\Sigma}$ . (I've never seen the 'Restriction Lemma' named as such, but I find the name appropriate). The approach may be found in Tao's An Introduction to Measure Theory (IMT), as well as Hunter's Measure Theory (MT). This approach is, I believe, the most common one, though it left me puzzled as to why the restriction was made to Carathéodory measurable sets specifically; some intuition may be found in this post or by studying equivalent (and more geometrically intuitive) definitions of Lebesgue measurable sets (as in Exercise 1.2.7 in IMT). $$\textbf{Third Approach}$$ Parting again from the Lebesgue outer measure $\mu^*$ , one defines Lebesgue measurable sets as those which can be 'approximated from above' by open sets arbitrarily well: Definition: a set $E\subseteq \mathbb{R}^d$ is Lebesgue measurable iff for every $\varepsilon>0$ there is some open set $U\subseteq \mathbb{R}^d$ containing $E$ such that $\mu^*(U\setminus E)<\varepsilon$ . Then the Lebesgue measure is characterized as the restriction of $\mu^*$ to Lebesgue measurable sets, and a bit of work shows that the collection of Lebesgue measurable sets is a $\sigma$ -algebra, as well as that $\mu$ is a measure. The approach is not as generalizable, although it is arguably more geometrically intuitive (specially when similarities and dissimlarities with the Jordan measure are made). It is also found in IMT.","['measure-theory', 'definition', 'lebesgue-measure', 'big-list']"
4585220,Properties of prime numbers proven as finite [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 1 year ago . Improve this question Many modern proofs/conjectures concerning prime numbers (twin primes, infinite primes not containing one specific digit) intend to show that some property of prime numbers is infinite. Are there any similar, nontrivial properties of prime numbers that have been proven to only appear within the first n, but not the rest (finite)? As a rough guideline to nontriviality, there should be at least ~3 somewhat spread out instances of the property that discontinue after reaching some number above ~50. The property cannot solely involve a simple operator such as < or > , and ideally should not involve repeated deletion of digits (truncatable primes) as this makes proof via exhaustion easier.","['number-theory', 'prime-numbers']"
4585252,"Zariski closure of $\{ (z, \bar z) : z\in\Bbb C \}$","The question I am intersted in is: If a polynomial $p\in\Bbb C[x,y]$ has the property $\forall z\in\Bbb C: p(z,\bar z)=0$ , is $p$ automatically the zero polynomial? Equivalent formulations: Is every nonzero polynomial nonzero at some point $(z,\bar z)$ ? Is the Zariski closure of $\{(z,\bar z):z\in\Bbb C\}$ the entire space $\Bbb C^2$ ? I am almost certain that the answer must be yes, but I can't think of a proof.","['zariski-topology', 'algebraic-geometry', 'polynomials']"
4585315,"If $\frac{1+\sin{\theta}}{\cos{\theta}} = n$, find $\tan{\frac{1}{2}\theta}$.","The question is: If $\cfrac{1+\sin{\theta}}{\cos{\theta}} = n$ , find $\tan{\frac{1}{2}\theta}$ . I'm quite confused on how to solve this problem. What trigonometric identities do I use? I tried squaring them and ended with $n^2=\dfrac{1+\sin{\theta}}{1-\sin{\theta}}$ but I suppose that doesn't really help the problem. Any suggestions would be appreciated.","['fractions', 'algebra-precalculus', 'trigonometry']"
4585401,How to separate cubic equations into two conic sections: Deep dive into Omar Khayyam,"Lots of people have asked how to use Khayyam's method but I am studying for my dissertation so really need to understand the why . What I really don't understand/ can't find useful proofs for is how he separated cubic equations into two conic sections. A work I have been using to gain a preliminary understanding is ' Omar Khayyam: Geometric Algebra and Cubic Equations ' by Siadat and Tholen ( https://doi.org/10.1080/10724117.2020.1770495 ) which gives a quick breakdown of equations of the form x^3 + bx = c into a semicircle and a parabola but it does not explain how Khayyam came to centre the semicircle at (r,0) or why the parabola is of the form y = x^2/sqrt(b), or even why he chose a semicircle and parabola in the first place, apart from that the maths simply works. I know that he built off of the works of menaechmus if that is relevant? Any good references anyone knows or if anyone knows how I should go about trying to prove equations of differing forms would be really helpful, thanks!","['algebraic-geometry', 'conic-sections', 'math-history', 'roots-of-cubics']"
