question_id,title,body,tags
2982158,Solution to equation using permutation,"I am hoping I am on the right track for my homework in Discrete Math. How many solutions does the equation $$a + b + c + d + e + f = 30$$ have if each variable must be a non-negative integer and $a ≤ 3, b ≤ 7$ and $d ≥ 8$ ? I started my solution using the formula: ${m+n-1 \choose n-1}$ where m is the number of non-distinct objects and n is the number of distinct objects. d ≥ 8 where ${22+9-1 \choose 9-1}$ = ${30 \choose 8}$ Then, a ≤ 3 which can be represented as a ≥ 4 ${17+6-1 \choose 6-1}$ = ${21 \choose 5}$ Finally, b ≤ 7 which can be represented as b ≥ 8 ${9+6-1 \choose 6-1}$ = ${14 \choose 5}$ During this process we have removed solutions for a ≤ 3 and b ≤ 7 twice so we have to add the solution back in once. We removed 25 - (3+7) = 15 so we must add back ${15+6-1 \choose 6-1}$ = ${20 \choose 5}$ Therefore, our solution is as follows: ${30 \choose 8}$ - ${21 \choose 5}$ - ${14 \choose 5}$ + ${20 \choose 5}$","['combinatorics', 'discrete-mathematics']"
2982172,What does $¥sum_{n=1}^¥infty¥frac{1}{¥sqrt n(n+1)}$ converge to exactly?,"If $$¥sum_{n=1}^¥infty¥frac{1}{¥sqrt n(n+1)}=S,$$ does $S$ have a known closed-form symbolic expression for its value? By the integral test it clearly converges, i.e. take $u=¥sqrt x$ and $u$ -substitute to get $$¥int_1^¥infty¥frac1{¥sqrt x(x+1)}dx=2¥arctan(¥sqrt x)¥rvert_1^¥infty=¥frac¥pi2.$$ The sum was also in a competition problem, or so I'm told, to show that $S<2$ (if a source for this problem can be found, I'd appreciate it).","['calculus', 'sequences-and-series', 'real-analysis']"
2982173,Is it possible to create sets that satisfy the following conditions?,"A class of 96 students must divide itself into 24 sets of 4 for an assignment. However, during the year there are 4 such assignments, and no student can ever work with any of the same partners. Prove that this is possible or impossible to do. Note that, if for project 1, Anne, Bob, Chris, and David are working together, then for project 2 Anne cannot work with Bob, Chris, or David for any other project.","['statistics', 'combinatorics']"
2982182,The limit $\lim_{x \to 0-} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4} \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt$,"A while back I derived the following expression valid for $x>0$ : $$\sum_{n=1}^\infty e^{-(n+x)^2}= \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt$$ While the integral doesn't converge for $x=0$ , it has a right limit: $$\lim_{x \to 0+} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt=\sum_{n=1}^\infty e^{-n^2}=\frac{1}{2} \left(\vartheta _3\left(0,\frac{1}{e}\right)-1\right)$$ But, despite the fact that the integral converges for $x<0$ , it converges to a different limit from the left side, as can be seen from the numerical plot by Mathematica: Surprisingly enough, by numerical integration with Mathematica, we seem to have: $$\lim_{x \to 0-} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt \approx -\frac{1}{2} \left(\vartheta _3\left(0,\frac{1}{e}\right)+1\right)$$ In other words, the limits are related as $L^- = -1-L^+$ . Is this correct? And why? Here's the derivation of the first equality https://math.stackexchange.com/a/2751575/269624 .","['limits', 'definite-integrals', 'sequences-and-series']"
2982189,Simplification of complex conjugates,"I was working through a limit problem and got stuck on the simplification. I have the answer key however I am not sure where I can simplify more. So the question is, $$f(z) = z \bar z$$ Differentiable at z=0. I know I can take the limit of this as it approaches zero to check for this. $$ f'(z) = \frac{f(z+h) - f(z)}{h}$$ Then the equation becomes: $$ f'(z) \lim z \Rightarrow 0 = \frac{(h+z)^2 (\bar h +\bar z) - z^2\bar z}{h}$$ $$ f'(z) \lim z \Rightarrow 0 = \frac{ (z^2 \bar h) + 2zh\bar h + h^2 \bar h + 2z \bar z h + h^2 \bar z}{h}$$ The professor has simplified then solution to: $$f'(z) \lim z \Rightarrow 0 = \frac{z^2 \bar h + 2z \bar z h }{h} $$ I think I must be missing some sort of an identity in my base knowledge. Any guidance would be greatly appreciated.","['complex-analysis', 'complex-integration', 'complex-numbers']"
2982210,Is the étale site a small category?,"Consider the étale site $X_{ét}$ of a scheme $X$ . As a category, this is the collection of all étale schemes over $X$ . Now, is this a set (i.e., is the étale site a small category)? If $X=Spec\ k$ , one could suspect that every set has a scheme structure which is étale over $X$ . Namely, $\coprod Spec \ k$ , where the coproduct is taken over the cardinality of the set. If so, the class of étale schemes over $X$ would be a proper class. Is this true? Thank you in advance. P.S.: My question is motivated by the following: if $X_{ét}$ is a proper class, I'm afraid $Sets^{X_{ét}^{op}}$ shouldn't be a category. But the theory of étale cohomology and of the étale topos is based on the fact that its ""subcategory"" of sheaves on the étale site $Sh(X_{ét})$ is indeed a category (which we call the étale topos). So, either $Sh(X_{ét})$ while $Sets^{X_{ét}^{op}}$ is not, which would be strange to me, or we have a problem.","['set-theory', 'algebraic-geometry', 'schemes', 'category-theory']"
2982260,The product of two zero-row-sum matrices,"Suppose $A\in Mat_{m\times n}(\mathbb{R}), B\in Mat_{n\times r}(\mathbb{R}).$ and their row sums are $0$ , i.e. $\displaystyle\sum_jA_{ij}=\sum_j B_{ij}=0.$ Suppose $AB=C$ . Show that the row sum of $C$ is still $0$ . My attempt: Suppose $A\in Mat_{m\times n}(\mathbb{R})$ is an arbitrary matrix and $B\in Mat_{n\times r}(\mathbb{R})$ is the matrix that the row sum of $B$ is $0$ . The $ith$ row sum is $$\begin{align}\displaystyle\sum_{j=1}^r (AB)_{ij} &=\sum_{j=1}^r\sum_{k=1}^n a_{ik}b_{kj} \\&=\sum_{k=1}^n \sum_{j=1}^r a_{ik}b_{kj} \\&=\sum_k^na_{ik}(\sum_j^r b_{kj}) \\& =\sum_k^n a_{ik}*0,~~~~\text{since the row sum of $B$ is $0$}.\end{align}$$ So, the row sum of product $AB$ is $0$ . So, if the row sums of both two matrices are $0$ , then the row sum of their product $C$ is also $0$ (because we can always have a zero-row-sum matrix on the right). Is my proof correct? Can someone check it for me? Thank you very much.","['matrices', 'linear-algebra']"
2982341,Why is it sometimes possible to solve multi variable single equation?,"Assume you have an equation: $\ 5x^2+4x+6=ax^2+bx+c $ Now theoretically, this is an equation of 4 variables, and it should not be solvable, but it is very apparent that a,b,c equals 5,4,6, in that order. Something similar happens with complex numbers: $\ 5 + 4i = a + bi $ Here solution for a,b is 5,4, again it is very apparent. My theory is that a,b or c, in these are something like incompatible number types . Therefore you can construct a system of equations from one single equation. The complex number equation is a good example, you can easily separate the complex and the non-complex part, as they virtually cannot influence the other. But in the first equation, it's all in the real plane, there is no complex stuff going on and the x squared can influence the x You can even do this: $\ c = 5x^2 + 4x + 6 - ax^2 - bx $ Which would suggest c is dependent on the value of both a and b, and you get a similar result defining a or b, potentially pointing to an infinite number of solutions. So why do these have only one solution? Assuming my theory is somewhat correct, what do mathematicians call these ""incompatible numbers"" properly?","['algebra-precalculus', 'systems-of-equations']"
2982344,Is there a process that is not square-integrable but still gives rise to a martingale when integrated w.r.t. Brownian motion?,"When an adapted process $X$ satisfies $\int_0^TX_t^2dt<\infty$ a.s. but not $E\int_0^TX_t^2dt<\infty$ , the stochastic integral $\int_0^tX_sdB_s$ , $0\le t\le T$ , is only guaranteed to be a local martingale (where $B$ is the underlying Brownian motion). Is it still possible, nonetheless, that $\int_0^tX_sdB_s$ is a martingale?","['local-martingales', 'martingales', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
2982356,Asymptotic behavior of solution to nonlinear ODE,"I am trying to determine the asymptotic behavior as $t \to \infty$ of the solution to the IVP: $$y''(t) - y(t) + \frac{1}{[y(t)]^3} = 0\\y(0) = 1;\, y'(0) = 1$$ Without the nonlinearity, we have solutions of the form $e^{\pm t}$ .  I think the nonlinear solution has similar behavior, but I'm not sure how to show this or determine the precise asymptotic form.",['ordinary-differential-equations']
2982366,Intuition Behind Whitney Covering Lemma,"I know Whitney Covering Lemma. But I do not know how it can be applied to PDE. More specifically, I do not know what is the intuition behind Whitney Covering Lemma. First, let me state the lemma: Let $\Omega$ be an open non-empty proper subset of $\mathbb{R}^n.$ Then there exists a family of closed cubes $\{Q_j\}_j$ such that $(1)$ the union of the cube is the whole space, and the cubes have
  disjoint interiors. $(2)$ $\sqrt{n}l(Q_j) \leq\operatorname{dist}(Q_j,\Omega) \leq 4 \sqrt{n} l (Q_j).$ $(3)$ If the boundaries of two cubes $Q_j$ and $Q_k$ touch then $\frac{1}{4} \leq \frac{l(Q_j)}{l(Q_k)} \leq 4$ . $(4)$ For a given $Q_j,$ there exist at most $12^n Q_k$ 's that touch it Here, we define $l(Q)$ as the length of a cube. My question is why the decomposition pick the constant like $4$ . I want to know whether it will work if $4$ change to $3$ or other numbers. Why there are $12^n$ not let us say $2^n$ ? Another question will be what the intuition of the lemma. Why we will use it in PDE?","['general-topology', 'real-analysis']"
2982372,Open connected subsets of path connected spaces,"Does every open and connected subset of path connected topological space has to be path connected? Statement should be false as there is a similar theorem but for Euclidean spaces, however I can't think of a counterexample. What about the same statement, but for path connected metric spaces?","['connectedness', 'path-connected', 'metric-spaces', 'examples-counterexamples', 'general-topology']"
2982397,The Number of involutory matrices over $\mathbb{Z_p} $,"I want to prove the number of 2-by-2 Involutory Matrices ( $A^2=I$ ) over $\mathbb{Z_p}$ using quadratic residue and legendre symbol. I already know that the formula is $p^2$ for characteristic of a field is 2 and $p^2+p+2$ for $p$ being an odd prime as stated here: Involutory matrix $2 \times 2$ I have also shown that the number of Involutory Matrices is twice the number of solutions ( $a,b$ ) to the congruence : $a^2+bc \equiv 1$ (mod $p$ ) Is there any way to come up with the formula using quadratic residue and legendre symbol? Thanks in advance.","['number-theory', 'quadratic-residues', 'linear-algebra', 'legendre-symbol']"
2982415,Definition of subgroup generated by a set,"Yes, I've checked the other similarly titled questions (they seem more on par with abstract algebra for a grad level course).  From the Gilbert and Gilbert text we have the following definition $$\langle A\rangle =\{x\in G| x=a_1+a_2+\cdots +a_n, \quad a_i\in A\quad or \quad -a_i\in A\}$$ for an arbitrary $A$ which is a subset of the group $G$ .  I don't like this definition because it doesn't seem natural; specifically the $n$ is fixed (and comes from apparently nowhere).  An exercise I'm currently working on is to show that if $H_1,H_2,\ldots H_n$ are subgroups of an abelian group $G$ , then $G=H_1+H_2+\cdots + H_n$ if and only if $G$ is generated by $\bigcup_{j=1}^n H_j$ . I don't want help with this second problem; however, I'm sharing it in hopes that it will clarify why I'm confused.  From the definition of $\langle A \rangle $ it seems that $n$ is arbitrary, that is to say it doesn't ""know"" that $H$ is the sum of $n$ distinct subgroups.  But if that's the case then when trying to the prove the second problem I don't know how to get started because I write something like the following: If $g\in G$ (and $G$ is generated by the union) then $g=a_1+\cdots + a_k$ for some $k\in \mathbb{N}$ and each $a_i\in \bigcup_{j=1}^n H_j$ .  I suppose I'm doing this correctly, I just don't trust this definition -- how does $\langle A \rangle $ know to ""go up to"" $n$ ?","['group-theory', 'abstract-algebra']"
2982422,$\int_{1}^{\infty}\frac{x^2-1}{(x^2+1)\sqrt{x^4+1}}dx=$?,Consider the convergent integral (I looked up difficult indefinite integrals on google images and then I saw this integrand and I was like hey let's see if it converges) $$I=\int_{1}^{\infty}\frac{x^2-1}{(x^2+1)\sqrt{x^4+1}}dx$$ We have the numerical approximation $$I\approx0.5553603672697931...$$ Which Wolfram alpha says is close to $\frac\pi{4\sqrt{2}}$ . All my attempts at this integral have been fruitless and I need some help. Here's the only attempt of mine that actually made the integrand smaller: $x=\tan u$ : $$I=\int_{\pi/4}^{\pi/2}\frac{\tan^2u-1}{\sqrt{\tan^4u+1}}du$$ Next step: bang head on floor in agony Any suggestions?,"['integration', 'improper-integrals']"
2982436,Spider Problem Counting Socks and Shoes,"Problem A spider has one sock and one shoe for each of its eight legs. In how many different orders can the spider put on its socks and shoes, assuming that, on each leg, the sock must be put on before the shoe? A) 8! (B) $2^8$ (C) $(8!)^2$ (D) $\frac{16!}{2^8}$ (E) 16! I am having trouble visualizing how the answer was gotten from this solution. Solution 2 Each dressing sequence can be uniquely described by a sequence containing two $1$ s, two $2$ s, ..., and two $8$ s -- the first occurrence of number $x$ means that the spider puts the sock onto leg $x$ , the second occurrence of $x$ means he puts the shoe onto leg $x$ . If the numbers were all unique, the answer would be $16!$ . However, since 8 terms appear twice, the answer is $\frac{16!}{(2!)^8} = \boxed{\frac {16!}{2^8}}$","['combinatorics', 'discrete-mathematics']"
2982459,Homomorphic image of modular lattice is modular?,"Let $L$ be modular lattice, $M$ be lattice and $f:L\to M$ be a homomorphism. I want to show $f(L)$ is a modular lattice.. We already know that homomorphic image of a lattice is a lattice. 
So we only want to show that if $f(a)\leq f(b)$ then $f(a) \vee (f(x)\wedge f(b))= (f(a)\vee f(x))\wedge f(b) $ for $a,b,x \in L$ Since L is modular $a\leq b$ implies $a \vee(x\wedge b)= (a\vee x)\wedge b$ My problem is: I must begin with the assumption $f(a)\leq f(b)$ then show $f(a) \vee (f(x)\wedge f(b))= (f(a)\vee f(x))\wedge f(b) $ for which I need to use $a \vee(x\wedge b)= (a\vee x)\wedge b$ But $f(a)\leq f(b)$ need not necessarily imply $a\leq b$ since it is only homomorphism and not isomorphism.",['discrete-mathematics']
2982535,Joint CDF and Integrals,"I am trying to find the joint CDF $F(x,y)$ for the following function. The following model answer was given. My query is why we need to consider the first case $0<x<y$ when $f_{X,Y}$ is only defined above $0<y<x$ ? Furthermore I do not understand what the variables $u$ and $v$ refer to in the integration. Do they refer to some new axis $u,v$ ? Do small $x$ and small $y$ represent any $x, y$ value, or do they refer to a point on the line $Y=X$ ?","['probability-distributions', 'probability-theory', 'probability']"
2982549,Proof by induction of summation inequality: $1 + 1/2+ 1/3+ 1/4+1/5+⋯+ 1/2^n \leq n + 1$,"I have been working on this problem for literally hours, and I can't come up with anything. Please help. I feel like I am about to go insane. For all n $\in$ N, we have $$1 + \frac{1}{2}+  \frac{1}{3}+  \frac{1}{4}+\frac{1}{5} +⋯+  \frac{1}{2^n}   ≤ n + 1$$ I know that I am supposed to use a proof by induction. Here is progress so far: 1) Let P(n) be $$\sum_{i=0}^{2^n} \frac{1}{i} $$ 2) Base case: $n = 1$ $$\sum_{i=1}^{2^n} \frac{1}{i} = \frac{1}{1}+ \frac{1}{2} =  \frac{3}{2}, \frac{3}{2} ≤ 2 $$ So P(1) is true. 3) Inductive hypothesis:
Suppose that P(k) is true for an arbitrary integer k $\geq$ 1 4) Inductive step:
We want to prove that P(k + 1) is true or, $$\sum_{i=1}^{2^{k+1}} \frac{1}{i} ≤ k + 2$$ By inductive hypothesis, $$\sum_{i=1}^{2^{k+1}} \frac{1}{i} = \sum_{i=1}^{2^k} \frac{1}{i} + \sum_{i=2^k+1}^{2^{k+1}}\frac{1}{i} ≤ k + 1 + \sum_{i=2^k+1}^{2^{k+1}}\frac{1}{i}$$ I know that I'm supposed to split the expression into two summations, but now I am completely stuck and don't know what to do from here. I got one hint that the fact $\frac{a}{b + c} < \frac{a}{b}$ is relevant, but I don't know how to get there from here.","['proof-writing', 'proof-verification', 'induction', 'discrete-mathematics']"
2982636,Does a norm ball around a real matrix contain all possible pairs of complex spectrum?,"We consider the normed vector space $(M_n(\mathbb R), \|\cdot\|_F)$ , i.e., real matrices with Frobenius norm. Let $A \in M_n(\mathbb R)$ be a diagonalizable matrix and have all eigenvalues to be real. Let $B_A(\varepsilon)$ denote the open norm ball with radius $\varepsilon > 0$ , i.e., \begin{align*}
B_A(\varepsilon) =\{ E \in M_n(\mathbb R): \|A-E\|_F < \varepsilon\}.
\end{align*} We know the complex eigenvalues of a real matrix must be conjugate pairs. My question is: for any combination of real or complex conjugate pairs of eigenvalues, is there always a matrix $E \in B_A(\varepsilon)$ has the spectrum with the same number of real and complex conjugate pairs. To be more clear, let $n = 2k$ be even, I would like to know whether there are always matrices in the norm ball such that have eigenvalues with $1$ complex conjugate pair, $2$ pairs, and so on until $k$ pairs of conjugate eigenvalues.","['perturbation-theory', 'linear-algebra', 'eigenvalues-eigenvectors']"
2982669,Are distributions all continuous?,"By a distribution, I mean it is a linear functional of the space of smooth compactly supported functions over $\mathbb R^n$ , i.e. $C_c^{\infty}(\mathbb R^n).$ I am reading a textbook by Strichartz, named A Guild to Distribution Theory and Fourier Transforms. He wrote that linear functionals all tend to be continuous . As we know, there are plenty of linear functionals which are not continuous. So what he referred to may be distributions. i.e. Distributions all tend to be continuous. He gave a rough explanation which I think is not a proof. His explanation: Let $\varphi$ and $\varphi_1$ be in $C_c^{\infty}(\mathbb R^n),$ and $f$ be a distribution. And let $\varphi_2:=\varphi_1-\varphi$ Then $\varphi_1=\varphi+\varphi_2$ Move $\varphi_1$ closer to $\varphi$ by considering $\varphi+t\,\varphi_2$ and let $t$ get small. Then $\langle f,\varphi+t\,\varphi_2\rangle=\langle f,\varphi\rangle+t\,\langle f,\varphi_2\rangle$ by linearity, and as $t$ gets small this gets close to $\langle f,\varphi\rangle.$ End of explanation. I think, to prove the continuity of $f$ , we need to show $\langle f,\varphi_1\rangle\to\langle f,\varphi\rangle$ when $\varphi_1 \to \varphi.$ While in the explanation, what he proved is that $\langle f,\varphi+t\,\varphi_2\rangle\to\langle f,\varphi\rangle$ when $t\to 0.$ He also wrote that this does not constitute a proof of continuity, since the definition requires more ""uniformly"", but it should indicate that a certain amount of continuity is built into linearity. And, all distribution you will ever encounter will be continuous. So my problem is, are distributions all continuous? Thanks in advance.","['continuity', 'functional-analysis', 'distribution-theory']"
2982713,If $y=\frac25+\frac{1\cdot3}{2!}\left(\frac25\right)^2 +\frac{1\cdot3\cdot5}{3!}\left(\frac25\right)^3+\ldots$ then what is the value of $y^2+2y$?,"If $$y=\frac25+\frac{1\cdot3}{2!}\left(\frac25\right)^2 +\frac{1\cdot3\cdot5}{3!}\left(\frac25\right)^3+\ldots$$ then what is the value of $y^2+2y$ ? This is a question from my coaching material in which binomial theorem, multinomial theorem and binomial theorem with fractional and negative indices are covered. How do I approach this problem? What is the pattern in it?","['summation', 'binomial-theorem', 'sequences-and-series']"
2982754,Bruhat-Tits Building of $PGL_3$: What does it look like?,"I am very new to this topic, and my background is mostly in graph theory and basic algebra. What I want for now is to understand the structure of the dimension $2$ complex $\mathcal{B}(PGL_3(K))$ where $K$ is a $p$ -adic field. In this case, we have vertices, edges and triangles, just one step above graphs and so easier to approach in elementary terms, I hope. So what does this building look like? I heard somewhere that the link of every vertex is a bipartite graph which is the Levy graph of the incidence structure of the projective plane over $\mathbb{Z}/p\mathbb{Z}$ . But I am unable to find any accessible references on this. All references I find start from and go deep into representation theory, while all I am seeking, at present, is an explicit combinatorial description of the building of $PGL_3$ as a hypergraph: what are the vertices, which vertices are connected by edges, what are the triangles, and what is the structure of the star or link of a vertex.
I am not looking for the most general definitions or abstractions. Is there a simple combinatorial description here, like in the case of graphs? While I will approach it using representation theory in time, it could help to have some feel for this structure just as a hypergraph at present. I want to play around with the combinatorial structure for now. Any explanations, or even accessible references, would help greatly. Thanks!","['hypergraphs', 'cw-complexes', 'algebraic-graph-theory', 'bruhat-tits-theory', 'group-theory']"
2982798,On integer solutions of $2\sqrt{\sqrt{2x}+\sqrt{y}}=\sqrt{x}+\sqrt{2y}$,"$\textsf{Background}$ From the double-angle formula $\cos2\alpha=2\cos^2\alpha-1$ , we can get $$\cos15^\circ=\sqrt{\frac{1+\cos30^\circ}2}=\frac{\sqrt{2+\sqrt3}}2$$ but we also know that it is equivalent to $\dfrac{\sqrt6+\sqrt2}4$ . This is an example of an equality such that $$2\sqrt{\sqrt{2x}+\sqrt{y}}=\sqrt{x}+\sqrt{2y}$$ after some rearranging. We can write $y$ in terms of $x$ without much bother: $$y=2+\frac x2+2\sqrt{1+\sqrt{2x}}-\sqrt{2x(1+\sqrt{2x})}.$$ But when are $x$ and $y$ integers? Here is a plot of the curve: Some obvious solutions are $(0,0)$ , $(0,4)$ , $(2,3)$ and $(32,0)$ . Of course, $x=2k$ for some integer $k$ , leaving us with $$y=2+k+2\sqrt{1+2\sqrt k}-2\sqrt{k(1+2\sqrt k)}$$ Hence this boils down to finding $k$ such that $$(1-\sqrt k)\sqrt{1+2\sqrt k}$$ is an integer. Any advances on this?","['elementary-number-theory', 'functions', 'real-analysis']"
2982842,Prove convergence of sequence given by $a_{1}=1$ and $a_{n+1}= \frac{1}{a_1+a_2+\ldots+a_n}$,"For sequence given by $a_{1}=1$ and $a_{n+1}= \frac{1}{a_1+a_2+\ldots+a_n}$ I have to prove that it converges to some number and find this number. I tried toshow that it's monotonic by calculating $$
\frac{a_{n+1}}{a_{n}} = \frac{1}{a_{n}(a_1+a_2+\ldots+a_n)}
$$ but I cannot say anything about the denominator. How can I try to find it's limit?","['limits', 'convergence-divergence', 'sequences-and-series']"
2982860,Why are $C^\infty_p\neq C^\infty_q$ when $p\neq q$?,"Let $C^\infty_p(M)$ be the set of all germs at point $p \in M$ . A germ at point $x$ is $$[f]_x = \{ g \in C^{\infty} (\mathcal{U}_x) :(\exists \mathcal{O_x} \subset \mathcal{U}_x) (g|_{\mathcal{O_x}}=f) \} \ ,$$ where $\mathcal{U}_x$ and $\mathcal{O_x}$ are open neighbourhoods of $x$ , in $M$ . Why do we always have $C^\infty_p\neq C^\infty_q$ when $p\neq q$ ? I need to understand this in order to understand how the tangent spaces 'as the' set of derivations are always disjoint for different points.","['differential-topology', 'differential-geometry']"
2982874,Differentiability of matrix square root operator,"I'm interested to know if the map: $$S:\mathcal{L}(\mathbb{R}^n)\rightarrow\mathcal{L}(\mathbb{R}^n)$$ $$S(T)=\sqrt{T^*T}$$ Is differentiable. I'm aware $T\mapsto T^* T$ is differentiable, and I know that since $T^*T$ is positive self-adjoint, the square root exists, but not sure where to go from here... My ideia was that, matrix-wise, choosing the correct basis, $T^*T$ is diagonal, then the map would be equivalent to taking the square root component-wise, which should be differentiable, though I don't know if that's a valid way to justify it...","['matrices', 'linear-transformations', 'real-analysis']"
2982878,Expected time before Farmer Brown is abducted?,"Farmer Brown is standing in the middle of his perfectly circular field feeling
very content. It is midnight and there is no moon and unknown to the farmer,
Martian zoologists are landing randomly at points on the circumference of his
field. They land at one minute intervals, starting at midnight. As soon as
there are martians at points A,B,C such that triangle ABC contains the center
of the field, Farmer Brown will be teleported to the waiting space-ship and
transported off to spend the rest of his life as an exhibit in a Martian zoo.
What is the expected time until he is abducted? My approach: If lets say the farmer gets abducted after k Martians land. This implies that the first k-1 martians all lie in the same semicircle. Also, the kth martian lies on the circle such that the far away martians in the initial k-1 martians, and the kth martian form a triangle that contains the center of the circle. The probability that the first (k-1) martians don't contain the center of the circle is (see here ). Also, the probability that the kth martian makes the center lie in a triangle formed by the kth martian and the ends of initial k-1 martians should be 1/4, since this is equivalent to the situation of only 3 martians. So the expected value of k, i.e. no. of martians after which the farmer gets abducted, should be The answer I get from this, is 3.5. Whereas the actual answer is 5. In the solution in that link, I don't understand where does the right hand side of the  probability equation come from. Where is my approach wrong?",['probability']
2982897,How to show the existence of the limit $\lim_{n\to \infty}\frac{x_n}{n}$ if $x_n$ satisfy $x^{-n}=\sum_{k=1}^\infty (x+k)^{-n}$?,"Suppose $x_n$ is the only positive solution to the equation $x^{-n}=\sum\limits_{k=1}^\infty (x+k)^{-n}$ ,how to show the existence of the limit $\lim_{n\to \infty}\frac{x_n}{n}$ ? It is easy to see that $\{x_n\}$ is increasing.In fact,  the given euation equals $$1=\sum_{k=1}^\infty(1+\frac{k}{x})^{-n} \tag{*}$$ If $x_n\ge x_{n+1}$ ,then notice that for any fixed $ k$ , $(1+\frac{k}{x})^{-n}$ is increasing,thus we can get $$\frac{1}{(1+\frac{k}{x_n})^n}\ge \frac{1}{(1+\frac{k}{x_{n+1}})^n}>\frac{1}{(1+\frac{k}{x_{n+1}})^{n+1}}$$ By summing  up all k's from 1 to $\infty$ ,we can see $$\sum_{k=1}^\infty\frac{1}{(1+\frac{k}{x_n})^n}>\sum_{k=1}^\infty\frac{1}{(1+\frac{k}{x_{n+1}})^{n+1}}$$ then from $(*)$ we see that the two series in the above equality are all equals to $1$ ,witch is a contradiction! But it seems hard for us to show the existence of $\lim_{n\to \infty}\frac{x_n}{n}$ .What I can see  by the area's principle is $$\Big|\sum_{k=1}^\infty\frac{1}{(1+\frac{k}{x_n})^n}-\int_1^\infty \frac{1}{(1+\frac{x}{x_n})}dx\Big|<\frac{1}{(1+\frac1{x_n})^n}$$ or $$\Big|1-\frac{x_n}{n-1}(1+\frac{1}{x_n})^{1-n}\Big|<\frac{1}{(1+\frac1{x_n})^n}$$","['limits', 'sequences-and-series']"
2982920,"WolframAlpha and I don't agree on $( xy\sin y )/(3x^2+y^2)$ as $(x,y)\to(0,0)$","WolframAlpha claims that the following limit does not exist: $$ \lim_{(x,y)\to(0,0)} \frac{xy\sin{y}}{3x^2+y^2} $$ https://www.wolframalpha.com/input/?i=lim+(xysiny)%2F(3x%5E2%2By%5E2)+as+%7Bx-%3E0,+y-%3E0%7D However, I just proved that its limit is zero. Here is how: $2|(\sqrt{3} x)(y)| \leq 3x^2 + y^2 $ by AM-GM. Therefore, $ |xy \sin{y}| \leq \frac{1}{2\sqrt3}(3x^2+y^2)|\sin{y}|$ And so, $ 0 \leq |\frac{xy\sin{y}}{3x^2+y^2}| \leq \frac{1}{2\sqrt{3}}|\sin{y}|$ The one on the left and the right both go to zero as $(x,y)\to(0,0)$ ; therefore our expression in the middle must also converge to zero. Finally, because $|\frac{xy\sin{y}}{3x^2+y^2}|$ converges to zero, $\frac{xy\sin{y}}{3x^2+y^2}$ converges to zero as well. I am absolutely sure my proof is logical and correct, especially because WolframAlpha says '0' to this: https://www.wolframalpha.com/input/?i=lim+(xy%5E2)%2F(3x%5E2%2By%5E2)+as+%7Bx-%3E0,+y-%3E0%7D . However, my textbook also claims it to be nonexistent. What is the limit? If it really is zero, then why does WolframAlpha claim it to be nonexistent? If it isn't zero, where did I go wrong?","['limits', 'multivariable-calculus', 'wolfram-alpha']"
2982934,"Show that $Tf(x) = g(x)f(x), \; \forall x\in [a,b]$ is a bounded linear operator $T \in B(X)$ .","Exercise : Let $X=C[a,b]$ be equipped with the norm $\| \cdot \|_\infty$ and $g \in X$ . We define the operator $T:X \to X$ to be : $$Tf(x) = g(x)f(x), \; \forall x\in [a,b]$$ Show that $T$ is a Bounded Linear Operator $(T \in B(X))$ . Attempt : Let $y(x),z(x) \in C[a,b]$ . Then, it is : $$T(y(x)+z(x)) = g(x)(y(x)+z(x)) = g(x)y(x)+g(x)z(x)$$ $$\implies$$ $$T(y(x)+z(x)) = Ty(x) + Tz(x), \; \forall y(x),z(x) \in C[a,b] $$ Let $\lambda \in \mathbb R$ and $f(x) \in C[a,b]$ . Then : $$T(\lambda f(x)) = g(x)[\lambda f(x)] = \lambda g(x)f(x)$$ $$\implies$$ $$T(\lambda f(x)) = \lambda f(x), \; \forall \lambda \in \mathbb R, \; \forall f(x) \in C[a,b]$$ Thus, $T$ is indeed linear. Also, if $f(x),g(x) \in C[a,b]$ then it also is $g(x)f(x) \in C[a,b]$ and thus $T:X \to X$ . For the boundedness, I need to prove that : $$\exists M>0 : \|Tf(x)\| \leq M \|f(x)\|$$ It is : $$Tf(x) = g(x)f(x) \Rightarrow \|Tf(x)\|_\infty = \|g(x)f(x)\|_\infty \leq \|g(x)\|_\infty \|f(x)\|_\infty $$ $$\Rightarrow$$ $$\|Tf(x)\|_\infty \leq \sup\{|g(x)| : x \in X\} \|f(x)\|_\infty $$ $$\|Tf(x)\|_\infty \leq G \|f(x)\|_\infty$$ since $g \in C[a,b]$ and thus $\exists G>0 : |g(x)| \leq G \; \forall x \in C[a,b] \implies G = \sup\{|g(x)| : x \in X\}$ . Question : Is my proof correct and rigorous enough ?","['operator-theory', 'proof-verification', 'functional-analysis', 'real-analysis']"
2982962,Does a sheaf of abelian groups on a scheme $X$ induce a sheaf of abelian groups on the étale site $X_{ét}$?,"Fixed a scheme $X$ , étale cohomology $H^\bullet(X,F)$ is defined for all sheaves of abelian groups $F$ over the étale site $X_{ét}$ . Now, just to understand, I tried to see if this covers sheaves of abelian groups over $X$ itself as well (i.e., sheaves over the Zariski site). So, does a sheaf of abelian groups on a scheme $X$ induce a sheaf of abelian groups on the étale site $X_{ét}$ , for which the étale cohomology groups are defined? My guess is that, given a sheaf of abelian groups $F$ over $X$ , the functor $$\tilde F:X_{ét}\to \mathbf{AbGrp}$$ defined by $\tilde F(g:Y\to X)=(g^*F)(X)$ is a sheaf of abelian groups over $X_{ét}$ . Is this true? Is this the natural way how sheaves over $X$ become handleable by étale cohomology, if there is any? Thank you in advance.","['etale-cohomology', 'topos-theory', 'algebraic-geometry', 'schemes']"
2982978,"Prove that the right shift operator $S(x_1,x_2, \dots) = (0,x_1,x_2,\dots)$ is bounded.","Exercise : Let $S: l^1 \to l^1$ be the right-shift operator : $$S(x_1,x_2,\dots) = (0,x_1,x_2,\dots)$$ Prove that $S$ is bounded and find its norm. Attempt : The space $l^1$ is : $$l^1 = \{(x=(x_n) : \sum_{i=1}^\infty x_n < + \infty\}$$ To show that the operator $S$ is bounded, I must show that : $$\exists \; M>0 : \|Sx\|\leq M\|x\|$$ But I can't really see how to proceed on this particular proof without having any knowledge of the norm that should be used. Shall the norm of $l^1$ space be used ? If so, what does  ""find the norm of the operator S"" ? I would really appreciate any tips/solutions or clarifications regarding this particular exercise. Note : I have NOT been introduced to isometries in my Functional Analysis class yet, so I am looking for an elementary bounded operator approach.","['operator-theory', 'functional-analysis', 'real-analysis']"
2983005,"Is $\{ (e^{2\pi i a n},e^{2\pi i b n }) : n \in \mathbb{Z} \}$ dense in the torus, where $a,b$ irrationals such that $a/b$ irrational?","I know that the set of points of the form $(e^{2\pi i t},e^{2\pi i a t })$ where $t \in \mathbb{R}$ is dense in the torus $S^1 \times S^1$ when $a \in \mathbb{R}$ is irrational. (This problem is asked here .) I also know that the set of points of the form $e^{2\pi i a n}$ where $n \in \mathbb{Z}$ is dense in $S^1$ , when $a$ is irrational. (This problem is asked here .) I believe it is true that the set of points of the form $$
(e^{2\pi i an},e^{2\pi i b n })
$$ is also dense in the torus, where $n \in \mathbb{Z}$ and $a,b$ are irrationals such that $a/b$ is also irrational. But I am unable to show this, and would appreciate any hint on how to proceed. I tried viewing the torus as the unit square $[0,1] \times [0,1]$ with edges identified appropriately. So, I need to show that the set of points $$(an \pmod 1, bn \pmod 1)$$ is dense in the unit square. In showing that the line $(e^{2\pi i t},e^{2\pi i a t })$ is dense in the torus, it suffices to show that it intersects every ball with centre on the vertical edge $\{ 0 \} \times [0,1]$ . However, to apply the same idea here, I need to find an integer $n$ such that $an \pmod 1$ and $bn \pmod 1$ are both arbitrarily close to $0$ . I can find integers $n_1$ and $n_2$ such that $an_1 \pmod 1$ and $bn_2 \pmod 1$ are both arbitrarily close to $0$ , by the same argument used to show that $e^{2 \pi i a n}$ is dense in $S^1$ . But I'm unable to arrive at a single integer that does the job for $a$ and $b$ simultaneously. I'm possibly missing only some small idea. Can anyone help me?","['general-topology', 'metric-spaces']"
2983016,Is weak derivative a bounded operator from $H^k(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$?,"I'm struggling to become comfortable with the concept of the weak derivative and Sobolev space. In my textbook, it is proved that the Sobolev space $H^k(\mathbb{R}^n)$ is a Hilbert space, and it is also proved that the weak derivative $D$ is a closed operator from $H^k(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$ . Does this mean that $D$ is a bounded operator? I guess so because a closed operator defined everywhere in a Hilbert space is bounded. Is that also mean $D$ is bounded as an operator from $L^2(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$ with domain $H^k(\mathbb{R}^n)$ ?","['sobolev-spaces', 'functional-analysis', 'weak-derivatives']"
2983024,"I have heard that $SO(3)$ is ""isomorphic"" to a sphere. Is this true? if so, how do we prove it?","i am not claiming that $SO(3)$ and a sphere are isomorphic. instead, i am asking if they are, and if so, for an intuitive proof.",['group-theory']
2983033,How to prove the following identity regarding Laplace transforms?,I tried solving it by integrating by parts but i was unsuccessful. $${\cal L}\left[\int_0^xf(x-t)g(t)\ dt\right]=F(p)G(p)$$,"['laplace-transform', 'ordinary-differential-equations']"
2983050,Every linear operator $T:X \to Y$ on a finite-dimensional normed space is bounded,"Exercise : Show that if $X$ is a finite-dimensional normed space and $Y$ is a normed space, then every linear operator $T:X \to Y$ is bounded. Attempt : Since $X$ is finite-dimensional, say $\dim(X)=n$ , there exists a basis $\{e1,e2,...,en\}$ of $X$ such that every element $x\in X$ can be written uniquely in the form: $$\begin{align} \quad x = a_1e_1 + a_2e_2 + ... + a_ne_n \end{align}$$ where $a_1,a_2,\dots,a_n \in \mathbb R$ . Now, $\forall \; x \in X$ , it is : $$\begin{align} \quad \| T(x) \|_Y &= \| T (a_1e_1 + a_2e_2 + ... + a_ne_n) \|_Y \\ &= \| a_1 T(e_1) + a_2 T(e_2) + ... + a_n T(e_n) \|_Y \\ & \leq \sum_{k=1}^{n} |a_k| \| T(e_k) \|_Y \end{align}$$ Using the Cauchy-Schwarz inequality, we yield : $$\begin{align} \quad \| T(x) \| & \leq \left ( \sum_{k=1}^{n} |a_k|^2 \right )^{1/2} \left ( \sum_{k=1}^{n} \| T(e_k) \|_Y^2 \right )^{1/2} \\ & \leq \left ( \sum_{k=1}^{n} |a_k|^2 \right )^{1/2} \cdot M \end{align}$$ But regarding equivalence of norm in correlation to finite-dimensional spaces, we have that : $$\begin{align} \quad \| T(x) \|_Y & \leq M \| x \|_* \end{align}$$ Then, $\exists c_1,c_2 \in \mathbb R^+ : \forall x \in X$ it is : $$\begin{align} \quad c_1 \| x \|_X \leq \| x \|_* \leq c_2 \| x \|_X \end{align}$$ Thus $\forall x \in X$ it is : $$\begin{align} \quad \| T(x) \| & \leq c_1M \| x \|_X \end{align}$$ which tells us that $T$ is bounded. Question : It seemed like a rather hard exercise to me so I am not sure if my proof/approach is definitely correct or rigorous enough. Any insight will be very helpful !","['operator-theory', 'proof-verification', 'functional-analysis', 'real-analysis']"
2983072,"How many distinct functions $f : \{1, 2, 3, 4, 5 \} \to \{1, 2, 3 \}$ are there?","How many distinct functions $f : \{1, 2, 3, 4, 5 \} \to \{1, 2, 3 \}$ are there, from the set $\{1, 2, 3, 4, 5\}$ to the set $\{1, 2, 3\}$ , whose range is a set of size exactly $2$ ? I got $3^5$ total number of functions but don't know how to go further?","['permutations', 'functions', 'combinatorics']"
2983075,Evaluating $\lim_{x \to \infty}\frac{1}{x}\int_0^x|\sin(t)|dt$,I would appreciate some help with this problem: Evaluate: $$\lim_{x \to \infty}\frac{1}{x}\displaystyle\int_0^x|\sin(t)|dt$$,"['limits', 'trigonometry', 'definite-integrals']"
2983094,How to integrate $\int_0^{\infty}\left(\frac{\sin(x)}{x}\right)^m dx$? [duplicate],"This question already has answers here : A sine integral $\int_0^{\infty} \left(\frac{\sin x }{x }\right)^n\,\mathrm{d}x$ (6 answers) Closed 5 years ago . How to evaluate $L(m):=\int_0^{\infty}\left(\frac{\sin(x)}{x}\right)^m dx$ ? 
I am familiar with the case $m=1$ , but what about the general one?","['integration', 'complex-analysis', 'real-analysis']"
2983116,Limit of an operator and eigenvalues,"can you help me how to solve this exercice? Define in $L^2(-1,1)$ $$ T_k[f](x):= \int_{-1}^1 \frac{(-1)^k}{(2k+1)!}(xy)^{2k+1} f(y)\,\,dy $$ i) show that $||T_k||\to 0$ ; ii) find eigenvalues of $T_0$ . I don't know how to solve the first point, while I tried to solve the second point solving a Fredholm equation: $\int_{-1}^1xyf(y)\,dy=\lambda f(x)$ .
So I have $xC=\lambda f(x)$ , where $C=\int_{-1}^1yf(y)\,dy$ , multiply $x$ in $L^2$ and I find $(x,x) C= \lambda C$ . So $\lambda=2/3$ is correct?","['compact-operators', 'eigenvalues-eigenvectors', 'operator-theory', 'hilbert-spaces', 'limits']"
2983151,Prove that $G$ is connected if and only if the matrix $(I_n + A)^{n−1}$ has no $0$'s.,"Let $G$ be a graph on $n$ vertices, $A = AG$ its adjacency matrix, and $I_n$ the $n \times n$ identity matrix.
Prove that $G$ is connected if and only if the matrix $(I_n + A)^{n−1}$ has
no $0$ 's. For the if part- as $G$ is connected there is a path between any two vertices, the maximum size of the path can be $n$ as there are $n$ vertices because of this observation there is always a path from any $u$ to any $v$ of length $n-1$ . Thus $(I_n+A)^{n-1}$ is non zero. (But I am not convinced with the idea). For the only if part I am not getting any convincing idea either. Thank you.","['graph-theory', 'discrete-mathematics']"
2983154,Modified NIM Game with more than one pile,"The game is played at two tables; on the first table, there are N heaps containing A1,A2,…,AN stones and on the second table, there are M heaps containing B1,B2,…,BM stones respectively. Player1 must remove a positive number of stones from one of the piles at her current table and on player2's turn, player2 must remove a positive number of stones from one of the piles at his current table. Whoever cannot remove any stone from a pile loses. If player1 wants then at her chance she can exchange the table . Then how can we predict who will win? I thought if m and n are equal then player2 wins but I think it is wrong.",['discrete-mathematics']
2983158,How is $\cos^2t + \sin^2t = 1$?,"I have to find the parametric functions that represent the curve: $$\left(\frac{x - x_0}a\right)^2 + \left(\frac{y - y_0}b\right)^2 = 1$$ The notes simplify this to $$\frac{(x - x_0)^2}{a^2} + \frac{(y - y_0)^2}{b^2} = 1$$ and then jump to saying that since $\cos^2t + \sin^2t = 1$ , $$\frac{x - x_0}a = \cos t\text{ and }\frac{y - y_0}b = \sin t$$ Where did the $t$ come from? and how is $\cos^2t + \sin^2t = 1$ ? I know how the $\cos$ and $\sin$ functions look, but im not sure how they got this formula and where they got $t$ from.","['trigonometry', 'parametric']"
2983160,Brauer-Severi varieties as quotients of forms of $\text{GL}_2$,"Let $L/F$ be a finite galois extension of fields, with galois group $\Gamma$ . Let $X$ be a variety over $F$ such that $X_L \cong \mathbb{P}^1_L$ over $L$ , corresponding to a cohomology class $\alpha \in H^1(\Gamma,\text{PGL}_{2,L})$ ; $\alpha$ determines an inner $F$ -form $G$ of $\text{GL}_{2}$ by means of the map $$H^1(\Gamma,\text{PGL}_{2,L}) \rightarrow H^1(\Gamma,\text{Aut}(\text{GL}_{2,L})).$$ Can $X$ be regarded as a homogeneous space for $G$ somehow?","['reductive-groups', 'algebraic-geometry', 'algebraic-groups', 'galois-cohomology']"
2983170,Why do we only have one set of solutions for the PDEs of Legendre and Hermite polynomials?,"This is an undergraduate-level mathematical physics problem. It may be trivial and basic to some of you, but it's important to me. In the mathematical physics course, the PDE for Hermite polynomials is $$H^{\prime\prime}(x)-2xH^\prime(x)+2nH(x)=0.$$ The PDE for Legendre polynomials is $$\frac{d}{d x}(1-x^2)\frac{d}{d x}P_l(x)+l(l+1)P_l(x)=0.$$ But I know there's a theorem stating that for $n$ -th order differential equation, we should get two linearly independent solutions, if zero boundary is imposed. Therefore I should expect another class of Hermite (Legendre) polynomials. But here, I don't see there's any boundary condition, both for Hermite and Legendre (both my professor and the textbook didn't mention B.C.). So I want to know if there's some implicit boundary conditions imposed here for these two kinds of partial differential equations. If so, what are they? Or did I misused the theorem mentioned above? Please feel free to answer or to comment. Thank you in advance!","['special-functions', 'ordinary-differential-equations', 'partial-differential-equations']"
2983179,$\sum_i X_i^2$ has $\chi^2_{n}$ distribution and $X_i$ i.i.d. imply $X_i$ normal,"Let $X_1,\ldots,X_n$ be i.i.d. random variables with distribution $F$ . It is known that if $F$ is the standard normal distribution then $$
S:=\sum_{i=1}^n X_i^2
$$ has a chi square distribution with $n$ degrees of freedom. I remeber that the converse is an open problem: if $S$ has a chi square distribution with $n$ degrees of freedom then $F$ has to be the standard normal. Do you have some references on this problem? (I remember that some instances has been solved, but I couldn't find them anymore)","['conjectures', 'statistics', 'probability-distributions', 'reference-request']"
2983197,Can a vector space over finite field be written as union of finite number of proper subspaces?,"Recently, I solved a problem that says- If $V$ is a vector space over an infinite field. Prove that, V cannot be written as set-thoretic union of a finite number of proper subspaces. But is this result true in case of finite field? . I can't get such an example where a vector space over finite field can be written as union of finite number of proper subspaces. Can anybody give such an example? Thanks for assistance in advance.","['finite-fields', 'linear-algebra', 'vector-spaces']"
2983209,Convergence using Laplace transform,"Consider the sequence $(Y_n)_{n\ge 1}$ of iid and integrable random variables, which are not almost surely constant. Let $\delta>0$ and for all $\lambda\in(-\delta,\delta)$ it holds $$L(\lambda):=E[e^{\lambda Y_1}]<\infty$$ Define $$\psi:(-\delta,\delta)\rightarrow\mathbb{R},\quad\psi(\lambda):=\log(L(\lambda))$$ For $n\ge 0$ define $$X_n^\lambda:=e^{\lambda\sum_{i=1}^nY_i-n\psi(\lambda)}$$ I was able to show, that $\psi$ is strictly convex on $(-\delta,\delta)$ by using the inequality of Cauchy-Schwarz and that $e^{\frac{\lambda_1}{2}Y_1}$ and $e^{\frac{\lambda_2}{2}Y_1}$ are linear independent for $\lambda_1\ne\lambda_2$ . snarksi contributed a nice answer how to show that $E[\sqrt{X_n^\lambda}]\rightarrow 0$ for $n\rightarrow \infty$ . At last I want to show that $X_n^\lambda\rightarrow 0$ almost surely for $n\rightarrow \infty$ and $\lambda\ne 0$ . Guess: This looks like I need to use the strong law of large numbers, but I am not sure about this yet. Thanks!","['stochastic-processes', 'probability-theory', 'probability', 'stochastic-calculus']"
2983228,Does some Lucas sequence contain infinitely many primes?,"Does some nontrivial Lucas sequence contain infinitely many primes? The Mersenne numbers $M_n=2^n-1:n$ not necessarily prime are a Lucas sequence with recurrence relation $x_{n+1}=2x_n+1$ . It's an open problem how many Mersenne numbers are prime and we know neither whether $0\%$ or $100\%$ are prime (asymptotically speaking). There are also similar sequences of repunits base $n$ with some nice maths surrounding them. There are Lucas sequences having primes up to some point and then no more primes, such as the sequence with the relation $x_{n+1}=4x_n+1$ given by $1,5,21,85,341,\ldots$ for which it can be shown that there are no more primes beyond $5$ . We can also find sequences having no primes at all such as the sequence with the same relation but starting at $8$ , given by $8,33,133,533,\ldots$ - and in fact it is true for any sequence for which $3x_0+1$ is a square that it has no primes - so we can say there are infinitely many Lucas sequences having no primes. The obvious case to ask is whether infinitely many of the Fibonacci numbers are prime - and this is another open problem. Is it known, or is it possible to show, that there is some (nontrivial) Lucas sequence (identifiable or otherwise), having infinitely many primes, or that there is none?","['fibonacci-numbers', 'number-theory', 'sequences-and-series', 'lucas-numbers', 'prime-numbers']"
2983251,Graph algebra with addition and multiplication,"First of all apologies if this sounds like a stupid question to some. I read a month ago a presentation about how graphs could be endowed with addition and multiplication in some interesting ways and I can't find anything about it by googling, so I am resorting to your knowledge. Basically, and out of my memory so I might be wrong, starting from $G = (E,V), G' = (E',V')$ : addition was simply $G + G' = (E + E', V + V')$ , with obvious meanings for edges and vertices addition (union of sets) multiplication was $G \times G' = (E + E' + V \times V', V + V')$ . Basically, for each vertex $v$ of $V$ , for any vertex $v'$ in $V'$ , you add $(v, v')$ edge to $G + G'$ . also if I remember well there was some distributivity law, maybe a(b+c) = ab + ac + bc Does that ring any bell to anybody? Sorry again for the shallowness of the question. I am looking for the name of that particular algebra so I can google it and find more about it.","['graph-theory', 'abstract-algebra', 'reference-request']"
2983282,Exercise about multiple integration,"Exercise text $\ \ \ $ Calculate $$\ \ \iiint_R y \ dxdydz\ \ $$ where $R$ is the cube portion $\ 0 \le x,y,z\le1 \ $ which is under the plane $\ x+y+z=2\ $ and above the plane $\ y+z=1\ $ . My solution Let $D=\{x+y\le2 \ ,\ y\ge1\}$ we have \begin{equation}
\begin{split}
\iiint_R y\;dxdydz=&\iint_D y\;dxdy\int_{1-y}^{2-x-y}\;dz\\
=&\iint_D\ {y(1-x)}\;dxdy\\
=&\int_0^2(1-x)\;dx\int_1^{2-x}y\;dy\\
=&\frac{1}{2}\int_0^2(1-x)(4+x^2-4x-1)\;dx\\
=&\frac{2}{3}
\end{split}
\end{equation} I'm not sure of the validity of my solution, could someone help me? Thanks in advance!","['integration', 'multivariable-calculus', 'proof-verification']"
2983330,"If $y=\frac{x^2}{x^4+25}$ ,prove: $0 \leq y \leq \frac{1}{10}$",We know that: $$y=\frac{x^2}{x^4+25}$$ Then we have to prove that: $$0 \leq y \leq \frac{1}{10}$$ How to use what we obtain from first fraction to prove what it wanted? Do you have an easy idea?,"['calculus', 'algebra-precalculus']"
2983399,Integral $\int_0^\infty \frac{\arctan(x^2)}{x^4+x^2+1}dx$,"Accidentally while trying to evaluate a similar integral, I think originally found here , I have taken the denominator instead of $x^4+4x^2+1$ as $x^4+x^2+1$ and stumbled into the following integral: $$J=\int_0^\infty \frac{(x^2-1)\arctan(x^2)}{x^4+x^2+1}dx$$ I think this have a closed form because the linked one has a simple closed form: $\displaystyle{\frac{\pi^2}{12\sqrt{2}}}$ , also if there is $\arctan x $ instead of $\arctan(x^2) $ then we have: $$\int_0^\infty \frac{\arctan x}{x^4+x^2+1}dx=\frac{\pi^2}{8\sqrt{3}}-\frac{2}{3}G+\frac{\pi}{12}\ln(2+\sqrt{3})$$ Some proofs are found here: Using $\int_0^{\infty} \frac{\tan^{-1}(x^2)}{x^2+a^2} \ dx$ or using residues .
Anyway I started  by splitting into two integrals and substituting $x=\frac{1}{t}$ : $$\int_0^\infty \frac{x^2\arctan(x^2)}{x^4+x^2+1}dx=\int_0^\infty \frac{\frac{\pi}{2}-\arctan\left(x^2\right)}{x^4+x^2+1}dx\Rightarrow J=\frac{\pi^2}{4\sqrt{3}}-2\int_0^\infty \frac{\arctan(x^2)}{x^4+x^2+1}dx$$ Well, now the main issue is to evaluate: $\displaystyle{I=\int_0^\infty \frac{\arctan(x^2)}{x^4+x^2+1}dx}$ Using the same method as in the second link I arrived at: $$I=\left(\frac{1-i\sqrt 3}{2}\right)f\left(\sqrt{\frac{1+i\sqrt 3}{2}}\right)+\left(\frac{1+i\sqrt 3}{2}\right)f\left(\sqrt{\frac{1-i\sqrt 3}{2}}\right)$$ Where $\displaystyle{f(a)=\int_0^{\infty} \frac{\tan^{-1}(x^2)}{x^2+a^2}=\frac{\pi}{2a}\left(\tan^{-1}(\sqrt{2}a+1)+\tan^{-1}(\sqrt{2}a-1)-\tan^{-1}(a^2)\right)},\,$ but I don't see how to simplify further. I also tried the ""straight forward"" way, by employing Feynman's trick to the following integral: $$I(b)=\int_0^\infty \frac{\arctan(bx)^2}{x^4+x^2+1}dx\rightarrow \frac{d}{db}I(b)=\int_0^\infty \frac{2bx^2}{(x^4+x^2+1)(1+b^4x^4)}dx$$ $$=\frac{2b}{b^8-b^4+1}\int_0^\infty \frac{x^2}{x^4+x^2+1}dx-\frac{b^5}{b^8-b^4+1}\int_0^\infty \frac{dx}{x^2+x+1}+$$ $$+\frac{2b^5}{b^8-b^4+1}\int_0^\infty\frac{dx}{1+b^4x^4}+\frac{b^9-b^5}{b^8-b^4+1}\int_0^\infty \frac{x^2}{1+b^4x^4}dx$$ $$=\frac{\pi}{\sqrt 3}\frac{b}{b^8-b^4+1}-\frac{2\pi}{3\sqrt 3}\frac{b^5}{b^8-b^4+1}+\frac{\pi}{\sqrt 2}\frac{b^4}{b^8-b^4+1}+\frac{\pi}{2\sqrt 2}\frac{b^6-b^2}{b^8-b^4+1}$$ Now since $I(0)=0$ we have: $ \displaystyle{I=I(1)-I(0)=\int_0^1 \left(\frac{d}{db}I(b)\right)db}$ Integrating the first two parts is okay-ish, but for the last two I have no idea on how to proceed, also it seems that only elementary constants appear thus I believe the integral can be approached in a nicer way. I would love to get some help, if it's possible without using residues since I am not great there.","['integration', 'definite-integrals', 'closed-form']"
2983417,Can ratio of smooth numbers approach 1?,"Can the ratio of $q$ -smooth numbers ever approach one? Asked more rigorously, can we ever have $$1\in \overline{\{a/b\; :\; a,b \;\text{ are } q\text{-smooth}\}}=\overline{\{\prod_{p_i\le q}p_i^{\alpha_i}\; :\; (a_1, \dots, a_{\pi(q)})\in\mathbb{Z}^{\pi(q)}\}}\;?$$ If $q=2$ , the answer is obviously no because $$1\not\in \overline{\{2^{\alpha}\; :\; \alpha\in\mathbb{Z}\}}=\{0\}\cup \{2^{\alpha}\; :\; \alpha\in\mathbb{Z}\}$$ however beyond this the problem is not easy. The reason I would like to know this is because this would imply that $$G(q)=\inf \{a/b\; :\; a>b,\; a,b \; q\text{-smooth}\}>1.$$ I suspect that we may be able to say even further that $$\overline{\{\prod_{p_i\le q}p_i^{\alpha_i}\; :\; (a_1, \dots, a_{\pi(q)})\in\mathbb{Z}^{\pi(q)}\}}=\{0\}\cup \{\prod_{p_i\le q}p_i^{\alpha_i}\; :\; (a_1, \dots, a_{\pi(q)})\in\mathbb{Z}^{\pi(q)}\}$$ which would clearly imply the result.","['number-theory', 'limits', 'elementary-number-theory']"
2983444,Neumann Series Invertibility,"It is a fairly quick exercise to show that for continuous operators $T$ on a Banach space $X$ with $\|T\| < 1$ we have the geometric series (aka Neumann series) type identity: $$
(I - T)^{-1} = \sum_{k = 0}^{\infty} T^k
$$ Showing this also shows the operator $(I-T)$ is invertible. My question is, is there a general way to prove this without a series approach? I attempted to prove that $I-T$ was a bijection. Injectivity comes from the fact that: $$
(I-T)x = 0 \iff x = Tx \iff x = 0
$$ Witht he last implication following from the fact that $\|T\| < 1$ . However, I am not sure how to prove surjectivity (if there is a way).","['banach-spaces', 'operator-theory', 'functional-analysis']"
2983445,Unit vector differentiation,"I came across an identity for differentiating an unit vector, however I can't prove it so I would appreciate if someone would explain how to derive the identity.
 Let $f(t)$ be a vector valued function, then its magnitude is given by $||f(t)||$ , and $f(t)$ is a differentiable curve such that $f(t) ≠ 0$ for all $t$ . 
Then the derivative of the unit vector is given by $\frac{d}{dt}\frac{f(t)}{||f(t)||}=\frac{f(t)✕f'(t)✕f(t)}{||f(t)||^3}$ Also the unit tangent vector $T(t)$ is defined as: $T(t)=\frac{f'(t)}{||f'(t)||}$ and in the same way $T'(t)=\frac{f'(t)✕f''(t)✕f'(t)}{||f'(t)||}$ . I appreciate any help you can provide.","['multivariable-calculus', 'vectors']"
2983452,"If $\sum_{n\geq 1}\frac{a_n}{n}$ converges, then $\lim_{n\rightarrow \infty}\frac{1}{n}\sum_{k=1}^na_k=0$","I am dealing with the test of the OBM (Brasilian Math Olympiad), University level, 2016, phase 2. As I've said at this topic (question 2) , I hope someone can help me to discuss this test. Thanks for any help. The question 1 says: Let be $(a_n)_{n\geq1}$ a real sequence such that $\sum_{n\geq 1}\dfrac{a_n}{n}$ converges. Prove that: $\lim_{n\rightarrow \infty}\dfrac{1}{n}\sum_{k=1}^na_k=0$ . My attempt: I've had an ideia if the sequence is positive. Something like that: Let be $C=\sum_{n\geq 1}\dfrac{a_n}{n}$ . The terms of the sum that we'll lead are nearlier of $0$ than these terms, so the limit exists. (Do I need anything else here?) Take $n=2^m$ . We have $\dfrac{a_i}{n}\leq\dfrac{a_i}{i}-\dfrac{1}{2}\dfrac{a_i}{i}-\ldots - \dfrac{1}{2^j}\dfrac{a_i}{i}$ if $\dfrac{1}{n}\leq \dfrac{1}{i}\bigg(1-\dfrac{1}{2}-\ldots - \dfrac{1}{2^j}\bigg)$ , it means, $i\leq n\dfrac{1}{2^j}$ . So, $\dfrac{1}{n}\sum_{k=1}^na_k=$ $\dfrac{a_{2^m}}{2^m}+\dfrac{a_{2^m-1}}{2^m}+\ldots + \dfrac{a_1}{2^m}\leq$ $\sum_{k=1}^{2^m}a_k-\sum_{k=1}^{2^{m-1}}a_k-\sum_{k=1}^{2^{m-2}}a_k-\ldots -\sum_{k=1}^{2^0}a_k$ Carrying to infty, $\lim_{n\rightarrow \infty}\dfrac{1}{n}\sum_{k=1}^na_k\leq C-\dfrac{1}{2}C-\dfrac{1}{4}C-\ldots=0$ As the terms are positive, the limit is zero, as we need prove. How can I extend if there's negative terms? I know there are gaps on my thoughts. I thanks for help.","['limits', 'proof-verification', 'sequences-and-series']"
2983502,Domain issues with Weyl quantization,"Most algebras of observables from quantum mechanics are closed. For example, fix a separable Hilbert space $H$ , and consider the algebra of bounded operators on it. This is a Banach space. In classical mechanics, the algebra of observables is typically the Poisson algebra of smooth functions $C^\infty(X)$ where $X$ is the classical phase space. I am wondering how this fact that spaces of ""quantum observables"" are larger than their classical counterparts is reconciled in quantization. For example, consider the machinery of deformation quantization, where there is supposed to be a star product $$f\star_\hbar g\in C^\infty(X)$$ which makes the classical observable algebra into a quantum one. This leads to formulations of quantum mechanics in phase space (e.g. see https://en.wikipedia.org/wiki/Phase-space_formulation ). If I am to be told that the phase-space formulation of quantum mechanics is to be entirely on equal footing with the Hilbert space formulation , then there must be a way to assign to arbitrary quantum observables (say $A,B$ ) completely equivalent classical counterparts $f_A,g_A$ . However, if this is true, what is the classical analogue of the theorem The space of trace class operators forms an even subalgebra of the space of Hilbert-Schmidt operators According to the Weyl-Wigner transform, the space of Hilbert-Schmidt operators corresponds to the closed space $L^2(X)$ . However, then the trace-class operators would be $$\text{trace-class operators}=\{f\star_\hbar g~~|~~f,g\in L^2(X)\}$$ So, just by two seconds of naivety, we already are in the uncomfortable situation where we have to define the Moyal product of non-differentiable functions. Is the Moyal product uniquely extendable to $L^2$ spaces, or even spaces of distributions? If not, then I would argue that the phase-space picture of quantum mechanics is incomplete, as there is no way of performing functional analysis.","['quantum-mechanics', 'operator-theory', 'functional-analysis', 'mathematical-physics']"
2983538,How many ways to place three distinguishable tokens on the white spaces of a $4$-by-$4$ chess board?,"Consider a $4\times 4$ chessboard like the one showing above. You want to place 3 distinguishable tokens. Each piece can only be placed in a white square, with only one piece per row and per column. How many ways are there to arrange the pieces? I have one way of solving this, but I really want to know way to solve this ""directly"". Solving Indirectly: All the cases ( $8\cdot 7\cdot 6$ ) except the ones that break the rules. So the cases that break the rules are: Imagine that I fix two points horizontally that break the rule, then I have 6 places to place the other one ( $6$ ), then I can do this in every row ( $4$ ), I can do this vertically as well ( $2$ ), and then I have to permute the 3 pieces ( $3!$ ), however I will repeat the cases where I can't tell if I'm doing this vertically or horizontally(the intersections of both) so, those cases are, I fix two points and I have 2 places for other one ( $2$ ), and I can do this in every row ( $4$ ), and I don't multiply by two because I only want to eliminate one time, and I permute the 3 pieces ( $3!$ ). $$8\cdot 7\cdot 6 -[6\cdot 4\cdot 2\cdot 3!-2\cdot 4\cdot 3!]=96$$","['contest-math', 'puzzle', 'combinatorics']"
2983566,Implicit functions and related differential equations,"I'm seeking guidance in derivation of implicit equation solutions to second degree differential equations.In the example below, differentiating twice just produced a tangle of terms which did not obviously lead to the required result. Example: If $$y^3 +3yx +2x^3 = 0, $$ prove that $$x^2(1+x^3)y'' - (3/2)xy' +y =0$$","['implicit-function', 'ordinary-differential-equations']"
2983641,Prove that $\lim_{k\to\infty}{ \sqrt[n]{ \prod_{i=1}^{n}{(x_i+k)}} - k } = \frac{\sum_{i=1}^{n}{x_i}}{n}$,"I accidentally discovered this equality, in which I can prove numerically using python. $$\lim_{k\to\infty}{ \sqrt[n]{ \prod_{i=1}^{n}{(x_i+k)}} - k } = \frac{\sum_{i=1}^{n}{x_i}}{n}$$ But I need to prove this equality in an algebraic way and I could not get anywhere. The right-hand side is nothing more than an arithmetic mean, while the left-hand side is a modification of the geometric mean.
I hope someone can help me at this point.","['limits', 'means', 'real-analysis']"
2983671,7-Dimensional Curvature and Curl,"The cross product from linear algebra is most often used in conjunction with 2-dimensional or 3-dimensional vectors.  However, it is also said to work with 7-dimensional vectors, although this version appears to live a bit deeper in the sea of mathematical prerequisites. In multivariable calculus, 2D-Curl and 3D-Curl are very much connected to the 2D cross product and 3D cross product, respectively. Curvature, with respect to arclength, has a loosely similar geometry to Curl (both involve some measure of straightness or lack thereof), and also connects with the cross product $(k = \frac{\|S'(t)\ \times\ S''(t)\|}{\|S'(t)\|^3}$ ). This raises the question, does the 7-dimensional version of the cross product lead to a 7D-Curl, 7D curvature, or 7-dimensional versions of any other topics in multivariable calculus tied to the cross product which don't exist in every dimension?","['cross-product', 'multivariable-calculus', 'linear-algebra', 'geometry']"
2983705,Combinatorial proof of $\binom{3n}{3} =3\binom{n}{3} +6n\binom{n}{2} +n^3$?,"Give a combinatorial proof of the following identity: $$\binom{3n}{3} =3\binom{n}{3} +6n\binom{n}{2} +n^3.$$ I've been working on this proof for hours, however I'm not able to show LHS = RHS-
I completely understand binomial theorem and few combinatorial proofs but not able to succeed this one.
Help would be appreciated.",['combinatorics']
2983706,"How to ""split up"" triple integrals when changing order of integration?","I'm trying to set up six different triple integrals of a tetrahedron and am having difficulty changing the order of integration, particularly finding the bounds for dzdxdy/dzdydx and dxdydz/dxdzdy. I am given the vertices of the tetrahedron, (8,7,1), (7,4,1), (2,5,1), and (5,5,5), and I have found the equations of the planes (see image below). I was able to come up with the projection on the xy-plane (see image below), but don't know how to ""split it up"" so I can find the bounds/integrate. I know with certain problems you need to divide the shape into subsections so each part can be integrated separately and then add them, but I've scoured my book, notes, and the internet and am still not sure how to split this particular triangle up. Is there a method to it (e.g. equations you can solve for), or do you just split it up however you like so that integration is possible for each of the sections? I'd appreciate any help regarding how I can move forward with this problem specifically, or just general information about how to ""break up"" integrals that are 2D projections. Thanks!","['integration', 'multivariable-calculus']"
2983721,How to evaluate $\int_{-\infty}^{\infty}\frac{x\arctan\frac1x\ \log(1+x^2)}{1+x^2}dx$,"While browsing similar questions on this site I came up with the following integral because I thought I could evaluate it. $$I=\int_{-\infty}^{\infty}\frac{x\arctan x\ \log(1+x^2)}{1+x^2}dx$$ I've been able to simplify it a bit. We first notice that $$I=\int_0^{\infty}\frac{\arctan x\ \log(1+x^2)}{1+x^2}2xdx$$ The substitution $u=x^2+1$ gives $$I=\int_1^{\infty}\arctan\sqrt{u-1}\ \log u\ \frac{du}u$$ Then $w=\log u$ gives $$I=\int_{0}^{\infty}\arctan\sqrt{e^w-1}\ dw$$ Which I do not know how to proceed with. Another approach I tried was this. Starting with the original integral, $x=\tan u$ : $$I=2\int_0^{\pi/2}u\tan u\log\sec^2u\ du$$ Which I also do not know how to do. Please help me proceed or give me a value of the integral (and show how you got it). If no closed form exists (AKA you have an answer in terms of a series or special function), I'm fine with that. cheers! Edit: In the comments it is discussed that the integral is not integrable over the positive reals, but the following related integral is: $$J=\int_0^{\infty}\frac{\log(1+x^2)\arctan\frac1x}{1+x^2}xdx$$ So. How do we find the value for $J$ ?","['integration', 'definite-integrals', 'real-analysis']"
2983730,The characteristic polynomial of $A$ is $x^n$ if and only if $\text{Tr}(A^i)=0$ for all $1\le i \le n$. [duplicate],This question already has answers here : Traces of all positive powers of a matrix are zero implies it is nilpotent (4 answers) If $A$ is nilpotent matrix then $tr(A)=0$ [closed] (4 answers) Closed 5 years ago . Let $k$ be a field of characteristic zero and $A$ be a matrix over $k$ . Then the characteristic polynomial of $A$ is $x^n$ if and only if $\text{Tr}(A^i)=0$ for all $1\le i \le n$ . The only proof I can think of is by applying the Jordan normal form to $A$ (considered as a matrix over $\overline{k}$ ). Is there any slick proof without invoking this theorem?,"['abstract-algebra', 'linear-algebra']"
2983733,Rigorous Proof of Slutsky's Theorem,"I was hoping to type up my proof of Slutsky's Theorem and get confirmation on the excruciating details being all correct... Statement of Slutsky's Theorem: $$\text{Let }X_n, \ X,\ Y_n,\ Y,\text{ share the same Probability Space }(\Omega,\mathcal{F},P).$$ $$\text{If }Y_n\xrightarrow{\text{prob}}c, \text{ for any constant } c \text{, and }X_n\xrightarrow{\text{dist}}X\text{ then:}$$ $$1.) \ X_n+Y_n\xrightarrow{\text{dist}}X_n+c$$ $$2.) \ X_nY_n\xrightarrow{\text{dist}}cX. \ \ \ \ \ \ \ \ \ \ $$ Proof of 1.) Let $x$ be a point such that $x-c$ is a point of continuity of $F_x$ and pick $\epsilon$ such that $x-c+\epsilon$ is another point of continuity of $F_x$ . By the Law of Total Probability: $$P(X_n+Y_n\leq x)=P(\{X_n+Y_n\leq x\}\cap\{|Y_n-c|\leq\epsilon\})+P(\{X_n+Y_n\leq x\}\cap\{|Y_n-c|>\epsilon\})$$ However, as $$\{ \ \{X_n+Y_n\leq x\}\cap\{|Y_n-c|>\epsilon\}\ \}\subseteq\{|Y_n-c|>\epsilon\}$$ $$\Rightarrow P(\{X_n+Y_n\leq x\}\cap\{|Y_n-c|>\epsilon\})\leq P(|Y_n-c|>\epsilon)$$ $$\Rightarrow P(X_n+Y_n\leq x)\leq P(\{X_n+Y_n\leq x\}\cap\{|Y_n-c|\leq\epsilon\})+P(|Y_n-c|>\epsilon)$$ Now note that $$\{|Y_n-c|\leq\epsilon\}\equiv\{c-\epsilon \leq Y_n \leq c+\epsilon\}$$ Thus $$P(X_n+Y_n\leq x) \leq P(X_n+c-\epsilon\leq x)+P(|Y_n-c|>\epsilon)$$ This inequality holds because we then have $$X_n+c-\epsilon\leq X_n+Y_n \leq X_n+c+\epsilon$$ so $$P(X_n+Y_n\leq x)\leq P(X_n+c-\epsilon\leq x)$$ and doing our limits $$\displaystyle\limsup_{n}P(X_n+Y_n\leq x) \leq \displaystyle\limsup_{n}P(\{X_n+c-\epsilon\leq x\})+\displaystyle\limsup_{n}P(|Y_n-c|>\epsilon)$$ The far right term is zero by $Y_n\xrightarrow{prob}c$ which gives us $$\displaystyle\limsup_{n}P(X_n+Y_n\leq x) \leq \displaystyle\limsup_{n}P(X_n+c\leq x+\epsilon)$$ As $\epsilon$ is only on the right side, and can be as small as needed and $x-c$ a point of continuity of $F_x$ , we get $$\displaystyle\limsup_{n}P(X_n+Y_n\leq x) = P(X+c\leq x)$$ The $\displaystyle\liminf_{n}$ follows similarly giving the same type of result $$\displaystyle\liminf_{n}P(X_n+Y_n\leq x) = P(X+c\leq x)$$ Thus by their equivalence $$\displaystyle\lim_{n\rightarrow\infty}P(X_n+Y_n\leq x) = P(X+c\leq x)\ \ \square$$ Proof of 2.) Assuming $\pm\epsilon / \delta$ are points of continuity of $F_x$ , and WLOG let $Y_n\xrightarrow{prob}0$ : $$P(|X_nY_n| > \epsilon)=P(\{|X_nY_n|>\epsilon\}\cap\{|Y_n|>\delta\}) + P(\{|X_nY_n>\epsilon\}\cap\{|Y_n|\leq\delta\})$$ Therefore as $$|Y_n|\leq\delta\Rightarrow\frac{1}{|Y_N|}\geq\frac{1}{\delta}\Rightarrow\frac{|X_nY_n|}{|Y_N|}\geq\frac{\epsilon}{\delta}\Rightarrow|X_n|\geq\frac{\epsilon}{\delta}$$ Also noting $$\{|X_nY_n|>\epsilon\}\cap\{|Y_n|>\delta\}\subseteq\{|Y_n|>\delta\}$$ $$\Rightarrow P(|X_nY_n| > \epsilon) \leq P(|Y_n|>\delta)+P(|X_n|>\frac{\epsilon}{\delta})$$ And so by subadditivity $$\leq P(|Y_n|>\delta) + P(X_n>\frac{\epsilon}{\delta}) + P(X_n\leq\frac{-\epsilon}{\delta}) $$ $$ = P(|Y_n|>\delta) + 1 - P(X_n\leq\frac{\epsilon}{\delta}) + P(X_n\leq\frac{-\epsilon}{\delta})$$ $$=P(|Y_n|>\delta) + 1 - F_n(\frac{\epsilon}{\delta})+F_n(\frac{-\epsilon}{\delta}) $$ Thus $$\limsup_{n}P(|X_nY_n|>\epsilon)\leq\limsup_{n}P(|Y_n|>\delta) + \limsup_{n}1 - \limsup_{n}F_n(\frac{\epsilon}{\delta})+\limsup_{n}F_n(\frac{-\epsilon}{\delta})$$ Using $Y_n\xrightarrow{prob}0$ we simplify to $$\limsup_{n}P(|X_nY_n|>\epsilon)\leq 1 - \limsup_{n}F_n(\frac{\epsilon}{\delta})+\limsup_{n}F_n(\frac{-\epsilon}{\delta})$$ $$=1 - F(\frac{\epsilon}{\delta})+F(\frac{-\epsilon}{\delta})$$ Let $\delta\rightarrow 0$ and so by properties of a CDF $$F(\frac{\epsilon}{\delta})\rightarrow 1 \text{ and }F(\frac{-\epsilon}{\delta})\rightarrow0$$ $$\Rightarrow P(|X_nY_n|>\epsilon)\rightarrow0$$ If $Y_n$ converges to a non zero constant the proof remains by just substitution $Y_n=Z_n+c$ .
The $\liminf$ again follows similarly.","['statistics', 'probability-theory', 'probability', 'real-analysis']"
2983736,"Integral $\int_0^1 \frac{(1-x^4)^{3/4}}{(1+x^4)^2}$, may involve beta function","Evaluate the integral: $$\int_0^1 \frac{(1-x^4)^{3/4}}{(1+x^4)^2} dx$$ I have used substitutions like $x^4 = u$ , or $x^{-4} = u$ . After many hours, I came up with $\frac{2}{1+x^4} = u$ which reduces the integral to : $$\int_1^2 \frac{2^{3/4}}{8} \left(\frac{u-1}{2-u}\right)^{3/4} du$$ and then taking $\frac{u-1}{2-u} = z$ gives: $$\frac{2^{3/4}}{8} \int_0^\infty \frac{z^{3/4} }{(1+z)^2} dz = \color{red}{ \frac{2^{3/4}}{8}\beta(\tfrac{7}{4},\tfrac{1}{4})}$$ Last answer comes from using: $$\int_0^\infty \frac{x^{m-1}}{(1+x)^{m+n}} dx = \beta(m,n)$$ This answer seems to be correct as online integral calculator gives $0.7005...$ as answer. What can be alternate approaches","['integration', 'beta-function', 'definite-integrals']"
2983741,An Integral from Irresistible Integrals,"I have been trying to work out a question from Irresistible Integrals, but I don't know how to proceed. The exact problem is Exercise 13.7.1. It asks us to show that $$\zeta(3)=4-\zeta(2)+\frac{8}{3}\int_0^{1/2}\frac{t\ln^3(t)}{\sqrt{1-4t^2}}dt$$ The $\zeta$ in question is the Riemann Zeta Function. The book does this integral through something that its calls its ""Master Formula,"" but asks the reader to check it directly, which I assume means to compute the integral directly. The book gives the hint of expanding the integrand as a series, using $$\frac{1}{\sqrt{1-4x}}=\sum_{n=0}^\infty\binom{2n}{n}x^n$$ After applying this, I have $$\int_0^{1/2}\frac{t\ln^3(t)}{\sqrt{1-4t^2}}dt=\sum_{n=0}^\infty\binom{2n}{n}\int_0^{1/2}t^{2n+1}\ln^3(t)dt$$ $$=-\sum_{n=0}^\infty\frac{1}{2^{2n+2}}\binom{2n}{n}\left(\frac{\ln^3(2)}{2n+2}+\frac{3\ln^2(2)}{(2n+2)^2}+\frac{6\ln(2)}{(2n+2)^3}+\frac{6}{(2n+2)^4}\right)$$ (If someone wants to check that to makes sure I'm right, then by all means, go for it) I get stuck from here. I have a few tricks to evaluate the sum for the first two terms, but not the last two terms. If you have any ideas on how to evaluate this sum (or an alternate way of evaluating this integral in the first place), let me know. Thanks! Edit : Considering that this integral is being multiplied by $8/3$ in the original problem, it may be convenient to fact or out the $8/3$ to get $$\frac{8}{3}\int_0^{1/2}\frac{t\ln^3(t)}{\sqrt{1-4t^2}}dt=$$ $$-\sum_{n=0}^\infty\frac{1}{3\cdot2^{2n-1}}\binom{2n}{n}\left(\frac{\ln^3(2)}{2n+2}+\frac{3\ln^2(2)}{(2n+2)^2}+\frac{6\ln(2)}{(2n+2)^3}+\frac{6}{(2n+2)^4}\right)$$ It also might be more convenient to factor the $2$ 's from the denominators and get $$\frac{8}{3}\int_0^{1/2}\frac{t\ln^3(t)}{\sqrt{1-4t^2}}dt=$$ $$-\sum_{n=0}^\infty\frac{1}{3\cdot2^{2n}}\binom{2n}{n}\left(\frac{\ln^3(2)}{n+1}+\frac{3}{2}\frac{\ln^2(2)}{(n+1)^2}+\frac{3}{2}\frac{\ln(2)}{(n+1)^3}+\frac{3}{4}\frac{1}{(n+1)^4}\right)$$ It looks a bit nicer, but I still don't know how to proceed. Edit 2 : A good suggestion is to turn this integral into a form of the Beta function. This can be done a few different ways, but if we take $u=4t^2$ we get $$\int_0^{1/2}\frac{t\ln^3(t)}{\sqrt{1-4t^2}}dt=\frac{1}{8}\int_0^1(1-u)^{-1/2}\ln^3\left(\sqrt{\frac{u}{4}}\right)du$$ $$=\frac{1}{64}\int_0^1(1-u)^{-1/2}\left(\ln^3(u)-3\ln^2(u)\ln(4)+3\ln(u)\ln^24)-\ln^3(4)\right)du$$ $$=\frac{1}{64}\left(\frac{\partial^3B}{\partial x^3}(1,1/2)-3\ln(4)\frac{\partial^2B}{\partial x^2}(1,1/2)+3\ln^2(4)\frac{\partial B}{\partial x}(1,1/2)-\ln^3(4)B(1,1/2)\right)$$ At this point, derivatives of the Beta function are tricky, but they boil down to derivatives of the $\psi$ function, which I am not very strong in. If someone has a solution from here, that would be handy as well, but I am hoping that someone can give a solution somehow using a series approach, as suggested in the text.","['integration', 'calculus', 'sequences-and-series']"
2983750,Showing that two binomials are relatively prime for all positive integers (Euclidean ?),"Show that $3x+11$ and $5x+18$ are relatively prime for all positive integers $x$ . Hi everyone I've looked around a lot and found similar questions like this here but when trying some of the tips I feel like whenever I get close it doesn't match. As I understand it there are two approaches I can take for a proof strategy and I can't get them to work (or am doing something wrong and not able to find the next logical step). For example via the Euclidean Algorithm So $3x+11$ and $5x+18$ are relatively prime. That means they are not both 0 and $$gcd((3x+11), (5x+18)) = 1$$ Also two integers $a$ and $b$ are relatively prime if and only if there exist integers $s$ and $t$ such that $$as+bt = 1$$ So I first tried dividing and cannot arrive at a way that I get this nice 1 sitting alone at the end. $$5x+18 = (1) (3x+11) + (2x+7)$$ $$3x+11 = (1) (2x+7) + (x+4)$$ $$2x+7 = (1)(x+4)+(x+3)$$ $$x+4 = (1)(x+3)+1$$ $$x+3 = 1(1)+(x+2)$$ By that last step I think I'm lost... Another common solution I'm seeing which is no help is people just saying
well you know that if $(3x+11)$ and $(5x+18)$ are relatively prime then there there are two integers s, t such that $$as+bt =1$$ and they pull out like $(3x+11)(5) + (-3)(5x+18) = 1 $ which is great and fine and all but I have no idea how to get those two numbers by any sort of method besides just guessing. There must be a way I'm missing or a fundamental step in the Euclidean Algorithm or definitions of Linear Combinations that I'm missing.","['coprime', 'integers', 'discrete-mathematics']"
2983756,Cannot solve recursion relation in power series solution to this ODE,"I'm trying to solve the differential equation $$\frac{d^2u}{dr^2} - \left[V_0(r-1)^2 + \frac{\ell(\ell+1)}{r^2} \right]u = -\lambda u$$ where $r\geq0$ is the radial component in spherical coordinates, $\ell\in \mathbb N$ and $V_0 >0$ , and $\lambda>0$ are the discrete eigenvalues of the system. I am looking for solutions which behave nice asymptotically, i.e. $u \to 0$ as $r \to 0$ and $r \to \infty$ . Using asymptotic analysis, we have $$\frac{d^2u}{dr^2} \approx V_0(r-1)^2u \implies u \approx e^{-\sqrt{V_0}(r-1)^2/2}$$ as $r \to \infty$ and $$\frac{d^2u}{dr^2} \approx \frac{\ell(\ell+1)}{r^2}u \implies u \approx r^{\ell+1}$$ as $r \to 0$ . I then guess a solution of the form $$u =  e^{-\sqrt{V_0}(r-1)^2/2} r^{\ell+1} \sum_{k=0}^\infty a_k r^k$$ for some power series coefficients $a_k$ . Plugging this into the differential equation however, I get recursion equations which depend on 3 coefficients, so I can't solve them. How should one solve this equation using asymptotic analysis and a series solution?","['frobenius-method', 'recurrence-relations', 'sturm-liouville', 'ordinary-differential-equations']"
2983777,"If $|z+w|=|z-w|$, prove that $\arg z-\arg w =\pm\pi/2$ [duplicate]","This question already has answers here : If $z$ and $w$ are complex numbers such that $|(z+w)| = |(z-w)|$, prove that $\arg(z)-\arg(w) = \pm (\pi/2)$ (3 answers) Closed 5 years ago . If $|z+w|=|z-w|$ , how to prove that $$\arg z-\arg w =\pm\frac{\pi}{2}$$ I squared the modulus so that I can use properties of conjugates to simplify it yielding $zw*=-wz*$ .","['algebra-precalculus', 'complex-numbers']"
2983802,Connectivity in a graph with even-degree vertices is preserved by edge removal,"I was wondering if I could get some help with this proof. Essentially, I have to prove that when you have a connected graph with each vertex being of even degree (at least 2) and it is possible to go from any vertex to another through some path, if you remove an edge, it is still possible to go from any vertex to another. I was thinking of using induction on number of edges, but I'm having trouble considering that once you remove an edge, the two vertices between the edge each lose a degree and no longer are of even degree.","['graph-theory', 'induction', 'discrete-mathematics']"
2983843,Gaussian matrix integration,"Consider a random hermitian matrix $B$ of size $N\times N$ with Gaussian probability measure given by $$
dx(B) = e^{-\frac{N}{2}Tr(B^2)}\prod_{i=1}^N dB_{ii} \prod_{i<j} d\Re(dB_{ij})d\Im(dB_{ij})
$$ where $B_{ii}, \Re(B_{ij}), \Im(B_{ij})$ are independent Gaussian random variables. How can we prove the following integral?  I am looking for a detailed proof that involves reducing it to the usual Gaussian Matrix integral that we can do, thanks. $$
\int dx(B) = 2^N \left(\frac{\pi }{N}\right)^{\frac{N^2}{2}}
$$","['integration', 'measure-theory', 'complex-analysis', 'matrices', 'gaussian-integral']"
2983928,Real and imaginary part of $\tan(a+bi)$,"When dealing with complex trigonometric functions, it is quite natural to ask how the real/imaginary part of $\tan(a+bi)$ can be expressed using $a$ and $b$ .
Of course, since $\tan z$ and $\tanh z$ are tightly linked for complex variables, we could derive the real/imaginary part for hyperbolic tangent from  the corresponding results for $\tanh(a+bi)$ and vice-versa. (We have $\tanh(iz)=i\tanh z$ and $\tan(iz)=i\tanh(z)$ .) I was not able to find this in a few basic sources I looked at. For example, I do not see it in the Wikipedia articles Trigonometric functions ( current revision ) and Hyperbolic function ( current revision ). (And List of trigonometric identities ( current revision ) does not mention much about complex trigonometric functions other than the relation to the exponential function.) I have at least tried to find what are a results for some specific value of $a$ and $b$ . I have tried a few values in WolframAlpha, for example, tangent of $2+i$ , tangent of $1+2i$ , tangent of $1+i$ .
On this site I found this question: Calculate $\tan(1+i)$ . I have tried to calculate this myself, probably my approach is rather cumbersome - I post it below as an answer. I will be grateful for references, different derivations, different expressions for this formula. (And I will also be grateful if I receive some corrections to my approach - but do not treat this primarily as a solution-verification question, it is intended as a general question.)","['complex-analysis', 'trigonometry', 'complex-numbers']"
2983950,How to dissect a rectangle to obtain an equal square?,"There are several propositions and constructions in Euclid's Elements that relate to the squaring of a rectangle, e.g. Proposition II.5 : If a straight line is cut into equal and unequal segments, then the rectangle contained by the unequal segments of the whole together with the square on the straight line between the points of section equals the square on the half. Proposition II.14 : To construct a square equal to a given rectilinear figure. Proposition VI.13 : To find a mean proportional to two given straight lines. But none of these resemble the "" proof without words "" (which isn't found in the Elements) that any rectangle can be dissected and rearranged to obtain an equal square: Performing this dissection essentially means to construct the angle $\alpha$ - everything else follows. My question is: How do I specifically construct the angle $\alpha$ when given an arbitrary
  rectangle?","['alternative-proof', 'euclidean-geometry', 'geometry']"
2983986,Prove $\sum_{k=1}^n \frac{(-1)^{k-1}}{k }\binom{n}{k}= H_n$ without the Beta function,"I know how to prove $$\sum_{k=1}^n \frac{(-1)^{k-1}}{k }\binom{n}{k}= H_n$$ by tackling it with the beta function. I was actually wondering if there is a proof of this fact without using the property of the Beta function $$B(x,y) = \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}$$","['calculus', 'binomial-coefficients', 'sequences-and-series', 'real-analysis']"
2984060,Finding a common Lipschitz constant for a family of contractions,"Let $(X,d)$ be a complete metric space and $f:[0,1] \times X \to X$ a family of functions such that $f(t,\cdot)$ is a contraction for every $t \in [0,1]$ . Further assume that $f(\cdot,x)$ is continuous for every fixed $x \in X$ . Can we conclude that there exists a common Lipschitz constant $C$ which is less than $1$ in the sense that $$
d(f(t,x),f(t,y)) \leq Cd(x,y) \ \ \forall t \in [0,1] \ \ \forall x,y \in X \ \ ? 
$$ I think an equivalent statement would be to ask if the Lipschitz constant of the above family of functions depends continuously on $t$ because then we could map the compact interval $[0,1]$ to another compact interval under this continuous map which would yield the result.","['fixed-points', 'fixed-point-theorems', 'analysis', 'functions', 'functional-analysis']"
2984085,What is n-dimensional DFT as a linear transformation matrix look like? How it can be expressed as a matrix multiplication?,"In the above picture, the Discrete Fourier Transform, for the case of 1-dimension is expressed as a matrix multiplication of the 1-D vector of length $N$ with a DFT matrix of dimension $N\times N$ . I want a similar thing for a general case of n-dimensional DFT. That is, let $x$ be an n-dimensional object, say $N_1\times N_2\times...\times N_n$ . I want to take a n-dimensional DFT of this object, by expressing as a product with a DFT matrix as in the case of 1-dimension example in the above figure. What kind of object would the DFT matrix (if i can call it a matrix) be? That defintely not a matrix product but something generalized to handle higher dimensions. Please provide me some theory and directions, or if it already exists, please point me to a reference. PS : I don't know anything about Tensors, so Ia m not sure if tensors would help.","['fourier-analysis', 'matrices', 'linear-algebra', 'linear-transformations', 'matrix-equations']"
2984136,"Sine Fourier Series for $\min(x, 1 - x)$.","I am currently taking a class on differential equations and only Analysis and Linear Algebra I and II were expected. In those subjects we never covered Fourier series. In an exercise I am now expected to solve $$
\sum_{k = 1}^{\infty} a_k \sin(\pi k x)
= \min(x, 1 - x)
$$ for the coefficients $a_k$ and for $x \in (0,1)$ . I'd be interested if anyone could share an approach, which someone with no previous knowledge of Fourier series could understand. for reference: the given differential equation is $u_t - u_{xx} = 0$ for $t > 0$ and $x \in (0,1)$ with $u(0,t) = u(1,t) = 0$ and $u(x,0) = \min(x, 1 - x)$ . for $x \in (0,1)$ EDIT 4 - Finally Correct \begin{align*}
    a_k
    & = 2 [1 - (-1)^k] \int_{0}^{\frac{1}{2}} x \sin(k \pi x) dx
    = 2 [1 - (-1)^k]  \left[ \frac{\sin(k \pi x)}{(k \pi )^2} - \frac{x}{k \pi } \cos(k \pi x) \right]_{x = 0}^{\frac{1}{2}} \\
    & = 2 [1 - (-1)^k] \left( \frac{\sin(\frac{1}{2} k \pi)}{(k \pi )^2} - \frac{1}{2 k \pi } \cos\left(\frac{1}{2} k \pi\right) - \left( \frac{\sin^2(0)}{(k \pi )^2} - \frac{0}{k \pi } \cos(0) \right) \right) \\
    & = \frac{[1 - (-1)^k]}{k \pi} \left[ \frac{2 \sin(\frac{1}{2} k \pi)}{k \pi} - \cos\left(\frac{1}{2} k \pi\right) \right]
\end{align*} Therefore we have $a_2k = 0$ .
For $a_{2k + 1}$ we have \begin{align*}
    a_{2k + 1}
    & = \frac{1 - (-1)^{2k + 1}}{(2k + 1) \pi} \left( \frac{2 \sin(\frac{1}{2} (2k + 1) \pi)}{(2k + 1) \pi} - \cos\left(\frac{1}{2} (2k + 1) \pi\right) \right) \\
    & = \frac{2}{(2k + 1) \pi} \left[ \frac{2 \overbrace{\sin\left(\frac{\pi}{2} + k \pi\right)}^{= \cos(k \pi)}}{(2k + 1) \pi} - \underbrace{\cos\left(\frac{\pi}{2} + k \pi\right)}_{= - \sin(k\pi) = 0.} \right] \\
    & = \frac{4 (-1)^k}{\left((2k + 1)\pi \right)^2}.
\end{align*}","['fourier-series', 'fourier-analysis', 'ordinary-differential-equations']"
2984151,Finding an integrating factor and solving: $(2x \sin(x + y) + \cos(x + y))dx + \cos(x + y)dy = 0$,"I am trying to find an integrating factor and solve the following differential equation: $$(2x \sin(x + y) + \cos(x + y))dx + \cos(x + y)dy = 0$$ These are my steps: $$(2x \sin(x + y) + \cos(x + y)) + \cos(x + y)dy/dx = 0$$ I check if the equation is exact: \begin{equation}
\partial U_{xy} = \partial U_{xy}
\end{equation} \begin{equation}
2x\cos \left(x+y\right)-\sin \left(x+y\right) \neq -\sin \left(x+y\right),
\end{equation} Its not so I need to find an integrating factor such that $$\frac{d}{dy} \left( μ(x)2x\cos \left(x+y\right)-\sin \left(x+y\right) \right)= \frac{d}{dx} \left( μ(x)-\sin \left(x+y\right) \right)$$ And at this point I simply get stuck. Any help or advice would be appreciated.","['integration', 'ordinary-differential-equations']"
2984222,$n$ has digit sum 100; $2n$ has digit sum 110,"My question is: A $n$ -digit number is given whose digit sum is $100$ , the number when doubled gives digit sum as $110$ then what is this $n$ -digit number? My approach: I assumed $n$ -digits to be $x_{1},x_{2},\cdots x_{n}$ and $n$ -digits after doubling the original number to be $y_{1},y_{2},\cdots y_{n}$ , so the equation comes out to be, $$\sum_{i=1}^{n}x_{i}=100$$ And another equation, $$\sum_{i=1}^{n}y_{i}=110$$ I'm not able to proceed futher after this.","['elementary-number-theory', 'discrete-mathematics', 'decimal-expansion']"
2984232,Prove a double inclusion of an arbitrary unions,"$B_n$ is defined as follows: $$B_n = \{ x \in \mathbb{N} \;|\; 3n+1 < x \le 3n+4 \}$$ What I need to do is: ""Calculate"" (not sure if that's the correct term, please correct me with the right one) the arbitrary unions of $B_n$ : $$\bigcup_{1 \le n \in \mathbb{N}}B_n$$ Prove the calculation using a double inclusion (showing that each set is a subset of the other). What I currently have: Considering that $1 \le n$ , I ""calculated"" the arbitrary unions of $B_n$ to be: $$\bigcup_{1 \le n \in \mathbb{N}}B_n = \{ x \in \mathbb{N} \;|\; 4 < x \}$$ Proving the first direction: Let: $$ x \in \bigcup_{1 \le n \in \mathbb{N}}B_n $$ Since $1 \le n \in \mathbb{N}$ , then also $4 < x \in \mathbb{N}$ . Thus: $$ \bigcup_{1 \le n \in \mathbb{N}}B_n \subseteq \{ x \in \mathbb{N} \;|\; 4 < x \} $$ Now, I'm not sure if my first-direction proof is correctly written - and please correct me if it's not - but what's more of an issue here is this: How do I approach the opposite direction proof? I'd be glad for any guidance.","['elementary-set-theory', 'proof-writing']"
2984235,Showing independence of increments of a stochastic process,"The textbook on stochastic calculus I am now reading says that
if $X\colon [0,\infty)\times\Omega\rightarrow\mathbb R$ is a stochastic process such that $X(t)-X(s)\sim N(0,t-s)$ for all $t \geq s \geq 0$ , $E[X(t)X(s)]=\min\{s,t\}$ for all $s,t \geq 0$ , then, $X$ exhibits independence increment, i.e. for every $0 \leq t_1<...<t_n$ , $X(t_1)$ , $X(t_2)-X(t_1)$ , …, $X(t_n)-X(t_{n-1})$ are independent. Here $X(t)$ denotes a random variable $X(t):\Omega\rightarrow \mathbb R$ such that $X(t)(\omega)=X(t,\omega)$ . But I guess this is not true. I suspect that we need an additional condition that $X$ is a Gaussian process. (Then, it is easy to show the independence) Am I on the right track? If so, can you give me some counterexamples? Or can it be shown without assuming Gaussian process? Any hint would be appreciated! Thanks and regards.","['stochastic-processes', 'brownian-motion', 'probability-theory']"
2984281,Using variable spearation to solve a linear ODE of first order,"Suppose I want to solve the ODE: $$f'(x) + 2f(x) = 3$$ I want to use variable separation, so I get: $$ f'(x) = 3 - 2f(x)$$ Now I want to divide by $3-2f(x)$ but I am unsure what I need to assume on $f$ in order to do that. That is, does that expression have to be non zero for all x, or only for a certain x? After that point I know what to do but I don't understand what I am supposed to do here. thanks",['ordinary-differential-equations']
2984306,Prove inequality $(1+\frac{1}{2n})^n<2$,"How can I prove inequality $$
(1+\frac{1}{2n})^n<2
$$ for $n\in\mathbb{N}$ by using induction proof method? I have tried to write that:
for $n=1$ it's true. So let's suppose that $(1+\frac{1}{2n})^n<2$ . and now I don't know what do nect because I know that $(1+\frac{1}{2(n+1)})^{n+1} > (1+\frac{1}{2n})^n$ but I don't know how to show that $(1+\frac{1}{2(n+1)})^{n+1} < 2$ .
In this task I cannot use the definition of $e$ number.","['algebra-precalculus', 'induction', 'inequality']"
2984329,What is meant by the 'truth' of a statement in a truth table? [duplicate],"This question already has answers here : What is the distinction being made with regards to truth and falsity in these two sources? (2 answers) Closed 5 years ago . The focus of propositional logic is said to be argument schemas that lead to valid conclusions, and not with the contents of the arguments themselves. This implies that an argument can consist of empirically false premises (i.e. factually false) but can still lead to a valid conclusion. For example consider the following valid argument: All cups are green. Socrates is a cup. Therefore, Socrates is green. Given then that we are not concerned with 'empirical truth' of statements in propositional logic, what do the 'truth values' assigned to statements  in a truth table represent/indicate? What is meant be 'truth' in propositional logic? Please could you ensure any answers are stated in simple terms as my understanding is minimal.","['propositional-calculus', 'logic', 'discrete-mathematics']"
2984337,P-value vs. Bayesian statistics,"Are there any theoretical considerations between $p$ -value and the Bayesian statistics? I mean say, any theorem regarding both of these two concepts at a time.","['statistical-inference', 'statistics', 'p-value', 'bayesian', 'probability-theory']"
2984351,"Asymptotic expansion of $\int_0^{+\infty} \frac{ne^{-\sqrt{t}}}{1+n^2t^2}\,dt$","I would like to get a general formula to get the asymptotic expansion at the order $n$ (so at whatever precision I want) of the following integral : $$I = \int_0^{+\infty} \frac{ne^{-\sqrt{t}}}{1+n^2t^2} \mathrm{d}t$$ Some thoughts : For now I am able to find an asymptotic expansion of order $1$ . First intuitively we have : $$I = O \left ( \frac{1}{n} \right )$$ From the expression : $$\frac{ne^{-\sqrt{t}}}{1+n^2t^2}$$ The change of variable : $\tan(\theta) = nt$ suggests itself and the problem boils down to calculating an asymptotic expansion of : $$\int_0^{\pi/2} e^{-\sqrt{\frac{\tan(\theta)}{n}}} \mathrm{d}\theta$$ Now it is possible to use the dominated convergence theorem because we have : $$e^{-\sqrt{\frac{\tan(\theta)}{n}}} \leq 1$$ Yet there is still a problem since $I$ is an improper and integral, so by using the dominated convergence theorem we only get an asymptotic expansion and not the exact value. That’s why I get the following asymptotic (of order $1$ ): $$\frac{\pi}{2} + O \left ( \frac{1}{n} \right )$$ Now is it possible to expand this in order to get a general formula for the asymptotic expansion of $I$ at whatever order we want ?","['integration', 'asymptotics', 'real-analysis', 'calculus', 'sequences-and-series']"
2984440,Bayesian Interpretation for Ridge Regression and the Lasso,"I'm learning the book ""Introduction to Statistical Learning"" and in the Chapter 6 about ""Linear Model Selection and Regularization"", there is a small part about ""Bayesian Interpretation for Ridge Regression and the Lasso"" that I haven't understood the reasoning. A Bayesian viewpoint for regression assumes that the coefficient vector $\beta$ has some prior distribution, say $p(\beta)$ , where $\beta = (\beta_0, \beta_1, \dots, \beta_p)^\top$ . The likelihood of the data can be written as $f(Y|X, \beta)$ , where $X = (X_1, X_2, \dots, X_p)$ . Multiplying the prior distribution by the likelihood gives us (up to a proportionality constant) the posterior distribution, which takes the form $$p(\beta|X, Y) \propto f(Y|X,\beta)p(\beta|X) = f(Y|X, \beta)p(\beta),$$ where the proportionality above follows from Bayes’ theorem, and the equality above follows from the assumption that X is fixed. The authors assume the linear model: $$Y = \beta_0 + X_1\beta_1 + \dots + X_p\beta_p + \epsilon,$$ and suppose the errors are independent and drawn from a normal distribution. There is also assumption that $p(\beta) = \prod_{j=1}^p g(\beta_j)$ for some density function $g$ . Then from those points, It turns out that ridge regression and the lasso follow naturally from two special cases of $g$ : If $g$ is a Gaussian distribution with mean zero and standard deviation a function of $\lambda$ , then it follows that the posterior mode for $\beta$ $-$ that is, the most likely value for $\beta$ , given the data—is given by the ridge regression solution. (In fact, the ridge regression solution is also the posterior mean.) If $g$ is a double-exponential (Laplace) distribution with mean zero and scale parameter a function of $\lambda$ , then it follows that the posterior mode for $\beta$ is the lasso solution. (However, the lasso solution is not the posterior mean, and in fact, the posterior mean does not yield a sparse coefficient vector.) I don't understand why ridge regression and the lasso follow 2 special cases of $g$ like that and why they have such distribution. Would anyone please help me explain this? Thank you so much in advance for all your help!","['machine-learning', 'statistics', 'linear-regression']"
2984465,Proving a series is convergent - $\sum _{n=1} ^\infty \frac{(-1)^n}{n}$ without using alternating series test,"$$\sum _{k=1} ^\infty \frac{(-1)^k}{k}$$ I know this question has been answered a few times but my professor has not taught alternating series test yet or anything other than ratio test, root test and comparison test where $a_i \geq 0$ for every $i \in \mathbb N$ and $\sum_{i=1} ^\infty a_i$ converges and if $|b_i| \leq a_i$ for every i then $\sum_{i=1} ^\infty b_i$ converges absolutely. So here's my attempt using Cauchy criterion. What we know: We say that the series $\sum _{i=1}^\infty a_i$ converges if the sequence of partial sums $(S_i)_i$$_\in$$_\mathbb N$ converges. From Cauchy criterion, $(S_i)_i$$_\in$$_\mathbb N$ converges if and only if it is a Cauchy sequence. It is quite obvious that $$\lim_{k\to\infty} S_k = \sum _{k=1}^\infty \frac{(-1)^k}{k}$$ . I denote $\lim_{k\to\infty} S_k = S$ Suppose ( $S_k$ ) is convergent. Then $\forall \epsilon \gt 0, \exists N \in \mathbb N$ such that $\forall n \geq N,$ $|S_n - S|$ = $\vert \sum_{k=n+1} ^\infty \vert$ $\lt \epsilon$ I am stuck here. Is it possible to find such N for all $\epsilon \gt 0$ to hold $\vert \sum_{k=n+1} ^\infty \vert$ $\lt \epsilon$ to be true? (If yes, then the sequence ( $S_k$ ) is convergent so $\sum_{k=1} ^\infty \frac{(-1)^k}{k}$ is convergent by the definition but I don't quite understand if we can always find such N) edit: I don't think ratio test or root test are applicable to solve this and is the alternating series test the only way to solve this problem?","['real-analysis', 'alternative-proof', 'sequences-and-series', 'limits', 'convergence-divergence']"
2984468,"Finding $\lim_{n\to \infty}\sqrt n \int_0^1 \frac{\,dx}{(1+x^2)^n}$","$$ 
\lim_{n\to\infty} n^{1/2}
\int_{0}^{1} \frac{1}{(1+x^2)^n}\mathrm{d}x=0
$$ Is my answer correct?
But I am not sure of method by which I have done.","['integration', 'limits', 'calculus']"
2984471,Is $f$ integrable?,"Exercise 11.21 in Real Analysis for... by Richard Bass says: 
Suppose $f: \mathbb{R}^n : \rightarrow \mathbb{R}$ is measurable, $c>0$ , and $p<n$ ? If $|f(x)| \leq c|x|^{-p} \chi_{B(0,1)}(x)$ a.e, prove that $f$ is integrable. First of all, am I right to assume that $|x|$ means $||x||$ ? In what follows, I will choose $||\cdot|| = || \cdot ||_1$ To get some intuition, I tried the case where $n=2$ and $p=1$ . We have that: $\int_{\mathbb{R^2}} |f(x)| \, dm(x) \leq c\int_{B(0,1)} ||x||_1 dm(x) = c\int_{-1}^{1} [ \int_{-1}^{1} \frac{1}{|x_1| + |x_2|}dm(x_1)]\, dm(x_2)$ and $\int_{-1}^{1} \frac{1}{|x_1| + |x_2|}dm(x_1) \leq \int_{-1}^{1} \frac{1}{|x_1|}dm(x_1)=2 \int_{0}^{1} \frac{1}{x_1} dm(x_1)$ But $\int_{0}^{1} \frac{1}{x_1} dm(x_1)$ is not finite. So, even in the easiest case I am kind of stuck. Can someone help me out ?","['integration', 'measure-theory', 'notation', 'real-analysis']"
2984493,Limit in $L^{1}(\mathbb{R})$,"I have the following problem concerning a limit in $L^{1}(\mathbb{R}$ ), the class of all Lebesgue integrable functions on $\mathbb{R}$ with the Lebesgue measure $m$ . Let $f\in L^{1}(\mathbb{R})$ . Does $$\lim_{h\to 0}\int_{\mathbb{R}}|f(x-h)-f(x)|~dx$$ exist? If it does, what is its value? My intuition is that the limit does exist. However, I have no idea how to prove it. I noticed that $\int_{\mathbb{R}}|f(x-h)-f(x)|~dx=||f(x-h)-f(x)||_{1}$ , and I know that since $f\in L^{1}(\mathbb{R})$ , we have $||f(x)||_{1}<\infty$ . I think this needs to used somewhere, but I'm not sure where. Any help is appreciated.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'lp-spaces']"
2984495,Does sheafification of bundles have a right adjoint?,"Given a topological space $X$ , let $\mathbf{Bundle}(X)=\mathbf{Top}/X$ be the category of bundles over $X$ , and let $\mathbf{Sh}(X)$ be the category of sheaves over $X$ . Then there's a sheafification functor $\mathbf{Bundle}(X)\to\mathbf{Sh}(X)$ that takes a bundle to its sheaf of sections, and this functor has a left adjoint that sends a sheaf to its corresponding étalé bundle. In the case where $X$ is the one-point space these functors are just the forgetful functor $U:\mathbf{Top}\to\mathbf{Set}$ and the functor $\mathbf{Set}\to\mathbf{Top}$ that equips a set with its discrete topology. In this case $U$ also has a right adjoint that equips a set with its codiscrete (a.k.a. indiscrete) topology. Does the sheafification functor have a right adjoint in the case of general $X$ ? Presumably this would be a functor that sent each sheaf to a bundle whose fibres had codiscrete topology.","['category-theory', 'sheaf-theory', 'adjoint-functors', 'general-topology', 'topos-theory']"
2984537,"Is this set dense in $\mathcal{C}^{\infty} (\mathbb{S}^3 , \mathbb{R}^3 ) $?","Consider $\mathcal{F} = {\{ f:\mathbb{S}^3 \to \mathbb{R}^3; f\mbox{ is smooth} \}}$ and the metric $d: \mathcal{F}\times  \mathcal{F} \to \mathbb{R} $ $$d(f,g) = |f-g| = \sup_{p\in \mathbb{S}^3} \|f(p) - g(p)\|, $$ it is easy to see that $(\mathcal{F}, d)$ is a metric space.
Let $T^2 \subset \mathbb{S}^3$ be the set $$T^2 = \frac{1}{\sqrt{2}}\cdot \mathbb{T}^2 = \left\{(x_1,x_2,x_3,x_4)\in \mathbb{S}^3 ; \ x_1^2 + x_2^2 = x_3^2 + x_4^2 = \frac{1}{2} \right\}. $$ Question: Is the set $\mathcal{A} = \{f\in \mathcal{F};\ f(p)\neq 0 \ \  \forall\ p\in T^2 \}$ dense in $\mathcal{F}$ ? This seems true but I'm a little confused about how I supposed to approach this problem. Can anyone help me?","['differential-topology', 'metric-spaces', 'analysis']"
2984566,Erdos-Kac implies the prime number theorem?,"I am curious as to whether the Erdos-Kac theorem can imply a lower bound on the density of primes, or perhaps imply the (weaker) infinitude of prime numbers all in all. It seems as if the Erdos-Kac theorem should imply that the probability of having only $1$ prime factor should be roughly $1/\log n$ , however, extrapolating this information from the assumption that the distribution is roughly Gaussian, and then calculating the probability of that event over the Gaussian random variable could lead one to think that the probability of having 0, or a negative number of prime divisors is also roughly $1/\log n$ , which doesn't even make sense. Most likely, this implies that the convergence to Gaussian is slower in the distribution's tail, and that in particular there should be some error term roughly of that size. Can anyone give me some direction as to how to think about the relation between the two theorems? And what kind of actual information can be extrapolated from the normal limit distribution, implied by the Erdos-Kac theorem, regarding the density of primes? Ciao","['analytic-number-theory', 'number-theory', 'analysis', 'prime-numbers']"
2984589,"If $X^{(n)},X$ are càdlàg and $X^{(n)}\to X$ in distribution, do the corresponding transition semigroups strongly converge?","Let $\left(\kappa^{(n)}_t\right)_{t\ge0}$ and $(\kappa_t)_{t\ge0}$ be Markov semigroups on $(\mathbb R,\mathcal B(\mathbb R))$ for $n\in\mathbb N$ $(T_n(t))_{t\ge0}$ and $(T(t))_{t\ge0}$ be strongly continuous contraction semigroups on $C_0(\mathbb R)$ (continuous functions $\mathbb R\to\mathbb R$ vanishing at infinity equipped with the supremum norm) with $$T_n(t)f=\int\kappa^{(n)}_t(\;\cdot\;,{\rm d}y)f(y)\tag1$$ and $$T(t)f=\int\kappa_t(\;\cdot\;,{\rm d}y)f(y)\tag2$$ for all $f\in C_0(\mathbb R)$ and $t\ge0$ $X^{(n)}$ and $X$ be real-valued càdlàg Markov processes with transition semigroups $\left(\kappa^{(n)}_t\right)_{t\ge0}$ and $(\kappa_t)_{t\ge0}$ , respectively, for $n\in\mathbb N$ Assume $$X^{(n)}_0\xrightarrow{n\to\infty}X_0\tag3$$ in distribution and $$X^{(n)}\xrightarrow{n\to\infty}X\tag4$$ in distribution (with respect to the Skorohod topology). Are we able to conclude $$\left\|T_n(t)f-T(t)f\right\|_\infty\xrightarrow{n\to\infty}0\tag5$$ for all $f\in C_0(\mathbb R)$ and $t\ge0$ ? The desired claim is part of the following theorem in the book of Kallenberg, but I don't understand his proof: Relevant part of the proof: EDIT : What's bothering me most: Why are we allowed to assume $X_0=x$ and $X^n_0=x_n$ ? Can the general case somehow be reduced to that case? I don't know how he's arguing that $X$ is almost surely continuous at $t$ . Is this really true? In any case, if we assume that $X$ is almost surely continuous, it is at least clear to me that $(T_n(t)f)(x_n)\xrightarrow{n\to\infty}(T(t)f)(x)$ for all $(x_n)_{n\in\mathbb N}\subseteq\mathbb R$ and $x\in\mathbb R$ with $x_n\xrightarrow{n\to\infty}x$ and $t\ge0$ . But why is that sufficient for $(5)$ ?","['operator-theory', 'markov-process', 'functional-analysis', 'semigroup-of-operators', 'probability-theory']"
