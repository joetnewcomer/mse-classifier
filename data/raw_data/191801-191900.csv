question_id,title,body,tags
3642769,continuous surjection from $GL_2(\Bbb R)$ to closed unit disc in the complex plane,Does there exist a continuous surjective map from $G = GL_2(\Bbb R)$ to the closed unit disc $\{z \in \Bbb C: |z| \le 1\}$ in $\Bbb C$ ? I know that $C^{*}$ sits inside $G$ as a subgroup. But it didn't help me. So kindly share some thoughts. Thank you.,"['matrices', 'continuity']"
3642786,Limit of the form $0*\infty$,"Consider the limit L= $\lim_{x\to\infty}$ $x^2*((\frac{x+1}{x-1})^x-e^2)$ . As $x$ approaches $\infty$ , $x^2$ approaches $\infty$ and $(\dfrac{x+1}{x-1})^x$ approaches $e^2$ , So we have a $0*\infty$ situation. I tried resolving this with L'hopital, by writing $x^2$ as $1/(1/x^2))$ , But it wasnt quite clear with how to proceed further. Another Idea I had was to write out the expansion of $(\dfrac{x+1}{x-1})^x$ by writing it as ( $1+\dfrac{2x}{x-1}$ )^x, and using the binomial theroem, But that didnt help either. This was from a high school maths exam and the syllabus DID-NOT include maclaurin/taylor series, so there has to be an easier way. The answer given is $2/3*e^2$","['limits', 'calculus', 'limits-without-lhopital', 'real-analysis']"
3642861,Prove $\binom{n}{k+1}+\binom{n}{k}=\binom{n+1}{k}$.,"For $n = 0,1,2,...$ and $k \in \{0,...,n\}$ , prove that $$\binom{n}{k+1}+\binom{n}{k}=\binom{n+1}{k}$$ Here's my attempt. $$\binom{n}{k+1}+\binom{n}{k}=\frac{n!}{(n-(k+1))!(k+1)!} + \frac{n!}{(n-k)!k!}$$ $$\implies \frac{n!(n-k)}{(n-(k+1))!(k+1)!(n-k)} + \frac{n!(k+1)}{(n-k)!k!(k+1)}$$ $$\implies \frac{n!(n-k)+n!(k+1)}{(n-k)!(k+1)!}$$ $$\implies \frac{n!((n-k)+(k+1))}{(n-k)!(k+1)!}$$ $$\implies \frac{n!(n+1)}{(n-k)!(k+1)!}$$ But I get stuck here because this does not equal $\binom{n+1}{k}$ but instead equals $\binom{n+1}{k+1}$ .","['real-analysis', 'stochastic-processes', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
3642868,Example for $E[E(X\mid\mathcal{G_1})\mid\mathcal{G_2}] \ne E[E(X\mid\mathcal{G_2})\mid\mathcal{G_1}]$,"If $X$ is an integrable random variable on probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and $\mathcal{G_1}, \mathcal{G_2}$ sub sigma fields of $\mathcal{F}$ then how can we find an example where $\Omega = \{a, b, c\}$ in which $$E[E(X\mid\mathcal{G_1})\mid\mathcal{G_2}] \ne E[E(X\mid\mathcal{G_2})\mid\mathcal{G_1}].$$ I would really appreciate if you could analytically show the steps of conclusion. I am self learning.","['conditional-expectation', 'probability-theory']"
3642899,"How to prove the sequence $\{a_n\}$ is unbounded, which satisfies the recurrence relation $a_{n+1}=\ln |a_n|$?","When I browsed Zhihu (a Chinese Q&A community), I met this question. That is Let $\{a_n\}$ be recursive s.t. $$a_1=2,\ a_{n+1}=\ln |a_n|(n\in \Bbb N).$$ Show that $\{a_n\}$ is unbounded. I want to investigate a subsequence $\{a_{t_n}\}$ of $\{a_n\}$ , where $t_n$ is greatest integer satisfying $$a_{t_n}=\min_{1\leqslant k\leqslant n}a_k.$$ Thus $a_{t_n}\to -A(<0),n\to \infty$ . However, it helps little with the origin question. So how can I solve it ?","['dynamical-systems', 'sequences-and-series']"
3642938,Deligne generic base change theorem $l$-adic sheaves,"Let $f:X \to Y$ be a finite type morphism of noetherian schemes and $F$ a constructible etale sheaf on $X$ . Deligne shows in SGA 4 1/2 that there exists a dense open subset $U \subseteq Y$ such that $f_*F|_U$ is constructible and is compatible with any base change. I've tried to show that a similar property also holds for $l$ -adic sheaves.So, I considered $F=(F_n)_{n \geq 1}$ an $l$ -adic sheaf on $X$ (by which I mean a projective system $(F_n)_{n \geq 1}$ where each $F_i$ is an $\dfrac{\mathbb{Z}}{l^i}$ sheaf such that $\dfrac{F_{n+1}}{l^nF_{n+1}} \cong F_n$ I would like to find an open subset $U$ such that for every $n \geq 1$ , $f_*F_n$ is constructible, $\dfrac{f_*F_{n+1}}{l^nf_*F_{n+1}} \cong f_*F_n$ and we have compatibility with any base change for every $f_*F_n$ . I tried to use that generic base change is true for every $F_n$ , but that didn't bring me up much ,as for every $f_*F_n$ the suitable open subset could change.","['etale-cohomology', 'algebraic-geometry', 'schemes']"
3642945,Sine Graph and Cosine Graph,"Can anybody explain to me how is the sin graph complementary to the cos graph as you only shift the sin graph by 90 degrees to get the same graph as the cos one. But by definition complementary is when you add some angles up to get to 90 degrees, but I only see the sin graph getting shifted. Another question is that I've been told that the cos graph is complementary to the sin graph. Does this mean that the graphs will be the same every 90 degrees?",['trigonometry']
3642975,Problem understanding invariant subspaces and foliations,"I am studying control theory and I am starting the concept of geometric control theory. As a prerequisite to this, I am studying the concet of invariant subspaces, and I having some troubles understanding some concepts. To try to understand my doubts I think I have to start from the beginning, but please correct me if I say something wrong. So, $V$ is an invariant subspace under $A$ if: $AV\subset V$ and in this context, we can find a coordinate transformation such that : $TAT^{-1}=\begin{pmatrix}
A_{11} &A_{12} \\ 
0 & A_{22}
\end{pmatrix}$ at this point the notes of my professor say that this implies that the invariant subspace is an eigenspace (but I don't understand why). And so this should implies that the evolutions that start in $V$ remains in $V$ , and this can be seen from the system in the new coordinates: $\dot{z_1}=A_{11}z_1 + A_{12}z_2+B_1u$ $\dot{z_2}=A_{22}z_2+B_2u$ Moreover, it says that if I consider two generic initial conditions whose difference belong to $V$ , their evolution remain if an affine variety of the same class (these last few are the literal words in my note, which I don't understand).  And it says that the structure induced by translation from $V$ is called foliation . I am very confused from this arguments, especially I cannot understand the concept of foliation. To give more context, I am studying this in order to arrive to characterize the reachability and observability in control theory, but don't know if it matters. Can somebody please help me make clarity?","['dynamical-systems', 'invariant-subspace', 'control-theory', 'differential-geometry']"
3643111,Probability of binomial distribution,"Here's the question No.8 from 2020 summer semester test of Auckland University. You have a box with lots of sticks of four colours: black, white, red and blue. There are equal number of sticks of each colour. That is, if you pick one stick then any colour will be equally probable. What is the probability to take two sticks of the same colour from the box? (You have to pick the sticks both at once.) (a) $\frac4{\binom53}$ (b) $4\frac{\binom53}{4\cdot3}$ (c) $\frac4{\binom42}$ (d) $\frac1{4\cdot3}$ I have an argument with my instructor, that is, my instructor agree that the answer is 2/5, but I think the answer should be 1/4. We argued if the probability of all 10 outcomes are same. Screenshot here: Could somebody tell me which is the correct answer? $2/5$ or $1/4$ ?",['combinatorics']
3643138,How to prove the following strange relation concerning fibonacci numbers,"Is the following relation concerning fibonacci numbers, $F_n$ true? $$F_{2n-1}^n=2^{2n^2}\prod\limits_{r=1}^{n}\prod\limits_{s=1}^{n}\left(\cos^2\frac{r\pi}{2n+1}+\cos^2\frac{s\pi}{2n+1}\right)$$ I am dumbfounded seeing this expression. Is the expression true. If so, should we try to prove the expression taking only the portions inside the brackets, or should we make use of de-moivre's theorem, or, any recurrence formulae? Meanwhile, I know of this relation among Fibonacci numbers and trigonometric function: $$F_n=\prod\limits_{k=1}^{\lfloor\frac{n-1}{2}\rfloor}\left(1+4\cos^2\frac{k\pi}{n}\right)$$ . How could we use this expression in proving the above relation. The main relation arose from the formulae for finding the number of tilings of a chessboard using dominoes. Any hints? Thanks beforehand.","['trigonometry', 'fibonacci-numbers', 'combinatorics', 'products']"
3643244,Lebesgue Integral - Self Learning,"I finished some courses on Calculus at college sometime ago, then it goes without saying I learned Riemann Integrals. However, I realized that there is another type of integrating functions: Lebesgue Integrals. Because of this, I really would like to understand them by my own. Which books would you recommend for me, who wants to learn by my on during this quarantine. It would be nice if the book contained exercises or even were like Stewart's Calculus. Thank you","['integration', 'lebesgue-integral', 'book-recommendation', 'reference-request', 'calculus']"
3643334,Counting Lyndon words with no adjacent character repeats,"I'm interested in counting aperiodic words in bracelets. I know that corresponds to Lyndon words, and I know how to count the number of Lyndon words for an $(n, k)$ bracelet using Moreau's necklace counting function: $$\frac{1}{n}\sum_{d|n}\mu \left(\frac{n}{d}\right)k^d$$ How could I add the condition that I only want to count words with no adjacent letter repeats? (Example: for $n=3$ and $k \geqslant 3$ , $ABC$ would count, but $ABCA$ wouldn't due to the repeating of 'A')","['lyndon-words', 'combinatorics', 'necklace-and-bracelets']"
3643337,How to show that $\arcsin|\sin x|-\arccos|\cos x|=0$ for all $x\in \Bbb R$,How to show that $\arcsin|\sin x|-\arccos|\cos x|=0$ for all $x\in \Bbb R$ I tried to draw the graph and got that $\arcsin|\sin x|=\arccos|\cos x|$ But I have no idea how to prove it. Thank you all!,['trigonometry']
3643403,Probability distribution vs. probability function,"Is there a difference between the expressions ""probability distribution"" and ""probability function"" or are they just synonyms?","['probability', 'terminology']"
3643449,Covariance basic properties and understanding,"Let's consider two random variables $A$ and $B$ having joint probability distribution $P(A,B)$ . I would like to understand better the limit cases of the correlation coefficient $r=\frac{C(A,B)}{\sigma(A)\sigma(B)}$ I first show what I understand and where I struggle. In the case $A$ and $B$ are not correlated, it means that $P(b|a)=P(b)$ (or equivalently $P(a|b)=P(a)$ ). In this case: $\int da db P(a,b) *a*b = \int da P(a)*a \int db P(b)*b$ which implies $C(A,B)=0$ and thus $r=0$ . In the case $A$ and $B$ are perfectly correlated, I can imagine a specific case which is: $P(b|a)=\delta(b-a)$ ( $b$ is always equal to $a$ ). Then we have: $$P(a) = \int db P(a,b) = \int da P(a) \delta(b-a) = P(b)$$ And finally: $$C(A,B)=\int da db P(a,b) a*b = \int da db P(a) \delta(b-a) * a * b - \int da P(a)*a \int db P(b)*b=Var(A)$$ And as $P(a)=P(b)$ I have $Var(A)=\sigma(A)^2=\sigma(A) \sigma(B)$ which proves $r=1$ . My question is the following: In the case of perfect correlations, the case $P(b|a)=\delta(b-a)$ is very specific. I would imagine a more general case like $P(b|a)=\delta(b-f(a))$ meaning that if I know $a$ I can deduce for sure $b$ but it is not necesserally the same as $a$ . I tried to derive something in this more general case but I didn't manage to find anything. Are there some properties here ? I also saw the case of ""anti correlation"" case for which $r=-1$ . To which $P(b|a)$ does that correspond to ? $P(b|a)=\delta(b+a)$ ?",['statistics']
3643479,Is there a way to calculate the sum of absolute values of the roots of a cubic polynomial without actually computing the roots?,"Let $ax^3+bx^2+cx+d$ be a cubic polynomial. Let $r_1$ , $r_2$ , $r_3$ be its roots. Let us assume all three roots are real. It is well known that $r_1+r_2+r_3=-\dfrac{b}{a}$ . Is there any way to calculate $|r_1|+|r_2|+|r_3|$ without actually computing the roots? The answer is of course easy if all roots positive or all roots are negative. What about otherwise? Thank you.","['cubics', 'algebra-precalculus', 'roots', 'polynomials']"
3643615,Derivative of $(uA+C)^{-1}\mathbf{b}$ w.r.t. $u\in\mathbb{R}$,"Given that $(uA+C)\mathbf{x}=\mathbf{b}$ where only $u\in \mathbb{R}$ and $\mathbf{x}\in\mathbb{R}^n$ are unknowns, and where $(uA+C)\in\mathbb{R}^{n\times n}$ is an invertible matrix, how can I determine $\frac{d\mathbf{x}}{du}$ ? I rewrite the equation to $$\mathbf{x}=(uA+C)^{-1}\mathbf{b}$$ and wonder whether there is any way to find/simplify $$\frac{d}{du}(uA+C)^{-1}\mathbf{b}$$ Background In my particular case $(uA+C)\mathbf{x} = \mathbf{b}$ comes from $$ \begin{bmatrix}
-x_1 & -y_1 & -1 & 0 & 0 & 0 & x_1x_1' & y_1x_1' & x_1' \\
0 & 0 & 0 & -x_1 & -y_1 & -1 & x_1y_1' & y_1y_1' & y_1' \\
-x_2 & -y_2 & -1 & 0 & 0 & 0 & x_2x_2' & y_2x_2' & x_2' \\
0 & 0 & 0 & -x_2 & -y_2 & -1 & x_2y_2' & y_2y_2' & y_2' \\
-x_3 & -y_3 & -1 & 0 & 0 & 0 & x_3x_3' & y_3x_3' & x_3' \\
0 & 0 & 0 & -x_3 & -y_3 & -1 & x_3y_3' & y_3y_3' & y_3' \\
-x_4 & -y_4 & -1 & 0 & 0 & 0 & x_4x_4' & y_4x_4' & x_4' \\
0 & 0 & 0 & -x_4 & -y_4 & -1 & x_4y_4' & y_4y_4' & y_4' \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
\end{bmatrix} \begin{bmatrix}h1 \\ h2 \\ h3 \\ h4 \\ h5 \\ h6 \\ h7 \\ h8 \\h9 \end{bmatrix} = \begin{bmatrix}0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\1 \end{bmatrix}$$ (which comes from here ) where $u$ is one of $x_1'$ , $y_1'$ , $x_2'$ , $y_2'$ , $x_3'$ , $y_3'$ , $x_4'$ , $y_4'$ . For example, for $u\equiv x_1'$ we have $$ A = \begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & x_1 & y_1 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{bmatrix} $$ Edit I vaguely remember a technique called implicit differentiation which I feel may be useful: $$ \frac{d}{du}(uA+C)\mathbf{x}=\frac{d}{du}\mathbf{b} $$ $$ \frac{d}{du}uA\mathbf{x}+\frac{d}{du}C\mathbf{x}=\mathbf{0} $$ $$ A\frac{d}{du}u\mathbf{x}+C\frac{d\mathbf{x}}{du}=\mathbf{0} $$ $$ A(\mathbf{x}+u\frac{d\mathbf{x}}{du})+C\frac{d\mathbf{x}}{du}=\mathbf{0} $$ $$ A\mathbf{x}+(uA+C)\frac{d\mathbf{x}}{du}=\mathbf{0} $$ $$ \frac{d\mathbf{x}}{du}=-(uA+C)^{-1}A\mathbf{x} $$ ... did I just solve it; is this correct?","['matrices', 'multivariable-calculus', 'matrix-equations', 'matrix-calculus']"
3643654,Prove that $A \cup C \subseteq B \cup C$ iff $A \setminus C \subseteq B \setminus C$,"This is an exercise from Velleman's ""How To Prove It"": Suppose $A$ , $B$ , and $C$ are sets. Prove that $A \cup C \subseteq B \cup C$ iff $A \setminus C \subseteq B \setminus C$ . Proof: Suppose that $A \cup C \subseteq B \cup C$ . Let $x \in A \setminus C$ be arbitrary. Then $x \in A$ and $x \notin C$ . Suppose $x \notin B$ . Since $x \notin B$ and $x \notin C$ , $x \notin B \cup C$ . Since $x \notin B \cup C$ and $A \cup C \subseteq B \cup C$ , $x \notin A \cup C$ . But this contradicts the fact that $x \in A$ . Thus, $x \in B$ . Since $x \in B$ and $x \notin C$ , $x \in B \setminus C$ . Since $x$ was arbitrary, it follows that $A \setminus C \subseteq B \setminus C$ . Now suppose that $A \setminus C \subseteq B \setminus C$ . Let $x \in A \cup C$ be arbitrary. Then either $x \in A$ or $x \in C$ . Suppose $ x \notin B \cup C$ . Since $x \notin C$ , it follows that $x \in A$ , so $x \in A \setminus C$ . Then since $A \setminus C \subseteq B \setminus C$ , $x \in B \setminus C$ . But this contradicts the fact that $x \notin B$ . Thus, $x \in B \cup C$ . $\square$ My first approach for the $\rightarrow$ direction was to use a proof by cases on whether $x \in B$ or $x \notin B$ . If $x \in B$ , then clearly $x \in B \setminus C$ , but the other case leads to a contradiction (as shown in the proof above). In a proof by cases, is it valid to eliminate some cases by showing that they lead to a contradiction? I would appreciate any other comments on the proof as well. Thanks!","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3643696,"Which sets are ""connectable""?","Let's name each set of more than three points ""connectable"", when it is possible to connect all of the points that belong to set with n line segments (where n is number of points) in such a way that they create a n -gon that don't intersect itself. Of course, points are placed in two dimensional space. Here are two examples of connectable sets( Sorry for bad quality of the pictures ): Next example shows points connected in improper way, the created polygon have only six sides, while the set consists of seven points(The orange point lies on the straight line segment). This set, and the previous one are not connectable. My question is: Can we easily determine whether given set is connectable or not? For example the set below looks like if it wasn't connectable, but I didn't managed to prove this. Thanks for all the help.","['graph-theory', 'geometry', 'polygons', 'combinatorial-geometry', 'algorithms']"
3643703,Does $K$-theoretical Atiyah-Singer index formula hold for non-compact manifolds?,"In famous The Index of Elliptic Operators: I Atiyah and Singer introduce two families of morphisms: $$\text{a-ind}^X,\, \text{t-ind}^X\colon K(TX)\to \mathbb Z$$ indexed by compact smooth manifolds $X$ .
The index theorem says that $\text{a-ind}^X = \text{t-ind}^X$ . However in the proof they define an excision property that essentially allows one to define analytical and topological indices for every (non-compact) smooth manifold, basically by using any embedding into a compact manifold. My understanding is that we can write $\text{a-ind}^X = \text{t-ind}^X$ for every (not necessarily compact) manifold $X$ . Have I missed an important point? Is there any reason why the theorem wasn't formulated as this?","['topological-k-theory', 'differential-geometry']"
3643722,Coin Flip Problem: a competition based on the probability of flipping heads,"I encountered a difficult coin problem and I wasn't sure how to solve the problem. A has 30 coins and B has 20 coins. Each coin is only flipped once, and the winner is the individual which received the most amount of heads. If both individuals receive the same amount of heads, A wins. What is the probability that B wins? I tried searching online but was unable to find any questions of this type. Given my lack of mathematical background, I tried to rely on my intuition. Because both individuals have the same probability of flipping heads when it comes to the first 20 choices, we should only consider the possibility of flipping a head for coins 21-30 for A . However, I believe this to be incorrect, so I would love to hear what the community thinks on this question. Thank you very much for your help!","['permutations', 'combinatorics', 'recreational-mathematics', 'problem-solving', 'probability']"
3643727,A changing probability relating to primes,"The probability that a process succeeds at step $t$ is $$\left( \prod_{k=1}^{t-1}{ 1-\text{Prime}(p+k)^{-1/c} } \right)(\text{Prime}(p+t))^{-1/c}$$ Here $p$ , $t$ and $c$ are naturals, and $\text{Prime}(x)$ is simply the $x$ th prime. How many steps, on average, does the proccess take until it succeeds, for a given $p$ and $c$ ? MY ATTEMPTS The first thing I tried was to try to convert the prime in the function to a power of $x$ , hoping that I could test it in my math software and get close to the same asymptotics: $$\prod_{k=1}^{t-1}{ \left(1-(\text{Prime}(p)^{d \cdot k})^{-1/c} \right) }\text{Prime}(p+t)$$ The idea was to approximate $\text{Prime}(p+k)$ with $x^{d \cdot  k}$ for $d \approx 1$ , say $d=1.1$ .  But by my calculations, this wasn't exacting enough.  Perhaps I have to rethink $d$ . That was probably my best attempt so far.  I'm still thinking that maybe we can approximate the prime values with a power of $x$ , or some suitable function.  I'm not sure what else to try.  I feel like I'm way off here. Anyways, the idea seems to be to get the product equal to around $1/2$ , which would be an average number of steps or trials.","['statistics', 'probability', 'prime-numbers']"
3643740,Maximum likelihood estimation of parameter $N$,"Every competitor in a marathon has a unique number on their shirt, from 1 to N. N is unknown. The observation is $n_1, \ldots ,n_K$ , which are randomly sampled from the $N$ competitors with equal probability. What is the MLE for $N$ ? My intuition is that the MLE is simply the maximum observed in that set but how do I prove this? At first I thought this was a multinomial but that doesn't make sense since there is a single observation or there would be K observations without replacement. Is this a categorical distribution? How do I derive the MLE for that?","['statistical-inference', 'statistics', 'parameter-estimation', 'maximum-likelihood', 'multinomial-distribution']"
3643843,"Understanding the simbolization of an ""either or"" in proofs.","In the book "" How to Prove It "", by Velleman, appear these two examples. Prove that for every integer $x$ , the remainder when $x^2$ is divided by 4 is either 0 or 1. Prove that for every real number x, if $x^2 \geq x$ then either $x \leq 0 \lor x \geq 1$ . Symbolization : $x \in \mathbb{Z} \to (x^2 \text{ has remainder } 0) \lor (x^2 \text{ has remainder } 1)$ $\forall x(x^2 \geq x \to (x \leq 0 \lor x \geq 1)$ In both cases, the author symbolises the conclusion with a disjunction. In my mind, the conclusion is an exclusive or . In the first example, if I write a number in the form $k \in \mathbb{Z}$ , that same number can not be written in the form $4l$ for some number $l \in \mathbb{Z}$ .
In the second one, a number being 0 excludes the possiblity of it being greater than or equal to 1. What would be the explanation for this issue, from a logic perspective ? If my perspective is incorrect, how does a proof of an ""exclusive or"" look like ?","['proof-explanation', 'logic', 'discrete-mathematics']"
3643895,Diagonalize matrix multiplication,"Let $V$ be the space of $2\times 2$ matrices with complex coefficients. Let $A \in V$ and let $L_A:V \to V$ , defined by $L_A(X)=A\cdot X$ . I am trying to solve the exercise (10) from this book : find a basis in $V$ such that the $4x4$ matrix of $L_A$ is block diagonal i.e. is of the form $$\left(\begin{array}{cc}
A & 0 \\ 0 & B\end{array}\right).$$ With $A$ and $B$ $2\times 2$ matrices. The linear map $L_A$ is diagonalisable as a map from $\mathbb{C}^4 \to \mathbb{C}^4$ , but I'm not sure how to obtain the required form and besides, the eigenvalues look rather ugly.","['tensor-rank', 'tensors', 'matrices', 'linear-algebra', 'linear-transformations']"
3643917,Limit of a integral $\lim_{x\to 0+} \frac{1}{x^2} \int_{0}^{x} t^{1+t} dt$,Find the limit of $$\lim_{x\to 0+} \frac{1}{x^2} \int_{0}^{x} t^{1+t} dt$$ . My idea to solve it is to use L'Hospital's rule but I am not sure why I can use it and how should i do it. Many thanks to them who are willing to help.,"['integration', 'limits', 'real-analysis']"
3643930,Rouché's Theorem with $h(z)=z^3+8z+23$,"I've asked a similar question to this one, and got a nice answer, but now I am struggling with this one. Rouché's Theorem: If $f(z)$ and $(g(z)$ are analytic on and inside the contour $C$ and $|f(z)|>|g(z)|$ for all $z$ on C, then $f(z)$ and $f(z)+g(z)$ have the same number of zeros. I'm asked to show that $h(z)=z^3+8z+23$ has only one zero inside the contour $C_2(0)=\{z:|z-0|=3\}$ . Here is some visual evidence that this is true. Now, I've tried all kinds of choices for $f(z)$ and $g(z)$ , but none of them have worked. For example, if I let $f(z)=8z+23$ and $g(z)=z^3$ , then I can write $$|f(z)|=|8z+23|\ge||8z|-|23||=1$$ for all $z$ on the contour $C_3(0)$ . However, $$|g(z)|=|z^3|=|z|^3=27$$ for all $z$ on the contour $C_3(0)$ . Thus, I have not shown that $|f(z)|>|g(z)|$ for all $z$ on the contour $C_2(0)$ . Here's another image that shows $|f(z)|$ is not greater that $|g(z)|$ for all $z$ on the contour $C_3(0)$ . So, can someone give me an $f(z)$ and a $g(z)$ such that $|f(z)|>|g(z)|$ for all $z$ on the contour $C_3(0)$ ? And if so, can you share the strategy you used to find them? Thanks.","['complex-analysis', 'rouches-theorem']"
3643955,"Proof that given $p$ prime and $n \in \mathbb{N}$, $n!$ divides $(p^n - 1)(p^n - p)\cdots(p^n - p^{n-1})$.","I was hoping to show this by Lagrange's theorem.
As the general linear group over $\mathbb{F}_p$ (the field with $p$ elements), $\mathrm{GL}_n(\mathbb F_p)$ has order $(p^n - 1)(p^n - p)\cdots(p^n - p^{n-1})$ , we just need to find a subgroup that has an order of $n!$ . We know that $S_n$ ( symmetric group ) has order $n!$ and since it is isomorphic to the set of permutation matrices with matrix multiplication as its operation, we already have or proof constructed. My problem here is that it works for every $p \in \mathbb{N}$ , it is not required for $p$ to be prime. Where am I wrong? Am I wrong?","['symmetric-groups', 'number-theory', 'group-theory', 'general-linear-group']"
3643985,Riemann Surface of $z=\sqrt{w}$,"Today I started learning about Riemann surfaces. In Gamelin's Complex Analysis , Gamelin states that the Riemann surface of $z=\sqrt{w}$ is ""essentially a sphere with two punctures corresponding to $0$ and $\infty$ ."" How is this true? The surface does not look like a sphere to me.","['complex-analysis', 'riemann-surfaces']"
3643991,Qualitative behavior of a seemingly simple ODE,"In case you're curious about context---there isn't one.  I am thinking about this out-of-the-blue because it is mysterious and interesting. Let $ a, p, q, y_0 $ be positive constants.  Consider the ordinary differential equation in $ y = y(x) $ , $$ y' = y^p - a x^q, y(0) = y_0$$ Let us only consider the behavior of the solution for $ x \geq 0 $ and $ y(x) \geq 0 $ .  Depending on the constants, the solution will either go to infinity, or go to zero (we consider the solution undefined after $ y(x) < 0 $ ).  This is obvious on inspection, but in case it's not obvious to you, I recommend you plot some numerical solutions for $ p = 2, q = 3, a = 1 $ . $ p = 2, q = 3, a = 1 $ ""> I am investigating the conditions under which this solution escapes to infinity.  I am not aware of any closed-form solutions for this ODE.  I'd like to understand the boundary between solutions that are escaping to infinity and those that are going to zero (it's not hard to show that there's no other possibility). I don't know of many tools here.  From my undergrad ODEs, I am vaguely familiar with a Lyapunov method.  Viz., we might try to define a function $ F = F(x,y) $ satisfying some inequality like $$
(*) \frac{d}{dx} \left[ F(x, y(x)) \right] \geq 0
$$ Such functions, if chosen well, may allow us to put certain upper envelopes on solutions that go to zero, and put lower envelopes on solutions that go to infinity.  In the following discussion, always assume $ x \geq 0, y \geq 0 $ . For instance, if we try $ F(x,y) = y^{r_1}(y^{r_2} + b x^{r_3}) $ for some appropriate (positive) constants $ b, r_1, r_2, r_3 $ , we have $ F = 0 $ only if $ y = 0 $ .  If we can additionally show that $ (*) $ holds, then we produce a lower-envelope for solutions that escape to infinity.  There is some hope that this might work.  Indeed, we have $$
\frac{d}{dx}\left[ F(x, y(x)) \right] = \frac{\partial F}{\partial x} + \frac{\partial F}{\partial y} y' = \frac{\partial F}{\partial x} + \frac{\partial F}{\partial y} (y^p - a x^q)
$$ It seems like some wizardry with the arithmetic-geometric inequality and good choice of constants can allow one to make this non-negative.  Can anyone help?","['inequality', 'ordinary-differential-equations', 'lyapunov-functions']"
3644049,Proof that $\sum_{n=0}^{\infty}(-1)^{n} = \frac{1}{2}$. Is there any error?,"So, I proved that: $$\int f(\ln x)\ dx = x \sum_{n=0}^{\infty}(-1)^{n} f^{(n)}(\ln x) \ \ \ +\ \ C$$ where $f^{(n)}$ is the nth derivative of $f$ . if we let $f(x) = e^{x}$ then $f^{(n)}(x) = e^x$ as well, so: $$\int e^{\ln x}\ dx = x \sum_{n=0}^{\infty}(-1)^{n} e^{\ln x} \ \ \ +\ \ C$$ giving us: $$\int x\ dx = x^{2} \sum_{n=0}^{\infty}(-1)^{n} \ \ \ +\ \ C$$ if we differentiate both sides with respect to $x$ we end up with: $$x=2x \sum_{n=0}^{\infty}(-1)^{n}$$ giving us: $$\sum_{n=0}^{\infty}(-1)^{n} = \frac{1}{2}$$ Am I doing something wrong or is this valid? Because I've learned that that series is divergent, yet through this method I've proven it to be $\frac{1}{2}$ wich is also its Cesàro sum.","['paradoxes', 'cesaro-summable', 'sequences-and-series']"
3644059,When are $GL_n$ and $GL_m$ equivalent... in characteristic 2?,"For fields $K$ and $L$ , I am interested in proving that "" $GL_n(K)$ and $GL_m(L)$ are isomorphic (as groups) if and only if $m=n$ and $K\simeq L$ "". I don't know how generally this is true, but: assume $K=L$ . In that case, if $char(K) \neq 2$ then there is a usual proof that $n=m$ by looking at the group of involutions of each, that yields $2^m = 2^n$ and this the result. if $char(K) = 2$ , I do not find any proof of this fact. is there a stronger result without supposing $K = L$ ? Can we at least conclude that $char(K) = char(L)$ ?","['general-linear-group', 'group-theory', 'linear-algebra']"
3644105,Basis-free definition of derivative of polynomial functions on a vector space,"Let $V$ be a finite dimensional vector space over an infinite field $k$ . The ring of polynomial functions on $V$ is the subalgebra of the $k$ -algebra of all functions $V\to k$ generated by the dual space $V^*$ , and is denoted by $k[V]$ . Let $(e_1,\dots,e_n)$ be an ordered basis of $V$ and let $(f_1,\dots,f_n)$ be its dual basis, then an element of $k[V]$ is a polynomial in $f_1,\dots,f_n$ . We can then define a (formal) derivative as follows: First, fix $i\in\{1,\dots,n\}$ and define $$
\partial_{e_i}(f_1^{r_1}\cdots f_{i-1}^{r_{i-1}}f_i^{r_i}f_{i+1}^{r_{i+1}}\cdots f_n^{r_n}) = r_i f_1^{r_1}\cdots f_{i-1}^{r_{i-1}}f_i^{r_i-1}f_{i+1}^{r_{i+1}}\cdots f_n^{r_n},
$$ for all $r_1,\dots,r_n\in \mathbb{Z}_{\geq 0}$ . Extending by linearity we obtain a well defined derivation $\partial_{e_i}:k[V]\to k[V]$ . Then for $v\in V$ , write $$
v = \sum_{i=1}^n a_i e_i, \qquad a_1,\dots,a_n\in k
$$ and define $$
\partial_v(f) = \sum_{i=1}^n a_i \partial_{e_i}(f), \qquad \forall f\in k[V].
$$ When we take $V=k^n$ and $(e_1,\dots,e_n)$ as the canonical ordered basis, the $i$ -th vector in the dual basis is the coordinate function $x_i:k^n\to k$ given by $x_i(a_1,\dots,a_n) = a_i$ , and $k[V]$ is precisely the polynomial ring $k[x_1,\dots,x_n]$ and the derivation $\partial_v$ coincides with the known formal directional derivative on that polynomial ring. The main issue with this definition is that it depends on the chosen basis $(e_1,\dots,e_n)$ . I would like to know if there is a basis-free definition of the derivative $\partial_v$ for a ring of polynomial functions $k[V]$ on a finite dimensional vector space $V$ over an infinite field $k$ .","['derivatives', 'abstract-algebra', 'linear-algebra', 'polynomials']"
3644119,Finding conditions for $\lim\limits_{n\to\infty}\sum\limits_{k=0}^{\lfloor\frac1{a_n}\rfloor}(-1)^k\binom nk(1-ka_n)^{n-1}=1$,Question: Find necessary and sufficient condition on the sequence $(a_n)_{n=1}^∞$ so that $$\lim_{n→∞}\sum_{k=0}^{\lfloor\frac1{a_n}\rfloor}(-1)^k\binom nk(1-ka_n)^{n-1}=1\tag 1$$ given that $\lim\limits_{n\to\infty}a_n=0$ and $a_n\gt 0$ for all $n\in\Bbb{N}$ . After some guesswork I got to a condition that if $\sum\limits_{n\ge 1} a_n=\infty$ then eq.(1) holds. But I was not able to prove it neither could I find a counterexample for the conjecture. Searching on internet I found that this sum is very closely related to a special case of Dvoretzky covering problem but still couldn't find the necessary and sufficient condition. Until now I have tried using approximations for the Binomial Coefficient and binomial approximation to tackle the sum to no avail. I would be glad if someone could help. Edit: I have got a counterexample for my conjecture i.e. $\sum\limits_{n\ge 1} a_n=\infty$ is alone not sufficient for eq.(1) to hold. So what should be the necessary and sufficient condition?,"['limits', 'sequences-and-series', 'probability', 'real-analysis']"
3644141,If $\int_x^{x+T}f(t)dt=C$ then $f$ is periodic,"If $f$ is a continious function from $\mathbb{R}$ to $\mathbb{R}$ and
  there exists $C$ such that: $\forall x\in\mathbb{R} :\int_x^{x+T}f(t)dt=C$ then $f$ is $T$ -periodic. Proving the inverse is easier and has already been answer on another question.","['integration', 'periodic-functions', 'functions']"
3644186,Under what conditions can an operator be moved under the integral,Let $\mathcal{H}$ be a Hilbert space and suppose $G=\{U(\alpha) \}_{\alpha \in \mathbb{R}} $ is one parameter group of linear bounded maps $U(\alpha):\mathcal{H}\to \mathcal{H}$ under composition such that $U(0)=Id $ . Now suppose that for a fixed $\psi\in \mathcal{H}$ we define $A_\psi:\mathbb{R}\to \mathcal{H}$ as $$\tau \mapsto \int_0^\tau U(\alpha)\psi  \;d\alpha $$ My question is: Under what conditions does the following equation holds? for any $\epsilon\in \mathbb{R}$ $$\bigr(U(\epsilon )\circ A_{\psi}\bigr)(\tau)= \int_0^\tau U(\epsilon)\cdot U(\alpha)\psi\; d\alpha $$ Here I used the notation $U(\epsilon)\cdot U(\alpha)\psi\equiv \bigr(U(\epsilon) \circ U(\alpha)\bigr)(\psi)$,"['integration', 'operator-theory', 'hilbert-spaces']"
3644200,Can the expected value be applied to non-linear functions?,"I'm doing a research project about the bias of different methods of integral estimation.  One of these methods involves the following math: $$ E\left[\sum_{i=1}^nf(x_i)\right] = \sum_{i=1}^nf(E[x_i])$$ for $ x_1, x_2,\ldots, x_n \sim G$ are i.i.d where $G$ is some probability distribution function. Does this math only hold when f is a linear function? Does it never hold? Does it always hold?","['expected-value', 'statistics']"
3644316,If $f : \mathbb R \rightarrow \mathbb R $ such that $f(x^2+x)+2f(x^2-3x+2) = 9x^2-15x$. Find $f(2016)$.,"Determine all $f : \mathbb R \rightarrow \mathbb R $ such that $$f(x^2+x)+2f(x^2-3x+2) = 9x^2-15x$$ for all $x$ . Find $f(2016)$ . Similar problem appeared on this site before: $f(x^2 + x)+2f(x^2 - 3x + 2)=9x^2 - 15x$ then find $f(2016)$ . (The question is now deleted.) The same problem with finding $2011$ (instead of $2016$ ) appeared in 2011 Singapore Mathematical Olympiad as problem 17 ( Wayback Machine ). I’ve tried put $x=0,1$ and got \begin{align*}
f(0)+2f(2)&=0\\
f(2)+2f(0)&=-6
\end{align*} which gives me $f(0)=-4$ , $f(2)=2$ . Similarly, if we notice that $x^2+x=x^2-3x+2$ holds for $x=\frac12$ , we can find the value at the point $\frac34=\left(\frac12\right)^2+\frac12$ . But the above doesn’t seem to help for other values. Thank you very much for helping.","['contest-math', 'functional-equations', 'functions', 'polynomials', 'algebra-precalculus']"
3644325,Extreme points in the intersection of hyperplanes and hypercube,"Let $A$ be any $c \times n$ matrix such that $c < n$ and let $b$ be any $c\times 1$ vector. It is also known that $A$ and $b$ are element-wise positive. Consider the set defined as \begin{align}
\mathcal{S}=\{x~|~Ax\leq b~,~x\in[0,1]^n\}
\end{align} where $[0,1]^n$ is the standard hypercube. If $\mathcal{S}$ is non-empty with at least two points, it is easy to see that $\mathcal{S}$ is a closed convex set. I am interested in the extreme points of $\mathcal{S}$ . Extreme points are the points which can never be contained inside a non-degenerate line in $\mathcal{S}$ (can be thought of as corners). Another way to say is, they can never be written as convex-combinations of two other points in $\mathcal{S}$ . Is the following statement true? Question: if $e$ is an extreme point of $\mathcal{S}$ , the number of components in vector $e$ such that $0<e_i<1$ is upper-bounded by $c$ .","['convex-optimization', 'linear-programming', 'matrices', 'linear-algebra', 'convex-analysis']"
3644337,$ E [E (Y\mid\mathcal{G_2}) 1_A ] = E (Y 1_A )$,"IF $Y \in \mathcal{L^1}  (\Omega, \mathcal{F}, \Bbb{P})$ and $\mathcal{G_1}  , \mathcal{G_2} ,\mathcal{G_3} $ are $\sigma $ fields in $\mathcal{F} $ If we assume that $Y$ is $\mathcal{G_1}$ measurable and $\mathcal{G_3}    $ is independent of $\mathcal{G_1}\bigvee\mathcal{G_2}$ . How can we prove that $ E [E (Y\mid\mathcal{G_2}) 1_A ] = E (Y  1_A )$ for every $A$ formed as $A= B \cap C$ , $B \in \mathcal{G_2}  $ , $ C \in \mathcal{G_3}  $ . And  then extend this to $\mathcal{G_2}\bigvee\mathcal{G_3}$ ( by using Dynkin's $π - λ $ theorem). I found a similar exercise but I was unable to prove this problem .","['conditional-expectation', 'self-learning', 'measure-theory', 'probability-theory']"
3644369,inequality for positive contraction operator,"Let $H$ be a Hilbert space, let $A\in B(H)$ satify $\|A\|\le 1$ . If $A$ is positive, i.e. $A$ is a self-adjoint operator and for all $x\in H$ , $\langle A(x),x\rangle\ge 0$ , proof that $${\|x-A(x)\|}^2\le {\|x\|}^2-{\|A(x)\|}^2, \forall x\in H.$$ This is a exercise. For $A$ is positive \begin{align*}
{\|x-A(x)\|}^2
&={\|x\|}^2+{\|A(x)\|}^2-\langle A(x),x\rangle-\langle x,A(x)\rangle\\
&={\|x\|}^2-{\|A(x)\|}^2+2{\|A(x)\|}^2-2\langle x,A(x)\rangle
\end{align*} so we should prove that $${\|A(x)\|}^2\le \langle x,A(x)\rangle$$ or $${\|A(x)\|}^2=\langle A(x),A(x)\rangle = \langle x,A(A(x))\rangle \le \langle x,A(x)\rangle$$ but i don't know how to use the condition "" $\|A\|\le 1$ "" and "" $\langle A(x),x\rangle\ge 0$ "".","['operator-theory', 'self-adjoint-operators', 'hilbert-spaces', 'functional-analysis', 'inequality']"
3644408,Trigonometry problem - Heights and Distances,"The angle of elevation of the top of a vertical tower from a point A, due east of it is 45 degrees. The angle of elevation of the top of the same tower from a point B, due south of A is 30 degrees. If the distance between A and B is $54\sqrt{2} m$ , then the height of the tower(in metres), is? Answer given : $54 m$ . They have proceeded by doing $\tan 30 =\frac{h}{OB}$ . And upon finding $OB$ , they use Pythagoras theorem to find the value of $h$ . How are they doing $\tan 30 =\frac{h}{OB}$ to begin with? If that occurs, should $\sin 30 = \frac{h}{BC}$ ? Shouldn't angle COB be 90 degrees in order to do that(But clearly it's greater than 90 degrees)?","['trigonometry', 'geometry']"
3644449,How is the dominated convergence theorem applied here?,"Let $(E,\mathcal E,\mu)$ be a probaiblity space and $A_n,B$ be linear contractions (operator norm at most $1$ ) on $L^p(\mu)$ for all $p\in[1,\infty]$ . Say we know that $$\left\|(A_n-B)f\right\|_{L^2}\xrightarrow{n\to\infty}0\tag1\;\;\;\text{for all }f\in\mathcal L^2(\mu).$$ I need help to understand the following argument which aims to conclude $$\left\|(A_n-B)f\right\|_{L^p}\xrightarrow{n\to\infty}0\tag2\;\;\;\text{for all }f\in\mathcal L^p(\mu)$$ for all $p\in[1,\infty]$ from $(1)$ : If $f\in\mathcal L^\infty(\mu)$ , then (since $A_n$ is a contraction) $(A_nf)_{n\in\mathbb N}$ is bounded in $L^\infty(\mu)$ which means that it is uniformly bounded $\mu$ -almost surely. Now I've read that $\left\|(A_n-B)f\right\|_{L^p}\to0$ follows from $(1)$ and the dominated convergence theorem. I don't get that. Clearly, $(A_nf)_{n\in\mathbb N}$ is uniformly bounded a.s. and hence trivially dominated by a $L^p$ -integrable function for all $p\in[1,\infty]$ . However, I don't get how we can utilize $(1)$ now. For the dominated convergence theorem we would need a.s. pointwise convergence of $A_nf$ to $Bf$ (so, for example, $A_nf\to Bf$ in $L^\infty$ ) ... (If this could be shown, then the extension to all $f\in L^p$ would be easy, since the elementary functions (which are in $L^\infty$ ) are dense in $L^p$ for all $p\in[1,\infty]$ .)","['measure-theory', 'lp-spaces', 'probability-theory']"
3644468,What is a relation in plain simple English?,"Can someone explain in simple English what a relation is? I found this definition: A relation between two sets is a collection of ordered pairs containing one object from each set. If the object x
x
 is from the first set and the object y
y
 is from the second set, then the objects are said to be related if the ordered pair (x,y)
(
x
,
y
)
 is in the relation. But I feel as though it is not intuitive","['elementary-set-theory', 'functions', 'relations']"
3644481,"Line Integral $\int_{\gamma} \frac{y}{\sqrt{x^2+y^2}}ds \qquad \qquad \gamma(t)\colon t\mapsto(\cos^3t,3\cos^2t\sin t)$ as $t \in (a,b)$","Hey there, I'm asked to find $$\int_{\gamma} \frac{y}{\sqrt{x^2+y^2}}ds \qquad \qquad \gamma(t)\colon t\mapsto(\cos^3t,3\cos^2t\sin t)$$ as $t \in (a,b)$ .
As we have regularity both in the field and in the curve, we can easily apply the standard formula: $$\int_{\gamma} \frac{y}{\sqrt{x^2+y^2}}ds = \int_a^bF(\gamma(t)) ||\gamma'(t)||dt$$ but this leads to terrible computations.
Is there anything smart I can do? Can I do something smart to simplify my operations when I'm going (like in this case) over a curve which is of the kind $t \mapsto (f(t),kf'(t))$ where $k$ is a constant?","['integration', 'multivariable-calculus', 'calculus', 'curves']"
3644484,Curious limit of a sequence used to prove Etemadi's SLLN,"I've been struggling with the proof of this proposition: Let $\{x_{n}\}_{n=1}^{\infty}$ be a sequence of non-negative real numbers. If $$\lim_{n\to\infty} \frac{1}{\left\lceil{r^n}\right\rceil}\sum\limits_{i=1}^{\lceil{r^n}\rceil}x_{i} = c$$ for all $r >1$ with $r\in \mathbb{R}$ ,
  then $$\lim_{n\to\infty} \frac{1}{n}\sum\limits_{i=1}^{n}x_{i} = c.$$ I 've been researching and looking for possible fancy properties of the ceiling function that could be suitable for this proof, but all my efforts have been in vain. If you could help me out I'd be very grateful. Observation: $\lceil{x}\rceil$ is the smallest integer $m$ such that $x \leq m$ , where $x\in\Bbb R$ . Further context(taken from comment): I think this lemma/proposition is used to prove Strong Law of Large Numbers of Etemadi (1981); it can be checked between pages 55-57 of Durret's Probability: Theory and Examples (above all in page 57) but I can't write the complete formal proof of this lemma used there.","['ceiling-and-floor-functions', 'real-analysis', 'sequences-and-series', 'limits', 'probability-theory']"
3644527,"Let $f : \mathbb R \rightarrow \mathbb R$ satisfy $f(x) \le x$ and $f(x+y) \le f(x)+f(y)$ for all $x,y \in \mathbb R$. Show that $f(x)=x$.","Let $f : \mathbb R \rightarrow \mathbb R$ satisfy $$f(x) \le x$$ and $$f(x+y) \le f(x)+f(y)$$ for all $x,y \in \mathbb R$ . Show that $f(x)=x$ . I already know that $f(0) = 0$ but I don’t know how to do next. Thank you very much for helping!","['contest-math', 'functional-equations', 'functional-inequalities', 'functions', 'algebra-precalculus']"
3644560,Product of a symmetric and anti-symmetric matrix,"I have the following question about matrices,
Let $S$ and $A$ be two $n \times n$ matrices which are respectively symmetric and anti-symmetric. Can I conclude anything about the products $SA$ or $AS$ , are they symmetric or anti-symmetric? This is part of a bigger problem where I have already shown, $$ \langle x, Ax \rangle = 0$$ For $A$ antisymmetric, but I require that $$ \langle Mx, Ax \rangle = 0$$ For some matrix M, what conditions could I impose on $M$ to satisfy this, I was hoping symmetry would be sufficient or do I require something stronger such as diagonality?","['inner-products', 'matrices', 'linear-algebra', 'symmetric-matrices', 'skew-symmetric-matrices']"
3644568,"Socle, the subgroup generated by the minimal subgroups","Edit : It may be a little opinion-based, so I’ve posted it on MathOverflow : The importance/use of socle in the theory of finite groups . ——————————————————————— Actually, I’m new here and not quite sure whether I should post this question on this site. If you think it is more suitable for MathOverflow, please tell me and I will delete this post. Definition. The socle of a group $G$ , denoted ${\rm Soc}(G)$ , is the subgroup generated by the minimal normal subgroups of $G$ . Here we only discuss it in the theory of finite groups. I know some basic facts. ${\rm Soc}(G)$ is the direct product of some of the minimal normal subgroups of $G$ . ${\rm Soc}(G)$ is semisimple. ${\rm Soc}(H\times K)={\rm Soc}(H)\times {\rm Soc}(K)$ . ${\rm Soc}({\rm Soc}(G))={\rm Soc}(G)$ . If $G$ is nilpotent, then ${\rm Soc}(G)$ is central and hence abelian. •••••• I can find the definition of socle in many, though not all, of the text books, but always not much is discussed about it. They don’t seem to attach much importance to the concept of socle . I think the concept of socle is important, because it is literally the “socle”, the plinth, of a group. So my question is : How is this concept used in the theory of finite groups? I’m a beginner and I want to know if there is any important use of the concept of solcle . I’m interested in it. Is there any theorem or article or book that you think I should know and read about it? Any comment or answer is welcome. Any help is sincerely appreciated. Thanks!","['finite-groups', 'reference-request', 'normal-subgroups', 'abstract-algebra', 'group-theory']"
3644588,Why isn't torsion the magnitude of the derivative of the binormal vector?,"I am learning about the $TNB$ , curvature and torsion and I found this weird derivation about torsion: $$\tau=-B'(s)\cdot \hat{N}(s).$$ And the explaination I got basically is that since $$|\hat{B}(s)|=1,$$ then $$B'(s)\perp \hat{B}(s).$$ Also using some algebraic manipulation you get that $$\hat{T}(s)\perp B'(s).$$ Therefore $B'(s)$ must be parallel to the normal vector $\hat{N}(s)$ since it's perpendicular to both $B$ and $T$ . So you could say that $B'(s)$ is some constant $\tau$ multiplied by $\hat{N}$ , and that's how you get to the first formula. So the question is, why is it done this way? Isn't it posible to say ""torsion is the speed of change of the binormal vector"", write it down as $\tau=|B'(t)|$ ? Am I missing something? Is there a historic or practical reason why it's defined this way? It just seemed very counterintuitive.","['multivariable-calculus', 'vectors', 'differential-geometry']"
3644632,Are 4x4 matrices useful in 3D only because of translation?,"Having interest in 3D computer graphics, I've stumbled upon four dimensional matrices. After a bit of research, I've found out that this was a trick to represent translations, but no more than a trick, which doesn't seem very satisfaying, because of the fourth components of any vector always being one. Is there any other more fundamental reason for the use of a 4D matrix in 3D? I'm not asking particularly in the context of computer graphics since this is a math forum.","['linear-algebra', 'geometry', '3d']"
3644723,Continuity of Markov chain' trasnition matrix functions,"I'm studying Continuous-time Markov chains . Given the definition of continous-time transition functions matrix : $P(t) = (P\small{ij}(t)) = \mathbb{P}(X\small{t} = j | X\small{0} = i)$ So I have two questions related to continuity of this functions: Can there be transitional functions which are non-continous? Can there be transitional functions which are continuous, but non-differentiable?","['markov-chains', 'continuity', 'calculus', 'derivatives', 'probability-theory']"
3644745,Trying to understand a proof of the Maximal ergodic theorem,"Let $(\Omega,\mathfrak A,P)$ be a probability space, $\Theta:\Omega\to\Omega$ be $(\mathfrak A,\mathfrak A)$ -measurable with $P=P\circ\Theta^{-1}$ and $$A_n:=\frac1n\sum_{i=0}^{n-1}F\circ\Theta^i\;\;\;\text{for }F\in\mathcal L^1(P).$$ Let $F\in\mathcal L^1(P)$ . I'm trying to understand the following proof of the Maximal ergodic theorem, $$\operatorname E\left[F;\max_{1\le i\le n}A_iF\ge0\right]\ge0\tag1$$ for all $n\in\mathbb N$ : First of all, shouldn't $$M_{n-1}\circ\Theta=M_n-F\tag2$$ hold everywhere (not only on $B$ )? And what's the point of taking the positive part $x^+:=\max(x,0)$ ? It should clearly hold $$X=M_n-M_{n-1}\circ\Theta\ge M_n-M_n\circ\Theta\tag3,$$ since $M_n$ is (pointwisely) a maximum over a greater set than the set over which the maximum in $M_{n-1}$ is taken ... What am I missing?","['measure-theory', 'ergodic-theory', 'probability-theory', 'dynamical-systems']"
3644777,Triple integral evaluation problem,"I am asked to evaluate the triple integral, $$\iiint_E (12x^2-2yx-5) \ dV$$ Where $E$ is the region enclosed by the surfaces $$z=x^2-1, \ z=1-x^2, \ y=0, \ y=2$$ Am I right in saying that we can define the region; $$E=\{(x,y,z)\ | \ -1\leq x\leq 1, \ 0\leq y \leq 2, \ x^2-1\leq z \leq1-x^2\}$$","['integration', 'multivariable-calculus', 'calculus', 'definite-integrals']"
3644797,Doubling Point Formula of Elliptic Curve is Not Working,"Let $E$ be an elliptic curve and a point $P = (x, y) \in E,$ from the duplication formula, the x-coordinate of $2P$ is - $$x_{(2P)}=(x^4-b_4*x^2-2*b_6*x-b_8)/(4*x^3+b_2*x^2+2*b_4*x+b_6)$$ The formula is given  on page $54$ in book The Arithmetic of Elliptic Curves by Joseph H. Silverman. but when I write a python program, and try an example it does not work! I tried the  below example - $$E:= y^2 = x^3 − 25x, P = (−4, 6),  2P = (\frac{1681}{ 144},\frac{ −62279}{ 1728} ) $$ I used the below python code - a_0=0; a_1=0; a_2=0; a_3=0;
a_4=-25; a_6=0;
P=(-4,6)
b_2=a_1**2+4*a_4; 
b_4=2*a_4+a_1*a_3; 
b_6=a_3**2+4*a_6; 
b_8=(a_1**2)*a_6+4*a_2*a_6- a_1*a_3*a_4+a_2*a_3**2-a_4**2;

x_2p=(x**4-b_4*x**2-2*b_6*x-b_8)/(4*x**3+b_2*x**2+2*b_4*x+b_6) My output is - x_2p= -1.154532967032967 But it should be - x_2p= 11.6736111111=  = 1681/144 Why it is not working?","['python', 'programming', 'algebraic-geometry', 'elliptic-curves']"
3644802,Correspondence between $k$-ary Lyndon words and $(k-1)$-ary Lyndon words without repetitions,"At Counting Lyndon words with no adjacent character repeats , it turned out that for $n\ge3$ the number of $k$ -ary Lyndon words of length $n$ without adjacent identical letters is the number of $(k-1)$ -ary Lyndon words of length $n$ . I suspect there should be an elegant combinatorial proof of this. Without the aperiodicity constraint of the Lyndon words, the number of circular arrangements of $n$ letters from an alphabet of size $k$ without adjacent identical letters is $$
(k-1)^n+(-1)^n(k-1)\;.
$$ It’s not surprising that this is roughly $(k-1)^n$ , since as you go around the circle, you can choose each letter freely except it can’t be the same as the previous one. What is surprising (to me), though, is that the boundary effect when you get back to the origin doesn’t quite cancel for unconstrained circular arrangements (leaving the term $(-1)^n(k-1)$ ), but does cancel exactly for aperiodic ones. In the algebraic derivation of the result, this happens because the Dirichlet convolution of $(-1)^n$ with the Möbius function is zero except at $n=2$ ; but I don’t know what that corresponds to combinatorially. One idea I had was to use the fact that a Lyndon word is lexicographically minimal among its rotations, which means that an aperiodic Lyndon word can’t start and end with the same letter (since otherwise you could rotate the last letter to the front, contradicting minimality). This could somehow make the boundary condition work out right when you look at the choices letter by letter. Another approach I tried was to treat the letters as residues modulo $k$ and consider the differences between neighbours instead of the values themselves. Then the constraint is that no difference must be $0$ , and the differences must add up to $0$ . Each admissible arrangement of differences corresponds to $k$ arrangements of letters. But I don’t see how to make that work, either. My questions are: Is there a natural bijection between the $k$ -ary Lyndon words of length $n$ without adjacent identical letters and the $(k-1)$ -ary Lyndon words of length $n$ ? Or is there some other combinatorial argument why there should be the same number of each?","['lyndon-words', 'inclusion-exclusion', 'combinatorics', 'mobius-inversion', 'necklace-and-bracelets']"
3644822,Why is the oldform map injective?,"Consider the space of cusp forms $S_k(\Gamma_0(N))$ ; it has two different maps to $S_k(\Gamma_0(Np))$ where $(p, N) = 1$ . We can combine them into a map $$S_k(\Gamma_0(N)) \oplus S_k (\Gamma_0(N)) \to S_k(\Gamma_0(Np))$$ given explicitly by $$(f_1, f_2) \mapsto f_1 + f_2 |_k \begin{pmatrix} p & 0 \newline 0 & 1 \end{pmatrix}.$$ I think I've seen it asserted that this map is injective; why? Here's what I've tried so far. If we define $\pi = \begin{pmatrix} p & 0 \newline 0 & 1\end{pmatrix}$ , then an element of the kernel would have to be of the form $(f|_k \pi, -f).$ So somehow if $f|_k \pi$ is still $\Gamma_0(N)$ -invariant, it should have to be trivial. From an adelic perspective, $f\in S_k(\Gamma_0(N))$ is a function on $GL_2(\mathbb{A}_f)$ that satisfies some transformation properties; in particular, it's constant on the compact open $U$ corresponding to $\Gamma_0(N)$ . If $f|_k \pi $ is still constant on $U$ , then $f$ is constant on both $\pi U \pi^{-1}$ and $U$ . I believe that I could conclude if those two compact opens (plus images of $GL_2(\mathbb{Q})$ ) together generated all of $GL_2(\mathbb{A}_f)$ . Do they? Or is there a different reason that $f$ must be trivial?","['number-theory', 'automorphic-forms', 'modular-forms', 'adeles']"
3644863,"Fair ten-sided die (with numbers {1, 2, ... 10}) rolled five times - probability that you get a strictly increasing sequence of five numbers?","My initial instinct was to split the possible configurations of five values into cases; i.e. examine the case in which the sequence of five values starts with a ""1"", starts with a ""2"", ... starts with 
""5"". However, I quickly realized that there were subcases for some of these cases (if my sequence of five values starts with ""1"", I must think about the cases where it starts with ""12"", ""13"", ... ""17"" and discard the cases where it starts with ""18"", ""19"", ""1 10"", as it is impossible to form a strictly increasing sequence of five numbers with those starting numbers). Additionally, even amongst the cases where the sequence starts with ""12"", ""13"", ... ""17"", I must discard the cases that have ""129"", ""139"", ... ""179"". Using this logic, I know I could eventually sum up all the possible configurations of five strictly increasing values and divide that by the total number of outcomes to get the probability; however, this method seems very time-consuming. Is there a better way I could approach this problem?","['combinatorics', 'probability']"
3644869,In how many different ways can you prove that $\sin^2x + \cos^2x = 1$,"The standard proof of the identity $\sin^2x + \cos^2x = 1$ (the one that is taught in schools) is as follows: from pythagoras theorem, we have (where $h$ is hypotenuse, $b$ is base and $p$ is perpendicular) $$h^2 = p^2 + b^2$$ dividing by $h^2$ on both sides: $$1 = \frac{p^2}{h^2}+\frac{b^2}{h^2}$$ since $\sin x = \frac ph$ and $\cos x = \frac bh$ , $$1 = \sin^2x+\cos^2x$$ Are there any more innovative ways of proving this common identity?","['alternative-proof', 'trigonometry']"
3644892,Surjectivity of homomorphism from decomposition subgroup to Galois group of residue field extension,"For any Galois extension $L/K$ of algebraic number fields with rings of integers $\mathcal{O}_L$ and $\mathcal{O}_K$ , any prime $\mathfrak{p} \subset \mathcal{O}_K$ , and any prime $\mathfrak{P} \subset \mathcal{O}_L$ above $\mathfrak{p}$ , one can define the decomposition subgroup of $\mathfrak{P}$ as: $$
D_{\mathfrak{P}}:=\{\varphi \in \textrm{Gal}(E/K) \mid \varphi(\mathfrak{P}) \},
$$ and Galois group of the corresponding residue field extension: $$
\textrm{Gal}((\mathcal{O}_L/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p})).
$$ One can then define a homomorphism: $$D_{\mathfrak{P}} \to \textrm{Gal}((\mathcal{O}_L/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p})) \qquad \textrm{given by} \qquad \varphi \mapsto \widehat{\varphi},
$$ where $\widehat{\varphi}: \mathcal{O}_L/\mathfrak{P}  \to \mathcal{O}_L/\mathfrak{P}$ is given by $\widehat{\varphi}(x\ (\textrm{mod}\ \mathfrak{P})) := \varphi(x)\ (\textrm{mod}\ \mathfrak{P})$ for all $x \in \mathcal{O}_L$ . Showing that this map is well-defined and that it constitutes a homomorphism is simply a matter of routine checking. However: It is said that the map is also surjective . I have been trying to prove this. We want to show that every $(\mathcal{O}_K/\mathfrak{p})$ -automorphism in $\textrm{Gal}((\mathcal{O}_L/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p}))$ is of the form $x\ (\textrm{mod}\ \mathfrak{P}) \mapsto \sigma(x)\ (\textrm{mod}\ \mathfrak{P})$ , but I cannot seem to see why this should be so. I have been trying to follow the proof given in chapter I, §9, p. 56 (proposition 9.6) of Algebraic Number Theory by J. Neukirch, but he proves it for the (more general) Dedekind domains, which seems to complicate matters. Does anyone know an elegant proof of the surjectivity of the above homomorphism, or a reference to other textbook proofs? Many thanks.","['algebraic-number-theory', 'number-theory', 'galois-theory', 'abstract-algebra', 'group-theory']"
3644895,Conditions for a.s convergence of a gamma series,"Let $(X_n)$ be a sequence of independent random variable, $X_n$ having the gamma distribution, $$f_{X_n}(x)=\frac{\alpha_n^{p_n}}{\Gamma(p_n)}e^{-x\alpha_n}x^{p_n-1}1_{[0,+\infty[}(x).$$ Find necessary and sufficient conditions on $(\alpha_n)_n,(p_n)_n,$ so that $\sum_nX_n$ converges a.s. Supposing that $\sum_n\frac{p_n}{\alpha_n}<+\infty$ and $\sum_n\frac{p_n}{\alpha_n^2}<+\infty,$ and since $\sum_n{Var(X_n-E[X_n]})<+\infty$ and $\sum_nX_n=\sum_n(X_n-E[X_n])+\sum_nE[X_n],$ this means that $\sum_nX_n$ converges a.s. For the converse, I think the easiest way to do it is to use the 3 series theorem, which means we have to find conditions, so that the series $$\sum_n\frac{\alpha_n^{p_n}}{\Gamma(p_n)}\int_{1}^{+\infty}e^{-x\alpha_n}x^{p_n-1}dx=\sum_n1-\frac{\alpha_n^{p_n}}{\Gamma(p_n)}\int_0^1e^{-x\alpha_n}x^{p_n-1}dx,$$ $$\sum_{n}\frac{\alpha_n^{p_n}}{\Gamma(p_n)}\int_{0}^1e^{-x\alpha_n}x^{p_n}dx=\sum_n\frac{\alpha_n^{p_n-1}}{\Gamma(p_n)}(p_n\int_{0}^{1}e^{-x\alpha_n}x^{p_n-1}dx-e^{-\alpha_n})$$ must converge, and here I am stuck, how to continue, using this facts.","['probability-limit-theorems', 'probability-theory', 'sequences-and-series']"
3644982,matrix exponential change of variables,"Consider an integral over the space $P_n$ of symmetric positive definite $n \times n$ matrices, $$
I = \int_{P_n} f(X) \, (\det X)^{-\frac{n+1}{2}} \, dX \;,
$$ where $dX = \prod_{i\le j} dx_{ij}$ and $dx_{ij}$ is the usual Lebesgue measure over $\mathbb{R}$ . It makes intuitive sense that there is a change of variables $X = \exp Y$ using the matrix exponential so that the integration can be carried out over the space $S_n$ of symmetric $n \times n$ matrices instead, $$
I = \int_{S_n} f(\exp Y) \, dY \;.
$$ Is this true? Edit: This was my approach. I believe the first integral can be written in terms of the eigendecomposition $X = R\Lambda R^T$ as $$
I = c_n \int\limits_{{\rm O}(n)} \, \int\limits_{\mathbb{R}^n_+} \! f(R\Lambda R^T) \, (\det \Lambda)^{-\frac{n+1}{2}} \, \prod_{i<j} |\lambda_i - \lambda_j| \, d\Lambda \, dR \;,
$$ with $c_n$ a constant, $d\Lambda = \prod_{i=1}^{n} d\lambda_i$ , and $dR$ the Haar measure on ${\rm O}(n)$ . The change of variables $X = \exp Y = R (\exp \Theta) R^T$ then gives $$
I = c_n \int\limits_{{\rm O}(n)} \, \int\limits_{\mathbb{R}^n} \! f(R(\exp \Theta)R^T) \, \prod_{i<j} 2 \sinh\bigl(\tfrac{|\theta_i-\theta_j|}{2}\bigr) \, d\Theta \, dR \;.
$$ Guess: $dY = c_n \, \prod_{i<j} |\theta_i - \theta_j| \, d\Theta \, dR$ also holds for the space $S_n$ . Then it would appear that the second integrand needs to be $$
I = \int_{S_n} f(\exp Y) \, \prod_{i<j} \frac{\sinh(|\theta_i-\theta_j|/2)}{|\theta_i-\theta_j|/2} \, dY \;,
$$ with $\theta_1, \ldots, \theta_n$ the eigenvalues of $Y$ . Is this true? If so, does the extra factor have a particular meaning?","['integration', 'measure-theory', 'reference-request', 'linear-algebra', 'symmetric-matrices']"
3645017,Laplacian of Kelvin Transform - Confusion about notation,"There is an exercise in Evans' book (chapter 2, problem #11). Suppose $u:\mathbb{R}^n\to\mathbb{R}$ is harmonic. Show that $\overline{u}(x)=u(\overline{x})|\overline{x}|^{n-2}=u(x/|x|^2)|x|^{2-n}$ is harmonic, where $\overline{x}=x/|x|^2$ . I'm less interested in the result, but I like this problem because it seems to be good practice in vector calculus. I want to improve my understanding of operations in $\mathbb{R}^n$ , as my research thus far has been in $\mathbb{R}$ . Anyways, I am rather confused about applying a Laplacian to this function. The hint is to show that $(D_x \overline{x})(D_x \overline{x})^T=|x|^4 I$ , which I have completed. But I want to understand the Laplacian in terms of matrices, products, transposes, traces, etc. I know that $\Delta(fg)=g\Delta f+f\Delta g+2(Df)\cdot (Dg).$ If $f(x)=u(x/|x|^2)$ and $g(x)=|x|^{2-n}$ , then this formula can be applied. But I am a bit lost on calculating $\Delta (u(x/|x|^2))$ . Any insight would be helpful. Thank you.","['laplacian', 'multivariable-calculus', 'analysis', 'partial-differential-equations']"
3645070,$L_{x}f=f$ for all $x \in \mathbb{R}$ implies $f=0$,"Let $f\in L^{2}(\mathbb{R})$ if $ L_{x}f=f$ for all $x\in \mathbb{R}$ in $L^{2}(\mathbb{R})$ then $f=0$ .
That is 'if for all $x\in \mathbb{R}$ , $ f(y-x)=f(y)$ for almost every $y \in \mathbb{R}$ (we take lebesgue measure) then $f$ is zero almost everywhere' Is this a true statement? If true what is the proof ? I couldn't figure out a proof, that is why I put it here.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
3645080,Prove that for every $n \in \mathbb{N}$ $\sum\limits_{k=2}^{n}{\frac{1}{k^2}}<1$ [duplicate],This question already has answers here : Proving by induction that $\sum\limits_{k=2}^n \frac1{k^2}\le 1$ (2 answers) Closed 4 years ago . $$\sum\limits_{k=2}^{n}{\frac{1}{k^2}}<1$$ First step would be proving that the statement is true for n=2 On the LHS for $n=2$ we would have $\frac{1}{4}$ therefore the statement is true for $n=2$ Now we must assume the statement is true for $n=j$ with $j\geq2$ $$\sum\limits_{k=2}^{j}{\frac{1}{k^2}}<1$$ Now we must prove true for $n=j+1$ $\sum\limits_{k=2}^{j+1}{\frac{1}{k^2}}<1$ $\Rightarrow \sum\limits_{k=2}^{j}{\frac{1}{k^2}}+\frac{1}{(k+1)^2}<1$ I cant seem to introduce the induction hypothesis,"['algebra-precalculus', 'summation', 'inequality']"
3645088,Isogenies between $\mathbb{C}^*/q^\mathbb{Z}$ and $\mathbb{C}^*/q'^\mathbb{Z}$,"Let $\Delta = \{ q \in \mathbb{C}^* | |q| \lt 1\}$ , $q \in \Delta$ , and $f : \mathbb{C}^*/q^\mathbb{Z} \to E'$ be an isogeny of degree $n$ . Then there exists the unique pair $(a, q')$ , where $a$ is a divisor of $n$ and $q'$ satisfies $q^a = q'^b$ for $b = n/a$ , such that: There exists $\mathbb{C}^* / q'^\mathbb{Z} \cong E'$ such that $f$ is the composition $\mathbb{C}^* / q^\mathbb{Z} \to \mathbb{C}^* / q^{a\mathbb{Z}} = \mathbb{C}^* / q'^{b\mathbb{Z}} \to \mathbb{C}^* / q'^\mathbb{Z} \cong E'$ .
  (Where $\mathbb{C}^* / q^\mathbb{Z} \to \mathbb{C}^* / q^{a\mathbb{Z}}$ is $u \mapsto u^a$ and $\mathbb{C}^* / q'^{b\mathbb{Z}} \to \mathbb{C}^* / q'^\mathbb{Z}$ is $u \mapsto u$ .) Here is what I have tried: Let $f : \mathbb{C}/\Lambda_\tau \to E'$ be an isogeny of degree $n$ .
Then this map is isomorphisc to $\mathbb{C}/\Lambda_\tau \to \mathbb{C}/K$ , where $K$ is a subgroup of $\mathbb{C}$ , containing $\Lambda_\tau$ as a subgroup of index $= n$ .
Thus this is a lattice. So write $K = \omega_1 \mathbb{Z} + \omega_2 \mathbb{Z}$ .
Since $K/ \Lambda\tau$ is of index $n$ , we may assume $a \omega_1, b \omega_2 \in \Lambda_\tau, n = ab.$ And for such $a,b$ , we have $\Lambda_\tau = a \omega_1 \mathbb{Z} + b \omega_2 \mathbb{Z}$ . If $\omega_1 = 1/a, \omega_2 = \tau/b$ ,
then $$\mathbb{C}/\Lambda_\tau \xrightarrow{\text{multiplicate by }a} \mathbb{C}/\Lambda_{a\tau}
 \xrightarrow{\operatorname{mod}} \mathbb{C}/\Lambda_{\frac{a\tau}{b}} 
\xrightarrow[\cong]{\text{multiplicate by }1/a} \mathbb{C}/K $$ is equal to $\mathbb{C}/\Lambda_\tau \to \mathbb{C}/K$ , so is isomorphic to $f$ , hence ok. For general $\omega_i$ , since the diagram $\require{AMScd}$ \begin{CD}
\mathbb{C}/\Lambda_\tau @>>> \mathbb{C}/K \\
@V{\times 1/a\omega_1}V{\cong}V @V{\times 1/a\omega_1}V{\cong}V\\
\mathbb{C}/\Lambda_{\frac{b}{a} \frac{\omega_2}{\omega_1}}  @>{\times a}>> \mathbb{C}/\Lambda_{\frac{\omega_2}{\omega_1}}
\end{CD} commutes, the highlighted statement is true if we allow to ""compositing isomorphisms with its source and target"". And if $\Im \tau, \Im (\frac{b}{a} \frac{\omega_2}{\omega_1}) \gt 1$ , then $q = q'$ , where $q = \exp(2 \pi i \tau)$ and $q' = \exp(2 \pi i \frac{b}{a} \frac{\omega_2}{\omega_1})$ .
So ok.
But if $|q| \lt e^{-2\pi}$ , then $|q'| \ge e^{-2 \pi}$ . So, how can I show the general case? (I want to show the highlighted statement to show $$\{ \text{ isogenies from } \mathbb{C}^*/q^\mathbb{Z} \text{ of degree }n \} / \sim \\ 
= \bigcup_{ a | n } \{ q' \in \Delta | q^a = q' ^{n/a} \}, $$ where $E \to E' \sim E \to E'' \iff $ there exists $E' \cong E''$ such that $E \to E''$ is $E \to E' \cong E''$ .)","['modular-forms', 'algebraic-geometry', 'elliptic-curves']"
3645131,"Checking if $\mathbb{Q}(5^{1/10},e^{\pi i/5})=\mathbb{Q}(5^{1/10},i)$","While doing some Galois theory I encountered with the field $\mathbb{Q}(5^{1/10},e^{\pi i/5})$ , which is a splitting field of the polynomial $f(t)=t^{10}-5$ . However, as it can be proved, the degree of this field over $\mathbb{Q}$ is equal to $20$ , so I think there should exist a better choice of the generators, so they represent better the structure of the field. I have thought that $i$ could be a good replacement for $\zeta=e^{\pi i/5}$ , but there is a problem; while it is true that $\mathbb{Q}(5^{1/10},\zeta)$ and $\mathbb{Q}(5^{1/10},i)$ have the same order, it is not clear that one has any inclusion between those sets at all; for instance $$\zeta+\zeta^4=2i\sin(\pi/5)$$ and $i$ would lie in the aforementioned field if $2\sin(\pi/5)$ lies in $\mathbb{Q}(5^{1/10},\zeta)$ . However $$2\sin(\pi/5)=\sqrt{\frac{1}{2}(5 - \sqrt{5})}$$ And whether there exists a crazy linear conmbination in the last field which equals $2\sin(\pi/5)$ or not is something I can't tell at the moment. Maybe I'm wrong with my intuition and $i$ is a bad choice? Is there some other element $z$ such that $[\mathbb{Q}(z):\mathbb{Q}]=2$ and $\mathbb{Q}(5^{1/10},\zeta)=\mathbb{Q}(5^{1/10},z)$ ? Thanks in advance for your help.","['radicals', 'field-theory', 'galois-theory', 'abstract-algebra', 'algebra-precalculus']"
3645139,Calculating the volume of a restaurant take-away box that is circular on the bottom and square on the top,"Having a bit of a problem calculating the volume of a take-away box: I originally wanted to use integration to measure it by rotating around the x-axiz, but realised that when folded the top becomes a square, and the whole thing becomes rather irregular. Since it differs in circumference I won't be able to measure it like I planned. Is there any method or formula that can be used to measure a shape like this, or do I just have to approximate a cylinder and approximate a box and add those two together?","['integration', 'geometry', 'volume']"
3645177,Divergence of improper integral if $f$ has limit $l>0$,"Lets suppose that $f:[a,\infty) \to \mathbb{R}$ is a Riemann integrable function and lets suppose that $$\lim_{x \to \infty} f(x) = l > 0$$ I am trying to prove that then $$\int_a^\infty f(x) \text{d}x=\infty$$ By hypothesis $f$ has limit $l > 0$ as $x \to \infty$ , so we know that for all $\varepsilon>0$ exists $K_{\varepsilon} > 0$ such that for all $x \geq K_{\varepsilon}$ it is $f(x)>l-\varepsilon$ . Since by hypothesis $l > 0$ and for the arbitrarity of $\varepsilon>0$ we can choose $\varepsilon=l/2$ ; so we have the estime $f(x)>l/2$ . So it is $$\int_a^\infty f(x) \text{d}x =\int_a^{K_\varepsilon} f(x) \text{d}x+\int_{K_\varepsilon}^\infty f(x) \text{d}x > \int_a^\infty \frac{l}{2} \text{d}x =\infty$$ Since the first integral on the right hand side is finite it does not influence the convergence, so we concentrate on the second integral; by the limit estimation we have that $$\int_{K_\varepsilon}^\infty f(x) \text{d}x > \int_{K_\varepsilon}^\infty \frac{l}{2} \text{d}x =\infty$$ So the integral is divergent. Some questions: 1) is the context correct? I've assumed that "" $f:[a,\infty)$ Riemann integrable"" means that the only point we have to study is when $x \to \infty$ because of the unboundedness; 2) when I split the integral in two integrals I suppose that $a<K_\varepsilon$ , can I do this? If yes, why? 3) is the proof correct in general? If not, where are the mistakes? If yes, how can I improve it? Thanks.","['integration', 'improper-integrals', 'definite-integrals', 'analysis', 'solution-verification']"
3645291,Lens space bundles over a circle must come from sphere bundle over a circle?,"The question I would like to answer is the following. From the classification of sphere bundles we know that the only orientable $S^3$ bundle over $S^1$ is $S^3 \times S^1$ . So suppose we have lens space bundle $L_n(1) \rightarrow P \rightarrow S^1$ , where $L_n(1)=S^3/\mathbb{Z}_n$ is the lens space sometimes also denoted by $L(n;1)$ , and $P$ is oreintable. Does it follow from bundle theory that $P=L_n(1) \times S^1$ ? My nose tells me this is true, but I know too little about bundle theory to answer it on my own.","['fiber-bundles', 'differential-geometry']"
3645342,Zeroes of $2z^5-15z^2+z+2$,"In preparation for qualifying exams I am working through old exams and came across the following question: Determine the number of roots, counted with multiplicity, of the equation $$2z^5-15z^2+z+2$$ inside the annulus $1\leq |z|\leq 2$ . It seemed like a relatively straight forward application of Rouche's Theorem and was able to show there are two roots inside the unit disk, but when I was considering the boundary of $D(0,2)$ , I couldn't seem to get a strict inequality in order to apply Rouche's Theorem . For example I chose $$f(z)=-15z^2+z+2$$ and $$g(z)=2z^5$$ but the best I could do was $|f(z)|\leq 64 =|g(z)|$ on $\partial D(0,2)$ . Similar problems happened on different choices for $f$ and $g$ . P.S. I am trying to use: If $|f|<|g|$ on $\partial D(0,r)$ then $|Z_{D(0,r)}(g-f)|=|Z_{D(0,r)}g|$","['complex-analysis', 'rouches-theorem', 'roots', 'polynomials']"
3645364,Prove that a given subset of the reals is countable,"Let $A\subseteq\mathbb{R}$ with $A$ uncountable. Let $B\subseteq A$ where for every $b\in B$ , $\exists n\in\mathbb{N}$ where $\left[b,b+\frac1n\right)\cap A$ is countable. Now, show $B$ is countable. I was thinking of assuming $B$ is uncountable and taking one interval for every $b\in B$ .
Then I would take a rational from each interval, and derive a contradiction as there are only countably
many rationals. This doesn't work as the intervals could overlap. I'm unsure how to continue.","['elementary-set-theory', 'order-theory']"
3645368,"Set theory: $n$ is a set in the naturals, if $x$ is in $n$, is $x$ also a natural number?","Im having trouble with a homework question from my Set Theory class. The question is, Let $n$ be a set and an element of the natural numbers. If $x$ is an element of $n$ , is $x$ also an element of the natural numbers? My intuition says yes, since we built up the natural numbers using only the empty set, I would guess that $x$ is just $n-1$ , but I'm having trouble proving this. My class is using the Zermelo-Fraenkel Set Theory axioms.","['elementary-set-theory', 'solution-verification', 'natural-numbers']"
3645564,Is it true that $\Gamma(\Lambda(T^*M)) \cong \Lambda(\Gamma(T^*M))$?,"Well, the question is in the title. Is it true, that given a smooth manifold $M$ , the following isomorphism holds: $$
\Gamma(\Lambda(T^*M)) \cong \Lambda(\Gamma(T^*M))
$$ $\Gamma$ - smooth sections functor, $\Lambda$ - exterior algebra functor. Base ring for both - $C^\infty(M)$ . Motivation: I'm kind of confused, because some sources define differential forms as sections of exterior bundle, others define forms as elements of exerior algebra of sections: For example: Wikipedia uses first definition https://en.wikipedia.org/wiki/Differential_form nLab uses second definition https://ncatlab.org/nlab/show/exterior+algebra (at the bottom) Are those equivalent?","['vector-bundles', 'exterior-algebra', 'differential-forms', 'differential-geometry']"
3645603,Is matrix exponential injective and surjective?,"Exponential of real numbers exp: $\mathbb{R}\rightarrow\mathbb{R}$ is injective. Does the same hold for exponential of real matrices exp: $\mathbb{R}^{2\times2}\rightarrow\mathbb{R}^{2\times2}$ ? What about surjectivity, can every regular real matrix be written as $X=$ exp $A$ ?","['matrices', 'matrix-exponential', 'linear-algebra']"
3645663,How to solve the random walk problem on the complete graph?,"In a complete graph of order $n$ , a moving point starts from a certain vertex and moves along the edges. At each vertex, the unpassed edges are selected with equal probability to continue the movement. What is the expectation of the number of passed edges until it stops its movement? The moving point probably does not pass all the edges. It just needs to move into a vertex and cannot move out.","['random-walk', 'probability']"
3645676,"$E(Y|Χ_1,Χ_2)=E(Y|Χ_1) $","If $Y \in \mathcal{L^1}  (\Omega, \mathcal{F}, \Bbb{P})$ and random Vectors $X_1$ , $X_2$ such that $\sigma(X_2)$ independent of $\sigma(Y,X_1)$ . I want to show that $E(Y|Χ_1,Χ_2)=E(Y|Χ_1) $ a.s. $$$$ Thought : We could maybe use the below results and if we define $\mathcal{G_1}, \mathcal{G_2} ,\mathcal{G_3}$ in an appropriate way  . We may be able to show the desired result. $$$$ Thus, $\mathcal{G_1}  , \mathcal{G_2} ,\mathcal{G_3} $ are $\sigma $ fields in $\mathcal{F}. $ If we assume that $Y$ is $\mathcal{G_1}$ measurable and $\mathcal{G_3}    $ is independent of $\mathcal{G_1}\bigvee\mathcal{G_2}$ . $ E [E (Y\mid\mathcal{G_2}) 1_A ] = E (Y  1_A )$ for every $A$ formed as $A= B \cap C$ , $B \in \mathcal{G_2}  $ , $ C \in \mathcal{G_3}  $ . I should define $\mathcal{G_1} \mathcal{G_2} \mathcal{G_3}$ in an apropriate way and we will be able to show that $E(Y|X_1,X_2)=E(Y|X_1) $ a.s.","['conditional-expectation', 'self-learning', 'measure-theory', 'probability-theory']"
3645681,Divergence theorem for non-compact manifolds,"I wonder whether there is a generalization of the divergence theorem or more generally of Stokes' theorem to non-compact domains or manifolds, much like the improper Riemann integrals.
Consider the function $f(x, y) = \frac{1}{x^2 y^2}$ integrated over the domain $D = [1, \infty)^2$ . This can be written as a nested improper Riemann integral and turns out as $1$ . Now this did not really use the divergence theorem, but consider a similar case for the divergence theorem where all integrals would be finite since the integrands decay quickly enough at infinity. If I understand it correctly, the generalized Stokes' theorem (and as a special case also the divergence theorem) still apply if the domain is not fully bounded in all directions as long as the integrand has compact support.
But $\frac{1}{x^2 y^2}$ has no compact support in $D$ . First question: Is there a generalization relaxing the compact support requirement? Such that it is enough that all integrals exist? So far I found (Karp - On Stoke's Theorem For Noncompact Manifolds, https://www.jstor.org/stable/2043967 ), but that requires complete manifolds. (Edit: It was pointed out that $D$ is cauchy complete. Although the article does not explicitly state it, I assume it refers to geodesical completeness, see https://en.wikipedia.org/wiki/Geodesic_manifold . This assumption makes sense for the article as it deals with geodesic balls and grows them towards infinity. For clearness I'll add ""geodesically"" to every occurrence of ""complete"" in the following.) $[1, \infty)^2$ is not geodesically complete, right? It appears to me that something similar should hold if the manifold or the domain is geodesically complete in some directions but bounded in other directions, possibly in more complicated manner than $[1, \infty)^2$ . E.g. consider a domain like $\{(x, y) \in \mathbb{R}^2 \colon y > x^2\}$ . My idea so far: If we had a nested sequence of compact domains $C_0 \subset C_1 \subset \ldots \subset D$ such that $\lim\limits_{j \to \infty} C_j = D$ , one can apply Stokes' Theorem to $f|_{C_j}$ and observe if the result converges as $j \to \infty$ . This is much like the technique behind improper Riemann integrals, but growing a compact domain instead of an interval towards an improper boundary part. Here it is probably helpful that ""in good cases"" ( https://en.wikipedia.org/wiki/Support_(mathematics)#Compact_support ) compactly supported functions lie densely in the set of functions that vanish at infinity. Second question: This construction is so simple it must be well known. I kindly ask for references where this is studied, material about this. Is there some pitfall that prevents us using it to apply Stokes' or the divergence theorem to manifolds or domains that are not compact or possibly neither compact nor geodesically complete? (Otherwise, why is it so hard to find a formulation for cases that are neither compact nor geodesically complete?) Third question: I am not much interested in pathological cases and assume that the integrand has no singularities. For my usecase, it can be assumed to be strictly positive, possibly zero at the boundary or at infinity. However, there certainly are pathological cases and it would be good to know conditions (on $f$ and $D$ ) to exclude them. For $D$ this should be somewhat weaker than geodesically complete or compact. Note:
There are a couple of similar questions but I did not find a satisfying(ly answered) one.
One of the best answers I found is in Requirements for integration by parts/ Divergence theorem , however it does not cover manifolds. My examples of non-manifold domains are illustrative, I am interested in a (Riemannian) manifold version. Also this one has an answer but also for a subset of $\mathbb{R}^n$ and required some justification in the comments: Divergence Theorem/Integration by Parts on Unbounded Domains These questions do not ask the same as my question although the title suggests some overlap: Divergence theorem on special unbounded domains Stokes theorem for non-compact case Domains for which the divergence theorem holds Sorry if I overlooked an actual duplicate.","['divergence-theorem', 'riemannian-geometry', 'stokes-theorem', 'vector-analysis', 'differential-geometry']"
3645714,Expected value of the length of max consecutive sequence of $1$'s in a random binary number,"Let $X$ be a random integer number from $0$ to $2^d − 1$ . Denote by $M(X)$ the length of the maximum consecutive sequence of 1’s in the binary representation of $X$ . Find expected value $E[M(X)]$ up to a constant multiplicative factor. For example, for the binary number “ $1101110$ ”, we have $M(1101110) = 3$ ; and for the binary number “ $11110110011$ ”, we have $M(11110110011) = 4$ .","['probability', 'computer-science']"
3645720,Condition for $L^r(\mu)=L^\infty(\mu)$ where $\mu(X)=1$,"This is Exercise 3.5 in Rudin's Real and Complex Analysis. Suppose $\mu$ is a positive measure on a set $X$ , with $\mu(X)=1$ . Rudin askes: Under what conditions do the two spaces $L^r(\mu)$ and $L^s(\mu)$ contain the same functions, where $0<r<s\leq \infty$ ? I am trying to show the case where $s=\infty$ . It is easy to show that $L^r(\mu)\supset L^\infty(\mu)$ using the Jensen's inequality. But I have no idea for finding a condtion on $X$ so that $L^r(\mu)=L^\infty(\mu)$ . Any hints?","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'measurable-functions']"
3645725,Please verify my proof of Gauss's Law,"Can someone please verify my proof of Gauss's Law? I directly copied it from my assignment, and it is an extra credit assignment, so I just want someone to tell me if it is completely correct or whether I made an assumption or there is something missing in my proof. We prove Gauss's Law for a single point charge, then use the superposition principle of the electric field to generalize it for multiple charges. We start from Coulomb's Law for the Electric Field: $$\mathbf{E}=\frac{1}{4\pi\varepsilon_0}\frac{Q}{r^2}\hat{\mathbf{r}}$$ where $+Q$ is a point charge. Negative charges change the direction of the entire field, so this proof will work for negative charges as well. Define the origin to be the location of this charge. Mathematically, we can write Coulomb's Law as $$\mathbf{E}=\frac{1}{4\pi\varepsilon_0}\frac{Q}{\lVert{\mathbf{r}\rVert}^3}\mathbf{r}$$ where $\mathbf{r}$ is the outward radial vector relative to the charge. \\ Consider an arbitrary closed surface $S$ that completely surrounds the charge. Consider an arbitrary tiny differential area element vector $d\mathbf{S}$ on $S$ that is normal to $S$ at that point. Then the differential electric flux $d\Phi_E$ is given by $$d\Phi_E=\mathbf{E}\cdot d\mathbf{S}$$ so if we take the closed surface integral around the surface, we get $$\Phi_E=\iint_S\mathbf{E}\cdot d\mathbf{S}$$ or $$\Phi_E=\frac{Q}{4\pi\varepsilon_0}\iint_S\frac{\mathbf{r}}{\lVert{\mathbf{r}\rVert}^3}\cdot d\mathbf{S}$$ We now show that the integral $$\iint_S\frac{\mathbf{r}}{\lVert{\mathbf{r}\rVert}^3}\cdot d\mathbf{S}=4\pi$$ We begin with the Divergence Theorem, which states that $$\iiint_V \nabla\cdot\mathbf{E}\;dV=\iint_{\partial V} \mathbf{F}\cdot d\mathbf{S}$$ where $V$ is a simply-connected closed region and $\partial V$ is the boundary surface of $V$ . For simplicity, let $$\mathbf{e}=\frac{\mathbf{r}}{\lVert{\mathbf{r}\rVert}^3}$$ It can be shown that $\nabla\cdot\mathbf{e}=0$ by writing $$\mathbf{e}=\frac{\mathbf{r}}{\lVert{\mathbf{r}\rVert}^3}=\frac{x\mathbf{i}+y\mathbf{j}+z\mathbf{k}}{(x^2+y^2+z^2)^{3/2}}$$ and directly using the definition of divergence. We cannot, however, use the divergence theorem directly on the region enclosed by $S$ on $\mathbf{e}$ since $\mathbf{e}$ is not defined at the origin. \\ We now consider a new region $E$ that is such that the outer boundary surface of $E$ is $S$ and the inner boundary of the surface is a sphere centered at the origin with radius $a$ such that the sphere is entirely contained within $S$ . Call the sphere $S_0$ . In this way, the origin is excluded from $E$ which allows us to use the divergence theorem. Now, $$\iiint_E \nabla\cdot\mathbf{e}\: dV = \iint_{\partial E} \mathbf{e}\cdot d\mathbf{S}=\iint_{\partial E} \mathbf{e}\cdot\mathbf{n}\: dS$$ where $\mathbf{n}$ is the outward unit normal vector. Now, $$\iint_{\partial E}\mathbf{e}\cdot\mathbf{n}\: dS=\iint_S \mathbf{e}\cdot\mathbf{n}_1\: dS+\iint_{S_0}\mathbf{e}\cdot(-\mathbf{n}_2)\: dS$$ Where $\mathbf{n}_1$ represents the outward normal of $S$ and $\mathbf{n}_2$ represents the outward normal of $S_0$ . Note that since the outward normal of $\partial E$ is actually the inward normal of $S_0$ , we must add a negative sign to account for this. As a result, we have $$\iiint_E \nabla\cdot\mathbf{e}\: dV=\iint_S \mathbf{e}\cdot d\mathbf{S}-\iint_{S_0}\mathbf{e}\cdot d\mathbf{S}$$ However, we said earlier that $\nabla\cdot\mathbf{e}=0$ , so we get $$\iint_S\mathbf{e}\cdot d\mathbf{S}=\iint_{S_0}\mathbf{e}\cdot d\mathbf{S}$$ This makes it so that the flux of the electric field through any closed surface is equal to the flux of the electric field through a sphere, which easy to find. We have $$\iint_{S_0}\mathbf{e}\cdot d\mathbf{S}=\iint_{S_0}\mathbf{e}\cdot\mathbf{n} \: dS=\iint_{S_0}\frac{\mathbf{r}}{\lVert{\mathbf{r}\rVert}^3}\cdot\frac{\mathbf{r}}{\lVert{\mathbf{r}\rVert}}\: dS=\iint_{S_0}\frac{1}{a^2} dS $$ where the last part is found by using the unit normal vector of a sphere and the fact that $\mathbf{r}\cdot\mathbf{r}=\lVert{\mathbf{r}\rVert}^2$ . This gets us $$\iint_{S_0}\frac{1}{a^2}dS=\frac{1}{a^2}4\pi a^2=4\pi$$ We just showed that the flux through the sphere is $4\pi$ which means that the flux through the arbitrary surface $S$ is also $4\pi$ . Going back to the initial equation, we get $$\Phi_E=\frac{Q}{4\pi\varepsilon_0}\iint_S \frac{\mathbf{r}}{\lVert{\mathbf{r}\rVert}^3}\cdot d\mathbf{S}=\frac{4\pi Q}{4\pi\varepsilon_0}=\frac{Q}{\varepsilon_0}$$ This shows that Gauss's Law holds for one charge. \\ Now, if there are multiple charges $q_1, q_2, \ldots, q_n$ in the surface, then the superposition principle states that the total electric field $\mathbf{E}$ is just the vector sum of the individual electric fields, or $$\mathbf{E}=\mathbf{E}_1+\mathbf{E}_2+\ldots+\mathbf{E}_n$$ Thus, $$\Phi_E=\iint_S\mathbf{E}\cdot d\mathbf{S}=\iint_S (\mathbf{E}_1+\mathbf{E}_2+\ldots+\mathbf{E}_n)\cdot d\mathbf{S}=\iint_S\mathbf{E}_1\cdot d\mathbf{S}+\iint_S\mathbf{E}_2
\cdot d\mathbf{S}+\ldots+\iint_S\mathbf{E}_n\cdot d\mathbf{S}$$ This equals $$\frac{q_1}{\varepsilon_0}+\frac{q_2}{\varepsilon_0}+\ldots+\frac{q_n}{\varepsilon_0}=\frac{q_1+q_2+\ldots+q_n}{\varepsilon_0}=\frac{q_{enc}}{\varepsilon_0}$$ Using this addition, we can see that Gauss's Law works for continuous charge distributions as well since a continuous charge distribution is simply made up of infinitely many point charges whose electric fields add due to superposition. \\ Finally, say that the charge is outside the closed surface. This means that the closed surface does not enclose the origin. Since $\nabla\cdot\mathbf{E}=0$ , the Divergence Theorem gives $$\iint_S \mathbf{E}\cdot d\mathbf{S}=\iiint_E \nabla\cdot\mathbf{E}\: dV=0$$ where $E$ is the region with $S$ as its boundary. Now because $\mathbf{E}$ is defined everywhere inside the region (as the only place $\mathbf{E}$ isn't defined is the origin, which we have already said is outside the region), we see that $\Phi_E=0$ . This easily extends to multiple charges outside the surface, since the divergence operator has a distributive property if each electric field is defined in the region, which it is. That is, $$\nabla\cdot(\mathbf{E}_1+\mathbf{E}_2+\ldots+\mathbf{E}_n)=\nabla\cdot\mathbf{E}_1+\nabla\cdot\mathbf{E}_2+\ldots+\nabla\cdot\mathbf{E}_n$$ which equals zero since each term equals zero. \\
We have thus proved Gauss's Law for the electric field.","['divergence-theorem', 'multivariable-calculus', 'solution-verification']"
3645829,Median of the set of numbers which consists of all positive integers whose digits strictly increase from left to right,"Consider the set $$S=\{1,2,3,4,5,6,7,8,9,12,13,14,15,16,17,18,19,23,24,\ldots,123456789\},$$ which consists of all positive integers whose digits strictly increase from left to right. This set is finite. What is the median of the set? This problem is harder than I thought at first. I first simply though the solution was $\frac{123456789+1}{2}=61728395.$ Turns out I'm wrong! Where am I going wrong? I checked my work and $61728395-1+1=61728395.$ Also, $123456789-61728395+1=61728395.$ These are equal, so the distance should also be equal. Where am I going wrong?",['combinatorics']
3645862,(Regularized) Dual Representation of Wasserstein-1 metric,"Consider $\mathbb{R}^d$ , the $d$ -dimensional Euclidean space. Let $W_1$ be the $1^{st}$ Wasserstein distance between probability measures $\mu, \nu$ $$W_1(\mu, \nu) = \inf_{\gamma \in \Gamma(\mu, \nu)} \int \|x-y\|_2d\gamma(x,y),$$ where $\Gamma(\mu, \nu)$ is the set of all measures on $\mathbb{R}^d \times \mathbb{R}^d$ with marginals $\mu, \nu$ .
It is well known that $W_1$ has the following dual representation $$W_1(\mu, \nu) = \sup_{\|f\|_{\text{Lip}} \leq 1} \int f(x)d(\mu-\nu)(x),$$ where $\|f\|_{\text{Lip}} = \sup_{x\neq y} \frac{|f(x)-f(y)|}{\|x-y\|_2}.$ I'm interested in understanding a slight variant of this dual objective $$\sup_{f} \left[\int f(x)d(\mu-\nu)(x) - \frac{M}{2}\|f\|_{\text{Lip}}^2\right],$$ where $M>0$ is a constant. Note that the earlier objective has a constraint on the Lipschitz constant, whereas the latter one has a regularization penalty on the  Lipschitz constant. Is the maximum of the above objective related to the $W_1$ metric? Can we obtain a closed-form expression for the maximum?","['convex-optimization', 'measure-theory', 'optimal-transport', 'functional-analysis']"
3645891,"Prove that $ f(x) $ has at least two real roots in $ (0,\pi) $","Let $ f $ be a continuous function defined on $ [0,\pi] $. Suppose that $$ \int_{0}^{\pi}f(x)\sin {x} dx=0,   \int_{0}^{\pi}f(x)\cos {x} dx=0 $$ Prove that $ f(x) $ has at least two real roots in $ (0,\pi) $",['calculus']
3645923,How to prove $\lim_{n\to\infty}\frac{1}{\Gamma(n/2+1)}\int_{0}^{n} t^{n/2}e^{-t}dt = 1$?,"How can we prove $$\lim_{n\to\infty}\frac{1}{\Gamma(n/2+1)}\int_{0}^{n}  t^{n/2}e^{-t}dt = 1$$ ? We ran experiments on MATLAB, it seems the statement is true.","['integration', 'limits', 'gamma-function']"
3645938,Number of random variables in a stochastic process taking a value,"Suppose I have a stochastic process $\{X_t : t \in [0,1]\}$ where the $X_t$ are iid continuous RVs supported on $\mathbb R$ . For any $x \in \mathbb R$ I know $P(X_t = x)=0$ , but I have uncountably many RVs. What is the (likely?) cardinality of $\{t \in [0,1] : X_t = 0\}$ ? Is this some kind of possibly-infinite valued random variable now? If my index set was countable I’d guess that I’d expect zero or maybe at most finitely many, but I’m not sure how to reason about this with an uncountable index. Do I need to have some distribution on $[0,1]$ ? Alternatively, what about the Lebesgue measure of $\{t : X_t = x\}$ ? I'm not sure if there's any reason for this set to be measurable unless it's at most countable, so I'm guessing if it is measurable then the measure will be zero but I'm not sure how to try showing that.","['stochastic-processes', 'cardinals', 'probability-theory']"
3645952,Reflective subcategories of monoids,"An exercise in The Joy of Cats, p. 59, is as follows: Show that no finite monoid, considered as a category, has a proper reflective subcategory. The obvious idea is to let $r : \cdot \to \cdot$ be a reflector. Then by assumption every arrow $f$ factors as $f' \circ r$ , where $f'$ is in the subcategory. Now if we can show that $r$ is itself in the subcategory, then we win... But this is giving me some trouble. The theorem is false for infinite monoids (and the second part of this problem, which I've done, gives a counterexample), but I'm not sure how to leverage finiteness without knowing my monoid is cancellative. We can conclude lots of things by pigeonhole, but I'm not sure how to apply them. Any help is appreciated ^_^","['monoid', 'abstract-algebra', 'category-theory']"
3645975,Very Ample Implies Separation of Points and Tangents: Miranda,"As a preface, this is not homework. I'm a professor, after all. I'm reading through Miranda's ""Algebraic Curves and Riemann Surfaces,"" and getting caught up on one point from Chapter VI. First, some background: a divisor $D$ is called very ample on compact Riemann Surface $X$ if a) its associated embedding of $X$ into projective space is a holomorphic embedding whose image is a Riemann Surface and b) its linear system $|D|$ is base point-free. It is a theorem that this happens if and only if $\dim L(D - q - p) = \dim L(D) - 2$ for all points $p, q \in X$ (including the case $p = q$ ), where $L(D)$ is the set of meromorphic functions on $X$ such whose principal divisors (divisors given by orders of points) are $\geq - D$ . Claim : a very ample divisor $D$ must have the property that the field generated by $L(D)$ separates points and tangents on $X$ . That is, given distinct $p, q \in X$ , there is a meromorphic function on $X$ in the field generated by $L(D)$ separating them (separates points), and, given any $p \in X$ , there must be a meromorphic function on $X$ in that same field whose multiplicity at $p$ is one, which means there is a meromorphic function $f$ on $X$ (in the field generated by $L(D)$ ) which is either a) holomorphic at $p$ with the order of $f - f(p)$ equal to one at $p$ , or b) which has a simple pole at $p$ (separates tangents). What I know : the very ample condition implies $$L(D - p - q) \subset L(D - p) \subset L(D)$$ is a strict chain of subspaces for any $p, q \in X$ , which means, for example, there is a function $f$ in $L(D - p)$ not in $L(D - p - q)$ . This function would satisfy the property that $ord_p(f) \geq -D(p) + 1$ , but that there is some point $x$ in its support where $ord_x(f) < -D(x)$ , but I am lost after that. I have begun to slowly get lost in the concepts over this past chapter, and would appreciate some help here. For reference, this claim is made on page 170, and is problem A on p 178. EDIT: The embedding associated to a divisor $D$ is given by $$\phi_D : X \to \mathbb P^n$$ where $p \to [f_0(p):...:f_n(p)]$ , and the $f_i$ are a basis for $L(D)$ . We also know this basis can be chosen so that $ord_p f_0(p) = -D(p)$ and $ord_p f_i(p) > -D(p)$ for all other $i$ .","['riemann-surfaces', 'complex-geometry', 'complex-analysis', 'divisors-algebraic-geometry', 'algebraic-geometry']"
3645995,A singular integral,"So, I was doing some PDE related computations and I obtained the following integral $$
\iint \frac{(y-y')\,f(x',y')}{(|x-x'|^2+|y-y'|^2)^\frac{3}{2}}\, \left|\frac{x'}{x}\right|^2 \,\mathrm{d} x'\,\mathrm{d} y'
$$ where $f$ is a continuous and compactly supported function, odd with respect to its first variable. Is this integral bounded (uniformly with respect to $x$ and $y$ )? I tried to do several changes of variable (for example one can replace $x'$ by $xx'$ to put the singularity in $x$ inside the part written $(..)^\frac{3}{2}$ ). I had a look on litterature on singular integrals but things seems usually more symmetric in these kind of theories. Any ideas, examples, counterexamples or proof of a result are welcome!","['functional-inequalities', 'singular-integrals', 'convolution', 'multivariable-calculus', 'integral-inequality']"
3646120,What is $\lim_{x \to 0} \frac{|x+1|+|x-1|-2}{|x+1|+|x-1|-2}$?,"$\displaystyle \lim_{x \to 0} \frac{|x+1|+|x-1|-2}{|x+1|+|x-1|-2}$ If $x \to 0$ , then it does not matter the value when $x=0$ , then would not it be just equivalent to $\displaystyle \lim_{x \to 0} 1$ which is equal to $1$ ? But Wolfram´s answer is: Limit does not exist on the real line, there are infinitely many singularities in every neighborhood of $0$ . Wolfram Is Wolfram wrong?","['limits', 'calculus']"
3646150,Existence of pseudo-regular polygons,"A regular polygon is a bounded, not self-intersecting polygon in which all edges have the same length and all interior angles are identically, say, $\theta$ .
It is known that $\theta=(1-2/n)\pi$ for some $n\ge 3$ . Now, define a pseudo-regular polygon as a bounded, not self-intersecting (but not necessarily convex) polygon in which all edges have the same length and all interior angles are $\in\{\theta,2\pi-\theta\}$ for some fixed $\theta<\pi$ . All regular polygons are pseudo-regular, and there are others: Question: Are there any with $\theta\not=(1-2/n)\pi$ for all $n\ge 3$ ? Update Based on the comment of  nickgard, I found a solution and posted it as an asnwer.
It was surprisingly straight forward.","['angle', 'geometry', 'polygons', 'plane-geometry']"
3646198,Prove the convexity for f: $\mathbb{R}^3$ $\to$ $\mathbb{R}$,"The problem below is one of my homework for the Convex Geometry course. 
I have tried to prove by using the Hessian matrix or the gradient but cannot figure out the right answers. Show that $$
f(x_1, x_2, x_3) = \cfrac1{x_1-\cfrac{1}{x_2-\cfrac1{x_3}}}
$$ is convex on $\left(\Bbb R_*^+\right)^3$ . Can you help me on this, please?","['convex-geometry', 'multivariable-calculus']"
3646199,Looking for a function that produces the illustrated graph,"I'm looking for a function that creates the blue curve shown in the picture. The point is that within a certain range (e.g. x=0 to x=0.8) the output of the function should be relatively close to 1.0. If possible it would be exactly 1 but ""close"" to 1 (within 10% or so) would be good enough. However, the first value produced by the function should be exactly 1. eventually, the output should drop sharply to y=0. The available input value is x which linearly increases along the x-axis from 0 to 1. The function could rely on any other parameter necessary to achieve the illustrated curve. Any ideas?","['functions', 'graphing-functions']"
3646203,"Examples of the events for which we cannot assign ""meaningful"" probabilities","Quote from the book I'm reading: Any collection of possible outcomes, including the sample space $\Omega$ and its complement, the empty set $\emptyset$ , may qualify as an event. Strictly speaking, however, some sets have to be excluded . In particular, when dealing with probabilistic models involving an uncountably infinite sample space; there are certain unusual subsets for which one cannot associate meaningful probabilities . Question 1 What is meant by ""meaningful"" probabilities? Question 2 Can you provide an example in which we cannot assign meaningful probabilities to the events of the sample space?",['probability']
3646216,Help understanding $D_{KL} (g;f)=0\iff f=g$ a.e.,"It's seems to be a well know property of the Kullback-Leibler divergence (according to Wikipedia ) that $$D_{KL} (g;f)=0\iff f=g\,\,\, a.e.$$ I am working with the continuous case. The second implication is straightforward and I am more interested in the $``\implies""$ direction. $$D_{KL}(g;f)=\int_{\mathbb R} \log\left(\frac{g(x)}{f(x)}\right)g(x)dx=0$$ I don't quite graps how this implies $f=g$ a.e. 
The logarithm is not non-negative, and hence I don't know how to proceed. I've read this follows from Gibb's inequality but I haven't been able to see how. Thanks in advance for any help.","['entropy', 'statistics', 'probability-distributions', 'probability-theory']"
3646259,What is a distribution,"I am studying the basics of geometrical control theory, and I am struggling with some concepts. At the moment I am studyng the concept of distribution . So far I have understood that a distribution is a law that associates to each point $x$ a subspace of the teangent space of $x$ : $$\Delta : x \rightarrow \Delta (x)\subset T_x\mathbb{R}^{n}$$ but I cannot grasp the concept. For example, if I consider a distribution: $$\Delta (x)=\begin{pmatrix}
x_1 & 1\\ 
x_1x_3 &x_1 \\ 
0 &0 
\end{pmatrix}$$ if I consider the definition, it should associate to each point a subspace, but what does it mean? Maybe each column of the distribution if a vector, and so a collection of vectors defines a subspace? This that I just said is just a reasoning I did, so I am not sure. Moreover, I have studied that a distribution is given by a set of independet vectors: $$\Delta (x)=\operatorname{span}[f_1(x),....,f_n(x)]$$ which I think is has to be true, otherwise they won't define a space. But I am also confused by the fact that each vectors is associated to a point, so if I take each vector by itself, I have a space with more vectors associated to points. After this, the notes of my professor start describing costant rank distributions and integrable distributions, which are hard to understand for me at this point, considering that I have not clear the concept of distribution. Can somebody please help me?","['dynamical-systems', 'control-theory', 'differential-geometry']"
3646300,A subtle problem regarding tangent line when gradient is zero,"In the section of ""Applications of Partial Derivates"" in Adams' calculus book, 7th edition, page 756, there is a part which talks about ""Lagrange Multipliers"".
It says: Suppose that $f$ and $g$ have continuous first partial derivatives near the point $P_0=(x_0,y_0)$ on the curve $C$ with equation $g(x,y)=0$ . Suppose also that, when restricted to points on $C$ , the function $f(x,y)$ has a local maximum or minimum value at $P0$ . Finally suppose that: (i) $P_0$ is not an endpoint of $C$ , and (ii) $∇g(P_0)≠0$ , Then there exists a number $λ_0$ such that $(x_0,y_0,λ_0)$ is a critical point of the Lagrangian function $L(x,y,λ)=f(x,y)+λg(x,y)$ . Proof: Together (i) and (ii) imply that $C$ is smooth enough to have a tangent line at $P_0$ … Can someone explain why the first sentence of the proof is true? I mean why is it that (i) and (ii) imply that $C$ is smooth enough to have a tangent line? Note that my main problem is with (ii). What happens to the smoothness and tangent line when $∇g(P_0)$ is zero and what difference does it make when it is non-zero? Is it a necessary condition for smoothness of $C$ on $P_0$ that $∇g(P_0)≠0$ ? Any help on the relevance of (ii) to the smoothness of $C$ on $P_0$ would be highly appreciated.","['multivariable-calculus', 'lagrange-multiplier']"
3646344,Find the interval of convergence of a power series with a single endpoint,"The given series is: $$\sum^\infty_{n=0}\left(x^{2n+1}+2x^{2n+2}\right)$$ I know that the interval of convergence can be found by the ratio test, so what I tried was: $$\lim_{n \to \infty}\frac{x^{2n+3}+2x^{2n+4}}{x^{2n+1}+2x^{2n+2}}=x^2$$ Now we know that $-1<|x^2|<1$ or just $x<1$ . Then solving for the single endpoint: $$\sum^\infty_{n=0}\left(1^{2n+1}+2^{2n+2}\right)$$ $$\lim_{n\to\infty}1^{2n+1}+2^{2n+2}=\infty$$ So the endpoint diverges, and the interval is $(-\infty,1)$","['power-series', 'limits', 'calculus', 'ordinary-differential-equations']"
3646355,Proving the uniqueness of a solution to $f(x-f(y)) = f(f(y)) + xf(y) + f(x) - 1$ [duplicate],"This question already has an answer here : Let $f:\mathbb{R}\to\mathbb{R}$ satisfy $f\big(x-f(y)\big)=f\big(f(y)\big)+x\cdot f(y)+f(x)-1$ for all $x,y\in\mathbb{R}$. (1 answer) Closed 4 years ago . Determine all functions $f: \mathbb{R} \rightarrow \mathbb{R} $ satisfying $f(x-f(y)) = f(f(y)) + xf(y) + f(x) - 1$ I have solved this by doing the  substitution $x \rightarrow 2f(y)$ and then replacing $x$ back. I get $f(x) = 1 -  \frac{x^2}{2}$ Now, I want to find all the other functions satisfying the equation or prove that this is the only solution. This is just like the question I have already asked, with the difference being that this functional equation has two variables alongwith some nested functions. From the approach in the answer to that question, I tried assuming another function $g$ satisfying the equation and then try to prove that $h = f - g$ is a constant function with value $0$ . But, I am unable to do that in this case. Also, there aren't many constraints on the function except it being from $\mathbb{R} \rightarrow \mathbb{R} $ . How can I even approach the problem in this case? Are there any methods involving calculus?","['functional-equations', 'calculus', 'functions']"
3646361,Prove that $F\in L^1(\mathbb{R})$,"Let $f\in L^1(\mathbb{R})$ and continuous on $\mathbb{R}$ such that its Fourier transform $\hat f$ equals zero in a neighborhood of zero. Let $F$ be function such that $\hat F$ exists and $$\hat f(x) =x\hat F(x),\quad \forall x\in \mathbb{R}$$ Prove that $F\in L^1(\mathbb{R})$ . Any hints on how to prove that? Thanks!","['fourier-transform', 'lebesgue-integral', 'functional-analysis']"
