question_id,title,body,tags
439062,Summation of series $\sum_{n=1}^\infty \frac{n^a}{b^n}$?,"How can we evaluate this series 
$$\sum_{n=1}^\infty \frac{n^a}{b^n}?$$ Here $a$ and $b$ are positive integers.
If $b=1$ then series will be diverging,
in other cases, it will be converging, but how to find this sum? Isn't there a simple solution which doesn't involve Stirling numbers?","['divergent-series', 'convergence-divergence', 'sequences-and-series', 'summation']"
439105,An odd question about induction.,"Given $n$ $0$'s and $n$ $1$'s distributed in any manner whatsoever around a circle, show, using induction on $n$, that it is possible to start at some number and proceed clockwise around the circle to the original starting position so that, at any point during the cycle, we have seen at least as many $0$'s as $1$'s:","['induction', 'binary', 'combinatorics']"
439127,Solve first order matrix differential equation,"If I have a differential equation $ y'(t)=A y(t)$ where A is a constant square matrix that is not diagonalizable(although it is surely possible to calculate the eigenvalues) and no initial condition is given. And now I am interested in the fundamental matrix. Is there a general method to determine this matrix? I do not want to use the exponential function and the Jordan normal form, as this is quite exhausting. Maybe there is also an ansatz possible as it is for the special case, where this differential equation is equivalent to an n-th order ode. 
I saw a method where they calculated the eigenvalues of the matrix and depending on the multiplicity n of this eigenvalue they used an exponential term(with the eigenvalue) and in each component an n-th order polynomial as a possible ansatz. Though they only did this, when they were interested in a initial value problem, so with an initial condition and not for a general solution. I was asked to deliver an example: so $y'(t)=\begin{pmatrix} 3 & -4 \\ 1 & -1 \end{pmatrix} y(t)$ If somebody can construct a fundamental matrix for this system, than this should be sufficient","['ordinary-differential-equations', 'calculus', 'real-analysis']"
439130,$f$ integrable but $f^2$ not integrable,"At this point in Bartle, $X$ is a nonempty set, $\mathcal{X}$ is a $\sigma$-algebra of subsets of $X$, and $\mu$ is a measure on $\mathcal{X}$. $f\in L(X,\mathcal{X},\mu)$ means: $f:X\to R$ is measurable. $\int f^+\,d\mu<+\infty$ and  $\int f^-\,d\mu<+\infty$. $\int f\,d\mu=\int f^+\,d\mu-\int f^-\,d\mu$. Can someone share a couple of counterexamples: $f\in L(X,\mathcal{X},\mu)$, but $f^2\not\in L(X,\mathcal{X},\mu)$ $f, g\in L(X,\mathcal{X},\mu)$, but $fg\not\in L(X,\mathcal{X},\mu)$ Thanks.",['measure-theory']
439133,What is a rational trigonometric function? Is $\cos x$ rational?,"I am reading Trigonometry by Gelfand and Saul. On p.140 they discuss rational trigonometric functions and define one as: A rational trigonometric function is a function you can get by taking the sine and cosine of various angles, together with all the constant functions, and adding, subtracting, multiplying or dividing them. I want to check my understanding of what exactly is meant by a rational trigonometric function. Is $\tan x$  rational because $\tan x = \dfrac{\sin x}{\cos x}$? (You take the sine and cosine of $x$ and divide) $\sin(x+y)$ is rational because $$\sin(x+y) = \sin x \cos y + \cos x \sin y$$ (You take the sine and cosine of $x$ and $y$ and there is multiplication and addition). $\sin x$ is not rational (because you are just taking the sine of $x$, and there is no multiplication, division, addition or subtraction). $\cos x$ is not rational for the same reason. $\sqrt{2} \sin\alpha$ is not rational either. Are my thoughts about rational trigonometric functions along the right lines?","['trigonometry', 'terminology']"
439155,Point evaluation of a linear functional on an Ultrapower,"Let $E$ be a Banach space and $(E)_{\mathcal U}$ be an ultrapower for some ultrafilter $\mathcal U$ on an index set $I$. It is remarked in a paper that $(E')_{\mathcal U}$ can be naturally embedded into $(E)_{\mathcal U}'$ (where I use $'$ to indicate the normed space dual). I just want to clarify that this natural embedding is given by the following action. $$(\varphi_{i})_{\mathcal U}:(x_{i})_{\mathcal U}\mapsto \lim_{i\to\mathcal U}\varphi_{i}(x_{i})$$ Is this correct?  (sorry if I chose poor tags) $\bf{\text{Definition}}$: $\lim_{i\to \mathcal U}x_i = x$ in a topological space $X$ if for every neighbourhood $U$ of $x, \{i\in I : x_i\in U\}\in \mathcal U$.","['functional-analysis', 'model-theory']"
439158,Small question about ODE,"i have this question : Given  three parameters $L,a$ et $\alpha$, we consider the
  differential equation : $$(E)\qquad x''+\alpha x' +a x + \sin x =L, \ 
> t\geq0$$ 1) Show that the maximal solutions of $(E)$ are defined on all $\mathbb {R}$. 2) Assume that $a>0$ et $\alpha \geq 0$. a) Establish the existence of a positive constant $C$ such that : $\displaystyle \frac{a}{4}x^2+\frac{y^2}{2}\leq C+1+\frac{L^2}{a^2}$ (You can use the functional $V(x,y)=\frac12 y^2+\frac{a}{2}x^2-L
 x-\cos x)$ I suppose that $y(t)=x'(t)$ , i have $\frac{dV}{dt}=-\alpha y^2$ so $V$ is decreasing but i don't know how to prove the existence of a positive $C$ such that :$\displaystyle \frac{a}{4}x^2+\frac{y^2}{2}\leq C+1+\frac{L^2}{a^2}$ I just find that : $\displaystyle\frac{y^2}{2}+\frac{a}{4}x^2 \leq V(x_0;y_0) + 1 + Lx-\frac{a}{4}x^2$ but how to find $\displaystyle\frac{L^2}{a^2}$ ?????????? Please help me Thank you .","['dynamical-systems', 'ordinary-differential-equations', 'analysis']"
439175,"""Essential"" open sets for sieves in topology as Grothendieck topology and T1 axiom","Call an open set essential to a generating set of a sieve if the sieve generated upon exclusion of that open set is smaller. Given a topological space $X$ and nonempty open set $U,$ consider the proposition: There exists a set $S\ni U$ generating a sieve covering $X$ to which $U$ is essential. If $X$ is T1 (one-point sets are closed), then this proposition is true: choosing a point $p\in U,$ consider $U$ together with $X-\{p\}.$ This generates a sieve covering $X,$ and upon exclusion of $U,$ generates no open sets containing $p.$ If $X$ is the two-point set $\{0,1\}$ with topology $\{\emptyset,\{0\},X\},$ then the proposition is not true for $U=\{0\}:$ any set $S$ generating a sieve covering $X$ would have $X$ itself as an element, and $X$ is enough to generate the entire topology as a sieve. My question is: is the proposition Every nonempty open set $U$ is essential to some set generating a sieve covering $X$ equivalent to the T1 axiom? If not, is it equivalent to some weaker separation axiom? This came up when poring through the definitions in a friend's attempt to generalize the functor $\text{Spec}:\text{Rng}\to\text{Top}$ to a functor $\text{Spec}:\mathcal{C}\to\mathcal{D}$ for any category $\mathcal{C}$ with arbitrary products and Grothendieck topology $\mathcal{D}.$","['general-topology', 'category-theory']"
439177,Summing Finitely Many Terms of Harmonic Series: $\sum_{k=a}^{b} \frac{1}{k}$,How do I calculate sum of a finite harmonic series of the following form? $$\sum_{k=a}^{b} \frac{1}{k} = \frac{1}{a} + \frac{1}{a+1} + \frac{1}{a+2} + \cdots + \frac{1}{b}$$ Is there a general formula for this? How can we approach this if not?,"['sequences-and-series', 'harmonic-numbers']"
439205,How can I solve this Initial Value Problem using the Euler method?,"My Problem is this given Initial Value Problem : $$y^{\prime}=\frac{3x-2y}{x}\quad y(1)=0$$ I am looking for a way to solve this problem using the Euler method . I have a given Interval of $[1,2]$ and a given step size $h$ of $h=0.1$ My Approach was: I can see, this is a differential Equation of first-order. I have one given initial condition $y(1)=0$. So this must be a initial value problem of first order.
For the Euler Method, we need a step size of $h>0$. So our $0.1$ seems to be okay. Next thing, should be calculating: $$t_k=t_0+kh, \quad \quad k=0,1,2,\dots $$
And this is the point where i think i am stuck. I failed in calculating this and after reading the definitions i didn't succeed in making the connection from this method towards a solution for my given initial value problem, at all.","['ordinary-differential-equations', 'integration']"
439210,Is the following $2$-form exact? What about the restriction of $\omega$ to another surface?,"I am not very good at working with $2$-forms, though I'm hoping to learn. I found this problem and have trouble starting it. I also do not know what a restriction would look like. Is the $2$-form $\omega = z\,  dx \wedge dy$ an exact form in $\mathbb{R}^3$? Is the restriction of $\omega$ to the surface $N = \{(x,y,z): z -x^2 - y^2 = 1\}$ exact? Any suggestions are appreciated!",['differential-geometry']
439212,Name of the $(-1)^n$ function?,"Does the function $f\left(n\right)=\left(-1\right)^n, n \in \mathbb{Z}$ used in a lot of mathematical formulas have a special name ? EDIT: The context of this question is that I need a name for this function in a software.","['exponentiation', 'functions', 'analysis']"
439220,What is the difference between square of sum and sum of square?,What is difference between square of sum $(\sum_{i=1}^{n}x_i)^2$ and sum of square $\sum_{i=1}^{n}x_i^2$? I think square of sum is bigger than sum of square but i can not find a relation between them. I mean: $$\left(\sum_{i=1}^{n}x_i\right)^2=\sum_{i=1}^{n}x_i^2+?$$,['calculus']
439228,How to construct a vector field under these conditions?,"Task: Construct a vector field $v:\mathbb{R}^2\rightarrow \mathbb{R}^2$ such that all the circles that ""touch"" y-axis in the origin (i.e. derivative in $(0,0)$ is in form $(0,a)$ for some $a$) are field lines of this field, and this vector field has to be continuously differentiable. My thoughts: It could look like this (up to direction): At first I consider the case $x>0$ (the right half of the plane). My idea was to parametrize each circle that ""touches"" y-axis as follows: $$\begin{align}x-r&=r\cdot \cos(t)\\y&=r\cdot \sin(t)\end{align}$$ and it implies $$\begin{align}x&=r\cdot( \cos(t)+1)\\y&=r\cdot \sin(t)\end{align}$$ Also for each point $(x,y)$ in $\mathbb{R}^2$ ($x>0$) there is only one $r$ such that $(x-r)^2+y^2=r^2$: $$\begin{align}
(x-r)^2+y^2&=r^2\\
x^2-2xr+r^2+y^2&=r^2\\
x^2-2xr+y^2&=0
\end{align}
$$ and thus $r=\frac{x^2+y^2}{2x}$. If I want all those circles to be the field lines, I have to set the values of $v$ to be the derivatives of the curve: $$\frac{d}{dt}c(t)=\frac{d}{dt}(r\cdot(\cos(t)+1),r\cdot\sin(t))=(-r\sin(t),r\cos(t))$$ So the vector field $v$ could be $$v(x,y)=v(r\cdot(\cos(t)+1),r\cdot\sin(t))=(-r\sin(t),r\cos(t))=(-y,x-r)=(-y,x-\frac{x^2+y^2}{2x})=(-y,\frac{x^2-y^2}{2x})$$ This $v$ is actually the function plotted above. So the question is now whether this function is continuously differentiable or not. The critical point is when $x$ is close to $0$. If we take a look at partial derivative, then $$\partial_xv=(0,\frac{x^2+y^2}{2x^2})$$ and it diverges when $x\rightarrow 0$, so it seems that this $v$ is not suitable, but I think the real $v$ should be somehow similar to the given $v$. But these are only my considerations that for sure can be wrong. I'd appreciate your help.",['multivariable-calculus']
439231,"If every ascending chain of primary ideals in $R$ stabilizes, is $R$ a Noetherian ring?","A commutative ring $R$ is called Noetherian if every ascending chain of ideals in $R$ stabilizes, that is,
$$
I_1\subseteq I_2\subseteq I_3\subseteq\cdots
$$
implies the existence of $n\in\mathbb{N}$ such that $I_n=I_{n+1}=I_{n+2}=\cdots$. My question is the following: Does there exist a non-Noetherian ring $R$ such that every ascending chain of primary ideals stabilizes? Remark. Note that there exists non-Noetherian ring $R$ such that every ascending chain of prime ideals stabilizes. This happens exactly when $R$ is non-Noetherian and $\operatorname{Spec}(R)$ is Noetherian topological space. See here and Exercise 12 of Chapter 6 in Introduction to Commutative Algebra by Atiyah & Macdonald.","['commutative-algebra', 'ideals', 'abstract-algebra']"
439237,Are there infinitely many $n$ such that $n$ and $2n+1$ are both prime numbers?,"It seems that there are many such $n$. For example, the following are such $n$'s under $4000$. 2 3 5 11 23 29 41 53 83 89 113 131 173 179 191 233 239 251 281 293 359 419 431 443 491 509 593 641 653 659 683 719 743 761 809 911 953 1013 1019 1031 1049 1103 1223 1229 1289 1409 1439 1451 1481 1499 1511 1559 1583 1601 1733 1811 1889 1901 1931 1973 2003 2039 2063 2069 2129 2141 2273 2339 2351 2393 2399 2459 2543 2549 2693 2699 2741 2753 2819 2903 2939 2963 2969 3023 3299 3329 3359 3389 3413 3449 3491 3539 3593 3623 3761 3779 3803 3821 3851 3863 3911 But my question is, is it known that there are infinitely many such $n$?",['number-theory']
439263,Sum of the arctangents of roots of a cubic equation (multiple choice),"If $A$ , $B$ , and $C$ are the roots of the equation $x^3+mx^2+3x+m=0$ , then the value of $$\arctan(A)+\arctan(B)+\arctan(C)$$ is given by A. $n\pi$ B. $n\pi/2$ C. $\pi(2n+1)/2$ D. none I met this question in JEE Exams of GOIIT but my human ability couldn't solve and I messed up on this question despite being a multiple choice question.","['trigonometry', 'polynomials']"
439264,definition of convergence of a spectral sequence,"In Lecture Notes in Algebraic Topology by Davis & Kirk, on page 241, there is written: What do $E^\infty$ and $\lim_{r\to\infty}E^r_{p,q}$ mean? If a spectral sequence is not first-quadrant and is not bounded (each diagonal having only finitely nonzero modules), such as the Leray-Serre-Atiyah-Hirzebruch spectral sequence, how is convergence defined? Shouldn't condition 1 be written so that we get an isomorphism $E^r_{p,q}\cong E^{r+1}_{p,q}$ instead of only a surjection?","['algebraic-topology', 'abstract-algebra', 'homological-algebra', 'spectral-sequences', 'commutative-algebra']"
439266,Fourier series for $[x]-x+\frac{1}{2}$,"$[x]-x+\frac{1}{2}$ has the Fourier series $$\sum_{n=1}^{\infty} \frac{\sin{2n\pi x}}{n\pi}.$$
By evaluating the series directly, which requires some work, it can be shown that the series is convergent to $[x]-x+\frac{1}{2}$ if $x$ is not an integer. My question is, do we have any criteria by which we can easily see that $$[x]-x+\frac{1}{2}=\sum_{n=1}^{\infty} \frac{\sin{2n\pi x}}{n\pi}$$ when $x$ is not an integer?","['fourier-series', 'analysis']"
439275,How to show $f$ is homogeneous of degree $p$ on an open $S$.,"Let $f:S\subseteq \Bbb R^n\to\Bbb R$. One can prove that if $f(\lambda {\bf x})=\lambda^pf({\bf x})$ for each ${\bf x}\in S$ such that $\lambda {\bf x}\in S$, then ${\bf x}\cdot \nabla f({\bf x})=pf({\bf x})$. The proof is not complicated: one defines the function $\varphi(\lambda)=f(\lambda {\bf x})$ for a fixed ${\bf x}$ and evaluates $\varphi'(1)$ in two different ways. I'd like to get a hint to prove the converse: if ${\bf x}\cdot \nabla f({\bf x})=pf({\bf x})$ for each ${\bf x}\in S$, $S$ open, then $f$ is homogeneous of degree $p$ in $S$. This problem is on Apostol's Mathematical Analysis.",['multivariable-calculus']
439281,Probability of an event happening N or more times,"I need to determine the probability of an event happening N or more times over M iterations. I know the probability of the event in question happening and its likelihood does not change over time. For example, say I am rolling a six-sided die and I want to know what is the probability that over the course of 100 rolls I'll roll a 1 or a 2 at least 75 times? Is there a nice and tidy formula for computing such probabilities? Thanks",['probability']
439289,Sum of the first n Prime numbers,"Let $P_i$ denote the i-th prime number. Is there any formula for expressing $$S= \sum_{i=1}^m P_i.$$ We know that there are around $\frac{P_m}{\ln(P_m)}$ prime numbers less than or equal to $P_m$. So, we have: $$S\le m\times P_m\le \frac{P_m^2}{\ln(P_m)}.$$ I want to know, if there is a better bound for $S$, in the litrature.","['prime-numbers', 'summation', 'number-theory']"
439298,"For a convex function, the average value lies between $f((a+b)/2)$ and $(f(a) + f(b))/2$","Suppose that $f\in C^2$, $f''(x)\geq 0$ $\,\,\,\forall x \in [a,b]$. I want to show that $$\frac{1}{2}(b-a)(f(a)+f(b))\leq \int_a^bf(t)\,dt\leq (b-a)f\left(\frac{a+b}{2}\right).$$If we divide by $b-a$, we see that the left term is less than the right term by definition of convexity, and it remains to show that the average value of the function lies between $f\left(\frac{a+b}{2}\right)$ and $\frac{1}{2}(f(a)+f(b))$. The mean value theorem for integrals implies that the average value is attained at some point $c\in (a,b)$. But it's not clear to me why $f(c)$ should lie in between two other points. Perhaps there's another theorem about integration we should apply. Any ideas?","['calculus', 'integration', 'derivatives']"
439302,Interesting Differentiation Technique,"@HansEngler Left the following response to this question regarding ""bad math"" that works, Here's another classical freshman calculus example: Find $\frac{d}{dx}x^x$. Alice says ""this is like  $\frac{d}{dx}x^n = nx^{n-1}$, so the answer is $x x^{x-1} = x^x$.""
  Bob says ""no, this is like  $\frac{d}{dx}a^x = \log a \cdot a^x$, so the answer is $\log x \cdot x^x$."" 
  Charlie says ""if you're not sure, just add the two terms, so you'll get partial credit"". The answer  $\frac{d}{dx}x^x = (1 + \log x)x^x $ turns out to be correct. In this comment , @joriki asserts that this is not ""bad math"" but rather a legitimate technique, You get the derivative of any expression with respect to $x$ as the sums of all the derivatives with respect to the individual instances of $x$ while holding other instances constant. I had never previously seen such a technique so naturally I tested it on a few examples, including $\frac{d}{dx} \left( x^{ \sin x}\right)$, etc. and it provided the correct result. The following three questions arose, $ \ \ $ 1. What is the proof of its is validity? $ \ \ $ 2. Are there any examples where this technique outshines standard methods?","['calculus', 'derivatives']"
439316,"$f$ measurable, $f=g$ almost everywhere, complete measure space [duplicate]","This question already has an answer here : Counterexample for a non-measurable function? (1 answer) Closed 10 years ago . Let $X$ be a nonempty set, $\mathcal{X}$ a $\sigma$-algebra of subsets of $X$, and $\mu$ a measure on $\mathcal{X}$ (i.e., $\mu:X\to[0,+\infty]$, $\mu(\phi)=0$, and $\mu$ is countably additive. Proposition: If $f:X\to R$ is a measurable function, $f=g$ almost everywhere, then $g$ is a measurable function. Can this proposition be proved in the the measure space is not complete ($\mathcal{X}$ contains all subsets of measure zero)? If not, can someone provide a counterexample? Thanks.",['measure-theory']
439327,"Two numbers are randomly selected from the set {0,1,2,3,4,5,6,7} without replacement","What is the probability that the sum of the two numbers is 7? [what i did] 0+7 
1+6 2+5 
4+3 my ans:  4/8 Is this right or wrong? Does without replacement mean we can't use the same number twice? IE: 4+2 AND 2+4? Thanks for the help",['probability']
439329,Why do we multiply in tree diagrams?,"In probability, we always lay out the events through tree to see what depends on what. Then we were taught to ""multiply"" through that branch to get the probability of that event. Why do we ""multiply""? I've noticed we have the same sort of rule in calculus too (chain rule) EDIT : I think my question was misinterpreted. I am asking just because we put a number (usually - if not almost fractional) beside a branch, why must we ""multiply"" through that number or that ""thing"" if I am being more abstract. Where ""thing"" could even mean a derivative operator $$\partial / \partial x$$",['probability']
439332,verifying differential equation solution with sage,"I solved the linear ODE system of equations:
\begin{equation}
x' = \begin{pmatrix}3&0&4\\0&2&0\\0&0&-3\end{pmatrix}x
\end{equation} Skipping the details I got the following eigenpairs: \begin{align}
\lambda_0=3, x_0=\begin{pmatrix}1\\0\\0\end{pmatrix}&\\
\lambda_1=2, x_1=\begin{pmatrix}0\\1\\0\end{pmatrix}&\\
\lambda_2=-3, x_2=\begin{pmatrix}\frac{2}{3}\\0\\1\end{pmatrix}&
\end{align}
Thus the general solution is:
\begin{equation}
x(t) = c_1e^{3t}\begin{pmatrix}1\\0\\0\end{pmatrix} + c_2e^{2t}\begin{pmatrix}0\\1\\0\end{pmatrix}+c_3e^{-3t}\begin{pmatrix}\frac{2}{3}\\0\\1\end{pmatrix}
\end{equation}
Here is what I got from sage: sage: t = var('t') 
sage: x = function('x', t)
sage: y = function('y', t)
sage: z = function('z', t)
sage: de1 = diff(x, t) -3*x -4*z == 0
sage: de2 = diff(y, t) -2*y == 0                                            
sage: de3 = diff(z, t) +3*z == 0                                            
sage: desolve_system([de1, de2, de3], [x, y, z])                            
[x(t) == 1/3*(3*x(0) + 2*z(0))*e^(3*t) - 2/3*e^(-3*t)*z(0),                 
 y(t) == e^(2*t),                                                           
 z(t) == e^(-3*t)*z(0)] So my solution looks fine in terms of $y(t)$ and $z(t)$ but my $x(t)$ is different in the coefficient of $e^{3t}$ Why does sage give a different answer? Specifically: Did I solve the system incorrectly? Did sage choose different eigenvectors? Is sage only giving me a nicer scaling of the eigenvectors? All help is greatly appreciated!","['sagemath', 'linear-algebra', 'ordinary-differential-equations']"
439344,What's the mean of all real numbers?,"At first, I had thought the average must be zero, since for every positive number there's an equal magnitude negative number to cancel out the positive number's effect on the average, leaving only zero to set the average. But you can make a similar argument about any number, for example using an arbitrary choice of 9, for every number x units greater than 9, there's another number x units less than 9, which would make 9 the mean. But since I could have chosen any number here instead of 9 that would mean that any and every number is the average of all real numbers. So, what is the mean of all real numbers?","['average', 'real-analysis']"
439356,A theorem about operator theory,"Define $$\operatorname{Ref}\mathcal{S}=\{T\in B(\mathcal{H}):Th\in[\mathcal{S}h], \forall h \in \mathcal{H}\},$$where $\mathcal{H}$ is a Hilbert space and $\mathcal{S}$ is a linear manifold of $B(\mathcal{H})$. A proposition of Conway's book A Course in Operator Theory says that $\operatorname{Ref}\mathcal{S^\ast}=(\operatorname{Ref}\mathcal{S})^\ast$ and the proof is left as an easy exercise. It is not easy for me, thanks to the one who can tell me a proof or give me a hint.","['operator-theory', 'operator-algebras', 'functional-analysis']"
439361,What is first set theory or logic?,"I know this question is a cliché but this is something I just cannot understand. This is my context: We define logic so we can define a formal language and then set theory, but to define logic we need set theory. So, which came first, the chicken or the egg? This is my attempt to understand this dilemma. We take a system of axioms  (must probably ZF) that we might call
meta-set theory and using the basic rules of logic and
meta-mathematics (natural numbers, recursion, etc.) we develop a
formal language and then, under such rules of language we construct
the theory of logic, then we define set theory formally (again ZF but
formally) and finally all the mathematical structures. (In this case
I'd say ZF is both a system  of axioms(a meta-theory) and also a
formal theory). This would be something tricky that avoids answering the question because we take as given both
meta-logic and meta-set theory at the same time (or at least the question of asking which was first loses all sense and interest).","['logic', 'elementary-set-theory']"
439369,"Given that $\cos x =-3/4$ and $90^\circ<x<180^\circ$, find $\tan x$ and $\csc x$","Given that $\;\cos x =-\frac{3}{4}\,$ and $\,90^\circ<x<180^\circ,\,$ find $\,\tan x\,$ and $\,\csc x.$ This question is quite unusual from the rest of the questions in the chapter, can someone please explain how this question is solved? I tried Pythagorean Theorem, but no luck. Is it possible to teach me how to use the circle diagram?",['trigonometry']
439399,Topological proof on discrete topology where $X$ is infinite,"How must I prove this problem?
Let $X$ be an infinite set and let $T$ a topology in $X$ in which all infinite subsets of $X$ are open. Prove: $T$ is a discrete topology in $X$.",['general-topology']
439458,How can I use the Heun's method to solve this first order Initial Value Problem?,"My Problem is this given Initial Value Problem: $$y^{\prime}=\frac{3x-2y}{x}\quad y(1)=0$$ I am looking for a way to solve this problem using Heun's method . I have a given Interval of $[1,2]$ and a given step size of $h=0.1$ The example is already solved with a numerical solution. But i want to know more. See here . After discussing the solution by Eulers Method with a friend, he told me about Heun's method. But we failed to apply it to our example. How would Heun's method be applied to this problem?","['ordinary-differential-equations', 'integration']"
439463,Holomorphic function with zero derivative is constant on an open connected set,"I was wondering about this fact, as I do not know how to prove it correctly. I tried with Cauchy-Riemann, but since they are PDE's I found it hard to show that this is the only thing that can cause this zero derivative","['calculus', 'complex-analysis']"
439471,Topologies coinciding at a point or a set.,"Consider a set equiped with two topologies. What does it mean to say that the two topologies coincide at a point in the set? Is it meaningful to talk about this concept in general. Is it meaningful in the context of metric spaces? p.s. I know what the relative topology is for any subset of a topological space and this concept is a different one, as is apparent from this problem .","['general-topology', 'metric-spaces']"
439493,About convergence of functions in $L_p$,"Suppose we have a sequence of functions $f_n\ge 0$, $f_n\in L^p(\mu)$, $\int f_nd\mu=1$, and $f\ge 0$, $f\in L^p(\mu), \int fd\mu=1$, $0<p<1$  such that $$g_n:=\frac{f_n^p}{\int f_n^pd\mu}\to g:=\frac{f^p}{\int f^p d\mu}\text{ in } L^1(\mu)$$. Would this imply $$\int f_n^p d\mu\to \int f^p d\mu?$$
All I could show is that $\int f_n^p d\mu$ is bounded. Suppose $M_n:=\int f_n^p d\mu\to \infty$. Then $$\mu(g_n>\epsilon^p)=\mu(f_n>\epsilon M_n^{1/p})\le \frac{1}{\epsilon M_n^{1/p}}\to 0$$ which says that $g_n\to 0$ in $[\mu]$-measure which is not possible. I am wondering whether $\int f_n^p d\mu$ should, in fact, converge. Or, is there a counter-example to disprove this?","['measure-theory', 'functional-analysis', 'real-analysis']"
439503,Prove that $\cot(A+B)=\frac{\cot A\cot B-1}{\cot A+\cot B}$,"The question is: Prove that:
  $$ \cot(A+B)=\frac{\cot A\cot B-1}{\cot A+\cot B} $$ I have tried expanding it as $\dfrac{\cos(A+B)}{\sin(A+B)}$ and $\dfrac{1}{\tan(A+B)}$.","['trigonometry', 'algebra-precalculus']"
439517,Unknown symbol '#' in set,"I am reading a text on Complexity theory. There is a set whose notation I cannot understand: ""Let $\sum$ =  {0,1,#}"" From the context, and given that the book is used computer science courses, it seems like $\sum$ is the set which contains all combinations of bit strings up to length '#'. In the text, a subset of $\sum$ is being used to define a set of palindromes in a Turing machine. I would like to know more about this # symbol. Another notation that I don't understand is in the following expression: $x \in \{0,1\}^{n/4}$ What is the purpose of the $n/4$?","['notation', 'turing-machines', 'computational-complexity', 'elementary-set-theory']"
439523,How do I write a sum of cosines as a product of sines?,"I am trying to prove that 
$$\cos A+\cos B+\cos C=4\sin\frac A2\sin\frac B2\sin\frac C2$$ for ABC is a triangle.
I tried up to the stage of
$$-2\sin^2 C+2\cos\frac{180-C}2 \cos\frac{A+B}2$$ 
but how do I proceed from here?",['trigonometry']
439548,Inequality on Shannon's entropy,"Let $P$ be a set of probabilities s.t. $\sum_{p_i \in P} p_i = 1$. Moreover, let $H(P)$ the Shannon's entropy of the set of probabilities $P$:
$$
H(P) = -\sum_{p_i \in P} p_i \log_2 p_i
$$ I define a set of actions $a_1, \ldots, a_N$ which modify the set of probabilities $P$. Performing an action. When $a_i$ is asked: Some of the probabilities are removed from $P$ $P$ is normalized so that its summation is still 1 In this context, I define $H_{i}(P)$ as the Shannon's entropy of the new set $P$. Performing two actions. When $a_j$ is asked after $a_i$: Some of the probabilities are removed from $P$ as a consequence of $a_i$ $P$ is normalized so that its summation is still 1 Some of the probabilities are removed from the new $P$ as a consequence of $a_j$ $P$ is normalized again The final Shannon's entropy is $H_{j}(P | a_i)$. Proof? Now, suppose I choose two actions $a_1$ and $a_2$ such that: 
$$
H_1(P) \leq H_2(P).
$$ 
How to prove whether the following is true (or, if it is not, whether there is a subset of cases in which it is true)?
$$
\forall a_i, i \neq 1,2: H_i(P|a_1) \leq H_i(P|a_2)
$$","['proof-writing', 'probability', 'entropy']"
439549,Proving a Lambert series identity from Ramanujan's Collected Papers,"While studying Ramanujan's Collected Papers I came across an identity $$q(1 + q + q^{3} + q^{6} + \cdots)^{8} = \frac{1^{3}q}{1 - q^{2}} + \frac{2^{3}q^{2}}{1 - q^{4}} + \frac{3^{3}q^{3}}{1 - q^{6}} + \cdots$$ which I am unable to establish (although the identity looks simple). I tried to use the the following identities: $\displaystyle Q(q) = 1 + 240\left(\frac{1^{3}q}{1 - q} + \frac{2^{3}q^{2}}{1 - q^{2}} + \frac{3^{3}q^{3}}{1 - q^{3}} + \cdots\right) = \left(\frac{2K}{\pi}\right)^{4}(1 + 14k^{2} + k^{4})$ $\displaystyle Q(-q) = \left(\frac{2K}{\pi}\right)^{4}(1 - 16k^{2} + 16k^{4})$ $\displaystyle Q(q^{2}) = \left(\frac{2K}{\pi}\right)^{4}(1 - k^{2} + k^{4})$ where we have $q = e^{-\pi K(k')/K(k)}$ and was trying to put the RHS (of the identity to be established) as a combination of the above $Q$ functions but was not able to do so. In this way I thought to transform the RHS in terms of $K, k$ and then reach the LHS which is $q\psi^{8}(q)$ where Ramanujan's $\psi(q)$ is related to Jacobi's theta function via $\vartheta_{2}(q) = 2q^{1/4}\psi(q^{2})$. I was able to write the RHS as $\displaystyle \sum_{n = 1}^{\infty}\frac{n^{3}q^{n}}{1 - q^{2n}} = \frac{1}{2}\sum_{n = 1}^{\infty}\frac{n^{3}q^{n}}{1 - q^{n}} + \frac{1}{2}\sum_{n = 1}^{\infty}\frac{n^{3}q^{n}}{1 + q^{n}} = S_{1} + S_{2}$ where $S_{1}$ can be expresssed in terms of $Q(q)$, but somehow could not express $S_{2}$ in terms of $Q$ functions. Maybe I am on the wrong path. If there is any simpler way to prove the identity please let me know.",['sequences-and-series']
439557,Maximum run of zeros in a $n$-bit binary string,"I came to know that, in a random string, one expects the longest sequence of zeros to be roughly of length $\log n$. I want to be able to prove this.
For this I need to know the probability that the longest sequence of zeros in a random $n$-bit string is of length $k$. Basically I need a good counting strategy to count the number of such $n$-bit strings i.e., where maximum run of zeros is of length $k$. Can somebody give a hint on how to proceed? I don't want a full answer.","['binary', 'probability']"
439571,Diameter of finite set of points is equal to diameter of its convex hull,"Let $M\subset \mathbb{R}^2$ be a finite set of points, $\operatorname{C}(M)$ the convex hull of M and 
$$\operatorname{diam}(M) = \sup_{x,y\in M}\|x-y\|_2$$
be the diameter of $M$ What I want to show now is, that it holds
$$\operatorname{diam}(M) = \operatorname{diam}(\operatorname{C}(M))$$ Because $$M\subseteq\operatorname{C}(M)$$ we obtain $$\operatorname{diam}(M) \le\operatorname{diam}(\operatorname{C}(M))$$ but how to proof that $$\operatorname{diam}(M) \ge \operatorname{diam}(\operatorname{C}(M))$$ I suppose it should be possible to construct a contradiction assuming $\operatorname{diam}(M) <\operatorname{diam}(\operatorname{C}(M))$ but i do not see how at this moment.",['geometry']
439589,proving a sum of binomial coefficients [duplicate],This question already has answers here : Sum with binomial coefficients: $\sum_{k=0}^{n}{2n\choose 2k}$ [closed] (5 answers) Closed 5 years ago . How can i prove that $\displaystyle\sum_{k=0}^{n}{2n\choose 2k}=2^{2n-1}$ I tried  using induction and pascal's identity but it didn't help me.,"['discrete-mathematics', 'binomial-coefficients']"
439596,"Number of $(0,1)$ $m\times n$ matrices with no empty rows or columns",I am looking to calculate the number of $m\times n$ matrices which have no empty rows or columns (at least one $1$ in each row and column). I have looked at the answers to a few similar questions such as 35019 and 329932 but I am struggling to make these approaches work in this case.,"['matrices', 'combinatorics']"
439607,Describe the conjugacy classes of an abelian group,"Describe the conjugacy classes of an abelian group. Each class is singleton set as for an abelian group $ax=xa$ $\forall x, a \in G$ which gives $xax^{-1}=a$ . Am I right?","['group-theory', 'abstract-algebra']"
439615,Simple groups of order 300,"I am aware of No simple group of order $300$ .
It is said that ""there would be 6 Sylow 5-groups, one of which will have an index of 6"", but why does one have index 6? If we write $|G|=p^k m$ where $p\nmid m$, then by Lagrange's theorem any $p$-Sylowgroup has index $m$, which in this case is 12?",['group-theory']
439628,How to obtain this Pohozaev identity for the Gross-Pitaevskii equation?,"The Gross-Pitaveskii equation (after plugging in the traveling wave ansatz and writing in moving frame coordinates) reads \begin{equation} ic\partial_1 v +\Delta v +v(1-\vert v \vert^2)=0.    \end{equation} Assume $v$ is a solution on $\Omega_n^N=[-n\pi,n\pi]^N$ and $v$ is $2\pi n$-periodic in every component. In [1,p.623] the authors give Pohozaev's formula for $v$ without any proof \begin{align} \frac{N-2}{2} \int_{\Omega_n^N} \vert \nabla v \vert^2+\frac{N}{4}\int_{\Omega_n^N} (1-\vert v \vert^2)^2 - c\frac{N-1}{v} \int_{\Omega_n^N} \langle Jv, \zeta_1 \rangle \\ = n\pi \int_{\partial \Omega_n^N} \left( \frac{\vert \nabla v \vert^2}{2} + \frac{(1-\vert v \vert^2)^2}{4} \right) - \int_{\partial \Omega_n^N} \partial_\nu v \left( \sum_{j=1}^N x_j \partial_j v \right). \end{align} Here the 2-form \begin{equation} Jv \equiv \sum_{1 \leq 1 < j \leq N} (\partial_i v \times \partial_j v) dx_i \wedge dx_j \end{equation} denotes the Jacobian of $v$ and $\zeta_1$ is the 2-form defined by \begin{equation} \zeta_1(x) \equiv - \frac{2}{N-1} \sum_{i=2}^N x_i dx_1 \wedge dx_i. \end{equation} Finally, $\langle \cdot, \cdot\rangle$ stands for the scalar product of 2-forms. My Question is : How do you obtain this ""Pohozaev's formula""? From what I have read on the internet already, it seems like you have to multiply the Gross-Pitaevskii equation by $(x|\nabla v(x))$ or similar and integrate by parts. But this doesn't help me too much. How do the 2-forms appear? I'm completly lost. Any hint would be much appreciated! [1] Béthuel, F., P. Gravejat und J. C. Saut: Travelling waves for the Gross- Pitaevskii equation. II. Comm. Math. Phys., 285(2):567–651, 2009.","['partial-differential-equations', 'differential-geometry']"
439636,Geometric visualization of covector?,How could I geometrically visualize a linear functional?,"['analytic-geometry', 'linear-algebra', 'visualization']"
439641,How to solve this special form of multivariate quadratic equations?,"Suppose there are $M$ known real vectors
$$
x^{i}=[x_{1}^{i},x_{2}^{i},\cdots,x_{N}^{i}],i=1,2\cdots,M
$$
in N-dimensional vector space and $M\geq 2N$. I want to know whether they span two orthogonal hyperplanes, that is some of these vectors span one hyperplane while the rest span another and these two hyperplanes are mutually orthogonal (I mean their normal vectors are orthogonal, maybe 'vertical' is a better word). So I write the unknown normal vectors to the two hyperplanes as
$$
n=[n_{1},n_{2},\cdots,n_{N}]\\
m=[m_{1},m_{2},\cdots,m_{N}]
$$
and they are orthogonal
$$
m\cdot n=0
$$
Now if $x$ are all on these two hyperplanes then the following equations must have a solution
$$
(m\cdot x^{i})(n\cdot x^{i})=0
$$
for all $x^{i}$. Expanding the above equations,
$$
(n_{1}x_{1}^{i}+n_{2}x_{2}^{i}+\cdots +n_{N}x_{N}^{i})(m_{1}x_{1}^{i}+m_{2}x_{2}^{i}+\cdots +m_{N}x_{N}^{i})=0\\
\sum_{i=1}^{N}n_{i}m_{i}=0
$$
are multivariate quadratic equations of $n_{i}$ and $m_{i}$. Now my question is: How do I know whether these equations are solvable or not given certain $x^{i}$s? Are there any constraints that can be placed on $x^{i}$s so that these equations have at least one real solution? Solving multivariate quadratic equations is a NP-hard problem in general. But I think this special form maybe not that hard. English is not my mother language so I've tried to explain my question as clear as possible. If there are any confusing points in my description, please leave a comment and I'll answer you as soon as I can. Thank you! Supplement: Maybe an example will help. Consider one vector $x^{1}=[1,1]$ in 2-dimensional real vector space. The above equations should be
$$
(n_{1}+n_{2})(m_{1}+m_{2})=0\\
n_{1}\cdot m_{1}+n_{2}\cdot m_{2}=0
$$
Some simple calculation gives
$$
\frac{n_{1}}{n_{2}}=-\frac{m_{1}}{m_{2}}=-\frac{m_{2}}{m_{1}}=\pm 1
$$
Because only the orientations of $n$ and $m$ are cared about, the ratios between entries are enough to specify the two vectors. Now if we add another vector $x^{2}=[0,1]$ to the original one-vector set, the equations should be
$$
(n_{1}+n_{2})(m_{1}+m_{2})=0\\
n_{2}\cdot m_{2}=0\\
n_{1}\cdot m_{1}+n_{2}\cdot m_{2}=0
$$
This time there is no real solution. It is harder to tell whether there is a real solution for these equations in higher dimensional space.",['multivariable-calculus']
439647,"Re-arranging the equation $d=v_i\,t+\frac{a\,t^2}{2}$ to get $t$ equation?","I'm trying to find $t$ equation by re-arranging the equation 
$\left(d=v_i\,t+\frac{a\,t^2}{2}\right)$
but I'm facing problem because the variable $t$ is existed in two terms. My try (uncompleted solution): $$\begin{align}
d=v_i\,\color{#00F}{t}+\frac{a\,\color{#F00}{t^2}}{2}\\\\
d-\frac{a\,\color{#F00}{t^2}}{2}=v_i\,\color{#00F}{t}\\\\
d-\frac{a\,\color{#F00}{t^2}}{2}=v_i\,\color{#00F}{t}\\\\
\color{#00F}{t}=\frac{d}{v_i}-\frac{a\,\color{#F05}{t^2}}{2\,v_i}\\\\
\frac{\color{#00F}{t}}{1}+\frac{a\,\color{#F00}{t^2}}{2\,v_i}=\frac{d}{v_i}\\\\
\frac{2\,\color{#00F}{t}\,v_i}{2\,v_i}+\frac{a\,\color{#F00}{t^2}}{2\,v_i}=\frac{d}{v_i}\\\\
\color{#00F}{t}\left(1+\frac{a\,\color{#F00}{t}}{2\,v_i}\right)=\frac{d}{v_i}\\\\
\end{align}$$ How can I complete the re-arranging to get $t$ equation ?",['algebra-precalculus']
439649,are elementary symmetric polynomials concave on probability distributions?,"Let $S_{n,k}=\sum_{S\subset[n],|S|=k}\prod_{i\in S} x_i$ be the elementary symmetric polynomial of degree $k$ on $n$ variables.  Consider this polynomial as a function, in particular a function on probability distributions on $n$ items. It is not hard to see that this function is maximized at the uniform distribution.  I am wondering if there is a ""convexity""-based approach to show this.  Specifically, is $S_{n,k}$ concave on probability distributions on $n$ items?","['symmetric-polynomials', 'convex-optimization', 'probability', 'lagrange-multiplier']"
439654,What is the meaning of $f(x) \rightarrow a$ as $g(x) \rightarrow b$?,"The motivating example was the case: $$f(x, y)\rightarrow0\mathrm{\ \ as\ \ }\sqrt{x^2+y^2}\rightarrow\infty$$ What exactly does this mean? I might define it as: Any sequence $x_n$ with $g(x_n)\rightarrow b$ verifies $f(x_n)\rightarrow a$. Is this right? Are there other definitions?","['definition', 'convergence-divergence', 'analysis']"
439658,The ordinary generating function for $ζ(s)$,"$$\zeta(s)^m = \sum_{n=1}^{\infty} \frac{a_n}{n^s}$$ where $ζ(s)$ is the Riemann zeta function has the ordinary generating function: $$\sum \limits_{n=1}^{\infty} a_nx^n = x + {m \choose 1}\sum \limits_{a=2}^{\infty} x^{a} + {m \choose 2}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} x^{ab} + {m \choose 3}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} \sum \limits_{c=2}^{\infty} x^{abc} + {m \choose 4}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} \sum \limits_{c=2}^{\infty} \sum \limits_{d=2}^{\infty} x^{abcd} +... $$
$\tag1$ Wikipedia reference is http://en.wikipedia.org/wiki/Dirichlet_series My Attempt to prove is below But I am stuck $$\zeta(s) = \sum_{n=1}^{\infty} \frac{1}{n^s}=(1+\frac{1}{2^s}+\frac{1}{2^{2s}}+....)(1+\frac{1}{3^s}+\frac{1}{3^{2s}}+....)(1+\frac{1}{5^s}+\frac{1}{5^{2s}}+....)...=\prod_{p= prime} \frac{1}{1-p^{-s}}$$ $$\zeta(s)^m = (\sum_{n=1}^{\infty} \frac{1}{n^s})^m=(\frac{1}{1^s}+\frac{1}{2^s}+\frac{1}{3^s}+.....)^m=\prod_{p= prime}(1-p^{-s})^{-m}=\prod_{p= prime}(1+mp^{-s}+\frac{m(m+1)p^{-2s}}{2!}+\frac{m(m+1)(m+2)p^{-3s}}{3!}+....)$$ If we find all prime factors for $n$ if $n=p^{b_1}_1p^{b_2}_2  p^{b_3}_3... p^{b_r}_r$  then $$a_n=\frac{m(m+1)..(m+(b_1-1))}{b_1!}.\frac{m(m+1)..(m+(b_2-1))}{b_2!}...\frac{m(m+1)..(m+(b_r-1))}{b_r!}$$ I could not see a way after that point how to prove the generation function .
Could you please help me how to get the result shown in Equation $1$ with elementary methods? Thanks a lot for answers","['sequences-and-series', 'special-functions', 'number-theory', 'generating-functions', 'prime-numbers']"
439660,"differential equation, bit off more than i could chew","I started down the path of a project for school that was inspired by mythbusters.  The oritinal thought was showing why a bullet will effectively cease effectiveness past a given depth.  So I'm rocking $F_d = \frac{1}{2}pv^2AC_d$ which we can effectively compress down to $F = Kv^2$ as the rest for my purposes will be constants.  Applying newton's laws to this we turn it into $y' = a / y'' = a$ making $F=ma = my''$, after a little help from a friend we arrive at $y'' = \frac{F}{m} = \frac{K}{m}(y')^2$. Letting $\alpha=\frac{K}{m}$ thus collapsing the problem finally down to $y'' = \alpha(y')^2$ This is the crux of my problem.  Can anyone explain the approach to solving this?  Seems this is a little beyond the calc II course this was originally for.  But seeing as I'm already neck deep in the problem in other ways, I see no point in giving up on it now.",['ordinary-differential-equations']
439671,prove：$\left|x+\frac{1}{x}\right|\geq 2$ [duplicate],This question already has answers here : How to prove this inequality $ x + \frac{1}{x} \geq 2 $ (20 answers) Closed 10 years ago . prove： $\left|x+\frac{1}{x}\right|\geq 2$ Can I just use $\left|\left(\sqrt{x}\right)^2+\left(\frac{1}{\sqrt{x}}\right)^2\right|\geq 2$ and $\left|\left(\sqrt{-x}\right)^2+\left(\frac{1}{\sqrt{-x}}\right)^2\right|\geq 2$?,"['inequality', 'algebra-precalculus']"
439689,"Möbius transform calculation, over an annulus","I started learning about Möbius transformations in my Complex Analysis textbook. This question appeared as an exercise (no solutions are provided, sadly): Let's say you have a Möbius transform that maps the annulus $r<|z|<1$ to a region bounded by two circles (for the sake of example take $|z|=1$ and $|z-1/4|=1/4$). Is this enough information to figure out $r$? What I've tried: Trying to figure out what different compositions of Möbius transforms will affect in here. I was thinking taking the inverse somehow would be a good idea but I couldn't find my way around the details of how I'd do this. I'm stumped, so an explanation of how this is possible would be great. Thanks!","['general-topology', 'mobius-transformation', 'complex-analysis']"
439694,Uniform Law of large numbers,"Could you please help with the proof of the proposition: Let $G(\cdot)$ be bounded, continuous, strictly increasing function on $\mathbb{R}.$ Let ${\xi_t},\, t\in\mathbb{Z}_+$ be i.i.d random variables. Would it be true to say that we have something like the uniform Law of large numbers here? Why?
$$
\sup_{x\in\mathbb{R}}\;\left|\;n^{-1}\sum_{t=1}^n G(x+\xi_t) - \mathbf{E}G(x+\xi_1)\;\right| \stackrel{P}\longrightarrow 0, \quad n\to\infty.
$$ Thanks in advance!","['probability-theory', 'law-of-large-numbers']"
439720,number of binary sets - combinatorics,"Just ran into this question: let $f(n,m)$ be the number of binary strings where there are at most $n$ 1's and at most $m$ 0's. the empty string also counts as a string. show that $f(n,m)=\binom{n+m+2}{n+1}-1$. thanks in advance, Yaron.","['discrete-mathematics', 'binary', 'combinatorics']"
439745,Prove:$|x-1|+|x-2|+|x-3|+\cdots+|x-n|\geq n-1$,"Prove:$|x-1|+|x-2|+|x-3|+\cdots+|x-n|\geq n-1$ example1: $|x-1|+|x-2|\geq 1$ my solution：(substitution) $x-1=t,x-2=t-1,|t|+|t-1|\geq 1,|t-1|\geq 1-|t|,$ square, $t^2-2t+1\geq 1-2|t|+t^2,\text{Since} -t\leq -|t|,$ so proved. question1 : Is my proof right? Alternatives? one reference answer: $1-|x-1|\leq |1-(x-1)|=|1-x+1|=|x-2|$ question2 : prove: $|x-1|+|x-2|+|x-3|\geq 2$ So I guess:( I think there is a name about this, what's that? wiki item?) $|x-1|+|x-2|+|x-3|+\cdots+|x-n|\geq n-1$ How to prove this? This is question3. I doubt whether the two methods I used above may suit for this general case. Of course, welcome any interesting answers and good comments.","['inequality', 'absolute-value', 'algebra-precalculus']"
439749,convexity and lower semi-continuity for weak convergence,"My question is a general one, whose answer can probably be found in any decent convex analysis book. I unfortunately don't have any at hand right now, so here it is: Let's consider a ""reasonable"" Banach space $X$ (say at least reflexive and separable as usual), a convex subset $C\subset X$ and a function $\Phi:C\to\mathbb{R}$ which is continuous for the strong $X$ topology and convex. What do I need to assume for $\Phi$ to be weakly lower-semicontinuous? Clearly differentiability works with the classical trick $x_n\rightharpoonup x$ and $\Phi(x_k)\geq \Phi(x)+D\Phi(x).(x_k-x)$, but I guess there must be less restrictive conditions than differentiability? Thank you!","['convex-analysis', 'analysis']"
439766,Find an equation of each plane tangent to $K$ which is parallel to the plane $x-y+z=1$,"Let $K$ be the cone given by $z=\sqrt {x^2+y^2}$ Find an equation of each plane tangent to $K$ which is parallel to the plane $x-y+z=1$ Sorry for not writing my ideas because I have No idea to solve this, honestly:( There are lots of such questions I need to solve. If somebody show me one of them 's solution, I try to solve others on my own. I wanna learn such type questions. Thank you!","['calculus', 'derivatives', 'real-analysis', 'analysis']"
439769,Inverse image presheaf,"Let $f:X\rightarrow Y$ be a continuous map of topological spaces, and $\mathscr{G}$ a sheaf on $Y$ . So far I failed to come up with a simple example where the presheaf $f^{-1}\mathscr{G}$ on $X$ obtained via the direct limit $$f^{-1}\mathscr{G}(U):=\lim_{f(U)\subset V}\mathscr{G}(V)$$ is not a sheaf. If anyone could give me an example (the simpler the better), it would be greatly appreciated.",['algebraic-geometry']
439776,"Techniques for determining how ""random"" a sample is?","What techniques exist to determine the ""randomness"" of a sample? For instance, say I have data from a series of $1200$ six-sided dice rolls. If the results were 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, ... Or: 1, 1, 1, ..., 2, 2, 2, ..., 3, 3, 3, ... The confidence of randomness would be quite low. Is there a formula where I can input the sequence of outcomes and get back a number that corresponds to the likelihood of randomness? Thanks UPDATE: awkward's answer was the most helpful. Some Googling turned up these two helpful resources: Statistical analysis of Random.org - an overview of the statistical analyses used to evaluate the random numbers generated by the website, www.random.org Random Number Generation Software - a NIST-funded project that provides a discussion on tests that can be used against random number generators, as well as a free software package for running said tests.",['probability']
439786,$\mathbb A^n$ is not a complete quasiprojective variety,Suppose that $\mathbb K$ is an algebrically closed field. In the course of Algebraic Geometry I've attended we gave the following definition (in what follows every space is to be intended on the field $\mathbb K$): Definition. A set $X \subset \mathbb P^N$ is said to be complete iff for every quasiprojective variety $Y$ the projection $\pi_2 \colon X \times Y \to Y$ is a closed map. I would like to prove (as an exercise) that the affine space $\mathbb A^n$ is not complete . If $n=1$ this is very easy: we take $Y=\mathbb A^1$ and we consider the closed subset $Z:=V(x_1x_2-1) \subset \mathbb A^{1}\times \mathbb A^{1}$; the projection onto the second factor $\pi_2(Z) \simeq \mathbb A^{1} \setminus \{0\}$ which is not Zariski closed. Is there an easy trick to adapt this argument to higher dimensional case? How would you prove it? Thanks.,"['general-topology', 'algebraic-geometry']"
439810,Algorithm for lattice of subgroups,In spite of my repeated efforts I have not been able to find the algorithm for calculating lattice of subgroups for any group. GAP does it very well but I need algorithm as I am trying to implement things myself as well.,"['gap', 'group-theory']"
439820,Find the value of $\space\large i^{i^i}$?,Is $\large i^{i^i}$ real ? How to find it? Thank You!,"['complex-numbers', 'calculus', 'algebra-precalculus']"
439821,Example of a restriction of sheaf not being a sheaf,"Let $\mathscr{F}$ be a sheaf on $X$, and $Y\subset X$ a subset. Define a presheaf $\mathscr{F}|_Y$ on $Y$ via the direct limit
$$\mathscr{F}|_Y(V):=\lim_{V\subset U}\mathscr{F}(U),$$
where $V$ is an open subset of $Y$, and $U$ is an open subset of $X$. Clearly $\mathscr{F}|_Y$ is a sheaf if $Y$ is an open subset of $X$. But I can't think of an example where $\mathscr{F}|_Y$ is not a sheaf. Can anyone think of an example?",['algebraic-geometry']
439831,"Is the point $(3, 2, −1, 4, 1)$ in the open ball $B^{5}$ $((1, 2, −4, 2, 3), 3)?$","This is question 11 from the text here . Is the point $(3, 2, −1, 4, 1)$ in the open ball $B^5 ((1, 2, −4, 2, 3),
3)$? In my attempt to solve this question, I took the point, subtracted each corresponding component from the ball's center, and then summed the squares of these values:
$$(3-1)^2+(2-2)^2+(-1-(-4))^2+(4-2)^2+(1-3)^2=21$$ Because $21>r^2$, that is $21>9$, I concluded that the point is not in the open ball.  However, the correct answer is yes, the point is inside the open ball.  (Answers are posted here ) For reference (because it might help explain my confusion) this is the definition of an open ball from the book: The set of all points $(x_1, x_2,...,x_n )$ in $\mathbb{R}^n$ which satisfy the inequality
  $(x_1 − p_1 )^2 + (x_2 − p_2)^2 +...+ (x_n − p_n )^2 < r^2$
  (1.1.15)
  is called an open n-dimensional ball with radius r and center p, which we denote $B^n(\textbf{p},r)$. Can someone help me figure out where I am going wrong?  Thanks! Update: I contacted the author of this textbook, Dan Sloughter, and he promptly corrected the answer guide.  Also, I was using an outdated version of the book/answers.  In case anyone needs them in the future, the updated links are: http://www.synechism.org/wp/the-calculus-of-functions-of-several-variables/ and http://dananne.org/dw/doku.php?id=cfsv:cfsv",['multivariable-calculus']
439851,"Evaluate the integral $\int^{\frac{\pi}{2}}_0 \frac{\sin^3x}{\sin^3x+\cos^3x}\,\mathrm dx$. [duplicate]","This question already has answers here : How to compute $\int_0^{\pi/2}\frac{\sin^3 t}{\sin^3 t+\cos^3 t}dt$? (4 answers) Closed 10 years ago . Evaluate the integral $$\int^{\frac{\pi}{2}}_0 \frac{\sin^3x}{\sin^3x+\cos^3x}\, \mathrm dx.$$ How can i evaluate this one? Didn't find any clever substitute and integration by parts doesn't lead anywhere (I think). Any guidelines please?","['definite-integrals', 'calculus', 'integration']"
439866,Holomorphic Parameter Integral,"Let $U\subseteq\mathbb{C}$ be open, $\gamma$ a way in $\mathbb{C}$ which is picewise differentiable continiously and $f\colon rg(\gamma)\times U\to\mathbb{C}$ a continious function. Consider the parameter integral
    $$
F(z):=\int_{\gamma}f(\omega,z), d\omega, z\in U.
$$
    Show: Let the function $z\mapsto f(\omega,z)$ be holomorphic in $U$ for every $\omega\in rg(\gamma)$ with continious derivation $\frac{\partial}{\partial z}f(\omega,z)$ on $rg(\gamma)\times U$. Then $F(z)$ is holomorphic in $U$, and one can differentiate under the integral:
    $$
F'(z)=\int_{\gamma}\frac{\partial}{\partial z}f(\omega,z)\, d\omega, z\in U
$$ Unfortunately I do not know how to show that.
I know the proof when $f$ is a function with values in $\mathbb{R}$ but cannot proof it here when $f$ has values in $\mathbb{C}$.",['complex-analysis']
439875,General expression for $\sin(2^n x)$,"Are there general expressions for $\sin(2^n x)$ and $\cos(2^n x)$ that only involve $\sin x$ and $\cos x$, and that moreover involve only polynomial (in $n$) number of terms? Edit : $2^n$ is not polynomial in $n$. A proof that no such expression exits (perhaps using the uniquness of Chebyshev polynomials?) would be gladly accepted.","['trigonometry', 'products']"
439883,How to find the smallest positive integer $K$ such that $(K -\lfloor\frac{K}{2}\rfloor + 1)(\lfloor\frac{K}{2}\rfloor + 1) \geq N$,"I am writing a program and I would need an explicit formula for the following: The smallest positive integer $K$ such that: $$\left(K - \left\lfloor\frac{K}{2}\right\rfloor + 1\right)\left(\left\lfloor\frac{K}{2}\right\rfloor + 1\right) \geq N$$ where $N$ is a given integer $> 1$. I tried with
$$K = \left\lfloor 2(\sqrt{N} - 1)\right\rfloor,$$
but it does not seem really correct in general. Can you explain how I can properly get the correct formula?","['modular-arithmetic', 'algebra-precalculus']"
439912,Prove this inequality $a^{\frac{a}{b}}b^{\frac{b}{c}}c\geq1$,"Please help me to prove this inequality. Assume $a,b,c>0$ and $abc\geq1$ then $a^{\frac{a}{b}}b^{\frac{b}{c}}c\geq1$. Thanks.","['inequality', 'algebra-precalculus']"
439913,A question about differentiability,"So, this is the last subject I have to study for my exam on Friday, and I still can not comprehend how to prove that a function is differentable. $$f(x,y) = \begin{cases}
(x^2 + y^2) \cdot \sin \left(\frac{1}{\sqrt{x^2 + y^2}}\right) & \text{ if }(x,y) \neq (0,0),\\
0& \text{ if }(x,y) = (0,0).
\end{cases}$$
  Is $f(x,y)$ differentiable at $(x,y) = (0,0)$? I know that I have to calculate the partial derivative according to the definition and then do another limit, but I do not know the formulas for these. I am very, very sorry for asking such a general question, but I am really in trouble and don't seem to understand it. I would appreciate very much a thorough answer.","['multivariable-calculus', 'calculus', 'derivatives']"
439918,locally compact Hausdorff space which is not second-countable,"I'm trying to find an example of a space that is Hausdorff and locally compact that is not second countable, but I'm stuck. I search an example on the book Counterexamples in Topology, but I can't find anything. Thank you for any help.","['general-topology', 'examples-counterexamples', 'second-countable', 'compactness']"
439928,Show that $B$ it is unbounded,"Let $X$ a Banach space of infinity dimension. Show that any open set $B$, with $B \neq \emptyset$, is unbounded in the weak topology.","['general-topology', 'functional-analysis']"
439939,Can someone explain the intuition behind this moment generating function identity?,"If $X_i \sim N(\mu, \sigma^2) $, we know that: $\bar{X} \sim N(\mu, \sigma^2 /n)$. But why does: $$\exp\left({\sigma^{2}\over 2}\sum_{i=1}^{n}(t_{i}-\bar{t})^{2}\right)= M_{X_{1}-\bar{X},X_{2}-\bar{X},...,X_{n}-\bar{X}}(t_1,t_2,...,t_n)$$ Where $M$ is the moment generating function? I have three pages of scratch work but it would be incredibly tedious to post that here, and I already know it's true... Thanks!","['statistics', 'probability-theory', 'summation', 'probability-distributions', 'probability']"
439941,How many different expressions can you get by inserting parentheses into: $x_{1}-x_{2}-\cdots-x_{n}$?,"I ran into this question and I am finding it very difficult to solve: How many different expressions can you get by inserting parentheses into:
  $$x_{1}-x_{2}-\cdots-x_{n}\quad ?$$ For example: $$\begin{align*}
x_{1}-(x_{2}-x_{3}) &= x_{1}-x_{2}+x_{3}\\
(x_{1}-x_{2})-x_{3}&=x_{1}-x_{2}-x_{3}\\
x_{1}-(x_{2}-x_{3})-x_{4})&=x_{1}-x_{2}+x_{3}+x_{4}\\
\end{align*}$$ I'm really desperate for a full answer. I've been working on this for 3 hours. Thanks in advance.",['combinatorics']
439943,Characterization of compactness in weak* topology,"Let $ X $ be Banach space, and $X^*$ its dual. A set $ F \subset X ^ * $ is weakly-* compact if and only if $ F $ is closed in the weak* topology and is bounded in norm. How does one prove this (well-known) fact? Notes This characterization of compactness in weak* topology is   similar to compactness in finite dimensional spaces, where it is equivalent to being closed and bounded. The analogous statement for  weak topology is false. An example is given in Weakly compact implies bounded in norm :  the closed unit ball of $c_0$ is weakly closed and norm bounded, but not weakly compact.","['general-topology', 'compactness', 'functional-analysis']"
439985,Spivak Calculus on Manifolds Exercise 2-9,"I'm kind of stumped on this exercise in two spots. First I'll state the problem: Two functions $f,g : \mathbb{R} \to \mathbb{R}$ are equal up to $n$th order at $a$ if $$\lim_{h \to 0} \frac{f(a + h) - g(a + h)}{h^n} = 0$$ (a) Show that $f$ is differentiable at $a$ if and only if there is a function $g$ of the form $g(x) = a_0 + a_1(x-1)$ such that $f$ and $g$ are equal up to the first order at $a$. (b) If $f'(a), \ldots , f^{(n)}(a)$ exist, show that $f$ and the function $g$ defined by $$g(x) = \sum_{i=0}^{n} \frac{f^{(i)}(a)}{i!}(x-a)^i$$ are equal up to $n$th order at $a$. Hint: The limit $$\lim_{x \to a} \frac{f(x) - \sum_{i=0}^{n-1} \frac{f^{(i)}(a)}{i!}(x-a)^i}{(x - a)^n}$$ can be evaluated by L'Hospital's rule. In part (a), ($\Rightarrow$) I have, but the converse I am just missing a detail. I can't see why $$\lim_{h \to 0} \frac{f(a + h) - a_0 - a_1h}{h} = 0$$ implies that $$a_0 = f(a)$$ I tried adding and subtracting $f(a)$ in the numerator of the limit to see if I could use the triangle inequality or some form of it to show that $$\lim_{h \to 0} \frac{f(a+h) - f(a) - a_1h}{h} \leq \lim_{h \to 0} \frac{f(a + h) - a_0 - a_1h}{h} = 0$$ but I haven't been able to prove that. On the other hand, for (b) I used the hint and got that $$\lim_{x \to a} \frac{f(x) - \sum_{i=0}^{n-1} \frac{f^{(i)}(a)}{i!}(x-a)^i}{(x - a)^n} = \lim_{x \to a} \frac{f^{n-1}(x) - f^{n-1}(a)}{(n-1)!(x-a)} = \frac{f^{(n)}(a)}{(n-1)!}$$ and then $$\lim_{x \to a} \frac{f(x) - \sum_{i=0}^{n} \frac{f^{(i)}(a)}{i!}(x-a)^i}{(x - a)^n} = \lim_{x \to a} \left[\frac{f(x) - \sum_{i=0}^{n-1} \frac{f^{(i)}(a)}{i!}(x-a)^i}{(x - a)^n}\right] - \frac{f^{(n)}(a)}{n!}\\ = \frac{f^{(n)}(a)}{(n-1)!} - \frac{f^{(n)}(a)}{n!} \neq 0$$ Can anyone tell me what I'm doing wrong? Edit : I calculated the factorial wrong in the denominator. Silly mistake. It is actually: $$\lim_{x \to a} \frac{f(x) - \sum_{i=0}^{n-1} \frac{f^{(i)}(a)}{i!}(x-a)^i}{(x - a)^n} = \lim_{x \to a} \frac{f^{n-1}(x) - f^{n-1}(a)}{n!(x-a)} = \frac{f^{(n)}(a)}{n!}$$ And then $$\lim_{x \to a} \frac{f(x) - \sum_{i=0}^{n} \frac{f^{(i)}(a)}{i!}(x-a)^i}{(x - a)^n} = \lim_{x \to a} \left[\frac{f(x) - \sum_{i=0}^{n-1} \frac{f^{(i)}(a)}{i!}(x-a)^i}{(x - a)^n}\right] - \frac{f^{(n)}(a)}{n!}\\ = \frac{f^{(n)}(a)}{n!} - \frac{f^{(n)}(a)}{n!} = 0$$","['multivariable-calculus', 'calculus']"
439988,How many permutations of presentations is possible in this conference?,"I came across the following solved question in a book and am having difficulty understanding the answer given for it. Q: A conference is to have eight presentations over the course of one day, consisting of three long presentations, and five short presentations. If the conference organizer doesn't want consecutive long presentations, and the conference is to start with a short presentation, how many schedules of presentations are possible? A: Let S and L stand for a short and long presentation respectively. The schedule must start with a short presentation, and every long presentation must be followed by at least one short presentation. So the schedule must be SLSLSLS, along with one more short presentation inserted somewhere. There are four ways to do this - SSLSLSLS, SLSSLSLS, SLSLSSLS, and SLSLSLSS. For each of these there are 5! * 3! possible schedules, giving a total of 2880 schedules. My analysis gave 7200 schedules instead as follows. The first S is fixed. This leaves four S's and three L's to be permuted with the no-two-consecutive-L restriction. Or let's generalize it to a S's and b L's. Then the number of compatible permutations, written as N(a, b) , can be expressed as the recurrence N(a - 1, b) + N(a - 1, b - 1) . Observing the terminal values N(0, 1) = 1, N(1, 0) = 1, N(1, 1) = 2 and N(0, 2) = 0 , and substituting a = 4 and b = 3 , the number comes to 10. This gives a total of 10 * 5! * 3! = 7200 schedules. What am I missing?",['combinatorics']
440013,De Rham cohomology notation,"According to http://en.wikipedia.org/wiki/De_Rham_cohomology , one defines the $k$-th de Rham cohomology group
  $H^{k}_{\mathrm{dR}}(M)$ to be the set of equivalence classes, that
  is, the set of closed forms in $\Omega^k(M)$ modulo the exact forms. On the other hand, the de Rham cohomology groups of a $n$-dimensional sphere $H_{dR}^q(S^n)$ is $\mathbb{R}$ if $q=0,n$ and 0 otherwise. I am not sure to understand the link between $\mathbb{R}$ and the equivalence groups. Does that mean that to generate the de Rham cohomology groups of $S^n$, one can take any constant function $\omega$ (case $q=0$) or non-zero $n$-differential form $\omega$ (case $q=n$), and that each equivalence class can be generated from the product of $\omega$ by a particular member of $\mathbb{R}$ ?","['homology-cohomology', 'differential-forms', 'differential-geometry']"
440019,Naively estimating the factorial,"A naive way to estimate the factorial is $n! \geq (a+1) (a+2) \dots n \geq a^{n-a}$ for any $a$. For example, it gives $n! \geq (n/2)^{n/2}$ and slightly better $n! \geq (n/3)^{2n/3}$. I am interested in how strong this naive estimation it can be. For which $a$ we get the best estimate? If my calculations are correct, this happens when $a = \frac{n}{W(e n)}$ where $W$ is Lambert W. Can the expression $\left(\frac{n}{W(e n)}\right)^{n-\frac{n}{W(e n)}}$ be simplified, or sensibly estimated by elementary functions?","['estimation', 'lambert-w', 'real-analysis']"
440028,Compact operator between Hilbert spaces: range and orthogonal complement of the kernel are separable,"Let $\mathcal{H}_1$ and $\mathcal{H}_2$ be Hilbert spaces and $T: \mathcal{H}_1 \rightarrow \mathcal{H}_2$ a compact operator. I want to show that $(\ker T)^\perp$ and $\text{ran}\ T$ are separable. Since $T$ maps to a Hilbert space, there is a sequence $(T_n)_{n \in \mathbb{N}}$ of finite-dimensional operators that converges to $T$ in the operator norm.
Unfortunately, I was unable to make proper use of this fact. Or do I have to use another approach? I don't know much about compact operators between Hilbert spaces... Can someone help me to get started on this? [Update on the Definitions I use here:] A Hilbert space is an inner product space $(\mathcal{H}, \langle .,.\rangle)$ that is complete with respect to the norm that is induced by $\|x\|=\langle x,x\rangle^{1/2}$. A linear space $\mathcal{X}$ is separable iff there exists a dense countable subset of $\mathcal{X}$, where countable means finite or countably infinite.","['hilbert-spaces', 'functional-analysis']"
440054,Linear dependence of multivariable functions,"It is well known that the Wronskian is a great tool for checking the linear dependence between a set of functions of one variable. Is there a similar way of checking linear dependance between two functions of two variables (e.g. $P(x,y),Q(x,y)$)? Thanks.","['multivariable-calculus', 'linear-algebra', 'ordinary-differential-equations']"
440058,Area of an elliptic?,"I'm looking for an analytic way to calculate the area of an elliptic described by $${x^2 \over a^2} + {y^2 \over b^2}=c^2$$
I saw it before, but now i've forgotten. I remember we set $x=a \cos x$ and $y=a \sin x$ but I don't remember what we did after that!","['geometry', 'calculus', 'algebra-precalculus']"
440065,"Is $\{\sin x,\cos x\}$ independent?","Is $\{\sin x,\cos x\}$ linearly independent in $\mathbb{R}^n$ ? I thought they were not because I can write $\cos x=\sin (x+\pi/2)$ . My professor on the other hand said it was independent and his proof is as follows: If $\{\sin x,\cos\}$ is independent in $[0,2\pi]$ , then it will be independent on all of $\mathbb{R}.$ (He didn't prove this either.) $a\cos x+b \sin x=0  ,\forall \vec{x}\in[0,2\pi].$ $x=0\implies a\cdot1+b\cdot0=0 \implies a=0$ . $x=\pi /2\implies a\cdot 0+b \cdot 1 \implies b=0$ . So $\{\sin x, \cos x\}$ is independent on $[0,2\pi],$ and thus independent everywhere. $QED$ . Is there something I am missing or not understanding...? Why is this set independent, when I can express an element of the set as a linear combination?",['linear-algebra']
440071,row echelon vs reduced row echelon form,"I apologize if this is a very basic question. I understand the difference between the two forms, but i was curious when row echelon from is enough. where is row echelon form used?. Why shouldn't I always go for reduced row echelon form?",['linear-algebra']
440087,Dirichlet Problem with piecewise smooth boundary,"Suppose a domain $ \Omega \subset \mathbb{R^2} $ with $ \partial \Omega $. For $ f \in C^{\infty}(\mathbb{R^2}) $, the dirichlet problem is to find $ u $ with $ \Delta u = 0 $ in $ \Omega $, and $ f = u $ on $ \partial \Omega $. What are the existence and regularity theorems for classical solutions $ u $ in the case that $ \partial \Omega $ is not smooth, but only piecewise smooth? I am not sure exactly where to look for these results beyond just knowing the standard references, and I am a little overwhelmed by this. I would grateful if someone could put point me in a better direction.","['reference-request', 'partial-differential-equations', 'analysis']"
440136,two dimensional linear differential equation with $1$ eigenvector,"I have the following linear differential equation: \begin{equation}
x' = \begin{pmatrix}3&-4\\1&-1\end{pmatrix}x
\end{equation}
The corresponding characteristic equation is:
\begin{equation}
\lambda^2-2\lambda+1 = (\lambda-1)(\lambda-1) \implies \lambda_1=\lambda_2=1
\end{equation}
A corresponding eigenvector is $\begin{pmatrix} 2\\1\end{pmatrix}$. By plotting the solutions to the equation I know that it is a degenerate node, i.e there is only one eigenvector for the matrix (I believe the terminology is that the eigenspace has dimension 10. How do I determine this without plotting the differential equation? How do I know that the eigenspace only has dimension 1?","['eigenvalues-eigenvectors', 'linear-algebra', 'ordinary-differential-equations']"
440164,Application of Green's theorem to probability,"I encountered this problem while reading a statistic text. Since I am not quite familar with the background knowledge. Wonder can someone help me to explain the details of the following proof? Suppose X follows a spherically symmetric distribution which has a density $f(||x-\theta||^2)$, and let $F(t)=2^{-1}\int_{t}^{\infty}f(u)du$ and $Q(t)=F(t)/f(t)$. I want to evaluate the risk of a general function $X+g(X)$:$R(\theta,X+g(X))=E_{\theta}[||X+g(X)-\theta||^2]=E_{\theta}[||X-\theta||^2]+E_{\theta}[||g(X)||^2]+2E[(X-\theta)'g(X)]$, where all values here are vector values of dimension p. Now $E[(x-\theta)'g(X)]=\int_{R^p}(x-\theta)'g(X)f(||x-\theta||^2)dx=\int_{R^p}g(X)'\nabla F(||x-\theta||^2)dx=\int_{R^p}\nabla g(X)' F(||x-\theta||^2)dx=E[Q(||X-\theta||^2)\nabla 'g(X)]$ It says the above whole thing follows from Green's theorem. However, I can't see  how to get  third and fourth equality and where Green's theorem comes from . I also can't see why the last step comes to $E[Q(||X-\theta||^2)\nabla 'g(X)]$","['probability-theory', 'multivariable-calculus', 'harmonic-analysis', 'functional-analysis']"
440180,Simplifying $\sin(4x)\cos(4x)$,"Simplify $\sin(4x)\cos(4x)$ using double angle or compound trigonometry. Can someone please show me how its done, Ive tried several times but no where near the answer.",['trigonometry']
440183,Double integral over a region,"Given $f(x,y)=\displaystyle\frac{x^2}{x^2+y^2}$ and $D=\{(x,y) : 0 \leq x \leq 1, x^2 \leq y \leq 2-x^2\}$ i have to solve $\displaystyle\int\displaystyle\int_Df(x,y)dA$. Here's my try: (1) Changing variables $x = \sqrt{v-u}$, $y= v+u$. (1.1) Since $0 \leq x \leq 1$, then $0 \leq v-u \leq 1 \rightarrow u \leq v \leq 1+u$ (1.2) Since $x^2 \leq y \leq 2-x^2$, then $v-u \leq v+u \leq 2-v+u \rightarrow -u \leq u \rightarrow 0\leq u$ and $v \leq 2-v \rightarrow v \leq 1$ (1.3) It seems that now i should integrate over  $S = \{(u,v) : 0\leq u \leq v \leq 1 \}$ (the upper triangle in $[0,1]\times[0,1]$ ?), so i may as well put $S = \{(u,v) : 0 \leq v \leq 1, 0 \leq u \leq v  \}$. (2) Alright, what do i need to calculate the integral? (2.1) First, i should calculate the Jacobian $ \displaystyle\frac{\partial(x,y)}{\partial(u,v)} = \left| \begin{array}{cc}
\frac{\partial x}{\partial u} & \frac{\partial x}{\partial v} \\
\frac{\partial y}{\partial u} & \frac{\partial y}{\partial v} \\
\end{array} \right| = \left| \begin{array}{cc}
-\frac{1}{2\sqrt{v-u}} & \frac{1}{2\sqrt{v-u}} \\
1 & 1 \\
\end{array} \right| = -\frac{1}{\sqrt{v-u}}$ (2.2) Then i have to solve $\displaystyle\int_0^1\displaystyle\int_0^v \frac{v-u}{(v-u)+(v^2+2uv+u^2)}\bigg(-\frac{1}{\sqrt{v-u}} \bigg)dvdu$
$=-\displaystyle\int_0^1\displaystyle\int_0^v \frac{\sqrt{v-u}}{v^2+v(1+2u) + (u^2-u) }dvdu$ (2.3) Well, here i'm stuck.I've been thinking about taking $z = \sqrt{v-u}$ and then $dz = \displaystyle\frac{1}{2\sqrt{v-u}}dv$ wich means $dv = 2zdz$, this would lead to an integral of the form
$2\displaystyle\int\displaystyle\int \frac{z^2}{z^2+z(1+4u)+ 4u^2 }dvdu = 2\displaystyle\int\displaystyle\int \frac{z^2}{(z+(\frac{1}{2}+2u))^2-2u }dvdu$ and if i put $w = z+(\frac{1}{2}+2u)$ i'll have $2\displaystyle\int\displaystyle\int \frac{(w-\frac{1}{2}-2u)^2}{w^2-2u }dwdu$ but it seems that the last one will lead to some ugly shaped solution and i would have a hard time getting the final answer.
What would be the best way to solve this?","['multivariable-calculus', 'integration']"
440186,What determines if a function has a least positive period?,"This question stems from this one, where if $f$ is continuous and $f(x) = f(x+1) = f(x+\pi)$, then $f$ must be constant. The above is shown using the density of $\mathbb{Z}+\pi\mathbb{Z}$ in $\mathbb{R}$ and the continuity of $f$. However, what jumps out at me from the question is the (seeming) incongruity of a period that is both rational and irrational. Specifically, if $f$ is non-constant and has a least positive period, $T$, then it cannot be that $f(x)=f(x+1)=f(x+\pi)$, since that would imply that $\pi$ is rational. But, as was pointed out to me, this cannot be used to prove the above because not every periodic function has a least positive period. So my question is, what determines if a function has a least positive period? Are there certain classes of functions that, if periodic, must have a least positive period? For instance, continuous periodic functions? Also, what other examples are there of non-constant periodic functions that do not have a least positive period? The example given to me (and the only one given on the Wikipedia page ) is the indicator function of rational numbers.","['real-analysis', 'periodic-functions']"
440191,Why is factorization of large number hard,Why factoring a number is difficult compared to finding out if it is prime (which can be done in polynomial time) ? I would think they might be of similar difficulty in terms of computational complexity.,"['primality-test', 'twin-primes', 'computational-complexity', 'number-theory']"
440202,definition of the Fourier transform of function on the sphere,Let $f: S^{n-1}\longrightarrow R^n$ be  even continuous function. What is the Fourier transform of $f$?,"['spherical-harmonics', 'fourier-analysis', 'functional-analysis', 'definition']"
440205,Computing Kähler differentials on $\mathbb P^1_A$ (What did Liu intend?),"Let $A$ be a ring and $X=\mathbb P^1_A$. On $D_+(T_0)\cap D_+(T_1)$, we
  have $$T^2_0d(T_1/T_0)= -T^2_1d(T_0/T_1).$$ How does one formally compute this transition? Of course this is obvious intuitively if one thinks of differential forms and $\mathbb P^1$ as a manifold. It is even obvious intuitively when thinking algebraically, if you think of the intersection as ""the place where you can invert $T_0$ and $T_1$,"" and then compute $d\left(\frac{T_1}{T_0}\frac{T_0}{T_1}\right)$. (Recall that we define $\mathbb P^1_A$ as $\operatorname{Proj} A[T_0,T_1]$. We can cover this with two principal open subsets $D_+(T_i)$, with sections $A[T_0,T_1]_{(T_i)}$. It is a relatively exercise to compute that on these ""charts"" the sheaf of differentials looks like $A[d(T_0/T_1)]$ and $A[d(T_1/T_2)]$. The elements above are then elements of $\mathcal O_X(2)\otimes \Omega^1_{X/A}$.) The excerpt above appears when Liu computes the sheaf of differentials on $\mathbb P_A^1$. He does this by writing down two differentials on each chart, noting they glue to a global section, then noting this global section is a generator. So in justifying the above, I would like to avoid doing what Hartshorne does, which is to guess that $\Omega^1_{X/A}$ is $\tilde{M}$ for a certain module $M$ and then checking that this is correct. Also, Liu constructs projective schemes by describing the sheaf $\mathcal O_X$ on principal open sets and then citing the theorem that this is enough to determine a sheaf. I think one can make the algebraic intuition I described above by using a more explicit description of the sheaf (like the one given in Hartshorne), but I'd like to avoid doing this, too. It is distinctly not in Liu's style, and I'm very curious what he intended. Update. Put another way, my question is how to derive the gluing maps for these ""charts"" rigorously and how to show how these gluing maps transform the differentials in the expected manner.","['sheaf-theory', 'algebraic-geometry', 'schemes', 'projective-schemes']"
440235,"""range of function"" vs ""target of function""?","Page 14 of Fundamentals of Computer Graphics states that if we have a function like this: ...the set that comes before the arrow is called the domain of the function, and the set on the right-hand side is called the target . ...The point f(a) is called the image of a , and the image of a set A (a subset of the domain) is the subset of the target that contains the images of all points in A . The image of the whole domain is called the range of the function. Then what exactly is the difference between the range of a function and the target of a function?",['functions']
