question_id,title,body,tags
3931535,restricted of the entropy function is concave and upper semi continuous,"Let $T:X \to X$ be a topologically mixing subshifts of finite type and $f:X\to \mathbb{R}$ be a continuous function. It is well known that the entropy function $\mu \mapsto h_{\mu}(T)$ is concave. I want to show that the following function is concave $$ H(t)=\sup\{h_{\mu}(T), \mu \in \mathcal{M}(X, T), \int f d\mu=t\},$$ where $\mathcal{M}(X, T)$ is the space of invariant measure. My attempt: for every $\mu_{1}, \mu_{2} \in \mathcal{M}(X, T)$ , let $\mu=\lambda \mu_{1}-(1-\lambda)\mu_{2}$ for some $\lambda \in (0,1)$ . Since the entropy is concave, $h_{\mu}(T)\geq \lambda h_{\mu_{1}}(T)+(1-
\lambda)h_{
\mu_{2}}(T).$ Let $a=
\int f d\mu_{1}$ and $\int f d\mu_{2}=b.$ $$\sup \{h_{\mu}(T): \mu \in \mathcal{M}(X,T), \int f d\mu=\lambda a+(1-\lambda)b\}\geq \sup \{\lambda h_{\mu_{1}}(T)+(1-
\lambda)h_{
\mu_{2}}(T): \mu \in \mathcal{M}(X,T), \int f d\mu=\lambda a+(1-\lambda)b\}$$ I don't know how to get the result. Edit: Is $H(t)$ upper semi continuous?","['probability-theory', 'ergodic-theory', 'functional-analysis', 'dynamical-systems']"
3931602,Two bijections between set of integers,"I have the following interesting question: Let $b$ be a $\mathbb{Z} \rightarrow \mathbb{Z}$ bijection, where $\mathbb{Z}$ denotes the set of integers. Is it possible that there exist a bijection between $\mathbb{Z}$ and $k+b(k)$ (where $k\in \mathbb{Z}$ )? That is: is it possible that $k+b(k)$ are all distinct integers and for every integer $S$ there exist (exactly one) an integer $n$ for which $S=n+b(n)$ ?","['elementary-set-theory', 'functions', 'integers']"
3931612,Sequence of uniform random variables,"Let $X_n$ be a sequence of random variables where $X_0$ is uniform in $[0,1]$ and $X_{n+1}$ is uniform in $[0,2X_n]$ . Does this sequence converge to anything (in probability, a.s., $L^1$ )? I'm not sure of how to condition $X_n$ to the previous outcome $X_{n-1}$ . A computer simulation seems to indicate that they should be converging to $0$ (in some sense), and that seems to be intuitive enough since it's much harder to get larger numbers and all the effort can be suddenly undone by getting a small number. Any ideas?",['probability-theory']
3931662,What does the limit of the characteristic function $\varphi(x)\xrightarrow{\lvert x\rvert\rightarrow \infty} 0$ tell us about $\mu(\{a\})$?,"If we know that $\varphi(x)\xrightarrow{\lvert x\rvert\rightarrow \infty} 0$ for the characteristic function $\varphi$ of the probability measure $\mu$ on $\mathbb{R}$ , what does that tell us about $\mu(\{a\})$ for any $a$ ? Because of the identity $$\mu(\{a\}) = \lim_{T\rightarrow\infty}\frac 1{2T}\int_{-T}^Te^{-ita}\varphi(t) dt$$ I think it should be $\mu(\{a\}) = 0$ for all $a$ . But I don't know how to formalize this idea, if it's true. Edit: A TA confirmed it is true that under the assumption $\mu(\{a\})=0$ for all $a$ , but I still don't even know how to start a possible proof/what the key insight is. Edit2: I have successfully shown that $$\lim_{T\rightarrow\infty}\frac 1{2T}\int_{-T}^T\varphi^2(t)dt = \sum_{x\in\mathbb{R}}(\mu(x))^2$$ But I need to show that the LHS is $0$ . It is not trivial to show that the integral is even finite in the limit, how can I show that the LHS is finite?","['characteristic-functions', 'measure-theory', 'probability-theory', 'probability']"
3931708,What is the probability (is my solution correct? If not solve it please),"Probability that a shooter hits the mark with a shot is 0,78. Find the probability if from five shots the shooter hits the mark at least two times.
My solution is: Let D: the event that it hits the mark at least rwi times and E: the shooter hits the mark only one time and B: the shooter never hits the mark (1-0,78) then: P(D)=1-P(B)-P(E) =1-(0.22)^5 - (5)(0,78)(0,22)^4 its multiple by 5 cuz there are 5 possibilities to choose one shot .","['probability-theory', 'probability']"
3931865,"Self-intersection of a cubic Bezier, interpretation of the solution","I am trying to understand the form of the determinants that I get when I try to calculate the self-intersection. Since I might have made some mistakes, I'm including the whole derivation: Let $\vec{P}(t)$ be a cubic Bezier curve in two dimensions. In power basis: $$
\vec{P}(t)=(−\vec{A}+3\vec{B}−3\vec{C}+\vec{D})t^3+(3\vec{A}−6\vec{B}+3\vec{C})t^2+(−3\vec{A}+3\vec{B})t+\vec{A}
$$ $$
=\vec{a}t^3+\vec{b}t^2+\vec{c}t+\vec{d}.
$$ For a loop intersection to occur, there must exist $(t,s), t\neq s$ : $$
\vec{a}(t^3-s^3)+\vec{b}(t^2-s^2)+\vec{c}(t-s)=0 \quad\quad\quad/(t-s)
$$ $$
\vec{a}(t^2+ts+s^2)+\vec{b}(t+s)+\vec{c}=0
$$ If I make the substitution $ u :=t+s/2$ , I get: $$
a_x(u^2+\frac{3s^2}{4})+b_x(u+\frac{s}{2})+c_x=0
$$ $$
a_y(u^2+\frac{3s^2}{4})+b_y(u+\frac{s}{2})+c_y=0
$$ I can eliminate the quadratic term by doing $a_y(I)-a_x(II)$ : $$
(a_yb_x - a_xb_y)(u+\frac{s}{2})+(a_yc_x-a_xc_y)=0
$$ $$
M:=a_yb_x - a_xb_y\quad\quad\quad N:=-(a_yc_x-a_xc_y)
$$ $$
u=\frac{N}{M}-\frac{s}{2}
$$ Substituting $u$ back: $$
\vec{a}\left[\left(\frac{N}{M}-\frac{s}{2}\right)^2+\frac{3s^2}{4}\right]+\vec{b}\frac{N}{M}+\vec{c}=0
$$ $$
\vec{a}\left[s^2 - \frac{N}{M}s+ \left(\frac{N}{M}\right)^2\right]+\vec{b}\frac{N}{M}+\vec{c}=0
$$ These quadratic equations have solutions: $$
s_i=\frac{1}{2a_i}\left(
a_i\frac{N}{M}\pm\sqrt{D_i}\right)
$$ $$
D_i=a_i^2\left(\frac{N}{M}\right)^2-4a_i\left(a_i\left(\frac{N}{M}\right)^2+b_i\frac{N}{M}+c_i\right)
$$ And now I'm confused... Why did I end up with two quadratic equations? Shouldn't there be just one? My understanding is that $D = 0$ corresponds to the cusp shape, $D > 0$ to a loop intersection and $D < 0$ to no intersection. Furtheremore, I would like to understand what $M=0$ (which blows up the determinant) corresponds to. The expression for the curve being quadratic explains it only partly, i.e. when $a_x = a_y = 0$ .
What do the other conditions in: $$
M=a_yb_x - a_xb_y=0
$$ correspond to? (E.g. what is 'wrong' with $(b_x = b_y = 0)$ , $(a_yb_x = a_xb_y)$ ?)","['bezier-curve', 'algebraic-geometry', 'intersection-theory']"
3931905,Functional derivative of the sum of a product,"Suppose I have a product like the following: $$P(A)=\sum_{i_1=0}^{\infty}\ldots\sum_{i_n=0}^{\infty}c_{i_1}\ldots c_{i_k} A(x^1_{1})\ldots A(x^1_{i_1})\ldots A(x^n_1)\ldots A(x_{i_n}^n)\\
=c_{0}^n+c_{1}c_0^{n-1}\sum_{k=1}^nA(x_1^k) +c_2c_0^{n-1}\sum_{k=1}^n A(x^k_1)A(x^k_2)+ c_1^2 c_{0}^{n-2}\sum_{i\neq j=1}^n A(x^i_1)A(x^j_1)+\ldots$$ where I have written explicitly the first three terms (all $i_k=0$ or one $i_k=1$ with all other zero and one $i_k=2$ with all other zero or two $i_a=i_b=1$ with all other zero). Now suppose I want to write  the $m$ -th functional derivative $\frac{\delta}{\delta A(y_1)}\ldots \frac{\delta}{\delta A(y_m)}P(A)\rvert_{A=0}$ calculated in zero. The derivative is defined as: $$\frac{\delta}{\delta A(y_1)} A(x) = \delta(x-y_1)$$ I know that a product $$\frac{\delta}{\delta A(y_1)}\ldots \frac{\delta}{\delta A(y_n)}\prod_{i=1}^{n}A(x_i)=\sum_{\sigma\in P_n}\prod_{i=1}^n\delta(x_{\sigma_i}-y_{i})$$ where $\sigma$ are permutations of the indices $P_n = \{1,\ldots,n\}$ and I can write $P(A)$ as: $$P(A)=\sum_{i_1=0}^{\infty}\ldots\sum_{i_n=0}^{\infty}\prod_{j=1}^{n}c_{i_j}\prod_{k=1}^{i_j}A(x_k^j)$$ However, now I don't know how to write $\frac{\delta}{\delta A(y_1)}\ldots \frac{\delta}{\delta A(y_m)}P(A)\rvert_{A=0}$","['permutations', 'real-analysis', 'combinatorics', 'functional-analysis', 'derivatives']"
3931970,Example of a Ring that has nothing to do with numbers,"What is an example of a ring that has nothing to do with numbers?
For example, for groups, we have dihedral groups, quaternions, etc. I'm missing the analogue of the characteristic of a ring, when the ring is not related to numbers (complex, real, integers,...). Part of why I want this example is because I want to see if the characteristic of a ring must be an element of the ring itself.","['ring-theory', 'abstract-algebra']"
3932041,True or False: The line y=x is always at 45 degrees to the x-axis?,"I have a doubt. My teacher has posted a question that Is it always/sometimes/never true that the line y=x is at 45 degrees to the x-axis ? I know that the slope of the line y=x is always 1, and the line must make 45 degrees with x-axis. I am a bit confused when I am plotting the line y=x at different X-scales (see Figures 1 and 2 attached).
I do not visually see the line at 45 degrees to the x-axis in Figure 2. What am I missing? Which answer would be correct and why?
( a ) It is always true
( b ) It is sometimes true because when we change the scale of x or y axis, graph will distort and not be at 45 degrees. See images attached. Fig 1 with equal x and y axis Fig 2 with different axis","['analytic-geometry', 'graphing-functions', 'geometry', 'slope', 'trigonometry']"
3932050,What is the expected value of the inverse of a Wishart matrix plus a scaled identity matrix?,"I'm trying to find the following: $$\mathbb{E}\left[\left(\mathbf{W}+\lambda\mathbf{I}\right)^{-1}\right]$$ where $\mathbf{W}\sim\mathcal{W}_{p}(n,\mathbf{\Sigma})$ is Wishart-distributed, $\lambda\ge 0$ is a constant, and $\mathbf{I}$ is the identity matrix.  It is known (e.g. Das Gupta, 1968) that $\mathbb{E}\left[\mathbf{W}^{-1}\right]=\frac{\mathbf{\Sigma}^{-1}}{n-p-1}$ , and the expected value of the inverse of a non-central Wishart matrix is also known (Hillier, 2019).  However, it's not clear how $\mathbf{W}+\lambda\mathbf{I}$ could be expressed as a non-central Wishart-distributed matrix. Approximations would also be useful, and I have tried $$\mathbb{E}\left[\left(\mathbf{W}+\lambda\mathbf{I}\right)^{-1}\right]\approx\mathbb{E}\left[\mathbf{W}^{-1}\right]-\lambda\mathbb{E}\left[\mathbf{W}^{-2}\right]+\lambda^{2}\mathbb{E}\left[\mathbf{W}^{-3}\right]+\mathcal{O}(\lambda^{3})$$ The higher order moments of the inverted Wishart are known (Von Rosen, 1988), so this can be calculated, but the estimate is only valid for very small $\lambda$ , especially when $p$ is close to $n$ . References: Das Gupta, S., ""Some aspects of discrimination function coefficients,"" The Indian Journal of Statistics , Vol. 30, No. 4, 1968. Hillier, G. et al., ""Properties of the inverse of a noncentral Wishart matrix,"" Available at SSRN 3370864 , 2019. Von Rosen, D., ""Moments for the inverted Wishart distribution,"" Scandinavian Journal of Statistics , Vol. 15, No. 2, pp. 97-109, 1988.","['expected-value', 'statistics']"
3932074,Is this explanation of normal subgroups and quotient groups correct?,"I apologize for the long post, but I'm currently a student finishing up his first semester in group theory. My introduction was pretty definition-heavy so I've found I can internalize concepts (such as quotient groups, normal subgroups, etc.) myself by forming my own way of motivating and teaching them intuitively. I'd like to know if my current presentation/understanding is correct. I think after learning about subgroups and Lagrange's theorem, a natural question is then if we can break down a group $G$ to better understand its parts and hopefully the whole $G$ (as is tradition in any analytical endeavor). But if we want to pull back any useful understanding of $G$ from this smaller group, it ought to preserve some structure of $G$ . That structure is exactly how the operation acts on elements of $G$ (since groups are just elements with an operation relating them). So for the sake of exploration, we pretend to have the magic function $\phi : G \rightarrow H$ that does exactly this for us–maps $(G, *_G)$ to some smaller part $(H, *_H)$ , then ask what we can say about $\phi$ . Our original goal was for $\phi$ to preserve the operation, i.e. for all $a, b \in G$ that $\phi(a *_G b) = \phi(a) *_H \phi(b)$ . The next thing I would observe is that since $H$ has smaller order, $\phi$ necessarily maps a multiple elements, say $a, b$ , in $G$ to the same element in $H$ . In this sense, $a$ and $b$ are ""equivalent"" under $\phi$ . Given that we have ""willed"" $\phi$ to operation-preserving, we can see that a natural way this arises by letting $ak = b$ for some $k \in G$ : $$ak = b \implies \phi(b) = \phi(a *_G k) = \phi(a) *_H \phi(k).$$ If we want $\phi(b) = \phi(a) *_H \phi(k) = \phi(a)$ then $\phi(k) = e_H$ . I think leads naturally to the definition of the kernel: it's a set of elements that maps to the identity, and makes $a$ equivalent to $b$ mod $\ker \phi$ . And in fact, as I've learned from this answer , we naturally get equivalence classes of elements that partition the group into cosets analogous to modular arithmetic. So, $\phi$ takes elements and puts them neatly into these equivalence classes (abstracting away some of the details in $G$ that look ""the same"" in $H$ , leading–at least for me–directly to the First Isomorphism Theorem). Then it makes sense to propose the map $\phi : g \mapsto g \ker \phi$ . The next question becomes what the operation of this $H$ looks like. We've established that elements of $H$ are cosets (and equivalence classes), so for two elements in cosets $g_1 \ker\phi$ and $g_2 \ker\phi$ , once combined by $*_H$ we'd want for the result to be in $g_1g_2 \ker\phi$ (modular arithmetic analogy works here as well). Set-wise, we might write $$g_1\ker\phi \cdot g_2\ker\phi = g_1g_2\ker\phi.$$ But does this come for free? For an element $g_1k_1g_2k_2 \in g_1\ker\phi \cdot g_2\ker\phi$ to look like $g_1g_2k$ for some $k$ , it must be that $k_1g_2 = g_2k_3$ for some $k_3$ . Set-wise this can be written as $g\ker\phi = \ker\phi g$ , i.e. left-costs = right-cosets and it turns out it indeed satisfies this condition and we are safe to proceed. So, in the end, we have designed $H$ , a broken-down version of $G$ . And how did we do it? By ""dividing out"" or ""quotienting out"" the information that looks the same under $\phi$ in $H$ – $\ker \phi$ . Thus we write $H$ as $G/\ker\phi$ , aptly called a quotient group. Although, you could flip this presentation, and instead of viewing from the kernel perspective, suppose $K$ is some arbitrary group. Then it must satisfy the condition of left-cosets = right-cosets (which we name normality because it is a nontrivial property that gives us a usable quotient) for $G/K$ to be a group, as $\ker\phi$ already does, and through satisfying normality automatically becomes the kernel of some homomorphism (namely the natural, which I've presented). My questions are: Is this presentation correct (on an intuitive level, I know there are lots of places for concrete proofs)? It feels right to me, but I also feel like I may have gotten definitions vs. implications mixed up. If so, does any textbook follows this approach that I can dig into? I think homomorphisms also can fit into this framework, given I suggest $\phi$ pretty early on, but how would non-surjective homomorphisms be explained?","['quotient-group', 'normal-subgroups', 'abstract-algebra', 'intuition', 'group-theory']"
3932125,Convergence of Mixtilinear Triangles to a Point,"First, some definitions: A mixtilinear incircle of a triangle is a circle that is tangent to two sides of the triangle and internally tangent to that triangle's circumcircle. There are three mixtilinear incircles for any nondegenerate triangle. The triangle connecting the centers of the three mixtilinear incircles is called the mixtilinear triangle of the first triangle. My impression is that the mixtilinear triangle always seems to be smaller than the original triangle. So, assuming that (or not assuming it but only looking at triangles for which it is true), my question is as follows: If one were to take the mixtilinear triangle of the mixtilinear triangle of the mixtilinear triangle of...of the original triangle, indefinitely, and it were to converge to a point, would that point have any geometric relationship to the original triangle? For example, might it be along the Euler line? I'd like to note that, even assuming my above observation about the size of the mixtilinear incircle is true (and if it's not, I'd be curious to see a counterexample!), there's no way of procedurally determining which was the original triangle, so any property satisfied by that point with regard to the original triangle would also have to be satisfied with regard to any of the infinitely many mixtilinear and sub-mixtilinear triangles. In my view, that seems to make it substantially less likely that there is any nice property, but I'm still curious. I came up with this problem myself- it's not from a textbook or anything like that, so I know of no ready-made solution just hiding out there. Also, I'm sorry for not adding more work, but I'm not generally very good at the inversive-geometry approach in which I encountered these triangles and from which I assume a proof would have to come.","['inversive-geometry', 'circles', 'geometry', 'triangles', 'triangle-centres']"
3932134,Finding the mle of a log normal distribution,"So let $X1,X2,..,XN$ be an independent sample from log normal distribution with the pdf $f(x,\theta)=(x^2 \sigma^2*2\pi)^{(-1/2)}e^{-(log(x)-\theta)^2/{2\sigma^2}}$ and we have $\sigma^2=1$ and $\theta$ uknown So I did the following we have the $L(\theta,x)=(x_1^2\sigma^22\pi)^{-1/2}e^{-(log(x_1)-\theta)^2/{2\sigma^2}}*(x_2^2\sigma^22\pi)^{-1/2}e^{-(log(x_2)-\theta)^2/{2\sigma^2}}*...*(x_n^2\sigma^22\pi)^{-1/2}e^{-(log(x_n)-\theta)^2/{2\sigma^2}}$ and I get the following $L(\theta,x)=(2\pi)^{(-n/2)}*(\sigma^2)^{-n/2}*(1)/(x_1*x_2*..*x_n)e^{(-1/2\sigma^2)\sum(log(x_i)-\theta)^2}$ So I take the $log(L(\theta,x)$ and I get $(-n/2)log(2\pi)+log(1/x^n)-(1/2\sigma^2)\sum(log(x_i)-\theta)^2$ So now to find the mle of $\theta$ I do $d/d(\theta)log(L(\theta,x))=0$ take the derivative and I get $=log(x_1)-\theta+log(x_2)-\theta+...+log(x_n)-\theta$ so I get $log(x_1)+log(x_2)+..+log(x_n)-\theta*n$ so the mle $\theta[hat]$ of $\theta$ is $\theta[hat]=((log(x_1)+log(x_2)+..+log(x_n))/n$ I am not sure if this is right.",['statistics']
3932186,Solutions to equation of $6$ variables,"Preliminaries: Let $M$ be any $4\times 4$ unitary matrix. Now, define the matrices $A$ and $B$ by $$A=M^\dagger\left[ \begin{pmatrix}
\cos(\theta) & -e^{i\lambda}\sin(\theta)\\ 
e^{i\phi}\sin(\theta) & e^{i(\lambda+\phi)}\cos(\theta)
\end{pmatrix}\otimes \begin{pmatrix}
1 & 0\\ 
0 &1 
\end{pmatrix}\right]M$$ $$B=M^\dagger\left[\begin{pmatrix}
1 & 0\\ 
0 &1 
\end{pmatrix}\otimes \begin{pmatrix}
\cos(\theta) & -e^{i\lambda}\sin(\theta)\\ 
e^{i\phi}\sin(\theta) & e^{i(\lambda+\phi)}\cos(\theta)
\end{pmatrix}\right]M$$ We may then define $f:\mathbb{R}^6\to \mathbb{R}$ by $$f(\theta,\lambda,\phi,\delta,\alpha,\beta)=\prod_{C\in\{A,B\}}\left(\left|\begin{pmatrix}
0\\ 
0\\ 
1\\ 
0
\end{pmatrix}^TC\begin{pmatrix}
\cos(\delta)e^{i\alpha}\\ 
\sin(\delta)e^{i\beta}\\\ 
0\\ 
0
\end{pmatrix}\right|+\left|\begin{pmatrix}
0\\ 
0\\ 
0\\ 
1
\end{pmatrix}^TC\begin{pmatrix}
\cos(\delta)e^{i\alpha}\\ 
\sin(\delta)e^{i\beta}\\\ 
0\\ 
0
\end{pmatrix}\right|\right)$$ Now, what are the zeros of this function? It is easy to show that any element of the set $$S=\{(k_1\pi ,\lambda, 2\pi k_2-\lambda,\delta,\alpha,\beta):k_1,k_2\in\mathbb{Z}\text{ and }\lambda,\delta,\alpha,\beta\in\mathbb{R}\}$$ is a solution to $f(\theta,\lambda,\phi,\delta,\alpha,\beta)=0$ . This is because $$\begin{pmatrix}
\cos(\theta) & -e^{i\lambda}\sin(\theta)\\ 
e^{i\phi}\sin(\theta) & e^{i(\lambda+\phi)}\cos(\theta)
\end{pmatrix}\Bigg|_{\theta=k_1 \pi,\phi=2\pi k_2-\lambda}=(-1)^{k_1}\begin{pmatrix}
1 & 0\\ 
0 & 1
\end{pmatrix}$$ and the matrix $A$ collapses down to $$A=M^\dagger[(-1)^{k_1}I_4]M=(-1)^{k_1}M^\dagger M=(-1)^{k_1}I_4$$ (where $I_4$ is the $4\times 4$ identity matrix), which in turn means all the inner products are zero. My question: Is there some $4\times 4$ unitary matrix $M$ such that $S$ is all the solutions to the equation $f(\theta,\lambda,\phi,\delta,\alpha,\beta)=0$ ? Motivation: If I could prove this question in the negative (there are no such matrices $M$ ), then I could show that at least $3$ qubits are required for an error detection code I am developing for a quantum computer. I won't bore you with all the details (unless someone wants to know more), but my problem has simplified to the linear algebra question above. Work: So far, I have tried a lot of different ways of proving the above without much success. For any set matrix $M$ , I can always find solutions that are not in $S$ . However, it does seem like almost all the degrees of freedom are required because there are some $M$ where the solution seems to lie on a line in $\mathbb{R}^6$ space (basically it depends on the difference between $\alpha$ and $\beta$ ). That is, it does not form a family of solutions on a plane/hyper-plane in the space. My current work is to try to use different generators of $U(4)$ and see if I can say something if I decompose $M$ into constituent parts (Here are two different papers I have been using for said generators). Unfortunately, this has not simplified my problem to the point where I can get a satisfactory solution.","['unitary-matrices', 'linear-algebra']"
3932228,Intuition on the Cuntz-Krieger relations for Leavitt path algebras and graph $C^*$-algebras,"Let $k$ be a commutative ring with unity and $E$ a quiver with source and target functions $E^1 \xrightarrow{s,t} E^0$ . The Leavitt path algebra of $E$ is the quotient of the path algebra of the double graph $k(E \sqcup E^\ast)$ by the Cuntz-Krieger relations $$
e^\ast f := \delta_{s,f} \ t(f) \tag{CK 1}
$$ for each pair of edges $e,f \in E^1$ and $$
v = \sum_{e  \ : \ s(e) = v}\tag{CK 2}ee^\ast
$$ for each regular vertex $v \in E^0$ . This means that $s^{-1}(v)$ is non-empty and finite, which means that $v$ is not a sink or an infinite emitter . This is analogous to the construction of graph $C^*$ -algebras, where the original Cuntz-Krieger relations arose, and include several algebras of interest. However, I would like to gain some intuition as to why these relations were considered in the first place. The original paper of Cuntz seems to relate $(CK1)$ and $(CK2)$ to topological Markov chains and symbolic dynamics, but I've had a hard time following the motivation. I'd really appreciate an explanation for non-experts.","['c-star-algebras', 'quiver', 'abstract-algebra', 'functional-analysis', 'soft-question']"
3932241,A clarification on the definition of an interval,"This an example of a definition of an interval as given by K.G. Binmore: Mathematical Analysis: A Straightforward Approach. A (real) interval is a subset I of the real numbers such that: $\forall x, y \in I: \forall z \in \mathbb{R} : ({x \le z \le y
 \implies z \in I})$ I'm wondering how does this definition fit together with open intervals where endpoints $x, y$ are not included in the interval. Does it still hold that $x, y \in I$ ? Furthermore, how should I understand $[3,2] = \emptyset$ which is a closed interval? Shouldn't closed intervals by definition contain endpoints and thus the set is not empty?","['elementary-set-theory', 'definition', 'real-analysis']"
3932274,"Prove: If two finite-dimensional vector spaces are isomorphic, then they have the same dimension.","Please comment on the validity of my proof. Any tips and suggestions are appreciated. Prove: If two finite-dimensional vector spaces are isomorphic, then they have the same dimension. Let $B=$ { $b_1,...,b_n$ } be a basis for a finite-dimensional vector space $V$ . Let $W$ be a finite-dimensional vector space, and define $T: V→W$ as an isomorphism between them. Let $x∈V$ , then $T(x)=T(c_1b_1+...+c_nb_n)$ for some real scalars $c_1...c_n$ as $B$ is a basis for $V$ . Also, because $T$ is an isomorphism, $T$ is a linear transformation, onto, and one-to-one. Because $T$ is onto, for any $y∈W$ , $y=T(x)=T(c_1b_1+...+c_nb_n)=c_1T(b_1)+...+c_nT(b_n)$ . Thereofore, $span$ { $T(b_1),...T(b_n)$ }= $W$ . Let $c_1T(b_1)+...+c_nT(b_n)=0$ . Because $T$ is one-to-one and linear $c_1T(b_1)+...+c_nT(b_n)=T(c_1b_1+...+c_nb_n)=0$ implies that $c_1b_1+...+c_nb_n=0$ . But because $b_1...b_n$ is a basis, it is linearly independent and so $c_1=...=c_n=0$ . Therefore { $T(b_1),...T(b_n)$ } is a linearly independent set. So, { $T(b_1),...T(b_n)$ } is a basis for $W$ and is clearly $n$ dimensional. So, $dim(V)=dim(W)$ .","['proof-writing', 'linear-algebra', 'vector-spaces', 'solution-verification']"
3932319,"Solving $a_n = c_{n,n - 1} a_{n - 1} + \dots + c_{n,0} a_{0}$","I have been drawn to the art of solving recurrence relations from an unrelated problem in analysis.
Given real numbers $a_0$ and \begin{eqnarray}
 & & c_{1,0} \\
 & c_{2,1} \quad & c_{2, 0} \\
c_{3,2} \quad & c_{3,1} \quad &  c_{3,0} \\
 & & \vdots \quad,
\end{eqnarray} is there a way to explicitly solve $a_n = c_{n,n - 1} a_{n - 1} + \dots +  c_{n,0} a_{0}$ ? One can work out the first few terms: $$
a_1 = c_{1,0} a_0 \quad; \quad a_2 = c_{2,1} a_1 + c_{2, 0} a_0 = \left(c_{2,1} c_{1,0} + c_{2, 0}\right) a_0 \quad ; \text{ etc.}
$$ However, I can't figure out how to extract a closed formula for $a_n$ . I have gone through a bit of literature but it seems that not many results can be applied to this problem.","['recurrence-relations', 'discrete-mathematics', 'recursion']"
3932366,Prove $ \lim_{h\rightarrow 0}\frac{1}{h}\int_a^x[f(t+h)-f(t)]\mathrm{d}t=f(x)-f(a). $,"Suppose $f(x)$ is continuous on $[a, b]$ . Prove that $\forall x\in (a,b)$ , we have $$
\lim_{h\rightarrow 0}\frac{1}{h}\int_a^x[f(t+h)-f(t)]\mathrm{d}t=f(x)-f(a).
$$ If $f$ id diffentiable, the conclution can be obtained by Newton-Leibniz formula easily. When $f$ is just continuous, I tried to use knowledge about integral with parameters. Write $$
F(h,x):=\frac{1}{h}\int_a^x[f(t+h)-f(t)]\mathrm{d}t,
$$ but it seems we still need to compute $\lim_{h\rightarrow 0}\frac{f(t+h)-f(t)}{h}$ , and prove uniform convergence. I have no idea how to go on. Is my thoughts workable? If not, please suggest your way. Appreciate any help!","['integration', 'analysis', 'multivariable-calculus', 'calculus', 'uniform-convergence']"
3932439,Estimate of Bernoulli numbers from the contour integral,"One knows (see https://mathworld.wolfram.com/BernoulliNumber.html )
that the Bernoulli number $B_n$ is $B_n=\frac{n!}{2i\pi}\int_{\mathcal C}\frac z{e^z-1}\frac{\mathrm dz}{z^{n+1}}$ , where $\mathcal C$ is a closed contour included in $\{z\in\mathbb C\mid |z|<2\pi\}$ . With this formula, is it possible to obtain the estimate: $|B_{2n}|\sim4\sqrt{\pi n}\left(\frac n{\pi e}\right)^n$ ? The proof I know depends on the zeta function, that I do not want to use.","['complex-analysis', 'number-theory']"
3932481,Eigenvalues of an almost diagonal matrix [duplicate],"This question already has answers here : How to find the eigenvalues of a block-diagonal matrix? (2 answers) Closed 3 years ago . I know that the eigenvalue of a diagonal matrix is simply the values in the diagonal. However, if I have a matrix of the following form: $$
\begin{bmatrix}
a & b & 0 & 0 \\
b & c & 0  & 0 \\
0 & 0 & d & e \\
0 & 0 & e & f
\end{bmatrix}.
$$ Is there a closed form way to express the eigenvalues of this matrix? I can derive the eigenvalue of the smaller blocks along the diagonal, but how does it relate to the overall matrix?","['matrices', 'eigenfunctions', 'block-matrices', 'eigenvalues-eigenvectors']"
3932511,Why do Mathematica and Wolfram|Alpha say $\Gamma(-\infty)=0$?,"According to Mathematica and Wolfram|Alpha, $\lim_{x\to -\infty}\Gamma(x)$ is equal to zero. See e.g https://www.wolframalpha.com/input/?i=gamma+function (at the bottom of the page), or try Limit[Gamma[x], x -> -Infinity] on Mathematica. This contradicts the fact that $|\Gamma(x)|$ can be arbitrarily large when x is close enough to any negative integer. Is Mathematica and Wolfram|Alpha wrong on this, or is there any other way to interpret this result?","['wolfram-alpha', 'mathematica', 'complex-analysis', 'gamma-function', 'limits']"
3932589,"Can a function be differentiable everywhere on its domain, but not Lipschitz on its domain?","If we suppose that a function is differentiable at every point on its domain (but place no more restrictions than that), does it follow that the function is Lipschitz on its domain? I think that it does not, and I suspect that it is because we do not require that the function is continuously differentiable. But I'm not sure how to prove my thought - specifically, I can't come up with a counterexample. If I am right that it is not Lipschitz, can we say if it will be locally Lipschitz at every point?","['derivatives', 'lipschitz-functions', 'real-analysis']"
3932598,"Calculate $I=\int_0^{2\pi}dx \int_0^{\pi} e^{\sin y(\cos x-\sin x)}\sin y\,dy$","I'm not quite sure how to calculate this integral: $$I=\int_0^{2\pi}dx \int_0^{\pi}  e^{\sin y(\cos x-\sin x)}\sin y\,dy$$ With Mathematica I see the result is $2\pi \sqrt 2 \sinh \sqrt 2$ . Is there any special technique for calculating this integral? Any help will be appreciated. Thank you for these brilliant solutions using Bessel function or complex analysis. After looking into this integral for a long time I found another ""primary"" solution: Rewrite it as $$I=\int_0^{2\pi}d\theta \int_0^{\pi}  e^{\sin \varphi(\cos \theta-\sin \theta)}\sin \varphi\,d\varphi$$ By polar coordinates it becomes $$I=\int_{u^2+v^2+w^2=1} e^{u-v}\,dS$$ since $dS=\sin\varphi d\theta d\varphi$ . Then choose an orthogonal transform such that $z=\frac{u-v}{\sqrt 2}$ , we get $$I=\int_{x^2+y^2+z^2=1} e^{\sqrt 2 z}\,dS$$ Going back to polar coordinates it becomes $$I=\int_0^{2\pi}d\theta \int_0^{\pi}  e^{\sqrt 2 \cos\varphi}\sin \varphi\,d\varphi$$ And finally we get $$I=2\pi \int_{-1}^1 e^{\sqrt 2 t}\,dt$$","['integration', 'definite-integrals', 'multivariable-calculus', 'calculus', 'multiple-integral']"
3932628,Area between two given equations,"Let $x^2 + y^2$ = 6 and $x = y^2$ . What is the area between them? I solved the two equations in terms of y and I graph it in Geogebra: https://www.geogebra.org/classic/ahnk4hfw Solving the two equations in terms of x, the graph is: https://www.geogebra.org/classic/nwznqk3c When I integrate in terms of y (the graph is the first one), the bounds are - $\sqrt 2$ and $\sqrt 2$ . The integrand is $ \sqrt {6-y^2} $ - $y^2$ . I got 4.63 as the area. $$\int_{-\sqrt 2}^{\sqrt 2} \sqrt {6-y^2} - y^2 \, dy = 4.63 $$ Although, I am not sure if I expressed the integral correctly because it seems that I am missing one function: the - $\sqrt {6-y^2} $ . When I follow the second graph, isn't it that the whole region is bounded by the two functions, and hence the area is the circle's area? Or should I only choose the positive square roots and not the negative ones? My last question is, what is the best approach of finding the integral of this case? Is it by integrating with respect to y or x? Do I only need to take the smaller region?","['calculus', 'area', 'analysis']"
3932637,What is the error in my work for this related rates problem?,"I have no clue why my math isn't working out and it is very frustrating. I feel as if I have the concepts correct; however, I just keep getting the wrong answer. Help?","['related-rates', 'calculus', 'derivatives']"
3932683,Prove that a summation is convergent,"Let $\{x_n\}$ be a decreasing sequence of positive numbers and $\lim_{n \to \infty} x_n = 0$ .
Prove that the following summation is convergent.(Hint: Use alternating series test.) $$S = x_1 -\frac{1}{2}(x_1+x_2) +\frac{1}{4}(x_1+x_2+x_3)-\frac{1}{8}(x_1+x_2+x_3+x_4) + \dots$$ My try: Let $$S_n = \frac{1}{2^{n-1}}\sum_{m=1}^nx_m$$ So we are interested in the convergence of $$S = \sum_{n=1}^{+\infty}(-1)^{n+1}S_n$$ We can prove that $\{S_n\}$ is a decreasing sequence: $$S_{n+1} - S_n = \frac{1}{2^{n}}\sum_{m=1}^{n+1}x_m - \frac{1}{2^{n-1}}\sum_{m=1}^nx_m = \frac{x_{n+1}}{2^n} + (\sum_{m=1}^nx_m)(\frac{1}{2^n} - \frac{1}{2^{n-1}}) = \frac{1}{2^{n-1}}(\frac{x_{n+1}}{2} + (\sum_{m=1}^nx_m)(\frac{1}{2} - 1))$$ $$\frac{x_{n+1}}{2} + (\sum_{m=1}^nx_m)(\frac{1}{2} - 1)\le0 \iff x_{n+1} - \sum_{m=1}^nx_m \le 0 \iff x_{n+1} \le \sum_{m=1}^nx_m$$ Which is true since $x_{n+1} \le x_n$ and $x_n\ge 0$ . Therefore we have $S_{n+1}\le S_n$ . Obviously $S_n \ge 0$ for all $n$ and we should prove $\lim_{n\to \infty}S_n = 0$ in order to use alternating series test. I couldn't prove that and got stuck here.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
3932729,Identify $S = 0$ for any set $S$ and form a non-boolean ring out of $\Delta$ on sets?,"Let $S$ be a set and define for each $A \subset S$ the negative of $A$ to be $-A = S \setminus A$ .  So that $A + S\setminus A = S$ .  Thus we identify $0 = S$ .  The $+$ operation is still $\Delta$ so if $-A$ were more than $S \setminus A$ it would be less than $S$ when $\Delta$ 'd with $A$ , similarly it can't be smaller than $S \setminus A$ .  Therefore for $|S| \geq 2$ , $R$ the ring formed is not boolean , as is the usual case for such $\Delta$ (symmetric difference) rings.  Is this then just $\mathcal{P}(S)/(S)$ where $(S)$ is the ideal generated by the whole set $S \in \mathcal{P}(S)$ the power set of $S$ ? Therefore, you can quotient a boolean ring and achieve a non-boolean ring?  That doesn't seem possible, you can't have a surjective $h: A \to B$ such that $A$ is boolean while $B$ is non-boolean. So where did I make an error?","['boolean-algebra', 'ring-theory', 'abstract-algebra', 'elementary-set-theory', 'boolean-ring']"
3932753,In what sense is logical entailment a set-theoretic relation?,"In set theory a relation is a subset of a Cartesian product. I suppose that in logics this product is the Cartesian square of the powerset of all propositions(?). Semantic/model-theoretic entailment between two sets holds (is ""true""?) when there is no interpretation that makes elements left of the double turnstile $\vDash$ all true and elements on the right all false. Syntactic/proof-theoretic entailment $\vdash $ holds if you can derive the RHS from the LHS. In what formal sense are these set theoretic relations, and is this at all important?","['propositional-calculus', 'predicate-logic', 'model-theory', 'logic', 'elementary-set-theory']"
3932757,A combinatorial identity involving Stirling numbers of the second kind,"Answering a recent question I came across the following interesting identity: $$
\sum_{k=0}^m\binom mk{n+k+1 \brace k+1}k!=\sum_{k=0}^m\binom mk (-k)^{m-k}(k+1)^{n+k}.
$$ Is there a simple way to prove it?","['summation', 'binomial-coefficients', 'combinatorics', 'stirling-numbers']"
3932778,Constructively embedding $\mathbb{Q}^\mathbb{N}$ into $\mathbb{R}$,"Using the axiom of choice it is provable that $\mathbb{R}$ is isomorphic to $\mathbb{Q}^\mathbb{N}$ as a vector space over $\mathbb{Q}$ . (Assuming AC, both spaces have a Hamel basis over $\mathbb{Q}$ of the same cardinality and are thus isomorphic.) So my question is whether such an isomorphism between $\mathbb{R}$ and $\mathbb{Q}^\mathbb{N}$ can be constructed without AC or, at least, whether we can embed $\mathbb{Q}^\mathbb{N}$ into $\mathbb{R}$ without AC. (By embedding I mean constructing an injective $\mathbb{Q}$ -linear map from one space into the other.) The latter is equivalent to asking whether we can construct a subspace of $\mathbb{R}$ that has a schauder-basis over $\mathbb{Q}$ , as such a subspace should automatically be isomorphic to $\mathbb{Q}^\mathbb{N}$ . Thanks for the help!","['schauder-basis', 'logic', 'vector-spaces', 'abstract-algebra', 'axiom-of-choice']"
3932793,Quadratic formula in differential equations,"$$(y')^2 + y' =\frac{y}{x} \tag{0}$$ The solution of this differential equation involves using the quadratic formula for a quadratic in terms of $y'$ but I'm a bit bothered that we get a $ \pm$ when we do that: $$y'  =- \frac12 \pm \sqrt{\frac{4y}{x} +1} \tag{1}$$ And then we could do $y=xt$ and solve but how exactly do we understand the plus or minus quantity which we get in step-1? It seems that the procedure of completing the quadratic formula generates two differential equation which solves the one in (0). So, should I solve both ones and the actual solution for (0) is a linear combination of both?",['ordinary-differential-equations']
3932910,"Smoothness of quotient of Holder continuous functions, provided the decay","Let $I=(-1,1)$ and $u \in \text{Lips}(I)$ , the space of Lipschitz continuous functions in I. Suppose that $$
|u(x)|  \le C |x|^\alpha
$$ for $x \in I$ , for some $\alpha \in (1,2)$ . I would like to estimate the Holder continuity of $$
v(x)=
\begin{cases}
|x|^{-\beta}\cdot u(x) &\text{ for } x \neq 0
\\
0& \text{ for } x =0
\end{cases}
$$ for some $1<\beta<\alpha$ (so that $|x|^{\beta}$ is also in $\text{Lips}(I)$ ) in the whole interval $I$ . It is clear that $v$ is in $\text{Lips}(I \setminus (-\varepsilon,\varepsilon))$ (and therefore $C^{\alpha-\beta}(I\setminus (-\varepsilon,\varepsilon))$ ) for any $\varepsilon \in (0,1)$ . and We also know that $v$ is ""Holder continuous at $0$ "", that is, $|v(x)-v(0)| \le C |x|^{\alpha-\beta}$ . Is it true that $v$ is Holder of order $\alpha - \beta$ ? The problem, of course, is to check if the Holder condition holds over sequences $\{x_n\}_n$ and $\{y_n\}_n$ such that $|x_n-y_n|\ll |y_n| \longrightarrow 0$ . I managed to prove that $v$ is in $C^{1-\beta/\alpha}(I)$ . Without further hypothesis, is this the best Holder smoothness $v$ can have in $I$ ? The choices of $\alpha$ and $\beta$ seemed to be a convenient regime to start, but the question could be done in a more general setting. EDIT Let me put my proof of the Holder regularity $1- \beta/\alpha$ .
Assum w.l.o.g that $|x|<|y|$ . We have from hypothesis that $$
|u(x)-u(y)| \le L |x-y|
$$ and for some constant $L>0$ and that $$
|u(x)-u(y)| \le C (|x|^\alpha+|y|^\alpha) \le 2C |y|^\alpha. 
$$ thefore, writing $|u(x)-u(y)|=|u(x)-u(y)|^{\delta}|u(x)-u(y)|^{1-\delta}$ ,
we have $$
\tag{1}
|u(x)-u(y)| \le C^\prime |x-y|^{(1-\delta)}|y|^{\delta\alpha}.
$$ Now, we write $$
\left | \frac{u(x)}{|x|^\beta}-\frac{u(y)}{|y|^\beta} \right|
=
\left | \frac{u(x)}{|x|^\beta} \frac{u(x)-u(y)}{|y|^\beta}-\frac{u(x)-u(y)}{|y|^\beta} \right|.
$$ Using the triangular inequality and $(1)$ and the fact that $|x|^\alpha$ is Lipchitz, we have \begin{align*}
\left | \frac{u(x)}{|x|^\beta}-\frac{u(y)}{|y|^\beta} \right|
&
\le C^{\prime \prime} \left [
|x|^{\alpha-\beta} |x-y|
+|y|^{\delta\alpha-\beta}|x-y|^{1-\delta}
\right]
\end{align*} We then choose $\delta = \beta/\alpha$ , and we get that the RHS is bounded by $C^{\prime \prime}|x-y|^{1-\beta/\alpha}$ .","['partial-differential-equations', 'holder-spaces', 'functional-analysis', 'real-analysis']"
3932921,Interesting infinite nested square roots of 2 for $2\cos1°$ and $2\sin1°$,"It is interesting to note that any angle between 45° to 90° satisfying $1\over4$ < $p \over q$ < $1\over2$ where $ p \over q$ is of form $p = 2^n $ and $q$ is an odd number satisfying $2^{n+1} <q <2^{n+2}$ can be represented as cyclic infinite nested square roots of 2 ( Hereafter referred as $cin\sqrt2$ ) Interestingly 64° falls between 45° and 90° and can be represented in radians as $16\pi \over 45$ Expansion of $2\cos\frac{16\pi}{45}$ happens as follows $2\cos\frac{16\pi}{45} = \sqrt{2+2\cos\frac{32\pi}{45}} =\sqrt{2-2\cos\frac{13\pi}{45}} $ $=\sqrt{2- \sqrt{2+2\cos\frac{26\pi}{45}}} = \sqrt{2- \sqrt{2-2\cos\frac{19\pi}{45}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2+2\cos\frac{38\pi}{45}}}} = \sqrt{2-\sqrt{2-\sqrt{2-2\cos\frac{7\pi}{45}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+2\cos\frac{14\pi}{45}}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+2\cos\frac{28\pi}{45}}}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-2\cos\frac{17\pi}{45}}}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2+2\cos\frac{34\pi}{45}}}}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-2\cos\frac{11\pi}{45}}}}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+2\cos\frac{22\pi}{45}}}}}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+2\cos\frac{44\pi}{45}}}}}}}}}$ $=\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-2\cos\frac{\pi}{45}}}}}}}}}$ ....1 For the sake of simplicity last nested radical can be represented as $n\sqrt2[3-1+2-1+1-]$ (nested square roots of 2 having $3-1+2-1+1-$ ) $2\cos\frac{\pi}{45}$ is represented as $\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+2\cos\frac{16\pi}{45}}}}}$ or simply as $n\sqrt2(4+2\cos\frac{16\pi}{45})$ ...2 Combining 1 & 2 will be single cycle of nested radical for $2\cos\frac{16\pi}{45}$ simply represented as $n\sqrt2[3-1+2-1+1-4+]$ Now we can represent $2\cos\frac{16\pi}{45}$ as cyclic infinite nested square roots of 2 as $cin\sqrt2(3-1+2-1+1-4+)$ As $64^\circ$ is $(2^6)^\circ$ taking half angle for 6 times will give noncyclic nested square roots of 2 as $n\sqrt2(6+)$ Therefore $2\cos1°$ can be represented as $n\sqrt2(6+)cin\sqrt2[3-1+2-1+1-4+]$ and $2\sin1°$ can be represented as $n\sqrt2(1-5+)cin\sqrt2[3-1+2-1+1-4+]$ This opens the world of nested square roots of 2 for calculating $2\cos1°$ or $2\sin1°$ without any need  by taking root of cubic equation which involves imaginary component. And no need to know the value of $\pi$ to evaluate trig values as in Taylor series expansion. Calculating single cycle itself provides result with accuracy of 7 digits after decimal point. (Six '2's in noncyclic part ten '2's in first cycle in infinite radical.) With available scientific calculators and by programming, I have confirmed the results (for a long Post like this I feel it is difficult to incorporate those things) My question is, is it possible to simplify above procedures by some other means?","['nested-radicals', 'trigonometry', 'pi']"
3932997,$(x^2 + 3)(x^3 - q) = 0$,"I'm trying to show that $(x^2 + 3)(x^3 - q) = 0$ is a counter-example to the Hasse Principle when $q \equiv 1 $ (mod $27$ ) is prime.
That is the above equation has solutions in $\Bbb{R}$ , $\Bbb{Q}_p$ for all primes $p$ (p-adic integers) but none in $\Bbb{Q}$ . It is clear that the equation has solutions in $\Bbb{R}$ and it's also clear it doesn't have any in $\Bbb{Q}$ . For the $\Bbb{Q}_p$ case, I have shown that it has solutions when $p \equiv 1$ modulo 3 as when $p \equiv 1$ (mod 3) then -3 is a quadratic residue, and so the equation has a solution in $\Bbb{F}_p$ which lifts to one in $\Bbb{Q}_p$ by Hensel's Lemma. I have also show than the equation has a solution in $\Bbb{Q}_p$ when $p = 3$ . Thus I'm left to showing that it has solutions in $\Bbb{Q}_p$ when $p \equiv 2$ modulo 3.
I'm stuck on this part! I believe it will come down to showing there is some $a$ such that $a^3 \equiv q$ (mod p) for all such primes $p$ , and then such a solution can be lifted by Hensel's lemma. However I've no idea how to do this. Any help with showing this much appreciated.","['number-theory', 'modular-arithmetic', 'prime-numbers']"
3933000,Partition function for a general Ising model as Gaussian integral,"Consider the Hamiltonian of Ising model $$H= - \sum_{x,y} J_{x,y}\sigma_x \sigma_y -  \sum_x h\sigma_x$$ where $\sigma_x$ can be $1$ or $-1$ and the number of sites is finite ( i.e. there are a finite number of $x,y$ ) and where $x,y$ are points of the a $d$ -lattice with side $L$ (i.e. $x,y \in \mathbb{Z} \cap[-L/2,L/2].$ So the partiction function is $$Z=\sum_{\sigma}e^{-\beta H}=\sum_{\sigma}e^{\beta\sum_{x,y} J_{x,y}\sigma_x \sigma_y} e^{\sum_x h\sigma_x}$$ where the sum is over all the possible choice of $\sigma=\pm 1$ . The goal is to write the partiction function as a Gaussian integral using the following formula $$\int e^{-\frac{1}{2}\sum\limits_{i,j=1}^{n}A_{ij} x_i x_j+\sum\limits_{i=1}^{n}B_i x_i} d^nx=\int e^{-\frac{1}{2}\vec{x}^T \mathbf{A} \vec{x}+\vec{B}^T \vec{x}} d^nx= \sqrt{ \frac{(2\pi)^n}{\det{A}} }e^{\frac{1}{2}\vec{B}^{T}\mathbf{A}^{-1}\vec{B}}$$ in view of the fact that $e^{\beta\sum_{x,y} J_{x,y}\sigma_x \sigma_y}$ has the form $e^{\frac{1}{2}\vec{B}^{T}\mathbf{A}^{-1}\vec{B}}$ ( thinking $\sigma=(\sigma_{x_1},...)$ as a vector with $L^d$ components and $J=(J_{xy})$ as a matrix $L^d\times L^d$ ) . Now, what i read on the notes is that $$e^{\beta\sum_{x,y} J_{x,y}\sigma_x \sigma_y}= (2\pi)^ {L^d}(detJ)^{-1/2}\int_{-\infty}^{+\infty}\prod_{x} d \varphi_x e^{-\frac{1}{2\beta}\sum_{x,y}\varphi_x J^{-1}_{xy}\varphi_y + \sum_{x}\varphi_x \sigma_x}.$$ To verify the last formula I tried to calculate the integral in the right head side using the classical techniques for the Gaussian integral (
completion of the square), but I didn't found the last formula. So my question is: is there something wrong with the last expression for $e^{\beta\sum_{x,y} J_{x,y}\sigma_x \sigma_y}$ as Gaussian integral?","['gaussian-integral', 'analysis', 'statistical-mechanics', 'quantum-mechanics', 'dynamical-systems']"
3933048,Partial Differentiation using chain rule,"I am trying to express $\frac{\partial^2u}{\partial y^2}$ and $\frac{\partial^2u}{\partial x\partial y}$ of the function $u=f(x,y,g(x,y))$ with partial derivative notation of $f$ and $g$ . However I am having a hard time doing so because I am a bit confused with the notation. I know that $\frac{\partial u}{\partial y}=\frac{\partial f}{\partial y}+ \frac{\partial f}{\partial g}\frac{\partial g}{\partial y}$ . But the problem is that I am not sure how to express $\frac{\partial^2u}{\partial y^2}$ . If I differentiate the $\frac{\partial u}{\partial y}$ by $y$ , I am thinking I will get $\frac{\partial^2 u}{\partial y^2}=\frac{\partial^2 f}{\partial y^2}+ ...$ , but I am not quite sure how the second term of the right hand side ( $\frac{\partial f}{\partial g}\frac{\partial g}{\partial y}$ ) will look like. Similarly, I have trouble in expressing $\frac{\partial^2u}{\partial x\partial y}$ using partial differentiation notation of $f$ and $g$ . How should it be done? Thanks.","['multivariable-calculus', 'calculus', 'partial-derivative', 'derivatives', 'chain-rule']"
3933060,Prove the determinant is $0$,"This is Problem 16.17 from the book Exercises in Algebra by A. I. Kostrikin. Prove that $$
\left|\begin{array}{ccccc}
\dfrac{1}{2 !} & \dfrac{1}{3 !} & \dfrac{1}{4 !} & \cdots & \dfrac{1}{(2 k+2) !} \\
1 & \dfrac{1}{2 !} & \dfrac{1}{3 !} & \cdots & \dfrac{1}{(2 k+1) !} \\
0 & 1 & \dfrac{1}{2 !} & \cdots & \dfrac{1}{(2 k) !} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & \dfrac{1}{2 !}
\end{array}\right|=0, \quad k \in \mathbb{N}
$$ My Attempt: I tried to expand it by the first column, but it seemed to be more complicated when I did that. I also tried to add edges to the determinant(in the hope that it will be easier to calculate), but I still failed to work it out. So, My Question is , how to calculate this determinant?","['determinant', 'linear-algebra', 'combinatorics', 'factorial']"
3933081,"$X_1,...,X_n \text{ iid }X_1\sim \operatorname{Ge}\big( \theta\big)\implies \mathbf X =(X_1,...,X_n)^T \in \text{ Exponential Family}$","$$\bullet \text{ Let} \quad X_1,X_2,...,X_n \text{ iid }X_1\sim \operatorname{Ge}\big( \theta\big)$$ $$\text{Goal: } \mathbf X =(X_1,...,X_n)^T \in \text{ Exponential Family of distributions.}$$ $$\text{ Its enough to show that :}$$ $$\exists \phi \in \Phi \subseteq \mathbb R^k,k\in\mathbb N, \text{parametric space s.t pmf:}$$ $$f(\mathbf X;\phi)=h(x)\cdot \exp{\bigg\{ \big< s(\mathbf X),\phi \big>_{\mathbb R^k} -K(\phi)\bigg\}},\mathbf X\in \mathcal X ,\phi\in\Phi . $$ $$\text{Note : $\big< \cdot \big>$ Inner product on  $\mathbb R^k$}.$$ $$\text{pmf of Geometric distr: }\Omega =\mathbb N,\operatorname{P}\big( X=x\big)=f_X(x)=(1-\theta )^{x-1}\theta .$$ $$\text{cdf: }F_X(x)=\operatorname{P}\big( X\le x \big)=1-(1-\theta )^x $$ $\text{So,}$ $$F_{\mathbf X}(\mathbf x)=\operatorname{P}\big(X_1\le x_1,X_2\le x_2,...,X_n\le x_n \big)=$$ $$ \color{black}{\underbrace{ \operatorname{P}\big(X_1\le x_1\big) \operatorname{P}\big(X_2\le x_2\big)\cdots \operatorname{P}\big( X_n\le x_n \big)=   }_{\text{independent}  }}$$ $$=\color{black}{\underbrace{ \operatorname{P}\bigg(X_1\le x_1 \bigg)^n   }_{ \text{identically }}}\implies F_{\mathbf X}'(\mathbf x)=n\operatorname{P}\big( X_1\le x_1\big)^{n-1}\cdot f_{X_1}(x_1) $$ $$=n\big( 1-(1-\theta )^{x_1}\big)^{n-1}\cdot \theta \big( 1-\theta \big)^{x_1-1}=f_{\mathbf X}(\mathbf x)$$ So, how can i continue the proof from this point? This is as far as  i can get... Any ideas? Thank you.","['statistical-inference', 'statistics', 'probability-distributions', 'exponential-distribution', 'probability-theory']"
3933125,Why does the definition of two variable differentiability include the partial derivatives of x and y?,"During calculus I was introduced to the definition of multi variable differentiability, which is defined as: $\lim_{(h,k)\to(0,0)}\frac{f(a+h, b+k)-f(a,b)-h\cdot f_x(a,b)-k\cdot f_y(a,b)}{\sqrt{h^2+k^2}}=0$ Now I don't seem to understand why the partial derivatives of x and y are inside the above definition. Let's says I would like to prove that a 2 variable function is differentiable at point (a,b), then it seems logical to state that differentiability means (this actually follows from the single variable definition): $\lim_{(h,k)\to(0,0)}\frac{f(a+h, b+k)-f(a,b)}{\sqrt{h^2+k^2}}=L_{h,k}$ Replacing $h$ and $k$ respectfully with $h=r\cos(\theta)$ and $k=r\sin(\theta)$ we acquire: $\lim_{r\to0}\frac{f(a+r\cos\theta, b+r\sin\theta)-f(a,b)}{r}=L_{r,\theta}$ So if function $f$ is differentiable then for each angle $ 0 \le\theta\le360$ in degrees a corresponding limit $L$ should exist and therefore $f$ is differentiable if all the limits holds for very small $r$ and all angles. In fact, with this definition we also test whether the partial derivatives of x and y exist. Hence I don't comprehend why the definition of two variable differentiability must include the partials x and y, it simply doesn't make sense. All it seems to be proving is that any linearization around point (a,b) can be expressed as a combination of linearizations of $f_x$ and $f_y$ . Thanks in advance. Jelle","['limits', 'multivariable-calculus', 'derivatives']"
3933156,Probability that the connection broke down in this grid,"See below chart. The yellow blocks are two islands. It's connected by
a grid of cables. There are 16 vertical cables and 9 horizontal cables
and 12 nodes (blue highlighted) in between. Hurricane strike and each cable has 1/2 probability of breaking. Two
islands lost contact when there is no path to go from one island to
the other on the grid. What's the probability that these two islands
lost contact? I am thinking of something like letting $f(1,1)$ be the probability that the top left node cannot be reached from top island. Then $f(1,1) = 0.5 \cdot (0.5 \cdot (1-f(1,2)) + f(1,2))$ . Reason is you need the direct cable from top island to first node broke, and you either need cable from $(1,1)$ to $(1,2)$ broke, or $f(1,2)$ broke. But the equation starts to get a bit messy. It looks like this might be able to expressed in matrix form or Markov Chain or some sort though..","['contest-math', 'combinatorics', 'reliability', 'probability']"
3933189,Series expansion of $x\sqrt{x^2-1} - \ln(x + \sqrt{x^2-1} )$ at $x=1$,"In various texts it is stated that a good approximation of, $x\sqrt{x^2-1} - \ln(x + \sqrt{x^2-1} )$ , about $x=1$ is given by, $\frac{4\sqrt{2}}{3} (x-1)^{3/2}$ . Plotting the graphs this is indeed the case, however, I am not sure how this approximation is derived. Entering the original equation in Wolfram Alpha it does list the above approximation as the first term in the Puiseux series expansion of the original function. I am not familiar with these and looking online I can't seem to find a way into calculating a Puiseux series for the relevant expression. Any suggestions or pointers for how to go about this would be greatly appreciated :)","['power-series', 'algebra-precalculus', 'taylor-expansion', 'laurent-series']"
3933215,Is an group determined by its torsion part and torsion-free part?,"Let $G$ be an abelian group.  Let $G_T$ be the torsion part of $G$ , i.e. the set of all elements of $G$ of finite order.  And let $G_F$ be the torsion-free part of $G$ , i.e. the set containing $0$ along with all elements of $G$ of infinite order.  Then my question is, is the isomorphism type of $G$ uniquely determined by the isomorphism types of $G_T$ and $G_F$ ? I think this is definitely true in the case when $G$ is finitely generated, but I'm asking about the general case.","['torsion-groups', 'exact-sequence', 'abstract-algebra', 'group-theory', 'abelian-groups']"
3933241,"Find, in radians the general solution of cos 3x = sin 5x","I am studying maths as a hobby. I have come across this problem: Find a general solution for the equation cos 3x = sin 5x I have said, $\sin 5x = \cos(\frac{\pi}{2} - 5x)$ so $\cos 3x = \sin 5x \implies 3x = 2n\pi\pm(\frac{\pi}{2} - 5x)$ When I add $(\frac{\pi}{2} - 5x)$ to $2n\pi$ I get the answer $x = \frac{\pi}{16}(4n +1)$ , which the book says is correct. But when I subtract I get a different answer to the book. My working is as follows: $3x = 2n\pi - \frac{\pi}{2} + 5x$ $2x = \frac{\pi}{2} - 2n\pi$ $x = \frac{\pi}{4} - n\pi = \frac{\pi}{4}(1 - 4n)$ but my text book says the answer is $\frac{\pi}{4}(4n + 1)$ Is the book wrong?",['trigonometry']
3933243,"Is $f(n)=\sqrt{n}$ the only function from $\Bbb{N}_0$ to $[0,\infty)$, with $f(100)=10$ and $\sum_{k=0}^n\frac{1}{f(k)+f(k+1)}=f(n+1)$?","Let $f:\mathbb{N_0} \rightarrow \left[0,\infty\right)$ be a function such that a) $f(100)=10$ b) $\dfrac{1}{f(0)+f(1)}+\dfrac{1}{f(1)+f(2)}+\cdots+\dfrac{1}{f(n)+f(n+1)}=f(n+1)$ for all $n\geq 0$ . Evaluate $f(n)$ . Clearly, $f(n)=\sqrt{n}$ , satisfies the conditions, but my question is, is it the only function possible? I don't see how using the value at $n=100$ would prove the function to be $\sqrt{n}$ , however if instead of $100$ , $f(1)=1$ was given, then we can prove by induction that $\sqrt{n}$ would be the only function by starting from the first term and finding the next term.","['algebra-precalculus', 'functions']"
3933308,Limit of a simple Integral,"Need to show that $$\lim_{t\to 1^-}(1-t)\int_0^t\frac{g(s)}{(1-s)^2}ds=g(1)$$ for any continuous function $g(s)$ . I tried a variable change $u=1/(1-s)$ which gives $du=ds/(1-s)^2$ with $$(1-t)\int_1^{\frac{1}{1-t}}g(1-\frac{1}{u})du$$ I cannot seem to figure out how to get to the limit, given that thus far it's correct.","['integration', 'improper-integrals', 'calculus', 'limits', 'derivatives']"
3933458,Question about proving existence of a function $f$ such that $f \circ f = g$ for an odd function $g$,"I have been reading a book on elementary mathematics and have come to a problem where I don't understand where the solution comes from. The problem goes : ""Let $g : \mathbb{R} \rightarrow \mathbb{R}$ be an odd function, such that $g(x) > 0$ whenever $x > 0$ . Show that there exists a function $f : \mathbb{R} \rightarrow \mathbb{R}$ for which $g = f \circ f$ ."" In the answer key they just say : ""Take $f(x) = -g(x)$ for $x \leq 0$ and $f(x) = -x$ for $x \geq 0$ ."" I am wondering what the reasoning is behind this answer. The truth is that I just want to see a more detailed solution to the problem. Can anyone help with this ?","['even-and-odd-functions', 'functions', 'function-and-relation-composition']"
3933535,What is the definition for an infinite set?,"I'm physicist, not a mathematician, but this time I have following question related to Math:
What is an infinite set per definition?
Of course I know, that a set is infinite, when it is not finite - clear. But lets say I have infinite set M. Assume there is a surjection $f: M \rightarrow \mathbb{N}$ So every element of $m \in M$ points to a given $n \in N$ . Such a set M must be, of course infinite, but does the definition suffice for all infinite sets, including non countable ones so I can say: ""Each infinite set has a surjection $f: M \rightarrow \mathbb{N}$ "" ? For example a surjective function for the non countable infinite set $\mathbb{R^+_0}$ could be $x \in [n-1, n) \mapsto n$ But does my definition include all possible infinite sets and is this definition reasonable at all? Sorry for mathematical incorrectness, but I think one can understand what I mean.",['elementary-set-theory']
3933588,Question on Reeb's theorem.,"I am reading through the first couple of chapters of Milnor's Morse theory, and I've gotten to Reeb's sphere theorem (theorem 4.1), If $M$ is a compact manifold and $f$ is a differentiable function on $M$ with only two critical points, both of which are nondegenerate, then $M$ is homeomorphic to a sphere. Milnor states that for some small enough $\varepsilon > 0$ , the sublevel sets $f^{-1}[0,\varepsilon]$ and $f^{-1}[1-\varepsilon,1]$ are closed $n$ -cells, which follows by the Morse Lemma. But I don't quite follow this. I've read other related posts, but none of them quite flesh out why we need a ""small enough"" $\varepsilon$ , or why exactly the Morse lemma implies that the aforementioned preimages are closed $n$ -cells. Now, I understand that the two critical points will have index $0$ and $1$ , which correspond to the minimum and maximum, but why does applying the coordinate maps given to us my the Morse lemma tell us that we get $n$ -cells, and not only containments? If anyone could clarify, that would be great.","['differential-topology', 'morse-theory', 'smooth-manifolds', 'differential-geometry']"
3933605,"Find $\lim_{(x,y)\to(0,0)} \frac{xy^3}{x+y}$","I have to compute $\displaystyle\lim_{(x,y)\to(0,0)} \frac{xy^3}{x+y}$ . When doing polar coordinates, I get $\displaystyle\lim_{r\to0}r^3\frac{\sin^3(\theta)}{\sin(\theta)+\cos(\theta)}$ but I'm not sure if I can say it's zero because of that denominator. I also tried this limit through lines, a parabola, and axis, all of them zero. My professor said something about ""what happens whe $x+y=0$ ?"" And the hint was to take $\displaystyle\frac{xy^3}{x+y}=1$ which implies $\displaystyle x=\frac{y}{y^3-1}$ and we have to check what happens when $y\to0$ . However, that leads to $0$ . I don't understand what is happening in $\displaystyle x=\frac{y}{y^3-1}$ , maybe something related to mean values theorem?","['multivariable-calculus', 'calculus', 'real-analysis']"
3933657,What is the probability that an event will happen when the probability decreases exponentially?,"So I am just a middle student who started studying probability in my stats class and I see the questions on this site are little advanced so I don't hope this one is too basic. Anyways lets say that the probability of an event happening was some number(like 1%), and each time a trial is run the of the event happening decreases by half(so 1% probability for the first trial, .5% probability for the second, .25% probability, and so on).
What is the probability that the event will happen after 1 trial, 10 trials, 100 trials, and an infinite amount of trials?","['infinity', 'probability']"
3933691,Exact angles of a 3-4-5 triangle,"I am interested in finding exact values for the angles of a 3-4-5 triangle. In particular, I would like to know the exact value of $\frac{1}{4}\sin^{-1}(\frac{4}{5})+\sin^{-1}(\frac{3}{5})$ . For context, this came up in an integral i was solving, mainly for fun. Here is the integral, in case there is a simpler solution: $$\frac{1}{2}\int_0^{\frac{2}{5}}1+f(2t)dt+\int_{\frac{2}{5}}^{\frac{1}{2}}f(t-1)dt-\frac{1}{2}\int_0^{\frac{1}{2}}f(2t-1)dt$$ where $f(x)=\sqrt{1-x^2}$ . I've looked at this question: Prove that the ratio of acute angles in a $3:4:5$ triangle is irrational , so I understand if what I'm asking for is not possible.","['integration', 'trigonometry', 'geometry']"
3933705,Calculating a limit around a differentiable point,"Here is the question: With the knowledge that $f$ has derivative in point $a$ and $k>h>0$ , show that this limit does not necessarily exist: \begin{align*}
lim_{k,h \rightarrow 0^+} \frac{f(a+k) - f(a+h)}{k-h}
\end{align*} Up until this point I tried functions like $f(x) = e^x$ and polynomial functions. which only made me more suspicious about the correctness of problem. Though my closest try was $f(x) = \sqrt{x}$ at point $0$ which almost works but fails to be differentiable at point $0$ . I have also tried to approach $k,h$ in a special way for example the substitution $h = k^n$ for sufficiently large $n$ makes things a little easier but at the end I failed to find a definite answer. Now I dont know if the claim is true or not (it may not be and the limit may always exist) but if so, a nice counter would be very appreciated. Thanks.","['limits', 'calculus', 'derivatives', 'examples-counterexamples']"
3933860,Locus of point at a fixed distance from midpoint of intercepts of a variable line segment with fixed distance,"Let A and B be variable points on the x-axis and y-axis respectively such that the line segment AB is in the first quadrant and of a fixed length 2d. Let C be the mid-point of AB and P be a point such that (a) P and the origin are on the opposite sides of AB and, (b) PC is a line of length d which is perpendicular to AB. Find the locus of P. Source In this problem, I have drawn the figure containing the line AB and point P and everything. I have also named point as(h, k),thereby applying all suitable equations.Inspite of all that, it is getting clumsy.
Can anyone provide a elegant solution to it?","['locus', 'geometry']"
3933958,subdifferential of ReLU function composition with affine function,"Let $f:\mathbb{R}^n\to\mathbb{R}^n$ be ReLU function, i.e., $f(x)=[\max(0,x_i)]_{i=1}^n$ . Let also $g:\mathbb{R}^m \to \mathbb{R}^n$ be an affine function $g(x)=Ax+b$ . What is the subdifferential of $f(g(x))$ ?","['machine-learning', 'functions', 'derivatives', 'subgradient']"
3934049,"What is the probability that a random regular expression defines the language of all binary strings $\{0, 1\}^*$?","Suppose we generate a random regular expression $R$ in the following way: We start with a single meta-symbol $S$ . Then each turn we independently replace all $S$ in our word with $\{0\}$ , $\{1\}$ , $(S \cup S)$ , $SS$ or $S^*$ with equal probability. This process terminates with probability $1$ due to the extinction criterion Galton-Watson branching processes. What is the probability $p$ that $R$ defines the language of all binary strings $\{0, 1\}^*$ ? All I know about this number is that it lies in  in $[\frac{1}{5 \sqrt{5}};\frac{1}{2}]$ . Here $\frac{1}{5 \sqrt{5}}$ is the probability of $R$ containing $(\{0\} \cup \{1\})^*$ or $(\{1\} \cup \{0\})^*$ as a subexpression, derived from the following equation: $x = \frac{2}{5^4} + \frac{1}{5}(5x - 2x^2)$ $2x^2 = \frac{2}{5^3}$ $x = \frac{1}{5 \sqrt{5}}$ And $\frac{1}{2}$ is the probability of $R$ defining an infinite language (which happens iff $R$ contains a Kleene star operator), derived from the following equation: $5y = 1 + 4y - 2y^2$ $2y^2 + y - 1 = 0$ $y = \frac{1}{2}$ However, I have no idea how to find the exact value of $p$ .","['regular-language', 'probability', 'stochastic-processes', 'regular-expressions', 'formal-languages']"
3934108,"Milnor's exercise: for any manifold $M$, $\mathrm{Hom}(C^\infty(M,\mathbb{R}),\mathbb{R})\cong M$","I am studying some chapters of Kolar-Michor-Slovak, Natural Operations in Differential Geometry , in particular the one on Weil bundles, where they present the famous ""Milnor's exercise"". They give two similar proofs, one much shorter than the other, supposedly because of omitted details. I would like to understand it better. So we have to prove the: Theorem For any manifold $M$ , $\mathrm{Hom}(C^\infty(M,\mathbb{R}),\mathbb{R})\cong M$ Where $\mathrm{Hom}$ refers to morphisms of commutative unital algebras and $\cong$ to bijection of sets (I suppose). Now the short proof goes like this: Consider an homomorphism of algebras $C^\infty(M,\mathbb{R}\xrightarrow{\phi}\mathbb{R})$ , by the usual short exact sequence argument , $\ker(\phi)\leq C^\infty(M,\mathbb{R})$ is an ideal of codimension $1$ ( notice that such an homomorphism cannot be the zero map, since $\phi(1_\mathbb{R})=1\in\mathbb{R}$ ). Now, consider the following system of subsets of $M$ , where $V(f)=f^{-1}(0)$ : $$\{V(f)\mid (M\xrightarrow{f}\mathbb{R})\in \ker(\phi)\}$$ this is clearly a filter of closed sets of $M$ , since $V(f^2+g^2)=V(f)\cap V(g)$ . Find a function $M\xrightarrow{f^*}\mathbb{R}\in \ker(\phi)$ which is unbounded on each non-compact closed subset of $M$ ( for instance a positive proper function, such as the square of the geodesic distance w.r.t. any Riemannian metric ). Then $V(f^*)$ is a compact set contained in $\bigcap_{f\in \ker(\phi)} V(f)$ , which is then nonempty. Let $x_0$ be one of its elements.
Then for any $f\in C^\infty(M,\mathbb{R})$ $f-\phi(f)1$ is in $\ker(\phi)$ so $(f-\phi(f)1)(x_0)=0$ , and $\phi(f)=f(x_0)$ .
So $x_0$ completely determines $\phi$ and the map $\phi\mapsto x_0$ is the desired bijection. I have fetched the italicised details. What I am having trouble understanding is the bold passage. Moreover I don't see where we use the fact that the given system of sets is a filter and that $\ker(\phi)$ has codimension 1: I suspect these are relevant for the bold passage also. Any help would be much appreciated.","['proof-explanation', 'manifolds', 'commutative-algebra', 'differential-geometry']"
3934137,Duality between differentiable manifolds and algebras of $C^\infty$ functions.,"As a corollary of Milnor's excercise: for any manifold $M$, $Hom(C^\infty(M,\mathbb{R}),\mathbb{R})\cong M$ , we obtain that Theorem Given any two manifolds $M_1,M_2$ the mapping: $$C^\infty(M_1,M_2)\rightarrow Hom(C^\infty(M_2,\mathbb{R}),C^\infty(M_1,\mathbb{R}))\quad f\mapsto g\xrightarrow{f^*}g\circ f$$ is a canonical bijection Now, this expresses the fact that the functor $C^\infty(\cdot,\mathbb{R}): \mathsf{Man}\rightarrow\mathsf{CAlg}$ is fully faithful. If we restrict to the subcategory of $\mathsf{CAlg}$ whose skeleton is given by the image of the functor, we obtain a duality. My first question is: has this subcategory a particular name? Can we say something more about it? Secondly, the result above reminds one of the immediate consequences of the Yoneda Lemma, but obviously it is not a proper instance of it. Can we link the two somehow? Thirdly: how does this result binds to the algebraic analogue for algebraic varieties and to the Gelfand duality for topological spaces? Can we homogeneously treat any category space as the dual of some subcategory of $\mathsf{CAlg}$ ?","['category-theory', 'reference-request', 'manifolds', 'commutative-algebra', 'differential-geometry']"
3934150,Traversing a maze from one cell to another,"I have maze (10*10) as shown below: Each cell has unique value ranging from [0,15] which actually defines its walls (see the image below). For example, value of first cell (r=0, c=0) is 7 and so on. Now I need to travel from entry point to exit point. Entry point is always at the left side of maze which is created by removing any wall. Same is done on the right side of maze where the exit is. These points will be provided by indicating with an arrow in the image. I know how we actually traverse from one point to another inside rectangular grid. It contains values in binary form where $1$ signify block to that cell and $0$ signify that path is possible from that cell. PS: You will be only provided a 10*10 matrix with values filled accordingly and you will need to get row and column number as a path from entry point to exit point.","['matrices', 'puzzle', 'algorithms']"
3934211,Find recurrence relation and general solution,I need help finding recurrence relation. We will glue a decorative tile with a size of 1 × n squares. We have available tiles of 4 colors with size 1x1 square tiles of 5 colors with size 1x2 square How much combinations is there to make decorative tile of size 1 x n squares? And what's the recurrence relation. I don't even know how to start solving this. Can you solve it or help me?,"['combinations', 'combinatorics', 'recurrence-relations', 'discrete-mathematics']"
3934218,Some questions about determinants,"I'm studying some Linear Algebra and determinants are being a real struggle for me. I can't understand them at all, but my biggest problem is with all the equivalent definitions and why they are in fact equivalent. Given $V, W$ vector spaces, we define the tensor product $\otimes$ of $f \colon V^k \to \mathbb{R}$ and $g \colon W^l \to \mathbb{R}$ as $(f \otimes g )(v_1, \dots, v_{k+l})$ $= f(v_1, \dots, v_k)g(v_{k+1}, \dots, v_{k+l})$ . Also, we define $V \otimes W = \langle v \otimes w \colon v \in V, w \in W \rangle$ (note that the tensor product of vectors is defined, since $V = V^{**}$ , which is a space of functions). Given $V$ a vector space, we define $X = V^{\otimes k} = V \otimes V \otimes \dots \otimes V$ ( $k$ times) and $Y =$ $\langle v_1 \otimes \dots \otimes v_k \colon \exists i,j \textrm{ } v_i = v_j \rangle$ (i.e. the set generated by the tensor product of $k$ vectors in which at least two are equal). We define $\wedge^k V = X/Y$ (call it exterior $k-$ power of $V$ ) and denote $\overline{u_1 \otimes \dots \otimes u_k} = u_1 \wedge \dots \wedge u_k$ . Given those important definitions of tensor product and exterior power of a space, let's introduce the definitions of determinant. Given $V$ a vector space with $\dim V = n$ and $T\colon V \to V$ a linear transformation, note that $\dim \wedge^n V = 1$ . Hence, the linear transformation $\wedge^n T \colon \wedge^n V \to \wedge^n V$ must be of the form $\wedge^n T(v) = cv$ for some constant $c$ . This constant is called the determinant of $T$ and denoted $c = \det T$ . The first thing that bothers me here is the assumption that $\wedge^n T(v) = cv$ for some constant $c$ , why is that? It seems trivial but I'm not getting it. The usual way we see determinants (in high school) is by beeing introduced to determinants of matrices, not of linear operators, but we can translate this definition to matrix just by saying that the determinant of $T$ is the determinant of it's matrix in some basis. My first question is: why is this definition independent of the chosen basis? Given a matrix $M = [m_{ij}]_{n \times n}$ we define its determinant $$\det T = \sum_{\sigma \in S_n} \textrm{sgn}(\sigma) m_{i\sigma(1)}\cdots m_{i\sigma(n)}.$$ Now given both definitions, why are those equivalent? Thanks in advance and if there is anything I can do to make this question better, let me know please!","['determinant', 'linear-algebra', 'tensor-products', 'exterior-algebra']"
3934265,Adjunction of pointed maps is a homeomorphism?,"What interests me the most is if the case of exponential law is true under the assumptions claimed for example on nlab: if $X, Y$ are Hausdorff and $Y$ is locally compact, then $F^0(X, F^0(Y, Z))\cong F^0(X\wedge Y, Z)$ using the pointed adjunction. I split this in two parts for comparison. Part 1: Exponential law in $\text{Top}$ . Let $F(X, Y)$ be the space of continuous functions from $X$ to $Y$ with compact-open topology. We denote the subbasic open set by $(A, W) = \{f\in F(X, Y): f(A)\subseteq W\}$ , $A$ compact, $W$ open. Define adjunction as $\alpha:F(X\times Y, Z)\to F(X, F(Y, Z))$ by $\alpha(f)(x)(y) = f(x, y)$ . $\alpha$ is continuous. Proof: The subbasic open sets in $F(X, F(Y, Z))$ are of the form $(A, (B, W))$ where $A, B$ are compact and $W$ is open. But $\alpha^{-1}(A, (B, W)) = (A\times B, W)$ which is open in $F(X\times Y, Z)$ . Define evaluation map $e_{X, Y}:F(X, Y)\times X\to Y$ by $e_{X, Y}(f, x) = f(x)$ . $e_{Y, Z}$ is continuous for locally compact $Y$ . If $e_{Y, Z}$ is continuous then $\alpha$ is bijective. Above is just to assure that if the map $x\mapsto(y\mapsto f(x)(y))$ is continuous then so is $(x, y)\mapsto f(x)(y)$ . If $X, Y$ are locally compact then $\alpha:F(X\times Y, Z)\cong F(X, F(Y, Z)) $ . Proof: It suffices to show that $\alpha^{-1}$ is continuous. If $$\gamma = e_{X\times Y, Z} \circ (\alpha^{-1}\times \text{Id}_{X\times Y}):F(X, F(Y, Z))\times (X\times Y)\to Z$$ is continuous then $\alpha^{-1}$ is, because we can apply adjunction operator on $\gamma$ to obtain $\alpha^{-1}$ . Easy calculations show that $\gamma(f, (x, y)) = f(x)(y)$ and so $\gamma$ is the composition $$F(X, F(Y, Z))\times (X\times Y) \to (F(X, F(Y, Z))\times X) \times Y \to F(Y, Z)\times Y \to Z   $$ first map being the canonical homeomorphism, second and third being evaluation maps, continuous because $X, Y$ are locally compact. This proves $\alpha$ is a homeomorphism. There is also a similar theorem which I'll mention. Let $Y$ be locally compact, $X, Y$ be Hausdorff. Then $\alpha$ is a homeomorphism. Sketch of proof: It suffices to note that sets of the form $(A\times B, W)$ for compact $A, B$ and open $W$ form a subbasis of $F(X\times Y, Z)$ under our assumptions. Part 2: Exponential law in $\text{Top}^0$ ? Suppose that all spaces are pointed from now on. Let $F^0(X, Y)$ be the subspace of $F(X, Y)$ of pointed continuous functions from $X$ to $Y$ , with base point being the constant map onto the base point of $Y$ . Denote the subbasic sets by $(A, W)^0 = F^0(X, Y)\cap (A, W)$ for compact $A$ and open $W$ . Let $p:X\times Y\to X\wedge Y$ be canonical quotient map. For simplicity we'll denote $p(x, y) = x\wedge y$ . Define adjunction of pointed maps as $\alpha^0:F^0(X\wedge Y, Z)\to F^0(X, F^0(Y, Z))$ by $\alpha^0(f)(x)(y) = f(x\wedge y)$ . $\alpha^0$ is continuous. Proof: As before, $(\alpha^0)^{-1}(A, (B, W)^0)^0 = (p(A\times B), W)^0$ , the sets of the form $(A, (B, W)^0)^0$ being subbasic. Define the pointed evaluation map $e_{X, Y}^0:F^0(X, Y)\wedge X\to Y$ by $e_{X, Y}^0(f \wedge x) = f(x)$ . $e_{Y, Z}^0$ is continuous for locally compact $Y$ . If $e_{Y, Z}^0$ is continuous then $\alpha^0$ is bijective. This is again just so that if $x\mapsto(y\mapsto f(x)(y))$ is continuous then also $x \wedge y\mapsto f(x)(y)$ . Finally: If $X, Y$ are locally compact, is $\alpha^0:F^0(X\wedge Y, Z)\cong F^0(X, F^0(Y, Z))$ ? Attempt at a proof: Once again we only need to show that $(\alpha^0)^{-1}$ is continuous. Consider the map $$\gamma^0 = e_{X\wedge Y, Z}^0 \circ ((\alpha^0)^{-1}\wedge \text{Id}_{X\wedge Y}) : F^0(X, F^0(Y, Z))\wedge (X\wedge Y)\to Z $$ explicitly $\gamma^0(f \wedge (x \wedge y)) = f(x)(y)$ . If $\gamma$ is continuous then by some version of pointed adjunction, so is $\alpha^{-1}$ . Once again we can decompose it into three maps, one being canonical and other two being pointed evaluation maps. However, the approach breaks down. Denoting $Q = F^0(X, F^0(Y, Z))$ , we'd have to show that the canonical map $Q\wedge (X\wedge Y)\to (Q \wedge X)\wedge Y$ is continuous. If we look at the statement of associativity of smash product, its proof uses Whiteheads theorem: If $q:X\to Y$ is quotient and $Z$ is locally compact then $q\times \text{Id}_Z$ is a quotient. More explicitly, to show that $Q\wedge (X\wedge Y)\to (Q\wedge X)\wedge Y$ is continuous, it uses that $Q$ is locally compact by showing $\text{Id}_Q\times p$ is a quotient map. Now to save this proof, two things come to mind. Assume that $Q$ is locally compact. I think this is a heavy and unwieldy assumption. Assume that $p$ is a proper map. This is somewhat better, and in case when $X, Y$ are compact Hausdorff spaces, $X\wedge Y$ is also compact Hausdorff as shown here https://math.stackexchange.com/a/1645794/476484 so $p$ is proper. Lastly, I'll mention an analogous theorem If $Y$ is locally compact, $X, Y$ are Hausdorff, $p$ is proper, then $\alpha^0$ is a homeomorphism. Sketch of proof: Show that sets of the form $(p(A\times B), W)^0$ where $A, B$ are compact and $W$ is open form a subbasis of $F^0(X\times Y, Z)$ . Main reference: ""Algebraic Topology"" by Tammo tom Dieck, Section 2.4 Reference to the case when $X, Y$ are compact Hausdorff: ""Algebraic Topology"" by C. R. F. Maunder, Theorem 6.2.38 c) Wikipedia reference nLab reference for smash product . Note the exponential law here is stated for pointed sets . nLab reference for exponential law This article lead me to the following reference, after I consulted the article with professor Zoran Škoda who wrote it: ""Lectures on Algebraic Topology. Fundamentals of homotopy theory."" by M. M. Postnikov (there seems to be no English version, but there is a Russian one) Postnikov claims that $p^*:F^0(X\wedge Y, Z)\to F^0(X\times Y, Z)$ is a topological embedding. It's clear to me that this map is continuous and injective. However, I'm not sure how to prove $p^*(A, V)^0$ is open in $p^*F^0(X\wedge Y, Z)$ . This can be found at the beggining of Chapter 4. Update : There was a good point towards me that the version on nlab is different. The claim that $F^0(X\wedge Y, Z)\cong F^0(X, F(Y, Z))$ are homeomorphic under suitable assumptions. But the map can lack to even be bijective under those assumptions. Consider $X = Y = Z = \{0, 1\}$ with discrete topology and base point $0$ , then $|F^0(X\wedge X, X)| = |F^0(X, X)| = 2$ but $|F^0(X, X^X)| = 4$ . Because of this let's assume they meant the version with $F^0(X\wedge Y, Z)\cong F^0(X, F^0(Y, Z))$ . cross-posted from math.overflow","['general-topology', 'algebraic-topology']"
3934274,For which type of input does this operation repeat the outcome eventually and run forever?,"This problem is a part of another (programming) problem on which I am working, the start of which requires us to identify a certain pattern, I believe. We are given a pair of positive integers x and y. We are going to perform an operation on this pair repeatedly to obtain a pair with equal values. We could as well say that this operation tries to balance this pair of integers so as to make them equal. The balancing operation is as follows: If the pair has unequal values, take the minimum, add it to the smaller integer and subtract it from the larger one.
If the pair still has unequal values, repeat this operation on the new values. The task is to find whether this operation will run forever or eventually stop(making the values equal)? Can this be determined by seeing the initial input itself? Hint for remembering the operation easily : The smaller one gets doubled, the larger one diminishes by value equal to the smaller one. See examples below. Example: Start with (1, 4). We see that (1, 4) --> (2, 3) --> (4, 1) --> (3, 2) --> (1, 4). At this point it is clear that this operation will not give equal values for the pair(1, 4). Also, at the point when we got the interchanged values (4, 1), we could say that they are going to be repeated (I guess). Example: Start with (1, 1). We see that the numbers are already equal. So, this operation is not applied. Or, we could say the algorithm/operation terminated at the start itself. Example: Start with (5, 8). We see that (5, 8) --> (10, 3) --> (7, 6) --> (1, 12) --> (2, 11) --> (4, 9) --> (8, 5) --> (3, 10). If ordering is ignored, the values look the same as before. They are in cycle. It will not give equal values ever. Example: Start with (1, 3). We see that (1, 3) --> (2, 2). Operation terminated since the pair has equal values now.","['functions', 'sequences-and-series', 'algorithms', 'binary-operations', 'pattern-recognition']"
3934285,Comparing cardinalities between infinite sets,"What is the relation of the cardinalities of the following two sets A and B, where A = the set of all subsets of the set of all even natural numbers and B = the set of all ﬁnite subsets of the set of all rational numbers? My reasoning: B is countable because the set of finite subset of a countably infinite set is countable. Therefore, we have that B as the same cardinality of the set of natural numbers. Furthermore, the set of all even natural numbers has the same cardinality of the set of natural numbers, as I guess we can find a bijection among them. But by Cantor's theorem as |P(X)|>|X|, therefore A as a greater cardinality of the set of natural numbers, hence, |A|>|B|. Is this reasoning correct? If not, what should I change? On top of that, do you have any tips on how to write it formally, in a proper proof? Thank you in advance.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3934300,Why have separate definitions for expectation and conditional expectation?,"I am taking a graduate course in probability and I am baffled by the definition of conditional expectation. We defined conditional expectation and are now proving many theorems that say that it works the same as normal expectation. This seems like a weird way of doing things. I have read several related questions on this site but it did not answer my question. Specifically, I understand that conditional expectation has to be a random variable and I understand how a sigma-algebra conveys information. Instead, I would first define conditional probability (probably in a way similar to the definition of conditional expectation). Then, I would take expectation with respect to this conditional distribution. That would have the advantage that I would not have to prove everything twice. Why not do it like this?","['conditional-probability', 'conditional-expectation', 'expected-value', 'probability-theory', 'probability']"
3934407,Number theory in sequence $x_{n+1}=x_n^3-2x_n^2+2$,"$x_1=5, x_{n+1}=x_n^3-2x_n^2+2$ Prove that, there is no prime $p=4k+3(k>1)$ and $p\mid x_n^2-3x_n+3$ I think I can have $p\mid t^2+1$ and then I have QED. But $p\mid x_n^2-3x_n+3$ means that $p\mid (2x_n-3)^2+3=t^2+3$ What should I do next?","['number-theory', 'divisibility', 'sequences-and-series']"
3934408,Why does $a^{\log_a(x)}=x$?,"I'm currently learning about logs and yesterday made a post on here . In that post I was told that $a^{\log_a(x)}=x$ From a commenter: ""It should be clear that..."" Nope, not for me. I've tried coming back to this since posting yesterday but cannot 'see it' or make it click. I'm seeking hand holding and a low level response. Why does $a^{log_a(x)}=x$ ?","['algebra-precalculus', 'logarithms']"
3934418,Compute $\oint_{|z|=4} \frac{e^{1 /(z-1)}}{z-2} d z$,"Here is an integral. $\oint_{|z|=4} \frac{e^{1 /(z-1)}}{z-2} d z$ Obviously, the function is not analytic in $D(0,4)$ , thus, we should apply residue theorem $\oint_{c} f(z) d z=2 \pi i \sum_{j=1}^{n} b_{1 j}$ where $b_{1j}$ is the first coefficient in Laurent series at the point of singularity. So, at the point $z_1 = 2$ we have a pole of the first order. $Res_{z_1} = e^1 $ at the point $z_2 = 1$ we have an essential singularity. Compute Laurent series of the function in the point $z=1$ . WolframAlpha: $\frac{e^{1 /(z-1)}}{z-2} = \sqrt[x-1]{e}\left(-1-(z-1)-(z-1)^{2}-(z-1)^{3}+O\left((z-1)^{4}\right)\right)$ Thus, $Res_{z_2} =  -1$ And we get: $\oint_{c} f(z) d z=2 \pi i (e - 1)$ It does not make sense, for a correct answer is $2i$ What is wrong? Tell me, please.","['complex-analysis', 'contour-integration', 'laurent-series', 'residue-calculus']"
3934488,Integrating $\frac{1}{(1-x)^2} $ into two different-looking functions,"Background I want to ""trick"" some students by showing that $$\int \frac{1}{(1-x)^2} \mathrm dx = \frac1{1-x} + C$$ in one instance and $$\int \frac{1}{(1-x)^2} \mathrm dx = \frac x{1-x} + C$$ in another. Obviously these look like two different results due to the different numerator, but as the more astute will point out, the difference between these functions is a constant, and they therefore have the same derivative. Question When solving the integral, using the substitution $u = 1-x$ we naturally arrive that the first results, but is there a way of solving the integral that ""naturally"" yields the second result?","['integration', 'indefinite-integrals', 'calculus', 'derivatives']"
3934491,Where can I find a modern general proof of the Feynman-Kac formula?,"Consider the partial differential equation $$
\frac{\partial u}{\partial t}(x, t)+\mu(x, t) \frac{\partial u}{\partial x}(x, t)+\frac{1}{2} \sigma^{2}(x, t) \frac{\partial^{2} u}{\partial x^{2}}(x, t)-V(x, t) u(x, t)+f(x, t)=0
$$ defined for all $x \in \mathbb{R}$ and $t \in[0, T]$ , subject to the terminal condition $$
u(x, T)=\psi(x)
$$ where $\mu, \sigma, \psi, V, f$ are known functions, $T$ is a parameter and $u: \mathbb{R} \times[0, T] \rightarrow \mathbb{R}$ is the unknown. Then the Feynman-Kac formula tells us that the solution can be written as a conditional expectation $$
u(x, t)=E^{Q}\left[\int_{t}^{T} e^{-\int_{t}^{r} V\left(X_{\tau}, \tau\right) d \tau} f\left(X_{r}, r\right) d r+e^{-\int_{t}^{T} V\left(X_{\tau}, \tau\right) d \tau} \psi\left(X_{T}\right) \mid X_{t}=x\right]
$$ under the probability measure $Q$ such that $X$ is an Itô process driven by the equation $d X=\mu(X, t) d t+\sigma(X, t) d W^{Q}$ where $W^{Q}(t)$ is a Wiener process (also called Brownian motion) under $Q$ , and the initial condition for $X(t)$ is $X(t)=x$ . Where can I find a complete (no steps left for the reader...) and modern (notation-wise) proof of that result ?","['stochastic-analysis', 'stochastic-processes', 'partial-differential-equations', 'probability-theory', 'stochastic-calculus']"
3934492,How can it be that the empty set is a subset of every set but not an element of every set?,"How can it be that the empty set is a subset of every set but not an element of every set? I've understood that the empty set must be a subset of every set because if it were not a subset of every set then the statement $\exists x : x \in \emptyset \land x \notin M$ , would need to be ture, but since the empty set has no elements this statement is a contradiction. But how can it be that the empty set is not element of every set, if it is a subset of every set? I also understood that it cannot be an element of itself, otherwise it wouldn't be the empty set anymore, but why is it not an element of every non-empty set?
If the empty set is subset of every set, than it also would need to be a subset of itself ( $\emptyset \subset \emptyset$ ), how can that be?",['elementary-set-theory']
3934503,Number of binary sequences with exactly $n$ distinct subsequences.,"Prove that number of binary sequences that have exactly $n$ distinct subsequences (including empty one) is $\varphi(n+1)$ (where $\varphi(n)$ is Euler's totient function ). For example, There are $\varphi(8)=4$ sequences with $7$ distinct subsequences: $$\{000000,111111,010,101\}$$ I came up with this question while solving some other problem and wrote a simple program to calculate it for small numbers and when I searched for the sequence on OEIS, to my surprise it was same as Euler's totient function, but I couldn't prove this result.","['number-theory', 'combinatorics-on-words']"
3934547,Series of characteristic polynomials,"Consider the sequence of symmetric matrices with diagonal 2 and second-diagonal s $-1$ , e.g. $$
M_4= \begin{pmatrix}
               2 & -1 & 0 & 0 \\
               -1 & 2 & -1 & 0\\
               0 & -1 & 2 & -1\\
               0 & 0 & -1 & 2\\
              \end{pmatrix} 
$$ I've found out that the characteristic polynomials are $$
\begin{cases}
P_1(x)=2-x\\
P_2(x)=(2-x)^2-1\\
P_n(x) = (2-x)P_{n-1}(x)-P_{n-2}(x)
\end{cases}
$$ Or with a variable change $$
\begin{cases}
Q_1(y)=y\\
Q_2(y)=y^2-1\\
Q_n(y) = y Q_{n-1}(y)-Q_{n-2}(y)
\end{cases}
$$ Looking at the first 8 $P_n$ I see that all eigenvalues are real (as for any symmetric matrix), they are between 0 and 4. How can I prove that all eigenvalues are between 0 and 4? Are these polynomials known (have a name)? How can I prove that the polynomial are sandwitched between $$
\frac{1}{x}+\frac{1}{4-x}\quad\text{and}\quad
-\frac{1}{x}-\frac{1}{4-x}
$$","['eigenvalues-eigenvectors', 'real-analysis', 'characteristic-polynomial', 'linear-algebra', 'polynomials']"
3934603,"How to compute $\int_0^\infty \frac{\tanh\left(\pi x\right)}{x\left(1+x^2\right)} \, \mathrm{d}x$?","How do I compute the following integral? $$\int_0^\infty \frac{\tanh\left(\pi x\right)}{x\left(1+x^2\right)} \, \mathrm{d}x$$ I tried some basic substitutions but they only make it more complicated. WolframAlpha says the answer is $2$ but I have no clue how to get there.","['integration', 'calculus', 'definite-integrals']"
3934640,"How can the center of mass of a region with density $d[x, y]$ be understood as as a kind of (average x-value, average y-value)?","For a region of uniform density, the center of mass is equal to centroid, which is equal to: $$(\text{average x-value}, \text{average y-value}) = \left(\frac{\int\int_R{x}\,dxdy}{ \int\int_R{1}\,dxdy}, \frac{\int\int_R{y}\,dxdy}{ \int\int_R{1}\,dxdy}\right)$$ For density $d[x, y]$ , the center of mass is instead: $$\left(\frac{\int\int_R{x d[x, y]}\,dxdy}{ \int\int_R{d[x, y]}\,dxdy}, \frac{\int\int_R{y d[x, y]}\,dxdy}{ \int\int_R{d[x, y]}\,dxdy}\right)$$ Is there a way to understand the center of mass with variable density using this same idea of an average value? The uniform density center of mass is analogous to finding the mean value in 1D ( $\frac{\int_a^b f[x]\,dx}{b - a} = \frac{F[b] - F[a]}{b -a}$ ); is there a way a similar way to understand center of mass for variable density? When I look online (such as this and this ), they use moment and mass, which I don't really grasp. So, preferably, I would like an explanation that doesn't use these concepts; or if they are necessary, an explanation that explains what they are and why they are necessary. What is the connection between $\left(\frac{M_y}{m}, \frac{M_x}{m}\right)$ , and $\left(\frac{\int\int_R{x}\,dxdy}{ \int\int_R{1}\,dxdy}, \frac{\int\int_R{y}\,dxdy}{ \int\int_R{1}\,dxdy}\right)$ and $\left(\frac{\int\int_R{x d[x, y]}\,dxdy}{ \int\int_R{d[x, y]}\,dxdy}, \frac{\int\int_R{y d[x, y]}\,dxdy}{ \int\int_R{d[x, y]}\,dxdy}\right)$ ? (One thought I had was: the reason the uniform density center of mass works is because all surrounding areas around the point balance out. (If you draw a straight line through the point, two mass of the two sides are the same. Or maybe another way of thinking of it is, if you take the integral of both sides created by the line, those two masses are equal). Perhaps the center of mass with variable density can be derived similarly?) Sorry if this is very rambling.","['integration', 'physics', 'multivariable-calculus']"
3934680,Convergence in Distribution ($Y \mid N = n)$ is $\chi^2_{2n}$ and $N$ is Poisson($\theta$)),"Suppose I have a hierarchical model like the following: $Y\mid N=n$ is governed by a chi-square distribution with $2n$ degrees of freedom, and $\theta$ is governed by a Poisson distribution. I want to show that as $\theta \rightarrow \infty$ , $\frac{Y - E[Y]}{\sqrt{\operatorname{Var}(Y)}} \rightarrow$ standard normal in distribution. I know that to show convergence in distribution, I have to show that the pdf (or cdf) $$\lim_{n \rightarrow \infty} f_{X_n}(x) = f_X(x),$$ but I am unsure how to go about this. How could I show that $\frac{Y - E[Y]}{\sqrt{\operatorname{Var}(Y)}} \rightarrow$ standard normal in distribution?","['statistics', 'probability-distributions', 'convergence-divergence', 'probability-theory', 'probability']"
3934736,What do subgroups of $\mathbb{Z}_{p_1}^{\alpha_1} \oplus ... \oplus \mathbb{Z}_{p_t}^{\alpha_t}$ look like?,"If $G = \mathbb{Z}_{p_1}^{\alpha_1} \oplus ... \oplus \mathbb{Z}_{p_t}^{\alpha_t}$ is it true that every subgroup of $G$ looks like $H_1 \oplus ... \oplus H_t$ , where $H_i \leqslant \mathbb{Z}_{p_i}^{\alpha_i}$ ? UPD: $p_i$ are primes (they may be equal). ""looks like"" means that every subgroup is isomorphic to $H_1 \oplus ... \oplus H_t$ (I want to know if I can find all subgroups using combintaions of subgroups in $\mathbb{Z}_{p_i}^{\alpha_i}$ ).","['abelian-groups', 'group-theory', 'abstract-algebra', 'finite-groups']"
3934746,Theorems you wish you knew in complex analysis,"I recently stumbled upon a theorem of Landau, which states Let $f(z)=\sum a_nz^n$ such that $f'(0)\neq 0$ and such that $f^{-1}(\{0,1\})=\emptyset$ . The radius of
convergence of $f$ is bounded by a constant $C(f(0),f'(0))$ The theorem is not hard to prove once one knows the Ahlfors-Schwarz-Pick lemma, but it is an extremely surprising statement, and a quite elementary one. In particular, one can easily state and explain it to a student taking a first course in complex analysis. A similar situation occurs with Picard's theorems and Schottky's theorem . My question is: What other ""relatively unknown"" theorems do you think fit this description? Before this question gets closed as ""opinion based"", let me state some criteria for what I am looking for: The statement is elementary (as explained before) The theorem is not usually taught (or stated) in a first course in complex analysis The proof requires nontrivial machinery from more advanced math(e.g. A-S-P for Landau's theorem)","['complex-analysis', 'soft-question', 'reference-request']"
3934892,Sporadic groups generated by two simple permutations,"Fixing $n\ge 1$ , consider the permutation $p$ on $n$ elements whose word representation consists of the even integers ascending up to $n$ , followed by the odd integers descending from $n$ . Let $q$ be the reverse of $p$ .  The permutations are perhaps more easily defined via example: when $n=8$ , we have $p=24687531$ and $q=13578642$ . Here's a natural question: What is the group $G$ generated by the permutations $p,q$ ? Using GAP, I have computed these groups for $1\le n\le 128$ . The answer is almost a straightforward one: $A_n$ when $n=0,1\pmod{4}$ , and $S_n$ when $n=2,3\pmod{4}$ . That is, it will be as large as possible, given the parity of $p$ and $q$ . However, this classification has the following exceptions: When $n=2^k$ for $k\ge2$ , $G$ is a combination of direct and semidirect products of certain cyclic groups, with an order of $2^k\cdot (k+1)$ ; I think it is always given by the semidirect product $(C_2)^k\rtimes C_{k+1}$ , though this doesn't always match how GAP's StructureDescription() function interprets the group. (When $k=2$ , this coincides with the expected $A_4$ .) When $n=6$ , $G$ is not $S_6$ , but $S_5$ . When $n=12$ , $G$ is not $A_{12}$ , but the sporadic simple group $M_{12}$ . I have two questions about these groups and their apparent classification. Can we understand how the $n=6$ and $n=12$ sporadic cases work? I suspect at least the $n=6$ case is related somehow to the sporadic outer automorphisms of $S_6$ , but I am not quite sure how this connection manifests. Can the classification outlined above be proven for all other $n$ , if indeed it is true? (If not, can a counterexample be found?) For convenience, the Sage code used to reach the above conclusions is linked here , and can be run here .","['permutations', 'group-theory']"
3934917,curve with constant curvature,"Let $\gamma$ : $I\twoheadrightarrow C\subset \mathbb{R}^2$ be a plane curve with constant curvature $\kappa>0$ . Show that $C$ is part of a circle with radius $\kappa^{-1}$ .
How to start this question, I don't have any clue.","['calculus', 'curvature', 'differential-geometry']"
3935000,Find y in terms of $t$,"So I am given this equation for the rate of a reaction: $$\frac{dy}{dt}=y^2-8y+15$$ when $t=0, y=0$ [ what does this mean? ] How can I proceed to find $y$ in terms of $t$ ? I checked out this site but I still don't get how you're supposed to find $y$ in terms of $t$ from it. Some guidance would be appreciated.","['calculus', 'implicit-differentiation', 'derivatives']"
3935003,Generalising norms over arbitrary fields,"I am curious about the structure we require on arbitrary fields if we want to generalise the notion of norms on vector spaces over fields other than either $\mathbb{R}$ or $\mathbb{C}$ . Specifcally, given a vector space $V$ over $\mathbb{F}$ , what structure must be imposed on $\mathbb{F}$ , such that we have a map $\|\cdot\|: V \to \mathbb{F}$ s.t. for any $a \in \mathbb{F}$ and any $\bar u, \bar v\in V$ , $$\text{(i) }\|\bar u+ \bar v\| \leq \|\bar u\|+\|\bar v\|$$ $$\text{(ii) }\|\bar v\| = e \to \bar v = \boldsymbol{0}, \text{where } e \text{ is the additive identity of } \mathbb{F}$$ $$\|a\bar u\| = |a|\|\bar u\|$$ From this question here , it seems that positive definiteness requires that we have an ordered field. The accepted answer implies this is enough structure to generalise the inner product. Where I am getting somewhat confused is how the generalisation works for norms. Specifically, is it really enough to have just have an ordered field in order to satisfy the norm property of $\|a\bar x\| = |a|\|\bar x\|$ ? I know that having an ordered field allows us to generalise (i) and (ii), but  how do we define what the modulus of $a$ is? I think the linked question is relevant since if we generalise the inner product over an arbitrary field, and we get a norm out of those inner products, we have made some progress. How does ordering the field allow us to define the modulus of scalars in a vector space over an ordered field? Do we need to specify additional structure?","['abstract-algebra', 'linear-algebra']"
3935048,Does left-multiplication by compact operators turn strong-convergence into norm-convergence?,"If $\{T_i\}_{i\in I}$ is a bounded net of operators on a Hilbert space $\mathscr H$ ,  converging strongly to some operator $T$ , and
if $K$ is  a compact operator on $\mathscr H$ , then the net $\{T_iK\}_i$ is known to converge in norm to $TK$ . Question . Is it also true that $\{KT_i\}_i$ converges in norm to $KT$ ? PS: The present question arouse in the comments following this answer and, while I can't remember ever questioning it, neither do I remember this being discussed anywhere.  After a while I
finally figured out the answer and I thought it would be nice to record it here. An affirmative answer to my question is implicitly assumed in the statement of this question .","['compact-operators', 'functional-analysis', 'strong-convergence']"
3935112,Trigonometric Integral Limit,"My problem is to evaluate the following limit: $$\lim_{n \to \infty}{\int^{n}_{0}{|\sin(x)|^n dx}}$$ I have no idea where to begin, but as you can tell the area under $\sin(x)^n$ decreases as $n$ approaches $\infty$ . WolframAlpha can't evaluate this for $n>134$ , where it equals about $9.29$ . If I had to guess I would say it's probably $\infty$ . One way to tackle this could be to find a representation of $$\int^{2\pi}_{0}{|\sin(x)|^n dx}$$ and multiply by $\frac{n}{2\pi}$ . This should approximate the integral for large $n$ .","['integration', 'limits']"
3935171,Sylow $p$-subgroup of a direct product is product of Sylow $p$-subgroups of factors,"Let $G = H \times K$ be a finite group (direct product), $P$ a Sylow $p$ -subgroup of $G$ . Prove that there exist Sylow $p$ -subgroups $H'$ , $K'$ of $H$ and $K$ respectively so that $P$ = $H' \times K'$ I am very new to the group theory, so can you explain solution properly? Thank you for your help.","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
3935226,"Twice continuously differentiable function such that $f’’-f<0, \forall x\in(0,1)$.","Let $f:[0,1]\to\Bbb R$ be twice continuously differentiable function such that $f’’(x)-f(x)<0, \forall x\in(0,1)$ and $f(0)=f(1)=0$ , then which of the following statements is/are true about $f$ ? $1.$ $f$ has at least one zero in $(0,1).$ $2.$ $f $ has at least two zeros in $(0,1).$ $3.$ $f(x)>0, \forall x\in (0,1)$ . $4.$ $f(x)<0, \forall x\in (0,1)$ . If i consider the example $x(1-x)$ on $[0,1]$ , then only option $3$ is correct one , but i want to solve the problem theoretically without using example or counter examples.  It seems that last option is false because that $f$ can’t be both negative and concave .  Please suggest how to discard rest options. Thanks .","['calculus', 'derivatives', 'ordinary-differential-equations', 'real-analysis']"
3935260,$\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}}$ [duplicate],"This question already has answers here : Infinite Series $\sum\limits_{n=1}^{\infty}\frac{1}{4^n\cos^2\frac{x}{2^n}}$ (3 answers) Closed 3 years ago . $\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}}$ How can I calculate this? Since there are $4^n$ and $\cos^2x$ , I tried: $$\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}} = 4\sum_{n=1}^{\infty}{\frac{\sin^2{\frac{\pi}{4 \cdot 2^n}}}{4^{n}\sin^2{\frac{\pi}{4\cdot2^{n-1}}}}}$$ to use $2\sin x \cos x = \sin2x$","['algebra-precalculus', 'trigonometry', 'summation', 'sequences-and-series']"
3935403,Finding Integer Solutions to $x^2-y^2-n=0$,"I am trying to find the integer solutions to the equation $x^2-y^2-n=0$ . Effectively, I am trying to find when the difference of two perfect squares is $n$ I have tried using a modified Newton's method to find the nearest point where the equation reaches parity; however, it ends up finding non-integer solutions. I am wondering if there is a way to factor/find all the integer solutions to this equation. For my algorithm, taking the square root is prohibitively costly and I am trying to avoid using it. Thanks for the help!","['integers', 'derivatives', 'discrete-mathematics', 'diophantine-equations']"
3935435,"Does the ratio of the $x-$values of two continuous functions $f(x), g(x) \in \mathbb{R^+}$ tell you anything about the ratio between their $y-$values?","Does the ratio of the $x-$ values of two continuous functions $f(x), g(x) \in \mathbb{R^+}$ tell you anything about the ratio between their $y-$ values? In general, obviously not. But suppose the following is also true: $\lim_{x \to \infty}f(x) = \lim_{x \to \infty}g(x) = 0$ , $\lim_{x \to \infty} \frac{f(x)}{g(x)}$ converges to $L_1$ and $\lim_{y \to 0+} \frac{f^{-1}(y)}{g^{-1}(y)}$ converges to $L_2$ . Then what can we say about $L_2$ in terms of $L_1$ ? e.g. If $L_1 = \infty$ then does $L_2 = \infty$ ? If $L_1$ is finite then is $L_2$ finite?","['limits', 'functions', 'graphing-functions', 'ratio']"
3935490,"What is the probability that three babies are boys, given that at least one is a boy?","I know this is a simple problem but I am arguing with a friend about its solution, so I want to show him an ""official"" proof!
Suppose that in any birth, the probability to have a boy is $48.5\%$ . If we have three persons expecting to deliver, what is the probability that at least one of them gives birth to a boy? If we know that at least one will give birth to a boy (suppose we have accurate ultra-sound results), what is the probability all three will have a boy? For the first question, we calculate the probability of one NOT having a boy, which is $1-0.485 = 0.515$ and then the required probability of all three not having a boy is $0.515^3 = 0.1365$ so the probability that at least one will have a boy is $1-0.1365 = 0.8634 = 86.34\%$ . For the second question, since the three events are independent, the probability that all three will have a boy given that at least one will have a boy is equal to the probability that the other two will have a boy. Is it $0.485^2$ ? I am not sure about the second one.","['conditional-probability', 'probability']"
3935536,Relating hyperspherical and Hopf coordinates for the unit three sphere,"I thought that my question would be very elementary and I could find the answer online somewhere, but I have been searching for it and still I have not found anything. What is the relation between the hyperspherical and the Hopf coordinates for the unit three sphere? Let's be more precise. Starting from the four dimensional Euclidean flat space \begin{equation}  
ds^2 = \sum^3_{i=0} dx^2_i
\end{equation} $\textbf{Hyperspherical coordinates}$ We can write a unit three-sphere simply by embedding it as \begin{equation}
\begin{aligned}
x_0		&= \cos \chi_1		\, ,\\
x_1		&= \sin \chi_1 \cos \chi_2		\, ,\\
x_2		&= \sin \chi_1 \sin \chi_2 \cos \chi_3		\, ,\\
x_3		&= \sin \chi_1 \sin \chi_2 \sin \chi_3		\, ,\\
\end{aligned}
\end{equation} and substituing the above yields \begin{equation}
ds^2 = d \chi^2_1 + \sin^2 \chi_1 (d \chi^2_2 + \sin^2 \chi_2 d \chi^2_3)
\end{equation} The coordinates take values as $0 \leq {\chi_1, \chi_2} \leq \pi$ and $0 \leq \chi_3 \leq 2 \pi$ . $\textbf{Hopf coordinates}$ These are the cooridnates for the embedding of $S^3$ in the complex plane $\mathbb{C}^2$ . However, the coordinate change is easily implemented as an embedding in four dimensional Euclidean space as \begin{equation}
\begin{aligned}
x_0		&= \cos \xi_1 \sin \vartheta	\, ,	\\
x_1		&= \sin \xi_1 \sin \vartheta	\, ,	\\
x_2		&= \cos \xi_2 \cos \vartheta	\, ,	\\
x_3		&= \sin \xi_2 \cos \vartheta	\, ,	\\
\end{aligned}
\end{equation} and substituing the above once more in the invariant line element gives us \begin{equation}
ds^2 = d \vartheta^2 + \sin^2 \vartheta d \xi^2_1 + \cos^2 \vartheta d \xi^2_2
\end{equation} The above is the Hopf bundle \begin{equation}
S^1 \rightarrow S^3 \rightarrow S^2
\end{equation} The coordinates range as follows: $0 \leq \vartheta \leq \pi/2$ and $0 \leq {\xi_1, \xi_2} \leq 2 \pi$ How are these two coordinate sets related to one another?","['spheres', 'change-of-basis', 'spherical-coordinates', 'hopf-fibration', 'differential-geometry']"
3935539,"What is the sign of the integral $\int_{0}^{2\pi}e^{\sin(x)}\cos(nx)\,dx$?","Let $I_n = \int_{0}^{2\pi}e^{\sin(x)}\cos(nx)\,dx$ for a natural $n$ .
I would like to prove that for $n$ odd this integral vanishes, while for $n = 4k$ for some natural $k$ , the integral is always positive and for $n = 4k+2$ it is always negative. I was able to do a few integrations by parts, and provided I didn't make mistakes, the result was the following rather ugly recurrence relation, valid for $n > 1$ : $$I_{n+2} = -\frac1{n-1}\left[(4n^3-2n)I_n+(n+1)I_{n-2}\right].$$ Also we have $I_1 = I_3 = 0$ (the first is obvious from the integral, the second follows by integration by parts). And from here, clearly it is immediate to see that it vanishes for every $n$ odd, just by induction. However I'm not able to see why $I_{4k}$ is always positive or $I_{4k+2}$ is always negative from this relation. What I know is that $|I_n| \le I_0 \approxeq 7.95$ . I also tried to rewrite the integral using $e^x = 1 + x + \ldots$ , moving the integral inside the summation, but still I couldn't come up with a solution. What do you suggest? Note : this integral comes from the calculation of the Fourier coefficients of $e^{\sin(x)}$ , and analogous properties hold for the coefficients of the sine terms. Also by a well-known theorem (Riemann-Lebesgue), $I_n$ goes to zero as $n\to\infty$ , and hence it's not possible to find a fixed constant lower bound for $|I_n|$ , making any estimation in the recurrence relation more difficult.","['integration', 'definite-integrals', 'recurrence-relations', 'real-analysis', 'complex-analysis']"
3935583,$\pi: E \rightarrow M$ ($E$ is a vector bundle) admits a global frame iff $E$ is a trivial vector bundle over $M$.,"(Proof of backward direction is clear: if $F$ is a diffeomorphism between $E$ and $M \times \mathbb R^k$ , then $p \mapsto (p, e_i) \mapsto F^{-1}(p, e_i)$ forms a basis of $E$ for $i = 1, \cdots, k$ .) Proof of forward direction: Let $E$ be a vector bundle over $M$ of dimension $k$ , and let $s_1, \cdots, s_k$ be a global frame. For all $ p \in M$ , there exists a local trivialization $\Phi: \pi^{-1}(U_p) \rightarrow U_p \times \mathbb R^k$ . Since $\Phi|_{E_p}$ is a linear isomorphism of vector spaces, and $s_1(p), \cdots, s_k(p)$ forms a basis of $E_p$ , $\Phi(s_1(p)), \cdots, \Phi(s_k(p))$ forms a basis of $\{p\} \times \mathbb R^k$ . Note that $(p, e_1), \cdots, (p,e_k)$ is a basis of $\{p\} \times \mathbb R^k$ . Hence, I can form a linear mapping  between basis $\Phi(s_1(p)), \cdots, \Phi(s_k(p))$ and another basis $(p, e_1), \cdots, (p,e_k)$ , $$(p, e_i) = \sum_{j=1}^k a_j^i(p) \Phi(s_j(p))$$ It suffices to prove that $a_j^i$ is smooth, but how do I prove so?
Any suggestions?",['differential-geometry']
3935614,Finite group generated by two different order $2$ elements is $\cong$ to $\mathbb{Z}_2^2$ or $D_n$,"I'm trying to solve this problem from my group theory course: Given $G$ finite group generated by two different order $2$ elements.
Prove that $G\cong \mathbb{Z}_2^2$ or $G\cong D_n$ for some $n\geq 3$ (being $D_n$ the dihedral group of degree $n$ ). The first part is easy, since if I consider $a,b$ these two different order $2$ elements, and suppose $G$ abelian, then I get $$G=\{1,a,b,ab\},$$ and obviously this is isomorphic to $\mathbb{Z}_2^2$ . I'm having trouble with the second part. I understand the idea of two different reflections from $D_n$ generating the whole $D_n$ , but I don't know how to prove it. I know that $$D_n\cong\mathbb{Z}_n\rtimes_\phi \mathbb{Z}_2$$ for $\phi$ verifying that $\phi(\bar0)=id$ and $\phi(\bar1)$ being the inversion (correct me if I'm wrong), but I don't know if this is even useful here or how to use it in that case. How can I prove this? Any help will be appreciated, thanks in advance.","['dihedral-groups', 'finitely-generated', 'semidirect-product', 'abstract-algebra', 'group-theory']"
3935643,Refinement of $\left(\frac{a+1}{a+b} \right)^{\frac25}+\left(\frac{b+1}{b+c} \right)^{\frac25}+\left(\frac{c+1}{c+a} \right)^{\frac25} \geqslant 3$,"It's a refinement of Prove $\left(\frac{a+1}{a+b} \right)^{\frac25}+\left(\frac{b+1}{b+c} \right)^{\frac25}+\left(\frac{c+1}{c+a} \right)^{\frac25} \geqslant 3$ . It's a attempt to find a simple proof of this fact . Now the refinement : Let $1\leq a\leq 2$ and $x\in[0,3-a]$ then define : $$f(x,a)= \left(\frac{\frac{(1+a)}{(x+a)}+\frac{(x+1)}{(3-x-a+x)}+\frac{(3-x-a+1)}{(3-x+a-a)}}{3}\right)^{\frac{2}{5}}$$ And : $$g(x,a)= \left(\frac{\frac{(x+a)}{(1+a)}+\frac{(3-x-a+x)}{(1+x)}+\frac{(3-x-a+a)}{(3-x+1-a)}}{3}\right)^{-\frac{2}{5}}$$ then we have : $$\left(\frac{(1+a)}{(x+a)} \right)^{\frac25}+\left(\frac{(x+1)}{(3-x-a+x)} \right)^{\frac25}+\left(\frac{(3-x-a+1)}{(3-x+a-a)}\right)^{\frac25} \geqslant\frac{195}{100}f(x,a)+\frac{105}{100}g(x,a) \geqslant 3$$ My refinement is based on two observation : With Jensen's inequality we have $x,y,z>0$ : $$3\left(\frac{\frac{1}{x}+\frac{1}{y}+\frac{1}{z}}{3}\right)^{-\frac{2}{5}}\leq x^{\frac{2}{5}}+y^{\frac{2}{5}}+z^{\frac{2}{5}}\leq 3\left(\frac{x+y+z}{3}\right)^{\frac{2}{5}}$$ For the rest I play with the coefficients to give the refinement. For the RHS we put : $$u=\frac{(1+a)}{(x+a)}$$ We make the same things for the others fractions and I think we can prove a more general inequality for $u,v,w$ . For the LHS I have tried to put on the same denominator but currently I don't see any good issue . Update 13/12/2020: We want to show a more general inequality with some constraints on it ,so we have the inequality : $$x^{\frac{2}{5}}+y^{\frac{2}{5}}+z^{\frac{2}{5}}\geq \frac{105}{100}\left(\frac{\frac{1}{x}+\frac{1}{y}+\frac{1}{z}}{3}\right)^{-\frac{2}{5}}+\frac{195}{100}\left(\frac{x+y+z}{3}\right)^{\frac{2}{5}}\quad(1)$$ Due to homogeneity we can put $u=\frac{x}{z}$ and $v=\frac{y}{z}$ and get : $$1+u^{\frac{2}{5}}+v^{\frac{2}{5}}\geq \frac{105}{100}\left(\frac{\frac{1}{1}+\frac{1}{u}+\frac{1}{v}}{3}\right)^{-\frac{2}{5}}+\frac{195}{100}\left(\frac{1+u+v}{3}\right)^{\frac{2}{5}}\quad(I)$$ Now we make the subsitution $u=p^3$ and $v=q^3$ we get : $$1+p^{\frac{6}{5}}+q^{\frac{6}{5}}\geq \frac{105}{100}\left(\frac{\frac{1}{1}+\frac{1}{p^3}+\frac{1}{q^3}}{3}\right)^{-\frac{2}{5}}+\frac{195}{100}\left(\frac{1+p^3+q^3}{3}\right)^{\frac{2}{5}}$$ Now we use Jensen's inequality we have : $$p^{\frac{6}{5}}+q^{\frac{6}{5}}\geq 2\left(\frac{p+q}{2}\right)^{\frac{6}{5}}$$ Remains to show the new bound : $$1+2\left(\frac{p+q}{2}\right)^{\frac{6}{5}}\geq \frac{105}{100}\left(\frac{\frac{1}{1}+\frac{1}{p^3}+\frac{1}{q^3}}{3}\right)^{-\frac{2}{5}}+\frac{195}{100}\left(\frac{1+p^3+q^3}{3}\right)^{\frac{2}{5}}$$ And now I'm stuck ...My last idea was to use the Gauss identity wich states for reals $a,b,c$ : $$a^3+b^3+c^3-3abc=(a+b+c)(a^2+b^2+c^2-ab-bc-ca)$$ Without success ! So I cannot find currently constraints on $x,y,z$ to have inequality $(1)$ For information we have the 2 variables version of the inequality ( $x>0$ ): $$\frac{2}{3}\left(\left(\frac{195}{100}\right) \left(\frac{1+x}{2}\right)^{\frac{2}{5}}+\frac{105}{100} \left(\frac{1+\frac{1}{x}}{2}\right)^{\frac{-2}{5}}\right)\leq 1+x^{\frac{2}{5}}$$ update : 14/12/2020 Starting from $(I)$ we can use Ji Chen's lemma to give some constraints . To works we need to split the coefficient $\frac{195}{100}$ into $1+\frac{95}{100}$ to have three variables . Finally I have tried for the LHS $uvw's$ method to find some others constraints . Question : How to show the refinement ?Is it also true for $2\leq a<3$ ? Thanks !","['substitution', 'multivariable-calculus', 'jensen-inequality', 'inequality']"
3935702,Existence of $\xi$ s.t. $f'''\left(\xi\right)=\frac{3f''\left(\xi\right)}{1-\xi}$,"Given $f(x)\in C^3$ , and $f(0)=f(1/2)=f(1)$ . Prove that there exists at least one point $\xi$ , such that $f'''\left(\xi\right)=\dfrac{3f''\left(\xi\right)}{1-\xi}$ . I tried to apply Mean Value Theorem to $f(x)$ , but anyway I can't construct the denominator $1-\xi$ . Can anyone help?","['calculus', 'derivatives', 'analysis', 'real-analysis']"
3935779,Condition to union of connected sets be connected,Let $X$ and $Y$ be connected spaces in $\mathbb{R}^n$ . If $\partial X \subset Y$ then $X \cup Y$ is connected. $\partial X$ is the boundary of X. i'm trying to prove this by showing somehow that $X \cap Y$ is non-empty and concluding that $X \cup Y$ is connected but i didn't have sucess Any help would be appreciated!,"['general-topology', 'functional-analysis', 'analysis']"
3935929,How is axiom of choice utilized within the given proof?,"I (only a beginner in set theory...) want to see a prove that an infinite set must have an infinite countable subset U: The following answer sounds quite logically for me: John Wayland Bales , Prove that every infinite set has a countable subset However, I guess that this proof depends at least on on some weaker variant of axiom of choice. John Wayland Bales constructs a series of non empty finite sets with increasing number of elements: For each $N\in\mathbb{N}$ , $S$ contains an element distinct from each
element in $U_N=\{x_1,x_2,\cdots,x_n\}$ , so define $U_{N+1}=U_N\cup\{x_{N+1}\}$ where $x_{N+1}$ is an element of $S$ distinct from each element of $U_N$ . Where is AC hidden in this argumentation?
I feel, that the last step is critical: Let $$U=\bigcup_{N\in\mathbb{N}}U_N$$ Then $U$ is a countable subset of $S$ . I would like to learn, how the proof is done ""correctly"" by using AC or some weaker weaker variant (axiom of countable choice...). My problem: Of course I see that recursive choices of ""any"" elements to create a new set are crucial, but those choices are done sequentially and not on an infinite set of sets that is already ""available"" and clearly defined. AC (in it's original textbook variant) is about the latter situation and not about a set, that is still in process of being constructed.","['elementary-set-theory', 'axiom-of-choice']"
3935949,Proof of Kőnig's line coloring theorem ($\chi'(G) = \Delta(G)$),"I'm trying to find a proof of Kőnig's line coloring theorem , i.e.: The chromatic index of any bipartite graph equals its maximum degree But to my surprise, I've only* been able to find two questions touching the subject: Edge-coloring of bipartite graphs Edge coloring of a bipartite graph with a maximum degree of D requires only D colors As graphs are my Achilles' heel, I'm incapable to use the information contained in the above to prove $\chi'(G) = \Delta(G)$ myself. * I've found many papers referring to it, but none proving, except for page 4 of CH6.pdf from first question, but I don't think it's sufficient.","['graph-theory', 'coloring', 'bipartite-graphs', 'discrete-mathematics']"
3935951,"$\sum_{k=1}^{n} \arcsin(\sin(k))= a_n+b_n \pi$, for $a_n,b_n\in\mathbb{Z}$; what can be said about the sequence $(a_n,b_n )$?","We have $\sum_{k=1}^{n} \arcsin(\sin(k))= a_n+b_n \pi$ for some integers $a_n,b_n$ . I have several questions about the behavior of these numbers: For which $n$ does $b_n=0$ and $a_n\ne 0$ , i.e. the sum is a non-zero integer? For which $n$ does $(a_n,b_n)=(0,0)$ , i.e. the sum vanishes? Aside from these subsequences, based on numerical evidence I conjecture that $\lim_{n\to\infty} a_n/b_n=-\pi$ , but I don't know how to prove it. Recall the convergents of $\pi$ are $3, 22/7, 333/106, 355/113, 103993/33102$ , etc. I computed $(a_n,b_n)$ for $1\le n\le 120000$ and here's what I found: As expected, I saw 'increased aberrations' for $n$ near the numerator of the numerators of the convergents. For example, $b_n=0$ and $a_n\ne 0$ when $$n=\{1,8,16,52,60,96,104,140,148,184,192,228,236,272,280,316,324,360,103632,103668,103676,103712,103720,103756,103764,103800,103808,103844,103852,103888,103896,103932,103940,103976,103984\}$$ and $(a_n,b_n)=(0,0)$ when $$n=\{24,44,68,88,112,132,156,176,200,220,244,264,288,308,332,352,103640,103660,103684,103704,10372
   8,103748,103772,103792,103816,103836,103860,103880,103904,103924,103948,103968,103992\}.$$ In particular, when $b_n=0$ and $a_n \ne0$ , aside from $n=1$ I found that $a_n=2$ . Aside from these values, the ratio is quite close to $\pi$ . We have $a_{120000}/b_{120000} =-\frac{248162}{78993}$ , which differs from $-\pi$ by about $0.0000231474$ . Here is a plot: Any information or insight would be much appreciated. I've heard of several continued fractions for $\pi$ and was wondering if perhaps this has to do with that. Update: I checked oeis.org for both the numerator and denominator and found nothing. Since $\arcsin(\sin(k))=x_k+y_k \pi$ , $x_k,y_k\in\mathbb{Z}$ , is essentially the signed distance between $k$ and its nearest multiple of $\pi$ , it is is clear that $x_k/y_k\approx -\pi$ . Then perhaps using the CLT or another probabilistic argument, one could examine the convergence of the random variable $a_n/b_n$ .","['summation', 'sequences-and-series', 'limits', 'continued-fractions', 'probability-theory']"
