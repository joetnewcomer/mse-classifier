question_id,title,body,tags
163779,OCR: some App to calculate the derivative on a line graph with iPhone/iPad?,"Problem I have a set of points like the ones shown on the right hand side of the image. So for each 'Ships Head' there is a corresponding value for 'Deviation'. In this example we can treat west as negative and east as positive values. On the left of the image there is a graph made from the points on the right. What I need to do is find a way of using a setup like this to work out the deviation for any given point on the graph. So for example, given the value of 10 degrees, we should be able to calculate the deviation as something around 3.8 degrees. Obviously its easy to manually draw a graph and then read off values however I need a way of doing this in code. I have never had to solve a problem like this before and I don't know where to start. I was thinking I could make use of trigonometry and maybe some sort of cosine wave but i don't know how to do this. What is the way of calculating the deviation for a given degree value based on the values on the right hand side of the image?","['trigonometry', 'graphing-functions', 'soft-question', 'math-software']"
163783,Summation Identity for Stirling Numbers of the First Kind,"For the Stirling numbers of the second kind , the following identity is well-known:
\begin{align}
S(n,l) = \sum_{k_1 + \cdots + k_l = n-l} 1^{k_1} 2^{k_2} \cdots l^{k_{l}},
\end{align}
where the sum is taken over non-negative integers satisfying $0 \leqslant k_1 \leqslant \cdots \leqslant k_l \leqslant n- l$. Is an analogous identity known for $s(n,l)$, the Stirling numbers of the first kind ? Edit : Thanks to Raymond, the correct formula is
\begin{align}
s(n,l) = (-1)^{n-l} \mathop{\sum_{k_1 + \cdots +k_{n-1} = n-l}}_{0 \leqslant k_i \leqslant 1} 1^{k_1} 2^{k_2} \cdots (n-1)^{k_{n-1}}.
\end{align}","['stirling-numbers', 'reference-request', 'combinatorics']"
163797,A problem in additive number theory.,"Original Problem: Counterexample given below by user francis-jamet. Let $A\subset \mathbb Z_n$ for some $n\in \mathbb{N}$. If $A-A=\mathbb Z_n$, then $0\in A+A+A$ New Problem: Is the following statement true? If not, please give a counterexample. If $A-A=\mathbb Z_n$ and $0\not\in A+A$, then $0\in A+A+A$.","['additive-combinatorics', 'number-theory']"
163816,an exercise book for probability theory recommendation request,"I'm looking for a good exercise book for probability theory, preferably at least partially with solutions to it. I want it to be detailed, not trivial, providing me solid fundamentals in the topic to be developed in the future. I'd wish it to be more of a ""applied"" technical university approach than the highly ""abstract"" one tailored for pure mathematics student at a university, however it need not to be so. The topics I would like it to cover are more or less like in the part one of the book ""Probability, Random Variables and Stochastic Processes"" by Papoulis and Pillai ( table of contents ). Thank you in advance.","['reference-request', 'probability']"
163831,Bruhat order and RSK,"The RS(K) correspondence is a bijection between elements of the symmetric group $S_n$ and pairs of standard tableaux of the same shape.  The symmetric group is partially ordered by the Bruhat order, so this bijection induces a partial ordering ""$\leq$""on the set of pairs of standard tableaux.  Is a natural ""tableaux-theoretic"" description of this ordering on pairs of tableaux known?  That is, can we give a condition for $(S,T)\leq (S',T')$ more natural than ""apply RSK in reverse and see if the second permutation dominates the first in the Bruhat order""?","['symmetric-groups', 'combinatorics']"
163844,Is an open linear map closed (to some extent)?,Suppose we have a surjective bounded linear operator acting between Banach spaces. By the Open Mapping Theorem it maps open sets in the domain to open sets in the codomain. Must the image of a closed linear subspace of the domain be closed then?,"['functional-analysis', 'banach-spaces']"
163850,Where does directed random walk hit the boundary?,"I have a problem that I more or less know the answer to, but would really like to see it done in a systematic, rather than ad hoc way. In spite of this, I will pose the question in a very concrete way. Consider a two-dimensional random walk on $\mathbb Z^2$. Fix a finite subset $S$ of $\mathbb Z^2$ in which each element of $S$ has strictly positive $x$-coordinate and assign a probability measure $\mu$ to $S$
Write the location of the 2D walk as $(X_n,Y_n)$ and let $(X_{n+1},Y_{n+1})=(X_n,Y_n)+(u,v)$, where $(u,v)$ is a randomly chosen element of $S$, chosen with distribution $\mu$. Let $T=\inf\{n\colon X_n\ge M\}$ for some (large) fixed $M$. I'm looking for a way to describe $Y_T$. Here's what I think is the answer: Write $(U,V)$ for a random element of $S$, write $\bar U=\mathbb EU$ and $\bar V=\mathbb EV$ (here $\mathbb E$ is with respect to $\mu$). I expect that $Y_T$ will have a distribution (for large $M$) close to a normal distribution with mean $M\bar V/\bar U$ and variance $(M/\bar U)\mathbb E(V-U\bar V/\bar U)^2$. Cross posting this to MO...","['probability-theory', 'random-walk']"
163858,Cauchy in Norm and Weakly converge Implies Norm convergent,"Let $X$ be a normed space and $(x_n)$ is a Cauchy sequence in the norm sense. Also assume the $x_n \rightarrow x_0 $ weakly. Then $x_n \rightarrow x_0 $ in norm. What I did:Take $ \varepsilon >0 $ since $x_n$ is cauchy there a $n_0$ such that $ |\!| x_n-x_m |\!|< \epsilon$ $\forall n,m \geq n_0$ From Hahn Banach there are $x^{*} _n\, \in X^{*}$ such that $|\!| x_n-x_0 |\!| = | x^{*}_n (x_n-x_0)|$ and $|\!| x^{*}_n |\!|=1$.
Hence 
\begin{align}
|\!| x_n-x_0 |\!| &= | x^{*}_n (x_n-x_0)|\\
&=| x^{*}_n (x_n-x_m+x_m-x_0)| \\
&\leq | x^{*}_n (x_n-x_m)|+| x^{*}_n (x_m-x_0)|\\
&\leq \varepsilon+| x^{*}_n (x_m-x_0)|.
\end{align}
Since the last inequality hold $\forall m \geq n_0$ we can take the limit in respect of $m$ and then we get $|\!| x_n-x_0 |\!| \leq \epsilon $ (Since   $x_n \rightarrow x_0 $  weakly). And then by definition we are done.
Where I saw this exercise there was a hint. Hint Observe that $x_n \in x_m +\varepsilon B_X$ and $x_m+\varepsilon B_X$ is weakly closed. How do we proceed from there?","['normed-spaces', 'convergence-divergence', 'functional-analysis']"
163862,"""Go-first"" dice for $N$ players","I'm interested in sets of dice that can be used to determine who ""goes first"" (hence the name) in an $N$-player game; more generally, I want to determine a complete ordering of the players with a single roll of the dice, and have this ordering be random.  Specifically, then, what's needed is an assignment of the labels $\{1,2,...,Nm\}$ to the faces of $N$ different $m$-sided dice, such that: No two faces share a label (so no ties can occur). When a face is chosen at random on each die, the rank-ordering of the dice based on the chosen faces is uniformly random across all permutations (so the rolls are fair). For instance, if $N=2$ and $m=2$ (two coins, basically), then you can label the coins $\{1,4\}$ and $\{2,3\}$.  A solution for $N=4$ and $m=12$ is sold here .  For what values of $N$ and $m$ are there solutions? A simple constraint on the minimum value of $m$ comes from the fact that we are choosing one of $N!$ possibilities on the basis of $m^N$ equiprobable rolls; certainly the former must divide the latter.  So for $N=2,3,4,5,6,\dots$, necessarily $m \ge 2, 6, 6, 30, 30, \dots$.  Is this minimum value always achievable?","['dice', 'probability-distributions', 'combinatorics']"
163888,"Show $g(a)= \operatorname*{arg}_{b \in B} \, f(a,b)=0$ is continuous when $g(a)$ is single-valued and $f$ continuous","Let $A$ and $B$ be two compact subsets of $\mathbb{R}$. Let $f:A \times B \to \mathbb{R}$ be a continuous function on $A \times B$. For each $a\in A$, define $B_a=\{b\in B:f(a,b)=0\}$, and suppose each $B_a$ is a singleton, so we may define a $g:A\to\Bbb R$ such that $g(a)$ is the unique element of $B_a$ for each $a\in A$. Is $g$ a continuous function of $a$? I tried the following. But I have the feeling it's not correct. Assume $g$ is not continuous at $a \in A$, then there exists a sequence $\{a_n\} \subset A$ converging to $a$ in $A$,
for which the sequence $\{b_n\}=\{g(a_n)\} \subset B$ does not converges to $b=g(a)$.
Since $B$ is compact, by the Bolzano-Weierstrass theorem, $\{b_n\}$ has a subsequence $\{b'_n\}$ 
converging to some $b'\ne b$ as $\{b_n\}$ does not converges to $b$. 
Let $\{a'_n\} \subset A$ be the subsequence of $\{a_n\}$ induces by $\{b'_n\}$.
Since $\{a_n\}$ converges to $a$ then every subsequence of $\{a_n\}$ converges to $a$ and $\{a'_n\}$ converges to $a$.
Since $g(a)$ contains a unique element $b$, then  $b'=b$ which is a contraction since $\{b'_n\}$ is a subsequence of $\{b_n\}$. (The previous sentence seems suspicious). The claim follows.","['real-analysis', 'analysis']"
163892,Is it true that the Laplace-Beltrami operator on the sphere has compact resolvents?,"We consider the Riemannian structure on the sphere $\mathbb{S}^n$ seen as a submanifold of $\mathbb{R}^{n+1}$ and the Laplace-Beltrami operator defined on $C^\infty(\mathbb{S}^n)$ by the equation $$\Delta f= -\operatorname{div}\operatorname{grad} f = -\frac{1}{\sqrt{g}}\frac{\partial}{\partial u^i}\left(\sqrt{g}g^{ij}\frac{\partial f}{\partial u^j}\right).$$ We regard $C^{\infty}(\mathbb{S}^n)$ as a dense subspace of the Hilbert space $L^2(\mathbb{S}^n)$. Question Is it true that $\Delta$ has compact resolvents, meaning that there exists $\lambda \in \mathbb{R}$ such that the closure of $\Delta-\lambda$ is invertible and its inverse operator is compact? I think that we can easily work out the special case $n=1$: in this case the equation $\Delta u-\lambda u = v$ reduces to the standard Sturm-Liouville problem $$\begin{cases} -\frac{d^2}{dt^2}u-\lambda u = v & t\in (-\pi, \pi) \\ {}\\ u(-\pi)=u(\pi) \\ u'(-\pi)=u'(\pi)\end{cases}$$ which admits Green's function for, say, $\lambda=-1$ (actually any $\lambda \notin \{0, 1, 4, 9 \ldots\}$ will do). So the inverse of $-d^2/dt^2+1$ is an integral operator and in particular it is compact. I suspect that, similarly, the operator $\Delta_{\mathbb{S}^n}+1$ admits Green's function in any dimension $n$, but I am unable to prove (or disprove) this. Thank you for reading.","['riemannian-geometry', 'spectral-theory', 'functional-analysis', 'partial-differential-equations']"
163905,Explanation of Proof of Zorn's lemma in Halmos's Book,"I have been reading Halmos's book on naive set theory on my own and have got stuck in the Chapter on Zorn's lemma. The 2nd and 3rd paragraphs are not very clear to me. Here is the text: Zorn's lemma. If $X$ is a partially ordered set such that every chain in $X$ has an upper bound, then $X$ contains a maximal element. Proof. The first step is to replace the abstract partial ordering in $X$ by the 
  inclusion order in a suitable collection of sets. More precisely, we consider, 
  for each element $x \in X$, the weak initial segment $\bar{s}(x)$ consisting of $x$ and 
  all its predecessors. The range $\mathscr{S}$ of the function $\bar{s}$ (from $X$ to$\wp(X)$) is a certain collection of subsets of $X$, which we may, of course, regard as  (partially) ordered by inclusion. The function $\bar{s}$ is one-to-one, and a necessary 
  and sufficient condition that $\bar{s}(x)\subseteq \bar{s}(y)$ is that $x\leq y$. In view of this, the task of finding a maximal element in $X$ is the same as the task of finding a maximal set in $\mathscr{S}$. The hypothesis about chains in $X$ implies (and is, 
  in fact, equivalent to) the corresponding statement about chains in $\mathscr{S}$. Let $\mathscr{X}$ be the set of all chains in $X$; every member of $\mathscr{X}$ is included in $\bar{s}(x)$ for some $x \in X$. The collection $\mathscr{X}$ is a non-empty collection of sets, 
  partially ordered by inclusion, and such that if $\mathscr{C}$ is a chain in $\mathscr{X}$, then the 
  union of the sets in $\mathscr{C}$ (i.e., $\bigcup_{A \in \mathscr{C}}A$) belongs to $\mathscr{X}$. Since each set in $\mathscr{X}$ is 
  dominated by some set in $\mathscr{S}$, the passage from $\mathscr{S}$ to $\mathscr{X}$ cannot introduce any 
  new maximal elements. One advantage of the collection $\mathscr{X}$ is the slightly 
  more specific form that the chain hypothesis assumes; instead of saying 
  that each chain $\mathscr{C}$ has some upper bound in $\mathscr{S}$, we can say explicitly that the union of the sets of $\mathscr{C}$, which is clearly an upper bound of $\mathscr{C}$, is an element of the collection $\mathscr{X}$. Another technical advantage of $\mathscr{X}$ is that it contains all the subsets of each of its sets; this makes it possible to enlarge 
  non-maximal sets in $\mathscr{X}$ slowly, one element at a time. Now we can forget about the given partial order in $X$. In what follows 
  we consider a non-empty collection $\mathscr{X}$ of subsets of a non-empty set $X$, subject to two conditions: every subset of each set in $\mathscr{X}$ is in $\mathscr{X}$, and the 
  union of each chain of sets in $\mathscr{X}$ is in $\mathscr{X}$. Note that the first condition implies that $\varnothing\in\mathscr{X}$. Our task is to prove that there exists in $\mathscr{X}$ a maximal set. and the proof continues... In the 2nd paragraph: 'Since each set in $\mathscr{X}$ is dominated by some set in $\mathscr{S}$, the passage from $\mathscr{S}$ to $\mathscr{X}$ cannot introduce any new maximal elements.' Here I am able to prove that every maximal element of $\mathscr{S}$ has to be a maximal element of $\mathscr{X}$, but surely there can be maximal elements of $\mathscr{X}$ which are not maximal elements of $\mathscr{S}$ and hence 'extra'- please explain.. In the 3rd para- The author considers a set $\mathscr{X}$ with the given properties, and states that the problem of finding a maximal element in $X$ is equivalent to finding a maximal set in $\mathscr{X}$.  How come? Detailed but simple answers would be much appreciated.",['elementary-set-theory']
163915,Finding $f'(0)$ when $f(x)=\int\limits_0^x\sin\left(\frac{1}{t}\right)dt$,"I need to show that $f'(0)=0$ for
$$
f(x)=\int\limits_0^x\sin\left(\frac{1}{t}\right)dt
$$
But fundamental theorem of calculus is unapplicable here. What should I do?","['integration', 'derivatives']"
163917,Continuous image of the intersection of decreasing sets in a compact space,"Suppose $B_{\epsilon}$ are closed subsets of a compact space and $B_{\epsilon} \supset B_{\epsilon'} \quad \forall \epsilon > \epsilon'$.  Furthermore, $B_0 = \bigcap_{\epsilon>0} B_{\epsilon}$.  For a continuous function $f$ can we conclude that
$$f(B_0) = \bigcap_{\epsilon>0} f(B_{\epsilon})?$$ I believe the answer to be yes.  It seems this should be a well-known property---I'm having trouble finding a reference.","['general-topology', 'compactness']"
163927,Which of these statements about $Q=\frac{1}{100}+\frac{1}{101}+\cdots+\frac{1}{1000}$ is correct?,"Pick the correct option regarding $Q$. $$Q=\frac{1}{100}+\frac{1}{101}+\cdots+\frac{1}{1000}$$
  Pick one option: $Q>1\qquad$ 2. $Q\leq \frac{1}{3}\qquad$ 3. $\frac{1}{3}<Q\leq \frac{2}{3}\qquad$ 4. $\frac{2}{3}<Q\leq 1$ My approach : $$Q = \frac{1}{100}+\frac{1}{101}+\cdots+\frac{1}{1000} > \frac{1}{1000}+\frac{1}{1000}+\cdots+\frac{1}{1000} = \frac{901}{1000}$$
$$\implies \frac{1}{100}+\frac{1}{101}+\cdots+\frac{1}{1000} > \frac{9}{10}$$ So, $Q > 1$. Option 1 is correct. Now, my question is: can this be proved with some other approach?",['algebra-precalculus']
163929,Relating the normalization of a variety over $\mathbb{Z}$ to its reduction mod $p$.,"I'm looking for a proof (or better, a reference) for the following claim. Claim: Let $X$ be an (irreducible) variety defined over $\mathbb{Z}$. Let $\nu:\tilde{X}\rightarrow X$ be its normalization. Then, for large enough primes $p$, $\tilde{X}/p$ is the normalization of $X/p$. The way I was trying to do this was by appealing to Serre's ""normal = $R1+S2$"" criterion. Doing this, it isn't difficult to prove that $X/p$ is $R1$ for all large primes. I'm having more difficulty with the $S2$ part. So, I'd appreciate either an elementary/direct proof of the above claim or a proof (or counterexample) of ""if $X$ is $S_k$ over $\mathbb{Z}$ then $X/p$ is $S_k$ over $\mathbb{F}_p$ for large enough primes $p$''.","['algebraic-geometry', 'reference-request']"
163941,"How to define rational composition of functions, appropriately?","Let $f: X \rightarrow X$ and  $f^{1/n}:X \rightarrow X$ such that $f$ is equal to $n$ times composition of $f^{1/n}$, i.e. $$f^{1/n} \circ f^{1/n}\circ \cdots \circ f^{1/n} = f $$ 
then $f^{1/n}$ is an $n$-th root of $f$. Such a function may well not exist in general, and if it does, might not be unique. But is there a universal way to construct unique n-th roots for arbitrary $f$?",['elementary-set-theory']
163946,Are Complex Substitutions Legal in Integration?,"This question has been irritating me for awhile so I thought I'd ask here. Are complex substitutions in integration okay?  Can the following substitution used to evaluate the Fresnel integrals: $$\int_{0}^{\infty} \sin x^2\, dx=\operatorname {Im}\left( \int_0^\infty\cos x^2\, dx + i\int_0^\infty\sin x^2\, dx\right)=\operatorname {Im}\left(\int_0^\infty \exp(ix^2)\, dx\right)$$ Letting $ix^2=-z^2 \implies x=\pm\sqrt{iz^2}=\pm \sqrt{i}z \implies z=\pm \sqrt{-i} x \implies dx = \pm\sqrt{i}\, dz$ Thus the integral becomes $$\operatorname {Im}\left(\pm \sqrt{i}\int_0^{\pm\sqrt{-i}\infty} \exp(z^2)\, dz\right)$$ This step requires some justification, and I am hoping someone can help me justify this step as well:
$$\pm \sqrt{i}\int_0^{\pm\sqrt{-i}\infty} \exp(z^2)\, dz=\pm\sqrt{i}\int^\infty_0\exp(z^2)\, dz=\pm\sqrt{i}\left(\frac{\sqrt{\pi}}{2}\right)$$ Thus $$\operatorname {Im}\left(\int_0^\infty \exp(ix^2)\, dx\right)=\operatorname {Im}\left(\pm\frac{\sqrt{i\pi}}{2}\right)=\operatorname {Im}\left(\pm\frac{(1+i)\sqrt{\pi}}{2\sqrt{2}}\right)=\pm\frac{1}{2}\sqrt{\frac{\pi}{2}}$$ We find that the correct answer is the positive part (simply prove the integral is positive, perhaps by showing the integral can be written as an alternating sum of integrals). Can someone help justify this substitution?  Is this legal?","['improper-integrals', 'special-functions', 'integration', 'fresnel-integrals', 'complex-analysis']"
163963,Tricky derivative with chain rule.,"Let $z = 1/x$ and $y = f(z)$, find $\dfrac{d^2y}{dx^2}$ So the answer was $$\frac{\mathrm{d} y}{\mathrm{d} x} = \frac{\mathrm{d} y}{\mathrm{d} z}\frac{\mathrm{d}z }{\mathrm{d}x }$$ Where $$\frac{\mathrm{d} y}{\mathrm{d} x} = \frac{\mathrm{d} y}{\mathrm{d} z}\frac{\mathrm{d}z }{\mathrm{d}x } =-\frac{\mathrm{d} y}{\mathrm{d} z}\frac{1}{x^2} = -\frac{\mathrm{d} y}{\mathrm{d} z}z^2$$ $$\dfrac{d^2y}{dx^2} =  \frac{\mathrm{d} }{\mathrm{d} x}\left ( \frac{\mathrm{d} y}{\mathrm{d} x} \right ) = \frac{\mathrm{d} }{\mathrm{d} x}\left ( \frac{\mathrm{d} y}{\mathrm{d} z}\frac{\mathrm{d}z }{\mathrm{d}x }\right ) = \frac{\mathrm{d} ^2y}{\mathrm{d} z^2}\left (\frac{\mathrm{d} z}{\mathrm{d} x}  \right )^2 + \frac{\mathrm{d} y}{\mathrm{d} z}\frac{\mathrm{d} ^2z}{\mathrm{d} x^2} $$ Could someone explain to me how on earth did $\frac{\mathrm{d} ^2y}{\mathrm{d} z^2}\left (\frac{\mathrm{d} z}{\mathrm{d} x}  \right )^2$ appear? EDIT: I am going to show what I did. $$\frac{\mathrm{d} }{\mathrm{d} x}\left ( \frac{\mathrm{d} y}{\mathrm{d} z}\frac{\mathrm{d}z }{\mathrm{d}x }\right ) = \frac{d}{dx}\left(\frac{dy}{dz}\right) \frac{dz}{dx}+\frac{d
^2z}{dx^2}\frac{dy}{dz} = \frac{d}{dx}\left(\frac{-1}{z^2} \frac{dy}{dx}\right) \frac{dz}{dx}+\frac{d
^2z}{dx^2}\frac{dy}{dz}$$ Basically I don't understand how $$\frac{d}{dx}\left(\frac{-1}{z^2} \frac{dy}{dx}\right)$$ could turn into $$\frac{\mathrm{d} ^2y}{\mathrm{d} z^2}\left (\frac{\mathrm{d} z}{\mathrm{d} x}  \right )^2$$ In fact I got  $$\frac{d}{dx}\left(\frac{-1}{z^2} \frac{dy}{dx}\right) = 2z^{-3}\frac{\mathrm{d} z}{\mathrm{d} x}\frac{\mathrm{d} y}{\mathrm{d} x} - \frac{1}{z^2}\frac{\mathrm{d} ^2 y}{\mathrm{d} x^2}$$","['calculus', 'derivatives']"
163973,Self-Linking Number on 3-Manifolds,"We can assign a framing to a knot $K$ (in some nice enough space $M$) in order to calculate the self-linking number $lk(K,K)$. But of course it is not necessarily canonical, as added twists in your vector field can remove/add crossings. Two things are stated in Witten's QFT paper on the Jones polynomial, which I do not quite see: 1) On $S^3$ we do have a canonical framing of knots, by requesting that $lk(K,K)=0$. Why? I must be understanding this incorrectly, because if we decide the framing by requiring $lk(K,K)=0$, so that the framing has whatever twists it needs to accomplish this, then aren't we making a choice?? We could have simply required $lk(K,K)=n$ for any integer $n$. If $n> 0$ does there then exist multiple possible framings? 2) For general 3-manifolds, we can have $lk(K,K)$ ill-defined or it can be a fixed fraction (modulo $\mathbb{Z}$) so that any choice of framing won't make it $0$. What are some examples? When is it possible to set a fixed fraction? Is there a relation between the 3-manifold $M$ and the fractional value you can assign to $lk(K,K)$?","['knot-theory', 'algebraic-topology', 'differential-geometry']"
163993,"Please recommend books on calculus, linear algebra, statistics for someone trying to learn Probability Theory and Machine Learning?","I am tackling some topics in Probability Theory and Machine Learning and while I have plenty of resources dedicated to those disciplines I am lacking in a good basic math foundation. Does anyone know any good, concise math books that can help introduce the foundations (calculus, linear algebra, statistics) of these disciplines to someone whose exposure to math is very limited? Of particular interest would be a book that could relate these concepts to someone familiar with programming to leverage that mode of thinking to relate the essential ideas.","['calculus', 'machine-learning', 'probability-theory', 'linear-algebra', 'reference-request']"
163997,$| f(z)| \le A + B \log {| z|}$ like inequality,"Let $f$ be an entire non-constant complex function and let $A$ and $B$ be given positive real constants. Is it possible that $|f(z)| \le A + B\log{| z|}$ for all complex $z$ such
that $| z| \ge 1$ ? I've been trying to solve using the fact that since $f$ is continuous in $\{z; |z|\le 1\}$ there exists $M=\sup\{ |f(z); |z|\le 1\}$, and then somehow use the Cauchy's integral formula for derivatives. Any ideas? Thanks",['complex-analysis']
164007,Proving $\sup\left\{ r\in\mathbb{Q}:r^{2}<3\right\}=\sqrt{3}$,"Let $E=\left\{ r\in\mathbb{Q}:r^{2}<3\right\}$.  Prove that $\sup E=\sqrt{3}$. Since $E$  is bounded from above by $\sqrt{3}$  and is nonempty, $\alpha:=\sup E$  must exist by the Least Upper Bound Principle. Now I am stuck. Suppose $\alpha<\sqrt{3}$. Then what? Edit: It just hit me.  If $\alpha < \sqrt{3}$ then since the rationals are dense in $\mathbb{R}$, there exists $q\in\mathbb{Q}$ such that $\alpha < q <\sqrt{3}$ and hence $\alpha^2 <q^2 <3$ which contradicts the fact that $\alpha$ is the sup of $E$",['analysis']
164010,Powers of $2 \times 2$ matrices expressed in linear form,"I recently reopened an old high school math textbook and came upon the matrices unit. Some of the questions were those rewrite-in-linear-form problems: given, say, $M^2 = 2M - I$, express in linear form ($aM+bI$) the matrices $M^3$ and $M^4$. The method of solution would be to express $M^n$ as $M^{n-1}M$ and continue expanding each consecutive set of powers until you end up substituting in the original $M^2 = 2M-I$, for answers of $M^3 = 3M-2I$ and $M^4 = 4M-3I$. Further, induction proof problems could also be posed, such as proving that $M^n = nM - (n-1)I$ for all $n \in \mathbb{Z}^+$. (Technically, it could also be for $n \in \mathbb{Z}$ if you consider $M^{-n} \equiv (M^{-1})^n \equiv (M^n)^{-1}$, which is relevant.) I decided to take this a step further, and see if I could take powers of $M$ where $M^2 = aM + bI$. After some experimentation, one can define two related sequences $(a_n)$ and $(b_n)$ which describe linear form coefficients of $M^n$. Trivially, $M^1 = M = 1M + 0I$ and $M^0 = MM^{-1} = I = 0M + 1I$, which defines $a_0$, $a_1$, $b_0$, and $b_1$ as 0, 1, 1 and 0, respectively. From this, and by the properties of expanding powers through $M^2 = a_2M + b_2I$, $$\begin{align}
&\text{Basic} \\
a_0 &= b_1 = 0 \\
a_1 &= b_0 = 1 \\
\\
&\text{Following} \\
a_{n+1} &= a_2 a_n + b_n \\
b_{n+1} &= b_2 a_n \\
\\
&\text{Preceding} \\
a_{n-1} &= \frac{1}{b_2}b_n \\
b_{n-1} &= a_n - \frac{a_2}{b_2} b_n \\
\end{align}$$
With a little playing around, one finds that $$a_n = a_2 a_{n-1} + b_2 a_{n-2}$$ which looks a little like the Fibonacci sequence, and since $b_n$ is already defined in terms of $a_n$, the crux of the problem lies in a non-recurring equation for $a_n$, given $a_2$ and $b_2$ as parameters. Is there a formula for $a_n$, and subsequently, $b_n$? Am I on the right track with this method or is there a more elegant exploitability in these sequences?","['matrices', 'recurrence-relations', 'sequences-and-series']"
164016,how to find maximal linearly independent subsets,"Given a set of vectors, we can compute the number of independent vectors by calculating the rank of the set, but my question is how to find a maximal linearly independent subset. Thanks!",['linear-algebra']
164024,Infinite extension in Galois theory,"I got this question while I am studying Galois correspondence. Let $K/F$ be an infinite extension and $G = \mathrm{Aut}(K/F)$.
Let $H$ be a subgroup of $G$ with finite index and $K^H$
be the fixed field of $H$. Is it true that $[K^H:F]= (G:H)$? For finite extension, I verified this 
is true. Is it true in infinite case also? Thanks","['galois-theory', 'abstract-algebra']"
164055,"For field extensions $F\subsetneq K \subset F(x)$, $x$ is algebraic over $K$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $x$ be an element not algebraic over $F$, and $K \subset F(x)$ a subfield that strictly contains $F$. Why is $x$ algebraic over $K$? Thanks a lot!","['abstract-algebra', 'field-theory']"
164059,Do probability distributions form a comonad?,"$\def\unit{{\rm unit}}\def\join{{\rm join}}$It's well known that (discrete) probability distributions form a monad . Specifically, if we let $PX$ be the set of discrete probability distributions on elements of $X$, and notate them as a set of pairs $(x,p)$ such that $\sum p=1$, then we have natural transformations $$\begin{align}
\unit : X & \to PX \\
\unit : x & \mapsto  \{ (x,1) \} \\
\\
\join: P(PX) & \to PX \\
\join: D & \mapsto \{(y,pq)| (x,p) \in D, (y,q)\in x \} 
\end{align}$$ that satisfy the monad laws. Can probability distributions be made into a comonad as well? For that, we would need to provide natural transformations $$\begin{align}
{\rm counit} : PX & \to X \\
{\rm cojoin} : PX & \to P(PX)
\end{align}$$ that satisfy the comonad laws. It seems that the role of counit can be played by mathematical expectation (as long as $X$ is an $\mathbb{R}$-module), but in that case what is the correct definition of cojoin? Edit: Zhen Lin pointed out in the comments that if you want to have counit being expectation, then you need an $\mathbb{R}$-module structure on $PX$ as well as on $X$. The module operations on $PX$ are inherited from those on $X$ in the following way: Addition $$D_1 + D_2 = \{ (x+y,pq) | (x,p)\in D_1, (y,q)\in D_2\}$$ Multiplication by a scalar $$qD = \{ (qx,p) | (x,p)\in D \}$$","['probability-theory', 'category-theory', 'probability-distributions', 'monads']"
164074,How to evaluate $ \lim \limits_{n\to \infty} \sum \limits_ {k=1}^n \frac{k^n}{n^n}$?,"I can show that the following limit exists but
I am having difficulties to find it. It is
$$\lim_{n\to \infty} \sum_{k=1}^n \frac{k^n}{n^n}$$
Can someone please help me?","['sequences-and-series', 'calculus']"
164082,Algebra of Functions,"There seems to be an interesting algebra of functions. Does it already exist in literature? Given functions $f_1 : X_1 \to Y$ and $f_2 : X_2 \to Y$, if $f_1(x) = f_2(x)$ for all $x \in X_1 \cap X_2$, then their sum is defined as $(f_1 + f_2) : X_1 \cup X_2 \to Y$, where
$$
(f_1 + f_2)(x) =
\begin{cases}
f_1(x) & x \in X_1\\
f_2(x) & x \in X_2.
\end{cases}
$$ Given functions $f : X \to Y$ and $g : Y \to Z$, their product is defined as $fg : X \to Z$, where
$$
(fg)(x) = g(f(x)).
$$ We immediately have the following: Addition is commutative and associative. The empty function with domain the empty set $\emptyset$ is the additive identity. Mutliplication is associative and distributes over addition. The identity function is the multiplicative identity. These properties seem so nice that this algebra must have been investigated before - does anyone have some references for this?","['functions', 'abstract-algebra']"
164099,Is the product of square singular and non singular matrices always singular?,"Given $A,B\in R^{n\times n}$ such that A is singular, and B is non-singular.  Is $(AB)$ always singular?  If so, how do I prove it?",['linear-algebra']
164119,All subgroup are Normal,"All subgroups of a abelian group are normal. But the converse is not true. If every subgroup of a group is normal, then what more can we say about the group?",['group-theory']
164126,How to evalutate this exponential integral,"Is there an easy way to compute $$\int_{-\infty}^\infty\exp(-x^2+2x)\mathrm{d}x$$
without using a computer package?","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
164127,An introductory textbook on functional analysis and operator theory,"I would like to ask for some recommendation of introductory texts on functional analysis. I am not a professional mathematician and I am totally new to the subject. However, I found out that some knowledge of functional analysis and operator theory would be quite helpful to my work... What I am searching for is some accessible and instructive text not necessarily covering the subject in great depth, but explaining the main ideas. I am not searching for a text for engineers, some amount of mathematical rigor would be fine. But I found myself unable of reading some standard textbooks covering in great depth a large amount of issues in theory of Banach spaces, etc. I am looking for something that proceeds to the most important topics (e.g., spectral theory) faster than the most of textbooks, but not at the expense of rigor. I.e., something that covers rigorously the main topics, but concentrates only on the main ideas.
Simply an accessible introductory text for a fast orientation in the subject. Moreover, I would prefer a text that does not require any background in measure theory and similar disciplines. And another question: is there any functional analysis book that deals primarily with sequence spaces? It need not fulfill the description above. Thank you for your recommendations!","['functional-analysis', 'reference-request', 'operator-theory']"
164128,Finding an orthogonal basis from a column space,"I'm having issues with understanding one of the exercises I'm making. I have to find an orthogonal basis for the column space of $A$, where: $$A = \begin{bmatrix}
0 & 2 & 3 & -4 & 1\\
0 & 0 & 2 & 3 & 4 \\
2 & 2 & -5 & 2 & 4\\
2 & 0 & -6 & 9 & 7
\end{bmatrix}.$$ The first question was to find a basis of the column space of $A$, clearly this is simply the first $3$ column vectors (by reducing it to row echelon form, and finding the leading $1$'s). However, then I had to find an orthogonal basis out of the column space of $A$, and here is where I get lost. I started off with finding the first vector: $$u_1 = \begin{bmatrix}0\\0\\2\\2\\\end{bmatrix}.$$ Then I thought I would find the second vector like this: $$u_2 = \begin{bmatrix}2\\0\\2\\0\\\end{bmatrix}-\left(\begin{bmatrix}2\\0\\2\\0\\\end{bmatrix}\cdot\begin{bmatrix}0\\0\\2\\2\\\end{bmatrix}\right)*\begin{bmatrix}0\\0\\2\\2\\\end{bmatrix} = \begin{bmatrix}2\\0\\2\\0\\\end{bmatrix}-4*\begin{bmatrix}0\\0\\2\\2\\\end{bmatrix} = \begin{bmatrix}2\\0\\-6\\-8\\\end{bmatrix}.$$ However, according to the result sheet we were given, instead of having a $4$, I should have $\frac{4}{8}$. I somehow can not figure out what I am missing, since the dot product of the two vectors clearly is $4$. Also, as a second question: if I had to find a orthonormal basis I would only have to take the orthogonal vectors found here, and multiply them by their $1$/length, correct?","['matrices', 'linear-algebra']"
164171,Proving that there are infinite cardinal numbers >$\mathfrak{c}$,"I was reading Simmons' book and he states that there are infinite cardinal numbers > $\mathfrak{c}$ where $\mathfrak{c}$ denotes the number of Real Numbers. For this, he states that we can construct a class consisting of the subsets of the set of Real Numbers and that it is not possible to have one-to-one correspondence with the 2 sets thus proving that there are numbers of higher cardinality. What I don't understand is how he went about proving the absence of 1-to-1 correspondence. He assumes that it is possible then establishes it via contradiction. ( I did not follow the proof at all but that's another story). Why can't we simply prove it by induction? If we take a set of 1 element, the ""number of elements"" in the set and the set of all it's subsets is different. (2^n specifically) so 1-to-1 correspondence is not possible. So, base case is proved. If we assume for k, k+1 th case is proved similarly. So, can't we state that for ANY set, 1-to-1 correspondence is not possible with the set of it's subsets?","['induction', 'cardinals', 'elementary-set-theory']"
164178,"Is $\mathbb{R}^\omega$ a completely normal space, in the box topology? [duplicate]","This question already has an answer here : Is $\mathbb{R}^\omega$ endowed with the box topology completely normal (or hereditarily normal)? (1 answer) Closed 5 years ago . Basically, what the title says. Is $\mathbb{R}^\omega$ a completely normal space in the box topology ?
($\mathbb{R}^\omega$ is the space of sequences to $\mathbb{R}$)
Thanks !",['general-topology']
164179,Induced $\sigma$-algebra vs. product $\sigma$-algebra,"Let $(E,\mathscr E)$ be a measurable space and $(S,2^S)$ be a finite set. Let 
$$
  \xi:(E,\mathscr E)\to(S,2^S)
$$
be a mesaurable function, i.e. $\xi^{-1}(s)\in \mathscr E$ for any $s\in S$. Now, let us denote by $\Omega = E^{\mathbb N_0}$ and by $\mathscr F$ its product $\sigma$-algebra. Also, let $\Sigma = S^{\mathbb N_0}$ and let $\mathscr S$ be the correspondent product $\sigma$-algebra. Let $\eta:\Omega\to\Sigma$ be the element-wise extension of $\xi$, i.e.
$$
  \eta(\omega_0,\omega_1,\dots) = (\xi(\omega_0),\xi(\omega_1),\dots).
$$ I wonder if $\mathscr S$ is different from 
$$
  \mathscr C = \{A\subseteq \Sigma:\eta^{-1}(A)\in \mathscr F\}.
$$
It is clear that $\mathscr S\subseteq \mathscr C$ - but can the strict inclusion actually happen?",['measure-theory']
164192,Solving a complex integral,"I need help solving an integral from John Conway book. 
Lets $\alpha$ complex number different from 1 find integral $$\int\frac{dx}{1-2\alpha\cos{x}+{\alpha}^2}$$ from 0 to $2\pi$ in unit circle $$(z-\alpha)^{-1}(z-\frac{1}{\alpha})^{-1}$$",['complex-analysis']
164201,Radon measures and sequences,"I have a question about Radon meaures: Given a Radon measures $ \mu_{1}, \mu_{2}$, both have compact support: How to show that  $\int \hat{\mu_{1}}(x)\,d\mu_{2}(x)=\int \hat{\mu_{2}}(x)\,d\mu_{1}(x)$ , where the ""hat"" means Fourier transform. Thanks for help in advance.","['measure-theory', 'fourier-analysis', 'functional-analysis', 'real-analysis']"
164204,Density of finite rank operators on Hilbert space,Are finite rank operators on Hilbert space $H$ dense in $B(H)$ in the weak operator topology?,"['operator-theory', 'functional-analysis']"
164208,Why is minimizing the nuclear norm of a matrix a good surrogate for minimizing the rank?,"A method called ""Robust PCA"" solves the matrix decomposition problem $$L^*, S^* = \arg \min_{L, S} \|L\|_* + \|S\|_1 \quad \text{s.t. } L + S = X$$ as a surrogate for the actual problem $$L^*, S^* = \arg \min_{L, S} rank(L) + \|S\|_0 \quad \text{s.t. } L + S = X,$$ i.e. the actual goal is to decompose the data matrix $X$ into a low-rank signal matrix $L$ and a sparse noise matrix $S$. In this context: why is the nuclear norm a good approximation for the rank of a matrix? I can think of matrices with low nuclear norm but high rank and vice-versa. Is there any intuition one can appeal to?","['matrix-rank', 'matrices', 'normed-spaces', 'linear-algebra', 'nuclear-norm']"
164216,How to solve $x'(t)=\frac{x+t}{2t-x}$?,"I wish to solve $x'(t)=\frac{x+t}{2t-x}$ with the initial condition
$x(1)=0$. I noted that $x'(t)=f(\frac{x}{t})$ where $f(y)=\frac{y+1}{2-y}$
so I denoted $y(t)=\frac{x(t)}{t}$ and got that $y'(t)=\frac{f(y)-y}{t}$
so I can write something like $\frac{dy}{dt}=\frac{f(y)-y}{t}$ so
$\frac{dy}{f(y)-y}=\frac{dt}{t}$ . Here I am a bit stuck, I know I should do something like take integrals
on both sides, but I am having trouble with the initial condition.
In this exercise I can leave integrals in the answer so I would like
to know how to get the solution with the integral, I think this requires
to calculate the boundaries of some integral (maybe of $\frac{f(y)-y}{t}$
?) How can I continue to get the solution with integral that satisfies
the initial condition ?
Help is appriciated!",['ordinary-differential-equations']
164228,Completeness and separability of Lévy's metric,"Let $D$ be the set of all functions $F: \mathbb{R} \rightarrow \mathbb{R}$ which are nondecreasing, left-hand-side continuous and $\lim_{x \rightarrow -\infty} F(x)=0$ and 
$\lim_{x \rightarrow \infty} F(x)=1$.
Let $d$ be a Lévy metric in $D$, that is: $$d(F,G)=\inf \{ e >0: G(x-e)-e \leq F(x) \leq G(x+e)+e\text{ for }x\in \mathbb{R} \}\;.$$ How to prove completeness and separability of $(D, d)$ ? I know that a sequence  $(F_n)$ from $D$ is convergent to $F$ from $D$ iff $\lim_{n\rightarrow \infty} F_n(x)=F(x)$ in each $x \in \mathbb{R}$ in which $F$ is continuous.","['metric-spaces', 'probability', 'analysis']"
164240,Fireworks under inverse-cube gravity,"What is the path of a projectile under an inverse-cube gravity law? Imagine that the law of gravity was changed overnight from
$F(r) = G m_1 m_2 / r^2$
to 
$F(r) = G' m_1 m_2 / r^3$.
To be specific, suppose 
$G' = G r_E$ where $r_E$ is the radius of the Earth,
so that the force at the Earth's surface is unchanged.
I am wondering how would the arc of a fireworks rocket
compare to the parabolic path it would follow under the inverse-square law.
(In the U.S. at this time of year, the evening sky is full of fireworks
as we approach the 4th of July.)
Presumably, the same rocket would travel a bit higher and cover
a bit more distance horizontally, but what is the precise path it would follow? It is known that the solutions to a central force that is inverse-cubic is a Cotes' Spiral ,
which comes in three varieties: But I am uncertain which of the three would apply here, and how to compute the relevant constants.
Perhaps a piece of an epispiral ,
something like this? It would be instructive to see the inverse-square parabola and the inverse-cubic Cotes's spiral,
for the same projectile initial conditions, plotted together... Addendum . After retrieving Arnol'd's book as per Mark Dominus's recommendation,
I wanted to share one interesting fact (p.37):  The only central-force laws
in which all the bounded orbits are closed are the inverse-square and inverse-cubic laws!","['geometry', 'plane-curves', 'classical-mechanics', 'physics']"
164244,Normal subgroup of prime index,Generalizing the case $p=2$ we would like to know if the statement below is true. Let $p$ the smallest prime dividing the order of $G$. If $H$ is a subgroup of $G$ with index $p$ then $H$ is normal.,"['finite-groups', 'group-theory', 'abstract-algebra', 'normal-subgroups']"
164250,"Mathematics in the "" The Art of Computer Programming""","I don't know of this the right place to ask this type of question and hence I apologize (in advance) for any inconvenience. Here is my question: I have studied Concrete Mathematics by Knuth, Graham and Patashnik. I am now studying The Art of Computer Programming by Knuth. I am really intrigued by the mathematics used in it (which is my main motivation to study this book in the first place) and thus am not using it (at all) for programming purposes. I wanted to know if what I am doing is right? Is it right to study the ""Bible of Algorithms"" just for the mathematics in it or should I consult more specialized mathematical books which deal with the topics covered in the TAOCP.","['discrete-mathematics', 'reference-request', 'algorithms']"
164256,How do I know which method of revolution to use for finding volume in Calculus?,"Is there any easy way to decide which method I should use to find the volume of a revolution in Calculus? I'm currently in the middle of my second attempt at Calculus II, and I am getting tripped up once again by this concept, which seems like it should be rather straight forward, but I can't figure it out. If I have the option of the disk/washer method and the shell method, how do I know which one I should use?","['calculus', 'integration']"
164264,Do elliptic operators on Riemannian manifolds have a regularizing effect?,"I'm working on my master thesis and need to handle some spectral theory of the Laplace operator on compact Riemannian manifolds and especially on the sphere. While investigating essential self-adjointness I stumbled on the following problem. * Problem *$\quad$ In a compact Riemannian manifold $M$ let $$\Delta=\operatorname{div}\operatorname{grad}$$ and let $f\in L^2(M)$ be such that $(f, u-\Delta u)=0$ for every $u \in C^{\infty}(M)$. Prove that $f=0$. I believe that the claim is true, because the condition $(f, u-\Delta u)=0$ means exactly that $f$ is a distributional solution of the elliptic equation $-\Delta f + f=0$, and so I expect it to be a $H^2_{\text{loc}}$ function (see Theorem 2.1 of Berezin - Shubin's book ). Since $M$ is compact this must imply that $f\in H^1(M)$ so that integrating by parts we get $\lVert f \rVert_{H^1}^2=(f, f)+(\operatorname{grad}f, \operatorname{grad}f)=0$. Unfortunately Theorem 2.1 above is set in an open subset of the Euclidean space and I don't know if it is applicable verbatim in a Riemannian manifold. Can you point me to some reference on this? Thank you.","['functional-analysis', 'riemannian-geometry', 'spectral-theory', 'reference-request']"
164271,algorithm related to XOR,"I have $N$ values, $a_1,a_2,a_3\ldots a_N$.
Now let us say i could increase any of these values by any amount such that the XOR sum becomes zero. $$(a_1+d_1) \oplus (a_2+d_2) \oplus \cdots \oplus (a_n+d_n) =0 $$ i need to find the deltas  $d_1,d_2,d_3,\ldots,d_n$ such that the sum of deltas is minimized.
 any delta , $d_k \ge 0$. $N$ could be up to $100$ in my case. Could you please tell if there is any known way to compute it. Many thanks","['algorithms', 'number-theory']"
164286,Line Bundle on subvarieties,"I've been having problem actually restricting a Line bundle $L$ defined on some projective space $\mathbb C \mathbb P^{N-1}$ to a subvariety $X$. I know how to do this on an abstract level, but actually computing what's going on, seems quite mysterious. From Fulton's ""Intersection Theory"" I have $c_1(L) \cap [X] = [C]$ where $C$ is the divisor corresponding to $\mathcal O_X(C) \simeq L\vert_X$ Now, I have $c_1(L)$ given by $-N[H]$ where $[H]$ denotes the hyperplane class in $\mathbb C \mathbb P^{N-1}$. I also have some polynomial $P$ whose zero locus defines $X$. I even know $c_1(TX) = 0$ and have computed that if $X$ is taken to be a divisor in $\mathbb C \mathbb P^{N-1}$, the corresponding line bundle would satisfy $c_1(\mathcal{O}(X)) = N[H]$ (Not quite sure yet if this helps). But, what I really would like to know is $c_1(L\vert_X)$ ? My attempts so far have been to find an actual section $s$ of $L$, use the equation for the zero locus and actually intersect that with $X$. However, finding such a section has proven difficult. How would one normally go about this? 
Am I on the right track? Any help is highly appreciated!","['projective-space', 'fiber-bundles', 'algebraic-geometry', 'elliptic-curves']"
164287,subgroup of connected locally compact group,I need a reference or a short proof for the following property: A nontrivial connected locally compact group $G$ contains an infinite abelian subgroup.,"['reference-request', 'topological-groups', 'group-theory', 'locally-compact-groups']"
164289,bounded measurable function is the uniform limit of a sequence of simple functions,Let $ f: \mathbb R \to \mathbb R $ a non-negative bounded measurable function. Prove that there exists a sequence of simple non-negative functions $ (f_n)_{n \in \mathbb N} $ such that $ f_n \to f$ uniform. Searching on Wikipedia I found the following http://en.wikipedia.org/wiki/Simple_function but I can't understand why the converge is uniform. Any help?,"['measure-theory', 'real-analysis']"
164301,"Exact sequence of sheaves in Beauville's ""Complex Algebraic Surfaces""","On the first pages of Beauville's ""Complex Algebraic Surfaces"", he has a surface $S$ (smooth, projective) and two curves $C$ and $C'$ in $S$. He defines $\mathcal{O}_S(C)$ as the invertible sheaf associated to $C$. I'm assuming that if $C$ is given as a Cartier divisor by $(U_\alpha,f_\alpha)$, then $\mathcal{O}_S(C)(U_\alpha)$ is generated by $1/f_\alpha$ (following Hartshorne's notation); this assumption is justified as Beauville says that $\mathcal{O}_S(-C)$ is simply the ideal sheaf that defines $C$. The part I don't understand is that he then takes a non-zero section $s\in H^0(\mathcal{O}_S(C))$ (and the same for $s'$) and says that it vanishes on $C$. Isn't this the definition of a global section of $\mathcal{O}_S(-C)$ though (according to the previous notation)? He then writes the exact sequence (which I don't really understand)
$$0\to\mathcal{O}_S(-C-C')\stackrel{(s',-s)}{\to}\mathcal{O}_S(-C)\oplus\mathcal{O}_S(-C')\stackrel{(s,s')}{\to}\mathcal{O}_S\to\mathcal{O}_{C\cap C'}\to 0.$$
I need to have the definitions clear in order to be able to understand the exact sequence. Can anybody help me out?",['algebraic-geometry']
164326,Angle between vectors when their dot product and norm of cross product are equal.,"I had a question in the final exam that asked what the angle between vectors a and b is if:
  $$\vec a \cdot \vec b=|\vec a\times\vec b| $$ Any hints please.",['multivariable-calculus']
164328,Linear combination of cosines: so close to perodic.,"I'm interested in linear combinations of cosines:
$$f(x) = \alpha_1 \cos(2\pi \theta_1 x) + \alpha_2 \cos(2\pi \theta_2 x) +
\cdots + \alpha_k \cos(2\pi \theta_k x)\enspace,$$
where $\alpha_i \in \mathbb{Z}$ and the $\theta_i$'s are linearly dependent
irrational numbers (when they are rational numbers or irrational linearly
independent, I have less trouble, as in the former case the function is
periodic, and in the second, any value of each $\cos$ can be attained
independently of the others). When plotting functions like this, one sees that they are not periodic, but
still, they are close to be.  In particular, it seems that there are values
$p$ and $\epsilon$ such that if $f(x) > \epsilon$, then $f(x+n\times p) >
\epsilon$, at least for the first few $n$'s.  I have two questions: Is this true? Is there a name for the pseudo-periodicity that $f$ seems to enjoy? Thanks!","['trigonometry', 'real-analysis']"
164369,How to calculate the perceived frequency of two sinusoidal waves added together?,"If you add together two sinusoidal waves of different frequencies, how do you calculate the frequency of the resulting function as perceived by a human?","['trigonometry', 'signal-processing']"
164384,Markov and independent random variables,"This is a part of an exercise in Durrett's probability book. Consider the Markov chain on $\{1,2,\cdots,N\}$ with $p_{ij}=1/(i-1)$ when $j<i, p_{11}=1$ and $p_{ij}=0$ otherwise. Suppose that we start at point $k$. We let $I_j=1$ if $X_n$ visits $j$. Then $I_1,I_2,\cdots,I_{k-1}$ are independent. I don't find it obvious that $I_1,\cdots,I_{k-1}$ are independent. It is possible to prove the independence if we calculate all $P(\cap_{j\in J\subset\{1,\cdots,k-1\}}I_j)$, but this work is long and tedious. Since the independence was written as an obvious thing in this exercise, I assume that there is an easier way.","['markov-chains', 'probability']"
164390,Does $\left(n^2 \sin n\right)$ have a convergent subsequence?,"I'm wrestling with the following: Question :  For what values of $\alpha > 0$ does the sequence $\left(n^\alpha \sin n\right)$ have a convergent subsequence? (The special case $\alpha = 2$ in the title happened to arise in my work.)  In a continuous setting this would be a very simple question since $x^\alpha \sin x$ achieves every value infinitely often for (positive) $x \in \mathbb{R}$, but I feel ill-equipped for this situation -- I have an eye on the Bolzano-Weierstrass theorem and not much else. I have shown the answer is affirmative for $\alpha \leq 1$.  Here is my idea. Proof when $0 < \alpha \leq 1$ :  Define $x_n = n^\alpha \sin n$ for all $n \in \mathbb{N}$.  We will find a bounded subsequence $(y_n)$ of $(x_n)$ so the Bolzano-Weierstrass theorem applies.  Let $n \geq 1$ be arbitrary; then by Dirichlet's approximation theorem there are $p_n, q_n \in \mathbb{N}$ satisfying
  $$q_n \leq n \,\,\,\,\,\,\,\,\,\, \text{and} \,\,\,\,\,\,\,\,\,\, |q_n \pi - p_n| < \frac{1}{n}.$$
  Take $y_n = x_{p_n} = (p_n)^\alpha \sin p_n$ for this index $n$.  Then
  $$\begin{eqnarray}|y_n| &=& (p_n)^\alpha \left|\sin(q_n \pi - p_n)\right|\\
&<& (p_n)^\alpha \left(\frac{1}{n}\right)\\
&<& \left(q_n \pi + \frac{1}{n}\right)^\alpha \left(\frac{1}{n}\right)\\
&\leq& \left(n \pi + \frac{1}{n}\right)^\alpha \left(\frac{1}{n}\right)\\
&\leq& \left(n \pi + \frac{1}{n}\right) \left(\frac{1}{n}\right)\\
&\leq& \pi + 1\end{eqnarray}$$
  so the sequence $(y_n)$ has a convergent subsequence $(z_n)$ by the Bolzano-Weierstrass theorem.  But $(z_n)$ is in turn a subsequence of $(x_n)$, which proves the claim. Unfortunately, my strategy breaks down when $\alpha > 1$ (where I replace $\alpha$ by $1$ in the chain of inequalities).  So in this case, can a convergent subsequence be found some other way or not?  (I have a suspicion as to the answer, but I don't want to bias people based on heuristics.)","['special-functions', 'sequences-and-series', 'analysis']"
164398,Varieties and Statistics,"Consider a random variable $X$ that can take on the values $0,1$ and $2$. So we have $$p_i = P(X=i), \ i = 0,1,2$$ $$\sum_{i=0}^{2} p_i = 1$$ and $$0 \leq p_i \leq 1$$ So identifying a random variable $X$ is the same thing as identifying a point $(p_0,p_1,p_2) \in \mathbb{R}^3$. Now suppose $X$ is a binomial random variable. Then $$p_i = P(X = i) = \binom{2}{i} q^{i}(1-q)^{2-i}$$ and $$4p_{0}p_{2}-p_{1}^{2} = 0$$ How is this related to algebraic geometry? The above equation is an algebraic variety in $\mathbb{R}^3$?","['statistics', 'algebraic-geometry', 'probability']"
164400,"Show $\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}dx = \ln(t),$ for $t \gt 0$","The problem is to show $$\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}dx = \ln(t),$$ for $t \gt 0$. I'm pretty stuck. I thought about integration by parts and couldn't get anywhere with the integrand in its current form. I tried a substitution $u=e^{-x}$ and came to a new integral (hopefully after no mistakes) $$ \int_0^1 \frac{u^{t-1}-1}{\log(u)}du, $$ but this doesn't seem to help either. I hope I could have a hint in the right direction... I really want to solve most of it by myself. Thanks a lot!","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
164408,"""Isolated"" pieces in figures of triangles","Let us consider a figure of the Euclidean plane comprised of finitely many non-degenerate non-overlapping triangles (i.e., no triangle has a zero area and no two distinct triangles have any inner point in common). Two distinct triangles are said to be neighbors iff they have at least two points in common (i.e., they share a portion of side of non-zero length, so indeed infinitely many points). Must there be at least one triangle that has at most three neighbors? Is this a known problem? Thanks in advance.","['geometry', 'graph-theory', 'euclidean-geometry']"
164410,Quick sort algorithm average case complexity analysis,"This is for self-study. This question is from Kenneth Rosen's ""Discrete Mathematics and Its Applications"". The quick sort is an efﬁcient algorithm. To sort $a_1,a_2,\ldots,a_n$, this algorithm begins by taking the ﬁrst element $a_1$ and forming two sublists, the ﬁrst containing those elements that are less than $a_1$, in the order they arise, and the second containing those elements greater than $a_1$, in the order they arise. Then $a_1$ is put at the end of the ﬁrst sublist. This procedure is repeated recursively for each sublist, until all sublists contain one item. The ordered list of $n$ items is obtained by combining the sublists of one item in the order they occur. In this exercise we find the average-case complexity of the quick sort algorithm, assuming a uniform distribution on the set of permutations. a) Let X be the number of comparisons used by the quick sort algorithm to sort a list of n distinct integers. Show that the average number of comparisons used by the quick sort algorithm is $E(X)$ (where the sample space is the set of all $n!$ permutations of $n$ integers). b) Let $I(j,k)$ denote the random variable that equals 1 if the $j^{th}$ smallest element and the $k^{th}$ smallest element of the initial list are ever compared as the quick sort algorithm sorts the list and equals 0 otherwise. Show that $X = \sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}$. c) Show that $E(X) = \sum_{k=2}^{n} \sum_{j=1}^{k-1} p$, where $p$ is the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared. d) Show that $p$ (the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared), where $k > j$, equals $2/(k − j + 1)$. I didn't have any particular problem with parts a, b and c . I think that I managed to understand parts a , b and c . For part a , this seems obvious from the definition of expected value. E(X) is the average value of the number of comparisons, weighted by the probability that the permutation has a particular order (which is $1/n!$). For part b , I verified that the sum $\sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}$ gives $I_{1,2} + I_{1,3} + I_{2,3} + I_{1,4} + I_{2,4} + I_{3,4}+\cdots+I_{n-1,n}$, that is, it gives the value of $I_{j,k}$ for every combination of $j$ and $k$. So, it sums 1 to every pair of integers that will be compared. Since the only situation two integers get compared is when one of them the the first element of the list (also called the ""pivot""), this means that these two integers will go each one to separate sublists, so that they will not be compared anymore (in other words, every pair of integers is compared at most once). Therefore, it makes sense to say that the mentioned sum will give $X$, the total number of comparisons made by quick sort. Part c also seems straightforward. The result follows from the linearity of the expected value (the expected value of a sum is the sum of the expected values): $E(X) = E\left(\sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}\right) = \sum_{k=2}^{n}\sum_{j=1}^{k-1}E(I_{j,k})$. The value of $E(I_{j,k})$ (the expected value of $I_{j,k}$) is 1 times the probability that $I_{j,k}$ gets the value 1; the probability that $I_{j,k}$ gets the value 1 is the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared, so $I_{j,k} = p$. So, $E(X) = \sum_{k=2}^{n}\sum_{j=1}^{k-1}p$. Part d is where I got stuck. I tried to reason the following way: given a list that will be ordered by quick sort, two integers $a_j$ and $a_k$ will get compared only if one of them is the pivot. Also, if a number that is smaller than $a_k$ and greater than $a_j$ is the pivot, $a_k$ and $a_j$ will go to separate sublists, so that they will never get compared. Otherwise, if the pivot is either greater than both $a_k$ and $a_j$, or smaller than them, $a_j$ and $a_k$ will both go to the same sublist, so that, in another recursive call of the algorithm, they may still get compared. But I'm not sure how to show that the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are ever compared is $2/(k − j + 1)$. Could anyone give a hint? I would prefer a hint over a complete solution, so that I can discuss it further in comments to fill in the holes.","['recursive-algorithms', 'discrete-mathematics', 'probability', 'algorithms']"
164418,"If $f_n\colon [0, 1] \to [0, 1]$ are nondecreasing and $\{f_n\}$ converges pointwise to a continuous $f$, then the convergence is uniform","Suppose that $\{f_n\}$ is a sequence of nondecreasing functions which map the unit interval into itself. Suppose that $$\lim_{n\rightarrow \infty} f_n(x)=f(x)$$ pointwise and that $f$ is a continuous function. Prove that $f_n(x) \rightarrow f(x)$ uniformly as $n \rightarrow \infty$, $0\leq x\leq1$. Note that the functions $f_n$ are not necessarily continuous. This is one of the preliminary exam from UC Berkeley, the solution goes like this: Because $f$ is continuous on $[0,1]$, which is compact, it is then uniformly continuous. Hence there exists $\delta >0$ such that if $|x-y|<\delta$ then $|f(x)-f(y)|<\epsilon$. We then partition the interval with $x_0=0, \cdots ,x_m=1$ such that the distance $x_{i}-x_{i-1}$ is less than $\delta$. Note that since there are only finite number of $x_m$, there is $N\in \mathbb{N}$ such that if $n\geq N$ then $|f_n(x_i)-f(x_i)|<\epsilon$ where $i=0,\cdots, m$ Now if $x\in[0,1]$, then $x\in[x_{i-1},x_i]$ for some $i\in\{1, \cdots m\}$. My question is how to use the nondecreasingness to arrived at this inequality, for $n\geq N$ $f(x_{i-1})-\epsilon<f_n(x)<f(x_{i-1})+2\epsilon$ Can someone please help, I have been staring at the inequality for about a day now. Thanks.","['metric-spaces', 'real-analysis', 'analysis']"
164422,"Matrix raised to a matrix: $M^N$, is this possible? with $M,N\in M_n(\Bbb K).$","I was wondering if there is such a valid operation as raising a matrix to the power of a matrix, e.g. vaguely, if $M$ is a matrix, is
$$
M^N
$$
valid, or is there at least something similar?  Would it be the components of the matrix raised to each component of the matrix it's raised to, resulting in again, another matrix? Thanks,","['matrices', 'complex-numbers', 'linear-algebra', 'exponentiation']"
164430,Seemingly obvious density question with bounds on higher partial derivatives,"I have the following two linear spaces of functions:
$\mathcal{A}(\mathbb{R}^n)$ contains all $f \in C^{\infty}(\mathbb{R}^{2n})$ such that
for each multi-indices $\alpha, \beta$ there is a constant $C_{\alpha, \beta} > 0$ with
$$|\partial_x^{\alpha} \partial_{\xi}^{\beta} f(x, \xi)| \leq C_{\alpha, \beta} (1+ |x| + |\xi|)^{-|\alpha| - |\beta|}.$$ 
And $\mathcal{B}(\mathbb{R}^{n+m})$ in the same way contains all functions $f \in C^{\infty}(\mathbb{R}^{2n + 2m})$ such that $$|\partial_{x}^{\alpha} \partial_{\xi}^{\beta} \partial_{y}^{\gamma} \partial_{\eta}^{\delta} f(x, \xi, y, \eta)| \leq C_{\alpha, \beta, \gamma, \delta} (1 + |x| + |\xi|)^{-|\alpha| - |\beta|} (1 + |y| + |\eta|)^{-|\gamma| - |\delta|}.$$ Here $\mathcal{A}(\mathbb{R}^n)$ is given the Fréchet topology of optimal constants, i.e. the topology generated by the seminorms $$\|f\|_{\alpha, \beta, K} := \sup_{(x, \xi) \in K}|((1 + |x| + |\xi|)^{|\alpha| + |\beta|}) \partial_x^{\alpha} \partial_{\xi}^{\beta} f(x, \xi)|$$ for each $K \subset \mathbb{R}^{2n}$ compact and multi-indices $\alpha, \beta$. Analogously for $\mathcal{B}$. QUESTION: Is $\mathcal{A}(\mathbb{R}^n) \otimes \mathcal{A}(\mathbb{R}^m)$ dense in $\mathcal{B}(\mathbb{R}^{n+m})$? IDEAS: I think the answer is yes as would anyone by looking at it. But I don't have a clear argument. I suspect ultimately a reduction to the density $C_c^{\infty}(\mathbb{R}^{n}) \otimes C_c^{\infty}(\mathbb{R}^m) \subset C_c^{\infty}(\mathbb{R}^{m+n})$ by a clever application of bump functions will do the trick. But if anyone has an idea or a good direct proof I'd be delighted. EDIT: Answered question about topology.","['general-topology', 'analysis']"
164444,How to disprove this fallacy that derivatives of $x^2$ and $x+x+x+\dots\quad(x\text{ times})$ are not same. [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Where is the flaw in this argument of a proof that 1=2? (Derivative of repeated addition) \begin{align*}
x^2 &= \underbrace{x + x + x + \dots + x}_{x \text{ times}}, \\
\therefore \frac{\mathrm{d}}{\mathrm{d}x} (x^2)
&= \frac{\mathrm{d}}{\mathrm{d}x} (\underbrace{x + x + x + \dots + x}_{x \text{ times}}) \\
&= \underbrace{1 + 1 + 1 + \dots + 1}_{x \text{ times}} \\
&= x.
\end{align*} But we know that $$ \frac{\mathrm{d}}{\mathrm{d}x} (x^2) = 2x. $$ So what is the problem? My take is that
we cannot differentiate both sides because $\underbrace{{x+x+x+\cdots+x}}_{x \text{  times}}$ is not fixed and thus $1$ is not equal to $2$ .","['calculus', 'derivatives', 'fake-proofs']"
164456,Some case when the central limit theorem fails,"If I understand correctly, for various versions of the central limit theorems (CLT) , when applying to a sequence of random variables, each random variable is required to have finite mean and finite variance, plus some other conditions depending on the version of the CLT. Months ago, I heard of something, probably about some case when the classical CLT fails, which I haven't been able to understand. I am not sure if my following description is correct, but that is perhaps the best I can recall: if one random variable in the sequence dominates (in some sense, such as in terms of magnitude?) the other random
  variables, then the central limit theorem doesn't hold. I was wondering if someone is able to figure out what the quote is trying to say? Thanks and regards! PS: A paper named Asymptotic Distribution Theory for the Kalman Filter State Estimator was mentioned regarding the above quote. I don't quite understand the paper, so cannot figure out how it helps to clarify the quote. But I guess Section ""3.2 Remarks on Theorems and Corollaries"" on page ""1999"" might be related.",['probability-theory']
164463,$\mathbb{Z}$-Polynomials in an Enumeration Identity,"I've conjectured the following identity: For $1 \leqslant k \leqslant l \leqslant n$ and $m \in \mathbb{N}$,
\begin{align}
\sum_{1 \leqslant i_1 < \cdots < i_l \leqslant n} i_{k}^{m} = \sum_{j = 1}^{m} P_{m,j}(k) \binom{n+j}{l+m},
\end{align}
where $P_{m,j}(k)$ generates the $\mathbb{Z}$-polynomial triangle:
\begin{align}
\begin{array}{cccccc}
m / j & 1 & 2 & 3 & 4 & 5 \\
1 & k & & & & \\
2 & k & k^{2} & &  & \\
3 & k & 3k^{2} + k & k^{3} & &  \\
4 & k & 7k^{2} + 4k & 6 k^{3} + 4k^{2} + k & k^{4} & \\
5 & k & 15 k^{2} + 11 k & 25 k^{3} + 30 k^{2} + 11k & 10 k^{4} + 10 k^{3} + 5 k^{2} + k & k^{5} 
\end{array}
\quad etc
\end{align}
In particular, 
\begin{align}
P_{m,1}(k) & = k \\
P_{m,2}(k) & = (2^{m-1} - 1) k^{2} + (2^{m-1} - m) k \\
P_{m,m-1}(k) & = \sum_{j = 1}^{m-1} \binom{m}{j+1} k^{m-j} \\
P_{m,m}(k) & = k^{m}.
\end{align}
When $k = 1$, the polynomials specialize to Eulerian numbers . Summing over $j$, I conjecture
\begin{align}
\sum_{j = 1}^{m} P_{m,j}(k) = \sum_{l = 0}^{m} |s(m,l)|k^{l} = (k)_{m},
\end{align}
where $s(m,l)$ is the $(m,l)^{\text{th}}$-Stirling Number of the first kind. Are these polynomials well known?","['eulerian-numbers', 'reference-request', 'combinatorics']"
164471,Proof that Gauss-Jordan elimination works,"Gauss-Jordan elimination is a technique that can be used to calculate the inverse of matrices (if they are invertible).  It can also be used to solve simultaneous linear equations. However, after a few google searches, I have failed to find a proof that this algorithm works for all $n \times n$, invertible matrices.  How would you prove that the technique of using Gauss-Jordan elimination to calculate matrices will work for all invertible matrices of finite dimensions (we allow swapping of two rows)? Induction on $n$ is a possible idea: the base case is very clear, but how would you prove the inductive step? We are not trying to show that an answer generated using Gauss-Jordan will be correct.  We are trying to show that Gauss-Jordan can apply to all invertible matrices. Note: I realize that there is a similar question here, but this question is distinct in that it asks for a proof for invertible matrices.","['matrices', 'linear-algebra', 'inverse', 'gaussian-elimination']"
164472,Proving that sequentially compact spaces are compact.,"I remember seeing this proof somewhere (perhaps here, but I don't remember where) that goes something like this. Suppose $X$ is sequentially compact, and by contradiction suppose $\{U_n\}$ is a countable open cover with no finite subcover.  Then for any positive integer $n$, the set $\{U_i : i \le n\}$ is not an open cover, so there exists $x_n \notin \bigcup_{i \le n} U_i$.  Hence, we obtain sequence, and by sequential compactness, there exists a subsequence $x_{n_j}$ that converges to $a \in X$.  However, $ a \in U_k$ for some positive integer $k$ and by construction, $x_{n_j} \notin U_k$ if $n_j \ge k$. This is a contradiction. Doesn't this only prove every countable open cover must have a finite subcover?","['general-topology', 'compactness']"
164497,"Exact sequence in Beauville's ""Complex Algebraic Surfaces""","On page 3 of Beauville's book (Lemma I.5) he takes two curves $C$ and $C'$ in a surface $S$ an takes global sections $s\in H^0(S,\mathcal{O}_S(C))$ and $s'\in H^0(S,\mathcal{O}_S(C'))$. In a recent post, I was explained that you can take $s$ and $s'$ to be 1. Beauville then writes the sequence $0\longrightarrow\mathcal{O}_S(-C-C') \xrightarrow{(s',-s)}\mathcal{O}_S(-C)\oplus \mathcal{O}_S(-C')\xrightarrow{(s,s')}\mathcal{O}_S\longrightarrow\mathcal{O}_{C\cap C'}\longrightarrow 0.$ I assume that if $\mathcal{O}_S(-C)$ (resp. $\mathcal{O}_S(-C')$)  is generated on an open set $U_\alpha$ by $f_\alpha$ (resp. $f_\alpha'$), then it makes sense that the first map in the sequence takes $f_\alpha f_\alpha'$ to $(f_\alpha,-f_\alpha')$, but I don't see how this is consistent with the notation $(s',-s)$, especially since $s$ and $s'$ can be taken to be 1! Where am I wrong here or not understanding something correctly?",['algebraic-geometry']
164512,Why is this operator not compact?,"Let $(a_n)$ be a sequence that tends to zero and $0<a_n<1$. Why is then the mapping $$ \ell_2 \rightarrow \ell_2,\ (x_1,x_2,\ldots)\mapsto ((1-a_1)x_1,(1-a_2)x_2,\ldots)$$ not compact ? Someone said I should look at its inverse, but that didn't helpt me either...","['operator-theory', 'functional-analysis']"
164537,How to obtain the number of digits in n!?,"How to obtain the number of digits in $n!$ ? My approach : I Used Stirling's formula to find out the approximate value of  $n!$ Let the approximate value be $S$ Thus, number of digits in $\ =  \left \lfloor \log S \right \rfloor$ + 1 where $\left \lfloor . \right \rfloor$ is floor function.","['algebra-precalculus', 'number-theory']"
164541,"Finding a point having the radius, chord length and another point","Me and a friend have been trying to find a way to get the position of a second point (B on the picture) having the first point (A), the length of the chord (d) and the radius (r). It must be possible right? We know the solution will be two possible points but since it's a semicircle we also know the x coordinate of B will have to be lower than A and the y coordinate must be always greater than 0.
Think you can help? Here's a picture to illustrate the example: Thanks in advance!","['trigonometry', 'circles']"
164561,Evaluate $\int_1^\infty \cosh^{-1}(x) \ln(x^2-1) \exp \left(- \frac{x}{T} \right) dx $,"I would be interested in any clue on how to evaluate the following integral
$$\int_1^\infty \cosh^{-1}(x) \ln(x^2-1) \exp \left(- \frac{x}{T} \right) dx   $$ I have tried integration by parts but it seems to lead only to other integrals of the same form, with additional powers of $x$ in the integrand.",['integration']
164567,Find the indefinite integral of $1/(16x^2+20x+35)$,"Here is my steps of finding the integral, the result is wrong but I don't know where I made a mistake or I may used wrong method. $$
\begin{align*}
\int \frac{dx}{16x^2+20x+35}
&=\frac{1}{16}\int \frac{dx}{x^2+\frac{20}{16}x+\frac{35}{16}} \\
&=\frac{1}{16}\int \frac{dx}{x^2+\frac{20}{16}x+\frac{10}{16}+\frac{25}{16}} \\
&=\frac{1}{16}\int \frac{dx}{(x+\frac{\sqrt{10}}{4})^2+(\frac{5}{4})^2}\\
&=\frac{1}{16}\frac{4}{5}\textstyle\arctan ((x+\frac{\sqrt{10}}{4})\cdot \frac{4}{5}) \\
&=\frac{1}{20}\textstyle\arctan(\frac{4x+\sqrt{10}}{5})
\end{align*}
$$","['trigonometry', 'integration']"
164574,The Limit of a Sequence of Paths,"Given a path connected topological space $X$, consider a sequence $x_1, x_2, x_3, \dotsc$ of points in $X$ converging at some $x \in X$. For each $x_i$ and $x_{i+1}$, there exists some path $p_i$ in $X$ from $x_i$ to $x_{i+1}$. I define the following for all positive integers $i$ and $j$ such that $i + 1 < j$: $$
p_{i \to i+1} = p_i \quad\text{and}\quad p_{i \to j} = p_i \cdot p_{i+1 \to j},
$$ where $\cdot$ denotes path composition; for any paths $f, g : [0, 1] \to X$ such that $f(1) = g(0)$, $(f \cdot g) : [0, 1] \to X$ is a path such that $$
(f \cdot g)(t) =
\begin{cases}
f(2t) & 0 \leq t \leq {\textstyle\frac{1}{2}}\\
g(2t - 1) & {\textstyle\frac{1}{2}} < t \leq 1.
\end{cases}
$$ It can be seen that $p_{i \to j}$ is a path from $x_i$ to $x_j$. Consider the sequence $p_{1 \to 2}, p_{1 \to 3}, p_{1 \to 4}, \dotsc$. Visually, the successive terms of the sequence show a path stretching a bit of its end to touch the next $x_k$. Under what conditions can I say that this sequence of paths converges to a path $p$ in $X$ with the following? $$
p(1 - 2^{-k}) = x_{k+1} \quad\text{and}\quad p(1) = x.
$$ For instance, does it suffice to require that $X$ has a metric $d$, and $\lim\limits_{i \to \infty} L(p_i) = 0$, where $L(q)$ denotes the length of a path $q$? However, this would impose a metric on $X$, which is a magic bullet I'd rather not use. In fact, does the notion of path length exist? Are there further conditions I must pose on $X$ so that the following limit exists for some path $q : [0, 1] \to X$? $$
L(q) = \lim_{n\to\infty}\sum_{m=1}^n d\left(\textstyle q(\frac{m-1}{n}),q(\frac{m}{n})\right).
$$ (The following ""appendix"" may not be fully relevant but it seems interesting) Consider the function $P : [0, 1]^2 \to X$, where $$
P(t,s) =
\begin{cases}
p_k(2 - 2^k(1 - t)) & t \leq s < 1, k = \lceil-\log_2(1 - t)\rceil\\
p_k\left(2 - 2^k\left(1 - \frac{t + s}{2}\right)\right) & s \leq t < 1, k = \left\lceil-\log_2\left(1 - \frac{t + s}{2}\right)\right\rceil\\
x & t = s = 1
\end{cases}
$$ $P$ can be visualized in the graph below: Solid lines contain points in the $ts$-plane which are mapped by $P$ to the same point in $X$. If the sequence $p_{1 \to 2}, p_{1 \to 3}, p_{1 \to 4}, \dotsc$ indeed converges to some path $p$ in $X$, then we have the following: $P : [0, 1] \times [0, 1] \to X$ is a homotopy from $p_1$ to $p$. $P(1 - 2^{2 - k}, t) = p_{1 \to k}(t)$ for any integer $k \geq 2$ and $t \in [0, 1]$. However, does the converse hold? If $P$ is continuous, then does the ""limit path"" $p$ exist?","['general-topology', 'metric-spaces', 'sequences-and-series', 'limits']"
164575,the sum $\sum \limits_{n>1} f(n)/n$ over primes,"Let 
$$
f(n)=\begin{cases}-1&\text{if $n$ is a prime integer},\\
1&\text{otherwise}.
\end{cases}
$$ 
Then, does the series
$$
\sum_{n>1} f(n)/n
$$
converge or diverge?","['convergence-divergence', 'sequences-and-series']"
164576,Problem from Brezis's book (mollifiers),Any ideas on how to get started with this? Let $\rho \in L^1(\mathbb{R}^N)$ with $\int \rho=1$. Set $\rho_n(x)=n^N \rho(nx)$. Let $f \in L^p(\mathbb{R}^N)$. Show that $\rho_n \star f \to f$ in $L^p(\mathbb{R}^N)$. The proof of Theorem 4.22 would almost go through for this case. The problem is that I don't know anything about the support of the $\rho_n$'s.This seems to be crucial for the proof of Proposition 4.21 which is used to prove the theorem.,"['measure-theory', 'functional-analysis']"
164581,"Find $\lim \limits_{y\rightarrow\infty}\left (\ln^2y\,-2\int_{0}^y\frac{\ln x}{\sqrt{x^2+1}}dx\right)$","I have difficulty with this limit. Where to start? $$\lim_{y\rightarrow\infty}\left (\ln^2y\,-2\int_{0}^y\frac{\ln x}{\sqrt{x^2+1}}dx\right)$$","['integration', 'limits']"
164614,How many points of intersection?,Suppose there are $n$ points equally spaced ( i.e. the distances between two consecutive points are same) on the circumference of a circle. Now if we join each point with every other points by a straight line then how many points of intersection will be there ? I tried to find a recurrance relation. Is there a recurrance relation to solve for the number of points of intersection ?,['combinatorics']
164623,Find the value of $(a^3 + b^3 + c^3)/(abc)$ if $a/b + b/c + c/a = 1$.,"Find the value of $$\frac{a^3+b^3+c^3}{abc}\qquad\text{ if }\quad \frac ab + \frac bc + \frac ca = 1.$$ I tried using Cauchy's inequality but it was of no help. Please guide me. $a, b, c$ are real.",['algebra-precalculus']
164636,Weakly compact operators on $\ell_1$,"Is the following assertion true/known? Let $V$ be a Banach space and let $T\colon \ell_1\to V$ be a bounded linear operator. Is it true that $T$ is not weakly compact if and only if there is a complemented subspace $X$ of $\ell_1$ (thus, isomorphic to $\ell_1$) such that $T|_X\colon X\to T(X)$ is an isomorphism? Of course, the part 'only if' is trivial. I've got some evidences that it might be true, yet I am not sure one thing in my proof.","['operator-theory', 'functional-analysis', 'banach-spaces']"
164647,"codimension of ""jumping"" of the dimension of fibers","Let $f:X\rightarrow Y$ be a dominant morphism of projective (and smooth if you like) varieties over an algebraically closed field $k$ such that $n=\dim(X)=\dim(Y)$. Then $f$ is proper, so by Chevalley's upper semi-continuity theorem, $\dim(X_y)$ is upper semi-continuous on $Y$. Since $f$ is dominant, on an open subset $U\subseteq Y$, $X_y$ is 0 dimensional for all $y\in U$. My question is, can we say $Y\setminus U$ must have codimension at least 2? We can construct an example where the codimension is exactly two by taking the blowup $B$ of $\mathbb{P}^2$ at a point and looking at the natural map $B\rightarrow\mathbb{P}^2$. If we did not impose that $X$ is irreduicible this need not be true, for example $(xy)\subseteq \mathbb{P}^2$ mapping to $\mathbb{P}^1$ via projection has a one dimensional fiber above the origin. I cannot seem to find an irreducible example and am hoping the answer to the above is positive. Thanks",['algebraic-geometry']
164666,Order of integration,"I am reading a book by  L. D. Landau titled Mechanics and there is a ""changing order of the integral"" step on page 28 that I don't get: $$\int_0^a\int_0^E \left[{dx_2\over dU}-{dx_1\over dU}\right]{dUdE\over \sqrt{(a-E)(E-U)}}\\=\int_0^a\left[{dx_2\over dU}-{dx_1\over dU}\right] dU \int_U^a{dE\over \sqrt{(a-E)(E-U)}}$$ I am not very good with changing orders of integrals (or summations for that matter). Could someone please explain? (And if at all possible, offer an intuitive way of understanding it?) Thanks.","['integration', 'limits']"
164670,Gauss-Lucas Theorem (roots of derivatives),"Gauss-Lucas Theorem states:
""Let f be a polynomial and $f'$ the derivative of $f$. Then the theorem states that the $n-1$ roots of $f'$ all lie within the convex hull of the $n$ roots $\alpha_1,\ldots,\alpha_n$ of $f$."" My Question is:
Is there a theorem which states that there exists a permutation $\sigma \in S_n$ that the inner area of the polygon which edges go through the roots of $f$ 
$$\alpha_{\sigma(1)}\longrightarrow\alpha_{\sigma(2)}\longrightarrow\ldots\longrightarrow\alpha_{\sigma(n)}\longrightarrow\alpha_{\sigma(1)}$$ contains all roots of $f'$? EDIT (OB) It is not completely clear from the original question wether the OP allowed for self intersections of the polygonal curve with vertices the roots of $f$. The question that has a bounty on its head asks for a polygonal Jordan curve with vertices the roots of $f$ containing the roots of $f'$ further assuming $f$ has simple roots . Roots of $f'$ are allowed to lie on the edges of the polygonal Jordan curve. We further assume $n\geq 3$ and that the roots of $f$ are not all aligned (i.e. not all contained in a real affine line.)","['geometry', 'convex-analysis', 'calculus', 'polynomials']"
164695,Prove that $\sum_{n=1}^\infty\frac{\sin(nz)}{2^n}$ is analytic on $\{z\in\mathbb{C}:|\operatorname{Im}(z)|<\log(2)\}$,Prove that $f(z)=\sum_{n=1}^\infty\frac{\sin(nz)}{2^n}$ is analytic on $A=\{z\in\mathbb{C}:|\operatorname{Im}(z)|<\log(2)\}$ I tried expanding $\sin(nz)$ in terms of $e^{inz}$ but that did not help me unless I am doing something wrong.  I know Weierstrass's M-test comes in to play.,"['analyticity', 'complex-analysis']"
164700,"How to transform a set of 3D vectors into a 2D plane, from a view point of another 3D vector?","I googled around a bit, but usually I found overly-technical explanations, or other, more specific Stackoverflow questions on how 3D computer graphics work. I'm sure I can find enough resources for this eventually, but I figured that it's good material for this site... Lets say that I have a 3D space, with x, y and z coordinates. Then, I have a set of vectors (vertices in computer graphics, I suppose) in that space (they can be forming a cube, for example). How do I go about transforming them for rendering on a 2D plane (screen)? I need to get x and y coordinates of 2D vectors, but, they need to be dependent on a specific point in space - the camera. When I move the camera, the x and y values should change. I guess the process will go something like this: Translate the 3D vectors according to the camera's x, y and z. Rotate the 3D vectors according to the camera's theta and phi (I will need a lot of to polar coordinate system and from polar coordinate system conversions for this, but sin and cos aren't expensive, right?) x = x/z, y = y/z, for transforming into 2D, I think, not sure about this part at all, I think I saw it somewhere. Scale all vectors according to the camera's distance from the scene (or something else?) Render. I brainstormed these on the fly, there are probably a tonne of better solutions. Also, please try to keep the math simple, as I only know basic trig and calc up to the chain rule, I'm not sure what are people actually using for this. I heard something about ""rotation matrices"", what are they, exactly? (Well, I'm about to Google that now, but can't hurt me to get an answer here as well.) Also, what are the standard directions for xyz space? (Is z ""up""?)","['geometry', '3d', 'transformation']"
164709,Derivative of square root,What would be the derivative of square roots? For example if I have $2 \sqrt{x}$ or $\sqrt{x}$. I'm unsure how to find the derivative of these and include them especially in something like implicit.,"['calculus', 'derivatives']"
164719,"Prove that $\int_0^1t^{p-1}(1-t)^{q-1}\,dt=\frac{\Gamma(p)\Gamma(q)}{\Gamma(p+q)}$ for positive $p$ and $q$","I'm trying to prove that for $p,q>0$, we have $$\int_0^1t^{p-1}(1-t)^{q-1}\,dt=\frac{\Gamma(p)\Gamma(q)}{\Gamma(p+q)}.$$ The hint given suggests that we express $\Gamma(p)\Gamma(q)$ as a double integral, then do a change of variables, but I've been unable thus far to express it as a double integral. Can anyone get me started or suggest an alternate approach? Note : This wasn't actually given to me as the $\Gamma$ function, just as a function $f$ satisfying $$f(p)=\int_0^\infty e^{-t}t^{p-1}\,dt$$ for all $p>0$, but I recognized that. This is in the context of an advanced calculus practice exam.","['beta-function', 'gamma-function', 'integration']"
164721,"If $K$ is an extension field of $\mathbb{Q}$ such that $[K:\mathbb{Q}]=2$, prove that $K=\mathbb{Q}(\sqrt{d})$ for some square free integer $d$","I think I have the later parts of this proof worked out pretty well but what's really stumping me is how to go from knowing $[K:\mathbb{Q}]=2$ to knowing that $K = \mathbb{Q}[x]/a_2x^2 + a_1x + a_0$. I mean all I know from $[K:\mathbb{Q}]=2$ is that every element of $K$ can be written in the form $bk_1 + ck_2$ for $b,c\in \mathbb{Q}$.  As far as I can tell I don't yet have any theorems at my disposal that say if $[K:\mathbb{Q}]$ is finite than $K$ must be algebraic over $\mathbb{Q}$, or anything like that.  How do I go from this premise about $K$ as a 2-dimensional vector space over $\mathbb{Q}$ to knowing something about elements of $K$ as roots of polynomials in $\mathbb{Q}[x]$?  Thanks.","['abstract-algebra', 'field-theory']"
164723,Does $\lim_{h\rightarrow 0}\ [f(x+h)-f(x-h)]=0$ imply that $f$ is continuous?,"Suppose $f$ is a real function defined on $\mathbb{R}$ which satisfies 
  $$\lim_{h\rightarrow 0}\ [f(x+h)-f(x-h)]=0.$$
  Does this imply that $f$ is continuous? Source : W. Rudin, Principles of Mathematical Analysis , Chapter 4, exercise 1.","['continuity', 'examples-counterexamples', 'real-analysis']"
164737,Probability that a set of 'N' random binary strings are all at least a certain Hamming distance 'k' apart,"Imagine I have a set of $N$ binary strings of length $L$, where I generate each string randomly (say, by flipping a coin for each bit).  What is the probability that all $N$ strings are at least a Hamming distance $k$ apart? I would be happy with a good lower bound estimate on the probability that all strings are unique.  We can estimate the relative sizes of $N$, $L$, and $k$ as: $N >> L$ (by at least an order of magnitude), $5 \leq L \leq 100$, and $k < L$.","['probability', 'combinatorics']"
164744,KL divergence between Bernoulli Distribution with parameter $p$ and Gaussian Distribution,"I am trying to find the Kullback–Leibler divergence between Bernoulli Distribution on two points $T, -T$ with parameter $p$ and Gaussian Distribution with mean $\mu$ and variance $\sigma^2$. My attempt is as follows: Let
$$
b(x) = q\delta(x-T)+p\delta(x+T) \sim \text{Bernoulli}(p) \\ g(x) \sim N(\mu, \sigma^2).
$$ $$
\begin{align}
D(b||g) &= \int_{-\infty}^{\infty}b(x)\log \left( \frac{b(x)}{g(x)}\right) dx \\
&=\int_{-\infty}^{\infty}b(x)\log \left( b(x) \right) dx - \int_{-\infty}^{\infty}b(x)\log \left( g(x) \right) dx \\ 
&=A-B
\end{align}
$$ My questions are as follows: Can I use the continuous representation of Bernoulli RV with the help of $\delta(.)$ functions where $\delta(.)$ is Dirac Delta function? Does $A$ exist? Because, on the set $\mathbb{R}-\{\pm T\}$, $\log(\delta(x \mp T))$ is $-\infty$. If we cannot calculate the KLD between a continuous and a discrete random variable, what is the KLD analogue for this case? My thought was that $B$ alone can serve as a distance. For example, if we want to measure the distance of $b(x)$ from two different Gaussian distributions $g_1(x), g_2(x)$, only $B$ depends on $g_1(x)$ or $g_2(x)$, and thus can contribute to KLD.","['statistics', 'real-analysis']"
164767,"Prime number generator, how to make","Can anybody point me an algorithm to generate prime numbers, I know of a few ones (Mersenne, Euclides, etc.) but they fail to generate much primes... The objective is: 
    given a first prime, generate the 'n' next primes. But thanks for the link ;-) for example : primes( 17, 50 ) -> Generate 50 consecutive primes starting at 17 and do not fail any prime in this 50... no holes!","['prime-numbers', 'primality-test', 'algorithms', 'number-theory']"
164772,Schwarz Lemma - like exercise,"There's this exercise: let $\,f\,$ be analytic on $$D:=\{z\;\;;\;\;|z|<1\}\,\,,\,|f(z)|\leq 1\,\,,\,\,\forall\,z\in D$$  and $\,z=0\,$  a zero of order $\,m\,$ of $\,f\,$. Prove that $$\forall z\in D\,\,,\,\,|f(z)|\leq |z|^m$$ My solution: Induction on $\,m\,$: for $\,m=1\,$ this is exactly the lemma of Schwarz, thus we can assume truth for $\,k<m\,$ and prove for $\,k=m>1\,$ . Since $\,f(z)=z^mh(z)\,\,,\,h(0)\neq 0\,$ analytic in $\,D\,$ ,  put 
$$g(z):=\frac{f(z)}{z}=z^{m-1}h(z)$$ Applying the inductive hypothesis and using Schwarz lemma $\,\,(***)\,\,$ we get that 
$$|g(z)|=\left|\frac{f(z)}{z}\right|=|z|^{m-1}|h(z)|\stackrel{ind. hyp.}\leq |z|^{m-1}\Longrightarrow |f(z)|\leq |z^m|$$
and we're done... almost : we still have to prove $\,|g(z)|\leq 1\,$ for all $\,z\in D$ in order to be able to use the inductive hypothesis and this is precisely the part where I have some doubts: this can be proved as follows (all the time we work with $\,z\in D\,$): $(1)\,\,$ For $\,f(z)=z^mh(z)\,$ we apply directly Schwarz lemma and get
$$|f(z)|=|z|^m|h(z)|\leq |z|\Longrightarrow |z|^{m-1}h(z)|\leq 1$$
And since now the function $\,f_1(z)=z^{m-1}h(z)\,$ fulfills the conditions of S.L. we get $(2)\,\,$ Applying again the lemma, 
$$|f_1(z)|=|z|^{m-1}|h(z)|\leq |z|\Longrightarrow |z^{m-2}h(z)|\leq 1$$and now the function $\,f_2(z):=z^{m-2}h(z)\,$ fulfills the conditions of them  lemma so...etc. In the step$\,m-1\,$ we get 
$$|z||h(z)|\leq |z|\Longrightarrow {\color{red}{\mathbf{|h(z)|\leq 1}}}\,$$ 
and this is what allows us to use the inductive hypothesis in $\,\,(***)\,\,$ above. My question: Is there any way I can't see right now to deduce directly, or in a shorter way, that $\,|h(z)\leq 1\,$ ?",['complex-analysis']
164777,Some digit summation problems,"What is the sum of the digits of all numbers from 1 to 1000000? In general, what is the sum of all digits between 1 and N? f(n) is a function counting all the ones that show up in 1, 2, 3, ..., n. so f(1)=1, f(10)=2, f(11)=4 etc. When is the first time
  f(n)=n. So for the first question, I tried thinking about it such that between 000000 and 999999, each digit will appear the same number of times, so if I find out how many times one digit appears I can just apply that to the other 9 digits (then add 1 for the last number 1000000): (the number of times 1 digit appears)*(1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9) = ... 1 Appears once between 1 and 9
1 appears 11 times between 1 and 99
1 appears 11 * 10 + 10 = 120 times between 1 and 999
...I'm not sure how to find the pattern But firstly I'm not so sure of my approach, secondly I'm not sure about how to find how many times one particular number appears, and third if this method worked it doesn't seem very good for solving the second part of the question. Lastly, I had a similar question to the first 2 (question 3) so I just grouped it with those. I hope they are related, and if not I can make a seperate question for that one. Thanks.","['elementary-number-theory', 'puzzle', 'algebra-precalculus']"
164783,CFT via Brauer groups vs via ideles,"I am interested in the relationship between the following two versions of CFT: Version 1 : (Brauer Group Version) Let $K$ be a number field. One constructs, for every finite place $v$ of $K$, a map $inv_v:Br(K_v)\rightarrow \mathbb{Q}/\mathbb{Z}$ in a (fairly straightforward) cohomological manner. Then the short sequence:
$$1\rightarrow Br(K)\rightarrow \oplus Br(K_v)\rightarrow \mathbb{Q}/\mathbb{Z}\rightarrow 1$$ 
where $\oplus Br(K_v)\rightarrow \mathbb{Q}/\mathbb{Z}$ is given by $\sum inv_v$, is exact. Version 2 : (Idele Version) We can construct a map $$K^{\times}\backslash \mathbb{I}_K/\prod O_v^{\times}  \to Gal(K^{ab}/K),$$
where $\mathbb{I}_K$ are the ideles associated with $K$, by $$(1,...,1,\pi_v,1,...,1)\mapsto Frob_v.$$ Furthermore, this map induces an isomorphism between the profinite completion of $K^{\times}\backslash \mathbb{I}_K/\prod O_v^{\times}$ and $Gal(K^{ab}/K)$. My question is: How do these two formulations of Class Field Theory relate to one another. Does one imply the other and vice versa? How does one get from one statement to the other? I have never quite been able to square this circle in my mind, even though I've been exposed to CFT for years. Any help would be greatly appreciated.","['class-field-theory', 'algebraic-number-theory', 'number-theory']"
164786,What is the correct value of $\pi$,"I have seen that: $\pi = 22/7$ $\pi = 3.14\ldots$ $\pi = 17 - \sqrt{192}$. $22/7 \gt \pi$ $22/7 \lt\pi$ My brain storming doubt was, is A = B? Is B = C? Is C= A = B? how D and E are correct or myself is totally wrong? Please discuss. I think, if any one is wrong, then whole mathematics may be wrong, especially things which we dealt with $\pi$. These questions there from long back in my mind. I think, by your help, I can end by your solutions or reasoning. Thanks in advance.","['pi', 'geometry', 'approximation']"
