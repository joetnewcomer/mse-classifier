question_id,title,body,tags
3789529,"Method to compute $\int_{\sqrt{2}}^{2} \int_{1}^{\sqrt{2}} \frac{(\log(\frac{xy}{2}))^2 (x^2+y^2) }{(x^2-y^2)^{2}}\,dx \,dy$","Can anybody give a hint, how to compute the integral analytically $$
\int_{\sqrt{\,{2}\,}}^{2}\int_{1}^{\sqrt{\,{2}\,}}
\log^{2}\left(xy \over 2\right)\,
{x^{2} + y^{2} \over \left(\,{x^{2} - y^{2}}\,\right)^{2}}
\,\mathrm{d}x\,\mathrm{d}y.
$$ Please, I am not looking for computer assisted proofs.","['integration', 'multivariable-calculus', 'multiple-integral']"
3789543,Observation and conjecture on Lychrel numbers,"A palindromic number (also known as a numeral palindrome or a numeric palindrome) is a number that remains the same when its digits are reversed. Consider a number $n>0$ in base $b\geq2$ , where it is written in standard notation with $k+1$ digits $a_{i}$ as: $${\displaystyle n=\sum_{i=0}^{k}a_{i}b^{i}}$$ with, as usual, $0\leq a_{i}<b$ for all $i$ and $a_{k}\neq0$ . Then $n$ is palindromic if and only if $a_{i}=a_{k-i}$ for all $i$ . Zero is written $0$ in any base and is also palindromic by definition. In this context, a Lychrel number is a natural number that cannot form a palindrome through the iterative process of repeatedly reversing its digits and adding the resulting numbers. It is conjectured that $196$ and other numbers that have not yet yielded a palindrome are Lychrel numbers, but no number in base 10 has yet been proven to be Lychrel. I was curious about the sequence of ""candidate Lychrel"" numbers, which can be found at https://oeis.org/A023108 . I tried to find some kind of pattern among them, and I found the following: every number of the form $99k-2$ is a candidate Lychrel for $1<k<9$ . This “curious” fact led me to check if some similar property ocurred for higher candidate Lychrel numbers, and I have checked that every number of the form $999k-1$ is a candidate Lychrel for $1<k<10$ excepting $k=5$ , which is a palindromic number; and every number of the form $9999k$ is a candidate Lychrel for $1<k<10$ . I have not checked further, only that $99999*2+1$ is also a candidate Lychrel. Clearly, it can be made the following rough conjecture: Conjecture . Let it be some number in base $10$ of  the form $n=999...9k-m$ . Let us denote with $j$ the number of ""9"" composing the form of $n$ . Then, if $1<{k}<9$ , $j\geq2$ and $m=4-j$ , $n$ is either a palindromic number or a Lychrel number. Any guess about the relationship between this clear pattern, and the dynamic of the add-and-reverse-digits process? Any counterexample to the conjecture? Thanks in advance!","['number-theory', 'recreational-mathematics', 'palindrome']"
3789544,Find smallest positive integer $n$ such that this particular group is isomorphic to a subgroup of $S_{n} $,"This is a problem of a masters exam for which I am preparing. Find the smallest positive integer $n$ such that $\mathbb{Z}/2\mathbb{Z}\times\mathbb{Z}/2\mathbb{Z} \times\mathbb{Z}/2\mathbb{Z}$ is isomorphic to a subgroup of $S_{n}$ . The structure of $\mathbb{Z}/2\mathbb{Z}\times\mathbb{Z}/2\mathbb{Z} \times\mathbb{Z}/2\mathbb{Z}$ is easy to see. But the problem arises on how can I be sure that a particular  group of permutations like $S_{4}$ or $S_{5} $ has a subgroup of element 8 or not. Then only I can think of its structure. So, my question is how I can be sure whether $S_{n} $ has a subgroup of specific order or not?","['symmetric-groups', 'group-theory', 'abstract-algebra']"
3789580,Calculate the distance of any point on the arc from the center of circle,"This is my first time posting so I hope my formatting is correct. Consider this, I have two circles, one big one small with radius $r_1$ and $r_2$ . The borders of both circles are touching. See image: Correct me if I'm wrong, I believe the angle from the center of the big circle is $2\arcsin\left(\dfrac{r_2}{r_1-r_2}\right)$ What I am actually interested in is subtracting the smaller circle from the larger circle, making a small channel like this: Is there an expression where I can find the radius of the bigger circle to any point of the arc of the channel? For the shortest distance is easy, basically just $r_1-2r_2$ . But what about all the other points? How do I go about calculating the distance to any point on the arc of the channel ? I can approximate it from the middle and approximate triangles within small steps but if there is a mathematical expression for it, that would be great. The ideal expression would have $r_1,r_2,\theta$ Thank you","['angle', 'circles', 'geometry', 'plane-geometry']"
3789586,Relating basis vectors at different points in a small neighborhood of a point in a manifold,"I'm reading a section [Core Principles of Special and General Relativity by Luscombe] on how the derivative of a basis vector in a manifold is related to connection coefficient. Quoting (the notation $A^{\alpha}_{\beta'}$ means $\partial x^{\alpha}/\partial x^{\beta'}$ - instead of using primed and unprimed variables, we use primed/unprimed indices to distinguish different bases): Consider the total differential of a vector field $\mathbf{t}=t^{\alpha}(x^1,\ldots,x^n)\mathbf{e}_{\alpha}$ (without specifying what "" $\text{d}$ "" means): $$\text{d}\mathbf{t}=\text{d}t^{\alpha}\mathbf{e}_{\alpha}+t^{\alpha}\text{d}\mathbf{e}_{\alpha}=\bigg(\frac{\partial t^{\alpha}}{\partial x^{\beta}}\text{d}x^{\beta}\bigg)\mathbf{e}_{\alpha}+t^{\alpha}\bigg(\frac{\partial\mathbf{e}_{\alpha}}{\partial x^{\beta}}\text{d}x^{\beta}\bigg)$$ The second term involves derivatives of vectors - the very quantiuty we're trying to formulate with the covariant derivative. We expect a change $\mathbf{e}_{\beta}\to\mathbf{e}_{\beta}+\text{d}\mathbf{e}_{\beta}$ under $x^{\alpha}\to x^{\alpha}+\text{d}x^{\alpha}$ because coordinate basis vectors are tangent to coordinate curves. We know that the manifold $M$ is locally flat. Thus in a sufficiently small neighborhood $p\in M$ there is a local inertial frame, the basis vectors of which are constants ; call them $\{\mathbf{e}^0_{\beta}\}$ . The coordinate basis $\{\mathbf{e}_{\alpha}\}$ in a neighborhood of $p\in M$ can be expressed in the basis $\{\mathbf{e}^0_{\beta}\}$ , $\mathbf{e}_{\alpha}(x)=A^{\beta'}_{\alpha}(x)\mathbf{e}^0_{\beta'}$ . Differentiating this formula (the $\mathbf{e}^0_{\beta'}$ are constants), $$\partial_{\mu}\mathbf{e}_{\alpha}=(\partial_{\mu}A^{\beta'}_{\alpha})\mathbf{e}^0_{\beta'}=(\partial_{\mu}A^{\beta'}_{\alpha})A^{\rho}_{\beta'}\mathbf{e}_{\rho}$$ where we've inverted the basis transformation, $\mathbf{e}^0_{\beta'}=A^{\rho}_{\beta'}\mathbf{e}_{\rho}$ Now this ""we know that the manifold $M$ is locally flat"" doesn't seem like a good enough explanation for why basis vectors at two different points were related by the transformation law. The book covers the explicit, mathematical derivation for why basis vectors in the same tangent space but under different charts $(U,x)$ and $(U',x')$ can be related by $\mathbf{e}_{\beta'}=A^{\rho}_{\beta'}\mathbf{e}_{\rho}$ . But in the above quote, basis vectors at different points, and hence belonging to different tangent spaces have been related by the exact same formula. Can anyone help me with a proper mathematical proof on how the same transformation law comes about in this context? Without that, "" $M$ is locally flat"" is a handwavy argument. Edit: For more context, I quote the text after the above quoted paragraph: Thus there is a three-index symbol , call it $\gamma^{\rho}_{\mu\alpha}\equiv(\partial{\mu}A^{\beta'}_{\alpha})A^{\rho}_{\beta'}$ , effecting the derivative of $\mathbf{e}_{\alpha}$ along the coordinate curve $x^{\mu}$ : $$\partial_{\mu}\mathbf{e}_{\alpha}=\gamma^{\rho}_{\mu\alpha}\mathbf{e}_{\rho}$$ which we note involves all other vectors of the basis. We'll show that $\gamma^{\nu}_{\alpha\mu}=\Gamma^{\nu}_{\alpha\mu}$ , the Christoffel symbols. [footnote: Many books define the connection coefficient with the above equation] While we invoked a physical argument to get to this point (spacetime manifold is locally flat), it's not necessary to do so. We'll reach the same conclusion once we define geodesic curves on a manifold, which in turn require parallel transport and the covariant derivative. It's all connected!",['differential-geometry']
3789594,When is the convolution between a Schwartz function and a smooth function again a Schwartz function?,"Consider a distribution $u\in\mathscr{S}'(\mathbb{R}^n)$ which is given by a smooth, polynomially bounded function $u$ , i.e. \begin{align}
u(f)=\int_{\mathbb{R}^n}u(x)f(x)~d^nx.
\end{align} for all $f\in\mathscr{S}(\mathbb{R}^n)$ . Furthermore, $u$ is such that $u\ast f\in\mathscr{S}(\mathbb{R}^n)$ for all $f\in\mathscr{S}(\mathbb{R}^n)$ . Does this imply $u\in\mathscr{S}(\mathbb{R}^n)$ ? My incomplete Idea: Choose $f$ in a way to probe the approximate value of $u$ in a given point and show that this is rapidly decreasing. For the derivatives choose $\partial^\alpha f$ for $\alpha\in\mathbb{N}^n$ .","['convolution', 'functional-analysis', 'distribution-theory']"
3789612,"In a Hausdorff door space, at most one point is a limit point","I'm having some trouble proving the following: If $(X,\tau)$ is a Hausdorff door space, then at most one point $x \in X$ is a limit point of $X$ . My approach was the following: I assumed that there existed $y \in X$ such that $y$ is also a limit point of $X$ , and then prove by contradiction that if $x$ is already a limit point, then the point $y$ cannot exist. However, I'm having some trouble completing this proof. Is this the correct approach? Any tip on how to solve this?",['general-topology']
3789617,Can someone please help me explain this fallacy [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 3 years ago . Improve this question $$\Omega = \int_{-1}^1 \frac{dx}{1+x²}\ =\ -\int_{-1}^1\frac{dy}{1+y²} $$ $$ \text{ by using the transformation }\;  x= \frac{1}{y}$$ $$ \Omega = - \Omega ,\ 0\,\text{hence } \Omega =0 $$ but the integral is obviously $$\frac{π}{2} $$","['integration', 'definite-integrals', 'calculus', 'indefinite-integrals', 'riemann-integration']"
3789657,Does there Always Exist a Finer/Coarser Topology such that the space is compact?,"Sorry for the somewhat vague title. My questions are as follows: Suppose $T$ is a quasicompact space. Does there exist a finer topology on $T$ such that it becomes compact? Suppose $T$ is a Hausdorff space. Does there exist a coarser topology on $T$ such that it becomes compact? The way I see this is that quasicompact/Hausdorff is a upper/lower bound on how fine the topology can be. This bound is also tight, in the sense that if two topologies $\tau_1 \subset \tau_2$ are both compact, then $\tau_1 = \tau_2$ . So the questions ask if we can always get inside this bound from some starting point $T$ . I am not sure what the answer is. I have tried using Zorn's lemma, but quasicompactness and Haustorff properties aren't preserved at the obvious upper/lower bound of chains of topologies on a space X (made from taking union/intersection of all topologies in the chain). I have also tried to construct counterexamples, but they havn't really worked either. I suspect that my examples are all too ""nice"", but I feel there are few pointers as to what a counterexample would look like. Thanks for taking the time to read this. I would greatly appreciate any insight into this question.",['general-topology']
3789674,General coefficient of a Taylor series of $\frac{1}{e^{(e^{1-x})+\frac{x}{2}}+e^{\frac{x}{2}}}$,Is it possible to write a general Taylor coefficient of the function $$\frac{1}{e^{(e^{1-x})+\frac{x}{2}}+e^{\frac{x}{2}}}?$$ Wolfram alpha produces this nasty thing.,"['power-series', 'calculus', 'taylor-expansion', 'real-analysis']"
3789676,Derivative of Softmax loss function (with temperature T),"I am try to calculate the derivative of cross-entropy, when the softmax layer has the temperature T. That is: \begin{equation}
p_j = \frac{e^{o_j/T}}{\sum_k e^{o_k/T}}
\end{equation} This question here was answered at T=1: Derivative of Softmax loss function Now what would be the final derivative in terms of $p_i$ , $q_i$ , and T? Please see the linked question for the notations. Edit: Thanks to Alex for pointing out a typo","['machine-learning', 'derivatives']"
3789686,Exterior covariant derivative for complex associated vector bundle.,"I recently came across a problem for the extension of the covariant derivative in a associated complex vector bundle. Let $(P, M, \pi, G)$ be a smooth  bundle with connection $\omega$ and $W$ be a complex vector space of finite dimension with representation $\rho: G \rightarrow GL(W)$ . Then, the associated bundle is $(E = P \times_{\rho}W, M, \pi_{\rho})$ . The book by Loring W. Tu defines the covariant derivative only for the case where W is real, as, for $\phi \in \Omega^{k}(P, W)$ , $$D\phi_{p}(X_{0},..., X_{k}) := d\phi_{p}(X_{0}^h,..., X_{k}^h).$$ And the formula, if $\phi \in \Omega^{k}_{\rho}(P, W)$ (right invariant with respect to $\rho$ and horizontal) $$D\phi = d\phi + \omega \wedge_{\rho} \phi,$$ also for the case where $W$ is real. If we call the elements $E$ the covariant of $[p, v]$ , then, for a section $\sigma \in \Omega^{0}(U \subset M, E)$ , $\sigma(q) = [s(q), w(q)]$ for $s \in \Omega^{0}(U, P)$ and $w \in C^{\infty}(U, W)$ , the covariant derivative induced is $$D \sigma = [s, dw + \rho_{*}w].$$ However, I have seen many uses of these results where $W = \mathbb{C}$ . Are these results valid for the case where W is complex? If so, does anyone know any text that proves this equation for this case? Thanks in advance.","['principal-bundles', 'differential-geometry']"
3789696,Global stability vs Global asymptotic stability,"After trying to get my head around this for an embarrassingly long time, I think I need some help...
We defined local (lyapunov) stability and asymptotic stability the following way: An equilibrium $y^*$ of $\dot{y} = f(y)$ is called stable, if for each $\varepsilon$ -neighbourhood $B_\varepsilon (y^*)$ there exists a $\delta$ -neighbourhood $B_\delta(y^*)$ such that $$y_0 \in B_\delta(y^*) \implies y(t) \in B_\varepsilon (y^*) \forall t\geq t_0$$ asymptotically stable, if $y^*$ is stable and there exist a $\mu$ -neighbourhood $B_{\mu} (y^*)$ such that $$y_0 \in B_{\mu} (y^*) \implies \lim_{t \to \infty} y(t, y_0) = y^*$$ Ok so up to here both defintions make total sense to me. Now here comes my trouble:
Later in the lecture we define ""global stability"" just with the following sentence: ""An equilibrium is called globally stable, if it is stable for (almost) all initial conditions, not just some which are close to the equilibrium $y^*$ ."" We don't introduce global asymptotic stability at all. But doesn't this definition of global stability imply $\lim_{t\to\infty} y(t, y_0) = y^* $ for all $y_0$ ? We also use this to prove global stability once. But wouldn't this be the definition of global asymptotic stability? What is the difference between the two? We go on to Lyapunov functions and mention there that under certain conditions you get global stability while if additionally $\dot V =0$ you get global asymptotic stability. This course isn't really about stability analysis so we didn't go into depth at all, or provided any proofs but I would really like to understand the difference between global stability and global asymptotic stability. I've read everything on google and found nothing, so I probably don't see something extremely trivial. Any help is appreciated!","['stability-in-odes', 'lyapunov-functions', 'ordinary-differential-equations', 'dynamical-systems']"
3789717,How did $-4$ come in $y(t)?$,"Write down the general solution of the linear system: $$\frac{dx}{dt} = x + y \tag1$$ $$\frac{dy}{dt} = 4x − 2y.\tag 2$$ My attempt : Here i found $x(t)=c_1e^{-3t} + c_2 e^{2t}$ To find $y(t)$ we have $\frac{dy}{dt} = 4x − 2y.$ $\frac{d^2y}{dt^2} = 4\frac{dx}{dt} − 2\frac{dy}{dt}.\tag 3$ From $(1)$ and $(3)$ , we have $\frac{d^2y}{dt^2} = 4x +4y − 2\frac{dy}{dt}.\tag 5$ from $(1)$ and $(5)$ , we have $$\frac{d^2y}{dt^2} +\frac{dy}{dt} - 6y=0$$ now convert them into auxiliary equation , then we have $y(t)= c_1e^{2t} + c_2e^{-3t}$ But orginal answer given is $y(t) = −4c_1e^{−3t} + c_2e^{2t}$ My confusion is that How did that $-4$ come in $y(t)?$",['ordinary-differential-equations']
3789747,Why do simplex codes have constant weight?,"I was reading a proof in Algorithms and Computation in Mathematics, Vol 18 by Anton Betton, where in Chapter 2. Bounds and Modifications, page 84, Theorem 2.1.7 , they've explained why in a simplex code, every word has constant weight $q^{m-1}$ . Consider the matrix ∆ from the proof of 2.1.6. This time, regard ∆ as a generator matrix. ... For this, we consider the encoding map $v \rightarrow \Delta.v$ . Write $$\Delta = (u^{(0)^T}| ... | u^{(n−1)^T})$$ with $u^{(i)} \in \mathbb{F}^m_q$ . Then, using the standard bilinear form, we have for $v \in \mathbb{F}^m_q$ , $v·\Delta= (〈v,u^{(0)}〉,...,〈v,u^{(n−1)}〉)$ . Fix an element $v \in \mathbb{F}^m_q \setminus \{0\}$ . The mapping $u \mapsto〈v,u$ 〉for $u \in \mathbb{F}^m_q$ is a surjective linear form, as already pointed out in the proof of 1.6.8. It takes on each value of $\mathbb{F}_q$ exactly $q^{m−1}$ times. Thus, for exactly $q^{m−1}(q−1)$ vectors $u\in \mathbb{F}^m_q$ the value of $〈v,u〉$ is nonzero. By linearity, we have $\langle v, \lambda u \rangle = \lambda \langle v,u \rangle$ for all $\lambda \in \mathbb{F}_q$ . In particular, the value of $\langle v,u \rangle$ is either always zero or always nonzero for elements of the form $w= \lambda u$ , where $\lambda \in \mathbb{F}^*_q$ . This means that the fact that $\langle v,u \rangle$ is zero or nonzero only depends on the one-dimensional subspace containing $u \neq 0$ . Now recall that the $u^{(i)}$ form a transversal of the one-dimensional subspaces (disregarding the zero vector, which is in every subspace). This means that the products $\lambda\cdot u^{(i)}$ where $\lambda \in \mathbb{F}^*_q$ and $0≤i< \frac{q^m−1}{q−1}$ take on every nonzero vector $u \in \mathbb{F}^m_q$ exactly once. The previous remark implies that the $q^{m-1}(q−1)$ vectors $u \in \mathbb{F}^m_q$ with $\langle v,u \rangle =0$ ( $u=0$ is not one of them!)  are contained in exactly $q^{m-1}$ one-dimensional subspaces. For clarity, they have defined the matrix $\Delta$ to be the following: Let $\Delta$ be any matrix whose columns form a system of nonzero representatives of the one-dimensional sub-spaces of $\mathbb{F}^m_q$ . The dual code of a Hamming-code, i.e.the code which is generated by the matrix $\Delta$ is called an $m-th$ order q-ary simplex-code I understand that why for every $q^{m-1}(q-1)$ vectors $u \in \mathbb{F}^m_q$ , $\langle v,u \rangle$ is nonzero, and that it being zero or non zero only depends on what $u$ is. However, I can't understand why $\lambda\cdot u^{(i)}$ takes every non zero vector $u \in \mathbb{F}^m_q$ exactly once. If someone could help me, I'd really be grateful!","['finite-fields', 'coding-theory', 'linear-algebra', 'discrete-mathematics']"
3789818,Geodesics of The Tangent Bundle,"Suppose $(M,g)$ is a complete Riemannian manifold. We can endow the tangent bundle $TM$ with a natural choice of metric, the so called Sasaki metric given by: $\alpha(t)=(p(t),v(t))$ , $\beta(t)=(q(t),w(t))$ . Then define $\langle\alpha^\prime(0),\beta^\prime(0)\rangle=\langle p^\prime(0),q^\prime(0)\rangle+\langle\frac{Dv}{dt}(0),\frac{Dw}{dt}(0)\rangle$ . In other words we identify the vertical vectors at $T_{(p,v)}TM$ with $T_pM$ and the Euclidean metric given on that by $g$ . Then we pullback $g$ by $D\pi: H \to TM$ to the horizontal vectors and define $H$ and $VE$ to be orthogonal to each other. In this metric one can prove if $\gamma(t)$ is a geodesic and $v(t)$ a parallel vector field along $\gamma$ , then $(\gamma(t),v(t))$ is a geodesic in $TM$ . Now suppose $(p,v)$ and $(q,w)$ are two arbitrary points in $TM$ and $\gamma$ is a geodesic with $\gamma(0)=p, \gamma(1)=q$ . Consider $v(t),w(t)$ which are the parallel transports of $v$ and $w$ along $\gamma$ . Is it true that the curve $\delta(t)=(\gamma(t),(1-t)v(t)+tw(t))$ is a geodesic between $(p,v)$ and $(q,w)$ ? Notice that if $w$ is the parallel transport of $v$ at $t=1$ then $\delta(t)$ is a geodesic. In other words this is equivalent to say if $\delta(t)=(\gamma(t),v(t))$ is a curve in $TM$ such that $\gamma$ is a geodesic in $M$ and $\frac{D^2v}{dt^2}=0$ , then $\delta$ is a geodesic in $TM$ . Do you have any counterexample or proof?","['riemannian-geometry', 'differential-geometry']"
3789825,A growth rate principle for entire functions,"Suppose $\widehat{f}(\xi) = O(e^{-a|\xi|^p})$ as $|\xi| \rightarrow \infty$ and $p>1$ . Then, show that $f$ is entire and $$ |f(z)| \leq Be^{a|z|^q}  $$ where $p$ and $q$ are conjugate and $$\widehat{f}(\xi) = \int_{\mathbb{R}} f(x) e^{-2 \pi i x \xi} dx $$ Some background: This is problem 1, Ch.4 in Stein's complex analysis . I came across it after some preliminary reading on uncertainty principles and harmonic analysis. Edit : I originally labelled this post ""An uncertainty type principle for entire functions"". Although it doesn't appear to imply anything about the concentration of a function near a point, there is a similar theme in the sense of establishing a relationship between the growth/decay rates of a (entire) function and its Fourier transform. It should also be mentioned that as $p \rightarrow \infty$ , $\widehat{f}$ becomes compactly supported and this result implies $f$ has growth order $q \rightarrow 1^+$ , which is one direction of the Paley-Weiner theorem. Work thus far : If we define $$f_n(z) = \int_{-n}^n \widehat{f}(\xi) e^{2 \pi i z \xi} d \xi$$ then $f_n$ is holomorphic for all $n$ and the rapid decay rate of $\widehat{f}$ immediately gives us that $f_n(z)$ converges uniformly to $f(z) = \int_{\mathbb{R}} \widehat{f}(\xi)e^{2 \pi i z \xi} d \xi $ , making $f$ entire. Now, \begin{align*}
|f(z)| & \leq \left|  \int_{\mathbb{R}} \widehat{f}(\xi) e^{2 \pi i z \xi} d \xi \right| \\
& \leq \int_{\mathbb{R}} A e^{-a|\xi|^p} |e^{2 \pi i z \xi}| d \xi \\
& \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \\
\end{align*} We may select $N$ large such that $\int_{|\xi| > N} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \leq 1  $ . Then we have $$ |f(z)| \leq A \int_{-N}^N e^{-a|\xi|^p + 2\pi |z||\xi|} d \xi + 1 \leq \tilde{A} \int_{-N}^N e^{|z|^q} d \xi = A' N e^{|z|^q}  $$ where we are using Young's inequality $ |z||\xi| \leq |\xi|^p/p + |z|^q/q \leq |\xi|^p + |z|^q  $ .
The constant $\tilde{A} = A' \cdot N$ depends on $N$ (which in turn depends on $z$ ). We should be able to do better and get a global constant independent of $N$ . Edit: per the comment from user @Shalop, we can make use of ""Young's inequality with $\epsilon$ "", which appears in the appendix of Evan's PDE book. For $\epsilon > 0$ given, we may replace $|\xi|$ with $|\xi \epsilon|$ and $|z|$ with $|z/\epsilon|$ to obtain \begin{align*}
|\epsilon \xi| |\frac{z}{\epsilon}| \leq \frac{1}{p} \epsilon^p |\xi|^p + \frac{|z|^q}{\epsilon^q q} \leq \epsilon^p |\xi|^p + C(\epsilon) |z|^q \leq \frac{a}{2} |\xi|^p + C(\epsilon) |z|^q 
\end{align*} Therefore, \begin{align*}
|f(z)| & \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \\
& \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + \frac{a}{2} |\xi|^p + c|z|^q} d \xi \\
& = A e^{c|z|^q} \int_{\mathbb{R}} e^{-\frac{a}{2}|\xi|^p} d \xi \\
& = B e^{c|z|^q} \\
\end{align*}","['complex-analysis', 'fourier-analysis']"
3789827,"For $n \times n$ matrices $A$ and $B$, if $(A^i - B^i)x = 0$ for $i = 1, \dots,\ n$, does $(A^{n+1} - B^{n+1}) x = 0$?","Conjecture: Let $A,B \in \mathbb{R}^{n \times n}$ and $x \in \mathbb{R}^n \setminus \{0\}$ . If $$\left( A^{i} - B^i \right) \, x = 0, \quad \forall i \in \{ 1, \dots, n \}$$ then $$\left( A^{j} - B^{j} \right) \, x = 0, \quad \forall j \in \{ n+1, n+2, \dots \}$$ My initial goal is to prove this for $j = n+1$ , i.e., $$\left(A^{n+1} - B^{n+1}\right)\,x = 0.$$ Since $$\left(A - B\right)\,x = 0,$$ we have $$A\,x = B\,x,$$ and similarly, $$A^{i}\,x = B^{i}\,x,\quad i = 1,\ \dots,\ n.$$ So $$\left(A^{n+1} - B^{n+1}\right)\,x = A^{n+1}\,x - B^{n+1}\,x = A^{n}\,A\,x - B^{n}\,B\,x = \left(A^{n} - B^{n}\right)\,A\,x = \left(A^{n} - B^{n}\right)\,B\,x,$$ and similarly, $$\left(A^{n+1} - B^{n+1}\right)\,x = \left(A^{n+1-i} - B^{n+1-i}\right)\,A^{i}\,x = \left(A^{n+1-i} - B^{n+1-i}\right)\,B^{i}\,x,\quad i = 1,\ \dots,\ n.$$ I'm not entirely sure where to go from here.","['matrices', 'linear-algebra']"
3789830,Geometric characterization of integral ring extensions,"In commutative algebra, one usually learns about Lying Over, Incomparability, Going Up and Going Down for integral extensions. These are, in their spirit, quite geometrical statements (as is e.g. demonstrated in Gathmann's lecture notes). I'm wondering if there is any kind of converse statement: Something in the sort of ""For (sufficiently nice) rings $R \hookrightarrow R'$ that satisfy (some of) Lying Over, Incomparability, Going Up, Going Down and some property, the extension is integral.""","['integral-extensions', 'algebraic-geometry', 'commutative-algebra']"
3789884,Is $1-\cos nt \leq n(1-\cos^nt)$?,"In an exercise about characteristic functions of probability measures, once is asked to show that $$
\begin{align}
1-\operatorname{Re}(\widehat{\mu}(nt))\leq n\Big(1-\big(\operatorname{Re}(\widehat{\mu}(t))\big)^n\Big)\tag{0}\label{zero}
\end{align}
$$ where $\widehat{\mu}(t)=\int e^{itx}\,\mu(dx)$ , and $\mu$ is a Probability measure on $(\mathbb{R},\mathscr{B}(\mathbb{R}))$ . Since $\Big(\int \cos(tx)\,\mu(dx)\Big)^n\leq \int\cos^n(tx)\,\mu(x)$ ,
inequality $\eqref{zero}$ will follow immediately if the following inequality holds $$
\begin{align}
1-\cos (n\alpha) \leq n\big(1-\cos^n(\alpha)\big),\quad\forall \alpha\in[0,2\pi]\tag{1}\label{one}
\end{align}
$$ I tried induction (for n=1,2 we have equality, for n=3, $\eqref{one}$ holds) however, there does not seem the be a clear inductive proof. I tried to use mean value theorem, but again, the proof eludes me. I have check numerically (just plotting the functions on the left and right hands sides) and it seems that the statement holds. Does anybody have a hint or know of a proof (or counter example) for $\eqref{one}$ ?.","['geometric-inequalities', 'probability-theory']"
3789885,"Proving $\cos a-\cos b-\cos c\geq -\frac{3}{2}$, where $a+b+c=2\pi$ and $a,b,c>0$","I need help proving the following trig inequality: $$\cos a-\cos b-\cos c\geq -\frac{3}{2}$$ where $a+b+c=2\pi$ and $a,b,c>0$ . I've found that equality occurs when $a=\frac{4\pi}{3},b=c=\frac{\pi}{3},$ but I'm not sure how to prove it in general. I would also like to only use math covered in precalc and below, if that matters.","['trigonometry', 'inequality']"
3789958,Median Based Probability,"Most of probability theory is formulated in what I would call the ""expectation framework"". In general, we are interested in quantities involving $\mathbb{E}\left[X\right]$ where $X$ is some random variable of interest. This of course is reasonable - with the use of expectation, we can reframe probability theory into measure theory/Lebesgue theory on a space of measure one. Expectation is convenient - first and foremost it is linear, and its ability to generate norms allows us to invoke things like $\mathcal{L}^p$ and $\mathcal{L}^2$ theory, and sometimes even general Banach space theory. However, elementary statistics courses (leaning away from probability theory for a bit) often criticize the expectation for its ability to be somewhat misleading as a measure of central tendency. It (simply by definition of course) can be influenced by the presence of outliers and large observations. It fails to exist for certain distribution (heavy-tailed laws) and as a result, many useful convergence theorems available to us fail to apply for these laws. Of course, I am sure expectation has further downsides (and upsides) than I have mentioned here. Question : Is it possible to formulate a coherent notion of probability theory where all results that involve expectation are replaced with median? Has this ever been attempted? Or would such a theory be equivalent to the current standard formulation of probability theory (say, through the use of various concentration inequalities), and will I feel silly minutes after asking this?","['statistics', 'math-history', 'soft-question', 'probability-theory']"
3789967,"For $a>1$, show that $\frac{1}{1+x}-\frac{1}{1+ax} \leq \frac{\sqrt{a}-1}{\sqrt{a}+1}$, $x \geq 1$","I'm self-learning the analysis I ""by Herbert Amann"" and got stuck in this problem. It's in Chapter IV Taylor's theorem. For $a>1$ and $x\geq 1$ show that $$\frac{1}{1+x}-\frac{1}{1+ax} \leq \frac{\sqrt{a}-1}{\sqrt{a}+1}$$ This is what I've tried: Let $f(t)=\frac{1}{1+tx}$ which is convex and, $f(a) \geq f(1)+f'(1)(a-1)$ so $\frac{1}{1+x}-\frac{1}{1+ax} \leq \frac{x}{(1+x)^2}(a-1) \leq \frac{a-1}{4}$","['calculus', 'functions', 'inequality']"
3789968,What is the $p$-adic valuation of $\zeta_p-1$?,"Let $\zeta_p$ be the $p^{th}$ root of unity in $p$ -adic field. I know that $v(\zeta_p-1)=\frac{1}{p-1}$ but I couldn't prove it. I have tried in the following way: $f(x)=(x-\zeta_p)(x-\zeta_p^2) \cdots (x-\zeta_p^{p-1})=\sum_{j=0}^{p-1}x^j=1+x+\cdots+x^{p-2}+x^{p-1}=\prod_{i=1}^{p-1}(x-\zeta_p^{i}).$ Now putting $x=1$ , we get $$f(1)=(1-\zeta_p)(1-\zeta_p^2) \cdots (1-\zeta_p^{p-1}),$$ and also $f(1)=p$ .  Thus $$1-\zeta_p=\frac{f(1)}{(1-\zeta_p^2) \cdots (1-\zeta_p^{p-1})}=\frac{p}{(1-\zeta_p^2) \cdots (1-\zeta_p^{p-1})}.$$ So $v(1-\zeta_p)=v(p)-v[(1-\zeta_p^2) \cdots (1-\zeta_p^{p-1})]=1-v(1-\zeta_p^2)- \cdots-v(1-\zeta_p^{p-1})$ How to finish the proof ? Help me in the above proof ?","['number-theory', 'p-adic-number-theory']"
3789976,"If $\{x_1,x_2,\cdots,x_n\}$ is a basis, is $\{x_1+x_2,x_2+x_3,\cdots,x_n+x_1\}$ a basis too?","Let's say we have a vector space $V$ with a basis $\{x_1,x_2,\cdots,x_n\}$ then is $\{x_1+x_2,x_2+x_3,\cdots,x_{n-1}+x_n,x_n+x_1\}$ a basis too? My Answer: For n=2 clearly this is false because of the following counter example: \begin{pmatrix}
1 & 0 \\
0 & 1 
\end{pmatrix} If we apply the above to get the new set \begin{pmatrix}
1 & 1 \\
1 & 1 
\end{pmatrix} which is not linearly indepedent to form a basis. But what about $n\geq3 ?$ I believe it should work by intuition that $v_1 = x_1+x_2$ can only be formed using $x_1$ and $x_2$ and so on hence any of the vectors cannot be formed using the others by any linear combination.","['change-of-basis', 'linear-algebra']"
3790003,"Given a triangle's circumcenter, incenter, and foot of one inner bisector, construct its vertices","Wernick's list problem number 82: The goal is to construct, with a straightedge and compass only, vertexes of $\triangle ABC$ but we're only given: its circumcenter, $O$ its incenter, $I$ its foot of the inner bisector of vertex $A$ on side $BC$ , $T_a$ . I draw line $IT_a$ for this is the inner bisector. And that's kinda it. These points are very unrelated. I thought about finding the contact point of the incircle with side $BC$ but this point also has no relation with $O$ . $O$ and $H$ are isogonal conjugates but this doesn't help much","['euclidean-geometry', 'geometry', 'geometric-construction']"
3790005,Evaluate $\lim_{k \to \infty} \int_0^1 \frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx$,"I want to evaluate $$\lim_{k \to \infty} \int_{(0,1)}\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx$$ where the integral is Lebesgue-integral. Attempt: Note first that for $x \in (0,1)$ , we have $\lim_k \frac{(1-x)^k \cos(k/x)}{\sqrt{x}} = 0$ . Also, $$\left|\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}\right| \leq 1/\sqrt{x}$$ and by monotone convergence theorem $$\int_{(0,1)}1/\sqrt{x}dx = \lim_n \int_{(1/n,1)} x^{-1/2}dx = \lim_n (2-2\sqrt{1/n})=2$$ so the dominated convergence theorem allows us to interchange integral and limit and we conclude that $$\lim_{k \to \infty} \int_{(0,1)}\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx = \int_{(0,1)}0 dx = 0$$ Is this correct?","['calculus', 'lebesgue-integral', 'measure-theory', 'real-analysis']"
3790060,"Topologies and sigma-algebras as ""hypergraphs"" containing an ""edge"" having 0 endpoints","A hypergraph $H$ is a pair $H=(X,E)$ where $X$ is a set of elements called nodes and $E$ is a set of non-empty subsets of $X$ called hyperedges. I'm wondering about the motivation behind specifying that hyperedges cannot have 0 endpoints ( $\emptyset$ is never a hyperedge)? If $\emptyset$ is allowed to be a hyperedge, then things like topologies and $\sigma$ -algebras on sets become examples of hypergraphs, which makes a relaxed definition of hypergraph seem like a nice abstraction. Does allowing $\emptyset \in E$ have significant consequences?","['measure-theory', 'graph-theory', 'hypergraphs', 'general-topology', 'soft-question']"
3790073,$f$ has a pole order $n$ then there exists a positive constant $C$ such that $C|z|^{-n}\leq |f(z)|$,"Question: Suppose $f$ has a pole order $n$ , $n\in \mathbb{Z}_{>0}, $ at $z=0$ then there exists a positive constant $C$ such that $C|z|^{-n}\leq |f(z)|$ on sufficiently small punctured disk about $0$ . This is my solution so far: Since $f$ has a pole order $n$ , $f$ has Laurent expansion in the form on $\sum_{m\geq-n}c_mz^m$ for all $z$ in some punctured disk about $0$ , say on $B(0,\epsilon)- \{0\}.$ Define $g(z):=z^nf(z)$ , then naturally this can be extended into a (continuous) function on $B(0,\epsilon)$ by defining $g(0)=c_{-n}\not=0.$ Now since the absolue function is continuous from $\mathbb{C}\to \mathbb{R}$ and so $|g(z)|$ is continuous on $B(0,\epsilon).$ In particular, $|g(0)|$ = $|c_{-n}|>0.$ Then by choosing $\epsilon=\frac{1}{2}|c_{-n}|,$ we have $\exists\delta>0$ such that $|g(z)|\geq \frac{1}{2}|c_{-n}|$ on $B(0,\delta).$ Then on $B(0,\delta)-\{0\}$ , we have the required inequality by setting $C=\frac{1}{2}|c_{-n}|.$ I was wondering if there are any flaws with my solution, the hint tells me to consider removable singularity but I did not use it much and so I was wondering if there is a slicker way of doing it. Many thanks!","['complex-analysis', 'singularity']"
3790135,Asymptotic equivalence and sums,"Suppose that for every $k \geq 1$ : $$ f_k (x) \sim c_k g(x), \quad x \to \infty,$$ where $f_k(x)$ and $g(x)$ are some positive functions and the $c_k$ nonnegative constants. My question is whether for every $m \geq 1$ : $$  \sum_{k=1}^m f_k (x) \sim \sum_{k=1}^m c_k g(x), \quad x \to \infty. \label{1}\tag{1} $$ I would think so, because when considering the limit of the quotient of both sides, one could just divide by $g(x)$ . The harder question is whether then even $$ \sum_{k=1}^\infty f_k(x) \sim \sum_{k=1}^\infty c_k g(x), \quad x \to \infty. \label{2}\tag{2}$$ Here, I am not sure anymore that this is true. Does this follow from \eqref{1}? Note that $f(x) \sim g(x)$ if $f(x)/ g(x) \to 1$ as $x \to \infty$ .","['sequences-and-series', 'asymptotics', 'real-analysis']"
3790215,Prove that vectors of a real inner product space are linearly independent.,"Let $V$ be a real inner product space. Let $u, v_1, ..., v_m \in V$ such that $$\langle u, v_i \rangle > 0, \ \forall{i}$$ $$ \langle v_i, v_j \rangle \leq 0, \ \forall i \neq j.$$ Prove that vectors $v_1, ..., v_m$ are linearly independent. There is a hint which says if a linear combination of the vectors with nonnegative coefficients is equal to zero, then all the coefficients must be equal to zero. I'm not sure how to carry out this proof using the hint.","['inner-products', 'linear-algebra', 'vector-spaces']"
3790218,I've Hit a Major Snag While Writing a Paper on Deriving the Cubic Formula!,"So I've writing a paper for school on deriving the cubic formula. As of now I have written the cubic formula as a system of two equations in terms of original coefficients $a$ , $b$ , $c$ , and $d$ . The system is below: $$z=\sqrt[3]{\frac{9abc-2b^3-27a^2d}{54a^3}\pm\sqrt{\frac{4ac^3+27a^2d^2-18abcd-b^2c^2+b^3d}{108a^4}}}$$ $$x=z-\frac{\left(\frac{-b^2}{3a^2}+\frac{c}{a}\right)}{3z}-\frac{b}{3a}$$ This system is almost entirely based off the work shown in this article ( http://math.sfsu.edu/smith/Documents/Cubic&Quartic.pdf ). The article says that ""Actually, the equation for $z$ gives three complex cube roots for each of the $+$ and $–$ signs, hence six different formulas for $z$ . But when you substitute these in the equation for $y$ , at most three different $y$ values will result, and the last equation will thus give at most three distince [sic] roots $x$ ."" The mention of a $y$ -value can safely be equated to my $x$ -value since I combined the original article's two equations ( $y=z-\frac{p}{3z}$ and $x=y-\frac{b}{3a}$ into a single equation). Thus, according to the very article that this equation was formulated from, when using the formula I should get 6 $z$ -values, but upon plugging these into my second equation to solve for $x$ , I should see only 3 distinct $x$ -values. When I test this, however, with the cubic $-2x^3+3x^2-x+5=0$ , which has solutions 1.92, -0.21-1.12 $i$ , and -0.21+1.12 $i$ , I get the following: $$z_1=1.399 \therefore x_1=1.901$$ $$z_2=-0.67+1.16i \therefore x_2=-0.2+1.11i$$ $$z_3=-0.67-1.16i \therefore x_3=-0.2-1.11i$$ $$z_4=0.461 \therefore x_4=1.142$$ $$z_5=-0.23+0.4i \therefore x_5=0.18+0.24i$$ $$z_6=-0.23-0.4i \therefore x_6=0.18-0.24i$$ Note that $z_1$ , $z_2$ , and $z_3$ all came from using a $+$ sign for the $\pm$ input in the equation for $z$ (the complex solutions came from multiplying the real solution by $e^\frac{2i\pi}{3}$ and $e^\frac{4i\pi}{3}$ ). Coincidentally (or not) only these 3 $z$ -values gave correct (though somewhat off due to lazy rounding) $x$ -values. The $z$ -values derived by using a $-$ sign for the $\pm$ input ( $z_4$ , $z_5$ , and $z_6$ ), however, did not yield correct $x$ -values. More crucially, the prediction the article made that the 6 $z$ -values would collapse into only 3 $x$ -values when plugged into the second equation did not come true. This has left me with really nowhere to go. I cannot possibly justify my paper by simply stating that ""you have to only use the $+$ side of the $\pm$ sign when solving for $z$ because it just works that way."" I need some justification for this decision. Or possibly I have made some mistakes in my calculations and the article's assertion was, indeed, correct. That's what I'm hoping to learn from you guys! If you have any insight into this problem, any questions for me, or any advice, please reach out!","['cubics', 'algebra-precalculus']"
3790226,Tangent bundle $TM\to M$ is an orientable bundle iff $M$ is orientable,"This is Example 6.3 in Bott-Tu, which asserts a smooth manifold $M$ is orientable iff the tangent bundle $TM\to M$ is an orientable bundle. If $A=\{(U_\alpha,\psi_\alpha)\}$ is an atlas for $M$ , then for each $\alpha$ , there is a local trivialization $\phi_\alpha:TU_\alpha\to U_\alpha \times \Bbb R^n$ (where $n=\dim M$ ) given by $\sum_{i=1}^n a^i \dfrac{\partial }{\partial x^i}|_p$ where $\psi_\alpha=(x^1,\dots,x^n)$ . Clearly the transition function $g_{\alpha \beta}:U_\alpha\cap U_\beta \to GL_n(\Bbb R)$ equals the Jacobian $U_\alpha\cap U_\beta \to GL_n(\Bbb R)$ , $p\mapsto J(\psi_\alpha \circ \psi_\beta^{-1})(p)$ . Thus if $A$ is an oriented atlas, then the trivialization $\{(U_\alpha, \phi_\alpha)\}$ is oriented, and this proves one direction. But how does the opposite direction hold? (There is no explanation in the book)","['orientation', 'tangent-bundle', 'smooth-manifolds', 'differential-geometry']"
3790242,Probability of two fair dice rolls having a total of $7$ or $11$?,"What's the probability of getting a total of $7$ or $11$ when a pair of fair dice is tossed? I already looked it up on the internet and my answer matched the same answer on a site. However, though I am confident that my solution is right, I am curious if there's a method in which I could compute this faster since the photo below shows how time consuming that kind of approach would be. Thanks in advance.","['dice', 'probability']"
3790291,closed form expression for the summation $\sum_{i=0}^{\infty}\binom{i+k}{i}x^ii^t$,"I’m trying to find a closed form expression for this summation. $\sum_{i=0}^{\infty}\binom{i+k}{i}x^ii^t$ Where k and t are given nonnegative integers. According to ( Checking Jaynes' formula 6.108 for $\sum\limits_{m=0}^\infty{m+a \choose m} m^nx^m$ ) the answer is ${(x\frac{d}{dx})}^t\frac{1}{{(1-x)}^{k+1}}$ And based on ( What's the property of this series? Is it special? Coefficients of $\left(x\frac{d}{dx}\right)^n f(x) $ ) we can write $\sum_{i=0}^{\infty}\binom{i+k}{i}x^ii^t=\left(x\frac{d}{dx}\right)^t\frac{1}{\left(1-x\right)^{k+1}}=\sum_{r=1}^{t}{S\left(t,r\right)x^r\frac{d^r}{dx^r}\frac{1}{\left(1-x\right)^{k+1}}}
=\sum_{r=1}^{t}{S\left(t,r\right)x^r\frac{\left(k+1\right)\left(k+2\right)\ldots\left(k+r\right)}{\left(1-x\right)^{k+r+1}}}
=\frac{1}{\left(1-x\right)^{k+1}}\sum_{r=1}^{t}{(k+1)(k+2)...(k+r)\ S\left(t,r\right)\ {(\frac{x}{1-x})}^r}$ Where $S(t,r)$ is the Stirling number of the second kind. This can be written in two ways. But none of them seems simpler to me. $=\frac{1}{\left(1-x\right)^{k+1}}\sum_{r=1}^{t}{\frac{(k+r)!}{k!}\ S\left(t,r\right)\ {(\frac{x}{1-x})}^r}$ Or since it includes a falling factorial ( $\left(k+r\right)_{\bar{r}}$ ), we can write $=\frac{1}{\left(1-x\right)^{k+1}}\sum_{r=1}^{t}{\sum_{u=0}^{r}{S\left(t,r\right)\left(\frac{x}{1-x}\right)^rs\left(r,u\right)\left(k+r\right)^u}\ }$ $=\frac{1}{\left(1-x\right)^{k+1}}\sum_{r=1}^{t}{\sum_{u=1}^{r}{S\left(t,r\right)\left(\frac{x}{1-x}\right)^rs\left(r,u\right)\left(k+r\right)^u}\ }$ $=\frac{1}{\left(1-x\right)^{k+1}}\sum_{u=1}^{t}{\sum_{r=u}^{t}{S\left(t,r\right)s\left(r,u\right)\left(\frac{x}{1-x}\right)^r\left(k+r\right)^u}\ }
$ Where $s(r,u)$ is the signed Stirling number of the first kind (Remember $\sum_{r=u}^{t}{S\left(t,r\right)s\left(r,u\right)=\delta_{tu}}$ but this one is more complicated).
The question has not been solved yet (finding a closed form expression for this summation. $\sum_{i=0}^{\infty}\binom{i+k}{i}x^ii^t$ ). Can you help me? (I wrote what I've tried since it may inspire you).","['analytic-combinatorics', 'binomial-coefficients', 'sequences-and-series', 'derivatives', 'stirling-numbers']"
3790309,"How to prove that $F(x) = \int_0^x f(t)$ is differentiable at $0$. Here $f(t)$ is continuous on $[-2 , 2]$.","How to prove that $F(x) = \int_0^x f(t)$ is differentiable at $0$ .  Here $f(t)$ is continuous on $[-2 , 2]$ . My Attempt : For a positive number $e$ , we will get a $\delta > 0$ such that $ -e < f(t) - f(0) < e$ for all $t \in (-\delta , \delta).$ Now $\int_0^h (-e) < \int_0^h (f(t) - f(0)) < \int_0^h e \implies   -e < \frac{F(h) - F(0)}{h} - f(0)<  e $ for all $h \in (0 , \delta). $ So we can say $F_+'(0) = f(0)$ Now $\int_0^h (e) < \int_0^h (f(t) - f(0)) < \int_0^h -e \implies   -e < \frac{F(h) - F(0)}{h} - f(0) <  e $ for all $h \in (- \delta , 0). $ So we can say $F_-'(0) = f(0)$ $\therefore$ $F'(0) = f(0)$ Can anyone please check my attempt?","['integration', 'solution-verification', 'derivatives', 'real-analysis']"
3790342,Misleading Definitions and Unanswerable Problems in Spivak's Calculus,"Spivak's Calculus 4th edition, Chapter 3 Functions, Page 47: DEFINITION: A function is a collection of pairs of numbers with the following property: if (a,b) and (a,c) are both in the collection, then b = c; in other words, the collection must not contain two different pairs with the same first element. He continues: This is our first full-fledged definition, and illustrates the format we shall always use to define significant new concepts. These definitions are so important (at least as important as theorems) that it is essential to know when one is actually at hand, and to distinguish them from comments, motivating remarks, and casual explanations. They will be preceded by the word DEFINITION, contain the term being defined in boldface letters, and constitute a paragraph unto themselves. Ok got it. Fast forward to the problem set, I'm up to problem 25) 25) Find a function f(x) such that g(f(x)) = x for some g(x), but such that there is no function h(x) with f(h(x)) = x I asked about this on MSE (see Spivak's Calculus Chapter 3 Problem 25 ), and after much discussion came to the resolution that the problem 25 is impossible given the above definition of a function. In summary, the problem is that in order to find f(x), you need to choose f(x) to be a non-surjective function, which requires the concept of codomain. However the above definition does not include the concept of codomain, only domain and image, hence it is impossible. My question is: What was Spivak thinking (and I mean literally)? How did Spivak intend for us to solve this problem? Is it an error on his part? Or is there a way to intuitively infer from the above definition that functions must be specified a codomain (codomain, not image) in order to be defined? If I had the solutions book to Calculus 4th Edition, this would greatly help answer my question, but I can't find it anywhere for free.","['elementary-set-theory', 'definition', 'functions']"
3790348,"Proving $\int_{0}^{1}xf(x)dx \leq \frac{2}{3}\int_{0}^{1}f(x)dx$ for all concave functions $f: [0,1]\rightarrow [0,\infty)$","I'm trying to prove the inequality $$\int_{0}^{1}xf(x)dx \leq \frac{2}{3}\int_{0}^{1}f(x)dx$$ for all continuous concave functions $f: [0,1]\rightarrow [0,\infty)$ . I've been working on this for a while and would just love a hint if anyone can see something obvious that I'm missing. What I've tried is observing that $\frac{2}{3} = \int_{0}^{1}\sqrt{x}dx$ and trying to use Holder's inequality with $p=q=2$ on the integral $\int_{0}^{1}xf(x)$ but the squaring and the integral seem to be in the wrong order. I think there might be something more to this idea since that's the only way I know off the top of my head that can split an integral of a product into a product of the integral at the cost of inequality. However, I can't see how concavity comes into play. Something else I've atempted is observing that because of the concavity of $f(x)$ we have for all $x \in [0,1]$ that $$xf(x) + (1-x)f(0) \leq f(x^2 + 0 (1-x)) = f(x^2)$$ so that $$\int_{0}^{1}xf(x) + (1-x)f(0) \leq \int_{0}^{1}f(x^2) \leq f\left(\int_{0}^{1}x^2dx\right) = f(1/3)$$ where the second to last inequality is Jenson's inequality (since $f(x)$ is concave). Evaluating the first integral as much as possible gave $$\int_{0}^{1}xf(x)dx + f(0)/2 \leq f(1/3)$$ but the above result feels incorrect somehow eventhough I feel fairly confident in every step.","['integration', 'jensen-inequality', 'integral-inequality']"
3790387,Computing $\int_0^1 \frac{\arcsin \sqrt x}{x^2-x+1} dx$ [duplicate],"This question already has answers here : $\int_{0}^{1}\frac{\sin^{-1}\sqrt x}{x^2-x+1}dx$ (5 answers) Closed 3 years ago . Compute: $$\int_0^1 \frac{\arcsin \sqrt x}{x^2-x+1} dx$$ Answer: $\frac{\pi^2}{6\sqrt 3}$ My Attempt: The obvious substitution: $\arcsin \sqrt x=t$ . This transforms my integral (say $I$ ) to: $$I=\int_0^{\frac{\pi}{2}} \frac{t\cdot 2\sin t\cos t}{\sin^4-\sin^2+1}dt$$ Then the substitution $t\rightarrow \left(\frac{\pi}{2}+0\right)-t$ . This leads to the denominator remaining the same. Then, I added the ""versions"" of $I$ and on some simplifications, obtained: $$I=\frac{\pi}{4}\int_0^{\frac{\pi}{2}}\underbrace{\frac{\sin 2t}{1-\frac{\sin^2 2t}{4}}}_{f(t)}dt$$ Since $f(x)=f\left(\frac{\pi}{2}-x\right)$ we say: $$I=\frac{\pi}{2}\int_0^{\frac{\pi}{4}}\frac{\sin 2t}{1-\frac{\sin^2 2t}{4}}dt$$ Now the substitution $2t=u$ transforms it to: $$I=\frac{\pi}{4}\int_0^{\frac{\pi}{2}}\frac{\sin u}{1-\frac{\sin^2 u}{4}}du$$ Or, $$I=\pi\int_0^{\frac{\pi}{2}}\frac{\sin u}{4-\sin^2 u}du$$ Then I tried to decompose it into partial fractions and integrate them individually, by converting them in terms of $\tan \frac u2$ but the answer I'm getting doesn't match the given one. Thanks in advance!","['integration', 'calculus', 'definite-integrals']"
3790506,"A rigid bar suspended from $2$ wires, given the coordinates of the centre of the bar, find the lengths of the two wires","I'm not sure whether this is a geometry or mechanics problem, and I'm not too hot on either so either way I need help :) I think it's pure geometry. Also I am not really sure how to formulate this problem, so again, please bear with me, this is really not my area of expertise. I have a bar of fixed length B suspended from two strings, of lengths $R_1$ and $R_2$ , fixed at their other ends to two fixed points, $P_1$ , $P_2$ , which lie on a horizontal line, and are a fixed horizontal distance apart, $S$ . For convenience I've defined these fixed points as at positions $(0,0)$ and $(S, 0)$ . $R_1$ and $R_2$ are not fixed, they can be varied. I want to calculate what the lengths of the two strings, $R_1$ and $R_2$ , need to be in order for the centre of the bar to lie at some specific location, which we will call $(x,y)$ In other word I want a function $F(x,y) \implies (R_1,R_2)$ I understand that there maybe more than one solution. I have tried to solve this by looking at the formula for the circles centred on $P_1$ and $P_2$ , and $(x,y)$ of radii $R_1$ and $R_2$ and $B$ , and then attempting the solve these simultaneously; however my maths is just not up to it. I've also tried to solve this mechanically by analysis the tensions in the strings assuming the bar has some mass $M$ , and then working back form the tension to the angles the strings have to make with the bar, and then solve that lot simultaneously to find the string lengths that would give those angles; but again my maths just can't cope. Can anyone assist me please? Simple Diagram","['classical-mechanics', 'circles', 'geometry']"
3790519,"How to prove that for $a_{n+1}=\frac{a_n}{n} + \frac{n}{a_n}$ , we have $\lfloor a_n^2 \rfloor = n$?","Let $(a_n)_{n\ge 1}$ be the sequence defined as the following : $$a_1=1 ,\ a_{n+1}=\dfrac{a_n}{n} + \dfrac{n}{a_n} ,\ n\ge1$$ Show that for every $n\ge4,\ \lfloor a_n^2 \rfloor = n$ . My approach to this problem was trying induction and using the function $f_n(x)=\dfrac{x}{n} + \dfrac{n}{x}$ : Proving the base case for $n= 4$ and then by the inductive hypothesis $\lfloor a_n^2 \rfloor = n$ implies that $$\sqrt{n} \le a_n \lt \sqrt{n+1}$$ We then apply $f_n$ knowing that it is decreasing in that interval following it up with the floor function and some polishing, all leads to this inequality : $$n+1\le \lfloor a_{n+1}^2 \rfloor \le n+2$$ So I can't exactly get $n+1$ since $n+2$ is a possibility, this problem is a product of the fact that if $a\lt b$ then $\lfloor a \rfloor \le \lfloor b \rfloor$ . Any insights would be greatly appreciated! I wonder if my result is correct because it seems like the only way.","['induction', 'ceiling-and-floor-functions', 'recurrence-relations', 'sequences-and-series']"
3790521,What is the range of $\vec{z}^{ \mathrm{ T } }A\vec{z} $?,"Let A be a 3 by 3 matrix $$\begin{pmatrix}
1 & -2  & -1\\
-2 & 1 & 1 \\
-1 & 1 & 4
\end{pmatrix}$$ Then we have a real-number vector $\vec{ z }= \left(
  \begin{array}{c}
    z_1 \\
    z_2 \\
    z_3
  \end{array}
\right)$ such that $$\vec{z}^{ \mathrm{ T } }\vec{z} = 1$$ $$z_1+z_2+z_3=1$$ What is the range of $\vec{z}^{ \mathrm{ T } }A\vec{z} $ ? I have found that $A$ 's eigenvalues are -1,2, and 5 and eigenvectors are $\left(
  \begin{array}{c}
    1 \\
    1 \\
    0
  \end{array}
\right)$$\left(
  \begin{array}{c}
    1 \\
    -1 \\
    1
  \end{array}
\right)$$\left(
  \begin{array}{c}
    -1 \\
    1 \\
    2
  \end{array}
\right)$ for each. Can anyone help me?","['optimization', 'qcqp', 'linear-algebra', 'non-convex-optimization']"
3790530,Non-trivial semidirect product $(\mathbb Z_2 \oplus \mathbb Z_2 \oplus\mathbb Z_2) \rtimes_\varphi \mathbb Z_3 \cong A_4 \oplus \mathbb Z_2$,"Claim: Non-trivial semidirect product $(\mathbb Z_2 \oplus \mathbb Z_2 \oplus\mathbb Z_2) \rtimes_\varphi \mathbb Z_3 \cong A_4 \oplus \mathbb Z_2$ . I'm classifying groups of order $24$ , and this is the case when $\mathbb Z_2 \oplus \mathbb Z_2 \oplus\mathbb Z_2$ is the Sylow- $2$ subgroup and $\mathbb Z_3$ acts non-trivially on it, which yields a homomorphism $\varphi: \mathbb Z_3 \to \text{Aut}(\mathbb Z_2 \oplus \mathbb Z_2 \oplus\mathbb Z_2) = \text{GL}_3(\mathbb F_2)$ . Let $A = \varphi(\bar{1})$ .
It is of order $3$ in $\text{GL}_3(\mathbb F_2)$ with minimal polynomial $x^2+x+1=0$ (wrong. see the answer by Derek Holt). Some suggest that $A$ can be quasi-diagonalized to $\left(\begin{smallmatrix} 1 & 0 & 0 \\0 & 1 & 1 \\ 0 & 0 & 1\end{smallmatrix}\right)$ , so for non-trivial $\varphi$ , we have $(\mathbb Z_2 \oplus \mathbb Z_2 \oplus\mathbb Z_2) \rtimes_\varphi \mathbb Z_3 \cong ((\mathbb Z_2 \oplus \mathbb Z_2) \rtimes \mathbb Z_3) \oplus \mathbb Z_2 \cong A_4 \oplus \mathbb Z_2$ . Such diagonalization method works well for groups of order $18$ .
However, Jordan normal form only works in algebraically closed field, and $\mathbb F_2$ is not algebraically closed.
Especially, $x^2+x+1=0$ has no root in $\mathbb F_2$ . So is this diagonalization method correct?
And if not, How can we prove the claim rigorously? Thanks for your time and effort.","['finite-groups', 'semidirect-product', 'abstract-algebra', 'sylow-theory', 'group-theory']"
3790537,Find the minimum value of $x_1^2+x_2^2+x_3^2+x_4^2$ subject to $x_1+x_2+x_3+x_4=a$ and $x_1-x_2+x_3-x_4=b$.,"Question: Find the minimum value of $x_1^2+x_2^2+x_3^2+x_4^2$ subject to $x_1+x_2+x_3+x_4=a$ and $x_1-x_2+x_3-x_4=b$ . My attempt: It can be easily seen that $x_1+x_3=\frac{a+b}{2}$ and $x_2+x_4=\frac{a-b}{2}$ . Further, the expression $[x_1^2+x_2^2+x_3^2+x_4^2]$ can be written as $[(x_1+x_3)^2+(x_2+x_4)^2-2(x_1x_3+x_2x_4)].$ I'm having trouble eliminating $(x_1x_3+x_2x_4)$ from this expression. Failing to make any sense out of this, I manipulated the existing expressions to deduce $$x_1x_2+x_1x_4+x_2x_3+x_3x_4=\frac{a^2-b^2}{4}$$ and $$(x_1^2+x_3^2)-(x_2^2+x_4^2)+2(x_1x_3-x_2x_4)=a\cdot b$$ Beyond this, I cannot make sense of the expressions anymore. I have no idea how to proceed with simplifying the expressions further, and would appreciate hints in the same direction.","['inequality', 'maxima-minima', 'cauchy-schwarz-inequality', 'optimization', 'algebra-precalculus']"
3790569,How can I show $\sum_{k=1}^{\infty}\frac{\sin{kx}}{k}=\frac{\pi-x}{2}$?,"I'm trying to show that $$\sum_{k=1}^{\infty}\frac{\sin{kx}}{k}=\frac{\pi-x}{2}$$ using the Taylor series. I tried to do it by first expanding a general formula $$f(g(x)) = f(g(a)) + xg'(a)f'(g(a)) +\frac{1}{2}x^2(g'(a)^2f''(g(a)+ g''(a) f'(g(a))) + HOT $$ Taking $ f(x) = \sin x$ and $ g(x) = kx$ and expanding around a=0, $ \sin(kx) = kx - \frac{(kx)^3}{3!} + \frac{(kx)^5}{5!}..$ Now, from here is there any way I could arrive at the formula in question?","['summation', 'functions', 'taylor-expansion', 'proof-writing']"
3790571,Infinite positive integer sequence with distinctive sum of digits,"I am looking at this problem. Interestingly most problems on that site has solutions except this one, thus I am asking here. https://www.komal.hu/feladat?a=feladat&f=A728&l=en Essentially, for question (a), we are asked to construct an infinite positive integer sequence $\{ a_i \}$ such that $a_{i+1} \leq 2a_i$ , and the sums of decimal digits of each item in the integer sequence are distinct.  For question (b), we are ask to prove if this is possible for binary digits . I am not even sure if question (a) is feasible at all. We will probably want to guarantee that the sum of digits is ascending as well, because otherwise we will run of of numbers eventually. Since if we ever had digit $9$ as the last digit, say $99$ , then from 99 to $2*99$ , there is no number with sum of digits greater than $18$ . But it seems like I will always hit a number with last digit = 9 however I construct my series","['contest-math', 'elementary-number-theory', 'sequences-and-series']"
3790625,Any diffeomorphism can be locally factorised with several primitive diffeomorphisms.,"I ask in this question how to solve an exercise of the text Analysis on Manifolds by James Munkres: the exercise consist to prove a theorem about diffeomorphism with more restrictive conditions. Since the solution I gave is similar to the proof of the theorem that Munkres gave for sake of completenes I put it here but if you want you can directely read my solution and when I refer to Munkres's proof you can see the step I use because I indicate it explicitely In text Analysis on Manifolds by James Munkres there is the following definition. So Munkres states that any diffeomorphism can be locally factorised with several primitive diffeomorphims so that he claims that the following theorem holds. Well Munkres prove it in four sep. So in the first step he proves that any linear transfomation is a diffeomorphism that could be factorised locally with severl primitive diffeomorphisms as you can check (if you like) to follow. Then in the second step he proves that any traslation is a diffeomorphism that could be factorised locally with two primitive diffeomorphisms as you can check (if you like) to follow. Then in the third step he proves that the theorem holds in the case where $g(0)=0$ and $Dg(0)=I_n$ as you can check (if you like) to follow. Finally in the four step he proves the general case using the preceding results. However then as exercise Munkres ask to show that the preceding theorem holds with more restrictive definition of diffeomorphism that is he ask to prove the following statement. So unfortunately I don't be able to use the Munkres's hit (are you able to do it?) but it seems I found the following alternative solution. First of all we observe that any linear transmormation could be factorised with serveral primitive diffeomorphisms: indeed as you can check the elementary row operation of type $2$ and $3$ (for datail see the step $1$ of the preceding theorem) modify only the $i$ -th row of a matirx and the elements of the $i$ -th row of a matrix are the $i$ -th components of the image of the vector of a base. Then if $t$ is a traslation of length and direction $\pmb c:=(c_1,...,c_n)$ then for any $i=1,...,n$ we can define the primitive diffeomorphism $$
t_i(x):=(x_1,..,x_i+c_i,...,x_n)
$$ and observe that $$
t(x)=x+c_1\cdot e_1+c_2\cdot e_2+...+c_n\cdot e_n=
\\
=\Biggl(\Big(...\big((x+c_1\cdot e_1)+c_2\cdot e_2\big)+...\Big)+c_n\cdot e_n\Biggl)=\Biggl(\Big(...\big(t_1(x)+c_2\cdot e_2\big)+...\Big)+c_n\cdot e_n\Biggl)=\Biggl(\Big(...\big(t_2(t_1(x))\big)+...\Big)+c_n\cdot e_n\Biggl)=
\\
=...=t_n\Big(...\big(t_2(t_1(x)\big)...\Big)=(t_n\,\circ...\circ\,t_1)(x)
$$ so that any traslation could be factorised with serveral primitive diffeomorphisms. Now as Munkres did we consider the special case where $a=0$ , $g(0)=0$ and $Dg(0)=I_n$ . So first we define the function $h_1A\rightarrow\Bbb R^n$ through the condition $$
h_1(x):=\big(g_1(x),x_2,...,x_n\big)
$$ and we observe that if $g_1(0)=0$ and $Dg_1=e_1$ then $h_1(0)=0$ and $Dh_1(0)=I_n$ and so it follows form the inverse function theorem that $h_1$ is a diffeomorphism ( clearly it is primitive! ) of a open neighborhood $V_0$ of $0$ with an open set $V_1$ that contains $h_1(0)=0$ . So now we define the function $h_2:V_1\rightarrow\Bbb R^n$ through the condition $$
h_2(y):=\Big(y_1,\big(g_2\,\circ\,h_1^{-1}\big)(y),y_2,...,y_n\Big)
$$ for any $y\in V_1$ and we observe that if $g_2(0)=0$ and $Dg_2(0)=e_2$ then $g\big(h^{-1}_1(0)\big)=0$ and $Dg_2\big(h^{-1}_1(0)\big)=Dg_2\big(h^{-1}_1(0)\big)\cdot Dh^{-1}_1(0)=Dg_2(0)\cdot\big(Dh_1(0)\big)^{-1}=e_2\cdot I_n=e_2$ and so $h_2(0)=0$ and $D h_2(0)=I_n$ thus it follows form the inverse function theorem that $h_2$ is a diffeomorphism ( clearly it is primitive! ) of a open neighborhood $U_1$ of $0$ with an open set $U_2$ that contains $h_2(0)=0$ . So the sets $$
W_0:=h^{-1}_1[U_1\cap V_1], W_1:=(U_1\cap V_1)\,\,\,\text{and}\,\,\,W_2:=h_2[U_1\cap V_1]
$$ are open neighborhoods of $0$ and the function $(h_2|_{W_1}\,\circ\,h_1|_{W_0})$ is a diffeomorphism from $W_0$ to $W_2$ such that $$
(h_2|_{W_1}\,\circ\,h_1|_{W_0})(x):=h_2(h_1(x))=h_2\big((g_1(x),x_2,...,x_n)\big)=\Big(g_1(x),\big(g_2\,\circ\,h^{-1}_1\big)\big((g_1(x),x_2,...,x_n)\big),x_3,...,x_n\Big)=\Big(g_1(x),\big(g_2\,\circ\,h^{-1}_1\big)\big(h_1(x))\big),x_3,...,x_n\Big)=\Big(g_1(x),g_2\big(h^{-1}_1(h_1(x))\big),x_3,...,x_n\Big)=\big(g_1(x),g_2(x),x_3,...,x_n\big)
$$ for any $x\in W_0$ . So for $i<n$ we assume that $V_0,V_2,...,V_i$ is a collection of open neighborhoods of $0$ for which exist a sequence of primitive diffeomorphisms $h_1,...,h_i$ there defined such that $$
h_1(0)=h_2(0)=...=h_i(0)=0\,\,\,\text{and}\,\,\,Dh_1(0)=Dh_2(0)=...=Dh_i(0)=I_n
$$ and moreover we suppose that $$
\big(h_i\,\circ...\circ\,h_2\,\circ\,h_1\big)(x)=\big(g_1(x),g_2(x),...,g_i(x),x_{i+1},...,x_n\big)
$$ for any $x\in V_0$ . So we define the function $h_{i+1}:V_i\rightarrow\Bbb R^n$ through the condition $$
h_{i+1}(y):=\Big(y_1,...,y_i,\big(g_{i+1}\,\circ\,h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\big)(y),y_{i+2},...,y_n\Big)
$$ for any $y\in V_i$ and so we observe that if by assumption $g_{i+1}(0)=0$ , $Dg_{i+1}(0)=e_{i+1}$ and if by the inductive hypothesis $h_1^{-1}(0)=h_2^{-1}(0)=...=h_i^{-1}(0)=0$ and $\big(Dh_1(0)\big)^{-1}=\big(Dh_2(0)\big)^{-1}=...=\big(Dh_i(0)\big)^{-1}=I_n$ then $$
(g_{i+1}\,\circ\,h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\big)(0)=0
$$ and $$
D\big(g_{i+1}\,\circ\,h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\big)(0)=Dg_{i+1}(0)\cdot Dh_1^{-1}(0)\cdot Dh_2^{-1}(0)\cdot...\cdot Dh_i^{-1}(0)=e_{i+1}\cdot I_n\cdot I_n\cdot...\cdot I_n=e_{i+1}
$$ so that $h_{i+1}(0)=0$ and $Dh_{i+1}(0)=I_n$ and so it follows form the inverse function theorem that $h_{i+1}$ is a diffeomorphism ( clearly it is primitive! ) of a open neighborhood $
U_i$ of $0$ with an open set $U_{i+1}$ that contains $h_{i+1}(0)=0$ . So the sets $$
W_0:=h^{-1}_1\Big[h^{-1}_2\big[...[h^{-1}_i[U_i\cap V_i]...\big]\Big],\,W_1:=h^{-1}_2\big[...[h^{-1}_i[U_i\cap V_i]...\big],\,...,
\\
W_{i-1}:=h^{-1}_i[U_i\cap V_i],\,W_i:=U_i\cap V_i\,\,\,\text{and}\,\,\,W_{i+1}:=h_{i+1}[U_i\cap V_i]
$$ are open neighborhoods of $0$ and the function $(h_{i+1}|_{W_i}\,\circ\,h_i|_{W_{i-1}}\,\circ\,...\circ\,h_2|_{W_1}\,\circ\,h_1|_{W_0})$ is a diffeomorphism of $W_0$ in $W_{i+1}$ such that $$
\big(h_{i+1}|_{W_i}\,\circ\,h_i|_{W_{i-1}}\,\circ\,...\circ\,h_2|_{W_1}\,\circ\,h_1|_{W_0}\big)(x)=\big(h_{i+1}\,\circ\,h_i\,\circ\,...\circ\,h_2\,\circ\,h_1\big)(x)=\Big(h_{i+1}\,\circ\big(h_i\,\circ\,...\circ\,h_2\,\circ\,h_1\big)\Big)(x)=h_{i+1}\Big(\big(h_i\,\circ\,...\circ\,h_2\,\circ\,h_1\big)(x)\Big)=h_{i+1}\Big(\big(g_1(x),g_2(x),...,g_i(x),x_{i+1},...,x_n\big)\Big)=
\\
=\Biggl(g_1(x),g_2(x),...,g_i(x),\Big(g_{i+1}\,\circ\,h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\Big)\Big(\big(g_1(x),g_2(x),...,g_i(x),x_{i+1},...,x_n\big)\Big),x_{i+2},...,x_n\Biggl)=\Biggl(g_1(x),g_2(x),...,g_i(x),\Big(g_{i+1}\,\circ\,h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\Big)\Big(\big(h_i\,\circ...\circ\,h_2\,\circ\,h_1\big)(x)\Big),x_{i+2},...,x_n\Biggl)=
\\
=\Biggl(g_1(x),g_2(x),...,g_i(x),\Big(g_{i+1}\,\circ\big(h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\big)\Big)\Big(\big(h_i\,\circ...\circ\,h_2\,\circ\,h_1\big)(x)\Big),x_{i+2},...,x_n\Biggl)=
\\
=\Biggl(g_1(x),g_2(x),...,g_i(x),g_{i+1}\biggl(\Big(h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\Big)\Big(\big(h_i\,\circ...\circ\,h_2\,\circ\,h_1\big)(x)\Big)\biggl),x_{i+2},...,x_n\Biggl)=
\\
=\Biggl(g_1(x),g_2(x),...,g_i(x),g_{i+1}\biggl(\Big(\big(h_1^{-1}\,\circ\,h_2^{-1}\,\circ...\circ\,h_i^{-1}\big)\circ\big(h_i\,\circ...\circ\,h_2\,\circ\,h_1\big)\Big)(x)\biggl),x_{i+2},...,x_n\Biggl)=
\\
=\Big(g_1(x),g_2(x),...,g_i(x),g_{i+1}(x),x_{i+2},...,x_n\Big)
$$ for any $x\in W_0$ . So finally by finite induction theorem we conclude that there exist a sequence $V_0,V_1,...,V_{n-1}$ of length $n$ for which exist a sequence $h_1,...,h_n$ of primitive diffeomorphism there defined,combinable and such that $g|_{V_0}\equiv h_n\,\circ...\circ\,h_2\,\circ\,h_1$ . Finally with the same arguments that Munkres did in the step $4$ we conclude that the theorem holds. So I ask if the solution I gave to exercise is correct and if not I ask to solve it. So could someone help me, please?","['diffeomorphism', 'alternative-proof', 'multivariable-calculus', 'solution-verification', 'differential-geometry']"
3790629,Matrix Equation $A^* B A = C $ solved for $A$,"Is there a standardized way to solve $A^* B A = C $ for $A$ if $A$ is a complex and square matrice, and $B$ and $C$ are real-valued and square matrices. $A^*$ is the conjugate transpose of $A$ . Is there a special name for such kinds of equations? Edit: Information that might help: The Matrix B and C are conjugate transpose auto-correlation matrices $B^* = b \cdot b^*  \\
C^* = c \cdot c^*
$","['matrices', 'matrix-equations', 'linear-algebra']"
3790655,Can one prove that there are exactly $n$ arbitrary constants exist in the solution of a $n$th order differential equation?,"I've heard that an $n$ -th order differential equation will always have exactly $n$ arbitrary constants in its solution; that is, if $y$ satisfies the differential equation $f(y(t),y^{(1)}(t),\cdots, y^{(n)}(t), t) = 0$ then it will always be of the form $y(t) = g(t; C_1, \cdots, C_n)$ where $C_1, \cdots C_n \in \mathbb{C}$ . This makes intuitive sense, as one might have to integrate $n$ times to get to the solution, which would mean $n$ constants of integration. It can even be proven quite easily in the constant-coefficient case; given that $\sum _{i = 1} ^{n} a_i \hat{D}^i y(t) = f_0(t)$ , one can factor the differential operator $\sum _{i = 1} ^{n} a_i \hat{D}^i$ that acts on $y$ into $n$ first order derivatives according to solutions to the characteristic equation, which are all integrated to create $n$ arbitrary constants. However, I am not satisfied with this argument. Consider, for example, the following second-order differential equation: \begin{align} \sin(y'') + (y')^2 = y\cos(t^2y''). \end{align} I cannot imagine how one would be able to apply either of the previous arguments (factorisation of the differential operator or $n$ integrations) to show that this has exactly two arbitrary constants. And even if one could show that there are two integrations in this case, the general case is still uncertain: Are there always going to be $n$ arbitrary constants? Is there perhaps a rigorous proof of this?",['ordinary-differential-equations']
3790675,Necessary and sufficient condition for weak convergence of gamma distribution,"Let $(X_n)_n$ be a sequence of random variable such that $f_{X_n}(x)=\frac{1}{\Gamma(\alpha_n)}\lambda_n^{\alpha_n}x^{\alpha_n-1}e^{-\lambda_nx}1_{]0,+\infty[}(x),$ where $\alpha_n>0,\lambda_n>0.$ Suppose that $\alpha_n=1,\forall n \in \mathbb{N}.$ Find a necessary and sufficient condition on $(\lambda_n)_n$ such that $(X_n)_n$ converges in distribution. More generally, find a necessary and sufficient condition on $\alpha_n,\lambda_n$ so that $(X_n)_n$ converges in distribution. The first part is easy, it converges in distribution if and only if $0<\liminf_n\lambda_n=\limsup_n\lambda_n$ . Concerning part 2), is it true that a condition of weak convergence is the convergence of $(\alpha_n)$ and $(\lambda_n)$ ?","['characteristic-functions', 'measure-theory', 'probability-theory', 'weak-convergence']"
3790685,"Prove that $F(x)=\int_{x_{1}^{0}}^{x_1}\cdots \int_{x_{n}^{0}}^{x_n} f(y) \, dy_1 \cdots dy_n$ is continuous","Let $\Omega$ be a open subset of $\mathbb{R}^{n}$ , $f \in L_{\operatorname{loc}}^{1}(\Omega)$ and $x^0=(x_{1}^{0},\dots,x_{n}^{0})$ an arbitrary point of $\Omega$ . Define $$F(x)=\int_{x_{1}^{0}}^{x_1}\cdots \int_{x_{n}^{0}}^{x_n} f(y) \, dy_1 \cdots dy_n.$$ My question: How to prove that $F$ is a continuous function in a sufficiently small neighborhood of $x^0$ ? I started trying to prove this statement in the case $\Omega=\mathbb{R}$ . So, let $x_0 \in \mathbb{R}$ and $(x_n) \subset \mathbb{R}$ such that $x_n \rightarrow  x_0$ in $\mathbb{R}$ . Let $M>0$ such that $-M<x_n<M$ and $-M<x_1^0<M$ for all $n \in \mathbb{N}$ . Then, for $x^0=x_{0}^{1}$ $$F(x_n)=\int_{x_1^0}^{x_n}f(y)dy=\int_{\mathbb{R}} 1_{(x_1^0,x_n)}(y)f(y)\,dy. \tag{*}$$ Then, define $g_n(y)=1_{(x_1^0,x_n)}(y)f(y)$ . We have that $|g_n(y)|\leq 1_{(-M,M)}|f(y)|=g(y)$ and $g \in L^1(\mathbb{R})$ . If we prove that $$1_{(x_1^0,x_n)} \rightarrow 1_{(x_1^0,x_0)} \hbox{ a.e. in } \mathbb{R},$$ the result follows from the Dominated Convergence Theorem. (This is also a point that I have not been able to prove.) It's just weird to write (*) this because it can happen $x_{n_0-1}<x_1^0$ and $x_{n_0}>x_1^0$ for some $n_0 \in \mathbb{N}$ . PS: This question comes from Corollary 1, page 263 in Trèves book Topological Vector Spaces, Distributions and Kernels.","['measure-theory', 'lebesgue-integral', 'real-analysis', 'continuity', 'functional-analysis']"
3790707,Can anyone prove that gamma function is complex for complex inputs?,"I am learning about gamma function and just got a doubt that how can I prove that gamma function gives out a complex number when taken complex numbers as inputs and that no real number would be obtained when complex numbers are taken as inputs. I am trying to prove this,but I don't think so that I have enough information of gamma function to prove that. Thanks in advance","['complex-analysis', 'number-theory', 'complex-integration', 'gamma-function']"
3790745,Why negative and positive degree of cosine function is the same? [duplicate],"This question already has answers here : Why is cos -x equal to cos x? (4 answers) Closed 3 years ago . I calculated $\cos(30^{\circ})$ and it is $\frac{\sqrt(3)}{2}$ . I calculated $\cos(-30^{\circ})$ and it is $\frac{\sqrt(3)}{2}$ . And, I don't know why? Can you explain me simply? I think that figures will be very much helpful.","['algebra-precalculus', 'trigonometry']"
3790773,Combining Cayley transform and Fourier series,"If one has a function $F(x)$ defined on the real line ( $x \in \mathbb{R}$ ) then one can study it by means of its Fourier transform. Because $\mathbb{R}$ is not compact one has a Fourier integral rather than a Fourier series (assuming $F$ is sufficiently nice that it can be expressed as such). However $\mathbb{R}$ can be mapped by the Cayley transform to the unit circle $C: x \mapsto \frac{i-x}{i+x}$ and so composing $F$ with the Cayley transform one can define $F$ on the unit circle by $F \circ C^{-1}$ . One then can compute Fourier coefficients $$a_n = \frac{1}{2\pi} \int_{\mathbb{T}} F \circ C^{-1}(e^{i\theta}) e^{-in\theta} \, d\theta = \frac{1}{\pi} \int_{\mathbb{R}} F(x) \left( \frac{i+x}{i-x} \right)^n \frac{1}{1+x^2} \, dx $$ $F \circ C^{-1}$ is of course not defined at $-1$ but $\{ -1 \}$ is a set of measure zero and so we could let $F \circ C^{-1}$ take some arbitrary value at this point. If $F$ is continuously differentiable, and if $F(\infty) = F(-\infty)$ and $F^\prime(\infty) = F^\prime(-\infty)$ then it would seem the Fourier series of $F \circ C^{-1}$ converges pointwise uniformly on the circle and so the series $$\sum_{n \in \mathbb{Z}} a_n \left( \frac{i-x}{i+x} \right)^n$$ should converge pointwise uniformly to $F(x)$ on $\mathbb{R}$ . Is this analysis correct and has this approach ever been studied before?","['fourier-series', 'fourier-analysis', 'real-analysis']"
3790775,Maximizing $\sum_{r=1}^n \sum_{m=1}^n s_rs_m \cos \frac{2\pi (r - m)}{n}$,"For a real $s \geq 1$ and an integer $n > 1$ , define real $s_r$ in $0 \leq s_r \leq s$ for $1 \leq r \leq n$ . Find the maximum value of the sum $$S = \sum_{r=1}^n \sum_{m=1}^n s_rs_m \cos \frac{2\pi (r - m)}{n}$$ It may be worth noting that there is a recurrance relation, which helps slightly. Defining $$S(t) = \sum_{r=1}^t \sum_{m=1}^t s_rs_m\cos\frac{2\pi(r-m)}n,$$ we obtain that $$S(t+1) = S(t) + s_{t+1}^2 + 2s_{t+1} \sum_{m=1}^t s_r\cos\frac{2\pi(t+1-m)}n.$$ In the special case that each $s_r = s$ , I found that the difference $S(t+1) - S(t) < 0$ when $$s^2\left(1 + 2\sum_{m=1}^t \cos\frac{2\pi (t+1-m)}n \right) \leq 0,$$ or when $$\sum_{m=1}^t \cos\frac{2\pi (t+1-m)}n = \sum_{m=1}^t \cos\frac{2\pi m}n \leq -\frac12,$$ which through a quick python program and some experimental values, I've found to hold true (without proof) when $\lceil n/2 \rceil < t \leq n$ . From this, I'm pretty sure the maximal sum $S$ when each $s_r \in \{s,0\}$ occurs when $$s_r = \begin{cases}
s & 1 \leq r \leq \lceil n/2 \rceil, \\
0 & \text{otherwise}.
\end{cases}$$ In the general case, $S(t+1) - S(t) < 0$ would occur when $$\sum_{m=1}^t s_m\cos\frac{2\pi(t-m)}n < -\frac{s_{t+1}}2,$$ however this sum is trickier to bound due to the weights attached to the cosine sum. Edit : Alright, I've tried some of the suggestions, particularly the one by dezdichado, which suggested $$S = \left( \sum_{r=1}^n s_r \cos\frac{2\pi r}n \right)^2 + \left( \sum_{r=1}^n s_r \sin\frac{2\pi r}n \right)^2, \tag{a}$$ which makes the problem, interestingly, about attempting to maximize the magnitude of the sum of multiples of $n$ th roots of unity: $$S = \left| \sum_{r=1}^n s_r e^{2\pi i r/n} \right|^2, \tag{b}$$ where each $0 \leq s_r \leq s$ , for some real $s \geq 1$ . However, trying to bound the sum in the form (a) is proving troublesome, especially since there are two different sums. I have a feeling there is some way to bound $S$ in the form (b), but I don't really see anyway to do it. Kinda given up on the problem, so any hints and solutions welcome!","['optimization', 'trigonometry', 'summation']"
3790786,"Let $A=\{1,2,3,...,9\}$ and $f:A \rightarrow A$ is a bijection such that $(fofofo\cdots n$ times) $=f$ but others are not identical to $f$","Let $\mathrm{A}=\{1,2,3,...,9\}$ and $f:\mathrm{A \rightarrow A}$ is a bijection such that $(fofofo\cdots n$ times) $=f$ but $(fof),(fofof), \cdots, (fofofo\cdots (n-1)$ times) are not identical to $f$ . Then largest value of $n$ is? Answer given- 21 I thought of taking an apt function and getting the answer, but answer seems out of range, any hint?",['functions']
3790797,"If $s \ge 2,$ then $\sum\limits_{k \ge 1} \frac{(-1)^k}{k!} s_k = 0$ where $s_k = \sum\limits_{b_1+\dots+b_k=s-k} \prod\limits_i \frac{1}{b_i+1}.$","Show that if $s \ge 2,$ then $\sum\limits_{k \ge 1} \frac{(-1)^k}{k!} s_k = 0$ where $s_k = \sum\limits_{b_1+\dots+b_k=s-k} \prod\limits_i \frac{1}{b_i+1}$ and the sum is over all non-negative $b_i.$ I was working on a problem related to the probability of certain cycles appearing and managed to show that the result I needed was equivalent to $\frac{t}{n} = \sum\limits_{r \ge 1} \sum\limits_{a_1, \dots, a_r \ge 1} \frac{(-1)^{r+1}}{r!} \binom{t}{a_1, \dots, a_r} \prod\limits_{i=1}^r \frac{(a_i-1)!}{n^{a_i}}$ for all $n.$ The coefficient of $1/n$ is clearly $t,$ so I realized that it suffices to show the coefficient of $\frac{1}{n^s}$ is zero for all $s \ge 2.$ After rearranging and removing the chaff, the claim that these coefficients vanish is the equality in the title of this post. After all of the work I've done on my problem, I would hate to have to start over from scratch. Hopefully, the question I posed has a nice and simple proof. You can rewrite $s_k$ as $$\int\limits_{[0,1]^k}\left[\sum_{b_1+\dots+b_k = s-k} x_1^{b_1} \cdots x_k^{b_k} \right] dx_1 \dots dx_k,$$ but I'm not sure whether this will help. You can go one step further and sneak $\frac{(-1)^k}{k!}$ in there: $$\frac{(-1)^k}{k!}s_k = \int\limits_{[0,1]^k}\left[\sum_{b_1+\dots+b_k = s-k} \prod\limits_i -x_i^{i(b_i+1)-1)} \right] dx_1 \dots dx_k.$$ But that still doesn't make combining all of the integrals any easier.","['multivariable-calculus', 'calculus', 'combinatorics', 'summation']"
3790805,Number of fixed points of a random permutation,"Consider a random permutation of numbers $1,...,31415$ . Let $A$ be the number of its fixed points (i.e. numbers which are not moved by permutation). Let $B$ be the number of non-fixed points. What is the variance of $B-A$ ? I have no idea.","['permutations', 'variance', 'combinatorics', 'probability-theory']"
3790844,"Show that if f is entire and $|f(z)|=1$ for all real numbers, then $f$ has no zeroes.","Show that if f is entire and $|f(z)|=1$ for all real numbers, then $f$ has no zeroes.
I am supposed to use Schwartz reflection principle, but I don't see how. It tells me that $\overline{f(\overline{z})}$ is entire. It is clear that $|\overline{f(z)}|=1$ for all real $z$ but that does not allow me to use identity theorem yet. However, even if i could use identity theorem, I don't see how it would be helpful here. Any hints or solutions would be appricaated.",['complex-analysis']
3790884,Find number of solutions of an ODE with a property,"I'm stucked on the following exercise: How many solution of $x'(t)=x(t) -e ^{-t^2}$ have the following property: $\lim_{t \rightarrow \pm \infty} x(t)=0$ ? I tried to integrate in $[0,t]$ , obtaining $$x(t)= c e^t -  e^{t} \int_0^t e^{-s^2} e^{-s} ds$$ Now I'd like to take the limit, in order to note that $x(t)$ is unbounded, by I don't know how to handle that integral. How can I move?","['integration', 'ordinary-differential-equations']"
3790907,Simple question concerning integrals and derivatives,"I have a question about integrals and derivatives. It concerns the proof of the formula of the energy stored in a capacitor. The formula is $E = \frac{1}{2}C.V^2$ where $E$ is the energy stored, $C$ the capacitance (a scalar constant), and $V$ is the voltage applied on the capacitor. Here is the proof, as presented in many physics textbook: we charge the capacitor during a time $t$ , leading its voltage to go from $0$ to $V$ . We note $P(t)$ the power, $U(t)$ the voltage accross the capacitor (going from $0$ at time = 0 to $V$ at time = $t$ ), and $I(t)$ the current flowing through the capacitor. We have the capacitor formula: $I(t) = C.\frac{dU}{dt}(t)$ , where $C$ is a scalar constant. \begin{align*}
P(t) &= U(t)\cdot I(t) \\
&= C\cdot U(t)\cdot\frac{dU}{dt} \\
\rightarrow dE &= C\cdot U(t)\cdot dU \\
\rightarrow \int_{0}^{t}{dE} &= \int_{0}^{V}{C\cdot U(t)\cdot dU} \\
\rightarrow E &= \frac{1}{2}C\cdot V^2
\end{align*} I do not understand two things. The first is: why do we write $\frac{dU}{dt}$ instead of $\frac{dU}{dt}(t)$ , because $\frac{dU}{dt}$ is the derivative of $U$ hence it is also a function of the variable $t$ ? The second is: we have $P(t) = C.U(t).\frac{dU}{dt}(t)$ hence $E = \int_{0}^{t}{P(t).dt} = \int_{0}^{t}{C.U(t).\frac{dU}{dt}(t).dt}$ . I thought we could not have the same $t$ as an integral bound and as the variable $dt$ ? Is it also legal to multiply by $dt$ and to simplify $\frac{dU}{dt}(t).dt$ by $dU(t)$ ? But what will be the meaning of $dU(t)$ ? It is not a derivative anymore, so what is it? If we do this simplification, we end up with $E = \int_{0}^{t}{C.U(t).dU(t)}$ , what is the meaning of such an integral, we now integrate with $dU(t)$ and not a simple $dU$ , it seems weird. By the way, how can we exchange $\int_{0}^{t}$ by $\int_{0}^{V}$ ? Thank you very much for your help. How can we write a rigorous proof of this formula?","['integration', 'derivatives']"
3790932,Algebraic numbers and algebraic functions,"If $f : \bar{\mathbb{Q}} \to \mathbb{Q}$ is a continuous function, where $\bar{\mathbb{Q}}$ denotes the set of algebraic numbers, does such function have to be constant?","['algebraic-number-theory', 'general-topology', 'real-analysis']"
3791053,Generating permutations using swaps of adjacent elements,"Is it possible to generate all permutations of order n in a sequence
by successive swaps of adjacent elements only, such that each
permutation appears exactly once? for example, for n = 3 (* denotes the next swap): $$ 1*2-3 $$ $$ 2-1*3 $$ $$ 2*3-1
 $$ $$ 3-2*1 $$ $$ 3*1-2 $$ $$ 1-3*2 $$ for n = 4, there is a pattern of length 8 that repeats 3 times: $$ 1*2-3-4 $$ $$ 2-1*3-4 $$ $$ 2-3-1*4 $$ $$ 2-3*4-1 $$ $$ 2-4-3*1 $$ $$ 2-4*1-3 $$ $$ 2*1-4-3 $$ $$ 1-2*4-3 $$ Also, the patterns themselves got me curious. Is there a way to generate them?","['permutations', 'discrete-mathematics']"
3791063,Geometric proof for why the midpoints of parallel chords of a parabola lie on the same line parallel to the axis,I was trying to figure out a geometric proof for why the midpoints of parallel chords of a parabola lie on the same line which is parallel to its axis. I searched on StackExchange and people have mentioned this property but haven't proved it. I was able to prove it algebraically but is there a proof of this property that only uses geometry and various properties of parabolas?,"['conic-sections', 'geometry']"
3791078,Proving a subgroup generated by a subset is a normal subgroup using universal properties,"I have the following (from Aluffi II.7.7): Theorem: Let $G$ be a group and $H \leq G$ be generated by all elements of a fixed order $N$ . Then $H$ is a normal subgroup of $G$ . I came up with a fairly simple proof using the concrete description for ""the subgroup generated by a subset"": the subgroup consists of exactly the products of elements of the subset. Proof: Using the concrete description for $H$ , any element $h \in H$ can be written as: $$ h = \prod_{1 \leq i < k} a_i,$$ where each $a_i$ has order $N$ . But for any $g \in G$ , we know each $g a_i g^{-1}$ has order $N$ as well, so: $$ \prod_{1 \leq i < k} ga_ig^{-1} \in H,$$ but this product is just $ghg^{-1}$ . Therefore, $H$ is normal in $G$ . However, I was wondering if there's a proof that uses the following definition of ""the subgroup generated by a subset"": Definition :
For any $A \subseteq G$ with the natural map $\iota: A \to G$ , the universal property for free groups implies that there exists a unique $\varphi: F(A) \to G$ such that the following diagram commutes: The subgroup generated by $A$ is then the image of $\varphi$ . One of my attempts is as follows: Let $G$ be a group, and let $A$ be the elements of order $N$ in $G$ . For any $g \in G$ , let $\gamma_g$ denote conjugation by $g$ ; consider the following diagram: The universal property for free groups guarantees that $\varphi_g$ exists and is unique. However, we also have $\varphi: F(A) \to G$ from the definition of the subgroup generated by $A$ : ... I'm convinced that $??? = \gamma_g$ makes the diagram commute, in which case for any $h \in \text{img }\varphi$ , then $h = \varphi(a)$ for some $a \in F(A)$ and $$ghg^{-1} = \gamma_g(\varphi(a)) = \varphi(\varphi_g(a)).$$ Thus, $ghg^{-1} \in \text{img } \varphi$ . I'm stuck on how to prove that $??? = \gamma_g$ with just universal properties. I tried invoking the universal property with $\varphi \, j \, \gamma_g : A \to G$ but couldn't seem to get anywhere. Does anyone have suggestions on how to proceed from here?","['category-theory', 'universal-property', 'normal-subgroups', 'abstract-algebra', 'group-theory']"
3791094,"Is it possible to find the intersection of this involute and roulette, given their parametric equations?","Background I have two parametric curves, and I want to find the parameter values of their intersection point closest to zero under certain conditions. The first curve is an involute of a circle with parameter theta: $$
x_1(θ) = \frac{Z}{2} ⋅ \cos(α) ⋅ (\cos(θ − \tan(α) + α) + θ ⋅ \sin(θ − \tan(α) + α)),
$$ $$
y_1(θ) = \frac{Z}{2} ⋅ \cos(α) ⋅ (\sin(θ − \tan(α) + α) − θ ⋅ \cos(θ − \tan(α) + α)),
$$ $$
0 ≤ θ_{min} ≤ θ ≤ θ_{max}
$$ (note that theta must always be greater than or equal to zero) And the second curve is a roulette with parameter gamma: $$
\begin{align}
x_2(γ) =& \left(1 - \frac{\operatorname{sgn}(P) ⋅ F}{\sqrt{P^2 + \left(γ ⋅ \frac{Z}{2}\right)^2}}\right) ⋅ \left(\operatorname{sgn}(P) ⋅ γ ⋅ \frac{Z}{2} ⋅ \sin(\operatorname{sgn}(P) ⋅ γ + Q) + P ⋅ \cos(\operatorname{sgn}(P) ⋅ γ + Q)\right) \\
 +& \frac{Z}{2} ⋅ \cos(\operatorname{sgn}(P) ⋅ γ + Q) - (1 - \operatorname{sgn}(P)^2) ⋅ F ⋅ \cos(γ - Q),
\end{align}
$$ $$
\begin{align}
y_2(γ) =& \left(1 - \frac{\operatorname{sgn}(P) ⋅ F}{\sqrt{P^2 + \left(γ ⋅ \frac{Z}{2}\right)^2}}\right) ⋅ \left(\operatorname{sgn}(P) ⋅ γ ⋅ \frac{Z}{2} ⋅ \cos(\operatorname{sgn}(P) ⋅ γ + Q) - P ⋅ \cos(\operatorname{sgn}(P) ⋅ γ + Q)\right) \\
 -& \frac{Z}{2} ⋅ \sin(\operatorname{sgn}(P) ⋅ γ + Q) - (1 - \operatorname{sgn}(P)^2) ⋅ F ⋅ \sin(γ - Q),
\end{align}
$$ $$
γ_{min} ≤ γ ≤ 0
$$ where $P := X - C + F$ and $Q := \frac{F ⋅ \sec(α) - P ⋅ \tan(α)}{\frac{Z}{2}}$ . The equations for the two curves are built with five independent variables: $Z$ is a positive integer, $X$ is a real number in the closed interval $[−1, 1]$ , $C$ is a real number in the closed interval $[1, 1.5]$ , $F$ is a real number in both the closed intervals $\left[0, (\tan(α) + \sec(α)) ⋅ \left(\frac{π}{4} - C ⋅ \tan(α)\right)\right]$ and $\left[0, (\tan(α) + \sec(α)) ⋅ \sec(α) ⋅ (C - 1)\right]$ , and $α$ is an angle in the closed interval $\left[0, \arctan\left(\frac{π}{4 ⋅ C}\right)\right]$ . The upper boundaries of the parameter values are $θ_{max} = \frac{\sqrt{\left(X + \frac{Z}{2} + 1\right)^2 - \left(\frac{Z}{2} ⋅ \cos(α)\right)^2}}{\frac{Z}{2} ⋅ \cos(α)}$ and $γ_{max} = 0$ $θ_{min}$ and $γ_{min}$ are the parameter values at the intersection that I want to find. I know that the curves have a touching intersection (where their tangents are the same) at the parameter values $θ = \frac{P}{\frac{Z}{2} ⋅ \tan(α)} - Q + \tan(α)$ and $γ = (1 - \operatorname{sgn}(P)^2) ⋅ \left(α - \frac{π}{2}\right) - \frac{\operatorname{abs}(P)}{\frac{Z}{2} ⋅ \tan(α)}$ (See the red and blue curves in the following picture.) However, when the values of the five variables are such that $\frac{P}{\frac{Z}{2} ⋅ \tan(α)} - Q + \tan(α) < 0$ , two things happen: The value of $θ_{max}$ from the above definition becomes negative, which makes it invalid for my purposes, and A transversal intersection (where the curves' tangents are distinct) appears at values of gamma and theta closer to zero than those for the touching intersection, and specifically with a positive value of theta. (See the red and blue curves in the following picture.) This transversal intersection does also exist when $\frac{P}{\frac{Z}{2} ⋅ \tan(α)} - Q + \tan(α) ≥ 0$ , it's just at a negative (invalid) value of theta and is thus hidden. The Problem I want to find closed-form expressions for the parameter values $θ_{min}$ and $γ_{min}$ at this transversal intersection in terms of $α$ , $Z$ , $X$ , $C$ , and $F$ , in the specific case where $\frac{P}{\frac{Z}{2} ⋅ \tan(α)} - Q + \tan(α) < 0$ , given the stated domains of the independent variables $α$ , $Z$ , $X$ , $C$ , and $F$ . Additionally, when that inequality is true, $θ_{min}$ should always be strictly greater than zero. When that inequality is not true, the value of any new expression for $θ_{min}$ is irrelevant, because I already have expressions that work in that case, so it's fine if the new expression is undefined or negative when that inequality is not true. Is it possible to find closed-form expressions here? Where These Curves Come From The curve with parameter theta is a portion of the envelope of the line described by the equation $$
\ \ \ \ \sin(β + α) ⋅ x \\
- \cos(β + α) ⋅ y \\
= \frac{Z}{2} ⋅ (\sin(α) + β ⋅ \cos(α))
$$ as the parameter $β$ varies from $-∞$ to $+∞$ . Specifically, it is the path of the point on that line with $(x, y)$ coordinates $$
\begin{pmatrix}\begin{align}
&\frac{Z}{2} ⋅ \cos(α) ⋅ (\cos(α + β) + \sin(α + β) ⋅ (\tan(α) + β)), \\
&\frac{Z}{2} ⋅ \cos(α) ⋅ (\sin(α + β) - \cos(α + β) ⋅ (\tan(α) + β))
\end{align}\end{pmatrix}
$$ The curve with parameter gamma is the path of one of the intersection points of the line $$
\ \ \ \ \left(\left(β ⋅ \frac{Z}{2} + Q\right) ⋅ \cos(β) - P ⋅ \sin(β)\right) ⋅ x \\
+ \left(\left(β ⋅ \frac{Z}{2} + Q\right) ⋅ \sin(β) + P ⋅ \cos(β)\right) ⋅ y \\
= \frac{Z}{2} ⋅ \left(β ⋅ \frac{Z}{2} + Q\right)
$$ with the circle $$
\ \ \ \ \left(x - \left(\left(\frac{Z}{2} + P\right) ⋅ \cos(β) + \left(β ⋅ \frac{Z}{2} + Q\right) ⋅ \sin(β)\right)\right)^2 \\
+ \left(y - \left(\left(\frac{Z}{2} + P\right) ⋅ \sin(β) - \left(β ⋅ \frac{Z}{2} + Q\right) ⋅ \cos(β)\right)\right)^2 \\
= F^2
$$ I've tried to find a way to relate the envelope of the first line, and its generating point, with the path of the second point. I've had no success so far, but I'm hopeful that a way to do so does exist. What Else I Know I do know that on the first curve, the radius of a point for a given value of theta is $r(θ) = \frac{Z}{2} ⋅ \cos(α) ⋅ \sqrt{θ^2 + 1}$ , and conversely the value of theta for a given radius is $θ(r) = \sqrt{\left(\frac{2 ⋅ r} {Z ⋅ \cos(α)}\right)^2 − 1}$ . This means that if I can find the radius of the transversal intersection point by any process, I can easily convert it into the value for $θ_{min}$ , and vice versa. I also know that the angle made with the $x$ -axis by a point on the curve at a given value of theta is $β(θ) = θ − \arctan(θ) + α − \tan(α)$ , which is transcendental and has no closed-form inverse, so I cannot use a known angle to find the value of theta. The same goes for the second curve, just with much more complicated expressions. Thus, if I get either one of $θ_{min}$ or $γ_{min}$ , I can use that value to find the other. If I can find the radius of the intersection separately, I can use it to find both values. Given these expressions, I know that the radius of the touching intersection is $r = \sqrt{(F - P ⋅ \csc(α))^2 + Z ⋅ (P - F ⋅ \sin(α)) + \left(\frac{Z}{2}\right)^2}$ . I've attempted to find a similar expression for the transversal intersection by working backwards from numerically-calculated values, without any success yet. For example, by plotting the two curves in graphing software and numerically calculating the parameter values of their intersections to ten decimal places, I created this plot, which shows the $γ_{min}$ value against the pressure angle $α$ (including some technically-invalid negative values of $α$ to get a broader sample size) for four different values of $Z$ , all with $X = 0$ , $C = 1$ , and $F = 0$ : The green lines show the known expression $γ_{min}(α)$ , while the red points are samples of the unknown expression for which I am searching. I've been trying to fit a curve to the red points, unfortunately without any success yet. As stated above, if I can find the equation that describes the red points and thus the value of $γ_{min}$ , I can use that to also find the value of $θ_{min}$ , which would completely solve my problem. Similarly, I numerically calculated the $θ_{min}$ values for $1°$ increments of $α$ with $Z = 24$ , $X = 0$ , $C = 1.25$ , and $F = 0$ and plotted the results. This shows that the unknown expression for $θ_{min}(α)$ is very close to half the known expression for $θ_{min}(α)$ reflected over the vertical line where $θ_{min}(α) = 0$ : To see what the difference is between that squashed reflection and the sampled points, I also plotted points where that curve is subtracted from the vertical coordinate, in red, and points where the vertical coordinate is divided by the height of that curve, in green: These sets of points look very much like they should be described by combinations of trig functions, but I haven't been able to find combinations that fit them exactly. I also figured out that the value of $γ_{min}$ seems to have an upper bound of $-\sqrt{\frac{T^2 - P^2}{\left(\frac{Z}{2}\right)^2}} - (1 - \operatorname{sgn}(P)^2) ⋅ \arccos\left(\frac{F^2 - \left(\frac{Z}{2}\right)^2 ⋅ (\cos(α)^2 - 1)}{2 ⋅ F ⋅ \frac{Z}{2}}\right)$ , where $$
T := \sqrt[3]{-\frac{F ⋅ B}{3} + \sqrt{\left(\frac{F ⋅ B}{3}\right)^2 + \left(P ⋅ Z - \frac{\left(\frac{2}{3} ⋅ F\right)^2 - B}{3}\right)^3}}\\
  + \sqrt[3]{-\frac{F ⋅ B}{3} - \sqrt{\left(\frac{F ⋅ B}{3}\right)^2 + \left(P ⋅ Z - \frac{\left(\frac{2}{3} ⋅ F\right)^2 - B}{3}\right)^3}}\\
  - \frac{2}{3} ⋅ F
$$ and $$
B := \frac{\left(\frac{F}{3}\right)^2 - \frac{Z}{2} ⋅ \left(\frac{Z}{2} ⋅ (A^2 - 1) + P\right)}{3}
$$ but I haven't been able to refine that into an exact solution. Context The curve with parameter theta is the involute face curve of a tooth on an involute gear, while the curve with parameter gamma is the roulette root curve of the same tooth. These curves are naturally generated in real life by the gear-shaping process called hobbing , without needing any fancy math. Representing them in a computer, which I want to do, is more difficult. The shapes of these curves are defined by five variables: $α$ , the angle of the contact force between meshed gear teeth, called the pressure angle ; $Z$ , the number of teeth on the gear; $X$ , the profile shift coefficient , specifying how far in or out the cutting tool is moved compared to cutting a standard gear profile; $C$ , the clearance factor , specifying how much clearance there is between the tooth roots on one gear and the tooth tips on a meshing gear as a multiple of the overall tooth height (a value of 1 gives zero clearance, a value of 1.5 gives half a tooth-height of clearance); and $F$ , the root fillet radius , specifying the radius of the fillet curve that joins the roots of the teeth to the faces of the teeth. There is one more gear design variable, called module or pitch , which describes the overall size of the gear. Because this variable is a uniform scaling factor, it has no effect on the angles involved or on the values of theta and gamma, so I have left it out of the equations for the sake of simplicity. When $\frac{P}{\frac{Z}{2} ⋅ \tan(α)} - Q + \tan(α) ≥ 0$ , the involute face curve transitions smoothly into the roulette root curve (with a touching intersection). However, when $\frac{P}{\frac{Z}{2} ⋅ \tan(α)} - Q + \tan(α) < 0$ , the root curve cuts off some of the face curve (with a transversal intersection). This is called undercutting and is in general undesirable, as it reduces the strength of the gear. However, small amounts of undercutting are tolerated in many situations. I want to find the point on each curve where this undercutting occurs so I can accurately draw an undercut gear in software. This question is very similar to another question on this site , but that question's answer doesn't address my particular problem.","['curves', 'parametric', 'geometry', 'differential-geometry']"
3791102,Is there a non-measurable set with measurable sections?,"Consider the following fragments from Axler's book ""Measure, Integration and Real analysis"" I honestly don't know how to find the desired set $E$ . I can't even find a single set $E \notin \mathcal{B}\otimes \mathcal{B}$ , let alone one with the property we are looking for! A hint into the right direction is appreciated!",['measure-theory']
3791112,Evaluate $\int _0^1\frac{\ln x\ln (1+x^2)}{1+x^2}\:dx$ without trigonometric and complex functions,"Earlier, I posted the sum evaluation that has the following integral representation. $$\sum _{k=1}^{\infty }\frac{\left(-1\right)^kH_k}{\left(2k+1\right)^2}=\int _0^1\frac{\ln \left(x\right)\ln \left(1+x^2\right)}{1+x^2}\:\mathrm{d}x$$ Ali Shather managed to prove here $$\int _0^1\frac{\ln \left(x\right)\ln \left(1+x^2\right)}{1+x^2}\:\mathrm{d}x=\frac3{32}\pi^3+\frac{\pi}8\ln^22-\ln2~G-2\text{Im}\operatorname{Li_3}(1+i)$$ which relies on trigonometric substitutions as well as complex methods. Question :
Can this integral be evaluated without the trig functions? and is it possible to evaluate it without complex methods? I tried using certain substitutions, but ended up with similar or even harder integrals. I'm not sure how to approach this.","['integration', 'definite-integrals', 'real-analysis']"
3791149,(geometry) How to construct inscribed circle between 3 circles?,"Suppose I have 3 circles not overlapping (but possibly touching) each other. Is there always an inscribed circle that is touching (i.e. tangent to) each of the 3 circles? And if yes, how do I construct it? For example if I have 3 circles like this: I would like to construct approximately this inscribed circle:","['circles', 'geometry']"
3791203,What do the level sets of the Shannon entropy look like?,"The Shannon entropy of a discrete probability distribution $\newcommand{\bs}[1]{\boldsymbol{#1}}\bs p\equiv (p_i)_{i=1}^n$ is defined as $H(\bs p)\equiv -\sum_{i=1}^n p_i \log p_i$ . Consider the corresponding level sets, that is, the sets of the form $$L^{(n)}_\alpha\equiv \left\{(p_1,...,p_n) : \sum_i p_i=1 \text{ and } H(p_1,...,p_n)=\alpha\}\subset\mathbb R^n\right\},\quad\alpha\in[0,\log n].$$ Is there a geometrical characterisation for these sets? Clearly, $L^{(n)}_{\log n}=\{(1,...,1)/n\}$ and $L^{(n)}_{0}=\{\bs e_1,...,\bs e_n\}$ where $(\bs e_i)_j=\delta_{ij}$ . What about the nontrivial cases with $0<\alpha<\log n$ ? For example, in the $n=3$ case the corresponding level sets/contour lines look like in the following: To get a better look at the contour lines we can parametrise the simplex as $$S(s,t)=(1,0,0)+\frac{t}{\sqrt2}(-1,1,0)+\frac{s}{\sqrt{3/2}}(-1/2,-1/2,1),$$ and then plotting $H(S(s,t))$ against $s,t\in\mathbb R^2$ we get We can push this further to visualise single level sets for $n=4$ , by using the parametrisation $$S(s,t,u) = (1,0,0,0) + \frac{t}{\sqrt2}(-1,1,0,0) + \frac{s}{\sqrt{3/2}}(-1/2,-1/2,1,0) + \frac{u}{\sqrt{4/3}}(-1/3,-1/3,-1/3,1),$$ and them plotting the $(s,t,u)$ such that $H(S(s,t,u))=\alpha$ . For example, with $\alpha=\log(3.2)$ we get where the tetrahedron shows how the normalisation constraint on the probabilities is translated into this $(s,t,u)$ space. The fact that $H$ doesn't care about the ordering of the elements in $\bs p$ implies a series of reflection symmetries on the level sets. What else can be said about them? The fact that not all such level sets are closed might make the problem less well-defined, in which case we might restrict our attention to the cases with $\log(n-1)\le \alpha \le \log n$ for which (I think) the level sets should be closed. Alternatively, one might extend the definition of $H$ to let it act on vectors that are not necessarily probability distributions. The Mathematica code to generate the figure can be found here .","['entropy', 'geometry', 'information-geometry', 'information-theory', 'probability']"
3791214,"Let $e,f$ be unit vectors in a real Banach space s.t $\|2e+f\|=\|e-2f\|=3$, show that $\|\lambda e+\mu f\|=|\lambda|+|\mu|$.","Let $e,f$ be unit vectors in a real Banach space s.t $\|2e+f\|=\|e-2f\|=3$ , show that $\|\lambda e+\mu f\|=|\lambda|+|\mu|$ . I have a hint which is to show there is are linear functionals of norm $1$ s.t $\phi(e)=\phi(f)=1$ and $\pi(e)=\pi(-f)=1$ . I could not prove the hint. I know that by hanh banach we can extend $\phi(\alpha e+\beta f)=\alpha +\beta$ to entire space. but I do not know how to show that it has norm $1$ . I am almost certain I have to use $\|2e+f\|=\|e-2f\|=3$ . I tried the following: let $\alpha,\beta$ be s.t $\|\alpha e+ \beta g\|=1$ then given $\|\alpha e+ \alpha/2 f\|=3/2\alpha$ and so $\|\alpha e+ \beta g\|=\|\alpha e+\alpha f+(\beta-\alpha/2)f\|=1$ . Then I tried reverse triangle inequality but that was not helpful. What do I do here?",['functional-analysis']
3791270,Proof of why conics map to conics after a perspective transformation,"Background Consider a world where the ground is the standard $x$ - $y$ plane with a Cartesian grid on it. The graph of a parabola $x^2 = 4ay$ is on this $x$ - $y$ plane. A person of with eye-level $h$ above the ground is walking along the ground and stops a bit before the origin of the $x$ - $y$ plane which is on the ground. He/she looks straight out in the direction of the positive $y$ -axis and instead of a parabola sees an ellipse. The following images and video animation illustrate this: View of parabola straight down from above: View of parabola with eyes at some height $h$ looking towards the horizon (positive $y$ -axis): Animation: https://www.youtube.com/watch?v=ukmqwGbfEZM Question My question is this: Is there a way to prove that a general conic under the type of perspective projection I described here (where you go from looking straight down from above at the conic on the ground to looking straight out along the $y$ -axis with your eyes at some height $h$ above the ground)  maps to another conic (such as in this case from parabola to ellipse)? More specifically, is there a way to convert the equation of a general conic in the first perspective (such as $x^2=4ay$ ) to an equation of the other conic in the second perspective given the parameters I described above (namely $h$ and that the person is looking out in the direction of the positive $y$ -axis)?","['projective-geometry', 'conic-sections', 'geometry']"
3791271,"Uniformly choose two derangements $\sigma_i,\sigma_j$. What is the distribution of $\sigma_i\circ \sigma_j$?","I was working on this question and come up with this problem. Let $\sigma_i,\sigma_j$ be two uniformly chosen derangements, i.e. $\sigma_i,\sigma_j \in D_n = \{\sigma \in S_n : \sigma(i)\neq i~\forall i\}$ . What is the distribution of $\sigma_i\circ \sigma_j$ ? Here we can see that every $\sigma \in S_n$ is the composition of two $\sigma_i,\sigma_j\in D_n$ . But some permutations are easier to produce than others. For instance, let $\sigma^*$ be the identity, we have $\sigma_i\circ\sigma_j = \sigma^*$ iif $\sigma_j =\sigma_i^{-1}$ . So, we are free to choose $\sigma_i$ , but then $\sigma_j$ is defined, therefore: $$P(\sigma_i\circ\sigma_j = \sigma^*) = \frac{1}{|D_n|} > \frac{1}{|S_n|} $$ But $\lim_{n\to\infty}\frac{|D_n|}{|S_n|} = \frac{1}{e}$ (see here ), it leads me to think that although it is not uniform, it could at least have the same order. So, my guess is that we can find $c,C > 0$ such that $$c\frac{1}{|S_n|} \leq P(\sigma_i\circ\sigma_j = \sigma) \leq C \frac{1}{|S_n|}~\forall \sigma\in S_n$$ for sufficiently large values of $n$ .","['permutations', 'probability-distributions', 'symmetric-groups', 'group-theory', 'probability']"
3791305,Calculate $\int_{0}^{\infty} \frac{x-\sin(x)}{x^3(1+x^2)}$,"Calculate $$\int_{0}^{\infty} \frac{x-\sin(x)}{x^3(1+x^2)}$$ I know i am supposed to use residue theorem. However, I am having trouble with the pole at $z=0$ normally i would try the funciton $$f(z)=\frac{z-e^{iz}}{z^3(1+z^2)}$$ but this clearly is not working  as this function has a pole of order 3 at $z=0$ . if i try to reduce the order of the pole i would need to do something along those lines: $$f(z)=\frac{z-ie^{iz}+i}{z^3(1+z^2)}$$ and here the pole is simple, but integrating this function will not give me the desired integral, I don' think. What do I do? Edit: Perhaps $y=x^2$ substitution and keyhole integration would work. I will have to check.","['integration', 'complex-analysis', 'residue-calculus']"
3791340,How fast can my hoard grow?,"Imagine a game played with tokens. You start with nothing. Every turn, you receive $2^k$ tokens, where $k$ is the total number of tokens you already have. How many tokens do you have after the $n$ th turn? (As an example, the first turn you have zero tokens, so you receive one. The second turn you have one token, so you receive two. The third turn you have three tokens, so you receive eight. The fourth turn you have eleven tokens, so you receive 2048.) I'm curious if there's a closed form for this. I suspect there isn't, so I'd also be satisfied with the asymptotic growth rate (the ""big O""). It certainly seems to grow faster than exponential, but I can't figure out how much faster. My best attempt at a recursive definition so far is $a_0 = 0$ , $a_n = a_{n-1} + 2^{a_{n-1}}$ , but this is rather inelegant and hard to do anything with. (This question came up during a game of Magic: the Gathering , using two particular cards: Anointed Procession says that if you would ""create"" a token (put it into play), you ""create"" twice that many instead, and Mythos of Illuna creates a token that's a copy of another card. The virtual tabletop crashes on the fourth iteration, and I'm curious how ridiculous this could get if it kept going.)","['closed-form', 'recurrence-relations', 'sequences-and-series']"
3791350,How to calculate $\theta = \arcsin\left(\frac{1}{2}\right)$ with given four function calculator?,"An example question is: In radian measure, what is $\arcsin \left(\frac{1}{2}\right)$ ? Select one: a. $0$ b. $\frac{\pi}{6}$ c. $\frac{\pi}{4}$ d. $\frac{\pi}{3}$ e. $\frac{\pi}{2}$ So, in the exam, I will be given only four function calculator. And is it possible to calculate this kind of trigo function? Or, do I have to memorise common values of trigo functions? Is there any tricks and tips for this problem?","['algebra-precalculus', 'pi', 'problem-solving', 'trigonometry']"
3791371,Removable singularity and Liouville's Theorem,"Please verify if I got either correct. 1a. Let $f$ be entire function such that $\sup_{\mathbb C} \left |\frac{f(z)}{z} \right | < \infty$ . Show $z = 0$ is a removable singularity of $g(z) = \frac{f(z)}{z}$ . 1b. Suppose $f$ and $g$ are entire functions such that $|f| \leq K|g|$ , show that $f = cg$ for all $z \in \mathbb{C}$ . I wrote that 1a. Since $\sup |f(z)/z| < \infty$ then $\left |\frac{f(z)}{z} \right | < M$ . Hence $\lim_{z \to 0}|zg(z)| = \lim_{z \to 0}|f(z)| \leq \lim_{z \to 0} M|z| =0.$ So passing the limit to both sides yields the result. 1b. I think this is just applying Liouville Theorem to $(f/g)$ never mind I found the answer. My answer is incomplete for 1b. Only need verification for 1a. Thanks for reading.","['complex-analysis', 'solution-verification']"
3791438,"Why $8^{\frac{1}{3}}$ is $1$, $\frac{2\pi}{3}$, and $\frac{4\pi}{3}$","The question is: Use DeMoivre’s theorem to find $8^{\frac{1}{3}}$ . Express your answer in complex form. Select one: a. 2 b. 2, 2 cis (2 $\pi$ /3), 2 cis (4 $\pi$ /3) c. 2, 2 cis ( $\pi$ /3) d. 2 cis ( $\pi$ /3), 2 cis ( $\pi$ /3) e. None of these I think that $8^{\frac{1}{3}}$ is $(8+i0)^{\frac{1}{3}}$ And, $r = 8$ And, $8\cos \theta = 8$ and $\theta = 0$ . So, $8^{\frac{1}{3}}\operatorname{cis} 0^\circ = 2\times (1+0)=2$ I just got only $2$ . Where and how others $\frac{2\pi}{3}$ , and $\frac{4\pi}{3}$ come from?","['cubics', 'trigonometry', 'pi', 'algebra-precalculus', 'complex-numbers']"
3791442,Show that $|\operatorname{median}(X) - \operatorname{mean}(x)| \leq \sigma_X$ [duplicate],"This question already has answers here : Distance between mean and median (2 answers) Closed 3 years ago . Let $m$ denote median and $\bar{x}$ denote mean and $\sigma$ denote the standard deviation, I want to show that $|m - \bar{x}| \leq \sigma$ . Since the LHS and RHS are both positive, we can prove $(m - \bar{x})^2 \leq \sigma^2$ instead. Here is what I've attempted with my first approach: \begin{align}
& |m - \bar{x}|^2 = |\bar{x} - m|^2 \\
= {} & \left|\sum_i (\frac{1}{n}x_i) - m\right|^2 \\
= {} & \left|\sum_i (\frac{1}{n}x_i) - \frac{n}{n}m\right|^2 \\
= {} & \left|\frac{1}{n}\sum_i x_i - m\right|^2 \\
= {} & \left(\frac{1}{n}\sum_i x_i - m\right)^2
\end{align} Also, $$
\sigma^2 = \frac{1}{n}\sum_i (x_i - \bar{x})^2
$$ I don't see an easy way to show that this quantity is $\geq$ than the previous quantity. Is this in the right direction? The standard deviation and mean are related, but it's not clear to me how the median relates to either one. I'm not sure if this is relevant, but I also know that the minimizers for the following are the mean and median, respectively $$
\bar{x} = \arg \min_y \sum_i (x_i - y)^2 \\
m = \arg \min_y \sum_i \left| x_i - y \right| \\
$$","['statistics', 'standard-deviation', 'median', 'means', 'proof-writing']"
3791513,"Prove that $(A,N;P,B)=(A,M;Q,C)=-1$ .","Given $\Delta ABC$ and incircle $\omega$ tangent to $BC,AC,AB$ at $Y,M,N$ respectively . Let $AY \cap \omega=X$ . Let the tangent through $X$ wrt $\omega$ intersect $AB$ and $AC$ at $P$ and $Q$ respectively .
Prove that $(A,N;P,B)=(A,M;Q,C)=-1$ . I am completely stuck in this problem. I tried considering the intersection of $FE$ and $BC$ , but no movement .",['geometry']
3791518,When you can look through a forest?,"Yesterday I was coming back home by train through various forests and I realised, that through some of them one can see to the other side and through some of them not. Can this be formalised? That is, what is the chance of seeing what is on the other side of the forest depending on the size of the forest, average number of trees per unit area and the diameter of their trunk?","['poisson-distribution', 'probability']"
3791561,How to find range of $\left[\frac{[x]}{x}\right]$,"If $[.]$ denotes greatest integer function, find the range of $$\left[\frac{[x]}{x}\right]$$ My friend and I tried solving this question and arrived at the answer ${0,1}$ but when we took the value of $x$ as $-0.14$ we got the range as $7$ and then while trying other numbers we started getting big numbers like $5,6$ etc.... But the answer given is ${0,1}$ , so did we do something wrong?
Thanks.","['algebra-precalculus', 'functions', 'ceiling-and-floor-functions']"
3791577,How many four digits numbers are there not containing zero and multiplication of its digits divisible by 7?,"I saw a question in my math book, it seems very trivial, it says that: How many four digits numbers are there not containing zero and
multiplication of its digits divisible by 7? I thought of: (all four digits numbers not containing zero) minus (all four digits numbers not containing 7 and 0) in order to find all four digits number not containing zero and multiplication of its four digits divisible by 7. Then $(9^4)-(8^4)=2465$ . However the answer is $4904$ . What am I missing?","['permutations', 'solution-verification', 'problem-solving', 'discrete-mathematics']"
3791622,Statistics 101: T test vs Z test. Sample proportion vs Sample mean,"Sorry, I'm just on Khan academy and can't seem to grasp the essence of statistics. Hope to find some help out here. Both are samples, but why when looking for confidence interval of a: sample proportion, we take $\hat{p} \pm Z^*\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ sample mean, we take take $\bar{x} \pm t^*{\frac{S}{\sqrt{n}}}$ What I understand:
That both are trying to determine the confidence level that Population mean falls between an interval. I can see from google that: Z-scores are based on your knowledge about the population's standard
deviation and mean.  T-scores are used when the conversion is made
without knowledge of the population standard deviation and mean. But I don't think I properly understand it: what throws me off the statement is that the confidence interval formula $\bar{x} \pm t^*{\frac{S}{\sqrt{n}}}$ still uses S(sampling standard deviation). Question: Why can't we just take $\bar{x} \pm Z^*\sqrt{\frac{\bar{x}(1-\bar{x})}{n}}$ as we did $\hat{p} \pm Z^*\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ ? Both are samples, why does one estimate with $\hat{p}(1-\hat{p})$ while the other uses S (sample standard deviation)? What is the difference between sample proportion and sample mean? Is the former Bernuli distribution and another not? Is the sample proportion confidence interval of a single sample VS sample mean which is the average of multiple samples ? Both are samples, why do we n-1 during t test, but not z test? I get that samples need to -1 to compensate for accuracy, but why didn't we do it for z tests? Don't feel pressure to answer all the questions, just what you can, perhaps the collective can help me out of this rut. Appreciate it your time reading this!","['standard-error', 'statistics', 'confidence-interval', 'sampling']"
3791635,Is there a standard way of equipping a sigma-algebra with a sigma-algebra?,"Suppose $(X, \mathcal X)$ is a measurable space. I'd like to say something about measurable functions taking values in $\mathcal X$ , but in order to do that, I need $\mathcal X$ to be equipped with a sigma-algebra. Is there a canonical way of equipping $\mathcal X$ with a sigma-algebra $\mathcal F_\mathcal X$ so that we can talk about measurable functions from $(X, \mathcal X)$ to $(\mathcal X, \mathcal F_\mathcal X)$ ? Some ideas that occurred to me: (1) $\mathcal F_\mathcal X = \{A \subset \mathcal X: \bigcup A \in \mathcal X\}$ . But I don't see that this is closed under complements. (2) $\mathcal F_\mathcal X = \{A \subset \mathcal X: \bigcup A \in \mathcal X \ \text{or} \ \bigcap A \in \mathcal X\}$ . But I don't see that this is closed under countable unions.","['measure-theory', 'reference-request']"
3791641,"Show that $\frac{dy}{dx} = 5y +28 \cos(y), y(0) = 54$ has a unique solution on $\mathbb{R}$","Show that $\frac{dy}{dx} = 5y +28 \cos(y), y(0) = 54$ has a unique solution on $\mathbb{R}$ . This is a spin off of one of the problems in Berkeley Problems in Mathematics. My solution (attempt) is quite alot shorter than the one presented by the authours ( they show that a unique solution exists on some neighbourhood of $(0,54)$ using a local version of Picard's theorem and then use IFT to find an explicit solution on this neighbourhood and prove that this solution is valid on $\mathbb{R}$ ) so I wanted to check that I hadn't missed something. Here is my solution: Let $f(x,y)= 5y +28\cos(y)$ . Fix $h >0$ . By basic properties of continuous functions $f$ is continuous on $[-h,h] \times \mathbb{R}$ and moreover Lipschitz in $y$ on this strip. This follows from, $|f_y (x,y)|=|5-28\sin(y)| \leq 5+28|\sin(y)| \leq 5+28 = 33$ and the MVT. Picard's theorem applies and we see that the IVP has a unique solution on $[-h,h]$ . But $h$ was arbitrary so the IVP has a solution on all of $\mathbb{R}$ . $\blacksquare$ Is this correct? In general I am bit unsure about how to prove the uniqueness/existence of global solutions... analytic continuation or global Picard?! Note the version of Picard's theorem I am using is The IVP $y'(x) = f(x,y), y(a)=b$ , has a unique solution on $\mathbb{R}$ provided, $\forall h:$ $f$ is continuous on $[a-h, a+h] \times \mathbb{R}$ $f$ is Lipschitz in y on $[a-h, a+h] \times \mathbb{R}$ .","['calculus', 'solution-verification', 'ordinary-differential-equations', 'real-analysis']"
3791691,"solving, the following limit","So, the following is the question  given: I could solve it partially, here is my approach:
The limit is of the form $(A+B)/C$ where $A$ and $B$ both approach $e^3$ while $C$ approaches $0$ , This can be found out by simply evaluating $A$ and $B$ separately. Now, we can write the limit as $$ \lim_{t \to 0}  [(1+3t+2t^2)^{1/t} - e^3]/t -\lim_{t \to 0} [(1+3t-2t^2)^{1/t} - e^3]/t $$ but I couldn't evaluate these two limits at least using LH rule as the derivative of numerator is quite a long expression. Kindly suggest a way to solve this question, all help is greatly appreciated.","['limits', 'calculus']"
3791701,Definition of connectedness and it's intuition,"We say a topological space $X$ to be connected if it can not be written as disjoint union of two nonempty open subsets.
Intuitively connectedness means our topological space is a single piece.I am not able to see how the above definition captures the intuition. Please help.",['general-topology']
3791703,"If $y'(t) = -\sqrt{y(t)}$, $y(0) = 0$ and $y(t) \ge 0$. Then $y \equiv 0$ on $\mathbb{R}$","Consider the following ODE $$y'(t) = -\sqrt{y(t)},$$ with initial condition $y(0) = 0$ . Does this initial value problem have a unique solution ( $y \equiv 0$ on $\mathbb{R}$ ) if we further assume that $y(t) \geq 0$ for every $t$ ? We can see that if $y(t) \geq 0$ for every $t$ , then $y' \leq 0$ , so $y$ is decreasing. As $y(0) = 0$ , we get that $y \equiv 0$ on $[0, \infty)$ . However, can we conclude that $y \equiv 0$ on $\mathbb{R}$ ?",['ordinary-differential-equations']
3791712,Finite lines on hypersurfaces always in symmetric position?,"Let $X\subset \mathbb {P}^n _\mathbb {C}$ be a general hypersurface of degree $d$ , such that $2(n-1)=d+1$ . It would be easy to see that $X$ contains finitely many projective lines. I have a series of questions on the symmetry of these lines: If we take $X'$ to be the Fermat hypersurface (namely, defined by $x_0^d+x_1^d+\cdots$ ), is it true that these lines are symmetric? That is to say, the automorphism group acts transitively on these lines. For a general $X$ and any two lines $l_1,l_2$ on it, is it true that we can deform it to some $X'$ such that there exists some automorphism of $X'$ which maps $l_1$ to $l_2$ ? For a general $X$ , is it true that any two lines $l_1,l_2$ are homological equivalent? Apparently, 1 implies 2 (take $X'$ in 2 to be the $X'$ in 1), and 3 looks even weaker. However, I have no idea how to prove or disprove the statement 1. Any comments would be helpful!","['complex-geometry', 'algebraic-geometry']"
3791719,How can $t$-statistic be used to test hypothesis?,"I have the following question:
A random sample of size 25 from a normal distribution has mean 47 and standard deviation 7. Based on $t$ -statistics, can we say that the given information supports the
conjecture that the mean of the population is 42? I'm really confused how $t$ -statistics works to reject or fail to reject a hypothesis. An explanation would be really helpful. Thanks!","['statistical-inference', 'statistics', 'hypothesis-testing']"
3791732,(X subset of Y or Y subset of X) is transitive?,"so I was trying to figure out how to prove something and I failed so because I think the statement is false.
anyways here is the statement : To prove if the relation is Transitive we need to assume xRy and yRv and prove xRv. so the assumption means that there are 4 options here : (1) --> if x⊆y and y⊆v then x⊆v (2) --> if y⊆x and v⊆y then v⊆x The main problem of the proof comes here : (3) --> if x⊆y and v⊆y then we can't prove x⊆v or v⊆x (I.e. x={1},v={2},y={1,2,3}) (4) --> if y⊆x and y⊆v then we can't prove x⊆v or v⊆x (I.e. y={1},v={1,2},x={1,3}) So we can't prove for all the scenarios which means its might be not transitive?
and if its not transitive then the relation is not considered as Partially ordered set or Equivalence relation. Sorry for the long post , Am I right that its not transitive? Thank you!","['equivalence-relations', 'relations', 'discrete-mathematics']"
3791753,Identity coming from contour integration,"Let $p(z) \in \mathbb{C}[z]$ be a monic polynomial of degree $n \ge 2$ , and assume that it has distinct roots $z_1,\dots,z_n$ . If we consider the contour integral $$\frac{1}{2\pi i}\oint_{\left|z\right|=R}\frac{dz}{p(z)}$$ for $R$ large enough so that all roots lie inside $\{\left|z\right|\le R\}$ , then by the Residue Theorem this is equal to $$\sum_{i=1}^n \text{Res}\left(\frac{1}{p(z)},z_i\right)=\sum_{i=1}^n \frac{1}{\prod_{j \ne i}(x_i-x_j)}\,.$$ On the other hand, as $R \to \infty$ the ML estimate shows that the integral goes to $0$ . Thus we have the identity $$\sum_{i=1}^n \frac{1}{\prod_{j \ne i}(x_i-x_j)}=0\,.$$ Is there another way of proving this identity (maybe from just algebraic manipulation)?","['complex-analysis', 'abstract-algebra', 'combinatorics']"
3791761,solving a particular form of Chini's equation,"Solve the initial value problem $$u''(t)+u'(t)=\sin u(t)$$ with
initial conditions $u(0)=1,u'(0)=0$ , and hence show that $u(t),u'(t)$ is bounded for all $t>0$ . Find $\displaystyle\lim_{t\to\infty}u(t)$ . I started with the substitution $u'(t)=p(t)$ . Then by chain rule $\displaystyle{u''(t)=\frac{dp}{dt}=p\frac{dp}{du}}$ . So our equation becomes $$p\frac{dp}{du}+p=\sin u \\ \implies \frac{dp}{du}=-1+\frac{\sin u}{p}$$ which (after a thorough search online) I identified as a particular form of Chini's equation . I calculated the Chini invariant as $C=\sec u$ , which is not independent of $u$ and hence can not be solved easily. I wonder whether this equation is solvable by any form of algebraic transformation or not. In case this equation is not solvable analytically, or at least in some closed form, how to check for boundedness of the solution? Any help is appreciated.",['ordinary-differential-equations']
3791769,Understanding the statement and the proof of Bertini's theorem in Griffiths and Harris,"I am having trouble understanding the statement and the proof of Bertini's theorem in Griffiths & Harris book (p. $137$ ). Frankly, I do not understand a word even after I read several answers on stack. The theorem is The generic element of a linear system is smooth away from the base locus of the system. First question . Does the statement above refer to linear of general line bundles rather than just line bundles associated to divisors? As far as I can say, it refers to a linear system of a line bundle associated to a divisor. Tell me if I am wrong. Second question . What is the generic element? Or what is the generic pencil? In the proof, the authors start with "" If the generic element of a linear system is singular away from the base locus of the system, then the same will be true for a generic pencil contained in the system; thus it suffices to prove Bertini for a pencil. "" Third question . What does the above sentence mean exactly? Now suppose $\left \{D_{\lambda} \right \}_{\lambda \in \mathbb{P}^1}$ is a pencil Fourth question . Why do the authors write $D_{\lambda} = (f+\lambda g = 0)$ ? What do $f,g$ mean here? The last question relates to the degree of a variety (p. $171$ ). Bertini applied to the smooth locus of $V$ the generic $(n-k)$ -plane $\mathbb{P}^{n-k} \subset \mathbb{P}^n$ will intersect $V$ transversely and so will meet $V$ in exactly $\mathrm{deg}(V) = ^{\#}(\mathbb{P}^{n-k}.V)$ points. Last question . What is generic $(n-k)$ -plane? In this case, why does it intersect $V$ transversely?","['complex-analysis', 'complex-geometry', 'algebraic-geometry', 'intersection-theory']"
3791779,"$(\mathbb{Q},+) $ and $(\mathbb{Q} \times \mathbb{Q},+)$ are not isomorphic as groups","I need help in solving this assignment question in abstract algebra. Prove that $(\mathbb{Q},+) $ and $(\mathbb{Q} \times\mathbb{Q},+)$ are not isomorphic as groups . I am unable to find a property that one of group would satisfy but not other despite thinking a lot . Kindly help. Thanks!!","['group-theory', 'abstract-algebra']"
3791783,Proving existence of solution for ODE $-s\varphi' + f'(\varphi)\varphi' = \varphi''$,"Let $f : \Bbb{R} \to \Bbb{R}$ be twice differentiable with $f'' > 0$ , and let $u_- > u_+$ be real numbers. Show that there exists a solution $\varphi(x)$ to the following differential equation: $$
-s\varphi' + f'(\varphi)\varphi' = \varphi'' \tag{1}
$$ such that $\lim_{x \to \pm\infty} \varphi(x) = u_\pm$ , and where $s = \frac{f(u_+) - f(u_-)}{u_+ - u_-}$ . My initial attempt is to observe that this DE can be nicely integrated to the following: $$
\varphi' = f(\varphi) - s\varphi + C \tag{2}
$$ Thus, it suffices to show the existence of a solution for this DE instead, where we are free to choose $C$ . I attempted to bring RHS over to LHS, which gives: $$
\int \frac{1}{f(\varphi) - s\varphi + C} \; \mathrm{d}\varphi = x + D
$$ where $D \in \Bbb{R}$ . Thus, if we define: $$
g(x) = \int \frac{1}{f(x) - sx + C} \; \mathrm{d}x
$$ and assuming that $g$ is invertible, then $\varphi(x) = g^{-1}(x)$ would be a solution to $(2)$ . However, there are a few issues in this approach that we need to tackle: The integral will not make sense if $f(\varphi) - s\varphi + C$ vanishes at some point in $\Bbb{R}$ . As we are free to choose $C$ , if we can show that $f(\varphi) - s\varphi$ is bounded from either above or below, then such a choice of $C$ will exist. I suspect we can use the convexity and the definition of $s$ to prove this, but my attempts are futile so far. Should the integral make sense, another problem is if $g$ is invertible. However, this should not be an issue as by FTOC: $$
g'(x) = \frac{1}{f(x) - sx + C}
$$ so if the denominator does not vanish, $g'$ is continuous and so must be strictly positive or negative, hence $g$ is strictly monotone, thus invertible. The biggest issue here is that this definition does not guarantee the requirement of $\lim_{x \to \pm\infty} \varphi(x) = u_\pm$ . I tried to manipulate the integral to fit this condition, but to no avail so far. I also tried other approaches, such as using Picard's iteration, but as this problem is not really an IVP they have not been successful. Any help is appreciated.","['ordinary-differential-equations', 'partial-differential-equations']"
3791826,Dirichlet rings,"Dirichlet's theorem on arithmetic progressions says that given coprime $a,b\in \mathbf Z$ , there are infinitely many positive integers $n$ such that $a+bn$ is prime. Let us call a ring $R$ a Dirichlet ring if it is a domain of characteristic $0$ and we have the following: For any $a,b\in R$ , if $R=aR+bR$ , then there are infinitely many $n\in \mathbf N$ such that $a+nb$ is prime in $R$ . Let us also call $R$ weakly Dirichlet if the above holds for $a,b\in \mathbf Z$ . How big is the class of (weakly) Dirichlet rings (e.g. does it include all Dedekind domains)? Is there any other useful characterisation of either class? My guess is that a ring of integers in a number field is Dirichlet, but my knowledge of number theory is rather superficial, so I'm not very confident even about that. It is easy to see that being weakly Dirichlet implies that infinitely many prime integers remain prime in $R$ , which should restrict the range of suspects somewhat. Addendum: The variant where there are infinitely many $r\in R$ with $a+rb$ prime is also interesting.","['number-theory', 'commutative-algebra', 'prime-numbers']"
3791835,"If $x$ is a nonnegative real number, find the minimum value of $\sqrt{x^2 +4} + \sqrt{x^2 -24x+153}$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question If $x$ is a nonnegative real number, then find the minimum value of $$\sqrt{x^2 +4} + \sqrt{x^2 -24x+153}$$ How can I approach this? Thanks",['algebra-precalculus']
3791843,"Correct result for this integral $\int \frac{\sqrt{\sqrt{\sqrt{2 \cos \left(5 \sqrt{x}+4\right)+2}+2}+2}}{\sqrt{x}}\, dx$","Wolfram|Alpha and its CAS, Wolfram Mathematica are, as far as I know, the only website and software that give the correct solution to this integral , $$ f(x) = \frac{\sqrt{\sqrt{\sqrt{2 \cos \left(5 \sqrt{x}+4\right)+2}+2}+2}}{\sqrt{x}} $$ $$ F(x) = \int f(x)\, dx$$ because deriving the function given as result and using the FullSimplify function of Mathematica we get to the original function that we wanted to integrate. This is the solution: $$ F(x) = \frac{1}{5} (-8) \sqrt{2} \sqrt{\cos \left(5 \sqrt{x}+4\right)+1} \sqrt{\sqrt{2} \sqrt{\cos \left(5 \sqrt{x}+4\right)+1}+2} \left(\sqrt{\sqrt{2} \sqrt{\cos \left(5 \sqrt{x}+4\right)+1}+2}-2\right) \sqrt{\sqrt{\sqrt{2} \sqrt{\cos \left(5 \sqrt{x}+4\right)+1}+2}+2} \csc \left(5 \sqrt{x}+4\right) + C $$ Fricas finds another expression for the integral that I'm curious about: $$ F(x) = \frac{1}{5} (-8) \sqrt{2} \sqrt{\sqrt[4]{2} \sqrt{\sqrt{\cos \left(5 \sqrt{x}+4\right)+1}+\sqrt{2}}+2} \left(\sqrt{2} \cos \left(5 \sqrt{x}+4\right)-2 \sqrt{\sqrt{2} \sqrt{\cos \left(5 \sqrt{x}+4\right)+1} \left(\sqrt{\cos \left(5 \sqrt{x}+4\right)+1}+\sqrt{2}\right)+2 \sqrt{\cos \left(5 \sqrt{x}+4\right)+1}+\sqrt{2}}\right) \csc \left(5 \sqrt{x}+4\right) + C$$ However, in this video, an incorrect result is given although the integration process seems correct. As above, you know that the result is incorrect since deriving the resulting function doesn't result in the original function we wanted to integrate. Is the expression given by Fricas equivalent to the one given by Wolfram|Alpha and Mathematica ? Final update : According to Mathematica , the expression given by FriCAS is not equal to the correct solution given by Mathematica and Wolfram|Alpha. This means it is not the solution to this problem. Even though I have a Pro Premium subscription, the step-by-step solution is not available for this input. What are the steps taken by Mathematica /Wolfram|Alpha to get to the given result?","['integration', 'indefinite-integrals', 'calculus', 'wolfram-alpha']"
