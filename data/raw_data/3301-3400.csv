question_id,title,body,tags
23454,How can $\frac{1}{a/x-b/x}$ be equal to $\frac{1}{a-b}$?,"In an exercise asking to mark true or false, it shows: $$\frac{1}{a/x-b/x}=\frac{1}{a-b}$$ It really look like false to me. But the answer is true ! How can it be?","['fractions', 'algebra-precalculus']"
23466,"Rewrite equation to solve for $x$, not $y$","I am doing calculus integration, and need to show my work for Horizontal slicing (even though Vertical slicing is far easier). The equation is $$y= x/\sqrt{2x^2+1}$$ I need to rewrite the equation so that it is $x=\;...$ in order to horizontally slice it (in other words, it should be rewritten so that it is dependent on $y$). 
This isn't exactly a calculus question, although it is being used for calculus. I'm probably missing something that is pretty obvious. 
Any help would be greatly appreciated!","['calculus', 'algebra-precalculus']"
23470,Realification and Complexification of Vector Spaces,"I am interested in a good comprehensive resource on realification and complexification of vector spaces over the reals or complexes (and the interplay of these structures on the 'same' space in general). In particular, understanding of the basic theory is necessary and useful for a more intuitive approach towards functional analysis. Can you give me a tip? For example, Serge Lang's classical book does not explicitly work this part out. I am aware of a few pages in Arnold's book on ODE, but there should be something more comprehensive and neat somewhere out there.","['vector-spaces', 'linear-algebra', 'reference-request', 'abstract-algebra']"
23484,Help solving $\int {\frac{8x^4+15x^3+16x^2+22x+4}{x(x+1)^2(x^2+2)}dx}$,"$\displaystyle\int {\frac{8x^4+15x^3+16x^2+22x+4}{x(x+1)^2(x^2+2)}\,\mathrm{d}x}$ I used partial fractions, solved $A = 2, C = 3$. $$\frac{A}{x} + \frac{B}{x+1} + \frac{C}{(x+1)^2} +\frac{(Dx+E)}{(x^2+2)}$$ \begin{align*}
&8x^4+15x^3+16x^2+22x+4\\
&\quad = A(x+1)^2(x^2+2)+B(x)(x+1)(x^2+2)+C(x)(x^2+2)+(Dx+E)(x)(x+1)^2
\end{align*}
Substitute in $x=0$ to get $4=A(1)(2)$, so  $A = 2$
$$6x^4+11x^3+10x^2+14x = B(x)(x+1)(x^2+2)+C(x)(x^2+2)+(Dx+E)(x)(x+1)^2$$
Substitute in $x=-1$ to get
$$6-11+10-14 = C(-1)(1+2)$$
so $-9=-3C$, thus $C=3$. Leaving me what I have below: Which brings me to where I am currently stuck. $$6x^4 +8x^3 +10x^2+8x = B(x)(x+1)(x^2+2) + (Dx + E) (x) (x+1)^2$$ Is the next best move to use substitution to solve for $B$?","['calculus', 'integration']"
23488,Three tangent circles inside a larger circle,"Suppose you're given a circle with center $O$, I'm curious, how can one construct with ruler and compass three circles inside the larger circle such that each is tangent to the larger circle as well as to the other two?","['geometry', 'circles']"
23496,Evaluating a complex integral,"I'm having trouble figuring out how to evaluate the integral $\int_{|z|=\rho} \frac{|dz|}{|z-a|^2}$ where $|a| \neq \rho$. This is a problem in Ahlfors in the section on Cauchy's Integral Formula, and I think by convention when he says $|z|=\rho$, he means the parametrization $z=\rho e^{it}, \; 0 \leq t \leq \pi$ (so that the winding number of a point inside this circle would be 1). I'm guessing there is some smart way to apply the integral formula (since it's in this section), and I naively tried to expand the integrand. However, you end up with $\frac{1}{(z-a)(\bar{z}-\bar{a})}$, and I don't believe $\bar{z}-\bar{a}$ is an analytic function, so I'm not sure how to proceed from here.",['complex-analysis']
23503,Create unique number from 2 numbers,"is there some way to create unique number from 2 positive integer numbers? Result must be unique even for these pairs: 2 and 30, 1 and 15, 4 and 60. In general, if I take 2 random numbers result must be unique(or with very high probability unique) Thanks a lot EDIT: calculation is for computer program,so computational complexity is important","['elementary-set-theory', 'functions']"
23511,How to solve 700 = 7x + 6y for a range of values?,"Last time I did any maths was A-Level (some time ago!). This is a programming/layout problem where I need to display 7 items across a page, with 6 gaps between them. I have a fixed width, but need to determine values of x and y that are integers where x > y. This 'feels' like something I could plot on a graph, hence solve with calculus but I need a pointer in the right direction. Ideally I'd like to solve it programatically but I need an understanding of how to solve it first. Further down the line, I'd like to be able to vary the number of items to get different values. Thanks","['algebra-precalculus', 'diophantine-equations']"
23522,Proofs of the Cauchy-Schwarz Inequality?,How many proofs of the Cauchy-Schwarz inequality are there? Is there some kind of reference that lists all of these proofs?,"['inner-products', 'inequality', 'big-list', 'real-analysis']"
23524,"Textbook on ""Generating Functions"" [duplicate]","This question already has answers here : Books/Resources on generating functions (9 answers) Closed 6 years ago . I have been looking on the net for a textbook that only is about ""Generating Functions"" but did not found much. Is there any textbook just about ""Generating Functions""?","['generating-functions', 'book-recommendation', 'reference-request', 'combinatorics']"
23532,product of smooth quasi-projective varieties,"I want to show that the product of smooth quasi-projective varieties is smooth. Call my varieties $A$ and $B$. Since both are smooth, at every point the dimension of the tangent space equals the dimension of the variety. Will the dimension of $A \times B$ be the sum of the dimensions of $A$ and $B$? If so, how can I show that the same thing happens to the dimension of the tangent space at any point?",['algebraic-geometry']
23533,"How to prove that the sequence of $x_n = (1,\frac{1}{2}, \frac{1}{3}, ... \frac{1}{n}, 0, 0...)$ does not converge under $\|\cdot\|_1$?","I'm reviewing past assignments and am still having trouble formulating a proof for this: Consider the sequence $(x_n)$, where $x_n = (1,\frac{1}{2}, \frac{1}{3}, \ldots, \frac{1}{n}, 0, 0, \ldots)$. Determine whether $(x_n)$ converges in $l_1$. It's simple to show that the coordinate-wise limit does not converge, but how can I show that the coordinate-wise limit is the only possible limit? Alternatively, I'm trying to show that $(x_n)$ is unbounded, which I think should be straightforward also, but is giving me trouble.","['convergence-divergence', 'functional-analysis', 'metric-spaces']"
23544,A commutative group structure on $R\times R$ for a ring $R$,"Let $R$ be a commutative ring. The Cartesian square $A=R\times R$ is endowed with the operation $(a_1,b_1)\circ(a_2,b_2)=(a_1+a_2,b_1+b_2+a_1a_2^2+a_1^2a_2)$ which turns $A$ into a commutative group. I have two questions concerning this group. Question 1: For what $R$ is $(A,\circ)$ isomorphic to $R\oplus R$? I managed to show that if $3$ is invertible in $R$ then the isomorphism holds.
It also holds for R=F_9, but does not hold for $R=\mathbb{F}_3$, $\mathbb{F}_9$, or $\mathbb{F}_{27}$.
Other rings $R$ in which $3$ is not invertible (including $R=\mathbb{Z}$) remain a mystery to me. Question 2: When is $(A,\circ)$ generated by the elements of the form $(a,0)$, $a\in R$? Again, only partial results here. Let $B$ be the subgroup of $A$ generated by $(a,0)$, $a\in R$. Then $B$ contains $(0,a_1a_2^2+a_1^2a_2)$ for all $a_1,a_2\in R$. Hence,
we have $B=A$ if $R$ is additively generated by the elements of the form $a_1a_2^2+a_1^2a_2$. This is so for $R=\mathbb{Z}/p\mathbb{Z}$ with $p$ odd.","['commutative-algebra', 'group-theory']"
23545,Isomorphism in coordinate ring,"Let $x_{1},x_{2},...,x_{m}$ be elements of $\mathbb{A}^{n}$, where $\mathbb{A}^{n}$ is the n-affine space over an algebraically closed field $k$. Now define $X=\{x_{1},x_{2},...,x_{m}\}$. Why is the coordinate ring $A(X)$, isomorphic to $\oplus_{j=1}^{m} k = k^{m}$?",['algebraic-geometry']
23579,Proving this convergence of series,"The following theorem is in Rudin's Principles of Mathematical Analysis , 8.2: Suppose $c_n \geq 0$ and $S = \sum c_n$ converges. Put $f(x) = \sum_{n=0}^{\infty} c_nx^n$. Show that $$
\lim_{x \rightarrow 1} f(x) = \sum_{n=0}^{\infty} c_n.
$$ Rudin goes on to give a somewhat involved proof using Abel Summation. I'm wondering why this is necessary; why not just this argument? ""Proof:"" Pick $N$ such that $\sum_{n > N} c_n < \epsilon$. Pick $r$ such that $1-r^N < \epsilon/S$. Then we have $$
\sum_{n=0}^{\infty} c_n - \sum_{n=0}^{\infty} c_nr^n = \sum_{n=0}^N c_n(1-r^n) + \sum_{n>N} c_n(1-r^n) < 2 \epsilon.
$$ Briefly, Rudin's method involves using Abel summation and then bounding the new sequence of partial sums, which seems like a less natural approach to me. Does anyone have a reason why he did that?","['convergence-divergence', 'sequences-and-series']"
23596,Why is the eigenvector of a covariance matrix equal to a principal component?,"If I have a covariance matrix for a data set and I multiply it times one of it's eigenvectors.  Let's say the eigenvector with the highest eigenvalue.  The result is the eigenvector or a scaled version of the eigenvector. What does this really tell me?  Why is this the principal component?  What property makes it a principal component?  Geometrically, I understand that the principal component (eigenvector) will be sloped at the general slope of the data (loosely speaking).  Again, can someone help understand why this happens?","['statistics', 'linear-algebra', 'eigenvalues-eigenvectors', 'covariance']"
23599,How to compute the following definite integral,"Studying some integral table, I came across the following definite integral
$$\int_0^{\pi} \log [ a^2 + b^2 -2 a b \cos \phi ]\,d\phi$$ for $a,b \in \mathbb{R}$. Does somebody know a nice way to get the results?","['calculus', 'integration']"
23600,Intuition behind Conditional Expectation,"I'm struggling with the concept of conditional expectation. First of all, if you have a link to any explanation that goes beyond showing that it is a generalization of elementary intuitive concepts, please let me know. Let me get more specific. Let $\left(\Omega,\mathcal{A},P\right)$ be a probability space and $X$ an integrable real random variable defined on $(\Omega,\mathcal{A},P)$ . Let $\mathcal{F}$ be a sub- $\sigma$ -algebra of $\mathcal{A}$ . Then $E[X|\mathcal{F}]$ is the a.s. unique random variable $Y$ such that $Y$ is $\mathcal{F}$ -measurable and for any $A\in\mathcal{F}$ , $E\left[X1_A\right]=E\left[Y1_A\right]$ . The common interpretation seems to be: "" $E[X|\mathcal{F}]$ is the expectation of $X$ given the information of $\mathcal{F}$ ."" I'm finding it hard to get any meaning from this sentence. In elementary probability theory, expectation is a real number. So the sentence above makes me think of a real number instead of a random variable. This is reinforced by $E[X|\mathcal{F}]$ sometimes being called ""conditional expected value"". Is there some canonical way of getting real numbers out of $E[X|\mathcal{F}]$ that can be interpreted as elementary expected values of something? In what way does $\mathcal{F}$ provide information? To know that some event occurred, is something I would call information, and I have a clear picture of conditional expectation in this case. To me $\mathcal{F}$ is not a piece of information, but rather a ""complete"" set of pieces of information one could possibly acquire in some way. Maybe you say there is no real intuition behind this, $E[X|\mathcal{F}]$ is just what the definition says it is. But then, how does one see that a martingale is a model of a fair game? Surely, there must be some intuition behind that! I hope you have got some impression of my misconceptions and can rectify them.","['intuition', 'probability-theory', 'probability', 'faq', 'conditional-expectation']"
23607,Upper bound for $n^{3-n}\sum_{k=1}^{n/2} \binom{n-2}{k-1}k^{k-2}(n-k)^{n-k-2}$,"I am trying to upper bound the following sum: $$\sum_{k=1}^{n/2} \frac{\binom{n-2}{k-1}k^{k-2}(n-k)^{n-k-2}}{n^{n-3}}.$$ Based on numerical computations, it seems like the upper bound is a constant (there is also another complicated proof that suggested the upper bound should be a constant). Any idea how to prove this? Stirling's approximation does not seem to help: using Stirling's (in a loose way) I can show that the sum is $O(log n)$. A related bound that would imply the bound on the above sum is to show that $$ \frac{\binom{n-2}{k-1}k^{k-2}(n-k)^{n-k-2}}{n^{n-3}} \leq \frac{c}{k^2}$$ for some constant $c$. Thanks!","['upper-lower-bounds', 'sequences-and-series', 'binomial-coefficients', 'combinatorics']"
23618,What does this statement in my text mean? (Complex Analysis),"So the problem was to integrate $\overline{z}$ over the half circle of radius 2, $ z = 2e^{i \theta}$ from $z = -2i$ to $z = 2i$. After going through the math, they say 
this integral is equal to the integral over the curve of $\frac{dz}{z}$ which is equal to $\pi i $. I don't follow how this equivalence was established. I hope I provided enough detail, still learning how to use MathJax. Thanks!",['complex-analysis']
23620,Definition of conditional expectation of a random variable given another one,"Suppose $(\Omega, \mathcal{F}, P)$ is a probability space and $(U, \mathcal{\Sigma})$ is a measurable space. There seem to be two ways of defining the conditional expectation of a r.v. $X: \Omega \rightarrow \mathbb{R}$ given another r.v. $Y: \Omega \rightarrow U$, denoted as $E(X\vert Y)$: As a $\sigma(Y)$-measurable
mapping from $\Omega$ to
$\mathbb{R}$, defined as: $$E(X\vert Y) = E(X \vert \sigma(Y)). $$
where $\sigma(Y)$ is the sigma algebra of r.v. $Y$, which I think is also denoted as $Y^{-1}(\mathcal{\Sigma})$? As a $\mathcal{\Sigma}$-measurable
mapping from $U$ to $\mathbb{R}$,
defined as follows (from Wikipedia ): Define measure Q on U to be the
probability measure induced by $Y$
on $(U, \mathcal{\Sigma})$, as $Q(B)
    = P(Y^{−1}(B)), \forall B \in \mathcal{\Sigma}$. Define $E(X \vert Y)$ to be the
integrable function $g:U \rightarrow
    \mathbb{R}$ such that $$ \int_{Y^{-1}(B)} X(\omega) \ d
    \operatorname{P} = \int_{B}
    g(u) \ d \operatorname{Q},
    \forall B \in \mathcal{\Sigma}.$$ If I am correct, this definition is related to the first one as:
$$E(X \mid Y) \circ Y= E\left(X \mid Y^{-1} \left(\Sigma\right)\right). $$ I was wondering which of the above two is the definition of $E(X \mid Y)$? Thanks and regards! References (links or books) will also be appreciated!",['probability-theory']
23625,Function that maximizes a function,"Let's say we have a real, continuous,
  positive function f(x) for which we
  define the quantity: $$\pi(f,a) = \frac{\int_0^a f(x)
 dx}{\int_0^a \sqrt{1+\left(\frac{df(x)}{dx}
 \right)^2 }dx}$$ we want to find the function f that maximizes $\pi$ for a given $a$. In general how do we attack problems of this kind: find $f$ such that  $\mathrm{F}(f)$ is maximum? Are there any constrains that guarantee that there is an analytical solution? How could the problem above be modified to have a solution?","['optimization', 'calculus-of-variations', 'functions']"
23646,Möbius transformations and concentric circles,"Given a Möbius transformation that maps one pair of concentric circles to another pair of concentric circles, why is the ratio of the radii preserved through the map? I thought about how Möbius transformations are compositions of rotations, scaling, inversion, and translation, and that intuitively, these types of maps shouldn't change the ratio of radii between two circles. Would it be correct to just say that if $\frac{r_1}{r_2}$ is the ratio of radii between the two circles, then 1) The radii are invariant under translation, $z \mapsto z+a$, so $\frac{r_1}{r_2}$ stays the same 2) Under scaling by a factor $z \mapsto az$, $\frac{ar_1}{ar_2} = \frac{r_1}{r_2}$ 3) Under inversion, $z \mapsto \frac{1}{z}$, $\frac{1/r_1}{1/r_2} = \frac{r_2}{r_1}$ Or is there a different/better way to think about this problem?",['complex-analysis']
23655,What is a quotient ring and cosets?,"So I am trying to understand what a coset is and what a quotient ring is. So I am going to tell you guys what I know. And please let me know if my thinking is right or wrong, and if I am missing something. For the rest of this post, assume $R$ is a ring and $I$ is an ideal of that ring. So $I = (m)$ is a principal ideal generated by $m$ where $m \in R$. Now the congruence class of $a$ and $I$ is denoted by $[a]_m$ but this congruence class can also be written as $a + (m)$ or simply $a + I$. 
now this congruence class is obviously a set. So is this the coset of it? So for any $a$ that you choose in $R$ and you ""add"" the ideal to it (generated by m which is also in $R$) you get a coset. The quotient ring $R/I$ just means ALL the cosets of $I$ in $R.$ So does this say that if hypothetically speaking $m = 3,$ then $1 + (3)$ is one coset, $2 + (3)$ is another coset and hence the quotient ring is ALL the cosets for every possible $a?$ I hope I make sense. If someone could send me a link to an easy (introduction to algebra) article or a ""tutorial"", that would be appreciated. I am using Hungerford Algebra. If anyone can explain this to me in easy english, that is appreciated. Thanks",['abstract-algebra']
23658,What are the postulates that can be used to derive geometry?,What are the various sets of postulates that can used to derive Euclidean geometry? It might be nice to have several different approaches together for comparison purposes and for ready reference. It might also be interesting to include an axiomatization (or two) of elliptical geometry.,"['geometry', 'axioms', 'big-list', 'euclidean-geometry']"
23667,When a conditional probability becomes a mapping to probability measures,"In the Wikipedia article for conditional expectation ,  conditional probability is defined in terms of conditional expectation. Given a sub sigma algebra of the one
on a probability space. Given a probability space $(\Omega,
\mathcal{F}, P)$ , a conditional
probability $P(A \mid \mathcal{B})$ of a measurable subset $A \in
\mathcal{F}$ given a sub sigma
algebra $\mathcal{B}$ of $\mathcal{F}$ , is defined as the
conditional expectation $E(A \mid
\mathcal{B})$ of indicator function $1_A$ of $A$ given $\mathcal{B}$ ,
i.e. $$ P(A \mid \mathcal{B}): = E(1_A
\mid \mathcal{B}), \forall A \in
\mathcal{F}.$$ So actually the conditional
probability $P(\cdot \mid
\mathcal{B})$ is a mapping $: \Omega
\times \mathcal{F} \rightarrow
\mathbb{R}$ . A conditional probability $P(\cdot
\mid \mathcal{B})$ is called regular if $P(\cdot|\mathcal{B})(\omega),
\forall \omega \in \Omega$ is also a
probability measure. Question: What are some
necessary and/or sufficient
conditions for a conditional
probability $P(\cdot \mid
\mathcal{B})$ to be regular? Given a random variable on a probability space. Suppose $(\Omega, \mathcal{F}, P)$ is a probability space and $(U,
\mathcal{\Sigma})$ is a measurable
space. There seem to be two ways of
defining the conditional expectation $E(X\mid Y)$ of a r.v. $X: \Omega
\rightarrow \mathbb{R}$ given
another r.v. $Y: \Omega \rightarrow
U$ , either as a $\sigma(Y)$ -measurable mapping $:
\Omega \rightarrow \mathbb{R}$ , or
as a $\Sigma$ -measurable mapping $:
U \rightarrow \mathbb{R}$ ,  as in
my previous post . If one let $X$ to be the indicator
function $1_A$ for some $A \in
\mathcal{F}$ , one can similarly
define $E(1_A \mid Y)$ to be
conditional probability of $A$ given $Y$ , denoted as $P(A\mid Y)$ .
Therefore $P(\cdot \mid Y)$ is a
mapping $: \Omega \times \mathcal{F}
\rightarrow \mathbb{R}$ or a mapping $: U \times \mathcal{F} \rightarrow
\mathbb{R}$ . Questions: (1). What are some necessary and/or
sufficient conditions for $P(\cdot
    \mid Y)$ to be regular, i.e. to be a
mapping $: \Omega \rightarrow \{
    \text{probability measures on
    }(\Omega, \mathcal{F}) \}$ or a
mapping $: U \rightarrow \{
    \text{probability measures on
    }(\Omega, \mathcal{F}) \}$ ? (2). Under what kinds of conditions, will $P(X \mid Y)$ defined as above be
equal to the ratio $\frac{P(X, Y)}{P(Y)}$ , the
definition used in elementary
probability? Thanks and regards! References (links or books) will also be appreciated!",['probability-theory']
23668,Proving $0$ is an ordinal,"In Introduction to Set Theory by J. Donald Monk, he defines ordinal as follows. Definition (1): $A$ is an ordinal iff $A$ is $\in$-transitive and each member of $A$ is $\in$-transitive. $A$ is $\in$-transitive iff for all $x$ and $y$ , $x \in y \in A \implies x \in A$. And using definition (1), I have a problem of showing  $0$ is an ordinal. My solution: Let $x \in y \in 0$, then show that $x \in 0$, but in the theorem shown before this, there cannot exist an $x \in 0$ for any $x$, for if $x \in 0$, then $x$ is a set and $x \neq x$, which is absurd. Hence  there cannot be an $x$ such that $x\in 0$ .But if this is the case, we cannot shown the above theorem by definition. Any ideas? thanks for your help. Edit: Initially I have 2 question to ask. But later on, I have found the answer to my first question. That is why I deleted it and the question post above is my second question.","['ordinals', 'elementary-set-theory']"
23669,property about topological space,"I have a question. Let $f,g$ be continuous functions from $X$ to $Y$, $X$ is a topological space and $Y$ a topological space under ordered topology. Then prove that the set $\{x \in X \ | \ f(x) < g(x)\}$ is open.
  I want to know that what intrisic property of order makes it possible.",['general-topology']
23674,How to find the integral closure of $\mathbb{Z}_{(3)}$ in the field $\mathbb{Q}(\sqrt{-5})$?,"Let $v$ be the 3-adic valuation on $\mathbb{Q}$ and consider the subring $\mathbb{Z}_{(3)}$ of $\mathbb{Q}$ defined by
$$
\mathbb{Z}_{(3)} = \{ x \in \mathbb{Q} : v(x) \geq 0  \}.
$$
That is, $\mathbb{Z}_{(3)}$ is the ring of rational numbers that are integral with respect to $v$.  $\mathbb{Z}_{(3)}$ is also the localization of $\mathbb{Z}$ at the prime ideal $(3)$.  I know $\mathbb{Z}_{(3)}$ is integrally closed in $\mathbb{Q}$. I want to find the integral closure of $\mathfrak{O}$ in the field $\mathbb{Q}(\sqrt{-5})$:
$$
\overline{\mathbb{Z}_{(3)}} = \{x \in  \mathbb{Q}(\sqrt{-5})  : x \text{ is a root of a monic irreducible polynomial with coefficients in } \mathbb{Z}_{(3)} \}
$$ How can I do this?  What should I be thinking about?","['algebraic-number-theory', 'number-theory']"
23686,cones in the derived category,"If I have two exact triangles $X \to Y \to Z \to X[1]$ and $X' \to Y' \to Z' \to X'[1]$ in a triangulated category, and I have morphisms $X \to X'$, $Y \to Y'$ which 'commute' (i.e., such that $X \to Y \to Y' = X \to X' \to Y'$), thene there exists a (not necessarily unique) map $Z \to Z'$ which completes what we've got to a morphism of triangles. Is there a criterion which ensures the uniqueness of this cone-map? I'd like something along the lines of: if $\operatorname{Ext}^{-1}(X,Y')=0$ then yes. (I might be too optimistic, cfr. Prop 10.1.17 of Kashiwara-Schapira Categories and Sheaves : in addition to $\operatorname{Hom}{(X[1],Y')} = 0$ they also assume $\operatorname{Hom} {(Y,X')} =0$. I really don't have this second assumption.) (In the case I'm interested in $X=X', Y=Y'$ and $X\to X'$, $Y \to Y'$ are the identity maps.) (If it makes things easier, although I doubt it, you can take the category to be the bounded derived category of coherent sheaves on some, fairly nasty, scheme.) In the context I have in mind $X, Y, X', Y'$ are all objects of the heart of a bounded t-structure. If we assumed $\operatorname{Hom}{(Z,Y')} = 0$ or $\operatorname{Hom}{(X[1],Z')} = 0$ then the result easily follows. I don't think I'm happy making those assumptions though.","['category-theory', 'homological-algebra', 'algebraic-geometry', 'triangulated-categories']"
23687,Relation between Borel–Cantelli lemmas and Kolmogorov's zero-one law,"I was wondering what is the relation between the first and second Borel–Cantelli lemmas and Kolmogorov's zero-one law ? The former is about limsup of a sequence of events, while the latter is about tail event of a sequence of independent sub sigma algebras or of independent random variables . Both have results for limsup/tail event to have either probability 0 or 1. I guess there are relations between but cannot identify them. Can the former be viewed as a special case of the latter? How about in reverse direction? Thanks and regards!","['probability-theory', 'borel-cantelli-lemmas', 'measure-theory', 'independence']"
23692,How does a hyperplane become a linear bundle?,"As we know,a hyperplane can seem as a divisor,and a divisor can become a linear bundle,I want to know what the structure of linear bundle is.
For example, the hyperplane is given by $a_0 z_0+a_1 z_1+\ldots+a_n z_n=0$,what is the projective map、transform function and so on?",['algebraic-geometry']
23695,Cantor–Bernstein–Schröder theorem and recursion,"I am poking on a proof of the subject theorem. Given sets $A_i$ and injections $f_i:A_i\to A_{1-i}$, $i\in \{0,1\}$, theorem defines a bijection $b$ between $A_0$ and $A_1$. $b$ uses an auxilary function $degree (x:A_i) := \cases{
1+degree(f_{1-i}^{-1}(x)), x\in f_{1-i}(A_{1-i}) \cr 0}$ “degree” may loop, denote this $\bot$. Then $b$ returns some value$\neq\bot$ on $\bot$ and is not constant in general. $b$ solves the halting problem. So, it is possible? (I assume that the codomain of “degree” is a flat domain.) (I have not posted this on cstheory because this is not a research-level question.)","['computer-science', 'elementary-set-theory']"
23699,Sobolev space on closed subset of the real line,"Everywhere I look in the literature, Sobolev spaces are defined on an open subset of the real line. What are the technical issues with defining a Sobolev space on a closed subset, i.e. are there problems at the boundary, and does anyone know any good references that cover this? My main purpose is to prove $H^1([0,T];\mathbb{R}) = 
\{ x \in L^2([0,T];\mathbb{R}) : ||x'||_{L^2} + \gamma^{2}||x||_{L^2} < \infty \}$ is a reproducing kernel Hilbert space. I can do this for $(0,T)$ and want to know if the proof is transferable to the case of the closed interval $[0,T]$. Many thanks, Matthew.","['sobolev-spaces', 'analysis']"
23705,How to invert this exponential function to solve for x:  $y = a \exp(bx) + c \exp(dx)$?,"Cheers. So if I don't make sense, I have a value for $y$, I need to know what $x$ is. $$y = a \exp(bx) + c \exp(dx)$$ $a =       12.85$,
$b =    0.001857$,
$c =      -54.24$,
$d =    -0.05316$","['inverse', 'functions']"
23712,Conditional expectation and independence,"Consider conditional expectation of
a real-valued r.v. $X$ given a sub
sigma algebra $\mathcal{B}$ of the
probability space $(\Omega,
    \mathcal{F}, P)$. Will independence between
$\sigma(X)$, i.e. the sigma algebra
of the r.v., and the given sub sigma
algebra $\mathcal{B}$ make $E(X \mid
    \mathcal{B}) \equiv E(X)$ ? Is independence between $\sigma(X)$
and the given sub sigma algebra
$\mathcal{B}$ is the only way to
define independence between $X$ and
$\mathcal{B}$? If there are other ways, will they
make $E(X \mid \mathcal{B}) \equiv
    E(X)$ ? Consider conditional expectation of
a real-valued r.v. $X$ given another
$S$-valued r.v. $Y$ on the same
probability space $(\Omega,
    \mathcal{F}, P)$. Will independence between $X$ and
$Y$ make $E(X \mid Y) \equiv E(X)$ ? Why? References are also appreciated!
Thanks and regards!",['probability-theory']
23714,Distance between a polytope and a point,How to calculate the distance between a convex polytope and a point? Polytope is specified as the solution to the system of linear inequalities. I'm looking for the method that is computationally efficient.,"['optimization', 'geometry', 'polytopes', 'computational-geometry']"
23723,What types of geometries are scale-invariant?,"This question explains that scale-invariance (or more accurately, similarity) is an important property of Euclidean geometry. Are there any other ways to define scale-invariant geometries in any sense? And how do they differ from Euclidean geometry?","['geometry', 'euclidean-geometry']"
23724,"set theory problems (well-ordered sets, countability, Zorn's Lemma, ...)","Let $A \subseteq P(\omega)$, where $\omega$ is the set of all natural numbers and $P(\omega)$ is the power set of $\omega$. If $\langle A,\subseteq\rangle$ is a well ordered set how can you prove that $A$ is a countable set. Let $A$ be a set which elements are closed sets of real numbers. If $\langle A,\subseteq\rangle$ is a well ordered set how can you prove that $A$ is a countable set. How can you prove that Zorn's lemma (so and the axiom of choice) is equivalent to that for every partially ordered set $\langle A,\le\rangle$ that satisfies Zorn's condition, for every $b\in A$ there exists a maximum element $a$ for which $b\le a$.",['elementary-set-theory']
23729,What is the condition for a field to make the degree of its algebraic closure over it infinite?,"As we all know , the algebraic closure often has an infinite degree. Also, this shows the necessary and sufficient condition for a Galois extension to be a finite extension of fields. However, we may want to characterize the cases of the case where the extension is not Galois, which is actually my question. And this question is related to this question .","['galois-theory', 'abstract-algebra', 'field-theory']"
23734,Is there a definite integral for which the Riemann sum can be calculated but for which there is no closed-form antiderivative?,"Some definite integrals, such as $\int_0^\infty e^{-x^2}\,dx$, are known despite the fact that there is no closed-form antiderivative. However, the method I know of calculating this particular integral (square it, and integrate over the first quadrant in polar coordinates) is not dependent on the Riemann sum definition. What I thought might be interesting is a definite integral $\int_a^bf(x)\,dx$ for which the limit of the Riemann sums happens to be calculable, but for which no closed-form antiderivative of $f$ exists. Of course there are some obvious uninteresting examples, like integrating odd functions over symmetric intervals, but one doesn't need Riemann sums to calculate these uninteresting examples. Edit: To make this a bit clearer, it would be nice to have a ""natural"" continuous function $f(x)$ where by some miracle $\lim_{n\to\infty} \sum_{i=1}^nf(x_i)\Delta x$ is computable (for some interval $[a,b]$) using series trickery, but for which no antiderivative exists composed of elementary functions.",['calculus']
23739,Local triviality of principal bundles,"Suppose I define a principal $G$-bundle as a map $\pi: P \to M$ with a smooth right action of $G$ on $P$ that acts freely and transitively on the fibers of $\pi$.  Does it follow that $P$ is locally isomorphic to $M \times G$ with the obvious right action of $G$ on $M \times G$?  Let's suppose $M$ is a manifold. I know that fiber bundles over a contractible set are trivial and a manifold is locally contractible, but I believe this statements refers to locally trivial fiber bundles and so will not apply to this case. A related question is: if we have a fibration such that the base space is contractible and all fibers are homeomorphic, does it follow that the fibration is just the product of the base with the fiber? Thanks!","['fiber-bundles', 'principal-bundles', 'algebraic-topology', 'differential-geometry']"
23740,Which books for refreshing high school algebra?,"I'll take a Calculus course next year, and my professor suggested reviewing high school algebra.","['book-recommendation', 'algebra-precalculus', 'reference-request']"
23748,Largest known integer,"Does there exist a property which is known to be satisfied by only one integer, but such that this property does not provide a means by which to compute this number? I am asking because this number could be unfathomably large. I was reading Conjectures that have been disproved with extremely large counterexamples? , does there exist a conjecture that is known to have a counterexample, but which has not been found, and where there is no ""bound"" on the expected magnitude of this integer? Is there known something about how the largest integer that is expressable in n symbols, grows with n?","['intuition', 'number-theory']"
23759,On the existence of closed form solutions to finite combinatorial problems,"Is it possible that a finite combinatorial problem may admit a closed form solution, and for it to be impossible in practice to prove the validity of this solution? I'm not sure if a rigorous definition can be given to the notion of a finite combinatorial problem, but I mean problems of the following nature: Given a set finite set $X$, which may or may not have additional structure, enumerate the number of elements in $X$ which satisfy some constraint defined in terms of the primitives of set theory and the additional structure of $X$. Since we are speaking of closed form solutions, we are really interested in families of finite combinatorial problems, parametrized by $\mathbb{N}$, which
scale in some natural way with increasing $n\in \mathbb{N}$. I'm not sure if the notion of a closed form solution can be given a rigorous definition, but I mean something along the lines of the following definition from Graham, Knuth, and Patashnik's Concrete Mathematics : An expression for a quantity $f\left(n\right)$ is in closed form if we can compute it using at most a fixed number of ""well known"" standard operations, independent of $n$. I understand that this question is vague and open ended, so I would be happy with answers or partial answers to any of the following subquestions. Are there examples of finite combinatorial problems for which empirical evidence suggests there is a closed form solution, but for which significant effort has failed to produce any proofs of the validity of this solution? Is it possible to give a rigorous axiomatization that captures the notion of of a finite combinatorial problem that working combinatorialists work with, and then bring to bear ideas along the lines of Godel's Theorems and Turing's work on the Halting Problem to produce an existence proof for such families of combinatorial problems? Can any rigorous formulation be given to the notion of a family of finite combinatorial problems scaling naturally with $n\in\mathbb{N}$? Are there examples of finite combinatorial problems which display a kind of regularity for large $n$. That is, are there any known families of finite combinatorial problems that scale naturally with $n\in\mathbb{N}$, such that $f\left(n\right)$, the answer to the problem associated to $n$, behaves haphazardly for small $n$, but can then be given in terms of a closed form expression for sufficiently large $n$? Is there anything to suggest that difficult combinatorial problems that have been studied, but for which little is known, may display this kind of regularity? Finally, are there any results in mathematical logic, set theory, or proof theory of which I am unaware, that render my question trivial or foolish? I would appreciate any help with this question that can be given. As someone with a decent background in combinatorics, but no deep knowledge of logic or set theory, I don't know where to begin with this. Edit:(In response to a comment of Qiaochu Yuan)
$n$ need not be the size of $X$. I hope this example should clarify what I'm trying to get at. Consider the problem of enumerating the permutations of the elements of a finite set $X$ of cardinality $n$. This problem may be cast as the following problem. Enumerate the elements of $X^n$, $\left(x_0,\ldots ,x_{n-1}\right)$, for which
$x_i = x_j$ if and only if $i = j$. The problem has solution $n!$, which may or may not be considered closed, depending on what you mean by ""well known"" in Knuth's definition. The answer to this problem is dependent only on the size of $X$, not on any interpretation of what the elements might be. In a sense, the problems of this manner could be said to scale naturally with $n$. Part of my question is to provide a rigorous definition of what I mean by scale naturally.","['proof-theory', 'logic', 'combinatorics']"
23763,"Where are this kind of series used, $\vartheta_{4}(0,e^{\alpha \cdot z})$?","In my recent explorations I stumbled upon the following series $$
\vartheta_{4}(0,e^{\alpha \cdot z})=1+2\sum_{k=1}^{\infty} (-1)^{k}\cdot e^{\alpha \cdot z\cdot k^{2}} ; \alpha \in  \mathbb{R}, z \in \mathbb{C}
$$ This is one of the well known  Jacobi theta functions/series with the peculiarity of having the variable $z \in \mathbb{C}$ in a different place, i.e. $e^{\alpha \cdot \mathbf{z} \cdot k^{2}}$!! The usual form of the theta function is \begin{align*}
\vartheta_{4}(z,e^{\alpha })=1+2\sum_{k=1}^{\infty} (-1)^{k}\cdot e^{\alpha \cdot k^{2}}\cos(2kz) ; 
\end{align*} but not in the case I have in hands. Does the former formula make any sense? Where are this kind of series used or analysed ? (Apart from the well known case of $$\psi(x)=\sum_{n=1}^{\infty}e^{-n^{2}\pi x}=\frac{1}{2} \left[ \vartheta_{3}(0,e^{-\pi x})-1 \right]$$
used in the context of the Riemann zeta-function.)","['special-functions', 'sequences-and-series', 'number-theory', 'theta-functions', 'complex-analysis']"
23775,Limit a.e. of a sequence measurable functions is measurable,"I'm having trouble showing the following: If $f_n$ is a sequence of measurable functions such that $f_n$ converges to $f$ almost everywhere, then $f$ is measurable. I was thinking of using $\limsup$ since I know that $\limsup f_n$ is measurable. But now I'm not sure how to continue my argument.",['measure-theory']
23776,Interpretation of sigma algebra,"My question is how to interpret sigma algebra, especially in the context of probability theory (stochastic processes included). I would like to know if there is some clear and general way to interpret sigma algebra, which can unify various ways of saying it as history, future, collection of information, size/likelihood-measurable etc? Specifically,I hope to know how to interpret the following in some consistent way: being given/conditional on a sigma algebra a subset being measurable or nonmeasurable w.r.t. a sigma
algebra a mapping being measurable or nonmeasurable w.r.t. a
sigma algebra in domain and another
sigma algebra in codomain a collection of increasing sigma algebras, i.e. a filtration of sigma algebras ... Following are a list of examples that I have met. They are nice examples, but I feel their ways of interpretation are not clear and consistent enough for me to apply in practice. Even if there is no unified way to interpret all the examples, I would like to know what some different ways of interpretation are. Stopping time Let $(I, \leq)$ be an ordered index
  set, and let $(\Omega, \mathcal{F},\mathcal{F}_t, \mathbb{P})$ be a
  filtered probability space. Then a random variable $\tau : \Omega \to I$ is called a stopping time if
  $\{ \tau \leq t \} \in \mathcal{F}_{t} \forall t \in I$. Speaking concretely, for τ to be a
  stopping time, it should be possible
  to decide whether or not $\{ \tau \leq t \}$ has occurred on the basis of the
  knowledge of $\mathcal{F}_t$, i.e.,
  event $\{ \tau \leq t \}$ is
  $\mathcal{F}_t$-measurable. I was still wondering how exactly to ""decide whether or not $\{ \tau \leq t \}$ has occurred on the basis of the knowledge of $\mathcal{F}_t$, i.e., event $\{ \tau \leq t \}$ is  $\mathcal{F}_t$-measurable."" Martingale process If a stochastic process $Y : T \times \Omega \rightarrow S$ is a martingale
  with respect to a filtration $\{ \Sigma_t\}$ and probability measure
  $P$, then  for all s and t with $s < t$ and all $F \in \Sigma_s$,
          $$Y_s = \mathbf{E}_{\mathbf{P}} ( Y_t | \Sigma_s ),$$ where $\Sigma_s $ is interpreted as ""history"". I was also wondering how $\Sigma_s, s < t$ can act as history, $\Sigma_s, s=t$ as present, and $\Sigma_s, s > t$ as future? I originally interpret a measurable
subset wrt a sigma algebra as a
subset whose ""size""/""likelihood""  is measurable,
and the class of such
size-measurable subsets must be
closed under complement and
countable union. In a post by Nate Eldredge , a
measurable subset wrt a sigma
algebra is interpreted by analogy of questions being answered: If I know the answer to a question
  $A$, then I also know the answer to
  its negation, which corresponds to the
  set $A^c$ (e.g. ""Is the dodo
  not-extinct?"").  So any information
  that is enough to answer question $A$
  is also enough to answer question
  $A^c$.  Thus $\mathcal{F}$ should be
  closed under taking complements. 
  Likewise, if I know the answer to
  questions $A,B$, I also know the
  answer to their disjunction $A \cup B$
  (""Are either the dodo or the elephant
  extinct?""), so $\mathcal{F}$ must also
  be closed under (finite) unions. 
  Countable unions require more of a
  stretch, but imagine asking an
  infinite sequence of questions
  ""converging"" on a final question. 
  (""Can elephants live to be 90? Can
  they live to be 99? Can they live to
  be 99.9?"" In the end, I know whether
  elephants can live to be 100.) Thanks in advance for sharing your views, and any reference that has related discussion is also appreciated!","['probability-theory', 'stochastic-processes', 'measure-theory']"
23790,"Prime ideals: definition, verification, and examples","So the question states that the intersection of two prime ideals is always a prime ideal. Well this is false but I need an example to counter it. I looked online and found one ""For example, inside $\mathbb Z, 2 \mathbb Z$ and $3\mathbb Z$ are prime, but there intersection, $6\mathbb Z$ is not prime"" so I just need some explanation to what a prime ideal is and how you can determine that an ideal is prime. The definition I know of is Let $R$ be a comm. ring with identity. An ideal P is prime iff $R \neq P$ and whenever $bc \in P$ then $b \in P$ or $c \in P$ I dont know how to apply this definition to the example above.",['abstract-algebra']
23808,coin toss question,"Two players A and B each has a fair coin and they start to toss simultaneously (counted as one round). They toss in $n$ ($\ge 1$) rounds and stop because they have accumulated the same number of heads (could be 0, the case that both of them did not get any head) for the first time. What is the distribution of $n$ and its expectation?",['probability']
23817,Some basics of Sobolev spaces,"Let $W^{m,p}(\Omega) = \{ f \in L^p(\Omega): D^\alpha f \in L^p(\Omega) \text{ for multi-indices } |\alpha| \leq m\}$, where $D$ denotes the weak derivative. Let $W_0^{m,p}$ denote the closure of $C_c^\infty(\Omega)$ in $W^{m,p}(\Omega)$. Why is it true that $W_0^{m,p}(\mathbb{R}^d) = W^{m,p}(\mathbb{R}^d)$, but in general $W_0^{m,p}(\Omega) \subsetneq W^{m,p}(\Omega)$? I am trying to understand why there is a need to consider $W_0^{m,p}(\mathbb{R}^d)$. I'm guessing it's because the elements in $W^{m,p}(\Omega)$ can get really messy, but I don't have very good intuition about both spaces.","['sobolev-spaces', 'functional-analysis', 'real-analysis']"
23844,The ring $\Bbb Z\left [\frac{-1+\sqrt{-19}}{2}\right ]$ is not a Euclidean domain,"Let $\alpha = \frac{1+\sqrt{-19}}{2}$. Let $A = \mathbb Z[\alpha]$. Let's assume that we know that its invertibles are $\{1,-1\}$. During an exercise we proved that: Lemma: If $(D,g)$ is a Euclidean domain such that its invertibles are $\{1,-1\}$, and $x$ is an element of minimal degree among the elements that are not invertible, then $D/(x)$ is isomorphic to $\mathbb Z/2\mathbb Z$ or $\mathbb Z/3\mathbb Z$. Now the exercise asks: Prove that $A$ is not a Euclidean Domain. Everything hints to an argument by contradiction: let $(A, d)$ be a ED and $x$ an element of minimal degree among the non invertibles we'd like to show that $A/(x)$ is not isomorphic to $\mathbb Z/2\mathbb Z$ or $\mathbb Z/3\mathbb Z$. How do we do that? My problem is that, since I don't know what this degree function looks like, I don't know how to choose this $x$! I know that the elements of $A/(x)$ are of the form $a+(x)$, with $a$ of degree less than $x$ or zero. By minimality of $x$ this means that $a\in \{0, 1, -1\}$. Now I'm lost: how do we derive a contradiction from this?","['principal-ideal-domains', 'ring-theory', 'euclidean-domain', 'abstract-algebra']"
23851,Question on the notion of a $\sigma$-algebra generated by a function,"I've started learning about measure theory and I'm trying to get some intuitive grasp of the basic concepts. This is only succeeding partially so far. There is an exercise which I don't quite understand. Here it is: Let $\Omega$ be the set of all sequences $\omega = (\omega_1,\omega_2,\ldots)$  where $\omega_n \in \{0,1\}$  $\forall n \geq 1$. Define for all $n$ the projections $p_n:\Omega \rightarrow \{0,1\}$ and let $\mathcal{F}_n = \sigma(p_1,\ldots,p_n)$. Prove that $\mathcal{F}_1 \subseteq \mathcal{F}_2 \subseteq \ldots$ The course material that I'm using defines the $\sigma$-algebra of a function in the context of borel sets $B \in \mathcal{B}(\mathbb{R})$, as in $\sigma(f) = \{\{f \in B\} : B \in \mathcal{B}(\mathbb{R})\}$ where $\{f \in B \} = \{\omega \in \Omega : f(\omega) \in B\}$ I have two questions about this exercise: 1) Is a $\sigma$-algebra generated by some function $f$ always defined in the context of Borel-algebras? Ie, in the case of our functions $p_i$, should we think of $p_i$ as a function mapping some sequence $\omega$ to $\{0,1\} \subseteq (a,b)$ for some $a,b \in \mathbb{R}$? 2) How should I read $\sigma(p_1)$? Because I'm having trouble connecting the nature of $p_i$ with the aformentioned definition of $\sigma(f)$.",['measure-theory']
23861,Archimedean property of $\mathbb{R}$,"Theorem:
If $x,y \in \mathbb{R}$ and $x > 0$, $\exists$ a positive integer $n$ such that $nx > y$ I read the proof by Rudin and understood it. I think it is very elegant and uses the LUB property of $\mathbb{R}$. But the way I tried to prove it is the following: If $x > y$, then $n = 1$. If $x < y$, then $y > 0$ and it makes sense to define $m = \frac{y}{x}$. $m \in \mathbb{R}$ using one of the field axioms. Since the set of natural numbers is unbounded $\exists n \in \mathbb{N}$ such that $n > m$. This implies $nx > y$. This proves the Archimedean property. Is there something wrong with the proof or am I assuming something that is not obvious? This is something I frequently wonder while I am trying to learn analysis. I really like the way Rudin proves the theorems in his book. But I find it really difficult to adapt that kind of thinking and rigor. I think a big reason why I find this difficult is because I have an engineering background and I am never used to being so rigorous with proofs. Can anyone suggest some tips (or your experience) that deal with improving the ability to write rigorous proofs (and the ability to find logical gaps in proofs).","['soft-question', 'analysis']"
23874,Motivation for the proof of Eisenstein's Criterion for irreducibility of polynomials,"I have been thinking about this for quite sometime. Eisenstein Criterion for Irreducibility: Let $f$ be a primitive polynomial over a unique factorization domain $R$ , say $$f(x)=a_0 + a_1x + a_2x^2 + \cdots + a_nx^n \;.$$ If $R$ has an irreducible element $p$ such that $$p\mid a_m\ \text{ for all }\ 0\le m\le n-1$$ $$p^2 \nmid a_0$$ $$p \nmid a_n$$ then $f$ is irreducible. Can anyone give me an explanation of how one might have conjectured this problem ? Thinking along, the same lines the first polynomial which came to my mind was $x^{2}+1 \in \mathbb{R}[x]$ which is irreducible. But there are lots of polynomials and it's very difficult to think of a condition, which would make them irreducible.","['motivation', 'irreducible-polynomials', 'number-theory', 'abstract-algebra', 'unique-factorization-domains']"
23879,"Projective, Quasi-Projective","X is a projective variety, W is a quasi-projective variety over the algebraically closed ﬁeld k. I would like to construct a k-algebra isomorphism between O(XxW) and O(W) (the rings of regular functions). On the level of varieties I know that the projection XxW->W maps closed sets to closed sets. I feel like this should lead me to the algebra, but I have no idea how I would define the map going the other way.",['algebraic-geometry']
23885,Why events in probability are closed under countable union and complement?,"In probability,  events are considered to be closed under countable union and complement, so mathematically they are modeled by $\sigma$-algebra.  I was wondering why events  are considered to be closed under countably union and complement? In Nate Eldredge's post , he has done an excellent job on explaining this, by using whether questions are answered or not as an analogy to whether events occur or not, if I understand his post correctly. However, if someone could explain plainly without analogy, it could be clearer to me. I was particularly curious why events are not considered to be closed under infinite (possibly uncountably) union, but instead just under countably union? So possibly to model events using the power set? I think this is not addressed in Nate Eldredge's post . My guess would be that the reason might be related to the requirement on the likelihood of any event to occur to be ""measurable"" in some sense. But how exactly to understand this requirement is unclear to me. PS: This post is related to my previous one Interpretation of sigma algebra , but the questions asked in these two are not the same. Thanks and regards!","['probability-theory', 'measure-theory']"
23886,generalizations of determinant and trace,"There are $n$ symmetric polynomials in the eigenvalues of a square matrix. Two of these are the determinant and the trace, each of which have countless applications and interpretations in algebra and geometry. What about the other symmetric polynomials? They are also similarity invariants, yet I've never seen them used or referenced. Are there any geometric interpretations, or applications, for these other invariants?",['linear-algebra']
23899,Formulas for the (top) coefficients of the characteristic polynomial of a matrix,"The characteristic polynomial of a matrix $A$ is defined as: $$\chi(A) = \det(xI-A) = \sum_{i=0}^n (-1)^i\cdot \operatorname{tr}^{(i)}(A) \cdot x^{n-i}$$ The trace is the sum of the eigenvalues of a matrix, tr(A) = tr (1) (A).  It is also the sum of the diagonal entries: $$\operatorname{tr}(A) = \sum_{i=1}^n A_{ii}$$ The sum of the products of pairs of eigenvalues is like the next trace. Is this formula valid? $$\operatorname{tr}^{(2)}(A) = \sum_{1 \leq i < j \leq n } A_{ii} A_{jj} - A_{ij} A_{ji}$$ What about this one? $$\operatorname{tr}^{(2)}(A) = \tfrac12(\operatorname{tr}(A)^2 - \operatorname{tr}(A^2))$$ Are there corresponding formulas for the next one, tr (3) ?","['matrices', 'linear-algebra', 'determinant']"
23902,What is the practical difference between a differential and a derivative?,"I ask because, as a first-year calculus student, I am running into the fact that I didn't quite get this down when understanding the derivative: So, a derivative is the rate of change of a function with respect to changes in its variable, this much I get. Thing is, definitions of 'differential' tend to be in the form of defining the derivative and calling the differential 'an infinitesimally small change in x', which is fine as far it goes, but then why bother even defining it formally outside of needing it for derivatives? And THEN, the bloody differential starts showing up as a function in integrals, where it appears to be ignored part of the time, then functioning as a variable the rest. Why do I say 'practical'? Because when I asked for an explanation from other mathematician parties, I got one involving the graph of the function and how, given a right-angle triangle, a derivative is one of the other angles, where the differential is the line opposite the angle. I'm sure that explanation is correct as far it goes, but it doesn't tell me what the differential DOES, or why it's useful, which are the two facts I need in order to really understand it. Any assistance?",['calculus']
23909,Help solving a limit,"While helping a friend out for an exam (last year of high school), I found an exercise that neither of us could solve. I've tried a couple of different approaches but nothing seemed to work. Could anyone tell me how to solve it, or at least some hints? This is the exercise: Knowing that $$\lim_{x \to a}\frac{x^2-\sqrt{a^3x}}{\sqrt{ax}-a}=12$$ Find out $a$. We can assume that $a$ exists and is real.","['calculus', 'limits']"
23945,Reconstruction Conjecture and Partial 2-trees,"Reconstruction conjecture says that graphs (with at least three vertices) are determined uniquely by their vertex deleted subgraphs. This conjecture is five decades old. Searching relevant literature, I found that the following classes of graphs are known to be reconstructible : trees disconnected graphs, graphs whose complement is disconnected regular graphs Maximal Outerplanar Graphs maximal planar graphs outerplanar graphs Critical blocks Separable graphs without end vertices unicyclic graphs (graphs with one cycle) non-trivial cartesian product graphs squares of trees bidegreed graphs unit interval graphs threshold graphs nearly acyclic graphs (i.e., G-v is acyclic) cacti graphs graphs for which one of the vertex deleted graph is a forest. I recently proved that a special case of partial 2-trees are reconstructible. I am wondering if partial 2-trees (a.k.a series-parallel graphs ) are known to be reconstructible. Partial 2-trees do not seem to fall into any of the above mentioned categories. Am I missing any other known classes of reconstructible graphs in the above list ? In particular, are partial 2-trees known to be reconstructible ? I asked this question at cstheory website also.","['graph-theory', 'combinatorics']"
23954,Stopping rules for Markov Chains,"The following is a quote from Lifting Markov Chains to Speed up Mixing , by Chen, Lovasz, and Pak: ...Thus we have described a (randomized) stopping rule that, for any starting node, stops in an expected number $O(\sqrt{n})$ steps, and the probability of stopping at each node is at least 1/2 its stationary probability. By standard results (see e.g. [9]), this implies that the mixing time is $O(\sqrt{n})$. My question: I would like a precise reference for this fact, especially one which has a proof I can read. The reference [9] is Mixing Times by Lovasz and Winkler, and I was unable to find this statement in there. Moreover, there is some ambiguity of what a mixing time of means; what I want it to mean in this case is that except from the eigenvalue at $1$, every other eigenvalue of the chain has modulus at most $1-c/\sqrt{n}$ for some constant $c>0$. Can someone provide a precise reference?","['probability-theory', 'markov-chains']"
23956,"Given a point and a set of triangles, what's would be a fast way to find which triangle the point belongs to?","I'm trying to do a piece-wise affine transform in Python. I have one image with a set of points hand marked and another set of points where I wish to ""move"" my current points and the texture between. This is my understanding of the transformation: Find the delaunay triangulation of the moved points For each pixel in the image, find the corresponding triangle Find the barycentric coordinates of the pixel for the triangle found in 2. Multiply the barycentric coordinates for the pixel in 3 and you
  have the coordinates of the pixel in
  the new image. I ran some tests and I believe my understanding is correct. I have two bottlenecks in my code currently. First, finding out if a point is inside a triangle. For that I am using the algorithm from the wikipedia page . The second bottleneck, and this is the real problem, is finding out the triangle a point belongs to (hence the title :)) I tried finding the distance from the points to the centers, then ordering the triangles in each iteration by the distance from its center to the point, but that doesn't always work. I believe the problem lies in the fact that I have to use the triangulation of the image I want and not from the image I have. I figure the displacement of the points/triangles comes into play then, but I'm not sure how.","['geometry', 'trigonometry', 'image-processing']"
23958,Derivation of the method of Lagrange multipliers?,"I've always used the method of Lagrange multipliers with blind confidence that it will give the correct results when optimizing problems with constraints. But I would like to know if anyone can provide or recommend a derivation of the method at physics undergraduate level that can highlight its limitations, if any.","['optimization', 'multivariable-calculus', 'lagrange-multiplier']"
23964,Symplectic form on a complex manifold,"I am a little muddled and am hoping I can get some clarification about forms in a complex manifold.  Since I am only concerned with local issues, consider $M = \mathbb C^n$ as a complex manifold.  So I have complex coordinates $z_1,\ldots,z_n$ and corresponding real coordinates $x_1, y_1,\ldots, x_n, y_n$ with $z_j = x_j + i y_j$.  Now I have a canonical complex structure $J$ on $M$ given by $J \partial_{x_j} = \partial_{y_j}, J \partial_{y_j} = -\partial_{x_j}$.  Then I have an isomorphism of the complex bundles between $TM$ and the holomorphic tangent bundle $T_{(1,0)} M = span_{\mathbb C} \{\partial_{z_j}\}$.  This isomorphism is given by
$$
(a+ib) \partial_{z_j} \mapsto a\partial_{x_j} + b\partial_{y_j}.
$$
Now let $\omega = \sum_i dx_i \wedge dy_i$ be the standard symplectic form on $M$.  What does this correspond to under the above isomorphism.  At first glance it is
$$
\tilde \omega = \frac{i}{2}\sum_j dz_j \wedge d\bar z_j
$$
where $dz_j = dx_j + i dy_j, d\bar{z_j} = dx_j - i dy_j$.  At second glance this can't be correct since this is zero on the holomorphic tangent bundle.  On third glance, everything seems to work out if I think of
$$
d\bar{z_j}(c\partial_{z_j}) = \bar c.
$$
But this is unsettling to me.  Is this the right way to think about it though?  Can I get in any trouble by thinking of it this way? The problem seems to be that the differentials of the real coordinates give real dual vectors, but the covectors $dz_j$, $d\bar z_j$ are inherently complex (their real span is not the real dual to $T_{(1,0)} M$ unless I interpret $d\bar z_j$ as mentioned above). I believe what is usually done is $\tilde\omega$ is considered to be a form on $TM \otimes \mathbb C$ and is a real symplectic form on
$$
\mathbb Rspan\{\partial_{x_j}, \partial_{z_j}\} = \mathbb Rspan\{\partial_{z_j} + \partial_{\bar z_j}, i(\partial_{z_j} - \partial_{\bar z_j})\}
$$
but I'd prefer to not complexify if I don't have to (since I am just concerned with the symplectic geometry and thus the real bundle, but I would like the convenience of the complex notation).","['complex-geometry', 'symplectic-geometry', 'differential-geometry']"
23967,Subset of a bounded set is bounded,"Show that if a set $A$ in a metric space is bounded, so is each subset
  $B \subseteq A$.","['general-topology', 'metric-spaces', 'real-analysis']"
23975,Formalizing Those Readings of Leibniz Notation that Don't Appeal to Infinitesimals/Differentials,"[Disclaimer: I've studied a lot of logic but never been good at analysis, so that's the angle I'm coming from below] In my attempt to find a precise version of the 'definitions' usually given when first introducing Leibniz notation in single or multivariable calculus or analysis, wherein there is no appeal to differentials or infinitesimals,  I've discovered that I'm confused about a few interrelated low-level issues around formalization and notation, etc.  I don't know which questions are the more basic ones here, so I'll just ask them as go along explaining what I think I do understand about proposed formal definitions of the sort in question. I'm concerned with both the $\frac{dy}{dx}$ notation and the ' $\frac{\partial y}{\partial x}$ ' notation for partial derivatives, but just the real-valued case. Since I suspect that my confusions stem from use-mention confusions, and the confusion of functions, variables, and their values, I will use, and assume familiarity with lambda notation, metavariables, and quasi-quotation throughout.  Where not stated, $\ulcorner\lambda x.\phi\urcorner$ refers to the function on the largest real domain on which $\phi$ is a real number. Assume only definitions for real variables are sought after below. Anyway, on with the definitions: These short articles by the author Thurston (the first five results) all give roughly the same formal definition of Leibniz notation: http://scholar.google.ca/scholar?hl=en&as_sdt=0,5&q=thurston+leibniz Whereas the top results for this search are by the author Harrison, and each give one of a few slight variants on a different definition: http://www.google.ca/search?q=%22leibniz+notation%22+%22lambda+term%22&ie=utf-8&oe=utf-8&aq=t&rls=org.mozilla:en-GB:official&client=firefox-a Here is my understanding of their definitions: HARRISON: $\ulcorner\frac{d\phi}{d\psi}\urcorner$ is a shorthand for $\ulcorner D(\lambda\psi.\phi)(\psi)\urcorner$ i.e. "" $\frac{dy}{dx}$ "" stands for "" $D(\lambda x.y)(x)$ "" This means that: $\psi$ must be a variable of the underlying logic (and it has a free and a bound occurence here) and $\phi$ must be a string such that $\ulcorner\forall x,\phi=f(x)\urcorner$ is true for some function $f:S\to R$ where $S\subseteq R$ . Q1. does anyone have a simpler way to state the restriction on $\phi$ ?
Q1.1 what is the proper name for the sort of string $\phi$ must be? THURSTON: $\ulcorner\frac{d\phi}{d\psi}\urcorner$ is a shorthand for $\ulcorner\frac{\psi'}{\phi'}\urcorner$ i.e. "" $\frac{dy}{dx}$ "" is short for "" $\frac{y'}{x'}$ "" This means that $\phi$ and $\psi$ must be names of functions from the reals to the reals. Q1.2 Are there other formal definitions in the literature I should compare to these? I haven't found any yet... Harrison's defintion does not return a value because a free variable is uninstntiated, in the same sense in which wffs which are not sentences do not return a truth value. Thurston's version, however returns a function. For instance, $\frac{df}{dx}=f'(x)$ for Harrison, $\frac{df}{dx}=f'$ for Thurston More concretely $\frac{d(x^2+x)}{dx}=$ $2x+1$ for Harrison $\lambda x.2x+1$ for Thurston Q2 is the value ' $2x+1$ ' which contains a free variable being returned, or are we implicitly quantifying over $x$ , or, let's call it ' $\xi$ ' for the purposes of quasi quotation, and saying: $\forall\xi,\ulcorner 2\xi+1\urcorner$ refers to (not 'is') the value returned? However, consider the following 'typical' calculus problem: "" $y = f(x)$ $x = g(u)$ $g(x) = x^3 - 7$ find $\frac{df}{dx}$ "" Thurston gets us $\frac{df}{dx} = \lambda x.\frac{1}{3x^2}$ This is undefined on Harrison's approach, since $x$ is not a variable of the logic, but the name of a function. Q3 should I be considering the possibility that the logic allows for variables ranging over functions? And if we pretended that it was we'd still get $\frac{df}{dx} = D(\lambda x.f)(x)$ but this is mal-formed since $\lambda x$ needs something like ' $f(x)$ ' rather than ' $f$ ' as input. And if we added a case to Harrison's definition to append ' $(x)$ ' or the like when it's missing, we'd still get $\frac{df}{dx} = 1$ , which is not equal to the result we got with Thurston's definition--but more strikingly, the function we evaluated to get 1 was, unike the $f'$ vs $f'(x)$ case above, not even the same function as was returned by Thurston's definition. Q4 What should I conclude from the fact that these definitions diverge in this manner? Now consider: "" $y = f(x)$ $f(x) = x^9$ find $\frac{dy}{dx}$ "" On Harrison's account, we could view $y$ as a metavariable, so that $f(x)$ is placed substitutionally into the defining string, but I have a feeling that is not the right way to understand it. However, if $y$ is merely a variable of the logic, it is a free variable in the result, and we end up with one free variable too many.. On Thurston's account, $y$ must be the name of a function, but "" $y = f(x)$ "" sets $y$ equal to an expression with a free variable, not equal to the name of a function Q5 should i view statements like "" $y=f(x)$ "" as involving a supressed "" $(x)$ "" and "" $\forall$ "" so that we get "" $\forall x,y(x)=f(x)$ "" ? Or should I see $y$ as a metavariable? Or, should I imagine the logic extended to allow some new syntactic category of 'dependent' variables, while thinking of the usual variables in the logic as 'independent' variables--i.e. those whose value does not depend on others? I think I am very confused about what happens when one variable depends on another. Q6 On a related note, I saw a passage recently that spoke in terms like "" $x(u)$ is the inverse function of $u(x)$ ""--how should this be understood more precisely? I've come to discover that I don't understand expressions of this sort at all! Q7 Does either of these definitions clearly capture 'practice' better than another? Q8 How should similar attempts be made for the 'del' notation for patial derivatives? Q9 Can someone give me an example of where $\frac{d}{dx}$ and $\frac{\partial}{\partial x}$ return different values on the same input?  If I'm not mistaken, in some formalizations this never happens, and in other formalizations it does--I think Harrison's would not allow for this since it just returns an 'expression' rather than one of the various functions that can be formed by an expression when you apply a lambda operator to it. I started also trying to read this article on revising patial derivative notation: [I've hit my link limit as I'm new here, but google ""revised notation for partial derivatives""  (with quotes).  It's by WC Hassenpflug] but I got stuck on the sentence: ""If we have a function $u = f(x,y)$ and the transformation $y=g(x\cup)$ is made, then it is not clear whether $\frac{\partial u}{dx}$ means $\frac{\partial u}{dx}\vert y$ or $\frac{\partial y}{dx}\vert n$ Can someone explain that one to me? Q10 This all bears some superficial similarity to the relationship between so-called 'random variables', which are actually functions, and what are called 'variables' in the underlying logic--this has also confused me, and I see many operations done in text on random variables where the operators have only been defined for values in the random variable's domain, and not on functions. Can anyone comment on this? I would be nice if I could dismiss two long-standing confusions with one stone :p","['calculus', 'definition', 'notation', 'logic', 'real-analysis']"
23978,How exactly do differential equations work?,"My textbook says that solutions for the equation $y'=-y^2$ must always be 0 or decreasing. I don't understand—if we're solving for y', then wouldn't it be more accurate to say it must always be 0 or negative. Decreasing seems to imply that we're looking at a full graph, even though the book is talking about individual solutions. Can someone explain this? Secondly, it gives that the family $y=\frac{1}{x+C}$ as solutions for the equation. It then tells me that 0 is a solution for y in the original equation that doesn't match the family, but I don't quite understand that. How can we know that y' will equal 0 if we're specifically looking outside of the family of solutions it gives?","['ordinary-differential-equations', 'calculus']"
23990,How to solve $\ddot{\theta} + \mu \dot{\theta}^2=0$,$\dot{\theta} \equiv \frac{d \theta(t)}{dt}$ I encountered this ODE $\ddot{\theta} + \mu \dot{\theta}^2=0$ How do I find a solution for $\theta(t)$. I know $\dot{\theta}(t=0)=\omega_0$,['ordinary-differential-equations']
24001,How does the method of Lagrange multipliers fail (in classical field theories with local constraints)?,"The method of Lagrange multipliers is used to find the extrema of $f(x)$ subject to the constraints $\vec g(x)=0$, where  $x=(x_1,\dots,x_n)$ and $\vec g=(g_1,\dots,g_m)$ for $m \leq n$. Although many textbooks get the final equations by arguing that at an extrema, the variation of $f(x)$  must be orthogonal to the surface $g(x)=0$, the ""simpler"" approach (and that which is commonly seen in field theory / optimizing functionals) is to construct the Lagrange function
$$ L(x,\lambda) = f(x) + \vec\lambda\cdot\vec g(x) $$
and varying w.r.t. $x$ and $\lambda$ to get the vector equations
$$
\begin{align}
  &x:&              0 &= \nabla f(x) + \sum_i \lambda_i \nabla g_i(x) \,, \\
  &\vec \lambda:&   0 &= \vec g(x) \ .
\end{align}
$$ The method only works if the extremal point is a regular point of the constraint surface, i.e. if $\mathrm{rnk}(\nabla\vec g) = m$. What is the best way of understanding what goes wrong when the extrema is not a regular point of the constraint? And, most importantly to me, how does this generalize to field theories (i.e. optimizing functionals) with local constraints ? What is the equivalent regularity condition for constraints in field theory? Instructive examples are more than welcome.","['optimization', 'multivariable-calculus', 'examples-counterexamples', 'functional-analysis']"
24003,A calculus question,"On the interval $(0, \infty)$,the function $f \geq 0$,$f' \leq 0$, and $f'' \geq 0$.Prove that $\lim\limits_{x \to \infty} xf'(x) = 0$.","['calculus', 'functions']"
24016,Example of Hausdorff space $X$ s.t. $C_b(X)$ does not separate points?,"We know the Stone-Weierstrass theorem for locally compact Hausdorff spaces (LCH) which states the following: Theorem: Suppose $X$ is LCH. A subalgebra $\mathcal{A}$ of $C_0(X)$ is dense if and only if it separates points ($\forall x,y \in X : x\neq y \implies \exists f \in \mathcal{A}: f(x) \neq f(y)$) and vanishes nowhere $(\forall x \in X \exists f \in \mathcal{A} : f(x) \neq 0$) and is closed under complex conjugation 1 . It's also easy to show that $C_b(X)$, the continuous and bounded functions on a topological space $X$, is a Banach space 2 . It would be obvious to try and show a variant of Stone-Weierstrass for $C_b(X)$ where $X$ is merely Hausdorff, and since it's obviously dense in itself, for such a theorem to exist it would be required that $C_b(X)$ separates points (that it vanishes nowhere is clear: it contains the constant functions). I've tried to come up with an example of a Hausdorff space where $C_b(X)$ fails to separate points (this could for example be a space where every non-constant continuous function is unbounded), but to no avail. So does anyone happen to have an instructive example lying around? PS: It's an interesting exercise to prove that given a LCH space $X$ the continuous functions with compact support, $C_{00}(X)$, separates points and vanishes nowhere. You get to use many theorems from topology in the process of constructing a continuous function such that $f(x)=1$ and $f(y)=0$ given distinct points $x,y \in X$ [Hint: Find a good compact subset and use Urysohn's lemma]. [1]: In the case of real-valued functions this is essentially a no-op, so including it in the theorem statement doesn't hurt. [2]: [Car00] shows in Lemma 10.8 that $B(X)$, the set of bounded functions on a set $X$ is a Banach space, and it's an immediate corollary from Thm 10.4 that $C_b(X)$ is closed in $B(X)$ for $X$ a metric space. Of course this  generalises readily to the case of $X$ a topological space.","['general-topology', 'separation-axioms', 'examples-counterexamples', 'real-analysis']"
24032,Can we make $\tan(x)$ arbitrarily close to an integer when $x\in \mathbb{Z}$?,"My 7-year-old son was staring at the graph of tan() and its endlessly-repeating serpentine strokes on the number line between multiples of $\pi$ and he asked me the question in the title.  More precisely, is the following true or false? For any $\epsilon > 0$, there exists some $N \in \mathbb{Z}^+$ such that 
$|\tan(N)-\lfloor \tan(N) \rceil| < \epsilon$.","['calculus', 'real-analysis', 'diophantine-approximation']"
24037,Is there a set-theoretic definition of Projective Space?,"I posted this on mathOverflow previously which was the wrong place to post it and I was asked to try this forum instead. Can anyone explain this in simple terms: I met projective space via a recent class on perspective drawing, believe it or not, but I didn't know that this was the ""space"" we were using. I came across a more detailed description trawling the net. In a book on point-set topology that I bought, it describes Euclidean n-space as a field made of (sorry I don't know how to write mathematical symbols yet): [ {n-tuples of reals}, Op(""+""), Op(""."") ] So what is the equivalent set-theoretic description for projective space? I haven't been able to find one anywhere. All I've found is that basically it is constructed by taking a regular plane and adding the 'horizon' line but I want to understand mathematically what it is. EDIT(2): I guess it's the fact of being on the sphere that matters. I think I get it... The whole antipodal points minus origin thing is how you would describe the surface of a sphere, isn't it? Parallel lines in R3 would hit the spherical boundary and then NECESSARILY converge as they follow that new curved surface... Yay! :o)",['general-topology']
24047,Finding the regular points of a rational map,"Let $X$ and $Y$ be (irreducible, quasi-projective) varieties (over an algebraically closed field $k$), and $\phi: X \to Y$ be a rational map. I think I understand what it means for $\phi$ to be regular at a point $x \in X$, but I'm lost as to how to prove that $x$ is (or isn't ) a regular point of $\phi$, when I am given a single representative of $\phi$. For example, suppose $X = Y = \mathbb{P}^2$ is the projective plane, and $\phi$ is the rational map determined by $\phi([x : y: z]) = [yz : zx : xy]$. This uniquely defines a rational map since $\mathbb{P}^2$ is irreducible and the equation makes sense away from $P = \{ [1 : 0 : 0], [0 : 1 : 0], [0 : 0 : 1] \}$, which is a closed set. I can see that $\phi$ is a birational equivalence (and even an involution!), and it seems intuitive that $\phi$ cannot be regular on $P$. But how do I prove this rigorously? Then, for a twist, consider the line $L \subset \mathbb{P}^2$ which satisfies the equation $x + y + z = 0$. Clearly, $L \cap P = \emptyset$, and $\phi(L)$ is the conic $xy + yz + zx = 0$, and $P \subset \phi(L)$. It turns out $\phi$ restricted to $\phi(L)$ is a morphism of varieties $\phi(L) \to L$, because we've thrown away enough of the obstructions to regularisation. So regularity seems to be something a bit more subtle than staring at polynomials... but the way I showed that this restriction did turn $\phi$ into an honest morphism was precisely that: I fiddled about with polynomials and equations until I got a consistent set which covered the whole curve. Is there a better / more general way of finding the points at which a a rational map is regular?",['algebraic-geometry']
24054,Converting polar equation to cartesian coordinate polar equation and back again?,"OK, so I have the following polar equation: $$r = \frac{\theta}{20}.$$ And I would like to translate this a little to the right, and down from the polar origin. Now, I figure since I know cartesian coordinate equation translations are quite simple, the best way to do this would be to convert this polar equation to a rectangular equation, translate, and then convert back to polar again. However, I was having some problems making the initial conversion. I know we are supposed to use the following relationships between polar and rectangular equations: \begin{gather*}
r^2 = x^2 + y^2,\\
y = r\sin \theta.
\end{gather*} But, I cannot seem to convert my equation correctly... Would someone be able to suggest a simpler way to make this translation? Or, assist me in converting to polar and back again? I'm quite new at this, so I apologize if this question is remedial. Thanks!","['polar-coordinates', 'algebra-precalculus', 'graphing-functions']"
24056,Splitting field of $x^{n}-1$ over $\mathbb{Q}$,"From I.N.Herstein's Topics in Algebra. Chap 5 Sec 5.3 Page 227 Problem 8 Problem 8 : If $n>1$ prove that the splitting field of $x^{n}-1$ over the field of rational numbers is of degree $\Phi(n)$ where $\Phi$ is the Euler $\Phi$-function. ( This is a well known theorem. I know of no easy solution, so don't be disappointed if you fail to get it. If you get an easy proof, I would like to see it.) First, I would like to see a proof of this result. Next, I think I have seen this proof in Dummit and Foote's Abstract Algebra book, but not sure. Anyway, next question is: Has an easy solution been found to this problem? If not, I would like to know what efforts have been taken to make the proof more simple. And why does Herstein think an easy solution can exist.","['galois-theory', 'abstract-algebra', 'field-theory']"
24060,"Uniform continuity on (0,1) implies boundedness [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I need to prove that if $f: (0,1) \rightarrow \mathbb{R}$ is Uniformly continuous then it is  bounded. Thank you.","['uniform-continuity', 'real-analysis', 'analysis']"
24067,Is this matrix diagonalisable?,"Let $A$ be the following matrix:
$$A = \left(\begin{array}{rrr}
-1 & \hphantom{-}3 & \hphantom{-}0\\
0  & 2 & 0\\
-3 & 3 & 2
\end{array}\right).$$
I've found that the eigenvalues are -1 and 2 (multiplicity 2). However, when I try to find the eigenvectors for the eigenvalue 2, I can only find one, as the augmented matrix $A-2I$ reduces to 
$$\left(\begin{array}{rrr}
1 & -1 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{array}\right).$$
So is there any other way to diagonalise this matrix, or have I made a mistake somewhere?",['matrices']
24070,Why can we think of the second fundamental form as a Hessian matrix?,"Let $f: U \rightarrow \mathbb{R}^3$ be an immersion that parametrizes a piece of a surface, and let $(h_{ij})$ be the matrix for the second fundamental form of that surface. According to pg. 70 of the text Differential Geometry by Wolfgang Kuhnel, we can think of the $(h_{ij})$ as ""the Hessian of matrix of a function $h$, which represents the surface as a graph over its tangent plane"". I have a ""heuristic"" understanding of what's going on, but I'd like to be a bit more careful about this.  What exactly is the function $h$?  Can we write it down explicitly (perhaps in terms of the parametrization $f$, the unit normal $\nu$, and their derivatives), so that we can directly check that its Hessian is indeed the second fundamental form $(h_{ij})$?",['differential-geometry']
24088,How is $3 + 4\cos \theta + \cos 2\theta \geq 0$ related to $\zeta(s)^3|\zeta(s + it)^4\zeta(s + 2it)| \geq 1$?,The inequality $$\zeta(s)^3 | \zeta(s + it)^4 \zeta(s + 2it)| \ge 1$$ follows from $$3 + 4 \cos(\theta) + \cos(2 \theta) \ge 0.$$ How is that done? What is the relationship between zeta and the trigonometry?,"['analytic-number-theory', 'riemann-zeta', 'number-theory']"
24091,The natural inclusion of an infinite abelian group $G$ into $\widehat{\widehat{G}}$,"I was recently trying to think of a simple example that demonstrates that the natural inclusion of an abelian group $G$ into $$\widehat{\widehat{G}}=\text{Hom}_{\mathsf{Ab}}(\text{Hom}_{\mathsf{Ab}}(G,\mathbb{C}^\times),\mathbb{C}^\times)$$
is not necessarily an isomorphism. Note that I'm looking at all homomorphisms; no topology on the group is involved (or, if you prefer, they are all discrete). Obviously, $G$ has to be infinite. However, I was having a bit of trouble finding an example satisfactorily simple - in fact, the only one I could prove worked was $G=\mathbb{Z}$, in which case $\widehat{G}=\text{Hom}_{\mathsf{Ab}}(\mathbb{Z},\mathbb{C}^\times)\cong\mathbb{C}^\times$, so that
$$\widehat{\widehat{G}}\cong\text{Hom}_{\mathsf{Ab}}(\mathbb{C}^\times,\mathbb{C}^\times)$$
which is uncountable due to the existence of uncountably many automorphisms of the field $\mathbb{C}$. However, that requires the axiom of choice, which seems like it ought not to be necessary. I'm sure I'm missing an obvious one - could someone provide a $G$ which doesn't require the axiom of choice to prove the map isn't surjective?","['group-theory', 'characters']"
24098,Quotient Space $\mathbb{R} / \mathbb{Q}$,"I've just learned about topological quotient spaces and was wondering if anyone can help me with this example I thought of. Let $(\mathbb{Q}, +)$ be the usual group of rational numbers for addition, likewise $(\mathbb{R}, +)$. Set $S$ to be the set of all cosets, t.i. $S=\mathbb{R}/\mathbb{Q}=\{x + \mathbb{Q} \mid x \in \mathbb{R} \}$. What is the quotient space $\mathbb{R} / S$ like? ($\mathbb{R}$ is equipped with the regular euclidian topology) What is it homeomorphic to? What does a typical open set look like? Thanks.",['general-topology']
24101,Finding joint sufficient statistics [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I'm trying to find two statistics $T_1$ , $T_2$ such that $(T_1, T_2)$ is jointly sufficient for $(\lambda, \theta)$ for a random sample $X_1, \dots, X_n$ from a two parameter exponential distribution. $f(x) = \begin{cases}
\lambda e^{-\lambda (x-\theta)}, & \theta < x < \infty, \\
0, & \text{elsewhere}.
\end{cases}$ Thanks.","['statistics', 'probability-distributions']"
24120,Measurability of a function,"I am having a hard time understanding a condition in building a measurable function. This is an example of a measurable function from this book (p. 55). Quoting verbatim: Consider $R_n(\omega)$, the Rademacher functions. These are measurable because they are piecewise constant; namely, for any subset $A$ of $\mathbb{R} \cup \{+\infty\} \cup \{-\infty\}$, we have that $\{\omega \in I; R_n(\omega) \in A\}$ is a finite union of intervals. where $I = [0,1]$ and the $n$th Rademacher function
\begin{align}
R_n(\omega) = \begin{cases}
1 & \textrm{if } a_n = 1 \newline
-1 & \textrm{if } a_n = 0
\end{cases}
\end{align}
and $a_n$ is the $n$th number in the binary expansion of $\omega \in I$. Namely, I don't get the condition placed regarding any subset $A$ of $\mathbb{R} \cup \{+\infty\} \cup \{-\infty\}$ If the only values $R_n$ can take are +1 and -1, what's the point in saying that $A$ can be any interval on the extended real line? Isn't it just as valid to state $\{\omega \in I; R_n(\omega) \in \{-1,1\}\}$ and argue that the Rademacher functions are measurable?",['measure-theory']
24123,Element-Wise Proofs?,"Prove by element-wise:
$$A \cup (B \cap C) = (A \cup B) \cap (A \cup C).$$ This is easy to prove by Venn Diagram, which I have already done. I do not, however, know how to prove using this technique. I know it has to do with proving each is a subset, but I do not understand the general method to prove this formally?",['elementary-set-theory']
24134,"Div, curl and linear algebra","I came across this post lying dormant on some online forum . I am putting it here verbatim, it seems to me worth a lot. By Prof. S. D. Agashe, IIT Bombay (Source: Vector Calculus, by Durgaprasanna Bhattacharyya, University
Studies Series,Griffith Prize Thesis, 1918, published by the University
of Calcutta, India, 1920, 90 pp) Chapter IV: The Linear Vector Function, article 15, p.24: ""The most general vector expression linear in $r$ can contain terms only
of three possible types, $r$ , $(a\cdot r)b$ and $c\times r$ , $a$ , $b$ , $c$ being constant unit vectors. Since $r$ , $(a\cdot r)b$ and $c\times r$ are in general non-coplanar, it follows from the theorem of the parallelepiped of vectors that the most general linear vector expression can be written in the form $\lambda \cdot r + \mu (a\cdot r)b + \nu (c\times r)$ , where $\lambda, \mu, \nu$ are scalar constants"". Bhattacharyya does not prove this. Has anyone seen a similar result and its proof? Bhattacharyya uses this to show that the divergence of the linear
function is ( $3 \lambda + a\cdot b$ ), that the curl is ( $a \times b + 2c$ ). He goes on to define div and curl of a differentiable function as the div and curl of the (linear) derivative function. The div and curl of a linear function are defined in terms of certain surface integrals. I am excited about this result because it seems to provide an excellent
route to div and curl, as Bhattacharyya himself remarks. Sorry for a rather long and ""technical"" communication.","['multivariable-calculus', 'linear-algebra']"
24146,Find all invertible $n\times n$ matrices $A$ such that $A^2 + A = 0$,"This was a question on one of our practice midterms: Find all invertible $n \times n$ matrices $A$ such that $$A^2 + A = 0.$$ I was told to expand $A^2$ and then solve, but that seems like a really ugly (and hard-to-generalize) solution... are there any better ones?","['matrices', 'linear-algebra']"
24154,Uniformly continuous functions,"Given a uniformly continuous function $f(x)$ on the real numbers $\Bbb R$, then by the definition of uniform continuity this means: for any $\epsilon>0$ there exists $\delta >0$ such that $|f(x)-f(y)|<\epsilon$ whenever $|x-y|<\delta$. My question is: Given $\epsilon_{n} =\frac{1}{3^{n}}$ (for example), and $y_{n}=x_{n}+w_{n}$ so that $|x_{n} -y_{n}|=|w_{n}|$,  then we know that there is $\delta_{n}>0$, how can we find the corresponding $\delta_{n}$? I don't know if my question makes sense.","['calculus', 'analysis']"
24161,Short Exact Sequences & Rank Nullity,"This is a well known lemma that consistently appears in textbooks, either as a statement without proof, or as an exercise (see for example pp. 146 of Hatcher) If $0 \stackrel{id}{\to} A \stackrel{f}{\to} B \stackrel{g}{\to} C\stackrel{h}{\to} 0$ is a short exact sequence of finitely generated abelian groups, then $\operatorname{rank} B = \operatorname{rank} A + \operatorname{rank} C$ . I've been trying to prove this unsuccessfully. What do we know? $f$ is injective, $g$ is surjective, $\mathrm{Im} f = \mathrm{ker} g$ , $\mathrm{Im} g = \mathrm{ker} h$ , $C\simeq B/A$ So I start with a maximally linearly independent subset $\{ a_\alpha \}$ of $A$ such that the sum (with only finite non-zero entries) $$\sum n_\alpha a_\alpha=0$$ for $n_\alpha \in \mathbb{Z}$ , implies that $n_\alpha=0$ . Where to go from here is a puzzle? Any hints would be appreciated","['exact-sequence', 'abstract-algebra', 'homological-algebra', 'modules', 'group-theory']"
24171,Lebesgue integral uniform convergence,"Let $f_n, f \colon [a,b] \to \mathbb{R}.$ Show that, if $f_n \to f$ uniformly, then the Lebesgue integrals are equal, i.e. $\int f = \lim \int f_n$ . This is clearly true for continuous functions, but how do I handle the case of non-continuous functions?","['integration', 'real-analysis']"
24177,Absolute continuity of measures,"Suppose $u$ and $v$ are measures on a measurable space $E$. Further suppose $u$ is finite and absolutely continuous with respect to v ($v(S)=0 \implies u(S)=0$).
The problem is: Show that $\forall \epsilon>0 \;\;\;\exists \delta: v(S)<\delta \implies u(S)<\epsilon.$ I've tried the following: Fix $\epsilon>0$. Let $S_n=\{measurable\;\; B\in E|u(B)>\epsilon, v(B)<1/n\}$. If $S_n$ is finite for some n we are done ($v(S)=0 \implies u(S)=0$). Now what I am trying to show is that the other case, $S_n$ is infinite $\forall n\in\mathbb{N}$, leads to a contradiction.
Any suggestions?",['measure-theory']
24178,What is the probability that $\pi(x) + x$ is injective?,"Let $S$ be a finite group with operator + and $\pi$ be a permutation on $S$.  Then what is the probability that $\pi(x) + x$ is injective over choices of $\pi$? The concrete instantiation I'm interested in is $S=$GF$(2^n)$ for fixed $n > 0$.  (Computer Scientists call this ""xor on $n$-bit strings."") For $n=1$ we have two permutations, neither of which produce an injection. For $n=2$ we have 24 permutations, 8 of which induce an injection so the probability is 1/3. Here is an example $\pi$ for $n=2$: $$\pi(0)=0,\ \pi(1) = z,\ \pi(z)=z+1,\ \pi(z+1)=1.$$ Here notice that $\pi(x) + x$ produces $0$, $z+1$, $1$, and $z$, respectively, which is an injection.","['discrete-mathematics', 'probability', 'combinatorics']"
24196,"Exercise in Do Carmo's ""Riemannian Geometry"": the Möbius band is nonorientable.","Of course there are many ways to prove this.  However, I came across the following exercise (Ch. 0 #3). Prove that:
  (a) a regular surface
  $S\subset \mathbb{R}^3$ is an
  orientable manifold if and only if
  there exists a differentiable mapping
  of $N:S\rightarrow \mathbb{R}^3$ with
  $N(p)\perp T_p(S)$ and $|N(p)|=1$, for
  all $p\in S$. (b) the Möbius band
  (Example 4.9 (b)) is non-orientable. In Example 4.9 (b), he constructs the Möbius band as the quotient by the antipodal map of the cylinder $C=\{(x,y,z)\in \mathbb{R}^3:x^2+y^2=1,|z|<1\}$.  The problem, of course, is that this isn't given as a surface in $\mathbb{R}^3$!  I was thinking for a second that maybe I should try and construct a map $C\rightarrow S^2$ with the right properties and check that it doesn't descend to a map on $M$, but that's stupid because if I were to embed $M\subset \mathbb{R}^3$, I'm pretty sure it couldn't possibly have those tangent planes anyways. Does anyone have any insight?  Presumably the solution to (b) should use the fact given in (a).",['differential-geometry']
24201,Artinian Ring Question,"Let $k$ be a field and $R$ be the exterior ring over $k^d $, that is, $k$-algebra generated by elements  $$x_1,\ldots,x_d,$$
where $$\ x_ix_j= - x_jx_i?$$ Is $R$ Artinian?","['ring-theory', 'abstract-algebra']"
24204,Understanding the Pareto distribution as applied to wealth,"The Pareto distribution is used to say, given a particular person X, what is the pdf of his wealth. I would like to explore the reciprocal question: Given the total amount of wealth in a population, what portion does a random person have.  I conjecture that this is simply a constant times the Pareto distribution. More interestingly: What is the shape of the distribution curve, if the richest person would be at the 0 point on the x axis, the next richest person to the right, and so on - we would see a monotonically decreasing curve.  But what is its shape? What is its derivative? It's quite likely that I'm not phrasing that question properly.  Let me ask a more basic question: What is the appropriate terminilogy to explore the question? Give a probability distribution applied many times over, what is the shape of the resultant allocation curve?","['statistics', 'probability-distributions', 'probability', 'mathematical-modeling']"
24220,"Show that if $G$ is a finite nilpotent group, then every Sylow subgroup is normal in $G$","Thank you~ Show that if $G$ is a finite nilpotent group, then every Sylow subgroup is normal in $G$. I know that the normalizer of any proper subgroup of a nilpotent group contains this subgroup properly. So I think maybe I can prove the normality of the Sylow subgroup of $G$, say $P$, by showing that $N(P)=N(N(P))$, thus showing that $N(P)=G$. (Here, $N(P)$ represents the normalizer of $P$ in $G$.) But I don't know how to complete this step. I'll appreciate your help. Many thanks.",['group-theory']
24237,"Diagonal  of the double sequence $(n+1)v_{h,n+1}-(2h+1)v_{h,n}-nv_{h,n-1}=0$","Update : it is not possible to reply to this question without additional information. My comment below: ""I have to agree with you that one ""cannot derive (2) from (1) alone"". Now it seems to me that one must consider how the sequences $v_{h,n}^{\prime }$ and $v_{h,n}$ are constructed. That is described in the first part of the paper, but unfortunately it is not easy for me to summarize it. As I understand Apéry transformed repeatidely a continued fraction whose approximants are $\dfrac{u_{h,n}^{\prime }}{u_{h,n}}$, iterating on $h$. The above sequences are $v_{h,n}^{\prime }=\dfrac{u_{h,n}^{\prime }}{h!n!}, v_{h,n}=\dfrac{u_{h,n}}{h!n!}$."" In Irrationalité de Certaines Constantes , Bull. section des sciences du C.T.H.S., n.º3, p.37-53, Roger Apéry derives rational approximations $\dfrac{v_{h,n}^{\prime }}{v_{h,n}}$ for $\ln (1+t)$, 
$\zeta (2)$ and $\zeta (3)$, the simplest being the one for the $\ln $. The
sequences $v_{h,n}^{\prime }$ and $v_{h,n}$, whose ratio converges
to $\ln (2)$, satisfy the recursive relation $$(n+1)v_{h,n+1}-(2h+1)v_{h,n}-nv_{h,n-1}=0.\qquad (1)$$ The diagonal sequences $w_{n}^{\prime }=v_{n,n}^{\prime },w_{n}=v_{n,n}$
satisfy $$(n+1)w_{n+1}-3\left( 2n+1\right) w_{n}-nw_{n-1}=0.\qquad (2)$$ Remarks: The initial conditions for $v_{h,n}^{\prime }$, $v_{h,n}$, $w_{n}^{\prime
}$, $w_{n}$ are not indicated in the paper. Recurrences $(1)$ and $(2)$ are the particular case for $t=1$ of, respectively, $$(n+1)v_{h,n+1}-\left( \left( n+1\right) -nt+h\left( 1+t\right) \right)
v_{h,n}-ntv_{h,n-1}=0\qquad (\ast)$$ (to simplify the notation the index $h$ was deleted in the original) and $$(n+1)w_{n+1}-\left( 2n+1\right) \left( 2+t\right) w_{n}-nt^{2}w_{n-1}=0.\qquad (\ast\ast)$$ Question : How do you derive $(2)$ from $(1)$? Copy of the mentioned paper","['recurrence-relations', 'sequences-and-series', 'number-theory']"
24268,Big $O$ vs Big $\Theta$,"I am aware of the big theta notation $f = \Theta(g)$ if and only if there are positive constants $A, B$ and $x_0 > 0$ such that for all $x > x_0$ we have
$$
A|g(x)| \leq |f(x)| \leq B |g(x)|.
$$
What if the condition is the following:
$$
C_1 + A|g(x)| \leq |f(x)| \leq C_2 + B |g(x)|
$$
where $C_1, C_2$ are possibly negative? Certainly more can be said than just $f = O(g)$. Is there a generalized $\Theta$ notation which allows shifts (by, say $C_1, C_2$)? In particular, I'm interested in the special case:
\begin{eqnarray}
-C  \leq f(x) - g(x) \leq C
\end{eqnarray}
for some positive $C$. How does $f$ compare to $g$ in this case? If $f$ and $g$ are positive functions of $x$ which both diverge to $\infty$, is it true that $f(x) = -C + g(x) + \Theta(1)$? What is the appropriate asymptotic notation in this case? Update Thanks for the clarifying answers. Now here is a slightly harder question. Suppose $f$ is discrete and $g$ is continuous. Suppose further that as $x \to \infty$, the difference $f(x) - g(x)$ is asymptotically bounded in the interval $[-C,C]$ but does not necessarily converge to $0$. Does $f \sim g$ still make sense? Would it be more appropriate to use $\liminf_{x \to \infty} f(x) - g(x) = - C$ and $\limsup_{x \to \infty} f(x) - g(x) = C$?","['asymptotics', 'real-analysis']"
