question_id,title,body,tags
3271095,Convergence speed of discrete approximation,"Here I asked the question about approximating the function $g(x) := \mathbb{E}(f(x,Y))$ , where $x \in R$ and $Y$ is a random variable. If you follow the link you will see that $g(x)$ can be approximated by finite sum $\frac{1}{n}\sum_{i=1}^nf(x,\mu_i)$ with any precision we desire. My question: whats is the speed of the convergence? Can we deduce how large $n$ should be to make error $\leq \epsilon$ Feel free to impose any reasonable conditions on $f$ and distribution of $Y$","['linear-regression', 'functional-analysis', 'approximation-theory']"
3271142,Clarification of L'Hopital Proof Pugh,"I am self-studying Real Analysis right now via Pugh's Real Mathematical Analysis but am having trouble understanding a step of the author's proof of L'Hopital's rule. The theorem is stated as: If $f$ and $g$ are differentiable functions defined on an intveral $(a,b)$ , both of which tend to $0$ at $b$ , ad if the ratio of their derivatives $f'(x)/g'(x)$ tends to a finite limit $L$ at $b$ then $f(x)/g(x)$ also tends to $L$ at $b$ , where $g(x),g'(x) \neq 0.$ His proof reads as follows: Given $\epsilon > 0$ we must find a $\delta > 0$ such that if $|x-b| < \delta$ then $|f(x)/g(x) - L|< \epsilon.$ Since $f'(x)/g'(x)$ tends to $L$ as $x$ tends to $b$ there does exist a $\delta > 0$ such that if $x \in (b-\delta, b)$ then $$\left\vert \frac{f'(x)}{g'(x)}-L \right\vert < \frac \epsilon 2.$$ For each $x \in (b-\delta, b)$ determine a point $t \in (b-\delta, b)$ which is so near to $b$ that \begin{align}|f(t)+g(t)| &< \frac{g(x)^2\epsilon}{4(|f(x)|+|g(x)|)} \\ |g(t)| &< \frac{|g(x)|}{2}.\end{align} Since $f(t)$ and $g(t)$ tend to $0$ as $t$ tends to $b$ , and since $g(x) \neq 0$ such a $t$ exists. It depends on $x$ , of course. By this choice of $t$ and the Ratio Mean Value Theorem we have, for some $\theta \in (x,t),$ \begin{align*}\left\vert \frac{f'(x)}{g'(x)}-L \right\vert &= \left\vert \frac{f(x)}{g(x)}-\frac{f(x)-f(t)}{g(x)-g(t)}+\frac{f(x)-f(t)}{g(x)-g(t)} - L \right\vert \\ &\le \left\vert \frac{g(x)f(t)-f(x)g(t)}{g(x)(g(x)-g(t))} \right\vert + \left\vert \frac{f'(\theta)}{g'(\theta)}-L \right\vert < \epsilon, \end{align*} which completes the proof that $f(x)/g(x) \to L$ as $x \to b.$ The part I didn't get was the last inequality $$\left\vert \frac{g(x)f(t)-f(x)g(t)}{g(x)(g(x)-g(t))} \right\vert + \left\vert \frac{f'(\theta)}{g'(\theta)}-L \right\vert < \epsilon,$$ which I'm sure relates to his constraints on $|f(t) + g(t)|$ and $g(t)$ . I understood his general point about $f(t)/f(x), g(t)/g(x)$ getting arbitrarily small so that $$\frac{f(x)}{g(x)} \approx \frac{f(x)-f(t)}{g(x)-g(t)}$$ but don't really understand the finer details of the proof. Any help is greatly appreciated. :)",['real-analysis']
3271157,Lifting of $K$-valued Points $X(K)$ over Valuation Ring $\mathcal{O}$,"Let $K$ be a non Achimedian valued field with valuation ring $\mathcal{O}$ . Let futhermore $X$ be a projective scheme over $\mathcal{O}$ with map $X \to Spec(\mathcal{O})$ . Donote by $\widetilde{X}$ the pullback of $X$ along $Spec(K) \to Spec(\mathcal{O})$ . My question is if (and why) we can identify the $K$ -valued points $\widetilde{X}(K)= Hom(Spec(K),\widetilde{X})$ with "" $\mathcal{O}$ -valued points"" $X(\mathcal{O})$ ? Is there a lifting theorem in the game?","['algebraic-geometry', 'schemes']"
3271176,"Prove that every continuous map $f: [0,1] \rightarrow [0,1]$ has a fixed point.","Prove that every continuous map $f: [0,1] \rightarrow [0,1]$ has a fixed point. Suppose $f$ does not have a fixed point, then $\forall x \in [0,1], f(x) \neq x$ . Thus we have a well defined function $g(x) = \frac{1}{f(x)-x}$ . Note that as $g(x)$ is the composition or continuous functions, it must be continuous. However, $g(0) > 0$ and $g(1) < 0$ , so by the intermediate value theorem $\exists x \in [0,1]$ such that $g(x) = 0$ . This is clearly impossible. Thus $f$ has a fixed point.","['general-topology', 'proof-verification', 'real-analysis']"
3271189,"Let $f$ a measurable function, then $kf$ is a measurable function with $k\in\mathbb{R}$","Let $f$ a measurable function, then $k.f$ is a measurable function with $k\in\mathbb{R}$ and $\mathbb{A}$ a sigma-algebra of sets. My attempt Suppose $k>0$ $x\in (k.f)^{-1}((\ c,\infty\ ))\iff k.f(x)>c \iff f(x)>\frac{c}{k}$ As $f$ is a measurable function then for all $\alpha=c/k\in\mathbb{R}$ we have $f^{-1}((\ a,\infty\ )\in \mathbb{A}$ this implies $\{x:f(x)>\alpha\}\in\mathbb{A}$ Then $(k.f)^{-1}((\ c,\infty\ ))\in\mathbb{A}$ In consequence, $k.f$ is a measurable function. For the other cases is analogous. is correct this?",['measure-theory']
3271267,Do functions require set theory? [duplicate],This question already has answers here : Confusion about the definition of function (2 answers) Closed 5 years ago . Do functions require set theory in order for us to even use them or talk about them?,"['foundations', 'definition', 'functions']"
3271298,"Find $\lim_{(x,y)\to(0,0)} \frac{xy^2}{(x^2+y^4)\sqrt{x^2+y^2}}$","I'm trying to prove that $$\lim_{(x,y)\to(0,0)} \frac{xy^2}{(x^2+y^4)\sqrt{x^2+y^2}}$$ doesn't exist. I've tried different paths like $(x,y)=(t^2,t)$ , and everything seems to work fine but the term $\sqrt{x^2+y^2}$ in the denominator. Do you know some other useful composition for this? Thanks in advance.","['limits', 'multivariable-calculus']"
3271334,Solution Of Diophantine Equations,"Find all integer solutions for the equation: $$(x+y)(y+z)(z+x)=txyz$$ such that gcd $(x, y)=1$ , gcd $(y, z)=1$ and gcd $(z, x)=1$ Now we can write our equation as $$(\frac{x+y}{y})(\frac{y+z}{z})(\frac{x+z}{x})=t$$ This gives $$(1+\frac{x}{y})(1+\frac{y}{z})(1+\frac{z}{x})=t$$ Now as $t$ is an integer and gcd $(x, y)=1$ , gcd $(y, z)=1$ and gcd $(z, x)=1$ so the only possibility is $$x=y=z=1$$ giving a solution as $$(x, y, z, t)=(1, 1, 1, 8)$$ Am I Right?","['number-theory', 'elementary-number-theory']"
3271370,"Is the subspace $N=\{y\in l_\infty: y_k=x_k\ a.a.k,\ x\in M \}$ closed or not?","Let $l_\infty$ be the set of all bounded real sequences. $S:l_\infty\to l_\infty$ be the shift operator defined by $S(x_1,x_2,x_3,\dots)=(x_2,x_3,x_4,\dots)$ for all $x\in l_\infty$ Let $M=\{x-Sx:x\in l_\infty\}$ . Then it is clear to me that $M$ is a linear subspace of $l_\infty$ . For a subset $P$ of $\mathbb N$ the natural/asymptotic density is defined by the limit (if it exists) $$\delta(P)=\lim\limits_{n\to \infty}\frac{|P\cap\{1,2,\dots,n\}|}{n}$$ We say a condition $\mathcal C$ is satisfied by $x_k\ a.a.k$ (for almost all k)
iff $E=\{k\in\mathbb N:x_k$ does not satisfy condition $\mathcal C$ $\}\implies\delta(E)=0$ . Let $N=\{y\in l_\infty: y_k=x_k\ a.a.k,\ x\in M \}$ .
Then $N$ is a linear subspace of $l_\infty$ . So, $M\subset N\subset l_\infty$ . My question : Is the subspace $N$ closed in $l_\infty$ or not?","['general-topology', 'linear-algebra', 'functional-analysis', 'density-function']"
3271398,The summation $\sum_{k=0}^{2n} (-1)^k \frac{{4n \choose 2k}}{{2n \choose k}}=\frac{1}{1-2n}$,"This summation has been created by perseverance over a long period of time by using the results from the Table of Series and Integrals By I.S. Gradshteyn and I.M.  Rhyzik [GR]. The  idea was to make a summation of binomial coefficients by utilizing the Integral representation of the reciprocal of the Beta (Integral/function): $$B(x,y)=\Gamma(x)\Gamma(y)/\Gamma(x+y)\tag{1}$$ as $$\frac{1}{B(x,y)}=\frac{(x+y-1)}{\pi} \int_{0}^{\pi/2}
\cos[(x-y)t]~\cos^{x+y-1}t ~dt~ \mbox{[GR, p. 959]}.\tag{2}$$ Let $$S_n=\sum_{k=0}^{2n} (-1)^k \frac{{4n \choose 2k}}{{2n \choose k}}. \tag{3}$$ We change the summand into Gamma function using $\Gamma(2z)=\frac{2^{2z-1}}{\sqrt{\pi}} \Gamma(z+1/2)\Gamma(z)$ , we
get $$S_n=\sqrt{\pi} \sum_{k=0}^{2n} (-1)^k \frac{\Gamma(z)}{\Gamma(z-k) \Gamma(k+1/2)},~~ z=2n+1/2.$$ We can re-write $S_n$ using (1) as $$ S_n=\sqrt{\pi} \frac{\Gamma(z)}{\Gamma(z+1/2)} \sum_{k=0}^{n} \frac{(-1)^k}{B(z-k,k+1/2)}.$$ Then $$S_n= \frac{2^{2n+1}}{\sqrt{\pi} \Gamma(2n)} \int_{0}^{\pi/2} \sum_{k=0}^{n} (-1)^k \cos[(k-n)t] \cos^{2n-1} t ~dt.$$ Note that [GR, p. 37] $$
\sum_{k=0}^{2n} (-1)^k \cos [(k-n)t] =\sum_{m=-n}^{n} (-1)^{m+n} \cos 2m t= (-1)^n \left[1+2\sum_{m=1}^{n}(-1)^m \cos 2mt\right]=\frac{\cos(2n+1)t}{\cos t}.
$$ We obtain $$
S_n=\frac{2^{2n}\Gamma(2n+1/2)}{\sqrt{\pi}\Gamma(2n)} \int_{0}^{\pi/2}  \cos(2n+1)t ~ \cos^{2n-2}t ~dt.
$$ Using the value of this integral from [GR, p. 416], we can write $$S_n=\frac{2^{2n}\Gamma(2n+1/2)}{\sqrt{\pi}\Gamma(2n)}\left(\frac{\pi} {2^{2n-1}(2n-1) B(2n+1/2,-1/2)}\right).$$ Finally by opening $B(x,y)$ and using $\Gamma(-1/2)=-2 \sqrt{\pi},$ we get $$ S_n=\frac{1}{1-2n}.$$ This sum (3) can be checked to be correct and consistent but it came mostly by the Table! So the question is: Can one give an alternate proof of (3) by hand which is simpler, more direct and characteristic?","['summation', 'binomial-coefficients', 'definite-integrals', 'sequences-and-series']"
3271414,"Convergence almost surely, cryptic sentence in wikipedia article","This article says https://en.wikipedia.org/wiki/Set-theoretic_limit#Almost_sure_convergence . The event that a sequence of random variables $Y_1, Y_2, \dots$ converges to another random variable $Y$ is formally expressed as $\{{\limsup _{n\to \infty }|Y_{n}-Y|=0\}}$ . It would be a mistake, however, to write this simply as a limsup of events. That is, this is not the event $ \limsup _{n\to \infty }\{|Y_{n}-Y|=0\}$ ! I was wondering if the second expression is simply incorrect notation because it did not have a pair of parentheses around the whole expression. Both expressions mean the same thing to me.","['convergence-divergence', 'probability-theory']"
3271439,Do we have $\text{Proj} A[X] = \text{Spec} A$?,"From the definition $\text{Proj} A[X] = \{ \text{ homogeneous ideals }\mathfrak p \in \text{Spec} A[X] \mid (X) \not\subset \mathfrak{p} \}$ . It seems to me that with this definition only the $A$ -ideals remain, so that we at least have a homeomorphism on the points. But do we also have $\mathcal O_{\text{Proj} A[X]} = \mathcal O_{\text{Spec} A}$ ?","['algebraic-geometry', 'schemes']"
3271457,Conjectures on the primality of $\sum\limits_{i=1}^n p_i^{p_i}$ and $\sum\limits_{i=1}^n (-1)^ip_i^{p_i}$,"Inspired by Is $29$ the only prime of the form $p^p+2$ ? . Claims on prime powers and their alternating sums Consider the expressions $\mathcal P=\sum\limits_{i=1}^n p_i^{p_i}$ and $\mathcal Q=\sum\limits_{i=1}^n (-1)^ip_i^{p_i}$ over the prime numbers $(p_i)_{i\in\Bbb N}$ . Then I claim that $n=2,4,24$ are the only occasions when $\mathcal P$ is prime. $n=2,4$ are the only occasions when $\mathcal Q$ is prime. PARI/GP code is for(n=1,+oo,if(isprime(sum(i=1,2*n,prime(i)^prime(i)))==1,print(n))) . Note that we need only check even $n$ as all prime powers are odd excluding $p_1=2$ . Frankly I have no clue where to start. However, $\mathcal P$ and $\mathcal Q$ can be represented as $$\pm2^2+3^3+x\,\text{terms of the form}\,(6k-1)^{6k-1}+(n-x-2)\,\text{terms of the form}\,(6k+1)^{6k+1}.$$ Now working in modulo $6$ , $$\mathcal P\equiv 4+0+x\cdot(-1)^{-1}+(n-x-2)\cdot1^1\equiv2-2x+n\pmod6$$ so $\mathcal P$ is always composite when $n\equiv2(x-1)\pmod6$ . Similarly, $$\mathcal Q\equiv -4+0+x\cdot(-1)^{-1}+(n-x-2)\cdot1^1\equiv n-2x\pmod6$$ so $\mathcal Q$ is always composite when $n\equiv2x\pmod6$ . Despite this, it is difficult to verify these congruences since $x$ can be hard to determine when $n$ is large. Nonetheless, I suspect a modular approach like the one above is too simple to solve the problem. I would appreciate any advances on this, though I would like further values of $n$ through computation to be made in the comments and not in the answers.","['number-theory', 'conjectures', 'prime-numbers']"
3271522,"$ 5r + 4s + 3t + 6u = 100, \:\: r \ge s \ge t \ge u \ge 0 $ maximum and minimum possible of $r + s + t + u$?","We have $$ 5r + 4s + 3t + 6u = 100, \:\: r \ge s \ge t \ge u \ge 0 $$ What is the sum of the maximum and minimum possible  of $r + s + t + u$ ? Attempt: Assume that $r'+s'+t'+u'$ is the maximum. Now if $u > 0$ , then we can have $$ (r' + K) + s' + t' + (u' - \frac{5}{6} K),  \:\: K > 0 $$ is bigger than the claimed maximum, with ( $r=r'+K, s=s', t=t', u = u' - \frac{5}{6}K$ ). We have a contradiction. So $u'=0$ . Now see $$ 5r + 4s + 3t = 100 $$ Similarly, let $r^{*} + s^{*} + u^{*}$ maximum. Then $$ r^{*} + (s^{*} - \frac{3}{4}C) + (t^{*} + C),  \:\: C > 0 $$ is bigger then the claimed maximum, provided that $s = s^{*} -(3/4)C \ge t = t^{*} + C$ with $$ C \le \frac{4}{7}(s^{*}-t^{*})$$ After this I have no idea.","['contest-math', 'algebra-precalculus']"
3271544,How to prove $\big | e^{it}-1 \big |=2 \bigg |\sin \left(\frac{t}{2}\right) \bigg |$ [duplicate],This question already has answers here : Complex number identity by trigonometry (5 answers) Closed 5 years ago . i started by rewriting: $$\big | \cos(t)+i\sin(t)-1 \big |=2 \bigg |\sin \left(\frac{t}{2}\right) \bigg |$$ $$\bigg | \frac{1}{2}(e^{it}+e^{-it})+\frac{1}2(e^{it}-e^{-it})-1 \bigg |=2 \bigg |\frac{1}{2}(e^{i\frac{t}{2}}+e^{-i\frac{t}{2}}) \bigg |$$ How do I get rid of the absolute value bars?,['complex-analysis']
3271547,Problem 1.23 in Fulton's Algebraic curves,"In Fulton's book ""Algebraic curves - an introduction to Algebraic Geometry"" (freely available from the author's web page http://www.math.lsa.umich.edu/~wfulton/CurveBook.pdf )
problem 1.23 says:
Give an example of a collection $\mathscr S$ of ideals in a Noetherian ring such that no maximal member of $\mathscr S$ is a maximal ideal. But a lemma just before this problem says: Lemma. Let $\mathscr S$ be any non-empty collection of ideals in a Noetherian ring $R$ .Then $\mathscr S$ has a maximal member, i.e. there is an ideal $I$ in $\mathscr S$ that is not contained in any other ideal of $\mathscr S$ . Does this mean that the only solution for the exercise is ${\mathscr S}=\emptyset$ ? If not, what am I missing?","['algebraic-geometry', 'maximal-and-prime-ideals']"
3271590,$\int_0^1\bigl( f(x)+f^{-1}(x )\bigr)\>dx=1$ [duplicate],"This question already has answers here : Show: $ f(a) = a,\ f(b) = b \implies \int_a^b \left[ f(x) + f^{-1}(x) \right] \, \mathrm{d}x = b^2 - a^2 $ [duplicate] (3 answers) Closed 5 years ago . Given any strictly-increasing continuous function $f$ such that $f(0) = 0$ and $f(1) = 1$ , show that $$\int_0^1 [f(x)+f^{-1}(x) ]dx= 1.$$ I tried using mean value theorem but it won't work. I tried few examples it is correct. Edit: If I draw  graph of picture, and seeing integral as area, we can see the integral is just area of the square $\{(0,0),(0,1),(1,1),(1,0)\}$ . Please give me a hint to attack this problem analytically.","['integration', 'calculus', 'derivatives', 'real-analysis']"
3271609,"unknown polynomial divided by $x^2(x-1)$, find the remainder.","I took an exam today and there's a problem stuck in my head; I still can't figure out yet. Here's the question (just the concept as I can't remember precisely). An unknown polynomial divided by $(x-1)^2$ leaves the remainder of $x + 3$ (not sure about the number) and when this polynomial is divided by $x^2 $ , it leaves $2x + 4$ (again, not sure about the number). From the given conditions, if this polynomial is divided by $(x-1)x^2$ , what would be the remainder? The solution as far as I figured out is this: first, from the division of $(x-1)^2$ , I got that $f(1) = 3$ in the same way from division of $x^2$ , I got $f(0) = 4.$ I can write the polynomial as follows: $f(x) = (x-1)(x)(x) g(x) + ax^2 +bx +c$ $ax^2 + bx + c$ is the remainder.  And to find $a,b,c$ , I can use the conditions above, so I got $c = 4$ by substituting $x = 0,$ and I got $a+b+4 = 3$ by substituting $x = 1.$ This leaves $a + b = -1,$ and I can't figure out how to continue; please help. Edit : I made a mistake $f(1)$ should be equal to $4$ and $a+b+c = 4$",['algebra-precalculus']
3271616,Integrating using surface and volume elements,"As a Physics Degree undergraduate, I have been forced countless times to use a certain method to integrate over 3D surfaces and volumes, which my lecturers like to call integration through surface and volume elements . I can't stand this method, nor I could ever understand how to do it, especially because it is not mathematically rigorous. However, at most cases, I'm not able to avoid it. For example - given the electric field of a ring of radius $r$ lying on $z=0$ at the point $(0,0,z_0)$ , I am required to find the electric field of a disk of radius $R$ lying on $z=0$ at the point $(0,0,z_0)$ . In order to do that, I have to use the aforesaid method - integrate the electric field I'm given with respect to the length element $dr$ , from $r=0$ to $r=R$ . Of course, doing that would also require to translate the charge density of a length element, to a charge density of a surface element, assuming they're both unifrom. But - Physics is not my problem here - but the math. And that's why I came here. I tried to understand using this method, but it sometimes works - and sometimes doesn't. I would be glad to know where I'm right, and where I'm wrong. $(\star)$ Important : The angle $\theta$ in Examples 1,2 is the angle of the polar coordinates . In Examples 3,4, it is the polar angle of the spherical coordinates (meaning it is not the azimuthal one). $(\star)$ I will denote $\color{green}{Good}$ in green and $\color{red}{Bad}$ in red. Lowercase will be integration variables, and uppercase would be given parameters. Example 1: Calculating the area of an empty cylinder of radius R and height H A. With respect to $dz$ Given a perimeter of a ring $2\pi R$ , the area of a ring with an infinitesimal height $dz$ would be given by $2\pi Rz$ . And then: $$S=\int\limits_{0}^{H}2\pi Rz\ dz=\color{green}{2\pi RH}$$ A correct answer, gladly. B. With respect to $d\theta$ We know that if we sliced the cylinder vertically, rotating with the angle $\theta$ , we would get lines of height $H$ each, multiplied by an infinitesimal width $Rd\theta$ . Thus, the surface element would be given by $HRd\theta$ . And then: $$S=\int\limits_{0}^{2\pi}HR\ d\theta=\color{green}{2\pi RH}$$ Again - a good answer.
But: this is where things are going to get ugly. Example 2: Calculating the volume of a cylinder of radius R and height H A. With respect to $dr$ We would want to sum cylinders with infinitesimal widths $dr$ , thus the volume element would be given by $2\pi H rdr$ (the perimeter of a ring of radius $r$ multiplied by the infinitesimal width $dr$ and height $H$ ). And then: $$V=\int\limits_{0}^{R}2\pi Hr\ dr=\color{green}{\pi HR^2}$$ This is of course correct, but: B. With respect to $d\theta$ We would want to sum the exact same slices we described at B. of Example 1 , but now they would also have a width of $R$ . Meaning: the volume element would be given by $HR^2d\theta$ (since every rectangle is of dimensions $H \times R$ , and we multiply each by an infinitesimal width $Rd\theta$ ). And now: $$V=\int\limits_{0}^{2\pi}HR^2\ d\theta=\color{red}{2\pi HR^2}$$ This is bad. I would show  you now 2 more examples - in the case of a sphere and a ball. It doesn't work there either. Example 3: Calculating the area of a sphere of radius R With respect to $d\theta$ Given a ring of radius $r$ , it can be easily checked to see that, geometrically, $r$ would be given by $R\sin\theta$ . The infinitesimal width of such disk, would be now $Rd\theta$ , thus the surface element would be given by $2\pi R^2\sin\theta d\theta$ . Therefore: $$V=\int\limits_{0}^{\pi}2\pi R^2\sin\theta \ d\theta=\color{green}{4\pi R^2}$$ Getting optimistic, let's try to calculate the volume of the ball. Example 4: Calculating the volume of a ball of radius R A. With respect to $dr$ We would want to sum spheres, of radius $r$ and infinitesimal width $dr$ each. Thus, the volume element would be given by $4\pi r^2 dr$ , and then: $$V=\int\limits_{0}^{R}4\pi r^2 \ dr = \color{green}{\frac{4}{3}\pi R^3}$$ But unfortunately: B. With respect to $d\theta$ Going again like B. of Example 3 , we would want to sum the exact same rings, but now they would be disks with the infinitesimal width $Rd\theta$ . The volume element would be given by $\pi (R\sin\theta)^2 Rd\theta$ , which leads us to: $$V=\int\limits_{0}^{\pi}\pi R^3 \sin^2\theta\ d\theta=\color{red}{\frac{1}{2}\pi^2 R^3}$$ I tried using the other elements too: $d\varphi$ , for example. the azimuthal angle, which is much more complicated, and also tried other shapes like a cone and even paraboloid. But it just won't work right. It works sometimes - and that's not enough for me, unfortunately. I put many efforts to this post, in order to show you my way of thinking, because that's how I had been taught to do this. But maybe it is not right (it feels like it, for sure). Thank you very much for reading all this, and I would be very glad to hear your thoughts. P.S. : I wish I could add pictures, but I don't know any programs that I can use to draw them.","['integration', 'physics', 'multivariable-calculus']"
3271631,A Special Observation on Prime Numbers and $\pi (n)$,"Update Please check recently posted on M.O $\eth(n)$ is a little algorithm I made, which may appear to be quite complex, so I will start with an example middle of the post. Questions are at the end of the post. Definition Let $W$ be the function ,  defined as $W(a,b)=r$ Let's given $a,b\in \mathbb{N}$ and $a>1$ Take $m$ to be the integer s.t. $a^{m+1} \ge b > a^{m}$ , i.e. $m = \lceil \log{b}/\log{a} \rceil - 1$ . Arrange as: $$a^{m+1} - b$$ $$ = r_{l} a^l + r_{l-1} a^{l-1}+... + r_1 a^1 + r_0 a^0 $$ $$=(r_{l} r_{l-1} ... r_{1} r_{0})_{a}$$ Where $r=\sum_{i=0}^{l}r_{i}$ ●We can prove easily $W(a,b)=r$ iff $b+r\equiv 1($ mod $a-1)$ ● Note $W(a,0)=$ not define Now here $n \in \mathbb{N}$ ◆ $S$ is a function defined as $$S(a,n)=\sum_{i=1}^{a}i^{n}$$ Let's $p$ is prime and $p+1=z$ ◆ $\eth$ is a function defined as $$\eth (n) = \sum_{W(z,W(z,S(z,2n)))\ne z}1$$ ● I strongly observed If $ z>2n+2$ Then $W(z,W(z,S(z,2n)))=z$ Hence I conclude • $$\eth(n)\leq \pi (2n+1)$$ • $$\eth(n) \approx \pi (n)$$ • $$|\eth(n) - \pi (n)|\leq 2$$ Observation table $$\begin{array}{c | c | c |c | }  n & \eth(n) & \pi(n) \\ \hline
1 & 2  & 0 \\ \hline
2 & 3 & 1 \\    \hline 
3 & 3 & 2 \\ \hline
5 &4& 3 \\ \hline
9 &4& 4 \\ \hline
10 &5& 4 \\ \hline
50 &15& 15 \\ \hline
100 &26& 25 \\ \hline
200 &44& 46 \\ \hline
 \end{array}$$ Example we want to find $W(6,W(6,S(6,2)))$ First calculate $S(6,2)=1^{2}+2^{2}+...+6^{2}=91$ $\implies W(6,W(6,91))$ Here for calculate $W(6,91)$ $ 6^{3}-91 = 125 = (325)_{6}$ $\implies r = \sum r_{i} = 3+2+5 =10$ $hence W(6,91) = 10$ Again to calculate $W(6,W(6,91))=W(6,10)$ $6^{2}-10 =26 = (42)_{6}$ $\implies r=\sum r_{i} = 4+2 =6$ Hence $W(6,W(6,S(6,2)))=6$ Table For $W(t,W(t,S(t,2)))$ which helps to calculate $\eth(1)$ . $$\begin{array}{c | c | c |c | }  t & W(t,S(t,2)) & W(t,W(t,S(t,2))) \\ \hline
2 & 2  & 0 \\ \hline
3^{*} & 3 & 0 \\    \hline 
4^{*} & 4 & 0 \\ \hline
5 & 6 & 7 \\ \hline
6^{*} & 10 & 6 \\ \hline
7 &5 & 2 \\ \hline
8^{*} &14& 8 \\ \hline
9 &12& 13 \\ \hline
10 &12& 16 \\ \hline
11 & 15  & 16 \\ \hline
12^{*} & 22 & 12 \\    \hline 
13 & 10 & 3 \\ \hline
14^{*} & 26 & 14 \\ \hline
15 & 21 & 22 \\ \hline
16 &20 & 26 \\ \hline
17 &24& 25 \\ \hline
18^{*} &34& 18 \\ \hline
19 &15& 4 \\ \hline
20^{*} &38& 20 \\ \hline
21 &30& 31 \\ \hline
\vdots &\vdots & \vdots \\ \hline
 \end{array}$$ $t^{*} = z $ From table $W(t,W(t,S(t,2)))$ we can calculate $\eth(1)$ by counting $z$ such that $W(z,W(z,S(z,2)))\ne z$ . we can observe it's only happens when $z=3$ and $4$ hence $\eth(1)= 2 $ ◆ $\chi$ is function defined as $$\chi(n)=\sum_{p \nmid S(p,2n)}1=\sum_{p-1|2n}1$$ And $ n \in \mathbb{N}$ Proof for $\chi(n)$ $\implies \eth (n)\geq \chi(n)$ Question What is formula for $\eth(n)$ ? Can we prove above observation ? You can check by using below program '''python n1= 2
o = 1
while n1 < 300:
    m = 2
    print(""\n n1="",n1)
    #print(""m="",m)

    num=n1
    sum_num = 0

    for i in range(1, num+1): 
        sum_num += i**(m)
    n2 = (sum_num)
    #print(""$n1^2m="",n2)

    rem_array = []
    while n2 != 1:
        mod = n2%n1
        if mod != 0:
          rem = n1-mod
          n2 = n2 + rem
          rem_array.append(round(rem))
          n2 = n2/n1
        else:
            n2 = n2/n1
            rem_array.append(0)         
    #print(rem_array[::-1],sum(rem_array))
    #print(sum(rem_array))

    n2 = sum(rem_array)
    rem_array = []
    while n2 != 1:
        mod = n2%n1
        if mod != 0:
          rem = n1-mod
          n2 = n2 + rem
          rem_array.append(round(rem))
          n2 = n2/n1
        else:
            n2 = n2/n1
            rem_array.append(0)
    #print(rem_array)
    #print(rem_array[::-1],sum(rem_array))
    if(n1 == sum(rem_array)):
        print(""W("",n1,"",W("",n1,"",S("",n1,"",m)))="",n1)
    #else:
        #print(""not ok"")                

    n1 += o '''","['number-theory', 'elementary-number-theory', 'riemann-hypothesis', 'analytic-number-theory', 'prime-numbers']"
3271682,Constructing rings with a specific lattice of ideals.,"Let $R$ be a commutative ring with 1. The ideals of $R$ form a lattice with inclusion as order relation. Let me call it the ideal lattice $L(R)$ of $R$ . Given an arbitrary lattice $L$ , there are some typical operations to obtain new lattices from $L$ . I wonder whether there are rings that have these lattices as their ideal lattices, and can be easily constructed from $R$ . Is there a ring $R'$ so that $L(R')$ is (isomorphic to) the dual lattice of $L(R)$ , i.e. the same lattice but with reversed lattice order. For ideals $I,J\in L(R)$ with $I\subseteq J$ , one can form the interval $$[I,J]:=\{K\subseteq R\text{ an ideal}\mid I\subseteq K\subseteq J\}.$$ This is again a lattice. Is there a ring with an ideal lattice isomorphic to $[I,J]$ ? As an example, I know that for some ideal $I\in L(R)$ , the interval $[I,R]$ is isomorphic to the ideal lattice of the quotient ring $R/I$ . There is an inclusion-preserving one-to-one correspondence between the ideals of $R/I$ and the ideals of $R$ that contain $I$ .","['ring-theory', 'abstract-algebra', 'lattice-orders', 'ideals']"
3271691,Why is it enough for $\lim\limits_{h \to 0} \vert f(x+h)-f(x)\vert = 0$ to show uniform continuity,"I have seen an argument along the lines of: if $f$ is a given function on $\mathbb R$ and, for any $x \in \mathbb R$ , $\lim\limits_{ h \to 0}\vert f(x+h)-f(x)\vert=0$ , then it immediately follows that $f$ is uniformly continuous. My question: I understand why $f$ would be considered continuous in the above case. I am however not sure why $f$ can immediately be considered as uniformly continuous. Is this necessarily true? Thanks for your help","['uniform-continuity', 'real-analysis', 'continuity', 'functional-analysis', 'sequences-and-series']"
3271699,Transitive action of a discrete group on a compact space,"Let $G$ be a discrete countable group acting on a compact, Hausdorff space $X$ . Assume that the action is transitive. Namely, $G\cdot x=X$ , for all $x\in X$ . Does it follow that $X$ is finite? I thought that the answer should be yes, as $G\cdot x$ is then a discrete compact space, and so must be finite. However, I am not sure anymore that I can claim that it is a discrete space. I'd appreciate any help.","['general-topology', 'group-actions', 'compactness', 'group-theory']"
3271730,To show that $o(o(x^3)-\frac{1}{2}x^2)-o(x^3)=o(x^2) \: as \: x \rightarrow 0.$ Apostol Calculus Example 1 pg.288,"I encounter this problem when I was trying to show that $\sec x=1+\frac{1}{2}x^2+o(x^2) \: as \: x \rightarrow 0.$ We know that $\cos x=1-\frac{1}{2}x^2+o(x^3).$ So $\sec x=\frac{1}{1-\frac{1}{2}x^2+o(x^3)} = 1+\frac{1}{2}x^2-o(x^3)+o(o(x^3)-\frac{1}{2}x^2)$ In the the book Calculus Apostol, it states that the the two little o's behind is equal to $o(x^2)$ without an explanation. I could prove that they equal to $o(x)$ since $-o(x^3)+o(o(x^3)-\frac{1}{2}x^2)$ $= -o(x^3)+o(o(x^3)-o(x))$ $= -o(x^3)+o(o(x^3)+o(x)) = -o(x^3)+o(o(x))=o(x)+o(x^3)=o(x).$ But is this correct, if then how can it equal $o(x^2)$ ?","['limits', 'calculus', 'asymptotics', 'real-analysis']"
3271802,Find the unique distribution of a random variable knowing the moments of the random variable,"This problem comes from Allan Gut's 'An Intermediate Course in Probability', but I cannot solve the problem. The random variable $X$ has the property that $$EX^{n}=\frac{2^{n}}{n+1}, \quad n = 1,2, ...$$ Find some (in fact, the unique) distribution of X having these moments. I know that the moment-generating function (MGF) can be expressed as $$\psi_{X}(t)= E\, e^{tX} = 1 + \sum_{k=1}^{\infty}\frac{t^{k}}{k!}EX^{k}.$$ I tried to use this expression to find an expression of the MGF that I can use to identify the distribution: $$\psi_{X}(t) = 1 + \sum_{k = 1}^{\infty}\frac{t^{k}}{k!}\frac{2^{k}}{k+1} = 1 + \sum_{k = 1}^{\infty}\frac{(2t)^{k}}{k!(k+1)}$$ $$ = 1 + \sum_{k = 1}^{\infty}\frac{(2t)^{k+1}}{2t(k+1)!} = 1 + \frac{1}{2t}\sum_{k = 0}^{\infty} \frac{(2t)^{k}}{k!} = 1+\frac{1}{2t}e^{2t}$$ But this is not an MGF I recognize, so I'm not sure how to proceed.","['probability-distributions', 'probability-theory', 'probability']"
3271810,"What is the right way to write $(a,b) \in E$ where $a$ and $b$ are elements of the set $E$?","Let $E$ be a set and $a$ and $b$ two elements of $E$ . How do you write correctly the previous statment using formal language? Let me explain where my question comes from. When I define multiple variables, I oftenly write ""Let $(a,b) \in E$ ..."" by mimicking my teachers. The following examples are what makes me suspicious of this notation : $E$ = { $(x,y)$ | $x$ and $y$ gets some propertie(s)} $E$ = { $x$ | $x$ get some propertie(s)} In the first example, $(a,b) \in E$ make sense to me because $(a,b)$ is an element of $E$ as a couple but $a \notin E$ and $b \notin E$ , which is not as i wanted. Now, the second example seems to have both $a$ and $b$ while $(a,b)$ is not. Looks good to me. Then why don't we write ""Let $(a,b) \in E^{2}$ ..."" ? I suppose it is some sort of convention, but I do not get why we use it since it could cause trouble when we use vectors : let's say $a$ and $b$ are real numbers, we usually write $v = \begin{pmatrix}
    a  \\
    b 
\end{pmatrix}
\in \mathbb{R}^{2}$ . Let's resume. Assuming $E$ is a set like the second example, do we have to write $(a,b) \in E^{2}$ or $(a,b) \in E$ ? In the lastest case, is it a convention or is there a reason i don't know why we do so ?","['elementary-set-theory', 'convention', 'notation']"
3271877,Is the failure of $\mathcal{B}(H)\simeq H\otimes H^*$ in infinite dimensions the reason for non-normal states in quantum information?,"In the algebraic formulation of quantum physics/information, states $\omega: \mathcal{A}\rightarrow \mathbb{C}$ are defined as linear functionals on a $C^*$ -algebra $\mathcal{A}$ (algebra of observables, representable as a subalgebra of $\mathcal{B}(H)$ for some Hilbert space $H$ via the GNS construction) that are positive ( $\omega(A^*A)\geq 0\,\forall A\in \mathcal{A}$ ) and normalized ( $\omega(I)=1$ for $\mathcal{A}$ with unit element $I$ or an equivalent condition for non-unital $\mathcal{A}$ ). These quantum states are then usually represented as density operators defined via $\omega(A)=:\text{Tr}(\omega A)$ , but it is well-known that in infinite dimensions there are so-called non-normal states that are not representable this way. Is this due to the fact that for infinite dimensions $\mathcal{B}(\mathcal{H})\simeq H\otimes H^*$ does not hold?","['c-star-algebras', 'operator-algebras', 'operator-theory', 'functional-analysis', 'quantum-mechanics']"
3271922,Why is Bézout's identity considered an identity?,"In most cases, identities seem to take values and give outputs that are irrelevant to the input data. example: $(a + b)^2  =  a^2 + 2ab + b^2$ $[\cos(x)]^2 + [\sin(x)]^2 = 1$ Yet Bézout's identity only seems to assert the existence of something, not a relation of the above kind. Am I missing something, maybe a way to look at it? [I know this isn't like a usual rigorous question, but something worth considering for those who enjoy mathematical literature] Views even if undecisive would be appreciated.","['elementary-number-theory', 'euclidean-algorithm', 'discrete-mathematics', 'terminology']"
3271948,"Proving limit of f(x) - Tnf(x) (Taylor) is zero, in multivariable calculus","So as we all probably know, for $ f : \mathbb{R} \to \mathbb{R}$ , and $T_nf(x)$ the taylor polynomial at a given point a, we have $\lim\limits_{x \to a} \frac{f(x) - T_nf(x)}{(x-a)^n} = 0$ . Our professor proved this by induction on $n$ , using the fact that $ T_n^{(j)}f = T_{n-j}f^{(j)}$ , where $(j)$ is the j-th derivative, and then using L'Hospital rule we conclude the claim for n+1. After learning some multivariable and vector calculus, we started to learn multivariable Taylor polynomials, which I understand, but we were given the following theorem w/o proof: Let $U \subseteq \mathbb{R}^n$ be an open set, $ a \in U $ , $ f:U \to \mathbb{R}^m$ such that $ f \in C^n(U) $ , i.e. $f$ is differentiable $n$ times in $U$ .
then: $\lim\limits_{x \to a} \frac{f(x) - T_nf(x)}{||x-a||^n} = 0$ or writing equivalently: $\lim\limits_{h \to 0} \frac{f(a+h) - T_nf(h)}{||h||^n} = 0$ So at first glance this looks simple, use induction and only treat the denominator as norm and derivatives are the differentia. But as far as I can gather, L'Hospital doesnt exist in multivariable functions.
How can I start my proof for this , without just using reduction for each parameter and pointing to the single dimension case?","['multivariable-calculus', 'taylor-expansion', 'polynomials', 'limits', 'derivatives']"
3271957,$\|A\|_\infty = \sup_{x\neq 0} \frac{\|Ax\|_\infty}{\|x\|_\infty}=\|A\operatorname{1}\|_\infty$,"Let $A$ be a $n\times m$ matrix, where every entry is either positiv (all entries are positiv) or negativ (all entries are negativ). Then holds: $\|A\|_\infty = \sup_{x\neq 0} \frac{\|Ax\|_\infty}{\|x\|_\infty}=\|A\operatorname{1}\|_\infty$ where $1=(1,1,\dotso, 1)^T\in\mathbb{R}^m$ [It should be $x\in\mathbb{R}^m$ too, this is not mentioned...] The equality $\|A\|_\infty=\|A\cdot 1\|_\infty$ is easy to see. First of all without loss of generality, we can assume that every entry in $A$ is positiv. Definition: It is $\|A\|_\infty=\displaystyle{\max_{i=1,\dotso, n}}\{\sum_{k=1}^m |a_{ik}|\}$ and $\|A1\|_\infty = \|\begin{pmatrix}\sum_{k=1}^m a_{1k}\\\vdots\\\sum_{k=1}^m a_{nk} \end{pmatrix}\|_\infty=\displaystyle{\max_{i=1,\dotso n}}\{\sum_{k=1}^m a_{ik}\}$ Now, I want to see the other equality.
Maybe, it is best to show something like $\|A1\|_\infty\leq \sup_{x\neq 0} \frac{\|Ax\|_\infty}{\|x\|_\infty}\leq \|A\|_\infty$ Where the first inequality, is trivial. So $\|A1\|_\infty\leq \sup_{x\neq 0} \frac{\|Ax\|_\infty}{\|x\|_\infty}$ holds for sure, because the RHS can not be smaller than $\|A1\|_\infty$ , because we take the supremum over every $x\neq 0$ , so espacially $x=1$ (here I mean equality of elements of $\mathbb{R}^m$ ). In that case, we have equality. We are left to show $\sup_{x\neq 0} \frac{\|Ax\|_\infty}{\|x\|_\infty}\leq \|A\|_\infty$ Do you have a hint how to show this?
Writing out the definition of $\|\dot\|_\infty$ for the fraction did not help me for now. Thanks in advance.","['matrices', 'normed-spaces', 'linear-algebra', 'functional-analysis']"
3271973,.derivative of ceil(x) proof and explanation,I know that the derivative is 0 for all x but can somebody explain this to me. I understand derivatives but I have been having a lot of trouble here. I know that $ceil(x)=(x+1/2) - (arctan(tan(pi*(x+1/2))))/(pi)$ for all non integer x so I differentiated that on wolfram alpha https://www.wolframalpha.com/input/?i=derivative+of+(x%2B1%2F2)+-+(arctan(tan(pi(x%2B1%2F2))))%2Fpi and got $1-(csc^2(pi*x)/(cot^2(pi*x)+1)$ and using the desmos graphing calculator to graph this I got https://www.desmos.com/calculator/mmzdqg6nba which is 0 for all non-integer x. can anybody show me an easier way to solve this problem.,['derivatives']
3272018,Equivalence classes of binary matrices under permutations of rows/columns,"Consider an MxN matrix A consisting entirely of 1's and 0's.
Let C be the equivalence class of A under permutations of its rows and permutations of its columns (but not rows with columns). 
Given A, how can I compute an invariant of C which is different for different equivalence classes?
How many classes are there for a given M and N?","['matrices', 'linear-algebra', 'combinatorics']"
3272027,Summation with $\tan^{-1}$,"I have to calculate $$\sum_{1 \le i <j <k \le n}^{} \arctan\left(\dfrac{n}{i} \right) \arctan\left(\dfrac{n}{j} \right)\arctan\left(\dfrac{n}{k} \right) $$ We notice for any positive number $x$ , we have $$\tan^{-1}(x) = \frac{1}{2i}\log\left(\frac{1+ix}{1-ix}\right) = \Im\log(1 + ix)$$ We can rewrite the sum at hand as $$\sum_{k=1}^\infty \tan^{-1}\frac{n}{k} = \Im\left[ \sum_{k=1}^\infty \log\left(1 + \frac{n}{k}\right) \right]
$$ but I can;t go on.","['trigonometry', 'sequences-and-series']"
3272030,Conditional Variance: Is it a random variable?,"Let's X, Y are random variables (i.e. each one maps elements of a sample space to real numbers). In particular, let's  X is such that $X:\Omega \rightarrow \mathcal{R}$ , where $\Omega=\{\omega_1, ..., \omega_n \}$ and $X(\omega_i)=i$ Then the conditional variance $Var(Y|X(\omega_i))$ is a random variable because it maps an element of a sample space of $\Omega$ to $\mathcal{R}$ . Now consider $Var(Y|X(\omega_i)=1 \bigcup X(\omega_i)=2)$ This expression maps a set $\{\omega_1, \omega_2 \}$ to $\mathcal{R}$ . So, it seems no more to satisfy the definition of a random variable. Then what is it? A measure? Perhaps no. 
Thank you for answering.",['probability-theory']
3272057,"Can this relationship between the Harmonic Number, Mertens, and Sum-of-Divisors functions be proven?","I've verified conjectured relationship (3) below for several thousand values of $x$ and suspect that it's true. (1) $\quad H(x)=\sum\limits_{n=1}^x\frac{1}{n}\qquad\qquad\qquad\quad$ ( Harmonic Number Function ) (2) $\quad M(x)=\sum\limits_{n=1}^x\mu(n)\qquad\qquad\qquad$ ( Mertens Function ) (3) $\quad H(x)\stackrel{?}{=}\sum\limits_{n=1}^x\frac{\sigma_1(n)}{n}\,M\left(\frac{x}{n}\right)\qquad\quad(\sigma_1(n)$ is the Sum-of-Divisors Function $)$ Question : Has conjectured relationship (3) above been proven or disproven (or can it be)?","['number-theory', 'mobius-function', 'divisor-sum', 'harmonic-numbers']"
3272063,Coefficients of the characteristic polynomial,"Let $A$ be an $n\times n$ matrix. Then its characteristic polynomial is $$\phi_A(x) = \det(xI - A) = x^n - (\operatorname{tr} A)x^{n-1} + \cdots + (-1)^{n-1}(\operatorname{tr}(\operatorname{adj}A))x + (-1)^n\det A,$$ where $\operatorname{adj}A$ denotes the adjugate matrix of $A$ . My question: Why are the coefficients of $\phi_A$ those shown above? I can see why $(-1)^n\det A$ is the constant term, since $$\det(A) = \phi_A(0) = (0-\mu_1)\cdots(0-\mu_n) = (-1)^n\mu_1\cdots\mu_n,$$ where $\mu_i$ are the roots ( $i=1,\dots,n$ ).  I also see why the coefficient of $x^{n-1}$ is minus the trace, since by Laplace expansion (along the first row): \begin{align*}
    &\det(xI-A)\\[10pt]
   &= \begin{vmatrix}
         x-a_{11} & -a_{12} & \cdots & -a_{1n}\\
         -a_{21} & x-a_{22} & \cdots & -a_{2n}\\
         \vdots & \vdots & \ddots & \vdots\\
         -a_{n1} & -a_{n2} & \cdots & x-a_{nn}
    \end{vmatrix}\\[10pt]
    &= (x-a_{11})\begin{vmatrix}
         x-a_{22} & \cdots & -a_{2n}\\
         \vdots & \ddots & \vdots\\
         -a_{n2} & \cdots & x-a_{nn}
    \end{vmatrix} + \underbrace{a_{12} \begin{vmatrix}
         -a_{21} & \cdots & -a_{2n}\\
         \vdots & \ddots & \vdots\\
         -a_{n1} & \cdots & x-a_{nn}
    \end{vmatrix} + \cdots}_{\text{at most polynomial of degree $n-2$}}\\[10pt]
   &=(x-a_{11})\bigg((x-a_{22})\begin{vmatrix} 
       x-a_{33} & \cdots & -a_{3n}\\
       \vdots & \ddots & \vdots\\
       -a_{n3} & \cdots & x-a_{nn}
    \end{vmatrix}
    +\underbrace{\underbrace{a_{23}\begin{vmatrix} 
       -a_{32} & \cdots & -a_{3n}\\
       \vdots & \ddots & \vdots\\
       -a_{n2} & \cdots & x-a_{nn}
    \end{vmatrix}+\cdots}_{\text{at most polynomial of degree $n-3$}}
     \bigg) + \cdots}_{\text{at most polynomial of degree $n-2$}}\\
    &\kern10pt\vdots\\[10pt]
    &=(x-a_{11})(x-a_{22})\cdots(x-a_{nn}) + \underbrace{\cdots}_{\text{at most polynomial of degree $n-2$}}\\[10pt]
    &= x^n - (a_{11}+a_{22}+\cdots + a_{nn})x^{n-1} + \cdots\\[10pt]
    &= x^n - (\operatorname{tr}A)x^{n-1} + \cdots
\end{align*} (Let me know if there is a more elegant way to obtain this). But what I cannot seem to prove is that the coefficient of $x$ is $ (-1)^{n-1}\operatorname{tr}(\operatorname{adj}A)$ . Attempting to work with the Laplace expansion (as I did to obtain the trace above) is leading me nowhere.","['matrices', 'determinant', 'linear-algebra']"
3272112,What is $\tilde{T}$ in Axler's Linear Algebra?,"On page 97 in section 3.E Axler gives definition 3.90: ""Suppose $T \in L(V,W)$ . Define $\tilde{T}: V/($ null $T) \to W$ by $\tilde{T}(v+$ null $T)=Tv$ ."" Immediately preceding this was just some theorems about the dimensions of quotient spaces. I don't quite understand what the purpose $\tilde{T}$ is, as it doesn't seem to be present in any of the exercises (at least not for 3.E), and it's not expanded upon afterward aside from presenting some statements about it's properties (e.g. $V/($ null $T)$ is isomorphic to range $T$ ). I don't even understand what the map ""represents"". Isn't $v+$ null $T$ a set? But $\tilde{T}$ doesn't equal another set, but rather a particular vector, $Tv$ . Does anyone have insight to this? Or a more common name for $\tilde{T}$ ? I haven't been able to find much on it anywhere.","['linear-algebra', 'linear-transformations', 'quotient-spaces']"
3272123,How to justify solving $f(x+1) + f(x) = g(x)$ using this spectral-like method?,"Let's say that I want to find solutions $f\in C(\Bbb R)$ to the equation $$
f(x+1) + f(x) = g(x)
$$ for some $g\in C(\Bbb R)$ . I can write $f(x+1) = (Tf)(x)$ where $T$ is the right shift operator and rewrite the equation suggestively as $$
(I+ T)f=g.
$$ Formally, I can say that the solution of this equation is $$
f= (I+ T)^{-1} g.
$$ Of course, I am aware that there are infinitely many solutions to the equation but please bear with me for a moment here. By the theory of operator algebra, if $f,g$ are from some nice Banach space $X$ and our linear operator $T:X\to X$ satisfies $\|T\|<1$ , then we have $$
f = \left(\sum_{n=0}^\infty (-T)^n \right)g.
$$ However, it is not unreasonable to expect that we should have $\|T\|=1$ for a right-shift operator in most reasonable function spaces so let's try to solve the equation $$
f= (I+\lambda T)^{-1} g.
$$ for $\lambda <1$ first then we'll take $\lambda\to 1$ . Note that all the steps until now is purely formal since $C(\Bbb R)$ is not a normed space. For a concrete example, let's say we take $g(x) = (x+2)^2$ . The previous method says that we first calculate (for $\lambda<1$ ) $$\begin{align}
f(x) &= \left(I - \lambda T + \lambda^2 T^2 - \dots \right) g(x) \\
&= (x+2)^2 -\lambda (x+3)^1 + \lambda^2 (x+4)^2 + \dots \\
&= \left(1-\lambda+\lambda^2-\dots \right)x^2 + \left(2-3\lambda+4\lambda^2-\dots \right)2x + \left(2^2-3^2\lambda+4^2\lambda^2-\dots \right) \\
&=  \frac{1}{1+\lambda} x^2 + 2 \frac{2+\lambda}{(1+\lambda)^2} x +  \frac{4+3\lambda + \lambda^2}{(1+\lambda)^3}.
\end{align}$$ We shall be brave here and substitute $\lambda=1$ even though the series doesn't converge there. This gives $$
f(x) = \frac 12 x^2 + \frac 32 x + 1
$$ but voilà, for some mysterious reasons unknown to me, this $f$ actually solves our original equation $f(x+1) + f(x) = (x+2)^2$ ! My question is simply: What are the hidden theories behind the miracle we observe here? How can we justify all these seemingly unjustifiable steps? I can't give you a reference to this method because I just conjured it up, thinking that it wouldn't work. To my greatest surprise, the answer actually makes sense. I am sure that similar method is probably practiced somewhere, probably by physicists. Some points worth mentioning: 1.) $C(\Bbb R)$ is probably not the right space to work with since it's not normed. However, I want my answer to be a continuous function on $\Bbb R$ so some form of continuity assumption is needed for our space $X$ . 2.) Norming $C(\Bbb R)$ with $L^\infty$ norm is not the way to go since it is possible that $f$ is unbounded, as our example shows. 3.) The solution $f$ is not unique since the kernel of $(I+T)$ consists of all $C(\Bbb R)$ functions $h$ such that $h(x+1)=-h(x)$ , e.g. $\sin(\pi x)$ . 4.) All the series expansions for $\lambda$ in my example converges when $|\lambda| <1$ but not at $\lambda=1$ but for some reason the result checks out.","['operator-theory', 'banach-algebras', 'real-analysis', 'functional-analysis', 'spectral-theory']"
3272127,Calculate the sum of series with square roots,Calculate the sum of the following series using partial sums: $$\sum_{n=1}^\infty \frac{\sqrt{n+1} - \sqrt{n}}{\sqrt{n} \sqrt{n+1}} $$ I rationalized the upper part of the fraction but I got lost. Could you please help me showing the steps of the how to transform the fraction into a partial sum? Thanks in advance.,"['calculus', 'algebra-precalculus', 'sequences-and-series']"
3272154,Concept of $d\left(\frac{1}{T}\right)$,"In thermodynamics, I was trying to solve the following integral. $$\int_{T_{1}}^{T_{2}} d \ln K=-\frac{\Delta H}{R} \int_{T_{1}}^{T_{2}} d\left(\frac{1}{T}\right)$$ $$\ln K\left(T_{2}\right)-\ln K\left(T_{1}\right)=-\frac{\Delta H}{R}\left(\frac{1}{T_{2}}-\frac{1}{T_{1}}\right)$$ $$\int_{T_{1}}^{T_{2}} d\left(\frac{1}{T}\right)$$ When I was studying this at school, normally we would have an indefinite integral such as $$\int x dx$$ where we have a variable and we are integrating it with respect to a small change to (most of the time) that variable itself, i.e. integrate $x$ with respect to $dx$ . But in this $\int_{T_{1}}^{T_{2}} d\left(\frac{1}{T}\right)$ I was left rather stuck. Are we integrating $1$ with respect to $d\left(\frac{1}{T}\right)$ or is this an incorrect definition of the statement? I'm just a bit confused by what this means in Layman terms. NOTE This is for an introductory chemistry student as well, apologies if the concept seems trivial to others.",['integration']
3272244,$f^{(n)}(x)>0$ for all $n$ implies $1/f(x)$ convex?,"I was wondering if it is true that if for $f:[0,\infty] \rightarrow \mathbb{R}_+$ $$\frac{{\rm d}^n}{{\rm d}x^n} \, f(x) > 0 \qquad \forall n \geq 0$$ then $1/f(x)$ is convex. It is not true if the interval defined above would be finite as can be seen from examples like $\frac{1}{1-x}$ or $-\log(1-x)$ , but it seems different as soon as the interval is infinite.","['functions', 'analysis', 'real-analysis']"
3272246,Mean Value Theorem: Continuous or Defined?,"One of the requirements of the MVT is that the function has to be continuous at each point on the closed interval $a\leq x\leq b$ . If we call the function $f(x)$ , I am confused about how the function is continuous at points $(a, f(a))$ and $(b, f(b))$ . The definition of a function being continuous at a point (let's call that point $(c, f(c)))$ is that $ \lim_{x\to c} f(x) = f(c).$ If we take the point $(a, f(a))$ , in order for $f(x)$ to be continuous at $(a, f(a))$ , $ \lim_{x\to a} f(x) = f(a)$ must hold true. However, it can't because the two sided limit doesn't exist. $x$ can approach $a$ from the right but not from the left, and $x$ can approach $b$ from the left but not from the right. So shouldn't ""has to be continuous at each point"" actually be ""has to be defined at each point""?","['calculus', 'real-analysis']"
3272277,"Let $X=\mathbb{D}^2/\sim$, where $(\cos(\theta),\sin(\theta))\sim(\cos(\theta+\frac{2\pi}{3}),\sin(\theta+\frac{2\pi}{3}))$, $\theta\in \mathbb{R}$","Let $X=\mathbb{D}^2/\sim$ , where $(\cos(\theta),\sin(\theta))\sim(\cos(\theta+\frac{2\pi}{3}),\sin(\theta+\frac{2\pi}{3}))$ for all $\theta\in \mathbb{R}$ . How is this topological space graphically? What does it look like? Thank you.","['general-topology', 'quotient-spaces']"
3272326,Integer solutions to a system equations,"I have the following probem: Find all integer solutions of the following system of equations $$
x + 2y = z ,\hspace{0.5cm} x^2 − 4y^2 + z^2 = 310
$$ So far I have tried, using the fact that $2\cdot5\cdot31=310 = x^2 − 4y^2 + z^2=(x+2y)(x-2y)+z^2=(x+2y-4y)(x+2y)+z^2=(z-4y)z+z^2=z(2z-4y)$ What I don't know how to follow up. Any ideas?","['number-theory', 'discrete-mathematics']"
3272403,Finding the image in an elliptic mirror,"I'm trying to find the location of the image of a point being reflected by a mirror shaped like (half of an) ellipse. The goal is to find a transformation $\mathbb{R}^2\rightarrow \mathbb{R}^2$ which sends each point on one side of the ellipse to the location of its mirror image point on the other side. (Points on the boundary of the ellipse remain fixed.) Previously, I've successfully found this transformation for parabolic mirror. The transformation is $$\widehat{x} = \frac{1+\sin{\alpha}}{\cos{\alpha}}\\ \widehat{\alpha} = \frac{1/4x^2-f}{x}$$ which you can prove using the following diagram. The coordinate system is chosen to take advantage of the parabola's reflective property: it sends vertical lines to lines through the focus and vice-versa; this is evident in the way that $\widehat{x}$ only depends on $\alpha$ and $\widehat{\alpha}$ only depends on $x$ . I thought it would be similarly straightforward to compute this transformation for an ellipse. I expected that here a convenient choice of coordinate system would be the angle formed between the target point and each focus—but when I attempt to use the ellipse's reflective property (rays from one focus reflect into the other focus) and solve for the location of the image point, I get increasingly hairy math involving quadratic equations (where the ray from one focus toward the point intersects the boundary of the ellipse) and nothing seems to simplify. I expected elegance similar to the parabola—am I taking a wrong approach somehow? (And if not, what's the explanation for the difference?) Edit: I did find another almost-convenient coordinate system $\langle \theta_1, \theta_2\rangle$ ; for a given point, to compute $\theta$ , draw a ray from the point to one focus. Find the point where the ray intersects the ellipse. The angle between that intersection point and the origin is $\theta$ . Doing so for both foci gives two angles. By the reflection property of the ellipse, the reflection map simply exchanges the angles $\theta_1 \leftrightarrow \theta_2$ . This is mathematically simple, but unsatisfying to me for a few reasons. First, the angles $\theta$ seem unnatural because they involve computing a point of intersection, which feels like a complicated intermediate variable. (I wish we could solve in terms of more natural-seeming parameters such as the angles between the foci and the point— which might still be difficult, because there are many confocal ellipses and so some intersection with the boundary must be involved somewhere.) Second, it doesn't seem to obviously relate to the formula I got for the parabola, whereas I would expect the parabola formula to emerge as an extreme limiting case of the ellipse.","['conic-sections', 'geometry']"
3272450,"The proof of SVD solver formula, $C^T C = V \Sigma^T \Sigma V^T$","This formula could be used to compute matrix multiplication transpose $${\displaystyle (\mathbf {AB} )^{\mathsf {T}}=\mathbf {B} ^{\mathsf {T}}\mathbf {A} ^{\mathsf {T}}}$$ This formula is used to elaborate matrix multiplication associativity $${\displaystyle (\mathbf {AB} )\mathbf {C} =\mathbf {A} (\mathbf {BC} )}$$ This formula is used to compute svd of a matrix. $$C = U \Sigma V^T$$ this MIT course puts them together and gives (equation_1) $$C^T C = V \Sigma^T \Sigma V^T \tag 1$$ what is the detailed proof for equation_1? first, what is the detailed procedure of $C^TC = (U \Sigma V^T)^TC$ how can I transfer this to $U^TU$ ? $$C^T = V \Sigma^T U^T$$","['matrices', 'linear-algebra', 'svd']"
3272542,A simple game on infinite chessboard,"Player $A$ chooses two queens and an arbitrary finite number of bishops on $\infty \times \infty$ chessboard and places them wherever he/she wants. Then player $B$ chooses one knight and places him wherever he/she wants (but of course, knight cannot be placed on the fields which are under attack by $A$ ). Then the game starts. First move is a move by player $A$ , then by player $B$ , and so on... If $A$ succeeds in finding a trap for $B$ (check-mates him) the game is over and $A$ wins. If $B$ can avoid being check-mated indefinitely then $B$ wins . Does $B$ always has a winning strategy? There are two versions of this game: 1) Knight is not allowed to capture figures of $A$ . 2) Knight is allowed to capture figures of $A$ . I would very like to see the solution of at least one of those two versions. For the purposes of this question, suppose whatever version you want. This is one of my problems, I like to create problems, especially simple ones. Peter mentioned a very good question in a chat, namely the issue of a draw, so *) If a knight is not under attack at some field but cannot move anywhere because all the fields where he can move are under attack then that is a draw. So, $A$ wins if he/she checkmates knight, that is, if she/he attacks knight and knight does not have a field to move on because all are under attack, including the one at which he is at. Notify me if we can improve this question. Also, I think that there is an amount of bishops that guarantees the win of $A$ , but do not know bounds on the number of bishops that guarantee the win. And, if knight is not allowed to capture figures of $A$ , then I think that two queens and three bishops always have a winning strategy. Update : We have some strategies for $7$ bishops alone, which would mean that two queens and five bishops are enough, but with two queens the $5$ is too many bishops, Peter has the question on ""are only two queens sufficient""? Also, now I think that two queens and two bishops are enough to always secure a winning strategy.","['game-theory', 'infinite-games', 'combinatorics', 'chessboard']"
3272545,Are countable topological spaces second-countable?,Are countable spaces (i.e. $\mathbb{N}$ with any topology) second-countable? A countable space can have at most $2^\omega$ open subsets which suggests that a counterexample may exist. On the other hand both discrete and anti-discrete (or more generally with countable topology) spaces are second-countable. Also note that obviously a countable space is separable. So if it is additionally metrizable then it is second-countable. But I couldn't prove that in general. Or is there a counterexample?,"['general-topology', 'second-countable']"
3272670,Does $\int_0^x f(t)dt=\int_0^x f(x-t)dt$ hold always?,"Question I have found out that for many functions ( $f(x)=x$ , $f(x)=e^x$ , $f(x)=\frac{1}{x+1}$ , etc.) the following expression is satisfied: $\int_0^x f(t)dt=\int_0^x f(x-t)dt$ . I am wondering: does this hold always, or it is just a nice property of a particular kind of functions? My question arises from the fact that in general $\int_a^x f(t)dt\neq\int_a^x f(x-t)dt$ , but when $a=0$ I have observed the equality to hold. Attempt of formal proof I have tried to prove the expression following the path of the proof of the fundamental theorem of calculus. Given $f(x)$ , we know that $F(x)=\int_a^x f(t)dt$ satisfies $F^\prime(x)=f(x)$ , where $a$ is set arbitrarily to $0$ . If we can prove that $G(x)=\int_0^x f(x-t)dt$ satisfies $G^\prime(x)=f(x)$ , then $\int_0^x f(t)dt=\int_0^x f(x-t)dt$ . I tried with the following steps. $G(x_1)=\int_0^{x_1} f(x_1-t)dt$ $G(x_1+\Delta x)=\int_0^{x_1+\Delta x} f(x_1+\Delta x-t)dt$ $G(x_1+\Delta x)-G(x_1)=\int_0^{x_1+\Delta x} f(x_1+\Delta x-t)dt-\int_0^{x_1} f(x_1-t)dt$ At this point the functions under the two integrals are different, so I get stuck. Related question I really struggle in finding an interpretation to the difference between $\int_0^x f(t)dt$ and $\int_0^x f(x-t)dt$ , if there is any at all. Can anyone suggest a practical explanation?","['integration', 'definite-integrals', 'calculus', 'functions', 'change-of-variable']"
3272672,Primes $p$ which satisfy $p \mid \sum_{i=1}^{p-1} i!$,"This question is inspired from @Mathphile's problem: The value $\sum_{i=1}^n i!$ where $n \in \mathbb{N}$ , is only semiprime for $n=3,4$ One can easily solve this conjecture by knowing that $9 \mid \sum_{i=1}^8 i!$ which implies that $9 \mid \sum_{i=1}^n i!$ for any $n \geqslant 8$ . We can notice: $$p \mid \sum_{i=1}^{p-1}i! \implies p \mid \sum_{i=1}^ni! \quad (n \geqslant p-1)$$ Are there finitely or infinitely many primes of this form? If there are an infinite number of them (which heuristically seems to be the case), we consequently have $\sum_{i=1}^n i!$ to have an arbitrarily large number of divisors (or prime divisors) $\forall$ $n>N$ for sufficiently large $N$ . Can we extend this to $p^k \mid \sum_{i=1}^{p^k-1} i!$ (for this to hold, it must hold for all powers $p^j$ for $1 \leqslant j \leqslant k$ )?","['number-theory', 'factorial', 'prime-numbers']"
3272712,Solve $3x^5-6x^3=0$ (Presumably using factoring?),I am to solve $3x^5-6x^3=0$ The solutions are provided as 0 and $\pm\sqrt{2}$ and I cannot see how to arrive at this. I wnet down various paths trying to factor the starting equation but that never got me anywhere e.g. $3x^5-6x^3=0$ $3x^2(x^3-2x)=0$ # now what? Also tried: $3x^5-6x^3=0$ $3x(x^4-2x^2)$ # where do I go from here? Is factoring the right path? How do I know how to approach this problem? How can I solve this equation?,"['algebra-precalculus', 'roots', 'factoring']"
3272731,Topological p-adic vector spaces are totally disconnected?,"Let $V$ be a $\mathbb{Q}_p$ -vector space endowed with a Hausdorff topology such that addition and scalar multiplication are continuous. Is $V$ necessarily totally disconnected? I am in particular interested to the case of normed (or even Banach) $\mathbb{Q}_p$ -vector spaces, with the topology induced by the norm. I know that ultrametric spaces are automatically totally disconnected but I'm not sure any normed vector space over $\mathbb{Q}_p$ is automatically ultrametric...","['banach-spaces', 'p-adic-number-theory', 'normed-spaces', 'topological-vector-spaces', 'functional-analysis']"
3272736,"Covariance of continuous functions, uniform and normal distribution","For X~Uniform(1, 9.9) and Y|X = x~Normal(1.4, x^2) What is Cov(X, Y) equal to? What I tried was:
E[XY] - E[X]E[Y] Where E[X] = 5.45 and E[Y] = 1.4 But for E[XY] I'm a bit clueless. I've considered: $$ \int_1^{9.9}\int_{-\infty}^{\infty} xx \frac{1}{9.9-1} \frac{e^-\frac{x^2}{2}}{\sqrt{2\pi}} dxdx = 1$$ or is E[XY] more like: $$ \int_1^{9.9}\int_{-\infty}^{\infty} xy \frac{1}{9.9-1} \frac{e^-\frac{(y-1.4)^2}{2x^2}}{\sqrt{2\pi x^2}} dydx = 7.63 $$ and now I realized that 7.63 is already equal to 5.45*1.4 so that would result in 0...","['statistics', 'covariance', 'uniform-distribution', 'probability-distributions', 'normal-distribution']"
3272745,"How to prove $\sum\limits_{i=1}^n \sum\limits_{j=1}^n \min\{s_i,s_j\}=\sum\limits_{k=1}^M c_k^2$","Let us assume that $s_1,\dots,s_n$ are some given non-negative integers. Let $M=\max\{s_1,\dots,s_n\}$ and for any $k$ let use denote $c_k=|\{i=1,\dots,n; s_i\ge k\}|$ . (In the other words, $c_k$ is the number of elements of the given set which have size at least $k$ .) Then $$\sum\limits_{i=1}^n \sum\limits_{j=1}^n \min\{s_i,s_j\}=\sum_{k=1}^M c_k^2.\tag{*}$$ (Notice that $c_0=n$ , however the term $c_0^2$ is not included on the RHS.) How can we prove this? This equality seems to be rather elementary (and I have included a proof by induction below). Still, I suppose that there are many interesting ways to prove this, so I thought that it might be reasonable to ask here to see various approaches to this sum and various ways to formulate the arguments why this equality holds. Motivation. This expression appears naturally in some considerations about commuting matrices. See, for example, Robert Israel's answer to Dimension of a subspace of $M_n(\mathbb C)$ . (The sum here is the formula he mentions in the last paragraph, in the case when there is only a single eigenvalue.) Example. Just to make sure that we are not trying to prove something which does not hold, let's have a look at least at one example. (After all, having some examples in front of us might be also useful when thinking about proofs.) Let us try the numbers $1$ , $1$ , $2$ , $3$ , $3$ , i.e., $s_1=s_2=1$ , $s_3=2$ , $s_4=s_5=3$ . We can write down the following table, where we have $\min\{s_i,s_j\}$ in the position $(i,j)$ and the last row/column contain the sums. $$
\begin{array}{ccccc|c}
  1 & 1 & 1 & 1 & 1 & 5 \\
  1 & 1 & 1 & 1 & 1 & 5 \\
  1 & 1 & 2 & 2 & 2 & 8 \\
  1 & 1 & 2 & 3 & 3 &10 \\
  1 & 1 & 2 & 3 & 3 &10 \\\hline
  5 & 5 & 8 &10 &10 &38
\end{array}
$$ At the same time we get $c_1^2+c_2^2+c_3^2=5^2+3^2+2^2=25+9+4=38$ . A special case. In particular, if we take $s_i=i$ , then we get the sum $$\sum\limits_{i=1}^n \sum\limits_{j=1}^n \min\{i,j\}=\sum_{k=1}^n (n-k+1)^2 = \sum_{k=1}^n k^2 = \frac{n(n+1)(2n+1)}6.\tag{⋄}$$ This sum seems to me as a rather natural exercise to give students for manipulation with sums and for trying out combinatorial proofs. I have tried searching whether there is some question on this site about $(\diamond)$ . I did not find such question - the closest one I've seen was this one: How prove this identity $\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}\min{\{i,j\}}(a_{i}-a_{i+1})(b_{j}-b_{j+1})=\sum\limits_{i=1}^{n}a_{i}b_{i}$ ? EDIT: After searching a bit more I found Combinatorial proof of $\sum_{1\le i\le n,\ 1\le j\le n}\min(i,j)=\sum_{i=1}^ni^2=\frac{n(n+1)(2n+1)}6$ and A Combinatorial proof for the identity $\sum_i \sum_j \min(i,j) = \sum_k k^2$ Proof by induction. There are certainly various more clever proofs, but as a starting point we can try induction on $M$ . $1^\circ$ If $M=0$ , then both sides of $(*)$ are equal to zero. $2^\circ$ Let us assume that the claim is true whenever we have number with maximum less than $M$ . W.l.o.g. we can assume that $s_i\ge1$ for each $i$ . (If suffices to notice that by including also $s_i$ 's for which $s_i=0$ we add zero to both sides. The RHS is not influenced at all, since such $s_i$ 's do not count in $c_k$ for $k\ge1$ . On the LHS we are only adding/omiting the terms of the form $\min\{0,s_i\}=0$ .) With this assumption we can use $s'_i=s_i-1$ . We can then apply the induction hypothesis on the numbers $s'_i$ . By noticing that $\min\{s_i,s_j\}=\min\{s'_i,s'_j\}+1$ and $c_k=c'_{k=1}$ we get \begin{align*}
S
&=\sum\limits_{i=1}^n \sum\limits_{j=1}^n \min\{s_i,s_j\} \\
&=\sum\limits_{i=1}^n \sum\limits_{j=1}^n (1+\min\{s'_i,s'_j\}) \\
&=n^2+\sum\limits_{i=1}^n \sum\limits_{j=1}^n \min\{s'_i,s'_j\} \\
&=n^2+(c'_1)^2+\dots+(c'_{M-1})^2= \\
&=m^2+c_2^2+\dots+c_M^2= \\
&=c_1^2+c_2^2+\dots+c_M^2
\end{align*}","['algebra-precalculus', 'summation']"
3272758,Prove $\lim\limits_{n\to \infty}\frac{1}{\sqrt n}\left|\sum\limits_{k=1}^n (-1)^k\sqrt k\right|= \frac{1}{2}$,"I'm trying to show that $$\lim_{n\to \infty} x_n=\lim_{n\to \infty}\frac{1}{\sqrt n}\left|\sum_{k=1}^n (-1)^k\sqrt k\right|= \frac{1}{2}.$$ Assuming $\lim\limits_{n\to\infty} x_n=x$ exists, we have $$x_{2n}=\frac{\sqrt{2n-1}(-x_{2n-1})+\sqrt {2n}}{\sqrt {2n}}$$ Letting $n\to \infty$ , $$\quad \quad x=-x+1$$ $$x=\frac{1}{2}$$ But I'm stuck on proving the existence of $\lim x_n$ . Any idea? Update: I just solved the problem using sandwich theorem + integral test. Still, I would like to see a continuation of my initial idea, i.e. proving $\{x_{2n}\}$ is monotonically increasing (similarly, $\{x_{2n+1}\}$ is monotonically decreasing)","['limits', 'sequences-and-series', 'real-analysis']"
3272785,Show that the tangent bundle $TM $ of a variety $M$ is Hausdorff.,"I read a Lemma Introduction to smooth manifolds"" which says that given a smooth n -manifold 𝑀, then the tangent bundle 𝑇𝑀 is a smooth 2𝑛-manifold, how can I prove this?","['manifolds', 'tangent-bundle', 'differential-geometry']"
3272797,Show that $p'(c)+100p(c)=0$,"Let $p(x)$ be a polynomial with real coefficients such that $a\le c \le b$ where $a,b$ are two consecutive roots of $p(x)$ . Show that there exists at least one c for which $$p'(c)+100p(c)=0$$ Okay, so this is what I tried, By Lagrange's Mean Value Theorem we can find a point $c$ in the interval $[a,b]$ such that $p'(c)=0$ but at that time, $100p(c)$ is not $0$ . I tried some other ways but I don't think those will work. Any help is appreciated.","['contest-math', 'calculus', 'derivatives']"
3272856,"Stuck on this - In ABC right triangle AC= $2+\sqrt{3}$ and BC = $3+2\sqrt{3}$. circle touches point C and D, Find the Area of $AMD$","In ABC right triangle $AC= 2+\sqrt{3}$ and $BC = 3+2\sqrt{3}$ . circle touches point C and D, Find the Area of $AMD$ Here's my strategy of solving this, I'm not sure if it's correct, if you find my explanation hard to understand you can just ignore and write the solution in your own way, thanks. 1. first area of main triangle, we know AC and CB so it'll be easy to calculate that, 2. to find the radius, we'll reflect triangle ABC on the left side of the circle, turning it into circle inscribed in isosceles triangle, and find it with the formula 3. to find the area of $AMD$ I'll subtract the area of sector $OMD$ , triangle $OAD$ and triangle $CDB$ from triangle $AMD$ , 4. $DBC$ is an isosceles triangle, so $CB=DB$ , then to find the area, I split it into 2 right triangles(it becomes 90 30 60 triangle) and find its height. So we got the Area of $DBC$ 5. Now similarly $OAD$ is isosceles, $OD=OC=radius$ of the circle  which we ""found""
also, split this in 2 to get right triangles and then calculate with Pythagorean theorem to find the height so we get Area of $OMD$ too, maybe we could find angles with trigonometry? I don't know that, and if we get the angle of $DOA$ we could find the sector $OMD$ as well and subtract it to the main triangle so we get the area of $AMD$ .","['triangles', 'circles', 'geometry']"
3272861,"Are there squares $s$ other than $9$, $121$, and $361$ such that the number of primes $\leq s$ divides the number of composites $\leq s$?","Let $C(n)$ be a function that counts composites $\leq n$ , $P(n)$ be a function that counts primes $\leq n$ , and $s$ be a perfect square. How many squares $s$ have the property $C(s)/P(s)$ is an integer? For example, with $s=3^2=9$ , we have $C(9) = \{4,6,8,9\} = 4$ and $P(9) = {2,3,5,7} = 4$ , so $C/P = 4/4 = 1$ . Also, $s=11^2=121$ and $s=19^2=361$ have the property that $P(s)$ divides $C(s)$ evenly, but I find no other $s \leq 30000^2$ . Is there a number theory argument for $9$ , $121$ , and $361$ being the only possible squares?","['number-theory', 'prime-numbers']"
3272870,A level conditional probability,"In an A Level maths textbook, the answer to an exercise question involves the use of $$P(B|A')=1-P(B|A)$$ where A and B are two events. However, this equality has never been mentioned elsewhere in the curriculum and does not seem to yield the correct answers for conditional probability questions. So does such an identity actually hold true or could it be just a typo? If it is true then how can one make sense out of it?","['conditional-probability', 'intuition', 'statistics', 'probability']"
3272894,Find an example of a set of points of the plane such that there exist at least $2^{n-2}$ good partitions.,"If a set of $n$ points of the plane can be divided into two subsets $\{ A_1, A_2, \dots,  A_k\}$ and $\{ B_1, B_2, \dots, B_{n-k}\}$ so that there is a point $M$ of the plane such that $$ MA_1+ MA_2+ \dots+MA_k= MB_1+ MB_2+ \dots+MB_{n-k},$$ then we shall say that there exists a good partition of the set of these $n$ points of the plane. Prove that for all $n \ge 2$ there is a set of $n$ points of the plane such that the number of good partition of this set is not less than $2^{n-2}$ . Partitions in which two sets $A$ and $B$ change between themselves are the same partitions. My work . I tried to place points at the vertices of a regular polygon or on a line at the same distance from each other. But it is difficult to prove the problem for these cases.","['contest-math', 'geometry', 'combinatorial-geometry', 'combinatorics', 'plane-geometry']"
3272898,Number of Regions for a Central Hyperplane Arrangement,"This question has likely been answered in full detail before, so any references would be greatly beneficial.  The question I have is as follows: Suppose we have $m$ central hyperplanes in $\mathbb{R}^n$ , that is, $m$ hyperplanes of dimension $n-1$ that cross through the origin.  How many regions does this arrangement split $\mathbb{R}^n$ into? It isn't difficult to find the answer for noncentral arrangements, this is given by Zaslavsky's Theorem.  Furthermore there is a detailed treatment of hyperplane arrangements in ""An Introduction to Hyperplane Arrangements"" at https://www.cis.upenn.edu/~cis610/sp06stanley.pdf . However, I wasn't able to find the result I am looking for. What I could find is that if we allow the hyperplanes to be in general position, then the arrangement $A$ of $m$ hyperplanes in $\mathbb{R}^n$ has \begin{equation}
r(A) = \sum_{j=0}^n {m \choose j}
\end{equation} regions. For the central arrangement question, the interesting case is when $m > n$ .  I believe that when $m \leq n$ , the number of regions is simply $2^m$ .","['mobius-inversion', 'mobius-function', 'combinatorics', 'geometry']"
3272913,"Probability question from British Math Olympiad, 1973","Recently I got a problem from British Math Olympiad, 1973
It is a probability question. In answering general knowledge questions (framed so that each question is answered yes or no), the teacher's probability of being correct is $\alpha$ and a pupil's probability of being correct is $\beta$ or $\gamma$ according to as the pupil is a boy or a girl. 
  The probability of a randomly chosen pupil agreeing with the teacher's answer is $\dfrac{1}{2}$ . 
  Find the ratio of a number of boys to girls in the class. I did it as $$b=\text{Number of boys}$$ $$g=\text{Number of girls}$$ so $$\frac{1}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{b+g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)\Bigg(\dfrac{g}{b+g}\Bigg)$$ $$\frac{b+g}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)b+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)g$$ divide by g $$\frac{b+g}{2g}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)\Bigg(\dfrac{g}{g}\Bigg)$$ $$\frac{b}{2g}+\frac{1}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)$$ $$\frac{b}{2g}-\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)=\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)-\dfrac{1}{2}$$ $$\frac{b}{g}=\dfrac{\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)-\dfrac{1}{2}}{\dfrac{1}{2}-\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)}$$ Is it right? Need Suggations.","['contest-math', 'algebra-precalculus', 'probability']"
3272917,"diffeomorphism from GL(n,$\Bbb {R}$) to SL($n,\Bbb {R}$) $\times \Bbb{R}^{\times}$","It is Loring W.Tu ""An introduction to manifolds"" problem 15.9 $f$ has a inverse $$g: (A, r)\mapsto AM_r$$ but how to show both $f$ and $g$ are $C^\infty$ ? SL( $n,\Bbb R$ ) have $n^2−1$ coordinates, not its entries edit：from Chrystomath's answer, I understood that $f$ is $C^\infty$ , but I cannot follow his proof about $g$ , I'm just a beginner in manifold","['manifolds', 'general-topology', 'differential-geometry']"
3272932,Derivative of eigenvalue of matrix with respect to its elements,"Assuming that matrix $A$ is positive semidefinite and that $\lambda$ denotes the eigenvalue, I would like to compute the following gradient $$\nabla_A \lambda(A)$$ I wanted to set this problem up as follows: $$\frac{ \partial \lambda(A)}{\partial A} = \frac{ \partial \lambda(A)}{\partial tr(A)} \frac{ \partial tr(A)}{\partial (A)} = I$$ However, I found different solutions online, namely : $$\partial \lambda(A) / \partial A_{ij} = (\mu \cdot b_i) (\mu \cdot b_j)$$ where $\mu$ is the associated eigenvector. What am I doing wrong? Thanks in advance for your help!","['positive-semidefinite', 'eigenvalues-eigenvectors', 'matrices', 'matrix-calculus', 'derivatives']"
3272934,Is $T(C) \subseteq R^m$ closed?,"Let $C \subset R^n$ be a closed, convex cone. Let $T: R^n \to R^m$ be a linear transformation. Is $T(C) \subseteq R^m$ closed? I'm very positive that the answer is NO. But I couldn't come up to a counter example so far. I also realized that any counter example (if exists) has to be in Dimension $n \geq 3$ , otherwise $C$ becomes a polyhedral and so is $T(C)$ .","['general-topology', 'convex-analysis', 'functional-analysis']"
3272960,"What Does ""Collection of Measure is Tight?'' Mean","I know that a collection of probability measure $(\mu_\varepsilon )_{\varepsilon > 0}$ on a (topological) measure space $(X,\mu)$ is tight if for all $\varepsilon >0$ , there is a compact $K_\varepsilon \subset X$ such that $\mu_\varepsilon (K_\varepsilon)>1-\varepsilon $ for all $\varepsilon >0$ . Question : What does this mean concretely, and why is this important ?","['measure-theory', 'probability']"
3272999,"Why $(\max\{0, x\})^n$ is a differentiable function?","I am reading this post that proves why $\max\{0,x\}$ is not differentiable. But why $(\max\{0, x\})^n$ for $n>1$ is differentiable?",['derivatives']
3273012,Axioms for homology and cohomology for CW complexes,"This is related to assertion made in Hatcher, Algebraic Topology, Chpt 3, Sec 1 and Chpt 2. I will write down axioms for cohomology and axioms for homology is written in a similar fashion. Cohomology theory for CW complexes is a sequence of contravariant functors with boundary map $\delta:H^n(A)\to H^{n+1}(X/A)$ where $(X,A)$ is a CW pair which implies $X/A$ makes sense as CW complex and it satisfies the following axioms. (1) If $f,g$ are homotopic, then $f,g$ induces same map on cohomology. (2) For each pair CW complex $(X,A)$ , there is a induced long exact sequence by $...H^n(X/A)\to H^n(X)\to H^n(A)\to H^{n-1}(X/A)...$ (3) For wedge sums of $X_i$ CW complexes, $X=\vee X_i$ for canonical inclusion $X_i\to X$ , $H^\star(X)\cong\prod_iH^\star(X_i)$ . $\textbf{Q:}$ For Eilenberg-Steenrod Axioms, I do recall that for disjoint spaces $X=\bigsqcup X_i$ , I have $H^\star(X)\cong\prod_i H^\star(X_i)$ . How did disjoint union follows from above axioms? Note that I do not even have $H^i(pt)=0$ for $i\neq 0$ here and neither can I say $H^i(\bigsqcup x_j)=\bigoplus_jH^i(x_j)$ for $x_j$ being points. So I do not even see how to apply $(2)$ .","['general-topology', 'algebraic-topology']"
3273017,Question about the union of an empty set,"I would like some clarification regarding the following text from a textbook: There is no problem with these definitions if one of the elements of $\mathscr{A}$ happens to be the empty set. But it is a bit tricky to decide what (if anything) these definitions mean if we allow $\mathscr{A}$ to be the empty collection. Applying the definitions literally, we see that no element of $x$ satisfies the defining property for the union of the elements of $\mathscr{A}$ . So it is reasonable to say that $$ \bigcup_{A \in \mathscr{A}}A=\emptyset$$ If $\mathscr{A}$ is empty. On the other hand, every $x$ satisfies (vacuously) the defining property for the intersection of the elements of $\mathscr{A}$ . I wanted to know why we don't say that every $x$ vacuously satisfies the defining property for the union of the elements of $\mathscr{A}$ ? Does it just come down to convention?",['elementary-set-theory']
3273031,Fresnel integral $\int\limits_0^\infty\sin(x^2) dx$ calculation,"I'm trying to calculate the improper Fresnel integral $\int\limits_0^\infty\sin(x^2)dx$ calculation.
It uses several substitutions. There's one substitution that is not clear for me. I could not understand how to get the right side from the left one. What subtitution is done here? $$\int\limits_0^\infty\frac{v^2}{1+v^4} dv = \frac{1}{2}\int\limits_0^\infty\frac{1+u^2}{1+u^4} du.$$ Fresnel integral calculation: In the beginning put $x^2=t$ and then: $$\int\limits_0^\infty\sin(x^2) dx = \frac{1}{2}\int\limits_0^\infty\frac{\sin t}{\sqrt{t}}dt$$ Then changing variable in Euler-Poisson integral we have: $$\frac{2}{\sqrt\pi}\int_0^\infty e^{-tu^2}du =\frac{1}{\sqrt{t} }$$ The next step is to put this integral instead of $\frac{1}{\sqrt{t}}$ . $$\int\limits_0^\infty\sin(x^2)dx = \frac{1}{\sqrt\pi}\int\limits_0^\infty\sin(t)\int_0^\infty\ e^{-tu^2}dudt = \frac{1}{\sqrt\pi}\int\limits_0^\infty\int\limits_0^\infty \sin (t) e^{-tu^2}dtdu$$ And the inner integral $\int\limits_0^\infty \sin (t) e^{-tu^2}dt$ is equal to $\frac{1}{1+u^4}$ . The next calculation: $$\int\limits_0^\infty \frac{du}{1+u^4} = \int\limits_0^\infty \frac{v^2dv}{1+v^4} = \frac{1}{2}\int\limits_0^\infty\frac{1+u^2}{1+u^4} du = \frac{1}{2} \int\limits_0^\infty\frac{d(u-\frac{1}{u})}{u^2+\frac{1}{u^2}} $$ $$= \frac{1}{2} \int\limits_{-\infty}^{\infty}\frac{ds}{2+s^2}=\frac{1}{\sqrt2}\arctan\frac{s}{\sqrt2} \Big|_{-\infty}^\infty = \frac{\pi}{2\sqrt2} $$ In this calculation the Dirichle's test is needed to check the integral $\int_0^\infty\frac{\sin t}{\sqrt{t}}dt$ convergence. It's needed also to substantiate the reversing the order of integration ( $dudt = dtdu$ ). All these integrals exist in a Lebesgue sense, and Tonelli theorem justifies reversing the order of integration. The final result is $$\frac{1}{\sqrt\pi}\frac{\pi}{2\sqrt2}=\frac{1}{2}\sqrt\frac{\pi}{2}$$","['integration', 'improper-integrals', 'definite-integrals', 'analysis', 'calculus']"
3273044,"Invertible elements of $A[t, t^{-1}]$","Let $A$ be a commutative ring and consider the Laurent polynomial ring: $$A[t,t^{-1}]:=\left\{\sum_{i\in\mathbb Z} a_it^i: \text{$a_i=0$ for almost all $i$}\right\}.$$ What is the group of invertible elements $\left(A[t, t^{-1}]\right)^\times$ ? Is it the set of all polynomials whose lowest degree coefficient is invertible?","['localization', 'ring-theory', 'abstract-algebra']"
3273061,Perfect finite groups with balanced presentations,"A balanced presentation for a group is a presentation with an equal number of generators and relations.  A perfect group is a group that is equal to its commutator group. I am wondering what finite perfect groups are known to admit balanced presentations?  I only know two example: the trivial group and the binary icosahedral group $\langle x,y \mid x^2=y^3=(xy)^5\rangle$ .  What are some other examples?","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'finite-groups']"
3273125,Condition for positive Determinant,"If we have that for any non-zero vector $x$ that $Ax\cdot x$ is a positive, why is determinant of $A$ positive?","['matrices', 'determinant']"
3273126,On equivalent ways to obtain the modulus of the gradient.,Recently I was following a seminar of one of the great living Italian mathematicians: Luigi Ambrosio (recently his student Alessio Figalli won the fields medal). One of his slides was dealing with the Eulerian/Lagrangian duality (a concept I was not so familiar with): I have two questions: Could one provide some intuition as to why these 3 ways of computing the modulus of the gradient are the same and could I have a reference to a proof of this fact? I am interested in all three equivalencies.,"['derivatives', 'differential-geometry', 'real-analysis']"
3273174,"proof verification: $f(x) = 1/x$ is not uniformly continuous on the open interval (0,1).","I've written a proof that $f\left(x\right)=\frac{1}{x}$ is not uniformly continuous on the interval $(0,1)$ and would like to know if it is correct. Here's what I've got. In order to show a function $f$ is not uniformly continuous on $A$ , it
  suffices to show there exist two sequences $(x_n)$ and $(y_n)$ in $A$ and an $\epsilon_0>0$ satisfying $\lim(|x_n-y_n|)=0$ but $|f(x_n)-f(y_n)|\ge\epsilon_0$ . Let $x_n=\frac{1}{n}$ and $y_n=\frac{2}{n}$ , with $n\ge3$ , and set $\epsilon_0=\frac{3}{2}$ . Then $\lim(|x_n-y_n|)=0$ , but $\left|\frac{1}{x_n}-\frac{1}{y_n}\right|=\left|n-\frac{n}{2}\right|=\frac{n}{2}\ge\epsilon_0=\frac{3}{2}$ ,
  as desired.","['continuity', 'proof-verification', 'real-analysis']"
3273178,$6$ bishops and a knight on an infinite chessboard,"Player $A$ places $6$ bishops wherever he/she wants on the chessboard with infinite number of rows and columns. Player $B$ places one knight wherever he/she wants. Then $A$ makes a move, then $B$ , and so on... The goal of $A$ is to checkmate $B$ , that is, to attack knight of $B$ with bishop in such a way that the knight of $B$ cannot move anymore because all the squares at which he can move are under attack by the bishops. $B$ wins if he has a winning strategy, that is, if he moves in such a way that $A$ will never checkmate him and, of course, $B$ always plays the best possible strategy. We tried in a chat-room to prove that $6$ bishops are always enough for $A$ to win, but, we still do not have a proof. Is $6$ the minimum number of bishops needed to secure $A$ a winning strategy? You can also join us in chat-room. There are two versions: 1) A knight is allowed to capture bishops. 2) A knight is not allowed to capture bishops. I would like to see the solution of at least one version.","['game-theory', 'infinite-games', 'combinatorics', 'chessboard']"
3273202,Generalization of normal subgroup,"I am wondering whether the following concept appears in the group theory literature under some (perhaps different) name. Let $G$ be a group and let $A,B$ be subgroups of $G$ . Definition. Say that $(A,B)$ is a normal pair if $[A,B]\subseteq A\cap B$ . Here, $[A,B]$ denotes the group generated by the commutators $\{[a,b]\colon a\in A,b\in B\}$ . Thus, the condition is equivalent to requiring that $[a,b]\in A\cap B$ for all $a\in A$ and $b\in B$ . Yet another equivalent condition is that $bA=Ab$ and $aB=Ba$ for all $a,b$ . Note that while $A,B$ are required to be subgroups of a common group, the definition is intrinsic to $A$ and $B$ in the sense that for all groups $G,H$ containing $A\cup B$ we have that $(A,B)$ is a normal pair when regarded as subgroups of $G$ if and only if it is a normal pair when regarded as subgroups of $H$ . The concept of a normal pair generalizes the concept of a normal subgroup. Indeed, $N\trianglelefteq  G$ is equivalent to $N$ being a subgroup of $G$ for which $(G,N)$ is a normal pair. One nice consequence of the definition is that whenever $(A,B)$ is a normal pair, $[A,B]\trianglelefteq A\cap B$ . So even though we started by just assuming a subgroup relationship, it was upgraded to a normal subgroup ""for free"" (see diagram below). To see why this is the case, note (by the previous paragraph) that it suffices to show that $$(A,B)\text{ is a normal pair}\implies([A,B],A\cap B)\text{ is a normal pair}.$$ It is clear that given the hypothesis, $\bigl[[A,B],A\cap B\bigr]\subseteq [A\cap B,A\cap B]$ . The latter group is immediately seen to lie both in $A\cap B$ as well as $[A,B]$ . This proves the claim. In fact, one can go even further and observe that the factor group $$\frac{A\cap B}{[A,B]}$$ (which is well-defined due to the previous paragraph) is always abelian. Indeed, it is a general fact (directly from the definitions) that a quotient group $G/N$ is abelian if and only if $[G,G]\subseteq N$ . Applied to $G=A\cap B$ and $N=[A,B]$ , it yields the claim. Similar reasoning shows that if $(A,B)$ is a normal pair, then not only is $[A,B]$ a normal subgroup of $A\cap B$ , but it is also a normal subgroup of $A$ (and therefore $B$ , by symmetry). Indeed, $[[A,B],A]\subseteq [A\cap B,A]$ and the latter subgroup is seen to be contained in both $A$ and $[A,B]$ . However, contrasting with the situation in the previous paragraph, $A/[A,B]$ is no longer necessarily abelian - for example, consider the normal pair $(G,\{\textrm{id}\})$ for any non-abelian group $G$ . Following the spirit that ""everything in sight is normal"", it also follows from normality of the pair $(A,B)$ that $A\cap B$ is a normal subgroup of $A$ (and therefore $B$ , by symmetry). Indeed, $[A,A\cap B]\subseteq A$ is clear and $[A,A\cap B]\subseteq [A,B]\subseteq A\cap B$ establishes the claim. (Note that this case of normality is implied by what we have already established in previous paragraphs as well.) Relations entailed by a normal pair $(A,B)$ : Legend: lines indicate normal subgroups (lower object contained in upper object) and $\Diamond$ means that the quotient group is abelian. In summary, I think this normal pair concept is quite a nice way to think about normal subgroups. I would be surprised if such a nice concept doesn't exist in the literature. And if it does exist, I would be curious to see some applications of it. One basic application that comes to mind is that various basic properties of the lower central series of a group follow immediately from our observations above.","['normal-subgroups', 'group-theory', 'definition', 'reference-request']"
3273222,Question about irreducible polynomials over finite fields,"I have the polynomial $f(T)=T^2+T+1$ ; then, for which primes $p$ does $f(T)$ have roots in $\Bbb F_p$ ? I tried this way: since the three roots of $f(T)$ are generated from the cubic root of $1$ , we need it to be contained in the field $\Bbb F_p$ ; namely that $m^3\equiv 1$ $($ mod $p)$ for some $m\in \Bbb F_p$ . For example in $\Bbb F_7$ we have that $2^3\equiv 1 $ $($ mod $7)$ and in fact in this field $2$ is a root of the polynomial $f$ ; however I don't know how to describe in general in which fields $f(T)$ is reducible and in which is not. Thank you :)",['abstract-algebra']
3273246,Injectivity and surjectivity of a recursive function,"Let $f:\mathbb{N} \to \mathbb{Q}^+$ defined as follows : $$\begin{cases} f(0) = 0 \\ f(2n) = \dfrac{1}{f(n)+1} \\ f(2n+1) = f(n)+1 \end{cases}\,.$$ It is asked to prove the injectivity then the surjectivity of $f$ . After examining first values taken by $f$ , I proved by induction that $f(2^k)=\dfrac{F_k}{F_{k+1}}$ where $(F_n)$ is the fibonacci sequence.
Also one notes that if $m$ and $n$ have different parity then we can't have $f(m) = f(n)$ since $f(2\mathbb{N}) \subset (0,1)$ and $f(2\mathbb{N}+1) \subset [1,+\infty)$ . Any ideas on how to finish the proof of injectivity and any thoughts about surjectivity are welcome. Thanks","['functional-equations', 'recurrence-relations', 'functions', 'sequences-and-series', 'rational-numbers']"
3273288,"Efficiency of $\hat{\theta}_{MLE}$ from $\operatorname{Beta}(\theta,1)$","I am working on a problem which asks me to discuss the efficiency of the MLE $\hat{\theta}$ given that $X_1,\ldots,X_n \sim_{iid} \operatorname{Beta}(\theta,1) $ . I was able to deduce that $$\hat{\theta} = \frac{n}{-\sum_{i=1}^n \ln X_i}$$ and that the Rao-Cramer Lower Bound is $$RCLB=\frac{\theta^2}{n}$$ . Since $E[\hat{\theta}]=\frac{n}{n-1}\theta$ the MLE is asymptotically  unbiased, and I found that $$Var[\hat{\theta}]= \frac{n^2\theta^2}{(n-1)^2(n-2)}$$ . What bothers me a little is that I was able to proove that the coefficient of $\theta^2$ is a value that is larger than $1 \over n$ when $1.57 < n$ so I see that this variance is indeed larger than the RCLB. However, the fact that when $n=1$ and $n=2$ is undefined makes me a bit uneasy. Is there something that needs to be considered in these cases or is there an assumption that I am missing?","['statistics', 'parameter-estimation', 'maximum-likelihood']"
3273291,Complex tensor product,"Let $x, y, z$ be three vectors in $\mathbb{R}^m$ , $\mathbb{R}^n$ , $\mathbb{R}^p$ , respectively. From them we can form the tensor product $x \otimes y \otimes z$ , which can be interpreted as a trilinear map $\mathbb{R}^m \times \mathbb{R}^n \times \mathbb{R}^p \mapsto \mathbb{R}$ defined as $$x \otimes y \otimes z (u, v, w) = \langle u, x \rangle \cdot \langle v, y \rangle \cdot \langle w, z \rangle.$$ $\langle u, x \rangle = \sum_{i=1}^m u_i x_i$ is the usual Euclidean inner product, with analogous definition for $\langle v, y \rangle$ and $\langle w, z \rangle$ . I start to get confused when the field is not $\mathbb{R}$ but $\mathbb{C}$ instead. Consider the same vectors as before, but with complex numbers. Let $\langle u, x \rangle = \sum_{i=1}^m u_i \overline{x}_i$ be the Hermitian inner product and $\langle u, x \rangle_\mathbb{R} = \sum_{i=1}^m u_i x_i$ . Now, what is the correct interpretation of $x \otimes y \otimes z$ as a trilinear product? 1) $x \otimes y \otimes z (u, v, w) = \langle u, x \rangle \cdot \langle v, y \rangle \cdot \langle w, z \rangle$ 2) $x \otimes y \otimes z (u, v, w) = \langle x, u \rangle \cdot \langle y, v \rangle \cdot \langle z, w \rangle$ 3) $x \otimes y \otimes z (u, v, w) = \langle u, x \rangle_\mathbb{R} \cdot \langle v, y \rangle_\mathbb{R} \cdot \langle w, z \rangle_\mathbb{R}$ Each choice seems to be reasonable but I don't want to guess and go for it. If possible, could you explain the reasoning behind the correct choice? Thank you.","['complex-analysis', 'multilinear-algebra', 'tensor-products']"
3273292,Minimizing a project costs through dynamic programming,"I have a project and I want to minimize the costs. I am responsible for the inspection of 1000 miles of sewer grid in Canada. My goal is to provide time high quality inspection reports. I tried to define the problem using optimization but I haven't used for a year. I want to know what would be the optimised number of people I should hire. The people I have to pay are robots drivers and inspectors. I have a $\$90000$ budget, two months on site and two weeks off site before. robots drivers take 6 pictures of every pole under different point of views and upload them on my cloud. The drivers upload their pics once a week. A well trained driver can inspect 15miles of sewer grid per day. Training lasts for one day, you can train two pilots in parallel. A photo inspector performs a quality check of the pictures on the Sterblue cloud. Sterblue asks the drone pilots to reinspect any poles not passing the quality checks. You can assume 10% of the poles have to be re-inspected. My AI on the cloud detects the defects. The customer expects 95% accuracy. The inspector performs a quality check of the detections found by the AI. They cost $300 a day and can handle 30miles/day for image quality review, 30miles/day to review the work of the AI. I have a free operations team that generates the inspection reports. 0,5 day is needed to prepare a report for 100 miles of grid. $$
\begin{cases}
\begin{aligned}
\min \ &800 \overbrace{x_1.y_1}^{\text{robot pilots x days}} &+ 300  \overbrace{x_2.y_2}^{\text{inspectors x days}}\\
&800 x_1.y_1 &+ 300 x_2.y_2&\le $90000\\
&y_1&+y_2 &\le 2 months\\
&15 x_1.y_1&&\ge 1000 miles+10\%x_1.y_1 \\
&15 y_1 &&= 30 y_2 \\
\forall i, x_i
\end{aligned}
\end{cases}
$$ Where $x_1$ is the number of robots drivers, $x_2$ the number of inspectors, $y_1$ the time spent by robot drivers, $y_2$ the time spent by inspectors. I know that inspection can't start before reports, and that I haven't found a way to write the 95% accuracy constraints. Can you help me improve the problem so I take into account every constraints ? What should $x_1$ and $x_2$ , the number of people I should hire, be ? I know I should do a Gantt diagram as well but I don't know yet where the major steps and dependencies are.","['nonlinear-optimization', 'combinatorics', 'dynamic-programming', 'optimization', 'problem-solving']"
3273313,Is Convergence of Moments true in Central Limit Theorem?,"My question is simple. Suppose that $X_1,X_2,\ldots$ is an infinite sequence of Rademacher random variables (i.e. $\mathbb{P}(X_1 = -1) = \mathbb{P}(X_1 = 1) = 1/2$ ). Let $S_n$ denote the random walk $S_n = \sum_{i=1}^n X_i$ . By the central limit theorem, $n^{-1/2}S_n$ has a limiting $N(0,1)$ distribution. My question is: Is it true that for all $k \geq 1$ , $n^{-k/2}\mathbb{E}(S_n^k) \rightarrow \mathbb{E} N(0,1)^k$ ? Finally, is the above true, if the $X_i$ 's are general i.i.d. mean $0$ , variance $1$ random variables?","['probability-limit-theorems', 'central-limit-theorem', 'probability-theory']"
3273378,Don't the derivatives of $\arctan x$ and $\operatorname{arccot} x$ imply they're negatives of each other?,"I think I'm misunderstanding something, but I'm not sure exactly what. So we know: $$\int - \frac{1}{x^2+1}dx=\operatorname{arccot}(x)+C$$ If we then bring the negative sign out of the integrand, we get: $$-\int \frac{1}{x^2+1}dx=-\arctan(x)+C$$ Since the integrals are the same, doesn't that imply that $\operatorname{arccot}(x) = -\arctan(x)$ ? I've repeated this process using $\sin(x)$ and $\cos(x)$ , but they check out as the negatives cancel to produce the same results.","['integration', 'trigonometric-integrals']"
3273391,"f(0) = 0, f(1) = 1, prove f(x) + 2019 = 2019f'(x) + x have at least one root on (0, 1)?","Suppose that f(x) is continuous on [0, 1], differentiable on (0, 1) and f(0) = 0, f(1) = 1. 
Prove that:
 f(x) + 2019 = 2019f'(x) + x have at least one root on (0, 1). I think this problem should be solved by using Lagrange theorem, but don't know where to start, can anybody give me a hint?","['functions', 'roots']"
3273396,Given $f$ integrable and $\int_E f\geq 0$ for every $E$ measurable set prove $f(x)\geq 0$ almost everywhere.,"Prove that if $f$ is integrable on $\mathbb{R}^d$ and $\int_E f\geq 0$ for every $E$ measurable set prove $f(x)\geq 0$ almost everywhere. Defining $F=\{x:f(x)<0\}$ I have managed to show that $\int_Ff=0$ . However, there is a line a proof I am reading that follows on from $\int_Ff=0$ saying ""Since $f<0 \text{ for all }  x \in F$ , we conclude that $m(F)=0$ "" and that doesn't really make sense to me. Question: I know that $\int_Ff=0$ implies $f=0$ almost everywhere in $F$ . But how does one get from that to $m(F)=0$ ? Proof I am reading:","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'measurable-functions']"
3273402,"Calculate the probability that in a city of some country with 400000 people, eight or more murders take place.","A country's monthly homicide rate is of 1 per 100000 people. Calculate the probability that in a given month, in a city of such country with 400000 people, eight or more murders take place. I'm currently having a hard time with this problem, my answer differs from the book where I found it so I'm unsure if I'm missing something. I suspect that the random variable X=""Number of murders in a month"" is distributed by a Poisson distribution with parameter $\lambda= 4= 400000 \times  \frac{1}{100000}$ . So I've made the calculations for: $P(X \ge 8)=1-P(X<8)=1-(P(X=0)+P(X=1)+P(X=2)+...+P(X=7))$ with $P(X=k)=\frac{e^{-4} 4^{k}}{k!}$ Both by myself and using RStudio but the result is around 0.051 while book says that the answer is 0.1874. Any help would be greatly appreciated!","['probability-distributions', 'probability-theory', 'probability']"
3273502,What happened to the limit of integration when using Tonelli's Theorem?,"I recently had encounter the integral $$\int_0^{\infty}{\Bigg[\int_0^x{1}dy\Bigg]f(x)dx}.$$ My question is why is the integral above equal to $$\int_0^{\infty}1{\Bigg[\int_y^{\infty}{f(x)}dx\Bigg]dy}?$$ In particular, I am interested on how to get the limit of integration with $[y,\infty]$ for $dy$ ? My understanding is that when using Tonelli's Theorem, the integrals are interchangeable. That is, I must have $$\int_0^{\infty}{\Bigg[\int_0^x{1}dy\Bigg]f(x)dx}=\int_0^x{\Bigg[\int_0^{\infty}{f(x)dx}\Bigg]dy}$$ Can you please help me realize where did I go wrong and how to get the correct limit of integration? Thanks in advance.","['multivariable-calculus', 'probability-theory', 'analysis', 'real-analysis']"
3273517,Why is it not possible to integrate over a singularity?,"I came across a question that states that the following integral does not exist $$\displaystyle \int_{-4}^{4} \frac{1}{x+2} \,\mathrm dx$$ I have seen similar questions on here where people have said that they can be integrated and have shown this. I am confused as to whether it can be or not.","['integration', 'calculus']"
3273546,How to differentiate using properties of logarithms,"How would I differentiate the function $\ln\dfrac{x-1}{x^3}$ by applying the properties of logarithms? I've already differentiated using chain rule and got $-\dfrac{2x-3}{(x-1)x}$ . However, I'm not sure how to do so with the properties of logarithms.","['calculus', 'derivatives']"
3273601,A seemingly true claim?,"Let $(a_n)$ be a sequence of positive real numbers. If $(a_n)$ is not bounded then $\lim\sup\Big(\frac{a_n}{1+a_n}\Big)=1$ . I was tempted to make the above claim when I tried proving the result below: Let $(a_n)$ be a sequence of positive real numbers. If $(a_n)$ is not bounded then show that $\Big(\frac{a_n}{1+a_n}\Big)$ does not tend to zero. My attempt : If $(a_n)$ is not bounded then there exists a strictly increasing (?) subsequence $(a_{n_k})$ of $(a_n)$ such that $a_{n_k}\to \infty.$ Claim : $\Big(\frac{a_{n_k}}{1+a_{n_k}}\Big)$ is a positive monotonically increasing sequence. \begin{align}
\frac{a_{n_{k+1}}}{1+a_{n_k+1}}-\frac{a_{n_k}}{1+a_{n_k}}=\frac{a_{n_{k+1}}-a_{n_k}}{(1+a_{n_k+1})(1+a_{n_k+1})}> 0 \hspace{3mm}(\because a_{n_{k+1}}-a_{n_k}>0)
\end{align} Hence $\Big(\frac{a_{n_k}}{1+a_{n_k}}\Big)$ is monotonic. Also it is evident that this is a positive sequence. Since there exists a subsequence which does not tend to zero implies that $\Big(\frac{a_n}{1+a_n}\Big)$ does not tend to zero. $\hspace{15cm} \blacksquare$ Looks to me that this particular subsequence has no reason to converge to any number other than $1.$ Is my claim true?","['limsup-and-liminf', 'limits', 'analysis', 'real-analysis']"
3273608,Picking balls from urns.,"We have 2 urns, 5 red balls and 5 green balls. We will split the 10 balls in the 2 urns in any way we like (provided that each urn has exactly 5 balls) and then will choose one urn at random, of which we will pick one ball.
  If the ball is red, we will be asked to draw a second one from the other urn. If the first ball is green, we will keep it out of the urn and draw a second one from the same urn. We will win 100,000 rupees if we pick 2 balls of the same color. What is the optimum way to split the balls in the urns? (obviously the urns are identical, they are not transparent and we can’t cheat! Also, once we split the balls, the urns are taken away and brought back to us, so that we don't know which is which.) Obviously we can't put 5 red in one urn and 5 green in the other, because if we pick the urn with the red balls, we will never pick 2 of the same color. So both jars must contain both colors but I can't figure out the optimum combination. I was told it is something about a Bayes theorem, but I am not familiar with this (although I looked it up in wiki). Any help? Many thanks!","['discrete-mathematics', 'combinatorics', 'probability']"
3273674,"If $\tan x=3$, then what is the value of ${3\cos{2x}-2\sin{2x}\over4\sin{2x}+5\cos{2x}}$?","If $\tan x=3$ , then what is the value of $${3\cos{2x}-2\sin{2x}\over4\sin{2x}+5\cos{2x}}$$ So what I did is change all the $\sin{2x}$ and $cos{2x}$ with double angle formulas, getting $${3\cos^2{x}-3\sin^2{x}-4\sin{x}\cos{x}\over5\cos^2{x}-5\sin^2{x}+8\sin{x}\cos{x}}$$ Now I thought of changing the top part to $\sin{x}$ and bottom part to $\cos{x}$ hoping to somehow get $\tan{x}$ in this way, but I ultimately got just $${3-6\sin^2{x}-4\sin{x}\cos{x}\over-5+10\cos^2{x}+8\sin{x}\cos{x}}$$ Had really no ideas what to either do after this, seems pretty unusable to me. Was there possibly a mistake I made in the transformation or maybe another way of solving this?","['algebra-precalculus', 'trigonometry']"
3273678,Degree of the kernel of a module map $R^n\rightarrow R^n$ for an Euclidean domain $R$,"Let $R$ be an Euclidean domain with the degree function $d$ . Let $A\in R^{n\times n}$ be an $n\times n$ -matrix with entries in $R$ such that det $(A)=0$ . As a module map $A:R^n\rightarrow R^n$ , there always exists a kernel element $v\in R^n$ since det $(A)=0$ . Assuming $d(A_{ij})\leq m$ for all $i,j$ , is there an explicit bound $k(m,n)$ such that there exists a kernel element $v\in R^n$ satisfying $d(v_i)\leq k(m,n)$ ? Edit : $v$ is assumed to be nonzero.","['matrices', 'euclidean-domain', 'abstract-algebra', 'linear-algebra']"
3273698,Unification of functions,"The operator ' $\circ$ ', denoting function composition, takes two functions, $f$ , and $g$ , satisfying $\text{rng}\ f \subseteq \text{dom}\ g$ , and returns a function $g\circ f$ , satisfying that $\text{dom}\ g\circ f = \text{dom}\ f$ , and that $(g\circ f)(x) = g\big(f(x)\big)$ , for every $x \in \text{dom}\ f$ . Consider the following, related operator, which we shall denote by ' $\langle\rangle$ '. This operator takes $n$ functions, $f_1, \dots, f_n$ , for any $n \in \{1,2,\dots\}$ , and returns a function, $\langle f_1, \dots, f_n\rangle$ , satisfying that $\text{dom}\ \langle f_1, \dots, f_n\rangle = (\text{dom}\ f_1)\times \cdots \times(\text{dom}\ f_n)$ , and that, for every $x_i \in \text{dom}\ f_i$ , $\langle f_1, \dots, f_n\rangle(x_1, \dots, x_n) = \big(f_1(x_1), \dots, f_n(x_n)\big)$ . For instance, if $f_1:\mathbb{N}^2\rightarrow\mathbb{N}$ is the function $f_1(a,b) = a + b$ , and if $f_2:\mathbb{N}\rightarrow\mathbb{N}$ is the function $f_2(c) = c^2$ , then $\langle f_1, f_2\rangle$ is the function with domain $\mathbb{N}^2\times\mathbb{N}$ , which returns $\langle f_1, f_2\rangle\big((a,b),c\big) = (a+b, c^2)$ for every $a, b, c \in \mathbb{N}$ . Does this operator have a standard name and notation, the way the composition operator has a standard name (namely 'composition') and notation (namely ' $\circ$ ')?","['logic', 'category-theory', 'functions', 'type-theory', 'lambda-calculus']"
3273699,Is the graph of a smooth function a manifold?,"Let $f:V\rightarrow M$ be a smooth map between smooth manifolds. Why is $Gr(f):=\{\ \left(v,f(v)\right)\ |\ v\in V\} $ a submanifold of $V \times M$ ? This is used in a proof by Kosinski (""Differentiable Manifolds"", chapter 4, Corollary 2.5) but it is not justified.","['smooth-functions', 'smooth-manifolds', 'differential-geometry']"
3273746,Dimension of a preimage,"Suppose we have a differentiable function $f:\mathbb{R}^{k}\to\mathbb{R}^{\ell}$ where $k>\ell$ . How can we formalize the fact that the ""inverse"" of a point $\mathbf{y}\in\mathbb{R}^{\ell}$ , $f^{-1}(\{\mathbf{y}\})$ will be a $(k-\ell)$ -dimensional set ?","['analysis', 'functions', 'inverse', 'general-topology', 'differential-topology']"
3273818,Probability for specific outcomes in fair die rolls,"We roll a fair die n times. We are looking for the maximum n, for which, the probability that the maximum value that appears in all outcomes is 5, is >24%. At the beginning I thought that the probability would be $(\frac{5}{6})^n$ , that is, the probability for one particular number not to be included in the outcomes (6, in our case). But then I figured out that we could have also cases where some other numbers are missing, but 5 is still the largest of those that appear. Any ideas?","['combinatorics', 'probability']"
3273844,How to find lyapunov function for the system?,I have to determine the stability of the system: $$\begin{cases}x' = xy^4 - 2x^3 - y \\ y' = 2x + 2x^2y^3 -y^7\end{cases}$$ How to fetermina what is Lyapunov function $V$ for this system? I know that later I have to find: $$\frac{dV}{dt} =\frac{\partial{V}}{\partial{x}}\frac{dx}{dt} + \frac{\partial{V}}{\partial{y}}\frac{dy}{dt}$$ but I can not realize how to find $V$ and where should I pay attention at.,"['lyapunov-functions', 'systems-of-equations', 'ordinary-differential-equations']"
