question_id,title,body,tags
4219700,Minimum number of handshakes in the party,"In a party of $n$ people, certain pairs of people shake hands with each other. In any group of $k$ people, there exists at least one person who shakes hands with all other persons in that group. What is the minimum number of handshakes that can take place at the party? The problem is inspired from a contest question which I want to solve in general. Here are my attempts in solving the problem: There are $\binom n k$ possible groups. In each group, the minimum number of handshakes is $k-1$ . So, at first I thought the answer should be $(k-1)\binom n k$ . But I realized that the maximum number of handshakes is $\binom n 2$ . So, I was highly over counting. Then, I tried for small cases. For $n=4$ and $k=3$ , we have $4$ people $A,B,C,D$ . And there are $4$ groups of $3$ . We take the first group $(A,B,C)$ where $A$ shakes hands with $B$ and $C$ . Then in the groups $(A,B,D)$ and $(A,C,D)$ , $B$ and $D$ shake hands with $D$ . So, we have a total of $4$ handshakes as minimum in this case. From here, I think it's not easy to find the minimum for even small cases. So, how to solve the problem?","['contest-math', 'combinatorics', 'discrete-mathematics', 'discrete-optimization', 'optimization']"
4219758,Hammack: Example 13.4 -- proof that there is no limit for sin(1/x) as x goes to 0,"In section ""13.3 Limits That Do Not Exist"", of his ""Book of Proof"" (3rd Edition) Hammack gives: Example 13.4 Prove that $ \displaystyle \lim_{x \to 0} \sin\left({\frac{1}{x}}\right)$ does not exist. As $x$ approaches $0$ , the number $\frac{1}{x}$ grows bigger, approaching infinity, so $\sin(\frac{1}{x})$ just bounces up and down, faster and faster the closer $x$ gets to $0$ . His proof appears to be a direct proof that it is not true that there is a limit -- but it seems to start as if it is a proof by contradiction.  This bothers me because a ""proof of the contrary"" does not seem to be the same as ""proof by contradiction"". Here is the proof as given: Proof. Suppose for the sake of contradiction that $ \displaystyle \lim_{x \to 0} \sin\left({\frac{1}{x}}\right) = L$ for $L \in \mathbb{R}$ .
Definition 13.2 guarantees a number $\delta$ for which $0 < |x - 0| < \delta)$ implies $|\sin\left({\frac{1}{x}}\right) - L| < \frac{1}{4}$ .  Select $k \in \mathbb{N}$ large enough so that $\frac{1}{k\pi} < \delta$ .  As $0 < \left|\frac{1}{k\pi} - 0\right| < \delta$ , we have $\left|\sin\left(\frac{1}{1/k\pi}\right)-L\right| < \frac{1}{4}$ , and this yields $\left|\sin\left(k\pi\right)-L\right| = \left|0-L\right| = \left|L\right|< \frac{1}{4}$ . Next, take $l \in \mathbb{N}$ large enough so that $\frac{1}{\frac{\pi}{2} + 2l\pi} < \delta$ , so we have $0 < \left|\frac{1}{k\pi} - 0\right| < \delta$ , we have $\left|\sin\left(\frac{1}{\frac{1}{\frac{\pi}{2} + 2l\pi}}\right)-L\right| < \frac{1}{4}$ , which simplifies to $\left|\sin\left(\frac{\pi}{2} + 2l\pi\right)-L\right| = \left|1-L\right| < \frac{1}{4}$ . Above we showed $\left|L\right|< \frac{1}{4}$ and $\left|1-L\right| < \frac{1}{4}$ . Now apply the inequality (13.2) to get the contradiction $1 < \frac{1}{2}$ , as $1 = |L+(1-L)| \le |L| + |1-L| < \frac{1}{4} + \frac{1}{4} = \frac{1}{2}$ . Hammack also gives: ... in symbolic form Definition 13.2 says $\displaystyle \lim_{x \to c} f(x) = L$ if and only if $\forall \epsilon > 0, \exists \delta > 0, (0 < |x - c| < \delta) \implies (|f(x) - L| < \epsilon)$ (13.4) I believe the contrary of that is: $\exists \epsilon > 0, \forall \delta > 0, (0 < |x - c| < \delta) \land \lnot(|f(x) - L| < \epsilon)$ So the above proof appears to prove the contrary.  It chooses an $\epsilon$ and shows that for all $\delta$ it is not true that $|f(x) - L| < \epsilon$ , no matter what value of $L \in \mathbb{R}$ might be.  Proving the last part is by contradiction: it is proved that assuming $|f(x) - L| < \epsilon$ is true (for all $\delta$ and all $L$ ) leads to a contradiction. So my actual questions are: perhaps I have misread Hammack, and all his proofs of the non-existence of limits are indeed (implicitly) direct proofs of not-existence (proof of the contrary), but the last step of that is generally a proof by contradiction ? Or: perhaps I am mistaken in thinking that ""proof of the contrary"" and ""proof by contradiction"" are different ?","['limits', 'calculus', 'proof-explanation']"
4219762,Principle of measurable choice,"Consider the following principle of measurable choice: Let $X,Y$ be complete separable metric spaces and $E$ a closed $\sigma$ -compact subset of $X\times Y$ . Then $\pi_1(E)$ is a Borel set in $X$ and there exists a Borel function $\varphi:\pi_1(E)\to Y$ whose graph is contained in $E$ . (Here $\pi_1$ denotes the projection of $X\times Y$ on $X$ ). Proof. Since $E$ is $\sigma$ -compact we can write $E=\cup_{i=1}^\infty C_i$ with each $C_i$ compact in $X\times Y$ . Then $\pi_1(E)=\cup_{i=1}^\infty \pi_1(C_i)$ with each $\pi_1(C_i)$ compact in $X$ since $\pi_1$ is continuous. Compact subsets of metric spaces are closed, hence Borel. Therefore $\pi_1(E)$ is a countable union of Borel sets in $X$ , hence Borel. Fix a countable dense subset $\{y_n:n\in\mathbb{N}\}$ in $Y$ . Define $\varphi_1:\pi_1(E)\to Y$ by the rule $\varphi_1(x)=y_{n_1(x)}$ , where $n_1(x)$ is the smallest $n$ such that $$E\cap \big[\{x\}\times \bar{B}_{1/2}(y_n)\big]\neq \emptyset \quad\quad\quad (1)$$ where $\bar{B}_{1/2}(y_n):=\{y\in Y: d(y,y_n)\}\leq 1/2\}$ . This is well-defined, since $x\in \pi_1(E)$ implies $(x,y)\in E$ for some $y\in Y$ , and by density there exists $n$ such that $d(y_n,y)<1/2$ . Hence the set of $n$ satisfying $(1)$ is not empty. Suppose inductively that $\varphi_k:\pi_1(E)\to Y$ has been defined for some $k\geq 1$ . Define $\varphi_{k+1}:\pi_1(E)\to Y$ by the rule $\varphi_{k+1}(x)=y_{n_{k+1}(x)}$ , where $n_{k+1}(x)$ is the smallest $n$ such that $$E\cap \big[\{x\}\times \bar{B}_{1/2^{k+1}}(y_n)\big]\neq \emptyset \quad \text{and} \quad d(y_n,\varphi_k(x))\leq 1/2^{k-1}\quad\quad\quad (2)$$ This is well-defined, since by definition of $\varphi_k(x)$ there exists $y\in Y$ such that $(x,y)\in E\cap \big[\{x\}\times \bar{B}_{1/2^k}(\varphi_k(x))\big]$ , and by density there exists $n$ such that $d(y_n,y)<1/2^{k+1}$ . Then $(x,y)\in E\cap \big[\{x\}\times \bar{B}_{1/2^{k+1}}(y_n)\big]$ and by the the triangle inequality $$d(y_n,\varphi_k(x))\leq d(y_n,y)+d(y,\varphi_k(x))\leq 1/2^{k+1}+1/2^k<1/2^{k-1}$$ so the set of $n$ satisfying $(2)$ is not empty. Question. At this point in the proof the author says that a simple induction argument shows that each $\varphi_k$ is Borel. This is where am having issues. Since the range of each $\varphi_k$ is contained in $\{y_n:n\in\mathbb{N}\}$ , it suffices to show that each preimage $\varphi^{-1}_k(y_n)$ is Borel in $\pi_1(E)$ . Any ideas on how to show it? Thanks for your help. EDIT. I made some progress below. Any feedback is very appreciated! Define the following correspondence : $$\phi:X\to \mathcal P(Y), \quad \phi(x)=\big\{y\in Y: (x,y)\in E\big\}$$ Note that $\phi(x)\neq\emptyset$ if and only if $x\in\pi_1(E)$ . Let $B$ a closed set in $Y$ , and define $E(B)$ by $$E (B):=\big\{x\in X : \phi(x)\cap B\neq \emptyset\big \}=\pi_1\big[(X\times B) \cap E \big]$$ I claim that $E(B)$ is Borel in $\pi_1(E)$ . Indeed $(X\times B) \cap E=\cup_{i=1}^\infty (X\times B) \cap C_i$ . For each $i$ , $(X\times B) \cap C_i$ is a closed subset of the compact set $C_i$ in $X\times Y$ , and is thus compact in $X\times Y$ . It follows (as above) that $\pi_1\big[(X\times B) \cap E \big]=\cup_{i=1}^\infty \pi_1 \big[(X\times B) \cap C_i\big]$ is a countable union of compact sets in the metric space $X$ , hence Borel in $X$ . Clearly, $\pi_1\big[(X\times B) \cap E \big]\subset \pi_1( E)$ , and so we conclude that $E(B)$ is Borel in $\pi_1(E)$ . Now let $A_n=E(B_n)$ with $B_n=\bar{B}_{1/2}(y_n)$ for each $n$ . Since each $B_n$ is closed in $Y$ , each $A_n$ is Borel in $\pi_1(E)$ by the previous claim. Moreover, we see that $$\varphi_1^{-1}(y_n)=A_n\setminus \cup_{i=1}^{n-1}A_i \quad\quad\quad (3)$$ for each $n$ , and so each preimage is Borel in $\pi_1(E)$ . It follows that $\varphi_1$ is Borel measurable. Now assume inductively that $\varphi_k$ is Borel measurable for some $k\geq 1$ . Let $A_n=E(B_n)$ with $B_n=\bar{B}_{1/2^{k+1}}(y_n)$ for each $n$ . As before each $A_n$ is Borel in $\pi_1(E)$ . Let $$C_n=A_n\cap \varphi_{k}^{-1}\big[\bar{B}_{1/2^{k-1}}(y_n)\big]$$ for each $n$ . Since $\bar{B}_{1/2^{k-1}}(y_n)$ is closed in $Y$ and $\varphi_k$ is Borel measurable by assumption, we have that each $C_n$ is Borel in $\pi_1(E)$ . Moreover we have $$\varphi_{k+1}^{-1}(y_n)=C_n\setminus \cup_{i=1}^{n-1}C_i \quad\quad\quad (4)$$ for each $n$ , and so each preimage is Borel in $\pi_1(E)$ . It follows that $\varphi_{k+1}$ is Borel measurable. By induction it follows that each $\varphi_k$ is Borel measurable. Note that in $(3)$ and $(4)$ I assumed each $y_n$ to be distinct. The case of a finite dense subset can be handled in the same way.","['measure-theory', 'solution-verification', 'measurable-functions', 'borel-sets', 'general-topology']"
4219787,Estimate $N_p$ norm of $\psi : x \longmapsto \int_{-\infty}^x \phi(t)\ \mathrm dt$,"Context and Assumptions : we consider the case of a very standard exercice in Schwartz functions theory: Let's suppose that $\phi$ is a $S(\mathbb{R})$ function, and let's suppose additionally that $\displaystyle\int_{-\infty}^\infty \phi(t)\ \mathrm dt=0$ . In a first time, I demonstrate that the function $\displaystyle \psi\colon\mathbb{R}\ni x\longmapsto \int_{-\infty}^x \phi(t)\ \mathrm dt\in \mathbb{R},$ defines a $S(\mathbb{R})$ function. Then, I am asked to estime $N_p$ norm of $\psi$ (also called $N_p$ semi-norm) in function of $N_p(\phi)$ . For the reminder, it is defined by : $$ N_p(f):=\sum_{\alpha\leq p,\beta \leq p}\sup \vert x^\alpha \partial^\beta f(x) \vert\text{ for all }f \in S(\mathbb{R}).$$ What I have done: $$N_p(\psi)=\sum_{\alpha\leq p,\beta \leq p}\sup \vert x^\alpha \partial^\beta\psi(x) \vert$$ $$= \sum_{\alpha\leq p,1\leq\beta \leq p}\sup \vert x^\alpha \partial^\beta\psi(x) \vert+\sum_{\alpha\leq p}\sup \vert x^\alpha \psi(x) \vert$$ $$=N_p(\phi)-\sum_{\alpha\leq p}\sup \vert x^\alpha \partial^p \phi(x) \vert+\sum_{\alpha\leq p}\sup \vert x^\alpha \psi(x) \vert$$ (I tried to copy it without failing the indexes, but if I did, I tried to isolate $N_p(\phi)$ in the terms using the fact $\psi$ is a primitive of $\phi$ ) I think there is something to find here, what I have written may not be what is waited I believe, I mean a common form should be found, I think, what would be the ""good way"" to Estimate $N_p$ norm of $\psi$ in function of $N_p(\phi)$ .","['schwartz-space', 'functions', 'functional-analysis']"
4219808,Is there a function which approaches the same value from both sides but is defined differently at that point? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question e.g. a function, f(x) where f(0) approaches 0 from positive x and 0 from negative x, but when you actually compute f(0) it is defined as a different value like 1? And I don't mean some function where you define it differently for x > 0, x < 0 and x = 0. Additionally a function where the limit at an x approaches a different number from positive x than from negative x, but is actually defined at that point. When the limit approaches a different value from two different directions usually we say it is therefore undefined at that point, but is this always the case?","['limits', 'functions']"
4219839,$\lim\limits_{x\to\infty}xf'\left(x\right)=1\Rightarrow\lim\limits_{x\to\infty}f\left(x\right)=\infty$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Let $f:\left(0,\infty\right)\longrightarrow\mathbb{R}$ differentiable on $\left(0,\infty\right)$ and $\lim\limits_{x\to\infty}xf'\left(x\right)=1$ . Show that: $\lim\limits_{x\to\infty}f\left(x\right)=\infty$ .
I get that for a sufficently large x: $\frac{1}{2x}<f'\left(x\right)<\frac{3}{2x}$ . But I'm not sure how to proceed.","['calculus', 'analysis', 'real-analysis']"
4219863,Probability distribution function and distribution function,Is there a difference between the two? For discrete variables: PMF and CDF exists. The CDF is what we call the distribution function For continuous variables: PDF and CDF exist. The CDF is what we call the distribution function. What is the probability distribution function then?,"['statistics', 'probability']"
4219878,Repeatedly selecting a random number from $\mathbb{N}_{≤n}$ always reaches $0$?,"Let $S$ be the set of natural numbers from zero to $n$ , namely $S = \{ s : s∈\mathbb{N} ∧ s ≤ n \}$ . With each turn we pick a random number from the set. If we get one specific number (let's say $0$ ), the experiment is complete. If we get any other number, we go on with the next turn (hoping to get $0$ and going on with yet another turn otherwise). Is it possible to prove that such an experiment always ends with a finite number of turns?",['probability']
4219907,Why is the expected length of an interval containing a point $\mathbb{E}\left[X^2\right]/\mathbb{E}[X]$ if interval length is IID?,"In general, for processes, in which the interarrival intervals with distribution $F_X(x)$ are IID, the expected length of an arbitrary chosed interval is $\mathbb{E}\left[X^2\right]/\mathbb{E}[X]$ . We see that for the above parts, the formula is certainly valid. Why is this statement true? For context: Suppose there existed an infinitely long line that is divided into IID intervals with lengths following some distribution. Let the random variable $X$ denote the length of an interval. If I arbitrarily picked a point on this line, the expected length of the interval containing this point is $\mathbb{E}\left[X^2\right]/\mathbb{E}[X]$ . Let $\mathbb{E}[X_s]$ be the expected length from start of interval to the point. Let $\mathbb{E}[X_e]$ be the expected length from the point to end of interval. I understand that if such distribution is exponential, then the expected length is $\mathbb{E}[X_s] + \mathbb{E}[X_e]$ , which happens to be $\mathbb{E}\left[X^2\right]/\mathbb{E}[X]$ . However, I'm not sure why this holds for the general case. Edit: For full context, this is taken from problem 4 on this pset . The quote is from the 4.b) answer Edit 2: The interval choice strategy is to first pick a point, then choose the interval containing this point. As @user6247850 mentions, larger intervals are favored.","['stochastic-processes', 'probability-theory', 'probability']"
4219940,Sum function of a power series derivative,"If $$f(x)=\sum_{n=1}^\infty \frac{2^n}{n} x^n\space\space\space x\in\left]-\rho,\rho\right[$$ how is $$f'(x)=\frac{2}{1-2x}$$ I've found that $$\vert\rho\vert=\frac{1}{2}$$ and I know that $$\sum_{n=0}^\infty{x^n}=\frac{1}{1-x}\space\space\space x\in\left]-1,1\right[$$ (think I need to use that).","['power-series', 'derivatives']"
4219975,Determining convergence of sequence $a_n=a_{n-1}^{-1}+a_{n-2}^{-1}$ [duplicate],"This question already has answers here : Proof of existence of a limit for the sequence recursively-defined with $a_1=1$, $a_2=1$ and $a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}$ for $n\ge2$ (5 answers) Closed 2 years ago . I'm trying to prove convergence for the sequence $$a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}$$ with $a_0=a_1=1$ . If it does converge then it converges to $\sqrt{2}$ , which agrees with numerical tests. $$$$ I've managed to prove two facts about the sequence, although I'm not sure they're relevant to the question or not. Firstly, for every set of three consecutive terms in the sequence, at least one is bigger than $\sqrt{2}$ and at least one is smaller than $\sqrt{2}$ . Secondly, if two consecutive terms are in the interval $(\alpha,\,2\alpha^{-1})$ for some $\alpha\in[1,\,\sqrt{2})$ , then all terms that follow are in this interval as well. $$$$ Does anyone have an idea for how to prove convergence, with or without these facts?","['recursion', 'sequences-and-series']"
4219990,"Is there a notion of Lucas/Fibonacci sequences beyond adding two numbers at a time, if so where could I read more about that?","So I recently learned about lucas/fibbonaci sequences EG; 1,1,2,3,5,7 or 3,4,7,11,18... A fact I learned about these sequence is that the limit of the quotient of the terms approaches the golden ratio (1.61803398874989484820). What I found independently (somewhat) was that this ratio could also be understood as the root of the polynomial $x^2-x-1$ (this can be derived from the geometric definition of the golden ratio). In trying to understand the golden ratio further, I extended the notion first by finding a new version of the fibbonaci sequence starting with three terms. 1,1,1:3,5,9,17,31,57,105... The ratios of this sequence converge to roughly 1.83, which is also one of the real roots of the polynomial $x^3-x^2-x-1$ . At this point, I'm pretty sure that's an obvious pattern. After I found the ratio for the 3-fibbonaci/lucas sequence I began to wonder what the ratio of an inifnite version of this would converge to (if at all). So I wrote out a general notation for a sequence where you add up n terms starting with (x0,x1,x2,,,,,,xn). The first term of the sequence is the summation from k=0 to n or ""X sub K."" The second term is the earlier term plus the summation from k=1 to n. As you write out the terms, you can show that the ratio of the terms converges to 2. Lastly, does this imply that 2 is the root of the polynomial $x^n-x^{n-1}....-x-1?$","['golden-ratio', 'number-theory', 'recurrence-relations', 'polynomials', 'sequences-and-series']"
4220006,Computing the Fourier transform of exponential decay in $\mathbb{R}^2$,"I am trying to compute this $\textbf{Fourier transform in}$ $\mathbb{R}^2$ $$ I(\mathbf{k})\equiv\mathcal{F}\big(e^{-a|\mathbf{x}|}\big)(\mathbf{k}) = \int_{\mathbb{R}^2} e^{-a|\mathbf{x}|}e^{i\ \mathbf{k}\cdot \mathbf{x}}\ \mathrm{d}x^2\quad,$$ where $\mathbb{R} \ni a > 0$ . Due to the rotational symmetry, I rewrite the above integral in polar coordinates and I find $$ I(\mathbf{k})= \int_{0}^{2\pi}\int_{0}^{\infty} e^{-ar\ +\ i|\mathbf{k}|r\cos{\theta}}\ r\ \mathrm{d}r\ \mathrm{d}\theta\quad,$$ where $r = |\mathbf{x}|$ . I'd like to get rid of the $\cos{\theta}$ term in the exponential with a change of variables, but setting $u=\cos{\theta}$ is not possible because I am missing a $\sin{\theta}$ . This is because $\mathrm{d}u = -\sin{\theta}\ \mathrm{d} \theta$ . I can make this $\sin{\theta}$ appear if I integrate by parts, but then a $\theta$ appears as well and the change of variables $u=\cos{\theta}$ still won't work. However, this change of variables works in $\mathbb{R}^3$ because the differential in spherical coordinates contains a $\sin{\theta}$ term. This has allowed me to compute the above integral in $\mathbb{R}^3$ . Then I found that $$ \int_{0}^{2\pi} e^{-i\beta\cos{\theta}}\ \mathrm{d}\theta = 2\pi\mathcal{J}_0(\beta)\quad,$$ where $\mathcal{J}_0$ is the Bessel function of the first kind, and $\beta \in \mathbb{R}$ . Thus I could possibly write $$ I(\mathbf{k}) = 2\pi \int_{0}^{\infty}e^{-ar}\mathcal{J}_0\big(i|\mathbf{k}|r\big)\ r\ \mathrm{d}r \quad,$$ but unfortunately I can't proceed further. What I'd like is to compute the above integral. Is there any other way I could obtain a closed form solution? It seems like a closed form solution in $\mathbb{R}^1$ and $\mathbb{R}^3$ exists, what about $\mathbb{R}^2$ though? Thanks in advance!","['integration', 'definite-integrals', 'fourier-transform', 'exponential-function', 'bessel-functions']"
4220026,One Dimensional Gaussian Integral involving a rational function,"In the process of solving this question Integral involving product of arctangent and Gaussian , I've come across the integral: $$ \int_0^b \frac{e^{-s^2}}{a^2 + s^2} d s . $$ This integral appears simple enough that I would expect something to be known about it. Does a closed-form solution exist in terms of $a$ and $b$ ? I haven't managed to find anything or work out the integral myself.","['integration', 'indefinite-integrals', 'definite-integrals', 'gaussian-integral']"
4220034,Prove that function is in $L^1$,"Let $E \subset \mathbb{R}$ be a measurable subset. Assume that $\int_{E} |x|^{1/4} |f(x)|^2 dx < \infty$ and $\int_{E} x^4 |f(x)|^3 dx < \infty$ , then I want to prove $f \in L^1 (E)$ . Morally the first inequality says that $f(x)$ behaves nicely at $0$ and the second inequality says that $f(x)$ behaves nicely at $\pm \infty$ but I'm struggling to prove the statement rigorously. A possible idea is to use Holder's inequality: we know that $f(x) x^{1/8} \in L^2 (E)$ and $f(x) x^{4/3} \in L^3 (E)$ and probably it can be used somehow but I don't know how. Anyways, any ideas are greatly appreciated!","['measure-theory', 'lebesgue-integral', 'analysis', 'real-analysis', 'lp-spaces']"
4220041,Non-algebraic flops,"I am looking at Exercise 84 on Kollár's Exercises in the birational geometry of algebraic varieties about non-algebraic flops: Let $X \subset \mathbb{P}^4$ be a general smooth quintic hypersurface. It is know that for every $d \geq 1$ , $X$ contains a smooth rational curve $\mathbb{P}^1 \cong C_{d} \subset X$ of degree $d$ with normal bundle $\mathcal{O}(-1)^{\oplus 2}$ . Prove that the flop of $C_{d}$ exists if we work with compact complex manifolds. Denote the flop by $\phi_{d}: X \dashrightarrow X_{d}$ and let $H_d$ be the image of the hyperplane class. Compute the self intersection $(H_{d})^{3}$ and conclude that the $X_{d}$ are not homeomorphic to each other and not projective. If I'm correct the intersection number $(H_{d})^{3} = 5 - 5d^3$ and the picard number $\rho(X_{d}) = 1$ so $X_{d}$ is not projective. However, I think the variety $X_{d}$ is constructed by first blowing up the curve $C_d$ with exceptional divisor $E \cong \mathbb{P}^1 \times \mathbb{P}^1$ , and then contract the other negative extremal ray by the minimal model program. Doesn't this construction always give projective varieties? I feel like I messed up with something in this contradiction. Any help is appreciated!","['algebraic-geometry', 'birational-geometry']"
4220059,Fredholm Alternative for Compact Operators - Why isn't it so simple?,"Let $\mathfrak{X}$ be a Banach space, and $K\in \mathcal{K}(\mathfrak{X})$ be a compact operator. Then given $\lambda\in\mathbb{C}\backslash\{0\}$ , we can show that $\operatorname{ker}(\lambda I - K)$ is finite dimensional $\operatorname{ran}(\lambda I - K)$ is closed Now, if $\mathfrak{M}\subseteq\mathfrak{X}$ is a finite-dimensional subspace, then $\mathfrak{M}$ is complemented in $\mathfrak{X}$ , so there exists a closed subspace $\mathfrak{N}\subseteq\mathfrak{X}$ such that $\mathfrak{X} = \mathfrak{M}\oplus\mathfrak{N}$ . Let $\mathfrak{R}$ be $\operatorname{ker}(\lambda I - K)$ 's complement in $\mathfrak{X}$ , and define $$
T : \mathfrak{R}\to \mathfrak{X},\qquad y\mapsto(\lambda I - K)y
$$ or in other words $T = (\lambda I - K)|_{\mathfrak{R}}$ . It's easy to see that $T$ is injective, and surjective onto it's range, which is closed. Thus $T$ induces an isomorphism $\mathfrak{R}\cong\operatorname{ran}(\lambda I - K)$ , and so $$
\mathfrak{X}\cong\operatorname{ker}(\lambda I - K)\oplus\operatorname{ran}(\lambda I - K)
$$ From this, hypothetically we should be able to obtain the Fredholm alternative : that $\lambda I - K$ is injective if and only if it is surjective. Actually, I suppose all this proves is that if $\lambda I - K$ is injective, then it must be surjective. However, it's totally possible that $\mathfrak{X}$ is isomorphic to the direct sum of the finite subspace $\operatorname{ker}(\lambda I - K)$ and the isomorphic copy of $\mathfrak{X}$ that is $\operatorname{ran}(\lambda I - K)$ , so we can't be sure that $\lambda I - K$ is injective. However, we can derive an additional factoid: $$
\dim(\mathfrak{X}/\operatorname{ran}(\lambda I - K)) = \dim\operatorname{ker}(\lambda I - K^*)
$$ where $K^*\in\mathcal{K}(\mathfrak{X}^*)$ denotes the Banach space adjoint (which is also compact). I forget if this is true or not, but I seem to recall that if an operator is surjective, then it's adjoint is injective, so this would be enough to prove the other direction of the Fredholm alternative (assuming such a result exists, which I'll have to verify). Most Banach space theory texts go through the motion of showing that $\lambda I - K$ has both finite ascent and finite descent (the towers $\{\operatorname{ran}(\lambda I - K)^n\}_{n\in\mathbb{N}}$ and $\{\operatorname{ker}(\lambda I - K)^n\}_{n\in\mathbb{N}}$ both stabilize), and from this derive the Fredholm alternative. Question: is this extra rigmarole about ascent/descent necessary for deriving the Fredholm alternative? Is there anything wrong with my deduction above, other than the missing ""fact"" that a surjective operator has injective adjoint? Edit: Unless I'm just having an off day (I'm prone to those), it seems trivially true that if $T\in\mathcal{B}(\mathfrak{X}, \mathfrak{Y})$ is surjective then $T^*\in\mathcal{B}(\mathfrak{Y}^*, \mathfrak{X}^*)$ is injective. Indeed, supposing $T^*f = T^*g$ , then $\forall x\in\mathfrak{X}$ , $f(Tx) = g(Tx)$ , but since $Tx$ ranges over $\mathfrak{Y}$ , this implies $f(y) = g(y)$ for all $y\in\mathfrak{Y}$ , so $f = g$ . Thus, don't we have the Fredholm alternative?","['banach-spaces', 'functional-analysis']"
4220078,If $\lim_k \mathcal{F}_k=\mathcal{W}$ then $\lim_{k \to \infty} E[X\mid\mathcal{F}_k]=E[X\mid\mathcal{W}]$ a.s?,"Let $X \in L^1,(\mathcal{F_k})_k$ a sequence of sub- $\sigma$ -algebra and converging to $\mathcal{W},$ i.e. $$\mathcal{W}=\bigcap_{k \in \mathbb{N}}\sigma\left(\bigcup_{q \geq k} \mathcal{F}_q\right)=\sigma\left(\bigcup_{k \in \mathbb{N}}\bigcap_{q \geq k}\mathcal{F}_q\right).$$ Do we have the almost sure convergence of $E[X\mid\mathcal{F}_k]$ to $E[X\mid\mathcal{W}]$ ? Justify. The following was asked before: If $\lim_k \mathcal{F}_k=\mathcal{W}$ then $E[X\mid\mathcal{F}_k]$ converges to $E[X\mid\mathcal{W}]$ , where convergence in $L^1$ was proved, letting $\mathcal{Q}^1_k=\sigma(\bigcup_{q \geq k}\mathcal{F}_q),\mathcal{Q}_k^2=\bigcap_{q \geq k}\mathcal{F}_q,$ then $E[X\mid\mathcal{Q}_k^1]$ and $E[X\mid\mathcal{Q}_k^2]$ converges a.s and in $L^1$ to $E[X\mid\mathcal{W}].$ The question is solved using the inequality: $$E[|E[X|\mathcal{F}_k]-E[X|\mathcal{W}]|] \leq E[|E[X|\mathcal{F}_k]-E[X|\mathcal{Q}_k^2]|]+E[|E[X|\mathcal{Q}_k^2]-E[X|\mathcal{W}]|] \leq E[|E[X|\mathcal{Q}_k^1]-E[X|\mathcal{Q}_k^2]|]+E[|E[X|\mathcal{Q}_k^2]-E[X|\mathcal{W}]|].$$ What about the almost sure convergence ? It seems it doesn't hold in general, in this case what counter-example do you suggest?","['conditional-expectation', 'martingales', 'measure-theory', 'probability-theory']"
4220081,Matrix exponential weirdness in WolframAlpha - it fails on diagonal matrices?,"So Wikipedia says this, which makes sense: But Wolfram computed this: Is this a bug or am I just extremely tired?","['wolfram-alpha', 'linear-algebra', 'matrix-exponential']"
4220102,Convergence of Minima of Converging Random Variables,"Suppose that $X_{ij}$ is a set of iid Rademacher random variables with $i,j\in \mathbb{N}$ .  We know that by the law of large numbers, for each row of this array, $\frac{1}{n}\sum_{j=1}^{n}X_{ij}\rightarrow 0$ almost surely.  Similarly, if we took an infinimum over a finite set of rows, that would also converge to $0$ almost surely.  I'm wondering what happens when we take an infimum of $f(n)$ rows as $n\rightarrow\infty$ .  Formally, if $$Y_{n} = \inf_{i=1,\ldots,f(n)}\frac{1}{n}\sum_{j=1}^{n}X_{ij}\,,$$ then what can we say about convergence of $Y_{n}$ to a limit? If $f(n)$ grows very slowly, $Y_{n}$ may still tend to $0$ .  I'm most interested in whether it's possible to get $Y_{n}$ to converge almost surely to a constant less than $0$ .","['probability-limit-theorems', 'probability-theory', 'probability']"
4220111,How many ways can an integer be written as a sum of three integer squares,"I'm working on a fairly simple Physics problem (particle in an infinite potential cube), and I'm asked: ""Are any of the energy eigenvalues degenerate? If so, what is the degeneracy?"". The expression for the energy (ignoring a constant multiplier) comes to the form $E = a^2 + b^2 + c^2$ Where a,b,c are all integers. Degeneracy occurs when some arrangement of these values gives the same energy value as some different arrangement. (So any state without a = b = c will have at least triple degeneracy via permutations). Is there some closed-form solution or sequence for how many ways an integer can be written as a sum of three integer squares?","['number-theory', 'sums-of-squares', 'combinatorics', 'physics']"
4220160,"PRMO Model Question : ""The least LCM of 20 natural numbers, not necessarily different, whose sum is 413, is _________""","This is a question I saw on a PRMO model paper conducted by an institution where I study (I mean, not my school, but an entrance coaching center) on August 1, 2021 as per the calendar here. I was initially dumbstruck on seeing the question. I have never tried playing with LCM's, but I somehow managed to reach a sort-of solution, which I am adding below: Let $a_1, a_2, a_3, \dots , a_{20}$ be the numbers. Given that their sum is odd, there are more odd numbers than even ones, or there are an odd number of odd numbers among the majority of even numbers among $a_1, a_2, a_3$ , etc. Also, $413 = 21\times 19 + 14$ , and since it is said that all of $a_1,a_2,a_3$ , etc. aren't necessarily distinct and since one of $a_1,a_2,a_3, \dots$ is even as per the first possibility, we can say that $19\space a_i$ 's are $21$ and the only even number among the $20$ integers is $14$ . Also $lcm(21,21,21,... \text{(19 nos.)},14) = 42$ , which is thus a possible candidate worth considering. I stopped there. The answer key also told me that $42$ is the answer,(only in a few papers did they add the full solution, which I am in a sort of disagreement with (personally) except for those questions which I or anybody else finds helplessly hard. This time, they just gave away the key  without steps and as I had found this problem a tough rock during the model exam, I longed to have a solution. I checked my copy of Justin Stevens' 'Olympiad Number Theory Through Challenging Problems' and 'Intermediate Number Theory' but in vain) but that still makes me think of the second possibility of the sum, which is quite more challenging than I thought. Also, I am not able to prove the minimality of $42$ in the solution set, which again disheartens me and makes me think that I arrived at the solution trivially. I would like to know if there's a better way to the solution and also how I can prove or disprove that $42$ is the minimum possible value. Also, providing links to similar questions with different sums and numbers will also do me a great help in learning.","['contest-math', 'number-theory', 'gcd-and-lcm']"
4220167,"Is every abelian group $(M,+)$ an $R$-module?","The idea is to show or give a counterexample to the affirmation that any abelian group can be turned to an $R$ -module, for any ring $R$ . Let $R$ be any ring with $1$ , and $(M,+)$ be an arbitrary abelian group. Does there exist a ring morphism $\psi:R\to{\rm End}(M,+)$ ? This question is just out of curiosity, if ${\rm End}(M,+)$ is isomorphic to a ring $S$ such that there are no ring homomorphisms from $R$ to $S$ , then we would have a counterexample to the proposition, but it does not seem as if that were the case, since $R$ and $M$ are completely arbitrary...","['modules', 'ring-theory', 'abstract-algebra', 'group-theory', 'abelian-groups']"
4220185,Grothendieck's Generic Freeness Lemma: Step in proof from Vakil's FOAG,"I'm trying to solve the following exercise (7.4.K) from Vakil's FOAG, which is a step in the proof of Grothendieck's Generic Freeness Lemma: Here's my attempt: We proceed by induction on $n$ to construct the compatible isomorphisms $\phi_n$ as in the exercise. We have an exact sequence $$0\to M_{n-1}\to M_n\to M_n/M_{n-1}\to 0$$ Since $M_n/M_{n-1}$ is free by assumption, it is projective and thus the exact sequence above splits. As a result we have $M_n\cong M_{n-1}\oplus M_{n}/M_{n-1}$ and a right inverse to the projection $M_n\to M_n/M_{n-1}$ . Call this map $\psi_n$ . Next, define $\phi_n$ to be $\phi_{n-1}$ on $M_{n-1}\cong\bigoplus_{i=1}^{i= n-1} M_i/M_{i-1}$ and $\psi_n$ on $M_{n}/M_{n-1}$ , and extend linearly. As a result we see that the maps $\phi_n$ are compatible in the sense that the diagram commutes. We take colimits to obtain a unique map $\bigoplus_{i\in \mathbb{N}} M_i/M_{i-1}\to M$ . Similarly, we get a unique map in the opposite direction, working with the inverses of the $\phi_n$ 's. Combining these, we see that $\bigoplus M_i/M_{i-1}\cong M$ , whence it follows that $M$ itself is free. I would be very grateful is someone could verify if what I've said makes sense, or point out where I've messed up. Thank you.","['algebraic-geometry', 'solution-verification', 'commutative-algebra', 'modules']"
4220192,Why doesn't P(Calvin wins the match by winning 2 more games than his opponent) = $P(C|W_1)P(W_1)+P(C|L_1)P(L_1) = (p)(p) + (1-q)(q)$?,"Calvin and Hobbes play a match consisting of a series of games, where Calvin has probability $p$ of winning each game (independently). They play with a “win by two” rule: the first player to win two games more than his opponent wins the match. Find the probability that Calvin wins the match (in terms of $p$ ), in two different ways. Blitzstein, Introduction to Probability (2019 2 edn), Chapter 2, Exercise 50, p 94. My attempt Let event $C$ be ""Calvin wins."" $$P(C) = P(C|W_1)P(W_1)+P(C|L_1)P(L_1) = (p)(p) + (1-q)(q)$$ This doesn't match the answer key, $\frac{p^2}{p^2+q^2}$ . I think the conceptual misunderstanding is $P(C|W_1)$ , $P(C|L_1)$ . For $P(C|W_1)$ , my thinking is: if we interpret this problem as the gambler ruin's problem, $i$ is originally at 2, but given that $W_1$ , we have that $i=3$ . Thus, because C occurring corresponds to $i=4$ , $$P(C|W_1) = \text{ (the probability that we move from } i=3 \text{ to } i = 4) = p$$ The same goes for $P(C|L_1)$ : $i$ is originally at 2, but given that $L_1$ , we have that $i=1$ . Thus, because C not occurring corresponds to $i=0$ , $$P(C|L_1) = 1 - P(C^c|L_1) = 1 -\text{ (the probability that we move from } i=1 \text{ to } i = 0) = 1-q$$ I know this is wrong because the gambler ruin's problem would interpret, for example, $P(C|W_1) = p_{i+1}$ . When I first learned the gambler ruin's problem, this made sense. However, now that I'm actually doing a problem that's kind of related, I'm left questioning this: why can't we just $P(C|W_1) = p^{n-i-1}$ , where $n$ represents the # of wins to win the series, $i$ is the original starting spot, and one represents winning the first game And yet, I also don't think the gambler's ruin problem totally applies here; the biggest difference is that given $W_1$ or $L_1$ , the important thing is that we are one spot away from the edge, so the probability of winning or losing one spot from the edge is either $p$ or $q$ , whereas if we were at an $i$ in the ""middle,"" $i$ can shift left, right, and back left, and left some more.","['gambling', 'probability']"
4220219,A too strong condition for a disconnected subspace,"A subspace $Y$ of a topological space $X$ is disconnected exactly when it can be written as a union $Y=A\cup B$ with $A$ and $B$ disjoint nonempty open subsets of $Y$ (in the subspace topology).  In terms of the topology of $X$ , we have $A=U\cap Y$ and $B=V\cap Y$ for open sets $U$ and $V$ in $X$ .  This translates to: $(1)$ $Y$ is disconnected iff $Y\subset U\cup V$ for some open sets $U$ and $V$ in $X$ , both meeting $Y$ , and with $U\cap Y$ and $V\cap Y$ disjoint. As indicated in Willard, Exercise 26D, the following is not true in general: $(2)$ $Y$ is disconnected iff $Y\subset U\cup V$ for some disjoint open sets $U$ and $V$ in $X$ , both meeting $Y$ . We cannot take $U$ and $V$ disjoint in condition $(1)$ in general.  See the answer to this question for a $T_0$ example.  A simple $T_1$ example is the line with two origins $X=\mathbb{R}\cup\{0^*\}$ .  The subspace $Y=\{0,0^*\}$ is disconnected, with the only possible disconnection being $\{0\}\cup\{0^*\}$ , but any two respective nbhds of $0$ and $0^*$ in $X$ are not disjoint. However, if $X$ is a metric space, we can require $U$ and $V$ to be disjoint, as shown here . Question : Is there an example of a Hausdorff space $X$ with a disconnected subspace $Y$ , where the disconnection cannot be witnessed by the traces on $Y$ of disjoint open sets in the ambient space? As mentioned above, any counterexample cannot be a metrizable space.  Also $Y$ cannot be finite, as any two points can be separated by disjoint open sets in a $T_2$ space. I just can't come up with any example.","['general-topology', 'connectedness']"
4220232,Do there exist groups with polynomial word problem and NP-complete conjugacy problem?,"Suppose $G$ is a finitely-generated group and $A$ is a finite symmetric set of its generators. Define $\pi: A^* \to G$ using the following recurrence: $$\pi(\Lambda) = e$$ $$\pi(a \alpha) = a\pi(\alpha)$$ Then we have two computational problems: Word problem : Given a word $a \in A^*$ determine whether $\pi(a) = e$ ( $e$ is the group identity element). Conjugacy problem : Given two word $a, b \in A^*$ determine whether $\pi(a)$ and $pi(b)$ are conjugate. There are known quite many groups $G$ , for which the word problem can be solved in polynomial time (in respect to the length of the word). This class of groups includes all hyperbolic groups, automorphism groups of all free groups, all automatic groups and also many groups, that do not fall under any of these categories  (like, for example, the Baumslag-Gersten group $\langle a, b | a^{a^b}= a^2 \rangle$ ). For all such groups, the conjugacy problem belongs to NP. Indeed, if we take a word $c \in A^*$ such that $\pi(c)^{-1}\pi(a)\pi(c) = \pi(b)$ as a witness, we can verify it in polynomial time by solving the word problem for $c^{-1}acb^{-1}$ . However, does there exist a group, in which the word problem is polynomial and the conjugacy problem is NP-complete? Such group (if it exists) will be neither hyperbolic nor automatic (assuming $P \neq NP$ ), because for all groups from those classes the conjugacy problem is also solvable in polynomial time.","['finitely-generated', 'abstract-algebra', 'discrete-mathematics', 'group-theory', 'computational-complexity']"
4220237,How to prove $\int_0^\frac{\pi}{2} \sin^{r} \theta d \theta \int_0^\frac{\pi}{2} \sin^{r-1} \theta d \theta = \frac{\pi}{2r}$ without Beta properties?,"Wondering if there is a high-school level approach that doesn't involve manipulation of special functions or convolutions or complex analysis. It is easy to prove this holds for positive integer values of $r$ , but trying to extend this beyond seems difficult. I thought of maybe using polynomial properties (vanishing at infinitely many points implies identically 0) but I am not sure if this is even a workable proof.","['integration', 'alternative-proof', 'definite-integrals', 'recurrence-relations']"
4220248,Example of a manifold satisfying some Ricci curvature condition,"Let $(M,g)$ be a Riemannian manifold with Ricci curvature $R_{ij}$ and scalar curvature $R$ . Suppose $X$ is a smooth vector field on $M$ satisfying the condition $$R_{ij}(\nabla^iX^j)\leq cR,$$ where $c$ is a constant. Now I am not able to find a non-trivial example of a manifold that satisfies this type of condition. I earnestly request everyone for providing this example.","['riemannian-geometry', 'differential-geometry']"
4220278,"Proving that a (complex) differential form is of type $(p, q)$ iff its conjugate is of type $(q, p)$ using complex vector fields","Let $(M, J)$ be a $n$ -complex manifold and $p+q=k$ where $0\leq k \leq 2n$ . I'm looking for a clean way to prove that $\mu\in \mathcal{A}^k(M, \mathbb{C}):=\Gamma\left(\bigwedge^k T_{\mathbb C}^*M \right)$ is a complex diferrential $k$ -form of type $(p, q)$ iff $\bar{\mu}$ is of type $(q, p)$ . Now, first of all, I want to do everything avoiding real arguments in a coordinate-free fashion using complex vector fields (i.e, smooth sections of the complexified tangent bundle of $M$ ,  which I will denote by $\mathfrak{X}(M, \mathbb C):=\Gamma\left(T_{\mathbb C}M \right)$ ). Ok, so firstly, we define $\bar{\mu}\in \mathcal{A}^k(M, \mathbb{C})$ by $$(1)\qquad\qquad\qquad
 \bar{\mu}(Z_1,\ldots,Z_k):= \overline{\mu(\bar{Z_1},\ldots,\bar{Z_k})},\qquad\qquad  Z_1,\ldots,Z_k\in \mathfrak{X}(M, \mathbb C).$$ I'm aware that one can check that a $k$ -form is a $(p,q)$ -form when $\lambda\star \mu= \lambda^p \bar{\lambda}^q \mu$ , with $\lambda \in \mathbb C$ (or more generally, for $\lambda \in \mathcal{C}^\infty(M, \mathbb C)$ ) and where $\lambda\star \mu\in \mathcal{A}^k(M, \mathbb{C}) $ is defined as $$(2)\qquad\qquad\qquad\lambda\star \mu (Z_1,\ldots,Z_k):= \mu(\lambda Z_1,\ldots, \lambda Z_k).$$ Now, the trouble comes here. If we want to check (2) applied to (1), we end up obtaining that $\lambda\star \bar\mu=\lambda^p\bar{\lambda}^q \bar\mu$ , which is definitely NOT what we want. However, if we instead define $\bar \mu$ by $$(3)\qquad\qquad\qquad
 \bar{\mu}(Z_1,\ldots,Z_k):= \overline{\mu(Z_1,\ldots,Z_k)},$$ then we arrive at the desired conclusion. Now, in fact I've taken definition $(3)$ for granted for some time, but now I'm convinced it is NOT the right one.
If we play with a toy example, let's say $ \mu = dz\wedge d\bar{z}$ and $Z=a\dfrac{\partial}{\partial z}+b\dfrac{\partial}{\partial \bar{z}}, W=\alpha\dfrac{\partial}{\partial z}+\beta\dfrac{\partial}{\partial \bar{z}}$ , we all agree that $\bar\mu= d\bar{z}\wedge dz$ , and we can easily check that $\bar\mu(Z, W)=\overline{\mu(\bar Z, \bar W)}=b\alpha-a\beta$ , whereas $\overline{\mu(Z, W)}=\overline{a\beta - b \alpha}$ , so definition $(1)$ is the right one. So, what am I missing here? I'm certain that the conjugate is given by $(1)$ . Not many authors bother to explain what $\bar\mu$ actually is, or how to compute it, a small portion of them just say that if $\mu=\alpha+i \beta$ , then $\bar\mu=\alpha -i\beta$ (which I agree with, but it is quite dry). In fact, formula $(1)$ appears in Poor's Differential Geometric Structures, a quite venerable and underrated text, and as we saw in the toy example, it is quite the right one. All that being said, we can infer that maybe $(2)$ doesn't work as expected for complex vector fields. If so, what can we do so that $(2)$ works for my desired proof?
I guess we can just take the following definition for a $(p, q)$ -form and everything is settled: A complex $k$ -form is of type $(p, q)$ if and only if it vanishes whenever applied
to $p+1$ vectors of type $(1, 0)$ or to $q + 1$ vectors of type $(0, 1)$ . The desired conclusion holds trivially using the previous definition, but I'm quite unsatisfied because $(2)$ is a pretty nice way to check if a $k$ -form is a $(p, q)$ -form. Any help or comments are appreciated. Just to be clear, I don't have trouble with the fact that $\mu$ is a $(p, q)$ -form iff $\bar \mu$ is of type $(q, p)$ (for example, using the definition above or local coordinates), rather, I want to see why $(2)$ doesn't hold or what does it need to work correctly in the fashion I want to use it.","['complex-geometry', 'multilinear-algebra', 'complex-manifolds', 'differential-forms', 'differential-geometry']"
4220291,Domain of $f(x)=1/\sqrt{\left\{x+1\right\}-x^2+2x}$ where {.} denotes the fractional part of $x$.,"Normally, in finding domain for square root function, what I do is that what ever is under the root should be equal to or greater than $0$ . Here the square root is in denominator so $\left\{x+1\right\}-x^2+2x > 0$ . But due to the fractional part function I don't know how to proceed. I know $\left\{x+1\right\} = x+1 -[x+1]$ but this isn't helping much either. Any help will be appreciated. Thank you.","['fractional-part', 'functions']"
4220293,"Is there something like ""stochastic induction""?","I'm trying to prove convergence of a stochastic approximation-like algorithm. I have two questions about prove-techniques when working with randomness. 1. For a non-random sequence $(a_t)_t$ one could prove $a_t \rightarrow a$ by induction as follows: $$\text{Assume } |a_t - a| \leq \epsilon \text{ for some } t \text{ and show that } |a_{t+1} - a| \leq \delta \cdot \epsilon \text{ with } \delta \in (0, 1)$$ Now consider the random case. If one would knew that the induction hypothesis holds with probability $p_t$ and the induction step holds with probability $q_t$ , e.g.: $$\mathbb{P}(|a_t - a| \leq \epsilon) \geq p_t, \text{ and if } |a_t - a| \leq \epsilon \text{ is true, then}$$ $$\mathbb{P}(|a_{t+1} - a| \leq \delta \cdot \epsilon \ \big| \ |a_t - a| \leq \epsilon) \geq q_t$$ Could one show that $a_t \rightarrow a$ almost surely? Furthermore, how would the conditions of $p_t$ and $q_t$ look like? I would assume that $\prod_t p_t \cdot q_t > C$ must hold. 2. Alternatively, for a non-random sequence $(a_t)_t$ one could prove $a_t \rightarrow a$ simply by showing that: $$|a_{t+1} - a| \leq \dots \leq \delta |a_t - a| \text{ with } \delta \in (0, 1) \ \forall t$$ Now consider again the random case. If the statement holds with probability $p_t$ . Does $a_t \rightarrow a$ follow with probability $\prod_t p_t$ ? Thanks in advance!","['stochastic-approximation', 'stochastic-processes', 'convergence-divergence', 'probability-theory', 'probability']"
4220297,To prove: $\cot^{-1}7+\cot^{-1}8+\cot^{-1}18 = \cot^{-1}3$,"To prove: $\cot^{-1}7+\cot^{-1}8+\cot^{-1}18 = \cot^{-1}3$ My Attempt: First Method: we know that $\cot^{-1}x = \tan^{-1}\frac{1}{x}$ for $x>0$ and $\tan^{-1}x+\tan^{-1}y = \tan^{-1}\frac{x+y}{1-xy}, xy<1$ Now $\cot^{-1}7+\cot^{-1}8+\cot^{-1}18$ = $\tan^{-1}\frac{1}{7}+\tan^{-1}\frac{1}{8}+\tan^{-1}\frac{1}{18}$ = $(\tan^{-1}\frac{1}{7}+\tan^{-1}\frac{1}{8})+\tan^{-1}\frac{1}{18}$ = $\tan^{-1}\frac{\frac{1}{7}+\frac{1}{8}}{1-\frac{1}{7}\frac{1}{8}}+\tan^{-1}\frac{1}{18}$ = $\tan^{-1}\frac{\frac{15}{56}}{\frac{55}{56}}+\tan^{-1}\frac{1}{18}$ = $\tan^{-1}\frac{3}{11} +\tan^{-1}\frac{1}{18}$ = $\tan^{-1}\frac{\frac{3}{11}+\frac{1}{18}}{1-\frac{3}{11}\frac{1}{18}}$ = $\tan^{-1}\frac{\frac{65}{198}}{\frac{195}{198}}$ = $\tan^{-1}\frac{1}{3}$ = $\cot^{-1}3$ Second Method: we know that $\tan^{-1}x+\cot^{-1}x = \frac{π}{2}$ for $x \in \Bbb R$ . So $\cot^{-1}x = \frac{π}{2} - \tan^{-1}x$ . Now $$\cot^{-1}7+\cot^{-1}8+\cot^{-1}18 = \frac{π}{2} - \tan^{-1}7+ \frac{π}{2} - \tan^{-1}8+ \frac{π}{2} - \tan^{-1}18 \implies \\ \frac{3π}{2} - (\tan^{-1}7+\tan^{-1}8+\tan^{-1}18) = \frac{3π}{2} - \tan^{-1}\frac{7+8+18-7×8×18}{1-7×8-8×18-7×18} \\ = \frac{3π}{2} - \tan^{-1}\frac{-975}{-325} = \frac{3π}{2} - \tan^{-1}3 = π + (\frac{π}{2} - \tan^{-1}3) = π + \cot^{-1}3 .$$ Also we know that $\tan x$ and $\cot x$ are periodic function with period $π$ . Please help me in Second Method. Is $π + \cot^{-1}3 = \cot^{-1}3$ ?. If yes, then elaborate it.","['trigonometry', 'inverse-function']"
4220340,"Prove if Hilbert dimension is finite, then the Hilbert space as a vector space has the same dimension","This is from Kreyszig's functional analysis text, chapter 3.6 #2. The backward direction is easy and just the Gram Schmidt process on any basis. I am having some trouble on the forward direction. So we start with a totally orthonormal set M such that the closure of the span is the entire space X (by definition of total orthonormal). I need to show that in fact, any element can be expressed as the span so M is in fact the basis. For any any element x in X, we can approximate it as close as we want by linear combinations of M, but I'm not sure how to proceed from here. The Parseval relation was introduced in this chapter, but I don't see any way to use it.",['functional-analysis']
4220378,Inverse derivation of differential equation $f(x)=\frac{dy}{dx} +\frac{d^2y}{dx^2}+\frac{d^3y}{dx^3}$,The following function is given: $$ f(x)=\frac{dy}{dx} +\frac{d^2y}{dx^2}+\frac{d^3y}{dx^3}$$ I'am looking for the inverse function in Leibniz writing style. Here is my attempt: $$ f^{-1}(x)=\frac{dx}{dy} -\frac{d^2x}{dy^2} {\Biggl(\frac{dy}{dx}}\Biggl)^3  -\frac{d^3x}{dy^3} {\Biggl(\frac{dy}{dx}}\Biggl)^4+3{\Biggl(\frac{d^2x}{dy^2}}\Biggl)^2  {\Biggl(\frac{dy}{dx}}\Biggl)^5 $$ Is this correct?,"['inverse-function', 'ordinary-differential-equations', 'partial-differential-equations']"
4220411,Find ellipse of maximum area which is entirely contained within the area defined by a set of points,"I have a set of $(x, y)$ coordinates, from which I would like to generate an ellipse of maximum possible area which is entirely contained within the area defined by the given points. The points are from contour lines and not given by an equation, but generally appear in the shape of skewed ellipses. For example, for the following points, x y 45.66172222222225 18.841511212833733 45.66144444444447 18.841603609265974 45.661166666666695 18.84167023720114 45.66088888888892 18.841708840666733 45.66061111111114 18.841714721198922 45.66033333333336 18.8416792127312 45.66005555555558 18.841586913726573 45.659907959603544 18.8415 45.659777777777805 18.841432324588876 45.65952133520022 18.84122222222222 45.65950000000003 18.841205864567236 45.65925240431259 18.840944444444442 45.65922222222225 18.84091291427614 45.65903462855747 18.840666666666664 45.65894444444447 18.840543213692058 45.658848018922384 18.84038888888889 45.658686482591534 18.84011111111111 45.6586666666667 18.840075891391127 45.65854057470615 18.83983333333333 45.65841385937155 18.839555555555553 45.658388888888915 18.839497076739338 45.65829635419802 18.839277777777777 45.65819317225286 18.839 45.65811111111114 18.838743972287034 45.658103781273304 18.83872222222222 45.65801729926895 18.83844444444444 45.657943630825045 18.838166666666666 45.65788130483856 18.837888888888887 45.65783333333336 18.837633786630168 45.65782843965894 18.83761111111111 45.657777930516 18.83733333333333 45.65773797205481 18.837055555555555 45.65770846520107 18.836777777777776 45.65768983794373 18.836499999999997 45.65768315829199 18.836222222222222 45.657690315425526 18.835944444444443 45.657714290504025 18.835666666666665 45.65775954170573 18.835388888888886 45.65783252126027 18.83511111111111 45.65783333333336 18.835108788071842 45.65792541129527 18.834833333333332 45.65806060225678 18.834555555555553 45.65811111111114 18.834474038899852 45.65823358922209 18.834277777777775 45.658388888888915 18.834082623685447 45.658457173026996 18.834 45.6586666666667 18.833784998750474 45.658731945343874 18.83372222222222 45.65894444444447 18.83353762228444 45.65906160654751 18.833444444444442 45.65922222222225 18.83332268424614 45.65945121712184 18.833166666666664 45.65950000000003 18.833133439986426 45.659777777777805 18.83295712908462 45.659898642372674 18.83288888888889 45.66005555555558 18.832794864416265 45.66033333333336 18.832647295512253 45.66040951888557 18.83261111111111 45.66061111111114 18.832503587959618 45.66088888888892 18.832375253663077 45.66099358303661 18.83233333333333 45.661166666666695 18.832250897046737 45.66144444444447 18.83213848859703 45.66169543834408 18.832055555555552 45.66172222222225 18.832044342721858 45.66200000000003 18.831951946289568 45.6622777777778 18.83188531835439 45.662555555555585 18.83184671488883 45.66283333333336 18.831840834356605 45.663111111111135 18.831876342824323 45.66338888888892 18.831968641828965 45.663536484840996 18.832055555555552 45.66366666666669 18.83212323096666 45.663923109244294 18.83233333333333 45.663944444444475 18.832349690988305 45.66419204013188 18.83261111111111 45.66422222222225 18.832642641279445 45.66440981588704 18.83288888888889 45.664500000000025 18.83301234186348 45.664596425522106 18.833166666666664 45.664757961852935 18.833444444444442 45.66477777777781 18.833479664164482 45.664903869738325 18.83372222222222 45.66503058507293 18.834 45.66505555555558 18.834058478816264 45.66514809024647 18.834277777777775 45.66525127219165 18.834555555555553 45.66533333333336 18.834811583268447 45.66534066317122 18.834833333333332 45.66542714517556 18.83511111111111 45.66550081361947 18.835388888888886 45.66556313960594 18.835666666666665 45.66561111111114 18.83592176892534 45.66561600478556 18.835944444444443 45.665666513928514 18.836222222222222 45.66570647238968 18.836499999999997 45.665735979243436 18.836777777777776 45.665754606500776 18.837055555555555 45.66576128615252 18.83733333333333 45.66575412901897 18.83761111111111 45.665730153940466 18.837888888888887 45.665684902738775 18.838166666666666 45.66561192318422 18.83844444444444 45.66561111111114 18.83844676748368 45.665519033149245 18.83872222222222 45.66538384218772 18.839 45.66533333333336 18.8390815166557 45.66521085522241 18.839277777777777 45.66505555555558 18.83947293187009 45.66498727141749 18.839555555555553 45.66477777777781 18.83977055680508 45.664712499100624 18.83983333333333 45.664500000000025 18.84001793327112 45.66438283789701 18.84011111111111 45.66422222222225 18.840232871309414 45.66399322732267 18.84038888888889 45.663944444444475 18.840422115569137 45.66366666666669 18.840598426470944 45.66354580207184 18.840666666666664 45.66338888888892 18.84076069113929 45.663111111111135 18.840908260043292 45.663034925558904 18.840944444444442 45.66283333333336 18.841051967595934 45.662555555555585 18.84118030189247 45.66245086140788 18.84122222222222 45.6622777777778 18.841304658508818 45.66200000000003 18.8414170669585 45.66174900610049 18.8415 45.66172222222225 18.841511212833733 and given the centre of the points $(h, k)$ , And the equation for an ellipse that is not at the origin and is rotated by an angle (taken from the answers at What is the general equation of the ellipse that is not in the origin and rotated by an angle? ), $$\frac{((x−h)\cos(A)+(y−k)\sin(A))^2}{a^2}+\frac{((x−h)\sin(A)-(y−k)\cos(A))^2}{b^2}=1$$ I would like to calculate the variables $a$ , $b$ (the semi-axes respectively) and $A$ (the angle of rotation of the ellipse from the x-axis) for an ellipse of the largest possible area, from which I will be able to construct an ellipse of the same size and angle at any point $(h, k)$ . My initial idea was to find the minimum radius of the area defined by the points and centred on $(h, k)$ , then find the radius of the same area at an angle of 90 degrees from the minimum, but a very rough calculation appears to show that this will include some amount of area outside the boundary defined by the points. For the ellipse to fit within the points, the major axis must then be narrower than the total width of the area at that angle. On the other hand, another possibility would be to find the maximum radius of the area defined by the points and centred on $(h, k)$ , then find the radius of the same area at an angle of 90 degrees from the maximum, but once again this includes some amount of area outside the point boundary, and for the ellipse to fit within the points, the minor axis must then be narrower than the total width of the area at that angle. It is difficult to tell which method will yield an ellipse of larger possible area by these rough plots, or if there is yet another superior method; so I ask, is there a method or algorithm to determine this analytically? If it is possible to use an equation for a skewed ellipse to cover an even larger area then that would be even better - the aim is to generate an equation for a shape covering the maximum amount of area defined by the points, to then be able to determine the width of the resulting shape at any angle.","['discrete-geometry', 'computational-geometry', 'conic-sections', 'geometry', 'optimization']"
4220420,Rational approximation to complex function involving arctan and sqrt,"I'm dealing with the following type of function where $\omega_a$ , $\gamma$ and $a$ are parameters: $$
f(\omega)\propto \sqrt{\omega_\textrm{a}-\omega-\textrm{i}\gamma}\; \arctan\left(\frac{a}{\sqrt{\omega_\textrm{a}-\omega-\textrm{i}\gamma}}\right)
$$ Im currently thinking of ways to approximate this function by a rational function (in $\omega$ ). The issue I'm having is that the quantities under the square root as well as in the arctan are complex. I've really no idea how to do it - I didn't hear any functional analysis but I feel like it has to do something with analytical continuation. I would be happy about any tips how to approach the problem! What I did first was trying to ignore that the arguments are complex-valued, so I did some Taylor expansion, Padé-approximation and such, but then the real and imaginary part of the approximant were completely different from the original function. I've stumbled upon this representation of the arcus tanges for complex arguments (taken from wikipedia): $$
\arctan(a+b\,\mathrm i) = \left\{
\begin{array}{ll} \displaystyle
\frac12\,\left(\arctan \frac{a^2+b^2-1}{2a} + \frac\pi2\,\textrm{sgn}(a) \right)
 & \; a\neq0 \\
0
 & \; a=0,\, |b|\leq1 \\ \displaystyle
\frac\pi2\,\textrm{sgn}(b)
 & \; a=0,\, |b|>1 \\
\end{array} \right\} \\
+ \mathrm i \cdot \frac12\,\operatorname{artanh} \frac{2b}{a^2+b^2+1}
$$ But since the argument in my function $f(\omega)$ involves a square root I do have a lot of terms to the power of $\frac{1}{2}$ , $\frac{3}{2}$ and so on. Regarding the range of values of $\omega \in [\omega_L, \omega_U]$ I can say that $\omega_L<\omega_a<\omega_U$ but it is not really restricted. Typical values are: $10^{15} <\omega < 10^{16},\;\omega_a = 3\cdot 10^{15}$ and $a=5\cdot10^{7}$ . With these values we have $$
    \max_\omega \Re\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}} \right) \approx 1.385 \qquad\qquad
    \min_\omega \Re\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.625
$$ $$
    \max_\omega \Im\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.0152 \qquad\qquad
    \min_\omega \Im\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.0150
$$","['complex-analysis', 'rational-functions', 'approximation']"
4220445,Find the directional derivative at a point and in the direction of a given vector.,"I have the function: $f(x,y) = x/(x+y)$ and I want to the find the directional derivative at the point $(1,2)$ and in the direction of the vector: $a=(4,3)$ . I started by finding the gradient of $f(x,y)$ which I found to be: $(y/(x+y)^2 , -x/(x+y)^2)$ , I then found the gradient at the point $(1,2)$ by substituting in $(1,2)$ and got the gradient of $f(1,2) = (2/9,-1/9)$ . Next I found the modulus of $a$ which is $\sqrt{4^2 +3^2} =5$ and I used this modulus to create $u$ where $u = a/|a|$ so $u = (4i +3j)/5$ which is equivalent to $(4/5,3/5)$ . Then from here I ran into an issue. I then tried to do $\nabla f \cdot u$ and the answer on the answer sheet is given to be $1/9$ , however when I do this multiplication I get: $((4/5 \cdot 2/9), (3/5 \cdot -1/9))$ which gives me $(8/45,-1/15)$ which is not what I want. Could someone please show me where I went wrong or what I was supposed to do once I found $\nabla f$ and $u$ Thanks in advance","['multivariable-calculus', 'derivatives']"
4220463,Proof of Brouwer's Fixed Point Theorem using Stokes' Theorem,"There is a proof of Brauwer's fixed point theorem (for functions $f:\overline{D(0,1)}\subset\mathbb{R}^n\rightarrow \overline{D(0,1)}$ ), it appears in several sources including the wikipedia page .
The idea is to construct a smooth function $r:\overline{D(0,1)}\rightarrow S^{n-1}$ such that $r|_{S^{n-1}}=Id$ : You assuming that $f$ has no fixed point, and let r(x) be the intersection point of the continuation of the line $[x,f(x)]$ with $S^{n-1}$ on the side of x. Showing it's smooth is not a big deal since $r(x)$ is of the form $r(x)=f(x)+\lambda(x-f(x))$ for $\lambda\geq 1$ and it clearly maps every point on $S^{n-1}$ to itself. Then you take a volume $\omega$ form on $S^{n-1}$ , and consider the pullback $r^*\omega$ and say that on one hand we have: $$0\underset{\text{volume form}}{<}\int_{S^{n-1}}\omega=\int_{S^{n-1}}{r|_{S^{n-1}}}^*\omega$$ and on the ohter hand: $$\int_{S^{n-1}}{r|_{S^{n-1}}}^*\omega=\int_{S^{n-1}}r^*\omega\underset{Stokes}{=}\int_\overline{D(0,1)}d(r^*\omega)=\int_\overline{D(0,1)}r^*(d\omega)=0$$ since $\omega$ is a maximal form on $S^{n-1}$ , it's exterior derivative $d\omega$ is zero. We have defined the pullback of a differential form using a smooth function $g:U\rightarrow \mathcal{M}$ for an open set $U\subset{\mathbb{R}^{n-1}}$ by $$g^*\omega(x)(v_1,\dots,v_{n-1})=\omega(g(x))(Dg(x)v_1,\dots,Dg(x)v_{n-1})$$ for any $x\in U$ and any vectors $v_1,\dots,v_{n-1}\in \mathbb{R}^{n-1}$ There is also a pullback with functions between manifolds using the local coordinates so I understand why $\int_{S^{n-1}}\omega=\int_{S^{n-1}}Id^*\omega=\int_{S^{n-1}}{r|_{S^{n-1}}}^*\omega$ , but what I don't understand it is why can we say that $\int_{S^{n-1}}{r|_{S^{n-1}}}^*\omega=\int_{S^{n-1}}r^*\omega$ - how does the definition of a pullback by a smooth function extend to the boundry of the open set such that we can say state this equality. More generally I start to wonder what do we mean when we pull-back differential forms from manifolds with boundry - is it the limit of the pull-backs from the interior, or do we pull them back using the induced atlas on the bounry? If it's the latter, how do we know we're getting a smooth differential form?","['stokes-theorem', 'fixed-point-theorems', 'differential-geometry']"
4220469,Galois conjugate $\sigma(a) = \Re(a)$ implies $\sigma(a) = a$?,"Let $a$ be a complex number which is algebraic over $\mathbb{Q}$ . Let $\sigma(a)$ be a Galois conjugate of $a$ , and let $\Re(a)$ be the real part of $a$ . Question : Is it true that $\sigma(a) = \Re(a)$ implies $\sigma(a) = a$ ?","['galois-theory', 'number-theory', 'algebraic-number-theory']"
4220481,Concentration inequality for Lipschitz Function,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space, $(X_n:\Omega\rightarrow \mathbb{R}^m)_n$ be a sequence of i.i.d. random variables and let $L:\mathbb{R}^m\rightarrow [0,\infty)$ be Lipschitz.  Let $\mu_n:=\frac1{n} \sum_{k=1}^n \delta_{X_k}$ .  Are there conditions under which: $$
\mathbb{P}\left(|\mathbb{E}_{X\sim\mu_n}[L(X)]-\mathbb{E}_{X\sim Law(X_1)}[L(X)]|\geq t\right)\leq \exp\left(
-t^2
\right),
$$ where $c>0$ is some constant?","['statistics', 'concentration-of-measure', 'probability-theory', 'large-deviation-theory']"
4220485,"If $f(f(x)) = 2x+1$, what is $f(13)$? [SOLVED by @DonThousand]","I found this problem in an old textbook of mine and am unsure how to solve it. This was in a chapter about functions. Any help will be appreciated. The Problem: If $f: \mathbb{N} \to \mathbb{N}$ is a strictly increasing function such that $f(f(x)) = 2x+1$ for all natural numbers $x$ . Solve for $f(13).$ Edit: To show my work-
I have tried manually guess and checking functions for $f(x)$ , especially functions similar to $x^{x-1}$ and variations. None of these functions seem to work. I also tried finding linear functions for $f(x)$ . If it is linear I believe it would be similar to $f(x) =x \sqrt2  + c$ where $c$ is a constant I am yet to ascertain.",['functions']
4220496,Edge Pairing of different Spanning Trees,"I've stumbled across this theorem a while ago Let $S$ and $T$ be two Spanning Trees on the same vertex set. Then there is a bijection $F: E(S) \to E(T)$ satisfying following edge exchange property: $S - e + F(e)$ is a Spanning Tree for all $e \in E(S)$ . I find this quite interesting since it summarizes some nice properties about Spanning Trees.
I came up with a proof for this theorem, but I am not 100% sure whether the proof is actually correct. Can anyone verify its correctness? Also, if you think there is an easier way to prove it, let me know. Proof. Let $n = | E(S)\setminus E(T) | $ be the number of edges, that differ from each Spanning Tree. We prove the theorem via induction in $n$ . The case $n = 0$ is trivial since we then have $S = T.$ Now assume that we have $n+1$ edges in $S$ that are not included in $T$ and that the assumption holds for $n$ . Let $e$ be any edge in $T - S$ (such an edge exists since both Spanning Trees contain equally many edges). Since $S$ is a Spanning Tree, there is a fundamental circle $C$ within $ S+ e$ . Since $T$ is a Spanning Tree, we have $C \not \subseteq T$ . Let $e^\prime \in C$ be any edge that is not included in T. We can now define $F(e^\prime) := e$ . The condition of the statement now holds for this pair of $e$ and $e^\prime $ by construction.
Let $S^\prime := S -e^\prime + e$ . Then, by the induction hypothesis, we find a bijection $G: E(S^\prime) \to E(T)$ satisfying the edge exchange property. It suffices to show, that $S - f^\prime + G(f^\prime)$ is a Spanning Tree too for all edges $f^\prime \in E(S) \cap E(S^\prime)$ (we can extend $F$ by $G$ then). Let $f^\prime \in E(S) \cap E(S^\prime)$ be such an edge and $f:= G(f^\prime)$ . To see this we, we can partition the vertex set: Note that $S - e^\prime - f^\prime $ contains exactly three connected components. We label these with $S_1, S_2, S_3$ such that $e^\prime$ is a bridge between $S_1$ and $S_2$ and $f^\prime$ is a bridge between $S_2$ and $S_3$ . We know that $S - e^\prime + e$ is a Spanning Tree. Therefore $e$ must be a bridge between $S_1$ and $S_2$ . Since $S - e^\prime + e - f^\prime + f$ is a Spanning Tree by the inductive hypothesis, exactly one of the following cases occurs: $G(f^\prime) = f$ is a bridge between $S_1$ and $S_3$ . $G(f^\prime) = f$ is a bridge between $S_2$ and $S_3$ . Either way, we can substitute $e^\prime$ back in for $e$ and still get a Spanning Tree. Thus, $S - f^\prime + f$ is a Spanning Tree. q.e.d. Let me know what you think about the theorem and this proof. I think it has some nice applications, e.g. for Minimum Spanning Trees it follows that the  bijection preserves the cost function, i.e. $c(f(e)) = c(e)$ for all edges $e \in E(S)$ . Also, note that the proof is highly constructive and one can easily construct an algorithm to compute the bijection. Feel free to comment if you have come up with some other applications.","['graph-theory', 'solution-verification', 'combinatorics', 'discrete-mathematics']"
4220499,What's the distance between triangles?,"How can we define distance between, say, two of them? And if we the distance between two of them and the distance of another one to the first, do we know its distance tö rhe second? What ways are possible to induce a distance on them. The middle point seems a reasonable one but if the distance is non-zero they can still overlap. Is there a way to make their distance zero when they touch at an arbitrary point? Let's simplify things. Instead of triangles consider circles in three dimensional space.","['mahalanobis-distance', 'measure-theory', 'hausdorff-distance']"
4220539,The closure of meromorphic functions under composition,"It is well-known that composing meromorphic functions on $\mathbb C$ does not necessarily result in a meromorphic function (e.g., $\exp\circ\frac1x$ , which has an essential singularity at $x=0$ .) Question: What is the ""closure"" of the meromorphic functions under composition? That is, what is the minimal extension field $K$ of the field $\mathcal M(\mathbb C)$ such that for each $f,g\in K\setminus\mathbb C$ , we have $f\circ g\in K$ . My naïve guess would be the field of holomorphic functions defined on $\mathbb C\setminus I$ , for some zero-dimensional complex analytic subset $I$ . Such a field will be certainly closed under composition, but I am not sure how to prove/disprove it is minimal . Here, I view meromorphic functions as entire functions $f\colon\mathbb C_\infty\setminus\{\infty\}\to\mathbb C_\infty$ , where $\mathbb C_\infty:=\mathbb C\cup\{\infty\}$ is the Riemann sphere. Then, we can define the composition of entire functions $f\colon\mathbb C_\infty\setminus I\to\mathbb C_\infty$ and $g\colon\mathbb C_\infty\setminus J\to\mathbb C_\infty$ with $f\circ g\colon \mathbb C_\infty\setminus(J\cup g^{-1}(I))\to\mathbb C_\infty:z\mapsto f(g(z))$ .","['complex-analysis', 'meromorphic-functions']"
4220564,How to prove that the equality relation is an equivalence relation?,"Fraleigh's algebra book presents the following Definition. Let $X$ be a  set. The equality relation in $X$ is the subset $$\{(x,x);\;x\in X\}\subset X\times X.$$ and also 0.19 Example of Fraleigh's algebra book says For any nonemtpy set $X$ , the equality relation $=$ defined by the subset $$\{(x,x);\;x\in X\}\subset X\times X.$$ is an equivalence relation. I tried to prove that the equality relation is an equivalence relation. and I failed. but Tao's analysis1 says in the appendix that equality just obeys the following four $axioms$ reflexive, symmetry, transitive, and substitution axioms. so what is the truth? Is the equality relation just an equivalence relation by axioms? or Is the equality relation provable that it is an equivalence relation?","['elementary-set-theory', 'equivalence-relations', 'abstract-algebra']"
4220572,Show that there are no real solutions of $1 + \sum_{n = 1}^{\infty} \frac{x^n}{\prod_{k=1}^{n} H_k} = 0$ where $H_k = \sum_{i=1}^{k} \frac{1}{i}.$,"EDIT : I found an alternative proof which seems correct. You do not have to read until bold letters since they are wrong. I recommend reading from ""New Solution"". Show that there are no real solutions of $$1 + \sum_{n = 1}^{\infty} \frac{x^n}{\prod_{k=1}^{n} H_k} = 0$$ where $$H_k = \sum_{i=1}^{k} \frac{1}{i}.$$ I managed to prove this, and I want to know if my proof is correct, and if there are any other (better) ways of proving it. (This is my first question and my English may be incorrect since English is not my first language.) The overall proof is proving by contradiction : let $$f(x) = 1 + \sum_{n = 1}^{\infty} \frac{x^n}{\prod_{k=1}^{n} H_k}$$ and suppose a real number $a$ such that $f(a) = 0$ . Since $f(x) \geq 1$ for $x \geq 0$ , it is trivial that $a \lt 0$ . Just a little distribution : $$\begin{align} f(x) &= 1 + \sum_{n = 1}^{\infty} \frac{x^n}{\prod_{k=1}^{n} H_k} = 1 + \sum_{n = 1}^{\infty} \left\{ \frac{x^{2n-1}}{\prod_{k=1}^{2n-1} H_k} + \frac{x^{2n}}{\prod_{k=1}^{2n} H_k}\right\} \\ \\ &= 1 + \sum_{n=1}^{\infty} \frac{x^{2n} + H_{2n} x^{2n-1}}{\prod_{k=1}^{2n} H_k} \end{align}$$ and $$e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} = 1 + \sum_{n=1}^{\infty} \left\{ \frac{x^{2n-1}}{(2n-1)!} + \frac{x^{2n}}{(2n)!} \right\} = 1 + \sum_{n=1}^{\infty} \frac{x^{2n} + 2nx^{2n-1}}{(2n)!} .$$ Meanwhile, $$H_k = \frac{1}{1} + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{k} \lt k$$ and $$\prod_{k=1}^{2n} H_k \lt (2n)!.$$ Since $a \in \mathbb{R^-}$ , $$a^{2n} + H_{2n} a^{2n-1} \gt a^{2n} + 2na^{2n-1}.$$ Therefore, $$0 = f(a) = 1 + \sum_{n=1}^{\infty} \frac{a^{2n} + H_{2n} a^{2n-1}}{\prod_{k=1}^{2n} H_k}$$ $$\gt 1 + \sum_{n=1}^{\infty} \frac{a^{2n} + 2na^{2n-1}}{(2n)!} = e^a \gt 0$$ and it is a contradiction. Edit : According to the comments, I found out that the following identity can not be concluded right away since $a^{2n} + H_{2n} a^{2n-1}$ may be negative for some $a$ . So now we have to show the whole identity for all $n \in \mathbb{N}$ and $a \in \mathbb{R^-}$ such that $f(a) = 0$ : $$ \frac{a^{2n} + H_{2n} a^{2n-1}}{\prod_{k=1}^{2n} H_k} \gt \frac{a^{2n} + 2na^{2n-1}}{(2n)!}$$ or prove a weaker statement : $$ \frac{a^{2n} + H_{2n} a^{2n-1}}{\prod_{k=1}^{2n} H_k} \gt \frac{(a \ln t)^{2n} + 2n(a \ln t)^{2n-1}}{(2n)!}$$ where $t \gt 0$ since the contradiction still holds if $f(a) \gt t^a.$ Since $a^{2n-1} < 0$ , the inequality we want to show is equivalent to the following inequalities : $$\frac{a + H_{2n}}{\prod_{k=1}^{2n} H_k} < \frac{a (\ln t)^{2n} + 2n (\ln t)^{2n-1}}{(2n)!},$$ $$a < \frac{2n \cdot \prod_{k=1}^{2n} H_k \cdot (\ln t)^{2n-1} - (2n)! \cdot H_{2n}}{(2n)! - (\ln t)^{2n} \cdot \prod_{k=1}^{2n} H_k}$$ for all $a \in \mathbb{R^-}$ such that $f(a) = 0.$ My further attempt was trying to show that there exists $t \in \mathbb{R^+}$ such that $$\frac{2n \cdot \prod_{k=1}^{2n} H_k \cdot (\ln t)^{2n-1} - (2n)! \cdot H_{2n}}{(2n)! - (\ln t)^{2n} \cdot \prod_{k=1}^{2n} H_k} \geq 0$$ for all $n \in \mathbb{N}.$ Suppose $t < e$ for a weaker statement, then $\ln t < 1$ and $$(2n)! - (\ln t)^{2n} \cdot \prod_{k=1}^{2n} H_k > (2n)! - \prod_{k=1}^{2n} H_k > 0,$$ and we get to prove: $$2n \cdot \prod_{k=1}^{2n} H_k \cdot (\ln t)^{2n-1} - (2n)! \cdot H_{2n} \geq 0$$ or $$\ln t \geq \left\{ \frac{(2n-1)!}{\prod_{k=1}^{2n-1} H_k} \right\}^{\frac{1}{2n-1}} =: F(n).$$ If there exists $M \in \mathbb{R}$ such that $F(n) < M$ for all $n \in \mathbb{N}$ , such $t \in \mathbb{R^+}$ will exist and the inequality above will hold. I am now struggling to prove this with the identities : $$\ln n + \frac{1}{n} < H_n < \ln n + 1$$ for $n \in \mathbb{N}$ , and $$\ln k = \sum_{n=1}^{\infty} \frac{1}{n} \cdot \left( \frac{k - 1}{k} \right)^n$$ for $\frac{1}{2} < k \in \mathbb{R}.$ Bad News : The function $F(n)$ seems to diverge when $n \to \infty$ , according to here . New Solution Note that $f$ is defined for all $x \in \mathbb{R}$ and if $f(a) = 0$ for $a \in \mathbb{R}$ then $a < 0$ . Assume $a < 0$ exists. For $n \in \mathbb{N}$ , $$\begin{align} \int_{a}^{0} \frac{x^{n}-a^{n}}{x-a} dx &= \int_{a}^{0} (x^{n-1} + ax^{x-2} + \cdots + a^{n-1}) dx \\ \\ &= \left[ \sum_{k=0}^{n-1} \frac{a^{k}}{n-k} x^{n-k} \right]_{a}^{0} = - a^{n} \sum_{k=1}^{n} \frac{1}{k} = - a^{n} H_{n} \end{align}$$ Using this result, $$\begin{align} \int_{a}^{0} \frac{f(x)}{x-a} dx &= \int_{a}^{0} \frac{f(x) - f(a)}{x-a} dx \\ \\ &= \int_{a}^{0} \frac{1}{x-a} \left[ \sum_{n=1}^{\infty} \frac{x^{n}}{H_{1} H_{2} \cdots H_{n}} - \sum_{n=1}^{\infty} \frac{a^{n}}{H_{1} H_{2} \cdots H_{n}} \right] dx \\ \\ &= \int_{a}^{0} \frac{1}{x-a} \left[ \sum_{n=1}^{\infty} \frac{x^{n} - a^{n}}{H_{1} H_{2} \cdots H_{n}} \right] dx \\ \\ &= \sum_{n=1}^{\infty} \frac{1}{H_{1} H_{2} \cdots H_{n}} \int_{a}^{0} \frac{x^{n} - a^{n}}{x-a} dx \\ \\ &= - \sum_{n=1}^{\infty} \frac{a^{n} H_{n}}{H_{1} H_{2} \cdots H_{n}} \\ \\ &= -a - \sum_{n=2}^{\infty} \frac{a^{n} H_{n}}{H_{1} H_{2} \cdots H_{n}} \\ \\ &= -a - a \sum_{n=2}^{\infty} \frac{a^{n-1}}{H_{1} H_{2} \cdots H_{n-1}} \\ \\ &= -a - a \sum_{n=1}^{\infty} \frac{a^{n}}{H_{1} H_{2} \cdots H_{n}} \\ \\ &= - a \cdot \left[ 1 + \sum_{n=1}^{\infty} \frac{a^{n}}{H_{1} H_{2} \cdots H_{n}} \right] \\ \\ &= - a f(a) \\ \\ &= 0 \end{align}$$ Since $f(0) = 1$ , $f(a) = 0$ and $\int_{a}^{0} \frac{f(x)}{x-a} dx = 0$ , there exists real number $a_{1} \in (a, 0)$ such that $f(a_{1}) = 0$ . (If not, then it is a contradiction since $f \ge 0$ on $(a, 0)$ , not $f = 0$ everywhere since $f(0) = 1$ , but $\int_{a}^{0} \frac{f(x)}{x-a} dx = 0$ .) Similarly, we can find $a_{n+1} \in (a_{n}, 0)$ such that $f(a_{n+1}) = 0$ . Now there are two ways to prove that this is impossible. First, since $f$ is an entire function, its zero-set should not have accumulation points. However, we can find infinite zeros in the interval $(a, 0)$ and it is a contradiction. Second, let the (partial) zero-set of $f$ be $S$ such that $S \subseteq (a, 0)$ . Since $S$ is bounded above, there exists $s := \sup S$ . Now we can find a sequence $\{ s_{n} \}_{n \in \mathbb{N}}$ in $S$ , that converges to $s$ . Since $f$ is continuous, $0 = \lim_{n \to \infty} f(s_{n}) = f(s)$ . Since $s$ is a zero of $f$ , there exists $s' \in (s, 0)$ such that $f(s') = 0$ . Since $s' \in S$ , if $s \ne 0$ then it contradicts the fact that $s = \sup S$ . If $s = 0$ , $f(s) = f(0) = 0$ because $s$ is a zero of $f$ . However, it is trivial that $f(0) = 1$ and it is a contradiction. Therefore, if $f(z) = 0$ then $z \in \mathbb{C} \, \backslash \, \mathbb{R}$ .","['complex-analysis', 'harmonic-numbers', 'real-analysis']"
4220585,Prove that the infinite $\sum_{\text{ p prime}}\frac{1}{2^p}$ is an irrational number. [duplicate],"This question already has answers here : $\sum\limits_{\text{prime }p} 2^{-p}$ is an irrational number (3 answers) Closed 2 years ago . Prove that the infinite $\sum_{\text{
p prime}}\frac{1}{2^p}$ is an irrational number. My progress: Suppose $$\omega = \sum_{\text{
p prime}}\frac{1}{2^p}= \frac{1}{2^2}+\frac{1}{2^3}+\dots$$ Also let $f(x)= x^{th}$ prime We will try to show that for $\omega$ and $\epsilon > 0,$ there is a positive integer $q$ and an integer $p$ such that $0 < |q\omega − p| < \epsilon.$ Suppose $$\frac{p}{q}= \frac{1}{2^2}+\frac{1}{2^3}+\dots +\frac{1}{2^{f(n)}}$$ Then we let $$q=2^{f(n)},~~p=2^{f(n)}\left(\frac{1}{2^2}+\frac{1}{2^3}+\dots +\frac{1}{2^{f(n)}}\right)$$ So $$|q\omega − p|= |2^{f(n)}\omega - 2^{f(n)}\left(\frac{1}{2^2}+\frac{1}{2^3}+\dots +\frac{1}{2^{f(n)}}\right)|$$ $$= \frac{2^{f(n)}}{2^{f(n+1)}}+\frac{2^{f(n)}}{2^{f(n+2)}} +\dots$$ $$=\frac{1}{2^{f(n+1)-f(n)}}+\frac{1}{2^{f(n+2)-f(n)}}+\dots \le \frac{1}{2^{f(n+1)-f(n)}}+\frac{1}{2^{f(n+1)-f(n)+1}}+\frac{1}{2^{f(n+1)-f(n)+2}}\dots $$ $$= \frac{1/2^ {f(n+1)-f(n)}}{1-2^ {f(n+1)-f(n)}}=\frac{1}{2^ {f(n+1)-f(n)}-1}$$ Now, the ending which I think of is that the difference between $f(n+1)-f(n)$ can be very big. Then when we have $f(n+1)-f(n)$ to be very big, then $1/2^{f(n+1)-f(n)}< \epsilon .$ I was actually motivated by the proof of proving e irrational. I am not sure about it. Any hints?","['number-theory', 'irrational-numbers', 'pigeonhole-principle', 'dirichlet-series', 'combinatorics']"
4220605,"Finding a basis for the kernel of the following linear transformation: $T(p(x))=p'(x)$,$T:P_3[\mathbb{R}]\rightarrow P_3[\mathbb{R}]$","By given the following linear transformation: $T(p(x))=p'(x)$ , $T:P_3[\mathbb{R}]\rightarrow P_3[\mathbb{R}]$ , find a basis and the dimension of the kernel. $Solution.$ \begin{align*}
\ker T & =\left\{p( x) \in P_{3}[\mathbb{R}]\Bigl| p'( x) =0\right\} \\ &=\left\{ax^{3} +bx^{2} +cx+d\Bigl| 3ax^{2} +2bx+c=0,a,b,c,d\in \mathbb{R}\right\}\\
& =\left\{ax^{3} +bx^{2} +cx+d\Bigl| c=-3ax^{2} -2bx,a,b,c,d\in \mathbb{R}\right\}\\
& =\left\{ax^{3} +bx^{2} +\left( -3ax^{2} -2bx\right) x+d\Bigl| a,b,d\in \mathbb{R}\right\}\\
& =\left\{a\left( x^{3} -2x^{2}\right) +b\left( x^{2} -2x\right) +d\Bigl| a,b,d\in \mathbb{R}\right\}\\
& =\operatorname{Span}\left\{x^{3} -2x^{2} ,x^{2} -2x,1\right\}\end{align*} in addition, the isomorphic vectors to the polynomials are linearly independent, can be easily checked and easy to see, so they are a basis for the kernel. Thus, $$B_{\ker T} =\left\{x^{3} -2x^{2} ,x^{2} -2x,1\right\} \Longrightarrow \dim\ker T=3$$ However, it is clear that this isn't true since the only polynomial who gives $p'(x)=0$ is $p(x)=d$ , so the basis is actually: $$B_{\ker T} =\left\{1\right\} \Longrightarrow \dim\ker T=1$$ and it's easy to see. Perhaps I'm finding here a basis for the $x$ 's? because I can't find why I get the wrong polynomials in the basis.","['linear-algebra', 'linear-transformations']"
4220621,Indefinite integration gives two different answers,"The question is : \begin{array}{l}
\text { If } \int \frac{x+1}{\sqrt{2 x-1}} d x=\mathrm{f}(\mathrm{x}) \sqrt{2 x-1}+\mathrm{C}, \text { where } \mathrm{C} \text { is }\\
\text { constant of integration, then } \mathrm{f}(\mathrm{x}) \text { is equal to : }
\end{array} Here is how we reach the answer : \begin{array}{l}
\sqrt{2 x-1}=t \Rightarrow 2 x-1=t^{2} \Rightarrow 2 d x=2 t \\
. d t \\
\int \frac{x+1}{\sqrt{2 x-1}} d x=\int \frac{\frac{t^{2}+1}{2}+1}{t} t d t=\int \frac{t^{2}+3}{2} d t \\
=\frac{1}{2}\left(\frac{t^{3}}{3}+3 t\right)=\frac{t}{6}\left(t^{2}+9\right)+c \\
=\sqrt{2 x-1}\left(\frac{2 x-1+9}{6}\right)+c \\
=\sqrt{2 x-1}\left(\frac{x+4}{3}\right)+c \\
\Rightarrow f(x)=\frac{x+4}{3}
\end{array} Here is how I solved it . \begin{aligned}
& \int \frac{x+1}{\sqrt{2 x-1}} \\
\text { Let } 2 x-1 &=t \\
& \frac{d t}{d x}=2 \\
& x+1=\frac{t+3}{2} \\
&=\frac{1}{2} \int \frac{t+3}{2 \sqrt{t}} d t \\
&=\frac{1}{4} \int\left(\sqrt{t}+\frac{3}{\sqrt{t}}\right) d t \\
&=\frac{1}{4} \times \frac{2}{3} t^{3 / 2}+\frac{1}{4} \times \frac{2 \times 3}{1} \times t^{1 / 2} \\
=& \frac{1}{2}\left(\frac{1}{3} t^{3 / 2}+3 t^{1 / 2}\right) \\
&=t^{1 / 2}\left(\frac{1}{6} t^{3}+\frac{3}{2}\right) \\
&=\sqrt{2 x-1}\left(\frac{1}{6}(2 x-1)^{3}+\frac{3}{2}\right)
\end{aligned} PS- It took me hour to write this . Pls tell if i solved it wrong . But Please answer.","['integration', 'indefinite-integrals']"
4220691,Pencil of irreducible cubics must have $9$ distinct base points?,"Let $\mathcal{L}$ be a pencil of cubics on $\Bbb{P}_\Bbb{C}^2$ whose general member is smooth and such that all members are irreducible. I'm trying to prove/disprove the following: The base locus of $\mathcal{L}$ consists of nine $9$ distinct points. I do have an intuitive argument, but formally speaking I'm still lost. The argument is: let $C,C'$ be smooth cubics. Generally, $C,C'$ meet in $9$ distinct points $P_1,...,P_9$ in the most general position possible (i.e., no three points are in a line, no six are in a conic). Let $\mathcal{L}'$ is the pencil of cubics through $P_1,...,P_9$ . The fact that $\mathcal{L}$ has only irreducible curves should mean that it is general in some sense, therefore essentially like $\mathcal{L}'$ . I've tried to formalize this by looking at $\Bbb{P}^9$ as the space of all cubics in $\Bbb{P}^2$ and $\mathcal{L}$ as a general line in it. But I don't know how to relate this with the condition of $9$ distinct points. Any help is appreciated, thank you!","['algebraic-geometry', 'surfaces', 'elliptic-curves']"
4220709,How to compute $\int_0^\infty \frac{\log(x)}{\sqrt{x}(x+1)} \ dx$ using the Residue Theorem?,"I have made the following attempt (I won't put every detail, but if necessary, I will edit the question). I consider $\Gamma_{R,\varepsilon}$ as the following path: and consider computing $\int_\Gamma \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx$ : \begin{equation}
\begin{aligned}
2\pi i\operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right) & = \lim_{\substack{R\to\infty \\ \varepsilon\to0^+}}\int_\Gamma \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx = \int_0^\infty \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx - \int_0^\infty \frac{(\log(x)+2\pi i)^2}{\sqrt{x}(x+1)} = \\
& = \int_0^\infty \frac{\log^2(x)-\log^2(x)-4\pi i \log(x) + 4\pi^2}{\sqrt x(x+1)}\ dx = \int_0^\infty \frac{-4\pi i \log(x) + 4\pi^2}{\sqrt x(x+1)}\ dx
\end{aligned}
\end{equation} Therefore, \begin{equation}
\begin{aligned}
\int_0^\infty \frac{\log(x)}{\sqrt{x}(x+1)} \ dx & = -\frac{1}{4\pi i}\left( 2\pi i\operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right) - \int_0^\infty \frac{4\pi^2}{\sqrt{x}(x+1)\ dx} \right) \\
& = -\frac 12 \operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right)-\pi i\int_0^\infty \frac{1}{\sqrt{x}(x+1)}\ dx = \\
& = \frac 12 \pi^2i - \pi^2i = -\frac 12\pi^2i
\end{aligned}
\end{equation} If I compute the original integral in a calculator, the result is $0$ . Could anyone please help me out telling me what is wrong with my reasoning?","['complex-analysis', 'residue-calculus', 'improper-integrals']"
4220731,Find an element of order $p$ in a non-abelian group $G$ of order $p^3$ where $p$ is an odd prime,"Problem. Let $p$ be an odd prime and $G$ be a non-abelian group of order $p^3$ . Suppose there exists an element $x\in G$ of order $p^2$ . Find an element $y\in G\setminus\langle x\rangle$ of order $p$ . It is true, by Cauchy's theorem or some other theorems, that $G$ has an element of order $p$ . However, we are not sure whether it lies in $\langle x\rangle$ because $x^p,x^{2p},\ldots,x^{(p-1)p}$ all have order $p$ . I tried another approach: The number of element in $G$ of order $p^2$ must be a power of $$\varphi(p^2)=p(p-1),$$ where $\varphi$ is the Euler's totient function. There are $p^3-1$ non-identity elements in $G$ . We have $$p^3-1=p(p-1)(p+1)+p-1=(p+1)\varphi(p^2)+p-1.$$ This also implies that $G$ has an element of order $p$ , but the remainder $p-1$ is problematic as we already have $p-1$ elements of order $p$ above. Does anyone have good ideas on this question?","['group-theory', 'abstract-algebra', 'finite-groups']"
4220735,relatively prime solutions of $\phi(x)+\phi(y)=\phi(x+y)$,"Let $\phi$ denote Euler's totient. A problem from a book I red required to prove that the equation $\phi(x)+\phi(y)=\phi(x+y)$ has infinitely many solutions. I solved it: Let's take $x=p$ and $y=2p$ , where $p\ge 5$ is prime; easy to check. Later I started looking for a solution with $\gcd(x,y)=1$ , I wrote a program in C that checked many small numbers and gave thousands of examples, but I was unable to spot one particular infinite sequence among them. How can we prove that the equation has infinitely many relatively prime solutions ? Here is a particular result from the program I wrote, all relatively prime solutions with $1\le x<y<100$ : $(1,2),
(4,5),
(5,16),
(6,19),
(7,38),
(8,17),
(8,77),
(11,16),
(13,14),
(13,20),
(16,35),
(24,41),
(24,53),
(25,26),
(25,32),
(26,29),
(28,37),
(28,65),
(29,40),
(29,64),
(30,89),
(31,86),
(32,55),
(36,89),
(36,97),
(37,50),
(37,56),
(38,47),
(44,85),
(44,89),
(46,79),
(48,97),
(49,62),
(50,91),
(52,77),
(53,88),
(55,92),
(56,89),
(61,80),
(62,83),
(64,77),
(64,95),
(68,91),
(76,77),
(78,97).$","['number-theory', 'totient-function', 'elementary-number-theory']"
4220742,The coordinate axes are not regularly imbedded in $\mathbb{A}_k^3$,"Exercise 12.1.F of Ravi Vakil's notes asks to prove that the scheme, $X$ , which is the union of the coordinate axes in $\mathbb{A}_k^3$ is not regularly imbedded in $\mathbb{A}_k^3$ .  The first part of the exercise asks to prove that the ideal cutting out X, $$I:=(xy, yz, xz),$$ is not generated by fewer than 3 elements. Let's assume we've already proved that. How then do we proceed? It is clear that $I$ itself is not generated by a regular sequence, else, by the first part of the exercise, such a sequence has length at least 3, and so the irreducible components of $I$ (which are lines) would have dimension zero.  But in the notes, regularity is defined locally: $\pi: X\rightarrow Y$ is a regular imbedding if, for every $p\in X$ ,  the kernel of $\mathscr{O}_{Y,\pi(p)}\to\mathscr{O}_{X,p}$ is generated by a regular sequence.  Now I do know that if $\pi$ is regular at $p$ , then there exists an affine neighborhood $\operatorname{spec} B$ of $\pi(p)$ with $\pi^{-1}(\operatorname{spec} B) = \operatorname{spec} A$ such that the kernel of $B\to A$ is generated by a regular sequence.  But I don't know whether if $Y$ ( $= \operatorname{spec} k[x,y,z]$ ) is affine, that I can ""glue"" all those regular sequences together to get a regular sequence for $I$ .","['algebraic-geometry', 'schemes']"
4220762,on the equation $\sigma(n+1)=\sigma(n)+1$,"Let $\sigma(k)$ denote the sum of all positive divisors of $k$ . Consider the equation $\sigma(n+1)=\sigma(n)+1$ . Has it been investigated before? (I did some search in books avaliable for me, and in the internet, didn't found) Does it have a solution except $n=2$ ? I checked up to $10^7$ , there are no other solutions in this interval.","['number-theory', 'divisor-sum', 'elementary-number-theory', 'reference-request']"
4220767,Evaluating $\int (1-2x^2y^2)e^{-x^2y^2}dx$,"I have the following integral, $$\int (1-2x^2y^2)e^{-x^2y^2}dx$$ It seems expanding the integrand and separating the integral is not a good idea since $\int e^{-x^2}dx$ has no elementary solution based on this post . I'm not sure how to proceed evaluating this integral. I know the answer is $xe^{-x^2y^2}+C$ and I checked it by taking derivative  ( moving backward) hoping some idea comes to my mind. But I'm not sure which integral technique should I use to get this result.","['integration', 'multivariable-calculus']"
4220771,"If an integral operator $T : L^p(\Bbb{R}) \to L^q(\Bbb{R})$ is well-defined, it is bounded","Let $p,q \in [1,+\infty\rangle$ and let $K : \Bbb{R}^2 \to \Bbb{R}$ be a measurable function such that the linear map $T : L^p(\Bbb{R}) \to L^q(\Bbb{R})$ given by $$(Tf)(x) = \int_{\Bbb{R}} K(x,y)f(y)\,dy, \quad \text{for a.e. $x \in \Bbb{R}$ and $f \in L^p(\Bbb{R})$}$$ is well-defined. Can we conclude that $T$ is bounded? My attempt: We shall use the Closed Graph Theorem to show that $T$ is bounded. Since $T$ is well-defined, for every $f \in L^p(\Bbb{R})$ the function $Tf$ is a well-defined $L^q(\Bbb{R})$ function which is equal to the above integral for a.e. $x \in \Bbb{R}$ . In particular, the integral $\int_{\Bbb{R}} K(x,\cdot)f(\cdot)$ exists for a.e. $x \in \Bbb{R}$ . We can conclude that for every $f \in L^p(\Bbb{R})$ there exists a set $N_f \subseteq \Bbb{R}$ of measure zero such that for all $x \in \Bbb{R}\setminus N_f$ holds $K(x,\cdot)f(\cdot) \in L^1(\Bbb{R})$ . Here comes the unclear part. Can we say that there exists a ""global"" set $N \subseteq \Bbb{R}$ measure zero such that for every $x \in \Bbb{R}\setminus N$ we have $$K(x,\cdot)f(\cdot) \in L^1(\Bbb{R}),\quad \text{ for all }f \in L^1(\Bbb{R})?$$ If so, we can proceed as in this answer : For all $x \in \Bbb{R}\setminus N$ we define a linear map $A_x : L^p(\Bbb{R}) \to L^1(\Bbb{R})$ as $A_x(f) := K(x,\cdot)f(\cdot)$ . It is easy to show that $A_x$ is bounded by the Closed Graph Theorem. Now for all $x \in \Bbb{R}\setminus N$ we define the linear functional $l_x : L^p(\Bbb{R}) \to \Bbb{C}$ as $$l_x(f) := \int_{\Bbb{R}} K(x,\cdot)f(\cdot) = \int_{\Bbb{R}} A_x(f) = (Tf)(x), \quad f\in L^p(\Bbb{R})$$ Since $A_x$ is bounded, $l_x$ is bounded as well. Now assume $f_n \xrightarrow{L^p} 0$ and $Tf_n \xrightarrow{L^q} f \in L^q(\Bbb{R})$ and we wish to show that $f = 0$ . Since $l_x$ is continuous for all $x \in \Bbb{R}\setminus N$ , for all such $x$ we have $$(Tf_n)(x) = l_x(f_n) \xrightarrow{n\to\infty} l_x(0) = 0$$ and hence $Tf_n \xrightarrow{\mathrm{a.e.}} 0$ . From $Tf_n \xrightarrow{L^q} f$ by passing to a subsequence we conclude $f = 0$ . Hence, $T$ is bounded by CGT. So basically, my question boils down to the fact whether the quantifiers ""for every"" and ""for almost every"" commute. Are the statements $$(\text{for every } f \in L^p(\Bbb{R}))(\text{for a.e. }x \in \Bbb{R}) \quad K(x,\cdot)f(\cdot)\in L^1(\Bbb{R})$$ $$(\text{for a.e. }x \in \Bbb{R})(\text{for every } f \in L^p(\Bbb{R})) \quad K(x,\cdot)f(\cdot)\in L^1(\Bbb{R})$$ equivalent?","['measure-theory', 'lp-spaces', 'functional-analysis', 'real-analysis']"
4220774,"What is the slope of $x^3+y^3 = 9$ at $(2,1)$?","The question is (verbatim): What is the slope of $x^3+y^3 = 9$ at $(2,1)$ Secondly, I am confused about how the differentiating carries out. If I differentiate both sides with respect to $x$ , I get $$
3x^2 + 3y^2 \frac{dy}{dx} = 0 \implies \frac{dy}{dx} = -x^2/y^2 = -4
$$ But if I try to rearrange the given equation first to get $y$ on the LHS, I get $$
x^3+y^3 = 9 \\
y^3 = 9 - x^3 \\
y = (9 - x^3)^{1/3} \\
\frac{dy}{dx} = 1/3 * (9 - x^3)^{-2/3} * -3x^2 = -x^2 (9 - x^3)^{-2/3}
$$ But now this derivative no longer depends on $y$ . What is the issue with the second approach?","['calculus', 'derivatives']"
4220842,"Does $r(x) >0$ almost everywhere imply $r(x) > 1/k > 0$ almost everywhere on an open set, some $k \in \mathbb{N}$?","Let $(a,b)\subseteq \mathbb{R}$ be an open interval, and suppose $r :(a,b) \to \mathbb{R}$ is Lebesgue measurable and positive almost everywhere on $(a,b)$ . Do there exist $k \in \mathbb{N}$ and $a < c < d < b$ so that $r(x) > 1/k$ for almost all $x \in (c,d)?$ Since $r$ is positive almost everywhere, by continuity of Lebesgue measure from below, we are guaranteed that $A_k = \{x \in (a,b) : r(x) > 1/k \}$ has positive Lebesgue measure for some $k$ , but it's unclear to me whether there must be an open interval $(c,d)$ such that $(c,d) \setminus A_k$ has measure zero. Hints or solutions are appreciated.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4220855,Is $(f(x) + g(x))/2$ equal to $(f(y) + g(y))/2$?,"If I have two functions $y = f(x)$ and $y = g(x)$ , and I define the mean function as $y = (f(x) + g(x))/2$ . Is this equivalent to rearranging for $x$ and determining $x = (f(y) + g(y))/2$ ? Visually, if I want to average two functions graphically (say supply and demand functions) - does my answer change depending on which axis I choose to define the dependent and independent variable?","['average', 'functions']"
4220902,nth derivative of function $f^{1/2}$,"I know the following Leibniz's rule $$(fg)^{(n)} = \sum_{k = 0}^n {n\choose k}f^{(k)}g^{(n-k)}$$ this formula can be generalized to the product of $m$ differentiable functions $f_1,f_2,\dots,f_m$ $$(f_1f_2\cdots f_m)^{(n)} = \sum_{k_1+k_2+\cdots+k_m=n} {n\choose k_1,k_2,\dots,k_m}\prod_{1\leq j\leq m} f_j^{(k_j)}$$ where $\displaystyle {n\choose k_1,k_2,\dots,k_m}=\frac{n!}{k_1!k_2!\cdots k_m!}.$ Which I have been able to prove by induction, but my question is: What happens if I want to make the nth derivative of $f^{1/2}$ ? Will it have the following form $$(f^{1/2})^{(n)}=\sum a_rf^{1/2-r_0}(f')^{r_1}(f'')^{r_2}\cdots (f^{(n)})^{r_n}\;?$$ where also $1/2=1/2-r_0+r_1+\dots+r_n$ . It is clear that I start thinking about this particular case and then generalize to an $f^{m/n}$ .","['functions', 'derivatives', 'real-analysis']"
4220935,Show that $f_n(x) = x^n$ defines a sequence of equicontinuous functions...,"Show that $f_n(x) = x^n$ defines a sequence of equicontinuous  functions on the interval (0, 1) that does not admit a subsequence that converges uniformly on (0, 1). Definitions Let E be a set formed by real functions defined in $X\subseteq R$ . We say that E is equicontinuous in $x_0 \in X$ if: Given $\epsilon \gt 0$ , $\exists \delta \ge 0$ such that $x \in X, |x-x_0| \lt \delta$ . $|f(x)-f(x_0)| \lt \epsilon$ , $\forall f \in E$ We say that E is equicontinuous if E is equicontinuous throughout $x_0 \in E$ .
A sequence $f_n x \to R$ is equicontinuous in $x_0$ if $E=$ { $fn: n \in N$ } is equicontinuous in $x_0$ : Given $\epsilon$ , $\exists \delta$ such that $x \in X$ , $|x-x_0 |\lt \delta$ . $|f_n(x)-f_n(x_0)| \gt \epsilon$ , $\forall n$ I can't think how to do this exercise. The sequence doesn't converge, right? When n goes to zero the sequence goes to 1 and when n goes to 1 the sequence goes to x, I don't think I understand. Can someone help me, thanks!","['equicontinuity', 'sequences-and-series', 'uniform-convergence', 'real-analysis']"
4220967,Uniqueness of Semidirect Product $(\mathbb{F}_p\times\mathbb{F}_p)\rtimes\mathbb{F}_p$,"Let $p$ be an odd prime. For a non-abelian group $G$ of order $p^3$ in which no element is of order $p^2$ , it is isomorphic to a semidirect product $$(\mathbb{F}_p\times\mathbb{F}_p)\rtimes\mathbb{F}_p.$$ Here I am trying to see if such semidirect product is unique up to isomorphism. Note that $$\operatorname{Aut}(\mathbb{F}_p\times\mathbb{F}_p)\cong\operatorname{GL}(2,\mathbb{F}_p),$$ so for convenience, we shall consider a nontrivial group homomorphism $\phi:\mathbb{F}_p\to\operatorname{GL}(2,\mathbb{F}_p)$ . Since $\phi$ is nontrivial, it must be injective in this case, so $\phi(1)=:A$ is of order $p$ . It has been shown from this post that $A$ has Jordan canonical form $J:=J_2(1)=\begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}$ . That is, $A=BJB^{-1}$ for some $B\in\operatorname{GL}(2,\mathbb{F}_p)$ . Now let $\psi:\mathbb{F}_p\to\operatorname{GL}(2,\mathbb{F}_p)$ be another nontrivial group homomorphism. Then $\psi(1)=CJC^{-1}$ for some $C\in\operatorname{GL}(2,\mathbb{F}_p)$ . By the following theorem: Theorem. Let $H$ and $K$ be two groups and $\phi,\psi:K\to\operatorname{Aut}(H)$ be group homomorphisms. If $\psi=\phi\circ f$ for some $f\in\operatorname{Aut}(K)$ , then $$H\rtimes_\phi K\cong H\rtimes_\psi K.$$ it suffices to find some $f\in\operatorname{Aut}(\mathbb{F}_p)$ such that $\psi=\phi\circ f$ . Suppose $f(1)=k$ . Then $$(\phi\circ f)(1)=\phi(f(1))=\phi(k)=\phi(1)^k=(BJB^{-1})^k=BJ^kB^{-1}.$$ If $\psi=\phi\circ f$ , then we shall have $$CJC^{-1}=\psi(1)=(\phi\circ f)(1)=BJ^kB^{-1}\implies (B^{-1}C)J=J^k(B^{-1}C).$$ Let $S:=B^{-1}C=\begin{bmatrix} a & b \\ c & d \end{bmatrix}$ . It follows that $$\begin{bmatrix} 
        a & a+b \\ c & c+d 
    \end{bmatrix}=\begin{bmatrix} 
        a & b \\ c & d 
    \end{bmatrix}\begin{bmatrix} 
        1 & 1 \\ 0 & 1 
    \end{bmatrix}=SJ=J^kS=\begin{bmatrix} 
        1 & k \\ 0 & 1 
    \end{bmatrix}\begin{bmatrix} 
        a & b \\ c & d 
    \end{bmatrix}=\begin{bmatrix} 
        a+kc & b+kd \\ c & d 
    \end{bmatrix}.$$ Then we have $c=0$ and $a=kd$ , which are not necessarily satisfied since $B$ and $C$ are arbitrary. Then I got stuck with this step. I'd appreciate it if anyone has good ideas on this.","['semidirect-product', 'group-theory', 'abstract-algebra', 'finite-groups']"
4220987,Area of Shaded Region Concentric Circles,"I have been asked to show that the shaded area of to concentric circles, one of radii $B$ (the smaller one) and the other of radii $A+B$ (the larger) is $\pi(A-B)(A+B)$ . What I have tried $\pi R^{2}-\pi r^{2}=a$ (this is the area of the shaded area) $\pi(A+B)^{2}-\pi B^{2}=a$ $\pi[(A+B)^{2}-B^{2}]=a$ $\pi(A^{2}+2AB+B^{2}-B^{2})=a$ $\pi(A^{2}+2AB)=a$ $\pi(A(A+2B))=a$ But I dont get how to reach the proposed expression. UPDATE The radii is wrong the correct is not $A+B$ , instead it is radii $A$ the larger one and $B$ the small.","['algebra-precalculus', 'circles']"
4221017,Using first principles find derivative of ln(sec(x)),"The question is to use first principles only. Thus I started with the same and got $$
y = \ln(\sec(x))
$$ $$
\frac{dy}{dx} = \lim_{h\to 0} \frac{\ln(\sec(x+h)) - \ln(\sec(x))}{h}
$$ after this I do not understand how do I eliminate the $h$ in the denominator. I tried to implement $\ln(A) - \ln(B) = \ln\bigl(\frac{A}{B}\bigr)$ which ultimately led to $$
\frac{dy}{dx} = \lim_{h\to 0} \frac{\ln\bigl(\frac{\sec(x+h)}{\sec(x)}\bigr)}{h}
$$ here I converted $\sec()$ to $\cos()$ $$
\frac{dy}{dx} = \lim_{h\to 0} \frac{\ln\bigl(\frac{\cos(x)}{\cos(x+h)}\bigr)}{h}
$$ Still I cannot proceed further.","['limits', 'calculus', 'derivatives']"
4221048,Prove that a non-decreasing function has zero derivative,"Let $f : \mathbb{R} \to \mathbb{R}$ be a non-decreasing function (i.e., $x \leq y \implies f(x) \leq f(y)$ ). Suppose at a point $a \in \mathbb{R}$ , there exists a sequence of positive numbers $\{x_n\}$ such that $x_n \to 0$ and $$
\lim_{n\to \infty} \frac{f(a + x_n) - f(a - x_n)}{x_n} = 0.
$$ I would like to prove (or find a counterexample) that $f$ is differentiable at $a$ and $f'(a) = 0$ . In particular, I'm trying to show that $$
\lim_{x \to 0} \frac{f(a + x) - f(a - x)}{x} = 0.
$$ If I pick an arbitrary $x > 0$ so that $x_n \leq x < x_m$ for some $n, m \geq 1$ , I can get the bound $$
\frac{f(a + x) - f(a - x)}{x} \leq \frac{f(a + x_m) - f(a - x_m)}{x_n}
\leq \frac{f(a + x_m) - f(a - x_m)}{x_m} \cdot \frac{x_m}{x_n}.
$$ The problem is that $x_m / x_n$ may be large if, for instance, $\{x_n\}$ converges to $0$ too rapidly. Does anyone know how I might be able to proceed?","['limits', 'derivatives', 'real-analysis']"
4221077,How can I arrange coloured triangles in hexagons so that they dont touch each other?,"Based on the fact that: There are 120 non-cyclical permutations of {1,2,3,4,5,6} Each permutation could be represented by a hexagon with 6 triangles of different colours; e.g., Is it possible to write a formula or algorithm (function) to arrange (in a tessellation) these 120 hexagons in such a way that each triangle of colour is completely separated from its own colour i.e. it is surrounded by 12 triangles of colours that are not it's own colour. e.g., like this: So that the result would be 720 Triangles composing 120 hexagons with unique non-cyclical permutations where no triangle touches (either at the point or at the side) a triangle of the same colour. To clarify - If one colouring is a rotation of another then it is not part of the 120 permutations that are permitted to compose the final pattern in which all unique permutations of colours are allowed to be used and should be used only once. Can the above pattern be generated ad infinitum?
Can we frame this in terms of colouring a 12 regular infinate graph?","['permutations', 'triangles', 'combinatorial-geometry', 'geometry']"
4221079,Is it possible to change $x^3\prod_{n=1}^{\infty}\left(1-\frac{x^4} {2\pi^2n^2}-\frac{x^6}{2\pi^3n^3}\right)$ to equal $x\sin{(x^2)}$?,"Consider a function $$f(x)=x^3\prod_{n=1}^{\infty}\left(1-\frac{x^4} {2\pi^2n^2}-\frac{x^6}{2\pi^3n^3}\right)$$ This function has its zeros when $x=0$ or $x^2=k\pi$ . This function is very similar to another function which is $$g(x)=x\sin{(x^2)}$$ . They have the same zeros and just that their increasing speed is different.
Is it possible to make some changes such that they are equal? One seems to be increasing and one is decreasing. Also, they are the functions that appears to have the exponential function $\frac 1 {x^3}$ .","['trigonometry', 'functions']"
4221106,Integration using inverse function,"If $3f\left( x \right) = 3 {x^4} + {x^3} + 3{x^2}$ and $\mathop {\lim }\limits_{a \to \infty } \int\limits_{2a}^{8a} {\frac{1}{{{{\left( {{f^{ - 1}}\left( x \right)} \right)}^2} + {{\left( {{f^{ - 1}}\left( x \right)} \right)}^4}}}dx}  = \ln(n)$ , find the value of $n$ . My approach is as follow , I tried to get the value of $f^{-1}(x)$ by putting a separate question in Maths-type Inverse of a quartic function but it has been closed so I am putting the original question. I cross checked it. Iam not able to approach it.",['functions']
4221123,"Prove that if sin$A < \frac ab$ and $a > b$, then $\angle B$ is acute.","Given $\triangle ABC$ , $a > b$ and $\angle A$ with the property that sin $A < \frac ab$ . How do I prove that $\angle B$ is an acute angle? I'm  trying to use this and proof that a triangle with this particular property isn't included in the ambiguous case of the sine law. I'd really appreciate any help.","['euclidean-geometry', 'trigonometry', 'geometry']"
4221137,What is the possible number of unique google meet codes?,"This is a sample google meet code: kgk-imsy-era Any idea how many such unique codes can be there? Given that a particular letter in the code may or may not repeat. If it repeats, we do not know how may times it'll repeat. Is it something like $$^{10}C_{x} \cdot 26^{x} \cdot ^{25}P_{(10-x)} + ^{26}P_{10}$$ where, x = number of times a particular letter is repeated Few points to note: The codes are always composed of 10 letters (and no numbers) The codes are case-insensitive The hyphens in between are just used to separate the letters and are not a part of the code Thanks!","['permutations', 'combinations', 'combinatorics']"
4221189,Does a differentiable function exist with $f'(0)=0$ but $f'(x_n) \to \infty$ as $x_n \to 0$,"Does a differentiable function $f:\mathbb{R}\to\mathbb{R}$ exist with $f'(0)=0$ where there is a sequence $x_n \to 0$ and $f'(x_n) \to \infty$ ? My first thought was to work with the function $f(x) = x^2\sin(1/x)$ if $x \neq 0$ and $f(x) = 0$ if $x = 0$ . This function is differentiable with derivative $f'(x) = 2x\sin(1/x) - \cos(1/x)$ if $x \neq 0$ and $f'(0) = 0$ if $x = 0$ . My issue now lies with constructing the necessary sequence. Is my thinking correct so far? Can someone help with constructing the sequence if it is possible, or show me where I went wrong in the case that it isn't possible?","['derivatives', 'functions', 'sequences-and-series', 'real-analysis']"
4221248,Tangent space of the normal bundle,"Let $M$ be a manifold endowed with a connection $\nabla$ . Let $M_0$ be a submanifold of $M$ , we denote by $N$ the normal bundle of $M_0$ . The following paragraph is from the book: Heat kernels and Dirac operators (page 217) By orthogonal projection, the Levi-Civita connection $\nabla$ gives a connection $\nabla^N$ on the normal bundle $N$ which is compatible with the induced metric.
Identifying $M_0$ with the zero section of $N$ , we obtain a canonical isomorphism $$TN_{|M_0} \cong TM_{|M_0}$$ How to prove that there's an isomorphism between the bundles $TN_{|M_0}$ and $TM_{|M_0}$ ?",['differential-geometry']
4221251,"Clarification on notation regarding fields, forms, and exterior algebra","Sorry if I've missed something quite obvious, but I can't seem to find a clear source for notation. $\Omega^p(T^*M)$ is the common notation I've seen for the space of $p$ -forms on the cotangent bundle $T^*M$ . Is $\Omega^p(T^*M)=\bigwedge^p(T^*M)$ a correct statement, or is there some other step I'm missing (where $\bigwedge(\cdot)$ is the exterior algebra)? What does $\Gamma(\cdot)$ mean when applied to one of these spaces (e.g., $\Gamma\bigwedge^p(T^*M)$ )? I've seen it mean 'all the fields on the space', but this doesn't seem consistent everywhere, and feels somewhat vague. What space does an $(n,m)$ -rank tensor belong to? Is it the direct sum $\bigwedge^n(TM)\oplus\bigwedge^m(T^*M)$ ? Thank you for your time, and again, sorry if this is made obvious in some text, I've not seen it.","['differential-geometry', 'tensors', 'definition', 'differential-forms', 'exterior-algebra']"
4221252,A twist to the definition of a derivative,"Two questions: Functions are connections between numbers. Derivatives are connections between functions. So is there something like connections between derivatives? What function does the following limit yield: $$\lim_{x \rightarrow a}  \frac{ f' (x)- f' (a)}{f(x)-f(a)}$$ (for example if we plug in $\sin(x),$ then we get $- \tan(x),$ and if we plug in $x^{2},$ then we get $\frac{1}{x} $ )","['definition', 'derivatives']"
4221373,Selecting a suitable Lyapunov function for the following systems to analyse global stability?,"SECOND BOUNTY! i) SI MODEL Consider \begin{align}
\frac{dS}{dt} &= \mu N -\frac{\beta S I}{N} - \nu S\\[2ex]
\frac{dI}{dt} &= \frac{\beta S I}{N} -\nu I
\end{align} Where $N=S+I$ is the total population. If we assume $\mu =\nu$ , the above reduces to: \begin{align}
\frac{dS}{dt} &= -\beta S I + \nu I\\[2ex]
\frac{dI}{dt} &= \beta S I -\nu I
\end{align} The equilibrium points: \begin{align*}
e_1 : \left( S_1^*, I_1^*\right)&= \left(1, 0\right), \\[2ex]
e_2 : \left( S_2^*, I_2^*\right)&= \left(\frac{\nu }{\beta}, \frac{\nu}{\beta}\left(\frac{\beta}{\nu}-1 \right)\right)
\end{align*} where $\mathcal{R}_0 = \beta/\nu$ . The set $\Omega = \left\lbrace \left(S,I\right)\in \mathbb{R}_+^2 : S\geq 0, I \geq 0, S+I \leq 1  \right\rbrace$ is our domain of definition. This set is a positively invariant set for our system. Now to prove the global (asymptotically) stability of $e_1$ is straightforward, we use the function $V = I$ and the result follows. Now my question is, how would I construct a Lyapunov function for $e_2$ ? I know it should be in the form of a Volterra function but, how can I choose a parricular one? any ideas? ii) SIS MODEL Consider \begin{align}
\frac{dS}{dt} &= \mu N -\frac{\beta S I}{N}+ \gamma I - \nu S\\[2ex]
\frac{dI}{dt} &= \frac{\beta S I}{N} -(\gamma+\nu) I
\end{align} Where $N=S+I$ is the total population. If we assume $\mu =\nu$ , the above reduces to: \begin{align}
\frac{dS}{dt} &= -\beta S I + (\gamma +\nu) I\\[2ex]
\frac{dI}{dt} &= \beta S I -(\gamma+\nu) I
\end{align} The equilibrium points: \begin{align*}
e_1 : \left( S_1^*, I_1^*\right)&= \left(1, 0\right), \\[2ex]
e_2 : \left( S_2^*, I_2^*\right)&= \left(\frac{\left(\gamma+\nu\right)}{\beta}, \frac{\left(\gamma+\nu\right)}{\beta}\left(\frac{\beta}{\gamma+\nu} -1\right)\right),
\end{align*} where $\mathcal{R}_0 = \beta/(\gamma+\nu)$ . Again, as in case (i) we have the set $\Omega = \left\lbrace \left(S,I\right)\in \mathbb{R}_+^2 : S\geq 0, I \geq 0, S+I \leq 1  \right\rbrace$ as our domain of definition. This set is a positively invariant set for our system. Analogously as earlier, to prove the global (asymptotically) stability of $e_1$ is straightforward, we use the function $V = I$ and the result follows. How would I chose a suitable Lyapunov function for this model to analyse the endemic equilibrium $e_2$ ? Well, if we find a suitable Lyapunov function for case (i) then we can just replace $\nu$ with $\gamma+\nu$ for this system. iii) SIR MODEL Consider \begin{align}
\frac{dS}{dt} &= \mu N -\frac{\beta S I}{N} - \nu S\\[2ex]
\frac{dI}{dt} &= \frac{\beta S I}{N} -(\gamma+\nu) I\\[2ex]
\frac{dR}{dt} &= \gamma I -\nu R
\end{align} Where $N=S+I+R$ is the total population. If we assume $\mu =\nu$ , the above reduces to: \begin{align}
\frac{dS}{dt} &= -\beta S I + \nu I +\nu R \\[2ex]
\frac{dI}{dt} &= \beta S I -(\gamma +\nu) I\\[2ex]
\frac{dR}{dt} &= \gamma I -\nu R -\xi R
\end{align} Using $R=N-S-I$ to kill degeneracy, this further reduces to \begin{align}
\frac{dS}{dt} &= -\beta S I + \nu  -\nu S \\[2ex]
\frac{dI}{dt} &= \beta S I -(\gamma +\nu) I\\[2ex]
\end{align} The equilibrium points read \begin{align*}
e_1 : \left( S_1^*, I_1^*, R_1^*\right)&= \left(1, 0, 0\right), \\[2ex]
e_2 : \left( S_2^*, I_2^*, R_2^*\right)&= \left(\frac{\left(\gamma+\nu\right)}{\beta}, \frac{\nu}{\beta}\left(\frac{\beta}{\gamma +\nu}-1\right), \frac{\gamma}{\beta}\left(\frac{\beta}{\gamma +\nu}-1\right)\right)\\[1ex]
\end{align*} where $\mathcal{R}_0 = \beta/(\gamma+\nu)$ . Again, as in case (i) and (ii) we have the set $\Omega = \left\lbrace \left(S,I\right)\in \mathbb{R}_+^2 : S\geq 0, I \geq 0, S+I \leq 1  \right\rbrace$ as our domain of definition. This set is a positively invariant set for our system. Theorem If $\mathcal{R}_0 \leq 1$ , then the disease-free equilibrium $e_1$ is globally asymptotically stable in $\Omega$ . Proof We use the function $V = I$ and the result follows. Theorem If $\mathcal{R}_0 > 1$ , then the endemic equilibrium $e_2$ is globally asymptotically stable in the interior of $\Omega$ . Proof To prove the global asymptotically stability for $e_2$ , consider the Lyapunov function (in the form of a Volterra function): $$V(S,I) = \left(S-S_2^*\right)+ \left( I-I_2^*\right) -S_2^* \ln \frac{S}{S_2^*} - I_2^* \ln \frac{I}{I_2^*}. $$ working out the time derivatives along our reduced system, we arrive to: $$\dot V = -\beta (S_2^* -S)^2 [\frac{1}{S}] \leq 0 $$ We see $\dot V$ is negative except when $\dot V$ takes on the equilibrium values so that $\dot V =0$ , so we have semi-definiteness. The largest compact invariant set in $\Omega$ so that $\dot V$ is $0$ is the singleton $\lbrace{ e_2\rbrace}$ . Hence, concluding from LaSalle's invariance principle, $e_2$ is globally asymptotically stable in $\Omega$ . iv) SIRS MODEL Consider \begin{align}
\frac{dS}{dt} &= \mu N -\frac{\beta S I}{N} +\xi R - \nu S\\[2ex]
\frac{dI}{dt} &= \frac{\beta S I}{N} -(\gamma+\nu) I\\[2ex]
\frac{dR}{dt} &= \gamma I-\xi R -\nu R
\end{align} Where $N=S+I+R$ is the total population. If we assume $\mu =\nu$ , the above reduces to: \begin{align}
\frac{dS}{dt} &= -\beta S I + \nu I +(\xi+\nu) R \\[2ex]
\frac{dI}{dt} &= \beta S I -(\gamma +\nu) I \\[2ex]
\frac{dR}{dt} &= \gamma I -(\xi +\nu) R
\end{align} with equilibrium points: \begin{align*}
e_1 : \left( S_1^*, I_1^*, R_1^*\right)&= \left(1, 0, 0\right), \\[2ex]
e_2 : \left( S_2^*, I_2^*, R_2^*\right)&= \left(\frac{\left(\gamma + \nu\right)}{\beta}, \frac{\left(\gamma+\nu \right) \left( \xi + \nu \right) \left( \frac{\beta}{\gamma+\nu} -1 \right) }{\beta\left(\gamma + \xi+\nu \right)}, \frac{\gamma \left(\gamma+\nu \right)\left( \frac{\beta}{\gamma+\nu} -1 \right) }{\beta\left(\gamma + \xi+\nu \right)}\right)
\end{align*} So my question(s) are; how do I find suitable Lyapunov functions for systems (i), (ii) and (iv) similar to my example in (iii)? Can you also show the full solution to systems (i), (ii) and (iv) like how I presented in (iii)? This will be appreciated! EDIT As per Hans comments for (i): By substituting $S=N-I$ into (2.4) we have \begin{align}
\frac{dI}{dt} &= (\beta - \nu)I - \beta I^2
\end{align} Solving (2.5) with initial condition $I(0)= I_0$ analytically, we have the solution to the system: \begin{align}
I(t) &= \frac{I_0 (\beta - \nu)}{\beta I_0 - e^{-\left(\beta - \nu\right)t} \left[ \beta I_0 - \left(\beta - \nu\right)\right]}.\\[2ex]
S(t) &= 1-I(t).
\end{align} We can make inferences of the long term behaviour of this model by examining the possible values of $\left(\beta -\nu\right)$ , that is, of course when (2.6) is feasible. We have two cases \begin{align*}
\beta - \nu & < 0 \\[2ex]
\beta - \nu & > 0
\end{align*} If $\beta - \nu < 0$ , then $e^{-\left(\beta - \nu\right)t} \rightarrow \infty \text{ as } t \rightarrow \infty$ hence \begin{align}
\lim_{t \to \infty} I(t) = 0.
\end{align} If $\beta - \nu > 0$ , then $e^{-\left(\beta - \nu\right)t} \rightarrow 0 \text{ as } t \rightarrow \infty$ hence we have the limit \begin{align}
\lim_{t \to \infty} I(t) = \frac{I_0\left(\beta-\nu\right)}{\beta I_0} = 1-\frac{\nu}{\beta}.
\end{align} $R_0 \leq 1$ : $R_0 >1$ : For (ii): Analogously as in section 2.1, we obtain the complete solution to our system: \begin{align}
I(t) &= \frac{I_0 (\beta - \gamma-\nu)}{\beta I_0 - e^{-\left(\beta - \gamma -\nu\right)t} \left[ \beta I_0 - \left(\beta -\gamma - \nu\right)\right]}.\\[2ex]
S(t) &= 1-I(t).
\end{align} As before, we make inferences of the long term behaviour of this model by examining the possible values of $\left(\beta -\gamma -\nu\right)$ , that is, of course when (2.14) is feasible. We have two cases \begin{align*}
\beta - \gamma-\nu & < 0 \\[2ex]
\beta - \gamma -\nu & > 0
\end{align*} If $\beta - \gamma-\nu < 0$ , then $e^{-\left(\beta - \gamma -\nu\right)t} \rightarrow \infty \text{ as } t \rightarrow \infty$ hence \begin{align}
\lim_{t \to \infty} I(t) = 0.
\end{align} If $\beta - \gamma -\nu > 0$ , then $e^{-\left(\beta - \gamma -\nu\right)t} \rightarrow 0 \text{ as } t \rightarrow \infty$ hence we have the limit \begin{align}
\lim_{t \to \infty} I(t) = \frac{I_0\left(\beta-\gamma -\nu\right)}{\beta I_0} = 1-\frac{\gamma+\nu}{\beta}.
\end{align} $R_0 \leq 1$ : $R_0 >1$ : Ignore the wrong equation tags.. But I'm not sure whether this edit is proving global stability for models (i) and (ii)..","['ordinary-differential-equations', 'lyapunov-functions', 'stability-in-odes', 'stability-theory', 'dynamical-systems']"
4221529,Measurability of random eigenvectors and random eigenvalues,"Let $A$ be an $n\times n$ real symmetric random matrix. Then $A$ has a spectral decomposition $A=Q\Lambda Q'$ with $Q$ orthogonal and $\Lambda$ diagonal. Am trying to show that
we can choose $Q$ and $\Lambda$ to be random matrices, i.e. to have measurable entries. Let $M_n$ denote the space $n\times n$ real matrices, and let $S_n$ denote the subspace of symmetric matrices in $M_n$ . I endow $M_n$ with the Frobenius norm and the corresponding metric topology. I will use the following principle of measurable choice proven here : Theorem. Let $X,Y$ be complete separable metric spaces and $E$ a closed $\sigma$ -compact subset of $X\times Y$ . Then $\pi_1(E)$ is a Borel set in $X$ and there exists a Borel function $\varphi:\pi_1(E)\to Y$ whose graph is contained in $E$ . (Here $\pi_1$ denotes the projection of $X\times Y$ on $X$ ). Let $X=M_n$ , $Y=M_n\times M_n$ and $$E=\bigg\{\big(A,Q,\Lambda\big)\in M_n\times M_n\times M_n: A \text{ is symmetric}, U \text{ is orthogonal},\Lambda \text{ is diagonal}\text{ and } A=Q\Lambda Q'  \bigg\}$$ By identification of $M_n$ and $M_n\times M_n$ with $\mathbb{R}^{n^2}$ and $\mathbb R^{2n^2}$ we see that $X,Y$ are separable complete metric spaces, and by identification of $M_n\times M_n\times M_n$ with $\mathbb R^{3n^2}$ we see that $E$ is $\sigma$ -compact. Using the sequential characterization of a closed set in a metric space and continuity of matrix multiplication we see that $E$ is closed. By the spectral theorem we have $\pi_1(E)=S_n$ . Therefore the above theorem provides us with a Borel function $\varphi:S_n\to M_n\times M_n$ whose graph is contained in $E$ , i.e. such that $\varphi_1(A)$ is orthogonal, $\varphi_2(A)$ is diagonal and $A=\varphi_1(A)\varphi_2(A)\varphi_1(A)'$ for all $A\in S_n$ . Since projections are continuous, $\varphi_1,\varphi_2:S_n\to M_n$ are also Borel measurable. $A$ being a random matrix means that each entry of $A$ is a random variable on some measure space $(\Omega,\mathcal F)$ . By identification of the measure spaces $(M_n,\mathcal B(M_n))$ and $(\mathbb{R}^{n^2},\mathcal B(\mathbb{R}^{n^2}))$ we see that $A:\Omega\to M_n$ is Borel measurable. By assumption $A$ take values in the closed subset $S_n$ of $M_n$ , and so in fact $A:\Omega\to S_n$ is Borel measurable. We conclude that the composition maps $\omega\mapsto Q(\omega):= \varphi_1(A(\omega))$ and $\omega\mapsto \Lambda(\omega):=\varphi_2(A(\omega))$ from $\Omega$ to $M_n$ are both Borel measurable and such that $A(\omega)=Q(\omega)\Lambda(\omega)Q'(\omega)$ for all $\omega\in\Omega$ . Is this proof legitimate? Thank you for your help.","['measure-theory', 'eigenvalues-eigenvectors', 'matrices', 'solution-verification', 'measurable-functions']"
4221530,Is my logic valid in showing that any two consecutive terms of the Fibonacci sequence are coprime,"Assume terms $a_n$ and $a_{n+1}$ share some common factor $x$ so that $a_n = xm$ for some integer $m$ and $a_{n+1} = xk$ for some integer $k$ . Since $a_{n-1}$ = $a_{n+1} - a_n = xk - xm = x(k-m)$ , $a_{n-1}$ is a multiple of $x$ as well. Then $a_{n-2}$ must also be a multiple of $x$ because $a_{n-2} = a_{n} - a_{n-1} = xm - (xk - xm) = x(2m-k)$ . Since each lower or upper term can be found by subtracting or adding one multiple of $x$ to another, we can say that every term in the sequence must then be a multiple of $x$ . Therefore, if any two consecutive terms share a common factor, then all terms must share a common factor. However, if $a_1=1$ we can see the counterexample of $a_3 = 2, a_4=3$ where $2$ and $3$ are consecutive terms with no common factors. Since not all terms then share a common factor, no two consecutive terms can share a common factor.","['algebra-precalculus', 'fibonacci-numbers']"
4221576,"Why and How do certain manipulations in indefinite integrals ""just work""?","I am going to take a very simple example to elaborate my question. When we integrate $\sec (x)\,dx$ we divide and multiply by $\sec (x) + \tan (x)$ . $$\int \sec(x)\,dx = \int \sec (x) \left[{\sec (x) + \tan (x) \over \sec (x) + \tan (x)}\right]\, dx$$ I am just solving from here. $$\int {\sec^2(x) + \sec(x)\tan(x) \over \sec(x) + \tan(x)} \, dx $$ Then we let $\sec(x) + \tan(x) = u$ $$\implies du = (\sec^2(x) + \sec(x)\tan(x))\,dx$$ $$\implies \int {du \over u}$$ $$= \ln{\left|\sec(x) + \tan(x)\right|} + c$$ Now coming to my questions. Why do we HAVE to make that manipulation of multiplying $\sec(x) + \tan(x)$ . Like I know its to get the answer...but why does it work so well? How to even think like that? Like ""if I multiply $\sec(x) + \tan(x)$ in the numerator and denominator then I'll be able to solve this very easily."" What in that integral gives one direction to think of such a manipulation ?","['integration', 'indefinite-integrals', 'calculus']"
4221583,Spherical trigonometry and statistics in higher dimensions,"Until recently I never properly fully assimilated the spherical laws of sines and cosines into my understanding, and thinking about those, I see some parallels with some things in statistics. Segments from the center of a sphere of unit radius to the three vertices of a triangle on the sphere meet at angles $\alpha,\beta,\gamma.$ The sides of the triangle are arcs of great circles and the two arcs at the vertex that is the endpoint of that one of the aforementioned segments that does not meet either of the others at angle $\alpha$ meet at angle $\mathbb A,$ and as $\alpha$ is related to $\mathbb A$ , so also are $\beta,\gamma$ to $\mathbb B,\mathbb C$ respectively. The spherical law of cosines then says $$
\cos\beta = \cos\alpha\cos\gamma+\sin\alpha\sin\gamma\cos\mathbb B. \tag 1
$$ Now consider vectors $x=(x_1,\ldots,x_n), y=(y_1,\ldots,y_n)\in\mathbb R^n.$ Let $\overline x=(x_1+\cdots+x_n)/n$ and similarly define $\overline y.$ Let $s_x^2=\big((x_1-\overline x)^2 + \cdots + (x_n-\overline x)^2\big)/n,\, s_x>0$ and similarly define $s_y^2.$ (Sometimes you see $n-1$ rather than $n$ in the denominator, but that won't change anything that concerns us here. It is often remarked that the correlation $\displaystyle \frac{\sum_{i=1}^n (x_i-\overline x)(y_i-\overline y) }{s_xs_y} $ is the cosine of the angle between the two unit vectors $\left( \frac{x_i-\overline x}{s_x} : i=1,\ldots,n \right)$ and $\left( \frac{y_i-\overline y}{s_y} : i=1,\ldots,n \right),$ known as the standardizations of $x$ and $y.$ Now consider a third vector $z=(z_1,\ldots,z_n)$ with $\overline z$ and $s_z$ defined similarly. Let $\alpha$ be the angle between the standardizations of $x$ and $y$ and similarly $\beta$ between $y$ and $z$ and $\gamma$ between $z$ and $x.$ And let $\mathbb C$ correspond to $\gamma$ as above. I leave it as an exercise to see that $\mathbb C$ is a certain dihedral angle and $\cos^2\mathbb C$ is the quantity that statisticians know as the coefficient of determination , which is the proportion of the variability in $z$ that is ""explained"" by the variability of $x$ and $y$ when $z$ is regressed on $x$ and $y,$ the ""unexplained"" part being the sum of squares of residuals that is minimized when regression is done be the method of ordinary least squares. A coordinate system in the $3$ -dimensional space spanned by the standardizations of $x,y,z$ may be chosen so that the standardization of $x$ becomes $\left[ \begin{array}{c} 1 \\ 0 \\ 0 \end{array} \right],$ and that of $y$ is $\left[ \begin{array}{c} \cos\alpha \\ \sin\alpha \\ 0 \end{array} \right],$ and that of $z$ is $\left[ \begin{array}{c} \cos\gamma \\ \sin\gamma\cos\mathbb B \\ \sin\gamma\sin\mathbb B \end{array} \right].$ Then the ordinary dot product between those last two vectors gives is the law of cosines of line $(1)$ above. But coefficients of determination are not used only in regressing one variable on exactly two others; they are used when one regresses one variable on $p$ others, and then they are the square of the cosine of the angle between a line corresponding to the response variable and a $p$ -dimensional space corresponding to the predictors. So can the relationship between spherical trigonometry and statistics be fruitfully extended to higher dimensions? Appendix: The total sum of squares is $\sum_{i=1}^n (z_i-\overline z)^2.$ The fitted values are $\widehat z_i = \widehat a + \widehat b x_i + \widehat c y_i$ where $\widehat a,\widehat b, \widehat c$ are the least-squares estimates. The residuals are $z_i - \widehat z_i.$ The unexplained sum of squares is the sum of squares of residuals when fitting is done by least squares: $\sum_{i=1}^n (z_i - \widehat z_i)^2$ The explained sum of squares is $\sum_{i=1}^n (\widehat z_i - \overline z)^2.$ The coefficient of determination is the proportion of variability in $z$ that is explained by $x$ and $y,$ i.e. it is $$ \frac{\text{explained sum of squares}}{\text{total sum of squares}}. $$ Exercise: The total sum of squares is the sum of the explained and unexplained sums of squares. (This can be reduced to showing that the vectors of residuals and of fitted values are mutually orthogonal.) $$ \sum_{i=1}^n (z_i-\overline z)^2 = \sum_{i=1}^n (\widehat z_i - \overline z)^2 + \sum_{i=1}^n (z_i - \widehat z_i)^2 $$","['linear-regression', 'spherical-trigonometry', 'statistics']"
4221620,Topological Concrete Categories: Axiomatizations,"I'm reading something on topological concrete categories. In every reference, given a category $\mathfrak{A}$ and an object $A$ , it is assumed to be acquainted with the its structure (and in fact the objects of $A$ are said structured sets). Now, in a paper by Dikranjan, Giuli and Tozzi (Topological Categories and Closure Operators), the following definition of a topological concrete category is given: ""a category $\mathfrak{A}$ together with a forgetful functor $U: \mathfrak{A} \longrightarrow {\bf Set}$ , such that the following conditions hold: existence of initial lift; fibre-smallness; every set of cardinality $1$ has exactly one $\mathfrak{A}$ -structure"" On the other hand, in the paper ""Topological Categories"" by Brummer, the definition of a topological concrete category is given as above, but replacing axiom 1) with existence and uniqueness of the lift, and replacing axiom 3) with the axiom 3') costant functions are lifted by $U$ . I expect that the two previous definitions of a topological concrete category are equivalent. I'm able to show that Brummer $\implies$ Dikranjan. In fact, if a set $X$ of cardinality $1$ has at least two structures, namely $(X,\mathcal{F})$ and $(X,\mathcal{G})$ , then $1_X: (X,\mathcal{F}) \longrightarrow (X,\mathcal{G})$ and $\overline{1}_X: (X,\mathcal{G}) \longrightarrow (X,\mathcal{F})$ are constant functions which agree by the uniqueness of initial lift. Concerning the converse, if I have a constant function $c: X \longrightarrow Y$ , I expect to factorize the corresponding $c: (X,\mathcal{F}) \longrightarrow (Y,\mathcal{G})$ (for each $(X,\mathcal{F}),(Y,\mathcal{G})$ ) as $(X,\mathcal{F}) \longrightarrow (\{c_X\},\mathcal{F}_{c_X}) \longrightarrow (Y,\mathcal{G})$ , where $\mathcal{F}_{c_X}$ is the only structure on $\{c_X\}$ . However, I don't know if my argument is correct. Secondly, does the existence of the initial lift imply the uniqueness of such a lift, because of the universal property defining it?","['general-topology', 'category-theory']"
4221630,Multivariable ODE with linear and quadratic terms,"Suppose $z(t):\mathbb R_+\to\mathbb R^n$ satisfies the ODE $$\frac{dz}{dt}=Az+\sum_k (C_kz)\odot(C_kz)$$ for matrices $A,C_1,\ldots,C_m\in\mathbb R^{n\times n}$ . Here $\odot$ denotes the Hadamard product. Is there any hope of writing a closed form solution for $z(t)$ ? In one dimension it seems the standard integrating factors trick works, but I’m not sure how to generalize.","['linear-algebra', 'ordinary-differential-equations']"
4221664,A property of matrix $(I-A)^{-1}$ for $A$ strictly substochastic.,"Let $A$ be a strictly substochastic matrix (i.e., nonnegative elements and row sums strictly less than one) and let $M = (I-A)^{-1}.$ Since $I-A$ is an M-matrix, I know that matrix $M$ has all nonnegative entries. Simulations also show that $m_{ii} \geq m_{ji}$ for all $i,j$ . Is that true in general? This is true in the 2x2 case, since letting $\Delta$ be the determinant of $I-A$ (which is positive), then $m_{11} = (1-a_{22}) / \Delta$ while $m_{21} = a_{21} / \Delta$ , and so $a_{21} + a_{22} < 1$ implies that $m_{11} > m_{21}$ , and similarly $m_{22} > m_{12}$ . It is also easy to show it directly in the 3x3 case. Perhaps one can show by induction, but I imagine that this is a well known result?","['matrices', 'linear-algebra']"
4221679,Why is the following recurrent sequence convergent?,"Let $a, b , c, d$ be reals. Define the sequence $(x_n)$ as: $$x_0 = a,\,\, x_1 = b$$ $$x_n = \left(1 - \frac{b^2}{n^2}\right)x_{n-1} + \frac{1}{n-1}\sum_{k=0}^{n-2}\binom{2n+1}{2k+1}^{-1} (x_{k+1}-x_k)(c\, x_{n-k-1}- d\, x_{n-k-2}),\,\,\, n \geq2.$$ I want to prove that $(x_n)$ is convergent.
Here are two examples for different values of $(a, b , c, d).$ It seems (after several numerical tests) that the sequence is bounded and monotone from specific $n_0.$ The boundness of the sequence imply that $$\sum_{k=0}^{n-2}\binom{2n+1}{2k+1}^{-1} (x_{k+1}-x_k)(c\, x_{n-k-1}- d\, x_{n-k-2})$$ is bounded and the term with the sum goes to zero. Thank you for any hint","['sequences-and-series', 'real-analysis']"
4221702,Transformation of sub-martingale and super-martingale,"Let $X=(X_k)_{k \in \mathbb{N}}$ be a $(\mathcal{F}_k)_k$ -adapted process and taking values in $\overline{\mathbb{R}}^+.$ If $X$ is super-martingale, for every $y \in \mathbb{R}^+$ is there a uniformly bounded super-martingale $(Y^y_k)_k$ such that for all $k \in \mathbb{N},\lim_{y \to +\infty} Y_k^y=X_k$ a.s. ? Repeat the question considering a sub-martingale $X.$ If $X$ is a super-martingale then the super-martingale property is preserved if we consider $Y_k^y=\min(X_k,y)$ which proves 1. since for every $k \in \mathbb{N},y \in \mathbb{R},E[Y_{k+1}^y|\mathcal{F}_k] \leq \min(E[X_{k+1}|\mathcal{F}_k],y) \leq Y_k^y$ and $Y_k^y$ is uniformly bounded by $y$ and for every $k,\lim_{y \to \infty} Y_k^y=X_k.$ Any suggestions how to deal with 2. ?","['conditional-expectation', 'stochastic-processes', 'probability-theory', 'martingales']"
4221720,Is there a relation among areas of concentric polygons?,"Is there a way to calculate the area of concentric, convex polygons ? I need a fast way to calculate the area of several, concentric polygons. I have their centroid in Cartesian coordinates and the height of the rings the others form with the sides of the first one ( $h_1, h_2, h_3, ..., h_n$ ). Please, see the picture below for a better understanding. Although the polygons in the picture are close to regular polygons, they aren't. I have the area of the smallest one, so I would like a way to calculate the others by using a rate based on their heights.","['trigonometry', 'area', 'geometry']"
4221740,"For which $a$, $b > 0$ is $f:(0,+\infty)\to\mathbb{R}:x\mapsto\frac{1}{(x^a+x^b)^2}$ integrable?","This problem was part of an Analysis exam on Lebesgue integration: For which $a$ , $b > 0$ is $f:(0,+\infty)\to\mathbb{R}:x\mapsto\frac{1}{(x^a+x^b)^2}$ integrable? We were taught to solve these kind of questions using arguments like $f(x)=\Theta(\frac{1}{x^\delta})$ , $f(x)=\text{O}(\frac{1}{x^\delta})$ or $f(x)=\Omega(\frac{1}{x^\delta})$ for $x\to 0$ or $x\to\infty$ for some $\delta\in\mathbb{R}$ (Landau Notation), but I can't seem to find $a,b >0$ such that integrability can be assured for $x\to 0$ and $x\to\infty$ . Here is an attempt I made; Suppose $a\geq b$ without loss of generality. Then for $x\to 0$ we have that $$f(x)=\Theta\left(\frac{1}{x^{2a}}\right) \hspace{2mm}\text{for }x\to0$$ giving us integrability for $x\to 0$ iff $\alpha<1/2$ . But for $x\to\infty$ we also have: $$f(x)=\Theta\left(\frac{1}{x^{2a}}\right) \hspace{2mm}\text{for }x\to\infty$$ so if we want integrability for $x\to\infty$ we need that $\alpha>1/2$ , which is not possible. I know I am missing some important subtlety here but I can't seem to find it. I would greatly appreciate a push in the right direction. Kind regards,
Jef","['integration', 'measure-theory', 'lebesgue-integral', 'asymptotics', 'real-analysis']"
4221758,Can a sequence of trace class operators $\rho_{n} \in B(H)$ converge to a multiplication operator under trace norm?,"Let $H$ be some infinite dimensional $Hilbert$ space. Now, let $B(H)$ be the set of all bounded linear operator over $H$ and let $seq :=\{\rho_{n}\}_{n=1}^{\infty}$ be a sequence of trace class operators in $B(H)$ , the trace class operators form an ideal over $B(H)$ . - My first question is this . Under what conditions, if any, does the sequence $seq$ converge to a multiplication operator under the trace norm $\| A\|_{1} : Tr(|A|)= Tr(\sqrt{A^{\dagger}A}
)$ . - My second question is a more specific version of the first . If the dynamics are generated by a contracting semigroup, i.e. $$\rho_{n} = L_{n}\rho_{0}$$ where $L_{n}$ are contracting linear maps, does the limit $\lim_{n\rightarrow \infty}\|\rho_{n}\|_{1}$ exists always? If so, what is the limiting operator and is it still trace class? - My third question is essentially the second but for a particular case. I have been working with the following operator. For $\psi(x) \in H = L^{2}(\mathbb{R})$ and $\sigma_{t}\in B(H)$ is defined as follows. $$\sigma_{t}\psi(x) := \int_{\mathbb{R}} e^{-t(x-y)^{2}}K(x,y)\psi(y)dy$$ . Where $K(x,y) \in L^{2}(\mathbb{R}^{2})$ is a $Hilbert-Schmidt$ kernel. Note tha for $t=0$ this is a very tame integral transform. I am worried about the behviour as $t\rightarrow \infty$ in the trace norm sense. i.e. if the limit of $\sigma_{t}$ exists under $\| \|_{1}$ , say $\sigma_{\infty}$ , what is it?  I am guessing that it should be some multiplication operator. $\lim_{t\rightarrow \infty}\|\sigma_{t}\|_{1} = ?  .$ Thank you very much for your help.","['quantum-mechanics', 'physics', 'functional-analysis', 'mathematical-physics']"
4221761,Immersed isometrically in $\mathbb{R}^4$,"I know well that there is an isometric immersion of the hyperbolic plane in $\mathbb R^5$ due to Rozendorn and that the hyperbolic plane cannot be immersed isometrically in $\mathbb R^3$ due to Hilbert , also I think that the problem in $\mathbb R^4$ is still open. So questions arise that I can't answer: Are there surfaces with negative Gaussian curvature immersed isometrically in $\mathbb R^4$ ? Are there surfaces with negative Gaussian curvature with $K\leq const<0$ immersed isometrically in $\mathbb R^4$ ? Are there surfaces with constant negative Gaussian curvature immersed isometrically in $\mathbb R^4$ ? Does anyone know where I can read more about the existence of complete surfaces with constant Gaussian curvature -1 immersed isometrically in $\mathbb R^4$ ?","['surfaces', 'riemannian-geometry', 'curvature', 'hyperbolic-geometry', 'differential-geometry']"
4221772,Solving the Riccati equation $y'=ay^2+f(x)y+b$,"I would like to know if someone knows a method to solve the following Riccati equation $$y'=ay^2+f(x)y+b$$ where of course $y'=\frac{dy}{dx}$ , $f$ is a continuous function and $a,b$ are constants. I know that if $f=C$ with $C$ a constant the equation is a separable equation, but I don't know what happen in the general case. If someone could give some advice, I will really appreciate it.",['ordinary-differential-equations']
4221775,Is convergence in $\ell^p$ spaces equivalent to coordinate-wise convergence?,"I'm a little rusty on this so I'm sorry if this has an obvious answer. My question is the following: let $\ell^p$ be the normed vector space of sequences $x = (x_n)_{n \in \mathbb{N}}$ such that $$
\|x\|_{p}\doteq\left(\sum_{n}\left|x_{n}\right|^{p}\right)^{1 / p} < \infty
$$ Is it true that a sequence $(y_n)_{n \in \mathbb{N}}$ of elements of $\ell^p$ (i.e a sequence of sequences, with $y_1 = (y^1_{1}, y^1_2, \cdots), y_2 = (y^2_1, y^2_2, \cdots), \cdots$ ) converges to some $y = (y_1, \cdots) \in \ell^p$ if, and only if, $$\lim_{n \to \infty}y^n_i = y_ i$$ for every $i \in \mathbb{N}$ ? Does either implication hold? I know this is true if the norm topology coincides with the product topology on $\mathbb{R}^{\mathbb{N}}$ , but it's clear to me if that's true either. I'd appreciate any help! Thanks in advance.","['topological-vector-spaces', 'analysis', 'real-analysis', 'functional-analysis', 'general-topology']"
4221876,Prove that sum of angles is constant,"We are given square ABCD, point E on the extension of side CD and CF perpendicular to EB.
Find the value of angles $α+β$ . I am trying to prove this by triangles similarity.
I can see that $\angle \alpha$ is equal to $\angle \alpha 1$ , which means that $\alpha+\beta$ is always $90^\circ$ .
To prove this, it would suffice to show that triangles $ABE$ and $ABF$ are similar. They share an angle $\angle ABE$ , so I must also show that $\angle AFB$ is equal to $\angle EAB$ .
I have tried several angles relations but can't see anything that proves the required. Any ideas please? PS: The source of the problem is a Facebook group - it was given to me by a friend who can't solve it either. Thank you in advance!","['euclidean-geometry', 'geometry']"
4221880,Solving an ODE - exact one?,"Given the following ODE, $$y' \arcsin(y)-x\sqrt{1-y^2} \arcsin ^2 (y) = 2x\sqrt{1-y^2}. $$ I guess that using some algebraic manipulations, I need to transform the equation into something in which I will be able to use the fact that $(\arcsin (x) ) ' = \frac{1}{\sqrt{1-x^2}}$ , but didn't manage to understand how exactly. I did manage to obtain the following form, in which I cannot see how to integrate the LHS, $$
\frac{\arcsin(y)}{\sqrt{1-y^2}}\cdot \frac{1}{2+\arcsin ^2 (y) } dy = x dx.
$$ Thank you!",['ordinary-differential-equations']
4221891,Prove that the area of $M$ is bigger than the area of $\mathbb{S}^2$,"Given $\mathbb{S}^2$ the unit sphere in $\mathbb{R}^3$ and let $f:\mathbb{S}^2\to \mathbb{R}$ be a $C^1$ function such that $f(x)\geq1$ for every $x\in\mathbb{S}^2$ and define $M=\{xf(x)|x\in\mathbb{S}^2\}$ 1.Prove that $M$ is smooth manifold with dimension of $2$ 2.Prove that the area of $M$ is bigger than the area of $\mathbb{S}^2$ Attempt: I proved it with composition of a map and f and showed that it is a regular parametrization. I've thought of doing the following $r:U\to\mathbb{S}^2$ map of the unit sphere $\int_M 1=\int_U \sqrt{\Gamma \left (\frac{d g}{dx_i} \right )}$ where $g(x_1,x_2)=r(x_1,x_2)f(r(x_1,x_2))$ but got stuck here and somehow to use the fact that $f(x)\geq1$ any hint?","['integration', 'manifolds', 'calculus']"
4221907,"The range of function $\frac{x+m}{x^2+1}$ contains interval [0,1] if m>3/k then k must be [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question The range of function $\frac{x+m}{x^2+1}$ $(m\in R)$ contains interval [0,1] if $m>\frac{3}{k}$ then k must be. I am not getting exact approach to solve this problem. T tried getting quadratic equation in x and then applying $D\geq 0 $ but it didn't work can anyone help thanks",['functions']
4221908,Functions where $ff^{(k)}<0$,"This is a follow up on Let $f$ be a twice-differentiable function on $\mathbb{R}$ such that $f''$ is continuous. Prove that $f(x) f''(x) < 0$ cannot hold for all $x.$ , for whoever is interested. Trying to generalize the linked question, we can ask for which $k$ the following proposition is true: Prop: Fix $k\ge 1$ . There is no real function $f$ (where the derivatives make sense) such that $f(x)f^{(k)}(x)<0$ for every $x$ . Prop is true for $k=2$ (see link for proofs). Prop is false for $k$ odd. Take $f(x)=e^{-x}$ as a counterexample. What about the other even values of $k$ ?","['functions', 'derivatives', 'real-analysis']"
4221914,Differential equation book with lots of exercises,"I am a post-doc with a PhD in theoretical physics. I have a background in the theory of differential equations, but I feel i lack of technique, so I am looking for a differential equations (ODE and PDE) book with lots of exercises. Can anyone suggest any?","['reference-request', 'ordinary-differential-equations', 'partial-differential-equations']"
4221931,How to use Leibniz integral rule If f goes to infinity?,"If $F(t)$ is defined as follows: $$
F(t) = \int_0^t \frac{y(\tau)}{\sqrt{t-\tau}}d\tau
$$ I want to calculate $F'(t)$ using Libniz integral rule. Use $f(t,\tau)$ to denote the part in the integration: $$
f(t,\tau) = \frac{y(\tau)}{\sqrt{t-\tau}}
$$ I know that $y(t)$ is a finite value, so $f(t,t)$ is $+\infty$ ,
use following formula ( https://en.wikipedia.org/wiki/Leibniz_integral_rule ), we would have the result equals to $+\infty - \infty$ , which is not what I want. $$
{\frac {d}{dx}}\left(\int _{0}^{x}f(x,t)dt\right)=f{\big (}x,x{\big )}+\int _{0}^{x}{\frac {\partial }{\partial x}}f(x,t)dt
$$ it looks like in this case Leibniz integral rule is not applicable. Is there a way to find $F'(t)$ ?","['integration', 'calculus', 'derivatives']"
4221941,Find the limit of given expressions:,"Given sequences $$a_n=\int_0^1 (1-x^2)^n \,dx$$ and $$b_n=\int_0^1 (1-x^3)^n \,dx$$ where $n \in \mathbb{N}$ , find $$\displaystyle\lim_{n\to \infty}(10\sqrt[n]{a_n}+5\sqrt[n]{b_n}).$$ So far:
I tried integrating expansions of $(1-x^2)^n$ and $(1-x^3)^n$ to get the series $C_0-\frac{C_1}{3}+\frac{C_2}{5}...\frac{(-1)^nC_n}{2n+1}$ and $C_0-\frac{C_1}{4}+\frac{C_2}{7}...\frac{(-1)^nC_n}{3n+1}$ . Since that was not working out, I tried integrating by parts: $$ \begin{align} a_n=\int_{0}^{1}(1-x^2)^ndx&=\left[x(1-x^2)^n\right]_{0}^{1}+2n\int_{0}^{1}x^2(1-x^2)^{n-1}dx \\\\&=0+2n\int_{0}^{1}\left[(1-(1-x^2))(1-x^2)^{n-1}\right]dx \\\\&=2na_{n-1}-2na_{n} \end{align} $$ then, with $a_0=1,\,a_1=\frac23,$ $$ a_{n}=\frac{2n}{2n+1}\cdot a_{n-1}, \quad n\ge1. $$ Hence it comes out as $$a_n=\frac{1\cdot2\cdot4\cdot6...2n}{1\cdot3\cdot5\cdot7...2n+1}$$ Similarly integrating $b_n$ , the result came out as: $$b_n=\frac{3n}{3n+1}\cdot b_{n-1}, \quad n\ge1. $$ $$b_0=1,\,b_1=\frac34$$ Transforming into $$b_n=\frac{1\cdot3\cdot6\cdot9...3n}{1\cdot4\cdot7\cdot10...3n+1}$$ Now I have to somehow put it into the given limit, but I have no idea how.","['limits', 'calculus', 'binomial-coefficients', 'definite-integrals']"
