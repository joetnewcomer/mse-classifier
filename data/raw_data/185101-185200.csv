question_id,title,body,tags
3410737,"Prob. 16, Sec. 2.3, in Herstein's TOPICS IN ALGEBRA, 2nd ed: A finite set closed under an associative product with only one of the cancellation laws","Here is Prob. 14, Sec. 2.3, in the book Topics in Algebra by I.N. Herstein, 2nd edition: Suppose a finite set $G$ is closed under an associative product and that both cancellation laws hold in $G$ . Prove that $G$ must be a group. Here is a Mathematics Stack Exchange post on this problem. And, here is Prob. 16, Sec. 2.3, in the book Topics in Algebra by I.N. Herstein, 2nd edition: In Problem 14 show by an example that if one just assumed one of the cancellation laws, then the conclusion need not hold. My Attempt: Let $$ G = \{ \, 1, -1 \, \}. $$ And for any $a, b \in G$ , let $a * b$ be defined as $$ a*b \colon= a \, \lvert b \rvert. $$ Thus we have $$ 1 * 1 = 1 = 1 * (-1), \qquad (-1)*1 = -1 = (-1) * (-1). $$ We note that in this set $G$ with this binary operation $*$ , the left cancellation law does not hold, for although we have $$ 1 * 1 = 1 = 1 * (-1), $$ it is not true that $$ 1 = -1.$$ However, the right cancellation law does indeed hold in $G$ , for if $a$ , $b$ , and $c$ are any elements in $G$ and if $$ a * c = b * c, $$ then we have $$ a \, \lvert c \rvert = b \, \lvert c \rvert, $$ and since $c \neq 0$ , therefore we must have $$ a = b. $$ Thus in our set $G$ with this particular binary operation $*$ , the right cancellation law holds but the left cancellation law does not. Moreover, for any elements $a$ , $b$ , and $c$ in $G$ , we obtain $$
\begin{align}
(a * b) * c &= \big(a \, \lvert b \rvert \big) * c \\
&= \big(a \, \lvert b \rvert \big) \, \lvert c \rvert \\
&= a \, \lvert b c \rvert \\
&= a \, \big\lvert b \, \lvert c \rvert \, \big\rvert \\
&= a \, \big\lvert \, b * c  \, \big\rvert \\
&= a * ( b * c).
\end{align}
$$ This shows that $*$ is an associative binary operation on $G$ . Thus $G$ is a finite set with an associative binary operation $*$ such that only one of the two cancellation laws holds in $G$ . Finally, we note that this set $G$ with this particular binary operation $*$ is not a group, because $G$ contains no identity element. In order to see that $G$ with respect to $*$ contains no identity element, we note that as $$ 1 * (-1) \neq -1, $$ so $1$ cannot be an identity element (more precisely a left identity element) of $G$ , and as $$ (-1) * 1  \neq 1, $$ so $-1$ cannot be an identity element (more precisely, a left identity element) of $G$ . On the other hand, either of $1$ and $-1$ can serve as a right identity element in $G$ , because for any element $a \in G$ , we have $$ a * (\pm 1) = a \, \lvert \pm 1 \rvert = a (1) = a. $$ However, in a group a right identity element is also a left identity element, and there is a unique such element. See Lemma 2.3.1 a. in Herstein. And, also refer to this Mathematics Stack Exchange post. Is this example good enough? If so, then is my presentation clear enough too? Or, are there any issues? Now let us consider this same set $G$ , namely, $$ G = \{ \, 1, -1 \, \}, $$ but now let $*$ be the binary operation on $G$ defined as follows: For any elements $a$ and $b$ of $G$ , let us define $a ~ b$ as $$ a*b \colon= \lvert a \rvert \, b. $$ Then we have $$ 1 * 1 = 1 = (-1) * 1, \qquad 1 * (-1) = -1 = (-1) * (-1).  $$ In this case, the left cancellation law holds in $G$ , for if $a, b, c \in G$ and if $$ a * b = a * c, $$ then $$ \lvert a \rvert \, b = \lvert a \rvert \, c, $$ and as $a \neq 0$ , so we must have $b = c$ , but the right does not hold in $G$ , for we have $$ 1 * 1 = (-1) * 1, $$ but $1 \neq -1$ . And, this binary operation $*$ on $G$ is of course associative, for if $a, b, c \in G$ , then we obtain $$
\begin{align}
a * ( b * c ) &= a * \big( \lvert b \rvert \, c \big) \\
&= \lvert a \rvert \, \big( \lvert b \rvert \, c \big) \\
&= \lvert a \rvert \, \lvert b \rvert \, c \\
&= \lvert a b \rvert \, c \\
&= \big\lvert a \, \lvert b \rvert \big\rvert \, c \\
&= \big\lvert a * b \big\rvert \, c \\
&= (a * b) *c.
\end{align}
$$ Thus again we have the finite set $G$ with an associative binary operation such that only one of the two cancellation laws holds in $G$ . Finally, we note that this set $G$ with this particular binary operation $*$ is again not a group. The element $1$ of $G$ cannot serve as an identity element (from the right) because $(-1) * 1 \neq -1$ , and $-1$ cannot serve as an identity element (again from the right) because $1 * (-1) \neq 1$ , although either of $1$ and $-1$ can serve as an identity element from the left, because for any element $a \in G$ have $$ (\pm 1 ) * a = \lvert \pm 1 \rvert \, a = 1 \cdot a = a. $$ Is this example OK? Or, are there problems? Any other examples of this kind please?","['proof-verification', 'examples-counterexamples', 'abstract-algebra', 'binary-operations', 'group-theory']"
3410740,In the range $0\leq x \lt 2\pi$ the equation has how many solutions $\sin^8 {x}+\cos^6 {x}=1$,"In the range $0\leq x \lt 2\pi$ the equation has how many solutions $$\sin^8 {x}+\cos^6 {x}=1$$ What i did $\cos^6 {x}=1-\sin^8 {x}=(1-\sin^4 {x})(1+\sin^4 {x})=(1-\sin^2 {x})(1+\sin^2 {x})(1+\sin^4 {x})$ $\cos^4 {x}=(1+\sin^2 {x})(1+\sin^4 {x}) , \cos^2{x}=0$ $(1-\sin^2{x})^2=(1+\sin^2 {x})(1+\sin^4 {x})$ $-3\sin^2{x}=\sin^6{x}$ Which is not possilbe Is there a trick or something to solve this equation or to know how many solutions are there ?",['trigonometry']
3410759,"If $m,n\in Z$ then {$x\in Z: mn\mid x$}$\subset${$x\in Z:m|x$}$\cap${$x\in Z:n\mid x$}","If $m,n\in Z$ then { $x\in Z: mn\mid x$ } $\subset$ { $x\in Z:m|x$ } $\cap$ { $x\in Z:n\mid x$ } I know this is true, but I'm having trouble proving it","['elementary-set-theory', 'elementary-number-theory']"
3410788,Matrices with special properties and their relation to an interesting problem about cards.,"For $k\in \mathbb{N}$ , $A$ , an $n$ x $n$ matrix has the following properties: Every entry belongs to the set $\{0,1,2,...,k \}$ , and, Every individual row and column adds up to $k$ . Question: Can we always permute just the rows (or just the columns) of $A$ to obtain a matrix which has all non-zero diagonal entries? Further, I encountered this question while solving the following recreational question on cards. Say I have an usual pack of $52$ cards ( $13$ cards of each type numbered from $1$ to $13$ ). In any arbitrary distribution of these cards into $13$ groups, can I always find an ordering of the groups such that group $i$ contains a card numbered $i$ ? I observed that if I form a matrix with the mentioned properties, where $n=13$ , and $k=4$ , and the $A_{ij}$ entry is the number of $j$ numbered cards in $i^{th}$ group, then the question on the matrix property is an equivalent of the question on cards. Finally, I have proved it is possible for any $k$ , and $n=3$ and $4$ . I would really appreciate further help. Thank you.","['matrices', 'card-games', 'discrete-mathematics']"
3410852,Problem in the properties of limit: $\lim\limits_{x \to\frac{\pi}{3}}\frac{\sin\left(x-\frac{\pi}{3}\right)}{1-2\cos\left(x\right)}$,"$$\lim\limits_{x \to\frac{\pi}{3}}\frac{\sin\left(x-\frac{\pi}{3}\right)}{1-2\cos\left(x\right)}$$ I used the following property:
if $$\lim\limits_{\large x \to\frac{\pi}{3}}f(x)=L$$ then $$\lim\limits_{x \to\frac{\pi}{3}}\frac{1}{f\left(x\right)}=\frac{1}{L}$$ where $L$ is a real number and nonzero,hence we have: $$\lim\limits_{\large x \to\frac{\pi}{3}}\frac{1-2\cos\left(x\right)}{\sin\left(x-\frac{\pi}{3}\right)}$$ substititute $x-\frac{\pi}{3}=u$ : $$\lim\limits_{\large u \to 0}\frac{1-2\cos\left(u+\frac{\pi}{3}\right)}{\sin\left(u\right)}$$ $$=\lim\limits_{\large u \to 0}\frac{1-\cos\left(u\right)+\sqrt{2}\sin\left(u\right)}{\sin\left(u\right)}=\lim\limits_{\large u \to 0}\frac{1-\cos\left(u\right)}{\sin\left(u\right)}+\sqrt{2}$$ $$=\lim\limits_{\large u \to 0}\frac{\sin\left(u\right)}{1+\cos\left(u\right)}+\sqrt{2}=\sqrt{2}$$ hence the main limit should be $\frac{1}{\sqrt{2}}$ which is wrong, but I don't know why, also is there any way to solve the problem without using Taylor series or L'hopital's rule?","['limits', 'trigonometry', 'definition', 'limits-without-lhopital']"
3410887,"Sigma Notation, to another Form of Sigma Notation and then a final result?!","There is this problem, I fail to understand the solution, $$ \sum_{i=1}^n \frac{i-1}{i!}=? $$ and the solution given is: Step - 1 : $\sum_{i=1}^n \frac{i}{i!} - \frac{1}{i!}$ Step - 2 : $\sum_{i=1}^n \frac{1}{(i-1)!} - \frac{1}{i!}$ Step - 3 : $1-\frac{1}{n!}$ Now, what i dont understand is, the transition from STEP 1to2 & STEP 2to3 Could you please me give me some explanation. Thank You, With Respect Umer Selmani","['summation', 'discrete-mathematics']"
3410890,"If $k$ is the smallest integer such that $[a^k]>[a]^k$, which of the following is true?","This is a question from the KVPY(SX)-2014 (an examination to get into various research institutes in India) paper. Q. For a real number $r$ let $[r]$ denote the largest integer less than or equal to $r$ . Let $a > 1$ be a real number which is not an integer and let $k$ be the smallest positive integer such that $[a^k] > [a]^k$ . Then which of the following statements is always true? $(A)\,\, k\le 2([a]+1)^2\quad (B) \,\, k\le ([a]+1)^4\quad (C)\,\, k\le 2^{[a]+1}\quad (D)\,\, k\le\frac{1}{a-[a]}+1$ The solutions which I’ve looked through on the Internet and on the booklet I’ve been given mostly state that by taking different values of a and k, option B is possible ( e.g. here ). But have not provided a proof on why. Or have put forward a proof that doesn't click my head (e.g. this ). I'm looking for a proof that suits the needs for a 12th grader in India.","['elementary-number-theory', 'algebra-precalculus', 'ceiling-and-floor-functions']"
3410897,Let $a_n$ equal the amount of roots of $f_n(x) = \frac{1}{n} x+\sin(x)$. Does $\sum_{n=1}^{\infty} \frac1{a_n}$ converge?,"Let $a_n$ equal the amount of roots of $f_n(x) = \frac{1}{n} x+\sin(x)$ .
Does $\sum_{n=1}^{\infty} \frac1{a_n}$ converge? For increasing $n$ the graph of $f_n(x)$ approaches the $x$ -axis, the image below shows the first four iterations of $f_n(x)$ .
The amount of roots increases for bigger $n$ . In particular, for $n\to\infty$ we see $a_n \to \infty$ , because $\lim_{n\to\infty} f_n(x) = \sin(x)$ . So the sequences $\frac1{a_n}$ converges to $0$ . Does the series converges, and if it does, is it there a specific limit?","['sequence-of-function', 'trigonometry', 'sequences-and-series', 'real-analysis']"
3410924,Positivity of a certain sum of Stirling numbers,"Past days I've been trying to prove that certain polynomials have positive coefficients. After a lot of thinking, I came up with a formula for each coefficient individually, and they are not that ugly. I think maybe someone can give me a hand on this. Synthetically, what I want to prove is that the following sum is positive: $$S(k,n,m)=\sum_{i=0}^{n-m-1} \sum_{j=0}^{k-1} (-1)^{i+j} \binom{n}{j}(k-j)^m {j \brack {j-i}} {{n-j}\brack {m+1+i-j}}$$ Where the symbol ${x \brack y}$ stands for the Stirling numbers of the first kind (without sign). I'm interested in the case $1\leq m,k\leq n-1$ . I have already proven the following: 1) If in the sum we set $m=n-1$ , we get just the well known recurrence for Eulerian numbers, so it is positive. For $m=n-2$ , the result is a sum of two Eulerian numbers. 2) If we replace $k$ by $n-k$ , the sum remains the same. 3) With $k=1$ , we get simply the Stirling numbers of the first kind. 4) With $m=1$ the sum is always positive. Probably someone with more experience working on this kind of sums can give me a hand. I bet that there may be even a way to understand this sum combinatorially.","['harmonic-numbers', 'eulerian-numbers', 'combinatorics', 'stirling-numbers']"
3410937,Total derivative is continuous. What about partials?,"If the total derivative $Df(x)$ of $f:\mathbb{R}^n \to \mathbb{R}^m$ is continuous does it imply that all partial derivatives are continuous? I would say yes of course because one can simply take the composition $(f \circ\pi_i)(x_i)$ , where $\pi_i: \mathbb{R} \to \mathbb{R}^n$ and $\pi_i(x_i)=(a_1, ..., x_i, a_{i+1},..., a_n)$ for a point $a=(a_1, ..., a_n)\in \mathbb{R}^n$ . As both functions $\pi_i$ and $Df(x)$ are continuous their composition is also continuous. But $Df(\pi_i(x_i))$ yields exactly the $i$ -th partial derivative. Is this correct?","['partial-derivative', 'continuity', 'multivariable-calculus', 'proof-explanation']"
3410940,Find the directional derivative in the direction of a parametric vector,"Find the directional derivative at $(1,0,0)$ of the function $$f(x,y,z) = x^2 + ye^z)$$ in the direction of the tangent vector at $g(0)$ to the curve $\mathbb{R}^3$ defined parametrically by $$g(t) = (3t^2 + t + 1, 2t , t^2)$$ $$\begin{align}
\nabla f(x,y,z) &= (2x, e^z, ye^z) \\
\frac{\partial f}{\partial g}(1,0,0) &= (2x, e^z, ye^z) \cdot (et^2 + t + 1, 2t, t^2) \\
&= 6t^2 + 2t + 2 + 2t \\
&= 6t^2 + 4t + 2
\end{align}$$ My textbook says that the answer is $2\sqrt{5}$ , which I don't think makes any sense and I think the book is wrong, but would like some other input on the matter, thank you","['partial-derivative', 'multivariable-calculus']"
3410975,Is there a simple proof that $(\Sigma a_n)(\Sigma b_n)=\Sigma (a_0b_n + \ldots + a_nb_0)$ whenever the series converge?,"That is, if the power series $\Sigma a_n$ , $\Sigma b_n$ and $\Sigma c_n$ converge to $A, B$ and $C$ respectively, where $c_n = a_0b_n + \ldots + a_nb_0$ , then, $$AB=C$$ Rudin's proof, for instance, makes use of Merten's Theorem and the continuity of power series (in fact, he mentions the theorem in chapter 3, but doesn't prove it until chapter 8 due to lack of tools to establish the result). I was just wondering if there was a more direct proof.","['complex-analysis', 'proof-writing', 'analysis', 'sequences-and-series']"
3410994,Counting number of strictly increasing and strictly non identical functions,"How many functions from $f:A \rightarrow B$ where $A=\{a_1,a_2,\ldots,a_6 \}, B=\{1,2,3,\ldots,9 \}$ such that $f(a_{i+1})>f(a_{i}) \quad \forall \quad 1 \leq i \leq 5$ and $f(a_j) \neq j \quad \forall 1 \leq j \leq 6$ Attempt: $a_6$ can take values $7,8,9$ . $a_5$ can take values $6,7,8$ so on till $a_1$ can take values $2,3,4$ . I wrote down these possibilities in a vertical column, one below the other, in the same order. I noted that starting from any row, we can proceed(values permissible) only vertically upward or diagonally upward to the next row. I couldn't think of any other idea. Although here brute Force with the above logic is feasible since the numbers and possibilities are fairly small (I got the answer doing so), but is there any other way? Preferably a more general one with set A having $n$ elements and set B having $m$ elements with the same constraints. I couldn't spot a pattern in the above brute Force method.","['combinations', 'functions', 'combinatorics']"
3411003,"Prove/Disprove: Let $G$ be a simple graph with $n$ nodes, as $\forall v\in V: \ deg(v)\ge 2$, then $G$ is connected","Prove/Disprove: Let $G$ be a simple graph with $n$ nodes, such that $\forall v\in V: \ deg_{_{G}}(v)\ge k$ , then $G$ is a connected graph. I. $G$ has $7$ nodes, such that $\forall v\in V: deg(v)\ge 2$ , prove/ Disprove that $G$ is a connected graph. II. $G$ has $7$ nodes, such that $\forall v\in V: deg(v)\ge 3$ , prove/ Disprove that $G$ is a connected graph. III. $G$ has $8$ nodes, such that $\forall v\in V: deg(v)\ge 3$ , prove/ Disprove that $G$ is a connected graph. I know that a simple graph is a graph where there are no loops and no parallel edges, and I know that $\\sum_{v\in V} deg(v) \ 2|E|$ , but I don't know how to ""imagine"" a graph as described above in order to find the answer.","['graph-theory', 'discrete-mathematics']"
3411022,Kinematics bike - average speed for three to reach tourist center,"Three tourists have a bicycle, they must reach the tourist center in the shortest possible time (the time is counted until the last tourist arrives in the center). The bicycle can only carry two people and so the third tourist should go on foot. The cyclist leaves another tourist on the way and returns to pick up what was on foot. Walking speed is $ v_1 $ and biking is $ v_2 $ . What is the average speed of tourists in functions $v_1$ and $v_2$ ? I thought like this: $ y $ is the distance traveled by A with velocity Vb over a time interval $ ∆t1, $ ie $ y = Vb.∆t2; $","['physics', 'functions', 'kinematics']"
3411076,Calculate $\lim_{x\to\infty}\frac{x^2}{x+1}-\sqrt{x^2+1}$,"I am stuck on a limit of the indeterminate form $\infty-\infty$ . I have tried many approaches, such as multiplying with conjugates etc. and I am unable to find a solution. I suspect that there is an elementary trick that I am plainly missing right here. Can anybody give me a hint or solution as to solve $$\lim_{x\to\infty}\frac{x^2}{x+1}-\sqrt{x^2+1}$$","['indeterminate-forms', 'limits', 'calculus']"
3411094,Find the last digit of $22^{23^{24^{25^{26^{27^{28^{\cdot^{\cdot^{\cdot^{67}}}}}}}}}}$,"Find the last digit of $22^{23^{24^{25^{26^{27^{28^{\cdot^{\cdot^{\cdot^{67}}}}}}}}}}$ in base- $10.$ Just to clarify, I want to find the last digit of the power tower of consecutive numbers starting at $22$ and ending at $67.$ I was just wondering if there was some general method that could be used to solve this? I don't know if Euler's Theorem might be useful for solving this problem, but it seems there might be a very simple approach.","['number-theory', 'exponentiation']"
3411105,How can I show the incompleteness of the irrational numbers?,"To show the incompleteness of the rational numbers, we just had to find a set of rational numbers, that does not have an supremum / infimum which is element of $\mathbb{Q}$ . For example, we could show that the set $\{x\in\mathbb{Q}|x²<2\}$ does not have a supremum in $\mathbb{Q}$ , because $\sqrt{2}\notin\mathbb{Q}$ . So we simply found a counter example and we were done, right? Now I'm wondering, how can we show the same thing for $\mathbb{R}$ \ $\mathbb{Q}$ (let's call it $\mathbb{I}$ for simplicity reasons). It feels like, you could just do the same thing we did for $\mathbb{Q}$ also with $\mathbb{I}$ , for example we know that $\frac{3}{2}\notin\mathbb{I}$ , but how can I actually prove that? In $\mathbb{Q}$ we could atleast construct numbers, but in $\mathbb{I}$ this gets kinda hard. Does someone have a tip for me? Thanks in advance!","['real-numbers', 'complete-spaces', 'irrational-numbers', 'analysis', 'real-analysis']"
3411106,Can a holomorphic function of several variables have just one zero?,Of course “several” in the title means $n$ strictly greater than 1 and the function is defined on some open subset of $\mathbb{C}^n$ . I tried to use the Weierstrass preparation theorem because it’s the only result on analysis of several variables I know but I couldn’t find a contradiction (I believe the answer is “no”).,['complex-analysis']
3411118,"Find the $1000$th digit after the decimal point of $\sqrt{n},$ where $n=\underbrace{11\dots1}_{1998 \text{ 1's}}$","Find the $1000$ th digit after the decimal point of $\sqrt{n}$ , where $n=\underbrace{11\dots1}_{1998 \text{ 1's}}$ . Obviously, $\underbrace{11\dots1}_{1998 \text{ 1's}}=\dfrac{1}{9}\left(9\cdot10^{1997}+9\cdot 10^{1996}+\dots+9\right),$ so we want to find $\left(\dfrac{10^{1998}-1}{9}\right).$ If only there was some way to convert this expansion into some closed form. I'm not sure if calculus would be useful. The problem asks for a single digit, so if we consider repeating digits, everything will be a lot easier. There seems to be a pattern in the decimal expansions of numbers consisting of only $1.$ For instance, $$\sqrt{1}=1,$$ $$\sqrt{11}=3.3166247...$$ $$\sqrt{111}=10.5356537...$$ $$\sqrt{1111}=33.3316666...$$ $$\sqrt{11111}=105.408728...$$ $$\sqrt{111111}=333.333166...$$ $$\sqrt{1111111}=1054.09250...$$ Every term of the form $\displaystyle\sum_{n=0}^{2k+1}10^n$ has $k+1$ $3$ 's at the beginning and $k+1$ 3's right after the decimal expansion, followed by one $1,$ and $2(k+1)$ $6$ 's. Proving this would prove that the $1000$ th digit is $1.$ This is the same as showing that $\sqrt{\left(\dfrac{10^{2m}-1}{9}\right)}=\dfrac{10^{m}-1}{3}+\dfrac{1}{3}-\dfrac{1}{6}\cdot 10^{-m}+\epsilon_m$ where $|\epsilon_m|<10^{-2m}.$ Edit: the previous question I asked was inspired by the current one, but the previous question seemed to have a rather unpleasant answer, so I changed it.","['algebra-precalculus', 'irrational-numbers', 'repunit-numbers']"
3411156,What sort of groups are generated by a single conjugacy class?,"To clarify, I am not looking for a classification but rather for well-researched examples of families of (finitely generated) groups generated by a single conjugacy class. A collection of examples, some from the answers and comments, is as follows. Let $W$ be a Coxeter group with presentation $$\langle s_1, \dots, s_n \;|\; (s_is_j)^{m_{ij}} \rangle,$$ with $m_{ii} = 1$ and $2 \leq m_{ij} = m_{ji} \leq \infty$ whenever $i \neq j$ (the relation $(s_is_j)^\infty$ stands for ""no relation""). Suppose that the graph $G$ with vertices $s_1, \dots, s_n$ and edges between $s_i$ and $s_j$ whenever $m_{ij}$ is finite and odd, is connected. Then, all the $s_i$ are conjugate and thus, $W$ is generated by a single, somehow distinguished conjugacy class. Specific groups in this family include dihedral groups $D_m$ for odd $m$ (the groups obtained when $n=2$ ) and symmetry groups $S_n$ (by letting $m_{i(i+1)} = 3$ and all other $m_{ij} = 2$ ). Braid groups $B_n$ (or more generally Artin groups for which the
same criterion on the off-diagonal weights as above holds) also satisfy that all standard generators are conjugate. Mapping class groups of surfaces are generated by finitely many conjugate Dehn twists around non-separating curves. Knot groups are generated by finitely many meridians. Are there any other families that come to mind?","['group-theory', 'finitely-generated', 'coxeter-groups', 'knot-theory', 'general-topology']"
3411188,"The principle of inclusion and exclusion: How many permutations of the set $\{1, 2,. . . , 8\}$ do not leave any even number in its place?","I am supposed to solve the following problem: How many permutations of the set $\{1, 2,. . . , 8\}$ do not leave any even number in its place? What I tried: $$8!-\left ( \binom{8}{1}7!-\binom{8}{ 2}6!+\binom{8}{3}5!-\binom{8}{4}4! \right )$$ But I know that this is incorrect. Can anyone tell me why?","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
3411263,Prove that $\int_{-\infty}^\infty \frac{1}{(\coth(x)+x)^2+\frac{\pi^2}{4}} \mathrm{d}x =1 $,"Prove that $$
\int_{-\infty}^\infty \frac{1}{(\coth(x)+x)^2+\frac{\pi^2}{4}} \mathrm{d}x =1 $$ The hyperbolic function $\coth x$ is defined by: $$
{\displaystyle \coth x={\frac {\cosh x}{\sinh x}}={\frac {e^{x}+e^{-x}}{e^{x}-e^{-x}}}={\frac {e^{2x}+1}{e^{2x}-1}}}.
$$ I got this problem from my friend and I tried hard to solve it but I don't know how to begin with it: all I can observe is that the denominator can never be zero. A similar problem I found in this site is this: Prove this $ \int_0^\infty\frac{\coth^2x-1}{(\coth x-x)^2+\frac{\pi^2}{4}}dx=\frac45 $ Could anyone please help?","['integration', 'calculus', 'definite-integrals']"
3411279,"Prove that $(1+a^2)(1+b^2)\geq 4ab$ for all $a,b>0$ without limits","I'm facing a problem where I need to prove that $(1+a^2)(1+b^2)\geq 4ab$ for all $a,b>0$ without any use of limits.
 I have tried 2 different methods that I'm not really sure about: 1) Taking out factors $a$ and $b$ so I get: $$ab(a+\frac{1}{a})(b+\frac{1}{b})\geq 4ab$$ $$(a+\frac{1}{a})(b+\frac{1}{b})\geq 4$$ and then split for cases: suppose $a,b<0.5$ so both $\frac{1}{a}>2$ and $\frac{1}{b}>2$ Therefore: $(a+\frac{1}{a})$ >2 and $(b+\frac{1}{b})$ >2 so $(a+\frac{1}{a})(b+\frac{1}{b}) >4$ and so on. In cases both are smaller but very close to $1$ is there any general way to prove that $(a+\frac{1}{a})>2$ ? 2) The other method I've tried was more direct and algebric, but wasn't too helpfull: $$(1+a^2)(1+b^2)=1+a^2+b^2+(ab)^2=1+(a-b)^2+2ab+(ab)^2$$ So I tried: $$(1+a^2)(1+b^2)\geq4ab \rightarrow 1+(a-b)^2+(ab)^2\geq2ab$$ but without limits it's too hard to say anything about cases where $a\rightarrow0$ or $b\rightarrow0$ or both. If there's anything I'm missing I'd like to be enlightened.","['algebra-precalculus', 'proof-writing', 'a.m.-g.m.-inequality', 'inequality']"
3411325,"Confused about the definition of a function. ""Each a in A belongs to a unique ordered pair, (a,b) in f"". What about asymptotes?","Studying Set theory, specifically functions. My textbook says as follows: A function $f:A\rightarrow B$ is a relation from $A$ to $B$ (i.e, a subset of $A\times B$ ) such that each $a$ in $A$ belongs to a unique ordered pair, $(a,b)$ in $f$ . This seems to add an additional 'rule' to the definition of a function from what I am familiar with in calculus. The requirement that every $a$ must map to some b is confusing to me. What about functions with vertical asymptotes? Don't those functions map from $\mathbb R\rightarrow\mathbb R$ , but there is some a value where the function is not defined? Or the same could be said about functions with ""holes"". Any help would be appreciated. Thanks!","['elementary-set-theory', 'functions']"
3411400,Quasi-components and components coincide for compact Hausdorff spaces,"I am attempting to solve exercise 1.10.1 from Topology and Geometry by Bredon: If $X$ is a compact Hausdorff space then show that its quasicomponents are connected (and hence that its quasi-components coincide with its components). The definition of the relation used for quasi-components is "" $d(p) = d(q)$ for every discrete valued map $d$ on $X$ ."" He gives the hint: If $C$ is a quasi-component, let $C = \cap C_{\alpha}$ where the $C_\alpha$ are the clopen sets containing $C$ . If $C$ is disconnected, then $C = A \cup B, A \cap B = \emptyset, A,B$ closed. Let $f:X \to [0,1]$ be $0$ on $A$ and 1 on $B$ . Put $U = f^{-1}([0,\frac{1}{2}))$ and apply the following result: Let $X$ be a compact space and let $\{C_\alpha \mid \alpha \in A\}$ be a collection of closed sets, closed with respect to finite intersections. Let $C = \cap C_\alpha$ and suppose that $C \subset U$ with $U$ open. Then $C_\alpha \subset U$ for some $\alpha$ . I don't understand which collection of closed sets to use. If we use the clopen sets $C_\alpha$ , and we have that $C \subset U$ but $U \subset X - B$ , so $B = \emptyset$ , and we don't need some $C_\alpha \subset U$ . Furthermore, how would we show that $C \subset U$ , it seems to more or less assumes $B = \emptyset$ .","['connectedness', 'general-topology', 'compactness']"
3411402,Stone-Cech compactification of discrete space is totally disconnected,"Let $X$ be a discrete space; consider the space $\beta(X)$ . a) Show that if $A\subset X$ , then $\overline{A}$ and $\overline{X-A}$ are disjoint, where the closures are taken in $\beta(X)$ . b) Show that if $U$ is open in $\beta(X)$ , then $\overline{U}$ is open in $\beta(X)$ . c) Show that $\beta(X)$ is totally disconnected. I was able to solve the parts a) and b) but cannot solve the last one. I would be very grateful if anyone can show to solve it.",['general-topology']
3411417,"If maximal subgroups of solvable group have equal cores, then they are conjugates","I have been asked to Show that if $U$ and $V$ are maximal subgroups of a soluble group $G$ , then the following conditions are equivalent: (a) - $U$ and $V$ are conjugates (b) - $U_{G} = V_{G}$ , i.e. , the subgroups have the same normal core I was able to show that $(a) \implies (b)$ , but I am having trouble in the other direction. I am trying to find a way to apply the Schur-Zassenhaus theorem to find that $U$ and $V$ are conjugates, but I don't see how this could be connected with the fact that $U_{G} = V_{G}$ .","['group-theory', 'abstract-algebra', 'finite-groups', 'solvable-groups']"
3411425,Why isn't $\text{Out}(S_6) \cong \{ e \}$?,"I am learning about automorphisms, and came across the fact that: $$\text{Out} (S_n) = \{e \}  \hspace{15pt} \text{when} \hspace{5pt} n \neq 6$$ I see why this is true for n in general, since $\text{Aut} (S_n) \cong S_n$ and I can convince myself that $\text{Inn}(S_n) \cong S_n$ , meaning that: $$\text{Out} (S_n) \cong \text{Aut}(S_n) / \text{Inn}(S_n) \cong \{e \}$$ What fails when n = 6?","['automorphism-group', 'group-theory', 'abstract-algebra']"
3411435,Reduction of a Power Series Solution Separated by an Integer?,"I am given the following equation: $$x(x-1)\ddot y + 6x^2\dot y + 3y = 0 $$ and have solved/found the regular singular points, the exponents at singularity, the first series solution and the form of the second series solution, which are all as follows: $x = 0, \space 1$ are regular singular points For $x = 0$ , $r_1 = 1, \space r_2 = 0$ Recurrence relationship: $$a_n = \frac {n^2 - n + 3}{n(n+1)}a_{n-1} + \frac {6(n-1)}{n(n+1)}a_{n-2}$$ $a_1 = \frac{3}{2}a_0$ The first solution is: $$y_1(x) = x + \frac{3}{2}x^2 + \frac{9}{4}x^3 + \frac{51}{16}x^4 + ...$$ Since the exponents differ by an integer, the second solution is of the form: $$y_2(x) = ay_1(x)ln(x) + 1 + \sum_{n=1}^{\infty} c_n(r_2)x^n$$ Substituting this equation into the original governing equation: $$x(x-1)\bigg\{ay_1(x)ln(x) + 1 + \sum_{n=1}^{\infty} c_n(r_2)x^n)\bigg\}^"" + 6x^2 \bigg\{ ay_1(x)ln(x) + 1 + \sum_{n=1}^{\infty} c_n(r_2)x^n \bigg\} ' + 3\bigg\{ ay_1(x)ln(x) + 1 + \sum_{n=1}^{\infty} c_n(r_2)x^n\bigg\} = 0 $$ Now my question is how does the above equation reduce to the following? : $$aln(x)L[y_1] + 2a(x-1)y' - \frac{(x-1)}{x}ay_1 + 6axy_1 + L\bigg[ 1 + \sum_{n=1}^{\infty} c_n(r_2)x^n \bigg] = 0$$ The above form is advantageous since $L[y_1] = 0$ , but I do not fully understand this reduction step. Thanks!","['power-series', 'algebra-precalculus', 'ordinary-differential-equations']"
3411452,Unexpected answer to an expected value problem,"Suppose you start on the zero notch of the line of integers. You flip a coin. If you get heads, you move to the integer on the right (+1), and if you get tails, you move to the integer on the left (-1). It turns out that the expected number of flips to reach +1, from 0, is infinity. Why?","['random-walk', 'probability']"
3411495,Independence of Random Variables ( Measure Theory),"Let $(\Bbb Ω,\Bbb F,μ)$ be a probability measure space (that is $μ(\Bbb Ω)=1$ ), $f:\Bbb Ω \rightarrow \Bbb R$ , a $\Bbb F$ -measurable function (random variable) and $φ:\Bbb R \rightarrow \Bbb R$ a Borel measurable function. We have to show that the family $(φ\circ f,f)$ is independent iff $φ\circ f$ is constanst $μ$ -a.e. If we suppose that $φ\circ f$ and $f$ are independent then we know that the σ-algebras $$σ(f)=f^{-1}(\mathcal{B} (\Bbb R))$$ $$σ(φ\circ f)=(φ\circ f)^{-1}(\mathcal B(\Bbb R))$$ are independent. We observe that $$σ(φ\circ f)=(φ\circ f)^{-1}(\mathcal B(\Bbb R))=f^{-1}(φ^{-1}(\mathcal B(\Bbb R))\subset f^{-1}(\mathcal B(\Bbb R))=σ(f)$$ So, if we pick an $A$ in $σ(f\circ φ)$ we have also picked an $A$ at $σ( f)$ . Then $(A,A)$ is an independent family. This implies that $μ(Α)=0$ or $μ(A)=1$ . This is where i'm stuck. I have and some other thoughts but i think that this is the right starting point. Any help would be great. Thank you in advance.","['measure-theory', 'probability-theory']"
3411513,Prove the equality (Taylor series).,"Prove the equality: $$
\frac{1}{3}\left(e^x+2e^{-x/2}\cos\frac{x\sqrt{3}}{2}\right)=
\sum_{n=0}^{\infty}\frac{x^{3n}}{(3n)!},\ \ -\infty<x<+\infty
$$ I tried to apply Euler's formula ( $e^{ix}=\cos x+i\sin x$ ) to this problem but it went rather unsuccessful. Here is what I did: $$
e^{-x/2}=e^{i(ix/2)}=\cos\frac{ix}{2}+i\sin\frac{ix}{2}\Rightarrow\\
\Rightarrow 2e^{-x/2}\cos\frac{x\sqrt{3}}{2}=2\cos\frac{ix}{2}\cos\frac{x\sqrt{3}}{2}+
2i\sin\frac{ix}{2}\cos\frac{x\sqrt{3}}{2}=\\
=\cos\frac{x(i+\sqrt{3})}{2}+\cos\frac{x(i-\sqrt{3})}{2}+
i\sin\frac{x(i+\sqrt{3})}{2}+i\sin\frac{x(i-\sqrt{3})}{2}=\\
=e^{ix(i+\sqrt{3})/2}+e^{ix(i-\sqrt{3})/2}=
e^{x(-1+i\sqrt{3})/2}+e^{x(-1-i\sqrt{3})/2}
$$ Then I tried to use Maclaurin series for $e^{x(-1+i\sqrt{3})/2}$ and $e^{x(-1-i\sqrt{3})/2}$ after which I got completely befuddled because it seemed to me that I had only complicated the initial problem. So, if anyone could help me, I would appreciate it.","['calculus', 'taylor-expansion', 'sequences-and-series']"
3411614,"Prove: $(\log{n})^k=\mathcal{O}(n^{\frac{1}{\mathcal{m}}})$ $k,m\in\mathbb{N}$","( $\mathbb{N}$ does not contain 0 in this case) How can I prove this? It feels intuitive and seems to be right. Sadly, I got no idea how to approach this proof. Can someone give me advice? There is a tip on the worksheet, which may be used: $\lim_{x\rightarrow\infty}\frac{(\log{x})^k}{x}=0$ Thanks in advance!","['logarithms', 'asymptotics', 'functions', 'algorithms', 'limits']"
3411665,About Hahn's decompositions and Radon-Nikodym theorem,"This is the question 8.K of Bartle's book: Let $(X,\mathcal{X})$ be a measurable space. Let $\mu$ a finite measure, let $\lambda< <\mu,$ and let $P_{n},N_{n}$ be a Hahn's decomposition for $\lambda=n\mu.$ Let $P=\bigcap P_{n},N=\bigcup N_{n}$ . Show that $N$ is $\sigma$ -finite for $\lambda$ , and that if $E\subset P$ , $E\in\mathcal{X},$ then either $\lambda(E)=0$ or $\lambda(E)=+\infty.$ The first part was straightforward, but I'm stucked on the second part. I did: $\lambda(E)=n\mu(E)\geq\mu(E)\geq 0$ . If $\mu(E)=0, \lambda(E)=n\mu(E)=0$ for all $n\in\mathbb{N}$ , so $\lambda(E)=0$ is a possibility. Now, I need to prove that, if $\lambda(E)>0$ , so $\lambda(E)=+\infty$ Maybe I can use the $\lambda < < \mu$ condition to apply the Radon-Nikodym. So, exists a function $f$ such that $\lambda(F)=\int_{F}f d\mu$ for all $F\in\mathcal{X}$ . So, $$\lambda(E)=\int_{E}fd\mu\leq\int_{P}fd\mu=\int_{\bigcap P_{n}}fd\mu\leq\int_{P_n}fd\mu, $$ but this way leads me no where. What can I do?","['measure-theory', 'radon-nikodym']"
3411671,Show $f$ is surjective $\iff f^{-1}(y)$ contains at least one element for all $y \in Y$,"Let $f: X \to Y$ be a function. Show $f$ is surjective $\iff f^{-1}(y)$ contains at least one element for all $y \in Y$ . Proof: Let $y \in Y.$ Suppose $f^{-1}(\{y\}) = \emptyset.$ Since $f$ is surjective, there's some $x \in X$ s.t. $f(x) = y.$ This implies $f(\{x\}) = \{y\}$ meaning $y = f(x) \in f(\{x\})$ . Then by definition of pre-image of set, $x \in f^{-1}(f(\{x\})) = f^{-1}(\{y\}).$ Contradiction. Now assume $x \in f^{-1}(\{y\}).$ Then by definition of inverse image of set, $f(x) \in \{y\}$ meaning $y = f(x)$ . This shows $f$ is surjective. Does the proof work? Thanks.","['elementary-set-theory', 'proof-verification', 'discrete-mathematics']"
3411678,How do I find the variance of $\hat\theta_\text{MLE}$ for $f_{\theta}(x) = \theta x^{\theta-1}$?,"Given, $$f_\theta(x) = \theta x^{\theta-1}, x \in [0,1], \theta >0$$ $$\hat\theta_\text{MLE} = \frac{-1}{\frac{1}{n} \sum_{i=1}^n \log(x_i)} $$ $$\operatorname{Var}(\hat\theta_\text{MLE}) = E_\theta(\hat\theta_\text{MLE}^2) - E_\theta(\hat\theta_\text{MLE})^2$$ How do I find the expectations, $E_\theta(\hat\theta_\text{MLE}^2)$ and $E_\theta(\hat\theta_\text{MLE})$ ,  given the presence of both summation and log in the denominator?","['expected-value', 'statistics', 'variance']"
3411680,Optimal strategy in three-player number-picking game,"Consider a game in which there are three players. Call them Player $1$ , Player $2$ , and Player $3$ . Here are the rules: Each player is supposed to select an integer between $1$ and $100$ . Player $1$ 's number is randomly generated. Player $2$ and Player $3$ both know that Player $1$ 's number is randomly generated. The person with the largest number has to pay the other two people the number that each one of them said (i.e. say Player $1$ picks $5$ , Player $2$ picks $70$ and Player $3$ picks $90$ . In this case, Player $3$ pays $5$ to Player $1$ and $70$ to Player $2$ ). Let's suppose you are Player $3$ . Furthermore, suppose that Player $2$ plays optimally. What's the best strategy if you want to maximize profit? I solved the $n = 2$ (two-player game) case here: Optimal strategy in probability-based game I want to extend it to $n = 3$ , but I can't figure it out. I would appreciate any help.","['game-theory', 'probability']"
3411720,Lebesgue measure is the completion of a product of Lebesgue measures,"I'm working on a problem from Stein and Shakarchi's Real Analysis book (Exercise 6.7.13). I'm having some trouble understanding the problem and am looking for some insight. Exercise 13: Let $m_j$ be the Lebesgue measure for the space $\mathbb{R^{d_j}}$ , $j = 1,2$ . Consider the product $\mathbb{R^d} = \mathbb{R^{d_1}} \times \mathbb{R^{d_2}}$ with $m$ the Lebesgue measure on $\mathbb{R^d}$ . Show that $m$ is the completion (in the sense of exercise 2) of the product measure $m_1 \times m_2$ Exercise 2, which is mentioned in the problem above: One can define the completion of a measure space $(\mathcal{X}, \mathcal{M}, \mu)$ as follows. Let $\mathcal{\overline{M}}$ be the collection of sets of the form $E \cup Z$ , where $E \in \mathcal{M}$ , and $Z \subset F$ with $F \in \mathcal{M}$ and $\mu(F) = 0$ . Define $\overline{\mu}(E \cup Z) = \mu(E)$ . $\mathcal{\overline{M}}$ is the smallest $\sigma$ -algebra containing $\mathcal{M}$ and all subsets of elements of $\mathcal{M}$ of measure $0$ , and the function $\overline{\mu}$ is a measure on $\mathcal{\overline{M}}$ and is complete. My thinking: My understanding of a measure being complete is that the measure of subsets of sets of measure $0$ also have measure $0$ . This coincides with the definition in exercise 2 in the sense that ""adding"" a subset of a set of measure $0$ onto any measurable set doesn't change the measure, so it makes sense to call those measure $0$ sets. To solve exercise 13, I need to show that if I take the union of a measurable set $E \in M$ and an element of $\mathbb{R^{d_1}} \times \mathbb{R^{d_2}}$ that is a subset of a set of measure $0$ , then the measure of the union is the same as the measure of $E$ . In this sense, subsets of measure $0$ have measure $0$ under $\mu$ . Am I thinking about this properly, or am I confused? Thanks!","['measure-theory', 'lebesgue-measure']"
3411742,A Property for Banach spaces which Do not have the finite tree property.,"In the paper, ""Banach Spaces which can be given an equivalent uniformly convex norm"" by Per Enflo, there is one lemma whose proof I failed to understand: Lemma. If a Banach Space $B$ does not have the finite tree property, then for every $\varepsilon>0$ there is an $n$ and a $\delta>0$ , such that if $z \in B$ and $(x_1,x_2,\dots,x_{2^n})$ is an $(n,\varepsilon)$ -partition of $z$ then $$\sum_{ j=1}^{2^n} \|x_j\| \ge (1+\delta)\|z\|.$$ Definitions: An ordered pair $(x_1,x_2)$ in a Banach space is a $(1,\varepsilon)$ -part of a
tree if $\|x_1 - x_2\| > \varepsilon$ . Now if the $(n,\varepsilon)$ -part of a tree is defined, we say that a $(2^{n+1})$ -tuple $(x_1, x_2,\dots,x_{2^{n+1}})$ is a $(n + 1, \varepsilon)$ -part of a tree if $\|x_{2j-1} -x_{2j} \| > \varepsilon$ , for $j=1,\dots,2^n$ and the $2^n$ -tuple $((x_1 + x_2)/2, (x_3 + x_4)/2, \dots)$ is an $(n,\varepsilon)$ -part of a tree. The Banach space $B$ has the finite tree property (FTP),
if there is an $\varepsilon > 0$ such that for every n, there is an $(n,\varepsilon)$ -part of a tree where
all elements have norm at most $1$ . The ordered pair $(x_1,x_2)$ is a $(1,\varepsilon)$ -partition of $z$ if $$x_1 + x_2 = z, \|x_1\|=\|x_2\|, \ and \ \|x_1/\|x_1\| - x_2/\|x_2\| \| \geq  \varepsilon.$$ Having defined an $(n, \varepsilon)$ -partition of $z$ , we say that the $2^{n+1}$ tuple $(y_1, y_2,..., y_{2^{n+1}})$ is an $(n+1,\varepsilon)$ -partition of $z$ if $\|y_{2j-1}\|=\|y_{2j}\|$ , $\|y_{2j-1}/\|y_{2j-1}\| - y_{2j}/\|y_{2j}\| \| \geq \varepsilon$ for $1\leq j \leq2^n$ and the $2^n$ -tuple $(y_1+y_2,y_3+ y_4,\dots)$ is an $(n,\varepsilon)$ -
partition of $z$ . The proof is rather short, it says assume $z$ has norm equal to 1.Taking a $(n,\varepsilon)$ -partition of $z$ and multiplying by $2^n$ every element, we get a $(n,\varepsilon)$ -part of a tree whose vectors have all norm $\geq 1$ .(It is easy to prove by induction that all elements in a $(n, \varepsilon)$ -partition of $z$ have norm at least $ 1/2^{n}$ ). Now since $B$ does not have the FTP there is an $n$ and a $\delta>0$ such that for all $(n,\varepsilon)$ -parts of trees formed by multiplication by $2^n$ of the vectors in a $(n,\varepsilon)$ -partition, there is one vector of length $\geq 1+2^n \cdot \delta$ and then the result follows. My question is, that $\delta$ depends on the chosen partition and so that delta doesn't necesarily have to work for all partitions. I can't see if there is something I am missing.","['proof-explanation', 'functional-analysis']"
3411788,Show that $\frac{3\> + \>\cos x}{\sin x}$ cannot have any value between $-2\sqrt2$ and $2\sqrt2$,"Show that $$\dfrac{3+\cos x}{\sin x}\quad \forall \quad x\in R $$ cannot have any value between $-2\sqrt{2}$ and $2\sqrt{2}$ . My attempt is as follows: There can be four cases, either $x$ lies in the first quadrant, second, third or fourth:- First quadrant : $\cos x$ will decrease sharply and sinx will increase sharply, so $y_{min}=3$ at $x=\dfrac{\pi}{2}$ . $y_{max}$ would tend to $\infty$ near to $x=0$ Second quadrant : $\cos x$ will increase in magnitude and sinx will decrease sharply, so $y_{min}=3$ at $x=\dfrac{\pi}{2}$ . $y_{max}$ would tend to $\infty$ near to $x=\pi$ Third quadrant: $\cos x$ will decrease in magnitude and sinx will increase in magnitude but negative, so $y_{min}$ would tend to $-\infty$ near to $x=\pi$ $y_{max}$ would be $-3$ at $x=\dfrac{3\pi}{2}$ Fourth quadrant: $\cos x$ will increase sharply and sinx will decrease in magnitude, so $y_{min}$ would tend to $-\infty$ near to $x=2\pi$ $y_{max}$ would be $-3$ at $x=\dfrac{3\pi}{2}$ So in this way I have proved that $\dfrac{3+\cos x}{\sin x}$ cannot lie between $-2\sqrt{2}$ and $2\sqrt{2}$ , but is their any smart solution so that we can calculate quickly.",['trigonometry']
3411813,How to show CES is not an algebra,"We say that a subset $V$ of $\{1,2,3,\dots\}$ has Cesaro density $\gamma(V)$ and denote $V\in CES$ if the limit $$\gamma(V):=\lim_{n\to \infty} \frac{\mid V\cap \{1,2,3,\dots, n\}\mid}{n}$$ exists. Give an example of sets $V_1\in CES$ and $V_2\in CES$ for which $V_1\cap V_2\notin CES$ . How to find such an example? If I try to show CES is not algebra.","['measure-theory', 'real-analysis']"
3411840,Derive the classical CLT from the Lindeberg-Feller CLT,I am wondering if there is a way to derive the classical CLT from the Lindeberg-Feller CLT. I looked at the two definitions on Wikipedia . But I am still very confused on how to start. I was wondering if anyone could provide me with a hint or direction to start. Thanks a lot!!,"['central-limit-theorem', 'probability-theory']"
3411876,Question on Artin Proof of The Classification of The Groups of Order $12$,"In the book Algebra Ed2 by Michael Artin, in chapter 7.8 where Artin classifies the groups of order $12$ , he considers a Sylow $3$ -subgroup $K$ and a Sylow $2$ -subgroup $H$ of order $4$ . Then $K\approx C_3$ and $H\approx C_4$ or $H\approx C_2\times C_2$ . Therefore $H\cap K=1$ , and then $HK=G$ as the product map is bijective. He proved that at least one of $H$ and $K$ is a normal subgroup, and consider them case by case. In Case 3, when $K$ is normal, but $H$ is not, he writes: Then $H$ operates by conjugation on $K = \left\{1,y,y^2\right\}$ . Since $H$ is not normal, it contains an element $x$ that doesn't commute with $y$ , and then $xyx^{-1} = y^2$ . Why must it be true that an element of $x$ in $H$ does not commute with $y$ ? Thanks!","['normal-subgroups', 'group-theory', 'abstract-algebra', 'sylow-theory']"
3411890,Sturm-Liouville Problem: Find Eigenfunctions,"I am looking for eigenfunctions of the Sturm-Liouville Problem: $y'' + \lambda y = 0$ With conditions: $ y'(0) = 0$ $y'(\pi) = y(\pi)$ I found that assuming $\lambda \le 0$ implies $y = 0$ . Supposing $\lambda > 0$ , we have: $y = A\cos(\sqrt{\lambda}x) + B\sin(\sqrt{\lambda}x)$ $y' = -A\sqrt{\lambda}\sin(\sqrt{\lambda}x) + B\sqrt{\lambda}\cos(\sqrt{\lambda}x)$ The first condition implies: $B\sqrt{\lambda} = 0$ $B = 0$ From the second condition: $A\cos(\sqrt{\lambda}\pi) + B\sin(\sqrt{\lambda}\pi) = -A\sqrt{\lambda}\sin(\sqrt{\lambda}\pi) + B\sqrt{\lambda}\cos(\sqrt{\lambda}\pi)$ $A\cos(\sqrt{\lambda}\pi) = -A\sqrt{\lambda}\sin(\sqrt{\lambda}\pi)$ $\cos(\sqrt{\lambda}\pi) = -\sqrt{\lambda}\sin(\sqrt{\lambda}\pi)$ Now I am looking for values of $\lambda$ which satisfy the above equation (hopefully there are infinite such values). Then the corresponding eigenfunctions will take the form $y = \cos(\sqrt{\lambda}x)$ . The problem is that I don't know how to find $\lambda$ . I appreciate any help!",['ordinary-differential-equations']
3411903,Understanding Gradient Policy Deriving,"I'm stuck with understanding pretty simple expression and would appreciate some help on this. The most interesting part for algorithms, it's way how we can come here. Using the original resources from Andrej Karpathy blog about Policy Gradient. Everything is clear with Monte Carlo credit assignments and supervised algorithms vs reinforcement. We have next expression, how we came up this optimization objective and gradient for it (images from another resources): 1) I'm familiar with derivation I think, but what was a point for taking log in this case? It's called likehood ratio trick sometimes and also explained here (where I still cannot get it). What is the point of using it here? 2) Can somebody show few Very simple examples of using it with numbers and how it works? Is there anything else about math I need to find or this could exist on Khan Academy? References : 1) Deep Reinforcement Learning: Pong from Pixels 2) An introduction to Policy Gradients with Cartpole and Doom 3) Deriving Policy Gradients and Implementing REINFORCE 4) Machine Learning Trick of the Day (5): Log Derivative Trick 12 UPDATE Please consider answering above two points. I don't need to find derivative of softmax and complicated output. I would appreciate some new explanation (different from articles above). And let's say that action space it's continues value and probability of taking action it's liner activation within very simple example.","['integration', 'derivatives', 'logarithms']"
3411962,Prove that concurrent lines in an arbitrary hexagon,"Let $A_i$ , $i = 1, 2,\ldots, 6$ , be six points on plane. Taking subscripts modulo $6$ , we denote, for $i = 1, 2,\ldots, 6$ , the intersection of the lines $A_iA_{i+1}$ and $A_{i+2}A_{i+3}$ by $B_{i+3}$ , and the second intersection of the circumcircles of triangles $A_iA_{i+1}B_{i+2}$ and $A_{i+1}A_{i+2}B_{i+3}$ by $C_{i+1}$ , and the circumcenter of the triangle $C_iB_{i+1}B_{i+2}$ by $D_i$ . Please provide the lines $D_1D_4$ , $D_2D_5$ , and $D_3D_6$ are concurrent.","['euclidean-geometry', 'geometry', 'plane-geometry']"
3411994,"Why is [0,1/2) open in [0, 1]?","With the usual metric in $\mathbb{R}$ , there is no open interval around $0$ that is completely contained in $[0,1/2)$ . However, I have come across the fact that "" $[0,1/2)$ is open in $[0,1]$ "" in a proof I am going through. It seems to directly contradict the definition of openness. A rationale behind this would be appreciated.","['general-topology', 'metric-spaces']"
3412049,Spivak Calculus 4th Ed. Chapter 11 Problem 27,"I am having trouble understanding what the following problem is getting at. I've included my attempted answers below each part. Chapter 11 Problem 27 (a) Suppose the polynomial function $f(x) = x^n + a_{n-1}x^{n-1} + .. + a_0$ has exactly $k$ critical points and that $f''(x) \neq 0$ for all critical points $x$ . Show that $n - k$ is odd. Since $f''(x) \neq 0$ all critical points are local minima or maxima. The sign of the derivative must switch at and only at each of these points since $f'$ is a polynomial. The sign of the derivative must also match the beginning and ending behavior of $f$ . For example, $f'$ starts negative and ends positive if $n$ is even. So for even $n$ , $k$ must be odd and for odd $n$ , $k$ must be even. (b) For each $n$ , show that if $n - k$ is odd, then there is a polynomial function $f$ of degree $n$ with $k$ critical points, at each of which $f''$ is nonzero. Let $f'(x) = (x - 1)(x - 2)...(x - k)(x^{n - k - 1} + 1)$ and integrate. $n - k - 1$ is even so $f$ has exactly $k$ critical points. Since each critical point $x$ is a single root of $f'$ , $f''(x) \neq 0$ (by product rule). (c) Suppose that the polynomial function $f(x) = x^n + a_{n-1}x^{n-1} + .. + a_0$ has $k_1$ local maximum points and $k_2$ local minimum points. Show that $k_2 = k_1 + 1$ if $n$ is even, and $k_2 = k_1$ if $n$ is odd. Seems like the argument in (a) also works here. Local maxima and minima must alternate and the restrictions on the end behavior enforce the given relationships. (d) Let $n, k_1, k_2$ be three integers with $k_2 = k_1 + 1$ if $n$ is even, and $k_2 = k_1$ if $n$ is odd, and $k_1 + k_2 < n$ . Show that there is a polynomial function $f$ of degree $n$ , with $k_1$ local maximum points and $k_2$ local minimum points. Hint: Pick $a_1 < a_2 < ... < a_{k_1 + k_2}$ and try $f'(x) = \prod_{i = 1}^{k_1 + k_2}(x - a_i) \cdot (1 + x^2)^{l}$ for an appropriate number $l$ . Similarly, seems like part (b) works here. All the critical points $x$ are local minima or maxima since $f''(x) \neq 0$ and the sign switching argument implies that there must be the correct number of each. However, this does not use the hint. Is this still correct? What is he getting at in the hint?","['calculus', 'derivatives', 'real-analysis']"
3412057,Closed Form for $\sum\limits_{n=-2a}^\infty(n+a){2a\choose-n}^4$,"Do either $~S_4^+(a)~=~\displaystyle\sum_{n=0}^\infty(n+a){2a\choose n}^4~$ or $~S_4^-(a)~=~\displaystyle\sum_{n=-2a}^\infty(n+a){2a\choose-n}^4~$ possess a meaningful closed form expression in terms of the general parameter a ? Ramanujan provided the following result : $~S_4^-\Big(-\tfrac18\Big)~=~\dfrac1{\bigg[\Big(-\tfrac14\Big){\large!}\bigg]^2~\sqrt{8\pi}}~,~$ which would point to a possible closed form expression in terms of $~(2a)!~$ and/or $~(4a)!~$ For lesser values of the exponent, we have Dixon's identity : $$\sum_{n=0}^\infty(-1)^n{2a\choose n}^3 ~=~ \sum_{n=-2a}^\infty(-1)^n{2a\choose-n}^3 ~=~ \cos(a\pi)~{3a\choose a,a},$$ and Vandermonde's identity : $$\sum_{n=0}^\infty(-1)^n{2a\choose n}^2 ~=~ \sum_{n=-2a}^\infty(-1)^n{2a\choose-n}^2 ~=~ \cos(a\pi)~{2a\choose a},$$ $$\sum_{n=0}^\infty{a\choose n}^2 ~=~ \sum_{n=-a}^\infty{a\choose-n}^2 ~=~ {2a\choose a},$$ as well as the binomial theorem : $$\sum_{n=0}^\infty{a\choose n}^1x^n ~=~ (1+x)^a,\qquad\sum_{n=-a}^\infty{a\choose-n}^1x^n ~=~ \Big(1+\tfrac1x\Big)^a.$$","['calculus', 'combinatorics', 'closed-form', 'sequences-and-series']"
3412063,"Lorenz system for $s=10$, $r=28$ and $b=8/3$ has unstable critical points, but they never go out of the butterfly shape","I'm studying the Lorenz dynamical system, and I'm asking myself if the critical points are unstable critical points. Considering the theory they are unstable - one eigenvalue $\in \mathbb{R}$ which is negative and 2 complex eigenvalues with a negative real part. But when I look at the critical points the results seem to oscillate around the critical value and never go to $\infty$ . It appears to me it's not an unstable critical point then? Can someone clarify which type of critical points these are?","['systems-of-equations', 'ordinary-differential-equations']"
3412083,Ideals of $P_3$,"This question originates from Pinter's Abstract Algebra Chapter 18.B7. If $D$ is a set, then the power set of $D$ is the set $P_D$ of all the subsets of $D$ .
Addition and multiplication are defined as follows: If $A$ and $B$ are elements of $P_D$ (that is, subsets of $D$ ), then \begin{align*}
    A+B &= (A-B) \cup (B-A) \text{ and } AB = A\cap B
\end{align*} Let $P_3$ be $P_D$ where $D=\{a,b,c\}$ . List all the ideals of $P_3$ . ( $B$ is an ideal of $A$ if and only if $B$ is closed with respect to subtraction and $B$ absorbs products in $A$ .) My attempt: Based on the multiplication table of $P_3$ , there are exactly $8$ ideals of $P_3$ .  Specifically, $\{\emptyset\}$ $\{\emptyset, \{a\}\}$ $\{\emptyset, \{b\}\}$ $\{\emptyset, \{c\}\}$ $\{\emptyset, \{a\}, \{b\}, \{a,b\}\}$ $\{\emptyset, \{a\}, \{c\}, \{a,c\}\}$ $\{\emptyset, \{b\}, \{c\}, \{b,c\}\}$ $P_3$ Is this correct?","['proof-verification', 'group-theory', 'ring-theory', 'abstract-algebra', 'abelian-groups']"
3412106,Limit involving floor function: $\lim\limits_{x\to 0} x \left\lfloor\frac1x \right\rfloor$ [duplicate],"This question already has answers here : How can I calculate this limit: $\lim\limits_{x\to 0} x\left\lfloor\frac{1}{x}\right\rfloor$? (4 answers) Closed 2 years ago . I'm studying calculus right now but I'm stuck at solving a limit involving floor function. The problem is to find $$\lim_{x\to 0}x \left\lfloor\frac{1}{x} \right\rfloor$$ where $\lfloor\cdot\rfloor$ denotes the floor function. My first thought was to let $x=1/t$ so when ${x\to 0+}$ then ${t\to \infty}$ so it seems $\lim_{t\to \infty}[t]/t$ doesn't exist. But I can't go any further and don't know whether my thought is correct. It seems $t=N+\delta$ doesn't help because t goes to infinity. Can it be proved by the epsilon-delta method or something else?
Thank you for your help.","['limits', 'calculus', 'ceiling-and-floor-functions']"
3412144,Explaining the concept of having data distributed in some probability distribution,"Cordially, can someone explain, in a plain simple way, what do we mean by saying ""input data are distributed according to some probability distribution"" Possibly this question sounds trivial to the community here but in fact I've never been able to understand it. I truly appreciate any answer.","['probability-distributions', 'probability']"
3412149,Example of turning nonautonomous system of ODEs to autonomous system of ODEs,"I am reading Chicone's book and it mentions that you can reduce an $n$ th order differential equation into a system of first order equations, and gives an example. Nevertheless, there's no example of how you convert a nonautonomous differential equation to an autonomous one. How does this work, say with $x' = x + t$ ?","['ordinary-differential-equations', 'dynamical-systems']"
3412212,Number of solutions pairs of $ax+by=n$,"Question: Given that $a, b, n$ are positive integers and $x, y$ are nonnegative integers such that $$ax+by=n$$ has at least one solution pair $(x, y) $ .
  How many solution pairs $(x, y) $ are there? For example, $$2x+3y=12$$ has $3$ solution pairs. They are $$(3,2),(6,0), (0,4).$$ However, I have no idea on how to find a general formula.","['discrete-mathematics', 'number-theory', 'combinatorics', 'elementary-number-theory']"
3412255,"Prove $\frac{1}{1+(k+1)^2} \lt \arctan(k+1) - \arctan(k) \lt \frac{1}{1+k^2}, k \in \mathbb N^*$","$$f:\mathbb R \to\mathbb R, f(x) = \arctan x  $$ $$\frac{1}{1+(k+1)^2} \lt f(k+1) - f(k) \lt \frac{1}{1+k^2}, k\in \mathbb N^*$$ I have to prove this for an exercise and I am would greatly appreciate some help. So far I have tried the following: Noticed that the expression can be written as: $$f'(k+1) \lt f(k+1) - f(k) \lt f'(k)$$ Now I tried to look at these functions' monotony and maybe get something out of it. For $k \in \mathbb N^*$ , $f(x)$ is increasing and $f'(x)$ is decreasing. Now I am not sure what to do next.","['calculus', 'functions', 'definite-integrals', 'inequality']"
3412415,GAGA pullback of sheaf of Kähler differential.,"Basically the question is here Analytification of algebraic differential forms for smooth complex projective scheme of finite type $X$ . Let $h: X^{an} \rightarrow X$ be the analytification morphism. I would love to see a more detailed proof why the pullback of $\Omega_{X/\mathbb{C}}$ , sheaf of Kähler differentials of $X$ , is $\Omega^{an}$ , the sheaf of holomorphic 1-forms of $X^{an}$ . I think we just need to construct a canonical morphism $h^*\Omega_{X/\mathbb{C}} \rightarrow \Omega^{an}$ and prove that it is injective or surjective, then the isomorphism follows from the fact that both are locally free of the same rank. Thank you in advance.","['complex-geometry', 'algebraic-geometry']"
3412555,Prove that he can bring back this amount of coins,"there are $2^{n+1}$ coins ( $n$ is a natural number). Each coin has a non-negative integer value. The coins are not necessarily distinct. Prove that it is possible to bring exactly $2^n$ coins such that the total value of earnings is divisible by $2^n$ . My thoughts:
So you can only bring back half of the coins, so I think we need to prove this somehow by induction or pigeonhole principle? With induction on $n$ .
Base case: $n=0$ , so there are $2$ coins total and can only bring back $1$ coin. Any natural number is divisible by $2^0=1$ so base case holds. IH: Assume claim holds true for $n=k$ . IStep: Prove claim holds true for $n=k+1$ . So there are $2\cdot{2^{k+1}}$ coins. We can split this up using algebra: $2^{k+1}+2^{k+1}$ Consider any of the $2^{k+1}$ coins. By IH, we can bring $2^{k}$ coins back that fits the claim.","['induction', 'proof-writing', 'discrete-mathematics']"
3412564,Sections on Möbius bundle correspond to $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x+n)=(-1)^nf(x)$,"I want to show that sections of the Möbius bundle correspond to functions $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x+n)=(-1)^nf(x)$ . 
Given a section of the Möbius bundle I want to define such an $f$ , this will give a map from sections of the Möbius bundle into the set of desired functions. We view $S^1$ as $\mathbb{R}/\mathbb{Z}$ where $\mathbb{Z}$ acts on $\mathbb{R}$ by $n\cdot x=x+n$ .
We get the Mobius bundle over $S^1$ by considering the $\mathbb{Z}$ action on $\mathbb{R}^2$ that is $n\cdot(x,y)=(x+n,(-1)^n y)$ . Denote the Möbius bundle by $L$ .
The projection $\pi:L\rightarrow S^1$ is then $\pi(x,y)=(x)$ . Recall that a section of a line bundle over $S^1$ is a map $s:S^1\rightarrow L$ such that $\pi \circ s= id_{S^1}$ . Intuitively this makes sense but I am not sure how to rigoursly identify these things. Given a section $s:S^1\rightarrow L$ , we want to define an $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x+n)=(-1)^nf(x)$ . The $(-1)^n$ term appears when we act on $(x,y)\in L$ by $n$ . So if for a section $s(x)=(s_1(x),s_2(x))$ I think we will need to define $f$ in terms of $s_2$ . But this only gives $(s_1(x),s_2(x))=n\cdot(s_1(x),s_2(x))=(s_1(x)+n,(-1)^ns_2(x))$ . Do we do something like $f(x)=\pi_2(n\cdot s(\overline{x}))$ ? where $\overline{x}$ is the $x$ minus the nearest integer to $x$ and $n$ is the nearest integer to $x$ ? This feels wrong, it seems like there should be a neater way to do this since $x+n$ and $(-1)^n$ both appear in the action of $\mathbb{Z}$ /","['vector-bundles', 'differential-geometry']"
3412624,"If for metric space $(X,d)$ we have $d(A,B)>0$ for any pair of non empty closed disjoint subsets $A$ and $B$. Show that $(X,d)$ is complete.","If for metric space $(X,d)$ we have $d(A,B)>0$ for any pair of non-empty  disjoint closed subsets $A$ and $B$ . Show that $(X,d)$ is complete. I am confused. If I let $A=N\subseteq R$ and $B=\{n+ \frac1n | n\in N, n\geq2\}$ then both $A$ and $B$ are disjoint and closed subsets of $(R, |\cdot|)$ , which is complete but $d(A,B)=0$ So does this disproves the above claim? EDIT: Looking carefully, the condition is not if and only if so this does not disproves the above claim. Please check my proof: Suppose $X$ is not complete $\rightarrow \exists (x_n)\in X  $ that is Cauchy but not convergent. If the set $F=\{x_n \mid n\in N\} $ is finite, then $(x_n)$ has a constant subsequence and thus $(x_n)$ converges to that constant. So $F$ has to be infinite. Hence, we can extract a subsequence from $(x_n)$ , say $(y_n)$ with all its terms distinct. Let $G=\{y_{2n}\mid n\in N\}$ and $H=\{y_{2n+1}\mid n\in N\}$ Then $G$ and $H$ are disjoint, closed subsets of $X$ but $d(G,H)=0$ as $(y_n)$ is also Cauchy. Is this proof okay?","['general-topology', 'metric-spaces', 'real-analysis']"
3412670,Question about $\operatorname{Aut}(S_6)$ and $\operatorname{Aut}(A_6)$,"From (1) , (2) , (3) , $[\operatorname{Aut}(S_6):\operatorname{Inn}(S_6)]=2$ . My question : $1$ . How to prove $\operatorname{Aut}(S_6)\cong S_6\rtimes_\varphi \mathbb Z_2$ ? $2$ . How to prove $\operatorname{Aut}(S_6)\not\cong S_6\times \mathbb Z_2$ ? $3$ . How to prove $\operatorname{Aut}(A_6)\cong \operatorname{Aut}(S_6)$ ? My effort : $1$ . For 1, it remains to show there exists $\sigma\in \operatorname{Aut}(S_6)\setminus \operatorname{Inn}(S_6)$ s.t. $\sigma^2=\text{id}$ . $2$ . For 2, $Z(S_6\times\mathbb Z_2)=\mathbb Z_2$ , it's sufficient to show $Z(\operatorname{Aut}(S_6))\neq\mathbb Z_2$ . $3$ . For 3, I proved $\operatorname{Aut}(S_n)\leqslant\operatorname{Aut}(A_n)$ (Is this correct?) and $[\operatorname{Aut}(A_6):\operatorname{Inn}(S_6)]\leqslant 2$ . Update: I wrote my answer below, but there still remain three questions: $1$ . I copied the result from a book to give an explicit element $\psi\in\operatorname{Aut}(S_6)\setminus \operatorname{Inn}(S_6)$ of order $2$ , and I wonder if there's a way to avoid doing so, i.e. find an element of order $2$ in $\operatorname{Aut}(S_6)\setminus \operatorname{Inn}(S_6)$ without writing it out explicitly. $2$ . I used the specific element $\psi$ to show $\mathbb Z_2\cong \langle \psi\rangle$ is not normal in $\operatorname{Aut}(S_6)$ , I wonder if we can analysis the center of $\operatorname{Aut}(S_6)$ instead. And what is center of $\operatorname{Aut}(S_6)$ ? $3$ . Is there a better way to prove $\operatorname{Aut}(A_6)\cong \operatorname{Aut}(S_6)$ ? Thanks for your time and effort!","['permutations', 'group-theory', 'abstract-algebra', 'solution-verification']"
3412677,$\cos(\pi/7)$ is a root of $8x^3-4x^2-4x+1=0$. How is the polynomial generated?,"According to Wolfram MathWorld , $\cos(\frac{\pi}{7})$ is a root of $8x^3-4x^2-4x+1=0$ . Similarly, $\cos(\frac{2\pi}{7})$ is a root of $8x^3+4x^2-4x-1=0$ . What's the procedure to generate these polynomials? I understand you can solve the cubic equations and check the cosines are indeed roots. My question is how does one arrive at those polynomials in the first place?","['cubics', 'trigonometry', 'polynomials', 'complex-numbers']"
3412757,If f is twice differenetiable at a and g is twice differentiable at $f(a)$ then prove..,$(f\circ g)''(a)= g'((f(a))(f''(a)+ g''(f(a))(f'(a))^2$ This looks like a product rule but I am not sure how to justify it and I don't know where the $(f'(a))^2$ came from,"['calculus', 'derivatives', 'real-analysis']"
3412800,"Calculate $\lim_{x\to 0} {1\over x} \int_0^x \cos(t^2)\,dt$","I have to calculate $$\lim_{x\to 0} {1\over x} \int_0^x \cos(t^2)\,dt$$ My intuition is that the answer is 1 because as $x$ becomes very small, $x^2$ also becomes very small and I am tempted to write $$\lim_{x\to 0} \int_0^x \cos(t^2)\,dt=\lim_{x\to 0} \int_0^x \cos(t)\,dt$$ And then, because $(\sin x)'=\cos x$ ,
we have $$\lim_{x\to 0} {1\over x} \int_0^x \cos(t^2) \, dt = \lim_{x\to 0} {1\over x} \int_0^x \cos(t) \, dt=\lim_{x\to 0} {1\over x} (\sin x -\sin 0)=\lim_{x\to 0} {\sin x\over x}= 1$$ (well known limit solved with L'Hôpital's rule) But I am pretty sure this is not rigorous and I am doing something I am not 'allowed to', especially the first equality I wrote.","['integration', 'limits', 'real-analysis']"
3412836,Proving that grassmannians are smooth manifolds,"I'm trying to show that real grassmannians $G(k, n)$ are smooth manifolds of dimension $k(n-k)$ .
The problem is set in this way: Identify the set of all real matrices with $n$ rows and $k$ columns with $\mathbb{R}^{kn}$ . Then consider the following equivalence relation on $\mathbb{R}^{kn}$ : $M_1 \sim M_2$ if and only if there exists $L \in GL(k,\mathbb{R})$ such that $M_1=M_2L$ . Then define $G(k, n)=\mathbb{R}^{kn}/ \sim$ . $G(k, n)$ becomes a topological space whose topology is the quotient topology. 
Now, for each subset of $J$ of $\{1, \ldots, n\}$ consisting of $k$ indices, consider the matrix $M_J$ obtained from $M \in \mathbb{R}^{kn}$ taking only the the $k$ rows whose indices are in $J$ and consider the set $$U_J=\{[M]\in G(k, n): detM_J \neq 0\}. $$ Finally, for each $J$ , define the map from $U_J$ to $\mathbb{R}^{k(n-k)}$ given by $$\phi_J([M])= (MM^{-1}_J)_{J^c}$$ where $J^c$ denotes the complement of $J$ in $\{1, \ldots, n\}$ . I think I've managed to show that this map is a homeomorphism, but I'm in trouble when I hace to prove that transitions map between the charts are smooth, i.e. for each $J_1,J_2$ the composition $\phi_{J_1} \circ \phi_{J_2}^{-1}$ is smooth. Any help would be greatly appreciated.","['grassmannian', 'differential-topology', 'differential-geometry']"
3412838,When is the Markov Inequality Equivalent?,For the Markov Inequality: $$\Pr(X > a) \leq \frac{E(X)}{a}$$ What nonnegative random variable $X$ and constant $a > 0$ makes the Markov Inequality equal?,"['statistics', 'proof-writing', 'probability', 'inequality']"
3412926,Is there a way to obtain a strict total order of sets of ordinal rankings?,"Consider a set of three ordinal rankings of three elements $A,B,C$ ; that is, a set of the form $\{\sigma_1,\sigma_2,\sigma_3\}$ where, for example, $\sigma_1 = ABC, \sigma_2 = ACB, \sigma_3 = CAB$ . (Here, $ABC$ is shorthand for $A\succ B\succ C$ , meaning that $A$ is preferable to $B$ , and $B$ is preferable to $C$ .) It's easy to see that we always can relabel the elements such that all sets can be written on the form $\{ABC,\sigma_2,\sigma_3\}$ , and thus reducing the number of sets to $(3!)^2 = 36$ , and since the order of elements in a set doesn't matter, these can in turn be reduced to 10 equivalence classes (two sets are equivalent if one can be obtained from the other by relabeling the elements, e.g. $\{ABC,ABC,ABC\}$ and $\{BAC,BAC,BAC\}$ ): $$P_1 = \{ABC,ABC,ABC\}, P_2 = \{ABC,ABC,ACB\},P_3 = \{ABC,ABC,BAC\},\\
P_4 = \{ABC,ABC,BCA\}, P_5 = \{ABC,ABC,CAB\}, P_6 = \{ABC,ABC,CBA\}\\
P_7 = \{ABC,ACB,BAC\}, P_8 = \{ABC,ACB,BCA\},\\
P_9 = \{ABC,BAC,CAB\},P_{10} = \{ABC,BCA,CAB\}.$$ My aim is to obtain a strict total order between these sets, with respect to ""internal agreement"": For instance, if I compare $P_1 = \{ABC, ABC, ABC\}$ with $P_2 = \{ABC,ABC,ACB\}$ and $P_{10} = \{ABC, BCA, CAB\}$ , we intuitively think that $P_1$ has maximal internal agreement, since the rankings are identical, but in $P_{10}$ there is very little internal agreement. And $P_2$ falls somewhere in between. Therefore, under some yet to be defined strict total order $<$ , one would like to have $$P_1 < P_2< P_{10}.$$ Is there a suitable way to define such an order? It seems that we ought to take the position of the elements into account (analagous to weighted Kendall's $\tau$ for distances between ordinal rankings), so that for example, $$P_1<P_2<P_3,$$ since it should be more ""costly"" to swap the first two elements in any ordering than to swap the last two elements. In short: Can $P_1,\dots,P_{10}$ be strictly totally ordered (no ties) with respect to ""internal agreement"" as discussed above? Any suggestions would be much appreciated. (Even other orders with relaxed conditions, or distance functions with an strict total order of the distances, might be valuable.)","['statistics', 'combinatorics']"
3412957,How to find the set which is written as an intersection of infinite sets?,"I need to find the following set $S = \displaystyle\bigcap_{n=1}^{\infty} \left[2-\dfrac{1}{n} , 3 + \dfrac{1}{n}\right]$ Now using hints from these questions : Union and intersection of the family of sets $[-1,1-\frac1n]$; describe and prove! ,and Does $\bigcup_{n=1}^\infty \left(-\infty, 1-\frac{1}{n}\right) = (-\infty, 1)$? I have tried to solve this problem on my own and would like to know if it is right or wrong. So, I claim : The given set $S =  (2,3)$ Suppose $y \in S$ then clearly $y  \gt 2$ and $y \lt 3$ Hence $y \in (2,3)$ So , $S \subset (2,3)$ Now I am having difficulty in proving the reverse claim ie How can I prove that $(2,3) \subset S$ . I think to produce an $n$ which satisfies the given inequality I need to use Archimedian Property , But I am not sure how to do that. I have two questions at this point. (i) Is my proof upto given point ie $S \subset (2,3)$ correct ? (ii) How can I show the reverse claim ? Thank you.","['elementary-set-theory', 'real-analysis']"
3412959,Working out the analysis of a circuit with non-linear resistor,"I am working on a problem from the Strogatz book, specifically problem 2.2.12. I am having trouble evaluating the fixed point that I found. I have summarized the problem statement here, and show my work below: Suppose a series circuit with a voltage source $V_0$ , a non linear resistor and a capacitor. Assume that the the non linear nature of the resistor is such that $I = g(V)$ , which is graphed in the book and I have tried to reproduce: So, to model the equation: $$V_0 = V_r + Q/C \Leftrightarrow V_r = V_0 - Q/C$$ Where $V_r$ is the voltage drop across the non-linear resistor. Coupling this with the fact (given in the text) that $\dot{Q} = I$ , the function $g(V)$ can be rewritten as $$\dot{Q} = g(V_0 - \frac{Q}{C})$$ and we see that $\dot{Q} = 0$ When $Q = \frac{V_0}{C}$ I thought to use the linearization technique mentioned in this chapter, namely to find out the sign of $f'(Q, t) = \ddot{Q} = -\frac{1}{C}g'(V_0 - \frac{Q}{C})$ at the fixed point. So here is where I get a little stumped. I see that $g'(V_0 - \frac{Q}{C})$ is positive and non-zero at (0,0) and therefore the overall value is negative (stable) due to the factor of $-\frac{1}{C}$ , but I don't know how to determine end behavior. The task was to determine the qualitative differences between this model and the one where voltage drop is simply given by $V_r = I_rR$ . That means, in my mind, that $Q(t) \rightarrow Q^* = V_0 / C$ as $t \rightarrow \infty$ , which is different than the fixed point in the example of a linear resistor. Is that all that the question is asking? But the stability remains the same... except that I recall stability analysis for non-linear equations is supposed to be local only, so maybe there is something else I am missing?","['nonlinear-dynamics', 'ordinary-differential-equations']"
3412976,"Expectations, Double Integrals and Jensen's Inequality","Consider two random variables distributed $v\backsim G(.)$ and $c \backsim F(.)$ with pdfs $g(.)$ and $f(.)$ . Let the supports of $c$ and $v$ be $[x,y]$ . Let $x<a=E(v)<b<y$ , so $[a,b]\subset\lbrack x,y]$ . Now
consider a strictly concave (twice differentiable and continuous) function $u(.)$ , with $u^{\prime}(.)>0$ , $u^{^{\prime\prime}}(.)<0$ , and $u(0)=0$ (passes through the origin). Establish sufficient conditions such that the
expression $\int_{a}^{b}u(E(v)-c)f(c)dc-\int_{a}^{b}\int_{x}^{y}%
u(E(v)-v)g(v)f(c)dvdc\geq0$ $\forall$ $v,c$ , where $E(v)=\int_{x}^{y}vg(v)dv.$ Things I've tried: $\int_{0}^{\bar{v}}u(E(v)-v)g(v)dv\leq0$ by Jensen's inequality. To see
this, let $E(v)-v=t$ . But $E(t)=E_{v}[E(v)-v]=0$ , and so $E(u(t))\leq
u(E(t))=0$ , since $u(0)=0$ by assumption. Clearly, $\int_{a}^{b}u(E(v)-c)f(c)dc\leq0$ , since we are integrating the
integrand $(E(v)-c)$ from $a=E(v)$ to $b$ . Intuitively, a variant of Jensen's inequality should apply if $c$ and $v$ are i.i.d. Let $c$ and $v$ be i.i.d. with identical supports. Then the
integrands are the same, and we have the expression $\int_{a}^{b}%
u(E(v)-v)f(c)dc-\int_{a}^{b}\int_{x}^{y}u(E(v)-v)g(v)f(c)dvdc$ . However, we
can't apply Jensen's inequality directly since $\int_{a}^{b}u(E(v)-v)f(c)dc$ is not $u(E(x))$ , even if we ""factor out"" the outer integrals. $\int_{x}%
^{y}u(.)g(v)dv$ seems to be a form of $E(u(x))$ . At a loss as to what to do here. Any help would be greatly appreciated. Thank you!","['probability-distributions', 'jensen-inequality', 'multivariable-calculus', 'probability-theory', 'probability']"
3413041,Statistics: Central Limit Theorem question,"A commuter encounters four traffic lights each day on her way to work. Let $X$ represent the number of these that are red lights. The probability mass function of $X$ is as follows: \begin{array}{c|ccccc}x&0&1&2&3&4\\\hline\operatorname P(X=x)&0.1&0.3&0.3&0.2&0.1\end{array} What is the probability that in a period of $100$ days, the average number of red lights encountered is more than $2$ per day? I have calculated mean to be $\mu = .038$ and $\sigma =  .04562$ (guessing st. deviation gets divided by $n$ large, which is $100$ ? Following a previous example I saw) I'm struggling figuring out how to get $\operatorname P(X>2)$ . I tried doing $\operatorname P(X \le 2)$ , but once I plug in the math ( $1 - \frac{2-.038}{\sqrt{.04562}}$ using formula $\frac{c-\mu}{\sqrt{\sigma}}$ ), I get a number that I cannot get a $z$ -score out of. I'm assuming some of what I'm doing is right, since I'm trying to follow notes we received in class. Otherwise, I'm having trouble getting the right $z$ -score to find the probability.",['statistics']
3413046,Given the following function how many solutions to $f(x)=0$ are there?,"I have the following function: $f: \mathbb{R} \rightarrow \mathbb{R}$ $f(x)=9^x-5^x-4^x$ And I have to find the number of real soltutions (so not necessarily the solutions themselves, just how many are there) for $f(x)=0$ and $f(x)-2 \sqrt{20^x}=0$ . For $f(x)=0$ this is what I did: $9^x-5^x-4^x=0$ I divided by $9^x$ , $1- \bigg (\dfrac{5}{9} \bigg)^x - \bigg (\dfrac{4}{9} \bigg)^x = 0$ $\bigg (\dfrac{5}{9} \bigg)^x + \bigg (\dfrac{4}{9} \bigg)^x = 1$ Since the left-hand side is the sum of two strictly decreasing functions, I conculded that the left-hand side is strictly decreasing ( $1$ ). So the equation can have at most $1$ solution. By pure guessing, I found that $x=1$ is a solution to the equation and because of ( $1$ ) it is the only solution. So, $f(x)=0$ has only one solution ( $x=1$ to be precise, but this is not necessary). I think I got this right, but if someone finds a mistake, please let me know. My real trouble is at the second part of the problem, where I have to find the number of solutions for: $9^x-5^x-4^x - 2 \sqrt{20^x} = 0$ I don't see how should I approach this. Any help will be appreciated.","['algebra-precalculus', 'functions', 'exponential-function', 'monotone-functions']"
3413054,$200n$ diagonals are drawn in a convex $n$-gon. Prove that one of them intersects at least $10000$ others.,$200n$ diagonals are drawn in a convex $n$ -gon. Prove that one of them intersects at least $10000$ others. There was no information about $n$ in a original problem. Attempt: Choose at random and uniform a diagonal with a probability $p={1\over 200n}$ and let $X$ be a number of diagonals that choosen one intersect. Then $X=X_1+X_2+...+X_{200n}$ where $X_i$ is an indicator for $i$ -th diagonal to cut choosen diagonal. So $$E(X) =  E(X_1) +E(X_2)+...=   P(X_1 = 1)+...$$ I don't know how to calculate/estimate $P(X_i=1)$ . Any ( non )probabilistic solution?,"['graph-theory', 'combinatorial-geometry', 'combinatorics', 'algorithms', 'discrete-optimization']"
3413070,Application of Radon-Nikodym Theorem,"Clearly, this question is an application of Radon-Nikodym theorem. So, I guess all needed to show is $\mu\ll m$ , but I have no clue how to show that here. The question also has hint which I struggle to understand. The hint is; let $g_A:y\to \mu(A+y)$ and define $\nu(A\times E)=\int_Eg_A(y)dm(y)$ . Why do we should define such another measure? What does it give us?","['measure-theory', 'radon-nikodym', 'real-analysis']"
3413082,"If A commutes with both of these matrices, then A must be a scalar multiple of the identity matrix","I am working on the following problem: Let $A$ be a $4 \times 4$ matrix with entries in a field of characteristic zero. Suppose that $A$ commutes with both $\begin{pmatrix} 1 & 0 & 0 & 0\\ 0 & 2 & 0 & 0\\ 0 & 0 & 3 & 0\\ 0 & 0 & 0 & 4 \end{pmatrix}$ and $\begin{pmatrix} 0 & 0 & 0 & 1\\ 1 & 0 & 0 & 0\\ 0 & 1 & 0 & 0\\ 0 & 0 & 1 & 0 \end{pmatrix}$ . Prove that $A$ is a scalar multiple of the identity matrix. I know that $A$ is a scalar multiple of the identity matrix if and only if $AB = BA$ for all other possible $4 \times 4$ matrices $B$ with entries in a field of characteristic $0$ . However, I'm struggling with deducing here that $A$ commuting with these specific matrices forces $A$ to be a scalar multiple of the identity matrix. Does commuting with these specific matrices force $A$ to commute with all $4 \times 4$ matrices with entries in a field of characteristic $0$ ? If so, how can I deduce this? Thanks!","['matrices', 'linear-algebra']"
3413117,Calculating the exponential of an upper triangular matrix,"Find the matrix exponential $e^A$ for $$ A = \begin{bmatrix}
2 & 1 & 1\\
0 & 2 & 1\\
0 & 0 & 2\\
\end{bmatrix}.$$ I think we should use the proberty If $AB = BA$ then $e^{A+B} = e^A e^B$ . We can use that $$\begin{bmatrix}
2 & 1 & 1\\
0 & 2 & 1\\
0 & 0 & 2\\
\end{bmatrix} 
=\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1\\
\end{bmatrix} 
+\begin{bmatrix}
1 & 1 & 1\\
0 & 1 & 1\\
0 & 0 & 1\\
\end{bmatrix}$$ Both matrices obviously commute. But I dont know how to calculate the exponential of $$\begin{bmatrix}
1 & 1 & 1\\
0 & 1 & 1\\
0 & 0 & 1\\
\end{bmatrix}.$$ Could you help me?","['matrices', 'matrix-exponential']"
3413123,Hitori and graph connectivity,"Hitori is a Sudoku-like game. These are its rules: It consists on an $n\times n $ matrix. Its terms are integer numbers
  from $1$ to $n$ . Let's say that each term is in a square. The player must mark every square as white or black. No two white squares in the same row or column can have the same
  number. No two black squares can share a side. The set of white squares is connected (two squares are connected iff they share a side). The solution, that is, the coloring of the squares, is unique. My question is about the ratio of black squares . I have played a good number of games and this ratio seems bounded around 30%, but I don't have the knowledge to find a precise good bound and prove it. I'd like to prove it myself . The lower bound seems related with the 3rd rule. That is, you mark a square as black because you know that other square with the same number in the same row or column is white. There is no other reason for a square to be black. The upper bound seems related to 4th, 5th and 6th rules. That is, you mark a square as white because it is adjacent to a black square, because being it black would make the set of white squares disconnected or simply because there is no white squares with the same number in the same row or column. My thoughts so far : The theorems that I have searched about connectivity of graphs are about minimal cuts to make the graph disconnected. But this is about maximal cuts to make the graph connected. On the other hand, for $n=3$ I have found these boards (0 is white and 1 is black): $$\begin{bmatrix}1&0&0\\0&1&0\\0&0&0\end{bmatrix}$$ $$\begin{bmatrix}1&0&1\\0&0&0\\1&0&1\end{bmatrix}$$ But I suspect that the bounds for the ratio can be improved as $n$ is increasing . Thus, my question is: what graph theory should I study to find these bounds?","['graph-theory', 'recreational-mathematics', 'puzzle', 'discrete-mathematics']"
3413162,"If $f(x) = x(1 - x^n)^{-1/n}$, how many function compositions does it take for $f(f(f(\cdots f(x_0)))) > 1$?","Fix an integer $n \geq 1$ and let $f(x) := x(1 - x^n)^{-1/n}$ . Fix $x_0 \in (0, 1)$ . Then there exists an $N$ (depending on $n$ and $x_0$ ) such that $f(f(f(\cdots f(x_0)))) > 1$ where the function composition occurred $N$ times. Is there a way to estimate the order of magnitude of $N$ depending on $n$ and $x_0$ , like what does $N$ asymptotically look like?","['asymptotics', 'analysis', 'real-analysis']"
3413253,Lindelöf and second countable spaces,"Can anyone give me some examples and non examples of Lindelöf or second countable space and spaces that is Lindelöf but not second countable?   And I understand the definition but find it is hard to visualize and imagine.
I have tried google it but it turns out I only found some silly examples like finite set or empty set. In general, how can one construct a topological space that is Lindelöf or second countable? Someone in stack exchange said the real line with discrete topology is Lindelöf, but I do not think so. We can simply construct an open cover defined by the collection of all the singleton set. And this open cover is well defined since singleton set is open in discrete topology. Hence, by definition it is not Lindelöf. Last question, is (0,1) in the real line equipped with usual topology Lindelöf? I think it is Lindelöf but I could not give any formal proof.
(0,1) fails to be a compact set since we can construct an open cover defined by (1/n,1-1/n) but this open cover does not work so well for arguing for Lindelöf property since quotient number is dense in (0,1). So intuitively I think it is Lindelöf. I wrote a pretty long question. My mothertongue is not English. Hopefully, you guys can understand me.","['general-topology', 'second-countable', 'lindelof-spaces', 'real-analysis']"
3413300,Application of the MacLaurin expansion of $e^2$,"While performing a computation, I came across a problem in which I needed to apply the MacLaurin expansion of $e^2$ $$e^2=\sum_{n=0}^{\infty}\frac{2^n}{n!}$$ I then noticed that similar expansions generated the following results $$\sum_{n=0}^{\infty}\frac{2^nn}{n!}=2\sum_{n=0}^{\infty}\frac{2^n}{n!}=2e^2\tag{1}$$ $$\sum_{n=0}^{\infty}\frac{2^nn^2}{n!}=6\sum_{n=0}^{\infty}\frac{2^n}{n!}=6e^2\tag{2}$$ $$\sum_{n=0}^{\infty}\frac{2^nn^3}{n!}=22\sum_{n=0}^{\infty}\frac{2^n}{n!}=22e^2\tag{3}$$ $$\sum_{n=0}^{\infty}\frac{2^nn^4}{n!}=94\sum_{n=0}^{\infty}\frac{2^n}{n!}=94e^2\tag{4}$$ and that if I found the pattern for the coefficients of $2,6,22,$ and $94$ above, I would be able to find the value for some arbitrary $k$ $$\sum_{n=0}^{\infty}\frac{2^nn^k}{n!}=?\sum_{n=0}^{\infty}\frac{2^n}{n!}=?e^2\tag{5}$$ However, it isn't clear to me why the coefficients are $2,6,22,$ and $94$ . I am therefore curious to understand two related questions Why do the coefficients in $(1)$ through $(4)$ come out to be $2,6,22,$ and $94$ ? Is this an application of geometric series or something similar which I have forgotten? Is there a deeper result that would generate the coefficients for any power of $n^k$ ? I would assume that this wouldn't be independent to $e^2$ and would work for any MacLaurin expansion of $e^x$ for any integer $x$ .","['combinatorics', 'taylor-expansion', 'sequences-and-series']"
3413310,Length of a cycle is $3k$ if every cycle has length of $\geq 5$,"Let $G$ be a simple graph G such that every vertex has degree at least $k\geq 3$ and every cycle of $G$ has length at least $5$ . Show that $G$ contains a cycle of length at least $3k$ . Let $P$ be a path of maximum length. By contradiction, assume that the longest cycle has length at most $3k − 1$ . I want to show that $G$ has a cycle of length $4$ . I tried to mimic the method in Diestel Proposition 1.3.1 to get the proof, but it didn't work. Any hint would be highly appreciated.","['graph-theory', 'discrete-mathematics']"
3413320,Proof of conjecture concerning numerically satisfactory pairs of solutions to generalized Airy equation?,"Question: Given a generalized Airy equation of the form $$
\frac{d^2y}{dx^2}-x^ny=0
$$ I conjecture that the following functions form a pair of linearly independent, numerically satisfactory solutions for $n\in \{0,1,2,3,4,...\}$ . How is this proven? $$
A_n(x)=\frac{_0F_1(;\frac{n+1}{n+2};\frac{x^{n+2}}{(n+2)^2})}{(n+2)^{\frac{n+1}{n+2}} \ \ \Gamma(\frac{n+1}{n+2})}-x\frac{_0F_1(;\frac{n+3}{n+2};\frac{x^{n+2}}{(n+2)^2})}{(n+2)^{\frac{n+3}{n+2}-1} \ \ \Gamma(\frac{n+3}{n+2}-1)} \\ 
$$ $$
B_n(x)=\frac{_0F_1(;\frac{n+1}{n+2};\frac{x^{n+2}}{(n+2)^2})}{(n+2)^{\frac{n+1}{n+2}-\frac{1}{2}} \ \ \Gamma(\frac{n+1}{n+2})}+x\frac{_0F_1(;\frac{n+3}{n+2};\frac{x^{n+2}}{(n+2)^2})}{(n+2)^{\frac{n+3}{n+2}-1-\frac{1}{2}} \ \ \Gamma(\frac{n+3}{n+2}-1)}
$$ Context: First, I already know that these functions are solutions because the confluent hypergeometric limit functions within them are simply the series solutions obtained through a straightforward solution attempt with a power series method . Second, I suspect that they are all linearly independent because these linear combinations appear to have a Wronskian given by $$
W\{A_n(x),B_n(x)\}=\frac{2\sin{(\frac{\pi}{n+2}})}{\pi\sqrt{n+2}}
$$ I have verified this Wronskian up to $n=8$ in Mathematica, but I'm not sure how to prove it. Furthermore, just for clarity, it's worth noting that these solutions reduce for the $n=0$ and $n=1$ cases to $$
A_0(x)=\frac{1}{\sqrt{2\pi}}e^{-x} \\ 
B_0(x)=\frac{1}{\sqrt{\pi}}e^x \\
A_1(x)=\text{Ai}(x) \\
B_1(x)=\text{Bi}(x) \\
$$ I have tested all of the pairs of solutions possible up to the limits of the numerical precision of Mathematica and found that $A_n(x)$ always converges to $0$ as $x\rightarrow\infty$ while $B_n(x)$ always diverges in the same limit. Likewise, for odd $n$ both solutions appear to oscillate exactly $\frac{\pi}{2}$ out of phase with one another as $x\rightarrow-\infty$ . These are (basically) the conditions set forward by J. C. P. Miller in the linked article for numerical satisfaction. However, I discovered these specific linear combinations through inspection. I have no idea why these constants are the ones that work. If you alter the constants even slightly, the solutions diverge wildly and no longer satisfy any of Miller's criteria. How could I have deduced the form of these solutions more systematically? Is there a proof to demonstrate that these specific solutions are the preferred ones? I know that there is a connection to the modified Bessel functions , but I don't really see it. There is clearly a hidden structure here that I'd like to understand and (hopefully) generalize to other, similar ODE families.","['ordinary-differential-equations', 'proof-writing', 'numerical-methods', 'airy-functions', 'hypergeometric-function']"
3413373,Low-rank covariance matrix,"I'm reading a paper in the context of high-dimensional data where the authors propose to estimate a $p\times p$ unknown covariance matrix $\Sigma$ with a $p\times p$ matrix $\tilde{\Sigma}$ that has low rank $r<p$ . Despite doing this, they don't give an intuition about the motivation of this approach. What are the consequences (or benefits) of having a low-rank estimation of $\Sigma$ ? All that I can think of is the connection with PCA: computing the eigenvectors of the low-rank estimation $\tilde{\Sigma}$ I will have the principal components. But why is this useful when I can compute the classical estimator $\hat{\Sigma}=n^{-1}X^{T}X$ (for $n\times p$ centered data $X$ ) and then compute the eigenvectors?","['statistical-inference', 'statistics', 'linear-algebra']"
3413439,How to study this sequence $u_n=\sum_{k=1}^{n}\frac{1}{n+2k}$,Please is there any way to prove that sequence is increasing ? I do: $u_{n+1}-u_n=\sum_{k=1}^{n+1}\frac{1}{(n+1)+2k}-\sum_{k=1}^{n}\frac{1}{n+2k}=\left[\frac{1}{n+3}+\frac{1}{n+5}+\ldots+\frac{1}{3n+1}+\frac{1}{3n+3}\right]-\left[\frac{1}{n+2}+\frac{1}{n+4}+\ldots+\frac{1}{3n}\right]$ i don't know how to continue,"['sequences-and-series', 'real-analysis']"
3413495,"Showing that if $ lim_{n \rightarrow \infty } \sin(nx)=0$, then...","let be $ x \in \mathbb{R} $ I want to show that if $$  \lim_{n \rightarrow \infty } \sin(nx)=0 $$ then $$\sin(x)=0 $$ Do you have any ideas for ways to prove it?
I don't know how to get there..
maybe using the fact that $\sin(a+b)= \sin(a)\cos(b)+\cos(a)\sin(b)..$ ? thanks for any help!","['limits', 'calculus', 'trigonometry']"
3413537,"How many of the words contain the text string ""mat"" somewhere in the word?","This problem consists of three problems. (i) How many different words can be made by rearrangement of the letters in the word ""matematik""? my answer $$\frac{n!}{k_m! \cdot k_a! \cdot k_t! \cdot} = \frac{9!}{2!\cdot2!\cdot2!}= \frac{9!}{8} = 9 \cdot 7!$$ (ii) How many of these words starts and ends with ""t""? I just removed the two ""t"" from the word ""matematik"", so now I have ""maemaik"". My calculations are as follows $$\frac{n!}{k_m! \cdot k_a!} = \frac{7!}{2! \cdot 2!} = \frac{7!}{4} $$ (iii) How many of the words contain the text string ""mat"" somewhere in the word? How should I understand this question? Understanding 1: How many of the words found in (i) contain one ""mat""? Understanding 2: How many of the words found in (i) contained at least one ""mat""? If assume understanding 2 is the right way to read, my answer is (per intuition) $$7!-\frac{5!}{2!}$$ I'm not sure how to explain my calculation with words. (Probably because my understanding is not sufficent). PS 1 The word ""matematik"" is danish. It means ""mathematics"". PS 2 The problem has been translated from Danish into English. The original problem had som ambiguity which has been eliminated. PS 3 Also, ""matematik"" is a word. But ""amtematik"" is not a word. Our professor should have used ""text string"" in stead of $word$ in the formulation of the problems.","['combinatorics', 'discrete-mathematics']"
3413569,Find a vector NOT perpendicular to a given set of vectors,"Let us suppose to have a finite set of vectors $S=\{v_1,\ldots,v_m\}$ in $\mathbb{R}^n$ (with $m \gg n$ in general). I need to find a vector $x \in \mathbb{R}^n$ that is NOT perpendicular to any vector in $S$ . The existence of such a vector $x$ is guaranteed, moreover almost every vector in $\mathbb{R}^n$ satisfies this property. But I need to find an algorithm to determine a vector with these properties, I cannot close my eyes and choose. Any ideas? EDIT1: in my case, the vectors in $S$ have some ""symmetries"" in the sense that they are generated by permutation and change of signs of a few vectors in $S$ EDIT2: $v_1+\ldots+v_m=0 \in \mathbb{R}^n$ EDIT3: I simplified the solution proposed by Tom Collinge. We define a sequence $\{x_i\}_{i=1}^m$ such that $x_m=x$ is what we are looking for. First define $x_1=v_1$ , so $x_1 \cdot v_1 \ne 0$ and they are not perpendicular (obviously). Then, recursively, define for $k \in \{2,\ldots,m\}$ $$
x_k=\begin{cases}
x_{k-1}+2v_k & \text{if }x_{k-1}=-v_k\\
x_{k-1}+v_k & \text{otherwise}
\end{cases}.
$$ By construction we have that $x_k \cdot v_i \ne 0$ for $i \le k$ , then $x_m \cdot v_i \ne 0$ for all $v_i \in S$ , so $x=x_m$ is not perpendicular to every element in $S$ . Can it works? EDIT4: As pointed out, the algorithm proposed in EDIT3 does not work","['orthogonality', 'linear-algebra']"
3413586,Conjectural closed-form of $\int_0^1 \frac{\log^n (1-x) \log^{n-1} (1+x)}{1+x} dx$,"Let $$I_n = \int_0^1 \frac{\log^n (1-x) \log^{n-1} (1+x)}{1+x} dx$$ In a recently published article , $I_n$ are evaluated for $n\leq 6$ : $$\begin{aligned}I_1 &= \frac{\log ^2(2)}{2}-\frac{\pi ^2}{12} \\ I_2 &= 2 \zeta (3) \log (2)-\frac{\pi ^4}{360}+\frac{\log ^4(2)}{4}-\frac{1}{6} \pi ^2 \log ^2(2) \\
I_3 &= \small 6 \zeta (3)^2+6 \zeta (3) \log ^3(2)-2 \pi ^2 \zeta (3) \log (2)+24 \zeta (5) \log (2)-\frac{23 \pi ^6}{2520}+\frac{\log ^6(2)}{6}-\frac{1}{4} \pi ^2 \log ^4(2)-\frac{1}{12} \pi ^4 \log ^2(2) \\
I_4 &= \small{-12 \pi ^2 \zeta (3)^2+288 \zeta (3) \zeta (5)+12 \zeta (3) \log ^5(2)-12 \pi ^2 \zeta (3) \log ^3(2)+168 \zeta (5) \log ^3(2)+108 \zeta (3)^2 \log ^2(2)-2 \pi ^4 \zeta (3) \log (2)-48 \pi ^2 \zeta (5) \log (2)+720 \zeta (7) \log (2)-\frac{499 \pi ^8}{25200}+\frac{\log ^8(2)}{8}-\frac{1}{3} \pi ^2 \log ^6(2)-\frac{19}{60} \pi ^4 \log ^4(2)-\frac{1}{6} \pi ^6 \log ^2(2)}
\end{aligned}$$ Based on these evidences, the author (me) made the conjecture that For positive integer $n$ , $I_n$ is in the algebra over $\mathbb{Q}$ generated by $\log(2)$ and $\{\zeta(m) | m\in \mathbb{Z}, m\geq 3\}$ . The closed-form of $I_5, I_6$ also satisfy this conjecture. $I_5$ is: -20\pi^4\zeta(3)^2+7200\zeta(5)^2-960\pi^2\zeta(3)\zeta(5)+14400\zeta(3)\zeta(7)+20\zeta(3)\log^7(2)-40\pi^2\zeta(3)\log^5(2)+600\zeta(5)\log^5(2)+600\zeta(3)^2\log^4(2)-\frac{76}{3}\pi^4\zeta(3)\log^3(2)-560\pi^2\zeta(5)\log^3(2)+8640\zeta(7)\log^3(2)-360\pi^2\zeta(3)^2\log^2(2)+10080\zeta(3)\zeta(5)\log^2(2)+1440\zeta(3)^3\log(2)-\frac{20}{3}\pi^6\zeta(3)\log(2)-112\pi^4\zeta(5)\log(2)-2400\pi^2\zeta(7)\log(2)+40320\zeta(9)\log(2)-\frac{149\pi^{10}}{1320}+\frac{\log^{10}(2)}{10}-\frac{5}{12}\pi^2\log^8(2)-\frac{7}{9}\pi^4\log^6(2)-\frac{19}{18}\pi^6\log^4(2)-\frac{47}{60}\pi^8\log^2(2) $I_6$ is: 10800\zeta(3)^4-100\pi^6\zeta(3)^2-36000\pi^2\zeta(5)^2-3360\pi^4\zeta(3)\zeta(5)-72000\pi^2\zeta(3)\zeta(7)+1123200\zeta(5)\zeta(7)+1209600\zeta(3)\zeta(9)+30\zeta(3)\log^9(2)-100\pi^2\zeta(3)\log^7(2)+1560\zeta(5)\log^7(2)+2100\zeta(3)^2\log^6(2)-140\pi^4\zeta(3)\log^5(2)-3000\pi^2\zeta(5)\log^5(2)+47520\zeta(7)\log^5(2)-3000\pi^2\zeta(3)^2\log^4(2)+90000\zeta(3)\zeta(5)\log^4(2)+24000\zeta(3)^3\log^3(2)-\frac{380}{3}\pi^6\zeta(3)\log^3(2)-2040\pi^4\zeta(5)\log^3(2)-43200\pi^2\zeta(7)\log^3(2)+739200\zeta(9)\log^3(2)-1140\pi^4\zeta(3)^2\log^2(2)+388800\zeta(5)^2\log^2(2)-50400\pi^2\zeta(3)\zeta(5)\log^2(2)+777600\zeta(3)\zeta(7)\log^2(2)-7200\pi^2\zeta(3)^3\log(2)-47\pi^8\zeta(3)\log(2)-560\pi^6\zeta(5)\log(2)+302400\zeta(3)^2\zeta(5)\log(2)-8880\pi^4\zeta(7)\log(2)-201600\pi^2\zeta(9)\log(2)+3628800\zeta(11)\log(2)-\frac{4714153\pi^{12}}{5045040}+\frac{\log^{12}(2)}{12}-\frac{1}{2}\pi^2\log^{10}(2)-\frac{37}{24}\pi^4\log^8(2)-\frac{253}{63}\pi^6\log^6(2)-\frac{527}{72}\pi^8\log^4(2)-\frac{223}{36}\pi^{10}\log^2(2) Question : How to prove the conjecture for general $n$ ? Any suggestion is appreciated. Some remarks: Even $I_3,I_4,I_5,I_6$ are extremely challenging, someone
    brave enough might want to embark on finding them independently. $I_n$ is not related to beta function in an obvious way, so the
    well-known differentiation trick does not work here. For any $I_n$ , the algorithm outlined in the article should 
        produce closed-form of $I_n$ in a finite amount of time if the
        conjecture is true. However, the algorithm is a bit mechanical, so
        benefits little toward a proof for general $n$ . Perhaps I am missing something, this conjecture is elementary to
state, so it might have an easy proof and I was being negligent.","['integration', 'definite-integrals', 'polylogarithm', 'closed-form', 'zeta-functions']"
3413594,Finding the coefficient of an ODE,"The real constants $𝑎_3,𝑎_2,𝑎_1,𝑎_0$ are such that the ODE $$𝑦^{(4)}+𝑎_3𝑦^{(3)}+𝑎_2𝑦''+𝑎_1𝑦'+𝑎_0𝑦=0$$ has $3𝑡𝑒^{−𝑡}+𝑒^{−4𝑡}\sin(𝑡)$ as a solution. What is $𝑎_0$ ? I would really like some help in solving this problem. The hint was to figure out the characteristic polynomial first, which is $$r^4 + a_3r^3 + a_2r^2 + a_1r + a_0 = 0.$$ While I could plug in the given solution in, that'd be too complicated. I've tried to see if I could simplify the expression $3𝑡𝑒^{−𝑡}+𝑒^{−4𝑡}\sin(𝑡)$ further into one term, but so far haven't really found a way to do so. Any help would really be appreciated!","['linear-algebra', 'characteristic-functions', 'ordinary-differential-equations', 'roots']"
3413622,Clarification of the sample space of stochastic processes,"I have encountered two different definitions of a stochastic process. The first definition tells me that every outcome is associated with a deterministic function of $t$ (every outcome maps to one sample path in the ensemble). A stochastic process can therefore be regarded as a $S^t$ -valued random variable, and the sample space is the sample space of that random variable. Fine. The second definition tells me to consider a stochastic process as a sequence of random variables on a probability space $(\Omega, \mathscr F, P)$ . One outcome in $\Omega$ results in a mapping for each and every random variable in the sequence (such that a ""deterministic"" function of time is created). Fine. What I would like to have clarified is if the two definitions always refer to the exact same ""sample space""? The first definition refers to the sample space of the $S^t$ -valued random variable, and, the second definition refers to the sample space shared by all the random variables in the sequence. Are these sample spaces the same (always)? Is it called the sample space of the stochastic process?","['stochastic-processes', 'probability-theory']"
3413628,"Possible to get a closed form expression, or an upper bound, for $ f(n)=\sum_{m=1}^\infty \bigg(\frac{m+n}{3}\bigg)^{m+n}\bigg(\frac{1}{m}\bigg)^m$?","Is it possible to get a closed form expression, or an upper bound, for the following function $f$ which is given by an infinite summation: $$
f(n) = \sum_{m=1}^\infty \bigg(\frac{m+n}{3}\bigg)^{m+n} \bigg(\frac{1}{m}\bigg)^m,
$$ for $n > 0$ ? Also, $n$ can be assumed to be large if this is any help. Note when $n=0$ , it is simply $$
f(0) = \frac{1}{2}.
$$","['summation', 'sequences-and-series', 'closed-form', 'real-analysis']"
3413696,Computing the nth derivative using the binomial theorem.,"Let n be an element of the set of  natural numbers Let $F(x)=x^2(1+x)^n$ and write $F^n$ for the nth derivative of the function $F$ . Compute $F^n$ by applying the Binomial Theorem to $(1+x)^n$ . I don't understand the step where I need to find the derivative of these terms: = $x^2 + {n \choose 1}x^3 + {n \choose 2} x^4 + .... + {n \choose n-1} x^{n+1} + x^{n+2} $ Even though I do understand how to show that for the first 3 terms the nth derivative is 0, but for the last two I have no clue?? Really appreciate any hints!!","['binomial-theorem', 'derivatives']"
3413740,Integrate $\int {\dfrac{x^2+\left(n-1\right)n}{\left(x\sin x+n\cos x\right)^2}}dx $,"$$\int {\dfrac{x^2+\left(n-1\right)n}{\left(x\sin\left(x\right)+n\cos\left(x\right)\right)^2}}dx $$ My Try: I multiple $x^{2n-2}$ to both N and D, then took D as $u$ and then solved to get $\dfrac{n\sin\left(x\right)-x\cos\left(x\right)}{x\sin\left(x\right)+n\cos\left(x\right)} + C$ as answer. My teacher told that this would have been much easier if we had applied linearity and written question as $={\displaystyle\int}\dfrac{x\sin\left(x\right)+\left(n-1\right)\cos\left(x\right)}{x\sin\left(x\right)+n\cos\left(x\right)}\,\mathrm{d}x-{\displaystyle\int}\dfrac{\left(\left(1-n\right)\sin\left(x\right)+x\cos\left(x\right)\right)\left(n\sin\left(x\right)-x\cos\left(x\right)\right)}{\left(x\sin\left(x\right)+n\cos\left(x\right)\right)^2}\,\mathrm{d}x$ I didn't get it, how did we write the above statement? I mean, please explain the method or steps for reaching to this part.","['integration', 'indefinite-integrals', 'trigonometric-integrals']"
3413797,Why is $y''(x)=f''(u)\cdot [g'(x)]^2$ not correct?,"Denote the 2-oder difference of $y=f(x)$ as $\Delta^2 y$ , namely \begin{align*} \Delta^2y&=\Delta(\Delta y)\\&=\Delta (f(x+\Delta x)-f(x))\\ &=f(x+\Delta x+\Delta x)-f(x+\Delta x)-(f(x+\Delta x)-f(x))\\ &=f(x+2\Delta x)-2f(x+\Delta x)+f(x).\\ \end{align*} If $f(x)$ is twice differentiable , then we can prove that \begin{align*} \lim_{\Delta x \to 0}\frac{\Delta^2 y}{(\Delta x)^2}&=\lim_{\Delta x \to 0}\frac{f(x+2\Delta x)-2f(x+\Delta x)+f(x)}{(\Delta x)^2}\\ &=\lim_{\Delta x \to 0}\frac{2f'(x+2\Delta x)-2f'(x+\Delta x)}{2\Delta x}\\ &=\lim_{\Delta x \to 0}\frac{f'(x+2\Delta x)-f'(x+\Delta x)}{\Delta x}\\
&=f''(x),\end{align*} which shows that $$\lim_{\Delta x \to 0}\frac{\Delta^2 y}{(\Delta x)^2}=\frac{{\rm d}^2 y}{({\rm d}x)^2}.$$ But, if we construct a composite function $y=y(x)$ with $y=f(u),u=g(x)$ ，where $f,g$ are also twice differentiable . Then $$\lim_{\Delta x \to 0}\frac{\Delta^2 y}{\Delta x^2}=\lim_{\Delta x \to 0}\left(\frac{\Delta^2 y}{(\Delta u)^2}\cdot \frac{(\Delta u)^2}{(\Delta x)^2}\right),$$ which seems to imply $$y''(x)=f''(u)\cdot [g'(x)]^2.$$ Of course, this is obviously not correct. But where does the misitake occur?","['calculus', 'derivatives']"
3413821,what is the particular solution of $y'' - y= -cos(x)$?,"I solved it like this $r^2 - 1= 0 \Rightarrow r=1,-1$ , so the roots are real, this means the complementary function will be of the form $$y = A \exp(x)+ B \exp(-x).$$ Then, I tried to find the particular solution using variation of parameters method, I got particular solution $y=\frac{9}{4}\sin(x) -\frac{7}{4}\cos(x)$ . Is this correct?",['ordinary-differential-equations']
3413917,The principal directions bissect the asymptotic directions,"I was trying to prove that: At a hyperbolic point, the principal directions bissect the asymptotic directions. Well, I tried to use the Euler's formula: Being $dN_p$ with eigenvalues $k_1,k_2$ , eigeinvectors $e_1,e_2$ , take $v$ one asymptotic direction. So, write $v=\cos\theta e_1+\sin \theta e_2$ , $\theta $ the angle from $e_1$ . We have: $$II_p(v)=0\iff\\
0=\cos^2\theta k_1+\sin^2 \theta k_2\iff\\
\sin^2 \theta=\dfrac{-k_1}{k_2-k_1};\cos^2\theta=\dfrac{k_2}{k_2-k_1}.$$ To get bissection, I thought that I should obtain $\sin^2 \theta=\cos^2\theta$ . I cannot finish. Many thanks in advance.","['surfaces', 'vector-fields', 'conic-sections', 'curvature', 'differential-geometry']"
3413918,Intersection of circles lie on an angle bisector,"Let $ A_1,B_1,C_1 $ be the tangency points of the intersection of the excircles of a triangle $ ABC $ with the sides $ BC,CA,AB, $ respectively. Prove that the circumcircles of $ ABB_1 $ and $ ACC_1 $ meet on a bisector of $ \angle BAC. $ What I thought: Circle $(ABB_1)$ has $\omega_1=b(s-a)$ and circle $(ACC_1)$ has $v_2=c(s-a)$ .
Their radical axis is given by $-yc(s-a)+zb(s-a)$ which is equation of $A$ angle bisector and we are done.","['contest-math', 'euclidean-geometry', 'geometry']"
3413923,"For continuous $f$ and $g$, $\{x \in X: f(x)=g(x)\}$ is closed","$\mathbf{Question}:$ Let $(X,d_1)$ and $(Y,d_2)$ be two metric spaces and $f,g: X \mapsto Y$ be two continuous functions. Then prove that $\{x \in X: f(x) =g(x)\}$ is closed in $X$ . Approach: We consider the function $h: X \mapsto \mathbb{R^+}\cup \{0\}$ defined by $h(x)=d_2(f(x),g(x))$ Lemma 1: $h(x)$ is continuous on $X$ . Proof: We have $d_2(f(x),g(x))+d_2(g(x),g(c))+d_2(f(x),f(c))\geq d_2(f(c),g(c))\implies d_2(g(x),g(c))+d_2(f(x),f(c))\geq d_2(f(c),g(c))-d_2(f(x),g(x))$ . Symmetry gives us $d_2(g(x),g(c))+d_2(f(x),f(c))\geq d_2(f(x),g(x))-d_2(f(c),g(c))$ Now, for any $\epsilon>0$ , $\exists$ $\delta>0$ such that $d_2(g(x),g(c))< \epsilon/2$ and $d_2(f(x),f(c))<\epsilon/2$ whenever $d_1(x,c)<\delta$ . Hence, we conclude $\forall \epsilon>0, \ \exists \delta>0$ such that $|h(x)-h(c)|<\epsilon$ whenever $d_1(x,c)<\delta$ , which establishes the lemma. Now, $h(x)=0$ , iff $f(x)=g(x)$ . We know that $\{0\}$ is a closed set in $\mathbb{R^+}\cup \{0\}$ and that the inverse image set of a closed set under a continuous mapping is a closed set. Hence $\{x \in X: h(x)=0\} \equiv \{x \in X: f(x)=g(x)\}$ is a closed set in $X$ . $\mathbf{Follow-up \ question}:$ If $A \subseteq X$ is dense in $X$ and $f(x)=g(x), \forall x \in A$ , then $f=g$ on $X$ . Attempt: By the previous theorem, $D=\{x \in X: f(x)=g(x)\}$ is closed in $X$ . Now, suppose, for some $k \in X \setminus A$ , $f(k) \neq g(k)$ . But, $A\subset D \implies A' \subset D'$ (derived set) $\implies k \in D'$ but $k \notin D$ which contradicts the fact that $D$ is closed. Is this correct? Please verify.","['continuity', 'general-topology', 'proof-verification', 'metric-spaces']"
3413944,Why is this ODE classified as non-autonomous?,"In my textbook, the following $$\frac{d^2{x}}{d{t^2}}-\alpha x\frac{d{x}}{d{t}}-x+x^3=\sin (\omega t) $$ is given as an example of a non-autonomous ODE, without explanation. From my understanding, an ODE is non-autonomous when the coefficient of the dependent variable and its derivatives depend on the independent variable. In this case does $1$ count as a derivative of the dependent variable and therefore it is being multiplied by $\sin (\omega t)$ ?",['ordinary-differential-equations']
