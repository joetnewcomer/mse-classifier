question_id,title,body,tags
2427918,probabilities on multiple choice questions,"I am setting a series of multiple choice questions. I have a range of option answers from 2 to 7. Some questions only have a single correct answer and others have more. 
I can tell the person taking the test what number are correct, or I can just tell them to 'select all that are correct'.
Is there a difference in the probability of someone guessing correctly between the two scenarios? I am, by the way, absolutely clueless at maths so please dumb your answer down to the lowest common denominator! eg Yes- if you tell them there are two correct answers it is xx:yy and if you don't tell them it is aa:bb.
Thank you.",['probability']
2428015,Prove that at a party of $25$ people there is one person knows at least twelve people.,"So, the full problem goes like this: There are $25$ people at a party. Assuming that among any three people, at least two of them know each other, prove that there exists one person who must know at least twelve people. I've been stuck on this problem for a while and haven't really figured out how to proceed. I'm pretty sure that there is an answer that can be found via the pigeonhole principle or some graph theory, but I'm not really sure how to get started. Any help would be appreciated.","['graph-theory', 'pigeonhole-principle', 'combinatorics', 'contest-math', 'discrete-mathematics']"
2428031,Convergence of ADM mass on asymptotically flat manifolds,"Hey dear mathematicians, I just read about Riemannian geometry and didn't understand this: Given a $n$-dimensional Riemannian manifold $(M,g)$ with a specific asymptotic such that the scalar curvature $R$ is given as $R=\sum_{i,j} \left( \partial_{i}\partial_{j}g_{ij} - \partial_{j}\partial_{j}g_{ii} \right) + \mathcal{O}(|x|^{-2p-2})$, where $2p+2>n$. Now the divergence theorem ensures the existence of $\lim\limits_{r \to \infty} \int_{\mathbb{S}_{r}} \sum_{i,j} \left( \partial_{i}g_{ij} - \partial_{j}g_{ii} \right)\nu_{j}\text{d}\xi(r)$, where $\nu=x/r$ is the Euclidean unit normal to $\mathbb{S}_r$ and $\text{d}\xi(r)$ is the Euclidean area element of $\mathbb{S}_r$. I don't understand this implication, can someone clarify this?
Thanks in advance! Sincerely, schoeni","['riemannian-geometry', 'general-relativity', 'divergence-operator', 'manifolds', 'differential-geometry']"
2428051,A Finite Boolean Ring is Generated by Finitely Many Copies of $\mathbb{Z} / 2 \mathbb{Z}$,"I'm trying to prove that every finite Boolean ring, $R$, is isomorphic to a finite number of copies of $\mathbb{Z} / 2 \mathbb{Z}$: \begin{align}
R \cong \mathbb{Z} / 2 \mathbb{Z} \; \times \cdots \; \times \; \mathbb{Z} / 2 \mathbb{Z}
\end{align} I'm aware that there are answers to this question on this website. However, almost all of the answers seem to use facts about modules and vector spaces defined over fields. This question is posed in section 7.6 in Dummit and Foote's Abstract Algebra . This section is part of the chapters which introduces the basics of ring theory (rings, homomorphisms, ideals, Chinese Remainder Theorem etc.). I'm not even sure how to being answering this question. I know that if $R$ were an integral domain, then we would have that $R \cong \mathbb{Z} / 2 \mathbb{Z} $. Please only give hints, considering that that the statement has to be proved using the material only included up till chapters 9 in the textbook.","['abstract-algebra', 'ring-theory', 'boolean-ring']"
2428053,Integral curves,"Suppose $f$ is a vector field. Let $g$ be an integral curve whose domain contains $[0,\infty)$. Now $\lim (g(t)) =p$ as $t \to \infty$. Then can we say that $f(p)$ is zero?","['differential', 'ordinary-differential-equations', 'geometry']"
2428099,Is $ \left(\frac{1}{2}\right)^n < \frac{1}{n}\left(\frac{n-1}{n}\right)^{n-1}$ true for $n \ge 3$?,"I have reason* to believe that the following inequality holds: $$ \left(\frac{1}{2}\right)^n < \frac{1}{n}\left(\frac{n-1}{n}\right)^{n-1}$$ for every $n\ge3$. I am having hard time proving it... (induction did not work). (Comment: For $n=2$ there is an equality). *My reasoning is very convoluted and is related to an entirely different problem, I am sure there is a straightforward argument.","['derivatives', 'inequality', 'logarithms', 'exponential-function', 'calculus']"
2428103,"Invariant notion of pseudovector, again","I know there is a lot of topics about pseudovectors (see 1 , 2 , 3 ), but I am not really satisfied with the answers in this topics, let me explain why. Let $V$ is some vector space such that $\dim V = 3$, then in all topics above offer think about pseudovectors as about elements of $\wedge^2 V$, but for me pseudovector is element of $\star(\wedge^2 V)$ where $\star$ is Hodge star operator. So for me $a \wedge b$ is $2$-vector and $\star(a \wedge b)$ is pseudovector. The problem is after using hodge star on $2$-vector we can't remember that this is actually pseudovector. So, i am interesting about next notion of pseudovector. Let $(V, \mathcal{O})$ is some vector space with fixed orientation and $\operatorname{inv} : (V, \mathcal{O}) \to (V, -\mathcal{O})$ is natural operator which reverse orientation, then pseudovector $p$ is such object that Can be naturally constructed from vector $v \in (V,\mathcal{O})$, $p = p(v)$ Satisfied to identity $\operatorname{inv}(p(v)) = -p(\operatorname{inv}(v))$ Codomen of Hodge star restricted on $(\wedge^2 V, \wedge^2 \mathcal{O})$, is actually pseudovectors of $(V, \mathcal{O})$ not vectors. Does such notion exists? Thank you.","['differential-geometry', 'linear-algebra', 'definition']"
2428150,$BV$ function with prescribed jump,"Let $S\subset \mathbb{R}^n$ be a set of Hausdorff dimension $n-1$ and measure theoretic normal $\nu$.  I will use $\mu$ to denote the restriction of $\mathcal{H}^{n-1}$ to $S$.  That is, $\mu(E) = \mathcal{H}^{n-1}(E\cap S)$. Suppose also that $f:S\to\mathbb{R}$ is a 
$\mu$-measurable function such that 
$$
\int_S |f(x)|\,d\mathcal{H}^{n-1} < \infty.
$$ Does there necessarily exist a function with bounded variation 
  $u\in BV(\mathbb{R}^n)$ such that the jump part of the total variation of
  $u$ is precisely $f\mu$? I believe that the answer is yes when both $S$ and $f$ are smooth.  For example, one can construct functions whose jump set is precisely the intersection of the hyperplane $\{x_n=0\}$ with the unit ball, and whose jump is constant.  With a covering argument, this gives the result when $S$ and $f$ are smooth. However, when $S$ is not smooth it seems much harder to patch together functions that have the correct jumps.","['geometric-measure-theory', 'real-analysis', 'measure-theory']"
2428163,Prove that the golden ratio is irrational by contradiction,"I am struggling to see where the contradiction lies in my proof. In a previous example, $1/\phi = \phi-1$ where $\phi$ is the golden ratio $\frac{\sqrt{5} + 1}{2}$. Since I am proving by contradiction, I started out by assuming that $ϕ$ is rational. Then, by definition, there exists $a,b$ such that $\phi = a/b$. After some simple calculations and using the result shown from my previous example, I found that $\phi= b/(a-b)$. I also know that $b < a$ from directly calculating the ratio. I know there is a contradiction in the result $ϕ = b/(a-b)$ but I cannot see it. Any help would be appreciated.","['golden-ratio', 'analysis', 'elementary-number-theory']"
2428177,Questions on Nonlinear Elliptic Theory by Schauder,"I recently started to study about Elliptic theory and below is a brief introduction  my professor made: Let $\;u:\mathbb R^n \to \mathbb R\;$ and $\;f:\mathbb R \to \mathbb
 R\;$ two functions which satisfy the following: $\;\Delta u=f(u(x))\;$ Boundary conditions over $\;\Omega\;$=open,bounded subset of $\;\mathbb R^n\;$ If $\;f\in C^\alpha\;$ then $\;u\in C^{2+\alpha}\;$. In addition
  $\;{\vert u \vert}_{C^{2,\alpha}(\Omega)} \le K {\vert f
 \vert}_{C^\alpha(\Omega)}\;$ where $\;K\;$ is a positive constant. He also mentioned that these estimates are due to Schauder and explained to me the ""bootstrap"" argument. Questions: I would like to study this result in more details but I can't find this Theorem anywhere. Are there any suggestions of books that might be helpful here? I was wondering if I could use the above in this system of equations:
$\;\Delta u_i=f_{u_i}(u(x))\;$ where $\;f_{u_i}=\frac {\partial f}{\partial u_i}(u)\;\;\;\forall 1\le i \le m\;$ and $\;u:\mathbb R^n \to \mathbb R^m\;$. The fact that I have $\;f_{u_i}(u(x))\;$ instead of $\;f_{u_i}(u_i(x))\;$ confuses me a lot. EDIT: After the suggestion in the answer below I searched on Gilbarg & Trudinger 's book and I came across with this Theorem: It seems to me it's quite close to the introduction my professor made. Although the extra term $\;{\vert u \vert}_{0;B_2}\;$ confuses me a lot. I tried to read about the norms and the notation of this chapter but I'm having a really hard time getting my head around them. I would appreciate if somebody could enlighten me about these. Is Theorem 4.6 the right one? Any help would be valuable. Thanks in advance!","['partial-differential-equations', 'regularity-theory-of-pdes', 'elliptic-equations', 'multivariable-calculus', 'elliptic-operators']"
2428187,$\epsilon-\delta$ limit proof,"Using the epsilon delta definition of limits prove:
  $$\lim\limits_{x \to -1} \frac{x^4+x+1}{x^3}=-1.$$ I have managed to get 
$$\left|{\frac{x^4+x+1}{x^3}}+1\right| =  \frac{\vert x+1\vert^2\vert x^2-x+1 \vert}{|x|^3}$$ 
which is a step closer I think since I have 
the factor $(x+1)$ which I can control. And I can also limit the other factor in the numerator. But the $x^3$ in the denominator is my problem because if I limit $(x+1)$ it seems to grow. 
I not sure what to do with it.","['real-analysis', 'calculus', 'limits']"
2428192,Bijective compositions implies each function is bijective.,"Let $X,Y,Z$ and $W$ sets, $f:X \to Y$, $g:Y \to Z$ and $h:Z \to W$ functions. If $g \circ f$ and $h \circ g$ are bijective, then $f,g$ and $h$ are bijective. My attemp of proof goes as follows: As $g \circ f$ and $h \circ g$ are both injective and surjective, then $f$ and $g$ are injective, $g$ and $h$ are surjective. So $g$ is bijective. How do I prove that $f$ is surjetive and $h$ is injective in order to show that $f$ and $h$ are also bijective? Thanks.","['elementary-set-theory', 'functions']"
2428193,Probability of rolling the same number twice in more than one round,"If two people roll a die, the probability of rolling the same number is $1/6$.
But what if they try it for example $3$ more times? How high is the probability that they will roll the same number at least once in $4$ rounds? I think that after the first round the probability is $1/6$ that the numbers are the same and $5/6$ that they are not.
In a second round this continues like in the tree below: ___________
   /           \
  1/6          5/6
 /   \        /   \
1/6  5/6     5/6  1/6 Now to calculate the probability after the second round, that they have at least in one round the same answer is:
$$(1/6 \cdot 1/6) + (1/6 \cdot 5/6) + (5/6 \cdot 1/6) =  11/36 \approx 30\%$$ Is that right?","['probability', 'dice']"
2428240,Proving the inquality $\int_{0}^{\infty} f^\lambda(t)d(t^\lambda) \le \left(\int_{0}^{\infty} f(t)dt\right)^\lambda$ for $\lambda\ge 1$,"I am actually reading an article where the authors used the following 
whithout mentioning any proof of it
$$\int_{0}^{\infty} f^\lambda(t)d(t^\lambda) \le \lambda\int_{0}^{\infty} \left(\int_0^t f(\tau)d\tau\right)^{\lambda -1}f(t) dt =  \left(\int_{0}^{\infty} f(t)dt\right)^\lambda $$ Where $\lambda\ge 1$, the expression $d(t^\lambda)$ stand for $\lambda t^{\lambda-1}dt$  and the function $f$ is a nonnegative nonincreasing and integrable function on $(0,\infty).$ My first Guess is that this inequality must be related to some convex inequalities (which I do not know): Because for $\lambda\ge 1$ the function $x\mapsto x^\lambda$ is convex and this function is very linked to this problem. Now the equality 
$$\lambda\int_{0}^{\infty} \left(\int_0^t f(\tau)d\tau\right)^{\lambda -1}f(t) dt =  \left(\int_{0}^{\infty} f(t)dt\right)^\lambda $$
is rather easy to check since by setting 
$$F(t) = \int_0^t f(\tau)d\tau$$ we end up with $$\lambda\int_{0}^{\infty} \left(\int_0^t f(\tau)d\tau\right)^{\lambda -1}f(t) dt = \lambda\int_{0}^{\infty} F(t)^{\lambda -1}F'(t) dt \\= F^\lambda(\infty)-F^\lambda(0)=  \left(\int_{0}^{\infty} f(t)dt\right)^\lambda $$ Any reference, idea,  help or proposal is very welcome.","['real-analysis', 'inequality', 'integral-inequality', 'calculus', 'analysis']"
2428271,"How to show that $\lim_{\varepsilon \rightarrow 0^+} \int_0^\infty \frac{\varepsilon}{\varepsilon^2+x}\sin(1/x) \, dx=0$?","So I tried integration by parts and substitution but I couldn't bound the integral on the inside so that the limit would tend towards zero. Any hints on how to do this? Here is the work I have done so far \begin{align}
\int_0^t \frac{\varepsilon}{\varepsilon^2+x} \sin(1/x) \, dx & = \int_0^t \frac{\varepsilon x}{\varepsilon^2+x^2}\sin(1/x^2) \, dx \\
&= \left.\arctan \left(\frac x {\varepsilon}\right) x\sin(1/x^2)\right|_0^t-\int_0^t\arctan \left(\frac x \varepsilon \right) \frac d {dx}(x\sin(1/x^2)) \, dx\\
&=-\int_0^t\arctan\left(\frac x \varepsilon \right)\frac{d}{dx}(x\sin(1/x^2)) \, dx
\end{align}","['real-analysis', 'calculus', 'improper-integrals', 'integration', 'analysis']"
2428277,"Distribution of $X_1-\min\{X_1,X_2,\ldots,X_n\}$ for i.i.d. sample $(X_k)$ with standard exponential distribution","Let $X_i ~ \sim \operatorname{Exp}(1), \text{ i.i.d. } i=1,2,\ldots,n$, and let $X_{(i)}$ denote the $i$-th order statistic of $(X_i)$. In other words, $(X_{(i)} : i\text{-th smallest one among } X_1, \ldots, X_n)$ Then how can I find the distribution of $Y = X_1-X_{(1)}$? I know that if $X_1$ is the minimum (which happens with probability $1/n$), $Y$ is $0$, but I don't know how to deal with the other cases.","['probability-theory', 'order-statistics', 'probability-distributions']"
2428310,direct limit presheaf being sheaf on Noetherian space,"Let $X$ be a noetherian topological space and $\{\mathcal{F}_i\}$ be a directed system. Assuming $U\mapsto \varinjlim \mathcal{F}_i(U)$ is a presheaf, I am trying to see that this is a sheaf on $X$. Let $s,t\in \mathcal{G}(U)=\varinjlim \mathcal{F}_i(U)$. We have natural maps $\tau_i(U):\mathcal{F}_i(U)\rightarrow \mathcal{G}(U)$ for each $i$. Given $s,t\in \mathcal{G}(U)$ we have $s=\tau_i(x_i), t=\tau_j(x_j)$ for some $x_i\in \mathcal{F}_i(U)$ and $x_j\in \mathcal{F}_j(U)$. Suppose we are given an open cover $\{U_l\}$ such that $s|_{U_l}=t|_{U_l}$ for all $l$. Then we have following commutative diagram from this question. So, we have  $$s|_{U_l}=\Phi_l(s)=\Phi_l(\tau_i(U))(x_i)=\tau_i(U_l)(x_i|_{U_l}).$$
So, $s|_{U_l}=t|_{U_l}$ implies $$\tau_i(U_l)(x_i|_{U_l})=\tau_j(U_l)(s_j|_{U_l})\in \mathcal{G}(U_l).$$
This, means, for some $k$ we have $$f_{ik}(U_l)(x_i|_{U_l})=f_{jk}(U_l)(x_j|_{U_l})$$
which is same as saying
$$f_{ik}(U)(x_i)|_{U_l}=f_{jk}(U)(x_j)|_{U_l}.$$
So, $f_{ik}(U)(x_i),f_{jk}(U)(x_j)\in \mathcal{F}_k(U)$ such that $$f_{ik}(U)(x_i)|_{U_l}=f_{jk}(U)(x_j)|_{U_l}.$$
As $\mathcal{F}_k$ is a sheaf, we have $$f_{ik}(U)(x_i)=f_{jk}(U)(x_j)$$
which is same as saying $s=t$. I have not used that $X$ is Noetherian. What am I missing here",['algebraic-geometry']
2428376,How can the Zeta function be zero?,How can the Zeta function be zero? If the zeta function is the Euler product: $$\zeta(s)=\prod_p \frac{1}{1-p^{-s}}$$ Then being a product my first thought was that it could only be zero if one or more of its terms were zero. This would require $\frac{1}{1-p^{-s}}$ to be zero for some prime $p$ So there would have to be some prime $p$ for which $p^{-s}$ is infinite. Clearly I'm misunderstanding something.  Are the zeroes where the terms $(1-p^{-s})$ diverge?,"['euler-product', 'sequences-and-series']"
2428389,Homotopy groups of integer homology 3-spheres,"Let $Y^3$ be a integer homology 3-sphere, i.e. $H_k(Y;\mathbb{Z}) = H_k(S^3;\mathbb{Z}), \forall k$, i.e.
$$
H_0(Y;\mathbb{Z}) = H_3(Y;\mathbb{Z}) = \mathbb{Z}
\quad
\text{and}
\quad
H_1(Y;\mathbb{Z}) = H_2(Y;\mathbb{Z}) = 0
$$
There are results about $\pi_1(Y)$ (e.g. M. A. Kervaire's 1969 paper ). Question : what do we know about $\pi_2(Y)$ and $\pi_3(Y)$ ? According to the edits below (solving some cases), here I suppose : $card(\pi_1(Y))=\infty$ (so exclude $S^3$ and Poincaré's homology 3-sphere), $Y$ is not a Brieskorn 3-sphere $M(p,q,r)$. $Y$ is reducible. Edit 1 : If $\pi_1(Y)=0$, then $\pi_2(Y)=0$ and $\pi_3(Y)=\mathbb Z$. This can be computed either using Hurewicz either considering Poincaré-Perelman theorem ($\pi_1(Y)=0$ implies $Y=S^3$). So lets suppose $\pi_1(Y)\ne 0$. A first explicit example of such a non-trivial homology 3-sphere is Poincaré's homology 3-sphere. Using the long exact sequence of homotopy of the fibration $A_5\rightarrow SO(3) \rightarrow Y$ it is easily shown that higher homotopy groups of Poincaré's homology sphere are given by $\pi_k(Y)=\pi_k(S^3), \forall k>1$, hence $\pi_2(Y)=0$ and $\pi_3(Y)=\mathbb{Z}$. Now we know $\pi_2$ and $\pi_3$ of two homology 3-spheres (standard $S^3$ and Poincaré's $\mathbb{Z}HS^3$). From Kervaire's theorem, those two cases are the only $\mathbb{Z}HS^3$ with finite fundamental group. So lets suppose now that $card(\pi_1(Y))=\infty$. Edit 2 : Also, for $p,q,r\in \mathbb{Z}_{\geq 2}$ pairwise coprime, the Brieskorn sphere $M(p,q,r)$ is an $\mathbb{Z} HS^3$. The case $M(2,3,5)$ is Poincaré's $\mathbb{Z} HS^3$ and was discussed in ""Edit 1"" . The other cases all have infinite $\pi_1$ and by Brieskorn's theorem are Eilenberg-Maclane spaces $K(\pi_1,1)$ (i.e. aspherical), hence they have $\pi_2 = 0$, $\pi_3 = 0$. Edit 3 : (Here I follow Thomas's idea, see answer below). Let $Y$ be a $\mathbb Z HS^3$ with infinite $\pi_1$. Then, since $Y$ is orientable, we have ""$Y$ irreducible implies $Y$ is $K(\pi_1(Y),1)$"" . So the case where $Y$ is irreducible, and has infinite $\pi_1$, is solved ($\pi_2 = 0$ and $\pi_3 = 0$). Remark that the notions of irreducible and prime concord in the case of $\mathbb Z HS^3$.","['algebraic-topology', 'gauge-theory', 'general-topology', 'differential-geometry']"
2428408,Relational algebra: if $f^{'}: E/ {\sim} \rightarrow X$ then $f^{'}$ is unique.,"Let $E$ be a set, and $\sim$ an equivalence relation on $E$, and let $p$ be a projection such that $p : E \rightarrow E/{\sim}$, and $x \sim y$ implies that $f(x)=f(y)$. Then there exists a unique $f' : E/ {\sim} \rightarrow X$ such that $f = f' \circ p$. Now, there is a proof for the fact that $f'$ is unique, which I am unable to understand. It follows from the fact that $p$ is surjective, and by supposing that there are two distinct functions $g,h$ such that $f = g \circ p = h \circ p$, then $g,h$ are identical on $\mathcal{P}(E)$, thus $g=h$, but I am unable to understand how you can come to this conclusion/","['category-theory', 'functions']"
2428417,finding the generators of a matrix in $SL_2(\mathbb{Z})$,"I know the two generators of $SL_2(\mathbb{Z})$ are $S=\begin{bmatrix} 
    0 & -1  \\
    1& 0 
\end{bmatrix}$ and $T=\begin{bmatrix}
    1 & 1  \\
    0& 1
\end{bmatrix}$ . Furthermore, $T^n =\begin{bmatrix}
    1 & n  \\
    0& 1
\end{bmatrix}$ . Suppose I have any matrix $A$ in $SL_2(\mathbb{Z})$ . I want to find its generators. Here is what I have done so far: I am trying to find the $a,b,c,d \in \mathbb{N}$ such that $A=S^a T^b S^{-c} T^{-d} \iff A T^d S^c= S^a T^b$ .
Also, since $S^4=1$ , I assumed $1 \leq a,c \leq 4$ . In general, I tried to  compare the coefficients of $A$ for every possible values of $a$ and $c$ , without success. Where is my mistake?","['matrices', 'modular-forms']"
2428449,"Derivative of a f(x,y) with respect to g(x,y)","I've seen other posts about finding a derivative with respect to another function, but I didn't understand how it would work when the functions have more than one variable. I would like a general explanation about how to find $\frac{df(x,y)}{dg(x,y)}$, but take the following functions to illustrate it: Given the functions $$f(x,y) = 3x + 5y$$
$$g(x,y) = 2x + y$$ is it possible to find $\frac{df}{dg}$?","['derivatives', 'calculus']"
2428529,Epsilon-Delta Proof limit $\frac{3x^2y}{ x^2 + y^2}$,"I have just learned about the Epsilon-Delta definition of a limit. I understand that if a function has a limit, then given any $ \epsilon > 0$, there is a $\delta > 0$, such that for all $x$ within $ \delta $ of $c$, $f(x)$ is within $\epsilon of L$. In other words, $|x - c| < \delta \rightarrow |f(x) - L| < \epsilon$ The task in my textbook was to find the limit of $3x^2y / (x^2 + y^2)$ as $(x,y) \rightarrow 0$. To prove that the limit of this function is $0$, we need to find $\delta > 0$ that confirms the inequalities specified above. As I set out to answer the question, I wrote down $0 < |x - 0| < \delta \rightarrow 3x^2y / (x^2 + y^2) - 0< \epsilon $ However, the book began with $0 < \sqrt{x^2 + y^2} < \delta \rightarrow 3x^2y / (x^2 + y^2) - 0< \epsilon $ Where do they get $\sqrt{x^2 + y^2}$ ? Please explain in the simplest way you can - I am very, very new to this!","['multivariable-calculus', 'epsilon-delta', 'limits']"
2428567,Closed form for $\sum_{n=1}^\infty \left(e-\left(1+\frac{1}{n}\right)^n \right)^2$?,"Is there a closed form for this series: $$\sum_{n=1}^\infty \left(e-\left(1+\frac{1}{n}\right)^n \right)^2 \approx 1.273278374727530507449$$ (Mathematica computation by Patrick Stevens). This is basically a sum of squared errors for all $n$ for the classic limit used to define $e$. Are there some other similar series of interest, representing a sum of squared errors? (I'm aware we can buid an infinite set of such series by using various limits for various constants, but I'm asking only about well known series). I don't really have motivation except for the fact that this series seems fundamental enough to have been studied before. Besides, there exists a special value for an infinite product : $$\prod_{k=2}^{\infty} e \left(1-\frac{1}{k^2} \right)^{k^2}=\frac{\pi}{e^{3/2}}$$ (The link had been here , but it's broken now). Update Some attempts to rearrange the series: $$e=\sum_{k=0}^\infty \frac{1}{k!}$$ $$\left(1+\frac{1}{n}\right)^n=\sum_{k=0}^n \left( \begin{array}( n \\ k \end{array} \right) \frac{1}{n^k}$$ Thus, we can write the general term as: $$\left(e-\left(1+\frac{1}{n}\right)^n \right)^2=\left( \sum_{k=0}^n \frac{1}{k!} \left(1-\frac{n!}{(n-k)!} \frac{1}{n^k} \right)+ \sum_{k=n-1}^\infty \frac{1}{k!} \right)^2$$","['exponential-function', 'closed-form', 'convergence-divergence', 'special-functions', 'sequences-and-series']"
2428574,Proving Equivalence Relation in $\mathbb{N}\times\mathbb{N}$,"I just need to see if this is correct Define a relation R on $\mathbb{N} \times \mathbb{N}$ by $<a,b>$ R $<c,d> $ iff $a+d=c+b$. Prove this is an equivalence relation. I am having an issue with the reflexive case. I wrote let $<a,b>\in\mathbb{N}\times\mathbb{N}$. Then $a+b=b+a$ by commutativity, thus $<a,b>$ R $<a,b>$, but should I instead be using $<a,a>$. Then for symmetric, I have that $<a,b>,<c,d>\in\mathbb{N}\times\mathbb{N}$ such that $<a,b>$ R $<c,d>$, $a+d=c+b$. Then,$a+d=b+c$= $d+a=b+c$, which we can just rewrite as $d+a=c+b$. Then, this shows $<c,d>$ R $<a,b>$ For transitivity, I have let $<a,b>,<c,d>,<x,y>\in\mathbb{N}\times\mathbb{N}$ such that $<a,b>$ R $<c,d>$ and $<c,d>$ R $<x,y>$. So, we have that $a+d=b+c$ and $c+y=d+x$. Then, we can do $(a+d)+(c+y)=(b+c)+(d+x)$. We can cancel out the $c$ and $d$ from both sides by subtracting and are left with $a+y=b+x$. Then, $<a,b>$ R $<x,y>$.","['relations', 'proof-writing', 'proof-verification', 'discrete-mathematics']"
2428629,Compact preimage of a point by C¹ function,"Let $f:\mathbb{R}^{m} \to \mathbb{R}$ ($m \geq 2$) be a $C^{1}$ function such that, for some $c \in \mathbb{R}$, $f^{-1}(c)$ is compact and non-empty. Show that $F=\{x \in \mathbb{R}^{m} | f(x) \leq c\}$ or $G=\{x \in \mathbb{R}^{m}| f(x) \geq c\}$ is compact. $F$ and $G$ are closed, then I only need show that one of them is bounded. I have tried to show by contradiction.","['real-analysis', 'analysis']"
2428653,Indefinite integral $\int \arctan^2 x dx$ in terms of the dilogarithm function,"I read about the integral
$$\int \arctan^2 x dx$$ in this old post: Evaluation of $\int (\arctan x)^2 dx$ By replacing
$$\arctan x = -\frac{i}{2}\left[\log(1+ix) - \log(i-ix)\right],$$
as suggested there, I ended up with this solution
$$\int\arctan^2 x dx = x\arctan^2x - \frac{1}{2}\log(1+x^2)\arctan x -\log 2 \arctan x  + \mbox{Im}\left\{\mbox{Li}_2\left(\frac{1+ix}{2}\right)\right\} + K, \tag{1}\label{uno}$$
where, as usual, $\mbox{Li}_2(z)$ is the dilogarithm function 
$$\mbox{Li}_2(z) = -\int_0^z \frac{\log(1-u)}{u}du=\sum_{k=1}^{+\infty}\frac{z^k}{k^2}.$$
Is this a correct development? In that case, if I determine, using \eqref{uno}, the definite integral $\int_0^1 \arctan^2xdx$ I get the result
$$\int_0^1 \arctan^2xdx=\frac{\pi^2}{16}-\frac{3\pi}{8}\log 2 + \mbox{Im}\left\{\mbox{Li}_2\left(\frac{1+i}{2}\right)\right\}.$$
If I now compare this result with the one given in Definite Integral of $\arctan(x)^2$ , i.e.
$$\int_0^1 \arctan^2xdx=\frac{\pi^2}{16}+\frac{\pi}{4}\log 2 - C,$$
where $C$ is the Catalan constant
$$C = \sum_{k=0}^{+\infty} \frac{(-1)^k}{(2k+1)^2},$$
I get the following expression:
$$\mbox{Im}\left\{\mbox{Li}_2\left(\frac{1+i}{2}\right)\right\} = \frac{5\pi}{8}\log 2 - C.$$
Is that reasonable?","['catalans-constant', 'complex-analysis', 'integration', 'special-functions', 'polylogarithm']"
2428660,Chess combinatoric problem,"We are given eight rooks, five of which are red and three of which are blue.  In how many ways can the eight rooks be placed on an 8-by-8 chessboard so that no two rooks can attack one another. I don't know how to start this problem.  Can anyone help?",['combinatorics']
2428665,Showing the alternating series $\sum_{n=1}^\infty (-1)^n \frac{n}{p_n}$ where $p_n$ is the $n$th prime converges,"So what I want to prove is: Proposition: Let $p_n$ be the $n$th prime. Then the alternating series $$\sum_{n=1}^\infty (-1)^n \dfrac{n}{p_n}$$ converges. Here's my (original) attempt. Could someone verify my proof is alright? Lemma 1: If $a_n$ and $b_n$ are sequences and $\lim_{x\to \infty} \frac{a_n}{b_n} = 1$, then $$\sum_{n=1}^\infty a_n \text{ converges} \iff \sum_{n=1}^\infty b_n \text{ converges},$$
$$\sum_{n=1}^\infty a_n \text{ diverges} \iff \sum_{n=1}^\infty b_n \text{ diverges}.$$ Proof: Follows directly from the limit comparison test . Proof of Proposition: Note that by the Prime Number Theorem ,
$$p_n \sim n \log(n),$$
that is, due to
$$\lim_{n\to \infty} \frac{p_n}{n \log(n)} =1.$$ Thus, by Lemma 1, 
$$\sum_{n=1}^\infty (-1)^n \dfrac{1}{\log (n)} \text{ converges} \implies \sum_{n=1}^\infty (-1)^n \dfrac{n}{p_n} \text{ converges}.$$ Now, the series $\sum_{n=1}^\infty (-1)^n \dfrac{1}{\log (n)}$ converges (as made clear by the alternating series test ). As a result, our proposition is proven. Note (Clément C.): As mentioned in the comments, this particular argument is faulty, since the ""Lemma"" used does not hold. (Specifically, it only holds for positive sequences (or negative sequences), but not those whose sign alternate.) A proof of convergence (or divergence) of the original series would be quite interesting. Observe also that the alternating series test does not seem to apply here, as even with the Prime Number Theorem it is not obvious (and may be false) that the sequence $\left(\frac{n}{p_n}\right)_n$ is non-increasing. Moreover, it is not clear that the ""usual"" remedy for this (i.e., performing a Taylor series expansion of $\lvert a_n\rvert$ to get a constant number of terms which constitute, each by itself, non-increasing sequences; until a last term is reached which is the term of an absolutely convergent series) can be applied here, as such a series development appears to only give very slowly decreasing terms. (That is, reaching a term whose seriess absolutely convergent does not seem to happen within a constant number of terms).","['number-theory', 'prime-numbers', 'proof-verification']"
2428701,"How many edge-disjoint copies of $s$-complete graph $K_s$ in the complete $s$-partite graph $K_{l,l,\dots,l}$ with each part of size $l$?","How many edge-disjoint copies of $s$-complete graph $K_s$ in the complete $s$-partite graph $K_{l,l,\dots,l}$ with each part of size $l$? For vertex-disjoint case, the answer is simple, just $l$ copies of $K_s$. But it seems there are much more edge-disjoint copies of $K_s$ in $K_{l,l,\dots,l}$. How many could it be? Is there any known result about it?","['combinatorics', 'graph-theory', 'discrete-mathematics']"
2428718,Predicates and Quantifiers,"Question: Establish these logical equivalences, where x does not
occur as a free variable in A. Assume that the domain is nonempty. a) ∀x(A → P(x)) ≡ A → ∀xP(x) b) ∃x(A → P(x)) ≡ A → ∃xP(x) My Solution a) Suppose A is false. Then A -> P(x) is trivially true because if hypothesis is false then conditional statement is trivially true. hence, both left-hand side and right-hand side are true. Second case if A is true. Then there are two sub-cases. (i) P(x) is true for every x, then left hand side is true, because if hypothesis and conclusion both are true then conditional proposition is true. Same reasoning can be given for right hand side also, right-hand side is also true as P(x) is true for every x. (ii) P(x) is true for some x, left-hand side will be true for that x, as hypothesis is true and conclusion is also true.
   But for those x, where p(x) is false, Left hand side will be false as hypothesis is true and conclusion is false. For right hand side it will always be false because A is true and ∀xP(x) is false Hence, both propositions are not equivalent. b) If A is false, then both left-hand and right-hand sides are trivially true as hypothesis is false. If A is true, then there are two sub-cases. i.P(x) is true for every x, then left-hand side is true, and same reasoning can be given for right hand-side, and right-hand side is also true.> ii.If P(x) is true for some x, left hand side is true and right hand side is also true. Hence, both propositions are equivalent. Please validate if my solution is correct.","['quantifiers', 'first-order-logic', 'propositional-calculus', 'discrete-mathematics']"
2428727,Prove that $g$ is One to one function if and only if $g$ is Onto,"If $g: X \to X$ such that $g^m=g^n$ for positive integers $m$  and $n$ where $m \gt n$. $g^m$ denotes $g(g(g(\cdots g(x))$ Prove that $g$ is One to one function if and only if $g$ is Onto. First i considered $m=2$ and $n=1$. So $$g(g(x))=g(x) \tag{1}$$ Now Since $g$ is Onto $\forall$ $y \in X$, $\exists$ $x \in X$ such that $$g(x)=y$$ So substituting $g(x)=y$ in $(1)$ we get $$g(y)=y$$ which is an identity function and hence $g$ is one to one. Similarly what ever $m$ and $n$ we choose we get $g$ as an identity function. is this correct approach?","['elementary-set-theory', 'euclidean-domain', 'functions']"
2428773,An equivalence of $\sigma$-additivity,"Let $(\Omega, \mathcal{A})$ be a measurable space and let $\nu: \mathcal{A}\to [0, \infty)$ be finitely additive with $\nu(\emptyset)=0$. Show the following: $\nu$ is $\sigma$-additive if and only if the following holds: If $A_j \in \mathcal{A}$ with $A_1 \supseteq A_2 \supseteq \ldots$ and $\mu(A_j)\geq \delta$ for all $j \geq 1$ for some $\delta >0$ then $\cap_{j=1}^\infty A_j\neq \emptyset$. My proof for the forward direction is as follows:
Suppose that $\nu$ is $\sigma$-additive. Since we also know that $\nu(\emptyset)=0$ and $\nu(A)\geq 0$ for all $A\in \mathcal{A}$ (since $\mu$ takes its values in $[0, \infty)$) then $\nu$ is a measure on $\mathcal{A}$. Let $\{A_j\}_{j=1}^\infty$ be a collection of sets in $\mathcal{A}$ such that $A_1\supseteq A_2 \supseteq \ldots$ and $\nu(A_j)\geq \delta$ for all $j\geq 1$ for some $\delta >0$. Suppose, to the contrary, that $\cap_{j=1}^\infty A_j=\emptyset$. Then $\nu(\cap_{j=1}^\infty A_j)=0$. However, by continuity from above we have
$$0=\nu(\emptyset) = \nu(\cap_{j=1}^\infty A_j)=\lim_{n\to \infty} \nu(A_j)\geq \lim_{n\to \infty} \delta=\delta >0,  $$
a contradiction. Thus, $\cap_{j=1}^\infty A_j\neq \emptyset$. For the other direction I was going to consider an arbitrary collection $\{A_j\}_{j=1}^\infty$ of sets in $\mathcal{A}$ and define a new collection $\{E_n\}_{n=1}^\infty$ by $E_n=\cup_{j=1}^\infty A_j\setminus (\cup_{i=1}^n A_i)$ for each $n \geq 1$. Clearly, the $E_n$'s are decreasing, but I have no idea how to proceed from there. Your help is greatly appreciated and thank you in advance!","['real-analysis', 'measure-theory']"
2428809,Show $\pmatrix{A & B\\ C & I}$ is nonsingular given that $A-BC$ is nonsingular.,"I'm having some trouble showing that the block matrix $$D = \pmatrix{A & B\\ C & I}$$ is nonsingular, given that $A-BC$ is nonsingular. I have gotten close with the following by saying let $$T = \pmatrix{(A-BC)^{-1} & -B(A-BC)^{-1}\\-C(A-BC)^{-1} & A(A-BC)^{-1}}.$$ (Basically, I'm trying to extend the formula for the inverse of a $2\times2$ real matrix to block matrices.) Then $$\begin{align}DT &= \pmatrix{A & B\\ C & I}\pmatrix{(A-BC)^{-1} & -B(A-BC)^{-1}\\-C(A-BC)^{-1} & A(A-BC)^{-1}} \\ &= \pmatrix{A(A-BC)^{-1}-BC(A-BC)^{-1} & -AB(A-BC)^{-1}+BA(A-BC)^{-1}\\ C(A-BC)^{-1}-C(A-BC)^{-1} & -CB(A-BC)^{-1} + A(A-BC)^{-1}}\\ &=\pmatrix{(A-BC)(A-BC)^{-1} & (BA - AB)(A-BC)^{-1}\\ O & (A - BC)(A-BC)^{-1}}\\ &=\pmatrix{I & (BA - AB)(A-BC)^{-1}\\ O & I}.\end{align}$$ I manage to get almost everything, except the top-right block. I want it to be $O$, but I'm not sure what information I have that makes it equal $O$. I don't necessarily know that $A$ and $B$ commute, i.e., $AB = BA$, which would imply the top-right block would zero out. Can anyone see if I made a mistake? If there is no mistake, can anyone give a hint on what to do to try and zero out the top-right block?","['matrices', 'linear-algebra']"
2428851,Finding Finite vs. Infinite Interections,"T/F: Let $A_n$ = $(0, \frac{1}{n})$ (a bounded set), and $B_n$ = [$n, \infty)$ (a closed set). Any finite intersection of $A_n$'s and $B_n$'s is non-empty, but the infinite intersection of $A_n$'s and $B_n$'s is empty. I think the answer is true, but my logic behind it is a bit iffy. Does it involve limits? This is my reasoning: As $n \rightarrow k$, where $k$ is some finite number, then $(0, \frac{1}{k})$ and $B_n$ = [$k, \infty)$ have finitely many numbers in it. So, we have a finite intersection of finite numbers, which makes it non-empty. On the other hand, As $n \rightarrow \infty$, then $(0, \frac{1}{\infty})$ and $B_n$ = [$\infty, \infty)$, then they're approaching ""emptiness""? I can't really grasp the ideas behind these finite/infinite intersections, so any clarification would be tremendously helpful. Thank you.","['general-topology', 'real-analysis', 'elementary-set-theory']"
2428854,Proof of $\sum_{i=1}^ni\cdot(n-i) = \binom{n+1}{3}$,"I would like to prove combinatorially that $\sum_{i=1}^ni\cdot(n-i) = \binom{n+1}{3}$ . Algebraically, this identity is easily proved in the following way: $LHS = (1+2+\cdot\cdot\cdot+n-1+n)\cdot n  - (1^2+2^2+\cdot\cdot\cdot+n^2)\\=n^2(n+1)/2 - n(n+1)(2n+1)/6 = (n+1)(n-1)\cdot n/6=RHS$ However, is there any combinatorial proof for this equality?","['combinatorics', 'discrete-mathematics']"
2428861,"Proof that $x^y + y^x > 1 \ \forall x,y > 0 $ [duplicate]","This question already has answers here : A classic exponential inequality: $x^y+y^x>1$ [duplicate] (1 answer) Exponential teaser [closed] (1 answer) Closed 6 years ago . The problem is trivial if at least one of $x$ or $y$ is greater than $1$.  So all we need is to proof that $x^y+y^x > 1 \ \forall x,y \in (0,1)$.","['algebra-precalculus', 'real-analysis', 'inequality', 'exponential-function']"
2428904,Example 1.5-9 in Kreyszig's INTRODUCTORY FUNCTIONAL ANALYSIS WITH APPLICATIONS: How to construct such examples?,"Let $X$ denote the set of all the real (or complex) valued continuous functions on the closed interval $[0, 1]$, and let $$ d(x, y) \colon= \int_0^1 \lvert x(t) - y(t) \rvert \ \mathrm{d} t $$
for all $x, y \in X$. This $d$ is a metric on $X$, and $(X, d)$ is not complete, as has been shown by Kreyszig, for the sequence $\left( x_n \right)$, where 
$$ x_n (t) \colon= 
\begin{cases} 
0 \ & \mbox{ if } \ 0 \leq t \leq \frac{1}{2}, \\ 
(m+2)\left( t - \frac{1}{2} \right) \ & \mbox{ if } \ \frac{1}{2} \leq t \leq \frac{1}{2} + \frac{1}{m+2}, \\
1 \ & \mbox{ if } \ \frac{1}{2} + \frac{1}{m+2} \leq t \leq 1, 
\end{cases}
$$
for $n \in \mathbb{N}$, is a Cauchy sequence that fails to converge to any point $x$ in $(X, d)$. Now my question is, what is the gist of the process involved in the  construction of such examples? I mean what do we need to look for in the functions $x_n$ that would constitute a Cauchy but not a convergent sequence? Another example given by Kreyszig is in Prob. 13, Sec. 1.5. Here $x_n$ is defined as 
$$ x_n(t) \colon= \begin{cases}
 n \ & \mbox{ if } \ 0 \leq t \leq n^{-2}, \\ 
t^{-1/2} \ & \mbox{ if } \ n^{-2} \leq t \leq 1.  
 \end{cases} 
$$
What is the gist of examples like this one? How do we generalise each one of these two examples to an arbitrary closed interval $[a, b]$, where $a$ and $b$ are some real numbers such that $a < b$?","['real-analysis', 'complete-spaces', 'functional-analysis', 'metric-spaces', 'analysis']"
2428905,Pencil and paper example of fitting normal distribution to data with MCMC,"I've been trying to understand Markov Chain Monte Carlo methods for a while and even though I somewhat get the idea, when it comes to me applying MCMC, I'm not sure what I should do. Many times I've gotten the answer ""use a package"" from professors, but I don't want to use a package, I want to do it myself so I can understand! ;) I've been trying to search internet for good examples but so far I have found none such example which explicitly shows step by step what is happening under the hood. Many examples which I've looked deal with kinda abstract examples which are difficult to fully grasp. In many of the examples what I'm left with is: ""Okay very nice method, now I want to write a MCMC program myself which fits e.g. normal distribution to data"". The problem is, I cannot program abstract concepts, I need a concrete example. Some examples I've found get lost in the details of the domain problem and forget to explain the MCMC method itself. So my question is: Can you provide me with a very simple pencil and paper example? This could be e.g. a problem where you have three data points, say $(4,5), (3,3)$ and $(4,2)$ in the xy-plane and you need to fit this data to normal distribution. Lets also assume that for some reason we need to apply MCMC for this problem (Metropolis-Hastings would be nice). Show me detailed steps of how you do this, taking the derivatives, equating to zero, choosing the proposal distribution, taking a random sample from posterior (if you use Bayesian method) et cetera. Do this like one or two iterations, just to show everybody how the calculations proceed. I think this example would provide valuable info for beginners in MCMC methods. Thank you! "" I hear and I forget. I see and I remember. I do and I understand. "" Confucius","['markov-chains', 'statistics', 'monte-carlo', 'normal-distribution']"
2428931,Cambridge A Level - Questions on Combinations,"I have learnt combinations and I have been attempting at these two questions but couldn't solve it: 1) In a mixed pack of coloured light bulbs there are three red bulbs, one yellow bulb, one blue bulb and one green bulb. Four bulbs are selected at random from the pack. How many different selections are possible? I did 3C1 * 1C1 * 1C1 * 1C1 = 3 However, that wasn't the answer. 2) There are 20 teachers at a conference. Of these, 8 are maths teachers, 6 are history teachers, 4 are physics teachers and 2 are geography teachers. Four of the teachers are to be chosen at random to take part in a quiz. In how many different ways can the teachers be chosen if there are to be at least two maths teachers? So I did 8C2 * 18C2 = 4284 Which also wasn't the answer. Could someone please tell me what I am doing wrong? Thanks in advance.","['combinations', 'combinatorics']"
2429001,"Can we identify absolutely continuous functions on $(a,b)$ with values in $X$ with $W^{1,1}((a,b);X)$?","Function $f:(a,b)\to \mathbb{R}$ is measurable and absolutely continuous if and only if there exists the weak derivative $\frac{df}{dx}\in L^1(a,b)$ . The weak derivative coincides with the classical derivative almost everywhere. Can we prove the same theorem for $f:(a,b)\to X$ , where $X$ is a Banach space? In order to have differentiabilty almost everywhere of absolutely continuous function $f$ with the values in an abstract Banach space, we have to assume that $X$ is reflexive. I tried to copy the proof from the very first case but I stop when it comes to integrating by parts. Does the classical integrating by parts has the same form for absolutely continuous functions with values in Banach spaces?","['functional-analysis', 'real-analysis', 'sobolev-spaces', 'absolute-continuity']"
2429022,"If the limit along all continuous paths is $0$ for $f(x,y)$, must the limit actually be $0$?","Say we have $f:\Bbb R^2 \to \Bbb R$ i.e. $z=f(x,y)$. We know that the limit $(x,y)\to(0,0)$ exists and is equal to $0$ for all continuous paths then can we conclude that the double limit is actually $0$ ? Why or why not? I feel that the answer should be yes as even for functions discontinuous at origin, the limit should exist. I can't prove it rigorously though. Any suggestions?","['multivariable-calculus', 'continuity', 'limits']"
2429058,Is there a closed form for the alternating series of inverse harmonic numbers?,"Let $H_n=\sum _{k=1}^n \frac{1}{k}$ be the n-th harmonic number. 
Since $H_{k+1}>H_k$ for $k=1, 2, 3, ...$ the sequence $\frac{1}{H_k}$ is monotonic decreasing as $n \to \infty$, and the Leibniz criterion tells us that the alternating series $$s_{H}=\sum _{k=1}^{\infty } \frac{(-1)^{k+1}}{H_k}\tag{1}$$ converges. Its numerical value is $$N(s_{H}) = 0.626332...$$ The natural question arises: Question 1 Is there a closed form for $s_{H}$, i.e. an expression in terms of known constants (or is it even a new constant)?
A possible selection of these constants might be those arising in the power series expansion of the zeta function, i.e. $$const=\left\{\gamma ,\log (\pi ),\log (2),\gamma _1,\gamma _2,\zeta (3), ...\right\}$$ Question 2 A variation of the question replaces the harmonic number by the logarithm, starting at $k=2$, and asks for a closed form of the series $$s_{L}=\sum _{k=2}^{\infty } \frac{(-1)^k}{\log (k)}\tag{2}$$ here $$N(s_{L})=0.924299 ...$$ Solution attempts For question 1 I have no idea to find a closed form, but the numerical value can be found to high precision. Mathematica gives the first 100 Digits with this command: NSum[(-1)^(n + 1)/HarmonicNumber[n], {n, 1, Infinity}, 
 WorkingPrecision -> 100, Method -> ""AlternatingSigns""] $N(s_{H})=0.626332482737912354708657266227986063950088333562581965723069813694423327263764315345087698850095778034583404083688989609231701677593263$ I cannot tell if all these digits are correct. My attempt to solve question 2 starts with the replacement $$\frac{1}{\log (k)}=\int_0^{\infty } \exp (-t \log (k)) \, dt=\int_0^{\infty } k^{-t} \, dt$$ The summation under the integral is just the definition of the alternating zeta function starting at k = 2 which can be written as $$\sum _{k=1}^{\infty } (-1)^k k^{-t}= (1-\zeta (t))+2^{1-t} \zeta (t)$$ Where $\zeta (t)=\sum _{k=1}^{\infty } k^{-t}$ is the Riemann zeta function. Hence we find $$s_{L}=\int_0^{\infty } ( (1-\zeta (t))+2^{1-t} \zeta (t) )\, dt\tag{3}$$ The integrand is well behaved in the region of integration (it resembles the decaying exponential). But still I am stuck here (and Mathematica as well). Table lookups Stimulated by a comment of ""J. M. is not a mathematician"" I looked up the constants $s_{H}$ and $s_{L}$ defined here in the available tables. The results are: The Inverse Symbolic Calculator [1] could not identify the two constants. The Online-Encyclopedia of integer sequences , searched for the sequence of the decimal digits, does not find $s_{H}$ but it does find $s_{L}$, and what's more, it contains the series of question 2: A099769 Decimal expansion of Sum_{n >= 2} (-1)^n/log(n). [2] Here I.V.Blagouchine gives the following interesting integral representation without proof $$s_{LB}=\int_0^{\infty } \frac{8 \tan ^{-1}(x)}{\sinh (2 \pi  x) \left(\log ^2\left(4 x^2+4\right)+4 \tan ^{-1}(x)^2\right)} \, dx+\frac{1}{2 \log (2)}\tag{4}$$ Mathematica gives the first 100 digits with this command: NSum[(-1)^n/Log[n], {n, 2, Infinity}, WorkingPrecision -> 100, 
 Method -> ""AlternatingSigns""] $N(s_{L})=0.9242998972229388559595701813595900537733193978869190747796304372507005417114
3468979899134744193228$ Ths coincides with the digits given in the comment of robjohn and those of Ref. [2]. References [1] https://isc.carma.newcastle.edu.au/index [2] https://oeis.org/A099769","['harmonic-numbers', 'sequences-and-series']"
2429079,When are the eigenvectors of an Hermitian matrix real?,"Consider a Hermitian matrix $M=M^\dagger$. Clearly, its eigenvalues are real, but what is the condition for the eigenvectors to be real as well? Edit 1: I consider the entries of $M$ to be complex numbers. Moreover, I call a vector real if all its components are real numbers. Edit 2: As pointed out in the comments, if $v$ is a real eigenvector of $M$, then also is $i v$. For this reason I might need to emphasise that I do not care about ``global'' complex coefficients.","['matrices', 'eigenvalues-eigenvectors', 'operator-algebras', 'linear-algebra']"
2429089,cusp vs. corner? or both?,"I searched through books and internet and they all have general definitions of them as follows: Cusp: where the slope of the tangent line changed from -infinity to +infinity (or the other way around) Corner: left-sided and right-sided derivatives are different. And I saw a problem which was asking if there is a corner or a cusp given a graph. The graph looked like: f(x)=-x, if x<0
=sqrt(x), if x>=0 So in short, one branch was straight, and another branch was curved. I know the point where x=0 is not differentiable. But would it be considered a corner or a cusp? In my opinion, it should be a corner because it does not change from -infinity to +infinity. However, while I was searching, I saw an example of graph that looks similar to that, and the website was calling it a cusp (sorry I cannot find the image anymore). Also, this is another question, but if a cusp have a slope of either -infinity or +infinity, wouldn't it be a subcategory of vertical tangent?","['derivatives', 'calculus']"
2429091,How to prove that below quantity is purely imaginary?,How do I prove that the following quantity is purely imaginary: $$\sum_{0\leq l_1<l_2<l_3<l_4\leq q-1} e^{-2\pi i \frac{(l_1^2-l_2^2+l_3^2-l_4^2)}{q} } $$ where $q$ is an odd number?,"['analytic-number-theory', 'algebraic-number-theory', 'gauss-sums', 'number-theory', 'elementary-number-theory']"
2429129,Why is the total variation of a complex measure defined in this way?,"I have the following question about the meaning of the total variation measure. If $(X,\mathcal{A})$ is a measurable space and $\nu$ is a signed measure, the total variation of $\nu$ is defined as $|\nu|=\nu^++\nu^-$ and this gives us an intuition that $|\nu|$ measures ""how much charge"" has been put on a set, no matter that some of it is positive and some of it is negative, excluding one another. Now  if $\mu=\mu_1+i\mu_2$ is a complex measure with $\mu_1, \mu_2$ being signed finite measures, the total variation of $\mu$ is defined as follows:$$|\mu|(E)=\sup\{\sum_{j=1}^{n}|\mu(E_j)|: (E_j)_{j=1}^{n}\text{are disjoint and in } 
\mathcal{A}, \bigcup_{j=1}^{n}E_j=E\}$$ My intuition would be to define $|\mu|$ as $|\mu_1|+|\mu_2|$, a measure that is able to count the total charge that has been assigned to a set by $\mu_1$ and $\mu_2$ both. If someone could explain the reasoning behind the complex total variation definition, I would be grateful.","['measure-theory', 'soft-question']"
2429149,Defining a piecewise function using restricted operations,"Question Can the piecewise function $$f(x) = \begin{cases}
    0 & \text{if $x > 0$} \\
    1 & \text{if $x = 0$} \\
    0 & \text{if $x < 0$} \\
\end{cases}$$ be defined using only the operations $+ , -, *, /, |\cdots|, \max$ , and $\min$ ? What I have tried I can define the first and last pieces: $0$ if $x > 0$ or $x < 0$ with $$1 - \frac{x}{x}$$ But this will fail with a division by $0$ in the case where $x = 0$ $$1 - \frac{0}{0}$$ I can fix the division error by forcing a 1 on the bottom. $$a(x) = 1 - \frac{x}{\max(1, x) \min(-1, x)}$$ This works for most negatives and $0$ and fails when $-1 < x < 0$ and $x > 0$ . When $x > 0$ , $a(x) = 2$ . Fixing this requires another max to check a number is positive. Defining $b(x)$ to be $2$ when $x > 0$ and $0$ when $x = 0$ or $x <= -1$ $$b(x) = 2\frac{\max(0, x)}{\max(1, x) \min(-1, x)}$$ Combining them to get $$c(x) = a(x) - b(x) = 1 - \frac{x - 2\max(0, x)}{\max(1, x) \min(-1, x)}$$ This mess is what I want except when $-1 < x < 0$ and $0 < x < 1$ . This is as far as I have gotten.",['functions']
2429215,Proof verification: show that $x - a = b$ can be rewritten as $x = b + a$.,"I am beginning an introductory college math course to catch up from my bad high school education. This is one my first proofs. Prove that $x - a = b$ can be rewritten as $x = b + a$. We have been given the properties of the operations of the set of the real numbers (not sure how to latex that). My proof is this: $x - a - (-a) = b - (-a)$ $x - 0 = b + a$ $x = b + a$ I'm not completely sure this is correct. I have another, more important and general doubt. In the proof I use the fact that adding something to both sides of an equation does not change the equation. Do I need to prove this, since no proof has been given in this course, if I want to use it? We are proving very intuitively obvious theorems, so I'm not sure what other intuitively obvious theorems I can use without proving first! Here's an attempt: Theorem: adding $x \in R$ to both sizes of an equation does not change the equation. If $a, b$ are real numbers and $a = b$, then $a$ and $b$ are the same. $a + x = b + x$ can then be rewritten as $a + x = a + x$, since a = b. Both sides are the same, so $a + x = b + x$. Here I'm not sure how to say that a bunch of operations in the real numbers is a real number. This also should work for all operations we haven't mentioned yet: if $a^{2/3} = b^{4/7}$, then $a^{2/3} + c = b^{4/7} + c$. I'm not sure if this complicates things, but I have no idea how to say this either way. Let's also ignore for a second that this is an introductory course. Would I need to prove this if I was asked to prove the theorem in an exam?","['algebra-precalculus', 'proof-writing', 'proof-verification']"
2429240,Golden angle for a circle: another definition,"The accepted definition for the golden angle is based on the ratio of circle arcs, i.e. if $\alpha_0$ is the golden angle in radians, then: $$\frac{a}{b}=\frac{b}{a+b}$$ Where $a=\alpha_0 R$ and $b=(2 \pi-\alpha_0) R$. If the angle is defined as such then we can show that $\alpha_0=(3- \sqrt{5}) \pi$. (All of the above is according to Wikipedia ). However, if we use the direct generalization of the common definition for the golden ratio for a line segment, we should be comparing areas instead of arc length. Thus, if $\alpha$ is the (new kind of) golden angle, we should define it using the segment area $A$ that we ""cut off"" by drawing the chord: $$A=\frac{1}{2} (\alpha-\sin \alpha)$$ $$\frac{A}{B}=\frac{B}{A+B}$$ We obtain a transcendental equation for the angle: $$\alpha-\sin \alpha=(3- \sqrt{5}) \pi=2(2-\phi) \pi$$ Numerically its value is: $$\alpha=2.7664077793984\dots=0.8805749453982892\dots \pi$$ I have not been able to find a closed form. Can we find a closed form for $\alpha$? Is it an algebraic multiple of $\pi$ or not? Unlike the common definition, this latter definition of the golden angle can be generalized for the sphere in 3D (cutting by a plane and then comparing volumes) or even the $n-$sphere in any number of dimensions. If I'm correct, then for a sphere we obtain an equation: $$(2+\cos (\alpha/2))(1-\cos (\alpha/2))^2=2(3-\sqrt{5})$$ Which makes $\cos \alpha_{3D}$ algebraic and as far as I understand $\alpha_{3D}$ an algebraic multiple of $\pi$. $$\alpha_{3D}=2.8228221947949\dots=0.898532211542238\dots \pi$$","['elementary-number-theory', 'golden-ratio', 'transcendental-equations', 'geometry']"
2429264,About the identity $\sum\limits_{i=0}^{\infty}\binom{2i+j}{i}z^i=\frac{B_2(z)^j}{\sqrt{1-4z}}$,"In the paper A Probabilistic Algorithm for k-SAT Based on Limited Local Search and Restart , by Uwe Schöning, I fail to understand an identity used in a proof:
$$\sum_{i=0}^{\infty}\binom{2i+j}{i}z^i=\frac{B_2(z)^j}{\sqrt{1-4z}}$$ for $z=q(1-q)$, with $$B_2(z)=\sum_{i=0}^{\infty}\binom{2i+1}{i}\frac1{2i+1}z^i=\frac{1-\sqrt{1-4z}}{2z}$$ and $$B_2(z)^r=\sum_{i=0}^{\infty}\binom{2i+r}{i}\frac{r}{2i+r}z^i$$ It would be great if someone could explain this to me.","['probability-theory', 'binomial-theorem']"
2429289,Linear transformations: one-to-one mapping.,"My Linear Algebra textbook offers the following theorem: Let $T: R^n \to R^m$ be a linear transformation. Then $T$ is one-to-one if and only if the equation $T(\vec{x})$ = $\vec{0}$ has only the trivial solution. I don't understand why this is true. From discrete mathematics, I know that a mapping/function $T: A \to B$ is one-to-one if, for $a \in A$ and $b \in B$, we have that $f(a) = f(b)$ implies that $a = b$. In other words, no two elements in the domain map to the same element in the codomain. In terms of vectors, that means that no two vectors $\vec{x}$ in the domain $R^n$ map to the same vector $A\vec{x}$ in $R^m$. Or in other words, $A\vec{x} = \vec{b}$ has at most one solution for all $\vec{x} \in R^n$. In the theorem they give, why are they only talking about $\vec{b} = \vec{0}$, the zero vector? What if $T(\vec{x}) = \vec{b}$ has infinitely many solutions for $\vec{b} \ne \vec{0}$, violating the condition for one-to-oneness? I don't see why only examining the special case of $T(\vec{x}) = \vec{0}$ can allow us to conclude that the entire mapping is one to one. Edit: or is that not what they're saying? Is it because of the wording ""if and only if""? Does the theorem actually translate to: if $T$ is one to one, then $T(\vec{x}) = \vec{0}$ has only the trivial solution if $T(\vec{x}) = \vec{0}$ only has the trivial solution, then $T(\vec{x})$ is one to one I can see both of these being true.","['linear-algebra', 'elementary-set-theory', 'discrete-mathematics']"
2429389,Is there a bijection of the natural numbers which swaps $\frac{1}{n}$-summable subsets with $\frac{1}{\sqrt{n}}$-summable subsets?,"Let me start with a precise statement of the question.  For a subset $A\subseteq \mathbb{N}$ and a series of positive real numbers $\sum_{n=0}^\infty a_n$ , I'll use the notation $\sum_A a_n$ as a shorthand for $\sum_{n\in A} a_n$ . Is there a bijection $f:\mathbb{N}\rightarrow \mathbb{N}$ with the property that for every $A\subseteq \mathbb{N}$ , $\sum_A \frac{1}{n}$ converges iff $\sum_{f(A)} \frac{1}{\sqrt{n}}$ converges? Background : Fix a series of positive terms $\sum_{n=0}^\infty a_n$ .  Given a subset $A\subseteq \mathbb{N}$ , call it $a_n$ -small if $\sum_A a_n$ converges.  The following proposition is easy to prove: Proposition :  The set $\{A\subseteq \mathbb{N}: A\text{ is } a_n\text{-small}\}\cup \{\mathbb{N}\}$ is a topology of closed sets on $\mathbb{N}$ . I will use the notation $(\mathbb{N},a_n)$ to refer to this topology.  Then one can ask how topological properties of $(\mathbb{N},a_n)$ are related to series properties of $\sum a_n$ .  For example, I can show: Proposition :  The following are equivalent. $\sum a_n$ converges. $(\mathbb{N},a_n)$ is discrete. $(\mathbb{N},a_n)$ is disconnected. $(\mathbb{N},a_n)$ is Hausdorff And there are other nice things.  For example, $(\mathbb{N},a_n)$ is compact iff $(\mathbb{N},a_n)$ is cofinite iff $\liminf a_n > 0$ . With this language, my question can be reformulated as... Are $\left(\mathbb{N}, \frac{1}{n}\right)$ and $\left(\mathbb{N}, \frac{1}{\sqrt{n}}\right)$ homeomorphic? I have made very little progress on this.  Of course, the identity function $i:(\mathbb{N}, \frac{1}{\sqrt{n}})\rightarrow (\mathbb{N}, \frac{1}{n})$ is a continuous bijection, but the inverse map is not continuous.  Also, if there is such a bijection, there there is such a bijection with agrees with $i$ on any preassigned finite set. Edit I thought I add in a slightly suprising (to me, at least) example when things work out to be homeomorphic. Begin with a convergent series $\sum c_n$ . and divergent series $\sum a_n$ with $\lim a_n = 0$ .  Create a new series $b_n$ using all the terms of $c_n$ and $a_n$ (in whatever order you wish).  Then $(\mathbb{N}, a_n)$ and $(\mathbb{N}, b_n)$ are homeomorphic.  The idea is that since $\lim a_n = 0$ , there is a convergent infinite subseries $\sum_A a_n$ .  Then we use a bijection which with $A$ and $A\cup \{\text{indices of }c_n\}$ to ""squeeze"" the $c_n$ in without changing the topology.  Of course, I am glossing over many details, but I can include them if desired.","['general-topology', 'real-analysis', 'sequences-and-series']"
2429488,Differential operators as sections of a vector bundle,"Most of the books which need to use differential operators in a hands on way adopt some variation of the following definition (here for simplicity I am avoiding discussion of differential operators between bundles): Defintion 1. A differential operator of order $\leq k$ on a smooth manifold $M$ is an $\mathbb{R}$ -linear map $D:C^{\infty}(M) \to C^{\infty} (M)$ such that in local coordinates it looks like $D f (p)= \sum_{i_1+...+i_n \leq k} A_{i_1 ... i_n}(p) \frac{\partial^{i_1+...+i_n} f}{\partial x_1^{i_1} ...x_n^{i_n}}|_p$ for some smooth functions $A_{i_1 ... i_n}$ . I have been searching for a different definition that  didn't employ coordinates right away, and I found the following definition in the ""Lectures on the geometry of manifolds"" by Liviu Nicolaescu and lecture notes of Misha Verbitsky (which are in Russian), which is, I believe, due to Grothendieck: Definition 2. Define differential operator of order zero to be the multiplication by a smooth function $m_f (g) = f \cdot g$ , or alternatively an operator $D$ such that the commutator $[D, m_g]=D \circ m_g - m_g \circ D$ is zero for any smooth function g. Define inductively differential operator of order $\leq k$ to be an operator $D$ such that $[D, m_g]$ is a differential operator of order $\leq k-1$ for any smooth $g$ . Denote the set of all differential operators of order $\leq k$ by $Diff^k (M)$ . Luviu's book than proves that differential operators are local in the sense that supp $D(f) \subset$ supp $f$ , which means that we can restrict those operators to  open subsets of $M$ , as is usually done to show that differential forms form a sheaf if one starts with top-down approach thinking of differential forms as alternating $C^{\infty}(M)$ multilinear maps of vector fields. This naturally brings me to the first question: Shouldn't the second definition be modified so that a differential
operator is a sheaf homomorphism instead of just being a linear map
between globally defined functions? Misha later on in his notes shows in a series of exercises, that if one defines the symbol algebra $\oplus S^i := \oplus \frac{Diff^i(M)}{Diff^{i-1}(M)}$ , which is an algebra over $C^{\infty}(M)$ , then it is isomorphic to $Sym^{\bullet} \mathfrak{X}$ - symmetric algebra over the vector fields. Finally he asks the reader to prove that for the case $M=\mathbb{R}^n$ we have an isomorphism of algebras $Diff^k(\mathbb{R}^n) \cong \oplus_{i \leq k} Sym^i \mathfrak{X(\mathbb{R}^n)}$ , which is basically the local form of the first definition. The latter algebra is just the space of global sections of the bundle $\oplus_{i \leq k} Sym^i (T \mathbb{R}^n)$ , which brings me to my second question: Can a differential operator of order $\leq k$ on M be thought of as a
global section of some bundle of ""differential operators""? By the usual correspondence, that would imply that differential operators of order $\leq k$ form a locally trivial sheaf of $C^{\infty}(M)$ modules. Misha says that this is indeed the case in the last problem of his problem set, but I can't make a rigorous proof of it and I am asking for a reference where this approach is presented in detail. I am also puzzled by the fact that it is not usually mentioned in most of the references I've looked at that differential operators can be thought of as sections of some bundle, which seems to be very fundamental from a differential-geometric perspective. Moreover, this approach can further be developed into a very elegant treatment of the symbol.","['differential-geometry', 'partial-differential-equations']"
2429520,Distinct integer solutions to $a^2+b^2=c^2+d^2$ [duplicate],"This question already has answers here : Diophantine equation $a^2+b^2=c^2+d^2$ (9 answers) Closed 6 years ago . I'm trying to find integer solutions to
$$a^2+b^2=c^2+d^2$$ with values  $a> c > d > b>0$ Or in other words, two triangles with integer legs and equal hypotenuse lengths, not necessarily integer. Seems like a Diophantine equation to me, but I only learned how to solve Diophantine equations in the form of Pell's equations. I couldn't find anything on this equation when I checked Wikipedia. It is similar to a Pythagorean quadruple, although not quite, so that's not helpful either. How do I find integer solutions to this?","['number-theory', 'recreational-mathematics']"
2429558,"Prove: $\operatorname{rank} A \leq 1$ iff $A=xy^T$ for some $x,y \in \mathbb{R}^{n \times 1}$. [duplicate]","This question already has answers here : A rank-one matrix is the product of two vectors (3 answers) Closed 6 years ago . Let $A \in \mathbb{R}^{n \times n}$. Then $\operatorname{rank} A \leq 1$ if and only if $A = xy^T$ for some $x, y \in \mathbb{R}^{n \times 1}$. Need help. I can't find sufficient facts nor theorems to support my proof on the statement.",['linear-algebra']
2429604,Combinatorics on rooks on chess board,In how many ways can five identical rooks be placed on the squares of an 8-by-8 board so that four of them form the corners of a rectangle with sides parallel to the sides of the board.,"['combinatorics', 'discrete-mathematics']"
2429615,Common quadratic Lyapunov function with all convex combinations Hurwitz,"I have two $n\times n$ Hurwitz stable matrices, so $A_i\in H_n$ for $i=1,2$ .  I also know that every possible convex combination of these two matrices is Hurwitz, i.e., \begin{equation}
C(A_1,A_2) = cA_1+(1-c)A_2 \in H_n \hspace{0.5cm} \forall c\in[0,1].
\end{equation} I would like to determine tractable conditions under which a common quadratic Lyapunov function exists for the unforced systems $\dot{x}(t)=A_i x(t)$ such that \begin{equation}
A_iP+PA_i^T = -Q_i \hspace{0.5cm} i=1,2
\end{equation} with $P=P^T>0$ and $Q_i=Q_i^T>0$ . I am familiar with some results that might help here, but so far nothing is applicable.  The matrices do not commute.  I cannot establish that they are simultaneously triangularizable.  They are generated from nonminimal systems and it is necessary that they are not expressed in companion form.  They are of order $n$ which will certainly be greater than 2. Perhaps this is not possible. However, I was hoping that I could exploit the known stability of all convex combinations somehow. I also have a related formulation that might be more feasible.  Say the problem is now framed as an unforced time-varying system $\dot{x}(t)=A(t)x(t)$ with \begin{equation}
A(t) = c(t)A_1 +(1-c(t))A_2 \hspace{0.5cm} c(t)\in[0,1].
\end{equation} The eigenvalues of $A(t)$ are always in the open LHP and $c(t)$ behaves nice enough to ensure that the system is exponentially stable.  I would like to determine conditions under which a constant Lyapunov matrix exists \begin{equation}
A(t)P+PA^T(t) = -Q(t).
\end{equation} I view this as somewhat akin to finding a common Lyapunov function for a switched system that can switch between an infinite number of modes.  Maybe I could restrict the time variation of $c(t)$ to help make this possible? Edit: Looking at this from the time-varying system perspective, I think a converse Lyapunov theorem could help. If the system is exponentially stable for all permissible $c(t)$ trajectories then can I claim there exists a Lyapunov function satisfying \begin{equation}
c_1\|x\|^2 \le V(x,t) \le c_2 \|x\|^2
\end{equation} \begin{equation}
\dot{V}(x,t) \le -c_3 \|x\|^2
\end{equation} with $c_1,c_2,c_3>0$ ? Could I further claim that the form of such a function is \begin{equation}
V(x,t) = x^TP(t)x
\end{equation} with a smooth $P(t)=P^T(t)>0$ for an appropriate $c(t)$ ?  Would there be any loss of generality in assuming this $P(t)$ to be a specific $P(t)$ , i.e. one satisfying properties of another result I wish to use? Edit 2: Is there any tractable way to relate the state transition matrices for $A_1$ , $A_2$ , and $A(t)$ ?  I believe that I would have to work directly from the $\dot{\Phi} = A(t)\Phi$ statement to determine its transition matrix which seems daunting.","['stability-theory', 'hurwitz-matrices', 'control-theory', 'ordinary-differential-equations', 'linear-algebra']"
2429619,substitution in $y' = \cos(y-x)$ equation,"I have one simple DE with separable variables to test substitutions skill: $$\begin{align*}
y' &= \cos(y-x) \\
\frac{dy}{dx} &= \cos(y-x) \\
t &= y -x \\
\frac{dy}{dx} &= \cos t
\end{align*}$$ But what should I do next? I mean I do not know if there's an algorithm to handle substitutions in DEs or no",['ordinary-differential-equations']
2429649,Proof of formula for area enclosed by parametric curve,"Suppose that $\theta \in [0,2\pi]$ and $(x(\theta), y(\theta))$ define a closed parametric curve. There is a formula that says the area enclosed by this curve is equal to $\frac{1}{2} \int\limits_0^{2\pi} (x\frac{dy}{d\theta}-y\frac{dx}{d\theta}) d\theta$. I know that this is a simple consequence of Green's Theorem however I would like to know if there is a proof of this statement that does not rely on it. All the proofs I can find online assume that we can actually parametrise our curve by $x$ as well as $\theta$ but this is not the case for many curves defined parametrically so is there a way of getting around that?","['multivariable-calculus', 'parametric', 'area']"
2429685,"Calculating a ""killer question"" for a total test score","all - I'm trying to figure out if this can be done at all, and if so, how; unfortunately, my skill set isn't up to the task, and I'm hoping to find an answer here - or at least guidance on how to approach it. I need to score a 10-question test that has weighted questions on a pass/fail basis, with 70% as the cut score. So far, so good - sum the total difficulties, multiply by 0.7, then check to see if the candidate's score is above or below (the framework we are using does all this automatically.) However, I now want to add another condition: if the candidate does a certain thing (something I can test for), I need the score to always be a fail (below 70%.) Changing the scoring framework to do this would be problematic in lots of ways - but treating the condition test as a hidden 11th question would be trivial. The challenge, then, is this: Given 10 questions with associated difficulty scores (as below), is it possible to calculate a difficulty score for question #11 such that failing it will produce a score below 70% in all cases, but passing it will result in the same pass/fail rate as if q#11 wasn't present? The weight can't be negative. Hopefully, I've managed to phrase this in a coherent manner; please feel free to ask any questions you need to clarify. Example of question weights: 2 3 2 2 3 2 1 3 2 3 ???","['combinatorics', 'logic']"
2429690,When can one pass a linear operator under the integral?,"Specifically, one the webpage: http://mathworld.wolfram.com/GreensFunction.html It is written that 
$$
\int\mathcal{L}G(x,s)f(s)ds = \mathcal{L}\left(\int G(x,s)f(s)ds\right)
$$ where $G$ is a Green function. Why can the linear operator be pulled out of the integral? Thanks!",['analysis']
2429700,Linear Algebra: Determine if sets Spans the same subspace,"In $V=C(\mathbb R)$, let: $S_1=\{\sin(x), \cos(x), \sin^2(x), \cos^2(x)\}$ and $S_2= \{1, \sin(2x), \cos(2x)\}$. Is $\operatorname{Span}(S_1)=\operatorname{Span}(S_2)$? I know that two sets of vectors in the same vector space, $S_1$ and $S_2$, span the same subspace if and only if: Each vector in $S_1$ can be written as a linear combination of the vectors in $S_2$ AND
Each vector in $S_2$ can be written as a linear combination of the vectors in $S_1$. I started off by creating linear combinations, but then I am stuck.","['trigonometry', 'linear-algebra']"
2429734,Given seven points inside a hexagon with side length $1$ prove that there exists two points with distance at most $1$,"Seven points are given inside a regular hexagon whose sides have length $1$. Prove that there are two among these seven points such that the distance between them is at most $1$. Now if I divide the hexagon into $6$ regions, since we have $7$ points, by the pigeon hole principle there is a region with at least two points in it. The distance between two points is at most $1$ because each region is an equilateral triangle with sides of length $1$. Would this be sufficient or any other approaches that would work better.","['pigeonhole-principle', 'solution-verification', 'discrete-mathematics']"
2429775,How to find Jordan normal form and basis?,"I have a matrix: $$A = \begin{pmatrix}-1&5&4\\ 4&-6&-6\\ -8&16&14 \end{pmatrix}$$ simplifying: $$A = \begin{pmatrix}-1&5&4\\ 2&-3&-3\\ -4&8&7 \end{pmatrix}$$ What steps should I reproduce to find Jordan form and Jordan basis, I am really really confuswd without good step by step example! What I really understand that I have to find eigenvalues, so I did: $$\det|A-I\lambda| = \begin{vmatrix}-1 - \lambda&5&4\\ 2&-3-\lambda&-3\\ -4&8&7-\lambda \end{vmatrix}  $$ so I found cubic equation which is: $$-\lambda^3+3\lambda^2-5\lambda+3 = 0$$
$$-(\lambda-1)^3-2(\lambda-1)$$ So as I can judge Jordan normal form will have three eigenvalues that equal to $\lambda = 1$ on its main diagonal, below main diagonal all the values should be ""$0$"". But I bet it is not all. I do not know how to proceed (If I am right at all), and do not know how to find Jordan's basis after :(","['eigenvalues-eigenvectors', 'jordan-normal-form', 'linear-algebra']"
2429835,Injective $\mathcal{O}_X$ module is flasque,"This is a lemma from Hartshorne. Let $(X,\mathcal{O}_X)$ be a ringed space. Then any injective $\mathcal{O}_X$ module is flasque. I am trying to prove this. Let $V\subseteq U$ be open subsets of $X$, we need to prove that the restriction map $\mathcal{F}(U)\rightarrow \mathcal{F}(V)$ is surjective morphism. As $\mathcal{F}$ is an injective module, any injective morphism of sheaves $0\rightarrow \mathcal{A}\rightarrow \mathcal{B}$ gives a surjective morphism $\text{Hom}(\mathcal{B},\mathcal{F})\rightarrow \text{Hom}(\mathcal{A},\mathcal{F})\rightarrow 0$. So, it is natural to look for  sheaves of $\mathcal{O}_X$ modules $\mathcal{A},\mathcal{B}$ such that $$\text{Hom}(\mathcal{B},\mathcal{F})=\mathcal{F}(U) \text{ and }\text{Hom}(\mathcal{A},\mathcal{F})=\mathcal{F}(V).$$ Hartshorne gave $\mathcal{B}=j_!\left(\mathcal{O}_X|_U\right)$ and $\mathcal{A}=j_!\left(\mathcal{O}_X|_V\right)$ and then says that $$\text{Hom}(\mathcal{B},\mathcal{F})=\mathcal{F}(U) \text{ and }\text{Hom}(\mathcal{A},\mathcal{F})=\mathcal{F}(V).$$
But, how did they come up with that example. How on earth can one guess such example. Any motivation regarding this is welcome. Coming to the proof of $$\text{Hom}(j|!\left(\mathcal{O}_X|_U\right),\mathcal{F})\cong \mathcal{F}(U).$$
Let $s\in \mathcal{F}(U)$, we construct a morphism of $\mathcal{O}_X$ modules 
$j_!\left(\mathcal{O}_X|_U\right)\rightarrow \mathcal{F}$. Let $W\subseteq X$ be open. If $W\nsubseteq U$ then $j_!\left(\mathcal{O}_X|_U\right)(W)=\emptyset$. So, with out loss of generality, we assume $W\subseteq U$. So, we define $\eta(W):j_!\left(\mathcal{O}_X|_U\right)(W)\rightarrow \mathcal{F}(W)$ i.e., $\eta(W):\mathcal{F}(W)\rightarrow \mathcal{F}(W)$. Let $t\in \mathcal{F}(W)$ then assign $t\cdot s|_W\in \mathcal{F}(W)$ to $t$. This collection gives a morphism of $\mathcal{O}_X$ modules. Let $\eta:j_!\left(\mathcal{O}_X|_U\right)\rightarrow \mathcal{F}$ be a morphism of sheaves of $\mathcal{O}_X$ modules. We need to assign an element of $\mathcal{F}(U)$ with this. $\eta$ comes with maps $\eta(W):j_!\left(\mathcal{O}_X|_U\right)(W)\rightarrow \mathcal{F}(W)$ for each $W\subseteq U$. To get an element of $\mathcal{F}(U)$ its only natural to consider $\eta(U):j_!\left(\mathcal{O}_X|_U\right)(U)\rightarrow \mathcal{F}(U)$ i.e., $\eta(U):\mathcal{F}(U)\rightarrow \mathcal{F}(U)$. We have $\eta(U)(1)\in \mathcal{F}(U)$ an element of $\mathcal{F}(U)$. I am almost sure that this is an isomorphism. Any suggestion on better proof is welcome. Any suggestion on how they come up with that example is welcome.",['algebraic-geometry']
2429840,Average distance from a point in a hollow sphere to the surface of the sphere?,"I know that the average value of a function $f(x,y,z)$ over a volume $D$ is given by
$$ \bar{f} = \frac{1}{V} \int\int\int_D f(x,y,z) dV $$
I'm trying to set up the integral of the average distance from a point some distance a from the origin of a hollow sphere to the surface of the sphere ( image from here ): I used this equation to find $d$: $R^2=a^2+d^2+2adcos(\theta)$
$$ \Rightarrow d = \sqrt{R^2-a^2sin^2(\theta)}-acos(\theta) $$
My problem is I am now having difficulty setting up the integral. I know I'm supposed to get:
$$ \bar{r} = \frac{3R}{2} \int_0^1 \int_0^{\pi} \sqrt{1-k^2sin^2(\theta)}k^2sin(\theta)dkd\theta $$
About the closest I can get to that is:
$$ \bar{d} = \frac{3}{4\pi R^3} \int_0^1 \int_0^{\pi} \int_0^{2\pi} \bigg(\sqrt{R^2-a^2sin^2(\theta)}-acos(\theta)\bigg)k^2sin(\theta)dkd\phi d\theta $$
I'm clearly conceptually missing something, so any advice for what I'm misunderstanding or hints on how to set up this integral would be greatly appreciated.","['multivariable-calculus', 'integration', 'definite-integrals', 'volume']"
2429872,"A lily pad doubles in area every second. After one minute, it fills the pond. How long would it take to quarter fill the pond ?","A lily pad doubles in area every second. After one minute, it fills the pond. How long would it take to quarter fill the pond? To me this seems like we can set up a fraction-like equation: $$\frac{60 \ \text{seconds}}{1} = \frac{x \ \text{seconds}}{1/4}$$ then $x = 15$ seconds. But the answer is $58$ seconds which really makes no sense to me. Any suggestions are greatly appreciated.","['recreational-mathematics', 'discrete-mathematics']"
2429894,Ring of rational-coefficient power series defining entire functions,"I'm wondering if anyone has come across the following ring before. Let $R$ be the ring of complex power series $f=\sum_{n \ge 0} a_n t^n$ such that $a_n \in \mathbb{Q} \: \: \forall \: n$ The function $f: \mathbb{C} \rightarrow \mathbb{C}$ is entire Any information about it would be welcome but in order to keep the question specific, I'll list a few things I would like to know in particular. Is $R$ a unique factorisation domain? Are there any elements of $R$ which are known to be prime/irreducible but are not associates of polynomials? If an element $f \in R$ is prime/irreducible, must all its zeroes (in $\mathbb{C}$) be simple? Is every $\alpha \in \mathbb{C}$ a root of some nonzero $f \in R$ ?","['abstract-algebra', 'ring-theory', 'complex-analysis']"
2429902,Image of a convergent sequence under a continuous function converges,"Let $f:X \mapsto Y$ be a continuous function between two topological spaces. Let $\{x_i\} \subset X$ be a convergent sequence with limit $x \in X$. Does it follow that $\{f(x_i)\} \subset Y$ converges to $f(x) \in Y$? This came up in a manifolds topology class, where we are mapping between a subset of metric space and a subset of the manifold with a homeomorphism.","['continuity', 'general-topology', 'metric-spaces']"
2429907,Tracing a curve along itself - can the result have holes?,"Let $\varphi:[0,1]\to\Bbb R^2$ be a continuous curve (not necessarily injective) with $\varphi(0)=(0,0)$. Let $f:[0,1]^2\to\Bbb R^2$ be defined as $f(s,t)=\varphi(s)-\varphi(t)$. Question : Is the image $f([0,1]^2)$ always simply connected ? The set $f([0,1]^2)$ can be thought of as the trace of the mirror curve $-\varphi$ when slided along $\varphi$. See the image below for an example. $\qquad\quad$ This problem came up to me in some non-trivial topological context but I consider it interesting in its own right. I am optimistic it can be proven with sufficiently advanced topological machinery, but might there be an elementary proof (as elementary as the term ""simply connected"")?","['connectedness', 'curves', 'continuity', 'geometry', 'general-topology']"
2429922,Showing That Points Are Concyclic,"The question is as follows: Show that the points (-1, 4), (9, 4), (3, -8), and (11,0) are concyclic. I know that the intersection of the perpendicular bisectors of at least two chords will be the center of the circle. I found the perpendicular bisector of the points $(-1, 4)$ and $(9, 4)$ and the perpendicular bisector of the points $(9, 4)$ and $(11, 0)$. The equation for the perpendicular bisector of the first two points were $x = 4$, however, I am not sure whether that is true or not, and for the second two points, I got the equation for the perpendicular bisector to be $y = \frac{1}{2}x + 3$, and then I solved this equation in terms of $x$, and got $x = 2y-6$. When I set $x = 4$ and $x =2y - 6$ equal to each other, I got the $y$ value to be 12. But that is incorrect because the correct answer is $(4, -1)$. Also, I even drew the two lines and their perpendicular bisectors and they both intersected at $(4, -1)$. I am pretty sure that there may be something with my algebra, but I just can't trace the error. Any help will be greatly appreciated.","['analytic-geometry', 'circles', 'geometry']"
2429957,A tough series related with a hypergeometric function with quarter integer parameters,"Is it possible to express $$ \sum_{n\geq
 0}\frac{\binom{4n}{2n}\binom{2n}{n}}{64^n(4n+1)} = \phantom{}_3
 F_2\left(\frac{1}{4},\frac{1}{4},\frac{3}{4}; 1,\frac{5}{4}; 1\right)
 $$ in terms of standard mathematical constants given by Euler sums and values of the $\Gamma$ function? This problem arise from studying the interplay between elliptic integrals, hypergeometric functions and Fourier-Legendre expansions. According to Mathematica's notation we have $$ \sum_{n\geq 0}\frac{\binom{4n}{2n}\binom{2n}{n}}{64^n}y^{2n}=\frac{2}{\pi\sqrt{1+y}}\,K\left(\frac{2y}{1+y}\right) $$ for any $y\in[0,1)$ , where the complete elliptic integral of the first kind fulfills the functional identity $$\forall x\in[0,1),\qquad K(x) = \frac{\pi}{2\cdot\text{AGM}\left(1,\sqrt{1-x}\right)} $$ hence the computation of the above series boils down to the computation of $$ \int_{0}^{1}K\left(\frac{2y^2}{1+y^2}\right)\frac{2\,dy}{\pi\sqrt{1+y^2}}\stackrel{y\mapsto\sqrt{\frac{x}{2-x}}}{=}\frac{\sqrt{2}}{\pi}\int_{0}^{1}\frac{K(x)}{\sqrt{x}(2-x)}\,dx\\=\frac{1}{\pi}\int_{-1/2}^{+\infty}\frac{\arctan\sqrt{u}}{\sqrt{u(1+u)(1+2u)}}\,du$$ where $K(x),\sqrt{2-x},\frac{1}{\sqrt{x}},\frac{1}{\sqrt{2-x}}$ all have a pretty simple FL expansion, allowing an easy explicit evaluation of similar integrals. This one, however, is a tougher nut to crack, since $\frac{1}{2-x}$ does not have a nice FL expansion. There are good reasons for believing $\Gamma\left(\frac{1}{4}\right)$ is involved, since a related series fulfills the following identity: $$ \sum_{n\geq 0}\frac{\binom{2n}{n}^2}{16^n(4n+1)}=\frac{1}{2\pi}\int_{0}^{1}K(x)\,x^{-3/4}\,dx = \frac{1}{16\pi^2}\,\Gamma\left(\frac{1}{4}\right)^4 $$ which ultimately is a consequence of Clausen's formula, stating that in some particular circumstances the square of a $\phantom{}_2 F_1$ function is a $\phantom{}_3 F_2$ function. March 2019 Update : after some manipulations, it turns out that the computation of the original $\phantom{}_3 F_2$ is equivalent to the computation of the integral $$ \int_{0}^{1}\frac{-\log x}{\sqrt{x(1+6x+x^2)}}\,dx = \frac{1}{\sqrt{2}}\int_{0}^{+\infty}\frac{z\,dz}{\sqrt{3+\cosh z}}$$ which is way less scary. Additionally, nospoon has already tackled similar integrals, so I guess he might have something interesting to share.","['special-functions', 'hypergeometric-function', 'elliptic-integrals', 'sequences-and-series']"
2429968,How to solve $c \arccos(x)=x$ for the $x$?,"The equation $$c \arccos(x)=x$$ certainly has at least one solution for every real number in range $[-1,1]$, because the $[-1,1]$ is the domain of the $\arccos$. For example, if the $x=0.5$, then $c=0.5/\arccos(0.5) \approx 0.4775$. The equation might be transformed to
$$
\arccos(x)=x/c \\
\cos(\arccos(x))=\cos(x/c) \\
x=\cos(x/c)
$$
but now what? 
The goal is to solve the equation for the $x$, not the $c$. Thank You.",['trigonometry']
2429982,Find the total number of coefficients in the expansion of $(x^2-x +1)^{22}$ that are divisible by $6$.,"Find the total number of coefficients in the expansion of $(x^2-x +1)^{22}$ that are divisible by $6$. So I am really stuck on this one.. I immediately defeated when I saw that I need to compute  $\binom {22} {a,b,c}$ where $a,b,c$ is the coefficients of $x^2,-x,1$. So what should be the next step I need to take?",['combinatorics']
2429998,Negation of $x \in A \cup B$.,"What is the negation of $x \in A \cup B$. Is it $x \in (\lnot A \cap \lnot B)$? Or is it, $x \notin (\lnot A \cap \lnot B)$? Or maybe something else?
Another question: how to distribute nonmembership of $x \notin (\lnot A \cap \lnot B)$?  Is it $x \notin \lnot A \land x \notin \lnot B$?","['logic', 'elementary-set-theory']"
2430015,Example of a normal ring which is not a domain,"In 'Commutative Ring Theory' by Matsumura the definition of normal ring is as follows: A ring $R$ is called normal if for every prime ideal $\mathfrak p\subset R$, $R_{\mathfrak p}$ is an integrally closed domain. I know that a domain is integrally closed if and only if localisation at every prime ideal gives an integrally closed domain, i.e., it is normal. I want to have an example of a 'non-domain' which is normal. Also is there any equivalent criteria for a ring (not necessarily domain) to be a normal ring like in the domain case? Thank you in advance.","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
2430047,Girsanov theorem and filtrations,"Let $\{W_t\}$ be a standard Wiener process on a probability space $(\Omega, \mathcal{F},P)$. Let $\mathcal{F}^W$ be the natural filtration generated by $\{W_t\}$. Let $\{\theta_t\}$ be an $\mathcal{F}_t^W$-adapted stochastic process satisfying 
$$
E_P\left[ \exp\left(\int_0^t  \frac{\theta_s^2}{2} ds\right) \right]<\infty , \forall t\geq 0,
$$ 
Then, the process
$$
\varepsilon_t = \exp\left(\int_0^t\theta_s dW_s - \frac{1}{2}\int_0^t\theta^2_s ds\right)
$$ 
is an $\mathcal{F}^W_t$-martingale (because Novikov's condition is satisfied) and it represents the Radon-Nikodym derivative $dQ/dP$ for some $Q$ that is equivalent to $P$. We also have that $\{X_t\}$ defined by $X_t=\int_0^t dW_s -\int_0^t\theta_sds $ is a standard Wiener process on $(\Omega, \mathcal{F}^W, Q)$. My question: Take the natural filtration generated by $\{X_t\}$, $\mathcal{F}^X$. What is the relationship between $\mathcal{F}^W$and $\mathcal{F}^X$? Do they coincide?","['stochastic-processes', 'probability-theory', 'filtrations', 'radon-nikodym', 'brownian-motion']"
2430049,Reference requestion for complex analysis with a view towards complex geometry,"As a background, I am a beginning graduate student whose background is primarily algebra and algebraic geometry. I have some background in analysis, but it is weaker. In particular I know the basics of measure theory and complex analysis but only at an undergraduate level. I am really interested in the Riemann-Roch theorem, and am approaching it from an algebraic geometry perspective at the moment, but I thought the best way to learn complex analysis would be to approach from the Riemann surface point of view. With that in mind, I am looking for a complex analysis/complex geometry book that is fairly self contained in terms of complex analytic background. Since I want to learn some complex analysis as well, I would like something that doesn't shy away from analytic arguments when necessary, but I would like something with a definite geometric flavour. I feel like the standard answer here is Griffiths and Harris, so perhaps it would be good if people could give me an idea on how this book would serve me for this purpose? I got the impression is was much more algebraic geometry than complex analysis though. The other is Schlag's Complex Analysis and Riemann Surfaces if anyone is able to give me an idea of how that would serve. Does such a book exist, or an I asking too much? To put it shortly, a self-contained complex analysis and complex geometry which doesn't shy away from complex analytic arguments but has a geometric slant with the view towards proving the Riemann-Roch theorem for complex manifolds.","['riemann-surfaces', 'complex-geometry', 'reference-request', 'complex-analysis', 'algebraic-curves']"
2430075,Combinatorial proof of $\binom{k}{i}\binom{n}{k}=\binom{n}{i}\binom{n-i}{k-i}$ [duplicate],"This question already has answers here : Combinatorial Proof of ${{n}\choose{k}} {{k}\choose{j}} = {{n}\choose{j}} {{n-j}\choose{k-j}}$ [closed] (2 answers) Closed 6 years ago . $$\binom{k}{i}\binom{n}{k}=\binom{n}{i}\binom{n-i}{k-i}$$ This identity could be easily shown using algebraic formula of combination. However, I would like to provide a combinatorial proof. I considered applying Pascal's equality, but got stuck. Any advice ?","['combinatorics', 'combinatorial-proofs']"
2430106,Sequentially continuous for monotone sequences implies sequentially continuous.,"Is it true that if  $f:X\rightarrow Y$ satisfies that $x_n\rightarrow x\implies f(x_n)\rightarrow f(x)$ for every monotone sequence $(x_n)_n$ then $f$ satisfies this for every sequence? (Here monotone means that $d(x_n,x)$ is a decreasing function of $n$.) Even $X=Y=\mathbb{R}$ would be useful. Thank you!","['general-topology', 'real-analysis', 'sequences-and-series']"
2430107,How to calculate the number of palindromes of a given number of characters?,"A palindrome is a set of characters which equal the same thing forwards and backwards, for example; abccba. For a set of a given amount of  characters (we can use 9 as an example) how would you calculate the amount of palindromes of characters mathematically? This doesn't mean the words that can be formed but rather characters which are the same at start characters and end characters. What formula can be used to calculate this for simple lengths like 9 with lowercase letters?","['combinatorics', 'palindrome']"
2430133,Probability that no team in a tournament wins all games or loses all games.,"Five teams play a tournament in which every team plays every other team exactly once. No ties occur, and each team has a $1/2$ probability of winning any game it plays. Find the probability that no team wins/loses all the games. My try: Each team plays all other teams once. So there are $\binom{5}{2} = 10$ games. 
For each game there are 2 possible outcomes so there's a total of $2^{10}$ possible outcomes. Number of outcomes where $1$ team wins all its games: 
Let's say team A wins all its games ($4$ in total). 
Then other $6$ games can end in $2$ possible outcomes. 
Since anyone team could win all its games, we get $5 \times 2^6 $ as the number of outcomes where $1$ team wins all its games. Similarly by symmetry, we get $5 \times 2^6 $ as the number of outcomes where $1$ team loses all its games. It's also possible for $1$ team to win all its games, and another team to lose all its games. But these will have been included in both totals above (i.e. calculated twice), so we must subtract this amount once from the totals above: 
Let's say team A wins all its games and team B loses all it's games (these include $7$ games, $4$ games for team A and $4$ games for team B, but we must remember that teams A and B play each other once, so there are only $7$ games in which team A or team B plays with certain victory or losing respectively). So, since any of the $5$ teams could be the one to win all its games, and any of the $4$ remaining teams could be the one to lose all its games, we get $5 \times 4 \times 2^3 = 20 \times 2^3. $ Probability that at least one team wins/loses all their games is 
$\frac{(5 \times 2^6 + 5 \times 2^6 − 20 \times 2^3)}{ 2^{10}} 
= \frac{15}{32}. $ Hence, probability that no team wins/loses all their games is $\frac{17}{32}.$ Is this alright?","['permutations', 'probability']"
2430167,Why are rational maps between projective varieties taken to be rational?,"Definition. Let $V_1$ and $V_2 \subseteq \mathbb{P}^n$ be projective varieties. A rational map from $V_1$ to $V_2$ is a map of the form $$\varphi : V_1 \rightarrow V_2, \qquad \varphi = [f_0,\ldots,f_n]$$ where the functions $f_0,...,f_n ∈ K(V_1)$ have the property that for every point $P ∈ V_1$ at which $f_0,...,f_n$ are all defined, $$\varphi (P) = f_0(P),...,f_n(P).$$ (p.11, The Arithmetic of Elliptic Curves, Joseph H. Silverman) On the next page, the remark explains that you can often multiply by polynomials to knock out the problematic points wher the $f_i$ 's are undefined. It seems to me that we can always do this. For instance, the map $$\varphi : \mathbb{P}^1 \rightarrow \mathbb{P}^1, \qquad [x,y] \mapsto [A(x,y)/B(x,y),C(x,y)/D(x,y)]$$ seems to be the same as the map $$\psi: \mathbb{P}^1 \rightarrow \mathbb{P}^1, \qquad [x,y] \mapsto [A(x,y)D(x,y),C(x,y)B(x,t)].$$ If so, it's not clear to my why we bother allowing the $f_i$ to be rational functions, when they could easily be assumed to be polynomials via the above trick. What am I not understanding?","['terminology', 'projective-geometry', 'algebraic-geometry']"
2430193,Group Russian Roulette,"This problem is from ""Mathematical Puzzles: A Connoisseur's Collection"" (P. Winkler, AK Peters, 2005) as the opening puzzle in the chapter ""Probability"". There are N armed people. At each chime of a clock everyone spins around and shoots a random other person. That person falls dead. AT THE NEXT CHIME, The survivors shoot again. Eventually either everyone is dead, or there is a single survivor. Given N, what is the chance that this game ends with a single survivor? Winkler's problem asks "" What is the probability of there being a survivor as N increases to infinity. The answer says ""Amazingly, this probability does not tend to a limit as N grows. ... "". The seeming simplicity of this problem made me think it would be easy to find an expression for the probability of a survivor as a function of N. I got nowhere, so i put it out here to see if anyone could provide some insight. I thought it should be pretty straightforward, but it already gets bogged down to compute the probability of there being a survivor even when N is as low as 4 or 5. So, here's my question-
  What is the probability, that with N shooters,  one will be left standing??",['probability']
2430303,The probability of hitting equally distanced mines on a straight line,"Recently I was given the following problem. Anti-tank mines are placed on a straight line 15 meters apart from each other. The tank, 3 meters wide, runs perpendicular to this line. What is the probability that the tank will hit a mine. My problem with this question is that the exact length of the line is not given. I guess depending on the length of the line, the probability might be different. It seems to me that the problem is not well defined. What is your opinion?",['probability']
2430323,What is the likelihood of two line segments crossing?,Consider a square space. Randomly select 4 points. Randomly connect two sets of two to each other with line segments. What is the chance of the line segments intersecting? (I will maybe try and solve this with a little Monte-Carlo simulation but would be very interested in an analytic solution.),"['probability', 'geometry']"
2430333,Homeomorphism of two compact sets,"If I have two compact subsets, $A$ and $B$, of the plane $\mathbb{C}$, and we know that $\partial A$ and $\partial B$ are homeomorphic, can we say that $A$ and $B$ are homeomorphic?",['general-topology']
2430361,The boundedness of norms of iterates of a linear operator,"Let $T$ be a linear bounded operator on a Banach space $X$. Suppose that $(a_n)$ and $(b_n)$ are two increasing sequences of positive integers such that $b_n > a_n$ for any $n$ and such that $\sup_{n}(b_n - a_n)<\infty$. Furthermore, assume that $\sup_{n}\|T^{b_n}\|<\infty$. Does it follow necessarily that $\sup_{n}\|T^{a_n}\|<\infty$? Note: the assumption clearly implies that the spectral radius of $T$, i.e., $\rho(T) = \lim \|T^n\|^{1/n}$, is at most $1$. However, an operator with spectral radius $1$ can   have unbounded norms of iterates, for example
$T = \left(\begin{smallmatrix} 1 & 1 \\ 0 & 1 \end{smallmatrix}\right) $ on $\mathbb{R}^2$.","['functional-analysis', 'normed-spaces', 'operator-theory']"
2430386,Proof by induction of Bézout's identity for $n$ integers with no common factors,"Question:
Let $n\geq 2$. For any integers $a_1,a_2,\ldots,a_n$ having no common factor, there exists integers $x_1,x_2,\ldots,x_n$ such that 
$$a_1 x_1 + a_2 x_2 + \ldots + a_n x_n = 1.$$ This is what they did and I don't understand $(\star)$ and $(\star \star)$: $P(n)$ is the predicate above. Basis: $P(2)$ is true by Bezout's Identity. Induction step: Let $k\in\mathbb{N}$ with $k\geq 2.$ Now assume that $P(k)$ is true, and let $a_1,a_2,\ldots,a_k,a_{k+1}$ be integers with no common factor. We must deduce that $$a_1 x_1 + \ldots + a_k x_k + a_{k+1}x_{k+1} = 1$$
for some integers $x_1,x_2,\ldots,x_{k+1}$. Let $g$ be the greatest common divisor of $a_1,\ldots,a_k$ $\qquad(\star)$ Then $\frac{a_1}{g},\ldots,\frac{a_k}{g}$ have no common factor. By the induction assumption, there exists integers $y_1,\ldots,y_k$ such that $$\left(\frac{a_1}{g}\right)y_1 + \ldots + \left(\frac{a_k}{g}\right)y_k = 1.$$ Also, $g$ and $a_{k+1}$ cannot have a common factor (else, $g$ would be a common factor of $a_1,\ldots,a_{k+1}$.) So by the Basis case, $\qquad (\star\star)$ $$gz+a_{k+1}z_{k+1} = 1$$
for some integers $z,z_{k+1}$. So my query is: $(\star)$: I thought that from assumption in the induction case, we assumed all those integers have no common factor? $(\star\star)$: Why do we use the basis case? Is this allowed? I've never seen a proof by induction in the induction step that uses the ""basis case""?","['discrete-mathematics', 'proof-explanation', 'elementary-number-theory']"
2430408,"Determine values of $ \ p , \ q \ $ if we have$ \ (3 \mathbb{Z}+1) \cap (4 \mathbb{Z}+2) =(p \mathbb{Z}+q) \ $","Determine values of $ \ p , \ q \ $ if we have $ \ (3 \mathbb{Z}+1) \cap (4 \mathbb{Z}+2) =(p \mathbb{Z}+q) \ $ Also use set comprehension notation for $ \ (r \mathbb{Z}+t) \cup 3 \mathbb{Z} \ , \ \ r \neq t  , \ \ r,t \in \mathbb{Z} $ Answer: $ (3 \mathbb{Z}+1) \cap (4 \mathbb{Z}+2) =(p \mathbb{Z}+q) \\ \Rightarrow \{a \in \mathbb{Z} | a=3k+1 \} \cap \{b \in \mathbb{Z} | b=4k'+2 \}=(p \mathbb{Z}+q) \\ \Rightarrow \{a \in \mathbb{Z} | a=b \} =(p \mathbb{Z}+q)$ But I can't proceed further . If there is any help ?",['elementary-set-theory']
2430451,Integration by Parts for multivariable functions,"Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$. Let also $f$ be twice continuously differentiable, $f \in C^2(\mathbb{R}^2)$,
and the function $\frac{\partial}{\partial x_1} \frac{\partial}{\partial x_2} f(x_1,x_2)$ be absolutely integrable,
$\frac{\partial}{\partial x_1} \frac{\partial}{\partial x_2} f(x_1,x_2)\in L_1(\mathbb{R}^2)$. I am wondering what are sufficient conditions for the following identity to hold
\begin{align*}
	 &\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} \frac{\partial}{\partial x_1} \frac{\partial}{\partial x_2} f(x_1,x_2)  dx_1dx_2\\
	 &\qquad\qquad=
	 \left(f(x_1,x_2)\Big\vert_{x_1=-\infty}^{x_1=+\infty} \right)\Big\vert_{x_2=-\infty}^{x_2=+\infty}\\
	  &\qquad\qquad= 
	 f(+\infty,+\infty) - f(+\infty,-\infty) -  f(-\infty,+\infty) + f(-\infty,-\infty)?
\end{align*} I would appreciate any ideas, suggestions, counterexamples. Thanks!","['integration', 'calculus', 'analysis']"
2430467,Possible outcomes of rolling two dice,"When you roll two dice at the same time which look same, what's the number of possible cases? My friend thinks '21' because they are not distinguished, that is (1,2)=(2,1), (1,3)=(3,1), ... (5,6)=(6,5) And I think the answer is 36 because they are different die even though they are not distinguished. I also think that 36 is right because if 21 is right, there will be a problem on computing probabilities of the events. I'm so confused Can anybody tell me what's the correct answer of this problem and the reason?","['probability', 'dice', 'discrete-mathematics']"
2430470,Randomising with adjacency constraints,"I am a high school political science teacher looking for some help in implementing a classroom exercise. It's a puzzle of sorts, I suppose. I've tried Googling the issue for a while, but my GoogleFu is simply not good enough to get me the solution I need. I apologise if I'm unclear in my description below. I want my class of 9 students to create a chain of arguments that respond to the previous one in the chain. I would like each student to be working in parallel, so there will be 9 chains being built simultaneously. I visualise it as a 9x9 table, with the columns being the themes of the argument chains and the rows being the responses. I would like to generate an order in which my students will be responding to arguments such that: 1) Each student is represented only once in each 'row' (responses). 2) Each student is represented only once in each 'column' (chain). 3) No student responds to the same student more than once, that is, in the vertical order of the columns, student X does not succeed Y in more than one column. I'm happy to be directed elsewhere if my question is not appropriate. Thanks for your help!","['puzzle', 'combinatorics', 'combinatorial-designs', 'latin-square']"
2430472,Total derivative not unique?,"I probably did something wrong as I get two different total derivatives, but I don't see what. I use this definition: https://en.wikipedia.org/wiki/Total_derivative#The_total_derivative_as_a_linear_map Let $f(x, y) = (x + y, x^2 + y^2, xy)$. Then $f(\xi + h) - f(\xi) = (h_1 + h_2, 2\xi_1h_1 + 2\xi_2h_2 + h_1^2 + h_2^2, \xi_1h_2 + \xi_2h_1 + h_1h_2) = (h_1 + h_2, 2\xi_1h_1 + 2\xi_2h_2, \xi_1h_2 + \xi_2h_1) + (0, ||h||^2, h_1h_2)$ but also $= (0, 2\xi_1h_1 + 2\xi_2h_2, \xi_1h_2 + \xi_2h_1) + (h_1 + h_2, ||h||^2, h_1h_2)$. In both cases, if we fill it in the definition with the first vector the linear map aka total derivative and call the second $R(h)$ we get in both cases $0 < \frac{||R(h)||}{||h||} < \frac{||h||^2}{||h||} = ||h||$, so both tend to 0 as h tends to 0 by the squeeze theorem. But that would mean we have two different total differentials which is impossible. Where do I go wrong?","['multivariable-calculus', 'real-analysis', 'frechet-derivative']"
2430475,surjective morphism of algebraic groups and fppf topology,"I'm reading Milne's course notes on Affine Group Schemes: http://www.jmilne.org/math/CourseNotes/AGS.pdf In Definition 7.1 it says: ""
A homomorphism $G \to Q$ of affine groups is said to be surjective (and
$Q$ is called a quotient of $G$) if the homomorphism $\mathcal O(Q)\to \mathcal O(G)$ is faithfully flat."" I'd like to have some further motivation for this definition: The definition seems to be related to the category of fppf-sheaves. Why is this the right category to work in? Can I simply switch categories an assume that the affine group schemes are fppf-sheaves? What is a surjective map in the category of fppf-sheaves? And/Or: how is a surjective map of fppf-sheaves related to ""$\mathcal O(Q)\to \mathcal O(G)$ is faithfully flat""? And finally, what happens if G and Q are not affine? What is the right notion of a surjective map?","['algebraic-groups', 'group-schemes', 'algebraic-geometry']"
2430517,What is the correct domain for this function?,"Consider the function $f(x)=\sin x\cdot\cos x\cdot\csc x\cdot\sec x$ Now we know that $\csc x$ is undefined ($\infty$) at $x=n\pi,n\in \mathbb Z$.Also $\sec x$ is undefined at $x=\frac {2n+1}{2}\pi,\ n\in\mathbb Z$. So the value of $f(x)$ at $x=\frac n2\pi, n\in \mathbb Z$ is undefined. So the domain of $f$ is $$Dom\ f=\left\{x\ |\ x \in \mathbb R\ \land\ x\ne\frac{n}{2}\pi\ \text{for any }n\in \mathbb Z\right\}$$ But by simplifying the expression for $f(x)$, we get
$$\begin{align}
f(x)&=\sin x\cdot\cos x\cdot\csc x\cdot\sec x\\
&= (\sin x\times\csc x)(\cos x\times\sec x)\\
&=(1)(1)\\
&=1
\end{align}$$
which is defined for all $x\in\mathbb R$. So by this method
$$Dom\ f=\mathbb R$$
Why is there a difference in the results of these methods and which one is the correct one?","['elementary-set-theory', 'trigonometry', 'functions']"
2430528,Why is the group cohomology for a profinite group always torsion?,"Let $G$ be a profinite group, $A$ be a discrete $G$-module, and $n>0$ be an integer. Why is the cohomology group $H^n(G;A)$ a torsion abelian group? Here $H^n$ denotes the continuous cohomology groups. This thread is related, but I didn't find the answer to my question. — I know that any (continuous) cocycle $f : G^n \to A$ has finite image, for $G$ is compact and $A$ is discrete. If the subgroup generated by the image of $f$ inside $A$ is also finite (say of cardinality $k$), then $k \cdot f = 0 : G^n \to A$ so that the class of $f$ in $H^n(G;A)$ has order at most $k$. 
If $f$ is also a group morphism, which holds if $n=1$ and $A$ is a trivial $G$-module, then the image of $f$ inside $A$ is already a subgroup, so the aforementioned condition is satisfied. – But in general, we only want to find a multiple of $f$ which is a coboundary (without this multiple to be the zero map itself, as it was the case above). I'm not sure how to proceed. Is there may a smarter way to do it? Thank you!","['abstract-algebra', 'group-cohomology', 'profinite-groups', 'torsion-groups']"
2430546,"Expectation of $\frac{X_{1}+X_{2}+X_{3}+...+X_{k}}{X_{1}+X_{2}+X_{3}+...+X_{n}}$ , $1 \leq k \leq n$?","Prove the following statement: Let $X_{1},X_{2}, \dots ,X_{n}$ be a set of exchangeable random variables. Then, $$E\left(\frac{X_{1}+X_{2}+X_{3}+\dots +X_{k}}{X_{1}+X_{2}+X_{3}+\dots +X_{n}}\right) = \frac{k}{n}  , \qquad 1 \leq k \leq n. $$ I tried writing $\frac{X_{1}+X_{2}+X_{3}+...+X_{k}}{X_{1}+X_{2}+X_{3}+...+X_{n}}$ 
in a nice form so that I can make calculations easier but only i could try is $1 - \frac{X_{k+1}+X_{k+2}+X_{k+3}+...+X_{n}}{X_{1}+X_{2}+X_{3}+...+X_{n}}$ and I am facing the same looking sum again,also can we use some trick as we know $E(X_{1}) = E(X_{i})$ for $i = 1,2,3,...,n$? Also induction may help,i think. Source: Problem 4.3-6 p. 126 of An introduction to Probability and Statistics by Rohatgi and Saleh. Any help is great!","['probability-theory', 'expectation', 'probability-distributions']"
2430553,How to solve $\cos({r^{-4}}\cos 4\theta - {4\theta}) = 0$ for $\theta$ and $r$?,"Problem Statement How does one solve the trigonometric equation
  $$\cos({r^{-4}}\cos 4\theta - {4\theta}) = 0$$ for $\theta$ and $r$? My Try Taking the inverse cosines of both sides, I get
$${r^{-4}}\cos 4\theta - {4\theta} = \cos^{-1}(0) = \frac{\pi}{2}+k\pi.$$ Rearranging the last equation gives
$$\frac{\cos 4\theta}{4 \theta} - r^4 = \frac{{r^4}\left(\frac{\pi}{2}+k\pi\right)}{4 \theta}.$$ This is where I get stuck. QUERY Of course, I know that I can rewrite the last equation as
  $$\cos 4\theta = {r^4}\left(4\theta + \frac{\pi}{2} + k\pi\right).$$ Unfortunately, I do not know what to do or what approach to take past this point.  Should I use iteration to approximate the solution(s), if any?  Or is it (logically) possible to prove that there do not exist any solutions to this equation? Thanks! Added September 15 2017 Actually, I have
$$r = (x^2 + y^2)^{1/2} := f(x, y)$$
and
$$\theta = \tan^{-1}\left(\frac{y}{x}\right) := g(x,y).$$
Does that help?","['algebra-precalculus', 'trigonometry', 'proof-verification']"
