question_id,title,body,tags
878487,Flat connection with non-trivial holonomy? I cannot get it,"maybe this is a dumb question, but I cannot understand how a principal $G$-bundle can have non-trivial holonomy with a flat connection. Maybe I'm missing something, but doesn't Ambrose-Singer theorem say that the holonomy is generated by the curvature? So if it vanishes, wouldn't holonomy be trivial? Furthermore, why a non-flat connection can have non-trivial holonomy on contractible paths? Doesn't the lifting depends only on homotopy? Can someone, please, show me a trivial example explaining these two facts?","['holonomy', 'principal-bundles', 'differential-geometry']"
878489,Radius of convergence continuous?,"Let $ f: [0,1] \rightarrow \mathbb{R} $ be analytic. Let $ r_f(x) $ be the radius of convergence of $ f $ at $ x $. Is $ r_x(f) $ continuous? Alternatively, is there an $ r_{min} $ I can choose so that the power series of $ f $ about $ x $ converges in $ (x-r_{min},\;  x+ r_{min}) $ for all $ x $. Obviously if $ r_f(x) $ is continuous, then this will be true. Also does this hold in higher dimensions, ie $ f: [0,1] \times [0,1] \rightarrow \mathbb{R} $? Thank you for reading!","['calculus', 'analyticity', 'real-analysis']"
878505,Linearize a first order differential equation,"The system described by $x'=2x^2-8$ is linearized about the equilibrium point -2. What is the 
resulting linearized equation? Answer is $x'=-8x-16$. How? I have no idea how it went from the first equation to the 2nd. Thanks.",['ordinary-differential-equations']
878507,The meaning of Inverse Matrix,"I am studying Linear Algebra, I have 3 questions in my mind What does an inverse matrix mean. I am trying to have a meaning of it, but I don't really understand. When a matrix does not have an inverse matrix, what does it mean? Hope to hear your expertise. I am sorry if I have place my questions in the wrong places.
Thank you.",['linear-algebra']
878519,Prove that $\sin(12^\circ)\sin(48^\circ)\sin(54^\circ)=\frac18$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Prove that $$\sin(12^\circ)\sin(48^\circ)\sin(54^\circ)=\frac18.$$ Without using a calculator. I tried all identities I know but I have no idea how to proceed. I always get stuck on finding $\sin36^\circ$.","['trigonometry', 'algebra-precalculus']"
878533,What is the solution to the system $\frac{df_n}{dt} = kf_{n-1}-(k+l)f_n+lf_{n+1}$?,"I'm trying to solve the system $$
\begin{matrix}
& \frac{df_1}{dt} = kf_1+lf_2 \\
& \vdots \\
& \frac{df_n}{dt} = kf_{n-1}-(k+l)f_n+lf_{n+1} \\
& \vdots \\
& \frac{df_N}{dt} = kf_{N-1}-lf_N
\end{matrix}
\tag{1}$$ with $f_1 (0) = f_0$ and $\forall n \neq 1 \ [f_n(0)=0]$, where $k$, $l$ and $f_0$ are real positive constants. The system may also be represented diagrammatically as $\fbox{1}\leftrightarrow
\fbox{2}\leftrightarrow
\fbox{3}\leftrightarrow
\cdots\leftrightarrow
\fbox{N}$ if this is desired. What is the solution to that system? I would like to study the cases where $N$ is finite and arbitrarily large. The standard general method (substitute exponentials, solve the resulting linear system) when followed directly becomes untractable for large N; I believe that a method that takes advantage of particular features of the problem besides linearity will be fruitful. There are two methods that I have considered, but I have been unable to carry out the calculation in either of them to completion. First, a direct method, using Laplace transforms; a strategy that renders the solution of the case $l=0$ particularly easy. Setting $t\rightarrow lt$ and defining $r = \tfrac{k}{l}$ eliminates one parameter, so that for some $n \neq 1,N$ $$
\frac{df_n}{dt} = rf_{n-1}-(r+1)f_n+f_{n+1}
$$ Taking the laplace transform ($f(t) \mapsto \tilde{f}(s)$) and rewriting the system in matrix form leads to the linear system $$
\begin{pmatrix}
 s+r   &   -1   &   0    &    0    &    0    &        & \cdots & \cdots &  0  \\
 -r    &  s+r+1 &  -1    &    0    &    0    &        & \cdots & \cdots &  0  \\
  0    &   -r   & s+r+1  &   -1    &    0    &        & \cdots & \cdots &  0  \\
  0    &    0   &  -r    &  s+r+1  &   -1    &        & \cdots & \cdots &  0  \\
\vdots & \vdots & \vdots & \vdots  &         & \ddots & \ddots & \ddots &\vdots\\
   0   &    0   &    0   &    0    & \cdots  & 0      &   -r   & s+r+1  &  -1 \\
   0   &    0   &    0   &    0    & \cdots  & 0      &    0   &  -r    & s+1 \\
\end{pmatrix}
\mathbf{f}_s
=
f_0
\begin{pmatrix}
1 \\
0 \\
0 \\
0 \\
\vdots\\
0 \\
0 \\
\end{pmatrix}
\Leftrightarrow \mathcal{T}_{N,s} \mathbf{f}_s = 
f_0 
\begin{pmatrix} 1\\ 0\\ \vdots \end{pmatrix}
$$ I am not sure how to proceed with solving this system, however I do believe that a recursive relation can be found without too much effort. I also suspect that the fact that $\mathcal{T}$ is a tridiagonal 'perturbed' Toeplitz matrix should help in the calculation.
However, since this solution leads to rational functions with an N-th degree polynomial in the denominator, for which the inverse Laplace transform must be calculated and in general factorising a polynomial of arbitrary degree cannot be done analytically, I abandon the calculation at this stage (I have worked out solutions for N=3 but even then the calculations are very long and tedious when done directly). There may be some shortcut to estimating the solution using this method - but I fail to see it. The second method that I have tried (which in reality it is more of an outline than a complete calculation) is to notice that the original system can be seen as a sum of all possible (and terminating) 'histories', such as $\fbox{1} \fbox{2} \fbox{3} \fbox{2} \fbox{3} \fbox{4} \cdots$ and $\fbox{1} \fbox{2} \fbox{3} \fbox{4} \fbox{5} \fbox{4} \fbox{3} \fbox{2} \cdots$. The solution for individual 'histories' (for the intermediate states) will be of the form $$
\sum_{m} { \left[ a_m \frac{(-kt)^m}{m!} e^{-kt} + b_m \frac{(-lt)^m}{m!} e^{-lt} \right] }
\tag{2}
$$ implying that the final solution of (1) must have a representation of the form $$\sum_{Histories} {\sum_{m} { \left[ a_m \frac{(-kt)^m}{m!} e^{-kt} + b_m \frac{(-lt)^m}{m!} e^{-lt} \right] }}$$ so that perhaps a solution like (2) can be used as an ansatz for the original equation. But I am not certain if this process is along the right path either. I have also thought of follwoing the usual method for linear systems of ODEs, i.e. calculating the spectrum of $\mathcal{T}_{r,1}$ $$
\mathcal{T}_{r,1} =
\begin{pmatrix}
  -r   &    1    &    0   &    0    & \cdots & \cdots & \cdots & \cdots \\
   r   &   -r-1  &    1   &    0    & \cdots & \cdots & \cdots & \cdots \\
   0   &    r    &  -r-1  &    1    & \cdots & \cdots & \cdots & \cdots \\
\vdots & \vdots  & \vdots & \vdots  & \ddots &        &        &        \\
       &         &        &         &        &    r   &  -r-1  &   -1   \\
       &         &        &         & \cdots &    0   &    r   &   -1   \\
\end{pmatrix}
$$ which contains $-r-1$ alsong the diagonal (apart of positions {1,1} and {N,N}, which are $-r$ and $-1$ respecively) $r$ in the subdiagonal and $-1$ in the superdiagonal. I am not certain how to calculate this either for arbitrary N. Help will be greatly appreciated!","['dynamical-systems', 'systems-of-equations', 'linear-algebra', 'ordinary-differential-equations']"
878586,not following a step in ash and novinger example of analytic but does not have primitive,"I'm trying to self-study complex analysis and am currently reading the book ""complex analysis"" book by ash and novick. 0n the top of page 14, they write that , if $f(z) = \frac{1}{z}$ and the path integral is over the path, $\exp(it)$, for 
$ 0 \le t \le 2\pi$, then $\int_{\gamma} = \int_{0}^{2\pi} \frac{1}{z} dz  
= [_{0}^{2\pi}\frac{i \exp(it)}{\exp(it)} dt = 2\pi $. That was clear. But then they explain that, for this example, the theorem that $\int_{\gamma} f(z) dz = 0$ when the path $\gamma$ is closed does not hold  because this is an example where $f(z)$ is analytic on $C - \{0\}$ but it does not have a primitive on $C - \{0\}$. I thought having a primitive and being analytic was the same thing so could someone explain the difference ? Even more importantly, could someone explain what's going on with this example that makes the path integral not be zero. Thanks a lot.",['complex-analysis']
878610,Automorphisms of $\mathbb{Z}/p\oplus\cdots\oplus \mathbb{Z}/p$,"Consider the abelian group
$$G = \underbrace{\mathbb{Z}/p\oplus\cdots\oplus \mathbb{Z}/p}_{n},$$
where $p$ is prime and $1\le n \le p$. I want to show that $G$ has no automorphism of order $p^2$. I observe that group automorphism of $G$ is the same as linear isomorphism of $G$ as a $\mathbb{Z}/p$-vector space. So the question is the same as to prove that there is no $n\times n$ invertible matrix in $\mathbb{Z}/p$ that has order $p^2$. My attempt is to calculate the order of $GL(n,\mathbb{Z}/p)$ and show that $p^2$ does not divide that order, but unfortunately this only works for $n\le 2$.","['linear-algebra', 'group-theory', 'abstract-algebra', 'abelian-groups']"
878613,Difference isometrically isomorphism and homeomophism.,What is the difference between isometrically isomorphism and homeomorphism?is an isometric mapping is continuous?,['functional-analysis']
878625,When is a power of an $m$-cycle also an $m$-cycle?,"I have a question taken from Abstract Algebra by Dummit and Foote
(pg. 33, q.11): Let $\sigma\in S_{n}$ be an $m$ -cycle. Show that $\sigma^{k}$ is
  also an $m$ -cycle iff $\gcd(k,m)=1$ . My efforts: By considering a few examples I believe that $\sigma^{k}$ decomposition
is a multiplication of cycles where each cycle is of length $\frac{m}{\gcd(k,m)}$ I have tried proving this by showing that $$
\frac{m}{\gcd(k,m)}+k\equiv_{m}1
$$ which shows that $\sigma^{k}$ maps $\frac{m}{\gcd(k,m)}$ back to $1$ hence is the cycle length (at least for the first cycle in the
decomposition, but I imagine that proving similar claim for the other
circles can be done analogy) . I have tried showing this by writing the equivalence as $$
m\mid\frac{m}{\gcd(k,m)}+k-1
$$ and trying to manipulate the above expression to see the divisibility,
but I haven't managed to do so.","['permutation-cycles', 'permutations', 'group-theory', 'abstract-algebra']"
878660,Atiyah-Macdonald Exercise 2.15,"I have worked out a solution to exercise 2.15 of Atiyah-Macdonald, which is needed in the solution of 2.3 (see Atiyah-Macdonald 2.3 ).  However, the solution seems overly complicated, and I am not entirely sure about the argument in part 2. Any corrections and/or improvements would be appreciated. Question: Let $A, B$ be rings (commutative, with $1$). Let $M$ be a module over $A$ and $P$ be a module over $B.$  Let $N$ be a bimodule over $A$ and $B$; that is, $N$ is simultaneously a module over $A$ and over $B$ and the operations are compatible in the sense that $(ax)b=a(xb)$ for $x\in N, a \in A, b \in B.$ Then $(M \otimes_A N) \otimes_B P \sim M \otimes_A ( N \otimes_B P).$  Here “$\sim$” denotes isomorphism, where both sides are viewed bimodules over $A$ and $B$. Attempt at solution: Step 1: For fixed $p \in P,$ define the map $f_p: M \times N \to  M \otimes_A (N \otimes_B P)$ which takes $(m, n) \mapsto m \otimes_A (n \otimes_B p).$ It’s easy to see that $f_p$ is $A-$multilinear.  Hence it induces a map $f’_p: M \otimes_A N \to M \otimes_A (N \otimes_B P)$ which is a homomorphism of $A-$modules such that $f’_p(m \otimes n) = m \otimes_A (n \otimes_B p)$. Step 2: Define now $g: (M\otimes_A N) \times P \to M \otimes_A ( N \otimes_B P)$ by $ g(x,y)= f_y’(x).$   We want to show that $g$ is $B-$multilinear. We show first that $g$ is $B-$multilinear in the first component.  Note that an element $x\in M\otimes_A B$ is of the form $x = \sum_1^{n} m_i \otimes_A n_i,$ with the $m_i \in M$ and $n_i \in N.$ Hence, for $\lambda \in B,$ we have $\lambda x_0+ x_1= \lambda \sum_1^{n_0} m^0_i \otimes_A n^0_i + \sum_1^{n_1} m^1_i \otimes_A n^1_i = \sum_1^{n_0} m^0_i \otimes_A \lambda n^0_i + \sum_1^{n_1} m^1_i \otimes_A n^1_i.$ Hence, we have \begin{align}
g(\lambda x_0+x_1, p)&= g( \sum_1^{n_0}(m^0_i \otimes_A \lambda n^0_i) + \sum_1^{n_1}(m^1_i \otimes_A n^1_i) , p) \\
&=\sum_1^{n_0} m^0_i \otimes_A (\lambda n^0_i \otimes_B p) + \sum_1^{n_1} m^1_i \otimes_A (n^1_i \otimes_B p) \\
&=\lambda \sum_1^{n_0} m^0_i \otimes_A (n^0_i \otimes_B p) + \sum_1^{n_1} m^1_i \otimes_A (n^1_i \otimes_B p) \\
&= \lambda g(x_0,p)+ g(x_1,p),
\end{align} where we have used the fact that $g(\cdot,y)=f’_y(\cdot)$ is $A-$linear. We can show that $g$ is $B-$linear in the second component by a similar argument. Step 3: To show this is an isomorphism, we construct an inverse mapping by the same procedure.","['commutative-algebra', 'abstract-algebra']"
878668,Is this another version of the gamma function?,"I know that $\Gamma  \left( x \right) $ is the unique function on $x \in (0, \infty)$ such that $f \left( 1 \right) =1$ $f(x+1)=xf(x)$ ${\frac {d^{2}}{d{x}^{2}}}ln(f \left( x \right))>0$ However define the set of functions $g(x)=\Gamma(x){e^{2\pi inx}}\:for\:n\in \Bbb Z$ and $i=\sqrt{-1}$, then $g(1)=\Gamma(1)e^{2\pi in}=1$ $g(x+1)=\Gamma(x+1){e^{2\pi in(x+1)}}=x\Gamma(x){e^{2\pi inx}}{e^{2\pi in}}=x\Gamma(x){e^{2\pi inx}}=xg(x)$ ${\frac {d^{2}}{d{x}^{2}}}ln(g \left( x \right))={\frac {d^{2}}{d{x}^{2}}}(ln(\Gamma(x))+2\pi i n x)={\frac {d^2}{dx^2}}ln(\Gamma(x))>0$ so therefore $g(x)=\Gamma(x)$ for $x\in(0,\infty)$. However, this is obviously not true, but it satisfies all the conditions of the Bohr-Mollerup theorem. Why is this? Is this some other version of the Gamma function? If anyone's curious, I got this idea from this post","['gamma-function', 'analysis']"
878686,Algebra problem (deriving a variable in a formula),"How do I derive the $m$ in the formula:
$$I=\left(1+\frac{r}{m}\right)^{mn} -1$$ all the values of the variables in the formula except $m$ is given and the question is find $m$.
I just don't know how to derive the formula using the knowledge of Algebra I have.",['algebra-precalculus']
878698,"Integral: $\int_0^{\pi} \frac{x}{x^2+\ln^2(2\sin x)}\,dx$","I am trying to solve the following by elementary methods:
$$\int_0^{\pi} \frac{x}{x^2+\ln^2(2\sin x)}\,dx$$ I wrote the integral as:
$$\Re\int_0^{\pi} \frac{dx}{x-i\ln(2\sin x)}$$
But I don't find this easier than the original integral. I have seen solutions which make use of complex analysis but I am interested in elementary approaches. Any help is appreciated. Thanks!","['definite-integrals', 'closed-form', 'calculus', 'integration']"
878707,Non integer derivative of $1/p(x)$,"I need to find the $k$'th derivative of $1/p(x)$, where $p(x)$ is a polynomial and $k\in\mathbb{R}$ It dosen't have to be an explicit formula, an algorithm which finds a formula for some $k$ is fine.","['fractional-calculus', 'calculus', 'derivatives']"
878709,Sketching a surface,"If $${\bf F}=2y{\bf i}-z{\bf j}+x^2{\bf k},$$ and $s$ is the surface of the parabolic cylinder $y^2=8x$ in the first octant, bounded by the planes $y=4$ and $z=6$, evaluate $$\int_S{\bf F}\cdot{\bf\hat n}\,dS,$$ where $\bf\hat n$ points in the direction of increasing $x$, by projecting the integral onto the plane $x=0$. I'm trying to draw a sketch to get a feel of the situation but am confused as to what the question is asking. I have sketched $y^2=8x$ in the plane $z=0$ and marked on the points where $y$ and $z$ are bounded.","['multivariable-calculus', 'surfaces', 'graphing-functions']"
878748,the use of Cartesian product,"I am currently studying in secondery level. I read cartesian product the other day and I found it absolutely bizarre. In my text book, there is this ""order pair"" which I understood fairly well and then there is cartesian product in which we multiply two sets. I don't understand the concept behind it. What is its application? How will it come to use in higher level study?",['elementary-set-theory']
878755,Coordinate ring of the product of projective variety,"Let $X\subseteq \mathbb{P}^r,Y \subseteq \mathbb{P}^s$ be two projectve varieties,what is the coordinate ring of $X\times Y$(segre embedding)?Is it true that $$S(X\times Y)=S(X)\otimes_k S(Y)?$$ I also want to know what is the dimension of $ X\times Y$? Edit:As Zhen Lin has indicated ,the equality $S(X\times Y)=S(X)\otimes_k S(Y)$ is not true.But what is the relationship between them,can we express $S(X\times Y)$ in terms of $S(X),S(Y)$?",['algebraic-geometry']
878758,"Video lectures of algebraic geometry (Hartshorne, Shafarevich, ... )","I am a commutative algebra student. Are there any video lectures on algebraic geometry available online for free? I'd like the lectures to cover main topics of the books like Hartshorne 's "" Algebraic Geometry "" or Shafarevich 's book, "" Basic Algebraic Geometry ."" I want to download, but if it is not for download, or isn't a career, please post it; it may be helpful for others. I've read "" Ideals, Varieties, and Algorithms "" by Cox, Little and O'Shea and almost 3 chapters of "" Algebraic Geometry "" of J.S. Milne, but there are gaps. Thanks a lot","['algebraic-geometry', 'big-list', 'reference-request', 'soft-question', 'online-resources']"
878770,Proximal Operator Fixed Point Property for Matrices,"$\newcommand{\prox}{\operatorname{prox}}$
$\newcommand{\argmin}{\operatorname{argmin}}$
$\newcommand{\dom}{\operatorname{dom}}$ Recall again that the proximal operator for vectors $\prox_{f}: R^n \rightarrow R^n$ of $f$ is defined as: $\prox_f(v) := \argmin_{x} \left(f(x) +(1/2)\|x-v\|_2^2 \right) $, where $f: R^n \rightarrow R \cup \infty$ is a closed proper convex function and $\|\cdot \|_2$ is the Euclidean norm. $\prox$ is strongly convex and not everywhere infinite, so there it will have a unique minimizer for every $v \in R^n$ The crucial property of proximal operator is that $x^*$ minimizes $f(x)$ iff $x^* = \prox_f(x^*)$, i.e. $x^*$ is a fixed point of $\prox_f$. Let us consider the proof of this property. The first part, namely, that if $x^*$ minimizes $f$ then $\prox_f(x^*)=x^*$, is trivial: $f(x) +(1/2)\|x-x^*\|_2^2 \le f(x^*) = f(x^*) +(1/2)\|x^*-x^*\|_2^2$ The second part uses the notion of subdifferential. In the proof authors say that $\tilde{x}$ minimizes $f(x) +(1/2)\|x-v\|_2^2$ i.e. $\tilde{x} = \prox_f(v)$ iff $0 \in \partial f(\tilde{x}) + (\tilde{x}-v)$, where the sum is of a set and a point. Recall the definition of the subdifferential: $\partial f(x) = \{ y$ |  $ f(z)\le f(x) + y^T(z-x)$ $\forall z \in \dom{f}\}$ Take $\tilde{x}=v=x^*$, it follows that $0 \in \partial f(x^*)$ so $x^*$ minimizes $f$. Question 1: Consider proximal operator defined for matrices now: $\prox_f(Y) := \argmin_{X} \left(f(X) +(1/2)\|X-Y\|^2 \right)$, where $X$ is some real $m$ by $n$ matrix. What norm function should be taken in the definition of the $\prox$ in this case? Frobenius? Or spectral norm (induced 2nd norm) which is the largest eigenvalue (is spectral norm even differentiable?)? Or something else? Question 2: Can the norm for the definition of $\prox$ in case of matrices be chosen in different ways? What conditions does the proof above impose on the norm function?","['matrices', 'convex-analysis', 'convex-optimization', 'proximal-operators']"
878775,"An ""obvious"" statement about a nonincreasing supremum","Consider a nonnegative function $f(t,x): [0,\infty) \times [0,1] \rightarrow [0, \infty)$.  Suppose we have the following property: $$ \mbox{ If } ~~~~~~~~~~f(t,y) > \frac{1}{2} \sup_{x \in [0,1]} f(t,x) ~~~~~~~\mbox{ then}~~~~~~~ \frac{d}{dt} f(t,y) < 0 $$ In words, if any $y$ has $f(t,y)$ at least half as big as the largest $f(t,\cdot)$, then $f(t,y)$ is decreasing. It seems very natural to guess that $$\sup_{x \in [0,1]} f(t,x) \mbox{ is nonincreasing in } t$$ This seems obvious - the ``top half'' of $f(t, \cdot)$ is always decreasing, so how can the supremum increase? But I don't see how to show this mathematically. Thus my question is whether this is true. Some comments: The above implicitly assumes that for each $x$, $f(t,x)$ is differentiable with respect to $t$. To make sure nothing weird happens at $t=0$, let us also assume that the function $f(t,x)$ is a continuous function of $t$ for each $x$. If it helps, we can further assume that its derivative $f_t(t,x)$ is a continuous function of $t$. Note that there is no assumption of differentiability or even continuity with respect to $x$. Furthermore, there is no assumption that the suprema in question must remain finite.","['real-analysis', 'analysis']"
878783,"General method to ""naturally interpolate"" to a complex map?","Given a region of the complex plane and a map $z \to f(z)$, is there a general way to ""naturally interpolate"" the point $z$ to $f(z)$ in such a way that the movement follows a ""natural"" smooth path that doesn't generate unnecessary ""kinks"" and overlaps? Background: I make educational animations . A couple of projects I've been playing around with involve complex numbers. I'm trying to figure out a general method to animate complex maps that look good and natural in terms of smooth deformations of the complex plane. Forgive me, but I have no way to confidently and formally state this question at this point. But I can illustrate it. Here's a great video illustrating Möbius transformations. You can see that for the inversion, the points on the plane follow a quite natural path from start to finish. This follows naturally from the rotation of the sphere used in the projection, in this particular case. But here's what a naive linear interpolation ($z \to (1-t) z + t f(z)$, with $0 \leq t \leq 1$) of the same transformation $z \to \frac{1}{z}$ looks like: As you can see, this method creates a lot of ""kinks"" and weird bends along the way. (Also, ignore the straight lines). I'm trying to avoid this, as it makes the animation more confusing than it should be. Some other examples. Here's the same method for $z \to z^2$: And $z \to e^z$ (using $[-1,1] \times [-\pi,\pi]$): In all these cases, I can imagine different and more natural ways to deform along the way, but I haven't come up with a general way to tackle this problem yet. I'm hoping there's something in complex analysis that can be helpful here, but I haven't found anything yet. Any ideas? EDIT : Here's $z \to e^z$ using Rahul's method with some translation: This is pretty much a perfect example of the sort of ""natural"" transformation I'm looking for. Each new step seems like an obvious deformation of the previous step following the same overall ""style"". It creates a nice sense of deliberation, which makes the movement intuitive, comprehensible and predictable.","['interpolation', 'geometry', 'complex-analysis']"
878785,"How to find an angle in range(0, 360) between 2 vectors?","I know that the common approach in order to find an angle is to calculate the dot product between 2 vectors and then calculate arcus cos of it. But in this solution I can get an angle only in the range(0, 180) degrees. What would be the proper way to get an angle in range of (0, 360)?","['geometry', 'angle', 'rotations']"
878800,"An exercise from my brother: $\int_{-1}^1\frac{\ln (2x-1)}{\sqrt[\large 6]{x(1-x)(1-2x)^4}}\,dx$","My brother asked me to calculate the following integral before we had dinner and I have been working to calculate it since then ($\pm\, 4$ hours). He said, it has a beautiful closed form but I doubt it and I guess he has tried to trick me again (as usual). So I am curious, what is the closed form ( if any ) of the following integral: \begin{equation}
\int_{-1}^1\frac{\ln (2x-1)}{\sqrt[\large 6]{x(1-x)(1-2x)^4}}\,dx
\end{equation} I have tried by parts method, partial fractions (stupid idea), converting into series (nothing familiar), many substitutions such as: $u=2x-1$, $u=1-x$, $x=\cos^2\theta$, etc, but I failed and got nothing. Wolfram Alpha also doesn't give an answer. Either he is lying to me or telling the truth, I don't know. Could anyone here please help me to obtain the closed form of the integral with any methods ( whatever it takes )? Any help would be greatly appreciated. Thank you.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
878804,When numbers of $1$ to $1000$ are written out in decimal notation. How many digits are $1$?,"Question: When numbers of $1$ to $1000$ are written out in decimal notation. How many digits are $1$? Attempt: $$1XX\\
X1X\\
XX1$$ The count of $1$ for the types above are,
$${{3}\choose{1}}*9*9$$ $$1000$$ Which is just one $1$. $$1X\\11\\X1$$ Which is $9+1+9 = 20$. $$11X\\1X1\\X11$$ Which contains, $${{3}\choose{1}}*9$$ And finally, $$1$$ Which is just 1. Adding them all together, $${3\choose 1}*81 + 1 + 9 + 1 + 9 + {3\choose 2}*9 + 1 = 291$$ The problem is the answer key demands $301$, if someone could point out what cases am I missing?",['discrete-mathematics']
878816,Solve inequality: $-5 < \frac{1}{x} < 0$,"Solve inequality: $-5 < \frac{1}{x} < 0$ I thought about how I can solve this. If I multiply all sides by $x$ I'm afraid I'm removing the answer, cause $\frac{x}{x}=1$. And when $x$ 'leaves' the inequality I'm left with no letter. How do I get just $x$ in the middle without adding $x$ to other sides or removing $x$? I then saw that: $\frac{1}{x} = -x$. So can I multiply all sides with $-1$. This also changes the signs. So I'm left with: $5> x > 0$. Is this correct? If not what did I do wrong?","['inequality', 'algebra-precalculus']"
878826,"Fundamental group of quotient of $S^1 \times [0,1]$","I have a past qual question here: Let $X = S^1 \times [0,1] /{\sim}$, where $(z,0) \sim (z^4,1)$ for $z \in S^1 = \{ z \in \mathbb{C} \colon \| z \| = 1 \}$. Compute $\pi_1(X)$. I've been trying to visualize $X$ as a cylinder of height 1 with the two ends identified `with a twist', but this has not seemed to help. Any help or hints would be much appreciated!","['general-topology', 'algebraic-topology', 'fundamental-groups']"
878847,Riesz measure associated with a subharmonic function,"In page  101, corollary 4.3.3., from Armitage and Gardiner's book on potential theory, the authors prove that any subharmonic function, can be identified with a positive measure (Riesz measure). In doing so, they consider the functional $L_s(\phi)=\int_\Omega s(x)\Delta \phi(x)$, $\Omega$ a open set, $\phi\in C_0^\infty(\Omega)$ and $s$ the subharmonic function. For any $\phi\in C_0(\Omega)$, he consider the mollified sequence $\phi_n$, which converges to $\phi$ uniformly and claim that $L_s(\phi_n)$ is Cauchy. Maybe, as he says, this is evident, however I fail to see it. If, for instance the regularized sequence $s_n$, is such that, $\Delta s_n$ is bounded uniformly in $L^1_{loc}(\Omega)$ then, the above is true, however, I also fail to see it. Any help is appreciated. Remark: I know how to extend $L_s$ to $C_0(\Omega)$, but with another approach, although the extension is the same, because of unicity. Update: For $x\in \Omega$, fix some $r>0$ such that $\overline{B(x,r)}\subset \Omega$.The regularization $s_n$ of $s$, is a sequence of subharmonic functions in $B(x,r)$ which converges decreasingly to $u$ in $B(x,r)$. Note that (Green's theorem) \begin{eqnarray}
 \int_{B(x,r)}|\Delta s_n| &=& \int_{B(x,r)} \Delta s_n      \nonumber \\
   &=& \int_{\partial B(x,r)} \frac{\partial s_n}{\partial\eta} \nonumber \\
   &=& r^{N-1}\frac{\partial}{\partial r}\left(\frac{1}{r^{N-1}}\int_{\partial B(x,r)}s_n\right) 
\end{eqnarray} Does anyone knows how to bound the right hand side uniformly in $n$? Also, note that the right hand side, can be written in terms of the average integral of $s_n$.","['potential-theory', 'partial-differential-equations', 'analysis']"
878851,How useful/useless is the indefinite integral,"After having met yet another person confused by indefinite integrals today, I've finally decided to ask the community. Do you think it makes sense to teach indefinite integrals? My opinion is that only definite integration should be taught since it is the only one that makes formal sense to me. Of course indefinite integrals can be used by people who know what they are doing, but it doesn't justify the introduction of this notion from the very beginning to the layest of the laymen. I would like to argue as follows: One often read/hears $\int..dx$ is the inverse of differentiation, its the anti-derivative. While one can make some sense of it, of course everybody knows that differentiation is an irreversible operation where information is lost, so there is no true inverse of that operation. For me the usage of ""anti-"" in the sense of ""almost-anti-"" is one source of confusion. In my opinion $\int f(x) dx$ should not be seen as a function, written like that, for my taste, I would say that it's not well-defined as a function. If it is a function, of what variable? Certainly not of $x$ . It would make slightly more sense to write $\int^t f(x)dx$ as now at least one can use this for differentiation. But still, as a function it is not completely unambiguous. Of course, there are applications where this additive uncertainty (which can be infinity) does not play a role, but again this is of no concern for people who are just being taught what integrals are. The only sensible use of writing $\int f(x)dx$ that I can imagine is as a sort of abbreviation in the sense ""you know what boundaries you have to insert, so let's just skip it"". It is like writing sums without giving the boundaries: $\sum f(n)$ , which I would generally avoid to do, unless everyone knows what is meant. Given that I see school text books full of indefinite integrals from the beginning and that the search on math.stackexchanges for ""indefinite integral"" gives >1000 results, where sometimes calculations of this sort (Link) are carried out with the result that $\int\frac{dx}{x}=\ln(x)$ without anyone complaining about the notation which is at most sketchy, and finally that searching wikipedia for ""indefinite integral"" automatically redirects to ""anti-derivative"", I would like to ask, what do you think about using indefinite integrals in mathematics? Should school children be exposed to it? Should it be taught? P.S.: this question has also been posted on MESE: (Link)","['integration', 'indefinite-integrals']"
878857,Properties of first-countable spaces,"Hi I have questions regarding first-countable spaces. I just want to confirm something: The following are properties regarding limits and continuity of first countable spaces on Wikipedia: If $f$ is a function on a first-countable space then $f$ has a limit $L$ at the point $a$ if and only if for every sequence $x_{n} \rightarrow a$ where $x_{n} \neq a$ for all $n$ we have $f(x_{n}) \rightarrow L$. If $f$ is a function on a first-countable space, then $f$ is continuous if and only if whenever $x_{n} \rightarrow a$ then $f(x_{n}) \rightarrow f(a)$. Assume that $f$ is defined on an open domain $\Omega$. I want confirm that property 1 allows $x \in \overline{\Omega}$ but property 2 requires that $a \in \Omega$? Secondly, I want to confirm that if $x \in \overline{\Omega} \setminus \Omega$ and we assume that $f$ is continuous on $\Omega$ then the only thing we can get from property 2 is that for any $x_{n} \rightarrow x$ it follows that $f(x_{n}) \rightarrow L$, where from 1 it follows that $L = \lim\limits_{x \rightarrow a}f(x)$? Thanks.","['general-topology', 'continuity']"
878872,Fundamental group smash product,is there a way to conclude what the first fundamental group of the smash product of two path-connected spaces is? probably there should be a general way like there is for the wedge sum due to van Kampen's theorem.,"['general-topology', 'algebraic-topology']"
878874,Absolute continuity of pushforward measure,"Problem: Let $\newcommand{\IR}{\mathbb{R}}\newcommand{\IL}{\mathcal{L}}\phi: \IR \times \IR^{n} \to \IR^n$ be $\IL^{n+1}$-measurable and satisfy for every $\IL^{n}$-nullset $A \subset \IR^n$ and $\IL^{1}$-almost every $t \in \IR$
$$
\IL^n(\{x: \phi(t,x) \in A\}) = 0.
$$
Show that then for all $\IL^{n+1}$-nullset $M \subset \IR^{n+1}$ it holds that
$$
\int \chi_M(t,\phi(t,x)) d\IL^{n+1} = 0.
$$ Remark: The last statement can be written as $(\operatorname{id},\phi)_\#\IL^{n+1} \ll \IL^{n+1}$ where we denote by $f_\#\mu$ the pushforward measure of $\mu$ under $f$. What I tried so far: I tried to use some standard Fubini argument. By setting
$$
M_t = \{x: (t,x) \in M\}
$$
we know by Fubini that, for $\IL^{1}$-almost every $t \in \IR$, we have $\IL^{n}(M_t)=0$. And thus, for each of these $t$, we get for $\IL^{1}$-almost every $s \in \IR$
$$
\IL^n(\{x: \phi(s,x) \in M_t\}) = 0.
$$
But I want to know something about the diagonal, i.e. $s=t$. I need that for $\IL^{1}$-almost every $t \in \IR$ we have $\IL^n(\{x: \phi(t,x) \in M_t\}) = 0$. Obviously we get this whenever $M$ can be written as $I \times M'$ for some $I \subset \IR$ and some $M' \subset \IR^n$. Anyhow, I don't know how this could help in getting the statement for general sets $M$.","['measure-theory', 'lebesgue-measure']"
878884,write this limit based on delta function,"If it’s possible, I want to write this limit based on delta function $$
\lim_{t\rightarrow 0}\frac{e^{-u/t}}{t^2},\qquad u>0
$$ would you mind helping me?",['limits']
878895,"If $X$ has CDF $F$, how can I find the CDF of $U= \max \{0,X \}$?","If $X$ has CDF $F$, how can I find the CDF of $U=\max\{0,X\}$? Obviously the suport of $U$ consists solely of nonnegative values. Am I right then in thinking  that for $u=0, F_U (u)=F_X(0)$ and for  $u > 0$, $F_U (u)
 =F_X(u)$? Thank you.","['statistics', 'self-learning', 'probability']"
878909,Question about proving that a ﬁnite intersection of big unions is a big union of ﬁnite intersections,"Let $I_{1}$,...$I_{k}$ be index sets and for each $1 \leq m \leq k$ and each $j \in I_{m}$, let $U_{j}$ be a set. Prove that:
$$(\bigcup\limits_{j_{1}\in I_{1}}U_{j_{1}}) \cap ... \cap(\bigcup\limits_{j_{k}\in I_{k}}U_{j_{k}}) = \bigcup\limits_{(j_{1},...,j_{k})\in I_{1} \times ... \times I_{k}}U_{j_{1}} \cap ... \cap U_{j_{k}} $$ I understand that I need to prove a finite intersection of big unions is a big union of finite intersections. How would I prove this?","['proof-writing', 'elementary-set-theory']"
878910,Calculating probabilities in horse racing!,"I've seen a few similar threads to this on different forums but they don't seem to conclude to a satisfactory answer. My question is this: If you have 3 horses, A, B, and C and you know the winning probabilities of each horse racing against each other as a pair, how do you work out their winning probabilities if all 3 horses race together? Is there a formula for n number of horses? So you know the probabilities of:
A beating B
A beating C
BA
BC
CA
CB I initially thought that: p(A winning) = p(A beat B). p(A beat C)
But this is clearly wrong. Can someone please help!!
Many thanks
Matt","['puzzle', 'probability']"
878913,Can you factor before finding derivative?,Say the function is $y=\frac{x^2-1}{x-1}$ Can you factor functions before finding the derivative or does that not work?,"['calculus', 'derivatives']"
878919,"""Equivalent"" definitions of the gluing axioms","I tried to convince myself that the two caracterizations of a presheaf that is a sheaf given in wikipedia are equivalent but I couldn't. (F presheaf and  notations from wiki)
Let's take a simple case,  the following inclusions of open sets: $$ U_1 \cap U_2 \subset U_i \subset U_1\cup U_2 =:U ,\quad (i=1,2)$$ The restriction maps $res_{U_i, U}:F(U)\rightarrow F(U_i) $ define the first arrow $F(U)\rightarrow F(U_1)\times F(U_2)$ in the equalizer diagram (cf. wikipedia link). (by def. of a product). Very very explicitely, the two other maps $F(U_1)\times F(U_2)\rightarrow F(U_1)\times F(U_1\cap U_2)\times F(U_2\cap U_1)\times F(U_2) $ are defined by the following maps $F(U_1)\times F(U_2)\overset{\pi_1}{\rightarrow} F(U_1) \overset{res_{U_1,U_1}}{\longrightarrow} F(U_1)\ $ ( $\pi_1$ canonical projection) $F(U_1)\times F(U_2)\overset{\pi_1}{\rightarrow} F(U_1) \overset{res_{U_1\cap U_2,U_1}}{\longrightarrow} F(U_1\cap U_2) $ $F(U_1)\times F(U_2)\overset{\pi_2}{\rightarrow} F(U_2) \overset{res_{U_1\cap U_2,U_2}}{\longrightarrow} F(U_1\cap U_2)\ $ $F(U_1)\times F(U_2)\overset{\pi_2}{\rightarrow} F(U_2) \overset{res_{U_2,U_2}}{\longrightarrow} F(U_2)\ $ and $F(U_1)\times F(U_2)\overset{\pi_1}{\rightarrow} F(U_1) \overset{res_{U_1,U_1}}{\longrightarrow} F(U_1)\ $ ( same as above) $F(U_1)\times F(U_2)\overset{\pi_2}{\rightarrow} F(U_2) \overset{res_{U_1\cap U_2,U_2}}{\longrightarrow} F(U_1\cap U_2)\ $ (order changed) $F(U_1)\times F(U_2)\overset{\pi_1}{\rightarrow} F(U_1) \overset{res_{U_1\cap U_2,U_1}}{\longrightarrow} F(U_1\cap U_2) $ (order changed) $F(U_1)\times F(U_2)\overset{\pi_2}{\rightarrow} F(U_2) \overset{res_{U_2,U_2}}{\longrightarrow} F(U_2)\ $ (same as above) All in all, that equalizer condition is just saying that $$ res_{U_1\cap U_2, U_1} \circ res_{U_1,U} \overset{!}{=} res_{U_1\cap U_2, U_2} \circ res_{U_2,U}$$ which already holds because both equal $res_{U_1\cap U_2, U} $ from the def. of presheaf. This doesn't look like gluing. What did I get wrong? Second question: the gluing axiom itself is said to be formulated for a concrete category such that sthg, whereas the equalizer condition holds for a category with products. Is one formulation more general than the other?","['category-theory', 'algebraic-geometry', 'algebraic-topology']"
878945,Determinant of a matrix shifted by m,"Let $A$ be an $n\times n$ matrix and $Z$ be the $n\times n$ matrix, whose entries are all $m$.
 Let $S$ be the sum of all the adjoints of $A$. Then my conjecture is $\det(A+Z)=\det(A)+Sm$ , in particular $\det(A+Z)=\det(A)$ holds if and only if
 $S=0$. If the conjecture is true, how can it be proven ? For invertible $A$, sylvester's theorem can be used. $\det(A+Z)=\det(A)\det(I+A^{-1}Z)$
 The matrix $A^{-1}Z$ is the product of the row vector containing the row sums of $A^{-1}$
 and the column vector $(m,...,m)$. Sylvester's theorem states that the order of the
 vectors can be exchanged. The scalar product of the vectors is $0$ if and only if 
 the sum of the row sums of $A^{-1}$ is $0$ and this is the same as the sum of the 
 adjoints of $A$ divided by the determinant of $A$. So, for invertible matrices, my
 conjecture should hold. But how can I manage the case when $A$ is singular ?","['matrices', 'linear-algebra', 'determinant']"
878948,Proof of separability of $L^p$ spaces,"The following is a proof in Brezis book. It shows the separability of $L^{p}$ spaces: I have a  few questions regarding the proof: It says 'it is easy to construct a function $f_{2} \in \varepsilon...$ "" and it also says  "" it suffices to split $R$ into small cubes...'. Would it work to choose $f_{2}$ in the following way: Assume we split $R$ as suggested. Let $R_{i}$ denote each small cube of $R$ , consider $f_{2_{i}} := C_{i}\chi_{R_{i}}$ where $C_{i}$ is a constant chosen from $[0, \delta - (\text{sup} f|_{R_{i}} - \text{inf} f|_{R_{i}})$ , then let $f_{2}(x) := \sum_{i}f_{2_{i}}(x)$ . It would then follow that $\Vert f_{1} - f_{2} \Vert_{\infty} < \epsilon$ . Is this fine? Can anyone see how the inequality $\Vert f_{1} -f_{2} \Vert_{p} \leq \Vert f_{1}-f_{2} \Vert_{\infty}|R|^{\frac{1}{p}}$ is obtained? Where exactly is the separability of $\Omega = \mathbb{R}^{N}$ used? Note that $\chi$ denotes the characteristic function. Thanks a lot for any assistance. Let me know if something is unclear.","['functional-analysis', 'normed-spaces', 'proof-verification', 'real-analysis', 'lp-spaces']"
878962,Finite additivity in outer measure,"Let $\{E_i\}_{i=1}^n$ be finitely many disjoint sets of real numbers (not necessarily Lebesgue measurable) and $E$ be the union of all these sets. Is it always true that 
$$
m^\star (E)=\sum_{i=1}^N m^\star(E_n)
$$
where $m^\star$ denotes the Lebesgue outer measure? If not, please give a counterexample. The Vitali set is a counterexample in the countable case, but I am not sure whether it is false in finite case.","['measure-theory', 'lebesgue-measure']"
878970,Expectation of the absolut value of the determinant of a random matrix,"Let $A$ be a random matrix of size $m\times m$ with integer entries $-n\ldots n$. Each value should have the same
 probability. What is the expectation of the random variable $$X := |\det A|$$ Can the variance of $X$ also be calculated ?","['statistics', 'matrices', 'determinant']"
878991,elementary proof for discrete Kantorovich-Rubinstein theorem?,"For the Kantorovich-Rubinstein theorem, please see the wikipedia page http://en.wikipedia.org/wiki/Wasserstein_metric (which does not contain a reference for the proof). I am only interested in the case of discrete distributions; that is, $\mu, \nu$ are measures on the real line supported on finite sets. I believe that there should be a simple combinatorial proof of the Kantorovich theorem in this setting. Any references? If someone can at least sketch the proof, it will be even better.","['probability-distributions', 'discrete-mathematics']"
878993,Showing a certain sequence is an orthonormal basis of $H^2(\mathbb{R}_{+}^{2}).$,"The problem is to show $$\left\{\frac{1}{\pi^{1/2}(i+z)}\left(\frac{i-z}{i+z}\right)^n\right\}_{n=1}^{\infty}$$ is an orthonormal basis of $H^2(\mathbb{R}_{+}^{2}).$ In another exercise, I have already shown $$\left\{\frac{1}{\pi^{1/2}(i+x)}\left(\frac{i-x}{i+x}\right)^n\right\}_{n=1}^{\infty}$$ is an orthonormal basis for $L^2(\mathbb{R}).$ Now they have a hint in this problem that I don't completely understand. They say it suffices to show $F \in H^2(\mathbb{R}_{+}^{2})$ and $$\int_{-\infty}^{\infty} F(x)\frac{(x+i)^n}{(x-i)^{n+1}}dx = 0$$ for $n = 0,1,2,...$ then $F = 0.$ They also claim Cauchy integral formula can be used to prove $$(\frac{d}{dz})^n(F(z)(z+i)^n)|_{z=i} = 0$$ then $F^{n}(i) = 0$ for $n = 0,1,2,...$ The first part of this hint would show that our set is orthonormal? Would we need to do the product rule $n$ times to show the second hint? I know if $F \in H^2(\mathbb{R}_{+}^{2}),$ then by Cauchy integral formula, $$F(z) = \frac{1}{2\pi i} \int_{\mathbb{R}}\frac{f(t)}{t-z}dt,\quad z\in \mathbb{R}_{+}^{2}$$ Then $$F^n(z) = \frac{n!}{2\pi i} \int_{\mathbb{R}}\frac{f(t)}{(t-z)^{n+1}}dt,\quad z\in \mathbb{R}_{+}^{2}.$$","['measure-theory', 'orthonormal', 'real-analysis', 'hardy-spaces']"
879002,What are $10^k \pmod 3$ and $n = \overline{a_ka_{k -1} \ldots a_1a_0}$?,"I feel like I should know these concepts, but I don't.",['discrete-mathematics']
879017,Convergence in $L^p$ by using Holder's inequality,"Let $1\lt p \lt \infty$ and $f\in L_p[0,\infty )$. Show that a)  $$\left\vert\int_0^x f(t)\,dt\right\vert\le\|f\|_px^{1-\frac{1}{p}},$$ for $x\gt 0$. b)  $$\lim_{x\to \infty} \frac{1}{x^{1-\frac1{p}}}\int_0^xf(t)\,dt=0.$$ For a) just I used Holder's inequality and got the result  but for b) I'm not able to figure out. I tried same Holder here too but I got $\le |f(t)|$  instead of $0$. Could you please just give me some hints for b)? Thanks in advance.","['measure-theory', 'lp-spaces', 'real-analysis']"
879022,Why does this infinite series equal one? $\sum_{k=1}^\infty \binom{2k}{k} \frac{1}{4^k(k+1)}=1$,Why does $$\sum_{k=1}^\infty \binom{2k}{k} \frac{1}{4^k(k+1)}=1$$ Is there an intuitive method by which to derive this equality?,"['sequences-and-series', 'calculus', 'limits', 'binomial-coefficients', 'taylor-expansion']"
879052,How to find mean and median from histogram,"Solution for finding   mean : The problem  faced  when i saw a  video to evaluate the mean https://www.youtube.com/watch?v=vMrc6dP8pCo According to the video, the lecturer said that, we can take the average of the measurement intervals. so according to him: we will get $$2.5 \times 15 +8.5\times 35+ ...$$
instead of $$1 \times 15 +6\times 35+ ...$$ Can we evaluate the mean and median precisely from the Histogram?",['statistics']
879057,Sequence of measurable functions converging a.e. to a measurable function?,"I understand if $(X, \Sigma, \mu)$ is a measure space, and we have a sequence of measurable functions $f_{n}$ such that $\lim \limits_{n \to \infty} f_{n}$ exists almost everywhere d$\mu$ (a.e. d$\mu$), then it's equal to a measurable function almost everywhere.  The way this is constructed is to first call the set where the limit doesn't exist $N$ (and this clearly has measure $0$).  Then, we: Define a new sequence 
$$\tilde{f_{n}} = \begin{cases} f_{n}(x) & x \not \in N \\
0 & x \in N \end{cases}$$ and we can think of $\tilde{f_{n}}$ as $f_{n} - f_{n}\chi_{N}$, where $\chi_{N}$ is the characteristic function of the set $N$.  Clearly, $\tilde{f_{n}}$ is measurable since it is the sum of measurable functions.  And so the limit of the sequence $\{ \tilde{f_{n}} \}$ is defined everywhere and measurable.  Specifically,
$$\lim \limits_{n \to \infty} \tilde{f_{n}} = \begin{cases} \lim \limits_{n \to \infty} f_{n} & x \not \in N \\ 0 & x \in N. \end{cases} $$ So we have a measurable function which is equal to $\lim \limits_{n \to \infty} f_{n}$ except on $N$.  But my question is: $\lim \limits_{n \to \infty} f_{n}$ is only defined on $X \setminus N$, which means its domain is $X \setminus N$.  Why do we say this is equal to $\lim \limits_{n \to \infty} \tilde{f_{n}}$ almost everywhere if they have different domains?  Does it make sense to talk about them not being equal on $N$ if one of them isn't even defined on $N$? I guess my question is:  If $X \subseteq X'$, and $f : X \to Y$ and $g : X' \to Y$, suppose $f = g$ on $X$ (with $X' \setminus X$ having measure $0$).  Does the statement $f = g$ a.e. even make sense?  We can't compare then on $X' \setminus X$ to say they aren't equal on it because one of the functions isn't even defined on that set. Another question that has been spawned from this question is whether it makes sense to integrate a function over a set that is not in its domain.","['measure-theory', 'functional-analysis', 'real-analysis']"
879069,The set of points where two continuous functions agree is closed.,"I want to prove that if $f,g$ are continuous functions from a topological space $(X,\tau)$ to a metric space $(Y,d)$ then the set $$ A = \{ x \in X : f(x) = g(x) \} $$ is closed. I found a very similar question asked on this site but it referred to Hausdorff spaces, which I haven't quite met. I know I can prove this by proving that the complement of $A$ is open. If I consider $b \in X$ such that $f(b) \neq g(b)$, then I can find two open sets $U,V \subseteq Y$ such that $f(b) \in U $, $\ g(b) \in V$ and $U \cap V = \varnothing$. Then since the functions are continuous we must have that $f^{-1}(U)$ and $g^{-1}(V)$, which both contain $b$, are open. Hence so is their intersection. Now I'm not sure how to proceed... EDIT: Whilst there are neater methods in the answers, I've just realised how I can finish the proof above. The intersection $$ W_b = f^{-1}(U) \cap g^{-1}(V)$$ lies entirely outside $A$ --- one can show this by supposing that there exists some $a \in A$ that is a member of $W_b$ and showing that $f(a) \in U$ and $g(a) \in V$. But $f(a) = g(a)$ by the assumption that $a \in A$, which is impossible since $U \cap V = \varnothing$. Then the union $$ \bigcup_{b \in X \setminus A} W_b$$ is a union of open sets and hence open, contains all $b \in X \setminus A$, and does not intersect with $A$ since $W_b \cap A = \varnothing$. Hence the union above is precisely $X \setminus A$, and hence $A$ is closed.","['general-topology', 'metric-spaces']"
879085,Another method for limit of $[e-(1+x)^{1/x}]/x$ as $x$ approaches zero [duplicate],This question already has answers here : Limit as $x\to 0$ of $\frac{(1+x)^{1/x}-e}{x}$ (6 answers) Closed 4 years ago . I have solved this limit: $\lim_{x \rightarrow 0} \frac{e-(1+x)^{\frac{1}{x}}}{x}$ using L'Hopital's rule and series expansion. Do you have other method for solving it?,"['limits-without-lhopital', 'exponential-function', 'calculus', 'limits']"
879089,"Prove $_2F_1\left(\frac13,\frac13;\frac56;-27\right)\stackrel{\color{#808080}?}=\frac47$","I discovered the following conjecture numerically, but have not been able to prove it yet:
$$_2F_1\left(\frac13,\frac13;\frac56;-27\right)\stackrel{\color{#808080}?}=\frac47.\tag1$$
The equality holds with at least $10000$ decimal digits of precision. It can be written in equivalent forms in terms of definite integrals:
$${\large\int}_0^1\frac{dx}{\sqrt{1-x}\ \sqrt[3]{x^2+(3x)^3}}\stackrel{\color{#808080}?}=\frac{\sqrt[3]4\,\sqrt3}{7\pi}\Gamma^3\!\!\left(\tfrac13\right),\tag2$$
or
$${\large\int}_0^\pi\frac{d\phi}{\sqrt[3]{\sin\phi}\,\sqrt[3]{55+12\sqrt{21}\cos\phi}}\stackrel{\color{#808080}?}=\frac{\sqrt[3]4\,\sqrt3}{7\pi}\Gamma^3\!\!\left(\tfrac13\right).\tag3$$ Update: A several more equivalent forms:
$$_2F_1\left(\frac13,\frac12;\frac56;\frac{27}{28}\right)\stackrel{\color{#808080}?}=\frac{2^{\small8/3}}{7^{\small2/3}}\tag4$$
$$\int_0^\infty\frac{dx}{\sqrt[3]{55+\cosh x}}\stackrel{\color{#808080}?}=\frac{\sqrt[3]2\,\sqrt3}{7\pi}\Gamma^3\!\!\left(\tfrac13\right)\tag5$$
$$C_{\small-1/3}^{\small(1/3)}(55)\stackrel{\color{#808080}?}=\frac{3}{7\pi^2}\Gamma^3\!\!\left(\tfrac13\right)\tag6$$
$$P_{\small-1/2}^{\small1/6}(55)\stackrel{\color{#808080}?}=\frac{\sqrt2\,\sqrt[4]3\,e^{\small-\pi\,i/12}}{7^{\small13/12}\,\pi^{\small3/2}}\Gamma^2\!\!\left(\tfrac13\right)\tag7$$
where $C_n^{(\lambda)}(x)$ is the Gegenbauer polynomial and $P_l^m(x)$ is the Legendre function of the first kind . Please suggest ideas how to prove this conjecture. What are other points where the function $_2F_1\left(\frac13,\frac13;\frac56;z\right)$ takes simple special values?","['closed-form', 'calculus', 'special-functions', 'definite-integrals', 'hypergeometric-function']"
879117,"Mathematician who talked about the probability of a ""good"" graph?","In my undergraduate years, one of my professors always talked about this one mathematician who was talking about ""good"" graphs and wondered about the existence of such a graph. Apparently this mathematician could not find such a graph, and then proceeded to show that the probability that such a graph existed was 1 by using a probability measure. Does anyone know to whom my professor was referring? [I apologize if such a question is inappropriate for this site.]","['probability-theory', 'graph-theory', 'reference-request']"
879148,an example of a continuous bijection which is not a homeomorphism [duplicate],"This question already has answers here : Finding counterexamples: bijective continuous functions that are not homeomorphisms (3 answers) Closed 9 years ago . I need an example of a continuous bijection $f:X \to Y$, where $X$ is NOT compact and $Y$ is Hausdorff, such that $f$ is not a homeomorphism. (It is easy to show that if $X$ is compact, then $f$ is necessarily a homeomorphism) Any help is appreciated, Thanks !","['general-topology', 'examples-counterexamples']"
879184,"Can polynomials with degree at least 2 over $\mathbb{R}$ have finite number of solutions in $End(\mathbb{R},+)$","Consider a polynomial of degree at least 2 with all coefficients in $\mathbb{R}$. We are concern with set of solution for the polynomial in $End(\mathbb{R},+)$ - the endomorphism ring of the abelian group $\mathbb{R}$ under addition. The question is: is it possible for the number of solution to be finite? My hunch is no, due to the polynomial lacking control over transcendental number. This at first appeared to be a simple application of Zorn's lemma, but it turns out to be not straightforward: one particular difficulty I'm having is whether there exist a proper invariant subspace for a particular solution. I'm sure there would be question like this somewhere, but I don't even know what to search for to find it. Thank you for your help.","['ring-theory', 'linear-algebra', 'elementary-set-theory', 'functional-equations']"
879192,What is this sequence of all permutations with gaps permissible [duplicate],"This question already has answers here : Shortest sequence containing all permutations (2 answers) Closed 9 years ago . Let there be a sequence $a_1, a_2, a_3,...,a_n$ that represent some actions that you know are required to solve a problem. However, you do not know what order these actions need to be taken to solve that problem, but you know that all of them are required at some point. What is the shortest such sequence $S$ of actions with length $m$ in terms of $n$ such that all permutations of the actions are contained within $S$ with gaps and overlaps permissible? Example: Let's say you know that 3 steps are required to fix your computer, but you don't know in what order: Restarting a program. Installing a different program. Run antivirus. So one sequence containing all permutations $(123,132,213,231,312,321)$ guaranteed would be $S=123\ 123\ 123$ (meaning $m$ has a guaranteed upper bound of $n^2$ if we extrapolate) but a shorter sequence would be $S=1231231$ (which I am not sure is of minimum length). How can we generate this minimum sequence?","['sequences-and-series', 'combinatorics']"
879195,Establishing an identity involving cotangent and cosecant,"$$\frac{\csc(x)-1}{\cot(x)}=\frac{\cot(x)}{\csc(x)+1}$$
Once again, ""Professor Google"" provides an example that's different enough that I can't solve ""my"" problem. I'm beginning to think that Google does this me on purpose.",['trigonometry']
879204,$F/K$ algebraic and every nonconstant polynomial in $K[X]$ has a root in $F$ implies $F$ is algebraically closed.,"Let $F/K$ be an algebraic extension of fields in characteristic zero.  If $F/K$ is normal, and every nonconstant polynomial $f \in K[X]$ has a root in $F$, then $F$ is algebraically closed.  This is obvious, because if $u$ is algebraic over $F$ (let us agree to fix some algebraic closure $\overline{K}$ of $K$ containing $F$ with $u \in \overline{K}$), then it is algebraic over $K$ with minimal polynomial $f \in K[X]$, which by hypothesis must have one and therefore all of its roots in $F$.  In particular $u \in F$. I have heard that the above assertion remains true if we drop the assumption that $F/K$ is normal.  But it seems to be a nontrivial result.  Can anyone get me started on how to prove this? Thoughts so far: It's enough to show that every algebraic extension of $K$ is $K$-isomorphic to a subfield of $F$.  Certainly this is true for every finite extension $E$ of $K$; we're in characteristic zero, so $E = K(v)$ for some $v \in E$.  If $f \in K[X]$ is the minimal polynomial of $v$ over $K$, then $f$ has some root $u \in F$, whence $E$ is $K$-isomorphic to the subfield $K(u)$ of $F$. So, I'm thinking next use some kind of Zorn's Lemma argument?","['extension-field', 'abstract-algebra', 'field-theory']"
879233,The difference between vector space and group,"When comparing the difference between the definition of vector space, I see that the main job is that vector space defines a scalar product while the group not, so here list two of my questions? 1.Why we need to define a scalar product for a vector space? Physical sense or some insight behind it? 2.One truly nice thing for vector space is that we represent the element with basis, so what we do with elements in vector space is just with basis,so why we can't do the same thing for group? I think the question may be a little silly, but I need a question.","['vector-spaces', 'group-theory', 'abstract-algebra']"
879239,Limit of a recursively defined sequence,"Let $\{a_n\}_{n\in\mathbb{N}}$ be a sequence of real numbers such that: $$\forall n\in\mathbb{N},\quad a_{n+1}=a_n + e^{-a_n}.$$ Prove that: $$\lim_{n\to+\infty}\frac{a_n}{\log n}=1.$$","['sequences-and-series', 'calculus', 'limits']"
879241,"Feynman's Algorithm for computing a logarithm of a number in [1,2]","I came upon the following quote concerning Feynman (the entire essay this is from can be found here ): Consider the problem of finding the logarithm of a fractional number between 1.0 and 2.0 (the algorithm can be generalized without too much difficulty). Feynman observed that any such number can be uniquely represented as a product of numbers of the form $1 + 2^{-k}$, where $k$ is an integer. Testing each of these factors in a binary number representation is simply a matter of a shift and a subtraction. Once the factors are determined, the logarithm can be computed by adding together the precomputed logarithms of the factors. The algorithm fit especially well on the Connection Machine, since the small table of the logarithms of $1 + 2^{-k}$ could be shared by all the processors. The entire computation took less time than division. I've given this half a thought and searched a little online, and by basically doing a ""binary search"" algorithm, one can determine what a set of factors are. See this question on another SE site. However, I am not convinced the factorization is unique since I can't think of an argument. (As an aside, the binary search method doesn't seem the most elegant way to compute the factors.) So my question is more precisely the following. For ${\bf a} = (a_1, a_2, \dots ) \in \{0,1\}^{{\bf N}}$, show that each number $x \in (1,2]$ is uniquely represented by a certain $\bf{a}$ such that
$$x = \prod_{k=1}^\infty (1+a_k 2^{-k}).$$ I know 
$$\prod_{k=1}^\infty (1+a_k 2^{-k}) = 1 + \sum_{k=1}^\infty \left(a_k + \sum_{1\leq i<j,i+j=k} a_i a_j \right) 2^{-k} = 1 + \sum_{k=1}^\infty b_k 2^{-k}$$
where $b_k$ are the binary digits of $x$, but this doesn't give me much insight.","['logarithms', 'sequences-and-series']"
879276,Prove Or Disprove: tr(AB)=tr(A)*tr(B),$\mathrm{tr}(AB)=\sum\limits_{i=1}^n \sum\limits_{j=1}^n a_{ij}*b_{ji}$ $\mathrm{tr}(A)*\mathrm{tr}(B)=\sum\limits_{i=1}^n a_{ii}*\sum\limits_{i=1}^n b_{ii}$ Therefore $\mathrm{tr}(AB) \neq \mathrm{tr}(A)*\mathrm{tr}(B)$ Is the proof valid?,"['linear-algebra', 'proof-verification']"
879293,Find the Value of Trigonometric Expression,Given $$\begin{align} \frac{\cos \alpha}{\cos \beta}+\frac{\sin \alpha}{\sin \beta}=-1 \end{align} \tag{1}$$ Find the value of $$\begin{align} \frac{\cos^3 \beta}{\cos \alpha}+\frac{\sin ^3\beta}{\sin \alpha} \end{align} \tag{2} $$ I Tried like this: From $(1)$ we have$$\sin\alpha \cos\beta+\cos\alpha \sin\beta=-\sin\beta \cos\beta$$ $\implies$ $$\sin(\alpha+\beta)=-\sin\beta \cos\beta \tag{3}$$ Eq $(2)$ is $$\frac{\frac{\sin\alpha}{4}\left(3\cos\beta+\cos3\beta\right)+\frac{\cos\alpha}{4}\left(3\sin\beta-\sin3\beta\right)}{\sin\alpha \cos\alpha}=\frac{\frac{3}{4}\sin(\alpha+\beta)+\frac{1}{4}\sin(\alpha-3\beta)}{\sin\alpha \cos\alpha}=\frac{\frac{-3}{4}\sin\beta \cos\beta+\frac{1}{4}\sin(\alpha-3\beta)}{\sin\alpha \cos\alpha}$$ I cannot proceed any further..please help me,['trigonometry']
879300,Geometric Interepretation of $\mathbb{G}_a$-torsors,"Let's fixed a locally ringed space $(X,\mathcal{O}_X)$ (although, this should apply to any ringed topos, but I haven't thought that through). In fact, if it's helpful, you can assume that $X$ is a complex manifold, or a scheme. The question then is: Is there a natural $\mathcal{O}_X$-module $\mathcal{F}$ such that $\text{Aut}_{\mathcal{O}_X}(\mathcal{F})=\mathcal{O}_X$? The reason for my interest is due to the fact that $H^1(X,\mathcal{O}_X)$ would then classify twists of $\mathcal{F}$. For example, because $\text{Aut}_{\mathcal{O}_X}(\mathcal{O}_X)=\mathcal{O}_X^\times$, we know that $H^1(X,\mathcal{O}_X^\times)$ classifies twists of $\mathcal{O}_X$, or more colloquially, line bundles. If there was such a sheaf $\mathcal{F}$, which had some nice geometric flavor, this might give some interesting insight into how to think about genus, or any other statistics associated to $h^1$. I apologize if I have missed something obvious! Thanks! PS: I am not particularly looking for another way to think about $\mathbb{G}_a$-torsors, than the context above. For example, thinking about them as extensions via the isomorphism $H^1(X,\mathcal{O}_X)\cong \text{Ext}^1(\mathcal{O}_X,\mathcal{O}_X)$ isn't particularly helpful to me, in this context.","['homology-cohomology', 'algebraic-geometry']"
879305,"Prove that $\sum\limits_{i=1}^n x_i <\frac{5}{3}$ for $x_i\ge 0, \forall i$ with $x_{i}x_{j}\le 4^{-|i-j|}, \forall i, j$","Question: Let $x_{1},x_{2},\cdots,x_{n}\ge 0$ with
  $$x_{i}x_{j}\le 4^{-|i-j|}$$
  for  all $i, j = 1, \dots, n.$ Show that
  $$x_{1}+x_{2}+\cdots+x_{n}<\dfrac{5}{3}.$$ This problem is  from
South East Mathematical Olympiad yesterday.maybe can use matrix or integral  inequality? I found the constant $\dfrac{5}{3}$ is best ,because we let
$$x_{n}=\dfrac{1}{4^k},x_{n-1}=\dfrac{1}{4^{k-1}},\cdots,x_{[n/2]+1}=\dfrac{1}{4},x_{[n/2]}=1,x_{[n/2]-1}=\dfrac{1}{4},\cdots,x_{2}=\dfrac{1}{4^{k-1}},x_{1}=\dfrac{1}{4^k}$$
it is clear this example such this condition,and we have
$$\lim_{k\to\infty}[x_{1}+x_{2}+\cdots+x_{n}]=\dfrac{1/4}{1-1/4}+1+\dfrac{1/4}{1-1/4}=\dfrac{5}{3}$$ if this inequlity to prove 
$$x_{1}+x_{2}+\cdots+x_{n}<2$$ we can use Mathematical induction $x_{1},x_{2},\cdots,x_{n}$ is less than 
$$1,\dfrac{1}{2},\dfrac{1}{2^2},\cdots,\dfrac{1}{2^{n-1}}$$
because Assmue that $n=k$ is true,Note 
$$x_{1}x_{k+1}\le \dfrac{1}{4^k}$$
since
$$x_{1}\le\dfrac{1}{2^{k}}$$
so
$$x_{k+1}<\dfrac{1}{2^{k}}$$
so
$$x_{1}+x_{2}+\cdots+x_{n}=\sum_{k=1}^{n}\dfrac{1}{2^{k-1}}<2$$ Thank you","['inequality', 'algebra-precalculus', 'contest-math']"
879317,Given an example of a metric space in which every sphere has two centers,"This is a question from Wilansky ""Topology for analysis"", P.15 Prob. 103 Maybe I was thinking too Euclidean, I can't come up some other ""centers"" of the sphere :(","['general-topology', 'metric-spaces']"
879319,Riemannian manifolds are metrizable?,"I've seen lots of casual claims that Riemannian manifolds (even without assuming second-countability) are metrizable. In the path-connected case, we can use arc-length to create a distance function. But how can one prove this without assuming path-connectedness (and second-countability)? (Motivated by Problem 2-D of Milnor-Stasheff.)","['general-topology', 'riemannian-geometry', 'metric-spaces']"
879334,"Smooth surfaces that isn't the zero-set of $f(x,y,z)$","The zero-set of any smooth function $f(x,y,z)$ with a non-vanishing gradient is a smooth surface. I was wondering if the reverse is true: is every smooth surface in $E^3$ the zero-set of some smooth function? If not, what do the counterexamples look like? I was thinking that a plane with a hole may qualify as a counterexample, but I have yet to prove it.","['manifolds', 'differential-geometry']"
879344,Number of triangles formed by all chords between $n$ points on a circle,"We have $n$ point on the circumference of a circle. We draw all chords between these points. No three chords are concurrent. How many triangles exist that their apexes could be on circumference of the circle or intersection points of chords and side of triangles is on chords? Things I have done so far: There are four situations: situation # $1$ :all points on circumference. situation # $2$ :two points on the circumference, one intersection point. situation # $3$ :one point on the circumference, two intersection points. situation # $4$ :three intersection points. Situation #1 is easily countable. ${n \choose 3}$ For other situations, I can't find a way for counting them. Answer (according to answer key): $${n \choose 3} + 4{n \choose 4} + 5{n \choose 5} + {n \choose 6}$$","['geometry', 'triangles', 'combinations', 'circles', 'combinatorics']"
879351,Matrix exponential of a skew-symmetric matrix without series expansion,"I have the following skew-symmetric matrix $$C = \begin{bmatrix}   0 & -a_3 &  a_2 \\
                     a_3 &    0 & -a_1 \\
                    -a_2 &  a_1 &    0 \end{bmatrix}$$ How do I compute $e^{C}$ without resorting to the series expansion of $e^{C}$ ? Shall I get a finite expression for it? NB:  Values of $a_i$ s can't be changed.","['matrices', 'matrix-calculus', 'matrix-exponential', 'skew-symmetric-matrices']"
879423,Expressing a recursively defined function in terms of factorials or gamma function,"Given the recursion $$f(n) = nf(n-1) + (n-1)f(n-2) $$
$$f(0) = 1, f(1) = 1$$ How exactly does one express the target function? I know that $$f(n) = nf(n-1)$$ gives rise to $$f(n) = \Gamma(n+1)$$ By repeatedly substituting I can then derive $$f(n) = \Gamma(n+1) + (n-1)f(n-2) + n(n-2)f(n-3) + n(n-1)(n-3)f(n-4) ... $$ Where to go from there?","['closed-form', 'recurrence-relations', 'discrete-mathematics', 'functional-equations', 'factorial']"
879444,Difference between parameterization and embedding of manifolds,"What is the difference between embedding and parameterization? Why, for example, we say Gauss parameterization of a convex hypersurfaces, and we don't call it an embedding?","['riemannian-geometry', 'manifolds', 'differential-geometry']"
879452,"If $\lambda$ is an eigenvalue of $A^2$, then either $\sqrt{\lambda}$ or $-\sqrt{\lambda}$ is an eigenvalue of $A$","$A$ is an $n\times n$ matrix of complex numbers. Prove that if $\lambda$ is an eigenvalue of $A^2,$ then $\sqrt{\lambda}$ or $-\sqrt{\lambda}$ is an eigenvalue of $A.$ If $\lambda$ is an eigenvalue of $A^2,$ we have $\lambda\alpha=A^2\alpha$ for some $\alpha.$ Then how can we find a $\beta$ s.t. $\sqrt{\lambda}\beta=A\beta?$","['linear-algebra', 'eigenvalues-eigenvectors']"
879456,Verification of the Stokes theorem for the surface that is a part of a cone,"Let $S$ consist of the part of the cone $z=(x^2+y^2)^{1/2}$ for $x^2+y^2\leq9$ and suppose $${\bf A}=(-y,x,-xyz).$$ Verify that Stokes theorem is satisfied for this choice of $\bf A$ and $S$. In the solution to this question in order to work out the surface integral you can project on to $z=3$ and evaluate over the region $x^2+y^2\leq9$. I was just wondering whether or not you could do the same but this time project onto the plane $z=0$?","['multivariable-calculus', 'vector-analysis', 'surfaces']"
879477,Calculating $\int_0^\pi \sin^2t\;dt$ using the residue theorem,"I want to use the residue theorem to calculate $$I:=\int_0^\pi \sin^2t\;dt$$ Since $\sin^2$ is an even function, we've got $$I=\frac{1}{2}\int_0^{2\pi}\sin^2t\;dt$$ The solution of this exercise defines $$f(z):=\frac{1}{iz}\left(\frac{1}{2i}\left(z-\frac{1}{z}\right)\right)^2=-\frac{1}{4i}\left(z-\frac{2}{z}+\frac{1}{z^3}\right)$$ concludes that $$\operatorname{res}(f,0)=\left(-\frac{1}{4i}\right)\cdot (-2)=\frac{1}{2i}$$ and $$I=\frac{1}{2}\left\{2\pi i\cdot \frac{1}{2i}\right\}=\frac{\pi}{2}$$ I don't understand what they're doing; especially $f$ seems to have no relationship to the original integrand. My approach was to try to write the integral as a contour integral: I hoped something like $$\frac{1}{2i}\int_{|z|=1}\frac{\sin^2z}{z}dz$$ would be worth a consideration. However, this integral is $0$; so, not exactly $I$.","['residue-calculus', 'contour-integration', 'complex-analysis', 'analysis']"
879489,What is the value of this double integral?,"Let $C$ be the subset of the plane given by 
$$ C \colon= \{ \ (x,y) \in \mathbb{R}^2 \ | \ 0 \leq x^2 + y^2 \leq 1 \}.$$ Then what is the value of the double integral 
$$ \int_{C} \int (x^2 + y^2) \ dx \  dy?$$ My work: In $C$, we have $-1 \leq x \leq 1$ and $-\sqrt{1-x^2} \leq y \leq \sqrt{1-x^2}$. So we have 
$$ \int_C \int (x^2 + y^2) \ dx \  dy = \int_{-1}^1 \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}} \ (x^2 + y^2) \ dy \ dx = 2 \int_{-1}^1 (x^2 \sqrt{1-x^2} + \frac{ (\sqrt{1-x^2})^3}{3} ) \ dx = \frac{4}{3} \int_0^1 (2x^2 + 1) \sqrt{1-x^2} \ dx.  $$ Now let $x= \sin t$. Then we obtain
$$ \int_C \int (x^2 + y^2) \ dx \  dy = \frac{4}{3} \int_0^1 (2x^2 + 1) \sqrt{1-x^2} \ dx = \frac{4}{3} \int_{t = 0}^{\pi/2} (2\sin^2 t + 1) \cos^2 t \ dt \ \ = \frac{1}{3} \int_{t=0}^{\pi/2} (2\sin^2 2t + 4 \cos^2 t) \ dt = \frac{4}{3} \int_{t=0}^{\pi/2}  ( 1 - \cos 4t + 2(1+ \cos 2t) ) \ dt = \frac{1}{3} \int_{t=0}^{\pi/2} (3 + 2 \cos 2t - \cos 4t) \ dt = \frac{\pi}{2}. $$ Am I right?","['multivariable-calculus', 'calculus', 'integration', 'definite-integrals', 'analysis']"
879527,Why not defining a measure as a function on functions?,"A measure $\mu$ is a function to $\left[0,\infty\right]$ on the
sets belonging to a $\sigma$-algebra. Then for
integrable functions $f$ the integral $\int fd\mu$ comes in, having
nice properties like: $$\int f+gd\mu=\int fd\mu+\int gd\mu$$ and $$\int cfd\mu=c\int fd\mu$$
Often I wonder: is there anything that keeps us from defining measure
$\mu$ as function on integrable functions (or eventually nonnegative integrable functions) instead of sets? And in
the same line: why not writing $\mu\left(f\right)$ or $\mu f$ instead of $\int fd\mu$?
The original value on set $A$ can easily be found back as $\mu\left(1_{A}\right)$. Are there good reasons not to do this? And if so can you give me some?","['definition', 'notation', 'measure-theory', 'probability-theory', 'soft-question']"
879567,Cannot follow the algebra,The following equality is stated in my text book and I cannot follow the algebra that makes it true. Please help me step through this to show how $$\frac{4^x}{3^{x-1}} = 4 \left(\frac{4}{3}\right)^{x-1}$$,['algebra-precalculus']
879585,"Proof of series expansion of $f(k) = {r - sk \choose n}$ in Concrete Mathematics book by D. Knuth, et. al.",Please help me prove this equation in page 190 of Concrete Mathematics 2nd Ed. book by D. Knuth : $f(k) = {r - sk \choose n} = {1 \over n!}(-1)^n s^n k^n + ... = (-1)^n s^n {k \choose n} + ... $ I believe this is the Newton series of $f(k)$ since that is the topic being explained on the page. But I can't prove it.,['discrete-mathematics']
879611,How do you calculate this limit $\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k}{n^2+k^2}$?,"How to find the value of $\lim_{n\to\infty}S(n)$, where $S(n)$ is given by $$S(n)=\displaystyle\sum_{k=1}^{n} \dfrac{k}{n^2+k^2}$$ Wolfram alpha is unable to calculate it. This is a question from a questions booklet, and the options for the answer are-- $\begin{align}
&A) \dfrac{\pi}{2} \\
&B) \log 2 \\
&C) \dfrac{\pi}{4} \\
&D) \dfrac{1}{2} \log 2
\end{align}$","['sequences-and-series', 'calculus', 'riemann-sum', 'summation', 'limits']"
879618,An incorrect answer for an integral,"As the authors pointed out in this paper (p. 2), the following evaluation which was in Gradshteyn and Ryzhik (sixth edition) is incorrect (and has been removed). $$
''\int_{0}^{\infty}\frac{1}{\left(1+x^{2}\right)^{3/2}} \frac{1}{\sqrt{1+  \frac{4 x^{2}}{3\left(1+x^{2}\right)^{2}}+\sqrt{1+  \frac{4 x^{2}}{3\left(1+x^{2}\right)^{2}}}}} \mathrm{d}x = \frac{\pi}{2\sqrt{6}}'' \qquad (*)
$$ A numerical evaluation gives $0.6663771 \cdots$ on the left hand side and $0.64127491 \cdots $ on the right hand side. I have not succeeded to correct $(*)$ . Do you have any idea on how to evaluate the above integral?","['definite-integrals', 'nested-radicals', 'closed-form', 'integration']"
879621,Is Dirac's delta function well-defined at Lebesgue points?,"Usually in textbooks, 
$$\int_{\mathbb{R}^d} \delta(\mathbf{x}-\mathbf{y})f(\mathbf{x}) = f(\mathbf{y})$$
holds given $f$ is continuous. On the other hand, the definition of Lebesugue point $\mathbf{y}$ is that the following limit exists
$$
\lim_{\epsilon\rightarrow0}\frac{1}{|B_{\epsilon}|}\int_{B_{\epsilon}}f(\mathbf{x}),
$$
where $B_{\epsilon}$ is the ball of radius $\epsilon$ centered around $\mathbf{y}.$
Lebesgure differentiation theorem says for $L^1(\mathbb{R}^d)$ function almost every point is a Lebesgue point. All these facts let me think the delta function is also well-defined almost everywhere for $f\in L^1(\mathbb{R}^d)$ because the definition of Lebesgure point is exactly an example of approximation of the delta function. More precisely, can the definition of the delta functional be extended to the domain $L^1$ in this way? For delta function, we take this definition: The delta function is a generalized function that can be defined as the limit of a class of delta sequences. My question is to extend this functional to $L^1$ such that the extended delta function is a linear bounded functional on $L^1.$","['sobolev-spaces', 'functional-analysis', 'real-analysis', 'lebesgue-integral']"
879638,Are there more examples of functional equations which are also valid for the identity map?,"I find the co-incidence of the identity: $$\sin(A+B)\sin(A-B) = \sin^2 A - \sin^2 B$$ very pleasing. So, I was wondering if there are more of these type of identities. To make my question precise: Are there more examples of functional equations which are also valid for the identity map? For example, the identity map and the $\sin$ function satisfies $$(f(A) + f(B))(f(A) - f(B)) = f(A)^2 - f(B)^2.$$ Thanks","['algebra-precalculus', 'big-list', 'functional-equations']"
879640,Are inverse matrices unique?,"Does a matrix have only one inverse matrix (like the inverse of an element in a field)? If so, does this mean that $A,B \text{ have the same inverse matrix} \iff A=B$?","['matrices', 'linear-algebra']"
879664,Finding derivative form the definition,"I want to find the derivative of the function $f:\mathbb R^n\to \mathbb R^m$ at a point $x_0\in \mathbb R^n$, where $f(x)=c\in \mathbb R^m$, is a constant function. What I did is as follows: If $f$ is differentiable at $x_0$, then there exists a linear function $L_{x_{0}}:\mathbb R^n\to \mathbb R^m$ such that $\lim\limits_{\parallel h\parallel \to 0}\frac{\parallel f(x_0+h)-f(x_0)-L_{x_0}(h)\parallel }{\parallel h\parallel }=0$. This gives $\lim\limits_{\parallel h\parallel \to 0}\frac{\parallel L_{x_0}(h)\parallel }{\parallel h\parallel }=0$.
 Now how to show that $L_{x_0}(h)=0?$ Please help!","['derivatives', 'real-analysis']"
879674,"$f$ is twice differentiable, $f + 2 f^{'} + f^{''} \geq 0$ , prove the following","Let $ f : [0,1] \rightarrow R$ . $f$ is twice diff.
 and $f(0) = f(1) = 0$ If $f + 2 f^{'} + f^{''} \ge 0$ , prove that $f\le 0$ in the domain. Please don’t give complete solution, only hints.","['calculus', 'derivatives', 'functions']"
879697,Basic Iwasawa Theory Question,"I'm looking at a paper that introduces some terms and intends to use concepts from Iwasawa Theory. I instantly find myself stuck at the second sentence and even after much searching on the internet, I still can't quite understand it. The paragraph that I'm trying to understand is taken from page 19 of http://wstein.org/papers/shark/shark.pdf This is the bit that I do not understand: Let $\Lambda$ be the completed group algebra $\mathbb{Z}_p[[\Gamma]]$. We use a fixed topological generator $\gamma$ of $\Gamma$ to identify $\Lambda$ with $\mathbb{Z}_p[[T]]$ by sending $\gamma$ to $1+T$. Any finitely-generated $\Lambda$-module admits a decomposition up to quasi-isomorphism as a direct sum of elementary $\Lambda$-modules. What is a completed group algebra $\mathbb{Z}_p[[\Gamma]]$? I've seen the wikipedia page http://en.wikipedia.org/wiki/Group_algebra but it doesn't seem to give me anything I can understand. An elaboration or an example might be good. How is $\mathbb{Z}_p[[\Gamma]]$ different from $\mathbb{Z}_p[[T]]$? What are elementary modules? Thanks for any help.",['number-theory']
879715,"Birthday ""Paradox"" - another, different, version!","Background Many people are familiar with the so-called Birthday ""Paradox"" that, in a room of $23$ people, there is a better than $50/50$ chance that two of them will share the same birthday. In its more general form for $n$ people, the probability of no two people sharing the same birthday is $p(n) = \large\frac{365!}{365^n(365-n)!}$ . Similar calculations are used for understanding hash-space sizes, cryptographic attacks, etc. Motivation The reason for asking the following question is actually related to understanding a specific financial market behavior. However, a variant on the ""Birthday Paradox"" problem fits perfectly as an analogy and is likely to be of wider interest to more people with different backgrounds. My question is therefore framed along the lines of the  familiar ""Birthday Paradox"", but with a difference, as follows. Situation There are a total of $60$ people in a room. Of these, it turns out that there are $11$ pairs of people who share the same birthday, and two triples (i.e. groups of $3$ people) who have the same birthday. The remaining $60 - 11\cdot2 - 2\cdot3 = 32$ people have different birthdays. Assuming a population in which any day is equally likely for a birthday (i.e. ignore Feb 29th & possible seasonal effects) and, given the specified distribution of birthdays mentioned above, the questioner would actually like to understand how likely (or unlikely) it is that these $60$ people were really chosen randomly. However, I am not sure if the question posed in that way is actually answerable at all. When I posed this question on another site (where it was left unanswered), I was at least advised to re-state the question in a slightly different way, as follows below. Question If $60$ people are chosen at random from a population in which any day is equally likely to be a person's birthday, what is the probability that there are $11$ days on which exactly $2$ people share a birthday, two days on which exactly $3$ of them share a birthday, and no days on which $4$ or more of them share a birthday?","['statistics', 'birthday', 'probability-theory', 'combinations', 'probability']"
879726,Evaluation of Sum of $ \sum_{n=1}^{\infty}\frac{\sin (n)}{n}$.,If $\displaystyle S = \sum_{n=1}^{\infty}\frac{\sin (n)}{n}.$ Then value of $2S+1 = $ Using Fourier Series Transformation I am Getting $2S+1=\pi$ But I want to solve it Using Euler  Method and Then Use Logarithmic Series. $\bf{My\; Try::}$ Using $\displaystyle \sin (n) = \left(\frac{e^{in}-e^{-in}}{2i}\right)$. So $\displaystyle S = \sum_{n=1}^{n}\frac{\sin (n)}{n} = \frac{1}{2i}\sum_{n=1}^{\infty}\frac{e^{in}}{n}-\frac{1}{2i}\sum_{n=1}^{\infty}\frac{e^{-in}}{n}$ Now Using $\displaystyle \ln(1-x) = -x-\frac{x^2}{2}-\frac{x^3}{3}...............\infty$ So Let $\displaystyle S = -\frac{1}{2i}\ln(1-e^{i})+\frac{1}{2i}\ln(1-e^{-i})$ Now How can I solve after that Help me Thanks,['complex-analysis']
879729,$x^2+1$ is almost always square free,"It seems like $x^2+1$ is almost always square free. Any research or heuristics why? I tried breaking the problem into solving $$x^2-ky^2=1$$
For various $k$, and I conjecture that for every $k$ there are at most finitely many solutions to the Diophantine equation. I'm pretty sure this is correct but dont know how to prove it. Any ideas on  my two problems?","['diophantine-equations', 'number-theory']"
879742,Is this a valid proof of $\lim _{n\rightarrow \infty }(1+\frac{z}{n})^n=e^z$?,"Define the function $g_n\left(z\right)=\left(1+\frac{z}{n}\right)^n$ for $\:n\in \mathbb{R^+}$. Then $$\frac{d}{dz}g_n\left(z\right)=n\left(1+\frac{z}{n}\right)^{n-1}\cdot\frac{1}{n}=\left(1+\frac{z}{n}\right)^{n-1}$$ Define $g_{\infty}\left(z\right)=\lim _{n\rightarrow \infty }g_n\left(x\right)=\lim_{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n$, then notice that $$\frac{d}{dz}g_{\infty}\left(z\right)=\frac{d}{dz}\left(\lim _{n\rightarrow \infty
 }g_n\left(x\right)\right)=\lim _{n\rightarrow \infty }\frac{d}{dz}g_n\left(z\right)$$$$=\lim_{n\to
 \infty}\left(1+\frac{z}{n}\right)^{n-1}=\lim_{n\to
 \infty}\frac{\left(1+\frac{z}{n}\right)^n}{1+\frac{z}{n}} 
 =\lim _{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n=g_\infty\left(z\right)$$ By considering that $g_n\left(0\right)=1\: \forall\:n\in \mathbb{R^+}$, we have
  the differential equation $$\frac{d}{dz}g_{\infty}\left(z\right)=g_\infty\left(z\right),\,g_\infty \left(0\right)=1$$ Which also has $e^z$ as a solution. However, the above differential
  equation has a unique solution, so therefore 
  $$g_\infty \left(z\right)=\lim
 _{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n=e^z\,\,\blacksquare$$ I came up with this proof myself, and I think it's quite elegant, but I'm unsure as to the validity of the proof. Something just doesn't seem right to me. Are there any invalid statements or loose ends to this proof? Also, how useful is this as a proof of the limit? You don't need to know  theory of differential equations, because you'd recognise easily that $e^z$ is its own derivative. Is there anything in it that might make it inaccessible, assuming you know that $\frac{d}{dz}e^z=e^z$?","['exponential-function', 'calculus', 'proof-verification', 'limits']"
879746,Evaluation of $ \int \frac{x^2+n(n-1)}{(x\cdot \sin x+n\cdot \cos x)^2}dx$,"Evaluation of $\displaystyle \int \frac{x^2+n(n-1)}{(x\cdot \sin x+n\cdot \cos x)^2}dx$ $\bf{My\; Solution:}$ Using $\displaystyle (x\cdot \sin x+n\cdot \cos x) = \sqrt{x^2+n^2}\left\{\frac{x}{\sqrt{x^2+n^2}}\cdot \sin x+\frac{n}{\sqrt{x^2+n^2}}\cdot \cos x\right\}$ $$\displaystyle = \sqrt{x^2+n^2}\cdot \cos\left(x-\phi\right)\;,$$ where $\displaystyle \sin \phi = \frac{x}{\sqrt{x^2+n^2}}$ and $\displaystyle \cos \phi = \frac{n}{\sqrt{x^2+n^2}}$ and $\displaystyle \tan \phi = \frac{x}{n}\Rightarrow \phi = \tan^{-1}\left(\frac{x}{n}\right)$ So Integral is $$\displaystyle = \int \sec^2(x-\phi)\cdot \left(\frac{x^2+n(n-1)}{x^2+n^2}\right)dx$$ Now Let $$\displaystyle (x-\phi) = y\Rightarrow \left(x-\tan^{-1}\left(\frac{x}{n}\right)\right)=y$$. Then $$\displaystyle \left(\frac{x^2+n(n-1)}{x^2+n^2}\right)dx = dy$$ So Integral is $$\displaystyle \int \sec^2(y)dy = \tan y +\mathbb{C} = \tan\left(x-\tan^{-1}\left(\frac{x}{n}\right)\right)+\mathbb{C}$$ So $$\displaystyle \int \frac{x^2+n(n-1)}{(x\cdot \sin x+n\cdot \cos x)^2}dx = \left(\frac{n\cdot \tan x-x}{n+x\cdot \tan x}\right)+\mathbb{C}$$ My Question is , Is there is any other solution other then that, because It is very Complex and Lengthy. If Yes, The please write here Thanks",['calculus']
879749,Expected number of coin tosses until a run of $k$ successive heads occurs,"Suppose each coin toss is independent, what is the expected number of coin tosses until a run of ""k"" successive heads occur? Tried finding a recursive expression to solve the problem but got completely lost.","['probability-theory', 'probability']"
879780,"given analytic $f(z)$ in $f(z)/(1-z)$ , derivative $f '(z)$ seems to have singularity at $z=1$","Quick version:
I want $f'(1)$, where $$F(z)=\frac{f(z)}{1-z}$$ with $f$ analytic at $z=1$. But when I follow a seemingly valid line of reasoning, I reach the conclusion that $f'(z)$ is not analytic at $z=1$. Long version:
I have no closed form for $f(z)$ or $F(z)$: I only have a series: $$F(z) = \sum_{k \geq 0} a_{n} z^{n}$$ where $a_{n}$ is a sequence of positive reals (expectations of random variables, if you're curious) that's known to converge to some $a>0$, but for which I have no explicit representation. Nevertheless, since $a_{n}$ converges to a positive real number, I can conclude that $F(z)$ has a simple pole at $z=1$ (since $F$ clearly has a singularity at $1$, and a singularity of order $<1$ or $>1$ would produce coefficients that converge to $0$ or infinity respectively.) So I can write $$F(z) = \frac{f(z)}{1-z}$$ where f(z) is analytic at z=1. As mentioned, I want f'(1) (it's the only missing piece for the asymptotics of a sequence related to a_{n}.) On the interval (0,1) I can then write $$f(z)=(1-z)F(z) = (1-z) \sum_{k \geq 0} a_{k} z^{k}$$ and then transform this into $$f(z) = a_{0} + \sum_{k \geq 1}(a_{k}-a_{k-1}) z^{k}$$ Then I differentiate term by term, yielding $$f'(z)= \sum_{ k \geq 1} k(a_{k}-a_{k-1}) z^{k-1}$$ But this sum might diverge at $z=1$ (its convergence depends on the rate of convergence of $a_{k}$, I think.) So since this expression for $f'(z)$ is valid on $(0,1)$ , its divergence at $z=1$ implies that $f'(z)$ grows arbitrarily large near $z=1$, i.e. that $f'(z)$ has a singularity at $z=1$. And this contradicts the fact that $f(z)$ is analytic at $z=1$ by its definition. I apologize for the vagueness of the following question, but I don't see what I'm doing wrong. I've tried considering a simpler case where $f(z)$ is a constant function, but in this case the sequence $a_{n}$ is constant, so the problematic series disappears. I've also googled ""power series/analytic function with no closed form,"" and come up empty-handed. So any help would be uber-appreciated.","['power-series', 'complex-analysis']"
879781,What is $k(X)[Y]$ and why is it a principal ideal domain? From a proof in Fulton's Algebraic Curves,"Fulton's ""Algebraic Curves"" says the following: Let $F$ and $G$ be polynomials belonging to $k[X,Y]$, where $k$ is a field. Let $F$ and $G$ not have a single common factor in $k[X][Y]$. Then they do not have a common factor in $k(X)[Y]$ either. As $k(X)[Y]$ is a PID, we have $(F,G)=1$. What is $k(X)[Y]$, and how is it a PID? Also, is $k[X][Y]=k[X,Y]$?",['algebraic-geometry']
879786,Union closure of a set of five finite sets,"I've been playing with some basic set theory while looking at the Union-closed sets conjecture . Pretty basic question, but given four finite sets $A,B,C,D, \mathcal{Y}$ where
$$A \cup B = C \cup D = \mathcal{Y}$$ where $A,B,C,D$ are all distinct, but $A, C$ are not necessarily disjoint from $B,D$, respectively. Also, $|\mathcal{Y}| > |A| \geq |B| \geq |C|  \geq |D|$. If it must be the case that these five sets are union closed, what can I say about $A \cup C$ and $B \cup D$? Intuitively,  I believe that $A \cup C = B \cup D = \mathcal{Y}$, but I am not sure. Any help, or a point in the right direction would be helpful. Thank you. Edit: Clearly, my intuition was incorrect. Having seen the counterexample, it seems more accurate to say that $A \cup C  = \mathcal{Y}$ or $C \subset A$, I will work with this and see what I get. Glad I could throw an idea out and have someone point out an example I had not thought of.",['elementary-set-theory']
879832,Reverse Cauchy Schwarz for integrals,"Let $f,g$ be two continuous positive functions over $[a,b]$ Let $m_1$ and $M_1$ be the minimum and maximum of $f$ Let $m_2$ and $M_2$ be the minimum and maximum of $g$ Prove that $$\sqrt{\int_a^bf^2 \int_a^b g^2}\leq \frac{1}{2}\left(\sqrt{\frac{M_1M_2}{m_1m_2}}+\sqrt{\frac{m_1m_2}{M_1M_2}}\right)\int_a^bfg$$ I can't make any significant progress on this one... Thanks for any hint.","['inequality', 'integration', 'integral-inequality']"
879840,How does $-\sqrt {\frac{{2 - \sqrt 2 }}{{2 + \sqrt 2 }}} $ simplify to $1 - \sqrt 2 $?,"I've the answer for a question in my textbook to be:
$-\sqrt {\frac{{2 - \sqrt 2 }}{{2 + \sqrt 2 }}} $ which i've then simplifed to: $-\sqrt {3 - 2\sqrt 2 } $ However my textbook states $-\sqrt {\frac{{2 - \sqrt 2 }}{{2 + \sqrt 2 }}} =  1 - \sqrt 2 $ How is this?","['fractions', 'algebra-precalculus']"
879842,Check my proof: Big O notation,"I was asked the following: We are given the functions $f(n)=n^{10\log(n)}$ and $g(n)=(\log (n))^n$. Which of the following statements is true: $f(n)\in\mathcal{O}(g(n))$, $f(n) \in \mathcal{\Theta}(g(n))$, $f(n) \in\mathcal{\Omega} (g(n))$ According to wolfram, the first result is true. This is because: $$\lim_{n \to \infty} \frac{f(n)}{g(n)} =0$$ which implies $f(n)\in\mathcal{O}(g(n))$. Here is what I did: $f(n) = n^{10 \log(n)} = (2^{ \log (n)})^{10 \log (n)}=2^{10 (\log(n))^2}$ For $n \geq 5$, $\log (n) >2$, and so: $2^{10 (\log(n))^2} < (\log (n))^{10 (\log(n))^2}$ notice that $$\lim_{n \to \infty} \frac{10 (\log(n))^2}{n}=0$$ (apply lhopital twice) and so if $n$ is large enough, $10 (\log(n))^2 < n$ and we can get $$(\log (n))^{10 (\log(n))^2} < (\log(n))^{n}$$ proving the thing we wanted to prove. My problem is that I used calculus. If possible, I would rather not use limits. I actually want to find such $n_0$ and $c$ such that $f(n) < cg(n)$ for all $n >n_0$. I did not do that in this ""proof"". Would appreciate help.","['asymptotics', 'logarithms', 'calculus', 'functions']"
879847,"If a thread is pulled out of a floating blob of water, must the thread be tangent to the surface of the blob at some point?","My motivation is the recent question I just answered, and my answer use too many hypothesis that I considered superfluous: Always ""one double root"" between ""no root"" and ""at least one root"" ? (Second version) So now on to the question: Consider a differentiable $n$-dimensional manifold $M$. Let $f:\Bbb
 S^{k}\rightarrow M$ be a differentiable bijective embedding of the
  $k$-sphere ($k\leq n$) into $M$. Let $H:[0,1]\times \Bbb
> S^{l}\rightarrow M$ be a differentiable function such that
  $H(t,\cdot)$ is bijective for all $t$ (this is a homotopy of an
  embedding of a $l$-sphere in $M$). Further,
  $\operatorname{range}(H(0,\cdot))$ intersects $\operatorname{range}(f)$
  but $\operatorname{range}(H(1,\cdot))$ does not intersect
  $\operatorname{range}(f)$. The question is: must there exist a $t$ and a point $p\in M$ such that between the tangent space of $\operatorname{range}(H(t,\cdot))$ at $p$ and the tangent space of $\operatorname{range}(f)$ at $p$, one must contains the other? I am sorry if this question have been answered before, or is even a standard theorem, or if this question is poorly phrased. I barely studied differential geometry. Thank you for your help. EDIT: Why the title? Consider a floating blob of water, and we have a thread submerged in it. Well, for simplicity, the question simply assume that the thread is a loop (which is essentially equivalent to a thread fixed at infinity) and we assume that we are already part way through pulling the thread out, so that part of the thread is the on the surface of the water blob. The surface of the water blob is the image of $f$, and the thread at time $0$ is the image of $H(0,\cdot)$. Now imagine we pull the thread out, it seems like at the last moment where the thread touch the water, at the point it touches, the tangent line to the thread is also tangent to the water surface at that point. Hence the question's title.","['differential-topology', 'homotopy-theory', 'differential-geometry']"
