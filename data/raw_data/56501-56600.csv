question_id,title,body,tags
614505,Showing that every subgroup of a metacyclic group is metacyclic,"I have tried to prove that every subgroup of a metacyclic group is metacyclic (where a group $G$ is metacyclic if it has a normal cyclic subgroup $C$ such that $G/C$ is cyclic).  I believe I have a proof, but it seems awfully piecemeal.  Is the following attempt at a proof valid, and if so, is there a more elegant proof? Let $G$ be metacyclic with normal cyclic subgroup $C$ such that $G/C$ is cyclic.  Let $H \le G$. If $H \ge C$, then $H/C$ is a subgroup of $G/C$, and so necessarily cyclic.  It follows that $H$ is metacyclic. Now suppose that $H \le C$.  Then $H$ is cyclic and so it clearly metacyclic. Next, suppose that $H$ is not as above and $H \cap C > 1$.  Since $C \triangleleft G$ we have $(H \cap C) \triangleleft H$ and $H \cap C$ (being a subgroup of $C$) is cyclic.  Then we have that $H/(H \cap C) \cong HC/C$ is a subgroup of $G/C$ and so $H$ is metacyclic by the above argument. Finally, if $H \cap C = 1$, then no nontrivial element of $H$ is in the kernel of the canonical homomorphism $\pi: G \to G/C$, and so there is an isomorphic copy of it in $G/C$.  Since $G/C$ is cyclic, $H$ must be cyclic, and so it is metacyclic. It follows that every subgroup of $G$ is metacyclic. Thanks.","['group-theory', 'abstract-algebra']"
614509,What is the big picture behind AKS algorithm?,"Despite a number of question on AKS algorithm here, there does not seems to anything related to the idea behind it (for those who don't know, AKS primality testing is found in PRIMES is in P ). I read through the paper, check all the step for correctness (and also fix a few small errors). Yet I still can't understand it at all, in the sense that I still can't see the big picture here. From my perspective, it looks like a bunch of unintuitive flashes of insight that just get thrown together until they work. So can someone explain the big idea behind it please? I would appreciate if someone can explain it fully, but here are a few specific questions to get you started: -How does the concept of ""introspective"" come up? -Why is it make sense to look at the group $G$ and $\mathcal{G}$? -How much ""wiggle room"" is there for the bound $o_{r}(n)>(\log_{2}n)^{2}$ (specifically the RHS)? -How could one have come up with the proof of an upper bound for $|\mathcal{G}|$? -How much ""wiggle room"" is there for $\lfloor\sqrt{\phi(r)}\log_{2}n\rfloor$? Thank you for your help.","['prime-numbers', 'intuition', 'algorithms', 'number-theory']"
614511,"For any $n$, there are at most two simple groups of order $n$? [duplicate]",This question already has answers here : Number of finite simple groups of given order is at most $2$ - is a classification-free proof possible? (2 answers) Closed 10 years ago . How do you prove that for any $n$ there are at most two simple groups of order $n$?,"['finite-groups', 'group-theory', 'abstract-algebra']"
614519,squares which are not the sum of a square and twice a triangular number,"I'm trying to determine conditions on integer squares which cannot be written as a square and twice a triangular [all numbers positive], i.e. integers $n \ge 1$ where there are no integers $a,b \ge 1$ such that $$ n^2 = a^2 + b^2+b.$$ For example, $$9 = 1^2 + 8 = 2^2 + 5,$$ so it is such a number; however, $16=2^2 + (2 \cdot 6)$, so it is not. This paper http://math.nju.edu.cn/~zwsun/111o.pdf claims a proof about numbers which cannot be written as the sum of a square and two [not necessarily equal] triangular numbers — I will try to adapt their proof if I can't find another. Any references or hints on how to approach the problem would be appreciated. Thanks! Kieren.","['square-numbers', 'sums-of-squares', 'elementary-number-theory', 'number-theory']"
614530,A use of Hahn-Banach and Riesz Representation,"Let $X$ be a compact Hausdorff topological space.  Suppose $X$ is not a singleton set and $C(X)$ denotes the space of continuous functions on $X$.  Do we have that for all $L \subset C(X)$ a nondense subspace, there exist two probability measures which agree in integration against all elements of $L$ but not on $C(X)$?  Here $L$ is assumed to contain the constants. (This last sentence was added after my comment, but before the answer.)",['functional-analysis']
614569,Chance of adjacent lockers with the same combination,"One weird thing that happened to me in high school was that the combination lock on my locker had the exact same combination as the locker next to it. It always struck me that the odds were crazy on this, but I never calculated it. The lock was a masterlock, the kind where you have 40 options for the first number, then 39 for the second (can't use the first number again), then 39 for the 3rd number (you can use the first number again for it). 1/59,280 chance that two locks have the same combination. (40 * 39 * 39) 1/29,640 chance that any specific combination is next to mine (w/2 lockers next to mine). That gives a 1 in (59,280 * 29,640) chance that a specific combination is next to mine? Or a 1/1,757,059,200 chance. This seems way too high, and there's probably something I'm missing here. Any thoughts on this calculation, or what it should be?",['probability']
614577,How find this function $f(2^m)=?$,"show that:there exists unique function $f:N^{+}\to N^{+}$,such
$$f(1)=f(2)=1$$
and
$$f(n)=f(f(n-1))+f(n-f(n-1))),n=3,4,\cdots$$ and Find $f(2^m),m>2,m\in N$ My try: let
$n=3$ ,then we have
$$f(3)=f(f(2))+f(3-f(2))=f(1)+f(3-1)=f(1)+f(2)=2$$
$$f(4)=f(f(3))+f(4-f(3))=f(2)+f(2)=4$$
$$f(5)=f(f(4))+f(5-f(4))=f(4)+f(1)=5$$
$$f(6)=f(f(5))+f(6-f(5))=f(5)+f(1)=6$$
$$f(7)=f(f(6))+f(7-f(6))=f(6)+f(1)=7$$
$$f(8)=f(f(7))+f(8-f(7))=f(7)+f(1)=8$$
so I guess
$$f(n)=n,n\ge 4$$ But my question: How to prove that there exists unique $f$ which fulfills these two conditions? Thank you","['recurrence-relations', 'functions', 'functional-equations']"
614614,How to solve this integral equation?,"Solve this integral equation:
$$
{{\rm e}^{{\rm i}k\,\sqrt{\vphantom{\Large A}\,r^{2} + z^{2}\,}\,}
\over
\sqrt{\vphantom{\large A}r^{2} + z^{2}\,}}
=
\int_0^{\infty}{\rm K}_{0}\left(\lambda r\right)
\cos\left(\,\sqrt{\vphantom{\Large A}\,\lambda^{2} + k^{2}\,}\,z\right)
{\rm f}\left(\lambda\right)\,{\rm d}\lambda
$$ where ${\rm f}\left(\lambda\right)$ is the unknown function.
${\rm K}_{0}\left(\lambda r\right)$ is the modified Bessel function of the second kind of order zero. $r > 0$. Could anyone give some hints ?. Thanks !.","['calculus', 'integral-equations']"
614617,Most natural symplectic structure?,"Suppose I have 2-dimensional manifold embedded in $\mathbb{R}^3$.
It's clear that the most natural Riemannian metric is the one induced by the
usual inner product. What about symplectic forms? Is there a canonical symplectic form I can put on this manifold? If not, then I ask for something weaker, an example of a typical form that one would expect to see on such a manifold, and can do explicit computations with.",['differential-geometry']
614622,Is a Lyapunov equation always solvable when matrix $A$ is negative definite?,"Given a negative definite matrix $A$ , is the following Lyapunov equation in $P$ $$P A + A^T P = -I$$ always solvable? What kind of form does the solution have? I would appreciate if examples could be given.","['linear-control', 'control-theory', 'matrices', 'systems-of-equations', 'matrix-equations']"
614629,Notation used for multivariate random variables,"Let $(\Omega, \mathcal{F}, P)$ be a probability space and $X_1(\omega), \dots, X_n(\omega)$ be random variables defined on the space. Suppose we are concerned with the joint behavior of the variables. Then one usually considers the variables as a single multivariate random variable defined as a vector of (one-dimensional) random variables: $\mathbf{X}(\omega) = (X_1(\omega), \dots, X_n(\omega))^T$. My first set of questions is : Is it necessary to pack random variables into a random vector to have a legitimate (mathematically correct) discussion about their joint distribution? Can one consider them as just a set $\{ X_1(\omega), \dots, X_n(\omega) \}$? A vector induces a particular order on its elements while a set does not. It is quite common to denote, for example, the joint PDF as $f_{X_1, \dots, X_n}(x_1, \dots, x_n)$ where, again, a particular order is implied even though the vector notation is not used explicitly. So, is it all about ordering? My second set of questions is : Is it correct to denote a set of random variables as $\text{(a-regular-weight-letter-goes-here)}(\omega)$, for example, $X(\omega) = \{ X_1(\omega), \dots, X_2(\omega) \}$? (The question is mainly concerned with the use of $\omega$ next to a set of random variables.) Then is it acceptable to denote, for instance, the corresponding PDF by $f_X(x)$ meaning that $x = \{ x_1, \dots, x_n \}$? Since the order is not specified, it is presumably wrong. Thank you. Regards,
Ivan","['probability-theory', 'random-variables', 'notation']"
614688,Differentiability in metric spaces,I have a question in mind:   Why can't we define differentiability in arbitrary metric spaces? Or can we define it really? Please discuss. I only have studied the notion of differentiability in $\mathbb{R}^n$.,"['metric-spaces', 'derivatives']"
614692,Two notions of total derivative.,"Let $f:\mathbb R^n\rightarrow \mathbb R^m$ be a function. By definition, $f$ is differentiable at $a$ if there exists a linear map $D_af:\mathbb R^n\rightarrow\mathbb R^m$ such that
$$\lim_{h\rightarrow 0}\dfrac{||f(a+h)-f(a)-D_af(h)||}{||h||}=0$$. When this limit exists, we call $D_af$ the total derivative of $f$ at $a$ and we call the corresponding matrix with respect to usual basis, the Jacobian matrix $J_af$. Now $f$ can be written as $f=(f_1,\cdots,f_m)$ where each $f_i:\mathbb R^n\rightarrow \mathbb R$ and $f(x)=(f_1(x),\cdots,f_m(x))$. We define the partial derivative of $f_i$ at $a=(a_1,\cdots,a_n)$ in the direction of $x_j$ by the real number (if it exists) $$\dfrac{\partial f_i}{\partial x_j}(a)=\lim_{h\rightarrow 0}\dfrac{f_i(a_1,\cdots,a_j+h,\cdots,a_n)-f_i(a)}{h}$$ And we show that when $f$ is differentiable at $a$ then all the real numbers $\dfrac{\partial f_i}{\partial x_j}(a)$ exist and the matrix elements $(J_af)_{i,j}=\dfrac{\partial f_i}{\partial x_j}(a)$. Now I see in wikipedia articles that they give the name total derivative also for some other notion: given a map $g:\mathbb R^n\rightarrow \mathbb R$ then the total derivative of $g$ with respect to $x_j$ is 
$$\dfrac{dg}{dx_j}=\dfrac{\partial g}{\partial x_1}\dfrac{dx_1}{dx_j}+\cdots+\dfrac{\partial g}{\partial x_n}\dfrac{dx_n}{dx_j}$$ My questions:
1) Is the formula above a definition for $\dfrac{dg}{dx_j}$ ? 2) Is the notion of $\dfrac{dg}{dx_j}$ reserved only for real valued maps $g:\mathbb R^n\rightarrow \mathbb R$ since it has partial derivatives in its definition formula? 3) How does these two notions of total derivative relate?","['multivariable-calculus', 'calculus']"
614741,Field automorphisms and varieties,"Let $C$ be an algebraically closed field and consider a variety $X$ over $C$. In the language of schemes $X$ is a separated, integral scheme over $C$ with a morphism of finite type
$f:X\longrightarrow \operatorname{Spec} C$. If $\sigma\in\operatorname{Aut} C$ then we can define the variety $X^\sigma$ as the scheme $X$ but with a morphism of finite type $\operatorname{Spec}(\sigma)\circ f: X\longrightarrow \operatorname{Spec} C$. So $X$ and $X^\sigma$ are the same as schemes but not as varieties. Now I'm trying to investigate the relationship between $X$ and $X^\sigma$ aside from the scheme theory, but in the language of classical algebraic geometry. In literature I've found the following theorem with a very short proof that I  don't understand. Theorem: Let $V(f_1,\ldots,f_m)\subset\mathbb P^n_C$ a classical variety where $f_1,\ldots,f_m$ are homogeneous polynomial of $C[x_0,\ldots,x_n]$. If $\sigma\in\operatorname{Aut(C)}$, and with an abuse of notation  we also indicate with $\sigma$ the induced authomorphism on $C[x_0,\ldots,x_n]$, then the closed subset $V(\sigma^{-1}(f_1),\ldots,\sigma^{-1}(f_m))$ ""corresponds"" to $X^\sigma$ (defined above) in the category of classical varieties. To be more precise if we apply the usual functor to the category of schemes at $V(f_1,\ldots,f_m)$ we obtain a variety $X$ and if we apply the same functor at $V(\sigma^{-1}(f_1),\ldots,\sigma^{-1}(f_m))$ we obtain $X^\sigma$. Proof: The two graded algebras $\frac{C[x_0,\ldots,x_n]}{(f_1,\ldots,f_m)}$ and $\frac{C[x_0,\ldots,x_n]}{(\sigma^{-1}(f_1),\ldots,\sigma^{-1}(f_m))}$ are clearly isomorphic thanks to an isomorphism $\widetilde\sigma$ induced by $\sigma$. Using  the morphism $\operatorname{Proj}(\widetilde\sigma)$ follows easily the thesis. Practically the theorem explains what is $X^\sigma$ for concrete varieties such as  closed subsets of $\mathbb P^n_C$, but I don't understand the last sentence of the proof; in particular applying the functor $\operatorname{Proj}$, I see only the isomorphism between $\operatorname{Proj}\left(\frac{C[x_0,\ldots,x_n]}{(f_1,\ldots,f_m)}\right)$ and $\operatorname{Proj}\left(\frac{C[x_0,\ldots,x_n]}{(\sigma^{-1}(f_1),\ldots,\sigma^{-1}(f_m))}\right)$.
Maybe it is a stupid question, since the proof should follow easily, but please help me to understand it. Thanks in advance. References: Essentially two articles: ""B.Köck - Belyi's theorem revisited"" and ""H.Hammer, F.Herrlich - a remark on the moduli field of a curve ""","['algebraic-geometry', 'schemes']"
614749,A Nim-like game with conditions and strategies,"The game: Given $S = \{ a_1,..., a_n \}$ of positive integers ($n \ge 2$). The game is played by two people. At each of their turns, the player chooses two different non-zero numbers and subtracts $1$ from each of them. The winner is the one, for the last time, being able to do the task. The problem: Suppose that the game is played by $\text{A}$ and herself. $\text{a)}$ Find the necessary and sufficient conditions of $S$ (called $\mathbb{W}$), if there are any, in which $\text{A}$ always clear the set regardless of how she plays. $\text{b)}$ Also, find the necessary and sufficient conditions of $S$ (called $\mathbb{L}$) in which $\text{A}$ is always unable to clear the set regardless of how she plays. $\text{c)}$ Then, find the strategies/algorithm by which $\text{A}$ can clear the set with $S$ that doesn't satisfy $\mathbb{L} \vee \mathbb{W}$. Next, suppose that the game is played by $\text{A}$ and $\text{B}$ respectively and $S$ that doesn't satisfy $\mathbb{W}$. $\text{d)}$ Is there any of them having the strategies/algorithm to win the game? If so, who is her and what is her winning way? (It's possible to suppose that $\text{A}$ and $\text{B}$ play the game optimally) $\;$ Note: $\text{1)}$ This is not an assignment. I have just create this out of a familiar thing in my life. So, I haven't known whether there is an official research or even names for the game. If so, I'd be very appreciated if you shared those. $\text{2)}$ The case of $n = 2$ is so obvious that we can eliminate that from consideration. We can do the same thing to an obvious condition in $\mathbb{W}$ (if $\mathbb{W} \neq \varnothing$): $\left ( \sum_{i \in S} i \right ) \; \vdots \; 2$. Thanks in advance. ${}$ Update 1: To clear many people's misunderstanding and to avoid it for new ones, I emphasize the word ""different"" above. And by ""different"", I mean different indices of numbers, not their values. If this is still not clear, I think we should consider $S$ as a finite natural sequence ($a_1$ to $a_n$) and not delete any of them once they become $0$. Update 2: (d) has been renewed a little, thank to Greg Martin.","['algorithmic-game-theory', 'combinatorial-game-theory', 'algorithms', 'recreational-mathematics', 'combinatorics']"
614759,Properties of Arithmetic Functions,"I was recently working on arithmetic functions and using Perron's formula to obtain asymptotic estimates. One observation I made was that the Dirichlet series  often can be written in terms of the Riemann zeta function. More formally, let $f(n)$ be an arithmetic function and $F(s)=\sum^\infty_0 f(n)n^{-s}$ be its Dirichlet series. Is true that $F(s)=\frac{A(s)}{B(s)}$, where $A(s)$ or $B(s)$ are some factors of $\zeta(s)$, or even possibly $\zeta'(s)$ (the first derivative) as in the case of the von Mangoldt function? It seems like this property is not essential to the rest of the analysis as I was just more concerned about where the poles but it did seem like an innate property as a result of the Euler product representation. Also one question that I had to grapple with was the handling of an essential singularity. As I did not have to work out the details for any particular example, I was left wondering about the impact of this as opposed to having a pole of some finite order. Do we adjust the line of integrations to avoid the essential singularity or are we still able to carry on the analysis with no issues whatsoever. Any insight provided will be helpful. Thanks!","['dirichlet-series', 'analytic-number-theory', 'arithmetic-functions', 'number-theory']"
614772,Number of horse races to determine the top three out of 25 horses [duplicate],"This question already has answers here : How to find the 3 fastest horses? (4 answers) Closed 8 years ago . This is a short mathematical puzzle from mindciphers.com which says : The London racetrack needs to submit its top three horses to the Kentucky Derby next month in order to compete for a prize. However in a recent electrical storm, all the racetrack's previous race history was erased such that no one knows the previous times of any of the horses. To make matters worse, each horse looks identical and it is impossible to remember which ones were the fastest. London racetrack is home to 25 horses, but their track can only race 5 horses at a time. What is the fewest number of races that can be conducted in order to determine the 3 fastest horses? Shouldn't be the answer be 6,Am I correct? Logically speaking, dividing 25 horses into 5 groups and racing each group would give us the fastest among each and then racing the winner from each group will give us the horses eligible for 1st,2nd and 3rd positions but i am still confused why is the solution to problem is 7 .. The solution to the problem says that : Divide the 25 horses into groups of 5 and race each group independently. (5 races)Place the winner of each preliminary race in a Championship race to determine the fastest horse of the 25. (1 race).Now you have the fastest horse but you still need to determine the 2nd and 3rd fastest horse. You can start by eliminating all horses that finished 4th or 5th in the preliminary races since there are clearly three horses faster than each of them (15 horses remaining). Next, you can eliminate all the horses from the groups that the 4th and 5th place Championship horses came from for the same logic (9 horses remain). Next, you can eliminate the horses that placed 2nd and 3rd from the group where the 3rd place Championship horse came from, as well as the horse that placed 3rd from the group where the 2nd place Championship horse came from (6 horses remain). Lastly, you can set aside the winner of the Championship race as s/he is clearly the fastest of the whole lot (5 horses remain).
    Now that you have 5 horses left, you can determine the 2nd and 3rd fastest horses of the entire group of 25 by the winner and 2nd place finisher of this last and final race. (1 race) ===>>>> 7 races in total.","['puzzle', 'discrete-mathematics', 'algorithms']"
614789,$\cos^2\frac{1}{2}(\alpha-\beta)=\frac{3}{4}$ if...........,Help please:                                                                    If $\sin\alpha+\sin\beta= \sqrt{3} (\cos\beta-\cos\alpha)$ then show that $\cos^2\frac{1}{2}(\alpha-\beta)=\frac{3}{4}$                                       please tell me how can I approach,['trigonometry']
614829,Proving a lower bound on the limit superior of a sequence.,"Prove that for every positive sequence {$a_{n}$}, $$\varlimsup_{n \to \infty}\frac{\sum_{i=1}^{n+1}a_{i}}{a_{n}}\geq 4$$ Also find the sequences {$a_{n}$} for which 4 is attained. Attempted Solution: At the moment, I just have the following clues: 1.$$b_{n}:=\frac{\sum_{i=1}^{n+1}a_{i}}{a_{n}}, $$$$c_{n}:=\sup \left\{b_{m}\mid m\geq n\right\} , $$$$\rightarrow\varlimsup_{n \to \infty}\frac{\sum_{i=1}^{n+1}a_{i}}{a_{n}}=\lim_{n \to \infty}c_{n}$$
2.$$b_{n}>1\rightarrow c_{n}>1\rightarrow\varlimsup_{n \to \infty}\frac{\sum_{i=1}^{n+1}a_{i}}{a_{n}}>1$$
3. Subproblem: Is it true that for positive sequences {$a_{n}$},
$$\lim_{n \to \infty}a_{n}= \infty\to \lim_{n \to \infty}  \frac{\sum_{i=1}^{n+1}a_{i}}{a_{n}}=\infty$$
If yes, then perhaps $\varlimsup_{n \to \infty}\frac{\sum_{i=1}^{n+1}a_{i}}{a_{n}}=\infty$and the result is proven for all positive unbounded sequences {$a_{n}$}. Kindly provide me hints so that I can progress further.","['inequality', 'summation', 'sequences-and-series', 'limsup-and-liminf']"
614830,Compound interest formula and continuously compounded interest formula derivation,"My textbook gives the formula for compound interest as: $A\left( t\right) =P\left( 1+\dfrac {r}{n}\right) ^{nt}$ Where:
P = The principal, r=the annual rate of interest, n= the frequency of compounding, t=Time in years and A is the total interest accrued over time. It then goes onto show how if we compound £1 continuously at a rate of 100% for 1 year, for greater and greater values of $n$ we get: $\left( 1+\dfrac {1}{n}\right) ^{n}\rightarrow e$ And then uses this to derive the formula for continuously compounded interest: $A\left( t\right) =Pe^{rt}$ The book says it uses ""a little calculus and the definition of e"" to derive this, but how exactly does it do this?","['applications', 'exponential-function', 'algebra-precalculus']"
614835,Divisibility of determinants and matrix rows,"I have stumbled upon an exercise that is giving me nighmares. I've found that it is quite common in older exercise books, but I haven't even heard about it in class or seen it in any lecture in all my years in college, even if it seems to be a basic and simple problem. Naturally, as it happens, these promblem books don't have a solution for it (They just skip it in the solution pages). Here it is: Given the matrix A=$ \left( \begin{array}{ccc}
a_{11} & a_{12} & ... &  a_{1n} \\
a_{21} & a_{22} & ... &  a_{2n} \\
\vdots & \vdots & \ddots & \vdots & \\
a_{n1} & a_{n2} & ... &  a_{nn} \end{array} \right) 
\in M_{n}(N) / (a_{11}, ..., a_{1n})$ are single-digit natural positive numbers, prove that the determinant of the matrix A is divisible by the GCD of the numbers formed by the rows of the matrix. I have tried applying determinant proprieties, solving the actual determinant and juggling with everything I know, but I just have no idea about how to do this. It is very unlikely that they ask us something like this at all, but I am very cusious and I want to know how can this be explained. Edit: Since this is confusing to write, here is another exercise I found using this: The numbers 20604, 53227, 25755, 20927 and 78421 are all divisible by 17. Prove that the determinant $\left| \begin{array}{ccc}
2&0&6&0&4 \\
5&3&2&2&7 \\
2&5&7&5&5 \\
2&0&9&2&7 \\
7&8&4&2&1 \end{array} \right|.$ is also divisible by 17 It's the same concept and it can be seen more clearly.","['matrices', 'linear-algebra', 'determinant']"
614872,"Let $R = \mathbb Z[i]$. Show $I \cap \mathbb Z$ is an ideal in $\mathbb Z$, for all $a \in I \cap \mathbb Z$, $10 \mid a^2 = N(a)$.","Let $R = \mathbb Z[i]$, $z = 3+i$ and $I = \langle z \rangle$. I need to show $I \cap \mathbb Z$ is an ideal in $\mathbb Z$, for all $a \in I \cap \mathbb Z$, $10 \mid a^2 = N(a)$ and $10 \mid a$, and $10\mathbb Z = I \cap \mathbb Z$. I have already proved that $10\mathbb Z \subset I$ since $N(z) = 10$.","['ring-theory', 'ideals', 'elementary-number-theory', 'abstract-algebra']"
614882,$0<a_n<\frac{a_{n-1}+a_{n-2}}{2} \Longrightarrow a_n\ $ converges,"Let $a_n$ be a sequence of positive real numbers such that
$$a_n<\frac{a_{n-1}+a_{n-2}}{2}$$
Show that $a_n$ converges.","['sequences-and-series', 'real-analysis']"
614896,"If $f$ is entire and $\exp(f(z))$ is a polynomial, then $f$ is constant.","In a recent question that was just deleted, @danielfischer gave at the end of his answer the following exercise: for entire $f$, $$e^{f(z)} \text{ is a polynomial} \iff f \text{ is constant}$$ I was thinking about how to prove this...my first idea was to use that $\text{Re}(f)$ is majored by some $\log$ function as $z\to \infty$. Any ideas?","['exponential-function', 'complex-analysis', 'polynomials']"
614919,"If $X=\{x\}$, then $\dim(X)=0$","If $X$ is a quasiprojective variety, then by definition $\dim(X)=trdeg(k(X)|k)$. I'm trying to prove if $X=\{x\}$ is a point, then $\dim(X)=0$ I'm already proved that $k[X]\cong k$, now if I prove $k(X)\cong k[X]$, I'm done. I'm almost sure it's just a simple argument, if someone has some idea or hint how to proceed I would really appreciate. Thanks in advance","['commutative-algebra', 'algebraic-geometry']"
614928,How to show that this integral equals $\frac\pi2$?,"While solving a physical problem from Landau, Lifshitz ""Mechanics"" book, I came across an integral: $$\int_0^\delta \frac{du}{\sqrt{\left(\frac{\cosh\delta}{\cosh u}\right)^2-1}}.$$ In the book only the final answer for the problem is given, from which I deduce that this integral must be $\frac\pi2$. I've tried feeding it to Wolfram Mathematica, but it wasn't able to evaluate it, returning unevaluated result. Evaluating it numerically confirms that this is a likely answer, but I haven't been able to prove this. I've tried making a substitution $v=\frac{\cosh\delta}{\cosh u}$ and got this integral instead: $$\gamma \int_1^\gamma \frac{dv}{v\sqrt{(\gamma^2-v^2)(v^2-1)}},$$ where $\gamma=\cosh\delta$, but still this doesn't give me a clue how to proceed. Also, I can't seem to eliminate the parameter ($\delta$ or $\gamma$), which shouldn't affect the result at all. So, the question is: how can one evaluate this integral or at least prove that it's equal $\frac\pi2$?","['definite-integrals', 'integration']"
614941,Continuity of parameter dependent integral (source needed),"I am looking for a reference from a book for the result of continuity of an integral (found in https://www.encyclopediaofmath.org/index.php/Parameter-dependent_integral ): Let $D \subset \mathbb{R}^n$ and $t \in (0,T)$ , and let $f(x,t)$ be a function that is continuous in $t$ for almost every $x \in D$ , and let $|f(x,y)| \leq g(x)$ where $g$ is integrable. Then $$J(t) = \int_{D}f(x,t)\,dx$$ is continuous with respect to $t$ . I tried the references on the site but they require continuity of $t \mapsto f(x,t)$ for every $x$ , but I need it for almost every $x$ only.","['reference-request', 'integration']"
614947,Coordinate ring of an open set,"I'm trying to solve Exercise 3.1 (b) in Hartshorne's Algebraic Geometry . I see a solution of it and it says that Any proper open set of $\mathbb A^1$ is $\mathbb A^1-S $, where $S$ is a finite number of points $\{p_1,\dots,p_n \}$. The coordinate ring of $\mathbb A^1-S$ is  $k[x,\frac {1} {x-p_1},\dots ,\frac {1} {x-p_n}]$. How can i show that the coordinate ring of $\mathbb A^1-S$ is  $k[x,\frac {1} {x-p_1},\dots ,\frac {1} {x-p_n}]$?","['algebraic-geometry', 'algebraic-curves']"
614958,"Matrix of a bilinear form <A,B> = tr(AB)","In revision for an upcoming exam, I've come across the following question:
Let the bilinear form (A,B) be defined as tr(AB) on the space of 2x2 real matrices. Find an orthogonal basis for the form. I know that when working with vectors, with (x,y) = (xt)Ay that I find the matrix by taking the bilinear form of basis elements, but I'm not sure how to do that here when working with matrices. I also know I'm supposed to get a number from this form (cause its the trace) so I started considering the matrices as 4-d vectors then, although I'm really not sure if I'm on the right track or not. (Not too sure where to go from here) One thought that turned me against it was if I just write the four entries of the vector as the 1st row of the matrix, then 2nd row, I'm not sure how that will get me tr(AB) as opposed to the trace of A times the transpose of B. I do know how to use Gram-Schmidt, but I presume that comes afterwards? Help would be greatly appreciated, as this question has really exposed my lack of knowledge on this topic. Thanks","['linear-algebra', 'bilinear-form']"
614969,"How to calculate volume of a cylinder using triple integration in ""spherical"" co-ordinate system?","Lets have a cylinder given by $x^2+y^2=1$ which is cut from the top by plane $z=2$ and bottom by $z=-2$.I am having problem regarding the limits of ρ for the equation
 ∭ ρ sin^2ϕ dρ dϕ dθ 
where ϕ is the angle that ρ makes with z axis and $θ$ is the azimuthal angle. I know ρ should start from zero but should it end at(or its upper limit be) cosec(ϕ)???","['calculus', 'integration', 'spherical-coordinates']"
614999,Main Theorems/Techniques for proving Homeomorphism?,General Question: what are the most common Theorems/Methods used to prove Homeomorphism? I encountered: - find the map explicitly - use the Compact-to-Hausdorff Lemma - find cts maps $f$ and $g$ s.t. $f\circ g=g\circ f= i$ where $i$ is the identity map. Can anyone deepen/correct/enlarge my list?,"['general-topology', 'relations']"
615000,Well ordering of type epsilon one,"I have been very interested in the countable ordinals for awhile now, but one thing has eluded me despite my research into the subject.  What is a well-ordering of the natural numbers corresponding to $\epsilon_1$? By $\epsilon_{1}$ I mean the second solution to the equation $\omega^a = a$.  I have a basic understanding of the ordinals up to $\epsilon_0$, and I have a (unproven) basic method for constructing a well-ordering of the natural numbers corresponding to those ordinals.  The ordinal $\epsilon_0$ is massively hard to comprehend but I have constructed an ordering on finite trees that has order type $\epsilon_0$, and after a long search found a way to convert finite trees to natural numbers.  However, I have yet to find anything that gives a well-ordering of the natural numbers or trees or pumpkins or any countable set with order type $\epsilon_1$.  Even a hint of an idea of the possibility of constructing an ordering on the natural numbers corresponding to $\epsilon_1$ would be helpful.  Also, if someone knows a process for going even farther, that would also be appreciated.","['ordinals', 'elementary-set-theory']"
615018,Finding the ratio of areas produced by perpendiculars from the $3$ sides of an equilateral triangle.,"A point O is inside an equilateral triangle $PQR$ and the perpendiculars $OL,OM,\text{and } ON$ are drawn to the sides $PQ,QR,\text{and } RP$ respectively. The ratios of lengths of the perpendiculars $OL:OM:ON \text{ is } 1:2:3$. If  $\ \dfrac{\text{area of }LONP}{\text{area of }\Delta PQR}=\dfrac{a}{b}, \quad$ where $a$ 
  and $b$ are integers with no common factors, what is the value of $a+b$ ? All that I was able to do is: Area $LONP=\frac{1}{2} |OL||PL|+\frac{1}{2} |NP||ON|=\frac{1}{2} |OL||PL|+\frac{1}{2} |NP|\ 3|OL|=\frac{1}{2} |OL|\ \left[\ |PL|+3|NP|\ \right]$ Area $PQR=\frac{1}{2} |PR||PQ|\sin 60^o=\frac{\sqrt 3}{4} |PR||PQ|=\frac{\sqrt 3}{4} |NP+RN||PL+LQ|=\frac{\sqrt 3}{4} \left[\ |NP|+|PL|+|RN|+|LQ| \ \right]$ Area $\Delta LON=\frac{1}{2} |ON||OL|\sin 120=\frac{\sqrt 3}{4} |OL|\ 3|OL|=\frac{3\sqrt 3}{4} |OL|^2$ $\mathbf{EDIT : }$Following Suraj M.S 's answer : $$\begin{align}
\text{Area } \Delta PQR &=\dfrac{3x\ RN}{2}+\dfrac{3x\ PN}{2}+\dfrac{x\ PL}{2}+\dfrac{x\ QL}{2}+ {x\ QM}+{x\ MR} \\
\\
&=\dfrac{3x\ (PN+RN)}{2}+\dfrac{x\ (PL+QL)}{2}+{x\ (QM+MR)}\\
\\
&=\dfrac{3x\ (PR)}{2}+\dfrac{x\ (PQ)}{2}+{x\ (QR)}\\
\\
&=kx(\dfrac{3}{2}+\dfrac{1}{2}+{1})=3kx\\
\end{align}$$
Area $\Delta PQR=\dfrac{1}{2} k^2 \sin 60^o=\dfrac{k^2 \sqrt 3}{4} \implies x=\dfrac{k}{4\sqrt 3}$ $\mathbf{Question: }$How do I now find the area of $LONP$ in terms of $x'$s and/or $k'$s only ?","['geometry', 'contest-math']"
615021,Cramer's rule: Geometric Interpretation,"I have a question concerning Cramer's rule: Let $A$ be a matrix and $A \cdot \vec x = \vec b$ a lineare equation. $A_i$ is the matrix $A$ where the i'th column is replaced by $\vec b$ if $det(A) \neq 0$, then we have a unique solution if $det(A)=0$ and at least one $det(A_i) \neq 0$, we have no solution if $det(A)=0$ and all $det(A_i)=0$ we have infinitely many solutions [false!] I'm looking for a geometric interpretation of the rule. I know that $det(A)=$area of parallelepiped, but I'm not able draw a picture for Cramer's rule. Anyone can help me here? Thanks a lot in advance,","['geometry', 'linear-algebra', 'determinant']"
615027,Dimension of a curve,"I'm trying to understand this example: Let $f(T_1,T_2)\subset k[T_1,T_2]$ be a non-constant irreducible polynomial. Let
  $X=Z(f)\subset \mathbb A^2$. We will see that $\dim(X)=1$. We have
  $k[X]=k[T_1,T_2]/(f)$ and $$\dim(X)= \operatorname{tr.deg}_k k(X) \lneq \operatorname{tr.deg}_k k(T_1,T_2) = 2.$$ Since in $k(X)$ the generators $T_1, T_2$ follow to an algebraic
  relation $f$. On the other hand, $\dim(X)\ge 1$ since $X$ is not finite, thus $\dim (X)=1.$ I didn't understand why the $\lt$ part and why $\operatorname{tr.deg}_k(k(T_1,T_2))=2$. Could someone help me? Thanks a lot.","['commutative-algebra', 'algebraic-geometry']"
615067,Where can I find details of the proof of Weil's theorem?,"I heard that Weil proved the Riemann hypothesis for finite fields. Where can I found the details of the proof? I found the following sketch but I was unable to fill the details: Motivation: I try to understand the elementary theory of finite fields but I'm not an expert of algebraic geometry, it would be nice to get some hints what should I study before I can understand schemes so well that I understand the proof. Let $C,E$ be two proper smooth curves over a field $k$, and $f:C\to E$ a finite morphism. Let us set $X=C\times_{\operatorname{Spec}k}E$. Let us consider the graph $\Gamma_f\subseteq X$ of $f$ endowed with the reduced closed subscheme structure. (a) Let $p_1:X\to C$ and $p_2:X\to E$ denote the projections. Then $p_1$ induces an isomorphism $\varphi:\Gamma_f\simeq C$. Show that $\omega_{X/K}\simeq p_1^*\omega_{C/k}\otimes p_2^*\omega_{E/k}$ and that $\omega_{X/k}|_ {\Gamma_F}\simeq \varphi^*\omega_{C/k}\otimes \varphi^*f^*\omega_{E/k}$. (b) Show that $$\operatorname{deg}_k\omega_{X/k}\mid_{\Gamma_f}=2g(C)-2+(\operatorname{deg} f)(2g(E)-2).$$ Deduce from this that $\Gamma_f^2=(\operatorname{deg} f)(2-2g(E))$. (c) Let us henceforth suppose that $C=E$. Let $\Delta\subset X$ denote the diagonal. Show that $\Delta^2=2-2g(C)$. (d) Let us suppose that $f\ne \operatorname{Id}_C$. Let $x\in X(k)\cap \Delta\cap \Gamma_f$, let $y=p_1(x)$, and let $t$ be a uniformizing parameter for $\mathcal{O}_{C,y}$. Show that $$i_x(\Gamma_f,\Delta)=\operatorname{length}\mathcal{O}_{C,y}/(\sigma(t)-t),$$ where $\sigma$ is the automorphism of $\mathcal{O}_{C,y}$ induced by $f$. (e) Let us take a finite field $k=\mathbb{F}_{p^r}$ of characteristic $p>0$, and let $f:C\to C$ be the Frobenius $F_C^r$. Show that the divisors $\Gamma_f,\Delta$ meet transversally and that $\Gamma_f\cap\Delta\subseteq X(k)$. Deduce from this that the cardinal $N$ of $C(k)$ is given by $N=\Gamma_f\cdot \Delta$.",['algebraic-geometry']
615086,Geometry Problem -- Find the area of the circle,"Points $A, B, C, D$ are on a circle such that $AB = 10$ and $CD = 7$.
  If $AB$ and $CD$ are extended past $B$ and $C$, respectively, they
  meet at $P$ outside the circle. Given that $BP = 8$ and $∠AP D = 60º$,
  ﬁnd the area of the circle. Based on the information, I came up with the following sketch: Based, on the given info, and the theorem of geometry that states that the product of two secants and their external parts are equal to each other ($AP\cdot BP\; =\; \mbox{C}P\cdot DP$) I was able to find that $DP = 9$. However, after this point I am stuck. I know I need to somehow find the radius, but I don't know how to proceed.",['geometry']
615087,Induction without base case?,"I'm doing a bit of research on set theory. So far it's quite interesting. Right now I'm reading about transfinite induction. The book states the following theorem about induction in a well-ordered set: Let $(X,<)$ be a well-ordered set. Let $P$ be a property which may hold for elements of $X$. Suppose that, for all $x \in X$, if every element $y<x$ has property $P$, then $x$ has property $P$. Then we conclude that every element of $X$ has property $P$. The theorem doesn't require a base case to hold. The book mentions that a base case is not needed here because if $x$ is the smallest element of $X$, then there are no elements $y<x$ so vacuously all such elements have property $P$. In a way, I understand what the author is saying. But I appeared to have found a trivial counterexample. If we consider $X=\mathbb{N}$ with the normal ordering, the statement is the same as ""strong induction"". If we try to ""prove"" the following statement is true $ \forall n\in \mathbb{N}$: $P(n)$ is the statement ""$n>1000$"" , (which is obviously false for $n=1$, say) Then we get something like: Suppose that $n$ is such that $P(m)$ holds whenever $m<n$, then $n>1000$. Thus $P(n)$ holds $\forall n \in \mathbb{N}$. There's obviously something wrong with the ""proof"". I suppose it's because ""$P(m)$ holds whenever $m<n$"" does not imply ""$n>1000$""? But I'm not too sure... Later on, the book states the version of induction for ordinals: Let $P$ be a property of ordinals, assume that $P(0)$ is true, $P(\alpha)$ implies $P(s(\alpha))$ for any ordinal $\alpha$ ($s(\alpha)$ is the successor ordinal of $\alpha$) If $\lambda$ is a limit ordinal and $P(\beta)$ holds for all $\beta < \lambda$, then $P(\lambda)$ holds. Then $P(\alpha)$ is true for all ordinals $\alpha$. This time a base case is required. But I read Wikipedia ( http://en.wikipedia.org/wiki/Mathematical_induction ) near the bottom under Transfinite Induction and it says ""strictly speaking, it doesn't..."" so I'm pretty confused.","['induction', 'elementary-set-theory']"
615093,Convergence of the sequence $a_n=\int_0^1{nx^{n-1}\over 1+x}dx$ [duplicate],"This question already has answers here : Limit of $s_n = \int\limits_0^1 \frac{nx^{n-1}}{1+x} dx$ as $n \to \infty$ (5 answers) Closed 9 years ago . How to prove the following sequence converges to $0.5$ ?
$$a_n=\int_0^1{nx^{n-1}\over 1+x}dx$$
What I have tried:
I calculated the integral $$a_n=1-n\left(-1\right)^n\left[\ln2-\sum_{i=1}^n {\left(-1\right)^{i+1}\over i}\right]$$
I also noticed ${1\over2}<a_n<1$ $\forall n \in \mathbb{N}$. Then I wrote a C program and verified that $a_n\to 0.5$ (I didn't know the answer before) by calculating $a_n$ upto $n=9990002$ (starting from $n=2$ and each time increasing $n$ by $10^4$). I can't think of how to prove $\{a_n\}$ is monotone decreasing, which is clear from direct calculation.","['sequences-and-series', 'convergence-divergence', 'calculus', 'integration', 'definite-integrals']"
615102,How do you prove that $\Bbb{Z}_p$ is an integral domain?,Let $\Bbb{Z}_p$ be the $p$-adic integers given by formal series $\sum_{i\geq 0} a_i p^i$.  I'm having trouble proving that it's an integral domain.,"['ring-theory', 'p-adic-number-theory', 'abstract-algebra']"
615119,How to generalize symmetry for higher-dimensional arrays?,"@BrianM.Scott 's answer to this question Q: 3-dimensional array suggests that there is no standard concept of symmetry for 3-, 4-, N-dimensional arrays, in constrast to the case for 2-D arrays, as in linear algebra for matrices.  Are there alternative definitions of symmetry for higher-dimensional arrays?  Are there specific definitions that are widely used in certain contexts, e.g. in tensor calculus? (I don't have a specific need; I'm trying to help implement a symmetry test for a matrix library [ core.matrix for the Clojure language].  Since the library allows higher-dimensional arrays, there's a question about whether there is a natural choice for what the symmetry test should return for higher-dimensional arrays.)","['tensors', 'matrices', 'linear-algebra']"
615134,Induced map on spectra of rings,"Let $B$ be a ring containing $A$, and the ring extension is integral. Furthermore, $B$ is a finitely generated $A$-algebra. Then how to show that the induced map on spectra of the rings is a finite map, i.e., inverse image of finite sets is finite.","['commutative-algebra', 'algebraic-geometry']"
615141,Does the series $\sum^\infty_{n=1}\frac{n!}{\sqrt{(2n)!}}$ converge/diverge?,"Does the series $\displaystyle\sum^\infty_{n=1}\frac{n!}{\sqrt{(2n)!}}$ converge/diverge? I used the ratio test but I'm not sure: $\begin{align} \frac{\frac{(n+1)!}{\sqrt{(2n+2)!}}}{\frac{n!}{\sqrt{(2n)!}}}
&=\frac{n+1}{\sqrt{(2n+1)(2n+2)}}\\
&=\frac{n+1}{4(n+1)^2\sqrt{2n+1}}\\
&=\frac{1}{4\sqrt{2n+1}} \end{align}$ The limit of that is smaller than $1$ so the series does converge. Is it correct ?","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis']"
615172,Why the total space of $\mathcal{O}(K)$ has trivial canonical bundle?,"Let $X$ be a smooth variety, and $K$ be the canonical divisor on $X$. Let $\mathcal{O}(K)$ be the corresponding canonical sheaf. Then why the total space $Spec\mathcal{O}(K)$ has trivial canonical bundle?","['algebraic-geometry', 'complex-geometry']"
615174,Decomposition of representation of symmetric group,"Let $V$, $\dim V=n-1$  be the standard representation of the symmetric group $S_n$  and let $V'= \langle x_1,x_2,\ldots,x_n \rangle$ be its  natural representation.   Then ( see. Fulton, Harris, 4.19) we have 
$$
{\rm Sym}^2 V=U \oplus V \oplus V_{(n-2,2)},
$$
where $U$ is the trivial representation and $V_{(n-2,2)}$  is  a representation that correspond  to a partition $(n-2,2).$ Question 1. What is the decomposition $
{\rm Sym}^2 V'?
$ Question 2. Can we indicate in explicit way a basis for each  irreducible component of this decomposition? My try is as follows. Since $V'=U \oplus V$  then 
$$
{\rm Sym}^2 V'={\rm Sym}^2U \oplus {\rm Sym}^2 V \oplus U \cdot V.
$$
I think that ${\rm Sym}^2U \cong U $  and $U \cdot V \cong V.$
Then 
$$
{\rm Sym}^2 V'={\rm Sym}^2U \oplus {\rm Sym}^2 V \oplus U \cdot V=2 U \oplus 2 V \oplus V_{(n-2,2)}.
$$
Am I right? If yes,  then what be answer  for the second question? I know  that $U=\langle x_1+x_2+\cdots+x_n \rangle$ and $V= \langle x_1-x_2,x_1-x_3,\ldots,x_1-x_n \rangle$,  but I don't know  what is  the basis for its realisation in ${\rm Sym}^2V'$  as polynomials  of degree $2.$ Edit. $2U=\langle x_1^2+x_2^2+\cdots+x_n^2 \rangle \oplus \langle x_1 x_2+x_1 x_2 +\cdots+ x_{n-1} x_n\rangle $ Butwhat is  the basis of $V_{(n-2,2)}$ and $V$  realised in ${\rm Sym}^2 V'?$","['symmetric-groups', 'finite-groups', 'group-theory', 'representation-theory']"
615180,Fubini's Theorem for Infinite series,"In the book what I've read, there is one point where the author suggest to begin the proof of the Fubini's Theorem for infinite sum in the case when is non-negative after this try to generalize. But I really have a bad time trying to understand the entire problem for various reason: number one I'm not absolutely sure if what I've done is correct and second I have no idea of how to pass in the general case. Any suggestion, advice whatever to deal with the general case it would be great. Thanks. Fubini's Theorem for Infinite series : Let $f: \mathbb{N} \times\mathbb{N} \rightarrow \mathbb{R} $ be a function such that $\sum _{(n,m)\in  \mathbb{N} \times\mathbb{N}} f(n,m)  $ is absolutely convergent. Then we have: $\sum _{n=0}^{\infty}\sum _{m=0}^{\infty} f(n,m) =\sum _{(n,m)\in  \mathbb{N} \times\mathbb{N}} f(n,m)=\sum _{(m,n)\in  \mathbb{N} \times\mathbb{N}} f(n,m)= \sum _{m=0}^{\infty}\sum _{n=0}^{\infty} f(n,m)$ Proof: We may assume that for each $n,m$, that the function is non-negative, i.e., $\forall n,m \in\mathbb{N}.f(n,m)\ge0 $. We set $L:=  \sum _{(n,m)\in  \mathbb{N} \times\mathbb{N}} f(n,m)  $, and we want to show that $\sum _{n=0}^{\infty}\sum _{m=0}^{\infty} f(n,m)$ converges to $L$. Let $X\subset \mathbb{N^2}$ and suppose that $X$ is finite. We claim that $\sum _{(n,m)\in  X} f(n,m) \le L$. Let $g: \mathbb{N^2}\rightarrow \mathbb{N}$ be a bijective map. If we restrict the map to $X$, clearly $g[X]$ is finite, hence bounded. Since $L$ is the sup of the  sequences of partial sums $\sum _{(n,m)\in  \{0...N\} \times\{0...M\}} f(n,m)$ which is monotonic increasing. Thus is at most $L$. First we have to show that $\sum _{n=0}^{\infty}\sum _{m=0}^{\infty} f(n,m)$ converges. It will suffice to to show that $\sum _{n=0}^{N}\sum _{m=0}^{\infty} f(n,m)\le L$ for any $N$. Since $\sum _{m=0}^{M} f(n,m) \rightarrow \sum _{m=0}^{\infty} f(n,m)$, $\sum _{n=0}^{N}\sum _{m=0}^{\infty} f(n,m)$ is the limit of $\sum _{n=0}^{N}\sum _{m=0}^{M} f(n,m)$ as $M \rightarrow \infty$. Then, by the monotonic convergence theorem it will suffice to show that $\sum _{n=0}^{N}\sum _{m=0}^{M} f(n,m)\le L$ for any $M$. But, $\sum _{n=0}^{N}\sum _{m=0}^{M} f(n,m) = \sum _{(n,m)\in  \{0...N\} \times\{0...M\}} f(n,m)$ by the Fubini's Theorem for finite series and since $\{0...N\} \times\{0...M\} \subset \mathbb{N^2}$ is a finite subset. the result follows for what we said above. Now let $\varepsilon >0$ be given. Then, $L -\varepsilon$  cannot be the sup of the sequence of partial sum and we can then find a finite set $ X \subset \mathbb{N^2}$ such that $\sum _{(n,m)\in  X} f(n,m) > L-\varepsilon$. Since $X$ is assumed to be finite then there is  contained in some set $ \{0...N\} \times\{0...M\}$. Thus for any $N'\ge N,M\ge M'$ we have $\sum _{n=0}^{N'}\sum _{m=0}^{M'} f(n,m) = \sum _{(n,m)\in  \{0...N'\} \times\{0...M'\}} f(n,m)\ge L-\varepsilon$, and hence since we already know that the sum exists $\sum _{n=0}^{\infty}\sum _{m=0}^{\infty} f(n,m)\ge\sum _{n=0}^{N'}\sum _{m=0}^{\infty} f(n,m)\ge L-\varepsilon$. Note: I already proved the Fubini's Theorem for finite series using induction. Also I think we can argue as follows. Let $g: \mathbb{N^2}\rightarrow \mathbb{N}$ be any bijective map. Since $ \sum _{(n,m)\in  \mathbb{N} \times\mathbb{N}} f(n,m)  $  converges absolutely then any rearrangement give us the same result. Thus $\sum _{i=0}^{\infty} f(g^{-1}(i)) =  L$. Also the function is non-negative, so the sequence of partial sums converges to its supremum, i.e., $L=\text{sup}_{N\ge 0}\sum _{i=0}^{N} f(g^{-1}(i))$. We claim that if  $X$ is a finite subset $\mathbb{N^2}$. Then $\sum _{(n,m)\in  X} f(n,m) \le L$. The sequence $\big(g(n,m)\big)_{(n,m)\in X} $ is finite and hence bounded. Let $N$ be an upper bound, i.e., $g(n,m)\le N$ for any $(n,m)\in X$. We set $\{ i\in \mathbb{N}: i\le N \}$. Then $g [X] \subset \{ i\in \mathbb{N}: i\le N \}$. We have: $\sum _{(n,m)\in  X} f(n,m)=\sum _{n\in  g[X]} f(g^{-1}(n)) \le \sum _{n\in \{ i\in \mathbb{N}: i\le N \}} f(g^{-1}(n))=\sum _{n=0}^{N} f(g^{-1}(n))\le L$. Thus $\sum _{(n,m)\in  X} f(n,m) \le L$ as desired. Let $n, M\in\mathbb{N} $ be arbitrary. Then $\sum _{(i,j)\in \{n\} \times \{0....M\}} f(i,j)=\sum _{m=0}^{M} f(n,m) \le L$ for each $M\ge 0$. Thus $\sum _{m=0}^{M} f(n,m)$ converges and is at most $L$, i.e.,  $\sum _{m=0}^{\infty} f(n,m)\le L$ for a fixed $n$. We claim that $\sum _{n=0}^{N}\sum _{m=0}^{\infty} f(n,m)\le L$ for any $N\in \mathbb{N}$. We argue by contradiction suppose that there is some $N\ge 0$ such that 
$\sum _{n=0}^{N}\sum _{m=0}^{\infty} f(n,m)> L$. For the sake of simplicity let $S_{N,\infty}:=\sum _{n=0}^{N}\sum _{m=0}^{\infty} f(n,m)$, and $S_{N,M}:=\sum _{n=0}^{N}\sum _{m=0}^{M} f(n,m)$. We may assume that $S_{N,\infty}> L$. Let us fix some $\varepsilon>0$ such that $\varepsilon< S_{N,\infty}-L$. Since $S_{N,M}\rightarrow S_{N,\infty}$. Let some sufficient large  $M$ such that $S_{N,\infty}-S_{N,M}\le \varepsilon<S_{N,\infty}-L$. Then $L<S_{N,M} = \sum _{n=0}^{N}\sum _{m=0}^{M} f(n,m) =\sum _{(n,m)\in  \{0...N\} \times\{0...M\}} f(n,m)\le L$ [since $\{0...N\} \times\{0...M\}$ is a finite subset of $\mathbb{N^2}$] a contradiction. This means that $S_{N,\infty}\le L$ for each $N\ge 0$ and hence $S_{\infty,\infty}\le L$. Let $X\subset \mathbb{N^2}$ which is finite. Then $X\subset \{0...N\}\times \{0...N\}$. So $\sum _{(n,m)\in  X} f(n,m)\le \sum _{(n,m)\in  \{0...N\} \times\{0...N\}} f(n,m)=\sum _{n=0}^{N}\sum _{m=0}^{N} f(n,m)\le S_{\infty,\infty}$. Since this hold for any finite set of $\mathbb{N^2}$, then $L\le  S_{\infty,\infty}$. Hence $L = S_{\infty,\infty}$ Is this correct? Any suggestion for the general case (the sign case), please.  What about if we show that $f(n,m)$ can be express as a part which is just positive and other which is negative, with this almost done, right? What do you think about it? Thanks.","['self-learning', 'sequences-and-series', 'proof-verification', 'real-analysis']"
615182,"Space of morhisms of representations, its dimension in special case","The symmetric group $S_n$ acts linearly on $\mathbb{C}^n$, hence it brings up to the representation in $\Lambda^m\mathbb{C}^n$. The goal is to evaluate the dimension of morphisms $\mathrm{Hom}_{S_n}(\Lambda^k\mathbb{C}^n,\Lambda^m\mathbb{C}^n)$. There is a general way to do it: given two representations $\rho_1$ and $\rho_2$ in $V_1$ and $V_2$ respectively of some group $G$ we can build a representation $T$ in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$ by $$T_g(\phi)=\rho_1(g)\circ\phi\circ\rho_2(g^{-1})$$
So, morphisms of $\rho_1$ and $\rho_2$ are exactly $G$-invariants in this representation of $G$ in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$. But the dimension of the space of $G$-invariants is the trace of $\frac{1}{|G|}\sum T_g$, i.e. the sum of traces $\frac{1}{|G|}\sum \operatorname{tr}(T_g)$. So, I do not believe we should evaluate each trace in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$... Could you help? Perhaps, there is another way?","['representation-theory', 'abstract-algebra']"
615212,Statements about attributes of given function.,"Let $HF(0) = \emptyset$. $HF(n+1) = P_\omega(HF(n))$, where $P_\omega(A)$ - set of all finite subsets of $A$, and $HF = \displaystyle\bigcup_{n\subset\omega}HF(n)$. Are those statements true? $HF(n-1) \subseteq HF(n) (\forall n>0).$ $(\forall n>0)HF(n)$ - finite. $HF$ has no countable sets. Is there any point in using math induction to prove some of the statements? Second statement seems true because it can be proven with math induction. If $n = 1$, then it's obvious that $HF(1)$ is finite. Now suggest that $HF(n)$ is finite, then $HF(n+1)$ is a set of all finite subsets of $HF(n)$, and because $HF(n)$ is finite, then $HF(n+1)$ is finite. I have a problem with third statement. Is it somehow a consequention of second statement?","['logic', 'elementary-set-theory']"
615231,Slick proof of Gauss' theorem,"Below is a very concise proof of Gauss's theorem (from the book Vector and Tensor Analysis with Applications by Borisenko, Tarapov). Unfortunately, I'm having trouble understanding it, despite staring at it for a few days. I'd really appreciate it if someone would explicitly show a couple of the intermediate steps. I've marked these with $(*)$: Gauss's Theorem: Given a volume $V$ bounded by a closed surface $S$, suppose the functions $$P(x_1,x_2,x_3),\ \ Q(x_1,x_2,x_3),\ \ R(x_1,x_2,x_3)$$
  and their derivatives $$\frac{\partial P}{\partial x_1},\ \frac{\partial Q}{\partial x_2},\ \frac{\partial R}{\partial x_3}$$ 
  are continuous on $V \cup S$. Then
  $$\iiint \limits_V \left( \frac{\partial P}{\partial x_1} + \frac{\partial Q}{\partial x_2} + \frac{\partial R}{\partial x_3} \right)dV = \iint \limits_S \left[ P\cos(\mathbf{n},x_1) + Q\cos(\mathbf{n},x_2)+ R\cos(\mathbf{n},x_3)\right]dS,$$
  where $\mathbf{n}$ is the unit exterior normal to $S$. Proof: Suppose no line parallel to the $x_1$-axis intersects $S$ in more than two points $M^\prime$ and $M^{\prime\prime}.$ Then, if $S_{23}$ is the projection of $S$ onto the $x_2x_3$-plane, we have
  $$(*)\iiint\limits_V \frac{\partial P}{\partial x_1}dV = \iint\limits_{S_{23}} \left( \int\frac{\partial P}{\partial x_1}dx_1\right)dS_{23} = \iint \limits_{S_{23}}\left[ P(M^\prime) - P(M^{\prime\prime})\right]dS_{23}.$$
  But the element $dS_{23}$ of the projection $S_{23}$ can be expressed in terms of the elements of the surface $S$ at the points $M^\prime$ and $M^{\prime\prime}$:
  $$dS_{23} = dS(M^\prime)\cos[\mathbf{n}(M^\prime),x_1] = -dS(M^{\prime\prime}) \cos[\mathbf{n}(M^{\prime\prime}),x_1].$$ Therefore
  $$ (**) \iiint\limits_V \frac{\partial P}{\partial x_1}dV = \iint \limits_S P(M)\cos[\mathbf{n}(M),x_1]dS(M),$$ where $M$ is a variable point of the surface $S$. The formulas $$\iiint\limits_V \frac{\partial Q}{\partial x_2}dV = \iint \limits_S Q\cos[\mathbf{n},x_2]dS,$$ $$\iiint\limits_V \frac{\partial R}{\partial x_3}dV = \iint \limits_S R\cos[\mathbf{n},x_3]dS$$ are proved in the same way, provided no line parallel to the $x_2$ or $x_3$-axis intersects $S$ in more than two points. Adding these formulas, we obtain
  $$\iiint \limits_V \left( \frac{\partial P}{\partial x_1} + \frac{\partial Q}{\partial x_2} + \frac{\partial R}{\partial x_3} \right)dV = \iint \limits_S \left[ P\cos(\mathbf{n},x_1) + Q\cos(\mathbf{n},x_2)+ R\cos(\mathbf{n},x_3)\right]dS.$$","['multivariable-calculus', 'vector-analysis']"
615244,What is the intuition behind the generalized confidence interval?,What is the intuition behind the generalized confidence interval? My best description on GCI that it is the way to derive a formula to calcuate the area of the center region in a asymetry distribution where it has the two-sided-equal-tailed regions in which the area of the two-sided-equal-tailed regions are the same in the n dimensional case. A paper on the GCI: http://www.stat.colostate.edu/statresearch/stattechreports/Technical%20Reports/2002/02_10.pdf Also: http://www3.stat.sinica.edu.tw/statistica/oldpdf/a10n420.pdf,"['statistics', 'intuition', 'probability-distributions', 'probability']"
615253,Is there any way to define differentiablity without any reference to the Euclidean space?,"We define metric spaces based on the properties of the real numbers $\Bbb{R}$. In the same spirit we define smooth manifolds. But there is a more general and elegant way to formulate our intuition of nearness without any reference to the real numbers which is called topology. Is there any way to do the same for smoothness? One might think of modeling smoothness on topological vector spaces instead of  $\Bbb{R}^n$ , but that is basically the same. So I am looking for something general, natural and at the same time useful like topology. And of course I know there isn't such a thing out there but I want to know what would you do if you wanted to lay down the theory of ""manifolds""? \ Can't we define differentiability on an arbitrary ordered field?","['soft-question', 'manifolds', 'differential-geometry']"
615269,"How to prove $\mathbb{Z}[\sqrt{2}i]=\{a+b\sqrt{2}i\mid a,b\in\mathbb{Z}\}$ is a principal ideal domain?","How to prove $\mathbb{Z}[\sqrt{2}i]=\{a+b\sqrt{2}i\mid a,b\in\mathbb{Z}\}$ is a principal ideal domain? I can prove it is unique factorization domain. Moreover, how to prove $\mathbb{Z}[\sqrt{n}i]=\{a+b\sqrt{n}i\mid a,b\in\mathbb{Z}\}$ is not unique factorization domain for all $n\geq 3$ hence they are not principal ideal domain?","['ring-theory', 'abstract-algebra']"
615271,More on numbers of homomorphisms.,"This is directly related to this question, but should be easier: Suppose for finite groups $G_1$ and $G_2,$ we know that for any group $H,$ 
$$|\rm{Hom}(G_1, H)| = |\rm{Hom}(G_2, H)|$$ Does it follow that $G_1 \simeq G_2?$ I would think that requiring that $H$ is finite should not make it less true, but whatever works for you.","['finite-groups', 'group-theory']"
615273,Book stacking problem with consecutively lighter books,"I'm currently working on problem 6a of this problem set from MIT Open Course Ware . It's a spin on the book stacking problem . In this scenario, any additional books you stack beyond the first one has half of the weight of the previous book, and you also have a duplicate of the lightest book on the stack. The solution in the problem set says that each additional book you stack in this case will give you exactly 1/4th of a book length for each additional book you add. My problem with this conclusion is that the solution assumes ""Thus, you can model this problem as stacking two books of equal weight"". Isn't this untrue since a stack of books has an uneven weight distribution whereas a single book would have a uniform weight distribution? With a large book stack (> 3), the stack will get lighter the farther you move away from it's center of gravity, which would need to be compensated for when finding the new center of gravity. Can someone explain how the solution came up with the fraction 1/4  as the constant growth length?",['discrete-mathematics']
615291,Continuous Linear Functional on $\ell^{\infty}$,"I'd like help answering two questions. 1) Prove that there is a continuous linear functional on $\ell^\infty$ such that $f(e_n)=0 \ \forall n \in \Bbb{N}$ and $f(a)=5$ where $a=(1,1,1,1,1,1,\ldots)$. 2) Prove that there is not a continuous linear functional on $\ell^\infty$ such that $f(e_n)=0 \ \forall n \in \Bbb{N}$ and $f(a)=4$ for $a=(1,1/2,1/3,1/4,\ldots)$. Note: $e_n$ stand for the point $(0,0,\ldots,0,1,0,\ldots,0,0)$ with $1$ in the $n$-th position and the rest $0$'s, i.e $(e_n)=(\delta_{mn})$. Thanks in advance.","['normed-spaces', 'functional-analysis', 'banach-spaces']"
615296,How to prove that $\mathrm{int}(f(U))=\varnothing$,Let $f:U\subset\mathbb{R}^m\longrightarrow\mathbb{R}^n$ be a continuous injective function where $m<n$ and $U$ an open set. How to prove that $$\mathrm{int}(f(U))=\varnothing$$ Any hints would be appreciated.,"['general-topology', 'real-analysis']"
615305,meromorphic function in the unit disc with only one pole of order n,"Let $f$ be meromorphic in a neighborhood of $\{|z| \leq 1\}\setminus \{1/2\}$ and have a pole or order $n$ at $1/2$. Suppose that $|f| < 3$ on $\{|z|=1\}$. Show that for any $\phi \in \mathbb{R}$, $f$ attains the value $3e^{i\phi}$ exactly $n$ times (counting multiplicities) in $\{|z| \leq 1\}$. I suspect that somehow Rouche's theorem will be needed to complete this proof. I started with observing that there exists a holomorphic function $g(z)$ in $\mathbb{\bar{D}}$ given by $g(z) = (z-1/2)^n f(z)$ such that $g(1/2) \neq 0$. Therefore using the maximum principle I can write that in $\mathbb{\bar{D}}$, $|g| < \max_{|z|=1} |z-1/2|^n |f| < 3\dfrac{3^{n}}{2^n}$. But I am confused on what holomorphic functions to choose and compare while applying Rouche's theorem.","['power-series', 'roots', 'complex-analysis']"
615307,Floquet Theory - Reducing ODE's to Constant Coefficient ODE's?,"Am I right in my reading of the bottom of this page by Arnold, where he apparently says that to any system of first order ODE's with periodic coefficients one can find a change of variables reducing the system to one with constant coefficients? In other words, we can find a change of variables that reduces something like $$y''+\sin(x)y'+\cos(x)y=0$$ to a constant coefficient ODE by Floquet's theorem? Surely this isn't right is it? Should I be as shocked with this as I am? Can one do this if we similarly start throwing in crazier periodic functions as coefficients, like saw-tooth functions etc...?","['ordinary-differential-equations', 'periodic-functions']"
615318,Maclaurin expansion of arctan: convergence?,"In my textbook, the Maclaurin series expansion of $\arctan{x}$ is found by integrating a geometric series, that is, by noting that $\frac{d}{dx}(\arctan(x)) = \frac{1}{x^2+1}$ then rewriting the latter as a geometric series over which one can then integrate. What bothers me is that the geometric series is only convergent when $|x| < 1$, but $\arctan(x)$ is defined for all $x$. This question of convergence is dismissed by the author, but I'm curious as to what's really going on here. Is the series expansion still valid outside the radius of convergence, and if so, why?","['power-series', 'calculus']"
615335,definition of determinant in Artin,"In Michael Artin's Algebra , the discussion on determinant starts from the standard recursive expansion by minors. Artin defines determinant as a function $\delta$ from a square matrix to a real number. Then Artin lists three characteristics for this function in Theorem 1.4.7 (page 20, second edition) as quoted below. ""Theorem 1.4.7 Uniqueness of the Determinant. There is a unique function $\delta$ on the space of $n\times n$ matrices with the properties below, namely the determinant. With $I$ denoting the identity matrix, $\delta(I)=1$ . $\delta$ is linear in the rows of the matrix $A$ . If two adjacent rows of a matrix $A$ are equal, then $\delta(A)$ =0."" In his book, Artin does not explain why $\delta$ should have these properties. I suppose in history people went through a period of trial and error before such abstract concept was proposed and accepted. Can anyone refer me to any source revealing how these properties were thought of, especially, the second and the third property. Thank you! Regards.","['linear-algebra', 'math-history', 'soft-question']"
615344,Derivatives and average velocities,"It is easily proven that given an everywhere differentiable function $f$ on $\Bbb R$, if $f$ is constant, linear, or a quadratic function, then $$\frac{f(x)-f(y)}{x-y}=\frac{f'(x)+f'(y)}{2}$$ for all distinct $x$ and $y$ in $\Bbb R$. Is it true, conversely that if that particular equation holds, then $f$ is a constant, linear or quadratic function? I thought of this problem after reading a MAA Focus magazine article.","['derivatives', 'functions']"
615360,Iterating a real continuous injective function having no fixed points.,"Let $f: \mathbb R \rightarrow\mathbb R$ be a continuous injective function. If $f(x)≠x ,\forall x∈\mathbb R$ and  there exists a positive integer $n$ such that $f^n(x)=x , \forall x∈\mathbb R$ , then how do we prove that $f^2(x)=x ,\forall x∈\mathbb R$ ?","['functions', 'continuity', 'real-analysis']"
615387,"Show that $\int_{-\infty}^{\infty} \frac{1}{x^4 + 1} \,dx = \frac{\pi}{\sqrt{2}}$ [duplicate]","This question already has answers here : Evaluating $\int_0^\infty \frac{dx}{1+x^4}$. [duplicate] (7 answers) Closed 10 years ago . Show that the following integral:
$$ \int_{-\infty}^{\infty} \frac{1}{x^4 + 1} \,dx = \frac{\pi}{\sqrt{2}}. $$
I know this is $\pi/\sqrt{2}$ which I was found with Mathematica. I think I could utilise the substitution $t = x^2 + 1$ or $t = 1/x$, but I can't seem to make an approach because the integral is quite different from what I have been dealing with. Is there a better approach?","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
615401,How would you prove $E = -\vec{\nabla} V$ from the electric potential's line integral?,"Basically, we were given an equation:
$$V_1 - V_2 = \int_{r_1}^{r_2}\vec{E}\cdot d\vec{r}$$ where $\vec{E}$ is the electric field distribution and $d\vec{r}$ is the displacement vector of the charge. Suppose that, in a 3D space, the electric field is $$\vec{E} = E_x \hat{i} + E_y \hat{j} + E_z \hat{k}$$ and the displacement vector is $$d\vec{r} = d_x \hat{i} + d_y \hat{j} + d_z \hat{k}$$ Given $V = V(x, y, z)$, we have to prove that $$E = -\vec{\nabla} V$$ Which make a whole lot of sense, considering that the equations for gradient theorem and line integral state so. However, assuming I have no clue what the gradient theorem is, how would I go about proving $E = -\vec{\nabla} V$ using only the given equations above? I know that if $V$ and $E$ were merely functions of $x$:
$$V(x) = \int_{x_o}^{x} E(x)dx$$
we can differentiate both sides with respect to the upper limit to get:
$$\frac{\partial V}{\partial x} = -E(x)$$
But how would I go about doing that if it was a 3D space? Do I need to use some electrostatic concepts, or is this all just basic calculus that I've long forgotten? I think I'm really overthinking this because my brain says it's simple, yet I just can't think of a way.","['multivariable-calculus', 'potential-theory', 'vector-analysis', 'physics']"
615451,Alternating group generators,"Consider the alternating group $\mathcal A_n$ ($n$ is an odd integer). Do $(12\cdots n)$ and $(12)(34)$ generate $\mathcal A_n$? In other words, $\langle (12\cdots n),(12)(34)\rangle =\mathcal A_n$. I know that $\langle (12\cdots n),(123)\rangle=\mathcal A_n$. But how can we make $(123)$?","['permutations', 'group-theory', 'symmetric-groups']"
615464,How many books are in a library?,"My cousin is at elementary school and every week is given a book by his teacher.  He then reads it and returns it in time to get another one the next week. After a while we started noticing that he was getting books he had read before and this became gradually more common over time.   Naturally, I started to wonder how one could estimate the total number of books in their library. Say the true number of books in the library is $N$ and the teacher picks one uniformly at random (with replacement) to give to you each week.  If at week $t$ you have received a book you have read before $x$ times, is there an unbiased estimator for the total number of books in the library and what is the variance of this estimator? Is there another biased estimator with lower variance? In my cousin's case, in the first $30$ weeks he received a book he had received before $3$ times.","['statistics', 'probability']"
615470,Rational roots of a cubic polynomial,"Find all distinct non-zero rational numbers $a$, $b$ and $c$ such that $x (x+a) (x+b) +c$ has 3 distinct non-zero rational roots. What I have so far: Let the polynomial have factorization $(x+x_1)(x+x_2)(x+x_3)$ where $x_i$'s are distinct non-zero
rational number. Equate coefficients of like power,
$$(x+x_1)(x+x_2)(x+x_3) = x (x+a) (x+b) +c,$$
after some algebraic manipulation we get:
$$
x_3^2  -  (a+b - x_1) x_3 + (a \cdot b - x_1 (a+b - x_1)) = 0
$$
Since $x_3$ is assumed to be rational, the discriminate must be rational
$$
r = \sqrt{(a+b - x_1)^2 - 4  (a \cdot b - x_1 (a+b - x_1))} 
$$
Assuming we can choose $a$, $b$ and $x_1$ such that $r$ is rational,
\begin{align*}
x_3 & = \frac{a + b - x_1 \pm r}{2} \\
x_2 &= a + b - x_1 - x_3 \\
c &= x_1 x_2 x_3 
\end{align*}
This meets all the requirements, if $x_1 \ne x_2 \ne x_3 \ne 0$. 
These conditions can be written as
\begin{align*}
r &\ne 0 \\
x_1 & \ne \frac{a+b\pm r}{3} \\
x_1 &\ne a+b\pm r \\
\end{align*} So the problem is equivalent to finding all $a$, $b$ and $x_1$ such that $r$ is rational and
the 3 conditions are met. But I cannot show if such an $r$ exists, or if does,
enumerate some values of $a$, $b$, and $x_1$, let alone all of them. Edit: corrected an algebraic  mistake.",['number-theory']
615505,Help finding the $\lim\limits_{x \to \infty} \frac{\sqrt[3]{x} - \sqrt[5]{x}}{\sqrt[3]{x} + \sqrt[5]{x}}$,"I need help finding the $$\lim_{x \to \infty} \frac{\sqrt[3]{x} - \sqrt[5]{x}}{\sqrt[3]{x} + \sqrt[5]{x}}$$ I did the following: $$\begin{align*}
\lim_{x \to \infty} \frac{\sqrt[3]{x} - \sqrt[5]{x}}{\sqrt[3]{x} + \sqrt[5]{x}}
=& \lim_{x \to \infty} \frac{(\sqrt[3]{x} - \sqrt[5]{x})(\sqrt[3]{x} + \sqrt[5]{x})}{(\sqrt[3]{x} + \sqrt[5]{x})(\sqrt[3]{x} + \sqrt[5]{x})}\\
\\
=& \lim_{x \to \infty} \frac{(\sqrt[3]{x})^2 - (\sqrt[5]{x})^2}{(\sqrt[3]{x})^2+2\sqrt[3]{x}\sqrt[5]{x}+(\sqrt[3]{x})^2}\\
\\
=& \lim_{x \to \infty} \frac{x^{2/3}-x^{2/5}}{x^{2/3}+2x^{1/15}+x^{2/5}}\\
\\
=& \lim_{x \to \infty} \frac{x^{4/15}}{2x^{17/15}}
\end{align*}$$ Somehow I get stuck. I am sure I did something wrong somewhere.. Can someone please help me out?","['radicals', 'calculus', 'limits']"
615534,"Let $x$ be in the set of real numbers $\mathbb{R}$ and let $f(x)=|2x-1|-3|2x+4|+7$ be a function, write $f(x)$ without the absolute value.","Let $x$ be in the set of real numbers $\mathbb{R}$ and let $f(x)=|2x-1|-3|2x+4|+7$ be a function, write $f(x)$ without the absolute value. I thought of it this way: $$f(x)=\begin{cases}2x-1-3(2x+4)+7 \,(\text{then I simplify)} & \text{if $x>0$}\\
-(2x-1-3(2x+4)+7)\,(\text{then I simplify)} & \text{if $x\le0$}\end{cases}$$ But is there some way without having to use the cases? Edit: NEW work on this problem! I found three cases; If $x\in ]-\infty,-2]$ then f(x)=$4x+20$ If $x\in]-2,1/2]$ then f(x)=$-8x-4$ If $x\in]1/2,+\infty[$ then f(x)=$-4x-6$ IS THIS TRUE? Thank you very much!","['absolute-value', 'functions']"
615548,Differentiability of a certain piecewise function,"Consider the function
$$
f(x)=\begin{cases}
x & \textrm{if } x \textrm{ is rational} \\
-x & \textrm{if } x \textrm{ is irrational}
\end{cases}
$$
It is well-known that $f(x)$ is continuous at $x=0$, and discontinuous everywhere else. Now, let's consider the modified function:
$$
g(x)=\begin{cases}
x^3 & \textrm{if } x \textrm{ is rational} \\
-x^3 & \textrm{if } x \textrm{ is irrational}
\end{cases}
$$
Then, $g(x)$ will be again continuous at $x=0$. But I am wondering: Is $g(x)$ differentiable at $x=0$? I think the answer might be 'yes', because by introducing the higher power $x^3$, we have ""smoothed out"" the behaviour of the function around the origin. On the other hand, the function looks too pathological to admit any points of differentiability.","['functions', 'continuity', 'examples-counterexamples', 'real-analysis']"
615577,"Ring epimorphism $f:R\rightarrow S$, $R$ has finitely many maximal ideals, then $f(J(R))=J(S)$.","Suppose $R$ and $S$ are commutative rings with unit, and $f:R\rightarrow S$ is an epimorphism. Prove that: $$f(J(R))\subseteq  J(S).$$ If $R$ has finitely many maximal ideals, then prove that:  $$f(J(R))=J(S).$$ I know how to show that $f(J(R))\subseteq  J(S)$ but for the inverse I don't know what should I do, so please help me. Recall that $J(R)$  is Jacobson radical of $R$.","['commutative-algebra', 'abstract-algebra']"
615579,Largest infinite cardinal used in a proof,"I've heard before that Knuth holds the record for the largest constant used in a mathematical proof. I was wondering what is the largest cardinal ever explicitly considered in set theory. I presume this will depend on the axioms chosen, but I'd be interested to know what's the 'largest infinity conceived by man'.","['infinity', 'cardinals', 'elementary-set-theory', 'soft-question']"
615581,"Intuition & Proof of rank(AB) $\le$ min{rank(A), rank(B)} (without inverses or maps) [Poole P217 3.6.59, 60]","I'm aware of analogous threads; I hope that mine is specific enough not to be esteemed one. $\mathbf{a^i}$ is a row vector. $A, B$ are matrices. Prove: $1$. $\mathbf{a^i}B$ is a linear combination of the rows of $B$. $2.$ Row space of $AB \subseteq$ row space of $B$. $\qquad$ $3.$ Column space of $AB \subseteq$ Column space of $A$. $4.$ If $\mathbf{a_i}$ is a column vector, then  $A\mathbf{a_i}$ is a linear combination of the columns of $A$. $5. \operatorname{rank}(A\color{#B8860B}{B}) \color{#B8860B}{\le} \operatorname{rank}\color{#B8860B}{B}  \qquad \qquad$ $6.\operatorname{rank}(AB) \leq \operatorname{rank} A$. In general, $x \leq a \text{ & } x \le b \implies x \le \min\{a, b\}$. So by $5 \, \& \, 6$, $\operatorname{rank}(AB) \leq \min\{\operatorname{rank}A,\operatorname{rank} B\}$. $\bbox[2px,border:2px solid grey]{\text{ Proof of #5 :}} \;$ The rank of a matrix is the dimension of its row space. Need to show : If $\operatorname{rowsp}(AB) \subseteq\operatorname{rowsp}(B)$, then $\operatorname{dim rowspace}(AB) \le \operatorname{dim rowspace}(B). $ Pick a basis for $\operatorname{rowsp}(AB)$. Say there are $p$ vectors in this basis. By $\#2$, row space of $AB \subseteq$ row space of $B$, $\color{green}{\text{so all of these $p$ vectors also $\in \operatorname{rowsp}(B)$}}$. Moreover, they must be linearly independent (hereafter dubbed l-ind). ${\Large{\color{red}{[}}} \;$
   Since the dimension of a space $=$ the maximum number of l-ind vectors in that space, 
  $\; {\Large{{\color{red}{]}}}}$ and $\color{green}{\text{$\operatorname{rowsp}(B)$ has $\ge p$ l-ind vectors}}$, thus $ \operatorname{dim rowspace}(B) \; \ge \; \operatorname{dim rowspace}(AB) = p. $ $\bbox[2px,border:2px solid grey]{\text{ Proof of #6 :}} \;$ Apply $ \operatorname{rank}M = \operatorname{rank}M^T$ and $\#5$: $ 
\operatorname{rank}(AB)^T = \operatorname{rank}(B^T\color{#B8860B}{A^T}) \quad \color{#B8860B}{\le} \quad \operatorname{rank}\color{#B8860B}{A^T} = \operatorname{rank}(A)$. $Q1.$ Please elucidate the above proof of $5$? I'm bewildered. What's the strategy? $Q2.$ On P209, Poole defines dimension as the number of vectors in a basis. So shouldn't the red bracket refer to a basis? If so, why doesn't the proof simply declare: By $2$, the basis for $\operatorname{rowsp}(AB)$ can be reused as a basis for $\operatorname{rowsp}(B).$ ? $Q3.$ How'd one previse to invert $AB$ and apply $\#5$ (the key strategem) for #6? $Q4.$ What's the intuition behind results $5$ and $6$? I'd be grateful for pictures. Sources: P147, 4.48, Schaum's Outline to Lin Alg , web.mit.edu/18.06/www/Spring01/Sol-S01-5.ps","['matrix-rank', 'matrices', 'linear-algebra', 'visualization', 'intuition']"
615582,$A\subset \mathbb{R}$ with more than one element and $A/ \{a\}$ is compact for a fixed $a\in A$,"Question is : Suppose $A\subset \mathbb{R}$ with more than one element and $A/ \{a\}$ is compact for a fixed $a\in A$ then $A$ is compact Every subset of $A$ must be compact $A$ must be finite $A$ is disconnected Only compact subsets of $\mathbb{R}$ I can think of are finite union of closed intervals and finite sets. Take a  finite union of closed intervals, If i remove one element for that I would end up with something which contains $[a,b)$  and this would be not compact so should be the whole set. So, First option is wrong i.e., $A$ is not compact. I can not say anything about second and fourth option but third option is possible I guess. Please help me to see this in detail..",['general-topology']
615586,Recurrence relation $f(n)=5f(n/2)-6f(n/4) + n$,"I have been trying to solve this recurrence relation for a week, but I haven't come up with a solution. $$f(n)=5f\left(\frac n2\right)-6f\left(\frac n4\right) + n$$ Solve this recurrence relation for $f(1)=2$ and $f(2)=1$ At first seen it looks like a divide and conquer equation, but the $6f(n/4)$ confuses me. Please help me find a solution.
Kind regards.","['recurrence-relations', 'discrete-mathematics', 'sequences-and-series', 'analysis']"
615604,"No field extension is ""degree 4 away from an algebraic closure""","Question: Suppose $[L:K]=4$ , $\operatorname{char}K \neq 2$ and $L$ is algebraically closed. Show that there is an intermediate field $M$ such that $[L:M]=2$ and $X^2 + 1$ splits over $M$ . Show that this leads to a contradiction. I have successfully found such $M$ . Would somebody please give me some hints to the last part?","['galois-theory', 'abstract-algebra', 'field-theory']"
615614,Non-integral powers of a matrix,"Question Given a square complex matrix $A$, what ways are there to define and compute $A^p$ for non-integral scalar exponents $p\in\mathbb R$, and for what matrices do they work? My thoughts Integral exponents Defining $A^k$ for $k\in\mathbb N$ is easy in terms of repeated multiplication, and works for every matrix. This includes $A^0=I$. Using $A^{-1}$ as the inverse, $A^{-k}=\left(A^{-1}\right)^k$ is easy to define, but requires the matrix to be invertible. So much for integral exponents. Rational definition I guess for a rational exponent, one could define $$A^{\frac pq}=B\quad:\Leftrightarrow\quad A^p=B^q$$ This will allow for more than one solution, and I'm not sure if the computations I'll describe below will find all solutions satisfying the above equation. So I'm not sure whether that's a reasonable definition. For non-rational exponents, a limit using a convergent series of rational exponents might work. Diagonalizable computation If $A$ is diagonalizable , then one has $A=W\,D\,W^{-1}$ for some diagonal matrix $D$. One can simply raise all the diagonal elements to the $p$-th power, obtaining a matrix which will satisfy the above equation. For each diagonal element, I'd define $\lambda^p=e^{(p\ln\lambda)}$, and since $\ln\lambda$ is only defined up to $2\pi i\mathbb Z$, this allows for multiple possible solutions. If one requires $-\pi<\operatorname{Im}(\ln\lambda)\le\pi$, then the solution should be well defined, and I guess this definition even has a name, although I don't know it. Non-diagonalizable computation If $A$ is not diagonalizable, then there is still a Jordan normal form , so instead of raising diagonal elements to a fractional power, one could attempt to do the same with Jordan blocks. Unless I made a mistake, this appears to be possible. At least for my example of a $3\times3$ Jordan block, I was able to obtain a $k$-th root. $$
\begin{pmatrix}
\lambda^{\frac1k} & \tfrac1k\lambda^{\frac1k-1} & \tfrac{1-k}{2k^2}\lambda^{\frac1k-2} & \\
0 & \lambda^{\frac1k} & \tfrac1k\lambda^{\frac1k-1} \\
0 & 0 & \lambda^{\frac1k}
\end{pmatrix}^k
=
\begin{pmatrix}
\lambda & 1 & 0 \\
0 & \lambda & 1 \\
0 & 0 & \lambda
\end{pmatrix}
$$ If the eigenvalue $\lambda$ of this block is zero, then the root as computed above would be the zero matrix, which doesn't result in a Jordan block. But otherwise it should work. Conclusion Edited since this question was first asked. So it seems that every invertible matrix can be raised to every rational power, as long as uniqueness is not a strong requirement. A non-invertible matrix apparently can be raised to non-negative powers as long as all Jordan blocks for eigenvalue zero have size one. Is this true? If not, where is my mistake? If it is, is there a good reference for this?","['eigenvalues-eigenvectors', 'exponentiation', 'linear-algebra', 'jordan-normal-form', 'complex-numbers']"
615618,Probably Riemann surface integral,"Here is the integral: May you please suggest some beautiful idea on using Riemann surface, or some Gauss-Ostrogradsky at the beginning. Also, the initial integral looks really symmetric, so maybe there is some way to simplify form or switch to spherical coordinates... And here are steps which I performed by myself: By integrating over φ, this can be reduced to one variable integral: Now I switch to complex plane: Now poles (there are 4, all lying on real axis, 2 of them are inside contour |z|=1: And suddenly, here comes sensation that there is root of polynomial, so there is branching at this points. I've put this equation into Wolfram, but it returns something alienish: This integral on integrals.wolfram.com .
Maybe it is possible to calculate all that limits at points θ=0 and θ=π. But there will be no way to prove that Mathematica solution, which is necessary for me :( Thank you for your attention.","['improper-integrals', 'definite-integrals', 'riemann-surfaces', 'spherical-coordinates', 'complex-analysis']"
615634,P(R) is contained in Nil(R) for noncommutative rings.,How to show that $P(R)$ is contained in $\operatorname{Nil}(R)$ (where $R$ is a noncommutative ring with identity)? Definitions I am using: A nil right ideal is one whose elements are all nilpotent. A prime ideal is a two sided ideal which satisfies the property: $aRb$ contained in $I$ implies $a$ is in $I$ or $b$ is in $I$. $P(R)$ is the intersection of all prime ideals. $\operatorname{Nil}(R)$ is the sum of all right nil ideals of $R$.,"['noncommutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
615639,Green function of the first quadrant,"Find the Green function of the first quadrant $x_1>0, x_2>0$ . HINT: Use the Green function of the half space $\Omega:=\left\{x\in\mathbb{R}^n : x_n > 0\right\}$ which is given by \begin{align*}
G_n(x,y)&:=E_n(x_1-y_1,\cdots,x_{n-1}-y_{n-1},x_n-y_n)\\
&\quad\ -E_n(x_1-y_1,\cdots,x_{n-1}-y_{n-1},x_n+y_n).
\end{align*} How I can find the Green function of the first quadrant? The difference to the half space is that I have another boundary…","['multivariable-calculus', 'potential-theory']"
615652,Should diffeomorphisms preserving arc length be affine?,"Problem Suppose $\varphi\colon V=\mathbb R^n\to V$ be a differmorphism and $d\varphi$ is its tangent mapping. $\langle\circ,\circ\rangle$ is a nondegenerate (symmetric or symplectic ) bilinear form on $V$. If $d\varphi$ preserves the scalar product everywhere, i.e. $\langle u,v\rangle=\langle d\varphi_x(u),d\varphi_x(v)\rangle$ for all $x\in V$ and $u,v\in V$ (identify $T_xV$ with $V$), should $\varphi$ be affine? Thoughts Suppose $\langle\circ,\circ\rangle$ is an inner-product, the result seems true, for it's not hard to show that $\varphi$ preserves arc length by curvilinear integral, then if $l_{pq}$ is the segment connecting $p$ and $q$ of the minimal distance, then $\varphi(l_{pq})$ connects $\varphi(p)$ and $\varphi(q)$ of the minimal distance, hence $l_{\varphi(p)\varphi(q)}$. Backgrounds The problem arises from the twin paradox in special relativity. The frame of reference of the traveling twin isn't inertial therefore isn't equivalent to the inertial frame of reference on earth, thus the time dilation argument is nonsense. Mathematically, if the coordinate system of the spacetime in which the frame of reference isn't inertial, we cannot determine the proper time of a world line naïvely from integrating $c^{-1}ds=\sqrt{dt^2-c^{-2}(x^2+y^2+z^2)}$ in the new coordinate system, i.e, the arc length of the world line isn't preserved under the coordinate transformation. Any idea? Thanks! Edit The symplectic case is already disproved by Seub.","['quadratic-forms', 'physics', 'symplectic-geometry', 'differential-geometry']"
615658,Why are these line bundles isomorphic? [modified],"Reading a book I met the following claim, and I don't understand how to justify it. [Actually I misunderstood the claim, below is the corrected version of it] Let $X$ be a variety and $E\subset X$ a divisor. Suppose we have a global section
$$ s: \mathcal{O}_X\to \mathcal{O}_X(E) $$
such that the vanishing locus of $s$ is a divisor $D\subset X$, and that $s$ vanishes of order $1$ there. Under these assumptions, it follows that $L(D)$ and $L(E)$ are isomorphic. Why is this the case?",['algebraic-geometry']
615666,Diagonalization and eigenvalues [duplicate],"This question already has an answer here : a linear algebra multiple choice problem (1 answer) Closed 6 years ago . Let $A$ $\in M_3(\mathbb R)$ which is not a diagonal matrix. Pick out the cases when
$A$ is diagonalizable over $\mathbb R$: a. when $A^2 = A$; b. when $(A - 3I)^2 = 0$; c. when $A^2 + I = 0$. I could eliminate c. by using the equation $\lambda^2+1$ and showing if a matrix has to satisfy this then it has to be diagonal. I am also in doubt whether all the eigen values of $A$ satisfy this or not.","['matrices', 'linear-algebra']"
615695,How to calculate the following sum:,"How may one calculate 
$$\lim_{n\to\infty} \ \left(\left(\sum_{k=1}^{n} \frac{1}{3k-1}\right) - \frac{\ln n}{3}\right) \ ?$$","['sequences-and-series', 'limits']"
615709,Is the set of closed points of a $k$-scheme of finite type dense?,"Let $k$ be a field.
Let $X$ be a scheme of finite type over $k$.
We denote by $X_0$ the set of closed points of $X$.
Is $X_0$ dense in $X$? Motivation See my comment to Martin Brandenburg's answer to this question .",['algebraic-geometry']
615713,Definite integral $\int_0^{2\pi}\frac{ab}{\sqrt{b^2\cos^2(\theta)+a^2\sin^2(\theta))}}\cos^2(\theta) d\theta$,"Could you help me finding the following definite integral, with $a$ and $b$ constants?  Thank you! $$\int_0^{2\pi}\frac{ab}{\sqrt{b^2\cos^2(\theta)+a^2\sin^2(\theta))}}\cos^2(\theta) d\theta$$","['calculus', 'integration']"
615722,Good textbook on geometries,"I am looking for a good textbook that thoroughly covers euclidean, affine, projective and non-euclidean geometries. I will be starting graduate school in algebraic geometry next year and I would like to get a better geometric intuition and understanding of the problems that led from one geometry to another (the motivating ideas) before getting deep into purely algebraic theories and forgetting the geometry behind. I have heard of the following books, though I am not sure which one would fulfill my purpose the best: Geometry by Brannan - It covers many geometries, though from the commentaries, it seems to be very basic. Geometry: Euclid and Beyond by Hartshorne - It is written by Hartshorne, who is a famous algebraic geometer, but the book does not seem to cover projective geometry. (Perhaps because Hartshorne has also written a book on the subject alone.) Geometry: A Comprehensive Course by Pedoe - It contains an introductory chapter on algebraic geometry, but doesn't cover Poincaré's upper half-plane model of hyperbolic geometry. Geometries by Sossinsky - It covers many different geometries and seems to use a strong algebraic approach, but I am not sure if it is very thorough in projective geometry based on the number of pages on the subject. Of course, if you have any other recommendations, please tell me!
Thank you!","['geometry', 'algebraic-geometry', 'projective-geometry', 'affine-geometry', 'reference-request']"
615727,Discretize differential equation by finite differences. What is the matrix?,"I have a differential equation:
$$ -u''(x) + \sigma u'(x) = f(x), \quad 0<x<1$$ with boundary conditions $u(0) = \alpha$ and $u(1) = \beta$.
I've discretized equation using symmetric (finite) differences:
$$ \frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2} + \sigma \frac{u_{i+1} - u_i}{h} = f_i $$
If $n$ is the number of discretization points,  $h = \frac{1}{n+1}$. My question is how would I get that in a matrix form $Ax = f$ ?","['ordinary-differential-equations', 'numerical-methods']"
615753,What values can $v-e+f$ attain if $G$ is a planar (non connected) graph?,"Let $G=(V,E)$ be a planar graph and choose planar representation. If $G$ is connected, then according to Euler's formula , we have $$v − e + f = 2,$$ were $v$ is the number of vertices, $e$ the number of edges and $f$ the number of regions bounded by edges, including the outer, infinitely large region. I was wondering which values $v-e+f$ can assume if $G$ is planar, but not connected. After some drawing, I feel that it can be any integer larges than 1, but I cannot prove it. Is there someone who can help me out?","['geometry', 'graph-theory']"
615755,Nodes of eigenfunctions and Courant's nodal domain theorem,"I am looking for a reference for properties of eigenfunctions of the Laplacian (on the Euclidean plane, and maybe also Laplace-Beltrami on a general manifold): The discreteness of the set of eigenvalues, Nodes of eigenfunctions, Courant's nodal domain theorem, The Faber-Krahn inequality, and other related results. I have tried Methods of Mathematical Physics (Courant, Hilbert) but it contains only some of the above, is quite old and a bit hard to read.","['reference-request', 'partial-differential-equations', 'analysis']"
615810,how many $1$s in the first n digits of $\pi$?,how many $1$s are there in the first n digits of $\pi$? Any good approximation of its distribution? How about the place of the $n$th $1$? Are these two questions related?,"['number-theory', 'soft-question', 'combinatorics']"
615842,Map $\{x+iy \mid x^2+y^2<1 \text{ and } x^2 + (y-1)^2<2\}$ conformally to UHP,"From an old qualifying exam: Let $D$ be the domain $$D :=\{x+iy \mid x^2+y^2<1 \text{ and } x^2 +
(y-1)^2<2\}.$$ Map the domain onto the upper half-plane. Obtain a function $f(z)$ analytic in the domain $D' := D \cap \{x+iy    \mid x>0\}$ and which takes on the boundary values
  $\text{Re}f(z) =    -1$ on the segment of the imaginary axis $-1<y<1$,
  and $2$ on the bounding circular arcs in $D'$, excluding the points
  $z=i$ and    $z=i-\sqrt{2}i$. Further $\text{Im}f(0)=0$. Is $f(z)$
  unique? (For the first, I have to assume they want a conformal mapping, but they did not indicate it...go figure. For the second, one of the arcs is not ""circular"", but I guess I know what they mean.) Let's focus on the first part for now; maybe if I get that I can get the second part. I have struggled to come up with some ideas for the first one. I don't know of any results about conformal mapping and parabolae. Maybe I should look at the polar form of a parabola?","['conformal-geometry', 'complex-analysis']"
615850,Hartogs space of $\mathbb{N}$,Suppose : $U=\chi(\mathbb{N})$ is the Hartogs space of $\mathbb{N}$. $(M_a)_{a\in U}$ a family of infinite subsets of $\mathbb{N}$ such that $a<b \rightarrow  M_b\subseteq M_a$. I'm trying (without any luck) to prove that there exists $a_0\in U$ such that for all $a\geq a_0 \rightarrow M_a=M_{a_0}$. Hartogs space of a set A is: A well ordered space $\chi(A)$ such that : $\chi(A)\nleq_c A$ $\chi(A)$ is the least set with that property (if $W$ is a well ordered set such that $W\nleq_c A$ then $\chi(A)\leq_0 W$). $A\leq_c B$ if the cardinality of the set B is greater than or equal to the cardinality of A. $\chi(A)\leq_0 W$ if $X(A)$ is an initial segment of $W$ that is there exists $w\in W$ such that $X(A)=_0 \{y\in W|y<w\}$ Thank you in advance for your time and effort.,['elementary-set-theory']
615860,Maximum of $|(z-a_1)\cdots(z-a_n)|$ on the unit circle,"Let $a_1,\ldots,a_n$ be points on the unit circle. Let $P(z)=(z-a_1)\cdots(z-a_n)$. The maximum principle or Rouche's theorem can be used to show that there exists a point $b$ on the unit circle such that $|P(b)|\geq1$. Question: What is the maximum value $c$ such that there always exists a point $b$ on the unit circle such that $|P(b)|\geq c$, regardless of what $a_1,\ldots,a_n$ are?","['complex-numbers', 'inequality', 'complex-analysis']"
615862,Was Fermat's last theorem proved based on Peano's postulates?,"Is the proof of Fermat's last theorem solely based on the Peano's postulates $+$ first order logic? Or it contains other axiomatic systems as well? What does it mean from foundations of math perspective to use several axiomatic systems to prove a conjecture? Do we know these axiomatic systems are consistent with one another? I'm not sure if I am asking it the right way, but I think logicians only prove the consistency of the axioms of one system not two different systems.","['logic', 'foundations', 'soft-question', 'number-theory']"
615867,Finite order function in the complex analysis.,"Assume that an entire function $f$ be finite order with finitely many zeros. Please show that either $f(z)$ is a polynomial or $f(z) + z$ has infinitely many zeros. Thank you. And I know the following theorem, Suppose f is entire function of finite order. Then either f has infinitely many zeros or $f(z)$ is of the form $Q(z)e^{P(z)}$ for polynomials $P$ and $Q$.","['harmonic-functions', 'self-learning', 'complex-analysis', 'analysis']"
615901,Intersection of Trig Functions,"The questions asks to find the intersections of $$f(x) = 2 \sin(x-7) + 6$$ and $$g(x) = \cos(2x-10) + 8$$ within the interval $[6,14]$. So my general strategy was, 1) equate the functions, 2) get all the $X$s on one side and 3) convert to the same trig function. So $$2 \sin(x-7) + 6 = \cos(2x-10) + 8$$ I recognized the double angle in the cosine function, so $$2 \sin(x-7) + 6 = \cos[ 2 (x-5) ] + 8$$ then $$2 \sin(x-7) + 6 = \cos^2(x-5) - \sin^2(x-5) + 8$$ $\cos^2$ can be replaced with an identity, so $$2 \sin(x-7) + 6 = 1 - \sin^2(x-5) - \sin^2(x-5) + 8$$ Group like terms and move then around, $$2 \sin(x-7) + 2 \sin^2(x-5) = 3$$ Extracting the $2$ from the left side. $$\sin(x-7) + \sin^2(x-5) = \frac 3 2$$ So here is where I hit a mental wall. I could use the sine addition formula, but that would reintroduce cosine. I can't simplify the terms any further since the angles are different. Where would I go from here? Or is my approach off completely?",['trigonometry']
615905,Finishing proof of identity $\sum_{k=b}^{n} \binom{n}{k} \binom{k}{b} = 2^{n-b} \binom{n}{b}$,"The identity $$
\sum_{k=b}^{n} \binom{n}{k} \binom{k}{b} = 2^{n-b} \binom{n}{b}\
$$ is one of a few combinatorial identities I having been trying to prove, and it has taken me way too long. I am using the principles most familiar to me (which are algebra, some basic combinatorial identities, but not applying differentiation or proof by bijection ). First I tried to see whether finding an identity for $\sum\limits_{k=0}^n \binom{n}{k}$ leads anywhere. $$\begin{align}
&\sum_{k=0}^{n} \binom{n}{k} = \sum_{0 \le k \lt b} \binom{n}{k} + \sum_{b \lt k \lt n}  \binom{n}{k} \tag{1} \\
\\
\end{align}$$ But it didn't for me, so I started over and next tried $$\begin{align}
&\sum_{k=b}^{n} \binom{n}{k} \binom{k}{b} = \sum_{k=b}^{n} \left( \frac{n!}{k! (n-k)! } \right) \left( \frac{k!}{(k-b)!} \right)  \tag{2} \\
\\
\end{align}$$ but this also fell short of a proof. It is really hard for me to step away from the problem. I was just hoping for a really a big hint on how to proceed.","['calculus', 'binomial-theorem', 'summation', 'binomial-coefficients', 'combinatorics']"
615912,Is there a combinatoric identity for the multiplicities of the following set?,"Are you ready for some psychedelic pictures? Define the multiset$$S_n=\left\{\sum_{j=1}^n(-1)^{\left\lfloor(k-1)/2^{j-1}\right\rfloor}u_n^j\mbox{ for }1\leq k\leq2^n\right\}$$
where $$u_n^j=\left(\begin{array}{cc}
\\ \mbox{Cos}\left(\frac{2\pi j}{n}\right)
\\ \mbox{Sin}\left(\frac{2\pi j}{n}\right)
\end{array}\right)$$
is the unit vector pointing in the $2\pi j/n$-direction. Here is a picture of $S_0$: Here is a picture of $S_1$: Here is a picture of $S_2$: Here is a picture of $S_3$: Here is a picture of $S_4$: Here is a picture of $S_5$: Here is a picture of $S_6$: Here is a picture of $S_7$: Here is a picture of $S_8$: Here is a picture of $S_9$: Here is a link to a 1761 x 1761 pixel version . Here is a picture of $S_{10}$: Here is a link to a 1941 x 1941 pixel version . Here is a picture of $S_{11}$: Here is a link to a 3432 x 3432 pixel version . Here is a picture of $S_{12}$: Here is a link to a 3048 x 3048 pixel version . Here is a picture of $S_{13}$: Here is a link to a 6683 x 6683 pixel version . Here is a picture of $S_{14}$: Here is a link to a 4317 x 4317 pixel version . Here is a picture of $S_{15}$: Here is a link to a 7638 x 7638 pixel version . Here is a picture of $S_{16}$: Here is a link to a 7946 x 7946 pixel version . The preceding pictures were obtained by placing a 2D Lorentzian function at the coordinates specified by each element of $S_k$. Because some points occur multiple times in $S_k$, some of the light sources are brighter than others, with bright points being high degeneracy, and dim points being low degeneracy. This naturally brings about the question: What is the distribution of point brightnesses in the preceding photographs? To get a start, I computed the degeneracy of each vector in $S_n$ for $0\leq n \leq 15$, and then histogrammed the degeneracies (ie, $\mbox{Tally[Tally[}S_n\mbox{][[All,2]]]}$ in Mathematica notation), which yielded the following results:
$$\left(
\begin{array}{cc}
 n\text{ = 0} & \left(
\begin{array}{cc}
 1 & 1 \\
\end{array}
\right) \\
 n\text{ = 1} & \left(
\begin{array}{cc}
 1 & 2 \\
\end{array}
\right) \\
 n\text{ = 2} & \left(
\begin{array}{cc}
 1 & 2 \\
 2 & 1 \\
\end{array}
\right) \\
 n\text{ = 3} & \left(
\begin{array}{cc}
 1 & 6 \\
 2 & 1 \\
\end{array}
\right) \\
 n\text{ = 4} & \left(
\begin{array}{cc}
 1 & 4 \\
 2 & 4 \\
 4 & 1 \\
\end{array}
\right) \\
 n\text{ = 5} & \left(
\begin{array}{cc}
 1 & 30 \\
 2 & 1 \\
\end{array}
\right) \\
 n\text{ = 6} & \left(
\begin{array}{cc}
 1 & 6 \\
 2 & 6 \\
 6 & 6 \\
 10 & 1 \\
\end{array}
\right) \\
 n\text{ = 7} & \left(
\begin{array}{cc}
 1 & 126 \\
 2 & 1 \\
\end{array}
\right) \\
 n\text{ = 8} & \left(
\begin{array}{cc}
 1 & 16 \\
 2 & 32 \\
 4 & 24 \\
 8 & 8 \\
 16 & 1 \\
\end{array}
\right) \\
 n\text{ = 9} & \left(
\begin{array}{cc}
 1 & 216 \\
 2 & 108 \\
 4 & 18 \\
 8 & 1 \\
\end{array}
\right) \\
 n\text{ = 10} & \left(
\begin{array}{cc}
 1 & 30 \\
 2 & 70 \\
 4 & 60 \\
 8 & 20 \\
 12 & 20 \\
 18 & 10 \\
 34 & 1 \\
\end{array}
\right) \\
 n\text{ = 11} & \left(
\begin{array}{cc}
 1 & 2046 \\
 2 & 1 \\
\end{array}
\right) \\
 n\text{ = 12} & \left(
\begin{array}{cc}
 1 & 36 \\
 2 & 72 \\
 4 & 36 \\
 6 & 72 \\
 10 & 12 \\
 12 & 72 \\
 20 & 12 \\
 36 & 36 \\
 60 & 12 \\
 100 & 1 \\
\end{array}
\right) \\
 n\text{ = 13} & \left(
\begin{array}{cc}
 1 & 8190 \\
 2 & 1 \\
\end{array}
\right) \\
 n\text{ = 14} & \left(
\begin{array}{cc}
 1 & 126 \\
 2 & 434 \\
 4 & 630 \\
 8 & 490 \\
 16 & 210 \\
 24 & 70 \\
 32 & 42 \\
 36 & 42 \\
 66 & 14 \\
 130 & 1 \\
\end{array}
\right) \\
 n\text{ = 15} & \left(
\begin{array}{cc}
 1 & 6510 \\
 2 & 4620 \\
 3 & 420 \\
 4 & 1380 \\
 5 & 360 \\
 6 & 360 \\
 8 & 60 \\
 9 & 120 \\
 10 & 180 \\
 12 & 120 \\
 14 & 60 \\
 20 & 30 \\
 38 & 1 \\
\end{array}
\right) \\
\end{array}
\right)$$
As an example of the notation above, for $n=15$, there were 6510 points of brightness 1, 4620 points of brightness 2, ..., and 1 point of brightness 38. I tried searching the Sloane OEIS database for the columns of these finite integer sequences to see if they formed the beginning of any sequences, but found no obvious matches. Question: Has anyone ever seen these sequences before? And is there a combinatorial method to determine the multiplicity of an arbitrary element of $S_n$? A bit of background: One can show with a little geometry that the vector elements of $S_n$ and their multiplicities are actually the locations and brightnesses of the maxima of the following bivariate function:
$$f_n(k_1,k_2)=\left|\int_{-\infty}^\infty dx\int_{-\infty}^\infty dy\mbox{ }e^{2\pi i(k_1x+k_2y)}\prod_{j=1}^ng\left[(1,0)\cdot
R\left(\frac{2\pi j}{n}\right)\cdot(x,y)\right]\mbox{Cos}\left[(1,0)\cdot
R\left(\frac{2\pi j}{n}\right)\cdot(x,y)
\right]\right|$$
where $g$ is any slowly-varying ""structure factor"" function and $R(\theta)$ is the rotation matrix of angle $\theta$. For example, here is a plot of $\sqrt{f_{11}(k_1,k_2)}$: A larger and much more beautiful 2000 x 2000 pixel version is available here . The above image is essentially $S_{11}$, but convolved with the Fourier transform of the structure factor (I used $g$ to be a shifted Heaviside theta function $g(x)=\theta(c-x)$). The brightness channels of the image are saturated to show the finer details of the set. One can also make additional interesting pictures by replacing $\mbox{Cos}\left[(1,0)\cdot
R\left(\frac{2\pi j}{n}\right)\cdot(x,y)
\right]$ with more complicated frequency-modulated functions like  $\mbox{Cos}\left[z\mbox{ }\mbox{Cos}\left[(1,0)\cdot
R\left(\frac{2\pi j}{n}\right)\cdot(x,y)
\right]\right]$, which according to the Jacobi-Anger expansion will generate higher-order Bessel-weighted harmonics of the lattice, such as shown in the following image of $S_5$: The image has been computed using an FFT which was purposefully chosen to Nyquist alias the higher harmonics of $S_5$ into the picture frame, generating the constellation-like pattern seen there. Here is a slightly-larger 1000 x 1000 pixel version . And here's another interesting one, which I can't remember how I made, but which might not actually be a picture of an $S_n$ (I was doing random things at the time): A 2000 x 2000 pixel version is available here . I hope someone finds the posted images as beautiful as I find them, even if a combinatoric solution is not available! :)","['fourier-analysis', 'combinatorics']"
615925,Who came up with the $\varepsilon$-$\delta$ definitions and the axioms in Real Analysis?,"I've seen a lot of definitions of notions like boundary points, accumulation points, continuity, etc, and axioms for the set of the real numbers. But I have a hard time accepting these as ""true"" definitions or acceptable axioms and because of this it's awfully hard to believe that I can ""prove"" anything from them. It feels like I can create a close approximation to things found in calculus, but it feels like I'm constructing a forgery rather than proving. What I'm looking for is a way to discover these things on my own rather than have someone tell them to me. For instance, if I want to derive the area of a circle and I know the definition of $\pi$ and an integral, I can figure it out.","['calculus', 'math-history', 'soft-question', 'real-analysis', 'analysis']"
