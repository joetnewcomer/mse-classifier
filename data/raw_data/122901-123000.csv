question_id,title,body,tags
1850433,Families as fibres of a morphism,"In both Algebraic Geometry by Hartshorne and Geometry of Schemes by Eisenbud and Harris, the authors describe the notion of a family of schemes as being the fibres of a morphism $f:X\to Y$. Or as Eisenbud/Harris put it $X$ can be loosely thought of as a family of schemes parametrized by the points in $Y$. I'm having a hard time seeing why this definition gives us the notion of parametrization. One would expect a parameter to be a member of the domain. But instead we have the parameter lying in the image scheme.","['schemes', 'algebraic-geometry']"
1850437,Proving Wilson's theorem,"Wilson's theorem: if $p$ is prime then $(p-1)! \equiv -1(mod$ $ p)$ Approach: 
$$(p-1)!=1*2*3*....*p-1$$ My teacher said in class that the gcd of every integer less than p and p is 1, so every integer has a multiplicative inverse $(mod$ $ p)$. He also said that the multiplicative inverses of each integer less than p is in the same set of integers less than p (This idea seems to be right, but does it have to be proven?). the multiplicative inverses of 1 and p-1 are self inverses (Drawing different mod grids, it looks like it's right, but again how is that true?). He concluded the following: $$1*(p-1)*(a_1a_1^{-1}*.....*a_{{p-3}/2}*{a_{{p-3}/2}}^{-1}) \equiv -1(mod\text{ } p)$$ So he is grouping all the elements with distinct multiplicative inverse. This makes sense because there are p-3 elements with distinct multiplicative inverses and p-3 is even, so we can group them in pairs. How do we know that one multiplicative inverse corresponds to just one number, so we can group them in such an easy way?.","['number-theory', 'elementary-number-theory']"
1850471,"Suppose that $(s_n)$ converges to $s$, $(t_n)$ converges to $t$, and $s_n \leq t_n \: \forall \: n$. Prove that $s \leq t$.","I'm stuck with the proof of the following: Suppose that $(s_n)$ converges to $s$, $(t_n)$ converges to $t$, and $s_n \leq t_n \: \forall \: n$. Prove that $s \leq t$. I've tried starting with $s_n \leq t_n \: \forall : n$ and the definitions of each limit (i.e. $|s_n - s| \leq \epsilon \: \forall \: n > N_1$), but I'm not really getting very far. Any help is appreciated!","['real-analysis', 'inequality', 'sequences-and-series', 'limits']"
1850542,When are embeddings into Euclidean space unique up to ambient isometry?,"Suppose I have a Riemannian smooth manifold $M$ and a smooth isometric embedding $M \hookrightarrow \mathbb{R}^n$.  Is this embedding necessarily unique up to some isometry of $\mathbb{R}^n$?  If not, is it possible to insert some extra conditions or structure to make this happen?","['riemannian-geometry', 'differential-geometry']"
1850562,"Differentiable, nonnegative derivative ae, nondecreasing?","I have been trying to prove or disprove:
Let $g$ be differentiable on the reals, have $g'(x)\geq 0$ except countably many values, then $g$ is non-decreasing. The main problem I face is that I don't have that $g'$ is continuous. Otherwise fundamental theorem of calculus $\int_a^b g'=g(b)-g(a)\geq 0$ will do the job nicely. I can't find counter examples either. Thanks for help!","['real-analysis', 'calculus', 'analysis']"
1850584,Image of circle under fractional linear transform increases in radius,"Let $\alpha,r\in\mathbb{R}$ with $r>0$ and $|\alpha|+r\le 1$, and consider the fractional linear transform
$$ f(z) = \frac{z-\alpha}{1-\alpha z}. $$
I would like to show the following: the circle in $C(\alpha,r)\subset\mathbb{C}$ centered at $\alpha$ with radius $r$ is mapped onto a circle of larger radius by $f$. My approach: Note that $f$ maps $[-1,1]$ into $[-1,1]$ with $f(-1)=-1$ and $f(1)=1$, and in particular it maps the line segment $[\alpha-r,\alpha+r]$ to some line segment $[f(\alpha-r),f(\alpha+r)]$ on the real line. Furthermore, the line segment $[\alpha-r,\alpha+r]$ is perpendicular to the boundary of $C(\alpha,r)$ at the intersection points $\alpha\pm r$, and since conformal maps preserve angles, the image of the line segment is also perpendicular to the boundary of $f(C(\alpha,r))$ at $f(\alpha\pm r)$. Thus, $[f(\alpha-r),f(\alpha+r)]$ is a diameter of the image of $f(C(\alpha,r))$, and so if $r'$ is the radius of the $f(C(\alpha,r))$, then $2r' = f(\alpha+r)-f(\alpha-r)$. Thus, we have
\begin{align} r' = \frac{1}{2}(f(\alpha+r)-f(\alpha-r)) &= \frac{1}{2}\left(\frac{\alpha+r-\alpha}{1-\alpha(\alpha+r)}-\frac{\alpha-r-\alpha}{1-\alpha(\alpha-r)}\right) \\
&=\frac{r}{2}\left(\frac{1}{1-\alpha^2-\alpha r}+\frac{1}{1-\alpha^2+\alpha r}\right) \\
&=r\left(\frac{(1-\alpha^2)}{(1-\alpha^2)^2-(\alpha r)^2}\right)
\end{align}
and hence
$$\frac{r}{r'} = \frac{(1-\alpha^2)^2-(\alpha r)^2}{1-\alpha^2}\le\frac{(1-\alpha^2)^2}{1-\alpha^2}\le 1\implies r'\ge r.$$ I would like to know if there is a simpler approach to show that the radius increases (since right now it appears just to be algebra magic), or if there is a non-rigorous but intuitive explanation for this effect. In particular, I'm wondering if this has anything to do with hyperbolic distances, given that hyperbolic distances are larger with respect to Euclidean ones near the boundary of the unit disk and smaller near the center.","['complex-analysis', 'mobius-transformation']"
1850609,Divergent Curves and Complete Manifolds,"I'm working on a problem in do Carmo's Riemannian geometry book (chapter 7, problem 5). He states that a divergent curve on a noncompact Riemannian manifold $M$ is a curve $\alpha: [0, \infty) \to M$ where given any compact $K \subset M$ we have there exists $T>0$ such that $\alpha(t) \not\in K$ for $t>T$.  Subsequently the length is defined in the usual sense for curves on a manifold: $$
L(\alpha) \;\; =\;\; \int_0^\infty ||\alpha'(t)|| dt.
$$ The problem I'm trying to prove is Prove that a noncompact manifold is complete if and only if every divergent curve has unbounded (i.e. infinite) length. The ""forwards"" direction of the proof is easy; I'm having trouble with the other direction.  If I assume that every divergent curve $\alpha$ has infinite length, how do I show completeness of the manifold?  I'm borrowing one strategy from MIT OCW but I don't totally agree with their proof.  They claim that we can start with some arbitrary geodesic $\gamma:[0,\epsilon) \to M$ and assume that such a geodesic cannot be extended to the interval $[0,\infty)$.  The set $R$ of points $x$ on which $\gamma$ can be extended to $[0,x)$ is nonempty and bounded above, thus let $s = \sup R$.  Define a re-parameterization $\alpha(t) = \gamma(s(1-e^{-t}))$, which is defined on $[0,\infty)$ but is of finite length.  If we can show that $\alpha$ is a divergent curve we are done. The problem I have with the proof in the link is that they claim that $\gamma$ approaches a point on the ""boundary"" of $M$, but I find this claim problematic since it's not clear how to define a boundary unless $M$ is embedded/immersed in some ambient space.  Ultimately I would like to show that $\alpha$ escapes every compact subset of $M$, but I'm starting to think this proof might be problematic. Can anyone suggest a way to amend the above proof as stated, or provide an alternate proof strategy?","['manifolds', 'riemannian-geometry', 'differential-geometry', 'geodesic']"
1850620,Laurent series of $\frac{1}{z^2(z-1)}$ when $0<\lvert z\rvert<1$,"$\frac{1}{z^2(z-1)} = -\left(\frac{1}{z}+\frac{1}{z^2}+\frac{1}{1-z}\right)$. I know that $\frac{1}{1-z}=\sum\limits_{n=0}^\infty z^n$, but what about the other two terms, should they be left as they are, since we can already think of $\frac{1}{z}$ and $\frac{1}{z^2}$ as Laurent series where $b_1 = 1$ in the first case, and the rest of $b_n=0$, and $b_2 = 1$ in the 2nd case, with all other $b_n=0$? Please let me know if there is a better way to find Laurent series.","['laurent-series', 'complex-analysis', 'sequences-and-series']"
1850662,Find $f(5)$ where $f$ satisfies $f(x)+f(1/(1-x))=x $,"Question: How do you Find $f(5)$ in which the function satisfies 
$$f(x)+f\left(\frac{1}{1-x}\right)=x $$
where $x\in\Bbb{R}$ and  $x\neq 0,1$? My steps: Step 1) Substitute $5$ into the equation to get: $$f(5)+f\left(\frac{1}{-4}\right)=5$$ But then I had gotten stuck there and I could not find $f(5)$ Please write detailed steps.","['algebra-precalculus', 'functional-equations']"
1850709,What is the rank of the matrix consisting of all permutations of one vector? [duplicate],"This question already has answers here : Subspace generated by permutations of a vector in a vector space (2 answers) Closed 7 years ago . Let $a=(a_1,...,a_n)^\top\in\mathbb{R}^n$ be a column vector and let $M_1,...,M_{n!}$ denote all $n\times n$ permutation matrices. When is the rank of the matrix that consists of all possible permutations of $a$:
$$ A=[M_1 a \,|\; ... \; |\, M_{n!} a]\in\mathbb{R}^{n\times n!} $$ 
equal to $n$?
Obviously, $rank(A)\le n$ and if all entries of $a$ are identical, then $rank(A)=1$. Moreover, if $A$ has rank $n$, then there exist two entries $i,j$ s.t. $a_i\not=a_j$. Is the converse statement also true?","['permutations', 'matrix-rank', 'linear-algebra']"
1850718,How can I prove that an ultrafilter induces a finitely additive measure?,"If $\mathcal{U}$ is an ultrafilter on a set $X$, it can be defined a function $\mu_{\mathcal{U}}\colon\mathcal{P}(X)\to\{0,1\}$ such that, for all $A\subseteq X$ it holds $\mu_{\mathcal{U}}(A)=1$ iff $A\in\mathcal{U}$. Are $\mu_{\mathcal{U}}(\emptyset)=0$ and finite additivity enough to prove that $\mu_{\mathcal{U}}$ is well-defined? Of course, given a subset $E$ of $X$, we can split $E$ into disjoint sets $E_1,\dots,E_n$.  If $\mu_{\mathcal{U}}(E)=1$, then exactly one $E_i$ belongs to $\mathcal{U}$, so $\mu_{\mathcal{U}}(E_1)+\dots+\mu_{\mathcal{U}}(E_n)=1$. If $\mu_{\mathcal{U}}(E)=0$, then none of the $E_i$'s belongs to $\mathcal{U}$, so $\mu_{\mathcal{U}}(E_1)+\dots+\mu_{\mathcal{U}}(E_n)=0$. Did I prove that $\mu_{\mathcal{U}}$ is actually a function, hence a finitely additive measure?","['filters', 'measure-theory', 'elementary-set-theory']"
1850799,What does it mean when the second derivative at a point is infinite?,What does it mean when the second derivative of a function at a certain point is infinite? What would be neat examples that illustrate what happens? When the first derivative is infinite you get a vertical slope. Does something similar happen with an infinite second derivative? In other words: can you see in $f(x)$ that $f''(x_{inf})\to\infty$?,"['derivatives', 'calculus']"
1850803,General guidelines to solve Mean Value Theorem problems,"I am wondering if there is a general guideline to solve this specific type of MVT problem. For the teachers: how do you explain to the students how to apply MVT for these two questions below? Question #1 Using $MVT$ prove that $$ e^{x} > 1+x $$ for all $x > 0$ Question #2 Using $MVT$ prove that $$\ln (1+x) < x$$ for all $x > 0$ For example, when dealing with Show that $$  x^3+e^x=0 $$ cannot have two zeros I find helpful to Find values for the function where $f_{x_1} < 0$ and $f_{x_2} > 0$, in this case for example $x_1 = -2$ and $x_2 = 1$ Show using the derivative that f'(x) is always positive (or negative, in another case) Do you have guidelines for the first two questions introduced?","['derivatives', 'calculus']"
1850830,Evaluating $\int_0^{\tfrac{\pi}{4}}\ln(\cos x-\sin x)\ln(\cos x) dx - \int_0^{\tfrac{\pi}{4}}\ln(\cos x+\sin x)\ln(\sin x)dx=\frac{G\ln 2}{2}$,"In order to compute, in an elementary way , $\displaystyle \int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$ (see Evaluating $\int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$ ) i need to show, in a simple way , that: $\displaystyle \int_0^{\tfrac{\pi}{4}}\ln(\cos x-\sin x)\ln(\cos x) dx - \int_0^{\tfrac{\pi}{4}}\ln(\cos x+\sin x)\ln(\sin x)dx=\dfrac{G\ln 2}{2}$ $G$ being the Catalan constant. The reason of my interest for this question is, if i am right , that this formula permits to find out a relation between integrals: $\displaystyle \int_0^1 \dfrac{\ln(1+x)\ln(1+x^2)}{1+x^2}dx$ $\displaystyle \int_0^1 \dfrac{\ln(1+x)^2}{1+x^2}dx$ $\displaystyle \int_0^{\tfrac{\pi}{4}}\big(\ln(\cos x)\big)^2 \dfrac{}{}dx$ and some constants.","['integration', 'definite-integrals']"
1850932,Complex integral with Residues Theorem,"I've been going crazy with this complex integral I have to estimate with the Residues Theorem. I'm obviously missing a sign or something else, but I fear I may be committing a conceptual mistake. $$\int_{0}^{\infty} \frac{\log x}{x^2-1} \mathrm{d}x$$ I choose to solve this integral by computing the following complex integral: \begin{align*}
\int_{\gamma} \frac{\log^2 z}{z^2-1}dz &= \lim_{\epsilon \to 0} \bigg{[} \int_{0}^{R} dx \frac{\log^2 (x+i\epsilon)}{(x+i\epsilon)^2-1}+\int_{R}^{0} dx \frac{\log^2 (x-i\epsilon)}{(x-i\epsilon)^2-1} \\
&+\int_{2\pi}^{0}d\theta i \epsilon e^{i\theta} \frac{\log^2 (\epsilon e^{i\theta})}{(\epsilon e^{i\theta})^2-1} +\int_{2\pi}^{0}d\theta i \epsilon e^{i\theta} \frac{\log^2 (1+\epsilon e^{i\theta})}{(1+\epsilon e^{i\theta})^2-1} \bigg{]} + \int_{\tilde \gamma}dz \frac{\log^2 z}{z^2-1}
\end{align*} Where $\gamma$ is the ""keyhole"" path, and $\tilde\gamma$ is the circle centered in $z=0$ with $R$ radius. If $R\rightarrow\infty$ , then: \begin{align*}
&=\int_{0}^{\infty} dz \frac{\log^2 (x)}{x^2-1}-\int_{0}^{\infty} dx \frac{(\log (x)+2\pi i)^2}{x^2-1} \\
&=-4\pi i \int_{0}^{\infty}dx\frac{\log (x)}{x^2-1}+ 4 \pi^2 \int_{0}^{\infty} dx \frac{1}{x^2-1}=-4\pi i \int_{0}^{\infty}dx\frac{\log (x)}{x^2-1}
\end{align*} since $$\int_{0}^{\infty}\frac{1}{x^2-1}\mathrm{d}x  = 0.$$ I can estimate the complex integral with the Residues theorem: $$\int_{\gamma} \frac{\log^2 z}{z^2-1}dz=2\pi i \mathrm{Res}[f(z), -1]=i \pi^3$$ and this means that: $$\int_{0}^{\infty} \frac{\log (x)}{x^2-1}\mathrm{d}x=-\frac{\pi^2}{4}$$ which is wrong, since the correct result should be $\frac{\pi^2}{4}$ . Is there something wrong with my procedure?","['complex-analysis', 'integration', 'residue-calculus']"
1850941,Bessel Function of the first kind,"Could you please help me understand how to prove $$J_{(1/2)} (x) =  \sqrt{\frac2{\pi x}}\cdot \sin⁡ x$$ using, $$J_p (x)  = \sum_{(n=0)}^\infty \frac{(-1)^n}{(n! \Gamma(n+p+1) )} \left( \frac x 2 \right)^{2n+p}$$ Thank you","['special-functions', 'ordinary-differential-equations', 'bessel-functions']"
1850955,Almost sure convergence implies convegence in distribution - proof using monotone convergence,"I'm trying to understand the following proof of the statement : ""Almost sure convergence implies convegence in distribution"" The definition of convergence in distribution is given as follows : $X_n$ converges in distribution to $X$ if and only if for all bounded real function $f$ we have : $$\lim_{n \rightarrow +\infty  }E\left[f(X_n)\right]=E\left[f(X)\right]$$ The proof goes like this : If $X_n$ converges almost surely to $X$ then $f(X_n)$ converges almost surely to $f(X)$. Now using the dominated convergence theorem which is : $$\lim_{n \rightarrow +\infty  } \int f_n d\mu = \int f d\mu $$ we get : $$\lim_{n \rightarrow +\infty  }E[f(X_n)]=E[f(X)].$$ My question is this : How using the dominated convergence theorem gets us from : 
$$f(X_n)\rightarrow^{a.s.} f(X)$$ to $$\lim_{n \rightarrow +\infty  }E[f(X_n)]=E[f(X)]$$ given that the almost sure convergence is given by : $P\left[\lim_{n \rightarrow + \infty} X_n = X\right] = 1$? One of my attempts is to write the convergence in distribution in the form of integrals like this : $$\lim_{n \rightarrow +\infty  }E[f(X_n)]=E[f(X)]$$ is equivalent to : $$\lim_{n \rightarrow +\infty  }\int f(y) \phi_n(y) dy=\int f(y) \phi(y) dy$$ with $\phi$ the density of $X$ and $\phi_n$ the density of $X_n$. But this is a little different from the monotone convergence theorem result. In the dominated convergence theorem we have the same measure, $\mu$, but writing the expectations gives us two different measures, which are $\phi_n dy$ and $\phi dy$, respectively the cumulative distributions for $X_n$ and $X$ Any help please? I appreciate if you can tell me why my attempt is not leading anywhere and at the same time give your own proof. Thank you!","['probability-theory', 'weak-convergence', 'integration', 'convergence-divergence', 'random-variables']"
1850959,Find the value of $y(1)$ of the ODE $y'+y=|x|$.,"Let $y$ be the solution of $$y'+y=|x|$$ for $x\in\mathbb{R}$ and $y(-1)=0$.
Then the value of $y(1)$ is $\frac{2}{e}-\frac{2}{e^2}$ $\frac{2}{e}-2e^2$ $2-\frac{2}{e}$ $2-2e$ I don't know what to do with the absolute value function in this problem. So I started like the regular first order equation by calculating integrating factor, and got
$$ye^x=\int |x|e^x dx+C.$$ Now I got stuck as how to tackle the absolute value function? Help me to solve this. Thanks!",['ordinary-differential-equations']
1850986,How does a pity timer affects probabilities?,"In a game called hearthstone you buy packs to collect cards. They have four types of cards. Each type of cards has assigned a probability. So you open a pack and a random number is generated. The most valuable cards (called legendary) as you may expect are the least frequent. The owners of the game didnt want people to quit the game because of bad luck so they added a pity timer. If you didnt open a legendary in the previous 39 packs, when you open the number 40 you will always get a legendary card and the timer is set to zero. If you opened a legendary before the 40 pack the timer is also set to zero. The problem can be formulated as follows. If an event has probability p to happen and you ask for a condition that is if n-1 times in a row the event didnt happened, the event will always happen on the trial number n. What is the new probability of the event happening due to this condition? Thanks for reading!",['probability']
1850991,"$X,Y$ be finite topological spaces such that there exist continuous injections from $X$ to $Y$ and $Y$ to $X$ ; are $X$ and $Y$ homeomorphic?","Does the analogue of Schroder-Bernstein hold for finite topological spaces ? i.e. Let $X,Y$ be finite topological spaces such that there exist continuous injections from $X$ to $Y$ and $Y$ to $X$ , then are $X$ and $Y$ homeomorphic ? I know that it isn't true for arbitrary topological spaces ( even metric spaces , take $(0,1)$ and $[-1,1]$ ) ; but I don't know what happens if we restrict only to finite topological spaces . Please help . Thanks in advance","['continuity', 'general-topology', 'elementary-set-theory']"
1851010,Integral over all internal points,"Let $X$ be some subset of real numbers, and $f$ a real-valued function on $X$. If  $ f(x) \geq 0$ for every point $x\in {X}$, then also:
$$\int_{x\in X} f(x)dx \geq 0.$$
What if $ f(x) \geq 0$ only for every point $x\in \text{interior}({X})$ - is it still true that 
$$\int_{x\in X} f(x)dx \geq 0 ?$$ I thought to claim that this is true because ""almost all"" points in $X$ are internal points (the boundary points have a measure of 0). It this true?","['general-topology', 'measure-theory']"
1851023,How much can we tell about $\det(X)$ if we know $\det(I + X)$?,"What can we tell about $\det(X)$ if we know $\det(I + X)$? Will it
give some kind of bound for $\det(X)$? In general, if we know the determinant of matrix $A + X$, where $A$ is a constant matrix, how much can we say about $\det(X)$? Thank you for the attention.","['matrices', 'linear-algebra', 'determinant']"
1851049,An equality concerning the Lebesgue integral,"Let $f:X\mapsto[0,+\infty)$ be a non-negative measurable function defined on the space $X$, endowed with the complete $\sigma$-additive, $\sigma$-finite, measure $\mu$ defined on the $\sigma$-algebra of the measurable subsets of $X$. I have read that the following equality holds for the Lebesgue integral: $$\int_X f d\mu = \int_{[0,+\infty)} \mu(\{x\in X: f(x)>t\}) d\mu_t$$where $\mu_t$ is the usual Lebesgue linear measure. I would like to understand why this equality holds, but I have got serious problems in proving even the measurability of the function $\phi:t\mapsto \mu(\{x\in X: f(x)>t\})$ (necessary for the Lebesgue integral to be defined) to myself, which would be proved if we could verify that, for any $c\in\mathbb{R}$, the set $$\{t\in\mathbb{R}_{\ge 0}:\mu(\{x\in X: f(x)>t\})<c\}$$is measurable. How can we prove the equality (including the measurability of $\phi$)? I $\infty$-ly thank anyone answering.","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1851084,Matrix equation $A^2+A=I$ when $\det(A) = 1$,"I have to solve the following problem:
find the matrix $A \in M_{n \times n}(\mathbb{R})$ such that:
$$A^2+A=I$$ and $\det(A)=1$.
How many of these matrices can be found when $n$ is given?
Thanks in advance.","['matrices', 'matrix-equations', 'determinant']"
1851087,Differentiation under the integral sign for volumes in higher dimensions,"Consider a smooth convex/compact domain $D\subset \mathbb{R}^n$ and a smooth, concave function $F:D\to \mathbb{R}$.  Then we can define the function that simply takes the volume of the upper contour sets determined by the argument: $$G(t) = \int_{\{x\in D \; : \; F(x) \ge t\}} d\lambda$$ where $\lambda$ denotes the Lebesgue measure.  I'm trying to figure out an expression for $\frac{d}{dt}G(t)$. This seems like nothing more than a special case of a higher-dimensional Leibniz Integral Rule , but wikipedia gives me a substantially more general formula than I suspect I need for this case (for definitions of terms see the link): $$\frac{d}{dt} \int_{\Omega(t)} \omega = \int_{\Omega(t)} i_{\vec{v}}(d_x \omega) + \int_{\partial \Omega(t)} i_{\vec{v}}\omega + \int_{\Omega(t)} \dot{\omega}.$$ I have almost no background in differential forms, but immediately I know, for starters, the volume form I'm integrating is time invariant so the last term drops out here.  Moreover, given I'm just concerned with a uniform density, I'd imagine the first term should be zero too? (This corresponding to the intuition that all that really matters here is how much 'volume bleeds out of the bag $\Omega(t)$' as I cinch it shut by increasing $t$, and hence I need only be concerned with the incremental flow of volume across the boundary.)  But that may be wildly incorrect. Ideally if someone could help guide me (ideally both intuitively and analytically) to be able to understand and describe this derivative I'd be very grateful!  In particular an expression for what the Leibniz rule reduces to in this case would be most welcome.","['derivatives', 'real-analysis', 'integration', 'measure-theory', 'differential-geometry']"
1851093,Is a weakly differentiable function differentiable almost everywhere?,"I am working with Sobolev spaces. Let's suppose $\Omega \subset \mathbb{R}^n$ is an open set. A function $u: \mathbb{R}^n \to \mathbb{R}$ in $L^1(\Omega)$ is said to be weakly differentiable if there exist functions $ g_1,...,g_n $  such  that  $$\qquad\qquad\qquad\qquad\qquad\int_{\Omega}u\varphi_{x_i}=-\int_{\Omega}g_i \varphi \quad \quad   \forall \varphi \in C^{1}_c(\Omega), \forall i=1,...,n. $$ Can every weakly differentiable function be restricted to an open set $\tilde{\Omega}$ such that $u$ is differentiable (classical derivative!) with $m(\Omega - \tilde{\Omega})=0$? I know this is true for dimension $1$. Is it true for every $\Omega \subset \mathbb{R}^n$?","['derivatives', 'weak-derivatives', 'real-analysis', 'sobolev-spaces']"
1851111,n-th roots of unity summing to $0$,"Let $\zeta = e^{2\pi i/n}$ be an $n$-th root of unity, and let $S = \{\zeta^m|m=0,1,\ldots,n-1\}$ be the corresponding sets of all $n$-th roots of unity. Let $k \leq z$. Let $C \subseteq S$ such that $k=|C|$. I made following conjecture, but so far I'm unable to prove it: Then $\sum_{c\in C} c = 0$ implies that $k= |C|$ is a $\mathbb Z$-linear combination of strict divisors (divisors strictly greather than 1) of $n$. This seems to be plausible, and I checked it up to $n=15$. For $n=15$ we have the interesting case that the converse does not hold for $k=11 = 1\cdot 5 + 2 \cdot 3$. Another observation we can use is that for $C \subset S$ we have the equivalence $$\sum_{c \in C} c = 0  \iff \sum_{d \in S \setminus C} d= 0$$ which is quite obvious when you consider that $\sum_{s\in S} s = 0$. So can anyone prove or disprove this conjecture?","['number-theory', 'combinatorics', 'complex-numbers']"
1851114,"If a function $f$ is holomorphic on the closed unit disk centered at the origin and is real valued whenever $|z| = 1$, then $f$ is constant.","I am preparing for qualifying exams, and this is a question from the Penn State Qualifying Exam for Fall 2015. It is stated as follows Let $\epsilon > 0$ and let $f$ be holomorphic (analytic) on the disk $S = \{z \in \mathbb{C} \ | \ |z| < 1 + \epsilon \}$. Suppose that $f(z)$ is real valued whenever $|z| = 1$. Prove that $f$ is constant. I have tried a few things in showing this to be true, but I keep finding holes in my logic. My largest issue is that the portion of the domain in which $f$ is real valued is not open, and so I'm not able to use many of the theorems I otherwise feel would be helpful (Open Mapping Theorem, Cauchy-Riemann Equations, Maximum Modulus, etc.). Most of my attacks towards this problem have centered around showing things for the unit disk $\mathbb{D}$ instead of $S$, because I figure if I can show that $f$ is constant on $\mathbb{D}$, then I can use the Identity Theorem to extend it to $S$. However, since I don't know anything about the specific values that $f$ obtains, I can't use Schwarz' Lemma either. I played with the idea, also, of suggesting that, if we consider the closure of $\mathbb{D}$, then $f(\partial{\mathbb{D}}) \in \mathbb{R}$. Since $\partial\mathbb{D}$ is closed and bounded and $f$ is analytic, it's image should also be bounded. That would put, for some $M \in \mathbb{R}$, $f(\partial{\mathbb{D}}) \in [-M,M]$, which is bounded and obtains a maximum (since $f$ is continuous and real valued here). I know that this set isn't open, but there is a Corollary in my text (Complex Analysis - Freitag) that says the following: ""If $K$ is a compact subset of the domain $D$ and $f:D \rightarrow \mathbb{C}$ is analytic, then the restriction of $f|K$ being a continuous function has a maximal modulus on $K$. By the Maximum Modulus Principle, we can moreover affirm that the maximal modulus value is necessarily taken on the boundary of $\mathbb{D}$."" The proof of that statement follows from the Open Mapping Theorem. Would it be appropriate to use that in this case, then? If $K = \partial \mathbb{D}$, even though it's technically not an open set, can I say that $f$ obtains its maximum on $\mathbb{D}$, state that it's constant, and then extend this to $S$ using the Identity Theorem? My issue here is that the constant itself isn't actually in $\mathbb{D}$, I appreciate any help for this problem (or any tips for showing that complex functions will be constant, as these types of problems show up often). Edit: My function $f$ is not necessarily entire, so Liouville's Theorem does not apply","['analyticity', 'complex-analysis', 'maximum-principle']"
1851115,nullity of infinite matrix A equals nullity of $A^T$?,"Suppose you have an infinite matrix A with real entries. I know the dimension of the null space of A. Question 1) if the dimension of the null space is a finite number k, is the dimension of the null space of $A^T$ also k? Question 2) if the dimension of the null space of A is infinite, is the dimension of the null space of $A^T$ also infinite? Thanks!","['matrices', 'functional-analysis', 'linear-algebra']"
1851152,"Family of partitions, s.t. the quadratic variation of a BM diverges a.s.","This question is about a specific step in the solution of exercise 1.13 a) of the book ""Brownian Motion"" by Peres and Mörters ( https://www.stat.berkeley.edu/~peres/bmbook.pdf ). The exercise is on page 40 and its solution on page 315. $B$ stands for a Brownian Motion. We need to show that, almost surely, there exists a family
$0=t_0^{n} \le t_1^{n} \le ... \le t_{p(n)}^n=t$ of (random) partitions, such that $\lim\limits_{n \to \infty} \sum\limits_{j=1}^{p(n)} \left(B\left(t_j^{(n)} \right) - B\left(t_{j-1}^{(n)} \right) \right)^2 = \infty$. The solution gives the arguments, that for given $M>0$ large, for any fixed $s\in [0,1]$, there exists $n \in \mathbb{N}$, such that the dyadic interval $I(n,s):=[k2^{-n},(k+1)2^{-n}]$ containing $s$ satisfies $\left |B\left((k+1)2^{-n}\right)-B\left(k2^{-n}\right)\right| \geq M2^{-\frac{n}{2}}$ (call it inequality 1) and call $N(s)$ the smallest integer $n$ for which this inequality holds. We think that $k$ depends on $s$, so we write $k(s)$. The solution tells us to apply Fubini's theorem to see that $N(s) < \infty$ almost surely. My question is now, whether we applied Fubini correctly. We thought that (call it remark 1) $N(s) < \infty$ almost surely $\thinspace$ $\Leftrightarrow \thinspace \int_{0}^{1} \mathbb{P} \left( \underset{n \ge 0}\bigcup \left\{ \left| B \left( \frac{k(s)+1}{2^n}\right)-B \left( \frac{k(s)}{2^n}\right)\right| \geq M2^{-\frac{n}{2}}\right\}\right) \mathrm{d}s < \infty$. Then to apply Fubini, we write \begin{align*}&\int_{0}^{1} \mathbb{P} \left( \underset{n \ge 0}\bigcup \left\{ \left| B \left( \frac{k(s)+1}{2^n}\right)-B \left( \frac{k(s)}{2^n}\right)\right| \geq M2^{-\frac{n}{2}}\right\}\right) \mathrm{d}s \\&= 
\int_{0}^{1} \int_{\Omega} \Bbb{1}_{\left\{ \underset{n \ge 0}\bigcup \left\{ \left| B \left( \frac{k(s)+1}{2^n}\right)-B \left( \frac{k(s)}{2^n}\right)\right| \geq M2^{-\frac{n}{2}}\right\} \right\}} \mathrm{d}\mathbb{P}(\omega) \mathrm{d}s \\
&= \int_{\Omega} \int_{0}^{1}  \Bbb{1}_{\left\{ \underset{n \ge 0}\bigcup \left\{ \left| B \left( \frac{k(s)+1}{2^n}\right)-B \left( \frac{k(s)}{2^n}\right)\right| \geq M2^{-\frac{n}{2}}\right\} \right\}} \mathrm{d}s \mathrm{d}\mathbb{P}(\omega)\end{align*} Now, since we know that there exists $n$, such that inequality 1 is fulfilled, the indicator function is equal to 1, hence the last expression is equal to $\int_{\Omega} \int_{0}^{1}  \mathrm{d}s \mathrm{d}\mathbb{P}(\omega)=1<\infty$ which implies due to remark 1 that $N(s)< \infty$. Can anybody say something especially about the correctness of remark 1 and whether you think the author meant that by using Fubini's theorem? Thanks for any comments.","['quadratic-variation', 'probability-theory', 'brownian-motion']"
1851248,Finding the inverse laplace transform using complex analysis.,I've been able to prove simple laplace transforms like $\dfrac {1}{(s+a)} $ quite easily but what about $\dfrac {1}{(s+a)^3+b^2} $ this does not seem easy to do since you cannot easily compute the residues of the denominator. How can this be done???,"['laplace-transform', 'complex-analysis', 'integration', 'definite-integrals', 'ordinary-differential-equations']"
1851267,How to show that a Schwartz distribution is in a Lebesgue or Sobolev space?,"It is known that all $L^p$ spaces (and, consequently, all $W^{s,p}$ spaces) can be embedded in the space of Schwartz distributions $\mathcal D '$. There is a problem, though: how do I check whether some given distribution $u \in \mathcal D '$ belongs to any of the Lebesgue or Sobolev spaces mentioned above? (There are problems requiring the student to show this, and I have no clue what technique(s) to use and how to approach them.)","['partial-differential-equations', 'distribution-theory', 'functional-analysis', 'lp-spaces', 'sobolev-spaces']"
1851287,Is a bijective smooth function a diffeomorphism almost everywhere?,"Suppose I have $f: M \rightarrow N \in C^{\infty}$ a smooth bijection between $n$-dimensional smooth manifolds. Does it have to be a diffeomorphism except for a set of measure 0? I think the proof might come from showing that $X = \{p: d_pf \text{ is not an isomorphism}\}$ has measure zero. Using the inverse function theorem you can show that the statement follows from this. By Sard's theorem, we know that $f(X)$ has measure zero, but I don't know how to go from there to $X$ having measure zero (since we don't know, for example, that $f^{-1}$ is locally Lipschitz). You may assume (if you want) that $M$ and/or $N$ are connected and/or compact. Thanks!","['real-analysis', 'smooth-manifolds', 'differential-geometry', 'inverse-function']"
1851292,Why is my solution wrong?,"Question: ""Find all x such that ${\frac{x-a}{b}}+{\frac{x-b}{a}}={\frac{b}{x-a}}+{\frac{a}{x-b}}$ , where a and b are constants."" My attempt: ${\frac{x-a}{b}}+{\frac{x-b}{a}}={\frac{b}{x-a}}+{\frac{a}{x-b}}$ Let $m=x-a$ ,Let $w=x-b$ . Therefore: ${\frac{m}{b}}+{\frac{w}{a}}={\frac{b}{m}}+{\frac{a}{w}}$ ${\frac{m}{b}}-{\frac{b}{m}}={\frac{a}{w}}-{\frac{w}{a}}$ ${\frac{m^2-b^2}{bm}}={\frac{a^2-w^2}{aw}}$ ${\frac{(m+b)(m-b)}{bm}}={\frac{(a+w)(a-w)}{aw}}$ Substituting back $m=x-a$ , $w=x-b$ : ${\frac{(x-a+b)(x-a-b)}{b(x-a)}}={\frac{(a+x-b)(a-x+b)}{a(x-b)}}$ Factoring out $-1$ from $(a-x+b)$: ${\frac{(x-a+b)(x-a-b)}{b(x-a)}}={\frac{-(a+x-b)(x-a-b)}{a(x-b)}}$ Dividing by $(x-a-b)$: ${\frac{(x-a+b)}{b(x-a)}}={\frac{-(a+x-b)}{a(x-b)}}$ Cross multiplying: $(x-a+b)(ax-ab)=(-x-a+b)(bx-ab)$ Distributing; $ax^2-abx-a^2x+a^2b+abx-ab^2=-bx^2+abx-abx+a^2b+b^2x-ab^2$ $ax^2-a^2x+a^2b-ab^2=-bx^2+a^2b+b^2x-ab^2$ $ax^2-a^2x+a^2b-ab^2-(-bx^2+a^2b+b^2x-ab^2)=0$ $ax^2+bx^2-a^2x-b^2x=0$ $(a+b)x^2-(a^2+b^2)x=0$ Factoring out $x$: $x[(a+b)x-(a^2+b^2)]=0$ Therefore: $x=0$ or $(a+b)x-(a^2+b^2)=0$ $(a+b)x=(a^2+b^2)$ $x=\frac{(a^2+b^2)}{(a+b)}$ My two solutions are $x=0$ and $x=\frac{(a^2+b^2)}{(a+b)}$; however, I am missing the solution $x=a+b$. Where did I eliminate this solution? How do I prevent this from happening (eliminating solutions) in the future? Is there a better way to solve this equation?",['algebra-precalculus']
1851326,"How do you prove that If X is an infinite set, then there is a denumerable subset Y of X such that X and X-Y are equipotent? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question How do you prove that If X is an infinite set, then there is a denumerable subset Y of X such that X and X-Y are equipotent?",['elementary-set-theory']
1851337,Inequality for hook numbers in Young diagrams,"Consider a Young diagram $\lambda = (\lambda_1,\ldots,\lambda_\ell)$.  For a square $(i,j) \in \lambda$ define hook numbers $h_{ij} = \lambda_i + \lambda_j' -i - j +1$ and complementary hook numbers $q_{ij} = i + j -1$.  Let
$$H(\lambda) = \prod_{(i,j) \in \lambda} h_{ij}\,, \qquad
Q(\lambda) = \prod_{(i,j) \in \lambda} q_{ij}\,.
$$ Question: is there an elementary proof of the following inequality:
$$H(\lambda) \le Q(\lambda).
$$ For example, when $\lambda = (3,2,1)$ we have 
$$H(\lambda)=5\cdot 3 \cdot 3 \cdot 1\cdot 1 \cdot 1 = 45, \qquad
Q(\lambda)=1\cdot 2 \cdot 2 \cdot 3\cdot 3 \cdot 3 = 108.
$$
Let me mention that 
$$\sum_{(i,j) \in \lambda} h_{ij} = \sum_{(i,j) \in \lambda} q_{ij},
$$
so somehow this says that $q_{ij}$ are more evenly distributed. Note: this inequality is a corollary of the main results in our paper .  The proof of the main result is algebraic and quite involved. UPDATE (7/7/2016)
Cross-posted on MO where it was resolved .","['young-tableaux', 'inequality', 'integer-partitions', 'combinatorics', 'algebraic-combinatorics']"
1851338,Intuition behind the proof of the validity of the Euclidean algorithm,"As the question title suggests, could anybody explain to me their intuition behind the proof of the validity of the Euclidean algorithm?","['algebra-precalculus', 'intuition', 'proof-explanation', 'elementary-number-theory']"
1851339,Possibly new solution to equal-mass three-body problem; refinement required,"(Since I didn't know which authorities to contact, I thought I'd post this here.) While messing around in this Wolfram Demonstrations applet , I found a suspicious pattern, in which I could see physical similarities between the path of the first object, the path of the second object at a later time, and even the path of the third object at an even later time. Through gradually tweaking that set of initial conditions, I was able to find an apparently new solution to the equal-mass three-body problem that wasn't listed here . Here are the initial conditions, with my restrictions in parentheses: $x_1(0)=0.7812$ $y_1(0)=-0.2465\;(\text{holding $x_1(0)^2+y_1(0)^2$ constant to avoid scaling})$ $x_2(0)=-0.2465\;(=y_1(0))$ $y_2(0)=0.7812\;(=x_1(0))$ $x_3(0)=-0.5347\;(=-x_1(0)-x_2(0))$ $y_3(0)=-0.5347\;(=x_3(0))$ $x_1'(0)=-0.6087$ $y_1'(0)=-0.286$ $x_2'(0)=0.286\;(=-y_1'(0))$ $y_2'(0)=0.6087\;(=-x_1'(0))$ $x_3'(0)=0.3227\;(=-x_1'(0)-x_2'(0))$ $y_3'(0)=-0.3227\;(=-x_3'(0))$ (I would estimate the uncertainty for all parameters to be roughly $0.01$ in either direction. It would be smaller, but a slight change in the position parameter can be practically canceled out by a slight change in one or both of the velocity parameters, apparently resulting in a relatively 2D structure in 3D parameter space.) This gives an approximate choreography with period $p\approx 17.0874$, shaped somewhat like a rosette: Going further in time, the entire system apparently rotates, but doesn't break apart: At this point, what algorithms or heuristics should I use to increase the precision of the parameters (for example, trying to make the paths match over increasing lengths of time)?","['reference-request', 'classical-mechanics', 'ordinary-differential-equations', 'calculus']"
1851361,Abuse of notation for infimum and supremum,"I would like to take the infimum and supremum of two sets  $(\frac{1}{2} e^{8m+4} - 1, e^{8m+4} - 1)$ and $(\frac{1}{2} e^{8m+4}, \frac{3}{2}e^{8m+4})$, but writing $\sup((\frac{1}{2} e^{8m+4}, \frac{3}{2}e^{8m+4})) < \inf((\frac{1}{2}
e^{8m+4} - 1, e^{8m+4} - 1)) \log(\inf((\frac{1}{2}
e^{8m+4} - 1, e^{8m+4} - 1))) < p_r$ and
  $\inf((\frac{1}{2} e^{8m+4},
\frac{3}{2}e^{8m+4}))\log(\inf((\frac{1}{2} e^{8m+4},
\frac{3}{2}e^{8m+4}))) > e^{8m+4}$ for all $m > \frac{1}{4}$. looks absolutely terrible. What I would like to write is this: If we let $k \in (\frac{3}{2} e^{8m+4} - 1, 2e^{8m+4} - 1)$ and $r \in (\frac{1}{2} e^{8m+4} - 1, e^{8m+4} - 1)$ then we have $c = k - r + 1 \in (\frac{1}{2} e^{8m+4}, \frac{3}{2}e^{8m+4})$. We observe that
  $\sup(c) < \inf(r) \log(\inf(r)) < p_r$ and $\inf(c)\log(\inf(c)) > e^{8m+4}$ for all $m > \frac{1}{4}$. These statements aren't equivalent given that $r$ and $c$ are elements of the respective sets and not the sets themselves. However, I fear that both the first approach and assigning variables to the given sets would make this statement significantly longer than it needs to be. Would this be considered a meaningful abuse of notation, or should I perhaps rewrite this another way? Thank you.","['number-theory', 'notation', 'article-writing', 'supremum-and-infimum']"
1851373,"In abstract algebra, what is an intuitive explanation for a field?","Wikipedia has the following to say about fields. In mathematics, a field is one of the fundamental algebraic structures used in abstract algebra. It is a nonzero commutative division ring, or equivalently a ring whose nonzero elements form an abelian group under multiplication. As such it is an algebraic structure with notions of addition, subtraction, multiplication, and division satisfying the appropriate abelian group equations and distributive law. What is an intuitive way about thinking about a field?","['intuition', 'abstract-algebra', 'number-theory', 'ring-theory', 'field-theory']"
1851378,Prove: $\frac{x}{\sqrt{y}}+\frac{y}{\sqrt{x}}\geq \sqrt{x}+\sqrt{y}$,"Prove: $$\frac{x}{\sqrt{y}}+\frac{y}{\sqrt{x}}\geq \sqrt{x}+\sqrt{y}$$ for all x, y positive $$\frac{x}{\sqrt{y}}+\frac{y}{\sqrt{x}}-\sqrt{x}-\sqrt{y}\geq 0$$ $$\frac{x\sqrt{x}+y\sqrt{y}-x\sqrt{y}-y\sqrt{x}}{\sqrt{y}\sqrt{x}}\geq 0$$ $$\frac{x(\sqrt{x}-\sqrt{y})+y(\sqrt{y}-\sqrt{x})}{\sqrt{y}\sqrt{x}}\geq 0$$ $$\frac{x(\sqrt{x}-\sqrt{y})-y(-\sqrt{y}+\sqrt{x})}{\sqrt{y}\sqrt{x}}\geq 0$$ $$\frac{(x-y)(\sqrt{x}-\sqrt{y})}{\sqrt{y}\sqrt{x}}\geq 0$$ $$\frac{(\sqrt{x}-\sqrt{y})(\sqrt{x}+\sqrt{y})(\sqrt{x}-\sqrt{y})}{\sqrt{y}\sqrt{x}}\geq 0$$ $$\frac{(\sqrt{x}-\sqrt{y})^2(\sqrt{x}+\sqrt{y})}{\sqrt{y}\sqrt{x}}\geq 0$$ All the elements are positive and if $\sqrt{x}=\sqrt{y}$ we get $0$ Is the proof valid?","['algebra-precalculus', 'proof-verification']"
1851382,Factoring out a $7$ from $3^{35}-5$?,"Please Note: My main concern now is how to factor $7$ from $3^{35}-5$ using Algebraic techniques, not how to solve the problem itself; the motivation is just for background. Motivation: I was trying to solve the following problem What is the remainder when $10^{35}$ is divided by $7$? I used the binomial formula: $\dfrac {(7+3)^{35}}{7}= \dfrac {7^{35} + \cdot \cdot \cdot 3^{35}}{7}= \dfrac {7^{35} + \cdot \cdot \cdot + 35 \cdot 3^{34} \cdot 7}{7}  + \dfrac {3^{35}}{7}$ Therefore, $10^{35}$ will have the same remainder as $3^{35}$ when divided by $7$. I was stuck here, and I wanted to try to reverse engineer the answer. I know the remainder is $5$. Therefore I should be able to write $3^{35} -5 + 5$ as $7k+5$. However, I have no idea how to factor out a $7$ from $3^{35}-5$, or from $10^{35}-5.$ How could I find this $k$ non-explicitly?","['algebra-precalculus', 'discrete-mathematics', 'factoring', 'elementary-number-theory']"
1851409,Picard-Lindelöf Theorem application,"I'm really lost here guys. I'd appreciate it if you could help. Consider the differential equation $$
\frac{dy}{dt} = f(t, y) \tag{1}
$$ with $f$ satisfying the conditions of the Picard-Lindelöf Theorem . Also, $y_1(t) = 3\ ,\ t \in \mathbb{R}$ is a solution of $(1)$ . What can we conclude about the solution $y(t)$ which satisfies the initial condition $y(0) = 1$ ?","['ordinary-differential-equations', 'initial-value-problems']"
1851459,Understanding this proof that $\lim\limits_{h\to 0}\frac{\cos(h)-1}{h}=0$,"I need help understanding how this limit is proved? : Show that $$\lim_{h\to 0} \frac{\cos (h)-1}{h}=0$$ Proof : Using the half angle formula, $\cos h = 1-2 \sin^2(h/2)$ $$\lim_{h\to 0} \frac{\cos (h)-1}{h}\\=\lim_{h\to 0}( -\frac{2 \sin^2(h/2)}{h})\\=-\lim_{\theta \to 0}\frac{\sin \theta}{\theta} \sin \theta\  \  \  \  \  \  \  \  \  \  \  \  \  \  \ \text{(Let $\theta=h/2$)}  \\ = -(1)(0)\\=0$$
I have no idea how this proof is done, so I apologize for the lack of my own thoughts in this question. I understand limits and know sin, cos, tan, but I am just very lost as what they did in each step. Can someone please explain all the steps of the proof as well as the half-angle formula. Thanks!","['trigonometry', 'calculus', 'limits']"
1851532,"How many functions from $\{0,1\} \times \{0,1\}$ to $\{0,1,2\}$ are there?","The question in my homework is: How many functions from $\{0,1\} \times \{0,1\}$ to $\{0,1,2\}$ are there? How many are one-to-one? How many are onto? My first step was to take the Cartesian Product of $\{0,1\} \times \{0,1\}$ in order to get a set $$A = \{(0,0),(0,1),(1,0),(1,1)\}$$ However I am unsure what to do next. Any help would be greatly appreciated","['functions', 'discrete-mathematics']"
1851544,Making sense of the commutator,"For a group $G$, the commutator of two elements is defined as $[a,b]=aba^{-1}b^{-1}$, and is usually said to measure the extent to which the elements $a$ and $b$ fail to commute. I'm having some trouble making sense of the last bit: I understand that if $a$ and $b$ commute, then $[a,b]=e$. But if $a$ and $b$ don't commute, in what sense is the commutator actually capturing the extent of their failure to commute, since there is no way to talk about how ""far"" an element $g\in G$ is from the identity? Am I just interpreting the word ""measure"" too literally here, or is there actually a way to think about commutators that makes it clear in what sense they compare the way two pairs of elements fail to commute?","['abstract-algebra', 'group-theory']"
1851553,Using higher order derivatives,"I am currently learning about the general Notion of Differentiability. I came across some difficulties when working with higher order derivatives and I am hoping for confirmation or comments on some questions I have. In the following, let $E$, $F$ be Banach Spaces, and let $X\subseteq E$ be open.
I do understand that for $x_0\in X$ it is $Df(x_0)\in\mathcal{L}(E,F)$.
My directional derivative for $v\in E\setminus\{0\}$ is defined as the derivative in $0$ of the function $(-\varepsilon,\varepsilon)\to F, t\mapsto f(x_0+tv)$ with $\varepsilon>0$ suitable to keep $x_0\pm\varepsilon v$ in $X$. So it is $D_vf(x_0)\in\mathcal{L}(\mathbb{R},F)$. When then stating $D_vf(x_0)=Df(x_0)v$ while $Df(x_0)v\in F$, are we already using the identification $\mathcal{L}(\mathbb{R},F)\cong F$? When extending the notion to higher order derivatives $D^kf(x_0)\in\mathcal{L}^k(E,F)$ I came across the statement $$D^kf(x_0)(h_1,\dots,h_k)=D(\dots D(Df(x_0)h_1)h_2\dots)h_k$$
that should somehow be linked to the above identification and that I really cannot wrap my head around.
It would be nice to see some step-by-step computation of that formula. Should I read myself more into multi-linear maps? Thanks in advance for any comment.","['multivariable-calculus', 'derivatives']"
1851598,Function with countably many points of discontinuity,"Aside from rigor, is this proof correct? Claim. Let $f$ be a function defined on $[0, 1]$ such that $\lim\limits_{y\to a} f(y)$ exists for all $a \in [0, 1]$. Then for any $\epsilon > 0$ there are only finitely many points $a \in [0, 1]$ with $$|\lim\limits_{y\to a} f(y) - f(a)| > \epsilon.$$ Proof. Suppose that there are infinitely many such points $a.$ Then by the Bolzano-Weierstrass Theorem, these points have a limit $x \in [0, 1].$ Let $$L := \lim\limits_{y \to x} f(y) = \lim\limits_{a\to x} f(a).$$ The condition $$|\lim\limits_{y\to a} f(y) - f(a)| > \epsilon$$ means that for $y$ close to $a$, $f(y)$ is far from $f(a).$ Similarly $\lim\limits_{a \to x} f(a) = L$ means that for $a$ close to $x,$ $f(a)$ is close to $L.$ Together this means that for $y$ close to $x$, $f(y)$ is far from $L$, but this contradicts the fact that $L = \lim\limits_{y \to x} f(y),$ i.e. for $y$ close to $x$, $f(y)$ is close to $L.$","['real-analysis', 'sequences-and-series', 'proof-verification', 'limits']"
1851644,Non-existence of $C^1$ injective mapping $\mathbb{R}^3 \to \mathbb{R}^2$.,"A friend of mine did a test yesterday where it asked to prove that there does not exist a $C^1$ injective mapping $\mathbb{R}^3 \to \mathbb{R}^2$. This is an immediate result from invariance of domain, but since this is a real analysis test (where people are being introduced to derivation in $\mathbb{R}^n$), I tried to come up with an elementary solution. However, none came to mind. I thought about using the local form of submersions (which, by the way, I wouldn't expect in this point in the course my friend is taking anyway), but we would need to have a regular value which is on the image, and this is not given by the hypotheses, neither by Sard's theorem. Since this was on the test, I have the feeling I may be letting something slip. My question therefore is to prove the given statement with only tools of differentiation in $\mathbb{R}^n$ (inverse function theorem, chain rule etc).","['general-topology', 'real-analysis', 'algebraic-topology']"
1851647,cohomology of total space,"Suppose $\mu:E\to B$ is a fiber bundle with fiber $F$. Furthermore, $F$ and $B$ have vanishing odd dimensional cohomology group. Is it true that $E$ has vanishing odd dimensional cohomology group? You can just assume $E,B,F$ are (possibly singular) algebraic variety. More specifically, you can assume the fiber $F$ is a partial flag variety. Thank you so much for your help!","['algebraic-topology', 'algebraic-geometry']"
1851657,"Basis-free formula for $\mathrm{Hom}_k(V,V)\rightarrow V^*\otimes V$","Let $V$ be a finite dimensional vector space over a field $k$.  Then  there is a natural map $\phi:V^*\otimes V\rightarrow \mathrm{Hom}_k(V,V)$ given by $$\phi:f\otimes v\mapsto \Big(x\mapsto f(x)v\Big)$$ (extended by linearity). It's not hard to check that this is well-defined and injective, hence surjective by a dimension count. The above suffices to define a (canonical) map $\phi^{-1}\colon\mathrm{Hom}_k(V,V)\rightarrow V^*\otimes V$. Explicitly, $\phi^{-1}(g)$ is the unique element of $V^*\otimes V$ that maps to $g$ under $\phi$. This definition of $\phi$ is basis-free, but it does not seem to give a formula for $\phi^{-1}$ in the same sense that the displayed equation gives a formula for $\phi$. Question 1: How should I make precise the notion that the displayed equation for $\phi$ counts as a ""formula"", but the definition of $\phi^{-1}$ does not? Question 2: Is there some alternate basis-free definitionof $\phi^{-1}$ that clearly would count as a formula? Comment:  It is easy to write down a basis-dependent formula for $\phi^{-1}$ and then prove that the result of this formula is independent of the choice of basis.  But I'm looking for a formula that never requires picking a basis in the first place.","['category-theory', 'canonical-transformation', 'linear-algebra']"
1851664,Prove that $\bigcup\mathbb{N}=\mathbb{N}$,"Prove that $\bigcup\mathbb{N}=\mathbb{N}$. Showing that $\mathbb{N}\subseteq \bigcup\mathbb{N}$ is simple. However, I'm not seeing how to handle showing $\bigcup\mathbb{N}\subseteq\mathbb{N}$. I know that $\mathbb{N}:=\bigcap\{z\in\mathcal{P}(x)|\text{ $x$ is inductive}\}$.
Therefore, $$\bigcup\mathbb{N}\Leftrightarrow \bigcup\big(\bigcap\{z\in\mathcal{P}(x)|\text{ $x$ is inductive}\}\big)$$ But I'm not sure what to make of this. EDIT: The definition of a natural number I'm working with is 
$\mathbb{N}=\{\mathbf{0},\mathbf{0^{+}},\mathbf{0^{++}},\mathbf{0^{+++}}\ldots\}$, where $\mathbf{0}=\emptyset$ and $\mathbf{0^+}=\mathbf{0} \cup {\mathbf{\{0\}}}$ and the set of natural numbers is as defined above",['elementary-set-theory']
1851666,How to compute the limit of $a_n$ from the following expression?,"Let $\{a_n\}$ be a sequence such that 
$$\lim_{n\to \infty}\left|a_n+3\left(\frac{n-2}{n}\right)^n\right|^\frac{1}{n}=\frac{3}{5}$$ Then calculate $\lim_{n\to \infty}a_n$. First I tried to take logarithm and got $\lim_{n\to \infty}\frac{1}{n}\ln\left|a_n+3\left(\frac{n-2}{n}\right)^n\right|=\ln\frac{3}{5}$, then I thought about L Hospital but that did not work. I am unable to dig it further. Can somebody give me a hint or push towards the solution? Thanks.","['sequences-and-series', 'limits']"
1851759,How to solve the equation $\log_{2x+3}(6x^2+23x+21)=4-\log_{3x+7}(4x^2+12x+9)$?,How to solve the equation $\log_{2x+3}(6x^2+23x+21)=4-\log_{3x+7}(4x^2+12x+9)$ ? Can someone please tell me a few steps as to how to approach these category of problems? I know $2x+3>0$ and $3x+7>0$ is a must.,"['algebra-precalculus', 'logarithms']"
1851770,"Prove by induction that $\sum_{i=1}^{2^n} \frac{1}{i} \ge 1+\frac{n}{2}, \forall n \in \mathbb N$","As the title says I need to prove the following by induction:
$$\sum_{i=1}^{2^n} \frac{1}{i} \ge 1+\frac{n}{2}, \forall n \in \mathbb N$$ When trying to prove that P(n+1) is true if P(n) is, then I get that: $$\sum_{i=1}^{2^{n+1}} \frac{1}{i} = (\sum_{i=1}^{2^n} \frac{1}{i} ) +(\sum_{i=1}^{2^n} \frac{1}{2^n+i} ) \ge 1+\frac{n}{2} + (\sum_{i=1}^{2^n} \frac{1}{2^n+i} )$$ using the inductive hypothesis. And for P(n+1) to be true it would be sufficient to prove that  $$1+\frac{n}{2} + (\sum_{i=1}^{2^n} \frac{1}{2^n+i} ) \ge 1+\frac{n+1}{2}$$  or rewriting $$\sum_{i=1}^{2^n} \frac{1}{2^n+i} \ge \frac{1}{2} $$ and here I'm a bit stuck Thank you for your help!","['inequality', 'algebra-precalculus', 'induction', 'summation', 'harmonic-numbers']"
1851800,Evalute $ \lim_{n\rightarrow \infty}\sum^{n}_{k=0}\frac{\binom{n}{k}}{n^k(k+3)} $,"Evaluate $\displaystyle \lim_{n\rightarrow \infty}\sum^{n}_{k=0}\frac{\binom{n}{k}}{n^k(k+3)}$. $\bf{My\; Try::}$ Although we can solve it by converting into definite Integration. But I want to solve it without Using Integration. So $\displaystyle \lim_{n\rightarrow \infty}\sum^{n}_{k=0}\frac{\binom{n}{k}}{n^k(k+3)} = \lim_{n\rightarrow \infty}\sum^{n}_{k=0}\frac{(n-1)(n-2).......(n-k+1)}{k!\cdot n^{k}\cdot (k+3)}$ Now How can i solve after that, Help required, Thanks",['limits']
1851845,Measurable Functions with Common Sigma Sub-Algebras,"Let $X:\mathbb{R}\rightarrow\mathbb{R}$ be a non-constant function, measurable with respect to the Borel-Algebra $\mathcal{B}$ and $\sigma(X)$ the sigma-algebra generated by $X$. Let $\mathcal{A}\subsetneqq\sigma(X)$, $\mathcal{A}\neq\{\emptyset, \mathbb{R}\}$ be a sub-sigma algebra of $\sigma(X)$. Question Does there always exist a $\mathcal{B}$-measurable function $Y:\mathbb{R}\rightarrow\mathbb{R}$ such that $\sigma(X)\cap\sigma(Y)=\mathcal{A}$ But neither is $\sigma(X)\subset\sigma(Y)$ nor $\sigma(Y)\subset\sigma(X)$. It was easy for me to find a few specific examples where $\sigma(X)$ has only a finite number of elements, but I am interested in the general case. EDIT: The example given by Eric answers the question as stated. But due to his comment and answer I noticed that I actually would like to understand something slightly(?) different. I am really interested in the case where $\mathcal{A}$ is also generated by a function, i.e. $\mathcal{A}=\sigma(f\circ X)$. The countable-uncountable sigma-algebra is not generated by a function since it is not countably generated (see here ) but a sigma-algebra generated by a function is.","['functional-analysis', 'probability-theory', 'probability', 'measure-theory']"
1851850,Probability of 4 specific numbers (1-3000) occuring in a sample of 400,"How to calculate the probability that four specific, distinct numbers from the range 1 - 3000 occur at least once in a fixed sample of 400 random numbers from the range 1-3000? The numbers in the sample can repeat as they were randomly generated. My intuition would be that it is basically a set of four ""scans"" of the 400 numbers, so the probability of hitting the 1/3000 searched number in each of the scans is roughly 400/3000 = 2/15. This would give the total probability count as (2/15)x(2/15)x(2/15)x(2/15) = 16/50625 = 0,000316. However, I'm not sure if this accounts (and if it should account) for the fact that it is a fixed sample so it's not ""re-rolled"" for each of the four scans. Thanks for any advice.","['combinatorics', 'probability']"
1851881,Lower semicontinuous function is measurable,"Let $(X, \mathfrak{M},\mu)$ be measure space such that $\mathfrak{M}$ contains all Borel sets of $X$. Let $f:X\to \mathbb{R}$ be lower semicontinuous function (LSC). Prove that $f$ is measurable. Proof: Let $U$ be an open set in $\mathbb{R}$ then $U=\bigsqcup \limits_{i=1}^{\infty}I_j$ where $I_j$ open intervals of form $(a_j,b_j)$. Then $f^{-1}(U)=\bigsqcup \limits_{i=1}^{\infty}f^{-1}(I_j)$. Let's take a look at $$f^{-1}(I_j)=f^{-1}((a_j,b_j))=\{x:a_j<f(x)<b_j\}=\{x:f(x)>a_j\}\cap \{x:f(x)<b_j\}$$
Since $$\{x:f(x)<b_j\}=f^{-1}((-\infty, b_j))=f^{-1}\left(\bigcup \limits_{n=1}^{\infty}(-\infty,b_j-\frac{1}{n}]\right)=\bigcup \limits_{n=1}^{\infty}f^{-1}\left((-\infty,b_j-1/n]\right)=$$$$=\bigcup \limits_{n=1}^{\infty}(f^{-1}\left((b_j-1/n,+\infty)\right))^c.$$
Since $f$ is LSC then for each $n$ the set $f^{-1}\left((b_j-1/n,+\infty)\right)$ is open $\Rightarrow$ $f^{-1}\left((b_j-1/n,+\infty)\right)\in \mathfrak{M}$ $\Rightarrow$ complement and countable union is also in $\mathfrak{M}$. Hence $f^{-1}(I_j)\in \mathfrak{M}$. Hence $f^{-1}(U)\in \mathfrak{M}$. Am I right?","['real-analysis', 'measure-theory']"
1851935,show that $\prod_{k=1}^{n-1}\left(2\cot{\frac{\pi}{n}}-\cot{\frac{k\pi}{n}}+i\right)$ is purely imaginary number,"Show that
$$\prod_{k=1}^{n-1}\left(2\cot{\dfrac{\pi}{n}}-\cot{\dfrac{k\pi}{n}}+i\right)$$
  is purely imaginary number where $i^2=-1$ where $n=2$  it is clear
$$2\cot{\dfrac{\pi}{n}}-\cot{\dfrac{k\pi}{n}}+i=2\cot{\dfrac{\pi}{2}}-\cot{\dfrac{\pi}{2}}+i=i$$
is  purely  imaginary number","['trigonometry', 'complex-numbers']"
1851955,"Use the chain rule to evaluate $\frac{\mathrm{d}}{\mathrm{d}x}\displaystyle\int_{x^2-1}^{\sin(x)} \cos(t) \, \mathrm{d}t $","Doesn't the derivative of that integral just equal $\cos(x)$? What does it mean to use the Chain Rule? I know for sure it has nothing to do with $u$-substitution. Any help would be appreciated, thanks.","['derivatives', 'integration', 'chain-rule', 'calculus']"
1852018,How long until I get out of bed?,"Suppose I have two independent alarm clocks which I set right before I go to bed. Their ring times are exponentially distributed with rates $\lambda_1$ and $\lambda_2$. Whenever alarm 1 goes off I immediately reset both alarms, but if alarm 2 goes off I actually get up. How long do I stay in bed? Am I right in saying that alarm clock one is redundant with respect to bed staying time?","['markov-chains', 'probability']"
1852025,A corollary of the Hahn-Banach theorem,"Let $Z$ be a subspace of normed linear space $X$ and that $y$ is an element of $X$ whose distance from $Z$ is $d$. Then there exists a $\Lambda \in X^* $ (the dual space of $X$) so that $\| \Lambda\| \leq 1$, $\Lambda(y) = d$ and $\Lambda(z) = 0$ for all $z \in Z$. This corollary is left as an exercise to the reader in chapter 3 of Reed and Simon's Functional Analysis, Corollary 3, page 77 . I assumed that this corollary would be short and have relatively simple ideas as the previous 2 corollaries which were proved, but after multiple fruitless attempts I tried to find some solutions online to similar problems. First I found some variations of the problem, for instance if $Z$ is closed, then one can define a linear functional $\lambda$ from $\operatorname{span}\{ y, Z \}$ to $\mathbb{R}$ by noting that each $x \in \operatorname{span}\{ y, Z \}$ can be written as a unique linear combination $x = \alpha y + z$ where $\alpha \in \mathbb{R}$ and $z \in Z$. Now define $\lambda$ by
$$ \lambda (\alpha y + z) = \alpha$$
This is a linear functional and the kernel of $\lambda$ is the closed subspace $Z$ and hence $\lambda$ is also continuous. The solution then refers to some theorem in which it was proved that 
$$\| \lambda \|_{\operatorname{span}\{ y, Z \}} = \frac{1}{d(0, \lambda^{-1} \{1 \})}$$
Since $\lambda^{-1} \{ 1 \} = y + Z$ it follows that
$$ \| \lambda \|_{\operatorname{span}\{ y, Z \}} = \frac{1}{d(0, y + Z)} = \frac{1}{d(y,Z)} = \frac{1}{d}$$
Now we have $\lambda(y) = 1$, $\lambda(z) = 0$ for all $z \in Z$ and $\| \lambda \|_{\operatorname{span}\{ y, Z \}} = \frac{1}{d}$. By an earlier corollary we may now extend the functional $\lambda$ to a  functional $\lambda'$ on the whole space $X$ and furthermore $\| \lambda'\|_X = \| \lambda \|_{\operatorname{span}\{ y, Z \}}$. Now if we define
$$ \Lambda(x) = d \lambda' (x)$$
then $\Lambda$ has the desired properties. This solution is fine as is, but the book I am using does not mention either of the two important steps (kernel is closed is equivalent to continuity, and the lemma for the relationship between the norm of $\lambda$ and preimage of $1$), so I am unsure if this was the method they had in mind. I am also unsure as to how to force a closed subspace. One method might be for instance to define the functional $\lambda$ from $\overline{\operatorname{span} \{ y, Z\}}$. Does anyone have a completely alternate, perhaps simpler solution, or a way to dodge the fact that subspace $Z$ is not closed?","['functional-analysis', 'banach-spaces']"
1852037,"Find all $a, b, c, d$","Find all $a, b, c, d$ satisfying
$$\frac{x^4+ax^3+bx^2-8x+4}{(x^2+cx+d)^2} = 1$$ My answers are: $$\begin{cases}
d=2\\
d=-2
\end{cases}
\quad \begin{cases}
a=4\\
a=-4
\end{cases} \quad
\begin{cases}
c=2\\
c=-2
\end{cases} \quad
\begin{cases}
b=8\\
b=0
\end{cases}$$ 
Is it right?",['algebra-precalculus']
1852048,Triangle with $3$ unknowns,"I have a situation where I am trying to calculate a leading shot for a character in a 2D top down game.  The enemy character moves with a certain speed $s$, which is applied to its normalized direction vector each game tick--so the game ticks are discrete units of ""time"" as opposed to actual time. I have my character, which shoots a bullet with speed $z$.  During my leading shot calculation, I can aim my character towards the enemy character, and calculate $\phi$ between the line drawn directly between the enemy and my character. I need to somehow calculate $\theta$, the angle I need to shoot the bullet in order to hit the enemy character...the unknowns are: $t$, $\theta$, and the third angle. Can't remember how to do this. Here is a picture of the situation:","['algebra-precalculus', 'trigonometry', 'triangles', 'geometry']"
1852065,uncountability proof [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question In the proof that the set of all sequences whose elements are 0 and 1 if we replace the set of reals with the set of natural numbers wouldn't that lead to the same contradiction that N is a proper subset of itself ?
thank you",['elementary-set-theory']
1852069,Finding a 3-embedded subgroup.,"I have the group of order $108$ , $$G=(((\mathbb{Z}_3 \times \mathbb{Z}_3)\ltimes \mathbb{Z}_3)\ltimes \mathbb{Z}_2) \ltimes \mathbb{Z}_2$$ obtained from an algorithm in GAP, but I need to prove that it has a $3$ -embedded subgroup (a subgroup $H\leq G$ such that $p\mid \ \vert H\vert $ and for any $x\in G-H$ , $p \nmid\ \vert H\cap {}^xH \vert$ where $^{x}H=xHx^{-1}$ ). Does anyone have an idea of how to attack it without using GAP algorithms? If it helps, it's the group with Id $[108,17]$ .","['finite-groups', 'semidirect-product', 'group-theory', 'gap']"
1852071,Idiotic determinant mistake?,"I need to calculate $$\begin{vmatrix} \lambda & -1 & 0 & 0\\ -1 & \lambda & 0 & 0 \\ 0 & 0 & \lambda & -1 \\  0 & 0 & -1 & \lambda \end{vmatrix}.$$ For the life of me I don't see what my mistake is: expanding in the first row we have
$$\lambda^2(\lambda ^2-1)-(-1)(-1)(\lambda ^2-1)= (\lambda^2-1)^2 .$$ What is my error?","['linear-algebra', 'determinant']"
1852072,Confusion Regarding Munkres's Definition of Basis for a Topology,"The definition of Basis for a Topology as given in Munkres's book is as follows, If $X$ is a set, a basis for a topology on $X$ is a collection $\mathcal{B}$ of subsets of $X$ (called basis elements ) such that For each $x∈X$, there is at least one basis element $B$ containing $x$ If $x$ belongs to the intersection of two basis elements $B_1$ and $B_2$, then there is a basis
  element $B_3$ containing $x$ such that $B_3⊆B_1∩B_2$. My question is, In the definition though we are defining ""basis for a topology"", there is no mention of the topology on $X$. What role the topology on $X$ plays in the definition? Is it just a simple printing mistake or I am missing something?","['general-topology', 'definition']"
1852090,Showing that $tf(x) + (1-t)f(y) \leq f(tx + (1-t)y)$,"Suppose that $f: \mathbb{R} \rightarrow \mathbb{R}$ is a twice continuously differentiable function such that $f''(x) \leq 0$. Prove that $$tf(x) + (1-t)f(y) \leq f(tx + (1-t)y)$$
  for any two points $x,y \in \mathbb{R}$ and $0\leq t\leq 1$. I started by attempting to take the second derivative of both sides, but this just gives me an incredibly messy result. Any input greatly appreciated.","['derivatives', 'real-analysis']"
1852130,Why is this proof of the chain rule incorrect?,I saw this proof of the chain rule but it says this is a flawed proof. Why? I guessed the reason it is wrong because you can't substitute $g(x+h)$ and $g(x)$ into in limit.,"['derivatives', 'chain-rule', 'calculus', 'proof-verification']"
1852135,Find the limit: $\lim_{n\to\infty} \frac{ \sum_{i=1}^n\lfloor i^3x \rfloor}{n^4}$,"$$\lim_{n \to {\infty}} \frac{ \sum_{i=1}^n\lfloor i^3x \rfloor}{ n^4}$$ My work
$$\lim_{n \to {\infty}} \frac{ \sum_{i=1}^ni^3x}{ n^4} -\lim_{n \to {\infty}} \frac{ \sum_{i=1}^n{\{i^3x\}}}{ n^4}$$
$$\lim_{n \to {\infty}} \frac{x{((n)(n+1))}^2}{4 {n^4}}-\lim_{n \to {\infty}}\frac{ \sum_{i=1}^n{\{i^3x\}}}{ n^4}$$ {.} represent fractional part Can I say this
 $$\lim_{n \to {\infty}}\frac{ \sum_{i=1}^n{\{i^3x\}}}{ n^4} = 0$$","['ceiling-and-floor-functions', 'limits']"
1852137,Area of a square whose one part is in circle,"A square has two of its vertices on a circle and the other two on a tangent to the circle. If the diameter of the circle is $10$ cm, then what is the area of the square is? My solution: I figured out this diagram What to do after this ?","['circles', 'tangent-line', 'geometry']"
1852169,"How can a $\sin x$ come out of the equation $\frac{d^2}{dx^2}f(x)=-f(x)$ as the solution, while there's no sign of a trigonometric function in it?","This is a differential equation: $$\frac{d^2}{dx^2}f(x)=-f(x)$$ Turns out that the answer is $\sin x$. But HOW?! It is impossible to achieve a trigonometric function by integrating that equation. How have mathematicians solved this? I agree that $\sin x$ is the correct answer because its second derivative is $-\sin x$, but I have no idea how one may have obtained it from the equation. Other examples are like:
$$\frac{d}{dx}f(x)=f(x)$$
Which leads to $e^x$.","['derivatives', 'trigonometry', 'integration', 'ordinary-differential-equations']"
1852208,Solve $\frac{\mathrm{d}y}{\mathrm{d}x} = (x-y)/(x+y)$,"Solve $$\frac { { d }y }{ { d }x } =\frac { x-y }{ x+y } $$ It is homogeneous, thus let $y = vx$. From this, $\frac{\mathrm{d}y}{\mathrm{d}x} = x\frac{\mathrm{d}v}{\mathrm{d}x} + v$ Thus, $v'x + v = (1-v)/(1+v)$ thus, $\frac{2}{1-v} + \ln(v - 1) = \ln(x) + C$. Which by substituion, $\frac{2x}{x-y} + \ln(y - x) = 2\ln(x) + C$ But I cant get it any further",['ordinary-differential-equations']
1852218,Chain rule proof - Apostol,"Apostol calculus I page 174-175 has the proof of chain rule. Theorem states: Let f be the composition of two functions u and v, say $f=u \circ v$. Suppose that both derivatives $v'(x)$ and $u'(y)$ exist, where $y=v(x)$. Then derivative $f'(x)$ also exists and is given by the formula $f'(x)=u'(y).v'(x)$. Proof: The difference quotient for f is (4.12): $\frac{f(x+h)-f(x)}{h}=\frac{u[v(x+h)]-u[v(x)]}{h}$ . Let $y=v(x)$ and let $k=v(x+h)-v(x)$. Then we have $v(x+h)=y+k$ and (4.12) becomes (4.13): $\frac{f(x+h)-f(x)}{h}=\frac{u(y+k)-u(y)}{h}$ . If $k\neq0$,then we multiply and divide by k and obtain (4.14): $\frac{u(y+k)-u(y)}{h}\frac{k}{k}=\frac{u(y+k)-u(y)}{k}\frac{v(x+h)-v(x)}{h}$. When h goes to 0, last quotient on right becomes $v'(x)$. Also, as $h$ goes to $0$, $k$ also goes to $0$ because $k=v(x+h)-v(x)$ and $v$ is continuous at $x$. Therefore the first quotient on the right approaches $u'(y)$ as $h$ tends to zero and this proves the result. $\square$ Although the foregoing argument seems to be the most natural way to proceed, it is not completely general. Since $k=v(x+h)-v(x)$, it may happen that $k=0$ for infinitely many values of $h$ as $h$ tends to zero in which case the passage from (4.13) to (4.14) is not valid. My doubt: 
I have trouble understanding the line ""it may happen that $k=0$ for infinitely many values of $h$ as $h$ tends to zero"" What is this line trying to convey and why is the proof incorrect? Thanks in advance.","['chain-rule', 'calculus']"
1852244,$f : \mathbb{R} \to \mathbb{R}$ (Lipschitz) continuous implies $f(A)$ is Borel for all Borel $A$.,"Full question: Let $(\mathbb{R}, \mathfrak{M}, m)$ denote the measure space $\mathbb{R}$ equipped with the Borel $\sigma$-algebra and the Lebesgue measure. Suppose $f : \mathbb{R} \to \mathbb{R}$ is Lipschitz continuous with Lipschitz constant $L$. Show $f(A) \in \mathfrak{M}$ and $m(f(A)) \le L m(A)$ for all $A \in \mathfrak{M}$. This is a question from an old preliminary exam. I feel quite comfortable, after assuming measurability of $f(A)$, in showing that $m(f(A)) \le L m(A)$ for all $A \in \mathfrak{M}$. I have found similar questions on this site, but none that do not assume $f$ is either one-to-one or onto, as well as the closest one to my question having an accepted answer that says the question is wrong. My progress (aka simple cases): If $A \subset \mathbb{R}$ is connected, we know that $A$ is either a point, or an interval (possibly infinite, and can be open, closed, or half-open). However, since $f$ is continuous, the set $f(A)$ must also be connected, so $f(A)$ is also a point, or an interval. In particular, if $A$ is connected, then $f(A)$ is either an $F_{\sigma}$ or a $G_{\delta}$ set (countable union of closed sets and countable intersection of open sets respectively). If $A \subset \mathbb{R}$ is open, due to the separability of $\mathbb{R}$, it must be a countable union of open intervals, so $A = \cup_{i=1}^{\infty} I_{i}$ for intervals $I_{i}$ and consequently $f(A) = \cup_{i=1}^{\infty} f(I_{i})$ is an $F_{\sigma}$ or $G_{\sigma \delta}$ set (the latter being countable unions of $G_{\delta}$ sets). If $A \subset \mathbb{R}$ is compact, then $f(A)$ is compact, and hence closed. If $A \subset \mathbb{R}$ is closed but not compact, we can write $A = \cup_{n = 1}^{\infty} A \cap [-n,n]$, and consequently, $f(A) = \cup_{n=1}^{\infty} f(A \cap [-n,n])$ is the countable union of compact sets, and hence a $G_{\sigma}$ set. My issue: I know that the Borel hierarchy continues on for an uncountable number of steps. So, I cannot use induction to try to finish the proof based off of these simple cases. So far unsuccessful, but yet a promising idea: I'm tempted to appeal to the monotone class lemma, (see Folland's Real Analysis page 66, Lemma 2.35) by showing that the sets from my simple case combined with some sets that involve $\mathbb{R} \setminus f(A)$ form an algebra and a monotone class, and consequently their $\sigma$-algebra is the same $\sigma$-algebra that is generated by the sets from the simple cases (which I believe is the Borel $\sigma$-algebra). The big guns: There's a remark (2.2.13) on the bottom of page 69 and top of page 70 in Federer's ""Geometric Measure Theory"" that says: If $f : X \to Y$ is continuous, $X$ is a complete, separable metric space, $Y$ is a Hausdorff space, $\mu$ measures $Y$, and every closed subset of $Y$ is $\mu$-measurable, then the $f$ image of every Borel subset of $X$ is $\mu$-measurable. This remark seems to imply the problem is true. However, this remark follows from two sections of Federer's GMT that are far beyond the expected knowledge for the prelim I'm studying for, and the sections are too terse for me to yet understand. Moreover, Federer goes through the process of defining Suslin sets, and considering the image of Borel sets as projections of Suslin sets. Again, none of this seems like ""prelim-level"" material. However, since Lebesgue originally thought he'd proved something along these lines (the error in his proof was found by Suslin) I'd be surprised if there's a more elementary proof. Maybe some of the restrictions in this specific problem make it possible. Thanks for reading. Cheers.","['geometric-measure-theory', 'real-analysis', 'measure-theory']"
1852254,How I can find all solutions of the ODE $(y')^{2}+y^{2}=4$,"I want to find all solutions of this ordinary differential equation:
$$
 (y')^{2}+y^{2}=4
$$ 
but I don't know how. It is impossible by use of series method or Laplace transform?","['ordinary-differential-equations', 'calculus']"
1852277,Is $n^7 - 77$ ever a Fibonacci number?,"As the question title suggests, is $n^7 - 77$ ever a Fibonacci number, where $n$ is a integer?","['fibonacci-numbers', 'algebra-precalculus', 'number-theory', 'contest-math', 'elementary-number-theory']"
1852278,solve $x(x^2+y^2)^{-1/2}+yy\prime(x^2+2y^2)=0$,"Help with this excercise.. :) $$x(x^2+y^2)^{-1/2}+yy\prime(x^2+2y^2)=0$$ the book says it is an exact differential equation, but how? $$x(x^2+y^2)^{-1/2}+yy\prime(x^2+2y^2)=0$$ $$x(x^2+y^2)^{-1/2}dx+y(x^2+2y^2)dy=0$$ $M=x(x^2+y^2)^{-1/2}$ $N=y(x^2+2y^2)$ $$\frac{\partial M}{\partial y}=-\frac{xy}{(x^2+y^2)^{3/2}}$$ $$\frac{\partial N}{\partial x}=2xy$$ I cant find the integrating factor,, :(",['ordinary-differential-equations']
1852300,How can we create arbitrarily long instances of the Euclidean algorithm?,How can we create arbitrarily long instances of the Euclidean algorithm? What kind of numbers are useful? What is the relationship between the size of these numbers and the number of steps?,"['number-theory', 'elementary-number-theory']"
1852366,de Rham cohomology of singular varieties: why completion?,"If $X$ is a smooth variety over an algebraically closed field $k$ of characteristic zero one can define algebraic de Rham complex 
$$
\mathcal{O}_X \to \Omega^1_X \to \ldots \to \Omega_X^n,
$$
where $\Omega^i_X = \wedge^i \Omega^1_X$, $n = \dim X$, and differential is the universal derivative $d: \mathcal{O}_X \to \Omega_X^1$ uniquely extended to $\Omega^\bullet_X$ by the product rule. Sheaves $\Omega^i_X$ can have non-trivial higher cohomology, this is a new phenomenon for algebraic varieties as compared to differential geometry, where the sheaves of differentials are acyclic. For this reason de Rham cohomology of $X$ are defined as the hypercohomology groups of the complex of sheaves
$$
H^i_{dR}(X) = \mathbb{H}^i(\Omega_X^\bullet).
$$ Now let $Y$ be a singular variety. How to define $H^i_{dR}(Y)$? The answer I saw several times is the following. Consider only $Y$ embeddable in a smooth $X$ with the sheaf of ideals $I$. Then take completion of the complex $\Omega_X^\bullet$ along $Y$:
$$
\Omega_Y^\bullet = \varprojlim \Omega_X^\bullet /I^k \Omega_X^\bullet.
$$
Hypercohomology of the completion are by definition the de Rham cohomology of $Y$. I have two questions: What is the idea behind taking the completion? Could we find a resolution of $Y$ inside $X$ as a sheaf of dg
algebras on $X$ and define de Rham cohomology of $Y$ as the de Rham
cohomology of this sheaf of dg algebras?",['algebraic-geometry']
1852384,Linear Algebra Textbook,"I'm looking for a textbook on Linear Algebra and I seem to have narrowed down the list to: Linear Algebra by Hoffman and Kunze; and Linear Algebra by Friedberg, Insel and Spence. I'm not quite sure which textbook to commit to since I can't seem to distinguish between them based on their individual merits and demerits. It'd be great if someone could weigh out the merits and demerits (exercises, content, depth etc.) of both books. Thanks.","['reference-request', 'linear-algebra']"
1852420,What does $\mathbb{R}^n \to \mathbb{R}^m$ mean? And what is $\mathbb{R}^n$?,What the does $\mathbb{R^n}$ mean? For example if something says that it is a transformation $T:\mathbb{R}^2 \rightarrow \mathbb{R}^3$. Does that mean that $\mathbb{R}^2 = 2 \times 2$ matrix? and that $\mathbb{R}^3 = 3 \times 3 $ matrix?,['linear-algebra']
1852464,Why Gaussian elimination on the columns changes the column space?,"This page on theorem 8.2 states that, Neither of the operations of the gaussian elimination changes the row space of an $m \times n$ matrix after applying the operation. It says later that this is only true about the row space and not the column space. I can clearly see how multiplying and adding two vectors does not change the row space. Let's assume any pair of two dimensional non parallel non zero vectors. These vectors span $R^2$. Thus it does not matter how we combine them linearly, they will still span $R^2$. The column space for any two non zero non parallel vectors can be thought of as being two dimensional vectors, spanning another two dimensional space again. Lets call this one $R^2_c$. Now here is my question, doing gaussian elimination on the columns of a matrix, will firstly, do nothing to the span of the column space, $R^2_c$, because that space still can be spanned with the two new column vectors, and secondly, it will result in two new row vectors in $R^2$ that can still span $R^2$. So it seems to me by doing linear combinations on the column space, neither the row nor the column space change. What am I doing wrong?","['self-learning', 'linear-algebra', 'vector-spaces']"
1852465,Probability in coin flip,"The question: Two persons $A$, $B$ simultaneously toss their individual coins, and win $1$ point if head is face up and $0$ points if tails is face up. The probability that the points of $A$ exceeds the points of $B$ after $3$ tosses is... My attempt: Because each person have $4$ available options of how many points they will have in the end $(0,1,2,$ and $3)$, the total amount of ways the score could be after $3$ tosses would be $4 \cdot 4 = 16$. The cases in which person $A$ wins would be $(1,0)$, $(2,0)$, $(2,1)$, $(3,0)$, $(3,1)$, and $(3,2)$. So the answer should be $\frac{6}{16}$ or $\frac{3}{8}$. The actual answer is $\frac{11}{32}$ My question: Where did I go wrong and how do I do it correctly? Thank you!",['probability']
1852470,"Build skew normal distribution knowing the mean, max, and min","Say I have a data point with included errors and I want to build some continuous distribution around it.  Normally this might be a Gaussian because one knows the sigma and mean right off the bat.  However, if you have asymmetric errors it becomes a lot harder.  It seems like you should be able to model a Gaussian about a data point with such errors using a skewed normal distribution, let me know if I am wrong. Essentially, I would like to know if there is a way to generate a standard normal distribution if you know the mean, max, and min?  The mean being the data point, max being the data point plus the upper bound, and min being the data point minus the lower bound.","['statistics', 'normal-distribution']"
1852485,Problem with definition of limit (why not big delta?),"I've been thinking about this for a little bit and I just can't shake my issue. So I'm sure we all know the definition but I'll just write it here: $$ \forall \epsilon > 0, \exists \delta > 0: \forall x \in D \; \text{that satisfy} \; 0 < \vert{x-c}\vert < \delta \; \text{the inequality} \; \vert f(x) - L\vert < \epsilon \; \text{holds}. $$ Now whenever people solve limits using the definition, they always follow a ""you give me an $\epsilon$ neighbourhood around L and I'll give you a $\delta$ neighbourhood around c that snugly fits around the pre-image of the $\epsilon$ neigbourhood."" My question is why does the $\delta$ neighbourhood necessarily fit snugly around the pre-image of the $\epsilon$ neighbourhood? When I think intuitively about limits, what I'd like the definition to be is something like this: ""As I take an increasingly smaller $\epsilon$ neighbourhood around L, if I can find an increasingly smaller $\delta$ neighbourhood around c that contains the preimage of the $\epsilon$ neighbourhood, then $\lim_{x \to c} \ f(x) = L$."" But I don't see that in the standard definition because why can't I take a $\delta$ neighbourhood that is arbitrarily large? For example if I'm considering $$\lim_{x \to 2} 2x$$ Why don't I just set $\delta$ = 1,000,000 or something big if $\epsilon$ = 1 ? and If episolon is two million then I set delta to a billion or whatever? If I set delta arbitrarily large wouldn't I still be satisfying $0 < \vert{x-c}\vert < \delta \; \text{such that the inequality} \; \vert f(x) - L\vert < \epsilon \; \text{holds} $? I just can't figure it out!
Thank you!","['real-analysis', 'limits']"
1852512,Faster way to find Taylor series,"I'm trying to figure out if there is a better way to teach the following Taylor series problem.  I can do the problem myself, but my solution doesn't seem very nice! Let's say I want to find the first $n$ terms (small $n$ - say 3 or 4) in the Taylor series for $$
f(z) = \frac{1}{1+z^2} 
$$ around $z_0 = 2$ (or more generally around any $z_0\neq 0$, to make it interesting!)  Obviously, two methods that come to mind are 1) computing the derivatives $f^{(n)}(z_0)$, which quickly turns into a bit of a mess, and 2) making a change of variables $w = z-z_0$, then computing the power series expansion for $$
g(w) = \frac{1}{1+(w+z_0)^2}
$$ and trying to simplify it, which also turns into a bit of a mess.  Neither approach seems particularly rapid or elegant.  Any thoughts?","['taylor-expansion', 'calculus']"
1852522,primes of the strict henselization,"I'm trying to get some intuition for the (strict) henselization of a local ring. Let $A$ be a local ring with maximal ideal $m$. I'm happy to assume it is Noetherian and normal. Let $p\subset m$ be a prime ideal. From basic facts of the strict henselization, I know that $mA^{h}$ is the unique prime ideal of $A^{h}$ lying above $m$. Is $pA^{h}$ necessarily prime? What about $pA^{sh}$? I'm guessing the answer is no, in which case, how should one think about the primes of $A^h$ or $A^{sh}$ lying over $p$? (For example, if $A$ is the local ring of a point $x$ in a scheme, then the primes of $A$ are ""germs"" of closed subschemes passing through $x$). Do they have the same height? Why is $mA^h, mA^{sh}$ still maximal if $pA^h,pA^{sh}$ isn't? Is it possible to recover $(A_p)^h$ or $(A_p)^{sh}$ from $A^h$ or $A^{sh}$ by localizing $A^h$ or $A^{sh}$ at some prime lying above $p$ and then (strict) henselizing again? What's a good reference for this?","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
1852551,Geometric basis for the real numbers,"I am aware of the standard method of summoning the real numbers into existence -- by considering limits of convergent sequences of quotients. But I never actually think of real numbers in this way. I think of a real number as a vector in 1D Euclidean space, the good old number line. A signed distance.  My intuition is that $\mathbb R$ is something at least as fundamental as $\mathbb Q$: It is the fabric upon which $\mathbb Q$ is drawn. That $\mathbb Q$ is embedded in $\mathbb R$, rather than extending to it. Or maybe side-by-side we could have geometry (defining $\mathbb R$), and  $\mathbb Q$ (constructed by algebra). And we could demonstrate an isomorphism between our $\mathbb Q$ and a matching subset of our $\mathbb R$. The classical extension of $\mathbb Q$ to $\mathbb R$ feels awkward and perverse to me. It doesn't seem right that $\mathbb Q$ should have some prior (or more fundamental) existence. In the same way that any computational system can be simulated on a Conway Game of Life with appropriate starting grid, we could postulate this as an axiomatic setup. But it looks contrived, some kind of entertaining mental contortion. Possibly interesting, but certainly not fundamental to understanding of the science. I like to build my mathematical universe from common sense constructs. A piece of paper (Euclidean plane) equipped with a straightedge and compass. And a counting system. I'm currently looking at Geometric Algebra, which is magnificent! But it requires a scalar field $\mathbb R$. Which means underneath this simplicity is the intricacy of the classical construction of $\mathbb R$ from $\mathbb Q$. I wonder if this is avoidable... It isn't clear to me that one cannot use geometry to define $\mathbb R$. Why should a Euclidean plane be a less valid foundation than $\mathbb Q$? Maybe signed area could be used for multiplication. So if I have a vector -3, I need a perpendicular vector -$1 \over 3$ to ensure the signed area is 1. etc. Is there some effort towards a geometric definition for $\mathbb R$, such that Algebra and Geometry may exist as two wings of the same bird?","['axioms', 'real-numbers', 'geometry']"
1852605,logarithm transition for the population growth equation,"Analyzing the growth population equation I came across with the below transition $$\frac{d \ lnN}{dt}=\frac{dN}{N dt}$$ which I don't quite follow.
Can anybody clarify this please?","['logarithms', 'ordinary-differential-equations']"
1852664,Where to read about sheaves?,"I'm working through Mumford's Red Book, and after introducing the definition of a sheaf, he says ""Sheaves are almost standard nowadays, and we will not develop their properties in detail."" So I guess I need another source to read about sheafs from. Does anybody know of any expository papers that cover them? I'd prefer to not have to dig deep into a separate textbook if possible.","['reference-request', 'sheaf-theory', 'algebraic-geometry']"
1852668,"Show that $\int_{E}{F(x,t)}d\mu\otimes\lambda=\int_{X}{\int_{[\varphi_1(x),\varphi_2(x)]}{F(x,t)d\lambda(t)d\mu(x)}}$","Let $(X,\mathcal{F},\mu)$ be a $\sigma-$finite measure space. Let $\varphi_1,\varphi_2:X\to\mathbb{R}$ functions in $\mathcal{M}(X,\mathcal{F},\mathbb{R})$ such that $\varphi_1(x)\leq\varphi_2(x)$ for all $x\in X$. Consider the set $E=\{(x,t)\in X\times\mathbb{R}:\varphi_1(x)\leq t\leq\varphi_2(x)\}$
Let $F\in L^{1}(X\times\mathbb{R},\mathcal{F}\otimes\mathcal{B}(\mathbb{R}), \mu\otimes\lambda)$. Show that, $$E\in\mathcal{F}\otimes\mathcal{B}(\mathbb{R})$$ $$\int_{E}{F(x,t)}d\mu\otimes\lambda=\int_{X}{\int_{[\varphi_1(x),\varphi_2(x)]}{F(x,t)d\lambda(t)d\mu(x)}}$$ Where $\lambda$ is the lebesgue measure over $\mathcal{B}(\mathbb{R})$. For the second question I use, Fubinni, but someone says to me that is wrong. Any help pls! Thanks!","['lebesgue-measure', 'measure-theory']"
1852691,Why use geometric algebra and not differential forms?,"This is somewhat similar to Are Clifford algebras and differential forms equivalent frameworks for differential geometry? , but I want to restrict discussion to $\mathbb{R}^n$, not arbitrary manifolds. Moreover, I am interested specifically in whether $$(\text{differential forms on }\mathbb{R}^n\text{ + a notion of inner product defined on them}) \simeq \text{geometric algebra over }\mathbb{R}^n$$ where the isomorphism is as Clifford algebras. ( I.e., is geometric algebra just the description of the algebraic properties of differential forms when endowed with a suitable notion of inner product? ) 1. Is any geometric algebra over $\mathbb{R}^n$ isomorphic to the exterior algebra over $\mathbb{R}^n$ in the following senses: as a vector space? ( Should be yes. ) as an exterior algebra? (Obviously they are not isomorphic as Clifford algebras unless our quadratic form is the zero quadratic form.) Since the basis of the geometric algebra (as a vector space) is the same (or at least isomorphic to) the basis of the exterior algebra over $\mathbb{R}^n$, the answer seems to be yes. Also because the standard embedding of any geometric algebra over $\mathbb{R}^n$ into the tensor algebra over $\mathbb{R}^n$ always ""piggybacks"" on the embedding of the exterior algebra over $\mathbb{R}^n$, see this MathOverflow question . 2. Are differential forms the standard construction of an object satisfying the algebraic properties of the exterior algebra over $\mathbb{R}^n$? 3. Does the answers to 1. and 2. being yes imply that the part in yellow is true? EDIT: It seems like the only problem might be that differential forms are covariant tensors, whereas I imagine that multivectors are generally assumed to be contravariant. However, distinguishing between co- and contravariant tensors is a standard issue in tensor analysis, so this doesn't really seem like an important issue to me. Assuming that I am reading this correctly, it seems like the elementary construction of the geometric algebra with respect to the standard inner product over $\mathbb{R}^n$ given by Alan MacDonald here is exactly just the exterior algebra over $\mathbb{R}^n$ with inner product. David Hestenes seems to try and explain some of this somewhat here and here , although I don't quite understand what he is getting at. (Also his claim in the first document that matrix algebra is subsumed by geometric algebra seems completely false, since he only addresses those aspects which relate to alternating tensors.)","['tensors', 'differential-forms', 'soft-question', 'geometric-algebras', 'differential-geometry']"
1852703,Dimensions of bounding box for arbitrary circle sector,"I need to determine the dimensions of bounding box for arbitrary circle sector as shown in the diagram below. Given: φ = Start angle in the range of 0 ~ 2π θ = Sweep angle in the range of 0 ~ 2π r = radius Determine: - Width of bounding box (w) - Height of bounding box (h) - Coordinates of the circle center (C) This problem is for on-screen display, so uses screen coordinates. i.e. x increases to the right, y increases downwards, and positive rotation is clockwise. As far as I can see, the result will be dependent on which quadrant points A and B fall in relative to each other. For example if A falls in the bottom -right quadrant and B in the bottom -left quadrant, then w will be the horizontal distance between A and B.
However if A falls in the bottom -right quadrant and B in the top -left quadrant, then w will be the horizontal distance between A and C plus the radius of the circle (since the left edge of the bounding box will be tangent to the circle). My algorithm to solve this seems to be rapidly becoming overly complex. Is there a simple and efficient way to solve this? Edit Below is the core of the algorithm I've come up with (in JAVA). If anyone has a more efficient approach than this, please let me know. // Calculate end angle
    arcAngleEnd = arcAngleStart + arcAngleSweep;

    /**
     * Do all calculations based on a unit circle for the moment.
     * We'll determine the actual radius later.
     **/

    float uLeft, uTop, uRight, uBottom;

    // Calculate arc Start and End unit vector components.
    float uXstart = (float) Math.cos(Math.toRadians(arcAngleStart));
    float uYstart = (float) Math.sin(Math.toRadians(arcAngleStart));
    float uXend = (float) Math.cos(Math.toRadians(arcAngleEnd));
    float uYend = (float) Math.sin(Math.toRadians(arcAngleEnd));

    // Determine bottom bound
    if ((arcAngleStart <= 90 && arcAngleEnd >= 90) || (arcAngleStart > 90 && arcAngleEnd >= 450)) {

        // Arc crosses the local +y axis
        uBottom = 1;

    } else if (uYstart <=0 && uYend <= 0) {

        // Arc does not extend below the local x axis
        uBottom = 0;

    } else {

        // Bottom bounds will be which ever is greater out of arc start and end points.
        uBottom = Math.max(uYstart, uYend);
    }

    // Determine left bound
    if ((arcAngleStart <= 180 && arcAngleEnd >= 180) || (arcAngleStart > 180 && arcAngleEnd >= 540)) {

        // Arc crosses the local -x axis
        uLeft = -1;

    } else if (uXstart >=0 && uXend >= 0) {

        // Arc does not extend left of the local y axis
        uLeft = 0;

    } else {

        // Left bounds will be which ever is lesser out of arc start and end points.
        uLeft = Math.min(uXstart, uXend);
    }

    // Determine top bound
    if ((arcAngleStart <= 270 && arcAngleEnd >= 270) || (arcAngleStart > 270 && arcAngleEnd >= 630)) {

        // Arc crosses the local -y axis
        uTop = -1;

    } else if (uYstart >=0 && uYend >= 0) {

        // Arc does not extend above the local x axis
        uTop = 0;

    } else {

        // Top bounds will be which ever is lesser out of arc start and end points.
        uTop = Math.min(uYstart, uYend);
    }

    // Determine right bound
    if (arcAngleEnd >= 360) {

        // Arc crosses the local +x axis
        uRight = 1;

    } else if (uXstart <=0 && uXend <= 0) {

        // Arc does not extend right of the local y axis
        uRight = 0;

    } else {

        // Right bounds will be which ever is greater out of arc start and end points.
        uRight = Math.max(uXstart, uXend);
    }","['analytic-geometry', 'trigonometry', 'geometry']"
1852704,Adjoint functors and the classical adjoint,"Is there any relationship between adjoint functors seen in category theory, and the classical adjoint (as in adjoint matrices)?","['category-theory', 'adjoint-functors', 'linear-algebra']"
1852735,A Contour Integral: $ - \frac{1}{2 \pi} \int_{- \infty}^{\infty} dE \; \frac{e^{-iEt}}{E^2 - \omega^2 + i\epsilon}. $,"I'm interested in computing the integral: $$ - \frac{1}{2 \pi} \int_{- \infty}^{\infty} dE \; \frac{e^{-iEt}}{E^2 - \omega^2 + i\epsilon}.  $$ I have two small queries: How does one choose the relevant contour while deciding to the integration. For example, the solution to the problem argues: If $t > 0$, we can add an integral along an
  arc at infinity in the lower half complex $E$ plane, since $e^{-iEt}$ vanishes on this arc. I'm not quite sure how has one pinned down the contour and what does it exactly mean to 'add an integral' to the original integral at hand. If someone could argue on how to approach solving the integral by choosing the relevant contonour (why?), that'd be great. For one of the poles, the solution states that: By the
  residue theorem, the value of the integral is $−2πi$ times this residue. Where does the minus sign come from? Doesn't the residue theorem state that the value of the integral on a closed contour enclosing a pole is $2πi$ times this residue? Thanks.","['complex-analysis', 'contour-integration', 'residue-calculus']"
1852745,Summation with combinations,"Prove that $n$ divides $$\sum_{d \mid \gcd(n,k)} \mu(d) \binom{n/d}{k/d}$$ for every natural number $n$ and for every $k$ where $1 \leq k \leq n.$ Note: $\mu(n)$ denotes the Möbius function. I have tried numerous values for this summation and the result seems to hold true. For example, if $n = 20, k = 12$ $$\sum_{d \mid 4} \mu(d) \binom{20/d}{12/d} = \mu(1) \binom{20}{12}+\mu(2) \binom{10}{6}+\mu(4)\binom{5}{3} = \binom{20}{12}-\binom{10}{6}=125760,$$ which is divisible by $20$. Similarly if we tried it for any $k$ with $1 \leq k\leq 20$, we would have $20$ divide the expression. How do I prove this result in the general case? That is, given any positive integer $n$, for all $k$ with $1 \leq k \leq n$ $$n \mid \sum_{d \mid \gcd(n,k)} \mu(d) \binom{n/d}{k/d}.$$","['number-theory', 'combinatorics']"
1852755,The map $f:\mathbb{Z}_3 \to \mathbb{Z}_6$ given by $f(x + 3\mathbb{Z}) = x + 6\mathbb{Z}$ is not well-defined,"By naming an equivalence class in the domain that is assigned at least two different values prove that the following is not a well defined function. $$f : \Bbb Z_{3} \to \Bbb Z_{6} \;\;\;\text{ given by } f(\overline x) = [x]  $$ In this case we represent an element of the domain as an $\bar x$ and use the notation $[x]$ for equivalence classes in the co-domain. $f(\overline0) =  [0] \;,$  $ \Bbb Z_{3}  \quad (3x+0)\;\; \overline 0 = \{ ...-6,-3,0,3,6...  \}, \; \Bbb Z_{6}\;  (6x+0)\; \overline0 =\{ ...-12,-6,0,6,12...\}$ $f(\overline1) = [1], $ $\qquad   \; (3x+1) \; \;\;\;\overline   1 = \{ ...-5,-2,1,4,7 ... \},\; \;  (6x+1)\;\overline1 =\{...-11,-5,1,7,13.. \}$ $f(\overline2) = [2], $ $\qquad  \qquad \qquad \;\overline 2 = \{ ...-4,-3,2,5,8 ... \},\;\;\overline 2 = \{ ...-10,-4,2,8,14  ...\},\;$ $f(\overline3) = [3] ,$  $\qquad \qquad \qquad \qquad \qquad \qquad,\; \quad \quad \quad \; \; \; \;\overline 3 = \{ ...-9,-3,3,9,15 ... \},$ $f(\overline4) =  [4],\qquad \qquad \qquad\qquad \qquad\qquad \; \quad \quad \quad \quad \; \;\overline 4 = \{ ...-8,-2,4,10,16...  \}, $ $f(\overline5) = [5], \qquad \qquad \qquad\qquad \qquad\qquad \; \quad \quad \quad \quad \;\;\overline 5 = \{ ...-7,-1,5,11,17...  \},  $ $f(\overline6) = [6] ,$ So my main question for this problem is how to find out if this question is not a function. From the information I have gathered here I still cannot see why this is not a function any help on showing how this is not function would be much appreciated. The set of equivalence classes for the relation $\cong_{m}$ is denoted $\Bbb Z_{m}$ The $ 3x+0 \text{ and } 6x+0$ are just showing how I got $\overline 0 $","['relations', 'equivalence-relations', 'functions']"
