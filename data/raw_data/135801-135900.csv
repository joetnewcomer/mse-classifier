question_id,title,body,tags
2152074,How to establish the identity of the infinite sum,How to prove the following identity? $$\sum_{n=-\infty}^{\infty}\frac{1}{(z+n)^2 +a^2} = \frac{\pi}{a}\cdot\frac{\sinh 2\pi a}{\cosh 2\pi a - \cos 2\pi z}$$,"['complex-analysis', 'fourier-analysis', 'sequences-and-series']"
2152116,Expectation of truncated log-normal,"Let's assume that $y=e^x$, where $x\sim N(\mu,\sigma^2)$, that is, $y$ follows a lognormal distribution. I'm interested in finding how $\mathbb{E}\left[y|y\geq a\right]$ varies with $\mu$ and $\sigma$. From https://en.wikipedia.org/wiki/Log-normal_distribution , it is to see that $$
\mathbb{E}\left[y|y\geq a\right]=\frac{\int_{a}^{\infty}yf\left(y\right)dy}{\int_{a}^{\infty}f\left(y\right)dy}=\underbrace{e^{\mu+\frac{1}{2}\sigma^{2}}}_{\mathbb{E}\left[y\right]}\frac{\Phi\left(\sigma-\frac{\ln a-\mu}{\sigma}\right)}{1-\Phi\left(\frac{\ln a-\mu}{\sigma}\right)}
.$$
So formally, if we define $h(\mu,\sigma) = \mathbb{E}\left[y|y\geq a\right]$, I want to understand $\frac{\partial h}{\partial\mu}$ and $ \frac{\partial h}{\partial\sigma} $, for any value of $a$.
I've tried to work out the derivatives, but I always find that both can take any sign. I'm not surprised that  $ \frac{\partial h}{\partial\sigma} $ can take any sign, but, shouldn't there be a way to prove that 
$$ \frac{\partial h}{\partial\mu} >0 ?$$ Is there a counterexample otherwise?","['statistics', 'normal-distribution', 'probability-distributions']"
2152214,3-fold simple branched cover,Where can I find a proof of the fact that every surface (with one boundary component) is 3-fold simple branched cover of the 2-sphere (2-disc)? I have seen this result in different places but without any reference to a proof.,"['algebraic-topology', 'complex-analysis', 'covering-spaces']"
2152228,About the sigma additivity of volume of half-open cubes in $\mathbb{R}^n$,"Many texts (Fremlin, Stroock,etc.) on measure theory seem to think this is a difficult lemma to prove. Tao proves this in a indirect way by approximating volume with the number of grid points. If $J_1, \dots , J_n$ are half-open covering $I$, then $\mu(I) \le \sum\limits_{i=1}^{n} {\mu(J_i)}$. (where $\mu$ is the standard volume in $\mathbb{R}^n$) But I have a proof in mind which is very clear and short, so I would like to know if there are issues with it. First, any nonempty half-open cube $K$ is uniquely written as 
$[a,b) := \{x|a \le x < b\}$ where inequality is component-wise. 
(I call $l(K):=a$ the left endpoint and $r(K):=b$ the right) Take $K_i = J_i \cap I$. Then $\mu(K_i) \le \mu(J_i)$ since 
$l(J_i) \le l(K_i) \le r(K_i) \le r(J_i)$ Now, let $L_j := \{l(K_i)_j\} \cup \{r(K_i)_j\} \cup \{l(I),r(I)\}$
where for example $l(K_i)_j$ is the $j$th component of $l(K_i)$.
(Basically I'm projecting the cubes on each component) Order each $L_j$ and consider the half-open cubes 
$[((L_1)_{a_1},\dots,(L_n)_{a_n}),((L_1)_{a_1+1},\dots,(L_n)_{a_n+1}))$ 
where each $a_j \le \#(L_j)-1$ (basically I'm considering the paritition into subcubes based on paritions) Now $\mu(I)$ is the sum of the volume of the subcubes. But each subcube lies entirely in some $K_i$ (if $x$ and $y$ are in the same subcube and 
$x \in K_i$ then $\forall j$, $x_j \in [l(K_i)_j,r(K_i)_j)$,
suppose $y_j \not\in [l(K_i)_j,r(K_i)_j)$ then there is an element of $L_j$ between two adjacent elements, so contradiction) And $\mu(K_i)$ is the sum of the volume of the subcubes in it, so we are done. This might look long but it's a simple idea, is it missing any important steps?","['lebesgue-measure', 'measure-theory', 'proof-verification']"
2152230,How to extract parameters of normal distribution from squared observations?,"Suppose I know the random variables follow normal distribution, i.e.,
$X\sim\mathcal(\mu,\sigma^2)$, but I can only observe the square of each sample $X^2_i$. How could I extract the parameters of $\mu$ and $\sigma$. I am thinking of moment matching, but it is unclear to me how to proceed. Anybody can help?","['machine-learning', 'statistics', 'estimation', 'random-variables']"
2152242,Derivative of $f(x)=e^7+\ln(4)$.,"I need to differentiate $$f(x)=e^7+\ln(4).$$ I know that $\dfrac d{dx}e^x = e^x$ and $\dfrac d{dx}\ln(x) = \dfrac {1}{x}$. I recently learned this, but I get stuck when it comes to solving this problem using real numbers. Can someone guide me with an example?","['derivatives', 'calculus']"
2152256,Big O notation on the log factorial,"For the computation of the log factorial, i.e., $\log(n!)$, is the Big(O) run time for this $n\log(n)$? How can this be assumed graphically? ***Update: How does the sum of $\log(n!)$ work then? I.e., the sum of log Factorial?","['asymptotics', 'discrete-mathematics']"
2152269,Contour integral of $\int_{-\infty}^\infty \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx$,"I'm having a little trouble figuring this one out. So far I've got
$$I = \int_{-\infty}^\infty \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx$$
Let 
$$I' = \oint_C \frac{e^{2\pi z / 3}}{\cosh{\pi z}}dz$$ Where the contour $C$ is a rectangle extending from $-R$ to $R$ in the limit of $R \rightarrow \infty$ and of height 1, which gives $$\int_{-R}^R \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx + \int_{R}^{-R} \frac{e^{2\pi x / 3 + i}}{\cosh{(\pi x + i)}}dx$$
$$=I - \int_{-R}^R \frac{e^{2\pi x / 3 + i}}{\cosh{(\pi x + i)}}dx$$
$$=\text{Res}(z = \frac{i}{z})$$ I'm having trouble solving the problem from here, as I'm not sure how to handle the separation of the denominator $\cosh{(\pi x + i)}$. Any help is appreciated!","['complex-analysis', 'contour-integration']"
2152271,Integral of a gradient over a plane area,"Let $A$ be a plane area bounded by a curve $\partial A$. Then, is $$ \iint_A \nabla f\, \textrm{d}x \textrm{d}y = \oint_{\partial A} f\ \hat{\mathbf{n}}\ dl $$ where $f=f(x,y)$ and $\mathbf{\hat n}$ is the outward unit normal?","['multivariable-calculus', 'integration', 'calculus']"
2152296,Conditional expectation and Iterated expectation problem,"I have $X_i|b_i \sim Poisson(\lambda_i)$, and $log(\lambda_i)=x_i^t\beta+\varepsilon_i$ further $\varepsilon\sim N(0,\sigma^2)$ then, how to find $E(X_i)$? I try using the iterated expectation $E(X_i)=E[E(X_i|b_i)]$, so $E(X_i)=E(\lambda_i)$ but how to use $log(\lambda)$ to find the solution? thanks.","['probability-theory', 'expectation', 'statistics']"
2152329,"Are column vectors considered the ""default"" orientation in linear algebra?","I am taking an online course where vectors are typically written out as column vectors. It seems like the only row vectors we have seen are the transposes of column vectors and labeled as such. So I'm wondering if mathematicians (at least those in linear algebra) tend to favor column vectors. This is essentially a question about convention, i.e. is it such a strong convention that if you told a mathematician about a vector without specifying its alignment, would they assume it is a column vector? Come to think of it I guess that might make sense since it is the first dimension.","['notation', 'convention', 'linear-algebra', 'vectors']"
2152348,Does the matrix exponential have this convexity property?,"Let $A$ be a real matrix (not necessarily symmetric) whose off-diagonal elements are all non-negative, so that the elements of the matrix exponential $\exp(A)$ are all non-negative. Let $\mathbf x$ be a vector whose elements are all non-negative. Let $\sum(\cdot)$ denote the sum of all the terms in a vector. I hypothesise that the function $f(t) = \log \,\sum\big(\exp(At)\, \mathbf x\big)$ is a convex function of $t$. Note that '$\log$' in this formula is an ordinary logarithm while '$\exp$' is a matrix exponential. From playing around with this I haven't found an easy way to show it, but I haven't found an obvious counterexample either. So my question is, is $f(t) = \log\, \sum\big(\exp(At)\, \mathbf x\big)$ a convex function of $t$, if the entries of $A$ and $\mathbf x$ are non-negative? For the avoidance of doubt, and for ease of searching for counterexamples, here is some Python code that calculates $f(t)$. ( A and x should be numpy arrays of the appropriate dimensions.) import numpy as np
import scipy.linalg as spl

def f(t, A, x):
    return np.log(np.sum(spl.expm(A*t).dot(x))) Notes Originally I was using the convention that ""convex"" means a downward curve, i.e. the second derivative is never positive. However, Jonas Meyer points out in a comment that there are examples where the second derivative is consistently positive. So now I guess my question is, can the second derivative of $f(t)$ change sign as a function of $t$? I'm mostly only interested in part of the function where $t>0$, though in examples it seems to work for $t<0$ as well, until the sum of the elements becomes negative. It might be necessary to make additional assumptions about $A$ and $\mathbf x$, e.g. that $\exp(A)$ is irreducible, or that $\mathbf x$ has all positive elements. If that's the case I'd like to know. The motivation has to do with growing populations in biology. It's equivalent to asking whether the per capita rate of population growth is always non-increasing in a simple model of a growing (or shrinking) population. This question is obviously closely related but not the same, and my hypothesis doesn't seem to immediately follow from that result. The result will be true if the elements of $\exp(At)$ are log-convex, which would be a generally useful result to know about if it's true. It turns out not to be the case that all the elements of $\exp(At)$ are either consistently all convex upward or convex downward; they can change from one to the other as a function of $t$. See my related MathOverflow question . This makes me skeptical that the hypothesis in this (Math.SE) question is true. Here is an example of what it tends to look like. For this example,
$$
A = \begin{pmatrix}1,1\\4,1\end{pmatrix}, \qquad \mathbf{x} = \begin{pmatrix}1\\0\end{pmatrix}.
$$","['biology', 'real-analysis', 'linear-algebra']"
2152349,Approximation of Exponentially and Normally Distributed Probabilities,PROBLEM A company uses a portable high-intensity flashlight: Batteries and bulbs burn out quickly. The lifetime of batteries has Exponential Distribution with mean $10$ hours. The bulbs have lifetimes that are Normally Distributed with mean $32$ and standard deviation $5$ . Assume batteries and bulbs are randomly sampled. Find the probabilities for the following events: [Where appropriate you may approximate probabilities] A battery lasts over $11$ hours. A sample of $20$ batteries has a sample mean over $11$ hours. A sample of $200$ batteries has a sample mean over $11$ hours. I am not sure how to solve these questions because I've only learned approximating with the normal distribution to the binomial. Any suggestions?,"['normal-distribution', 'probability-distributions', 'statistics', 'exponential-distribution', 'word-problem']"
2152350,"How to find $k$ such that $(\mathbb{Z} \times \mathbb{Z})/ \langle (m,n)\rangle \cong \mathbb{Z} \times \mathbb{Z}_k$","In John Fraleigh's book, A First Course In Abstract Algebra Exercises 15.7 and 15.11, one shows that 
$$
(\mathbb{Z} \times \mathbb{Z})/ \langle (1,2)\rangle \cong \mathbb{Z} \times \mathbb{Z}_1 \cong \mathbb{Z} \ \ \ \ \  \mbox{ and  } \ \ \ \ \ (\mathbb{Z} \times \mathbb{Z})/ \langle (2,2)\rangle \cong \mathbb{Z} \times \mathbb{Z}_2
$$ 
One does this with the first isomorphism theorem. With the same idea I proved for example that 
$$
(\mathbb{Z} \times \mathbb{Z})/ \langle (2,3)\rangle \cong \mathbb{Z} \times \mathbb{Z}_1 \cong \mathbb{Z} \ \ \ \ \ \mbox{ and }\ \ \ \ \ (\mathbb{Z} \times \mathbb{Z})/ \langle (2,4)\rangle \cong \mathbb{Z} \times \mathbb{Z}_2
$$
So I conjectured that $(\mathbb{Z} \times \mathbb{Z})/ \langle (m,n)\rangle \cong \mathbb{Z} \times \mathbb{Z}_{k}$ where $k=\mathrm{gdc}(m,n)$. For the previous four cases, the homomorphism $\phi: \mathbb{Z}\times \mathbb{Z} \to \mathbb{Z} \times\mathbb{Z}_k$ given by
$$
\phi(x,y)=\left(\frac{nx-my}{k}, \ x \ \ (\mathrm{mod} \ k) \right)
$$
is surjective with kernel =$\langle (m,n)\rangle$. However, this is not the case when $(m,n)=(4,6)$. So, I cannot use what I did for the four cases to prove the general case. What I want to know is if my conjecture is true. If so, how can I give a general homomorphism? If it is not true, how can I find $k$, such that $(\mathbb{Z} \times \mathbb{Z})/ \langle (m,n)\rangle \cong \mathbb{Z} \times \mathbb{Z}_k$? Thanks in advance for any help/hint/comment!","['abstract-algebra', 'quotient-spaces', 'group-isomorphism']"
2152354,Find a bijection between sets of functions,"Let $\mathcal{F}(A,\,B)=\{f \text{ function}\,:\,f:A\to B \}$, so I have to determine a bijection between $\mathcal{F}(A,\,B)$ and $\mathcal{F}(A-\{a\},\,B)$, with $a\in A$. I'm having a little trouble with this one, every help will be really appreciated.","['algebra-precalculus', 'functions']"
2152360,"why do people say ""x dimensional vector"" when vectors have only one dimension?","I am new to linear algebra and have been confused by the terminology ""n dimensional vector"" that my online course instructor uses. He refers to vectors as an ""n dimensional vector"" where n is the number of elements in the vector. For example he might say that this is a 5-dimensional vector: [10 15 20 25 30] However by definition a vector is 1D. I guess this is an etymology question, but why would people use such confusing terminology? If somebody said something was a ""5 dimensional matrix"" I assume nobody would think that means it has 5 elements, rather they would think it has 5 dimensions, so why do they talk about vectors differently?","['matrices', 'vectors']"
2152365,Determine if a set of graphs are isomorphic,"I am trying to use adjacency matrices to show if the graphs are isomorphic. I have created the matrices but am finding it hard to interpret them to find a pair (or more) of isomorphic graphs for each A, B and C. I am comparing the matrices to see if they can be ""rearranged"" to look like another matrix. Is this a poor way to check if graphs are isomorphic?? Isn't graphs that are isomorphic able to be ""redrawn"" to look like each other? Would this make all graphs in A and B not possible to be isomorphic?","['graph-theory', 'discrete-mathematics']"
2152374,Use infinite series to prove,"Use infinite series to prove that $$\arcsin{x}\lt \frac{x}{1-x^2},$$ for $0\lt x\lt1$.","['power-series', 'inequality', 'trigonometry', 'sequences-and-series']"
2152392,a stupid question about function's limit,"Ok so recently I was doing a problem about limit. I know that every rational function that has a same exponent for the numerator and denominator will result in a definite number( I dont know if my wording is right but I just mean $ \lim_{x\rightarrow \infty }\frac{\sqrt{x^{2}+2}}{x}=1$. However I was thinking about the range: if this particular function wont actually head become exactly $1$ and it is describing the ratio of a sequence, will a number in the sequence become infinite large because the ratio is always larger than one? Or is there a particular number that the number in the sequence can't exceed( I actually will be gald to see if there is a maximum ratio and the number in the sequence cannot exceed a particular number...)? If someone can answer me I will be really glad...(a stupid precal student wrote this so plz dont judge me) Sorry i have extremely bad wording but I mean if this function is only describing the ratio between elements in a set and the elements itself is dependent on the function( new element is the ratio times previous element) and the function is dependent on the elements( the x value in the ratio function is a element in the set that has the ""latest value"")will the set have infinitely many numbers and their quantitative value will head toward infinite since the ratio is always a little greater than one?","['linear-algebra', 'functions']"
2152410,When does convergence in measure imply convergence almost everywhere?,"I know that convergence almost everywhere implies convergences in measure(sometime it said locally). I also know that convergence in measure implies the existence of subsequence which is convergent almost everywhere. However I wonder if there are some additional conditions from which the convergence in measure will imply convergence almost everywhere (for a whole sequence, not just subsequence). Please don't mention discreteness. Let's just take real line for example, and a sequence of functions on it. Thank you, for any help.","['real-analysis', 'measure-theory', 'convergence-divergence']"
2152413,are all vectors position vectors?,"So i have two questions: 1) If Vectors (say in R2) are independent of their location in space, then couldn't you theoretically for any vector in R2 regardless of its position, just move it such that its tail emanates from the origin to become a position vector? 2) Can we represent all positions/points in the 2D coordinate system as position vectors, and does that mean all points in the 2D coordinate system are just vectors emanating from the origin?","['linear-algebra', 'vectors']"
2152429,Does Leibniz's rule hold for improper integrals?,"Does this hold in general?
$$
\frac{\mathrm{d}}{\mathrm{d}t}\int_{-\infty}^{\infty} f(x,t) \mathrm{d}x = \int_{-\infty}^{\infty}\frac{\partial}{\partial t}f(x,t) \mathrm{d}x.
$$
I know it is true if the bounds on the integral are finite but can the result be extended to improper integrals? Also if it is true in special cases, what are those cases? Thanks a lot!","['improper-integrals', 'integration', 'calculus']"
2152514,Predicates and quantifier,"I am working on predicates and quantifier and got confused. Can someone explain this? “All lions are fierce.” “Some lions do not drink coffee.” “Some fierce creatures do not drink coffee.” Let P(x), Q(x), and R(x) be the statements “x is
a lion,” “x is fierce,” and “x drinks coffee,” respectively Here is the answers for those statements $\forall$x(P (x) → Q(x)). ∃x(P (x) ∧ ¬R(x)). ∃x(Q(x) ∧ ¬R(x)). In this problem, Can someone explain why using ""∧"" in 2nd and 3rd statements ? I do not really understand when i need to use → and ∧. What is the differences ?",['discrete-mathematics']
2152542,Numerical coefficient of a quintic function,"Let $P( x )$ be a polynomial of degree $5$. If  $P(1)=0$ , $ \ $ $P(3)=1$, $ \ $ $P(9)=2$, $ \ $ $P(27)=3$, $ \ $$P(81)=4$, $ \ $$P(243)=5$,  what is the numerical coefficient of $x$ in $P( x )$? I tried Lagrange interpolation as method and got $121/162$ but somehow in looking for the its high school level solution... any idea how to solve this is greatly appreciated. Tnx in advance...",['functions']
2152562,Sum of random variables at least $\log n$,"Let $X_1,\dots,X_n$ be independent random variables in $\{0,1\}$, and $X=X_1+\dots+X_n$. Suppose that $\mathbb{E}[X]=1$. What is the best possible upper bound on $\text{Pr}(X>\log n)$? Using the multiplicative form of Chernoff's bound , we have that $\text{Pr}(X>1+\delta)<\dfrac{e^\delta}{(1+\delta)^{1+\delta}}$ for any $\delta>0$. When $\delta$ is $\log n-1$, then this becomes $\dfrac{e^{\log n-1}}{\log n^{\log n}}$. This is approximately $n^{1-\log\log n}$. Are there examples of random variables $X_1,\dots,X_n$ that shows that this bound resulting from Chernoff is (approximately) tight?","['expectation', 'probability', 'random-variables']"
2152588,"If a linear operator commutes with right shift in $\ell^p$, then it is continuous","I'm studying for a PHD qualifying exam and I got stuck with this problem: Let $p\ge 1$ and $l^p:= L^p(\mathbb{N},\mu)$, where $\mu$ is the counting measure. Let $S:\ell^p\rightarrow \ell^p$ the right shift operator defined by $$S(x_1,x_2,\cdots)=(0,x_1,x_2,\cdots)$$ and suppose that the linear operator $T:\ell^p\rightarrow\ell^p$ satisfies $TS=ST$. Prove that $T$ is continuous. I tried the following approach: First I defined $\{e_j\}_{j=1}^\infty$ as the subset of $l^p$ given by $e_j(n)=\delta_{jn}$, where $\delta_{jn}=1$ if $j=n$ and $\delta_{jn}=0$ otherwise. Noticing that $S^m e_j=e_{j+m}$ I managed to prove $||T(e_{j+1})||_p\le ||T(e_1)||_p$ using the fact that $ST=TS$. I chose to name $C:=||T(e_1)||_p$. Then I let $||x||=1$ and tried to prove $||Tx||_p \le K$ for some constant $K$ by doing the following: $$||Tx||_p=||T(\sum_{n=1}^\infty x_n e_n)||_p = ||\sum_{n=1}^N T(x_ne_n)+T\sum_{n=N+1}^\infty x_n e_n||_p\le ||\sum_{n=1}^N x_n T(e_n)||_p+||T\sum_{n=N+1}^\infty x_ne_n||_p\le \sum_{n=1}^N  ||x_n T(e_n)||_p+||T\sum_{n=N+1}^\infty x_n e_n||_p \le \sum_{n=1}^n |x_n| ||T(e_n)||_p+||T\sum_{n=N+1}^\infty x_n e_n||_p\le \sum_{n=1}^N C|x_n|+ ||T \sum_{n=N+1}^\infty x_n e_n ||_p =C\sum_{n=1}^N |x_n|+ ||T\sum_{n=N+1}^\infty x_n e_n ||_p =C\sum_{n=1}^N |x_n|+||T\sum_{n=N+1}^\infty x_n e_n||_p. $$ Then, if I let $N\rightarrow \infty$ I get $||Tx||_p\le C||x||_1$. This works if $p=1$, but fails for greater values of $p$ since I have no guarantee that $x\in \ell^1$ if $p>1$. I looked for books and articles about linear operators that commute with the shift operator but I only found papers with several lemmas that I couldn't figure out while taking the test with a time limit. I Also tried to generalize the previous discussion by placing $p$ in different parts of the expresions, but I didn't get anything useful. The last approach I tried was noticing that if $L$ is the left shift operator we get $T=LTS$, also $||T||$ and $||S||=1$. Sadly, I didn't get anything nice with that. I'm looking for a hint that allows me to generalize my proof for $p\ge 1$ or a totally different solution or hint to solve it. The problem isn't clear about if I need to prove it for $\ell^\infty$, but I'll be happy if I understand the finite case. Any help is appreciated.","['functional-analysis', 'lp-spaces']"
2152726,On the limit of $\sin^2 (\pi\sqrt{n^2+n})$,What is the limit of the sequence $\sin^2 (\pi\sqrt{n^2+n})$ as $n$ tends to infinity? My Attemp: I replace the square root with $n+\frac 12$ (its equivalent) and the rest is routine: $\lim \sin^2 (\pi\sqrt{n^2+n}) = \lim \sin^2 (\pi n + \frac{\pi}2) = 1$ Is this correct?,"['convergence-divergence', 'sequences-and-series', 'calculus', 'limits']"
2152735,"What does ""open set"" mean in the concept of a topology?","Given the following definition of topology, I am confused about the concept of ""open sets"". 2.2 Topological Space. We use some of the properties of open sets in the case of metric spaces in order to define what is meant in general by a class of open sets and by a topology. Definition 2.2. Let $X$ be a nonempty set. A topology $\mathcal{T}$ for $X$ is a collection of subsets of $X$ such that $\emptyset,X\in\mathcal{T}$ , and $\mathcal{T}$ is closed under arbitrary unions and finite intersections. We say $(X,\mathcal{T})$ is a topological space . Members of $\mathcal{T}$ are called open sets. If $x\in X$ then a neighbourhood of $x$ is an open set containing $x$ . It seems to me that the definition of an open subset is that subset $A$ of a metric space $X$ is called open if for every point $x \in A$ there exists $r>0$ such that $B_r(x)\subseteq A$ . What is the difference of being open in a metric space and being open in a topological space? Thanks so much.","['general-topology', 'metric-spaces']"
2152751,Why does the eigenvalues of $AA^T$ are the squares of the singular values of $A$?,"Let $A$ where it's non-zero singular values are $\sigma_1,\ldots,\sigma_r$. $A$ can be written as $A=U\Sigma V$ where both $U,V$ are unitary matrices. Let's look at $$AA^T = U\Sigma V^TV\Sigma U^T= U\Sigma^2 U^T$$ Now, from this point one should infer that the eigenvalues of $AA^T$ are $\sigma_1^2,\ldots,\sigma_r^2$ but I'm not sure how exactly. Is that has something to do with the fact that $U$ is unitary?","['matrices', 'svd', 'numerical-methods', 'linear-algebra']"
2152754,Calculate 3D triangle area by determinant,"It is well known that the area of the triangle (with vertices $a, b, c$) can be calculated as $ \frac{1}{2}\det\left(\begin{bmatrix} a - c \\ b - c \end{bmatrix}\right) = \frac{1}{2}\det\left(\begin{bmatrix} a_x - c_x, a_y - c_y \\ b_x - c_x, b_y - c_y \end{bmatrix}\right)$ But what if I want to calculate the area of a triangle in 3 (or any higher) dimensions? I tried to extend the matrix as $ \begin{bmatrix} a_x - c_x, a_y - c_y, a_z - c_z \\ b_x - c_x, b_y - c_y, b_z - c_z \\ 1, 1, 1 \end{bmatrix}$ and $ \begin{bmatrix} a_x - c_x, a_y - c_y, a_z - c_z \\ b_x - c_x, b_y - c_y, b_z - c_z \\ 0, 0, 1 \end{bmatrix}$ but I got incorrect results. I'm not interested in solutions involving cross products.","['euclidean-geometry', 'geometry', 'linear-algebra', 'vectors', 'vector-spaces']"
2152822,Making sense of measure-theoretic definition of random variable,"I have some understanding of measure theory / real analysis, and some understanding of probability theory, but I'm having some trouble putting the two together. According to Wikipedia: Let $(\Omega, \mathcal{F}, P)$ be a probability space and $(E, \mathcal{E})$ a measurable space. Then an $(E, \mathcal{E})$-valued random variable is a function $X : \Omega \to \mathcal{E}$ which is $(\mathcal{F}, \mathcal{E})$-measurable. Now for example, let's take $X$ be a standard Gaussian random variable, $X \sim \mathcal{N}(0, 1)$. I think $E = \mathbb{R}$ since $X$ takes values in $\mathbb{R}$. Also, we should have $\mathcal{E} = \mathscr{B}(\mathbb{R})$ the Borel $\sigma$-field of $\mathbb{R}$. But, what should $(\Omega, \mathcal{F}, P)$ be? Furthermore, let's try to calculate $\mathbb{E}[X]$ the mean of $X$. By Wikipedia's definition, $$\mathbb{E}[X] = \int_\Omega X\, dP = \int_\Omega X(\omega)\, P(d\omega).$$ This raises some questions. How does this relate to the elementary computation:
$$\mathbb{E}[X] = \int_{-\infty}^{\infty} x\cdot f_X(x)\, dx$$
How does $f_X : \mathbb{R} \to \mathbb{R}^{\geq 0}$ relate to the measure-theoretic definition of $X$? What is the meaning of $P(d\omega)$? $P$ is a measure so it makes sense to integrate $dP$, but what is $d\omega$?","['probability-theory', 'measure-theory']"
2152866,3 plate dinner problem,Consider n people dining in a circular table. Each of them is ordering one of three plates. What is the probability that no two people sitting next to one another will order the same plate? I intuitively think that every person except the first one has 2 choices as he cannot order the same as the one preceding him. However i can't figure out what happens with the last person as he can have either 1 or 2 choices depending whether the person before him had chosen the same dinner as the first person.,"['combinatorics', 'probability']"
2152878,Intuition and practical examples of probability laws over infinite-dimensional spaces,"I need to get familiar with probabilities over separable Hilbert spaces. It's a bit difficult for me to think of something as a probability distribution over a space of function: I can't imagine how it could be defined, but in terms of finite-dimensional objects. For example, let's consider the only probability distribution over a function space that I know of: the Gaussian Process. We say that $f\sim GP(\mu(x),c(x,x'))$ if, for any finite set $X_n=\{x_1, \dots, x_n\}$, $\mathbf{f}=(f(x_1),\dots,f(x_n))$ is a random vector having the multivariate normal distribution $\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})$ with $\boldsymbol{\mu}=(\mu(x_1),\dots,\mu(_n))$ and $\boldsymbol{\Sigma}$ is a symmetric positive definite matrix with components $\Sigma_{ij}=c(x_i,x_j)$. Are there other practical examples of probability laws over function spaces? Are they always defined in terms of probability distributions of finite-dimensional vectors/matrices, or is it possible to define them directly in terms of infinite-dimensional objects? Also, does it makes sense to talk about a CDF for infinite-dimensional objects? It seems to me that we can at least talk of a Cumulative Distribution Functional . For example, it could make sense to compute $P(F(x)<g(x))$ where $F(x)$ is my random function and $g(x)$ is any element of the separable Hilbert space, by interpreting the above inequality in the natural sense. I.e., we ask ourselves which is the probability that $F$ is less than $g$ for all $x\in X$ where $X$ is the domain of the functions in our separable Hilbert space. Then the role of the CDF in finite-dimensional probability spaces would be taken by the functional $\mathcal{F}(g)=P(F(x)<g(x))$. I don't know how useful this construct would be, though: I don't even know if it makes sense to talk about continuous functionals (I seem to remember from Functional Analysis that you only considered continuous linear functionals, but this functional is obviously not linear).","['probability-theory', 'hilbert-spaces', 'probability-distributions']"
2152925,Decimal Fibonacci Number?,"Would it ever be possible to start the Fibonacci sequence with a decimal number, less than 1? https://oeis.org/A000045","['fibonacci-numbers', 'sequences-and-series']"
2152926,How would you discover the normal distribution?,"What is the simplest or easiest or most clear way that a mathematician could discover the normal distribution and the central limit theorem? The derivation does not need to be rigorous.  (Much of calculus was discovered and understood clearly before rigorous proofs were provided, and maybe a similar thing is true for the central limit theorem.) It's ok if the answer is not historically accurate.  (But I'd also be interested in knowing how the normal distribution was discovered historically.) Is there a viewpoint that makes the central limit theorem intuitive or ""obvious""?",['probability']
2152948,A group of order 30 has at most 7 subgroups of order 5,"Show that a group of order 30 has at most 7 subgroups of order 5. This should be a basic question (from an introductory algebra course), but I got no clue... Please help!","['abstract-algebra', 'group-theory']"
2152983,Derivative of trace of log of matrix products w.r.t. a matrix,"Is there a way to calculate $$\frac{\partial\; \mbox{tr}\{\log(X^tBX)\}}{\partial X},$$ where $X$ and $B$ are $n\times n$ matrices?","['matrices', 'matrix-calculus', 'derivatives']"
2152997,Is it possible to obtain a 12×12 carpet by cutting a 16×9 carpet once?,"Yesterday my brother asked me a question. Suppose you have a carpet of size $16×9$. Now you have to cut this carpet in such a way that after cutting it and arranging pieces, the dimension is $12×12$. You can only cut the carpet once. You can arrange the obtained pieces in any way you like.
  How can you do this?","['recreational-mathematics', 'geometry']"
2153004,"If $f \circ g$ is surjective, then f is surjective","Let $f: X \rightarrow Y$ and $g: Y \rightarrow X$ If $f \circ g$ is surjective, then f is surjective, too. 
I think that is true. Question : How can I proove that? I have so far: $\forall y \in Y: \exists x \in X : f(x)=y$ $\forall x \in Y : \exists y \in Y : f \circ g(y)= x$","['functions', 'discrete-mathematics']"
2153020,Evaluting $\lim_{n \to \infty}P(A)$ where P(A) denote probability of selecting a white ball from urn,"There are $n$ urns $u_1,u_2,\cdots,u_n$.Each urn contains $2n+1$ balls.The $ith$ urn contains $2i$ types of balls.$P(u_i)$,i.e. probability of selecting $ith$ urn is proportional to $i^2+2$.If we randomly select one of the urns and draw one ball and probability of ball being white be $P(A)$,then the question is to evaluate $$\lim_{n \to \infty}P(A)$$ I tried to use $$P(A)=\sum_{i=1}^n P(A \cap u_i)P(u_i)$$$P(u_i)=k(i^2+2)$ .I understand that there must be atleast two balls in the urn which has the same colour.But I couldnot proceed with this.Any ideas?Thanks.","['probability-theory', 'probability']"
2153065,probability of discrete random variable,"In a nuclear reaction, a particle can either separate into two pieces,
or not separate, with respective probabilities $2/3$ and $1/3$ . Knowing that
pieces behave like new independent particles, find the law of
probability and mean of the number of particles obtained after two reactions from of a single particle. Let $X$ be the random variable which designates the number of pieces obtained after two reactions. It is clear that $X\in \{1, 2, 3, 4\}$ and the probability distribution of this variable ${(K, P (X = k)) / 1 ≤ k ≤ 4}$ And he came after that and give me the probability of each case. $P(k=1) = 3/27$ $P(k=2) = 8/27$ $P(k=3) = 8/27$ $P(k=4) = 8/27$ Can anyone help me to prove this solution?","['independence', 'probability-theory', 'probability', 'probability-distributions']"
2153071,How do we prove this kind of inequality?,"Let $1\le p<2$, we want to show that for any $a,b,c,d\in\Bbb R$ the following holds:
$$
|a-b|^p + |b-c|^p + |c-d|^p + |d-a|^p \ge |a-c|^p + |b-d|^p
$$
The equation is symmetric in $a,c$ and $b,d$. Since I am quite bad at solving this kind of inequality in general, I would really love you could explain the thought process behind solving inequalities like this one. PS. The tag functional analysis is because I encountered this in a context related to $L^p$ spaces.","['functional-analysis', 'real-analysis', 'inequality', 'analysis']"
2153091,Small question about proof,How do I prove this without using a calculator? $124235127381 · 34562736458392 \not= 4293905956544262926431352$ What methods should I use? Or a suggestion in a method to use in order to solve this.,"['proof-explanation', 'discrete-mathematics']"
2153092,An inequality concerning Lagrange's identity,"Does the following inequality still hold
  $$(a^2_{1}+b^2_{2}+b^2_{3})(a^2_{2}+b^2_{3}+b^2_{1})(a^2_{3}+b^2_{1}+b^2_{2})\ge (b^2_{1}+b^2_{2}+b^2_{3})(a_{1}b_{1}+a_{2}b_{2}+a_{3}b_{3})^2 $$
  $$+\dfrac{1}{2}(b_{1}a_{2}b_{3}-b_{1}b_{2}a_{3})^2+\dfrac{1}{2}(b_{1}b_{2}a_{3}-a_{1}b_{2}b_{3})^2+\dfrac{1}{2}(a_{1}b_{2}b_{3}-b_{1}a_{2}b_{3})^2\tag{*}$$
  for $a_{i},b_{i}\in \mathbb R,i=1,2,3$? we  know Lagrange's identity $$(a^2_{1}+a^2_{2}+a^2_{3})(b^2_{1}+b^2_{2}+b^2_{3})=(a_{1}b_{1}+a_{2}b_{2}+a_{3}b_{3})^2+\sum_{i=1}^{2}\sum_{j=i+1}^{3}(a_{i}b_{j}-a_{j}b_{i})^2$$ then we have Cauchy-Schwarz inequality
$$(a^2_{1}+a^2_{2}+a^2_{3})(b^2_{1}+b^2_{2}+b^2_{3})\ge (a_{1}b_{1}+a_{2}b_{2}+a_{3}b_{3})^2$$","['multivariable-calculus', 'inequality', 'polynomials', 'cauchy-schwarz-inequality']"
2153101,Is there an anti-derivative of $\sin{e^{x}}$ in terms of standard functions?,I know that this is an unusual function to talk about. Is there any chance that the integral exists in terms of standard functions?,"['integration', 'functions']"
2153161,Checking whether a multivariable function is convex,"I have a simple question. I have a multi-variable function that I'm supposed to check whether convex or not. I know the definition for convexity as follows: The function $f(x)$ is convex if: $$ f(\lambda x_1 + (1 - \lambda x_2)) \leq \lambda f(x_1) + (1 - \lambda )f(x_2)$$ But this is for the single variable case. How do I generalize it for multi-variable case? The author of this question seems to be showing that the function $f(x,y)$ is convex if, $$ f(\lambda x_1 + (1 - \lambda x_2),\lambda y_1 + (1 - \lambda y_2) ) \leq \lambda f(x_1,y_1) + (1 - \lambda )f(x_2,y_2) $$ But it hasn't been explicitly written anywhere. Is this correct? Please help. EDIT:
The two functions should be corrected as:
$$ f(\lambda x_1 + (1 - \lambda) x_2) \leq \lambda f(x_1) + (1 - \lambda )f(x_2)$$
$$ f(\lambda x_1 + (1 - \lambda) x_2,\lambda y_1 + (1 - \lambda) y_2 ) \leq \lambda f(x_1,y_1) + (1 - \lambda )f(x_2,y_2) $$","['multivariable-calculus', 'convex-analysis']"
2153169,"$G$ is finite group with $N$ normal in $G$, not contained in $Z(G)$.","Let $G$ be a finite group and $N$ be a proper normal subgroup of $G$. If $N$ is not contained in in the center $Z(G)$, then prove that there exists a proper subgroup $H$ of $G$, such that $|H|>\sqrt{|G|}$. Attempt: Since $N\not\subset Z(G)$, we get $x\in N-Z(G)$. Since $x\notin Z(G)$, we get $C(x)=\{g\in G:gx=xg\}$, the centralizer subgroup of $x$ is proper. Now $|G|/|C(x)|=[G:C(x)]=|[x]|$, where $[x]$ is the conjugacy class of $g$. Now if we can show that $|[x]|<|C(x)|$, then we will be done. Also note that $x\in N$ implies that $[x]=\{gxg^{-1}:g\in G\}\subset N$ thus we also have $|[x]|\leq|N|$. Now if we can prove that $|N|<|C(x)|$ then we'll be done. If possible let $|N|\geq |C(x)|$. But I'm stuck after that. Please let me know if i can proceed after that, or you may give me a hint for another process.","['finite-groups', 'normal-subgroups', 'group-theory']"
2153173,Why is the Borel Subgroup self normalizing?,"Let $B = B_n(\mathbb{F})$ be the set of upper triangular matrices of order $n$ with entries from $\mathbb{F}$. I am supposed to be showing $N_G(B) = B$ I have been told that what we need to notice here is that the stabilizer of the standard flag (when considered with its natural action due to $GL_n(\mathbb{F})$ is $B$ and we are supposed to be using this fact here, somehow. My attempt was to try picking an element from the normalizer and showing that it necessarily stabilizes the standard flag, and hence deduce that the elements in the normalizer are in fact in the stabilizer, which is $B$. However, I couldn't succeed with this. [ I have no idea of why flags or Borel groups are considered in general. So, please post an answer which is approachable for a person with no knowledge of Algebraic Groups. ]","['algebraic-groups', 'group-theory']"
2153335,Single set in a topology,"What is meant by a single set in a topological space? The statement goes as: ""let $X$ and $X'$ denote a single set in the topologies $\mathcal{T}$ and $\mathcal{T'}$ respectively"".",['general-topology']
2153348,Evalute the series $\sum_{n=0}^\infty \frac{(-1)^n}{n^2+1}$,"I want to find the value to which this series converges $$\sum_{n=0}^\infty \frac{(-1)^n}{n^2+1}$$ I tried looking at the sequence of partial sums $$S_k = \sum_{n=0}^k \frac{(-1)^n}{n^2+1}$$ and I noticed that $$\frac{-1}{n^2+1} \leq \frac{(-1)^n}{n^2+1} \leq \frac{1}{n^2 +1}$$ and so I think that by the squeeze rule I can see ( I could have just noticed it by logic, but okay) that the terms converge to zero. How do I find the value of the original series though? I could only show that it converged","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
2153363,Universal cover of flat surface obtained from the regular octagon,"Consider the flat surface $(X,\omega)$ obtained identifying pairs of parallel sides of the regular octagon of area 1 by translation. I’m trying to understand what its universal cover (with the induced metric) looks like. I’ve read that “it’s composed of an infinite number of copies of the octagon glued together with eight around each vertex to create cone points of angle $6\pi$”. What exactly does it mean “glued together with eight around each vertex”? Chosen a base point $x_0\in X$, the universal cover of $(X,\omega)$ should be such that the preimages of a point $x\in X$ are given by all homotopy classes of paths from $x_0$ to $x$, am I right? I'm trying to understand why these two definitions of the universal cover of $(X,\omega)$ are equivalent, but I can't see why for each homotopy class of paths between $x_0$ and $x$ one should have a point in a different copy of the octagon. Why is that?","['riemannian-geometry', 'differential-geometry']"
2153365,How to calculate the series $\sum\limits_{n=1}^{\infty} \arctan(\frac{2}{n^{2}})$?,"I encountered the series 
$$
\sum_{n=1}^{\infty} \arctan\frac{2}{n^{2}}.
$$ I know it converges (by ratio test), but if I need to calculate its limit explicitly, how do I do that? Any hint would be helpful..","['real-analysis', 'sequences-and-series']"
2153416,Epsilon-Delta: Prove $\frac{1}{x} \rightarrow 7$ as $x \rightarrow \frac{1}{7}$,"Prove that $\displaystyle\frac{1}{x} \rightarrow 7$ as $\displaystyle x \rightarrow \frac{1}{7}$. I need to show this with an $\epsilon-\delta$ argument. Still figuring these types of proofs out though, so I could use some tips/critiques of my proof, if it is correct at all. It might not be so clear, but I use the fact that $\displaystyle\left|x - \frac{1}{7}\right| < \delta$ several times in the proof. For $\varepsilon > 0$, let $\displaystyle\delta = \min\left\{\frac{1}{14}, \frac{\varepsilon}{98}\right\}$. Then $\displaystyle \left|x - \frac{1}{7}\right| < \delta$ implies: $$\left|\frac{1}{7}\right| = \left|\left(-x + \frac{1}{7}\right) + x\right| \leq \left|x - \frac{1}{7}\right| + \left|x\right| < \frac{1}{14} + |x|,$$ and so $\displaystyle |x| > \frac{1}{14}$. Also, $\displaystyle \left|x - \frac{1}{7}\right| < \delta$ implies: $$\left|\frac{1}{x} - 7\right| = \left|\frac{1-7x}{x}\right| = 7\frac{\left|x - \frac{1}{7}\right|}{|x|} < 98\left|x - \frac{1}{7}\right| < \frac{98\varepsilon}{98} = \varepsilon.$$ Thus for $\varepsilon > 0$, $\displaystyle\left|\frac{1}{x} - 7\right| < \varepsilon$ if $\displaystyle\left|x - \frac{1}{7}\right| < \delta$, for  $\displaystyle \delta = \min\left\{\frac{1}{14}, \frac{\varepsilon}{98}\right\}$.","['epsilon-delta', 'real-analysis', 'proof-verification', 'limits']"
2153427,Principal Bundle and Cocycle,"Let $G$ be a Lie Group and X a smooth manifold . Let $ G Bund(X)$ be the category of $G$-Principal Bundles. Objects are maps $\pi: P \rightarrow X$ where $P$ is a right $G$-space such that the local triviality is satisfied and maps $f: \pi_1 \rightarrow \pi_2$ are $G$-morphisms $f: P_1 \rightarrow P_2$ such that $\pi_2\circ f = \pi_1$. A standard result is that there is a bijection between the first Chech Cohomology group $\check{H}^1(X, G)$ and isomorphism classes of $G$-Principal Bundles. To see that, given a $G$-cocycle $\{{g_{\alpha\beta}}\}$ over an open cover $\{U_{\alpha}\}$ of $X$, one can form the space $P = \bigcup_{\alpha}(\{\alpha\}\times U_\alpha\times G)$ and quotient it by $(\alpha, x, g) \sim (\beta, y, h) \Leftrightarrow (x = y) \wedge (h = g_{\beta\alpha}(x)\cdot g)$. That being said, my question is do we have an equivalence of categories (groupoids here)
$$C \simeq G Bund(X)$$ for a category $C$ that is described in term of $G$-cocycles. I know that there is such an equivalence given a classifying space $BG$ and in the principal bundle article of the ncatlab they are talking about an equivalence: $$\mathbf{H}(X, \mathbf{B}G) \stackrel{\simeq}{\to} G Bund(X)$$. But can we state that with a category $C$ whose objects are $G$-cocycles or cohomologous classes $\omega\in \check{H}^1(X, G)$? Also, I would be glad if someone explain the equivalence found in the ncatlab article but concretely in our case (not in the abstract context of ncatlab). I don't figure out wether this abstract construction is more related to cocycles or to classifying spaces. Thanks, Paul.","['category-theory', 'principal-bundles', 'homology-cohomology', 'differential-geometry']"
2153476,Every Submodule of a Free Module is Isomorphic to a Direct Sum of Ideals,"Suppose that $R$ is a ring with identity and $R^{\oplus n}$ is a free left $R$-module.  Is every submodule of $R^{\oplus n}$ isomorphic to $A_1\oplus \ldots \oplus A_n$ where $A_i$ are left ideals of $R$? Edit: It appears that this is false, and an example is given in a linked question . Can anyone explain why the example works?","['abstract-algebra', 'modules', 'noncommutative-algebra']"
2153479,Sign of integral of $\frac{ 2 ^{\frac{it}{2/3}} \Gamma ( \frac{it +1}{2/3}) }{ 2 ^{\frac{it}{1.5}} \Gamma ( \frac{it +1}{1.5}) } \frac{1}{(a+it)^k}$,"Can we determine the sign of the following function
\begin{align}
f(a,k)=\int_{-\infty}^\infty  \frac{ 2 ^{\frac{it}{2/3}} \Gamma \left( \frac{it +1}{2/3}\right)  }{  2 ^{\frac{it}{3/2}}  \Gamma \left( \frac{it +1}{3/2}\right) }   \frac{1}{(a+it)^k} dt,
\end{align} 
where $a\neq 0$ and $k \ge 1$ is some positive integer. The conjecture is that the sign of the integral is equal to
 \begin{align}
{\rm sign } (f(a,k))={\rm sign}(a)^k.
\end{align} Perhpas the following limit can be usefull. By using a  method  in this question it is not difficult to see that
\begin{align}
\left |  \frac{ 2 ^{\frac{it}{2/3}} \Gamma \left( \frac{it +1}{2/3}\right)  }{  2 ^{\frac{it}{3/2}}  \Gamma \left( \frac{it +1}{3/2}\right) }  \right| \to O( e^{- (\frac{3}{2}-\frac{2}{3}) t}) \text{ as } t \to \infty.
\end{align} Thanks","['complex-analysis', 'real-analysis', 'integration', 'gamma-function']"
2153505,On existence of polyhedra with a fixed number of edges per face,"Let $P$ be a convex polyhedra such that each face has exactly $A$ edges. Denote with $V$, $E$ and $F$ the number of vertices, edges and faces of $P$ respectively. Since each face has $A$ edges we get that $E=\frac{AF}{2}$. This means that $A$ and $F$ cannot be both odd. The graph $G$ induced by $P$ is a planar graph such that each vertex has at least degree $3$. This means we can use Euler's formula to get the amount of vertices: 
$$V=2+E-F=\frac{4 + AF -2F}{2}.$$ Question For which values of $A$ and $F$ does such a convex polyhedron exist? If such a polyhedron exists, how many such non-isomorphic polyhedra exist? By isomorphism I mean that their respective skeleton graphs are isomorphic as graphs. Partial results The average degree $d$ of $G$ is equal to $d=\frac{2E}{V}=\frac{2AF}{4+(A-2)F}$. Since each vertex has at least degree $3$ we get that $3 \leq d$. Since $G$ is planar we also have that $d < 6$. This two inequalities give restrictions to the possibilities of $A$ and $F$: $3 \leq d$ gives that
$$A \leq \frac{6F-12}{F}.$$
The inequality $d < 6$ gives that
$$\frac{3F-6}{F} < A.$$
This gives us that $A < 6$. We also have that $3 \leq A$ since a face of a polyhedron has at least $3$ edges.
The above inequalities and the fact that $F \geq 0$ give If $A=3$, then $F \in [4, \infty)$ If $A=4$, then $F \in [6, \infty)$ If $A=5$, then $F \in [12, \infty)$ Denote with $\mathcal{E}$ the set of all even numbers. Since $A$ and $F$ cannot be both odd we have that If $A=3$, then $F \in \mathcal{E} \cap [4, \infty) $ If $A=4$, then $F \in [6, \infty)$ If $A=5$, then $F \in \mathcal{E} \cap [12, \infty)$","['polyhedra', 'combinatorics', 'graph-theory', 'geometry']"
2153513,How one can prove that the Moore-Penrose pseudoinverse can be calculated by using the limit concept?,"How one can prove that 
 the Moore-Penrose pseudoinverse can be calculated by using the limit concept as $$H^+=lim_{\delta \to 0^+} (\delta I+H^*H)^{-1}H^*$$, where $H^*$ denotes the Hermitian matrix. I know this limit exists even if $A^*A$ is not invertible. Moreover, since $(H^*HH^*+\delta H^*)=H^*(HH^*+\delta I)=(H^*H+\delta I) H^*$, and $(H^*HH^*+\delta H^*)$ and $H^*(HH^*+\delta I)H^*$ have inverses when $\delta > 0$ hence $$H^+=lim_{\delta \to 0^+} (\delta I+H^*H)^{-1}H^*$$
$$=lim_{\delta \to 0^+} H^*(\delta I+HH^*)^{-1}.$$ But, I couldn't go further to prove the limit definition is also Moore-Penrose pseudoinverse.i.e. $lim_{\delta \to 0^+} (\delta I+H^*H)^{-1}H^*=H^+=(H^*H)^{-1}H^*.$ I was wondering if anyone could help me?","['matrices', 'pseudoinverse']"
2153521,Monty Hall - 1000 Exercises in Probability,"The following problem is exercise 1.4.5(a) in One Thousand Exercises in Probability : 5. The Monty Hall problem: goats and cars. (a) Cruel fate has made you a contestant in a game show; you have to choose one of three
  doors. One conceals a new car, [sic] two conceal old goats. You
  choose, but your choosen door is not opened immediately. Instead, the
  presenter opens another door to reveal a goat, and he offers you the
  opportunity to change your choice to the third door (unopened and so
  far unchosen). Let $p$ be the (conditional) probability that the third
  door conceals the car. The value of $p$ depends on the presenter's
  protocol. Devise protocols to yield the values $p = \frac{1}{2}$, $p =\frac{2}{3}$.
  Show that, for $\alpha \in [\frac{1}{2}, \frac{2}{3}]$,
  there exists a protocol such that $p = \alpha$. Are you well advised
  to change your choice to the third door? This is the solution given later in the book: 5. (a) One cannot compute probabilities without knowing the rules governing the conditional probabilities. If the first door chosen
  conceals a goat, then the presenter has no choice in the door to be
  opened, since exactly one of the remaining doors conceals a goat. If
  the first door conceals the car, then a choice is necessary, and this
  is governed by the protocol of the presenter. Consider two 'extremal'
  protocols for this latter situation. (i) The presenter opens a door chosen at random from the two
  available. (ii) There is some ordering of the doors (left to right, perhaps) and
  the presenter opens the earlier door in this ordering which conceals a
  goat. Analysis of the two situations yields $p = \frac{2}{3}$ under (i), and
  $p = \frac{1}{2}$ under (ii). Let $\alpha \in [\frac{1}{2}, \frac{2}{3}]$, and suppose the presenter
  possesses a coin which falls with heads upwards with probability
  $\beta = 6\alpha - 3$. He flips the coin before the show, and adopts
  strategy (i) if and only if the coin shows heads. The probability in
  question is now $\frac{2}{3} \beta + \frac{1}{2}(1 - \beta) = \alpha$. You never lose by swapping, but whether you gain depends on the
  presenter's protocol. This solution seems completely wrong to me for multiple reasons: The deterministic protocol adds information, and the probability shouldn't be reduced with more information. By switching, the contestant is guaranteed the car as long as he does not select the car first, and this outcome is independent of the chosen protocol, since the protocol only applies when the contestant selects the car first. This question appears to have already been answered on StackExchange, and the answer there is not in agreement with this given solution. As far as I can tell, the authors are confusing ""the conditional probability that the third door conceals the car"" with the conditional probability of winning by switching when the location of the car is unknown. To see what I mean, suppose we label the doors 1, 2, and 3, and we let $C^{(d)}$, $G^{(d)}$, and $S^{(d)}$ be the events that the $d$th door contains a car, contains a goat, or is first selected by the contestant, respectively. Let $d_1$, $d_2$, and $d_3$ be the doors first selected by the contestant, revealed by the host, and then leftover, respectively. With this notation, the conditional probability $p$ is $P(C^{(d_3)} | G^{(d_2)}, S^{(d_1)}) = \dfrac{P(C^{(d_3)}, G^{(d_2)} | S^{(d_1)})}{P(G^{(d_2)} | S^{(d_1)})} = \dfrac{\frac{2}{3}}{1} = \dfrac{2}{3}$ However, we can construct a specific situation where the conditional probability is $\frac{1}{2}$: Suppose the host always reveals the smallest numbered door containing a goat. If we take $d_1 = 3$ and $d_2 = 1$, then we have $P(C^{(2)} | G^{(1)}, S^{(3)}) = 1 - P(G^{(2)} | G^{(1)}, S^{(3)}) = 1 - \dfrac{P(G^{(2)}, G^{(1)} | S^{(3)})}{P(G^{(1)} | S^{(3)})} = 1 - \dfrac{\frac{1}{3}}{\frac{2}{3}} = \dfrac{1}{2}$ But this is a specific situation that relies on more than just the protocol of the host, since there is a $\frac{1}{3}$ chance that the car could be behind the first door, so that, by picking the third door and having the second door revealed, we would know with certainty that the car is behind door one before we switch. Thus, the conditional probability of $\frac{1}{2}$ is only attained when the location of the car is unknown after the reveal. (And our sanity check of $\frac{1}{3} \cdot 1 + \frac{2}{3} \cdot \frac{1}{2} = \frac{2}{3}$ agrees with our conditional probability $p$ that the third door contains a car, not knowing which specific doors are opened). That the authors made a mistake is further cemented in the last sentence of their solution: ""whether you gain depends on the presenter's protocol."" In fact, regardless of the presenter's protocol, there is always an event of non-zero probability where you benefit by swapping. It should read, ""whether you have the possibility of not gaining by switching after conditioning depends on the presenter's protocol."" Their solution seems wrong to me, but the authors have fancy credentials (Ph.D.s from Oxford) and positions at Oxford and Cambridge, so I'm hesitant to write it off as an error. It is possible I could have misread the problem or completely miscalculated the conditional probabilities. The details do, after all, seem rather nuanced. Is this problem/solution an error? Am I just nitpicking wording?","['monty-hall', 'probability']"
2153522,Evaluate limit of an integral: $\lim_{x\to \infty }\frac{1}{x}\int _0^x\:\frac{dt}{2+\cos t}$,"$$\lim _{x\to \infty }\frac{1}{x}\int _0^x\:\frac{dt}{2+\cos t}$$ Can someone explain to me if it is a limit of type $\frac{\infty}{\infty}$ or not and why ? I considered it to be one, applied L'Hospital and got $\cos\infty$, which would mean that the limit does not exist, but the answer is $\frac{1}{\sqrt{3}}$","['integration', 'limits']"
2153537,Burnside / Cauchy-Frobenius Lemma for the automorphism group of a symmetric block design,"I am quite familiar with the Burnside/Cauchy-Frobenius Lemma, which states that for a group $G$ acting on a set $X$, where $O$ is the number of orbits of $X$ under the action of $G$, we have: $$O=\frac{1}{|G|}\sum\limits_{g\in G}|\{x\in X: xg=x\}|,$$
that is, the number of orbits is found by finding the number of fixed points of the action for each group element and adding them up. I'm trying to write this lemma down in notation more friendly to the specific situation where we have a symmetric design $D$ and its automorphism group $\text{Aut}(D)$, but I am not entirely comfortable with what I came up with, and thought I would check with the community. I have already proven (and it is well-known) that any automorphism on a symmetric design $D$ fixes the same number of blocks and points, further blurring things. I believe $D$ is playing the role of $X$ above, and it makes sense to consider both blocks and points fixed by any element $\sigma\in\text{Aut}(D)$. I also think it makes sense that $\text{Aut}(D)$ is playing the role of $G$ above. So I arrive at the following statement for Burnside's Lemma in the context of a symmetric design and its automorphism group: $$O=\frac{1}{|\text{Aut}(D)|}\sum\limits_{\sigma\in\text{Aut}(D)}|\{p\in D:\sigma p=p\}|,$$ where $p$ represents a point. Does this look good to you? Main concern: $D$ isn't really a set, in the traditional sense - it is an incidence structure, so writing ""$p\in D$"" feels wrong/notationally abusive, but writing it out for blocks $b$ has the same problem. I suppose I could further muddy things by saying $X$ is the set of points on which our design lives, but then writing $p\in X$ seems to destroy the relation between my group ($\text{Aut}(D)$) and my set ($D$?... $X$?...) The questions: Does my statement of Burnside's Lemma for this situation look right? Is everything I'm doing consistent with a good understanding of how a design's automorphism group interacts with the design itself? Is my set in the summand reasonable and not too notationally weird?","['combinatorial-designs', 'abstract-algebra', 'permutations', 'combinatorics', 'group-theory']"
2153545,Why is the distributive property so pervasive in mathematics?,"I just read this post which gives a geometric argument for the distributive law for real numbers, which I liked: https://math.stackexchange.com/a/466397/241685 However the distributive law comes up everywhere, not just for numbers. Set intersection distributes over union, inner products distribute over vector addition, wedge products distribute over vector addition, ring multiplication distributes over ring addition, matrix multiplication distributes over matrix addition, etc. Is it that we are intentionally studying systems which generalize the distributive law for numbers, or is it that the systems we study which are interesting happen to generalize the distributive law? And either way, why is this the case?","['abstract-algebra', 'math-history', 'soft-question', 'philosophy']"
2153549,"Computing $\int\frac{-1}{\sqrt{a^2 - x^2}}\,\text{d} x$ disagrees with the commonly known antiderivative","I have been scratching my head about this problem all day. If one takes the derivative of $\cos^{-1}\frac{x}{a}$, it is quite straightforward to show that the result is $\frac{-1}{\sqrt{a^2 - x^2}}$. However, when I compute the integral of this result using substitution, I obtain the following: \begin{align}I = \int \frac{-\text{d} x}{\sqrt{a^2 - x^2}} &= \int \frac{-\text{d} x}{a\sqrt{1 - \frac{x^2}{a^2}}} 
\end{align}
and then setting $\sin u = \frac{x}{a}$,
\begin{align}
\text{d} (\sin u ) &= \cos u \,  \text{d} u = \frac{1}{a}\text{d} x; \\
\Rightarrow
I &= \int \frac{-\cos u }{\sqrt{1 - \sin^2 u}}\text{d} u \\
&= \int \frac{-\cos u}{\sqrt{\cos^2 u}}\text{d} u \\
&= \int -\text{d} u = -u.
\end{align} Finally we have 
\begin{align}
\sin u &= \frac{x}{a},  \\
\Rightarrow -u & = I = - \sin^{-1}\frac{x}{a}.
\end{align} Anybody have any insight on this? Would be greatly appreciated. I can't see where I'm going wrong or how these could be equivalent values, the only inkling I have is that the inverse trig ratios are not true functions, but I'm not even sure that this is relevant.","['integration', 'trigonometry']"
2153580,Transcendental numbers in $\mathbb{Q}_p$,"I'm trying to prove that $K((x))/K(x)$ is not an algebraic extension, where $K$ is a field of characteristic $p>0$, and $K((x))$ is the field of fractions of $K[[x]]:=\{\sum_{i=0}^{\infty}a_ix^i\mid a_i\in K\}$. To make it more concrete, I'm considering the case $K=\mathbb{Z}/p\mathbb{Z}$ and $x=p$, so that we need to find $\tau\in\mathbb{Q}_p$ transcendental in respect to the field extension $\mathbb{Q}_p|\mathbb{Q}$. I thought about $\tau:=\sum_{i=0}^{\infty}\frac{p^n}{n!}$, which I've checked converges in the $p$-adic metric, but I'm not sure is transcendental or not. It's very tempting to say that $e^p=\sum_{i=0}^{\infty}\frac{p^n}{n!}$, and since $e$ is transcendental, we're done, but I know this probably doesn't make any formal sense. How do I resolve this?","['number-theory', 'algebraic-number-theory', 'p-adic-number-theory']"
2153619,Where do Mathematicians Get Inspiration for Pi Formulas?,"Question: Where do people get their inspirations for $\pi$ formulas? Where do they begin with these ideas? Equations such as$$\dfrac 2\pi=1-5\left(\dfrac 12\right)^3+9\left(\dfrac {1\times3}{2\times4}\right)^3-13\left(\dfrac {1\times3\times5}{2\times4\times6}\right)^3+\&\text{c}.\tag{1}$$$$\dfrac {2\sqrt2}{\sqrt{\pi}\Gamma^2\left(\frac 34\right)}=1+9\left(\dfrac 14\right)^4+17\left(\dfrac {1\times5}{4\times8}\right)^4+25\left(\dfrac  {1\times5\times9}{4\times8\times12}\right)^4+\&\text{c}.\tag{2}$$$$\dfrac \pi4=\sum\limits_{k=1}^\infty\dfrac {(-1)^{k+1}}{2k-1}=1-\dfrac 13+\dfrac 15-\&\text{c}.\tag{3}$$
Have always confused me as to where Mathematicians always get their inspirations or ideas for these kinds of identities. The first one was found by G. Bauer in $1859$ (something I still want to know how to prove. I've found this recently asked question still open for proofs), the second was found by Ramanujan. And has a relation with Hypergeometrical series. I'm wondering whether people see $\pi$ in other formulas, such as$$\sum\limits_{k=1}^{\infty}\dfrac 1{k^2}=\dfrac {\pi^2}6\implies\pi=\sqrt{\sum\limits_{k=1}^\infty\dfrac 6{k^2}}\tag{4}$$
And isolate $\pi$, or if something new comes up and they investigate it? For example, I'm wondering if it's possible to manipulate the expansion of $\ln m$ $$\ln m=2\left\{\dfrac {m-1}{m+1}+\dfrac 13\left(\dfrac {m-1}{m+1}\right)^3+\dfrac 15\left(\dfrac {m-1}{m+1}\right)^5+\&\text{c}.\right\}\tag{5}$$ To get a $\pi$ formula. Or the series$$\sum\limits_{k=1}^{\infty}\dfrac 1{k^p}=\dfrac {\pi^p}n\tag{6}$$
Which converges faster and faster as $p$ gets larger and larger.","['sequences-and-series', 'soft-question', 'pi']"
2153633,"Why can't we define ""the"" derivative when mapping from $\mathbb{R}^2 \to \mathbb{R}$?","When we map from $\mathbb{R} \to \mathbb{R}$, the derivative is given by $\lim_{x  \to a} \dfrac {f(x) - f(a)}{x-a}.$ When we map from $\mathbb{C} \to \mathbb{C}$ (basically $\mathbb{R}^2 \to \mathbb{R}^2$) we also have a definition for the derivative, $\lim_{z  \to w} \dfrac {f(z) - f(w)}{z-w}.$ However, when we map  $\mathbb{R}^2 \to \mathbb{R}$, we have only partial derivatives, $\dfrac {\partial f}{\partial x}$, $\dfrac {\partial f}{\partial y}$, and directional derivatives. Why is it that we can't define the derivative just as we do in the other $2$ cases? Is it because there is no nice way to define division between a member of $\mathbb{R}$ and a member if $\mathbb{R}^2$?","['complex-analysis', 'real-analysis', 'calculus']"
2153663,set relations (relation that is symmetric and transitive but not reflexive),"My discrete book says that the set $A = \{4,5,6\}$ and the relation $R = \{(4,4),(5,5),(4,5),(5,4)\}$ is symmetric and transitive but not reflexive. I was wondering how this is possible, because if a set $A$ is symmetric, doesn't it also need to include $(5,6),(6,5),(4,6),(6,4)$? Also if it's transitive, doesn't it have to include $(4,5),(5,6),(4,6)$? 
I thought the definition of a transitive relation was that $(x$  $R$ $y)$ $\land$ $(y$ $R$ $z)$ then $(x$ $R$ $z)$.","['relations', 'logic', 'elementary-set-theory', 'discrete-mathematics']"
2153693,Understanding the physical sense of Inclusion–exclusion principle,"The man wants to paint $15$ benches in red, green and blue colours. How many ways he can paint the benches, such that he must paint at least one bench in each colour. We can't rearrange benches after painting. My solution:
There are $3^{15}$ ways to paint all benches, using 3 colours.
There are $3 \cdot 2^{15}$ ways to paint all benches, using 2 colours.
There are $3$ ways to paint all benches, using 1 colour. So the answer is $3^{15} - 3\cdot 2^{15} + 3 = 14 250 606$, because we first must subtract all ways to paint using two colours, which also contain the ways to paint using one colour, so we also have to add $3$ at the end. Another explanation can be done using Euler's diagrams. I know this problem can be tackled using the Inclusion–exclusion principle. Namely, the formula $|A \cap B \cap C| = |A| + |B| + |C| - |A \cup B| - |A \cup C| - |B \cup C| + |A \cup B \cup C|$. The problem is I don't really understand the physical sense of sets $A, B, C$. What do they represent? What are the elements they consist of? But the most absurd thing for me is that it seems like $|A| = |B| = |C| = 1$, but in the same time $|A \cup B|$ and $ |A \cup C|$ are significantly bigger then $|A| = |B| = |C| = 1$. I know it's wrong, but I don't have any other ideas.","['inclusion-exclusion', 'combinatorics', 'elementary-set-theory', 'discrete-mathematics']"
2153701,Application of the Spectral Theorem,Suppose $T$ is a compact self-adjoint operator and $f$ is a unit vector such that $\| (T -3)f \| \leq 1/2$. Denote by $p$ the orthogonal projection onto the direct sum of eigenspaces of $T$ with eigenvalue $2 \leq \lambda \leq 4$. I want to show that $$\| p f \| \geq \frac{\sqrt{3}}{2}.$$ I'm unsure of how to consider the norm of $p$ and how to relate it to the eigenvalues. Perhaps $$\| Tf \| = \lambda \| p \circ T f \|?$$,"['functional-analysis', 'real-analysis', 'spectral-theory', 'operator-theory']"
2153711,What is the probability that a coin is fair?,"You paly a game with your friend Alice where you bet on the outcome of a coin toss. The coin has been provided by Alice. You think there is a 50% chance that she would have provided an unfair coin. If the coin is unfair then you believe that the probability that it will turn up heads is uniform in [0, 1]. The question is that, 1: You toss the coin and it comes up head. What is the probability that the coin is fair? 2: You toss the coin for the second time and it comes up head again. Now, what is the probability that the coin is fair? For me, I solve this problem through this way, P(fair|data) = $\frac{P(data|fair)P(fair)}{P(data|fair)P(fair)+P(data|unfair)P(unfair)}$ Where I know that P(fair)=0.5, P(data|fair)=$p^1(1-p)^0$=$p=0.5$ (as fair means P(head)=0.5=p), P(unfair)=0.5, So, the previous equation can be substitued as, P(fair|data) = $\frac{0.5*0.5}{0.5*0.5+P(data|unfair)*0.5}$ My question is how to express the term of P(data|unfair)? Thanks.","['bayesian', 'probability']"
2153737,Semi-group theory and Poisson equation on the upper half plane,"We first look at the 2D Laplace equation , say on the upper half plane:
$$\Delta u=0,\quad -\infty<x<\infty, y>0$$
$$u(x,0)=g(x),$$
where $g\in L^p(\mathbb{R})$ for some $1\leq p<\infty$. Then the general solution can be represented using the Poisson kernel
$$P_y(x)=\frac{y}{\pi(y^2+x^2)},$$
with
$$u(x,y)=(P_y*g)(x)=\frac{1}{\pi}\int_{-\infty}^\infty \frac{y}{y^2+(x-t)^2}g(t)dt.$$
Now if we define the following linear operator on $L^p(\mathbb{R})$:
$$T_yg(x)=(P_y*g)(x).$$
Then we can verify that the family $\{T_y\}_{y\geq 0}$, satisfies the semi-group properties: $T_0=\mathrm{id}$, i.e. $T_0$ is the identity operator; $T_{y+s}=T_yT_s$ for any $y,s\geq 0$. Thus we see that we can study solutions of the Laplace equation from the view of semi-group theory. Here is my question: Can we perform similar analysis to the Poission equation? i.e. consider the solutions of the poisson equation from the view of semi-group theory? The Poisson equation is basically the laplace equation with a source term
$$-\Delta u=f(x,y),\quad -\infty<x<\infty, y>0$$
$$u(x,0)=g(x),$$
here we use the same domain as above. In this case the general solution can be represented by using the Green's function:
$$G(x,y)=\frac{1}{2\pi}\ln\sqrt{x^2+y^2},$$
with
$$u(x,y)=\int_{\mathbb{R}\times\mathbb{R}^+}G(x-x',y-y')f(x',y')dx'dy'+\int_{\{y=0\}}g(x')\frac{\partial G}{\partial\mathbf{n}}(x-x',y-y')dS,$$
where in the second integral above $\mathbf{n}$ is the normal vector of $\{y=0\}$ pointing ourwards the domain $\mathbb{R}\times\mathbb{R}^+$. If we want to view the solution from semi-group theory, then we need to find a suitable Banach space $X$ and a family of bounded linear operators $\{T_t\}_{t\geq 0}$ on $X$ which form a semi-group. But I'm not sure whether this can be done. Any ideas on this question are greatly appreciated.","['semigroup-of-operators', 'poissons-equation', 'partial-differential-equations', 'operator-theory', 'functional-analysis']"
2153807,What's really going on behind calculus? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I'm currently taking maths at A Level and I have found it strange that it is not explained why the differential of $x^n$ is $nx^{n-1}$, for example. I can see that it works through observation and first principle, but how can it be derived? And what about for an unknown function, not based on trigonometry, $e^x$ or polynomials? Is there some sort of intuition or derivation that can lead to a general answer, other than making observations? Another thing that I do not quite understand is why higher derivatives of some function is denoted by $\frac{d^ny}{dx^n}$. Sorry if this sounds really basic but I would appreciate any explanations/links to good resources (I've had a look online and couldn't find too much other than some nice explanations special cases etc). Thanks :)","['intuition', 'real-analysis', 'soft-question', 'calculus']"
2153809,Is this a new operation? [duplicate],"This question already has answers here : what operation repeated $n$ times results in the addition operator? (5 answers) Closed 7 years ago . I was thinking ""What is before addition"", and came up with this.
This analogy describes it: Addition is to multiplication as [operation] is to addition.
On wikipedia it says it is just ""1+b"".
I came up with an alterantive;
the symbol that I'll use for it will be $@$. $b@b=b+2$ $b@b@b=b+3$ $b@b@b@b=b+4$... For example: $3@3=5$ If you try to compute it you run into problems. For example: $3@2=(0@0@0)@(0@0)$ but it also equals $(-1@-1@-1@-1)@(-1@-1@-1)$ $(0@0@0)@(0@0)=(-1@-1@-1@-1)@(-1@-1@-1)$ $0@0@0@0@0=-1@-1@-1@-1@-1@-1@-1$ $0+5=-1+7$ $5\neq6$ So, you can't take away or add parentheses. 1)Is this new? 2)How do you compute it?","['hyperoperation', 'functions']"
2153810,High-dimensional shapes with known volume formulas,"There don't seem to be a lot of high-dimensional shapes whose volume, surface area, etc. can be expressed in a concise way.  The examples I know of are: Spheres Cubes (or parallelotopes, more generally) Simplices Zonotopes What other classes of high dimensional objects admit relatively simple volume (or area, etc.) formulas? EDIT: Since zonotopes are the most unfamiliar of my examples, here's a reference: Chapter 9 of "" Computing the Continuous Discretely "".  To summarize, a zonotope is a set of the form $$\{a_1 \vec{x}_1 + \cdots + a_m \vec{x}_m \:|\: a_1,\dots,a_m\in[0,1]\}$$ where $\vec{x}_1,\dots,\vec{x}_m\in \mathbb{R}^n$ are fixed.  This is like a parallelotope, except the vectors $\vec{x}_j$ need not be linearly independent (e.g. $m$ can be greater than $n$ ).  The volume of such a zonotope is given by $$ \sum_{S\subset \{1,\dots,m\}, |S|=n} |\det[x_i]_{i\in S}|$$ which means: ""Take any n of the m vectors $\vec{x_i}$ and compute the volume of the parallelotope formed by these n vectors in $\mathbb{R}^n$ .  Sum over all such parallelotopes and you get the volume of the zonotope.""","['volume', 'big-list', 'polytopes', 'geometry']"
2153834,Proof of the sequential criterion for limits,"Let $f:D\to\mathbb R$ and let $c$ be an accumulation point of $D$. Then $(i)\lim_{x\to c}f(x)=L$ iff $(ii)$ for every sequence $(s_n)$ in $D$ that converges to $c$ with $s_n\neq c$ the sequence $(f(s_n))$ converges to $L$ I'm okay with one direction. To prove the other direction (taking the contrapositive statement): Suppose $L$ is not a limit of $f$ at $c$. Find a sequence $s_n$ in $D$ such that $s_n$ converges to $c$ but $(f(s_n))$ does not converge to $L$ Since $L$ is not a limit of $f$ at $c$, $\exists\epsilon>0$ such that $\forall\delta>0$ $\exists x\in D$ such that $0<|x-c|<\delta$ implies $|f(x)-L|\ge\epsilon$. Now the book I'm reading, Steven Lay's ""Analysis with an introduction to proof"" goes on as follows: "" In particular, for each $n\in\mathbb N$, there exists $s_n\in D$ with $0<|s_n-c|<1/n$ such that $|f(s_n)-L|\ge\epsilon$"" Thus exhibiting $(s_n)$ as the required sequence. I'm not sure why is it required that $\delta$ must be related to $1/n$ .
.
. ok, I want to show that there exists a sequence $s_n$ that converges to $c$ such that $(f(s_n))$ does not converge to $L$ Let $s_n$ coverge to $c$. Then $\forall \delta>0 \exists N\in \mathbb N$ such that $n\ge N \to |s_n-c|<\delta$ Now I want to make this statement into: $\forall \delta>0 \exists s_n \in D$ such that $|s_n-c|<\delta$ please detail how that happens.","['real-analysis', 'limits']"
2153892,Prove that it is impossible to have integers $b=5a$ under a digit re-ordering [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $a$ be a positive integer and let $b$ be obtained from a by moving the initial digit of $a$ to the end. Prove that it is impossible to have $b=5a$.","['decimal-expansion', 'problem-solving', 'number-theory', 'recreational-mathematics', 'elementary-number-theory']"
2153897,How to prove $f(z)=|z|$ is nowhere differentiable,Hi so i am trying to prove that the function is not  analytic but i am having trouble. I am supposed to use the definition $\frac{f(z+h)-f(z)}{h}$. I tried using the fact that $|z|=\sqrt{z\overline{z}}$ but I cannot see anything obvious. I know my aim is to show that if you approach $0$ at different angles you get different limits but to do so i have to somehow make the equation simpler.,['complex-analysis']
2153925,Find $ \lim_{n \rightarrow \infty} \left(n \int^{\frac{\pi}{4}}_0 (\cos(x)-\sin(x))^n \right)$,"Find $$ \lim_{n \rightarrow \infty}  \left(n \int^{\frac{\pi}{4}}_0 (\cos(x)-\sin(x))^n \right)$$ I've managed to prove that the limit is in $(0,1]$ and I believe it is $1$ but I don't know how to prove it. Could you help me?",['limits']
2153928,Inverse Laplace transform of $e^{-\sqrt s}$,How could one possibly find the inverse Laplace transform of $e^{-\sqrt{s}}$ using a table of Laplace transforms?,"['ordinary-differential-equations', 'laplace-transform', 'partial-differential-equations']"
2153940,"""Prime decomposition of $\infty$""","I've just read the following exercise: ""Determine for some (or all) $n\leq 10$ the prime decomposition of $2, 3, 5$ and $\infty$ in $\mathbb{Q}(\zeta_{12})$, where $\zeta_{12}$ is a primitive $12$-th root of unity. In particular, determine the different places
above $2, 3, 5$ and $\infty$, their ramication indices and their inertia degrees."" What is ""prime decomposition of $\infty$"" supposed to mean here?","['number-theory', 'algebraic-number-theory', 'field-theory', 'commutative-algebra']"
2153970,Identity operator on $L^2(\mathbb{R}^d)$,"I want to show that the identity operator on $L^2(\mathbb{R}^d)$ cannot be given by an absolutely convergent integral operator. That is, if $K(x,y)$ is a measurable function on $\mathbb{R}^d \times \mathbb{R}^d$ such that for each $f \in L^2(\mathbb{R}^d)$ and $T(f)(x) = \int_{\mathbb{R}^d} K(x,y)f(y)dy$ converges for almost every $x$, then $T(f) \neq f$ for some $f$. Therefore, suppose that $T(f)(x)$ converges absolutely for almost every $x$ and $T(f) = f$ for all $f$. Then $$f(x) = \int_{\mathbb{R}^d} K(x,y) f(y) dy \leq \int_{\mathbb{R}^d} \left| K(x,y)f(y) \right|dy< \infty.$$ I don't really know how to proceed from here.","['real-analysis', 'operator-theory', 'functional-analysis', 'measure-theory', 'integral-operators']"
2153988,When does zero cross-quadratic variation imply independence of Brownian motions?,"We know that if $X$, $Y$ are Normal random variables with zero covariance then they are independent if and only if they are bivariate Normal, i.e. $aX+bY$ is Normal for all a,b. Similarly if $B_t$, $W_t$ are Brownian motions with zero cross-quadratic variation $\langle B,W\rangle_t$, and $aB_t+bW_t$ is Normal for all $a$, $b$ and $t$ then I can prove they are independent. Does anybody know of a weaker sufficient condition? I can show that $B_t$ and $cB_{\frac{t}{c^2}}$ have zero cross-quadratic variation for all $c\neq 1$ yet are dependent so I do need an extra condition. My advisor thinks that if the Brownian motions are adapted to the same filtration then that is sufficient but I'm not convinced and I can't find anything in the literature that explores this topic.","['independence', 'quadratic-variation', 'filtrations', 'probability', 'brownian-motion']"
2154052,Taylor series in complex analysis -- change base point,"Develop $$ \sum_{n=1}^{\infty} z^n $$ in a Taylor series, around $z=a$ with $|a|<1.$ What is the new radius of convergence? Solution. Now i think this is a ""clitche"", but i know that $$\frac{1}{1-z}=\sum_{n=1}^{\infty} z^n $$ for $|z|<1.$ Now if i take $$ \frac{1}{1-z} =  \frac{1}{1-a} \, \frac{1}{1-\frac{z-a}{1-a}} = \frac{1}{1-a} \, \sum_{n=1}^{\infty} \left(\frac{z-a}{1-a}\right)^n $$ for $|\frac{z-a}{1-a}|<1$, so $|z-a|<|1-a|$ is the new radius of convergence. Is it right? Cause i'm a little confused. Is this the representation of an analytic function in that disk? Is the analytic continuation of the original function? i had never learn this in a simple words. Thanks for your time.","['taylor-expansion', 'complex-numbers', 'complex-analysis', 'power-series', 'analysis']"
2154087,Continuous Function non-zero only on a given open set,"Given an arbitrary open set $U$ in a Hausdorff space $X$, is it possible to construct a continuous function $f:X\to \mathbb C$ such that $\{x\in X\mid f(x)\neq 0\} = U$? My intuition, mostly due to Urysohn's lemma (even though it is stated for locally compact Hausdorff spaces), seems to think so, though I am having quite a bit of trouble writing one down. If more assumptions need to be made, which ones should they be? Does Urysohn's lemma tell us that this is true for locally compact Hausdorff spaces?","['continuity', 'general-topology', 'analysis']"
2154119,given derivative to get the original function,"Let $f : \mathbb R^n → \mathbb R^m$ be a differentiable function such that
$f (\mathbf 0) = \mathbf 0$ and $D f (\mathbf x)(\mathbf h) = 2⟨\mathbf x, \mathbf h⟩$ for any $\mathbf x, \mathbf h ∈ \mathbb R^n$.
Show that $f (\mathbf x) = ⟨\mathbf x, \mathbf x⟩$. How should I use the theorem that $f : U ⊆ \mathbb R^n → \mathbb R^m$ with $U$ open and connected. If $D f (\mathbf x) = O$ for every $x ∈ U$, then $f$ is constant to prove this? Thanks.","['multivariable-calculus', 'real-analysis', 'derivatives']"
2154171,Is this a better 'natural' extension of factorials than the Gamma function?,"I don't know about gamma function, but if I were to extend the definition of factorials in an intuitive and natural way, I would do it like this: Suppose we want to get the value of $5.5!$. So, I need to get in the middle of $5!$ and $6!$ intuitively. To get to $6!$ from $5!$, we multiply $5!$ by 6, i.e. we apply the function $f(x)=6x$ to $x=5!$. Since, we have to get in the middle of this operation, I'd apply the funcional-square root of $f(x)=6x$, i.e. $\sqrt{6}x$ to $5!$ so, $5.5!=5!*\sqrt{6}$ by this definition. Similarly, To get $7.1!$ I would apply the functional-tenth root of $f(x)=8x$, i.e., $f(x)=x*8^{0.1}$ to 7! which gives $7!*8^{0.1}$. So, my extension would be:
To get $x!$: If $k$ is the fractional-part of $x$ and $a$ is its integer part, then $$x!=a!\cdot (a+1)^k$$ I couldn't understand much about gamma function, but I can surely say one thing that this one is a lot simpler. Is there anything wrong with this? UPDATE: I did some calculations on my calculator and found that my factorial definition gives values relatively close to the gamma function.","['factorial', 'gamma-function', 'functions']"
2154180,How to prove that $K =\lim \limits_{n \to \infty}\left( \prod \limits_{k=1}^{n}a_k\right)^{1/n}\approx2.6854520010$?,"I was going through a list of important Mathematical Constants, when I saw the Khinchin's constant . It said that : If a real number $r$ is written as a simple continued fraction : $$r=a_0+\dfrac{1}{a_1+\dfrac{1}{a_2+\dfrac{1}{a_3+\dots}}}$$ , where $a_k$ are natural numbers $\forall \,\,k$ , then $\lim \limits_{n \to \infty} GM(a_1,a_2,\dots,a_n )= \left(\lim \limits_{n \to \infty} \prod \limits_{k=1}^{n}a_k\right)^{1/n}$ exists and is a constant $K \approx  2.6854520010$ , except for a set of measure $0$ . First obvious question is that why the value $a_0$ is not included in the Geometric Mean? I tried playing around with terms and juggling them but was unable to compute the limit. Also, is it necessary for $r$ to be ""written-able"" in the form of a continued fraction ? Thanks in Advance ! :-)","['constants', 'continued-fractions', 'calculus', 'limits']"
2154181,The inverse map of the stereographic projection,"Let $\mathbb S^1$ the unit circle centered at the origin and the pole $p=(0,1)$. The stereographic projection is the homeomorphism $\varphi:\mathbb S^1\setminus \{p\}\to \mathbb R^1$. In order to find a formula for $\varphi$, note that the point of the semi-straight line $px$ are of the form $p+t((x,y)-p)$ with $t>0$ and $(x,y)\in \mathbb S^1$. This point is in the line $y=0$ whenever the last coordinate $1+t(y-1)$ is zero. So the $\varphi(x,y)=\frac{x}{1-y}$. I'm having troubles to find a formula of the inverse. It seems just high school geometry, but I couldn't find the inverse.","['analytic-geometry', 'real-analysis', 'stereographic-projections', 'geometry']"
2154196,Another Hessian determinant question,"The Kulkarni–Nomizu product of two symmetric matrices $h_{ij}$ and $k_{kl}$ is
$$
(h\wedge \!\!\!\!\!\!\bigcirc k)_{ijkl} = h_{ik}k_{jl} + h_{jl}k_{ik} - h_{il}k_{jk} - h_{jk}k_{il}.
$$
'Squaring' a matrix with this product, we get
\begin{align}
(h\wedge \!\!\!\!\!\!\bigcirc h)_{ijkl} &= h_{ik}h_{jl} + h_{jl}h_{ik} - h_{il}h_{jk} - h_{jk}h_{il} \\
&= 2(h_{ik}h_{jl} - h_{il}h_{jk}),
\end{align}
(which I recognize as twice the determinant of $h_{ij}$ in 2D). In particular, if $h_{ij}$ is the Hessian of a scalar function $f$,
$$
h_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j} \equiv f_{,ij},
$$
then half the product is
$$
\tfrac{1}{2}(h\wedge \!\!\!\!\!\!\bigcirc h)_{ijkl} = f_{,ik}f_{,jl} - f_{,il}f_{,jk}.
$$
Again, in 2D, this is the determinant of the Hessian, which I understand to be the discriminant at a critical point (only in 2D). Finally, if we trace this over the indices $(i,k)$, and again over $(j,l)$, we get
\begin{align}
\sum_i \sum_j \tfrac{1}{2}(h\wedge \!\!\!\!\!\!\bigcirc h)_{ijij}
&= \sum_i h_{ii} \sum_j h_{jj} - \sum_i \sum_j h_{ij} h_{ji} \\
&= (h_{11}+h_{22}+\ldots)^2 - (h_{11}^2+h_{22}^2+\ldots+h_{12}h_{21}+\ldots) \\
&= 2(h_{11}h_{22}-h_{21}h_{21})+2(h_{11}h_{33}-h_{31}h_{31})+\ldots \\
&= 2\sum (\text{determinants of $2\times2$ minors of $h$.}) \\
&= 2\sum (\text{products of eigenvalues of $2\times2$ minors of $h$?})
\end{align}
If $h$ is the Hessian of $f$, this is
$$
2(f_{,11}f_{,22}-f_{,21}f_{,21})+2(f_{,11}f_{,33}-f_{,31}f_{,31})+\ldots 
$$
or (I think)
$$
2(\lambda_1\lambda_2 + \lambda_1\lambda_3 + \ldots + \lambda_2\lambda_3 + \ldots)
$$ Questions What would possess me to take the Kulkarni–Nomizu product of a Hessian? Has anyone seen anything like this? What does the product tell us about $f$ geometrically? (Not necessarily at a critical point). What does the double trace tell us about $f$? What does the sum of pairs of eigenvalues mean?? EDIT: I just found out this is called the 2nd symmetric function of eigenvalues. What does it mean?","['hessian-matrix', 'matrix-calculus', 'multivariable-calculus', 'differential-geometry', 'linear-algebra']"
2154221,Solve the equation : $\tan \theta + \tan 2\theta + \tan 3\theta = \tan \theta \tan 2\theta \tan 3\theta $,"I've been having some trouble solving this equation. (The solution in my book is given as $ \frac {n \pi}{3}, n \in \mathbb{Z} $ ) Here is what I've done $$\frac {\sin \theta}{\cos \theta} + \frac {\sin (2\theta)} {\cos (2\theta)} + \frac{\sin (3\theta)}{\cos (3\theta)}= \frac {\sin \theta}{\cos \theta} \frac {\sin (2\theta)} {\cos (2\theta)} \frac{\sin (3\theta)}{\cos (3\theta)}$$ $$ \frac {\sin \theta \cos (2\theta) \cos (3\theta) + \cos \theta \sin (2\theta) \cos (3\theta) + \cos \theta \cos (2\theta) \sin (3\theta) - \sin \theta \sin (2\theta) \sin (3\theta)  }{\cos\theta \cos (2\theta) \cos (3\theta)} = 0 $$ $$\cos (2\theta) \{\sin\theta \cos (3\theta) + \cos \theta \sin (3\theta) \} + \sin (2\theta) \{\cos \theta \cos (3\theta) - \sin \theta \sin (3\theta) \} = 0 $$ $$\cos (2\theta) \sin(3\theta + \theta) +\sin(2\theta) \cos(3\theta + \theta) = 0 $$ $$ \cos (2\theta) \sin (4\theta) + \sin (2\theta) \cos (4\theta) = 0$$ $$ \sin (2\theta + 4\theta) = 0$$ $$\sin (6\theta) = 0 $$ $$ \theta = \frac {n\pi}{6}, n \in Z$$ I understand from this question that whatever mistake I am making is in the third step, where I remove $\cos \theta \cos (2\theta) \cos (3\theta) $ from the denominator. However, despite reading through the aforementioned post, I couldn't really get the intuition behind why this is wrong. I'd like : To understand the intuition behind why removing $\cos \theta \cos (2\theta) \cos (3\theta) $ is a mistake. To know how to solve this question correctly How do I avoid making these types of mistakes when solving trigonometric equations",['trigonometry']
2154273,Find Minima and Maxima of $ y = \frac{x^2-3x+2}{x^2+2x+1}$,"$$ y = \frac{x^2-3x+2}{x^2+2x+1}$$ I guess I made some mistakes cause after taking the first derivative and simlifying I have $$y = \frac{2x^3-4x^2+5}{(x+1)^2}$$ but then numerator has complex roots. which should not be, IMO","['derivatives', 'maxima-minima']"
2154295,$\int_{0}^{\infty}{\sin^2bx\over x^2}\cdot{\mathrm dx\over e^{2ax}}=b\tan^{-1}\left({b\over a}\right)-{a\over 2}\ln{\left(a^2+b^2\over a^2\right)}?$,"Consider $(1)$ $$\int_{0}^{\infty}{\sin^2bx\over x^2}\cdot{\mathrm dx\over e^{2ax}}=I\tag1$$
  $(a,b)>0$ How does one show that $$I=\color{blue}{b\tan^{-1}\left({b\over a}\right)-{a\over 2}\ln{\left(a^2+b^2\over a^2\right)}}?$$ An attempt: Using $\sin^2(x)={1-\cos(2x)\over 2}$ $(1)$ becomes $${1\over 2}\int_{0}^{\infty}{e^{-2ax}\over x^2}-{e^{-2ax}\cos(2bx)\over x^2}{\mathrm dx}=I\tag2$$ $$I_1-I_2=I\tag3$$ $I_1$ is diverges, so else can we tackle $(1)?$","['integration', 'definite-integrals', 'trigonometric-integrals', 'calculus']"
2154298,"What is the measure of the set of numbers in $[0,1]$ whose decimal expansions do not contain $5$?","I just came across an exercise that asks to show that set of numbers in $[0,1]$ which possess decimal expansion not containing the digit $5$ has measure zero. How do I approach this? I tried thinking of relating this to Cantor set but, I see that numbers whose decimal expansion contains the digit $5$ are both contained in the Cantor set as well in its complement too, I thought if it was in the Cantor set and since measure of Cantor set is zero, so it's measure will be zero but this does not happen. In fact how is this set measurable? Any idea?","['lebesgue-measure', 'measure-theory']"
2154366,Proving $n^2 \csc^2(nx) = \sum_{k=0}^{n-1}\csc^2\left(x+ k \frac{\pi}{n}\right)$ (without calculus?),"I recently came across the following trigonometric identity in a test: $$
n^2 \csc^2(nx) =
\sum_{k=0}^{n-1}\csc^2\left(x+ k \frac{\pi}{n}\right)
$$ The question was to prove the result for any natural number $n$ . What would be a good way to approach this problem? My initial line of thought was that since $\csc^2 x$ is the negative of the derivative of $\cot x$ , the sum of the above series could be evaluated by differentiating a series involving the cotangent. Hence the question is equivalent to showing that : $$
n \cot(nx) = \sum_{k=0}^{n-1} \cot\left(x+ k \frac{\pi}{n}\right)
$$ Taking the derivative of both sides with respect to the variable $x$ and multiplying the resulting equation by $-1$ , we arrive at the required result. Although this does look simpler, I couldn't find a way to calculate the new sum. Could logarithms be used for this? Does this method work on further simplification? Or is there an alternative route to the answer (involving, for instance, complex numbers)? EDIT : It turns out that the method does indeed work, as explained in this answer , where the second summation has been calculated using basic trigonometric expansions and a bit of algebra. Nevertheless, Is there a different way to prove the identity without using calculus ? Or even better (ideally), from trigonometry alone? Invoking calculus in a trig problem of this sort seems a tad unnatural, unintuitive and unappealing to me.",['trigonometry']
2154383,Continuity vs Differentiability Intuitive Differences [duplicate],"This question already has answers here : Continuous versus differentiable (8 answers) Closed 7 years ago . I am a developer and am beginning to dabble with these mathematical concepts. I got to know that continuity means that making small changes in the input means that the output will also change by small amount only. This looks fine to me, as this means there will not be breaks in the curve leading to abrupt jumps i.e. discontinuity. Now, similarly, differentiability, I heard it means that at a point you can do linear approximation of the curve or something like a tangent to the curve exists at that point...but I don't get it. What does differentiability mean intuitively? What special property does differentiability confer to the curve? Is differentiability related to continuity? EDIT: I am trying to understand the input vs output relation under differentiability the same way in which I explained continuity above. The other question does not focus on this (I read it, it was defining it in terms of derivatives rather than an input-output perspective). Thanks for your help.","['calculus', 'continuity', 'statistics', 'differential-geometry', 'linear-algebra']"
2154393,Equation of three lines forming a equilateral triangle.,"Prove that if general equation $$\cos \left(3\alpha\right)\left(x^3 -3xy^2\right) + \sin3\alpha\left(y^3 - 3x^2y\right) + 3a\left(x^2 + y^2\right) - 4a^3 = 0$$ represents three lines then they form a equilateral triangle of area $3a^2\sqrt 3$. This equation looks like an good candidate to solve in polar coordinates than in cartesian coordinates. Converting it into polar coordinates by parts
\begin{align}
\left(x^3 -3xy^2\right) &= r^3 \left(\cos^3 \theta - 3\cos \theta \sin^2 \theta\right) =r^3 \left(4\cos^3 \theta - 3\cos \theta\right) = r^3\cos 3\theta \tag1\label1 \\
\left(y^3 - 3x^2y\right) &= r^3\left(4\sin^3 \theta - 3\sin\theta\right) = r^3\left(\cos\left(3\pi/2 - 3\theta\right)\right) = -r^3\sin 3\theta\tag2\label2
\end{align} Using $\eqref1$, $\eqref2$
\begin{align}
r^3\left(\cos 3\alpha\cos 3\theta - \sin3\alpha\sin 3\theta\right) + 3ar^2 - 4a^3 &= 0 \\
r^3\cos \left(3\alpha+ 3\theta\right) + 3ar^2 - 4a^3 &= 0
\end{align} On dividing by $a^3$ and substituting $z = r/a$
$$z^3\cos \left(3\alpha+ 3\theta\right) + 3z^2 - 4 = 0.$$ Now this happens very often to me, I am not able to solve this cubic for $z$.I did try to find the factor by putting $\,z = \sin\left(3\alpha + 3\theta\right),\,\tan\left(3\alpha + 3\theta\right),\,\ldots$ What should I do now ? how to solve this cubic ?","['coordinate-systems', 'analytic-geometry', 'geometry', 'conic-sections', 'linear-algebra']"
2154401,"Does a continuous function on the closed unit disc ""hit"" all encircled points?","Let $f$ be a continuous complex-valued function defined on the closed unit disc $\mathbb{D}$ in the complex plane. Then the restriction of $f$ to the complex unit circle $\mathbb{T}$ is a closed curve $C$ in the complex plane. Let $z \in \mathbb{C}$ be some number such that $z \notin f(\mathbb{T}$), and suppose that the winding number of $C$ around $z$ is not 0. Can we in this case be certain that $z\in f(\mathbb{D})$? (I would also be interested in an answer in the particular case, where the winding number is 1). Intuitively it seems like there cannot be any holes in the continuous image of $\mathbb{D}$, at that $f$ therefore must ""fill out"" any region in the complex plane, that $C$ encircles. But I don't know how to argue. PS: If the answer could be stated without too much algebraic topology-lingo, that would be preferable (or, if you use ideas from algebraic topology, then translate them to non-specialist terms, if possible).","['general-topology', 'complex-analysis', 'real-analysis', 'algebraic-topology']"
2154461,How to construct integer polynomial of degree $n$ which takes $n$ times the value $1$ and $n$ times the value $-1$ (in integer points),"Question is like in title: For positive integer $n$ I want to construct a polynomial $w(x)$ of degree $n$ with integer coefficients such that there exist $a_1<a_2<\cdots<a_n$ (integer numbers) satisfying $w(a_1)=w(a_2)=\cdots=w(a_n)=1$ and $b_1<b_2<\cdots<b_n$ (also integer numbers) satisfying $w(b_1)=w(b_2)=\cdots=w(b_n)=-1$. I am not sure if such polynomial even exists for every $n$. EDIT: $a_i, b_i$ are not predetermined, as someone mentioned in a comment.","['abstract-algebra', 'polynomials', 'integers']"
2154471,A density proof not via Stone-Weierstrass,"Context: I have proved Weierstrass' theorem (polynomials are dense in $C[a,b]$) in two ways: one using Bernstein polynomials, and one using convolutions. You can also use Stone-Weierstrass theorem, however I do not quote that result since I have not proved it. My question, however, is of a different nature: I am not allowed to use Stone-Weierstrass, but am asked to prove the following: Given a continuous function $f \in C(\mathbb R)$ such that $\lim_{|x| \to \infty} f(x) = 0$, and given $\epsilon>0$, there exists a polynomial $p$ such that $|f(x) - p(x)e^{-|x|}| < \epsilon$ for all $x \in \mathbb R$. Which is to say, the set $\{ p(x)e^{-|x|} : p \in \mathscr P\}$ is dense in the set of continuous functions on $\mathbb R$ decaying to zero (in the supremum norm). You cannot try to approximate $f(x)e^{|x|}$ by polynomials, because that will give you a right side bound dependent on $x$, which is not the case in uniform convergence. Furthermore, working over $\mathbb R$, breaking it into compact intervals and applying Weierstrass is getting me nowhere. Hence, I need help on this question. I request an incomplete ""fill-in-the-blank"" answer, if that's possible!","['polynomials', 'uniform-convergence', 'functional-analysis', 'weierstrass-approximation', 'approximation']"
2154502,Show that if $\chi(r)=rR(r)$ then $\frac{d}{dr}\left(r^2\frac{dR(r)}{dr}\right)=r\frac{d^2 \chi(r)}{dr^2}$,"My Attempt: I first applied the product rule to 
$$\fbox{$\color{blue}{\frac{d}{dr}\left(r^2\frac{dR(r)}{dr}\right)}$}\tag{1}\label1$$ to obtain 
$$2r\frac{dR(r)}{dr}+r^2\frac{d^2R(r)}{dr^2}\tag{2}\label2,$$ and then wrote out the chain rule for 
$$\frac{dR(r)}{dr}$$ as 
$$\frac{dR(r)}{dr}=\frac{dR(r)}{d \chi(r)}\frac{d\chi(r)}{dr}\tag{3}\label3.$$ Then from $\chi(r)=rR(r)$ and using the product rule again 
$$\frac{d\chi(r)}{dr}=R(r)+r\frac{d^2R(r)}{dr^2}\tag{4}\label4,$$ and since $R(r)=\dfrac{\chi(r)}{r},$ then
$$\frac{dR(r)}{d \chi(r)}=\frac{1}{r}\tag{5}\label5.$$ Substituting $\eqref4$ and $\eqref5$ into $\eqref3$, I find that 
$$\frac{dR(r)}{dr}=\frac{1}{r}\left(R(r)+r\frac{d^2R(r)}{dr^2}\right)=\frac{1}{r}R(r)+\frac{d^2R(r)}{dr^2}\tag{6}\label6$$ Substituting $\eqref6$ into $\eqref2$ yields 
$$\begin{align}\fbox{$\color{blue}{\frac{d}{dr}\left(r^2\frac{dR(r)}{dr}\right)}$}&=2r\frac{dR(r)}{dr}+r^2\frac{d^2R(r)}{dr^2}\\&=2r\left(\frac{1}{r}R(r)+\frac{d^2R(r)}{dr^2}\right)+r^2\frac{d^2R(r)}{dr^2}\\&=2R(r)+(2r+r^2)\frac{d^2R(r)}{dr^2}.\end{align}$$ As you can see the expression I desire for $$\fbox{$\color{blue}{\frac{d}{dr}\left(r^2\frac{dR(r)}{dr}\right)}$}$$ is getting every-more complicated and I haven't even computed the second derivative of $R(r)$ yet. I fear that I am either making a mistake or missing a much simpler approach. In my notes it said that It is straightforward to show that $$\frac{d}{dr}\left(r^2\frac{dR(r)}{dr}\right)=r\frac{d^2 \chi(r)}{dr^2}.$$ So this implies that I am missing something very simple. If someone would care to point out my errors and/or give me any hints/tips on how to reach the desired result I would be most thankful. Regards.","['derivatives', 'chain-rule', 'calculus']"
