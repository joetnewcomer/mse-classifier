question_id,title,body,tags
3768090,"Is it ever possible to ""win"" a 50/50 game with a clear goal in mind.","Lets say I have 750 dollars and want at least 1250 dollars at the end of a 50/50 game where I can bet any possible value. Is there any way in which I can raise my chances of winning? And if there is, how can I define the best initial bet to be doubled? (At first I thought problems like these were easy to solve and there was no possible way to ""win"", but at the same time I have some doubts about it and don't know the mathematical explanation for it.)","['binomial-distribution', 'probability']"
3768094,"Two sequences $f_n$ and $g_n$ such that $\int_{[0,1]}f_n g_n$ does not go to $0$ as $n\rightarrow\infty$, with these conditions on $f_n$ and $g_n$","Question: Suppose $f_n, g_n:[0,1]\rightarrow\mathbb{R}$ are measurable functions such that $f_n\rightarrow 0$ a.e. on $[0,1]$ and $\sup_n\int_{[0,1]}|g_n|dx<\infty$ . Give an example of two sequences $f_n$ and $g_n$ such that $\int_{[0,1]}f_n g_n$ does not go to $0$ as $n\rightarrow\infty$ . Prove that for any such sequences $f_n$ and $g_n$ , and every $\epsilon>0$ , there exists a measurable set $E\subset[0,1]$ such that $m(E)>1-\epsilon$ and $\int_Ef_n g_ndx\rightarrow 0$ . My thoughts:  I was thinking of doing something like $f_n=n\chi_{(0,\frac{1}{n}]}$ , which I believe would converge pointwise to $1$ a.e...I am just having a hard time trying to think of a $g_n$ that would work such that the integral of their product over $[0,1]$ wouldn't go to $0$ ....
For the second question, I immediately was thinking Egorov, but I haven't quite been able to figure out how to use it here. Any suggestions, ideas, etc. are appreciated!  Thank you.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3768122,"How fast does $\lim_{ t \to 0} E \left[ \|Z\|^2 1_{B}(X,X+\sqrt{t} Z) \right]= E \left[ \|Z\|^2 \right] E[1_B(X)]$","Let $X \in \mathbb{R}^n $ and $Z \in \mathbb{R}^n  $ be two independent standard normal random vectors. We are interested in the following quantity: \begin{align}
E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]
\end{align} for some set $B\subset \mathbb{R}^n $ . Assumptions about the set $B$ : 1) Assume that $1>P(Z\in B)>0$ ; 2) (Optional) $B$ is convex. Concretely, we are interested in how this quantity behaves as $t \to 0$ . First, it is easy to show that \begin{align}
\lim_{ t \to 0} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]=  E \left[ \|Z\|^2  \right] E[1_B(X)],
\end{align} where we have used the dominated convergence theorem and the bound $\|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \le \|Z\|^2$ . My question is: Can we say something about how fast does this approach the limit?  Specificaly, can we say something about $$\lim_{ t \to 0} \frac{d}{dt} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]= ???$$ Edit: The derivative is given by \begin{align}
&2 \frac{d}{dt} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]\\
&=\frac{E[\|Z\|^4  1_{B \times B}(X,X+\sqrt{t} Z)]-   (n+2) E[\|Z\|^2  1_{B \times B}(X+\sqrt{t} Z ,X) ]}{t}
\end{align} Now, if take the limit as $t \to 0$ of the numerator than we get \begin{align}
&\lim_{n \to \infty} E[\|Z\|^4  1_{B \times B}(X,X+\sqrt{t} Z)]-   (n+2) E[\|Z\|^2  1_{B \times B}(X+\sqrt{t} Z ,X) ]\\
&=  E \left[ \|Z\|^4  \right] E[1_B(X)] - (n+2) E \left[ \|Z\|^2  \right] E[1_B(X)]\\
&=0
\end{align} where we have used that the fourth moment is given by $E \left[ \|Z\|^4  \right]=n(n+2)$ . Therefore, we have zero over zero.
I tried using L'hospital rule more times, but we keep getting zero over zero no matter how many times we apply  L'hospital rule.","['expected-value', 'probability-theory', 'probability', 'normal-distribution']"
3768146,"For a function $f: X \to Y$, if $Y-V$ is finite, when is $X - f^{-1}(V)$ finite?","I apologize if this is a silly question but I just do not know enough set theory (i.e., sizes) to understand if it's even silly. My question is Let $f: X \to Y$ be a function of sets. Suppose $V \subset Y$ , and that $Y - V$ is finite (countable). Is $X - f^{-1}(V)$ finite (countable)? What conditions do we need to place on $f$ to guarantee it will be finite (countable)? So I kind of have two questions. But I will take either. Why I care: I'm asking this because I want to know the following. Recall that for a set $X$ , we can endow $X$ with the finite complement topology where a set $U \subset X$ is open if $X - U$ is finite. Denote this topology on a set $X$ as $FC_X$ . Now suppose $f: X \to Y$ is a function. As $X$ and $Y$ are sets, we may ask: Does the function $f: X \to Y$ extend to a continuous function $f: (X, FC_X) \to (Y, FC_Y)$ ? For such a function to be continuous, we need that $f^{-1}(U)$ is open if $U$ is open. In this case, that means that if $Y - U$ is finite then $X - f^{-1}(U)$ must be finite. But I do not know when that last statement holds, and hence it's my question above. My guess is that if $f$ is injective, then it will be true, but I don't really know if that's true. I lack the set theory knowledge to really attack such a problem. Finally, if the above answer is true, it tells me that I've got a functor $F: \textbf{Set} \to \textbf{Top}$ where $X$ is sent to the finite complement topology. I'm also interested in the countable case, since that would give me another different functor. But that's besides the question.","['elementary-set-theory', 'general-topology']"
3768147,Line Integral gives no work done?,"For the following question, $$
\mathbf{F}=\langle-y, x\rangle
$$ For this field: Compute the line integral along the path that goes from (0,0) to (1,1) by first going along the $x$ -axis to (1,0) and then going up one unit to (1,1) . I got an answer of $0$ , by doing: But the answer key concludes that the answer is $1$ : To compute $\int_{C} \mathbf{F} \cdot d \mathbf{r}$ we break the curve into two pieces, then add the line integrals along each piece.
First, fix $y=0$ (so $d y=0$ ) and let $x$ range from 0 to 1 . $$
\int_{x=0}^{x=1} \mathbf{F} \cdot d \mathbf{r}=\int_{x=0}^{x=1}-y d x+x d y=\int_{0}^{1} 0 d x=0
$$ Next, fix $x=1$ (so $d x=0$ ) and let $y$ range from 0 to 1: $$
\int_{y=0}^{y=1} \mathbf{F} \cdot d \mathbf{r}=\int_{y=0}^{y=1}-y d x+1 d y=1
$$ We conclude that $\int_{C} \mathbf{F} \cdot d \mathbf{r}=1$ I understand the solution from the answer key, but I don't get why my solution doesn't work. Please assist.","['integration', 'multivariable-calculus', 'calculus', 'line-integrals']"
3768151,"How can I study the convergence of the improper integral $\int_{0}^{ \infty} \frac{\sin(x)}{x+1} \, \mathrm dx\,$?","I need to study the convergence of the following improper integral: $$\int_{0}^{\infty} \dfrac{\sin(x)}{x+1}\, \mathrm dx$$ I did the following: $$ -1 \leq \sin(x)  \leq 1  \\
\implies \dfrac{-1}{x+1}  \leq \dfrac{\sin(x)}{x+1}  \leq \dfrac{1}{x+1} \\   
\implies \left|\dfrac{\sin(x)}{x+1}\right|  \leq \dfrac{1}{x+1} \\
 \implies \int_{0}^{\infty} \left|\dfrac{\sin(x)}{x+1}\right| \, \mathrm dx   \leq \int_{0}^{\infty}\dfrac{1}{x+1}\, \mathrm dx = \infty  $$ I planned to use the comparison criterion and then the absolute convergence criterion. However, the idea did not work for me.","['integration', 'convergence-divergence', 'improper-integrals', 'real-analysis']"
3768155,Positive integer solutions to $\frac{1}{a} + \frac{1}{b} = \frac{c}{d}$,"I was looking at the equation $$\frac{1}{a}+\frac{1}{b} = \frac{c}{d}\,,$$ where $c$ and $d$ are positive integers such that $\gcd(c,d) = 1$ . I was trying to find positive integer solutions to this equation for $a, b$ , given any $c$ and $d$ that satisfy the above conditions. I was also trying to find whether there are additional requirements on $c$ and $d$ so that positive integer solutions for $a$ and $b$ can even exist. I found that this equation simplifies to $abc - ad - bd = 0$ so that $abc = d(a+b)$ . Also, since the equation is equivalent to $a+b = ab(\frac{c}{d})$ , this means $a$ and $b$ are the roots of the quadratic $dx^2-abcx+abd = 0$ since their product is $ab$ and their sum is $a+b = ab(\frac{c}{d})$ . However, after I analyzed the quadratic I just ended up with $a = a$ and $b = b$ . Any ideas on how to solve this further? Again, I need to find all the conditions on the positive integers $c$ and $d$ (where $\gcd(c,d) = 1$ ) such that positive integer solutions for $a, b$ can exist. And then also find the positive integer solutions for $a$ and $b$ given that those conditions are satisfied.","['egyptian-fractions', 'elementary-number-theory', 'factoring', 'algebra-precalculus', 'quadratics']"
3768161,Are all complex functions onto?,"I am not sure whether this question even makes sense. But I was just wondering whether all inverse operations of functions defined in complex numbers will stay inside complex numbers. (i.e. we don't have to extend the complex number system): $x^2$ is a well-defined function of real numbers alone and yet there is no real number such that $x^2 = -1$ , i.e. there is no inverse, for $-1$ (and so we need complex numbers). Is there a theorem that says that this kind of thing cannot happen with complex numbers? Maybe all continuous complex functions are onto? Or, maybe all taylor series with complex coefficients are onto?","['complex-analysis', 'complex-numbers']"
3768205,What is the Fourier transform of the bump function $e^{-\frac{1}{1-|x|^2}}$?,"Let $$f(x):= 
\left\{
  \begin{array}{ll}
    e^{-\frac{1}{1-|x|^2}}, & \hbox{$|x|<1$;} \\
    0, & \hbox{$|x|\geq1$.}
  \end{array}
\right.$$ This is a generic bump function (a smooth positive bounded function with compact support). It is a Schwartz function, so it has a Schwartz Fourier transform. My question is about calculating its Fourier transform $\hat{f}$ : Since $f$ is radial (i.e. rotationally invariant),  then so is $\hat{f}$ . So $\hat{f}(\xi)=\hat{f}(|\xi|,0,...,0)$ for all $\xi \in \mathbb{R}^{n}$ . Therefore, denoting $x^\prime=(x_2,x_3,...,x_n)$ , we have $$\hat{f}(\xi)=\int_{|x|\leq 1}e^{\dot{\imath}x_{1}|\xi|}e^{-\frac{1}{1-|x|^2}}dx=\int_{|x|\leq 1}e^{\dot{\imath}x_{1}|\xi|}e^{-\frac{1}{1-|x|^2}}dx\\= \int_{-1}^{1}e^{\dot{\imath}x_{1}|\xi|}\int_{|x^\prime|\leq \sqrt{1-x_1^2}}e^{-\frac{1}{1-x_1^2-|x^\prime|^2}}dx^\prime dx_1\\= \int_{-1}^{1}e^{\dot{\imath}x_{1}|\xi|}\int_{\mathbb{S}^{n-2}}\int_{0}^{\sqrt{1-x_1^2}}e^{-\frac{1}{1-x_1^2-\rho^2}}\rho^{n-2}d\rho d\omega_{n-2} dx_1\\
=|\mathbb{S}^{n-2}|\int_{-1}^{1}e^{\dot{\imath}x_{1}|\xi|}\int_{0}^{\sqrt{1-x_1^2}}e^{-\frac{1}{1-x_1^2-\rho^2}}\rho^{n-2}d\rho  dx_1$$ And I am stuck here!","['harmonic-analysis', 'fourier-analysis', 'fourier-transform', 'real-analysis']"
3768238,Can $a \bmod 3$ be represented arithmetically without the mod or other integer-related functions?,"I've noticed that $a \bmod b$ (with 'mod' in the operational sense) can also be represented using various tricks of formulation. For instance, that $$a \bmod b = a - b\left\lfloor\frac{a}{b}\right\rfloor .$$ There are several ways to do it by (ab)using various functions like ceiling, max, abs, and the like. However, I realized yesterday that $$a \bmod 2 = \frac{1-(-1)^a}{2}.$$ I find this interesting as I consider basic exponentiation to be a purer operation in some sense than something like floor, perhaps in that it doesn't have a built-in sense of conditionality or knowledge of fractional parts. Furthermore, you can use substitution to reach arbitrarily high powers of $2$ , as in $$a \bmod 4 = \frac{1-(-1)^a}{2}+1-(-1)^{\frac{a-\frac{1-(-1)^a}{2}}{2}},$$ which amounts to right-shifting $a$ by one spot and repeating the process to get the second bit you need for the $\bmod 4$ . I realize that's not pretty, but I'm interested that it's possible. The motivation here is identifying situations where formulae may implicitly support a richness of computational complexity one wouldn't expect, which parity detection and manipulation goes a long way towards. Which leads me to my question: Is there some way using exponentiation or other basic operations to find a comparable expression for $a \bmod 3$ , or ideally, $a \bmod b$ ?","['number-theory', 'computational-complexity', 'modular-arithmetic']"
3768246,Define $X_n=\sum_{k=1}^n kx_k$ and $Y_n=\sum_{k=1}^n ky_k$. Prove that there exists an $n$ such that $X_n<Y_n$.,"Question: Let $x_k, y_k\geq 0$ .  Suppose that $\sum_{k=1}^\infty x_k<\infty$ and $\sum_{k=1}^\infty y_k=\infty$ .  Define $X_n=\sum_{k=1}^n kx_k$ and $Y_n=\sum_{k=1}^n ky_k$ .  Prove that there exists an $n$ such that $X_n<Y_n$ . My thoughts: So, $x_k$ is a convergent sum and $y_k$ is a divergent sum both of non-negative terms.  Since $\sum_{k=1}^\infty x_k<\infty$ , we know that $S_{x_k}=\sum_{k=1}^n x_k$ , the sequence of partial sums is convergent, and since $\sum_{k=1}^\infty y_k=\infty$ , we know that $S_{y_k}=\sum_{k=1}^\infty y_k$ is also divergent (to $\infty$ since all terms are non-negative).  But here is where I get stuck.  I'm a bit stuck on how to deal with the $k$ in $X_n$ and $Y_n$ , because I can't just pull it out of each series since it's value depends on the sum.  I was thinking that maybe there was a more measure-theoretic way of dealing with this, but I'm not sure.  Maybe it can just be salvaged by dealing with the series and their partial sums?","['measure-theory', 'convergence-divergence', 'real-analysis']"
3768273,"Why should this result be true? If $f: [0,1] \to \mathbb{R}$ is differentiable, $g$ is continuous, and $f'(t) = g(f(t)),$ then $f$ is monotonic.","If $f: [0,1] \to \mathbb{R}$ is differentiable, $g$ is continuous, and $f'(t) = g(f(t)),$ then $f$ is monotonic. Example 1: Suppose $g(x) = x \Rightarrow f' = f.$ Then $f = ce^x$ which is indeed monotonic. Example 2: Suppose $g(x) = x^n \Rightarrow f' = f^n$ for $n \ne 1.$ Then $df/f^n = dx \Rightarrow x+C = f^{1-n}/(1-n) \Rightarrow f = ((1-n)x + C)^{1/(1-n)},$ monotonic again. It seems bizarre that $g$ can be anything we want, and yet the result will be true. Since $f$ is continuous, it suffices to prove $f$ is injective. So suppose $f(a) = f(b)$ with $a<b.$ Avenue 1: Then $f'(a) = g(f(a)) = g(f(b)) = f'(b).$ But what's next? This seems like a dead end. Avenue 2: There exists $c \in (a,b)$ such that $f'(c) = 0$ by Rolle's Theorem. Thus, $g(f(c)) = 0.$ But what's next? Looks like another dead end again. Is there a 3rd avenue? I've been looking for one. Until I find it, I cannot believe the result. Update: The answer here solves my question. The question also appeared previously on MSE , but I do not like the method used there since it seems to assume $f'$ is continuous.","['calculus', 'ordinary-differential-equations']"
3768332,$ \sum_{n=1}^\infty \csc^2(\omega\pi n)= \frac{A}{\pi} +B $,"$$ \sum_{n=1}^\infty \csc^2(\omega\pi n)= \frac{A}{\pi} +B $$ if $\omega =-\frac{1}{2}+\frac{\sqrt{3}}{2}i$ find $\frac{A^2}{B^2}$ My Attempt $$ \sum_{n=1}^\infty \csc^2(\omega\pi n)= \sum_{n=1}^\infty csch^2(i\omega\pi n)= 4\sum_{n=1}^\infty  \big(e^{\pi n \big( \frac{i}{2} + \frac{ \sqrt{3} }{2} \big) }-e^{-\pi n \big( \frac{i}{2} + \frac{ \sqrt{3} }{2} \big)}\big) ^{-2} $$ $$\sum_{n=1}^\infty  \big(e^{\pi n \big( \frac{i}{2} + \frac{ \sqrt{3} }{2} \big) }-e^{-\pi n \big( \frac{i}{2} + \frac{ \sqrt{3} }{2} \big)}\big) ^{-2}= \big(ie^{\pi\frac{\sqrt{3}}{2}}+ie^{-\pi\frac{\sqrt{3}}{2}}\big)^{-2}+ \big(-e^{\pi\sqrt{3}}+e^{-\pi\sqrt{3}}\big)^{-2} +\big(-ie^{3\pi\frac{\sqrt{3}}{2}}-ie^{-3\pi\frac{\sqrt{3}}{2}}\big)^{-2}+  \big(e^{2\pi\sqrt{3}}-e^{-2\pi\sqrt{3}}\big)^{-2} +...$$ $$=  \sum_{n=0}^\infty  \big(ie^{(4n+1)\pi\frac{\sqrt{3}}{2}}+ie^{-(4n+1)\pi\frac{\sqrt{3}}{2}}\big)^{-2} +\sum_{n=0}^\infty  \big(-e^{(2n+1)π√3}+e^{-(2n+1)π√3}\big)^{-2} +\sum_{n=0}^\infty  \big(-ie^{(3+4n)\pi\frac{\sqrt{3}}{2}}+-ie^{-(4n+3)\pi\frac{\sqrt{3}}{2}}\big)^{-2}+
\sum_{n=0}^\infty  \big(e^{(2n)π√3}-e^{-(2n)π√3}\big)^{-2}  $$ $$\sum_{n=0}^\infty  \big(-e^{(4n+1)\pi\sqrt{3}}-2-e^{-(4n+1)\pi\sqrt{3}}\big)^{-1}+ \sum_{n=0}^\infty   \big(e^{2(2n+1)\pi\sqrt{3}}-2+e^{-2(2n+1)\pi\sqrt{3}}\big)^{-1} + \sum_{n=0}^\infty  \big(e^{(3+4n)\pi\sqrt{3}}-2+e^{-(3+4n)\pi\sqrt{3}}\big)^{-1}+ \sum_{n=1}^\infty  \big(e^{4n\pi\sqrt{3}}-2+e^{-4n\pi\sqrt{3}}\big)^{-1}  $$ I have found the sums numerically and $\sum_{n=0}^\infty  \big(-e^{(4n+1)\pi\sqrt{3}}-2-e^{-(4n+1)\pi\sqrt{3}}\big)^{-1}+ \sum_{n=0}^\infty   \big(e^{2(2n+1)\pi\sqrt{3}}-2+e^{-2(2n+1)\pi\sqrt{3}}\big)^{-1} + \sum_{n=0}^\infty  \big(e^{(3+4n)\pi\sqrt{3}}-2+e^{-(3+4n)\pi\sqrt{3}}\big)^{-1}+ \sum_{n=1}^\infty  \big(e^{4n\pi\sqrt{3}}-2+e^{-4n\pi\sqrt{3}}\big)^{-1} \approx -0.00429$ How can I evaluate this analytically?","['trigonometric-series', 'calculus', 'summation']"
3768402,Inherited Riemannian metric on a submanifold,"I am a beginner in differential geometry and I am reading chapter 1 of Differential Geometry of Loring Tu. For a smooth manifold $M$ , a Riemannian metric on $M$ is an assignment that assigns $p\in M$ to an inner product on $T_pM$ , such that for any smooth vector fields $X,Y$ on $M$ , the map $p\mapsto \langle X_p,Y_p \rangle$ is a smooth function on $M$ . Let $(M,\langle,\rangle_M)$ be a Riemannian manifold and $N$ be a submanifold. Then for each $p\in N$ , $T_pN$ is  a subspace of $T_pM$ , so we can naturally define a Riemannian metric on $N$ by letting $\langle v,w\rangle_N=\langle v,w\rangle_M$ for $v,w\in T_pN, p\in N$ . But how can we show that this Riemannian metric on $N$ satisfy the smoothness condition? I.e., for any smooth vector fields $X,Y$ on $N$ , how can we show the map $p\mapsto \langle X_p,Y_p \rangle$ is a smooth function on $N$ ?","['smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
3768431,The number of ways to represent a natural number as the sum of three different natural numbers,"Prove that the number of ways to represent a natural number $n$ as the sum of three different natural numbers is equal to $$\left[\frac{n^2-6n+12}{12}\right].$$ It was in our meeting a year ago, but I forgot, how I proved it. Let the needed number be $a_n$ , where $n\geq6$ and let $b_n$ be number of ways to represent a natural number $n$ as the sum of two different natural numbers. Thus, $a_n=b_{n-3}+b_{n-6}+...$ because we can go from $(a,b)$ , where $a<b$ , to $(1,a+1,b+1)$ , $(2,a+2,b+2)$ ... Thank you for your help!","['contest-math', 'ceiling-and-floor-functions', 'telescopic-series', 'combinatorics', 'natural-numbers']"
3768439,Probability of picking buttons from a bag,"A bag contains $30$ buttons that are colored either blue, red or yellow. There are the same number of each color ( $10$ each). A total $4$ buttons are drawn from the bag. Compute the followings: Find $n(\Omega)$ . The probability that at least $3$ of them are red? The probability that there is at least one of each color? This seems like a basic problem but my professor and I cannot agree on an answer. I think the probabilities are $2/21$ and $100/203$ for parts $2$ and $3$ respectively. I used combinations to calculate the probabilities. My professor said $n(A)/n(\Omega)$ is $3/15$ for both so that is the answer for both $2$ and $3$ .","['conditional-probability', 'combinations', 'probability']"
3768479,Evaluate $\int \frac{2-x^3}{(1+x^3)^{3/2}} dx$,"Evaluate: $$\int \frac{2-x^3}{(1+x^3)^{3/2}} dx$$ I could find the integral by setting it equal to $$\frac{ax+b}{(1+x^3)^{1/2}}$$ and differentiating both sides w.r.t. $x$ as $$\frac{2-x^3}{(1+x^3)^{3/2}}=\frac{a(1+x^3)^{3/2}-(1/2)(ax+b)3x^2(1+x^3)^{-1/2}}{(1+x^3)}$$ $$=\frac{a-ax^3/2-3bx^2}{(1+x^3)^{3/2}}$$ Finally by setting $a=2,b=0$ , we get $$I(x)=\frac{2x}{(1+x^3)^{1/2}}+C$$ The question is: How to do it otherswise?","['integration', 'indefinite-integrals', 'calculus']"
3768519,How to represent the given information correctly to solve for a particular solution to a differential equation?,"Lupita's lawn is left unattended so that an infestation of weeds begins to take over. The rate of growth of the weeds is proportional to the area of lawn not yet invaded by weeds. a) If $W \space m^2$ is the area of lawn taken over by weeds after t weeks, and the lawn has a total area of $A \space m^2$ , write the differential equation that models the situation. b) The area taken over by weeds grows from one quarter to one half the total area of the lawn in $T$ weeks. If $t = 0$ when $W = \frac{1}{4}A$ , solve the differential euqation in part a). First I write down the differential equation, which is: $\frac{dW}{dt} = k(A - W)$ . I proceed and find the general solution for this differential equation which is: $W = A - Be^{-kt}$ for that I let $e^c = B$ . I continue this with the information I know to interpret; that is when $t = 0$ , $W = \frac{1}{4}A$ . This gives: $\frac{1}{4}A = A - Be^{-k(0)}$ $\frac{3}{4}A = B$ . Substituting this back to the equation: $W = A - \frac{3}{4}Ae^{-kt}$ Now this is where I am stuck. I am unsure how to represent ""The area taken over by weeds grows from one quarter to one half the total area of the lawn in $T$ weeks"" mathematically. I have the proportional constant $k$ left to solve. Do I have to do something like: $ \int _{\frac{1}{4}A}^{\frac{1}{2}A}\:\frac{1}{A-W}dW\:=\:\int _0^T\:k\:dt$ How can I solve for $k$ , hence the equation? FYI the answer is: $W\:=\:A\:-\frac{3}{4}Ae^{ln\left(\frac{2}{3}\right)t}$ Thanks.","['calculus', 'ordinary-differential-equations']"
3768583,Relation between tautological line bundle and blow up at the origin,"We can define the projective $n$ -space $\mathbb{P}^n$ as the quotient of $\mathbb{C}^{n+1}\setminus \{0\}$ by the action of $\mathbb{C}^*$ with all weights equal to $1$ . Moreover we can define the tautological line bundle of $\mathbb{P}^n$ as $$\mathcal{O}_{\mathbb{P}^n}(-1)=\{(u,v)\in\mathbb{P}^n\times \mathbb{C}^{n+1}\mid v=tu \text{ for some $t\in\mathbb{C}$} \}.$$ But this definition is equal to the definition of the blow-up at the origin $0$ of $\mathbb{C}^{n+1}$ .
I'd like to understand how this definitions talk to each other: at the moment I've a naive idea of what a blow-up is and I've just started talking about line bundles, but I ddon't have a clear idea in mind of the connection between these two objects (and moreover if $\mathcal{O}_{\mathbb{P}^n}(-a)
$ can still has a similar interpretation, or is it just a peculiar property of $\mathcal{O}_{\mathbb{P}^n}(-1)$ ). I know this question may sound too vague, but I hope someone can give me some advice on how to see the tautological line bundle as a blow-up.","['algebraic-geometry', 'blowup', 'line-bundles', 'projective-varieties']"
3768620,A kind of isoperimetric inequality for polynomials?,"During my programming of an app I stumbled upon the following question: Suppose you are given a monic polynomial $f \in \mathbb{C}[x]$ . Consider $f$ as a function and let $D \subset \mathbb{C}$ be the unit disc in the target complex plane. Then we can compute the volume $V_f := \int_{f^{-1}(D)} 1 dx$ of the preimage of $D$ with respect to the Lebesgue measure $dx$ on the source. Computational experiments yield that there is an upper bound on $V_f$ as $f$ ranges over all (Edit) monic polynomials. My guess is that the maximum is achieved whenever $f$ has exactly one root of multiplicity $n = \operatorname{deg} f$ . To me, this is very similar to the isoperimetric inequality in the sense that we are looking for an ""optimal shape"" determined by the polynomial $f$ in order to maximize a volume. Yet, I do not know of any mathematics that treat this or a related question. Do you?","['complex-analysis', 'measure-theory', 'euler-lagrange-equation']"
3768663,how to find convolution between $f(x)=e^{-2x^2}$ and $g(x)=e^{-2x^2}$?,"I wanted to find the convolution between the two function. By definition I get, $$(f*g)(x)=\int_{\mathbb R}e^{-2(x-y)^2}e^{-2x^2}dy=\int_{-\infty}^{\infty}e^{-4x^2+4xy-2y^2}dy $$ But I am not able to calculate the given integral.","['integration', 'ordinary-differential-equations', 'real-analysis', 'calculus', 'functional-analysis']"
3768690,What is value of this integral? $\int_{0}^{\infty}\frac{\log(1+4x^2)(1+9x^2)(9+x^2)+(9+x^2)\log(4+x^2)(10+10x^2)}{(9+x^2)^{2}(1+9x^{2})}dx$,"What is value of this integral $$I=\int_{0}^{\infty}\frac{\log(1+4x^2)(1+9x^2)(9+x^2)+(9+x^2)\log(4+x^2)(10+10x^2)}{(9+x^2)^{2}(1+9x^2)}dx$$ My work : \begin{align*}I&=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)(10+10x^2)}{(9+x^2)(1+9x^2)}dx\\
&=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)}{1+9x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)}{9+x^2}dx\\
&=j_{1}+j_{2}+j_{3}\\
\end{align*} $$j_{1}=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx=\sum_{n=0}^{\infty}\frac{(-1)^n(2^{2(n+1)})}{n+1}\int_{0}^{\infty}\frac{x^{2(n+1)}}{9+x^2}dx$$ $$j_{2}=\log(4)\int_{0}^{\infty}\frac{1}{1+(3x)^2}dx+\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(n+1)(2^{2(n+1)})}\int_{0}^{\infty}\frac{x^{2(n+1)}}{1+9x^2}dx=\frac{\log(4)\pi}{6}+\sum_{n=0}^{\infty}\frac{(-1)^n}{(n+1)2^{2(n+1)}}\int_{0}^{\infty}\frac{x^{2(n+1)}}{1+9x^2}dx$$ $$j_{3}=\int_{0}^{\infty}\frac{\log(4+x^2)}{9+x^2}dx=\frac{\log(4)\pi}{54}+\sum_{n=0}^{\infty}\frac{(-1)^n}{(n+1)2^{2(n+1)}}\int_{0}^{\infty}\frac{x^{2(n+1)}}{9+x^2}dx$$ Wait for a review to find solutions to this","['integration', 'improper-integrals', 'real-analysis', 'calculus', 'sequences-and-series']"
3768703,A theorem about sequences Cauchy in measure (Folland's Book),"I'm reading Folland's book, and I had a hard time following one of the proofs. I'm trying to understand the proof for: Suppose that $\{f_n\} \subset L^1$ , and that $\{f_n\}$ is cauchy in measure. Then there is a measurable function $f$ such that $f_n \to f$ in measure, and there is a subsequence $\{f_{n_j}\}$ that converges to $f$ a.e.. Moreover, if also $f_n \to g$ in measure, then $g = f$ a.e.. Here is my attempted proof, in that I modified the written proof in the bits that I couldn't understand. Is this proof correct? (I'm especially worried about the $f^{-1}(B) = \left(\left(\bigcap_{l=k}^\infty \bigcup_{j=l}^\infty g_j^{-1}(B)\right) \cap F^c \right) \cup F \text{ if } 0 \in B$ part, and any error corrections are greatly appreciated.) $\newcommand{\norm}[1]{\left\lVert#1\right\rVert}$ As $f_n$ is cauchy in measure, we can choose a subsequence $\{g_j\} = \{f_{n_j}\}$ of $\{f_n\}$ such that if $E_j = \{ x:\norm{g_j(x) - g_{j+1}(x)} \ge 2^{-j}\}$ , then $\mu(E_j) \le 2^{-j}$ . If $F_k = \cup_{j=k}^\infty E_j$ , then $\mu(F_k) \le \sum_k^\infty 2^{-j} = 2^{1-k}$ . If $x$ is not in $F_k$ , for $i \ge j \ge k$ (note that $\norm{g_j(x) - g_{j+1}(x)} \le 2^{-j}$ in this case) $$\norm{g_j(x) - g_i(x)} \le \sum_{l = j}^{i-1} \norm{g_{l+1}(x) - g_l(x)} \le \sum_{l = j}^{i-1} 2^{-1} \le 2^{1-j}. $$ Thus $\{g_j\}$ is pointwise cauchy on $F_k^c$ . Let $F = \bigcap_1^\infty F_k = \limsup E_j$ . Then as $\mu(F_k) \le 2^{1-k}$ , $\mu(F) = 0$ . If we set $f(x) = \lim g_j(x)$ for $x \notin F$ and $f(x) = 0$ for $x \in F$ , then $f$ is measurable (explained below) and $g_j \to f$ a.e. (as $F$ is a null set). $x \in F^c$ , $x \in \bigcup_{k=1}^\infty F_k^c$ , note that $j \ge k$ by definition. So on such $x$ , $g_j(x)$ is cauchy, so it converges. For any borel set $B$ , $$f^{-1}(B) = \left(\left(\bigcap_{l=k}^\infty \bigcup_{j=l}^\infty g_j^{-1}(B)\right) \cap F^c \right) \cup F \text{ if } 0 \in B$$ $$f^{-1}(B) = \left(\left(\bigcap_{l=k}^\infty \bigcup_{j=l}^\infty g_j^{-1}(B)\right) \cap F^c \right)  \cup \emptyset \text{ if } 0 \notin B$$ For justification, $ a \in \left(\left(\bigcap_{l=k}^\infty \bigcup_{j=l}^\infty g_j^{-1}(B)\right) \cap F^c \right)$ $\iff$ $a \in g_j^{-1}(B)$ for infinitely many $j$ . We need only show $g_j^{-1}(B)$ is a measurable set to conclude $f$ measurable. But this is immediate; as $g_j \in L^1$ , there exists measurable and integrable $h_j$ and $h_j = g_j$ a.e., say on set $N$ . Then $$ g_j^{-1}(B) = (h_j^{-1}(B) \cap N) \cup N_B$$ where $N_B \subset N$ , so is a null set in a complete measure space. The measurability of $g_j$ thus follows from measurability of $h_j$ . From $\norm{g_j(x) - g_i(x)} \le 2^{1-j}$ that we proved above we obtain $\norm{g_j(x) - f(x)} \le 2^{1-j}$ for $x \notin F_k$ and $j \ge k$ (As $\norm{\cdot}$ is continuous, we can pass through limits, i.e. $\lim_{i \to \infty}$ ). $\{ \norm{g_j - f} \ge \epsilon\}$ is no larger than $F_k$ for large enough $k$ , but as $\mu(F_k) \to 0$ as $k \to \infty$ , we have that $g_j \to f$ in measure. Noting that $$ \{ x: \norm{f_n(x) -f(x)} \ge \epsilon\} \subset \{ x: \norm{f_n(x) - g_j(x)} \ge \frac{\epsilon}{2}\}\bigcup \{ x: \norm{g_j(x) - f(x)} \ge \frac{\epsilon}{2}\}$$ we conclude $f_n \to f$ in measure (As $f_n$ is cauchy in measure, $\{ x: \norm{f_n(x) - g_j(x)} \ge \frac{\epsilon}{2}\}$ has very small measure for large $n,j$ and as $g_j \to f$ in measure, $\{ x: \norm{g_j(x) - f(x)} \ge \frac{\epsilon}{2}\}$ has very small measure for large $j$ .). Finally, suppose $f_n \to g$ in measure. Similar to above, $$ \{ x: \norm{f(x) -g(x)} \ge \epsilon\} \subset \{ x: \norm{f_n(x) - f(x)} \ge \frac{\epsilon}{2}\}\bigcup \{ x: \norm{g(x) - f_n(x)} \ge \frac{\epsilon}{2}\}$$ for all n. Now we have $f_n \to f$ in measure as well, and using a similar process to above, we conclude that $\mu(\{ x: \norm{f(x) -g(x)} \ge \epsilon\}) = 0$ for all $\epsilon$ (by letting $n$ grow large). Letting $\epsilon$ tend to $0$ through some sequence of values, we conclude that $f=g$ a.e..","['measure-theory', 'solution-verification', 'probability-theory', 'real-analysis']"
3768705,Conjecturing that all AP-GP mixed sequences are the first derivatives of a pure GP,"I was studying some series which are mix of AP and GP as $$(a+d)+(a+2d)r+(a+3d)r^2+......$$ An example could be, $1+2x+3x^2+4x^3+.....$ If i took ${|x|}\lt1$ , and
while calculating the sum of the series upto $\infty$ terms by multiplying the series with $x$ and getting the answer as $$\frac {1}{(1-x)^2}$$ I just realised this series is the first derivative of the following series, $$1+x+x^2+x^3+x^4+.......$$ I tried this with all the examples in my book, all of them could be somehow reduced to the derivative of some GP. So my final question is weather all AP-GP mixed sequences can be expressed as derivative of some GP. If so, how can we prove it?","['derivatives', 'sequences-and-series']"
3768707,"Profesor used this property in a statistics class, first that I've seen this [duplicate]","This question already has answers here : Simplify $\sum (x_i- \mu)^2$ (2 answers) Closed 3 years ago . $$
\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}+n(\bar{X}-\mu)^{2}
$$ My professor didn't prove this, but said it is easy to. I am confused because I can't seem to get it. Would appreciate it if someone could help. I am new to statistics, please bear with me if I make stupid statements.",['statistics']
3768717,The Broken Calculator Problem,"So here is the Problem :- Tom has a specific calculator . Unfortunately, all keys are broken except for one row $: 1,2,3,+,-$ . Tom presses a sequence of $5$ random keys; where at each stroke, each key is equally likely to be pressed. The calculator then evaluates the entire expression, yielding a result of E. Find the Expected Value of E. Before doing this we need to remember some facts :- $(i)$ Excess Operators will be parsed as signs. For e.g. :- $-2-+3$ gives $E = -5$ .and $-+-31$ gives $E = 31$ $(ii)$ Trailing Operators are discarded . For e.g. :- $2-+--$ gives $E = 2$ $(iii)$ Negative Sums are allowed . For e.g. :- $13 - 22$ give $E = -9$ . $(iv)$ A string consisting only of operators , gives $E$ as $0$ . This Problem looks very interesting to me . First of all there can be many different types of sums for E and second, it's definitely not quite easy to get the expected value of it, and I don't know who to start doing it . Any ideas for this problem will be greatly appreciated !!","['probability', 'probability-distributions', 'expected-value', 'recreational-mathematics', 'calculator']"
3768747,"If $A$ is a rank $1$ matrix, then $A^2= \operatorname{Tr}A \cdot A$","I am posting this question because I want to know if my proof is correct (I know that the result holds for $\mathbb{K}=\mathbb{C}$ and I see no reason why it wouldn't work for an arbitrary field, but I just want to be sure). Claim : Let $A \in \mathcal{M}_n(\mathbb{K})$ ( $\mathbb{K}$ is a field, $n\in \mathbb{N}, n\ge 2$ ) such that $\operatorname{rank}A=1$ . Then we have that $A^2=\operatorname{Tr}A\cdot A$ . Proof : Since $\operatorname{rank}A=1$ , $A's$ lines are proportional i.e. $A= \begin{pmatrix}
b_1c_1 & b_1c_2 &...& b_1c_n\\
b_2c_1 & b_2c_2 &...& b_2c_n\\
... & ... & ...& ...\\
b_nc_1 & b_nc_2 &...& b_nc_n\\
\end{pmatrix}=\begin{pmatrix}
b_1 & 0 &...& 0\\
b_2 & 0 &...& 0\\
... & ... & ...& ...\\
b_n & 0 &...& 0\\
\end{pmatrix}\cdot \begin{pmatrix}
c_1 & c_2 &...& c_n\\
0 & 0 &...& 0\\
... & ... & ...& ...\\
0 & 0 &...& 0\\
\end{pmatrix}.$ Let $B:=\begin{pmatrix}
b_1 & 0 &...& 0\\
b_2 & 0 &...& 0\\
... & ... & ...& ...\\
b_n & 0 &...& 0\\
\end{pmatrix}$ and $C:=\begin{pmatrix}
c_1 & c_2 &...& c_n\\
0 & 0 &...& 0\\
... & ... & ...& ...\\
0 & 0 &...& 0\\
\end{pmatrix}$ . We have that $A^2=B(CB)C=\operatorname{Tr}A\cdot BC=\operatorname{Tr}A\cdot A$ and we are done.","['matrices', 'solution-verification', 'linear-algebra']"
3768778,To show some set is positive Lebesgue measure,Let $P$ be a set of positive Lebesgue measure in $\mathbb{R}^n$ and $O$ be an open set in $\mathbb{R}^n$ such that $E=P\cap O$ is a set of zero Lebesgue measure. Can we conclude that $P\setminus \overline{E}$ is a set of positive Lebesgue measure?,"['measure-theory', 'lebesgue-measure']"
3768789,Combination to find integers satisfying a condition,"Let $n$ and $k$ be positive integers such that $n\ge\frac{k(k+1)}{2}$ .
The number of solutions $(x_1,x_2,\dots,x_{k})$ , with $x_1\ge1$ , $x_2\ge2$ ,..., $x_{k}\ge k$ for all integers satisfying $x_1+x_2+\dots+x_{k}=n$ is? I substituted the last equation in the first inequality. $$x_1+x_2+\dots+x_{k}\ge\frac{k(k+1)}{2}.$$ Took $x_1$ as $1+ t_1$ , $x_2$ as $2+t_2$ ...where $t_i\ge 0$ . On simplifying by using sum of k numbers, I end with with $t_1+t_2+\dots+t_{k} \ge0$ . Since $x_1,x_2$ ... are in increasing order, and sum of all $t$ values is $0$ , I conclude that this is only possible when $t=0$ . Therefore only one solution is possible when $LHS = RHS$ . The inequality is not valid. But the answer is $\frac{1}{2}(2n-k^2+k-2)$ . What am I missing here?","['elementary-number-theory', 'inequality', 'integers', 'combinatorics']"
3768791,Solving $\arg\left(\frac{1}{z}\right) = \arg(\bar z)$?,"$$\arg\left(\frac{1}{z}\right) = \arg(\bar z)$$ So, I used the definition $z\bar z = |z|^2$ Then I divided both sides by $z$ ; $$\bar z= \frac{|z|^2}{z}$$ But $|z|^2$ is a scalar, $>0$ Then $$\arg\left(\frac{|z|^2}{z}\right) = \arg(\bar z)$$ This is where I am stuck. Is $|z|^2$ a constant? Do I take it out and  write it as $|z|^2\arg\left(\frac{1}{z}\right)$ or no; what do I do?","['complex-analysis', 'complex-numbers']"
3768814,"Triangle tangent to 3 Parabolas, finding the common area","Triangle $ABC$ , $AB=4$ , $BC=15$ , $AC=13$ . Two sides are tangents to the respective Parabolas. We have to find the area shaded. My approach- I tried finding the area of the quadratures(Archimedes) formed but it
doesn't help as- I have to find the area between the 2 intersecting
Parabolas also which I can't find.","['area', 'conic-sections', 'geometry']"
3768870,"If the largest positive integer is n such that $\sqrt{n - 100} + \sqrt{n + 100}$ is a rational no. , find the value of $\sqrt{n - 1}$ .","So here is the Problem :- If the largest positive integer is n such that $\sqrt{n - 100} + \sqrt{n + 100}$ is a rational no. , find the value of $\sqrt{n - 1}$ . What I tried :- I think that for $\sqrt{n - 100} + \sqrt{n + 100}$ to be a rational no. , both $(n - 100)$ and $(n + 100)$ have to be squares. Suppose :- $(n - 100)$ = $k^2$ and $(n + 100)$ = $m^2$ for some positive integers $k,m$ , and in the end I could only deduce that $(m + 10)(m - 10) = k^2 + 100$ , but then I couldn't proceed . Also by guesswork, I could deduce that for $n = 125$ , both nos. do become squares, although I don't know whether $n = 125$ is the highest or not. Any hints or explanations to this problem will be greatly appreciated !","['number-theory', 'sums-of-squares', 'problem-solving', 'elementary-number-theory']"
3768872,"How to solve $\int_0^1dx\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}\,dy$","The original question is: Prove that: $$\begin{aligned}\\
\int_0^1dx\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}\,dy\neq\int_0^1dy&\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}\,dx\\
\end{aligned}\\$$ But I can't evaluate the integral $$\int_0^1dx\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}\,dy$$ At first, I assumed $x^2+y^2=z^2$ . But, it is so complicated. Then, I assumed $x=r\cos\theta$ and $y=r\sin\theta$ . But, I can't calculate the limits. Solving the equations I got three values of $\theta$ i.e. $\theta=0$ , $\theta=\frac{\pi}{4}$ and $\theta=\frac{\pi}{2}$ . I am just confused. Please help.","['multivariable-calculus', 'calculus', 'definite-integrals']"
3768912,Algebra vs. Geometry: understanding a quote by Michael Atiyah,"Algebra is the offer made by the devil to the mathematician. The devil says: ""I will give you this powerful machine, it will answer any question you like. All you need to do is give me your soul: give up geometry and you will have this marvelous machine. -- Michael Atiyah This captivating remark confuses me -- what is the fundamental difference between algebra and geometry? I thought these labels more represented historical trends in mathematical inquiry rather than real technical distinctions. See Difference between algebra and geometry Atiyah seems to be suggesting a distinction between the reasoning/axioms associated with geometry and those associated with algebra. Is there a difference? If so, what is it?","['abstract-algebra', 'soft-question', 'geometry', 'math-history']"
3768946,How to solve the ODE $y' = \frac{x+y-2}{y-x-4}$?,"I am trying to solve the ODE $$y' = \frac{x+y-2}{y-x-4} \tag1 $$ This is a homogeneous special form ODE. Let $x = u -1$ and $y=v+3$ in order to transform it to a homogeneous ODE. Hence, $$ (1) \iff v'(u) = \frac{u+v(u)}{v-u} \tag 2$$ At last let $v(u) = z(u)u \iff v'(u) = z'(u)u+z(u)$ therefore, $$ (2) \iff \frac{z'(u)}{z(u)+1} = \frac1u \tag 3$$ $(3)$ is a seperate variable ODE. Therefore we integrate both sides. $$ \int \frac{z'(u)}{z(u)+1} \,du = \int \frac1u \,du $$ This integral seems to be easy to evaluate $$ \int \frac{z'(u)}{z(u)+1} \, du $$ but I can't get my head around it. Any ideas?","['integration', 'indefinite-integrals', 'calculus', 'ordinary-differential-equations']"
3768973,Branch cut of square root,I don't really understand how branch cuts work. Let's take the complex function $f(z) = \sqrt{z}$ . Apparently this function is not defined for $\mathbb{R}^{-}$ . But why? We defined $i$ to be $\sqrt{-1}$ and now it's multivalued?,"['complex-analysis', 'branch-cuts']"
3768983,Convergence of $\displaystyle\sum_{n=1}^{\infty}\frac{(2i)^{n}\cdot n!}{n^{n}}$,"I have to show the series $$\sum_{n=1}^{\infty}\frac{(2i)^{n}\cdot n!}{n^{n}}$$ converges. I know it does and I tried to use the ratio test, but in the final limit, I got $$\lim_{n\to\infty}2i\left[\left(1+\frac{1}{n}\right)\right]^{-1}$$ which results at $$\frac{2i}{e}$$ and I don't know if I can't say it's smaller than 1 because of the imaginary unity.","['complex-analysis', 'convergence-divergence', 'sequences-and-series']"
3769005,Second order derivative of a chain rule (regarding reduction to canonical form),"I've been stuck on this for a couple of days. So this is from this book (""Partial Differential Equations in Mechanics 1"", page 125). Section 4.2 Reduction to canonical forms, which leads to the development of the Laplace equation. In this section, I don't understand how they expand the second-order partial derivative: Where, Here is what I got so far. When I do it, I only get to have 4 terms, and not 5 like what's in the book. Here I apply product rule first and then the chain rule (Note, I'm using square brackets to indicate that I am taking the partial derivative of whatever is in them. Just to keep it organized). $$\begin{align}
\frac{\partial}{\partial x}\frac{\partial u}{\partial x} &= \\
&= \frac{\partial}{\partial x} \biggl( \frac{\partial u}{\partial \xi} \frac{\partial \xi}{\partial x} + \frac{\partial u}{\partial \eta} \frac{\partial \eta}{\partial x} \biggr) \\
&=\frac{\partial}{\partial x} \biggl( \frac{\partial u}{\partial \xi} \frac{\partial \xi}{\partial x}\biggr) + \frac{\partial}{\partial x} \biggl(\frac{\partial u}{\partial \eta} \frac{\partial \eta}{\partial x} \biggr) \\
&= \frac{\partial}{\partial x} \biggl[ \frac{\partial u}{\partial \xi} \biggr] \frac{\partial \xi}{\partial x} + \frac{\partial u}{\partial \xi} \frac{\partial}{\partial x} \biggl[ \frac{\partial \xi}{\partial x} \biggr] + 
\frac{\partial}{\partial x} \biggl[ \frac{\partial u}{\partial \eta} \biggr] \frac{\partial \eta}{\partial x} + \frac{\partial u}{\partial \eta} \frac{\partial}{\partial x} \biggl[ \frac{\partial \eta}{\partial x} \biggr] \\
\text{Now the chain rule:}\\
&= \frac{\partial}{\partial \xi}\biggl[\frac{\partial u}{\partial \xi}\biggr] \frac{\partial \xi}{\partial x} \frac{\partial \xi}{\partial x} 
+ \frac{\partial u}{\partial \xi} \frac{\partial^2 \xi}{\partial x^2} 
+ \frac{\partial}{\partial \eta}\biggl[\frac{\partial u}{\partial \eta}\biggr] \frac{\partial \eta}{\partial x} \frac{\partial \eta}{\partial x} 
+ \frac{\partial u}{\partial \eta} \frac{\partial^2 \eta}{\partial x^2} \\
&=\frac{\partial^2 u}{\partial \xi^2} \biggl(\frac{\partial \xi}{\partial x} \biggr)^2 
+ \frac{\partial u}{\partial \xi} \frac{\partial^2 \xi}{\partial x^2} 
+ \frac{\partial^2 u}{\partial \eta^2} \biggl(\frac{\partial \eta}{\partial x} \biggr)^2 
+ \frac{\partial u}{\partial \eta} \frac{\partial^2 \eta}{\partial x^2} 
\end{align}
$$ My tree of the chain rule looks like this (is it correct?) In addition, if someone could explain why this chain rule is valid? Granted, this may be a whole topic on its own, so if you could just point to some resource or what this particular operation is called, that would do. $$
\frac{\partial}{\partial x}\biggl[ \frac{\partial u}{\partial \xi} \biggr] = \frac{\partial}{\partial \xi} \biggl[\frac{\partial u}{\partial \xi}\biggr]\frac{\partial \xi}{\partial x}
$$ Thank you in advance. UPDATE: (as per answer by @peek-a-boo) P.S. Corrections or edits are welcomed.","['multivariable-calculus', 'partial-differential-equations']"
3769007,From pointwise convergence in probability to uniform convergence in probability for non-decreasing random processes,"I have a sequence of non-decreasing random processes $D_n:[0,1]\rightarrow \mathbb{R}$ (for each $n\geq 1$ , $u\leq v$ implies $D_n(u)\leq D_n(v)$ ) such that $D_n(0)=0$ a.s. and for every $t\in [0,1]$ the following convergence holds: $D_n(t)\overset{\mathbb{P}}{\underset{n\to\infty}{\longrightarrow}}t$ (in fact I can even prove it in $\mathbb{L}^2$ , but it doesn't seem necessary). I want to prove a uniform convergence in probability, i.e. $\sup_{t\in [0,1]}  \vert D_n(t) -t\vert \overset{\mathbb{P}}{\underset{n\to\infty}{\longrightarrow}}0$ . I managed to prove it (more details below), but the idea is pretty similar to the proof of a standard analytic result (see Julian's answer for more details) : pointwise convergence of monotonous functions on a compact set to a continuous limit implies uniform convergence. I am asking : Is there a way to apply directly (without rewritting the proof) this theorem in such context, even if the functions are random  ? If not, is there an ersatz of Dini's Theorem for convergence in probability ? It seems too obvious for not having been done yet... N.B: The ""standard analytic result"" mentioned above is called ""second Dini's Theorem"" in french, but seems to have no english name or source. My proof: Let $\varepsilon >0$ , consider an integer $m>\frac{2}{\varepsilon}$ . Then $\Big( \vert D_n(\frac{k}{m})-\frac{k}{m}\vert \leq \frac{\varepsilon}{2} \ \forall \ k=0,\dots, m\Big)$ implies $\sup_{t\in [0,1]}\vert D_n(t)-t\vert \leq \varepsilon$ (because the random functions $D_n$ are non-decreasing). Thus the probability of the first event is smaller or equal to the probability of the second, i.e.: $$\mathbb{P}\left(\left\vert D_n\left(\frac{k}{m}\right)-\frac{k}{m}\right\vert \leq \frac{\varepsilon}{2} \ \forall \ k=0,\dots, m\right)\leq \mathbb{P}\left(\sup_{t\in [0,1]}\vert D_n(t)-t\vert \leq \varepsilon\right).$$ If I consider the complementary events, I can use the union bound to get $$\mathbb{P}\left(\sup_{t\in [0,1]}\vert D_n(t)-t\vert > \varepsilon\right)\leq \sum_{k=0}^m \mathbb{P}\left( \left\vert D_n\left(\frac{k}{m}\right)-\frac{k}{m}\right\vert > \frac{\varepsilon}{2}\right).$$ The sum in the right-hand side converges to $0$ since it is a sum of finitely many terms going to $0$ (the choice of $m$ only depends on $\varepsilon$ , not on $n$ ).","['stochastic-processes', 'convergence-divergence', 'uniform-convergence', 'probability']"
3769072,Proof of Morera's Theorem for Triangular Contours,"Sorry if this has been proven previously on MSE but I cannot find an obvious duplicate. I am attempting to prove the stronger version of Morera's theorem namely: If $f:U\mapsto\mathbb{C}$ is a continuous function on an open set $U$ such
that $\int_\gamma f(z)\,\mathrm{d}z=0$ for all triangular contours $\gamma$ contained in $U$ , then $f$ is holomorphic on $U$ . Proof (attempt): Let $a\in U$ . Since $U$ is open, $\exists\,r\gt0$ such that $B(a,r)=\{z\in\mathbb{C}:|z-a|\lt r\}\subseteq U$ . Now consider $f$ restricted to the domain $B(a,r)$ . Using the given assumptions, this restriction of $f$ is continuous and satisfies $\int_\gamma f(z)\,\mathrm{d}z=0$ for all triangular contours $\gamma$ contained in $B(a,r)$ . Then we can define $F:B(a,r)\mapsto\mathbb{C}$ by $$F(z)=\int_{[a,z]}f(w)\,\mathrm{d}w$$ where $[a,z]$ is the line segment from $a$ to $z$ in $\mathbb{C}$ . This function is now well-defined as $B(a,r)$ is connected. Next we can calculate \begin{align}
F'(z)
&=\lim_{h\to0}\frac{F(z+h)-F(z)}h\\
&=\lim_{h\to0}\frac{\int_{[a,z+h]}f(w)\,\mathrm{d}w-\int_{[a,z]}f(w)\,\mathrm{d}w}h\\
&=\lim_{h\to0}\frac{\overbrace{\int_{[a,z+h]}f(w)\,\mathrm{d}w+\int_{[z+h,z]}f(w)\,\mathrm{d}w+\int_{[z,a]}f(w)\,\mathrm{d}w}^{=\int_\gamma f(w)\,\mathrm{d}w=0}+\int_{[z,z+h]}f(w)\,\mathrm{d}w}h\\
&=\lim_{h\to0}\frac{\int_{[z,z+h]}f(w)\,\mathrm{d}w}h\\
&=\lim_{h\to0}\frac1h\int_0^1f(z+ht)\cdot h\,\mathrm{d}t\\
&=\lim_{h\to0}\int_0^1f(z+ht)\,\mathrm{d}t\\
&=\int_0^1\lim_{h\to0}f(z+ht)\,\mathrm{d}t\\
&=\int_0^1f(z)\,\mathrm{d}t\qquad(f\text{ continuous})\\
&=f(z)\\
\end{align} Thus $F$ is holomorphic on $B(a,r)$ with derivative $f$ . So, in particular, we can apply Cauchy's differentiation formula to give $$f'(a)=F''(a)=\frac1{\pi i}\int_\gamma\frac{F(z)}{(z-a)^3}\mathrm{d}z$$ for a suitable contour $\gamma$ . But $a\in U$ was chosen arbitrarily and hence $f$ is holomorphic on $U$ .","['complex-analysis', 'contour-integration', 'solution-verification', 'cauchy-integral-formula']"
3769097,"Showing that $(\mathbb{C}[x,y]/(xy))_x\cong \mathbb{C}[x]_x$","I'd like to understand rigorously why $(\mathbb{C}[x,y]/(xy))_x\cong \mathbb{C}[x]_x$ . Intuitively, it seems reasonable. However I'd like to know whether the kernel of the map I've constructed for the isomorphism is correct. We can start with a map $f:\mathbb{C}[x,y]\rightarrow \mathbb{C}[x]_x$ mapping $f(x,y) \mapsto f(x,0)\mapsto f(x,0)/1$ . If the kernel of this map is $(xy)$ ,we get a map $f:\mathbb{C}[x,y]/(xy)\rightarrow \mathbb{C}[x]_x$ . This gives us an induced map from $(\mathbb{C}[x,y]/(xy))_x\rightarrow \mathbb{C}[x]_x$ by the universal property of localization, and it is not hard to show that this is a bijection. However, is the kernel in fact $(xy)$ ? We have $\rm ker f= \{f(x,y)\in \mathbb{C}[x,y]\mid f(x,0)/1=0/x^n \text{ for some $n$}\}$ , and so the kernel consists of elements of the form $x^nf(x,y)$ where $f(x,0)=0$ or $x=0$ . Does this imply that the kernel is $(xy)$ ?","['localization', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3769113,Book Request - General Relativity (for mathematicians),"Please can someone recommend some books on 'higher-level' (couldn't think of a better way to phrase...) books on GR? I've read over half of Wald (General Relativity) and I'm about to finish Carroll (Spacetime and Geometry). I didn't really enjoy reading Wald (sacrilege!), but I've really really enjoyed Spacetime and Geometry - I felt it was more modern, and almost like I was being lectured in the subject. For some reason, it didn't feel the same with Wald, most probably because I read Wald from a .pdf and Carroll from hardback. I really enjoyed the Black Hole aspects of S&G, but I feel that I'm little weak on gravitational waves. I'd also like to see some more advanced differential geometry too, like spinors and tetrads (even though I don't know what they are yet, they sound important). If someone could recommend a book with the feel of Carroll but more advanced content, I'd be extremely grateful. I feel the answer to my question is to go back and try Wald again, however I would like some other opinions!","['book-recommendation', 'general-relativity', 'reference-request', 'differential-geometry']"
3769134,Does this orthogonal matrix parametrization have a name?,"Given two linearly independent unit vectors $u, v \in \mathbb{R}^{n,1}$ , the matrix $$
P(u, v) = I + 2 vu^{T}-\frac{(u+v)(u+v)^{T}}{1+u^Tv}
$$ is the unique special orthogonal matrix that brings $u$ to coincide with $v$ and reduces to the identity when projected to the orthogonal complement of $\mathrm{span}(u,v)$ . That is: $$P^T(u,v) P(u,v) = I$$ $$P(u,v)u = v$$ $$P(u,v)w = w\quad \forall w \in \mathbb{R}^{n,1}\ /\ u^Tw = 0 \wedge v^Tw = 0$$ (Note that for $n > 3$ not all special orthogonal matrices can be expressed in this way.) I've never encountered this parametrization before today. Does it have a name?","['reference-request', 'matrices', 'orthogonal-matrices', 'linear-algebra', 'terminology']"
3769136,Distribution of the ratio of two Normal variables,"Considering a sample of size $n$ from a $N(\mu,\sigma^2)$ distribution: $X_1, \ldots , X_n$ , I need to find the ratio of \begin{equation}
 R = \frac{\tilde{\mu} - \mu}{\hat{\mu} -\mu},
\end{equation} where $\tilde{\mu} = X_1 $ one observation, and $\hat{\mu} = \bar{X}$ , the sample mean. I know that $ \frac{\tilde{\mu} - \mu}{\sigma} \sim N(0,1)$ , $ \frac{\sqrt{n}(\hat{\mu} - \mu)}{\sigma} \sim N(0,1)$ , and the ratio of two normally distributed variables is Cauchy - for this to happen do we need for the variables to be independent? Also, there is a $\sqrt{n}$ coming in the picture when simplifying the ratio that I am not sure how to handle.","['statistics', 'probability-distributions', 'normal-distribution']"
3769173,Using Runge-Kutta integration to increase the speed and stability of gradient descent?,"For a gradient descent problem with $\mathbf{x}\in \mathbb{R}^N$ I can evaluate the gradient $\mathbf{\nabla}_\mathbf{x} \in \mathbb{R}^N$ that reduces the least squares error, $y$ . However, simply updating the position using $\mathbf{x'} = \mathbf{x} + \mathbf{\nabla}_\mathbf{x}$ converges very slowly to the global minimum of the least squares error (which is also the global minimum of the gradient magnitude, where the gradient is zero). I tried simply scaling up the step, i.e. $\mathbf{x'} = \mathbf{x} + h\mathbf{\nabla}_\mathbf{x}$ , however while this dramatically improves convergence times in some cases, it can become unstable in others (particularly when some of the components of $\mathbf{\nabla}_\mathbf{x}$ are much larger than others -- scaling up all components of the gradient can cause the gradient descent method to ""climb up the side of a canyon"" rather than descending the canyon, and the system can either oscillate or explode). I would like to use the 3rd order Runge-Kutta method to follow the curvature of the gradient space, so that I can take larger steps without the system blowing up. I have applied this to simulating mass-spring systems before (using Runge-Kutta integration to integrate acceleration to find velocity, and velocity to find position) -- however I can't figure out how to apply it to this gradient descent problem. I think I have some fundamental misunderstanding about how the Runge-Kutta methods work. They requires a function $f=(x, y)$ to be defined, which I believe computes the gradient of the curve at $x$ . However I don't understand why $y$ needs to be supplied to the function -- isn't $y$ a function of $x$ ? Can Runge-Kutta even be applied to the gradient descent problem? It seems like there should be a way to adapt Runge-Kutta to gradient descent, since each update step $\mathbf{x'} = \mathbf{x} + \mathbf{\nabla}_\mathbf{x}$ is basically an integration step. Is the step size $h$ simply the magnitude of the gradient, i.e. $h_i = |{\mathbf{\nabla}_{\mathbf{x}_i}}|$ and $\mathbf{y}_i = {\mathbf{\nabla}_{\mathbf{x}_i}} / h_i$ ? If Runge-Kutta is not applicable here, can somebody please suggest a robust and fast gradient descent algorithm to try? Some more detail: in the case of this problem, the gradient surface is fairly smooth, and quite strongly convex (there are few if any local minima that are not global minima), but the error surface is less convex. In other words, sometimes gradient descent will continue walking down the gradient slope in the direction of the global minimum of gradient, and the least squares error will increase temporarily before decreasing to the global minimum of least squares error. (The gradient is not computed from the least squares error measure itself, but using a different method that directly identifies the locally-best least squares solution, which moves the system closer to the globally-optimal least squares solution.) The gradient is therefore more reliable for gradient descent than the slope of the least squares error surface.","['ordinary-differential-equations', 'runge-kutta-methods', 'least-squares', 'numerical-methods', 'gradient-descent']"
3769270,Can we really compose random variables and probability density functions?,"A renowned professor of statistics (whose name I will not reveal here) told me that the notation $p(x)$ makes perfect sense when $p$ is a pdf and $x$ is a RANDOM variable (i.e. a function). I was a bit surprised because I never thought that a pdf accepts functions as input, but, actually, $p(x)$ means a composition of the pdf with the r.v. $x$ (a function), i.e. composition of functions, i.e. it would be equivalent to $p \circ x = f(x)$ . This information revolutionized my view of statistics and revolutionized the way I look at expressions, like $p(x)$ , in many formulas, where I thought that $p(x)$ was actually an output (a number) of the function $p$ (e.g. a pdf) when evaluated at the point $x$ of its domain, even though, in certain cases, it seemed like $p(x)$ needed to be a function (but I only thought that whoever had written that was just careless and wrote $p(x)$ instead of just $p$ ). Now, what those people had written, i.e. $p(x)$ , probably made sense, because $p(x)$ is a function, and, actually, a random variable, because $x$ is a random variable. So, formally, why does it really make sense to compose random variables and p.d.f.s? An r.v. $x$ is typically defined as $x \colon \Omega \to E$ , where $\Omega$ is the sample space and $E$ is a measure space (e.g. $\mathbb{R}$ should be measurable). What are the domain and codomain of the pdf? The domain should be $E$ , because, otherwise, why can we compose $p$ (the pdf) and $x$ (the random variable)? Moreover, in many cases, we define what is apparently a pdf, and then we use it in places that require ""probability distributions"" or ""random variables"".  For example, on page 13 of these notes , we define the multi-variate Gaussian pdf as follows $$
p(x)=\frac{1}{(2 \pi)^{n / 2} \operatorname{det}(\Sigma)^{1 / 2}} \exp \left(-\frac{1}{2}(x-\mu)^{T} \Sigma^{-1}(x-\mu)\right)
$$ I thought that the $x$ in the formula above was the dummy variable of the pdf Gaussian (at least, that's how I used to read that formula above), i.e. an element of its domain, but, then, after that definition, the author derives the analytic expression for the computation of the KL divergence using $x$ as a random variable, because, at some point, he will take the expectation of $x$ and, as far as I know, we can only take expectations of random variables (with respect to distributions), so $x$ must be a random variable there. So, is $x$ , in the definition of the Gaussian pdf above, also a random variable, and does that mean that the pdf (denoted by $p(x)$ ) is also a random variable?","['measure-theory', 'statistics', 'function-and-relation-composition', 'probability-theory', 'random-variables']"
3769320,Is it true that the infinity norm of the matrix exponential $\|e^{At}\|_{l^\infty} \leq 1$ if $A$ is a negative diagonally dominant matrix?,"Assume $A = (a_{ij}) \in \mathbb{R}^{N\times N}$ is negative diagonally dominant matrix, i.e. $|a_{ii}| \geq \sum_{j = 1, j\neq i}^{N} |a_{ij}|$ with $ a_{ii} < 0, 1 \leq i \leq N$ . For example: \begin{equation}
A = 
\left[
\begin{array}{ccccc}
-2 & 1  &   &  & 1 \\
1  & -2 & 1 &  & \\
 & \cdots & \cdots & \cdots &  \\
 &        &  1 & -2 & 1\\
 1&     &   & 1 & -2 \\
\end{array}
\right]_{N\times N}
\end{equation} Is it true that the infinity norm of the matrix exponential $\|\mathrm{e}^{A t}\|_{l^\infty} \leq 1, \forall t \geq 0$ ? EDIT 1 The $l^\infty$ norm of a matrix $B  = (b_{ij}) \in \mathbb{R}^{N\times N}$ is given by \begin{align*}
\|B\|_{l^\infty} = \mathop{max}_{i = 1, \cdots, N}\{\sum_{j = 1}^{N} |b_{ij}| \}.
\end{align*} How to prove it? Lemma 3.1 of (Du Qiang, et al., 2019, MAXIMUM PRINCIPLE PRESERVING EXPONENTIAL TIME DIFFERENCING SCHEMES FOR THE NONLOCAL ALLEN-CAHN EQUATION)[https://arxiv.org/pdf/1902.04998.pdf] shows that (I think there is a typo in the stricit diagonally dominant condition, $j \neq i$ is missing) When $\kappa = 0$ is it still true that $\|\mathrm{e}^{A t}\|_{l^\infty} \leq 1$ ? EDIT 2 I wrote a short matlab code to verify the inequality N = 10;
for i = 1:100000
    A0 = 2*rand(N, N) - 1; % random value in [-1, 1]
    A = A0 + A0'; % construct symmetric matrix;
    v = -(sum(abs(A), 2) - abs(diag(A)));
    for i = 1:N
        A(i,i) = v(i); % Assign v to the diagonal elements
    end
    tmp = norm(expm(A), inf);
    if  tmp > 1
        tmp
    end
end Thank you very much!","['positive-semidefinite', 'normed-spaces', 'matrix-exponential', 'matrices', 'numerical-linear-algebra']"
3769329,$2^x$ is irrational if $x$ is irrational?,"Prove/Disprove that if $x$ is irrational, then $2^x$ is also irrational. My attempt for the proof:
Suppose $2^x>0$ is a rational number, then $2^x=\frac{a}{b}$ for some natural numbers $a$ and $b$ . Taking logarithm with base $2$ on both sides to get, $x=\log_2 \frac{a}{b}$ . Here I stuck! how to reach at $x$ is rational?",['real-analysis']
3769349,What is the definition of a Gaussian random variable?,"Some people define a Gaussian random variable as a random variable that has a Gaussian p.d.f., which is defined (for the univariate case) as $$
{\displaystyle f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}}
$$ Now, this is fine, but $f$ above is not the Gaussian random variable, or is it? A random variable must take values from the sample space $\Omega$ to measurable space, but isn't the Gaussian p.d.f. defined from $\mathbb{R}$ to $\mathbb{R}$ ? So, what is the formal definition of a Gaussian random variable (i.e. do not tell me that it's a random variable with p.d.f. $f$ ). I want to know how it is formally defined. For example, a Bernoulli r.v. is defined as $$
{\displaystyle Y(\omega )={\begin{cases}1,&{\text{if }}\omega ={\text{heads}},\\[6pt]0,&{\text{if }}\omega ={\text{tails}}.\end{cases}}}
$$ What is the equivalent definition of a Gaussian r.v.? I am asking this question after having asked these ones: Can we really compose random variables and probability density functions? and Why is the exact relationship between a Gaussian p.d.f. and its associated probability measure and random variable? .","['statistics', 'normal-distribution', 'probability-theory', 'random-variables']"
3769360,Irreducible representation is injective,"Let $\rho:G \to GL(V)$ a irreducible representation where $|G|=p^3$ and $\dim(V)\neq 1$ over $\mathbb{C}$ , then $\rho$ is injective. I managed to reach the following relationship $$|G|=|\ker\rho|\dim(V)^2+\sum_{g\notin\ker\rho}|\chi(g)|^2$$ where $\chi$ is the character of $\rho$ . I think this can help to get that the kernel is trivial, but I couldn't get anywhere. I am also wondering about the importance of the order of the group being $p^3$ .","['group-theory', 'abstract-algebra', 'representation-theory']"
3769388,Critical Point Classification,"We're modeling competing species in my mathematical modeling class and we were taught the nullclines and direction arrows as a method to classify what critical points are and their stability. Usually, there are four directions arrows around each critical point that help determine whether it's a sink, a source, a saddle, or a center/spiral. But I just came across this case, where I have 6 direction arrows around one critical point and I have no idea how to go about classifying it. I tried to search online but I don't know if I'm not using the correct words or if there's just something wrong about this. The equation system we have is $\frac{dx}{dt} = x(a-bx-ky)$ $\frac{dy}{dt} = y(c-dy-\sigma x)$ and we're told to analyze what happens when $\frac{a}{k}=\frac{c}{d}$ Here's the graph I got. I can see that $(0,0)$ is a source and $(\frac{a}{b},0)$ is a saddle.
Not sure what $(0,\frac{a}{k}=\frac{c}{d})$ is supposed to be or how to analyze it. The $\frac{dx}{dt}$ nullclines are in green, and the $\frac{dy}{dt}$ nullclines are in blue.",['ordinary-differential-equations']
3769415,Finding values using the equation of $x$ that satisfies $\left\{ x \right\} + \left\{ {\frac{1}{x}} \right\} = 1$,"Let the real number $x$ satisfies $\left\{ x \right\} + \left\{ {\frac{1}{x}} \right\} = 1$ and $k$ denotes the value of $\left\{ {{x^3}} \right\} + \left\{ {\frac{1}{{{x^3}}}} \right\} = k$ (where $\{\cdot\}$ denotes
fractional part function). Find the value of $k$ . My approach is as follows: $x$ cannot be an integer, $x = n + a,a \in \left( 0,1 \right)$ $$a + \left\{ {\frac{1}{{n + a}}} \right\} = 1 \Rightarrow \left\{ {\frac{1}{{n + a}}} \right\} = 1 - a = t,t \in \left( {0,1} \right)$$ Not able to proceed from here.","['fractions', 'functions']"
3769433,If $H^*$ is isomorphic with $H$ is H always a Hilbert space?,"If $H$ is a Hilbert space then $H^*$ is isomorphic with $H$ . I am asking if we have a vector space H equipped with inner product ( , ) and $H^*$ is isomorphic with $H$ is it true to say that $H$ is Hilbert?
Edit:I am also interested for cases that the norm of H is not the ordinary norm given from inner product","['hilbert-spaces', 'functional-analysis']"
3769456,"Given $k, a \in \mathbb{R}$, find a polynomial $P$ such that $P(k) = a$","You are given two real numbers $k,a \in \mathbb{R}$ , and you are promised that there is a polynomial with integer coefficients $P \in \mathbb{Z}[X]$ such that evaluating it on $k$ yields $a$ , i.e. Promise: $\ \exists P \in \mathbb{Z}[X] \ \ \ s.t.\ \ P(k) = a$ Problem: find such $P$ . In general, I'd expect more than one solution to exist; then I'd be interested in obtaining the one with lowest degree. Note that $k$ may be any real number, and a particular case of interest (due to context, see below) is $k = -\frac{\sqrt{2}}{2}$ . Some context. I'm a PhD student in computer science and this problem came up in my research when trying to reverse engineer a black box. Essentially, $k$ is a parameter set a priori and $a$ is the output the black box produces; finding $P$ would let me know valuable information about the internal workings of the black box. I am aware that, if it were the case that $k \in \mathbb{N}$ and $a > 0$ , then I could obtain each coefficient of the polynomial by calculating remainders: $p_0 = a \bmod k$ , gives the coefficient of the 0-degree term; $p_1 = \frac{a - p_0}{k} \bmod k$ , gives the coefficient of the 1-degree term, and so on... $p_2 = \dots$ However the fact that $k$ may be any real number prevents me from using this kind of approach from discrete maths.","['real-numbers', 'number-theory', 'ring-theory', 'polynomials']"
3769470,"If there is an into isometry from $(\mathbb{R}^m,\|\cdot\|_p)$ to $(\mathbb{R}^n, \|\cdot\|_q)$ where $m\leq n$, then $p=q$?","Let $p,q\in [1,\infty)$ .
Note that $p,q\neq\infty$ .
Let $m\geq 2$ be a natural number. The paper Isometries of Finite-Dimensional Normed Spaces by Felix and Jesus asserts that if $(\mathbb{R}^m,\|\cdot\|_p)$ is isometric to $(\mathbb{R}^m, \|\cdot\|_q)$ , then $p =q$ . I am interested in the case when they have different dimensions.
More precisely, Let $m,n\geq 2$ be natural numbers such that $m\leq n$ and $T:(\mathbb{R}^m,\|\cdot\|_p)\to (\mathbb{R}^n, \|\cdot\|_q)$ be a linear operator (Note that the dimension of domain and codomain are different).
If $T$ is an isometry (not necessarily onto), does $p = q$ ? By the paper above, if $m=n$ , then we have $p=q$ .
However, if $m<n$ , I am not sure whether the same result holds. If there is a reference that cites this result, it would be good if someone can provide it.","['reference-request', 'isometry', 'functional-analysis', 'real-analysis']"
3769496,How do I use the loop invariant to show that this code correctly computes $\sum_{k=0}^{n-1} 2k$?,"I am supposed to use the loop invariant (I) to show that the code below correctly computes $$\sum_{k=0}^{n-1} 2k$$ evenSum(int n){
   p = 2(n-1)
   i = n-1
   while i>0 do{
      //(I)  $p=\sum_{k=i}^{n-1} 2k$
      i--
      p = p+2i
      }
   return p
} For clarity, (I) in the code above is $$p = \sum_{k=i}^{n-1} 2k$$ Here's my work so far: Proving the base case of the loop invariant (I): $$p=2(n-1);$$ $$ i = n-1; $$ $$\sum_{k=i}^{n-1}2k = \sum_{k=n-1}^{n-1}2k= 2(n-1) \Rightarrow \sum_{k=i}^{n-1}2k = p$$ Inductive step: Assume (I) is true before an iteration $$p_{old}= \sum_{k=i_{old}}^{n-1}2k$$ We need to prove (I) is true after an iteration $$p_{new}= \sum_{k=i_{new}}^{n-1}2k$$ So, I'm stuck on completing the proof. I know that I need to utilize $p = p + 2i$ from the code, perhaps setting it up as $p_{new} = p_{old} + 2(i_{old}-1)$ ? I'm uncertain as to how to complete my proof, any help or input would be appreciated!","['programming', 'discrete-mathematics', 'algorithms']"
3769517,Simplifying inequality contradicts actual inequality,"I am doing a problem and am not sure why the final step is the following $x^{2}<4 <=> -2<x<2$ When simplifying $x^{2}<4$ it becomes $x<±2$ which is the same as $x<2$ , $x<-2$ but this does not match the actual inequality of $-2<x<2$ , since $x>-2$ not $x<-2$ which is one of the inequalities
obtained in the line above My question: Inequalities are swapped when multiplying & dividing by negative numbers , so is the reason why $x^{2}<4 <=> -2<x<2$ because square rooting both sides of $x^{2} <4$ give $x<2$ AND $x >-2$ since $4$ became $-2$ so it is like the inequality rule of dividing by a negative number ?
Hence the sign is flipped when considering $√(4)=-2$ ? $<=> 4/-2=-2$ ? What I think: $x^{2}<4$ gives four possible inequalities: (1) $x<2$ (2) $-x<-2=>x>2$ (3) $-x<2=>x>-2$ (4) $x<-2$ . By inspection, (1) & (3) are the actual inequalities and (2) & (4) are false solutions. (1) & (3) = $x<2$ , $x>-2$ $<=>$ $-2<x<2$ Is this the reason why??","['algebra-precalculus', 'inequality']"
3769561,Convergent Sequences in Extremally Disconnected Hausdorff Spaces,"It's written in Willard (15G.3) that the only convergent sequences in a Hausdorff Extremally Disconnected space are the eventually constant sequences. However, it has not provided a proof. I've tried to derive this myself, but am unable to do so. There's another post on Math Stackexchange about this problem, but a solution wasn't presented there. So, any help in proving this is appreciated!","['separation-axioms', 'general-topology', 'sequences-and-series']"
3769567,"Given the position vectors of the vertices of a triangle, prove that another point is the orthocentre of the triangle.","The original problem is: If a, b, c, d are the position vectors of points A, B, C, D respectively such that $$(\vec{a}-\vec{d}). (\vec{b}-\vec{c})= (\vec{b}-\vec{d}). (\vec{c}-\vec{a})= 0$$ then prove that D is the orthocentre of ${\Delta}$ ABC. How do we go  about proving that a point is the orthocentre of a triangle? I've tried expanding the dot product but I don't seem to get anywhere.","['euclidean-geometry', 'vectors', 'vector-spaces', 'geometry']"
3769604,How do I check the primeness of ideals of a finitely generated algebra over a field?,"In other words, how do I check whether the algebraic set given by a set of polynomial equations is irreducible? For example, I encountered the following example when working through Vakil's notes on algebraic geometry: Show that $k[x,y,z,w]/(wz-xy,wy-x^2,xz-y^2)$ is an integral surface. (Here $k$ is a field.) I know that if the ideal is principal, then we only have to check that the generator is prime. However, I don't know of any efficient way to check primeness in general. How does one approach such problems? In particular, how do I show that $(wz-xy,wy-x^2,xz-y^2)$ is a prime ideal? Thanks in advance.","['affine-varieties', 'algebraic-geometry', 'commutative-algebra']"
3769636,Help with finding the Lebesgue decomposition of measures,"Consider the increasing, right-continuous function $$ F(x) = 
\begin{cases} 0      &x < 0 \\
              1+x    &x \geq 0
\end{cases}
$$ and let $\nu = \nu_F$ be the associated Borel measure on $\mathbb R$ (so $\nu((a,b]) = F(b)-F(a)$ ).  Find the Lebesgue decomposition of $\nu$ with respect to: (a) $m$ (b) $\delta$ , the Dirac measure at 0 (c) the Cantor measure $\mu$ I think I have a solution to (a), but I am lost as to how to do parts (b) and (c). I'd appreciate any help. This is my attempt for (a): We want to find measures $\rho$ and $\lambda$ such that $$\nu = \rho + \lambda$$ with $\rho << m$ and $\lambda \perp m$ . By the Radon-Nikodym Theorem, $\exists F'$ such that $$\rho(A) = \int_A F'(x) dx. $$ Since $F(x)$ is increasing then for some interval $(a,b] \in \mathcal B$ , $$\rho((a,b]) = \int_a^b F'(x) dx \leq F(b)-F(a) = \nu((a,b]). $$ Clearly, $\rho << m $ . Next define $$\lambda = \nu-\rho.$$ To show that $\lambda \perp m$ , let $E = \{0\}$ and $F = \mathbb R - \{0\}.$ We want to show that $m(E)=\lambda(F)=0$ . It is trivial that $m(E) = 0$ . To show $\lambda(F) =0$ , notice $\lambda \geq 0$ since $\rho(A) \leq \nu(A) \ \ \forall A \in \mathcal B.$ Hence on $(-\infty,0):$ $$ \lambda((-\infty,0))=\nu(-\infty,0)-\rho(-\infty,0)\geq 0  $$ But since $\nu(-\infty,0)=0$ , then $\rho((-\infty,0)=0 \implies \lambda((-\infty,0) = 0$ . Finally on $(0, \infty),$ note that $\nu = \rho$ . Hence $$ \lambda((0,\infty)) = \nu((0,\infty))-\rho((0,\infty))=0$$","['measure-theory', 'lebesgue-measure', 'radon-nikodym', 'real-analysis']"
3769702,"Divergence of $\sum_{n=1}^{\infty}\prod_{k=1}^n q_k$ for some enumeration $(q_n)_{n}$ of $\mathbb{Q}\cap (0,1)$","Given an enumeration $(q_n)_{n}$ of $\mathbb{Q}\cap (0,1)$ , let us consider the series $$\sum_{n=1}^{\infty}\prod_{k=1}^n q_k.$$ Find an enumeration such that the series is convergent. Find an enumeration such that the series is divergent. is rather easy: take any enumeration $(a_n)_{n}$ of $\mathbb{Q}\cap (0,1/2]$ and any enumeration $(b_n)_{n}$ of $\mathbb{Q}\cap (1/2,1)$ . By letting $(q_n)_n=a_1,b_1,a_2,b_2,\dots$ , it follows that $$\sum_{n=1}^{\infty}\prod_{k=1}^n q_k< 2\sum_{n=1}^{\infty}\frac{1}{2^n}=2.$$ seems to be more challenging and I did not solve it so far. Any hints? I read about this problem a few years ago, but I can't remember the source. If someone find it please let me know! Bonus question 1'. Is there any enumeration $(q_n)_{n}$ of $\mathbb{Q}^+$ such that the series is convergent?","['sequences-and-series', 'real-analysis']"
3769778,Simplified closed form for Fibonacci numbers and O(1) implementation,"A friend of mine got the task to implement Fibonacci such that it will take less than 10 seconds for the 2000000th number. This was an interesting task so I set myself the task to make a super fast implementation for any $n$ . The trivial recursion algorithm will take too much time ( $O(F_n)$ operations), and using dynamic programming also won't work ( $O(n)$ operations). Here even the closed form solution might fail as it take $O(\log n)$ operations using fast exponentiation. Another problem is that $F_n$ becomes huge and operations become more and more expensive. To avoid these problems I decided to compute $\log(F_n)$ instead, The intuition is that $\log a^n = n\log a$ so we reduce the number of operations to 1. First let me present the math behind my code: $$a = \frac{1+\sqrt{5}}{2}, b = \frac{1-\sqrt{5}}{2}, c=\frac{1}{\sqrt{5}}, d=\frac{b}{a}$$ $$F_n = c(a^n - b^n) = ca^n(1-d^n)$$ I use tilde to denote numbers in the log domain (e.g $\tilde{a} = \log a)$ : $$\tilde{F}_n = \tilde{c} + n\tilde{a} + \log(1-d^n)$$ This almost solves the exponentiation problem, but we still have the $d^n$ , which can also be solved by: $$= \tilde{c} + n\tilde{a} + \log(1-(-1)^ne^{n\log (-d)})$$ This is not so clean as we could do the exact same thing in the $F_n$ formula, ideally I want to remove the $1-d^n$ completely - Note this does help numerically. Now for the more technical part, I implemented this exact algorithm to python using python (numpy): log_d = log(-(1 - sqrt(5))/(1 + sqrt(5)))
sign = -1 if n % 2 else 1
return log(1 / sqrt(5)) + n*log((1 + sqrt(5)) / 2) + log(1 - sign * exp(n * log_d)) This code works well, with less than 0.0001 seconds for n=2 million, and I haven't found an instance where round(exp(log_fibonacci(n))) != fibonacci(n) . Something I noticed about my code is that round(exp(log_fibonacci(n))) != fibonacci(n) is 0 for $n>15$ is 0 because of numerical issues. This is actually very interesting, because it means my function computes $$\tilde{F}_n = \tilde{c} + n\tilde{a}$$ which consists of only 2 operations!
This raised the following question: Is there a constant $N$ such that any $n>N$ satisfies $F_n=\text{round}\left(\frac{1}{\sqrt{5}}\left(\frac{1+\sqrt{5}}{2}\right)^n\right)$ ? If not, can we find the $n$ 's that does not satisfy this formula?","['numerical-methods', 'fibonacci-numbers', 'discrete-mathematics']"
3769788,Find the value of $k$ in the equation $\sin {1^\circ}\sin {3^\circ}.......\sin {179^\circ} = \frac{1}{{{2^k}}}$,Find the value of 'k' in the equation $\sin {1^\circ}\sin {3^\circ}.......\sin {179^\circ} = \frac{1}{{{2^k}}}$ My approach is as follow $\sin {1^\circ} = \sin {179^\circ}$ $T = {\sin ^2}{1^\circ}{\sin ^2}{3^\circ}..{\sin ^2}{89^\circ}$ $\left( {\frac{{1 - \cos {2^\circ}}}{2}} \right) = {\sin ^2}{1^\circ}$ $T = \left( {\frac{{1 - \cos {2^\circ}}}{2}} \right)\left( {\frac{{1 - \cos {6^\circ}}}{2}} \right)\left( {\frac{{1 - \cos {{10}^\circ}}}{2}} \right)....\left( {\frac{{1 - \cos {{178^\circ}}}}{2}} \right)$ $2 + \left( {n - 1} \right)4 = 178 \Rightarrow n = 45$ $T = \frac{1}{{{2^{45}}}}\left( {1 - \cos {2^\circ}} \right)\left( {1 - \cos {6^\circ}} \right)\left( {1 - \cos {{10}^\circ}} \right)....\left( {1 - \cos {{178^\circ}}} \right)$ $\left( {1 - \cos {{178}^\circ}} \right) = \left( {1 + \cos {2^\circ}} \right)$ $T = \frac{1}{{{2^{45}}}}\left( {1 - {{\cos }^2}{2^\circ}} \right)\left( {1 - {{\cos }^2}{6^\circ}} \right)\left( {1 - {{\cos }^2}{10^\circ}} \right)....\left( {1 - {{\cos }^2}{{86}^\circ}} \right)\left( {1 - \cos {{90}^\circ}} \right)$ $T = \frac{{{{\sin }^2}{2^\circ}.{{\sin }^2}{6^\circ}.{{\sin }^2}{{10}^\circ}......{{\sin }^2}{{86}^\circ}}}{{{2^{45}}}}$ Not able to proceed from here,['trigonometry']
3769803,Continuity of derivative of a continuous monotone function,"We know that every continuous monotone function defined on [a, b] possesses a finite derivative almost everywhere. What about the continuity of the derivative? Can I say that the derivative of this function is continuous almost everywhere? Or if we define $\tilde f(x) = \liminf_{y \to x-} \frac{f(y)-f(x)}{y-x}$ , what is the continuity of $\tilde f(x)$ ? Is that continuous almost everywhere?","['continuity', 'derivatives', 'real-analysis']"
3769819,General trick to factorize an inequality of the kind $a+b\leq 1$,"I have found this method in solving this kind of inequality : Let $x,y>0$ such that $x+y=1$ then we have : $$x^{2y}+y^{2x}\leq 1$$ Well now we want to solve the general problem : $$a+b\leq 1$$ Under some constraint on $1>a,b>0$ Well a bit of algebra and trigonometric's formulae  shows that it's equivalent to : $$\sin^2\Big(a\frac{\pi}{2}\Big)+\sin^2\Big(b\frac{\pi}{2}\Big)\leq 1$$ But : $$\sin^2\Big(a\frac{\pi}{2}\Big)+\sin^2\Big(b\frac{\pi}{2}\Big)\leq \cos^2\Big(a\frac{\pi}{2}\Big)+\sin^2\Big(a\frac{\pi}{2}\Big)$$ Or : $$\sin^2\Big(b\frac{\pi}{2}\Big)\leq \cos^2\Big(a\frac{\pi}{2}\Big)\quad (1)$$ Or : $$\Big(\sin\Big(b\frac{\pi}{2}\Big)-\cos\Big(a\frac{\pi}{2}\Big)\Big)\Big(\sin\Big(b\frac{\pi}{2}\Big)+\cos\Big(a\frac{\pi}{2}\Big)\Big)\leq 0$$ The problem is : $$\Big(\sin\Big(b\frac{\pi}{2}\Big)-\cos\Big(a\frac{\pi}{2}\Big)\Big)$$ Or : $$\Big(\cos\Big((b-1)\frac{\pi}{2}\Big)-\cos\Big(a\frac{\pi}{2}\Big)\Big)$$ Now we use the fact : $$\cos(p)-\cos(q)=-2\sin\Big(\frac{p+q}{2}\Big)\sin\Big(\frac{p-q}{2}\Big)$$ We get : $$-2\sin\Big(\frac{\pi(b+a-1)}{4}\Big)\sin\Big(\frac{\pi(b-1-a)}{2}\Big)$$ Now it's clear that it's equivalent to the original problem. Now the idea is using power series: factorize the expression. We have : $$\cos^2(x)=\sum_{n\geq 2} \frac{(2 i)^{-2 + n} (1 + (-1)^n) (-\frac{π}{2} + x)^n}{n!}$$ See here And : $$\sin^2(x) = - \sum_{k=1}^{\infty} \frac{(-1)^k 2^{-1 + 2 k} x^{2 k}}{(2 k)!}$$ See here Well now making the difference in the inequality $(1)$ we can factorize to get someting like : $$0\leq \frac{\pi}{2}(a-1-b)\Big(P\Big(\frac{\pi}{2}a,\frac{\pi}{2}b\Big)\Big)$$ Here I have used the fact : $$x^n-y^n=(x-y)(Q(x,y))$$ With $n\geq 1$ a natural number . Now the problem is the : $$P(\frac{\pi}{2}a,\frac{\pi}{2}b)\quad (2)$$ My questions :
Is it just unsuable ?
Can we have more informations on $(2)$ ,I mean as it is equal to zero ?
Can we improve the situation ?
Can we have a good estimation of $(2)$ ? Thanks in advance !!","['inequality', 'factoring', 'polynomials', 'power-series', 'trigonometry']"
3769830,"Polar Optical ""Reflection"" model","Using the well known mirror reflection equation in Gaussian Geometric Optics relating $(u,v)$ object(blue)/ image (red) distances: $$\frac{1}{u(\theta)}+\frac{1}{v(\theta)}=\frac{1}{f} \tag1 $$ Gaussian form of reflection between object/image: $$ [u(\theta)-f]\cdot [v(\theta)-f)] = f^2  \tag2 $$ Reflection of object point to a diametrically opposite image point by mapping: $$ r\rightarrow \dfrac{1}{1/f-1/r} \tag3 $$ Green circle is $r=f$ and brown $r=2f$ correspond to focal and curvature central positions. Plotted below is a circle $ ( u = 2 \cos \theta ) $ diameter $D=2$ units through the origin ""reflected"" about an origin centered unit focal circle $f=1$ with the above polar transformations : A bizarre reflection curve with asymptotes at angles $ \cos\theta_{asymptote}=\frac{f}{D}$ . A straight line and and an ellipse respectively ""reflect"" to an ellipse and hyperbola.A Hyperbola reflects to another hyperbola. Is this known in Optics or Geometry? Please give references if available. No such reference made in elementary physics text-books like those authored by Halliday /Resnick. In this Research We have image formation in the same way as in paraxial geometric optics by means of mapping at (3) as happens with mirrors/lenses. If object is between $(f,2 f)$ the image is outside $2f$ and vice-versa. If the object is on $2f$ circle the image is also on the same circle. Object at $\infty$ maps to focal circle $f=1$ and vice- versa. The difference that may be noted here is that the object /image need not be at a constant distance/radius on a single concentric circle from the origin but can extend freely across $ ( r=f,2f )$ radii circles. A polar generalization is seen here. When object extends across $2f$ brown circle the object, image and 2f circle are always concurrent. Picture below shows the image (red) of an eccentric Circle object (blue). Concurrency of the three lines are clearly seen. It is not yet clear how eccentric circles reflect to secondary tiny islands/ovals seen at left and in the first picture. In view of the above where we are obeying Gauss geometric optics, for time being dropping out quotes for reflection sounds appropriate. Due to the polar placement of object/image curves a distinction between reflective (mirrors) and refractive (lenses) ray tracing  can be  also overlooked.",['geometry']
3769882,What is a solution to the recurrence relation $f(n) = f(n-1) +f\Big(\left\lfloor \frac{n}{2} \right\rfloor\Big)$?,"Let $\mathbb{N}=\{1,2,3,\ldots\}$ .  Find a closed form or an asymptotic form of $f: \mathbb{N} \to \mathbb{N}$ , where $f$ satisfies $f(1) = 1$ and $$f(n) = f(n-1) + f\bigg(\left\lfloor \frac{n}{2} \right\rfloor\bigg)\,.$$ What is a closed-form solution to this recurrence relation? Neither the Master theorem , nor its generalization, the Akra-Bazzi method , seem to be applicable.","['functional-equations', 'functions', 'recurrence-relations', 'sequences-and-series']"
3769908,Why use limit laws to verify continuity instead of direct substitution?,"My textbook (Calculus Early Transcendentals, 8th edition, by James Stewart ) asks to verify a function is continuous at a point using the definition of continuity and the limit laws. However, why would the text explicitly state to use the limit laws to verify continuity? I'm assuming this implies that direct substitution shouldn't be used and looking at solutions online confirms my suspicions as they all use limit laws as well. However, using direct substitution is much faster than using the limit laws and both methods achieve the same result. For example, show that $f(x) = (x+2x^3)^4$ is continuous at $x=-1$ By definition of continuity, we're trying to show that $\lim_{x\to-1}(x + 2x^3)^4 =f(-1)$ Show that $f(-1)$ exists $$f(-1)=(1+2(-1)^3)^4 = 81$$ Now for the limit Using the limit laws: $$\lim_{x\to-1}(x + 2x^3)^4$$ $$=[\lim_{x\to-1}x + 2x^3]^4$$ $$=[\lim_{x\to-1}x + \lim_{x\to-1}2x^3]^4$$ $$=[\lim_{x\to-1}x + 2\lim_{x\to-1}x^3]^4$$ $$=[-1 + 2(-1)^3]^4 = 81$$ Using direct substitution: $$\lim_{x\to-1}(x + 2x^3)^4 = (1+2(-1)^3)^4=81$$ In either method we reach the same result that $\lim_{x\to-1}(x + 2x^3)^4 = 81$ which verifies that $f(x)$ is continuous at $x=-1$ since $\lim_{x\to-1}(x + 2x^3)^4 =f(-1)$ Perhaps I'm missing some important connection between continuity and limits as to why limit laws are used instead of direction substitution to verify continuity?","['limits', 'calculus', 'continuity']"
3769924,How to calculate the limit of sequence,"The question is calculate limit of sequence $$
\lim_{n \to \infty}
\frac{\left(2\,\sqrt[\Large n]{\, n\,}\, -
\,\sqrt[\Large n]{\, 2\,}\right)^{n}}{n^2}
$$ I'm trying to simplify the equation, like divide $\,\sqrt[\Large n]{\, n\,}\,$ , but can't get more.  I drew the continuous function plot, which shows value tends to $0.4$ . Do any method show more details about this question ？.","['limits', 'calculus', 'sequences-and-series']"
3769936,Why can't we convert the area element $dA$ to polar by multiplying the polar expressions for $dx$ and $dy$? [duplicate],"This question already has answers here : A doubt regarding change of variables in Double Integrals. (3 answers) Closed 3 years ago . Say I have a 2D integral in rectangular coordinates and want to convert to polar. I transform the dx dy starting with: $$\begin{array}{c}
x = r\cos\theta \\
y = r\sin\theta \\
\end{array}
$$ So ... $$\begin{array}{c}
dx = \cos\theta\,dr - r \sin\theta\,d\theta \\
dy = \sin\theta\,dr + r \cos\theta\,d\theta \\
\end{array}
$$ Then expanding out the multiplication ... $$\begin{align}
dx\,dy &= \cos\theta\,\sin\theta\,dr^2 - r^2\,\cos\theta\,\sin\theta\,d\theta^2
         + r\,\cos^2\theta\,dr\,d\theta - r\,\sin^2\,\theta\,dr\,d\theta \\
&= r\,dr\,d\theta + \cos\theta\,\sin\theta\,(dr^2 - r^2\,d\theta^2) - 2\,r\,\sin^2\theta\,dr\,d\theta \hspace{3em}\text{... uh oh!}
\end{align}
$$ So there's $r\,dr\,d\theta$ but with some extra terms. Why doesn't this naive and direct approach work out?","['integration', 'multivariable-calculus', 'polar-coordinates']"
3769941,Solving $\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{xy+{y}^{2}}{{x}^{2}+{y}^{2}}$.,"Solve $$\frac{\mathrm{d}y}{\mathrm{d}x}=\dfrac{xy+{y}^{2}}{{x}^{2}+{y}^{2}}.$$ I have tried to solve this question by assuming $y/x$ to be $v$ , but I am stuck on the integral $$\int\frac{{v}^{2}+1}{{v}^{3}-1},$$ please help me with this integral or suggest a method to directly solve the differential equation.","['indefinite-integrals', 'calculus', 'ordinary-differential-equations']"
3769948,Evaluate the following integral $ \int_1^{\infty} \frac{\lbrace x\rbrace-\frac{1}2}{x} dx$,"$$\int_1^{\infty} \frac{\lbrace x\rbrace-\frac{1}2}{x} dx$$ Here $\lbrace\cdot\rbrace$ denotes the fractional part. I found this challenging integral, and I'm curious about the solution, so I decided to do some efforts to solve it, but sadly I didn't, any hints? Attempts: \begin{align}
\int_1^{\infty} \frac{\lbrace x\rbrace-\frac{1}2}{x} dx&=\int_1^{\infty} \frac{1\lbrace x\rbrace-1}{2x} dx\\
&=\int_1^{\infty}\frac{\lbrace x\rbrace}{x}-\frac{1}{2x}dx\\
&=\int_1^\infty \frac{x-\lfloor x\rfloor-1}{x}-\frac{1}{2x}dx\\
&=\int_1^\infty \frac{x-\lfloor x\rfloor-1}{x} dx -\int_1^\infty \frac{dx}{2x}
\end{align} I thought about this property: $$\int_0^\infty \varphi (x) dx=\lim_{a\to \infty} \int_0^a \varphi(x) dx$$ So I applied it only for the second fraction because its antiderivative was easy enough, and here's what I've got: \begin{align}
\int_1^\infty \frac{dx}{2x}&=\lim_{a\to \infty} \int_1^a \frac{dx}{2x}\\
&=\lim_{a\to \infty}\frac{\ln (x)}{2}\bigg\vert_0^a\\
&=\lim_{a\to \infty}\frac{\ln (a)}2 -\frac{\ln (0)}{2}
\end{align} And here I felt that I'm wrong I can't get $\infty -\infty$ , So any thoughts or hints, I'll be thankfull!","['integration', 'definite-integrals', 'fractional-part', 'calculus', 'riemann-zeta']"
3769959,Describing homomorphisms from $\Bbb Z_n$ to $D_m$.,"I've been asked to find all group homomorphisms from $$\Bbb Z_n\to D_m,$$ where $n$ and $m$ are distinct natural numbers. I now understand how to describe homomorphic groups using functions between two groups of numbers, but I'm a little confused how I would write a homomorphism from integers in $\Bbb Z$ mod $n$ to set permutations of symmetries on a regular shape in the dihedral group. Would I just represent the homomorphism as mapping, with arrows drawn from elements in $\Bbb Z_n$ to elements in $D_m$ ? Thanks in advance for any help!","['group-homomorphism', 'group-theory', 'dihedral-groups']"
3770004,"Suppose $A$, $B$, and $C$ are sets. Prove that $C\subseteq A\Delta B$ iff $C\subseteq A\cup B$ and $A\cap B\cap C=\emptyset$.","Not a duplicate of Suppose $A$, $B$, and $C$ are sets. Prove that $C ⊆ A △ B$ iff $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$. Suppose $A, B$, and C are sets. Prove that $C\subset A\Delta B \Leftrightarrow C \subset A \cup B$ and $A \cap B \cap C = \emptyset $ Set theory: Prove that $C \subseteq A \Delta B \iff C \subseteq A \cup B \wedge A \cap B \cap C = \emptyset$ This is exercise $3.5.21$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $A$ , $B$ , and $C$ are sets. Prove that $C\subseteq A\Delta B$ iff $C\subseteq A\cup B$ and $A\cap B\cap C=\emptyset$ . Here is my proof: $(\rightarrow)$ Suppose $C\subseteq A\Delta B$ . $(1)$ Let $x$ be an arbitrary element of $C$ . From $C\subseteq A\Delta B$ and $x\in C$ , $x\in A\Delta B$ . Now we consider two cases. Case $1.$ Suppose $x\in A\setminus B$ . Ergo $x\in A\cup B$ . Case $2.$ Suppose $x\in B\setminus A$ . Ergo $x\in A\cup B$ . Since the above cases are exhaustive, $x\in A\cup B$ . Thus if $x\in C$ then $x\in A\cup B$ . Since $x$ is arbitrary, $\forall x(x\in C\rightarrow x\in A\cup B)$ and so $C\subseteq A\cup B$ . Therefore if $C\subseteq A\Delta B$ then $C\subseteq A\cup B$ . $(2)$ Suppose $A\cap B\cap C\neq\emptyset$ . So we can choose some $x_0$ such that $x_0\in A$ , $x_0\in B$ , and $x_0\in C$ . From $C\subseteq A\Delta B$ and $x_0\in C$ , $x_0\in A\Delta B$ . Now we consider two cases. Case $1.$ Suppose $x_0\in A\setminus B$ . Ergo $x_0\notin B$ which contradicts $x_0\in B$ and so it must be the case that $A\cap B\cap C=\emptyset$ . Case $2.$ Suppose $x_0\in B\setminus A$ . Ergo $x_0\notin A$ which contradicts $x_0\in A$ and so it must be the case that $A\cap B\cap C=\emptyset$ . Since the above cases are exhaustive, $A\cap B\cap C=\emptyset$ . Therefore if $C\subseteq A\Delta B$ then $A\cap B\cap C=\emptyset$ . From parts $(1)$ and $(2)$ we can conclude that if $C\subseteq A\Delta B$ then $C\subseteq A\cup B$ and $A\cap B\cap C=\emptyset$ . $(\leftarrow)$ Suppose $C\subseteq A\cup B$ and $A\cap B\cap C=\emptyset$ . Let $x$ be an arbitrary element of $C$ . From $C\subseteq A\cup B$ and $x\in C$ , $x\in A\cup B$ . Now we consider two cases. Case $1.$ Suppose $x\in A$ . Now we consider two cases. Case $1.1.$ Suppose $x\in A\setminus B$ . Ergo $x\in A\Delta B$ . Case $1.2.$ Suppose $x\notin A\setminus B$ and so $x\notin A$ or $x\in B$ . Now we consider two cases. Case $1.2.1.$ Suppose $x\notin A$ which is a contradiction. Case $1.2.2.$ Suppose $x\in B$ which is a contradiction since $A\cap B\cap C=\emptyset$ . Since cases $1.2.1$ and $1.2.2$ lead to a contradiction then case $1.2$ leads to a contradiction. From case $1.1$ or case $1.2$ we can conclude $x\in A\Delta B$ . Case $2.$ Suppose $x\in B$ and a similar argument shows $x\in A\Delta B$ . Since case $1$ and case $2$ are exhaustive, $x\in A\Delta B$ . Thus if $x\in C$ then $x\in A\Delta B$ . Since $x$ is arbitrary, $\forall x(x\in C\rightarrow x\in A\Delta B)$ and so $C\subseteq A\Delta B$ . Therefore if $C\subseteq A\cup B$ and $A\cap B\cap C=\emptyset$ then $C\subseteq A\Delta B$ . From $(\rightarrow)$ and $(\leftarrow)$ we can conclude $C\subseteq A\Delta B$ iff $C\subseteq A\cup B$ and $A\cap B\cap C=\emptyset$ . $Q.E.D.$ Is my proof valid $?$ Is my proof unnecessarily redundant or every step is needed $?$ Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3770039,How do you show that $\mathbb{Z}^2$ is a closed set in $\mathbb{R}^2$?,"In $(\mathbb{R}, \tau_{st})$ , we can write $\mathbb{R} \setminus \mathbb{Z} = \bigcup_{n \in \mathbb{Z}} (n,n+1)$ , and hence $\mathbb{R} \setminus \mathbb{Z}$ is an open set. Thus the complement, $\mathbb{Z}$ , is closed. In $(\mathbb{R}^2, \tau_{st})$ I am not sure how to write an expression for $\mathbb{R}^2 \setminus \mathbb{Z}^2$ in terms of open balls. So the first part of my question is whether we can write this in a 'neat' expression like above? I can try to write $\mathbb{R}^2 \setminus \mathbb{Z}^2 = \mathbb{R}^2 \setminus \bigcup_{n,m \in \mathbb{Z}} \big\{(n,m)\big\}$ . So knowing that $\big\{(n,n)\big\}$ is a closed set, we have the complement of the union of closed sets. But this is an infinite union, so I can't actually conclude that $\mathbb{Z}^2 = \bigcup_{n,m \in \mathbb{Z}} \big\{(n,m)\big\}$ is actually closed in this manner. I know that we can say $\mathbb{Z}^2$ is closed by arguing its set of limit points is empty, but is there any other way I can show this? In particular, is there a way to show (analogous to the $\mathbb{R}^1$ case above) that $\mathbb{R}^2 \setminus \mathbb{Z}^2$ is closed, without relying on an argument by limit points? I.e. Can I show the set as an explicit construction of union of open balls?",['general-topology']
3770047,What is the difference between quasigroup with associativity and semigroup with inverse?,"Or is there no actual difference? Is the difference just in nomenclature. Literature gives no clear answer.
What I understood is that quasigroup with associativity makes it to become group.
Howevere semigroup with inverse is not quasigroup like quasigroup with associativity. I base my classes on wikipedia handy table: https://en.wikipedia.org/wiki/Semigroup I kinda understood that problem lies in the word ""inverse"". It is understood differently in quasigroups and in semigroups. This kind of mess makes things very hard to learn. The problem might lie in the very simplictic wiki table of algebraic structures. Like whole chapter needs to be reworked. Please respond in clear simple terms, provide explicit examples. Often it happens, that responses are just to get more points and they dont actually help, very ""sofisticated, smart sounding"". Quite a problem with this page. So please try to be concrete, thank you kindly.","['quasigroups', 'group-theory', 'semigroups', 'inverse']"
3770061,USAMO 2017 -TSTST P2: Which words can Ana pick?,"Ana and Banana are playing a game. First Ana picks a word, which is defined to be a nonempty sequence of capital English letters. (The word does not need to be a valid English word.) Then Banana picks a nonnegative integer $k$ and challenges Ana to supply a word with exactly $k$ subsequences which are equal to Ana's word. Ana wins if she is able to supply such a word, otherwise she loses. For example, if Ana picks the word ""TST"", and Banana chooses $k=4$ , then Ana can supply the word ""TSTST"" which has $4$ subsequences which are equal to Ana's word. Which words can Ana pick so that she wins no matter what value of $k$ Banana chooses?  (Find all words such that Ana can pick at the start and always have a winning response regardless of the value of $k$ chosen by Banana.) Remarks. If Ana chooses ""A"", then for any $k$ , Ana can give a word with exactly $k$ subsequences ""AAA...A"" ( $k$ times).
If Ana chooses ""AB"", then for any $k$ , Ana can give a word with exactly $k$ subsequences ""ABBB...B"" ( $k$ times). If Ana chooses a string with no repetition at the end, say $X_1X_2X_3\cdots X_n$ , where $X_{n-1}\neq X_n$ , then Ana wins for any value of $k$ by supplying $$X_1X_2X_3\cdots X_{n-1}\underbrace{X_nX_n\cdots X_n}_{k\text{ terms}}\,.$$ If Ana chooses a string of length $n>1$ consisting of the same letter, she loses if Banana takes $k=2$ already. PS: I didn't posted it AOPS since we only get solutions there . Thanks in advance.","['contest-math', 'combinatorics-on-words', 'combinatorics', 'combinatorial-game-theory']"
3770069,When does equality hold in $\Bigr\lvert\sum_{k=1}^n a_kb_k\Bigr\rvert^2 \le \left(\sum_{k=1}^n |a_k|^2\right)\left(\sum_{k=1}^n |b_k|^2\right)$?,"I'm reading Ahlfors' complex analysis. During the proof of Cauchy's inequality, the author uses the following equation: $$
\sum_{k=1}^n \bigr\lvert a_k - \lambda \overline{b_k}\bigr\rvert^2 = \sum_{k=1}^n |a_k|^2 + |\lambda|^2\sum_{k=1}^n |b_k|^2 - 2  \Re\left(\overline{\lambda}\sum_{k=1}^n a_kb_k\right) \tag{1}
$$ where the $a_k$ 's, $b_k$ 's and $\lambda=\frac{\sum_{j=1}^n a_jb_j}{\sum_{j=1}^n |b_j|^2}$ are all some complex numbers. After the proof is concluded, the author states the following: From $(1)$ we conclude further that the sign of equality holds in $\Bigr\lvert\sum_{k=1}^n a_kb_k\Bigr\rvert^2 \le \left(\sum_{k=1}^n |a_k|^2\right)\left(\sum_{k=1}^n |b_k|^2\right)$ if and only if the $a_k$ are proportional to the $\overline{b_k}$ . I understand that the idea here is that, under the hypothesis that $a_k$ and $\overline{b_k}$ are linearly dependent, then in equation $(1)$ both sides should be equal to $0$ (instead of greater or equal to $0$ as in the normal proof). However, I don't see how this is the case. If I take $a_k = \gamma_k \overline{b_k}$ for some scalars $\gamma_k$ 's then $(1)$ reduces to \begin{align}
\sum_{k=1}^n \bigr\lvert \gamma_k \overline{b_k} - \lambda \overline{b_k}\bigr\rvert &= \sum_{k=1}^n |\gamma_k \overline{b_k}|^2 + |\lambda|^2\sum_{k=1}^n |b_k|^2 - 2  \Re\left(\overline{\lambda}\sum_{k=1}^n \gamma_k \overline{b_k}b_k\right) \notag \\
&= \sum_{k=1}^n |\gamma_k|^2 |b_k|^2 + |\lambda|^2\sum_{k=1}^n |b_k|^2 - 2  \Re\left(\overline{\lambda}\sum_{k=1}^n \gamma_k |b_k|^2\right) \notag 
\end{align} but from here, I don't see how I could simplify the result further. Could somebody explain to me what the author meant and why it is that equality holds in this case? Thank you!","['complex-analysis', 'proof-explanation', 'cauchy-schwarz-inequality', 'complex-numbers']"
3770159,Faulhaber's polynomials and irreducibility in the sums of powers,"$\color{brown}{\textbf{The setup and observations}}$ For $d\in{\bf N}$ and $n\in{\bf N}^\star$ , denote by $S_d(n)$ the sum of the $d$ -powers of integers $1$ to $n$ : $$S_d(n)=\sum_{k=1}^nk^d.$$ A simple use of the binomial theorem in developping the quantity $(k+1)^{d+2}-k^{d+2}$ and summing it yields the following recursive relation: $$S_{d+1}(n)=\frac{1}{d+1}\left\{(n+1)^{d+2}-1-\sum_{k=0}^d\binom{d+2}{k}S_k(n)\right\}.$$ This allowed me to implement a $\verb|Python|$ script to compute them inductively. I calculated the first 100 polynomials. Here are some examples: $\small S_8(n)=\displaystyle\frac{n(n + 1)(2n + 1)(5n^6 + 15n^5 + 5n^4 - 15n^3 - n^2 + 9n - 3)}{90}$ $\small S_9(n)=\displaystyle\frac{n^2(n + 1)^2(n^2 + n - 1)(2n^4 + 4n^3 - n^2 - 3n + 3)}{20}$ $\small S_{10}(n)=\displaystyle\frac{n(n + 1)(2n + 1)(n^2 + n - 1)(3n^6 + 9n^5 + 2n^4 - 11n^3 + 3n^2 + 10n - 5)}{66}$ $\small S_{11}(n)=\displaystyle\frac{n^2(n + 1)^2(2n^8 + 8n^7 + 4n^6 - 16n^5 - 5n^4 + 26n^3 - 3n^2 - 20n + 10)}{24}$ Amongst all things, there are a few of interest: Every $S_d(n)$ is a rational polynomial in $n$ , where OEIS:A064538 appears. The roots of the polynomials seem to follow some interesting pattern, as described on this thread. For odd values of $d$ , $S_d$ is divisible by $\left(\frac{n(n+1)}{2}\right)^2$ . For even values of $d$ , it is divisible by $\frac{n(n+1)(2n+1)}{6}$ . $\color{brown}{\textbf{Getting into polynomials}}$ For $\delta\in{\bf N}$ , denote as $F_\delta(X)$ the Faulhaber polynomial : $$F_\delta(X)=\frac{1}{2^{2\delta+2}(\delta+1)}\sum_{q=0}^\delta\binom{2\delta+2}{2q}(1-q)B_{2q}\left[(8X+1)^{\delta+1-q}-1\right],$$ where $(B_n)_{n\in{\bf N}}$ are the Bernoulli numbers . Then, this polynomial has lowest degree term $X^2$ , and Faulhaber showed that: $$S_{2d+1}(n)=F_d\left(\frac{n(n+1)}{2}\right)\qquad\text{and}\qquad S_{2d}(n)=\frac{n+1/2}{2d+1}F_d'\left(\frac{n(n+1)}{2}\right).$$ The question now comes when one looks at the irreducible decomposition of $S_d$ as a polynomial over ${\bf Q}$ . Having the previous properties in mind, set: $$T_d(n)=\begin{cases}\frac{4}{n^2(n+1)^2}S_d(n)&\text{if $d$ is odd,}\\\frac{6}{n(n+1)(2n+1)}S_d(n)&\text{otherwise.}\end{cases}$$ Then my script returned that $T_d$ was always irreducible, except for the values $d=9$ and $d=10$ . Just so that we are on the same page, here are the corresponding examples from before: $\small T_8(X)=\displaystyle\frac{5X^6 + 15X^5 + 5X^4 - 15X^3 - X^2 + 9X - 3}{15}$ $\small T_9(X)=\displaystyle\frac{(X^2 + X - 1)(2X^4 + 4X^3 - X^2 - 3X + 3)}{5}$ $\small T_{10}(X)=\displaystyle\frac{(X^2 + X - 1)(3X^6 + 9X^5 + 2X^4 - 11X^3 + 3X^2 + 10X - 5)}{11}$ $\small T_{11}(X)=\displaystyle\frac{2X^8 + 8X^7 + 4X^6 - 16X^5 - 5X^4 + 26X^3 - 3X^2 - 20X + 10}{6}$ $\color{brown}{\textbf{The questions}}$ Are there known results regarding this? One can ask the following questions: Is it true that $T_d$ is always irreducible over ${\bf Q}$ for $d\neq 9,10$ ? Is there an explanation behind those exceptional values $d=9,10$ ? Or if the first question turns out to be false, what are those values of $d$ for which $T_d$ is reducible? Do they follow some pattern? ( e.g. would it happen that an odd value would be followed by an even value, both sharing the property that $T_d$ is reducible?) $\color{brown}{\textbf{My (failing) ideas}}$ What I thought about doing first is proving that if $P(X)$ is irreducible over ${\bf Q}$ , then $P\left(\frac{X(X+1)}{2}\right)$ is irreducible as well. But it turns out it isn't true, for if simply $P(X)=X$ , then the statement doesn't hold. This means that studying the Faulhaber polynomial just won't work, and one really has to work with the $T_d$ . Now, working for instance on the odd case scenarios, we seek to prove irreducibility of $$\small T_{2d+1}(X)=\frac{1}{2^{2d}(d+1)X^2(X+1)^2}\sum_{q=0}^d\binom{2d+2}{2q}(1-q)B_{2q}\left[(4X(X+1)+1)^{d+1-q}-1\right]$$ for all $d\neq4$ . I'm lost. I have no clue of where to even begin, the definition seems to rely on the values of the numerators and denominators of the Benoulli numbers, which I know are some very tough problems from number theory. Thus, applying either the Eisenstein criterion, or reducing modulo some prime number, seems like a dead end. I have made a related question involving an expression I have derived for the odd case: $$\small T_{2d+1}(X)=\frac{1}{2(d+1)}\sum_{\ell=0}^{2d-2}\left\{(-1)^\ell\sum_{k=\ell+2}^{2d}\binom{k}{\ell+2}\binom{2d+2}{k+2}B_{2d-k}\right\}X^\ell.$$ Now, I have no clue whether this is any useful into proving that it is irreducible. Indeed, assuming the inner sum cannot be simplified further (which was the point of the related question), proving irreducibility of $T_{2d+1}$ therefore highly relies on the numerators and denominators of the Bernoulli numbers, which are known to be hard questions...","['irreducible-polynomials', 'bernoulli-numbers', 'sequences-and-series']"
3770168,"How many distinct permutations of the string ""NADAMADRID"" have the word DAM appearing in them?","How many distinct permutations of the string ""NADAMADRID""  have the word DAM appearing in them? Normally, under the Mississippi Rule, you would take the total number of characters factorial, then divide by the product of all the characters that repeat factorial. In this case however, they ask how many times a certain word will appear in the permuations of a bigger string. I was confused on how to do this problem, and how i would count these possibilites.","['permutations', 'combinatorics-on-words', 'combinatorics', 'discrete-mathematics']"
3770171,Finding the central manifold of a dynamical system,"Take the dynamical system: $$x' = 0.5(1-x)xy$$ $$y' = -y(1-x)^3-y^2(2x^2-1.5x+0.5)-2x(1-x)^4+x(1-x)^3.$$ I want to find the central manifold and deduce its dynamics (stable or unstable). The above system is already in the following required form: $$ x' = Ax + f(x,y)$$ $$y' = By + g(x,y)$$ where necessarily $A=0$ and $B=-1$ . Given this, we can parameterise the centre manifold by: $$h(x) = ax^2+bx^3+cx^4 +O(x^5).$$ First, we compute $y' = \frac{dh}{dx}x'$ which is: $$ y' = a^2x^4 + O(x^5)$$ and we compare it with the $y'$ from the above dynamical system, which is: $$y' = -x+(5-a)x^2+(3a-b-9)x^3+(-\frac{a^2}{2}-3a+3b-c+7)x^4 + O(x^5).$$ Comparing coefficients between the two $y'$ 's gives $a=5$ , $b=6$ and $c=-27.5$ . This means that the centre manifold should be parameterised by: $$h(x) = 5x^2+6x^3-27.5x^4 +O(x^5).$$ Question : I do not believe the stated $h(x)$ to be the correct approximation to the manifold . You can see the correct centre manifold in the figure of the phase plane for the system I have attached. If you plot $h(x)$ on something like Desmos, you can clearly see that it is not a good approximation. Can you spot an error in my working or have I not included something I should have? Thanks","['ordinary-differential-equations', 'calculus', 'taylor-expansion', 'manifolds', 'dynamical-systems']"
3770183,Relation between Maximal Spectrum of different rings.,"We first list two results of similar form: Theorem 1. If $X$ is a compact Hausdorff space, then the map $$F: X\to\mathrm{MaxSpec}(C(X,\Bbb R)), F(x)=\{f\in C(X,\Bbb R): f(x)=0\}$$ is a homeomorphism. Theorem 2. If $k$ is an algebrically closed field, then the map $$F: \mathbb A_k^n\to \mathrm{MaxSpec}(k[x_1,...,x_n]), F((a_1,...,a_n))=\left<x_1-a_1,...,x_n-a_n\right>$$ is a homeomorphism. Neither of the two results implies each other nor the proof of them seem similar. For example Theorem 1 uses Urysohn Lemma in a crucial way but Theorem 2 is just Zariski Lemma. I wonder if they are special cases of a more general theorem. In general for some topological space $X$ we can associate to it a ring, say $F(X)$ and we can look now at the Maximal spectrum of $F(X)$ . I am asking for the properties of the $X$ and $F$ to allow us have some nice relationship between $X$ and the maximal Spectrum of $F(X)$ .","['zariski-topology', 'algebraic-geometry', 'commutative-algebra']"
3770201,Explicit elliptic fibration for $x_0^4+x_1^4+x_2^4+x_3^4=0$ (Fermat's quartic),"In Huybrecht's Lectures on K3 surfaces , there's an explicit description of an elliptic fibration for the K3 surface $X:=\{(x_0:x_1:x_2:x_3)\in\Bbb{P}_\Bbb{C}^3\mid x_0^4+x_1^4+x_2^4+x_3^4=0\}$ (Fermat quartic), with the following explanation (example 3.11): I don't get how proposition 3.10 helps us. My questions are: How does the existence of the elliptic curve $E$ such that $mE\in|L|$ for some $m$ allow us to conclude that there is an elliptic fibration on $X$ ? Was the map $X\to\Bbb{P}^1$ somehow suggested by the proposition? How do I verify that the map is an elliptic fibration?","['algebraic-geometry', 'k3-surfaces', 'arithmetic-geometry']"
3770255,"Difference between ""measure"" and ""metric""","I was reading about mathematical structure and came across the distinction of metric and measure as follows: A measure: intervals along the real line have a specific length, which can be extended to the Lebesgue measure on many of its subsets.
A metric: there is a notion of distance between points. Question: Isn't metric a super category of measure? So a measure is a form of a metric?","['measure-theory', 'metric-spaces']"
3770280,Proofs by Induction: are my two proofs correct?,"I have been trying to understand how proof by mathematical induction works, and I am struggling a bit. But, I think I am understanding it and I just want to verify that what I am doing is correct (and if not, why?) I have attached a screenshot (as a link) of my problem (black ink) and my work (red ink). My main issue is understanding what the final conclusion should be. What I did was check to see if the left and right side of the problem were equal after assuming $k + 1$ is true, and adding the appropriate terms to both sides, and simplifying. So, in my final steps of the induction phase, my question is, did I reach the right result? Prove: $1 + 3 + 6 + \cdots + \dfrac{n(n + 1)}{2} = \dfrac{n(n + 1)(n + 2)}{6}$ . Base: $P(1) = 1$ . Induction: \begin{align*}
\underbrace{1 + 3 + 6 + \cdots + \frac{k(k + 1)}{2}}_{\dfrac{k(k + 1)(k + 2)}{6}} + \frac{(k + 1)(k + 2)}{2} & = \frac{(k + 1)(k + 2)(k + 3)}{6}\\
\frac{k(k + 1)(k + 2)}{6} + \frac{(k + 1)(k + 2)}{2} & = \frac{(k + 1)(k + 2)(k + 3)}{6}\\
\frac{k(k + 1)(k + 2) + 3(k + 1)(k + 2)}{6} & = \frac{(k + 1)(k + 2)(k + 3)}{6}\\
\frac{(k + 1)(k + 2)(k + 3)}{6} & = \frac{(k + 1)(k + 2)(k + 3)}{6}
\end{align*} Prove: $5 + 10 + 15 + \cdots + 5n = \dfrac{5n(n + 1)}{2}$ Base: $P(1) = 5$ Induction: \begin{align*}
5 + 10 + 15 + \cdots + 5k + 5(k + 1) & = \frac{5k(k + 1)}{2} + 5(k + 1)\\
\frac{5k(k + 1)}{2} + 5(k + 1) & = \frac{5k(k + 1)}{2} + 5(k + 1)
\end{align*} My problem and my work","['induction', 'solution-verification', 'discrete-mathematics']"
3770282,"$\rho(f,g)=\int_E \min(1,|f-g|)dm$. Prove that $f_n$ converges to $f$ in measure if and only if $\rho(f_n,f)\rightarrow 0$ as $n\rightarrow\infty$","Question :  Suppose $m$ is a finitemeasure on a measurable space $E$ .  Define $\rho(f,g)=\int_E \min(1,|f-g|)dm$ .  Prove that $f_n$ converges to $f$ in measure if and only if $\rho(f_n,f)\rightarrow 0$ as $n\rightarrow\infty$ . My Thoughts : For the backwards direction, if $\rho(f_n,f)\rightarrow 0$ as $n\rightarrow 0$ , then we have that $\lim_{n\rightarrow\infty}\int_E\min(1,|f_n-f|)dm=\lim_{n\rightarrow\infty}\int_E|f_n-f|dm=0$ , and so we have uniform convergence, which implies in measure convergence.  For the forward direction, I am not really sure if I should consider cases, that is, when $1$ is the minimum and then when $f_n-f$ is the minimum and show that if $1$ is the minimum then the statement can't be true, and so $f_n-f$ must be the minimum and then show that the only way we get in measure convergence is if that integral equals $0$ ... but I am not quite sure how to do that.   Any thoughts, suggestions, etc. are greatly appreciated!  Thank you.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3770372,"Is the set of uniformly bounded non-decreasing functions a compact set with the metric $𝑑(𝑓,𝑔)=\sup|𝑓−𝑔|$?","Fix $M>0$ . Let $\Phi = \{f|f:[a, b] \to [-M, M] \, \text{is an non-decreasing function} \}$ . Define a metric $d: \Phi \times \Phi \to [0, \infty)$ by $𝑑(𝑓,𝑔)=\sup_{x \in [a, b]}|𝑓(x)−𝑔(x)|$ . Is the topology induced by 𝑑 compact?","['functional-analysis', 'compactness', 'real-analysis']"
3770568,"Corollary 5.39, Lee - Introduction to Smooth Manifolds","I am struggling with understanding how to prove Corollary 5.39 in Lee - Introduction to Smooth Manifolds . I found an answer on this post: A characterization of tangent space to level set of a smooth submersion , but I do not understand the computation done there. Why do we have $d\Phi_p^i(v) = v\Phi^i$ ? By definition of the pushforward, for $f \in C^\infty(\mathbb{R})$ we have $d\Phi_p^i(v)f = v(f\circ\Phi^i).$ But by the linked answer, it seems we would also have $d\Phi_p^i(v)f = (v\Phi^i)f$ . But $(v\Phi^i)f \in C^\infty(\mathbb{R})$ , not $\mathbb{R}$ . What am I missing here?","['manifolds', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
3770630,A circle is divided into $5$ parts as shown in the diagram and parts are colored either red or green. Find which area is bigger.,"In the given diagram, there are $5$ points $A, B, C, D$ and $E$ on the circumference of the circle such that $\angle ABC = \angle BCD = \angle CDE = 45^{\circ}$ and $O$ is the center of the circle. Sectors made by $AB$ and $DE$ , and area of the circle between $BC$ and $CD$ are highlighted in green. Area of the circle between $AB$ and $BC$ , and between $CD$ and $DE$ are highlighted in red. Which area is bigger, the area highlighted in red or the area highlighted in green? This was sent to me by someone. While I solved the problem (given below), the sender said that the source solution arrived at the conclusion that points $A$ , $O$ and $E$ are collinear and $OC \perp AE$ , so $\displaystyle \angle OCB = \angle OCD = \frac{45^{\circ}}{2}=22.5^{\circ}$ . While I agree with points being collinear and $OC \perp AE$ but that cannot obviously be the reason for the angles being equal. In fact the solution does not depend on them being equal as we can see. I am seeking help in establishing $\angle OCB = \angle OCD$ if that is indeed true, which I cannot see how one can conclude based on what is given. My solution: Say, $\angle OCB = \theta$ . Then, $\angle ACB = \angle OCD = (45^{\circ}-\theta)$ and $\angle DCE = \theta$ . Segment $AB= \displaystyle r^2 \left[\frac{\pi}{4}-\theta-\sin(45^{\circ}-\theta)\cos(45^{\circ}-\theta)\right]$ Segment $DE= \displaystyle r^2 \left[\theta-\sin \theta \cos \theta\right]$ $\triangle OBC = r^2 \sin \theta \cos \theta$ $\triangle ODC = r^2 \sin(45^{\circ}-\theta)\cos(45^{\circ}-\theta)$ Section $BOD = \dfrac{\pi}{4} r^2$ Adding all of the above, total area in green $= \dfrac{\pi}{2} r^2$ . So the red area has to be the same too. In addition to my question on $OC$ being bisector of $\angle BCD$ , let me also know if any of you have a simpler solution.","['euclidean-geometry', 'trigonometry', 'area', 'geometry']"
3770680,Proving $\int_{0}^\infty \left(\frac{1}{(1+ix)^b}-\frac{1}{(1-ix)^b}\right)\sin(ax)\mathrm{d}x =\frac{-ia^{b-1}e^{-a}\pi}{\Gamma[b]} $,"In Mathematica, $$\int_{0}^\infty \left(\frac{1}{(1+ix)^b}-\frac{1}{(1-ix)^b}\right)\sin(ax)\mathrm{d}x =\frac{-ia^{b-1}e^{-a}\pi}{\Gamma[b]}$$ I want to prove this, but I can't.
If anyone knows the proof of the above definite integral,
Thank you for your instruction.","['integration', 'trigonometry', 'definite-integrals', 'gamma-function']"
3770686,Proving Kepler's 1st Law,"I am currently taking a Multivariable Calculus class, and my professor says there are going to be proofs on the next exam. He says that proving one of the three Kepler's law is going to be on it, but I do not know how to prove Kepler's 1st Law. Kepler's First Law states that When orbiting, the orbited object (i.e. the Sun) is at one of the focus of the elliptical orbit. This is what I started with. $\vec{a}\times\vec{h}=\frac{-GM}{r^2}\vec{u}\times\left(r^2\ \vec{u}\times\vec{u'}\right)=-GM\left[\left(\vec{u}\cdot\vec{u'}\right)\vec{u}-(\vec{u}\cdot\vec{u})\vec{u'}\right]=GM\vec{u'}$ because $\vec{u}\cdot\vec{u'}=0$ and $\vec{u}\cdot\vec{u}=1$ because $\vec{u}$ is a unit vector. I have gotten this far, but I do not know how to continue from here. Can anyone steer me along the right direction and tell me if I have the correct idea?","['physics', 'multivariable-calculus']"
3770707,Are balls around a point always symmetric about the axes?,"I think they are. And I have sketched the following proof so far. Every ball around the origin is symmetric to the X-axis (generalize to all axis and around all points) Let $\| \cdot \|$ be any norm on $\mathbb{R}^n$ . Say the set $\{t \in \mathbb{R}^n : \|t\| \neq \|t_x\|\}$ is non-empty, where $t_x$ is the reflection of $t$ about the $X-$ axis. Let $r$ be ""a"" vector in the set with the smallest norm. Clearly, $r \neq \underline 0$ , so take the line joining $r$ and $\underline 0$ . The function $\|\cdot\|$ is continuous everywhere in the ball of radius $\|r\|$ , and this line is inside ball by its convexity. Therefore $\|\cdot \|$ is continious on this line , and assumes $0$ at $\underline 0$ and $\|r\|$ at $r$ . Therefore by $IVT$ , for every large enough $m$ there is a point $r_m$ on this line such that $\|r_m\| = \|r\| - \frac{1}{m}$ . By the collinearity of $r, r_m$ and $\underline 0$ , we have, $$\|r-r_m\| = \|r\|-\|r_m\| = \frac{1}{m} \implies r_m \rightarrow r $$ Also, by continuity of reflection, we have $r_{m_x} \rightarrow r_x$ , and by continuity of $\|\cdot\|$ , we have $\|r_m\| \rightarrow \|r\|$ , and $\|r_{m_x}\| \rightarrow \|r_x\|$ . Notice, by minimality of $r$ , $\|r_m\| = \|r_{m_x}\|$ ; that is they are the same sequence, and hence must have the same limit. Hence, $\|r_x\| = \|r\|$ . Contradiction! Or the set of assymetric vectors is non-empty. I have the following concerns. Does the fact really hold? If no, where did I go wrong, and what is a counterexample? Assuming it does, the ""lines"" between two points $x$ and $y$ induced by a norm and by convexity might be different. Particularly, the set $\{tx + (1-t)y: 0\leq t \leq 1\}$ is always the straight line joining $x$ and $y$ . However the set $\{z : \|y - z\| + \|z - x\| = \|y - x\|\}$ needn't always be a straight line. For example, it can be ""L"" shaped like in the case of $\|\cdot \|_1$ norm. Does this conflict affect the proof. Is there a simpler way to show this?","['spheres', 'normed-spaces', 'real-analysis', 'continuity', 'symmetry']"
3770741,Prime ideals are maximal among principal ideals: geometry?,"The claim is for a domain $R$ , among principal ideals of the form $(r)$ for $r \in R$ , the principal ideals which are prime are maximal among principal ideals . That is, we have $(p)$ a principal ideal which is also prime, $p \neq $ 0. If $(p) \subseteq (a)$ then either $(a) = (p)$ or $(a) = R$ . The proof is quite short: Since $(p) \subseteq a$ we have $p = ar$ . Since $ar = p \in (p)$ and $(p)$ is prime, either $a \in (p)$ or $r \in (p)$ . Case 1: $a \in (p)$ . we get $(a) \subseteq (p)$ . Combined with the assumption that $(p) \subseteq (a)$ we get $(a) = (p) ~ \square$ Case 2: $r \in (p)$ . This means that $r = ps$ . Hence $p = ar = a(ps) = (as)p$ . Thus $p - (as)p = 0$ , or $p(1 - as) = 0$ . Since $p \neq 0$ , $R$ is a domain, we have $as = 1$ : $a$ is a unit in $R$ . So $(a) = R ~ \square$ I wish to understand the above proof in terms of $\operatorname{Spec}(R)$ . We have that $(p)$ is a generic point of $\operatorname{Spec}(R)$ . it also corresponds to the equation $p = 0$ We next take the ideal $(a)$ , which corresponds to the equation $(a) = 0$ . But this ideal need not be prime, and is thus not part of the prime spectrum $\operatorname{Spec}(R)$ . How to we proceed from here? In general, I want to re-learn all basic ideal theory in terms of algebraic geometry and spectrum. Is this always possible?","['ring-theory', 'algebraic-geometry', 'commutative-algebra', 'ideals']"
3770743,A geometric/intuitive proof of why shortest distance between two non-intersecting curves lie along the normal,"I saw this post but it was too technical for me. I am looking for proof similar to what is shown in this Quora post by Nicholas Halderman. The part I found confusing/ hard of the proof was where he proves the lemma:'a small displacement in this direction along this curve will result in a point closer to B.',  I am looking for alternate geometric proof/ a more elaborate explanation on what he has done in the post.",['calculus']
3770747,Functions satisfying differential equation of the Weierstrass elliptic function $\wp$,The Weierstrass elliptic function $\wp$ satisfies the following differential equation: $${\wp'}^2 = 4 \wp^3 - g_2 \wp - g_3$$ Which other functions do? Are the solutions always elliptic functions?,"['complex-analysis', 'elliptic-functions', 'special-functions', 'ordinary-differential-equations']"
3770753,What is the motivation for sequences to be defined on natural numbers?,"Possible duplicate: Sequences with Real Indices I am trying to understand the motivation for various definitions in real analysis. Take for instance the definition of a sequence where it is defined as a function from natural numbers to that of real numbers. But why natural numbers? I cannot substantiate it with a reasonable argument and I am looking for one. I have been able to substantiate certain definitions based on some of my own reasoning, while that might not have been the real reason why it was defined that way. Take for instance the definition of convergence of a sequence. I think one of the central definitions in analysis is that of convergence of a sequence. Here we say that a sequence is said to converge to a limit $L$ if any $\epsilon$ -neighborhood of $L$ has all but finitely many terms of the sequence. I ask the usual set of questions to myself Why do we need this definition? Why was it defined this way? I thought of some possible answers. There are questions about the operations of addition and subtraction, and the manipulation of those operations resulting in questions about re-arrangements of infinite series. The foundation to answering such questions lies in the answer to ""does it even even make sense to represent the sum of infinite numbers by one number?"" What is the logical basis to represent that infinite sum by one number? Then we get the answer that the sequence of partial sums converge and so we can represent them as one number. Then we get the questions ""what is a sequence and what does it mean to say that the sequence converges?"" Then we get the definitions for a sequence and the definition of convergence. Definition of convergence makes sense to me. Let's assume we are thinking of two numbers $a$ and $b$ . What are some of the rigorous ways to define the quality of two numbers being equal? A popular one is to say that $a \geq b$ and $b \geq a$ . Another is the topologic definition where we say that $a$ always lies in any $\epsilon$ -neighborhood of $b$ no matter how small $\epsilon$ is. Now, we can modify this definition to obtain the definition of convergence of a sequence where we replace "" $a$ "" with ""all but finite terms of the sequence"". There you go. We got a definition for the convergence of a sequence. The part I could not substantiate to myself was the need to define sequences as functions on natural numbers to real numbers. Why not define sequences on some other index set? For instance, why not define it on real numbers? More generally, we have countability properties defined but why even bother with natural numbers when what we want in the end is real numbers?","['soft-question', 'sequences-and-series', 'functional-analysis', 'real-analysis']"
3770815,Probability of selecting an even number from the set of natural numbers,"In the above problem, if I form the sample space as the following set: $$S= \{\text{even number, odd number}\}.$$ Obviously both events are equally likely, since there is no reason to prefer one over the other. Also, this is the set of all possible outcomes of the experiment in which a number is being randomly selected from the set of natural numbers (note that an experiment can have more than one sample spaces). So why is $P(\text{selecting an even number})$ not as simple as $$\frac{1}{2}\cdot \frac{\text{number of favourable outcomes from the sample space}}{\text{total outcomes in sample space}}?$$","['probability-distributions', 'probability-theory', 'probability']"
3770846,Probability for an $n\times n$ matrix to have only real eigenvalues,"Let $A$ be an $n\times n$ random matrix where every entry is i.i.d. and uniformly distributed on $[0,1]$ . What is the probability that $A$ has only real eigenvalues? The answer cannot be $0$ or $1$ , since the set of matrices with distinct real eigenvalues is open, and also the set with distinct, but not all real, eigenvalues is open (the matrices with repeated eigenvalues have measure zero). I don't see any easy transformation that links the two sets, and working on the characteristic polynomial seems quite impractical. Also, I have the feeling that $[0,1]^{n^2}$ is not a good space to work in, due to its lack of rotational invariance.","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'random-matrices', 'probability']"
3770849,An open set invariant under a linear map implies it is an isometry or of finite order?,"Let $U \subseteq \mathbb R^2$ be an open, bounded, connected subset. Let $A \in \text{SL}_2$ ( $A$ is an invertible $2 \times 2$ matrix with determinant $1$ ) and suppose that $AU = U$ . Must $A$ be either orthogonal or of finite order? If we assume that $0 \in U$ , then I can prove that $A$ is diagonalizable (over $\mathbb C$ ), with all eigenvalues of modulus $1$ . I am not sure if this helps though. Indeed, we can assume that $B_r(0) \subseteq U \subseteq B_{R}(0)$ . Thus for any $x \in B_r(0)$ and for any $k \in \mathbb{Z}$ , since $A^k U \subseteq U$ , $|A^k x| \le R$ . This implies that all orbits of $A$ are bounded, i.e. $\sup_{k\in\mathbb{Z}}\|A^k x\|<+\infty$ for any $x\in \mathbb{R}^n$ , which implies the required assertion about diagonalizablilty .","['geometry', 'matrices', 'orthogonal-matrices', 'matrix-calculus', 'linear-algebra']"
