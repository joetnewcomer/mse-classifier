question_id,title,body,tags
1226500,Set of all orthogonal matrices over $\mathbb C$ is compact/not,How to show the fact that the set of all orthogonal matrices over $\mathbb C$ is compact By an orthogonal matrix over $\mathbb C$ I mean a matrix $A$ satisfying $AA^T=I$ and here $A^T=(a_{ji})$ where $A=(a_{ij})$ It is not the same as unitary matrix where in unitary matrix we take transpose and then conjugate or vice versa I know that set of all orthogonal matrices over $\mathbb R$ is compact. I think the closedness of the set will follow from the same arguements as in the above case. But the boundedness part not sure,"['compactness', 'matrices']"
1226503,How can i calculate Total no. of digit in $2^{100}\cdot 5^{75}$,"How can i calculate Total no. of digit in $2^{100}\cdot 5^{75}$ $\bf{My\; Try::}$ I have used $$\log_{10}(2) = 0.3010$$. Now Total no. of digit in $$x^y = \lfloor \log_{10}x^y\rfloor +1$$ Now  $$\log_{10}(2^{100}\cdot 5^{75}) = 100\cdot \log_{10}(2)+75\log_{10}(5) = 100\cdot \log_{10}(2)+75-75\log_{10}(2)$$ So we get $$\log_{10}(2^{100}\cdot 5^{75})=30.10+75=105.10$$ So We get no. of Digit in $$2^{100}\cdot 5^{75} = \lfloor \log_{10}(2^{100}\cdot 5^{75})\rfloor +1 = 105+1 = 106$$ Can we solve it without using $\log\;,$ If yes then plz explain me, Thanks",['algebra-precalculus']
1226505,A function is continuous if and only if its composition with the inclusion map is continuous.,"I want to show that if I have space $X, Y$ and a subspace $A \subset X$ with subspace topology then $f: Y \to A$ is continuous if and only if $\iota \circ f: Y \to X$ is continuous, where $\iota: A \hookrightarrow X$ is the inclusion map. I have shown that $\iota$ is continuous from basic definitions. I have also shown the forward implication: the continuity of $f$ means that $f^{-1} \circ \iota^{-1}$ will always pull out neighborhoods. I'm having trouble showing the converse where the continuity of $f$ comes from the continuity of $\iota \circ f$. I've tried working with the open set definition of topologies, but the key problem is that open sets in $A$ may not be open in $X$, so I'm having trouble relating $\iota^{-1} \circ f^{-1}: X \to Y$'s behavior on open sets to $f^{-1}: A \to Y$'s behavior. In general, we know that if $f, g$ are continuous then $f \circ g$ is continuous. Under what conditions can we say the converse is true?",['general-topology']
1226549,Proper axiomatization of Euclidean Geometry that Euclid would approve of,"It is relatively common knowledge that Euclid's axiomatization is not sufficient to prove all the things that Euclid wants to, and that there are other axiomatizations out there that strengthen Euclid's in order to make Euclidean geometry fully rigorous. So now, imagine Euclid comes back from the dead and looks around at what the world has done with his geometry. There are many examples of texts that treat Euclidean geometry, but in some sense they are all different from what Euclid's Elements were - a theorem, a construction and a proof. It seems that the overwhelming majority of Euclidean geometry texts are Euclidean in the sense of the parallel postulate, but not Euclidean in the manner of exposition. In a lot of ways, analytic geometry has replaced the old straight-edge & compass method, and not without good reason, but I can't help but feel that something is lost by ditching this method, if nothing but the hands-on approach. So the question is this: Is there a text in Euclidean geometry which has a sufficient axiomatization to prove (and shows to the reader) all the propositions in The Elements, and is written in the same style? For clarity, I am seeking a text which captures the two things about Euclid that make him stand out - the axiomatic approach as well as the constructive straightedge/compass method. I am not sure if a contemporary text has been written that uses solely these tools, but if one existed, that would be the most ideal.","['euclidean-geometry', 'geometry', 'reference-request']"
1226567,Can anyone help out with this differential equation,"$$t^2x''-(6t^4+2t)x'+9t^6x=0$$ I don't have an effective (I don't know how to solve these types) way of solving it, because the technique used in class was unclear to me. I would very much appreciate an answer on this. Thanks in advance.
 and$$xx''+2x^2x'^2+x'^2=2xx'/t,x(1)=1,x'(1)=3.$$","['calculus', 'ordinary-differential-equations']"
1226601,amenable groups versus amenable graphs,"In operator algebras, one is often concerned with amenable groups, defined by one of many equivalent conditions. http://en.wikipedia.org/wiki/Amenable_group#Equivalent_conditions_for_amenability In percolation theory and ""random geometry"" one is often concerned with amenable graphs, i.e. those with Cheeger constant $0$. Are these two notions of amenability related?","['probability-theory', 'percolation', 'graph-theory', 'operator-algebras', 'functional-analysis']"
1226627,"Evaluating $\int\limits_0^\infty \frac{e^x}{1+e^{2x}}\mathrm dx$, alternate methods","Problem: Evaluate $$\displaystyle\int\limits_0^\infty \frac{e^x}{1+e^{2x}}\mathrm dx$$ My progress: I have actually solved the problem, but I fear that I may not have used the ""desired"" methods. Using substitution $u = e^x$, we can rewrite the integral and get $$ \arctan(e^x)\bigg|_0^\infty $$ Then we need to evaluate the limit $$\displaystyle\left(\lim\limits_{x\to\infty}\arctan(e^x)\right) - \arctan(e^0)$$ Now, this is where I think my solution differs from the intended method (which I don't know what is). When I evaluate the above limit, I realize that $\tan(x)$ has a vertical asymptote for $x = \frac\pi2$, which means that $\arctan(x)$ has a horizontal asymptote for $y = \frac\pi2$, and is continuously increasing. Then, since $x\to\infty \Rightarrow e^x\to\infty$, we can conclude that $$\displaystyle\lim\limits_{x\to\infty}\arctan(e^x) = \frac\pi2$$ which gives the final answer $$\displaystyle\int\limits_0^\infty \frac{e^x}{1+e^{2x}}\mathrm dx = \left(\lim\limits_{x\to\infty}\arctan(e^x)\right) - \arctan(e^0) = \frac\pi2 - \frac\pi4 = \underline{\underline{\frac\pi4}}$$ My question: Is there a more ""calculating"" way of evaluating the aforementioned limit? I.e. using some general rules of limits rather than intuition? Bear in mind, I like my own solution. It was satisfying. I just feel like there is something else I should know, which I'm missing out on.","['calculus', 'definite-integrals', 'improper-integrals']"
1226633,How prove $\sigma(4^p-1)<(2^{p+1}-1)^2$,"If $p$ is an odd prime numbers, show that
  $$\sigma(4^p-1)<(2^{p+1}-1)^2$$
  where $\sigma(n)$ stands for the sum of divisors. I thought of using the formula for $\sigma(n)$: If $4^p-1=3^k\cdot (p_{1})^{t_{1}}(p_{2})^{t_{2}}\cdots (p_{m})^t_{m}$
we get
$$\sigma(4^p-1)=(4^p-1)\left(\prod_{i=0}^{n}\dfrac{1}{3^i}\right)\left(\prod_{1\le i\le m}\left(1+\dfrac{1}{q_{1}}+\cdots+\dfrac{1}{q^{t_{i}}_{i}}\right)\right)$$
but couldn't get any further.","['prime-numbers', 'number-theory', 'divisor-sum', 'inequality']"
1226684,"Is this relation transitive, reflexive, symmetric?","I am having a hard time identifying transitive relations. I think I understand those that are symmetric, but do correct me if I'm wrong. For a set $S = \{0,1,2,3,4\}$ and a relation $Z = \{(0,2),(2,2),(2,3),(3,4)\}$ I have found: I think it is not reflexive because there is no loop including 1. I am struggling with this one, but I think it is transitive. I believe this is not symmetric as there is no $(2,0), (3,2)$ or $(4,3)$. Any help is much appreciated, I don't seem to be able to get my head around what I feel like are likely to be really simple concepts.","['relations', 'discrete-mathematics']"
1226701,A measure on the space of probability measures,"I've been reading about optimal transport and it's connections to geometry. At some point one has to study a bit of the structure of the space of probability measures, $\mathcal{P}(X)$, (over a metric space X) given the 2-Wasserstein metric $W_2$. I was wondering if there is a 'canonical' way of endowing ($\mathcal{P}(X),W_2)$ with a 'nice' probability measure. More specificaly, let $(X,d)$ be a metric space, and $(\mathcal{P}(X),W_2)$ it's space of probability measures with the 2-Wasserstein metric. Then, Can we set a 'nice' measure, $\mu$, in $(\mathcal{P}(X),W_2)$? (here by nice I guess I mean a non trivial measure that will maybe let us study $(\mathcal{P}(X),W_2,\mu)$ as a metric mesure space. I realize this is vague, a little guidance here would be appreciated) If we can, what conditions on $X$ are required? Is there any other measure that is usually given to  $(\mathcal{P}(X),d)$? Where $d$ can be another metric distinct from $W_2$. Thanks, for the time. Any comments and references are highly appreciated! -------EDIT-------- (After a while) I posted this question in mathoverflow, where it was answered. Here the link: https://mathoverflow.net/questions/203499/a-measure-on-the-space-of-probability-measures","['probability-theory', 'measure-theory', 'metric-spaces', 'functional-analysis', 'metric-geometry']"
1226790,Fitting a circle,"Given a figure like , how can I determine the radius of the circle with middlepoint H analytically? CDFE is a square with sides 6/5, with E and F being points on the circles with radii 2.","['geometry', 'circles', 'analytic-geometry']"
1226823,"Does there exist any uncountable group , every proper subgroup of which is countable?","Does there exist an uncountable group , every proper subgroup of which is  countable ?","['elementary-set-theory', 'infinite-groups', 'abstract-algebra', 'group-theory', 'model-theory']"
1226829,Find the limit of $4^n\cdot\binom{2n}{n}/\binom{4n}{2n}$,"I am trying to prove that $$f(n)=4^n\frac{\dbinom{2n}{n}}{\dbinom{4n}{2n}}$$ converges as $n\rightarrow\infty$. I have already tried to use the fact that, if $n, k \in\mathbb{N}, n\geq k\geq1,$ then $(\frac{n}{k})^k\leq\binom{n}{k}\leq e^k(\frac{n}{k})^k$.  However, this has been to no avail. Could anybody suggest how I could approach this proof?","['limits', 'binomial-coefficients']"
1226863,How can I prove Holder inequality for $0<p<1$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question Let $0<p<1$ snd $\dfrac{1}{p}+\dfrac{1}{p'}=1$ . Notice that $p'<0$ .
If $f \in L^{p}$ and $0<\int_{\Omega}\vert g(x) \vert^{p'}dx < \infty$ then, $$\int_{\Omega}\vert f(x)g(x) \vert dx \geq (\int_{\Omega}\vert f(x) \vert^{p}dx)^{\frac{1}{p}}(\int_{\Omega}\vert g(x) \vert^{p'}dx)^{\frac{1}{p'}} $$ The assumption on $g$ implies that $g>0$ almost surely.","['analysis', 'lebesgue-integral']"
1226867,Clarification on basic (horizontal) differential forms,"Here's a question from Lee's Smooth Manifolds (Exercise 12-9) which was more or less answered here . The question is this: Let $\pi:M\to N$ be a smooth surjective submersion between smooth manifolds $M,N$ such that each fiber is connected. A tangent vector $v\in T_pM$ is vertical if $d\pi_p(v)=0$. Suppose $\omega\in\Omega^k(M)$. Show that there exists $\eta\in\Omega^k(N)$ such that $\omega=\pi^{\ast}\eta$ if and only if $i_v\omega_p=0$ and $i_vd\omega_p=0$ for all $p\in M$ and vertical $v\in T_pM$. [Hint:first do the case in which $\pi:\mathbb{R}^{n+m}\to \mathbb{R}^n$ is a projection onto the first $n$ coordinates]. So the forward direction ($\omega=\pi^{\ast}\eta\Rightarrow$etc.) is a straightforward computation. However, the other implication is not at all clear. I could see how the hint could help in the general case, since we ought to be able to choose coordinates so that we can reduce to this case locally and glue it together to get some sort of global result with partitions of unity. However, even in this simplest case I'm not sure where to go. The linked answer does provide a sketch of the proof, although I don't understand it. Any help would be greatly appreciated.","['differential-geometry', 'smooth-manifolds']"
1226868,"To prove $\prod\limits_{n=1}^\infty\cos\frac{x}{2^n}=\frac{\sin x}{x},x\neq0$ [duplicate]","This question already has answers here : Finding the limit $\lim \limits_{n \to \infty}\ (\cos \frac x 2 \cdot\cos \frac x 4\cdot \cos \frac x 8\cdots \cos \frac x {2^n}) $ (3 answers) Closed 6 years ago . Prove $$\prod_{n=1}^\infty\cos\frac{x}{2^n}=\frac{\sin x}{x},x\neq0$$ This equation may be famous, but I have no idea how to start. I suppose it is related to another eqution: (Euler)And how can I prove the $follwing$ eqution?
$$\sin x=x(1-\frac{x^2}{\pi^2})(1-\frac{x^2}{2^2\pi^2})\cdots=x\prod_{n=1}^\infty (1-\frac{n^2}{2^2\pi^2})$$
I can't find the relation of the two. Maybe I am stuck in a wrong way,thanks for your help.","['analysis', 'sequences-and-series', 'infinite-product', 'trigonometric-series']"
1226873,Function on a Power Set,"Let $f\colon \mathcal{P}(A)\mapsto \mathcal{P}(A)$ be a function such that $U \subseteq V$ implies $f(U) \subseteq f(V)$ for every $U, V \in \mathcal{P}(A)$. Show there exists a $W \in \mathcal{P}(A)$ such that $f(W) = W$. This is what I've been thinking: Notice $A \subseteq A$ therefore $f(A) \subseteq f(A)$ and as $f(A) \in  \mathcal{P}(A)$, this implies $f(A) \subseteq A$. Then $f(f(A)) \subseteq f(A) \subseteq A$ and so $f(f(f(A))) \subseteq f(f(A)) \subseteq f(A) \subseteq A$. If $A$ is finite, this process should leave you with the desired $W$ (I think) after a finite number of iterations. Not so sure about the infinite case. I might even be going about this totally wrong so any suggestions would be very much appreciated. Thanks!","['lattice-orders', 'elementary-set-theory', 'fixed-point-theorems', 'proof-verification']"
1226904,"The limit of $xy/(y-x^3)$ at $(0,0)$ does not exist","How to prove that
$$\lim_{(x,y)\to (0,0)}\frac{xy}{y-x^3}$$
doesn't exist? Obviously, if $f(x,y)=\frac{xy}{y-x^3}$ and, for instance, $\gamma_1(t)=(t,0)$, we have $\lim_{t\to0}f(\gamma_1(t))=0$. We just need to find another curve $\gamma_2(t)$ with $\gamma_2(t_0)=(0,0)$ such that $\lim_{t\to t_0}f(\gamma_2(t))\neq 0$ and we are done. But, what curve to choose??","['calculus', 'limits', 'multivariable-calculus']"
1226974,"For $f\in L^1_{loc} (\Omega)$, $f=0$ almost everywhere in $\Omega$ provided $\int_{\Omega}f(x)\Phi (x)dx=0 , \forall \Phi \in C_{c}^{\infty}(\Omega)$","I need to show that $f=0$ almost everywhere in $\Omega$ provided $$\int_{\Omega}f(x)\Phi (x)dx=0 , \forall \Phi \in C_{c}^{\infty}(\Omega)$$ Here is how I have decided to proceed. Suppose there exists some measurable set $\bar{\Omega} \subseteq \Omega$ such that $f\neq0$ in $\bar{\Omega}$. I want to show that $\int_{\Omega}f(x)\Phi (x)dx\neq0$. My problem is coming from the construction of $\Phi$. It has been suggested to me that I approximate $\Phi(x)=\chi_{\bar{\Omega}} $ (indicator function) using convolution. So let $\Phi_{\epsilon}=\int_{\Omega}\eta_{\epsilon}(x-y)\Phi(y)dy$ I have that $\Phi_{\epsilon} \to \Phi$ a.e. as $\epsilon \to 0$ and that $\Phi_{\epsilon} \in C_{c}^{\infty}(\Omega_{\epsilon}), \forall \epsilon>0$ where $\Omega_{\epsilon}$ is the set with an $\epsilon$-slice removed near the boundary. Now,
\begin{align}
\int_{\Omega}f(x)\Phi_\epsilon (x)dx &=\int_{\Omega-\bar{\Omega}}f(x)\Phi_\epsilon (x)dx+\int_{\bar{\Omega}}f(x)\Phi_\epsilon (x)dx 
\end{align} This is where I get stuck. I know the second integral is non-zero, and the first one should go to zero, but I am not sure how to finish off the proof here. Do I take the limit as $\epsilon \to 0$ ? What are things that stop me from just taking this limit? Thanks for any help! I've been stuck on this for a while.","['partial-differential-equations', 'real-analysis', 'measure-theory']"
1226998,A differentiation question conceptual query,"I'm quite unsure about how to deal with differentiation of absolute functions, and their continuity. For example, the question I was dealing with was the following: $$ f(x) = \frac{x}{1 + |x|}$$ According to me, the equation is continuously differentiable everywhere, given there's no sharp point in its graph. (The graph which I constructed below) Apparently, though, the derivative has a point of dicontinuity at 0. (According to the solutions in my problem set). I can't intuitively understand why that would be.","['derivatives', 'functions']"
1227031,Do commuting matrices share the same eigenvectors?,"In one of my exams I'm asked to prove the following Suppose $A,B\in \mathbb R^{n\times n}$ , and $AB=BA$ , then $A,B$ share the same eigenvectors. My attempt is let $\xi$ be an eigenvector corresponding to $\lambda$ of $A$ , then $A\xi=\lambda\xi$ , then I want to show $\xi$ is also some eigenvector of $B$ but I get stuck.","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1227040,CAT(K) Finsler manifolds.,"I was wondering if the following is true (and common knowledge): Let $(M,F)$ be a Finsler manifold. Let d be the induced distance by the norm in the usual sense. That is, $d(x,y)=\inf${lenghts of all piece-wise smooth curves...}. We consider then $(M,d)$ as a metric space. My questions, which are probably quite easy, are these: 1) Suppose that $d$ is a righteous metric, in the sense that is also symmetric. Does that imply that $(M,F)$ was actually a Riemannian manifold for starters? If not could you please show me a counter example? 2) If the answer to 1) is negative then suppose $(M,d)$ happens to also be a $CAT(\kappa)$ space. does it follow that M is necessarily a Riemannian manifold? If not, what about $\kappa =0$? Thanks a lot in advance for any help clearing this out. Of curse, any reference is gratefully welcomed.","['differential-geometry', 'metric-geometry', 'riemannian-geometry']"
1227045,"Problem with translating ""Kozyklus Eigenschaft"" to English","I'm struggling with the translation of the book written by Bernd Aulbach about ordinary differential equations. There is one notion that I can't find reference for even on the German webpages about ODEs. Bernd Aulbach wrote: Gegeben sei eine offene Teilmenge $D$ des $\mathbb R^{1+N}$ , eine stetige und bezüglich $x$ Lipschitz-stetige
  Funktion $f \colon D \to \mathbb R^N$ und die somit definierte
  Differenzialgleichung $\dot x = f(t,x)$ . Die für alle $(t, \tau, \xi)$ aus der Menge $\Omega$ definierte Funktion $\lambda(t, \tau, \xi) = \lambda_{\max}(t, \tau, \xi)$ nennen wir dann die allgemeine Lösung
  der Differenzialgleichung. $$\Omega : \{(t, \tau, \xi) \in \mathbb
> R^{1+1+N} : (\tau, \xi) \in D, t \in I_{\max}(\tau, \xi)\}$$ Sei $(\tau, \xi)$ ein beliebiger Punkt aus $D$ . Dann gelten für jedes $\sigma \in I_{\max}(\tau, \xi)$ die Beziehungen (...) und $\lambda(t,
> \sigma, \lambda(\sigma, \tau, \xi)) = \lambda(t, \tau, \xi)$ für alle $t \in I_{\max}(\tau, \xi)$ , die Identität nennen wir die Kozyklus-Eigenschaft der allgemeinen Here is my (quite accurate, I hope) translation of the second part (which is more important): Let $(\tau, \xi)$ be any point lying in $D$ . The following equalities are true for all $\sigma \in I_{\max}(\tau, \xi)$ : (...) and $\lambda(t, \sigma, \lambda(\sigma, \tau, \xi)) = \lambda(t, \tau, \xi)$ for all $t \in I_{\max}(\tau, \xi)$ , this identity is called the cocycle property of general solution. I can't understand what the ""cocycle property"" actually is and how to translate it to English.","['mathematical-german', 'translation-request', 'ordinary-differential-equations']"
1227114,Clarifying the Definition of an Inductive Set,"I'm having trouble understanding this particular definition of an inductive set. Definition. $\exists S (\varnothing\in S\land (\forall x \in S)x\cup \{x\}\in S)$. We call a set with this property inductive. From an already asked post I understand that the above definition is equivalent to this definition. Axiom of infinity: What is an inductive set? Definition. We say that $A$ is an inductive set if $\varnothing\in A$, and whenever $x\in A$ then $x\cup\{x\}\in A$ as well. However my troubles lie with the following. I think every set has $\varnothing$ as a member. Additionally, I think that $\forall x(x \cup \{x\} = x)$. If I am interpreting the definition correctly (which I suspect I am not) and my assumptions are correct (again, dubious) wouldn't every set be inductive?",['elementary-set-theory']
1227122,Market Making Card Bet Game,"In an interview I received the follow question: We have 3 cards face down, and we give each card in a deck of 52 a numeric score ( A = 1, 2=2, .... , J=11, Q=12, K = 13). The interviewer asked me to find the expected sum of these 3 cards, I approximated that each card has an expected value of (1+2+...+13)/13 = 7, and so the sum is approximately going to be 21 (or adjusted down slightly to 20.5). Then the game begins as follows. You begin with $1000. I will quote a price to play this game, and you are able to either buy x units, or sell me x units, then we turn over the cards and you realize your profit or loss. For example: Lets say you are given a price of 25, clearly this is greater than 21, so I would choose to sell (Short) 10 units at that price. The cards turn out to have a sum of 23, so I make a profit of (25-23)*10 = 20. So my total money now is 1020, and so on. We played several rounds of this, and I was just wondering what is an appropriate strategy for this game? I tended to increase the units I would buy when quoted a very low price, and increase the number I would sell when quoted a very high price (relative to 21), but now that I think about it, is there a more sophisticated way of approaching this problem?","['finance', 'probability', 'puzzle']"
1227147,What is the mistake in this proof?,"During a long night without sleep I managed to come up with a proof for a statement I know is false, and for the life of me I cannot figure out what I did wrong. Where is my mistake? Theorem: Let $f:A\to B$ be any function. There is a bijection from A onto B. Proof: By contradiction. Assume there is no bijection from A onto B. Consider the statement ""If f is a surjection, then f is an injection."" This statement is true iff either f is not a surjection or f is an injection (this is material implication). But this statement is false, because if f is a surjection it can't be an injection because there are no bijections. So then the statement ""Either f is not a surjections or it is an injection"" is false, meaning f is a surjection and not an injection (demorgan). But if f is not an injection then either f is not an injection or it is a surjection. Using material implication again, this is equivalent to the statement ""if f is an injection then it is a surjection,"" which is false because then there would be a bijection. So f is an injection and not a surjection, which is clearly a contradiction. This is obviously absurd but I'm having trouble thinking straight. Where is my error?","['elementary-set-theory', 'proof-verification', 'logic']"
1227190,$A^2=AB+BA$. Prove that $\det(AB-BA)=0$,"Let $A,B$ be two $3\times 3$ matrices with complex entries, such that $A^2=AB+BA$. Prove that $\det(AB-BA)=0$ Nice problem, and I want to find a solution. $AB-BA=A^2-2BA=(A-2B)A$ so if $|A|=0$ we have done, if $|A| \not=0$ I can't prove.","['linear-algebra', 'matrices']"
1227239,Prove that $\int_{\Omega}|f_n-f_0|d\mu\rightarrow 0$ (by weaker assumption on Scheffé's lemma: $f_n\xrightarrow{\mu} f_0$),"I'm dealing with this problem. Let $(\Omega,\mathcal{F},\mu)$ be a measure space and $\{f_n\}$ a sequence of nonnegative integrable functions. Suppose $f_n\xrightarrow{\mu} f_0$ and $\displaystyle\int_\Omega f_nd\mu\xrightarrow{n\rightarrow\infty}\int_\Omega f_0d\mu<\infty$. Prove that $\displaystyle\int_{\Omega}|f_n-f_0|d\mu\xrightarrow{n\rightarrow\infty} 0$. If the convergence of $\{f_n\}$s to $f_0$ were almost everywhere , then the problem would become Scheffé's lemma . By convergence in measure, for each $\epsilon>0$ and natural $n$, define :
$\displaystyle E^\epsilon_n:=\{\omega\in\Omega\;;\;|f_n-f_0|(\omega)\geq\epsilon\} \;\wedge\;F_n^\epsilon:=\Omega-E^\epsilon_n$
$$\int_\Omega |f_n-f_0|d\mu=I_1+I_2\quad;\quad I_1=\int_{E^\epsilon_n} |f_n-f_0|d\mu\;\wedge\;I_2=\int_{F^\epsilon_n} |f_n-f_0|d\mu$$
We have $\mu(E_n^\epsilon)\rightarrow 0$ and $|f_n-f_0|<\epsilon$ over $F_n^\epsilon$.
But I can't control the terms $|f_n-f_0|$ in $I_1$ and $\mu(F_n^\epsilon)$ in $I_2$ when the measure of space is not finite ! EDIT My book has never mentioned ""Scheffé's lemma"".","['convergence-divergence', 'lebesgue-integral', 'measure-theory']"
1227244,Product of Two Orientable Manifolds is Orientable,"I am trying to show that following: Let $M$ be an oriented smooth manifold of dimension $m$, and $N$ be an oriented smooth manifold of dimension $n$. Then $M\times N$ is orientable. Let $\pi_M:M\times N\to M$ and $\pi_N:M\times N\to N$ be canonical projections. Since $M$ and $N$ are orientable, we can find non-vanishing forms $\omega \in \Omega^m(M)$ and $\eta\in \Omega^n(N)$. I think that $\pi_M^*(\omega)\wedge \pi_N^*(\eta)$ should then be a non-vahinsghing $(m+n)$-form on $M\times N$. I am unable to show this. Let us write $\pi_M^*\omega$ as $\omega^*$ and $\pi_N^*\eta$ as $\eta^*$. One of the difficulties I am facing is that $\omega^*\wedge \eta^*$ is $\binom{m+n}{n}\sum_{\sigma\in S_{m+n}}  {^\sigma}(\omega^*\otimes \eta^*)$. I need to operate this thing on a basis of $T_{(p,q)}(M\times N)$, where $p\in M$ and $q\in N$. I know that $T_{(p,q)}(M\times N)\cong T_pM\oplus T_qN$ via the isomorphism $Z\mapsto (d\pi_MZ, d\pi_NZ)$. Can somebody see what to do from here?","['differential-geometry', 'smooth-manifolds', 'differential-forms', 'orientation']"
1227245,"Is $[0,1]/{\approx}$, where $0\approx \frac{1}{2}$, homeomorphic to $S^1$","Consider the quotient space ${[0,1]}/{\sim}$, where $[0,1]$
is equipped with the standard Euclidean topology, and where and the equivalence
relation $\sim$ identifies its endpoints, i.e. gives rise to a partition
$$
\left\{ \left\{ x\right\} :x\in(0,1)\right\} \cup\{0,1\}
$$
of $[0,1]$. Now it is clear that $[0,1]/{\sim}$ is homeomorphic to
the circle $S^{1}$. My question is: Suppose we replace the equivalence
relation with another, $\approx$, which identifies a different pair of points,
say $0$ and $\frac{1}{2}$; it would thus now give rise to the partition
$$
\{ \left\{ x\right\} :x\in(0,1]\setminus\{ \frac{1}{2}\} \} \cup\{0,\frac{1}{2}\}.
$$ Is then ${[0,1]}/{\approx}$ still homeomorphic to $S^{1}$? (Note: I suppose that's not the case, due to some high-level theorems
that immediately tell us, that it can't be the case; but I don't know
those theorem. For whose interested, here's a sketch of the proof of the claim about $[0,1]/{\sim}$: The map 
$$
f:[0,1]\rightarrow S^{1},\ t\mapsto(\cos2\pi t,\sin2\pi t)
$$
is a continuous surjection that makes the same identifications as
the canonical projection $p$ from $[0,1]$ to $[0,1]/{\sim}$,
i.e. $p(x_{1})=p(x_{2})$ iff $f(x_{1})=f(x_{2})$. Some high-level
theorem then guarantee us that $f$is a quotient map, so $[0,1]/{\sim}$ is
homeomorphic to $S^{1}$.)","['algebraic-topology', 'general-topology']"
1227260,Derivative of sin(x)/x at $0$ by definition of derivative,"the question I am attempting is: Show $f '(0) = 0$ for: $$f(x) = \left\{
\begin{array}{lr}
\frac{\sin(x)}{x} & : x \neq 0\\
1 & : x=0
\end{array} 
\right.$$ So I got stuck after the following working: $$
f'(0)  =  \lim_{h \to 0} \frac{f(0+h) - f(0)}{h} \\
 = \lim_{h \to 0} \frac{\frac{\sin(h)}{h}-\frac{\sin(0)}{0}}{h}\\
= \lim_{h \to 0} \frac{\sin(h)}{h^2}
$$
and the above limit does not exist. Am I not applying the derivative definition right? or am I going wrong somewhere else? EDIT: 
I now see that f(0) = 1 from the definition of the function, however I still have:
$$\lim_{h \to 0}\frac{\sin(h)-h}{h^2}$$
which I am struggling to evaluate. Splitting into two fractions the first fraction is still the one from above which does not exist. Also this must be from definition of derivative directly and not by L'Hopitals rule as it has not been taught yet.","['analysis', 'limits', 'real-analysis', 'derivatives']"
1227282,Set Theory Jech - Induction Proof Ex. 1.9,"Exercise 1.9 in Set Theory (Jech) asks : Let $A$ be a subset of $\mathbb N$ such that  $\emptyset \in A$, and if $n \in A$ then $n + 1 \in A$. Then $A = \mathbb N$ . I have seen some solutions using ∈-minimal property. But I proved it this way : $\emptyset \in A$ Also, if $n \in A$, $n+1 \in A$ i.e. $n \cup \{n\} \in A$ Hence $A$ is inductive => $\mathbb N$  is a subset of $A$ since $\mathbb N$  is the smallest inductive set.
But $A$ is a subset of $\mathbb N$  (by hypothesis).
Hence $A = \mathbb N$ . Is this a valid proof?",['elementary-set-theory']
1227283,"Prove that if $\sum a_n$ converges absolutely, then $\sum a_{2n}$ converges.","In posting this question, I noticed a lot of 'similar' threads pop up, but felt that they required a fundamentally different approach. If any of you feel differently, please feel free to vote this thread as a duplicate and I will delete it. Here is my approach , I would appreciate help/correction where relevant, as I am unsure of how robust my answer is: If $\sum a_n$ converges absolutely, then we have that $\sum |a_n|$ converges.
This implies that $\sum a_n$ also converges, and that the sequence $(a_n)_{n \in \mathbb{N}}\to 0$.$^{(1)}$ This means that the sequence $(a_n)$ is bounded and monotone (decreasing), and as such convergent. Looking at $(a_{2n})$ we notice it is a sub-sequence of $(a_n)$ and converges to the same value (Bolzano-Weiestrass).$^{(2)}$ Then the partial sums $(s_{2n}) \to A$ and thus $\sum a_{2n} = A$ Is this sufficient? I feel it is a little wishy/washy in using bolzano-weistrass. Do I need to formally show $(a_{2n})$ is a sub-sequence of $(a_n)$ Any tips/hints/corrections are greatly appreciated. $^{(1),}$$^{(2)}$ - I am not required to show these results, as quoting the theorem from my notes is considered sufficient by my professor.","['sequences-and-series', 'real-analysis']"
1227314,Relation between Lipschitz condition and linear growth condition,"If for a function $f:\mathbb{R}\rightarrow\mathbb{R}$ it is given that it satisfies a Lipschitz condition $\big|f(x)-f(y)\big| \le L\big|x-y\big|$, for all $x,y\in\mathbb{R}$, can we say anything about the bound of $|f(x)|$. Can it be guaranteed to satisfy $|f(x)| \le a|x| + b$, for some $a,b>0$? Intuitively it should, as the derivative of the function is finite at all points, we should be able to find a line (no matter how steep) such that $f(x)$ is under the line everywhere. But how do I prove it? Also, what about the inverse: Given that $|f(x)| \le a|x| + b$ is satisfied for all $x\in\mathbb{R}$, can we say anything about the Lipschitz condition, either locally or globally?","['lipschitz-functions', 'continuity', 'functional-analysis']"
1227341,Prove that $14322\mid n^{31} - n$,"Im trying to prove that $ 14322 \mid n^{31} - n $, $ \forall n \in \mathbb{Z}$ My thought was to rewrite $n^{31} - n$
which a got to $$ 2(n-1)\sum_{i=0}^{n} i \sum_{k=0}^{14} n^k \sum_{j=0}^{14} (-1)^kn^k $$ but this didnt (in my opinion) contribute to much. I tried to assume that it was false, and then try to get a contradiction. saying that  $n^{31}-n=q\cdot 14322 + r$, $0<r<q, q\in \mathbb{Z}$ then reaching a contradiction $\Rightarrow$ $r=0$. I did not see any obvious contradiction. Hints?",['discrete-mathematics']
1227346,Variation of Tower of Hanoi,"I have been reviewing the solution of the following problem for which I have to find a recurrence relation for the number of moves: ""In the Tower of Hanoi puzzle, suppose our goal is to transfer all n disks from peg 1 to peg 3, but we cannot move a disk directly between pegs 1 and 3. Each move of a disk must be a move involving peg 2. As usual, we cannot place a disk on top of a smaller disk."" The solution involves the following steps: Move n-1 disks from peg 1 to peg 3 (requires Sn-1 steps) Move the nth disk from peg 1 to peg 2 (requires 1 step) Move n-1 disks from peg 3 to peg 1 (requires Sn-1 steps) Move the nth disk from peg 2 to peg 3 (requires 1 step) Now it takes Sn-1 steps to move the remaining disks from peg 1 to peg 3. I understand perfectly from 1 to 4 but I do not get the idea of step 5. I will very much appreciate your feedback. Finally, the recurrence relation is Sn = 3Sn-1 + 2.","['recurrence-relations', 'discrete-mathematics']"
1227355,"Name of a ""factorial"" distribution","Is there a common name for the distribution $P(m)=\frac{(m-1)}{m!}$, for integers $m\in \{1,\infty\}$? Its mean is $e$.","['probability-theory', 'probability', 'probability-distributions']"
1227409,indexing all combinations without making list [duplicate],"This question already has an answer here : A positional number system for enumerating fixed-size subsets? (1 answer) Closed 8 years ago . What is the most efficient way to to find the i'th combination of all combinations without repetition and without first creating all combinations until i. K is fixed (number of elements in each combination) and N is fixed (number of elements to be combined). The order does not matter although extra kudos for finding i in the following order... 1 2 3 4 5 6 7 8 1,2,3,4 1,2,3,5 1,2,3,6 1,2,4,5 1,2,4,6 1,2,5,6 1,3,4,5 1,3,4,6 9 10 11 12 13 14 15 1,3,5,6 1,4,5,6 2,3,4,5 2,3,4,6 2,3,5,6 2,4,5,6 3,4,5,6","['combinations', 'combinatorics']"
1227419,Having trouble evaluating this integral,"$$\int\limits_6^{16}\left(\frac{1}{\sqrt{x^3+7x^2+8x-16}}\right)\,\mathrm dx=\frac{\pi }{k}$$ Note: $k$ is a constant.","['calculus', 'definite-integrals', 'integration']"
1227566,Is there a set which is a group with respect to both addition and multiplication?,"Since addition requires 0 as it's identity and 0 has no inverse under multiplication this would seem to suggest that it is impossible but I am unable to prove it or find an example. Perhaps the rules are different enough under complex numbers, quaternions, or octonions to allow such a set to be possible.",['abstract-algebra']
1227570,The minimal group with Fitting length three,Let $G$ be a group with Fitting lengt $3$ i.e $$e< F_1< F_2 < F_3=G$$ and $F(G)=F_1$ and $\bar {F_2}=F(G/F_1)$. If every proper subgroup of $G$ and every non-trivial quatient of $G$ has fitting lengt at most $2$ then can we say that $F_i/F_{i-1}$ is abelian ? Or What can we say in that case ?,"['abstract-algebra', 'group-theory', 'finite-groups']"
1227597,How to show that $6^n$ always ends with a $6$ when $n\geq 1$ and $n\in\mathbb{N}$,"Is there a proof that for where $n$ is a natural number $$6^n$$ will end with a $6$? I can understand conceptually that $6\cdot 6$ ends with $6$ and then multiplying that by $6$ will still end with $6$, but is there an actual proof?","['induction', 'algebra-precalculus']"
1227607,Is there a companion to the book 'A Synopsis of Elementary Results in Pure and Applied Mathematics' by George S. Carr?,A Synopsis of Elementary Results in Pure and Applied Mathematics by George S. Carr is as most of you probably know a book that was famously used by the great mathematician Ramanujan. It is said he proved most of the theorems and formulas in this book before he went off to study at Cambridge University with G. H. Hardy. This is quite a feat given that there are about 6000 formulas and theorems in this book. Given that it's a popular and well known book I'm curious as to whether there has ever been a companion guide (or any other resources) published for this book that contains proofs (or hints and the like) of theorems/formulas in question. I am asking as i'd like to work through a portion of this text. Thanks.,"['soft-question', 'algebra-precalculus', 'reference-request', 'book-recommendation', 'advice']"
1227613,Proving isomorphism between graphs,"If I'm asked to prove two graphs are isomorphic by constructing an isomorphism E.g for these two graphs if I start from $u_1$ I have an option to send $u_1$ to any of $v_1$ to $v_6$ and I start by sending $u_1$ to $v_1$ and then for $u_2, u_2$ is adjacent to $u_1$ so image of $u_2$ will be adjacent to image of $u_1$ which is $v_1$ so I have the options of $v_4, v_5$ and $v_6$. My question is that won't we then have different isomorphisms because of the different options that we have to send $u_2$ to, also if I had decided to send $u_1$ to $v_2$ at the start instead of to $v_1$ for example then would  have obtained a different isomorphism, so is there not a unique answer for the isomorphism? So basically if two graphs are isomorphic should we be able to construct an isomorphism regardless of which vertex we choose to start from? I'm asking because the answer that I obtained is different from the one given in the mark scheme, The answer I obtained for the isomorphism was \begin{align*}
u_1 &\to v_1\\ u_2 &\to v_4\\ u_3 &\to v_2\\ u_4 &\to v_5\\ u_5 &\to v_3\\ u_6 &\to v_6,\end{align*} I would be grateful if someone could check this for me.","['graph-theory', 'discrete-mathematics']"
1227621,"Expressing ${}_2F_1(a, b; c; z)^2$ as a single series","Is there a way to express
$${}_2F_1\bigg(\frac{1}{12}, \frac{5}{12}; \frac{1}{2}; z\bigg)^2$$
as a single series a la Clausen? Note that Clausen's identity is not applicable here.","['power-series', 'sequences-and-series', 'hypergeometric-function']"
1227630,How do I prove that the recurrence contains no perfect square?,"Given the recurrence
$$a_{n+2} = 14a_{n+1} - a_n - 6$$
with $a_1=1$ and $a_2=8$, how do I prove that none of the $a_n$'s apart from $a_1$ is a perfect square. This is not a homework problem, rather part of a small side project. PS : I am aware that we can obtain a closed form solution for the recurrence, however that doesn't seem to help me answer the question, i.e., it is equivalent to proving that $\dfrac{(2+\sqrt3)^{2k-1}-(2-\sqrt3)^{2k-1}}{4\sqrt3} + \dfrac12$ is not a perfect square except for $k=1$. EDIT : Elementary quadratic residue based arguments for small primes enable me to obtain that $n \equiv a \pmod b$, but doesn't seem to help me in ruling out all possible cases except $n=1$. EDIT : To give the problem more context, I was trying to prove that the Mordell's equation $y^2=x^3+1$ has the solutions only as $(-1,0)$, $(0,\pm1)$ and $(2,\pm3)$. After some algebra, you need to find integer solutions to $2m^3-3m^2+1 = n^2$, which in turn results in the above claim.","['recurrence-relations', 'number-theory']"
1227637,"Let $A_i= \left \{...,-2,-1,0,1,...,i \right\}$. Find $\bigcup_{i=1}^{n} A_i$ and $\bigcap_{i=1}^{n} A_i$","I have the following assignment: Let $A_i= \left \{...,-2,-1,0,1,...,i \right\}$. Find a) $\displaystyle \bigcup_{i=1}^{n} A_i$ b) $\displaystyle \bigcap_{i=1}^{n} A_i$ I think the  first one is: $\displaystyle \bigcup_{i=1}^{n} \left \{...,-2,-1,0,1,...,i \right\} = \left \{...,-2,-1,0,1,2...,n \right\}$ But what about the second one?",['elementary-set-theory']
1227639,$\forall \alpha \exists \beta: \beta > \alpha$ where $\alpha$ and $\beta$ cardinals,"I have to prove ZF $\vdash$ $\forall \alpha \exists \beta:\beta > \alpha$, where $\alpha, \beta-$ cardinal numbers. I can prove it only in ZFC . Let's fix some cardinal number $\alpha$. By Cantor's theorem there is no bijection between $\alpha$ and $\mathcal{P}(\alpha)$ (set of all subsets of $\alpha$). Using axiom of choice we can transform $\mathcal{P}(\alpha)$ to a well-ordered set. Then I proved a theorem in ZF that there is an isomorphism between every well-ordered set and some ordinal. Suppose $x \sim \mathcal{P}(\alpha)$. Assume by axiom of specification
$$
A = \{z \in x + 1 \mid \exists f: z \to x \land f - \text{bijection}\}
$$
$A$ is non-empty and is a subset of a well-ordered set hence it has least element $\beta$. This is our cardinal number. But how to avoid axiom of choice ?","['elementary-set-theory', 'axiom-of-choice', 'cardinals']"
1227642,statistics dice problem,"If $5$ fair dice are thrown at the same time, how do you find the probability that there are three $1$'s and two $2$'s? The answer says its $5C2 \cdot (1/6)^5$ but I don't understand why.","['statistics', 'combinatorics']"
1227653,Help to understand changing order of integration,"I have a problem I have been working on, with the solution but the thing is I don't really understand how it is done. The question, is to compute, $$\int_0^1 \int_{9x^2}^9 x^3\sin(8y^3) \,dy\,dx $$ Now, I did notice that we are going to have to reverse the order of integration so first I took note of, as of now I have $$0 \le x \le 1$$ and $$9x^2 \le y \le 9$$ and I tried to consider the graph. This is where I am getting confused, I don't know if I am supposed to consider the area basically above the line $$0\le x\le\sqrt{\frac{y}{9}}$$  and put $0 \le y \le 9$ and compute. I know that is what I should do, but I am having a lot of trouble seeing this from the graph. My apologizes as I am not aware of how to put graphs on the site. I mean I am having trouble visualizing what it is meant to say $x$ is less than that value of $y$, when are we not considering the region bounded above? I appreciate all answers and comments, ideally though I would like an answer that includes graphics if possible! Could anyone shed some light on this? Ps, this is not homework and I already have the final solution if anyone wants to check, it is $$=\frac{1-\cos(5832)}{7776}$$ Thank you all","['multivariable-calculus', 'integration']"
1227685,Monotone increasing continuous function with $\int_a^b f' = f(b) - f(a)$ which is not absolutely continuous,"If $f:[a, b] \to \mathbb{R}$ is continuous and real-valued, f' integrable on [a, b], and $\int_a^b f' = f(b) - f(a)$, must f be absolutely continuous? What if f is monotone increasing? For the first part, I have as a counterexample the Cantor-Lebesgue function joined with itself reflected across the line x = 1; this has derivative f' = 0 everywhere it exists, and f(0) = f(2) = 0, but it's obviously not absolutely continuous. My instincts tell me there should be a similarly pathological example which is monotone increasing, but I may be wrong. Is there a way either to find such a counterexample or to use the fact that the function is now monotone increasing to show that $\int_a^x f' = f(x) - f(a)$ for every x in [a, b]? Progress edit: It seems any reasonable counterexample is a sum of a singular function that begins and ends at 0, but goes up and down in the middle, and an absolutely continuous function that increases faster than the singular function in the part where the latter is going down, but I'm not convinced it's possible for that to exist. Singular non-AC functions seem to inherently have a property that is something like an infinite slope in a set of measure zero. On the opposite front, I know that any BV function f is equal to the sum of an AC function g and a singular function h, so it suffices to show h is constant to get an absolutely continuous function. Showing that h must be constant means assuming I have a ""bump"" where it goes up and then down again, or vise versa, and then showing said bump's existence contradicts one of the properties of f somehow...but I don't see how. I've tried looking at the monotonicity-based inequalities and they seem to point the wrong way to be useful.","['measure-theory', 'continuity', 'real-analysis', 'bounded-variation', 'cantor-set']"
1227697,"Is there a relationship between trigonometric functions and their ""co"" functions?","We all know that sine is one over cosecant, cosine is one over secant, etc. But is there any relationship between sine and cosine, secant and cosecant, and tangent and cotangent? What I am asking here is the meaning of the ""co-"" prefix. Thanks.","['terminology', 'trigonometry']"
1227713,"If Riemann integrable, then it has finite number of discontinuities [duplicate]","This question already has answers here : Example of Riemann integrable $f: [0,1] \to \mathbb R $ whose set of discontinuity points is an uncountable and dense set in $[0,1]$ [closed] (3 answers) Closed 9 years ago . I know that any bounded function with a finite number of discontinuities is Riemann integrable over some interval. Is vice versa i.e., 
If a bounded function is Riemann integrable, then it has a finite number of discontinuities? Thanks.","['analysis', 'integration']"
1227753,What is the adjoint of the wave operator $\square_{g}$ in Sobolev Spaces?,"I have a three part question. The Laplace-Beltrami operator is an operator which is the typical example of a self-adjoint operator in $L^{2}$. I am wondering if this is also true for other Hilbert spaces $W^{k,2}$. The second part of the question and in which I am more interested is the following: How much the results are true for metrics with are not positive definitive. For example, the D'Alambertian (wave operator) in a general Pseudo-riemannian space. Below I am trying to calculate explicitly the adjoint for $\square_{g}$ in $H^{1}({{\cal{U}}_{t_{1}}^{+}},\nu_{g})$. Any comments will be appreciated. The wave operator is self-adjoint in $L^{2}({{\cal{U}}_{t_{1}}^{+}},\nu_{g})$ which means that for all $\psi,\omega \in C_{c}^{\infty}({{\cal{U}}_{t_{1}}^{+}})$ it is true that:
$$(\psi,\square\omega)_{L^2}=(\square\psi,\omega)_{L^2}$$. which allow us to write: $$\int_{{{\cal{U}}_{t_{1}}^{+}}} \square_{g}\psi\omega \nu_{g}
=
\int_{{{\cal{U}}_{t_{1}}^{+}}} \psi\square_{g}\omega \nu_{g}$$ Now taking into account the contracted Ricci identity: $$\square(\psi_{,i})=(\square\psi)_{,i}+R^{j}_{i}\psi_{,j}$$ we have the following equality: $$
\int_{{{\cal{U}}_{t_{1}}^{+}}} (\square_{g}\psi)_{,i}\omega_{,i} \nu_{g}
=
\int_{{{\cal{U}}_{t_{1}}^{+}}} (\square_{g}(\psi_{,i})-R^{j}_{i}\psi_{,j})\omega_{,i}  \nu_{g}
$$ Now the first term using the self adjointness of $\square_{g}$ can be rewritten as:
$$
\int_{{{\cal{U}}_{t_{1}}^{+}}}\square_{g}(\psi_{,i})\omega_{,i} \nu_{g}
=
\int_{{{\cal{U}}_{t_{1}}^{+}}} \psi_{,_{i}}\square_{g}(\omega_{,i}) \nu_{g}
$$
which again using the contracted Ricci identities gives:
$$
\int_{{{\cal{U}}_{t_{1}}^{+}}}\psi_{,_{i}}\square_{g}(\omega_{,i}) \nu_{g}
=
\int_{{{\cal{U}}_{t_{1}}^{+}}} \psi_{,_{i}}((\square_{g}\omega)_{,i}+R^{j}_{i}\omega_{,j}) \nu_{g}
$$ Now putting together the above equalities we have that: $$
  \int_{{{\cal{U}}_{t_{1}}^{+}}}\square\psi\omega \nu_{g}+ \int_{{{\cal{U}}_{t_{1}}^{+}}}(\square\psi)_{i}\omega_{i} \nu_{g}=\int_{{{\cal{U}}_{t_{1}}^{+}}}\psi\square\omega \nu_{g}+ \int_{{{\cal{U}}_{t_{1}}^{+}}}\psi_{i}(\square\omega)_{i} \nu_{g}+\int_{{{\cal{U}}_{t_{1}}^{+}}}(R^{i}_{j}-R^{j}_{i})\psi_{,j}\omega_{,i}   \nu_{g}
$$ It seems that in the case $R^{i}_{j}=0$ then the $\square_{g}$ is self adjoint.
Is that correct? So to sum up. My main question is: How can I calculate the adjoint of the wave operator $\square_{g}$ in Sobolev Spaces?","['differential-geometry', 'hilbert-spaces', 'functional-analysis']"
1227765,Intuition behind the connection one-form,"When we define a connection on one principal bundle $\pi: P\to M$ with structure group $G$ we define it as an association of one subspace $H_pP\subset T_pP$ for each $p\in P$ such that $T_pP = H_pP \oplus V_pP$ If $\delta_g : P\to P$ is the right action by $g$, then $(\delta_g)_\ast H_p P = H_{p\cdot g}P$ for each $g\in G$ The intuition behind this as I know is that we want to say how do we move from one fibre to the other. Vertical vectors, which live in the vertical spaces $V_pP$ cannot do this, because they point along the fibres. Because of that we want to select at each point one complement, the horizontal vectors, which will point to another fiber. Now, one alternative way to define a connection is by means of one $\mathfrak{g}$-valued one-form $\omega$ such that If $A\in \mathfrak{g}$ and $X^A$ is the associated vector field in $P$ then $\omega(X^A) = A$. $\delta_g^\ast \omega = \operatorname{Ad}_{g^{-1}}\omega$, that is, for each $\tau \in T_pP$, $(\delta_g^\ast \omega)_p(\tau) = \operatorname{Ad}_{g^-1}(\omega_p(\tau))$ Then the horizontal spaces are defined by $H_p P = \ker \omega_p$. Now, given the intuition on what a connection should be, how intuitivelly we can understand this? How can one, based on the definition of a connection one-form, understand it is able to do the same thing a connection does? It seems to me that the connection one-form, given one vector $v\in T_p P$ indicating a direction gives one infinitesimal transformation that in some sense corrects the direction so that is becomes horizontal. Because of that if the vector given to it is already horizontal it gives zero. Is this really what the connection form does? If so, how can one see this in a more precise way?","['principal-bundles', 'differential-geometry', 'connections', 'intuition']"
1227769,Can this be shown: $\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\dots}}} = \sqrt a$?,$$\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\sqrt[3]{a\cdots}}}}}}}}}=\sqrt{a}$$ Just for fun. I would like to read the proof of this if it exists. Any references would be appreciated.,"['radicals', 'sequences-and-series', 'nested-radicals']"
1227774,A quite strange question about measure,"this strange question just occurred to me, that say $E\subset[0,1]$ and $mE=1$, does it imply the closure $\overline E=[0,1]$? Or is there a closed proper set in $[0,1]$ that has measure $1$? In that case removing a limit point will satisfy my question. It seems easy but I just can not find a example....","['real-analysis', 'measure-theory']"
1227779,Integral for which numeric methods will always give an incorrect result?,"I was thinking about the following function: $$f(x) = \begin{cases}0 & x\;\mathrm{computable}\\1&\mathrm{otherwise}\end{cases}$$ And the following definite integral: $$I = \int_0^1 f(x)\;\mathrm dx$$ I know that since the computable numbers are countable, $I=1$. However, am I correct in assuming that any numerical method will give $I=0$ (because of the computable nature of any $x$ a computer can create)?","['numerical-methods', 'definite-integrals', 'integration']"
1227783,Laurent series of $\frac1{\sin^2z}$ around 0,"I  tried to expand $\frac{z^2}{\sin(z)^{2}}$ using Taylor expansion, but the coefficient involved some limit of $\frac{0}{0}$ and was really difficult to calculate. (I tried to convince myself the constant term of the Taylor expansion is 1 because $\lim_{x\rightarrow 0}(\frac{z^2}{\sin(z)^{2}})$=1 and the coefficients of z with odd degree are $0$ because $\frac{z^2}{\sin(z)^{2}}$ is a even function). But how do I solve those coefficients explicitly...? Thank you.","['laurent-series', 'sequences-and-series', 'calculus', 'complex-analysis']"
1227800,"Let $H$ have order $m$ and $K$ have order $n$, where $m$ and $n$ are relatively prime. Then $H \cap K=\{e\}$","Let $H$ and $K$ be subgroups of $G$ . Let $H$ have order $m$ and $K$ have order $n$ , where $m$ and $n$ are
relatively prime. Then $H \cap K=\{e\}$ My proof: Let $H$ and $K$ be subgroups where the $\text{ord}(H)=m$ and $\text{ord}(K)=n$ and $m,n$ are relatively prime. We know that $H \cap K$ is a subgroup of $H$ and $K$ since it contains the elements of both in $H$ and $K$ . We shall let the $\text{ord}(H \cap K)=d$ . Then, by Lagrange's theorem, the order of $H$ is a multiple of the order of $H \cap K$ . In other words, $m$ is a multiple of $d$ or $d|m$ . Similarly,  by Lagrange's theorem, the order of $K$ is a multiple of the order of $H \cap K$ . In other words, $n$ is a multiple of $d$ or $d|n$ . Since $d$ divides both $m$ and $n$ and we know $m$ and $n$ are relatively prime then, the order of $H \cap K$ must be $1$ . Since $H \cap K$ is a subgroup, then by properties of subgroup, it contains an inverse which means it must also contain an identity and since $H \cap K$ contains one element, it must contain the identity. As a result, $H \cap K=\{e\}$ Hopefully, someone can confirm or correct any mistakes I made. Thanks!","['abstract-algebra', 'solution-verification']"
1227802,Why are logarithms of trigonometric functions useful?,"I have noticed that in many trigonometric tables the logarithm of the trigonometric values are given. Why this is given and not the actual values of the trigonometric functions? For example, instead of listing the value of $\sin(43^\circ)$, it is the value of $\log(\sin(43^\circ))$ that is listed. The only reason I cam come up with is that in the use of the law of $\sin$:
$$
\frac{\sin(A)}{a} = \frac{\sin(B)}{b}
$$
taking logarithms on both sides one gets
$$
\log(\sin(A)) - \log(a) = \log(\sin(B)) - \log(b)
$$
making it easier to use that specific formula. But this wouldn't work with the law of cosine. Are there other reasons to prefer logarithms of trigonometric functions over just the actual values of the trigonometric functions?","['math-history', 'logarithms', 'reference-request', 'trigonometry']"
1227816,Why does the residue method not work straight out of the box here?,"I'm trying to evaluate the integral $$I = \int_0^{\infty} \frac{\cos(x)-1}{x^2}\,\mathrm{d}x $$ The way I've done this is by rewriting $\frac{\cos(x)-1}{x^2}$ as $\Re\left[\frac{e^{iz}-1}{z^2}\right]$, and then using the residue method to get $$I = \Re\left[\frac{i\pi}{2}\cdot\mathrm{Res}\left(\frac{e^{iz}-1}{z^2}; 0\right)\right]$$ It's clear from the series expansion of $e^{x}$ that the residue evaluates to $i$, which gives us an answer of $-\frac{\pi}{2}$. My question is, why was it necessary to change $\frac{\cos(x)-1}{x^2}$ to a complex-valued function? I see that if I attempt to jump straight to the residue theorem before converting the function, I end up with a residue of $0$, which is clear from the series expansion of $\cos(x)$, which gives $$\frac{\cos(x)-1}{x^2} = -\frac{1}{2}+\frac{x^2}{24}+\cdots$$ But, still, why doesn't the residue theorem immediately apply in this example?","['improper-integrals', 'definite-integrals', 'residue-calculus', 'integration', 'complex-analysis']"
1227885,Trace of a product of two PSD symmetric matrices being zero means this product being a zero matrix?,"Some one can help me with this problem? I have two real positive-semidefinite matrices $P$ and $Z$, $P \succeq 0$, $Z \succeq 0$, and they are both symmetric ($P^T = P$ and $Z^T = Z$). Also trace$ (P\cdot Z) = 0$. Does that mean $P \cdot Z = 0$ ? Assume they are both $n \times n$ square matrices. Thanks！","['semidefinite-programming', 'linear-algebra', 'matrices']"
1227887,When is Chebyshev's $\vartheta(x)>x$?,"Various bounds and computations for Chebyshev's functions $$
\vartheta(x) = \sum_{p\le x} \log p, \quad \psi(x) = \sum_{p^a\le x} \log p
$$ can be found in e.g. Rosser and Schoenfeld, Approximate Formulas for Some Functions of Prime Numbers Dusart, Estimates of Some Functions Over Primes without R.H. Nazardonyavi and Yakubovich, Sharper estimates for Chebyshev’s functions $\vartheta$ and $\psi$ Nazardonyavi and Yakubovich cite Ingham to give as Theorem 1.14 $$
\psi(x)-x = \Omega_{\pm}\left(x^{1/2}\log\log\log x\right)
$$ and Wikipedia cites Hardy and Littlewood already with $$
\psi(x)-x \neq o\left(x^{1/2}\log\log\log x\right)
$$ (though it doesn't say explicitly that large deviations should be on both sides, but follows the two-sided result of Schmidt). These suggest that there should be infinitely many $x$ with $\psi(x)-x>A\sqrt{x}$ for any given constant $A$ . But Dusart gives for all $x>0$ $$
\psi(x)-\vartheta(x)<1.00007\sqrt{x}+1.78\sqrt[3]{x}
$$ which is bounded by a constant multiple of $\sqrt{x}$ . Hence (if I read correctly) there should be infinitely many $x$ with $\vartheta(x)>x$ . Is any such value for $x$ known, or a range where this is expected to occur?","['number-theory', 'chebyshev-function']"
1227889,Number of elements in an equivalence class,"Let a set X = {1, 2, 3, 4, ... , 2015} and a set Y = {1, 2, 3, 4, ... , 271}. Let S be the relation on P(X) defined by: For all sets A, B, that are elements of P(X), (A,B) are elements of S if and only if |A n Y| = |B n Y| How many equivalence classes are there?
How many elements are in the equivalence class [{271}]? I calculated there to be 272 equivalence classes, because Y has 271 elements, the number of elements that A can share with Y is 272, from 0 - 271. However, for the next question, I don't know if I'm interpreting this right, but I think it's asking for the number of sets where A shares 271 elements with Y. However, since A is an element of the power set of X, it has 2^2015 sets, and if you remove the 271 elements that A shares with Y, there is still 2^1744 sets in A. Each one of those can match up to 2^1744 sets in B, and at this point I think I'm already very wrong. However, I just don't see any other way of going about this question, unless I'm misinterpreting the question itself. Any help would be greatly appreciated. Thank you.","['equivalence-relations', 'discrete-mathematics']"
1227904,How do I understand constraints on high order derivatives of the Gauss Map?,"I'm trying to understand the constraints resulting from differentiating an unit normal field $N$ on a surface $S$ in $\mathbb{R}^3$.  If I write the unit-length constraint at a point $p \in S$,
I have: 
$$\langle N(p), N(p) \rangle = 1$$ Here, the angle brackets correspond to the standard dot product in $\mathbb{R}^3$.
(For notational simplicity, I'll leave out the $p$ from now on.)  I can take a directional derivative of this equation in the direction $\vec{v} \in T_p S$ to get: $$ \langle D_\vec{v} N, N \rangle + \langle N, D_{\vec{v}} N \rangle = 0  $$ This shows that the image of the differential of the Gauss Map lies in $T_p (S)$. I can continue along this analysis, taking more and more directional derivatives to get constraints on the higher derivatives, e.g if $\vec{u} \in T_p (S)$ $$ \langle D_{\vec{u}} (D_\vec{v} N), N \rangle + \langle  D_\vec{v} N, D_\vec{u} N \rangle + \langle  D_\vec{u} N, D_\vec{v} N \rangle + \langle N, D_{\vec{u}}(D_{\vec{v}} N)\rangle = 0 $$ I would like to think of this process in tensorial terms -- that is, terms like $D_{\vec{u}} (D_\vec{v} N)$ can be considered as a $(1, 2)$ tensor.  So, let me write $D_{\vec{u}} (D_\vec{v} N)$ as $D^2 N$ and so on.
For example, if I take $m$ derivatives, I will get terms such as T = $\langle D^i N, D^j N \rangle$ where $i + j = m$. I believe I can think of $T$ as a $(0, m)$ tensor, where I place the first $i$ inputs into the $D^i N$ and the next $j$ inputs into the $D^j N$.  To be more precise, I think I need to consider $D^i N$ as a (1, i) tensor and $D^j N$ as a (1, j) tensor and then the dot product forms some kind of contraction. My question involves how to represent these terms via arrays and computation. How do I represent a single term like $T$ as a m-dimensional array that can take in $m$ vectors?  For now, I would just like to verify (via code and a given surface, so I can calculate derivatives of the normal field of any order) that if I sum up the L.H.S of each equation, I will get 0.  But how do I express these tensors correctly? I do not want to choose my directions (like $\vec{v}, \vec{u}$) explicitly, but instead write the tensor formulations as arrays of numbers in a tangent plane basis.  So, when I sum up all the terms, I should get a m-dimensional array of zeros. I think I need to be careful, as there is an ordering of inputs that notation like $D^i N$ hides.   That is, there will be multiple terms involved of the same order derivatives, but involving different input vectors.  For example, if my first three inputs are $\{\vec{v}, \vec{u}, \vec{w}\}$, I don't think I can consider the tensor $\langle D_\vec{u} (D_\vec{v} N), D_\vec{w} N \rangle$ as equal to the tensor $\langle D_\vec{w} (D_\vec{v} N), D_\vec{u} N \rangle$.  Thus, I believe I will need to rearrange dimensions of these arrays in a proper fashion.  But I don't know what ""proper"" is. I apologize if this writeup is unclear; please ask for clarification if needed.  And thank you so much for any enlightenment you can give me!  Even a suitable reference would be much appreciated! EDIT: To be more precise about my confusion:  Suppose I take $n$ derivatives.  I will have terms like $D^i N$, with $i < n$.  Although an individual $D^i N$ is a $2 \times 2 \cdots \times 2 \times 3$ array, with $i + 1$ total dimensions, I need to ""embed"" it as a $n + 1$ dimensional array in order to dot product it or sum it with the various other terms in the equation.  This is because the different $D^i N$ terms are tensors acting on different sets of input vectors.  So, to combine these different tensors, I need to place them all in the same space -- the space of $(1, n)$ tensors. If I know my normal field and surface completely, this should just be a matter of bookkeeping.  I believe I just pad certain dimensions (corresponding to the unused inputs) of the arrays with copies of the rows from the dimensions of the used inputs.  In this fashion, these tensors will be independent of the set of $n - i$ unused inputs. Is this correct?","['differential-geometry', 'tensors']"
1227911,An interesting semi-linear PDE problem,"Assume $u\in H^1(\mathbb{R}^n)$ has compact support, and assume that it is a weak solution of the semi linear equation
  $$
-\Delta u+c(u)=f\;\;\text{in}\;\mathbb{R^n}
$$
  where $f\in L^2(\mathbb{R^n})$ and $c:\mathbb{R}\to\mathbb{R}$ is a smooth function with $c(0)=0$ and $c'\ge 0$. Prove that $u\in H^2(\mathbb{R^n})$. I know exactly how to prove this following the hint in textbook by ""difference quotient"" method. However, my friend told me it can be proved by Fourier transformation and don't assume $c' \ge 0$. Any hint? Thanks!","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
1227914,"Proving that $\phi_a(z) = (z-a)/(1-\overline{a}z)$ maps $B(0,1)$ onto itself.","I want to prove that if $\phi_a: B(0,1) \to \Bbb C$ is given by $\phi_a(z) = (z-a)/(1-\overline{a}z)$ with $|a| < 1$, then $|\phi_a(z)| < 1$. Resist the itch on your finger urging you to close the question: I already took a look at this question and this one . I'm supposed to prove things in the most elementary way possible (not by choice, sadly). Meaning: no Möbius transformations (I haven't studied them yet, anyway), no exponential maps, etc. My attempt so far: $$ \begin{align} |\phi_a(z)| &< 1  \iff  \left| \frac{z-a}{1-\overline{a}z}\right| <1 \iff \\ \iff |z-a| &< |1-\overline{a}z|   \iff |z-a|^2 < |1-\overline{a}z|^2 \iff \\ \iff |z|^2-&2\,{\rm Re}(\overline{a}z)+|a|^2 < 1  -2\,{\rm Re}(\overline{a}z)+|\overline{a}z|^2 \iff \\ \iff &|z|^2 + |a|^2 < 1 + |a|^2|z|^2\end{align}$$ I'm stuck here. If $|a|^2 < |a|^2|z|^2$, then I could go back on these implications, but this is false (would give $|z|^2 > 1$). Is there a way to save this, or there is another (elementary) approach? Thanks!","['complex-analysis', 'complex-numbers', 'inequality']"
1227941,Prove: $(\det(A-B)+\det(A+B) )^2 \ge 4\det(A^2-B^2 )$,"Let $A,B \in  \mathcal{M}_n (\mathbb{R})$ two matrices so that: a) $AB^2=B^2 A$ and $BA^2=A^2 B$ b) $\text{rank}(AB-BA)=1$. Prove: $$(\det(A-B)+\det(A+B) )^2≥4\det(A^2-B^2 )$$ This is a solution: Denote $C=AB-BA$. Then $rank(C)=1$ so $C=p\cdot q^T$ where $p,q$ are
  column vectors and $tr(C)=0$. This proves that 
  $C^2=p\cdot q^T\cdot p\cdot q^T=tr(C)C=0.$ If $D=A^2-B^2$ then a) implies that $CD=DC$ and $D$ commutes with
  $A,B$. As a consequence $tr(CD^{-1})=0$. If $\det(D)=0$ we have nothing to prove. Else $D$ is invertible and
  $(CD^{-1})^2=0$. We have $(A-B)(A+B)=A^2-B^2+AB-BA=D+C$. We would like to prove that
  $\det(A-B)(B-A)=\det(A^2-B^2)$. For this define $ f(t)=\det(AB-BA+t(A^2-B^2))$ and see that $f(t)=\det(D)\det(CD^{-1}+tI)=\det(A^2-B^2)\cdot t^n$. Replace $t=1$ in the previous relation to get 
  $\det(AB-BA+A^2-B^2)=\det(A^2-B^2)$ and we are done. But i don't understand why  $tr(CD^{-1})=0$ ??","['determinant', 'linear-algebra', 'matrices']"
1228085,A basic question regarding Lebesgue's density theorem,"Here is the question from Pugh's Real Mathematical Analysis: My answer to $b)$ is that for a closed square, points on corner has density $1/4$, while on the sides the density is $1/2$. But how to understand that ""almost every point has density 1"" by Lebesgue's density theorem? Is it because side of a square in $R^2$ has lower dimension and thus has zero measure (i.e. line in a plane has zero measure)? For $c)$, I want to use set of natural numbers (denote as $N$), which has measure $0$. So $m(B \cap N)=0$, while $mB$ is the length of interval. So  this imply that density of any natural number is $0$? I find a little bit confused because the denominator (length of interval) also tends to $0$. Still can someone show the density of points in the cantor set? By Lebesgue's density theorem, almost every point should have density of 1, but how to compute that, and are there points in cantor set with other values of density? What's more, the textbook does not require the ball $B$ to be centered at $x$, while many other materials require the ball to be centered at $x$ (and if B's centre is x, the textbook calls such density the balanced density as the picture shows). So what's the difference between those 2 versions of ""density""? Are they eventually the same definition? It is confused to compare limits where one come from balls centred at a point (balanced density), while others only require ball contain a point (density in this textbook). Thanks!","['lebesgue-measure', 'proof-verification', 'measure-theory']"
1228179,Find integer $n$ that satisfies $(\lg n)^{2^{100}} <\sqrt{n}$ with $n > 2$,"If $(\lg n)^{2^{100}} < {n^{1/2}}$, where $\lg$ is the binary logarithm , then $$(\lg n)^{2^{101}} < n$$
$$2^{101}\lg \lg n < \lg n$$
$$101 < \lg \lg n - \lg \lg \lg n$$ I don't know that whether I assume that $n = 2^x$.
Anyway suppose that $n = 2^x$, then $\lg \lg \lg n = \lg \lg x$. So, suppose that $x = 2^y$ (it's ambiguous), then $101 < y - \lg y$
therefore, $y = 108$, $n = 2^{2^{108}}$. I'm curious that there is exact solving method. Because I'm not sure, if $n = 2^{2^{108}} - 1$, what happens??","['discrete-mathematics', 'algebra-precalculus', 'logarithms']"
1228192,algebra generated by finite set,"Is algebra generated by a finite set $A$ same a the $\sigma$-algebra generated by the same set $A$? For example: $X=\{1,2,3,4\}$, $A=\{\{1,2\},\{ 2,3\},\{ 4\} \}$, what is the algebra generated by $A$ on $X$?",['measure-theory']
1228203,Find $f(x) $ given that: $f'(x)=\frac{f(x)-x}{f(x)+x}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I would appreciate if somebody could help me with the following problem: Find $f(x)$ given that: $f \colon \mathbb{R^+} \rightarrow  \mathbb{R^+}$ , $f$ is differentiable function, and $f'(x)=\frac{f(x)-x}{f(x)+x}$ I tried  but couldn't get it that way.","['ordinary-differential-equations', 'functional-equations']"
1228229,Insert squares into square [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $ABCD$ be a square, $AB=2a$
Is it possible to insert two disjoint squares, both of side $a$ into $ABCD$?",['geometry']
1228242,"A ""Theorem Style"" Problem Book in Differential Geometry","I am trying to teach myself differential geometry using Lee's Introduction to Smooth Manifolds . To test my understanding, and learn the subject better, I am looking for a good problem book in differential geometry. The kind of problems I am looking for are non-computational ones. The problems which are very much like theorems in themselves. The best I can describe the kind of book I am looking for is something like Berkeley's Problems in Mathematics is for undergraduate mathematics. The problems are not too hard. But each problem teaches something nice.","['book-recommendation', 'differential-geometry', 'smooth-manifolds', 'problem-solving']"
1228251,Compute $\lim_{x\rightarrow0}\frac{e^{x^2} - \cos x}{\sin^2 x}$,"Find the limit as $x$ approaches $0$ of $\dfrac{e^{x^2} - \cos x}{\sin^2 x}$ What I tried is as $x$ approaches $0$, $e^{x^2}$ tends to $1$ and so the numerator tends to $1-\cos x$ and after doing some trigonometric simplifications I got the answer as $\frac 12$. Is this right? Any help would be appreciated.","['calculus', 'limits']"
1228281,What did I do wrong trying to find this limit?,"In another question , a user asked to find:
$$\lim_{x\to 0} \frac{\exp(x^2)-\cos(x)}{\sin(x)^2}$$
I thought I could use pure trigonometric identities to find the limit. Apparently I was mistaken, but I can't find my mistake. Here's what I did: Knowing $\sin(x)^2 = \frac{1-\cos(2x)}{2}$:
$$\frac{\exp(x^2)-\cos(x)}{\sin(x)^2} = \frac{\exp(x^2)-\cos(x)}{\frac{1-\cos(2x)}{2}} = \frac{\exp(x^2)-\cos(x)}{1} \cdot \frac{2}{1-\cos(2x)}$$
$$ = \frac{2(\exp(x^2)-\cos(x))}{1-\cos(2x)}$$
And knowing $\cos(2x) = 2\cos(x)^2-1$:
$$\frac{2(\exp(x^2)-\cos(x))}{1-\cos(2x)} = \frac{2(\exp(x^2)-\cos(x))}{1-(2\cos(x)^2-1)} = \frac{2(\exp(x^2)-\cos(x))}{-2(\cos(x)^2)}$$
$$ = -1 \cdot \frac{\exp(x^2)-\cos(x)}{\cos(x)^2} = -1 \cdot \left( \frac{\exp(x^2)}{cos(x)^2} -\frac{\cos(x)}{\cos(x)^2} \right)
= -1 \cdot \left( \frac{\exp(x^2)}{cos(x)^2} -\frac{1}{cos(x)} \right) $$
And we can plug in $x=0$ since we don't run the risk of an indeterminate form:
$$ -1 \cdot \left( \frac{\exp(0^2)}{cos(0)^2} -\frac{1}{cos(0)} \right)  = -1 \cdot \left( \frac{1}{1^2} -\frac{1}{1} \right) = -1 \cdot 0 = 0$$ Apparently the correct answer is $3/2$. Where did I go wrong?","['solution-verification', 'calculus', 'algebra-precalculus', 'trigonometry']"
1228290,State space representation involving derivatives of input,"We have the system $y''=-7y'-12y-u'-2u$ If we choose $x_1=y,x_2=y'$ we can write the system as $x'=Ax + Bu \\ y= Cx$ Finding A is easy, but how do I find expressions for $B$ and $C$ when we have derivatives of the input in the expression?","['control-theory', 'ordinary-differential-equations']"
1228297,How to prove $\oint_\Gamma \nabla\theta\cdot\vec{dr}=\pm2\pi $ around a phase singularity/over a cut,"How would you prove that
$$\oint_\Gamma \nabla\theta\cdot\vec{dr}=\pm2\pi $$ We know that $\theta\in(-\pi,\pi)$, suppose that $\theta$ is continuous in the region bounded by and along $\Gamma$ apart from a cut. On one side of the cut $\theta=-\pi$ and the other $\theta=\pi$, so $\theta$ makes a jump of magnitude $2\pi$ over this cut. Effectively I am describing the atan2 function, however i'm not assuming uniform change in $\theta$. Is this as simple as saying, let us treat this contour as a disconnected line integral $\Gamma:[0,1]\rightarrow\mathbb{R}$ such that $\theta(\Gamma(0))=\mp \pi$ and $\theta(\Gamma(1))=\pm \pi$, therefore,
$$ \int_\Gamma \nabla\theta\cdot\vec{dr}=\theta(\Gamma(1))-\theta(\Gamma(0))=\pm2\pi $$ I'm asking as it's been a while since i've studied any formal complex analysis and i'm hopeful there's a more formal way to think about this.","['line-integrals', 'complex-analysis']"
1228307,Why is the empty set considered an interval?,What is the definition of an interval and why is the empty set an interval by that definition?,"['analysis', 'real-analysis', 'definition']"
1228319,group scheme of prime order p is killed by p,"In the article ""Group Schemes of Prime Order"" by Tate and Oort (see here ) it is proved that a group scheme of prime order $p$ over the base $S$ is killed by $p$ (Theorem 1). The authors state that it clearly suffices to consider the case $S = $ Spec$(R)$, where $R$ is a local ring with algebraically closed residue class field. I don't quite understand this reduction and would be thankful if someone could explain it to me.","['algebraic-geometry', 'schemes']"
1228320,Can transcendental to the power transcendental be rational?,Can a transcendental number to the power of a transcendental number be a rational number?,"['transcendental-numbers', 'number-theory', 'rationality-testing']"
1228350,"For what values of t, the solution for this equation exist","I need help in finding maximal solution for the problem: 
$$ \cases {{\dot{x} = x^2+t}\\{x(0)=0}}$$
I know that because $x(1) \geq \frac{1}{2}$ and that every solution $x(t)$ of the problem is greater than or equal to $\tan (t+x(1) - 1)$ gives that $$\displaystyle \lim_{t \rightarrow \frac{\pi +1}{2}}x(t) = \infty$$
Is this enough or can I tighten this? What do I do with negative $t$'s ? (I also tried to bound the absolute value of the integral equation and use Gronwell inequality i.e: $$\lvert x \left( t\right)\rvert = \rvert \int_{0}^{t}x^2+t\ dt\lvert < something$$
as well as $$|\int_0 ^t \frac{dx}{x^2}| = |\int_0 ^ t 1+\frac{t}{x^2}dt|< anything$$  but no success.) An other attempt with Pickard iterations: $\varphi_{0} = 0$ and $\varphi_{n} = \int_0 ^t \varphi^2_{n-1}(s) + s\ ds$, after some calculations, (and I need help in verifying correctness) I got 
$$\varphi_n(t) = \sum _{i=0}^n \frac{t^{a_i}}{a_i \cdot {a_{i-1}^2 \cdot... \cdot {a_{0}^{\log_2{i}}}}} = \frac{t^{a_n}}{a_n \cdot a_{n-1}^2 \cdot ... \cdot a_{0}^{\log n}} + O( \frac{t^{a_{n-1}}}{{a_{n-1}}^{n-1}} )$$ When $a_n = 3\cdot 2^{n-1}-1$ By ratio test - the series diverges when t>1, but $ \frac{1}{2} \leq x(1) \leq \tan(1)$ (previous lines) gives that the solution can be extended for $t$'s larger than 1. What is going on Here?","['proof-verification', 'real-analysis', 'ordinary-differential-equations']"
1228367,Vertical asymptotes of a given non-rational radical funtion,"We have that $f$ is a function $f(x) = x\sqrt{x+4}$. Hence, $f'(x) = \dfrac{3x+8}{2\sqrt{x+4}}$. Then, $\lim_{x \to -4^+}f'(x) = -\infty$. This means that $f$ has a vertical slope at $f(-4)$. It was my first thought to say, by this, $f$ has a vertical asymptote at $x = -4$; I wonder, though, is it so that an asymptote can necessarily only exist when a function is rational?","['calculus', 'limits', 'functions', 'radicals', 'derivatives']"
1228403,Polynomials and Divisibility Rule.,"The question is this - If $f(x)$ and $g(x)$ are two polynomials such that the polynomial $h(x)=xf(x^3)+x^2g(x^6)$ is divisible by $x^2+x+1$, then which of the following are true? 1. $f(1)=g(1)$ 2. $f(1)=-g(1)$ 3. $h(1)=0$ So I wrote out this $$xf(x^3)+x^2g(x^6)=Q(x).(x^2+x+1)$$
where $Q(x)$ is the quotient polynomial. Then I tried substituting a few values like $1$ and $0$, but these get me nowhere. The $Q(x)$ is making problems and also the fact that $x^2+x+1=0$ does not have easy to substitute roots. Can anyone give any hints or general tips regarding questions like these? Thank you. Edit Real coefficients to the polynomials might have to be assumed, I'm not sure.","['polynomials', 'divisibility', 'algebra-precalculus']"
1228432,Prove that $\det(AA^T+I)\ge 1$,"If $A$ is a matrix with real entries, prove that $$\det(AA^T+I)\ge 1.$$ I tried using the eigenvalues. One thing came into my mind: maybe $AA^T$ is positive definite (I don't know whether this is true or not). However, I prefer a solution that does not use properties of positive definite matrix. So I have 2 questions here: Is the statement ""$AA^T$ is positive definite"" true? Could you help me with a solution that does not use properties of positive definite matrix? Thanks a lot.","['eigenvalues-eigenvectors', 'determinant', 'linear-algebra', 'inequality']"
1228513,What is the exponent of a group?,"I don't really understand the definition: The exponent of a group G is the smallest natural number x such that for all $g \in G,g^x = e$. It seems like it's saying, for EVERY element of the group, when you keep applying the group operation to itself which power to itself gives you e.What is the lowest number that this is true for for all elements of G. First of all, what would even be the point of creating some definition like that, what purpose does something like this serve? I guess, I would see that you could get the lcm of all the exponents that equal e, but it seems like a pretty tedious process to figure out where g's equal e. I am obviously missing something, can someone help me out here? Thanks scores.","['abstract-algebra', 'group-theory']"
1228534,"Borel sigma-algebra over [0,1]","I just started studying this, so forgive me if I get something wrong. I have been given the following definition of a Borel $\sigma$-algebra over $\Omega=[0,1]$: It is the smallest $\sigma$-algebra that contains all intervals $(a,b)$ with $0\leq a<b\leq1$. Lets call this algebra $\mathcal{B}$. Now apparently, every subinterval of $[0,1]$, including a half-open one like $[0,1)$, should be in $\mathcal{B}$. Even simpler, $\{0\}\in\mathcal{B}$ should be correct. Right? I can not figure out how this would work - I know that complements, intersections and unions of any elements of $\mathcal{B}$ are again elements of $\mathcal{B}$. With the given definition, I don't know how to obtain a subset that contains either $0$ or $1$ and not both: $0\leq a<b\leq 1, M = (a,b) => 0,1 \notin M => 0,1\in \overline{M}$. I have searched using google and stackexchange, but I seem to have been given an uncommon definition. Is the definition wrong or am I missing something?",['measure-theory']
1228567,Probability of throwing balls into bins.,"Suppose we have $M$ balls placed randomly into $N$ boxes, wherein each ball has an equal chance of landing in each bin. How would we go about finding the expected number of balls in the first box? I assumed we could use a binomial distribution, wherein we would regard a ball being thrown into the first box as a success, and the probability of success is $1/N$. Hence, from this, the expected value of balls in the first box is $M/N$. Is this a correct approach?",['probability']
1228587,Why is it called the Fundamental Theorem of Arithmetic?,"The Fundamental Theorem of Arithmetic is easy enough to understand, saying that every integer greater than 1 is either prime or is the product of a unique combination of prime numbers. What I don't understand is why this is ""fundamental."" This may have massively important implications in number theory and cryptography and whatever else, but in terms of arithmetic , which I think of as adding, subtracting, multiplying, and dividing, it doesn't really actually seem to have that much importance....I don't see why it should be so fundamental . Can someone explain its importance, or why it isn't called perhaps the ""Fundamental Theorem of Number Theory""? I would expect the Fundamental Theorem of Arithmetic to be something.","['number-theory', 'elementary-number-theory', 'soft-question']"
1228593,Proof of the Frobenius Schur indicator,"I am trying to prove the Frobenius-Schur indicator for $\chi$ irreducible character. \begin{equation}
	i_{\chi} =
	\begin{cases}
	0,  & \text{if $\chi$ is not real valued} \\
	\pm1, & \text{if $\chi$ is real valued}
	\end{cases} 
	\end{equation} Now starting from definition $$\begin{align}i_{\chi} &= \frac{1}{|G|}\sum_{g \in G}\chi(g^2) \\
&=  \frac{1}{|G|}\sum_{g \in G}\chi_{S^2V}(g)-\chi_{A^2V}(g) \\
&= \frac{1}{|G|}\sum_{g \in G}\chi_{S^2V}(g)-\frac{1}{|G|}\sum_{g \in G}\chi_{A^2V}(g) \\
&= \dim (S^2V)^G-\dim (A^2V)^G 
\end{align}$$ which is the number of trivial representations in $S^2V$ - number of trivial representations in $A^2V$. Somehow this is related to the fact that $\chi$ is an irreducible character. I'm pretty sure I am correct so far but I cannot see how this relates to the final answer. I have looked at this online but I am not familiar with invariant bilinear form so could these please be avoided.","['representation-theory', 'characters', 'group-theory', 'finite-groups']"
1228599,Why is the negation of $A \Rightarrow B$ not $A \Rightarrow \lnot B$?,"The book I am reading says that the negation of ""$A$ implies $B$"" is ""$A$ does not necessarily imply $B$"" and not ""$A$ implies not $B$"". I understand the distinction between the two cases but why is the first one considered true?","['logic', 'propositional-calculus', 'discrete-mathematics']"
1228603,Relation between vague convergence and weak convergence,This is the Portemanteau Theorem. And this is its corollary. I tried to prove that (i) implies (ii) in this corollary using the Portemanteau Theorem above. But I have kept failed... What is so frustrating here is that I can't think of any way to apply the Portemanteau Theorem to continuous functions with compact support... Could anyone help me with this?,"['probability-theory', 'probability-distributions', 'real-analysis', 'measure-theory']"
1228635,Integrate two sets of Data and check similarity,"I have the following CSV Data
I used Excel Charts to plot the Data I want to compare these Data with other Data, in another word i want to comapre 2 curves and check the similarity between them in my case
$$
y = f(x) = \text{Value | x=Time}
$$ i found the following formula $$
\% \text{ error} = \frac{\sum{||{f(x)-g(x)}}||}{\sum\sqrt{(x_{i+1}-x_{i})^2+(y_{i+1}-y_{i})^2}}
$$ is this Formula correct ? are $x_{i} \text{ and } y_{i}$ the Value or simply the Indices that are in my case Time ? what if the both functions have different x or Time but they have/follow the same trend ? i'm using python for programming","['statistics', 'dynamic-programming', 'integration']"
1228642,Using the binomial theorem to generate a geometric proof of the derivative.,"According to wikipedia, if we wanted to prove $$(x^n)'=nx^{n-1}$$ geometrically by creating an $n$-dimensional hypercube $$(x+\Delta x)^n$$ and setting $a=x$ and $b=\Delta x$, we could expand using the binomial theorem to $$x^n + nx^{n-1}\Delta x + \binom{n}{2}x^{n-2}(\Delta x)^2 + ...$$ (and this is where I lose it) the terms $(\Delta x)^2$ and higher become negligible as $\Delta x \to 0$, which yields the formula $$(x^n)'=nx^{n-1}$$ However, if $\Delta x \to 0$, wouldn't that yield the formula $$(x^n)'=x^n$$ as every term but the first in the expanded version is reduced to $0$ by being multiplied by $(\Delta x)^k$, where $1\le k \le n$? I don't understand where the leading $x^n$ goes, or why $nx^{n-1}\Delta x$ does not equal 0 as $\Delta x \to 0$","['binomial-theorem', 'derivatives']"
1228666,"The Ackermann's function ""grows faster"" than any primitive recursive function","I am looking at the proof that the Ackermann's function is not primitive recursive. At the part: ""We will prove that Ackermann's function is not primitive recursive by showing that it ""grows faster"" than any primitive recursive function. That means that we need a precise way of comparing the ""growth rate"" of the two-variable function $A$ with that of an arbitrary $n-$variable function. What we shall attempt to do is show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $$A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) \tag {*}$$ for all values of $x_1, \dots , x_n$. 
The proof is accomplished by induction on the number of compositions and primitive recursions needed to define the function $f$. "" Could you explain to me why we want to show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) $ for all values of $x_1, \dots , x_n$ in order to show that the Ackermann's function ""grows faster"" than any primitive recursive function ?? Also, why do we use induction on the number of compositions and primitive recursions needed to define the function $f$ ?? $$$$ EDIT: The proof that the Ackermann's function is not primitive recursive is the following: To prove this we need the following properties concerning the values of $A$. $A(x,y)>y$. $A(x,y+1)>A(x,y)$. If $y_2>y_1$, then $A(x,y_2)>A(x,y_1)$. $A(x+1, y) \geq A(x,y+1)$. $A(x,y)>x$. If $x_2>x_1$, then $A(x_2, y)>A(x_1, y)$. $A(x+2, y)>A(x,2y)$. We will prove that Ackermann's function is not primitive recursive by showing that it ""grows faster"" than any primitive recursive function. That means that we need a precise way of comparing the ""growth rate"" of the two-variable function $A$ with that of an arbitrary $n-$variable function. What we shall attempt to do is show that for any given $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $$A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n) \tag {*}$$ for all values of $x_1, \dots , x_n$. 
The proof is accomplished by induction on the number of compositions and primitive recursions needed to define the function $f$. In order to carry out the induction step of the proof, we need two auxiliary results. The results of these results ensures that if the functions $g_1, \dots , g_m$ and $h$ satisfy $(*)$, so does the function $f$ obtained from $g_1, \dots , g_m$ and $h$ by functional composition. Lemma 1 . Let the $n-$variable function $f=h \circ (g_1, \dots , g_m)$ be obtained from the functions $g_1, \dots , g_m$ and $h$ by composition. Assume the existence of natural numbers $k_1, \dots , k_m$, and $k_0$ such that $$A(k_i, \max (x_1, \dots , x_n)) > g_i (x_1, \dots , x_n) \text{ for } 1 \leq i \leq m\\ \text{ and } \\ A(k_0, \max (y_1, \dots , y_m )) > h(y_1, \dots , y_m)$$ for all $x_1, \dots , x_n$ and $y_1, \dots , y_m$. Define $k$ to be the natural number $\max (k_0, k_1, \dots , k_m)+2$. Then $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n)$ for all $x_1, \dots , x_n$. Lemma 2 . Let the $(n+1)-$variable function $f$ be defined by primitive recursion from the $n-$variable function $g$ and the $(n+2)-$variable function $h$, so that $$f(x_1, \dots , x_n, 0)=g(x_1, \dots , x_n) \\ f(x_1, \dots x_n, y+1)=h(x_1, \dots , x_n , y, f(x_1, \dots , x_n, y))$$ Assume the existence of natural numbers $k_g$ and $k_h$ such that $$A(k_g ,\max (x_1, \dots , x_n)) > g(x_1, \dots , x_n) \\ \text{ and } \\ A(k_h, \max (x_1, \dots , x_n , y , z)) > h(x_1, \dots , x_n , y, z)$$ for all $x_1, \dots ,x_n, y$ and $z$. Define $k$ to be the natural number $\max (k_g, k_h)+3$. Then $A(k, \max (x_1, \dots , x_n , y)) > f(x_1, \dots  ,x_n , y)$ for all $x_1, \dots , x_n, y$. Theorem 1. For each $n-$variable primitive recursive function $f$, there exists a natural number $k$ such that $A(k, \max (x_1, \dots , x_n)) > f(x_1, \dots , x_n)$, for all $x_1, \dots , x_n$. Proof. By iduction on the number of compositions and primitive recursions needed to define $f$. We use $\hat{x}$ to denote $\max (x_1, \dots , x_n)$. Basis. If the derivation of $f$ requires no compositions or primitive recursions, three cases are possible. If $f$ is the constant function whose value is $c$, choose $k=c$. Property $5$ then guarantees that $A(k, \hat {x})=A(c, \hat{x})>c=f(x_1, \dots , x_n)$. If $f$ is the projection function whose valuee is $x_i$, choose $k=0$. Then $A(k,\hat{x})=A(0,\hat(x))=\hat(x)+1>x_i=f(x_1, \dots , x_n)$. If $f$ is the successor function, choose $k=1$. Then $A(k,x)=A(1,x)>A(0,x)=x+1=f(x)$. Induction step. Assume the statement of the theorem to be true for all functions requiring $w$ or fewer compositions and primitve recursions. Let $f$ be a function requiring a total of $w+1$ compositions and primitive recursions. Two cases are possible. If $f$ is derived from functions $g_1, \dots , g_m$ and $h$ by composition, the induction hypothesis must apply to each of $g_1, \dots , g_m$, and $h$. Lemma $1$ then guarantees the existence of a number $k$ such that $A(k,\hat{x})>f(x_1, \dots , x_n)$. If $f$ is derived from the functions $g$ and $h$ by primitive recursion, the induction hypothesis must apply to $g$ and $h$. Lemma $2$ then guarantees the existence of a number $k$ such that $A(k, \hat{x})>f(x_1, \dots , x_n)$. Theorem $1$ provides a formal expression of the notopn that $A$ ""grows faster"" than any primitive recursive function. It is now a simple matter to establish: Theorem 2. Ackermann's function is not primitive recursive. Proof. Assume hat Ackermann's function is primitive recursive. Then according to Theorem 1, there must exist a natral number $k$ such that $$A(k, \max (x,y)) > A(x,y)$$ for all $x$ and $y$ . Setting $x=y=k$ then yields the contradiction $$A(k,k) > A(k,k)$$ from which we conclude that $A$ cannot be primitive recursive.","['computer-science', 'ackermann-function', 'discrete-mathematics', 'recursion']"
1228667,Omitting the hypotheses of finiteness of the measure in Egorov theorem,"I want to prove that if I omit the fact that $\mu (X) < \infty$ in Egorov theorem and place instead that our functions $|f_n| <g$ and $g$ is integrable, we still get the result of Egorov's theorem. Fix $m$ a natural number. I took $ w_{n} = |f_n-f|$ and thus by DCT $\int |f_{n} - f|$ goes to zero. Then I took $\bigcup_n {( w_{n} \geq 1/m)}$. I need its measure to be finite. Its measure is less than the sum of the measures of each $ w_n\geq 1/m)$ varying $n$, and by Tchebychev, this is less than $m\int|f_{n} - f|$.  But I got stuck here. Any help is appreciated. Thanks!","['real-analysis', 'uniform-convergence', 'measure-theory']"
1228698,Over-determined and Under-determined systems,"How do I show that a system is both over-determined and under-determined? I am supposed to come up with a matrix that satisfies both but am not really sure I understand what types of equations would satisfy these criteria. If anyone could give me an example and maybe a format to go by, I would appreciate it.",['statistics']
1228710,How can I calculate Index of Coincidence of Vigenère cipher?,"I have computed the letter frequency of the cipher text. However, I don't know how to apply Friedman Test to Vigenère cipher. I couldn't calculate the Index of Coincidence. Does anyone can help to me ? Letters' frequencies : $f_{0} = 0.059 \qquad f_{14} = 0.031 \\
f_{1} =0.055 \qquad f_{15} = 0.064 \\
f_{2} = 0.030 \qquad f_{16} = 0.029 \\
f_{3} = 0.018 \qquad f_{17} = 0.026 \\
f_{4} = 0.029 \qquad f_{18} = 0.027 \\
f_{5} = 0.040 \qquad f_{19} = 0.042 \\
f_{6} = 0.070 \qquad f_{20} = 0.046 \\
f_{7} = 0.030 \qquad f_{21} = 0.046 \\
f_{8} = 0.032 \qquad f_{22} = 0.017 \\
f_{9} = 0.023 \qquad f_{23} = 0.027 \\
f_{10} = 0.046 \qquad f_{24} = 0.036 \\
f_{11} = 0.059 \qquad f_{25} = 0.032 \\
f_{12} = 0.046 \\
f_{13} = 0.039 $ By using these frequencies, how can I calculate Index of Coincidence ?","['cryptography', 'statistics', 'linear-algebra', 'discrete-mathematics']"
1228719,"The sets $\{-x,x\}$ form a partition of $\mathbb Z$","I've been really trying to understand how some of these proofs work; I've spent a majority of my time studying the material for this class, but I'm still performing poorly in it. It doesn't help that the book is very vague; what's worse is that it contains little to no solutions and does not have a solutions manual, so I don't even know if I'm right or wrong half the time. Anyways, in the problem, we are asked to prove that a set is a partition. A problem from the book: Prove that $P=\left\{X: X = \{-x,x\} \space \text{and} \space x\in\mathbb{N} \cup\{0\}\right\}$ is a partition on $\mathbb{Z}$. Recalling that the three criteria of a partition are that: If $X$ is an element of the partition, $X$ cannot be empty. If $X$ and $Y$ are elements of the partition, they are equal or pairwise disjoint. The union of all the elements in the partition are equal to the set we are taking the partition of. I'd greatly appreciate help. I understand what the criteria demand intuitively, but I just can't seem to connect the logic when I do the proofs.","['elementary-set-theory', 'set-partition']"
