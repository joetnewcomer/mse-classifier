question_id,title,body,tags
2486535,Calculate shortest distance between random point and line,"Considering the following situation: The red dot is located at $(0,0)$ and the blue dot is at $(0,-2)$. A black line is crossing the red dot and is rotated at $\alpha = 45Â°$ relative to the red dot. With this information, how can I find the length of the yellow dashed line? My first intuition is to calculate the distance $d$ between the two dots using: $$d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$ The next step should be to calculate the distance between red dot and the point where the black line and yellow dashed line cross. But I can't seem to find how to do that, and even then, I am not sure of what to do next. The problem gets worse since the methodology to find the distance of the yellow dashed line should work for different cases in which the blue dot can be located somewhere else. For example, the following image has the situation in which the black line is still rotated at $\alpha = 45Â°$, the red dot is still at $(0,0)$ but the blue dot is located at $(-1,-2)$ The ultimate goal is to find a methodology that enables calculating the length of the yellow dashed line for any location of the blue dot but also any degree of rotation of the black line knowing that the red dot will always be at $(0,0)$. An example of such situation is shown on the picture under: Here the red dot is still at $(0,0)$, the blue dot is at $(-2,-2)$ but the black line is rotated by $\alpha = 60Â°$ relative to the red dot. Is it even possible to achieve this?",['geometry']
2486559,How is tanÎ¸ in this equation not equal 1/2,"I have been practicing a lot of pre-calculus equations, and currently, I am studying ""Trigonometry"" I have stumbled across this following question: If $\tan(2\theta) = \frac{4}{3}$, $\frac{\pi}{2} < \theta < \pi$, Find $\tan\theta$. I have first got the formula of $\tan(2\theta)$ and equaled it to $\frac{4}{3}$, then I got solving until I was left with: $$(2\tan\theta - 1)(\tan\theta + 2) = 0$$ So that means that $\tan\theta = \frac{1}{2}$, $\tan\theta = -2$.
That's where I was stuck, so I checked for answers and said that $\frac{1}{2}$ was rejected? What does it mean? How do I know if something is rejected or not?","['algebra-precalculus', 'trigonometry']"
2486561,Prove that $\cos (n \arccos (x))$ is a polynomial of $n$-th degree,"So, we got an assignment from the mathematical analysis class to prove that $\cos (n \arccos (x))$ is a polynomial of $n$th degree. I tried to prove it with mathematical induction and so far what I got is: basis :- $T(1) - \cos (1\cdot\arccos (x)) = \cos(\arccos(x)) = x$ Inductive step : $T(n+1)$ - assume it holds for $T(n)$, then it must hold for $T(n+1)$ $$\begin{align}\cos[(n+1) \arccos(x)] = &\cos[n \arccos(x) + \arccos(x)] &\\= 
&\cos[n \arccos(x)] \cos[\arccos(x)] - \sin[n \arccos(x)] \sin[\arccos(x)] 
&\\=& \cos[n\arccos(x)] x - \sin[n \arccos(x)] \sin[\arccos(x)]\end{align}$$ and this is where I got stuck because I don't know what to do with the sine part. like, I get that the $x\cos(n \arccos(x))$ holds because, by inductive step, it holds that $\cos(n\arccos(x))$ is the polynomial of nth degree, so $x\cos(n \arccos(x))$ is polynomial of $(n+1)$th degree. But I don't know if this is enough to prove this or if I need to do something with the sine too.","['induction', 'analysis']"
2486589,$\forall :=\textbf{for every} \ x\in D_f\cap N^+_{\epsilon}(a) \Rightarrow := \textbf{implies that} \ f(a)=f(x)$,"Clime : let $f'(a +)=0$ then $$ \exists  \  N^+_{\epsilon}(a) $$ such that : $$\forall :=\textbf{for every} \ x\in D_f\cap  N^+_{\epsilon}(a) \Rightarrow := \textbf{implies that} \ f(a)=f(x)$$ it is right ? how prove ?
please helpe me","['derivatives', 'calculus']"
2486590,Natural density and Poincare's recurrence,"Let $(X,\mathcal{B},\mu,T)$ be a dynamical system and let $A \in \mathcal{B}$ such that $\mu(A)>0$ and $\forall x \in X$ we define $$L_x=\{n \in \Bbb{N}|T^nx \in A\}$$ Prove that $\mu(\{x:\bar{d}(L_x)>0\})>0$ where $$\bar{d}(L_x)=\limsup_n \frac{|L_x \cap \{1,2...n\}|}{n}$$. My first thought is that i have to use somewhere Poincare's recurrence theorem. But i cannot understand the behavior of the density function. From Poincare we just know that for almost every $x \in A$ we have that $L_x$ is infinite. Can some give me a hint to solve this? I clearly do not want a full solution. I want hint to solve this only with Poincare's Theorem and the properties of the natural  density function.(Not Ergodic Theorems) Any help is appreciated. Thank you in advance","['real-analysis', 'dynamical-systems', 'number-theory', 'ergodic-theory', 'measure-theory']"
2486639,projection theorem for a finite-dimensional problem,"Using the projection theorem, solve the finite-dimensional problem: minimize $x'Qx$ ($x'$ is the transpose of $x$ ) subject to $Ax = b$ where $x$ is an $n$-vector, $Q$ a positive-definite symmetric matrix, A an $m$x$n$ matrix ($m<n$), and $b$ and $m$-vector Solution: I tried to apply Gauss-markov theorem but the professor told me that my approach was completely unnecessary, Source: Book Optimization by Vector Space Methods (Luenberger). Ch3, prob 21.","['functional-analysis', 'optimization', 'hilbert-spaces']"
2486706,How do I show that formal logarithm is the inverse of the formal exponential?,"Let $A$ be a unital commutative and associative $\mathbb{Q}$-algebra. Define $exp(f):=\sum_{n=0}^\infty \frac{f^n}{n!}$ for each $f\in XA[[X]]$. Define $log(f):=\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n} (f-1)^n$ for each $f\in 1+XA[[X]]$. Hence, we have two maps $exp:XA[[X]]\rightarrow 1+XA[[X]]$ and $log:1+XA[[X]]\rightarrow XA[[X]]$. I am trying to prove that $log$ map is the inverse of the $exp$ map. The first thing I tried is to directly show $log\circ exp=id$ and $exp\circ log = id$ by checking if the identities hold for every element $f$, but this does not work well since this way involves too many calculations. For example, $$[X^n]exp(log(f))=[X^n]\sum_{k=0}^n log(f)^k/k! = \sum_{k=0}^n \frac{1}{k!} [X^n]log(f)^k= \sum_{k=0}^n \frac{1}{k!} [X^n](\sum_{l=1}^k \frac{(-1)^{l+1}}{l} (f-1)^l)^k$$. Thus, we have to show that $$\sum_{k=0}^n \frac{1}{k!} [X^n](\sum_{l=1}^k \frac{(-1)^{l+1}}{l} (f-1)^l)^k=[X^n]f$$. But this calculation is really a nightmare.. Is there a clever way to show this? If not, how do I wisely calculate to show the above identity? Thank you in advance.","['abstract-algebra', 'formal-power-series', 'combinatorics', 'discrete-mathematics']"
2486718,"What is the name of this theorem of Jakob Steiner's, and why is it true?","In The Secrets of Triangles a remarkable theorem is attributed to Jakob Steiner. Each side of a triangle is cut into two segments by an altitude. Build squares on each of those segments, and the alternating squares sum to each other. The book doesn't include a proof, and I'm not sure how to start. Does this theorem have a name? How could one go about proving this beautiful relationship?","['euclidean-geometry', 'triangles', 'geometry']"
2486726,"Condition on $X$ in $(0,1)$ with $m=E(X)$ for $\lim\limits_{t\to1}(1-t)E\left[\frac{(X-m)^2}{(m+t(X-m))^2}\right]$ to exist and be finite","Let $X \in (0,1)$ be a continuous random variable.   What would be a sufficient conditions on $X$ such that \begin{align}
\lim_{t \to 1}\ (1-t)\, \mathbb E \left[  \frac{(X-\mathbb E[X])^2}{ \left(\mathbb E[X]+t(X-\mathbb E[X]) \right)^2}\right]
\end{align}
  is finite. I tried the monotone convergence theorem but it does not seem to apply. I also spent some time thinking about how to apply dominated convergence theorem.  However, I am not sure how to bound $$(1-t) \frac{(X-\mathbb E[X])^2}{ \left(\mathbb E[X]+t(X-\mathbb E[X]) \right)^2}$$
I have ploted the function
\begin{align}
f(t)= (1-t)\frac{(a-b)^2}{(b+t(a-b))^2}
\end{align} for $a \in (0,1)$ and $b \in (0,1)$ and it seems to be bounded.  However, not sure how to find and exact bound.","['probability-theory', 'expectation']"
2486802,Difference between $y = x^{1/2}$ & $y = x^{2/4}$,"The other day something occurred to me when graphing $y = x^{1/2}$. I understand that this is equivalent to $y = \sqrt{x}$ & this can't have negative values for $x$. But is it not also equivalent to $y = x^{2/4}$
which in turn is $y = \sqrt[4]{x^2}$ which would allow negative values for $x$? I know the easy answer here is to say you should simplify $\frac24$ first but is there a deeper mathematical explanation for what looks to me to be a bit of a paradox?","['functions', 'graphing-functions']"
2486808,Expected number of heads in n coin tosses,"What is the expected number of heads in n coin tosses, where the probability of landing one head is p? I know that the probability of having k heads in n tosses is
$$\ \binom{n}{k}p^k(1-p)^{n-k}$$ So, the expected number of heads in n tosses is
$$\sum_{k=0}^n k\binom{n}{k}p^k(1-p)^{n-k}$$ But I'm not sure how to simplify this further. Any help would be appreciated!","['expectation', 'probability']"
2486845,$(\sqrt{10}+3)^{2010}$,"What are the first 100 digits of $(\sqrt{10}+3)^{2010}$ after the decimal point? I used a calculator to figure out $(\sqrt{10}+3)^{2}$ up to of $(\sqrt{10}+3)^{6}$ and they all have increasing numbers of nines after the decimal point. Does that pattern continue, and if so, why?",['number-theory']
2486879,Number of Tetrahedrons in a Cube,I am trying to find out Number of Tetrahedrons in a unit cube My Try: Total ways to choose four vertices if $\binom{8}{4}=70$ From this we have to remove $1.$ All $6$ faces $2.$ $6$ Quadrilaterals formed by face Diagonals $3.$ $2$ Concave Quadrilaterals formed by Body Diagonals Hence Total tetrahedrons is $70-6-6-2=56$ Is this fine?,"['solid-geometry', 'combinatorics', '3d', 'geometry']"
2486894,Condition number of a diagonal matrix,"Let $\|\cdot\|$ be any norm on $\mathbb{C}^n$. Let $A\in \mathbb{C}^{n\times n}$ We define the matrix norm by $||A||=\max_{||x||=1}||Ax||$. If $A=diag(\lambda_1,...,\lambda_n)$ and it is invertible, then do we always have $$||A||\cdot||A^{-1}||=\frac{\max_i|\lambda_i|}{\min_i|\lambda_i|}?$$","['matrices', 'normed-spaces', 'linear-algebra', 'condition-number']"
2486908,Irreducible outer automorphism and pseudo-Anosov homeomorphisms,"In Bestvina and Handel's paper on train track maps , they state that a pseudo-Anosov map on a punctured surface with one orbit of punctures induces an irreducible automorphism, which is not fully irreducible if there's more than one puncture (Example 1.4 on Page 6). They don't give a proof of this and I haven't been able to find a proof (nor a sketch of one) anywhere. Suppose $p:\Sigma \to \Sigma$ was the homeomorphism, $\phi = [p_*]$ was the induced outer automorphism in $Out(F_n) \cong Out(\pi_1(\Sigma))$, and $f:\Gamma \to \Gamma$ was map of graphs that was a reduction for $\phi$, i.e., $\phi = [f_*]$ in $Out(F_n) \cong Out(\pi_1(\Gamma))$ and it has a non-contractible invariant proper subgraph. How am I supposed to relate $\Sigma$ and $\Gamma$ to get a contradiction? The two are homotopy equivalent but there's no reason for $\Gamma \to \Sigma$ to be an embedding.","['low-dimensional-topology', 'group-theory', 'free-groups']"
2486920,Number of solutions of $\sin (2x)+\cos (2x)+\sin x+\cos x=1$,Find Number of solutions of $\sin (2x)+\cos (2x)+\sin x+\cos x=1$ in $\left [0 \:\: 2\pi\right]$ The equation can be written as: $$\sin (2x)+1-2 \sin^2x+\sin x+\cos x=1$$ $\implies$ $$\sin x+\cos x=2\sin^2 x-2 \sin x\cos x$$ $\implies$ $$\sin x+\cos x=2\sin x\left(\sin x-\cos x\right)$$ $\implies$ $$\frac{\sin x+\cos x}{\sin x-\cos x}=2\sin x$$ $\implies$ $$\frac{1+\tan x}{1-\tan x}=-2\sin x$$ $$\tan \left(\frac{\pi}{4}+x\right)=-2\sin x$$ Now i have drawn the graphs of  $\tan \left(\frac{\pi}{4}+x\right)$ and $-2\sin x$ and observed there are two solutions. is there any other way?,"['algebra-precalculus', 'trigonometry', 'calculus']"
2486922,Integration on manifold using the flow of a vector field,"In a Physics paper the author states without proof something that seemed quite strange to me. The paper is on General Relativity, so he assumes a Lorentzian manifold $(M,g)$ is given. His hypothesis are: Suppose $f$ is a continuous scalar function on $M$ whose support $W$ extends to past and future infinity but which is bounded in spacelike directions, and take $L$, parametrized as $\gamma(s)$ by the proper time $s$ along it, to be a timelike worldline representing an observer. We shall now take $\Sigma(s)$ to be an arbitrary spacelike hypersurface through $\gamma(s)$ which depends continuously on $s$. Then if $w^\alpha$ is a vector field such that displacement of every point by $w^\alpha ds$ maps $\Sigma(s)$ into $\Sigma(s+ds)$ for each $s$, we have
  $$\langle f,\phi\rangle=\int ds \int_{\Sigma(s)} f\phi \sqrt{-g}w^\alpha n_\alpha d\Sigma,$$
  for all compactly supported $\phi\in C^\infty_0(M)$ being $n^\alpha$ the normal to $\Sigma(s)$. I believe that it all boils down to this: given a one-parameter family of spacelike hypersurfaces $\Sigma(s)$, and a vector field $W$ such that its flow satisfies $\Phi^X_\delta(\Sigma(s))=\Sigma(s+\delta)$, we have $$\int_M f(x) d^nx=\int ds \int_{\Sigma(s)} f \sqrt{-g} W^\alpha n_\alpha d\Sigma.$$ I might be wrong though, and it might only work with $\phi$ and with the hypothesis on the support of $f$. The thing is: how this is proven? Actually, if $\phi : (-\epsilon,\epsilon)\times M\to M$ is the flow of $W$ so that $\phi_t : M\to M$ is the diffeomorphism moving points a parameter value $t$ on the integral curves, we can consider the set $$A = \{\phi(s,p) \in M :s\in (-\epsilon,\epsilon),p\in \Sigma(s)\}$$ Then if $\varphi : U\subset \mathbb{R}^{n-1}\to \Sigma(s)$ is a parametrization of the hypersurface, we shall have a parametrization $\psi : (-\epsilon,\epsilon)\times U\to A$ given by $$\psi(s,q)=\phi(s,\varphi(q)).$$ Let $(y^\alpha)$ a coordinate system on $(-\epsilon,\epsilon)\times U\subset \mathbb{R}^n$ and $(x^\mu)$ a coordinate system on $M$ Now pick $f\in C^\infty_0(M)$, the $n$-form $f\epsilon$ has compact support, where $\epsilon$ is the Lorentzian volume form. But if $h : M\to \mathbb{R}$ is $h = \sqrt{|g|}$ what we want is to integrate $\omega = fh dx^0\wedge\cdots \wedge dx^{n-1}$. But by a theorem on Spivak DG Vol. 1 (7.7) we have $$\psi^\ast \omega=(fh\circ\psi) \det\left(\dfrac{\partial(x^\mu \circ \psi)}{\partial y^\alpha}\right) dy^0\wedge \cdots dy^{n-1}$$ The issue now is to compute that determinant. I concluded (not much rigorously really) that $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^0}=W^\mu\circ \psi$$ While for the other I computed not rigorously also that $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^i}=\dfrac{\partial(x^\mu\circ \phi)}{\partial x^\nu}\dfrac{\partial (x^\nu\circ \varphi)}{\partial y^i}$$ The first seems to be the Jacobian of the flow of $W$, the second seems to be the components of $\varphi_\ast e_i$ so the basis of the tangent spaces of $\Sigma$ induced by the basis of $\mathbb{R}^{n-1}$. If I'm not mistaken this is the same as $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^i}=\phi_{\ast}(\varphi_\ast e_i)=(\phi\circ\varphi)_\ast e_i$$ So the first column of the matrix are the components of $W$ and the $i$-th column are the components of the $i$-th basis vector of $\mathbb{R}^n$ pushed to $M$ throguh $(\phi\circ\varphi)$ - the parametrization followed by the flow. Now I think that the normal covector $n$ is $$n = \star (\phi\circ\varphi)_\ast e_1\wedge \cdots \wedge (\phi\circ\varphi)_\ast e_{n-1}$$ The matrix above has $W$ in one column and these vectors on the others. Computing the determinant with the Levi-Civita symbol $\varepsilon_{\mu_1\dots\mu_n}$ gives $$\det(J)=\varepsilon_{\mu_1\dots \mu_n} W^{\mu_1} (\phi\circ\varphi)_\ast e_1^{\mu_2}\cdots e_{n-1}^{\mu_n}$$ But then combining with the factor $h\circ \psi$ we factored will turn the Levi Civita symbol to $\epsilon_{\mu_1\cdots\mu_n}$ which in turn gives the Hodge dual $$\psi^\ast \epsilon = (f \epsilon_{\mu_1\cdots \mu_n}\circ \psi W^{\mu_1})\circ \psi(\phi\circ\varphi)_\ast e_1^{\mu_2}\cdots(\phi\circ\varphi)_\ast e_{n-1}^{\mu_n} dy^0\wedge \cdots \wedge dy^{n-1}= (fW^\mu n_\mu)\circ \psi dy^0\wedge\cdots \wedge dy^{n-1} $$ I just don't know if this is right. Is my approach correct?","['semi-riemannian-geometry', 'riemannian-geometry', 'general-relativity', 'integration', 'differential-geometry']"
2486970,Let $f\colon \mathbb R\to\mathbb R$ be a continuous function such that $f(i) = 0$,"Let $f\colon \mathbb R\to\mathbb R$ be a continuous function such that $f(i) = 0$, for all $i\in \mathbb Z$ . Which of the following statement is true$?$ $(A)$ $\operatorname{Image}(f)$ is closed in $\mathbb R$. $(B)$ $\operatorname{Image}(f)$ is open in $\mathbb R$. $(C)$ $f$ is uniformly continuous. $(D)$ None of the above. If we take $f(x) = 0$, for all $x\in \mathbb R$, then $\operatorname{Image}(f)$ is a singleton set. Also we know that every singleton set is closed in $\mathbb R$. So option $B$  is wrong. For option $(C)$, I take $f\colon \mathbb R\to\mathbb R$ such that $f(x) = x \sin\pi x $, this function $f$ is not uniformly continuous. So option $C$ is also wrong. Now my problem is that the answer of this question is option $D$ but i am not able to get any function to discard option $A$. So please help me. Thanks you.","['continuity', 'uniform-continuity', 'real-analysis', 'functions']"
2487001,Estimate a series,"I'm stuck on a step in a proof. Does there exist a constant $C$ such that $\sum_{l=0}^{\infty} [1+(t+lb)^2]^{-\alpha}\leq Ct^{-2\alpha}$ uniformly in $t>0$, where $ b>0, \alpha >1$ are fixed.","['real-analysis', 'sequences-and-series', 'analysis']"
2487022,"""Reversed"" Caratheodory Condition?","My homework says to prove that if $\mu^*$ is an outer measure on a set $X$, and $\mathcal{M}$ is the set of of $\mu^*$-measurable subsets, then $(X\mathcal{M},\mu^*)$ is a complete measure space. The definition given for ""$\mu^*$-measurable"" is as follows: A set $E\subset X$ is said to be $\mu^*$-measurable if for any set $A\subset X$, $\mu^*(E) = \mu^*(E\cap A) + \mu^*(E\cap A^c)$. The definition I have seen before is: A set $A\subset X$ is said to be $\mu^*$-measurable if for any set $E\subset X$, $\mu^*(E) = \mu^*(E\cap A) + \mu^*(E\cap A^c)$. Are these equivalent conditions?",['measure-theory']
2487035,Can we find a function that satisfies these conditions?,"Let $$
f (x)  := \begin{cases} 
\lceil{x}\rceil  &\mbox{for } x \le 1 \\[8pt]
\lceil{2x}\rceil-1 &  \mbox{for } x > 1 
\end{cases}
$$
be a function and $n$ be a positive integer number. We are given a set of positive real numbers $A = \{a_1, \dots, a_n\}$. We want to find an $\varepsilon > 0$ and a function $g (x)$ such that $$
\begin{cases} 
g(a_i) \le a_i  &\mbox{$\forall a_i \in A$ } \\
f(g(a_i)) = f(a_i) &  \mbox{$\forall a_i \in A$}\\
f(g(a_i) - \varepsilon) < f (g(a_i)) &  \mbox{$\forall a_i\in A$}
\end{cases}
$$ By trial and error, I ended up with $$
g(a_i)  = \begin{cases} 
a_i-1+\varepsilon  &\mbox{For $a_i \in A$ and integer} \\
\lfloor{a_i}\rfloor + \varepsilon &  \mbox{For $a_i \in A$ and not integer}.
\end{cases}
$$
in which $\varepsilon$ could be any positive real number such that $$
\varepsilon \le \frac{ \displaystyle\min_{i=1,\dots,n} \{a_i - \lfloor {a_i}\rfloor \colon a_i - \lfloor {a_i}\rfloor > 0 \} }{2}
$$
Unfortunately it does not necessarily satisfy the second condition. So what do you think? Is there a function $g(x)$ that satisfies those conditions? Edit: I want to show that we can always find an $\varepsilon  \to 0$ for any given set $A$. Basically, I am looking for an upper bound for $\varepsilon$ which is less than one. As is mentioned in one of the answers, for $\varepsilon > 1$ we can simply take $g(a_i)=a_i$ and $\varepsilon = 2$.","['real-analysis', 'functions']"
2487059,What's the kurtosis of exponential distribution?,"Original question (with confused terms): Wikipedia and Wolfram Math World claim that the kurtosis of exponential distribution is equal to $6$. Whenever I calculate the kurtosis in math software (or manually) I get $9$, so I am slightly confused. I calculate 4th central moment as: $$
D^4X = \int_0^\infty (x-\lambda^{-1})^4 \lambda e^{-\lambda x} \, dx\,.
$$ And kurtosis as: $$
K = \frac{D^4X}{(D^2X)^2}
$$ Is the approach and result correct (kurtosis equal to $9$)? I trust that the calculation of this very specific integral I shown is correct. Comment: I didn't know ' kurtosis ' and ' excess kurtosis ' are different terms. Thank you all for your help.","['exponential-distribution', 'statistics', 'probability-distributions']"
2487079,Integral between max and 2nd max closing up over time?,"Suppose you repeatedly sample from continuous distribution F with convex support Let's say you drew 2 4 3 5 in order. Denote the biggest number at $t$th sampling by $b(t)$, second biggest number at  $t$th sampling by $a(t)$ So we have $a(4)=4$ $b(4)=5$ My question is whether $$A=\int_{a(t)}^{b(t)}dF(x)$$ will be decreasing, at least in expectation sense, over time. Again, we repeatedly sample from continuous distribution F with convex support. Intuitively, this must be true. Just imagine uniform distribution, then the distance between $b(t)$ and $a(t)$ will likely shrink. But I can't seem to prove mathematically. In fact, I don't even know how to mathematically express the concept of ""second biggest"". How should I even proceed? ============================================== My tentative approach is as follows. If  $b(t+1)>b(t)$, then $a(t+1)=b(t)$ $$A(1)=\int_{}^{b(1)}dF(x)$$
$$A(2)=\int_{b(1)}^{b(2)}dF(x)=F(b(2))-F(b(1))$$  if $b(2)>b(1)$
$$A(t)=\int_{a(t)}^{b(t)}dF(x)$$
$$A(t+1)=\int_{b(t)}^{b(t+1)}dF(x)=F(b(t+1))-F(b(t))$$","['statistics', 'integration', 'sampling', 'sampling-theory']"
2487116,"Does the ""prime ant"" ever backtrack?","A few mathematical questions have come up from the question "" The prime ant ðŸœ "" on the Programming Puzzles & Code Golf Stack Exchange. Here is how the prime ant is defined: Initially, we have an infinite array A containing all the integers >= 2 : [2,3,4,5,6,.. ] Let p be the position of the ant on the array. Initially, p = 0 (array is 0-indexed) Each turn, the ant will move as follows: if A[p] is prime, the ant moves to the next position : p â† p+1 else, if A[p] is a composite number, let q be its smaller divisor > 1. We divide A[p] by q , and we add q to A[p-1] . The ant moves to the previous position: p â† p-1 Here are the first moves for the ant: 2  3  4  5  6  7  8  9  ... 
 ^
 2  3  4  5  6  7  8  9  ... 
    ^
 2  3  4  5  6  7  8  9  ... 
       ^
 2  5  2  5  6  7  8  9  ... 
    ^
 2  5  2  5  6  7  8  9  ... 
       ^
 2  5  2  5  6  7  8  9  ... 
          ^
 2  5  2  5  6  7  8  9  ... 
             ^
 2  5  2  7  3  7  8  9  ... 
          ^ Questions relate to proving the sequence is well-defined: I wonder whether the sequence is well-defined for arbitrarily large n (or whether the composite case could ever push the ant to the left of the initial 2). â€“ Martin Enderâ™¦ Oct 9 at 6:59 Whether all prime values appear: @MartinEnder Another open question is whether a prime > 7 can eventually be left behind for good. â€“ Arnauld Oct 9 at 10:39 And what the asymptotic growth looks like: @Arnauld I'm curious how the ant's position grows with respect to the number of moves. My guess is logarithmic. â€“ kamoroso94 Oct 9 at 12:58 I have added this sequence to the On-Line Encylopedia of Integer Sequences (OEIS) as sequence A293689 . Here's what the plot of the first 10000 terms looks like:","['random-walk', 'combinatorics', 'oeis', 'asymptotics']"
2487175,Evaluating $\frac{-1}{\frac{-1}{\frac{-1}{\dots}}}$,"I was attempting to evaluate the following infinite fraction: $$\frac{-1}{\frac{-1}{\frac{-1}{\dots}}}$$ So I let $x=\frac{-1}{\frac{-1}{\frac{-1}{\dots}}}$, thus $x=\frac{-1}{x}$ and we arrive at $x^2=-1$, so $x=\pm i$. Is this correct?",['sequences-and-series']
2487196,Linear approximation of hyperbola vs of circle?,"I was trying to do a linear approximation using hyperbolic trig functions and comparing that with a linear approximation to a circle at any given angle $a$. So I found that for the unit circle: $$f(x)=-\cot(a)(x-\cos(a)) + \sin(a)$$ But for a hyperbola $x^2-y^2=1$:
$$g(x)=\coth(a)(x-\cosh(a)) + \sinh(a)$$ If my equations are correct, Iâ€™m wondering why theyâ€™re the only difference between the two is the negative term before cotangent in the circle linearization but no negative term in the hyperbola linearization. Any ideas as to why this is?","['hyperbolic-functions', 'linear-approximation', 'trigonometry', 'calculus']"
2487214,How to calculate the limit $\lim_{x \to 1} \frac{x + x^2 +\cdots+ x^n - n}{x - 1}$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How can I find the limit of the following function: $$\begin{equation*}
\lim_{x \to 1}
\frac{x + x^2 +\cdots+ x^n - n}{x - 1}
\end{equation*}$$ Any help will be appreciated.
Thanks!","['functions', 'limits']"
2487309,How long can this sequence be?,"The positive integers $a,b$ with $a>1$ and the prime $n$ is given. Define the sequence $u$ with the recurrence relation : $u_1=n$ , $u_{j+1}=a\cdot u_j+b$ for all $j\ge 1$. The sequence terminates as soon as the next term is composite. For example , with $n=587, a=3,b=16$ , the sequence has length $11$ because $u_{12}$ is composite. Can this sequence be arbitary long ? If no, what is the maximal possible length ?","['number-theory', 'recurrence-relations', 'prime-numbers']"
2487373,Non measurable vector subspace of a Banach space,"My question is the following: Let $(E,\Vert\cdot\Vert_E)$ be a real Banach space, $\mathcal{B}(E)$ its Borel sigma algebra (i.e. the sigma algebra containing all open balls). Is it possible for a vector subspace $V$ of $E$ to be non-measurable? In particular, is it possible in the case $E$ is separable? The question arises from this particular case: let $A:D(A)\to F$ be a closed operator, where $(F,\Vert\cdot\Vert_F)$ is another Banach space and $D(A)$ is a vector subspace of $E$. Let $X$ be an $E$-valued random variable (from a standard probability space) such that $X$ belongs to $D(A)$ $\mathbb{P}$-almost surely. Is it true that $AX$ is an $F$-valued random variable? In the case I impose $D(A)$ to be measurable, I can prove it without difficulties. So the (more specific than the one above) question is: does a closed operator $A$ defined on a non measurable domain $D(A)$ exist? In the case the space $F$ is reflexive, I'm able to show that $D(A)$ must be measurable by expressing it as a countable union of closed sets, but I have no idea how to approach the problem without any assumption on $F$. UPDATE I'm trying to construct a counterxample using the following space: $$E=\bigg\{ f:[0,1]\to\mathbb{R} \text{ such that } \sum_{x\in [0,1]} f(x)^2<\infty\bigg\}$$ where the sum (of nonnegative elements) over a non countable set in defined in the following way: $$\sum_{x\in [0,1]} a_x = \sup\bigg\{ \sum_{i\in I} a_i : I\subset [0,1] \text{ finite} \bigg\}$$ In the case the elements can have both positive and negative sign but $\sum_{x\in [01]}\vert a_x\vert <\infty$, then the sum $\sum_{x\in [0,1]} a_x$ is defined by taking positive and negative parts respectively. This definition of sum has the nice property that if $\sum_{x\in [0,1]} \vert a_x\vert<\infty$, then there can be at most a countable amount of points $x$ such that $a_x\neq0$. Now $E$ is a vector space that can be normed with
$$ \Vert f\Vert_E = \sqrt{\sum_{x\in [0,1]} f(x)^2}$$
which is induced by the scalar product
$$\langle f,g\rangle = \sum_{x\in [0,1]} f(x)g(x)$$
It can be shown that $E$ is a Banach (and therefore Hilbert) space; it is not separable, since the family $\{e_x : x\in [0,1]\}$ ($e_x$ denotes the function that sents $x$ to $1$ and everything else to $0$) is an uncountable, $1$-separated family. Moreover $\{e_x : x\in [0,1]\}$ is an orthonormal basis of $E$ (in the sense that is a family of orthonormal elements such that any $f\in E$ can be arbitrarily approximated by finite linear combinations of it). I think $E$ is a good place where to search for a counterexample since it's nice enough to work with it but at the same time a bit strange (it contains infinite copies of the $l^2$ space). In order to show that a subspace is not measurable, I should show that it is the image through a measurable map of a non measurable set from another measurable space. My candidate for the non measurable subspace was something like
$$ V = span\{ e_x : x\in A\}$$
where $A$ is a Vitali set (or any other non measurable subset of [0,1]). So what I'd like is a measurable map $T:(\mathbb{R},\mathcal{B}(\mathbb{R}))\to (E,\mathcal{B}(E))$ (actually $T$ does not need to start from $\mathbb{R}$ but I guess that's the space one would work with) such that the image of a non measurable subset through $T$ is $V$. However I haven't find anything so far. Any ideas? Any help would be much appreciated!","['operator-theory', 'banach-spaces', 'measure-theory', 'vector-spaces']"
2487440,Restriction of Line Bundles on Surfaces,"Suppose I have a smooth projective surface $S$, and irreducible curves $C,C'$ in $S$. I was wondering if:
$$\mathcal{O}_S(C)|_{C'}\cong \mathcal{O}_{C'}(C\cap C') $$
It would make sense, as on $C'$, $C\cap C'$ are points so a divisor on a curve and reflects my geometric intuition. The problem is that I don't know well how to deal with restrictions; my only way was to work locally. Thanks in advance!","['vector-bundles', 'sheaf-theory', 'divisors-algebraic-geometry', 'algebraic-geometry']"
2487450,How to calculate the autocorrelation of a markov chain?,"i want to know how to calculate the autocorrelation of a markov chain (e.g for a simple random walk ). while i was searching online; i found a lecture with a two states {-1,1} markov chain with the following transition matrix  \begin{bmatrix}\alpha&1-\alpha\\1-\alpha&\alpha\end{bmatrix} 
the lag-d autocorrelation was given as: $( 2\alpha-1)^d $. i was wandering how they got this answer? I was wandering how to calculate the autocorrelation in general for simple markov chains, or at least for just this simple example","['random-walk', 'markov-chains', 'statistics', 'correlation']"
2487452,Motivation behind proof,"The following problem is taken from IMC $2017$ Day $1$, August $2, 2017$. Let $f:\mathbb{R}\to(0,\infty)$ be a differentiable function, and suppose that there exists a constant $L>0$ such that 
  $$|f'(x)-f'(y)|\leq L|x-y|$$
  for all $x,y.$
  Prove that 
  $$(f'(x))^2<2Lf(x)$$
  holds for all $x.$ The official solution goes as follows: Solution: Notice that $f'$ satisfies the Lipschitz-property, so $f'$ is continuous and therefore locally integrable. Consider an arbitrary $x\in\mathbb{R}$ and let $d=f'(x).$
  We need to prove $f(x)>\frac{d^2}{2L}.$ If $d=0,$ then the statement is trivial. If $d>0,$ then the condition provides $f'(x-t) \geq d-Lt;$ this estimate is positive for $1\leq t <\frac{d}{L}.$
  By integrating over that interval, 
  $$f(x)>f(x)-f(x-\frac{d}{L})=\int_0^{\frac{d}{L}}f'(x-t) \,dt \geq \int_0^{\frac{d}{L}}(d-Lt)\,dt=\frac{d^2}{2L}.$$
  If $d<0,$ then apply $f'(x+t)\leq d+Lt=-|d|+Lt$ and repeat the same argument as 
  $$f(x)>f(x)-f(x+\frac{|d|}{L}) = \int_0^{\frac{|d|}{L}}(-f'(x+t))\,dt \geq \int_0^{\frac{|d|}{L}}(|d|-Lt)\, dt = \frac{d^2}{2L}.$$ Question: What is a motivation behind the proof above? Yes, I can fully understand the solution if I read line by line. However, I attempted the problem myself for 1 hour and could not get anywhere. It would be good if someone can tell me a motivation of considering the proof above. It is okay if you want to provide an alternative solution to the problem. An alternative solution will give us another way of thinking the problem.","['contest-math', 'real-analysis', 'proof-explanation']"
2487470,Avoiding numerical cancellation question for $\sin x -\sin y$ for $x \approx y$,"When trying to avoid cancellation, one tries to reformulate the equation in order to avoid subtraction between almost equal terms. In $\sin (x) - \sin (y), x \approx y$ the suggested solution is to reformulate it to $$2\cos\left(\frac{x+y}{2}\right)\sin\left(\frac{x-y}{2}\right)$$ But I don't understand how it is any better? The subtraction between $x, y$ remains. Is it because $\lvert\,\sin(x)-\sin(y)\,\rvert\leq \lvert\,x-y\,\rvert$, so cancellation is less likely to happen between $x,y$ than the sines?","['numerical-methods', 'catastrophic-cancellation', 'trigonometry']"
2487492,Elegant proof of combinatorial statement: at least $l-k+1$ children who were in larger teams,"There are $n$ children, who play a game where in round $1$ they spilt up in $k$ teams (every team non-empty, pairwise disjoint). After a while it gets boring, so they form new teams to play round $2$; this time, they split up in $l$ teams (every team non-empty, pairwise disjoint), where $l>k$, and this beeing the only condition. Prove that there are at least $l-k+1$ children, for which their team in the first round was of strictly larger size than in the second round. This was a homework problem in a course last year which I had a very hard time proving, and finally, a day before the deadline, I found a proof which was three pages long and used a pretty messy induction with a whole lot of definitions and notations I had to introduce (it took me the whole day to write). Is there an elegant proof of this statement? If you want to see my proof, comment below and I will try to summarize it. But I guarantee you, its very messy! :)","['combinatorics', 'discrete-mathematics']"
2487500,How can I visualise groups in Group Theory?,"I'm having a hard time grasping groups in Group Theory. Is it okay to visualise them as being sets with the group axioms and a binary operation, intuitively as a Venn diagram? Also, $(G,*)$ and $G$ without $*$ is really confusing me. I can't seem to move on in my study of Group Theory because of this. Can anyone also recommend me any online sources for a clear understanding of groups, please? What are some applications of groups? How can I apply them and see them to better understand their purpose. I feel really anxious whenever I open my textbook on Group Theory and it's because of these answers that I'm missing. I've looked through countless books and online notes. Everything is seems too complex and doesn't sit in my mind. I would love to study this subject more effectively. I had this problem while studying Set Theory and I need another approach for Group Theory. Thank you!","['abelian-groups', 'reference-request', 'group-theory', 'binary-operations']"
2487512,Bezout's Theorem for curves,"I'm stuck with an exercise which implies the strong version of the Bezout's theorem. $\textbf{Statement}:$ Let $C_1[x,y,z], C_2[x,y,z]$ be the two algebraic curves on $CP^2$ of degrees $m,n$ respectively. Let $A$ be the common point of the two curves such that the degree of $A$ for $C_1$ is $r$ and for $C_2$ it is $s$. Show that the corresponding to $A$ solution of
$$
\mathrm{Res}(C_1,C_2)[y,z] = 0
$$
has the degree $s\cdot r$. This exercise proves the Bezout's theorem almost directly. Since the resultant equation is of order $mn$ then the number of common points is exactly $mn$ counting the multiplicities (by the homogeneity of $\mathrm{Res}$ and fundamental thm. of algebra) . And the aforementioned exercise shows that the multiplicity of the root in the resultant is actually the product of multiplicities of the root $A$ for $C_1,C_2$. The problem is that the multiplicity of a point for an algebraic curve is defined through reduction of the equation of the curve on the lines and looking for the order of the root for this one-dimensional polynom.So reducting the resultant on some lines gives big formulas in which I cannot see what is the order of the corresponding root.","['algebraic-curves', 'algebraic-geometry']"
2487526,Does the identity $\cos^2(x)+\sin^2(x)=1$ hold in a unital Banach algebra where $1$ is the unit?,"Let's assume that we have an unital Banach algebra $T$ and we define sine and cosine using the normal power series definition as for $\mathbb{R}$.
Let $x \in T$ and let $1$ be the unit of $T$. Does the Pythagorean trigonometric identity $\cos^2(x)+\sin^2(x)=1$ still hold?","['functional-analysis', 'trigonometry', 'operator-theory', 'analysis']"
2487527,Injection/Surjection between sets of functions,"Consider three non-empty sets $A$, $B$ and $C$ and a function $ f_1:A \rightarrow B$. Further consider the following definitions $f_2:A^Câ†’B^C : x \mapsto fâˆ˜x$ and
$ f_3 : C^B \rightarrow C^A: yâ†¦yâˆ˜f $. It can be proven: 
(a) that if $f_1$ is injective then $f_2$ is injective and $f_3$ is surjective and (b)  that if $f_1$ is surjective then $f_2$ is surjective and $f_3$ is injective. Question: I usually have no problems with proving functions are surjective or injective
or with function compositions but I am a little bit lost of what exactly the definitions are stating. Because ""sets of all functions (e.g. from $C$ to $A$ etc.) are involved and because x and y appear on both sides of the functions definitions I am a little bit lost of what is being mapped to what here. I reread the definitions many times but I still lack an intutitive picture
of the mapping chain. If somebody could enlighten me with a small intuitive description or maybe 
a small graphical sketch of what is being mapped to what so I can understand the problem a little bit better before I start proving. 
Thank you.","['elementary-set-theory', 'functions']"
2487544,Verify that two or more functions are linearly independent on an interval,"If we want to verify that 1 and x are linearly independent on the interval [0,1]  , can we solve it as following ? let
 $$c_1 +c_2  x=0$$
at x=0 
$$c_1=0$$
at x=1 
$$c_2=0$$
So 1 and x are linearly independent on the interval [0,1] This is how my teacher solved it but I am not convinced because I think it is not sufficient to try two values of x only ! 
I know that we can prove that 1 and x are independent using Wronskian . My problem is : can we use the method of  $$c_1 y_1(x) + c_2 y_2(x) =0$$ to prove that two functions are independent on an interval by trying only 2 values of x and getting that all constants are zero ?! are two values of x sufficient ?! why ?! and must we try the values at beginning and end of the interval ?","['ordinary-differential-equations', 'determinant']"
2487572,How to find the sum in a series when the common difference is alternated?,"The problem is as follows: Find the sum of the first 16 terms in:
  $$1,3,9,11,17,19,...$$ So far I was only able to find that the common difference between the terms goes from $2,6,2,6,...$ however in the second difference the sign is alternated $4,-4,4,...$ therefore making it impossible to use a second degree polynomial to create a recursion formula. What is the method that should be used to find the sum and the formula for the terms?. Edit: Is it possible to obtain a recursion formula which can be used for the whole sequence?.","['algebra-precalculus', 'sequences-and-series']"
2487612,What is the physical meaning of an integral?,"The derivative $\frac{dy}{dx}$ of a function $y=f(x)$ tells us how has the function $y=f(x)$ changes with the change in $x$ at the point $(x,y)$. What is the physical meaning of the integral of the function $y=f(x)$ i.e., $I(a,b)=\int\limits_{a}^{b} f(x)dx$ except the fact that it represents the area under the curve bounded by $x=a$, $x=b$ and $y=f(x)$? To be specific the work done under a force, in one-dimension, is given by $\int F(x)dx$. Why should it be called a continuous sum? How does the area interpretation work out if the function being integrated is a function of several variables?","['physics', 'integration', 'calculus']"
2487620,Prove: if $f:G\to H$ isomorphism there is $k:H \to G$ isomorphism,"Prove: if $f:G\to H$ isomorphism there is $k:H \to G$ isomorphism Isomorphism is an homomorphism which is $1-1$ and onto. $f$ is homomorphism: $\forall g_1,g_2\in G$ there are $h_1,h_2\in H$ s.t  $f(g_1\cdot g_2)=f(g_1)*f(g_2)$ 2.1-1: $f(g_1)=f(g_2)\rightarrow g_1=g_2$ onto: for all $h\in H$ there is $g\in G$ s.t $f(g)=h$ $f$ is 1-1 and onto so there is $f^{-1}$ 1-1 and onto. looking at$$g_1\cdot g_2=_{(1)}f^{-1}\large{[f(g_1\cdot g_2)]=f^{-1}[f(g_1)*f(g_2)]}=_{(2)}f^{-1}[h_1*h_2]$$ where $(1)$ $f$ is $inverse$ $(2)$ $f$ is $inverse$ and in particular onto. So $k=f^{-1}$ is isomorphism Is it valid? sorry for my wording","['group-theory', 'proof-verification']"
2487622,Solution to second order non constant differential equation without first derivative,"Cheers! So I am studying the book â€˜Introduction to quantum mechanicsâ€™ by David J. Griffiths for my introductory course of quantum mechanics. On page 51 at the bottom it introduces the differential expression:
\begin{equation}
\Phiâ€™â€™ = \xi^2 \Phi
\end{equation}
Without saying much further, it presents the general solution as:
\begin{equation}
\Phi = A e^{-\xi^2/2} + B e^{\xi^2/2}
\end{equation}
Indeed, when I check this solution with the differential equation, I can see that it can match it. However I am still completely missing on how one would arrive from the differential equation to the general solution. I have already been trying several different methods, all unsuccessful, so I would indeed appreciate any help I could get.",['ordinary-differential-equations']
2487644,Strengthening of the Jordan curve theorem,"The Jordan curve theorem tells us that a continuous loop in the plane with no self-intersection points divides the plane into two connected components, the interior, which is bounded, and exterior, which is unbounded, and both components have that curve as a boundary. Since both components are open because they are connected they are also path-connected. But still, that does not seem enough to me. Because interior cannot have holes (or it can if my intuition is wrong) we should be able to say that interior is at least simply connected . This is probably proven relatively long time ago, or it can be proven (if true) with some combination of known results from analysis and topology, but since my knowledge is poor in those areas I am not sure what results to combine effectively so as to arrive at this conclusion. So, how to prove that? Or, where to find a proof?","['algebraic-topology', 'general-topology', 'path-connected', 'connectedness']"
2487646,A differentiable function intersecting every vertical plane $y = \lambda x$ must be linear,"This question is from a midterm that I just took and wasn't able to solve. If someone could provide a sketch for a solution that would be really helpful, also currently I'm studying analysis by Munkres, could someone suggest books that would help me be better prepared for the next midterm. Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$, such that f(x,y) = z is differentiable and intersects every vertical plane $y = \lambda x$ in a straight line. 
Show that f is a linear function $f = ax + by + c$. Can the differentiabilty condition be reduced to just continuity? Thank you","['derivatives', 'real-analysis', 'continuity']"
2487701,Replacing expectation by Lp norm,"It is known that for a Lipschitz function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ that if $X \sim \mathcal{N}(0,I_n)$ then
$$
\| f(X) - \mathbb{E}f(X)\|_{\psi_2} \leq C \|f\|_{Lip}
$$
where $\| \|_{\psi_2}$ refers to the subgaussian norm (i.e. the smallest constant $C$ such that $\mathbb{E} \exp(X^2/C^2) \leq 2$).  Is it possible to replace the $\mathbb{E}f(X)$ by $(\mathbb{E} f(X)^3)^{1/3}$ and still get a concentration inequality of the same form. I have no problem replacing the expectation by the median as it is well known that the expectation and median are close for subgaussian random variables.  I would like to prove the same phenomenon for Lp norms.","['normed-spaces', 'probability-theory', 'expected-value', 'functional-analysis', 'lipschitz-functions']"
2487727,how to comput the number of equivalence relation in a finite set?,"Example: 
Let $A =\{1,2,3\}$ and $S =\{(1,1)(2,2)(3,3)(1,2)(1,3)(3,1)(1,3)(2,3)(3,2)\}$
$S$ is an equivalence relation on $A$, and it has $9$ order pairs in it. Which is the square of element in $A(3^2=9)$ Let $A=\{1,2,3,4\}$, and $S=\{(1,1)(2,2)(3,3)(1,2)(1,3)(3,1)(1,3)(2,3)(3,2)(1,4)(4,1)(2,4)(4,2)(3,4)(4,3)(4,4)\}$
$S$ is an equivalence relation on $A$, and it has $4^2=16$ order pairs in it. By this pattern, if $A=\{1,2,3,4,5,6,7,8,9,10\}$ then there should be $10^2$ equivalence relations in $S$. Question:
If $A$ is a set of natural numbers $\{1,2,3.....,n\}$ then how many equivalence relation $S$ have on $A$? By the above example I know there are going to be $n^2$ equivalence relations, but I just donâ€™t know how to prove it. I was wondering if anyone can give me a hint.","['equivalence-relations', 'elementary-set-theory', 'discrete-mathematics']"
2487738,Find all real square matrix $A$ which $A=\operatorname{adj}(A)$,"Find all real square matrix $A$ which $$A=\operatorname{adj}(A)$$ My thoughts: We have the well-known equation $$ A\operatorname{adj}(A)=\operatorname{det}(A)I_n$$ Since $A=\operatorname{adj}(A)$, it comes to $$ A^2=\operatorname{det}(A)I_n$$ So, if $\operatorname{det}(A)=0$, then $A^2=O$. if $\operatorname{det}(A)\neq0$, then we get (if $n\neq2$)  $$(\operatorname{det}(A))^2=(\operatorname{det}(A))^n$$ $$ \operatorname{det}(A)=\pm1$$ $$ A^2=\pm I_n$$
In this case, $A$ seems like a involutory matrix. How to characterize the matrics mentioned above? Or what further properties should $A$ follows so we can completely characterize $A$? Thanks for your help!","['matrices', 'linear-algebra']"
2487774,Relation of trace and determinant,"Let $A$ be a $3\times3$ non-diagonal matrix with $A=A^{-1}$ . Prove that $\det A = \operatorname{tr} A =\pm1$ I have already proved $\det A = \pm1$ , but I have no idea about how to proceed with $\operatorname{tr} A$ . Thank you.","['matrices', 'determinant', 'proof-writing', 'trace', 'linear-algebra']"
2487811,Why are prime numbers so common?,"Why are primes so common? I have trouble rationalizing that even when you get into the range of millions and billions, you still see primes appear just a few hundred numbers apart. I would think the probability of primes appearing once you get to very large numbers would be extremely low, considering the amount of possible whole number divisors for a whole number n is equal to n - 2 , not counting 1 and the number itself. It seems odd to me that primes appear so closely even in the billions. I mean, there are billions of possible numbers to divide from and you're telling me none of them divide evenly at all? It would make sense for this event to occur once every say million numbers, but every hundred just seems very close to me. I don't study mathematics. This thought has just been lingering in my head for a while, and I would like to hear someone who knows what they are talking about explain to me why primes appear so closely. And please explain it in a way that makes sense to someone who isn't familiar with higher level mathematical terminology, or explain advanced terminology if you must use it. Thank you!","['number-theory', 'prime-numbers']"
2487816,Number of square submatrices of a matrix and occurrence of each value in the new submatrices,"We are given a n x m matrix. I have to find the total number of square sub-matrices possible of the given matrix. For e.g., 3 x 3 matrix is given as follows: 1 2 3
4 5 6
7 8 9 All possible square submatrices are: 1 x 1: |1|, |2|, |3|, |4|, |5|, |6|, |7|, |8|, |9| = Total = 9
2 x 2: |1 2|  |1 2|  |4 5|  |1 3|  |1 3|  |4 6|  |2 3|  |2 3|  |5 6|
       |4 5|, |7 8|, |7 8|, |4 6|, |7 9|, |7 9|, |5 6|, |8 9|, |8 9| = Total = 9
3 x 3: |1 2 3|
       |4 5 6|
       |7 8 9| = Total = 1 I referred this question . But the formula there gives me total of only matrices which can be formed by consecutive rows and columns. And I have to calculate all the dimensions separately. For 3 x 2 matrix: 1 2
3 4
5 6

1 x 1: 6 possible.
2 x 2: |1 2|  |1 2|  |3 4|
       |3 4|, |5 6|, |5 6| = 3 possible We can't get a 3 x 3 matrix for above, so we take min(n, m) and only produce square matrix with min value. Similarly for (2 x 3) matrix, (2 x 4) matrix and so on. And if we see the total number of occurrences of each value in the matrix of 3 x 3 is 6. Means in the above given example the total number of occurrences of 1 is 6 times and similarly all other numbers appear exactly 6 times. And for 3 x 2 
matrix each number appears 3 times in the submatrices. For a 2 x 2 matrix each value occurs exactly 2 times. Question: (1) Total number of square submatrices which can be formed from a given n x m matrix. (2) Total number of occurrences of each value of a matrix in the new square submatrices made. Here, 1 <= n, m <= 1000000000 . Value of n and m may be same and may not be same. EDIT 1: As suggested by the community members, I referred this question too, but the answer given there also ignores skipping of rows and columns while forming new submatrices. From given 3 x 3 matrix, they are: |1 2|  |2 3|  |1 3|  |4 6|  |1 3|
                                   |7 8|, |8 9|, |4 6|, |7 9|, |7 9| The formula given there gives answer as 14 but it is 19. It doesn't take into account this given matrices.","['matrices', 'combinatorics', 'random-matrices', 'discrete-mathematics']"
2487832,Crisis in my understanding of probability [duplicate],"This question already has answers here : Why is not the answer to all probability questions 1/2. (6 answers) Closed 6 years ago . If I were to roll a die, what would â€‹be the probability of getting $2$? Certainly it would be $\dfrac 16$ (because there are $6$ numbers and sample space contains 6 numbers)
 But I think we can look at it another way. 
We need $2$ right? and from $1-6$ there is only one number which is $2$ i.e. $2$. If I were to roll there would essentially be two types of numbers ie. one which is $2$ and one which is not ie $1,3,4,5,6$. So there are two basic outcomes.
P(E) = number $2$Ã·total outcomes ie $2$.
P(E)= $\dfrac 12$
So why is the probability $\dfrac 16$(when it is clear that the outcome we desire, can either happen or not happen.) Shouldn't the probability be $\dfrac 12$ instead, why not?","['terminology', 'probability-theory', 'probability', 'paradoxes']"
2487841,Product of vector bundles.,"If $\pi_1:E_1\to M$ and $\pi_2:E_2\to M$ are two vector bundles over $M$, then we can construct a new vector bundle $E_1\oplus E_2$ by declaring the fibre at each $x\in M$ to be $(E_1\oplus E_2)_x:=(E_1)_x\oplus(E_2)_x$. One usually calls this (to my knowledge) the Whitney sum of $E_1$ and $E_2$. One could denote this by $E_1\times E_2$, but this seems rather unnecessary. My question: if I encounter the notation $E_1\times E_2$, could any other vector bundle than the Whitney sum bundle be meant? The question popped up when considering Dirac structures on a manifold $M$, and the considering two Dirac structures on $M$ and their product $L_1\times L_2$.","['terminology', 'poisson-geometry', 'vector-bundles', 'differential-geometry']"
2487845,$x(p âˆ’ x)y(p âˆ’ y)$ is square implies $x = y$,"Given a prime $p > 2$ and positive integers $x,y \le \frac{p âˆ’ 1}{2}$, prove that if $x(p âˆ’ x)y(p âˆ’ y)$ is a perfect square, then $x = y$. This question was previously asked without context , and so was closed, but I did start towards a solution. The primary insight is that the result depends on the unique representation of a prime as a sum of squares . Obviously if that were not true we could have $m_0^2+n_0^2=m_1^2+n_1^2=p$. Then we could choose $x=m_0^2$ and $y=m_1^2$ as the lesser parts of those two different representations and with all contributing values being square, get a square that disproves the claim. The other strand of proof that I did not succeed in completing was to eliminate the possibility that the various components might multiply together to give a square. Here are my thoughts on this so far: Since $p$ prime, $x$ is coprime to $v:=(p-x)$ and $y$ is coprime to $w:=(p-y)$. Find $g :=\gcd(x,y)$ and $h:=\gcd(v,w)$, and set $(a,b,c,d):=(x/g,y/g,v/h,w/h)$. If one of these terms is $1$ then all are, and $x=y$. Assume that we have $a,b,c,d>1$. Then the expression of interest is $abcdg^2h^2$, which is square iff $abcd$ is square. The only possible common factors are in the pairs $(a,d)$ and $(b,c)$ so we would need $ad$ square and $bc$ square. Can anyone either complete my proof or find a better way to demonstrate the truth of the opening claim?","['number-theory', 'elementary-number-theory']"
2487877,Can we determine an oblique asymptote of a function by the limit of $f'(x)$?,"Some references show that to find an oblique asymptote of a function $f(x)$ , we must see the limit of $$ m = \lim_{x \rightarrow \pm \infty} \frac{f(x)}{x} $$ If $m \ne 0$ and finite, then there is an oblique asymptote of the form $y = mx + c$ .
However, I think it would be more intuitive by searching the limit of $$ \lim_{x \rightarrow \pm \infty} f'(x) $$ If this limit exists, then we can determine the asymptote. Question : Am I correct if I generalize the 2nd one for finding an oblique asymptote? I have not seen any reference to use the second one (limit of $f'$ ) for finding an oblique asymptote. But it is more intuituive .., and we can also see from the first one that $\lim \limits_{x \rightarrow \pm \infty} \frac fx  $ has an indefinite form $\frac{\infty}{\infty} $ , then by L'Hopital it can be equal to $\lim f'(x)$ . Thanks in advance.","['derivatives', 'asymptotics', 'calculus', 'functions', 'terminology']"
2487889,Solve this limit using equivalent infinitesimals,"I am given the following limit, which I'm asked to solve. $$L=\lim_{x\to 0}\dfrac{2(\tan x-\sin x)-x^3}{x^5}$$ I get confused with equivalent infinitesimals most of the time. I know the correct answer to this limit is $\boxed{1/4}$. However, this is what I did: $$\left.
\begin{array}{l}
&\sin x \approx x\\
&\tan x \approx x
\end{array}
\right\}
\Rightarrow L=-\lim_{x \to 0} \dfrac{x^3}{x^5}=-\lim_{x \to 0} \dfrac{1}{x^2}=\boxed{-\infty}$$ I know this problem can indeed be solved by taking 3 terms in the MacLaurin Series of each function (i.e. for both the sine and tangent functions). But sometimes this is not always necessary. Sometimes it's sufficient to take the first non-zero term in its MacLaurin Series. But as far as I was taught in school, the equivalent infinitesimal is defined as the first non-zero term in the MacLaurin Series of a function. How many terms should I grab to go safe for every case? Why doesn't it suffice to take just the 1st non-zero term?","['terminology', 'taylor-expansion', 'calculus', 'limits']"
2487944,the maximum value of a function $f(x)=ax^2+bx+c$ is $10$. Given that $f(3)=f(-1)=2$ find $f(2)$,"could you please help solving this? The maximum value of $f(x)=ax^2+bx+c$ is $10$. Given that $f(3)=f(-1)=2$ find $f(2)$ I've realized that $f(1)$ is the middle between two of those which will be the vertex, however, how do I proceed from that? Question was asked a month ago, however, not answered properly","['algebra-precalculus', 'polynomials', 'quadratics']"
2487980,Finding mean value of a distribution so that the probabilty of an interval equals 0.5,"So, I have an exercise I can't solve that goes like this: ""Professor Y always adjusts its students' grades by adding a fixed value c to each grade so that 50% of the students get a grade between 70 and 80. If the grades follow a normal distribution with an expected value of 65 and a variance  of 38, what value of c should be added? There are two possible values, choose the one which benefits the students the most."" This is what I've managed to do so far: Adding a value c to all grades corresponds to shifting the mean value of the distribution to the right. Let X be the variable which represents the students' grades, modeled by a normal distribution N(65,38). We want to know the value of c such that: P(a < X < a + 10) = 0.5 <=> P(X < a + 10) - P(X < a) = 0.5 c = 70 - a a (and by consequence c) can take two values because we can easily see graphically that there are two posssible intervals, symmetric to each other about the mean which are a solution to the problem. The preferred value for a is the smaller one, so that c can be larger, which causes a greater change on the grades. I stopped here because I couldn't find a way to solve the two equations and get the values of c and a. Any help is highly appreciated.","['statistics', 'probability', 'normal-distribution', 'random-variables']"
2488004,Inequality AM/HM <= (AM/GM)^n with packing problem interpretation,"I have stumbled upon the following inequality while exploring ""Hoffman's packing problem"", which I'm pretty convinced is true, but unable to prove. Let $n \geq 2$ be a natural number and let $x_1, \dots, x_n$ be positive real numbers. How do I prove that:
$$
\frac{AM}{HM} \leq \left(\frac{AM}{GM}\right)^n,
$$
where the harmonic mean $HM$, geometric mean $GM$ and arithmetic mean $AM$ are defined as:
$$
HM = \frac{n}{\sum_{i=1}^{n}{\frac{1}{x_i}}}, \quad
GM = \sqrt[n]{\prod_{i=1}^{n}{x_i}} \quad
\text{and} \quad
AM = \frac{1}{n}\sum_{i=1}^{n}{x_i}.
$$ What I know so far We have equality if $n=2$ or if $x_1 = \dots = x_n$. I haven't been able to prove the inequality in general, but for $n=3$ (let's use $x_1,x_2,x_3 = a,b,c$ for clarity) we obtain:
$$
\frac{\frac{a+b+c}{3}}{\frac{3}{\frac{1}{a}+\frac{1}{b}+\frac{1}{c}}}
\leq
\left(\frac{\frac{a+b+c}{3}}{\sqrt[n]{abc}}\right)^3
\Leftrightarrow\\
\frac{(a+b+c) \cdot (bc + ac + ab)}{9abc} \leq \frac{(a+b+c)^3}{27abc}
\Leftrightarrow\\
3(bc + ac + ab) \leq (a+b+c)^2 \quad (*)
\Leftrightarrow\\
0 \leq a^2 + b^2 + c^2 - bc - ac - ab
\Leftrightarrow\\
0 \leq 2a^2 + 2b^2 + 2c^2 - 2bc - 2ac - 2ab
\Leftrightarrow\\
0 \leq (a - b)^2 + (b - c)^2 + (c - a)^2,
$$
which is clearly true. Interpretation as packing problem The inequality can be interpreted as an $n-1$ dimensional packing problem. For instance if $n=3$ the inequality can be rearranged as $3(bc + ac + ab) \leq (a+b+c)^2$, see (*) above. We can look at this like fitting three $a \times b$, three $b \times c$ and three $c \times a$ rectangles inside a square with side-length $a+b+c$. Here is an example of a packing: Caption: Suppose $a < b < c$. This is a packing of 3 red $a \times b$, 3 blue $b \times c$ and 3 green $c \times a$ rectangles inside a square with side-length $a+b+c$.","['puzzle', 'inequality', 'packing-problem', 'calculus']"
2488036,Convergence of densities vs. other modes of convergence for random variables,"While I was summarizing the relations between different modes of convergence for random variables, I got stuck at the convergence of the densities...
My question: $X_n \to X$ a.s. (or in $L_1$/ in probability) $\quad
 \overset{?}{\Rightarrow} \quad f_{X_n} \to f_X$ a.e. (or in any other
  sense) where $X,X_n: (\Omega,\mathcal{F},P)\to (\mathbb{R},\mathcal{B}(\mathbb{R}))$ measurable, with laws $\mu_{X_n},\mu_X << \lambda$ [Lebesgue measure] (in order to admit density functions $f_{X_n}, f_X$  on $\mathbb{R}$)","['weak-convergence', 'probability-theory', 'convergence-divergence', 'density-function']"
2488097,"Prove that if both $a$ and $b$ divided by $n$ give remainder 1, then $ab$ divided by $n$ gives remainder 1.","Here's is my approach: $a=q_1n+1$ $b=q_2n+1$ $ab = q_1q_2n^2+q_1n+q_2n+1=(q_1q_2n+q_1+q_2)n+1$ I'm not sure if this is sufficient, and if so, whether there's a better proof.",['discrete-mathematics']
2488144,"Show that for a $âˆˆ G, Na âˆˆ G/N$, order(Na) is a factor of order(a).","Let $(G, Â·$) be a group and $N$ be a normal subgroup and $G/N$ be
the corresponding quotient. Show that for a $âˆˆ G, Na âˆˆ G/N$ order(Na) is a factor of order(a). I am really confused about how to proceed with this. I understand that it is asking me to prove that the order of an element in the quotient group divides the order of an element in a group that it is the quotient group of, but I am unsure of how to proceed. Here is what I have so far: Assume that $ord(a) = m $ $(Na)^m = N(a^m) = N(e) = Ne = N$ But i am not really sure where I can take this with the work above. Any help would be appreciated!","['abstract-algebra', 'group-theory']"
2488149,Why $\limsup_n E(|X_n|^r)<\infty$ as a criteria for tightness?,"Let $X_n$ have as a distribution function $F_n$. Let's assume that exists an $r>0$ such that $\limsup_n E(|X_n|^r)<\infty$. Why does it imply that $\{F_n\}$ is tight? My try: $\limsup_n E(|X_n|^r)<\infty \implies \forall_n \forall_{\epsilon>0}\exists_{\lambda_{\epsilon,n} >0} P(|X_n|\geq\lambda_{\epsilon,n})\leq \frac{E(|X_n|^r)}{\lambda_{\epsilon,n}^r}=\epsilon$ (by Markov inequality). This means that for all $\epsilon>0$, exists a finite interval $I$ such that $F_n(I^c)\leq \epsilon$ for all $F_n$. Resnick's textbook is one text giving this criteria. But why do we have the $\limsup$? why not just $\forall_n E|X_n|^r<\infty$? Any help would be appreciated.","['probability-theory', 'measure-theory']"
2488181,If $\mathfrak{so}(3)$ is the Lie algebra of $SO(3)$ then why are the matrices of $\mathfrak{so}(3)$ not rotation matrices?,"If $\mathfrak{so}(3)$ is the Lie algebra of $SO(3)$ then why are the matrices of $\mathfrak{so}(3)$ not rotation matrices? They aren't infinitesimal rotations either.
The matrices of $\mathfrak{so}(3)$ are skew-symmetric matrices which are the type used to calculate the cross product. How can $\mathfrak{so}(3)$ be tangent to $SO(3)$ if they're never even in $SO(3)$?","['matrices', 'lie-algebras', 'lie-groups']"
2488218,How to calculate the surface area of a cube given a diagonal?,"I encountered this problem while practicing for a mathematics competition. A cube has a diagonal length of 10. What is the surface area of the cube? No Calculators Allowed. (Emphasis mine) I'm not even sure where to start with this, so I scribbled down some numbers and solved for a square instead of a cube. Presumably, you can calculate the diagonal of a cube using the Pythagoras Theorem somehow, though I'm not sure how.","['solid-geometry', 'geometry']"
2488300,Descartes number,"In 1638 Descartes wrote a letter to Mersenne where he talks about how the number $$D=3^2â‹…7^2â‹…11^2â‹…13^2â‹…22021$$ would be an odd perfect number if we mistakingly assume that $22021$ is prime. My question is, do we know what method Descartes used when he found his number and does anyone know where I can find a copy of the letter that he sent to Mersenne in November of 1638? I've tried several searches online, and at our local academic library, but have had no luck. Any help would be greatly appreciated!","['number-theory', 'perfect-numbers', 'math-history']"
2488309,$f$ is Continuous if and only if its Graph is Closed in $X \times Y$,"Let $f: X \to Y$ ; let $Y$ be compact Hausdorff. Then $f$ is continuous if and only if $G_f = \{(x,f(x)) \mid x \in X \}$ is closed. Here is my shot at a proof: Suppose that $f : X \to Y$ is continuous, and let $(x,y) \in \overline{G_f}$ but assume $y \neq f(x)$ . As $Y$ is Hausdorff, there exists $U,V$ open in $Y$ and disjoint such that $y \in U$ and $f(x) \in V$ . Since $V$ is a nbhd of $f(x)$ and $f$ is continuous, there exists an $O \subseteq X$ that is open and contains $x$ such that $f(O) \subseteq V$ . Since $O \times U$ is an open nbhd of $(x,y)$ , there must be some $(p,q) \in G_f \cap O \times U$ . This means $p \in O$ and that $f(p)=q \in U$ . But $f(O) \subseteq V$ , so $U$ and $V$ must intersect--a contradiction. Hence $y= f(x)$ and $G_f$ must be closed. Now we show the other direction. Suppose that $G_f$ is closed, let $x \in X$ be arbitrary, and let $V$ be a open nhbd of $f(x)$ . Then $Y-V$ is closed, and therefore the intersection $C:=G_f \cap [X \times (Y-V)]$ is closed in $X \times Y$ . By an earlier problem, we know that $\pi_1$ is a closed map and so $\pi_1(C)$ is closed in $X$ , and therefore $X-\pi_1(C)$ is open. I will argue that $x \in X-\pi_1(C)$ by contradiction. If $x$ were in $\pi_1(C)$ , then there would exist a $p \in X$ and a $q \in Y-V$ such that $f(p)=q$ and $x= \pi_1(p,f(p))$ or $x=p$ . But this would mean $f(x)=q \in Y-V$ or $f(x) \notin V$ , which contradicts the assumption that $V$ is a nbhd of $f(x)$ . Hence $x \in X - \pi_1(C)$ . Now we argue that $a \in f^{-1}(V)$ if and only if $a \notin a \notin \pi_1(C)$ . Suppose that $a \in \pi_1(C)$ . Then $a = \pi(p,f(p))$ or $a=p$ where $f(p) \in Y-V$ . This means that $f(a) \in Y - V$ and therefore $a \notin f^{-1}(V)$ . Now suppose that $a \notin f^{-1}(V)$ . Then $f(a) \notin V$ and therefore $f(a) \in Y-V$ . From this we get $(a,f(a)) \in G_f \cap [X \times (Y-V)] = C$ which implies $a \in \pi_1(C)$ . From this we can conclude that if $a \in X-\pi_1(C)$ , then $f(a) \in V$ , proving that $f(X-\pi_1(C)) \subseteq V$ which in turn proves that $f$ is continuous. How does this sound?",['general-topology']
2488398,"Show that if $f$ is increasing on $[a, b]$ and satisfies the intermediate value property, then $f$ is continuous on $[a, b]$","I know this question has been asked before but I feel like my approach to solving the problem is ""different"" (EDIT: turned out to be different because it's wrong!) Since $[a,b]$ is closed and bounded we may conclude that, by the Heini-Borel theorem, $[a, b]$ must be compact. By definition of compactness, every sequence in $[a,b]$ must contain a subsequence that converges to a limit that is also in $[a,b]$ . Consider any arbitrary increasing subsequence $\{x_n\}$ inside $[a,b]$ . By the definition of compactness, we know that there exist some $c \in [a,b]$ such that $\{x_n\} \rightarrow c$ . Since $f$ satisfies the intermediate value property, we know that $f(c)$ exists and is within the range of $f$ . One of the ""characterizations of continuity"" states that: ""For all $\{x_n\} \rightarrow c$ , it follows that $f(x_n) â†’ f(c).$ "". How do I show that $f(x_n)$ converges to $f(c)$ ? Thing is, I know that $f(x_n)$ has to converge to something since the range of $f$ is a compact set ( $[f(a), f(b)]$ )â€¦ I'm just trying to show that $f(x_n) \rightarrow f(c)$ ! Any idea of how I can go about this?",['real-analysis']
2488412,Choosing a Lyapunov Function for a Nonlinear system (Cubics),"I am working on being able to recognize appropriate Lyapunov functions to show the stability (or instability) of equilibrium points. I have the following system: $\begin{pmatrix}
\dot{x} \\ \dot{y}
\end{pmatrix} =
\begin{pmatrix}
0 & 1 \\ -1 & -2
\end{pmatrix}\begin{pmatrix}
x \\ y
\end{pmatrix} + \begin{pmatrix}
-x^3 \\ 2x^3
\end{pmatrix}$ with the equilibrium point $\bar{x}=(0,0)$. I wish to prove that $\bar{x}$ is asymptotically stable via an appropriate Lyapunov function. I started with $V(x,y) = x^4 + y^4$ but I was not sure how to show that $\dot{V} < 0$. Does anyone have any ideas? Should I use a different Lyapunov function?","['stability-in-odes', 'ordinary-differential-equations', 'stability-theory']"
2488420,Does there exist a infinite dimensional Banach subspace in every normed space?,"We know that every normed space contains a separable subspace. Let $X$ a normed space. Suppose that Hamel's basis of $X$ is uncountable, $X$ isn't a reflexive and Banach space (see below). Does there exist an infinite dimensional Banach subspace $B$ of $X$? Remark: If $X$ is Banach take any infinite dimensional closed subspace in $X$,  and we have done. (Let $(x_{n})_{n}$  linearly independent  sequence, so  $S=\overline{ \langle (x_{n})_{n} \rangle}$ is a closed subspace in $X$, then $S$ is a Banach subspace of $X$). We have to show the question when $X$ isn't a Banach space. In particular, if $X$ isn't Banach, then $X$ isn't reflexive. (Suppose $X$ isn't Banach. If $X$ is reflexive , $J(X)=X''$, and $X''$ is Banach, then $X$ is Banach.) We have to show the question when $X$ isn't a reflexive and Banach space. If $X$ is normed space with Hamel's basis countable then $X$ can't have a subspace that is Banach in $X$. In fact, let $S$ a Banach subspace of $X$, then Hamel's basis of $S$ is uncountable, but Hamel's basis of $X$ is countable. An example of normed space with countable basis: ""Consider $c_{00}$, the space of the sequences $x=(x_{n})$ of real numbers which have only finitely many non-zero elements, with the norm $ \|x\|=\sup _{n}|x_{n}|$ . Its standard basis, consisting of the sequences having only one non-zero element, which is equal to 1, is a countable Hamel basis."" ( https://en.wikipedia.org/wiki/Basis_(linear_algebra) ) We have to show the question when Hamel's basis of $X$ is uncountable, and $X$ isn't a reflexive and Banach space.","['functional-analysis', 'normed-spaces', 'banach-spaces']"
2488432,If a surface $S$ admits two differentiable orthogonal families of geodesics $\Rightarrow$ The Gaussian curvature of $S$ is zero.,"This question was previously posted in Orthogonal differentiable family of curves . But I'm facing unsolved issues. I'm still interested in solve the following exercise: QUESTION: We say that a set of regular curves on a surface $S$ is a differentiable family of curves on $S$ if the tangent lines to the curves of the set make up a differentiable field of directions. Assume that a surface $S$ admits two differentiable orthogonal families of geodesics. Prove that the Gaussian curvature of $S$ is zero. where a differentiable field of directions is: Definition: A field of direction $r$ in a open $U \cap S$ is a correspondence which assigns to each $p$ $\in$ $U\cap S$ a line $r(p)$ in $T_pS$ passing through $p$ . $r$ is said to be diferentiable at $p$ $\in$ $U \cap S$ if there exists a nonzero differentiable vector field $w$ , defined in a neighborhood $V\cap S$ $\subset$ $U \cap S$ of $p$ , such that for each $q$ $\in$ $V\cap S$ , $w(q) \neq 0$ is a basis of $r(q)$ ; $r$ is diferentiable in $U\cap S$ if it is differentiable for every $p$ $\in$ $U$ . At the end of the book, Manfredo give us the following hint Manfredo's Hint : Parametrize a neighborhood of $p\in S$ in such a way that the two families of geodesics are coordinate curves (Corollary 1, Sec. 3-4). Show that this implies that $F=0$ , $E_v=0, $ $G_u = 0$ . Make a change of parameters to obtain that $\bar{F} = 0$ , $\bar{E} = \bar{G} =1$ . where Corollary 1, Sec.3-4 is: Corollary 1. (Sec.3-4): Given two fields of directions $r$ and $r'$ in an open set $U \subset S$ such that at $p$ $\in$ $U$ , $r(p) \neq r'(p)$ , there exists a parametrization $x$ in a neighborhood of $p$ such that the coordinate curves of $x$ are the integral curves of $r$ and $r'$ . And now my problem appears. Let $\tau_1$ be the field of directions associated to the first family, and $\tau_2$ be the field of directions associated to the second family (note that $\tau_1$ and $\tau_2$ are orthogonal). I really don't understand why when we apply the Corollary 1 (Sec. 3-4), on the fields of directions $\tau_1$ and $\tau_2$ , we end up getting a chart $x: U \subset \mathbb{R}^2 \rightarrow W \cap S$ , in such a way that the coordinate curves, $x(u, c^{te})$ and $x(c^{te},v)$ , are the two families of geodesics. From what I know, when the coordinate curves are the integral curves of 
 fields of directions $\tau_1$ and $\tau_2$ , we can only conclude that $x_u(u, c^{te})$ is l.d with the direction $\tau_1(x(u, c^{te}))$ and $x_v(c^{te},v)$ is l.d. with the direction $\tau_2(x(c^{te}, v))$ . GI can't see any reason for these coordinate curves to solve the geodesic's differential equation. In the best case scenario I was only able to conclude that the coordinate curves have the same path of a geodesic (which implies nothing). Does anyone know how I outline this problem and solve the exercise?","['curvature', 'geometry', 'differential-geometry', 'surfaces', 'geodesic']"
2488452,Switching Iterated Integrals from dxdy to dydx,"I am having issues switching an iterated integral from dxdy to dydx : Switch the integral $\int_0^2 \int_y^{2y}6xy$ dx dy to a dy dx integral in the form of $\int_0^2 \int_{...}^{...}6xydydx$ + $\int_2^4 \int_{...}^{...}6xydydx$ What I'm having issues with here is trying to break it up into pieces-- is the first one just from 0 to y, and the next one from y to 2y?","['multivariable-calculus', 'integration', 'calculus']"
2488460,Sum-of-squares quartic polynomials in three variables,"Suppose $f \in \mathbb R [x,y,z]$ is a homogeneous polynomial of degree $4$. Furthermore, suppose we can write $$f(x,y,z)=\sum_i p_i(x,y,z)^2$$ where each $p_i$ is a homogeneous polynomial of degree $2$. My question: Is there any ""clean"" intuition for the set of degree-$4$ $f$'s that can be written this way? For example, if restriction $f$ to the unit sphere, do its maxima or minima have any relationships to one another?  How do we distinguish this set from the full set of degree-$4$ homogeneous polynomials? I know this question is vague.  I'm trying to get an intuition for the ""sum of squares"" (SOS) condition in this case.","['real-algebraic-geometry', 'polynomials', 'algebraic-geometry', 'sum-of-squares-method', 'ideals']"
2488531,The average of $X_iX_j (i\neq j) $ goes to $\mathbb E(X)^2$ in probability,"Suppose $(X_n)_n\geq 1$ are i.i.d. $\mathbb E(X)=\mu$, $\sigma^2= \operatorname{Var}(X)<\infty$. I want to show  $$\frac 1 {n(n-1)} \sum_{1\,\leq\, i,j\,\leq\, n,\,\, i\,\neq\, j} X_iX_j\to \mu^2$$ in probability. Here is what I tried. Applying Strong law of large number we have $$\frac 1 {n^2} \left( \sum_{1\leq i\leq n} X_i\right)^2\to \mu^2$$ in probability. For all $\epsilon>0$, $\mathbb P(|1/n^2(\sum_{1\leq i\leq n} X_i)^2-\mu^2|\geq\epsilon)\to 0 $. Expand this we have  $\mathbb P(|(\sum_{1\leq i,j\leq n, i\neq j} X_iX_j-n(n-1)\mu^2+\sum_{1\leq i\leq n}X_i^2-n\mu^2|\geq n^2\epsilon)\to 0 $. I don't know how to proceed from here. In particular , I'm wondering how to use Var$(X)<\infty$.",['probability']
2488563,Prove the implication: $k$ is odd implies $k^n$ is odd,"So far, I have my base case where  $ k = 2n+1 $ and $k^n \equiv (2n+1)^n$. Plugging in $1$ for $n$ gives me $3$, which is odd so the base case is true. Now for the inductive hypothesis: Assume $P(n)$ is true I want to prove the implication $P(n)\implies P(n+1)$ via contraposition. So I would assume it is not the case $k^n$ is odd, so I assume $k^n$ is even. I would then rewrite $k^n=2l$ as it is equivalent to multiple of integer $l$. I'm confused where to go from here though, so if someone can help me figure this out I would greatly appreciate it. Thank you!","['induction', 'proof-explanation', 'discrete-mathematics']"
2488621,"Rolling a die, probability of the sum","I need help with a particular problem in my statistics textbook. Imagine rolling a normal die with six sides $100$ times.
I need to find the probability that the sum of the values rolled in those $100$ times is less than $300$ . So for the sum, we want to look at the random variable $Y=X_1+X_2+...+X_{100}$ . Every $X_i$ should have the same mean and variance, let's say the mean is $\mu$ and the variance is $\sigma^2$ . Then the mean of $Y$ would be $100\mu$ and the variance is $100\sigma^2$ . We want to find $P(Y<300)$ . Using a continuity correction, we want to look at $P(Y<300.5)$ .
Then $P(Y<300.5)=P\left({Z<\dfrac{300.5-100\mu}{\sqrt{100 \sigma^2}}}\right)$ . I could find the answer from here. However, I am having a hard time figuring out what $\mu$ and $\sigma^2$ should equal. I know that $\mu=np$ and $\sigma^2=np(1-p)$ for a normal approximation. But I don't know what $n$ and $p$ would be for the $X_1, X_2, ..., X_{100}$ or if that is the correct way to go about this problem. Any help is appreciated, thank you.","['normal-distribution', 'probability-distributions', 'statistics', 'probability', 'dice']"
2488625,"What does the phrase ""Lusin-type"" mean?","This might be a English question rather than a mathematical question, however I was wondering what the phrase ""Lusin-type"" refers to. I have seen a lot of theorems so-called ""Lusin-type theorem"" or ""quantitative Lusin-type theorem"". However I am not in the field of measure theory, I only know the Lusin's theorem, informally saying that ""every measurable function is nearly continuous"". I feel the phrase ""Lusin-type"" means, except on a set of small measure, some property holds almost everywhere on the rest of domain.","['terminology', 'sobolev-spaces', 'measure-theory', 'partial-differential-equations']"
2488660,How to check if its finite,"For $X \sim Pois(\lambda)$, find $E(2^X)$ if it is finite. I know how to solve this (we use Law of Unconscious Statistician) but am doubtful as to how we specify the condition for which it is finite. Can someone tell me how we find the condition?","['generating-functions', 'probability']"
2488691,Prove a compact Hausdorff space with a group structure is a topological group,"Here is an exercise from the textbook of topology by Armstrong. Let $G$ be a compact Hausdorff space which has the structure of a group. Show that $G$ is a topological group if the multiplication function $m:G\times G \rightarrow G$ is continuous. I tried to use the conditions to prove the inverse function is also continuous, but I couldn't find out how to connect the inverse with the multiplication... Any help will be appreciated.","['general-topology', 'topological-groups']"
2488726,Determining an inner automorphism via queries,"Let $G$ be a group. You are given that $\phi$ is some inner automorphism of $G$, i.e, $\phi(x) = axa^{-1}$ for some $a \in G$ uniquely determined modulo the center of the group. You're not sure what $a$ is, but you have a machine that can magically compute $\phi(x)$ on individual values of $x$. Is there a good algorithm/procedure for figuring out what $a$ is (modulo the center) by making queries to this machine? I'd really be interested in answers for any structures with notions of inner automorphisms. An application which interests me is the following: Suppose $\phi$ is some automorphism of a central simple algebra over a field which I have some nice description for which makes it easy to compute. By the Skolem-Noether Theorem, I know $\phi$ is actually inner. Can I figure out what element $\phi$ conjugates by?","['algorithms', 'group-theory', 'automorphism-group']"
2488728,Find $k$ such that $f(k)$ is Minimum,Find $k$ such that $$f(k)=\int_{0}^{4} |4x-x^2-k|dx$$ is Minimum I splitted the Modulus in to two cases: $1.$   if   $4x-x^2-k \ge 0$ Then $$f(k)=\int_{0}^{4} (4x-x^2-k)dx=\frac{32}{3}-4k$$ $2.$ if   $4x-x^2-k \lt 0$  Then $$f(k)=4k-\frac{32}{3}$$ But How to minimize $f(k)$ which is linear in $k$?,"['algebra-precalculus', 'integration', 'definite-integrals', 'functions']"
2488732,Epsilon-Delta proof for a limit of a function,"$\lim\limits_{x \to 2} \frac{x^2+4}{x+2}=2$ I understand the structure of the epsilon delta proof, but I need help with the scratchwork/setup. Using |$\frac{x^2+4}{x+2}-2$| $<\epsilon$ , you can factor and you're left with |$x-4$|$< \epsilon$. What I'm stuck on is solving for $x-a$ or $x-2$. Can I do something with the Triangle Inequality to say |$x-2-2$| $\le$ |$x-2$|$ \;+\; 2$ $< \epsilon$ Any help would be appreciated!","['epsilon-delta', 'real-analysis', 'analysis', 'limits']"
2488739,Equivalence between two definitions of compactifications of an elliptic curve,"Suppose we have the curve $y^2=h(x)=x(x-1)(x-2)$ in $\mathbb{C}^2$. Then this is clearly not compact and I saw two definitions for compactifying this and I want to prove that they are equivalent. Method $1$ : Consider the homogenization of the curve given by $y^2z=x(x-z)(x-2z)$. Now just take the zero set in $\mathbb{C}P^2$. Now this is compact since it is a closed subset of a compact set. Method 2 : This is the method I saw in the book ""Algebraic curves and Riemann surfaces"" by Rick Miranda. The definition used here is two take two patches and glue them by an isomorphism. So the curve we consider is $w^2=z^4h(\frac{1}{z})=z(1-z)(1-2z)$. Now we have an open set $V=\{(z,w): z \neq 0\}$ and an open set $U=\{(x,y): x \neq 0\}$ and they are isomorphic via a map $\phi(z,w)=(\frac{1}{x},\frac{y}{x^2})$. Now wee can glue these curves using this isomorphism. Now I am really not sure if these two definitions are equivalent. Any help is appreciated. Thanks.","['riemann-surfaces', 'elliptic-curves', 'projective-geometry', 'algebraic-geometry']"
2488746,"$f(x)=\sqrt{\dfrac{x-\sqrt {20}}{x-3}}$, $g(x)=\sqrt{x^2-4x-12}$, find the domain of $f(g(x))$","$f(x)=\sqrt{\dfrac{x-\sqrt {20}}{x-3}}$, $g(x)=\sqrt{x^2-4x-12}$, find the domain of $f(g(x))$. For some reason, I cannot get the correct answer. Here is what I tried. $D_g:$
$$x^2-4x-12\ge0$$
$$(x-6)(x+2)\ge0$$
$$\boxed{(-\infty,-2] \cup [6,\infty)}$$ $D_f:$
$$\dfrac{x-\sqrt{20}}{x-3}\ge0$$
$$\boxed{(-\infty, \sqrt {20}] \cup (3,\infty)}$$ $D_{g(f)}:$
$$\sqrt{x^2-4x-12}\le \sqrt{20}$$
$$[-4,8]$$
$$\text{or}$$
$$\sqrt{x^2-4x-12}>3$$
$$(-\infty, -3) \cup (7,\infty)$$
$$\boxed{(-\infty, -3)\cup (-3,-2) \cup (7,\infty)}$$ So then my final answer was $$\color{blue}{\boxed{(-\infty, -3)\cup (-3,-2) \cup [6,7) \cup (7,\infty)}}$$ What did I do wrong? Correct Answer: $x\le-4\ \text{or}\ -3<x\le-2\ \text{or}\ 6\le x<7\ \text{or}\ x\ge8$","['algebra-precalculus', 'function-and-relation-composition', 'functions']"
2488790,Joint PDF from marginal of two variables,"Sam is a stockbroker with investment and revenue that are not certain. His investment, $X$, each month is a random variable with the PDF in the image. $Y$ is the amount of money he earns in a month and is distributed uniformly between 0 and twice the amount he invested that month. (a) What is the joint PDF $f_{X,Y}(x, y)$? (b) What is the probability that in any given month, Sam makes a profit? (c) Sam continues his job for 10 years. What would be the approximate probability that he makes a profit in at least 63 of the months? Attempted Solution: a) Do I need to differentiate the marginal PDFs of both the variables and add them up. But I don't understand how the marginal PDF graph of $Y$ would look like. It would be a horizontal line with lower bound $0$, and the upper bound $2X$? b) For this I will find $P(Y>X)$, would this be $\frac X{2X}$, since for a profit to be earned $Y$ must be greater than $X$. This would be the upper half of the marginal PDF graph of $Y$. c) Clueless about this.","['uniform-distribution', 'probability', 'probability-distributions']"
2488837,Can I quickly determine the eigenvalues of this matrix?,"I am working on observability and detectability in controls and I ran across this example that I didn't understand. The author deliberately sought the form of this matrix, because of its ""block-form"" in order to quickly find the eigenvalues \begin{bmatrix}
    l_{11}  & -1  & -1 & 0 & 0 \\
    0 & -1  & 0 & 0 & 0 \\
    0 & -1  & -1 & 0 & 0 \\
    0 & -.1 & -2 & l_{42} & -.1 \\
    0 &  1  &  2 & 0 & -.2
\end{bmatrix} The author was then able to state the eigenvalues were $\{l_{11}, -1, l_{42}, -.2\}$ I was under the impression that I could only determine the eigenvalues via  a matrix diagonal if the matrix was upper/lower triangular?","['matrices', 'eigenvalues-eigenvectors', 'control-theory', 'linear-algebra']"
2488891,solving inequality contains logarithm,"I have the following inequality: $$0.39n\log(n) \leq S \leq 0.5n\log(n)$$ How can I find a proper range for $n$? I can have something like: $$10^{S/0.5} \leq n^n \leq 10^{S/0.39}$$ But it's not merely based on $n$, also it'll produces a large number for most of the numbers and will cause overflow in computer's memory.","['logarithms', 'inequality', 'ordinary-differential-equations']"
2488892,Is every group homomorphism the induced homomorphism of a continuous function?,"If $f : X \to Y$ is a continuous function and we fix base points $x_0 \in X$ and $y_0 = f(x_0)\in Y$, then $f$ induces a group homomorphism 
$$f_*: \pi_1(X, x_0) \to \pi_1(Y, y_0)$$
between the fundamental groups of $(X, x_0)$ and $(Y,y_0)$. I was just wondering if there is some kind of reciprocal property, that is: If $\psi : \pi_1(X,x_0) \to \pi_1(Y,y_0)$ is a homomorphism, is it true that $\psi = f_*$ for some continuous function $f: X \to Y$?","['algebraic-topology', 'group-homomorphism', 'general-topology', 'fundamental-groups']"
2488906,Is entropy being maximized and the norm being minimized by the same (unique) probability vector somehow related?,"Consider the set of probability vectors $$
\mathcal P_n=\Big\lbrace x\in[0,1]^n\,\Big|\,\sum_{i=1}^n x_i=1\Big\rbrace\subset\mathbb C^n
$$ for any $n\in\mathbb N$ where $x_i$ is the $i$ -th component of $x$ . Since $\mathcal P_n$ is a non-empty convex and closed set, there exists a unique vector of minimal norm which, unsurprisingly, turns out to be the equilibrium $\frac1n(1,\ldots,1)$ as a simple consequence of Cauchy-Schwarz. On the other hand given $x\in \mathcal P_n$ we can define the entropy as in quantum information via $$
S:\mathcal P_n\to\mathbb R_0^+\qquad x\mapsto-\sum_{i=1}^n x_i\log(x_i).
$$ It is well known that the entropy is maximal if and only if $x=\frac1n(1,\ldots,1)$ . Question: I wondered if the entropy being maximized and the norm being minimized by the same unique vector $\frac1n(1,\ldots,1)$ is somehow related? I don't see a direct connection since the logarithm obviously is not linear but I still feel like there might be some kind of link between those two results. Thanks in advance for any answer or comment!","['entropy', 'linear-algebra', 'quantum-information']"
2488916,"A good introductory book to geodesics, curve length, curvature.","I'm looking for a book about geodesics, curve length, curvature. Preferably something around undergraduate level. I'm doing a project where we have to show that a simulation we run, plots a geodesic on a sphere. So something that can give me the basics would be a helpful start. Thanks.","['curves', 'book-recommendation', 'differential-geometry', 'curvature']"
2488994,"Why does the ""$bx$"" term in the general quadratic $ax^2+bx+c$ shift the parabola along a parabolic arc?","I've been playing around a little in Desmos with the graphs of quadratics and trying to figure out the role each of the terms $ax^{2}$, $bx$, and $c$ in the general quadratic $ax^{2}+bx+c$ play, and I've noticed some interesting behavior with the $bx$ term. Changing $a$ and $c$ has the effect I'd expect; $a$ determines the direction/scaling of the parabola, and $c$ shifts it vertically, but changing $b$ shifts the graph in a way I found rather unexpected. Keeping $a$ and $c$ the same and sliding $b$ around seems to move the parabola along another downwards parabolic arc; I assumed that the arc might be just a flipped version of the original parabola, and sure enough, graphing $-ax^{2}+c$ showed me that the first parabola's vertex was moving perfectly along the path traced by the second. Some further experimentation in Desmos also opened up a connection for me of the tangent line of the parabola $ax^{2}+bx+c$ and the line $bx$. ( Link to the Desmos graph here ) What I'm curious about is: Why is this the case? Is there an intuitive way of understanding why the $bx$ term makes the graph behave like this?","['algebra-precalculus', 'quadratics', 'graphing-functions', 'analytic-geometry']"
2489013,Closed property of nonempty finite set,I came across this text in Rudin's book where it has been mentioned that a non-empty finite set is closed. But a closed set is a set which contains all of it's limit points in the set itself but none of the elements of a non-empty finite set can possibly have a limit point because a neighborhood of a limit point has infinite points . So how come a non-empty finite set be a closed set ??,['real-analysis']
2489034,Requirement of a smallest element for MÃ¶bius inversion on a finite poset,"Here is the MÃ¶bius Inversion Formula on a finite poset $(X, \le)$ : Suppose $(X, \le)$ has a smallest element--that is, an element $0$ such that $0 \le x$ for all $x \in X$ .
Let $\mu$ be its MÃ¶bius function and let $F : X \rightarrow \Re$ be a real-valued function defined on $X$ . Let the function $G : X \rightarrow \Re$ be  defined by $$G(x) = \sum_{z:z \le x} F(z),\ \ (x \in X).$$ Then $$F(x) = \sum_{y:y \le x} G(y) \mu(y,x),\ \ (x \in X).$$ The proof in Introductory Combinatorics by Richard A. Brualdi reads: Let $\zeta$ be the zeta function of $(X, \le )$ . Using the properties of $\zeta$ and $\mu$ , we calculate as follows for $x$ an arbitrary element in $X$ : $$
\begin{align*}
\sum_{y:y \le x} G(y)\mu(y,x) &= \sum_{y:y \le x} \mu(y,x) \sum_{z:z \le y} F(z) \\
&= \sum_{y:y \le x} \mu(y,x) \sum_{z:z \in X} \zeta(z,y)F(z) \\
&= \sum_{z:z \in X} F(z) \sum_{y:z \le y \le x} \zeta(y,x) \mu(y,x) \\
&= \sum_{z:z \in X} F(z) \delta(z,x) \\
&= F(x)
\end{align*}
$$ From my perspective, the condition "" $(X, \le )$ has a smallest element"" seems unused. So can anyone tell me how this proof use this condition implicitly?","['combinatorics', 'mobius-inversion', 'order-theory', 'discrete-mathematics']"
2489076,Express in terms of constants and series $-\int_0^1\log\left( \left\{ x^{-1/3} \right\} \right)dx$,"This morning I've calculated the case $k=2$ of an integral involving the fractional part function $ \left\{ x \right\} $, this 
$$-\int_0^1\log\left( \left\{ x^{-1/k} \right\} \right)dx,\tag{1}$$ in terms of well-known constants and the series $\sum_{n=1}^\infty\frac{\log (n+1)}{n^2}$. Question. Is it known from the literature the calculation $(1)$ for integers $k\geq 2?$ Or in other case can you calculate a different case for example $k=3$? I am saying to calculate in terms of constants or series, as I did with my example $k=2$. Thanks in advance.","['reference-request', 'fractional-part', 'closed-form', 'integration', 'definite-integrals']"
2489080,Swapping an improper integral and series,"What are the hypothesis that allow me to write the identity $$\int_{x_0}^{+\infty}\left(\sum_{n=1}^{\infty}f_n(x)\right)\mathbf{d}x=\sum_{n=1}^{+\infty}\left(\int_{x_0}^{+\infty}f_n(x)\mathbf{d}x\right)$$ , where $x_0\in\mathbb{R}$ and $\forall n\in\mathbb{N}_{>0}\ \ f_n:[x_0,+\infty)\to\mathbb{R}$ is a continuous function? I know that exist many theorems about a similar argument, but in the hypothesis the set of integration is a bounded closed interval. Maybe I can use the definition of improper integral? I mean. Fix $M>x_0$, and suppose that $\sum_{n=1}^{+\infty}f_n(x)$ is uniformly convergent over $[x_0,M]$ for all $M>x_0$, then: $$\lim_{M\to+\infty}\int_{x_0}^{M}\left(\sum_{n=1}^{\infty}f_n(x)\right)\mathbf{d}x=\lim_{M\to+\infty}\sum_{n=1}^{+\infty}\int_{x_0}^{M}f_n(x)\mathbf{d}x$$ but it's not the same thing...","['real-analysis', 'improper-integrals', 'sequences-and-series']"
2489098,Simplifying $\frac{x}{\sqrt[3]{x+1}-1}$,Simplify the following fraction: $$\frac{x}{\sqrt[3]{x+1}-1}$$ How should I approach this? unlike $(a-b)(a+b)=a^2+b^2$ ?,['algebra-precalculus']
2489124,"Why is the axiom of foundation/regularity called ""regularity""?","I'm curious about the history of the word ""regularity"" in the axiom of foundation/regularity. Both of those terms are used interchangeably (Wikipedia and most texts seem to use ""regularity"", while MathWorld uses ""foundation"", for one). But in actually describing the meaning of the axiom, the term ""well-founded"" is common, while I've never seen sets described as ""regular"". It the use of the term ""regularity"" based on the assumption that it is intuitive a ""regular"" set means one which conforms to basic principles like being well-founded and extentional? Or does this term have some other meaning of which I'm unaware? For reference, I'm writing a book which touches on set theoretical concepts and I'm undecided on which term to use. Advice is appreciated.","['axioms', 'elementary-set-theory']"
2489126,Uncountable Set with Cofinite Topology,"In this proofwiki page, it is written without any justification that $\cap \mathcal{B}_x = \{x\}$ where $\mathcal{B}_x$ is some countable basis of a point $x$ in the uncountable set $S$ endowed with the cofinite topology. Why is this true? Indeed, I just proved that it cannot be true in an uncountable space with the cofinite topology. Is this proof flawed? This steps seems crucial in obtaining a contradiction. What I am trying to do is prove that if $X$ is an uncountable set with the cofinite topology, then it cannot be first countable. I read this , but I couldn't see how to use Brian Scott's hints. Here is what he wrote: To prove that $X$ is not first countable, you must show that some point of $X$ does not have a countable local base. All points of $X$ â€˜look alikeâ€™ in the cofinite topology, so it doesnâ€™t matter what point we pick, so let $x\in X$ be any point. Suppose that $\mathscr{B}=\{B_n:n\in\Bbb N\}$ is a countable local base of open sets at the point $x$, meaning that if $U$ is any open nbhd of $x$, then $x\in B_n\subseteq U$ for some $n\in\Bbb N$. For each $n\in\Bbb N$ let $F_n=X\setminus B_n$: $B_n$ is open, so by definition $F_n$ is finite. Let $F=\{x\}\cup\bigcup_{n\in\Bbb N}F_n$; $F$ is the union of countably many finite sets, so $F$ is countable. $X$ is uncountable, so there is some $y\in X\setminus F$. Let $U=X\setminus\{y\}$. Is $U$ an open nbhd of $x$? Is there any $n\in\Bbb N$ such that $x\in B_n\subseteq U$? I would answer the first question affirmatively; and to answer the question, which is presumably ""no"", I would suppose that there is such an $n \in \Bbb{N}$. But I am having trouble identifying the contradiction. Before I even sought help from google, I tried the following (and several variations on it). Let $x \in X$, and let $y \in X - \{x\}$. Then $X-\{y\}$ is open and therefore there is an open set $U_y$ such that $x \in U_y \subseteq X - \{y\}$. Thus we have a mapping $y \mapsto U_y$. I tried to show this mapping is injective, but I couldn't. If I had succeeded, then I believe this would have shown that if there were any basis at $x$, it would have to be uncountable, which means that $X$ is not first countable. But, as you may have noticed, I abjectly failed in this task. Is there a way to get any of these to proves to work, especially the one I proposed?","['general-topology', 'proof-explanation']"
2489156,"Given $f(x)=x^n+px + q, \ n\in{\mathbb{N}}$","Problem: Given $f(x)=x^n+px+q, \ n\in{\mathbb{N}}, \ x\in\mathbb{R},$ determine (as a function of $n$) the maximum number of distinctive real roots that $f$ can have for $p,q\in\mathbb{R}.$ I need help to understand this problem. Below follows a solution from my professor, but I don't really understand. Solution: $n=1:$ One real root for $p\neq-1$ and no real root if $p=-1$. $n\geq2:$ In this case, $f'(x)$ must have a root between the two roots for $f(x)$. The derivative $f'(x)=nx^{n-1}+p$ has one root for even $n$ and max two roots for odd $n\Rightarrow f$ has max two roots for even $n$ and max three for odd $n$. Can someone explain to me what is going on here? I understand the first $n=1$ case but for the second case I have the following questions: If $n=2$, then I understand why $f'(x)$ must have one root between the two roots of $f(x)$. This is because in order for $f(x)$ to have two roots, the derivative must change sign so that the function changes direction and intercepts the $x$-axis again. But she never specifies if it's for $n>2$ or $n=2.$ Why is this statement true: ""the derivative has one root for even $n$ and max two roots for odd $n$""? Any help to understand this is welcome. If there are simpler methods to prove this, only using differentiation, please let me know.","['derivatives', 'polynomials', 'calculus']"
2489231,Number of coniugacy classes of a group.,"I was thinking about how to compute the number of coniugacy classes of a group $G$, in particular I'm interested in the number of coniugacy classes of $GL_n(\mathbb{F}_p)$. This is clearly related to the number of irreducible representations of this group, but searching on the internet, I found out that this is actually an ""open"" problem. If the field in which we are considering our matrices is algebrically closed, we can use an argument like the Jordan form to attack this problem, but this doesn't work in $\mathbb{F}_p$. Can you suggest me some papers about this topic? I found that there are only upper and lower bounds for this number, but not an asymptotic behaviour or something like this. Given a general group $GL_n(\mathbb{F}_p)$ how many coniugacy classes
  are there? Do you think this is a question for StackExchange or should I ask this on Overflow? Any hint/paper/actual research on this topic? Thanks in advance.","['finite-fields', 'matrices', 'finite-groups', 'representation-theory', 'group-theory']"
