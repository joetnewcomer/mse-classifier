question_id,title,body,tags
674574,Surjection from a Noetherian ring induces open map on spectra?,"Let $A$ be a Noetherian ring, $f: A\rightarrow B$ a surjective ring map, then should the induced map on spectra $f^*: Spec(B)\rightarrow Spec(A)$ be an open map? In Atiyah and Macdonald, Chapter 1, Exercise 21, $f^*$ is already a closed map and is a homeomorphism from $Spec(B)$ onto the closed subset $V(\ker f)$ of $Spec(A)$. Since $f: A\rightarrow B$ trivially satisfies the ""going-down property"" defined in Chapter 5, Exercise 10 of Atiyah and Macdonald, and if the conclusion of Chapter 7, Exercise 24 is true, then $f^*$ must be an open map, and by Chapter 1, Exercise 21, we only need to show the image of $f^*$, i.e. $V(\ker f)$, is open in $Spec(A)$. Is it true? So the problem is reduced to If $A$ is a Noetherian ring, $f: A\rightarrow B$ a surjective ring map, then should the closed subset $V(\ker f)$ of $Spec(A)$ is also open in $Spec(A)$? Since any closed subset of $Spec(A)$ is of the form $V(\ker f)$ for some surjective ring map $f: A\rightarrow B$, we have also reduced the problem to In the space $Spec(A)$ (having the Zariski topology), where $A$ is a Noetherian ring, does the collection of open sets and of closed sets coincide?","['commutative-algebra', 'algebraic-geometry']"
674589,Prove -n^2 diverges to negative infinity,"Prove directly that the following sequence diverges to negative infinity $a_n = -n^2$ I understand that the sequence will diverge to negative infinity. I know that I must somehow integrate an $n$ and $M$ in some sort of inequality. In class we have been doing ""scratch works"" and then writing the proof starting from the bottom of our scratch work and moving up. Please help as we have done no examples with negative in class. If the sequence diverges to negative infinity, this implies that for every $M$ < 0 , there exists an N such that $n$ > $N$; this implies that $a_n < M$. Not sure how to proceed now.","['convergence-divergence', 'discrete-mathematics', 'real-analysis']"
674591,Relationship between intersection and compositum of fields,"This issue came up in a number theory lecture today. Let $K$ be a number field and let $L/K$ be an abelian (finite Galois) extension. Then there exists a primitive $m$th root of unity $\zeta_m$ so that $K(\zeta_m)\cap L=K$ so that $m$ satisfies a number of nice qualities. We tried to apply the following fact: if $(m,p)=1$ for every prime $p\in\mathbb Z$ ramifying in $\mathcal O_L$, then $\mathbb Q(\zeta_m)\cap L=\mathbb Q$. The issue in moving this fact up to $K/\mathbb Q$ is that, for general fields $E_1,E_2,E_3$, $E_1(E_2\cap E_3)\neq E_1E_2\cap E_1E_3$. However in our case, we do have that $K(\zeta_m)\cap L=K$, where $m$ is chosen via primes ramifying from the base field $\mathbb Q$. Perhaps if $K/\mathbb Q$ were Galois, this might be easier, but the question is this: Given three fields $F,K,L$ contained in some larger field $M$, under what (minimal) conditions do we have $F(K\cap L)=FK\cap FL$?","['number-theory', 'class-field-theory', 'algebraic-number-theory', 'galois-theory', 'field-theory']"
674615,How find this $\prod_{n=2}^{\infty}\left(1-\frac{1}{n^6}\right)$,"How find this 
$$\prod_{n=2}^{\infty}\left(1-\dfrac{1}{n^6}\right)$$ I think we can find this value have closed form
$$\prod_{n=2}^{\infty}\left(1-\dfrac{1}{n^{2k}}\right)$$
since
$$1-\dfrac{1}{n^6}=\left(1-\dfrac{1}{n^3}\right)\left(1+\dfrac{1}{n^3}\right)$$
so I think we must find this
$$\prod_{n=2}^{\infty}\left(1-\dfrac{1}{n^3}\right)$$
and
$$\prod_{n=2}^{\infty}\left(1+\dfrac{1}{n^3}\right)$$ Thank you","['sequences-and-series', 'infinite-product']"
674621,How can you find the cubed roots of $i$?,"I am trying to figure out what the three possibilities of $z$ are such that $$
z^3=i
$$ but I am stuck on how to proceed. I tried algebraically but ran into rather tedious polynomials. Could you solve this geometrically? Any help would be greatly appreciated.","['complex-numbers', 'algebra-precalculus']"
674681,Proving that $\sin x \gt \frac x2$,I was working on this question and I got a contradiction. $\sin x \gt \dfrac x2$ for     $0 \lt x \lt \dfrac {\pi}{2}$ $\arccos ( \sin x)) \gt \arccos (\dfrac x2)$ $\dfrac {\pi}{2} -x \gt \arccos (\dfrac x2)$ $\arcsin (\dfrac x2) +\arccos (\dfrac x2) -x \gt \arccos (\dfrac x2)$ $\arcsin (\dfrac x2) \gt x$ $\dfrac x2 >\sin x$ Why am I getting this contradiction if the original statement is true? Thanks. P.S. I evaluated $\arccos ( \sin x))$ using Wolframalpha .,"['trigonometry', 'inequality']"
674759,"Homework: Second derivative of $\langle Ax, x \rangle$","So let $A \in M_{n}$ and define $f: \mathbb{R}^n \to \mathbb{R}$ by $f(x) = \langle Ax, x \rangle $. Find f' and f''. After some work, I found the first derivative to be $f'(x)(v) = \langle Ax, v \rangle + \langle Av, x \rangle = \langle (A^T + A)x, v \rangle$. That is not what I'm having trouble with. I don't think it is necessary to compute the second derivative the ""long way"" through a complicated limit. I believe that since $f'$ is itself a linear function, then we should have $f''(x) = f'$. That $f''(x)(v,w) = f'(v,w) = \langle (A^T + A) v, w \rangle$. However I don't know how to justify this. I feel that there are some basic mechanics that I am missing. I am more interested in the mechanics than in a direct answer.","['multivariable-calculus', 'inner-products', 'analysis']"
674763,Can vector spaces over different fields be isomorphic?,"Two vector spaces are said to be isomorphic iff there's an invertible linear map between them. It can be shown that isomorphic vectors spaces would have to have the same finite dimension or both be infinite dimensional. But what if they are over different fields? For example, would the trivial vector space over $\mathbb C$ be considered isomorphic to the trivial vector space over $\mathbb R$? Or would it not, since, if we let $T$ be the only possible linear map between them, $T(i0)\neq iT(0)=i0$, since $i0$ is not defined in the codomain (since $i$ is not a scalar in $\mathbb R$)? Also, are there any other examples of vector spaces over different field that would be ""isomorphic"" like this?",['linear-algebra']
674769,$\sin(x)$ infinite product formula: how did Euler prove it?,"I know that $\sin(x)$ can be expressed as an infinite product, and I've seen proofs of it (e.g. Infinite product of sine function ). I found How was Euler able to create an infinite product for sinc by using its roots? which discusses how Euler might have found the equation, but I wonder how Euler could have proved it. $$\sin(x) = x\prod_{n=1}^\infty \left(1-\frac{x^2}{n^2\pi^2}\right)$$ So how did Euler derive this? I've seen a proof that requires Fourier series (something not know [formally] by Euler, I guess). I also know that this equation can be thought intuitively, and it's really true that it will have the same roots as the sine function, however it's not clear that the entire function converges to the sine function. So, even if Euler guessed it, how was his proof accepted, for this formula to calculate the zeta function for even integers? $$\zeta(2n) = (-1)^{n+1} \frac{B_{2n}(2\pi )^{2n}}{2(2n)!}$$ I've checked a proof of this result, and it requires the sine infinite product. Also, the Basel problem (solved by him) used this infinite product too, and he got famous by this proof, so the sine infinite product might have been accepted by the mathematical community at that time.","['complex-analysis', 'calculus', 'real-analysis', 'math-history']"
674782,$m(E)=0$ then $m(\lbrace x^2 : x\in E\rbrace$?,"Let E be a subset of $\mathbb{R}$ with lebesgue measure zero. How can I prove that $\lbrace x^2 : x\in E\rbrace$ also has lebesgue measure zero? Let $\epsilon>0$, I should find a cover of $\lbrace x^2 : x\in E\rbrace$ with total length at most $\epsilon$. since $m(E)=0$ so there exists a countable collection of intervals $\{ (a_k, b_k)\}$ such that $\sum b_k-a_k<\epsilon$. Then what is the next step? How can I find a cover for $\lbrace x^2 : x\in E\rbrace$?  If without loss of generality we think that $E\subset \mathbb{R}^+$ then $\bigcup (a_k^2, b_k^2)$ is a cover for $\lbrace x^2 : x\in E\rbrace$. But how to prove $\sum b_k^2-a_k^2<\epsilon$?","['measure-theory', 'lebesgue-measure', 'real-analysis', 'analysis']"
674787,Munkres' Question on Manifolds,"In Munkres' 'Analysis on Manifolds' on pg. 208 there's a question which reads: QUESTION: Let $f:\mathbb R^{n+k}\to \mathbb R^n$ be of class $\mathscr C^r$.
Let $M$ be the set of all the points $\mathbf x$ such that $f(\mathbf x)=\mathbf 0$ and $N$ be the set of all the points $\mathbf x$ such that $$f_1(\mathbf x)=\cdots=f_{n-1}(\mathbf x)=0\text{ and } f_n(\mathbf x)\geq 0$$
Assume $M$ is non-empty. 1) Assume $\text{rank} ~ Df(\mathbf x)=n$ for all $\mathbf x\in M$ and show that $M$ is a $k$-manifold without boundary in $\mathbb R^{n+k}$. 2) Assume that the matrix $\displaystyle\frac{\partial(f_1,\ldots,f_{n-1})}{\partial \mathbf x}$ has rank $n-1$ for all $\mathbf x\in N$ and show that $N$ is a $(k+1)$-manifold with boundary in $\mathbb R^{n+k}$. I am trying to show $(2)$ and I am not sure if the hypothesis of $(1)$ is required to do that. I have approached this question using the constant rank theorem which dictates: Constant Rank Theorem: Let $U$ be open in $\mathbb R^n$ and $\mathbf a$ be any point in $U$. Let $f:U\to \mathbb R^m$ be a function of class $\mathscr C^p$ such that $\text{rank } Df(\mathbf z) =r$ for all $\mathbf z\in U$. Then there exist open sets $U_1,U_2\subseteq U$ and $V\subseteq \mathbb R^m$ such that $\mathbf a\in U_1$ and $f(\mathbf a)\in V$, and $\mathscr C^p$-diffeomorphisms $\phi:U_1\to U_2$ and $\psi:V\to V$ such that $$(\psi\circ f\circ \phi^{-1})(\mathbf z)=(z_1,\ldots,z_r,0,\ldots,0)$$
for all $\mathbf z\in U_2$. My approach to solve $(2)$ shall be clear by my solution of $(1)$: Let $\mathbf a\in M$.
   We know that there exists $U$ open in $\mathbb R^{n+k}$ such that $\mathbf a\in U$ and $\text{rank }Df(\mathbf x)=n$ for all $\mathbf x\in U$.
   By the Constant Rank Theorem there exists open sets $U_1$ and $U_2$ in $\mathbb R^{n+k}$ and $V$ in $\mathbb R^n$ such that $\mathbf a\in U_1\subseteq U_1$ and $f(\mathbf a)=\mathbf \in V$, along with diffeomorphisms $\phi:U_1\to U_2$ and $\psi:V\to V$ satisfying
   $$(\psi\circ f\circ \phi^{-1})(\mathbf x) =(x_1,\ldots,x_n)$$
   for all $\mathbf x\in U_2$.
   Say $\psi(\mathbf 0)=(t_1,\ldots,t_n)$ and define $S=\{(t_1,\ldots,t_n,z_1,\ldots,z_k):z_i\in \mathbb R\}\cap U_2$. Claim 1: $\phi^{-1}(S)=M\cap U_1$. Proof: Let $\mathbf q=(t_1,\ldots,t_n,z_1,\ldots,z_k)$ be in $S$.
            Then $\phi^{-1}(\mathbf q)$ obviously lies in $U_1$.
           We now show that $\phi^{-1}(\mathbf q)$ lies in $M$.
            Note that $(\psi\circ f\circ \phi^{-1})(\mathbf q)=(t_1,\ldots,t_n)$.
            This gives $(f\circ \phi^{-1})(\mathbf q)=\psi^{-1}(t_1,\ldots,t_n)=\mathbf 0$.
           This means that $f(\phi^{-1}(\mathbf q))=\mathbf 0$ and hence $\phi^{-1}(\mathbf q)$ is in $M$.
           For the reverse containment assume that $\mathbf q\in M\cap U_1$.
           Then $\mathbf q=\phi^{-1}(\mathbf s)$ for some $\mathbf s\in U_2$.
           Also, $f(\mathbf q)=0$ since $\mathbf q\in M$.            Thus $(f\circ\phi^{-1})(\mathbf s)=\mathbf 0$.
            Operating $\psi$ on both the sides we get $(\psi\circ f\circ \phi^{-1})(\mathbf s)=\psi(\mathbf 0)$.
            But the LHS of the last equation is $(s_1,\ldots,s_n)$ and the RHS is $(t_1,\ldots,t_n)$.
            Thus $s_i=t_i$ for $1\leq i\leq n$.
            Therefore $\mathbf s\in S$ and $\mathbf q\in\phi^{-1}(S)$.
            This settles the claim. Now define $T=\{(z_1,\ldots,z_k)\in\mathbb R^k: (t_1,\ldots,t_n,z_1,\ldots,z_k)\in S\}$. Claim 2: $T$ is open in $\mathbb R^k$. Proof: Define $g:\mathbb R^k\to \mathbb R^{n+k}$ as $$g(z_1,\ldots, z_k)=(t_1,\ldots,t_n,z_1,\ldots,z_k)$$
            Clearly $g$ is injective and continuous.
            We now show that $g^{-1}(U_2)=T$.
            Note that $g^{-1}(U_2)=g^{-1}(S)$.
            Let $\mathbf q\in S$.
            Say $\mathbf q=(t_1,\ldots,t_n,q_1,\ldots,q_k)$ and it is obvious that $g^{-1}(\mathbf q)\in T$.
            Now let $g^{-1}(\mathbf q)\in T$ for some $q\in \mathbb R^{n+k}$.
            We need to show that $\mathbf q\in U_2$.
            Say $g^{-1}(\mathbf q)=(b_1,\ldots,b_k)$.
            Then $\mathbf q=(t_1,\ldots,t_n,b_1,\ldots,b_k)\in S$ and thus $\mathbf q\in U_2$. So we have shown that $T=g^{-1}(U_2)$.
            Now since $g$ is a continuous function and $U_2$ is open in $\mathbb R^{n+k}$, we infer that $T$ is open in $\mathbb R^k$ and the claim is settled.
    Now define a function $\alpha:T\to M\cap U_1$ as $$\alpha(\mathbf z)=\phi^{-1}\circ g(\mathbf z)$$
    It is a trivial matter to verify that $\alpha$ is a coordinate patch about the point $\mathbf a$ in $M$ and the proof is complete. To solve $(2)$ what I did was define a function $g:\mathbb R^{n+k}\to \mathbb R^{n-1}$ as $$g(\mathbf x)=(f_1(\mathbf x),\ldots,f_{n-1}(\mathbf x))$$
Then $\text{rank }Dg(\mathbf x)=n-1$ for all $\mathbf x\in N$.
Let $\mathbf z_0\in N$.
I can show that there exists an open set $U\subseteq \mathbb R^{n+k}$ such that $\mathbf z_0\in U$ and $\text{rank }Dg(\mathbf z)=n-1$ for all $\mathbf z\in U$.
Thereby, using the conastant rank theorem I get $U_1, U_2,\psi$ and $\phi$ such that $(\psi\circ g\circ\phi^{-1})(\mathbf x)=(x_1,\ldots,x_{n-1})$
Can somebody guide me what to do from here?","['multivariable-calculus', 'manifolds']"
674793,"Why is a statement such as, ""It's 5 o'clock"" excluded from propositions?","From MIT notes: A proposition excludes statements whose truth varies with circumstance such
  as, “It’s five o’clock”. And: A predicate is a proposition whose truth depends on the value of one or more variables . If a proposition excludes statements whose truth varies with circumstance, why is a predicate considered as a proposition whose truth depends on the value of one or more variables? In other words, why can't I just write a statement like ""It's 5 o'clock"" as: $P(x) ::=$ ""$x$ is equal to 5"" Thanks!",['discrete-mathematics']
674807,"What does ""$\cong$"" sign represent?","I came across this sign when reading some papers.  I looked up Wikipedia.  It says ""The symbol ""$\cong$"" is often used to indicate isomorphic algebraic structures or congruent geometric figures.""  So if A $\cong$ B, does this mean A and B are roughly the same but not equal? Edit:
I found this sign in a paper call Identifying Change Points in Linear Regressionns http://goo.gl/dNMONQ , In page 9 there is an equation(equation 3.1) says RSS $\cong$ RSS1+RSS2. RSS is residual sum of square of one regression line, RSS1 and RSS2 is another two residual sum of square of regression lines. thank you for your help.","['notation', 'abstract-algebra']"
674813,Exact sequence induces exact sequences for free parts and torsion parts?,Let $A$ be a PID and consider the exact sequence of finitely generately modules over$A$: $$0\longrightarrow M' \overset{f}{\longrightarrow}M\overset{g}{\longrightarrow}M''\longrightarrow 0 \tag{1}.$$ Denote the free part and torsion part by $F(M)$ etc. and $T(M)$ etc. respectively. Does the above exact sequence induces ones on the free parts and torsion parts?,"['homological-algebra', 'commutative-algebra', 'abstract-algebra', 'exact-sequence']"
674814,Prime elements in $\mathbb{Z}[\sqrt{2}]$,"What are the prime elements in the ring $\mathbb{Z}[\sqrt{2}]$? Note that since the ring is a PID (and thus a UFD) then prime = irreducible. Even more, it is Euclidean with respect to the absolute value of the norm: $N(a+b\sqrt{2})=a^2-2b^2$ so it has a nice structure. I know that if $N(\alpha)=p$ with $p$ prime integer then $\alpha$ is a prime element. Not a very explicit description but it would do. Nevertheless, I think there are other primes not covered by the above case. What about prime integers, are they still prime in $\mathbb{Z}[\sqrt{2}]$? I am hoping a classification can be found similar to the primes in $\mathbb{Z}[i]$... Edit: As Alex Youcis points out, it is probably useful to keep in mind that all the units in this ring are characterized by $\pm(1-\sqrt{2})^n$, so the search for prime elements should be up to these.","['principal-ideal-domains', 'ring-theory', 'abstract-algebra']"
674827,"Borel $\sigma$-algebras on the Skorohod space $D[0,1]$","On the Skorohod space $D[0,1]$ of cadlag functions one usually considers either the uniform norm $\|\cdot\|_{\infty}$ or the $J_1$-metric $\varrho$. I was wondering whether both generate the same Borel $\sigma$-algebra: It is widely known that $$\varrho(f,g) \leq \|f-g\|_{\infty},$$ i.e. the $J_1$-topology is coarser, and this implies in particular that the corresponding Borel $\sigma$-algebras satisfy the relation $$\mathcal{B}((D[0,1],\varrho)) \subseteq \mathcal{B}((D[0,1],\|\cdot\|_{\infty}). \tag{1}$$ On the other hand, one can show that $\mathcal{B}((D[0,1],\varrho))=\sigma(\pi_t;t \in [0,1])$ where $\pi_t(f) :=f(t)$, $t \in [0,1]$, denotes the natural projection (see e.g. Billingsley, Convergence of Probability Measures, Theorem 12.5). Now for any countable dense set $T \subseteq [0,1]$, $1 \in T$, we have $$B_{(D[0,1],\|\cdot\|_{\infty})}[0,1] := \{f \in D[0,1], \|f\|_{\infty} \leq 1\} = \bigcap_{t \in T} \{f \in D[0,1]; \pi_t f \in [-1,1]\} \in \sigma(\pi_t;t \in [0,1]) \stackrel{(1)}{=} \mathcal{B}((D[0,1],\varrho)).$$ by the right-continuity of the functions. A similar argumentation shows that $B_{(D[0,1],\|\cdot\|_{\infty})}[f,\varepsilon] \in \mathcal{B}((D[0,1],\varrho))$ for any $\varepsilon>0$, $f \in D[0,1]$. Hence, $$\mathcal{B}((D[0,1],\varrho)) \supseteq \mathcal{B}((D[0,1],\|\cdot\|_{\infty}),$$ and this means that both Borel-$\sigma$-algebras are equal. Is there anything wrong about this argumentation?","['measure-theory', 'skorohod-space']"
674847,Continuous function on $\mathbb{Q}$,"Let $f:\mathbb{Q}\to\mathbb{R}$ be a function defined as: $$f(x) = 
\begin{cases}
    0 &  x^2 < 2\\
    1 &  x^2 \geq 2
\end{cases}
$$ Is this function continuous? How can we check the continuity around $\sqrt{2}$ since it's not in $\mathbb{Q}$?","['calculus', 'continuity', 'real-analysis']"
674877,"What is the sum of the reciprocal of primes? (Yes, it diverges..) [duplicate]","This question already has answers here : Does the sum of reciprocals of primes converge? (3 answers) Closed 10 years ago . It's well known that the summation over 1/p diverges just as 1/n does. However, in the case of the sum of 1/n, we can establish upper and lower bounds to the sum with the integrals over 1/n and 1/(n-1). Therefore we can say that the sum is asymptotically equal to ln(x). Can we do anything similar for the sum of the reciprocals of the prime numbers? I suspect there isn't a neat function due to the unpredictable distribution of prime numbers.",['number-theory']
674879,Show that $f$ is harmonic,"Let us consider the function: $$
f(α,β)
\equiv
\sum_{n = 1}^{\infty}\left(-1\right)^{n - 1}\left[%
{n^{2\alpha - 1} - 1 \over n^{\alpha}}\,\cos\left(\beta\ln\left(n\right)\right)
\right]
$$ My question is: Show that $f$ is harmonic
$\quad\forall\ s = \alpha + \beta\,{\rm i}\quad$ with $\quad 0 < \alpha < 1$.","['multivariable-calculus', 'riemann-zeta', 'zeta-functions', 'harmonic-functions', 'proof-verification']"
674886,Double integrals in polar coordinates,"Determine the domain of $$\!\!\!\!\!\!\!{\small
D \equiv
\left\{\left(x,y\right) \in \mathbb{R}^{2}\
{\large\mid}\
x \in \left[\,{-\,\frac{1}{\,\sqrt{\,{2}\,}\,},
\frac{1}{\,\sqrt{\,{2}\,}\,}}\,\right],\
y \in \left[\,{\left\vert\,{x}\,\right\vert,
\,\sqrt{\,{1 - x^{2}}\,}\,}\,\right]\right\}}
$$ in polar coordinates and draw it. Also how would you integrate $$\int\int_D \frac{1}{1+x^2 + y^2}dA$$ which is i guess $$\int_{-\frac{1}{\sqrt{2}}}^{\frac{1}{\sqrt{2}}}\int_{|x|}^{\sqrt{1-x^2}} \frac{1}{1+x^2 + y^2}dydx$$ I guess in the integral you can use the polar coordinates $$\int\int_D \frac{1}{1+r^2\cos^2(\phi) + r^2\sin^2(\phi)}rdrd\phi$$ $$\int\int_D \frac{r}{1+r^2}drd\phi$$ $$\int_{\frac{1}{4\pi}}^{\frac{3}{4\pi}}\int_0^1 \frac{r}{1+r^2}drd\phi=\int_{\frac{1}{4\pi}}^{\frac{3}{4\pi}}\left(\frac 12 \ln(1+1^2)-\frac 12\ln(1+0^2) \right)d\phi$$ $$\int_{\frac{1}{4\pi}}^{\frac{3}{4\pi}}\frac{\ln{2}}{2}d\phi=\left(\frac{3}{4\pi}\frac{\ln{2}}{2}-\frac{1}{4\pi}\frac{\ln{2}}{2} \right)=\frac{\pi}{4}\ln{2}$$ Did I get it right?","['multivariable-calculus', 'integration']"
674893,Surface reconstruction from Laplace-Beltrami eigenfunctions,"Consider a smooth, compact Riemannian surface $\mathcal{S}$ in $\mathbb{R}^3$ and suppose we are given the complete set of eigenfunctions $\{\phi_i\}$ of the associated Laplace-Beltrami operator. Is this information sufficient to fully reconstruct the surface? [As far as I know, one can infer the Riemannian metric from the Laplace-Beltrami eigenfunctions and thus fundamental geometrical properties like curvature. But I don't have enough information to actually draw the surface in its embedding space, correct? With what (minimal) information can I supplement knowing the set $\{\phi_i\}$ such that I am able to draw the surface?] EDIT :
The above statement is wrong (thanks for the comments). I still think the topic is interesting: To what extend and in what way are the Riemannian metric and the Laplace-Beltrami eigenvalue problem related and determined by each other?",['differential-geometry']
674907,How do you find the height of a triangle given $3$ angles and the base side? Image given.,"This question has me absolutely stumped. This is the image of the question, how can I work out $x$? I've been doing a variety of attempts but I just cant get it.","['trigonometry', 'triangles']"
674929,Etale subgroup-scheme,"Let $A$ and $B$ be two abelian varieties over a field $k$ and let $l$ be a prime number not dividing the caracteristic of $k$. Let $\phi : A \to B \in Hom(A,B)$ be such that $\phi$ is zero on $A_{l^n}(\overline{k})$. In arithmetic geometry by Cornell and Silverman, Milne says on page 124 in the proof of lemma 12.6 that $\phi$ is zero on $A_{l^n}$ because $A_{l^n}$ is an étale subgroup scheme of $A$. I don't understand why being étale implies this so I'd be grateful if someone could explain this","['abelian-varieties', 'algebraic-geometry']"
674957,How can this population extinct because of gender inequality?,"This population has the properties as follows: (1) It is an isolated population, which means the individuals can only mate with others in this population. (2) It is a monogamy population, which means each individual should only has one mate. (3a) Each couple should give birth to N children. N is an integer. (3b)(alternative to 3a) Each couple gives birth to k children, and k follows a Poisson distribution: P(k)=$\frac{N^k}{k!}e^{-N}$. N can be a non-integer. (4) The length of breeding cycle in this population is constant and consistent from individual to individual. All the individuals only give birth at their fixed breeding age. (5) There is a gene called DOOM. If one spouse in a couple carries the DOOM gene, they will give birth to male children at the probability of Pm. A couple without DOOM has the same probability to give birth to male children and female children. (6) If one spouse in a couple carries the DOOM gene, their children will carry DOOM gene. (7) All the individuals can not distinguish those with DOOM from those without DOOM. (8) Initial conditions: The percentage of male DOOM carriers equals to female DOOM carriers, and is $q_0$. The percentage of male DOOM non-carriers equals to female DOOM non-carriers, and is $(1-2q_0)/2$. At the beginning, all the individuals are at their breeding age. [Question] In what condition given by N, Pm and $q_0$, this population will diminish gradually?","['probability-theory', 'stochastic-processes', 'probability']"
674971,Showing that $\lim\limits_{n \to\infty} z_n = A$ implies $\lim\limits_{n \to\infty} \frac{1}{n} (z_1 + z_2 + \ldots + z_n) = A$ [duplicate],"This question already has answers here : On Cesàro convergence: If $x_n \to x$ then $z_n = \frac{x_1 + \dots +x_n}{n} \to x$ (3 answers) Prove convergence of the sequence $(z_1+z_2+\cdots + z_n)/n$ of Cesaro means [duplicate] (3 answers) Closed 4 years ago . In what follows let all values be in $\mathbb{C}$.  I'm trying to show that if $$\lim z_n = A,$$ that then $$
\lim_{n \to \infty} \frac{1}{n} (z_1 + z_2 + \ldots + z_n) = A.
$$ For ease of notation, let $s_n = \frac{1}{n} (z_1 + z_2 + \ldots + z_n)$. Attempt: Let $n \in \mathbb{N}$ be arbitrary and consider that $$
\left| A - s_n \right| = \left|A - \frac{1}{n} (z_1 + \ldots + z_n) \right| = \left|A - \frac{z_1}{n} - \ldots - \frac{z_n}{n} \right| 
$$ so that through repeated applications of the triangle inequality we have that $$
\left| A - s_n \right| \le \left| A - \frac{z_n}{n} \right| + \left| - \frac{z_{n-1}}{n} - \ldots - \frac{z_{1}}{n} \right| \le \left| A - \frac{z_n}{n} \right| + \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right|
$$ Now as $n \rightarrow \infty$, we have that the numerator of the term  $\left| -\frac{z_{n-1}}{n} \right|$ approaches $-A$ while the denominators of all of the terms in the sum $\left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right|$ approach infinity.  \uline{[Gap]}. Then as $n \rightarrow  \infty$, we have that $\left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right|$ approaches $0$. On the other hand, we have also that $z_n \rightarrow A$ (by hypothesis) so that the term $\left| A - \frac{z_n}{n} \right|$ can get as close to $\left| A - \frac{A}{n} \right|$ as we'd like.  Yet since $\frac{A}{n} \rightarrow 0$, we have that $\left| A - \frac{z_n}{n} \right| \rightarrow \left| A - 0 \right| = \left| A \right|$. Then since $$
\left( \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| \right) \rightarrow 0
$$ and $$
\left| A - \frac{z_n}{n} \right| \rightarrow \left| A \right|
$$ we have that $$
|A - s_n| \le \left| A - \frac{z_n}{n} \right| + \left( \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| \right) \rightarrow |A| + 0 = |A|.
$$ Question: My argument doesn't quite work since I have shown only that $|A - s_n| \rightarrow |A|$ and yet we want $|A - s_n| \rightarrow |0|$.  Is there a way to keep most of my argument in place and yet actually to prove the desired statement?","['analysis', 'sequences-and-series', 'limits']"
674982,"Difference between closed, bounded and compact sets","In real analysis, there is a theorem that a bounded sequence has a convergent subsequence. Also, the limit lies in the same set as the elements of the sequence, if the set is closed. Then when metric spaces are introduced, there is a  similar theorem about convergent subsequences, but for compact sets. At this point things get a bit abstract. So, can somebody explain the difference between compact , bounded and closed sets with examples ?","['general-topology', 'metric-spaces', 'compactness']"
674991,Intuition for an open mapping,"What is an intuitive picture of an open mapping? The definition of an open mapping (a function which maps open sets to open sets) is simple sounding, but it's really not as easy to picture as the simple language would suggest. When I think of fields, for example, I immediately think of the rational numbers, the real numbers, the complex numbers, the integers modulo a prime, etc. When I think of continuous functions, I can picture common examples like polynomials, the absolute value function, etc., or nastier ""artificial"" examples like the Weierstrass function. What are the functions I should think of, nasty and nice, when I think of open mappings?","['general-topology', 'open-map', 'intuition']"
675005,A simple sheaf computation,"I am currently taking my first course in algebraic geometry and am stuck at te following problem, which I am sure is simple.  Consider $Y := \mathbb P^1 \times \{x\}$ as a closed subscheme of $\mathbb P^1 \times \mathbb P^1$.  Suppose you have a line bundle $\mathcal L$ on $\mathbb P^1 \times \mathbb P^1$, which is of the form $p_1^*(\mathcal O(n_1)) \otimes p_2^*(\mathcal O(n_2))$, where $p_1,p_2$ are the projections onto the two factors.  What is $\mathcal L \otimes \mathcal O_Y$?  I am not able to rigorously prove it.",['algebraic-geometry']
675018,Limit of $\sqrt[x]{\frac{\tan x}{x}}$ as $x \to 0$,"I am trying to calculate the Limit $$\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$$ Wolfram Alpha says it's $1$ . But I get $$\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$$
$$= \exp \lim_{x \to 0} \ln \left(\left(\frac{\tan x}{x}\right)^{1/x}\right)$$
$$= \exp \lim_{x \to 0} \frac{\ln(\tan(x)) - \ln(x)}{x}$$
Using L'Hospital:
$$= \exp \lim_{x \to 0} \frac{\frac{1}{\tan(x)\cos^2(x)} - \frac{1}{x}}{1}$$
$$= \exp \lim_{x \to 0} \frac{1}{\sin(x)\cos(x)} - \frac{1}{x}$$
$$= \exp \lim_{x \to 0} \frac{1}{\sin(2x)} - \frac{1}{x}$$
$$= \exp \lim_{x \to 0} \frac{x - \sin(2x)}{\sin(2x) x}$$ But when I calculate
$$\lim_{x \to 0} \frac{x - \sin(2x)}{\sin(2x) x}$$ with Wolfram Alpha I get $\pm \infty$ . So the limit of $\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$ should be $e^{\pm \infty} = 0 \text{ or } \infty \neq 1$. Which is both wrong. Where is my mistake?",['limits']
675034,Finding inverse in non-commutative ring,"Let $a,b,c,x$ be elements of a unital non-commutative ring. Assume $c$ is an inverse of $1-ab$: $$ c(1-ab) = 1$$ How can I find an inverse for $1-ba$? What I tried: Denote the unknown by $x$. Then $x (1-ba) = 1 = x - xba$. I tried to replace $1$ with $c(1-ab)$ but it didn't help because I cannot solve for $x$. I also tried to subtract $x (1-ba) $ from $ c(1-ab)$ but couldn't solve for $x$ either. Any suggestions?","['ring-theory', 'abstract-algebra']"
675039,Equality with floor function and logarithm,Prove that if n is odd then $\lfloor(\log_2(n))\rfloor=\lfloor(\log_2(n-1))\rfloor$. I tried to substitute $n=2k+1$ but it didn't help me in any way.,"['logarithms', 'discrete-mathematics', 'ceiling-and-floor-functions']"
675041,How to calculate radius of convergence of the following series?,"How can I calculate radius of convergence of the following series? $$\Large
\sum\limits_{n=0}^\infty \frac{5^{n+1}}{\sqrt[n]{(2n)!}}z^{n}
$$ I tried using D'alembert convergence test but cannot figure out how to calculate. I know the answer is $\LARGE\frac{1}{5}$","['convergence-divergence', 'complex-analysis']"
675081,A Problem about Common Eigenvector,"Question 1: Let $A$ , $B$ be two $n\times n$ complex matrix satisfy: $AB-BA=0$ . Then $A$ , $B$ have a common eigenvector. Question 2: Let $A$ , $B$ be two $n\times n$ complex matrix satisfy: $AB-BA=B$ . Then $A$ , $B$ have a common eigenvector. Question 1 It is easy to prove. Let $\lambda$ be a eigenvalue of $A$ and $V_\lambda$ be the eigensubspace. For any $x\in V_\lambda$ , we have $A(Bx)=\lambda(Bx)$ . So $V_\lambda$ is the invariant subspace of $B$ . Question 2 I have some ideas but fail to solve it all. Let $Ax=\lambda x$ . Then we have $A(Bx)=(\lambda+1)(Bx)$ . Assume $V_{\lambda_1}$ , $V_{\lambda_2}$ ,.., $V_{\lambda_s}$ are all eigensubspaces of $A$ and $n_0,...,n_s$ are the index: for any $i$ , there exists $x\in V_{\lambda_i}$ and we have $B^{n_i}x\not=0$ but for all $y\in V_{\lambda_i}$ , $B^{n_i}y=0$ . How is the next step? Or is there any different idea? Can someone help me? Thank you.","['matrices', 'linear-algebra']"
675082,Proving convergence of real and imaginary parts,"I am trying to prove that a complex sequence $(z_n)$ converges if and only if $(\Re(z_n))$ and $(\Im(z_n))$ converge. Now $\impliedby$ was straightforward, but I got a bit stuck with $\implies$ : $$|z_n-z| = |(x_n+iy_n)-(x+iy)|$$ $$=|(x_n-x)-i(y_n-y)|$$ $$\geq||x_n-x|-|y_n-y||$$ Now $\displaystyle\lim_{n\to\infty} z_n =0 \implies \displaystyle\lim_{n\to\infty} ||x_n-x|-|y_n-y|| = 0$ Which then leaves me with having $\displaystyle\lim_{n\to\infty} |x_n-x|=\displaystyle\lim_{n\to\infty} |y_n-y|$ , and unsure what to do to deduce these limits are zero. How should I proceed, or how should I begin this half of the proof if this is a dead end?","['sequences-and-series', 'complex-analysis']"
675089,"If $\lvert f(x)\rvert\leq \lvert x\rvert^2$, then $f$ is differentiable at $0$",Let $f:\Bbb{R}^2\to\Bbb{R}$ be a function such that $\lvert f(x)\rvert\leq \lvert x\rvert^2$. Show that $f$ is differentiable at $0$. My solution: We want to show that $$\lim_{h\to 0}\dfrac{f(h)-f(0)}{ h}$$ exists. By assumption $f(0)=0$ and $$\dfrac{\lvert f(h)\rvert}{\lvert h\rvert}\leq\dfrac{\lvert h\rvert^2}{\lvert h\rvert}=\lvert h\rvert$$. So by the $\epsilon-\delta$ definition the result follows. Is this correct?,"['calculus', 'real-analysis', 'limits']"
675122,$1/2$ or $1$? probability that all bacteria will die,"Suppose there is a bacterium in a bottle, it has $\frac{1}{3}$ chance to die and it has $\frac{2}{3}$ chance to split into 2 individuals, and the new individuals will follow this rule and so on. So here is the question, what is the probability that all bacteria are dead in the bottle? Denote by p the probability that all the bacteria are dead.
$$ p =\frac{1}{3}+\frac{2}{3}p^2$$ and it gives that 
$p = 0.5$ or $1$, so what is the next step? Which one is the answer? thanks.",['probability']
675145,"Simplicial Complexes, Triangulation general question.","I am taking a first course in topology, and I am struggling with simplicial complexes. Specifically the triangulation of subspaces of $ \mathbb{R}^n $ confuses me. If you could help me on the following points I would be very grateful. In general how do you construct a triangulation of a subspace? I have been given a very basic example, where the 2-sphere is triangulated, but how do we go about doing this for more complicated subspaces, such as the ""Dunce hat"" space? Additionally how do we prove or disprove the existence of such a triangulation? Do you have any book recommendations which would help with triangulation specifically and with simplicial complexes in general? EDIT: drew a picture for barycentric subdivison, but drawing it took ages. will find an easier way for the next one. Clearly this does not give a simplicial complex. I can see how the next subdivison does.","['general-topology', 'algebraic-topology', 'triangulation']"
675161,Dirichlet series expansion?,"When an analytic function $f(x)$ is given, we can easily obtain the coefficient of $x^n$ in a power series expansion of it. I'd like to know if there exists something similar for Dirichlet series. Is there a systematic way to get the coefficient of $n^{-x}$ when a function $f(x)$, if it can be represented as a Dirichlet series, is given?","['generating-functions', 'analysis']"
675164,Moduli space of isogeny classes of elliptic curves,"The modular curve $Y(1)$ classifies isomorphism classes of elliptic curves, namely its $K$-points for any field $\mathbb Q\subseteq K\subseteq \mathbb C$ correspond via the $j$-invariant to $\mathbb C$-isomorphism classes of elliptic curves defined over $K$. My question is: what if one wants to classify isogeny classes of elliptic curves defined over $K$? Is there an appropriate moduli space for that? Namely, is there an algebraic variety $Y$ whose $K$-points correspond functorially to $\mathbb C$-isogeny classes (or even better $K$-isogeny classes) of elliptic curves defined over $K$?","['algebraic-geometry', 'elliptic-curves', 'moduli-space']"
675167,Why topology is called Rubbersheet Geometry?,"Usually topology classes starts with comparing doughnut and tea cup. But after introductory class teacher will move to the definition of topology as a collection of subsets of a set having certain properties..
At what point does this meet with our ""rubber sheet geometry""",['general-topology']
675171,Limit of a function by definition $\lim\limits_{x\to0} \frac{x^2-1}{2x^2-x-1}=1$,"Prove, using the the $(\varepsilon-\delta)$ definition of limit that: $$\lim_{x\to0} \frac{x^2-1}{2x^2-x-1}=1$$ What I've tried so far: By the $\varepsilon-\delta$ definition of a limit $$0<|x|<\delta\implies\bigg|\frac{x^2-1}{2x^2-x-1}-1 \bigg|<\varepsilon$$ so I'm trying to express the RHS in terms of $|x|$: $$\bigg|\frac{x^2-1}{2x^2-x-1}-1\bigg|\iff\bigg|\frac{-x^2+x}{2x^2-x-1}\bigg|\iff\frac{|x||x-1|}{|2x+1||x-1|}\iff\frac{|x|}{|2x+1|}<\frac{\delta}{|2x+1|}$$ I know I should somehow get rid of the variable $x$ by making an estimation on $|2x+1|$. If I estimate that: $|2x+1|>\frac12$ which holds for $x\in(-\infty,-\frac34)\cup(-\frac14,+\infty)$ I get: $$\frac{\delta}{|2x+1|}<\frac{\delta}{\frac12}=2\delta$$So then $\delta=\frac\varepsilon2$. Is the esimation justified? Should I also find a suitable $\varepsilon$ for the interval $(-\frac34, -\frac14)$? Or maybe there is anoher method on proving the statement. I'd appreciate some suggestions on how to proceed or correct my proof.","['epsilon-delta', 'limits']"
675195,"Measure theory, probability, tail events.","I have a problem with tail events. At the top of page 19 of Stefan Grosskinsky's lecture notes , it is pointed out that $A := \{\omega: \lim_{n\rightarrow\infty}X_n(\omega) \text{ exists}\}$ is a tail event, where $(X_n)_{n \in \mathbb{N}}$ are random variables defined on probably space $(\Omega, \mathcal{A}, \mathbb{P})$, taking values in $(\mathbb{R}, \mathcal{B})$, where $\mathcal{B}$ is the Borel $\sigma$-algebra on $\mathbb{R}$. Refer to bottom of page 18 for the definition of tail events. While this certainly sounds intuitive, I wanted to see if I can show more rigorously how this is true. I need to show that $$\forall M \in \mathbb{N}, \quad A \in \mathcal{T}_M,$$ where $\mathcal{T}_M := \sigma(X_{M+1}^{-1}(\mathcal{B}), X_{M+2}^{-1}(\mathcal{B}), \ldots)$. I realise the following. \begin{equation*} \begin{split} A &= \{\omega: \exists c \in \mathbb{R}, \forall \epsilon > 0, \exists N \in \mathbb{N}, \forall n > N, X_n(\omega) \in (c-\epsilon, c+\epsilon)\} \\ &= \bigcup_{c \in \mathbb{R}} \bigcap_{\epsilon > 0} \bigcup_{N \in \mathbb{N}} \bigcap_{n > N} X_n^{-1}(c-\epsilon, c+\epsilon). \end{split} \end{equation*} After a long night's struggle I managed to convince myself of the following. I will skim the details for now but please do ask me for more detail if you're interested. Certainly $X_n^{-1} (c-\epsilon, c+\epsilon) \in X_n^{-1}(\mathcal{B})$ for each particular $n \in \mathbb{N}$. So for a particular $N \in \mathbb{N}$, we have $\bigcap_{n>N}X_n^{-1}(c-\epsilon, c+\epsilon) \in \sigma(X_{N+1}^{-1}(\mathcal{B}), X_{N+2}^{-1}(\mathcal{B}), \ldots) := \mathcal{T}_N$, by definition of $\sigma$-algebra (in particular the closure of $\sigma$-algebrae under countable intersections). Notice that $\bigcap_{n>N}X_n^{-1}(c-\epsilon, c+\epsilon)$ tends \emph{up} as $N \rightarrow \infty$. So $$\bigcup_{N\in\mathbb{N}} \bigcap_{n>N}X_n^{-1}(c-\epsilon, c+\epsilon) = \lim_{N \rightarrow \infty} \bigcap_{n>N}X_n^{-1}(c-\epsilon, c+\epsilon),$$ and so it is certainly a member of $\mathcal{T}_M$ for any finite $M \in \mathbb{N}$. So far so good, we have shown that $\forall M \in \mathbb{N}$, $\bigcup_{N\in\mathbb{N}} \bigcap_{n>N}X_n^{-1}(c-\epsilon, c+\epsilon) \in \mathcal{T}_M$. Now we only need to deal with the $\bigcap_{\epsilon>0}$ and the $\bigcup_{c \in \mathbb{R}}$, bearing in mind however that $\sigma$-algebrae are closed under \emph{countable} intersections and unions, and that $\bigcap_{\epsilon>0}$ and $\bigcup_{c \in \mathbb{R}}$ are uncountable union and intersection. I can see that the intersection $\bigcap_{\epsilon > 0}$ can be changed to a countable intersection $\bigcap_{\epsilon \in \mathbb{Q}, \epsilon > 0}$ without changing the set. That is, for a fixed $c \in \mathbb{R}$, we have $$\bigcap_{\epsilon > 0} \bigcup_{N \in \mathbb{N}} \bigcap_{n > N} X_n^{-1}(c-\epsilon, c+\epsilon) = \bigcap_{\epsilon \in \mathbb{Q}, \epsilon > 0} \bigcup_{N \in \mathbb{N}} \bigcap_{n > N} X_n^{-1}(c-\epsilon, c+\epsilon).$$ Again, please ask me for details if you're interested but I won't go into it here. Now comes the key point. First (for short-hand notation) define $$A_c := \bigcap_{\epsilon > 0} \bigcup_{N \in \mathbb{N}} \bigcap_{n > N} X_n^{-1}(c-\epsilon, c+\epsilon)$$ for each $c \in \mathbb{R}$. I can't turn the \emph{uncountable} union $\bigcup_{c \in \mathbb{R}}$ into a \emph{countable} one. That is, it seems to me that $$\bigcup_{c \in \mathbb{R}} A_c \neq \bigcup_{c \in \mathbb{Q}} A_c.$$ For example, think about the event that $X_n$ tend to an irrational number. So it seems to me that, at least from this analysis, we cannot say that $A := \{\omega: \lim_{n\rightarrow\infty}X_n(\omega) \text{ exists}\}$ is a member of $\mathcal{T}_M$ (or indeed the tail $\sigma$-algebra $\mathcal{T}$). At most we can say that $\{\omega: \lim_{n\rightarrow\infty}X_n(\omega) \text{ exists in }\mathbb{Q}\}$ is a member of $\mathcal{T}_M$ for every $M \in \mathbb{N}$ (and so is in $\mathcal{T}$). Am I wrong? Is my analysis wrong? Please feel free to ask me to expand on any part of this. This is a long and complicated (tedious rather) question I know. I'd really really appreciate any help. Thank you very much for your time!","['measure-theory', 'probability']"
675196,"Answer Says $\lim_{(x,y)\rightarrow(0,0)}\frac{x^3y^2}{x^4+y^6} = 0$. I say DNE. What did I do wrong? [duplicate]","This question already has answers here : Does the limit $\lim_{(x,y)\to (0,0)} \frac {x^3y^2}{x^4+y^6}$ exist (2 answers) Closed 8 years ago . I was asked to find 
$$\lim_{(x,y)\rightarrow(0,0)}\frac{x^3y^2}{x^4+y^6}$$ Observe that setting y=mx results in $$\lim_{(x,mx)\rightarrow(0,0)}\frac{x^3(mx)^2}{x^4+(mx)^6} = 0$$
The textbook solution then proved that the limit is 0 using the squeeze theorem. However, I tried to set y=x^(4/6) and I got:
$$\lim_{(x,y)\rightarrow(0,0)}\frac{x^3(x^{\frac{4}{6}})^2}{x^4+(x^{\frac{4}{6}})^6} = \lim_{x\rightarrow0}\frac{x^4}{x^4+x^4} = \frac{1}{2}$$ So I concluded that the limit does not exist. 
I am not convinced that my solution is correct, I would really appreciate to know the reason why I am wrong. Thank you","['multivariable-calculus', 'calculus', 'limits']"
675239,$AB=BA$ implies $AB^T=B^TA$ when $A$ is normal,"I am looking for an elementary proof (if such exists) of the following:
$$
AB=BA \quad\Longrightarrow\quad AB^T=B^TA,
$$
where $A$ and $B$ are $n\times n$ real matrices, and $A$ is a normal matrix, i.e., $AA^T=A^TA$  - it is true for complex matrices as well, with $A^T$ replaced by $A^*$. There is a non-elementary proof of this using the exponential of a matrix and properties of entire functions. Update. In the first version of the question, both $A$ and $B$ were supposed to be normal, but as Shlomi correctly pointed out, this is true even in the case when only one of them is normal.","['matrix-equations', 'matrices', 'matrix-calculus', 'linear-algebra']"
675258,Using Cauchy integral formula to calculate $\int_\gamma \frac{\cos{z}}{z^n}$,"Let $\gamma(\vartheta)=\mathrm{e}^{i\vartheta},\,\vartheta\in[0,2\pi]$, and consider the integral $$I(n)=\int_\gamma \frac{\cos{z}}{z^n},$$ where $n\in \{0,2,4,6,...\}$. Is there any way to prove that $I(n)=0$ for all $n$, only by looking at the integral formula of Cauchy for $\cos{z}$ and the winding number of $\gamma$, i.e. only by looking at the expressions $$\int_\gamma \frac{\cos{z}}{z},\ \int_\gamma\frac{1}{z}$$ Remark: by expanding $\cos{z}$ in series, I know how to calculate $I(n)$. My question is whether it is possible to avoid this way.","['residue-calculus', 'complex-analysis', 'contour-integration']"
675271,Hahn-Banach separation theorem for Hilbert spaces,What is the strongest form of the Hahn-Banach separation theorem for Hilbert spaces? Could you please provide a reference?,"['convex-analysis', 'hilbert-spaces', 'functional-analysis']"
675274,Three Fundamental Principles,"How many different pizzas can be ordered if a pizza can be selected with any combination of the following ingredients: anchovies, ham, mushrooms, olives, onion, pepperoni, and sausage? Can someone give me a hint to this question.",['discrete-mathematics']
675277,Proving increasing function defined as bivariate normal,"Suppose $c>0,\sigma>0$ and $\tau>0$ are fixed real constants. Then I'd like to prove that the function $g_c:(-1,1)\mapsto\mathbb{R}$
 defined by
 \begin{equation}
 g_c(\rho)=\int_{-\infty}^\infty\int_{-\infty}^\infty\frac{ \{(-c)\vee x \wedge c\} \{(-c)\vee y \wedge c\}}{\sqrt{2\pi(1-\rho^2)}\sigma\tau}
 e^{-\frac{\sigma^2x-2\rho\sigma\tau xy+\tau^2y^2}{2(1-\rho^2)\sigma^2\tau^2}}dxdy
 \end{equation}
 is strictly increasing. I have tried to prove by differentiating $g_c$ w.r.t. $\rho$. But, this doesn't help because the result is very ugly. Can anyone help me? Thanks in advance PS: The function $g_c$ can be rewritten as $g_c(\rho)=E( (-c)\vee [(X_{\sigma,\rho}Y_{\tau,\rho})\wedge c])$ for some random variable $(X_{\sigma,\rho},Y_{\tau,\rho})^T\sim N_2(0,\Sigma)$ where
 $$
 \Sigma=
\begin{pmatrix}
\sigma^2 & \rho\sigma\tau \\
\rho\sigma\tau & \tau^2
\end{pmatrix}.
$$
But, I also don't know how to see my problem using this fact.","['probability-theory', 'random-variables', 'functions']"
675279,An inequality question,"The question says that $x > 0$ and then we have to prove that $(x + 1)^{1/2} < 1 + (1/2)x$.
I tried this question and proved  that  $(x + 1) < (1 + (1/2)x)^2$ but after this I am not able to proceed because  I can't do square root in both sides  because this will not be true for fractions and decimals.",['algebra-precalculus']
675285,Continuous real-valued functions on the first uncountable ordinal,"It is a continuation to this question. Let $X$ be the ordinal space $[0,\Omega)$ , with the order topology, where $\Omega$ is the first uncountable ordinal. Let $f\colon X \rightarrow \mathbb R$ be a continuous, real-valued function on $X$ . Can we conclude that $f$ is constant on some interval $(\alpha,\Omega)$ , where $\alpha$ is a countable ordinal?","['general-topology', 'ordinals']"
675292,Determinant of 4x4 Matrix by Expansion Method,"Find det(B) = \begin{bmatrix} 2 & 5 & -3 & -2 \\ -2 & -3 & 2 & -5 \\ 1 & 3 & -2 & 0 \\ -1 & -6 & 4 & 0 \\ \end{bmatrix} I chose the 4th column because it has the most 0s. Using basketweave, I solved for the determinants of the minor 3x3 matrices of entry B 14 and B 24 . det(B 14 ) = \begin{bmatrix} -2 & -3 & 2 \\ 1 & 3 & -2 \\ -1 & -6 & 4 \\ \end{bmatrix} det(B 14 ) = (-24 - 6 - 12) - (-12 - 24 - 6) = -42 - (-42) = 0 det(B 24 ) = \begin{bmatrix} 2 & 5 & -3 \\ 1 & 3 & -2 \\ -1 & -6 & 4 \\ \end{bmatrix} det(B 24 ) = (24 + 10 + 18) - (20 + 24 + 9) = 52 - 53 = -1 I have checked with a matrix calculator and the the determinants of the 3x3 minor matrices are correct. To find the det(B), I multiplied B 14 by det(B 14 ) and B 24 by det(B 24 ) and followed the + - + - pattern as showed by the formula here (scroll below for 4x4 formula). The rest will be 0s anyway. det(B) = [-2(0)] - [-5(-1)] + [0] - [0] = -5 Checking again with the matrix calculator, the correct answer is +5 . I am confused as to how the signs apply. How did det(B) arrive to +5?","['matrices', 'linear-algebra', 'laplace-expansion', 'determinant']"
675293,Correct standard form for the equation of a line?,"So I was tutoring an Algebra 1 student yesterday and we were reviewing the three forms in which one can write the equation for a line: point-slope form, slope-intercept form and standard form. I told him to write an equation in standard form and he wrote: $\frac x5 + \frac y4 = 1$ and I told him to rewrite it without any fractions as $4x +5y = 20$ Are both forms correct? I understand that the latter form may be more common but what I really want to know is if it is acceptable to use the former. Thanks all!",['algebra-precalculus']
675364,Relationship between a class of non-linear differential equations and algebraic geometry.,"I was just thinking about non-linear differential equations of a single variable, $F(f(x))=0$ that are polynomial in the derivatives of $f$.  For example: $$ 2\left(\frac{d^3f}{dx^3}\right)^5 - \frac{1}{7}\left(\frac{df}{dx}\right)^2  + \frac{d^2f}{dx^2} = 0$$ This can be considered as a polynomial in three variables, $x,y,$ and $z$: $$ 2x^5 - \frac{1}{7}y^2  + z = 0$$ This polynomial has a set of roots that has various properties which it derives from algebraic geometry, and my question is: Can someone explain what sort of things from algebraic geometry influence the solution set of the original differential equation? Thanks! P.S. I found this , but it's a pretty hard paper so it's gonna take awhile to work through anything, is this paper relevant to my question?","['ordinary-differential-equations', 'algebraic-geometry']"
675390,Euler characteristic of a Y-shaped pipe?,"I'm familiar with the idea in topology that shapes that can be continuously deformed into one another are considered ""equivalent"". I read about the Euler Characteristic as being Vertices-Edges+Faces. Thinking of this number as related to the genus of an object, and the genus as the number of holes it has (which is probably where I'm going wrong), I began wondering what the Euler number or genus of a Y-shaped pipe (see below) would be, having three openings that all converge together. Y-shaped pipe: Thanks in advance for any help!","['general-topology', 'algebraic-topology']"
675417,How can I integrate this zeta function expression?,"Can you integrate this function: $$f(k)=\exp\left(-\Re\left(\sum\limits_{n=1}^{n=scale} \frac{1}{n} \zeta(1/2+i \cdot k)\sum\limits_{d|n} \frac{\mu(d)}{d^{(1/2+i \cdot k-1)}}\right)\right)$$ with respect to $k$? The result I would like to achieve is the plot from the accumulated function as in this Mathematica program: (*program start*)
scale = 300;
Print[""Counting to 60""]
Monitor[g1 = 
   ListLinePlot[
    0.69*Accumulate[
      Table[Exp[-Re[
          Zeta[1/2 - I*k]*
           Total[Table[
             Total[MoebiusMu[Divisors[n]]/
                Divisors[n]^(1/2 - I*k - 1)]/n, {n, 1, scale}]]]], {k,
         0 + 1/1000, 60, N[1/6]}]], DataRange -> {0, 60}, 
    PlotRange -> {-0.15, 15}];, Floor[k]]
Show[g1, ListPlot[Table[{N[Im[ZetaZero[n]]], n}, {n, 1, 13}], 
  PlotStyle -> Black, Filling -> Axis]]
(*program end*) The function jumps about one unit at $k$ values equal to zeta zeros.","['complex-numbers', 'riemann-zeta', 'elementary-number-theory', 'integration']"
675423,Validity of my weird proof that $AB$ and $BA$ have the same eigenvalues?,"On a recent linear algebra exam, I was required to prove that ""for every $n \times k$ matrix $A$ and $k \times n$ matrix $B$ over the same field, it holds that $AB$ and $BA$ have the same eigenvalues except for 0."" This is a classic result and I really should have known better, but for some reason the only proof I could come up with is the following. It's kind of uncanny (the examiner rejected it), but I think it might be valid anyway. Am I correct? Proof: Let $M_{AB}(t)$ and $M_{BA}(t)$ be the minimal polynomials of $AB$ and $BA$ respectively. It holds that: $M_{AB}(AB)=0$. Therefore: $B \cdot M_{AB}(AB)=0$ $M_{AB}(BA) \cdot B=0$ $M_{AB}(BA) \cdot BA=0$ So we see that $BA$ is a zero of the polynomial $M_{AB}(t) \cdot t=0$. Therefore, $M_{BA}(t)\: |\: M_{AB}(t)\,t$, which means that $M_{BA}(t)$ and $M_{AB}(t)$ share the same irreducible factors except possibly for $t$, and the claim follows. $\square$ Please note: I know that this result has been addressed many times on this site, but I didn't find my proof anywhere, so I think this isn't a duplicate.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'proof-verification']"
675438,Nice Arctan Identity,"Prove that $ \text{arctan}\left(\frac{a+d}{c}\right)=2\text{arctan}\left(\frac{a}{c}\right) $ if $a, d, c$ are positive reals satisfying $$ a^4+a^2c^2+a^2d^2+2a^3d = c^2d^2 $$ (credit: bobthesmartypants)",['trigonometry']
675442,Prove the int(int(S)) = int(S),"I had a question on what exactly I need to show in proving that the interior of the interior of a set is equal to the interior of a set. I'm given a set $A\subset X$, where $X$ is a topological space, and I want to show $int(A) = int(int(A))$, where $int(A)$ is defined as the union of all open sets contained in $A$. Is the following proof valid? Let $\mathcal{O}$ be the set of all open sets $O\subset A$ and $\mathcal{G}$ be the set of all open sets $G\subset int(A)$. We will show that if $S\in \mathcal{O} \implies S\in \mathcal{G}$. Suppose $S$ is open, $S\subset A$. Then $\forall x\in S, \exists \epsilon > 0$ s/t $N_{\epsilon}(x)\subset S$. By definition of $int(A)$, $int(A) = \cup_{O\in \mathcal{O}} O$, so in particular $S\subset int(A)$. But then $N_{\epsilon}(x)\subset S$ still holds so $S$ is open in $int(A)$, and therefore if $O\in \mathcal{O} \implies O\in \mathcal{G}$. Then the union of all $O$ in $\mathcal{O}$ is in the union of all $G\in \mathcal{G}$, so that $int(A) \subset int(int(A))$ Going the other way, if $S\subset int(A)$ and $S$ is open, then $\forall x\in S, \exists \epsilon > 0$ s/t $N_{\epsilon}(x)\subset S$. Since $int(A) \subset A$, $S\subset A$ and so $N_{\epsilon}(x)\subset S$ still holds, so $S$ is open in $A$, then $G\in \mathcal{G} \implies G\in \mathcal{O}$, so the union of all $G\in \mathcal{G}$ is in the union of all $O\in \mathcal{O}$, so $int(int(A))\subset int(A)$, and each is a subset of the other so they are equal. Any help would be great. Thanks!",['general-topology']
675459,Expected Value of 10000 coin flips,"We toss a fair coin 10000 times and record the sequence of the results. Then we count the number of times that a sequence of 5 heads in a row followed immediately by 5 tails in a row has occurred among these results. (Of course, this number is a random variable.) What is the expected value of this number? Enter your answer as a decimal or a fraction, whichever you prefer. I have made some progress on it but granted I have one attempt left I didn't want to mess this up. I have determined that for 5 heads, and for 5 tails to occur in ten tries, the probability is 0.0009765625 with an expected value as well. My line of thinking was since we can't expect to get this sequence occur until the 10th try, the expected value of flipping 10,000 times would be 9990*0.0009765625  but this was wrong. I feel I'm very close since for any sequence of ten tries, the expected value will be 0.0009765625","['statistics', 'probability']"
675472,Lock combinatorics [duplicate],"This question already has an answer here : The 6 generals problem (1 answer) Closed 10 years ago . 'Six generals propose locking a safe containing top secret information with a number of different locks. Each general will be given keys to certain of these locks. How many locks are required and how many keys must each general have so that, unless at least four generals are present, the safe cannot be opened?' I suspect this question is more complicated than my interpretation of the language. To me the answer seems to be that if each general is given n keys, there must be 3n+1 locks. This is because in the 'worst-case' scenario where each has n distinct keys, 3 generals can open 3n locks.
Perhaps this is a gross simplification, but if anyone cares to comment that would be a great help!",['combinatorics']
675473,Why does the Cauchy distribution have no mean if it's symmetric around 0?,"Something that didn't make intuitive sense to me when learning about the Cauchy distribution was that there was no defined mean for the function, even though the function was clearly centered at zero and equally valued in both directions. Is there any reason for this?","['probability-distributions', 'probability']"
675474,What is the practical impact of a matrix's condition number?,"Let's say I am trying to solve a square linear system
$Ax = b$
for whatever reason. A perturbation $\delta b$ in $b$ will lead to a perturbation $\delta x$ in $x$, whose relative norm is bounded by the condition number of A $\kappa (A)$ according to
$$\frac{||\delta x||}{||x||} \leq \kappa(A) \frac{||\delta b||}{||b||}. \tag{1}$$
If the only error/uncertainty of $b$ is due to rounding errors caused by floating point operations, then I am fine as long as $\kappa(A)$ is significantly smaller than the inverse of machine epsilon $\epsilon_\text{mach}$ (right?). But it seems to me that for many (most?) applications, there will be relative errors in $b$ on an order of magnitude much greater than $\epsilon_\text{mach}^{-1}$. An average relative error of $10^{-3}$ in $b$ seems commonplace (for some applications, even $10^{-1}$ is to be expected). Condition numbers on the order of $10^3$, or even $10^6$, also seem very common, especially when the dimensions of $A$ are large. So what does this mean? If $\kappa(A) > 10^3$, I have to make sure that my relative error in $b$ is less than $10^{-3}$, preferably less than $10^{-5}$, in order to get any kind of significance in my computations when solving for $x$? Or are you going to tell me that since Equation $(1)$ is only a worst-case scenario, this will usually not be a problem? After fooling around with random matrices in MATLAB however, it seems to me that the ""average"" scenario usually is not that far from the worst-case scenario. I realize that the answer to this question probably is very problem dependent, but it seems to me that this would be a very frequent problem in practice, and yet in engineering education it is only ever discussed in math courses, and even in those courses there is not much emphasis on this seemingly severe and common problem.","['matrices', 'numerical-linear-algebra', 'condition-number']"
675475,"stats - calculate marginal pdf of $f(x,y)$ - limits of integration?","I have the following equation $$
f(x,y) = \frac{2}{x^2 (x-1) y^{(2 x-1)/(x-1)}}
\quad \forall x>1, y>1
$$ I am trying to find that marginal pdf w.r.t. $x$, $f_X(x)$. Normally I would just take $\int f(x,y) dy$ using $x$'s domain as limits, aka over $[1, \infty)$. But that integral won't converge here. What am I doing wrong? This problem should be solve-able.",['statistics']
675481,"If $f,g$ are continuous at $a$, show that $h(x)=\max\{f(x),g(x)\}$ and $k(x)=\min\{f(x),g(x)\}$ are also continuous at $a$","If $f,g$ are continuous at $a$, show that $h(x)=\max\{f(x),g(x)\}$ and $k(x)=\min\{f(x),g(x)\}$ are also continuous at $a$. Here is my attempt at a proof. It feels very elaborate and I am not sure if it is correct. Can someone please point out any mistakes or places where I may improve. Thanks! By the definition of continuity at $a$ of $f,g$ we have that $\lim\limits_{x\to a}f(x)=f(a)$ and $\lim\limits_{x\to a}g(x)=g(a)$. Suppose that $f(a)>g(a)$. Then there exists a $\delta>0$ such that $f>g$ for all $x$ satisfying $|x-a|<\delta$. Then for $x$ satisfying $|x-a|<\delta$ we have $h(x)=f(x)$ and $k(x)=g(x)$ and thus $h$ and $k$ are continuous at $a$ because $f$ and $g$ are continuous at $a$. Now if $f(a)<g(a)$ we simply relabel $f=\tilde{g}$ and $g=\tilde{f}$, so that $\tilde{f}(a)>\tilde{g}(a)$ and we apply the previous result to show that again $h$ and $k$ are continuous at $a$.\ Now if $f(a)=g(a)$ then we can distinguish three cases. $f\geq g$ in a small neighborhood about $a$, $f\leq g$  in a small neighborhood about $a$ or $f\geq g$ on one side of $a$ and $f\leq g$ on the other side. In the first case we assume that $f\geq g$ in some small neighborhood about $a$. Then, since $f(a)=g(a)$ we have $h(x) = f(x)$ in this neighborhood and $k(x) = g(x)$ and again we see that $h$ and $k$ are continuous at $a$ due to the continuity of $f$ and $g$ at $a$. Similarly if $f\leq g$ in a neighborhood around $a$ then $h(x)=g(x)$ and $k(x)=f(x)$ in this neighborhood and $h$ and $k$ are continuous at $a$. Suppose that just to the left of $a$ we have $f\geq g$ and just to the right of $a$ we have $f\leq g$. Then $\lim\limits_{x\to a^-}h(x)=\lim\limits_{x\to a^-}f(x)=f(a)=h(a)=g(a)=\lim\limits_{x\to a^+}g(x)=\lim\limits_{x\to a^+}h(x)$. Similarly $\lim\limits_{x\to a^-}k(x)=\lim\limits_{x\to a^-}g(x)=g(a)=k(a)=f(a)=\lim\limits_{x\to a^+}f(x)=\lim\limits_{x\to a^+}k(x)$. So $\lim\limits_{x\to a}h(x)=h(a)$ and $\lim\limits_{x\to a}k(x)=k(a)$ which means that $h$ and $k$ are continuous at $a$. Lastly if $f\leq g$ just to the left of $a$ and $f\geq g$ just to the right of $a$ we can relabel $f=\tilde{g}$ and $g=\tilde{f}$ and apply the last result to show $h$ and $k$ are continuous at $a$. Again, please point out any mistakes I may have made. Thanks!!",['real-analysis']
675500,Euler characteristic of the product,"I want to prove that Euler characteristic of the product of two compact oriented manifolds is the product of their Euler characteristics. As always I do, I'm considering Guillemin-Pollack definitions, i.e., the Euler characteristic of M, compact and oriented, $\chi(M) = I(\Delta,\Delta)$ where $\Delta$ is the diagonal of $M\times M$ and $I(\Delta,\Delta) = I(i,\Delta) =$ sum of orientation numbers of each $p\in i^{-1}(\Delta)$ using pre image orientation. Here $i:\Delta \to M \times M$ is the inclusion. Help!","['compact-manifolds', 'differential-geometry']"
675503,Very probable event occuring at least once during $n$ trials,"Assume that Bob carries eggs from point $A$ to $B$. He can carry $1$ egg each time. Let the probability that Bob breaks an egg be $0.99999$ which is almost a certain event (for me). If Bob carries $100$ eggs separately, can we say the probability of Bob breaking an egg is $0.99999 \% = 0.00999$? I am asking because $0.99999$ is a very high probability in my opinion, and changing the try count doesn't have any practical effect on the above example.",['probability']
675522,What's the intuition behind Pythagoras' theorem?,"Today we learned about Pythagoras' theorem. Sadly, I can't understand the logic behind it. $A^{2} + B^{2} = C^{2}$ $C^{2} = (5 \text{ cm})^2 + (7 \text{ cm})^2$ $C^{2} = 25 \text{ cm}^2 + 49 \text{ cm}^2$ $C^{2} = 74 \text{ cm}^2$ ${x} = +\sqrt{74} \text{ cm}$ Why does the area of a square with a side of $5$ cm + the area of a square with a side of $7$ cm always equal to the missing side's length squared? I asked my teacher but she's clueless and said Pythagoras' theorem had nothing to do with squares. However, I know it does because this formula has to somehow make sense. Otherwise, it wouldn't exist.","['geometry', 'intuition']"
675527,Prove no real number satisfies $x^{2} = -1$,"I ran a search, but, oddly enough, I can't to find a similar question on here. (If so, kindly point me in that direction, and I'll take this one down.) It seems like a pretty basic question in real analysis, but I'm struggling to come up with a suitable proof that no real number satisfies $x^{2} = -1$. I assume it's a proof by contradiction, but I'm just not seeing it.",['algebra-precalculus']
675546,Upper bound of Euclidean norm on vectors in $\mathbb{R}^n$,"Show that for any vectors $v_1,\ldots,v_n \in \{-1,1\}^n \subset \mathbb{R}^n$, there exist $\epsilon_1,\ldots,\epsilon_n \in \{-1,1\}$ such that the Euclidean norm of $v=\sum_{i=1}^n \epsilon_i v_i$ is bounded by $n$. Any help appreciated.","['probability-theory', 'discrete-mathematics']"
675555,"Show that the iterated $\ln^{[n]}$ of tetration(x,n) is nowhere analytic","$$f(x) = \lim_{n\to \infty} \ln^{[n]} x \uparrow\uparrow n$$ The conjecture is that $f(x)$ is monotonic and infinitely differentiable at the real axis, but nowhere analytic; because at each point on the real axis, the Taylor series has a zero radius of convergence.  The function is well defined at the real axis, but not as well behaved in the complex plane.  $f(x)$ is a useful function for comparing tetration for different bases, to see how much faster one base grows than another, where x can be thought of as the tetration base.  See my post, Comparison between two tetrations showing the evaulation of $f(\pi)$. How difficult would it be to show that $f(x)$ is infinitely differentiable, and nowhere analytic?  Below, is a graph of $f(x)$, showing the ""logarithmic singularity"" at the real axis near 1.805; for $x >\approx1.805$, $f(x)$ is real valued and converges nicely at the real axis. One simplification I found, also shows that $f(x)$ behaves somewhat like $\ln(x)+
\ln(\ln(x))$ as x increases.  The $x \uparrow \uparrow n$ term grows very rapidly, so that
the $\ln(\ln(x))$ term becomes insignificant in the equation below, that can be used to evaluate $f(x)$.  At the same time as the $x \uparrow \uparrow n$ term in the denominator becomes insignificant at the real axis, it becomes less and less well behaved in the complex plane. $$f_n(x) = \ln^{[n]} x \uparrow\uparrow n$$
$$f_{n+1}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) ) $$
$$f_{n+2}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) + \ln(\ln(x))) $$
$$f_{n+2}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) \times (1+ \frac{\ln(\ln(x))}{(x \uparrow\uparrow n)\ln(x)}) $$
$$f_{n+2}(x) = \ln^{[n]}  (
\exp^{on}(f_{n+1})
\times (1+ \frac{\ln(\ln(x))}{
\exp^{on}(f_{n+1})
}) $$ After this, the algebra gets messy.... but here's the next step I took.  Eventually, you get to an equation of $f_{n+2}(x) \approx f_{n+1}(x) +$ reciprical of a superexponential product. $$f_{n+2}(x) \approx  f_{n+1} + 
\frac{\ln(\ln(x))}
{ \exp^{on}(f_{n+1}) \times \exp^{on-1}(f_{n+1}) \times \exp^{on-2}(f_{n+1}) \times ... \exp(f_{n+1}) } + O\frac{1}{(\exp^{on}(f_{n+1})
)^2}$$ For this function, ""Nowhere analytic"" means the function has a well defined Taylor series at the real axis, but the Taylor series has a zero radius of convergence, so that that the function is not equal to its Taylor series. This is because the Taylor series terms eventually grow faster than any exponential series, so that for any value of r you pick, for n large enough, $|a_n|>r^n$, or equivalently, $\ln(|a_n|)>n\ln(r)$. I think the key to showing this is to look at the function $f_n(x)-f_{n-1}(x)$, as n increases. In the complex plane, $f_6(x)$ has a singularity near x=1.96219034541054 + 0.254713677298596i.  The $f_6$ singularities occur where $\exp^{4}(f_{5})
 =-\ln(\ln(x))$.  As x gets larger, the singularities get closer to the real axis, and
also, as n gets larger, the singularities get closer to the real axis.","['tetration', 'power-towers', 'real-analysis', 'analyticity', 'complex-analysis']"
675587,Maximum size of a bipartite subgraph on a random graph,"Show that almost every $G \in \mathscr{G}(n,\frac{1}{2})$ contains no bipartite subgraph with more than $\frac{n^2}{8} + n^{\frac{3}{2}}$ edges. Tried using Markov's inequality by setting a = $\frac{n^2}{8} + n^{\frac{3}{2}}$, but I got that the probability is less than or equal to 1, which doesn't help.
By almost every $G$ I mean that as $n$ tends to infinity the probability of the bipartite subgraph having more than $\frac{n^2}{8} + n^{\frac{3}{2}}$ edges tends to 0. May have something to do with finding a threshold function for bipartite graphs (might not).","['graph-theory', 'discrete-mathematics', 'random-graphs']"
675598,Limit point of isolated singularities,"Suppose $f$ is analytic on $\mathbb{C}$ (or some open domain) except at a sequence $(c_n)$ and its limit point $c$. If each $c_n$ is a removable singularity, what can we say about $c$? While $c$ was not an isolated singularity for $f$, it becomes isolated once we remove the $c_n$'s, right? Is $c$ now necessarily a certain type of isolated singularity, or it can be either removable, pole, or essential? What about when $a_n$'s are all poles or all essential, can we say anything about the singularity $c$? For example, is $f$ necessarily unbounded near $c$?",['complex-analysis']
675626,Is there a systematic way to detect overcounting in simple combinatorics?,"TL;DR : In simple combinatorics problems, is there a systematic way to detect overcounting before computing the counts and comparing them? Is it simple enough to be taught to undergrads: At my university, we teach ""Finite"", a terminal math course for non-majors. It's very popular --- ""popular"" --- since it's required for gen ed and the business school. Roughly a quarter of the course is devoted to simple combinatorics. Here's a standard type of question: You have a standard deck of playing cards (fifty two cards, four suits of thirteen cards each). You draw a hand of five cards. How many ways are there of drawing at least one card from each suit? The correct answer is $C(4,1)C(13,2)C(13,1)^3$: First choose one suit to draw two cards from, then choose two cards from that suit, then choose one card from each of the remaining three suits. However, if a student hasn't set the problem up quite correctly but still groks the basic idea of coming up with a method for selecting the hand and counting from it, they might think: First I'm going to draw one from each suit and then draw one from the remaining cards: $C(13,1)^4C(48,1).$ Problem : The second method double-counts every outcome. Here's another standard sort of question: You have five pens, four erasers, and three pencils. You draw three of them. How many ways are there of drawing at least two erasers? The correct answer is $C(4,2)C(8,1) + C(4,3)$, since you can either draw two erasers and one other thing, or you can draw three erasers. However, a student might think: I'll draw two erasers, and then I'll draw one of the remaining ten things: $C(4,2)C(10,1)$. Problem : The second method overcounts by eight. These two overcounts are typical student mistakes. They're very subtle. They're of two different types -- one is a multiplicative overcount and another is an additive overcount. And I can't figure out how to quickly tell whether a method (e.g. ""draw one from each suit, then draw a fifth card"") will lead to an overcount. The best I can come up with is ""do the problem correctly and compare the answer with the number they got."" What I'd like to do is figure out how to tell whether a method for finding an answer is an overcount without actually having to compute the number it gives and compare that to the correct count. I thought about this for a while, talked with another teacher, and we couldn't figure out how to teach students to identify and correct these mistakes. Of course, the first priority is teaching students to correctly break down the problem, but after that, it wasn't clear to us how best to instruct students to be aware of and correct these subtle counting errors. Question : Is there a systematic way to catch and correct overcounting errors in simple combinatorics?","['education', 'combinatorics']"
675646,if there are 5 points on a sphere then 4 of them belong to a half-sphere.,"If there are 5 points on the surface of a sphere, then there is a closed half sphere, containing at least 4 of them. It's in a pigeonhole list of problems. But, I think I have to use rotations in more than 1 dimension. Regards","['geometry', 'pigeonhole-principle']"
675674,A Curious Identity,"I met the following equations when I was trying to solve a complex line integral (W.Rudin, RCA, p.228 ex.13). My question is how to prove them: We have to show that for $n>2$ even $$
2^{n/2}\prod^{\left(n - 2\right)/2}_{k = 1}
\left[1 - \cos\left(2k\pi \over n\right)\right] = n,
$$ and for $n>1$ odd, $$
2^{\left(n - 1\right)/2}\prod_{k = 1}^{\left(n - 1\right)/2}
\left[1 - \cos\left(2k\pi \over n\right)\right]
=n\text{ ?}$$ -This can be rewritten as a curious identity after the below hint of Greg Martin- Thx.","['complex-analysis', 'real-analysis']"
675678,Probability of Coin Game,"Suppose we play the following game. We take turns tossing a fair coin, and whoever is the first to reach $2$ heads (not necessarily in a row) wins. You go first. Draws are not allowed, so for example, if you flip heads, then I flip heads, and then you flip heads again, you win (I don't get a chance to toss the coin again).
What is the probability that you will win the game? Enter your answer as a fraction, such as $\frac23$. I'm not sure how to approach this. I understand the probability of getting a head on the first two tries is $\frac14$. I also understand that the first person who goes should have better odds.  Just not sure how to approach this with infinite turns until you get two heads.","['statistics', 'probability']"
675680,Proof involving the infinite number of primes,"Given that $R = p_1p_2\cdots p_n + 1$ where $p_1 < p_2 < \cdots  < p_n$ and $p$ are prime numbers. Prove that if $R$ is not prime then $R$ must have a prime factor $q$ that is larger than $p_n$ . I directly understand that this question refers to Euclid's infinite primes proof however; Honestly, I don't know really how to even begin this problem. Any advice on this problem would be very helpful and appreciated.",['discrete-mathematics']
675773,How to think of the Zariski tangent space,"The Zariski tangent space at a point $\mathfrak m$ is defined as the dual of $\mathfrak m/\mathfrak m ^2$. While I do appreciate this definition, I find it hard to work with, because we are not given an isomorphism from $\mathfrak m/\mathfrak m^2$ to $(\mathfrak m/\mathfrak m ^2)^\vee$ (which I'd wish for at least in the finite dimensional case so that I could put my hands on something concrete). So my question is: how does one go from this abstract definition to actually writing down what is the $T_{X,p}$ as a scheme? To take a simple case, we might consider $$X=k[x,y,z]/(x+y+z^2,x+y+z^3); \qquad p=(x-0,y-0,z-0)$$ Then, the cotangent space is easy to calculate. It is the plane cut out by $x+y$, i.e. it is the scheme $k[x,y,z]/(x+y)$. But what is the tangent space as a scheme?","['algebraic-geometry', 'schemes']"
675787,How many ways to split n elements in k groups? [duplicate],"This question already has an answer here : Counting ways to partition a set into fixed number of subsets (1 answer) Closed 10 years ago . The order of the groups does not matter The size of group must be at least 1 For example, in a more specific question How many ways to split 5 number in 2 groups? , we got the answer 15 from Jared, which is the sum of 5 ways to split in group size 1 and 4, and 10 ways to to split in group size 2 and 3. For more general cases, what is the formula to calculate this?","['permutations', 'combinatorics']"
675826,Prove that matrices of the form $\begin{pmatrix} x & x \\ x & x \end{pmatrix}$ are a group under matrix multiplication.,"G is the set of matrices of the form $G=$$\begin{pmatrix} x & x \\ x & x \end{pmatrix}$.
So for this set to be a group I know it needs to be: Closed under matrix multiplication The Associative Property holds Contains an Identity Element Every element needs to have an inverse So the form of the matrices is such that all the elements are the same but not 0. How do I go about proving these? Working through this problem, I seem to have hit a contradiction. Since G is a subgroup of the bigger $2x2$ nonsingular matrices group why does G not have the same identity element as its parent group? Namely \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} Isn't the subgroup supposed to have the same identity element as its parent group?","['matrices', 'linear-algebra', 'group-theory', 'abstract-algebra']"
675833,find the distance between 2 functions,f(x) = $e^x$. g(x) = $.5(e-1/e) + 3x/e$. How do you find||f-g||. The inner product is defined as $\int_{-1}^1 f(x)g(x) dx$. I've tried this: $\int_{-1}^1 (e^x - (.5(e- e^{-1} + 3x/e)))^2dx$. This does not give the right answer of 1 -7e^-2.,"['orthogonal-polynomials', 'inner-products', 'functions']"
675839,"If the ring map $f: A\rightarrow B$ is integral, fibres of $f^*$ are finite, then $f$ is finite?","If the ring map $f: A\rightarrow B$ is integral, i.e. $B$ is integral over the subring $f(A)$, and each fibre of the induced map $f^*: Spec(B)\rightarrow Spec(A)$ is a finite set, then should $f$ be finite (i.e., $B$ is finitely generated as an $A$-module)? This is the last part of Atiyah and Macdonald, Exercise 4 of Chapter 8. I want to use the conclusion of Exercise 15 in Chapter 5 to construct a counterexample, but failed. Also, by Exercise 12, 13 in Chapter 5, there are general ways to give examples of ring pairs $(B, A)$ such that $B$ is integral over the subring $A=B^G$, for some finite subgroup $G$ of $Aut(B)$, and each fibre of the induced map $Spec(B)\rightarrow Spec(A)$ is finite. So the point now is to give some examples such that $B$ is not finitely generated as an $A$-module. (As Benja's example below, but I cannot show his assertions.) I make a digression: Does these conditions imply that $f: A\rightarrow B$ is of finite type, i.e., $B$ is finitely generated as an $A$-algebra?","['commutative-algebra', 'algebraic-geometry']"
675842,I have a 2x2 positive-semidefinite matrix. I am trying to find the equation of its elements.,"So long story short. I have a matrix $A \in S^2_+$, that is, a symmetric, positive semi-definite 2x2 matrix. Here it is: $A = \begin{bmatrix} x & y \\y & z \end{bmatrix}$. Here is what it 'looks like' apparently. I have two problems: The first one is that I would like to find out the constraints of the $x,y$, and $z$. For example, that $x \geq0$, $z \geq0$, and the same for $y$. I do not know how to find this. I have tried multiple things like using the characteristic polynomial etc, but no dice. I know that the eigenvalues must be $\geq0$ etc, but... Once I know what the x,y and z are, I think I will be able to interpret this diagram. That is all, I appreciate any help. Thanks!","['matrices', 'symmetry', 'eigenvalues-eigenvectors', 'determinant']"
675926,Distance between point and plane,"Find the distance from the Point $A = (1,0,2)$ to the plane passing through the point $(1,-2,1)$ and perpendicular to the line given by the parametric equations: $$
\begin{align}
x & = 7, \\ 
y & = 1 + 2t, \\
z & = -3 + t.
\end{align}
$$ The answer is $\sqrt{5}$, but I can't seem to get that. I get that the plane equation ends up being $0x + 2y + z + 3 = 0$, but then when I try to compute the distance it turns out to be $\sqrt{3}/\sqrt{5}$ or something along those lines.","['multivariable-calculus', 'vectors']"
675933,Probabilistic Proof That An Absolutely Continuous Function is Differentiable Almost Everywhere,"Consider the probability space $([0,1), \mathcal{B}, \lambda)$ where $\mathcal{B}$ is the Borel $\sigma$-algebra and $\lambda$ is the uniform measure. Let $A_{i,n} = [(i-1)2^{-n}, i2^{-n})$ for $i \in \{1, 2, \dots, 2^n\}$ and $n \in \{0, 1, 2, \dots\}$. Let $\mathcal{F}_n = \sigma(A_{i,n} : i \in \{1, 2, \dots, 2^n\})$. Let $x(\cdot)$ be an absolutely continuous function on the unit interval and let $h_{i,n} = 2^n(x(i2^{-n}) - x((i-1)2^{-n}))$. Define $X_n = \sum_{i=1}^{2^n} h_{i,n} \mathbb{1}_{A_{i,n}}$. I have already shown that $\{X_n\}$ is a $\mathcal{F}_n$-martingale. The next steps are: (i) Show that $\{X_n\}$ is uniformly integrable. (ii) There exists an integrable $h:[0,1) \rightarrow \mathbb{R}$ such that
$x(t) - x(s) = \int_s^t h(u)du$ for all $0 \leq s \leq t < 1$. (iii) Using Lebesgue's Theorem, conclude that $\frac{dx}{dt} = h$ a.e. I know that once I have (i), $X_n$ will converge a.s. and in $L^1$ to $X_\infty$. I can use this to get (ii) and then use (ii) to get (iii). I know it is simple, but I'm stuck on (i).","['probability-theory', 'martingales', 'lebesgue-integral']"
675955,Mean Value Theorem help,"once again. I wish to prove that
$$\frac{2}{\pi} = \cos\left( \frac{\pi t}{2}\right) + \sin\left( \frac{\pi}{2} ( 1-t ) \right)$$ for some t in the interval $( 0, 1 )$ given the function $$f( x, y ) = \sin(\pi x ) + \cos(\pi y ).$$ I was told that I could prove it using the mean value theorem, but I am not exactly sure how to use it in this case. Thank you for your help ahead of time.",['multivariable-calculus']
675969,Measurability of the set of differentiable function in the borel sigma algebra of the continuous functions,"I was studying stochastic calculus and it came up this question of measurability: Let $\mathcal{C}=\mathcal{C}([0,1])$ be the set of continuous functions from $[0,1]$ to $\mathbb{R}$ with the uniform topology and his borel sigma algebra $\mathcal{B}$. Is the set $\{f\in \mathcal{C}: f \text{ is differentiable} \}$ in $\mathcal{B}$? Is the set $\mathcal{C}^1([0,1]) $in $\mathcal{B}$ ? Thanks!",['measure-theory']
675981,"If $A$ and $B$ are sets of real numbers, then $(A \cup B)^{\circ} \supseteq A^ {\circ}\cup B^{\circ}$","I have a proof for this question, but I want to check if I'm right and if I'm wrong, what I am missing. Definitions you need to know to answers this question: $\epsilon$-neighborhood, interior points and interiors.  Notation: $J_{\epsilon}(a)$ means a neighborhood formed around a (i.e. $(a-\epsilon, a+\epsilon)$.  An interior point in some set $A$ is a point where an $\epsilon$-neighborhood can be formed within the set.  The set of all interior points in $A$ is denoted as $A^0$ and is called the interior. My proof for the question:  I'm proving based on most subset proofs where you prove that if an element is in one set, then it must be in the other.  Say $x \in A^0 \cup B^0$.  Then there is a $\epsilon > 0$, where $J_{\epsilon}(x) \subseteq A$ or $J_{\epsilon}(x) \subseteq B$.  This implies that $J_{\epsilon}(x) \subset A \cup B$ which then implies $x \in (A \cup B)^0$.  We can conclude from here that $(A \cup B)^0 \supseteq A^0 \cup B^0$.","['general-topology', 'proof-verification', 'real-analysis']"
675991,Prove that a uniformly convergent convergent sequence of $N^\text{th}$ degree polynomials must converge to some $N^\text{th}$ degree polynomial,"So here's the question I'm trying to answer: Suppose $p_n(x) = \sum_{k=1}^N a_k^{(n)} x^k$ is a sequence of polynomials such that $p_n \to f$ uniformly over $[0,1]$ for some function $f:[0,1] \to \mathbb{R}$.  Prove that $f$ must itself be an $N^\text{th}$ degree polynomial. I've already shown that if each $a_k^{(n)} \to a_k$, then $p_n(x) \to p(x) = \sum_{k=1}^N a_k x^k$  uniformly (earlier part of the problem).  I'm thinking that there's some way to show that if $p_n \to f$, then $a_k^{(n)}$ converges for each $k$.  This certainly works for $k = 0$, since we can guarantee that the sequence $a_k^{(n)} = p_n(0)$ is Cauchy.  I've gotten stuck in trying to extend this to other coefficients; I'm thinking there's some trick involving subtracting the $a_0^{(n)}$ off and dividing by $x$, maybe some fancy induction along those lines. Other potentially helpful thoughts: we can guarantee that $f$ is continuous since it is the uniform limit of continuous functions. Remember also that we have a compact domain, so that all of these functions are bounded and achieve their max/min. Any comments, hints, or answers are very much appreciated.",['real-analysis']
676011,Curvature of a curve lying on a sphere?,"This is a sample question from a multivariate calculus class. Any insight would be appreciated. Suppose the curve $\mathbf{r} = \mathbf{r}(s)$ is parametrized by a natural parameter and lies on the unit sphere centered at the origin.
Show that its curvature satisfies $$\kappa = \sqrt{ 1 + \left(\mathbf{r}'' \cdot \left(\mathbf{r} \times \mathbf{r}' \right) \right)^2}.$$ Below is what I'm familiar with and what I've tried to use, but I can't seem to connect the ideas together. The unit sphere at the origin can be represented as $x^2 + y^2 + z^2 = 1$. If $\mathbf{r} = \langle\ x(s),\ y(s),\ z(s) \ \rangle$ lies on the sphere, then $\mathbf{r}$ will intersect the sphere at any point such that $[x(s)]^2 + [y(s)]^2 + [z(s)]^2 = 1.$ From this I gather that $\| {\mathbf{r}} \| = 1.$ Since the norm of $\mathbf{r}$ is constant, then $\mathbf{r} \cdot \mathbf{r}' = 0$. Therefore $\mathbf{r}$ and $\mathbf{r}'$ are orthogonal to one another. But we know that $\mathbf{r}'$ is tangent to our curve, and $\mathbf{r}''$ would be normal to our curve. I suppose we could use unit vectors and then the Frenet-Serret equations may come into play, but I don't see it. I'm familiar with the various curvature formulas, and I'd like to believe $\kappa = \| \mathbf{r}''(s) \|$ will be the one that works for us. Thank you very much!","['multivariable-calculus', 'differential-geometry']"
676046,"Ring of integers for $\mathbb{Q}(\sqrt{23},\sqrt{3})$","What is the ring of integers for $\mathbb{Q}(\sqrt{23},\sqrt{3})$? So, these are numbers of the form $a+b\sqrt{3}+c\sqrt{23}+d\sqrt{69}$ where $a,b,c,d\in\mathbb{Q}$, and we want to find ones whose minimum polynomial is monic. But I'm not sure how to find the minimum polynomial for a number of this form. Are there any theorems/methods to help?","['ring-theory', 'algebraic-number-theory', 'number-theory']"
676051,"homomorphism $f: \mathbb{C}^* \rightarrow \mathbb{R}^*$ with multiplicative groups, prove that kernel of $f$ is infinite.",Let $f: \mathbb{C}^* \rightarrow \mathbb{R}^*$ be a homomorphism of the multiplicative group of complex numbers to the multiplicative group of real numbers. I need to show that the kernel of $f$ must be infinite. I do know that $\mathbb{C}^*$ and $\mathbb{R}^*$ are not isomorphic to each other from here . So does that mean $f$ is not onto? But how will I be able to show that the kernel is infinite? Thanks in advance.,"['abstract-algebra', 'complex-analysis', 'group-theory', 'real-analysis']"
676081,Why is using $p$-values bad?,"I was reading this article on nature, and it seems to suggest that using $p$-values is bad, yet most of the textbooks I have read about statistics use $p$-value as a method of rejecting the null-hypothesis.  I am confused, why would textbook teach a method if it is so flawed.","['statistics', 'probability']"
676087,Estimate the Number of Conjugacy Classes of $G$,This is a series of questions in my book unanswered. Let $c(G)$ be the number of conjugacy classes in $G$. Define $\bar{c}(G):=\frac{c(G)}{|G|}$. Now we estimate the $\bar{c}(G)$ of a non-abelien $G$. (a) $\bar{c}(G)\leq \frac{5}{8}$. (b) There is a finite group $H$ with $\bar{c}(H)=\frac{5}{8}$. (c) Suppose that there exists a prime number $p$ and an element $x\in G$ such that the cardinality of the conjugacy class of $x$ is divisible by $p$. Find a good/sharp upper bound for $\bar{c}(G)$. I have no idea to solve these questions. Is there any special technologies to solve the kind question?,"['finite-groups', 'group-theory']"
676089,How to denote a set of functions,"Say there is an unknown function $h(x)$ $$\int_A^B h(x) = c$$ $A$, $B$ and $c$ are known. So $h(x)$ can have various forms on the range $[A,B]$. I want to know how to denote the set of functions for $h(x)$. I know the notation for a set is $\{...\}$. So would it be: $\{h(x)|\int_A^B h(x) = c\}$? Or is there a different way to refer to a bunch of different possible functions? I intend to narrow down this set by gradually introducing boundary restrictions/conditions. E.g. $h(x) \in \mathbb R$ and $h(x) = f(x)\cdot g(x)$ with $g(x)$ known.",['functions']
676112,the best constant in an inequality?,"I learnt how to show the below inequality by C-S inequality: k is from $0$ to $\infty$ If $\sum a_{k}^{2}9^{k}\le 5$ then $\sum |a_{k}|2^{k}\le 3$. next,I tried to show that 3 is the best possible constant in the last inequality. Could you please help me to show how 3 is the best possible constant.","['inequality', 'sequences-and-series', 'calculus', 'analysis']"
676121,Are there sets $A$ and $B$ such that $A \in B$ and $B \in A$?,"I think that the question is clear from the title: Are there sets $A$ and $B$ such that $A \in B$ and $B \in A$? My feeling is that the definition of any two such sets will be circular (we can't define $B$ till we define $A$ and we can't define $A$ till we define $B$), and hence will be excluded by some axiom. On the other hand, I can't see an inherent contradiction, though I wouldn't be surprised if some form of Russell's paradox pops up, pushed behind one more set of braces.",['elementary-set-theory']
676122,A rearrangement of an absolutely convergent series converges absolutely to the same limit,"I just completed the following proof.  Is it valid? Let $\sum_{k=1}^{\infty} a_k$ be an arbitrary convergent series that also converges absolutely.  Then $\sum_{k=1}^{\infty} a_k \in \mathbb{C}$ and $\sum_{k=1}^{\infty} |a_k| \in \mathbb{R}$. Let $\{b_k\}$ denote a rearrangement of the $\{a_k\}$.  That is, we have that $\{a_k\} = \{b_k\}$ yet $a_i = b_i$ needn't hold. We will first show that $\sum_{k=1}^{\infty} b_k$ converges absolutely (immediately implying it converges non-absolutely).  We will use the Cauchy Criterion on the partial sums of $\sum_{k=1}^{\infty} |b_k|$ to demonstrate this. First let $\epsilon > 0$. Consider that since $\sum_{k=1}^{\infty} |a_k| \in \mathbb{R}$, we have that $\exists N_1 \in \mathbb{N}$ s.t. for all $N_1 < m < n$ we have $$
\sum_{k=m}^n |a_k| \le \epsilon.
$$ Now let $0 < N_2$ be large enough s.t $\{a_1, \ldots , a_{N_1}\} \subseteq \{b_1, \ldots , b_{N_2}\}$.  Let $M > max\{N_1, N_2\}$.  Let $M < m' < n'$.  Then since $\{b_k\} - \{b_1, \ldots , b_{m'}\} \subseteq \{a_{N_1}, a_{N_{1}+1},  a_{N_{1}+2} \ldots\}$, we will have that $$
\sum_{k=m}^n |a_k| \le \epsilon \implies \sum_{k={m'}}^{n'} |b_k| < \epsilon.
$$ Then we have that $$
\left| \sum_{k={m'}}^{n'} |b_k| \right| = \sum_{k={m'}}^{n'} |b_k| < \epsilon
$$ so that since $\epsilon$ was arbitrary, we have obtained that $$
\left| \sum_{k=1}^n |b_k| - \sum_{k=1}^m |b_k|  \right| = \left| \sum_{k=m}^n |b_k|  \right| \rightarrow 0
$$ so that via the Cauchy Criterion for Convergence we have that $\sum_{k=1}^{\infty} |b_k|$ converges to some  value in $\mathbb{R}$ as desired. Then it follows that $\sum_{k=1}^{\infty} b_k$ is absolutely convergent (and hence also just convergent). $\square$","['sequences-and-series', 'calculus', 'solution-verification', 'complex-analysis', 'limits']"
676124,Proving $\text{Li}_3\left(-\frac{1}{3}\right)-2 \text{Li}_3\left(\frac{1}{3}\right)= -\frac{\log^33}{6}+\frac{\pi^2}{6}\log 3-\frac{13\zeta(3)}{6}$?,"Ramanujan gave the following identities for the Dilogarithm function : $$
\begin{align*}
\operatorname{Li}_2\left(\frac{1}{3}\right)-\frac{1}{6}\operatorname{Li}_2\left(\frac{1}{9}\right) &=\frac{{\pi}^2}{18}-\frac{\log^23}{6} \\
\operatorname{Li}_2\left(-\frac{1}{3}\right)-\frac{1}{3}\operatorname{Li}_2\left(\frac{1}{9}\right) &=-\frac{{\pi}^2}{18}+\frac{1}{6}\log^23 
\end{align*}
$$
Now, I was wondering if there are similar identities for the trilogarithm ? I found numerically that $$\text{Li}_3\left(-\frac{1}{3}\right)-2 \text{Li}_3\left(\frac{1}{3}\right)\stackrel?= -\frac{\log^3 3}{6}+\frac{\pi^2}{6}\log 3-\frac{13\zeta(3)}{6} \tag{1}$$ I was not able to find equation $(1)$ anywhere in literature. Is it a new result? How can we prove $(1)$? I believe that it must be true since it agrees to a lot of decimal places.","['special-functions', 'sequences-and-series', 'real-analysis', 'analysis', 'polylogarithm']"
676160,Is there a group homomorphism $\Bbb{C}^*\to\Bbb{R}^*$ with a countable kernel?,"Consider a group homomorphism $f:\Bbb{C}^*\to\Bbb{R}^*$.
In a recent question we easily established that $\ker(f)$ is necessarily infinite. The homomorphisms that can be easily described are of the form
$$
f(z)=|z|^a
$$
for some real constant $a$. All those homomorphisms contain the unit circle in their kernel.
This raises the suspicion: Is $\ker (f)$ necessarily uncountable? Not all the homomorphisms are of the above form. The group of positive real numbers is divisible , i.e. all the positive real numbers have positive roots of a given integer order. This implies that in the category of Abelian groups the group $\Bbb{R}_{>0}$ is an injective object (Zorn's lemma is needed to prove this). This implies the existence of other homomorphisms as follows. Let $\omega\in\Bbb{C}$ be a number such that i) $|\omega|=1$, and ii) $\omega^n\neq1$ for all $n\in\Bbb{Z}$, IOW $\omega=e^{2\pi i r}$ for some irrational real number $r$. Let us select $a\in\Bbb{R}_{>0}$, $a\neq1$. Consider the subgroup $H=\langle \omega\rangle\times\Bbb{R}_{>0}\le\Bbb{C}^*$. The rule
$$
f_a(\omega^nx)=a^nx,
$$
for all $x\in\Bbb{R}_{>0}$, then defines a homomorphism $f_a:H\to\Bbb{R}_{>0}$. By injectivity of the target group we can extend this to a homomorphism $f'_a$ from all of $\Bbb{C}^*$ to $\Bbb{R}_{>0}$ such that $f'_a(\omega)=a\neq1$. But does that really help answer the question? Neither $\Bbb{C}^*$ nor $\Bbb{R}^*$ is finitely generated, so we don't know whether they can be written as a direct product of a torsion group and a free abelian group, or do we?","['group-theory', 'abstract-algebra']"
