question_id,title,body,tags
318981,"$\iint_D \cos \left( \frac{x-y}{x+y} \right)\,dA$","I'm studying to a Calculus test and I couldn't solve the following exercise: Calculate $\iint_D \cos \left( \frac{x-y}{x+y} \right)\,dA$ where $D$ is the region of the plane $xy$ limited by $x+y=1$, $x=0$ and $y=0$. After a little of thinking I've got the following: $$
\int_0^1\int_0^{1-y}\cos\left(\frac{x-y}{x+y}\right)\,dx\,dy
$$ I have no idea how to solve it. Wolfram Alpha couldn't solve it too.","['definite-integrals', 'integration']"
318983,How to solve the improper integral $\int_{-\infty}^{\infty} \frac{x^2}{x^6+9}dx$ (possible trig substitution),$$\int_{-\infty}^{\infty} \frac{x^2}{x^6+9}dx$$ I'm a bit puzzled as how to go about solving this integral. I can see that it isn't undefined on -infinity to infinity. But I just need maybe a hint on how to go about solving the problem.,"['improper-integrals', 'integration']"
318990,Is always possible to find a generalized eigenvector for the Jordan basis M?,"$A$ is a defective matrix, meaning that there are fewer linearly independent eigenvectors than eigenvalues; the algebraic multiplicity of $\lambda_1$ is $v_i = 2$ while the geometric multiplicity is $\mu_1 = 1$: $$
A = \begin{bmatrix}1 & 1 \\ 0 & 1\end{bmatrix}, \lambda_1 = 1, e_1 = \begin{bmatrix}1 \\0\end{bmatrix}
$$ The block diagonal matrix $J$ (Jordan form) would be: $$
J = \begin{bmatrix}\lambda_1 & 1 \\ 0 & \lambda_1\end{bmatrix}
$$ Correct me if I'm wrong: The number of blocks $J(\lambda_i)$ in $J$ equals the number of distinct eigenvalues ($1$ in this example). Each block is a square matrix of order $v_i$ (the algebraic multiplicity of $\lambda_i$). In this case there is only one block $J(\lambda_1)$ of order $2$. Each block $J(\lambda_i)$ has many miniblocks as the geometric multiplicity $\mu_i$ (in this case $2$), that is $J(\lambda_i, 1)...J(\lambda_i, \mu_i)$. Each miniblock has this strcture: $$
\begin{bmatrix}\lambda_i & 1 \\ 0 & \lambda_i\end{bmatrix}
$$ Right now $J = \begin{bmatrix}1 & 1\\0 & 1\end{bmatrix}$. I need to find out the basis (the matrix $M$). Assume that the columns of $M$ are $x_1$ and $x_2$. We know that (Jordan form) $AM = MJ$. Computing the product a column at time we have: $$
Ax_1 = \lambda_1x_1\\
x_1 = e_1 = \begin{bmatrix}1\\0\end{bmatrix}\\
Ax_2 = x_1 + \lambda_1x_2\\
(A - I\lambda_1)x_2 = x_1
$$ And $x_2$ is the generalized eigenvector ($\begin{bmatrix}c\\1\end{bmatrix}$). Question 1 : the choice of $c$ is up to me? I imagine that, because $M$ should be not singulare, I have to choose the right value by myself. Question 2 is: is always possible to solve $(A - I\lambda_1)x_2 = x_1$ and why? In other words, the generalized eigenvector always exists?","['matrices', 'block-matrices']"
318998,Problem involving permutation matrices from Michael Artin's book.,"Let $p$ be the permutation $(3 4 2 1)$ of the four indices.  The permutation matrix associated with it is 
$$ P =
\begin{bmatrix}
0 & 0 & 1 & 0 \\ 
1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 1 & 0 & 0
\end{bmatrix}
$$
This is the matrix that permutes the components of a column vector. The problems asks you to decompose $p$ into transpositions and show that the associated matrix product equals the above matrix.  However, I'm not getting that it does and I've run through it several times.  Here are my calculations: $p = (12)(14)(13)$ $$
P_{(12)} = \begin{bmatrix}
0 & 1 & 0 & 0 \\ 
1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{bmatrix}, 
P_{(14)} =\begin{bmatrix}
0 & 0 & 0 & 1 \\ 
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
1 & 0 & 0 & 0
\end{bmatrix},
P_{(13)}=\begin{bmatrix}
0 & 0 & 1 & 0 \\ 
0 & 1 & 0 & 0 \\
1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1
\end{bmatrix}
$$ However, 
$$P_{(12)} (P_{(14)} P_{(13)}) = 
\begin{bmatrix}
0 & 1 & 0 & 0 \\ 
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0
\end{bmatrix}
\neq P$$ I don't see where I've made a mistake.","['permutation-matrices', 'abstract-algebra', 'matrices', 'finite-groups', 'group-theory']"
319001,Is $f(x)= \cos(e^x)$ uniformly continuous?,"As in the topic, my quest is to check (and prove) whether the given function $$f(x)= \cos(e^x)$$is uniformly continuous  on $\left\{\begin{matrix}x \in (-\infty;0]
\\ 
x \in [0; +\infty)
\end{matrix}\right.$ . My problem is that I have absolutely no idea how to do it. Any hints will be appreciated and do not feel offended if I ask you a question which you consider stupid, but such are the beginnings. Thank you in advance.","['calculus', 'analysis']"
319005,Prove that $(e+x)^{e-x}>(e-x)^{e+x}$,"I get stuck with proving that $$(e+x)^{e-x}>(e-x)^{e+x}$$ for $x \in (0, e)$. All I know, is that it is doable with Jensen inequality, and I started with defining $$f(x)=(e+x)^{e-x}$$ and further $$g(x)=\ln \cdot f(x)$$ and... nothing more come to my mind, I kindly ask for any help & hints. Thanks","['inequality', 'exponential-function', 'calculus', 'analysis']"
319028,Real part of holomorphic function cannot have a maximum,"I am trying to prove that if $f$ is a holomorphic function from a domain $U$ to $\mathbb{C}$, and the real part has an interior local maximum at a point $a$ in $U$, then $f$ is a constant. I am new to complex analysis, but I was thinking maybe I need to use some variant of the local maximum principle? Thanks.",['complex-analysis']
319035,Motivation of Feynman-Kac formula and its relation to Kolmogorov backward/forward equations?,"Kolmogorov backward/forward equations are pdes, derived for the semigroups constructed from the Markov transition kernels. Feynman-Kac formula is also a pde corresponding to a stochastic process defined by a SDE. 
But I was wondering if the stochastic process is also Markovian? I.e., does Feynman-Kac formula apply only to Markov process? Does the semigroups from the Markov transition kernels also lead to Feynman-kac pde? If not, what leads to Feynman-Kac pde? If yes, Is Feynman-Kac pde also some kind of Kolmogorov backward/forward equation? if not, how is Feynman-Kac pde related to Kolmogorov backward/forward equations? Thanks and regards!","['stochastic-processes', 'markov-process', 'partial-differential-equations', 'stochastic-calculus', 'functional-analysis']"
319044,Necessary condition for pairwise sufficient statistic [duplicate],"This question already has answers here : Pairwise measurable derivatives imply measurability of combined derivative (2 answers) Closed 11 years ago . I'm struggling to prove the following. If $T:\left(X,\mathbf{A}\right)\rightarrow\left(Y,\mathbf{B}\right)$ is a pairwise sufficient statistic for a set $\left\{\mu_0,\mu_1,\mu_2\right\}$ of three measures on $\left(X,\mathbf{A}\right)$ , then $\frac{d\mu_0}{d\left(\mu_0+\mu_1+\mu_2\right)}$ (the Radon-Nikodym derivative) is $T^{-1}\left(\mathbf{B}\right)$ -measurable modulo $\mu_0+\mu_1+\mu_2$ . It is supposedly proved in the otherwise accessible and irreproachable article ""Application of the Radon-Nikodym Theorem to the Theory of Sufficient Statistics"" by Halmos and Savage ( Lemma 9 , page 238), but i'm dissatisfied with the proof, since in my opinion it justifies the claim modulo $\mu_0$ only. I'd appreciate help in either understanding Halmos & Savage's proof or proving it from scratch.","['statistics', 'measure-theory']"
319048,Elementary Symmetric group Question,"The question is as follows TRUE or FALSE: For n > 1, any element of $S_{n}$ has order less than
or equal to n. If true, give a short proof and if false, give an explicit
counter-example. I feel a little lost ( as i often do in proofs that i cant prove via counter example) $S_{n}$ is a Bijection so the order of $S_{n} = n$  ( as long as we are in the land of finite n) I think im lost on the meaning of Element having an order greater then 1. The only way i can really interpret the order of a element greater then 1 is in a finite cyclic group  where the order of some element $a_{1} = <a_{1}> $  If i was in a case such as this i may make an attempt to prove that the order of $a_{1} = a_{n-1} = S_{n}$ and then try and show using some idea of sorts. That Order of all $a_{i}$ < order of $a_{1}$ for all i that are not n-1 or 1 Could someone try and explain in.. well terms that someone who doesn't get math might understand?  i would really like to understand the order of elements in this context correctly EDIT Above is wrong.","['elementary-set-theory', 'group-theory']"
319067,Automorphism proof ( simple),"So the problem is given by Let G be a group and define $\pi $ : $\rm\:G \to G\:$  by $\pi(a)$ = $a^{-1}$, for every a in
G. Prove that $\pi $ is an automorphism of G if and only if G is abelian. Though i have no idea how to prove it clearly $\pi$ is  Bijection on G
i would like to use the fact that the identity element in G is $a_{e}$ and that the Kernel of G is $a_{e}$ So knowing $\pi (a_{e})$ = $(a_{e})^{-1}$ = $a_{e}$ and if the kernel is preserved i believe i can conclude i have a bijection somehow? i believe i have one direction of the proof as well Assume $\pi$ is an automorphism Want To Show G is abelian $\pi(ab)$ = $(ab)^{-1}$ = $(b)^{-1}(a)^{-1}$ $\pi(a)$ $\pi(b)$ = $(a)^{-1}(b)^{-1}$ but by homomorphism property of $\pi$ $\pi(a)$ $\pi(b)$ = $\pi(ab)$ thus $(a)^{-1}(b)^{-1}$= $(b)^{-1}(a)^{-1}$ So G must be abelian if $\pi$ is an automorphism Now for the other direction i believe my confusion lies in  im not certain i can assume $\pi$ is a homomorphism if i can i think i could show that $\pi$ is an automorphism. If someone could help me implement an idea to prove i have a bijection and point me in the right direction on the second half it would be much appreciated.","['elementary-set-theory', 'group-theory']"
319093,Finite Group Proving finite order of elements and Subgroup Question,"The question is as follows Let G be a finite group. (i) Prove that every element of G has finite order. For this want to use the idea that if G is finite then for a in G, $a^{n}$ = $e$ for some n in $Z^{+}$
and treat a is a generator of a cyclic group that is a subset of G the the order of each $<a_{i}>$   must be less than or equal to G. since G is of finite order each $<a_{i}>$ is also of finite order. but i am really not sure i can treat this group in such a way? (Secondly) Suppose that H is a subset of G which is non-empty and, for any
a, b in H, ab is also in H. Prove that H is a subgroup of G. For this i want to try and use that since ab is in H $(ab)^{n}$ should be in H and for some n in $Z^{+}$ $(ab)^{n}$ = e but im not sure my assumption in part 1 is correct... could someone point me in the right direction please? EDIT I think i understand since H is finite ( cause G is finite) I understand why for any h in H
$<h>$ must be a subset of H but how do we prove that $(h)^{2}$ is in H oh! Perhaps we use for any a,b in H ab is H and just pick h twice so hh must be in H thus $(h)^{n}$ must be in H and $(h)^n$ = e for some n in $Z^{+}$ by G and this must be true for all h in H ? EDIT (ii) Ok let a and b be in H and left $a^{l} = e$ and  $b^{k}= e$ for some l and k in $Z^{+}$
then $b^{k}$$a^{l}$ is in H and $b^{k}$$a^{l}$ = e so $b^{-k}$$b^{k}$$a^{l}$ = $b^{-k}$ so $a^{l}$ = $b^{-k}$ Can we assume from this that every h in H has an inverse because every $h^{n}$ has one? Im still curious about above but i think that anon actually had answered my question of where the i could find the Inverse element from at the end of his post. ( i just need to digest the information a bit) Thanks so much to all of you, its very helpful to be able ask a question and get such a wonderful number of different ways of looking at the problem.","['finite-groups', 'elementary-set-theory']"
319099,Cayley's Theorem (Simple),"I don't really like to ask questions where i don't understand whats going on at all, but i just can seem to wrap my head around Cayley's Theorem, we went over it in class and i also watched a YouTube lecture that had a proof of theorem in it. I can't quite wrap my head around it though. A question in my textbook is as follows Apply Cayley's Theorem to the group $U_{12}$. Write an explicit group
isomorphism from this group to a specic set of permutations of $U_{12}$. Where $U_{12}$ is $\mathbb Z_{12}$ with all the stuff that does not have a multiplicative inverse thrown out. Can someone Translate what this says to English and then perhaps back to math in a simpler way perhaps?","['elementary-set-theory', 'group-theory']"
319100,"Closed form of, or series for $\int_{\epsilon-i\infty}^{\epsilon+i\infty}\frac{e^{az+b^2z^2}}{\sin\pi z}\,dz$","I've been trying to find a closed form expression/series expansion for the following integral without success: $$F(a,b)=\int_{\epsilon-i\infty}^{\epsilon+i\infty} e^{az+b^2z^2}\Gamma(z)\Gamma(1-z)\,dz=\pi\int_{\epsilon-i\infty}^{\epsilon+i\infty}\frac{e^{az+b^2z^2}}{\sin\pi z}\,dz$$ for some $\epsilon\in(0,1)$ . Any input is greatly appreciated!","['definite-integrals', 'improper-integrals', 'gamma-function', 'complex-analysis']"
319103,"Show that if $U$ is an open connected subspace of $\mathbb{R}^2$, then $U$ is path connected","Show that if $U$ is an open connected subspace of $\mathbb{R}^2$, then $U$ is path connected. (Hint:Show that given $x_0 \in U$, the set of points can be joined to $x_0$ by a path in $U$ is both open and closed in $U$.) This should not be too difficult, but I am stuck at some point. Let $x_0 \in U$ Let $A = \{ x \in U | \text{there is a path connecting $x$ and $x_0$} \}$ $\subset U$. I want to show that $A$ is open, so let $x \in A$. By openness of $U$, we can find a basic open set $\prod_{i=1}^2 (a_i,b_i)$ such that $\prod_{i=1}^2 (a_i,b_i) \subset U$. But I am stuck in showing that $\prod_{i=1}^2 (a_i,b_i)$ lies entirely in $A$.",['general-topology']
319126,Polar decomposition of invertible elements in a unital C$ ^{*} $-algebra.,"If $ A $ is a unital C$ ^{*} $-algebra and $ a $ is invertible, then $ a = u|a| $ for a unique unitary element $ u $ of $ A $. If $ \| a \| = \| a^{-1} \| = 1 $, what can you say about $ |a| $? I don’t know how to start!","['c-star-algebras', 'operator-algebras', 'banach-algebras', 'functional-analysis']"
319130,Calculate the volume of the solid that's above the plane $xy$ and is limited by the paraboloid $z=x^2+y^2$ and the cylinder $x^2+y^2=2y$,"I'm studying to my test of Calculus and I'm not sure about the result I got. This is how I've done it: Discover the interval of z:
$$
0 \leq z \leq x^2+y^2
$$ Setup the integral:
$$
\iint_D \, \int_0^{x^2+y^2} \, dz \,\, dA
$$ It equals to:
$$
\iint_D x^2+y^2 \, dA
$$ I've transformed the region $D$ to:
$$
u = x \therefore x = u \\
v = y - 1 \therefore y = v + 1 \\
J = \begin{vmatrix} 1 & 0 \\ 0 & 1 \end{vmatrix} = 1
$$ And setup the integral to:
$$
\iint_{u^2+v^2=1} u^2+(v+1)^2 \, du \, dv = \iint_{u^2+v^2=1} u^2+v^2+2v+1 \, du \, dv
$$ Using polar coordinates:
$$
\int_0^{2\pi} \int_0^1 \left( r^2 + 2 r \sin \theta + 1 \right) r \, dr \, d\theta =
\int_0^{2\pi} \int_0^1 r^3 + 2 r^2 \sin \theta + r \, dr \, d\theta
$$ Solving:
$$
\int_0^{2\pi} \frac{3}{4} + \frac{2}{3} \sin \theta \, d\theta =
\frac{3\pi}{2}
$$ So, is it right? I'm not sure about the transformation I've done.","['multivariable-calculus', 'calculus', 'integration']"
319132,A ‘strong’ form of the Fundamental Theorem of Algebra,"Let $ n \in \mathbb{N} $ and $ a_{0},\ldots,a_{n-1} \in \mathbb{C} $ be constants. By the Fundamental Theorem of Algebra, the polynomial
$$
p(z) := z^{n} + \sum_{k=0}^{n-1} a_{k} z^{k} \in \mathbb{C}[z]
$$
has $ n $ roots, including multiplicity. If we vary the values of $ a_{0},\ldots,a_{n-1} $, the roots will obviously change, so it seems natural to ask the following question. Do the $ n $ roots of $ p(z) $ depend on the coefficients in an analytic sort of way? More precisely, can we find holomorphic functions $ r_{1},\ldots,r_{n}: \mathbb{C}^{n} \to \mathbb{C} $ such that
  $$
z^{n} + \sum_{k=0}^{n-1} a_{k} z^{k} = \prod_{j=1}^{n} [z - {r_{j}}(a_{0},\ldots,a_{n-1})]?
$$ The definition of a holomorphic function of several complex variables is given as follows: Definition Let $ n \in \mathbb{N} $ and $ \Omega \subseteq \mathbb{C}^{n} $ be a domain (i.e., a connected open subset). A function $ f: \Omega \to \mathbb{C} $ is said to be holomorphic if and only if it is holomorphic in the usual sense in each of its $ n $ variables. The existence of $ r_{1},\ldots,r_{n}: \mathbb{C}^{n} \to \mathbb{C} $ that are continuous seems to be a well-known result (due to Ostrowski, perhaps?), but I am unable to find anything in the literature that is concerned with the holomorphicity of these functions. Any help would be greatly appreciated. Thank you very much!","['complex-numbers', 'several-complex-variables', 'complex-analysis', 'polynomials']"
319139,A question on definition of field of fractions,"Wikipedia defines the field of fractions of a domain as The field of fractions or field of quotients of an integral domain is the ""smallest"" field in which it can be embedded. What does ""smallest"" mean mathematically in this context? Is it possible to embed an integral domain in two different fields which have no elements in common?","['commutative-algebra', 'ring-theory', 'abstract-algebra', 'definition']"
319145,Cardinality of a set containing subsets of $\omega_{1}$,"Consider the set $ \{ X \subseteq \omega_{1} \ | \text{ such that }  |X| = \aleph_{0} \} $ I know $\omega$ is in this set. But then I thought about it and realized that {2,3,4,... } was also in this set, and it has cardinality $ \omega $ . The answer turns out to be $2^{\aleph_{0}}$. Is there a bijection from the set in question to $P(\omega) $ or is there a straight forward counting argument. edit: Changed $2^{\omega} $ to $ 2^{\aleph_{0}} $.","['cardinals', 'elementary-set-theory']"
319154,Multiple roots of polynomials over a finite field,"Show that $x^4+x+1$ over $\mathbb{Z}_2$ does not have any multiple zeros in any field extension of $\mathbb{Z}_2$. Show that $x^{21} + 2x^8 +1$ does not have multiple zeros in any extension of $\mathbb{Z}_3$. Show that $x^{21} + 2x^9 +1$  has multiple zeros in some extension of $\mathbb{Z}_3$. These are three similar problems on field extensions. Can anybody help me please - how can I solve this type of problem? I am learning about field extensions on my own, so my ideas are not very clear. Please help.","['field-theory', 'abstract-algebra', 'polynomials']"
319165,Transformation of domain in Evans,"From Evans, Partial Differential Equations, Page 53. Let $\Phi(x,s)=\frac{1}{{4\pi t}^{n/2}}e^{-\frac{|x|^{2}}{4t}}$. Evans used $E(x,t,r)$ to denote the region $$(y,s)\in \mathbb{R}^{n+1}|s\le t, \Phi(x-y,t-s)\ge \frac{1}{r^{n}}$$
In particular he used $E(r)$ to denote the region $E(0,0,r):\Phi(-y,-s)\ge \frac{1}{r^{n}}$. My question is how the following two equalities (here $u$ is an $C^{2}$ function in $y$ and $s$): $$\int\int_{E(1)}\sum^{n}_{i=1}u_{y_{i}}y_{i}\frac{|y|}{s^{2}}+2ru_{s}\frac{|y|^{2}}{s}dyds=\frac{1}{r^{n+1}}\int\int_{E(r)}\sum^{n}_{i=1}u_{y_{i}}y_{i}\frac{|y|}{s^{2}}+2u_{s}\frac{|y|^{2}}{s}dyds$$ and $$\frac{1}{r^{n}}\int\int_{E(r)}u(y,s)\frac{|y|^{2}}{s^{2}}dyds=\int\int_{E(1)}u(ry,r^{2}s)\frac{|y|^{2}}{s^{2}}dyds$$
The transformation of domain is the obvious issue at here. For any function $u(y,s)$, to transform $\int\int_{E(r)}u(y,s)$ to $\int\int_{E(1)}u(y',s')$ one need to make certain dilation and change of variables. The reason is when we change $\Phi(x,t)\rightarrow \Phi(rx,r^{2}t)$, there is an extra $\frac{1}{r^{n}}$ term such that $\frac{1}{r^{n}}\Phi(x,t)=\Phi(rx,r^{2}t)$. Therefore $\Phi(-y,-s)\ge 1$ implies $\Phi(-ry,-r^{2}s)\ge \frac{1}{r^{n}}$. So $(y,s)\rightarrow (ry,r^{2}s)$ change $E(1)$ to $E(r)$. But in the second inequality the situation is reversed. I do not really know how to reach from here to the above equalities, so I decided to ask.","['multivariable-calculus', 'partial-derivative', 'partial-differential-equations']"
319167,How to find all automorphisms of $\mathbb{Q}(\sqrt[3]{5})$? [duplicate],This question already has an answer here : Calculate $\mathrm{Gal}(\mathbb{Q}(\sqrt[5]{3})/\mathbb{Q})$ (1 answer) Closed 11 years ago . Find all automorphisms of $\mathbb{Q}(\sqrt[3]{5})$. How can I solve the above problem ? Please help someone.,"['abstract-algebra', 'field-theory']"
319174,Why doesn't Spivak ever write $dx$ in an integral?,"I've noticed that Spivak, and many other analysis books I read like Munkres, do not use $dx$ when they integrate. Why is that? This is a serious question.","['notation', 'integration']"
319197,"A normal, idempotent linear operator must be self-adjoint","I have been trying to solve this problem for quite a while. I am still unsure of whether any of the avenues I have pursued have been of any use. Any advice will be much appreciated. Question: Let $V$ be a finite-dimensional inner product space, and let $E$ be an idempotent linear operator on $V$ . Prove that if $EE^* = E^*E$ , then $E$ is self-adjoint. (This is essentially exercise 5(a) in sec. 80 on p.162 of Paul R. Halmos, Finite-Dimensional Vector Spaces , but Halmos didn't assume that the dimension of $V$ is finite.)",['linear-algebra']
319200,Number of ways to seat students at a round table subject to certain conditions.,"In an Olympic contest, there are $n$ teams.  Each team is composed of $k$ students attending different subjects.  How many ways are there to seat all the students at a round table such that $k$ students in a team sit together and there are no two students who attend the same subject seat next to one another? My attempt: Let $S_n$ denote the total way to seat all the student in $n$ teams with $k$ students on each team in a way that satisfies the problem. Then I find that $\forall n \geq 2$ $S_{n+1}=\alpha.nS_n$ with $\alpha = 2(k-1)!-(k-2)!$
But there is problem for me to find $S_2$ because it may be non-relative to $S_1$. Help me!",['combinatorics']
319230,Are these subsets of $\mathbb{R}$ homeomorphic?,"Consider the following subspaces of $\mathbb{R}$ with the usual topology:
$$X = (0, 1) \cup \{2\} \cup (3, 4) \cup \{5\} \cup \cdots \cup (3n, 3n + 1) \cup \{3n + 2\} \cup\cdots$$
$$Y = (0, 1] \cup (3, 4) \cup \{5\} \cup\cdots\cup (3n, 3n + 1) \cup \{3n + 2\} \cup\cdots$$
Is $X$ homeomorphic to $Y$ ? For $X$ to be homeomorphic to $Y$, we need to specify a bijective function from $X$ to $Y$ and inverse function from $Y$ to $X$ are continuous. From $(3,4)$ onwards, we can map by identity function. How can I map $(0,1) \cup \{2\}$ to $Y$? $(0,1]$, in usual topology is not open and closed. Can I write $(0,1]$ as $(0,1)\cup\{1\}$, and then map $\{0,1\}$ by identity map and $\{1\}$ to $\{2\}$. Please forgive me if any of what I think is stupid.","['general-topology', 'metric-spaces']"
319237,"Every uncountable Polish Space has a copy of $\{0, 1\}^\mathbb{N}$","I am having trouble verifying corollary 7.8 on p. 6 in this document http://www.math.ucla.edu/~biskup/275b.1.13w/PDFs/Standard-Borel-Spaces.pdf My troubles are with the definition of the ""tree"" sequence of balls.  Particularly, I don't see the claims at the bottom of the second to last paragraph, saying that $B_{\sigma0}$ is disjoint from $B_{\sigma1}$ and both are contained in $B_{\sigma}$.  There are a number of typos in this proof that I think I have figured out.  I believe symbols like ""$\sigma0$"" to denote concatenation. There are a few missing ""$\in$""s.  I have not figured out what he really means in the definition of $r_n$, which I imagine is part of the hindrance in me being unable to prove the claims mentioned above.  Anything addressing these questions would be useful, but I am sufficiently confused such that a rewrite of the proof starting from the point where he constructs the balls and ending at the point where he makes the disjointness and containment claims would be useful.  In any case, I certainly would like to be told what the $r_n$ means and why it makes the disjointness and containment claims true, hence the ""tree"" aspect of the construction.  Thanks.","['probability-theory', 'measure-theory', 'descriptive-set-theory', 'real-analysis']"
319245,Number of possibilities to cross a hexagonal lattice.,"An ant walks along the line segments in the hexagonal lattice shown, from start to finish.  The ant must go in the direction shown if there is an arrow, and never goes on the same line segment twice.  How many different paths can the ant take? I am not looking for an answer to this, just a hint on how to get started. I have an adjacency matrix setup, and know that I can use A^r to find possibilities for r number of lengths, but that includes retaking the same paths. How do I get over that bump? Note: Original image here","['probability-theory', 'graph-theory', 'discrete-mathematics', 'combinatorics']"
319267,A rational curve in the exceptional locus?,Let $f:X\rightarrow Y$ be a blow-up of a complex manifold $Y$ along a smooth submanifold. Is it easy to see that the exceptional locus contains a rational curve? Could anyone give a proof or suggest a reference for this fact?,['algebraic-geometry']
319269,"$L_{p}(\mathbb{T})$ is not uniformly convex if $p \in \{1,\infty\}$.","How can I prove that $L_{p}(\mathbb{T})$ is not uniformly convex if $p \in \{1,\infty\}$. Here $\mathbb{T} = \mathbb{R}/\mathbb{Z}$","['convex-analysis', 'functional-analysis', 'lp-spaces']"
319277,"Suppose that $m,n \in \mathbb{Z}$ and $m$ divides $n$. Show that $\frac{\mathbb{Z}_n}{\mathbb{Z}_m} \cong \mathbb{Z}_\frac{n}{m}$","Suppose that $m,n \in \mathbb{Z}$ and $m$ divides $n$. Show that $$\frac{\mathbb{Z}_n}{\mathbb{Z}_m} \cong \mathbb{Z}_\frac{n}{m}$$ I try to use the third isomorphism theorem to show but I don know how to apply it here. Anyone can guide me ?",['abstract-algebra']
319289,"For the relation $R = \emptyset$ on $\{1, 2, 3\}$, is it reflexive, symmetric, transitive?","In the case below, a relation on the set $\{1, 2, 3\}$ is given. Of the three properties, reflexivity, symmetry, and transitivity, determine which ones the relation has. Give reasons. $R = \emptyset$ I guessed that it was reflexive, symmetric, and transitive. My teacher said that it was not reflexive, but I didn't understand why. My reasons for it being reflexive, symmetric, and transitive was because they didn't have an if part that could make it false. Is this the same as saying that it is vacuously true? If not, what would be the reasons for whether or not it is reflexive, symmetric, and transitive?","['relations', 'discrete-mathematics']"
319317,Correlation between polynomial equations and matrix determinants,"Expanding $p(x)=(ax-b)(cx+d)$ we get $acx^2+(ad-bc)x-bd$. Notice the determinant of the matrix $\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
$ is $ad-bc$ exactly like the constant of $x$ in the polynomial expansion. So I searched links between the equation and the matrix determinant. I only found the solution of the equation $p(x)=0$ to be $x \in \{b/a, -d/c\}$. Then I found numerous other things, but none of them were simple enough to be considered worthy remembering. My question: What are the correlations between the polynomials and determinants of the matrices with entries being the coefficients of the polynomial?","['matrices', 'linear-algebra', 'determinant', 'polynomials']"
319321,Understanding the Leibniz formula for determinants [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 months ago . The community reviewed whether to reopen this question 18 days ago and left it closed: Original close reason(s) were not resolved Improve this question I am a programmer and trying to write the Leibniz formula for determinants into C++ code, but I am unable to fully understand it.
Can someone walk me through it? $$\det(A)=\sum_{\sigma \in S_n}\text{sgn}(\sigma)\prod_{i=1}^{n} a_{\sigma(i),i}$$","['matrices', 'linear-algebra', 'determinant']"
319337,"Prove that $\int_0^{\pi/2} \cos^{p+q-2}(\theta) \cos((p-q)\theta)d\theta = \frac{\pi}{(p+q-1)2^{p+q-1}B(p,q)}$","Does anybody know how to prove this identity $?$ : \begin{align*}
& \int_{0}^{\pi/2}
\cos^{p + q - 2}\,\left(\,{\theta}\,\right)
\cos\left(\,{\left[\,{p - q}\,\right]
\theta}\,\right)
\,{\rm d}\theta
\\[2mm] = & \
\frac{\pi}{\left(\,{p + q - 1}\,\right)
2^{p + q - 1}\,
\operatorname{B}\left(\,{p,q}\,\right)}\ ,
\qquad p+q>1,\ q<1
\end{align*} where $\operatorname{B}\left(\,{x,y}\,\right)$ denotes Beta Function . I am confused because the result contains beta function in the denominator. I did it using Cauchy's Beta Integral but my friend says there's another method using contour integration: I can't figure it out.","['definite-integrals', 'special-functions', 'complex-analysis']"
319356,idempotent functions,"Let $X$ be a set of three elements, say $X=\{1,2,3\}$. I'm searching functions $f:X\longrightarrow X$ such that $f\circ f=f$. In particular, i'm interested in number of such functions $f$, how many are there? Can i generalize for $n$ in place of 3?","['algebra-precalculus', 'functions']"
319358,Can an uncountable family of positive-measure sets be such that no point belongs to uncountably many of them?,"I would be happy to know whether the following is true: For every uncountable family $\Gamma$ of positive-measure sets in a $\sigma$-finite measure space, there is at least one point that belongs to uncountably many members of $\Gamma$. And if this is false for general $\sigma$-finite measure spaces, is it true for Lebesgue measure?","['measure-theory', 'descriptive-set-theory']"
319382,Hartshorne exercise III.6.2 (b) - $\mathfrak{Qco}(X)$ need not have enough projectives,"Let $X=\mathbb P^1_k$, with $k$ an infinite field. Show that there does not exist a projective object $\mathcal P$ either in $\mathfrak{Qco}(X)$ or $\mathfrak{Coh}(X)$ together with a surjection $\mathcal P\to \mathcal O_X\to 0$. The author suggests to consider surjections of the form $\mathcal L\to \mathcal L\otimes k(x)\to 0$, where $x$ is a closed point, and $\mathcal L$ is an invertible sheaf on $X$. I don't know how to choose $\mathcal L$, and I don't see how to use (quasi-)coherence here. Any suggestion? Thank you in advance.","['sheaf-theory', 'algebraic-geometry']"
319385,How does one show that there exists some $z \in X$ such that $f(z) = z$ under certain circumstances?,"In a previous exercise, one was asked to show that the sequence $(x_n)_{n > 0}$ in $X$ (with $(X,d)$ a non-empty, complete metric space) in which we have $d(x_n,x_{n+1}) \leq \theta d(x_{n-1} , x_n ) $, is convergent (with $0  < \theta < 1$). I did this by showing that $(x_n)$ is a Cauchy sequence. In the present exercise, the following is given: $f : X \to X$ is a map such that for all $x,y \in X$ we have $d(f(x),f(y)) \leq \theta d(x,y) $, 
with $0 < \theta <1$. One is now asked to show that there exists some $z \in X$, such that $f(z) = z$. The following hint is given: pick some $z_0 \in X$ and consider the sequence $(z_0, f(z_0), f(f(z_0)), \dots ).)$. The question is: how do I prove that there is some $z$ such that $f(z) = z$ ? I tried using the result of the previous exercise, but I couldn't figure out how to use it, nor do I know how to use the hint.","['general-topology', 'metric-spaces']"
319395,How to find intersection with $x$ or $y$ axis,"As my question says, how do I find intersection with $x$ or $y$ axis. For example, if given function is $f(x)=x^3+x^2-x-1$, how do I find the intersection with $x$ and $y$ axis. Right now, I only know that when we are searching for intersection with $x$, we take $y=0$ and when we search for $y$, we take $x=0$. However, if the intersection with $y$-axis, $x=0$, then we get, $f(x)=0+0-0-1$, therefore it will be, $(0,-1)$, but when we search for $x$-axis, $y=0$, what do change $0$ for? There is no $y$ in the function.",['functions']
319400,$\sum \limits_{k=1}^{\infty} \frac{6^k}{\left(3^{k+1}-2^{k+1}\right)\left(3^k-2^k\right)} $ as a rational number.,"$$\sum \limits_{k=1}^{\infty} \frac{6^k}{\left(3^{k+1}-2^{k+1}\right)\left(3^k-2^k\right)} $$ I know from the ratio test it convergest, and I graph it on wolfram alpha and I suspect the sum is 2; however, I am having trouble with the manipulation of the fraction to show the rational number. ps. When it says write as a rational number it means to write the value of $S_{\infty}$ or to rewrite the fraction?","['sequences-and-series', 'calculus']"
319401,Classify all regular polyhedra,How can we classify all regular polyhedra? I know that there are five regular polyhedra as a hint. Thanks.,"['geometry', 'discrete-mathematics', 'polyhedra', 'euclidean-geometry', 'platonic-solids']"
319407,Maximize absolute value of complex logarithm,"I'm trying to solve exercise 9 in chapter 14 of Real & Complex Analysis of Walter Rudin: Suppose $g \in H(U), |\Re(g)|<1$ in $U$ , and $g(0)=0$ . Prove that $$|g(re^{it})|\le\frac2\pi\log\frac{1+r}{1-r}$$ $U$ is the unit disc. My thoughts: Call $\Omega = \{x+iy:-1<x<1\}$ . I constructed a one-to-one conformal mapping from $\Omega$ to $ U$ : $$f(z) = -i\frac{\exp(\frac\pi2iz)-1}{\exp(\frac\pi2iz)+1}$$ I applied the Schwarz lemma to $f\circ g$ to get: $$\left| \frac{\exp(\frac\pi2ig(re^{it}))-1}{\exp(\frac\pi2ig(re^{it}))+1} \right| \le r$$ But no matter how I manipulate it, I cannot get $|g(re^{it})|$ out of it. Another approach: Use the inverse of $f$ : $$f^{-1}(z) = \frac2{\pi i}\log\frac{1+iz}{1-iz}$$ By using this question and the maximum modulus principle I get: $$|g(re^{it})| \le \max_{t\in[0,2\pi]} |f^{-1}(re^{it})|$$ The right side reaches its maximum at $re^{3\pi i/2}$ per wolfram alpha, but I cannot do it via algebra or calculus (equations and derivatives too complicated). I feel there is an easier way and I'm missing something. What is it?","['conformal-geometry', 'complex-analysis']"
319416,"Prove $\operatorname{dist}(\overline{A},\overline{B}) = \operatorname{dist}(A, B)$","This is the last question on the exercise sheet and I am having real trouble formalizing my intuitions. It should be obvious.  Since the closure of a set is the set of all points in the universe with distance zero to the set, then there should be no difference between finding the distance between the set and the distance between their closures (since zero is the additive identity). I feel like I could take advantage of the triangle inequality to formalize the picture in my head, but I can't seem to grasp it concretely. Working Definitions: $$ d(x, A) = \inf_{a \in A}\{d(x,a)\} $$
$$ \overline{A} = \{x \in X : d(x, A) = 0\} $$
$$ \operatorname{dist}(A, B) = \inf_{b \in B}\{d(b, A)\} $$","['general-topology', 'metric-spaces']"
319419,$e^{iBt}e^{-iAt}$converges as operator norm,"Let $A,B$ be self-adjoint operators on $H$,then we can define the strong limit
$$
W=s-\lim_{t\to+\infty}e^{iBt}e^{-iAt}
$$
If the limit exists, then W is called the wave operator, which is fundamental in the scattering theory. My question here is that if instead, we consider the operator norm above,then what can be said about it ? I was told that the the limit exists if and only if $A=B$, but I don't know how to prove this statement.",['functional-analysis']
319430,Sigma algebra generated by a set,"When determining the smallest sigma-algebra generated by a finite collection of sets (and hence the smallest algebra containing that collection), is there any faster way to do this than by direct computation? On a related note, is there a criterion for selecting a set which generates the finest sigma-algebra (that is, the power set)?",['measure-theory']
319432,Prove that $\frac 1 {x+y}+\frac 1 {y+z}+\frac 1 {z+x}\geq \frac 5 2$.,"Given: $x,y,z\geq0$ $xy+yz+zx=1$ Prove that $\displaystyle \frac 1 {x+y}+\frac 1 {y+z}+\frac 1 {z+x}\geq \frac 5 2$ . I tried using Cauchy's inequality LHS $\geq\frac 9 {2a+2b+2c}$ , but failed. Please give me some ideas. Thank you.","['multivariable-calculus', 'symmetric-polynomials', 'inequality', 'substitution', 'uvw']"
319437,Limit of series involving ratio of two factorials,"$$
  \sum^{\infty}_{j=0} \frac{(j!)^2}{(2j)!} = \frac{2 \pi \sqrt{3}}{27}+\frac{4}{3}
$$ The above series is in a homework sheet. We're not expected to find the limit, just prove its convergence. That's easy, but since we were given the limit, it got me thinking about how to find such a limit. If anyone could point me in the right direction, I'd be happy to discover it on my own, but after a few hours of searching, I don't feel much closer.","['factorial', 'sequences-and-series', 'real-analysis', 'limits']"
319439,"If $f(z)\neq 0$ in a disk $\{z:|z| \leq R\}$, then $\log f(z)$ is a holomorphic function in the disk?","Is this statement true or false? I see it in a book, but I can not give a counterexample. Could you?",['complex-analysis']
319442,Show $\sum_{a_1=1}^n\sum_{a_2=1}^{a_1}\sum_{a_3=1}^{a_2}...\sum_{a_m=1}^{a_{m-1}}a_m=\frac 1 {(m+1)!}\prod_{k=0}^m(n+k)$.,"When playing around Wolfram Alpha, I find something interesting: $\displaystyle \sum_{a_1=1}^n a_1=\frac 1 2 n(n+1)$ $\displaystyle \sum_{a_1=1}^n\sum_{a_2=1}^{a_1} a_2=\frac 1 6 n(n+1)(n+2)$ $\displaystyle \sum_{a_1=1}^n\sum_{a_2=1}^{a_1}\sum_{a_3=1}^{a_2} a_3=\frac 1 {24} n(n+1)(n+2)(n+3)$ I then deduce that $\displaystyle \sum_{a_1=1}^n\sum_{a_2=1}^{a_1}\sum_{a_3=1}^{a_2}...\sum_{a_m=1}^{a_{m-1}}a_m=\frac 1 {(m+1)!}\prod_{k=0}^m(n+k)$. But I don't know how to prove or disprove this. Please help. Thank you.",['sequences-and-series']
319443,"difference between conformal map, biholomorphic map and automorphism","Could anyone tell me what the difference is between a map which is conformal, bi-holomorphic and an automorphism from $D\rightarrow D$ or $D$ to the upper half plane (in that case I know that is not automorphism)? Maybe I am getting confused about terminology? Please someone explain with examples.",['complex-analysis']
319467,Valuation rings,What's the spectrum of a valuation ring? How to describe morphisms from it to a scheme? Is it enough to set the image of generic point and of a maximal ideal and correspondent map of local rings?,"['commutative-algebra', 'algebraic-geometry', 'valuation-theory']"
319474,Hartog's theorem and affineness?,"Is the following true? I see it is true for X affine, but I do mot know how to show it otherwise.
Let X be a normal noetherian local scheme of dimension 2, with closed point s. Show that $X \setminus \{s\}$ is not affine.",['algebraic-geometry']
319488,How do I derive the identity $\sin(a+b)=\sin(a)\cos(b) + \cos(a)\sin(b)$ using the Unit Circle,"I'd like it explained through the unit circle as I find trig identities easier much easier to understand in this manner. EDIT: I know you have to apply the identity $\sin(x)=\cos(90-x)$, but I'm wondering how i'd visualise all this on the unit circle?","['trigonometry', 'algebra-precalculus']"
319508,"Integral $ \int\limits_{-\infty}^\infty \exp \left[-\frac{(x-x_o)^2}{2 \sigma_x^2}-i (p - p_0) \frac{x}{\hbar}\right] \, dx $","Can somebody show me how to calculate this integral? $$
\int\limits_{-\infty}^\infty \exp \left[-\frac{(x-x_o)^2}{2 \sigma_x^2}-i (p - p_0) \frac{x}{\hbar}\right] \,  dx
$$ $x_0$, $p_0$, $\hbar$ are constants and $\sigma_x$ is a standard deviation of the Gaussian which we are integrating here. Somebody told me that i should complete the square. EDIT: Thank you @Michael Hardy for a superb explaination. I did continue your calculation and got this: $$
\begin{split}
&\phantom{=}\int\limits_{-\infty}^\infty e^{-w^2} \cdot \underbrace{\exp \, -\left\{2x_o\dfrac{\sigma_x^2 i (p-p_0)}{\hbar} - \left( \frac{\sigma_x^2 i (p-p_0)}{\hbar} \right)^2 \right\}}_{constant}\, \mathrm{d} w =\\
&= \sqrt{\pi} \exp \, \left\{- 2x_o\dfrac{\sigma_x^2 i (p-p_0)}{\hbar} + \left( \frac{\sigma_x^2 \cdot i (p-p_0)}{\hbar} \right)^2 \right\}
\end{split}
$$ To get this result i used Gaussian integral . What i expected to get was the result in the below picture but my result is somewhat different. Why would that be? Was my integration wrong? In the picture there are some constants before the integral which do not play any signifficant role here. Could someone explain, how author of the integral in the picture gets the result he does?",['integration']
319525,A question concerning multi-indices,"I am having difficulties understanding the following formula : $$(x_1+\cdots+x_n)^k=\sum_{\alpha,|\alpha|=k}\frac{|\alpha|!}{\alpha!}x^\alpha $$
where $\alpha$ is a multi-index. I find this notation very confusing,  I can't even evaluate the first term of the sum. My question is why does this formula hold and how can the sum be expanded? Here is what I know : $\alpha =(\alpha_1,\alpha_2,\cdots,\alpha_n)$  , $|\alpha|=\alpha_1+\alpha_2+\cdots+\alpha_n$ and $\alpha!=\alpha_1!\alpha_2!\cdots\alpha_n!$ Clearly expanding the sum with these yeilds the multinomial expression. What I cant seem to understand is how does the sum expand. Edit: I think it makes sense now. What I needed to know ( and well didn't :/): The condition $|\alpha|=k$ means $\alpha$ is fixed and all that needs to to be done is to find some $\alpha_i's$ whose sum is $k$ and the number of $\alpha_i's$ is equal to the number of terms ($n$ in the equation above)","['notation', 'multinomial-coefficients', 'combinatorics']"
319538,Joint density with continuous and binary random variable,"Assume $X\in\mathbb{R}$, $Y\in\{0,1\}$ are two random variables. What allows us to claim that $$f_{X}(x) = f_{XY}(x,1) + f_{XY}(x,0)$$
where $f_X(x)$ and $f_{XY}(x,y)$ are densities.",['probability-theory']
319551,Nim addition- binary addition without carrying,"A nim addition table is essentially created by putting, in any cell, the smallest number not to the left of the cell and not above that cell in its column. However, I know for a fact that nim addition is equivalent to binary addition without carrying. How does the first method of creating a nim addition table translate to the second method? I am certain it has something to do with the fact that the nim table cycles every $\mathbb{Z}/2^n$. I know that binary addition without carrying is the same as writing out 2 numbers as a sum of powers of 2, scratching out powers appearing in both sums, and adding the remaining. So in essence, I am asking how the first method I mentioned of creating a nim addition table translates to this method. Note that I am not asking about the actual game.","['combinatorial-game-theory', 'game-theory', 'binary', 'number-theory']"
319558,Approximate Differential Equation?,"Let $x \in \mathbb{R}$ be a variable and $c\in\mathbb{R}$ a parameter. Also, let $f(x,c)$ be a function dependent on $x$ and $c$. Furthermore, define a Differential Equation which is solved by the function $y(x)$: $$\left(\frac{d}{dx}\right)^2 y(x) + f(x,c)y(x)=0$$ Suppose, the general Differential Equation is too hard to solve, but for practical reasons only the solution with $c\approx 0$ is required. Naively I would expand $f(x,c)$ around $c=0$ and then compute the approximate Differential Equation. To the order $O(c^1)$ for example I would have to solve the following (where a prime denotes a derivative in respect to $c$): $$\left(\frac{d}{dx}\right)^2 y(x) + \big(f(x,0)+f'(x,0)~c + O(c^2)\big)y(x)=0$$ If $f(x,0)$ and $f'(x,0)$ turn out to be simple enough and if we neglect the $O(c^2)$ terms, this approximated equation might turn out to be solvable. Does this give a mathematically valid approximation for the solution $y(x)$? Maybe there are some subtleties which I did not consider? For instance, I have the feeling that the solution $y(x)$ should also be considered as a function of $c$ (as in $y(x,c)$) and be somehow involved in the expansion. It would be nice if someone knowledgeable could shed some light onto this.","['approximation', 'ordinary-differential-equations']"
319577,Unique factorization in $\mathbb Z(\sqrt{-19})$,"An elementary confusion about class number: In $\mathbb Z(\sqrt{-19})$ we have $N(1+\sqrt{-19}) = (1+\sqrt{-19})(1-\sqrt{-19}) = 2^2\cdot 5.$ I see that 2 and 5 are irreducible, 4 is not. In a UFD a non-zero, non-unit element can be factored uniquely (up to associates) as a finite product of irreducibles. What is it about the two factorizations of 20 above that prevents them from being non-trivial distinct factorizations into a finite product of irreducibles? Thank you.","['algebraic-number-theory', 'abstract-algebra']"
319585,How to solve the non homogeneous equations,"I am looking for the proof of the following I have the following equations $x_1^2+x_2^2+x_3^2+....+x_n^2=1$, $x_1+x_2+x_3+........+x_n=1$ $0 \leq x_i\leq 1$ for-all $i$ I believe that the only solution to the above is one of the variable value is one and remaining all are zero.
If it is true then how can we prove that.
Many Thanks","['roots', 'algebra-precalculus', 'systems-of-equations']"
319588,The span of the orthorgonal projections is norm dense in $B(H)$,This is a question in my functional analysis book. How to use the spectral theorem to prove that the span of the orthogonal projections is norm dense in $B(H)$?,"['operator-theory', 'operator-algebras', 'von-neumann-algebras', 'hilbert-spaces', 'functional-analysis']"
319591,"Why does $\int_{-\infty}^{\infty}e^{-x^2}\sin x\,dx=0?$","I can't get my head around something... Why does $\displaystyle\int_{-\infty}^{\infty}e^{-x^2}\sin x\,dx=0$ but $\displaystyle\int_{-\infty}^{\infty} \sin x\,dx$ or $\displaystyle\int_{-\infty}^{\infty} \frac{\sin x}{x^{2n}}\,dx$ doesn't converge? I thought maybe the first equality can be justified by saying the integrand is odd, but since this is also the case for the others, I don't understand why they aren't $0$. Does this have something to do with the exponential function ""dominating"" the sine?","['improper-integrals', 'integration']"
319594,Normal $T\in B(H)$ has a nontrivial invariant subspace,I am wondering if the following is true: Every normal $T\in B(H)$ has a nontrivial invariant subspace if $\dim(H)>1$?,"['vector-spaces', 'hilbert-spaces', 'functional-analysis', 'operator-theory']"
319609,Noether normalization theorem,"I'm reading: Hulek, ""Elementary Algebraic Geometry"", i can't understand a comment he does about Noether normalization theorem, which tells: Le $k$ be a field with infinitely many elements, let $A=k[a_1,\ldots,a_n]$ be a finitely generated $k$-algebra, then we can find $y_1,\ldots,y_m$ elements of $A$, with $m\leq n$ such that $y_1,\ldots,y_m$ are algebraically indipendent over $k$ and $A$ is a finitely generated $k[y_1,\ldots,y_m]$-module In the comments after the proof, Hulek says:""....we see that $y_1,\ldots,y_m$ can be taken to be any ""general"" choice of linear forms in $a_1,\ldots,a_n$....."" Why linear forms? $y_1,\ldots,y_m$ are elements of $k[a_1,\ldots,a_n]$ so $y_i's$ should be polynomials of arbitrary degree in $a_1,\ldots,a_m$....what does it means linear form in this contest?",['algebraic-geometry']
319615,Solving a quadratic diophantine equation in two variables,"I have an equation in the following form: $$6mn+m+n=x$$ $$m,n,x\in\Bbb Z; \qquad0 < m,n$$ If I were given a value for $x$ , how would I go about finding solutions to this equality for $m$ and $n$ or determining that there are no solutions for $x$ in this form? Example: $x = 15 \implies6(1)(2)+1+2=15 \implies(m=1,n=2),(m=2,n=1)$","['algebra-precalculus', 'diophantine-equations', 'problem-solving']"
319628,Dealt 3 cards. Odds of being dealt any pair?,"This is not to aid a gambling habit.  I am simply curious how to do this math. You get dealt 3 cards.  What are the odds of having any pair?  (We can exclude 3 of a kind) Total number of hands = $\begin{pmatrix}52 \\ 3\end{pmatrix}$  = 22100 What do I do next?  (Added from response below) How many ways can I get a pair of 2's, for example?
$\begin{pmatrix}4 \\ 2\end{pmatrix}$  = 6
And there are 13 types of pairs I can get.
So, 13x6 = 72.
So, there is only a 72/22100 chance of being dealt a pair? Supplemental:  If there are 5 players, what are the odds at least 1 person is holding a pair?","['card-games', 'probability', 'combinatorics']"
319632,Alternative solutions to $\lim_{n\to\infty} \frac{1}{\sqrt{n}}\int_{ 1/{\sqrt{n}}}^{1}\frac{\ln(1+x)}{x^3}\mathrm{d}x$,"Here is a limit that can be computed directly by performing the integration and then taking the limit, but the way is rather ugly. What else can we do? Might we avoid the integration? 
$$\lim_{n\to\infty} \frac{1}{\sqrt{n}}\int_{ 1/{\sqrt{n}}}^{1}\frac{\ln(1+x)}{x^3}\mathrm{d}x$$","['definite-integrals', 'calculus', 'real-analysis', 'limits']"
319650,Definitions of conditional independence,"How are conditional independence defined for various cases? For one case, given two random variables $X$ and $Y$, and a subsigma algebra $\mathcal G$ of the underlying sigma algebra $\mathcal F$, or another random variable $Z$. What is the definition of the conditional independence between $X$ and $Y$ given $\mathcal G$ or $Z$? Is it related to the independence between $E(X\mid \mathcal G)$ and $E(Y \mid \mathcal G)$, and independence between $P(X\in A\mid \mathcal G)$ and $P(Y\in A\mid \mathcal G)$, for any $A \in \mathcal F$? I am trying to see if there is some relation between conditional independence and independence? Thanks and regards!",['probability-theory']
319663,How do I show that a matrix is injective?,"I need to determine whether this matrix is injective 
\begin{pmatrix}
2 & 0 & 4\\
0 & 3 & 0\\
1 & 7 & 2
\end{pmatrix} Using gaussian elimination, this is what I have done:
\begin{pmatrix}
2 & 0 & 4 &|& 0\\
0 & 3 & 0 &|& 0\\
1 & 7 & 2 &|& 0
\end{pmatrix} Divide row1 by 2, and then minus row3 by values of row1:
\begin{pmatrix}
1 & 0 & 2 &|& 0\\
0 & 3 & 0 &|& 0\\
0 & 7 & 0 &|& 0
\end{pmatrix} Divide row 2 by 3, divide row 3 by 7 and minus row 3 by row2:
\begin{pmatrix}
1 & 0 & 2 &|& 0\\
0 & 1 & 0 &|& 0\\
0 & 0 & 0 &|& 0
\end{pmatrix} Am I doing this correctly? How do I show that the matrix is (not) injective? I was thinking along the lines of ""$x + z \ne 0$.""","['matrices', 'linear-algebra', 'gaussian-elimination']"
319665,On the $j_!$ of a sheaf,"Let $X$ be a topological space, and $U$ an open subset. Denote $j:U\to X$ the inclusion. Let $\mathcal F$ be a sheaf on $U$ .
We define $j_!\mathcal F$ to be the sheaf associated to the presheaf $$\mathcal V\mapsto\left\{ \begin{array}{ll} \mathcal F(V) & \mbox{if } V\subseteq U \\ 0 & \mbox{otherwise} \end{array} \right.$$ I know that the stalk $(j_!\mathcal F)_x$ is equal to $\mathcal F_x$ for $x\in U$ , and $0$ for $x\notin U$ , and that $j_!\mathcal F$ is the only sheaf with this property. Is it true that $j_!\mathcal F(V)=0$ whenever $V\nsubseteq U$ ? Is this true under suitable conditions on $X$ ? I'm particularly interested in the case that $X=\mathbb P^1_\mathbb C$ and $\mathcal F=\mathcal O_X$ .","['sheaf-theory', 'algebraic-geometry']"
319686,"Is the unit ball: $B(0,1)=\{f \in L_p(X,u): \|f\|_p<1\}$ convex? , $0<p<1$","Let $(X,\mathbb{X},u)$  be a measure space $L_p(X,u)=\{ f:X\to \mathbb{C}: \|f\|_p<\infty\}$ , $0< p <1$ , $f$: measurable function $\|f\|_p=\left( \displaystyle \int_X |f|^p  \;\text{d}u\right)^\frac{1}{p}$  , $\|\cdot\|_p: $  quasi-norm Is the unit ball: $B(0,1)=\{f \in L_p(X,u): \|f\|_p<1\}$ convex? Any hints would be appreciated.","['functional-analysis', 'real-analysis']"
319687,meaning of $X'=AX$,i have been trying to learn differential equations and I saw various types and methods to solve those types of equations. My question is that $X'=AX$ represents linear DE but I am just seeing linear transformation when I am seeing $AX$. What does this represent ?,"['linear-algebra', 'ordinary-differential-equations']"
319705,$ \lim_{x\rightarrow 0^-} \frac{\operatorname{arccot}(x) - \frac{\pi}{2}}{x}$,"$$\lim_{x\rightarrow 0^-} \frac{\operatorname{arccot}(x) - \frac{\pi}{2}}{x}$$ The title says everything. I already know the limit is $+\infty$, I just want to see how it can be calculated. (Please don't use L'Hôpital's rule, I haven't covered it yet at school)",['limits']
319724,Isomorphic Hilbert spaces,"As part of a broader proof , I need to show that every two separable Hilbert spaces (that contains a dense countable set) are isomorphic (the linear mapping from one space to the other is injective and isometric if I say right). I'd be happy to get any help on this.","['hilbert-spaces', 'functional-analysis', 'abstract-algebra']"
319737,for all $a>0$ find supremum of $f(x)=a^{-x} + a^{\frac{-1}{x}} \in (0;+\infty)$,"As in topic, this quest is marked as a rather difficult. All I suppose is that it has something to do with maybe defining a helpful function like $$g(x):= \ln {f(x)}$$ and then doing something with $g'(x)$, but I am not quite sure why do I have to act that way. Could anyone give a hint? Thank you for your time.","['calculus', 'analysis']"
319764,"1 to the power of infinity, why is it indeterminate? [duplicate]","This question already has answers here : Why is $1^{\infty}$ considered to be an indeterminate form (9 answers) Closed 11 years ago . I've been taught that $1^\infty$ is undetermined case. Why is it so? Isn't $1*1*1...=1$ whatever times you would multiply it? So if you take a limit, say $\lim_{n\to\infty} 1^n$, doesn't it converge to 1? So why would the limit not exist?","['exponentiation', 'infinity', 'limits']"
319768,push forward of vector field,"In Gauge Fields, Knots, and Gravity , exercise 18 is the following: Show that if $\phi:M \to N$ we can push forward a vector field $v$ on $M$ to obtain a vector field $\phi_*$ on $N$ satisfying $(\phi_* v)_q = \phi_*(v_p)$, whenever $\phi(p)=q$ . I don't understand the question. I don't see how $(\phi_* v)_q$ is defined, given that we always apply the pushforward to tangent vectors, and not vector fields. If someone could explain the question, that would be good. Edit: $M$ and $N$ are smooth manifolds, $\phi$ is a diffeomorphism.",['differential-geometry']
319772,Linear optimization problem: Minimizing a linear function over an affine set.,"The problem is as follows: Give an explicit solution of the linear optimization problem below. $$ 
   \text{minimize}\ c^Tx \\
   \text{subject to}\ Ax\ =\ b
$$ No other information is given. My solution is  basically as follows: $$
p^*\ = \left\{ 
  \begin{array}{l l}
    \infty & \quad \text{if $Ax=b$ has no solution}\\
    \lambda^\top b & \quad c=A^\top \lambda \text{ for some } \lambda\\
    \ -\infty & \quad \text{if $Ax=b$ has infinitely many solutions (underdetermined)}
  \end{array} \right.
$$ When $Ax=b$ has no solution the problem is infeasible. Therefore the optimal point is $\infty$. When $Ax=b$ has infinitely many solutions, the system in unbounded below and therefore the optimal solution in $-\infty$. Now the actual solution of this problem is shown here (See problem 4.8 part a): http://www.docin.com/p-347099771.html I would like to understand how they got the second solution ($\lambda^Tb$) when A is non-singular and Ax=b has a unique solution. Thanks in advance.","['optimization', 'matrices', 'convex-optimization']"
319784,Understanding a particular evaluation of $\prod\limits_{n=2}^{\infty}\left(1-\frac{1}{n^3}\right)$,"I'm having a hard time understanding the following evaluation of the infinite product $$ \prod_{n=2}^{\infty}\left(1-\frac{1}{n^3}\right).$$ In particular, I don't understand how you go from line 2 to line 3. Here $\omega = -\frac{1}{2}+ i \frac{\sqrt{3}}{2}$ , which is a primitive third root of unity. $$\begin{align}\prod_{n=2}^{\infty}\left(1-\frac{1}{n^3}\right)  &=\prod_{n=2}^{\infty}\frac{(n-1)(n^2+n+1)}{n^3} \\  &=\lim_{m\to\infty}\frac{1}{m}\prod_{n=2}^m\frac{(n-\omega)(n-\omega^2)}{n^2} \\  &=\lim_{m\to\infty}\frac{\Gamma(m+1-\omega)\Gamma(m+1-\omega^2)}{m(m!)^2\Gamma(-\omega)\Gamma(-\omega^2)(1-\omega)(1-\omega^2)(-\omega)(-\omega^2)} \\  &=\frac{1}{3\Gamma(-\omega)\Gamma(-\omega^2)} \\ &=\frac{\sin{\pi(-\omega)}}{3\pi} \\  &=\frac{\cosh (\frac{\sqrt{3}\pi}{2})}{3\pi } \end{align}$$ EDIT : I think I'm starting to make sense out of this by writing out the terms. $$ \begin{align} \prod_{n=2}^{m} \frac{(n- \omega)(n-\omega^{2})}{n^{2}} &= \frac{(2-\omega)(3-\omega) \cdots (m- \omega)(2-\omega^{2})(3-\omega^{2})\cdots (m- \omega^{2})}{2^{2} \cdot 3^{2} \cdot \cdots  \cdot m^{2}}  \\ &= \frac{1}{(m!)^{2}} \frac{\Gamma(m+1-\omega)}{(1-\omega)(-\omega)\Gamma(-\omega)} \frac{\Gamma(m+1-\omega^{2})}{(1-\omega^{2})(-\omega^{2})\Gamma(-\omega^{2})} \end{align}$$ Now I have to figure out how to take the limit as $m \to \infty$ .","['gamma-function', 'infinite-product', 'limits']"
319791,"If $g$ is an element in an abelian group $G$ and $H\leqslant G$, must there exist an $n$ such that $g^n\in H$?","Let $G$ be an abelian group and $H$ a subgroup of $G$. For each $g \in G$, does there always exist an integer $n$ such that $g^{n} \in H$?","['group-theory', 'abstract-algebra', 'abelian-groups']"
319802,An approximate eigenvalue for $ T \in B(X) $.,"This is a problem from Conway’s Functional Analysis : Definition An approximate eigenvalue for $ T \in B(X) $ is a scalar $ \lambda $ such that there is a sequence of unit vectors $ x_{n} \in X $ such that $ T(x_{n}) - \lambda x_{n} \rightarrow 0 $. Show that any eigenvalue for $ T $ is an approximate eigenvalue for $ T $, and that any approximate eigenvalue for $ T $ lies in the spectrum of $ T $, which we denote by $ \sigma(T) $. If $ X $ is a Hilbert space, show that $ \lambda \in \sigma(T) $ if and only if either $ \lambda $ is an approximate eigenvalue for $ T $ or $ \overline{\lambda} $ is an eigenvalue for $ T^{*} $.","['eigenvalues-eigenvectors', 'banach-spaces', 'spectral-theory', 'hilbert-spaces', 'functional-analysis']"
319812,Is $\mathbb{Z}^2$ cyclic?,Is $\mathbb{Z}^2$ cyclic? What does it mean for a group to be cyclic? Is it just that it has one generator? Thanks,"['cyclic-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
319814,Why the number of ways of selecting $r$ things out of $n$ identical things is 1,"Would some one please provide me a detailed information regarding -
""why the number of ways selecting $r$ things out of $n$ identical things is 1"". Here is my example - let's say I entered into clothes shop and I saw a set of 100 identical shirts. So if I have to select any 5 out of these 100, I can select them in 
even series or odd series or multiples of 10 series or first 5 or last 5 or randomly any 5 right? then why every where I am seeing just ""1"" as answer.",['combinatorics']
319855,"Say $f$ is entire, $|f'(z)|\le e^{|z|}$, and $f$ vanishes on the set $\{\frac{n}{\sqrt{1+|n|}}: n\in \mathbb{Z}\}$. Why must $f$ be constantly zero?","Say $f$ is entire, $|f'(z)|\le e^{|z|}$, and $f$ vanishes on the set $\{\frac{n}{\sqrt{1+|n|}}: n\in \mathbb{Z}\}$. Why must $f$ be constantly zero?",['complex-analysis']
319867,"How to show that quotient space $X/Y$ is complete when $X$ is Banach space, and $Y$ is a closed subspace of $X$?","How to show that quotient space $X/Y$ is complete when $X$ is Banach space, and $Y$ is a closed subspace of $X$? Here's my attempt: Given a Cauchy sequence $\{q_n\}_{n \in \mathbb{N}}$ in $X/Y$, each $q_n$ is an equivalence class induced by $Y$, I want to find a representative $x_n$ in $q_n$ so that the induced sequence $\{x_n\}_{n \in \mathbb{N}}$ is also a Cauchy sequence in $X$. But I don't know how to construct such sequence.","['vector-spaces', 'quotient-spaces', 'functional-analysis', 'banach-spaces']"
319868,Metric completion of field of fractions,"The integers have as a field of fractions the rational numbers which have a metric completion as the real numbers. The reals can be represented by infinite decimal expansions which can be approximated by finite decimal expansions and some real numbers have algorithms which can generate the digits but some reals are uncomputable and some are undefinable. If instead you start with a polynomial ring, $\Bbb{Q}[X]$ say, and form the field of rational functions $\Bbb{Q}(X)$, what metric completions of this fraction field exist and how can they be represented? For background see profile.","['metric-spaces', 'function-fields', 'abstract-algebra', 'number-theory']"
319869,Jacobian of a Composition involving a Linear Transformation,"Let $f:{\mathbb{R}^n} \to \mathbb{R}$. For each $z \in {\mathbb{R}^n}$ define $\tilde f\left( z \right) = f\left( x \right)$, where $x = Az + s$, for some $A \in {\mathbb{R}^{n \times n}}$, $s \in {\mathbb{R}^n}$. I want to find $\nabla \tilde f\left( z \right)$ and ${\nabla ^2}\tilde f\left( z \right)$ in terms of $\nabla f\left( x \right)$ and ${\nabla ^2}f\left( x \right)$, respectively. Please note the following: In class we defined the gradient of a function $f:{\mathbb{R}^n} \to \mathbb{R}$ w.r.t. $x=(x_{1},...,x_{n})$ as follows: $$\nabla f\left( x \right) = {\left[ {\frac{{\partial f}}{{\partial {x_1}}}\left( x \right),...,\frac{{\partial f}}{{\partial {x_n}}}\left( x \right)} \right]^T};$$ ${\nabla ^2}f\left( x \right)$ is the Hessian of $f$; I'll denote the Jacobian of $f$ by ${J_f}$. Here's what I've done: $x = \varphi \left( z \right) = Az + s$, where $A = {\left( {{a_{ij}}} \right)_{\scriptstyle1 \le i \le n\atop\scriptstyle1 \le j \le n}}
$ and $s = {\left( {{s_i}} \right)_{1 \le i \le n}}
$. $$\nabla \tilde f\left( z \right) = {J_{\tilde f}}{\left( z \right)^T} = {J_{f \circ \varphi }}{\left( z \right)^T} = {\left( {{J_f}\left( {\varphi \left( z \right)} \right){J_\varphi }\left( z \right)} \right)^T} = {J_\varphi }{\left( z \right)^T}{J_f}{\left( x \right)^T} = {J_\varphi }{\left( z \right)^T}\nabla f\left( x \right)$$ Now, as the i th component of $\varphi$ is $${\varphi _i \left( z \right)} = \sum\limits_{j = 1}^n {{a_{ij}}z}  + {s_i}$$
then, $\frac{{\partial {\varphi _i}}}{{\partial {z_i}}}\left( z \right) = {a_{ij}}$, for all $j = 1,...,n$ and $z \in {\mathbb{R}^n}$. Consequently, ${J_\varphi }{\left( z \right)}=A$, so I can conclude that:
$$\nabla \tilde f\left( z \right) = A^T \nabla f\left( x \right).$$ The problem arises when I try to find ${\nabla ^2}\tilde f\left( z \right)$. I know that: $$\nabla \tilde f = {A^T} \circ \nabla f \circ \varphi$$
so
$${\nabla ^2}\tilde f\left( z \right) = {J_{{A^T} \circ \nabla f \circ \varphi }}\left( z \right).$$
However, I don't know how to take $A^T$ out of the Jacobian. I suspect that:
$${J_{{A^T} \circ \nabla f \circ \varphi }}\left( z \right) = {A^T} {J_{\nabla f \circ \varphi }}\left( z \right) = {A^T} {J_{\nabla f}}\left( {\varphi \left( z \right)} \right) {J_\varphi }\left( z \right) = {A^T} {J_{\nabla f}}\left( {\varphi \left( z \right)} \right) A = {A^T} {\nabla ^2}f\left( x \right) A$$
but I don't know to justify the first step in the last string of equalities. Is my suspicion correct? Why? I'd greatly appreciate any help. Thanks in advance.","['multivariable-calculus', 'real-analysis']"
319870,distribution with point support,"Let $u$ be a distribution on $\mathbb{R}^n$ with support = $\left\{0\right\}$. Then there exists $N$ such that $u$ has order $N$. Let $\chi\in C_0^{\infty}(\mathbb{R}^n)$ a smooth function with $\chi(x) = 1$ for $0\leq |x|\leq 1 $, $\chi(x)\in [0,1]$ for $1\leq |x|\leq 2$, $\chi(x)=0$ for $|x|\geq 2$ Denote $ \chi(x/r) = k_r(x)$ for $r\in (0,1]$. For the case $N=0$ I want to show that there exists $c_1$ such that $$|\left\langle u,\phi \right\rangle|\leq c_1 |\phi(0)|  $$
for all $\phi \in C_0^{\infty}(\mathbb{R}^n)$. The idea would be to apply $u$ on $\phi = k_r\phi+(1-k_r)\phi$ and letting $r\to 0$. So then I guess we can write $$ |\left\langle u,\phi \right\rangle| \leq |\left\langle u,k_r\phi \right\rangle| + |\left\langle u,(1-k_r)\phi \right\rangle |$$
But not really sure how this follows... Moreover how can i show that $\left\langle u,\phi \right\rangle = \left\langle u,\phi \chi\right\rangle = \left\langle u,\chi\right\rangle\phi(0) $?","['distribution-theory', 'functional-analysis', 'real-analysis']"
319878,Can a collection of points be recovered from its multiset of distances?,"Consider $n$ distinct points $x_1,\dots,x_n$ on $\mathbb{R}$. Associated to these points is the multiset of all distances $d(x_i,x_j)$ between two points. Suppose one is only handed this multiset (you do not know the corresponding indices). Does this allow one to uniquely recover the original points up to reflection and translation?","['metric-spaces', 'discrete-mathematics', 'recreational-mathematics', 'combinatorics']"
319914,Find the value $\sum_{n=1}^{\infty}(e-(1+\frac{1}{n})^n)$,How to find the following series' value? $$\sum_{n=1}^{\infty}\bigg(e-\Big(1+\frac{1}{n}\Big)^n\bigg)$$,"['sequences-and-series', 'calculus', 'real-analysis', 'analysis']"
319921,Use Integration by Parts to prove that $\int x^{n}\ln{x}\ dx=\frac{x^{n+1}}{(n+1)^{2}}\left[-1+(n+1)\ln{x}\right]+c$,"I've gotten most of the way, but I can't see how I can transform my answer into the form in the assignment: Use Integration by Parts to prove that $\displaystyle\int x^{n}\ln{x}\ dx=\frac{x^{n+1}}{(n+1)^{2}}\left[-1+(n+1)\ln{x}\right]+c$ \begin{align}
\int x^n\ln{x}\ dx&=\frac{\ln{x}\cdot x^{n+1}}{n+1}-\int\frac{x^{n+1}}{n+1}\cdot\frac{1}{x}\ dx\\
&=\frac{\ln{x}\cdot x^{n+1}}{n+1}-\frac{1}{n+1}\int x^n\ dx\\
&=\frac{\ln{x}\cdot x^{n+1}}{n+1}-\frac{1}{n+1}\left[\frac{x^{n+1}}{n+1}\right]+C\\
&=\frac{x^{n+1}}{(n+1)^2}+\dots
\end{align}","['calculus', 'integration']"
319934,"If $V$ is a vector space over $k$, is every $k[x]$-module structure on $V$ induced by some linear transformation?","Suppose $V$ is a vector space over a field $k$. Fixing a linear transformation $T$, it is common to make $V$ a $k[x]$-module by defining $f(x)\cdot v=f(T)(v)$. Is every possible $k[x]$-module structure over $V$ necessarily induced by some $T\in L(V)$? If $V$ is some $k[x]$-module, we can define a map $T$ on $V$ by $T(v)=x\cdot v$. Then $T$ is additive. But for scalars, 
$$T(cv)=x\cdot(cv)=(xc)\cdot v=(cx)\cdot v=c\cdot(x\cdot v)=c\cdot T(v)$$
but I don't think we can assume that multiplication by scalars in $k$ over $V$ as a $k$-vector space needs to be the same as multiplication by scalars in $k$ when viewing $V$ as a $k[x]$-module.","['modules', 'abstract-algebra']"
319947,Maximal ideals in polynomial rings with real and complex coefficients,"I was asked in homework to think about maximal ideals in polynomial rings $\mathbb{R}[x]$ and $\mathbb{C}[x]$. I have realized that: $\forall c\in\mathbb{R},\;I_c : = \{p(x)\in\mathbb{R}[x]\;|\;p(c) = 0\}$ is an ideal (similar for $\mathbb{C}[x]$), now in order to prove it to be maximal, I need to show:
$$I_c\subset J\subsetneq A,\;J\text{ is an ideal}\Longrightarrow I_c = J$$
which I have difficulty showing. Secondly, I don't know how to show that all maximal ideas are in the form of $I_c$. Some help please. Thank you.",['abstract-algebra']
319954,System of linear differential equations with time-varying coefficients,"Could someone please suggest a technique for solving the following system of ODEs? $$\begin{aligned} x_1' &= \,\,\,\,(1 + 2 \cos 2t) x_1 + (1 - 2\sin 2t) x_2\\ x_2' &= - (1 + 2 \sin2t) x_1 + (1 - 2 \cos 2t) x_2 \end{aligned} $$ What I initially tried to do was differentiate the first equation to obtain an equation for $x_1''$ and then substitute expressions for $x_2$ and $x_2'$ .  This resulted in a second-order DE involving $x_1''$ , $x_1'$ , and $x_1$ .  But this equation was extremely complex in terms of its variable coefficients.  I am thinking there must be a simpler approach.  Thanks.",['ordinary-differential-equations']
319959,"How to rigorously justify ""picking up half a residue""?","Often in contour integrals, we integrate around a singularity by putting a small semicircular indent $\theta \rightarrow z_0 + re^{i\theta}$, $0 \leq \theta \leq \pi$ around the singularity at $z_0$. Then one claims that the integral ""picks up half a residue"" as $r \rightarrow 0$, so we compute the residue, divide by two, and multiply by $2\pi i$ to get the limiting value of the integral over the small semicircle. I don't see how to justify this rigorously. I tried adapted the proof of the residue theorem, which involves expanding Taylor series, but this crucially relies on the fact that the path is closed. I also tried using seeing if the values of the function on the semicircle all tend to the same value as the semicircle shrinks to zero. But I'm not sure if this is even true, since we don't really have nice behavior of the function at $z_0$. So my question is this. Under what circumstances can we claim that the integral over a small semicircle centered at a pole $z_0$ is $\pi i$ times the residue at $z_0$, and how do we prove this?","['residue-calculus', 'complex-analysis']"
319963,"If $2^n - 1$ is prime from some integer $n$, prove that n must also be prime.","I understand the idea of the proof. I just want to make sure I wrote my proof well. Suppose $n$ is not prime. Then $\exists x,y \in \mathbb{Z}$ such that $n = xy$. $2^{xy} - 1 = (2^x)^y - 1$ $ = (2^y - 1)(2^{y(x-1)} + 2^{y(x-2)} + ... + 2^{y} + 1)$ Since $2^{n} - 1$ is divisible by $2^y - 1$ it must be that $2^n - 1$ is not prime. Contradiction. Thus $n$ must be prime. How does this look?","['divisibility', 'number-theory']"
319968,Integrating $\sin^2(x)$ using imaginary numbers.,"I know I can change ""$\sin^2\theta$"" to ""$\frac{1}{2}(1-\cos(2\theta))$"" or use integration by parts, but I was curious about doing it using imaginary numbers. I tried this but it didn't work. $$\int \sin^2\theta d\theta= \operatorname{Im}\left\{ \int e^{2i\theta }\right\} = \operatorname{Im}\left\{ \frac{1}{2i} e^{2i\theta }\right\}= \operatorname{Im}\left\{ \frac{\cos2\theta + \sin2\theta i}{2i}\right \}= -\frac{1}{2}\cos2\theta$$ this is not the same answer I get using the other methods. I assume I did something wrong somewhere. How should I do this?","['trigonometry', 'complex-numbers', 'integration']"
319975,If $A \subseteq C$ and $B \subseteq D$ then $A \times B \subseteq C \times D$,"Show that: if $A \subseteq C\,$ and $\,B \subseteq D,\,$ then $\,A \times B \subseteq C \times D.$ Can anyone help me with this?","['logic', 'discrete-mathematics', 'elementary-set-theory']"
