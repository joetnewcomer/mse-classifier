question_id,title,body,tags
4471600,When an ellipse touches the sides of a triangle,"An ellipse touches the sides of a triangle $abc$ from inside in the points $a',b',c'$ . How can I prove, that the lines $ aa',bb',cc'$ meet in one point? The ellipse equation is : $ \frac{x^2}{A^2} + \frac{x^2}{B^2}= 1 $ I've seen this kind of questions in old exams, therefore I would like to know how to handle such a proof right. Do I have to build equations for $aa',bb',cc'$ ? If yes, how do do that?","['conic-sections', 'geometry']"
4471615,Structure induced by a sheaf,"Let $n\geq 1$ and $F$ be a sheaf on $\mathbb{R}^n$ of continuous functions. Assume for every open subsets $U,V$ of $\mathbb{R}^n$ and every $f\in F(U)$ , $g\in F(V)$ , $g\circ f\in F(U\cap f^{-1}(V))$ . $\bullet$ Is there a name to qualify such a sheaf ? Let $X$ is a set, $(U_i)_{i\in I}$ a collection of non empty subsets covering $X$ and for $i\in I$ , let $z_i:U_i\to\mathbb{R}^n$ be and injective function with an open image. If we assume that for every $(i,j)\in I^2$ , $z_i(U_i\cap U_j)$ is open and $z_j\circ z_i^{-1}\in F(z_i(U_i\cap U_j))$ then there is a unique topology on X such that each $z_i$ is a homeomorphism onto it's image. $\bullet$ Is there a name to define such structure on $X$ induced by $F$ ? A $F$ -manifold or something like that ? For example if $n=2$ and $F$ is the sheaf of holomorphic maps on $\mathbb{C}$ then a Riemann surface is any set $X$ with a Hausdorff connected topology induced by $F$ . Smooth manifolds are defined is a similar way.","['manifolds', 'riemann-surfaces', 'sheaf-theory', 'differential-geometry']"
4471680,What does $\mbox{diag}(A)$ denote?,"Let $A$ be a $2 \times 2$ matrix. What does $\mbox{diag}(A)$ denote? It can't refer to a block-diagonal matrix, so does it basically mean $A$ with anything but the diagonal set to $0$ ?","['matrices', 'notation', 'linear-algebra']"
4471682,Chasing a monster on a $3 \times 3$ grid,"There are nine rooms as shown below $$\begin{array}{|c|c|c|}\hline1&2&3\\\hline4&5&6\\\hline7&8&9\\\hline\end{array}.$$ A monster is in one of the rooms. Each turn, the people open $k$ different rooms and check if the monster is inside. If the monster isn’t seen, it will go to another room that has a common side with the previous one. Find $k$ for which people can guarantee finding the monster. I proved $k=3$ works. First, while the monster is hidden, its room number will go in a cycle of odd and even. Open rooms $(2,4,6);(2,4,6);(5,7,9);(5,7,9)$ in the first four turns in this order. I’ll prove this works by separating the problem into two cases: The room number of the monster is odd-even-odd-even in the first four turns. Then in the second turn the monster must be in room $8$ or else it is found. So in the third turn the monster must be found. The room number of the monster is even-odd-even-odd in the first four turns. Then in the third turn the monster must be in room $8$ or else it is found. So in the fourth turn the monster must be found. But how to prove $k<3$ doesn’t work?","['contest-math', 'combinatorics']"
4471691,How to solve the triangulation problem?,"I have $3$ sensors. I've built the following system of equations that match the data from sensors. I need to find $x$ , $y$ , $R_a$ , $R_b$ , $R_c$ , $\alpha$ , $\beta$ and $\gamma$ . Can you please help me, or at least hint how can I solve this system. \begin{align}A_x & = x+R_a\cos \alpha \\
A_y & = y+R_a\sin \alpha \\
B_x & = x+R_b\cos \beta \\
B_y & = y+R_b\sin \beta \\
C_x & = x+R_c\cos \gamma \\
C_y & = y+R_c\sin \gamma \\
R_b-R_a & = z_1 \\ 
R_c-R_a & = z_2
\end{align}","['trigonometry', 'systems-of-equations', 'triangulation']"
4471713,Proving that $\angle MAC = 30^{\circ}$,"In $\Delta ABC$ , $M$ is an interior point such that, $MB=MA$ , $MC=CB$ , $\angle CBA = 2 \angle BAC$ . Prove that $\angle MAC = 30^\circ$ I was able to solve this question using trigonometry here's my solution I was however unable to find any synthetic solution and require some aid for that.","['euclidean-geometry', 'triangles', 'angle', 'geometry']"
4471729,"Let $a_1$ be linearly independent to $a_2$ over $\mathbb{Q}.$ For $n\geq 3,$ let $ a_n = \vert a_{n-1} - a_{n-2} \vert.$ Does $\sum_n a_n\ $ converge?","Let $a_1$ be linearly independent to $a_2$ over the rational numbers. For $n\geq 3,\ $ let $ a_n = \vert a_{n-1} - a_{n-2} \vert.$ Does $\sum_n a_n\ $ converge? For example, let $a_1 = 1,\ a_2 = \ln 2=0.693\ldots\ .\ $ Then, $\ a_3 = \vert a_2 - a_1 \vert = 0.306\ldots,\ \ a_4 = \vert a_3 - a_2 \vert = 0.386\ldots,\ \ a_5 = \vert a_4 - a_3 \vert = 0.0794\ldots\ .$ I am not sure how to judge how quickly this converges to $0.$","['convergence-divergence', 'irrationality-measure', 'euclidean-algorithm', 'sequences-and-series']"
4471756,Is it possible to prove that for any injective function $f: \mathbb{R} \to \mathbb{R}$ if $f(x)>f^{-1}(x)$ then $f(x)>x$?,"So I just came up with this question in my brain, when thinking about that the inverse function has a graph that is symmetric to the original function's graph about the line $y=x$ . Then if $f(x)>f^{-1}(x)$ the curve of $f$ should be strictly above $f^{-1}$ without any intersection, and by my instinct I think it shall be able to deduce that $f(x)>x$ for all $x$ , but I do not know how to prove this either algebraically or rigorously graphically. So is this statement true? And if so, how can it be proved?","['functions', 'geometry', 'real-analysis']"
4471781,How to show that if two vector fields $X$ and $Y$ are tangent to a submanifold then so is their Lie bracket?,"Let $M$ be a smooth manifold and let $Q$ be a submanifold of $M$ . Consider two vector fields $X, Y \in \mathfrak{X}(M)$ such that $X_q, Y_q\in T_qQ$ for every $q\in Q$ . Prove that $[X, Y]_q\in T_qQ$ for every $q\in Q$ . So, I came across the following proposition in Lee's ""Introduction to Smooth Manifold"": Proposition 8.22. Let $M$ be a smooth manifold, $S\subseteq M$ be an embedded manifold with or without boundary, and $X$ be a smooth vector field on $M$ . Then $X$ is tangent to $S$ if and only if $(Xf)|_S=0$ for every $f\in C^\infty(M)$ such that $f|_S\equiv0$ . Thus, I thought that I have to show that, for $f\in C^\infty(M)$ such that $f|_Q=0$ , we have $[X, Y]_q(f)=0$ . But $[X, Y]_q(f)=X_q(Y(f))-Y_q(X(f))=0$ because $Y(f)$ and $X(f)$ are smooth functions on $M$ that vanish on $Q$ and $X_q$ and $Y_q$ are in $T_qQ$ . So, I thought that I was done, but my instructor said that this doesn't prove that $[X, Y]_q\in T_qQ$ . I don't really understand why, could anyone please explain this to me?","['vector-fields', 'lie-derivative', 'differential-geometry']"
4471804,"Please recommend a good textbook on measure theory, real analysis","I have read that G.B.Folland's real analysis. I like the contents that I covers because, like baby Rudin, I can study a lot of content fast. Nevertheless, I took a lot of time to understand since the proofs of the book are omitted much. A lot of proofs that (in my thought) would have been okay to be explained more were omitted. So I am looking for a more descriptive book that covers Folland's contents and its approaches. I have looked through some other books but I don't think I've ever seen a book that covers some topics like Radon-Nikodym theorem or Caratheodory's theorem as detailed as Folland's. I have heard that 'The way of analysis' is Baby Rudin's manual, and I wonder if there is a book in a similar position about Folland's real analysis book.","['measure-theory', 'reference-request', 'book-recommendation', 'real-analysis']"
4471842,Geometry - I am getting two different results when using two different scalar product properties,"I am trying to solve a problem regarding the scalar product.
The problem has multiple choices, and I solved it in two different ways, and got different values. Both of the values were a choice, but only one of them is right, and I don't understand why. Here is the problem: Firstly, I have this image along with the following info: $[AB]$ is a diameter of the circumference of center $O$ The radius value is 2 The triangle $[AOP]$ is a right triangle And then, I am asked the value of $ \vec {AP} \cdot \vec {AB} $ . Those are my two answers: Answer 1: $ \overline {AO} = 2 \\ \overline {OP} = 2 $ $ 
\overline {AP}^2 = \overline {AO}^2 + \overline {OP}^2 \\
\overline {AP}^2 = 2^2 + 2^2 \\
\overline {AP} = \sqrt {8}, \overline {AP} > 0  \\
\overline {AP} = 2 \sqrt 2
$ Since $O$ is the orthogonal projection from $P$ in $ \overline {AB} $ , $\vec {AP} \cdot \vec {AB} = \vec {AP} \times \vec {AO} = 2 \sqrt 2 \times 2 = 4 \sqrt 2 $ Answer 2: $
\newcommand{\sininv}{\sin^{-1}}
\sin \alpha = \frac {\overline {OP}} {\overline {AP}} = \frac 2 {2 \sqrt 2} = \frac {\sqrt 2} 2 \\
\alpha = \sininv (\frac {\sqrt 2} 2) = 45º
$ $
\vec {AP} \cdot \vec {AB} = \overline {AP} \times \overline {AB} \times \cos 45º = \frac {8 \sqrt 2 \times \sqrt 2} 2 = 4 \times 2 = 8
$ The right answer is the second one. Why can't I use the first one to solve the problem? I would appreciate any help.","['inner-products', 'trigonometry', 'geometry']"
4471844,Is there a way to use the Weierstrass Substitution for $n\theta$?,"So, I was looking at the Wikipedia page for the tangent half-angle formula (or Weierstrass substitution) and I noticed something: Is there a similar set of substitutions as the ones below: $$\cos\theta = \frac{1 - t^2}{1 + t^2}$$ $$\sin\theta = \frac{2t}{1 + t^2}$$ $$\tan\theta = \frac{2t}{1 - t^2}$$ but have $n\theta$ instead of $\theta$ ? Edit: The reason why I asked this question is because I was trying to solve the following question below (I made the question up!) : Find the value of $\theta$ and hence the $s_\infty$ in this geometric sequence : $$\frac{1}{2}\sin^4 4\theta, \frac{1}{6}\cos^3 8\theta, \frac{1}{24}\tan^2 12\theta$$ and I ended up with this equation (by trying to find $r$ and using the fact that $\frac{u_2}{u_1}$ $=$ $\frac{u_3}{u_2}$ as well as using power-reduction formulas and sum-to-product formulas) : $2\cos 24\theta(3\cos 8\theta - 2) + \cos 16\theta (8 cos 4\theta - 1) + \cos 4\theta - 4 = 0$ I was thinking at this point to use the Weierstrass substitution for $\cos$ $n\theta$ but I couldn't find any analogue for it, hence the posting of this question. Edit 2: Although the solution posted by Somos is great for personal use, I have decided to uncheck the solution because I want a solution to the question asked above that I can explain easily to A-Level Mathematics students that don't want to hear about anything beyond the syllabus. So if there are any solutions that stay within the boundaries of A-Level Mathematics, please feel free to post it. Edit 3: The reason why I have checked Somos's solution is that the solution has helped me out the most, not because it solves the problem.",['trigonometry']
4471854,Cauchy equivalent condition,"Let $E$ be a topologic vector space. $x_i$ with $i\in I$ is a Cauchy net iff $\lim_j \ x_{\phi(j)}-x_{\psi(j)}=0$ for any $(\phi,\psi)$ pair of cofinal and increasing maps from $J$ to $I$ . I proved the necessity part but I struggle with sufficiency. I assumed the given limit is zero but $x_i$ is not a Cauchy net. Then $\exists V$ $0$ -neighborhood $\forall i\in I \ \ \exists i_1,i_2 \geq i$ such that $x_{i_1}-x_{i_2} \notin V$ . Also given limit says $\forall V$ $0$ -neighborhood $\exists j_0 \in J$ such that $\forall j\geq j_0 \ \ x_{\phi(j)}-x_{\psi(j)}\in V$ I cannot see the relation between $i_1,i_2$ and maps for getting contradiction because I am not sure about surjectivity. How can I proceed to get given limit is not zero? I appreciate any kind of help. Thanks","['general-topology', 'cauchy-sequences', 'analysis']"
4471856,Can we determine the transition semigroup of a Markov process by its resolvent?,"Let $(E,\mathcal E)$ be a measurable space, $$\mathcal E_b:=\left\{f:E\to\mathbb R\mid f\text{ is bounded and }\mathcal E\text{-measurable}\right\}$$ be equipped with the supremum norm and $(\kappa_t)_{t\ge0}$ be a Markov semigroup on $(E,\mathcal E)$ . It is easy to verify that $$\kappa_tf:=\int\kappa_t(\;\cdot\;,{\rm d}y)f(y)\;\;\;\text{for }f\in\mathcal E_b\text{ and }t\ge0$$ is a contraction semigroup on $\mathcal E_b$ . So, it does make sense to talk about the (integral representation of the) resolvent of $(\kappa_t)_{t\ge0}$ . However, we can consider something weaker here. Assume that $$[0,\infty)\to\mathbb R\;,\;\;\;t\mapsto(\kappa_tf)(x)\tag1$$ is Borel measurable for all $(x,f)\in E\times\mathcal E_b$ . Now, let $$\rho_{\text w}:=\left\{\lambda\in\mathbb R:\int_0^\infty e^{-\lambda t}\left|(\kappa_tf)(x)\right|\:{\rm d}t<\infty\text{ for all }(x,f)\in E\times\mathcal E_b\right\}$$ and $$R_\lambda(x,B):=\int_0^\infty e^{-\lambda t}\kappa_t(x,B)\:{\rm d}t\;\;\;\text{for }(x,B)\in E\times\mathcal E\text{ and }\lambda\in\rho_{\text w}.$$ Question 1 : Let $\lambda\in\rho_{\text w}$ . What do we need to ensure that $R_\lambda$ is actually a Markov kernel on $(E,\mathcal E)$ ? Is it sufficient (by Fubini's theorem) to assume that $$[0,\infty)\times E\to\mathbb R\;,\;\;\;(t,x)\mapsto(\kappa_tf)(x)\tag2$$ is Borel measurable for all $f\in\mathcal E_b$ ? Question 2 : What is the weakest assumption we need to impose in order to show that $$[0,\infty)\to\mathcal E_b\;,\;\;\;t\mapsto\kappa_tf\tag3$$ is Borel measurable for all $f\in\mathcal E_b$ ? Is it sufficient to assume Borel measurablility of $(2)$ for all $f\in\mathcal E_b$ ? Now let $(\Omega,\mathcal A,\operatorname P)$ be a probability space, $(\mathcal F_t)_{t\ge0}$ be a filtration on $(\Omega,\mathcal A)$ and $(X_t)_{t\ge0}$ be an $(E,\mathcal E)$ -valued $(\mathcal F_t)_{t\ge0}$ -adapted process on $(\Omega,\mathcal A,\operatorname P)$ . Question 3 : Let $s\ge0$ and $f\in\mathcal E_b$ . How can we infer from $^1$ $$\operatorname E\left[\int_0^\infty e^{-\lambda t}f(X_{s+t})\:{\rm d}t\mid\mathcal F_s\right]=(R_\lambda f)(X_s)\tag4\;\;\;\text{for all }\lambda\ge0$$ that $$\operatorname E\left[f(X_{s+t})\mid\mathcal F_s\right]=(\kappa_tf)(X_s)\;\;\;\text{for all }t\ge0\tag5$$ (i.e. that $(X_t)_{t\ge0}$ is a time-homogeneous $(\mathcal F_t)_{t\ge0}$ -Markov process on $(\Omega,\mathcal A,\operatorname P)$ with transition semigroup $(\kappa_t)_{t\ge0}$ )? First of all, I guess we need to assume that $$\Omega\times[0,\infty)\to E\;,\;\;\;(\omega,t)\mapsto X_t(\omega)\tag6$$ is $\mathcal A\otimes\mathcal B([0,\infty))$ -measurable in order to ensure that the left-hand side of $(4)$ is well-defined. I would like to find an elegant way to prove question 3. Note that I'm familiar with operator theory and functional analysis. I guess it's easier to argue with this knowledge. Let $A\in\mathcal F_s$ and \begin{align}\mu((a,b])&:=\operatorname E\left[\int_a^bf(X_{s+t})\:{\rm d}t;A\right];\\\nu((a,b])&:=\operatorname E\left[\int_a^b(\kappa_tf)(X_s)\:{\rm d}t;A\right]\end{align} for $0\le a<b$ . We know that $\mu$ and $\nu$ are uniquely determined by their Laplace transform $\mathcal L_\mu$ and $\mathcal L_\nu$ ; \begin{align}\mathcal L_\mu(\lambda)&=\int\mu({\rm d}t)e^{-\lambda t}=\operatorname E\left[\int_0^\infty e^{-t\lambda}f(X_{s+t})\:{\rm d}t;A\right]\\\mathcal L_\nu(\lambda)&=\int\nu({\rm d}t)e^{-\lambda t}=\operatorname E\left[\int_0^\infty e^{-t\lambda}(\kappa_tf)(X_s)\:{\rm d}t;A\right]=(R_\lambda f)(X_s)\end{align} for all $\lambda\ge0$ .By $(4)$ , $$\mathcal L_\mu=\mathcal L_\nu\tag7.$$ From this we can infer that $$\int_a^b\operatorname E\left[f(X_{s+t});A\right]\:{\rm d}t=\int_a^b\operatorname E\left[(\kappa_tf)(X_s);A\right]\:{\rm d}t\;\;\;\text{for all }0\le a<b\tag8$$ and hence $$\operatorname E\left[f(X_{s+t});A\right]=\operatorname E\left[(\kappa_tf)(X_s);A\right]\;\;\;\text{for Lebesgue-almost all }t\ge0\tag9.$$ However, I have no idea how to conclude from here (especially since the Lebesgue-null set in $(9)$ depends on $A$ ).","['measure-theory', 'stochastic-processes', 'markov-process', 'semigroup-of-operators', 'probability-theory']"
4471899,Torsion Free Spin Connection,"Ok I am not exactly sure how much of this common notation/terminology, and how much is unique to the book I'm reading, so bear with me for a moment here. First we have a vector bundle $E$ associated to the orthonormal frame bundle of some manifold $M$ . There is a soldering form, an isomorphism from $TM\rightarrow E$ , given by a collection of one forms $e^I$ (equivalently a vector valued one form): $$e^I=e^I_\mu dx^\mu$$ where $I$ is an index $I=1,\dots,n$ . This encodes a riemannian metric on $M$ via: $$g(v,u):=\langle e^I(u),e^I(v)\rangle=g_{\mu\nu}=e^I_\mu e^J_\nu \delta_{IJ}$$ A metric connection on $E$ then satisfies the following property: $$d^\omega\delta^{IJ}=\omega^I_K\delta^{KJ}+\omega^J_K\delta^{KI}=0$$ Which is really just the condition that $\omega^i_j=-\omega^j_i$ , or, equivalently, that $\omega$ is a one form with values in $\mathfrak{o}(n)$ . Torsion is then defined as: $$T^I:=d^\omega e^I=de^I+\omega^I_Je^J$$ I am pretty sure I am fine with all of this, but this next jump is a calculation that I haven't been able to follow: given the soldering form, there exists a unique metric and torsion free connection given by: $$
\omega^I_{\mu J}=e^{\rho I}e_J^{\sigma}\left(-C_{\mu\rho\sigma}+C_{\rho\sigma\mu}+C_{\sigma\mu\rho}\right)
$$ Where: $$C_{\mu\rho\sigma}=e_{\mu I}\partial_{[\rho}e^I_{\sigma]}$$ The object $e^\mu_I$ is the inverse of the soldering form defined as $e^\mu_Ie^J_\mu=\delta^J_I$ , and $e^\mu_Ie^I_\nu=\delta^\mu_\nu$ . I am a little confused as to what the objects $e^{\rho I}$ and $e_{\mu I}$ are. In principal I know what this calculation is, it's essentially the equivalent of the formula for the Christoffel symbols in the levi-civita connection, however deriving this in this gauge theory esque framework as proved troublesome. I figured I should just set $T^I$ equal to zero and use $\omega^I_J=-\omega^J_I$ at some point to get the components of the connection, but this has not worked. I first wrote everything explicitly, and examined the $i$ th component of $T^I$ : $$
T^i=d(e^i_\mu dx^\mu)+\omega^i_{\nu j}e^j_\mu dx^\nu\wedge dx^\mu
$$ Carrying out the exterior derivative of the first term we obtain: $$
T^i=\partial_\nu e^i_\mu dx^\nu\wedge dx^\mu+\omega^i_{\nu j}e^j_\mu dx^\nu\wedge dx^\mu
$$ Contracting $T^i$ with the coordinate vector fields $\partial_\mu$ and $\partial_\nu$ we obtain: $$
i_{\partial_\nu}\left(i_{\partial_\mu}T^i\right)=\partial_\nu e^i_\mu-\partial_\mu e^i_\nu+\omega^i_{\mu j}e^j_\nu-\omega^i_{\nu j}e^j_\mu
$$ Setting this equal to zero I thought I could do something to solve for $\omega^i_{\mu j}$ , but everything I think of doing doesn't pan out, which suggests to me that I'm attacking this the incorrect way. Any advice or hints would be greatly appreciated. Edit: I am now convinced I need to use the following coordinate invariant koszul formula: $$2g(\nabla_X Y,Z)=Xg(Y,Z)+Yg(Z,X)-Zg(X,Y)-g(X,[Y,Z])+g(Y,[Z,X])+g(Z,[Y,X])$$ But I am not quite sure how to translate it in this frame work. When finding the components of the levi civita connection you just let $X=\partial_i,Y=\partial_j,Z=\partial_k$ but I am not sure what I should let $X,Y,Z$ be since I don't feel like I can use the coordinate vector fields. Could I just let $e_i$ be the standard basis vectors on $\mathbb{R}^m$ and then set $X=e_\mu^ie_i, Y=e_\nu^ie_i, Z=e_\eta^ie_i$ ? Or should I should let $e^I_u$ denote a basis vector and have $\left(\nabla_{e^I_\nu} e^I_\mu\right)^j=\omega^j_{\nu I} e^I_\mu$ ?","['cartan-geometry', 'connections', 'gauge-theory', 'differential-topology', 'differential-geometry']"
4471978,What are the eigenvalues of $\begin{pmatrix} A & B \\ B &-A \end{pmatrix}$ in terms of $A$ and $B$?,"It is known that the set of eigenvalues of the following block matrix $$ C = \begin{pmatrix} A & B \\ B & A \end{pmatrix} $$ is the union of the eigenvalues of the matrices $A + B$ and $A - B$ . I am interested in the matrix of the following form $$ C = \begin{pmatrix} A & B \\ B &-A \end{pmatrix} $$ Is there a description of the eigenvalues of $C$ in terms of $A$ and $B$ ? Edit. If $AB=BA$ , then we can do the following. $$ 
C = 
\begin{pmatrix} 
A & B \\ B &-A \end{pmatrix}
\begin{pmatrix} 
v \\ u \end{pmatrix} =\lambda \begin{pmatrix} 
v \\ u \end{pmatrix}
$$ implies $$
\left\{
  \begin{array}{l}
    Av+Bu=\lambda v \\
    Bv-Au=\lambda u 
  \end{array}.
\right.
$$ By multiplying the first equation by $B$ and assuming $AB=BA$ , we get $$
(A^2+B^2)u=\lambda^2u.
$$ Therefore, $\lambda^2$ is an eigenvalue of $A^2+B^2$ , what is discussed in the comments.","['matrices', 'block-matrices', 'eigenvalues-eigenvectors']"
4471993,Show That Wigner’s Theorem Defines a Surjective Homomorphism $\operatorname{U}(2) \rightarrow \operatorname{SO}(3)$,"Preliminary Knowledge We are working on the finite dimensional Hilbert space $\mathbb{C}^2$ .  The projective Hilbert space is given by $$\mathbb{P}(\mathbb{C}^2)=\big(\mathbb{C}^2 \backslash \{0\}\big)/\mathbb{C}^*, \tag{1}$$ where the equivalence relation $\psi \sim \phi$ is satisfied when $\psi=\lambda \phi$ , for some $\lambda \in \mathbb{C}^*$ and $\psi ,\phi \in \mathbb{C}^2 \backslash \{0\}$ . An important structure is quantum mechanics is the transition probability , which is the map $p:\mathbb{P}(\mathbb{C}^2) \times \mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{R}$ defined by $$p([\psi],[\phi])=\frac{|\langle \psi , \phi \rangle |^2}{\langle \psi , \psi \rangle \langle\phi , \phi \rangle}. \tag{2}$$ Furthermore, a quantum mechanical symmetry is defined as an invertible map $f:\mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{P}(\mathbb{C}^2)$ which preserves the transition probability: $$p(f([\psi]),f([\phi]))=p([\psi],[\phi]), \quad \text{for} \space [\psi],[\phi] \in \mathbb{P}(\mathbb{C}^2).\tag{3}$$ And finally, Wigner's theorem states that for any quantum mechanical symmetry $f:\mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{P}(\mathbb{C}^2)$ there exists a unitary or anti-unitary operator on $\mathbb{C}^2$ that induces $f$ on $\mathbb{P}(\mathbb{C}^2).$ What we know Consider now the set of all one-dimensional projectors in $\mathbb{C}^2$ : $$ \mathbb{E} := \{e \in \operatorname{End}(\mathbb{C}^2) : e^2=e=e^*, 0 \ne e \ne I, \operatorname{dim} \operatorname{im} (e)=1\}, \tag{4}$$ where $I$ is the identity.  By identifying $\mathbb{E}$ with the space of all $2 \times 2$ complex matrices $\operatorname{M}_{2 \times 2}(\mathbb{C})$ with trace $1$ (while excluding the obviously trivial zero and identity matrix), it is straightforward to show that any $e \in \mathbb{E}$ can be written as $$e(\vec{x})=\frac{1}{2}I + \frac{1}{2}\sum_{i=1}^{3}x_i \sigma_i, \quad||\vec{x}||=1, \tag{5}$$ where $\sigma_i$ are the $3$ Pauli matrices.  Equation $(5)$ turns out to define an isomorphism $S^2 \longrightarrow \mathbb{E}$ , and thus $S^2 \cong \mathbb{E}$ .  One can also show that $\mathbb{E} \cong \mathbb{P}(\mathbb{C}^2)$ , and so we have $\mathbb{P}(\mathbb{C}^2) \cong S^2$ .  Then,  by using the formula $p(e,f)=\operatorname{Tr}(ef)$ for any $e,f \in \mathbb{E}$ , we can show that transition probability is given by $$p(\vec{x},\vec{y})=\frac{1}{2}(1+ \langle\vec{x},\vec{y}\rangle), \quad \text{for} \space\vec{x},\vec{y} \in S^2. \tag{6}$$ Next, consider the group of all quantum mechanical symmetries: $$G:= \{f:S^2 \longrightarrow S^2 \space | \space f \space \text{invertible and} \space p(f(\vec{x}),f(\vec{y}))=p(\vec{x},\vec{y}) \space \forall \vec{x},\vec{y} \in S^2\}, \tag{7}$$ as well as the orthogonal group $\operatorname{O}(3)$ , given by $$\operatorname{O}(3; \mathbb{R}) = \{\rho \in \operatorname{GL}(3; \mathbb{R}) \space | \space \langle \rho a, \rho b \rangle = \langle a,b \rangle \space \forall a,b \in \mathbb{R}^3 \}. \tag{8}$$ One can then show that $G \cong \operatorname{O}(3)$ , and hence identify $\operatorname{O}(3)$ with $G$ . The Problem We now restrict to $\operatorname{SO}(3) \subset \operatorname{O}(3)$ .  Show that Wigner's theorem defines a surjective homomorphism $\operatorname{U}(2) \longrightarrow \operatorname{SO}(3)$ sending $u \mapsto R$ defined by $$ue(\vec{x})u^*=e(R(\vec{x})). \tag{9}$$ My Question I do not understand the meaning of equation $(9)$ and I have no idea how to use it; I expected to be given the explicit formula of the homomorphism!  I tried inverting it by using $e^{-1}$ to isolate $R$ , but to no avail.  How then can I show that this map is a homomorphism using equation $(9)$ ? More importantly, I do not see how Wigner's theorem relates to the problem; I'm trying to find a surjective group homomorphism, how can the unitary/anti-unitary operator that induces $f:S^2 \longrightarrow S^2$ help me with that?  The theorem doesn't seem to state anything useful in particular. Any hints/answers will be well appreciated.  Thank you!","['group-homomorphism', 'group-theory', 'abstract-algebra', 'quantum-mechanics']"
4472027,Expected number of ball tosses to have at least 5 balls in 4 out of 5 bins (Skyrim application),"I have a bit of an interesting probability question that has an application to Skyrim and the number of quests you need to complete to get an achievement for the Thieves Guild. I can generalize the problem in terms of balls and bins. Say you have an infinite number of balls available, and there are 5 bins , we can label them bins 1-5 ( the bins are distinct ). When you toss a ball, it is equally likely to fall into each bin (1/5 chance). What is the expected number of tosses so bins 1-4 have at least 5 balls in them ? Each bin can hold an infinite number of balls, and we don't care about the balls falling into bin 5 (meaning it can't necessarily be the first 4 bins to have 5 balls). I know that if I only cared about 1 bin reaching 5 balls, the expected value would be 5/p where p is the probability (1/5), but I can't continue this logic once one of the bins has 5 balls since the other bins may already have balls in them (the ""misses"" from trying to fill the first bin) so I have to use some other reasoning. I wrote some code that I think simulates the rules above and I am getting around 29.7, which is lower than I would expect (the absolute minimum tosses is 20) so I would like to confirm or disprove this result as well as know how to generate a mathematical formula and calculate this without code. Link to the code: https://github.com/nodnarb22/Skyrim-Thieves-Guild-Radiant-Quest-Simulator/blob/main/thievesguild Any help or input would be much appreciated!","['expected-value', 'probability']"
4472055,Show that $M :=\{J\in M_{2n}(\mathbb{R}); J^2 = -I\}$ is a submanifold of $M_{2n}(\mathbb{R})$,"I want to show that: $$ 
M := \{J \in M_{2n}(\mathbb{R}) \mid J^2 = -I \}
$$ is the submanifold of $M_{2n}(\mathbb{R})$ , and I am given a hint to use Theorem 1. Theorem 1. Let $m,n,l \geq 0$ . Suppose that $O$ is an open set of $\mathbb{R}^{n}$ , and $O'$ is a open set of $\mathbb{R}^m$ , and the mappings $F: O \to O'$ and $G: O' \to \mathbb{R}^l$ are of the class $C^{\infty}$ . Suppose that the points $a_0 \in O$ , $\,b_0 \in O'$ , and $c_0 \in \mathbb{R}^{l}$ satisfy the following conditions:
( i ) $F(a_0) = b_0$ ,
( ii ) $GF(O) = c_0$ , and
( iii ) the sequence of linear mappings $$
\mathbb{R}^n \xrightarrow{(JF)_{a_0}} 
\mathbb{R}^m \xrightarrow{(JG)_{b_0}} \mathbb{R}^l 
$$ is exact. Then, there is a open set $W \subseteq \mathbb{R}^m$ that satisfies $b_0 \in W \subseteq O'$ , and we have $$
W \cap F(O) = W \cap G^{-1}(c_0) 
$$ and $W \cap F(O)$ will be a $C^{\infty}$ -submanifold of $\mathbb{R}^m$ . However, I don't know how to use this theorem. In my opinion, I can consider $G$ as $\det$ , and $\det^{-1} \{\pm{1}\}$ will be $M$ , but I don't know what $J(\det)$ is. Please help me!!!!!  I am Japanese, so I am not good at $\LaTeX$ and English. There may be a lot of mistakes in my context, please forgive me.","['geometric-topology', 'smooth-manifolds', 'differential-geometry']"
4472063,Failure of the Lebesgue differentiation theorem,"Following wikipedia , we know that the Lebesgue differentiation theorem holds for quite general measures on separable metric spaces as long as they are finite dimensional, more explicitly if the measure is doubling, or the metric space is a Riemannian manifold or if the metric space is locally compact and the metric is an ultrametric. What I gather is that there can exist a Banach $X$ , a positive measure $\mu$ and a measurable function $f:X\to \mathbb R$ such that $$
\mu\left\{x\in X \,\middle|\,\frac{1}{\mu(B(x,\varepsilon))}\int_{B(x,\varepsilon)}f\mu\not\to f(x)\right\}>0.
$$ I understand that one standard proof of this theorem relies on the density of continuous functions inside the integrable ones and I read somewhere that there can be continuous functions which are not locally integrable.
Sadly I managed only to find an example of a continuous curve inside a Topological Vector Space which isn't integrable, while what I expect here is a real valued continuous function which isn't integrable. Question 1) What fails in the proof of the Lebesgue differentiation theorem for a general measure in a separable metric space? Question 2) do you know of a space where the continuous functions with compact support are not dense in the integrable functions for a given measure?","['measurable-functions', 'measure-theory', 'lebesgue-integral', 'metric-spaces']"
4472079,Strong mixing of a function of strong mixing and convergence sequence,"Suppose the process $X = \left\{X_{t}:t\in Z\right\}$ is strong mixing with the coefficient $\alpha(j) \rightarrow 0$ defined as \begin{equation}
\alpha(j)=\sup_T\sup_{1\leq k\leq T-j}\sup\left\{\lvert P(A\cap B)-P(A)P(B)\rvert: B\in\mathcal{F}_{-\infty}^{k},A\in\mathcal{F}_{k+j}^{+\infty}\right\},
\end{equation} where $\mathcal{F}_{i}^{k}=\sigma\left(X_{l}:i\leq l\leq k\right)$ . Meanwhile, let $\beta = \{\beta_{t}:t\in Z\}$ be a process that is convergent to the constant $\beta_0$ in probability in the sense that for all $\epsilon>0\,,$ \begin{equation} \lim_{t\to\infty}P(|\beta_t - \beta_0|<\epsilon) = 0 \end{equation} My aim is to show that the process $Y = \{Y_t\}$ where $Y_t = f(X_t,\beta_t)$ is also a strong mixing for a Borel function $f$ . I know that if $X$ and $\beta$ are two independent strong mixing then $Y$ is also a strong mixing. But, here, $\beta$ and $X$ are not independent.","['convergence-divergence', 'probability-theory', 'probability', 'mixing']"
4472093,Are circle-tangent polynomials always either odd or even?,"By saying circle-tangent polynomial I mean a polynomial of degree $N>2$ that lies mostly inside a unit circle except for the two tails exiting the circle and going to infinity and is tangent to the unit circle at all of its $N-1$ points of intersection with that circle, as in the graphs below: As shown in the graph all such polynomials seem to be either odd or even functions. I can even show that a circle-tangent cubic must only be in the form $y=Ax^3+Cx$ as follows. My attempt to prove that circle-tangent cubics must be odd Consider $y=Ax^3+Bx^2+Cx+D,A\ne 0$ . We can find the points of intersections of the cubic and the unit circle with $$x^2+(Ax^3+Bx^2+Cx+D)^2-1=0,$$ which is a polynomial of degree 6. However, noticing that the cubic must be tangent to the circle at all intersection points, all of its distinct roots must be repeated roots. In fact, since the two tails that lead to infinity crosses the circle while being tangent at the intersections, there must be two distinct roots, each with a multiplicity of 3. Naming them $p$ and $q$ , we can rewrite the resultant sextic with $$\begin{align}x^2+(Ax^3+Bx^2+Cx+D)^2-1\equiv k(x-p)^3(x-q)^3&&(1)\end{align}$$ Replacing $x$ with $-x$ we have $$\begin{align}x^2+(-Ax^3+Bx^2-Cx+D)^2-1\equiv k(x+p)^3(x+q)^3&&(2)\end{align}$$ $(1)-(2)$ , we have $$4(Ax^3+Cx)(Bx^2+D)\equiv k\left((x-p)^3(x-q)^3-(x+p)^3(x+q)^3\right).$$ Plugging $x=p$ , we have $$\begin{align}(Ap^3+Cp)(Bp^2+D)\equiv -2kp^3(p+q)^3&&(3)\end{align}$$ and plugging $x=q$ , we have $$\begin{align}(Aq^3+Cq)(Bq^2+D)\equiv -2kq^3(p+q)^3&&(4)\end{align}$$ Assuming $p,q\ne 0$ , and we notice that on the right hand side $\frac{(3)}{p^3}\equiv \frac{(4)}{q^3}$ , so $$
\begin{align}
\frac{(Ap^3+Cp)(Bp^2+D)}{p^3}&\equiv \frac{(Aq^3+Cq)(Bq^2+D)}{q^3}\\
\left(Ap+\frac Cp\right)\left(Bp+\frac Dp\right)&\equiv \left(Aq+\frac Cq\right)\left(Bq+\frac Dq\right)\\
ABp^2+\frac{CD}{p^2}&\equiv ABq^2+\frac{CD}{q^2}
\end{align}
$$ In order to make the identity hold, the only conclusion is that $p=-q$ (since $p\neq q$ ) or $AB=CD=0$ . If $p=-q$ , then $(1)$ can be rewritten as $$x^2+(Ax^3+Bx^2+Cx+D)^2-1\equiv k(x^2-p^2)^3$$ Since the right hand side is even, so does the left hand side. This gives that the cubic must be odd. On the other hand, if $AB=CD=0$ , then obviously $B=0$ . With this, the $x^5$ term of the resultant sextic disappears, and according to Vieta's theorem $3p+3q=0$ , giving $p=-q$ , and from above we have $D=0$ as well. Generalizing the argument to higher powers Since for a degree- $N (N>2)$ circle-tangent polynomial $P_N(x)=\sum_{n=0}^N A_nx^n$ there are $N-1$ intersection points, two of which have multiplicity 3 while the remaining have multiplicity 2, we should be able to rewrite $x^2+(P_N(x))^2-1$ with the identity $$\begin{align}x^2+(P_N(x))^2-1\equiv k(x-r_1)^3\left(\prod_{n=2}^{N-2}(x-r_n)^2\right)(x-r_{N-1})^3&&(5)\end{align}$$ The argument above still works for the step replacing $x$ with $-x$ : $$\begin{align}x^2+(P_N(-x))^2-1\equiv k(x+r_1)^3\left(\prod_{n=2}^{N-2}(x+r_n)^2\right)(x+r_{N-1})^3&&(6)\end{align}$$ $(5)-(6)$ gives $$4\left(\sum_{m=0}^{\lfloor{N/2}\rfloor}A_{2m}x^{2m}\right)\left(\sum_{n=0}^{\lfloor{(N-1)/2}\rfloor}A_{2n+1}x^{2n+1}\right)\equiv k\left((x-r_1)^3\left(\prod_{n=2}^{N-2}(x-r_n)^2\right)(x-r_{N-1})^3-(x+r_1)^3\left(\prod_{n=2}^{N-2}(x+r_n)^2\right)(x+r_{N-1})^3\right)$$ which, if plugging $x=r_1,r_2,\cdots,r_{N-1}$ , loses the symmetry it has in the cubic case. And here is where I stopped. I would like to ask, if there is any method to extend my argument that such circle-tangent polynomials must be either odd or even to higher order, or if there can be any counterexamples for higher orders.","['algebraic-geometry', 'polynomials']"
4472105,"If set $C$ has 60 elements, and set $B_i$ has 9 elements randomly sampled from $C$, what is the mean value of $i$ to seeing all elements of $C$?","This question is inspired by the Yu-Gi-Oh TCG. Every so often, the game receives a new set containing either 60 or 100 new cards (this is the set $C$ in the question title). However, they don't just sell you the 60 or 100 cards upfront. No, instead you must buy booster packs , each of which contains 9 cards randomly sampled from the 60 or 100 cards of the entire set (this is the set $B_i$ in the question title). With the question's inspiration out of the way, my question is this: On average, how many booster packs are required to collect the entire 60 or 100-card set? A related question would be: What is the probability of having the entire set after opening $x$ booster packs?","['statistics', 'probability']"
4472132,"Exponential generating function of the relation $B(n,k)=B(n-1,k-1)+(n-1)B(n-2,k-1)$ —just over $n$—","Let $B(n,k)$ the number of permutations of the set $[n]=\{1,\ldots,n\}$ that are decomposable in $k$ disjoint cycles of order $1$ or $2$ . For example, $\mu=(1,3)(2,5)(4)(6,7)(8)$ is counted by $B(8,5)$ . Find the exponential generating function $A(x)$ for the sequence $B(n,k)$ $$A(x)=\sum_{n\geq k}B(n,k)\frac{x^n}{n!}.$$ Well, this is my approach. It's necessary that $n\geq k\geq0$ . For $n\geq2$ and $k\geq1$ , one can prove the identity $$B(n,k)=B(n-1,k-1)+(n-1)B(n-2,k-1).$$ We also must have $B(n,0)=B(0,n)=B(1,n)=1$ for all $n\geq0$ . Taking the derivative of $A(x)$ —to cancel the term $(n-1)$ — and using the recurrence relation we get $$
\begin{align*}
A'(x)
&=\sum_{n\geq 1}B(n,k)\frac{x^{n-1}}{(n-1)!}\\
&=1+\sum_{n\geq 0}B(n+2,k)\frac{x^{n+1}}{(n+1)!}\\
&=1+\sum_{n\geq 0}\left[B(n+1,k-1)+(n+1)B(n,k-1)\right]\frac{x^{n+1}}{(n+1)!}\\
&=1+\sum_{n\geq1}B(n,k-1)\frac{x^n}{n!}+x\sum_{n\geq0}B(n,k-1)\frac{x^n}{n!}.
\end{align*}
$$ I would like to find a functional equation, or a O.D.E to solve $A(x)$ , but I don't know how to manipulate the term $B(n,k-1)$ to get it. Any ideas? Secondly, I suspect $A(x)$ must be in terms of $k$ , am I right?
Thirdly, I found the sequence in the OEIS A122848 , and a closed formula for the coefficient is $$B(n,k)=\frac{n!}{(n-k)!(2k-n)!2^{n-k}},$$ but I'd like to avoid to prove this, preferably.
Still, any answer is welcome.","['combinatorics', 'combinatorial-proofs', 'generating-functions']"
4472208,Presentation of a subgroup of a given index,"I am unable to find an explanation of why it is possible to compute a finite presentation of a finite index subgroup in a given finitely presented group. More particularly, if $G$ is a virtually nilpotent group (given by a finite presentation), how do I find algorithmically a nilpotent subgroup $N < G$ of finite index? I know that there are the Todd-Coxeter and the Reidemeister-Schreier process. However, in the Todd-Coxeter algorithm a finite generating set of $N$ needs to be the input, and in the Reidemeister-Schreier algorithm we need a Schreier set. So my question is: Knowing that $G$ is virtually nilpotent, how do I find a finite presentation of a nilpotent subgroup $N$ of finite index? Thanks in advance!","['group-presentation', 'combinatorial-geometry', 'algorithms', 'group-theory', 'decision-problems']"
4472246,Conditional probability with an extra term,"Consider an experiment having three possible outcomes that occur with probabilities $p_1$ , $p_2$ , and $p_3$ , respectively. Suppose n independent trials of the experiment are conducted and let $X_i$ denote the number of times the $i^{th}$ outcome occurs. What is the density of $X_1 + X_2?$ Find $P(X_2 = y \space|\space X_1 + X_2 = z), y = 0, 1, 2, ... ,z$ ? I have solved the first question correctly, but there is something wrong with my solution for the second part below; I have explained my approach for the second part. My approach: $P(X_2 = y \space|\space X_1 + X_2 = z) = \frac{P(X_1 + X_2 = z \space| \space X_2 = y) \space P(X_2 = y)} {P(X_1 + X_2 = z)} = \frac{P(X_1 = z-y\space| \space X_2 = y) \space P(X_2 = y)} {P(X_1 + X_2 = z)}$ Now, RHS terms: $P(X_1 = z-y\space| \space X_2 = y) = {n-y \choose z-y} p_1^{z-y}p_3^{n-z}$ $P(X_2 = y) = {n \choose y} p_2^{y}(1-p_2)^{n-y}$ $P(X_1 + X_2 = z) = {n \choose z} (p_1+p_2)^{z}(p_3)^{n-z}$ (This term was calculated in the first part of the question and hence its verified.) Substituting these terms in the equation, we get: $P(X_2 = y \space|\space X_1 + X_2 = z) = \frac{{n-y \choose z-y} p_1^{z-y}p_3^{n-z} {n \choose y} p_2^{y}(1-p_2)^{n-y}}{{n \choose z} (p_1+p_2)^{z}(p_3)^{n-z}}$ On simplifying the RHS, we get: $RHS = {z \choose y} (\frac{p_1}{p_1+p_2})^{z-y} (\frac{p_2}{p_1+p_2})^y (1-p_2)^{n-y}$ but the answer given in the book is: ${z \choose y} (\frac{p_1}{p_1+p_2})^{z-y} (\frac{p_2}{p_1+p_2})^y $ I have an extra term $(1-p_2)^{n-y}$ in my answer; I have rechecked it multiple times, and it doesn't seem like a calculation mistake. Am I making any conceptual mistakes? PS.: The question is from Introduction to Probability Theory, Hoel Port Stone, Chapter-3 Q22 . Okay, it seems the first term of the RHS in the original equation is wrong, as I can't use $p_1$ and $p_3$ because now the sample space has reduced; changing it to the following gives the correct answer: $P(X_1 = z-y\space| \space X_2 = y) = {n-y \choose z-y} (\frac{p_1}{p_1+p_3})^{z-y} (\frac{p_3}{p_1+p_3})^{n-z}$ Right? Also, can we directly state the answer using some argument along the lines of conditional probability?","['conditional-probability', 'probability-theory', 'probability', 'random-variables']"
4472331,The Riesz-Fischer theorem Rudin,"There are the definitions which we need for the proof: Let { $\phi_n$ } be orthonormal on $X$ . Suppose $\sum |c_n|^2 $ converges, and put $s_n$ = $c_1\phi_1 + ... + c_n\phi_n $ . Then there exists a function $f$ $\in$ $\mathscr L^2(\mu)$ such that { $s_n$ } converges to $f$ in $\mathscr L^2(\mu)$ , and such that $f$ $\sim$ $\sum_{n=1}^\infty$ $c_n$$\phi_n$ . There is the proof: For $n$ $\gt$ $m$ , $||s_n - s_m||^2$ $=$ $|c_{m+1}|^2+...+|c_n|^2$ , so that { $s_n$ } is a Cauchy sequence in $\mathscr L^2(\mu)$ . By the previous theorem, there is a function $f$ $\in$ $\mathscr L^2(\mu)$ such that $\lim_{n\to \infty}$ $||f - s_n||$ $=$ $0$ . Now, for $n$ $\gt$ $k$ , $\int_{X} f $$\bar \phi_k$ $d\mu$ $-$ $c_k$ $=$ $\int_{X} f $$\bar \phi_k$ $d\mu$ $-$ $\int_{X} s_n $$\bar \phi_k$ $d\mu$ , so that $|\int_{X} f \bar \phi_k d\mu - c_k|$ $\leq$ $||f-s_n||$ $\cdot$ $||\phi_k||$ $+$ $||f-s_n||$ . Letting $n\to \infty$ , we see that $c_k$ $=$ $\int_{X} f $$\bar \phi_k$ $d\mu$ ( $k = 1,2,3,...$ ), and the proof is complete. I don't understand why is $c_k$ equal of $\int_{X} s_n $$\bar \phi_k$ $d\mu$ in this equation ( $\int_{X} f $$\bar \phi_k$ $d\mu$ $-$ $c_k$ $=$ $\int_{X} f $$\bar \phi_k$ $d\mu$ $-$ $\int_{X} s_n $$\bar \phi_k$ $d\mu$ ) and I don't understand how do we get the last inequality $|\int_{X} f \bar \phi_k d\mu - c_k|$ $\leq$ $||f-s_n||$ $\cdot$ $||\phi_k||$ $+$ $||f-s_n||$ Any help would be appreciated.","['integration', 'measure-theory', 'lebesgue-measure', 'orthonormal', 'lebesgue-integral']"
4472369,Can $f(x) + f'(x) + f''(x)$ be negative,"Here $f(x)$ is $ax^2 + bx +c$ and, $f(x) > 0$ , $a ≠ 0$ . The question that I am trying to solve is I have to see whether $g(x) = f(x) + f'(x) + f''(x)$ is :- i) $g(x) > 0 ~~\forall x\in\Bbb R$ ii) $g(x) < 0 ~~\forall x\in\Bbb R$ iii) $g(x) = 0 ~~\forall x\in\Bbb R$ iv) $g$ has real roots My initial attempt was checking for all values of $x ≥$ $\frac{-b}{2a}$ . In this range of values it can be easily seen that $g(x)$ is going to be positive and cannot be equal to 0. After this, I went over to the possibility that $x < $$\frac{-b}{2a}$ . Once again, it is trivial enough to see that only $f'(x)$ is going to be negative. However, I am unable to check whether the sum $f(x) + f'(x) + f''(x)$ is going to be negative or not. My second thought process was to observe $f(x)$ and $f'(x)$ . By putting $x = \frac{-b-2a}{2a}$ , I got the minimum value as $-$ $(\frac{b^2}{4a} + a +c)$ . If $2a$ $≥$ $(\frac{b^2}{4a} + a +c)$ , then $g(x)$ $≥$ $0$ . If $2a$ $<$ $(\frac{b^2}{4a} + a +c)$ , then $g(x)$ can be negative and positive (implying that it is $0$ for some $x$ ). After this, I have no idea how to proceed. I do not know whether this approach will work or not. Any help is much appreciated. Thanks in advance!","['calculus', 'functions', 'polynomials']"
4472440,What is the probability of rolling 6 on two cubes when we only count the higher of the two numbers,"We roll a six-sided die twice in a row and count the larger of the two different numbers. How likely is it to get a 6 this way? (This problem was translated and there isn't any additional information). I am very confused - firstly, I tried counting all of the different possibilities which would fit the criteria such as rolling: 1,6 2,6 3,6 4,6 5,6 6,1 6,2 6,3 6,4 6,5 There are 10 different possibilities where the higher of the 2 numbers would be 6, so I originally wrote the answer such as 10/36
But then I came with more possibilities and I do not know if they are correct such as: Counting an additional 11th possibility of rolling 6,6 (I don't know if it should be included due to the two numbers being the same value, so I don't know if it counts as a six, because otherwise I would assert that 6 is bigger than 6) Reducing the total number of possibilities from 36 to 21 (so that I would remove the repeating ones but I am not sure if it's correct)",['probability']
4472451,A simple special case of Gronwall's inequality for Dini derivatives,"Let $I=[t_0,t_1)\subset \Bbb R$ an interval and $a,b,c\ge0$ with $a>c$ . Assume that $f\colon I\to\Bbb R$ is a continuous function with $$\tag{1}
f(t)-f(s)\le \int_s^t\left( -af(r)+be^{-cr} \right) dr \quad \text{for all $s,t\in I$.} 
$$ If $f$ were differentiable, dividing by $(t-s)$ and letting $s\to t$ would imply $$
f'(t) \le -af(t)+be^{-ct}  \quad \text{for all $t\in I$},
$$ and hence one could apply the differential version of Gronwall's Lemma and arrive at $$\tag{2}
f(t) \le f(t_0)e^{-a(t-t_0)}+\frac{b}{a-c}e^{-at}\left(e^{(a-c)t}-e^{(a-c)t_0}\right)  \quad \text{for all $t\in I$}.
$$ Note that, contrary to the classical integral version of Gronwall's Lemma, (1) holds for all $s,t\in I$ and not just for $s=t_0$ and $t\in I$ . Hence even if $f$ is not differentiable (but continuous!), the inequality (1) still implies $$\tag{3}
Df(t) \le -af(t)+be^{-ct}  \quad \text{for all $t\in I$},
$$ where $D$ denotes any Dini derivative. However, I do not understand completely how to continue from here in order to prove that (2) holds. In the case $b=0$ , (3) implies $D^+(\log f)\le-a$ and so (2) follows immediately. I am not sure how to deal with the term $be^{-ct}$ if $b$ does not vanish, though. So, does (1) (or (3)) imply (2) also for $b\neq0$ and if yes, how can we prove it?","['dini-derivative', 'integral-inequality', 'ordinary-differential-equations', 'real-analysis']"
4472453,Estimation of $\lvert f' \rvert$ via Cauchy-integral formula,"I am asked to prove that if $f: \mathbb{C} \rightarrow \mathbb{C}$ is entire and $\lvert f(z) \rvert \leq 1$ on $\overline{B_1(0)}$ , then $\lvert f'(z) \rvert \leq 4$ on $\overline{B_\frac{1}{2}(0)}$ . What I did is to choose any $z \in \overline{B_\frac{1}{2}(0)}$ . I then easily observed that $\overline{B_\frac{1}{2}(z)} \subseteq \overline{B_1(0)}$ . Then: $$
\lvert f'(z) \rvert = \left \lvert \frac{1}{2\pi i} \oint_{\partial K_\frac{1}{2}(z)} \frac{f(w)}{(w-z)^2}~\mathrm{d}w\right \rvert \leq \frac{1}{2\pi} \oint_{\partial K_\frac{1}{2}(z)} \frac{\overbrace{\lvert f(w) \rvert}^{\leq 1}}{\underbrace{\lvert w-z\rvert^2}_{=\frac{1}{4}}}~\mathrm{d}w \leq 2
$$ So I got an even better estimate... . Do you know if I made a mistake? Thank you. I am also personally interested in what is the sharpest estimation of this kind. I know that $\lvert f' \rvert = 1$ is possible e.g. for $f(z) = z^2$ .","['integration', 'complex-analysis', 'inequality', 'cauchy-integral-formula']"
4472465,Trace distance of tensor products of operators.,"Let us focuse on the set of positive operators of trace 1 acting on some infinite dimensional Hilbert space, call it $S(H_{1})$ where $H$ is the mentioned Hilbert space. Let $S(H_{2})$ be another such space and now let $\rho \in S(H_{1})$ and $\sigma \in S(H_{2})$ . The tensor product operator $\rho\otimes\sigma \in S(H_{1})\otimes S(H_{2})$ . Now, let $U$ be some unitary map that mapping, i.e. an automorphism on $S(H_{1})\otimes S(H_{2})$ , and $\Lambda$ a completely positive map acting on $S(H_{1})\otimes S(H_{2})$ acting non trivially only on the subspace $S(H_{2})$ of $S(H_{1})\otimes S(H_{2})$ . i.e. for $\rho\otimes\sigma \in S(H_{1})\otimes S(H_{2})$ $$\Lambda(\rho\otimes\sigma) = \rho\otimes\Lambda_{2}\big(\sigma\big)$$ where $\Lambda_{2}$ is acompletly positive map. I would like to know if there are any helpful results that help in the treatment of trace distances of the following sort. I know that the trace has a nice seperability property i.e. $Tr(A\otimes B) = Tr(A)Tr(B)$ and the trace distance also shares this $\|A \otimes B \|_{1} = \|A\|_{1}\|B\|_{1}$ . I am wondering if there is anything, some separability or linearity property, that might render the following into a product of traces which are not traces of tensor product states. $$\| U\Big(\rho\otimes \sigma\Big) - \Lambda\Big( U\Big(\rho\otimes \sigma\Big)\Big)\|_{1}$$ where the trace distance is defined as follows $$ \|A-B\|_{1} = \frac{1}{2}Tr\{\sqrt{(A-B)^{\dagger}(A-B)}\}$$ Thanks in advance.","['operator-theory', 'reference-request', 'linear-algebra', 'functional-analysis', 'quantum-computation']"
4472469,Average vs. Median in a sample vs. the full population,"Let's say I take a random sample from a full population of which I know average and median. Can I estimate the average and median for the sample from the average and median of the full population (without an explicit calculation)? I am assuming the median should be close, while the averages do not need to be close at all, depending on the distribution. In other words, if I select an hypothetical random element, the value for that element should be probabilistically closer to the median of the population rather than the average.","['average', 'statistics', 'median']"
4472489,Closed form for $\lim\limits_{n\to\infty}\prod\limits_{k=1}^n{\left(2-\frac{2n^2-\pi^2+8}{n^2}\cos{\frac{(2k-1)\pi}{n}}\right)}$?,"I am looking for a closed form for: $$\lim_{n\to\infty}\prod_{k=1}^n{\left(2-\frac{2n^2-\pi^2+8}{n^2}\cos{\frac{(2k-1)\pi}{n}}\right)}$$ (Wolfram suggests that it's approximately 6.17966.) Context : I was thinking about the curve $y=2^{n-1}(x-\cos{\frac{0\pi}{n}})(x-\cos{\frac{1\pi}{n}})(x-\cos{\frac{2\pi}{n}})...(x-\cos{\frac{n\pi}{n}})$ . Here is the graph when $n=6$ , for example: It is an $n+1$ degree curve tangent to the unit circle at $n$ points, and the total area of the $n$ regions enclosed by the curve and the x -axis is always $1$ (for any $n$ ). The product , let's call it $P$ , of the areas of the regions enclosed by the curve and the x -axis, approaches $0$ as $n\to\infty$ . But then I discovered that if we magnify the curve so that the average area of the regions is always $2$ (for any $n$ ), then $P$ approaches 6.17966... as $n\to\infty$ . The limit in the question is this number. (To derive the limit expression, I used an equivalent expression for the curve: $y=-\sqrt{1-x^2}\sin{(n\arccos{x})}$ , and stretched it vertically and horizontally by scale factor $\sqrt{2n}$ so that the average area of the regions is $2$ .) This idea of the product of areas of regions in a circle approaching some positive number is inspired by this question . My attempt : I tried relating the limit to a similar limit, $\lim_{n\to\infty}\prod_{k=1}^n{\left(2-2\cos{\frac{(2k-1)\pi}{n}}\right)}=4$ , as well as taking the log of the product, but I didn't make any progress. I am not very familiar with evaluating infinite products and would like to learn more.","['circles', 'closed-form', 'polynomials', 'infinite-product', 'limits']"
4472493,Laplace-Beltrami operator of a vector field/function on an arbitrary curved surface,"Given a surface $\mathcal S$ , I want to compute the Laplace-Beltrami operator of a tangent vector field/function $\mathbf v: \mathcal S \to T\mathcal S$ . Definitions/what I know: There exists a parametrization $\mathbf {X}(x^1,x^2)$ of the surface $\mathcal S$ (with local coordinates $x^1, x^2$ ), which defines two tangent vectors to each point on the surface $\mathbf e_i = \frac{\partial \mathbf X}{\partial x^I} = \partial_i \mathbf X$ (basis vectors, orthogonal but not necessarily orthonormal). The covariant derivative of a vector $\mathbf v$ with contravariant components $v^i$ is $\nabla_i v^j = \mathbf e^j \cdot \partial_i \mathbf v = \partial_i v^j + \Gamma_{ik}^j v^k$ , where $\Gamma_{ik}^j$ are the Christoffel symbols. The gradient $\nabla_{\mathcal S}$ of a scalar function $u: \mathcal M\to \mathbb R$ is given by $\nabla_{\mathcal S} u = \mathbf e^i \partial_i u$ , and the divergence $\nabla_{\mathcal S}\cdot$ of a vector function $\mathbf v$ is given by $\nabla_{\mathcal S} \mathbf v = \nabla_i v^i$ . The Laplace-Beltrami operator is defined for a scalar function $u$ by $\Delta_{\mathcal S} u = \nabla_{\mathcal S} \cdot \nabla_{\mathcal S}u = g^{ij} \nabla_i \nabla_j u$ , where $g^{ij}$ is the inverse of the metric $g_{ij}$ . My questions: Is the Laplace-Beltrami operator of a vector function $\mathbf v$ given by $\Delta_{\mathcal S} \mathbf v = \nabla_{\mathcal S} \cdot \nabla_{\mathcal S} \mathbf v$ ? How does that look (contravariant) componentwise? Is it $[\Delta_{\mathcal S} \mathbf v]^k = g^{ij} \nabla_i \nabla_j v^k$ ? I found in a reference a different expression: $\Delta_{\mathcal S} \mathbf v = \mathbf e_i \nabla_j\nabla^j v^i - 2 \mathbf n C_j^i \nabla_i v^j - \mathbf e_k v^i C_i^j C_j^k$ , where $\mathbf n$ is the normal to the surface and $C_{ij} = -\mathbf n \cdot \partial_i\partial_j\mathbf X$ is the curvature tensor. This is obtained by ""several times applying the Gauss-Weingarten relations"": $\partial_i\mathbf e_j = -C_{ij} \mathbf n + \Gamma_{ij}^k \mathbf e_k$ and $\partial_i \mathbf n = C_i^j \mathbf e_j$ . Is this maybe the correct expression instead of the one in question 1?","['laplacian', 'tensors', 'differential-geometry']"
4472499,Why do we care about flat and projective modules?,I was reading the definitions of projective modules and flat modules and found myself a bit unenlightened (by all of their equivalent definitions). At least the Wikipedia articles for these classes of modules did not provide enough (if any) motivation for the definitions. Is there an intuition behind these definitions that could help me understand what's going on here?,"['abstract-algebra', 'modules']"
4472588,Characterizing the boundary of image of $f:\mathbb{R}^n\to\mathbb{R}^n$,"Note: The original question asked how to prove that $f$ maps interior points to interior points when it has a positive Jacobian. This was a silly question as it's an immediate consequence of the Inverse Function Theorem as pointed out in the comment. I modified the question to better reflect the true nature of the issue. Consider a differentiable map $f$ with positive definite Jacobian: $$f(x,y):\Omega = [0,\infty)\times Y\longrightarrow\mathbb{R}^{m+1}, \text{ where } Y\subseteq\mathbb{R}^{m}\,\, \text{is compact, simply connected}.$$ My question is how to accurately describe the boundary of the image of $f.$ We know that from the Inverse Function Theorem that: $$F(\partial\Omega)\subseteq\partial F(\Omega).$$ But it seems that ""new"" boundary can form, if we look at the limit: $$g(y) = \lim\limits_{x\to\infty} f(x,y).$$ This limit exists and finite for any $y\in Y$ and
for the particular problem I am working on, $g(y)$ turns out to be piecewise constant i.e.,: $$g(y) = \sum\limits_{s\in S}a_s\mathbf{1}_{\{X_s\}}(y)$$ where $Y = \cup_{s\in S}Y_s$ is a finite partition of $Y.$ So I am tempted to conclude: $$\partial F(\Omega) = F(\partial\Omega)\cup\{a_s\vert\ s\in S \}.$$ However, numerical simulation strongly suggests that the line segments (or hyperplanes) joining the points $a_s$ also lie on the boundary of image of $f.$ So at this point, I want to prove something like for two limit points $a_s,a_t$ : $$\forall\alpha\in[0,1]: \alpha a_s + (1-\alpha)a_t\in\partial F(\Omega).$$ But none of the usual theorems about diffeomorphism I find is of direct help, as they deal with open sets or they are about holomorphic functions. However, my $\Omega$ is not open and my function is real. Can someone point me to a nice reference that deals with results like this?","['real-analysis', 'jacobian', 'functional-analysis', 'manifolds', 'differential-topology']"
4472617,Phase portrait of $\ddot{x} + \sin(x)=0$ near the origin.,"I am trying to sketch the phase portrait of the second order ODE describing a pendulum near the origin: $$\ddot{x}+\sin(x)=0.$$ I write this as the first order system: $$ \begin{aligned} \dot{x} &= y \\ \dot{y} &= -\sin(x) \end{aligned} $$ The Jacobian at the origin is given by: $$ J(0,0) = \begin{pmatrix} 0 & 1\\ -1 & 0 \end{pmatrix} $$ thus giving us eigenvalues $\pm i$ and resulting in a non-hyperbolic fixed point. The system has energy $$ E = \frac{1}{2}y^{2}+1-\cos(x) $$ and so it is a gradient field. A well-known result is that gradient fields do not have cycles. However, searching online, I came across the plot: https://www.researchgate.net/figure/Potential-well-of-the-simple-pendulum-and-the-phase-portrait-in-the-absence-of-friction_fig1_258272363 I am not sure where I went wrong. Any help would be greatly appreciated.","['nonlinear-dynamics', 'ordinary-differential-equations', 'dynamical-systems']"
4472636,Does there any diffentiable function $f$ such that $f'$ is discontinuous exactly on $\Bbb{Q} $ and continuous on $\Bbb{R}\setminus \Bbb{Q}$?,"Does there exists
any diffentiable function $f$ such that $f'$ is discontinuous exactly on $\Bbb{Q} $ and continuous on $\Bbb{R}\setminus \Bbb{Q}$ ? Since $\Bbb{Q}$ is $F_{\sigma}$ , we can produce a function which is discontinuous only on $\Bbb{Q}$ . For an example we can pick Thomae's function .But Thomae's function has no primitive. Because if thomae's function $f$ has a primitive $F$ then $F'=f $ . Since $F'$ is Darboux function, image of $F'=f$ must contains an intervals and this is not possible as Thomae's function doesn't attain irrational values. By choosing a particular example, we can conclude the impossibility of existence of such function. If $f'$ is Darboux function and belongs to Baire class $1$ then $f'$ has a primitive $f$ . Hence our goal is to create a Darboux function $f'$ of Baire class $1$ which is continuous on $\Bbb{Q}$ and discontinuous on $\Bbb{R}\setminus \Bbb{Q}$ . How to produce such function?","['integration', 'analysis', 'real-analysis', 'elementary-set-theory', 'derivatives']"
4472643,Show that there is a point $x_0\in\Bbb{R}^n$ such that $Df(x_0)=0$,"Let $f : \Bbb{R}^n \to \Bbb{R}$ be a $C^1$ function such that $$\lim\limits_{\|x\|\to\infty}f(x)=0$$ Show that there is a point $x_0 \in \Bbb{R}^n$ such that $Df(x_0)=0$ . I'm struggling to finish the proof. My idea was to distinguish some case. Let for example suppose that there is $z\in \Bbb{R}^n$ such that $f(z)>0$ . Let $\epsilon>0$ . By limit hypothesis at infinity we have the existence of $c>0$ s.t $\|x\|\ge c \implies |f(x)|<f(z)$ . The idea now is to look what's going on in the set $\overline{B(0,c)}$ . As $f$ is continuous and $\overline{B(0,c)}$ is a compact set, then $f$ has it's max and min there. But, I'm struggling to show that max cannot occur on the board of my close ball. If someone could help I would appreciate it. Thank you","['scalar-fields', 'multivariable-calculus', 'derivatives', 'real-analysis']"
4472677,Are compact spaces the only spaces with locally compact continuous images?,"Let $X$ be a topological space such that for every continuous map $f: X \to Y$ , $f(X)$ is locally compact. Must $X$ be compact ? (It would therefore characterise compact spaces.) If possible, I would prefer a constructive proof/counterexample.","['general-topology', 'compactness']"
4472687,Why does $\tan\left(x\right)\tan\left(y\right)<1 \implies x + y < 90\deg$,"If $0<x<90$ and $0<y<90$ , why does $\tan\left(x\right)\tan\left(y\right)< 1 \implies x + y < 90$ ? I know that $\tan{x}\tan{y} = \frac{\sin{x}\sin{y}}{\cos{x}\cos{y}}$ , but I don't see if $\frac{\sin{x}\sin{y}}{\cos{x}\cos{y}}<1\implies x + y < 90$ is any easier to make sense of.",['trigonometry']
4472693,Estimate of the $n$-th derivative of $\frac{x}{(x+1)(x+2)-2e^{-3x}}$,"For $x > 0$ let $$
f(x) = \frac{x}{(x+1)(x+2)}.
$$ I would like to estimate the $n$ -th derivative of $f$ . To this end I use partial fractions decomposition $$
f(x) = \frac{2}{x+2} - \frac{1}{x+1}
$$ and easily obtain $$
|f^{(n)}(x)| \le C n! \frac{1}{x^{n+1}},
$$ for some constant $C > 0$ (independent of $n$ ) and all $x > 0$ . My question is: what happens if we consider $$
g(x) = \frac{x}{(x+1)(x+2) - 2e^{-3x}}?
$$ The function $g$ is not rational, hence we do not have partial fractions decomposition. However, numerical analysis suggest that it is possible to obtain similar estimate of the $n$ -th derivative of $g$ as for $f$ . Does there exist $D > 0$ such that for all non-negative integers $n$ and all $x > 0$ we have $$
|g^{(n)}(x)| \le D n! \frac{1}{x^{n+1}}?
$$ Edit. I tried the following approach: since $f$ , as a complex function defined on the right-half plane ( $0$ is a removable singularity), is holomorphic, by the Cauchy formula it follows that for every $x > 0$ we have $$
f^{(n)}(x) = \frac{n!}{2\pi i} \int_\gamma \frac{f(z)}{(z-x)^{n+1}} dz,
$$ where $\gamma$ is any closed path around $x$ . Hence, if we let $\gamma$ to be a circle with center at $x$ and radius $x$ , then $$
|f^{(n)}(x)| \le \frac{n!}{2\pi} \frac{1}{x^{n+1}} \int_\gamma |f(z)| dz.
$$ It looks promising, since $f(z)$ is bounded (say, by $M > 0$ ) for $\mathrm{Re}(z) \ge 0$ . However, the integral is taken over the circle with length $2\pi x$ , which implies $$
|f^{(n)}(x)| \le M \frac{n!}{x^n}, \qquad x > 0.
$$ This is nice, but I would like to get the estimate of the form $$
M \frac{n!}{x^{n+1}}.
$$ Is it somehow possible to refine this mathod to get $\frac{1}{x^{n+1}}$ instead of $\frac{1}{x^n}$ ?","['complex-analysis', 'calculus', 'derivatives', 'real-analysis']"
4472723,Polar decomposition for unbounded operators,"If $T$ is a closed, densely defined linear transformation on a Hilbert space $\mathcal{H}$ , then $T$ has a polar decomposition $T=V(T^{*}T)^{\frac{1}{2}}$ where $V$ is the partial isometry defined by extending the map $(T^{*}T)^{\frac{1}{2}}x\mapsto Tx$ for $x\in D(T^{*}T)$ (where $D(T^{*}T)$ is the domain of $T^{*}T$ and a core for both $T$ and $(T^{*}T)^{\frac{1}{2}}$ ). Since $V$ is bounded it follows that $T^{*}=(T^{*}T)^{\frac{1}{2}}V^{*}$ , and hence $TT^{*}=VT^{*}TV^{*}$ . What I do not understand is the following claim: $T^{*}T$ restricted to the closure of the range of $T^{*}$ is unitarily equivalent to $TT^{*}$ restricted to the closure of the range of $T$ and $V$ implements this equivalence. Specifically, I do not see how it can possibly be true that if $Tx_{n}\rightarrow y$ , then $y\in D(TT^{*})$ (or even that $y\in D(T^{*})$ ). Since $TT^{*}$ is closed, this amounts to showing that $TT^{*}Tx_{n}$ has a limit in $\mathcal{H}$ . Since it is not assumed that $y$ is in the domain of any of these operators, it doesn't seem to me that this can possibly be shown. Edit: I don't even think it's true that $Tx\in D(T^{*})$ for every $x\in D(T)$ . This goes against everything I know about unbounded operators. If this were always true, then  there would be no point in stipulating that $x\in D(T^{*}T)$ when you could just write $x\in D(T)$ .","['functional-analysis', 'operator-algebras']"
4472765,Computing the Jacobian for the change of variables from cartesian into spherical coordinates,"This is the question: My question is whether the answer is $\rho^2\sin\phi$ or if it is $-\rho^2\sin\phi$ or if it doesn't necessarily matter, and why not. I found a solution online that set up the determinant in the same way that I set up my determinant, however they got $\rho^2\sin\phi$ instead of $-\rho^2\sin\phi$ (which is what I got). This is the solution online: But I found another solution online that also set up the determinant the way that I set it up and it got $-\rho^2\sin\phi$ (which is what I got also). This  solution is: So I just want to know which is the correct answer and why. This is my solution:","['jacobian', 'multivariable-calculus', 'spherical-coordinates', 'determinant']"
4472775,Need Help With Using Cycle Permutation to Rotate Squares,"I'm a high school math teacher and I'm working with some calculus students who are exploring other areas of math for an end-of-year project. I thought I would introduce them to some basic group theory by exploring the symmetries of a square. However, I'm a little rusty, and I'm getting some results that don't make (physical) sense. This is how I'm laying out the square, and I've calculated the elements of the dihedral group as such in cycle notation ( $R$ represents a $90$ degree rotation counter-clockwise): $R=(1234)$ $RR=(13)(24)$ $RRR=(1432)$ $V=(12)(34)$ $H=(14)(23)$ $D_1=(13)$ $D_2=(24)$ I can put the Cayley table together just fine, but I run into a problem when I try and actually compose two permutations that involve either $D_1$ or $D_2$ . For example, flipping across the $D_1$ axis and then rotating counter-clockwise by $90$ degrees should be equivalent to $R$ composed with $D_1$ . And this is equivalent to $(1234)(13)=(14)(32)=H$ . However, when I do those two actions physically with an actual square, I get $V$ - that is, the square is in a position equivalent to merely flipping around the vertical axis - not $H$ . I've tried compositions with all sorts of other situations, and they all work, so it's only compositions with $D_1$ or $D_2$ involved that give results not matching their physical representation. I'm really trying to figure out what's going on here, but it just isn't clear. Can anyone point me in the right direction? Thank you so much!","['group-theory', 'geometry', 'permutation-cycles']"
4472776,"$\frac{\partial f(x,y)}{\partial x} = n \cdot \frac{\partial f(x,y)}{\partial y} \implies f(x,y) = g(nx+y)$ for some differentiable function $g$","Does $\frac{\partial f(x,y)}{\partial x} = n \cdot \frac{\partial f(x,y)}{\partial y} \implies f(x,y) = g(nx+y)$ for some differentiable function $g$ ? I found the proof here but it uses directional derivatives. Is there a more elementary way to do this? Can we do something like this: Consider some $(a,b)$ and the line $nx+y = na+b$ it belongs to. We will show that every $(x,y)$ on this line maps to the same real number. For brevity, let $na+b = c$ . Let $h(x) = U(x,c-nx)$ . Then \begin{align*}\frac{\partial U(x,y)}{\partial x} = n \cdot \frac{\partial U(x,y)}{\partial y} &\implies \frac{dh(x)}{dx} = n \cdot \frac{dh(x)}{dy} = n \cdot \frac{dh(x)}{d(c-nx)} = \frac{dh(x)}{dx} \cdot (-1)  
\\ &\implies h'(x) = 0
\end{align*} This tells us that $h$ is constant as desired. Is this proof correct?","['multivariable-calculus', 'calculus', 'solution-verification']"
4472820,"Why can we simplify $(x^2-4)/(x-2)$ to get $x+2,$ but what happens at $x=2$ when $y=(x^2-4)/(x-2)?$","When teaching algebra I have always taught that we can simplify $\dfrac{x^2-4}{x-2}$ by factorising the top line and ""cancelling"" the $(x-2)$ in the top and bottom because they are a factor of $1.$ But what about if $x=2\,?$ I have recently been sketching functions and was asked to sketch $\dfrac{f(x)}{g(x)}$ where $f(x)=x^2-4$ and $g(x)=x-2$ and the answer in the book has the line $y=x+2$ with the point where $x=2$ removed. Are these questions subtly different or is the simplification technically incorrect? Does it have an implication that $x$ is not equal to $2?$","['algebra-precalculus', 'graphing-functions']"
4472847,How do I rearrange $s=vt+v(\frac{m}{b})(e^{-(\frac{b}{m}t)}-1)$ to make $t$ the function?,"I've tried Wolfram Alpha for this, but the result contains a W([expression]), which I don't understand. Even just knowing what that means would probably be enough to get the answer I need, honestly. As a side-note, I don't really know what else to tag this question with, or even if this is the right tag, so feel free to suggest tag amendments.",['algebra-precalculus']
4472850,"Can a 4D spacecraft, with just a single rigid thruster, achieve any rotational velocity?","It seems preposterous at first glance. I just want to be sure. Even in 3D the behaviour of rotating objects can be surprising (see the Dzhanibekov effect); in 4D it could be more surprising. A 2D or 3D spacecraft (with no reaction wheels or gimbaling etc.) needs at least two thrusters to control its spin. See my answer on space.SE. For any two $4\times4$ matrices $X$ and $Y$ , define the commutator $[X,Y]=XY-YX$ , the anticommutator $\{X,Y\}=XY+YX$ , and the Frobenius inner product $\langle X,Y\rangle=\text{tr}(X^\top Y)$ , where $\text{tr}$ is the trace and $\top$ is the transpose. Let $M$ be a symmetric positive-definite $4\times4$ matrix, and $T=\mathbf f\,\mathbf r^\top-\mathbf r\,\mathbf f^\top$ an antisymmetric $4\times4$ matrix. ( $M$ describes the distribution of mass in the spacecraft, $\mathbf r$ is a vector locating the thruster relative to the centre of mass, $\mathbf f$ is the force produced by the thruster, and $T$ is the torque produced by the thruster. More details here . Everything is described in the rotating reference frame.) The angular velocity $\Omega(t)$ , an antisymmetric $4\times4$ matrix, changes with time $t$ according to Euler's equation $$\{M,\Omega'(t)\}+[\Omega(t),\{M,\Omega(t)\}]=f(t)T$$ where $f(t)\geq0$ is a function (continuous, piecewise-constant, or just integrable) describing when and how strongly the thruster is used. Question: Can $M$ and $T$ be chosen such that, for any two antisymmetric $4\times4$ matrices $\Omega_0$ and $\Omega_1$ , there exist $t_1>0$ and $f$ such that the solution $\Omega$ to Euler's equation with initial value $\Omega(0)=\Omega_0$ has final value $\Omega(t_1)=\Omega_1$ ? To simplify things, we may take $f$ to be a combination of Dirac deltas instead of an ordinary function. Then the angular velocity satisfies $\{M,\Omega'(t)\}+[\Omega(t),\{M,\Omega(t)\}]=0$ except at a finite set of times when $\{M,\Omega(t)\}$ changes by a positive multiple of $T$ . Here is Euler's equation in terms of the components $\omega_{ij}$ of the angular velocity. Assume that $M$ is diagonal, with components $m_i>0$ . $$(m_1+m_2)\,\omega_{12}'(t)+(m_2-m_1)\big(\omega_{13}(t)\,\omega_{32}(t)+\omega_{14}(t)\,\omega_{42}(t)\big)=f(t)\,\tau_{12}$$ (And permute the indices to get 6 equations like this.) If $m_1=m_2$ , then $\omega_{12}'$ has constant sign; $\omega_{12}$ is either always non-increasing, or always non-decreasing. So, if the difference between initial and final values of $\omega_{12}$ has the wrong sign compared to $\tau_{12}$ , then there is no solution. Thus, we must take $m_1\neq m_2$ , and similarly $m_i\neq m_j$ for $i\neq j$ . The Frobenius inner product of two antisymmetric matrices has every term duplicated: $\sum_{i,j}x_{ij}y_{ij}=2\sum_{i<j}x_{ij}y_{ij}$ (since $x_{ji}=-x_{ij}$ and $y_{ji}=-y_{ij}$ ). So it's natural to take half of this. The angular momentum is $L(t)=\{M,\Omega(t)\}$ . Its squared magnitude is $\tfrac12\langle L(t),L(t)\rangle$ ; the derivative of this is $\langle L(t),f(t)T\rangle$ . So the angular momentum has constant magnitude whenever $f(t)=0$ . (The angular momentum itself would be constant in an inertial reference frame, but here we're using a rotating reference frame.) The rotational energy is $\tfrac14\langle\Omega(t),L(t)\rangle$ ; the derivative of this is $\tfrac12\langle\Omega(t),f(t)T\rangle$ . So the energy is constant whenever $f(t)=0$ . All of that applies in any dimension. But in 4D there's another constant, the angular momentum bivector's exterior square, or equivalently its inner product with its Hodge dual. Here are those constants in component form. Squared magnitude of angular momentum: $$(m_1+m_2)^2\omega_{12}^2+(m_1+m_3)^2\omega_{13}^2+(m_2+m_3)^2\omega_{23}^2\\+(m_1+m_4)^2\omega_{14}^2+(m_2+m_4)^2\omega_{24}^2+(m_3+m_4)^2\omega_{34}^2$$ Doubled energy: $$(m_1+m_2)\omega_{12}^2+(m_1+m_3)\omega_{13}^2+(m_2+m_3)\omega_{23}^2\\+(m_1+m_4)\omega_{14}^2+(m_2+m_4)\omega_{24}^2+(m_3+m_4)\omega_{34}^2$$ Halved exterior square of angular momentum: $$(m_1+m_2)(m_3+m_4)\omega_{12}\omega_{34}-(m_1+m_3)(m_2+m_4)\omega_{13}\omega_{24}+(m_2+m_3)(m_1+m_4)\omega_{23}\omega_{14}$$ (Its derivative is the exterior product of angular momentum and torque: $(m_1+m_2)\omega_{12}\,f\,\tau_{34}+\cdots$ .) These three constants define two ellipsoids and another quadratic surface (with signature $+^3-^3$ ) in the 6D space of antisymmetric matrices. When $f=0$ , $\Omega$ must remain on the intersection of these three quadratic surfaces. When $f>0$ , the above expressions are just quadratic forms, not necessarily constant. It seems more convenient here to work with $L$ instead of $\Omega$ . Of course $l_{ij}=(m_i+m_j)\omega_{ij}$ . Let's write a quadratic form as $q(L)=q(L,L)$ , using the same symbol for the corresponding bilinear form. All three of the above forms have derivative $2q(L,L')=2q(L,f\,T)$ ; in other words $q(L,[\Omega,L])=0$ . If we can find some combination of those forms such that $q(L,T)\geq0$ for all relevant $L$ , then $q(L)$ would be always non-decreasing in time; there would be no solution when the initial and final values have $q(L_1)<q(L_0)$ . But I'm not sure what ""relevant"" means here; I haven't thought this through. Notice that Euler's equation has a time symmetry: Given a solution $\Omega(t)$ , we can construct another solution $\tilde\Omega(t)=-\Omega(t_1-t)$ , so that $\{M,\tilde\Omega'(t)\}+[\tilde\Omega(t),\{M,\tilde\Omega(t)\}]=f(t_1-t)\,T$ , and the initial and final values are swapped (and negated): $\tilde\Omega(0)=-\Omega_1$ and $\tilde\Omega(t_1)=-\Omega_0$ . Therefore, any angular velocity can be reached from any other, if and only if any angular velocity can be reached from $0$ . (We can reverse a path from $0$ to $-\Omega_0$ to get a path from $\Omega_0$ to $0$ , and concatenate that with a path from $0$ to $\Omega_1$ , to get a path from $\Omega_0$ to $\Omega_1$ .) Also, Euler's equation has a scale symmetry: Given a solution $\Omega(t)$ , for any $k>0$ we can construct another solution $\tilde\Omega(t)=k\,\Omega(kt)$ , so that $\{M,\tilde\Omega'(t)\}+[\tilde\Omega(t),\{M,\tilde\Omega(t)\}]=k^2f(kt)\,T$ , and the final value is $\tilde\Omega(t_1/k)=k\,\Omega(t_1)=k\,\Omega_1$ . Therefore, any angular velocity can be reached from $0$ , if and only if any angular velocity in a small neighbourhood of $0$ can be reached from $0$ . (It looks like these two symmetries are related by $k=-1$ , but we should keep a distinction between positive time and negative time.) This has the form of a quadratic differential equation, $\mathbf x'(t)=\mathbf x(t)\odot\mathbf x(t)$ where $\odot$ is some bilinear function. (Specifically, for antisymmetric matrices $X$ and $Y$ , define $X\odot Y=-\{M,\}^{-1}([X,\{M,Y\}])$ , so Euler's equation is $\Omega'=\Omega\odot\Omega$ , as long as $f=0$ . Alternatively, define $X\odot Y=-[\{M,\}^{-1}(X),Y]$ , so Euler's equation is $L'=L\odot L$ .) Fix a norm on the space, and find some constant $\lVert\odot\rVert>0$ such that $\lVert\mathbf x\odot\mathbf y\rVert\leq\lVert\odot\rVert\lVert\mathbf x\rVert\lVert\mathbf y\rVert$ for all $\mathbf x,\mathbf y$ . Given initial value $\mathbf x(0)=\mathbf a$ , the equation $\mathbf x'=\mathbf x\odot\mathbf x$ has the power series solution $$\mathbf x(t)=\sum_{n=0}^\infty t^n\frac{\sum^{n!}\mathbf a^{n+1}}{\sum^{n!}1}$$ where the coefficient of $t^n$ is the average of all possible ways of evaluating $\mathbf a^{n+1}$ using the product $\odot$ . For example, the coefficient of $t^3$ is $\tfrac16$ of $$\sum^6\mathbf a^4=((\mathbf a\mathbf a)\mathbf a)\mathbf a+(\mathbf a(\mathbf a\mathbf a))\mathbf a+2(\mathbf a\mathbf a)(\mathbf a\mathbf a)+\mathbf a((\mathbf a\mathbf a)\mathbf a)+\mathbf a(\mathbf a(\mathbf a\mathbf a))$$ $$\newcommand{\aaaa}[3]{\mathbf a\underset{#1}\odot\mathbf a\underset{#2}\odot\mathbf a\underset{#3}\odot\mathbf a} =\aaaa{1}{2}{3}+\aaaa{2}{1}{3}\begin{matrix}{}+\aaaa{1}{3}{2} \\ {}+\aaaa{2}{3}{1}\end{matrix}+\aaaa{3}{1}{2}+\aaaa{3}{2}{1}.$$ (In the $1$ -dimensional algebra, the product is associative, and the power series simplifies to $\sum_nt^na^{n+1}=a/(1-at)$ .) This converges absolutely, for small $t$ : $$\sum_{n=0}^\infty\left\lVert t^n\frac{\sum^{n!}\mathbf a^{n+1}}{\sum^{n!}1}\right\rVert\leq\sum_{n=0}^\infty|t|^n\lVert\odot\rVert^n\lVert\mathbf a\rVert^{n+1}=\frac{\lVert\mathbf a\rVert}{1-|t|\lVert\odot\rVert\lVert\mathbf a\rVert},$$ $$|t|<\frac{1}{\lVert\odot\rVert\lVert\mathbf a\rVert}.$$ And at certain times (when the thruster is used) an impulse may be applied to $\mathbf x$ , with a fixed direction $\mathbf b$ but an arbitrary magnitude $c>0$ , thus: $\mathbf x(t+)=\mathbf x(t-)+c\mathbf b$ . These impulses, and the time intervals between them, are many variables that we can control. If the number of variables is at least $6$ (or the dimension of the space $\mathbf x$ is in), then there is hope of surrounding $0$ in an open set, and thus reaching everywhere in the space (according to the previous section). $$\mathbf x(0+)=0+c_0\mathbf b$$ $$\mathbf x(t_1-)=\sum_{n=0}^\infty\frac{t_1^n}{n!}\sum^{n!}\mathbf x(0+)^{n+1}$$ $$\mathbf x(t_1+)=\mathbf x(t_1-)+c_1\mathbf b$$ $$\mathbf x(t_1+t_2-)=\sum_{n=0}^\infty\frac{t_2^n}{n!}\sum^{n!}\mathbf x(t_1+)^{n+1}$$ $$\mathbf x(t_1+t_2+)=\mathbf x(t_1+t_2-)+c_2\mathbf b$$ $$\mathbf x(t_1+t_2+t_3-)=\sum_{n=0}^\infty\frac{t_3^n}{n!}\sum^{n!}\mathbf x(t_1+t_2+)^{n+1}$$ $$c_0,t_1,c_1,t_2,c_2,t_3\geq0$$ $$\mathbf x(t_1+t_2+t_3-)\approx0\quad?$$","['physics', 'analysis', 'ordinary-differential-equations', 'dynamical-systems']"
4472879,Slicing a tesseract,"A friend of mine was recently struggling with visualising a problem involving a cube that had been sliced into 2 equal parts, diagonally in all 3 dimensions. The result leaves a cut surface which is an equilateral triangle. That got me thinking. If you cut a cube in two diagonally in all three dimensions, you get a 2D surface that's an equilateral triangle. So, if you cut a tesseract diagonally in all 4 dimensions, what is the cut ""surface""? Instinctively, I'm assuming the cut ""surface"" is actually a 3d shape, and at a guess it might be a tetrahedron, but I just don't have the maths to know how to work it out.
Would love both answers and/or educated guesses! Thanks","['geometry', '3d']"
4472906,Finding the minimum value of $(x_1-x_2)^2 +\left(\frac{9}{x_1} - \sqrt{1-x_2^2}\right)^2$ by using trigonometry,Find the minimum value of the given function by using trigonometry $$(x_1-x_2)^2 + \left(\dfrac{9}{x_1} - \sqrt{1-x_2^2}\right)^2$$ I know the distance formula method but is there any other suitable method to solve this? I’m thinking along the lines of trigonometry or AM-GM inequality.,['algebra-precalculus']
4472928,How to draw a 3D circle that is tangent to two lines?,"I have two 3D space lines on the same plane (M-R and N-R), and I have two known point on the individual line (M and N). the angle between two lines is unknown. And now I want to draw a circle that is tangent to both of the lines (on the same plane), and touch two known points. I know the center (o) is where two perpendicular of lines in M and N intersect each other. but I do not know how to calculate perpendicular line in 3D space and in specified plane. Or something like this image:","['circles', 'geometry', '3d']"
4472955,"Finding: $\int_0^\infty \frac{|\sin (ax)|^c - |\sin(bx)|^c}{x} \, dx$","Prove that for $a,b,c>0$ $$\int_0^\infty \frac{|\sin 
 (ax)|^c- |\sin(bx)|^c}{x} \, dx = \log\left(\frac{a}{b}\right) \frac{\Gamma(1+c)}{2^c\Gamma^2\left(1+\frac c2\right)}.$$","['integration', 'calculus', 'definite-integrals', 'real-analysis']"
4472972,Example of torsion-free sheaf which is not locally free,"What is a standard example of a torsion-free sheaf, say on the complex projective plane, which is not locally free?","['algebraic-geometry', 'coherent-sheaves']"
4472973,first step analysis-tossing two coins example,"I am having trouble to understand this easy solution, why does only $A,B,C,D$ could partition the sample space? How come the $\mathbb{P}(B)=\mathbb{P}(C)=\frac{33}{36}$ ? Isn't that suppose to be $\frac{4}{36}$ and $\frac{2}{36}$ ,repectively. Thank you for any help and comments.","['conditional-probability', 'statistics', 'solution-verification', 'probability']"
4473021,A man desires to throw a party for some of his friends. In how many ways can he select 8 friends from a group of 14 friends?,"A man desires to throw a party for some of his friends. In how many ways can he select $8$ friends from a group of $14$ friends if the two of his friends(say ’A’ and ’B’) will not attend the party together? This is what I've done: Lets make two groups one for A and one for B $A$ = $\{A,C,D,E,F,G,H,I,J,K,L,M,N\}$ $B$ = $\{B,C,D,E,F,G,H,I,J,K,L,M,N\}$ Since $A$ and $B$ will not attend together, there is only 13 friends to choose from: $^{13}C_8 = 1287$ ways to invite. Is this approach and answer correct?","['combinations', 'combinatorics']"
4473043,How many 5-digit numbers can be formed such that they read the same way from either of the side (that is the number should be palindrome)?,"How many 5-digit numbers can be formed such that they read the same way from either of the side (that is the number should be palindrome)? My approach: $S = \{0,1,2,3,4,5,6,7,8,9\}$ From the set all the numbers can be selected for: $position 1 = 10 $ , $position 2 = 10 $ , $position 3 = 9  $ since we are looking for a palindrome $10.10.9.1.1 = 10^2.9$ ways palindrome $5$ digit numbers can be formed. Is this approach and answer correct?",['combinatorics']
4473114,Sphere arch parameterization,"I have an engineering problem that I can't get right. I have a unit vector in point A and a unit vector in point B. I know that the two points are connected by a spherical arch. That is, they both lie on the same sphere, and the two unit vectors both point along this sphere (tangential to the sphere). I also know the arch length between the two points, but I am not given the actual positions of the points (need to set a reference). I need a parameterization in one variable f(t) of the curve between the two points. Figure: Parametrize curve along sphere from Q to P From what I figure, it should be defined by the central angle between the points ( https://en.wikipedia.org/wiki/Great-circle_distance ) and the radius R of the sphere, which I have both found. But I can't figure out how to make a parameterization f(t) = [x(t), y(t), z(t)]. EDIT: Note that I am not given the positions A and B, only the unit vector in these points which is assumed to point tangential to the sphere and the arch length between them. This is a real life problem, and the apparatus gives direction of motion at t_0 and direction of motion at t_1 and the distance travelled. It is assumed to travel in spherical motions with a large R (I can adjust for the R later). So I can naturally set the position of A to (0,0,0), but I am not given the position of B. All help is appreciated:) Kind regards,
Fredrik","['spherical-coordinates', 'geometry', 'spherical-geometry']"
4473115,How to prove $\lim_{x\to 0} \lfloor\frac{\sin(x)}{x}\rfloor \cot(x)=0$?,"How to prove $\displaystyle \lim_{x\to 0} \left \lfloor\frac{\sin(x)}{x}\right\rfloor \cot(x)=0$ ? We know that,
For $x>0$ , it holds $\sin x<x$ , so $$
0<\frac{\sin x}{x}<1 \tag{*}
$$ For $x<0$ $$
\frac{\sin x}{x}=\frac{\sin(-x)}{-x}
$$ so the inequality (*) holds for every $x\ne0$ . Hence $$\displaystyle\lim_{x\to 0} \Big \lfloor\frac{\sin(x)}{x}\Big\rfloor \cot(x)=0.$$ On the other hand, $\displaystyle\lim_{x\to 0} \cot(x)=\infty$ .","['limits', 'calculus', 'algebra-precalculus', 'analysis']"
4473137,Is the fact $f$ is a Lipschitz function implies $|\text{grad} f| \leq 1$ true for functions on Riemannian manifolds?,"This fact is immediate if $M = \mathbb R^n$ since we can write $\partial_i f = \lim \frac{f(x+te_i) - f(x)}{t}$ .
But I didn't know whether it holds for complete Riemannian manifolds. Recently, I'm reading Geometric Analysis by Peter Li. The proof of the Cheeger-Gromoll splitting theorem in his book(Theorem 4.4) is more simple than the one on Peterson's book, which avoid the application of smooth support functions, but I don't think it is rigorous enough, so I want some help. In the last few lines on Page 35, he said that ''By regularity theory, $\beta^+$ is a smooth harmonic function with $|\nabla \beta^+| \leq 1$ '', where $\beta^+$ denotes the Buseman function. Obviously, $\beta^+$ is Lipschitz, but I'm wondering how to derive the property that $|\nabla \beta^+| \leq 1$ . For your reference, the book can be found at https://www.cambridge.org/core/books/geometric-analysis/D0A2375D56122B91A0BA370530978248 After viewing the comments, it is true and can be proved as follows. We choose the normal coordinates centered at $x$ ,
then $|grad \beta(x)| = \sum_j (\partial_j \beta)^2$ .
Suppose by contradiction that $|grad \beta(x)| > 1$ ,
then there exists a small neighborhood $U$ near $x$ such that $\sum_j (\partial_i \beta)^2 > 1$ for all $y\in U$ .
Choose $y\in U$ such that the unique minimizing normal geodesic $\gamma$ with $\gamma(0) = x$ and $\gamma(1) = y$ satisfies $\dot\gamma_k(t) = \partial_k\beta(\gamma(t))$ for all $t\in [0,1]$ , $k = 1,\ldots, m$ .
Then by the Lipschitz condition, $$
  1\geq \frac{\beta(\gamma(t)) - \beta(x)}{t} = \frac1{t}\int_0^t \langle{\nabla \beta, \dot\gamma\rangle}\, ds 
  = \frac1{t}\int_0^t \sum_{k=1}^m \partial_k\beta \dot\gamma_k\, ds 
  = \frac1{t}\int_0^t \sum_k (\partial_k \beta)^2 > 1,
  $$ which is a contradiction.","['lipschitz-functions', 'differential-geometry', 'riemannian-geometry', 'real-analysis']"
4473265,Joining $\infty$ and -$\infty$ in complex contour integral.,"When solving the following integral $$\int_{-1}^1 \frac{1}{(x^4+1)\sqrt{1-x^2}} \, dx$$ using complex contour integration, I decided to take the keyhole contour, looping around the branch point at $-1$ . This however led me to the same integral up top, but with the limits between $-1$ and $\infty$ . To get around this, I decided to use the following reasoning, that I'm not quite sure is correct. Hear me out. $\int_{-1}^\infty \frac{1}{(x^4+1)\sqrt{1-x^2}} \, dx$ = - $\int_{1}^{-\infty} \frac{1}{(x^4+1)\sqrt{1-x^2}} \, dx$ = $\int_{-\infty}^{1} \frac{1}{(x^4+1)\sqrt{1-x^2}} \, dx$ by a simple swapping of signs. thus, using the idea of the Riemann sphere, I said that $\int_{-1}^\infty \frac{1}{(x^4+1)\sqrt{1-x^2}} \, dx$ + $\int_{-\infty}^{1} \frac{1}{(x^4+1)\sqrt{1-x^2}} \, dx$ = $\int_{-1}^1 \frac{1}{(x^4+1)\sqrt{1-x^2}} \, dx$ . The way I thought about this is that we can connect - $\infty$ and + $\infty$ on a Riemann sphere, so going around it amounts to the same thing as going from $-1$ to $1$ . Again, I'm not a rigorous mathematician, more of a Physicist, so I only care if this reasoning would lead me to the correct answer.","['complex-analysis', 'contour-integration', 'residue-calculus']"
4473301,Move points in plane to a line via non-overlapping paths,"If we have $k$ points in an infinite 2-dimensional real plane, is there an algorithm to ""move"" those points to some line $L$ in the plane via completely non-overlapping paths? The $k$ points are arbitrarily placed but in unique positions. Alternatively, the problem can be phrased as connecting each point $p_i$ to a line $L$ via a line segment such that none of the line segments overlap.","['computational-geometry', 'geometry', 'plane-geometry', 'algorithms']"
4473312,Flipping $n$ sticky coins until they are all heads,"Consider a collection of $n$ coins, of which $k$ initially are heads. These coins are ""sticky"" and, when flipped, remain the same with probability $p > 1/2$ , and flip over with probability $1-p < 1/2$ . Time proceeds in synchronous rounds, and in each round, we flip each coin. As a function of $k$ , $p$ , and $n$ , what is the expected number of rounds before all coins land heads? In particular, I am interested in a lower bound on the expected number of rounds before all coins land heads (especially for $k=n-1$ ). For a constant $p$ , the expected number of rounds before all coins land heads is lower-bounded by an exponential function, but for $p \approx 1 - \frac{1}{poly(n)}$ , the answer is less clear. It's also possible to frame this question as a Markov chain (which can also be thought of as a Kronecker product of $n$ smaller two-state Markov chains). In this formulation, it is easy to write a formula for the expected number of rounds before all coins land heads, but I'm interested in a clean asymptotic expression in $k$ , $n$ , and $p$ . Edit: In the Markov chain formulation, the transition matrix is a $2^n$ by $2^n$ matrix $P$ where the $(i,j)^{th}$ entry is the probability of transitioning from state $i$ to $j$ . We can assume that the all-heads state is an absorbing state and therefore write $P$ as \begin{pmatrix} Q&R \\ \mathbf{0} &1\end{pmatrix} where $Q$ is a $2^n - 1$ by $2^n - 1$ matrix, $R$ is a $2^n - 1$ by $1$ matrix, and $\mathbf{0}$ is a $1$ by $2^n - 1$ matrix of all zeroes. Now, letting $N = (I - Q)^{-1}$ (or equivalently $N = \sum_{k=1}^\infty Q^k$ ) be the fundamental matrix, we can see that the expected number of steps until absorption from a state $i$ is the $i^{th}$ entry of $N \mathbf{1}$ . (Wikipedia article here .)
However, this expression still seems nontrivial to analyze with respect to asymptotic bounds.","['statistics', 'markov-chains', 'asymptotics', 'probability-theory', 'probability']"
4473351,Number of lines on a singular cubic surface,"A smooth cubic surface contains 27 lines, but a singular cubic surface with rational double points contains fewer lines. Question: Why is the number of lines equal to $\binom{8-r}{2}+n-1$ , where $r$ is the total number of points in the Dynkin diagrams of the singularities, and $n$ the number of singularities? Is there a similar formula for other del Pezzo surfaces ? Example. Consider the case $A_{1}A_{4}$ . The total number of points is $5$ and there are $2$ singularities, so the number of lines equals $\binom{8-5}{2}+2-1=4$ .","['algebraic-geometry', 'projective-geometry', 'singularity-theory']"
4473354,Number of draws before you see all candies?,"Recently, I thought of the following question: Suppose there are 5 candies in a bag - you choose two candies, and then put these two candies back in the bag (assume each candy has an equal probability of being selected). On average, how many times do you need to choose candies before you are guaranteed to have seen every candy at least once? In a way, this problem kind of reminds me of the ""Coupon Collector Problem"" ( https://en.wikipedia.org/wiki/Coupon_collector%27s_problem ), but I am not sure how to solve this problem using the Coupon Collector framework. I thought of framing this problem as a Markov Chain: State 2 : You have observed 2 unique candies State 3: You have observed 3 unique candies State 4: You have observed 4 unique candies State 5: You have observed 5 unique candies (Absorbing State) It took me a long time, but I think I was able to create a Transition Matrix for this problem : A = matrix(
   c(0.1, 0.6, 0.3, 0, 0,0.3, 0.6, 0.1, 0,0, 0.6, 0.4, 0,0,0, 1), # the data elements
   nrow=4,              # number of rows
   ncol=4,              # number of columns
  byrow = TRUE) 



     [,1] [,2] [,3] [,4]
[1,]  0.1  0.6  0.3  0.0
[2,]  0.0  0.3  0.6  0.1
[3,]  0.0  0.0  0.6  0.4
[4,]  0.0  0.0  0.0  1.0 From here, I suppose I could use the Theory of Markov Chains and find out the expected number of transitions until you reach the Absorbing State - but it was quite difficult to correctly calculate the transition probabilities. I imagine that once the number of states (i.e. ""candies"") increase, it will become very difficult to calculate all these transition probabilities. I was hoping for an easier way which would directly allow you to calculate the expected number of draws needed to observe ""M"" candies (at least once) with ""N"" draws and each draw of size ""K"" (e.g. M = 5, K = 2, N = ?) - provided you are given the probability of selecting any given candy (e.g. suppose the candies did not have equal probabilities of being selected). Can someone please suggest another way of solving this problem? Thanks! ""Food"" for Thought: Suppose there were ""M"" candies"" and you draw ""K"" candies ""N"" number of times. Suppose this time, you don't know the true value of ""M"" and you only have information on ""K"" and ""N"" - is there a way to estimate ""M"" based on the data you collect from ""K"" and ""N""?","['statistics', 'markov-chains', 'coupon-collector', 'probability']"
4473363,$\sqrt[3]{10-x}+\sqrt[3]{30-x}=\sqrt[3]{15-x}+\sqrt[3]{25-x}$,I just happened to find a problem and an elegant solution. The question asks us to solve the following equation $$\sqrt[3]{10-x}+\sqrt[3]{30-x}=\sqrt[3]{15-x}+\sqrt[3]{25-x}$$ I am answering this question below but I would love if you can also share a different solution. P.S: I composed this problem by myself. I do not know if this problem is available anywhere. I would love to get some feedback about the same. It motivates me to create problems and discuss with others.,"['functions', 'elementary-functions', 'systems-of-equations', 'abstract-algebra']"
4473373,"Help understanding how change of order of integration results in $\int_x^{1} \int_0^{t} f(s)ds dt = \int_{0}^{1} (1- \max(x,t)) f(t) dt$","In this question, it mentions that after changing the order of integration, we obtain: $$\int_x^{1} \int_0^{t} f(s)ds dt = \int_{0}^{1} (1- \max(x,t)) f(t) dt$$ (assume $f\in C[0,1]$ and $x \in [0,1]$ ). I am trying to understand why. EDIT Thanks to dan_fulea and Brian Moehring I identified my mistake and the solution. Below is the correct form: $$\int_x^{1} \int_0^{t} f(s)ds dt = \int_0^{1} \int_{\max\{x,s\}}^{1} f(s)dt ds = \int_0^{1} f(s)\int_{\max\{x,s\}}^{1} dt ds=\int_0^{1} f(s)\big(1-\max\{x,s\}\big) ds$$","['integration', 'multivariable-calculus', 'calculus']"
4473378,approximating probability mass function from a large data,"I am learning elementary probability; especially I am interested in learning how to find probability mass functions and density functions from data. I think I perfectly understand the theory: For example, let's take $X$ as a random variable which takes values $1$ to $10$ with frequencies $4,4,5,5,6,10,3,3,4,6$ . I know how to calculate the relative frequency from this information, i.e. here $n=50$ data size. Now the approximate will be to perform this experiment sufficient amount of time, and then the relative frequencies converge to probabilities, and we have the distribution approximately. Now, let's say I have data for, let's say, the last five years, 2021 to 2016, where each day I have seen a number between $0$ to $50$ . Trials are independent. Based on this data, can I calculate $P[X=49]$ in $2022$ on a specific day? Thank you very much for helping me find out the PMF of such data.","['statistics', 'probability-distributions']"
4473404,Can it be derived from Hilbert's axioms that every plane contains a set of non-collinear points?,"Can the following claim be derived from Hilbert's axioms as they are described in Wikipedia ? Every plane contains a set of non-collinear points. If the answer to the previous question is ""no"", can the following claim be derived from Hilbert's axioms? In every plane that contains at least two distinct points $P$ and $Q$ there is a point non-collinear with $P$ and $Q$ . I posted a virtually identical question yesterday, but after a user pointed out in the comments that in Townsend's translation of Hilbert's axioms there is an axiom essentially stating the first claim, I concluded that the Wikipedia page was faulty, and deleted my question. However after some research I've come to realize that Hilbert's axioms underwent refinements over the years, even after his death, and specifically Townsend's translation, from 1950, does not reflect the latest stage in this process of refinement. The 13th edition of the German publication of Hilbert's axioms, from 1987 (this is the latest version I've been able to lay my eyes on), has no axiom that states that every plane contains a set of non-collinear points. I believe the Wikipedia version of Hilbert's axioms reflects the latest ""official"" version of Hilbert's axioms, and, at any rate, it is with respect to this version that I request that my question be interpreted.","['axiomatic-geometry', 'geometry']"
4473425,$D^{n}$ with all but one edge identified with a point is homeomorphic to $D^{n}$.,"Let us denote $D=[0,1]^{n}$ and let $A=\bigg\{(x_{1},...,x_{n})\in D^{n}\,,\exists i\,,s.t\,,1<i\leq n\, ,x_{i}\in\{0,1\}\bigg\}\cup\bigg\{\{1\}\times[0,1]^{n-1}\bigg\}$ . Then I want to prove that $D/\sim$ with $A$ identified to a point is homeomorphic to $D$ . I am having trouble as to produce an explicit homeomorphism(or even a continuous surjection from $D^{n}$ to itself which identifies $A$ with a point and makes $\{0\}\times[0,1]^{n-1}$ the boundary of $D^{n}$ . In terms of CW complexes , I can say that the space consists of a single $0$ -cell with the $n-1$ -cell $D^{n-1}$ attached to it by the constant map(So that it is homeomorphic to $S^{n-1}$ ) . And then we attach the $n$ -cell $D^{n}$ with the boundary $S^{n-1}$ being attached to $S^{n-1}$ of the $n-1$ skeleton by the identity map. So it is homeomorphic to $D^{n}\cong D$ . I tried to do it for the $n=2$ case by mapping $\{0\}\times[0,1]$ to the boundary of $S^{1}$ by $(0,x)\mapsto e^{2i\pi x}$ and $\bigg\{\{1\}\times[0,1]\bigg\}\cup\bigg\{[0,1]\times\{0\}\bigg\}\cup\bigg\{[0,1]\times\{1\}\bigg\}$ to the point $(1,0)$ . Now this map $p:\partial(D)\to D^{2}$ is such that $p_{*}$ is the trivial homomorphism so it extends continuously to a map $p:D\to D^{2}$ but how do I tell if it is surjective or anything else? I have also considered by transforming the square to a hemisphere with boundary(lower) such that the boundary represents . (in the case of D^{2}, I want $[-1,1]$ represent the lower boundary which we will identify with the three edges of the square) . After that I want to draw lines from a point say $p=(0,0,...,0,-2)$ to the (upper) boundary and extend this line to meet $p$ and then use the universal property of the quotient to identify the lower boundary with the point $(0,0,...,0-2)$ to get a bijection which will be a homeomorphism because our space is compact , hausdorff and so is the target. Here is a picture which will perhaps explain a bit more on what I was trying to do:- But as I said, even in this case the explicit map is very complicated and does not allow us to readily view continuity or bijectivity. It's all in terms of lines which depend on the end point. I want to see an explicit map which would help me in constructing these in the future. Most books do not provide explicit maps and say in words however for an initial course in topology and algebraic topology, these things help us to see what's happening more explicitly. Why I need this: I am trying to show that for $n\geq 2$ every cts $f:S^{n}\to X$ extends to a cts map $F:D^{n+1}\to X$ iff $\Pi_{n}(X,x_{0})$ is trivial. Where $X$ is a path connected space. To prove the converse I will need the above result.","['general-topology', 'algebraic-topology', 'quotient-spaces']"
4473429,Are solutions of $\Delta f \leq -a^2 f$ constant on a compact manifold?,"Let $(M^n,g)$ be a closed (compact, without boundary) smooth Riemannian manifold and let $\Delta = -\operatorname{div} \operatorname{grad}$ be the induced Laplacian on $M$ (so that the eigenvalue problem is written in the form $\Delta u = \lambda u$ ). My question is simple: let $a \in \mathbb{R}$ , $a \neq 0$ , and suppose that $f \in C^2(M)$ satisfies the inequality $$\Delta f(x) \leq -a^2 f(x) \quad x \in M.$$ Question : Does it follow that $f$ is constant? Does it depend on $a$ ? What I have done so far : Let $x_0$ be a point of maximum of $f$ . It must hold that $\Delta f(x_0) \geq 0$ . So, $$ 0 \leq \Delta f(x_0) \leq -a^2 f(x_0) \implies f(x_0) \leq 0.$$ Thus, $f(x) \leq 0$ for every $x \in M$ . Another thing to notice: no eigenfunction of $\Delta$ satisfies the inequality, unless it is a nonpositive constant.","['eigenfunctions', 'riemannian-geometry', 'laplacian', 'partial-differential-equations', 'differential-geometry']"
4473467,"Is there an explicit example of a complete norm on $C[0,1]$ that is not equivalent to $\|\cdot\|_\infty$?","Does anyone have an constructive, explicit example for a norm $||.||$ on $C[0,1]$ , such that $(C[0,1], ||\cdot||)$ is a Banach space, but such that $||\cdot||$ is not equivalent to $||\cdot||_{\infty}$ ? I know that if convergence in $||\cdot||$ implies pointwise convergence then it is equivalent to $||\cdot||_{\infty}$ (see https://math.stackexchange.com/q/4471871 ). There is also this result Finding norm on $C[0,1]$ , which is not equivalent to the supremum norm, but which still makes $C[0,1]$ into a separable Banach space , but it uses some isomorphism which is based on the existence of a Hamel basis, which one cannot explicit construct.","['axiom-of-choice', 'banach-spaces', 'functional-analysis', 'metric-spaces']"
4473479,Find a conservative vector field that has the indicated potential,"Find a conservative vector field that has the indicated potential $$f(x,y,z)=\sin \left (x^2+y^2+z^2\right ).$$ My answer: $$2x\cos \left (x^2+y^2+z^2\right )i+2y\cos \left (x^2+y^2+z^2\right )j+2z\cos \left (x^2+y^2+z^2\right )k.$$ For this question, do I need to derivate $x$ for $i$ , $y$ for $j$ , $z$ for $k$ ?","['multivariable-calculus', 'calculus', 'vector-fields']"
4473482,Find values of the parameter for the given conic,"Given $\mathbb{R}^2$ an affine space and the conics: $Q_\alpha:3x_1^2-\alpha x_1x_2+3x_2^2+14x_1-2x_2+3=0$ $C_\beta:x_1^2+2x_2^2+2\beta x_1x_2-6x_1+5=0$ $i)$ Find $\alpha$ and $\beta$ such that $Q_\alpha$ is a hyperbola and  the line $(r):x_2=x_1-1$ is tangent to $C_\beta$ $ii)$ For the value found for $\beta$ at $i)$ find the canonical form of $C_\beta$ (i.e., classify the conic) using isometries My Attempt: I would like to know whether my approach is right and if otherwise, how to correct it. $i)$ For the first parameter : $\alpha$ In order to find $\alpha$ i thought it would be useful to require that $\Delta≠0$ and $\delta<0$ Where if $Q_\alpha:x^\top A x+Bx+c=0, \delta=det(A)$ and $\Delta=det(A_1)$ where $\begin{align*}A_1= \begin{bmatrix}
                A & \frac{1}{2}B^\top \\
                \frac{1}{2}B & c\\
                \end{bmatrix}
\end{align*}, $ but it does not help me too much as I have already seen . For the other parameter : $\beta$ I would just plug in the value of $x_2=x_1-1$ in the equation of $C_\beta$ and require the discriminant to be zero but this method does not always  work  as I have been told(I think that in dimension 3 things do not work this way? Given that we are working with the asymptote cone). How should I proceed in this situation? $ii)$ In order to classify the conic using isometries I would try to find the rotation R(an orthogonal matrix with $det(R)=1$ ) of $\mathbb{R}^2$ making the change of coordinates $x=Rx'$ for x $\in\mathbb{R}^2$ in the equation of $C_\beta:x^\top A' x+B'x+c'=0$ using eigenvectors and eventually Completing the Squares if needed. Another Question: How could this kind of problems be tackled in a simple way? I mean finding the parameter from the equation of a quadric surface knowing its nature(i.e. an ellipse, or a hyperboloid of one sheet for quadric surfaces) I have seen similar problems here but their solution seems too complicated, having to know some previous classifications and so on.","['geometry', 'quadratic-forms']"
4473516,A functional calculus question,"Let $f(x)$ be a continuous function in the real number set, such that $$f(x)=\begin{cases} \pi, \,\, \text{if} \,\, x> 1\\  g(x), \,\,\text{if}\,\,x≤ 1\end{cases}$$ Which of these statements are always correct? 1. $$\lim_{x\to 1} g(x)=\pi$$ 2. $$g(1)=\pi$$ 3. $$\lim_{x\to 1^-}\frac{f(x)}{g(x)}=1$$ My attempts. Maybe I can not see the right connection about the continuity between $f(x)$ and $g(x)$ . That is my first problem. We have $$f(1)=\lim_{x\to 1^+} f(x)=\pi=\lim_{x\to\ 1^-}f(x)=g(1)\implies \pi=g(1)
$$ I think this doesn't imply, $\lim_{x\to 1} g(x)=\pi$ . I want to say that about $3$ , that is not always correct. Because, it can be $$\lim_{x\to 1^-}g(x)=0$$ But, $$g(1)=\pi$$ So, my answer is $2$ . It is possible that, I am completely wrong. I am not sure, what is going on here, exactly.","['limits', 'calculus', 'continuity', 'real-analysis']"
4473539,History of special quadratic reciprocity $(-3/p)_2$ and $(5/p)_2$,"https://hsm.stackexchange.com/questions/14533/special-quadratic-reciprocity-3-p-2-and-5-p-2-in-addition-to-1-p-2 asks about the history of special cases of quadratic reciprocity that are understandable for ""geometric"" reasons. I'm curious whether Euler or Lagrange knew these cases before Gauss. I'd imagine that Franz Lemmermeyer @franzlemmermeyer knows this very well, but I only belatedly realized that he is not attending the history of science and math stack exchange...","['number-theory', 'quadratic-reciprocity']"
4473543,Why does $Ax+By+C+\lambda(A'x+B'y+C')=0$ represent the set of lines that pass through the intersection of $Ax+By+C=0$ and $A'x+B'y+C'=0$,"For example, given $\color{green}{l_1:5x-2y-8=0}$ and $\color{blue}{l_2:3x+8y-8=0}$ , We can compute the set of lines that pass through the intersection of $l_1$ and $l_2$ $$5x-2y-8+\lambda(3x+8y-8)=0$$ $$(5+3\lambda)x+(-2+8\lambda)y+(-8-8\lambda)=0$$ for any $\lambda\in\Bbb{R}$ $$\lambda$$ $$(5+3\lambda)x+(-2+8\lambda)y+(-8-8\lambda)=0$$ $$-1$$ $$x-5y=0$$ $$1$$ $$4x+3y-8=0$$ $$2$$ $$11x+14y-24=0$$ Why does this method work? The closest thread I could find is, A general circle through the intersection points of line $l$ and circle $S_1$ has the form $S_1+\lambda L$ . What is the significance of $\lambda$ ? . For example if we want to find lines through the point of intersection of 3x+4y+5=0 and 2x+y+4=0 . The required lines would be obtained by substituting different values of λ in 3x+4y+5+λ(2x+y+4)=0 The accepted answer is, Let us take up the case of lines first.
Let $L_1(x,y)$ and $L_2(x,y)$ be two lines which intersect at $(a,b)\\$ .
Thus $$L_1(a,b)=0\\L_2(a,b)=0$$ Now let $L_3(x,y)$ be another line such that $$L_3(x,y)=L_1(x,y)+\lambda L_2(x,y)$$ Now, if we are able to show that $L_3$ passes through $(a,b)$ ,i.e. the intersection point of $L_1$ and $L_2$ , our job will be complete.To do this we put $(a,b)$ in our expression for $L_3$ $$L_3(a,b)=L_1(a,b)+\lambda L_2(a,b)$$ $$\Rightarrow L_3(x,y)=0+\lambda .0$$ $$\Rightarrow L_3(x,y)=0$$ So as you can see, for any value of $\lambda$ , our line $L_3$ always passes through the intersection of lines $L_1$ and $L_2\\$ .
You can the same with any two curves(e.g. two circles) . What I understood from this answer is, Consider the lines $L_1(x, y)$ and $L_2(x, y)$ which intersept at $(a, b)$ such that $L_1(a, b)=0$ and $L_2(a, b)=0$ Assume that $L_3(x,y)=L_1(x,y)+\lambda L_2(x,y)$ Then this means that $L_3$ passes through $(a, b)$ I do not understand how this proves that $L_3(x,y)=L_1(x,y)+\lambda L_2(x,y)$ spans a set of distinct lines that pass through $(a, b)$ . In the case of circles of the form $x^2+y^2+Dx+Ey+F=0$ and $x^2+y^2+D'x+E'y+F'=0$ that intersect and are not concentric, we can't have $\lambda=-1$ because we would get their radical axis, not another circle. I'm looking for a proof by deduction if possible (as opposed to assumption).","['analytic-geometry', 'algebra-precalculus', 'linear-algebra']"
4473549,Proving a closed form of an integral [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Is there any proof for this integral? $$\int \limits _0^1\frac{1}{a^2x^2+1}\left [\left (1-\frac{x}{2}\ln \frac{1+x}{1-x}\right )^2+\frac{\pi^2x^2}{4}\right ]^{-1}\,dx=\frac{\arctan a}{a-\arctan a}-\frac{3}{a^2},\quad \operatorname{Re}(a)>0.$$ I tried substituting $x=\frac{1-x}{1+x}$ but the integral seems to be harder.","['integration', 'calculus', 'definite-integrals', 'closed-form']"
4473552,Solving the differential equation $y' = x - y^2$,"I know this differential equation is ""unsolvable"", this is my attempt at trying to solve it. I will start by finding a formula for a general DE of the form $ y' = f(x, y) $ , where $ f(x,y) $ can be written as $ g(x)+h(y) $ Take the differential of both sides $ d(y') = d(f(x, y)) $ $ y''(x)dx = \cfrac{\partial f}{\partial x}dx + \cfrac{\partial f}{\partial y}dy $ Divide both sides by $ dx $ $ y'' = \cfrac{\partial f}{\partial x} + \cfrac{\partial f}{\partial y}\cfrac{dy}{dx} $ $ y'' - \cfrac{\partial f}{\partial y}y' = \cfrac{\partial f}{\partial x} $ Using the definition of $ f $ we have $ \cfrac{\partial f}{\partial y} = \cfrac{\partial}{\partial y}(h(y)) = \cfrac{dh}{dy} $ and $ \cfrac{\partial f}{\partial x} = \cfrac{\partial}{\partial x}(g(x)) = \cfrac{dg}{dx} $ $ y'' - \cfrac{dh}{dy}\cfrac{dy}{dx} = \cfrac{dg}{dx} $ $ y'' - \cfrac{dh}{dx} = \cfrac{dg}{dx} $ $  y'' = \cfrac{dg}{dx} + \cfrac{dh}{dx} $ Integrate both sides $ \displaystyle \int y''dx = \int \cfrac{dg}{dx}dx + \int \cfrac{dh}{dx}dx $ $ y' = g(x)+h(x) + c_1 $ $ \displaystyle \int y'dx = \int (g(x)+h(x)+c_1)dx $ $ \displaystyle y(x)= \int (g(x)+h(x))dx + c_1x + c_2 $ Now we can use this formula to solve $ y'= x - y^2 \implies g(x) = x $ and $ h(y)=y^2 $ $ \displaystyle y(x) = \int (x - x^2)dx + c_1x+c_2  = \cfrac{x^2}{2} - \cfrac{x^3}{3} + c_1x + c_2 $ Apply the initial conditions $ y(0) = 1 \implies (c_2 = 1) \wedge (y'(0) = 0 - y(0)^2 = -1) $ $ y'(0) = -1 \implies c_1 = -1 $ $ y(x) = \cfrac{x^2}{2} - \cfrac{x^3}{3} -x + 1 $ This function satisfies the initial conditions but doesn't solve the DE and I can't see where I went wrong. Which step above was invalid? I'm thinking it has something to do with $ \cfrac{\partial f}{\partial y} = \cfrac{\partial}{\partial y}(h(y)) = \cfrac{dh}{dy} $ and $ \cfrac{\partial f}{\partial x} = \cfrac{\partial}{\partial x}(g(x)) = \cfrac{dg}{dx} $ but I'm pretty sure that is valid.","['integration', 'calculus', 'derivatives', 'ordinary-differential-equations']"
4473560,Let $a$ and $b$ be roots of $x^2-7x+2$. Find the value of $a^6 + b^6$.,"Let $a$ and $b$ be roots of $x^2-7x+2$ . Find the value of $a^6 + b^6$ . Answer: $a+b = 7, ab = 2$ $$\begin{align}
(a+b)^6 &= a^6 + 6a^5b+15a^4b^2+20a^3b^3+15a^2b^4+6ab^5+b^6 \\[4pt]
a^6 + b^6 &= (a+b)^6 -  (6a^5b+15a^4b^2+20a^3b^3+15a^2b^4+6ab^5) \\
&= (a+b)^6 - (6ab(a^4 + b^4) + 15a^2b^2 (a^2 + b^2) + 20(ab)^3)
\end{align}$$ now, $$\begin{align}
a^4 + b^4 &= (a+b)^4 - (4a^3b + 6a^2b^2 + 4ab^3) \\
&= (a+b)^4 - (4ab(a^2 + b^2) + 6(ab)^2) \\
&= (a+b)^4 - (4ab((a + b)^2 - 2ab) + 6(ab)^2) \\
&= 7^4 - (4(2)(7^2 - 2(2)) + 6(2)^2) \\
&= 2017
\end{align}$$ so $$\begin{align} 
&\phantom{=}\; (a+b)^6 - (6ab(a^4 + b^4) + 15a^2b^2 (a^2 + b^2) + 20(ab)^3)\\
&= 7^6 - (6\cdot2\cdot(2017) + 15(2)^2 (7^2 - 2(2)) + 20(2)^3) \\
&= 90585
\end{align}$$ correct?","['algebra-precalculus', 'solution-verification', 'quadratics']"
4473603,Critically damped system,"Coming from engineering background, my math might not be as rigour here. Please enlighten me. By definition, critically damped 2nd order system ( $\zeta=1$ ) does not have overshoot. Is the statement above (my assumption) false? For context, this is the system: $$
Q\ddot{x}+2\zeta \omega_n\dot{x}+\omega_n^2x=\omega_n^2r
$$ which is also in the form: $$
Q\ddot{x}+a\dot{x}+bx=br
$$ where $r$ is some constant. I know that the response is in the form: $$
x(t)=r\left[1−(k_1+k_2t)e^{\frac{−\omega_n}{Q}t}\right]
$$ Where $k_1$ , $k_2$ is some constant depend on initial condition. For $x(0) = 0$ , We know that $k_1=0$ , but how to determine $k_2$ (which depends on $x'(0)$ )? I know that this might be very trivial for some of you, but I'm really confused. For context, I asked a similar question in the electrical engineering site . If you are interested, the problem is the 2nd order system that I set ""gains"" for (gains correspond to changing the coefficient in the ode (a & b)), behave critically damped. However, when I set up a the original first order system with the input of the controlled gains, it had an overshoot. If you know why kindly please enlighten me as well.
This is the unstable first order system trying to be controlled: $$
p\dot{x}-lx=r
$$ Letting $$
r= K_p\left(c-x\right) + K_i\int _0^tc-x\ dt\ + K_d\left(\dot{c} - \dot{x}\right)
$$ This is a PID control for 1st order system. Making the sytem to become 2nd order. and track the value $c$","['control-theory', 'ordinary-differential-equations']"
4473610,Problem about algebraic structure of $\cos\frac{2kπ}{23}$,"Motivation I calculated the radical expression of $\cos\dfrac{2kπ}{23}$ , but I encountered some problems when extending to $\cos\dfrac{2kπ}{47}$ . One step in my calculation process is too computationally intensive. I hope to find some mathematical methods to reduce the computational complexity. My Steps Consider $$
\sum_{k=1}^{11}\left(22\cos\frac{2 k π i}{23}+1\right)=0
$$ Equivalent to solving the equation: $$
\begin{aligned}
\frac{x^{11}}{23}
&=55 x^9+33 x^8-25146 x^7-25564 x^6+4986058 x^5+5978445 x^4\\&-398587728 x^3-426851414 x^2+8767235268 x+4452145237
\end{aligned}
$$ Its 11 roots $x_i$ can be obtained by combining the 10 roots $r_i$ of the resolvent. $$
\begin{aligned}
x^{10}+23^{55}&
=2300783⋅23x^9
+2300783⋅23^{45}x\\&
-89208309334⋅23^3x^8
-89208309334⋅23^{36}x^2\\&
+200684695229998⋅23^6x^7
+200684695229998⋅23^{28}x^3\\&
-8686635837127304⋅23^{10}x^6
-8686635837127304⋅23^{21}x^4\\&
-60954221740648059⋅23^{15}x^5\\&
\end{aligned}
$$ Let $$
\begin{aligned}
ω&= e^{2πi/11}\\
ω^n&=ω^{n\bmod 11}
\end{aligned}
$$ Due to the properties of cyclic groups, the roots of the presolution can be written as $R = M_{\text{inner}}⋅Z$ where $z_i\in\mathbb{Q}$ and $m_{i,j} = ω^{i j \bmod 11}$ After numerical guessing and symbolic check, we can get: $$
\begin{bmatrix}
r_1\\r_2\\r_3\\r_4\\
r_5\\r_6\\r_7\\r_8\\
r_9\\r_{10}\\
\end{bmatrix}=
23\begin{bmatrix}
1 & ω & ω^2 & ω^3 & ω^4 & ω^5 & ω^6 & ω^7 & ω^8 & ω^9 \\
1 & ω^2 & ω^4 & ω^6 & ω^8 & ω^{10} & ω & ω^3 & ω^5 & ω^7 \\
1 & ω^3 & ω^6 & ω^9 & ω & ω^4 & ω^7 & ω^{10} & ω^2 & ω^5 \\
1 & ω^4 & ω^8 & ω & ω^5 & ω^9 & ω^2 & ω^6 & ω^{10} & ω^3 \\
1 & ω^5 & ω^{10} & ω^4 & ω^9 & ω^3 & ω^8 & ω^2 & ω^7 & ω \\
1 & ω^6 & ω & ω^7 & ω^2 & ω^8 & ω^3 & ω^9 & ω^4 & ω^{10} \\
1 & ω^7 & ω^3 & ω^{10} & ω^6 & ω^2 & ω^9 & ω^5 & ω & ω^8 \\
1 & ω^8 & ω^5 & ω^2 & ω^{10} & ω^7 & ω^4 & ω & ω^9 & ω^6 \\
1 & ω^9 & ω^7 & ω^5 & ω^3 & ω & ω^{10} & ω^8 & ω^6 & ω^4 \\
1 & ω^{10} & ω^9 & ω^8 & ω^7 & ω^6 & ω^5 & ω^4 & ω^3 & ω^2 \\
\end{bmatrix}⋅
\begin{bmatrix}
384812 \\188298 \\-625515 \\-78859 \\
740707 \\84370 \\834405 \\98208 \\
361900 \\-56177 \\
\end{bmatrix}
$$ Likewise, $X=M_{\text{outer}}⋅\sqrt[11]{R}$ After numerical guessing and symbolic check, we can get: $$
\begin{bmatrix}
x_1\\x_2\\x_3\\x_4\\x_5\\
x_6\\x_7\\x_8\\x_9\\x_{10}\\
x_{11}\\
\end{bmatrix}=
\begin{bmatrix}
ω^3 & ω & ω^2 & ω^8 & 1 & 1 & ω^3 & ω^9 & ω^{10} & ω^8 \\
ω & ω^8 & ω^7 & 1 & ω & ω^{10} & 1 & ω^4 & ω^3 & ω^{10} \\
ω^9 & ω^2 & ω^9 & ω^{10} & ω^8 & ω^3 & ω & ω^2 & ω^9 & ω^2 \\
ω^{10} & ω^4 & ω & ω^3 & ω^2 & ω^9 & ω^8 & ω^{10} & ω^7 & ω \\
ω^2 & ω^{10} & ω^{10} & ω^4 & ω^6 & ω^5 & ω^7 & ω & ω & ω^9 \\
ω^7 & ω^9 & ω^3 & ω^2 & ω^9 & ω^2 & ω^9 & ω^8 & ω^2 & ω^4 \\
ω^6 & ω^7 & 1 & ω^9 & ω^4 & ω^7 & ω^2 & 1 & ω^4 & ω^5 \\
ω^8 & 1 & ω^6 & ω^6 & ω^3 & ω^8 & ω^5 & ω^5 & 1 & ω^3 \\
ω^4 & ω^3 & ω^5 & ω & ω^5 & ω^6 & ω^{10} & ω^6 & ω^8 & ω^7 \\
1 & ω^6 & ω^4 & ω^7 & ω^7 & ω^4 & ω^4 & ω^7 & ω^5 & 1 \\
ω^5 & ω^5 & ω^8 & ω^5 & ω^{10} & ω & ω^6 & ω^3 & ω^6 & ω^6 \\
\end{bmatrix}⋅
\begin{bmatrix}
\sqrt[11]{r_1} \\
\sqrt[11]{r_2} \\
\sqrt[11]{r_3} \\
\sqrt[11]{r_4} \\
\sqrt[11]{r_5} \\
\sqrt[11]{r_6} \\
\sqrt[11]{r_7} \\
\sqrt[11]{r_8} \\
\sqrt[11]{r_9} \\
\sqrt[11]{r_{10}} \\
\end{bmatrix}
$$ And finally $$
\begin{aligned}
\cos\left(\frac{2kπ}{23}\right) = \frac{1}{22}\left(x_k-1\right)
\end{aligned}
$$ Question During my calculation, $M_{\text{outer}}$ was obtained by exhaustiveness. The computer took about two days to get this result, and the time required to calculate $n = 47$ would be unacceptable. $$
M = ω\,\verb+^+\,\begin{bmatrix}
 3 & 1 & 2 & 8 & 0 & 0 & 3 & 9 & 10 & 8 \\
 1 & 8 & 7 & 0 & 1 & 10 & 0 & 4 & 3 & 10 \\
 9 & 2 & 9 & 10 & 8 & 3 & 1 & 2 & 9 & 2 \\
 10 & 4 & 1 & 3 & 2 & 9 & 8 & 10 & 7 & 1 \\
 2 & 10 & 10 & 4 & 6 & 5 & 7 & 1 & 1 & 9 \\
 7 & 9 & 3 & 2 & 9 & 2 & 9 & 8 & 2 & 4 \\
 6 & 7 & 0 & 9 & 4 & 7 & 2 & 0 & 4 & 5 \\
 8 & 0 & 6 & 6 & 3 & 8 & 5 & 5 & 0 & 3 \\
 4 & 3 & 5 & 1 & 5 & 6 & 10 & 6 & 8 & 7 \\
 0 & 6 & 4 & 7 & 7 & 4 & 4 & 7 & 5 & 0 \\
 5 & 5 & 8 & 5 & 10 & 1 & 6 & 3 & 6 & 6 \\
\end{bmatrix}
$$ Structurally, the coefficients constitute a cycle. Can $M_{\text{outer}}$ be derived directly from the point of view of group theory? Update to commits The solution of $p = 17$ doesn't help much because the highest expansion is only quadratic expansion, while $p = 23$ is up to 11st expansions, $p=47$ is up to 23rd expansions, and $p=59$ is up to 29th expansions.","['galois-theory', 'group-theory', 'trigonometry']"
4473644,Let $x^2 + 3x +1 = 0$. Is $x^{2048} + \dfrac{1}{x^{2048}}$ divisible by 3?,"Let $x^2  + 3x +1 = 0$ . Solve for $x^{2048} + \dfrac{1}{x^{2048}}$ . Is it divisible by 3? $x^2 + 1 = -3x \Rightarrow x+ \dfrac{1}{x} = -3$ $x^2 + \dfrac{1}{x^2} = (x + \dfrac{1}{x})^2 - 2 = 9 -2 = 7$ $x^4 + \dfrac{1}{x^4} = (x^2 + \dfrac{1}{x^2})^2 - 2 = 49 - 2 = 47$ seeing the pattern, let $s_n = x^{2^n} + \dfrac{1}{x^{2^n}}$ I need $s_{11}$ $s_1 = -3$ $s_2 = 7$ $s_3 = 47$ $s_4 = 47^2 - 2 = 2207$ $\vdots$ $((2207^2 -2)^2 - 2)^2 -2)^2 ... - 2)$ quite big But I realized I didn't have to simplify it, I just have to check if $((((((2207^2 - 2)^2 -2)^2 -2)^2 -2)^2 -2)^2 - 2)^2 -2$ is divisible by 3","['algebra-precalculus', 'solution-verification', 'quadratics']"
4473663,"A circle, a square, and an equilateral triangle had the same area. If their perimeters represent their ages, who are the oldest and the youngest?","Once upon a time, a circle, a square, and an equilateral triangle had the same area. If their perimeters represent their ages, who are the oldest and the youngest? Note: Perimeter of a circle is its circumference. Solve without a calculator. Answer:
Let $s, r, x$ be the sidelength of the square, the radius of the circle, and the sidelength of the triangle, respectively. $s^2 = \pi r^2 = x^2 \dfrac{ \sqrt{3}}{4}$ $s = r\sqrt{\pi} = x \sqrt{\dfrac{ \sqrt{3}}{4}} =  x {\dfrac{ \sqrt[4]{3}}{2}}$ Without using a calculator, still clearly, $s > r, s > x, x > r \Rightarrow s > x > r$ . But what I need is the comparison of $4s, 2\pi r,$ and $3x$ . Given $s > x,$ clearly $4s > 3s > 3x$ . editing this part below: it's still messy I'm on it right now. Given $s > r$ , clearly, $4s > 4r$ , $2 \pi r > 6r > 4r > 4s$ . Given $x > r,$ clearly, $$ okay, I can't seem to compare the others. I only know square's older than the triangle. p.s. is it correct I tagged algebraic-geometry? lol","['euclidean-geometry', 'algebra-precalculus', 'geometry']"
4473666,"Guess 2/3 of the Average - Is 0 More ""Powerful"" than 100?","I was reading about this game called ""Guess 2/3 of the Average"" ( https://en.wikipedia.org/wiki/Guess_2/3_of_the_average ). Players guess an integer between 0 and 100 - the winner is the player whose guess was closest to 2/3 of the average number guessed by all players. I read that if everyone knows how this game works, the best guess to make is 0. This is because guessing the number 0 will ""shrink"" the average of all guesses (and 2/3 of the average) closer to 0, thus making your guess closest to the average of 2/3rd's of all guesses and making you the winner. (However, this strategy is only valid if everyone knows how the game works - if players guess random numbers, then 0 is no longer the best guess) I tried to explain this game to my friend and explain why guessing the number 0 is the best guess. My friend argued that if guessing the number 0 has the ability to ""shrink"" 2/3rd's of the average guesses towards 0 - wouldn't guessing the number 100 have the equal ability to ""expand"" 2/3rd's of the average guess towards 100? I used this analogy: Suppose there are 3 exams - if you score 100/100 marks on two of the exams and score 0/100 on the third exam, your average grade is 66%. But if you score 0/100 on two exams and score 100/100 on the last exam, your average grade is only 33%. My informal reasoning was that the number 0 is much more powerful in pulling an average towards itself  compared to the number 100. But now, I beginning to doubt my own logic and reasoning. Can someone please explain the logic behind why guessing the number 0 is the best guess for this game (assuming that everyone knows how this game works)? Thank you!","['statistics', 'means', 'game-theory', 'average', 'probability']"
4473689,Simplifying a sum of binomial coefficients multiplied by power of choice number,"Let $n$ be a positive integer. Prove that $$ \sum_{k=0}^n \binom{n}{k}(k+1)^{k-1}(n+1-k)^{n-k} = (n+2)^n$$ Trying to generalize a combinatorial problem, my collegue have obtained the LHS with some numerical evidences which indicates the equation may holds.
I have tried to prove it elementarily but failed. What I have succeeded is to prove it using exponential generating function with Lambert omega function. The exponential generating function of the LHS is $$
\sum_{n=0}^{\infty} \frac{x^n}{n!} \sum_{k=0}^n \frac{n!}{k!(n-k)!} (k+1)^{k-1} (n+1-k)^{n-k}
$$ which can be arranged $$
\left( \sum_{k=0}^{\infty}\frac{(k+1)^k}{(k+1)!}x^k \right) \left( \sum_{l=0}^{\infty} \frac{(l+1)^l}{l!} x^l \right)
$$ Let $L(x) = -W_0(-x)$ where $W_0$ is the principal branch of the Lambert $W$ function.
Then the series expression $L(x) = \sum_{n=1}^{\infty} \frac{n^{n-1}}{n!} x^n$ and the differential equation $xL'(x) = \frac{L(x)}{1-L(x)}$ and hence the series expression $\sum_{n=1}^{\infty} \frac{n^n}{n!} x^n = \frac{L(x)}{1-L(x)}$ holds.
These observations at hands, the exponential generating function of the LHS can be written as $$
\left(L(x)/x \right) \left(\frac{ L(x)}{x(1-L(x))} \right) = \frac{L(x)^2}{x^2(1-L(x))}
$$ On the otherhand the exponential generationg function of the RHS is $\left( L(x)/x \right)'$ .
But then $$
 \left(\frac{L(x)}{x}\right)' = \frac{xL'(x)-L(x)}{x^2} = \frac{L(x)^2}{x^2(1-L(x))}
$$ which completes the proof. However, I thing there would be a beautiful combinatorial argument which proves the identity. Is there anyone who can help to find such a proof?","['combinations', 'combinatorial-proofs', 'binomial-coefficients', 'combinatorics', 'generating-functions']"
4473710,Computing block systems for non-transitive permutation groups.,"Atkinson as well as Schönert and Seress describe methods to compute the minimal block system for transitive permutation groups; in particular in Permutation Group Algorithms by Ákos Seress, we find Theorem 5.5.1 Suppose that a set S of generators for some transitive $G \leq Sym(\Omega)$ is given and $|\Omega| = n$ . Then a minimal block of imprimitivity can be computed [...] by a deterministic algorithm. Is there a way to compute such block systems for non-transitive permutation groups? I have not found anything in the literature about such a computation.","['gap', 'computational-algebra', 'magma-cas', 'computer-algebra-systems', 'group-theory']"
4473711,How to prove that $\frac{1}{1^2}+\frac{1}{2^2}+\dots+\frac{1}{n^2}+\dots=\frac{\pi^2}{6}$ using the spiral right angle triangle method?,"I see this formula given below on You tube video of mathologer channel and then I try to find some new method to prove it : $$\sum_{n=1}^\infty \frac1{n^2} = \frac{\pi^2}6$$ I tried to prove it geometrically like this Our attempt : (1) First I tried to convert it in inverse trignometric form like this but that doesn't help much: (2) In my second attempt I rotate the length of $1/2$ length from $1$ then I rotate $1/3$ length from remaining $1/2$ but that thing doesn't help us. (3) In my third attempt, I tried to use coordinate geometry but that makes things more complex. My question :How to prove that that summation of $1/n^2$ where $n$ tends to infinity is equal to $π^2/6$ by using spiral right angle triangle method ? EDIT NOTE: Sinc the last line segment Whose length tends to Square root of $π^2/6$ but not exactly equal to Square root of $π^2/6$ so it is probably not possible to solved it by using pure geometry .
we understand that there must be needs of theory of Limit to prove it .
so we will also accept the solution which take the use of both concept means geometry with slight use of calculus.","['summation', 'geometry', 'riemann-hypothesis', 'calculus', 'eulers-method']"
4473746,How many ways can you arrange nothing?,"I have heard that you can arrange nothing in only $~0! = 1$ way. That is, leave it like that, nothing. Is that reasoning correct? I want to understand why there's one way to arrange nothing when there's nothing to be arranged in the first place. You can't arrange something that doesn't exist, right? I hope you help me understand this concept.","['combinatorics', 'probability-theory', 'probability']"
4473751,Why does this desmos plot of the integral of $\sqrt{1+e^x}$ have these discontinuities?,"I computed the integral of $\sqrt{1+e^x}$ by hand and got $$2\sqrt{1+e^x} + \ln\left(\sqrt{1+e^x} - 1\right) - \ln\left(\sqrt{1+e^x} + 1\right) + C,$$ or $$2\sqrt{1+e^x} + \ln\left(\frac{\left(\sqrt{1+e^x} - 1\right)^2}{e^x}\right) + C.$$ But when I plot the graph on Desmos, this strange thing happened: Can anyone explain this discontinuity phenomenon I have seen? And, is there a better form of the function that the one I have?","['integration', 'desmos', 'machine-precision', 'calculus', 'numerical-methods']"
4473782,Counting endofunctions by inclusion–exclusion,"While leafing through the OEIS, I noticed the following conjecture (from  Werner Schulte, OEIS A000312 ): For integer $n \ge 0$ $$  \sum_{k=0}^n  (-1)^{n - k} { n \brack k }{n+k \brace k} =  n^n . $$ Here ${ n \brack k }$ denotes the unsigned Stirling cycle numbers and $\left\{ {n} \atop  k\right\}$ the Stirling set numbers. This led me to wonder whether $T(n,k) := { n \brack k } {n+k \brace k}$ is the number of simple combinatorial or set theoretical objects. Can anyone describe such objects and derive the conjecture from them?","['summation', 'combinatorial-proofs', 'oeis', 'inclusion-exclusion', 'combinatorics']"
4473853,"How can I calculate the area of a circle centered at (2,2) with radius 2 using double integrals","This is what the graph loosk like. Obviously I know $\pi r^2$ but if I specifically wanted to find the area using double integrals in polar coordinates, how would I go about it? My guess is that $\theta$ goes from $0$ to $\pi/2$ and for $r$ I need to do: $(x-2)^2+(y-2)^2=4$ $x^2-4y+4+y^2-4y+4=4$ $(x^2+y^2)-4(x+y)=-4$ $r^2-4(r\cos\theta+r\sin\theta)=-4$ $r^2=4(r\cos\theta+r\sin\theta)-4$ Not exactly sure what to do from here.","['integration', 'multivariable-calculus']"
4473860,Problem with Veblen's proof for the transcendence of $\pi$,"I'm trying to understand the following proof , (no need to read all of it), but there's one point where I'm stuck. The proof is by contradiction, so they use the definition of an algebraic number (a is algebraic if there exists a polynomial in the field extension such that $f(a)=0$ : "" $x_1,...,x_n$ are algebraic, so they are the roots of an equation $$f(x) = a_0+a_1x+...+a_nx^n$$ with integral coeffiecients, $a_0\neq0, a_n\neq0$ ."" Yet, on the last page the Girard–Newton formulas are used: ""But from Newton's formulas $$S_1+a_1=0, S_2+a_1S_1+2a_2+0,...$$ it follows that $S_1,S_2,...,S_{s-p}$ are whole numbers. Where from my own calculations based on Wikipedia (so not sure if this is correct), these formulas are given by $$\sum^k_{i=1} (-1)^{i-1}a_{n-k+i}S_i = ka_{n-k}$$ for $1 \leq k \leq n$ . Meaning that we would get $a_nS_1 + a_1 = 0$ etc. So if $a_n$ isn't 1, if $f$ isn't monic, $S_i$ wouldn't be an integer. Why do we suddenly assume $f$ to be monic, since this doesn't follow from the definition of an algebraic number.
Is the proof wrong? What am I missing? This has been messing with me for days, thank you in advance. Edit: This is guessing work, but I think we may assume $f$ is monic from the start. By looking at the proof for the transcendence of $e$ , this is obvious.But I think there might be a way to choose $x_1,...,x_n$ as roots for $f$ such that it is monic and $$c+\sum^{n}_{i=1} e^{x_i} = 0.$$ Edit²: The formulas should be as follow: $a_nS_1 + a_{n-1} = 0, S_2 = S_1^2-2\frac{a_{n-2}}{a_n}$ etc","['number-theory', 'transcendence-theory', 'abstract-algebra', 'symmetric-polynomials']"
4473891,Angle of rotation between two points on cylindrical helix,"Schematic drawing of the problem I would like to calculate the angle of rotation $\theta$ between two points $A$ and $B$ , positioned on the termini of a helix wrapping around a cylinder of known diameter $2r$ and length $L$ in a counter-clockwise manner. The angle $\alpha$ , i.e. the acute angle between the vertical axis of the cylinder and the slope of the helix, is the only other parameter known. How would you calculate the angle $\theta$ ? Please see the attached image. The coordinates of $A$ and $B$ are not known; any point (here $B$ ) at the top of the cylinder rotates with angle $\theta$ respective to a point (here $A$ ) at the bottom. My goal is to find the resulting $\theta$ only knowing $L$ , $r$ , and $\alpha$ . Note that $\theta$ can be larger than $360^\circ$ if the helix has more than one revolution on the cylinder. As an example, consider the following values: $\begin{align}\qquad
\alpha &= 0.3^\circ \\
L &= 1.5 \\
r &= 0.2
\end{align}$ I tried to get an answer by using basic trigonometry, but I'm missing the helical aspect of the rotation I think. To calculate $\theta$ , I assumed that it was basically the angle of an isoceles triangle with two sides $r$ and one side $\tan(\alpha) \cdot L$ (because the chord between $A$ and the projection of $B$ is the opposite side of a right-angled triangle denoted by $\tan(\alpha) \cdot L$ ). Since the resulting triangle is not right-angled, I split it in two and calculated half $\theta$ with $$\sin(\frac{\theta}{2}) = \frac{1}{2}\tan(\alpha)\cdot\frac{L}{r}$$ such that $\frac{\theta}{2} = \sin^{-1}(\frac{1}{2}\tan(\alpha)\cdot\frac{L}{r})$ and therefore $$\theta = 2\cdot\sin^{-1}\left(\tan(\alpha)\cdot\frac{L}{2r}\right)$$ Solving this equation for my example yields $2\cdot \sin^{-1}(\tan(0.3)\frac{1.5}{2\cdot 0.2}) = 2.25^\circ$ , which seems feasible. However, my equation breaks down when $\theta$ is greater than $180^\circ$ — because there is no triangle anymore — and it certainly cannot deal with more than one revolution ( $>360^\circ$ ). I have trouble finding the right equations to deal with this problem. By chance, I stumbled upon an equation for helix torsion $$w = \frac{k}{r \cdot (1+k^2)}$$ on https://www.redcrab-software.com/en/Calculator/Helix , in which $w$ is the torsion, $k$ is the helix slope, and $r$ is the radius. It gives similar results to my own equation at small values of $\alpha$ when I multiply the answer by $L$ and use radians instead of degrees, before converting back to degrees: $\frac{0.3\cdot\frac{\pi}{180}}{0.2\cdot(1+(0.3\cdot\frac{\pi}{180})^2)}\cdot1.5\cdot\frac{180}{\pi} = 2.25^\circ$ . It also seems to be able to deal with $\theta > 180^\circ$ . I do not understand how it works, however, nor how it was derived. Is this even the right equation? I cannot find it anywhere else on the internet. Could anyone help me solve my problem?","['trigonometry', 'rotations']"
4473895,"On the existence of infinitely many linearly independent solutions for a non-linear IVP $y'=f(t,y),~y(t_0)=y_0$.","Consider the IVP $$
\begin{cases}
y'=f(t,y),\\
y(t_0)=y_0
\end{cases}
\label{1}\tag{$\ast$}
$$ Case $1$ : $f$ is Lipschitz w.r.t $y$ and continuous w.r.t $t$ in a vertical (infinite) strip $[a,b]\times \Bbb R$ containing the point $(t_0,y_0)$ . Here the existence and uniqueness of the solution on the interval $[a,b]$ is guaranteed by Picards Theorem. Case $2$ : $f$ looses the Lipschitz continuity w.r.t $y$ near the point $(t_0,y_0)$ like $f(t,y)=4y^{3/4},\sqrt y,... $ (take $y_0=0$ ). Mostly, I have seen infinitely many linearly independent solutions for such non linear $f$ . Doubts: i. Can we conclude that if there exists two linearly independent solutions for \eqref{1}, then there will be infinitely many linearly independent solutions. If so, how to justify the claim? ii. Any other conditions required to ensure there will be infinitely many linearly independent solutions for \eqref{1}?","['initial-value-problems', 'ordinary-differential-equations', 'real-analysis']"
4473910,"On Alperin's paper ""The Green Correspondence and Brauer's Characterization of Characters"" (aka what is a central factor?)","I was studying the paper ""The Green Correspondence and Brauer's Characterization of Characters"" by J. Alperin and I couldn't understand two of the passages. Hypotheses and notations $G$ is a finite group with the following properties: $G$ is not nilpotent; Every proper homomorphic image of $G$ is elementary; $G$ has a unique minimal normal subgroup $N$ ; $N$ is a $p$ -group for some prime number $p$ (and thus it's elementary abelian). First unclear passage At this moment of the paper, Alperin is proving that $N = O_p(G)$ , the $p$ -core of $G$ (that is, the largest normal $p$ -subgroup of $G$ ). To do so, he argues that $O_p(G)$ is an elementary abelian group in the following fashion: ""If $O_p(G)$ is not elementary abelian then the Frattini subgroup $D(O_p(G))$ of $O_p(G)$ is not $1$ so must contain $N$ , by (3). But then $O_p(G)/D(O_p(G))$ is a central factor of $G$ so that $N$ will be also. Hence, $N$ is a central factor and $G/N$ is nilpotent so we have contradicted (1)."" The terminology ""central factor"" was new to me and I had to search for possible definitions. The only one that made sense in this context was the following: if $H,K \trianglelefteq G$ are normal subgroups and $K \leq H$ , we say that $H/K$ is a central factor of $G$ if $H/K \leq Z(G/K)$ . Based on this definition, I assumed that a (normal) subgroup of $G$ is a central factor if it's contained in $Z(G)$ (this agrees with the definition of central factor in Groupprops Subwiki if the normal subgroup is abelian, which is our case). Is there any other definition which makes more sense here? I can see that $D(O_p(G))$ is not trivial and contains $N$ . I also agree that $O_p(G)/D(O_p(G))$ is a central factor of $G$ , since $G/D(O_p(G))$ is nilpotent by (2) so $O_p(G)/D(O_p(G))$ is the $p$ -Sylow subgroup of $G/D(O_p(G))$ and is abelian. But how this implies that $N$ is a central factor? (Knowing this, I am able to understand the final sentence of the argument.) Second unclear passage The paper continues and Alperin has just proved that $N = O_p(G)$ . He then invokes the Schur-Zassenhaus theorem and concludes that $G$ is the semi-direct product of $N$ and another subgroup $K$ (but I think this is irrelevant for my question). We arrive at this sentence: ""The uniqueness of $N$ now gives us that $N$ is not a central factor of $G$ ; hence, no non-trivial character of $N$ is stabilized by $G$ ."" Since $Z(G)$ is normal in $G$ , it must contain $N$ if it isn't trivial. But then we could argue that $G$ is nilpotent as before, a contradiction. Thus, $Z(G) = 1$ and $N$ is clearly not a central factor. This intuitively implies that no non-trivial irreducible character of $N$ is stabilized by $G$ , but I cannot give a proof. Could someone help me here too? I said that it was ""intuitive"" so here is what my intuition says: We know that $N$ is elementary abelian so we understand what the irreducible characters of $N$ look like. If $\chi$ is a non-trivial character of $N$ , there is $n \in N$ such that $\chi(n) \neq 1$ and hence $\chi(n)$ equals some primitive $p$ -th root of unity. Since $G$ has trivial center, there is $g \in G$ such that $gng^{-1} \neq n$ . It is reasonable to expect that $\chi(gng^{-1}) \neq \chi(n)$ (which would imply that $g$ does not stabilize $\chi$ ) but $\chi$ can indeed assume repeated values and this inequality is not (immediately) guaranteed. We would need to search for the right $n$ and the right $g$ . Instead of dealing with individual elements of $N$ , I also tried working with the isomorphism between $N$ and its dual group. If this isomorphism were compatible with the actions of $G$ , the result would follow from the fact that $Z(G) = 1$ . But this isomorphism is not canonical, so you can correctly guess that my calculations didn't take me where I wanted. Maybe there is some combinatorial argument or maybe we have enough information to understand the action of $G$ on $N$ , I don't know... To sum it up Which definition of ""central factor"" is Alperin probably using? If I am using the correct one: How to prove that $N$ is a central factor in the first passage? How to guarantee that the non-trivial irreducible characters of $N$ aren't fixed by $G$ in the second passage?","['representation-theory', 'group-theory', 'finite-groups', 'characters']"
4473966,A uniform bound of Hölder class-like densities.,"Let $f(x)$ satisfies $f\geq 0$ and $\int_R f(x)dx = 1$ , suppose it also in the so-called H $\ddot o$ lder class, i.e. $\mid f(x)^{(l)}-f(y)^{(l)}\mid \leq L\mid x-y \mid^{\alpha}$ for all $x, y \in R$ , where $f(x)^{(l)}$ is the $l-$ order derivative of $f$ , $l$ is a positive integer, $0<\alpha<1$ and $L$ is a positive number. The question is to show that such class of $f$ is uniform bounded, i.e., $f(x)\leq M$ for all $x$ and all $f$ satisfies the conditions, where $M$ is a constant only depends on $l,\alpha, L$ . It seems like a mathematical analysis problem with a quite simple form. A proof or any references and directions are appreciated.","['statistics', 'analysis', 'real-analysis', 'probability-theory', 'density-function']"
4474054,Solving $-u''+u=\delta'(x-1)$ using the Fourier transform,"Using Fourier transforms, solve the following boundary value problem $$-u''+u=\delta'(x-1)$$ where $\delta$ stands for the Dirac delta function, with $u(x) \to 0$ as $\lvert x \rvert \to \infty$ . I applied Fourier transforms to both sides of the equation and I arrived to the conclusion that the Fourier transform of the solution must be $$u_F(k)=\frac{ike^{-ik}}{\sqrt{2\pi}(k^2+1)}$$ Then, using a Foruier transforms table, I get the following solution $u(x)=e^{x-1}/2$ if ( $x<1$ ) and $u(x)=-e^{1-x}/2$ if ( $x\geq 1$ ), which is the derivative of $e^{-\lvert x-1\rvert}/2$ . As this function has Fourier transform $\frac{e^{-ik}}{\sqrt{2\pi}(k^2+1)}$ , its derivative has Fourier transform $ik\frac{e^{-ik}}{\sqrt{2\pi}(k^2+1)}$ , and hence should be the solution to the boundary problem. The problem is this function is not even continuous at $x=1$ . What exactly is it that I'm doing wrong? Or, if I've done everything right so far, how can I fix this discontinuity problem?","['fourier-analysis', 'dirac-delta', 'ordinary-differential-equations', 'fourier-transform', 'distribution-theory']"
4474056,"What purely real analytic techniques are there to evaluate $\int_{-\pi/2}^{\pi/2}\frac{1}{1+\sin^4(x)}\,\mathrm{d}x$?","$\newcommand{\d}{\,\mathrm{d}}$ Last night, I evaluated the following integral: $$\begin{align}I:&=\int_{-\pi/2}^{\pi/2}\frac{1}{1+\sin^4(x)}\d x\\&=\int_{-1}^1\frac{1}{(1+x^4)\sqrt{1-x^2}}\d x\\&=\frac{\pi}{2^{3/4}}
(\sin(\pi/8)+\cos(\pi/8))\\&=\frac{\pi}{2}\sqrt{1+\sqrt{2}}\end{align}$$ Using a ""double keyhole"" (as I phrase it) contour method involving a management of branch cuts and residues at infinity, here . Although I was happy to have succeeded in this, I wondered afterwards if I would have had any hope of evaluating $I$ with real analytic technique only. The challenge: Evaluate $I$ without use of complex analysis or even of complex arithmetic (e.g. for partial fraction decompositions involving $i$ ) I posed this to some friends and they came up with the following method which I wanted to share with MSE: $$\begin{align}I&\overset{x\mapsto\tan x}{=}\int_{-\infty}^\infty\frac{1+x^2}{(1+x^2)^2+x^4}\d x\\&\overset{x\mapsto1/x}{=}2\int_0^\infty\frac{1+x^2}{(1+x^2)^2+1}\d x\\&=2\int_0^\infty\int_0^\infty e^{-t(1+x^2)}\cos(t)\d t\d x\quad\text{Repr. with IBP}\\&=\sqrt{\pi}\int_0^\infty\frac{e^{-t}\cos(t)}{\sqrt{t}}\d t\end{align}$$ $$\begin{align}J:&=\int_0^\infty\frac{e^{-t}\cos(t)}{\sqrt{t}}\d t\\J^2&=\int_0^\infty\int_0^\infty\frac{e^{-(t+x)}\cos(t)\cos(x)}{\sqrt{tx}}\d t\d x\\&\overset{x\mapsto tx}{=}\int_0^\infty\int_0^\infty\frac{e^{-t(1+x)}\cos(t)\cos(tx)}{\sqrt{x}}\d x\d t\\&=\frac{1}{2}\int_0^\infty\frac{1}{\sqrt{x}}\cdot\frac{1+x+x^2}{(1+x)(1+x^2)}\d x\\&\overset{x\mapsto x^2}{=}\frac{1}{2}\int_0^\infty\left(\frac{1+x^2}{1+x^4}+\frac{1}{1+x^2}\right)\d x\\&=\frac{1}{2}\left[\frac{\pi}{4}\csc\left(\frac{\pi}{4}\right)+\frac{\pi}{4}\csc\left(\frac{3\pi}{4}\right)+\frac{\pi}{2}\right]\\&=\frac{\pi}{4}(1+\sqrt{2})\end{align}$$ Referencing this answer by Sangchul. We conclude: $$\begin{align}I&=\sqrt{\pi}\cdot\sqrt{J^2}\\&=\sqrt{\pi}\cdot\sqrt{\frac{\pi}{4}(1+\sqrt{2})}\\&=\frac{\pi}{2}\sqrt{1+\sqrt{2}}\end{align}$$ Among those who helped me, who use MSE, I credit @TheSimpliFire and @KStarGamer who are much better at real integration than I am! My question is less of a question and more of a request for a list - a list of other, purely real, methods to attack this integral. I hope the outcome of this will be an interesting selection of advanced integration techniques that I and others can learn from. Note 1: I am aware of this posting by Quanto but it uses complex numbers. Note 2: You must expand the cosine product as a sum of cosines and use the same integral representation (which is classically gotten from complex arithmetic but can be done with integration by parts): $$\int_0^\infty e^{-tx}\cos(t)\d t=\frac{x}{x^2+1},\,x\gt0$$","['integration', 'big-list', 'real-analysis']"
