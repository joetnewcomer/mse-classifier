question_id,title,body,tags
1449357,What is Amalgamation,"My question is what exactly is free product of groups with amalgamation? 
I came across this term in algebraic topology.
Is it possible to explain it at a level that an undergraduate with knowledge of basic group theory  can understand?
Some examples would be fine too.
Thanks!","['group-theory', 'algebraic-topology']"
1449424,Why does the polar coordinate method not work?,"I tried to calculate the limit $\lim\limits_{(x,y)\rightarrow(0,0)} (x^2+y^2)^x$ By using polar coordinates $ x = r \cdot \cos(\theta)$ $y = r \cdot \sin(\theta)$ resulting in $((r\cdot \cos(\theta))^2+(r\cdot \sin(\theta))^2)^{r\cdot \cos(\theta)}$ $ = (r^2(\cos^2(\theta)+\sin^2(\theta))^{r\cdot\cos(\theta)} =  (r^2)^{r\cdot\cos(\theta)} = r^{2r\cdot \cos(\theta)}$ which for $r \to 0$ is $1$ But the actual limit of $\lim\limits_{(x,y)\rightarrow(0,0)} (x^2+y^2)^x$ is $0$. Why does the polar cooridinate method not work? Thank you in advance.","['multivariable-calculus', 'limits', 'polar-coordinates']"
1449426,How many roots have modulus less than $1$?,"If roots of the equation $$x^7 - 4x^3 + x + 1=0$$ are plotted on the Argand plane, how many of them have distance from the origin less than $1$? I found, by plotting the rough curve of $y= x^7 - 4x^3 + x + 1$ that it has three real roots, out of which two of them have modulus greater than $1$ and one has modulus less than $1$. But I don't know how to do the same for non - real roots. The answer given in my book is that $3$ roots have modulus less than $1$.","['roots', 'complex-numbers', 'algebra-precalculus', 'polynomials', 'complex-analysis']"
1449431,Do subgroup and quotient group define a group?,Does a (normal) subgroup along with its corresponding quotient group define a group completely? Or are there groups with isomorphic normal subgroups and isomorphic corresponding quotient groups which are themselves as a whole not isomorphic?,"['group-theory', 'examples-counterexamples', 'normal-subgroups']"
1449488,'Complementary topology'?,"Let $(X,\mathscr{T})$ be a topological space, and define a new topology $\mathscr{T}'$ on $X$, such that the collection of closed sets $\mathscr{C}$ of the topology $\mathscr{T}$ form a sub-basis for $\mathscr{T}'$. Lets refer to $\mathscr{T}'$ as the 'complementary topology' for convenience. In fact since the intersections of closed sets are again closed and since $X\in \mathscr{C}$, the sub-basis also covers the space, so the sub-basis $\mathscr{C}$ would be a basis for $\mathscr{T}'$. I was curious as to the properties of this topology. An initial thought was that this may be the discrete topology. Taking for example the standard euclidean topology $(\mathbb{R},\mathscr{T}_{E})$, if we form the 'complementary topology', we have in our basis $\mathscr{C}_E$, that $\{x\}\in\mathscr{C}_E, \, \forall x\in\mathbb{R}$. Since open sets are formed from unions of these sets, any set is open so $\mathscr{T}_{E}'=\mathscr{T}_{D}$, the discrete topology. This cannot be true in general since taking for example a three point set $\{1,2,3\}$, with the topology $\mathscr{T}=\{\emptyset, \{1\},\{1,2\},\{1,2,3\}\}$, the complementary topology is given by $\mathscr{T}'=\{\emptyset,\{3\},\{2,3\},\{1,2,3\}\}$, which is certainly not the discrete topology. However in the second example we do have that $(\mathscr{T}')'=\mathscr{T}$. So I am curious if there are conditions on the topology such that we have either $(\mathscr{T}')'=\mathscr{T}$ or $(\mathscr{T})'=\mathscr{T}_D$? Is there a simple example where neither hold? Of course if the topology was discrete in the first place both would hold.",['general-topology']
1449494,how to prove using elementary comparisons that $x \log x \leq \log(2x^2-3x+2)$?,"I am trying to show that $x \log x \leq \log(2x^2-3x+2)$ on $[1,2]$ . The things is that these two functions are pretty close to each other: so I have a hard time finding a simple function which trivially lies between the two.","['logarithms', 'calculus', 'inequality', 'functions']"
1449521,GCD domain is LCM domain [duplicate],"This question already has an answer here : Greatest Common Divisor implies Least Common Multiple? (1 answer) Closed 2 years ago . On this Wiki page it is written: A GCD domain is an integral domain $R$ with the property that any two non-zero elements have a greatest common divisor (GCD). Equivalently, any two non-zero elements of $R$ have a least common multiple (LCM). How to prove last statement that is equivalence of GCD and LCM for all elements? (I am able to prove in Bezout ring but I am not able to prove in general GCD ring.) Does the existence of gcd of two elements implies existence of lcm and conversely in any integral domain?","['abstract-algebra', 'ring-theory']"
1449554,Line Bundle of deg $2g-1$ and generated by global sections,"Let $X$ be a smooth projective curve of genus $g \geq 2$ over $\mathbb{C}.$ Does there exist a line bundle $L$ on $X$ of degree $\deg L= 2g-1$ such that it is generated by global sections? (One can show that if $L$ is a line bundle of degree $\deg L=2g-1$ such that the canonical sheaf $\omega_{X}$ is not a subsheaf of $L$ , then L is generated by global sections. So it is enough to show the existence of such a line bundle. I do not know whether this is easy? )",['algebraic-geometry']
1449558,Convergence properties of empirical CDF?,"Let $X_1,\dots,X_n$ denote a sequence of dependent - let's say stationary and ergodic - sample from a distribution $F$, e.g. obtained as a stationary Markov chain. Then the empirical CDF is given by $$\hat F_n(z) = \frac{1}{n} \sum_{i=1}^n I(X_i \leq  z).$$ The $X_i$ can be assumed to have all finite second and higher moments if necessary. Now, I am interested in the convergence of $\hat F_n $ to $F$. In the independent case, there exists the classical Glivenko theorem which gives us uniform convergence. I have already found suitably generalized versions, which also hold for the case discussed here. What I would like to know, is whether it also holds that $\hat F_n$ converges in $L^2$ to $F$, i.e.,
$$ \int_\mathbb{R}  (\hat F_n(z) - F(z))^2 dz \rightarrow 0. $$ Can someone point point me towards some literature? I assume that this should be a standard textbook result, but coming from biology  applications, I am not really familiar with the mathematical statistics literature. Alternatively, can this be somehow proved from the Glivenko-Cantelli theorem?","['probability-theory', 'probability-limit-theorems']"
1449563,Height/Radius ratio for maximum volume cylinder of given surface area,"I am a bit confused by this problem I have encountered: A right circular cylindrical container with a closed top is to be constructed
with a fixed surface area. Find the ratio of the height to the
radius which will maximize the volume. I know the volume to be $ \pi{r}^2h$, but I don't see what equation I should be solving for. How can I solve for the ratio? Thanks","['optimization', 'calculus']"
1449587,Partial differentiation of the absolute value of a function containing complex coefficients.,"I have a function, $H$, which is a dependent on a number of parameters, $\theta_{i=1,\ldots,n}$ and a number of complex coefficients. The function hence gives a complex quantity. $H$ is relatively simple to differentiate w.r.t $\theta_i$. What I am interested in finding is, \begin{equation}
\sum_i \left| \frac{\partial|H|}{\partial \theta_i} \right|^2
\end{equation} Here is where I am unsure of myself: Because H is a function of theta \begin{equation}
\frac{\partial|H|}{\partial \theta_i} = \frac{\partial|H|}{\partial H}\frac{\partial H}{\partial \theta_i}
\end{equation} My question is: How do I calculate the differential of $|H|$ w.r.t $H$, given that H is complex (I think that this differential is undefined everywhere except zero?) Is there another way of expanding this in a form where I can calculate the differential. Note: although I can calculate dH/dtheta, it is difficult to directly calculate d(abs(H))/dtheta. Many thanks in advance. Edit If you will indulge me for one more question, Am I right in saying: \begin{equation}
\frac{\partial H_R}{\partial \theta_i} = 0.5 \left(\frac{\partial H}{\partial \theta_i}  + \frac{\partial \overline{H}}{\partial \theta_i}  \right)
\end{equation} So that I can use the partial differentials I have already calculated?","['partial-derivative', 'complex-analysis', 'complex-numbers', 'derivatives']"
1449599,Given $g$ find an $f$ which is solution for $L f = g$. How do I do this?,"I am learning about Stochastic processes.
To characterize uniqueness of solutions to a given Stochastic differential equation, I need to find for each continuous function $g :\Bbb{R}^2_+ \to \Bbb{R}$ a function $f:\Bbb{R}^2_+ \to \Bbb{R}$ such that $$ -\gamma f + (\partial_x f) (y-x) + (\partial_y f) (x-y) + \frac{1}{2} \bigg((\partial_{xx} f) x + (\partial_{yy} f) y\bigg) = g $$ This is I believe an inverse problem which has to do with spectral techniques such as proving that $\gamma  \in \rho(L)$ where $$L f = (\partial_x f) (y-x) + (\partial_y f) (x-y) + \frac{1}{2} \bigg((\partial_{xx} f) x + (\partial_{yy} f) y\bigg)$$ Maybe this can be solved more straightforwardly by finding a Green's function $G(x,y,\tilde{x}, \tilde{y})$ that satisfies 
$$ -\gamma G  - L G = \delta_{x -\tilde{x}} \delta_{y - \tilde{y}}$$ or something similar and then defining $$f = G*g. $$ How can we find such an $f$? Does it exist? Is there any good reference on the literature for this subject? Note: Here $(\partial_x f) (y-x) $ means $(\partial_x f(x,y)) \cdot (y-x)$","['differential-operators', 'analysis', 'reference-request', 'inverse-problems']"
1449629,How to calculate the determinant of this matrix?,"The matrix is $\mathbf{A}=\bigl[a_{ij}\bigr]_{1\leqslant i,j\leqslant n}$ and is defined as follows: $$a_{ij}=
\begin{cases}
i\; \mbox{if } i = j,\\
n\; \mbox{otherwise.}
\end{cases}
$$
or
$$\mathbf{A}=
\begin{bmatrix}
1 & n & \ldots & n\\
n & 2 & \ldots & n\\
\vdots & \vdots & \ddots & \vdots\\
n & n & \ldots & n\\
\end{bmatrix}$$ I tried one by one, for $n=1,2,3,$ and $4$ and I found a formula like: $$\det(\mathbf{A})=(-1)^{n+1}\cdot n!.$$ I could not prove it by induction.","['determinant', 'matrices']"
1449660,Length of digits before the period in decimal expansion for rational numbers,"I'm a newbie with number theory and I've been reading this page and trying to figure out how to calculate the length of the digits before the period and digits of the period of a rational number of the form $m/n$. I came up with the following steps but unfortunately this doesn't always work Compute the prime factors for the denominator $n$ If there are 10-coprimes factors, there's a period otherwise there isn't If there's a period, calculate its length taking each 10-coprime factor and doing the discrete logarithm $10^k\equiv 1 \pmod{factor}$ to find the maximum $k \le n$ (i.e. the maximum multiplicative order between the factors) There are digits before the period only if the denominator $n$ can be expressed as $n_02^\alpha5^\beta$ (and $n_0$ is coprime to 10) so the length of the digits before the period is the maximum between 0, $\alpha$ and $\beta$ The approach above, however, doesn't work since I'm getting length of 1 for the digits before the period for a simple rational number like $124/6 = 20,\bar6$ (while the result should be 0). I suppose the error should be in step 4.","['rational-numbers', 'number-theory', 'decimal-expansion', 'elementary-number-theory']"
1449672,Determine shift between scaled rotated object and additional scale step,"I am trying to find the amount to move an object so that, when it rotates and resizes, the resize would be smooth. I have a Qt program, where I have to rotate objects around center, and resize based on top left anchor. Unfortunately, built-in transformations combine anchors, so I can either do both transformations around center, or top left, or any unique point. The item coordinates are based on top-left corner. To perform operations around center, I translate item by cx , cy , perform rotation, translate by -cx , -cy . The transform used by the program is calculated by multiplying scale, then rotation then translation, is I think: $$ t=
        \begin{bmatrix}
        sx & 0 & 0 \\
        0 & sy & 0 \\
        0 & 0 & 1 \\
        \end{bmatrix}
.
        \begin{bmatrix}
        cos(\theta) & sin(\theta) & 0 \\
        -sin(\theta) & cos(\theta) & 0 \\
        0 & 0 & 1 \\
        \end{bmatrix}
.
        \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        tx & ty & 1 \\
        \end{bmatrix}
$$ (Based on documentation ... $$ t= \begin{bmatrix}
        scaleX& shearX & projX \\
        shearY & scaleY & projY \\
        transX & transY & 1 \\
        \end{bmatrix}
$$
) To rotate around center, I translate item to its (scaled) center, rotate, translate back, then resize.  The result is correct, but the item appears to move. After much struggle, I came to the solution that I have to adjust the item position on resize (or include the shift in the transform, but seems a position change is better since it allows the user to revert it). I just can't figure out by how much. I have tried to determine the item top-left coordinates before the resize, apply the transformation (which involves replacing current item transform with the transform that has the new parameters), determine the item top-left coordinates again, and shift by the change. The result was... horrific. Item still moves on resize after rotate, but the rotation anchor changed to bottom-right... I don't understand why. (I have tried many other ways to offset the move, none worked). Assume a rectangular object that has been rotated (perhaps also initially resized), around its center. (in image, the green text). If I resize it, I would like to keep the top left point fixed (like the blue text). Because of the fact that the transformations are compounded, creating a transformation containing resize and rotation would first resize (yellow text) and then rotate around the new center - resulting in the red text. Visually, there is a jump on resizing a rotated text... Legend: green = initial, blue = desired, red = actual, yellow = intermediate step to get red Note - I cannot apply rotation ater resize, because the way transforms work, I would end up with a skewed object if my scaling factors on x and y are different: So, my only option is to determine the shift between the previously rotated (and perhaps stretched) item top left, and the resulting stretched item top left points. How can I determine the dx and dy difference between the two points ? (in first image, top left of green text and top left of red text) I have seen questions that seem similar, but they attempt transformation around a unique anchor and have identical x and y scale factors... It is the anchor change that gives me headaches. Edit - I found a temporary solution - I am storing the ""old"" t31 and t32 , and adjusting position by the difference between the ""old"" and ""new"" values. I would prefer calculated values, since knowledge of the ""old"" item introduces more complications...","['analytic-geometry', 'matrices', 'geometry', 'trigonometry', 'transformation']"
1449680,Surjective+finite-type+quasi-finite doesn't imply finite,"Exercise II.3.5 (c) in Hartshorne, Algebraic Geometry, asks to find an example of a surjective, finite-type and quasi-finite morphism of schemes which is not finite. I need to find a finitely generated $A$-algebra $B$ which is not finite generated as an $A$-module. The only examples, I could find, of such a kind of $B$ give rise to a morphism which is not quasi-finite. Basically I was trying to use some modification of the classic $B=\mathbb{C}[x]$. I have also thought to  find a morphism which is not closed, since we know that a finite morphism is always closed, but even this way didn't lead me anywhere. Do you have any suggestion? P.S.: $f$ quasi-finite means that $f^{-1}(y)$ is a finite set for every point $y\in Y$. MOREOVER: while thinking at this example, I asked another question to myself. Which is a quasi-finite morphism which is not of finite-type? Thank you very much!",['algebraic-geometry']
1449686,prove $\mathscr{P}(\mathbb{N}\times\mathbb{N})=\mathscr{P}(\mathbb{N})\otimes\mathscr{P}(\mathbb{N})$,"How to prove $\mathscr{P}(\mathbb{N}\times\mathbb{N})=\mathscr{P}(\mathbb{N})\otimes\mathscr{P}(\mathbb{N})$? Here is my thinking:
by definition, $\mathscr{P}(\mathbb{N})\otimes\mathscr{P}(\mathbb{N})=\sigma(\mathscr{R})$, where $\mathscr{R}=\{R_1\times R_2:R_i\in\mathscr{P}(\mathbb{N})\}$. I am confused about $\mathscr{P}(\mathbb{N}\times\mathbb{N})$. What is $\mathscr{P}(\mathbb{N}\times\mathbb{N})$? Can I write $\mathscr{P}(\mathbb{N}\times\mathbb{N})=\sigma(\mathscr{E})$, where $\mathscr{E}=\{(k,m):k,m\in\mathbb{N}\}$? Similarly, can I write $\mathscr{P}(\mathbb{N})=\sigma(\mathscr{G})$, where $\mathscr{G}=\{k:k\in\mathbb{N}\}$?",['measure-theory']
1449690,Maximum amount of divisors of the number $n^m+m^n$,"We are given some positive integer $m$. What maximum amount of distinct prime divisors a number $n^m+m^n$ can have, where $n\in\mathbb{Z}_+$? Edit: As noted in comments, there is no reason to think that such maximum exists. In that case the question is following: why for every positive integers $m$ and $x$ there exists a positive integer $n$ such that the number $n^m+m^n$ has more than $x$ distinct prime divisors?","['number-theory', 'divisibility', 'elementary-number-theory']"
1449726,"$\int_X g \, d\mu =\int_0^\infty\mu(x:g(x)>t) \, dt$ [duplicate]","This question already has an answer here : Show that $\int|f(x)|dx=\int_0^\infty m(E_\alpha)d\alpha$ (1 answer) Closed 5 years ago . I've been stuck on this prelim problem for a while. I'm not sure how to start. I tried playing around with simple functions, but I can't relate $\psi(t)$ to $g$. Let $g:X\to[0,\infty)$ be a measurable function and $\psi(t)=\mu\{x
\in X : g(x) > t\})$. Prove that
  $$\int_X\!g\,\mathrm{d}\mu=\int_0^\infty\!\psi(t)\,\mathrm{d}t.$$","['real-analysis', 'measure-theory']"
1449739,How do I solve $\lim_{x \to 0} \frac{\sqrt{1+x}-\sqrt{1-x^2}}{\sqrt{1+x}-1}$ indeterminate limit without the L'hospital rule?,I've been trying to solve this limit without L'Hospital's rule because I don't know how to use derivates yet. So I tried rationalizing the denominator and numerator but it didn't work. $\lim_{x \to 0} \frac{\sqrt{1+x}-\sqrt{1-x^2}}{\sqrt{1+x}-1}$ What is wrong with $\lim_{x \to 0} \frac{\sqrt{1+x}-\sqrt{1-x^2}-1+1}{\sqrt{1+x}-1} = \lim_{x \to 0} \frac{\sqrt{1+x}-1}{\sqrt{1+x}-1} + \lim_{x \to 0} \frac{1-\sqrt{1-x^2}}{\sqrt{1+x}-1}$ = 1 + DIV?,"['calculus', 'limits', 'continuity', 'indeterminate-forms', 'radicals']"
1449828,Autonomous exponentially stable steady-state and small non-vanishing perturbations,"My question considers if an autonomous system having a exponentially stable steady-state will continue to do so for non-vanishing small perturbations. Consider the system $\frac{d}{dt}x=f(x)+\epsilon g(x)$, with $x\in\mathbb{R^n}$, and $f,g$ continuously differentiable vector fields. Assume that the system for $\epsilon=0$ has an (not necessarily globally) exponentially stable steady-state at $x_0^{SS}$. Intuitively, I would assume that for $|\epsilon|\ll 1$, the system should also have an exponentially stable steady-state $x_\epsilon^{SS}$. My questions: (i) Does this hold, (ii) if it holds, what is the name of the theorem saying so, or where do I find it? Note: I am talking about non-vanishing perturbations, i.e. $g(x_0^{SS})\neq 0$, implying in general that $x_\epsilon^{SS}\neq x_0^{SS}$, if $x_\epsilon^{SS}$ exists (what I don't know). What I tried: (1) I read the corresponding chapters in Khalil's ""Nonlinear systems"". There, it seems to be always assumed that $g$ depends on the time $t$. Consequently, I only found theorems saying that one can bound the difference: $\|x_\epsilon(t)-x_0(t)\|<b$ if $|\epsilon|\ll 1$, but not that the system has still a steady state (it could e.g. oscillate). My question seems to be easier, maybe too easy. (2) I found the concept of structural stability, and I understand it such that the system is structurally stable if $\epsilon=0$ is not a bifurcation point. Structural stability seems to imply that the system with $|\epsilon|\ll 1$ will still have a stable SS, which is what I want. But I couldn't connect exponential stability with structural stability. Again, everything I found did only concentrate on (for me) too general cases.","['stability-theory', 'ordinary-differential-equations', 'perturbation-theory']"
1449830,Differential Equations: Jordan Form of a Matrix,"I am using Lawrence Perko's book Differential Equations and Dynamical Systems , for my Differential Equations course. At the moment we are going over Jordan Forms of a linear system $x^{'}(t) = Ax$, where A is an $n\times n$ matrix. The solution of the system is $x(t) = e^{At}x_0 = Pe^{Bt}P^{-1}x_0$. For the purpose of this problem, we are considering two elementary Jordan blocks. \begin{align}
B_1 & = \begin{bmatrix}
          \lambda & 1 & 0 & \dots & 0\\
          0 & \lambda & 1 & \dots & 0\\
          \vdots & & \ddots\\
          0 & \dots & & \lambda & 1\\
          0 & \dots & & 0 & \lambda
         \end{bmatrix} 
& 
B_2 & =  \begin{bmatrix}
D & I_2 & 0 & \dots & 0\\
          0 & D& I_2 & \dots & 0\\
          \vdots & & \ddots\\
          0 & \dots & & D& I_2\\
          0 & \dots & & 0 & D
         \end{bmatrix} 
\end{align} 1st Elementary case is where we have $\lambda$ to be one of the real eigenvalues of some matrix $A$. \ 2nd Elementary case is where consider $\lambda$ is a complex number $a+ib$ with \begin{align}
D & = \begin{bmatrix}
          a & -b\\
          b & a
         \end{bmatrix} 
& 
I & =  \begin{bmatrix}
1 & 0\\
0 & 1
         \end{bmatrix} 
& \text{and }& &
0 & = \begin{bmatrix}
0 & 0\\ 0 & 0 
\end{bmatrix}
\end{align} Here is my question: Suppose that the elementary blocks $B$ in the Jordan form of the matrix $A$, given by $B_1$ or $B_2$, have no ones or $I_2$ blocks off the diagonal respectively. Show that if all of the eigenvalues of $A$ have nonpositive real parts, then for each $x_0\in\mathbb{R}^n$ there is a positive constant $M$ such that $|x(t)|\leq M$ for all $t\geq 0$. Now since we know for a fact that the real parts of all eigenvalues $\lambda_i$ are negative or zero, then every $y_i = e^{\lambda t}\rightarrow 0$ or $y_i = e^{\lambda t}\rightarrow 1$ as $t\rightarrow \infty$ (implying the system is stable or centered). Since we also don't have the ones and $I_2$ (for each respective case), we have matrix $A$ to be semisimple. Focusing on the first case. Since we are looking to prove the norm of our solution is less than some constant $M$ for all $t\geq 0$. We have by the properties of norm operators on a linear transformation \begin{align}
|x(t)| = &|e^{At}x_0|\leq ||e^{At}||\cdot |x_{0}| &=& ||Pe^{Bt}P^{-1}||\cdot|x_{0}|\\
& & \leq & ||P||\cdot ||e^{Bt}||\cdot||P^{-1}||\cdot |x_{0}|\\
& & \leq & ||P||\cdot ||e^{Bt}||\cdot\frac{1}{||P||}\cdot |x_{0}|\\
& & \leq & ||e^{Bt}||\cdot|x_{0}|\\
& & \leq & e^{||B||\cdot|t|}\cdot|x_{0}|\\
\end{align} Since the initial condition $x_0$ is a constant vector, bounded by some value $M$, and $||B||=\max_{|x|\leq 1}|T(x)| = 0$. Thus $e^{||B|||t|}x_0\leq e^{0}\cdot M = $ M. Am I on the right track? I would assume The second case follows a similar procedure. Is there anything I may have incorrectly? Please let me know. Thank You for you time. I appreciate any feedback, comments, or suggestions you may have. Thank you in advance and have a wonderful day.","['jordan-normal-form', 'linear-algebra', 'ordinary-differential-equations', 'normed-spaces']"
1449843,marginal density without a joint density given,"Let X and Y have a joint uniform distribution on the region described by 0≤y≤1-$x^2$; -1≤x≤1. Find E[X] and E[Y] What I've tried The graph will look like this. I know i need to find the marginal densities, and here's what i've tried $f_X(x)$=$\int_{0}^{1-x^2}f(x,y)dy$ E[X]=$\int_{-1}^{1}$$xf_X(x)dx$ $f_Y(y)$=$\int_{-1}^{1}f(x,y)dx$ E[Y]=$\int_{0}^{1-x^2}$$yf_Y(y)dy$ however when I plug in $1-x^2$ as the density the answers for the expected values come out wrong. I'm using this because I assume the density to be used should be $y=1-x^2; -1≤x≤1$","['probability', 'statistics']"
1449874,Is it possible to describe the Collatz function in one formula?,"This is related to Collatz sequence, which is that
$$C(n) = \begin{cases} n/2 &\text{if } n \equiv 0 \pmod{2}\\ 3n+1 & \text{if } n\equiv 1 \pmod{2} .\end{cases}$$ Is it possible to describe the Collatz function in one formula? (without modular conditions)","['collatz-conjecture', 'elementary-number-theory', 'functions']"
1449907,How to find the maximum and minimum value of $2^{\sin x}+2^{\cos x}$,"My try: Let $y$ =  $2^{\sin x}+2^{\cos x}$ Applying AM GM inequality I get 
$y$ $> 2.2^{(\sin x+\cos x)/2}$. 
Now, the highest value of R.H.S is $2^{\frac{\left(2+\sqrt{2}\right)}{2}}$. Should this mean that $y$ is always greater than $2^{\frac{ \left ( 2+\sqrt{2}\right ) }{2}}$?
But this is not true (we can see in the graph). Calculus method:
$dy/dx$ = $\ln\left(2\right){\cdot}{2}^{\sin\left(x\right)}\cos\left(x\right){-\ln\left(2\right){\cdot}{2}^{\cos\left(x\right)}\sin\left(x\right)}$ When $dy/dx$ =0, $\tan x = 2^{\sin x- \cos x}$ and I am stuck here. https://www.desmos.com/calculator/p3zfvkq2mn","['calculus', 'trigonometry']"
1449925,Tensor varieties?,"I read somewhere that the space of rank-one tensors, known as the Segre variety, defined by
$$ Seg: \mathbb{P}V_1 \times \cdots \times \mathbb{P}V_n \rightarrow \mathbb{P}(V_1 \otimes \cdots \otimes V_n)$$
$$([v_1],\ldots,[v_n]) \mapsto [v_1 \otimes \cdots \otimes v_n] $$
is a variety. This means that it should be the zero locus of some polynomials. But how does one plug tensors into polynomials?","['algebraic-geometry', 'tensors']"
1449935,cosine of fraction of an angle in terms of the cartesian components,"Given, $\cos\theta=\frac{x}{\sqrt{x^2+y^2}}$, how can you write 
$\cos\frac{\theta}{n}$ (n an integer for simplicity) 
in terms of x and y? 
For example, one may say
$\cos\frac{\theta}{n}=?\frac{x}{\sqrt{x^2+(y/n)^2}}$","['angle', 'polar-coordinates', 'trigonometry']"
1449946,"Permutation: Distribute 10 distinct items in 3 boxes: one box contain odd number, one box even number object , and all boxes at least one item.","I wish to distribute $10$ distinct toys to my children $A, B$ and $C$ . Each child must get at least one toy, but $A$ must receive an even number of toys, while $C$ must receive an odd number. How many ways can I go about my distribution? It's from an exam question. I had stumbled upon it doing my revision, but I still couldn't figure out how to go about solving it.","['combinatorics', 'permutations']"
1449969,How many way to arrange seven men on ten chairs?,"We have $7$ men and $10$ seats, in how many different way is possible to arrange the $7$ man on the chairs under the condition that no two empty chairs are adiacent? This is my solution: The total amount of permutations without the condition is: $$10!$$ Just permute all, this will include adjacent and not adjacent chairs without distinction. No i will remove some permutation in order to fullfill the condition! If i consider all the three seats as a single entity, and remove them from my count i have: $$10!-8!$$ Seven men plus one big chair (the tree chairs as a single entity) Now I should remove all the paired (two chairs) chairs from my count, i must be sure that the third chair is not adjacent to the pair, to account for this situation i must consider the following cases: The pair of chairs is at the extreme border of the row The pair of chairs is somewhere in the middle of the row In the first case the amount of permutation allowed is: $$2{3 \choose 2}{7 \choose 1}7!$$ Two border, a group of $2$ chairs from the $3$ possible then one boy from the $7$ available and finally the other boys and the chair permuted. For the second case, i need to put $2$ boys near the chair,so: $$7{3 \choose 2}{7 \choose 2}6!$$ Where $7$ are the possible position for the group of chairs plus the boys. So the final count is: $$10!-8!-2{3 \choose 2}{7 \choose 1}7!-7{3 \choose 2}{7 \choose 2}6!$$ Which is $2318316$. Does this make any sense? Thank you.",['combinatorics']
1450005,Derive the Trigonometric Functions,"How can the Sine Function be derived? Given $\angle{A}$ as input, derive a function that would give $\frac{a}{c}$ as output. $$$$ How can the Cosine Function be derived? Given $\angle{A}$ as input, derive a function that would give $\frac{b}{c}$ as output. $$$$ How can the Tangent Function be derived? Given $\angle{A}$ as input, derive a function that would give $\frac{a}{b}$ as output. $$$$ I am looking for either of the following: The historical way to calculate the trigonometric functions as well as a proof that it works for a right-angled triangle Any other way to calculate the trigonometric functions as well as a proof that it works for a right-angled triangle In other words, an algorithm on its own would not be enough, you have to prove that it works for a right-angled triangle.
$$$$ Side note: I am aware of the Taylor-series expansion of the trigonometric functions. $$$$ I am also aware of the exponential definition of the trigonometric functions.$$$$ $$$$ If you could geometrically prove how any of these trigonometric identities work for a right-angled triangle, that would answer my question as well. Another side note I do not believe this question belongs in The History of Science and Mathematics -Stack Exchange. That forum focuses on where and when certain Mathematical concepts were created, which is not my question.",['trigonometry']
1450097,Geometrical interpretations of SVD,"I'm a bit confused by the various geometrical/visual interpretations of SVD or better I'm wondering how to reconcile them. Transformations : As explained here , the 3 matrices produced by the SVD can be interpreted as rotation, scaling, rotation. Projection on an axis (dimensionality reduction): As explained here , SVD enables to capture the most of the variance in the data by selecting the right orthogonal axes. My (very naive) question is: are these 2 interpretations related visually or not at all, and if yes, how?  Or are they 2 unrelated applications of SVD? As far as I understand, the transformations of the matrices (1) can be applied to anything/any object, so it's not about the data mentioned in (2) so I would say it's not related but I may be wrong (because in (2) we also talk about rotations...). Please note that I'm looking for the intuition with as few math as possible (I don't know much linear algebra as you may have guessed).
Many thanks.","['svd', 'geometry', 'linear-algebra', 'intuition']"
1450100,Bounded sequence in a Banach space,"Let $(X,||\cdot||)$ be a Banach space in $\mathbb{K}$ and $(x_n)$ a sequence in $X$, and let $f$ be any function in $X^*$ (the dual space of $X$) such that the sequence $(f(x_n))$ is bounded. I am trying to prove that in this case, the sequence $(||x_n||_X)$ is bounded. I have managed to prove than for a given integer $n$, $||x_n||_X=||\psi_{x_n} ||$, where $\psi$ is a function defined on $X^*$ with values in $\mathbb{K}$ defined by $\psi_{x_n}(f)=f(x_n)$. So if the sequence $(f(x_n))$ is bounded, then so is 
$(\psi_{x_n}(f))$. Can we conclude that this implies that $||\psi_{x_n} ||$ (and therefore $||x_n||_X$) is bounded? My intuition tells me it does, as $||\psi_{x_n} ||=\sup\limits_{f\neq0}\{\frac{||\psi_{x_n}(f)||}{||f||}\}$, but I am not sure since $\psi_{x_n}$ is a function while $(\psi_{x_n})$ is a sequence (of functions..).","['banach-spaces', 'complex-analysis', 'real-analysis', 'functional-analysis']"
1450153,$\mathbb{P}$ divisible into infinitely many subsets $S_i$ of consecutive primes where $\sum S_i = \text{prime}$?,"Let $\mathbb{P}$ be the set of all primes, $p_n$ the $n^{\text{th}}$ prime and $S_i$ a subset of $\mathbb{P}$, consisting of the smallest amount of consecutive primes for which $\sum S_i = \text{prime}$. Rule 1: if the last prime of $S_i$ is $p_n$, then the first prime of $S_{i+1}$  must be $p_{n+1}$. Rule 2: $|S_i| \ge 2 $ If we start with the first primes we get 
$$S_1 = \{ 2,3 \} \quad \to \quad \sum S_1 = 5$$ followed by $$S_2 = \{ 5,7,11 \} \quad \to \quad \sum S_2 = 23$$ 
$$S_3 = \{ 13,17,19, 23, 29 \} \quad \to \quad \sum S_3 = 101$$ 
$$S_4 = \{ 31,37,41 \} \quad \to \quad \sum S_4 = 109$$
$$\dots$$ After calculating the subsets for the first $10^4$ primes, I'm inclined to say that there are infinitely many of these subsets. Is there any way we can prove this?","['prime-numbers', 'number-theory']"
1450174,If all $L^p$ norms are bounded then the $L^\infty$ is bounded,"Suppose that $||f||_p \le K$ for all $1 \le p <\infty$ for some $K>0$.
How to show that the essential supremum exists and bounded by $K$ that i s$||f||_\infty \le K$? I know how to prove that if $f \in L^\infty$ then 
\begin{align}
lim_{p \to \infty} ||f||_p=||f||_\infty
\end{align}
but this already assume that $f \in L^\infty$ in this question we have to show that $f$ has an essential supremum. To be more precise I don't think I can use a technique when I define
\begin{align}
A_\epsilon =\{ x | \ |f(x)|>||f||_{\infty}-\epsilon \}
\end{align} I feel like here we have to use some converges theorem.
Thanks for any help","['lp-spaces', 'functional-analysis']"
1450186,Show the probability of liminfA is 1,"Consider a random set $S$ constructed as follows.
    For any $n>2$, $\mathbb p(n\in S) = 1/\log n$, all independently. Show that $S$ almost surely satisfies the twin prime property: there are
    infinitely many pairs $n,n+1\in S$. Show that $S$ almost surely for all but finitely many $n$ there is a    solution to $n=x+y$ with $x,y\in S$. For the first part, I have shown that for $A_{2n}=\{2n,2n+1 \in S\}$, $A_{2n}$ are independent. $\mathbb P(A_{2n})=\frac{1}{log(2n)log(2n+1)}$. By comparing with $\frac{1}{nlog(n)}$, $\sum\frac{1}{nlogn}$ diverges then $\sum\frac{1}{log(2n)log(2n+1)}=\infty$. Thus we have $\mathbb P(A_{2n},i.o.)=1$ by Borel_Cantelli. Since $A_{2n}$ is a subsequence of events of $A_n=\{n,n+1\in S\}$, $A_n$ also happens infinitely often. For the second part. I feel it's to show the probability of liminf is 1, but I wonder what to do next. Can someone give me a hint?","['probability-theory', 'borel-cantelli-lemmas', 'prime-numbers', 'independence', 'limsup-and-liminf']"
1450190,Justifying differentiation of infinite product,"Let $(z_n)_{n\in\mathbb{Z}}$ be a sequence of complex numbers s.t. the product $P(z):=\prod_{n=1}^{\infty}{\left(1-\frac{z}{z_{-n}}\right)\left(1-\frac{z}{z_{n}}\right)}$ is absolutely convergent for every $z\in\mathbb{C}$, and hence defines an entire function with zeros at every $z_k$. Is there some nice way to justify $\frac{\mathrm{d}}{\mathrm{d} z}P(z_k)=\frac{-1}{z_k}\prod_{|n|\geq1, n\neq k}{\left(1-\frac{z_k}{z_{n}}\right)}$? I guess one is not allowed to simply use the product rule for differentiation here?","['analysis', 'sequences-and-series', 'calculus', 'complex-analysis']"
1450220,Proofs regarding measure of intersection of sets,"Let $(X,\mathcal{A},\mu)$ be a measure space, let $A_1,A_2,A_3,\ldots\in \mathcal{A}$, and let
$\sum_{j=1}^{\infty}\mu(A_j)<\infty$. The task is to prove the following: 1) $\lim_{n\rightarrow \infty} \mu \Big( \bigcap_{j=1}^n A_j \Big)=0$ and 2) $\mu \Big( \bigcap_{j=1}^\infty A_j \Big)=0$ I don't see a fundamental difference between these two and I'm wondering if that means I've misunderstood something.
My approach, in both cases, would be to argue that since the intersection is between an infinite amount (or approaching an infinite amount) of sets in the sigma algebra, that must mean that at some point a set will meet its complement, and therefore the intersection must be the empty set whose measure is 0. Is this the right way to go about it? Or have I missed something? In what ways, if any, should the proofs differ? Thanks in advance! edit: I would be very grateful if your answers would contain explanations to why my initial approach can/can't be done, and not merely proofs of the above","['elementary-set-theory', 'real-analysis', 'measure-theory']"
1450276,Number Theory Positive Divisor Problems,"I'm in number theory and I've been assigned these problems for homework. I've searched throughout the relevant section of the book but I can't seem to find anything that relates to solving these problems. Describe $n\in \mathbb{N}$ when the number of positive divisors of $n$ is 105. Which positive integers $n<100$ have the greatest number of positive divisors? Any help at all is appreciated, thanks. Edit: Solved #1: Note that if $n=\prod^{k}_{i=1}p_i^{c_i}$, then $\prod^{k}_{i=1}(1+c_i)$ is the number of positive divisors of $n$, since any $p_i$ can occur up to $c_i$ times, or not at all. If $n$ has 105 positive divisors, then $105=\prod^k_{i=1}(1+c_i)$. Note that $105=3\cdot 5\cdot 7$. So, $105=(1+2)(1+4)(1+6)\implies n=p_1^2\cdot p_2^4\cdot p_3^6$.","['prime-factorization', 'prime-numbers', 'number-theory', 'elementary-number-theory', 'divisibility']"
1450285,"Show that if $p$ is a prime number, and $G$ is a transitive subgroup of $S_p$, then $G$ must contain a cycle of length $p$.","Note that a subgroup $G$ of $S_n$ is called a transitive subgroup of $S_n$ if it acts transitively on the set $\{1,2,...,n\}$ . I understand that for any $x$ , $y$ $\in \{1,2,...,p\}$ , there exists an element $g \in G$ such that $g x=y$ , but I do not know how to use this to demonstrate the existence of a $p$ -cycle. This comes in a section of text about group actions, which is before discussion of Sylow Theorems, so I presume the proof will not require them. Any help is very appreciated.","['abstract-algebra', 'group-theory', 'symmetric-groups', 'group-actions']"
1450307,Is there a way to decide whether a differential equation is solvable or not?,"Martin Davis, Yuri Matiyasevich, Hilary Putnam and Julia Robinson had negatively settled Hilbert 10th problem, I wonder if there is an analog result to the differential equations ?","['computability', 'logic', 'ordinary-differential-equations']"
1450318,Show $C(\mathbb{R})$ is not separable.,"The hint to do so is to show that $C(\mathbb{R})$ has an uncountable subset where the elements are very far apart. Here $C(\mathbb{R})$ has norm $$||f||_{C(\mathbb{R})} = \sup_{x \in \mathbb{R}}|f(x)|$$ My idea is as follows: Define the set $$\Lambda := \{f \in C(\mathbb{R}) : f(n) = n \, \text{or} \, \, f(n) = 0 \, \text{for each} \, n \in \mathbb{N}\}$$ Let $\Omega \subset \Lambda$ be the subset of piecewise linear functions. Then $\Omega$ is uncountable, since it is equivalent to the set of all binary sequences. Moreover, if $f,g \in \Omega$, then $$||f-g||_{C(\mathbb{R})} \geq 1.$$ My other idea was to take $f(x) = 1-2|x|$ and shift it left and right, copy and paste it, and define the set of all possible shifts and pastes. In this case too, the difference between elements is $1$. Say, functions like Are either of these viable sets of functions to use? If so, I'm a bit confused as to how this implies the set is not countable. Is it because any countable subset has to be far from some of these functions?","['analysis', 'functional-analysis', 'real-analysis', 'general-topology']"
1450380,Is my algebraic space a scheme?,"Consider $\mathcal{M}_{1,1}$ over $\bar{\mathbb{Q}}$. I have an algebraic stack $\mathcal{M}$ finite etale over $\mathcal{M}_{1,1}$ I can prove that it is an algebraic space (essentially because all its ""hidden fundamental groups"" are trivial - ie, all geometric points of $\mathcal{M}$ have trivial 2-automorphism groups) Must it be a scheme?","['algebraic-geometry', 'algebraic-stacks']"
1450401,About Sylow's 2nd and 3rd theorems,"I just do not understand one step of proof of Sylow's second theorem given in my textbook Basic Abstract Algebra by P. B Bhattacharya. The step is, as K is a Sylow p-subgroup of G, hence $gcd(|G/N(K)|, p) = 1$. How it comes? Here, the notation $N(K)$ represent the normalizer of $K$ and $| |$ is used for order.",['abstract-algebra']
1450413,How to sum two subsets [duplicate],"This question already has an answer here : Addition of two subspaces [closed] (1 answer) Closed 8 years ago . This is an example from Linear Algebra Done Right by Axler: Suppose that $U = \{(x, x, y, y) \in F^4 : x, y \in F\}$ and $W = \{(x, x, x, y) \in F^4 : x, y \in F\}$ Then $U + W = \{(x, x, y, z) \in F^4 : x, y, z \in F\}$ I don't understand how $U$ and $W$ sum to that. Can someone explain how this conclusion came about? Thank you!","['elementary-set-theory', 'vector-spaces', 'linear-algebra', 'discrete-mathematics']"
1450424,Find the side length of triangle ABC;,"Let ABC be an equilateral triangle, and let P be a point in the interior of the triangle. Given that PA = 3, PB = 4, and PC = 5, find the side length of ABC. Relatively simple problem I think, but I can't quite get the right way to solve this. Please nothing fancy shmancy involving graphs or who-knows-what. I should be able to solve this with pretty basic trigonometry. a few thoughts that may be wrong, but people on here ask me to provide my own thoughts first: At first glance I thought Law of Cosines might help, but I didn't go much places with it. I haven't officially learned trig, so I'm not much good at this.",['trigonometry']
1450472,Prove that $2^n+(-1)^{n+1}$ is divisible by 3.,"Prove that $2^n+(-1)^{n+1}$ is divisible by 3 for $n\in\mathbb{N}$. My attempt: For $n=1$: $2^1+(-1)^2 = 2 + 1 = 3, 3 |3$ We assume that $3|(2^n+(-1)^{n+1})$ Then for $n+1$: $2^{n+1} + (-1)^{n+2} = 2\cdot 2^n -(-1)^{n+1}$ I am trying to show that for $n+1$, the expression is a constant multiple of the case for $n$ plus or minus a multiple of $3$. However, the minus sine I pulled out of the alternating term is tripping me up. Am I going about this the right way?","['discrete-mathematics', 'divisibility', 'elementary-number-theory']"
1450473,I have a bag containing N coins. What is the probability that I have a round dollar amount?,"In my country we have \$0.10, \$0.20, \$0.50, \$1, and \$2 coins. 
If I were to pour a bag of coins out on the table what would be the probability that I could buy a heap of \$1 snacks without needing any change? Does this change if the bag doesn't contain any whole dollar value coins? I'm fairly sure the that  $P=0.1$ for very large values of $N$ (as there is 10 possible cent values). I'd like to be able to prove this and be able to see how the probability changes with $N$, but I cant figure out a rule for the entire series & larger values of $N$. I've written a little Python simulation to test $N$ values $0$ through $50$ and I'll edit with the results of that when it finishes. EDIT: Results of my script seem to confirm my thought: http://pastebin.com/cD8PeuwT",['probability']
1450485,A 100-gallon tank intiially contains 100 gallons of sugar water at a concentration of .25lbs of sugar/gallon.,"A 100-gallon tank initially contains 100 gallons of sugar water at a concentration of .25lbs of sugar/gallon. 
Suppose that sugar is added to the tank at a rate of p pounds/min. Suppose that sugar water is removed at a rate of 1gallon/min and that the water in the tank is well mixed. 
What value of P should we pick so that  that when 5 gallons of sugar solution is left in the tank the concentration is .5lbs of sugar/gallon? I have that S(t)=k(100-t)-P(ln(100-t)(100-t)) So when t=0, I have 100k-100Pln(100)=25 and
   when t=95, I have 5k-5Pln(5)=2.5 I have tried solving this system of equation but even my ODE mind cannot wrap around the solution. I have that P= 1/(4ln20), am I on the right path?","['solution-verification', 'applications', 'ordinary-differential-equations']"
1450491,How to make $\log x^a = a\log x$ work using multivalued complex approach,"The following identity holds for all $a$ and $x$ using the principal branch:
$$
    \log x^a = a\log x
        + 2\pi i \left\lfloor \pi-\Im (a\log x) \over 2\pi \right\rfloor
$$
e.g. for $a=2$, $x=-1$: LHS = $\log (-1)^2 = \log 1 = 0$ RHS =
$2\log(-1)+ 2\pi i \left\lfloor \pi-\Im (2\log (-1)) \over 2\pi \right\rfloor$
=$2\pi i+ 2\pi i \left\lfloor \pi-\Im (2\pi i) \over 2\pi \right\rfloor = 2\pi i - 2\pi i = 0$ Everything is single valued and there is no problem. How can I perform the same calculation using multivalued logarithms? In other words, I want to use the (multivalued) identity:
$$\log x^a = a\log x$$
for $a=2$, $x=-1$. I pick the same branch for both LHS and RHS, let's pick the principal branch (so that we can reuse the values calculated above), and then I add the $2\pi i n$ term for each logarithm and get: LHS = $\log (-1)^2 + 2\pi i n = 2\pi i n$ RHS = $2\log(-1) + 2\pi i \left\lfloor \pi-\Im (2\log (-1)) \over 2\pi \right\rfloor + 2\cdot 2\pi i m = 4\pi i m$ And we can see that LHS is not equal to RHS, otherwise $m$ would have to be half-integer. Where did I make the mistake? How can I make LHS equal to RHS using the multivalued approach?","['complex-analysis', 'complex-numbers']"
1450492,How to calculate $ \lim_{n\to \infty}\left(\sum_{k=1}^{n}\frac{1}{3k+1}-\frac{\ln n}{3}\right)$,When I learned harmonic series. I met this limit. $\displaystyle \lim_{n\to \infty}\left(\sum_{k=0}^{n}\frac{1}{3k+1}-\frac{\ln n}{3}\right)=\frac{\gamma}{3}+\frac{\sqrt3\pi}{18}+\frac{\ln3}{2}$ $\gamma$ is EulerGamma. But i don't know how to prove it.And naturally i got: $\displaystyle \lim_{n\to \infty}\left(\sum_{k=0}^{n}\frac{1}{pk+1}-\frac{\ln n}{p}\right)\qquad p\in N$ Could someone help me to solve the two limits?,"['analysis', 'sequences-and-series', 'calculus', 'limits']"
1450494,"$C([a,b])$ is separable","We will show that $\mathbb{Q}[x]$ is dense in $C([a,b]).$ This follows from the Weierstrass Approximation Theorem, since given any $f \in C([a,b])$, there exists a sequence of polynomials $$\{p_n\}_{n \in \mathbb{N}} \xrightarrow{u} f.$$ Now, label the real coefficients of $p_n$ as $\{a_0,a_1, \ldots a_n\}.$ Take sequences of rationals $\{q_{i_k} \}_{k \in \mathbb{N}} \to a_i$ with $q_{i_k} \leq a_i$. Let $r_{n,k} \in \mathbb{Q}[x]$ be the polynomial with these coefficents. Clearly then $$\{r_{n,k}\}_{k \in \mathbb{N}} \xrightarrow{u} p_n$$ for each $p_n$ since given $\epsilon >0$ and $K \in \mathbb{N}$ large enough, $$||r_{n,K} - p_n||_{C([a,b])} \leq \epsilon \sum_{i=1}^{n}|x_0^i|$$ for some $x_0 \in [a,b]$ since $r_{n,K} - p_n$ is continuous on the compact set $[a,b]$ at attains a maximum at, say, $x_0$. This $x_0$ works for all $k \geq K$ since the rationals converge to $a_i$ from the left.   This then implies that $$\lim_{n \to \infty} \lim_{ k \to \infty} p_{n,k}  = f,$$ i.e. 
$$\{r_{n,k}\}_{n \in \mathbb{N}, \, k \in \mathbb{N}} \xrightarrow{u} f$$ implying $C([a,b])$ is separable. Now my question concerns the bit about the $x_0$. Is it fair to say that this $x_0$ is the same for all polynomials if the rationals converge on the left or right (the point being from one side only so that the signs never change)? Is this even necessary? Any other details I need add?","['analysis', 'proof-verification', 'real-analysis', 'functional-analysis']"
1450497,"Conditions that topologies must have if (only if) the condition ""$G_\delta$ iff (open or closed)"" holds?","Consider the class of topological spaces $\langle X,\mathcal T\rangle$ such that the following are equivalent for $A\subseteq X$: $A$ is a $G_\delta$ set with respect to $\mathcal T$ $A\in\mathcal T$ or $X\smallsetminus A\in\mathcal T$ Open sets, of course, are always $G_\delta$. So, equivalently, we are considering the topological spaces such that closed sets are $G_\delta$ and non-open $G_\delta$ sets are closed. Clearly, not all spaces satisfy this equivalence. For example, with respect to the typical topology, $\Bbb R$ has (many!) $G_\delta$ subsets that are neither open nor closed. On the other hand, with respect to the order topology, the set $\omega_1\cup\{\omega_1\}$ has $\{\omega_1\}$ as a closed subset that is not $G_\delta$ (unless, of course, $\omega_1$ is a countable union of countable sets, as may happen in models of $\mathsf{ZF}$). On the other hand, there are certainly spaces that do satisfy the equivalence, with the discrete and trivial topologies on any set giving us two (not-very-enlightening) examples. I wonder, then, has the described class of topological spaces been studied in much depth? If so, I am curious about the following: Are there any non-trivial topologies that make such a space? Is there any common nomenclature for such spaces? Are there sets of conditions on a topology that imply (or are implied by) a space being part of the class of such spaces? Furthermore, the members of this class may clearly vary from model to model of $\mathsf{ZF},$ so is there any such set of conditions such that one implication or the other (or both) is equivalent to a Choice principle? Edit : The examples so far (aside from indiscrete spaces on sets with at least two points) have the property that every subset of the underlying set is open or closed. Is it possible that all such space are indiscrete or have all subsets open or closed? Another thing that is readily apparent (now that I'm a little more awake) is that $\langle X,\mathcal T\rangle$ has the desired property if and only if $$\sigma(\mathcal T)=\mathcal T\cup\{X\setminus U:U\in\mathcal T\},$$ where $\sigma(\mathcal T)$ is the (Borel) $\sigma$-algebra (on $X$) generated by $\mathcal T.$","['terminology', 'axiom-of-choice', 'general-topology', 'reference-request', 'set-theory']"
1450519,prove by contradiction:gcd and divisibility,"Let's say there are $3$ natural numbers $a,b$ and $c$.
$a|(b+c)$ and $\text{gcd}(b,c) = 1$,prove that $\text{gcd}(a,b)=1$ I know that I can prove this statement by contradiction. Let's suppose $\text{gcd}(a,b) = d$ with $d>1$, and $d|a$, $d|b$. But how can I get $\text{gcd}(b,c)>1$? And how to approach $\text{gcd}(a,d)$ can not be greater than $1$ therefore it must be $1$? Thanks so much for the help!","['induction', 'discrete-mathematics']"
1450626,Is it true that $E[\|X_{n+1}-E[X_{n+1}|\sigma(X_n)]\|^p] \leq E[\|X_{n+1}\|^p]$ when $p\ge2$?,"I have seen in a paper to use (this is my understanding, I may be wrong) the following for $p \geq 2$:
$$
E[\|X_{n+1}-E[X_{n+1}|\sigma(X_n)]\|^p] \leq E[\|X_{n+1}\|^p]
$$ 
where the norm is Euclidean norm and $\{X_n\}$ is a Markov process. I sense Hilbert space projection idea here but that works only for $p =2$.","['probability-theory', 'conditional-expectation']"
1450634,A Confusion Regarding the Intrinsic Definition of CW Complexes,"$\newcommand{\mc}{\mathcal} \newcommand{\set}[1]{\{{#1}\}} \DeclareMathOperator{\im}{im} \newcommand{\disun}{\amalg} \newcommand{\vp}{\varphi}$ Preliminary Material. Definition. An $n$- cell is a topological space homeomorphic to the open ball $B^n$.
A cell is a space which is an $n$-cell for some $n$. Definition. Let $X$ be a topological space.
A cell decomposition of $X$ is a collection $\mc E=\set{e_\alpha}_{\alpha\in J}$ of disjoint subspaces $e_\alpha$ of $X$ such that each $e_\alpha$ is a cell and $X=\bigcup_{\alpha\in J}e_\alpha$. Definition. Let $X$ be a topological space and $\mc E$ be a cell decomposition of $X$.
The $n$- skeleton of $X$  is defined as the union of all the cells in $\mc E$ of dimension $n$ or lower.
The $n$-skeleton of $X$ is written as $X^n$. Definition. Let $X$ be a topological space and $\mc E$ be a cell decomposition of $X$.
Let $e$ be an $n$-cell in $\mc E$.
We say that a map $\Phi:D^n\to X$ is a characteristic map corresponding to $e$ if i) $\Phi$ maps $B^n$ homeomorphically onto $e$, and ii) $\Phi(S^{n-1})\subseteq X^{n-1}$. Definition. Let $X$ be a Hausdorff topological space and $\mc E$ be a cell decomposition of $X$.
We say that $\mc E$ is a CW-complex structure on $X$ if the following axioms are satisfied: (CM) Each $e\in \mc E$ admits a characteristic map. (CF) For each cell $e\in \mc E$, the closure of $e$ intersects only a finite number of cells in $\mc E$. (WT) A subset $A$  of $X$ is closed in $X$ if and only if $A\cap \bar e$ is closed in $X$ for each $e\in \mc E$. Theorem 1. Let $X$ be a Hausdorff space and $\mc E$ be a cell decomposition of $X$ satisfying the (CM) axiom.
Then for each $n$-cell $e\in \mc E$, we have $\bar e=\Phi_e(D^n)$, where $\Phi_e$ is any characteristic map corresponding to $e$. Proof. For any continuous map $f:A\to B$ between topological space $A$ and $B$, we have $f(\bar S)\subseteq \overline{f(S)}$ for all subspaces $S$ of $A$.
Using this, we get $\Phi_e(D^n)\subseteq \bar e$.
On the other hand, since $D^n$ is compact, we have $\Phi_e(D^n)$ is a compact subspace of $X$.
Since $X$ is Hausdorff, $\Phi_e(D^n)$ is closed in $X$.
But since $e\subseteq \Phi_e(D^n)$, we must have $\bar e\subseteq \Phi_e(D^n)$.
So we conclude that $\bar e=\Phi_e(D^n)$. Theorem 2. (Topology of CW Complexes.)
Let $X$ be a Hausdorff topological space and $\mc E$ be a cell decomposition on $X$ satisfying the (CM) and the (WT) axiom.
Let $\mc F$ be the set of characteristic maps, one for each cell in $\mc E$.
Then the topology on $X$ is final with respect to $\mc F$. Proof. Write $\mc F=\set{\Phi_\alpha: D_\alpha\to X}_{\alpha\in J}$, where each $D_\alpha$ is a closed unit ball in some Euclidean space and each $\Phi_\alpha:D_\alpha\to X$ is a characteristic map corresponding to some cell in $\mc E$, while insisting that $\mc F$ has exactly one characteristic map for any given cell in $\mc E$. Let $F$ be a subspace of $X$.
We have $$
\begin{array}{rcl}
F \text{ is closed in } X & \stackrel{(1)}{\iff} & F\cap \im(\Phi_\alpha) \text{ is closed in } X \text{ for all } \alpha\in J\\
& \stackrel{(2)}{\iff} & F\cap \im(\Phi_\alpha) \text{ is closed in } \im(\Phi_\alpha) \text{ for all } \alpha\in J\\
&\stackrel{(3)}{\iff} & \Phi_\alpha^{-1}(F\cap \im(\Phi_\alpha))\text{ is closed in } D_\alpha \text{ for each } \alpha\in J\\
&\stackrel{(4)}{\iff} & \Phi_\alpha^{-1}(F)\cap D_\alpha \text{ is closed in } D_\alpha \text{ for each } \alpha\in J\\
&\stackrel{(5)}{\iff} & \Phi_\alpha^{-1}(F) \text{ is closed in } D_\alpha \text{ for all } \alpha\in J
\end{array}
$$
    Since $\mc E$ satisfies the (CM) axiom, (1) is justified by Theorem 1 and the (WT) axiom. To see (2), we note that if $F\cap \im(\Phi_\alpha)$ is closed in $X$, then $F\cap \im(\Phi_\alpha)$ is closed in $\im(\Phi_\alpha)$ too, for $\im(\Phi_\alpha)$ is a compact and hence closed subspace of $X$. The other direction is similar.
To get $(3)$, note that if $\Phi_\alpha^{-1}(F\cap \im(\Phi_\alpha))$ is closed in $D_\alpha$, then it is in fact a compact subspace of $D_\alpha$ because closed subspaces of compact spaces are compact.
Therefore, the image of $\Phi_\alpha^{-1}(F\cap \im(\Phi_\alpha))$ under $\Phi_\alpha$, which is nothing but $F\cap \im(\Phi_\alpha)$, is a compact and therefore closed subspace of $\im(\Phi_\alpha)$.
The steps (4) and (5) are obvious. The Main Confusion. Let $(X, \mc E)$ be a CW-complex structure on a Hausdorff space $X$.
  We want to express $X^n$ as a space formed by attaching $n$-discs to $X^{n-1}$. For each $e\in \mc E_n$, let $\Phi_e:D^n_e\to X^n$ be a characteristic map for $e$.
By the co-product property of the disjoint union, we get a map $\Phi:\disun_{e\in \mc E_n}D^n_e\to X^n$.
We write $Z=\disun_{e\in \mc E_n}D^n_e$.
Again, the maps $\Phi:Z\to X^n$ and the inclusion map $i:X^{n-1}\hookrightarrow X^n$ give a map $f:Z\disun X^{n-1}\to X^n$. For each $e\in \mc E_n$, write $\vp_e$ to denote $\Phi_e|_{S^{n-1}_e}$, that is, $\vp_e$is the restriction of $\Phi_e$ to the boundary of $D^n_e$.
Then we have a map $\vp:\disun_{e\in \mc E_n} \partial D^n_e\to X^{n-1}$ again obtained by the co-product property of disjoint union. Now the map $f$ factors bijectively through the space $Z\disun_{\vp}X^{n-1}$
giving a bijective map $\alpha:Z\disun_{\vp}X^{n-1}\to X^n$. We will show that the map $\alpha$ is a homeomorphism.
We know that the topology on $X^{n}$ is final with respect to the maps $\Phi:Z\to X^n$ and the inclusion map $i:X^{n-1}\hookrightarrow X^n$.
Thus $\alpha^{-1}$ is continuous if and only if both $\alpha^{-1}\circ i$ and $\alpha^{-1}\circ \Phi$ are continuous.
But this is evident from the commutative diagram and therefore $\alpha $is a homeomorphism. Confusion. The above working shows that no matter what were the choices of the characteristic maps $\Phi_e$ for $n$-cells in $X$, we get that $X^n$ is homeomorphic to $Z\disun_{\vp}X^{n-1}$.
  This is perplexing because two different characteristic maps for an $n$-cell may attach the boundary of the $n$-disc in different ways to $X^n$. But still we end up getting the same space (up to homeomorphism).
  I do not ""directly see"" why this should be so. Can somebody shed some light on this? That said, I am not entirely sure I my working is correct. I have not see this in any book. I just recetnly read the definition of a CW complex and thought a bit about the definition, ending up with this question. Hope somebody can settle this. Thanks.","['algebraic-topology', 'general-topology', 'cw-complexes']"
1450656,Is supremum over a compact domain of separately continuous function continuous?,"Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces, and consider the product metric space $(X\times Y,d)$ with a product metric $d$. Let $f(x,y):X\times Y\to \mathbb{R}$ be a separately continuous function. Suppose $X$: compact. Is $g(y)=\sup\limits_{x\in X}f(x,y)$ continuous? What if $Y$ is also compact? ++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++ Suppose $X$ is not compact. Then, it fails even when $f$ is (jointly) continuous.
A counter example is given http://at.yorku.ca/cgi-bin/bbqa?forum=ask_an_analyst_2005&task=show_msg&msg=4110.0001 . 
That $x$ can go as far as possible does bad. Another counter example where $X$ is not compact is Supremum of continuous functions is continuous? . Suppose $X$ and $Y$ are compact, and $f$ is (jointly) continuous. Following the argument here: How prove this $g(x)=\sup{\{f(x,y)|0\le y\le 1\}}$ is continuous on $[0,1]$ it seems to hold, using $f$ being uniformly continuous on $X\times Y$. Go back to my question. In this case, we cannot use the uniform continuity. I tried doing the following and got stuck. From the compactness of $X$ and continuity in $x$, we can take $x^*_j\in\mathrm{argmax}_x f(x,y_j)$, ($j=1,2$), and
$$
|g(y_1)-g(y_2)|\le |f(x_1^*,y_1)-f(x_1^*,y_2)|+|f(x_1^*,y_2)-f(x_2^*,y_2)|.
$$
The first term is good as $f(x_1^*,\cdot)$ is continuous, but I could not do anything with the second term, and started to think maybe this is not true.","['calculus', 'metric-spaces', 'continuity', 'real-analysis', 'multivariable-calculus']"
1450675,Is there a function to *reverse* a number,"Is there a function say $$f(x)$$ which can Reverse constant number ? For example if we have $$x=22314$$ then $$f(x)=41322$$ Please tell me if it is possible. I suspect the use of $floor$ or $ceil$ kind of functions ... This may help : This is called the Number extractor function as it extracts the $n^{\text{th}}$ digit from a number $a$: $$f(n) = \left \lfloor 10^{n-1} \cdot a \right \rfloor - 10 \left \lfloor 10^{n-2} \cdot a \right \rfloor , n \in \mathbb{Z^{+}}$$ For example if $a=\pi$ then $f(1)=3 , \space f(2)=1 , \space f(3)=4 ...$ Or if $a=32=32.\bar{00}$ then $f(1)=3 , f(2) =2 , f(3)=0 , f(4) =0 ...$ Thanks!","['ceiling-and-floor-functions', 'functions']"
1450689,Why does the magnitude of the cross-product of a and b give the area of a parallelogram spanned by a and b?,"I tried looking it up but many websites just state it without proof and without intuition.  I'm hoping to learn it a little bit better so that I don't forget how to compute the Jacobian when working with surface integrals where the divergence theorem is not applicable. If you have a good online reference instead, please feel free to provide it :-) Thanks,","['surface-integrals', 'area', 'multivariable-calculus', 'cross-product']"
1450700,Show that $X_n$ follow somewhat a CLT,"Let $X_i$ be i.i.d. $f_X(x)=\dfrac{1}{|x|^3}1_{\{|x|>1\}}$. Show that $\dfrac{\sum_{i=1}^nX_i}{\sqrt{n\log n}}\to N(0,1)$. I realized that $Var(X_i)=\infty$ and $E(X_i)=0$. I cannot apply Lindeberg or Lyapounov CLT in any way, so I tried to use characteristic functions. I observe that $$\lim_{n\to\infty}\varphi_{S_n}\left(\dfrac{t}{\sqrt{n\log n}}\right)=\exp\left[\lim_{n\to\infty}-\left (\int_1^\infty\dfrac{4n}{x^3}\sin^2 \left(\dfrac{tx}{2\sqrt{n\log n}}\right)dx\right)\right]$$ I now want to show that this limit is equal to $\exp(-t^2/2)$. How can I do that? I don't think I can apply Dominated Convergence here. So essentially the task is to prove that the integral converges to $t^2/2$ as $n\to\infty$.","['probability-theory', 'central-limit-theorem', 'probability-limit-theorems', 'independence', 'convergence-divergence']"
1450708,Limit of $x\left(e-\left(\frac{x+2}{x+1}\right)^x\right)$ when $x\to+\infty$,"Find $$\lim_{x\to\infty}x\left(e-\left(\frac{x+2}{x+1}\right)^x\right)$$ I calculated $\lim\limits_{x\to\infty}\left(\frac{x+2}{x+1}\right)^x=e$ but then the limit in question becomes $0\times \infty $ form, and further solution becomes messy. Please tell a solution without the use of series expansions because I have no knowledge of these.","['calculus', 'limits']"
1450720,What's the property of this series? Is it special? Coefficients of $\left(x\frac{d}{dx}\right)^n f(x) $,"I am think about this expression : $e^{\lambda x \frac{d}{dx}}f(x)$. Let us look at each term in the expansion of the exponential operator $e^{\lambda x \frac{d}{dx}}$,
 $$\left(x\frac{d}{dx}\right)^n f(x) $$ For example, (denote $\partial = \frac{d}{dx}$)
\begin{align*} 
  n&=1 : \quad x \partial  \\
   n&=2 : \quad x^2 \partial^2 + x\partial \\
  n&=3 : \quad x^3 \partial^3 + 3x^2\partial^2 + x\partial \\
  n&=4 : \quad x^4 \partial^4+6x^3 \partial^3 + 7x^2\partial^2 + x\partial \\
 n&=5 : \quad x^5 \partial^5+ 10x^4 \partial^4+25\ x^3 \partial^3 + 15x^2\partial^2 + x\partial \\
n&=6 : \quad x^6 \partial^6+15x^5 \partial^5+ 65x^4 \partial^4+90\ x^3 \partial^3 + 31x^2\partial^2 + x\partial \\
\end{align*} I wonder if there is a general expression for the coefficient. I have expanded it out and it seems that they are related to binomial coefficients though its kind of tedious. If there is a general expression of these coefficients, what's its properties?  Thank you very much.","['number-theory', 'binomial-coefficients', 'combinatorics']"
1450725,Lipschitz maps between Riemannian manifolds,"Let $U \subset \mathbb R^n$ and $V \subset \mathbb R^m$ be two open subsets with $U$ convex and $f: U \to V$ a $C^1$-map. Then, using the fundamental theorem of calculus among other things, one can show that the following are equivalent: 1) there exists $M \in \mathbb R$ such that $\forall x,y \in U$: $|f(y)-f(x)| \leq M|y-x|$. 2) $\forall x \in U: ||Df(x)|| \leq M$. Now let $(U,g)$ and $(V,h)$ be two Riemannian manifolds and $f: U \to V$ a $C^1$-map. I want to know in how far the above equivalence can be extended in this situation. It seems that I cannot simply do the same proof. Any hint would be appreciated. Thanks!","['differential-geometry', 'riemannian-geometry']"
1450765,Conservative vector fields and Energy,"If one knows that $\vec{F}=m\vec{a}$ is a conservative force, which means that $\vec{F}=\nabla\phi$, and that energy $E(t) = \frac{1}{2}mv(t)^2 + \phi(\vec{x}(t))$, where $v(t) = \|\vec{v}(t)\|$ then it can be deduced that $E'(t) = m\frac{d}{dt}(v\cdot v) + \frac{d\phi}{dt} = m(\vec{v}\cdot \vec{a} - \vec{a}\cdot \vec{v}) = 0$. (Corrections were made as the discussion went).","['physics', 'derivatives']"
1450769,Is a bijective morphism of quasi-affine smooth varieties an isomorphism?,We have a bijective morphism $f:X\to Y$ of quasi-affine varieties (say over $\Bbb{C}$). Can $f$ fail to be an isomorphism if $X$ and $Y$ are smooth?,['algebraic-geometry']
1450773,"What is ""pointwise"", in the context of function composition?","APOLOGY: This question is asked by someone foreign to math, with the expectation that math.stackexchange can be a resource to (among other things) understand math concepts. I'm a self-taught project-of programmer. I would like to understand ""projection"", beacuse it's used in functional programming (related to lamda calculus I hear), and in a database called MongoDB. For the math term of projection Wikipedia links to ""function composition"", whose page in turn links to ""pointwise"". The question is: What is “pointwise”, in the context of function composition? So that (from wikipedia's ""projection"" ) ""In mathematics, a projection is a mapping of a set (or other mathematical structure) into a subset (or sub-structure), which is equal to its square for mapping composition (or, in other words, which is idempotent)."" Can be understood once (from wikipedia's ""function composition"" ): In mathematics, function composition is the pointwise application of one function to the result of another to produce a third function. Is understood... Thanks in advance. Also, resources to material that can help with this kind of doubts are very much welcome","['terminology', 'function-and-relation-composition', 'functions']"
1450826,How to compute $\lim\limits_{x\to 0}\dfrac{e^{f(x)}-e^x}{2x-\sin\left( f(2x) \right)}$,"Let  $f:\mathbb{R}\longrightarrow \mathbb{R}$ a function such that : $f(x)=x-x^3+o(x^3).$ Compute 
   $$ \lim\limits_{x\to 0}\dfrac{e^{f(x)}-e^x}{2x-\sin\left( f(2x) \right)}$$ My thoughts: note that : $e^{x}=1+x+\dfrac{x^2}{2}+\dfrac{x^3}{6}+o(x^3)$ $\sin(x)=x-\dfrac{x^3}{6}+o(x^3)$ $e^{f(x)}=1+f(x)+\dfrac{f(x)^2}{2}+\dfrac{f(x)^3}{6}+o(f(x)^3)$ $\sin(f(2x))=f(2x)-\dfrac{f(2x)^3}{6}+o(x^3)$ $f(x)=x-x^3+o(x^3)$ $f(2x)=2x-8x^3+o(x^3)$ indeed,
\begin{align}
e^{f(x)}&=1+f(x)+\dfrac{f(x)^2}{2}+\dfrac{f(x)^3}{6}+o(f(x)^3)\\
&=1+\left(x-x^3+o(x^3) \right)+\dfrac{\left(x-x^3+o(x^3) \right)^2}{2}+\dfrac{\left(x-x^3+o(x^3) \right)^3}{6}+o(x^3)\\
&=1+\left(x-x^3+o(x^3) \right)+\dfrac{\left(x-x^3+o(x^3) \right)^2}{2}+\dfrac{\left(x-x^3+o(x^3) \right)^3}{6}+o(x^3)\\
\end{align}
or $\left(x-x^3+o(x^3) \right)^2=(x^{2}-2x^{4}+x^{6} )+o(x^3)=x^{2}+o(x^3) $
\begin{align}
\left(x-x^3+o(x^3) \right)^3&=(x-x^{3}+o(x^3))(x-x^{3}+o(x^3))^2=(x-x^{3}+o(x^3))(x^{2}+o(x^3))\\
&=x^3+o(x^3) 
\end{align}
we plug those values in $e^{f(x)}$ \begin{align}
e^{f(x)}&=1+\left(x-x^3+o(x^3) \right)+\dfrac{\left(x-x^3+o(x^3) \right)^2}{2}+\dfrac{\left(x-x^3+o(x^3) \right)^3}{6}+o(x^3)\\
&=1+\left(x-x^3+o(x^3) \right)+\dfrac{ x^{2}+o(x^3)}{2}+\dfrac{x^3+o(x^3)}{6}+o(x^3)\\
e^{f(x)}&=1+x+\dfrac{x^2}{2}+\dfrac{x^3}{6}-x^3+o(x^3)
\end{align}
then
\begin{align}
e^{f(x)}-e^{x}&=1+x+\dfrac{x^2}{2}+\dfrac{x^3}{6}-x^3+o(x^3)-e^{x}\\
&=1+x+\dfrac{x^2}{2}+\dfrac{x^3}{6}-x^3+o(x^3)-(1+x+\dfrac{x^2}{2}+\dfrac{x^3}{6}+o(x^3))\\
&=1+x+\dfrac{x^2}{2}+\dfrac{x^3}{6}-x^3+o(x^3)-1-x-\dfrac{x^2}{2}-\dfrac{x^3}{6}+o(x^3))\\
e^{f(x)}-e^{x}&=-x^{3}+o(x^3)
\end{align} $$\fbox{$e^{f(x)}-e^{x}=-x^{3}+o(x^3)$}$$ \begin{align}
\sin(f(2x))&=\left(2x-8x^3+o(x^3)\right)-\dfrac{\left(2x-8x^3+o(x^3)\right)^3}{6}+o(x^3)\\
\end{align}
or 
$\left(2x-8x^3+o(x^3)\right)^3=(8x^{3}\left(1-4x^{2}\right)+o(x^3)=8x^{3}+o(x^3) $ then
\begin{align}
\sin(f(2x))&=\left(2x-8x^3+o(x^3)\right)-\dfrac{\left(2x-8x^3+o(x^3)\right)^3}{6}+o(x^3)\\
&=\left(2x-8x^3+o(x^3)\right)-\dfrac{8x^{3}+o(x^3)}{6}+o(x^3)\\
&=2x-8x^3-\dfrac{8x^{3}}{6}+o(x^3)\\
&=2x-\dfrac{28x^{3}}{3}+o(x^3)\\
\end{align} $$\fbox{$2x-\sin(f(2x))=\dfrac{28x^{3}}{3}+o(x^3))$}$$ \begin{align}
\dfrac{e^{f(x)}-e^x}{2x-\sin\left(f(2x)\right)}&=\dfrac{-x^{3}+o(x^3)}{\dfrac{28x^{3}}{3}+o(x^3)}=-\dfrac{-3}{28}+o(x^3)\\
\end{align} $$\lim\limits_{x\to 0}\dfrac{e^{f(x)}-e^x}{2x-\sin\left( f(2x) \right)}=\dfrac{-3}{28}$$ Is my proof correct Please if you find any mistake try to correct it with details of calculations","['power-series', 'taylor-expansion', 'calculus', 'limits', 'solution-verification']"
1450836,Contradiction when applying CLT to Poisson random variables?,"We know that if $X\sim \mathrm{Pois}(\lambda)$ and $Y\sim \mathrm{Pois}(\mu)$
 are independent then $X+Y\sim \mathrm{Pois}(\lambda+\mu).$ This means that if $X_{1},\ldots,X_{n}$ are independent with $X_i \sim \mathrm{Pois}(1/n)$ (and so $E(X_i) = \operatorname{Var}(X_i)=1/n)$ then $S_n=\sum\limits_{i=1}^n X_i\sim \mathrm{Pois}(1)$
for all $n$. If the CLT holds, it follows that $S_n\sim \mathrm{Pois}(1)$ is a normal
distribution, which is not true. What is wrong with this argument?","['probability-theory', 'central-limit-theorem', 'poisson-distribution']"
1450859,Proof of the monotone convergence theorem for the conditional expectation,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $\mathcal F$ be a $\sigma$-algebra on $\Omega$ with $\mathcal
   F\subseteq\mathcal A$ $X_n,X$ be non-negative random variables on $(\Omega,\mathcal A,\operatorname P)$ The monotone convergence theorem for the conditional expectation states, that if $X_n\uparrow X$ almost surely, then $$\operatorname E\left[X_n\mid\mathcal F\right]\stackrel{n\to\infty}\to\operatorname E\left[X\mid\mathcal F\right]\;.$$ Clearly, by the monotonicity of the conditional expectation, $$Z:=\lim_{n\to\infty}\operatorname E\left[X_n\mid\mathcal F\right]$$ exists. Since each $\operatorname E\left[X_n\mid\mathcal F\right]$ is $\mathcal F$-measurable by definition, $Z$ is $\mathcal F$-measurable, too. Why is it not that clear, that $$\operatorname E\left[X_n\mid\mathcal F\right]\uparrow Z\;?\tag{1}$$ All proofs I've read so far only state, that there is a modification (version) of $Z$ with $(1)$. Clearly, the conditional expectation is only almost everywhere uniquely determined. So, the monotonicity only yields $$\operatorname E\left[X_n\mid\mathcal F\right]\le \operatorname E\left[X_{n+1}\mid\mathcal F\right]$$ on $\Omega\setminus N_n$ for some $\operatorname P$-null set $N_n\subseteq\Omega$. However, since $$N:=\bigcup_nN_n$$ is a $\operatorname P$-null set, too, we should be able to immediately conclude, that $(1)$ holds on $\Omega\setminus N$, i.e. almost everywhere. So, what am I missing?","['probability-theory', 'conditional-expectation', 'measure-theory', 'stochastic-processes', 'probability']"
1450910,Shortest method for $\int_{0}^{1}\frac{x^{4}\left(1-x\right)^{4}}{1+x^{2}}$,"I don't want to solve by expanding it and all, I tried corollary but denominator becomes messy, also in the options there is $\pi$ so tried several trigonometric substitutions too","['definite-integrals', 'trigonometry']"
1450913,Manipulation of unions and intersections,"I have a set that can be constructed in the following way: \begin{align}
B&=\bigcap_{i=1}^{k} \bigcup_{j=1}^{n} F_{i,j}\\
&= (F_{11} \cup F_{12} \cup \ldots \cup F_{1n})\cap(F_{21} \cup F_{22} \cup \ldots \cup F_{2n})\cap \ldots \cap(F_{k1} \cup F_{k2} \cup \ldots \cup F_{kn})
\end{align} Where $F_{i,j}=E_{j}$ or $E_{j}^{c}$ (may be different for each $i$). For a proof I am doing, I want to write the above as the union of the intersections of the $F_{i,j}$'s. Although I am not sure if this can be done, by the nature of the sets $F_{i,j}$ I believe the above union/intersection can at least be simplified. Originally I thought (foolishly) that unions and intersections could commute, but much to my dismay, they cannot. I need some generalized version of the distributive law that will allow me to collapse this union/intersection. Can anyone provide a generalized distributive law that might help simplify the above?",['elementary-set-theory']
1450917,"A special value polylogarithm identity involving $\text{Li}_3(-1/2),\,\text{Li}_3(-1/3),\,\text{Li}_3(2/3),\,\text{Li}_2(-1/3),\,\text{Li}_2(2/3)$","I've found that
\begin{align}
\mathcal{L} = 2\operatorname{Li}_3\left(-\frac{1}{2}\right)+\operatorname{Li}_3\left(-\frac{1}{3}\right)+2\operatorname{Li}_3\left(\frac{2}{3}\right)+\operatorname{Li}_2\left(-\frac{1}{3}\right) \ln(3)+2\operatorname{Li}_2\left(\frac{2}{3}\right) \ln(3)
\end{align}
equals to
$$
\mathcal{L} = \frac{\pi^2}{3}\ln(2)+\frac{1}{3}\ln^3(2)-\frac{1}{3} \ln^2(3) \ln\left(\frac{27}{8}\right)-\frac{\zeta(3)}{6}.
$$ How could we prove this identity? A numerical approximation:
$$
\mathcal{L} \approx 1.701652530545172752791574942340971991312113932043\dots
$$","['closed-form', 'polylogarithm', 'special-functions', 'integration']"
1450919,Finitely generated vs presented,"I am curious exactly what are the differences between finitely generated and finitely presented? I understand that finitely generated means we have, for an $R$-module $M$ that there exists an epimorphism
$$p:R^n\to M$$
and definitionally that finitely presented is when the kernel of $p$ is finitely generated that is
$$h:R^m\to\ker p$$
is an epimorphism, so we get
$$R^m\xrightarrow{h} R^n \xrightarrow{p} M\to 0$$
being exact. What I don't get is what additional information does it supply? Wouldn't the kernel of any such epimorphism be finitely generated? If not got a good example of it not being the case?","['abstract-algebra', 'modules', 'finitely-generated']"
1450921,How do we solve the laplace transform of the Heat Kernel?,"I am interested in the value of $$\int_0^\infty e^{-\alpha t}\frac{e^{-\frac{|x-y|^2}{2t}}}{\sqrt{2\pi t}}\, dt $$ this is the laplace transform of the Heat kernel (changing the time variable) This integral came up in this exercise: Exercise 3.7. Show that the resolvent for Brownian motion is given by $$U(\alpha)f(x)=\frac{1}{\sqrt{2\alpha}}\int_{-\infty}^\infty f(y)e^{-\sqrt{2\alpha}|x-y|}dy.$$ where $$U(\alpha)f=\int_0^\infty e^{-\alpha t}T(t)f\,dt,\quad\alpha>0,\tag{3.6}$$ First setps: \begin{align}
 U(\alpha)f(x) &= \int_0^\infty e^{-\alpha t} T(t) f (x)\, dt \\
&= \int_0^\infty e^{-\alpha t} \int_{-\infty}^\infty \frac{e^{-\frac{|x-y|^2}{2t}}}{\sqrt{2\pi t}} f (y)\, dy\, dt \\
&=   \int_{-\infty}^\infty f(y)\int_0^\infty e^{-\alpha t}  \frac{e^{-\frac{|x-y|^2}{2t}}}{\sqrt{2\pi t}} \, dt \, dy \\
 \end{align} So one can guess that $$ \int_0^\infty e^{-\alpha t}  \frac{e^{-\frac{|x-y|^2}{2t}}}{\sqrt{2\pi t}} \, dt = \frac{\exp{- \sqrt{2\alpha}|x-y|}}{\sqrt{2 \alpha}}$$ But How do we get such result? Here is my attempt at proving this: $$\int_0^\infty e^{-\alpha t}  \frac{e^{-\frac{|x-y|^2}{2t}}}{\sqrt{2\pi t}} \, dt = \int_0^\infty \exp\bigg\{-\alpha t - \frac{|x-y|^2}{2t}\bigg\}  \frac{1}{\sqrt{2\pi t}} \, dt \\
=  \int_0^\infty \exp\bigg\{-\bigg(\sqrt{\alpha t} - \frac{|x-y|}{\sqrt{2t}}\bigg)^2 + \sqrt{2\alpha}|x-y|\bigg\}  \frac{1}{\sqrt{2\pi t}} \, dt\\
=  \exp\bigg\{- \sqrt{2\alpha}|x-y|\bigg \}\int_0^\infty \exp\bigg\{-\bigg(\sqrt{\alpha t} - \frac{|x-y|}{\sqrt{2t}}\bigg)^2 \bigg\}  \frac{1}{\sqrt{2\pi t}} \, dt$$ So now I am at the point that I need to prove $$\int_0^\infty \exp\bigg\{-\bigg(\sqrt{\alpha t} - \frac{|x-y|}{\sqrt{2t}}\bigg)^2 \bigg\}  \frac{1}{\sqrt{2\pi t}} \, dt = \frac{1}{\sqrt{2 \alpha}} $$ But I don't see how to do it","['brownian-motion', 'laplace-transform', 'integration']"
1450945,Determinant always equal to zero?,"I just finished writing a computer program that takes as input a number of matrices and computes the inverse of the product of matrices. To test this program, I wanted to input a $3 \times 2$ matrix followed by a $2\times 3$ matrix so that the product would be a $3\times 3$ matrix. No matter how hard I try, the determinant of the product turns out to be zero and so the product is non-invertible. Is there a theorem in linear algebra that implies that the product of a $3\times 2$ matrix and $2\times 3$ matrix will always have determinant zero?","['determinant', 'linear-algebra']"
1450946,How can I prove $\lim \limits_{n \to \infty}\left(1+\frac{1}{a_n}\right)^{a_n}=e$ without involving function limit?,"If I already know that
$$\lim \limits_{n \to \infty} a_n=+\infty$$
Then how can I prove
$$\lim \limits_{n \to \infty}\left(1+\frac{1}{a_n}\right)^{a_n}=e$$ 
without involving function limit? This question comes because you may find some books on calculus or analysis (maybe they are badly written) require you to prove something like
$$\lim \limits_{n \to \infty}\left(1+\frac{2}{n}\right)^{n}=e^2$$
or something more complex even before they formally introduce the definition of limit of a function, They are hard to prove because you can't simply take something like $\frac{n}{2}$ as a subsequence of $n$. The definition of limit of a function (at infinity) here mean: For a real function $f$ which is well-defined on $[a, +\infty)$, if for any $\epsilon >0$, there is a positive number $M \geq a$ such that when $x>M$ we can say $|f(x)-A|<\epsilon$, then
  $$\lim \limits_{x \to \infty}f(x)=A.$$ While the definition of limit of a sequence here mean: For a sequence $\{a_n\}$, if for any $\epsilon>0$, there is a positive integer $N$ such that when $n>N$ we can say $|a_n-A|<\epsilon$, then $$\lim \limits_{n \to \infty}a_n=A.$$ I know sequence is a ""special"" kind of function whose domain is $\mathbb{N}$ and thus sequence limit is but a special case of function limit. Here I say avoid involving the idea of function limit means not to use the idea above but only to prove it by the ""special case"" below. After all, $(1+\frac{1}{a_n})^{a_n}$ is still a ""special"" function - a sequence. p.s. $e$ is defined by
$$\lim \limits_{n \to \infty}\left(1+\frac{1}{n}\right)^n=e.$$ My try so far: Since $$\lim \limits_{n \to \infty}\left(1+\frac{1}{n}\right)^n=e,$$ for every $\epsilon>0$, there is $N \in \mathbb{N}$ s.t. for all $n>N$,$$|\left(1+\frac{1}{n}\right)^n-e|<\epsilon.$$ Meanwhile, since $$\lim \limits_{n \to \infty} a_n=+\infty,$$ for $N' \in \mathbb{N}$ and $N'>N$, there is $N'' \in \mathbb{N}$ s.t. for all $n>N''$, $a_n>N'>N.$ However, if $a_n$ become bigger then $1+\frac{1}{a_n}$ will be smaller, and vise versa, so I don't know how to deal with $\left(1+\frac{1}{a_n}\right)^{a_n}.$","['limits', 'real-analysis', 'proof-writing', 'exponential-function']"
1450962,"Show that functional $f(x)=x'((a+b)/2)$ is bounded in $C^1([a,b])$ but unbounded in $C([a,b])$","Let $C^1([a,b])$ be normed vector space of all continuously differentiable functions defined on $[a,b]$ with a norm
$$||x||=\sup_{t \in [a,b]} |x(t)|+\sup_{t \in [a,b]} |x'(t)|$$
We have to show that the functional $f(x)=x'((a+b)/2)$ is  bounded on $C^1([a,b])$ and not bounded on $C([a,b])$ (space of continuously differentiable functions with a norm $||x||=\sup_{t \in [a,b]} |x(t)|$. Showing that $f(x)=x'((a+b)/2)$ is bounded on $C^1([a,b])$ is easy here is the proof
\begin{align}
|f(x)|=|x'((a+b)/2)| \le sup_{t \in [a,b]} |x'(t)| \le sup_{t \in [a,b]} |x'(t)|+\sup_{t \in [a,b]} |x(t)|=||x||
\end{align} But how to show that it's unbounded on $C([a,b])$? Also, is this particular functional important in some way?",['functional-analysis']
1451001,Is every injective function invertible?,"Is every injective function invertible? How could I prove such thing? (Or is it just a necessary but not sufficient condition?) If $f:A\rightarrow B$ is injective then $f(a) = f(b) \Rightarrow a = b$ for all $a,b\in A$. If $f(x)=y$ is invertible, there is some function $g(y)=x$. I don't see how to put these things together, so help would be appreciated.","['elementary-set-theory', 'calculus', 'functions']"
1451008,The polynomial $a z^n+z+1$ has at least one root in $|z| \leq 2$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I am trying to solve this problem, but I don't have any idea. The problem is: Prove that for arbitrary $a \in \mathbb{C}$ and $n \geqslant 2$, polynomial $P(z) = a z^n+z+1$ has at least one root inside the disc $S = \{ z \in \mathbb{C} \mid |z| \leqslant 2 \}$. Does anyone have idea? Thanks in advance.","['polynomials', 'complex-analysis', 'roots']"
1451023,Infinite sums: adding terms,"I would like to know where I can find a formal treatment of an idea I had, assuming it makes sense. Consider the infinite sum $$\sum\limits_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$$ and define the partial sum $$S_N=\sum\limits_{n=1}^{N}\frac{1}{n^2}$$ I guess that $$R_N = S_N + \frac{1}{N}$$ should converge faster as $N\rightarrow\infty$. Does it make sense? Any formal theory? Thanks!!!","['summation', 'limits']"
1451033,Integral w.r.t counting measure,"Definition of integral is given 
$$
\int f d\mu=\sup{\left\{\int s\ d\mu : 0 \leq s \leq f , s \ \text{ is a simple function} \right\}}
$$ Now let $f: \mathbb{N} \rightarrow [0,\infty)$ be a non-negative measurable function on the natural numbers and $\mu$ is the counting measure on $\mathbb{N}$. Prove the following using definition of integral:
$$
\int_{\mathbb{N}}f\ d\mu =\sum_{k=1}^{\infty} f(k)
$$ I could prove that $\int_{\mathbb{N}}f\ d\mu \geq \sum_{k=1}^{\infty} f(k)$ using simple functions of the form $f_N=\sum_{k=1}^N f(k)1\{n=k\}$. How do I prove the other direction ? Note: We shouldn't use Monotone Convergence Theorem.","['lebesgue-integral', 'measure-theory']"
1451073,Definition of a positive rational number,"In baby rudin page 3 it says: Definition An ordered set is a set $ S $ in which an order is defined. For example, $ \mathbb{Q} $ is an ordered set if $ r < s $ is defined to mean
  that $ s  - r $ is a positive rational number. My question is how a positive rational number is defined. I looked for an answer in google and all I could find is that a number is positive if it is greater than zero. Thanks","['elementary-set-theory', 'calculus']"
1451097,Repetition in digits on a normal number,"Consider a normal real number $0< n < 1$. Let $n_i$ denote the $i^\text{th}$ digit of $n$. What is the probability that there exists some $k \in \mathbb{N}$ such that $n_1=n_{1+k}, n_2=n_{2+k}, \ldots, n_k=n_{2k}$? I know that there are normal numbers that don't satisfy this. Maybe an easier question is if the digits of $n$ are random.","['probability-theory', 'number-theory']"
1451101,Normal form of currents,"Let $M$ be an $n$-dimensional manifold. Then the space of currents $\mathcal D^k(M)$ of degree $k$ on $M$ is the space of continuous linear functionals on the space of test $n-k$-forms. Two typical examples of currents are
$$
\mathcal{F}(\omega) = \int_\Gamma \omega
$$
where $\Gamma$ is a $n-k$-chain, and
$$
\mathcal{G}(\omega) = \int_M  \eta \wedge \omega
$$
where $\eta$ is a $k$-form. One can extend the action of Lie derivative from forms to currenst simply by
$$
L_X \mathcal{H}(\omega) = \mathcal{H}(L_X \omega)
$$
So the algebra of differential operators on $M$ acts on the space of $k$-currents. Is it true that the two examples of currents above generate the space of currents as a module over the ring of differential operators, i.e. any current can be obtained from a current like $\mathcal{F}$ or $\mathcal{G}$ by successive applications of Lie derivatives? If no, can the statement be repaired by adding more closure operations/generators? Or is it a completely wrong attitude, and a general current is a significantly more ""singular"" object?","['differential-geometry', 'distribution-theory']"
1451118,Let $f\colon\Bbb R\to \Bbb R-\{3\}$ be a function such that there exist $T>0$ with $f(x+T)=\frac{f(x)-5}{f(x)-3}$ for every $x\in\Bbb R$.,"Let $f\colon \Bbb R\to \Bbb R-\{3\}$ be a function with the property that there exist $T>0$ such that $f(x+T)=\frac{f(x)-5}{f(x)-3}$ for every $x\in \Bbb R$. Prove that $f(x)$ is periodic and find the period of $f(x)$. For $f(x)$ to be periodic, we need to prove $f(x+\lambda)=f(x)$, where $\lambda$ is the fundamental period of $f(x)$. But there seems no path to prove this in the given definition of the function. Please help me.","['periodic-functions', 'functions']"
1451134,Generalized Monomials,"Let $P$ be the set of all power functions $p_a$: $(0, \infty)\longrightarrow\mathbb{R}$, $x\mapsto x^a$, indexed by $a\in [0, \infty)$. Is $P$ linearly independent over $\mathbb{R}$? Intuitively, the answer is clearly yes (at least to me), but it seems to be escaping straightforward proof attempts. Follow-up question: Does the subspace of $C^{\infty}((0, \infty))$ spanned by $P$ admit some ""nice"" characterization?","['linear-algebra', 'functional-analysis']"
1451139,Riemann Hypothesis: Is $1/2$ of critical line same as the $1/2$ of square-root accurately of error term of prime number theorem?,"Here is a question about Riemann Hypothesis: Is $1/2$ of critical line same as the $1/2$ of square-root accurately of error term of prime number theorem $?$ In other words, (just for some brain exercise), let's assume that critical line is at $x=3/4$, does this mean that the error term in prime number theorem will be proportional to the power of $3/4$ $?$ So $|\pi(x) - Li(x) |$ would be bounded by $x^{(3/4)}$ $?$ Which book has a simple proof of this $?$ Thank you.","['prime-numbers', 'number-theory', 'riemann-zeta', 'analytic-number-theory']"
1451144,Advanced complex function theory book recommendation,"I would like to have some recommendations in order to self study the above topic. I have already studied some complex function theory, covering some of the more 'classical' theorems (the Bloch-Landau theorem, the Little & Big Picard theorems, Riemann mapping theorem) and some introductry to analytic continuation ideas.
I would like to further study this, and more specifically: Gamma&Zetta functions, elliptic functions, harmonic functions, and further study of holomorphic and meromorphic functions. Also, What books out there have a proof of Zalcman's lemma?","['book-recommendation', 'self-learning', 'reference-request', 'complex-analysis']"
1451168,Infinite torsion CAT(0) groups,"Do all infinite CAT(0) groups contain a $\mathbb{Z}$ subgroup? I am aware that this has been established for hyperbolic groups, and similar questions have appeared on open questions lists for CAT(0) groups, namely here . However, typically this is worded as 'Does there exist an infinite torsion subgroup of a CAT(0) group' or 'is there a infinite torsion group which acts properly discontinuously on a CAT(0) space.' Obviously subgroups can be fairly distorted and cocompactness is a strong condition. Does anyone know if this is an established fact, or is this still an open question? For the sake of clarity I am defining $G$ to be CAT(0) if it acts properly discontinuously and cocompactly on a proper CAT(0) space.","['metric-spaces', 'group-theory', 'geometric-group-theory', 'open-problem']"
1451184,Find the terms of a geometric progression given two partial sums.,"Given an increasing geometric progression such that: $$a_1+a_2+a_3+a_4+a_5=93\qquad\text{ and }\qquad a_2+a_4=30,$$ find $a_1$ , $a_2$ , $a_3$ , $a_4$ , $a_5$ without using the sum formula . What I did: Let $q$ denote the common ratio of the geometric progression, so that $$a_1q+a_1q^3=30\qquad\text{ and }\qquad a_1+a_1q+a_1q^2+a_1q^3+a_1q^4=93.$$ Dividing the two equations yields $$\frac{1+q+q^2+q^3+q^4}{q+q^3}=\frac{93}{30},$$ but I don't know how to solve this equation. Edit: I edited the question so that $a_1+a_2+a_3+a_4+a_5=93$ and NOT $a_1+a_2+a_3=93$ .","['summation', 'sequences-and-series', 'geometric-progressions', 'algebra-precalculus']"
1451203,Inequality for conditional expectation,"I have three random variables that are dependent, $\theta, Y,X$. Under which conditions on the distributions does the following implication hold: For a known function $g(.)$, two different realizations $Y=y$ and $Y=y'$ and the same realization $X=x$,
$$E[g(\theta)|Y=y]\neq E[g(\theta)|Y=y']\implies E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']?$$ It seems to me this will boil down to finding conditions for the consequent to be true, i.e., $E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']$ for $y\neq y'$. My thoughts:
\begin{equation}
E[g(\theta)|X=x,Y=y]=\int g(\theta) f(\theta|X=x,Y=y) d\theta,
\end{equation}
so if $f(\theta|X=x,Y=y)$ first order stochastically dominates $f(\theta|X=x,Y=y')$ or vice versa, then $E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']$ (assuming $g$ is strictly increasing or decreasing). This is of course only a sufficient and not necessary condition, but still it is not clear to me when  first order stochastic dominance of $f(\theta|Y=y)$ in $y$ implies first order stochastic dominance of $f(\theta|X=x,Y=y)$. Any ideas on that are very much appreciated. Thanks!","['conditional-expectation', 'probability', 'probability-distributions']"
1451208,Fourier transform of $ |x|^{s} $ and $\log|x| $,"Can anyone provide or give an expression in the sense of distribution theory for the functions $|x|^{s} , \log|x| $? I mean I would like to evaluate the Fourier transform $ \int_{-\infty}^{\infty}f(x)\exp(-iux) $ of these transforms in case it is possible.","['integral-transforms', 'fourier-analysis']"
1451219,Name and proof of mathematical inequality,"I'm reading a book on functional analysis and I've come across an inequality i.e. Suppose we have $$ a, b, c, p, q \ge 0 $$ and $$ p + q = 1 $$ then $$ a+b^pc^q \le (a+b)^p(a+c)^q$$ I'm curious on how one would prove this inequality let alone if there is a name of this inequality.  I'd like to note this is not a homework problem.  Thanks!","['analysis', 'linear-algebra', 'real-analysis', 'functional-analysis']"
1451221,Show that $e^{x+y}=e^xe^y$ using $e^x=\lim_{n\to\infty }\left(1+\frac{x}{n}\right)^n$.,I was looking for a proof of $e^{x+y}=e^xe^y$ using the fact that $$e^x=\lim_{n\to\infty }\left(1+\frac{x}{n}\right)^n.$$ So I have that $$\left(1+\frac{x+y}{n}\right)^n=\sum_{k=0}^n\binom{n}{k}\frac{(x+y)^k}{n^k}=\sum_{k=0}^n\frac{1}{n^k}\sum_{i=0}^k\binom{k}{i}x^iy^{k-i}=\sum_{k=0}^n\binom{n}{k}\sum_{i=0}^k\binom{k}{i}\left(\frac{x}{n}\right)^i\left(\frac{y}{n}\right)^{k-i}$$ But I can't get $$\left(1+\frac{x+y}{n}\right)^n=\sum_{k=0}^n\binom{n}{k}\left(\frac{x}{n}\right)^k\sum_{i=0}^n\binom{n}{i}\left(\frac{y}{n}\right)^i.$$ Any idea ?,"['real-analysis', 'exponential-function']"
1451247,Proof writing involving union and intersection : $(A \cup B = A \cap B) \implies ( A = B)$,"Prove: $(A \cup B = A \cap B) \implies ( A = B)$ Suppose $x \in A$, then $x ∈ A \cup B$. So then $x \in A \cap B$. Thus $x \in B$ and thus $A \subseteq B$ Suppose $x \in B$, then $x \in A \cup B$. So then $x \in A \cap B$. Thus $x \in A$ and thus $B \subseteq A$ Therefore, $A = B$ Is this correct? Another way to prove this? tips for a better proof writing?","['elementary-set-theory', 'proof-verification']"
1451276,Matrix exponential for Jordan canonical form,"Let $X$ be a real $n \times n$ matrix, then there is a Jordan decomposition such that $X = D+N$ where $D$ is diagonalisable and $N$ is nilpotent. Then, I was wondering whether the following is correct. $$ e^{tX}(x) = \sum_{k=0}^{m} \frac{t^k N^k}{k!} \left(e^{t \lambda_1} \alpha_1 v_1+\cdots+e^{t \lambda_n} \alpha_n v_n \right).$$ Here $x = \sum_{i=1}^{n } \alpha_i v_i$ and $v_i$ are the eigenvectors of the diagonalisable matrix, $\lambda_i$ are the eigenvalues of $D$ and $m$ is the degree up to which $N^k$ is still non-zero. Is this correct or am I doing something wrong? Cause I could not find a general equation for this matrix exponential, so I tried my best. (Thus, I am only asking for a verification or correction of this answer.) If anything is unclear, please let me know.","['matrix-exponential', 'jordan-normal-form', 'linear-algebra', 'matrices']"
1451281,Showing that $n$ exponential functions are linearly independent.,"I have $n$ lambdas, which are all different real and positive numbers, where: 
$\lambda_1 < \lambda_2 < \cdots < \lambda_n$. I then have to show that these functions are linearly independent: $$e^{\lambda_1 t}, e^{\lambda_2 t}, \ldots, e^{\lambda_n t}$$ So I guess what I want to show is that the only solution to this equations: $$c_1 e^{\lambda_1 t} + c_2 e^{\lambda_2 t}+ \ldots +c_n e^{\lambda_n t}=0, \quad \text{for all } t$$ is that all constants are zero.
I am not entirely sure how to do this when it is for $n$ lambdas - I did it earlier for just 3 lambdas, where I differentiated the function, so I have tried to use the same approach. I wanted to get $n$ equations with $n$ unknown, so I differentiated the function $n-1$ times, and then I chose to look at the case where $t = 0$, so I have something looking like this: $$c_1+c_2+ \ldots +c_n = 0$$ $$c_1 \lambda_1+c_2 \lambda_2+ \ldots +c_n \lambda_n = 0$$ $$ \cdots $$ $$c_1 \lambda_1^{n-1}+c_2 \lambda_2^{n-1}+ \ldots +\lambda_n^{n-1} = 0$$ Then I put this into a matrix $Ac = 0$, and now I want to show that the $\det(A)$ doesn't equal zero, so that the only solution is c = 0, but I'm not quite sure how to do this, or whether there is an easier way to do it ?","['independence', 'linear-algebra']"
1451287,Which PDE book covers these topics best?,"I have an exam in January and I want to prepare ODE and PDE section first as they carry good weightage. For ODE I have S.L. Ross' book, which I like and have always referred to. But I haven't done PDE yet and I have to prepare it now. My syllabus consists of these topics- Linear and quasilinear first order partial differential equations method of characteristics; second order linear equations in two variables and their classification Cauchy, Dirichlet and Neumann problems; solutions of Laplace wave in two dimensional Cartesian coordinates Interior and exterior Dirichlet problems in polar coordinates Separation of variables method for solving wave and diffusion equations in one space variable Fourier series and Fourier transform and Laplace transform methods of solutions for the above equations. My main and only focus is these topics with as many problems I can try on them. Can someone recommend a good book/s which covers all these topics. Thanks!","['reference-request', 'ordinary-differential-equations', 'partial-differential-equations']"
1451289,$L^p$ and $\mathscr{l}^p$ embeddings and norm inequalities,"I'm trying to summarize what I know about $L^p$ spaces at the moment and have a few questions.
I think that for $1\le p\le q\le \infty$ one has $$\mathscr{l}^p(\mathbb{N})\subseteq\mathscr{l}^q(\mathbb{N}) \text{ and for all }x\in\mathscr{l}^p(\mathbb{N}): \| x\|_q\le\| x \|_p$$ while for a finite measure space $(X,\mu)$ $$L^q\subseteq L^p \text{ and for all }f\in L^q:\| f\|_p\le\mu(X)^{\frac{1}{p}-\frac{1}{q}}\| f\|_q$$ My questions: 
1. Are the above statements correct? Are the two statements about sequence spaces also true if I consider $\mathbb{Z}$ instead of $\mathbb{N}$? Are the space-inclusions 'proper' for $p<q$? For the non-sequential $L^p$ spaces: What if my measure isn't finite. Is there still something I can say about embeddings and norm-inequalities? I tried Wikipedia but couldn't make much sense of what I read. Is there anything else important I should know about $L^p$ spaces? I'm talking very basic stuff that may be useful for an undergraduate writing a functional analysis exam. Save inequalities, I know most of these already. I know that's quite a lot but I tried to find answers to these questions for quite a while without much success.","['lp-spaces', 'functional-analysis', 'measure-theory']"
1451308,"$\lim_{n\rightarrow \infty }\frac{1}{n}\int_{Y<n} Y \, dP=0$?","$Y$ is a non-negative random variable, not necessary integrable. How to show
$$\lim_{n\rightarrow \infty }\frac{1}{n}\int_{Y<n}Y \, dP=0$$ My idea is to find a good upper bound that converges to zero. However, I didn't find a good one. My upper bound is 
$$\frac{1}{n}\int_{Y<n}Y \, dP\leq \frac{1}{n}\int_{Y<n}n \, dP\leq \int_{Y<n}dP\leqslant 1.$$","['probability-theory', 'probability', 'real-analysis', 'measure-theory']"
1451342,How to show $p_n < p_1 + p_2 + \cdots + p_{n-1}$?,"How do you show that, if $p_n$ denotes the $n$th prime, $n > 3$, then $$p_n < p_1 + p_2 +\cdots + p_{n-1}$$ using the Bertrand conjecture and induction? Here is what I've come up with, but I'm not sure if it's correct: Let $n=4$. Then, $p_4 = 7$, so we have: $$7 < 2+3+5 = 10.$$ Assume that the statement is true for $n$ so that $p_n < p_1 + p_2 +\cdots + p_{n-1}$. We want to prove that this is true for $n+1$. $$p_{n+1} < p_1 + p_2 +\dotsc + p_{n-1} + p_n.$$ But we assumed that $p_n < p_1 + p_2 +\cdots + p_{n-1}$, so we have: $$p_{n+1} < p_1 + p_2 +\cdots + p_{n-1} + p_n < p_n + p_n = 2p_n.$$ We know that $p_n < p_{n+1}$, so we have: $p_n < p_{n+1} < 2p_n$, which is true by the Bertrand conjecture. $\blacksquare$","['prime-numbers', 'number-theory', 'induction', 'elementary-number-theory']"
