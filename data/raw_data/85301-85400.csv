question_id,title,body,tags
1123958,"Proving that $\sup f'\left( \left( 0,\infty \right) \right)=0$ under a certain set of conditions.","Let $f$ be a twice differentiable function on $\left( 0,\infty  \right)$ s.t. $f''(x)>0$ for all $x\in \left( 0,\infty  \right)$. Prove, that if the following conditions are satisfied: $\underset{x\to \infty }{\mathop{\lim }}\,f\left( x \right)=L<\infty $. $\forall x\in \left( 0,\infty  \right).f'\left( x \right)<0$. Then $\sup f'\left( \left( 0,\infty  \right) \right)=0$ . How would you go about proving this?","['supremum-and-infimum', 'derivatives']"
1123964,An integral with respect to the Haar measure on a unitary group,"Let $A,D\in \mathbb{C}^{n \times n}$ be diagonal matrices. I need to calculate 
$$\int_{U(n)}\det{(A-HDH^\dagger)}\,\mathrm{d}H$$ 
where $dH$ is the unit invariant Haar measure on the group of unitary matrices and $H^\dagger$ is the conjugate transpose of $H$. (If $A=I$ this is very easy to solve, but I want the answer for $A\neq I$ in terms of $A$ and $D$.)","['differential-geometry', 'statistics', 'algebraic-geometry', 'random-matrices', 'probability']"
1123968,How to evaluate the limit $\lim_\limits{x\to 0+ } \frac{1}{\sqrt{x}}\left ( \frac{1}{\sin x} - \frac{1}{x}\right )$?,"$$\lim_{x\to 0^+ } \frac{1}{\sqrt{x}}\left ( \frac{1}{\sin x} - \frac{1}{x}\right ) =\ ?$$ I rearranged it as
$$\lim_{x\to 0^+ } \frac{x-\sin x}{x\sqrt{x}\sin x} = \lim_{x\to0^+ } \frac{x-\sin x}{x^{\frac{3}{2}}\sin x}$$ Which gives an indetermination of the form $0/0$. Then, I tried L'Hospital:
$$\lim_{x\to 0^+ } \frac{x-\sin x}{x^{\frac{3}{2}}\sin x} = \lim_{x\to 0^+ } \frac{1-\cos x}{\frac{3}{2}x^{\frac{1}{2}}\sin x + x^{\frac{3}{2}} \cos x}$$ Should I continue to apply L'Hospital or is there a simpler way to solve it?","['indeterminate-forms', 'calculus', 'limits']"
1123998,how to calculate this logarithmic function?,"Im having trouble in graphing this log function: $y=\log _{1/4}\left|x^2-5x+6\right|$ I found the intervals: $(-\infty, 2)$, $(2,3)$, $(3,\infty)$ Should I just give $x$ values and find $y$ to graph this or is there another way?","['graphing-functions', 'logarithms', 'functions']"
1124003,How to calculate probability of users generating distributed events reaching n events per 15 minutes?,We have games & apps that connect to services such as Facebook and Twitter to fetch information. These services have various rate-limit caps that you cannot exceed - typically based on a 15 minute window of time. If we exceed this rate - the service blocks for a while. This makes my users sad. For a concrete example - you can only fetch a users tweets about 300 times per 15 minute window. I would like to estimate how many users it might take before I could reasonably expect to hit this quota of 300 events in any given 15 minute window. This is so I can look ahead from our usage trends and maybe cache this data or pool it or whatever. Assumptions: A user can be expected to use the app for 5 minutes then quit There is a 1/5 any given user will access this twitter feed during a session (based on actual usage) I would restrict this usage to daylight hours (Not yet concerned about lower levels of - users at night - most of our gamers are in the US mainland and not night owls) I assume usage is evenly spread across this time. I see it is connected to questions such as this: ( How to calculate the probability of two events happening within a certain time period using exponential distribution ) but I can't quite connect the dots :) Thanks for any input!,"['statistics', 'probability-distributions', 'probability']"
1124005,Easy: Graphs of Straight Line,I can't exactly figure out how to work this out. Well I know the equation for a straight line is $y = mx + c$ $c = gradient$ Therefore if I multiply $3$ by the number $x$ to get the gradient $6$ and $2$ I can work out which is line is which... With $y = 3(x + 2)$ I tried to expand but then I got confused. Can someone explain in easy terms? Thanks guys.,"['algebra-precalculus', 'graphing-functions']"
1124047,"Urn with marbles, unknown number of colors","When I started with this calculation I thought this was going to be a flashback from school decades ago but now after searching I'm confused if I'm over thinking it or if it's not as trivial as I thought - please point me in the right direction if I am. Assume an urn with N=1000 total marbles. After pulling 70 without replacement, 11 different colors were drawn with different frequencies. based on only these values, can I calculate the probability there are k colors? I know 10 < k < 942 but how do I calculate the p for let's say k= 50 or what range the p would be less than 0.05? Thank you!","['statistics', 'sampling']"
1124051,Verifying a Vector Space Via Given Axioms,"Let $X$ be the collection of all sequences $\{\alpha_n\}_{n=1}^{\infty}$ of scalars from $\mathbb{K}$ such that $\alpha_n=0$ for all but a finite number of values of $n$. Define addition and scalar multiplication on $X$ by $\{\alpha_n\} + \{\beta_n\} = \{\alpha_n + \beta_n \}$ and $\lambda \{\alpha_n\} = \{\lambda \alpha_n\}$. Verify that $X$ is a vector space over $\mathbb{K}$. According to my textbook which is being used for this problem, I need to verify the property of closure under addition and scalar multiplication as well as the following 8 axioms: 1). $x+(y+z)=(x+y)+z$ $\{\alpha_n\} + (\{\beta_n + \gamma_n\}) = \{\alpha_n + \beta_n + \gamma_n\}$ and similarly, $\{(\alpha_n + \beta_n)\} + \{\gamma_n\} = \{\alpha_n + \beta_n + \gamma_n\}$ by definition of addition on $X$. 2).$x+y=y+x$ $\{\alpha_n\} + \{\beta_n\} = \{\beta_n\} + \{\alpha_n\}$. Since $\{\alpha_n\} = 0$ for all but finitely many values of $n$, then $\{\alpha_n\} + \{\beta_n\} = 0+0 = \{\beta_n\} + \{\alpha_n\} = 0+0$. 3). $x+0 = x$. $\{\alpha_n\} + 0 = \{\alpha_n\}$. By the definition of addition on $X, \{\alpha_n\} + 0 = \{\alpha_n + 0\} = \{\alpha_n\}$. 4). $x+ (-1)x= 0$. $\{\alpha_n\} + (-1)\{\alpha_n\}=0$. Let $\lambda = -1$ and we use the definition of scalar multiplication: 
$\{\alpha_n\}+ \lambda \{\alpha_n\} = \{\alpha_n\} + \{\lambda \alpha_n\}$. Using the definition of addition on $X$, we get $\{\alpha_n+ \lambda \alpha_n\} = \{\alpha_n - \alpha_n\}=0$. 5). $(\lambda + \mu)\{\alpha_n\} = \lambda \{\alpha_n\} + \mu \{\alpha_n\}$. Using the definition of scalar multiplication on $X$, we can write $(\lambda+\mu)\{\alpha_n\} = \{(\lambda + \mu)\alpha_n\} = \{\lambda \alpha_n + \mu \alpha_n\}$. Using addition on $X$, we can have $\{\lambda \alpha_n + \mu \alpha_n\} = \{\lambda \alpha_n\} + \{\mu \alpha_n\}$. Again using scalar multiplication, we have $\lambda \{\alpha_n\} + \mu \{\alpha_n\}$. 6). $\lambda \{\alpha_n + \beta_n\} = \lambda \{\alpha_n\}+ \lambda\{\beta_n\}$. By scalar multiplication on $X$,  $\lambda \{\alpha_n + \beta_n\} = \{\lambda(\alpha_n + \beta_n)\}$. Using addition, $\lambda\{\alpha_n+\beta_n\} = \lambda[\{\alpha_n\}+\{\beta_n\}]$. By scalar multiplication, $\lambda[\{\alpha_n\}+\{\beta_n\}] = \{\lambda \alpha_n\} + \{\lambda \beta_n\}$. Again by scalar multiplication, $\lambda\{ \alpha_n\} +\lambda \{ \beta_n\}$. 7). $(\lambda \mu)\{\alpha_n\} = \lambda (\mu \{\alpha_n\})$. By scalar multiplication, $(\lambda \mu)\{\alpha_n\} = \{(\lambda \mu)\alpha_n\}$. Writing $(\lambda \mu) = (\lambda)(\mu)$, we have $(\lambda)(\mu)\{\alpha_n\}$. By scalar multiplication, $(\lambda)(\mu)\{\alpha_n\} = \lambda\{\mu \alpha_n\}$. 8). $1 \cdot \{\alpha_n\} = \{\alpha_n\}$. Let $\lambda=1$. By scalar multiplication, $\lambda \{\alpha_n\} = \{\lambda \alpha_n\} = \{1 \cdot \alpha_n\} = \{\alpha_n\}$. I have not shown the property of closure under addition and scalar multiplication since I am unsure about how to do that with my given information. Any help/advice/suggestions will be greatly appreciated. Thanks in advance. The textbook I am using is Functional Analysis An Elementary Introduction by Markus Haase.","['vector-spaces', 'proof-writing', 'functional-analysis', 'proof-verification']"
1124142,intersection of infinite collection of finite sets?,"I know that there are questions asking like ""intersection of a infinite collection of sets"" and I can understand that the answer for that one is a null set, but I got a question here, in which all sets are finite and nonempty. Please take a look at the pic below. It's a True/False question. What I'm confused about is that the ""infinity"" sign in the interception. Since all sets are finite, does it mean that there are many sets in the chain are the same? (because the symbol used is for subsets not for proper subsets). Please give me some hints how I should think about this question. Thank you",['elementary-set-theory']
1124195,Why do modular curves parametrise elliptic curves?,"Let $Y_1(N)=\Gamma_1(N)/H$ , where $H$ is the upper half plane. In these lecture notes http://alpha.math.uga.edu/~pete/modularandshimura.pdf , the author makes the following statement: "" $Y_1(N)$ parameterizes isomorphisms $(E,P) \mapsto (\Lambda_\tau,1/N \cdot 1)$ , or, informally, elliptic curves together with a distinguished point of exact order $N$ ."" I would like to know: i) What precisely does this mean? What does 'parameterize' mean? ii) Can anyone sketch the main ideas in proving this result? (A reference would also be appreciated. I have found the paper by Deligne-Rapoport mentioned in the link below, but it looks a little intimidating. I will tackle it if need be, but would like a more informal explanation first!) This is a related question, but I don't think it's quite the same as what I am asking: The modular curve X(N)","['modular-forms', 'algebraic-geometry', 'algebraic-number-theory', 'elliptic-curves']"
1124244,Chain rule for partial derivatives intuition,Can somebody give me an intuitive explanation for the below equations. I'm not sure how they come about and how they can be perceived logically. $$\frac{\partial z}{\partial s} =\frac{\partial f}{\partial x}\frac{\partial x}{\partial s}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial s} \ \ \text{and} \ \ \frac{\partial z}{\partial t} =\frac{\partial f}{\partial x}\frac{\partial x}{\partial t}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial t} $$,"['multivariable-calculus', 'derivatives']"
1124251,Proof of intersection and union of Set A with Empty Set,"I need to prove the following: Prove that $A\cup \!\, \varnothing \!\,=A$ and $A\cap \!\, \varnothing \!\,=\varnothing \!\,$ It's my understanding that to prove equality, I must prove that both are subsets of each other.
So to prove $A\cup \!\, \varnothing \!\,=A$, we need to prove that $A\cup \!\, \varnothing \!\,\subseteq \!\,A$ and $A\subseteq \!\,A\cup \!\, \varnothing \!\,$. However, I found an example proof for $A \cup \!\, A$ in my book and I adapted it and got this: $A\cup \!\, \varnothing \!\,=$ {$x:x\in \!\, A  \ \text{or} \ x\in \!\, \varnothing \!\,$}
= {$x:x\in \!\, A$} = A $A\cap \!\,  \varnothing \!\,=$ {$x:x\in \!\, A  \ \text{and} \ x\in \!\, \varnothing \!\,$}
= {$x:x\in \!\, \varnothing \!\,$} = $\varnothing \!\,$ Do my proofs look ok?","['elementary-set-theory', 'solution-verification']"
1124291,Why is Klein bottle non-orientable?,"I am doing the homework of differential geometry and encounter this problem: The Klein bottle $K^2$ is defined to be the identification space 
  $$[0, 1] \times [0, 1]/{\sim}, \text{ where the identification is }
(x, 0)\sim (1-x, 1) \text{ and } (0, y) \sim (1, y).$$ i) Prove that $K^2$ is non-orientable. ii) For a submanifold $M$ on $K^2$ defined by $1/4\leq x\leq3/4, 0\leq y\leq1,$ is $M$ orientatble? I already know that I need to check the orientation of the tangent space along some curve. But I am not quite sure how I can write down the proof in a formal way. Could anyone help? Any comment? Thanks! Edit: I have done the first part. Can anyone help me with the second? I have a feeling that the submanifold $M$ is isomorphic to the Möbius strip. But I don't have good reasons. Edit: Yes, $M$ is indeed the Möbius strip.","['non-orientable-surfaces', 'differential-geometry', 'general-topology', 'mobius-band', 'klein-bottle']"
1124305,Differential of a function in non-normed topological vector spaces,"I would like to know if it is possible to define the differential of a function in a topological vector space that does not have a norm. To make things clear, let $E$ and $F$ two topological vector spaces over $\mathbb{R}$ , such that there is a norm $\left\|\cdot\right\|$ defined on $E$ , let $U$ an open set of $E$ , $f:U\to F$ a function from $U$ to $F$ and $u\in U$ . As the function defined by $\left\{\begin{array}{c}E\to E\\h\mapsto u+h\end{array}\right.$ is continuous, there exits a neighbourhood $V$ of $0$ in $E$ such that $\forall h\in V,\,\left(u+h\right)\in U$ , such that for $h\in V$ , the value $f\left(u+h\right)$ is defined. Then, the differential of function $f$ at point $u$ is generally defined as the only linear map $\text d_uf:V\to F$ such that: $$f\left(u+h\right)=f\left(u\right)+\text d_uf\left(h\right)+\underset{h\to0}{o}\left(h\right)\text{ ;}$$ where $\underset{h\to0}{o}\left(h\right)$ is Landau's small o notation, which means: $$\lim\limits_{h\to0}\frac{f\left(u+h\right)-f\left(u\right)-\text d_uf\left(h\right)}{\left\|h\right\|}=0\text{.}$$ It is clear that the latter definition involves the norm $\left\|.\right\|$ defined on $E$ . My question is, can we define the differential of a function (or an equivalent of Landau's notation) such that it does not involve the norm $\left\|\cdot\right\|$ , so that it is defined on any topological vector space - i.e. not necessarily one which has a topology induced by a norm. Thank you for any answer.","['differential-topology', 'functional-analysis']"
1124330,Proof of transformation law for double integrals,"The second volume of Apostol's Calculus seems rather circumspect in its discussion of the change of variables formula for double integrals.  Section 11.29 offers a proof under the following very limited circumstances: Let $R$ be a rectangle, $R^*$ its image under a one-to-one mapping $u = U(x,y)$, $v = V(x,y)$, with the inverse mapping given by $x = X(u,v)$, $y = Y(u,v)$.  Assume that both $X$ and $Y$ have continuous second-order partial derivatives, and that the Jacobian determinant $J(u,v)$ is never $0$ in $R^*$.  Then \begin{align}
\iint\limits_R dx\, dy & = \iint\limits_{R^*}|J(u,v)| \,dx\,dy
\end{align} The proof Apostol gives is a straightforward application of Green's Theorem, except for one small issue:  let $C$ be the boundary of $R$, $C^*$ be the boundary of $R^*$, and parameterize $C^*$ by 
\begin{align}
\mathbf{\alpha}(t) = W(t)\mathbf{i} + Z(t)\mathbf{j}
\end{align}
with $t$ on some interval $[a,b]$.  Apostol then asserts that
\begin{align}
\mathbf{\beta}(t) = X[W(t),Z(t)]\mathbf{i} + Y[W(t),Z(t)]\mathbf{j}
\end{align}
represents a parameterization of $C$.  I'm afraid I don't understand the basis for this assertion.  The continuity of $X$ and $Y$ along with the one-to-oneness of the map $x = X(u,v), y = Y(u,v)$ would seem to guarantee that $\mathbf{\beta}(t)$ is a piecewise smooth closed path within $R$, but it is unclear to me that we have boundaries mapping to boundaries.  Is there some way to show that this is the case? (Perhaps not so coincidentally, the proof that Munkres gives in his supplemental notes on MIT's OpenCourseware site is almost identical, except that in his statement of the theorem that $C$ maps to $C^*$ is an explicit hypothesis.)",['multivariable-calculus']
1124342,Find $\lim_{n\to \infty}({1\over \sqrt{n^2+1}}+{1\over \sqrt{n^2+2}}+\cdots+{1\over \sqrt{n^2+n}})$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question strong text Find $\lim_\limits{n\to \infty}\left({1\over \sqrt{n^2+1}}+{1\over \sqrt{n^2+2}}+\cdots+{1\over \sqrt{n^2+n}}\right)$ . I do know it is bounded by $1$ . I tried using the sandwich rule with no success. How can I solve it?","['calculus', 'real-analysis', 'limits']"
1124381,Independence of path in a closed curve line integral,"Let $f(t)$ be a continuous function. Let $C$ be a smooth closed curve. Show that $$\oint\limits_C xf(x^2 + y^2)\,dx + y f(x^2 + y^2)\,dy = 0$$ Hint : Remember that $f(t)$ has a primitive function $F(t)$. Use this fact to construct a potential function for the vector field. If we prove that the vector field $F(x,y) = (x \cdot f(x^2 + y^2),y \cdot f(x^2 + y^2))$ is conservative in its domain, then we can use the fact $$\int\limits_C {F \cdot dr} = \varphi (r(b)) - \varphi (r(a)) = 0$$ to express the initial line integral as a potential function difference between two points on a closed smooth curve, which would imply that any path taken between these two points would yield the same integral value. Now in order to show that the given vector field is conservative we need to find its potential, which means we have to calculate $$\frac{d\varphi}{dx} = x \cdot f(x^2 + y^2)\text{ and }\frac{d\varphi}{dy} = y \cdot f(x^2 + y^2)$$ How can we find a potential function $\varphi (x,y)$ if we do not know the form of the function $f(x^2 + y^2)$? If we replace the argument with, say, $t = {x^2} + {y^2}$ we would need to calculate the integrals $$\frac{d\varphi}{dx} = x \cdot f(t)\text{ and }\frac{d\varphi}{dy} = y \cdot f(t)$$ but we cannot treat $f(t)$ as constant since its dependent on both variables $x$ and $y$. What i had in mind is to show that due to symmetry $F(x,y) = F(y,x)$, which implies that a closed loop is cut evenly by two curves ${C_1}$ and ${C_2}$, their sum defines the closed loop region. $F$ is conservative vector of the field if $$\frac{d}{dy} (x \cdot f(x^2 + y^2)) = 2xyf' = \frac{d}{dx} ( y \cdot f(x^2 + y^2))$$ Now we know that the field is conservative, which implies $F = \nabla \varphi $ for some scalar potential function $\varphi $ defined over the closed loop. Therefore, $$F \cdot dr = \left( \left( \frac{d\varphi}{dx} \right)i + \left( \frac{d\varphi}{dy} \right)j \right) \cdot \left( {dxi + dyj} \right) = \frac{{d\varphi }}{{dx}}dx + \frac{{d\varphi }}{{dy}}dy = d\varphi $$ Since $C$ is a continuous smooth, closed curve, parametrized, say, by $r = r(t),\,\,\,a \le t \le b$ then $r(a) = r(b)$ and $$\int\limits_C F \cdot dr = \int\limits_a^b \frac{d\varphi (r(t))}{dt} \, dt = \varphi (r(b)) - \varphi (r(a)) = 0$$ However, i don't think that it is sufficient to claim that the given vector field is conservative based on the equality of partial derivative of its components. We still need to find a potential function i think. For example, if instead of $F(x,y) = (x \cdot f(x^2 + y^2),y \cdot f(x^2 + y^2))$ we were given a vector field, say, $F(x,y) = (x \cdot ({x^2} + {y^2}),y \cdot (x^2 + y^2))$ we could easily find its potential to be $\varphi (x,y) = \frac{x^4}{4} + \frac{x^2 y^2}{2} + \frac{y^4}{4} = \frac{1}{4} (x^2 + y^2 )^2$. Now we can take any smooth closed curve, parametrize it and show that the potential at any two points on the curve is the same, hence its difference is zero. For example, in our case we can take a unit circle and parametrize it as $x = \cos t \text{ and }y = \sin t$. Now we just chose two random points on the curve, say, $P_1(1,0) \text{ and } P_2 (0,1)$ and show that $$\oint\limits_C x(x^2 + y^2)\,dx + y(x^2 + y^2)\,dy = \left[ \frac{1}{4} ( x^2 + y^2)^2 \right]_{(1,0)}^{(0,1)} = \frac{1}{4} - \frac{1}{4} = 0$$ How to deal when we are given $f(x^2 + y^2)$ instead of a function itself?",['multivariable-calculus']
1124396,Integral inequality $\int_0^x{f(t)^3 dt \leq \left( \int_0^x f(t) dt\right)^2} :\forall x>0$,"Let $f(0) = 0$ and $0<f'(x)\leq1$ for all $x \geq0$, then prove: $$\int_0^x{f(t)^3 dt \leq \left( \int_0^x f(t) dt\right)^2} :\forall x>0$$ The hint I was given was ""differentiate, factor and differentiate again"" but I'm not sure where to start","['inequality', 'calculus', 'integration', 'real-analysis', 'derivatives']"
1124414,Can we find the GCD of two polynomials in $\mathbb Q[x]$ by representing the coefficients as vectors?,"Can we find the GCD of two polynomials in $\mathbb Q[x]$ by representing the coefficients as vectors? For example: $f=x^5+3x^4+x^3+4x^2+1$, and $g=x^5+3x^4+4x^3+3x+1$ Can we represent these polynomials as f $=(1,3,1,4,0,1)$ and g $=(1,3,4,0,3,1)$ and somehow perform matrix operations to find the GCD?","['number-theory', 'abstract-algebra', 'polynomials', 'matrices', 'linear-algebra']"
1124423,Prove that the projection operator $\mathbb P_+\equiv|+z\rangle\!\langle +z|$ is Hermitian,"Use Dirac notation (the properties of kets, bras and inner products) directly to establish that the projection operator $\mathbb{\hat P}_+$ is Hermitian. Use the fact that $\mathbb{\hat P}^2_+=\mathbb{\hat P}_+$ to establish that the eigenvalues of the projection operator are $1$ and $0$. I know how to prove this using mathematical notation, i.e. for any $x,y\in V$ we must show that $\langle x, \ \mathbb{\hat P}_+y\rangle = \langle \mathbb{\hat P}_+x, \ y\rangle$ but how can I prove the way the book suggested, i.e. using Dirac notation and the properties of kets and bras?","['projection-matrices', 'physics', 'mathematical-physics', 'linear-algebra', 'quantum-mechanics']"
1124433,Show that $P(X > \lambda) \geq \frac{(EX - \lambda)^2}{EX^2}$,"Question: Let X be a nonnegative random variable and $0 < \lambda \leq EX$. 
Show that $P(X > \lambda) \geq \frac{(EX - \lambda)^2}{EX^2}$ At first glance I thought I could use some variation of Markov's Inequality. However, I'm not entirely sure where to start.","['statistics', 'measure-theory', 'probability-theory', 'real-analysis', 'probability']"
1124434,How to check my answer in combinatorics problems,"Combinatorics problems (combinations and permutations) are an absolutely maddening subject for me. I can seem to work my way to the answer, provided I already know the correct answer. However, I can only rarely get the correct answer on the first try. This is obviously a problem on tests. In algebra and calculus I can usually verify that an answer is correct by working backwards or plugging the result back in to the original equation. Is there some way to do the same for enumeration problems?","['soft-question', 'combinatorics']"
1124435,Proving that $\sin1 $(radian) is irrational without using Taylor Series Expansion.,"In university last semester I was asked to prove that $\sin1$ (1 radian that is) is irrational ,  and ended up simply using the Taylor Series Expansion. This method provides a very quick solution, but I am curious as to whether anyone has a method for proving this without making use of the Taylor Series Expansion . I feel as though doing so must be possible using some number theory, but am low on ideas as to an alternative approach to the question. Note: If anyone is interested in my solution using Taylor Series Expansion (although it is not the focus of my question), here it is : From 
  $$ \sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} -  \dots$$
  We see that 
  $$ \alpha = \sin 1 = 1 - \frac{1^3}{3!} + \frac{1^5}{5!} -  \dots
$$
  Given integers $a$ and $b$, if $\alpha = \frac{a}{b}$ then it follows that $b!\alpha \in \mathbb{Z}$, and $b!\alpha = C + D$ where $C \in \mathbb{Z}$ and we have :
  $$
D = \begin{cases}
\pm(\frac{1}{b+1} - \frac{1}{(b+1)(b+2)(b+3)} + \dots) \text{    if $b$ is even}\\
\pm(\frac{1}{(b+1)(b+2)} - \frac{1}{(b+1)\dots(b+4)} + \dots ) \text{ if $b$ is odd}\\
\end{cases} $$
  In each case we can see that $0 < D < 1$, giving us a contradiction. 
  Thus, we have that $\sin 1 $ is irrational. 
  $$ \blacksquare $$","['proof-writing', 'number-theory']"
1124458,Two definitions for non-singular in codimension 1,"I am trying to understand how the following definitions are the same. Shafarevich definition (pg 128) -
A variety is non-singular in codimension one if the singular locus has codimension $> 1$. Hartshorne definition (pg 130) -
A scheme is non-singular in codimension one if every local ring $\mathcal{O}_x$ of dimension one is regular. My question is how to prove Hartshorne $\implies$ Shafarevich . I guess that if $X$ is an affine variety and $Sing(X)$ has an irreducible component $Y$ of codimension one, then the local ring $\mathcal{O}_{\mathfrak{p}}$ of the corresponding prime $\mathfrak{p}$ should be non-regular. Is this true? If so where can I find the proof?","['commutative-algebra', 'algebraic-geometry', 'definition']"
1124486,27 Lines on a Cubic,"In Ravi Vakil's notes, there is a proof (in section 27, of course) of the famous result that every nonsingular cubic hypersurface in $\mathbb{P}^3_k$ over an algebraically closed field $k$ has exactly 27 lines. In the proof, we set up an incidence correspondence in Exercise 27.3.A, show that it is an 19-dimensional irreducible nonsingular variety, then use the facts about dimensions of fibers in Exercise 27.3.B to show that every cubic has a line, and that a dense open subset of the space of cubics have only finitely many lines on them. Then in 27.3.2, the proof that there are 27 lines on every nonsingular cubic surfaces, it says that $\pi$ (the map from our incidence correspondence to the space of cubics) has dimension 0 over the entire locus of nonsingular cubics. But it seems based off the exercise that we should only be able to conclude that $\pi$ is of dimension 0 over a dense open subset of the set of nonsingular cubics.  What am I missing? Any help is appreciated.","['geometry', 'algebraic-geometry']"
1124506,Cauchy-Riemann Equations Written as Complex Conjugate,"Apparently, it can be shown that the Cauchy-Riemann equations can be written simply as, $df/dz^*=0$. I do not understand how it does not immediately follow from this that $df/dz=0$. When we proved the relations originally, we used
$$\frac{df}{dz} = \frac{\delta u+i\delta v}{\delta x+i\delta y}$$
Taking both the limits $\delta x\to0$ and $\delta y \to 0$, and requiring they be equal for the derivative to be defined. Doing the same thing for $df/dz^*$, we get exactly the same thing for $\delta x\to 0$. Since this has to be zero, haven't we also shown that $df/dz=0$ if $df/dz^*$ is defined? Or am I missing something obvious? Thanks!",['complex-analysis']
1124507,Is it possible to find the area of a shape from its perimeter?,Is it possible to find the area of a free form shape knowing the perimeter?  An example would be a clover leaf shape.  If the perimeter is 96 how would I know what the area would be?,"['geometry', 'calculus', 'area']"
1124518,"Is there a name for this special, ""most parallel"" ultraparallel line in hyperbolic geometry?","Suppose you're in the hyperbolic plane, and you have a line L and a point P not through L. There are an infinite number of lines parallel to L that go through P. However, there's one line M which is ""special"" in that the closest that it gets to L is exactly P. One way to construct this line is to draw the perpendicular from P down to L, then obtain M by drawing the perpendicular through L at P. Another way, in the Klein model, is to get the unique chord M going through P which is ""parallel"" to L if L and M are both extended outside of the disk to the rest of the Euclidean plane. I believe this line should also be the ""bisector"" of the angle made by the asymptotic limiting parallels to L which go through P. Does this line have a name in the hyperbolic geometry literature? It is, in a certain sense, the ""most parallel"" line to L going through P.","['hyperbolic-geometry', 'geometry', 'terminology']"
1124529,Short intervals with all numbers having the same number of prime factors,"How to prove that for some $k, n_0$, for all $n \ge n_0$ it is never the case that all integers in $\{n, n+1, \dots, n + \lfloor (\log{n})^k \rfloor\}$ have exactly the same number of prime factors counted with multiplicity? I can prove that for any $\epsilon \gt 0$, there exists $n_0$ such that for $n \ge n_0$ not all integers in $\{ n, \dots, n + \lfloor n^\epsilon \rfloor \}$ have the same number of prime factors: assuming that they all have $x$ prime factors, we must have $x \gt \log_2{n^\epsilon} = \epsilon \cdot \log_2{n}$ because the number in the interval divisible by the largest power of $2$ has at least that many factors.  So the smallest prime factor of any number in that range is at most $n^\frac{1}{x} \le n^{\frac{1}{\epsilon \cdot \log_2{n}}} = 2^{\frac{1}{\epsilon}}$ which is constant, and for sufficiently large $n$ we have a contradiction.  I think the same argument might work for even smaller intervals like $\{n, n+1, \dots, \lfloor n+n^\frac{1}{\log{\log{n}}} \rfloor\}$. The harder problem with $(\log{n})^k$-size intervals is implied by Cramér's conjecture (since with $k \gt 2$ there would always be a prime and a non-prime) but not vice-versa and it seems like it might be tractable given that I can solve the $n^\epsilon$-size case.  How to prove it?","['prime-numbers', 'number-theory']"
1124538,"Solution of 2nd order linear ODE with regular singular points, and complex exponents at singularity","The steady state temperature distribution of a rod given by:
    \begin{equation}
        \frac{\textrm{d}p(x)y'}{\textrm{d}x} - y = 0,\; 0 \leq x \leq 1,\; \text{and} \;y(0) = 0,
    \end{equation} where $y(x)$ is the steady state temperature distribution, and $p(x) = x^s$ is the spatially dependent conductivity of the rod, for some $s \in [0, 1)$. For $0 \leq s < 1$ what is the form of the solution close to $x = 0$ (i.e. the first the term of the series solution)? Does a solution exist for $s = 1$? $s > 1$? First, simplify the equation into a recognizable form:
    \begin{align*}
        &\quad \frac{\textrm{d}p(x)y'}{\textrm{d}x} - y = 0 \\
        &\equiv p(x)y'' + p'(x)y' - y = 0 \\
        &\equiv y'' + \frac{p'(x)}{p(x)}y' - \frac{1}{p(x)} y = 0 
    \end{align*} Since $p(x) = x^s$, thus $p'(x) = sx^{s-1}$ and $p''(x) = s(s-1)x^{s-2}$. Substituting:
    \begin{align*}
        &\quad y'' + \frac{p'(x)}{p(x)}y' - \frac{1}{p(x)} y = 0 \\
        &\equiv y'' + \frac{s}{x}y - \frac{s^2 - s}{x^2}y = 0
    \end{align*} We can immediately recognize that $x = 0$ is a regular singular point since:
    \begin{align*}
        &\lim_{x\rightarrow 0}  \frac{sx}{x} = s
        &\lim_{x\rightarrow 0} -\frac{(s^2 - s)x^2}{x^2} = s - s^2
    \end{align*}
It is worth noting that these limits exist for all $s$. So, we look for solutions of the form:
    \begin{align*}
        y = \sum_{n=0}^{\infty} a_nx^{n+r}
    \end{align*}
where $r(r-1) + sr + (s - s^2) = 0 = r^2 + (s-1)r + (s - s^2)$ is the corresponding indical equation. Solving for $r$, we obtain:
    \begin{align}
        \nonumber &\quad r = \frac{-(s-1) \pm \sqrt{(s-1)^2 - 4(s - s^2)}}{2} \\
        \nonumber &\equiv r = \frac{-(s-1) \pm \sqrt{s^2 - 2s + 1 - 4s + 4s^2}}{2} \\
        &\equiv r = \frac{-(s-1) \pm \sqrt{5s^2 - 6s + 1}}{2}
    \end{align} For what values of $s$ do we get imaginary $r$? That would be when the discriminant of the quadratic formula is less than zero: 
    \begin{align*}
        5s^2 - 6s + 1 < 0
    \end{align*}
Consider when $s = 0$:
    \begin{align*}
        &\quad 5s^2 - 6s + 1 = 0 \\
        &\equiv s = \frac{6 \pm \sqrt{36 - 20}}{10} \\
        &\equiv s = \frac{6 \pm \sqrt{16}}{10} \\
        &\equiv s = \frac{6 \pm 4}{10} \\
        &\equiv s = 1 \vee s = \frac{1}{5}\\
    \end{align*}
Since for $(s=0 \wedge d = 5s^2 - 6s + 1) \implies d = 1$, then we know that the discriminant is positive for all values of $s \leq \frac{1}{5}$ and $s \geq 1$, and we have:
    \begin{align*}
        r_1 &= \frac{-(s-1) + \sqrt{(s - 1)(s - \frac{1}{5})}}{2} \\
        r_2 &= \frac{-(s-1) - \sqrt{(s + 1)(s - \frac{1}{5})}}{2}
    \end{align*} The general solution is of the form:
    \begin{equation*}
        y = c_1\sum_{n = 0}^{\infty} a_nx^{n + r_1} + c_2\sum_{n = 0}^{\infty} a_nx^{n + r_2}
    \end{equation*}
where $a_n$ might be complex if $\frac{1}{5} s < 1$ We know that $y(0) = 0$, therefore:
    \begin{align*}
        &\quad y(0) = 0 = c_1\sum_{n = 0}^{\infty} a_n0^{n + r_1} + c_2\sum_{n = 0}^{\infty} a_n0^{n + r_2} \\
        &\equiv 0 = c_1\sum_{n = 0}^{\infty} a_n + c_2\sum_{n = 0}^{\infty} a_n \\
        &\equiv 0 = (c_1 + c_2) \\
        &\equiv c1 = -c_2
    \end{align*} The first term of this series is:
    \begin{align*}
        \nonumber &\quad c_1\left(a_0x^{r_1} - a_0x^{r_2}\right) \\
        \nonumber &\equiv c_1a_0\left(x^{\frac{-(s-1) + \sqrt{(s - 1)(s - \frac{1}{5})}}{2}} - x^{\frac{-(s-1) - \sqrt{(s - 1)(s - \frac{1}{5})}}{2}}\right) \\
    \end{align*}
Let $\frac{1 - s}{2} = \alpha$ and $\frac{\sqrt{(s - 1)(s - \frac{1}{5})}}{2} = \beta$
If $0 \leq s \leq \frac{1}{5}$:
    \begin{equation*}
        y \approx c_1a_0\left(x^{\alpha + \beta} - x^{\alpha - \beta}\right)
    \end{equation*} If $\frac{1}{5} < s < 1$:
    \begin{equation*}
        y \approx c_1a_0\left(x^{\alpha + i\beta} - x^{\alpha - i\beta}\right)
    \end{equation*}
Recall that:
    \begin{align*}
        &\quad x^r = e^{rln(x)} \\
        &\implies x^{\lambda + i\mu} = e^{\lambda\ln(x)}e^{i\mu\ln(x)} \\
        &\equiv x^{\lambda + i\mu} = e^{\lambda\ln(x)}(\cos(\mu\ln(x)) + i\sin(\mu\ln(x))) 
    \end{align*}
So we have oscillatory solutions.
Thus: 
    \begin{equation*}
        y \approx c_1a_0x^{\alpha}\left(2i\sin(\beta\ln(x))\right)
    \end{equation*} Since the limits determining if $x = 0$ is a regular point exist for all $s$, we can write a (non-trivial) Frobenius series solution for all values of $s$. Questions: 1) I have not used information about $0 \leq s < 1$, which is bothersome. Did I miss an opportunity to use it to simplify the form of the first term? 2) Is my reasoning for why solutions exist for $s = 1$ and $s > 1$ sound?","['ordinary-differential-equations', 'solution-verification']"
1124563,Distance between four points,"I have four points as shown in this figure: I want to calculate one vector for all these points. So, what would be the correct way: 1) I take the vector between $A-B, B-C, C-D$ and add them $(A-B + B-C + C-D)$ — for example: 
$$A-B = (x_2-x_1)i + (y_2-y_1)j + (z_2-z_1)k$$
2) Directly take the vector between $(A-D)$, would it be the same? Or is there any other possible solution?","['geometry', 'contest-math']"
1124578,"Solve $(\alpha,\beta)$ for $\lim_{n\to\infty} \frac{\sqrt[n^2]{1!2!\cdots n!}}{n^\alpha} = \beta$","Find the ordered pair $(\alpha,\beta)$ with non-infinite $\beta \ne 0$ such that $$\lim_{n\to\infty} \frac{\sqrt[n^2]{1!2!\cdots n!}}{n^\alpha} = \beta$$ My approach: $$\ln (1!2!\cdots n!) = (n)\ln 1 + (n-1)\ln 2 + \cdots + (2)\ln (n-1) + \ln(n) \\ \begin{align} = n\ln\left(\frac{1}{n}\right) + (n-1)\ln\left(\frac{2}{n}\right) + \cdots + \ln\left(\frac{n}{n}\right) + \frac{(n)(n+1)}{2} \ln (n)\end{align}$$ Then $$\ln(\sqrt[n^2]{1!2!\cdots n!}) = \frac{1}{n^2} \ln(1!2!\cdots n!) = \frac{n+1}{n} \cdot \ln n + \frac{1}{n} \left[\sum_{m=1}^n \left(\frac{n+1-m}{n} \cdot \ln \frac{m}{n}\right)\right]$$ And that's about as far as I got. Any ideas about proceeding with this method or perhaps even with a different method? Thanks A","['summation', 'calculus', 'limits']"
1124622,Can someone explain the basic idea behind the sectional curvature formula?,"I found the following equation on Wikipedia here : \begin{equation}
K(u,v)={\langle R(u,v)v,u\rangle\over \langle u,u\rangle\langle v,v\rangle-\langle u,v\rangle^2}
\end{equation}
No explanation I could understand was given for where this formula comes from or why it represents sectional curvature. Can someone just briefly summarize how this formula works in words? How does it let me measure sectional curvature?","['riemannian-geometry', 'differential-geometry']"
1124635,Am I solving this question correctly?,"How can I evaluate the following term:
$$\left((\{a,b\}\cup\{b,a\})\times(\{b,a\}\cap\{a,b\})\right)\setminus
\left((\{b,a\}\setminus\{a,b\})\cup(\{a,b\}\times\{b,a\})\right)$$ You can see the notes to my approach in this picture. Am I solving it correctly?","['discrete-mathematics', 'elementary-set-theory']"
1124657,Can we interchange the Integral and Summation when a limit is $\infty$?,"I was trying to Evaluate the Integral: $$\Large{I=\int_1^{\infty} \frac{\ln x}{x^2+1} dx}$$ $$\color{#66f}{{\frac{1}{x^2+1} = \frac{1}{x^2\left(1+\frac{1}{x^2}\right)}=\frac{1}{x^2}\cdot \frac{1}{1+x^{-2}}=\frac{1}{x^2} \sum_{n=0}^{\infty} \left(\frac{1}{-x^{2}}\right)^{n}}}$$ $${I=\int_1^{\infty} \left(\frac{\ln x}{x^2}-\frac{\ln x}{x^4}+\frac{\ln x}{x^6}+\cdots\right)dx}=-\int_1^{\infty} \sum_{k=1}^{\infty} \frac{\ln x}{(-1)^kx^{2k}} dx$$ Now I would like to interchange the integral and the summation, like : $$-\int_1^{\infty} \sum_{k=1}^{\infty} \frac{\ln x}{(-1)^kx^{2k}} dx=-\sum_{k=1}^{\infty} \int_1^{\infty}  \frac{\ln x}{(-1)^kx^{2k}} dx$$ But I'm not sure  if I can do that when $\infty$ is present (not real)... $$\text{I know that:}$$ $$\bbox[8pt, border: solid 2pt crimson]{-\int_1^{b} \sum_{k=1}^{a} \frac{\ln x}{(-1)^kx^{2k}} dx=-\sum_{k=1}^{a} \int_1^{b}  \frac{\ln x}{(-1)^kx^{2k}} dx}$$ $$\color{crimson}{\text{Where a, b is real}}$$ But is it the same when $a,b=\infty$?","['definite-integrals', 'summation', 'calculus']"
1124670,If $\int _{-\infty}^{\infty}f=1$ then prove that $\int_{-\infty}^\infty\frac{1}{1+f(x)}=\infty$,"Given that $f:\mathbb R\rightarrow (0,\infty)$ is  a measurable function. If $\int _{-\infty}^{\infty}f=1$ then prove that $\int_{-\infty}^\infty\dfrac{1}{1+f(x)}=\infty$ Any hints on how to proceed with this problem Following your notes $\int_{-\infty}^\infty\dfrac{1}{1+f}\geq \int 1-\int f=1.measure (\mathbb R)-1=\infty$",['measure-theory']
1124701,Logic supporting column operations on matrices,"In matrices, we justify row operations by drawing parallels with solving a system of equations i.e.: 1.Interchanging rows = Interchanging equations \ 2.Adding one multiple of a row to another = Adding one multiple of an equation to another \ 3.Multiplying all terms of a row by a constant = multiplying both sides of an equation by that constant. Now, we can do much the same with columns as well. What's the logic supporting column operations? Can we draw a parallel to solving  a system of equations for column operations as well? Thanks!","['matrices', 'linear-algebra', 'systems-of-equations']"
1124734,Inverse limit of $\mathbb{Z}/n\mathbb{Z}$,"I know that this is well-known fact that $$\lim\limits_\leftarrow\mathbb{Z}/n\mathbb{Z}=\prod\limits_p\mathbb{Z}_p,$$ however I don't know the rigorous proof of this. Can anyone give me the explanation? Thanx.","['group-theory', 'number-theory']"
1124771,Using Markov Property in solving PDE/SDE,"I am solving the (boundary?) value problem (from Bjork I think, see below) By Feynman-Kac , any solution has the form of a conditional expectation $$F(t,x) = E[\psi(X_T)|X_t = x]$$ where $$\psi(x) = x^2$$ $\{W_t\}_{t \in [0,T]}$ is standard Brownian motion in the filtered probability space $(\Omega, \mathfrak F, \{\mathfrak F_t\}_{t \in [0,t]}, \mathbb P)$ where $\mathfrak F_t = \mathfrak F_t^W$, the natural filtration of standard Brownian motion. $\{X_t\}_{t \in [0,T]}$ is any (I guess the only different thing is $X_0$, and that doesn't matter?) stochastic process in the same probability space satisfying either of the two SDEs $$dX_t = \pm \sigma dW_t$$ and thus $$X_T = X_t \pm \sigma (W_T -W_t)$$ So, I try to evaluate $$E[\psi(X_T)|X_t] \tag{*}$$ and then replace $X_t$ with $x$ as follows: $$(*) = [(X_t \pm \sigma (W_T -W_t))^2|X_t]$$
$$ = E[X_t^2 \pm 2\sigma (W_T -W_t)X_t + (\sigma (W_T -W_t))^2|X_t]$$
$$ = E[X_t^2|X_t] \pm 2\sigma E[(W_T -W_t)X_t|X_t] + E[(\sigma (W_T -W_t))^2|X_t]$$
$$ = X_t^2 \pm 2\sigma X_t E[(W_T -W_t)|X_t] + E[(\sigma (W_T -W_t))^2|X_t]$$
$$ = X_t^2 \pm 2\sigma X_t E[W_T -W_t|X_t] + (\sigma^2)E[(W_T -W_t)^2|X_t]$$ $$ = X_t^2 \pm 2\sigma X_t E[W_T -W_t|\mathscr F_t] + (\sigma^2)E[(W_T -W_t)^2|\mathscr F_t] \tag{**}$$ $$ = X_t^2 \pm 2\sigma X_t E[W_T -W_t] + (\sigma^2)E[(W_T -W_t)^2]$$ $$ = X_t^2 \pm 2\sigma X_t (0) + \sigma^2(T-t)$$ $$ = X_t^2 + (\sigma^2)(T-t)$$ $$\to E[\psi(X_T)|X_t] = X_t^2 + \sigma^2(T-t)$$ $$\to E[\psi(X_T)|X_t=x] = x^2 + \sigma^2(T-t)$$ $$\to F(t,x) = x^2 + \sigma^2(T-t)$$ About the use of the Markov property in $(**)$, I know that $W_T - W_t$ is independent of $\mathfrak{F_t}$, but I think that $$X_t \ \in \ m \mathfrak F_t \ \to \ W_T - W_t \ \text{is independent of} \ X_t \tag{3}$$ If $(3)$ is wrong, why? If $(3)$ is right, does this mean we don't need to use the Markov property? Everything after $(2)$ holds if we replace $\mathscr F_t$ with $X_t$? Why/Why not? The problem seems to be taken from Bjork's Arbitrage Theory in Continuous Time. I got the problem from my class notes. Neither Bjork nor Wikipedia seems to use the Markov property","['stochastic-processes', 'partial-differential-equations', 'probability-theory', 'stochastic-calculus', 'stochastic-differential-equations']"
1124779,"$\land,\lor$ and $\lnot$ determinate a functionally complete basis","I read that a Boolean algebra is defined by the binary operations $\land$ and $\lor$ and the unary operation $\lnot$ on a set such that $$\varphi\land(\psi\land \chi)=(\varphi\land \psi)\land \chi,\quad \varphi\lor(\psi\lor \chi)=(\varphi\lor \psi)\lor \chi$$
$$\varphi\land \psi=\psi\land \varphi,\quad \varphi\lor \psi=\psi\lor \varphi$$
$$\varphi\lor (\psi\land \chi) = (\varphi\lor \psi) \land (\varphi \lor \chi)   ,\quad	\varphi \land (\psi\lor \chi) = (\varphi \land \psi) \lor (\varphi \land \chi) $$ $$\varphi \lor (\varphi \land \psi) = \varphi,\quad \varphi\land (\varphi\lor \psi) = \varphi$$ $$\varphi\land 0 =0,\quad \varphi\lor1=1$$ $$\varphi\lor\lnot \varphi=0,\quad \varphi\land\lnot \varphi=1$$ The text states that $\land,\lor$ and $\lnot$ determinates a functionally complete basis in the sense that any function $\{0,1\}^n\to\{0,1\}$ can be expressed by using such operations, and I would like to understand a proof of that. I have verified that the statement is true for $n=2$. Moreover, I know that the number of all the functions mapping $\{0,1\}^n$ into $\{0,1\}$ are $2^{2^n}$ and I supposed I could verify by induction that we can write all the functions $\{0,1\}^n\to\{0,1\}$ with $\land,\lor$ and $\lnot$, but I am not able to prove it to myself. Could anybody prove it here or give a link to some on line resource? I heartily thank you!","['boolean-algebra', 'discrete-mathematics']"
1124793,Martingale with respect to a decreasing filtration,"I am trying to solve problem 2.16 from the book ""Continuous Martingales and Brownian Motion"" by Revuz and Yor. There are two things that confuse me from the exercise so hopefully someone can shed some light into the subject. For the Standard Brownian Motion $B$, set $\mathcal G = \sigma\,(B_u, u \geq t)$. I have to prove that for every real $\lambda$, the process 
$$M_t = \exp\left(\frac{\lambda B_t}{t}-\frac{\lambda^2}{2t}\right), \,\,\,\, t > 0$$
is a martingale with respect to the decreasing family $\mathcal G_t$ . This confuses me, as normally these proofs involve proving that a stochastic process is a martingale with respect to a natural (increasing) filtration adapted to the process in question, so I wonder what could be the applications of working with such family. The exercise also includes the following hint: observe that $\left(B_s - \frac{s}{t}B_t\right)$ is independent of $\mathcal G_t$ for $s<t$ OR use time-inversion. How can one use time-inversion to prove the above argument? Thanks everyone in advance.","['stochastic-processes', 'martingales', 'stochastic-analysis', 'probability-theory', 'stochastic-calculus']"
1124799,Uniqueness of determinant,"In Artin Algebra 2nd edition page 22, the author proved the uniqueness of determinant by saying that any matrix $A$ can be written in reduced row-echelon form $A'$: $A'=E_1\cdots E_kA$ where $E_i$ are the elementary matrix. Then $A'$ is either $I$ or has a zero row. If $A'=I$, then $\delta(A')=1$. Otherwise, $\delta(A')=0$. In both cases, $\delta(A')$ is determined, and hence by
$$\delta(A')=\delta(E_1)\cdots\delta(E_k)\delta(A)$$
$\delta(A)$ is determined uniquely. However, as he himself pointed out immediately in the following paragraph, the sequence $E_1\cdots E_k$ is not unique. Then why is $\delta(A)$ uniquely determined? Edit:
The author defined determinant as a function $\delta(A)=d\in \mathbb{R}$ satisfying the following 3 conditions: (i) $\delta(I)=1$ (ii) $\delta$ is linear in the rows of the matrix $A$ (iii) If two adjacent rows of $A$ are equal, then $\delta(A)=0$ He then proved that the above conditions imply some properties that all of us know, e.g., (a) Interchanging two rows reverses the sign (b) If $A$ has a zero row, then $\delta(A)=0$ (c) Multiplying one row by a number and adding it to another row doesn't change the determinant (d) $\delta(E)=\pm1$ or $c$ (e) $\delta(AB)=\delta(A)\delta(B)$ Then he proved that the function $\delta$ so defined is unique, as shown in the beginning of my post, which I don't understand","['linear-algebra', 'determinant']"
1124801,Crossed Ladders Problem,"I tried to use the angles ( $\cos$ and $\tan$ ) and the Intercept theorem but I don't know where is the trench in the figure. Is it just the base? Could someone write down the steps by drawing each figure that's gonna be needed in your proof? I think it usually leads to polynomial equations of degree 4: $$x^4-6x^3-36x^2+216x-324=0$$ but I'm not sure and I need the steps for writing it in LaTex. I think it is about $$6,326 m $$ by using Newton's method .","['geometry', 'nonlinear-system', 'algebra-precalculus', 'polynomials', 'quartics']"
1124812,"Given that a,b,c are distinct positive real numbers, prove that (a + b +c)( 1/a + 1/b + 1/c)>9","Given that $a,b,c$ are distinct positive real numbers, prove that $(a + b +c)\big( \frac1{a}+ \frac1{b} + \frac1{c}\big)>9$ This is how I tried doing it: Let $p= a + b + c,$ and $q=\frac1{a}+ \frac1{b} + \frac1{c}$. Using AM>GM for $p, q$, I get: $$\frac{p+q}{2} > {(pq)}^{1/2}$$
$$\sqrt{(a + b +c)\bigg(\frac1{a}+ \frac1{b} + \frac1{c}\bigg)} < \frac{\big(a+\frac1{a} + b+\frac1{b} + c+\frac1{c}\big)}2$$
And for any $x\in \mathbb{R}, \space \space x+\frac1{x}≥2.$ Thus, $$(a + b +c)\bigg(\frac1{a}+ \frac1{b} + \frac1{c}\bigg)<9, $$
which is the opposite of what had to be proven. What did I do wrong?","['inequality', 'algebra-precalculus']"
1124834,Weil divisors fail over singular varieties,"Let be $k$ an algebraically closed field. We know that if $X$ is an irreducibile, normal variety, one can associate to every rational function $(f)\in k(X)^*$ a Weil principal divisor $$(f)=\sum_{Y} \nu_Y Y$$ where $Y$ varies among prime divisors of $X$ and $\nu_Y $ is the valutation morphism associated to the ring $\mathscr{O}_{X,Y}$. As the theory of Weil divisors is developed over normal or locally factorial varieties, I wonder if there is an example where this correspondence fails. Does anyone have an hint for a counter-example of rational function
  over a singular variety that can't be associated to a Weil divisor
  over $X$?","['geometry', 'algebraic-geometry', 'commutative-algebra', 'algebraic-curves']"
1124852,"Why are functional analysts interested in not only the point spectrum of $f$, but also, its spectrum?","Suppose $\mathbb{K}\in \{\mathbb{R},\mathbb{C}\},$ that $X$ is a Banach space over $\mathbb{K}$, and that $f : X \leftarrow X$ is a bounded linear transform. Then the spectrum of $f$ is defined as the set of all $\lambda \in \mathbb{K}$ such that $f - (\lambda \cdot \mathrm{id}_X)$ fails to be invertible in the category $\mathbf{Ban}$ of Banach spaces and bounded linear transforms, and the point spectrum of $f$ is defined as the set of all eigenvalues of $f$, i.e. the set of all $\lambda \in \mathbb{K}$ such that $f-(\lambda \cdot \mathrm{id}_X)$ fails to be injective. I don't get why we should care about the spectrum of $f$, as opposed to the point spectrum. In fact, even the point spectrum seems like an ""auxiliary"" construction to me. The way I see it, what we really want is to understand the ""eigenspace function"" $\mathrm{Eig}_f : \mathrm{Sub}(X) \leftarrow \mathbb{K}$ into the linear subspaces of $X$ given as follows. $$x \in \mathrm{Eig}_f(\lambda) \iff f(x) = \lambda x$$ In order to learn things about $\mathrm{Eig}_f$, one strategy would be to first try to find the set of all $\lambda \in \mathbb{K}$ such that $\mathrm{Eig}_f(\lambda)$ has elements beyond $0$. This is precisely the point spectrum of $f$. The hope is that by first finding the point spectrum, we will know for which $\lambda \in \mathbb{K}$ we ought to ""look further."" This motivates the importance of the point spectrum of $f$, but makes no mention of the spectrum. So: Question. Why are functional analysts interested in not only the point spectrum of $f$, but also, its spectrum?","['motivation', 'functional-analysis']"
1124917,Limit $I=\lim_{n \to \infty } \sqrt[n]{\int_0 ^1 x^{\frac{n(n+1)}{2}}(1-x)(1-x^2)\cdots(1-x^n)d x}$,"Im a new participant in this mathematical forum, so this is one of that i couldn't solve it. $$I=\lim_{n \to \infty } \sqrt[n]{\int_0 ^1 x^{\frac{n(n+1)}{2}}(1-x)(1-x^2)\cdots(1-x^n)d x}$$ I've tried to transform the product in a summation as function of a logarithmic function, and I wasn't been successful. Like $u=x^n$, $du=nx^{n-1}dx$ $g_n(u) = \sqrt[n]{\frac{ dx}{du} \cdot x^{\frac{n(n+1)}{2}} \cdot \prod_{k=1}^n(1 - x^k)}$ $g_n(u)=\sqrt[n]{\frac{1}{nx^{n-1}}} \cdot x^{\frac{n+1}{2}} \cdot e^{\frac 1n\sum_{k=1}^n \ln(1 - x^k)}$","['sequences-and-series', 'integration', 'limits']"
1124929,Clarification from old post: Union of sigma-algebras is non sigma-algebra,"I have been working on slightly different problem from one posted back in 2013 here . I followed closely the hints given by @martini there, but nevertheless I still got stuck. I am retyping the question here not to duplicate but for your convenience: Suppose $\mathscr A_1 \subset \mathscr A_2 \subset \ldots$ are $\sigma$-algebras of subsets of set $X$ . Give example of $\bigcup_{i=1}^{\infty} \mathscr A_i$ that is non $\sigma$-algebra. (The 2013 old post did not have the phrase in bold .) And to that question @martini suggested to generate an example using natural numbers $\mathbb N$ and $F_n = \{\{1\}, \{2\}, \ldots \{n\}\}$, which I think makes sense and is relevant for my question. Here are what I have gone so far: (1) Let $F_n = \{\{1\}, \{2\}, \ldots \{n\}\}$, let $\sigma(F_n)$ be its $\sigma$-algebra, and let make this example simple by making $n=2$ only (2) If $F_1:=\{1\}$, then
$\sigma(F_1)=\{\emptyset,\{1\},\{1\}^c,\mathbb N \}$ (3) If $F_2:=\{\{1\},\{2\}\}$, then $\sigma(F_2)=\{\emptyset,\{1\},\{1\}^c,\{2\},\{2\}^c
 \{1,2\},\{1,2\}^c,\mathbb N\}$ (4) Here $\sigma(F_1) \cup \sigma(F_2)=\sigma(F_2)$, and $\sigma(F_2)$ is a $\sigma$-algebra. Since I am looking for non $\sigma$-algebra, therefore this is not the example I have been looking for. I thinks I have been misunderstanding some concepts from the beginning, but what are they? Thank you for your time and help. NOTE: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ To find out if this posting is a duplicate, I did my due diligence by asking opinions from experienced users here , and prior to that I had tried to post the question outside but got only lukewarm response.","['measure-theory', 'analysis']"
1124930,"Doubt about proof of factorization $f=pi$, where $i$ is acyclic cofibration and $p$ is fibration","I try to understand a proof in More Concise Algebraic Topology: Localization, completions and model categories by May & Ponto ( pdf ). The proof is on page 262, and it is for the statement Any map $f:X\to Y$ factors as the composite of an acyclic cofibration and a fibration The authors proceed as follows. Let $Z_0=X$ and $\rho_0=f$. We assume inductively that we have constructed a map $\rho_n:Z_n\to Y$. We define $N\rho_n$ as the pullback of $Y^I\to Y\leftarrow Z_n$. Where the first map is $\varepsilon_0$ (evaluation at $0$). The composite $N\rho_n\to Y^I\to Y$ can also be written as $N\rho_n\to N\rho_n\times I\to Y$ where the first map is inclusion at $0$ and the second map is the adjunct of the map $N\rho_n\to Y^I$. If we now define $Z_{n+1}$ as the pushout of $N\rho_n\times I\leftarrow N\rho_n\to Z_n$, this induces a unique map $\rho_{n+1}:Z_{n+1}\to Y$ making certain triangles commute. For the first $n$, I have displayed the various arising maps in the following diagram. I hope it's not too confusing, the arrows must be thought of as evolving towards the front for increasing $n$. Let $Z$ be the colimit of the sequence $Z_0\hookrightarrow Z_1\hookrightarrow \dots$, with $\nu:Z_0\hookrightarrow Z$ the initial inclusion into this colimit. Since all the maps $\nu_n$ are acyclic cofibrations, so is $\nu$. If $\rho:Z\to Y$ denotes the map induced by the $\rho_n$, then $\rho\nu=f$, so it suffices to show that $\rho$ is a fibration. This is the case if in the following square there is a lift, where $N\rho$ is the pullback of the diagram $Y^I\to Y\leftarrow Z$. One can show that, since we are working in the category of weak Hausdorff $k$-spaces, the canonical map $\text{colim}N\rho_n\to N\rho$ is a homeomorphism. Also, $\text{colim}(N\rho_n\times I)\cong N\rho\times I$. This way, the map $N\rho\to Z$ is the colimit of the maps $N\rho_n\to Z_n$. So practically all the objects in the square are colimits. Now according to the authors, the diagonal is induced by the maps $\lambda_n:N\rho_n\to Z_{n+1}$. Here comes the point I am doubtful about: I don't see why the square with $\lambda_0$ and $\lambda_1$ commutes. In fact, I'm pretty sure it does not commute: A point in $N\rho_0\times I$ is of the form $(q,z, t)$, which by the map $\lambda_0$ is sent to its equivalence class and then via $\nu_1$ to the class represented by $\left(\overline{q(t)},(q,z,t),0\right)$ (where the bar denotes constant path) while $(q,z,t)$ is sent via the other map to $\left(q,\left(\overline{\rho_0(z)},z,0\right),t\right)$
and then via $\lambda_1$ to that element's equivalence class in $Z_2$. Is there any way how one could use the constructions of pushouts and pullbacks to acquire the desired lift?","['general-topology', 'model-categories', 'category-theory', 'algebraic-topology']"
1124934,Erdős-Szekeres theorem on monotone sequences,"Given a sequence $S$ with $21$ different numbers. It is known that there isn't any monotone subsequence in the length of $6$. Prove that there exists $2$ monotone subsequences, one decreasing and the other increasing, in the length of $5$. Solution: $4\cdot5+1=21$ So according to Erdős-Szekeres we know that there exists an increasing monotone subsequence in the length of $5+1$ or decreasing subsequence in the length of $4+1$, or the other way around. And it's given there is no monotonic subsequence in the length of $6$. Therefore we know that if there isn't a increasing subsequence in the length of $6$ then there is a decreasing subsequence in the length of $5$ and, and if there isn't a decreasing subseqeuence in the length of $6$ there exists an increasing subsequence in the length of $5$. Therefore we have two subseqeuences , one decreasing one increasing in the length of $5$. Can someone verify if this solution is correct. I am not sure if I understood the theorem correctly. Thank you in advance!",['discrete-mathematics']
1124996,Why is Multiplicative Notation Used for Groups (Instead of Additive)?,"In documents relating to group theory it seems common to use a multiplicative notation to represent the group operation. For example, I'm reading Herstein's ""Topics in Algebra"" and looking for some pointers about vector spaces in the section on groups. In the vector space section the group operation combining vectors is (quite logically) represented as addition ($v = v_1 + v_2$), but when I switch across to the section on groups it's multiplication ($c = ab$). Besides finding the switch of notation unhelpful, I feel that the additive notation is a better analogy with real arithmetic: all group elements have an inverse as they do with addition, whereas the multiplicative notation carries an untrue suggestion that there may be a ""0"" which has no inverse. So, have I missed something: is there some reason why the multiplicative notation is preferable ?","['notation', 'group-theory']"
1125001,Solution techniques for f'(x)=f(g(x)),"I stumbled over this seemingly natural question and was surprised, that I couldn't find a satisfying answer. 
Differential equations of the type $f'(x)=g(f(x))$ are studied for all kind of classes of g, but what is there to say about solutions to the opposite case where $f'(x)=f(g(x))$? I even failed to find solutions for the very simple case $f'(x)=f(1-x)$, say on domain $[0,1]$. 
Ultimately I am looking for solutions to 
$ f'(x)=\frac{1-f(x)}{f(1-x)-1+x} $.
Thank you for any helpful comments.","['ordinary-differential-equations', 'functional-equations']"
1125014,Solution of nonhomogenious differential equations,"Kindly help me regarding below math problem.
How can I prove? Show that if $y_1(x)$ is a solution of
  $$y'' + ay' + by = f_1(x)$$
  and if $y_2(x)$ is a solution of
  $$y'' + ay' + by = f_2(x)$$
  then the function $y_1(x) + y_2(x)$ is a solution of
  $$y'' + ay' + by = f_1(x) + f_2(x).$$","['ordinary-differential-equations', 'calculus']"
1125020,Can every differentiable scalar function be written as a divergence of some vector field?,"My question is simple: can every differentiable function $f$ defined on a bounded, connected subset of $\mathbb{R}^3$ be written as a divergence of some vector field ? That is, given the vector field $\mathbf{F}$, you can write:$$f=\nabla\cdot\mathbf{F}$$
Is this always possible? How to prove it?","['multivariable-calculus', 'calculus', 'vector-analysis']"
1125070,Counting the numbers with certain sum of digits.,The question : In how many different numbers between $1$ and $100000000$ have the sum of their digits equal to $45$? I'm thinking about using the stars and bars formula but I'm not sure if it's possible and how. Thanks in advance !,"['discrete-mathematics', 'combinatorics']"
1125078,Not every complex manifold is of the form $X_{an}$ where $X$ is some algebraic variety,"I want to show that not every complex manifold is of the form $X_{an}$ where $X$ is some algebraic variety, providing a counterexample. The candidate for this counterexample seems to be the open unit disk $D$ in $\mathbb{C}$. But how can I proof that $D$ is not isomorphic to a complex analytic manifold $X_{an}$ for any nonsingular curve $X$?",['algebraic-geometry']
1125083,Find $\lim_{x\to \infty}{[({1\over e}(1+{1\over x})^x)]^x}$.,"Find $\lim_{x\to \infty}{[({1\over e}(1+{1\over x})^x)]^x}$. 
I have been trying for hours using the continuity of $e$ and using L'Hopital rule but it gets really scattered and ugly. I am in despaire. I would really, truly, appreciate your help.","['calculus', 'real-analysis', 'limits']"
1125087,Is the Law of Large Numbers empirically proven?,"Does this reflect the real world and what is the empirical evidence behind this? Layman here so please avoid abstract math in your response. The Law of Large Numbers states that the average of the results from multiple trials will tend to converge to its expected value (e.g. 0.5 in a coin toss experiment) as the sample size increases. The way I understand it, while the first 10 coin tosses may result in an average closer to 0 or 1 rather than 0.5, after 1000 tosses a statistician would expect the average to be very close to 0.5 and definitely 0.5 with an infinite number of trials. Given that a coin has no memory and each coin toss is independent, what physical laws would determine that the average of all trials will eventually reach 0.5. More specifically, why does a statistician believe that a random event with 2 possible outcomes will have a close to equal amount of both outcomes over say 10,000 trials? What prevents the coin to fall 9900 times on heads instead of 5200? Finally, since gambling and insurance institutions rely on such expectations, are there any experiments that have conclusively shown the validity of the LLN in the real world? EDIT: I do differentiate between the LLN and the Gambler's fallacy. My question is NOT if or why any specific outcome or series of outcomes become more likely with more trials--that's obviously false--but why the mean of all outcomes tends toward the expected value? FURTHER EDIT: LLN seems to rely on two assumptions in order to work: The universe is indifferent towards the result of any one trial, because each outcome is equally likely The universe is NOT indifferent towards any one particular outcome coming up too frequently and dominating the rest. Obviously, we as humans would label 50/50 or a similar distribution of a coin toss experiment ""random"" , but if heads or tails turns out to be say 60-70% after thousands of trials, we would suspect there is something wrong with the coin and it isn't fair. Thus, if the universe is truly indifferent towards the average of large samples, there is no way we can have true randomness and consistent predictions--there will always be a suspicion of bias unless the total distribution is not somehow kept in check by something that preserves the relative frequencies. Why is the universe NOT indifferent towards big samples of coin tosses? What is the objective reason for this phenomenon? NOTE: A good explanation would not be circular: justifying probability with probabilistic assumptions (e.g. ""it's just more likely""). Please check your answers, as most of them fall into  this trap.","['statistics', 'applications', 'law-of-large-numbers', 'probability']"
1125088,Torsion-freeness is not affine local,"I am working on an ""unimportant"" exercise (c.f. Vakil, exercise 13.5.J) which goes as follows Exercise 13.5.J: Find an example on a two-point space showing that $M:=A$ might not be a torsion-free $A$ -module even though $\mathcal{O}_{SpecA}=\tilde{M}$ is torsion-free. So what I gather from this question is to show an (affine?) scheme with two points over which $M$ might not be torsion-free even though localisation of $M$ at every point is. If I were to construct a scheme with two points, that would probably be something like $\text{Spec}(\mathbb{C}\times\mathbb{C})$ . But I run into trouble soon because of the following confusion: If $A$ is torsion-free, it means for all $ab=0$ , either $a$ is a zero divisor or $b=0$ . So for $A$ to be not torsion-free means there exists a relation $ab=0$ such that both $a$ is not a zero divisor and $b\neq 0$ , which to me is ridiculous... How should I solve this question? Am I going in a wrong direction? (i.e. misinterpret the definition of torsion-free sheaves etc)",['algebraic-geometry']
1125089,Quadratic Transformation to make a point simple,"This is exercise 7.21 from Fultons ""Algebraic Curves"" . Let $X$ be a nonsingular projectiv curve, $P \in X$. Show that there is a projective plane curve $C$ with only orinary multiple points and a birational morphism $f:X \rightarrow C$ such that $f(P)$ is simple on $C$. I do have a birational morphism from $X$ to a proj. plane curve with only ordinary multiple points, but i dont know how to make $f(P)$ simple. Fulton gives the hint to do quadratic transformation centered at $f(P)$ but i dont understand how this leads to $f(P)$ becoming simple. I don't even really understand where the point $f(P)$ is after the transformation since ""centered at $f(P)$"" means that after a coordinate transformation $f(P)$ is the point $(0,0,1)$ on which the quadratic transformation is not defined. I would really appreciate some help with this. Ok, after reading some additional stuff it seems that the point $f(P)$ is ""replaced"" by points $P_1,\ldots,P_r$ on the transformed curve with multiplicities $s_1,\ldots,s_r$ and $\sum s_i \leq r$ if $r$ is the multiplicity of $f(P)$. And in ""Lectures on Curves,Surfaces and Projective Varieties, A Classical View on Algebraic Geometry "" they say that this way the multiplicities can be reduced to $1$ by successive quadratic transformation. But I don't understand why there cant just be one point with multiplicity $r$.","['algebraic-geometry', 'curves']"
1125096,Can this special case happen when working with L'Hopitals rule?,"I am using this version of L'Hopital's rule Assume that $\lim_{x \rightarrow a}f(x)=\lim_{x \rightarrow a}g(x)=0$, and that the limit-value $\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$ exists
(could be $\infty$  or $-\infty$). Then the limit 
value $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ also exsits, and
$\lim_{x \rightarrow a} \frac{f(x)}{g(x)}=\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$. I have two questions: When we have said that $\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$, exists, then we have also said that $g'(x)$ is not zero around $a$ , so this does not create a problem? This is my main question: Could there be a special case, where the hypothesis of the rule is satisfied, but for every neighbourhood around $a$ , there is an $x$ such that $g(x)=0$, and so that $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ is not defined, and hence the rule stated as it is, is wrong? Because the rule says that the limit value of $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ exists if the hypothesis is satisfied? (The reason I am suspecting this is what I write below about Cauchy's Mean Value Theorem). On Wikipedia: http://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule they assume that $g'(x)$ is not zero. But they do not say anything about $g(x)$, how do we know that there are not infinitely many points around $a$ , where $g$ is zero? The reason I am asking is that they use Cauchy's mean value theorem in my book for the proof. http://en.wikipedia.org/wiki/Mean_value_theorem#Cauchy.27s_mean_value_theorem But when using the form with fractions, they have to assume that the denominator is not zero? It doesn't say that if $g'(c)$ is non-zero then $g(b)-g(a)$ is nonzero, we are only allowed to go to the fraction part of the theorem if we know that both is non-zero?","['calculus', 'derivatives', 'real-analysis', 'limits']"
1125097,Stirling Numbers Proof,"Let $n > 1$ be an integer. Prove the following: $$\sum\limits_{k=1}^{\infty} (-1)^k (k - 1)! S(n,k) = 0$$ where $S(n,k)$ is a Stirling number of the second kind . (Hint: Recurrence Relation) Workings: The recurrence relation of Stirling numbers of the second kind I believe is: $S(n+1,k) = k S(n,k) + S(n,k-1)$ Though I do not see how this will potentially help out. Any help will be appreciated.","['recurrence-relations', 'combinatorics']"
1125138,How to prove that $A × (B ∩ C) = (A × B) ∩ (A × C)$?,"I have to prove that $A × (B ∩ C) = (A × B) ∩ (A × C)$. While I know this is true by thinking about it I'm having a lot of trouble actually writing the proof. I'm relatively new to proofs so I have a lot of difficulty writing the equations that are necessary for the proof, all I really know how to do is write the whole thing out in words which isn't a very good proof.",['elementary-set-theory']
1125188,There is a primitive $m^{th}$ root of unity in $\mathbb{Q}_p$ $\Leftrightarrow m \mid (p-1)$,"After Hensel's Lemma there is the following proposition in my notes: If $p$ is a prime and $m \in \mathbb{N}$ then there is a primitive $m^{th}$ root of unity in $\mathbb{Q}_p$ $\Leftrightarrow m \mid (p-1)$. To prove this proposition we begin as follows: $(\Rightarrow) $ Let $a$ be a primitive $m^{th}$ root of unity in $\mathbb{Q}_p$. That means that $m$ is the smallest natural number such that $$a^m \equiv 1 \pmod p$$ (correct?) Can we suppose that $m$ and $p$ are coprime, and use Fermat's little theorem we have that $a^{p-1} \equiv 1 \pmod p$? Can we conclude from this that $m \mid (p-1)$? How do we prove the other direction? Perhaps using Hensel's Lemma?","['p-adic-number-theory', 'number-theory', 'abstract-algebra', 'algebraic-number-theory', 'hensels-lemma']"
1125226,Determining if a function is one-to-one or onto.,"We have two sets: $\{1,2\}$ and $\{a,b,c\}$ . How would I go about listing the functions between these two sets and then identifying if those functions are either one-to-one or onto? Would the functions be $(1,a)(2,a)$ etc?","['discrete-mathematics', 'elementary-set-theory']"
1125233,Show that integral of Gaussian distribution is 1,"Under a normal distribution, μ = 0 and σ = 1, but when then integrating this equation, I get an error function. Without using Riemann sums, how can I prove that this equation = 1? I have only had a year of calc, no multivar.","['gaussian-integral', 'integration']"
1125255,When are vector bundles on toric varieties also toric varieties?,"Let $X$ be a toric variety, and $\pi:E\to X$ a vector bundle, say of rank $2$. You can think of $X=\mathbb P^1$. When is the total space of $E$, or of $P(E)$, a toric variety? What do I need in order to lift the torus action on $X$ to a torus action on $E$, or on $P(E)$, so to get an open orbit? I ask this because I was reading this thesis , and on page $2$ I found the following statement, which I do not understand: If a vector bundle over a toric variety splits as a sum of line bundles, then its projectivization admits a toric variety structure"". I want to understand at least the case of $\mathbb P^1$, where every vector bundle splits. But I have no idea why the splitting is so relevant in general.","['algebraic-geometry', 'toric-varieties']"
1125259,How to find $\lim\limits_{n\to \infty }(1 + \frac{1}{n})^n$,"$\lim _{n\to \infty }\left(1 + \frac{1}{n}\right)^n$ How do I get started with this one? Variable substitution would be one way, but our lecturer hasn't covered that yet, so there should be some other way. Usually with these kinds of limits we modify the function so that it resembles one of the standard limits that we may use without proving them.","['limits-without-lhopital', 'limits']"
1125263,One problem on set theory having two parts,"Problem: Let $S$ be a universal set and $A$ be a fixed subset of $S$ . If $A\cup B = B$ holds for all subset $B$ , prove that $A = \varnothing$ , If $A\cap B= B$ holds for all subset $B$ , prove that $A =S$ What I have tried is the following Let $x \in A$ then $x\in A\cup B \Rightarrow x\in B \Rightarrow A \subset B$ .",['elementary-set-theory']
1125288,"Find $F'(t)$, where F is an integral","I need to find $F'(t)$, where $F(t)=\int_{[0,t]^2}e^{\frac{tx}{y^2}}dxdy$. My first approach: Let's observe that $\int e^{\frac{tx}{y^2}}dx=\frac{y^2}{t}e^{\frac{tx}{y^2}}+C$. So I get: $$F(t)=\int_{[0,t]^2}e^{\frac{tx}{y^2}}dxdy=\int_{0}^{t}\frac{y^2}{t}e^{\frac{t^2}{y^2}}-\frac{y^2}{t}dy$$ But now the integral isn't so easy. Has anybody got any ideas? Is there a better way to find the derviative of $F$ or do I need to calculate it like that?","['multivariable-calculus', 'calculus', 'analysis']"
1125291,How many expressions can be formed with two commutative and associative functions?,"EDIT: I have posted a generalization of this question to MathOverflow here . Suppose we have two binary functions $f,g$ which are commutative and associative, i.e., satisfying
$$ f(a,b) = f(b,a) \qquad g(a,b) = g(b,a)$$
$$ f(a,f(b,c)) = f(f(a,b),c) \qquad g(a,g(b,c)) = g(g(a,b),c)$$
for all $a,b,c$. If we have $n$ indeterminates $x_1, x_2, \ldots, x_n$, what is the number $a_n$ of distinct expressions can we produce using $f,g$ and one of each indeterminate? For example, in the case $n=3$, the expressions $f(x_1, f(x_2, x_3))$ and $f(x_1, g(x_2, x_3))$ are clearly distinct. However, $f(f(x_2, x_1), x_3)$ is equivalent to the first, and $f(g(x_3, x_2), x_1)$ is equivalent to the second. Using a simple brute force search, the first few terms of the sequence $(a_n)$  are
$$1, 2, 8, 52, \ldots$$
which correspond to several sequences in OEIS.","['functions', 'combinatorics']"
1125320,Polya's urn model - limit distribution,"Let an urn contain $w$ white and $b$ black balls. Draw a ball randomly from the urn and return it together with another ball of the same color. Let $b_n$ be the number of black balls and $w_n$ the number of white balls after the $n$ -th draw-and-replacement. Let $X_n$ be the relative proportion of white balls after the $n$ -th draw-and-replacement. I start with $b=w=1$ , so the total number of balls after the $n$ -th draw-and-replacement is $n+2$ .
Now I want to find the limit distribution of $X_n$ ; I already showed that $X_n$ is a martingale and that it converges a.s.
It is $$X_n = \dfrac{w_n}{n+2} \quad\text{for}\quad n \in \mathbb{N}_0. $$ I've read that the limit distribution is a beta distribution, but I don't know how to get there. I could write $w_n$ as the sum of $Y_i$ where $Y_i$ is $0$ , if the $i$ -th ball is black and $1$ , if the $i$ -th ball is black. Then I'd have $$ w_n = 1+\sum_{i=1}^{n} Y_i. $$ Does this help? How can I proceed? Thanks! :)","['stochastic-processes', 'convergence-divergence', 'probability-theory', 'polya-urn-model', 'probability-distributions']"
1125334,Help with $\lim_{x\rightarrow +\infty} (x^2 - \sqrt{x^4 - x^2 + 1})$ [duplicate],This question already has answers here : Limits: How to evaluate $\lim\limits_{x\rightarrow \infty}\sqrt[n]{x^{n}+a_{n-1}x^{n-1}+\cdots+a_{0}}-x$ (6 answers) Closed 9 years ago . $\lim_{x\rightarrow  +\infty} (x^2 - \sqrt{x^4 - x^2 + 1}) = ?$ I don't know how to solve the indetermination there... is it possible to rearrange the expression in brackets in order to use L'Hospital or Taylor Series?,"['radicals', 'calculus', 'limits']"
1125335,"Matrix function to express pair-wise distances of rows in $X, Y$","There are two real matrices: $X, Y$ with $X$ being of dimension $n_1$ x $p$, $Y$ of dimension $n_2$ x $p$. The goal is to form the matrix $D$ of dimension $n_1$ x $n_2$ where each element $d_{ij}$ is computed as the (L2-) norm of the difference of row i of X and row j of Y: $$d_{ij} = \lVert x_i - y_j \rVert_2^2$$ My question is how to derive a matrix formula for $D$. I.e $$D = g(X,Y)$$ Here is my attempt at starting: I can expand $\lVert v\rVert_2^2$ as $v^Tv$ where $v = x_i - y_j$ to obtain: $$d_{ij} = x_i^Tx_i + y_j^Ty_j - 2x_i^Ty_j$$ But I'm not sure how to proceed.","['matrix-equations', 'matrices', 'normed-spaces', 'linear-algebra']"
1125378,"Construction of a triangle given some special points ($O,H,I$)","I'm a newbie in this site. I tried to search if this question was already answered but I'm not sure on how to do it. The problem is: given three distincts points $O,H,I$ namely the circumcenter, the orthocenter and the incenter of a triangle $\triangle ABC$ , construct $\triangle ABC$ . What have I tried: $$\left| \overline{OI} \right| ^2 = R^2 - 2Rr$$ Taking the midpoint $N$ of $\ \overline{OH} $ (center of the nine point circle) we have: $\left| \overline{NI} \right| = \frac{R-2r}{2}$ So it seems to me we can obtain $R$ and $r$ from these points. I also tried to solve it using complex numbers it looked like this: Let $a^2,b^2,c^2$ be the vertexes of $\triangle ABC$ in the complex plane in which the origin is the circumcenter let us also define $R=1$ (so $|a|=|b|=|c|=1)$ to simplify. Then we have that the orthocenter $H=a^2+b^2+c^2$ and the incenter $I=ab-ac +bc$ to find a solution to my problem is to find $a^2,b^2,c^2$ in terms of $H$ and $I$ but it was too complex to me. This complex approach indicates that the reflection of the incenter with respect to the circumcenter is important.
  Another cool distance formula is $\left| \overline{OH} \right|^2 = 9R^2 - (a^2+b^2+c^2)$ with $a,b,c$ being the sides of $\triangle ABC$","['geometry', 'triangles', 'geometric-construction']"
1125388,Almost every graph is asymmetric?,"Here is a question: If i choose at random an isomorphism class of graph(no loops, undirected) on n vertices(with uniform probability on the set of such isomorphism classes), is the probability that the resulting graph has trivial automorphism group, going to 1 as n goes to $+\infty$? I guess yes, but i do not have a neat argument. Thanks for any suggestion. Edit 1: I have the same question restricted to the isomorphism classes of regular n graph(each vertex the same degree). Do the asymmetric one appear almost surely also in this restricted space of graphs? Edit 2: in the comment it turns out that is a theorem of Erdős, the first question. I'm still interested in knowing if my question in Edit 1 has been already answered.","['graph-theory', 'random-graphs', 'combinatorics']"
1125413,Law of total probability explanation,What is the intuition behind the law of total probability? http://en.m.wikipedia.org/wiki/Law_of_total_probability,['probability-theory']
1125488,Determining density involving scaled beta distribution,"Suppose $Y \sim \mathrm{Beta}(2,1)$. If $X = \theta{Y}$ (for some $\theta > 0$) how do I determine the joint density $f(x, \theta)$? Edit: the density for $Z$ is $2z$. Would it be correct to say, then, that $$f(x, \theta) = \frac{2}{\theta} x$$","['statistics', 'probability', 'probability-theory']"
1125550,Determine the region of convergence of series of complex functions,"I have this problem. Find the region of convergence of the following series of complex functions $$
\sum_{n=1}^\infty \frac{2^n}{z^{2n}+1}
$$ The progress I have made so far is that when n goes to infinity $f_n$ has a singularity everywhere in the border of the unit disc. So my intuition tells me that the series converges in the unit disc, although I don't know how to prove this.","['sequences-and-series', 'complex-analysis']"
1125566,"How to make a ""function""?","I dropped out of school early when I was still a teenager and now I'm trying to take my GED. I'm really close to passing but I'm still having trouble understanding some concepts. In the pre-test, there is this question: Add one number to each column of the table so that it shows a function. Do not repeat an ordered pair that is in the table. $$\begin{array}{c|c}
x & y \\
\hline
6 & 6 \\
3 & 8 \\
9 & 12 \\
7 & 8 \\
\fbox{?} & \fbox{?}
\end{array}$$ $$\fbox{ 3 }\quad\fbox{ 6 }\quad\fbox{ 7 }\quad\fbox{ 8 }\quad\fbox{ 9 }\quad\fbox{ 12 }$$ I'm not entirely sure what a function is, and I have found some questions on SE explaining it, I'm not really getting any of it. It's all confusing. So I was hoping if someone could explain this question to me, and  what's the answer, and why. I'm hoping this could help me understand the concept.","['algebra-precalculus', 'functions']"
1125576,Parametric representation of a line segment with boundaries,"Let $S$ be a subset of $\mathbb{R}^n$. $S$ is called convex if for all pairs of $(a, b)$, line segment from $b$ to $a$ is element of $S$. It is also given that $at + (1 - t)b$ is line segment between two vectors, for $0 < t < 1$. I can't see how $at+(1-t)b$ is found, and why boundary for $t$ is important.","['multivariable-calculus', 'linear-algebra', 'elementary-set-theory']"
1125587,Euclidean Geometry challenge.,"Can someone help me on this one? I have found that $\frac{1}{(x+1)^2}+1=\frac{1}{x^2}$, but I can't solve the fourth degree equation that comes with it. There must be a easier way!",['geometry']
1125594,Two questions about discrete valuation rings of varieties,"Let $X$ be a proper, normal variety over $\mathbb{C}$, and $k(X)$ be its field of rational functions. I think the following two statements are true, but I was unable to give a proof or find the references: (1) For any $f \in k(X), f \neq 0$, there are only finite discrete valuations $v$ of $k(X)$ such that $v(f) \neq 0$. (2) For any discrete valuation $v$ of $k(X)$, there exists a variety $Y$, birational to $X$, and a Weil divisor $E$ such that the valuation given by this divisor is the same as  $v$. Any suggestion for either problem is welcome!","['commutative-algebra', 'algebraic-geometry', 'birational-geometry']"
1125598,Power set of a set containing a set,"I need some help understanding this concept a little better. I understand the general power sets, but only worked nice and easy examples where only the set consisted of only single elements like $\{a,b,c\}$. I can do that power set, but I am confused on the power set of a set containing a set. The problem I am trying to work is $\{a,\{a,b\}\}$. Typically when you have a set $\{x,y\}$ the power set is $\{\{x\},\{y\},\{x,y\}\}$ so would this problem be similar to that where $\{y\}=\{a,b\}$? Or would I then need to perform a second power set on the inner set?","['data-analysis', 'computer-science', 'elementary-set-theory']"
1125641,Is there a function that can reproduce this simple pattern?,"input:  0, 1, 2, 3, 0, 1, 2, 3...
output: 0, 1, 1, 0, 0, 1, 1, 0... I'm trying to resolve a function that takes the input and produces the corresponding output but despite how simple it looks, i can't quite seem to figure it out. Any suggestions?",['functions']
1125667,complex analysis differentiation and existence of a point?,"If $f(z) = z^3$
prove that there is no point $c$ on line segment $[1,i]$ 
s.t. $(f(i)-f(1)) / (i-1) = f'(c)$. So differentiating:
$$f'(c) = 3c^2$$
$$3c^2 = (f(i)-f(1))/(i-1) = (-i-1)/(i-1) = i$$ Hence $c = \sqrt{i/3}$. Am i doing this right? 
Could anyone also clarify what the line segment $[1,i]$ means?
Is it the diagonal line from the real axis $1$ to the Im axis $i$?","['derivatives', 'complex-analysis']"
1125716,Rewrite $\sin(\omega t)$ in terms of exponentials,Could someone please give me a pointer or two. I am trying to rewrite $\sin(\omega t)$ and it should be something similar to $\dfrac{e^{2j\omega t}-e^{-2j\omega t}}{2j}$ but I can't quite seem to get it right.,['trigonometry']
1125725,Prove that $\left| f'(x)\right| \leq \sqrt{2AC}$ using integration,"Suppose that $f(x)$ is a $C^2$ function on $\mathbb{R}$ such that $\left| f(x) \right| \leq A$ and $\left| f''(x) \right| \leq C $ for $x \in \mathbb{R}$.
Prove that $\left| f'(x)\right| \leq \sqrt{2AC}$.","['calculus', 'integration', 'real-analysis', 'analysis']"
1125758,Poisson complete statistic,"I have the same question as this thread, but I cannot understand the proof. The problem is, given $f(\lambda)=\sum_{k=0}^\infty g(k)\frac{(n\lambda)^k}{k!}=0,\forall\lambda>0$. How to show $g(k)\equiv0$? The accepted answer in that thread claims that $f(0)=g(0)$. Why? I believe $f(0)=0$. But I cannot see why $g(0)=0=f(0)$. One comment claims ""an infinite summation is zero iff each term in it is identically zero"". But there is no proof. So, can anyone prove $g(k)\equiv0$ or the claim ""an infinite summation is zero iff each term in it is identically zero""? Thanks!","['statistics', 'poisson-distribution', 'taylor-expansion', 'analysis']"
1125766,Proving that two summations are equivalent: $\sum_{i=1}^n i^3 = (\sum_{i=1}^n i)^2$ [duplicate],"This question already has answers here : Proving $1^3+ 2^3 + \cdots + n^3 = \left(\frac{n(n+1)}{2}\right)^2$ using induction (16 answers) Closed 9 years ago . Give a constructive proof to show that for all $n \geq 1$ , $\sum\limits_{i=1}^n i^3 = (\sum\limits_{i=1}^n i)^2$ Observe that $(n+1)^4 - n^4 = 4n^3 + 6n^2 + 4n + 1$ . Now, the two following equalities are obvious: $\sum\limits_{i=1}^n i^3 = 1^3 + 2^3 + 3^3 + ... + n^3$ $(\sum\limits_{i=1}^n i)^2 = (1 + 2 + 3 + ... + n)^2$ And they are both obviously equivalent given the first few test cases: $\sum\limits_{i=1}^n i^3 = A(n)$ $A(1) = 1^3 = 1$ $A(2) = 1^3 + 2^3 = 1 + 8 = 9$ $A(3) = 1^3 + 2^3 + 3^3 = 9 + 27 = 36$ $(\sum\limits_{i=1}^n i)^2 = B(n)$ $B(1) = (1)^2 = 1$ $B(2) = (1 + 2)^2 =9 $ $B(3) = (1 + 2 + 3)^2 = 36$ Now, I am thinking of finding the closed-forms for both functions in the hopes that they are indeed the same. Then I would prove those closed forms to work by induction. But: I don't know if that would be a sound way to do it. I don't know if this would even qualify as constructive, as the question requests. As you may tell, I am no math major. I am a Computer Science major, though. This is a computing fundamentals class. I took discrete 1.5 years ago, so my knowledge is about as fresh as a litter box. I've been in quite a rut for a few hours over this.","['induction', 'summation', 'discrete-mathematics']"
1125803,Is this a valid way to show that the recursive sequence $x_n = x_{n-1} + \frac{1}{x_{n-1}^2}$ is unbounded?,"I'm working through some analysis textbooks on my own, so I don't want the full answer. I'm only looking for a hint on this problem. Rosenlicht's Introduction to Analysis asks me to prove that $x_n = x_{n-1} + \frac{1}{x_{n-1}^2}$, where $x_1 = 1$, is unbounded. I'm not sure how to approach this, but here's what I tried. To save myself typing, I let $b := x_n$ and $a := x_{n-1}$. Since $b > a > 1$ as $n \to \infty$, we know that \begin{align}
b &> a \\
e^{\ln b} &> e^{\ln a} \\
\frac{e^{\ln b}}{e^{\ln a}} &> 1 \\
e^{\ln b - \ln a} &> 1
\end{align} but I'm not sure where to go from here, or if this is even the right direction. I'm trying to show that $b - a > \ln b - \ln a$, because then I can say that the sequence is always growing faster than the logarithmic function, which I know is unbounded. To show that $b - a > \ln b - \ln a$, I tried proof by contradiction. If $b - a \le \ln b - \ln a$, then $e^{b-a} \le e^ {\ln b - \ln a}$. Thus $\frac{e^b}{e^a} \le \frac{e^{\ln b}}{e^{\ln a}} = \frac{b}{a}$, and once again I'm not sure where to go. I know that to show something is bounded, I need to show that $\exists M > 0$ s.t. $x_n < M, \forall n$. I know how to do that with non-recursive sequences, e.g. $x_n = f(n), n \in \mathbb{N}$ because it's just algebra, but I'm not sure how to go about this with a recursive sequence (once that I wasn't successful at putting in non-recursive terms).","['sequences-and-series', 'real-analysis', 'limits']"
1125869,What is the period of $\sin 2\theta + \sin \frac{\theta}{2}$ [duplicate],This question already has answers here : Principal period of $\sin\frac{3x}{4}+\cos\frac{2x}{5}$ [duplicate] (2 answers) Closed 9 years ago . What is the period of $\sin 2\theta  + \sin \frac{\theta}{2}$? The period of the first term is $\pi$ and that of the second is $4\pi$. Does that mean that the period of the whole is $4\pi$?,"['trigonometry', 'real-analysis', 'periodic-functions']"
1125876,Borderline case of interpolation of Banach spaces,"Let $B \subset A$ be Banach spaces with a continuous embedding . Is the inequality
$$
\|b\|_B
\leq
C \sup_{t > 0} \inf_{\tilde{b} \in B} \{ \|b - \tilde{b}\|_B + t \|\tilde{b}\|_A \}
\quad
\forall b \in B
$$
valid for some $C \geq 1$? What if the embedding is compact? For example , take the sequence spaces $B := \ell_2$ and $A := \ell_\infty$ with norms $|\cdot|_\infty \leq |\cdot|_2$. 
Let $b \in \ell_2$. 
Let $K \geq 0$ be the $\sup \inf$. Then, for any $t > 0$, 
the infimizer satisfies $|\tilde{b}|_\infty \leq K / t$,
and reduces each component of $b$ by at most $K/t$:
$$
\inf_{\tilde{b} \in \ell_2}
\{ |b - \tilde{b}|_2 + t |\tilde{b}|_\infty \}^2
\geq
\sum_{n} \max\{ 0, |b_n| - K/t\}^2 
.
$$
This sum goes to $|b|_2^2$ as $t \to \infty$, implying the inequality with $C = 1$.","['interpolation-theory', 'functional-analysis', 'banach-spaces']"
1125878,"A starting lineup consists of 2 forwards, 2 guards and 1 center. How many different starting lineups..","A certain school has $4$ forwards, $4$ guards, $3$ centers and $1$ person who can play as either a forward or a guard. How many different starting lineups can be made? I came up with 2 answers to this problem. However I don't know which one is right and I can't tell the difference between the two: Solution 1:
There are two possibilities, X is a forward, in which there is $\binom{5}{2}\binom{4}{2}\binom{3}{1} = 180$ ways of making this starting lineup. X could be a guard as well, which results in the same number, $180$ ways of making the starting lineup. Add together to get $360$ different ways of making this starting lineup. Solution 2:
There are three possibilities which encompass all possible starting lineups: x is not picked, x is picked as a forward, and x is picked as a guard. When x is not picked, there is $\binom{4}{2}\binom{4}{2}\binom{3}{1} = 108$ different lineups without x in it. when x is picked as a forward, you only need to pick one more forward, so there is $\binom{4}{1}\binom{4}{2}\binom{3}{1} = 72$ different lineups with x as forward. the same number will result when you pick x as a guard: $72$. adding $108+72+72$ results in $252$ different lineups. So the problem is that I can't see the fault in logic in either of my solutions. Which one is the right one? edit: centers","['statistics', 'combinatorics']"
1125910,Product Manifold: Tangent Spaces,"Problem Given a product manifold. How to prove that its tangent spaces split into direct sums:
  $$T_{(p,q)}(M\times N)\cong T_pM\oplus T_qN$$ Attempts One could try the geometric perspective:
$$\Phi:T_{(p,q)}(M\times N)\to T_pM\oplus T_qN:[(\alpha,\beta)]\mapsto([\alpha],[\beta])$$
$$\Psi:T_pM\oplus T_qN\to T_{(p,q)}(M\times N):([\alpha],[\beta])\mapsto[(\alpha,\beta)]$$
Then bijectivity becomes pretty easy but linearity quite nasty. (Besides it is well-defined.) One could also try the algebraic perspective:
$$\Phi:T_{(p,q)}(M\times N)\to T_pM\oplus T_qN:\delta\mapsto(d_{(p,q)}\pi_M\delta,d_{(p,q)}\pi_N\delta)$$
Then linearity becomes evident but bijectivity becomes pain. (Besides there's an explicit but ugly inverse.) Is there maybe some nice trick??",['differential-geometry']
1125915,"Limit points of the differential system $\dot {x}=y-x+x^3$, $\dot{y}=-x$","Consider the following system of differential equations:
$$\dot
{x}=y-x+x^3,\qquad
\dot{y}=-x.$$
By linearization, it's easy to see that $(0,0)$ is a (nonlinear) sink. Show that there exists an open connected set $D$ such that if $\phi^t:\mathbb{R}^2\rightarrow \mathbb{R}^2$ is the solution flux,
  then $\lim\limits_{t\rightarrow +\infty} \phi^t(x_0,y_0) = (0,0)$ iff $(x_0,y_0) \in D$ and such that $\partial D$ is compact and invariant, that is, such that $\phi^t(x_0,y_0) \in \partial D$ for all $t \in \mathbb{R}$ and $(x_0,y_0) \in \partial D$. Maybe this can be done with a substitution (to show  that this system behaves like for instance $\dot
{r}=r(r-1)$, $\dot{\theta}=1$)
or by finding a function $f \in C^1(\mathbb{R}^2,\mathbb{R})$ such that $(0,0)$ is a minimum for $f$, $\nabla f(z) \cdot \dot{z}<0$ for every $z=(x,y)$ in $D$, and $\nabla f(z) \cdot \dot{z}=0$ for every $z=(x,y)$ in $\partial D$.","['dynamical-systems', 'ordinary-differential-equations']"
1125923,Proving Pascal's identity,"So I came across Pascal's identity: Prove that for any fixed $r\geq 1$, and all $n\geq r$,
$$
\binom{n+1}{r}=\binom{n}{r}+\binom{n}{r-1}.
$$ I know you can use basic algebra or even an inductive proof to prove this identity, but that seems really cumbersome. I was wondering if anyone had a ""cleaner"" or more elegant way of proving it. For example, I think the following would be a decent combinatorial proof. Proof: Let $S$ be a set with $n+1$ elements, and consider some fixed $x\in S$. There are $\binom{n+1}{r}\;\; r$-subsets of $S$--count them according to whether or not they contain $x$: there are $\binom{n}{r}$ not containing $x$, (each formed by choosing $r$ of the remaining $n$ elements in $S\setminus\{x\}$), and there are $\binom{n}{r-1}\;\; r$-sets containing $x$, (each formed by selecting an additional $r-1$ elements in $S\setminus\{x\}$). Is that right? Are there any other efficient ways of doing it?","['binomial-coefficients', 'proof-verification', 'combinatorics']"
1125926,Finding the unit normal vector,"Q. Consider the following vector function. $$ r(t)= \langle 6\sqrt{2}t,e^{6t},e^{-6t} \rangle $$ Find the unit tangent and unit normal vectors T(t) and N(t). I found $$T(t)= \frac{1}{\sqrt{2+e^{12t}+e^{-12t}}}\langle \sqrt{2},e^{6t},-e^{-6t}\rangle $$ but when I try finding $N(t)=T'(t)/|T'(t)|$ the calculations just go out of hand and I cannot reach an answer. Can someone please help me in finding the answer.","['multivariable-calculus', '3d', 'calculus', 'differential-geometry']"
1125928,Understanding Lipschitz domain,"Here is the definition of Lipschitz domain given by Wikipedia. Let n ∈ N, and let Ω be an open subset of Rn. Let ∂Ω denote the boundary of Ω. Then Ω is said to have Lipschitz boundary, and is called a Lipschitz domain, if, for every point p ∈ ∂Ω, there exists a radius r > 0 and a map $h_p$ : $B_r(p)$ → Q such that (i) $h_p$ is a bijection; (ii) $h_p$ and $h^{-1}_p $ are both Lipschitz continuous functions; (iii)$h_p$(∂Ω ∩ Br(p)) = $Q_0$ (iv) $h_p$(Ω ∩ Br(p)) = $Q_+$; where
$B_{r} (p) := \{ x \in \mathbb{R}^{n} | \| x - p \| < r \}$
denotes the n-dimensional open ball of radius r about p, Q denotes the unit ball B1(0), and $Q_{0} := \{ (x_{1}, \dots, x_{n}) \in Q | x_{n} = 0 \}$; $Q_{+} := \{ (x_{1}, \dots, x_{n}) \in Q | x_{n} > 0 \}$. Then, it says that  ""a Lipschitz domain (or domain with Lipschitz boundary) is a domain in Euclidean space whose boundary is ""sufficiently regular"" in the sense that it can be thought of as locally being the graph of a Lipschitz continuous function."" What I do not understand is the part that says that the boundary of Lipschitz can be thought of as the graph of a Lipschitz continuous function. What does it mean by the graph of a Lipschitz function?
Which Lipschitz function does it talk about?  Does it refer to the function $h_p$ as given above? Please help me understand this!!","['differential-geometry', 'partial-differential-equations', 'real-analysis']"
1125939,How can I prove this integral is equal to f(0)?,"Given that $f$ continuous over $[-1,1]$, how can I show 
$\lim_{x \to 0}\frac{1}{x}\int_0^xf(t)dt = f(0)$?
I know the limit of $\frac{1}{X}$ doesn't exist at 0, and it's negative infinity from the left and positive infinity from the right, but I'm not sure how that helps anything.","['calculus', 'integration', 'limits']"
