question_id,title,body,tags
2060998,Count elements in a cyclic group of given order,"For example, how many elements of order $3$ are in 
$$\{e,\sigma,\sigma^2\}$$
My way:
exclude $e$, consider $\sigma\ne e$, $\sigma^2\ne e$ but $\sigma^3=e$ hence $\sigma$ is of order 3. Same as $\sigma^2$. Given a cyclic group of arbitrary order, say $$\{e,\sigma,\sigma^2,\cdots,\sigma^N\}$$
How many elements are of order $n\leq N$? There is a formula to verify one by one: $$G=<a>,O(a)=n,O(a^m)=\frac{n}{gcd(m,n)}$$ but is rather laborious","['abstract-algebra', 'group-theory']"
2061012,"All continuous functions $f: \mathbb{R} \to \mathbb{R}$ satisfying $n^2 \int_x ^{x + {1\over n}} f(t)\,dt = nf(x) + {1\over2}$?","As the question title suggests, what are all continuous functions $f: \mathbb{R} \to \mathbb{R}$ satisfying$$n^2 \int_x^{x + {1\over n}} f(t)\,dt = nf(x) + {1\over2},$$for any $x \in \mathbb{R}$ and any positive integer $n$, $n \ge 2$?","['derivatives', 'real-analysis', 'calculus', 'functions', 'integration']"
2061024,How should I solve this quesiton on Integration?,"I want to answer this question:
If
$$
\lim_{n \to\infty} n^k \int_0^{1/n} x^{x+k-1} dx = f(k)
$$
for $k \in \mathbb N$, what is
$$
\left[\frac{1}{f(5)}\right],
$$
where square brackets denote the greatest integer function (i.e., ceil)? I tried it by substituting $t = x + k - 1$, but got stuck.","['integration', 'calculus', 'limits']"
2061030,Local holomorphic charts of the torus,"Let $\mathbb{C} \backslash \mathbb{Z}^2$ be the usual torus, seen as a holomorphic manifold. What are the most usual local holomorphic charts that are used to study this holomorphic manifold ? I have the same question for the general torus $\mathbb{C}^n \backslash \Lambda$. I've seen a lot of documentation about these torus but not the charts written in an explicit way.","['complex-geometry', 'complex-analysis', 'differential-geometry']"
2061035,Eigenvalues of $AB$ and $BA$ are the same?,"In the MIT linear algebra online lecture, when doing SVD, Gilbert Strang said that the eigenvalues of $AB$ and $BA$ are the same. I was trying to prove this as follows: Let $A$ be $m \times n$ matrix and $B$ be $n \times m$ matrix. Then $AB$ is $m \times m$ and $BA$ is $n \times n$. Let
$$ABx=\lambda x$$
Then
$$BA(Bx)=\lambda(Bx)$$
and $\lambda$ is an eigenvalue of $BA$ as well, and vice versa. Q.E.D. However, after a second thought I think the above proof has a pitfall. Namely, if $x$ is in the null-space of $B$ then $BA$ needs not have eigenvalue $\lambda$. So my questions is: Is the statement that $AB$ and $BA$ have the same eigenvalues true for general $m \times n$ matrix $A$ and $n \times m$ matrix $B$? If yes, how to prove it? If no, is it true for the special case when $B=A^\dagger$? And how to prove it?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2061066,Proof of an equivalent definition of strictly convex?,"$X$ is a normed space. If for all $x,y\in X$ such that $\|x\|=\|y\|=1, x\neq y$, we have that $\|\frac{x+y}{2}\|<1$, then we know that $X$ is strictly convex. How can I show that for all $\lambda \in (0,1)$, $\|\lambda x + (1-\lambda) y\|<1$ always holds?","['functional-analysis', 'normed-spaces', 'convex-analysis']"
2061091,"Proof that all natural numbers can be compared with each other from Halmos' ""Naive Set Theory""","I'm having a hard time understanding a proof from ""Naive Set Theory"" by Paul Halmos. First of all, Halmos defines $\mathbb{N}$ as an intersection of all inductive subsets of any inductive set $I$. ($I$ is inductive if $\varnothing \in I$ and $x \in I \Rightarrow x\cup \{ x \} \in I$). He then proceeds to proof that $\cap \{ A \subseteq I \ | \ A$ is inductive $\}$ doesn't depend on the choice of $I$, that is, $\mathbb{N}$ is well-defined. He also denotes $\varnothing$ by $0$ and $n \cup \{n \}$ by $n^{+}$ in the context of $\mathbb{N}$ Now, what I don't understand is the following proof ($p.51$ of the book): Two natural numbers $m$ and $n$ are comparable is $m \in n, \ n \in m,$ or $m = n$.
  Any two natural numbers are comparable. Proof: For any $n \in \mathbb{N}$, $S(n) = \{ m \in \mathbb{N} \ | \ m$ and $n$ are comparable $\}$. Then $S = \{ n \in \mathbb{N} \ | \ S(n) = \mathbb{N} \}$ The proof is by induction. First, we show that $0 \in S$ ( $ \Leftrightarrow S(0) = \mathbb{N}$).
  Clearly $0 \in S(0)$ (as $0 = 0$). If $m \in S(o)$, then it's either $0 \in m$ or $0 = m$. In the latter case, $0 \in m^{+}$, so $m^{+} \in S(0)$. In the former case, $0 \in m\cup \{ m \} = m^{+}$ as $0 \in m$. So, by induction, $S(0) = \mathbb{N}$, and $0 \in S$. Now, assume that $n \in S$. That is, $S(n) = \mathbb{N}$. We now need to prove that $n^{+} \in S$, that is, $S(n^{+}) = \mathbb{N}$.
  Clearly, $0 \in S(n^{+})$ (as $n^{+} \in S(0)$). Now, assume $m \in S(n^{+})$. 
  It follows that $m \in n^{+} , \ n^{+} \in m$ (in which case $n^{+} \in m^{+}$) , or $m = n^{+}$ (in which case $n^{+} \in m^{+}$). In the first case, it's either $m = n$, or $m \in n$. If $m = n$, we're done.
  If $m \neq n$, then $m \in n$. The last case splits according to the behavior of $m^{+}$ and $n$: since $m^{+} \in S(n)$ , we must have either $n \in m^{+}, \ n = m^{+},$ or $m^{+} \in n$. What I don't understand is the bold-faced part in the last paragraph. Why we have $m^{+} \in S(n)$ then?","['proof-explanation', 'elementary-set-theory', 'elementary-number-theory']"
2061109,Is there an algebraic number of degree at least 3 such that the partial quotients on its continued fraction are bounded by any reasonable function?,"Let $$2^{1/3}=a_0+\frac{1}{a_1+\dots}$$ be the canonical continued fraction of $2^{1/3}$. It is relatively easy to prove that if $a_n<10\phi^n$ then the equation $x^3-2y^3=1$ has no nontrivial integer solutions (this equation has no solutions anyway, but it would be an interesting alternative, and relatively easy, proof). The first few terms actually are: $2^{1/3}= $[1; 3, 1, 5, 1, 1, 4, 1, 1, 8, 1, 14, 1, 10, 2, 1, 4, 12, 2, 3, 2, 1, 3, 4, 1, 1, 2, 14, 3, 12, 1, 15, 3, 1, 4, 534, 1, 1, 5, 1, 1, 121, 1, 2, 2, 4, 10, 3, 2, 2, 41, 1, 1, 1, 3, 7, 2, 2, 9, 4, 1, 3, 7, 6, 1, 1, 2, 2, 9, 3, 1, 1, 69, 4, 4, 5, 12, 1, 1, 5, 15, 1, 4, 1, 1, 1, 1, 1, 89, 1, 22, 186, 6, 2, 3, 1, 3, 2, 1, 1, 5, 1, 3, 1, 8, 9, 1, 26, 1, 7, 1, 18, 6, 1, 372, 3, 13, 1, 1, 14, 2, 2, 2, 1, 1, 4, 3, 2, 2, 1, 1, 9, 1, 6, 1, 38, 1, 2, 25, 1, 4, 2, 44, 1, 22, 2, 12, 11, 1, 1, 49, 2, 6, 8, 2, 3, 2, 1, 3, 5, 1, 1, 1, 3, 1, 2, 1, 2, 4, 1, 1, 3, 2, 1, 9, 4, 1, 4, 1, 2, 1, 27, 1, 1, 5, 5, 1, 3, 2, 1, 2, 2, 3, 1, 4, 2, 2, 8, 4, 1, 6, 1, 1, 1, 36, 9, 13, 9, 3, 6, 2, 5, 1, 1, 1, 2, 10, 21, 1, 1, 1, 2, 1, 2, 6, 2, 1, 6, 19, 1, 1, 18, 1, 2, 1, 1, 1, 27, 1, 1, 10, 3, 11, 38, 7, 1, 1, 1, 3, 1, 8, 1, 5, 1, 5, 4, 4, 4, 7, 2, 1, 21, 1, 1, 5, 10, 3, 1, 72, 6, 9, 1, 3, 3, 2, 1, 4, 2, 1, 1, 1, 1, 2, 1, 7, 8, 1, 2, 1, 8, 1, 8, 3, 1, 1, 3, 2, 1, 8, 1, 1, 1, 1, 1, 6, 1, 4, 3, 4, 1, 1, 1, 4, 30, 39, 2, 1, 3, 8, 1, 1, 2, 1, 3, 1, 9, 1, 4, 1, 2, 2, 1, 6, 2, 1, 1, 3, 1, 4, 1, 2, 1, 1, 5, 1, 2, 10, 1, 5, 4, 1, 1, 4, 1, 2, 1, 1, 2, 12, 2, 1, 8, 3, 2, 6, 1, 3, 10, 1, 2, 20, 1, 6, 1, 2, 186, 2, 2, 1, 2, 47, 1, 19, 2, 2, 1, 1, 1, 2, 1, 1, 3, 2, 8, 1, 18, 3, 5, 39, 1, 2, 1, 1, 1, 1, 4, 1, 5, 2, 6, 3, 1, 1, 1, 4, 2, 1, 6, 1, 1, 220, 1, 3, 1, 3, 1, 4, 5, 1, 2, 1, 13, 2, 2, 2, 1, 1, 1, 1, 7, 2, 1, 7, 1, 3, 1, 1, 11, 1, 2, 2, 4, 2, 33, 3, 1, 1, 2, 6, 3, 1, 1, 3, 6, 8, 3, 4, 84, 1, 1, 2, 1, 10, 2, 2, 20, 1, 3, 1, 7, 13, 14, 1, 29, 1, 1, 5, 1, 7, 1, 1, 2, 1, 56, 1, 3, 2, 1, 13, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 255, 2, 4, 5, 1, 1, 1, 3, 1, 3, 3, 1, 6, 1, 1, 6, 1, 71, 1, 9, 1, 2, 1, 11, 5, 1, 25, 1, 6, 67, 2, 9, 6, 1, 5, 2, 15, 1, 2, 48, 2, 7, 1, 3, 1, 4, 21, 1, 1, 2, 1, 27, 3, 26, 2, 1, 1, 2, 5, 7, 3, 7451, 2, 29, 4, 3, 8, 17, 3, 8, 2, 3, 1, 1, 1, 5, 113, 1, 3, 4, 1, 4, 1, 1, 13, 1, 34, 1, 2, 7, 1, 3, 3, 7, 1, 3, 1, 1, 4, 2, 69, 1, 3, 12, 34, 1, 2, 151, 1, 4941, 4, 1, 1, 12, 3, 4, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 6, 16, 1, 2, 27, 2, 13, 4, 1, 1, 1, 3, 11, 1, 1, 3, 1, 53, 2, 15, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 3, 3, 1, 9, 1, 1, 10, 3, 1, 1, 2, 1, 2, 2, 1, 10, 9, 1, 2, 5, 1, 2, 2, 1, 1, 2, 4, 7, 1, 5, 1, 1, 1, 1, 4, 2, 25, 16, 5, 4, 1, 3, 2, 3, 13, 1, 49, 6, 2, 5, 1, 1, 2, 7, 3, 2, 1, 1, 1, 4, 1, 1, 1, 5, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 4, 1, 2, 1, 10, 5, 4, 8, 10, 2, 4, 1, 1, 1, 4, 1, 41, 1, 3, 1, 56, 3, 1, 1, 3, 1, 3, 1, 5, 6, 6, 3, 1, 2, 1, 1, 1, 12, 1, 10, 2, 1, 1, 1, 1, 50, 5, 1, 2, 6, 5, 1, 2, 5, 6, 5, 2, 77, 1, 4, 2, 1, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 1, 1, 1, 6, 2, 1, 1, 7, 1, 5, 1, 1, 1, 1, 2, 2, 1, 1, 5, 2, 1, 5, 1, 1, 1, 4, 1, 2, 17, 1, 20, 7, 4, 2, 1, 1, 1, 2, 1, 4, 7, 3, 4, 3, 3, 5, 31, 1, 1, 2, 2, 6, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 23, 20, 1, 22, 16, 4, 2, 1, 3, 2, 1, 1, 2, 5, 5, 1, 1, 15, 3, 1, 1, 2, 1, 1, 1, 4, 2, 1, 2, 23, 6, 10, 3, 2, 3, 6, 2, 1, 1, 1, 1, 1, 1, 4, 3, 2, 1, 2, 1, 4, 10, 7, 1, 1, 1, 1, 3, 3, 2, 108, 1, 1, 11, 2, 6, 1, 4, 1, 2, 2, 9, 3, 1, 1, 3, 22, 4, 1, 93, 1, 3, 1, 4, 2, 1, 2, 3, 2, 1, 2, 11, 1, 1, 3, 1, 2, 1, 28, 23, 4, 11, 1, 9, 1, 4, 3, 1, 6, 1, 2, 1, 12, 2, 6, 19, 1, 4, 4, 2, 1, 1, 1, 1, 1, 10, 3, 4, 5, 4, 4, 1, 43, 1, 1, 5, 1, 73, 6, 35, 5, 4, 1, 13, 2, 1, 6, 1, 4, 2, 1, 1, 1, 27, 1, 1, 4, 1, 1, 7, 1, 1, 14, 9, 14, 1, 1, 1, 1, 10, 3, 3, 1, 2, 5, 7, 4, 2, 6, 4, 2, 4, 20, 1, 5, 2, 1, 1, 3, 1, 1, 2, 1, 2, 2, 11, 1, 1, 14, 1, 1, 14, 1, 9, 1, 1, 1, 33, 2, 1, 3, 7, 2, 3, 1, 2, 1, 27, 1, 1, 2, 34, 2, 1, 8, 6, 4, 1, 1, 7, 1, 5, 3, 1, 354, 3, 2, 1, 1, 2, 6, 1, 1, 3, 17, 1, 3, 1, 195, 1, 6, 1, 1, 1, 25, 1, 3, 1, 2, 304, 5, 1, 1, 5, 1, 2, 9, 4, 1, 1, 4, 2, 1, 44, 1, 1, 1, 2, 8, 16, 1, 204, 1, 1, 1, 2, 1, 2, 3, 3, 1, 1, 20, 1, 11, 1, 8, 1, 2, 16, 1, 1, 1, 10, 5, 1, 10, 6, 1, 5, 2, 1, 33, 6, 6, 1, 3, 1, 1, 28, 1, 10, 3, 1, 1, 23, 2, 2, 1, 7, 4, 1, 4, 1, 7, 1, 2, 1, 1, 1, 2, 2, 2, 7, 1, 5, 201, 6, 1, 10, 8, 9, 1, 3, 3, 8, 5, 1, 136, 1, 2, 6, 2, 1, 2, 2, 9, 1, 4, 2, 2, 5, 1, 29, 1, 1, 4, 12, 1, 6, 4, 1, 13, 1, 2, 1, 2, 6, 127, 2, 2, 1, 1, 119, 1, 124, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 10, 1, 9, 3, 2, 3, 2, 4, 1, 8, 1, 2, 2, 2, 3, 1, 8, 1, 4, 3, 2, 8, 3, 1, 3, 1, 6, 3, 2, 4, 1, 3, 4, 1, 1, 5, 1, 4, 4, 9, 2, 3, 16, 1, 1, 2, 1, 3, 16, 1, 4, 2, 1, 10, 1, 4, 1, 2, 6, 4, 1, 5, 6, 2, 1, 1, 1, 6, 1, 1, 11, 1, 2, 23, 1, 7, 11, 2, 2, 1, 4, 1, 2, 1, 2, 49, 8, 1, 3, 3, 1, 1, 3, 2, 2, 2, 1, 1, 1, 1, 4, 2, 1, 4, 1, 2, 8, 1, 9, 3, 9, 1, 1, 5, 23, 5, 11, 1, 1, 1, 1, 1, 90, 2, 1, 5, 56, 1, 2, 3, 1, 8, 85, 1, 1, 131, 2, 1, 4, 2, 1, 1, 37, 1, 14, 1, 5, 2, 4, 1, 1, 1, 11, 1, 1, 1, 2, 2, 1, 1, 1, 52, 18, 4, 7, 2, 101, 2, 1, 119, 1, 1, 1, 3, 1, 13, 3, 1, 1, 6, 1, 1, 27, 2, 1, 2, 3, 3, 4, 3, 11, 1, 5, 3, 1, 9, 1, 1, 15, 1, 1, 2, 1, 2, 4, 15, 2, 1, 2, 7, 1, 5, 1, 6, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 2, 23, 1, 1, 19, 1, 5, 12, 3, 5, 1, 1, 10, 2, 1, 3, 1, 2, 3, 3, 1, 22, 1, 2, 1, 1, 1, 1, 1, 5, 1, 2, 36, 2, 1, 1, 1, 4, 3, 10, 1, 14, 6, 1, 5, 2, 1, 328, 1, 1, 2, 1, 1, 2, 11, 1, 2, 1, 1, 1, 7, 1, 2, 16, 2...] More here . So if we have an even weak upper bound on the coefficients on the continued fraction of an algebraic number we can solve lots of diophantine equations using approximation arguments. I think even something ridiculous like $$\alpha=[a_0;a_1\dots]\implies a_n < e^{e^{e^n}}$$ for some known algebraic $\alpha$ might prove useful. It looks like such a statement should be easy to prove but unfortunately I don't have anything so far.","['number-theory', 'continued-fractions', 'approximation']"
2061119,Proof for if $A$ is invertible then $AB$ is invertible,"First, $A$ and $B$ are square matrices So to prove if $AB$ is invertible, then $A$ is invertible: I let $C=(AB^{-1})B$ Then $CA=(AB^{-1})AB=I$ And $C=A^{-1}$
, so A is invertible. But how do I prove it the other way around? I'm pretty sure this would require that $B$ also be invertible for it to be true. Is there a quick way to disprove that if $A$ is invertible then $AB$ is invertible?","['matrices', 'linear-algebra', 'inverse']"
2061161,Infinite series and the IMO,"I have been stuck at this problem, as my approaches have not led me to the proper result. The problem is as follows: Prove that if $|x| <1$, then $$\frac{x}{(1-x)^2} + \frac{x^2}{(1+x^2)^2} + \frac{x^3}{(1-x^3)^2}\cdots = \frac{x}{1-x} + \frac{2x^2}{1+x^2} +\frac{3x^3}{1-x^3}\cdots$$ I tried finding the generalised term of the two sequences on either side of the equality but I couldn't go in the right approach. Any help is appreciated.",['sequences-and-series']
2061168,Smooth Integrable Functions with Integrable Derivatives,"Let $f: \mathbb{R}^n \rightarrow \mathbb{C}$ be a smooth function, that is $f \in C^{\infty}(\mathbb{R}^n)$, such that $f$ and all its derivatives belong to the Lebesgue space $L^p(\mathbb{R}^n)$, with $1 \leq p < \infty$. I am trying to prove that f must vanish at infinity, that is it satisfies
\begin{equation}
\lim_{|x| \rightarrow \infty} |f(x)| = 0.
\end{equation}
I could only prove the statement for $p=1$ (see the note below).
Any help is welcome. Thank you very much for your attention in advance. NOTE (Motivation and Case p=1) First a matter of notation: if $\beta_i$ is a non-negative integer for $i=1,\dots,n$, we call $\beta=(\beta_1,\dots,\beta_n)$ a multi-index, we set $|\beta|=\beta_1+\dots+\beta_n$ as usual, and 
\begin{equation}
D^{\beta}f = \frac{\partial^{|\beta|} f}{\partial x_{1}^{\beta_1} \dots \partial x_{n}^{\beta_n}}.
\end{equation}
We also denote by $D_i$ the partial derivative with respect to the i-th coordinate. The relevance of the question comes from the fact that the space of functions
\begin{equation}
\mathcal{D}_{L^p} = \left \{ f \in C^{\infty}(\mathbb{R}^n) :  D^{\beta} f \in L^p(\mathbb{R}^n) \textrm{ for each multi-index $\beta$} \right \}
\end{equation}
is relevant in the theory of distributions. This vector space is topologised through the family of semi-norms
\begin{equation}
|| f ||_{p,N} = \max \left \{ || D^{\beta} f ||_p : |\beta| \leq N \right \} \quad \quad (N=0,1,2,\dots),
\end{equation}
where $|| . ||_p$ denotes the norm of the space $L^p(\mathbb{R}^n)$.
It was introduced by Schwartz in Théories des Distributions, Chapter VI, $\S{8}$, where I found the statement I am trying to prove, which is a crucial step in a remarkable embedding theorem. To state it, let us also introduce the space $\mathcal{B_0}$ (in the notation used by Schwartz this space is denoted with the symbol $\dot{\mathcal{B}}$) which is the vector space of all $f \in C^{\infty}(\mathbb{R}^n)$ such that $f$ and all its derivatives vanish at infinity. We topologise $\mathcal{B_0}$ thought the family of semi-norms:
\begin{equation}
|| f ||_{\infty,N} = \max \left \{ || D^{\beta} f ||_{\infty} : |\beta| \leq N \right \} \quad \quad (N=0,1,2,\dots),
\end{equation}
where $|| . ||_{\infty}$ denotes the norm of the space $L^{\infty}(\mathbb{R}^n)$. Schwartz states that if $1 \leq p < \infty$ then each $f \in \mathcal{D}_{L^p}$ not only is bounded, but it also vanishes at infinity. This clearly implies that for $q \geq p$, we have $\mathcal{D}_{L^p} \subset \mathcal{D}_{L^q} \subset \mathcal{B_0}$. Moreover each inclusion is continuous. Now let us come back to our question. The case $p=1$ can be proved as follows. Let $g \in C^{\infty}(\mathbb{R}^n)$ be a function with compact support such that $g=1$ on the unit ball with center $0$. Fix $r > 0$ and for any $x \in \mathbb{R}^n$ define $g_r(x)=g(x/r)$. Then set
$\phi_r=fg_r$. If $d > 0$ is such that $[-d,d]^n$ contains the support of $\phi_r$, then by repeated integration we get for any $x=(x_1,\dots,x_n)$:
\begin{equation}
\phi_r(x) = \int_{-d}^{x_1} \dots \int_{-d}^{x_n} (T\phi_r)(y) dy = \int_{-\infty}^{x_1} \dots \int_{-\infty}^{x_n} (T\phi_r)(y) dy,
\end{equation}
where $T=D_1...D_n$ (by the way, note that the last equality just says that $\phi_r$ is the convolution of $T\phi_r$ and Heaviside function $H$ on $\mathbb{R}^n$) . For any $R > 0$ define 
\begin{equation}
Q(R)= \{ x=(x_1,\dots,x_n) \in \mathbb{R}^n : \min\{x_1,\dots,x_n\} \leq -R \}.
\end{equation}
We have that for any $x \in Q(R), z \in Q(R)$:
\begin{equation}
\left| \phi_r(x) - \phi_r(z) \right| \leq \int_{Q(R)} |(T\phi_r)(y)| dy.
\end{equation}
By using Leibniz formula we get that there exists $C> 0$ such that for any $r \geq 1$ we have
\begin{equation}
\int_{Q(R)} |(T\phi_r)(y)| dy \leq C M(R),
\end{equation}
where
\begin{equation}
M(R) = \max \left \{ \int_{Q(R)} \left| (D^{\beta}f)(x) \right| dx : |\beta| \leq n \right \}.
\end{equation}
By taking $R$ large enough, we get that for any $\epsilon > 0$, there exists $R > 0$ such that for any $x \in Q(R)$, $y \in Q(R)$, we have $|f(x) - f(y)| < \epsilon$. Since $f \in L^1(\mathbb{R}^n)$, we conclude that for any $\epsilon > 0$ there exists $r > 0$ such that $|f(x)| < \epsilon$ for any $x \in Q(r)$. By applying this result to $f(-x)$, we then get the desired conclusion. A final note. Clearly, the fact that $f$ vanishes at infinity implies that $f$ is bounded. In the case $p=1$, this fact can be directly proved by using the representation above
\begin{equation}
\phi_r(x) = \int_{-\infty}^{x_1} \dots \int_{-\infty}^{x_n} (T\phi_r)(y) dy.
\end{equation}
Actually, from this representation and Leibniz formula we get 
\begin{equation}
||f||_{\infty} \leq 2^{n} || g ||_{\infty,n} ||f||_{1,n},
\end{equation}
so that, if we set $A=2^{n} || g ||_{\infty,n}$, we conclude that
\begin{equation}
||f||_{\infty} \leq A ||f||_{1,n}.
\end{equation}
Clearly the same inequality applies to each derivative of f. 
So we conclude that $\mathcal{D}_{L^1} \subset \mathcal{B_0}$ and that the inclusion $\mathcal{D}_{L^1} \hookrightarrow \mathcal{B_0}$ is continuous. Moreover, we also get that for $1 < q < \infty$ we have $\mathcal{D}_{L^1} \subset \mathcal{D}_{L^q}$ and that the inclusion $\mathcal{D}_{L^1} \hookrightarrow \mathcal{D}_{L^q}$ is continuous. We have so proved two particular cases of the general embedding theorem stated by Schwartz.","['functional-analysis', 'real-analysis', 'distribution-theory']"
2061169,Implicit Function Theorem Proof (Rudin),"Given $f\in\mathscr{C'}$ where $f$ is a map from the open set $E\subset R^{n+m}$ to $R^{n}$, $f(a,b)=0$ for some point $(a,b)\in E$. In the second part of the proof it says: Finally, to compute $g'(b)$, put $(g(y),y)=\phi(y)$. Then $$ \phi'(y)k=(g'(y)k,k)$$ for $y\in W=\{y\in R^m : (0,y)\in V\}, k\in R^m$ What $V$ or $W$ is isn't really important. My question is where does the k come from and why does it simply disappear later in the proof?","['real-analysis', 'implicit-function-theorem', 'analysis']"
2061175,"How to show an infinite number of algebraic numbers $\alpha$ and $\beta$ for $_2F_1\left(\frac13,\frac13;\frac56;-\alpha\right)=\beta\,$?","( Note : This is the case $a=\frac13$ of ${_2F_1\left(a ,a ;a +\tfrac12;-u\right)}=2^{a}\frac{\Gamma\big(a+\tfrac12\big)}{\sqrt\pi\,\Gamma(a)}\int_0^\infty\frac{dx}{(1+2u+\cosh x)^a}.\,$ There is also $a=\frac14$ and $a=\frac16$ .) In a post , Reshetnikov considered some integrals and the surprising evaluations, $$ \frac{1}{48^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[3]{x^2+\color{blue}{4}x^3}}=\,_2F_1\big(\tfrac{1}{3},\tfrac{1}{3};\tfrac{5}{6};-\color{blue}{4}\big)= \frac3{5^{5/6}}\tag1$$ $$ \frac{1}{48^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[3]{x^2+\color{blue}{27}x^3}}=\,_2F_1\big(\tfrac{1}{3},\tfrac{1}{3};\tfrac{5}{6};-\color{blue}{27}\big)=\frac{4}{7}\tag2$$ We postulate these are just the first of an infinite family of algebraic numbers $\alpha$ and $\beta$ such that, $$_2F_1\left(\frac13,\frac13;\frac56;-\alpha\right)=\beta\tag3$$ $$\begin{array}{|c|c|c|c|c|}
\hline
p&\tau&\alpha&\beta&\text{Deg}\\
\hline
3&\frac{1+3\sqrt{-3}}2& \large \frac13& \large \frac{2}{3^{2/3}}&1\\
5&\frac{1+5\sqrt{-3}}2&\color{blue}{4}& \large\frac3{5^{5/6}}  &1\\
7&\frac{1+7\sqrt{-3}}2&\color{blue}{27}&\large\frac47&1\\
11&\frac{1+11\sqrt{-3}}2& \sqrt{11}\big(2\sqrt3 + \sqrt{11}\big)^3& \large\frac6{11^{11/12}} \frac1{U_{33}^{1/4}} &2 \\
13&\frac{1+13\sqrt{-3}}2& 4\sqrt{13}\big(4 + \sqrt{13}\big)^3&\large\frac7{13}\frac1{U_{13}}&2\\
17&\frac{1+17\sqrt{-3}}2& \frac4{729}\left[(1 + \sqrt[3]{17})^2 + 6\right]^6& \large\frac9{17^{5/6}}\left(\frac{18}{17^{1/3}}-7\right)^{1/3}&3\\
19&\frac{1+19\sqrt{-3}}2& \frac1{27}\left[(1 + \sqrt[3]{19})^2 + 5\right]^6 &\large \frac{10}{19} \Big(1-\frac{(1-19^{1/3})^2}{3}\Big)&3\\
29&\frac{1+29\sqrt{-3}}2& 4(u_1)^6&\frac{15}{29^{5/6}}(u_2)^{1/3}  &5\\
31&\frac{1+31\sqrt{-3}}2& \frac1{27}( v_1)^6 &\frac{16}{31} (v_2)&5\\
\hline
\end{array}$$ and so on, where $U_{13} = \frac{3+\sqrt{13}}2$ , $U_{33} = 23+4\sqrt{33}\,$ are fundamental units , while $u_i$ and $v_i$ are roots of quintics, etc. (While the quintics were solvable in radicals, unfortunately they don't have the simple form as the others. The original forms for $p=17,19$ were found by yours truly while alternative ones were suggested by Reshetnikov.) And $\text{Deg}$ is degree of $\alpha(\tau)$ and $\beta^6(\tau)$ . Conjecture 1: Let $\tau = \frac{1+p\sqrt{-3}}{2}$ . Using the Dedekind eta function quotient $\lambda=\frac{\eta\big(\tfrac{\tau+1}{3}\big)}{\eta(\tau)}$ ,
then $\alpha$ is just a quadratic, $$16\cdot27\,\alpha(1+\alpha)=\left( \lambda^6 -27\, \lambda^{-6} \right)^2$$ or more simply, $$\alpha = \frac1{4\sqrt{27}}\big(\lambda^3-\sqrt{27}\,\lambda^{-3}\big)^2\tag4$$ And if $p=6k\pm1$ is a prime, then $\alpha$ and $\beta^6$ of $(3)$ are algebraic numbers of degree $k$ . Alternatively, one can use the well-known j-function $j(\tau)$ , $$j(\tau) = {1 \over q} + 744 + 196884 q + 21493760 q^2 + 864299970 q^3+\dots$$ which is easily calculated in Mathematica as 12^3KleinInvariantJ[tau]. Conjecture 2: Let $\tau = \frac{1+p\sqrt{-3}}{2}$ . Then $\alpha$ is an appropriate root of, $$j(\tau) = \frac{432}{1+f}\left(\frac{5+4f}{1 - f}\right)^3,\quad \text{where}\quad f = \frac{2\alpha+1}{2\sqrt{\alpha(1+\alpha)}}$$ P.S. Conjecture 2 is indebted to the answer by Noam Elkies , though the nature of $\tau$ which should provide the correct $\alpha(\tau)$ seems to have been left out.","['conjectures', 'radicals', 'calculus', 'hypergeometric-function', 'modular-forms']"
2061204,Can an indefinite integral evaluate to zero?,"Problem : Evaluate $\displaystyle\int \frac{\sin x+\cos x}{\cos^2 x+\sin^4 x} \, dx $ I evaluated in the following way, and somehow got zero : $$I=\int \frac{\sin x+\cos x}{\cos^2 x+\sin^2 x(1-\cos^2 x)} \, dx$$ $$I=\int \frac{\sin x}{\cos^2 x+\sin^2 x(1-\cos^2 x)}dx +\int \frac{\cos x}{\cos^2 x+\sin^2 x(1-\cos^2 x)} \,dx $$ $$I=\int \frac{\sin x}{1-\sin^2 x\cos^2 x} \, dx +\int \frac{\cos x}{1-\sin^2 x\cos^2 x} \, dx$$ $$I=I_1+I_2$$ Substituting $\cos x=t$ in $I_1$ and $\sin x=u$ in $I_2$ This gives :
$$I_1=-\int \frac{1}{1-(1-t^2)t^2} \, dt $$
and
$$I_2=\int \frac{1}{1-u^2(1-u^2)} \, du $$ Since $I_1=-I_2$, $I=0$ My textbook gives me the answer : 
$$I=\frac{1}{2\sqrt{3}}\log\left(\frac{\sqrt{3}+\sin x-\cos x}{\sqrt{3}-\sin x+\cos x}\right) + \tan^{-1}(\sin x-\cos x) + C$$
which seems to have involved the substitution $\sin x-\cos x=t$. I tried to simplify the denominator to make it a function of  $(\sin x-\cos x)$ but I couldn't. Could you please explain why my method did not work and how do I proceed to obtain the answer given ?","['algebra-precalculus', 'indefinite-integrals', 'integration']"
2061208,Why cadlag Processes have atmost countable discontinuities?,"Hi Guys I was trying to understand a proof on mathstack exchange by @Lord_Farin and I cannot really follow the proof. Can some body help me here?(Please see my doubts in bold) Cardinality of set of discontinuities of cadlag functions It clearly suffices to prove that there are only countably many discontinuities on any interval $[0,n]$. The existence of left- and right-hand limits means that for all $x$ and for all $N$, there exists an $\epsilon_{x,N}$ with: $$\forall y,z \in B(x; \epsilon_{x,N}): (y-x)(z-x) > 0 \implies |f(x)-f(z)| <\frac1N$$ where the antecedent ensures that $y$ and $z$ are on the same side of $x$. Why is this last statement  even true? . It would be clear if it was continuous but the author is just using existence of left and right limits. Where do we even use the point $y$ By compactness of $[0,n]$, finitely many of the $B(x;\epsilon_{x,N})$ cover $[0,n]$. That is, except for finitely many points (the centers $x$ for the covering balls), we can be sure that no discontinuity of size bigger than $\frac1N$ exists in $[0,n]$. This last statement is not clear to me at all. I mean the existence of finitely many open balls with center $x$ tells me if I assume (which i don't really understand why) what is written above is true then at these finitely many points there are no jumps/discontinuities? Thus, for each $N$, the set: $$\left\{x \in [0,n]: \left|\lim_{\xi\to x^+}f(\xi) - \lim_{\xi\to x^-}f(\xi)\right| > \frac1N\right\}$$ is finite. It follows that the set of discontinuities on $[0,n]$: $$\left\{x \in [0,n]: \lim_{\xi\to x^+}f(\xi) \ne \lim_{\xi\to x^-}f(\xi)\right\} = \bigcup_{N \in\Bbb N}\left\{x \in [0,n]: \left|\lim_{\xi\to x^+}f(\xi) - \lim_{\xi\to x^-}f(\xi)\right| > \frac1N\right\}$$ is countable, and hence so is: $$\left\{x \in [0,\infty): \lim_{\xi\to x^+}f(\xi) \ne \lim_{\xi\to x^-}f(\xi)\right\} = \bigcup_{n \in \Bbb N}\left\{x \in [0,n]: \lim_{\xi\to x^+}f(\xi) \ne \lim_{\xi\to x^-}f(\xi)\right\}$$","['calculus', 'analysis']"
2061270,"Geometry, Creating rectangle given 2 diagonal points.","ok so i've encountered some post about it but i just cant understand why it works.. Given 2 opposite points of Rectangle (X1,Y1) , (X3,Y3)
Need to find the other 2 points. so some one in this Post offered this as an answer: x1 = ?  ;  y1 = ? ;    // First diagonal point
  x2 = ?  ;  y2 = ? ;    // Second diagonal point

  xc = (x1 + x2)/2  ;  yc = (y1 + y2)/2  ;    // Center point
  xd = (x1 - x2)/2  ;  yd = (y1 - y2)/2  ;    // Half-diagonal

  x3 = xc - yd  ;  y3 = yc + xd;    // Third corner
  x4 = xc + yd  ;  y4 = yc - xd;    // Fourth corner i just cant understand why it works, help would be much appriciated.",['geometry']
2061273,Rings in which every ideal contains a minimal ideal,"For a commutative Artinian unital ring, it is well known that every ideal contains at least a minimal ideal, a non-zero ideal that dose not contain a proper non-zero ideal. In general, not Artinian case, are rings with above property important or are they a famous class of rings, or are there any characterization or description for them?","['artinian', 'algebraic-geometry', 'ring-theory', 'commutative-algebra', 'ideals']"
2061281,Solve the equation $5x^2+5y^2-8xy-2x-4y+5=0$,While I was solving the question given by Harsh Kumar I could not find the real roots just because I changed the sign of $5y^2$. I also proved that there don't exist any real solution of that equation. The equation I made by mistake was: $$5x^2+5y^2-8xy-2x-4y+5=0.$$ Please help me to find the solutions if exist.,"['algebra-precalculus', 'quadratics']"
2061285,Is the Hausdorff dimension invariant under homeomorphisms?,"Recently I was thinking extensively about dimensions of a spaces and ascertained that algebraic or topological definitions of dimensions could hardly be not an integer. So I'm curious whether the Hausdorff or Minkowski dimensions invariant under homeomorphisms, not just isometries for if not, it is not a measurement of an intrinsic property of the space under consideration. Does anyone has a good idea on this?",['general-topology']
2061325,Random placement of rooks on a chessboard [duplicate],"This question already has answers here : What is the probability that when you place 8 towers on a chess-board, none of them can beat the other. (3 answers) Closed 7 years ago . $8$ rooks are placed randomly on an $8\times 8$ chess board. What is the probability of having exactly one rook each row and each column? I guess there is no meaningful order here?",['statistics']
2061354,Double Sigma combinations: $\sum_{j=0}^{11}\sum_{i=j}^{11}\binom ij$,"Find the sum.
$$\sum_{j=0}^{11}\sum_{i=j}^{11}{i \choose j}.$$ I am getting the answer as $4095$ although the answer is given as $4092$.","['combinatorics', 'summation', 'binomial-coefficients']"
2061408,Random but even distribution of AB v. BA,"I'm a software developer not a statistician, so use small words. :) I'm looking for an algorithm to generate a sequence of AB tests that are randomly distributed to users, but ensures an equal distribution. The sequence must be reproducible using a seed value. (I'll get around to actually finding a software algorithm, but first I need to understand/clarify what I'm trying to do.) So: 6 subjects or 50 or 500 (always an even number). Exactly half the subjects must get test A then test B, the other half must get B then A. The profile cannot be simply AAABBB, since the subject list is not necessarily randomized. It needs to be reproducible. So, a ""seed"" number will ensure I can get that exact same distribution again. The seed also ensures I can guarantee a different sequence if that's what I want. My first shot at this involves a random profile where the second half is ""flipped"", ensuring it's symmetrical. So: 20 subjects, Seed = 314 My simple algorithm just runs through the seed, toggling A to B until it hits the halfway point, then reverses the sequence: 3     1 4       3...      
A A A B A A A A B B (flip) A A B B B B A B B B
B B B A B B B B A A        B B A A A A B A A A
                          ...3 4       1 3 One of the things I've run up against is that, for a small number such as 6, a seed number must be highly constrained, or several different seeds will result in the same profile. So: 6 subjects, Seed = 523 5...
A A A (flip) B B B
B B B        A A A
              ...5 but seed 427 does the same thing: 4...
A A A (flip) B B B
B B B        A A A
              ...5 (In fact, there are so few possible permutations of profiles, the seed itself must be constrained to no more than about 24 or so possible values. Not really a seed anymore. More like 'pick a number from 1 to 24')",['statistics']
2061429,What is the minimum number of edges in this special graph?,"Assume that graph $G$ has $2n$ vertices and special property: If we select any $n$ vertices, among them there should be a vertex $v$ connected with rest $n-1$ vertices. What is the minimum number of edges in this graph? My attemps are the following: Select any $n$ vertices. There must be $n-1$ edges from a vertex $v$. Remove the vertex $v$ from the graph and repeat. So there are at least $(n-1)(n+1)=n^2-1$ vertices in a graph. It is clear that an edge is counted only once. There are $2n \choose n$ subsets of $n$ vertices with at least $n-1$ edge in a subset. Every edge is counted at most $2n-2 \choose n-2$ times, so there are at least $4n-2$ edges. This is even worse than first attempt. My experiments with small graphs shows that lower bound must be at least 2 times greater, if not more. 
It is clear that both my approaches are dumb, something more elegant must be used. 
Can you help with it? Thanks a lot for your time and ideas.","['combinatorics', 'graph-theory']"
2061430,Integrate geodesic equations to compute intrinsic induced metric,"On $\mathbb{R}^3$ with coordinates $x,y,z$ consider the Riemannian metric $g=\displaystyle{\frac{dx^2+dy^2+dz^2}{x^2+y^2}}$ defined on $X:=\mathbb{R}^3\setminus\{(0,0,z)\}$. Given any point $p_1\in X$ and $p_2$ any point in a sufficiently small neighborhood of $p_1$, I want to compute the distance $d(p_1,p_2)$ with respect to the metric $d$ which is the intrinsic metric induced by $g$. Take for example $p_1=(1,1,1)$ and $p_2=(3/2,-3/2,2)$ how do I compute $d(p_1,p_2)?$ The only way I've figured to compute $d(p_1,p_2)$ is to compute the geodesic $\gamma$ from $p_1$ to $p_2$ and then to compute its length. I've computed the geodesic equations of $g$ ($\gamma_1$ is the component of $\gamma$ in the coordinate $x$ and so on): $$\ddot\gamma_1=\displaystyle{\frac{2y\dot\gamma_1\dot\gamma_2+x(\dot\gamma_1^2-\dot\gamma_2^2-\dot\gamma_3^2)}{x^2+y^2}}$$ $$\ddot\gamma_2=\displaystyle{\frac{2x\dot\gamma_1\dot\gamma_2-y(\dot\gamma_1^2-\dot\gamma_2^2+\dot\gamma_3^2)}{x^2+y^2}}$$ $$\ddot\gamma_3=\displaystyle{\frac{2(x\dot\gamma_1+y\dot\gamma_2)\dot\gamma_3}{x^2+y^2}}$$ But I don't know how to integrate these differential equations to get the equation of the geodesic from $p_1$ to $p_2$ and then compute its length.","['riemannian-geometry', 'differential-geometry']"
2061460,"Fake proof for ""differentiability implies continuous derivative"": review","We known that a function may be differentiable at a point while having discontinuous derivative at such point. The following exercise proposes a fake proof for the proposition ""let $f : \mathbb{R} \rightarrow \mathbb{R} $ be everywhere continuous and differentiable, then $f'$ is continuous over $\mathbb{R}$""; I am asked to find the mistake(s). We prove that, for every $ a \in \mathbb{R}$, $\lim_{x \rightarrow} f'(x)=f'(a)$. Fix a point $a \in \mathbb{R}$, for every $x \in \mathbb{R}$ with $x>a$, $f$ is continuous on $[a,x]$ and differentiable on $(a,x)$, hence by MVT there exists a point $\xi \in (a,x)$ such that: $$ \frac{f(x)-f(a)}{x-a} = f'(\xi) $$Now, the limit of the LHS when $x \rightarrow a$ exists (and equals $f'(a)$ since $f$ is differentiable at $x=a$), so does the limit of the RHS. Finally, notice that when $x \rightarrow a$, then  $c \rightarrow a$, leading to: $$  f'(a)=\lim_{\xi \rightarrow a} f'(\xi). $$
My thought is that the trick lies in the worlds ""when $x \rightarrow a$, then  $\xi \rightarrow a$"": $\xi$ is in fact a function of $x$ (even if not explicitly said) $\xi=\xi(x)$, so the previous assertion somehow requires the continuity of $\xi(x)$. Is that idea correct or there is something else I couldn't see?","['derivatives', 'real-analysis', 'continuity', 'calculus']"
2061461,Combinatorial coefficients squared,"If $C_0,C_1,C_2,...,C_n$ are the combinatorial coefficients in the expansion of $(1+x)^n$ then prove that: $$1C_0^2+3C_1^2+5C_3^2+...+(2n+1)C_n^2=\dfrac{(n+1)(2n)!}{n!n!}=(n+1)\binom {2n}n$$ I am able to compute the linear addition but not the squares of coefficients. Thanks!",['combinatorics']
2061465,"Given $ab+bc+ca=3abc$, prove $\sqrt{\frac{a+b}{c(a^2+b^2 )}}+\sqrt{\frac{b+c}{a(b^2+c^2)}}+\sqrt{\frac{c+a}{b(c^2+a^2 )}}\leq 3$","$a, b, c$ are positive real numbers such that    $ab+bc+ca=3abc$ Prove∶ $$\sqrt{\frac{a+b}{c(a^2+b^2 )}}+\sqrt{\frac{b+c}{a(b^2+c^2)}}+\sqrt{\frac{c+a}{b(c^2+a^2 )}}\;\;\leq\; 3$$","['inequality', 'cauchy-schwarz-inequality', 'algebra-precalculus', 'sum-of-squares-method', 'contest-math']"
2061512,definite integral of elliptic integral of first kind,"The signal-to-noise ratio of a Hall-effect magnetic sensor is proportional to
$$ H(f,p)=\frac{I_1 (f,p)}{\sqrt{KK'(\frac{1-f}{1+f})} \sqrt{KK'(\frac{1-p}{1+p})}} $$
with $KK'(x)=K(x)K'(x)$ and $K'(x)=K(\sqrt{1-x^2}) $ and
$$ I_1(f,p)=\int_{\alpha=0}^{\pi/2} \frac{F(\alpha,\frac{1-p}{1+p})d\alpha}{\sqrt{\sin^2\alpha+(\frac{1-f}{1+f})^2\cos^2\alpha}} $$
with the incomplete elliptic integral of first type $F(\alpha,k)=\int_{t=0}^{\alpha}\frac{dt}{\sqrt{1-k^2\sin^2t}}$ and $K(k)=F(\pi/2,k)$. The two parameters $0\le f,p\le 1$ are related to input and output resistances $0\le\lambda_f,\lambda_p\le\infty $ via
$$\lambda_f=\frac{2K(f)}{K'(f)}=\frac{K'(\frac{1-f}{1+f})}{K(\frac{1-f}{1+f})} \quad \lambda_p=\frac{K'(p)}{2K(p)}=\frac{K(\frac{1-p}{1+p})}{K'(\frac{1-p}{1+p})}=\frac{2K((\frac{1-\sqrt p}{1+\sqrt p})^2)}{K'((\frac{1-\sqrt p}{1+\sqrt p})^2)}$$ Questions: Q1: 
Is it possible to compute $I_1$ in closed form, at least for specific values of $f,p$ (except 0 or 1)? Q2: Is it possible to simplify $I_1$ for the special case of a symmetric Hall-plate with equal input and output resistances $\lambda_f=\lambda_p$, which means $\sqrt p=\frac{1-\sqrt f}{1+\sqrt f}$? Q3: Numerical inspection shows that $H(f,p)$ remains constant if one transforms $(\lambda_f,\lambda_p)\to(2/\lambda_f,2/\lambda_p)$, which means $(f,p)\to(\frac{1-f}{1+f},(\frac{\sqrt{1+p}-\sqrt{2\sqrt{p}}}{\sqrt{1+p}+\sqrt{2\sqrt{p}}})^2)$ I have wrecked my brain for months about these points: fruitlessly. Any properties of $H(f,p)$ or even better $H(\lambda_f,\lambda_p)$, which can be seen in the integral above would be interesting. $H(\lambda_f,\lambda_p)$ in 3D-plot and contour-plot The plot shows that $H(\lambda_f,\lambda_p)$ has a maximum at $\lambda_f=\lambda_p=\sqrt 2$ and you can also see the symmetry in the contour plot (red circles). It becomes also apparent that there are infinitely many points on the iso-lines, for which $H(\lambda_f,\lambda_p)$ is constant. It would be great to have a closed formula that relates $\lambda_f$ versus $\lambda_p$ along an iso-line. For the symmetric case $\lambda_f=\lambda_p$ I have found a fairly accurate and astonishingly simple approximation (error < 2%)
$$ H(\lambda_f=\lambda_p) \approx \frac{\lambda_f}{\sqrt{\lambda_f^4+\lambda_f^2/2+4}} $$
The accurate expression for this case can be cast in the form
$$ H(\lambda_f=\lambda_p) = \frac{I_2(f)}{K(f)K(\frac{1-f}{1+f})} \quad I_2(f)=\frac{1}{1+f}\int_{\alpha=0}^{\pi/2}\frac{F(\alpha,\frac{2\sqrt f}{1+f})d\alpha}{\sqrt{1-\frac{4 f}{(1+f)^2}\cos^2\alpha}}$$ 
where $I_2$ is only a weak function of $f$ and $I_2(f)=I_2(\frac{1-f}{1+f})$ (by numerical inspection). $I_2(0)=I_2(1)=\pi^2/8$ and the maximum is $I_2(\sqrt 2-1)=(\sqrt 2/3) K^2(\sqrt{2}-1)$. Using the integral definition of $F(\alpha,k)$ one can rewrite 
$$ I_2(f)=\int_{x=0}^{1}\int_{y=0}^{\sqrt{1-x^2}}\frac{(1+f)dy dx}{\sqrt{1-x^2}\sqrt{1-y^2}\sqrt{(1+f)^2-4 f x^2}\sqrt{(1+f)^2-4 f y^2}} $$
Transforming into cylindrical coordinates and computing over the 90° angle gives 
$$ I_2(f)=\int_{x=0}^{1} \frac{K(\frac{(1-f)x\sqrt{1+6f+f^2-4fx}}{(1+f)(2-x)\sqrt{1+2f+f^2-4fx}})}{(2-x)\sqrt{1+2f+f^2-4fx}}dx = \int_{z=0}^{1} \frac{K(\frac{1-f}{1+f}\frac{1-z}{1+z}\sqrt{\frac{(1+f)^2+4fz}{(1-f)^2+4fz}})}{(1+z)\sqrt{(1-f)^2+4fz}}dz  $$
where we have only a complete instead of an incomplete elliptic integral - however, I still do not see the symmetry:- The last integral has some similarity to (131) in ""Elliptic integral Evaluations of Bessel moments"", by Bailey,Borwein,Broadhurst,Glasser (free download https://arxiv.org/pdf/0801.0891.pdf ). If we set $\hat f = 2f/(1+f^2)$ then there is a one-to-one relation between $f$ and $\hat f$ in the interval [0,1]. Then the transformation $f\to (1-f)/(1+f)$ means $\hat f\to\sqrt{1-\hat f^2}$ and the conjecture is $I_2(\hat f)=I_2(\sqrt{1-\hat f^2})$. In the general case $\lambda_f \ne \lambda_p$ we set $\hat p = (1-p)^2/(1+6p+p^2)$. Again there is a one-to-one relation between $p$ and $\hat p$ in the interval [0,1]. Then the transformation $p\to (\sqrt{1+p}-\sqrt{2\sqrt{p}})^{2} (\sqrt{1+p}+\sqrt{2\sqrt{p}})^{-2}$ means $\hat p\to\sqrt{1-\hat p^2}$ and the conjecture is $H(\hat f,\hat p)=H(\sqrt{1-\hat f^2}, \sqrt{1-\hat p^2})$. By partial integration one can show that $H$ and $I_1$ remain the same, if $\lambda_f$ and $\lambda_p$ are swapped.","['calculus', 'integration', 'definite-integrals', 'elliptic-integrals', 'special-functions']"
2061556,Why is my calculation of $\lim_{x\to \infty} (\sqrt{x^2+x}-x)$ wrong?,"Statement : $\lim_{x\to \infty} (\sqrt{x^2+x}-x)$ Here's my solution: $\lim_{x\to \infty} (\sqrt{x^2(1+ \frac1x )}-x)$ $\lim_{x\to \infty} (x\sqrt{(1+ \frac1x )}-x)$ As $x\to \infty$,  $\sqrt{(1+ \frac1x )}\to 1$ Therfore, as $x\to \infty$, $x -x = 0$","['infinity', 'calculus', 'limits']"
2061575,"Simple proof of area of ""rectangled"" circle","Here is a simple problem which I would occasionally assign to my precalculus students and to my calculus students. The precalculus students always found a simpler answer. Sometimes it is possible to know too much. :) Construct a simple proof that the area of the shaded region of the circle is $$ \frac{1}{2}\pi r^2+2ab $$ Caution! Mousing over the yellow region will reveal the answer. Bonus: For those who got the answer or who revealed the answer, what does the dashed line represent? What is its equation?","['algebra-precalculus', 'calculus', 'circles']"
2061593,Differential Geometry (Curves): $\alpha(s)=\lambda(s)n(s)\implies \lambda$ differentiable?,"Here, differentiable means $C^\infty$. Let $I\subset \Bbb{R}$ be an open interval and $\alpha:I\to \Bbb{R}^3$ be a regular curve parameterized by arc length ($|\alpha'(s)|=1,\forall s\in I$) with curvature $|\alpha''(s)|=k(s)>0,\forall s\in I$. Define $n(s)$ as the normal vector, by $n(s)=\dfrac{1}{k(s)}\alpha''(s)$, which we also know to be differentiable, i.e. $n:I\to \Bbb{R}^3$ is differentiable. We also denote $b$ the binormal vector, $\tau$ the torsion, etc. Suppose then that all the normal lines to the curve meet together at the origin. This implies that, for each $s\in S$, there exists a unique $\lambda(s)\in \Bbb{R}$ such that $\alpha(s)=\lambda(s)n(s)$. So, I can define a function $\lambda:I\to \Bbb{R}$ such that each $\lambda(s)$ is as above. Question: Is $\lambda:I\to \Bbb{R}$ differentiable? Why? I know that $\alpha$ and $n$ are differentiable, but does this $\alpha=\lambda n$ alone suffice to know that $\lambda$ is differentiable? I need this in order to show that $\alpha$ is in fact a part of a circle. At Manfredo's Differentiable Geometry of Curves and Surfaces this is the exercise 4, of §1.5 and he suggests simply to take the derivative of $\alpha=\lambda n$, (which furthermore he claims to be constant!) to get
$$(1-\lambda k)t+\lambda'n-\lambda \tau b=0,$$
but I don't know if it is allowed to take $\lambda'$... Edit: to say that $\alpha(s)=\lambda(s)n(s)=const.$ seems wrong, since I'm trying to prove that $\alpha(s)$ lies on a circle. Maybe the author did mean that $\lambda(s)=const.$ (?)","['derivatives', 'differential-geometry']"
2061595,"Determinant of the matrix with $a_{i,j} = (i+j)^2$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Determinant of the matrix with $ a_{i,j} = (i+j)^2 $ I was trying to solve, but it is impossible","['linear-algebra', 'determinant']"
2061649,Finding distinct integer solutions to $x_1 + x_2 + ...+ x_r = n$,"How many different (distinct $x_i$) non-negative integer solutions does the equation $x_1 + x_2 + ...+ x_r = n$ have? We know that it has $n+r-1 \choose r-1$ non negative solutions. But how many are different? actually I want to solve this problem...
choose 5 card from 13 cards that every cards marked with number 1 to 13 .
how many way sum of chosen cards if greater than 40.
so i want to know how many distinct solution that equation has. because we have only one card from each one. then i'm going to calculate this for n= 41 to 55","['number-theory', 'combinatorics', 'discrete-mathematics']"
2061669,Differentiate ln$(100|x|)$,"I asked to find $\frac{\text{dy}}{\text{dx}}$ for $y = \ln(100|x|)$.
\begin{eqnarray}
\frac{\text{d}\,\text{ln}(100|x|)}{\text{dx}}  &=& \frac{\text{d ln(100|x|)}}{\text{d 100|x|}} \cdot \frac{\text{d (100|x|)}}{\text{dx}}\\
&=&\frac{1}{\text{100|x|}}\cdot \frac{\text{d (100|x|)}}{\text{dx}}
\end{eqnarray} I'm not sure how to calculate the derivative of 100$|x|$. Any hints would be appreciated.","['derivatives', 'calculus']"
2061695,How can I solve this: $-e^{-5x}x^7(5x-8)=0$,"I'm examining function slope and determine relative extrema of function (local minimum and local maximum) The example is as following:
$
y = x^8 e^{-5x}
$ To do this I have to determine derivative of this function, which is:
$$
y' = 8x^7e^{-5x}+x^8(-5e^{-5x}) = -e^{-5x}x^7(5x-8)
$$ Then according to my notes I need to solve equation from derivative:
$
-e^{-5x}x^7(5x-8)=0
$ How to solve this equation?","['derivatives', 'calculus']"
2061756,relationship between elliptic curves over $\mathbb{C}$ & Weierstrass $\wp$-function,"I'm studying about elliptic curves over $\mathbb{C}$, then at some point the Weierstrass $\wp$-function appear. It appears to show that: 1) $\wp$ and $\wp'$ generate the field of meromorphic functions on $\mathbb{C}/\Lambda$; 2)$\wp'(z)^{2}=4\wp(z)^{3}-g_{2}\wp(z) -g_{3}$; 3)$z \rightarrow (1,\wp(z),\wp'(z))$ is an isomorphism. My question is that I can not see why exactly this function appears. What is the reason for proving these facts 1), 2) and 3) in relation to Weierstrass $\wp$-function.It is not clear to me the purpose of proving 1), 2) and 3) ... I sorry if this question is trivial","['riemann-surfaces', 'elliptic-curves', 'elliptic-functions', 'algebraic-geometry']"
2061772,"Given $x_{n+1}=x_n+\frac{c}{x_{n-1}}$, find the product of two successive terms $x_kx_{k+1}$","I have the following nonlinear recurrence $$x_{n+1}=x_n+\frac{c}{x_{n-1}}$$ where $c$ is a constant - and if it makes things easier, let's assume it's a positive integer - with initial conditions $x_1=2$ and $x_2=3$. I'm asked to find a product of consecutive terms in the sequence $x_kx_{k+1}$, namely $x_{50}x_{51}$. How can I approach this? One thing that came to mind was to rewrite as $(x_{n+1}-x_n)x_{n-1}=c$. Then
$$\begin{cases}
(x_{n+1}-x_n)x_{n-1}=c\\
(x_n-x_{n-1})x_{n-2}=c
\end{cases}$$the idea being that I might be able to extract some explicit information about $x_nx_{n-1}$. Or perhaps to allow me to write $x_n$ in terms of products of consecutive terms. Dividing one equation by the other gives
$$\frac{(x_{n+1}-x_n)x_{n-1}}{(x_n-x_{n-1})x_{n-2}}=1\implies x_{n+1}x_{n-1}-x_nx_{n-1}=x_nx_{n-2}-x_{n-1}x_{n-2}$$
I'm thinking the next step would be to introduce products, like something along the lines of
$$\begin{align*}
x_{n+1}x_{n-1}-x_nx_{n-1}&=x_{n+1}x_{n-1}-x_{n+1}x_n+x_{n+1}x_n-x_nx_{n-1}\\
&=-x_{n+1}(x_n-x_{n-1})+x_{n+1}x_n-x_nx_{n-1}
\end{align*}$$
but I'm not sure if there's any benefit to doing so. Another manipulation that occurred to me would be to recursively expand the right side:
$$\begin{align*}
x_{n+1}&=\frac{c}{x_{n-1}}+x_n\\
&=c\left(\frac{1}{x_{n-1}}+\frac{1}{x_{n-2}}\right)+x_{n-1}\\
&=c\left(\frac{1}{x_{n-1}}+\frac{1}{x_{n-2}}+\frac{1}{x_{n-3}}\right)+x_{n-2}
\end{align*}$$
though I don't really know what this would accomplish.","['recurrence-relations', 'sequences-and-series']"
2061785,"If $n > 1$ and all $n$ positive integers $a, a + k, \cdots , a+ (n - 1)k$ are odd primes, show every prime $<n \mid k$.","Background: This is from Rosen 5th edition, $3.2.15$ Number Theory.
This is an important proof because $3$ following problems require it to be correct. If $i=0$ , and $j=p$ then this proof is wrong and $p\mid (i-j)$ and $p$ may not divide $k$ . Can this proof be modified so that it is correct or do I not understand it?",['number-theory']
2061789,A student forgot the Product Rule for differentiation and made the mistake of thinking that $(fg)'=f'g'$...,"A student forgot the Product Rule for differentiation and made the mistake of thinking
    that $(fg)'=f'g'$. However, he was lucky and got the correct answer. The function f that he used was $f(x)=e^{x^2}$
     and the domain of his problem was the interval $(\frac{1}{2} , \infty)$What was
    the function $g$? For the product rule $(fg)'=f'g + fg'=e^{x^2}\cdot 2x\cdot g+e^{x^2}\cdot g'$ What the student did $(fg)'=f'g'=e^{x^2}\cdot 2x \cdot g'$ Now we assume both of these to be equivalent to other $$(fg)' =(fg)'$$ $$ e^{x^2}\cdot 2x\cdot g+e^{x^2}\cdot g'=e^{x^2}\cdot 2x \cdot g'$$ $$  e^{x^2}\cdot 2x\cdot g = g' (e^{x^2} \cdot 2x - e^{x^2} )$$ $$ \frac{e^{x^2}\cdot 2x}{e^{x^2} \cdot 2x - e^{x^2}} = \frac{g'}{g} $$ $$ \frac{2x}{2x-1} = \frac{g'}{g} $$ This is the part I am unsure about since I'm not sure if I can cancel the $e^{x^2} out $ After dominiks comment I continue $$ \frac{2x-1+1}{2x-1} = \frac{g'}{g} $$ $$ 1 + \frac{1}{2x-1} = \frac{g'}{g} $$ $$ \int 1 + \frac{1}{2x-1} dx = \int \frac{g'}{g} dx$$ $$ x+\frac{\ln|2x-1|}{2}+c =\ln|g|$$ $$ g=e^{x+\frac{\ln|2x-1|}{2}+c}$$ $$ \therefore g(x)={\sqrt{2x-1}} \cdot Ae^{x} $$",['integration']
2061806,How does one calculate probability when there are infinite possibilities?,"For example, if I picked a random integer, from the infinite amount of integers, what would be the probability of picking, say 1? And how can this be extended? Say I have x + y = 0, and I pick a random integer each for x and y, what is the probability of it being a true statement? Please answer keeping in mind I haven't really taken any course in probability or statistics.","['probability', 'infinity']"
2061815,Relationship between prime factorizations of $n$ and $n+1$?,"Are there any theorems that give us any information about the prime factorization of some integer $n+1$, if we already know the factorization of $n$? Recalling Euclid's famous proof for the infinity of the set of prime numbers, I guess we know that if $n = p_1 p_2 p_3$, then $n+1$ cannot have $p_1$, $p_2$, or $p_3$ as factors. But is there any way we could use the information about $n$'s factorization to determine something more precise about the factorization of $n+1$?","['number-theory', 'prime-numbers']"
2061821,A question regarding integration over $\varnothing$,Does $\int_\varnothing f(x)dx = 0$ make any sense? Is one allowed to use $\varnothing$ this way?,"['real-analysis', 'integration', 'calculus', 'analysis']"
2061826,"Orientability and Spin of projective space $\mathbb{RP}^n$, $\mathbb{CP}^n$, $\mathbb{HP}^n$","What are the orientability of the real projective space $\mathbb{RP}^n$ , the complex projective space $\mathbb{CP}^n$ and the quaternionic projective space $\mathbb{HP}^n$ , for any $n$ ? Are the $\mathbb{RP}^n$ , $\mathbb{CP}^n$ and $\mathbb{HP}^n$ spin-manifold or not, for any $n$ ? p.s. What is known: I know $\mathbb{RP}^n$ is non-orientable for even $n$ and orientable for odd $n$ . I know orientable manifolds for $n \leq 3$ all are spin manifold. I know $\mathbb{CP}^4$ is orientable but not spin manifold. Partial answers are welcome.","['manifolds', 'geometric-topology', 'general-topology']"
2061857,Application of Gronwall's lemma,"Use Gronwall's lemma to prove that the IVP
$$\frac{dy}{dt}=e^{\sin t}y(t),~y(0)=y_{0}~~~(*),$$
with $y_0$ being given, has an infinite interval of existence for its solutions. My approach: Gronwall's lemma states that Suppose that $g(t)$ is a continuous real-valued function that satisfies $g(t) \geq 0$ and 
  $$g(t) \leq C+K \int_{0}^{t} g(s)~ds$$
  for all $t \in [0,a],$ where $C$ and $K$ are positive constants.  It then follows that 
  $$g(t) \leq C e^{Kt},~~\textrm{for all}~t \in [0,a].$$ Solving $(*)$ we get 
$$y(t)=y_0 \cdot e^{ \int_{0}^{t} e^{\sin s}~ds}.$$
How can I set up an inequality for this and apply Gronwall's to conclude what's being asked ? What I'm understanding is existence of an infinite interval means that the solution exists for all values of $t.$ Any help is much appreciated.","['stability-in-odes', 'ordinary-differential-equations']"
2061915,Have functions with this scaling behavior been studied? Do they have a special name?,"In attempting to understand the mathematical content of certain dimensional analysis procedures one encounters in mathematics, physics, and engineering, I've noticed it's useful to understand functions having certain generalized homogeneity/scaling properties: Given a $k$-by-$n$ matrix with rational entries $A = (a_{ij})$ and $\lambda = (\lambda_1, \lambda_2, \dots, \lambda_k)\in \mathbb R^n_+$, define a transformation $S_{A,\lambda}:\mathbb R^n\to\mathbb R$ as follows:
$$
  S_{A,\lambda}\begin{pmatrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}
=
\begin{pmatrix}
  \lambda_1^{a_{11}}\lambda_2^{a_{21}}\cdots\lambda_k^{a_{k1}}x_1 \\
  \lambda_1^{a_{12}}\lambda_2^{a_{22}}\cdots\lambda_k^{a_{k2}}x_2 \\
  \vdots \\
  \lambda_1^{a_{1n}}\lambda_2^{a_{2n}}\cdots\lambda_k^{a_{kn}}x_n
\end{pmatrix}.
$$ Now suppose that there exists such an $A$ and rational numbers $\Delta_1, \Delta_2, \dots, \Delta_k$, such that $f:\mathbb R^n\to\mathbb R$ satisfies
$$
  f(S_{A,\lambda}(x)) = \lambda_1^{\Delta_1}\lambda_2^{\Delta_2}\cdots\lambda_k^{\Delta_k}f(x)
$$
for all $\lambda\in\mathbb R^n_+$. In the special case: $A$ is the identity matrix, all $\lambda_i$ are equal, and the $\Delta_i$ sum to $m$, I believe $f$ would be called a homogeneous function of degree $m$. Is there a special name for such functions $f$ when there are no such restrictions on $A$, $\lambda_i$, and $\Delta_i$?  Have they been studied in some generality?","['linear-algebra', 'functions']"
2061953,Insights into linear algebra from abstract algebra,"I use linear algebra quite a lot in applications, but I do not have a very strong abstract algebra background (i.e. around the level of an intro course, just knowing the basics of rings, groups, ideals, the first isomorphism theorem). Of course, the latter is far more general, so I was interested in how it can given insight into the former.
For instance, I thought it was interesting to look at the set of rotations as the group $SO(3)$. So, essentially I'm curious as to what insights one can glean from ""viewing linear algebra though an abstract algebra lens"".
Not necessarily practical tools, but rather more important are ones that aid in understanding or intuition (i.e. provide something new). As a particular example, what are the relations of vector spaces to these abstract structures, and is viewing them from that point of view helpful?","['abstract-algebra', 'linear-algebra', 'soft-question']"
2061958,Lower Bound for Anagram Sequence,"I noticed what looked like a polynomial-looking lower bound for OEIS sequence A023094 : a(n) is least k such that k and 2k are anagrams in base n (written in base 10)."" I've conjectured that $\forall n > 1,\ A023094(3n - 1) = A000567(n) = 3n^2 - 2n$. On this domain the following inequalities hold: 
    $$3n - 1 \leq A000567(n) < (3n-1)^3$$
    $$3n - 1 \leq A000567(n)\times 2 < (3n-1)^3$$ Therefore both $A000567(n)$ and $2 \times A000567(n)$ are two ""digit"" numbers in base-$(3n-1)$. For example: $$A023094(5) = 8 = 13_5\ (\text{and }16 = 31_5)$$
$$A023094(8) = 21 = 25_8\ (\text{and }42 = 52_8)$$
$$A023094(11) = 40 = 37_{11}\ (\text{and }80 = 73_{11})$$ I'm confident that $A000567(n)$ and $2 \times A000567(n)$ are anagrams in base-$(3n-1)$, but I don't know how to prove if they're minimal anagrams. (Heuristics suggest that they probably are minimal.) Any ideas on how to prove or disprove this? Also I'd be curious to hear thoughts on why this pattern appears for numbers of the form $3n - 1$, but not numbers of the form $3n$ or $3n + 1$.","['puzzle', 'combinatorics', 'oeis', 'discrete-mathematics']"
2061972,"Prove that $\sum\limits_{cyc}\frac{a^2}{a^3+2}\leq\frac{4}{3}$ if $a, b, c, d > 0$ and $abcd=1$","Let $a$ , $b$ , $c$ and $d$ be positive numbers such that $abcd=1$ . Prove that: $$\frac{a^2}{a^3+2}+\frac{b^2}{b^3+2}+\frac{c^2}{c^3+2}+\frac{d^2}{d^3+2}\leq\frac{4}{3}.$$ Vasc's LCF Theorem does not help here. Also I tried MV method, but without success.","['contest-math', 'inequality', 'calculus']"
2062012,How do I see that $E - \bigcup_{n \in \mathbb{N}} E_n$ is of measure zero?,"For $n \in \mathbb{N}$ let $f_n$ be a nondecreasing function on $[a, b]$. Assume that both $\sum_{n \in \mathbb{N}} f_n(a)$ and $\sum_{n \in \mathbb{N}}f_n(b)$ converge and let $f = \sum_{n \in \mathbb{N}} f_n$ on $[a, b]$. Let $A$ be the measure-zero set in $[a, b]$ consisting of all points $x$ such that either $f'(x)$ does not exist or $f_n'(x)$ does not exist for some $n \in \mathbb{N}$. For $n \in \mathbb{N}$ let $E_n$ be the set of points of $[a, b] - A$ where $f_n'$ is nonzero and let $E$ be the set of points of $[a, b] - A$ where $f'$ is nonzero. Question. How do I see that $E - \bigcup_{n \in \mathbb{N}} E_n$ is of measure zero? My thoughts on the problem so far are as follows. Assume the contrary. To get a contradiction, apply Vitali's covering technique to points $x$ of $E - \bigcup_{n \in \mathbb{N}} E_n$ where $f'(x) > \alpha$ for some appropriate $\alpha > 0$ in order to construct disjoint open intervals $(x, x + r)$ with$${{f(x + r) - f(x)}\over r} > \alpha$$and$${{f_n(x + r) - f_n(x)}\over r} < \beta$$for $n \le N$ for some appropriate $\beta > 0$ and some appropriate $N \in \mathbb{N}$. However, I need some help with carrying this out and filling the details. Is it possible someone out there can help me fill in the details?","['real-analysis', 'calculus', 'functions', 'measure-theory', 'sequences-and-series']"
2062018,How many $1\times 1\times 1$ cubes does the internal diagonal pass through in a $150\times 400\times 660$ rectangular prism?,"Problem: A $150\times 400\times 660$ rectangular prism is cut into $39600000$ $1\times 1\times 1$ cubes. An internal diagonal of the prism passes through how many of the $1\times 1\times 1$ cubes? Insight: Instead of looking at a $150\times 400\times 660$ rectangular prism, I looked at a $$ \dfrac{150}{\gcd(150,400,660)} \times \dfrac{400}{\gcd(150,400,660)} \times \dfrac{660}{\gcd(150,400,660)}   \implies 15\times 40\times 66$$ rectangular prism. However, these numbers were still too large to compute the problem manually. Are there any elegant solutions to this problem? I also tried putting the prism on the $xyz$ plane, but that got me nowhere as well. Any help is appreciated!",['geometry']
2062029,Criteria of finite Lebesgue measurability2,"The problem: Let $E$ be a Lebesgue measurable subset of $\mathbb{R}^d$ with finite measure . To show that $\forall \epsilon>0$ , $\exists$ a compact set $V$ such that $m(E \setminus V) \leq \epsilon$ . My approach: $E$ is Lebesgue measurable . Fix $\epsilon > 0$ . Now we can employ the inner approximation by closed set criterion for Lebesgue measurability to assert that $\exists$ a closed set $F$ , contained in $E$ , such that $m(E \setminus F) \leq \frac{\epsilon}{3}$ . Now if $E$ is bounded, so is $F$ and we are done. So let us assume that $E$ is unbounded, so that $F$ is not necessarily bounded. By monotonicity , $m(F) \leq m(E) < \infty$ . Let us decompose $\mathbb{R}^d$ into countable number of almost disjoint closed bounded boxes. More formally, $\mathbb{R}^d=\bigcup_{n=1}^{\infty}B_n$ , where $B_n$$'$ s are almost disjoint closed boxes. Now let $G$ be the set of all these closed boxes which are completely contained inside $F$ . Formally written, $$G=\bigcup\Big\{B_{n_j} : B_{n_j} = B_n ~\mbox{for some}~ n \in \mathbb{N} ~\mbox{and}~ B_{n_j} \subset F\Big\}$$ Clearly $G \subset F$ . Since $G$ is countable union of almost disjoint closed boxes, $m(G)=\sum_{j=1}^{\infty}|B_{n_j}|$ . Again by monotonicity , $m(G) \leq m(F) < \infty$ . Hence the sum $\sum_{j=1}^{\infty}|B_{n_j}|$ converges. Now we can choose $N \in \mathbb{N}$ , which depends on the pre-fixed $\epsilon$ , such that the partial sum $\sum_{j=1}^N|B_{n_j}| \geq \sum_{j=1}^{\infty}|B_{n_j}|-\frac{\epsilon}{3}$ . Define $S_N=\bigcup_{n_j=1}^N B_{n_j}$ . Clearly, $S_N \subset G$ . $S_N$ is closed and bounded (being finite union of closed, bounded boxes) and hence compact , by the Heine-Borel theorem . Thus it is a possible candidate for the required compact set contained in $E$ . Now, by additivity of Lebesgue measure, $m(G)=m(S_N)+m(G \setminus S_N)$ . Then $m(G \setminus S_N)=m(G)-m(S_N)=\sum_{j=1}^{\infty}|B_{n_j}| - \sum_{j=1}^N|B_{n_j}| \leq \frac{\epsilon}{3}$ . Finally we need to control the quantity $m(E \setminus S_N)$ . Note that $$E \setminus S_N = (E \setminus F) ~\bigcup~ (F \setminus G) ~\bigcup~ (G \setminus S_N)$$ Each of the sets in the right-hand side of the above equation is Lebesgue measurable (each being intersection of two Lebesgue measurable sets). Using additivity , we have $$m(E \setminus S_N)=m(E \setminus F)+m(F \setminus G)+m(G \setminus S_N)$$ We have already shown that $m(E \setminus F) \leq \frac{\epsilon}{3}$ and $m(G \setminus S_N) \leq \frac{\epsilon}{3}$ . All that is left is to control the quantity $m(F \setminus G)$ . It is intuitively very clear that we should be able to keep this quantity as small as possible, whenever $E$ is Lebesgue measurable , making the decomposition of $\mathbb{R}^d$ increasingly finer . What I need is a rigourous argument to defend this point. Any help would be greatly appreciated. EDIT: I think that I found a logic. Suppose $m(F \setminus G) > \frac{\epsilon}{3}$ . Since $F \setminus G$ is Lebesgue measurable , we can use the inner approximation by closed criterion for Lebesgue measurability to assert that $\exists$ a closed set $H$ , contained in $F \setminus G$ such that $m((F \setminus G) \setminus H) \leq \frac{\epsilon}{3}$ . Then we can include $H$ to $G$ and replace $G$ with $G^*=G \cup H$ in the above argument and continue. Please check if this reasoning is good enough.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2062045,Proof Verification About Sequence Limits,"I had work to hand in which included the following question Let $(a_n), (b_n)$ satisfy $\lim_{n\rightarrow\infty} a_nb_n=1$. Proof that if for all $n$, $0\leq a_n,b_n \leq 1$ then
   $\lim_{n\rightarrow\infty} a_n=\lim_{n\rightarrow\infty}b_n=1$. My solution which I handed in was pretty straightfoward- showing easily that $a_nb_n\leq a_n\leq 1$ and the same for $b_n$. Then I used the squeeze theorem to show their limits are $1$. However, people (also the teachers who assisted some students) started talking about partial limits and Bolzano–Weierstrass which really makes my dbout my solution's validness, which I seek here from you at the moment. Thanks in advance. EDIT See my comment below","['real-analysis', 'sequences-and-series', 'proof-verification', 'limits']"
2062053,Solving two equations of 2nd degree and 2 variables,"I spent hours trying to solve this system of equations, they're two equations with two variables, and both are 2nd degree equations, I don't know, both equal zero, so each one equals the other, but I came to a step where I'm stuck. The system is:
\begin{cases}
x^2+y^2-xy=21\\
x^2-8y^2+2xy = 0
\end{cases}",['algebra-precalculus']
2062160,heat equation in polar coordinates,"Consider the heat equation in polar coordinates,
$$\frac{\partial u}{\partial t}=h^2\left(\frac{\partial^2 u}{\partial r^2}+\frac{2}{r}\frac{\partial u}{\partial r}\right), t>0, 0<r<R.$$
A sphere of radius $R$ is initially at constant temperature $u_0$ throughout, then has surface temperature $u_1$ for $t>0$. Find the temperature throughout the sphere for $t>0$ and in particular in the center $u_c$. I can solve the heat equation when in cartesian form, however polar coordinates has always been my weakness and i have been stumped for a while, i have let $U(r,t)=F(r)G(t)$ then substituted into our original equation to get $$G'(t)+(\lambda^2)G(t)=0 \text{ where } \lambda=kh$$ $$F""(r) + F'(r)/r + k^2F(r)=0$$ i have the initial condition that $U(r,0)=u_0$ and the boundary conditions that $u(R,t)=u_1$ however i do not know where to go from here, any help is appreciated.","['heat-equation', 'ordinary-differential-equations', 'polar-coordinates']"
2062203,An application of Fatou's lemma,"Let $\{f_k\}_{k \in \mathbb{N}}$ be a family of real positive measurable function on $D \subseteq \mathbb{R}$  such that $0 \leq f_0 \leq f_1 \leq \ldots $. If $\lim f_k = f$ on $D$ then $$\lim \int_D f_k(t)dt = \int_D \lim f_k(t) dt = \int_D f(t) dt.$$ Is this proof is right? And is there another way for the solution? Thank you! PROOF. Let $\{g_k\}_{k \in \mathbb{N}}$ be a sequence of non-negative measurable functions on $D$. If $\lim_{k \to +\infty} g_k = g$ then we have
$$\int_D g = \int_D \lim g_k = \int_D \liminf_{k\to +\infty}( g_k )\leq \liminf_{k \to + \infty} \left(\int_D g_k \right) = \lim_{k \to + \infty} \int_D g_k.$$
And then 
$$\int_D g \leq \lim_{k \to + \infty} \int_D g_k.$$
Note that $0 \leq f_0 \leq f_1 \leq \ldots \leq f$ on $D$. Then $\bullet$ Let us consider the family $\{f - f_k\}_{k \in \mathbb{N}}$. We have $\lim_{k \to +\infty } (f - f_k ) = 0$ and $f - f_k$ is a non-negative function for any $k \in \mathbb{N}$. Then
$$ 0 \leq \lim_{k \to + \infty} \int_D (f - f_k)$$ or $$ \lim_{k \to + \infty} \int_D f_k \leq \int_D f.$$ $\bullet$ Let us consider the family $\{f_k\}_{k \in \mathbb{N}}$ then we have
$$\int_D f \leq \lim_{k \to + \infty} \int_D f_k .$$
This implies that
$$\lim_{k \to + \infty} \int_D f_k  = \int_D \, f \ .$$","['lebesgue-measure', 'integration', 'lebesgue-integral', 'measure-theory']"
2062236,Understanding that there are infinitely many primes of form $4n+3$,"I read the proof of, that there are infinitely many primes of form $4n+3$ and it goes here : Proof. In anticipation of a contradiction, let us assume that there exist only finitely many primes of the form $4n+3$; call them $q_1,q_2,\ldots ,q_s$. Consider the positive integer $$N=4q_1q_2\cdots q_s -1 = 4(q_1q_2\cdots q_s -1)+3$$ and let $N=r_1r_2\cdots r_t$ be its prime factorization. Because $N$ is an odd integer, we have $r_k\ne 2$ for all $k$, so that each $r_k$ is either of the form $4n+1$ or $4n+3$. By the lemma, the product of any number of primes of the form $4n+1$ is again an integer of this type. For $N$ to take the form $4n+3$, as it clearly does, $N$ must contain at least one prime factor $r_i$ of the form $4n+3$. But $r_i$ cannot be found among the listing $q_1,q_2,\ldots ,q_s$, for this would lead to the contradiction that $r_i \mid 1$. The only possible conclusion is that there are infinitely many primes of the form $4n+3$. $q_1,q_2,\ldots ,q_s$
I need an explanation from last three line i.e. this . They said that: $q_{1},q_{2}, \cdots ,q_{s}$ is of the form $4n+3$ (let) . $r_{i}$ is of form $4n+3$ (at least one) . $r_{i}$ cannot be found in listing $q_{1},q_{2}, \cdots ,q_{s}$ And lemma they used is: The product of two or more integers of the form $4n+1$ is of the same form. My problems: If above two holds then why $r_{i}$ cannot be found in listing $q_{1},q_{2}, \cdots ,q_{s}$. And how $r_{i}|1$ If all this holds then why $q's$ are infinite. Please give the most elementary explanation as you can, any help worth a lot to me, Thanks. (I took this from David M. Burton book) .","['number-theory', 'prime-factorization', 'prime-numbers', 'elementary-number-theory']"
2062273,Prove that set of continuous functions with finite integrals over $ \mathbb{R}$ form a ring,"Prove that the set of all continuous functions $ R = \{f: \mathbb{R} \rightarrow \mathbb{R} \} $ on $ \mathbb{R} $ satisfying $ \int_{ \mathbb{R} } | f(x) | dx < \infty$ forms a ring. It's easy to see these functions form an abelian group with respect to the usual addition of functions. However in this case we can't use the usual multiplication operation $(f \times g) (x) = f(x)g(x)$ since our identity would have to be $1$ which doesnt have a finite integral over the whole of $\mathbb{R}$ so is not in $R$. I tried to pick a random function, say $ 1/ (1+x^2) $ and 'force' it to be the identity somehow but I couldn't find a way. Would I possibly have to come up with another addition operation as well? Any hints would be appreciated.","['abstract-algebra', 'ring-theory', 'functions']"
2062274,Is there a formula that Compute ($\sin x $) with Approximation.??,We know that : $$\sin 30^\circ = \frac{1}{2}=0.50$$ $$\sin 45^\circ=\frac{\sqrt{2}}{2}\simeq 0.707$$ $$\sin 60^\circ= \frac{\sqrt{3}}{2}\simeq 1.73$$ $$\vdots$$ Is there a formula that Compute ($\sin x $) with Approximation.?? $$\sin 1^\circ\simeq?$$ $$\sin 2^\circ \simeq?$$ $$\sin 3^\circ \simeq?$$ $$\vdots$$,['trigonometry']
2062292,Is the set $P^{-1}(\{0\})$ a set of measure zero for any multivariate polynomial?,"Let $P \in \mathbb{R}[X_1,\dots,X_n]$ be a non-constant multivariate polynomial with real coefficients. Let's consider it as a map $P: \mathbb{R}^n \to \mathbb{R}$. Is it true that the Lebesgue measure of the set $$P^{-1}(\{0\})$$ is necessarily of measure zero?","['lebesgue-measure', 'polynomials', 'measure-theory']"
2062348,Terminology question on sets and intersections,"Is there a terminology for the following property: Given $n$ sets, that for all combinations of two of them, $A_i$, $A_j$, the intersection $A_i \cap A_j$ is either the null set or equal to either $A_i$ or $A_j$. -- The picture I had in my head was lego blocks representing the different sets. Set-up A : Picture link doesn't satisfy (Red, Yellow is just one example) Set-up B Picture below satisfies the property. Intersection of any two blocks is either empty or one of the two blocks in its entirety.","['terminology', 'elementary-set-theory']"
2062357,The set of all limits of sub-series of an absolute convergent series,"Let $\sum_{i=1}^\infty a_i$ be an absolute convergent series and let $\sum_{i=1}^\infty b_i$ be a sub-series of it, i.e.
$$b_j=c_j\cdot a_j\quad (c_j\in\{0,1\}),\qquad\forall j\in\mathbb N$$
We can say that $\sum_{i=1}^\infty b_i$ is absolutely convergent as well. So its limit, say $L$, is a real number. Now the question is, what can be said about the set of all possible values of $L$? Is it connected? Closed maybe? Neither closed / connected / compact? I have no idea. Can we determine whether a specific number belongs to this set or not? I was specially interested in finding a sub-series of $\sum \frac 1{n^2}$ whose limit is, say $\frac{\pi}6$, and then I ended up with this question.","['real-analysis', 'sequences-and-series', 'limits']"
2062360,"Is there a known transformation between $_2F_1\big(\tfrac12,\tfrac12;1;z\big)$ and $_2F_1\big(\tfrac12,\tfrac12;1;z^2\big)$?","In this post , the OP seeks a closed-form for,
$$A=\,_2F_1\big(\tfrac12,\tfrac12;1;\tfrac19\big)=1.02966\dots$$
Using the transformation,
$$\,_2F_1\big(\tfrac12,\tfrac12;1;z\big) = \tfrac2{1+\sqrt{1-z}}\,_2F_1\Big(\tfrac12,\tfrac12;1;\big(\tfrac{1-\sqrt{1-z}}{1+\sqrt{1-z}}\big)^2\Big)$$
or more generally ( DLMF 15.8.21 ),
$$\,_2F_1\big(a,b;a-b+1;z\big) = (1+\sqrt{z})^{-2a}\,_2F_1\Big(a,a-b+\tfrac12;2a-2b+1;\tfrac{4\sqrt{z}}{(1+\sqrt{z})^2}\Big)$$
we can transform $A$ to,
$$A =6\times\frac{\,_2F_1\big(\tfrac12,\tfrac12;1;\color{blue}{(1-\sqrt2)^8}\big)}{(1+\sqrt2)^2}$$
However, it turns out that the following do have a closed-form,
$$\begin{aligned}
B&=\,_2F_1\big(\tfrac12,\tfrac12;1;\color{blue}{(1-\sqrt2)^4}\big)=1.00748\dots\\[2.0mm]
&=\frac{\big(1+\sqrt2\big)\Gamma^2\big(\tfrac14\big)}{2^{5/2}\,\pi^{3/2}}\end{aligned}$$
$$\begin{aligned}
C&=\,_2F_1\big(\tfrac12,\tfrac12;1;\color{blue}{(1-\sqrt2)^2}\big)=1.04760\dots\\[2.0mm]
&=\frac{\sqrt{1+\sqrt2}\,\Gamma\big(\tfrac18\big)\Gamma\big(\tfrac38\big)}{2^{9/4}\,\pi^{3/2}}\end{aligned}$$ Q: So, is there a known transformation between $_2F_1\big(\tfrac12,\tfrac12;1;z\big)$ and $_2F_1\big(\tfrac12,\tfrac12;1;z^2\big)$?","['hypergeometric-function', 'ordinary-differential-equations', 'gamma-function', 'closed-form']"
2062435,Meaning of stacked arrows,"I just stumbled across ( pag 5 ) a symbol made of two arrows stacked together ( \rightrightarrow in latex, it seems that MathJax does not recognize it). The author uses it without giving a definition, so I guess it is supposed to be quite standard/well-known in the field but I never met it. May someone point me to the definition?","['computability', 'notation', 'functions']"
2062447,Characterisation of uniformly continuous function,"I have the following exercise:
Let $(X,d)$, $(Y,e)$ be metric spaces. This is the definition of distance of sets used in the exercise: $d(A,B)=inf\{d(a,b)\colon a \in A, b \in B\}$ $d(f(A),f(B))=inf\{e(f(a),f(b))\colon f(a) \in A, f(b) \in B\}$ The exercise is: Prove that $f\colon X \rightarrow Y$ is uniformly continuous if and only if, for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$. If we suppose that $f$ is uniformly continuous, the implication is easy. But the converse is very hard for me. Let me show you what I have tried: Suppose that for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$, and for the sake of a contradiction suppose also that $f$ is not uniformly continuous. Then there exist $\epsilon_0>0$ such that for all $\delta>0$, exist $x_\delta$, $y_\delta$ in $X$ such that $d(x_\delta, y_\delta)<\delta$ but $e(f(x),f(y)) \geq \epsilon_0$. In particular, for all $\delta=\frac{1}{n}>0$ there exist $x_n,y_n$ in $X$ such that $d(x_n,y_n)<\frac{1}{n}$ but $e(f(x_n),f(y_n)) \geq \epsilon_0$ Then $A=\{x_n \colon n \in \mathbb{N}\}$ and $B=\{y_n \colon n \in \mathbb{N}\}$ are such that $d(A,B)=0$. Then by hypotheses, we have that $d(f(A),f(B))=0$. Then, in particular for $\epsilon_0>0$, there exist $x_n,y_m$ in $X$ such that $e(f(x_n),f(y_m))<\epsilon_0$. But I get a contradiction if $n=m$ but I don't know how to proceed in case that $n\neq m$. Any help would be appreciated.","['uniform-continuity', 'general-topology', 'metric-spaces']"
2062458,"Evaluate $\frac{1}{zx+y-1}+\frac{1}{zy+x-1}+\frac{1}{xy+z-1}$ if $x+y+z=2,x^2+y^2+z^2=3,xyz=4$","Evaluate $\frac{1}{zx+y-1}+\frac{1}{zy+x-1}+\frac{1}{xy+z-1}$ if $x+y+z=2,x^2+y^2+z^2=3, xyz=4$ The first thing that I notice is that it is symetric to $a,b,c$ but it can't help me .The other idea is finding the numbers but giving it to wolfram alpha gives five complex set of answers. Another idea that looks to be nice is this: $\sum\limits_{}^{cyc}\frac{1}{xy+z-1}=\sum\limits_{}^{cyc}\frac{x}{x^2-x+4}$ Maybe it gives the answer but it is to hard to calculate. Any hints?",['algebra-precalculus']
2062514,Moduli space vs. moduli stack of vector bundles,"I would like to understand in an intuitive level first and then a technical level also (keeping in mind I am a physicist) the difference between the moduli space of vector bundles and the moduli stack of vector bundles over an algebraic variety or scheme over a complete field, in specific $\mathbb{C}$ is sufficient for me. We can assume that the rank of the vector bundle is fixed. There is some jargon that I cannot figure out: moduli space vs. coarse moduli space, moduli space vs. moduli stack, moduli functor and moduli space etc. I also want to note that I understand to some extent the definition of an algebraic stack as a 2-category but I do not see how this can be a possibly singular variety whose points parametrize isomorphism classes of vector bundles. I also am a bit confused on the same question with the replacement of vector bundles to sheaves . But I do have some idea about the differences between the moduli space of the first and the moduli space of coherent torsion free sheaves. To summarize: Can you please explain in both intuitive and (Semi)-technical
level the difference between the words space and stack? Can you clarify when we need one and when the other? Can you explain the jargon? What happens if we switch to vector bundles to sheaves? P.S. There are some nice books like the one of Huybrechts but it is quite above my level for now.","['sheaf-theory', 'moduli-space', 'algebraic-geometry', 'coherent-sheaves', 'vector-bundles']"
2062518,Rational Eisenstein primes that split,"In this Wikipedia article it is mentioned that primes of the form $p \bmod 3 = 1$ split in the ring of Eisenstein integers $\Bbb E$. By analogy to the Gaussian primes I tried to prove that for such primes there exists $a, b \in \Bbb Z$ such that $p = a^2-ab+b^2$. But I got stuck somewhere. Let's take following ingredients : $\omega, \omega^2$ the usual $3$thd degree roots of unity, $u$ a primitive root of $\Bbb Z_p$, $\mathfrak{p}$ the ideal $\Bbb Fp$. I am interested in the quotient ring $\Bbb F/\mathfrak{p}$. I chose $p^2$ elements of the form $a\omega+b\omega^2$ with $0 \leq a,b < p$ as representatives of the cosets and multiplication is executed as complex numbers and applying $\bmod p$ afterwards. It is not hard to see that $r = u^{\frac{p-1}{3}}$ is a root of $X^3-1 = (X-1)(X^2+X+1)$ in $\Bbb Z_p$. It is not a root of $X-1$ so $-r$ is a root of $X^2-X+1$. From this we can conclude that for $x = \omega +(p-r)\omega^2$ we must have that its norm $N(x) = 0 \bmod p$. Unluckily I don't see how this allows me to find an element with norm = $p$. Example 1: $p = 19$ We have $u = 2$  and $r = 2^6 \bmod 19 = 7$, $x = \omega + 12\cdot\omega^2$ but $N(x) = 7 \cdot 19$. I know that the ideal generated by $x$ in $\Bbb F/\mathfrak{p}$ is $x, 2x, 3x, \ldots, 18x$ and that (by luck?) $N(3x) = 19$ so that $19 = 3^2 - 3\cdot5 + 5^2$; Example 2: $p = 37$ We have $u = 2$  and $r = 2^{12} \bmod 37 = 26$, $x = \omega + 11\cdot\omega^2$ but $N(x) = 3 \cdot 37$. I know that the ideal generated by $x$ in $\Bbb F/\mathfrak{p}$ is $x, 2x, 3x, \ldots, 36x$ and that (by luck?) $N(4x) = 37$ so that $37 = 4^2 - 4\cdot7 + 7^2$; Conclusion I am able to construct an ideal of elements all of which have norm that is a multiple of $p$, I strongly suspect that one of these has exactly norm $p$ but can't prove it.",['number-theory']
2062522,Each person has at most 3 enemies in a group. Show that we can separate them into two groups where a person will have at most one enemy in the group.,"The question that I saw is as follows: In the Parliament of Sikinia, each member has at most three enemies. Prove that the house can be separated into two houses, so that each member has at most one enemy in his own house. I built a graph where each person corresponds to a vertex and there is an edge between them if the two are enemies. Then I tried to color the vertices of the graph using two colors and remove edges that were between vertices of different colors. The goal is to arrive at a graph with max degree 1. I tried a couple of examples. It seems to workout fine, but I don't know how to prove it.","['graph-theory', 'algorithms', 'formal-proofs', 'puzzle', 'combinatorics']"
2062570,Find the missing coordinates.,"Fill in the missing coordinates on the unit circle, represented by the letters. Using sin and cos, we have a $\sin(45^\circ)$ of $\frac{\sqrt{2}}{2}$ and a $\cos(45^\circ)$ of $\frac{\sqrt{2}}{2}$, and a $\cos(60^\circ)$ of $\frac{1}{2}$, and a $\sin(60^\circ)$ of $\frac{\sqrt{3}}{2}$. The coordinates I need are represented by A, B,C, D, E and F. The answer is A: $\frac{\sqrt{2}}{2}$, $\frac{\sqrt{2}}{2}$, B: $-\frac{1}{2}$, $\frac{\sqrt{3}}{2}$, C: $-\frac{\sqrt{3}}{2}$, $\frac{1}{2}$, D: $-\frac{\sqrt{2}}{2}$, $-\frac{\sqrt{2}}{2}$; E: $\frac{1}{2}, \frac{\sqrt{3}}{2}$; F: $\frac{\sqrt{3}}{2}$, $-\frac{1}{2}$. How does one come up with these coordinates? Thank you.",['trigonometry']
2062573,"Math competition problem, prove that $\int_{-\infty}^\infty e^{-\pi x^2 \left(\frac{\alpha +x}{\beta +x}\right)^2}dx=1~$ for $~0<\beta<\alpha$.","Recently there was a math competition in our university where this question Question: Prove that $\displaystyle\int_{-\infty}^\infty e^{-\pi  x^2 \left(\frac{\scriptstyle\alpha +x}{\scriptstyle\beta +x}\right)^2}dx=1~$ for $~0<\beta<\alpha$ has been asked, but nobody could solve it. I know that
$$
\int_{-\infty}^\infty e^{-\pi  x^2}dx=1
$$
but this doesn't help much. What are possible routes to deal with this kind of integrals? Any integration experts has any clue how this is done? Thanks.","['calculus', 'closed-form', 'integration', 'definite-integrals', 'contest-math']"
2062581,On the Arakelov metric in the construction of the Kawazumi-Zhang invariant,"For a compact Riemann surface $\Sigma$ of genus $h\geq 1$, the Kawazumi-Zhang invariant is defined as, $$\varphi(\Sigma) = \sum_{\ell >0}\frac{2}{\lambda_\ell} \sum_{m,n=1}^h \bigg\vert \int_\Sigma \phi_\ell \omega_m \wedge \bar \omega_n\bigg\vert^2$$ where we have $\Delta_\Sigma \phi_\ell = \lambda_\ell \phi_\ell$ and $\{\omega_1, \dots, \omega_n\}$ form an orthonormal basis of holomorphic forms on $\Sigma$ and it is stressed $\Delta_\Sigma$ is with respect to the Arakelov metric on $\Sigma$. There are other equivalent ways of expressing the invariant, which may be more suitable for explicit computation. For hyperbolic Riemann surfaces of certain genus, it can also be directly related to the Faltings invariant. However, many rely on this notion of an Arakelov metric, and as a string theorist, I have not delved into Arakelov theory. As such, I would greatly appreciate if someone could elucidate what the Arakelov metric is, perhaps explicitly for a particular manifold, given this seems to be the only thing from Arakelov theory I need to be able to compute $\varphi(\Sigma)$. For those curious, the motivation is that the integration of $\varphi(\Sigma)$ over the moduli space of Riemann surfaces of genus $h= 2$ arises in the evaluation of an amplitude in type II string theory.","['complex-geometry', 'riemann-surfaces', 'differential-geometry']"
2062585,Cayley Table Wikipedia Notation,"Wikipedia says that this is a Cayley table of Dih4: Can somebody explain what are these numbers/colors mean? Wikipedia page on Cayley table uses letters and does not mention any numbers. Also what are these small tables with red squares on top/left mean? There are other examples of such a schemes like here Update: I recently figured out that 'small tables with red squares' are actually a permutation matrices corresponding to the group's elements, but the question about numbers and colors is still open. Update 2: as Nex pointed out the numbers come from Caley table of S4 group. Symmetric group S4 page contains explanation of the colors: Even permutations are white: the identity eight 3-cycles three double-transpositions (in bold typeface) Odd permutations are colored: six transpositions (green) six 4-cycles (orange)","['finite-groups', 'notation', 'group-theory', 'cayley-table']"
2062609,Question on a Proof of Rearrangements for Absolutely Converging Double Series,"In Appendix B of Jameson's The Prime Number Theorem , the author gives a proof of the assertion that given real numbers $\left\{a_{j,k}\right\}_{j,k\ge 1},$ if $$\sum_{j=1}^\infty \sum_{k=1}^\infty \left|a_{j,k}\right|$$ then for any bijection $\sigma : \mathbb{N} \to \mathbb{N}^2$ we have that the sums 
$$\sum_{j=1}^\infty \sum_{k=1}^\infty a_{j,k}
= \sum_{k=1}^\infty \sum_{j=1}^\infty a_{j,k} 
= \sum_{n=1}^\infty a_{\sigma(n)}$$ all converge and are equal to one another. The proof begins (and this is the part I do not understand) by saying that it suffices to show that the result holds for the case where $a_{j,k} \ge 0$ for all $j,k\ge 1$ because if this is true then the assertion follows for general real valued sequences by writing $$a_{j,k} =  a_{j,k}^+ - a_{j,k}^-$$ where for any real $x$ we denote
$$x^+ = \begin{cases} 
x & \text{if} & x\ge 0 \\
0 & \text{otherwise}
\end{cases} $$ and $$x^- = \begin{cases} 
-x & \text{if} & x < 0 \\
0 & \text{otherwise.}
\end{cases} $$
How does this substitution actually imply that the result holds for general real-valued sequences once we know that it holds for nonnegative sequences? Any explanation on how this argument works would be greatly appreciated.","['absolute-convergence', 'summation', 'sequences-and-series', 'analysis']"
2062611,Translation of a finite set and lebesgue measure,Let $A \subset \mathbb{R}$ a finite set and $E \subset \mathbb{R} $ a lebesgue measurable set and $m(E)>0$.Prove that $\exists x\in \mathbb{R}$ and $\exists s>0$ such that $x+sA \subset E$. I tried to use fubini's theorem and the steinhauss theorem without success. Can someone help me with this?,"['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
2062613,Standard Error of weighted mean estimate,"$X$ is a random variable with unknown distribution. A number of experiments are conducted to estimate $X$. Each experiment has a different reliability measure in estimating $X$. These $n$ experiments resulted in following sample set $\{x_1, x_2, x_3, ... , x_n\}$ with corresponding non-zero weights being $\{w_1, w_2, w_3, ... , w_n\}$. The higher weight corresponds to higher reliability. Note ${\sum_{i=1}^n{w_i}}$ can be greater than $1$. The best unbiased estimator of true value of $X$ is the weighted mean of sample, $\hat{X} = \bar{x}_w$, where,   $\bar{x}_w = \frac{\sum_{i=1}^n{w_ix_i}}{\sum_{i=1}^n{w_i}}$ The estimator for variance of $X$ from its true mean is, $\hat{\sigma^2} = \bar{\sigma^2}_w$, where, $\bar{\sigma^2}_w = \frac{\sum_{i=1}^n {w_i(x_i-\bar{x}_w)^2}}{\sum_{i=1}^n{w_i}}$, What would be the best estimate of Standard Error of the sampling distribution of $\bar{x}_w$. Would it be $\frac{\bar{\sigma}_w}{\sqrt{n}}$. If yes, can someone help derive/explain it.","['statistics', 'standard-deviation', 'standard-error', 'random-variables']"
2062615,Can an element in a ring with unity be both a unit and zero-divisor? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I know this cannot be true for $\Bbb Z_n$, but is this also true in general rings? If so, how can you prove this?","['abstract-algebra', 'ring-theory']"
2062642,Why are complex numbers so magical? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question Both the real numbers and the complex numbers have a whole bunch of really nice properties: For reals, we have ordering, the intermediate value theorem, etc.  Complex numbers are algebraically closed, and we have nice calculus results like the Cauchy–Goursat theorem, holomorphicity implies analyticity, etc.  These results are to be contrasted with the case of e.g. higher dimensional spaces like $\mathbb{R}^n$ or other structures like the quaternions. My feeling is that all the nice properties of the reals can be traced to completeness and ordering.  However, I don't have a feeling for why the complex numbers have such miraculous analytical properties.  Since $\mathbb{C}$ is defined essentially as the algebraic closure of $\mathbb{R}$, I might naively suspect that closedness is the crucial property, but I don't see how that manifests itself in proving theorems like Cauchy-Goursat.  Perhaps Cauchy-Goursat is itself the essential property? So my question is: Are there one or two fundamental properties of the complex numbers which beget all the other miracles of complex analysis?  In other words, what makes complex analysis so different from real analysis or quaternionic analysis?","['complex-analysis', 'complex-numbers', 'soft-question']"
2062669,How many 19-bit strings can be generated from having an even number of ones?,"So essentially how many 19-bit strings can you make with 2 1's or 4 1's or .... or 18 1's? I know the # of 19-bit strings that can be produced with 2 1's would be 19!/17!2! and the number of 19-bit strings that can be produced with 4 1's would be 19!/15!4! ..... up until 19!/18! in the case where there are 18 1's. The thing I don't understand is how much overlap occurs. I know this problem has to do with inclusion-exclusion principle, I am just confused on how to calculate the intersection of every single possible outcome.","['permutations', 'discrete-mathematics']"
2062686,Basic geometry question and proof that $dT/d\Theta = 1 + T^2$ [duplicate],"This question already has answers here : Finding $\frac {d(\tan \theta)}{d\theta}$ (2 answers) Closed 3 years ago . I started to flick through Needham's Visual Complex Analysis and pretty much fell on my face in the first exercise. On page ix, he shows a proof that $dT/d\Theta = 1 + T^2$ if $T = tan(\Theta)$. He does so by comparing the black triangle with the initial triangle (grey). What I don't understand is why the length of the one segment is $L*d\Theta$. I'm sure I'm lacking some basic math here..... Shouldn't the length be $L*tan(d\Theta)$ (which obviously would be less helpful)?","['derivatives', 'geometry']"
2062714,How can I calculate the radius of a circle that touches AD and DC and goes through point B of a square,"I'm having a lot of trouble with an exercise in which I have to calculate the radius of a circle that only touches AD and CD of a square with the side 1 length and goes through point B. Heres my sketch: After thinking about it for about 20 minutes, I just can't find an approach to solve this. I just don't have any given parameters. Does anybody have any idea on how to solve this?","['algebraic-geometry', 'geometry']"
2062752,Is a topological $n-1$ sphere in $\mathbb{R}^n$ always the boundary of a topological $n$ ball/disk?,"In the plane ($n=2$) the assertion is true, it is the Jordan-Schoenflies theorem. The full content of the theorem is false already for $n=3$, due to the Alexander horned sphere. However, the part that it contradicts is that the exterior component is not simply connected, but the interior component still is a topological ball. The so called ""Alexander trick"" is tempting, but it assumes the sphere is the boundary of unit ball to begin with... Attempting to adapt the proof in a naive manner fails for non-convex cases. So - my question is this: Let $M$ be an $n-1$ dimensional sub-manifold of $\mathbb{R}^n$ that is homeomorphic to $S^{n-1}$. By the Jordan-Brouwer separation theorem, $M$ separates $\mathbb{R}^n$ to two connected components. Is the interior (bounded) component a topological $n$-disc, i.e. homeomorphic to $D^n$, with $M$ as its boundary? (If it helps - smoothness may be assumed)","['manifolds', 'general-topology', 'smooth-manifolds']"
2062755,Is the limit of $f(n) = n-n$ zero as $n\rightarrow \infty$?,"I have been working on a proof which involves sums and products going to infinity. I am wondering whether the following proof of a limit is valid, and whether that result would allow me to come to another conclusion. What is: $$\lim \limits_{n \to \infty} f(n)\text {, where }f(n) = n-n$$ I have worked this out to be $$\lim \limits_{n \to \infty} n-n = \lim \limits_{n \to \infty} n(1-1) = \lim \limits_{n \to \infty} n\cdot 0 = 0$$ I'm not sure whether this is the correct way of proving this limit, or whether the answer is correct. My math teacher had said that the whole limit raised a red flag in his mind, and he wasn't sure why. If my limit is correct, though, I would like to know whether the following is also valid: $$\lim \limits_{n \to \infty} f(n)\cdot n = 0$$","['functions', 'limits']"
2062760,$f(x+y) = f(x)+f(y)$ continuous at $x_0=0 \implies f(x)$ is continuous over R? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $x,y \in R$ $f(x+y) = f(x)+f(y)$ is it true that if $f$ is continuous at $x_0=0$, than $f$  is continuous in $R$?","['functions', 'limits']"
2062786,"When viewing Sobolev spaces as completions, how does the notion of weak derivative arise?","Suppose instead of defining the Sobolev spaces $W^{k,p}(\Omega), \Omega\subset\Bbb R^n$ as the space of functions whose Sobolev norm (with weak derivatives) is finite, we define it as the completion of the subset of $C^\infty(\Omega)$ functions whose Sobolev norm is finite (call it $C^{k,p}(\Omega)$). By a theorem of topology, these spaces are homeomorphic, since $C^{k,p}(\Omega)$ is dense in both $W^{k,p}(\Omega)$ and $\text{comp}(C^{k,p}(\Omega))$. So while these constructions are equivalent...that's not very clear. For instance, it is not clear what $Df$ is supposed to mean, when $f$ is an equivalence class of Cauchy sequences in $C^{k,p}(\Omega)$. (I also don't know how to interpret the equivalent class as a function $f:\Omega\to\Bbb R$ in the first place. I imagine it is an equivalence class of functions that agree a.e. somehow.) In the ""standard"" viewpoint, we have that $Df$ is just the weak derivative. So how does one interpret what $Df$ means in the completion viewpoint, and can one show that $\int Df\varphi=-\int fD\varphi$, $\forall \varphi\in C^1_0(\Omega)$, just like for weak derivatives? If this makes sense for $\Bbb R^n$, then I would like to understand it on manifolds. The completion viewpoint seems to be dominant in the geometric analysis literature, but no one explains what $\nabla f$ is actually supposed to be. In Chavel ( Eigenvales in Riem. Geo. ), we find: Given a function $f\in L^2(M)$, we say that $Y\in\mathscr L^2(M)$ is a weak derivative of $f$ if 
  $$\int_M\langle Y,X\rangle=-\int_M f\operatorname{div}(X)$$
  for all compactly supported $C^1$ vector fields $X$. (Here $\mathscr L^2(M)$ are the square integrable vector fields.) Now, this viewpoint is somewhat different from the usual PDE one since we use compactly supported vector fields...but I suppose this is just a reflection of the fact that $\partial f/\partial x^i$ has no intrinsic meaning on a manifold. I am either looking for someone to clear up my questions here, or give a good reference on this subject.","['riemannian-geometry', 'partial-differential-equations', 'reference-request', 'functional-analysis', 'sobolev-spaces']"
2062790,"Show that if $\mathcal{A}$ is a collection of inductive sets, then the intersection of the elements of $\mathcal{A}$ is an inductive set","Show that if $\mathcal{A}$ is a collection of inductive sets, then the intersection of the elements of $\mathcal{A}$ is an inductive set My Attempted Proof: Let $\mathcal{A}$ be a collection of inductive sets. Then$$\mathcal{A}= \left\{A_i\right\}_{i\in I} $$ where $A_i$ is an inductive set and $I$ is an arbitrary indexing set. Each $A_i$ contains $1$, and $\forall x \in A_i$ we have $x+1 \in A_i$. $$\text{Put  } \ \ \gamma = \bigcap_{A_i\in\mathcal{A}}A_i$$ Since $1 \in A_i$ for all $A_i\in \mathcal{A} \implies 1 \in \gamma$. Now put $x = 1$. Since $1 \in \gamma \implies x+1 = 2 \in A_i$ for all $A_i \in \mathcal{A} \implies x+1 \in \gamma$ Now put $x = 2$. Since $2 \in \gamma \implies x+1 = 3 \in A_i$ for all $A_i \in \mathcal{A} \implies x+1 \in \gamma$ Continuing this process recursively we can see that $1 \in \gamma$, $x \in \gamma$ and $x+1 \in \gamma$ for all $x \in \gamma$. Thus $\gamma$ is an inductive set. $\square$ Firstly is my proof correct? If so how rigorous is it? If it is correct and fairly rigorous, then any suggestions on how to improve it? I feel it is a bit hand-wavy at the moment","['alternative-proof', 'proof-verification', 'induction', 'proof-writing', 'elementary-set-theory']"
2062801,Examples for $f(\bar A)\subsetneq\overline{f(A)}$ with $f$ being continuous,"Suppose $X$ and $Y$ are topological spaces and $f:X→Y$ is a map. Then $f$ is continuous if and only if $f(\bar A)⊆\overline{f(A)}$ , where $\bar A$ denotes the closure of an arbitrary set $A$ . This is a very known theorem, I just could not find any example of topological spaces $X$ and $Y$ , a function $f$ and set $A$ and an element $x$ such that $x$ is in $\overline{f(A)}$ and not in $f(\bar A)$ , someone know an example? I found out that this element may be an element on $Y$ on the derived set of $f(A)$ but not in $f(D(A))$ where $D(A)$ is the derived set of $A$ . But anything ore than this. Nomenclature: derived set is the set of the limit points, and limit point is a point such that each neighbourhood (open set containing the element) intersects the set in question.","['general-topology', 'real-analysis', 'examples-counterexamples', 'continuity']"
2062820,Justify the fact that antiderivative of $\frac{1}{x}$ is $\ln |x|$ not $\ln x$,"Justify the fact that antiderivative of $\frac{1}{x}$ is $\ln |x|$ not $\ln x$ Does the derivatives domain $have$ to be the $same$ as the original functions? $\frac{1}{x} \neq 0$, but $\ln x >0$. Their domains don't agree, but how can this prove that the derivative is $not$ $\frac{1}{x}.$ I $can$ prove that derivative of $\ln |x|$ is in fact $\frac{1}{x}$, but why does simple $\ln x$ not work?","['derivatives', 'integration', 'calculus']"
2062852,Taylor expansions of order $n+1$ of $C^n$ functions,"Main Question. Suppose $f:I\to\mathbb{R}$ is of class $C^n$, and suppose $f$ has a Taylor expansion of order $n+1$ at $a$ : does it follow that $f^{(n)}$ have a derivative at $a$? If not, what are some further assumptions one can impose on $f$ to make such a statement true? Motivation. Let $I$ be an interval, and let $a\in I$ be one of its points. Recall that $f:I\to\mathbb{R}$ is said to have a Taylor expansion of order $n$ at $a$ if there are real numbers $c_0,\dots,c_n$ such that
$$f(x)=\sum_{k=0}^nc_k(x-a)^k+o_a\Big((x-a)^n\Big)$$
The following is a basic result about Taylor expansions : Theorem 1a. Let $f:I\to\mathbb{R}$ be a function, then $f$ has a Taylor expansion of order $0$ at $a$ iff $f$ is continuous at $a$, $f$ has a Taylor expansion of order $1$ at $a$ iff $f$ has a derivative at $a$. Analoguous statements are false for higher order Taylor expansions : even if $f$ has a Taylor expansion of order $n\geq 1$ at $a$, $a$ may be the only point in $I$ where $f$ is continuous, let alone differentiable. Recall that Taylor expansions can be integrated : Theorem 2. Let $F:I\to\mathbb{R}$ be differentiable, and let $f=F'$ be its derivative. Suppose $f$ has a Taylor expansion of order $n$ at $a$. Then $F$ has a Taylor expansion of order $n+1$ at $a$ which is given, as one might expect, by formally integrating the Taylor expansion of $f$ (and adding $F(a)$). Let us define
$$D^n(I)=\lbrace f:I\to\mathbb{R}\quad\text{ s.t. }\quad f',f'',\dots,f^{(n)}\text{ exist everywhere on }I\rbrace\,,$$
and two subsets
$$D_aD^n(I)\subset C_aD^n(I)\subset D^n(I)$$
where $f\in D^n(I)$ belongs to $C_aD^n(I)$ iff $f^{(n)}$ is continuous at $a$, and to $D_aD^n(I)$ iff $f^{(n)}$ is differentiable at $a$. Note that $D^0(I)$ is the set of all functions $I\to\mathbb{R}$, $C_aD^0(I)$ the subset of those functions that are continuous at $a$, and $C_aD^0(I)$ the subset of those functions that are differentiable at $a$. From Theorem 1a and Theorem 2 it easily follows, by successive integrations, that Theorem 1b. Let $f\in D^n(I)$ be a function with derivatives up to order $n$ if $f\in C_aD^n(I)$, then $f$ has a Taylor expansion of order $n$ at $a$, ( EDIT : this, while true, follows from the next point, and continuity plays no role) if $f\in D_aD^n(I)$, then $f$ has a Taylor expansion of order $n+1$ at $a$. And the coefficients in the Taylor expansion are, up to some factorials, $f(a),\dots,f^{(n)}(a)$ and $f^{(n+1)}(a)$. For $n=0$, the converse holds : this is Theorem 1a , but for $n\geq 1$, he converse to both statments is false : there are differentiable functions such that $f(x)=o(x^2)$ at $0$, yet $f'$ isn't even continuous at $0$; something like $f(x)=x^3\sin(\frac1{x^{2}})$ will do. Some calculations Let us suppose $f$ is $C^n$ and has a Taylor expansion of order $n+1$, so that, for some $c_{n+1}\in\mathbb{R}$,
\begin{array}{rcl}
f(x) & = & \sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k
    +
    \overbrace{\int_{a}^x\frac{(x-t)^{n-1}}{(n-1)!}\left[f^{(n)}(t)-f^{(n)}(a)\right]dt}^{=o((x-a)^n)}\\
    & = & \sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k+\frac{c_{n+1}}{(n+1)!}(x-a)^{n+1}+o_a\Big((x-a)^{n+1}\Big)
\end{array}
We take the difference and obtain
$$\frac1{x-a}\int_{a}^x\left(\frac{x-t}{x-a}\right)^{n-1}\left[\frac{f^{(n)}(t)-f^{(n)}(a)-c_{n+1}(t-a)}{x-a}\right]dt=o_a(1)$$
which we can rewrite as
$$\frac1{x-a}\int_{a}^x\left(\frac{x-t}{x-a}\right)^{n-1}\left[\frac{f^{(n)}(t)-f^{(n)}(a)-c_{n+1}(t-a)}{t-a}\right]\frac{t-a}{x-a}dt=o_a(1)$$
which can be rewritten as
$$\int_{0}^1(1-u)^{n-1}\left[\frac{f^{(n)}((x-a)u+a)-f^{(n)}(a)-c_{n+1}(x-a)u}{x-a}\right]du=o_a(1)$$
Without loss of generality we may assume $a=0$, and setting $g(t)=f^{(n)}(t)-f^{(n)}(0)$, $g$ is may be any continuous function under the sun vanishing at $0$, and the hypothesis becomes
$$\int_{0}^1(1-u)^{n-1}\left[\frac{g(xu)}{x}-c_{n+1}u\right]du=o_a(1)$$
and the question becomes Suppose $c$ is a real number, and $g:\mathbb{R}\to\mathbb{R}$ is continuous, vanishes at $0$ and satisfies
  $$\lim_{x\to 0}\int_{0}^1(1-u)^{n-1}\left[\frac{g(xu)}{x}-cu\right]du=0$$
  Can anything be deduced about differentiability of $g$ at $0$? Such as ""$g$ is differentiable at $0$ and $g'(0)=c$? Presumably the $(1-u)^{n-1}$ factor has no incidence on the result, and replacing $g$ by $h(t)=g(t)-ct$ we can further reduce the problem to the following Suppose $h:\mathbb{R}\to\mathbb{R}$ is continuous, vanishes at $0$ and satisfies
  $$\lim_{x\to 0}\int_{0}^1\frac{h(xu)}{x}du=0$$
  Is $h$ necessarily differentiable at $0$ with $h'(0)=0$? The answer to this question is no : consider $h(x)=x(1-\delta(x))$ where $\delta(x)=\sum_{k=0}^\infty T_k(x)$, where $T_k$ is the piecwise affine tent function that is constant equal to zero outside of $[2^{-n}-\frac1{4^n},2^{-n}1\frac1{4^n}]$ and takes the value $1$ at $2^{-n}$. Likely conclusion and new question It seems likely that the answer to the question in this generality (that is : $f$ $C^n$ admitting a Taylor expansion of order $n+1$) is no , and the above should provide a counter example. However, it seems likely that the answer becomes yes if we assume $f^{(n)}$ to be $K$-lipschitz on some neighborhood of $0$ : Suppose $h:\mathbb{R}\to\mathbb{R}$ is $K$-lipschitz, vanishes at $0$ and satisfies
  $$\lim_{x\to 0}\int_{0}^1\frac{h(xu)}{x}du=0$$
  Is $h$ necessarily differentiable at $0$ with $h'(0)=0$?","['derivatives', 'taylor-expansion']"
2062860,"Prove that if $12a+6b+4c+3d=0$, then $a+bx+cx^2+dx^3=0$ has a real solution in $(0,1)$","Assume that $a,b,c,d$ are real numbers such that $12a+6b+4c+3d=0$. Prove that $a+bx+cx^2+dx^3=0$ has a real solution in $(0,1)$. Note : I have no idea ! How is the assumption even related to the statement that the question wants us to prove? I don't understand. Second Note ( Edited ) : I know that if $x$ is too large, the equation goes to $+\infty$ and when $x$ is so much below $0$, the equation goes to $-\infty$. Then we can apply mean value theorem and say there exists some point such that on that point, the equation becomes zero. It's ok. But how to show that the root is in $(0,1)$ and what is the use of knowing $12a+6b+4c+3d=0$? Thanks in advance.",['real-analysis']
2062876,Prove $|\cos z|^2=\cos^2x+\cosh^2y$,"That what I tried 
$$
\cos z= \cos (x+iy)= \cos x \cos iy- \sin x \sin iy=\cos x \cosh y-i\sin x \sinh y\\
|\cos z|^2= \cos^2(x) \cosh^2(y)+\sin^2(x)\sinh^2(y)\\
\sinh^2(y)=\cosh^2(y)-1
$$
Then
$$
\cos^2(x) \cosh^2(y)+\sin^2(x) \cosh^2 (y)-\sin^2 (x)= \cosh^2 (y)-\sin^2 (x)
$$
 What did I do wrong ?",['complex-analysis']
2062886,Identity function that returns $1$ for the input $0$.,"I'm looking for a way to write the following function: \begin{equation}
id(x) = \begin{cases}
x & x \neq 0 \\
1 & x = 0
\end{cases}
\end{equation} However, I want to implement it without using conditionals. Any ideas? The simpler, the better.","['arithmetic-functions', 'functions', 'arithmetic']"
2062904,Evaluate $\lim\limits_{x \to \infty} \sin(\frac{1}{x})^x$,"This in an exercise in my Analysis book in a section on L'Hopital's rules. $$\lim\limits_{x \to \infty} \left[\sin\left(\frac{1}{x}\right)\right]^x$$
Now it's an indeterminate of the form $0^\infty$ however I don't know how to solve this. I have tried the following: $$y=\lim\limits_{x \to \infty} \left[\sin\left(\frac{1}{x}\right)\right]^x$$
$$\ln y=\lim\limits_{x \to \infty}\ln \left[\sin\left(\frac{1}{x}\right)\right]^x$$
$$\ln{y}=\lim\limits_{x \to \infty} x\ln{\sin\frac{1}{x}}$$
Now this is an indeterminate limit of form $\infty\cdot\infty$ which approaches $\infty$. However I may not write now that therefore $y=e^\infty=\infty$. How do I write this out correctly?","['real-analysis', 'limits']"
2062910,Bra-ket notation - what does $|0\rangle$ mean?,"So, I've read that $|0\rangle$ does not mean the zero vector, that is just represented by $0$. So what does $|0\rangle$ and $\langle 0|$  ""equal"" in standard matrix notation? In particular, are there some general rules I can follow for the translation of bra-ket notation into standard matrix notation? I come up against problems like $\langle 0|0\rangle$ and I understand what is happening intuitively, but I have no idea how to practically carry it out (for what it's worth, I'm used to normal matrix notation and can solve problems in it). Thanks! EDIT: Perhaps I didn't make my question clear. I know that $\langle 0|0\rangle$ represents an inner product or dot product, that $\langle 0|$ represents a row vector, and that $|0\rangle$ represents a column vector; this is what I meant by understanding it intuitively. However, given the problem $\langle 0|0\rangle$ I don't know what the answer is, because I don't know how to work it out; I'm used to standard matrix notation.","['quantum-mechanics', 'notation', 'linear-algebra']"
2062913,How to prove that the following function is maximized when $p = q$?,"Given the following function: \begin{equation}
f(q,p) = q\log(2p) + (1 - q)\log(2 - 2p)
\end{equation} Given some $q \in [0,1]$ we need to prove that $f(q, p)$ is maximized when $p = q$. How to prove this?","['derivatives', 'partial-derivative', 'optimization', 'maxima-minima']"
2062930,Is it it possible to draw perfect circles with a trammel?,"Using a basic, two-groove Archimedes trammel, is there a geometry or configuration that can draw a circle instead of an ellipse?","['classical-mechanics', 'geometry']"
2062947,What is symmetry?,"In probability, I have often seen the argument ""and this probability equals $\frac 1n$ by symmetry"" and I have never really understood the formality behind that statement. One of the biggest problems I have had with this line of reasoning is when solving the following problem: There are $n$ small and $m$ large pills in a bottle, every day, one of them is taken at random. If a large pill is taken, it is broken into two small pills, one of them is eaten and the other returned to the flask. If a small pill is taken out, it is eaten. What is the expected value of small pills remaining in the bottle after the last large pill has been taken? The solution used the linearity of expectation and $n+m$ indicator variables, and to calculate the expected value of the first $n$ indicator variables (corresponding to the initial $n$ small pills) it said that it sufficed to consider only the $1+m$ pills consisting of that small pill and the $m$ big ones, and then, by symmetry, the probability that it survived the $m$ large ones was $\frac {1}{m+1}$. The problem is I do not really understand why it suffices to consider only those $m+1$ pills and why they they have probability $\frac {1}{m+1}$ of being chosen last. What are the formalities behind this argument?","['expectation', 'probability']"
2062954,Maximum Elo Rating.,"I'm trying to implement a variant of the Elo system, for a game I'm working on. 
Giving two players $A$ and $B$ with ratings $R_A$ and $R_B$ respectively, the expectation of $A; E_A$ is given by the formula: $$E_A = \frac{1}{1+10^{\frac{R_B-R_A}{Y}}}\tag{*}$$ The expectation of $B$ is similarly given by: $$E_B = \frac{1}{1+10^{\frac{R_A-R_B}{Y}}}$$ The different possible game outcomes are given scores:
A win is $1.0$, a loss is: $0.0$, and a draw is $0.5$. The actual score of $A$ is $S_A$. After a match between $A$ and $B$, the new ranking of $A; R'_A$ is given by: 
$$R'_A = R_A + K(S_A - E_A)$$ Question: Given a sample with a population size of $n$ in which each player reveives an initial rating of $c$. Assuming that the players actively cooperate, what's the maximum possible rating that one player can receive? A simpler question is: Is it possible to increase the rating of all players in the sample? I think the answer is 'No' (since the rating gain of each player is deducted from another player). However if it was 'Yes' then there would be no limit, since by induction it will be possible to prove that if a strategy to increase all player's rankings from $c$ to $g \{g: c \lt g\}$ existed, then same strategy could be used to improve all rankings from $a$ to $b$ $\{a,b: g \le a \lt b\}$ and there would be no maximum value. My system doesn't implement the concept of floors or ceilings. $K$ is constant throughout all rankings.  The maximum possible ranking is trivially $\le n\cdot c$, but I want a better upper bound.
(As @Sil points down below: $R'_A+R'_B = R_A+R_B$ (since $S_A+S_B=1$ and $E_A+E_B=1$), so the overall ELO sum should remain the same after match as it was before it. $\tag{**}$ The overall ELO sum in this case being: $n \cdot c$ As for a lower bound for max rankings, I'm thinking of a binary search: $n/2$ people win the first $n$ matches. Their new rating will be calculated as 
$$R' = R + K(1-0.5)$$
$$R' = R + .5K$$ The set will be reduced to $n/2$, and this will continue till set $= 1$. The number of matches $m$ played this way wilk be approx $\lg n$. Max ranking through this method, will be: $$c + \frac{K}{2}\cdot \lg n$$ While that provides a lower bound, thus is one scenario in which I think a binary search is suboptimal in increasing rankings. I think increasing average ratings, may work, but I'm not sure. I would appreciate an answer where the maximum rating is given as a function of $K, c \& n$. I'm currently using $K = \sqrt{Y}$ $(*)$ Most chess Elo algorithms use a value of $Y = 400$ $(**)$ By this argument, it is possible to prove that $\not\exists$ a strategy to increase ratings of all players. It isalso possible to prove that it is impossible to improve average player rankings. (The average rating will always remain $1000$)","['probability', 'functions', 'probability-distributions']"
2062960,there exist infinite many $n\in\mathbb{N}$ such that $S_n-[S_n]<\frac{1}{n^2}$,"recent conjecture ：Let $S_n=1+\frac{1}{2}+\frac{1}{3}+\ldots+\frac{1}{n}$, where $n$ is a positive integer. Prove that ：there exist infinite many $n\in\mathbb{N^{+}}$ such that
$$S_n-[S_n]<\dfrac{1}{n^2}$$
where $[x]$ represents the largest integer not exceeding $x$. previous problem: How to prove that $a<S_n-[S_n]<b$ infinitely often","['conjectures', 'inequality', 'number-theory', 'harmonic-numbers', 'ceiling-and-floor-functions']"
2062980,Notation for set of arbitrarily many dice rolls.,"The set of outcomes for a single dice roll is given by: \begin{equation}
[6] = \{1,2,3,4,5,6\}
\end{equation} The set of outcomes for $n$ dice rolls is given by: \begin{equation}
[6]^n = \{ (x_i,\ldots,x_n)|x_i \in [6], i \in [n]\}
\end{equation} What's the notation for the set of outcomes for arbitrarily many dice rolls? \begin{equation}
\Omega = \{ (1),(2),(3),(4),(5),(6),(1,1),(1,2),(1,3),(1,4),(1,5),(1,6),\ldots \}
\end{equation} Also, for some $\omega \in \Omega$ what's the notation to get the number of die rolled? Is it $|(1,6)| = 2$?",['elementary-set-theory']
2062984,Meaning of row space,"I used to think of the row space of an $m \times n$ matrix $A$ as the column space of $A^T$ , and therefore the row vectors are the images of the standard dual basis of $\mathbb{R}^m$ under $A^T$ . But it seems that we can have an interpretation of the row space without introducing the dual space. I think, but am not sure, that the row spaces are those vectors which are 1-1 mapped to vectors in the column space. Is this correct?","['matrices', 'linear-algebra', 'vector-spaces']"
