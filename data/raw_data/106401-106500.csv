question_id,title,body,tags
1512962,$\lim_{x\to 0+}=(1/x)^{\sin x}$? [duplicate],"This question already has answers here : Calculate $\lim_{x\to 0}\frac{1}{x^{\sin(x)}}$ (4 answers) Closed 8 years ago . $\lim_{x\to 0+}=(1/x)^{\sin x}$ I think I should rewrite it into a from $e^{\ln}$ , but I can't continue the calculation after this step.","['calculus', 'limits', 'exponential-function', 'functions', 'trigonometry']"
1512977,Are these subsets of the powerset P(N) countable?,"I am only a first semester undergraduate (of mathematics) so I would appreciate the answers to not be too complicated.
Also English is not my first language, so my explanations might be a little off. While trying to prove that the Powerset $\mathcal{P}(\mathbb{N})$ is uncountable I ran into something that I wasn't able to understand. So, I define the set
$$
\mathbb{N}_n=\{\{a_1,a_2,\ldots,a_n\}:a_i\in \mathbb{N} \; \forall i \text{ and } a_i \neq a_j \; \forall i \neq j\} \text{ for } n \in \mathbb{N}
$$
basically the set goes like this
$$
\mathbb{N}_0=\{ \emptyset \} \\
\mathbb{N}_1=\{ \{1\},\{2\},\{3\},\ldots \} \\
\mathbb{N}_2=\{ \{1,2\},\{1,3\},\{2,3\},\{1,4\},\ldots \} \\
\vdots
$$
and we can conclude that
$$
\text{if } \mathbb{N}_i \cap \mathbb{N}_j = \emptyset \text{ then } i \neq j \\
\bigcup\limits_{i \in \mathbb{N} \cup \{0\}} \mathbb{N}_i = \mathcal{P}(\mathbb{N})
$$
Okay, so there are a countable number of sets $\mathbb{N}_i$. Also the set $\mathcal{P}(\mathbb{N})$ is uncountable. Also as briefly mentioned in yesterdays lecture (at my university), a countably infinite union of countable sets is a countable set. From this I have concluded that: $
\text{There exists an } i \in \mathbb{N} \text{ such that the set } \mathbb{N}_i \text{ is uncountable.}
$ Now, there is the possibility of a mistake that I have made in a previous statement. But in the case that I haven't, this last statement seems very counter intuitive to me. I have also tried proving / disproving it but failed. My question is where have I either made a mistake, or if I haven't how do I prove or disprove my final statement.",['elementary-set-theory']
1513006,How many variables can be pairwise anticorrelated,"I am working on a computational project involving analysis of data.  Each item of data that I have has a few hundred attributes; I have several million items of data.  The attributes are essentially random variables and I am computing the correlation of each pair of variables.  The formula to do that is: $$ \rho_{xy} = \frac{\mathbb{E}( (X-\mu_{x})(Y-\mu_{y}) )}{\sigma_{x}\sigma_{y}}$$ where $X$ and $Y$ are the attributes.  This value always lies between $+1$ and $-1$.  Intuitively, if $\rho_{xy}\approx +1$ then $X$ and $Y$ typically differ from their respective means in the same way, i.e. if $X$ is above average then so is $Y$ and if $X$ is below average, then so is $Y$.  This is called positive correlation.  Similarly, if $\rho_{xy}\approx -1$ then $X$ and $Y$ typically differ from their means in opposite directions, i.e. if $X$ is above average, then $Y$ is below and vice versa.  This is called negative correlation. From all of my data, I build a correlation matrix $C=[\rho_{ij}]$ which contains the correlation coefficient of the $i^{\text{th}}$ and $j^{\text{th}}$ variable in the $ij$-entry.  I want to view this matrix as an edge-weighted graph and perform clustering.  A ""positive"" clique would correspond to a number of pairwise positively correlated variables.  It is clear that many variables can be pairwise positively correlated; so I could potentially see large ""positive"" cliques in the graph. My question is: How many variables could I see that are pairwise negatively correlated?  Intuition tells me probably only 2.  But I cannot prove this.  Basically, I want to define ""negative"" cliques--a set of nodes all of whose edges are weighted with (nearly) $-1$, and I want to know how large my ""negative"" cliques could be. Edit: Perhaps a better way to ask the question is: to what degree can ""anti-correlation"" be transitive?  I.e. if $x$ is (strongly) anti-correlated to $y$, and $y$ is (strongly) anti-correlated to $z$, how strongly can $x$ and $z$ be anti-correlated? Also, if there is a way to say how large this ""negative"" clique could be as a function of how near the edge weights are to $-1$ that would be helpful.  The idea that there largest negative clique has 2 vertices is working on the assumption that I only have an edge when the weight is exactly $-1$.  If I relax that to an edge when the weight is smaller than $-1+\epsilon$ (small $\epsilon$) then I can probably have slightly more than 2 vertices--how many more is the question (and how does that related to $\epsilon$).","['probability', 'correlation']"
1513008,The line integral $\int_{\gamma}\frac 1z$ and branchs of logarithm,"Fix $w=re^{i\theta}\neq 0$ and let $\gamma$ be a rectifiable path in $\mathbb{C}\setminus\{0\}$ from $1$ to $w$. Show that there is a $k\in\mathbb{Z}$ such that $\displaystyle\int_{\gamma}\dfrac 1z=\log r+i\theta+2\pi i k$. If we could find some primitive $F$ of $\dfrac 1z$, we would have $\displaystyle\int_{\gamma}\dfrac 1z=F(w)-F(1)$. If we could take $F(z)=\log z$, the principal branch, then $F(w)=\log r + i\theta$ and $F(1)=0$. But where does that $k\in\mathbb{Z}$ come from? It seems we can't take the principal branch so lightly. How can we find a good primitive?",['complex-analysis']
1513043,Is a straight line closed in $\mathbb{R}^2$ with no interior points?,Is a straight line closed in $\mathbb{R}^2$ with no interior points? It seems to me that all the points on a straight line are limit points. None of them can form a neighborhood of $ r>0 $ that is completely in the straight line. So a straight line is closed with no interior points in $\mathbb{R}^2$. Is that true?,"['metric-spaces', 'general-topology']"
1513085,Wald's Identity for non-i.i.d. Case,"I am looking for Wald's  Identity for non-i.i.d. case as discussed in the following links: https://en.wikipedia.org/wiki/Wald%27s_equation What are the assumptions for applying Wald's equation with a stopping time Can someone please refer me to a book where I can find discussion about the Wald's Identity for non-i.i.d. case. Also, from assumptions mentioned on Wikipedia page it is not clear to me that for what level of dependence between random variables the general version of Wald's identity will not hold.","['probability-theory', 'markov-chains', 'random-walk']"
1513086,Proof of existing degree $n$ binomial,Let $P(x)$ be a polynomial with real coefficients such that $P(x) > 0$ for all $x \ge 0$. Prove that there exists a positive integer $n$ such that $(x + 1)^n P(x)$ is a polynomial with nonnegative coefficients. HINTS ONLY. I tried the binomial theorem with a quadratic case with: $f(x) = (x+1)^n (x^2 + 2x +1) = \sum_{k=0}^{n} \binom{n}{k} (x^{k+2} - x^{k+1} + 80x^k)$ But nothing really past this.,"['contest-math', 'real-analysis', 'algebra-precalculus', 'proof-writing', 'analysis']"
1513105,How possible for function to be $A \subset f^{-1} \left( f(A) \right) \forall f$?,"While trying to understand concept of measurable function I read on wiki more about function inverse and found interesting fact about them. For every function $f$, subset $A$ of the domain and subset $B$ of the
  codomain we have $A \subset f^{−1}(f(A))$ and $f(f^{−1}(B))\subset B$. If $f$ is injective we have $A = f^{−1}(f(A))$ and if ''f'' is
  surjective we have $f(f^{−1}(B)) = B$. I have made a sketch, and have some questions: 1) do we need to have mapping from all elements of A to other set? (Otherwise I get $f^{−1}(f(A)) \subset A$, see picture 2) 2) can inverse of surjective function have 2 elements at the domain? 3)$A \subset f^{−1}(f(A))$ does not work in general as you see! Maybe I do some restricted operations? It only works if I have 2 elements: 1 from set and 1 out of the set mapping to the same element in codomain.",['functions']
1513111,weak convergence in $l^p$ implies bounded and pointwise convergence,"Let $1<p<\infty$, $(u_n)_{n\in\mathbb{N}}\subseteq l^p(\mathbb{N})$ such that $u_n$ converges weakly to $u\in l^p(\mathbb{N})$. Prove that (1) $(u_n)$ is bounded and (2) for all fixed component $j\in n\in\mathbb{N}$ it is $\lim_{n\to\infty} u_{n,j}=u_j$ (in lecture we called it ""pointwise convergence of sequences""). My questions are: (1) is ""$(u_n)$ bounded"", i.e. $\|u_n\|<\infty$ for all $n\in\mathbb{N}$ already satisfied because $(u_n)_{n\in\mathbb{N}}\subseteq l^p(\mathbb{N})$? For (2) it is to show that $|u_{n,j}-u_j|\to 0,\; n\to\infty$ for fixed $j\in\mathbb{N}$. But I don't know how to do this.","['sequences-and-series', 'convergence-divergence', 'weak-convergence', 'functional-analysis']"
1513129,What does Ramsey theory tell us?,"I have recently started reading about Ramsey theory, though I'm a bit confused about what does it actually tell us. As long as I understood, it says that in a big enough complete graph one can find a monochromatic edge coloring. But, I'm confused a bit about the purpose of the Ramsey number, $R(r,s)$. I see from the calculations that each Ramsey number has a value, what does the values correspond to? On the other hand, in some places I see it written as ""$R(r,s)$, means that we can color the edges of the graph with two colors, where there is no monochromatic $K_r$ of color $1$, and no monochromatic $K_s$ of color $2$"", and in some places I see the opposite, that there is a monochromatic complete graph, this confuses me a lot, do we try to ensure that there is no monochromatic complete graph or there is?","['graph-theory', 'ramsey-theory', 'discrete-mathematics']"
1513141,measuring the regularity of a grid,"I'd like to find a method for scoring the difference in regularity of points in grids - there are two examples below (left) a relatively well ordered grid and (right) a relatively disordered grid. I have a brutish method which analyses nearest neighbours, finds approximate orientations (rotation and shear) and then attempts to fit a modelled grid (and computes the score of the model compared with the real data). It seems that there must be a more elegant solution, maybe by calculating an entropic value for each grid (I only want to know which is more regular, and maybe by how much). Thanks in advance, Dan",['statistics']
1513178,What's the name of this basic formula,"Is there a name for this formula
$$ x^n -y^n = (x-y) \cdot \sum_{k=0}^{n-1} x^{n-1-k} \cdot y^k$$","['terminology', 'algebra-precalculus']"
1513187,"Are there numbers $x, y \in \mathbb{Q}$ such that $\tan(x) + \tan(y) \in \mathbb{Q}$?","My question is related to the following one: Is $\{\tan(x) : x\in \mathbb{Q}\}$ a group under addition? It was shown that the above set is not closed under addition using the Lindemann-Weierstrass theorem . That tells us that $\tan(x) + \tan(y)$ need not be of the form $\tan(z)$ where $x,y,z \in \mathbb{Q}$. An initial attempt in trying to show that the above set is not closed involved trying to find $x, y \in \mathbb{Q}$ such that $\tan(x) + \tan(y) \in \mathbb{Q}$, because $\tan(x)$ is irrational when $x$ is a non-zero rational. However, I have not managed to find any rational numbers that do satisfy this property. I'm looking for non-trivial examples, so I'm discounting the case $x=-y$ for which $\tan(x) + \tan(y) = 0$. The primary difficulty that I faced was that the decimal expansion gave me no clues whether I was looking at a rational number or an irrational number. I also tried playing with the formula for $\tan(x+y)$ but I was not able to derive anything from that either. I checked a few of my guesses on Wolfram|Alpha and it says that they are all transcendental. I'm beginning to suspect that $\tan(x) + \tan(y)$ is never rational when $x$ and $y$ are rational, but I don't know how to prove that either. Does anyone have any ideas on the best way to proceed? Thank you for your help.","['number-theory', 'rationality-testing', 'trigonometry']"
1513220,Show that there is a step function $h$ on $I$ and a measurable subset $F$ of $I$ for which $h= \psi$ on $F$ and $m(I-F) < \epsilon$,"Let I be closed and bounded interval and $\psi$ a simple function defined on I. Let $\epsilon>0$. Show that there is a step function $h$ on $I$ and a measurable subset $F$ of $I$ for which $h= \psi$ on $F$ and $m(I-F) < \epsilon$. please any idea i am truly struggling with this problem, thanks, just ideas i do not want it to be solve. i am looking for where to start ok thanks","['real-analysis', 'measure-theory']"
1513226,Proof that $\cos(\pi/3)=1/2$,"Is it possible to prove that $\cos(\pi/3)=1/2$ without using any trigonometric identities? To be specific, my calculus-book simply states that with an angle of $\pi/3$ on the unit-circle the points (0,0) and (1,0) are the vertices of an equilateral triangle with edge length 1. But how can one reach such conclusion? Thanks!",['trigonometry']
1513230,"Show that if $f(z)$ is a continuous function on a domain $D$ such that $f(z)^N$ is analytic for some integer $N$, then $f(z)$ is analytic on $D$.","Show that if $f(z)$ is a continuous function on a domain $D$ such that $f(z)^N$ is analytic for some integer $N$, then $f(z)$ is analytic on $D$. I had no clue, I was trying to use the facts that zeros of $f(z)^N$ are isolated. So, zeros of $f(z)$ are isolated too. Now do I have to use uniqueness theorem?","['analyticity', 'complex-analysis']"
1513260,Forgot my basic math...,"So a younger (college student) asked me for my help to solve a basic math question, and to my surprise, I've forgot some basic math rules, rendering me unable to answer the problem. According to online math-generators the answer should'nt be what I'm getting.. And I am unable to follow the auto-generated steps... I hope this forum can be of help, as I actually really do like maths, (but obviously have been neglecting it) The problem is a reduction problem, and is as follows:
$\left(\frac{1}{2}\right) \times\left(\frac{2}{2a}\right)+\frac{\left(\frac{2a}{6}\right)}{\left(\frac{6}{5}\right)}$ What I do is this: $$\left(\frac{1}{2}\right) \times\left(\frac{2}{2a}\right)+\frac{\left(\frac{2a}{6}\right)}{\left(\frac{6}{5}\right)} $$ $$=\left(\frac{2}{6a}\right)+\frac{\left(\frac{2a}{6}\right)}{\left(\frac{6}{5}\right)} $$ $$=\left(\frac{1}{3}\right)+\frac{\left(\frac{1a}{3}\right)}{\left(\frac{6}{5}\right)} $$ (I fear this may be wrong?) $$=\frac{\left(\frac{4}{4a}\right)}{\left(\frac{6}{5}\right)} $$ $$=\left(\frac{4\times5}{4\times6a}\right) $$ $$=\frac{20}{24a} $$ $$=\frac{5}{6a}$$",['algebra-precalculus']
1513279,On what domain is the dilogarithm analytic?,"The series $\displaystyle\sum \dfrac{z^n}{n^2}$ converges for $\lvert z\rvert<1$ by the ratio test, meaning that the dilogarithm function $\text{Li}_2(z),$ which is equal to the series $\displaystyle\sum \dfrac{z^n}{n^2}$ when it converges, is certainly analytic on $\lvert z\rvert<1$. Similarly, by the ratio test, the series diverges for $\lvert z\rvert>1$. And we know that for a meromorphic function, the radius of convergence is always the distance from the center to the nearest singularity (wikipedia). Hence we should conclude that this function has a pole somewhere on $\lvert z\rvert=1$? On the other hand, at the point $z=1$ it converges to $\pi^2/6$ (see Basel problem ), it must also converge at the point $z=-1$, and it is stated on this question by Ben that the series is convergent on the whole circle $\lvert z\rvert=1$ (this confused me and prompted the question), and on a comment to an answer to a related question, one is reminded by user 23rd that if a function is analytic on a closed disk, then it is analytic on an open disk of larger radius. So we should conclude that this series is convergent for some $z$ with $\lvert z\rvert>1$? For the whole complex plane? In fact, this Wolfram alpha page does claim that the function is analytic on all of $\mathbb{C}$ (if I'm reading it correctly; it's very terse). Actually that second related question ( singularity of analytic continuation of $f(z) = \sum_{n=1}^\infty \frac{z^n}{n^2}$ ) already contains the answer to my question: the dilogarithm is analytic on $\mathbb{C}\setminus [1,\infty)$. But I can't understand how that answer is consistent with the other remarks, and the Wolfram page. How is this situation reconciled? Could I get an explanation that's a little more detailed than what's already there?","['complex-analysis', 'special-functions', 'polylogarithm']"
1513301,"Show that if there exist two complex numbers $a,b$ such that $f(a)=a$ and $f(b)=b$ then $f(z)=z$ for all $z\in B(0,1)$.","Let $f:B(0,1) \to B(0,1)$ holomorphic. Show that if there exist two complex numbers $a,b$ such that $f(a)=a$ and $f(b)=b$ then $f(z)=z$ for all $z\in B(0,1)$. There is a suggestion in the excercise that says, consider the function $g(z)=\frac{h(z)-a}{1-\overline{a}h(z)}$ with $h(z)=f \left(\frac{z+a}{1+\overline{a}z} \right)$ and use Schwarz Lemma. Ok, so I've been thinking about this excercise for a while, I wasn't able to solve it. Im not seeing how can I use the suggestion. By replacing, I easily got that $g(0)=0$ but Im not being able to prove that $|g(z)|<1$ and also Im not being able to continue even assuming that is true. Any hint in how to use the suggestion?",['complex-analysis']
1513303,Find coefficients with the binomial theorem,"I need the find the coefficient of $$x^6y^6 \,\ \text{in} \,\ (2x^3-3y^2)^5$$ I don't know how to do these style of problems, where there are powers within the parenthesis. I know how to do the ones where there's just a power outside of the parenthesis, but I am lost here, seems like the technique to complete these are different.","['discrete-mathematics', 'polynomials', 'algebra-precalculus']"
1513386,Fisher Information for Exponential RV,"Let $X \sim exp(\lambda_0)$; i.e, an exponential random variable with true parameter $\lambda_0 > 0$.  The density is then $f(x;\lambda_0) = \lambda_0 e^{-\lambda_0 x}$.  For a given $\lambda > 0$, the Fisher information is defined as
\begin{align*}
I(\lambda) & := E\left( \left(\frac{\partial \log f(X; \lambda)}{\partial \lambda}\right)^2\right) \\
& = \int_0^\infty \left(\frac{\partial \log f(x; \lambda)}{\partial \lambda}\right)^2 \, f(x; \lambda) \, dx \\
& = \int_0^\infty \left(\frac{1}{\lambda^2} - \frac{2x}{\lambda} + x^2\right) \, \lambda e^{-\lambda x} \, dx \\
& = \frac{1}{\lambda^2}.
\end{align*} Here's a plot of $I(\lambda)$: What exactly is the Fisher information telling me?  As I understand it, the larger the Fisher information, the ""more information"" the random variable $X$ is giving me about my MLE estimate of $\lambda$.  How am I supposed to use this here?  I guess if my MLE estimate is $\hat{\lambda} = 0.1$, then $I(0.1) = 100$.  Is this good?  Is this the correct usage of Fisher information?  But, I don't see how the actual value of the random variable $X$ affects this at all, nor do I see how the true parameter $\lambda_0$ affects this.  Have I misinterpreted Fisher information?","['statistics', 'statistical-inference']"
1513393,$\lim a_n = 0$ if $\left|\frac{a_{n +1}}{a_n}\right|\to L < 1$,"Suppose that $a_n \neq 0$, for every n and that $L = \lim |\frac{a_{n +1}}{a_n}|$ exists. Show that if L < 1, then $\lim a_n = 0$. What I did so far: If L < 1 and $L = \lim |\frac{a_{n +1}}{a_n}|$, there exists $n_0$ such that for $n \geq n_0$, $0 < |a_{n+1}| < |a_n|$. That means that the sequence $(|a_n|)_{n \geq n_0}$ is decreasing. Consider the set $S = \{ |a_0|, ..., |a_{n_0} \}$. S is finite. Let $\beta = \max_{0 \leq i \leq n_0} |a_ i|$. Thus, $(|a_n|)$ is limited (because, for every n, $0 \leq |a_n| \leq \beta).$ Now I have that $(|a_n|)$ is limited and, throwing away a finite number of terms (the $n_0$ firsts) I can assume that it is decreasing. So I know that $(|a_n|) converges. How can I prove that it converges to $0$? I also know that if I prove that $ \lim |a_n| = 0$, then I have that $ \lim a_n = 0$.","['analysis', 'real-analysis']"
1513400,"If $X$ is beta distributed, how can you show that $1-X$ is also beta distributed? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Can you just plug in $1-X$ into the Beta Density Function?",['probability']
1513402,Lusin's Theorem - does $f$ ever have to be continuous?,"Recall Lusin's Theorem: Let $f$ be a real-valued measurable function on $E=[0,1]$.  Then, for each $\epsilon > 0$, there is a continuous function $g$ on $\mathbb{R}$ and a closed set $F$ contained in $E$ for which $f=g$ on $F$ and $m(E\backslash F) < \epsilon$. I was wondering if $f$ itself ever has to be continuous at any point (as a function on $E$)? I figured that it would at least need to be continuous on the interior of $F$, where it actually equals $g$ (I realize it technically equals $g$ on the boundary of $F$ as well, but we don't know what's going on outside $F$, so we can't necessarily say it's continuous on the boundary, can we?), because there it's coinciding with a function that is known to be continuous. Is there any more to this, and if so (and even if not), what would a proof look like?","['lebesgue-measure', 'continuity', 'real-analysis', 'measure-theory']"
1513437,Showing an inequality: $\sqrt{xy} \leq \frac{2xy}{x+y}$,"For $x,y \in \mathbb{R}_{0}^+$ I want to show that
$$\sqrt{xy} \leq \frac{2xy}{x+y}$$
only if $x=y$. I think squaring both sides is a equivalence transformation due to $x>0, y>0$ but it didn't get me anywhere. Can someone give me a hint or a solution?","['algebra-precalculus', 'inequality']"
1513443,"For all sets $A$ and $B$, $P(A \times B) = P(A) \times P(B)$","Prove each statement that is true and find a counterexample for each statement that is false. For all sets $A$ and $B$ , $P(A × B) = P(A) × P(B)$ . For all sets $A$ and $B$ , $P(A ∩ B) = P(A) ∩ P(B)$ . Here $P$ is the power set. Can some show or explain to me how to do this? I'm very confused. Thanks.","['elementary-set-theory', 'discrete-mathematics']"
1513481,Locally free sheaf which is not isomorphic to a constant sheaf.,Let $\mathscr{F}$ be a sheaf of abelian groups. We say that $\mathscr{F}$ is a locally free sheaf if $\forall x \in X$ exists some $U \subset X$ such that $\mathscr{F}_U$ (restriction of $\mathscr{F}$ to U) is isomorphic to a constant sheaf with stalks $\mathbb{Z}^m$. I've just proved that if $X$ is connected then the rank of $\mathscr{F}$ is well defined. But I need to find a locally free sheaf (with X connected) which is not isomorphic to a constant sheaf. I don't know many examples so I'm stuck in this exercise.,"['algebraic-geometry', 'sheaf-theory']"
1513522,a dense set in plane [duplicate],This question already has answers here : Boundary Question in $\mathbb{R}^{2}$ (Manifolds) (2 answers) Closed 4 years ago . Is there a dense set in $\Bbb{R^2}$ that every vertical line or horizontal line intersect in finite points. I think that we can consider $\Bbb{Q} ×\Bbb{Q}$ but every vertical line or horizontal line don't intersect in finite points.,"['metric-spaces', 'examples-counterexamples', 'general-topology']"
1513554,What is a particular and a homogenous solution of a differential equation?,"When solving linear nonhomogeneous equations, we deal with two types of solutions: particular homogeneous Why do we have these two types of solutions for differential equations? What does each of them represent?","['motivation', 'ordinary-differential-equations']"
1513576,"Relation between the Lie functor applied to a Lie group action, and the fundamental vector field mapping?","Let $M$ be a smooth manifold, and $G$ a Lie group with Lie algebra $\mathfrak{g}$. The Lie algebra of the diffeomorphism group of $M$ is the usual Lie algebra of vector fields on $M$; that is $\text{Lie}(\text{Diff}(M)) = \Gamma(TM)$. Given a smooth left-action of $G$ on $M$ expressed as a Lie group homomorphism $\lambda : G \to \text{Diff}(M)$, we obtain a Lie algebra homomorphism $\text{Lie}(\lambda): \mathfrak{g} \to \Gamma(TM)$. What is the relation between this Lie algebra homomorphism and the fundamental vector field mapping $\zeta: \mathfrak{g} \to \Gamma(TM)$, which is an anti-homomorphism of Lie algebras? Recall that the fundamental vector field mapping is given by
$$\zeta(X)_x = T_e \bar{\lambda}(-, x).X$$
for any $x \in M$ and $X \in \mathfrak{g}$. Here I have written the group action as a smooth map $\bar{\lambda}: G \times M \to M$. I don't know much about infinite-dimensional Lie groups and manifolds, but it seems that there should be some simple relationship between these two mappings. ( X-post to mathoverflow )","['lie-groups', 'differential-geometry', 'lie-algebras', 'representation-theory']"
1513577,"Choose $3n$ points on a circle, show that there are two diametrically opposite point","On a circle of length $6n$ , we choose $3n$ points such that they split the circle into $n$ arcs of length $1$ , $n$ arcs of length $2$ , $n$ arcs of length $3$ . Show that there exists two chosen points which are diametrically opposite. Source: Russian MO $1982$ Swiss MO $2006$ - Final round IMAC $2012$ Romania MO $2018$ - $9$ . grade Edit: Partition of circumference into $3k$ arcs","['contest-math', 'combinatorial-geometry', 'continuity', 'combinatorics']"
1513605,Moment generation function -> characteristic function uniqueness,"Here's my proof that moment generation function (if exists) uniquely determines characteristic function. Can you please see how to make it more rigorous or improve in either way (e.g. by citing relevant well-known theorems). Thank you very much - any suggestions are welcome! Theorem. Let $F(X)$ be a probability distribution  of $X$ and suppose the MGF, $M(t)$ exists in an open ball centered at $t = 0$. Then, the characteristic function is uniquely determined by $M(t)$ alone. In other words, if $M(t)=\sum_{x=0}^{\infty} \frac{t^n \mu_n}{n!}$ has a positive radius of convergence about $0$, there is a unique characteristic function associated with it. \newline Proof: The theorem can be easily proven by using analytical continuation technique. Let's extend MGF on a ball $R = \{x | |x| <r\} , r \in \mathbb{R}$ to a strip $S =\{z | |Re(z)| < r\}$ on complex plain. it is easy to see that $M(z)$ is bounded on $S$: $|M(z)| = | \int\limits_{\mathbb{R}} e^{zt} dF(t) | < \int\limits_{\mathbb{R}} |e^{zt}| dF(t) = M(x)$, so using Fubini's theorem we can see that $\int\limits_{\partial B} M(z) dz = \int\limits_{\partial B} \int\limits_{\mathbb{R}} e^{zt} dt dz = \int\limits_{\mathbb{R}}( \int\limits_{\partial B} e^{zt} dz ) dt = 0 $ on every open ball $B \subset S$, so $M(z)$ is analytical continuation on $S$. Because the uniqueness of analytical continuation, if $M_1(x) = M_2(x), x \in R$, then $C_1(x) = M_1(-ix) = M_2(-ix) = C_2(x)$. Q.E.D.","['characteristic-functions', 'probability', 'complex-analysis', 'moment-generating-functions']"
1513614,History: Probability Theory,"Of course they're both major oversimplifications, but which of (1) and (2) is closer to the truth? Lebesgue invents measure theory and then Kolmogorov notices that measure theory can be used to axiomatize probability theory. Lebesgue invents measure theory, Kolmogorov gives an axiomatization of probability theory, then someone notices the connection.","['math-history', 'probability']"
1513665,Normal unit vector,"I am looking at the following exercise: I have done the following about the second part, about the signed curvature of $\iota$ : The signed curvature of $\gamma$ is different from the signed curvature of $\iota$, right? So, let $\kappa_s$ be the signed curvature of $\gamma$ and $\kappa_{s, \iota}$ the signed curvature of $\iota$. We have $$\iota '(s)=\gamma '(s)-\gamma '(s)+(l-s)\gamma ''(s) \Rightarrow \iota '(s)=(l-s)\gamma '' (s) \tag{1}$$ We define as the unit tangent vector $\textbf{t}$, the signed unit normal vector $\textbf{n}_{s, \iota}$ and the signed curvature $\kappa_{s, \iota}$ of $\iota$ the corresponding quantities of the unit speed reparametrization of $\tilde{\iota}(a)$, where $a$ is the arc length of $\iota$. 
So, $$\textbf{t}=\frac{\iota ' (s)}{\|\iota ' (s)\|}=\frac{\iota '(s)}{a'(s)}$$ 
Therefore, $$\iota '(s)=a'(s)\textbf{t}$$ We have that if $\iota$ is a unit-speed plane curve, then $$\textbf{n}_{s, \iota } ' =-\kappa_{s, \iota} \iota'$$ Generalizing this formula for a regular curve, not necessarily unit-speed, we have $$\textbf{n}_{s,\iota } ' =-\kappa_{s,\iota}a'(s)\textbf{t} \tag{2}$$ $$(1) \Rightarrow a'(s)\textbf{t}=(l-s)\gamma ''(s) \Rightarrow a'(s) \textbf{t}=(l-s)\kappa_s \textbf{n}_s$$ $$(2) \Rightarrow \textbf{n}_{s, \iota } '=-\kappa_{s, \iota} (l-s)\kappa_s \textbf{n}_s$$ Which is the relation between the normal unit vector of the curve and normal unit vector of the involute of the curve?","['vectors', 'curves', 'involutions', 'ordinary-differential-equations']"
1513696,Show that every finite family of random variables is tight.,"A family of random variables $(X_i)_{i \in \mathcal{I}}$ is said to be $tight$ if for every $\epsilon>0$ there exist a compact set $K_\epsilon$ such that $$\displaystyle\sup_{i \in \mathcal{I}}\mathbb{P}(X_i\notin K_{\epsilon})<\epsilon$$ Show that every finite family of random variables is tight. So I tried to star with only one random variable, say $X$. So, I have that $\mathbb{P}(X\notin K_\epsilon)=\mathbb{P}(\{\omega : X(\omega) \notin K_\epsilon \})$ And I get stuck right there. I don't know how to construct my compact set $K_\epsilon$ because I don't know how to work with the event $\{\omega : X(\omega) \notin K_\epsilon \}$. Any help?","['probability-theory', 'probability']"
1513701,Local maximum implies derivative is $0$,"If $f$ is a differentiable real function in an open set $E \subset \Bbb R^n$ and $f$ has a local maximum at a point $\textbf{x} = (x_1, x_2, \cdots , x_n) \in E$, show $f'(\textbf{x}) = 0$. I think it would be nice if I could show that each component is $0$, which I think means showing the partial derivative at each component is $0$, but I don't know how to show this.","['multivariable-calculus', 'real-analysis', 'derivatives']"
1513715,Prime spiral with regular triangles,"I wrote a little program that creates a Ulam like spiral, only with regular triangles instead of squares. The following image shows the way it is set up: In this set up all the uneven numbers will be represented by a downward pointing triangle. All prime numbers will be represented by a colored triangle. Now if we make the spiral bigger, we see some interesting patterns emerging: A few observations: much like Ulam's spiral the prime numbers tend to be on diagonals the diagonals that go from bottom left to top right appear much clearer in the bottom left and center triangular part of the spiral as wel as in the top center and right part. The top left and bottom right triangular parts have more of the diagonals that go from bottom right to top left, but they are not that well defined the diagonals that go from bottom left to top right seem to be the only lines where there are more than 3 primes in a row (if we exclude the first two primes in the center) there are a few diagonals that go from bottom right to top left that have 3 primes in a row, these seem to only appear on the horizontal line that goes through the center of the spiral the vertical lines from 7 down and from 13 up seem to have no primes on them Any thoughts or explanations? Do the same theories about the Ulam spiral apply to this one? Update: If I rotate the bottom half of the spiral 180 degrees around the center, such that the vertical 'prime free' lines of 7 and 13 are on top of eachother, another strange 'prime free' line appears from the center to just below the middle of the right side:","['prime-numbers', 'number-theory']"
1513733,Solving a homogeneous quadratic equation in three variables over the integers.,"Is there any procedure for determining if an infinite amount of solutions exist for an equation of the type $x^2 = ay^2 + byz + cz^2$ for arbitrary integer constants $a, b, c$ and variables $x, y, z \in \mathbb{Z_+}$? If not, does knowing at least one non-trivial solution of the equation help determine if an infinite amount of solutions exist? Example (if it helps): let $x^2 = 202 y^2+14yz+9z^2$. Here one solution is $y=z=1$ and $x=15$, do there exist infinitely many other solutions?","['number-theory', 'conic-sections', 'diophantine-equations', 'quadratics', 'elementary-number-theory']"
1513748,Definition of the rank of infinite matrix,"How is the rank of an infinite matrix defined?  Is it the same as in the finite case, i.e. the number of elements in a basis for some matrix?  How are the dimensionalities of the column and null spaces defined for infinite matrices?  I have searched quite a bit online and have found no discussion of these issues.","['infinity', 'linear-algebra', 'matrices']"
1513793,Show that $Y$ and $Z$ are independent and find their distributions,Suppose that $X\sim\exp(\lambda=1)$. Let $Y$ be the integer part and $Z$ be the fractional part. Show that $Y$ and $Z$ are independent and find their distributions. This one is kinda confusing. Any help?,"['probability-theory', 'probability', 'statistics']"
1513812,The Wald test with Poisson distribution,"Let $X_1,\ldots, X_n\sim \operatorname{Poisson}(\lambda)$. Let $\lambda_w>0$ be given, I am trying to find the size $\alpha$ Wald test for $H_0$: $\lambda=\lambda_w$ vs $H_1$: $\lambda\neq \lambda_w$. I got stuck with how to get start to compute. I think I need to go with computing the power function and use it (I am still trying...). But I was told that Wald test size is computed in a special way (which is faster also). Can any body help me on finding this size $\alpha$ Wald test?","['probability', 'statistics', 'statistical-inference']"
1513842,Extraneous Roots [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question When dealing with extraneous roots and checking them, if you find that one of the, two roots let's say, is extraneous, then does this imply that the other root is real or would one need to check the other root as well...so potentially it has no roots? I'm pretty sure the one root being extraneous would imply that the other root is real  just by thinking of it logically but I cannot ever remember being told this and cannot find verification anywhere else.",['algebra-precalculus']
1513906,"Integers of the form 89, 889, 8889,... not perfect squares","Show that an integer of the form 89, 889, 8889,... is not a perfect square. I know a perfect square will have an odd number of divisors so my first attempt would be assuming that an integer of the form 89, 889, 8889,... is a perfect square and then show that 89, 889, 8889,... all have an even number of divisors. I do not know how to begin proving that 89, 889, 8889,... all have an even number of divisors. Any hints or suggestions would be greatly appreciated. Thanks.",['number-theory']
1513934,Find $\lim (a_{n+1}^\alpha-a_n^\alpha)$,"Assume $\alpha \in (0,1)$, and $\{a_n\}$ is a strictly monotone increasing positive series. and $\{a_{n+1}-a_n\}$ is bounded. Find $$\lim_{n \rightarrow \infty}(a_{n+1}^\alpha - a_{n}^\alpha)$$. My idea is first proving for rational numbers , then use a rational sequences to approximate real numbers. But I can only prove for rational numbers. If $\alpha \in \Bbb{Q} \cap (0,1)$: $$a_{n+1}^\alpha - a_{n}^\alpha = a_{n+1}^{\frac{q}{p}} - a_{n}^{\frac{q}{p}}=\frac{\left((a_{n+1}^q)^{\frac{1}{p}}-(a_{n}^q)^{\frac{1}{p}}\right)\left((a_{n+1}^q)^{\frac{p-1}{p}}+(a_{n+1}^q)^{\frac{p-2}{p}}(a_{n}^q)^{\frac{1}{p}}+\cdots+(a_{n}^q)^{\frac{p-1}{p}}\right)}{(a_{n+1}^q)^{\frac{p-1}{p}}+(a_{n+1}^q)^{\frac{p-2}{p}}(a_{n}^q)^{\frac{1}{p}}+\cdots+(a_{n}^q)^{\frac{p-1}{p}}}=\frac{a_{n+1}^q-a_n^q}{(a_{n+1}^q)^{\frac{p-1}{p}}+(a_{n+1}^q)^{\frac{p-2}{p}}(a_{n}^q)^{\frac{1}{p}}+\cdots+(a_{n}^q)^{\frac{p-1}{p}}}=(a_{n+1}-a_n)\frac{(a_{n+1}^{q-1}+\cdots+a_n^{q-1})}{(a_{n+1}^q)^{\frac{p-1}{p}}+(a_{n+1}^q)^{\frac{p-2}{p}}(a_{n}^q)^{\frac{1}{p}}+\cdots+(a_{n}^q)^{\frac{p-1}{p}}}$$
For $\{a_n\}$ is a strictly monotone increasing positive series. then $\lim a_n = a$ or $\lim a_n = +\infty$ If $\lim a_n = a$. then $\exists M>0$. such that $$\left| \frac{(a_{n+1}^{q-1}+\cdots+a_n^{q-1})}{(a_{n+1}^q)^{\frac{p-1}{p}}+(a_{n+1}^q)^{\frac{p-2}{p}}(a_{n}^q)^{\frac{1}{p}}+\cdots+(a_{n}^q)^{\frac{p-1}{p}}} \right|<M$$. So $0\leq\lim (a_{n+1}^\alpha-a_n^\alpha) \leq \lim (a_{n+1}-a_n) M=0$ If $\lim a_n = +\infty$, then $$\frac{(a_{n+1}^{q-1}+\cdots+a_n^{q-1})}{(a_{n+1}^q)^{\frac{p-1}{p}}+(a_{n+1}^q)^{\frac{p-2}{p}}(a_{n}^q)^{\frac{1}{p}}+\cdots+(a_{n}^q)^{\frac{p-1}{p}}} \rightarrow 0$$
So for rational numbers, $\lim_{n \rightarrow \infty} (a_{n+1}^\alpha - a_n^\alpha) = 0$ For $\alpha \in (0,1)$, I choose $\alpha_k \in \Bbb{Q}\cap (0,1)$, and $\lim \alpha_k = \alpha$.  But I can't construct the following relationship $$\lim_{n\rightarrow \infty}\lim_{k\rightarrow \infty}(a_{n+1}^{\alpha_k}-a_{n}^{\alpha_k}) = \lim_{k\rightarrow \infty}\lim_{n\rightarrow \infty}(a_{n+1}^{\alpha_k}-a_{n}^{\alpha_k})$$ I want to follow this way to extend the index from rational numbers to real numbers. But I failed. Can we solve this problem using this method? Is there any other way to solve this problem?","['analysis', 'sequences-and-series']"
1513938,raising/ lowering indices,"Here is my understanding of tensors: There is more than one way to think about tensors. One way is be thinking about tensors as objects with components which obey some transformation laws.  For instance ${T^{abc}}_{def}$ is one component of the type $(3,3)$ tensor $T$.  To raise or lower indices you multiply by the metric tensor, like $g_{ah}g^{ei}{T^{abc}}_{def}={{{{{T_h}^{bc}}_d}^i}_f}$. Another way is to think of a type $(p,q)$ tensor as a multilinear function from the Cartesian product of $p$ copies of the dual space $V^*$ and $q$ copies of the vector space $V$ to the reals: $T: \underbrace{V^* \times \cdots \times V^*}_{\text{p times}} \times \underbrace{V \times \cdots \times V}_{\text{q times}} \to \Bbb R$. The way to recover the components of the tensor from the multilinear function is just by evaluating the tensor at the basis one-forms and vectors.  For instance, if $\{\omega^a\}$ is the standard orthonormal basis of one-forms and $\{v_a\}$ is the standard orthonormal basis of vectors, then $T(\omega^a, \omega^b, v_c, v_d) = {T^{ab}}_{cd}$. My question is: What corresponds to the idea of raising and lowering indices for the multilinear function form of a tensor?","['multilinear-algebra', 'mathematical-physics', 'differential-geometry', 'linear-algebra', 'tensors']"
1513949,"Are partial derivatives always commutative? When is $\frac{\partial^2}{ \partial x\partial y}f(x,y)\neq\frac{\partial^2}{\partial y\partial x}f(x,y)$?","I learned in my Calculus 3 class that $\frac{\partial}{\partial x}\left(\frac{\partial}{\partial y}f(x,y)\right) = \frac{\partial}{\partial y}\left(\frac{\partial}{\partial x}f(x,y)\right)$ Are there any counter examples to this?","['calculus', 'examples-counterexamples']"
1513982,"Looking for a quick ""randomish"" way to map 1..N to 1..N and back","This is related to a programming problem I have, but posted here because I think I'll get a better answer. I've got database records that have ID's 1,2,3,....  Assume I'll never have more than a couple million records.  Currently you can view that data by http://mysite/000000001 , http://mysite/000000002 , etc.  Manager would rather those numbers look more random so people don't think ""oh I'm the 352nd person to sign up"".  Are there any quick ways to generate a 1-1 reversible mapping that looks basically random? Ideas: Deterministically scrambling the digits and adding some constant is easily reversible but not quite random-looking enough. I know I can multiply by a prime factor of N (say I choose N to be a billion, I can multiply by 384720347) and then mod by N, which will give a 1-1 mapping.  That's probably the lower bound on ""random-looking"", but doesn't seem easily reversible.  (Correct me if I'm wrong). Notes: Of course I don't want to create a million-item lookup table. ""N"" isn't restricted to anything in particular, other than being somewhere between (say) a billion and a trillion.  If an algorithm only works assuming N is prime, or N is a power of 2, or N is 932483920 then that's acceptable.","['discrete-mathematics', 'number-theory', 'elementary-number-theory', 'combinatorics']"
1513992,Punctured disk in complex analysis,"According to the book I'm reading, the punctured disk is neither open nor closed. I understand why it isn't open, namely because it contains boundary points. But why is it not a closed set? All the points |z| = 1 or the boundary points are contained in the set. Unless they consider the point |z| = 0 to be a boundary point. Then the conclusion to why it is not closed is that the set does not contain the point|z| = 0. Is my reasoning correct or is there some other reason I'm not seeing as to why it would not be closed. Also, in this context, just to clear up confusion, the set of points that make up the unit circle |z| = 1 is a closed set, right? Even though it doesn't contain points |z| < 1. I'm unsure about the meaning of the closure of a set and a closed set. Thank you.","['complex-analysis', 'epsilon-delta']"
1514005,"If $ \int_0^{\pi}f(x)\cos(nx)\,dx=0$ for all $n$ then prove that $f\equiv 0$","If $f:[0,\pi]\to \mathbb R$ is continuous and $f(0)=0$ such that $\displaystyle \int_0^{\pi}f(x)\cos(nx)\,dx=0$ for all $n=0,1,2,\cdots$ then prove that $f\equiv 0$ in $[0,\pi]$. I want to apply Weierstrass approximation theorem. As $f$ is continuous so there exists a sequence of polynomials $\{p_n(x)\}$ such that $p_n(x)\to f$ uniformly. If I expand $\cos nx=1+\frac{n^2x^2}{2!}+\cdots$ then $$\int_0^{\pi}f(x)\,dx+\frac{n^2}{2!}\int_0^{\pi}x^2f(x)\,dx+\cdots=0.$$which implies  $\displaystyle \int_0^{\pi}x^{2n}f(x)\,dx=0$ for each $n=0,1,2,\cdots$. Is this step correct ? If yes then I can deduce from it that $f\equiv 0$. If I am Not correct then solve it please.","['analysis', 'real-analysis', 'definite-integrals', 'integration']"
1514019,The subspace associated with the affine set $C$ is the nullspace of $A$.,"This is an example from my book: Example 2.1: The solution set of a system of linear
equations, $C = \{ x | Ax = b\}$,  Where  $A \in R^{m\times n}$ and $b \in R^m$, is an affine set. To show this suppose $x_1, x_2 \in C$ then for any $\theta$ we have: $
A(\theta x_1 + (1-\theta)x_2) = \theta Ax_1 + (1-\theta)Ax_2 = \theta b + (1-\theta)b = b
$
Which shows that the affine combination $\theta x_1 +(1-\theta)x_2 $ is also in C.  The subspace associated with the affine set $C$ is the nullspace of $A$. I understand the proof but I cant understand the last sentence. From what I know if $x$ is a solution for $Ax = b$ Then every linear combination of x is a also a solution, And that is the definition of the range space. What am I missing here?","['calculus', 'linear-algebra']"
1514028,"How can I show that on $[-1,0]$ $|\sin(x)|\le|x|$?",It's pretty obvious to me as I see the plot of the two functions but how can I prove it with some algebra?,"['inequality', 'functions']"
1514047,Betti number of nonnegative Ricci curvature and positive scalar curvature closed 3-mfd,"Suppose that $M^3$ is a closed 3-manifold with nonnegative Ricci curvature and positive scalar curvature, I think $b_1(M^3)\leq 1$. Is this right and is there a quick cut proof?","['differential-geometry', 'riemannian-geometry', 'geometric-topology']"
1514057,Can we say that 'Limit' is an operator?,"Can we say that 'Limit' is an operator? This idea has come to mind visualizing the fact that "" '$\frac{d}{dx}$' is an operator and derivative of a function is defined by 'Limit'"".","['calculus', 'limits']"
1514078,"Finding the flux of the vector field $F=y^2\hat{i}+xy\hat{j}-z^2\hat{k}$ outward through the surface $z=2\sqrt{x^2+y^2}$ , $0\leq z\leq2$","I need to find $\iint_\limits{S}F\cdot\hat{n} d\sigma$ where $\hat{n}$ is the unit outward normal to the surface $S$. Here $S$ is just the conical surface without the base. If I parameterize the surface as follows : $$\gamma=r \cos\theta\hat{i}+ r\sin\theta\hat{j}+2r\hat{k}$$  then,
$$\iint_\limits{S}F\cdot\hat{n}d\sigma=\int_0^{2\pi}\int_0^1F\cdot(\gamma_r\times\gamma_\theta) dr d\theta$$
This gives the answer $-2\pi$. However the correct answer is $2\pi$. So I think I have not taken the correct outward direction for $\hat{n}$. My question is why is the unit outward normal not given by $\dfrac{\gamma_r\times\gamma_\theta}{|\gamma_r\times\gamma_\theta|}$ but by the negative of it for this problem? P.S. This is a homework question. Thank you!",['multivariable-calculus']
1514084,A Problem regarding properties of a matrix and the dimention of the vector space [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $A,B$ are two $n\times n$ matrices such that $A^2+B^2=AB$ and $AB-BA$ is invertible . Show that $3$ divides $n.$","['linear-algebra', 'matrices']"
1514098,"$|x^2-xy-y^2|=1$ implies that $x=\pm F_{n+1},\; y=\pm F_n$","So I've proved that $
A=
\begin{pmatrix}
1 & 1 \\
1 & 0
\end{pmatrix} 
\implies A^n= 
\begin{pmatrix}
F_{n+1} & F_n\\
F_n & F_{n-1}
\end{pmatrix}
$ for Fibonacci numbers $F_i$.  I'm also asked to show conversely that $|x^2-xy-y^2|=1$ implies that $x=\pm F_{n+1},\; y=\pm F_n$.  So it occurred to me that given $
\Lambda=
\begin{pmatrix}
x & y\\
y & x-y
\end{pmatrix}, 
$ the determinant of $\Lambda$ is $x^2-xy-y^2$.  If det $\Lambda=\pm 1$, then $\Lambda$ is non-singular.  The inverse is simple enough, and just playing around with stuff I noticed that $\Lambda^{-1}A\Lambda =A$ and so $A^n=\Lambda^{-1}A^n\Lambda$.  However I'm not sure how to proceed from here.    Any hints?","['combinatorics', 'fibonacci-numbers']"
1514147,Prove that a continuous image of a closed subset of a compact space is a closed subset,"Suppose $f$ is a continuous mapping from a compact metric space $X$ into a metric space $Y$. Prove that if $F$ is a closed subset of $X$, then $f[F]$ is a closed subset of $Y$. Here is my idea for the proof: The continuous image of a connected space is connected. Use the intermediate value theorem to show that the image of every continuous real-valued function is an interval, and should return closed sets into closed sets. Corrections are appreciated!","['metric-spaces', 'continuity', 'general-topology', 'compactness']"
1514172,Find domain of $ y = \arcsin\big(\frac{2}{2+\cos x}\big)$,"what is a principle of fining domain of Trigonometric func or inverse (arcsin,...)? I need find domain of this funciton $$ y = \arcsin\left (\frac{2}{2+\cos x}\right)$$ First step i do this: $$\arcsin(x) \in [-1,1]$$
$$-1 \leq \frac{2}{2+\cos x} \leq 1$$ =>
$$\cos x \geq 4 $$ and $$\cos x \geq 0$$
Am i true?","['trigonometry', 'functions']"
1514184,How to get this variational equation and this linearization?,"Consider the following system:
$$
u'=v,~~~~~v'=-cv-f(u)+w,~~~~~w'=-(\epsilon / c)(u-\gamma w).
$$ Here, $f(u)=u(u-a)(1-u),~a< 1/2$ and $\varepsilon,\gamma$ are positive. Here are two results I do not understand how to get them: (1) Let $S_{\epsilon}=(u_{\epsilon}, v_{\epsilon}, w_{\epsilon})$ be a solution. Consider the variational equations:
    $$
\delta u'=\delta v',~~~~~\delta v'=-c\delta v - f'(u_{\epsilon})\delta u+\delta w,~~~~~\delta w'=-(\epsilon /c) (\delta u - \gamma\delta w).~~~ (*)
$$ (2) $(*)$ is well approximated by the system linearized at $U_1=(u_1,v_1,w_1)$ (this is a special point of the phase space) with $\epsilon =0$:
    $$
\delta u' = \delta v,~~~~~\delta v'=-c\delta v-f'(u_1)\delta u+\delta w,~~~~~\delta w'=0.~~~(**)
$$ I would like to know how to get $(*)$ and $(**)$. Is variational equation and linearization the same?","['dynamical-systems', 'ordinary-differential-equations']"
1514204,All functions such that $f'(x) = f(x+1)-f(x) = \frac{f(x+2)-f(x)}{2}$ for all $x \in \mathbb{R}$,"I would like to find all (differentiable) functions $\mathbb{R} \to \mathbb{R}$ satisfying $$f'(x) = f(x+1)-f(x) = \frac{f(x+2)-f(x)}{2}$$ for all $x \in \mathbb{R}$. I claim that the only functions are $f(x) = ax+b$ with $a,b \in \mathbb{R}$. My proof goes as the following: Since $f'(x) = f(x+1)-f(x)$ and $f$ is differentiable, $f'$ is differentiable and we have $f''(x) = f'(x+1)-f'(x)$. By assumptions we get $2f'(x)+f(x) = f(x+2)$ and thus $$f'(x+1) = f(x+1+1)-f(x+1) = f(x+2)-f(x+1) = 2f'(x)+f(x)-f(x+1) = 2f'(x)-f'(x) = f'(x)$$ Therefore $f'(x+1)=f'(x)$ for all $x \in \mathbb{R}$, and $f''(x) = 0$ for all $x \in \mathbb{R}$. This proves that $f(x) = ax+b$. Is this proof correct? If not, what is wrong with it and what other functions satisfy these conditions?","['proof-verification', 'real-analysis', 'derivatives']"
1514231,P-value of a test of binomial success probability,"How do I get the $p$-value for tossing a coin 100 times with the result 30 Tails and 70 Heads for the null hypotheses $H_0=0.5$?
At best, a command in Matlab should be given to obtain this number, with a brief explanation of its derivation. Together with the result, i.e. whether we reject $H_0$. Moreover, what is the power (= the parameter $\beta$) of the test?","['hypothesis-testing', 'statistics']"
1514269,"How to prove that $(\mathbb Q,+)$ is not isomorphic to $(\mathbb Q^*,\times)$?","Given that there is the additive group $\mathbb Q$ of rational numbers, and the multiplicative group $\mathbb Q^*$ of non-zero rational numbers, prove that $(\mathbb Q,+)$ is not isomorphic to $(\mathbb Q^*,\times)$. How many methods can you think of and can you provide a complete solution? I am a self-learner of maths and feel difficult to offer a rigorous proof, but here are my thoughts: I could try to assume a isomorphism $\theta$ exists between the two groups and prove that $\theta$ cannot exist. I could try to find some property which should preserve under isomorphism but is satisfied only by one of the groups. However I could not proceed in either direction, could someone please help?",['group-theory']
1514285,Tricks to find $\dim H^0(O(D)(n))$,"Let $X$ be a curve of genus $g\neq 0$ and $D$ a divisor on $X$. If $n \in \mathbb{Z}$ and $O(D)(n)=O(D)\otimes O(n)$ is the twist of $O(D)$ by $n$, there is a manageable proceedings to find the dimension of $H^0(O(D)(n))$? If $\deg O(D)(n) <0$ we have easily $H^0(O(D)(n))=0$ If $\deg O(D)(n) > 2g-2$ by Riemann Roch we have $\dim H^0(O(D)(n)) = \deg O(D)(k) + 1 - g $. I'm in trouble in the other cases, where I've found just some bouds, given by degree of $O(D)(n)$, in particular, since $g>0$, if $D$ is effective we have $\dim H^0(O(D)(n)) \leq \deg O(D)(n)=n \deg D$ There are other possibly bounds? 
I'm even not sure about the last equivalence: $\deg O(D)(n)=n \deg D$.
It is wel known in the case X is a plane curve, holds it in general? Thank you for help!","['projective-geometry', 'algebraic-curves', 'algebraic-geometry', 'schemes', 'divisors-algebraic-geometry']"
1514288,Why does $\det A=0$ imply that there exists a non-zero solution to the homogeneous linear equations determined by $A$?,"Why does $\det A=0$ imply that there exists a non-zero solution to the homogeneous linear equations determined by $A$ ? Moreover, is it an ""if and only if"" case? That is, if there's a non-zero solution to the set of linear equations, does the matrix determined by the coefficients automatically have a determinant of zero?","['systems-of-equations', 'determinant', 'linear-algebra', 'matrices']"
1514295,Does the operation of a group matter when talking about isomorphism?,"When we say two groups are isomorphic to each other, do we have to specify the operations on each group? Does this matter? For example, here is a problem from the book 'Algebra and Geometry' by A.F.Beardon: Let $G$ be the group of real $2\times 2$ matrices of the form
  $$M(a)= \begin{pmatrix}
         a & a \\
         a & a \\
        \end{pmatrix}
$$
  where $a \neq 0$. Show that $G$, under the usual multiplication of matrices, is isomorphic to $\mathbb R^*$, the group of non-zero real numbers. I solved this problem by defining an isomorphism $$\theta(M(a))=2a$$
which does not involve any specification of the operation on group $\mathbb R^*$. So my question is : When we talk about the isomorphism between two groups, is it important to specify also the operations defining the two groups?",['group-theory']
1514312,Conformal iff $E=G$ and $F=0$,"Prove that a parametrization $x(u,v)$ is conformal (angle-preserving) if and only if the coefficients of the first fundamental form satisfy $E=G$ and $F = 0$. My attempt: It suffices to consider $e_1$ and $e_2$ in $\mathbb{R}^2$. It is easy to show that the differential $dx(e_1)=x_u$ and $dx(e_2)=x_v$. Note that $e_1$ and $e_2$ are orthogonal to each other, while $x_u$ and $x_v$ are also orthogonal to each other in the corresponding tangent space. Now, note that, by assumption, $$\cos \theta = \frac{\langle e_1,e_2\rangle}{\|e_1\|\cdot \|e_2\|} = \frac{\langle x_u,x_v\rangle}{\|x_u\|\cdot\|x_v\|} = \frac{F}{\sqrt{EG}}.$$ However, $\langle e_1,e_2 \rangle=0$ implies $F=0$. What about $E$ and $G$? I appreciate any hints here. Thanks in advance.",['differential-geometry']
1514354,Proof of non-existence of a continuous bijection between $\mathbb{R}$ and $\mathbb{R}^2$,"There are a lot of websites and forums, which explain that there is a bijection between $\mathbb{R}$ and $\mathbb{R}^2$, and even give some bijections. (By the way: Can you generalize it? since it works with the natural Numbers and the real numbers, does there exist a bijection between any infinite set $X$ and $X^2$) On some websites there is claimed that there doesn't exist a continuous bijection. But how would I approach such a proof? (I don't need a complete proof,... just a starting point because I have absolutely no idea how to begin this.)","['elementary-set-theory', 'continuity', 'general-topology']"
1514366,Prove that $A(A+B)^{-1}B=B(A+B)^{-1}A$,"Given $A$, $B$ are two square matrices, $A+B$ is non-singular, prove above state.
This is one part of my algebra mid term, of course, I failed, I have no idea where I should start. One thing appeared in my mind during the exam is $A(I+A)=(I+A)A$, $(I+A)$ is non-singular, how to represent A+B under that form... That maybe a wrong idea.","['linear-algebra', 'matrices']"
1514367,"Geometrically ruled surface, sections and intersection numbers.","Consider a geometrically ruled surface $\pi: S\longrightarrow C$ where both $S$ and $C$ are projective, non-singular and complex ($C$ is obviously a curve). By using Tsen theorem one can show that there exists a section $\sigma:C\longrightarrow S$ such that $\pi\circ\sigma=id_C$. Now, for every fiber  $F$ of $\pi$, it is clear that $\sigma(C)\cap F$ is a single point. But why $F.\sigma(C)=1$? I mean, a fibre $F\cong\mathbb P^1$
 and $\sigma(C)$ could have the same tangent line on the intersection point. (This ''fact'' is assumed as true without any explaination in Hartshorne book in the proof of the proposition $V.2.2$)","['surfaces', 'algebraic-curves', 'algebraic-geometry', 'schemes', 'divisors-algebraic-geometry']"
1514374,Group $G$ is nilpotent if and only if $G^n = 1$ for some $n \geq 0$,"This is from the book Abstract Algebra , $3$ rd edition, by Dummit & Foote; theorem $8$ on page $194$ . Definition ( upper central series ): For any group $G$ define the following subgroups inductively: $$Z_0(G) = 1, \qquad Z_1(G) = Z(G)$$ and $Z_{i+1}(G)$ is the subgroup of $G$ containing $Z_i(G)$ such that $$Z_{i+1}(G)/Z_i(G) = Z(G/Z_i(G)).$$ The chain of subgroups $$Z_0(G) \leq Z_1(G) \leq Z_2(G) \leq \cdots$$ is called the upper central series of $G$ . Definition ( nilpotent ): A group $G$ is called nilpotent if $Z_c(G) = G$ for some $c \in \Bbb Z$ . The smallest such $c$ is called the nilpotence class of $G$ . Definition ( $G^n$ and lower central series ): For any (finite or infinite) group $G$ define the following subgroups inductively: $$G^0 = G, \qquad G^1 = [G, G], \qquad \text{ and } G^{i+1} = [G, G^i].$$ The chain of groups $$G^0 \geq G^1 \geq G^2 \geq \cdots$$ is called the lower central series of $G$ . The next theorem shows the relation between the upper and lower central series of a group. Theorem $8$ : A group $G$ is nilpotent if and only if $G^n = 1$ for some $n \geq 0$ . More precisely, $G$ is nilpotent of class $c$ if and only if $c$ is the smallest non-negative integer such that $G^c = 1$ . If $G$ is nilpotent of class $c$ then $$Z_i(G) \leq G^{c - i - 1} \leq Z_{i+1}(G) \qquad \text{ for all } i \in \{0, 1, \ldots , c - 1\}.$$ Proof: This is proved by a straightforward induction on the length of either the upper or lower central series. $\square$ I don't see the straightforward proof here, and would like the complete details. Is there another book or reference that includes the complete proof in detail?","['abstract-algebra', 'group-theory', 'reference-request']"
1514390,"Prove $x=y$, given $\frac{1}{\sin x}+\frac{1}{\sin(x+\alpha)}=\frac{1}{\sin y}+\frac{1}{\sin(y+\alpha)}$","Given $x,y\in(0,\frac{\pi}{2}]$, $\alpha>0$ is a constant satisfying $0<x+y+\alpha<\pi$, Also it is known that $$\frac{1}{\sin x}+\frac{1}{\sin(x+\alpha)}=\frac{1}{\sin y}+\frac{1}{\sin(y+\alpha)}$$ How can we prove $x=y$ ""elegantly""? I am stuck on this problem for several days. Please help.","['algebra-precalculus', 'trigonometry']"
1514404,How to prove the concurrency of these lines?,"Suppose that in $\Delta ABC$ we take a point $D$ on $BC$ such that the incircles of $\Delta ACD$ and $\Delta ABD$ are tangent at a point.Now suppose that points $H$ and $I$ are defined on segments $AC$ and $AB$ in the same manner as $D$ was defined on $BC$ above. How can i prove that lines $AD,BH,CI$ are concurrent ? My attempt: I've applied Ceva's Theorem and by that I've got :$$ \cfrac{AH \cdot CD \cdot BI}{HC \cdot DB \cdot AI}=1$$ And after that I haven't really made so much progress,some of the thoughts I had was to prove that $AH=AI$ ,$CD=HC$ and $BI=DB$. But from that i don't simple know how to proceed,for example if we consider$AI=AH$,we see that we have to prove that $IS=UH$ but how to prove that?Same reasoning goes for the other equalities.. Also if you would adopt my approach how would you continue ? (I am not asking to post solutions only using this approach,but just any hint)","['euclidean-geometry', 'geometry', 'triangles']"
1514408,Matrix determinant lemma with adjugate matrix,"I would like a proof of the following result, given on wikipedia . For all square matrices $\mathbf{A}$ and column vectors $\mathbf{u}$ and $\mathbf{v}$ over some field $\mathbb{F}$,
$$
\det(\mathbf{A}+\mathbf{uv}^\mathrm{T}) = \det(\mathbf{A}) + \mathbf{v}^\mathrm{T}\mathrm{adj}(\mathbf{A})\mathbf{u},
$$
where $\mathrm{adj}(\mathbf{A})$ is the adjugate matrix of $\mathbf{A}$. Note that $\mathbf{A}$ may be singular. However, the proof given on wikipedia requires that $\mathbf{A}$ is nonsingular.","['determinant', 'matrices']"
1514485,Prove $S$ is composite,"HINTS ONLY Let $a, b, c, d, e, f$ be positive integers. Suppose that $S = a + b + c + d + e + f$
  divides both $abc + def $ and $ab + bc + ca − de − ef − fd$. Prove that $S$ is composite. Must be solved using polynomials in some way HINTS ONLY I was thinking of defining $P(x) = (x + a)(x + b)(x+c) + (x + d)(x + e)(x + f)$ such that $P(0) = abc + def$. And $S | P(0)$. But besides that, I dont see anything obvious. Hints please?","['contest-math', 'number-theory', 'elementary-number-theory', 'algebra-precalculus']"
1514488,Stopping times and hitting times for càdlàg processes,"I can't find the proof of the following lemma in any book: LEMMA: If $X=\{X_t\}_{t\in T}$ is adapted and right continuous, then for every closed set $C \subset E $, the variable $\tau_{C}:=\inf\{t\in T:X_t\in C\}$ is a stopping time. I know that this lemma is a particular case of Debut theorem. But in my opinion exists an easier proof of the lemma, anyone know some reference? I found the following proof but in my opinion it isn't correct: Proof: Set $d(\centerdot,\centerdot)$ the distance in $E$, it's easy to prove that for every $D\subset E$ the function $x\mapsto d(x,D)$ is continuous from $E$ to $\mathbb{R}$.
So, if $X$ is a right continuous process, for every $\omega \in \Omega$ the real function $u\mapsto d(X_{u}(\omega),C)$ is right continuous and is zero in every and only points $u\geq 0$ s.t. $X_u(\omega)\in C$. we can write:
$$\{\tau_{C}\leq t\}=\{\exists u \in T\cap[0,t]:d(X_u,C)=0\}=\{\inf_{u\in(T\cap[0,t]\cap\mathbb{Q})\cup\{t\}}d(X_u,C)=0\}$$
... I can't understand the last equality. In my opinion you need that the infimum is a minimum in order to claim this equality, but I can't understand why this is true.","['probability-theory', 'stopping-times', 'stochastic-calculus', 'stochastic-processes']"
1514520,Finding values of a piecewise function such that it is differentiable at $x=1$,"Let $$ f(x)= \begin{cases} a-x & x \leq 1, \\ \frac{1}{bx} & x>1. \end{cases} $$ Considering this piecewise defined function find values of $a,b$ such that the function is differentiable at $x=1$. Give the value of $f'(1)$. I don't know how to go about this question without having any actual numerical values. Any help would be greatly appreciated.","['continuity', 'derivatives']"
1514522,Infinite Discrete Form of Jensen's Inequality,"I refer to Wikipedia: https://en.wikipedia.org/wiki/Jensen%27s_inequality#Alternative_finite_form ""There is also an infinite discrete form."" There is no mention of how exactly the infinite discrete form looks like, but I guess that it is something like if: $\sum_{n=1}^\infty \lambda_n=1$, then $\varphi(\sum \lambda_n x_n)\leq \sum \lambda_n \phi(x_n)$. Is that correct? How is the infinite discrete form proved? Thanks a lot.","['analysis', 'real-analysis', 'inequality']"
1514620,Error in Stein Shakarchi Exercise on $H^{1}(\mathbb{R})$ and $L\log L$,"In Stein and Shakarchi's Functional Analysis (Princeton Lectures in Analysis Vol. 4), the authors claim in Section 2 Exercise 17 that the function
    $$f(x):=\dfrac{\chi_{|x|\leq 1/2}}{x(\log|x|)^{2}}$$
does not belong to the real Hardy space $H^{1}(\mathbb{R})$. Specifically, the authors write ""Consider the function $f$ defined by $f(x)=1/(x((\log x)^{2})$ for $0<x\leq 1/2$ and $f(x)=0$ if $x>1/2$, and extended to $x<0$ by $f(x)=-f(-x)$. Then $f$ is integrable on $\mathbb{R}$, with $\int f=0$, hence $f$ is a multiple of a 1-atom in the terminology of Section 5.2 Verify that $M(f)\geq c/(|x|\log|x|)$ for $|x|\leq 1/2$, hence $M(f)\notin L^{1}$, thus by Theorem 6.1 we know that $f\notin H_{r}^{1}$."" $H_{r}^{1}$ is their notation for the (atomic) real Hardy space. Theorem 6.1 refers to the $L^{1}$ boundedness of the maximal convolution operator $M(f)(x):=\sup_{t>0}|\Phi_{t}\ast f(x)|$ on $H_{r}^{1}$, where $\Phi$ is $C^{1}$ and compactly supported. This seems false. Decompose $f$ as
    $$\sum_{j=2}^{\infty}f_{j},\quad f_{j}:=f\chi_{2^{-j}\leq |x| < 2^{-j+1}}$$
Then
    $$\|f_{j}\|_{L^{\infty}}\leq \left(2^{-j}(\log|2^{-j+1}|)^{2}\right)^{-1}=\dfrac{2^{j}}{(j-1)^{2}(\log 2)^{2}}\leq c2^{-j}j^{-2}$$
By odd symmetry $\int f_{j}=0$ for all $j$. Since $|\left\{2^{-j}\leq x<2^{-j+1}\right\}|=2^{-j+1}$, we can define $\infty$-atoms $a_{j}$ by
    $$a_{j}(x):=(2c)^{-1}j^{2}f_{j}$$
and write
    $$f=\sum_{j}2cj^{-2}a_{j},$$
which belongs to $H^{1}(\mathbb{R})$. In fact, it seems that $f$ is precisely an example that the subspace of compactly supported $L\log L$ functions is properly contained in $H^{1}(\mathbb{R})$. Indeed, for $c>0$ sufficiently small
    \begin{align*}
		\int_{-1/2}^{1/2}|f(x)|\log^{+}|f(x)|dx&=\int_{-c}^{c}\dfrac{1}{|x|(-\log|x|)}dx=\infty
	\end{align*}
One can also see that $f\notin L\log L$, as the Hardy-Littlewood maximal function of $f$ is not integrable on a neighborhood of the origin. Returning to my original assertion, am I being silly here? Or is this indeed an error in the text.","['hardy-spaces', 'harmonic-analysis', 'functional-analysis']"
1514644,How to Find the value of a trigonometric function if other very complicated trigonometric equation is given?,"Q)If $\operatorname{sin}\alpha+\operatorname{cos}\alpha=\frac{\sqrt7}2$, $0 \lt \alpha \lt\frac{\pi}{6}, then \operatorname{tan}\frac{\alpha}2 $ is: (1)$\sqrt{7}-2$ (2)$(\sqrt{7}-2)/3$ (3)$-\sqrt{7}+2$ (4)$(-\sqrt{7}+2)/3$ i did this question by two ways but both the was were getting so complex however on solving them completely which took $4.25$ pages the answers were ridiculously different. $I^{st}$ Method: squaring both sides $$(\operatorname{sin}\alpha+\operatorname{cos}\alpha)^2=\frac{7}4=1+ \operatorname{sin}2\alpha=\frac 74\implies\operatorname{sin}2\alpha=\frac 34\implies\operatorname{cos}2\alpha=\frac{\sqrt{7}}{4}$$
$$\text{hence, }\operatorname{tan}2\alpha=\frac{3}{\sqrt{7}}\implies 3tan^2\alpha+2\sqrt{7}tan \alpha -3=0\implies tan\alpha=\frac{\surd7 \pm 4}3 $$ no from this if i want to calculate the value of $\tan\alpha/2  $   then you can think how different the answer could be! $II^{nd} $ Method $$1+2\sin\alpha\cos\alpha=\frac74\implies \sin^2\alpha\cos^2\alpha=\frac{9}{64}$$
$$64\sin^4\alpha-64\sin^2\alpha+9=0\implies \sin^2\alpha=\frac{64\pm 64\sqrt{7}}{2\times 64}$$ even from this you can have the idea how different the answer will be so different because the value of $$\tan\alpha=\sqrt{\frac{64 \pm16\surd7}{64 \mp 16\surd7}}$$.",['trigonometry']
1514690,Homemorphism from $S^n$ to $S^n$,"Let $S^n$ be the unit $n$-sphere($n\geq2$) and $X=\{a_1,...,a_k\}$, $Y=\{b_1,...,b_k\}$ be two finite subsets of $S^n$, does there exist a homemorphism $f$ from $S^n$ to $S^n$ such that $f(a_i)=b_i$ for $1\leq i\leq k$?","['algebraic-topology', 'general-topology']"
1514750,Criterion for Membership in Hardy Space $H^{1}(\mathbb{R}^{n})$,"Let $H^{1}(\mathbb{R}^{n})$ denote the real Hardy space (I am agnostic about the choice of characterization). It is known that if $f:\mathbb{R}^{n}\rightarrow\mathbb{C}$ is a compactly supported function (say in a ball $B$) such that $\int f=0$ and $$\int_{\mathbb{R}^{n}}|f(x)|\log^{+}|f(x)|dx<\infty$$ then $f\in H^{1}(\mathbb{R}^{n})$ and moreover, we have an estimate of the sort $$\|f\|_{H^{1}}\lesssim |B|\|f\|_{L\log L(dx/|B|)}$$ See Lemma 3.10 in these notes for details. One can also show this result by means of a Calderon-Zygmund decomposition for a truncated Hardy-Littlewood maximal function to produce an atomic decomposition for $f$. Suppose we now consider measurable functions $f$, not necessarily compactly supported, such that $\int f=0$ and $$\int_{\mathbb{R}^{n}}\left|f(x)\right|\log\left||2+|f(x)|\right|dx<\infty$$ Is it true that $f\in H^{1}(\mathbb{R}^{n})$? I don't have my intuition for the answer to this question at the moment. A corresponding result for functions $f\in L^{p}(\mathbb{R}^{n})$, where $1<p<\infty$, with $\int f=0$ fails. In one dimension, take $$f(x):=\dfrac{\text{sgn}(x)}{|x|^{(1+\epsilon)/p}}\chi_{(-1,1)^{c}}(x),$$ where $\epsilon>0$ is sufficiently small so that $(1+\epsilon)/p<1$. Since $f\notin L^{1}(\mathbb{R})$, we see that $f\notin H^{1}(\mathbb{R})$. The problem here is that we can have $f\in L^{p}\setminus L^{1}$. However, by considering the factor $\log(2+|f|)$, we have the estimate $$\int|f|\leq(\log|2|)^{-1}\int|f|\log|2+|f||,$$
which addresses this issue.","['hardy-spaces', 'harmonic-analysis', 'real-analysis', 'functional-analysis']"
1514761,What is the correct solution for the limit $\lim_{x\to\infty} x \sin\frac1x$?,"$$\lim_{x\to\infty} x \sin\left(\frac{1}{x}\right) = ?$$ Not a long ago I saw this function, and I was curious, what limit it has, when $x$ approaches $\infty$? Some of my friends said fast that it must approach $\infty$, since $\sin$ is a bounded function, and $x$ goes to infinity, therefore infinity * bounded must be infinity. Some others said that $\sin(\frac{1}{x})$ is $0$, since $\frac{1}{x}$ is $0$, when $x \rightarrow \infty$. So, the first possible solution should be $\infty$, but here is an other one. Let $y=\frac{1}{x}$. If $x \rightarrow \infty$, then $y \rightarrow 0$. Using that: $$\lim_{x\to\infty} x \sin\left(\frac{1}{x}\right) = \lim_{y\to 0} \frac {1}{y} \sin(y) = \lim_{y\to 0} \frac{\sin(y)}{y}  = 1$$ Here is a proof that, $\lim_{y\to 0} \frac{\sin(y)}{y}  = 1$: Proof So here we have $2$ completely different solutions for the same task, which both seem ""logical"". Is any of them correct, or if not, what should be the solution? Is this convergent, or divergent? Any help appreciated!","['limits', 'real-analysis', 'trigonometry']"
1514796,"$n$-words over the alphabet $\{0,...,d\}$ without consecutive $0$'s","I'm trying to solve the following problem in chapter 3 of Aigner's A Course in Enumeration: Let $f(n)$ be the number of $n$-words over the alphabet $\{0,1,2\}$ that contain no neighboring 0's. Determine $f(n)$. One is easily led to the recurrence $f(n)=2(f(n-1)+f(n-2))$ and the generating function $$F(x)=\frac{1+x}{1-2x-2x^2}.$$ At this point, I am trying to solve for $f(n)$. I used partial fractions to get
$$f(n)=\frac{1+\sqrt{3}}{2\sqrt{3}}(\frac{-1+\sqrt{3}}{2})^n+\frac{-1+\sqrt{3}}{2\sqrt{3}}(\frac{-1-\sqrt{3}}{2})^n$$
for $n\geq 2$, but I cannot reconcile this with Brian M. Scotts answer here: Recurrence relation for the number of ternary strings containing 2 consecutive zeros vs not containing I also tried generalizing, by looking at the $n$-words over $\{0,...,m\}$ with no consecutive $0$'s. This leads one to the generating function $$F_m(x)=\frac{1+x}{1-mx-mx^2}.$$
Since my determination of $f(n)$ gives incorrect values, I made a mistake. After an hour of checking, I just cannot find it. Furthermore, Aigner gives the following answer $$f(n)=\sum_i(\binom{n+1}{2i+1}+\binom{n}{2i+1})3^i,$$
which cannot come from this fibonacci-like approach. Any ideas?","['recurrence-relations', 'generating-functions', 'combinatorics']"
1514807,Distribution of sum of $n$ i.i.d. symmetric Pareto distributed random variables,"Let $X$ be a random variable which follows the symmetric Pareto distribution . For a fix, real parameter set $\alpha > 0$ and $L>0$, its PDF is defined as
$$
p_X(x) = 
  \left\{
  \begin{array}{ll}
    \frac{1}{2}\alpha L^\alpha |x|^{-\alpha-1}  & |x| \geq L \\
    0 & \mbox{otherwise.}
  \end{array}
  \right.
$$ If possible, I would like to derive PDF $p_S(x)$, where $S = \sum_{i=1}^n X_i$. Each $X_i$ is i.i.d. according to the PDF given above. I'm particularly interested in the tail distribution $\overline{F}_S(x) = Pr(S > x)$. My approach is to calculate the $n$-th power of the CF $\varphi_X(\omega)$ and calculate its Fourier transform to obtain $p_S(x)$. However, I'm uncertain if this procedure is valid here. Is it? Do any restrictions emerge inevitably w.r.t. $\alpha$? I observe some ""unhandy terms"". Is it possible to obtain $p_S(x)$ analytically and in closed form? First of all, the CF of a (one sided) Pareto distribution is given by $\varphi_Y(\omega) = \alpha L^\alpha (-i\omega)^\alpha\Gamma(-\alpha, -i\omega L)$. Is the upper incomplete gamma function well defined for a real negative exponent and imaginary integral bounds? I have
\begin{eqnarray}
\varphi_S(\omega) &=& \frac{1}{2^n}(\varphi_Y(\omega) + \varphi_Y(-\omega))^n\\
&=& \left(\alpha L^\alpha\right)^n|\omega|^{\alpha n}|\Gamma(-\alpha, i\omega L)|^{n} \cos \left( \arg \left( \Gamma(-\alpha, i\omega L)\right)+ \sigma(\omega)\frac{\alpha\pi}{2}\right)\;,
\end{eqnarray}
where $\sigma(\cdot)$ is the signum function. Alternatively, I have
\begin{eqnarray}
\varphi_S(\omega) &=& \left( \alpha L^\alpha \int\limits_{L}^\infty x^{-\alpha-1} \cos \left(\omega x \right) \,\mathrm{d}x \right)^n.
\end{eqnarray} Does this help in any way to get $p_S(x)$ or $\overline{F}_S(x)$? How could I proceed? P.S.: In my case, n is a power of 2. If the inversion has no chance to succeed for a fix $n$, what would be an appropriate approach to investigate $\lim_{n \to \infty} \overline{F}_S(x)$?","['probability-distributions', 'stochastic-integrals', 'problem-solving', 'probability', 'stochastic-analysis']"
1514808,Tangent of Cubic Hermite curve,"I have created cubic curve using CatmullRom Spline or Akima spline. From those, I obtain $a, b, c, d$ parameters. To get point on the curve, I do this $f(t) = a + bt + ct^2 + dt^3$ How to get tangent at $f(t)$? By just simply doing $ f´(t) = b + 2ct + 3dt^3$ or is this wrong and I have to calculate new $a, b, c, d$ as well? EDIT: For example, Catmull-Rom is calculated SplineSegment[] C = new SplineSegment[n];
for (all control points)
{
    C[i].a = 0.5f * (                 2 * cp[i]);
    C[i].b = 0.5f * (   - cp[i - 1]             +     cp[i + 1]);
    C[i].c = 0.5f * ( 2 * cp[i - 1] - 5 * cp[i] + 4 * cp[i + 1] - cp[i + 2]);
    C[i].d = 0.5f * (   - cp[i - 1] + 3 * cp[i] - 3 * cp[i + 1] + cp[i + 2]);           
} Natural cubic spline: SplineSegment[] C = new SplineSegment[n];
for (all control points)
{
    C[i].a = cp[i];
    C[i].b = D[i];
    C[i].c = 3 * (cp[i + 1] - cp[i]) - 2 * D[i] - D[i + 1];
    C[i].d = 2 * (cp[i] - cp[i + 1]) + D[i] + D[i + 1];
}

//D is calculated from Cubic spline matrix","['curves', 'spline', 'derivatives']"
1514829,Divisibility sequence resulting in limit with pi,"Consider the following sequence of operations : Start with a natural number $n$ and then round it up to the closest multiple of $n-1$ .Then round up this new number to the closest multiple of $n-2$ and so on until you round to a multiple of $1$ . Call this last number $f(n)$ . For example for $n=11$ the sequence is :
$11,20,27,32,35,36,40,40,42,42,42$ and this means that $f(11)=42$ At first it seemed to me that this sequence is extremely hard to predict because we can't know how the multiples are distributed . But to my amazement the following limit holds : Prove that: $$\lim_{n \to \infty} \frac{n^2}{f(n)}=\pi$$ What I found : If $k \leq \lfloor \frac{n}{2} \rfloor$ then after the $k$-th operation the number is $(k+1)(n-k)$ . This is not hard to prove by induction on $k$ . As an example the sequence for $n=11$ can be seen as :
$$11,2 \cdot 10,3 \cdot 9,4 \cdot 8 ,5 \cdot 7 ,6 \cdot 6, \ldots $$ But after this we have $40=5 \cdot 8$ that breaks the pattern .I couldn't find any such patterns for $k>\lfloor \frac{n}{2} \rfloor$ and the sequence afterwards seems pretty arbitrary . I am still amazed by how $\pi$ plays a role in this pure number theoretic question and I'd love to see a proof of the limit (or at least something new about the sequence ). Thanks for everyone that can help me with this extraordinary problem .","['pi', 'limits', 'number-theory', 'elementary-number-theory', 'divisibility']"
1514890,Proving that a function is not differentiable using a certain definition,"I have been given the following function: $$f(x,y) = \begin{cases} \dfrac{xy(2x^2 - y^2)}{2x^2 + y^2} & \text{if $(x, y) \ne (0, 0)$} \\ 0 & \text{if $(x, y) = (0, 0)$} \end{cases}$$ Now we would like to show that the partial derivatives are both continuous at the point $(0, 0)$, but neither one of them is differentiable at (0, 0). First we should analyze the behavior at $(0, 0)$, as the quotient rule will not apply at that point, so we should go by the definition: $$ f_x(0, 0) = \lim_{x \rightarrow 0} \dfrac{f(x, 0) - f(0, 0)}{x} = \lim_{x \rightarrow 0} \dfrac{0 - 0}{x} = 0 $$
$$ f_y(0, 0) = \lim_{y \rightarrow 0} \dfrac{f(0, y) - f(0, 0)}{y} = \lim_{y \rightarrow 0} \dfrac{0 - 0}{y} = 0$$ Then we can obtain the following partial derivatives: $$ \frac{\partial f}{\partial x} = \begin{cases} \dfrac{4 x^4 y + 8 x^2 y^3 - y^5}{\left(2x^2 + y^2\right)^2} & \text{if $(x, y) \ne (0, 0)$} \\ 0 & \text{if $(x, y) = (0, 0)$} \end{cases}$$ $$ \frac{\partial f}{\partial y} = \begin{cases} \dfrac{4x^5 - 8x^3 y^2 - xy^4}{\left(2x^2 + y^2 \right)^2} & \text{if $(x, y) \ne (0, 0)$} \\ 0 & \text{if $(x, y) = (0, 0)$} \end{cases}$$ My goal is to show that both of them are continuous at $(0, 0)$, but neither is differentiable. I have already shown that both of them are continuous by showing that both partials have a limit of $0$ at $(0, 0)$. (I just took the limit in polar coordinates). But to show differentiability, I am to use the following definition of differentiability: A function $f(x, y)$ is differentiable at $(x_0, y_0)$ if it can be expressed in the form: $$ f\left(x, y\right) = f\left(x_0, y_0\right) + \frac{\partial f}{\partial x} \Delta x + \frac{\partial f}{\partial y} \Delta y + \xi \left(x, y\right)$$ Where $\Delta x = x - x_0$, $\Delta y = y - y_0$, $r = \sqrt{(x - x_0)^2 + (y - y_0)^2}$ and $\xi$ has the following property: For any $\epsilon > 0$, there exists a $\delta > 0$ such that whenever $\delta < r$, $\left | \xi \right | < \epsilon r$. In other words, $\left | \xi \right |$ disappears faster than any linear multiple of $r$ as the point is approached. I am to use this definition to prove that the partial derivatives are not differentiable. How could I prove that, for some $\epsilon > 0$, there is no valid choice of $\delta$?","['partial-derivative', 'calculus', 'multivariable-calculus', 'derivatives']"
1514894,Confusion on the meaning of the Vitali- Covering Lemma,"In Folland, Lemma 3.15 gives a version of the Vitali-Covering Lemma: Lemma 3.15: Let $\mathscr{C}$ be a collection of open balls in $\mathbb{R}^{n}$, and let $U= \bigcup_{B \in \mathscr{C}} B$. If
  $c<m(U)$, there exists disjoint $B_{1}, \ldots, B_{k} \in \mathscr{C}$
  such that $\sum_{j=1}^{k} m(B_{j})> 3^{-n} c$. I am very unclear on the significance of this result. Is it true that $U \subset \bigcup_{j=1}^{k} 3 B_{j}$? If so, how is this implied by this lemma?","['lebesgue-measure', 'real-analysis', 'general-topology', 'measure-theory']"
1514901,"Evaluate $A_0=\dfrac{3}{4}$, and $A_{n+1}=\dfrac{1+\sqrt{A_n}}{2}$","Let $A_0=\dfrac{3}{4}$, and $A_{n+1}=\dfrac{1+\sqrt{A_n}}{2}$ for all $n\geq0$. How to find the value of  $\displaystyle\prod_{n=1}^\infty A_n$ ? I don't have any idea. Thank you.","['infinite-product', 'algebra-precalculus', 'trigonometry']"
1514956,Pointwise convergence implies $L^p$,"Simply, why is it that convergence pointwise, $u_j \rightarrow u$, implies convergence in $L^p$ if $|u_j(x)| \le g(x)$ for some $g$ in $L_+^p$?","['lp-spaces', 'convergence-divergence', 'real-analysis', 'measure-theory']"
1514983,Prove that function $g(n)=\zeta^{5n}$ is surjective from $\mathbb Z$ to the set of roots of unity,"I have this math problem, that I'm kind of stuck on. $\mu_{102} = \{ z \in \mathbb{C}: z^{102} = 1\}$ Let $\zeta = e^{\frac{2 \pi i}{102}}.$  Define $g : \mathbb{Z} \to
 \mu_{102}$ with the formula $g(n)= \zeta^{5n}$ for $ n \in
 \mathbb{Z}$.  Show that $g$ is surjective. I know that to prove a function is surjective I have to let $y\in \mu_{102}$ and find $x\in \mathbb{Z}$ such that $f(x) = y$. However, I'm not sure how to apply this to the given function.","['elementary-set-theory', 'roots-of-unity', 'complex-numbers', 'functions']"
1515022,Can the integral of Brownian motion be expressed as a function of Brownian motion and time?,"Let $W_t$ be standard Brownian motion, and define
$$
X_t := \int_0^t W_s ~\textrm{d}s.
$$
The marginal distributions of $X_t$ are easy to write down (see here ), but it doesn't seem possible to express $X_t$ as a function $f(t,W_t)$ of time and the process $W_t$ itself. Is it indeed impossible? And could somebody refer me to a proof?","['probability-theory', 'brownian-motion', 'stochastic-integrals', 'stochastic-processes']"
1515033,Every function on $\mathbb{R}^n$ that is continuous in each variable separately is Borel measurable.,"I'm trying to solve exercise 2.11 from Folland's Real Analysis. Firstly, how do we show that $f_n$ is Borel measurable on $\mathbb{R} \times \mathbb{R}^k$? I really have no idea how to show this when we have separately Borel measurable functions. Next, I can't show that $f_n\to f$ pointwise. For any $(x,y)\in \mathbb{R}\times \mathbb{R}^k$, $f_n(x,y)=n[f(a_{i+1},y)(x-a_i)-f(a_i,y)(x-a_{i+1})]=n[x[f(a_{i+1},y)-f(a_i,y)]+\frac{1}{n}[f(a_i,y)-f(a_{i+1},y)]]$, but because of the $n$ outside the bracket, I can't show that this converges to $f$. How can I show this? Also, how can I conclude from this fact that every function on $R^n$ that is continuous in each variable separately is Borel measurable? I would greatly appreciate any suggestions, hints, or solutions.","['analysis', 'real-analysis', 'measure-theory']"
1515035,Curious about an empirically found continued fraction for tanh,"First of all, and since this is my first question in this forum, I would like to specify that I am not a professional mathematician (but a philosophy teacher); I apologize by advance if something is wrong in my question. I enjoy doing numerical computations on my leisure time, and at the end of the last summer, I was working on some personal routines related to the world of ISC . With the help of these pieces of code, I detected algorithmically several identities, among which the following one
$$
\tanh z = \operatorname*{K}_{n=1}^{\infty} \frac{1 + \left((n-1) \frac{\pi}{4} z^{-1}\right)^2}{(2n-1) \frac{\pi}{4} z^{-1}} \tag{1} \label{1}
$$ The previous notation is the one I use; I find it convenient and it can be found for instance in Continued Fractions with Applications by  Lorentzen & Waadeland, but I know that some people don't like it; it has to be read the following way:
$$
a_0 + \operatorname*{K}_{n=1}^{\infty} \frac{b_n}{a_n} = a_0 + \cfrac{b_1}{a_1 + \cfrac{b_2}{a_2 + \cfrac{b_3}{a_3 + \dotsb}}}
$$ This continued fraction is nice when used for computing the hyperbolic tangent of numbers like $\pi/4$ and other simple multiples of $\pi$ since it will only involve integer numbers in the expansion of the continued fraction. Of course I browsed a little in order to see what was known about it, for example here , but I didn't find anything similar. I also sent it to several professional mathematicians, who told me that it could be difficult to recognize easily whether this continued fraction was equivalent
to some other identity or not. I haven't myself the required skills to study further this expression, but I would be very happy to know more about it: is it something well-known? Is it something that comes trivially from some other identity? Is it (who knows?) something new? Edit 1: I posted myself an answer to the question by thinking something new was found; but it happened to be related to the precision in the computation. For that reason I may delete this answer in the future. Edit 2: In this edit I am going to explain more how I came up with the identity and to add a code that can be used to test the identity. I will not post my C code here because it is too long but I can really share it if someone wants it. Basically: I coded in the end of last summer a program in C computing very quickly millions of random continued fractions; each one was computed up to its 36th convergent; convergence was checked by looking at the difference between 35th and 36th convergent. Any quadratic value was discarded as not interesting for my purpose. Remaining values were matched against all non-quadratic values in Shamos's catalogue of real numbers by computing the PSLQ vector for $[z,1,S]$ (where $z$ was a continued fraction and $S$ a number from Shamos's book). I used a personal hygienic C macro for the pslq algorithm that I share here . The precision when computing the PSLQ algorithm on double-precision numbers was ""poor"" (about 12 digits) but I focused on speed for this project. Whenever an interesting result was returned by the PSLQ algorithm (low norm of the returned vector), the continued fraction was computed a second time with the dd type from D.H. Bailey's libqd library (about 32 exact digits only but much quicker than any arbitrary precision library; furthermore precision in Shamos's book is only 20 digits). If the coefficients previously returned by the PSLQ algorithm were able to find again the relation with at least 17 exact digits, current parameters were printed. I made this program run for several weeks on three cores of a Raspberry Pi 2 (which is rather slow but which can compute long tasks without getting warm). Results had to be later generalized ""by hand"" when similar values were noticed by me. What I finally got was much more than I could expect. Above is one of these results. Below is some code for Maxima (using the bfloat types): /* Set the precision of the computation with bfloat numbers */
fpprec: 1024$

/* compute the n-th convergent of the continued fraction at x */
K(x,n) :=  block([ a,b,p1:1,p2:0,q1:0,q2:1],
  for k:1 thru n do (
    /* compute the k-th partial denominator as a */
    a:bfloat((2*k-1)*%pi/4/x),
    /* compute the k-th partial numerator as b */
    b:bfloat(1+((k-1)*%pi/4/x)^2),
    /* compute the k-th convergent as p2/q2 */
    p:a*p2+b*p1, q:a*q2+b*q1,
    /* shift values for simulating the matrix operation */
    p1:p2, p2:p, q1:q2, q2:q), p/q); You can try it online by using this link (just change the value at the end of the code once the page will be loaded). In a future edit I will add some plots illustrating the convergence of the continued fraction in \eqref{1} when the number of partial numerators (denominators) goes to infinity. Edit 3: Here is a plot showing the convergence of the continued fraction compared to the classical one for $\tanh$. The abscissa is the rank of the convergent (the last value of $n$ in the formula above):","['closed-form', 'number-theory', 'continued-fractions', 'hyperbolic-functions']"
1515086,Riemann like sums for Lebesgue integrable function,"Let $f(x)$ be a non-negative function on $\mathbb{R}$ such that $\int_{-\infty}^{\infty}f(x) \ dx=1.$ Actually, f(x) is a probability density function for a continuous random variable. Can I justify that 
$$
\lim_{n \rightarrow \infty} \sum_{m \in\mathbb{Z}} \frac{1}{n} f(\frac{m}{n}+\frac{z}{n})= \int_{-\infty}^{\infty} f(x) \ dx
$$
where $z \in [0,1]$ is fixed. I am trying to use Lebesgue Dominated convergence Theorem but which function should I pick up as a dominator to justify the exchange of limits and integrals ?","['real-analysis', 'measure-theory']"
1515093,Axioms of Affine Space,"In every definition of an affine space I see, the affine space is defined as a set $A$ with an associated vector space $V$ with a group action of $V$ on $A$. But I also see that vector spaces are often identified as ""affine spaces with an origin"". This makes me think (/hope) that we there should be some equivalent definition of an affine space that doesn't rely on the concept of a vector space.  Are there some axioms of an $n$-dimensional affine space (analogous to the ones for a vector space) that make no reference to vector spaces?  If so, would we then be able to show that an affine space equipped with an origin satisfies all of the vector space axioms?","['affine-geometry', 'linear-algebra', 'axioms']"
1515109,Can any 3d rotation be done with only two angles?,"Up until now I didn't really have to deal with rotation matrices, but now, a question has come up: Can I rotate a 3d vector in any way I'd like in 3d by only specifying two angles of rotation? My intuition tells me it is possible: Any 3d vector can be defined using two angles and the vector's norm. Using two rotations about an axis, we can rotate the vector relative to the XY plane and then relative to the XZ/YZ plane to get another vector in any direction we want. I found a few other intuitive explanations, but these aren't proofs. I have been told I'm wrong by a few people. Almost anywhere I look I see 3D rotations expressed in terms of 3 angles, but if I'm missing something, I can't for the life of me figure out what it is.","['linear-algebra', 'rotations']"
1515113,Does fractional part converge in distribution to a uniform random variable?,"Let $X$ be a continuous random variable with a density function $f(x).$ Let $\{x\}$ denote the fractional part of a real number. I am tryng to prove that 
$$
\mathbb{P}[\{nX\}\leq z] \rightarrow z, \ \ \forall z \in [0,1]
$$ Can anyone help me in this ? My attempt: If $g_n(z)$ is the density of $\{nX\}$, I got $g_n(z)=\sum_{m \in \mathbb{Z}}\frac{1}{n}f(\frac{m}{n}+\frac{z}{n})$. Can I justify from here ? One can assume nice properties on $f$ if needed but I want to keep those assumptions as minimal as possible.","['probability-theory', 'probability', 'probability-limit-theorems']"
1515145,Arbitrary factors for the (modified) Mathieu equation,"I am currently confronted with a physical equation that, after a fair amount of reworking, can be recast in the form of the modified Mathieu equation : \begin{equation}
y(x)'' - (a - 2q \cosh(2x)) y(x) = 0
\end{equation} In this case, the parameters $a$ and $q$ are somewhat arbitrary real numbers (q can be any positive real number but is bounded from below at a negative value), although they do obey the relation \begin{equation}
a = k^2 - 2q,\ k \in \mathbb{N}
\end{equation} But from what I can see on the Mathieu equation, those types of situations are very rarely taken into account and are instead generally speaking of the form \begin{equation}
y(x)'' - (a_n(q) - 2q \cosh(2x)) y(x) = 0
\end{equation} where only certain values of $a$ are considered, with $n$ generally integer, rational or in very rare cases real, and even then usually restricted to specific regions As far as I can tell, my equation will inevitably cross into the unstable regions for some configurations of the physical system. How can the modified Mathieu equation be dealt with in such circumstances? Does it differ significantly from the Mathieu equation in terms of stability? Is there any exact solution, or if not, can properties still be decided from it?","['stability-in-odes', 'physics', 'ordinary-differential-equations']"
1515154,Proving that $Df(\vec{0})=\vec 0$ for differentiable and even function $f : \mathbb{R}^n\to \mathbb{R}$,"Let $f : \mathbb{R}^n\to \mathbb{R}$ a function so that $f(\vec x)=f(-\vec{x})$ for all $\vec x\in \mathbb{R}^n$ ($f$ is even function). If $f$ is differentiable in all point $\vec x_0\in\mathbb{R}^n$. Calcule $Df(\vec{0})$. I know that $Df(\vec{0})=\vec 0\in \mathbb{R}^n$, now, then $$\lim_{\vec x\to \vec 0}\frac{f(\vec x)-f(\vec 0)-Df(\vec 0)\vec x}{\|\vec x\|}=\lim_{\vec x\to \vec 0}\frac{f(\vec x)-f(\vec 0)}{\|\vec x\|}$$ My quiestion is, how to prove that the previous limit on the right is zero? Thanks for your help.","['differential-geometry', 'multivariable-calculus', 'derivatives']"
