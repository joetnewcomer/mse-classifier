question_id,title,body,tags
2260986,Uniformization of metrics vs. uniformization of Riemann surfaces,"The uniformization theorem in complex analysis says that T1. Any Riemann surface of genus $0$ is conformally equivalent to the unit sphere. The uniformization theorem in differential geometry says that T2. Any smooth Riemannian metric on $S^2$ is conformal to the round metric. T2 implies that any metric $g_{ij}$ on a sphere has the form $e^\sigma (g_0)_{ij}$, where $g_0$ is the standard metric of the unit sphere. In particular, any two metrics are conformal to each other.
Here are a few paradoxical statements that seem to follow from this: Cor1. Any diffeomorphism $f:S^2\to S^2$ is a holomorphic map. This is because we can use this map to define a new metric $\,f_\ast g$, but the new metric must be conformal to the old metric, therefore $f$ is a conformal map. As far as I understand, being conformal in the sense of Riemannian geometry is the same as being conformal in the sense of complex analysis (?). Obviously, this is nonsense because the only holomorphic automorphisms of $S^2$ are the Möbius transformations. Cor2. Any coordinate chart on $S^2$ is conformal for any metric. This is because the metric is proportional to some other metric, which is diagonal in these coordinates, therefore is itself diagonal. This is also obviously nonsense because locally the matrix of the metric is an arbitrary symmetric positive $2\times 2$ matrix. What am I missing, and what is the relationship between T1 and T2? If I want to deform Riemannian metrics on the sphere (no complex structure), is it indeed enough to look at just the conformal variations, or are there nontrivial quasiconformal variations?","['riemann-surfaces', 'riemann-sphere', 'riemannian-geometry', 'differential-geometry']"
2260988,Showing a holomorphic function f is constant under certain conditions,"Let $f$ be holomorphic on the open unit disk $D = \{z : \space|z| < 1 \}$. Show that if any
of the following conditions holds, then f is constant in D: i. $f'= 0$ everywhere in D ii. $f$ is real-valued in D iii. $|f|$ is constant in D iv. $\arg(f)$ is constant in D How do you show all these?
Im thinking for the first one it would maybe be to do with the cauchy riemann equations but im not sure how to appoach this? and the I have an idea for the third that by liouvilles theorem $|f|$ is bounded and because it is holomorphic in this range it is therefore constant?",['complex-analysis']
2261052,"Differential equation, periodic solution, eigenvalues","Sorry for my bad english. Let $u : \mathbb{R} \rightarrow \mathbb{R}^n$ a solution of a linear differential equation $ x'(t) = Ax(t)$ $(1)$ with $ A \in M_{nn}(\mathbb{R})$. We suppose A is a diagonalizable matrix. We want to prove that if this equation has a periodic solution (non-zero) with period $T > 0$, then the matrix $e^{TA}$ has the eigenvalue $1$ ; and to deduce that if all the eigenvalues of A are real, then $(1)$ hasn't periodic solution non constant. I don't see how to make explicit it. Someone could help me ? Thank you in advance...",['ordinary-differential-equations']
2261062,Is there a topology so that $f(x)=x$ is continuous but $g(x)=x^2$ is not?,"Is there a topology $T$ on $\mathbb R$, so that $f : (\mathbb R,T) \longrightarrow (\mathbb R, T) , f(x) = x $ is continuous but $g : (\mathbb R,T) \longrightarrow (\mathbb R, T) , g(x) = x^2$ is not continuous?",['general-topology']
2261065,Why do most of the operations treating $dy/dx$ as a ratio works?,"We all know that since $\textrm{d}y$ and $\textrm{d}x$ are not numbers, we can't treat $\frac{dy}{dx}$ as a ratio. However, in various operations, this treatment seems to work. I've picked a few examples: Chain Rule: $$\frac{du}{dx} = \frac{du}{dy} \frac{dy}{dx}$$ Variable separation: $$ \frac{dy}{dx} = f(x)h(y)$$
$$\frac{dy}{h(y)} = f(x)dx$$ Integral of $\frac{dy}{dx}$ :
$$ \int \frac{dy}{dx}dx = \int dy = y$$
And there is also some examples that this treatment does not work:
$$\frac{dy}{dx} = - \frac{\partial F / \partial y}{\partial F / \partial x}$$
Where the minus sign shows that this is a counterexample. Now, if this isn't correct, why does it works for most cases? And, if it works for most cases, why there are a few cases that it won't work? Thanks. References 1) Answer from asmeurer in Is $\frac{dy}{dx}$ not a ratio?","['derivatives', 'calculus']"
2261079,What's an example of a nodal curve whose normalization has genus 1?,"Is there an example of an integral projective curve $X$ over an algebraically closed field $k$ with nodal singularities whose normalization is a (smooth) genus 1 curve? More generally, given any $g,n$, can we always find an integral projective curve $X$ over $k$ with $n$ nodes whose normalization is genus $g$?",['algebraic-geometry']
2261146,Calculate $\int_{-\infty}^{\infty} \frac{\sin^2(\pi Rx)}{R(\pi x)^2}dx$ for $R>0$.,"Calculate $$\int_{-\infty}^{\infty} \frac{\sin^2(\pi Rx)}{R(\pi x)^2}dx$$ for $R>0$. 
The value is $1$, but I don't know which integration technique I need to use to calculate this. I would greatly appreciate any help.","['integration', 'definite-integrals', 'calculus', 'analysis']"
2261193,Conditional distribution of $X$ given that $X+Y=2$,"I have $X$ and $Y$ independent $\Gamma(2,a)$-distributed random variables. I am trying to find conditional distribution of $X$ given that $X+Y=2$. My solution: set $U = X+Y, V = X.$ Inversion yields $ X=V, Y=U-V.$ $$f_{X,Y}(x,y)=f_X(x)\cdot f_Y(y) = \frac{1}{a^4}\cdot xy\cdot e^{-(x+y)/a} $$ $J = -1$, so $|J| = 1$, thus $$f_{U,V}(u,v) = f_{X,Y}(v, u-v)\cdot 1 = \frac{1}{a^4} \cdot v(u-v)\cdot e^{-u/a},$$ from which I got the $f_U(u) = \frac{1}{a^4}\cdot e^{-u/a}\cdot \left( u-\frac{v^3} 3 \right)$, then $$f_{V\mid U=2}(v) = \frac{f_{U,V}(2,v)}{f_U(2)} = \frac{e^{-2/a} \cdot(2v-v^2)}{a^4} \cdot \frac{a^4}{e^{-2/a}\cdot(2-v^3/3)} = \frac{3v(2-v)}{6-v^3},$$ but the book gives $\frac{3x}{2}\cdot(1-\frac{x}{2})$ Since $V=X$, the above $2$ should match, but not sure where I made the mistake.Checked multiple times, but no luck. Please help. Thank you.","['gamma-distribution', 'probability-theory', 'probability', 'random-variables']"
2261213,Integral representation of the Digamma function,"The digamma function is defined to be $\psi^{(0)}(x)=\frac{d}{dx}ln(\Gamma(x))$, from which we can derive: 
$$\psi^{(0)}(x)=\frac{d}{dx}ln(\Gamma(x))=\frac{\Gamma'(x)}{\Gamma(x)}$$ 
also,
$$\frac{d}{dx}\Gamma(x)=\int_{0}^{\infty}\frac{d}{dx}t^{x-1}e^{-t}dt=\int_{0}^{\infty}t^{x-1}ln(t)e^{-t}dt$$
therefore,
$$\psi^{(0)}(x)=\frac{\int_{0}^{\infty}t^{x-1}ln(t)e^{-t}dt}{\int_{0}^{\infty}t^{x-1}e^{-t}dt}$$
that's as far as I got, so my question is, is there a way to simply this expression so that the digamma function can be expressed as a single integral, as opposed to a quotient of integrals?","['calculus', 'analysis']"
2261220,How does one evaluate $\lim _{n\to \infty }\left(\sqrt[n]{\int _0^1\:\left(1+x^n\right)^ndx}\right)$?,I tried using Lebesgue's dominated convergence theorem and I'm getting $\lim _{n\to \infty }\left(1+\int _0^1x^ndx\:\right)$ which is $1$. But the answer should be 2.,"['definite-integrals', 'sequences-and-series', 'calculus', 'limits']"
2261274,The whole space is an open set in a metric space,"Let $(X,d)$ be a metric space. Then both $X$ and $\emptyset$ are open sets. I went over the proofs and it seems to be trivial, and I get it for $\emptyset$, but why must the whole space be open? Can't $X$ be a closed ball?","['general-topology', 'metric-spaces']"
2261294,$T$-Invariant sub-$\sigma$-algebra definition,"The following is (taken from) an exercise (2.1.7) from Einsiedler and Ward’s Ergodic Theory with a view towards number theory : Let $\mathsf{X}=(X,\mathscr{B},\mu,T)$ be a measure preserving system. A sub-$\sigma$-algebra $\mathscr{A}\subset\mathscr{B}$ with $T^{-1}\mathscr{A}=\mathscr{A}$ modulo $\mu$ is called $T$-invariant sub-$\sigma$-algebra. What does $T^{-1}\mathscr{A}=\mathscr{A}$ modulo $\mu$ mean? I’m thinking something along the lines of $\mu(T^{-1}A \Delta A)=0$ for all $A\in\mathscr{A}$, but I’m not sure (the book never defines this, or I must have missed it).","['ergodic-theory', 'measure-theory']"
2261332,How to calculate $14^{2017^{2017}} \mod 60$?,"$14^{2017^{2017}} \mod 60$ So, I know that I should begin with decomposing $60$ to the prime factors, which are: $ 3, 2^2, 5$, now I should calculate $14^{2017^{2017}} mod$ all three of these prime factors. My question is, what is the easiest way of calculating $14^{2017^{2017}} \mod 3$?","['congruences', 'modules', 'discrete-mathematics']"
2261357,Why are effective divisors the same thing as curves on $X$?,"In Vakil's FOAG, Chapter $20$, he starts section $20.2$ by writing Let $X$ be a regular projective surface, and $C$ and $D$ be effective divisors (i.e., curves) on $X$ ... My question is, why are effective divisors on $X$ the same thing as curves on $X$? I understand that divisors, up to linear equivalence, are the same as invertible sheaves because $Pic(X)$ is isomorphic to $Cl(X)$, and I understand that invertible ideal sheaves on $X$ are the same as effective cartier divisors, which are the same as curves on $X$ because these are closed subschemes $Y\hookrightarrow X$ cut out locally by one non-zero-divisor, so in particular $\dim Y=1$, i.e. $Y$ is a curve. It seems just a few more logical steps should give the correspondence Vakil uses here, but I don't see it immediately. It's probably been covered prior in the book, but I've skipped around sections a bit and must have missed it.","['schemes', 'curves', 'algebraic-geometry', 'divisors-algebraic-geometry']"
2261373,Superelliptical Trig Functions,"The six normal trigonometric functions relate to the unit circle and the coordinates of the endpoints of the radii making some angle $\theta$ with the x-axis (sine represents the y-coordinate, cosine the x-coordinate, and tangent the ratio of the two). Does there exist a analogous set of functions for the unit superellipse with equation
$$x^4+y^4=1?$$
I've been struggling to define such functions that are periodic and work for all values of $\theta$, $0$ through $2\pi$.",['trigonometry']
2261400,"Prove that for any connected graph, there exists a closed walk that visits every edge exactly twice. [duplicate]","This question already has an answer here : Show that every nontrivial connected graph $G$ has a closed spanning walk that contains every edge of $G$ exactly twice. (1 answer) Closed 4 years ago . For this to occur, every vertex has to have an even degree. Since this is a connected graph, we know that this must be true. How do you prove that the closed walk visits every edge exactly twice ? Does the existences of a closed walk mean that there is a cycle in the graph?","['graph-theory', 'discrete-mathematics']"
2261410,Proving bessel identity $[J_0(x)]^2 + 2[J_1(x)]^2 + 2[J_2(x)]^2 + \cdots = 1$ and $|J_0(x)|\le 1$,"The generating function for a Bessel equation is: $$g(x,t) = e^{(x/2)(t-1/t))}$$ Using the product $g(x,t)\cdot g(x,-t)$ show that: a) $$[J_0(x)]^2 + 2[J_1(x)]^2 + 2[J_2(x)]^2 + \cdots = 1$$ and consequently: b) $$|J_0(x)|\le 1, \forall x$$ c) $$|J_n(x)| \le \frac{1}{\sqrt{2}}; n=1,2,3,\cdots$$ For a) I tried the product: $$e^{(x/2)(t-1/t))}\cdot e^{(x/2)(-t+1/t))} = 1$$ I at least arrived at the right side of the equation. Since this generates the bessel functions, I should arrive at something related to $J_n$ in the left side. I know that $$e^{(x/2)(t-1/t))} = \sum_{n=0\infty}^{\infty} J_n(x)t^n$$ $$e^{(x/2)(-t+1/t))} = \sum_{n=0\infty}^{\infty} J_n(x)(-t)^n$$ but it's not just a matter of multiplying coefficients from the two infinite series, right? For $b$, I tried to use Proving Bessel equation $J_{0}(u+v) = J_0(u)\cdot J_0(v)+2\sum_{s=1}^{\infty}J_s(u)\cdot J_{-s}(v)$ but it's not as obvious I have no idea how to deal with $c$, could somebody help me?","['bessel-functions', 'physics', 'ordinary-differential-equations', 'sequences-and-series']"
2261418,Prove that $G$ or $\bar G$ must be nonplanar if G has 11 vertices.,"The exact problem is the following: ""Let G be a graph with 11 vertices. Prove that $G$ or $\bar G$ must be nonplanar. I went to my professor to discuss the proof, but she said it didn't quite work, that something was ""off"" about it. The following is the proof I presented: Let $G$ be a graph with 11 vertices. It is clear that $\lvert{E(G)}\rvert$+$\lvert{E(\bar G)}\rvert$=$\lvert{E(K_{11})}\rvert$=$55$. Assume, for the sake of contradiction, that both $G$ and $\bar G$ are nonplanar. Then $$\lvert{E(G)}\rvert+\lvert{E(\bar G)}\rvert \le (3\lvert{V(G)}\rvert-6)+(3\lvert{V(\bar G)}\rvert-6)=54. \Rightarrow\Leftarrow$$ 
Therefore, either $G$ or $\bar G$ is nonplanar. So, where exactly does this proof fail? Any tips on the aesthetics of the proof would also be greatly appreciated.","['graph-theory', 'planar-graphs', 'proof-verification', 'proof-writing', 'discrete-mathematics']"
2261479,(Average) Number of cycles of length m in permutations on N with k cycles,"Suppose we have permutations on $[1,2,...,n]$ that have exactly $k$ cycles (which there are $|s(n,k)|$ of where $s(n,k)$ is the Stirling number of the first kind). What is the average number of cycles of length $m$ for one of these permutations? Let's call this number $C(m,n,k)$. So for $m=1$, this is the total number of fixed points in all those permutations divided by |s(n,k)|. Even for this case I'm having trouble formulating a recurrence relation. We know by definition that $\sum_m C(m,n,k)=k$ and $\sum_m m.C(m,n,k)=n$. For example, for $n=4,k=2$, $|s(4,2)|=11$ and we have,
$$C(1,4,2) = 8/11, \qquad C(2,4,2) = 6/11, \qquad C(3,4,2) = 8/11$$
and for $n=9, k=3$, $|s(9,3)|=118124$ and we have,
$$\;\;\;C(1,9,3)=117612/|s(9,3)|=0.9957...,
\\\; C(2,9,3)= 63504/|s(9,3)|=0.5376...,\\\; C(3,9,3)=46032/|s(9,3)|=0.3897..., \\\; C(4,9,3)=37800/|s(9,3)|=0.3200...,\\\; C(5,9,3)=33264/|s(9,3)|=0.2816...,\\\; C(6,9,3)=30240/|s(9,3)|=0.2560...,\\\;C(7,9,3)=25920/|s(9,3)|=0.2194...$$ At the moment, I'm mainly interested in the case where $n=k^2$. From the above experiment it seems possibly \lim_{k\to\infty} C(1,k^2,k)=1. edit: From Marko's answer this is not true. Ultimately, I'm interested the cumulative distribution, say, 
$$\lim_{k\to\infty} \sum_{m=0}^{kx} C(m,k^2,k)$$ Any references or help would be greatly appreciated.","['stirling-numbers', 'cyclic-decomposition', 'generating-functions', 'permutations', 'combinatorics']"
2261486,finding different equivalence relations,"The original question is: How many different equivalence relations can we define on the set $A = \{x,y,z\}$? I illustrate my confusion in reaching a possible solution with 2 parts below: Part (1): The possible partitions of set $A$ are: a) $\{\{x\}, \{y\}, \{z\}\}$ b) $\{\{x\}, \{y, z\}\}$ c) $\{\{y\}, \{x, z\}\}$ d) $\{\{z\}, \{x, y\}\}$ e) $\{\{x, y, z\}\}$ Part (2): One possible equivalence relation is $\{(x,x), (y,y), (z,z)\}$. My question is, how can I use something from Part (1) to get to Part (2)? There is clearly something integral to equivalence relations that I am missing. I know that an equivalence relation is transitive, symmetric, and reflexive, but how does part 2 show transitivity or symmetry?","['equivalence-relations', 'elementary-set-theory']"
2261487,Complete measure spaces and convergence in $L^p(\mu)$,"Problem: Let $(X, \mathcal{M}, \mu)$ be a complete measure space. Prove that, if $f_n(x)$ converges to $f(x)$ in $L^3(\mu)$, then $f^3_n(x)$ converges to $f^3(x)$ in $L^1(\mu)$. My attempt: Let $\|f\|_p = \left(\int_X|f|^p\,d\mu\right)^{1/p}$. Then $$f \in L^3(\mu) \implies \|f\|_3 < \infty \implies \|f^3\|_1 = \|f\|^3_3 < \infty  \implies f^3 \in L^1(\mu).$$ My issue: I don't feel like this proof is complete or correct; I didn't use the fact that $(X, \mathcal{M}, \mu)$ is a complete measure space (at least, not explicitly; if I implicitly assumed it, I'm unsure where), and I'm not confident that my first and last implications are correct (I'm used to seeing things like $L^3[0, 1]$, but not $L^3(\mu)$). My request: If anyone could guide my apparent misunderstandings of the concepts used here, I would greatly appreciate it. If I'm on the wrong track, I'd also appreciate a nudge in the right direction (but NOT a full solution). Extra info: I'm using Royden's Real Analysis","['real-analysis', 'lp-spaces', 'measure-theory', 'convergence-divergence']"
2261494,Evaluate $\int_0^\infty \frac{\ln^2(z)}{1+z^2}$dz by contour integration [duplicate],"This question already has answers here : Evaluate $\int_0^\infty \frac{(\log x)^2}{1+x^2} dx$ using complex analysis (5 answers) Closed 7 years ago . Background: This is part b of problem 12.4.3 from Arfken, Weber, Harris Math Methods for Physicists to show that $\int_0^\infty \frac{\ln^2(z)}{1+z^2}$dz$=4(1-\frac{1}{3^3}+\frac{1}{5^3}-\frac{1}{7^3}+\dots)$. Part b of the question asks to show that this series evaluates to $\frac{\pi^3}{8}$ by contour integration. Where is my mistake: $\lim_{z \to 0}zf(z)=0$ and $\lim_{z \to \infty}zf(z)=0$ so the big and little circle equal 0.$ Drawing a branch cut along the positive x axis and integrating counterclockwise along the positive x-axis around a big circle the negative x-axis from infinity and the little circle: Assume $I=\int_0^\infty \frac{\ln^2(x)}{1+x^2}\text{dx}$ We can add the components of along the contour and set that equal to the value of $2\pi i \text{Res}[f(z),i]$ evaluated at the poles $\pm i$
$$\int_0^\infty \frac{\ln^2(z)}{1+z^2}\text{dz}+\int_{\infty}^0 \frac{\ln^2(z)}{1+z^2}\text{dz}=2\pi i \text{Res}[f(z),\pm i]\tag{1}$$ $$\int_0^\infty \frac{(\ln^2 \mid x\mid}{1+x^2}\text{dx}-\int_0^{\infty} \frac{(\ln\mid x\mid+2i\pi)^2}{1+x^2}\text{dx}=2\pi i \left (\lim_{z \to i}\frac{\ln^2(z)}{2z}+\lim_{z \to -i}\frac{\ln^2(z)}{2z}\right )\tag{2}$$ $$\int_0^\infty \frac{(\ln^2\mid x\mid}{1+x^2}\text{dx}-\int_0^{\infty} \frac{(\ln^2\mid x\mid+\color{red}{4\ln|x|i\pi}-4\pi^2)}{1+x^2}\text{dx}=2\pi i \left (\lim_{z \to i}\frac{\ln^2(z)}{2z}+\lim_{z \to -i}\frac{\ln^2(z)}{2z}\right )\tag{3}$$
$$0I+\color{red}{0}-\left[\tan^{-1}(x)\right]\mid^{\infty}_0(4\pi^2)\text{dx}=(2\pi i)  \left (\frac{-\pi^2/4+9\pi^2/4}{2i}\right )\tag{4}$$
$$0I+2\pi^3=\frac{8\pi^3}{4}\tag{5}$$ For explanation of the red integral see here , here or here . I found my error. It was a negative sign, and the two sides cancel to zero so you can't evaluate it this way, but I found an answer which evaluates it from negative to positive infinity so I'm marking the question as a duplicate. See dustin's answer at the link for the contour integration.",['complex-analysis']
2261508,Decomposition of differentiable function as a dot product?,"If $f:\mathbb{R}^n\to\mathbb{R}$ is a differentiable function with $f(0)=0$, then $f(\mathbf{x})=\mathbf{x}\cdot g(\mathbf{x})$ for some $g:\mathbb{R}^n\to\mathbb{R}^n$. I tried adapting the proof of Euler's homogeneous function theorem, but couldn't figure out a similar equation for a not necessarily homogeneous $f$. The reason I did this is because the right hand side looks like the result of differentiating $f(\alpha\mathbf{x})$ w.r.t. $\alpha$, where $g(\mathbf{x})$ is $Df(\mathbf{x})$. Any suggestions?","['derivatives', 'real-analysis', 'homogeneous-equation', 'multivariable-calculus', 'vector-analysis']"
2261509,Relationship between two Cauchy interlacing formulas,Let $A_n$ be an $n \times n$ Hermitian matrix and let $A_{n-1}$ be the $(n-1) \times (n-1)$ top-left minor.  The Cauchy Interlacing Formula says that the eigenvalues of $A_{n-1}$ interlace those of $A_n$.  (See Exercise 14 at https://terrytao.wordpress.com/2010/01/12/254a-notes-3a-eigenvalues-and-sums-of-hermitian-matrices/ ) The Cauchy Interlacing Formula for rank-one updates (See Theorem 6.7 at https://math.berkeley.edu/~nikhil/courses/270/lec6.pdf ) says that the eigenvalues of a Hermitian matrix $A$ interlace those of $A + v v^*$ for any vector $v$. Is there any relationship between these two theorems?,"['matrices', 'symmetric-matrices']"
2261526,Proof $f'(z)=0$ implies $f(z)$ locally constant.,"I am currently reading ""Theory of Complex Functions"" by Remmert and I encountered this theorem: Let $f:D\rightarrow\mathbb{C}$ be a complex holomorphic function. If $f'(z)=0, \forall z\in D$ , then $f$ is locally constant in $D$ . Here is part of the proof: Consider any open ball $B=B_{r}(b)\subset D$ and any $z\in B$ . Let $L$ denote the line segment from $b$ to $z$ and let $\epsilon>0$ be given. For each $c\in L$ , there is a disc $B_{\delta}(c)\subset D$ , $\delta=\delta(c)>0$ , such that $|f(w)-f(c)|<\epsilon|w-c|,\forall w\in B_{\delta}(c)$ . Because finitely many discs $B_{\delta}(c)$ suffice to cover the line $L$ , there is a succession of points $z_{0}=b,z_{1},\cdots,z_{n}=z$ on $L$ such that $|f(z_{i})-f(z_{i-1})|<\epsilon|z_{i}-z_{i-1}|, 1\leq i\leq n$ ."" $\cdots$ I understand why finitely many discs cover $L$ since it is compact. My question is how do you prove that there is a succession of points $z_{0},\cdots,z_{n}$ such that $|f(z_{i})-f(z_{i-1})|<\epsilon|z_{i}-z_{i-1}|$ ? The statements seems intuitively obvious but I can't provide the rigorous argument.",['complex-analysis']
2261527,Why is an M-estimator from statistics not necessarily measurable?,"I read somewhere that an M-estimator , defined as estimators that maximize a criterion of the form: $$
\theta \mapsto M_n(\theta) = \sum_{i=1}^{n}m_\theta(Y_i)
$$
for some functions $\{m_\theta: \theta \in \mathcal{H}\}$. $Y_i$ here are random variables. I read a remark in a textbook that an M-estimator is not necessarily measurable, since it is defined as an argmin or an argmax over an uncountable set $\mathcal{H}$. I do not understand what minimizing and maximizing over an uncountable set necessarily implies measurability. Could someone help me here? thanks.","['statistical-inference', 'probability-theory', 'robust-statistics', 'statistics', 'probability']"
2261546,"""Multi-valued limit"" $\lim_{(s,t)\to (\frac{1}{2}, \frac{1}{2})} \frac{t-s}{1-2s}$","I'm working on a larger problem and it would be very helpful if the following were true: For $0\leq s < \frac{1}{2}$ and $s \leq t \leq 1-s$, for every $\varepsilon > 0$ there exists a $\delta > 0$ such that if $\sqrt{(t-\frac{1}{2})^{2}+(s-\frac{1}{2})^{2}} < \delta$ then either
  $$\left|\frac{t-s}{1-2s} \right| < \varepsilon \text{$\quad$ or $\quad$} \left|\frac{t-s}{1-2s} - 1 \right| < \varepsilon$$ That is, as $s$ and $t$ both approach $\frac{1}{2}$, the function is either very close to $1$ or very close to $0$. It's not obviously true to me, but it would wrap the problem up nicely and I haven't been able to think of a counter example path.","['epsilon-delta', 'real-analysis', 'limits']"
2261551,Not sure how to use taylor theorem to show something is true for all real numbers.,Let $f:\mathbb R \to \mathbb R$ be a function which is differentiable at every $x \in \mathbb R$. a) Assume that $f'(x) = f(x)$ for all $x \in \mathbb R$ and $f(0) = 0$. Prove that $f(x) = 0$ for all $x \in \mathbb R$. (Hint: Taylor's theorem.) b) Assume that $f'(x) = f(x)$ for all $x \in \mathbb R$. Prove that $f(x) = f(0)e^x$.,"['derivatives', 'analysis']"
2261583,Find a particular solution of $\frac{1}{xD+1} (x^{-1}) $,"I'm familiar with sums where the coefficient of D is a constant. I don't know how to solve ones like these, and I don't know what these sums are called.
Can someone please suggest any reference material (available online) for this?",['ordinary-differential-equations']
2261593,"For the expectation of a random variable $Y$, what does the $dy$ term imply in: $\mathbb{E}[Y] = \int_{\mathcal{Y}}y \ p(dy)$?","For a random variable $Y$, assume that it has distribution $p$ on a space $\mathcal{Y}$. Then, I have seen the expectation of $Y$ written as: $$
\mathbb{E}[Y] = \int_{\mathcal{Y}}y \ p(dy)
$$ I am wondering why there is a $dy$ inside of the distribution $p$. Is this perhaps referencing the Lebesgue measure?","['probability-theory', 'probability', 'statistics']"
2261596,Find naturals numbers $p$ and $q$ such that $\frac{\sqrt{p^2+7}}{\sqrt{q^2-3}}$ is rational,Find naturals numbers $p$ and $q$ such that $\frac{\sqrt{p^2+7}}{\sqrt{q^2-3}}$ is rational i have taken $$\frac{\sqrt{p^2+7}}{\sqrt{q^2-3}}=\frac{a}{b}$$ where $a$ and $b$ are positive integers which are co prime  then after simplification we get $$3a^2+7b^2=(aq-bp)(aq+bp)$$ $$3(a^2+b^2)+4b^2=(aq-bp)(aq+bp)$$ Obviously $a$ and $b$ both cannot be even since they are co prime but now if i consider other cases i could not find $p$ and $q$...i will be happy if i get any hint,"['number-theory', 'prime-numbers', 'elementary-number-theory']"
2261656,Why are the roots of generator polynomials consecutive powers?,"When dealing with block codes such as BCH or Reed-Solomon. There is a concept called a generator polynomial (which is a special case of a polynomial code). As far as I can tell the definition of a generator - is a polynomial defined over a finite field that is the multiplication of roots that are consecutive powers. For example, a generator polynomial used in Reed-Solomon codes over GF$(q)$, the finite field of $q$ elements, is of the form $$g(x) = g_0 + g_1x + \cdots + g_nx^{N} = (x-\alpha)(x - \alpha^2)\cdots (x-\alpha^{N})$$ where $N=2t$ My question is why are the roots meant to be consecutive in value? Every definition I've read so far seems to suggest that is to be the case without providing an explanation. Would the code still (in all conditions) work if the N-roots were arbitrarily defined over elements in the field? like so: $$g(x) = g_0 + g_1x + \cdots + g_nx^{N} = (x-\alpha^7)(x - \alpha^4)\cdots (x-\alpha^{103}) + (x-\alpha^{28})$$ Any explanation or a link to a paper or some such explaining it all would be great!","['number-theory', 'finite-fields', 'coding-theory', 'polynomials']"
2261804,Show all matrices very similar to the identity matrix are invertible,"Please don't post completed solutions for 24 hours, as this is a homework problem, and I just need a bit of guidance. Given a $N\times N$ matrix A, let $|\mathbf{*}|_{2}$ be the sum of the squares of each element of such a matrix. If $|I-A|_2 \leq \frac{1}{2}$, then $A^{-1}$ must exist. Following is an overview of my attempts, not the question itself. From the assumption, it follows that the absolute value of every element of $|I-A|_2$ is less than $\frac{1}{2}$, or one is exactly $\frac{1}{2}$ and all others are $0$. I've attempted to show that such a matrix can be changed to row echelon form, by using the bounds of each element of $A$, showing that if I subtract some multiple of the first row from all following rows, $A_{2,2}$ must be positive, but it doesn't hold for the general case, specifically not for $A_{3,3}$. If the function $L_A$ (the linear map taking in vectors $v$ from $R^n$, and outputting $A\cdot v$) could be shown to map only $0_n$ to $0_n$, that would be sufficient, but my attempts to prove that have reduced to attempting to show that A can be reduced to ref form, and if I could show that directly, that would be sufficient proof. Similarly, if I could show $L_A$ to be injective or surjective, or that the kernel of $L_A$ was $\{0_n\}$, I could show that $A^{-1}$ must exist, but I have been unable to do so. Thank you in advance","['matrices', 'advice', 'linear-algebra']"
2261832,Disappearing conservative field with zero divergence: is it zero in higher dimensions?,"I have a vector field, which I know is conservative (it is the divergence of a scalar field). It has divergence zero, and it disappears at infinite distance. The dimensionality of the problem is arbitrary. I am working in a Euclidean space. If I understand correctly, then in two or three dimensions, this vector field is necessarily zero. This is because any vector-valued function is fully determined by its divergence (=0), its curl (=0) and its value on the boundary (->0). Does this finding extend to higher dimensions? Is a disappearing conservative field with zero divergence still necessarily zero?",['multivariable-calculus']
2261837,Why is the Hilbert space of Hilbert Schmidt operators important?,"The Hilbert Schmidt-operators form a Hilbert space with the inner product $\langle A, B \rangle = \text{tr}(B^*A)$.  What is the applications of this space?  What does it mean for $A$ and $B$ to be orthogonal?","['functional-analysis', 'hilbert-spaces']"
2261844,Confusion in fundamental theorem of calculus,"In the wikipedia article shown below, it says $A(x)$ represents the area beneath the curve $y=f(x)$ between $0$ and $x$ . Then it says $f(x)=A'(x)$ , i.e. $A(x)=\int f(x)dx$ which means $\int f(x)dx$ represents the area beneath the curve $y=f(x)$ between $0$ and $x$ . I think there is nothing wrong up to here. Now if we put $f(x)=e^{x}$ then $A(x)=e^{x}$ and at $x=0$ , $A(x)=e^{0}=1$ That is, the area $A(x)$ beneath the curve $y=f(x)$ between ( $0$ and $x=0$ ) is $1$ . Now how can we get non-zero area when we find the area between same points (i.e. $0$ and $0$ )","['real-analysis', 'integration', 'calculus']"
2261855,Finding the nth element of a sequence,"Suppose we have sequence given by $$ (1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,...) $$ I need to prove that $a_n = \lfloor{ \sqrt{2n} + \frac{1}{2} \rfloor} $ . Try: I notice the following. The last occurrence of 1 occurs at $a_1$ , the last occurrence of $2$ occurs at $a_3$ , the last occurrence of $3$ occurs at $a_6$ . So, if we define $F(n)$ to be the last occurrence of digit $n$ , then we guess $$ P(n) = \frac{n(n+1)}{2} $$ Who show by induction. base case is clear. Suppose the formula holds true for some $k$ , that is suppose $P(k) = \frac{ k(k+1) }{2}$ . Note $P(k+1) = P(k) + k+1$ since the (k+1)th last entry is k+1 positions after the kth entry. Thus, $$ P(k+1) = \frac{k(k+1)}{2} + k+1 = \frac{(k+1)(k+2)}{2} $$ and guess is true by induction. Now, let $a_n = m$ . Since $a_n$ must lie between $P(m-1)$ and $P(m)$ we have $$ P(m-1) < n \leq P(m) \implies \frac{ (m-1)m}{2} < n \leq \frac{m(m+1)}{2} \implies m^2 - m < 2n \leq m^2 + m $$ now, since $m^2 + m + 1/4 > m^2 + m$ and since adding $1/4$ to $m^2-m$ would still be less than $2n$ , then $$ m^2 - m + \frac{1}{4} < 2n < m^2 +m + \frac{1}{4} \iff (m-1/2)^2 <2n < (m+1/2)^2 $$ Thus, $$ m - 1/2 < \sqrt{2n} < m + 1/2 \implies m < \sqrt{2n} < m + 1$$ Hence, $m = a_n = \lfloor{ \sqrt{2n} + \frac{1}{2} \rfloor}$ . Is this a correct argument? Any feedback would be really appreciated. IS there a better approach to solve this problem?","['sequences-and-series', 'discrete-mathematics']"
2261896,Uniform sum of positive upper semicontinuous functions is upper semicontinuous?,"Let $X$ be a metric space. A real-valued function $f : X \rightarrow \mathbb{R}$ is upper semicontinuous if it satisfies one of the followings: $(1)$ For all $c \in \mathbb{R}$, its preimage $f^{-1}(-\infty,c)$ is open in $X$. $(2)$ For all $x \in X$ and all $\varepsilon>0$, there exists an open neighbourhood $U$ of $x$ such that for all $y \in U,$ we have $f(y) < f(x) + \varepsilon$. I know that finite sum of upper semicontinuous is upper semicontinuous. Question: Suppose for each natural number $n$ , $f_n$ is a non-negative upper semicontinuous function and $(f_n)$ is decreasing. Assume that $\sum_{n=1}^{\infty}(-1)^nf_n$ converges uniformly to $g$. Is $g$ an upper semicontinuous function?","['real-analysis', 'uniform-convergence', 'functional-analysis', 'semicontinuous-functions', 'metric-spaces']"
2261919,Reflexive closure of Banach space,"Given a Banach space $E$, need there exist a reflexive Banach space $\overline{E}$ and a map $T: E \to \overline{E}$ such that any map $S: E \to X$, where $X$ is a reflexive Banach space, factors through $\overline{E}$ via $T$? This $\overline{E}$ would then be a sort of reflexive ""closure"" or ""envelope"" of $E$. My initial thought was to look at the colimit of 
$$E \hookrightarrow E^{**} \hookrightarrow E^{****} \hookrightarrow \dots$$
but this is just a wild guess. For it to work, I'd need to know that the double dual commutes with colimits in the category of Banach spaces, and that seems doubtful to me.","['functional-analysis', 'banach-spaces']"
2261936,"Reference request on statistical convergence, asymptotics","I'm looking for good literature on asymptotics in statistics. I've learned about alsmost sure convergence, convergence in probability, convergence in law, $O_p, o_p$, etc... Definitions, theorems and limited examples. But besides the definitions I don't feel that I get what the true meaning of these concepts implies... Can someone give me a good reference which truly explains these concepts by means of graphs , intuition and perhaps simulation .","['reference-request', 'statistics', 'asymptotics']"
2261946,"What does ""hemicontinuity"" of a multi-valued ""function"" mean intuitively?","I am wondering about this. I saw this on Wikipedia: https://en.wikipedia.org/wiki/Multivalued_function One can differentiate many continuity concepts, primarily closed graph property and upper and lower hemicontinuity. (One should be warned that often the terms upper and lower semicontinuous are used instead of upper and lower hemicontinuous reserved for the case of weak topology in domain; yet we arrive at the collision with the reserved names for upper and lower semicontinuous real-valued function). There exist also various definitions for measurability of multifunction. But what does this mean, this ""upper and lower hemicontinuity"" and ""closed graph property"" mean intuitively ? The page on that ( https://en.wikipedia.org/wiki/Hemicontinuity ) doesn't seem to be quite as helpful as I'd like since it's in very general topological terms. The most familiar type of multivalued ""function"" (relation) I'm aware of is the ones involving complex numbers, but I presume all these arising from analytic continuations are simply continuous once maximally extended (thus presumably both upper and lower hemicontinuous)? I'm also familiar with ""semicontinuity"" of a real valued ordinary function (left and right continuity) -- is that what is being referred to here or something else? Is there a relationship? If we took a complex multivalued function, say, what would we have to do to it to make it only, say, upper hemicontinuous but not lower? What would such a thing ""look"" like? If we ""tear"" one of the sheets, would that do the job (leaving it still defined everywhere but we cut and bent one so that an 'edge' of discontinuity exists with continuity from one direction yet it still covers the plane. Obviously this breaks holomorphizm as well as continuity even outside the tear zone if we allow arbitrary deformation like this but we're not after that when we're dealing with a more basic geometric/topological property such as this)? That is, does the hemicontinuity of multi-valued map just generalization of the usual idea of continuity from one direction but not another to a multi-valued setting, or what? (It seems like maybe, but maybe not. What if we tear several sheets but they are one-sided continuous from different directions?) I'd be curious as to how this relates to this more familiar concept of the complex multivalued relation.","['general-topology', 'analysis', 'geometry']"
2261957,Probability of getting a second $6$,"A sister has two fair six sided dice, one red one blue, the dice are rolled together. The sister announces to her brother who is sat in another room and unable to see the dice, that there is at least one six in the outcome. Then asks him what are the odds that the other die is a six. He replies $1/6$, she says no it has to be $1/11$. Who is right or most likely to be right? Please help settle this family feud!","['probability', 'dice']"
2262000,Inequality: Norm of difference in exponential of matrices,"Let $A$ and $B$ be two matrices. Then,
$$
\|e^{A+B}- e^A\| \leq \|B\|e^{\|A\|+\|B\|}.
$$ Can anyone give me a proof or reference for this inequality, please? Thank you.","['inequality', 'matrices', 'reference-request', 'normed-spaces', 'matrix-exponential']"
2262006,Why is the plot of some functions so similar to the plot of ln(x)?,"Using https://www.desmos.com/calculator and my calculus knowledge (the integral power rule $\int x^n dx= (x^n+1)/(n+1)+C$ and the exception $\int x^{-1}dx=ln(x)+C$), I have noticed that functions like $1000(x^{0.001})-1000,\ 1000000(x^{0.000001})-1000000$ etc. have a very similar plot to $\ln(x)$. Is there any justification for why it is like that (apart from the integral rule I've mentioned)? Can logarithms of other bases than $e$ be approximated in a similar way? Thanks!","['logarithms', 'indefinite-integrals', 'functions', 'graphing-functions']"
2262011,Are there any other interesting topologies on $\mathrm{Spec} (A)$ other than Zariski's?,"This might be a somewhat stupid question, but I've been wondering if it is possible to define some other topology on $\mathrm{Spec} (A)$ other than Zariski topology in a way that it has some interesting properties as well. First of all, I am new as this is my first encounter with anything close or related to algebraic geometry, so be easy on me =). And second, what I'd like to know is if, for example, there is a topology on $\mathrm{Spec} (A)$ such that, say, $\mathrm{Spec} (A)$ is Hausdorff or has any other nice properties (connectedness, compactness, etc...), or why if such a topology exists, isn't as interesting as Zariski topology. Note: I am aware of a ""similar"" question here . However, I'm not interested that much in why Zariski topology is important since I think I understand how it arises naturally.","['zariski-topology', 'algebraic-geometry', 'commutative-algebra']"
2262017,Islands and bridges,"I stole this question from another site :) The archipelago of Wonderland consists of 131072 islands. For any two islands, there is a bridge that connects them. There are 17 managing companies that service at least one of these bridges each. The servicing personnel have decided to go on strike and therefore bring out of service some of the bridges but in such a way that with the remaining bridges, all islands can be accessed from any other island, either directly or through some other island. It has therefore been agreed that only some of the 17 companies will allow their personnel to go on strike. What is the maximum number of companies that can safely allow their personnel to go on strike, given the above condition? Really challenging but I have no clue what to do!","['combinatorics', 'graph-theory']"
2262036,Complex integral with non integer pole multiplicity,"I'm trying to calculate the following complex integral:
$$
\int\limits_{\sigma-i\infty}^{\sigma+i\infty}\frac{1}{s^\alpha}e^{as}\,ds
$$
where $a>0$, $\sigma\in\mathbb{R}$ and $\alpha\in (0,1)$. So far I have tried to use the residue theorem, but as $\alpha$ is not an integer it does not work. I have tried also to do a change of variables to get only integer exponents (without success so far). Maybe someone can give some advice on this. Thank you for reading.","['complex-analysis', 'complex-integration']"
2262037,Derivative of $\operatorname{arcsec } x$ using first principles,"$\DeclareMathOperator{\arcsec}{arcsec}$How is $\arcsec x$ differentiated using first principles? I tried substituting $A = \arcsec(x+h)$ and $B = \arcsec(x)$ while solving using $h \to 0$, but it doesn't seem to be a good idea (as $\arcsec(\sec x)$ is not always equal to $x$). Could anyone please post a detailed solution? P.S. 
The original question asked for the derivative of $\sqrt{\arcsec x}$; I managed to bring it till here after multiplying the denominator and numerator by conjugate of numerator and eliminating the square root. Help is appreciated. Thanks a lot.","['derivatives', 'trigonometry', 'calculus', 'limits']"
2262104,Functional equations $f\left(\frac{x+y}{2}\right)=\frac{f(x)+f(y)}{2}$ and $f(x)=\frac{f\left(\frac{2}{3}x\right)+f\left(\frac{4}{3}x\right)}{2}$.,"Suppose $f$ is continuous and $f\left(\frac{x+y}{2}\right)=\frac{f(x)+f(y)}{2}$. Can we claim that $f(x)=kx$? What if $f$ only satisfy $f(x)=\frac{f\left(\frac{2}{3}x\right)+f\left(\frac{4}{3}x\right)}{2}$? This functional equation was called Jensen's equation on wiki, but there is no further discussion about it","['real-analysis', 'functions', 'functional-equations']"
2262159,Recovering the Lie derivative of a covector from Cartan's formula on 1-forms,"The coordinate expression of the Lie derivative of a covector field, $w$ with respect to a vector field $X$ is given by: $$
\mathcal{L}_{X}w = \left(X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}} + w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}}\right)\mathrm{d}x^{\mu}
$$ But since a covector is also a 1-form, this should be recoverable using Cartan's formula: $$
\mathcal{L}_{X}w = \left(\mathrm{d}\iota_{X} + \iota_{X}\mathrm{d}\right)w
$$ where $\mathrm{d}$ is the external derivative and $\iota_{X}$ is the internal produce with respect to $X$. However, when I expand Cartan's formula, I get: $$\begin{align}
\left(\mathrm{d}\iota_{X} + \iota_{X}\mathrm{d}\right)w_{\mu}\mathrm{d}x^{\mu} &= \left(\frac{\partial X^{\alpha}w_{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}}\right)\mathrm{d}x^{\mu} \\
&= \left(w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}}\right)\mathrm{d}x^{\mu} \\
&= \left(X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}} + w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}}\right)\mathrm{d}x^{\mu} + X^{\alpha}\frac{\partial w_{\alpha}}{\partial x^{\mu}}\mathrm{d}x^{\mu}\\
&= \mathcal{L}_{X}w + X^{\alpha}\mathrm{d}w_{\alpha}\\
\end{align}$$ Most likely I've done something wrong (the extra term comes from the product rule on $\frac{\partial X^{\alpha}w_{\alpha}}{\partial x^{\mu}}$, but I'm not sure this the correct way to treat the gradient of $X^{\alpha}w_{\alpha}$), or there's some reason that $X^{\alpha}\mathrm{d}w_{\alpha}$ vanishes. $X^{\alpha}$ and $w_{\alpha}$ are in general not zero, so that implies the components of $w$ are closed, so: $$
\mathrm{d}w_{\alpha} = 0
$$ but I can't think of any way to justify this, since in general they're just functions on a manifold and functions aren't necessarily closed (are they?).","['differential-geometry', 'exterior-algebra']"
2262167,$\mathbb{Z}[G]$ isomorphic to $\mathbb{Z}[H]$ then what can be said about $G$ and $H$? [duplicate],"This question already has an answer here : Minimal counterexamples of the isomorphism problem for integral group rings (1 answer) Closed 7 years ago . The question in title has been considered for finite groups $G$ and $H$, but I do not know its situation, how far it is known whether $G$ and $H$ could be isomorphic. I have two simple questions regarding it. Q.0 If $\mathbb{Z}[G]\cong \mathbb{Z}[H]$ then $|G|$ should be $|H|$; because, $G$ is a free basis for the free additive abelian group $\mathbb{Z}[G]$ , am I right?  (I am asking this because in Isaac's character theory, I saw something different argument, not too lengthy, but I was thinking for the above natural arguments.) Q.1 Are there known examples of finite groups $G\ncong H$ with $\mathbb{Z}[G]\cong \mathbb{Z}[H]$? (In the book of character theory by Isaacs, he stated for metablelian groups $G,H$, $\mathbb{Z}[G]\cong \mathbb{Z}[H]$ implies $G\cong H$; it was proved by Whitcomb, in $1970$; but book has not been further revised, I don't known what is done after $1970$).","['finite-groups', 'representation-theory', 'ring-theory', 'group-theory']"
2262188,Finding the next term in a sequence.,"So this came up in a math competition some of students participated in over the weekend.  Expected highest level of mathematics is calculus 1. Let $a_n$ be an arithmetic sequence, $b_n$ be a geometric sequence and suppose that $c_n=a_n-b_n$.  The first four terms of $c_n$ are $2, 8, 6, 20$.  Find $c_5$. My students had two minutes and no calculator to answer this... I've played with this a bit and think that partial sums is probably the direction to go if this is going to be a 2 minute problem but I'm stuck!  I've gotten to a couple spots that I think are along the right direction but perhaps I'm not thinking about this correctly.  Here's what I know: $c_5=S_5-S_3-c_4$ So if I could find the partial sum at 5 I've got this... The other idea that I have is that the common ratio of the geometric series is $(-b_2)/(b_1)$ (I believe) but I'm still fairly at a loss as how to get our next term.  Some help would be appreciated!","['algebra-precalculus', 'sequences-and-series']"
2262198,Proof of the residue formula Res$(f(z);z_0) = -\frac{q''(z_0)}{(q'(z_0))^3}$ for a pole of order two,Suppose $f(z) = \frac{1}{(q(z))^2}$ where $q(z_0) = 0$ and $q'(z_0) \neq 0$ Show that Res$(f(z);z_0) = -\frac{q''(z_0)}{(q'(z_0))^3}$ I been messing around with $f$ for quite a while and honestly I have no idea how to even start. Any help or insights (or point me in the right direction) is deeply appreciated.,"['complex-analysis', 'residue-calculus', 'analysis']"
2262225,Why does $A^TAx = A^Tb$ have infinitely many solution algebraically when $A$ has dependent columns?,"This is a problem from least square approximation, where we solve the equation $A^TAx = A^Tb$ when $Ax = b$ is unsolvable. The case I am dealing with is when A has dependent columns, i.e. A is an m by n matrix where the rank r is smaller than n. In this case $A^TA$ is a singular n by n matrix with dependent columns, the rank of which is also r (Rank($A^TA$)=Rank($A$)). Now in the book Introduction to Linear Algebra of the legendary Gilbert Strang, he says and I quote, when A is singular, $A^TA$ is also singular, and the equation $A^TAx = A^Tb$ had infinitely many solutions, the pseudoinverse gives us a way to choose a ""best solution"" $x^+=A^+b$. I understand why the equation has infinitely many solutions geometrically : Because what the equation asserts geometrically is to find the projection of b, denoted by p, in the column space of A, then solve the new equation $A\hat x$ = p. Because we can always project b onto the column space of A, whether it's singular or not, we know there must be a solution to the equation $A\hat x$=p and if there is a solution, there are infinitely many because A is singular. My question is how do we know that the equation have infinitely many solution algebraically , to make it clearer, I don't understand why the equation has at least one solution. I do understand that once it has at least one solution, it has infinitely many. Algebraically, I understands that $A^Tb$ will take us to $C(A^T)$, and it will take away the part of b that lies in $N(A)$. But what does it has to do with   $C(A^TA)$ ? My hypothesis is there is some formula regarding $C(A^TA)$ and $C(A^T)$ that I am not aware of. For example, if $C(A^TA) = C(A^T)$, then my problem is solved. Also, I found this How come least square can have many solutions? , I know what  $\hat x^TA\hat x$ in sums will looks like, but I don't know where it came from, but assuming that this is actually correct, I understand the arguments made in that thread. Any instruction will be appreciated.","['matrices', 'least-squares', 'linear-regression', 'linear-algebra']"
2262246,A central limit theorem in renewal theory,"I failed to prove the exercise 27.15. in Billingsley's textbook. Let $X_1,X_2, \dots$ be i.i.d. positive random variables with expectation $m$ and variance $\sigma^2 \in (0,\infty)$. If $N_t = \max \{n : S_n \leq t \}$, then $$\frac{S_{N_t} -t}{\sqrt{t}} \Rightarrow 0.$$ I already proved that $\frac{t}{N_t} \rightarrow m$ as $t \rightarrow \infty$ and the following facts (what author gave me as hints): If $X_i$ are i.i.d. with $\mathbb{E}X^2 < \infty$, then $n \, \mathbb{P}(|X_1| \geq \varepsilon \sqrt{n}) \rightarrow 0$ and $\displaystyle n^{-\frac{1}{2}} \max_{1\leq k \leq n} |X_k| \rightarrow 0$ in probability. Any help will be appreciated. Thanks!","['real-analysis', 'probability-theory', 'central-limit-theorem', 'probability', 'measure-theory']"
2262268,Non-positivity of partial sums of certain Legendre symbols,"Let $T(c, k, p) := \sum_{i = 0}^{k} \left( \frac{i^2 + c}{p} \right) $, where $p$ is a prime number. It is known, that $T(c, p - 1, p) = -1$ for $p \nmid c$. Now, I would like the sequence $T(c, 0, p), T(c, 1, p), \ldots, T(c, p - 1, p)$ to be non-positive. So I wrote a program for searching such pairs $c < p$ and the result is quite interesting: there is no such pair for $c \in [12, 999]$ and $p < 200000$. The pairs that were found are $\{(2, 3), (2, 5), (2, 11), (3, 5), (3, 7), (5, 7), (5, 13), (5, 17), (6, 7), (6, 13), (7, 11), (10, 11), (11, 13)\}$. So here is my question: Are these the only pairs $c < p$ for which all partial sums of $\left( \frac{0^2 + c}{p} \right), \left( \frac{1^2 + c}{p} \right), \ldots, \left( \frac{(p-1)^2 + c}{p} \right)$ are non-positive? Another question is whether for given $c$ the first moment when this partial sum achieves a positive value is bounded by some constant. In other words whether $\forall_{c \in \mathbb{N}} \exists_{C_c} \forall_{p \in \mathbb{P}, p > C_c} \exists_{k \in \mathbb{N}, k < C_c} T(c, k, p) > 0$. I believe that the answer for this one is negative. EDIT:
regarding the first question, all partial sums are non-positive iff they all belong to $\{0, -1, -2\}$. So it would be enough to prove that for sufficiently large $p$ there will always be 3 consecutive quadratic residues or 3 consecutive quadratic nonresidues in $\left( \frac{0^2 + c}{p} \right), \left( \frac{1^2 + c}{p} \right), \ldots, \left( \frac{(p-1)^2 + c}{p} \right)$. I know that stronger result holds for the sequence $\left( \frac{0}{p} \right), \left( \frac{1}{p} \right), \ldots, \left( \frac{p-1}{p} \right)$, but I don't know the proof of it. Perhaps a similar approach could solve my problem? EDIT2: it could and it does.","['number-theory', 'legendre-symbol', 'elementary-number-theory']"
2262284,Convergence in Distribution of the maximum of a sequence.,"I've come across this problem which has completely stumped me. It goes as follows: Let $(X_n)$ be a sequence of independent and identically distributed exponential random variables with parameter $\lambda$. Let $M_n$ denote max{$X_1,...,X_n $}. Show there exists a random variable $Z$ such that $M_n - \frac{1}{\lambda} \log (n) $ converges in distribution to $Z$. Now this problem seems really hard, so I tried proving it for convergence in probability to see if that would work and imply convergence in distribution, but I couldn't get very far. Moreover, calculating the expectations also seems non-trivial due to the fact that it would be hard to integrate $M_n = \frac{1}{\lambda} \log n$. Any suggestions and ways to approach this problem would be greatly appreciated as I've been stuck on this for a long time. Should I try using the Skorohod equivalent statement? Thanks.","['probability-theory', 'probability', 'measure-theory', 'analysis']"
2262294,Integrating a sum of delta functions?,"I know that the ""hand-wavy"" definition of the $\delta (x)$ function is
$$  
\delta(x) = 
     \begin{cases}
       \infty &\quad\ x=0 \\
       0 &\quad\text{otherwise}
     \end{cases}
$$ and the more rigorous definition is that it's the limit of a sequence of functions $f_n$ for which $f_n(x) \rightarrow 0$ for all $x \neq 0$, and $f_n \rightarrow \infty$ for $x=0$, and (edited to add) $\int f_n = 1$ for all $n$. From this perspective, I see why the integral should be one, because the integral of all of the $f_n$ is equal to $1$. Now, suppose I want to construct a function $f(x,y)$ in the plane for which $$  
\nabla ^2f(x,y) = 
     \begin{cases}
       a &\quad\ (x,y) \in D \\
       0 &\quad\text{otherwise}
     \end{cases}
$$
where $D$ is some simply connected region. I can definitely solve $\nabla ^2f(x,y) = \delta(\|(x,y) - (x_0,y_0)\|)$ for any point $(x_0,y_0)$. This is just done by using the fundamental solution $$f(x,y) = \frac{-1}{2\pi} \ln\left( \|(x,y)-(x_0,y_0)\|\right)$$ My question is whether I can do the following: Because I want the Laplacian of $f$ to be as described above, can I write $$ f(x,y) = a \int_D \frac{-1}{2\pi} \ln\left( \|(x,y)-(x_0,y_0)\|\right) \,dA \quad ?$$ where $dA$ refers to integration with respect to $(x_0,y_0)$ over the area of $D$. My confusion is coming from the fact that: The Laplacian of $f$ will be the Laplacian of a sum of (infinitely) many $\delta$ functions, so intuition tells me it should be infinite; on the other hand, integrating a $\delta$ function gives $1$, so the factor of $a$ in front of the integral should give the desired result, no?","['partial-differential-equations', 'greens-function', 'laplacian', 'integration', 'boundary-value-problem']"
2262299,Solving simultaneous recurrence relations. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Need help solving the following system:
$$s_n=s_{n-1}+2t_{n-1}+2$$
$$t_n=-2s_{n-1}+t_{n-1}+n$$ $$n\ge2$$
$$s_1=1$$ $$t_1=2$$","['combinatorics', 'computer-science', 'discrete-mathematics']"
2262307,Orthonormal set for the set of compactly supported functions,"How to find an orthonormal set in the space of compactly supported smooth functions on $\mathbb{R}$? Moreover, for the operator $\frac{d^2}{dt^2}$, what are the eigenfunctions in the space of compactly supported smooth functions on $\mathbb{R}$?","['hilbert-spaces', 'operator-theory', 'functional-analysis', 'laplacian', 'eigenfunctions']"
2262311,Basic question on countable intersection and union of sets,"I am just a beginner at measure theory, and I have a very basic question on the following fact found in Robert Ash, Probability and Measure theory , page 7: Now this strikes me as a little asymmetric. Very informally speaking, and I know this makes no sense, but we seem to have to have a concept of ""$b^-$"" in that say $[a,b)=a...b^-$, a concept of {b} in $[a,b]=[a,b) \cup \{b\}$, but no corresponding concept of ""$a..b^+$"" which I would have defined exactly as per the first equation $\cap_1^{+\infty} [a,b+ {1\over n}) $ I ask because in David Williams ""Probability with Martingales"" 3.12, ""Skorokhod representation of a random variable with prescribed distribution function"", the distributions are perforce right-continuous - really, this is enforced (in my mind as it stands) by the 'asymmetry' above, as exhibited by the first equation. Put in another way which might make more sense: Is it possible to build a series of strictly decreasing sets $F_{n+1} \subset F_n$ such that the countable intersection $ \cap F_n=[a,b)$ ? (And just to make sure): Does anything change is we allow uncountable intersections in (1) above ? Thank you in advance.","['real-analysis', 'measure-theory', 'elementary-set-theory', 'probability-theory']"
2262319,determine the probability of each value multiple rolls of dice. stop once same number shown N times,"Trying help my daughter with a problem. The problem:
Two dice. Each numbered 1-6. Both dice are rolled at the same time to get one of 11 values in the range 2-12.
The 11 values have a different probability of occurring:
Number 2 has 1/36 probability of being rolled each time (1 + 1).
Number 3 has 2/36 probability of being rolled each time (1 + 2 and 2 + 1).
and so on. Keep rolling the dice until one of the values has been rolled N times. The first value to be rolled N times is the winner.
For each of the 11 values work out the probability of that value being the winner. Independent event probability means the multiplication of probabilities. For N = 2, the probability of getting 3 twice in two rolls is (2/36 * 2/36) = 4/1296 = 1/324.
Which means the probability of not getting 3 twice in two rolls is (2/36 * 34/36 + 34/36 * 34/36 + 34/36 * 2/36) = (68/1296 + 1156/1296 + 68/1296) = 1292/1296 = 323/324 But this problem allows me to keep rolling the dice until I get the same value come up N times.
Still assuming N = 2, that would the maximum would be rolling all the numbers once, then rolling the  1*11 + 1 = 12. I would need to roll the dice between two and 12 times to guarantee to get two matching values. 
I assume I need to add up the various probabilities for rolling 2 to 12 times. I start having trouble because I don't have/know a formula which calculates the probabilities of the different permutations for the different number of rolls. e.g The value 3 would win if you rolled 12 times getting 2,3,4,5,6,7,8,9,12,11,10,3 probability of ((2/36)^2 * (34/36)^12), but how many permutations? The value 3 also wins in these cases rolling only four times.
1,2,3,3 probability of ((2/36)^2 * (34/36)^2) is the same as 3,1,2,3 and so on But value 3 doesn't win in this case 3,1,1,3, so I can't just apply ((2/36)^2 * (34/36)^2) * NumberOfPermutations. Ultimately want to solve for N=8",['probability']
2262325,isomorphic extension fields of the $p$-adic numbers,"For an exercise I have to show that the number of non-isomorphic degree $2$ extensions of the field of $p$-adic numbers $\mathbb{Q}_p$ equals $3$. I was able to show that 
$$\mathbb{Q}_p^\times/\left(\mathbb{Q}_p^\times\right)^2 \cong \mathbb{Z}/2\mathbb{Z} \oplus \mathbb{Z}/2\mathbb{Z}$$
where $K^\times$ denotes the group of units in the field $K$. If I could prove that $\mathbb{Q}_p(\sqrt{d}) \cong \mathbb{Q}_p(\sqrt{e})$ if and only if $d = u^2e$ for $p$-adic numbers $d,e,u$, then I would be done. I recalled the proof that $\mathbb{Q}(\sqrt{2})$ is not isomorphic to $\mathbb{Q}(\sqrt{3})$, where it is shown that (well, at least in the proof I saw) that if there would have been an isomorphism, then $\sqrt{2}$ would be an element of $\mathbb{Q}(\sqrt{3})$, but this proof uses that the isomorphism would fix the rational numbers. I do not immediately see how to generalize this to the $p$-adic case. Any hints or would my approach be completely wrong? Answer using hint We might consider integers. Let $d,e$ be integers such that there is no $p$-adic number $u$ satisfying $d = u^2e$. Suppose however that $\mathbb{Q}_p(\sqrt{d}) \cong \mathbb{Q}_p(\sqrt{e})$ by some isomorphism $\phi$. Note that $\phi(1) = 1$, hence we have that 
$$d = 1 + 1 + \ldots + 1 = \phi(1)+ \ldots + \phi(1) = \phi(d) = \phi(\sqrt{d}^2) = \phi(\sqrt{d})^2$$
hence $\phi(\sqrt{d}) = \pm \sqrt{d}$. This implies that $\sqrt{d} \in \mathbb{Q}_p\sqrt{e})$. Since $\mathbb{Q}_p(\sqrt{e})$ is a vectorspace over $\mathbb{Q}_p$ of dimension $2$ we can pick a basis $\{1, \sqrt{e}\}$, from which we find that 
$$\sqrt{d} = a + b\sqrt{e}$$
with $a,b \in \mathbb{Q}_p$. However, this implies that $d = a^2 + 2ab\sqrt{e} + b^2e$ and this results in 
$$\begin{cases}
   d &= a^2 + b^2e\\
   0&= 2ab
\end{cases}$$
The last equations implies that either $a$ or $b$ is zero. But this implies that $d = b^2e$ respectively $d = a^2$. The former is not possible by assumption, while the latter does not give an extension of degree $2$. Hence these extensions can not be isomorphic.","['number-theory', 'group-homomorphism', 'extension-field', 'p-adic-number-theory']"
2262353,Probability of two people meeting in a given square grid.,"Amy will walk south and east along the grid of streets shown. At the same time and at the same pace, Binh will walk north and west. The two people are walking in the same speed. What is the probability that they will meet? I tried using Pascal's triangle but I have no idea how to proceed.","['combinations', 'combinatorics', 'random-walk']"
2262417,Finding the Cardinality of a Cartesian Product,"Problem : $$A=\{ 1,2,3, \dots, n \}$$ $$\text{ Find the Cardinality of ... } $$$$\{(a,S) | a \in S, S \in P(A)\}$$ So the way I've approached this problem thus far was to find the cardinality of $S$ and then multiply it by the cardinality of $a$. If I'm not mistaken the cardinality of $S$ should be $2^n-1$ as $S$ cannot be an element of itself and the cardinality of $P(A)$ is $2^n$. However, I'm having difficulty finding the cardinality of $a$. Is it just n? And if so, why is that?",['elementary-set-theory']
2262419,Do $\Bbb H$ and $\Bbb R^2$ have the same uniform structure?,"The hyperbolic upper half plane $\Bbb H$ and euclidean space $\Bbb R^2$ are not isomorphic as metric spaces, which can be see from the fact that in $\Bbb R^2$ for any point not on a geodesic there exists exactly one geodesic going through that point that does not intersect the original geodsic, whereas in $\Bbb H$ there exist infinitely many such geodesics. I cannot see any such argument that uses information visible to the uniform structure however. Are $\Bbb H$ and $\Bbb R^2$ isomorphic as uniform spaces?","['hyperbolic-geometry', 'general-topology', 'uniform-spaces', 'differential-geometry']"
2262424,A function of a Markov chain is necessarily again a Markov chain?,"I was curious about the above questions. If the answer is not, is there a mathematical proof of that? e.g. given a function $f:\mathcal X \rightarrow \mathcal Y$, with $\mathcal X$ a finite state space, find a Markov Chain $(X_n)_{n\ge 0}$ such that $(Y_n)_{n\ge 0}$ with $Y_n = f(X_n)$ is not a Markov Chain.","['probability-theory', 'information-theory', 'markov-chains', 'markov-process', 'probability']"
2262429,4 tangent lines to parabola with points on circle,"Parabola with focus F and circle with center F (the same F) have two points in their intersection. Show that there are points A,B,C and D on the circle such that the lines containing AB, BC, CD and DA are tangent to the parabola.
The hint was about choosing point A s.t. the line through AF and the line through the point A that is parallel to the axis of symmetry intersect the circle on symmetric (with respect to the axis of symmetry) points, and the take D and B to be the intersection of the tangents through A (to the parabola) with the circle and show that they are symmetric (again, with respect to the axis of symmetry).
I understand why D and B being as described finishes the proof, however, I don't see why is it true.
Thanks.","['contest-math', 'euclidean-geometry', 'geometry']"
2262441,Conservation laws for geometric/gravitational functionals,"Consider a compact Riemannian manifold $M$ with a metric $g$ and a geometric functional on it, i.e. a functional of only $g$: $$J[g]$$ This can be the volume, the Einstein-Hilbert action, the Green's function of the Laplace operator, the zeta function of $(M,g)$ etc. Define the variation $\Pi_{ij}$ of this functional by $$\delta J(g)[\delta g]=\intop_M \Pi_{ij}(x)\delta g^{ij}(x)\mathrm{d}V(x).$$ My question is if there exists a theorem that says $$\nabla^i \Pi _{ij}=0.$$ The basic idea for why this could be true is that since $J$ is a functional of only $g$, its variation is also a functional of only $g$. Therefore the $x$-dependence in $\Pi_{ij}(x)$ can come in only through $g_{ij}(x)$. However, covariant derivatives of the metric are zero. This becomes an actual proof for functionals of explicitly local quantities like the Einstein-Hilbert action $J=\int R\mathrm{d}V$. I would like to understand if this is extended to non-local functionals like $J=G(x,y)$, where $G$ is the Green's function of $\Delta$. I haven't been able to come up with a functional whose variation is known or easily computable for which this is not true. In physics these ""conservation laws"" are related to diffeomorphism invariance, but I wonder if this simple version of it can be made rigorous. One way to look at this is to say that the variation of the metric can always be written as $\delta g_{ij}=\nabla_i \xi_j+\nabla_j \xi_i$ for some vector field $\xi^i$. Then $$\delta J[g]=-2 \intop_M \nabla^i \Pi _{ij} \xi^j \mathrm{d}V.$$ If this variation were to be zero, we would have our conservation law. However, I see no reason for it to be zero. Somehow it looks suspiciously believable because, say, the Einstein tensor is divergenceless, and even the variation of the Green's function $G(x,y)$ seems to have this property away from $x$ and $y$ (based on some variational formulas I have found in the mathematical literature).","['mathematical-physics', 'physics', 'riemannian-geometry', 'differential-geometry']"
2262459,"Intuition behind Cauchy's theorem, simply-connected domain, and $\oint_C 1/z^2 dz = 0$","I am trying to develop an intuition for the difference between $\oint_C 1/z^2 dz = 0$ and $\oint_C 1/z \,dz = 2\pi i$. The classical proof of Cauchy's integral theorem seems to be to use Green's theorem along with the Cauchy-Riemann equations. This however, requires a simply connected domain, which $1/z^2$ doesn't have. So if $1/z$ and $1/z^2$ both have a pole at $0$, why do they behave differently when integrating around a closed curve? I know how to compute the integrals by parameterizing a circle of radius $1$ around $0$, so this is not what I am looking for. Terence Tao has an interesting explanation which I have a hard time wrapping my head around, so perhaps someone could explain starting from here? Another way to view Cauchy’s theorem is an assertion that every (continuously) differentiable function has an antiderivative. This is true infinitesimally (because $f(z_0)+f'(z_0)(z-z_0)$ has an antiderivative of $f(z_0)(z-z_0) + \frac{1}{2} f'(z_0) (z-z_0)^2)$, and it propagates to be true locally (by summing up and estimating the errors), and then (assuming no topological obstructions, such as poles) it is true globally. In one dimension, the corresponding statement is that every continuous function has an antiderivative (i.e. the fundamental theorem of calculus). In two dimensions, one needs an extra order of control on the function (continuous differentiability rather than just continuity) because one needs one better order of control on the error term to compensate for the extra dimension (dividing a non-infinitesimal two-dimensional region into infinitesimal ones requires many more pieces than for a one-dimensional region, thus allowing many more errors to accumulate.)","['complex-analysis', 'integration']"
2262475,Calculate singular integral,"Show that $$\int_{0}^{1}\log(\sin(\pi x)) dx=-\log(2).$$ I've tried using a toy contour consisting of a rectangle, but I don't know what to do with the singularities at $0$ and $1$. Every solution is welcomed, but I prefer to use complex analysis.","['logarithms', 'complex-analysis', 'integration']"
2262488,Matrix determinant as Dickson polynomial $\frac{x^{n+1}-y^{n+1}}{x-y}$,"Given matrix $$
A=\begin{bmatrix}
x+y&xy&0& .&.&. &0\\
1&x+y&xy&0& .&.&0 \\
0&1&x+y&xy&.&.&. \\
.&.&.&.&.&.&. \\
.&.&.&.&.&.&0 \\
.&.&.&.&.&.&xy \\
0&.&.&.&0&1&x+y
\end{bmatrix}
$$ prove by induction that $$|A|=\frac{x^{n+1}-y^{n+1}}{x-y}$$ $x \neq y$, $A_{n \times n}$. The determinant expression appears to be Dickson polynomial of second kind. Let $D_n$ be the determinant of $A_n$. We can see that the appropriate recurrence relation is $$D_n=(x+y)D_{n-1}-xyD_{n-2}$$ Base cases:
$$D_1=x+y=\frac{x^2-y^2}{x-y}$$ $$
D_2=(x+y)^2-xy=x^2+xy+y^2=\frac{x^3-y^3}{x-y}
$$ Suppose that $$D_n=(x+y)D_{n-1}-xyD_{n-2}$$
Then we need to prove that $$D_{n+1}=(x+y)D_{n}-xyD_{n-1}$$ Which can be developed as:
$$
D_{n+1}=(x+y)((x+y)D_{n-1}-xyD_{n-2})-xyD_{n-1}=
$$
$$
=(x+y)^2D_{n-1}-xy(x+y)D_{n-2}-xyD_{n-1}=
$$
$$
=(x^2+xy+y^2)D_{n-1}-xy(x+y)D_{n-2}=
$$
$$
=\frac{x^3-y^3}{x-y}D_{n-1}-xy(x+y)D_{n-2}
$$ I tried doing this up to $D_{n-6}$ in order to get any insights into possible simplification but I'm pretty stuck.","['induction', 'recurrence-relations', 'linear-algebra', 'determinant']"
2262555,Kronecker product of positive definite matrices,"I am looking for a reference where it is proved that given two positive definite matrices $A\in M_n$, $B \in M_m$, their Kronecker product $A\otimes B$ is positive definite.
More precisely, I am looking for a computation showing that 
$$\langle (A\otimes B)v,v\rangle \ge 0$$
for every $v\in \mathbb{C}^{mn}$. I specifically don't want to use the argument about the eigenvalues or the mixed-product and square roots, but a very direct computation of the inner product above. I would appreciate the help.","['matrices', 'reference-request']"
2262557,Identity with sum of reciprocals of binomial coefficients,How do I prove the following identity: $$\sum_{r=1}^{m} \frac{(m+1)(r-1)m^{r-1}}{r {m \choose r}} = m^m -1$$ I tried using the method shown in this answer to get the following integral: $$\frac{m+1}{m} \int_{0}^{1}(\frac{m^{m+1}(1-t)^{-1}t^{m-1}}{t(m+1)-1} + \frac{m(1-t)^{m-1}}{(t(m+1)-1)^2} + \frac{m^{m+1}t^m(1-t)^{-1}}{(t(m+1)-1)^2}) dt$$ But I have no idea on how to proceed from here.,"['combinatorics', 'integration', 'binomial-coefficients', 'sequences-and-series']"
2262682,Determining parametrization of curve from its acceleration,"I am doing a project in which I have an object experiencing acceleration in a direction changing with time.
I know the along-track and transverse acceleration components $a_{||}(t)$ and $a_{\perp}(t)$ in the comoving frame of the object, but not in an inertial reference frame. As time passes $a_{\perp}(t)$ increases while $a_{||}(t)$ decreases, so I expect the motion of the object to be a spiral in an inertial reference frame, and it is a parametrization of this spiral I am looking for. I have attempted to describe the curvature by $\kappa(t) = \frac{v(t)^{2}}{a_{\perp}(t)}$, where $v(t) = \sqrt{a_{\perp}(t)^{2} + a_{||}(t)^{2}} \ t$, and as expected I find the curvature to be increasing in time. Now how do I find a parametrization for the resulting motion in an inertial frame? I have looked into frenet-serret basis but the only thing resembling a solution I have not been able to find a solution.
The closes I have found is this parametrization for an arc-length parametrized curvature: $\eta(t) = \int_0^t\cos\left( \int_0^t \kappa(s)ds\right)ds$ But I get curve that spirals outwards in time from origo, not inwards. Any help is appreciated, am I going about this the wrong way?","['curves', 'differential-geometry', 'curvature']"
2262738,Solve $2x^2y'y'' - xy'' + y' =0$,"I'm solving the differential equation $2x^2y'y'' - xy'' + y' =0$ Can someone verify whether I'm correct? My attempt: We let $z = y'$ The differential equation becomes: $$2x^2zz' - xz' + z = 0$$ $$\Rightarrow 2x^2z\frac{dz}{dx} - x\frac{dz}{dx} + z = 0$$
$$\Rightarrow  -x + z\frac{dx}{dz} = -2x^2z$$ This is a Bernouilli equation in $x$. Let's substitute $u = 1/x, du/dz =-1/x^2dx/dz$ which yields: $$z\frac{du}{dz} +u = 2z$$ This is a first order linear differential equation, which has the solution (after separation of variables) $$u =c_1(z-2)$$ or $$\frac{1}{x} = c_1(y'-2)$$ and equivalently: $$y' = 2 + \frac{1}{c_1x}$$ and after integration: $$y = \frac{1}{c_1}\ln|c_1x| + 2x + c_2$$ I'm asking to verify this because the solution in my book says the solution should be $$1/2\ln|x| \pm 1/2 \sqrt{1_4c_1x^2} \mp 1/2\ln(1 + \sqrt{1-4c_1x^2}) \pm 1/2\ln(2\sqrt{|c_1|x} + c_2)$$",['ordinary-differential-equations']
2262789,Solving recurrence relation with non-constant coefficient,"Need help with this:
$$D_n=(n-1)(D_{n-1}+D_{n-2})$$
$$n\ge2$$
$$D_1=0,D_2=1$$ This is actually recurrence relation of derangement numbers.","['combinatorics', 'computer-science', 'discrete-mathematics']"
2262795,asymptotic growth of coefficients of two-variable power series,"Suppose you have a function of two variables, say $f(x,y)$, that is nice enough to equal a power series $\sum_{m,n} a_{m,n}x^my^n$ in some region about the origin. Is there a rough asymptotic formula for $a_{m,n}$ based solely on $m$, $n$ and the singularities of $f$? This question is essentially a two-dimensional version of the root test: if $f(x)=\sum_n a_nx^n$, and $r$ is the modulus of the smallest singularity of $f$, then $a_n\sim r^{-n}$. Two simple-but-contrasting examples are $f_1(x,y)=\frac{1}{(1-2x)(1-3y)}$ with $a_{m,n}=2^m3^n$ and $f_2(x,y)=\frac{1}{1-xy}$ with $a_{m,n}=0$ unless $m=n$ and then $a_{m,m}=1$. As a particular application, I am interested in approximating the coefficients of the rational function $\frac{1}{(1-x)^2(1-y)^2-xy}$, which is the generating function of an array of numbers of combinatorial objects I am studying.","['generating-functions', 'combinatorics', 'complex-analysis', 'asymptotics']"
2262808,Exterior derivative of 2-forms and divergence,"I'm working through A Geometric Approach to Differential Forms . The deriative of a $2$-form $\omega$ in $\mathbb{R}^3$, denoted $d\omega$ and operating on vectors $U, V, W \in T_p \mathbb{R}^3$, is defined as $$d\omega(U, V, W) = \nabla_U \omega(V, W) - \nabla_V \omega(U, W) + \nabla_W \omega(U, V)$$ where $\nabla_U \omega(V, W)$ denotes the directional derivative of $\omega(V, W)$ in the direction $U$. Suppose that we have a $2$-form $\omega = f(x, y, z) \ dx \wedge dy + g(x, y, z) \ dy \wedge dz + h(x, y, z) \ dx \wedge dz$. One way to calculate $d\omega$ is to realize that it must have the form $d\omega = a(x, y, z) \ dx \wedge dy \wedge dz$. Geometrically, we can think of $d\omega$ as taking three vectors, calculating the signed volume of the parallelogram formed by those three vectors, and then applying a scaling factor $a(x, y, z)$. So one way to determine $a(x, y, z)$ is to use the above definition of $d\omega(U, V, W)$ to see how it acts on vectors corresponding to a parallelogram of signed volume $1$. If I take $U = (1, 0, 0)$, $V = (0, 1, 0)$, and $W = (0, 0, 1)$, and I go through the computations, I arrive at $$d\omega = \left( \frac{\partial g}{\partial x} - \frac{\partial h}{\partial y} + \frac{\partial f}{\partial z} \right) \ dx \wedge dy \wedge dz.$$ This seems to be right as far as I can tell. In particular, the second term is given by $\nabla_V \omega(U, W) = \partial h / \partial y$, with the negative sign coming from the alternating signs in the definition of $d\omega(U, V, W)$. Explicitly, my calculation is $$\nabla_V \omega(U, W) = \nabla \left( \underbrace{f \begin{vmatrix} 1 & 0 \\ 0 & 0 \end{vmatrix}}_0 + \underbrace{g \begin{vmatrix} 0 & 0 \\ 0 & 1 \end{vmatrix}}_0 + \underbrace{h \begin{vmatrix} 1 & 0 \\ 0 & 1 \end{vmatrix}}_h \right) \cdot V = \frac{\partial h}{\partial y}.$$ Furthermore, I know that there's a connection between the exterior derivative of a $2$-form in $\mathbb{R}^3$ and the operation of the divergence. From, e.g., the Wikipedia description , it seems that divergence is $$(g, h, f) \mapsto \frac{\partial g}{\partial x} + \frac{\partial h}{\partial y} + \frac{\partial f}{\partial z}$$ where I've ordered $f, g, h$ for consistency with the representation of $\omega$. The difference here compared to my expression for $d\omega$ is that the term $\partial h / \partial y$ is positive rather than negative. Whence the difference?","['multivariable-calculus', 'differential-forms', 'divergence-operator', 'vector-analysis']"
2262828,Sum of two independent Martingale also martingale : solution from Ross,"Hi I am working on problem 6.8 from Sheldon Ross's Stochastic Processes book. The given solution at the back of the book goes like: Here I am confused on the red boxed part. How the assumption of X and Y's independency allows to go from $E[X_n|X_i + Y_i, i = 1,..,n-1]$ to $E[X_n|X_i, i = 1,..,n-1]$ in the inner expectation? I am having hard time to ""prove"" it systematically using properties of expectation. For the problem, I am thinking my solution more like this: $$E[X_n|X_i + Y_i, i = 1,..,n-1]$$
$$ = E[E[X_n|X_i + Y_i, i = 1,..,n-1]|Y_1,..., Y_{n-1}]$$
$$ = E[E[X_n|X_i, i = 1,..,n-1]|Y_1,..., Y_{n-1}]$$ 
$$ = E[X_{n-1}|Y_1,..., Y_{n-1}]$$
$$ = X_{n-1}$$ Could someone help me understand how to logically come to the rectangular boxed portion of the official solution?","['martingales', 'probability-theory', 'conditional-expectation', 'expectation']"
2262868,"Let $U$ and $V$ be vector spaces, and $T_1$ and $T_2$ be linear maps from $U$ to $V$ and $V$ to $U$ respectively, and are onto maps.","Let $U$ and $V$ be vector spaces, and $T_1$ and $T_2$ be linear maps from $U$ to $V$ and $V$ to $U$ respectively, and are onto maps. Are $U$ and $V$ isomorphic? If both space are finite dimensional then they are isomorphic. But in other cases? I think they are not isomorphic. But then I am finding it hard to find a counterexample. Any suggestion?",['linear-algebra']
2262896,Concluding divergence based on first and second derivatives,"I've just started a calc III course and we're currently reviewing calc II. While doing some problems about infinite sequences, I had the thought that if $\{a_n\} = f(n)$ for $n = 1, 2, 3, ...$ and if, for all values of $x$ greater than some $c$, $f$ is continuous with $f '(x) > 0$ and $f ''(x) > 0$ (or $f '(x) < 0$ and $f ''(x) < 0$), $\{a_n\}$ must be divergent. I saw my prof at office hours today and he agreed with the intuition. He said that if I could find or come up with a proof for this, I could use it on our quiz tomorrow to prove that sequences diverge. I haven't found any sort of proof and am having trouble figuring it out on my own (or maybe my intuition was wrong), so would anyone be able to confirm/deny this and help come up with a proof? Thanks in advance, Nicholas","['derivatives', 'sequences-and-series', 'calculus', 'proof-writing', 'convergence-divergence']"
2262905,What is the example of a module that is local but not endolocal?,A module $M$ over a ring $R$ is called local if $M$ has a largest proper submodule. A module $M$ over a ring $R$ is called endolocal if $End_R(M)$ is local. I am trying to find an example for a local module but not endolocal.,"['abstract-algebra', 'modules']"
2262907,Is there an easy way to evaluate this complex integral without partial decomposition?,"$$\int_{C_2(0)}\frac{1}{z^2+z+1}\ dz$$ Where $C_2(0)$ is the open ball of radius 2, centred at 0, in the complex plane. Using partial fractions and Cauchy's integral formula, I show'd the integral is equal to 0. However, the partial fractions part seemed unnecessarily long-winded to me. Did I miss a trick by approaching the problem using partial fractions?","['cauchy-integral-formula', 'complex-analysis', 'definite-integrals']"
2262931,"$x^6+2x^3-3x^2+1$, irreducible over $\mathbb{Q}$","$x^6+2x^3-3x^2+1$, irreducible over $\mathbb{Q}$. I am trying to determine whether or not the above polynomial is irreducible over the specified field, $\mathbb{Q}$. Some tools I have are: Eisenstein's Criterion, reduction $\mod p$ (where p is a prime), the rational roots theorem, among other smaller tricks. Eisenstein's Criterion cannot be applied since the $\gcd(2,3)=1$ which divides the leading coefficient. Moreover, the rational roots theorem asserts only that the polynomial does not reduce into a polynomial of degree $1$ and one of degree $5$; still, the polynomial might reduce. Therefore, I tried reduction $\mod p$. I figured that $x^6+2x^3-3x^2+1 \equiv x^6 +2x^3+1\mod 3$. Then, replace $x^3=y$ so that we have $y^2+2y+1 \mod 3$. Unfortunately, this does factor since $[2]$ is a zero and therefore we have learned nothing about the original polynomial. What is a different, better method of attack?","['irreducible-polynomials', 'abstract-algebra', 'polynomials', 'proof-verification']"
2262952,Rouche's Theorem and Roots [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Use Rouché’s Theorem to find the number of roots of the polynomial $z^5 +z^4 +3$ in the annulus $1 < |z| < 2$.","['complex-analysis', 'roots', 'complex-numbers', 'rouches-theorem']"
2262961,Understanding Takens' Embedding theorem,"I am having some trouble understanding Takens' embedding theorem , and was hoping that someone with greater knowledge could help out. Formally, the theorem goes as follows: Let $M$ be a compact manifold of dimension $m$. For pairs $(\phi,y)$, where $\phi : M \rightarrow M$ is a smooth diffeomorphism (an invertible function that maps one differentiable manifold to another such that both the function and its inverse are smooth) and $y : M \rightarrow \mathbb{R}$ a smooth function, it is a generic property that the $(2m+ 1)$--delay observation map $ \Phi_{(\phi,y)}: M \rightarrow \mathbb{R}^{2m+1}$ given by
  \begin{equation}
	\label{eq:mapping}
	\Phi_{(\phi,y)}(x) =  \left(y(x),y \circ \phi (x),\ldots,y \circ \phi^{2m} (x) \right)
\end{equation}
  is an embedding; by `smooth' we mean at least $C^2$. In English it says (not necessarily using the same notation as theorem) : Suppose that a measured time series $y(1),y(2),...,y(N)$ lies on a $D$-dimensional attractor of an $n$ th-order deterministic dynamical system. The starting point obtains an embedding from the recorded data. A convenient, though not unique, representation is achieved by using delay coordinates, for which a delay vector has the following form: $$\mathbf{y}(k) = [y(k),y(k-\tau),\ldots,y(k - (d_\text{e}-1)\tau)]^{\mathsf{T}},$$ where $d_\text{e}$ is the embedding dimension and $τ$ is the delay time. Takens has shown that embeddings with $d > 2n$ will be faithful generically so that there is a smooth map $f:\mathbb{R}^{d_\text{e}} \mapsto \mathbb{R}$ such that $$y(k+1) = f(\mathbf{y}(k))$$ for all integers $k$, and where the forecasting time $T$ and $\tau$ are also assumed to be integers. My issues: The time-series lives on some $D$-dimensional attractor, so that would be equivalent to saying we are measuring some system and we record data of dimension $D$? I.e. imagine we are measuring some system of stock prices consisting of three different stocks, and we sample this price at every $\Delta t$, then $D=3$? An $n^{th}$ order deterministic dynamical system, means that it has $n$ degrees of freedom? I don't understand what $n$ (or $m$ in the theorem actually is)? So assuming e.g. $n=4$, then as long as my $d_\text{e}=9$ or more I can accurately map from that space back to the measured space (this is still without knowing what $n$ actually represents)? Here's some Lorenz data that might aid explanations:","['differential-topology', 'smooth-manifolds', 'compact-manifolds', 'chaos-theory', 'differential-geometry']"
2262997,The $\limsup X_n \leq X$ almost surely,"I have this following problem on my Probability problem set. Let $(X_{n})$ be a sequence of random variables and $X$ another random variable in $(\Omega, \mathcal{F}, P)$ such that $P(\{\omega \in \Omega: \limsup X_{n}(\omega) \leq X(\omega)\}) = 1$. Show that for any $\epsilon > 0$, there is an event $A$ with $P(A) < \epsilon$ and $N \in \mathbb{N}$ large enough so $X_{n}(\omega) < X(\omega) + \epsilon$ for all $n \geq N$ and for all $\omega \in A^{c}$. Here's my work. Given $\omega \in \Omega$, $(X_{n} (\omega))$ is a sequence of real numbers and I will omit $\omega$ but I have already chosen one in $\Omega$. Let $k \in \mathbb{N}$. Then, $\limsup X_{n} \leq X + 1/k$ if and only if there is some $n_{0}$ such that $X_{n} \leq X + 1/k, \forall n>n_{0}$. If this is right, this translates to: $\{\omega \in \Omega: \limsup X_{n}(\omega) \leq X(\omega)\} = \bigcap_{k=1}^{\infty}\bigcup_{n=1}^{\infty}\bigcap_{z=n}^{\infty}\{\omega \in \Omega: X_{z} < X + 1/k\}$ Then, I think that the result follows because we can take $A$ as the complement of the set in the LHS, which will have measure zero, less then any given $\epsilon > 0$ and if we let $\omega$ in the RHS set, we will have that for all $n > N$, with $N$ large enough, the desired inequality. My question is if the translation from limsup properties to the set language is right and if the whole argument is sound. Thanks a lot for the support!","['probability-theory', 'limsup-and-liminf', 'probability', 'sequences-and-series', 'solution-verification']"
2263076,Rigorous proof of $f'(c)=0$ where $c$ is a global maximum,"My question is with regard to whether my following 'proof' is wrong or if it is an acceptable way to show that at a maximum $c$, $f'(c)=0$. A function  $f : [a,b]$ $ \to\Bbb R$ is differentiable at $c\in (a,b)$ and $f$ achieves a global maximum at $c$. Prove $f'(c)=0$. My Proof: Since $f(c)$ is a global maximum then $f(c)\ge f(x) \forall x \in (a,b)$. Using the definition of a derivative $f'(c)=\lim \limits_{x\to c}\frac {f(x)-f(c)}{x-c}$ we see that $f(x)-f(c)$ will always be negative. If we approach the limit from the left then $\lim \limits_{x\to c^-}f'(c)>0$, and if we approach the limit from the right then $\lim \limits_{x\to c^+}f'(c)<0$. But we know that $f'(c)$ exists so $f'(c)=0$.","['derivatives', 'real-analysis', 'limits']"
2263077,General procedure for finding an integral basis for ring of algebraic integers,"I have a question regarding an algorithm for finding the ring of algebraic integers $\mathfrak{O}_K$ in an algebraic number field $K$. The algorithm that I have been using is as follows: 1) Take a $\Bbb{Q}$-basis $w = \{ w_1, ..., w_n\}$ with $w \subset \mathfrak{O}_K$. Let $M$ be the $\Bbb{Z}$ span of $w$, so $M \subset \mathfrak{O}_K$. Calculate $\Delta[M]^2=\Delta[w_1, ..., w_n]^2$ - the usual discriminant. 2) If $\;[\mathfrak{O}_K:M]=m\quad$then $\quad|\Delta(M)^2| = m^2|\Delta(\mathfrak{O}_K)^2|$ If $|\Delta(M)^2|$ is squarefree then we know that $m=1$ and $w$ is a $\Bbb{Z}$ basis for $\mathfrak{O}_K$ Otherwise we check for each prime $p$ with $p^2$ dividing $|\Delta(M)^2|\;$ we look for $\alpha\in\mathfrak{O}_K$ of the form $\alpha = \frac1p\sum_jc_jw_j$ where $c_j\in\Bbb{Z}$ not all divisible by p. We can multiply through by an integer to make the $c_k$ which is not divisible by $p$ by 1. Clearly only need to check co-efficients $0\le c_j \lt p$. If we find such an $\alpha$ with $c_k$ not equal to zero, we replace $w_k$ with our $\alpha$ to get another $\Bbb{Q}$-basis, $M'$ and our discriminant is divided by $p$. 3) We repeat with our new basis $M'$. If such an $\alpha$ doesn't exist then $p$ doesn't divide $\;[\mathfrak{O}_K:M]=m\quad$ -we use a theorem of Cauchy on finite groups here I believe. My question is as follows, if we check a prime $p_1$ for basis $M$ and we find no such $\alpha$ of the form $\alpha = \frac{1}{p_1}\sum_jc_jw_j$ where $c_j\in\Bbb{Z}$ not all divisible by $p_1$, -so we move to the next prime $p_2$ with $p_2^2$ dividing $|\Delta(M)^2|\;$; if we find such an $\alpha$ and get a new basis $M'$, do we have to re-check all the possible $\alpha$'s for prime $p_1$ in our new basis $M'$ again?? Thanks","['number-theory', 'algorithms', 'algebraic-number-theory']"
2263089,Good final exam bonus problem for calculus students? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I'm making a final exam for a first course in calculus at a university.  I need some suggestions for a good bonus problem.  By ""good"" I mean an interesting problem that some of the brighter students could solve in about 15 minutes. Hopefully it should involve limits, derivatives, or integrals. The problem should NOT involve trig functions. The problem should NOT be theoretical. These students can't do real analysis proofs, for instance.",['calculus']
2263092,Is the Haar measure on the orthogonal group uniform on preimages of balls in orbits?,"Let $G$ be the orthogonal group on $\mathbb{R}^n$. The norm on $G$ is the operator norm. $G$ is a compact (Lie) group, so it has a unique Haar measure $\mu$ of total measure 1 which is both left and right invariant. Fix a unit vector $x_0 \in \mathbb{R}^n$. The orbit of $x_0$ is $Gx_0 = S^{n-1} \subseteq \mathbb{R}^n$. The map $\alpha: g \mapsto g x_0$ is a surjection from $G$ to $S^{n-1} \subseteq \mathbb{R}^n$. Cover $S^{n-1}$ by balls $B_i$ in $\mathbb{R}^n$ of radius $r$ whose centers lie on $S^{n-1}$. I think the preimages $\alpha^{-1}(B_i)$ of the balls should all have the same measure (say up to a constant factor). How can I prove (or disprove) this? EDIT: https://en.wikipedia.org/wiki/Spherical_measure#Relationship_with_other_measures According to that wikipedia article, the image measure of the Haar measure $\mu$ on $G$ through $\alpha$ is exactly the uniform measure $\sigma$ on the sphere:
$$
\sigma(A)=\mu(\{ g: \alpha(g)=gx_0 \in A\}) = \mu(\alpha^{-1}(A))
$$
In particular, 
$$
\sigma(B_i \cap S^{n-1}) = \sigma(B_i) = \mu(\alpha^{-1}(B_i \cap S^{n-1}))
$$
Since $\sigma$ is uniform and since the balls have the same radius with centers on the sphere, $\sigma(B_i \cap S^{n-1})=\sigma(B_j \cap S^{n-1})$ for all $i,j$. Thus my question can be reduced to: Why is the image measure $\mu(\alpha^{-1}( \; \cdot \; ))$ exactly the uniform measure $\sigma$ on the sphere?","['measure-theory', 'group-theory', 'haar-measure', 'lie-groups']"
2263114,Distance between Centroids of the Faces of a Regular Tetrahedron,"I was recently given this question to solve: In regular tetrahedron $ABCD$, $AB = 1$. What is the distance between the centroids of triangles $ABC$ and $ABD$? This is how I solved it: If we set $A = (0, 0, 0)$, $B = (1, 0, 0)$, and correspondingly $C = (\frac{1}{2}, \frac{\sqrt{3}}{2},0)$, then the centroid of $\triangle{ABC}$ is $\frac{A + B + C}{3}$, or $(\frac{1}{2}, \frac{\sqrt{3}}{6},0)$. In  $\triangle{ABD}$, the length of the median from $D$ is equal to $\frac{\sqrt{3}}{2}$, so the height of the tetrahedron from $D$ to base ${ABC}$ can be found to be $\frac{\sqrt{6}}{3}$ using the Pythagorean Theorem. Knowing that the centroid of $\triangle{ABD}$ lies $\frac{1}{3}$ of the way from the midpoint of $AB$ to $D$, the coordinates of the centroid can be determined as $(\frac{1}{2}, \frac{\sqrt{3}}{18},\frac{\sqrt{6}}{9})$. Then, using the distance formula the desired length can be found as $\frac{1}{3}$. However, I wasn't satisfied with this solution because I'm convinced there is a cleaner way to solve this, ideally using Euclidean geometry (or anything without coordinate bashing). Can anyone provide such a solution?","['euclidean-geometry', 'geometry']"
2263124,Find the linear tangent map $T_{I_n} \ f$,"I want to find $T_{I_n} \ f$ where the map is $\ f : X \mapsto X^2$ with $X\in SL_n(\mathbb{R})$. By definition of the linear tangent map : $T_{I_n}\ f : T_{I_n}SL_n (\mathbb{R})\to T_{f(I_n)}SL_n(\mathbb{R})$. But here notice that $f(I_n)=I_n^2=I_n$ and $\ f : SL_n(\mathbb{R})\to SL_n (\mathbb{R})$ because if $\det (X)=1$ then $\det(X^2)=(\det(X))^2=1$. Now I want to determine $T_{I_n}SL_n (\mathbb{R})$. So I consider the $\mathcal{C}^{\infty}$-map $g: X \mapsto \det(X)-1$ for $X\in SL_n(\mathbb{R})$. Using the basis of elementary matrix and differentiability theory I find : for $H \in \mathcal{M}_n(\mathbb{R})$ $Dg(X).H=Tr(X^{-1}H).$ Notice that it's a submanifold of $\mathcal{M}_n(\mathbb{R})$ where the dimension is $n^2-1$ (the codim is $1$ by definition of $g$). Indeed the derivative is surjective (we can chose for instance $H=X\neq 0$ and the derivative does not vanish) so $g$ is a submersion. Now we link this argument to the tangent space. For $X$ the tangent space is : $\ker Dg(X).H=Tr(X^{-1}H)=0$. So for $I_n$ it is $T_{I_n}SL_n(\mathbb{R})=\{H \in \mathcal{M}_n(\mathbb{R})\ / \ Tr(H)=0\}=\mathfrak{sl}(\mathbb{R})$. So I have to find : $T_{I_n}\ f : \mathfrak{sl}(\mathbb{R}) \to \mathfrak{sl}(\mathbb{R})$. Now I use the argument of drawing a curve on the manifold. I have to build $\gamma : 0\in L\subset \mathbb{R} \to SL_n (\mathbb{R})$ where $\gamma(0)=I_n \in SL_n(\mathbb{R})$. Then if I chose $\gamma(t)=I_n+tX$, $t\in L$, I get $\gamma'(0)=X\in SL_n(\mathbb{R})$. But is $\gamma(t)\in SL_n(\mathbb{R})$ for all $t\in L$ ? Or maybe I have to use the set $\mathfrak{sl}(\mathbb{R})$ ? I think I'm confused with the domains of maps. To conclude I have to use the equivalence class of curves such that : $T_{I_n} \ f (\overline{\gamma(t)})=\overline{f(\gamma(t))}$. Thanks in advance !","['smooth-manifolds', 'multivariable-calculus', 'manifolds', 'tangent-bundle', 'differential-geometry']"
2263131,Proving a Line to bisect a line in a Triangle,"From point $A$ tangents $AB$ and $AC$ to a circle are drawn ($B$ and $C$ tangent points); $PQ$ is a diameter of the circle; line $L$ is tangent to the circle at point $Q$. Lines $PA$, $PB$, and $PC$ intersect line $L$ at points $A_1, B_1, C_1$. Prove that $A_1B_1 = A_1C_1$.","['circles', 'euclidean-geometry', 'geometry']"
2263167,Calculate as a fraction $\sum_{n=1}^{1000} (1/(n^2-4))$,"I've been working on this problem for hours and haven't seemed to get anywhere. I've split the summation in various ways, without really getting anywhere. Is there any simple method or identity that i'm missing here? Thank you for your help. Calculate as a fraction $\sum^{1000}_{n=3}(\frac{1}{n^2-4})$ Use the shift from the proof of the Binomial Theorem.","['summation', 'discrete-mathematics']"
2263184,How to prove the following Mean Value Theorem?,"Let the function $f:\left[  0,T\right]  \times\mathbb{R}
\rightarrow\mathbb{R}$ be a function of time $t\in\left[  0,T\right]  $ and $x\in\mathbb{R}$, such that the partial derivatives $\partial
f\left(  t,x\right)  /\partial t$ , $\partial f\left(  t,x\right)  /\partial x$ and $\partial^{2}f\left(  t,x\right)  /\partial x^{2}$ exist and are
continuous for all $(t,x)\in\left[  0,T\right]  \times\mathbb{R}$. Then for
any $t,t+\Delta t\in\left[  0,T\right]  $ and $x,x+\Delta x\in\mathbb{R}$,
there exist constants $a,b\in\left[  0,1\right]  $ such that
$$
f\left(  t+\Delta t,x+\Delta x\right)  -f\left(  t,x\right)  =\frac{\partial
f\left(  t+a\Delta t,x\right)  }{\partial t}\Delta t+\frac{\partial f\left(
t,x\right)  }{\partial x}\Delta x+\frac{1}{2}\frac{\partial^{2}f\left(
t,x+b\Delta x\right)  }{\partial x^{2}}\left(  \Delta x\right)  ^{2}%
$$ Remark, my method
\begin{align*}
&  f\left(  t+\Delta t,x+\Delta x\right)  -f\left(  t,x\right)  \\
&  =f\left(  t+\Delta t,x+\Delta x\right)  -f\left(  t,x+\Delta x\right)
+f\left(  t,x+\Delta x\right)  -f\left(  t,x\right)  \\
&  =\frac{\partial f\left(  t+a\Delta t,x+\Delta x\right)  }{\partial t}\Delta
t+\frac{\partial f\left(  t,x\right)  }{\partial x}\Delta x+\frac{1}{2}%
\frac{\partial^{2}f\left(  t,x+b\Delta x\right)  }{\partial x^{2}}\left(
\Delta x\right)  ^{2}%
\end{align*}
However, the first term is $\frac{\partial f\left(  t+a\Delta t,x+\Delta x\right)  }{\partial t}\Delta t$ not $\frac{\partial f\left(  t+a\Delta t,x\right)  }{\partial t}\Delta t$, say, the second variable in $f(\cdot,\cdot)$ is not $x$, but $x+\Delta x$.","['multivariable-calculus', 'real-analysis', 'taylor-expansion']"
2263220,Integral $\int_0^\pi \big( (1+\alpha \cos x) \cos x \big)^n dx $,"I have been struggling with the integral $$ I_n(\alpha) = \frac{1}{\pi} \int_0^\pi \big( (1+\alpha \cos x) \cos x \big)^n dx,$$ where $\alpha$ is real and $n$ is a non-negative integer. 
It is relatively easy to get the values for specific $n$; $$I_0(\alpha) = 1,~~I_1(\alpha) = \alpha/2,~~I_2(\alpha) =\frac{1}{8} \left(3 \alpha ^2+4\right), \ldots$$ But how do I get the expression for general $I_n(\alpha)$?
I have tried building a recursion but did not quite succeed.
I also tried taking the derivatives of 3.661.3 from Gradshteyn-Ryzhik
but did not get anything nice. Edit I Attempt using the binomial theorem: \begin{align} 
\frac{1}{\pi} \int_0^{\pi} dx~ \big( 1 + \alpha\cos (x) \big)^n \cos (x)^n
&= \frac{1}{\pi} 
\int_0^{\pi} dx~ \cos (x)^n \sum_{m=0}^n{ {n}\choose{m}} \alpha^m \cos(x)^m \\
&= \sum_{m=0}^n{ {n}\choose{m}} \alpha^m \frac{1}{\pi} \int_0^{\pi} dx~ \cos (x)^{n+m} \\
&= \sum_{m=0}^n{ {n}\choose{m}} \alpha^m
\frac{ 2^{n+m} \pi }{(n+m)! \Gamma\left( \frac{1}{2}(1-n-m) \right)^2} 
\begin{cases}
1,~~n+m ~ {\rm even}\\
0,~~n+m ~ {\rm odd}
\end{cases}
\end{align} But I did not quite manage to express the last sum in some nice form...
the best I got is: \begin{align} I_n(\alpha) &=
\left(1 + (-1)^n\right) \frac{\Gamma (n+1)}
{2^{n+1}\Gamma \left(\frac{n+2}{2}\right)^2}
\,_3F_2\left(\tfrac{1}{2}(1-n),\tfrac{1}{2}(1+n),-\tfrac{n}{2};\tfrac{1}{2},1+\tfrac{n}{2};\alpha ^2\right) \\
&~~~~+
 \left(1 + (-1)^{n+1}\right)
\frac{n \Gamma (n+1)}
{2^n(n+1) \Gamma \left(\frac{n+1}{2}\right)^2}
\alpha \,_3F_2\left(\tfrac{1}{2}(1-n),1-\tfrac{n}{2},1+\tfrac{n}{2};\tfrac{3}{2},\tfrac{1}{2}(3+n);\alpha ^2\right)
\end{align} But it is not very instructive... P.S. The same can be also be obtained from the solution suggested by orlp. Edit II Following a nice suggestion of Igor's I got the result $$ I_n(\alpha) = \frac{2i}{(2n)!} \lim_{z\to i} \frac{d^{2n}}{dz^{2n}}
\frac{\left(1 +\alpha + (1-\alpha) z^2 \right)^n \left(1 - z^2\right)^n}{(z+i)^{2n+1}}.
 $$
However, it is quite tricky now (at least for me) to explicitly compute this derivative.
Any suggestions?",['integration']
2263237,Relation between the spectrum of a ring and affine varieties.,"When we define the spectrum of a ring, we associate a topology to this space, and we call this topology, the Zariski topology. However, the Zariski topology is the one associated to the space $k^n$ where $k$ is an algebraically closed field, and the closed sets are affine varieties which are the image of the radical ideals of the ring of polynomials. My question is: What is the relation between these two concepts? Is the spectrum of a ring a generalization of affine varieties? Please if you can help me with this, I'll really appreciate it.","['zariski-topology', 'ring-theory', 'affine-varieties', 'algebraic-geometry']"
2263273,The infinitely bounded definite integral of an odd function,"Often in mathematics, particularly in physics, we welcome definite integrals from $-\infty$ to $\infty$ of odd functions, since they are equal to zero. Such as $\int_{-\infty}^{\infty} \sin(x) dx = 0$ . So, simple question; why does WolframAlpha fail to evaluate infinite bounded definite integrals of odd functions, stating that the solution ""does not converge""? Is it not exactly accurate to say that the answer is zero? Edit: Rather, I should say that the integral over symmetric bounds , in general, of an odd function is zero. Why when we use bounds at $\pm\infty$ is this not the case?","['integration', 'calculus']"
