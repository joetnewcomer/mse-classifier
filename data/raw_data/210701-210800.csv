question_id,title,body,tags
4235855,Write a double integral for surface area of cone $z=1-\sqrt{x^2+y^2}$ above the plane $x+2z+1=0$.,"Write a double integral for surface area of cone $z=1-\sqrt{x^2+y^2}$ above the plane $x+2z+1=0$ . First I started with finding projection of these two in $xOy$ plane: $-\frac{1}{2} - \frac{x}{2}=1-\sqrt{x^2+y^2}$ ... which is ellipse $$\frac{(x-1)^2}{2^2} + \frac{y^2}{(\sqrt{3})^2}=1.$$ Then using formula $$P=\iint_D \sqrt{1+p^2+q^2}dxdy;$$ I have $z(x,y)=1-\sqrt{x^2+y^2}$ I can easily find partials $p$ and $q$ and I get $\sqrt{2}$ for the $P=\int\int_D \sqrt{2}dxdy$ . Now the area over which the integration is done $D$ : Since it is ellipse I put elliptical coordinates to be: $x=1+2rcost$ and $y=\sqrt{3}rsint$ , where $0\leq r \leq 1$ and $0\leq t \leq 2\pi$ and Jacobian is $2\sqrt{3}r$ . Final, the integral would look like this: $$P=\int_{0}^{2\pi}\int_{0}^{1} \sqrt{2}2\sqrt{3}rdrdt.$$ Is this correct?","['multivariable-calculus', 'multiple-integral']"
4235879,Baysian analysis of the Poisson distribution,"$ D = (x_i )_{i=1:n}$ is the training data, where $x_i$ follows a Poisson distribution of parameter $\lambda$ . The likelihood is $ p(D | \lambda) = \prod_{i=1}^n exp(-\lambda) \lambda^{x_i}/{x_i!} $ We assume that the prior distribution of $\lambda$ is $p(\lambda) = Ga(\lambda|a,b)$ ( gamma distribution ) The goal is to show that the posterior follows a gamma distribution. The demonstration that I found in a textbook is the following : $$
\begin{align}
\mathsf p(\lambda|D) &\propto p (\lambda) p(D | \lambda) \\
 &\propto  exp(-\lambda(b+n)) * \lambda^{a-1 + \sum x_i}
\end{align}
$$ and to conclude that $ p(\lambda|D) = Ga(a + \sum x_i, b+n )$ I don't understand how you can so easily ignore the constant term of the gamma distribution ( by that I mean $ \beta^\alpha / \Gamma (\alpha) $ ). Why is it only necessary to show that the distribution is proportional to these two terms to conclude that it's a gamma distribution ?","['statistical-inference', 'statistics', 'bayesian', 'gamma-distribution']"
4235899,Derivative of $\frac{d \int p(x) dx}{d p(x)} $,"Suppose $p(x)$ is a probability between 0 and 1 . It looks $$\frac{d \int p(x) dx}{d p(x)} = 1$$ but I find it a bit difficult to convince myself why? I feel influenced by the fact that $\frac{d \int p(x) dx}{dx} = p(x)$ . Can anyone provide a better understanding of the above derivative? In contrast, I find it relatively more intuitive in the case of a discrete random variable, where $$\frac{d \sum_{i} p(x_i) }{d p(x_i)} = 1$$","['integration', 'calculus', 'derivatives']"
4235909,Derangement with extra box,"I was going through PnC questions and I came across this problem. Four balls numbered $1,2,3,4$ are to be placed into five boxes numbered $1,2,3,4,5$ such that exactly one box remains empty and no ball goes to its own numbered box. The no. of ways is? I worked out the problem in the following way. Case 1: box 5 is not selected and thus total derangements $d_4=9$ Case 2: Any one of 4 boxes say box 1 is not selected $ C(4,1)$ case 2(a) ball 1 goes to box 5 then total derangements $d_3=2$ Case 2(b) ball 1 goes to either of other two boxes say box 2 Case 2(b)(i) ball 2 goes to 5 then $d_2=1$ Case 2(b)(ii) ball 2 doesn't go to box 5 then also $d_2=1$ Thus, total number of ways $=9+C(4,1)\{2+2*2\}=33$ But none of the answer matches. Please help me identify error in the reasoning. I got the error
Case 2(b) should be ball 1 goes to either of other three boxes say box 2 and
Case 2(b)(ii) ball 2 doesn't go to box 5 then also $2*d_2=1$ So, finally it comes to $=9+C(4,1)\{2+3*(1+2)\}=53$","['permutations', 'derangements', 'combinatorics']"
4235922,"Derivative of the absolute value $|x^3|$, when $x = 0$.","Can we find the derivative of $|x^3|$ at $x = 0$ ? I was trying to find the derivative of $|x^3|$ within the range of $[-1/2, 1/2]$ . I got the equation for the derivative of $|x^3| = 3x^3 / |x|$ . for $x \neq 0$ . Is the equation correct? And the other thing is I want the derivative of $|x^3|$ at $x = 0$ to obtain the full solution. How can I find it? Any help would be appreciated.","['absolute-value', 'modules', 'calculus', 'algebra-precalculus', 'derivatives']"
4235927,What is wrong with my two fair dice probability question reasoning?,"There is a game where you are asked to roll two fair six-sided dice. If the sum of the values equals 7, then win £21. However, must pay £5 to play each time both dice are rolled. Do you play this game? One way to think about this is that getting a 7 comes with 1/6 chance, and to make money we need to get 7 at a rate of 1/4, so the answer is not to play. Another way to think about it is: what is my chance of throwing a 7 at least once in every 4 throws? In which case I would calculate a probability of not throwing a 7 4 throws in a row (5/6)^4, and then subtract this from 1 to get a probability of throwing at least one 7. Which is 1 - (5/6)^4 = 0.52. By this logic I would play the game. Both of these answers cannot be correct. Could someone explain to me which one is incorrect and why? Thanks! EDIT: wow, this is the first time I asked a question on StackOverflow, did not expect to get so many responses. Thank you all, I am very grateful!","['statistics', 'dice', 'probability']"
4235982,Probability of meeting your friend on a tournament.,"There are $2^n$ players in a knock-out chess tournament. They all have identical skill. This means for any two pairings the probability of either winning is $\frac{1}{2}$ . The table is assigned uniformly randomly. You and your friend are both competing. What is the probability you guys meet? Method one Draw out a knock-out table in a rooted binary tree sense. Without loss of generality put yourself at the bottom left leaf. We can condition the probability you and your friend meet on the friends initial location. Notice we have $2^n-1 $ positions they could be in. One of the positions is adjacent to you in which case the probability you meet is $1$ . Two of these positions are only one game away from in which case you must both win your games to meet, with probability $\frac{1}{4}$ . Four of these positions are two games away from you in which case you meet if you both win two games. $\frac{1}{2^4}$ . And so on. Formally: Probability of meeting = $\sum\limits_{i = 0}^n \frac{2^i}{2^n-1} \cdot (\frac{1}{2^i})^2$ = $\frac{1}{2^n-1}\sum\limits_{i = 0}^n \frac{1}{2^i} = \frac{1}{{2^n}-1} \cdot \frac{\frac{1}{2^{n+1}} -1}{1-\frac{1}{2}} = \frac{1}{2^{n-1}}$ This method is the nuts and bolts. A little bit of fiddle with geometric series but fairly intuitive. Method two This method seems much nicer. I thought it was legitimate and it gets the same answer but I found a big hole in it explained at the end. Let the positions of the contestants be $C_1 , C_2, C_3 , ... , C_{2^n} $ . Let $M_{i,j}$ denote the event that contestant $i$ meets contestant $j$ By full symmetry the probability of $M_{i,j}$ is the same for all $i \not= j \in [1,2^n] $ . We have a total of $2^n - 1$ games in the tournament as each game removes a single player. We have a total of $2^n$ choose $2$ = $\frac{2^n \cdot (2^n - 1)}{2} = 2^{2n-1} -2^{n-1}$ couplings of $M_{i,j}$ . ( $\star$ ) Matches played are like picking $2^n -1$ balls from a bag with $2^{2n-1} -2^{n-1}$ balls in it. So the probability you and your friend meet is $\frac{2^n -1}{2^{2n-1} -2^{n-1}} = \frac{1}{2^{n-1}}$ . Nifty huh, we get the same answer as before but much cleaner. However this method is wrong! Step $(\star)$ is a violation. We cannot for example pick the balls $M_{1,2} , M_{1,3} , M_{1,4} , ..., M_{1,2^n}$ as contestant $1$ cannot play everyone! Can someone help me make the second method work? Im sure its not far off. Or is it just a coincidence that it works?","['statistics', 'probability']"
4236005,Clean proof of Baker-Campbell-Hausdorff Formula,"I am thinking of the cleanest way to prove the BCH formula and I have come up with this. First, work out $e^{\lambda A}Be^{-\lambda A}$ by expanding the exponentials (sums go from $0$ to $\infty$ ): $$\left(\sum_{n}\frac{\lambda^n}{n!}A^n \right)B\left(\sum_{k}\frac{(-\lambda)^k}{k!}A^k \right).$$ This can be written as $$\sum_{n,k}\frac{(-1)^k\lambda^{n+k}}{n!k!}A^nBA^k.$$ We define $m=n+k$ , and rewrite the previous expression as $$\sum_{m=0}^{\infty}\sum_{n=0}^m\frac{(-1)^{m-n}\lambda^{m}}{n!(m-n)!}A^nBA^{m-n}.$$ By dividing and multiplyling by $m!$ inside the sum we finally arrive to $$\sum_{m=0}^{\infty}\frac{\lambda^m}{m!} \sum_{n=0}^m(-1)^{m-n}\frac{m!}{n!(m-n)!}A^nBA^{m-n}.$$ The formula is  usually presented as $$e^{\lambda A}Be^{-\lambda A}=B+\lambda[A,B]+\frac{\lambda^2}{2!}[A,[A,B]]+...$$ By comparing with what I got, proving BCH is reduced to proving $$\underbrace{[A,[A,[...,[A,B]...]}_{m}=\sum_{n=0}^m(-1)^{m-n}\frac{m!}{n!(m-n)!}A^nBA^{m-n}.$$ At this point I thought this could be easily proven by induction, but now I'm not sure it is that simple. The equation is true for $m=1$ , and if we assume it is true for $m$ , then we get $$\underbrace{[A,[A,[...,[A,B]...]}_{m+1}=A\underbrace{[A,[A,[...,[A,B]...]}_{m}-\underbrace{[A,[A,[...,[A,B]...]}_{m}A$$ $$=A\left(\sum_{n=0}^m(-1)^{m-n}\frac{m!}{n!(m-n)!}A^nBA^{m-n}\right)-\left(\sum_{n=0}^m(-1)^{m-n}\frac{m!}{n!(m-n)!}A^nBA^{m-n}\right)A$$ $$=\sum_{n=0}^m(-1)^{m-n}\frac{m!}{n!(m-n)!}(A^{n+1}BA^{m-n}-A^nBA^{m+1-n})$$ $$=\sum_{n=0}^m(-1)^{m+1-n}\frac{m!}{n!(m-n)!}(A^nBA^{m+1-n}-A^{n+1}BA^{m-n}).$$ I would like to see this is equal to $$\sum_{n=0}^{m+1}(-1)^{m+1-n}\frac{(m+1)!}{n!(m+1-n)!}A^nBA^{m+1-n},$$ since that would complete the proof. I've tried to work it by inserting commutators here and there, but the algebra becomes too involved. Any help would be truly appreciated. Maybe the last expression is more transparent if read as $$\sum_{n=0}^{m+1}(-1)^{m+1-n}\begin{pmatrix}m+1\\n \end{pmatrix}A^nBA^{m+1-n}$$","['quantum-mechanics', 'induction', 'linear-algebra', 'lie-algebras']"
4236058,Alternative and more direct proof that an integral is independent of a parameter,"I'm looking for alternative ways to calculate the integral $$
\int\limits_0^\infty\frac{\tanh(\alpha x)}{\tanh(\pi x)}\sin(2\alpha x^2)\,dx=\frac{1}{4},\qquad \alpha>0.\tag {*}
$$ It was derived in a lengthy calculation using roundabout method from Fourier transform of a function of two variables. However, it seems like the integral (*) might have a simple proof? Note that when $\alpha=\pi$ , the the integral reduces to Fresnel integral $$
\int\limits_0^\infty\sin(2\pi x^2)\,dx=\frac{1}{4}.
$$ Thus if one could prove that it is independent of the parameter $\alpha$ , then its value could be found.","['integration', 'definite-integrals', 'alternative-proof', 'contour-integration', 'trigonometric-integrals']"
4236080,Volume of Lie groups and homogeneous manifolds with respect to Riemannian volume forms,"(Motivations / background below, but the question is self contained.) Question Suppose $G$ is a compact Lie group and $K$ a closed subgroup. Let $X=G/K$ the corresponding homogeneous manifold (to be concrete: we quotient by multiplication on the right by $K$ , namely elements of $X$ are cosets $[g]=gK$ ). Suppose also that $G$ is equipped with a bi-invariant Riemannian metric $\gamma$ . Let $\Omega_G$ be the associated volume form. (In coordinates $\gamma=\gamma_{ij}(x)dx^idx^j\Rightarrow\Omega_G=\sqrt{\det\gamma_{ij}(x)}dx^1\wedge...\wedge dx^n$ .) The restricted Riemann metric $\gamma|_K$ induces a volume form $\Omega_K$ on $K$ . Moreover $\gamma$ induces an invariant Riemannian metric on $X$ ; the way I see this is because $T_{[g]}X \simeq T_gG / T_g(g.K)\simeq(T_g(g.K))^{\perp_\gamma}$ (where $g.K$ is the orbit of $g$ under right multiplication by $K$ and the superscript $\perp_\gamma$ denotes the orthogonal subspace with respect to $\gamma$ ) so that we can define the metric on $T_{[g]}X$ by restricting $\gamma$ to $(T_g(g.K))^{\perp_\gamma}$ . What I would like to prove (or disprove?) is that $$
(\star)\qquad\qquad\int_G\Omega_G=\int_X\Omega_X\int_K\Omega_K,
$$ or even some version for integration of functions on $G$ if possible. (Maybe I need some version of the ""coarea formula""?) Motivations / Background Let $\mathcal U_n$ be the real Lie group of unitary matrices of size $n$ and let $\mathcal H_n$ be the real vector space of Hermitian matrices of size $n$ .
We can define the bi-invariant Riemannian metric $\gamma_U^{(n)}(M,N)=tr(MN^\dagger)$ on $\mathcal U_n\ni U$ where $M,N\in T_U\mathcal U_n=\sqrt{-1} U \mathcal H_n$ . I would like to take $G=\mathcal U_n$ and $K=\mathcal U_{n-1}$ ; the latter is embedded via $i:K\to G:U\mapsto \begin{pmatrix}1 & 0 \\ 0 & U\end{pmatrix}$ which is isometric, namely $i^*\gamma^{(n)}=\gamma^{(n-1)}$ .
The quotient $X=G/K$ is diffeomorphic to $S^{2n-1}\subset\mathbb C^n$ via $f:[U]\mapsto Ue_1$ (i.e. via the map $f$ sending $[U]\in X$ to the first column of $U$ , which is a norm 1 vector in $\mathbb C^n$ ).
It also seems to me that $\Omega_X$ , as defined above, is $2^{n-1}\Omega_{S^{2n-1}}$ (namely $\Omega_X=2^{n-1}f^*\Omega_{S^{2n-1}}$ ), where $\Omega_{S^m}$ is the standard volume form on the sphere. Finally, the factorization property $(\star)$ above, along with the standard identity $Vol(S^{m-1})=2\pi^{m/2}/\Gamma(m/2)$ , would imply that $$
Vol(\mathcal U_n)=Vol(\mathcal U_{n-1})Vol(X)=Vol(\mathcal U_{n-1})2^{n-1} Vol(S^{2n-1})=Vol(\mathcal U_{n-1})\frac{(2\pi)^n}{(n-1)!}.
$$ Together with the initial value $Vol(\mathcal U_1)=2\pi$ (which can be computed directly) this argument seems to provide the correct value for $Vol(\mathcal U_n)=\frac{(2\pi)^{n(n+1)/2}}{1!\cdots (n-1)!}$ (with respect to the present normalization of the Haar measure), but I am still puzzled by the equality $(\star)$ above.","['volume', 'haar-measure', 'lie-groups', 'differential-geometry']"
4236082,How is this a tangent vector?,"Let $\pi :E\to M$ be a vector bundle with typical fiber $V$ . Suppose that $\pi^*E$ is the pullback bundle of $E$ by $\pi$ . If $(\zeta, \xi) \in \pi^*E$ , then the map $\pi(\zeta +t\xi)$ is constant in $t$ , because both $\zeta$ and $\xi$ are in the same fiber, call it $E_p$ . In my textbook ( Differential Geometric Structures by Poor), it is said that the map $\mathcal J:\pi^*E\to TE$ given by $$\mathcal J(\zeta +t\xi) = \frac d{dt}\Big|_{t=0}(\zeta +t\xi)$$ actually maps into the vertical bundle $\mathcal VE$ . My questions are: How is $\frac d{dt}\Big|_{t =0} (\zeta + t\xi) \in TE$ ? And How is it in $\mathcal VE$ ?","['vector-bundles', 'tangent-bundle', 'differential-geometry']"
4236120,Donsker Theorem like result for sum of Sums,"Recently I came up with the following question. Let's say that $X_i$ are i.i.d random variables with $\mathbb{E}[X_1] = 0$ and $\mathbb{V}\text{ar}(X_1) = 1$ . We know by Donkser Theorem that: $$\frac{S_n}{\sqrt{n}} \to B(1) \sim N(0,1)$$ This case is Donsker with $t=1$ and using the special fact that $\mathbb{E}[X_1] = 0$ and $\mathbb{V}\text{ar}(X_1) = 1$ . Now my question is how can I find the following: $$\lim_{n \to \infty} \frac{1}{n^{3/2}}\sum_{k=1}^n S_k$$ My first idea was passing $n^{1/2}$ inside and finding: $$\lim_{n \to \infty} \frac{1}{n}\sum_{k=1}^n \frac{S_k}{n^{1/2}} = \lim_{n \to \infty} \frac{1}{n}\sum_{k=1}^n \frac{S_k}{k^{1/2}}\cdot \frac{k^{1/2}}{n^{1/2}}$$ But from here on out I have no idea how to procced. I may be wrong but it looks like I will have many Normal like distributions all scaled by a certain factor and then I take the mean of all of them. But I am lost in how I can find a more closed value for the limit. Any ideas?","['stochastic-processes', 'probability-theory', 'stochastic-calculus']"
4236207,"For a non-normal extension, is the Galois action still transitive on roots that *are* in the extension?","Let $L/F$ be a field extension where $L$ is the splitting field of the irreducible $f \in F[X]$ . Then $\text{Gal}(L/F)$ acts on the roots of $f$ transitively - this follows from how every isomorphism of fields in $L/F$ can be extended to an automorphism of $L$ . Now let $K$ be an intermediate field of $L/F$ , where $K$ contains only some of the roots of $f$ . Is it true that the automorphisms of $K$ fixing $F$ act transitively on the roots of $f$ in $K$ ? I know it holds if each of the the roots of $f$ in $K$ generate $K/F$ , but I'm not seeing a counterexample where $K$ is not simply generated by some of the roots, or some inductive proof applying this fact to simple subextensions.","['field-theory', 'galois-theory', 'abstract-algebra', 'extension-field']"
4236220,Proving the sum to product formula with complex numbers starting from the left hand side,"I've just asked a similar question today Prove the sum to product formulas with complex numbers but I was wondering what if we wanted to start with the left hand side instead of the right hand side? Because at the end I want to be able to think, to derive this formula without knowing the outcome, the right hand side, so I'm wondering about how to do it starting from the left hand side . My goal: $$\sin x+\sin y=2\sin\left(\frac{x+y}{2}\right)\cos\left(\frac{x-y}{2}\right)$$ Recall the complex definition  of sine and cosine: $$\sin z=\frac{e^{iz}-e^{-iz}}{2i}$$ and $$\cos z=\frac{e^{iz}+e^{-iz}}{2}$$ Applying both we get after simplifying a bit: $$\frac{e^{ix}-e^{-ix}+e^{iy}-e^{-iy}}{2i}$$ but I don't really know what to do now. I've also tried with the opposite substitution that I used when proving this starting from the right hand side $\alpha=\frac{x+y}{2}$ and $\beta=\frac{x-y}{2}$ but I'm pretty sstuck. I know I have to factor it to get it closer to our goal, but no clue on how to factor this. Any hints?","['trigonometry', 'proof-writing', 'complex-numbers']"
4236227,"Limit at (0,0) of $\frac{xy^2\sqrt{x^2+y^2}}{x^2 +y^4}$","$$\text{Let}\ f(x,y) = \frac{xy^2\sqrt{x^2+y^2}}{x^2 +y^4}$$ WolframAlpha tells me that $\lim_{(x,y) \to (0,0)} f(x,y)$ does not exist. To prove the non-existence of the limit, I tried three different paths ( $y=kx, y=kx^2, y=kx^3)$ and they all equal zero. From the graph of the function it looks like the limit is indeed zero. Also I thought I was able to prove the limit does indeed exist at $(0,0)$ with the epsilon-delta definition: $$y^2 \leq x^2+y^2 \leq x^2 + y^4 \iff \frac{y^2}{x^2+y^4} \leq 1 \overset{|x|<1}{\iff} \frac{|x|y^2}{x^2+y^4} \leq 1 \iff \frac{|x|y^2\sqrt{x^2+y^2}}{x^2+y^4} \leq \sqrt{x^2+y^2} \iff \left|\frac{xy^2\sqrt{x^2+y^2}}{x^2+y^4} - 0\right|\leq \left|\sqrt{(x-0)^2+(y-0)^2}\right| \lt δ := ε $$ So for $δ = ε$ we have that $\|x -(0,0)\| < δ \implies |f(x,y) - 0| < ε$ I'm confused","['limits', 'multivariable-calculus']"
4236241,Simple but interesting problem about the binomial coefficient from Olympiad,"""Let's define $a_n=\sum\limits_{k=0}^{\lfloor n/2 \rfloor} {n-k \choose k}\left(-\frac{1}{4}\right)^k$ .  Evaluate $a_{1997}$ ."" This problem is from the final round of an old South Korean Mathematical Olympiad (1997 KMO). I think this problem is very simple, but requires some combinatoric ideas, and also is very interesting. But as a lot of time has passed by, I cannot find any solutions or guidelines about it. I tried to divide the explicit form of $(x+y)^{2k}$ with $x^k$ , but it doesn't work well. Would you help me?","['contest-math', 'summation', 'binomial-coefficients', 'combinatorics']"
4236246,"""Barn Door"" trig problem [duplicate]","This question already has answers here : Help calculating angles for woodworking (2 answers) Closed 2 years ago . I am mainly a computer science guy, currently trying to create a 3d model of a barn door.  This led me into an interesting little problem that my trigonometry skills are apparently too rusty to solve. In the given illustration, $A$ and $B$ are known as well as $W$ , The hypotenuse( $C$ ) and its angle are obvious even to me, but this is not the same thing as the angle of the diagonal board. What is the best way to calculate that? Thanks for your patience.","['trigonometry', 'geometry']"
4236295,The number of fixed points of an involution on a finite set has the same parity as the cardinality as the set,"What is wrong with the following proof-probably familiar to many? Assume that $S$ is a finite set and that $f:S\rightarrow{S}$ is a bijection . Let ${\rm{Fix}}{f_{S}}$ denote the set of fixed points of $f$ . Then the union of $$\{\{s,f(s)\}:s\in{S}\}$$ can be written as the disjoint union of ${\rm{Fix}}{f_{S}}$ , and its complement in $S$ , say $S'$ . Since $S'$ is the finite union (say $r$ of them) of sets of the form $\{s,f(s)\}$ each of which contains two elements, we conclude that $|S|=|{\rm{Fix}}{f_{S}}|+2r$ . Thus, $|S|-|{\rm{Fix}}{f_{S}}|=2r$ , and so $|S|\equiv|{\rm{Fix}}{f_{S}}|({\rm{mod}})2.$ I have seen this argument prove that for an involution $f$ of a finite set $S$ that cardinality of $S$ , and the cardinality of the set of its fixed points have the same parity. My question is where do we use the fact that $f$ is an involution (i.e. $(f\circ{f})$ is equal to the identity mapping $S\rightarrow{S}$ ) in this proof?",['elementary-set-theory']
4236297,Hartshorne Exercise I.7.7,"I'm trying to solve the following exercise from Hartshorne's Algebraic Geometry, namely Exercise I.7.7 Exercise I.7.7: Let $Y$ be a variety of dimension $r$ and degree $d>1$ in $\mathbb{P}^{n}$ . Let $P \in Y$ be a nonsingular point. Define $X$ to be the closure of the union of all lines $P Q$ , where $Q \in Y, Q \neq P$ . (a) Show that $X$ is a variety of dimension $r+1$ . (b) Show that $\operatorname{deg} X<d$ . [Hint: Use induction on dim $Y$ .] I think I've solved part (a) by showing that $X$ is birational to a cone, but my main concern is about part (b). For part (b), what I want to do is to pick a hyperplane, $H$ , not containing $Y$ , through $P$ such that $Y\cap H$ has just one irreducible component, and the intersection multiplicity along this irreducible component is $1$ . Thereafter, I would replace $Y$ by $Y\cap H$ and thereby reduce $\text{dim } Y$ by $1$ . Now, $X\cap H$ is the closure of the union of all lines through $P$ to points of $Y\cap H$ . This would enable me to get an inductive argument running, as suggested in the hint. Degrees are behave exactly as we want them to, i.e. $\text{deg } Y = \text{deg } Y\cap H$ , and likewise for $X$ , as can be easily seen from Theorem I.7.7 (page 53). However, the trouble is that I can't see a good way to actually pick $H$ , if at all this approach can be made to work. I would be very grateful is someone could provide a hint as to what I should try to do now. Thank you.","['algebraic-geometry', 'commutative-algebra', 'projective-varieties']"
4236386,The sequence $(x_n)$ : $x_{n+2}=\frac{x_{n+1}\sqrt{x_n^2+1}+x_{n}\sqrt{x_{n+1}^2+1}-x_n-x_{n+1}}{x_{n+1}x_n-(\sqrt{x_{n+1}^2+1}-1)(\sqrt{x_n^2+1}-1)}$,"The sequence $(x_n)$ is defined by the formula: $$\left\{\begin{array}{cc}
x_1=1, x_2=\sqrt{3}\\
x_{n+2}=\frac{x_{n+1}\sqrt{x_n^2+1}+x_{n}\sqrt{x_{n+1}^2+1}-x_n-x_{n+1}}{x_{n+1}x_n-\big(\sqrt{x_{n+1}^2+1}-1\big)\big(\sqrt{x_{n}^2+1}-1\big)}, \quad n=1,2,3\dots
\end{array} \right.$$ Find $\lim\limits_{n\to \infty}x_n$ . I see: $$\begin{array}{rl}
x_{n+2}&=\frac{x_{n+1}\sqrt{x_n^2+1}+x_{n}\sqrt{x_{n+1}^2+1}-x_n-x_{n+1}}{x_{n+1}x_n-\big(\sqrt{x_{n+1}^2+1}-1\big)\big(\sqrt{x_{n}^2+1}-1\big)}\\
&=\frac{x_{n}\big(\sqrt{x_{n+1}^2+1}-1 \big)+x_{n+1}\big(\sqrt{x_{n}^2+1}-1 \big)}{x_{n+1}x_n-\frac{x_n^2x_{n+1}^2}{\big(\sqrt{x_{n+1}^2+1}+1\big)\big(\sqrt{x_{n}^2+1}+1\big)}}\\
&=\frac{x_{n+1}\big(\sqrt{x_{n}^2+1}+1\big)+x_{n}\big(\sqrt{x_{n+1}^2+1}+1\big)}{\big(\sqrt{x_{n+1}^2+1}+1\big)\big(\sqrt{x_{n}^2+1}+1\big)-x_nx_{n+1}}
\end{array}$$ That's all I can do. So, I hope hints from you. Thank you.","['limits', 'sequences-and-series']"
4236413,parallel transport $w$ along $\gamma$: Explicit computation,"Let $S^2 = \{(x,y,z) \in \mathbb{R}^3 | x^2 + y^2 +z^2 =1\}$ . For fixed $t \in [0,1)$ consider the curve $\gamma(t) = (r\cos(t), r\sin(t), \sqrt{1-r^2})$ , $t\in [0,2\pi]$ . Take $w\in T_{\gamma(0)} S^2$ . I want to compute the parallel transport $w$ along $\gamma$ . Naively I know parallel transport $w$ along $\gamma$ as follow: Let $x(u,v) = \gamma(t)$ , then $w = ax_u + b x_v$ , then \begin{align}
  \frac{Dw}{dt} &= \left(a' + \Gamma^1{}_{11} au' + \Gamma^1{}_{12} av' + \Gamma^{1}{}_{12} bu' + \Gamma^1{}_{22} bv' \right) x_u  \\
  & \quad + \left( b'+ \Gamma^2{}_{11} au' + \Gamma^2{}_{12} a v' + \Gamma^2{}_{12} bu' + \Gamma^2{}_{22} bv' \right) x_v 
\end{align} where $\Gamma^{i}{}_{jk}$ are Chritoffel symobl. So assuming my Riemannian metric as $ds^2=dx^2+dy^2+dz^2 = r^2dr^2+ r^2\sin^2(\theta) d\theta^2$ , I can compute $\Gamma$ . But I am having trouble computing $v$ and corresponding $a,b$ . Since $w \in T_{\gamma(0)} S^2$ , I guess $w$ should pass through the point $\gamma(0) = (r,0,\sqrt{1-r^2})$ From $x(u,v) = \gamma(t) = (r\cos(t),r\sin(t),\sqrt{1-r^2})$ , Can I idenitfy $(u,v) = (r,t)$ ? But in this case $u$ is independent of $t$ so my $u'$ all vanishes... Is my approach correct? (How to formulate $a,b$ out of $\gamma(t)$ ?) I am familiar with the covariant derivatives acting on tensors, $\nabla_{\mu} x^{\nu} = \partial_{\mu} x^{\nu} + \Gamma^{\nu}{}_{\mu \rho} x^{\rho}$ like in General relativity, but not familiar with these differential geometry notations so having trouble expliict computations.","['connections', 'riemannian-geometry', 'differential-geometry']"
4236445,Directional Derivative of a piecewise defined function,"Here is a problem and the solution to it. $\quad$ let $f: \mathbb{R}^{3} \rightarrow \mathbb{R}$ be a continuously differentiable function with: $$
f(t, 2 t, 0)=e^{3 t}+1, \quad f(t,-t,-t)=2 \cos \left(t^{3}\right)+3 t, \quad f(0, t, 3 t)=\log \left(t^{2}+1\right)+2
$$ a) Compute the directional derivatives $D_{v} f(0,0,0)$ for $v_{1}=(1,2,0), v_{2}=(-1,1,1)$ and $v_{3}=(0,1,3)$ .
b) Find $D f(0,0,0)$ .
Solution:
a) $f(0,0,0)=2 .$ We take the directional derivatives $$
\begin{aligned}
&D_{(1,2,0)} f(0,0,0)=\lim _{t \rightarrow 0} \frac{f(t, 2 t, 0)-f(0,0,0)}{t}=\lim _{t \rightarrow 0} \frac{e^{3 t}+1-2}{t}=\lim _{t \rightarrow 0} 3 e^{3 t}=3 \\
&D_{(-1,1,1)} f(0,0,0)=\lim _{t \rightarrow 0} \frac{f(-t, t, t)-f(0,0,0)}{t}=\lim _{t \rightarrow 0} \frac{2 \cos \left(-t^{3}\right)-3 t-2}{t}=\lim _{t \rightarrow 0} 2 \sin \left(-t^{3}\right) 3 t^{2}-3=-3, \\
&D_{(0,1,3)} f(0,0,0)=\lim _{t \rightarrow 0} \frac{f(0, t, 3 t)-f(0,0,0)}{t}=\lim _{t \rightarrow 0} \frac{\log \left(t^{2}+1\right)+2-2}{t}=\lim _{t \rightarrow 0} \frac{2 t}{t^{2}+1}=0
\end{aligned}
$$ b) We can compute the directional derivatives the following way $D_{v} f(0,0,0)=D f(0,0,0) \cdot v$ . By $$
D f(0,0,0)=\left(\frac{\partial}{\partial x_{1}} f(0,0,0), \frac{\partial}{\partial x_{2}} f(0,0,0), \frac{\partial}{\partial x_{3}} f(0,0,0)\right)=:(a, b, c)
$$ we get the system of equation $$
a+2 b=3 \quad \wedge \quad-a+b+c=-3 \quad \wedge \quad b+3 c=0
$$ so, $a=3$ und $b=c=0$ . We conclude $D f(0,0,0)=(3,0,0)$ . My first question is: How can I (if possible) find an explicit form of the gradient such that I don't have to have a system of equations to find $D f(x,y,z)$ usually regarding tasks about directional derivatives I just computed the partial derivatives to get the gradient, plugged in the point in question and made a dot product with the direction. Second question: How do I (if possible at all) compute the directional derivative at a different point in the directions of the $v_{i=1,2,3}$ or even better in other directions?
is the following possible? $$
\begin{aligned} &D_{(1,2,0)} f(5,4,3)=... \\
&D_{(-1,1,1)} f(5,4,3)=... \\
&D_{(0,1,3)} f(5,4,3)=...
\end{aligned}
$$ or $$
\begin{aligned} &D_{(3,2,1)} f(5,4,3)=... \\
&D_{(-1,2,4)} f(5,4,3)=... \\
&D_{(0,-1,2)} f(5,4,3)=...
\end{aligned}
$$ My feeling was none of the two suggestions is possible, because the function is not defined at the point $(5,4,3)$ and the new randomly chosen $v_{i=4,5,6}$ in the second example?
I was also playing with the thought that any point could be decomposed into a linear combination of the original $v_{i=1,2,3}$ such that it'd be possible to take the directional derivative at any point? I could not find similar tasks to extrapolate some information from them, maybe someone knows how I could find similar examples - I didn't know what to google for to get similar tasks.
Thanks!",['multivariable-calculus']
4236461,a map of even degree must identify a pair of antipodal points,"I'm stuck on this problem in Armstrong's Basic Topology Chapter 9, P206. Prove that if $f:S^n\to S^n$ has even degree, it must identify a pair of antipodal points of $S^n$ . I know some similar conclusions such as ""if $f$ preserves antipodal points, then $f$ has odd degree"", ""if f has odd degree, it must carry some pair of antipodal points into a pair of antipodal points"".
I tried a similar skill used in solving the second problem: consider a homotopy $F(x,t)=\frac{tf(x)+(1-t)f(-x)}{||tf(x)+(1-t)f(-x)||}$ and the degree of $F(x,1/2)$ .  I let $F(x,t)=\frac{tf(x)-(1-t)f(-x)}{||tf(x)-(1-t)f(-x)||}$ in this problem to look for contradiction. But I can get nothing about the degree of these $F(x,t)$ for certain $t$ s. And since $deg(-f(-x))=deg(f)$ holds for any $f$ , I 've found no contradiction so far. Is this a wrong approach? Any small tip would be appreciated.","['general-topology', 'homotopy-theory', 'algebraic-topology']"
4236464,"Evaluate $\int_{0}^{1/2}\frac{e^x(2-x^2)}{(1-x)^{3/2}(1+x)^{1/2}}\,dx$","Consider the following intergal: $$\int_{0}^{1/2}\frac{e^x(2-x^2)}{(1-x)^{3/2}(1+x)^{1/2}}dx$$ I have tried this by trying to write the numerator as 1 + the product of the below-given functions and then using partial fractions. I've also thought of trying to do some trig substitutions but then that simply gives an exponential raised to a trig ratio etc. All in all, this integral has beaten me.
An online calculator gives the following indefinite value: $$-\frac{\sqrt{1-x}\sqrt{1+x}e^x}{(x-1)} + C$$ While the definite value is: $$\sqrt{3e}-1$$ With the solution, can the answerer also add what came to his mind when he looked at the integral, in the sense of how did he think to approach this problem? There must obviously be some features of this expression that more experienced people can see and hence can guess the method which might work. I want to know what such features have been identified while solving this.
On the other hand, if there is just a normal standard way of solving this. I would love to know that too!","['integration', 'definite-integrals']"
4236502,Show that in $\mathbb R^3$ the function $F(x)=\frac{-1}{4\pi|x|}e^{-|x|}$ is a fundamental solution of the operator $\Delta-I$,"Show that in $\mathbb R^3$ the function $F(x)=\frac{-1}{4\pi|x|}e^{-|x|}$ is a fundamental solution of the operator $\Delta-I$ By the way,the function $F$ is the Yukawa potential.What I try is that if $F$ is any fundamental solution, taking Fourier transform about $(\Delta-I)F=\delta$ plus noting that the characteristic polynomial of the operator is $-(1+4\pi^2|\xi|^2)$ I can get $$F=\int _{\mathbb R^d}\frac{1}{-(1+4\pi^2|\xi|^2)}e^{2\pi ix\xi}d\xi=-\frac{1}{2}e^{-|x|}$$ in the sense of distribution.So in $\mathbb R^3$ I think $-\frac{1}{2}e^{-|x|}$ may be a fundamental solution which is different from the given function $\frac{-1}{4\pi|x|}e^{-|x|}$ (Is what I calculate right?this incidentally show that in general the fundamental solution is not unique?).But how to show $\frac{-1}{4\pi|x|}e^{-|x|}$ is also a fundamental solution?The hint says to use two identity $$\int_{|\xi|=1}e^{2\pi i\xi x}d\sigma(\xi)=\frac{2\sin(2\pi|x|)}{|x|},\hat{Q_y}(\xi)=e^{-2\pi y|\xi|}\frac{sign(\xi)}{i}$$ where $Q$ is the conjugate Possion kernel.But I can't apply them to solve the problem.Can anyone give me a helping hand,thank you","['functional-analysis', 'distribution-theory']"
4236510,ADE types singularities of $K3$ surfaces,"I was reading a paper in which they have an algebraic surface \begin{equation}
F(x, y, u) = u^2(1+xy)= (x+y).(x+y-4xy+x^2y+xy^2)
\end{equation} After homogenising the surface they get; \begin{equation}
F(x, y, u,z) = u^2(z^2+xy)-(x+y).((x+y)z^2-4xyz+x^2y+xy^2)
\end{equation} They are saying one of the singularities of this projective hypersurface is $[x:y:u:z] = [1:1:0:1]$ and this singularity is ADE type $A_1$ . I have found on the internet so far that to prove it $A_1$ type; I have to show that the singular point is analytic isomorphic to \begin{equation}
x^2+y^2+z^2 =0
\end{equation} Can someone please explain how I can show that? I would be a great help if you explain the steps for the calculation in simpler words as I don't have much mathematical background knowledge in this area.","['algebraic-geometry', 'abstract-algebra', 'surfaces', 'k3-surfaces']"
4236554,"Counting problem with numbered deck of cards, probability one card is exactly double another","I've recently purchased a book I assume has an incorrect solution to this problem. I wanted to run my solution by you Assume you have a deck of 100 cards with values ranging from 1 to 100 and that you draw two cards at random without replacement. What is probability one card is precisely double that of the other? My solution: Assume first card can be double or second card can be double If first card is double it can be any even number (50 choices) If first card is double, second card has 1/99 probability of being the half-card So for the first card to be double, the probability is: 50 * 1/100 * 1/99 For the second card to be double, we simply double our total probability. So the probability of drawing two cards, where one is double the other, is: 2 * 1/2 * 1/99 or 0.0101 Can someone let me know if I'm correct? The book's solution is double this, saying since order does not matter there are exactly 50 * 2 = 100 ways to draw such a pair. So the desired probability is 100/(100 choose 2) .","['combinatorics', 'probability']"
4236566,A simple interpretation of algebraic cycles as homology classes,"I understand an algebraic cycle to be a formal linear combination of closed irreducible subvarieties of some variety $X$ (over $\mathbb{C}$ ).
I guess to make things concrete, make $X$ smooth and projective with dimension $n$ . Now I have read that a $\operatorname{codim} p$ -cycle $Z$ in $X$ defines a $(2n-2p)$ -dimensional homology class $[Z] \in H_{2n-2p}(X)$ .
My question is What/is there a pedestrian explanation of why this is the case, and how to visualise it? Even an example with say $\mathbb{P}^1$ would be helpful here.
I know very little algebraic geometry overall (say only Hartshorne I and the first few chapters of II), so hopefully a minimal amount of reference to say divisors or intersection theory would be ideal (but I'm not sure if this is possible!)","['algebraic-cycles', 'algebraic-geometry', 'homology-cohomology', 'intersection-theory']"
4236703,Distribution of Sum of Sample Mean and Sample Variance from a Normal Population.,"Let $X_i\sim^{iid} N(\mu, \sigma^2)$ . Let $\bar X$ and $S^2$ denote the usual, resp, sample mean and sample variance. What is the distribution of $\bar X+S^2$ ? Since we know that the sample mean and sample variance are independent in a Normal population, I guess my question would be equivalent to asking what is the resulting distribution of independent Normal distribution and a Chi-Squared distribution.","['statistics', 'probability-distributions', 'normal-distribution', 'sampling', 'probability']"
4236738,"$[0,1]$ not compact with the discrete metric","I am trying to show that $[0,1]$ is not compact when $\mathbb{R}$ is equipped with the discrete metric. Consider $\mathbb{R}$ equipped with the discrete metric. Since every singleton set in $\mathbb{R}$ is both open and closed, under the discrete metric, every subset of $\mathbb{R}$ is both open and closed. Thus $[0,1]$ can be expressed as the union of arbitrarily many singleton sets (the union of arbitrarily many open sets is itself open). The collection of such sets constitutes an open cover of $[0,1]$ (call this cover $G$ ). Yet, if we remove at most one of the singleton sets from $G$ , $G$ no longer covers $[0,1]$ . Thus, $G$ is a cover, of $[0,1]$ , that does not admit a finite sub cover. Thank you.","['general-topology', 'analysis']"
4236785,"Under what conditions, or how can be done that, one says that something divergent can have a value?","Excuse my question, I just don't get it. In this proof , is mentioned: Now if you write formally the derivative of the Dirichlet-series for zeta then you have $$ \zeta'(s) = {\ln(1) \over 1^s}+{\ln(1/2) \over 2^s}  +{\ln(1/3) \over 3^s} + \ldots $$ This is for some s convergent and from there can be analytically continued to $s=0$ as well from where the the formal expression reduces to $$ \zeta'(0) = -(\ln(1) +\ln(2) +\ln(3)  + \ldots )$$ which is then formally identical to $ - \lim_{n \to \infty} \ln(n!)$ . That is, one ultimately gets $ - \lim_{n \to \infty} \ln(n!)$ In that same proof, mentions that $\zeta'(0)=-\ln\sqrt{2\pi}$ Ultimately, one would get to "" $\infty!=\sqrt{2\pi}$ "" Why the two values "" $\infty$ "" and $\sqrt{2\pi}$ were assigned to be equal? Thanks in advance.","['analytic-continuation', 'proof-explanation', 'complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
4236811,What is the dual space of a signed measures with zero mean,"For locally compact space $X$ , Let $C_c(X)$ be the compactly supported, continuous functions on $X$ to $\mathbb{C}$ . It is known theorem ( Riesz-Markov-Kakutani ) that the dual space of $C_c(X)$ is characterized by Radon measures on $X$ , say ${\cal M}(X)$ . My question is, what is the dual space of the subspace. $$
{\cal M}_0(X) = \left\{\mu \in {\cal M}(X)\bigg| \int_X \mathrm d\mu = 0\right\}
$$ Here is my initial idea:
Consider an equivalence relation for $f, g \in C_c(X)$ : $$
f\sim g \quad \text{if} \quad f(x)-g(x) = c \quad \text{for some }c\in\mathbb{C}, \forall x\in X
$$ and we can consider equivalence class $[f]\subset C_c(X)$ . The claim is the family of this equivalence class is dual to ${\cal M}_0(X)$ . The duality pairing is the natural pairing, while it is well-defined because $\mu(f) = \mu(g)$ if $f\sim g$ . For metric or norm, $\|[f]\| = \inf_{f\in[f]} \|f\|$ is adopted. How can I validate the guess, or is there other conditions that I need to refine?","['measure-theory', 'duality-theorems', 'functional-analysis', 'dual-spaces']"
4236870,The mean ergodic theorem for weakly mixing extension,"I got stuck with the following while going through the proof of Lemma 3.21 from the book 'Ergodic Theory: Independence and Dichotomies' by Kerr and Li. Problem: If $(X,\mu,T)$ is a weakly mixing extension of $(Y,\nu,S)$ , then $$\{f\in L^2(X|Y):f\circ T=f\}\subseteq L^{\infty}(Y).$$ Here I recall the following definitions which are used for the above problem. Definition 1: Let $(X,\mu)$ and $(Y,\nu)$ be two probability measure space. Let $T:X\rightarrow X$ and $S:Y\rightarrow Y$ be two invertible measure preserving transformations. We say that $(X,\mu,T)$ is an extension of $(Y,\nu,S)$ if there is a $T$ invariant conull set $X'\subseteq X$ and an equivariant measurable map $\pi : X'\rightarrow Y$ such that $\mu (\pi^{-1}(A))=\nu (A)$ for all measurable $A\subseteq Y$ . Definition 2: Given an extension $(X,\mu,T)\rightarrow (Y,\nu,S)$ , let $\mathbb{E}_Y:L^2(X)\rightarrow L^2(Y)$ be the conditional expectation. Then $L^2(X|Y)$ is the completion of $L^{\infty}(X)$ with respect to the norm $\|f\|:=\|\mathbb{E}_Y(f\cdot\overline{f})\|^{1/2}$ . Definition 3: An element $f\in L^2(X|Y)$ is said to be conditionally weakly mixing if the mean $$\lim_{n\rightarrow\infty}\frac{1}{n}\sum_{s=-n}^{s=n}\|\mathbb{E}_Y((f\circ T^s)\cdot\overline{f})\|=0.$$ Definition 4: The extension $(X,\mu,T)\rightarrow (Y,\nu,S)$ is said to be weakly mixing if every element in $L^2(X|Y)$ orthogonal to $L^{\infty}(Y)$ is conditionally weakly mixing. Thanks in advance for any help or suggestion.","['conditional-expectation', 'measure-theory', 'ergodic-theory', 'functional-analysis']"
4236879,Orbits of $z_{n+1} = z_n ^2 - 1$,"Consider the sequence $z_{n+1} = z_n ^2 - 1$ defined for an arbitrary complex number $z_0$ . I am trying to determine all $z_0$ such that the sequence eventually becomes periodic. Here is my progress so far: If $|z_0|> \frac{1+\sqrt{5}}{2}$ the sequence is absolutely increasing since $$|z_{n+1}|=|z_n^2 - 1|\geq|z_n|^2-1 > |z_n| ,$$ which is true since $ |z_n| > \frac{1+\sqrt{5}}{2}$ holds inductively. If $z_0=\frac{1+\sqrt{5}}{2}$ the sequence would be the constant sequence of $\frac{1+\sqrt{5}}{2}$ and hence periodic. Similar to the first case if $|z_0|<\frac{1}{2}$ or more precisely if $|z_0|$ less than the root of $\alpha^3 +2\alpha -1 = 0,$ the sequence $\{z_{2i} \}$ becomes strictly decreasing since $$|z_{2i}| = |z_{2i-1}^2 - 1 |= |z_{2i-2}^4 - 2z_{2i-2}^2|<  |z_{2i-2}| \Leftrightarrow |z_{2i-2}^3 - 2z_{2i-2}| < 1.$$ Which holds true if $$ |z_{2i-2}^3 - 2z_{2i-2}| \leq  |z_{2i-2}^3|+| 2z_{2i-2}| <1.$$ And as a result $\{z_i\}$ cannot be periodic.",['complex-analysis']
4236929,Proof of indexed inverse image statement,"Prove that: $f^{-1}(\bigcap_{\lambda \in \Lambda}B_{\lambda})=\bigcap_{\lambda \in \Lambda}f^{-1}(B_{\lambda})$ My proof: Suppose, $x\in f^{-1}(\bigcap_{\lambda \in \Lambda }B_{\lambda}) \iff f(x) \in \bigcap_{\lambda \in \Lambda}B_{\lambda}. \iff f(x) \in B_{\lambda}, \forall \lambda \in \Lambda \iff x\in f^{-1}(B_{\lambda}),\forall \lambda \in \lambda. \iff x\in \bigcap_{\lambda \in \Lambda} f^{-1}(B_{\lambda}).$ Am I correct?","['elementary-set-theory', 'solution-verification', 'real-analysis']"
4236966,What is the notation $f¢(x)$ stands for in context of derivatives?,"Consider the remark given here in the chapter 6 named APPLICATION OF DERIVATIVES from NCERT class 12 book There is a more generalised theorem , which states that if $\mathbf{f¢(x) > 0}$ for $x$ in an interval excluding the end points and $f$ is continuous
in the interval, then $f$ is increasing. Similarly, if $\mathbf{f¢(x) < 0}$ for $x$ in an interval excluding the end points and $f$ is continuous in
the interval, then $f$ is decreasing. I am facing two issues in understanding it, What is the notation $f¢(x)$ ? Is it $f'(x)$ ? How is it a generalisation of the following theorem as told? (I can see no difference in both, if 1 is true) Let $f$ be continuous on $[a, b]$ and differentiable on the open
interval $(a,b)$ . Then (a) $f$ is increasing in $[a,b]$ if $f ′(x) > 0$ for each $x \in (a,
 b)$ (b) $f$ is decreasing in $[a,b]$ if $f ′(x) < 0$ for each $x \in (a,
 b)$ (c) $f$ is a constant function in $[a,b]$ if $f ′(x) = 0$ for each $x
 \in (a, b)$","['notation', 'derivatives']"
4236975,Bounding linear transformation by a constant,"I am stuck on an exercise in Spivak which comes up alot in the text. Exercise Spivak 1-10: If $T:\mathbb{R}^m\to \mathbb{R}^n$ is a linear transformation, show that there is a number $M$ such that $|T(h)|<M|h|$ for all $h\in \mathbb{R}^m$ . Hint: estimate $|T(h)|$ in
terms of $|h|$ and the entries in the matrix $T$ . My work is as follows Assume that $\{\textbf{e}_1,\dots, \textbf{e}_m\}$ is a basis for $R^m$ and $\{\textbf{u}_1,\dots, \textbf{u}_n\}$ is a basis for $\mathbb{R}^n$ . Then Fix $h=c_1\textbf{e}_1+\dots+c_m\textbf{e}_m\in \mathbb{R}^m$ . Finally, assume that $t_{ij}$ are the entries for the matrix representation of $T$ . $$|T(h)|\\
=\left|\sum_{i=1}^mc_iT(e_i)\right|\\
=\left|\sum_{i=1}^m\sum_{j=1}^nc_it_{ij}\textbf{u}_j\right|\\
\leq\sum_{i=1}^m\left|\sum_{j=1}^nc_it_{ij}\textbf{u}_j \right|\\
=\sum_{i=1}^m \sqrt{\sum_{i=1}^n (c_i t_{ij})^2 }$$ . I have seen that I need to apply the Cauchy Schwarz inequality however I am not sure how to apply this due to the square inside of the square root in the last equality. How can I proceed from here? (I'm not worried about the step where I need to take the max over all of the matrix entries).","['complex-analysis', 'calculus', 'linear-algebra', 'real-analysis']"
4236989,Use Epsilon Definition of Limit to Prove Limit Exists,"We have the function $$f(x,y)=
\begin{cases}
0  & \textrm{if } x=y=0 \\[2ex]
(x+y)\ln(x^2+y^2) & \textrm{otherwise}
\end{cases}$$ and need to prove $\lim\limits_{(x,y) \to (0,0)} f(x,y) = 0$ . We need to show that for any $\epsilon>0$ we can find a $\delta > 0$ such that for any $(x.y)$ with $0< \sqrt{x^2+y^2}<\delta$ , we have $|f(x,y)| < \epsilon$ Some of the steps are: $$\begin{align}|f(x,y)| &= \left|(x+y)\ln(x^2+y^2)\right| \\&= \left|\frac{2(x+y)}{\sqrt{x^2+y^2}}\sqrt{x^2+y^2}\ln(\sqrt{x^2+y^2})\right| \\&\le 2\sqrt{2}\left|\sqrt{x^2+y^2}\ln(\sqrt{x^2+y^2})\right|
\end{align}$$ but I do not understand how you get including expression including $\sqrt{x^2+y^2}$ after plugging in the value to the absolute value and how that relates to the inequality. There has to be a step I am missing.","['limits', 'proof-explanation', 'epsilon-delta', 'real-analysis']"
4237006,What is the sum of the angles a+b+c?,"For reference: (figure without scale) My progress: Circle centers are collinear.
I think that the straight line joining the centers passes through the point of tangency with the side of the triangle. Therefore, the triangles formed will be rectangles and $\measuredangle a$ and $\measuredangle b$ will be $90^\circ$ . It remains to demonstrate that $\measuredangle c = 45^\circ$ . Update:","['euclidean-geometry', 'angle', 'geometry', 'plane-geometry']"
4237038,Twin Births Casella Berger Probability Question,"I was reading through Casella and Berger's Statistical Inference when I came across the following problem: The probability of a twin birth is approximately 1 /90, and we can assume that
an elementary school will have approximately 60 children entering kindergarten
(three classes of 20 each) . Explain how our ""statistically impossible"" event can be
thought of as the probability of 5 or more successes from a binomial(60, 1 /90). Is
this even rare enough to be newsworthy? I'm struggling to understand how this is a binomial distribution. I looked up explanations for this online and got limited results. In my understanding, the probability of there being a pair of twins would be the probability of choosing two people to be twins, with the remaining $60-2 = 58$ people being twin-less. Basically, if $X$ is the random variable indicating how many sets of twins are in the incoming class, then $$P(X = x) = {60 \choose 2x} \Big(\frac{1}{90}\Big)^x \Big(\frac{89}{90}\Big)^{\frac{60-2x}{2}}$$ since we would choose $2x$ people to be twins, with each pair having $\frac{1}{90}$ people being twins, and then the rest of the remaining pairs ( $\frac{60 - 2x}{2}$ ) would have probability $\frac{89}{90}$ of not being twins. I found an explanation here that I don't understand: I think the book is correct ""in the first order""; you are double counting. Suppose there are n students in a classroom. We ask each student: ""do you have a twin sibling?"" If the the student answers ""no,"" he or she leaves the classroom. If the student answers ""yes,"" we ask the student to identify the sibling. Then both of them leave. If all students were to answer ""no,"" the combinatorial coefficient would be 0Cn. If only one student answered ""yes,"" then the combinatorial coefficient isn't 2Cn, it is 1C(n-1). If exactly k students answered yes, then the combinatorial coefficient isn't (2k)Cn, it is kC(n - k). I know something is wrong with my approach, but I don't understand how I would be ""double counting"" the number of twins. Thank you for any help.","['statistical-inference', 'statistics', 'probability-distributions', 'binomial-distribution', 'probability']"
4237066,Remainder Theorem Technique,"Determine the remainder when $(x^4-1)(x^2-1)$ is divided by $1 + x + x^2$ (HMMT 2000, Guts Round) A. Write the division in the form: $$(x^4-1)(x^2-1)= (1 + x + x^2)Q(x) + R(x)$$ B. Multiply both sides by $x-1$ : $$(x-1)(x^4-1)(x^2-1)= (x^3-1)Q(x) + R(x)(x-1)$$ C. Substitute $x^3=1,x\neq1$ , and reduce the resulting equation: $$(x-1)(x-1)(x^2-1)= R(x)(x-1)$$ D. Divide both sides by $x-1$ : $$R(x)=(x-1)(x^2-1)=x^3 -x - x^2 + 1=-(x^2+x+1)+3=3$$ For someone who knows the method, is it valid to skip Steps B and D , directly substitute $x^3=1,x\neq1$ and use the fact that $x$ is a cube root of unity to get $x^2+x+1=0$ .","['contest-math', 'algebra-precalculus', 'polynomials', 'complex-numbers']"
4237090,$A\subset (B\cup C)$ $\implies$ $A\subset B $ or $A\subset C$,"Clearly, it is not true that $A\subset (B\cup C)$ implies $A\subset B $ or $A\subset C$ , since if $A=\{b,c\}, B=\{a,b\}, \text{ and }C=\{c,d\}$ , then $A\subset B\cup C =\{a,b,c,d\}$ but $A\not\subset B$ and $A\not\subset C.$ However, if one tries to prove the above statement, where does the proof go wrong? Proof: Let $x\in A$ . Since $A\subset B\cup C, x\in A\implies x\in B\cup C\implies x\in B$ or $x\in C. $ Since $x\in A\implies x\in B$ or $x\in C$ is equivalent to $x\in A\implies x\in B$ or $x\in A\implies x\in C$ , this shows $A\subset B$ or $A\subset C. \blacksquare$","['elementary-set-theory', 'fake-proofs']"
4237105,"For an acute angled triangle $ABC,$ if $p=\frac{\sqrt3+\sin A+\sin B+\sin C}{2\sin A\sin B\sin C}$, find the range of $p$","$$ p=\frac{\sqrt3+\sin A+\sin B+\sin C}{2\sin A\sin B\sin C}$$ $\displaystyle \sin A+\sin B+\sin C=4\cos\frac{A}{2}\cos\frac{B}{2}\cos\frac{C}{2}$ and $\displaystyle \sin A\sin B\sin C=8\cos\frac{A}{2}\cos\frac{B}{2}\cos\frac{C}{2}\sin\frac{A}{2}\sin\frac{B}{2}\sin\frac{C}{2}$ in a triangle $A<90^\circ, \text{so} \space A/2<45^\circ$ then $ \sin\frac{A}{2}<1/\sqrt2$ . However, $$ \cos\frac{A}{2}>1/\sqrt2$$ So this probably doesn't lead us anywhere :( . Can anyone please help, thanks.","['inequality', 'maxima-minima', 'functions', 'geometric-inequalities', 'trigonometry']"
4237116,Piecewise smooth vector field along a one-parameter family of curves,"Let $(M,g)$ be a Riemannian manifold. According to Lee's book on Riemannian manifolds, a one-parameter family of curves is defined as a continuous map $\Gamma:J\times I\to M$ , where $I,J$ are intervals on the real line. This map got its name since we can thus obtain two collection of curves in $M$ : the main curves $\Gamma_s(t)=\Gamma(s,t)$ defined by holding $s$ constant, and the transverse curves $\Gamma^{(t)}(s)=\Gamma(s,t)$ defined by holding $t$ constant. Now we can introduce the notion of a vector field along such family of curves. A vector field along $\Gamma$ is a continuous map $V:J\times I\to TM$ such that each $(s,t)\in J\times I$ is assigned a vector $V(s,t)\in T_{\Gamma(s,t)}M$ . One example of such is the velocity vector field of a transverse curve, denoted by $$(\partial_s\Gamma)(s_0,t_0)={\Gamma^{(t_0)}}'(s_0).$$ I'm sorry that still another definition needs to be introduced. $\Gamma$ is said to be admissible if: (i) The domain of $\Gamma$ is of the form $J\times[a,b]$ for some open interval $J$ . (ii) There is a partition $(a_0,\ldots,a_k)$ of $[a,b]$ such that $\Gamma$ is smooth on each rectangle $J\times[a_{i-1},a_i]$ . Partitions like this are called admissible. (iii) Every main curve is a piecewise regular curve segment. A curve is said to be regular if it has non-vanishing velocity. Given an admissible family $\Gamma$ , we describe a continuous vector field along $\Gamma$ as piecewise smooth if the restriction of the vector field to each $J\times[a_{i-1},a_i]$ for some admissible partition $(a_0,\ldots,a_k)$ . Lee claims that $\partial_s\Gamma$ is one such vector field, and his argument about continuity of $\partial_s\Gamma$ on the whole $J\times[a,b]$ is confusing me: To see that is continuous on the whole domain $J\times[a,b]$ , note on the one hand that for each $i=1,\ldots,k-1$ , the values of $\partial_s\Gamma$ along the set $J\times\{a_i\}$ depend only on the values of $\Gamma$ on that set, since the derivative is taken only with respect to the $s$ variable; on the other hand, $\partial_s\Gamma$ is continuous (in fact smooth) on each sub-rectangle $J\times[a_{i-1},a_i]$ and $J\times[a_{i},a_{i+1}]$ , so the right-hand and left-hand limits at $t=a_i$ must be equal. Why is Lee concerned about the values of $\partial_s\Gamma$ along $J\times\{a_i\}$ ? Is he doing something like $$\lim_{x\to a}f(x)=f(a)?$$ Thank you so much for your patience. Thank you.","['riemannian-geometry', 'differential-geometry']"
4237137,Modelling the variance of dollar values of the rare/mythic slot in a Magic: the Gathering booster pack,"I'm trying to model the variance of a certain kind of card that is pulled from a Magic: the Gathering trading card pack. My simplified model is this: I open a booster pack containing exactly one card. In this instance, the probability of getting a mythic is $w_M=\frac{1}{8}$ and the probability of a rare is $1-w_M=\frac{7}{8}$ , so: $\frac{7}{8}$ of the time, it is a rare card that is selected from a list of $i$ equally likely rare cards having dollar values $R = (r_1,...,r_i)$ $\frac{1}{8}$ of the time, it is a mythic card that is selected from another list of $j$ equally likely mythic cards having dollar values $M = (m_1,...,m_j)$ A example set of values we can easily work with might be: $R = (0.1, 0.2, 0.5, 3.0, 3.5)$ $M = (0.1, 5, 10)$ Calculating the population variance of each component of $R$ or $M$ would be straightforward: $$\sigma^2_R=\frac{\sum^i_{k=1}{(r_i - \mu_R)^2}}{i} = \frac{(0.1-1.46)^2+(0.2-1.46)^2+(0.5-1.46)^2+(3.0-1.46)^2+(3.5-1.46)^2}{5} = 2.1784$$ $$\sigma^2_M=\frac{\sum^j_{k=1}{(r_i - \mu_M)^2}}{i} = \frac{(0.1-5.033..)^2+(5-5.033..)^2+(10-5.033..)^2}{3} = 16.3356$$ However, I'm not sure how to combine these two values into something that accurately reflects the entire model of the variance of dollar values from getting a rare card $\frac{7}{8}$ of the time and a mythic card $\frac{1}{8}$ of the time. I expect that naively averaging variances like this doesn't work, but I think this incorrect calculation hints at what I'm trying to calculate: $$\sigma^2_{R\cap M}= \frac{7\sigma^2_{R}+\sigma^2_{M}}{8}=\frac{7\times2.1784+16.3356}{8}=3.9481$$ After doing some research of what I've modelled, this feels like trying to calculate the variance of combined weighted discrete independent uniform distributions - that is to say, each of $R$ and $M$ are discrete uniform distributions in themselves, and I'm trying to combine them together in a way that one distribution is seven times more likely to occur than the other. When looking at combining continuous independent uniform distributions, I found the Irwin-Hall distribution , but that seems to be modelling equally likely continuous independent uniform distributions and likely more complex than what I'm looking for. Some ideas I have to work around my inability to combine these distributions would be: Experimentally calculate variance by simulating a large number of pack openings Making some combined uniform discrete distribution $R_7M = R\cup R\cup R\cup R\cup R\cup R \cup R \cup M$ that has seven of each rare value and one of each mythic value (this doesn't work because there isn't typically the same number of mythic and rares) Doing something like above but with tuples of overall probability and dollar values like $RM = {(\frac{7}{7i+j},r_1), ..., (\frac{7}{7i+j},r_i), (\frac{1}{7i+j},m_1), ..., (\frac{1}{7i+j},m_j)}$ and then calculating the variance using these tuples somehow? I'm looking for a way that for arbitrary $P_M, R, M$ I can either transform the problem into something that I can calculate the variance on, or a way to calculate the combined weighed variance of the two distributions. I'm sure that I'm just forgetting some basic concept of statistics and probability - this concept of combined variance feels like something that would have been covered in an introductory statistics class, but I'm just not finding the right words to describe it.","['card-games', 'uniform-distribution', 'variance', 'probability']"
4237154,How to solve this kind of ordinary differential equations $t y y^{\prime \prime}-2 t\left(y^{\prime}\right)^{2}+3 y y^{\prime}=0$,"Often, to solve an ODE, it if enough to classify it correctly and apply correspondent well-known method. But in this case I struggle $t y y^{\prime \prime}-2 t\left(y^{\prime}\right)^{2}+3 y y^{\prime}=0$ It is non-linear homogeneous second-order ODE with variable coefficients. In textbooks, people talk about similar equations where one variable is missing (x or y or y'). In that case, we use substitution like y = z(z) or y' = p(x). But in my ODE, I do not see what to do.",['ordinary-differential-equations']
4237193,Any fibration of $S^3$ by simple closed curves must have base space $S^2$ and be equivalent to the Hopf-fibration.,"I am currently reading Great Circle Fibrations of the Three-Sphere by Gluck and Warner since I am very interested in the Hopf-fibration. In particular I'm looking for properties which make it special, so this caught my eye. In the introduction, the authors remark that Any fibration of $S^3$ by simple closed curves must have base space a two-sphere and, as is well known [S], must be equivalent to the Hopf-fibration. Sadly, the reference, Steenrod's The Topology of Fibre Bundles , isn't available through my university library or any of its partners. Since this is ""well known"", I was hoping that someone could perhaps outline a proof, reference a theorem/construct which can be used to prove this fact, or another source in which a proof could be found.","['fiber-bundles', 'algebraic-topology', 'differential-geometry']"
4237196,Symmetry of mixed partial derivatives.,"I have come across two theorems, which I think are essentially trying to say the same thing: 1) The mixed derivative theorem: If $f(x, y)$ and its partial derivatives $f_x$ , $f_y$ , $f_{xy}$ and $f_{yx}$ are defined in a neighborhood of $(x_0, y_0)$ and all are continuous at $(x_0, y_0)$ , then : $$f_{xy}(x_0, y_0) = f_{yx}(x_0, y_0).$$ 2) Clairaut's theorem: Suppose that $f$ is defined on a disk $D$ that contains the point $(a,b)$ . If the functions $f_{xy}$ and $f_{yx}$ are continuous on this disk then: $$f_{xy}(a,b) = f_{yx}(a ,b).$$ Why are there two separate theorems for conveying the same thing?
Is it that the second one is an improved version of the first one?
It seems that the mixed derivative theorem lists some redundant conditions, because existence of the second order partial derivatives would imply the continuity of $f_x$ and $f_y$ .
Is it wrong to conclude this?","['calculus', 'derivatives', 'ordinary-differential-equations']"
4237197,Number of ternary sequences of length $n$ with same number of $1$'s and $0$'s,"My attempt is considering the number of $1$ 's to be $k$ then for each $k$ we choose choose the inner order of the $1$ 's and $0$ 's which has ${2k \choose k }$ options then choosing the indices of the $2$ 's which has ${ n \choose n -2k } = { n \choose 2k }$ . So if we sum for each $k$ we get: $\sum_{k=0}^{\left \lfloor \frac{n}{2} \right \rfloor} {2k \choose k }{ n \choose 2k } = \sum_{k=0}^{\left \lfloor \frac{n}{2} \right \rfloor} \frac{(2k)!}{k!k!} \frac{n!}{(2k)!(n-2k)!} = \sum_{k=0}^{\left \lfloor \frac{n}{2} \right \rfloor} \frac{n!}{k!k!(n-2k)!} $ The problem is that this doesn't add up to a nice closed form, any idea how to get a nice closed form from here or by any other method?",['combinatorics']
4237206,"If a symmetric matrix commutes with all symmetric matrices, is it then a multiple of the identity?","I know that, if a matrix commutes with all matrices, then it is a multiple of the identity; see here . The same conclusion holds if a (special) orthogonal matrix commutes with all (special) orthogonal matrices, as shown here and here . In this context, I wonder if the following claim is true. Claim : If a symmetric matrix $A$ commutes with every other symmetric matrix, does it then follow that $A = \lambda  I$ for some $\lambda \in \mathbb{R}$ ?","['vector-spaces', 'matrices', 'abstract-algebra', 'linear-algebra', 'linear-transformations']"
4237261,Solving a nonlinear PDE,"I wish to solve the following PDE: $$
u_t - (u^{2})_{xx}=0
$$ with some boundary conditions which right now is not of much relevance apart from the fact that $u(t,x)$ is a piecewise continuous function and $u_x(t,0)=0$ . I have used the following substitution: $u(t,x)=f(\eta)t^{-\frac{1}{3}}$ and $\eta=xt^{-\frac{1}{3}}$ which reduces the above equation to a single variable of the form: $$
\partial_{\eta}\left ( 2ff_\eta + \frac{\eta f}{3} \right )=0
$$ Now, I am very confused about how to proceed with this reduced form to solve the above equation and find the analytical solution of $f(\eta)$ thereby finding the analytical solution of $u(t,x)$ . Help of any sort is deeply appreciated. Thanks in advance.","['ordinary-differential-equations', 'partial-differential-equations']"
4237268,Solving differential equation featuring $f(1)$ as a coefficient,"Starting with $g(x)=\int_{1/x}^1 g(kx)(2-2k)dk+1,$ after integration by parts of the RHS I get the following DE for the second antiderivative of $g(x),$ say $f(x)$ : $x^2f''(x)+(2x-2)f'(1)-2(f(x)-f(1))-1=0.$ I'm not really sure how to approach this - for instance, if I pretend $f(1)$ and $f'(1)$ are merely constants, I can spot the differential operator $x^2f''(x)-2f(x)$ has eigenfunctions $1/x$ and $x^2$ . However, the usual plan of using these homogeneous solutions to find the general solution seems not to work, as my homogeneous solutions (and their first derivatives) don't vanish at $x=1$ . Is there perhaps a better way of attacking the original integral equation? It's also worth mentioning I have a BC - namely $g(1)=1.$","['ordinary-differential-equations', 'integro-differential-equations']"
4237360,Probability that one weighted mean of iid random variables is greater than the other,"I read somewhere that if $X_1,\dots, X_n,Y_1,\dots,Y_m$ are all i.i.d. and admit probability densities w.r.t the Lebesgue measure and we choose weights $\omega_1,\dots,\omega_n,\rho_1,\dots,\rho_m$ such that $\sum_{i=1}^n\omega_i=\sum_{i=1}^m\rho_i=1$ , we have: $$\mathbb{P}\left(\sum_{i=1}^n\omega_iX_i\leq \sum_{i=1}^m\rho_iY_i\right)=1/2.$$ I have tested this numerically and it seems to hold, but I cannot seem to prove it, does someone have an idea on how to do this?","['statistics', 'probability']"
4237397,Is the image of a separable metric space under a measurable map still separable?,"This question stems from Problem 10, section 4.2 and Problem 9, section 13.1 of Real Analysis and Probability written by Dudley. Similar question has been posed in: Problem 10, section 4.2 of R.M. Dudley, Real Analysis and Probability . In Problem 10, section 4.2, we are asked to prove: Let $f$ be a Borel measurable function from a separable metric space $X$ onto a metric space $S$ with metric $e$ . Show that $(S, e)$ is separable. And in Problem 9, section 13.1, we are asked to prove: Let $(S, d)$ be a separable metric space and $(T, e)$ a metric space. Let $f$ be a Borel measurable function from $S$ into $T$ . Assuming the continuum hypothesis, prove that the range $f[S]$ is separable. I'm very confused about the difference between these two statements. It seems that the proof of the previous one does not need the continuum hypothesis. But I can't find such a proof. In my point of view, we can't prove Problem 10 in section 4.2 without assuming continuum hypothesis, if we follow the hint given by Dudley: If $S$ is not separable, then show that for some $ε>0$ , there is an uncountable subset $T$ of $S$ with $d(y, z)>ε$ for all $y\neq z$ in $T$ . Use Problem 9 (the statement and proof of Problem 9 is given in: Problem 9, section 4.2 of R.M. Dudley, Real Analysis and Probability ) to get a measurable function $g$ from $X$ onto $T$ . All $g^{-1}(A) (A \subset T)$ are Borel sets in $X$ . Thanks in advance to your help!","['measure-theory', 'functional-analysis']"
4237401,2d random walk: expected time to hit enclosing square,"Problem : consider a random walk on a 2d square lattice. We start at the origin and each second we move by one unit either up, down, left or right with equal probability (equal to $1/4$ ). Suppose there is a square surrounding the origin of the plane, centered at $(0,0)$ and whose sides have length $L=4$ , i.e. the vertices of the square are located at the four points $(\pm 2,\pm 2)$ . Question : what is the expected time required to hit the square? Now, we can get an approximation of the expected time by computing the RMS distance, which is given by $$\sqrt{E(D_N^2)} = \sqrt{N}$$ where $D_N$ is the distance from the origin after $N$ seconds. However, this is obviously not the same as the expected distance itself, which would be $E(|D_N|)$ . I know that the latter can be at least computed asymptotically (i.e. when $N\rightarrow \infty$ ), but for the problem in question we expect $N\sim 4$ , which is clearly much smaller than infinity, so I would like to find a more accurate value (if possible!). I have tried using the results from 1.4.2 in this reference , but I am stuck trying to compute $p_n(x,y;A)$ , i.e. the probability of being at point $y$ at time $n$ when starting from point $x$ , where $x,y \in A$ . For example, let's say we want to compute $p_n(0,0)$ , that is the probability of returning to the origin after $n$ steps when there is no boundary . It is known that this is equal to $$\begin{cases}p_{2n}(0,0) = 4^{-2n} {2n \choose n}^2\\ p_{2n+1}(0,0)=0 \end{cases}.$$ My issue is that I don't know how to compute this probability when there is a boundary. Clearly we must have $p_n(0,0;A)\le p_n(0,0)$ since some paths are not allowed anymore, but I'm not sure how to compute it exactly. Honestly I'm not even sure this is the right route to solve the problem. I hope I stated the problem clearly. I have been away from statistics for a few years, so I'm quite rusty. Any help would be greatly appreciated!","['statistics', 'combinatorics', 'random-walk']"
4237450,Tangent line to a two variables function,"Given the function $$f(x,y)=\sqrt{x^2+y^2-9}$$ I have to find the tangent line to it obtained from the intersection of the plane $y=-3$ with its graph at $(4,-3,4)$ . Since $$\frac{\partial f}{\partial x}(4,-3)=1$$ then the tangent line will be $$y-(-3)=1\cdot(x-4)$$ I want to know if it's correct.","['multivariable-calculus', 'tangent-line']"
4237483,Multivariate Lagrange inversion with powers,"Let the formal power series $\phi_1,\dots,\phi_m$ in the variables $x_1,\dots,x_m$ be defined by \begin{equation}
    \phi_i(x_1,\dots,x_m)=x_i\rho_i(\phi_1,\dots,\phi_m),\qquad i = 1,\dots,m
\end{equation} for some formal series $\rho_i(x_1,\dots,x_m)$ . Then, for any formal power series $f(x_1,\dots,x_m)$ we have \begin{equation}
    [{\vec x}^{\,\vec n}]f(\vec  \phi(\vec  x)) 
    = [{\vec t}^{\,\vec n}]f(\vec  t)
      \text{det}[K(\vec  t)]
      {\vec \rho}^{\,\vec n}(\vec  t)
\end{equation} where $K(\vec  t)$ is a matrix from $\mathbb R^{m\times m}$ , \begin{equation}
    K(\vec  t)_{i,j}=\delta_{i,j}-\frac{t_i}{\vec  \rho_i(\vec  t)}\frac{\partial \vec  \rho_i}{\partial t_j}(\vec  t), \qquad i,j\in 1,\dots,m
\end{equation} where $\vec  t=(t_1,\dots,t_m)$ , $\vec  n =(n_1,\dots,n_m)$ , ${\vec x}^{\,\vec n}=x_1^{n_1}x_2^{n_2}\cdots x_m^{n_m}$ and $\vec  x(\vec  y)=[x_1(\vec  y),\dots,x_m(\vec  y)]$ . In the case that $m=1$ , we recover the standard Lagrange-inversion formula. Consider the system \begin{equation}
    \phi_i(x_1,\dots,x_m)=x_i\rho_i(\phi_1^{p_1},\dots,\phi_m^{p_m}),\qquad i = 1,\dots,m
\end{equation} where $p_i$ are integer powers. How can I apply the Lagrange inversion theorem in this case? For a 1-dimensional scenario, my attempt is as follows. The coefficient of $x^n$ in $f(\phi^m(x))$ with $\phi(x) =x\rho(\phi^m(x))$ for $m=1,2,\dots$ . I find \begin{align}
[x^n]f(\phi^m(x))=&\frac{n!}{2\pi i}\oint \frac{f(\phi^m(x))}{x^{n+1}}dx\\
=& \frac{(n-1)!}{2\pi i}\oint \frac{1}{x^n}\left(\frac{d}{dz}f(\phi^m(x))\right)dz\\
=& \frac{(n-1)!}{2\pi i}\oint \frac{1}{x^n}\left(f'(\phi^m(x))m\phi^{m-1}(x)\phi'(x)\right)dx\\
=&\frac{m(n-1)!}{2\pi i}\oint\frac{ \rho(\phi^m(x))^n}{\phi^n(x)}\left(f'(\phi^m(x))\phi^{m-1}(x)\phi'(x)\right)dx
\end{align} In the last step we considered $x$ as a function of $\phi$ and $\rho$ from above. We now change the volume element and move the $\phi^{m-1}$ term to the denominator to obtain \begin{equation}
    [x^n]f(\phi^m(x))=\frac{m(n-1)!}{2\pi i}\oint\frac{ 1}{\phi(x)^{n-m+1}}\left[\rho(\phi^m(x))^nf'(\phi^m(x))\right]d\phi
\end{equation} We must then undo the Cauchy formula; however, this is where I am a bit stuck due to the denominator in $\phi(x)$ . My attempt is as follows $$
[x^n]f(\phi^m(x))= \frac{m}{n}[t^{n-m}]\rho(t^m)^nf'(t^m)
$$ where we have again simplified $1/n=(n-1)!/n!$ . I am not certain this is correct; however.","['power-series', 'lagrange-inversion', 'combinatorics']"
4237511,"Given $\mathbb E[f(X^\top u)f(X^\top v)] \equiv h(u^\top v)$ for $X \sim N(0,I)$ and unit-vectors $u,v$, compute $h(1)$ and $h'(0)$ in terms of $f$","Let $f:\mathbb R \to \mathbb R$ be a continuous function and define $F:S_{d-1} \times S_{d-1} \to \mathbb R$ by $F(u,v) := \mathbb E[f(X^\top u)f(X^\top v)]$ , where $S_{d-1}$ is the unit-sphere in $\mathbb R^d$ and $X \sim N(0,I_d)$ . Because of rotational invariance of the distribution of $X$ , it is clear that $F(u,v) \equiv h(u^\top v)$ for some continuous function $h:[-1,1] \to \mathbb R$ . Questions: (1) How smooth can the function $h$ be on the open interval $(-1,1)$ , especially around the point $0$ ? (2) In case $h$ is differentiable at $0$ , what is the value of $h'(0)$ in terms of $f$ ? Observation For computing the value of $h(0)$ , one can take any $a,b \in S_{d-1}$ such that $a^\top b = 0$ . Then $X^\top a$ and $X^\top b$ are independent random variables and so $$
h(0) = h(a^\top b) = \mathbb E[f(X^\top a)f(X^\top b)] = \mathbb E[f(X^\top a)]\mathbb E[f(X^\top b)] = \mathbb E[f(X_1)]^2 = \sigma_0(f)^2,
$$ where $\sigma_k(f)$ is the $k$ th Hermite coefficient of $f$ , defined by $\sigma_k(f) = \mathbb E_{G \sim N(0,1)}[f(G)\operatorname{He}_k(G)]$ and $\operatorname{He}_k$ is the probabilist's $k$ th Hermite polynomial; in particular, $\mathrm{He}_0(z) = 1$ , $\mathrm{He}_1(z) := z$ , $\mathrm{He}_2(z) := z^2-1$ , $\mathrm{He}_3(z) := z^3-3z^2$ , etc. Similarly, for computing $h(1)$ one can take $a \in S_{d-1}$ and note that $$
h(1)=h(a^\top a) = \mathbb E[f(X^\top a)^2] = \mathbb E[f(X^\top a)^2] = \mathbb E[f(X_1)^2]=\sigma_0(f^2).
$$","['statistics', 'taylor-expansion', 'gaussian-integral', 'hermite-polynomials', 'probability']"
4237530,Why the differences between each number of a $x^2$ sequence is always an odd number and increase by $2$?,"I'm not a math person at all and I realize that this might be obvious, I'm trying to increase my awareness about it, so please excuse me if the question is too basic.  Also excuse my lack of formatting in expressing my ideas, any tip or correction would be appreciated. If you square the elements of a sequence of natural numbers $(1, 2, 3, 4,...)$ you respectively get $1,4,9,16,...$ If you calculate the difference between each consecutive element, you get $3,5,7, ...:$ This list of differences would always be composed of odd numbers. Why? Also, why does it 'grows' linearly, increased by $2$ on every step? Thanks.","['algebra-precalculus', 'natural-numbers']"
4237546,Cauchy surface for sphere,"If we have a Lorentzian manifold $\mathbb{R} \times S^n$ with metric $g= -dt^2 + ds^n$ where $ds^n$ is just the standard round metric for spheres. Does this manifold have a Cauchy surface, i.e. is it globally hyperbolic? And if so what is the Cauchy surface?
Basically that would mean that the Cauchy surface is homeomorphic to $S^n$ . I think that means that there exists no Cauchy surface but I am not sure.","['semi-riemannian-geometry', 'differential-geometry']"
4237564,Proving that the entire function which satisfies a given property is unique,"Let $\phi : \mathbb{C} \to \mathbb{C}$ be an entire function satisfying the following three properties: $|\phi'(z)| \leq |\phi(z)|$ for all $z \in \mathbb{C}$ $\phi(0) = 2$ $\phi(1) = 1$ The problem I'm working on says to show that (a) $\phi$ never vanishes, and (b) that $\phi$ is uniquely determined by these properties. I was able to prove (a) using the Argument Principle, and was able to find a function that satisfied all these properties, namely $\phi(z) = 2 e^{- (\ln 2) z}$ . I'm stuck on how to prove that this is the only solution, and would appreciate help, because I'm at a loss.","['complex-analysis', 'entire-functions']"
4237645,Why can we just replace $z$ by $ z^2$ in this Taylor expansion?,"When we expand $\sin(z^2)$ , we can apparently just replace $z$ by $z^2$ in the Taylor series obtained by expanding $\sin(z)$ . I can't see why. I mean, we can see that the derivatives of $\sin(z^2)$ will be a messy, with a lot of cos and sin, what make us conclude that just to replace $z²$ is enough to get the right series? The same thing goes to any Taylor series? I mean, if $f(x) = \sum x^n f^{(n)}(0)/n!$ , when can we conclude that $f(x^2) = \sum x^{2n} f^{(n)}(0)/n!$ ?","['calculus', 'taylor-expansion']"
4237646,"Does $\frac{\overline X - \mu}{S/\sqrt n}$ converge to $N(0,1)$?","Suppose that $X_1,...,X_n,...$ are i.i.d. with $EX_i = \mu < \infty$ and $Var X_i = \sigma^2 < \infty$ . Now, I know that by the Central Limit Theorem that $$
\frac{\overline X - \mu}{\sigma/\sqrt n} \rightharpoonup N(0,1).
$$ Now, suppose that instead of the actual $\sigma^2$ , I use the sample standard deviation $S^2 = \sum^n_{i=1}\frac{(X_i-\overline X)^2}{n-1}$ . Thus, is it true that $$
\frac{\overline X - \mu}{S/\sqrt n} \rightharpoonup N(0,1).
$$ My intuition is that this is true, but surprisingly I was not able to find easily anywhere. Sorry if this is a silly question. [","['statistics', 'probability-theory', 'weak-convergence', 'normal-distribution']"
4237653,Hartshorne Chapter IV Exercise 5.2,"If $X$ is a curve of genus $ \geq 2$ over a field of characteristic $0$ , show that the group $\operatorname{Aut} X$ of automorphisms of $X$ is finite. Hint: If $X$ is hyperelliptic, use the unique $g_1^2$ and show that $\operatorname{Aut} X$ permutes the ramification points of the $2$ -fold covering $X \to \mathbb{P}^1$ . If $X$ is not hyperelliptic, show that $\operatorname{Aut} X$ permutes the hyperosculation points of the canonical embedding. I have a proof in the case that $X$ is hyperelliptic, but as I am not very familiar with hyperosculation points, I am struggling to prove the non-hyperelliptic case. Could anyone give me a hint regarding that?","['algebraic-curves', 'algebraic-geometry']"
4237690,$A$ Lebesgue measurable iff $\forall\varepsilon>0\ \exists G=\bigcup_{n=1}^{N}I_n$ bounded open intervals: $|A\setminus G|+|G\setminus A|<\varepsilon$,"""Suppose $A\subset\mathbb{R}$ and $|A|<\infty$ . Prove that $A$ is Lebesgue measurable if and only if for every $\varepsilon>0$ there exists a set $G$ that is the union of finitely many disjoint bounded open intervals such that $|A\setminus G|+ |G\setminus A|<\varepsilon$ "" $\Rightarrow$ Since $|A|<\infty$ there must be a sequence of open bounded intervals containing $A$ because if all of the sequences of open intervals containing $A$ all contained at least one unbounded interval then by definition of outer measure we would have $|A|=\infty$ , contradiction. Let now $\varepsilon>0$ : then, among these sequences of open bounded intervals there must be one $I_1,I_2,\dots$ such that $\sum_{n=1}^{\infty}\ell(I_k)\leq |A|+\frac{\varepsilon}{2}$ (if there existed $\bar{\varepsilon}>0$ such that for every bounded sequence of open intervals containing $A$ we had $\sum_{n=1}^{\infty}\ell(I_k)>|A|+\bar{\varepsilon}$ then by taking the $\inf$ of both sides we would have $|A|\geq |A|+\bar{\varepsilon}$ so $\bar{\varepsilon}\leq 0$ , a contradiction). Since $\bigcup_{n=1}^{\infty}I_n$ , being the union of open sets, is an open set, we know that we can write it as the disjoint union of other open intervals $J_n$ , which must thus also be bounded so $\bigcup_{n=1}^{\infty}I_k=\bigcup_{n=1}^{\infty} J_k$ , $\sum_{n=1}^{\infty}\ell(J_k)=|\bigcup_{n=1}^{\infty} J_k|= |\bigcup_{n=1}^{\infty}I_k|<|A|+\frac{\varepsilon}{2}<\infty$ and since $\sum_{n=1}^{\infty}\ell(J_k)$ is convergent there must be $N\geq 1$ such that $\sum_{n=N+1}^{\infty}\ell(J_k)<\frac{\varepsilon}{2}$ thus if we take $G=\bigcup_{n=1}^{N}J_n$ we have $$|A\setminus G|+|G\setminus A|=|A\setminus\bigcup_{n=1}^{N}J_n|+|(\bigcup_{n=1}^{N}J_n)\setminus A|\leq |\bigcup_{n=1}^{\infty}J_n\setminus\bigcup_{n=1}^{N}J_n|+|\bigcup_{n=1}^{\infty}J_n\setminus A|\overset{A\in\mathcal{L},|A|<\infty}{=}|\bigcup_{n=N+1}^{\infty}J_n|+|\bigcup_{n=1}^{\infty}J_n|-|A|<|\bigcup_{n=N+1}^{\infty}J_n|+\frac{\varepsilon}{2}\leq\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon$$ as desired. $\Leftarrow$ By hypothesis we know that for every $n\geq 1$ there exist $j_n$ bounded disjoint open intervals $G_{1_n}, G_{2_n},\dots, G_{j_n}$ such that $G_{n}=\bigcup_{k=1}^{j_n}G_{k_n}$ and $|A\setminus G_n|+|G_n\setminus A|<\frac{1}{n}$ . Consider now $H=\bigcup_{n=1}^{\infty}G_n$ : being the union of open sets it is open hence Borel and we have that $A\setminus H\subset A\setminus G_n$ so $|A\setminus H|\leq |A\setminus G_n|\leq\frac{1}{n}-|G_n\setminus A|\leq\frac{1}{n}$ for every $n\geq 1$ so $|A\setminus H|=0$ \ EDIT 15 September now if I could show that $H\subset A$ I could conclude that $A$ is Lebesgue measurable. One way to do this is to try by contradiction so suppose that $H\setminus A\neq\emptyset$ : now I believe that if $H\setminus A$ contained a countable number of elements we could take them out of $H$ and obtain a Borel set $H'\subset A$ for which $|A\setminus H'|=0$ but what if the number of elements in $H\setminus A$ is uncountable? Would this method still work? DEF. (Lebesgue measurable set)
A set $A\subset\mathbb{R}$ is called Lebesgue measurable if there exists a Borel set $B\subset A$ such that $|A\setminus B|=0$ .","['measure-theory', 'solution-verification', 'lebesgue-measure', 'real-analysis']"
4237700,Why is the Legendre transform (of vector bundles) a smooth morphism $\mathbf FL:E\to E^*$?,"The Legendre transform of convex functions $\mathbb R^n\to\mathbb R^n$ can be given a nice geometric interpretation as a way to characterise a function via the set of the tangent spaces to its graph. The Wikipedia page mentions that this idea can be generalised to define the Legendre transform of smooth functions $L:E\to\mathbb R$ for a generic vector bundle $\pi:E\to M$ with $M$ a smooth manifold.
I'm trying to understand how (or if?) this definition connects with the geometric one mentioned above. In the Wiki page, they define the Legendre transform of $L:E\to \mathbb R$ as the smooth morphism $$\mathbf FL:E\to E^*,$$ such that, for all $v\in E$ , $$\mathbf FL(v) \equiv \mathrm d(L|_{E_x})(v),$$ where $L|_{E_x}:E_x\to\mathbb R$ is the restriction of $L$ to the fiber $E_x$ over $x\in M$ such that $x=\pi(v)$ (so that $v\in E_x$ ).
As pointed out in the Wikipedia page, this means that $$(\mathbf FL(v)) (w) = (\mathrm d(L|_{E_x})(v))(w)
= \partial_t|_0 L(v + tw)\in\mathbb R.$$ There is then some more explanation about what this looks like in local coordinates: $$\mathbf FL(x;v_1,...,v_r) = (x; p_1,...,p_r),
\quad\text{where}\quad p_i = \frac{\partial L}{\partial v_i}(x; v_1,...,v_r).$$ However, I can't see how this relates (if it does at all) to the intuition in the simple case of looking at tangent planes to the graph of the function. Sure, given $f:\mathbb R\to\mathbb R$ , to find $\max_x (px-f(x))$ we compute $p=f'(x_0)$ , but the Legendre transform is then obtained replacing $x_0=x_0(p)$ in $px_0-f(x_0)$ , which we are not doing here at all it looks like.","['legendre-transformation', 'convex-geometry', 'vector-bundles', 'differential-geometry']"
4237702,Is it always true that if $a^2=b$ then $a=\pm\sqrt{b}$?,"Is it always true that if $a^2=b$ then $a=\pm\sqrt{b}$ ? I've seen it stated that if $x^2=k$ then $x=\pm\sqrt{k}$ where k is real, but have not seen the more general case, so I'm wondering if there is a reason why not.
If this is not true generally, what are some counter examples that could be shown on an Algebra 1 level? Edit: A better statement of my original question might be this... It appears that ""if $a=b$ then $a+c=b+c$ "" is universally true
regardless of context. Are there contexts in which $a^2=b$ could not
be equivalently written as $a=\pm\sqrt{b}$ ? Would any such context be
understandable on an Algebra 1 level? Perhaps where still with $a$ and $b$ limited as either complex numbers or expressions with complex
coefficients. Thank you!","['algebra-precalculus', 'radicals']"
4237726,Compute or approximate the mode of a normal distribution with skew parameter $\lambda$. How about for Ashour 2010's approximation?,"I'd like to compute the mode for a normal distribution with skew parameter λ . I assume I can just differentiate, but is there a shortcut or approximation? I'd like to learn how to do this generally, for my own statistical knowledge. But, more pressingly, I'm a developer and I'm writing a program that uses the approximation in Ashour and Abdul-hameed (2010) of a skewed normal. I need to at least approximate the mode for the distribution therein. How could I compute or approximate the mode for an Ashour 2010's approximation?","['statistics', 'normal-distribution']"
4237800,Eigenvalues of $\left[\begin{matrix}1&\epsilon&2\epsilon\\\epsilon&1&2\epsilon\\-2\epsilon&-2\epsilon&2\end{matrix} \right]$ as a series in $\epsilon$,"Consider the matrix $$
M := \left[ \begin{matrix} 1 & \epsilon & 2\epsilon \\ \epsilon & 1 & 2\epsilon \\ -2\epsilon & - 2\epsilon & 2 \end{matrix} \right]
$$ for some small parameter $0 < \epsilon \ll 1$ . My question is how does one solve for the eigenvalues $\lambda$ of this matrix as a series in $\epsilon$ , given that the zeroth-order (with $\epsilon = 0$ ) eigenvalues have degeneracy ? I am more interested in the procedure than anything else here. The eigenvalues are exactly given by $$
\lambda \in \left\{ 1 - \epsilon, \frac{3 + \epsilon - \sqrt{ 1 - 2 \epsilon - 31 \epsilon^2}}{2} , \frac{3 + \epsilon + \sqrt{ 1 - 2 \epsilon - 31 \epsilon^2}}{2} \right\} \ ,
$$ which when expanded for $0  < \epsilon \ll 1$ gives respectively $$
\lambda \in \left\{ 1 - \epsilon, 1 + \epsilon + 8 \epsilon^2 + \mathcal{O}(\epsilon^3)  , 2 -  8\epsilon^2 + \mathcal{O}(\epsilon^3) \right\} \ .
$$ How would one solve for these eigenvalues as a series if it was not possible to solve for the exact eigenvalues? My attempt: Normally what I would do would be to assume I have a series $$
\lambda = \lambda_0 + \epsilon \lambda_1 + \epsilon^2 \lambda_2 + \ldots
$$ and insert this series into the characteristic equation for the matrix which is here $$
\lambda^3 - 4 \lambda^2 + (5 + 7 \epsilon^2) \lambda -2 - 6 \epsilon^2 + 8 \epsilon^3 = 0 \ .
$$ However this method yields nonsense because of the degeneracy of the first two eigenvalues (both being 1) in the limit that $\epsilon = 0$ . To describe what happens: the characteristic equation tells me that $\lambda_0^3 - 4 \lambda_0^2 + 5 \lambda_0 - 2 = 0$ for $\epsilon =0$ , which gives me that $\lambda_0 \in \{1,1,2\}$ . However, at next order in $\epsilon$ in the characteristic equation tells me $5 \lambda_1 - 8 \lambda_0\lambda_1 + 3 \lambda_0^2 \lambda_1 = 0$ , which when evaluated for the degenerate $\lambda_0 = 1$ just says that $0=0$ and so gives no information at all, and so I cannot proceed to find $\lambda_1$ .","['matrices', 'power-series', 'perturbation-theory', 'eigenvalues-eigenvectors']"
4237810,Prove that $\sum_{k=0}^n(-1)^k{n \choose k}\frac{1}{k+m+1}=\sum_{k=0}^m(-1)^k{m \choose k}\frac{1}{k+n+1}$.,"I actually found this question in a calculus exercise, so I thought maybe it is an idea to convert an infinite sum to a Riemannian Integral. But then, I realized that it was missing the $\lim_{n \rightarrow \infty}$ and the $\frac{1}{n}$ (which turns to $dx$ in the limit) I saw in most other types. Heck! it even had two limits in the form of $m$ and $n$ . $$\sum_{k=0}^n(-1)^k{n \choose k}\frac{1}{k+m+1}=\sum_{k=0}^m(-1)^k{m \choose k}\frac{1}{k+n+1}$$ I then tried out at least making the $\frac{k}{n}$ part(which becomes $``x""$ ) and taking a $log$ on both sides(due to it being a factorial which can be converted into a sum of terms in a $log$ ) but then it became utter garbage since no clean expression came out. I am currently back on square 1 now. Please help","['calculus', 'binomial-coefficients', 'combinatorics', 'summation']"
4237818,Minute hand and hour hand interchange,"A person who left home between $4$ p.m. and $5$ p.m. returned between $5$ p.m.
and $6$ p.m. and found that the hands of his watch has exactly changed places. When
did he go out? My attempt : The dial of a clock is divided into $60$ equal divisions. In one hour, the minute
hand makes one complete revolution, i.e., it moves through $60$ divisions and the hour
hand moves through $5$ divisions.
Suppose, when the man went out, the hour hand was $x$ divisions ahead of the point
labeled $12$ on the dial, where $20 < x < 25$ (as he went out between $4$ p.m. and $5$ p.m.).
Also suppose, when the man returned, the hour hand was $y$ divisions ahead of zero
mark and $25 < y < 30$ .
Since the minute hand and hour hand exactly interchanged places during the interval
that the man was out, the minute hand was at y when he went out and at $x$ when he
returned.
Since the minute hand moves $12$ times as fast as the hour hand, we can say that the angle that the minute hand sweeps will be $12$ times that swept by the hour hand. But, I am not able to express this in terms of $x$ and $y$ . Any constructive hint is appreciated.","['algebra-precalculus', 'puzzle']"
4237861,Does $\sum |a_n|b_n $ converge?,"Let $$\sum |a_n|<\infty,\quad \sum b_n<\infty$$ Then $$\sum |a_n|b_n < \infty?$$ I tried to bound this sum, since $0 < a_n < 1 $ for $\forall n>N$ but this wasn't efficient because $b_n$ isn't a positive sequence. Next, I tried to use AM-GM but I don't have $\sum (b_n)^2<\infty$ so I guess I need another approach to prove / disprove this one. Thanks for help","['summation', 'sequences-and-series', 'real-analysis']"
4237930,Strange inequality involving *nested* binomial coefficients and combinatorial interpretation,"Recently, I solved a question that asked for a geometric proof of the identity $\binom{\binom{n}{3}}{2} < \binom{\binom{n}{2}}{3}$ and I did it here using the combinatorial interpretation of lines and triangles in an $n$ -gon, and exploiting the symmetry of these line-triangle configurations to provide an injective (and non-surjective) map from a set with cardinality $\binom{\binom{n}{3}}{2}$ to a set of cardinality $\binom{\binom{n}{2}}{3}$ . This brought me to the more general question : Suppose that $b>c$ . Then, for all $n$ , is the following true? $$\binom{\binom{n}{b}}{c} < \binom{\binom{n}{c}}{b}$$ (Note : we define $\binom{k}{l} = 0$ if $l>k$ ). I want a proof of this, but I've just left some avenues open so that others can explore them below. To break the suspense, this identity is true, but I've actually never seen a proof of it, so here goes. Gamma function I looked here for some details, and apparently a ""lengthy,uninspiring computation involving Gamma functions"" is required.  Nevertheless, I couldn't quite find a reference to this computation : so I'd love one. Having said that , if someone can write up an (lengthy, uninspiring etc.) argument that involves Gamma functions, I'd be delighted. To provide some details on the link, we have : $$
\binom{n}{k} = \frac{n!}{(n-k)!k!} = \frac{\Gamma(n+1)}{\Gamma(n-k+1)\Gamma(k+1)}
$$ and therefore, nested binomial coefficients will involve nested Gamma functions, at which point I wasn't quite able to work my way through. Combinatorial interpretation The same document as above provides a telling combinatorial interpretation : $\binom{\binom{n}{b}}{c}$ is the number of ways of choosing a subset of $c$ elements ,from the set of subsets of $b$ elements of $\{1,2,...,n\}$ . which it then twists into : $\binom{\binom{n}{b}}{c}$ is the number of $b \times c$ matrices with entries in $\{1,...,n\}$ , such that the elements are strictly increasing along rows, and the rows, interpreted as vectors , are strictly lexicographically increasing. So perhaps one can work with these combinatorial objects. On the other hand, one can see if something around what I did with the $n$ -gons can be generalized, I struggled to do so. Short note : binomial basis expansion Note also, that the linear-algebraic approach that I proposed in my answer (to give an algebraic proof of the nested binomial identity) can probably work here (i.e. writing the nested binomial coefficients in the polynomial basis $\binom{n}{k},0<k\leq bc$ ) : but the coefficients when one uses the binomial basis are quite complicated, see here . Note that both the nested binomial coefficients are polynomials of degree $bc$ in $n$ , so one can try to see if something works out via binomial basis expansions. Alternate definitions See if alternate definitions/generalizations of the binomial coefficient are helpful, like this one . Note that if we can make the binomial coefficient into a nice continuous-parameter function, then we can investigate these properties using real analytic methods. EDIT : This document of  Marko Riedel contains details of the Egorychev (Егорычев) method , which is basically a complex-analytic representation of the binomial coefficients. Anyone is free to use any of the identities available here, and I thank Marko for creating this useful list. The basic problem here is the nesting of the coefficients, so any fundamental operation that simplifies the nesting (converting the nesting into an operation that is easier to understand) will be appreciated, either in the comments or as a partial answer. Finally, further comments on inequalities involving further nestings like $\binom{\binom{\binom{n}{a}}{b}}{c}$ and so on will be appreciated as well.","['gamma-function', 'binomial-coefficients', 'linear-algebra', 'combinatorial-proofs']"
4237954,Lebesgue differentiation theorem for Radon measures,"Given any Radon measure $\mu$ on $\mathbb{R}^n$ and locally integrable function $f$ , the generalized version of the Lebesgue differentiation theorem states that $$ \lim_{r \downarrow 0} \frac{1}{\mu(B(x,r))} \int_{B(x,r)} f d \mu = f(x)  \; \; \; \; \mu-a.e   $$ where $B(x,r)$ is a Euclidean ball of radius $r$ . I'm looking for a reference that provides the same statement for balls constructed using other equivalent norms on $ \mathbb{R}^n$ . In particular, when $B(x,r)$ is a ball of radius $r$ with respect to the $ \| . \|_{\infty}$ norm. Edit : Please note that I am looking for a reference that states this for all radon measures.","['reference-request', 'measure-theory', 'functional-analysis', 'real-analysis']"
4237964,Pullback of Riemannian volume form under diffeomorphism,"Let $M$ and $N$ be two oriented Riemann manifold. Let $\varphi:M\to N$ be the orientation preserving diffeomorphism. Prove the Riemann vol form after pull back is given as follows: $$\varphi^*dV_g = dV_{\varphi^* g}$$ Where $g$ is the Riemann metric on $N$ . My attempt: First note that if pick a local orthonormal frame on $N$ as $(E_1,...,E_n)$ then $dV_g(E_1,..,E_n)  = 1$ ,Now we change the frame into $(d\varphi^{-1}(E_1),...,d\varphi^{-1}(E_n))$ then it's again a local frame  on $M$ but not necessarily orthogonal in metric on $M$ but it's orthogonal in metric $\varphi^* g$ hence we have $dV_{\varphi^*g}(d\varphi^{-1}(E_1),...,d\varphi^{-1}(E_n)) = 1$ while $\varphi^*dV_g(d\varphi^{-1}(E_1),...,d\varphi^{-1}(E_n)) = dV_g(E_1,..,E_n)  = 1$ ,since all the oriented orthnormal frame on $(M,\varphi^* g)$ has the form $(d\varphi^{-1}(E_1),...,d\varphi^{-1}(E_n))$ . Hence we have the desired conclusion, Is my proof correct? It's there some better proof?","['manifolds', 'riemannian-geometry', 'differential-geometry']"
4237984,Prove every permutation of the alphabet contains a subset of six letters in order,"Prove that no matter the arrangement of the alphabet you can find a subset of six letters in alphabetical order, read from left to right or right to left. For example the permutation {g,w,z,c,d,p,i,b,y,t,a,n,u,e,r,j,l,x,s,v,m,f,q,k,h,o} contains the subset {a,e,j,l,m,q}. I know I have to construct a partially ordered set and possibly use Dilworth's Theorem, however I don't know how to begin tackling this problem.","['order-theory', 'combinatorics', 'discrete-mathematics']"
4237989,Finding the least point of numerical range which lies on real axis,"Given $A\in\mathbb{C}^{n\times n}$ , its numerical range is $W(A):=\{(\Re (x^*Ax),\Im(x^*Ax)) :x^*x=1\}\subseteq \mathbb{C}^2$ . $W(A)$ is a convex set. An example of $W(A)$ plot is given in the figure below (red line is the boundary of $W(A)$ ). $\hspace{6cm}$ Given $A$ , I want to find the point on the boundary of $W(A)$ , the point which is minimum on the real-axis (blue point on the figure). I think we need to minimize real-coordinate and make a constraint that imaginary-coordinate is zero: \begin{array}{ll} \underset{x\in\mathbb{C}^{n}}{\text{min}} & \Re(x^*Ax)\\ \text{s.t.} & \Im(x^*Ax)=0,\\&x^*x=1.\end{array} Since $\Re(x^*Ax)=\frac{A+A^*}{2}$ and $\Im(x^*Ax)=\frac{A-A^*}{2i}$ , we get this problem \begin{array}{ll} \underset{x\in\mathbb{C}^{n}}{\text{min}} & x^*(\frac{A+A^*}{2})x\qquad=&\underset{x\in\mathbb{C}^{n}}{\text{min}} & \frac{1}{2}(x^*Ax+x^*A^*x)\qquad=&\underset{x\in\mathbb{C}^{n}}{\text{min}} & x^*Ax\\ \text{ s.t.} & x^*(\frac{A-A^*}{2i})x=0,&\text{ s.t.} & x^*Ax=x^*A^*x,&\text{ s.t.} & x^*x=1\\&x^*x=1&&x^*x=1\end{array} But $x^*Ax$ might be complex in general and minimization of $x^*Ax$ is not possible then, I couldn't find where I am doing wrong.","['optimization', 'linear-algebra']"
4238000,Expectation of a random variable which is the minimum of a random variable and a constant,"Given $X \sim exp(\lambda)$ and a constant $c \ge 0$ . Let $Y=\min(X,c)$ .
I would like to find $E[Y]$ and tried looking for possible approaches in link1 and link2 . However, the accepted answers in both URLs give very different results. For example, according to the answer in link1 \begin{align*}
\mathsf E(Y)
 & = \mathsf E(Y\mid X\leq c)\,\mathsf P(X\leq c)+\mathsf E(Y\mid X>c)\,\mathsf P(X> c)
\\
 & = \mathsf E(X\mid X\leq c)\,\mathsf P(X\leq c) +\mathsf E(c\mid X>c)\,\mathsf P(X>c)
\\
 & = \mathsf E(X\mid X\leq c)\,\mathsf P(X\leq c) +c\,\mathsf P(X>c) \\
 & = (1-e^{-\lambda c})\int_0^c t\lambda e^{-\lambda t}dt + ce^{-\lambda c}
\end{align*} and according to the accepted answer in link2 : \begin{align*}
E(Y)&= \int_0^\infty P( Y > t) dt \\
       &= \int_0^\infty P( X > t, c > t) dt \\
       &= \int_0^\infty P( X > t)1\{ c > t\} dt \\
       &= \int_0^c P(X > t)dt \\
       &= \int_0^c e^{-\lambda t}dt
\end{align*} What even confused me more is another direct solution to this problem shown in the second answer in link1 . Which one is correct? Honestly I am not sure how to start with this problem, but the first answer seems to make more sense to me.","['probability-theory', 'probability']"
4238007,"$\iint \sqrt{1-y^2}$ on a disk. Converges and satisfies Fubini, but doing it as an iterated integral diverges?","I am trying to evaluate the integral: $$\iint_D \sqrt{1-y^2} dx dy$$ Where D is the disk centered at $(1, 0)$ and with radius 1. Notice that this integral clearly converges: in the disk, $y^2<1$ , so $|\sqrt{1-y^2}|<1$ . This also means the integral satisfies Fubini. One change of variables $(x, y) \mapsto (x+1, y)$ moves the circle to the origin, and leaves the integrand unchanged. I then change to polar coordinates: $(\rho, \theta) \mapsto (\rho\cos \theta, \rho \sin \theta)$ obtaining: $$ \int_0^{2\pi} \int_0^1 (1-\rho^2\sin^2\theta)^\frac12\rho \ d\rho d\theta $$ I found an antiderivative of the integrand as a function of $\rho$ : $$ -\frac 1 {3\sin^2\theta} (1-\rho^2\sin^2\theta)^\frac32 $$ Evaluating it at $0$ and $1$ reduces the inner integral to the following: $$ \int_0^{2\pi} -\frac 1 {3\sin^2\theta} \left [ (1-\sin^2\theta)^\frac32-1 \right ] d\theta$$ This simplifies to: $$ -\frac {1} 3 \int_0^{2\pi} \frac{\cos^3\theta-1}{\sin^2\theta}d\theta$$ But Wolframalpha says this does not converge. Where did I go wrong?","['multivariable-calculus', 'multiple-integral']"
4238019,Coefficient of $x^{10}$ in $f(f(x))$,"Let $f\left( x \right) = x + {x^2} + {x^4} + {x^8} + {x^{16}} + {x^{32}}+ ..$ , then the coefficient of $x^{10}$ in $f(f(x))$ is _____. My approach is as follow $f\left( {f\left( x \right)} \right) = f\left( x \right) + {\left( {f\left( x \right)} \right)^2} + {\left( {f\left( x \right)} \right)^4} + {\left( {f\left( x \right)} \right)^8} + ..$ Let $T = f\left( x \right);U = {\left( {f\left( x \right)} \right)^2};V = {\left( {f\left( x \right)} \right)^4};W = {\left( {f\left( x \right)} \right)^8}$ Let the coefficient of $x^{10}$ in $T $ is zero Taking U ${\left( {f\left( x \right)} \right)^2} = {\left( {x + {x^2} + {x^4} + {x^8} + ..} \right)^2}$ Hence the coefficient of $x^{10}$ in $U$ is $2x^{10}$ hence $2$ For $V$ and $W$ it is getting complicated hence any short cut or easy method to solve it","['combinatorics', 'polynomials']"
4238033,Calculate the closed form of the following series,"$$\sum_{m=r}^{\infty}\binom{m-1}{r-1}\frac{1}{4^m}$$ The answer given is $$\frac{1}{3^r}$$ I tried expanding the expression so it becomes $$\sum_{m=r}^{\infty}\frac{(m-1)!}{(r-1)!(m-r)!}\frac{1}{4^m}$$ but I do not know how to follow. Any help will be appreciated, thanks.","['calculus', 'binomial-coefficients', 'closed-form', 'summation']"
4238056,If you have $2n$ people how many different ways can you pair them up?,"If you have $2n$ people how many different ways can you pair them up? My method: Considering making pairs like this: Randomly line them up and then pair of the $1^{st}$ person in line with the $2^{nd}$ , the $3^{rd}$ with the $4^{th}$ , ..., the $(2n-1)^{th}$ with the $2n^{th}$ We have $2n!$ ways to line them up. However, this overcounts pairs, a lot. Consider just 6 people. $A,B,C,D,E$ and $F$ . The line $ABCDEF$ gives the same result as the line $BACDEF$ We can flip each person with their partner. He can do this $n$ times so we have overcounted $2^n$ times per order. However, we have still overcounted! Consider again the line $ABCDEF$ this gives the same pairs as $ABEFCD$ We can indeed shuffle the pairs , as long as they remain with their partners in any order! We have $n!$ ways to shuffle the pairs. My final answer is then $\frac{2n!}{2^n n!}$ Is this correct? Is anyone able to give some pointers as to how to use some code to confirm this?  Does someone have a nicer answer?",['combinatorics']
4238102,Approximation of Stirling numbers of the second kind ${2n \brace n}$,"I want an approximation of ${2n \brace n}$ as $n\to\infty$ , also ${\cdot\brace\cdot }$ is the Stirling numbers of the second kind. Right now, I know an evaluation \begin{equation}
{2n \brace n}=O\left(n^n\binom{2n}{n}\right)
\end{equation} holds up, but I don't know an accurate evaluation or approximation. Could you help me finding a good approximation? I would appreciate it if you do!","['limits', 'binomial-coefficients', 'stirling-numbers', 'approximation']"
4238107,For what value(s) of the parameter a is it possible to find explicit formulas ( without integrals),For what value(s) of the parameter a is it possible to find explicit formulas ( without integrals)  for the solution to $$\dfrac {dy}{dt} = aty + e^{-t^2}$$ I tried solving the question by the method of finding the integrating factor of the differential equation of the form $dy/dt + P(t)y = Q(t)$ but could not reach any conclusion as I was unable to solve the integral. Plus the question says no integrals are to be used. now I am clueless. Kindly help me.,['ordinary-differential-equations']
4238120,Combined Proportions,"I've been taking an ODE course and a word problem involved some quantity $x$ being directly and inversely proportional to others. I recall it said something like: $x$ is directly proportional to $y$ and $z$ and inversely proportional to $t$ . I didn't really paused and ponder that the appropriate formula for $x$ was $x = k\dfrac{yz}{t}$ , for some $k \in \mathbb{R}$ . I assumed that this proportionality took place whenever the other variables were held constant. However, today I wanted to, step by step, get to the formula given above. Writing all definitions: $x = a\cdot y$ , $x = b \cdot z$ and $x = \dfrac{c}{t}$ . But I wasn't able to get to that formula! I'm stuck. Can anyone shed some light on this problem?","['algebra-precalculus', 'ordinary-differential-equations']"
4238139,Central limit theorem for randon variables with exponentially decaying covariance,"Let $X_1,X_2,...$ be i.i.d. bounded random variables with $\mathbb{E}[X]=0$ . In addition, let $C_1,C_2>0$ and $\{d_{i,j}\}_{i,j\in \mathbb{N}}$ such that $$d_{i,j} = C_1e^{-C_2|i-j|} $$ Now, define $$Y_n = \sum_{j=1}^n d_{n,j} X_n\cdot X_j $$ Does $$\frac{Y_1+...+Y_n}{\sqrt{n}} \overset{d}{\longrightarrow} N(0,\sigma^2)?$$ Generally the exponential decay of the covariance of the $Y_i$ is not enough. However, I think that for this type of random variable it should work, but not sure how to prove it. Thanks!","['probability-limit-theorems', 'central-limit-theorem', 'covariance', 'probability-theory', 'probability']"
4238184,A morphism $S' \to S$ is a morphism of descent for $(Sch \to Sch)$ iff it is a universal effective epimorphism for $(Sch)$?,"In SGA 1, VIII there is the following theorem (roughly translated by me) Theorem 5.2 Let $\mathcal F$ be the fibred category of arrows over the category of schemes (i.e. objects are morphisms $X \to S$ and morphisms are commutative squares). If $g: S' \to S$ is a fpqc morphism, then $g$ is a morphism of descent for $\mathcal F$ . This means that for any $X, Y \in \operatorname{Sch}/S$ , the diagram $$\DeclareMathOperator{\Hom}{Hom} \Hom_S(X,Y) \to \Hom_{S'}(X', Y') \rightrightarrows \Hom_{S''}(X'', Y'')$$ is an equalizer diagram (where $X' = X \times_S S'$ , $S'' = S' \times_S S'$ , $X'' = X \times_S S''$ and similarly for $Y$ ). Then Grothendieck writes that according to Giraud [D], Theorem 5.2 is equivalent to Corollary 5.3 Any fpqc morphism is a universal effective epimorphism. The proof of the later statement can be found in the stacks project, 023P (assuming the definitions are the same). However I don't know about the equivalence of Theorem 5.2 and Corollary 5.3, and didn't find anything from skimming Giraud. Is that easy, or covered somewhere in the stacks project? [D] J. Giraud, Méthode de la descente , 1964","['descent', 'algebraic-geometry']"
4238197,A Function to Generate Pythagorean Triples,"For a given right triangle $ABC$ with hypotenuse $C$ , if you know that value of one of the legs, such as $B$ , you can calculate possible values for the other two sides by using the equation $""\dfrac{B^2}4\pm1""$ . For example, if you are given the value of $4$ , solving would proceed as follows: $4^2 = 16; \dfrac{16}4 = 4$ ; and $4\pm1 = 3,5$ giving the other two sides lengths. This becomes the well-know $3,4,5$ Pythagorean triple. This equation will work for any value of A, and will give whole number outputs for any even number. For odd numbers, there is the slightly different equation "" $\dfrac{(B^2)\pm1}{2}$ "". I am currently unaware of how to derive these equations, and knowing how would be most helpful. Edit: The odd equation will work for any given number due to the following: (note that a very similar evaluation will work for the even version of the equation) ${A^2}+{B^2}={C^2}$ , $A=\dfrac{(B^2)-1}{2}$ , $C=\dfrac{(B^2)+1}{2}$ . These are all given as they are part of the function. ${(\dfrac{{B^2}-1}{2})^2}+{B^2}={(\dfrac{{B^2}+1}{2})^2}$ by substituting for $A$ and $C$ . ${\dfrac{{B^4}-2{B^2}+1}4}+{B^2}={\dfrac{{B^4}+2{B^2}+1}4}$ by squaring $A$ and $C$ . ${B^4}-2{B^2}+1+4{B^2}={B^4}+2{B^2}+1$ by multiplying everything by $4$ . $-2{B^2}+4{B^2}=2{B^2}$ with some cancelling. $1=1$ or $0=0$ through more cancelling. Therefore, any value of $B$ will make the equation true. The reason that it works best with odd whole numbers is because ""odd"" $*$ ""odd"" $=$ ""odd"",  ""odd"" $\pm1=$ ""even"", and only even numbers leave whole values when halved. Update: One of the comments asked if this equation could be modified for other values of $C-A$ . After some thought, I have found a family of equations capable of producing triples with any value of $C-A$ . Let's assume that $C-A=2x$ . There is a number $\theta$ whose value is halfway between $C$ and $A$ , so therefore $A=\theta -x$ , and $C=\theta +x$ Substituting these values into ${A^2}+{B^2}={C^2}$ gives us the following: ${(\theta-x)^2}+{B^2}={(\theta+x)^2}$ ${B^2}+{\theta^2}-2\theta x+{x^2}={\theta^2}+2\theta x+{x^2}$ ${B^2}=4\theta x$ $\theta ={\dfrac{B^2}{4x}}$ Because $B=\theta -x$ and $C=\theta +x$ : $B={\dfrac{A^2}{4x}}-x$ $C={\dfrac{A^2}{4x}}+x$ If $C-A=2$ , then $x=1$ , and the equation simplifies to "" $\dfrac{B^2}4\pm1$ "". Other values of x will work as well. For $C-A=3$ , $x=1.5$ , and the new equation is "" $\dfrac{B^2}6\pm1.5$ "" This equation produces integers when $B$ is an odd multiple of $3$ . A similar process to the one above can be worked out for any other value of $x$ .","['pythagorean-triples', 'real-analysis', 'trigonometry', 'triangles', 'algebra-precalculus']"
4238241,An Intriguing Question on Hyperbola!,"Let tangents $PA$ and $PB$ on hyperbola from any point $P$ on the Director Circle of hyperbola such that $d(P,AB).d(C,AB)=4d(S_1,PA).d(S_2,PA)$ and $|AS_1-AS_2|=4$ where $d(P,AB)$ denotes distance of point $P$ to the line $AB$ and $S_1$ and $S_2$ are the foci and $C$ is centre of the hyperbola. If asymptotes of hyperbola pass through the point $(1,2)$ and a line $y=4$ intersects the branch of hyperbola  which lies entirely on the first quadrant only at a point then find the length of traverse axis of the hyperbola and its equation. This is originally a question i had encountered in a test I had given, and i do know however that the director circle is the circle from which  a pair of perpendicular tangents can be drawn and from  the question it becomes clear that $2a=4$ but I am unable to make any use of the equation $d(P,AB).d(C,AB)=4d(S_1,PA).d(S_2,PA)$ maybe it is some property of hyperbola I am unaware of, in the given 'solution' they had directly stated the value of $b$ (of hyperbola) but I have no idea how they got that and I would highly appreciate any help with this question as it had been bugging me for quite a while now, thanks!","['euclidean-geometry', 'geometry']"
4238245,Is it true that $f'(\xi_1)(\xi_1-a)+f'(\xi_2)(\xi_2-b)+f(a)+f(b)=0$ if some conditions are met?,"Problem : if function $f$ is continuous on the closed interval $[a,b]$ and differentiable on the open interval $(a,b)$ , and $$\int_a^b f(x)dx=0$$ Prove that there exists two distinct real numbers $\xi_1,\xi_2\in(a,b)$ such that $$f'(\xi_1)(\xi_1-a)+f'(\xi_2)(\xi_2-b)+f(a)+f(b)=0$$ I suspect I should use some sort of mean value theorem to prove this problem, but I tried all forms of the theorem listed on the Wikipedia page without any success. I am beginning to suspect this problem might be wrong and am looking for counter-example. Any help from you is greatly appreciated!","['calculus', 'examples-counterexamples']"
4238259,What is the value of the $MC$ segment in the figure below?,"For reference : In the figure, $F. M , G , H$ are points of tangency. What is the value of the $MC$ segment if $AF = 4, BF = 6~ and~ AM = 8$ ? My progress: I couldn't see almost any information... I only know that by property FH = MG",['geometry']
4238263,Fractional calculus and spectral theory,"I've been trying to build a more solid understanding of fractional calculus, and the closer I look, the more it seems like there are some deep connections to Fourier analysis (and spectral theory in general) that I can't quite make out. Consider the following thought experiment: We can consider the identity operator to be the limit of a sequence of gaussians in a convolution algebra.  Similarly, we can consider the differential operator $D$ to be the limit of a sequence of derivatives of gaussians .  These give us a pretty solid basis for visualizing what these operators look like (graphics courtesy of wikipedia): When we extend to fractional operators, we obtain a continuous interpolation between these two: As the order increases past $1$ , more peaks emerge.  Notice that this is beginning to look an awful lot like a wavelet basis... Now, these operators act convolutionally - so, given some function $f$ in the convolution algebra, we can consider $f'(t) = \langle D,(x \to f(x-t)) \rangle$ .  In particular, we can consider $f^{(a)}(0) = \langle D^a,f \rangle$ . This notation seems highly suggestive - we have an indexed family of operators ( $D^a$ ), and a continuous function defined by their action (via the inner product) on a given reference function.
When we do this same thing with sinusoids, we get a Fourier transform.  Does this yield anything similar? Viewed another way: when we only look at derivatives of discrete order, this kind of expansion yields a power series.  If fractional calculus allows us to look at derivatives of continuous order, can we generalize a power series to some sort of continuous spectrum, in the same way we generalize from a discrete Fourier series to a continuous Fourier transform? And is there anything behind apparent similarity to wavelet transforms? I realize this question is pretty vague, but any guidance would be appreciated.","['soft-question', 'functional-analysis', 'fractional-calculus']"
4238270,Is my proof of $\overline{A \cup B}= \overline{A} \cup \overline{B} $ correct?,"I am trying to proof $\overline{A \cup B}= \overline{A} \cup \overline{B} $ , where $\overline{A}$ is the topological closure of A.
I did some thinking and I came up with this.
My Question is: Is my proof correct? First I am trying to proof $\overline{A \cup B} \subseteq \overline{A} \cup \overline{B}$ Let $x \in \overline{A \cup B}=(\cap_{A \cup B \subseteq P, P closed}P)$ For every P that statisfies the condition below the cap $x$ is in P. Furthermore $A \subseteq \overline{A}$ and $B \subseteq \overline{B}$ , as result we get $A \cup B \subseteq \overline{A} \cup \overline{B}$ .
As union of two closed sets $\overline{A} \cup \overline{B}$ is obviously closed. So the condition for P is statisfied and as consequence $x \in \overline{A} \cup \overline{B}$ The Second direction is: $\overline{A} \cup \overline{B} \subseteq \overline{A \cup B}$ Let $x \in \overline{A} \cup \overline{B}$ , without loss of generality let $x \in \overline{A}=(\cap_{A \subseteq P, P closed}P)$ This means x is in every P  that statisfies A $\subseteq$ P and P is closed. $\overline{A \cup B}:=(\cap_{A \cup B \subseteq H, H closed}H)$ trivially $A \subseteq A \cup B$ , so if $A \cup B$ is a subset of a set $H$ that is closed, so is $A$ , which means that all $H$ satisfy the conditions for $P$ . This means $x \in H$ for all $H$ that satisfies $A \cup B \subseteq H$ , $H$ closed. So as a result $x \in  \overline{A \cup B}$",['general-topology']
4238283,How to solve a limit that can be factored but doesn't help?,"I saw examples that can be factored, eliminating the part that causes the indetermination, none of this type. The other option is by rationalize but dont know how to apply it here. $$\lim_{x \to 4} \frac{2x^2+7x+5}{x^2-16}$$ I tried by factoring, doesn't help $$\lim_{x \rightarrow 4} \frac{(2x+5)(x+1)}{(x-4)(x+4)} \\$$ UPDATE : I make a mistake, the numerator is ${2x^2+7x+5}$ not ${x^2+7x+5}$ , really sorry.",['limits']
4238297,Weird generalization of disconnected topological spaces,"I'm learning about connected topological spaces, and i came up with a related question i'm not able to answer. To make things simpler, i'm going to give some definitions. Let $X$ be a topological space. For a positive integer $n \in \mathbb{N}$ , $n \geq 2$ we say that $X$ is $n$ -separated if there exist non empty and pairwise disjoint open subsets $U_1, ..., U_n \subset X$ such that $X = U_1 \cup \cdot \cdot \cdot \cup U_n$ , furthermore, we say that $X$ is countably separated if there exists a sequence $\{ U_n \}_{n=1}^\infty$ of non empty pairwise disjoint open subsets of $X$ such that $X = \cup_{i=1}^\infty U_i$ . It's obvious that if a topological space is countably separated then it is $n$ -separated for all $n \geq 2$ . Now i'm trying to understand if the converse is true. The only thing i was able to notice is that if a topological space is $n$ -separated for all $n \geq 2$ , then it has infinitely many connected components. Indeed, suppose by contradiction that $C_1, ..., C_m \subseteq X$ are all the connected components of $X$ , for some $m \in \mathbb{N}$ , $m \geq 1$ . By definition there are non empty and pairwise disjoint open subsets $U_1, ..., U_{m+1} \subseteq X$ such that $X = \cup_{i=1}^{m+1} U_i$ . Notice that each $C_i$ is contained in one of the $U_j 's$ (Suppose by contradiction that $C_i$ intersects more than one of the $U_j$ 's. Without loss of generality we can reorder the $U_j$ 's and suppose that there is an $1 < r \leq m+1$ such that $C_i$ intersects $U_1, ..., U_r$ and doesn't intersect $U_j$ for $j > r$ . This means that $C_i = C_i \cap (U_1 \cup U_2 \cup \cdot \cdot \cdot \cup U_r) = (C_i \cap U_1) \cup (C_i \cap (U_2 \cup \cdot \cdot \cdot \cup U_r))$ , in contradiction with the fact that $C_i$ is connected) and therefore, because $m + 1 > m$ , this implies that at least one of the $U_i$ 's is empty. Contradiction.","['general-topology', 'connectedness']"
4238314,Why does Solving system of quadratic equations gives extra roots?,"Consider these system of Equations \begin{align*}
\begin{cases}
x^2+4x+4=0\\\\
x^2+5x+6=0
\end{cases}
\end{align*} For solving them
We have Method 1- Subtract both equations So $-x-2=0$ Hence, $x=-2$ Method-2 Add both equations $2x^2+9x+10=0$ After applying quadratic formula, we get $x=-2$ or $x=-5/2$ . But only $x=-2$ satisfies the system of equation. Why is the $-5/2$ not satisfying the system of equations, what is intuition behind the error in method 2?","['algebra-precalculus', 'systems-of-equations', 'quadratics']"
4238362,Help understanding the proof of $A^\circ \cap B^\circ = (A\cap B)^\circ $ in a topology text,"So $(A \cap B)^{\circ}=A^{\circ} \cap B^{\circ}$ . I was reading the following proof: I need help understanding the second part. I don't know if it's a typo, but it seems to me that the conclusion $(A\cap B)^{\circ} \subseteq A^{\circ} \cap B^{\circ}$ is reached both times and that doesn't complete the result.","['elementary-set-theory', 'general-topology']"
4238388,Is a product of $p$-subgroups still a $p$-subgroup?,"A $p$ -group is a group in which every element has order a power of $p$ . Let $G$ be a group, and let $P$ and $Q$ be $p$ -subgroups of $G$ . Suppose that the product $PQ$ is a subgroup of $G$ (equivalently, $PQ=QP$ ). Is $PQ$ necessarily a $p$ -subgroup of $G$ ? If $P$ and $Q$ are finite then the answer is yes, because $\lvert PQ\rvert=\lvert P\rvert\cdot\lvert Q\rvert/\lvert P\cap Q\rvert$ is a power of $p$ . If $P\leq N_G(Q)$ (or vice versa), then the answer is yes. Proof : Let $a\in P$ and $b\in Q$ .
If $a^{p^k}=1$ , then \begin{align*}
(ab)^{p^k}&=a^{p^k}(a^{-(p^k-1)}ba^{p^k-1})(a^{-(p^k-2)}ba^{p^k-2})\cdots(a^{-2}ba^2)(a^{-1}ba)b\\
&=(a^{-(p^k-1)}ba^{p^k-1})(a^{-(p^k-2)}ba^{p^k-2})\cdots(a^{-2}ba^2)(a^{-1}ba)b\in B,
\end{align*} so $(ab)^{p^k}$ has order a power of $p$ , which shows that $ab$ has order a power of $p$ . Alternative Proof (thanks to David Craven): Note that $Q\trianglelefteq PQ$ , where the quotient group $PQ/Q\cong P/(P\cap Q)$ is a $p$ -group. Let $g\in PQ$ .
Then $gQ\in PQ/Q$ , so $Q=(gQ)^{p^k}=g^{p^k}Q$ for some $k$ .
Then $g^{p^k}\in Q$ , so $1=(g^{p^k})^{p^j}=g^{p^{k+j}}$ for some $j$ .","['group-theory', 'p-groups']"
4238487,Log-sum-exp is the conjugate of relative entropy: a quick proof,"Let $(\Omega, \mathcal A, dm)$ be a measure space. For measurable functions $f\colon \Omega\to \mathbb R$ such that $\exp(f)$ is integrable, and for $\rho>0$ such that $\int \rho\, dm=1$ , we define $$
L(f)=\log\int_\Omega e^{f}\, dm,\quad \text{and}\  \quad H(\rho)=\int_{\Omega} \rho\log\rho\, dm. $$ These two functionals satisfy the Legendre-Fenchel inequality $$\tag{1}
\int_\Omega f\rho\, dm\le L(f)+H(\rho), $$ with equality if $e^f=C\rho$ for some $C>0$ . Question . Is there a direct proof of (1) based on the Jensen inequality? In the first page of this paper , J.Lehec suggest that this is ""easily seen"" to be the case. This answer seems to be strictly related, and it does contain a proof of (1). However, I wonder if there is a ""one-line"" proof of (1), one that does not need to introduce a lot of definitions. I can prove (1) by means of the variational calculus. Namely, I can prove that $$\tag{2}
H(\rho)=\max_{\exp(f)\in L^1} \left( \int_{\Omega} f\rho\, dm - L(f)\right).$$ (This is essentially the same computation that I find, for example, in this question , concerning the finite-dimensional case). For a bounded $g$ , we let $f=f_\star+\epsilon g$ in the term in brackets in (2), noting that $\exp(f_\star +\epsilon g)\in L^1$ if $\exp(f_\star)\in L^1$ (that is, $g$ is an admissible variation). We differentiate in $\epsilon$ , then set $\epsilon=0$ , inferring that $f_\star$ is a critical point if and only if $$
\int_\Omega g\rho\, dm = \frac{\int_\Omega e^{f_\star} g\,dm}{\int_\Omega e^{f_\star}\, dm}, \quad \forall g\in L^\infty(\Omega).$$ We immediately see that $f_\star=\log \rho$ is a critical point (not unique), and since $L$ is convex, the functional to maximize in (2) is concave, hence all critical points are maximizers. $^{[1]}$ Thus, plugging $f=f_\star$ in (2) we conclude the proof. [1] This might need to restrict the domain of $L$ , since $\{f\,:\,\exp(f)\in L^1\}$ is not a vector space. EDIT : As Olivier Diaz points out in the comments, this domain is a convex set. This is a consequence of the Hölder inequality. Therefore, it is true that critical points are maximizers, as stated above.","['legendre-transformation', 'measure-theory', 'entropy', 'convex-analysis', 'probability-theory']"
4238501,Meaning of derivative of function by absolute value: $\frac{d}{d|x|} f(|x|)$,What does the following Leibniz's notation of derivative mean? $$\frac{d}{d|x|} f(|x|)$$ $f(|x|)$ is a function of absolute value of variable x . I am OK with this notation and I know how to treat it: $$\frac{d}{dx} f(|x|)$$ What is the difference between those two?,"['notation', 'derivatives']"
