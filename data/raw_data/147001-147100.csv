question_id,title,body,tags
2411314,Average size of symmetric differences of measurable sets,"Let $E\subset [0,1]$ be any measurable set.  I am interested in expressions of the form
$$
I_t = \frac{1}{t} \int_0^t |E\,\Delta\, (E+s)| \,ds,
$$
and in particular of the behavior as $t\to 0$.  My question is Are there better bounds available on $I_t$ than simply $I_t > 0$?  In particular, if $E$ is known to be a set of infinite perimeter, does it follow that $I_t = \omega(t)$? If $E$ has finite perimeter, I already know that it is equivalent to a union of finitely many intervals, and $I_t = \Theta(t)$.  The real question is about the behavior of general measurable sets.  One can construct sets for which there is a lot of cancellation for particular choices of $s$, but since this asks about averaged information I hope that better bounds might be available.","['geometric-measure-theory', 'real-analysis', 'measure-theory']"
2411337,Am I solving Dido's isoperimetric (variational) problem correctly?,"I am trying to solve Dido's isoperimetric problem, more specifically, the version where we have to maximize the area under a curve, given that the two endpoints are on the x-axis, and given a fixed arclength: That is, we have to maximize $$J(y)=\int_a^by(x)dx$$ subject to constraint $$C(y)=\int_a^b\sqrt{1+(y'(x))^2}dx$$ Where we assume $a$ is fixed, but $b$ is allowed to vary. Am I solving this correctly? Besides the boundary constraint (because of variable boundary $b$ ) $L_{y'}(b)=0$ , we of course formulate the Euler-Lagrange equation $L_y=\frac d {dx}L_{y'}$ , based on $J$ subject to the constraint $C$ , so that the Lagrangian becomes: $$L(y,y')=y(x)+\lambda\sqrt{1+(y'(x))^2}$$ Therefore: $$L_y=1$$ $$L_{y'}=\lambda \frac {y'(x)} {\sqrt{1+(y'(x))^2}}$$ $$\frac d {dx} L_{y'}=\lambda y''(x)\left(\frac {1} {\sqrt{1+(y'(x))^2}}-\frac {(y'(x))^2}{\left (1+(y'(x))^2\right)^{\frac 3 2}}\right)$$ which is equal to $$\frac d {dx} L_{y'}=\lambda y''(x)\left(\frac {1}{\left (1+(y'(x))^2\right)^{\frac 3 2}}\right)$$ This gives the Euler-Lagrange equation $$\lambda
y''(x)=\left (1+(y'(x))^2\right)^{\frac 3 2}$$ I have no idea how to solve this ODE, and moreover, it doesn't seem like this is what I should be getting. Did I derive this result correctly? If so, How do I solve it? note: I know that it is also possible to solve by parameterizing $x=x(t), y(x)=y(x(t))$ . I want to do this as well, later, but I would first like to understand the approach I'm taking here.","['euler-lagrange-equation', 'calculus-of-variations', 'ordinary-differential-equations']"
2411354,Monotonicity of $f(x) =\sin(\ln(x))-\cos(\ln(x))$,"Find the interval in which $f(x) =\sin(\ln(x))-\cos(\ln(x))$ is increasing. 
After differentiating we get $$f'(x) = \frac{\cos\left(\ln(x)\right)}{x} +\frac{\sin\left(\ln(x)\right)}{x}$$
Now how do we analyze this expression?",['derivatives']
2411414,complex polynom roots precision,"i am interested in finding roots of complex polynoms (with complex coefficients). i found that if the polynom has degenerate (multiple) root(s) then such algorithms like Newton and Durand-Kerner ones do not lead to the convergent results (simply speaking, the convergence is bad). does anyone in forum knows an algorithm to increase the accuracy (precision) of finding the degenerate roots (for the general case of complex polynoms) ? Thanks.","['complex-analysis', 'numerical-methods', 'polynomials', 'roots']"
2411428,How to maximise this quantity?(probably related to mutual information),"Suppose I have a $n\times n$ matrix $X$ such that all its entries sum up to 1 and all entries are non-negative. Then, I have to maximize this quantity:
$$\sum_{i=1}^n\sum_{j=1}^n \left|x_{ij}-\left(\sum_{k=1}^{n}x_{ik}\right)\cdot\left(\sum_{k=1}^{n}x_{kj}\right)\right|$$. So, I think this should be achieved when $X$ is diagonal, but I don't have a concrete argument. I don't really know how to start with this. This is a homework problem and might be related to quadratic mutual information. I am thankful for any hints or solutions.","['multivariable-calculus', 'statistics', 'information-theory', 'linear-algebra']"
2411455,Defining interpolation spaces of Hilbert spaces using domains of unbounded operators,"This comes from the book Non-Homogeneous Boundary Value Problems and Applications I by Lions and Magenes, section 2.1. Let $X\subset Y$ be a dense continuous injection of separable complex Hilbert spaces. We will define a strictly positive self-adjoint densely-defined unbounded operator $S$ in $Y$ as follows. Let $D(S)$ denote those $x\in X\subset Y$ such that $$X\to\Bbb C,\quad v\mapsto\langle u,v\rangle_X$$ is continuous w.r.t. the topology on $X$ induced by $Y$. Then we may define an operator $S:D(S)\to Y$ by setting $$\langle u,v\rangle_X=\langle Su,v\rangle_Y$$ for all $v\in X$, which uniquely defines $Su$ by density. Now, the authors state the following (without proof or explanation): Proposition For $S$ defined as such, $D(S)$ is dense in $Y$, and furthermore that $S$ is self-adjoint. Using the spectral theorem for unbounded self-adjoint operators, if we set $\Lambda=S^{1/2}$, then $D(\Lambda)=X$. However, I haven't managed to figure out the proof of any of these claims. For  general background, we have the following equivalence. We say that a densely-defined unbounded operator $S:D(S)\to Y$ on $Y$ is symmetric if it is closable and $\langle Su,v\rangle_Y=\langle u,Sv\rangle_Y$ for all $u,v\in D(S)$. Then for any symmetric operator $S$, the following are equivalent. The operator $S$ is self-adjoint. The operator $S$ is closed, and $\ker(S\pm i)=0$ as subspaces of $D(S)$. We have $\operatorname{im}(S\pm i)=Y$ where the image is of $D(S)$. Equivalently, we may replace $i,-i$ above with $\lambda,\bar\lambda$ for any strictly complex $\lambda$. Now, assuming that $D(S)\subset Y$ is dense and $S$ is closable, I see that $S$ is symmetric. Furthermore, for any $v\in D(S)$, we have that $$\langle Sv,v\rangle_Y=\lVert v\rVert_X\ge C\lVert v\rVert_Y$$ for some fixed $C>0$. This tells us that $S$ is injective, and furthermore that is $S$ if closed, then it is self-adjoint, since for any $\lambda\in\Bbb C\setminus\Bbb R$ with $|\lambda|<C$, if $Sv=\lambda v$ then $$0=|\langle Sv,v\rangle_Y-\langle\lambda v,v\rangle_Y|\ge C\lVert c\rVert_Y-|\lambda|\lVert v\rVert_Y$$ so that $v=0$. However, showing that $S$ is closed or even closable is beyond me. Any help with approaching a proof of the proposition would be greatly appreciated.","['hilbert-spaces', 'partial-differential-equations', 'operator-theory', 'functional-analysis', 'spectral-theory']"
2411487,How to calculate the second derivative of the determinant?,"I am working on the following question and have managed to do most of it but unfortunately I am getting stuck on the last bit. I think part of my confusion lies with calculating second determinants (which are linear maps to a space of linear maps) of matrices (which are themselves linear maps). This is the question: Let $V = M_{n×n}(\mathbb{R})$ . By considering $\det(I + A)$ as a polynomial in the entries of $A$ , show that the function $\det : V → \mathbb{R}$ is differentiable at the identity matrix $I$ and that
its derivative there is the function $A → \text{tr} A$ . Hence show that $\det$ is differentiable at any
invertible matrix $X$ , with derivative $A → \det X \text{tr}(X^{−1}A)$ . Compute the second derivative
of det at $I$ as a bilinear map $V × V → \mathbb{R}$ , and verify it is symmetric. I have done everything except for the last bit. However whatever I try for the last bit is not fruitful. I know that the second derivative at $I$ is a bilinear form whose matrix has as its entries the values of the second partial derivatives $D_{ij}(I)$ but I don't see how to compute the second partial derivatives. I know what the first partial derivatives are though as I worked them out for the first part of the question (at $I$ they are the trace of the matrix that represents the $i^{th}$ basis vector). I also see how we can view the partial derivative as a function of $X$ but I don't see how to extend that to work out the limit $D_{ij}f(I) = \lim\limits_{t \to 0} \frac{D_{\mathbf{e}_j}f(I+t\mathbf{e}_i)-D_{\mathbf{e}_j}f(I)}{t}$ I don't think the solution to the first bit is important for the last part so I am not posting it up, however if you wish to see it please let me know and I will add it. Thanks for all your help.","['matrices', 'multivariable-calculus', 'analysis', 'derivatives']"
2411505,Bayesian statistics - finding a posterior distribution,"Suppose the number of sales, N, in a year on a sales portfolio has a
  poisson distribution with parameter $\lambda$. Sales are either large
  with probability $p$ or small with probability $1-p$, independently
  from each other. Suppose we observer $r$ large sales. Show that the conditional
  distribution of $N - r \mid r$ is poisson. I've managed to complete the question from first principles: Let $R$ be the number of large sales, we have $ R \mid N$ is binomially distributed with parameters $N$ and $p$. If we consider $P(N - r = s \mid R = r)$ and apply Bayes conditional probability formula we eventually get the result. I am wondering if there is perhaps a simplier way to do it? For instance, could we perhaps just directly use the the result that, $$ \text{ Posterior PDF } \propto \text{Prior PDF } \times \text{ Likelihood}$$ that is, $$f(\theta \mid x) \propto f(\theta) \times L(x \mid \theta)$$ Can this general formula be applied in this case as a shortcut?","['bayesian', 'statistics', 'probability']"
2411506,When does the $f^{(n)}$ converge to a limit function as $n\to\infty$?,"(This was something someone (almost) asked in a comment in a thread about repeated differentiation of polynomials.) Consider a general smooth (that is $C^\infty$) function $f$. As usual $f^{(n)}$ denotes the $n$th derivative of $f$. Under what circumstance does $\{ f^{(n)} \}_{n=1}^\infty$ converge to a limit function as $n$ goes to infinity? For example when $0<k<1$ is fixed and $f(x)=e^{kx}$, then we have the pointwise convergence $f^{(n)} \to 0$ for $n\to\infty$ where $0$ is the zero function. The case $k=1$ is different. Of course when $f(x)=\cos x$, there is no convergence of the $f^{(n)}$. But $\cos(kx)$ ... Can a criterion be given?","['derivatives', 'convergence-divergence', 'functions', 'limits']"
2411538,"$\{a+b|a,b\in\mathbb N^+\wedge ma^2+nb^2\in\mathbb P\}=\{k>1|\gcd(k,m+n)=1\}$","Conjecture: $\{a+b|a,b\in\mathbb N^+\wedge ma^2+nb^2\in\mathbb P^{>2}\}=\{k>2|\gcd(k,m+n)=1\}$ 
if $m,n\in \mathbb N^+$ and $\gcd(m,n)=1$. This is a generalization of Any odd number is of form $a+b$ where $a^2+b^2$ is prime . Perhaps the generalization will spread some light of what is going on? There is a perfect match of the formula for all tests I've done. https://mathoverflow.net/questions/280123/the-set-of-numbers-ab-such-that-ma2nb2-is-prime","['conjectures', 'diophantine-equations', 'sums-of-squares', 'number-theory', 'prime-numbers']"
2411554,Image of the union is the union of the images,"$$ f\left(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}\right) = \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$$ Let $b \in f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$
$\rightarrow b=f(a)$ for some $a \in (\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$. Since $a \in (\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) \rightarrow a \in A_{\lambda}$ for some $\lambda \in \wedge$. Since $b=f(a)$, then $b \in f(A_{\lambda})$ for some $\lambda \in \wedge$. $\rightarrow b \in \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$
$\rightarrow f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) \subset \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$. I used a similar argument to prove $\bigcup\limits_{\lambda \in \wedge} f(A_\lambda) \subset f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$. Which shows $ f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) = \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$. Please let me know if this is valid.","['elementary-set-theory', 'proof-verification']"
2411625,Intro Probability Question,"Of $33$ people, $17$ like red, $14$ like green, and $11$ do not like either. What is the probability that a student likes red and green? What's the probability that exactly one of the following is true: the student likes red (call this event $A$) or the student likes green (call this event $B$).? So far I have that $P(A) = \frac{17}{33}$ and $P(B) = \frac{14}{33}$. I know we are looking for $P(A \cap B)$ for part one. I am wondering if for part two the formula would be $P(A) + P(B) -2P(A \cap  B)$.",['probability']
2411632,"How to prove that if $S\subset \mathbb{Z}$ has a supremum $a$, then $a\in S?$","This question came up in my undergraduate intro to Real Analysis class. We are given that $\mathbb{R}$ is a complete ordered field, and $\mathbb{Z}$ is a subset of the set $\mathbb{R}$. I don't really know where to start. I thought of starting from the definition of integers, but we haven't been given one. I tried to make up a definition and the best I can think of is $\{1, 1+1, 1+1+1, ...\} \cup \{-1, -1 + (-1), -1 + (-1) + (-1),...\}$, but I'm not sure of how to make it more formal.","['real-analysis', 'supremum-and-infimum', 'elementary-set-theory']"
2411640,"Prove $C_b^j (I, \mathbb{R})$ is a complete space","Let I be a real interval (possibly infinite). Let $C_b^j (I, \mathbb{R}) = ${$f:I \rightarrow \mathbb{R}$ such that $f$ is j-times continuously differentiable and $f^{(m)}$ is bounded for $m \leq j$} Define a norm on this space to be $$||f||_{C^j} = \sum_{m=0}^j || f^{(m)}||_{sup}$$ I want to prove that this space (with this norm) is complete.  I know that any metric space can be naturally completed, so WLOG, if {$f_n$} is any Cauchy sequence in $C_b^j (I, \mathbb{R})$, we know there exists a limit function $f = lim_{n \rightarrow \infty} f_n$.  The task is to show that f is a member of $C_b^j (I, \mathbb{R})$. However, here I am having technical issues.  If I want to show that f is bounded, continuous, or differentiable (j times), then I end up needing epsilon delta arguments based on the distance between $f$ and some $f_n$.  However, the distance between $f$ and $f_n$ is based on the norm which already assumes that f is j times differentiable and that the derivatives are bounded.  Can anyone shed some light on this circular bit of logic?","['functional-analysis', 'real-analysis']"
2411716,Solve the equation $(2^m-1) = (2^n-1)k^2$,"Find the solutions to the equation $(2^m-1) = (2^n-1)k^2$ where $m,n,k$ are positive integers. One solution is $m = n$. Since $2^n-1 \mid 2^m-1$, it follows that $n \mid m$ because $\gcd(2^m-1,2^n-1) = 2^{\gcd(m,n)}-1$. Let $m = nd$ for some positive integer $d$. Then we have $$\dfrac{2^m-1}{2^n-1} = \dfrac{2^{nd}-1}{2^n-1} = 2^{(d-1)n}+2^{(d-2)n}+\cdots+2^n+1 = k^2.$$ Therefore we can write $k^2 = 1u \ldots u_2$ where $u = \underbrace{00 \ldots 0}_{n-1 \text{ }\text{zeros}}1$ with $u$ appearing $d-1$ times. How can we continue from here?","['number-theory', 'diophantine-equations']"
2411725,How would one differentiate the exponential map?,"In General Relativity if $(M,g,\nabla)$ is spacetime being $\nabla$ the Levi-Civita connection, then we can define on a geodesically convex set $U\subset M$ the map $\sigma : U\times U\to \mathbb{R}$ $$\sigma(x,y)=\dfrac{1}{2}g_x(\exp_x^{-1}(y),\exp_x^{-1}(y))$$ in other words, $\sigma(x,y)$ is a half of the geodesic distance squared between two points $x,y\in U$. Given a chart $(x,V)$ (here we are thinking that $U\subset V$), we can then consider the covariant derivative $\nabla_\mu$ with respect to $\frac{\partial}{\partial x^\mu}$. I want to compute objects like $$\nabla_\mu \sigma(x,y)$$ $$\nabla_\mu \nabla_\nu \sigma(x,y)$$ with the understanding that the derivative keeps $x$ fixed. So $x$ is a parameter here. The first derivative is obviously the partial, since $\nabla_X$ is $X$ itself on $C^\infty(M)$. The issue is that we need to differentiate $\exp_x^{-1}$ and this doesn't seem trivial. All I know about $\exp_x$ is that it is a map $\exp_x : T_x M\to U$ which given $X\in T_xM$, if $\gamma_{x,X} : I\subset\mathbb{R}\to U$ is the unique geodesic with $\gamma_{x,X}(0)=x$ and $\gamma_{x,X}'(0)=X$ then $\exp_x(X)=\gamma_{x,X}(1)$. I have no idea on how to differentiate this map, let alone its inverse. So how do we compute $\nabla_\mu \sigma(x,y)$ with $x$ fixed? How the exponential map is differentiated?","['mathematical-physics', 'riemannian-geometry', 'differential-geometry', 'general-relativity']"
2411727,"Independent odds, am I (+ friend) seeing this wrong or is there a mistake in the practice exam?","I found this exercise in a practice exam: Any student has a 90% chance of entering a University. Two students
  are applying. Assuming each student’s results are independent, what is
  the probability that at least one of them will be successful in
  entering the National University? A. $0.50$ B. $0.65$ C. $0.88$ D. $0.90$ E. $0.96$ I think the answer is something different than the answers above, namely $0.99$. $0.01 = (0.1 \times 0.1)$ is the chance of neither, so $1 - 0.01$ must be $0.99$ right? But it's not part of the possible answers. Other way: $(0.9 \times 0.9) + (0.9 \times 0.1) + (0.1 \times 0.9) = 0.99$ Am I missing something here?",['probability']
2411739,"We have to show that if z,w $\in\mathbb{C}$ with $|$z$|<$ 1 and $|$w$|<$ 1 and $\bar{z}$w $\neq$ $\bar{w}$z then we have the following:","$$\left| (1+|z|^2)w - (1+|w|^2)z \right| > \left| \overline zw - \overline wz  \right|$$ This is the third day in a row that I am working on this problem. I have tried various manipulations like dividing by the product $|$ (1+$|$z$|^{2}$). (1+$|$w$|^{2}$), trying to prove this in polar form and so on. So far have not gotten anywhere. I am trying to self-learn complex analysis by doing problems but this problem has me stumped.","['complex-analysis', 'complex-numbers']"
2411794,An alternative way to define improper integrals,"Improper Riemann integrals are usually defined via limits. Standard Definition : Let $f:[0, \infty) \to \mathbb{R}$. We say $f$ is improper Riemann integrable on $[0, \infty)$ if it is proper Riemann integrable on compact intervals and the following limit exists $$ \lim_{t \to \infty} \int_{0}^{t} f(x) \ dx$$ Instead of this, can we define the improper integral with ""partitions"" of $[0, \infty)$ as we do with the normal Riemann integral? Preliminaries : A partition of $[0, \infty)$ is a strictly increasing sequence $p:\mathbb{N}_{\geq 1} \to [0, \infty)$ with $p(1) = 0$ and $$\lim_{n \to \infty} p(n) = +\infty$$ A tagging of a given partition $p$ is any sequence $t:\mathbb{N}_{\geq 1} \to [0, \infty)$ such that $t(n) \in [p(n), p(n+1)]$ for all $n \geq 1$. A refinement of a partition $p$ is a partition $p'$ which contains $p$ as a subsequence. The mesh of a partition $p$ is the quantity $\sup\{p(n+1) - p(n): n \in \mathbb{N}_{\geq 1}\}$. It is denoted as $||p||$. $||p|| = +\infty$ is possible. There's two ways we can go about our definition. Definition 1 : Let $f:[0, \infty) \to \mathbb{R}$. We say $f$ is improper Riemann integrable on $[0, \infty)$ if there is a real number $L$ such that for all $\epsilon>0$ there is a partition $p_{\epsilon}$ such that for every refinement $p_{\epsilon}'$ of $p_{\epsilon}$ and any tagging $t$ of $p_{\epsilon}'$ the sum 
$$S(f, p_{\epsilon}', t) \stackrel{\text{def}}{=} \sum_{n=1}^{\infty} [p_{\epsilon}'(n+1) - p_{\epsilon}'(n)]f(t(n))$$ converges and $$|L - S(f, p_{\epsilon}', t)| < \epsilon$$ Definition 2 : Let $f:[0, \infty) \to \mathbb{R}$. We say $f$ is improper Riemann integrable on $[0, \infty)$ if there is a real number $L$ such that for all $\epsilon>0$ there is a $\delta>0$ such that for every partition $p_{\delta}$ with $||p_{\delta}||<\delta$ and any tagging $t$ of $p_{\delta}$, the sum 
$$S(f, p_{\delta}, t) \stackrel{\text{def}}{=} \sum_{n=1}^{\infty} [p_{\delta}(n+1) - p_{\delta}(n)]f(t(n))$$ converges and $$|L - S(f, p_{\delta}, t)| < \epsilon$$ Problem : Are all of these definitions equivalent? Partial answers are fine.","['improper-integrals', 'real-analysis', 'integration']"
2411840,The necessary and sufficient conditions for continuity of a map between topological spaces in terms of the inverse images of open (or closed) sets,"Can we make the following definition? Let $X$ and $Y$ be topological spaces, and let $p$ be a point of $X$. Then a function $f \colon X \to Y$ is continuous at $p$ if, for every open set $V$ in $Y$ such that $f(p) \in V$, there is an open set $U$ in $X$ such that $p \in U$ and $f(U) \subset V$. Is this definition the required generalisation of the classical $\varepsilon$ $\delta$ - definition? Now can we prove the following theorem? Let $X$ and $Y$ be topological spaces, and let $p$ be a point of $X$. Then the function $f \colon X \to Y$ is continuous at $p$ if and only if, for every open (respectively, closed) set $V$ in $Y$ such that $f(p) \in V$, the inverse image $f^{-1}(V)$ is open (respectively, closed)  in $X$. Is this statement correct? If so, then how to prove it? My Attempt: First, suppose that, for every open set $V$ in $Y$ such that $f(p) \in V$, the inverse image $f^{-1}(V)$ is open in $X$. Let us take $U$ to be this inverse image. Then $p \in U$ and 
  $$ f(U) = f \left( f^{-1}(V) \right) \subset V, $$
  as required. Conversely, suppose that $f$ is continuous at $p$, and let $V$ be an open set in $Y$ such that $f(p) \in V$. As $f$ is continuous at $p$ and as $V$ is an open set in $Y$ such that $f(p) \in V$, so  there is an open set $U$ in $X$ such that $p \in U$ and $f(U) \subset V$. So we can conclude that $$p \in U \subset f^{-1} \left( f(U) \right) \subset f^{-1}(V), $$ 
  and hence $p \in U \subset f^{-1}(V)$. What next?","['continuity', 'general-topology']"
2411843,"$(\lambda I-A)^{-1}C\subset C,\forall \lambda\in\Bbb K:\Re(\lambda)>\|A\|\implies e^{tA}C\subset C,\forall t\in\Bbb R$","This is the exercise 25 in the book Analysis II of Amann and Escher, page 148. Let $C$ a closed and convex subset of $E$ and $A\in\mathcal L(E)$ . Show that these statements are equivalent: $e^{tA}C\subset C$ for all $t\in\Bbb R$ . $(\lambda I-A)^{-1}C\subset C$ for all $\lambda\in\Bbb K$ such that $\Re(\lambda)>\|A\|$ . (Note: here $E$ is a Banach space and $\Bbb K=\Bbb R\text{ or }\Bbb C$ .) I know that $$e^{tA}=\lim_{n\to\infty}\left(I-\frac{t}nA\right)^{-n},\quad (\lambda I-A)^{-1}=\int_0^\infty e^{-s(\lambda I-A)}\mathrm ds$$ What I had tried $(ii)\implies (i)$ If $n>\|A\|$ then the operator $n I-A$ is invertible. Now observe that $$n I-A=n\left(I-\frac1{n}A\right)\implies (n I-A)^{-1}=\frac1{n}\left(I-\frac1{n}A\right)^{-1}\tag1$$ Now if I use recursively the last result I get $$n^{-n}\left(I-\frac1{n}A\right)^{-n}C\subset C$$ for all $n>\|A\|$ . But due to the factor $n^{-n}$ I cant show that $e^AC\subset C$ . Some help will be appreciated, thank you. W.I.P.: from the comments I assume there is some typo or lack of some important information in the exercise so I will try to add some restrictions on it. By example: it can be seen that assuming $E=\Bbb R$ and $A=I$ and $\lambda,t\in\Bbb R$ (in addition to $\Re(\lambda)>\|A\|$ ) and some perfect interval the statement holds. So maybe assuming these conditions for arbitrary real Banach space $E$ the exercise make sense. That is: $\lambda,t\in\Bbb R$ and $C\subset E$ is a closed and convex subset with more than one point in it. Thus, trying to show $(ii)\implies (i)$ we want to find some ""valid"" expression in terms of linear functions $(\lambda I-A)^{-1}$ to prove that $(I-\frac{t}nA)^{-1}C\subset C$ , what will let me show that $e^{tA}C\subset C$ . Because $C$ is convex then $$\frac{\sum_{k=0}^n r_k(\lambda_k I-A)^{-k}}{\sum_{k=0}^n r_k}C\subset C$$ for arbitrary $r_k>0$ and $\lambda_k>\|A\|$ . Then taking $r_k=\frac1{k!}$ and $\lambda_k=m$ , and by the closedness of $C$ we find that $$e^{-1}\lim_{n\to\infty}\sum_{k=0}^n \frac{(m I-A)^{-k}}{k!}C=e^{(m I-A)^{-1}-I}C\subset C$$ However from the last expression it is not so clear how I can prove that $e^{tA}C\subset C$ .","['functional-analysis', 'linear-algebra', 'analysis', 'operator-theory']"
2411844,Different answer from using definition of contour integral to using Cauchy's Integral Formula,"The contour integral is: $$\int_{\Gamma}\frac{\cos z + i \sin z}{(z^2 + 36)(z+2)} \mathrm{d} z$$ where $\Gamma$ is the circle centred at the origin, with radius 3, traversed once positively. I computed this contour integral to be $\frac{\pi i e^{-2}}{20}$, however, WolframAlpha is claiming that it's equal to zero when I try to do it by parametrisation with $z:= e^{it}$ for $0 \leq t \leq 2\pi$. W|A Link: http://www.wolframalpha.com/input/?i=integral+from+0+to+2pi+of+(e%5E(i(e%5E(it)))%2F((e%5E(2it)+%2B+36)(e%5E(it)%2B2))+ ++e%5E(it)+ +i+dt Why does W|A give a different answer? Am I wrong then with my original answer?",['complex-analysis']
2411860,Finding the Coefficient of $(x^3 + 2y^2)^n$ containing $x^{18} y^{12}$,"I was helping somebody when I scratched my head because of this question. It goes like 
this: If the middle term of the expansion of $(x^3 + 2y^2)^n$ is $C x^{18} y^{12},$ find C. My work: I let $u = x^3$ and $v = 2y^2.$ Then doing this: $$(u)^6 = (x^3)^6 \space  and \space \space \left(\frac{v}{2} \right)^6 = (y^2)^6$$ we get $u^6 = x^{18}$ and $\left(\frac{v^6}{64} \right) = y^{12}$ We now conclude that the expression $(u + v)^n$ has a term $(u^6)\left(\frac{v^6}{64} \right)$ along its expansion when $u = x^3$ and $v = 2y^2$ We need to find its equivalent term of $(u^6)\left(\frac{v^6}{64} \right)$ when we go back to dealing with $(x^3 + 2y^2)^n.$ Everybody knows that in the binomial expansion of $(u + v)^n,$ in each term, the sum of the exponents of $u$ and $v$ is $n.$ and there are $n+1$ terms. With that in mind, the sum of the particular term $(u^6)\left(\frac{v^6}{64} \right)$ is $n = 12$ and the number of terms in that particular expansion is $12+1 = 13.$ Since the problem asks for the coefficient of the middle term $C x^{18} y^{12},$ we need to find its middle term. Turns out, in the binomial expansion containing $13$ terms, the middle term would 
be the $7$th term. Now looking for for the expression of the $7$th term: $$nth \space term = C(n, r-1) u^{n-r+1} v^{r-1}$$
$$expression \space of \space 7th \space term = C(12, 7-1) (x^3)^{12-7+1} (2y^2)^{7-1}$$
$$ = (924) (x^3)^{6} (2y^2)^{6}$$
$$ = (924) (x^{18}) (2)^{6}(y^2)^{6}$$
$$ = (924) (x^{18}) (64) (y^2)^{6}$$
$$ = (924) (x^{18}) (64) (y^{12})$$
$$ = 59136 x^{18} y^{12}$$ Therefore, we conclude that $C = 59136.$ Lastly, the equivalent term of $(u^6)\left(\frac{v^6}{64} \right)$ from $(u + v)^n$, when we go back to dealing with $(x^3 + 2y^2)^n$, is $59136x^{18}y^{12}$ I've done my best but I couldn't verify it. Is my solution correct?",['algebra-precalculus']
2411923,Integrating a partial derivative with second variable a function of the first?,"These questions are related but don't answer my specific question: 1 , 2 , 3 . Assume we have a two-variable function where the second depends on the first: $z=f(x,y(x))$ Is it possible in this case to calculate the integral of the partial derivative of $f$ with respect to $x$, that is independent of the specific form of $f$ and $y(x)$? $$\int\frac {\partial f}{\partial x}(x,y(x))dx=?$$ We cannot apply the fundamental theorem of calculus directly as we would if it was not a partial but a standard derivative: $$\int\frac {d}{dx}f(x,y(x))dx=f(x,y(x))+C$$ Is there some similar (general!) formula for the partial derivative case?","['multivariable-calculus', 'partial-derivative', 'calculus']"
2411929,Show that any subgroup of $G$ of index $p$ (if it exists) is normal in $G$.,"Let $G$ be group and $p$ be the least prime divisor of $|G|$.Then any subgroup of $G$ of index $p$ (if it exists) is normal in $G$. My attempt $:$ Let $H \leq G$ be such that $[G:H] = p$.Let us consider the action of $G$ on the set $A$ of all left cosets of $H$ in $G$ (where the action is the left multiplication). Let $\pi_H$ denote the permutation representation of this action.Let $K = Ker\ \pi_H$. Then $K$ is a subgroup of $H$ (In fact $K$ is the largest normal subgroup of $G$ contained in $H$). Let $[H:K]=k$.Then $[G:K]=[G:H][H:K] = pk$. Since $\pi_H : G \longrightarrow Sym (A)$ is a homomorphism so by first isomorphism theorem we have $G/K \cong \pi_H (G)$. Since $|A| = [G:H] = p$. So $Sym (A) \cong S_p$. Hence $\pi_H (G)$ is a subgroup of $S_p$. This shows that $pk = |G/K| = |\pi_H (G)|$ divides $|S_p|=p!$ i.e. $k | (p-1)!$. Now since $k$ divides $|G|$ so if $k$ is prime or composite then by minimality of $p$, $k$ has to have a prime divisor $q \geq p$.Then $q | (p-1)!$ and since $q$ is prime so $q|(p-k)$ for some $1 \leq k \leq p-1$, a contradiction since $q \geq p$.Hence $k = 1$ and consequently $H = K$, completing the proof. Is the above reasoning correct at all? Please verify it. Thank you in advance.",['group-theory']
2411945,Trisect a quadrilateral into a $9$-grid; the middle has $1/9$ the area,"Trisect sides of a quadrilateral and connect the points to have nine quadrilaterals, as can be seen in the figure. Prove that the middle quadrilateral area is one ninth of the whole area.","['plane-geometry', 'quadrilateral', 'euclidean-geometry', 'geometry', 'area']"
2411960,Elementary Set Theory: Proof of Distributive Property [duplicate],"This question already has answers here : Question about the proof of the distributive property for sets (2 answers) Closed 5 years ago . I'm new to proofs.  While working through a finite math book, I've been asked to prove the distributive properties of set operations.  I'll use the distributive property of union over intersection as the example for my question. Prove that A ∪ (B ∩ C) = (A ∪ B) ∩ (A ∪ C). The proofs I see for this property aim to show, in two steps, that each side is a subset of the other side.  For example, the first step usually looks something like this: Let x ∈ A ∪ (B ∩ C). If x ∈ A ∪ (B ∩ C) then x is either in A or in (B and C). x ∈ A or x ∈ (B and C) x ∈ A or { x ∈ B and x ∈ C} { x ∈ A or x ∈ B} and { x ∈ A or x ∈ C} x ∈ (A or B) and x ∈ (A or C) x ∈ (A ∪ B) ∩ x ∈ (A ∩ C) x ∈ (A ∪ B) ∩ (A ∪ C) x ∈ A ∪ (B ∩ C) => x ∈ (A ∪ B) ∩ (A ∪ C) Therefore, A ∪ (B ∩ C) ⊂ (A ∪ B) ∩ (A ∪ C) Then the second step would do something similar to show that (A ∪ B) ∩ (A ∪ C) ⊂ A ∪ (B ∩ C). My question in this-- In jumping from lines 3 to 4, aren't we relying on the very property we're trying to prove? If so, how is that considered as proof? I don't have trouble following the steps, and I don't doubt that the property is valid.  But as a newcomer to proofs I'm confused because it looks (to me) like we're using the property to prove itself.  To my non-mathematician mind, drawing a couple of Venn diagrams provides a more intuitive ""proof"" than manipulating these equations.",['elementary-set-theory']
2411963,Number of zeros of the second derivative of composition of sigmoid-like functions,"Consider the bounded, positive and monotonic functions $f(x) = \frac{x^k}{a^k+x^k}$ and $g(x) = \frac{b^h}{b^h+x^h}$ with $a,b>0,$ and $k,h > 1$ and defined for $x\in \mathbb{R}^+$. Using simulations, it looks to me that the second derivative $(f\circ g\circ f \circ g)''$ has at most one zero. I tried to prove it analytically using the chain rule and the fact that $f'(x) = \frac{k}{x}f(x)\big(1-f(x)\big)$ and similarly for $g'(x)$ but with no success. I can see that the number of zeros (taking their multiplicity into account) must be odd because the second derivative is positive at $x=0$ and negative at $x\rightarrow \infty$. It's probably irrelevant, but I can also show that the second derivative can be expressed as the sum of four functions $h_{1}, h_{2},h_{3}, h_{4}$ with $h_{1},h_{2}$ having two zeros and $h_{3},h_{4}$ having one zeros and $h_{1},h_{2},h_{3}$ having a common zero. Any help towards a proof or a counter-example would be much appreciated.","['derivatives', 'functions']"
2411980,About two relative primes $a$ and $b$ whose sum is constant.,"$\forall (a, b) \in \mathbb{N}$ who are also relatively prime, whose sum is always $c$ (therefore $a + b = c$ for a given number $c$), and the number of divisors for a natural number $n$ is written as $A(n)$, How can I get:
   $$\sum A(a)\times A(b) : a + b = c?$$",['number-theory']
2412029,Evaluate a limit using l'Hospital rule,"Evaluate $$\lim_{x\to0} \frac{e^x-x-1}{3(e^x-\frac{x^2}{2}-x-1)^{\frac{2}{3}}}$$
I tried to apply l'Hospital rule in order to get the limit to be equal to
$$\lim_{x\to0}\frac{e^x-1}{2(e^x-\frac{x^2}{2}-x-1)^{-\frac{1}{3}}(e^x-x-1)}$$
but the new denominator has an indeterminate form itself and by repeatedly applying l'Hospital rule, it doesn't seem to help... This is where I got stuck.","['derivatives', 'real-analysis', 'calculus', 'limits']"
2412031,Relation between radius of smallest sphere containing a n-dimensional simplex and its edge length,"I have a $n$-dimensional simplex with maximum edge length equal to $l$. Do we have a relationship between radius of minimum volume sphere (thus minimum radius sphere) containing the simplex and maximum edge length ""$l$"".
Also is there a relationship between volume of the simplex and volume of minimum sphere (in terms of radius) containing it.","['simplex', 'geometry']"
2412080,$a^2=ab+b^2+b+5$ has no integer solutions,"Prove that the equation $a^2=ab+b^2+b+5$ has no integer solutions. My attempt: $4a^2=4ab+4b^2+4b+20$ $4a^2-4ab+b^2 = 5b^2+4b+20$ $5(4a^2-4ab+b^2) = 5(5b^2+4b+20)$ $5(2a-b)^2=(5b+2)^2+96$ Let $2a-b = x$, $\;5b+2=y$ we get $\;5x^2-y^2=96$. Please suggest on how to proceed.",['number-theory']
2412081,"Is this statement true: $\mathsf{Cov}(X,Y)\geq 0$, $\mathsf{P}(Y>0)=1$, show that $\mathsf{Cov}\Big(X,\dfrac{1}{Y}\Big)\leq 0$","I was trying to prove a problem and I got stuck at a point. The problem leads to a point where I have to show: Let, $X$ and $Y$ are two r.v. If $\mathsf{Cov}(X,Y)\geq 0$ and $\mathsf{P}(Y>0)=1$, then show that $\mathsf{Cov}\Big(X,\dfrac{1}{Y}\Big)\leq 0$. But I could not find a way to go from $Y$ to $\dfrac{1}{Y}$, also I have a feeling that there may be a counterexample of the problem. Any help would be appreciated. Thanks to Einar Rødland , but in the problem I did not have $(X,Y)$ and $(X, 1/Y)$ same in distribution. The problem was to show if $\mathsf{E}\Big(\dfrac{Z_1-Z_2}{Z_1+Z_2}\Big)\geq 0$, then $\mathsf{E}(Z_1-Z_2)\geq 0$, where $Z_1$ and $Z_2$ are different positive r.v. and $\mathsf{Cov}(Z_1+Z_2,Z_1-Z_2)\geq 0$","['statistics', 'probability', 'covariance']"
2412118,What are the roots of $x^4 + x^2 + 1$?,"I tried to find them for a quite a while but to no avail. I tried the substitution $y = x^2$, but the result is a mess. Is there any systematic way to get the roots for this quartic polynomial? Any help or insight is deeply appreciated.","['algebra-precalculus', 'roots', 'polynomials', 'quartics']"
2412144,Understanding a dynamical system for virus populations,"I am reading the book: M. A. Novak, R. M. May: Virus Dynamics: Mathematical Principles of Immunology and Virology . Oxford University Press, 2000. I came across few places that I don’t understand. 
In the model, uninfected cells react with free virus to give rise to infected cells; the rate constant is $\beta$. Infected cells produce free virions at rate $k$. Uninfected cells, free virus and infected cells die at rates $d$, $u$ and $a$, respectively. Uninfected cells are replenished at rate $\lambda$. The schematic of the model is: The model equations are [eq. (3.1) p. 18 in the link]: $$
\begin{alignat}{1}
\dot{x} &= λ - dx - βxv,\\
\dot{y} &= βxv - ay, \\
\dot{v} &= ky - uv,
\end{alignat}
$$ where $x$, $y$, and $v$ are the populations of uninfected cells, infected cells and virions. The basic reproductive ratio, $R_0$ is the number of newly infected cells that arise from any infected cell when almost all cells are uninfected (and the system is near its equilibrium): $$R_0= \frac{\beta \lambda k}{adu}$$ What I don’t understand is: It is mentioned that if $R_0<1$ the virus will not spread since every infected cell will produce on average less than one infected cell. If we start with $N$ infected cells, then on average, we expect roughly ${\ln N}\over {\ln(1/R_0)}$ rounds of replication before the virus population dies out. How is this ${\ln N}\over {\ln(1/R_0)}$ found? If $R_0>1$ then virus will initially grow exponentially, and $r_0$ is the exponential growth rate of the population. Then it is said $r_0$ is given by the larger root of the equation $r_0^2+(a+u)r_0+au (1-R_0)=0$. How did they come up with this equation? Then they say in the equation $r_0^2+(a+u)r_0+au (1-R_0)=0$ if $u \gg a+r_0$ we find the approximation $r_0=a(R_0-1)$. How is this $r_0=a(R_0-1)$ obtained?","['ordinary-differential-equations', 'dynamical-systems']"
2412175,Decomposition of real number into elements of null measure sets,"Are there sets A and B such that any $x \in \mathbb{R}$ can be decomposed as $x = a+b$, $a \in A$ and $b \in B$, where the Lebesgue measure of $A$ and of $B$ is null. There is an indication that this should follow from the fact that $C_q = \{z \in[0,1]; z_i\in\{0,2,\cdots,q-1\}\}$ has null measure for every $q \in \mathbb{N}$, where $z_i$ are the numbers in the q-adic expansion of $z$, that is $$z=\sum_{i=1}^{\infty}\frac{z_i}{q^i}$$","['measure-theory', 'cantor-set']"
2412183,"Prove $\displaystyle{\lim_{x \to 2}}\,x^3 + 1 = 9$ $(\delta < 1 \text{ or } \delta \leq 1)?$","My math prof demonstrated this proof today and I'm not sure I understand all the steps. I don't understand why the $\delta$ has to be divided by 2 after selecting the minimum. Here are the steps he showed: We should show $\forall\epsilon > 0, \exists\delta > 0$ (let's call this eq1):
$$|x-2| < \delta \implies |x^3 + 1 - 9| = |x-2||x^2 + 2x + 4| < \epsilon$$ Assume $\delta < 1$, this bounds $|x - 2| < 1$ and implies $1 < x < 3$. Now we know: $$|x^2 + 2x + 4| < 19$$
So, if we can show:
$$|x-2| < \delta \implies |x-2||x^2 + 2x + 4| < 19|x-2| < \epsilon$$
eq1 follows for $\delta < 1$. The above is trivially true for $\delta = \epsilon/19$. But we must account for $\delta >= 1$ and therefore set:
$$
\delta = \frac{1}{2}\min(\epsilon/19,1)
$$
QED. Why is the $\frac{1}{2}$ factor needed? To me it looks redundant. According to the prof it was because $\delta = 1$ is a possibility. But if $\delta = 1$ then $\epsilon = 19$ and:
$$|x-2| < 1 \implies |x-2||x^2 + 2x + 4| < 19$$
is obviously true. Could the $\frac{1}{2}$ factor have been avoided by instead assuming $\delta <= 1$? I'm not even sure why I have to ""soil"" my proof by covering the $\delta >= 1$ case with the $\min$ function. Can't I just say ""The proof holds for small deltas ($\delta < 1$) which is all that matters for limits?""","['epsilon-delta', 'calculus', 'limits']"
2412232,Direct product vs direct sum of infinite dimensional vector spaces?,"These seems like simple questions, but I cannot seem to find straightforward answers: (1)  If $V$ and $W$ are infinite (possibly uncountable) dimensional vector spaces, does $V \bigoplus W = V \times W$ ?  That is, is there any difference between the direct sum and direct product of infinite dimensional vector spaces? (2)  If $\{ V_i \}_{i \in I}$ is an infinite (possibly uncountable) collection of finite dimensional vector spaces, does $ \bigoplus_{i \in I} V_i = \times_{i \in I} V_i$ ?  Is the direct product product of infinitely many vector spaces even defined since vectors are supposed to consist of finite linear combinations of basis vectors (I realize there are subtleties in what ""basis"" means in the case of an infinite dimensional vector space)? The inspiration for this question comes from the study of Banach spaces.  Namely, that the product (or direct sum?) of Banach spaces can be made into a Banach space.","['functional-analysis', 'abstract-algebra', 'linear-algebra', 'vector-spaces']"
2412284,"The data set $\{x_1,\dots,x_{10}\}$ has a mean $\mu=10$ and a standard deviation $\sigma=3$. Find the value of $\sum_{i=1}^{10}[(x_i-12)^2]$.","Problem The data set $\{x_1,\dots,x_{10}\}$ has a mean $\mu=10$ and a standard deviation $\sigma=3$. Find the value of $$\sum_{i=1}^{10}\left[\left(x_i-12\right)^2\right]$$ My solution Using formulae for variance and mean, $$\mu = \frac{1}{10}\sum_{1=1}^{10}x_i = 10 \implies \sum_{1=1}^{10}x_i = 100$$
$$\sigma^2 = \frac{1}{10}\sum_{i=1}^{10}\left(x_i^2\right)-\mu^2 = 9 \implies \sum_{i=1}^{10}x_i^2 = 10\left(9+\mu^2\right) = 1090$$ Then, with a bit of algebra, $$\begin{align}
\sum_{i=1}^{10}\left[(x_i-12)^2\right] &= \sum_{i=1}^{10}\left(x_i^2-24x_i+144\right) \\
&= \sum_{i=1}^{10}\left(x_i^2\right)-24\sum_{i=1}^{10}\left(x_i\right)+\sum_{i=1}^{10}\left(144\right) \\
&= 1040-24\left(100\right)+144\cdot10 \\
&= 130
\end{align}$$ Question Is there another (significantly different) approach to solving this problem? Any input is welcome! I believe that I had originally tried to somehow arrive at a univariate function that mapped the mean to the variance and then evaluate that for a mean equal to $12$, but I soon realized that I had erroneously parenthesized the $\mu^2$ with the $x_i^2$ term  in the argument of the summation formula for $\sigma^2$, so that approach definitely wouldn’t work.","['means', 'standard-deviation', 'variance', 'statistics', 'summation']"
2412297,Argument of sum of two complex numbers,"I was trying to find solution to $\arg(z+w)$, where $z$ and $w$ are two complex numbers in terms of $\arg(z)$ and $\arg(w)$. 
Making a parallelogram out of vector addition of the $2$ complex numbers in Argand plane leads to $$\arg(z+w)=\frac{\arg(z)+\arg(w)}{2}$$ Am I correct or there are some cases to be accounted for?
(consider only principal arguments)","['complex-analysis', 'complex-numbers']"
2412330,Is this a modified Monty Hall problem (numbered doors)?,"On a job interview, I got this question: Monty placed a car and two goats behind three identical doors (and the things do not move during the game). You receive the prize which is behind the door you picked in the second round. You choose door number 1. Then, Monty opens door number 3 and you see a goat there. If you want to win a car, should you change your guess from door no 1 to door no 2? I answered: YES and was told I was wrong. The interviewer explained me, that the difference between classical MH problem and this problem is that this problem clearly states, that Monty opens door number 3, which reduces the state space and after that my chance is 50/50. I still believe chance of picking right door at first attempt is 1/3 and this probability is not changed by the information that Monty opens door number 3. Am I missing something or was the interviewer wrong?","['monty-hall', 'probability']"
2412375,Suppose we roll a fair $6$ sided die repeatedly. Find the expected number of rolls required to see $3$ of the same number in succession.,"Suppose we roll a fair six sided die repeatedly. Find the expected number of rolls required to see $3$ of the same number in
succession From the link below, I learned that $258$ rolls are expected to see 3 sixes appear in succession.  So I'm thinking that for a same (any) number, the rolls expected would be $258/6 = 43$ . But I'm unsure how to show this and whether it really is correct. How many times to roll a die before getting two consecutive sixes?","['probability-theory', 'probability']"
2412379,Information geometry: geometry of exponential families,"I've read in various locations that the geometry of exponential families are flat. Is this true? I don't understand because, I have also read that the family of gaussians with unknown mean and unknown variance has hyperbolic geometry, which is not flat! and the family of multinomial distributions has spherical geometry. Here is a arxiv paper which seems to suggest both are true: https://arxiv.org/abs/0911.4863 There must be something fundamental that I'm not understanding. I'm not an expert in differential geometry.","['probability-theory', 'differential-geometry', 'probability-distributions']"
2412392,"If $f'+f''\geq f^2$ show that $\frac{f'}{f''}\leq 1$ for all $x\in(0,+\infty)$.","I have a question about this : Let a function $f$ with domain $]0,+\infty[$ and codomain $]0,+\infty[$ and twice differentiable with the following inequality :
  $$f'+f''\geq f^2$$ Show that we have $\dfrac{f'}{f''}\leq 1$ for all $x\in$  $]0,+\infty[$ I have no idea to prove or disprove this . Thanks.","['real-analysis', 'calculus']"
2412409,Fastest way showing the limit exists without finding the limit?,"Let $\{a_n\}$ and $\{b_n\}$ be two integer sequences such that $a_1=b_1=1,$ \begin{align*}
a_n=a_{n-1}+b_{n-1},\qquad\qquad b_n =r\,a_{n-1}+b_{n-1}.
\end{align*} Where $r$ is a natural number $>1$. ($r$ is a fixed value) Write $c_n={b_n}/{a_n}$, how to prove the following limit exist without finding it? \begin{align*}
\lim_{n\to\infty} c_n.
\end{align*} Attempt I used mathematical induction to prove $\{c_{2n}\}$ is monotonically decreasing and $\{c_{2n+1}\}$ is monotonically increasing. Then, note that \begin{align*}
c_{n+1}=\frac{b_{n+1}}{a_{n+1}}&=\frac{r\,a_n+b_n}{a_n+b_n}\\
&=r-\frac{r-1}{\frac 1{b_n/a_n}+1}<r
\end{align*} Therefore, $0<c_n<r$. $\vdots$ Instead of continuing using this method (too complicated), any other faster ways to prove ""exist""? I tried to use the definition of Cauchy sequence and contraction mapping (they are 2 methods), but I don't think they work here. Any hints or tips are appreciated:)","['recurrence-relations', 'cauchy-sequences', 'limits', 'contraction-operator', 'sequences-and-series']"
2412472,Direct (or inverse) image of subgroup under Second Isomorphism Theorem's isomorphism.,"I want to prove this: Let $G$ be a group, with $K,V\leq G$ , $V\trianglelefteq G$ and $KV=G$ . Let $$\varphi:K/K\cap V \to G/V$$ given by $k(K\cap V)\mapsto kV$ be the isomorphism of the Second Isomorphism Theorem. Let $H\leq G$ with $V\leq H$ . Then $\varphi((H\cap K)/(K\cap V))=H/V$ . My attempt: I could prove that $\varphi((H\cap K)/(K\cap V))\leq H/V$ like this: Let $h=k\in H\cap K$ . Then $kV=hV$ and $\varphi(k(K\cap V))=kV=hV\in H/V$ . I wanted to prove the converse like this: Let $h\in H$ . I want to prove that there exists $k=h'\in H\cap K$ such that $h(K\cap V)=k(K\cap V)$ . I don't know how to proceed. My first idea was to take $v_1\in V,k_1\in K$ such that $h=k_1v_1$ , but I don't know how to use that.",['group-theory']
2412515,Which of the following is (are) correct?,"Let $F$ be a finite field.If $f:F\rightarrow F$,given by $f(x)=x^3$ is a ring homomorphism,then $(A)$$F=\mathbb Z/3\mathbb Z$. $(B)$$F=\mathbb Z/2\mathbb Z$ or $Characteristic$ of $F=3$. $(C)$$F=\mathbb Z/2\mathbb Z$ or $\mathbb Z/3\mathbb Z$. $(D)$$Characteristic$ of $F$ is $3$. Solution: If  $F=\mathbb Z/3\mathbb Z=${$0,1,2$} or $F=\mathbb Z/2\mathbb Z=${$0,1$},then elements of $F$  are  satisfying the operation preserving properties.This leads me (PLEASE CHECK!!) to the  selection of options$(A)$,$(B)$ and $(C)$. I'm not getting how to accept or discard option $(D)$. Please give some suggestions  about my attempt......","['finite-fields', 'abstract-algebra', 'ring-theory', 'group-homomorphism']"
2412519,"Show that $7 |(n^6 + 6)$ if $7 ∤ n$, $∀ n ∈ ℤ$","Show that $7 |(n^6 + 6)$ if $7 ∤ n$, $∀ n ∈ ℤ$ I need to prove this by the little Fermat's theorem. My attempt $n^6 \equiv -6 \pmod 7$ To show $7  ∤ n$ I need to show that $N$ is not congruent to $0$ mod $7$. as $-6 \equiv 1\pmod 7$ $n^6 \equiv 1\pmod7$ But now, How can I show $N$ is not congruent to $0$ mod $7$ ?","['polynomials', 'divisibility', 'factoring', 'elementary-number-theory', 'discrete-mathematics']"
2412536,Regular functions on plane minus origin,"Let $k$ be algebraically closed and consider $X = \mathbb{A}^2 \setminus O$. How does one show that $\mathcal{O}(X) \cong k[x, y]$? I am more or less aware of how to do this from a sheaf-theoretic point of view: the distinguished opens are $D(x)$ and $D(y)$, and the regular functions on these are simply elements of $k[x, y]_x$ and $k[x, y]_y$, so a regular function is a function which agrees on the overlap, and thus has no power of $x$ or $y$ in the denominator, i.e. is an element of $k[x, y]$. Can this proof be translated to the classical point of view? In particular, how does one assert that the regular functions on a ""distinguished open set $D(f)$"" are simply the polynomials localized at $f$ -- the rest will be the same after this.",['algebraic-geometry']
2412595,Ballot counting when ties occurs exactly $r$ times,"Ballot Problem with Fixed Number of Ties: Problem Statement : In an election, candidate A receives $m$ votes and candidate B receives $n$ notes. Let $m \ge n$. In how many ways can the ballots be counted so that ties occur exactly $r$ times ($r \le n$)? Example : $m = 3, n = 2, r = 1$. There are 4 such scenarios: for order ABAAB, BAAAB the tie occurs at the 2nd vote; for order AABBA, BBAAA the tie occurs at the 4th vote. Call this number $Z( m,n, r)$. My practical goal is to answer the following:  Given the total number of votes $N$, how many ways can we order the ballots to have exactly $r$ ties? It is 
\begin{equation}
Z(N,r) = \sum_{n = r}^{N/ 2} Z( N-n, n ,r ) + \sum_{n = r}^{N/ 2} Z( n, N-n ,r )
\end{equation}
once we figure out $Z(m,n,r)$. It would be nice if one can get $Z(N,r)$ or its generating function directly, but I think the ""$r$-tie"" ballot problem is interesting on its own. Mapping to lattice path enumeration Here is an equivalent form of the problem: Consider lattice path from $(0,0)$ to point $(m,n)$ with only up $(0,1)$ or right $(1,0)$ movement in $m +n $ steps. Excluding the starting point $(0,0)$, how many lattice paths hit the (lattice point on the) diagonal line $y = x$ exactly $r$ times? The following figure shows a lattice path that reaches (4,3) and its image under Andre's reflection. It hits the diagonal 3 times. $r = 0$ is the strictly monotonic path The $r = 0$ problem can be solved by Andre's reflection principle . (method used here is similar to this ME post ) First of all $m > n$, otherwise the end point $(n,n)$ will be one touching point. Since no touching of the diagonal is allowed, the first step must go right. There are ${ m + n - 1 \choose m-1}$ such paths but we need to exclude the ones that touches the diagonal. Suppose there is one such path (first step going right) that touches the diagonal, we can do reflection about the $ y= x$ line for the path between the origin and the first intersection (see Figure). The reflected path is one that starts with up movement. Since such paths will definite cross the diagonal line to reach $(m,n)$, it is easy to see that the map is one-to-one. There are ${m+n -1 \choose n - 1}$ such paths. In sum, the result is
\begin{equation}
Z( m, n, 0) = { m + n - 1 \choose m - 1 } - {m+n -1 \choose n - 1} = { m + n - 1 \choose n } - {m+n -1 \choose n - 1} \quad m > n 
\end{equation}
which is very similar to the ballot theorem . Any idea of approaching the general $r$? Thanks! Update 1: $m = n, r = 1$ is the strictly monotonic Dyck path The only intersection is at the end point $(n,n)$, so this is basically a Dyck path that hits the diagonal once. This ME post gives the general result for a Dyck path to hit the diagonal $k$ times. Setting $k$ = 1, the result is $\frac{1}{n}{2n - 2 \choose n-1 }$. Here the path can be either above or below the diagonal line, hence a factor of $2$,
\begin{equation}
Z( n, n, 1 ) = \frac{2}{n}{2n - 2 \choose n-1 }
\end{equation} Update 2: number of lattice paths that crosses the diagonal $k$ times Call this number $C( m, n, r )$. Kern, Malcolm; Walter, Stanley , Ballot theorem and lattice path crossings , Can. J. Stat. 6, 87-90 (1978). ZBL0387.60018 . gives the result
\begin{equation}
C( m,n, r ) = \left\lbrace
  \begin{aligned}
    &\frac{2(r+1)}{n} {2n \choose n - r -1 } & m = n \\
    &\frac{m - n + 2r + 1}{m + n + 1} { m + n +1  \choose n - r } & m > n \\
\end{aligned}  
\right.
\end{equation} This is a relevant but different problem. Notice the difference between ""touch"" and ""cross"". Only going from one side of $y=x$ to the other is considered as a ""cross"". In the ballot problem, this is a change of the leading candidate, not a tie. One can check that $C( n, n, 0 )$ is twice the Catalan number.","['combinatorics', 'integer-lattices', 'discrete-mathematics']"
2412614,Hartshorne exercise 1.1 (c),"I want to know how can I find the conditions where $A(W)$, the affine coordinate ring of a variety given by an irreducible quadratic polynomial in $k[x,y]$, is isomorphic to $A(V)$ or to $A(Z)$ where $V$ is a parabola defined by $y=x^2$ and $Z$ is the hyperbola given by $xy=1$. Thanks in advance for your answers.",['algebraic-geometry']
2412646,"Does the sequence $x_0=12$ , $x_{n+1}=x_n^2+1$ contain a prime?","I wonder whether the sequence defined by $$x_0=12$$ $$x_{n+1}=x_n^2+1$$ for all non-negative integers $n$ contains a prime number. The following table shows from left to right : The index $n$ , the number of digits of $x_n$ and the smallest prime factor of $x_n$.For $n=17$, I did not find a prime factor so far. ? x=12;j=0;while(length(digits(x))<10^6,j=j+1;x=x^2+1;p=2;while(Mod(x,p)<>0,p=ne
xtprime(p+1));print(j,""   "",length(digits(x)),""   "",p))
1   3   5
2   5   2
3   9   13
4   18   2
5   35   733
6   70   2
7   139   5
8   277   2
9   554   1536673
10   1107   2
11   2214   13
12   4427   2
13   8854   5
14   17707   2
15   35413   13
16   70825   2 As we can see, a prime of the desired form must have more than $140\ 000$ digits. The smallest prime factor of $x_9$ is already large and the smallest prime factor of $x_{17}$ will be considerably larger (I currently search for a prime factor) Is $x_{17}$ prime ? Does the sequence contain a prime ? UPDATE : This is a somewhat modified program to determine the indices $n$ for which $x_n$ has no prime factor belo $10^7$ ? for(k=1,50,p=1;gef=0;while((gef==0)*(p<10^7),p=nextprime(p+1);s=12;for(j=1,k,s
=lift(Mod(s^2+1,p)));if(s==0,gef=1));if(gef==0,print1(k,"" "")))
17 33
? Since $x_{33}$ is already huge , the only hope is $x_{17}$, but if I did not make an error using the factordb-database, $x_{17}$ should be composite.","['number-theory', 'prime-numbers', 'sequences-and-series']"
2412650,In a two dimensional curl what does the number you get represent?,"As for example let the field be $\mathbf{F} = \langle -y,x\rangle$.  When I do the math I get $2$!  But $2$ what ?   One source says it measure ""twice the angular speed"" because we are measuring unit angular speed"" .  I assume $2$ is a number that applies to only this particular example... then what happens with other examples? Is it possible to have $4$,$5$, $6$ and is that then $4$,$5$, $6$ times the angular speed because we are measuring unit angular speed?  Any help is appreciated. I have also another example $G= <x,x>$and the Curl = $1$. Now if the curl represents a direction , let's assume this and we place it in the context of the $3$ dimensional curl then since the direction is perpendicular to the plane of the forces causing the spin, how can the spin be in the plane when the force is pointing up?",['multivariable-calculus']
2412656,Does taking sections commute with base change?,"Let $X$ be a scheme over a field $k$, and let $K$ be a field extension of $k$.
Let $X_K$ denote the base change. I want to know whether for any open $U\in X,\mathscr O(U_K)=\mathscr O(U)\otimes_k K.$ I believe this should be true, since for any affine open $V=specA$ inside $U$, we have $\mathscr O (V_K)=A\otimes_k K=\mathscr O(V)\otimes_k K,$ so maybe, since the sections agree locally, they should be the same. But I'm not sure how to put this rigorously. Any help would be appreciated.","['schemes', 'algebraic-geometry']"
2412666,"Show that if $f: [0,1]\to \mathbb{R}$ is lower semi-continuous then attains its minimum on $[0,1]$","Let $f: [0,1]\to \mathbb{R}$ be a lower semi-continuous function, then $$ \liminf_{x\to a} f(x) \geq f(a), \forall a \in [0,1]$$ I have to prove that $f$ attains its minimum on $[0,1]$, that is: $\exists x_0 \in [0,1]$ such that $f(x_0) \le f(x)$, $\forall x \in [0,1]$. This is a problem from a past qualifying exam in Measure Theory. I'm trying to solve it but I do not know how I should begin with this problem. I did not understand where the Inf is taken. What means that limit?","['continuity', 'real-analysis']"
2412671,"Show that if $f$ is uniformly continuous and is Lebesgue integrable on $\mathbb{R}$, then $\lim_{|x| \to \infty}|f(x)| = 0$","Show that if $f: \mathbb{R} \to \mathbb{R}$ is uniformly continuous such that $$\int_{-\infty}^{\infty}|f(x)| < \infty \Rightarrow \lim_{|x| \to \infty}|f(x)| = 0$$ I already try this but I'm not sure it works: Consider $$A_n = \{x \in \mathbb{R}: |f(x)| \geq n \}$$ Then $$m(A_n)n \leq \int_{A_n}|f(x)| \leq \int_{\mathbb{R}}|f(x)| < \infty$$ Hence, $$m(A_n) \leq \frac{1}{n}\int_{\mathbb{R}}|f(x)| < \infty$$ Thus, $$\lim_{n\to \infty}m(A_n) = 0 = m(\cap_{n = 1}^{\infty}A_n)$$ Therefore, $m(\{x \in \mathbb{R}: |f(x)| = \infty\}) = 0$ Did this implies that $f$ goes to 0 as $|x| \to \infty$? I don't think so. I was wondering if I can use another approach using the fact that it is lebesgue integrable and uniformly continuous. Then the integral of $f$ is the near the integral of a simple function that is bounded and vanish outside a set of finite measure, but I do not know how to attack this problem using this approach.","['uniform-continuity', 'real-analysis', 'lebesgue-integral', 'limits']"
2412722,Average shortest distance between some random points in a box,"Suppose there is a square box with side length $m$ (measured in pixels). Let there be $n$ points in this box, distributed uniformly within the box (with integer coordinates, aligned to a pixel grid). If we take from each point the Euclidean distance to its nearest neighbor, what would be the expected value of this distance averaged over all points? My actual problem is about a discrete pixel grid, an $m\times m$ bitmap image, but if that's easier I would be happy with a continuous solution. A more general solution e.g. for a rectangle instead of a square box is welcome, but at this point it is not necessary. I found similar questions about the continous case, but without answers. For me it wouldn't be easy to generalise the case for two points only.","['geometric-probability', 'euclidean-geometry', 'probability', 'uniform-distribution', 'discrete-mathematics']"
2412749,The definition of absolute continuity without disjointness of intervals is satisfied only by Lipschitz functions,"A function $f: [a,b] \rightarrow \mathbb{R}$ is Lipschitz continuous if and only if $\forall \epsilon >0, \exists \delta>0$ such that for every finite collection of closed intervals in $[a,b]$, $\{[a_k,b_k]\}_{k=1}^N$ (not necessarily disjoint) with $\sum_{k=1}^N b_k-a_k < \delta$ then $\sum_{k=1}^N |f(b_k)-f(a_k)|<\epsilon$ The easy part is to prove that a Lipschitz function satisfy the property. But I'm having trouble with the other part. I tried to mimic the proof that $\sqrt{x}$ does not satisfy the property with not necessarily disjoint intervals but unfortunately I got stuck. I saw this exercise on chapter 5 of Bruckner, real analysis. I would really appreciate any hints or suggestions.","['real-analysis', 'absolute-continuity', 'continuity', 'measure-theory', 'lipschitz-functions']"
2412804,Examples of inner products on a polynomial vector space,"So far, I have only seen examples like the following: $$
\langle p, q \rangle = \int_0^1 p(x)q(x)\ dx,
$$ where $p$ and $q$ are elements (polynomials) of a finite-dimensional polynomial vector space. I'm wondering if there other kinds of inner products involving polynomials, without involving integrals or more interesting ones of the same kind.","['linear-algebra', 'inner-products']"
2412810,Can we approximate any open set by sub-domains with smooth boundary?,"In some books, mainly about PDEs, I read that any open set can be approximated by sub-domain with smooth boundary  (not just piecewise smooth). In 1 dimensional case, this seemly to be quite trivial: for any subdomain, use small open balls to cover its boundary and then mollify the connection parts. But in the higher dimensional case, I think this is not that obvious. So the first question is:  how can we approximate any open set by sub-domain with smooth boundary? And the second question is: In what meaning the approximation is? Pointwise, i.e., we can find subdomain $D_n$ with smooth boundary such that $D_n\uparrow A$? uniformly pointwise? Or in the Lebesgue measure sense? etc.","['sobolev-spaces', 'differential-geometry', 'differential-topology', 'partial-differential-equations']"
2412814,gramian matrix and trace relationship,"Suppose $M$ is an $n \times m$ incidence matrix of a simple graph $G$ with $n$ vertices and $m$ edges. 
As an exercise in my graph theory course, we proved the diagonals of $M^T M$ equal $2$ for any simple graph. While determining whether I actually believed this or not using NumPy, I stumbled upon a larger idea that exposed a lack of my understanding in Linear Algebra. For any $n \times m$ matrix $A$ I speculate that, 
$$tr(A^TA) = \sum_{i = 1}^{n}\sum_{j = 1}^{m}a_{ij}^2$$ Which now makes me think of trace as a function describing the ""size"" of a matrix i.e. when performing a matrix vector product how small or large can we expect differences to be in our resultant vector from different perturbations of input vectors? Is my assumption wrong? If not, is there any intuition on why this is true? I'm not satisfied with the thought that ""the math just works out"".","['matrices', 'trace', 'intuition', 'linear-algebra']"
2412828,"Solve $ \int_0^2 \sqrt{x+\sqrt{x+\sqrt{x+\dotsb}}}\,dx $","I haven't seen this question, but if someone has, it would be very appreciated if you could send a link! I've been very interested in the MIT Integration Bee, and one question that stood out to me was: $$ \int_0^2 \sqrt{x+\sqrt{x+\sqrt{x+\dotsb}}}\,dx $$ I tried rewriting a couple of ways to simplify it, but nothing seemed to help. According to the official MIT Integration Bee website, the answer is $$ \frac{19}{6} $$ Thanks!","['nested-radicals', 'integration', 'definite-integrals']"
2412841,How to prove this property of parabola using geometry?,"Tangents are drawn from a point A to a parabola. These tangents touch the parabola at points B and C. Now, if we draw a tangent to the parabola on a point D (on the parabola) such that it intersects AB at P and AC at Q. Then $$\frac{\mathrm{AP}}{\mathrm{AB}}+\frac{\mathrm{AQ}}{\mathrm{AC}}=1$$ I proved this using analytical approach (Taking parabola $y^2=4ax$ , and other points accordingly) and succeeded. But I tried lot but couldn't prove this geometrically. Can you please give me hint on how to approach this proof geometrically. I am currently working and have proceeded this much. $$\frac{\mathrm{AP}}{\mathrm{AB}}+\frac{\mathrm{AQ}}{\mathrm{AC}}=
\frac{\mathrm{AP \cdot AC}+\mathrm{AB \cdot AQ}}{\mathrm{AB \cdot AC}}=\frac{\mathrm{\dfrac{1}{2}\sin ({A})\cdot AP \cdot AC}+\mathrm{\dfrac{1}{2}\sin ({A}) \cdot AB \cdot AQ}}{\mathrm{\dfrac{1}{2}\sin ({A})  \cdot AB \cdot AC}} =\frac{\operatorname {Ar.}(\Delta APC)+\operatorname {Ar.}(\Delta AQB)}{\operatorname {Ar.}(\Delta ABC)}$$ Therefore, what remains to prove is $$\operatorname {Ar.}(\Delta APC)+\operatorname {Ar.}(\Delta AQB)=\operatorname {Ar.}(\Delta ABC)$$ Which is same as proving $$\operatorname {Ar.}(\Delta AQB)=\operatorname {Ar.}(\Delta BPC)$$ Thanks.","['conic-sections', 'geometry']"
2412887,Showing $f=0$ almost everywhere.,"let $f\in L^2(\mathbb{R},\mathcal{L},m) $, and suppose that 
  $$\int_\mathbb{R}f(y)e^{-(x-y)^2/2}dy=0$$ for all $x\in\mathbb{R}$. Prove that $f=0$ a.e. I can say 
$$f*g(x)=\int_\mathbb{R}f(y)e^{-(x-y)^2/2}dy=0,$$ where $g=e^{-x^2/2}$. Hence, $\widehat{f*g}=0$. Now I'm not sure if it's good enough to say $\widehat{f*g}=\hat{f} \cdot \hat{g}$. As a result, if $\hat{g}\neq 0$, then $\hat{f}=0$ and then $f=0$. Is it a valid argument?","['real-analysis', 'fourier-analysis', 'analysis', 'fourier-transform']"
2412912,On Hahn-Banach Theorem,"The following is the first part of a proof for Hahn-Banach Theorem (Extension of linear functionals) from Kreyszig's book of Functional Analysis: I don't undertsand the blue-underlined sentence of the text above. My questions are: 1- How each $D(g)$ is a vector space? Suppose $x_1, \ x_2 \in D(g)$ then $g(x_1) \le p(x_1)$ and $g(x_2) \le p(x_2)$. Then $g(x_1+x_2) = g(x_1)+g(x_2) \le p(x_1)+p(x_2)$ does not imply $g(x_1+x_2) \le p(x_1+x_2)$, because we have $p(x_1+x_2)\le p(x_1+x_2)$ by definition. So How $x_1+x_2 \in D(g)$?! The book has considered $a \ge 0$, so $g(ax) = ag(x) \ge ap(x)$. So the problem is just the sum inequality. 2- How $\bigcup D(g)$ is a vector space because ""$C$ is a chain""? I can't see a coonection.","['functional-analysis', 'proof-explanation']"
2412914,Calculating expected value of sample standard deviation [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How do we calculate $$ \begin{align}E[S]&=E\left[\sqrt{\frac{1}{n-1}\sum_i(x_i-\bar{x})^2}\right]\\&=E\left[\sqrt{\frac{1}{n-1}} 
 \sqrt{\sum_ix_i^2-n\bar{x}^2}\right]. \end{align}$$ I am asking this question out of curiosity mostly because it is easy to show that $E[S^2]=\sigma^2$ but not so easy to calculate this.",['statistics']
2412942,Express covariant derivative in terms of exterior derivative,"I know there is an intimate relation between covariant, Lie and exterior derivative. I know that the covariant derivative requires more structure than the exterior, so it would be possible.
How do I express a covariant derivative $\nabla_{X} Y$ in terms of the exterior derivative, assuming the Levi-Civita connection?","['exterior-derivative', 'differential-geometry', 'exterior-algebra']"
2412959,Pointwise convergence implies convergence in $L^p$?,"In this question a user asks if pointwise convergence implies convergence in $L^p$. I would have thought that the answer is yes. I am not experienced with measure theory, which is how that question is framed. The following statement seems to assert that p.w. convergence implies convergence in $L^p$:
$$
\lim_{n\to \infty} ||f_n - f||_{L^p(\Omega)}^p = \lim_{n\to \infty} \int_\Omega |f_n(x)-f(x)|^p dx = \int_\Omega |\lim_{n\to \infty} f_n(x)-f(x)|^p dx = \int_\Omega |0|^p dx = 0.
$$
But the answers to the other post say that p.w. convergence does not imply convergence in $L^p$, so what am I missing?","['functional-analysis', 'lp-spaces']"
2412975,Why are infinite dimensional spaces understood in terms of Cauchy Sequences?,"I am physicist, learning functional analysis. Why is that separability, completeness etc... Is spoken in terms of Cauchy Sequences for infinite dimensional vector spaces?
I cannot get the intuition behind it.","['functional-analysis', 'sequences-and-series', 'education']"
2412986,How is continuity different between a sequence of points in $\mathbb{R}^n$ and a sequence of functions in a function space?,"For any continuous function $f(x)$ we have that
$$
(*) \quad \quad \lim_{x\to x_0} f(x) =  f(\lim_{x\to x_0}x) = f(x_0).
$$
Because of this, I always believed that by the continuity of the norm function, for a sequence of functions $f_n$ converging to some function $f$, that we could say
$$
(**) \quad \quad \lim_{n\to \infty} ||f_n||_p =  || \lim_{n\to \infty} f_n||_p = ||f||_p.
$$
So is there a difference between $(*)$ and $(**)$? Are we not allowed to perform the switching of limits in $(**)$, even though the norm is continuous? On a related note I also always thought we could do the following for a sequence of functions in a Hilbert space:
$$
\lim_{n\to \infty} \langle f_n, g \rangle = \langle   \lim_{n\to \infty} f_n, g \rangle = \langle f, g \rangle.
$$
Is this also not true?","['functional-analysis', 'normed-spaces', 'real-analysis', 'measure-theory']"
2412993,Given the invertible matrix $A$ so that $A+A^{-1}=2I_n$,"Given the invertible matrix $A$ so that $A+A^{-1}=2I_n$, which of the following equalities stand true? 1)$A=3I_n$ 2)$A^3+A^{-3}=2I_n$ 3)$A=-A$ 4)$A^2+A^{-2}=I_n$ 5)$A-A^{-1}=2I_n$ I know the formula for $A^{-1}$, but I'm not sure if and how should I use it 
here or what else should I apply. Could I have some hints on how to approach this? Thank you","['matrices', 'inverse']"
2413042,Equivalence of two multisets of natural numbers,"I want to show that the two multisets of natural numbers given by : $\{4m^2+(2n+1)^2\}$ for $m,n \in \mathbb{Z}_{\ge 0}$ and $\{2(k+l+1/2)^2+2(l+1/2)^2\}$ for $k,l \in \mathbb{Z}_{\ge 0}$ are equal as multisets (i.e. allowing repetitions). These two multisets arise as spectra of some domains that I suspect to be isospectral. One can compute the first few elements, they both start out with $\{1,5,9,13,17,25,25,29, ... \}$ and numerically they agree further along as well. My first approach was to assume that $m,n$ can be written as linear combinations of $k,l$ and vice versa but if such a transformation exists, the $2$-by-$2$ matrix would have to have only positive integer entries and its inverse would have to have only positive integer entries as well and the only matrices with these properties are permutation matrices which don't work here.","['algebra-precalculus', 'elementary-number-theory', 'combinatorics', 'quadratic-forms', 'discrete-mathematics']"
2413060,Prove that $DG+HE=GH$ for the given figure.,"What I could gather: $$\measuredangle ODB=\measuredangle OFC=\measuredangle OEC =90 \text{ degrees}$$
$$OD=OF=OE=r$$
$$\measuredangle ODE=\measuredangle OED$$
$$\measuredangle DOE=2\measuredangle DME$$","['geometric-transformation', 'euclidean-geometry', 'projective-geometry', 'geometry']"
2413062,Why only orientation-preserving transformations are considered when integrating forms?,"The volume form is known to be invariant under a change of coordinates $T$ with $\det(T)>0$, so consequently integral of forms are also invariant. But what happens when the change of coordinates has $\det(T)<0$? Is the integral invariant under transformations with negative determinant? In Calculus of one variable, when the determinant is negative one would just reverse the limit of integration, why we don't do the same when dealing with forms? In Calculus of multivariable, the absolute value of the determinant is taken, so I guess my question is related to why there's an absolute value there (is it put by hand or does it show up naturally?).","['differential-forms', 'change-of-basis', 'integration', 'differential-geometry']"
2413065,Alternative(?) definition for normalizer [duplicate],"This question already has answers here : Conjugate subgroup strictly contained in the initial subgroup? (4 answers) Closed 6 years ago . Let $G$ be a group and $H$ be a subgroup. Consider the following set:
$$\hat{N}(H):=\left\{g\in G: g^{-1}Hg \subset H\right\} $$
The normalizer of $H$ is usually defined as
$$N(H):=\left\{g\in G: g^{-1}Hg=H\right\} $$
My question is: are these two sets equal?
If $H$ is finite, then the answer is certainly positive. The map $x\mapsto gxg^{-1}$ is an injective map from $H$ onto $H$, so if $H$ is finite, it is also invertible. Thus $g^{-1}Hg\subset H$ implies $g^{-1}Hg=H$, and $\hat{N}(H)=N(H)$. In the general case, my guess would be no. The normalizer is a subgroup of $G$, whereas $\hat{N}(H)$ possibly isn't. While $1 \in \hat{N}(H)$ and $g,h \in \hat{N}(H)\Rightarrow gh \in \hat{N}(H)$, if $g\in \hat{N}(H)$ i cannot deduce that $g^{-1}\in \hat{N}(H)$. 
I couldn't find any counterexample, though. I know that $H$ would have to be infinite and nonabelian (otherwise $g^{-1}Hg=gHg^{-1}$). I tried to use some subgroups of $\operatorname{GL}_2(\mathbb{C})$, but all the ones I could construct had the whole $\operatorname{GL}_2(\mathbb{C})$ as their normalizer.","['abstract-algebra', 'group-theory']"
2413067,Can purchase of insurance be justified mathematically? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Improve this question When I ask people to explain why they buy insurance, I often hear vaguely of ""spreading the risk"", but I am not actually sure what that means nor if insurance does this. How is an insurance company any different than a casino? In a thought experiment where some large number of people who purchase insurance are compared against an equal number of people who do not, it seems to me when one takes into account the cost of insurance, the people who do not purchase it end up better financially than those who do not. It is argued that insurance is needed to protect against catastrophic events but isn't poverty in old age a catastrophic event also? I realize that these are not strictly mathematical questions but at its base, insurance must be either a good or bad choice based on statistics and probability. EDIT: More succinctly: Buying insurance is making a bet with a negative expectation. If there is some way to justify this mathematically then are there other bets with negative expectation, like buying lottery tickets or roulette that can be justified and how? EDIT: People are saying, this is not a mathematical question but the question: Is a person likely to be better off financially if the buy insurance is a pretty mathematical question. If you took 100 people and half bought insurance and the other did not, which group would have more money at the end of some period, is mathematical. I can answer this question about any negative-expectation betting, so why is insurance any different?","['finance', 'probability', 'actuarial-science']"
2413114,Can I get an example of a function that satisfies the finite dimensional MPT?,"The finite dimensional Mountain Pass Theorem states:
Theorem (Finite Dimensional MPT, Courant). Suppose that
ϕ ∈ C1(Rn,R) is proper and possesses two distinct strict relative
minima x1 and x2. Then ϕ possesses a third critical point x3 distinct
from x1 and x2, characterized by
ϕ(x3) = inf Σ∈Γmax x∈Σ ϕ(x)
where Γ = {Σ ⊂ Rn;Σ is compact and connected and x1,x2 ∈ Σ} By proper Courant means the function is coercive. So I am trying to find a finite dimensional function that has two minima and is coercive for my thesis so I can study it and write an algorithm to find the saddle point. As a side question I don't particularly understand what the inf max means. I think it's the smallest of the maximums but I'm not really sure. Thank you for taking the time to read this question and taking the time to help me.","['functional-analysis', 'multivariable-calculus']"
2413134,Finding the minimum value of $a^2+b^2+c^2$ [duplicate],"This question already has answers here : How to prove $a^2 + b^2 + c^2 \ge ab + bc + ca$? (12 answers) Closed 6 years ago . Let $a$, $b$ and $c$ be $3$ real numbers satisfying $2 \leq ab+bc+ca$. Find the minimum value of $a^2+b^2+c^2$. I've been trying to solve this, but I don't really know how to approach this. I thought of $(a+b+c)^2 = a^2+b^2+c^2 + 2(ab+bc+ca)$, but that gives me  $a+b+c$, which is unknown. How can I solve this?","['inequality', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality', 'algebra-precalculus', 'maxima-minima']"
2413199,How to determine if a $\lim\limits_{n \rightarrow \infty}{(1+{ix\over n})^n}$ would be complex [duplicate],"This question already has answers here : Do the polynomials $(1+z/n)^n$ converge compactly to $e^z$ on $\mathbb{C}$? (3 answers) How to prove Euler's formula: $e^{i\varphi}=\cos(\varphi) +i\sin(\varphi)$? (17 answers) Closed 6 years ago . Question Recently, I have been looking at complex limits, The most famous being $e^{ix}$=$\lim\limits_{n \rightarrow \infty}{(1+{ix\over n})^n}$. An example would be that when $x = \pi$ we know that the answer will be -1. But how do you determine this due to the fact that you can always $+1$ which will determine the outcome. I am fully aware that you are able to do this via the $i\cdot \sin(a \ln b) +\cos(a\ln b)$ however, how can you prove this via a limit, because if you test it on a calculator, most of the time you'll end up with some imaginary part. Specifically I have been looking at the representation of $\sin x={ie^{-ix}\over 2}-{ie^{ix}\over 2}$. Everyone would be safe to assume that $\sin x$ is always real, but when you apply a limit then how can you determine if it is only real or imaginary and real?","['exponential-function', 'complex-numbers', 'limits']"
2413202,A good substitution to prove $\frac{f(b)-f(a)-(b-a)f'(a)}{g(b)-g(a)-(b-a)g'(a)}=\frac{f''(c)}{g''(c)}$. [duplicate],"This question already has an answer here : Prove that $a<c<b$, $\frac{f(b)-f(a)-(b-a)f'(a)}{g(b)-g(a)-(b-a)g'(a)}=\frac{f""(c)}{g""(c)}$ (1 answer) Closed 6 years ago . Let $f'(x)$ and $g'(x)$ satisfy the hypothesis of mean value theorem, then prove that $$\frac{f(b)-f(a)-(b-a)f'(a)}{g(b)-g(a)-(b-a)g'(a)}=\frac{f''(c)}{g''(c)}$$ where $g''(c)\neq 0$. I have tried various things like Cauchy MVT with $f'(x)$ and $g'(x)$, substituting $h(x)=\dfrac{1}{g'(x)}$ ,$h(x)=f'(x)+\dfrac{a}{g'(x)}$ where $a\in\mathbb{R}$, but it didn't lead anywhere. Any help will be appreciated. Please note that I am allowed to use only Cauchy's MVT , LMVT and Rolle 's theorem.","['derivatives', 'calculus']"
2413232,Problem in understanding module complements,"Let $A$ be a $\mathbb{K}$ -algebra and $M$ be an $A$ -module, $N \subset M$ be a submodule. A module complement of $N$ is defined as a submodule $N'\subset M$ so that $M = N \oplus N'$ . Now in our lecture we defined a semisimple $A$ -module as an $A$ -module so that for every submodule exists a module complement. But isn't that a trivial property that is true for all $A$ -modules, because of this: $M \cong N \oplus M / N$ , where $M / N$ is an $A$ -module by the operation $a.(m+N)=a.m+N$ for $a \in A$ , $m+N \in M/N$ , so $M/N$ is always a module complement of $N$ ?","['abstract-algebra', 'modules', 'representation-theory']"
2413237,How to prove this identity involving the series $\sum_{m=1}^\infty \frac{\sin m\theta}{\sinh m u}$?,"In Methods of Mathematical Physics by Jeffreys and Jeffreys I have found this absolutely fascinating exercise (which is from the Cambridge Mathematical Tripos for 1938): By expressing $\sin m\theta$ and $\sinh mu$ in terms of exponentials, prove the identity $$
\sum_{m=1}^\infty \frac{\sin m\theta}{\sinh m u}=\sum_{n=1}^\infty \frac{\sin\theta}{\cosh(2n-1)u-\cos\theta} \quad(u>0,\theta\text{ real}).
$$ (p. 55 of the 3rd edition) As I have never encountered such series before, this one has given me quite some difficulty. I half suspect that there is some clever trick involving the geometric series that I've missed. But even after much fiddling around I can't seem to crack it. Any help would be much appreciated.","['sequences-and-series', 'analysis']"
2413255,Example of an integral domain which is not a field,I just proved that a commutative ring $R$ is an integral domain iff $R$ is isomorphic to a subring of a field. My question is why can't $R$ be a field with these conditions? Aren't we satisfying all of the field's properties? Thanks.,"['abstract-algebra', 'ring-theory', 'ring-isomorphism', 'integral-domain']"
2413266,Help Calculation of $\sum_{k=1}^{\infty} \frac{k^{2n}}{e^k -1}$,"Recently, I read a book : Euler, Riemann, Ramanujan - Contact mathematician beyond the space-time by Nobushige Kurokaw. It says that Ramanujan had found the following formula $$\sum_{k=1}^{\infty} \frac{k}{e^{2k \pi}-1}=\frac{1}{24}-\frac{1}{8\pi}$$ After few month, I succeeded in finding similar formula using Euler-Maclaurin Formula: $$\sum_{k=1}^{\infty}\frac{k}{e^k -1}=\frac{{\pi}^2}{6}-\frac{11}{24}$$
$$\sum_{k=1}^{\infty}\frac{k^{2n-1}}{e^k -1}=\frac{\left| B_{2n}\right|}{4n}((2\pi)^{2n}+(-1)^{n+1}) \quad when \quad n>1$$ I wonder if we can generalize te following formula : $$\sum_{k=1}^{\infty}\frac{k^{2n}}{e^k -1}$$ I tried with various ways, but I failed. Please answer back users~~~ PS. It's first time that I answer a question on this site. So I could have made some mistakes while writing....","['summation', 'sequences-and-series', 'calculus']"
2413267,Understanding SVD Notation,"Given any $m \times n$ matrix $M$, one can write
$$
M = U\Sigma V^T
$$
 is the Singular Value Decomposition, where $U$ and $V$ are orthonormal and $\Sigma$ is a diagonal matrix. Now, the same $M$ can be written as: $$M = \sum_{i=1}^r u_i  c_i  v_i^T\,,$$ where $u_i$ is the $i$th column of $U$, $v_i$ is the $i$th column of $V$ and $c_i$ is the $i$th diagonal entry of $\Sigma$. I don't understand why the second representation is the same as first one? In general, how could matrix multiplication be expressed as product of columns, I have learnt that matrices are multiplied row by column. This is the only way even Profs do, so how can a matrix multiplication be expressed as only involving column vectors? Sorry if the question is too basic, but I am having lot of trouble understanding how people are using column vectors in matrix multiplications.","['matrix-equations', 'matrices', 'matrix-decomposition', 'svd', 'linear-algebra']"
2413270,WDVV equation and the Seiberg-Witten prepotential,"I'm trying to understand the derivation of a pretty well-known formula (4.15) in https://arxiv.org/pdf/hep-th/9701123.pdf , namely
\begin{equation}
\frac{\partial^3 \mathcal{F}}{\partial a_I\partial a_J\partial a_K} = Res_{d\omega = 0}\frac{dW_IdW_JdW_K}{d\omega d\lambda}.
\end{equation}
Where $\mathcal{F}$ is the Seiberg-Witten prepotential, $a^D_I = \partial \mathcal{F}/\partial a_I$. $dW_I$ are normalised basis 1-form on the SW curve, $dW_I = (\partial/\partial a_I)dS_{SW}$. The Seiberg-Witten differential is given by $dS_{SW} = \lambda d\omega, d\omega = dw/w$. The Seiberg-Witten curve is defined by $\mathcal{P}(\lambda,w) = (w + 1/w) - P_N(\lambda) = 0$. I managed to follow the derivation up to (4.13)
\begin{equation}
\frac{\partial dv_L}{\partial s_M} = -\Big[\Big(\frac{(\partial \mathcal{P}/\partial s_M)(\partial \mathcal{P}/\partial s_L)}{\mathcal{P}'} -
 \frac{\partial^2\mathcal{P}}{\partial s_M\partial s_L}\Big)\Big]\frac{d\omega}{\mathcal{P}'}
\end{equation}
where $\{s_I\}$ is the moduli space coordinates and $dv_I = (\partial/\partial s_I) dS_{SW}$. However I don't understand the next step which is to substitute this result back into (4.11). Assuming I don't care about $\Sigma_{KLM}$ part for now(?), (it is zero if all $b$-periods are closed and I'm happy with that assumption), how do I show that 
\begin{equation}
Res (du_K \frac{\partial v_L}{\partial s_M}) = -Res_{d\omega = 0}\frac{(\partial \mathcal{P}/\partial s_K)(\partial \mathcal{P}/\partial s_L)(\partial \mathcal{P}/\partial s_M)}{(\mathcal{P}')^3}\frac{d\omega^2}{d\lambda}?
\end{equation}
I think my main problem is I don't know how to integrate $\partial dv_K/\partial s_M$ to get $\partial v_L/\partial s_M$.","['residue-calculus', 'complex-analysis', 'riemann-surfaces', 'differential-geometry']"
2413273,Trying out Green functions in simple context,"I am a physics student, and have had to use Green's function methods prior (in electrodynamics for example), but things were always badly explained. Now I am trying to brush up on things a bit and figured I'd try to solve some very simple ODEs (that can be otherwise integrated). Problem is I am not getting sensible results, and I don't even know how can I incorporate boundary conditions into the problem. Example calculation: Consider the linear ODE $ f'+\alpha f=g $ where $\alpha$ and $g$ are constants. The linear operator is then $$L=\frac{d}{dx}+\alpha,$$ moreover, since this is a translation-invariant operator, we will have $G(x,x')=G(x-x')$. Let's assume initial conditions are given by $f(0)=Q$. Then this equation can be integrated to give $$ f(x)=\left(Q-\frac{g}{\alpha}\right)e^{-\alpha x}+\frac{g}{\alpha}. $$ Now I'll try to solve this ODE using a Green's function method. Let $G(x-x')$ be the Green's function satisfying $$ L_{(x)}G(x-x')=\delta(x-x'), \\ \frac{d}{dx}G(x-x')+\alpha G(x-x')=\delta(x-x'). $$ I have no idea how to proceed, so I'm gonna take a Fourier transform. I have no idea if it is even well defined here or not, but physicists have done worse: $$ G(x-x')=\int G(k)e^{-ik(x-x')}\ dk, \\ \delta(x-x')= \int\frac{1}{2\pi}e^{-ik(x-x')}\ dk.$$ I get the following for Fourier-components: $$ (\alpha-ik)G(k)=\frac{1}{2\pi}, $$ so $$ G(x-x') =\frac{1}{2\pi}\int\frac{1}{\alpha-ik}e^{-ik(x-x')}\ dk.$$ This integral doesn't converge but I don't worry, as $G$ might just be a singular distribution. Instead, we have $$ f(x)=\int G(x-x')g\ dx'=\frac{g}{2\pi}\int dk\frac{1}{\alpha-ik}e^{-ikx}\int dx'e^{ikx'} \\ =g\int dk \frac{1}{\alpha-ik}e^{-ikx}\delta(k)=\frac{g}{\alpha}. $$ This certainly provides a solution of the equation, but not what I want. And I'm not surprised it didn't work, I didn't specify initial/boundary conditions. Probably when I took the Fourier transform, I accidentally gave some bogus boundary conditions, like $f$ should be zero in infinity or something, but I don't know. Question: What went wrong? I assume initial/boundary conditions, but how can I control them? How can I specify what initial/boundary conditions do I want? How do I find Green's function for proper initial/boundary conditions? Was taking the Fourier transform the wrong move there?","['boundary-value-problem', 'greens-function', 'ordinary-differential-equations', 'fundamental-solution']"
2413285,Surjectivity of the derivative of $A \mapsto A^t A$.,"I'm trying to solve this problem, but when I calculate the derivative of $\Phi$ I get $$(D\Phi)_A (H) = A^t H + H^t A.$$ In particular, the derivative at identity is $H + H^t$. But this can't be surjective as $(2)$ states as it would imply every matrix in $GL(n;\mathbb{R})$ is equal to its transpose.","['derivatives', 'matrix-calculus', 'differential-geometry']"
2413325,How to Interpret Matrices,"It seems to me that a m x n matrix can be interpreted in two ways: a collection of m points, each in n-dimensional space. In this case, a point is a row vector. a collection of n points, each in m-dimensional space. In this case, a point is a column vector. I see in some places they interpret a matrix as 1 and in some places as 2. This causes the notations to be different and makes a lot of thing confusing, at least for me. Add to this the interpretation of a matrix as a linear transformation and things become more confusing. I have a few questions, all on the same theme: What is the standard way to interpret matrices? How to reconcile the notations? For example, If I know some theorem for which I had done the derivation understanding a row to be a point and then in some place it says apply the theorem considering a column to be a point. Is there any trick to understand or write equations that makes the two interpretations equivalent? And finally, are the two interpretations equivalent? Sorry if this is too trivial but this thing seems really confusing.","['matrix-equations', 'matrices', 'matrix-decomposition', 'statistics', 'linear-algebra']"
2413331,Triple Integral With Spherical Coordinates - Napkin Ring?,"I wish to calculate the integral bellow, where $T$ is the region bounded by $x^2 + y^2 = 1$ and $x^2 + y^2 + z^2 = 4.$ It looks to me that it represents a Napkin ring.
$$\iiint_T\bigl(x^2 + y^2\bigr)\,\text{d}V.$$
The answer is $\dfrac{\bigl(256 - 132\sqrt{3}\,\bigr)\pi}{15}.$","['volume', 'multivariable-calculus', 'integration', 'definite-integrals', 'spherical-coordinates']"
2413359,Can every domain be exhausted by compact *connected* subsets?,"Let $D \subset \Bbb R^n$ be an open connected set. I would like to exhibit an increasing sequence of compact connected subsets of $D$ converging to $D$. For example, for a ball we might take a sequence of closed ball inside it of radius $r-\frac 1n$. User SteamyRoot showed that the usual closed exhaustion that generalizes the above example, given by $D_n = \{ x\in D: \mathrm{dist}(x, \partial D) \geq \frac 1n \}$ is not always connected (by considering the shape of eye-glasses), even before modifying it to be bounded. Considering an infinite sequence of glasses connected to one another in a row that are smaller and smaller shows that this will not be connected no matter how small we choose $n$. We also cannot do this by taking the union of all closed squares of side length $2^{-n}$ contained entirely within $D$. This is again not connected because of the same counterexample (infinite glasses), even though this example does have such an exhaustion.","['general-topology', 'metric-spaces']"
2413394,prove ABCD is also a square,"What we know is that: 1. ABCD is a quadrilateral. 
2. The red area is a square. 
3. AH=BE=CF=DG The question is prove that ABCD is also a square.
I have realised that the four triangles here AHG, DGF, EFC and HBE have the same length hypotenuse and also AH = DG = CF = BE, so if I can prove ∠ A, B, C, D are 90°, then four triangles are congruent. Then I will know that four sides, AB,BC,CD,DA are the same length then I can prove it. 
The problem is that I dont know how to prove angle A,B,C,D are 90 degree. 
Thanks!",['geometry']
2413396,What is the connection and the difference between the Golden Ratio and Fibonacci Sequence?,"The Golden Ratio, i.e. $\varphi = \frac{1+\sqrt{5}}{2}$ and Fibonacci sequence, i.e. $F_n=F_{n-1}+F_{n-2}$ with the initial conditions $F_0=0$ and $F_1=1$ are clearly connected, but not perfectly so, and I'm seeking to understand this. I've been trying to read up a bit to understand the similarities and differences between these 2. A Live Science article, for instance, says: Around 1200, mathematician Leonardo Fibonacci discovered the unique
  properties of the Fibonacci sequence. This sequence ties directly into
  the Golden ratio because if you take any two successive Fibonacci
  numbers, their ratio is very close to the Golden ratio. As the numbers
  get higher, the ratio becomes even closer to 1.618. For example, the
  ratio of 3 to 5 is 1.666. But the ratio of 13 to 21 is 1.625. Getting
  even higher, the ratio of 144 to 233 is 1.618. These numbers are all
  successive numbers in the Fibonacci sequence. Or, as another source put it: The quotient of any Fibonacci number and it's predecessor approaches
  Phi, represented as ϕ (1.618), the Golden ratio. Based on these descriptions, it sounds like the the ratio of consecutive Fibonacci numbers and the Golden Ratio converge asymptotically but are not identical (especially with the initial ratios). I would like to understand this a little bit better. Asides from Live Science and Google, I did some preliminary research on Mathematics SE and Cross Validated. The closest question I could find was an unanswered one which primarily focused on the relationship between Arctangents and the Fibonacci sequence.","['golden-ratio', 'fibonacci-numbers', 'trigonometry']"
2413418,A contour integral and the residue theorem for infinitely many singularities,"Consider the following integral $$\int_0^{\infty}\frac{1}{1+x^\alpha}dx, $$
where $\alpha > 1$. In the case where $\alpha$ is an integer, one can show, as I do below, that the integral evaluates to $\frac{\pi}{\alpha}\csc(\pi/\alpha)$. However, I think the integral evaluates to the same expression even for non-integer $\alpha$. I distinctly recall checking this on wolfram alpha, but now the calculation seems to require additional computation time, which I don't have. Maybe someone can check? Anyway, for integer $\alpha = n \geq 2$, let $$f(z) = \frac{1}{1+z^\alpha} = \frac{1}{1+z^n}, $$
and consider the contour integral $$\int_{\gamma}f(z)dz, $$
where $\gamma$ is a wedge shaped contour of radius $R$, opening angle $2\pi/n$ and one of its sides on the $x$-axis (I hope this is clear!). It's trivial to show that the contribution from the circular segment vanishes when $R \to \infty$. Let $$I = \int_0^R \frac{1}{1+x^n}dx.$$ The path for the remaining contribution can be parametrized as $z(t) = te^{i2\pi/n}$, where $t$ goes from $R$ to $0$. The corresponding integral is $$\int_R^0\frac{1}{1+(te^{i2\pi/n})^n}e^{i2\pi/n}dt = -e^{i2\pi/n}I.$$ In the limit $R \to \infty$, we then have $$\int_{\gamma} f(z)dz = (1-e^{i2\pi/n})I.$$ It is also clear that $f$ has a single singularity inside $\gamma$, namely at $z = e^{i\pi/n}$. One finds that the residue is $-e^{i\pi/n}/n$, and by the residue theorem, we get $$\int_0^\infty \frac{1}{1+x^n}dx = (\pi/n)\csc(\pi/n).$$ Questions Is the generalization to non-integer $\alpha$ true? If true, how do we prove it? Regarding point 2, I remember I tried to generalize the argument some time ago. The problem is of course that that $f$ will have (countably) infinitely many singularities $z_k = e^{i\pi(2k+1)/\alpha}$, with $k \in \mathbb{Z}$. Can we apply the Residue Theorem in this scenario?","['complex-analysis', 'residue-calculus']"
2413449,$g^*(\mbox{d}x) = \mbox{d}x \circ g^{-1}$ for $g$ an isometry,"Suppose $(M,\gamma)$ is a Riemannian manifold, $g$ an isometry, $\mbox{d}x$ the Riemannian volume form on $(M, \gamma)$. I can't really understand these formulae, sometimes found in literature. First, \begin{equation}\tag{1}
g^*(\mbox{d}x) = \mbox{d}x\circ g^{-1}.
\end{equation} Next, let $f : M \to N$ be a smooth function (here, $g$ can be seen as an element of a group $G$ acting by isometries in some specified way on both $M$ and $N$); sometimes I find \begin{equation}\tag{2}
\vert{\mbox{d}(g \circ f)}\vert^2 = \vert \mbox{d}f\vert^2 \circ g^{-1}.
\end{equation} I can't catch the precise meaning of the rhs. I know what the operations involved are (pullback, exterior derivative, commutation property of pullback and exterior derivative, differential, chain rule...); my problem concern what one precisely means when writing a thing such as $g^*(\mbox{d}x) = \mbox{d}x \circ g^{-1}$ instead of \begin{equation}
g^*(\mbox{d}x) = \sqrt{|\gamma(g(x))|}J_g(x)\mbox{d}g^1(x) \wedge\dots \wedge \mbox{d}g^m(x) = \mbox{d}(g(x)).
\end{equation} Here, $m = \dim M$, $J_g(x)$ the jacobian of the coordinate transformation $g$ evalueted at $x$ while $\sqrt{|g^*(\gamma(x))|} = \sqrt{|\gamma(g(x))|}$ because $g$ is an isometry. I'm not really into differential and Riemannian geometry, so I'm probably missing something entirely elementary.","['riemannian-geometry', 'differential-geometry']"
2413468,Bounding chromatic number for a specific graph,"A school has $n$ students and $k$ disjoint classes. Every two students in the same class are friends. For each two different classes, there are two people from these classes that are not friends. Prove that we can divide students into $n-k+1$ groups so that students in same group are not friends. As far as i know the problem belong to Lovasz but searching for it under his name proved futile. Any reference or solution would be greatly appreciated.","['combinatorics', 'graph-theory']"
2413493,Direct Proof - Discrete Mathematics,I am given Prove that there are no integer solutions to the equation $$x^2=4y+3$$ I started off by proving the square of the integer is either $0 \pmod{4}$ or $1 \pmod{4}$. If $x$ is even then $x=2k$ for some integer $k$. Then $x^2=(2k)^2=4k^2$. Will this satisfy the question?,['discrete-mathematics']
2413547,M tosses $7$ fair coins and has $M$ heads. $A$ tosses $6$ fair coins and has $A$ heads. Find probability $P(M>A).$,"$M$ tosses $7$ fair coins and has M heads. A tosses $6$ fair coins and has $A$ heads. Find probability $P(M>A)$.
I suppose that both distributions are binominal, but I don't know what to do next.",['statistics']
2413555,help with this doubts about analysis. (usual metric),"help with this doubts about analysis. (usual metric) (Please answer) Find the set $B$ such that its derived set $B´=A$ where $A=\{\frac{1}{n},n\in \mathbb{Z^+}\}$. is there any theorem to say that any derived set is closed? If this is so, then the problem would not have a solution. _ 
I told my teacher about something that he had read that the derived set should be closed, but he told me that he was confusing the derived set with  closure set, (Could you explain this to me?) I was thinking of the possible proof that the derived set is closed. Theorem: $A$ is closed if and only if $A^{\prime} \subseteq A $ if $(A^{\prime})^{\prime}\subseteq A^{\prime}$ then $A^\prime$ is closed, propuse it a my teacher but, he said that it is not always true.. how proof that $(A^{\prime})^{\prime}\subseteq A^{\prime}$ for every $A$ I've already asked this exercise here, but every time I have class, I'm confused. and im sorry my English is bad.","['general-topology', 'real-analysis', 'analysis']"
2413606,How do I solve an equation of the form $(\ddot{r}-\frac{A}{r^3})=B$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Can we solve an equation of the form $$(\ddot{r}-\frac{A}{r^3})=B$$ where $A$, $B$ are constants subjected to the initials conditions $r=R$, and $\dot{r}=v$ at $t=0$? Overhead dots represent derivatives w.r.t time $t$. This is the equation I arrived at while solving a physics problem, and it remains to solve this equation.","['derivatives', 'ordinary-differential-equations', 'initial-value-problems', 'boundary-value-problem']"
