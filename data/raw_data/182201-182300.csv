question_id,title,body,tags
3326172,"Norm $||.||$ on $C(X)$ is equivalent to $||.||_{\infty}$ norm if evaluation linear functionals on $(C(X),||.||)$ is continuous.","Let $X$ be compact Hausdorff space. Let $||.||$ be a norm on $C(X)$ which makes it into a Banach space and also assume that the linear functional $\lambda_x$ given by $\lambda_x(f)=f(x)$ is continuous for each $x$ . 
Show that there exist positive constants $A, B$ such that $$A||f||_{\infty}\le ||f|| \le B||f||_{\infty}.$$ I was trying to show that $f\to f$ is a bounded linear map from $(C(X),||.||)$ to $C(X)$ equipped with the sup norm. The map $f\to f$ is clearly one to one and onto, therefore open mapping theorem will give me the desired result. In order to show the continuity of the above map, I observe that $$|f(x)|=|\lambda_x(f)|\le ||\lambda_x|| ||f||.$$ I would want to supremum over all $x$ in both sides so that I can get the sup norm in LHS. But my issue is that I do not know a uniform bound on Norms of functionals $\lambda_x$ . I do not know how to by pass this, I have a feeling that Uniform boundedness principle can be useful to get a uniform bound on the Norms of these functionals but I am unable to carry out the task. Any help in this regard or any other way to attack this problem would be appreciated.","['functional-analysis', 'real-analysis']"
3326181,Analysis of a Continuous Piecewise Function,"I've recently come across a question that has completely stumped me, as follows: Given a function $f(x)$ such that $$
f(x) = 
\begin{cases}
\frac{a}{x-1} [3 \sin (x-1) - 2 \tan (\ln x)],
& \text{ if } 1/2 \lt x \leq 1 \\
b,
& \text{ if } x=1 \\
\int ^{x^2} _{4(x-1)} e^{x + [\ln(t+1)]^c} \,dt,
& \text{ if } x \gt 1.
\end{cases}
$$ Given that $f$ is differentiable, find the values of $a, b \text{ and }c.$ My immediate understanding is that since $f$ is differentiable, then it is also continuous for its entire domain. This means that taking the limits of each individual function as $x$ approaches 1 should yield the same result. The first function was significantly easier to evaluate: \begin{align}
\lim\limits_{x \to 1^-} \frac{a}{x-1} [3 \sin (x-1) - 2 \tan (\ln x)]
&= a \bigg(\lim\limits_{x \to 1^-}(3 \cos(x-1) - \frac{2 \sec^2(\ln x)}{x} \bigg)
&& \text{L'Hopital's Rule} \\
&= a
\end{align} And therefore $a=b$ . It's at the third function where I haven't the slightest idea of how to solve it. I've attempted, to no avail, integration by parts and converting the integral to a Riemann sum, but it feels as though I'm attempting to solve it through exhausting whatever techniques I have at hand. I'd appreciate if someone could give an idea of how to understanding evaluating not just this particular integral, but integrals of similar form.","['integration', 'functions', 'piecewise-continuity']"
3326212,For what continuous $f$ we can write $f(x)+a\cdot f(x+\alpha)$ as $b\cdot f(x+\beta)$?,"After reading about harmonic addition theorem, I am interested in: Find all continuous $f:\mathbb R\mapsto\mathbb R$ that admit identities of the form $$f(x)+a\cdot f(x+\alpha)=b\cdot f(x+\beta)$$ for all real $a,\alpha,x$ , where $b,\beta$ only depend on $a,\alpha$ . Obviously, we only have to determine $f$ up to a scaling constant and argument shift, because if $F(x)$ is such function, then so is $AF(x+B)$ . As a result of harmonic addition theorem, $\sin x$ is such function. Also, the identity function $\text{Id}$ is also such function, with $b=a+1$ , $\beta=\frac{a\alpha}{a+1}$ . Any other examples? Can all such functions be found?","['functional-equations', 'functions', 'real-analysis']"
3326215,"If $u=\sqrt {a\cos^{2}x+b\sin^{2}x} + \sqrt {b\cos^{2}x+a\sin^{2}x}$ , find the maximum and minimum value of $u^2$.","If $u=\sqrt {a\cos^{2}x+b\sin^{2}x} + \sqrt {b\cos^{2}x+a\sin^{2}x}$ , find the maximum and minimum value of $u^2$ . This problem was bothering me for a while. The minimum value of $u $ seemed relatively easy to find by using AM-GM followed by Cauchy-Schwarz but both equalities don't hold simultaneously. It seems a bit tempting to assume that the maximum occurs at $x= {\pi/4}$ but I couldn't find a proof to the conjecture. Would someone please help me to find the maximum and minimum with a short relevant proof? Note: I discovered that the function $u $ is periodic  with period ${\pi/2} $ .",['trigonometry']
3326227,Limit associated with a recursion,"Update : a full solution to the recursion below has now been found, and it is discussed here . If $z_n < 2y_n$ then $y_{n+1} = 4y_n - 2z_n$ $z_{n+1} = 2z_n + 3$ Else $y_{n+1} = 4y_n$ $z_{n+1} = 2 z_n - 1$ Consider the following limit: $$\lim_{n\rightarrow\infty} \frac{1}{n}\left(z_{n+1} - \sum_{k=1}^n z_k\right) \tag{$\star$}$$ The limit may or may not exist, and it may or may not depend on the initial conditions. Let us assume that the initial values $y_1$ and $z_1$ are strictly positive integers. Question : If $y_1 \neq 2 z_1$ and $2y_1 \neq z_1$ , is it true that $(\star)$ is always $1$ , and otherwise the limit is always $3$ ? Now let's the fun begin... Let $d_n=\frac14(z_n-2z_{n-1}+1)$ . The sequence $d_n$ represents the binary digits of some unknown number $x$ , a number that depends on the initial conditions. It turns out that if $y_1=2, z_1=5$ then that number is $x=\sqrt{2}$ . You may ask: so what? Here is where it becomes fascinating: If you answer my question about the limit converging to $1$ , say for $y_1=2, z_1=5$ , then you proved that exactly 50% of the binary digits of $\sqrt{2}$ are zero. An article about this recursion (with connection to the digits distribution) can be found here . An application to the gaming industry can be found in section 2.1 in the following article . The source code I used in my computations is accessible here (Perl code using the Bignum library for exact arithmetic.) I can produce a large number of $z_n$ on request, for those interested and not familiar with high precision computing. Hints and expectations The case with the limit converging towards $1$ , I call it the standard case . At this point, the result about the limit is still a conjecture. It is based on the fact that for a number such as $\sqrt{2}$ , the distribution of the binary digits is believed to be uniform on $\{0,1\}$ . Generally speaking, the limit is equal to $4p-1$ where $p$ is the proportion of binary digits equal to one in the number $x$ in question: this fact is easy to prove, almost trivial, as the formula in the limit was built with that goal in mind. Also note that in the standard case, you can never have $y_n = 2z_n$ or $2y_n = z_n$ at any iteration $n$ , otherwise, it would force the convergence towards $3$ according to this conjecture, and imply that $x$ is rational. Also, if the limit, rather than being $1$ was (say) $1.2$ , it would imply that 55% of the binary digits of $\sqrt{2}$ are equal to one. Even proving (in the standard case) that the limit is strictly above $-1$ or strictly below $3$ would be a spectacular discovery: it would imply that the proportion of digits of $\sqrt{2}$ equal to zero is strictly positive (that is, it does not tend to zero as you look at longer and longer sequences of successive digits.) To this day, whether this fact is true or not remains a mystery. I don't know if proving my conjecture is easy, extremely difficult, or impossible to prove or disprove. But I will accept any answer that brings some light to help answer my question, even if it is just a reference to relevant, very interesting previous work. Also, insights about the case where $y_1$ or $z_1$ are not integers, are welcome: for the few cases I tested so far, the limit was equal to $1$ , unless $y_1=2z_1$ or $2y_1 = z_1$ , but convergence can be slow when we are close to $y_1=2z_1$ or $2y_1 = z_1$ . Below is a chart showing convergence to $1$ (relatively slow, of the order $1/\sqrt{n}$ just like for the central limit theorem - not a coincidence - and chaotic) using $y_1=2, z_1=5$ . The X-axis represents $n$ , the number of iterations. The convergence is much faster when the limit is $3$ . Suggested path to solve this problem One way to handle this problem is to consider the sequence $d_n$ of digits of $x$ as a realization of an ergodic stochastic process. Such processes have an equilibrium distribution, called attractor in chaos theory, even though the dynamical system considered here is entirely deterministic. See my article on the theory of randomness, here , and my book Applied Stochastic Processes, Chaos Modeling, and Probabilistic Properties of Numeration Systems , here . The equilibrium distribution is solution to a stochastic integral equation. Here we are dealing with discrete values, and with a discrete stochastic equation that seems to only have two solutions (the standard case, and the other one.)  Assume that the probability (at any iteration $n$ ) for $d_n$ to be equal to one, is $p$ . At equilibrium, the probability for $d_{n+1}$ to be equal to one, must also be $p$ . This yields a stochastic equation, based on the recurrence system mentioned in the introduction, and the only unknown is $p$ . In order for the equilibrium to hold (that is, solving this equation with respect to $p$ ) must yield $p=1/2$ in the standard case. Update: One thing that could also help is looking at what happens with non-integer initial values. For instance, $y_1 \rightarrow 2, z_1 \rightarrow 5$ . I did notice during this experiment that $y_1=1.2, z=5.3$ leads to the non standard case, with the limit converging to $3$ and $x$ being a rational number. So the definition of the standard case needs some refinement (at least to handle non-integer initial values) and examples leading to the non-standard case (though rare) may be more numerous than initially thought. Another interesting chart Here I try to build a second order approximation for the limit. Let $$L(n)= \frac{1}{n}\left(z_{n+1} - \sum_{k=1}^n z_k\right) \tag{$\star$}$$ I am interested in the error $E(n) = \sqrt{n}\cdot \Big(L(n)-1\Big)$ . In a traditional problem, you would expect $E(n)$ to tend to a constant as $n \rightarrow\infty$ . Not here, the error behaves like a Brownian motion, again, just like in the central limit theorem. Yet the system is fully deterministic here. Note that I used $y(1)=2, z(1)=5$ to produce the chart below. While I did not test it, I would expect that the same Brownian behavior occurs regardless of the initial conditions, as long as we are dealing with the standard case. Also, if you look closely at the above chart, I believe it is NOT a true Brownian motion. It is too regular, and most importantly, the error seems to be bounded. The (apparently) bounded error, together with the non-dependence on the initial conditions (yet to be verified) for the probabilistic behavior, makes me think that this problem, after all, might be solvable. And maybe another way to sole this problem is to get good enough asymptotic expansions for $y_n$ and $z_n$ . Note The recursion mentioned here is identical to the one featured in section 2.1 in this article after the change of variable $z_n = 4x_n + 1$ . An additional change of variables, $w_n=z_n - 2y_n$ , could prove useful. A different approach If the goal is to prove that that binary digits of $\sqrt{2}$ are uniformly distributed, a different approach is as follows. Consider the sequence $q_k=2^{-\{ k \log_2 3 \}}$ where the brackets represent the fractional part function. The number $q_k$ is rational, it has a period of $2 \cdot 3^{k-1}$ in its binary expansion, and the proportion of digits equal to zero is always 50%. The median of $\{q_1, q_2, \cdots q_n\}$ tends to $\sqrt{2}/2$ and if $n$ is odd, it is equal to one of the $q_k (1\leq k\leq n$ ): it is the middle value when these numbers are ordered. Thus the proportion of zero in the median is always exactly 50% if $n$ is odd. But is this also true at the limit as $n\rightarrow \infty$ ? Not necessarily, this is not the case if you consider the minimum or the maximum, instead of the median. So it is more complicated: some $q_k$ (infinitely many) must be removed to guarantee this fact, and they must be chosen carefully so as to not change the value of the limiting median. One way to do this successfully is as follows. Keep only those $q_k$ that satisfy $|p_m(q_k) - \frac{1}{2}| < \frac{C}{\log m}$ for all $m=2,3, \cdots, \lfloor \log k\rfloor$ where $p_m(\alpha)$ is the proportion of digits of $\alpha$ that are equal to 1 among the first $m$ digits, and $C$ is a constant. Would this eventually eliminate $\sqrt{2}/2$ ? Probably not. Would this impact the limiting value of the median? Probably not. But these are extremely challenging questions. It is probably not hard to compute the exact proportion of $q_k$ that you eliminated by doing so. Yet it is not impossible that $\sqrt{2}/2$ can't be reached anymore after applying this thinning process, but only a neighboring irrational that shares (say) the same first $10^{10,000}$ digits. Update: If the $q_k$ being removed were evenly spread (they may not), we are left with the same limit distribution (that of $2^{-X}$ where $X$ is uniform on $[0, 1]$ ). Thus its median $\sqrt{2}/2$ would stay the same. Or perhaps, after removing the set $S$ all those $q_k$ , the median $M_n$ computed on $\{q_1,\cdots,q_n\} \setminus S$ still satisfies $|M_n - \frac{\sqrt{2}}{2}|<\frac{D}{\log n}$ , where $D$ is a constant. That would be enough to prove the main result. If you are only interested in finding a classic math constant $\alpha$ with 50% zeros and 50% ones in its binary expansion, then replace the median $M_n$ by the closest number to $\alpha$ among $\{ q_1, \cdots, q_n\}$ . An example is $\alpha = \frac{1}{2 \log 2}$ . This number is the expectation of the distribution in question, instead of the median. One interesting fact related to this number is the following. The $m$ - th digit of $q_k$ averaged over all $k=1,2,\cdots$ is denoted as $\mu_m$ . Its exact value is known and discussed in a previous MST question ( here ). For $m>1$ , the sequence $\mu_m$ is strictly increasing and converges exponentially fast to $\frac{1}{2}$ . An immediate consequence of the definition of $\mu_m$ is that $$\sum_{m=1}^\infty \frac{\mu_m}{2^m} = \frac{1}{2\log 2}.$$ Also, less obvious to prove but not difficult: we have $\mu_1=1$ and for $m>1$ , we have: $$\mu_m = \frac{1}{\log 2}\cdot\log \frac{2^{2^{m-1}} \cdot (2^{m-1})!^3 }{(2^{m-2})!^2 \cdot (2^m)!}  .$$ More on this in my next article. Conclusions and next steps It looks like $\sqrt{n}\cdot\Big(L(n) - 1\Big) = O(1)$ . This is enough to prove the main result in this discussion, but this asymptotic relationship has yet to be proved (or disproved). A weaker result, possibly easier to prove, is the following: $(\log n) \cdot \Big(L(n) - 1\Big) = o(1)$ . This is also enough to prove the main result. See chart below illustrating this conjecture. Another approach discussed in the section A different approach , does not seem to be easier. A related question is whether or not, for two irrational numbers $\alpha, \beta$ linearly independent on the set of rational numbers, the correlation between the digits of $\alpha$ and $\beta$ in base $b$ is zero. To prove this, it suffices to prove that the sequences $\{ b^n\alpha\}$ and $\{ b^n\beta\}$ are not correlated. It was proved that this was true for the sequences $\{ n\alpha\}$ and $\{ n\beta\}$ , see here . Unfortunately, this does not help. Here the brackets represent the fractional part function. But this epitomizes the issue that we are dealing with here. If $\alpha$ is irrational, then $\{n\alpha\}$ (sometimes called $n \alpha \mbox{ modulo } 1$ ) is equidistributed, regardless of $\alpha$ (irrational). But $\{b^n\alpha\}$ is equidistributed only for almost all irrational numbers. The first sequence is sometimes referred to as a universally good averaging sequence , while the latter is termed a universally bad averaging sequence : see this Wikipedia entry . A weaker conjecture is the following: infinitely many irrational numbers $\sqrt{r}$ with $r$ a rational number, have 50% zeros and 50% ones in their binary expansion. You might be able to prove it without being able to name a single of these numbers satisfying this property (I tried and failed so far; it is probably still a mystery today.) Finally, if you are interested to see how chaotic the behavior of non-normal numbers is (contrasted with supposedly normal numbers such as $\sqrt{2}$ ), read my recent MSE discussion, here . It gives some nice insights about what makes a number such as $\sqrt{2}, \pi, e$ or $\log 2$ stand out. Update The relation $\sqrt{n}\cdot\Big(L(n) - 1\Big) = O(1)$ is a direct consequence of the Berry-Essen theorem , a refinement of the central limit theorem that applies in this case. It would be true here if the digits of (say) $\sqrt{2}$ were i.i.d. with a Bernouilli distribution of parameter $p=\frac{1}{2}$ , as they appear to be. Thus proving this asymptotic result for $\sqrt{2}$ would be very difficult at best, impossible at worst. But a weaker result might be reachable. Along the same lines, see a new question (with answer) that I posted recently on MSE, here , and also here . It shows what would happen if $\sqrt{2}$ was a well-behaved but non-normal number, say with 75% of its digits equal to $1$ . Update #2 I wrote an article based on this question and some other related questions, You can read here .","['number-theory', 'recursion', 'sequences-and-series', 'recreational-mathematics', 'probability']"
3326234,Latin Square Problem,"I would like to create some latin square based problems similar to the ones in these images: But I'm lost about how to pick the ""hint"" numbers (those that are not hidden) so my problem has only one unique solution. Is there a clear defined criteria to accomplish this?","['abstract-algebra', 'discrete-mathematics']"
3326272,Entire function such that $\text{Im}f = \text{Re} ^4 f + 1$ is constant,"So I came across this problem: Prove that if $f$ is entire, $u=\text{Re} f$ , $v=\text{Im} f$ and $v(z)=u^4(z)+1$ $\forall z\in \mathbb{C}$ , then $f$ is constant. In this particular case, $v(z)\gt 0 \ \forall z\in \mathbb{C}$ , so applying Liouville's theorem to $g=\exp(if)$ does the job, but I was wondering if there are any solutions that exploit the specific equality between $u$ and $v$ instead of just the positivity of $v$ .","['complex-analysis', 'entire-functions']"
3326277,Why am I getting two different answer for this geometry question?,"There is a right triangle $\textrm{ABC}$ like the diagram above, and the point $\textrm{D}$ set so that $\mathrm{\overline{AD}=\overline{BC}}$ . If point $\mathrm{E}$ divides line segment $\mathrm{AB}$ in the ratio of $5:2$ , $\mathrm{\overline{AD}=\overline{DE}=\overline{CE}}$ . Let $\angle\mathrm{ABC}=\theta$ , then find the value of $\tan\theta$ . So what I did was I selected a point $\mathrm{F}$ on $\mathrm{\overline{BC}}$ so that $\mathrm{\overline{EF}\perp\overline{BC}}$ , then I let $\mathrm{\overline{EF}}=h$ , $\mathrm{\overline{AD}}=x$ . Then I can say $$h:h+x=2:5$$ So I get $$h=\frac{2}{3}x$$ Then I can use pythagorean theorem on $\triangle\mathrm{EFC}$ I get $$\mathrm{\overline{FC}}=\frac{\sqrt{5}}{3}x$$ Therefore $$\tan\theta=\frac{\mathrm{\overline{FE}}}{\mathrm{\overline{BF}}}=\frac{2}{3-\sqrt{5}}=\frac{3+\sqrt{5}}{2}$$ However, If I just find $$\tan\theta=\frac{\mathrm{\overline{CA}}}{\mathrm{\overline{BC}}}=\frac{7}{3}$$ I am really confused. Is there something wrong with my steps?",['geometry']
3326290,Tips for discrete mathematics in Contests and a example problem.,"In the last time I did lot's of preparations for future math contests and I discovered a problem where I don't know how to start with. Here is the problem: In a spa there are 100 showers. In every shower is a faucet which controlles the water for this shower. Due to a mistake every faucet controlles the water for exactly 5 other showers as well. Show that you can ever select 10 showers so that you don't notice the defect, when you close the remaining 90 showers. I already tried it with a graph, so every shower is connected to 5 other showers. Then I tested wether ther is a peculiarity. But that's where it ends. Maybe I don't know about specific techniques for such problems? I hope that I can look at some example solutions (for this and simmilar problems;I would be very grateful if you could post links to similar problems with solutions) and discover a own way to attack such problems. Maybe you have other advices as well. problem source: German Mathmatic Olympiade 2010 for 11th graders (PDF) Warm regards CodeCrafter1","['contest-math', 'problem-solving', 'discrete-mathematics']"
3326300,"$C([0, 1],[0, 1])$ is dense in $\Pi_{[0, 1]}[0, 1]$?","Is the space $C([0, 1], [0, 1])$ of continuous functions $[0, 1] \to [0, 1]$ dense in the space $\Pi_{[0, 1]}[0, 1]$ of all such functions regarding pointwise convergence?","['general-topology', 'functional-analysis']"
3326308,"Show that $\sqrt[3]{1+\sqrt{3}}$ isn't an element of the field $\mathbb{Q}(\sqrt{3} ,\sqrt[3]{2})$","Setting $\alpha = \sqrt[3]{2}$ and $a+b\alpha+c\alpha^2=\sqrt[3]{1+\sqrt{3}}$ for $a,b,c$ in $\mathbb{Q}(\sqrt{3})$ (The minimal polynomial for $\sqrt[3]{2}$ in $\mathbb{Q}(\sqrt{3})$ is $x^3-2=0$ since if it were reducible that would imply the existence of $\sqrt[3]{2}$ in $\mathbb{Q}(\sqrt{3})$ which is easily shown not to be true)  . This comes down to proving that the equations $$ a^3+9ab^2=1 $$ and $$ 3b^3+3a^2b=1$$ have no solutions $a,b$ in $\mathbb{Q}(\sqrt{3})$ . This is obviously extremely difficult to prove so there should be a better approach. This is too long for a comment. Considering the the irreducible polynomials for $\sqrt[3]{2}$ and $\sqrt[3]{1+\sqrt{3}}$ over $\mathbb{Q}(\sqrt{3})$ we see they are $x^3-(1+\sqrt{3})$ and $x^3-2$ respectively. If the two extensions in the comments are equal that would imply that there is an automorphism of the field $\mathbb{Q}(\sqrt{3})$ which fixes $\mathbb{Q}$ and sends $1+\sqrt{3}$ to $2$ but there is only one nontrivial automrphism of this field that fixes $\mathbb{Q}$ and it sends $\sqrt{3}$ to $-\sqrt{3}$ . So the two extensions can't be isomorphic, let alone equal. Is this correct?","['field-theory', 'number-theory', 'abstract-algebra', 'polynomials']"
3326334,Why are self-adjoint operators important?,"I am learning about self-adjoint and normal operators. So far, they have come up in the Spectral theorem, which says self-adjoint operators have an eigenvalue basis and a corresponding diagonal matrix. Do self-adjoint (or normal) operators have any other useful properties? (i.e. why are they important in linear algebra?) Since it is fairly straightforward, at least from what i've learnt, to find eigenvalues with the characteristic equation, it seems to me that you wouldn’t first try to see if an operator is self-adjoint before you diagonalize it, but would just find the eigenvalues and vectors.","['self-adjoint-operators', 'adjoint-operators', 'linear-algebra']"
3326362,"Bessel function integral: $\int_{0}^{\infty} e^{-ax}x^{m}\left(J_{0}(bx) \right)^{2} \, \mathrm dx$","I am  working on a  problem. Solving the PDE for my problem, these Bessel integrals arise: $$\int^\infty_0 e^{-ax}x^m(J_0(bx))^2dx,\quad \int^\infty_0 e^{-ax}x^m(J_1(bx))^2dx\qquad \text{and} \qquad\int^\infty_0 e^{-ax}x^mJ_0(bx)J_1(bx)dx$$ where $~J_0~$ and $~J_1~$ are the Bessel functions of first kind. I haven't found the solution in any table or book, and due to my limited background in applied mathematics I don't know how to integrate it by myself. Does anybody know the solution? Thanks a lot in advance","['integration', 'improper-integrals', 'analysis', 'bessel-functions']"
3326404,"Finding global extrema of $a\left(\frac{1}{2}-b\frac{\sin(cx)}{x} \right) - b(1-\cos(cx))$, for $x\geq 0$","I have the following equation: \begin{equation}
f(x) = a\left(\frac{1}{2}-b\frac{\sin(cx)}{x} \right) - b(1-\cos(cx)), \quad x\geq0,
\end{equation} where a, b and c are strictly positive constants. When I plug this into WolframAlpha to solve for min/max of $f(x)$ for $x>0$ , it returns no global min/max is found. However, from all of the figures that it provides, the global min and max appears to be after to be within the first ""cycle"" - see figure. The numeric also confirms this, but I am struggling to find out how to prove that it is the case (if it is). Any hint would be much appreciated. Here is the link for the numerical approximations of those peaks.","['maxima-minima', 'calculus', 'trigonometry']"
3326406,Find value of $(\cos\frac{2\pi}{7})^ {\frac{1}{3}} + (\cos\frac{4\pi}{7})^ {\frac{1}{3}} + (\cos\frac{8\pi}{7})^ {\frac{1}{3}} $,"The question of finding the value of $$(\cos\frac{2\pi}{7})^ {\frac{1}{3}} + (\cos\frac{4\pi}{7})^ {\frac{1}{3}} + (\cos\frac{8\pi}{7})^ {\frac{1}{3}} $$ was on my list. I was trying to apply the $n$ -th roots of unity, but other ideas are welcome. I also tried Newton's sums, but it's not working. I searched around here and I didn't find a similar one, but if they do, just say that I delete the topic.","['trigonometry', 'radicals']"
3326408,Ex. 14.4.7 from A First Look at Rigorous Probability Theory,"I have found myself stumped by the following question from Rosenthal's A First Look at Rigorous Probability Theory and would appreciate hints. Exercise $\mathbf{14.4.7}$ : Let $C \in \bf{R}$ and let $\{Z_i\}$ be an i.i.d. collection of random variables with $\textbf{P}[Z_i = -1] = 3/4$ and $\textbf{P}[Z_i = C] = 1/4$ .  Let $X_0 = 5$ and $X_n = 5 + Z_1 + Z_2 + \ldots + Z_n$ , for $n \geq 1$ . (a) Find a value of $C$ such that $\{X_n\}$ is a martingale (b) For this value of $C$ prove or disprove that there is a random variable $X$ such that as $n \to \infty$ , $X_n \to X$ with probability $1$ (c) For this value of $C$ prove or disprove that $\textbf{P}[X_n = 0 \text{ for some } n \in \textbf{N}] = 1$ I believe that for part (a) $C$ must be $23$ and for part (b) it is sufficient to note that for such a sequence to converge, as it is integer-valued, it must eventually be constant which is impossible almost everywhere in this case.  Part (c) however, eludes me.","['martingales', 'probability-theory', 'markov-chains']"
3326425,"Differentiation of a function of three variables, dependent on a function of two variables. Chain rule","Question: Let $ f(s,t) $ be a differentiable function of two variables and let $h(x,y,z)=z\cdot f(\frac{x}{z}, \frac{y}{z})$ . Simplify the expression $(x,y,z) \cdot \nabla h$ I am having trouble understanding how to go about this problem.
My solution attempt: $\frac{\partial f}{\partial x} = \frac{\partial f}{\partial s}\cdot \frac{\partial s}{\partial x} + \frac{\partial f}{\partial t}\cdot \frac{\partial t}{\partial x} = \frac{\partial f}{\partial s}\cdot\frac{1}{z}$ $\frac{\partial f}{\partial y} = \frac{\partial f}{\partial s}\cdot \frac{\partial s}{\partial y} + \frac{\partial f}{\partial t}\cdot \frac{\partial t}{\partial y} = \frac{\partial f}{\partial s}\cdot\frac{1}{z}$ $\frac{\partial f}{\partial z} = \frac{\partial f}{\partial s}\cdot \frac{\partial s}{\partial z} + \frac{\partial f}{\partial t}\cdot \frac{\partial t}{\partial z} = \frac{\partial f}{\partial s}\cdot\frac{-x}{z^2} + \frac{\partial f}{\partial t}\cdot\frac{-y}{z^2}$ This should in turn give $\nabla h = (\frac{\partial f}{\partial s}, \frac{\partial f}{\partial t}, f(\frac{x}{z},\frac{y}{z}) + \frac{\partial f}{\partial s} \cdot \frac{-x}{z^2} + \frac{\partial f}{\partial t} \cdot \frac{-y}{z^2})$ And therefore $(x, y, z) \cdot \nabla h = x \cdot \frac{\partial f}{\partial s} + y \cdot \frac{\partial f}{\partial t} + z\cdot (f( \frac{x}{z} , \frac{y}{z} ) + \frac{\partial f}{\partial s} \cdot \frac{-x}{z^2} + \frac{\partial f}{\partial t} \cdot \frac{-y}{z^2}) = \frac{\partial f}{\partial s \cdot z} + \frac{\partial f}{\partial t \cdot z} + z \cdot f( \frac{x}{z}, \frac{y}{z})$ The answer is supposed to be $zf$ , but I cannot figure out how to reach that conclusion. Could someone perhaps point me in the right direction; what am I doing wrong?","['multivariable-calculus', 'chain-rule']"
3326431,Showing that there is unique matrix $B$ such that $B^k=A$ for some $A$,"Let $A$ be a $n$ by $n$ real matrix with distinct positive eigenvalues $\lambda_1$ ,..., $\lambda_n$ . And let $k$ be an odd integer. Then, I was able to show that there exists a real matrix $B$ such that $B^k=A$ . However, it is not so easy to show that such $B$ is unique. How do I exclude the possibility that $B$ has some complex eigenvalues and still the entries of $B$ are all real? Could anyone please explain?","['matrices', 'linear-algebra']"
3326439,I don't understand the logical leap made in the analogy of $e$,"$e$ is often explained in terms of compound interest. If I found a bank that gave me 100% annual compound interest, then if I put in £1.00, at the end of the year, I would have £2.00. If I were more savvy, and instead asked for 50% interest paid biannually, then I would end up with more – £2.25 to be exact. (This is because 50% of £1.50 > 50% of £1 – simple interest, rather than compound interest, would still only give me £2.00.) $e$ appears to be the logical extreme of this idea: of taking $\frac{100%}{n}$ % interest $n$ times per year. I understand it as the limit of $(1+1/n)$ as $n$ tends to infinity. When the analogy starts to break down for me is when it is therefore concluded that you can take the interest infinitely/continually often. Obviously, this is conceptually harder already, because of the introduction of infinity. However, it is also seems to beg the question ""what is the interest rate?"". If it is 0%, then the £1.00 will never increase, but any more than 0%, and then the individual interest rates would no longer add up to 100%. Is it some kind of infinitesimal? To illustrate my wariness, I have this example from the wikipedia article on limits ( https://en.wikipedia.org/wiki/Limit_(mathematics) ): $$f(x)=\frac{x^2-1}{x-1}$$ As $x$ gets arbitrarily close to 1, $f(x)$ approaches 2, no matter which side you approach 1 from. However, $f(1)$ is undefined as involves division by zero. Similarly, as $n$ tends to infinity in the $e$ analogy, the growth rate becomes arbitrarily close to $e$ . But I don't see how this means that when $n=\infty$ , the growth rate is necessarily $e$ . After all, if you plug $n=\infty$ into the normal formula $(1+1/n)^n$ , it seems that it breaks down (forgive me if you cannot use infinity in this way).","['limits', 'exponential-function', 'infinity']"
3326456,Image of a Topologically Regular Set?,"This question has come up as a small question in my research and I think I'm a little too thick in the weeds with extraneous details to see it cleanly. If necessary, I can add some more conditions on the spaces and maps that follow---just ask! Suppose $(X, d_x, \mu_x)$ and $(Y, d_y, \mu_y)$ are metric measure spaces, with metrics $d_x$ and $d_y$ and Borel measures $\mu_x$ and $\mu_y$ respectively. Let $f:X \to Y$ be continuous (and hence measureable). Generally assume that $X$ and $Y$ are ""nice"" (e.g., manifolds) but $f$ is ""messy."" Definition : A set $U$ is called topologically regular (or a regular closed set ) if it is the closure of its interior, i.e., $\overline{\mathrm{int } U} = U$ . Theorem : If $A \subseteq X$ is compact and $f$ is continous, then $f(A) \subseteq Y$ is compact. Suppose for everything that follows that $A \subseteq X$ is non-empty, compact, and topologically regular. My aim is to establish the weakest possible condition on $f$ such that $f(A) \subseteq Y$ is also topologically regular. Baby Question : If $f:X \to Y$ is continuous, is $f(A) \subseteq Y$ topologically regular? Counter Example: Consider $f:\mathbb{R}^2 \to \mathbb{R}^2$ with the Euclidean metrics and Lebesgue measures. Let $f(x,y):=(x, 0)$ ; observe that $f$ is clearly continuous. However, $[0,1]^2$ is topologically regular but $f([0,1]^2) = [0,1] \times \{0\}$ which has empty interior and is hence not topologically regular. $\blacksquare$ Clearly we need a stronger condition on $f$ in order to guarantee that the image is also topologically regular. The following would be sufficient, but is a stronger condition than I could ever possibly dream of in my context. Theorem : If $f:X \to Y$ is a homeomorphism, then $f(A)$ is topologically regular. Proof: Clearly $f( \mathrm{int}~A) = \mathrm{int}~ f(A)$ as $f$ is a homeomorphism; since $A$ is topologically regular and non-empty, we have that $\mathrm{int}~A \neq \emptyset$ and hence $\mathrm{int}~f(A) \neq \emptyset$ . Let $y \in \partial f(A)$ and $\epsilon > 0$ be given. We seek to show that the ball $B(y, \epsilon)$ has non-trivial intersection with $\mathrm{int}~f(A)$ .  Since $f(A)$ is compact (and hence closed), we have that $y \in f(A)$ and hence $x:= f^{-1}(y) \in A$ . Since $A$ is topologically regular, we have that $f^{-1}(B(y, \epsilon)) \cap \mathrm{int}~A \neq \emptyset$ and therefore $$B(y, \epsilon) \cap f(\mathrm{int}~A) = B(y, \epsilon) \cap \mathrm{int}~f(A) \neq \emptyset.$$ Hence $y \in \overline{\mathrm{int}~f(A)}$ and thus $f(A) = \overline{\mathrm{int}~f(A)}$ as desired. $\blacksquare$ The Question In my specific context, $f$ will land somewhere on the spectrum between being continuous (trivially easy) and being a homeomorphism (provably impossible). What are the weakest possible conditions on $f$ to guarantee that $f(A)$ is topologically regular? Do any (or all?) of the following suffice? If they fail, what additional (if any) hypotheses on $f$ or the spaces $X$ and $Y$ are necessary? $f:X \to Y$ is continuous and bounded-to-one , i.e., there exists $M \in \mathbb{N}$ such that $\mathrm{Card } f^{-1}(y) \leq M$ for all $y \in Y$ . $f:X \to Y$ is continuous and almost everywhere constant-to-one , i.e., there exists $M \in \mathbb{N}$ such that $\mathrm{Card}~f^{-1}(y) = M$ almost everywhere. $f:X \to Y$ is continuous and almost everywhere injective. $f: X \to Y$ is Lipschitz continuous. Edit: See above counter example $f: X \to Y$ is $\alpha$ -Holder continuous. Edit: See above counter example Edit Per comments from @WilliamElliot and @HennoBrandsma, $f$ being continuous and an open (or closed) mapping suffices. The proof is similar to that of $f$ being a homeomorphism as above, but with some care taken as to inclusions instead of inequalities. In my specific context, this actually solves my problem as I can show that $f$ is a closed map. I still think there's some interesting analysis to be done regarding the five conditions I've listed above, so I'll leave the question open for now. Edit 2: Open Mapping There seems to be some confusion in the comments. I give a proof below that $f$ is continuous and an open mapping suffices. I also give proof that my Counter-Example is neither an open mapping nor a closed mapping. Proposition E1 : The map $f:\mathbb{R}^2 \to \mathbb{R}^2$ given by $f(x,y):= (x,0)$ is not an open mapping. Proof: Given open $U \subseteq \mathbb{R}^2$ , we have that $f(U)= A \times \{0\}$ for some $A \subseteq \mathbb{R}$ , which is not open in $\mathbb{R}^2$ . $\blacksquare$ Proposition E2 : The map $f:\mathbb{R}^2 \to \mathbb{R}^2$ given by $f(x,y):= (x,0)$ is not a closed mapping. Proof. Define $U:=\{(x,y) \in \mathbb{R}^2 \mid y \geq 1/x \text{ and } x > 0\}$ . We have that $U$ is closed, but $f(U) = (0, \infty)\times \{0\}$ which is not closed. $\blacksquare$ Proposition E3 : Suppose $f:X \to Y$ is continuous. If $f$ is an open mapping and $A \subseteq X$ is topologically regular, then $f(A)$ is topologically regular. Proof. Let topologically regular $A \subseteq X$ be given.
We begin by noting that if $A=\emptyset$ , then the proposition holds vacuously. Therefore, assume that $A \neq \emptyset$ and thus $\mathrm{int} A \neq \emptyset$ . Since $\mathrm{int} A \subseteq A$ , we have that $f(\mathrm{int} A) \subseteq \mathrm{int} f(A)$ and in particular is non-empty. Let $y \in f(A)$ and open neighborhood $U\ni y$ be given. Since $f$ is continuous, $f^{-1}(U)$ is open in $X$ and in particular $f^{-1}(U) \cap A$ is non-empty. As $\overline{\mathrm{int} A} = A$ , we have that $f^{-1}(U) \cap \mathrm{int} A \neq \emptyset$ . Therefore $$U \cap \mathrm{int} f(A) \supseteq U \cap f(\mathrm{int} A) \supseteq f \left(f^{-1}(U) \cap \mathrm{int} A \right) \neq \emptyset$$ and thus $y \in \overline{\mathrm{int} f(A)}$ as desired. $\blacksquare$ Edit 3: Closed Mapping Having $f$ be continuous and a closed mapping is insufficient to guarantee that the image is topologically regular. Counter-Example: Consider $f:[0,1]^2 \to [0,1]^2$ (with the standard topologies) defined by $f(x,y):=(x,0)$ . We can clearly see that $f$ is continuous and we will show that $f$ is a closed mapping. Let a closed subset $A \subseteq [0,1]^2$ . As $A$ is a closed and bounded subset of $\mathbb{R}^2$ , we have that $A$ is compact. Since the image of a compact set is compact (and thus closed), we have that $f(A)$ is closed as well and thus $f$ is a closed mapping. However, $f(A) \subseteq [0,1] \times \{0\}$ and thus $\mathrm{int}~f(A) = \emptyset$ in $[0,1]^2$ . Therefore, given any non-empty $A$ we have that $\overline{\mathrm{int} f(A)} = \emptyset \neq f(A)$ and thus $f(A)$ cannot be topologically regular. $\blacksquare$","['general-topology', 'measure-theory']"
3326507,Discontinuity of norm on $\ell^p$ defined by vector-space isomorphism to $\ell^q$,"I'm reading the paper by Dijkstra and van Mill called Topological equivalence of discontinuous norms, and in its introduction there is this: Consider the case of $\ell^p$ and $\ell^q$ , where $p<q$ . Then as vector spaces, $\ell^p$ and $\ell^q$ are isomorphic (they have Hamel basis of the same cardinality) and so under this equivalence the norm on $\ell^q$ defines a norm on $\ell^p$ , which is badly discontinuous of course. Now, i get how the norm is constructed, by I absolutely don't understand, why it is ""badly discontinuous of course"". I tried driving the continuousnes to contradiction by applying Pitt's compactness theorem on the isomorphism and then using the compactnes on sequence of vectors with one coordinate being 1 (changing places) and the others being 0, but I can't get to prove boundedness of the isomorphism (taken as going from $\ell^q$ to $\ell^p$ , I can prove boundedness in the other direction quite easily, considering continuity of the norm we want to contradict). What can I do?","['continuity', 'normed-spaces', 'topological-vector-spaces', 'functional-analysis']"
3326528,"inverse function theorem: $f$ is invertible(smooth inverse), then Jacobian determinant is not zero?","Source: ""An Introduction to Manifolds"" by Loring W. Tu, p339, p68 For a proof, see  Rudin  ""Principles of Mathematical Analysis"" P221 But, if the map $f$ is invertible(has a $C^\infty$ inverse) in some neighborhood of $p$ , then the  Jacobian determinant is not zero?","['functions', 'analysis', 'real-analysis']"
3326529,A misunderstanding on the independence of orientation of line integrals?,"I've found the following problem: Calculate the line integral of the first kind $$\int_C (x+y)ds$$ Where $C$ is the contour of the triangle $ABO$ with the vertices at $A=(1,0),B=(0,1),C=(0,0)$ . In the previous presentation of the subject, it says that the line integral of the first kind is independent of the orientation. So, we compute first from $A$ to $B$ by acknowledging that this path is given by the line $y=1-x$ and in the solution, the author computes: $$\int_{0}^{1}\sqrt{2} dx$$ Doing this way, we get $\int_{0}^{1}\sqrt{2} dx=\sqrt{2}$ but here we are computing the value from $B$ to $A$ and not from $A$ to $B$ .  We should compute it as $$\int_{1}^{0}\sqrt{2} dx$$ But doing this way, it would yield $-\sqrt{2}$ and our line integral should be independent of the path of integration. How come we get two different results? I may have understood something wrong. Notice that I computed only the segment from $A$ to $B$ but looking at the solution, it doesn't seems the situation is going to change if I compute for the whole triangle.","['multivariable-calculus', 'definite-integrals']"
3326534,Quadratic matrix equation $XAX=B$ [duplicate],This question already has an answer here : Matrix equation with symmetric and positive definite matrices [duplicate] (1 answer) Closed last year . Let $A$ and $B$ be two positive semidefinite $n \times n$ matrices. Does the following quadratic matrix equation have a solution in the set of real symmetric matrices? $$XAX=B$$ It's a special case of the Riccati equation. I want just to prove the existence of such real matrix $X$ .,"['matrices', 'matrix-calculus', 'symmetric-matrices', 'matrix-equations', 'quadratics']"
3326539,"Interesting question about finding a quadratic polynomial such that $h(\alpha)=\beta, \ h(\beta)=\gamma, \ h(\gamma)=\alpha$","$f(x)=x^3-3x^2+1, \forall x\in\mathbb R$ , $g(x)=1-\frac{1}{x} ,\forall x\in\mathbb R, x \neq 0$ . i) Show that $f(x)$ has $3$ distinct and real roots. ii) It is given $\gamma < \beta < \alpha$ , where $\gamma, \alpha, \beta$ are the roots of $f(x)$ . Show that $g(\alpha)=\beta, \ g(\beta)=\gamma, \ g(\gamma)=\alpha$ . iii) Given $h(x)$ is a quadratic function such that $h(\alpha)=\beta, \ h(\beta)=\gamma, \ h(\gamma)=\alpha$ . Part (i) and (ii) are quite easy to show. (i): \begin{align} D(f)&=−27𝐴^2𝐷^2+18𝐴𝐵𝐶𝐷−4𝐴𝐶^3−4𝐵^3𝐷+𝐵^2𝐶^2 \\
&=-27(1)(1)-4(-3^3)(1)>0. 
\end{align} (ii): $g'(x)=\frac{1}{x^2} \implies g(x)$ is strictly increasing from the interval $(-\infty, 0)$ & $(0, \infty)$ . We also know that $f(g(\alpha))=f(\beta)=0$ . Similarly for $g(\beta)$ & $g(\gamma)$ . So $g(\beta), g(\gamma), g(\alpha)$ are roots to $f(x)$ . Consider $g(\gamma)$ which now can either equal $\alpha, \beta$ or $\gamma$ . Since the function is strictly increasing and not monotonically increasing, we conclude $g(\gamma) \neq \gamma$ . So $g(\alpha)=\gamma,  \beta$ | $g(\beta)=\alpha, \gamma$ | $g(\gamma)=\alpha, \beta$ . We use the fact that $g(x)$ is one to one to conclude that $g(\gamma) \neq g(\alpha)$ . Thus only one of these 2 possible solutions are true. Suppose $g(\alpha)=\gamma$ , $g(\beta)=\alpha$ , $g(\gamma)=\beta$ . Since $g(x)$ is strictly increasing, then it implies that one of the roots must lie within the negative interval and that root is $\gamma$ . We can show then that $\beta>1$ which would make $\alpha<1$ , which is a contradiction, so the other possibility must be true, proving $g(\alpha)=\beta, \ g(\beta)=\gamma, \ g(\gamma)=\alpha$ . (iii): This part is the part I'm stuck at. This is what I've tried. $f(g(x))= -\frac{1}{x^3}+3(\frac{1}{x})-1$ . So if $g(\alpha)$ is a root to $f(x)$ , it implies $\frac{1}{\alpha}$ is a root for $x^3-3x+1=0$ . $\gamma=\frac{1}{1-\alpha}, \beta=\frac{1}{1-\gamma}, \alpha=\frac{1}{1-\beta}$ . $g^2(x)=\frac{1}{1-x}$ which potentially could be easier to work with. That the distance between the roots can be modelled by the distance between the $g(x)$ and $g^2(x)$ graphs. The coloured segments are lines of the same length: That the following are true: $$(\alpha - \beta)(\gamma) = \gamma - \beta$$ $$(\alpha - \gamma)(\beta) = \alpha - \beta$$ $$(\beta - \gamma)(\alpha) = \alpha - \gamma$$ But after this I'm stuck. How can I proceed?","['functions', 'polynomials']"
3326615,Trying to visualize the hierarchy of mathematical spaces,"I was inspired by this flowchart of mathematical sets and wanted to try and visualize it, since I internalize math best in that way. This is what I've come up with so far: Version 1 (old diagram) Version 2: Is there anything that I'm missing, or that is incorrectly marked? For example, where exactly should I insert a box for Fréchet Spaces? And, is it safe to say that Normed Vector Spaces are a proper subset of the intersection between Locally Convex Spaces and Metric Spaces (or is it the entire intersection?) Edit: Thank you, everyone, for your input. Obviously no single diagram is going to encapsulate the entirety of functional analysis, geometry, and topology (not to mention the myriad of algebraic structures I've ignored, as some of you have pointed out.) As someone who does a lot of analysis, I would often find myself going back to Wikipedia or my textbooks to re-read the definitions of the various spaces and sets I am working with. I just wanted something that could help me keep a lot of these ideas straight in my head; and was pretty and useful to glance at. I think I've settled on my final version (for now.) In summary, here is a quick bullet list of the labeled components of the diagram: Topological Spaces : sets with a notion of what is ""open"" and ""closed"". Vector Spaces : sets with operations of ""addition"" and ""(scalar) multiplication"". Topological Vector Spaces : ""addition"" and ""multiplication"" are continuous in the topology. Metric Spaces : sets that come with a way to measure the ""distance"" between two points, called a metric ; the topology is generated by this metric. Locally Convex Spaces : sets where the topology is generated by translations of ""balls"" ( balanced , absorbent , convex sets); do not necessarily have a notion of ""distance"". Normed Vector Spaces : sets where the topology is generated by a norm, which in some sense is the measure of a vector's ""length"". A norm can always generate a metric (measure the ""length"" of the difference of two vectors), and every normed space is also locally convex. Fréchet Spaces : a set where the topology is generated by a translation-invariant metric; this metric doesn't necessarily have to come from a norm. All Fréchet spaces are complete metric spaces (meaning that if elements of a sequence get arbitrarily ""close"", then the sequence must converge to an element already in the space.) Banach Spaces : a set that is a complete metric space, where the metric is defined in terms of a norm. Inner Product Spaces : sets with a way to measure ""angles"" between vectors, called an inner product . An inner product can always generate a norm, but the space may or may not be complete with respect to this norm. Hilbert Spaces : an inner product space that is complete with respect to this induced norm. Any inner product space that is incomplete (called a ""pre-Hilbert Space"") can be completed to a Hilbert space. Manifold : a set with a topology that locally ""looks like"" Euclidean space. Any manifold can be turned into a metric space.","['geometry', 'general-topology', 'visualization', 'functional-analysis']"
3326617,Show that the general value of $\theta$ satisfying $\sin\theta=\sin\alpha$ and $\cos\theta = \cos\alpha$ is given by $\theta = 2n\pi + \alpha$ [duplicate],"This question already has answers here : If $\cos x=\cos y$ and $\sin x=\sin y$ is $x=y$ or $x=2\pi,y=0$ or $x=0,y=2\pi$? $x,y\in[0,2\pi]$ (2 answers) Closed 4 years ago . The general value of $\theta$ simultaneously satisfying equations, $$\sin\theta = \sin\alpha \quad\text{and}\quad \cos\theta = \cos\alpha$$ is given by $$\theta = 2n\pi + \alpha \ \forall \ n \in \mathbb{Z} \\$$ My attempt: Adding the two equations, $$\sin\theta + \cos\theta = \sin\alpha + \cos\alpha$$ $$\sin\theta - \sin\alpha = \cos\alpha - \cos\theta$$ $$2\cos\left( \frac{\theta + \alpha}{2} \right)\sin\left( \frac{\theta - \alpha}{2} \right)= 2\sin\left( \frac{\theta + \alpha}{2} \right)\sin\left( \frac{\theta - \alpha}{2} \right)$$ $$\cos^2\left( \frac{\theta + \alpha}{2} \right) = \sin^2\left( \frac{\theta + \alpha}{2} \right)$$ $$\cos(\theta + \alpha) = 0$$ $$\therefore \theta + \alpha = (2n+1)\frac{\pi}{2},\  n \in \mathbb{Z}$$ $$\theta = (2n+1)\frac{\pi}{2} - \alpha, \ n \in \mathbb{Z} $$ Why doesn't my solution match with the correct solution? Please help!",['trigonometry']
3326640,Approximations using derivatives,"I came across the following definitions in my textbook: The differential of $x$ , denoted by $dx$ , is defined by $dx = \Delta x$ The differential of $y$ , denoted by $dy$ , is defined by $dy=f'(x) dx$ or $dy = (\frac{dy}{dx})\Delta x$ I understood the first part. However, the second part doesn't make intuitive sense to me. What is the intuitive explanation for the second definition?","['calculus', 'derivatives', 'approximation']"
3326667,Cardinality of a sum(product) of two ordinals equals to sum(product) of their cardinalities,"An exercise from Halmos ""Naive Set Theory"", p. 101: Prove that if $\alpha$ and $\beta$ are ordinal numbers, then $\text{card}~(\alpha + \beta) = \text{card}~\alpha + \text{card}~\beta$ and $\text{card}~(\alpha \cdot \beta) = \text{card}~\alpha 
\cdot \text{card}~\beta$ . Use the ordinal interpretation of the operations on the left side and the cardinal interpretation on the right.",['elementary-set-theory']
3326686,Prove or disprove that there does not exist a monotone function $f:\mathbb{R}\rightarrow\mathbb{Q}$ which is onto.,Prove or disprove that there does not exist a monotone function $f:\mathbb{R}\rightarrow\mathbb{Q}$ which is onto. Clearly $f$ can not be continuous. Suppose $f$ is discontinuous. Then it can have only countably many points of discontinuity. From this how to proceed?,"['monotone-functions', 'real-analysis']"
3326716,Same moments and boundedness of one rv implies same distribution,"If $X$ is a bounded random variable and $Y$ is another random variable (not assumed to be bounded) with $E[X^n] = E[Y^n]$ for $n = 1, 2, 3, . . .,$ . Then , show that $X$ and $Y$ must have same distribution.","['moment-generating-functions', 'characteristic-functions', 'probability-distributions', 'probability-theory']"
3326720,PMF for the maximum of two four-sided dices,"Suppose we roll two four-sided dice, that is, each die has four sides, numbered $1, 2, 3, 4$ . Let $X_1$ and $X_2$ be the numbers that appear on the first and second die respectively, and let $Z = \max\{X_1, X_2\}$ , that is $Z$ is the larger of the two numbers rolled. Find the probability mass function of $Z$ . The tricky part for me is that it takes the $\max$ of two numbers. Therefore, my initial approach was listing all the possible combinations where there could be a $\max$ number, e.g.: $(1,2, 2,1, 2,2)$ for side $2$ . But I assumed that, because there is no $0$ side, $1$ can't be max. I'm struggling to get the probabilities $f_z(z) = 12/16$ , $f_z(z) = 4/16$ , $f_z(z) = 3/16$ . $f_z(z) = 5/16$ . What $z$ values would they have to be to get to these probabilities? Note that I used $f_z(z)$ , for $Z$ . I initially thought the $z$ would be an interval of values but I was completely wrong.","['dice', 'functions', 'probability']"
3326729,"Combinatorial proof that the exponential and logarithmic functions are inverse, the other way around","In the spirit of Combinatorial Argument for Exponential and Logarithmic Function Being Inverse , is there a combinatorial proof that $\exp$ and $\log$ are inverse, evaluating the composition the other way around? More precisely, since $\log (1+x) = \sum_{k=1}^\infty \frac{(-1)^{k-1}}{k} x^k$ for $|x| < 1$ and $\exp x = 1+ \sum_{m=1}^\infty \frac{1}{m!} x^m$ , the coefficient of $x^n$ in $\log \exp x$ is $$\sum_{a_1+\cdots + a_k = n} \frac{(-1)^{k-1}}{a_1! \ldots a_k! k} $$ where, as in the linked question, the sum is over all ways to write $n$ as an ordered sum $a_1 + \cdots + a_k$ of strictly positive integers. It's clear the coefficient is $1$ when $n=1$ , since the only summand is $(-1)^0/1 = 1$ . Is there a combinatorial proof that this coefficient is $0$ unless $n=1$ ?","['generating-functions', 'combinatorics', 'exponential-function', 'logarithms']"
3326780,10-digit numbers with constraints,"How many 10-digit numbers can be made by using the digits {5,6,7} (all of them) and with the additional constraints that no two consecutive digits must be the same and also that the first and last digits of the number must be the same? I am trying to find a solution by using combinatorics. I start from the 1st leftmost digit, which can have any value from {5,6,7} (3 possibilities). 
Then we move to the 2nd digit, which can have 2 values (since it can't be the same with the 1st) and so on, and for the last digit we only have 1 option. But this is not correct, because for the 9th digit we have the restriction that it must be different from the 8th and also different from the 10th, which, in turn, is equal to the 1st. 
I don't know how to express this. I therefore tried to find a recursive relation. 
I found that the general relation is $a(n) = 2*a(n-1)$ if n odd and $2*a(n-1) + 6$ if n is even. For n=4, we have 6 such numbers (4-digit numbers, but with the given restrictions). Then if we add one more digit to the right, we remove the rightmost (4th) digit, which had to be the same with the first, and now for the 3rd digit we have 2 options instead of 1 (we can also add the options that were rejected because they were neighboring with the 4th digit). So in total we now have $2 x 6 = 12$ options.
Therefore, $a(4)=6$ and $a(5)=12$ .
I don't understand, however, where this $+6$ (in the recursive relation) comes from! By the way, the correct answer is 510. Many thanks in anticipation.",['combinatorics']
3326784,Trigonometric equations: cotangent,"If I have $cot(x-a)=cot(x-b)$ Where x is in radians and equal on both the sides and not equal to $0$ or $π$ Also for a and b, they are not equal to $0$ or $π$ Does the above equality mean $a=b$ ?
If not then how do we even find the value of a and b?
Do we need any more conditions? There are no singularity points of cotangent between points $(x-a)$ and $(x-b)$",['trigonometry']
3326790,Find absolute maxima and minima of a multivariable function in the domain D,"I am trying to find the absolute maxima and minima of $ f(x,y) = 2x^3 + y^4$ in the domain $D = \{(x,y)| x^2 + y^2 \le 1 \}$ I have made an attempt as shown in attached picture. Please ignore dashed areas. Attached picture .
The answer is (1,0) and (-1,0). I do NOT want to use the Lagrange multiplier method to solve. Is it legal to substitute $y^4 = (1-x^2)^2$ into $f(x,y)$ to make a single variable $f(x)$ and then find $f'(x) =0 $ ? Then, after finding the $x$ can I substitute into $x^2 +y^2 = 1$ to find y? Then can I plug it back into $f(x,y)$ to find critical points? I want to know how to find max and min on the boundary $x^2 + y^2 = 1$ without the LM method? Thanks for your help!","['partial-derivative', 'multivariable-calculus']"
3326815,"What is the number of strings at size $n$ that is constructed from ${a,b,c,d}$ and there is an even num of $a$","What is the number of strings at size $n$ that is constructed from ${a,b,c,d}$ and there is an even num of $a$ ? I have tried to answer it as recursion formula in the following logic: In order to build $ A(n) $ , I will split into several cases: if the string starts with $a$ , then I will need another $a$ to make an even number of $a's$ . so we get $aa[A(n-2)]$ meaning 2 $a's$ at the start + a valid string at the size of $n-2$ . if it starts with $b,c,d$ we get $b[A(n-1)]$ + $c[A(n-1)]$ + $d[A(n-1)]$ , meaning a one of the letters + a valid string at the size of $n-1$ . So we will get a recursion formula that looks like that: $A(n) = A(n-2) + 3A(n-1)$ I'm not 100% on my answer, am I right to approach it in that direction?","['discrete-mathematics', 'recursion']"
3326837,$\frac{d}{dt}$ represents an operator or infinitesimal change?,"In high school physics, they teach us a little bit Calculus as it would be done months later in maths. And many times my physics teacher wrote things like $$\frac{dv}{dt} =\frac{dv}{dx}\frac{dx}{dt}$$ That seemed ok, as we were taught $\frac{dv}{dt}$ represents ratio of two infinitesimal changes. But in maths we were taught $\frac{d}{dt}$ is an operator and so can't be separated as that. I'm confused on this. Which is correct, and if $\frac{d}{dt}$ is an operator (can't be separated) then how can relations like the one mentioned above can be derived?","['notation', 'calculus', 'derivatives']"
3326845,"Necessary condition of changing signs of a divergent series $\sum_{n=1}^{\infty}p_{n}$ to make it convergent,$p_{n}$ decreases and tends to $0$.",Let $p_{n}$ decreases and tends to $0$ while $\sum_{n=1}^{\infty}p_{n}$ is divergent. We choose $\varepsilon_{n}=\pm 1$ to make $\sum_{n=1}^{\infty}\varepsilon_{n}p_{n}$ convergent. I want to prove that $$\liminf_{n\to\infty}\frac{\varepsilon_{1}+\cdots+\varepsilon_{n}}{n}\leq0\leq\limsup_{n\to\infty}\frac{\varepsilon_{1}+\cdots+\varepsilon_{n}}{n}.$$ I think this is true because the number of positive terms had better be as much as the number of negative terms to make the series convergent.But I cannot prove it.Any help will be thanked.,['sequences-and-series']
3326861,Does the series $\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n}$ converge uniformly?,"Does the following series $$\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n}$$ converge uniformly? I know the series converges pointwise since $\sum_{n}\frac{\cos n}{n}$ and $\sum_{n}\frac{\sin n}{n}$ converge. From desmos, it seems the series converges to some sort of sine wave and is infinitely differentiable. I have tried rewriting the series into $$\sum_{n=1}^{\infty}\frac{\cos n\cos x - \sin n\sin x}{n}$$ in order to use the Weierstrass M-Test. However, I'm not sure how to get a sequence of constants $C_{n}$ such that $$\sup_{x\in\mathbb{R}}\left|\frac{\cos n\cos x - \sin n\sin x}{n}\right|\leq C_{n}$$ and where $\sum_{n=1}^{\infty}C_{n}$ converges. I tried using the triangle inequality but this gives me something like $$\frac{|\cos n| + |\sin n|}{n}$$ This doesn't appear to help because it negates cancellation of positive and negative terms so my intuition tells me $\sum_{n=1}^{\infty}\frac{|\cos n| + |\sin n|}{n}$ would diverge as the harmonic series diverges. Is it possible to use the Weierstrass M-Test here to prove the series $\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n}$ converges uniformly?","['convergence-divergence', 'uniform-convergence', 'sequences-and-series']"
3327032,"What is the general solution of this equation :$2^x 3^y+1=7^z$ with $x, y , z$ are integers?","I have got these triplet solution $(x,y,z)=(1,1,1),(4,1,2)$ for this equation: $$2^x 3^y+1=7^z$$ with $x, y , z$ are integers, But i can't get general solution of it, I have attempted to use Gausse theorem for the solution of $ ax+by= c $ , with $a, b, c$ are integers but my problem i can't transfer the titled equation to that of Gausse as a linear form, any way ?","['modular-arithmetic', 'number-theory', 'elementary-number-theory', 'diophantine-equations', 'discrete-mathematics']"
3327037,Show that this ideal cannot be generated by 2 elements,"Let $Y$ be the curve given parametrically by $x=t^3, y = t^4, z = t^5$ . Show that $I(Y)$ is a prime ideal of height $2$ in $k[x,y,z]$ which cannot be generated by two elements. Obviously $(x^4-y^3,x^5-z^3) \subseteq I(Y)$ , but these ideals can't be equal because the one on the right is generated by two elements. So, what is the prime $I(Y)$ ? And how can i show its height is precisely 2?","['algebraic-geometry', 'commutative-algebra']"
3327074,Recursive formula to find the number of natural numbers in which there are no two adjacent even digits.,"Need to find a Recursive formula that finds all the natural numbers (number can't start with a 0), in which there are no two adjacent even digits. (For example: $13261$ is not a valid number because 2,6 are adjacent). So if I look at the $A_n$ step in the recursion I can divide the problem into 2 ways: Case 1: $A_n= \text{odd}$ (valid number in size $n-1$ ). In this case, the odd number has 5 options to choose from. Case 2: $A_n = \text{even, odd}$ (valid number in size $n-2$ ). In this case, we have 4 options for the even number and 5 for the followed odd number. So the recursive function that I've got is $A_n=5A_{n-1}+20A_{n-2}$ Is it correct ?","['combinatorics', 'discrete-mathematics', 'computer-science']"
3327182,$π(x+y) - π(x) ≤ c·y/\ln(y)$ for some constant $c$?,"Thinking about the prime number theorem, I wondered whether it is known that there is some constant $c$ such that $π(x+y) ≤ π(x) + c·y/\ln(y)$ for every integers $x,y > 1$ . I read that experts believe $π(x+y) ≤ π(x) + π(y)$ fails for some $y$ , since it fails for $y = 3159$ if the k-tuple conjecture holds , but it is just barely false, so I am curious if it is known to be true if the inequality is relaxed by a constant factor. If so, is it also known that $π(x+y) ≤ π(x) + π(y) + c·\!\sqrt{y}·\ln(y)$ for some constant $c$ ? I simply do not know how to search for such conjectures, and neither Wikipedia nor Wolfram seem to state any results that would affirm or refute these two conjectures easily, so any references would be appreciated! (After a year, I've now posted it on MO .)","['number-theory', 'conjectures', 'prime-numbers', 'reference-request']"
3327197,"Combinatorics the number of options for $k$ different balls in n different cells, with at least $1$ ball in each cell","How do I calculate the number of options for $k$ different balls in $n$ cells, with at least $1$ ball in each cell? Lets say $6$ different balls in $3$ different cells, with at least $1$ ball in each cell. like this: $$x_1+x_2+x_3 = 6$$ I would like to see an explanation please and not just the answer. Thanks!","['combinatorics', 'discrete-mathematics']"
3327246,find min of $a+b$ given sum of $a\geq b\geq c\geq d$ is 9 and square sum is 21,"Suppose $a\geq b\geq c\geq d>0$ and all are real numbers, and $a+b+c+d=9,a^2+b^2+c^2+d^2=21$ , how to find the minmum of $a+b$ ? What I attempted:
I can show $b\geq 1.5$ and $a\leq 3$ .for $r\geq 0$ , I consider $\sum(a-r)^2=\sum a^2-2r\sum a+4r^2=21-18r+4r^2$ , then $a\leq \sqrt{21-18r+4r^2}+r$ which implies $a\leq 3$ . Also I guess the min shoul be 5 and there are two solutions: 3,2,2,2 and $2.5,2.5,2.5,1.5$ . But I cannot prove it. New attempts: $6-2a=(a-3)^2+\sum(b-2)^2$ $2d-3=\sum(a-2.5)^2+(d-1.5)^2$ then $2(d-a)+3\geq 1$ which implies that $d\leq c\leq b\leq a\leq d+1$","['inequality', 'geometry', 'maxima-minima', 'optimization', 'algebra-precalculus']"
3327247,An entire function satisfies $f(az+b)=f(z)$,"Here is a problem that I got stuck on while preparing for an upcoming exam: If $a,b\in \mathbb{C}$ and $f:\mathbb{C}\to\mathbb{C}$ is non-constant and entire with $f(az+b)=f(z)$ for all $z\in \mathbb{C}$ , prove that there exists a positive integer $n$ such that $a^n=1$ . I proved the first part of the problem which is the same thing but with $b=0$ . I proved this by breaking into the three cases of $|a|<1$ , $|a|=1$ and $|a|>1$ . The first and last case, I got a contradiction that $f$ is constant (by analytic continuation and Liouville theorem respectively). I am not sure however, how to do it with $b\neq 0$ . I would really appreciate a hint.","['complex-analysis', 'entire-functions', 'analytic-continuation']"
3327268,"Is $f(x,y)=\frac{1}{x^2+y^2+1}$ uniformly continuous?","Is \begin{align*}
f(x,y)=\frac{1}{x^2+y^2+1}
\end{align*} uniformly continuous? I was able to show that $f$ has a global maximum at $f(0,0)=1$ , but I can't seem to work out a proper estimate for uniform continuity. Any insights would be greatly appreciated.","['multivariable-calculus', 'uniform-continuity', 'real-analysis']"
3327283,Graph of the function (2x^2-2)/(x^2-1),"I am learning precalculus and my precalculus book gives this equation: for this graph: But when I enter that equation into some online graph tool like Symbolab ( https://www.symbolab.com/graphing-calculator ) I get this graph: It seems that (many) online calculators cancel (x+1)(x-1) in numerator/denominator before drawing a graph. So, which graph of those 2 is ""correct""? Why? P.S. My previous question was downvoted and removed as ""not interesting for math community"". That was very rude having in mind that I am beginner, looking for a help. Perhaps I should join some other forum for math beginners but I don't know which and where?",['algebra-precalculus']
3327317,Comparison with singular cohomology for the cohomology of quadrics.,"In ""Etale cohomology and the Weil Conjectures"" By Freitag & Kiehl, chapter 3, paragraph 4, the following statement is made about the computation of the cohomology of quadrics: For what follows, we need some result about the cohomology of quadrics over a separably closed base field $k$ . One can for instance deduce them easily from the corresponding results on singular cohomology of quadrics over the field of complex numbers by using the comparison theorem (Chap. I §12) and the method of specialization (I, §8). The aforementioned ""specialization method"" points to the existence of a specialization morphism between stalks of a sheaves given two geometric points $\eta, a$ such that $a$ is a specialization of $\eta$ . I cannot derive what they said in this chapter. To me, comparison with singular cohomology only works for schemes/varieties over the complex numbers. Yet this results are used in order to prove the Picard-Lefschetz formula and eventually to be used in the proof of the Weil's conjectures, which are about varieties over $\mathbb{F}_p$ . I suspect that going from $\mathbb{C}$ to any other field is done by the mentionned ""specialization method"", and that checking on $\mathbb{C}$ is enough since every smooth quadrics on a separably closed field have a ""normal form"" that is independent on the coefficient field. But I can not derive this. So I am asking for either a sketch of how it is done, or a referrence where the passage from $\mathbb{C}$ to any separably closed field is done explicitly.","['etale-cohomology', 'algebraic-geometry', 'reference-request']"
3327325,Is this solution correct? Show that a set $A$ of open intervals satisfies $|A| \leq \aleph_0$,"$A$ is a set of open and non-empty intervals (real intervals) such that for all $B,C,D \in A$ we have $B \cap C\cap D= \emptyset$ . Show that $|A| \leq \aleph_0$ . This is what I did and I would like to know if it is correct. For all $q \in \mathbb{Q}$ define $A_q = \{B \in A : q \in B\}$ . Obviously $A= \cup_{q \in \Bbb{Q}} A_q$ because every non-empty interval contains a rational number. However, since every three intervals in $A$ do not intersect, we must have $|A_q| <3$ for every rational number $q$ . Therefore we represented $A$ as a countable union of countable sets, and therefore $A$ is countable (here by countable I mean at most $\aleph_0$ ). Is it correct?",['elementary-set-theory']
3327338,Show that the only endomorphism $\phi$ of $\mathbb{Z}_7 \times \mathbb{Z}_7$ satisfying $\phi^5 = \text{id}$ is the identity.,"Let $\phi: \mathbb{Z}_7 \times \mathbb{Z}_7 \to \mathbb{Z}_7 \times \mathbb{Z}_7$ be a homomorphism such that $\phi^5 = \text{id}$ . Show that $\phi$ is the identity. My attempt : Since $\ker(\phi) \subset \ker(\phi^2)\subset \cdots \subset \ker(\phi^5) = 0$ , it follows that $\phi$ is injective. Since $|\mathbb{Z}_7\times \mathbb{Z}_7|$ is finite, $\phi$ is automatically an isomorphism. Then $\phi$ should map a subgroup to a subgroup. Consider $\phi(\mathbb{Z}_7 \times 0)$ , then it should be mapped to $\mathbb{Z}_7 \times 0$ or $0 \times \mathbb{Z}_7$ . Without loss of generality, we consider the former case. In particular, $\phi(1,0)$ should be a generator for $\mathbb{Z}_7 \times 0$ . Suppose $\phi(1,0) = (a,0)$ . Then $(1,0) = \phi^5(1,0) = \phi^4(a,0) = \phi^3(a^2,0) = \cdots = (a^5,0)$ . Thus, $a^5 = 7k+1$ for some $k \in \mathbb{Z}$ . By testing $a \in \mathbb{Z}_7$ , we see that the only possibility is that $a = 1$ . The discussion for $\phi(0,1)$ is similar. Could anyone help me take a look at my attempt? Is my approach reasonable, and is there any better method to do this problem?","['group-theory', 'abstract-algebra']"
3327356,Limit of sum of areas of infinite amount of triangles,"I apologize for the possible incorrect use of math terms since English is not my native language and I'm not a mathematician, but this issue came to my mind about a month ago and I was unable to solve it, so I will appreciate any help. Let length of a line segment $L$ be $1$ . Also define variable $r$ (ratio) that can be any real number on the interval $(0;1)$ . Let us put the vertical line segment with length $L$ starting from the point $(0;0)$ on the orthogonal coordinate system; the other point of this line segment is $(0;L)$ . Put the next line segment with the following rules: Starting point should be located on the X axis, let us assume it as a point $(X(n);0)$ , where $X(n)>X(n-1)$ ; Lets treat the previous line segment like a vector, multiply it by $r$ . The end point of this vector is the end point of the new line segment. Here is the example which displays $n = 6$ triangles built with the $L = 1$ and $r = 0.8$ . Initially I tried to solve the following tasks: Find the function $f(L, r, n)$ which will return the sum of the areas of $n$ triangles giving the length of the line segment is $L$ and a ratio is $r$ ; Define the limit of the $f(L, r, n)$ with $L = 1$ ; $r \to 1$ and $n \to \infty$ ; Assuming that these issues were solved before, what is the correct way to call this task and where I can find the information about it? Here is what I have discovered so far. First, let us find one of the angles of the $n$ -th triangle. Define $\beta(n)$ as an angle between $(n-1)$ -th and $n$ -th line segment; $\alpha(n)$ as an angle between X axis and the $n$ -th line segment. For the sake of simplicity let us use $\alpha_N$ and $\beta_N$ instead of a function form. Since the first triangle is the right triangle, $\sin(\alpha_1)$ is defined by the known relations: $$\sin(\alpha_1) = \frac {r * L}{L} = r$$ Using the law of sines, investigate the second triangle. $$\frac {\sin(\alpha_2)}{L*r} = \frac{\sin(\pi - alpha(1))}{L};$$ $$\sin(\alpha_2) = \sin(\pi - \alpha_1) * r = \sin(\alpha_1) * r$$ Since there is no dependency from the right triangle in this formula, we can generalize the result: $$\sin(\alpha_n) = \sin(\alpha_{n-1})*r$$ or for the calculation simplicity sake: $$\alpha_n = \arcsin(r^n)$$ Knowing that the sum of the angles of the triangle is $\pi$ , we get the following: $$\pi = \alpha_n + \beta_n + (\pi - \alpha_{n-1});$$ $$0 = \alpha_n + \beta_n - \alpha_{n-1};$$ $$\beta_n = \alpha_{n-1} - \alpha_n$$ Find the area of the $n$ -th triangle with the following formula: $$S(n) = \frac 1 2 * L * L* r * \sin(\beta_n) = \frac 1 2 * L^2 * r * \sin(\beta_n)$$ Such formula is acceptable for the calculations, but we can represent it in a different way. $$\sin(\beta_n) = \sin(\alpha_{n-1} - \alpha_n) = \sin\alpha_{n-1}*\cos\alpha_n - \sin\alpha_n*\cos\alpha_{n-1}=$$ $$ = r^{n-1}*\sqrt{1-r^{2n}} - r^n*\sqrt{1-r^{2n-2}} $$ Since that is the solution for the first question, I had tried to solve the second, but with no avail. $$Sum(L,r) = \frac 1 2 *L^2 \lim_{r \to 1, n \to \infty} (r * \sum_{n=1}^\infty \sin(\beta_n)) $$ I also had tried to change the way of area calculation to the sum of the trapezoids, but it wasn't successful as well. $$S_t(n) = \frac {L*r^{n-1} + L*r^n} 2 * \cos\alpha_n*(1-r)*L$$ I was unable to apply any known to me technique (such as L'Hôpital's rule, Taylor series investigation) to reach the solution, so I resorted to approximate solution. I have managed to calculate the result of the function $f$ with the $L = 1$ ; $r = 0.999999$ ; $n = 100000000$ : $$f(1,0.999999,10^8) = 0.7853973776669734$$ The length of the whole construct was approximately equal to $100.6931$ , knowing that the side of the $n$ -th triangle on the X axis is: $$B(n) = L*r*(\frac {\cos\alpha_n} r - \cos\alpha_{n-1}))$$ The result is more or less close to the $\frac \pi 4 (0.7853981633974483)$ , which was surprising. I had tried to apply this knowledge (the infinite sum of $\sin\beta_n$ should approach to $\frac \pi 2$ ; knowledge that $\int_0^{+\infty}\frac {dx}{(1+x)*\sqrt{x}} = \pi$ ), but was unable to do so. So here is the final composite question: Are there any errors in my calculations? Is there a way to solve this without resorting to approximations? Is this sum really approaches to the $\frac \pi 4$ ? How can I define the curve which is shaped by these triangles? Assuming that these issues were solved before, what is the correct way to call this task and where I can find the information about it? Thank you in advance!","['approximation', 'geometry', 'pi', 'sequences-and-series', 'limits']"
3327381,"What is the number of subsets at size $k$ of the set $\{1,\ldots,n\}$ such that if a subsets contains $2$ it does not contain $1$?","What is the number of subsets at size $k$ of the set $\{1,\ldots,n\}$ such that if a subsets contains $2$ it does not contain $1$ ? So  think about that. We have $n$ numbers and $k$ subgroups. If $2$ contains so have groups on size $(k-1)n +$ , but how to start with that. Consider the set $A=\{1,\ldots,n\}$ .Count the number of subsets of $A$ of cardinality $k$ . How many subsets of cardinality on size $k$ do contain the number $2$ and not $1$ ?","['combinatorics', 'discrete-mathematics']"
3327429,tangent inequality in triangle,"Let $a$ , $b$ and $c$ be the measures of angles of a triangle (in radians). It is asked to prove that $$\tan^2\left(\dfrac{\pi-a}{4}\right)+\tan^2\left(\dfrac{\pi-b}{4}\right)+\tan^2\left(\dfrac{\pi-c}{4}\right) \ge 1$$ When does equality occur ? My try : Letting $u:= \tan\left(\dfrac{\pi-a}{4}\right)$ and $v:= \tan\left(\dfrac{\pi-b}{4}\right)$ the inequality reduces to proving $$u^2+v^2+\dfrac{(1-uv)^2}{(u+v)^2} \ge 1\quad\quad (*)$$ ( $$u,v\in (0,1)$$ ) ( using $a+b+c=\pi$ and the formula for $\tan(x+y)$ and the fact that $\tan\left(\dfrac{\pi}{2}-x\right)=\dfrac{1}{\tan x}$ ) I'm having trouble in proving that last inequality. Any suggestions are welcome. Thanks. Edit : is the following reasoning to prove the inequality (*) sound ? (*) is obvious when $u^2 + v^2 \ge 1$ so we only have to deal with the case $u^2 + v^2 \le 1$ which we assume true in what follows. (*) $\iff (u^2 + v^2)(u + v)^2 \ge (u+v)^2+(1-uv)^2$ Setting $x:= u^2 + v^2$ and $a:=uv$ we get (*) $\iff x^2+(2a-1)x \ge a^2+4a-1$ Now some calculus $(x^2+(2a-1)x)' = 2x + 2a-1$ the function $\phi:x\mapsto x^2+(2a-1)x$ then has a minimum at $\dfrac 12 - a$ which is $\phi\left(\dfrac 12 - a\right) = -a^2+a-\dfrac 14$ It then suffices to have $-a^2+a-\dfrac 14 \ge a^2+4a-1$ This last ineq is equivalent to $8a^2+12a-3 \le 0$ which, in turn, is equivalent to $a \in \left[\dfrac{-6-\sqrt{60}}{8}, \dfrac{-6+\sqrt{60}}{8}\right]$ Recall that we're working under the assumption $u^2 +v^2 \le 1$ , that yields in particular that $uv \le \dfrac 12$ . since $ \dfrac{-6-\sqrt{60}}{8} \le 0 \le a := uv \le \dfrac 12 \le \dfrac{-6+\sqrt{60}}{8}$ , we're done. Thanks for taking time to check the correctness of the above proof.","['inequality', 'jensen-inequality', 'geometric-inequalities', 'triangles', 'trigonometry']"
3327459,Quasi-coherence of the annihilator ideal sheaf of the sheaf associated to an $A$-module $M$,"$\def\Ann{\mathrm{Ann}}
\def\Spec{\operatorname{Spec}}$ I am trying to find an example which shows that the annihilator ideal sheaf, denoted by $\mathrm{Ann}(\mathcal F)$ , of a quasi-coherent sheaf $\mathcal F$ on a locally-noetherian scheme $X$ , is not necessarily quasi-coherent. (I have showed that coherence of $\mathcal F$ implies coherence of $\mathrm{Ann}($$\mathcal F)$ .) The annihilator ideal sheaf is defined by $\Ann(\mathcal F)(U) = \{f\in O_X(U)|$ $f$ kills $\mathcal F|_U\} =$ $= \{f\in O_X(U)\mid \forall \text{ open } V\subset U$ $f|_V$ kills the $O_X(V)$ -module $\mathcal F(V)\}$ , for an open $U\subset X$ . For an example, I took the noetherian scheme $X=\Spec(\mathbb{Z})$ , the abelian group (or equivalently the $\mathbb{Z}$ -module) $M$ to be the subgroup $G\leq\mathbb{Q/Z}$ consisting of all elements whose order is a power of a fixed prime $p$ , say $p=2$ (this is an example in Atiyyah&Macdonald, p.74), and looked at the quasi-coherent sheaf $\mathcal F=\widetilde M$ , i.e., the sheaf associated to $M$ on $\Spec(\mathbb{Z})$ (for the sheaf associated to a module definition, look in Hartshorne p.110). Now take $U\subset X$ to be the open set $D(2)=\{q\in X|2\notin q\}$ . It is clear that for every prime ideal $(2)\neq q\in X$ we have $M_q=0$ ( $M_q$ is the localization $(\mathbb{Z}-q)^{-1}M$ ), and thus, $\Ann(\mathcal F)(U) = O_X(U)$ .  In particular, it follows that $\Ann(\mathcal F)(U)$ is not trivial, since, for example, the section $q\mapsto \frac{1}{1}\in A_q$ is not the zero section in $O_X(U)$ . Why I did do this? because my guess is that if $\Ann(\widetilde M) $ is quasi-coherent, then it will be isomorphic to $\widetilde {\Ann(M)}$ , where $\Ann(M)$ is the annihilator of $M$ as a $\mathbb{Z}$ -module, but it is easily seen that $\Ann(M)=0$ , so [if my guess is correct] we conclude that $\Ann(\widetilde M) $ is not quasi-coherent, as desired. Do my guess is correct? if it doesn't so, do my example is correct even though?","['algebraic-geometry', 'abstract-algebra', 'coherent-sheaves', 'quasicoherent-sheaves']"
3327497,Lebesgue density theorem: a martingale proof,"I'm trying to prove the Lebesgue density theorem using Mantingale convergence theorem. In this post How to prove the Lebesgue density theorem using martingales? I see that someone proved it using a trick due to Morayne and Solecki, but I can't understand it and I can't get access to the referenced article neither. Could anyone kindly guide me or provide any reference so I can solve the following issues? Why to take $A \subseteq \left[\frac{1}{3},1\right)$ ? Can we do that without loss of generality? I tried to use the fact that $1/3=\sum_{k\geq 1}1/4^k$ to write $$ \left[\frac{1}{3},1\right) = \bigcap_{n=1}^{\infty} \left[\sum_{k = 1}^{n} 1/4^k, 1\right), $$ but it didn't help. If $F_n'(x)\in \mathcal{F}_n'$ , Why is $F_n'(x)$ just $F_n(x)$ shifted by one of the four numbers $\pm 2^{-n}\left(\frac{1}{3}\right), \pm 2^{-n}\left(\frac{2}{3}\right)$ ? I see that $F_n'(x)$ is an element of $\mathcal{F}_n'$ , which is the $\sigma$ -algebra $\mathcal{F}_n$ shifted by $\frac{1}{3}$ , so $F_n'(x)$ does not necessarily has to be related to $F_n(x)$ , because it may be a union of elements of the partition generating $\mathcal{F}_n$ but shifted by $\frac{1}{3}$ . I'd really apreciate any help.","['martingales', 'measure-theory', 'probability-theory', 'real-analysis']"
3327501,Euler-Poincare characteristic for relative schemes,"Let $X\to S$ a morphism of Noetherian schemes. Assume that $\mathcal F$ is a coherent sheaf on $X$ with the following property: the support of $\mathcal F$ is proper over a subscheme of $S$ of dimension $0$ . Then I've read in Kollar's book ""Rational curves on algebraic varieties (chap VI appendix 2)"", that in this case it is possibile to define the Euler-Poincare characteristic $\chi_S(\mathcal F)$ . This is quite weird because I've seen the Euler-Poincare characteristic only for algebraic varieties. What is $\chi_S$ ? I suppose that is the alternating sum of the lengths of cohomologies where somehow we use the properties of Artinian modules. Can you please explain the construction in details?","['coherent-sheaves', 'algebraic-geometry', 'sheaf-cohomology', 'schemes']"
3327540,Is there a theorem related to 0 xor 1 xor 2 xor ... xor 1000000 = 1000000?,"While testing for a program, I found that 0 xor 1 xor 2 xor ... xor 1000000 = 1000000 and it is true for the numbers in this form except for 10: 1 1 true
10 11 false
100 100 true
1000 1000 true
10000 10000 true
100000 100000 true
1000000 1000000 true
10000000 10000000 true
100000000 100000000 true
1000000000 1000000000 true (the true means it follows the rule and false means it doesn't). Is there any theorem that is related to this? And what is so special about the number 10? The program in Ruby if you are interested to try out: n = 1
10.times do
   r = (0..n).inject(:^)
   puts ""#{n} #{r} #{n == r}"" 
   n *= 10
end",['discrete-mathematics']
3327545,On a proof of Cauchy's theorem,"I am reading various reviews of Ablowitz and Fokas' Complex Variables: Introduction and Applications . In one review , the reviewer wrote that the authors' proof (which will be replicated below) of Cauchy-Goursat theorem is simply wrong. However, to my knowledge, the more or less identical proofs have been used in many books, such as Brown and Churchill's Complex Variables and Applications , 8/e (2004, pp.152-156),
Moore and Hadlock's Complex Analysis (1991, p.68), James Kelly's Graduate Mathematical Physics (2006, pp. 29-31) as well as Krishna's Complex Analysis (2010, pp.293-295) written by Vasishtha et al. . Here are my questions: Is the proof really wrong? If this proof is correct, is it a good one? It seems that this proof is fairly shorter than many others (such as Priestley's or Bak and Newman's). Below are the statement and proof of the theorem that appear on pp.105-108 of the second edition of Ablowitz and Fokas' text. (A more detailed proof in the same spirit with very similar wordings can be found in Brown and Churchill's textbook.) Theorem 2.7.1 (Cauchy-Goursat) If a function $f(z)$ is analytic at all points interior to and on a simple closed contour, then $$\oint_C f(z)dz=0.\tag{2.7.1}$$ Proof Consider a finite region $R$ consisting of points on and within a simple closed contour $C$ . We form a square mesh over the region $R$ by drawing lines parallel to the $x$ and $y$ axes such that we have a finite number of square subregions in which each point of $R$ lies in at least one subregion. If a particular square contains points not in $R$ , we delete these points. Such partial squares will occur at the boundary (see Figure 2.7.1). We can refine this mesh by dividing each square in half again and again and redefine partial squares as above. We do this until the length of the diagonal of each square is sufficiently small. We note that the integral around the contour $C$ can be replaced by a sum of integrals around the boundary of each square or partial square $$\oint_C f(z)dz = \sum_{j=1}^n \oint_{C_j} f(z)dz\tag{2.7.2}$$ where it is noted that all interior contours will mutually cancel because each inner side of a square is covered twice in opposite directions. Introduce the following equality: $$f(z)=f(z_j)+(z-z_j)f'(z_j)+(z-z_j)\tilde{f}_j(z)\tag{2.7.3a}$$ where $$\tilde{f}(z)=\left(\frac{f(z)-f(z_j)}{z-z_j}\right)-f'(z_j)\tag{2.7.3b}$$ We remark that $$\oint_{C_j}dz=0, \quad \oint_{C_j}(z-z_j)dz=0\tag{2.7.4}$$ which can be established either by direct integration or from the known anti-derivatives: $$1=\frac{d}{dz}z, \quad (z-z_j)=\frac{d^2}{dz^2}\frac{(z-z_j)^2}{2}, \quad\ldots$$ then using the results of Theorem 2.4.1... (Remark by question asker: theorem 2.4.1 here refers to the contour integral analogue of the fundamental theorem of calculus, i.e. $\int_C f(z)dz = F(z_2)-F(z_1)$ when $F$ is an analytic function with a continuous derivative $f$ in a domain $D$ and $C$ is a contour lying inside $D$ with endpoints $z_1$ and $z_2$ .) ... Then, it follows that \begin{align}
\left|\oint_C f(z)dz\right|
&\leq \sum_{j=1}^n \left|\oint_{C_j}f(z)dz\right|\\
&= \sum_{j=1}^n \left|\oint_{C_j}(z-z_j)\tilde{f}_j(z)dz\right|\\
&\leq \sum_{j=1}^n \oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz\tag{2.7.5}
\end{align} It can be established (remark by question asker: see Brown and Churchill for details) the mesh can be refined sufficiently such that $$\left|\tilde{f}_j(z)\right|=\left|\frac{f(z)-f(z_j)}{z-z_j}-f'(z_j)\right|<\epsilon\tag{2.7.6}$$ Calling the area of each square $A_j$ , we observe the geometric fact that $$|z-z_j|\leq\sqrt{2A_j}\tag{2.7.7}$$ Thus, using Theorem 2.4.2 (remark by question asker: i.e. the M-L formula) for all interior squares, we have $$\oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz \leq (\sqrt{2A_j})\epsilon(4\sqrt{A_j})=4\sqrt{2}\epsilon A_j\tag{2.7.8}$$ and for all boundary squares, the following upper bound holds: $$\oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz \leq (\sqrt{2A_j})\epsilon(4\sqrt{A_j}+L_j)\tag{2.7.9}$$ where $L_j$ is the length of the portion of the contour in the partial square $C_j$ . Then $\oint_C f(z)dz$ is obtained by adding over all such contributions Eqs. $(2.7.8)$ and $(2.7.9)$ . Calling $A=\sum A_j,\ L=\sum L_j$ , quantity $A$ being the area of the square mesh bounded by the contour $C$ and $L$ the length of the contour $C$ , we have $$\oint_C f(z)dz \leq \left(4\sqrt{2}A+\sqrt{2AL}\right)\epsilon\tag{2.7.10}$$ We can refine our mesh indefinitely so as to be able to choose $\epsilon$ as small as we wish. Hence the integral $\oint_C f(z)dz$ must be zero. $\ {}_\blacksquare$","['complex-analysis', 'solution-verification']"
3327560,Étale cover of proper schemes,"In Topology, by Definition, when we have a compact space $X$ and an open cover $(U_i)_{i\in I}$ , there exists a finite subcover $U_1,\ldots, U_n$ which covers $X$ . Is there an analogous definition for general Grothendieck topologies? For instance, does there exist the definition of properness in the étale topology, by which I mean that if $(U_i \rightarrow X)_i$ is an étale cover of $X$ , there exists a finite subset of étale open $(U_1\rightarrow X), \ldots, (U_n \rightarrow X)$ ? Furthermore, if $k$ is a field and $X$ a proper $k$ -scheme, is it proper in the étale topology?","['algebraic-geometry', 'grothendieck-topologies']"
3327564,Using de Moivre's formula to find an expression for $\sin 3x$ in terms of $\sin x$ and $\cos x$,"I was asked to use de Moivre's formula to find an expression for $\sin 3x$ in terms of $\sin x$ and $\cos x$ . De Moivre's formula is this: $$\cos nx+i\sin nx=(\cos x+i\sin x)^n$$ I plugged $3$ in for $n$ and got the following: $$\cos 3x+i\sin 3x = (\cos x+i\sin x)^3$$ At this point, I am stuck. I don't know how to take this and solve for $\sin 3x$ . I could do: $\sin 3x=\frac{(\cos x+i\sin x)^3-\cos 3x}{i}$ , but I do not think the answer is supposed to have an imaginary number in it. If I expand my numerator I get: $$\frac{\cos^3x-3\sin^2x\cos x+i(3\cos^2x\sin x-\sin^3x)-\cos 3x}{i}$$ Simplifying this gets me: $$\frac{-3\sin^2x\cos x}i+3\cos^2x\sin x-\sin^3x$$ This still leaves me with an imaginary number. How do I get rid of it? And, are my other steps correct?","['trigonometry', 'complex-numbers']"
3327586,Show that $\alpha=||x(t)||_2$ where $t> 0$.,"Consider the initial value problem: $x^{'}(t)=Ax(t),x(0)=x_0$ where $t\ge 0$ Suppose that $A$ is a skew symmetric matrix and $\alpha=||x_0||_2$ . Show that $\alpha=||x(t)||_2$ where $t> 0$ . My try : I got easily the fact that $x(t)=e^{Ax} +x_0$ where $\alpha=||x_0||_2$ . But I am not getting how to show that $\alpha=||x(t)||_2$ . Can someone give some hint on how to apply the fact that $A^T=-A$ and how to get this?","['matrices', 'matrix-equations', 'ordinary-differential-equations', 'matrix-calculus']"
3327593,Prove $r$ the smallest quadratic non-residue modulo $p \geq 3$ is prime,"I've been struggling to find the solution for this question for a while now and thought I might as well ask for some help. The question is: Let $r$ be the smallest positive quadratic non-residue modulo $p \geq 3$ , that is, the smallest positive integer $r$ for which the congruence $x^2 \equiv r \enspace (\textrm{mod} \enspace p)$ has no solution. Prove that r is a prime number. Any help is appreciated. Thank you!","['modular-arithmetic', 'number-theory', 'discrete-mathematics', 'quadratic-residues', 'prime-numbers']"
3327602,"If $\alpha$ is a quadratic integer in $\mathbb{Q}[\sqrt{d}]$, then define a notion of congruence $\pmod{\alpha}$.","If $\alpha$ is a quadratic integer in $\mathbb{Q}[\sqrt{d}]$ Q, then define a notion of congruence $\pmod{\alpha}$ . Furthermore, define $+$ , $−$ , and $\times$ for congruence classes, and show that this notion is well-defined. I believe that the notion of congruence $\pmod{\alpha}$ means $x+y\sqrt{d}\equiv z+w\sqrt{d}$ , $x\equiv z$ and $y\equiv w$ modulo $\alpha$ . Also, I was able to define $+$ for all congruence classes, which would be $[a,b]+[c,d]=[a+c,b+d]$ . What would the congruence classes be for $-$ and $\times$ ? Also, how would I be able to show that this notion is well-defined?","['number-theory', 'algebraic-number-theory']"
3327614,Integrability of a distribution on $S^{2n-1}$,"Let $\theta$ be the restriction of $$ \eta = x^2 dx^1 - x^1 dx^2 + \cdots + x^{2n} dx^{2n-1} - x^{2n-1} dx^{2n} $$ to the unit sphere $S^{2n-1} \subset \mathbb{R}^{2n}$ . Since $\theta$ is a nowhere vanishing $1$ -form, $\ker \theta$ defines a distribution on $S^{2n-1}$ . Is it integrable? As I understand it an equivalent condition for integrability here is that $\theta \wedge d \theta = 0$ , which holds trivially for $n = 1$ . If I computed correctly, I've gotten that $\eta \wedge d \eta \neq 0$ on $\mathbb{R}^{2n}$ except when $n = 1$ (so $\ker \eta$ is not integrable on $\mathbb{R}^{2n}$ for $n \geq 2$ ), but this does not necessarily mean that the pullback $i^*(\eta \wedge d \eta) = \theta \wedge d \theta$ along the inclusion map $S^{2n-1} \to \mathbb{R}^{2n}$ is nonzero as well, right? In which case I'm not sure how to go about this, since checking whether $\theta \wedge d \theta = 0$ directly in local coordinates on $S^{2n-1}$ seems messier than an intended solution.. (this is an old exam problem). Any help would be appreciated!",['differential-geometry']
3327644,"What does the adjoint action of a Lie group on its Lie algebra, ${\rm Ad}:G\times{\frak g\to g}$, actually give us?","We know that a Lie group G acts on itself by conjugation. That is, $g \rightarrow I_g = R_{g^{-1}}\circ L_g$ and that this action is an automorphism associated to $G$ . We also know that conjugation maps $e$ (identity on $G$ ) to itself so we would expect the derivative of $I_g$ to map $T_eG=\mathfrak{g}\rightarrow T_eG=\mathfrak{g}$ . Now, according to Marsden and Ratiu's $\textit{Introduction to Mechanics and Symmetry}$ (Chapter 9, pg. 311), differentiating $I_g$ at $e$ gives the $\textbf{adjoint representation}$ of $G$ on $\mathfrak{g}$ : $$\textrm{Ad}_g:=T_eI_g:T_eG=\mathfrak{g}\rightarrow T_eG=\mathfrak{g}$$ Explicitly, the adjoint action of $G$ on $\mathfrak{g}$ is given by $$\textrm{Ad}:G\times \mathfrak{g}\rightarrow \mathfrak{g},\:\:\:\:\:\textrm{Ad}_g(\xi) = T_e(R_{g^{-1}}\circ L_g)\xi$$ $\textbf{Question}$ : What is that map actually giving us? What does taking the derivative actually mean here? (Yes, I know its a tangent space map but, that doesn't tell me much about this particular case) It's taking in a vector in $\mathfrak{g}$ and outputting what exactly? I feel like almost $\textit{every}$ book just gives something like 'differentiating the conjugate gives a map from $\mathfrak{g}$ to $\mathfrak{g}$ ' and hides what's happening inside. The example from Marsden and Ratiu leads to more questions than answers too. $\textbf{Example}:$ For $SO(3)$ we have $I_A(B) = ABA^{-1}$ so differentiating with respect to $B$ at $B=\textrm{identity}$ gives $\textrm{Ad}_A \hat{v} = A\hat{v}A^{-1}$ . However $$(\textrm{Ad}_A \hat{v})(w) = A\hat(v)A^{-1}w = A(v \times A^{-1}w) = Av \times w$$ so $$(\textrm{Ad}_A\hat{v})=(Av)^{\hat{}}$$ Identifying $\mathfrak{so}(3)$ with $\mathbb{R}^3$ gives $Ad_A v = Av$ . $\textbf{Question:}$ What????? How did we end up evaluating at $w$ . How did we end up taking a cross product in there? And again, what did we really end up with as a result of this map? A representation should be a matrix associated to an element of the Lie group, no? So what is our matrix in this example? Is it $A$ ? $\textbf{Further context}$ : I'm trying very hard to understand this to get to what is meant by the $\textrm{Ad}^*$ -equivariant moment map.","['symplectic-geometry', 'lie-algebras', 'tangent-spaces', 'lie-groups', 'differential-geometry']"
3327711,"What does ""isomorphism"" exactly refer to in topology?","I am reading an article and I came across the sentence that states as below: ""A linear separating isomorphism from $C(T)$ onto $C(S)$ is continuous, in which $C(S)$ and $C(T)$ denote sup-normed Banach spaces of real or complex-valued continuous
functions on the compact Hausdorff spaces $S$ and $T$ , respectively."" The writer has used only the injectivity and surjectivity properties to prove the theorem, so it has made me think that the isomorphism mentioned above is the same as a bijection map .
On the other hand, I have been used to seeing isomorphisms in Algebra. Is there anything more than this with the word isomorphism in the sentence above? Any help would be highly appreciated.","['general-topology', 'real-analysis']"
3327728,"Is this ""one-sided"" version of the fundamental lemma of calculus of variations true?","Let $\mathbb{D}^n \subseteq \mathbb{R}^n$ be the closed $n$ -dimensional unit ball, and let $A:\mathbb{D}^n \to \mathbb{R}^k \otimes \mathbb{R}^k$ be smooth. Suppose that $ \langle A , V \otimes V \rangle_{L^2} \ge 0$ for every smooth map $V:\mathbb{D}^n \to \mathbb{R}^k$ . Explicitly, I assume that $ \int_{\mathbb{D}^n} \langle A(x) , V(x) \otimes V(x) \rangle_{\mathbb{R}^k \otimes \mathbb{R}^k} dx \ge 0$ where $\langle , \rangle_{\mathbb{R}^k \otimes \mathbb{R}^k}$ is the tensor product metric on $\mathbb{R}^k$ , i.e. $$ \langle v_1 \otimes v_2 , w_1 \otimes w_2\rangle := \langle v_1, w_1 \rangle_{\mathbb{R}^k} \cdot \langle v_2 ,w_2 \rangle_{\mathbb{R}^k}.$$ Question: Is it true that $ \langle A(x) , v \otimes v \rangle_{\mathbb{R}^k \otimes \mathbb{R}^k} \ge 0$ for every $x \in \mathbb{D}^n$ and every $v \in \mathbb{R}^k$ ? This seems like a ""one-sided"" analogue of the fundamental lemma of the calculus of variations .","['calculus-of-variations', 'variational-analysis', 'multivariable-calculus', 'real-analysis']"
3327772,How to prove these two elements are conjugate?,"This is a problem from S.-T. Yau College Student Mathematics Contests 2019. Let $G$ be a finite group. Assume that for any representation $V$ of $G$ over a field of characteristic zero, the character $\chi_{V}$ takes value in $\mathbb{Q}$ . Assume $g$ is an element in $G$ such that $g^{2019}=1$ . Prove that $g$ and $g^{19}$ are conjugate in $G$ . Here is what I have got: Since $\chi_V$ is an algebraic integer, we can deduce $\chi_V$ takes value in $\mathbb{Z}$ . To prove $g$ and $g^{19}$ are conjugate in $G$ , it suffices to show $\chi_V(g)=\chi_V(g^{19})$ for any irreducible representation $V$ , because any class functions of $G$ is a linear combination of $\chi_V$ where $V$ is irreducible. I know the fact that $\chi_V$ takes value in $\mathbb{Z}$ plays an important role in this problem. But I don't know how to use it. I hope someone may help me. Thanks a lot!","['representation-theory', 'group-theory', 'finite-groups']"
3327786,What is the surface area of given surface .,"Compute the area of that part of plane $x+y+z=2a$ which lies in the first octant and is bounded by the cylinder $x^2+ y^2 =a^2$ Now $z = 2a -x -y$ , $\dfrac{\partial{z}}{\partial{x}} = -1$ $\dfrac{\partial{z}}{\partial{y}} = -1$ , $ds  = \sqrt{3}dxdy$ Area is given by : $\int\int_{A} \sqrt{3}dxdy$ where A is the area of $x^2+ y^2 =a^2$ in first quadrant. so Surface area  = $\dfrac{\sqrt{3}\pi a^2}{4}$ .  However the answer in my book is $\dfrac{3\pi a^2}{4}$ . can anyone tell me what is wrong with my solution ? and why is my answer is incorrect ?","['integration', 'multivariable-calculus']"
3327799,"Plane coloring $\mathbb{R}^2$, $2$ colors per line",Is there a coloring of $3$ colors on $\mathbb{R}^2$ such that every line contains exactly $2$ (different) colors and there is no triangle with unit area whose vertices lie on $3$ different colors? All points have to be colored. All $3$ colors have to be used.,['discrete-mathematics']
3327803,Coadjoint action of Lie group on dual of its Lie algebra,"From Marsden and Ratiu's $\textit{Introduction to Mechanics and Symmetry}$ : The $\textbf{coadjoint representation}$ of $G$ on $\mathfrak{g}^*$ , the dual of the Lie algebra $\mathfrak{g}$ is defined as follows. Let $\textrm{Ad}_g^*:\mathfrak{g}^* \rightarrow \mathfrak{g}^*$ be the dual of $\textrm{Ad}_g$ defined by $$\langle \textrm{Ad}_g^*\alpha, \xi\rangle = \langle \alpha, \textrm{Ad}_g \xi \rangle$$ for $\alpha \in \mathfrak{g}^*$ and $\xi \in \mathfrak{g}$ . Then the map $$\Phi^*:G\rightarrow GL(\mathfrak{g}^*,\mathfrak{g}^*), \:\:\:\:\:\:\textrm{Ad}_{g^{-1}}^*=(T_e(R_g \circ L_{g^{-1}}))^*$$ $\textbf{Question}:$ How are the natural pairings given above related to the map $\Phi^*$ ? What is being taken in and what is being produced by the mapping? Also, in the definition of $\Phi^*$ , why is there a $g^{-1}$ written in $\textrm{Ad}_{g^{-1}}^*$ . Also, what is the actual representation of $g$ on $\mathfrak{g}^*$ ? It should be a matrix, yes? I don't see it. My apologies if the answers to these questions seem obvious to some but to me, this definition seems almost deliberately opaque and any clarification will be much appreciated.","['symplectic-geometry', 'lie-algebras', 'tangent-spaces', 'lie-groups', 'differential-geometry']"
3327907,"Generalizing Archimedes' ""The Quadrature of the Parabola""","In the third century BC Archimedes discovered that The area enclosed by a parabola and a line (left figure) is 4/3 that of a related inscribed triangle (right figure). Consequentially, the area enclosed by a parabola and a line is 2/3 that of a parallelogram which has the chord and its tangential-to-the-parabola-copy as two of its sides. I have tried to derive this result myself using calculus. Suppose $f:I \subseteq \mathbf{R} \to \mathbf{R}$ is a smooth convex function (so that the chord is on a fixed side of the graph), defined over some interval $I$ . For $a < b$ , let $[a,b] \subseteq I$ be a closed subinterval. The area of the segment bounded by the graph of $f$ and the chord $\overline{(a,f(a)) (b,f(b))}$ is given by $$\int_a^b \left( f(a)+(t-a) \frac{f(b)-f(a)}{b-a} - f(t) \right) \mathrm{d}t. \tag{1}$$ For the areas of the inscribed triangle and related parallelogram, we will use the point $c \in (a,b)$ , which has the slope $$f'(c) =\frac{f(b)-f(a)}{b-a}.$$ Such a point exists according to the MVT, and it is unique because of the convexity of $f$ . Thus $$c = c(a,b)= f'^{-1} \left( \frac{f(b)-f(a)}{b-a} \right). $$ The area of the aforementioned parallelogram is then the area between two parallel segments $$\int_a^b \left[ f(a)+(t-a) \frac{f(b)-f(a)}{b-a} - \left( f(c)+(t-c) \frac{f(b)-f(a)}{b-a} \right) \right] \mathrm{d}t.$$ Archimedes' result implies that $$
\begin{align}&\int_a^b \left( f(a)+(t-a) \frac{f(b)-f(a)}{b-a} - f(t) \right) \mathrm{d}t \\
&= 
k \int_a^b \left[ f(a)+(t-a) \frac{f(b)-f(a)}{b-a} - \left( f(c)+(t-c) \frac{f(b)-f(a)}{b-a} \right) \right] \mathrm{d}t
\end{align} \tag{3}$$ for $f(x)=x^2$ , $a<b$ , $c(a,b)=\frac{a+b}{2}$ and $k=\frac{2}{3}$ . My questions are about going in reverse: Is it possible to systematically arrive at $f(x)=x^2$ (or a similar parabola), starting off with knowledge that $f$ is convex over some interval, $f$ satisfies Equation $(3)$ for all subintervals $[a,b]$ of its domain and $k=\frac{2}{3}$ ? Is it possible to generalize this result by solving Equation $(3)$ for $k \neq \frac{2}{3}$ (clearly, $k \leq 1$ )? I would appreciate guidance on how to do this if possible. Thanks!","['integration', 'integral-equations', 'ordinary-differential-equations', 'geometry', 'calculus']"
3327949,Proof verification: if $W_1 \subseteq W_2$ then $\dim(W_1) \le \dim(W_2)$,"Let $W_1$ and $W_2$ be subspaces of vector space $V$ . Prove that
  If $W_1 \subseteq W_2$ then $\dim(W_1) \le \dim(W_2)$ . My proof:
Let $v_1, ...,v_n$ be base vectors of vector space $W_1$ and $W_1 \subseteq W_2$ . Then $\dim(W_1) = n$ .
From the assumptions we have that $v_1, ..., v_n \in W_2$ and because they are base vectors in $W_1$ they are lineary independent. Therefore 
if $\operatorname{span}(v_1, ...,v_n) = W_2$ then $\dim(W_2) = n = \dim(W_1)$ . Otherwise there exists vector $v_{n+1} \in W_2$ such that $v_{n+1}$ is not linear combination of $v_1, ...,v_2$ and therefore $\dim(W_2) \ge n+1$ . Hence $\dim(W_1) \le \dim(W_2)$ .","['proof-verification', 'linear-algebra', 'vector-spaces']"
3327957,Limits and Continuity in Multi variable calculus.,"Checking continuity of $f(x,y)$ at $(0,0)$ : $$
f(x,y)=\begin{cases}\dfrac{x^3+y^3}{x-y}\ \ ,x\neq y\\0\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ,x=y
\end{cases}$$ Using polar coordinates $x=r\cos\theta$ and $y=r\sin\theta$ , $$\lim_{r\rightarrow 0}\dfrac{r^3(\cos^3\theta+\sin^3\theta)}{r(\cos\theta-\sin\theta)}=0$$ Hence, $$\lim_{(x,y)\rightarrow (0,0)}f(x,y)=f(0,0)=0$$ But its graph doesn't look like continuous near-complete $z$ -axis. Being very new to this I don't know what's going on here, please help.","['multivariable-calculus', 'limits', 'calculus', 'continuity']"
3327995,Some fine details in the Proof of Hartshorne II.8.17,"Me again, sorry for keep spamming with Hartshorne post. But for sure I think questions like this can facilitate other's learning. I am fine with the proof above the red line. What I would like to ask is some details on the parts underlined in green. I understand how we obtain the ideal sheaf $\mathscr{I}'$ , but I am not sure why there is a ""corresponding closed subscheme"". It appears to me that the structure of Theorem 8.17 is as follows: Assume $Y$ is irreducible and some other conditions, then "" $Y$ is singular"" iff ""condition (1)+(2) are satisfied"". Now in the second underline, it seems to me it means conditions (1)+(2) will implies non-singularity together with irreducibility , which is an assumption statement. First of all, I cannot see explicitly why $Y\subseteq Y'$ and I cannot find any reference to the fact that both scheme being integral, irreducible will lead to the fact that $Y=Y'$ and $\mathscr{I}=\mathscr{I}'$ . Thank you very much in advance.","['proof-explanation', 'algebraic-geometry']"
3328029,Is every finite rank operator a linear combination of rank one projections?,"Let $X$ be a Banach space and let $F(X)\subseteq B(X)$ be the subset of finite rank operators. Let $u\in F(X)$ , must $u$ be a linear combination of rank one projections? I know this result is true for Hilbert spaces, but I suspect it fails in general even though I don't have a counterexample.","['banach-spaces', 'functional-analysis']"
3328094,Number of minimal sections in a (geometrically) ruled surface,"Let $\mathbb{P}(X)$ be a non-trivial $\mathbb{P}^1$ -bundle over a curve $C$ (here $X$ is a vector bundle of rank 2 over $C$ ). A minimal section of $\mathbb{P}(X)$ is a section of minimal self-intersection. My questions are the following: Can $\mathbb{P}(X)$ admit a infinite number of minimal section? If not, why? Is there a known example of non trivial $\mathbb{P}^1$ -bundle with $3$ distinct minimal sections (or infinite number of minimal section, and it would also answer my first question)? The related examples that I know are the following: If $\mathbb{P}(X)\simeq \mathbb{F}_n$ is a Hirzebruch surface (i.e $C\simeq \mathbb{P}^1$ ) with $n\neq 0$ . Then there exists an unique minimal section of self-intersection $-n$ . If $C$ is an elliptic curve. It follows from the article (plus a little extra work): Maruyama, M. , On automorphism groups of ruled surfaces , J. Math. Kyoto Univ. 11, 89-112 (1971). ZBL0213.47803 .,
that all $\mathbb{P}^1$ -bundles over $C$ have at most $2$ minimal sections. Actually Maruyama shows for all curve $C$ , independently of the genus, that if the minimal self-intersection is negative then the minimal section is unique. In particular, if the example I am looking for exists, then it should be over a curve of genus $\geq2$ and the minimal self-intersection is non-negative. Unfortunately, I don't know anything on vector bundles of rank $2$ over a curve of genus $\geq 2$ and I have not found any concrete examples ... Thank you in advance for your time!",['algebraic-geometry']
3328096,Cyclic quadrilateral and trapezoid,"A circle with diameter the minor base $CD$ of a trapezium $ABCD$ intersects its diagonals $AC$ and $BD$ in, respectively, their midpoints $M$ and $N$ . The lines $DM$ and $CN$ intersect in $P$ and $AC$ and $BD$ intersect in $H$ . Show that $AD=CD=BC$ and $HP \perp AB$ . $DMNC$ is a cyclic quadrilateral and $CD||MN$ , thus $DMNC$ is an isosceles trapezoid. Therefore, $CM=DN$ and $AC=BD$ . Now I am trying to show $AD=CD$ . $\angle DCM$ is inscribed and it's equal to $\angle DNM$ but I don't see how to compare it with $\angle CAD$ . How is this done? For the second part of the problem, I tried to show that $HO$ passes through $P$ ( $HO \perp CD$ because $\triangle CDH$ is isosceles and if we show $P \in HO$ we are done).","['quadrilateral', 'euclidean-geometry', 'circles', 'geometry']"
3328113,Derivation of D-dimensional Laplacian in spherical coordinates,"I'm trying to derive the D-dimensional laplacian over Euclidean space for a function $f$ that is invariant under D-dimensional Euclidean rotations. Specifically i'm trying to go from the equation $$
\Delta_D \phi = U'(\phi)
$$ to the equation $$
\frac{d^2\phi}{dr^2}+\frac{D-1}{r}\frac{d\phi}{dr} = U'(\phi)
$$ where $r = (x_1^2+x_2^2+x_3^2+\dots+x_D^2)^{1/2}$ . I'm a physicist and currently I don't have much knowledge about differential geometry and operators over manifolds, but still i wanted to know how, in a rigorous manner, to derive that equation under that change of coordinates. Searching on the internet i found that the general form for the laplacian is given by the Laplace-Beltrami operator $$
\Delta_D \phi= \frac{1}{\sqrt{\det g}}\partial_i\left(\sqrt{\det g}g^{ij}\partial_j\phi\right)
$$ but i don't know how the metric tensor is in the coordinates specified. I know that in Euclidian space is just a Kroneker delta, but what about spherical coordinates? 
On the Wikipedia article gives the result right away without any explanation. I'm really curious to see how to derive it. I didn't find any explanation with computation in my google search.","['physics', 'laplacian', 'differential-geometry']"
3328140,"Generalizing the ""The Volume of a Cone is a Third that of its Bounding Cylinder"" fact","The ancient result is that a right-circular cone of height $h$ and base-radius $r$ will have volume $\frac{1}{3} \pi r^2h$ , which is $1/3$ the volume of the cylinder with same base and height. And the same is true if you start with a square-based pyramid: it's volume will be $1/3$ the volume of the rectangular prism that it lives in. Here's a relevant MathSE question for that . What is the most general statement of this fact that we currently know to be true? Thinking of the locally two-dimensional case, I'm pretty sure that this fact still holds if you start with any ""nice"" bounded planar region, build a generalized cylinder with bases and cross-sections congruent to that region, then take any point on a base of that cylinder as the apex of your cone. And then this generalizes even further due to Cavalieri's principle . But is this true? And in what generality is is true? Like, what conditions must we have on our base region? Furthermore, is there a version of this in higher dimensional spaces? Is there a version of this in spaces that are not $\mathbb{R}^n$ ?","['euclidean-geometry', 'geometry', 'multivariable-calculus', 'calculus', 'algebraic-geometry']"
3328142,Prove that the Pullback of a proper embedding is surjective on p-forms,"This is from an old qualifying exam, and I want to check the answer that I have given. The question is Let $N$ be a compact embedded submanifold of a manifold $M$ . Show that $\Omega^p(M) \rightarrow \Omega^p(N)$ is surjective for all $p$ . Here $\Omega^p(M)$ is the vector space of smooth $p$ -forms. Here is my attempt: Let $\iota: N \rightarrow M$ be the inclusion map and pick a point $q \in N$ . Let $(U_q, (x^i))$ be an open chart centered at $\iota(q) = q$ such that $U_q\cap N = V_q$ is a local $k$ -slice of $U_q$ . Then we know that $(\iota^{-1}(V_q), (y^i)) = (V_q, (y^i))$ where $y^i(a) = x^i(a)$ for $a\in V_q$ and $i \in \{1, \ldots, k\}$ . Then for any $\omega \in \Omega^p(N)$ , we can express $\omega$ in terms of these local coordinates as a sum over increasing multi-indices $I$ by $$\omega = {\sum_I}^\prime \omega_I dy^{i_1}\wedge \cdots \wedge dy^{i_p}$$ where each $\omega_I$ is a smooth coordinate function defined on $V_q$ . Well, if we keep the same indexing set and define the $p$ -form $\eta$ on $U_q$ by $$\eta = {\sum_I}^\prime (\eta_I) dx^{i_1}\wedge \cdots \wedge dx^{i_p}$$ with $\eta_I(\iota(a)) = \omega_I(a)$ , then \begin{align*}
\iota^*\eta &= {\sum_I}^\prime (\eta_I\circ \iota) d(x^{i_1}\circ \iota)\wedge \cdots \wedge d(x^{i_p}\circ \iota)\\
&= {\sum_I}^\prime \omega_I dy^{i_1}\wedge \cdots \wedge dy^{i_p}\\
&= \omega
\end{align*} hence we have that the map $\Omega^p(U_q) \rightarrow \Omega^p(V_q)$ is surjective for all $p$ . Now, we know that $\{U_q\}_{q\in N}$ forms an open cover of $N$ and admits a smooth partition of unity $\{\varphi_q\}_{q\in N}$ subordinate to this open cover. Define $\psi_q = \varphi_q\vert_{N}$ . Then the collection $\{\psi_q\}_{q\in N}$ will be a smooth partition of unity of $N$ subordinate to the open cover $\{V_q\}_{q\in N}$ . Let $\widetilde{\omega}\in \Omega^p(N)$ be any smooth $p$ form on $N$ . Since this form is smooth, we know that there is an indexed collection of $p$ -forms $\{\omega^q\}_{q\in N}$ such that $$\widetilde{\omega} = \sum_{q\in N}\psi_q\omega^q.$$ Now define the $p$ -form $\widetilde{\eta}\in \Omega^p(M)$ by $$\widetilde{\eta} = \sum_{q\in N}\varphi_q\eta^q$$ where each $\eta^q$ is such that $\iota^*\eta^q = \omega^q$ as given in the first portion of this proof and $\widetilde{\eta}|_y = 0$ for any $y\not\in\bigcup_{q\in N}U_q$ . This will be defined and smooth on all of $M$ since $supp(\varphi_q\eta^q)\subseteq U_q$ . Furthermore, since this partition of unity is locally finite, for any $x \in N$ , we have that $\widetilde{\omega}|_x = \iota^*\widetilde{\eta}|_x$ , and so $\widetilde{\omega} = \iota^*\widetilde{\eta}$ . Hence, $\Omega^p(M) \rightarrow \Omega^p(N)$ is surjective for all $p$ . $\qquad \clubsuit$","['differential-forms', 'differential-geometry']"
3328169,Does a graph with $6$ vertices where each vertex degree is $4$ have to be planar?,"Does a graph with $6$ vertices where each vertex degree is $4$ have to be planar?
I can draw a graph that is none planar, and another one which is planar.
furthermore, there are $12$ arcs (can get it from $6*4 = 2$ *arcs)
so according to a known theory $12 \leq 3n - 6$ so it might be planar.
but it doesn't have to be. Thanks.","['graph-theory', 'discrete-mathematics']"
3328171,How to compute $\partial \frac{1}{z^*}$?,"I have trouble understanding some basic concepts in Complex Analysis: For $z=x+\mathrm{i}y$ , we define: $$\partial \equiv \frac{\partial}{\partial z}=\frac{1}{2}\left(\frac{\partial}{\partial x}-i \frac{\partial}{\partial y}\right)$$ The following is stated as obvious: $$\partial \frac{1}{z^{*}}=\pi \delta(x) \delta(y)$$ In order to prove this equality I was told to integrate the left and right hand sides over a small square centered at the origin. However I do not recover the desired result. My main obstacles is to understand why: $$\int_{-\epsilon}^\epsilon\int_{-\epsilon}^\epsilon\pi \delta(x) \delta(y)\mathrm{d}x\mathrm{d}y\neq\pi\text{ ?}$$ $$\left(\frac{\partial}{\partial x}-i \frac{\partial}{\partial y}\right)\frac{1}{x-\mathrm{i}y}\neq-\frac{1}{(x-\mathrm{i}y)^2}+\frac{1}{(x-\mathrm{i}y)^2}=0 \text{ ?}$$ Edit: I suspect it has something to do with the fact that $\frac{1}{z^*}$ does not have a series expansion....","['integration', 'complex-analysis', 'dirac-delta']"
3328186,"Prove that $A= \left\lbrace f \in X: \int_0^1f(x) dx>1 \right\rbrace$ is an open set in $(X,d)$.","Let $X=C[0,1]$ be a set of real continuous functions on $[0,1]$ . Given these metrics below $$d(f,g)=\max_{x \in [0,1]} e^{-x^2} \vert f(x)-g(x) \vert\ , \ \forall f,g \in X$$ $$p(f,g)= \int\limits_0^1{\vert f(x)-g(x)\vert dx}, \ \forall f,g \in X$$ . Question 1: I have already proved that $p(f,g) \le e \cdot d(f,g) $ , so that with $f \in X$ and for all sequence $(f_n) \subset X$ , I have if $\lim d(f_n,f)=0$ then $\lim p(f_n,f)=0$ . Moreover, if $\lim p(f_n,f)=0$ then $\lim d(f_n,f)=0$ does not happen. However I can't find the example to point out it doesn't happen. Is there any example ? And how can you find out this example ? Question 2: Prove that $A= \left\lbrace f \in X: \int\limits_0^1f(x) dx>1 \right\rbrace$ is an open set in $(X,d)$ . For this question I intend to write it as an inversion of open set and the mapping is continuos but I stuck. Do you have any solution for this ? Thank you","['general-topology', 'metric-spaces']"
3328198,Asymptotic Gilbert-Varshamov Bound Using Hilbert's Entropy Formula,"I am reading Walker's book Codes and Curves and am having trouble proving this Lemma regarding the Asymptotic Gilbert-Varshamov bound. Suppose that $q$ is a prime power and we define \begin{align*}
V_q(n,r) &:= \sum\limits_{i=0}^r {n\choose r}(q-1)^i
\end{align*} We define the Hilbert entropy function as \begin{align*}
H_q(x) &:= \cases{0, & x= 0\\
x\log_q(q-1)-x\log_q x - (1-x)log_q(1-x), & $0 < x \leq 1-\frac{1}{q}$}
\end{align*} There is a lemma that states if $0\leq\lambda\leq 1-\frac{1}{q}$ then \begin{align*}
\lim\limits_{n\to\infty}\frac{1}{n} \log_q V_q(n,\lfloor \lambda n\rfloor) &= H_q(\lambda)
\end{align*} Walker suggests using Stirling's approximation to get this limit. Here is what I have so far: First, I find that if $0<\lambda \leq 1-\frac{1}{q}$ then \begin{align*}
H_q(\lambda) &= \lambda\log_q(q-1)-\lambda\log_q \lambda - (1-\lambda)log_q(1-\lambda)\\
&= \log_q\left(\frac{(q-1)^\lambda}{\lambda^\lambda(1-\lambda)^{1-\lambda}}\right)
\end{align*} Then, try to calculate $\lim\limits_{n\to\infty} \frac{1}{n}\log_q V_q(n,\lfloor \lambda n\rfloor)$ . \begin{align*}
\lim\limits_{n\to\infty} \frac{1}{n}\log_q V_q(n,\lfloor \lambda n\rfloor) &= \lim\limits_{n\to\infty} \log_q\left(\left(\sum\limits_{i=0}^{\lfloor \lambda n\rfloor} {n\choose i}(q-1)^i\right)^\frac{1}{n}\right)\\
&= \log_q\left(\lim\limits_{n\to\infty} \left(\sum\limits_{i=0}^{\lfloor \lambda n\rfloor} {n\choose i}(q-1)^i\right)^\frac{1}{n} \right)
\end{align*} Looking only at the terms inside the logarithm, I would like to show that \begin{align*}
\lim\limits_{n\to\infty} \left(\sum\limits_{i=0}^{\lfloor \lambda n\rfloor} {n\choose i}(q-1)^i\right)^\frac{1}{n}  &= \frac{(q-1)^\lambda}{\lambda^\lambda(1-\lambda)^{1-\lambda}}
\end{align*} Unfortunately, I get stuck here. This stackexchange post pointed me to this resource which essentially shows the case for $q=2$ in exercise 9.42. It looks easy to generalize to this problem using the provided method. However, I do not quite understand this crucial step: If we let $m = \lfloor\lambda n\rfloor$ , then we get that \begin{align*}
{n\choose m}\sum\limits_{i=0}^m \left(\frac{\alpha}{1-\alpha}\right)^i = {n\choose m}\frac{1-\alpha}{1-2\alpha}
\end{align*} This step seems so simple based off of geometric series, but I cannot get my calculations into the provided form.","['coding-theory', 'combinatorics', 'entropy', 'asymptotics']"
3328203,Does asymmetric fraction of finite groups tend to $0$?,"Let’s define asymmetric fraction of a finite group $G$ as the number $af(G) = \frac{|\{(g, a) \in G \times Aut(G)| a(g) = g\}|}{|G||Aut(G)|}$ . Equivalently it can be defined as $P(A(X) = X)$ , where $A$ and $X$ are independent uniformly distributed random elements of $Aut(G)$ and $G$ respectively. Is it true, that $\forall \epsilon > 0 \exists N \in \mathbb{N} \forall G ((\lvert\,G\,\rvert > n) \to (af(G) < \epsilon))$ ? I know, that $af(C_{p^n}) = \dfrac{p^n + \Sigma_{i = 1}^n  p^ip^{n - 1 - i}(p - 1)}{p^{2n - 1}(p - 1)} = \dfrac{(np - n + 1)}{p^n(p - 1)}$ and, that $af(G) \leq \frac{1}{2} + \dfrac{|\{g \in G| \forall a \in Aut(G) \text{ } a(g) = g\}|}{2|G|}$ . However this is clearly not enough to prove the statement.","['automorphism-group', 'finite-groups', 'group-theory', 'group-actions', 'probability']"
3328227,"Is there a known non-euclidean geometry where two concentric circles of different radii can intersect? (as in the novel ""The Universe Between"")","From the 1951 novel The Universe Between by Alan E. Nourse. Bob Benedict is one of the few scientists able to make contact with the invisible, dangerous world of The Thresholders and return—sane! For years he has tried to transport—and receive—matter by transmitting it through the mysterious, parallel Threshold. [...] Incredibly, something changed. A pause, a sag, as though some terrible pressure had
  suddenly been released. Their fear was still there, biting into him, but there was something else. He was aware of his body around him in its curious configuration of orderly disorder, its fragments whirling about him like sections of a crazy quilt. Two concentric circles of different radii intersecting each other at three different points . Twisting cubic masses interlacing themselves into the jumbled incredibility of a geometric nightmare. The author might be just throwing some terms together to give the reader a sense of awe, but maybe there's some non-euclidean geometry where this is possible.","['noneuclidean-geometry', 'big-list', 'geometry', 'circles', 'soft-question']"
3328238,Understanding the sheaf $\mathcal{O}_x(U)$ over an open $U\subseteq X$ as a subset of the Cartesian product $\prod_{P\in U} R_P$.,"I am reading from the red book of varieties and schemes of David Mumford about sheaves: Let $R$ be a commutative ring, $1\in R$ , $X=\text{Spec}R$ the set of all prime ideals $P \nsubseteq R$ and a $U\subseteq X$ an open subset of $X$ with the Zariski topology. Moreover, let $R_S=S^{-1}R$ the localization of $R$ over a multiplicatively closed subset $S\subseteq R$ . Definition: The author defines $\mathcal{O}_x(U)=\Gamma(U,\mathcal{O}_X)$ to be the set of elements $$\{s_P\} \in \prod_{P\in U} R_P$$ for which there exists a covering of U by distinguished open sets $X_{f_a}$ together with elements $s_a\in R_{f_a}$ such that $s_P$ equals the image of $s_a$ in $R_P$ whenever $P \in X_{f_a}$ . Questions : 1) What exactly are the elements $\{s_p\}$ ? Is an element $s\in \prod_{P\in U} R_P$ a ""P-tuple""? Is it something like $s=(...,s_P,s_Q,...) \in \prod_{P\in U} R_P$ such that $s_P \in R_P$ , $s_Q \in R_Q$ for some prime $P,Q \in U$ ? 2) I suppose that to find the image of $s_a$ in $R_P$ , we use the fact that $P \in X_{f_a}$ , and so $f_a \notin P$ , so we can write $s_a=\frac{g_a}{{f_a}^n} \in R_{f_a}$ , hence the image of $s_a$ in $R_p$ is the corresponding germ $[s_a]=[(\frac{g_a}{{f_a}^n},X_{f_a})]$ in the direct limit $$R_P=\varinjlim\limits_{X_f \in U_p} R_f,$$ where $U_p=\{X_f:P\in X_f\}$ . Is that right? 3) I can't see how $s_P$ can coincide with $[s_a]$ , where $[s_a]$ is the image of $s_a$ in $R_P$ . Can you give me a simple example of a commutative ring $R$ and an open $U\nsubseteq X$ such that $\{s_P\}_{P \in U}=\{[s_a]\}_{a\in A}$ as in the above definition? What is $\mathcal{O}_x(U)$ in this case and how is it related with the tuples $\{s_P\} \in \prod_{P\in U} R_P$ ? 4) Does there exist an alternative definition of $\mathcal{O}_x(U)$ or a book/link which gives more details/examples about this definition?","['algebraic-geometry', 'sheaf-theory']"
3328267,How to solve a first order differential equation with parameters inside functions: $ag'(cy)+bg'(ey)=\alpha$,"I am trying to solve a first order differential equation with the condition that $g(y)=0$ iff $y=0$ : \begin{align*}
    &ag'(cy)+bg'(ey)=\alpha\\
    &g(0)=0, \tag{1}
\end{align*} where parameters $a,b,c,e$ are real nonzero constants; $\alpha$ is a complex constant; function $g(y):\mathbb{R}\to \mathbb{C}$ is a function mapping from real number $y$ to a complex number. The goal is to solve for function $g(\cdot)$ . This is what I have done. Solve this differential equation by integrating with respect to $y$ : \begin{align*}
    \frac{a}{c}g(cy)+\frac{b}{e}g(ey)=\alpha y+\beta,
\end{align*} where $\beta$ is another complex constant. Plugging in $y=0$ and using the fact that $g(0)=0$ , we have $\beta=0$ . Therefore, we have \begin{align*}
    \frac{a}{c}g(cy)+\frac{b}{e}g(ey)=\alpha y.
\end{align*} The background of this problem is Cauchy functional equation, so my conjecture is one solution could be $g(y)=\gamma y$ . Plugging in $g(y)=\gamma y$ , I get $\gamma=\frac{\alpha}{a+b}$ , which implies that one solution is $g(y)=\frac{\alpha}{a+b} y$ . Then, I move on to show uniqueness. I define a vector-valued function $h\equiv (h_1,h_2)^T$ such that \begin{align*}
    h_1(y)&=\frac{a}{c}g_1(cy)+\frac{b}{e}g_1(ey)\\
    h_2(y)&=\frac{a}{c}g_2(cy)+\frac{b}{e}g_2(ey),
\end{align*} where $g(y)\equiv g_1(y)+ig_2(y)$ . Then, I rewrite this differential equation as \begin{align*}
    &h'(y)=\alpha\\
    &h(0)=0, \tag{2}
\end{align*} where $\alpha\equiv (\alpha_1,i\alpha_2)^T$ . By the uniqueness theorem of first order differential equation, solution $h(y)$ is unique. I have two questions. First, I think equation (1) and (2) should be equivalent. However, it seems that equation (1) can imply equation (2) but equation (2) may not imply equation (1). This is because $h(0)=0$ may imply either $g_1(0)=0,g_2(0)=0$ or $\frac{a}{c}+\frac{b}{e}=0$ . Second, I have only proved that $h(y)$ is unique. How should I proceed to show $g(y)$ is also unique.","['functional-equations', 'ordinary-differential-equations']"
3328286,Mind-blowing Sums: Compute $\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^22^n}$ and $\sum_{n=1}^\infty\frac{H_n^3}{n^22^n}$,"How to prove the following two sums \begin{align}
\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{n^22^n}&=2\operatorname{Li}_5\left(\frac12\right)+\ln2\operatorname{Li}_4\left(\frac12\right)-\frac{31}{32}\zeta(5)+\frac{1}{8}\ln2\zeta(4)+\frac18\zeta(2)\zeta(3)\\&\quad-\frac{1}{12}\ln^32\zeta(2)+\frac{1}{40}\ln^52
\end{align} \begin{align}
\sum_{n=1}^\infty\frac{H_n^3}{n^22^n}&=-14\operatorname{Li}_5\left(\frac12\right)-9\ln2\operatorname{Li}_4\left(\frac12\right)+\frac{279}{16}\zeta(5)-\frac{25}{4}\ln2\zeta(4)-\frac78\zeta(2)\zeta(3)\\&\quad-\frac74\ln^22\zeta(3)+\frac{13}{12}\ln^32\zeta(2)-\frac{31}{120}\ln^52
\end{align} where $H_n^{(p)}=1+\frac1{2^p}+\cdots+\frac1{n^p}$ is the $n$ th generalized harmonic number of order $p$ and $\operatorname{Li}_s(x)=\sum_{n=1}^\infty\frac{x^n}{n^s}$ is the polylogarithmic function. Edit: These two sums were proposed by Cornel Ioan Valean here but no solution was submitted. I am presenting my solution in the answer section and  would like to see different approaches. Thanks.","['integration', 'definite-integrals', 'harmonic-numbers', 'polylogarithm', 'sequences-and-series']"
3328387,Computing $(A\otimes I + I \otimes A)^{-1} \text{vec}B$,"Suppose I have two positive semi-definite $n$ -by- $n$ matrices $A$ , $B$ and an $n$ -by- $n$ identity matrix $I$ , and I'm looking for a way to compute, approximate or bound the following quantity: $$(A\otimes I + I \otimes A)^{-1} \text{vec}B$$ Concretely I'm dealing with matrices with $n$ ranging from $100$ to $4000$ , so $A$ is easy to invert, while $A \otimes I$ is too large, so need a way to compute this using operations on $n$ -by- $n$ matrices Additionally, I found the following to give a decent approximation when $A$ , $B$ can be Kronecker-factored, wondering if there's a reason for that. $$0.5 A^{-0.5} B  A^{-0.5}$$ Any tips or literature pointers are appreciated!","['control-theory', 'linear-algebra', 'inverse', 'kronecker-product', 'matrix-equations']"
3328404,drawing marbles with different probabilities,"Suppose I have $N$ marbles ( $m_1$ to $m_N$ ).
The chance that I take the $i$ -th marble $m_i$ is $p(0,i)$ (adding up to $1$ ).
If I now take a marble (say the marble with number $M_1$ ) out and want to take a second one, the chances, for all $i<>M_1$ , have changed to $p(1,i)=\frac{p(0,i)}{1-p(0,M_1)}$ , again adding up to 1 (and $p(1,M_1)=0$ ). 
If I want to take a third one, again the chances will have chanced, depending on the first 2 I took out. Now my question is: what is the chance, when I take $K$ marbles out of a bag containing $N$ marbles, that marble $m_1$ is not taken? I'm looking for a result in terms of the original chances $p(0,i)$ . For $p(0,i)=\frac{1}{N}$ this is the traditional problem. Just so that you don't wonder about the marbles having different probabilities: the question comes from a different perspective: I'm trowing darts at balloons of different lengths hanging in line and have therefor different chances of hitting them. When one is hit, it will disappear and the other balloons will again form a line (so no gaps). Thanks in advance","['statistics', 'probability']"
3328417,"Numerical range of the first derivative operator on $\{ u \in H^1(0,1): u(1)=0 \}$","I need to calculate the numerical range of the operator $T:D(T)\subseteq L^2(0,1) \to L^2(0,1)$ defined by $$D(T):=\{ u \in H^1(0,1): u(1)=0 \}, \ Tu:=u', \ u \in D(T),$$ where $H^1(0,1)$ is the Sobolev space of functions in $L^2(0,1)$ whose first weak derivative belongs to $L^2(0,1)$ . My attempt For each $u \in D(T)$ with $\|u \|=1$ we have that $$\langle Tu,u \rangle=\int_0^1u' \overline{u}dx=-|u(0)|^2 - \int_0^1u\overline{u'}dx.$$ If we add $\langle Tu,u \rangle$ on both sides of this equality, we get that $$2\langle Tu,u \rangle=-|u(0)|^2 + 2 i \int_0^1 \mbox{Im}(u' \overline{u})dx.$$ I think that the last one equality implies that the numerical range $W(T)$ of $T$ is given by $$W(T):=\{\langle Tu,u \rangle: u \in D(T), \|u \|=1 \}= \{z \in \mathbb{C} : \mbox{Re}(z) \leq 0 \}.$$ Is my argument right? Do you know another way to calculate $W(T)$ ? Thank you.","['operator-theory', 'spectral-theory', 'functional-analysis']"
3328422,Show that $\left\vert\frac{\pi}{4} - \left(1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9}\right)\right\vert < 0.1$,"Show that $$\left\vert\frac{\pi}{4} - \left(1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9}\right)\right\vert < 0.1 .$$ I know that $\arctan 1 = \frac{\pi}{4}$ and that the sequence being subtracted is a partial sum of its Taylor series. I believe you use the alternating series test to explain, but all I get from it is that the series will converge on $[-1,1]$ .","['approximation', 'calculus', 'pi', 'taylor-expansion', 'sequences-and-series']"
3328433,How to get the bar and star formula?,"I have this statement: Prove the bar and star formula for positive integers $\binom{n-1}{k-1}$ My attempt was: Imagine I have a certain equation: $x_1 + x_2 + ...+x_k=n$ Now, i have: $\underbrace{**********}_\text{n times}$ , $\underbrace{||||||||}_\text{(k-1) times}$ Since, the solutions must be positive, the bars cannot go before the first star, after the last star or two bars together. So, the first bar have $n-1$ positions, the second bar have $n-2$ position, the third bar have $n-3$ position, etc. Also there are $k-1$ bars, so the last bar have $n -(k-1)$ positions, that is $n-k+1$ . Thus, there are $(n-1)(n-2)\cdot ....\cdot (n-k+1) = \frac{(n-1)!}{(n-k)!}$ possible combinations. But from here, i can't get the formula to prove. I know that i need to divide by ( $k-1)!$ , but why? What elemets i am overcounting? A graphic explanation would be quite useful. Thanks in advance.",['combinatorics']
3328437,Prove the following stopping time Cannot be a predictable stopping time.,"Fix a filtered probability space $(\Omega,\mathcal{F},(\mathcal{F}_t)_{t\geq 0},\mathbb{P})$ and let $b$ be a measurable Bernoulli random varaible independent from the filtration $(\mathcal{F}_t)_{t\geq 0}$ . Define random time $$\tau:= \infty I_{\{b=0\}}$$ and the enlarged filtration $\mathcal{G}_t:=\mathcal{H}_{t+}$ where $\mathcal{H}_t:=\mathcal{F}_t\vee \sigma(\tau\wedge t)$ for all $t\geq 0$ . (I edited filtration $\mathcal{G}$ to be right-continuous) Question: Show that random time $\tau$ $\textbf{cannot}$ be a $(\mathcal{G}_t)_{t\geq 0}$ -predictable stopping time. Recall the definition of predictable stopping time: A stopping time $T$ is said to be predictable if there exists a sequence of stopping times $T_n$ such that $T_n$ is increasing, $T_n<T$ on $\{T>0\}$ for all n, and $\lim_{n\rightarrow \infty}=T$ a.s.. $\hspace{2cm}$ However, my following example shows that $\tau$ is a $(\mathcal{G}_t)_{t\geq 0}$ -predictable stopping time and I don't know where I did wrong. First, it is clear that $\tau$ is a $(\mathcal{G}_t)_{t\geq 0}$ -stopping time because $\{\tau\leq t\}\in \sigma(\tau\wedge t)\subset\mathcal{G}_t$ for all $t> 0$ . At $t=0$ , $\{\tau=0\}=\{b=1\}\in \mathcal{H}_s$ for any $s>0$ . Since $\mathcal{G}_0=\mathcal{H}_{0+}$ , hence, $\{\tau=0\}\in \mathcal{G}_0$ . Then, consider the random times $$\tau_n:=n I_{\{b=0\}}$$ for $n\geq 1$ . They are also $(\mathcal{G}_t)_{t\geq 0}$ -stopping times. Moreover, $\lim_{n\rightarrow\infty}\tau_n=\tau$ and $\tau_n=n<\tau=\infty$ when $\tau>0$ . Hence, $\tau$ is announced by $\tau_n$ .","['measure-theory', 'stopping-times', 'probability-theory']"
3328442,Are there any infinite dimensional division algebras?,"Appart from the finite dimensional division algebras like $\mathbb{R, C, H, O}$ Are there any infinite dimensional division algebras? (Especially any ""exceptional"" ones?) I was thinking maybe the ring over polynomials might be a division algebra if you include negative exponents and allow infinite series. But I'm not sure if every series gives a unique member of the algebra. You might have $(1+x)^{-1} = 1-x+x^2-...$ Well I guess the space of functions is a division algebra since you can add and divide them $f(x)g(x)$ and $f(x)/g(x)$ and has an identity element $1$ . What about the ring over polynomials with rational or irrational exponents? Or ones based on lattices?",['abstract-algebra']
3328473,How to solve for $~ 2x - \tan(x)=0~$,"I need to find the roots for this function $$~ 2x - \tan(x)=0~$$ in order to graph it. I have found the one root $~(x=0)~$ but there are two more $~(x= -1.164 ,~ x= 1.164)~$ . How can I find these answers without a graphing calculator ? Or is this not possible without a calculator? Thanks, any help is appreciated.","['calculus', 'trigonometry']"
