question_id,title,body,tags
1249196,What are the differences in mental skills required to master abstract algebra and analysis?? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I had took undergraduate-level abstract algebra and analysis courses before. And I find I can do proofs in analysis faster than in abstract algebra. However some other students is opposite to me. I find this phenomenon is interesting. To me when I trying to do proofs in analysis there is some kind of visualization coming first in my mind, and that aids me a lot to write down the proofs. In algebra I can barely have visualization in mind when doing proofs, so I easily get stuck in practicing this subject. So I wonder and would like to ask your opinions: What are the differences in mental skills required to master abstract algebra and analysis?","['abstract-algebra', 'analysis', 'education']"
1249294,"Extreme points of unit ball of Banach spaces $\ell_1$, $c_0$, $\ell_\infty$","Find extreme points of the unit balls of each Banach space, $l^1  $,    $c_0$,   $   
l^\infty$ Can you help me with this one? For the first space, $l^1$, I thought there was no extreme point, but apparently, this is not the answer :( And I don't know if the fact that $l^\infty$ contains $c_0$ matters in this problem. Thanks.","['banach-spaces', 'functional-analysis']"
1249307,If $f:S^1\to S^1$ doesn't have any fixed point then it is homotopic to the identity,How to show that every continuous function $f:S^1\to S^1$ without fixed points is homotopic to the identity? (without using homology nor the concept of degree).,"['homotopy-theory', 'algebraic-topology', 'general-topology']"
1249382,Union of affine varieities is a projective variety?,"Let $X \subset \mathbb{P}^n$ be a subset and let $U_i = \{ [z_0: \cdots :z_n] : z_i \neq 0 \}$ for $0 \leq i \leq n$ be the usual affine cover of projective space.  Suppose that $X \cap U_i$ is an affine variety when considered in $\mathbb{A}^n$ via the standard map $[z_o: \cdots :z_n] \mapsto (z_o/z_i,...,z_n/z_i)$ for all $0 \leq i \leq n$.  Is it true that $X$ itself is then necessarily a projective variety?",['algebraic-geometry']
1249383,Simplifying the expression $2\cos^{2}6x-1$,"I am trying to simplify the expression $2\cos^{2}6x-1$. The book got the answer of $\cos 12 x$ by doing $2\cos^{2}6x-1 = \cos2\left(6x\right) = \cos12x$ It said the double angle is $12x$. I don't know how $2\cos^{2}6x-1$ got to $\cos2\left(6x\right)$, can anyone explain how this works? It said it used cosine of double-angle formula, but I am not sure how it got the answer.",['trigonometry']
1249392,Intuition behind the Riesz-Thorin interpolation theorem,"Quoting the definition on Wikipedia , Let $(\Omega_1, \Sigma_1, \mu_1)$ and $(\Omega_2, \Sigma_2, \mu_2)$ be $\sigma$-finite measure spaces. Suppose $1 \leq p_0 \leq p_1 \leq \infty$, $1 \leq q_0 \leq q_1 \leq \infty$, and let $T : L^{p_0}(\mu_1) + L^{p_1}(\mu_2) \to L^{q_0}(\mu_2) + L^{q_1}(\mu_2)$ be a linear operator that maps $L^{p_0}(\mu_1)$ (resp. $L^{p_1}(\mu_1)$) boundedly into $L^{q_0}(\mu_2)$ (resp. $L^{q_1}(\mu_2)$). For $0 < \theta < 1$, let $p_\theta$, $q_\theta$ be defined as above. Then $T$ maps $L^{p_\theta}(\mu_1)$ boundedly into $L^{q_\theta}(\mu_2)$ and satisifies the operator norm estimate $$ \|T\|_{L^{p_\theta} \to L^{q_\theta}} \leq \|T\|^{1-\theta}_{L^{p_0} \to L^{q_0}} \|T\|^\theta_{L^{p_1} \to L^{q_1}}.$$ I am having some difficulty visualizing the statement of this theorem, and therefore do not understand why this is an ""interpolation"" theorem. What is the intuition behind this theorem? What is being interpolated here?","['lebesgue-integral', 'lp-spaces', 'real-analysis', 'functional-analysis']"
1249393,$n$ such that $|\sin in | > 10 000$,"An exercise in my book asks me to find $n\in \mathbb N$ such that $|\sin in |> 10 000$. Could someone please check my solution? I wrote $$ |\sin in |^2 = \cosh^2 n + \sinh^2 n = 1 + 2 \sinh^2 n$$ hence $|\sin in |> 10 000$ if and only if $$ \sinh n > {\sqrt{9 999}\over \sqrt{2}}$$ Is it correct like this or is it possible to find $n$ $more explicitly
  (without using a calculator)?","['solution-verification', 'complex-analysis']"
1249394,Is the Laplace transform a vector space isomorphism? And what space is it isomorphic to?,"The laplace transform is a linear transformation, $\mathcal{L}: \mathcal{M} \rightarrow?$, where $\mathcal{M}$ is the set of exponentially bounded functions on $\mathbb{R},$since $\mathcal{L}(af(x)+bg(x))=a \mathcal{L}(f(x))+b\mathcal{g(x)}$   for $a,b\in \mathbb{R}$ and $f,g \in \mathcal{M}$. 
It seems to be injective since $\operatorname{Ker}(\mathcal{L})=0$ unless I've missed something. Therefore by the rank-nullity theorem $\mathcal{L}$ must surjective and so it is an isomorphism. So my questions are 1) Is this proof outline correct? and 2) what set is the laplace transform mapping into?","['vector-spaces', 'linear-algebra', 'laplace-transform', 'linear-transformations']"
1249408,Find all integers n such that the quadratic $5x^2 + nx – 13$ can be expressed as the product of two linear factors with integer coefficients.,"I am unsure of how to approach this problem. I have thought about using the Rational root theorem, but I am unsure if this answers the question being asked. Using the theorem, I get $\frac{p}{q} = \pm 1, \pm 13, \pm \frac{1}{5}$, and $\pm \frac{13}{5}$ as possible roots. Then I use synthetic division and Horner's method to get a remainder of $-(n+8)$. For this to be a solution, $-(n+8)=0$, so $n = -8$. Then I could do this for $+1, +13, -13,$ etc. Is this the correct approach to answering the original question? Original question: Find all integers $n$ such that the quadratic $5x^2 + nx – 13$ can be expressed as the product of two linear factors with integer coefficients. Why would I need to have a rational root to answer the problem? Couldn't I have complex solutions where I can express $5x^2 + nx - 13$ (where n is an integer) as a product of two linear factors with integer coefficients? I greatly appreciate any insight you could provide on this. It's been about 2 years since I've done any mathematics (a brief foray into Neuroscience turned into a longer expedition than intended) and I am longing to return to the beautiful realm of mathematics. Thanks for your time in reading through this jumbled mathematical thought!","['factoring', 'quadratics', 'integers', 'algebra-precalculus']"
1249412,Why isn't $d\mathbf{A}$ normalized in Stokes' theorem?,"For a nice curve $C$ which is a boundary of a smooth surface $D$, Stokes' theorem says that $$\begin{align*}
\oint_C \mathbf{F}\cdot d \mathbf{s} = \iint_D (\nabla \times \mathbf{F} )\cdot d\mathbf{A}
\end{align*}$$ However, I don't think I understand exactly what is going on with the $d\mathbf{A}$ term. I would think that it is the vector of magnitude differential area $dA$ and direction $\hat{n}$, where $\hat{n}$ is the unit vector in the direction perpendicular to the orientation of $dA$. However, by reading practice problems online, I see that this is not the case. What exactly is the definition of this $d\mathbf{A}$? In addition, many sources online show that after evaluating the dot product $(\nabla \times \mathbf{F} )\cdot \mathbf{A}$ (no $dA$ term), the surface integral is magically done only in the $xy$ plane, rather than any other randomly defined plane. Is this legal?",['multivariable-calculus']
1249431,"Is the complex Banach space $C([0,1])$ dual to any Banach Space?","I've been able to show that the extreme points of $C([0,1])$ are the continuous functions that take values on the unit circle. However, I'm not sure how to reason from here as to whether or not it is the dual to any Banach space. Any hints? The standard approach I've been using to show things are not dual to any space has been to use Krein-Milman and Alaoglu to argue by contradiction, but I don't know what the closed convex hull of unitary complex functions is.","['banach-spaces', 'functional-analysis']"
1249459,Range of $n(A \Delta B)$ in sets A and B,"I was trying to solve this question- ""If 2 sets A and B are such that n(A) = 15 and n(B) = 25, find the no. of elements in the range of $n(A \Delta B)$.Now, this is what I did- For $n(A\Delta B)$ to be maximum, $n(A \cap B)$ should be minimum, i.e.$0$. Thus, $n(A\Delta B)= n(A\cup B) - n(A\cap B)$ = $n(A) + n(B) - 0$ = $25+15=40$ For the minimum value of $n(A \Delta B)$, $A \subset B$, i.e. $n(A \cap B) = n(A) =15$. Also, for minimum value of the symmetric difference, $A\subset B$ means that $n(A \cup B) = n(B) = 25$. Thus, minimum value is $n(A\Delta B)= n(A\cup B) - n(A\cap B)$ = $25-15=10$ Thus, the range should be max. value - min. value = $40 -10 =30$.
But the answer is given as 16. How? Thanks in advance!",['elementary-set-theory']
1249474,A problem about $e^{2\pi i \alpha_1}+e^{2\pi i \alpha_2}+\cdots+e^{2\pi i \alpha_N}=0$,"Let $\alpha_i\in [0,1),\; i\in \{1,\cdots,N\}$ for some positive integer $N$, such that
$$e^{2\pi i \alpha_1}+e^{2\pi i \alpha_2}+\cdots+e^{2\pi i \alpha_N}=0$$
and if for any non-empty proper subset $E\subset \{1,\cdots,N\}$ satisfy $\sum_{k\in E}e^{2\pi i\alpha_{k}}\neq 0$, then $N$ be a prime number, and $\{\alpha_i: i\in \{1,\cdots,N\}\}=\rho+\{\frac{i}{N}:i\in\{0,\cdots,N-1\}\}$  for some $\rho \in [0,1)$.","['prime-numbers', 'algebraic-number-theory', 'complex-analysis', 'elementary-number-theory']"
1249478,Evaluate $\text{k}$ from the given equation,"If $$ \int_{0}^{\infty} \left(\dfrac{\ln x}{1-x}\right)^{2} \mathrm{d}x + \text{k} \times \int_{0}^{1} \dfrac{\ln (1-x)}{x} \mathrm{d}x =0$$ then find the value of $\text{k}$ My Approach : Let $\text{I}= \displaystyle \int_{0}^{\infty} \left(\dfrac{\ln x}{1-x}\right)^{2} \mathrm{d}x + \displaystyle \text{k} \times \int_{0}^{1} \dfrac{\ln (1-x)}{x}\mathrm{d}x$ $=\displaystyle \int_{0}^{1} \left(\dfrac{\ln x}{1-x}\right)^{2} \mathrm{d}x + \int_{1}^{\infty} \left(\dfrac{\ln x}{1-x}\right)^{2} \mathrm{d}x + \displaystyle \text{k} \times \int_{0}^{1} \dfrac{\ln (1-x)}{x}\mathrm{d}x$ Now, for the second integral, let $x=\dfrac{1}{t}$, $\implies \text{I}= \displaystyle \int_{0}^{1} \left(\dfrac{\ln x}{1-x}\right)^{2} \mathrm{d}x + \displaystyle \int_{0}^{1} \left(\dfrac{\ln t}{1-t}\right)^{2} \mathrm{d}t + \displaystyle \text{k} \times \int_{0}^{1} \dfrac{\ln (1-x)}{x}\mathrm{d}x$ $= 2\displaystyle \int_{0}^{1} \left(\dfrac{\ln x}{1-x}\right)^{2} \mathrm{d}x + \displaystyle \text{k} \times \int_{0}^{1} \dfrac{\ln (1-x)}{x}\mathrm{d}x$ $=2\displaystyle \int_{0}^{1} \left(\dfrac{\ln x}{1-x}\right)^{2} \mathrm{d}x + \displaystyle \text{k} \times \int_{0}^{1} \dfrac{\ln x}{1-x}\mathrm{d}x$ However, I can't seem to think of a way to simplify it further and find the value of $\text{k}$. Any help will be appreciated. Thanks in advance.","['calculus', 'real-analysis', 'definite-integrals', 'algebra-precalculus', 'integration']"
1249488,An Application of Stokes's Theorem,"Let $D^2=\{(x,y)\in \mathbf R^2: x^2+y^2\leq 1\}$ be the unit disc in $\mathbf R^2$, and $D^3=\{(x,y,z)\in \mathbf R^3: x^2+y^2+y^2\leq 1\}$ be the unit disc in $\mathbf R^3$. Let $i_{\pm}:D^2\to D^3$ be two maps defined as
  $$
i_{\pm}(x, y)=\left(x, y, \pm\sqrt{(1-x^2-y^2)}\right)
$$
  Let $\omega$ be a closed $2$-form in a smooth manifold $M$, and $F:D^3\to M$ be a smooth map.
  Then I need to show that
  $$
\int_{D^2}(F\circ i_+)^*\omega = \int_{D^2} (F\circ i_-)^*\omega
$$
  where $D^2$ has the standard orientation governed by the form $dx\wedge dy$. Attempt: Since $\omega$ is a closed form, it seems that Stokes's Theorem might be useful.
Define $H_+=\{\left(x, y, \sqrt{1-x^2-y^2}\right): (x, y)\in D^2\}$ and $H_-=\{\left(x, y, -\sqrt{1-x^2-y^2}\right): (x,y)\in D^2\}$. Now $H_+\cup D^2$ is the boundary of the ""upper solid half unit disc"" $D^3_+$ in $\mathbf R^3$ and $H_-\cup D^2$ is the boundary of the ""lower solid half unit disc"" $D^3_-$ in $\mathbf R^3$. By Stokes we have
$$
\int_{H_+\cup D^2}i_+^*(F^* \omega)= \int_{D^3_+}d(F^* \omega))=\int_{D^3_+} F^* d\omega = 0
$$
Therefore
$$
\int_{D^2}i_+^*(F^*\omega) = -\int_{H_+} i_+^*(F^*\omega)
$$
Similarly
$$
\int_{D^2}i_-^*(F^*\omega) = -\int_{H_-} i_-^*(F^*\omega)
$$
How do I proceed from here? Thanks.","['smooth-manifolds', 'differential-forms', 'integration', 'differential-geometry', 'multivariable-calculus']"
1249491,A math contest question related to Ramsey numbers,"In a group of 17 nations, any two nations are either mutual friends,
mutual enemies, or neutral to each other. Show that there is a
subgroup of 3 or more nations such that any two nations in the
subgroup share the same kind of relationship. I am kind of guessing that you will have to use pigeonhole principle but not quite know how to apply?  Help will be appreciated. The problem comes from Fermat II 2014 , a math contest of the University of Tennessee for high school students.","['contest-math', 'graph-theory', 'ramsey-theory', 'combinatorics']"
1249516,Calculate a determinant.,"Let $a_{1},  \cdots, a_{n}$ and $b$ be real numbers. I like to know the determinant of the matrix
$$\det\begin{pmatrix}
  a_{1}+b & b & \cdots & b \\
 b & a_{2}+b & \cdots & b \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  b & b & \cdots & a_{n}+b
 \end{pmatrix}=?$$
I guess the answer is $$a_{1} \cdots a_{n}+ \sum_{i=1}^{n} a_{1} \cdots a_{i-1} b a_{i+1}\cdots a_{n} $$ after some direct calculations  for $n=2,3$. The question is how to calculate it for general $n$. Thanks!","['determinant', 'linear-algebra']"
1249520,Expansion of $(a+b+c+d)^n$,How to expand when $(a+b+c+d)^n$? Can I allow it to be $[(a+b)+(c+d)]^n$ and then use binomial theorem to expand it?,['algebra-precalculus']
1249546,"Classify $ \mathbb{Z}_9\times\mathbb{Z}_8\times\mathbb{Z}_8/\langle(3,2,4)\rangle$.","Since the order of $(3,2,4)$ is $12,$ the quotient group is of order $48.$
Now I have a problem. Consider $(1,0,1)+\langle(3,2,4)\rangle.$ The element is of order $ 72,$ I think. But, it's impossible you know, so I can't solve this problem.","['abelian-groups', 'group-theory']"
1249552,What is the geometrical difference between continuity and uniform continuity?,Can we explain  between ordinary continuity and Uniform Continuity difference geometrically ? What is the best way to describe the difference between these two concepts? Where the motivation of Uniform Continuity came from? Thank You.,"['continuity', 'uniform-continuity', 'real-analysis']"
1249617,Prove that matrix is symmetric and positive definite given the fact that $A+iB$ is.,"I have some questions regarding the following problem Let $ A + iB $ - hermitian and positive definite, where $A, B \in \mathbb R^{n\ \times\ n} $ show that the real matrix $$C =\begin{pmatrix} A & -B \\ B & A \end{pmatrix} $$ is symmetric and positive definite. How can the following system of linear equations be solved using Cholesky decomposition of C: $ (A+iB)(x+iy)=B+iC$ I've tried to transform C and get to $A + iB$ , I've tried to compute the determinants to get to $A + iB$ but I had no result. Moreover, I have no idea how to approach the second part of the problem. Thank you","['matrix-equations', 'linear-algebra', 'matrix-decomposition', 'matrices']"
1249648,The function $\phi(p)=\|f\|_{L^p}^p$ is convex,"Fix an arbitrary function $f\in L^p([0,1])$ and define
  $$\phi(p)=\|f\|_{L^p}^p$$ for $p\in [1,\infty)$. Prove $\phi$ is
  convex. Comments: This is a standard property of $L^p$ spaces, but no good reference is available online. This question aims to fix that.","['lp-spaces', 'functional-analysis']"
1249655,Write $\mathbb{P}^3_{\mathbb{C}}$ as a union of disjoint lines,"Is there a set $\Gamma=\{L \subseteq \mathbb{P}^3_{\mathbb{C}}: L \textrm{ is a projective line}\}$ such that every point $p \in \mathbb{P}^3_{\mathbb{C}}$ lies on exactly one line $L_p \in \Gamma$? I know that this is possible for the real numbers, so I wonder wonder if it is correct for the complex numbers too.","['projective-geometry', 'projective-space', 'algebraic-geometry', 'linear-algebra']"
1249670,Can we solve recurrence relations indexed by R?,"Recurrence relations are equations with functions from $\mathbb N\rightarrow \mathbb N$. For example given $a:\mathbb N\rightarrow \mathbb N$ (write $a(n)$ as $a_n$) solving the recurrence relation $a_n = A\cdot a_{n-1}+B\cdot a_{n-2}$ means finding the function $a$. There are methods for doing this. Question: Are there methods for solving similar equations when the function is $a:\mathbb R\rightarrow \mathbb N$? For example, $a(x) = A\cdot a(x-\alpha) + B\cdot a(x-\beta)$ for some fixed $\alpha,\beta\in\mathbb R$?","['recurrence-relations', 'sequences-and-series', 'functional-equations', 'functions']"
1249674,"Does ""equalisers always closed"" imply $T_2$?","Is there a non-$T_2$ space $(X,\tau)$ with the following property? For all topological spaces $A$ and continous maps $f,g:A\to X$ the set $\{a\in A: f(a) = g(a)\} \subseteq A$ is closed.",['general-topology']
1249706,"""Length"" of rationals in an interval","For $x \in \mathbb{R}$, define $r(x)$ as follows:
$$
r(x)=
\begin{cases}
1 &\text{if $x$ is rational},\\
0 &\text{if $x$ is irrational}.
\end{cases}
$$ Q. What is $\int_0^1 r(x) dx$ ? I know the rationals are dense in an interval, but countable, and so ""sparse."" My motivation is a desire to average over the rationals, and in some sense
this integral would be the denominator.
If the integral is zero, then I'll have to think of another route. Thanks!","['rational-numbers', 'irrational-numbers', 'real-analysis', 'definite-integrals']"
1249707,Connection between algebraic multiplicity and dimension of generalized eigenspace,"Assume $V$ to be a finite dimensional vector space. Define the algebraic multiplicity $am(\lambda)$ of an eigenvalue $\lambda$ of a linear operator $T:V\to V$ as the maximum index of the factor $(t-\lambda)$ appearing in the characteristic polynomial of $T$ . Also define $G_\lambda=\{v\in V:(T-\lambda I)^kv=0\}$ . I want to show that $\dim(G_\lambda)=am(\lambda)$ without using Jordan Form. Sheldon Axler in ""Linear Algebra Done Right"" specifically defined the ""multiplicity"" of $\lambda$ as $\dim(G_\lambda)$ , hence I could not get any help from it. I am not very conversant with the properties of the Jordan form, hence I would like a more elementary proof. Please note that I cannot use the decomposition of $V$ into a direct sum of generalized eigenspaces because I will need to prove that indeed, $am(\lambda)=\dim(G_\lambda)$ to prove this. I started by assuming that $f(t)=(t-\lambda)^kp(t)$ where $f$ is the characteristic polynomial of $T$ , $p$ is any other polynomial not containing the factor $(t-\lambda)$ . So I will have to show that $\dim(G_\lambda)=k$ . By Cayley Hamilton Theorem, $f(T)=0\implies (T-\lambda I)^kp(T)=0$ hence $p(T)v\in G_\lambda \forall v\in V$ . Now consider the collection $\{p(T)v,(T-\lambda I)p(T)v,...,(T-\lambda I)^{k-1}p(T)v\}$ for a nonzero $v\in V$ which I know is linearly independent (based on the previous exercise) and hence $\dim(G_\lambda)\geq k$ . How will the other direction follow?","['eigenvalues-eigenvectors', 'vector-spaces', 'linear-algebra']"
1249726,Can the probability of an event be an irrational number?,"I am wondering whether it is possible to construct an experiment, where the probability of occurrence of an event comes out to be an irrational number.",['probability']
1249730,Prove that $x$ has order $5$.,let $ x \in G$ such that $(a^{-1})*(x^2)*(a) = x^3$ for some self inverse $a.$ Prove that $x$ has order $5.$ I don't know how to start this proof. Seems really difficult.,"['abstract-algebra', 'group-theory']"
1249742,"Prove that if $R$ is an integral domain and has ACCP, then $R[X]$ has ACCP","Let $R$ be a commutative ring. (i) Prove that $R$ has ACCP if and only if every non-empty collection of principal ideals of $R$ has a maximal element. (ii) Prove further that if $R$ is an integral domain and has ACCP, then $R[X]$ has ACCP. Attempt. (i) ($\Rightarrow$) Suppose that there exists a non-empty collection of ascending chain of principal ideals of $R$ that does not have a maximal element. Then, for every ideal $I_i$ in this collection we can always take an ideal $I_{i+1}$ such that $I_i \subseteq I_{i+1}$. If not, then $I_i$ is the maximal element in this collection which is not possible. Hence, $R$ does not have ACCP. Contradiction. ($\Leftarrow$) Suppose $R$ does not have ACCP. Then we can find a chain of principal ideals that do not terminate. This chain does not have a maximal element. Contradiction. I don't really know how to prove it directly other than by contradiction. Can someone show me how? (ii) I can't see how can I apply the first part.","['abstract-algebra', 'integral-domain', 'ring-theory']"
1249778,"Extreme points of the unit balls of $l^\infty, C([0,1])$","Determine the extreme points of the unit balls of $l^\infty$, and $C([0,1])$ for real-valued functions, with the uniform norm. Is $C([0,1])$ the dual of a Banach space? I've found the extreme points of $C([0,1])$, but I'm not sure if it is the dual or not. And can anyone help me with finding the extreme points of the unit balls of $l^\infty$? Thank you.","['banach-spaces', 'functional-analysis']"
1249782,solutions such that a combination number is odd,"Let $m$ be a positive integer. Given $m$, I want to find the largest $n$,  $1\leq n\leq m$, such that $$m+n\choose n
$$ is odd. Is there any standard theorems or results? Any references? Thanks!","['combinations', 'number-theory', 'elementary-number-theory', 'combinatorics']"
1249801,Are these two limits equal to each other?,"I'm curious about whether these two limits are the same (well I know they are equal since Wolfram Alpha confirms it, but I want to know whether the reasoning is justified): $$ \lim_{x\rightarrow \infty} \frac{\ln{x}}{x} \;\; \text{ is equivalent to  } \;\; \lim_{x\rightarrow 0}\;x\ln{x}   $$ I've already found that:
$$ \lim_{x\rightarrow \infty}\frac{\ln{x}}{x} =0  $$
and then tried to use this to find the second limit:
$$ \lim_{x\rightarrow \infty}\frac{\ln{x}}{x} = \lim_{x\rightarrow \infty}\; \frac{1}{x}\times \ln{ \left( \frac{1}{x} \right)^{-1} }= -\lim_{x\rightarrow \infty}\; \frac{1}{x}\times \ln{ \left( \frac{1}{x} \right) } $$
since $1/x$ tends to $0$ as $x$ tends to $\infty$ then I let: $y=1/x$ and thus:
$$= -\lim_{1/y\rightarrow\infty} \; y\ln{y} $$
and given that $1/y \rightarrow \infty$ would imply that $y\rightarrow 0$:
$$=-\lim_{y\rightarrow 0}y\ln{y}$$
So the limit would be:
$$-\lim_{y\rightarrow 0}y\ln{y}=\lim_{x\rightarrow \infty}\frac{\ln{x}}{x} =0$$ I'm just not quite sure whether this is strictly correct, since it seems to me that $1/x$ would approach zero at a different 'rate' than $x$ would and thus the limits wouldn't necessarily have to be the same.","['limits-without-lhopital', 'calculus', 'limits']"
1249817,Probability - Poisson arrival of rain,"I'm trying to solve this Poisson problem. A rain shower lasts 10 minutes and in that time deposits $10^6$ raindrops over 100 $m^2$. a) What is the probability of at least one drop landing in 1 $cm^2$ b)On average, how much time elapses before a raindrop hits the 1 $cm^2$ area. I understand the first part, the intensity is 1 drop/$cm^2$ so the probability is of at least one is $P(x\ge1)=1-\frac{(1^0)e^{-1}}{0!}=0.632$ But I'm not sure about the second part. I don't see how the number of drops, the time interval, and the two areas relate to each other to appear in a Poisson proccess. Particularly since I'm apparently not trying to find the probability of no drops after some amount of time.","['poisson-distribution', 'probability', 'statistics']"
1249836,"Is the set of points or the set of lines on a plane ""larger""?","Is the set of points or the set of lines on a plane ""larger"",or there is a 1-1 correspondence between lines and points?",['elementary-set-theory']
1249874,Does Tom catch Jerry?,"Tom has Jerry backed against a wall. Tom is distance 1 away (perpendicularly). At time t=0, Jerry runs along the wall. Tom runs directly towards Jerry. Tom always runs directly towards Jerry. Tom and Jerry both run at the same speed. Does Tom catch Jerry? How close does he get (in the limit t tends to infinity)? What shaped curve does Tom run? Edit: I made this problem up last week. Friends enjoyed it, I thought this site might too. Hint: Take the x-axis as the wall, and assume Jerry runs to the right, without loss of generality at speed 1. Let $x(t)$ and $y(t)$ be Tom's position at time $t$. So $x(0) = 0$, and $y(0) = 1$. Consider Tom's direction of travel at time $t$ towards Jerry at $(t, 0)$. Write $\theta$ for the (positive) angle below the horizon. Then $$ \tan \theta =  \frac{dy}{dx} =  \frac {y}{t-x} $$ Tom runs at unit speed, so also $$ \frac{dy}{dt} = - \sin \theta $$ $$ \frac{dx}{dt} = \cos \theta $$ That's as far as I got, I don't know how to solve such a complex differential equation.","['differential-games', 'calculus', 'ordinary-differential-equations']"
1249883,How is the notion of adjunction of two functors usefull?,Is there a secret or an intuitive idea behind the fact of creating the concept of adjunction of two functors ( Functor - Adjoint Functor ) ? How is this notion of adjunction of two functors usefull ? Thank you in advance for your help.,"['algebraic-geometry', 'schemes', 'adjoint-functors', 'category-theory']"
1249899,What is the largest function whose integral still converges?,"Let C be the set of all functions $f(x)$ whose integral converges, i.e. for some constant $x_0$: $$\int_{x_0}^\infty f(x) dx < \infty$$ While playing with integrals in Wolfram Alpha , I noticed the following pattern: $$\frac{1}{x} \notin C \hspace{2cm} \frac{1}{x^2} \in C$$ $$\frac{1}{x \cdot \ln x} \notin C \hspace{2cm} \frac{1}{x \cdot \ln^2 x} \in C$$ $$\frac{1}{x \cdot \ln x \cdot \ln \ln x} \notin C \hspace{2cm} \frac{1}{x \cdot \ln x \cdot \ln^2 \ln x} \in C$$ Note that the functions at the left become asymptotically smaller, the functions on the right become asymptotically larger, and the gap between them becomes ""narrower"". This raises the following question: what is the ""largest function"" in $C$ and what is the ""smallest function"" not in $C$? Formally: Is there a function $f_{max}\in C$ such that, for every other function $g\in C$: $$\lim_{x\to\infty}{g(x) \over f_{max}(x)}=0$$ Is there a function $f_{min}\notin C$ such that, for every other function $g\notin C$: $$\lim_{x\to\infty}{f_{min}(x) \over g(x)}=0$$","['limits', 'real-analysis', 'improper-integrals', 'functional-analysis', 'integration']"
1249906,Asymptotic expression of $\int_{- D}^{D} \frac{\text{tanh}(\xi)}{\xi -\omega}\mathrm{d}\xi$,"How to derive the following asymptotic expression ($|\omega| \ll D $)? $$P.V.\int_{- D}^{D} d\xi \frac{\tanh(\beta \xi)}{\xi -\omega} \approx 2  \ln\left(\frac{D}{\sqrt{\omega^2+T^2}}\right),\ \ \  \beta =1/T,\ \  \omega, T \rightarrow 0.$$ Two limiting cases: 1) $\omega=0, \lim_{T\rightarrow 0}\int_{- D}^{D} d\xi \frac{\text{tanh}(\beta \xi)}{\xi} \approx 2  \ln\left(\frac{D}{T}\right) + C \approx 2  \ln\left(\frac{D}{T}\right)$; 2) $T=0, \lim_{\omega \rightarrow 0} \int_{- D}^{D} d\xi \frac{\theta(\xi)-\theta( -\xi)}{\xi -\omega} \approx 2  \ln\left(\frac{D}{\omega}\right).$ Some write $2  \ln\left(\frac{D}{\text{max}(\omega, T)}\right)$ instead of $ 2  \ln\left(\frac{D}{\sqrt{\omega^2+T^2}}\right).$ Can anyone elaborate Jack's answer? Thank you. Reference. Actually, this is an important expression from physics, which is directly related to the Kondo problem , the divergence at the third order of perturbation theory.","['asymptotics', 'cauchy-principal-value', 'calculus', 'integration']"
1249943,Proving that if a set is both open and closed then it is equal to the real numbers,"Prove that if $A$ is both open and closed then $A = \mathbb{R}$ also as one suggested let $A \neq \emptyset$ You may use what ever definition of open and closed you would like, just avoid going into metric spaces, haven't covered that topic yet. My question is well essentially how to prove this statement but considering I like to do things myself, I was wondering if anyone had any particular suggestions to help me solve this. attempted proof: Let $a\in A$ then since $A$ is open there exists an open interval $N(a,\epsilon)$ such that $$a\in N(a,\epsilon)\subset A$$ Then $a$ must be an interior point of $A$, but since $A$ is also closed then $a$ must also be an accumulation or limit point of $A$ as well. I am going to stop here because I am not sure if this is the right approach here, any suggestions would be greatly appreciated.",['general-topology']
1249948,How prove $\root 4\of{\frac{1}{2}\sin x\cos z}+\root 4\of{\frac{1}{2}\cos x\sin z}=\root{12}\of{\sin 2y} $? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $\sin(x+y) = 2\sin\left(\dfrac{x-y}{2}\right)$ and $\sin(y+z) = 2\sin\left(\dfrac{y-z}{2}\right)$. How prove  $\root 4\of{\frac{1}{2}\sin x\cos z}+\root 4\of{\frac{1}{2}\cos x\sin z}=\root{12}\of{\sin 2y} $  ?",['trigonometry']
1249953,How many topologies exist on a finite set?,In my topology class we are asked to list all topologies on a $3$ element set. I have found $29$ and this should be the correct result. Now I wonder whether there is some formula that determines this number exactely or at least whether there are better bounds than $2$ and $2^{2^n}$ ;),"['combinatorics', 'general-topology']"
1249971,Can trigonometric functions for double precision be implemented in terms of those for single precision?,"In some program environments like GLSL there is support for single and double precision numbers for arithmetic and square roots computation, but only single precision trigonometric functions are available. To support the double precision versions one would have to implement them manually. The more precise versions could just be implemented from scratch e.g. via Taylor or Padé approximations. But is there a way of making use of already present single precision implementation to improve performance?","['approximation', 'floating-point', 'numerical-methods', 'trigonometry']"
1249979,The graph has an Euler tour iff in-degree($v$)=out-degree($v$),"I am looking at the proof that $G$ has an Euler tour iff in-degree($v$)=out-degree($v$), that I found at this site: www.cs.duke.edu/courses/fall09/cps230/hws/hw3/headsol.pdf (Problem 2) A simple cycle is a path in a graph that starts and ends at the same vertex without passing through the same vertex more than once. A complex cycle is a cycle that passes through the same vertex more than once. We can easily decompose a complex cycle to a set of simple cycles by breaking up the cycle at those points where the cycle passes through the same vertex more than once. As the first part of our proof, we will prove that if $G$ has an Euler tour, in-degree($v$)=out-degree($v$) for each vertex $v \in V$. We have already established that a complex cycle can be decomposed to a collection of simple cycles. However vertices on a simple cycle have in-degree($v$)=out-degree($v$)=1. Since each vertex in a complex cycle, and therefore in an Euler tour, is part of one or more simple cycles it will have in-degree($v$)=out-degree($v$). Could you give me an example of a complex cycle that is decomposed to a set of simple cycles, where we can see that in-degree($v$)=out-degree($v$)? The second part of our proof requires us to prove that if in-degree($v$)=out-degree($v$) for each vertex $v \in V$, $G$ has an Euler-tour. Let $C$ be the complex cycle involving the most edges in $G$. In order for $G$ not to be an Euler tour, there must be some vertices that $C$ passes through ( since the graph is connected ) but does not exhaust all edges. We have already established that the vertices of a complex cycle have the property that in-degree($v$)=out-degree($v$). Therefore $G'=G-C$ will also have that property. If a connected component in a graph has in-degree($v$)=out-degree($v$) then it contains at least one cycle $C'$. However this contradicts our initial hypothesis that $C$ is the cycle involving the most edges in $G$ since we would construct a larger cycle by starting at some common vertex of $C$ and $C'$, traversing all of $C$s edges and then $C'$s edges. Therefore $C$ is an Euler tour. First of all, it says that ""In order for $G$ not to be an Euler tour, there must be some vertices that $C$ passes through ( since the graph is connected ) but does not exhaust all edges. "" I haven't understood why we have to show that $G$ does not exhaust all edges. In order for $G$ not to be an Euler tour, couldn't it also hold that  $G$ traverses an edge more than once? Then it says that ""We have already established that the vertices of a complex cycle have the property that in-degree($v$)=out-degree($v$). Therefore $G'=G-C$ will also have that property."" Why will $G'=G-C$ be a complex cycle, although $G$ isn't necessarily? Also, could you explain me why it holds that: "" If a connected component in a graph has in-degree($v$)=out-degree($v$) then it contains at least one cycle $C'$."" Finally, could you explain me the contradiction? EDIT : I also want to describe an algorithm that runs in time $O(E)$ and finds an Euler tour of $G$, if it exists. (Hint: Merge edge-disjoint cycles.) 
If we apply DFS, we will get a set of cycles formed by disjoint sets of edges, right? But how can we know if it holds that in-degree(v)=out-degree(v), for all vertices in $V$? Do we have to do something like that? algorithm","['computer-science', 'graph-theory', 'discrete-mathematics']"
1249989,Example of a ring without unity that has a subring with unity? [duplicate],"This question already has answers here : If a subring of a ring R has identity, does R also have the identity? (4 answers) Closed 8 years ago . I can't think of a ring without unity that has a subring with unity. There must be some element in the parent ring that doesn't work with the subring's identity, but I'm struggling to see how that would be possible. Any suggestions?",['abstract-algebra']
1250070,What does the 2nd degree derivative of a cubic Bezier curve actually represent?,"I have a $3D$ Bezier curve. Each co-ordinate along its path is defined by the equation:
$$
f(t) = t^3 \bigl(a_2+3(c_1-c_2)-a_1\bigr) + 3t^2 (a_1-2c_1+c_2) + 3t(c_1-a_1) + a_1
$$
where $a_1, a_2$ are the anchor points and $c_1, c_2$ the control points (a.k.a. tangents at $a_1,a_2$). I want a $3D$ car model to move along this path. In order to orient the car, I use the 1st degree derivative which happens to be the curve's tangent (a.k.a. the function for the curve's direction ) :
$$
f'(t) = 3t^2 \bigl(a_2+3(c_1-c_2)-a_1\bigr) + 6t(a_1-2c_1+c_2) + 3(c_1-a_1)
$$
I orient the car using this function's output as direction - considering (0,1,0) as the ""up"" vector. It works a treat. Now, I wanted to make the car's front wheels turn left & right according to the car turning left & right. I thought I should use the 2nd degree derivative and use its output to orient the wheels. $$
f''(t) = 6t \bigl(a_2+3(c_1-c_2)-a_1\bigr) + 6(a_1-2c_1+c_2)
$$ It turns out to be a nightmare, thus my concept must be wrong. My biggest query is that $f''(t)$ is non-zero even when the Bezier is degenerated to a straight line (all 4 points belonging to a straight line)! Since, in the case of a straight line, the direction $f'(t)$ is constant, shouldn't its derivative be always zero ? For example, for $a_1,a_2,c_1,c_2$ respectively: Vector3D(-4.01,0.00,-1.90) Vector3D(4.01,0.00,-1.90)
Vector3D(-2.01,0.00,-1.90) Vector3D(2.01,0.00,-1.90) I get a constant $f'(t)$ and a variable $f''(t)$ !! f'(0.08)=Vector3D(-1.00,0.00,0.00) f''(0.08)=Vector3D(10.14,0.00,0.00)
f'(0.11)=Vector3D(-1.00,0.00,0.00) f''(0.11)=Vector3D(9.42,0.00,0.00)
f'(0.15)=Vector3D(-1.00,0.00,0.00) f''(0.15)=Vector3D(8.44,0.00,0.00)
f'(0.18)=Vector3D(-1.00,0.00,0.00) f''(0.18)=Vector3D(7.69,0.00,0.00)
f'(0.21)=Vector3D(-1.00,0.00,0.00) f''(0.21)=Vector3D(6.87,0.00,0.00)
f'(0.24)=Vector3D(-1.00,0.00,0.00) f''(0.24)=Vector3D(6.16,0.00,0.00)
f'(0.27)=Vector3D(-1.00,0.00,0.00) f''(0.27)=Vector3D(5.47,0.00,0.00)
f'(0.30)=Vector3D(-1.00,0.00,0.00) f''(0.30)=Vector3D(4.70,0.00,0.00)
f'(0.33)=Vector3D(-1.00,0.00,0.00) f''(0.33)=Vector3D(4.03,0.00,0.00)
f'(0.36)=Vector3D(-1.00,0.00,0.00) f''(0.36)=Vector3D(3.37,0.00,0.00)
f'(0.39)=Vector3D(-1.00,0.00,0.00) f''(0.39)=Vector3D(2.63,0.00,0.00)
f'(0.42)=Vector3D(-1.00,0.00,0.00) f''(0.42)=Vector3D(1.99,0.00,0.00)
f'(0.44)=Vector3D(-1.00,0.00,0.00) f''(0.44)=Vector3D(1.34,0.00,0.00)
f'(0.47)=Vector3D(-1.00,0.00,0.00) f''(0.47)=Vector3D(0.62,0.00,0.00)
f'(0.50)=Vector3D(-1.00,0.00,0.00) f''(0.50)=Vector3D(-0.02,0.00,0.00)
f'(0.53)=Vector3D(-1.00,0.00,0.00) f''(0.53)=Vector3D(-0.74,0.00,0.00)
f'(0.56)=Vector3D(-1.00,0.00,0.00) f''(0.56)=Vector3D(-1.38,0.00,0.00)
f'(0.58)=Vector3D(-1.00,0.00,0.00) f''(0.58)=Vector3D(-2.03,0.00,0.00)
f'(0.61)=Vector3D(-1.00,0.00,0.00) f''(0.61)=Vector3D(-2.67,0.00,0.00)
f'(0.64)=Vector3D(-1.00,0.00,0.00) f''(0.64)=Vector3D(-3.41,0.00,0.00)
f'(0.67)=Vector3D(-1.00,0.00,0.00) f''(0.67)=Vector3D(-4.07,0.00,0.00)
f'(0.70)=Vector3D(-1.00,0.00,0.00) f''(0.70)=Vector3D(-4.74,0.00,0.00)
f'(0.73)=Vector3D(-1.00,0.00,0.00) f''(0.73)=Vector3D(-5.51,0.00,0.00)
f'(0.76)=Vector3D(-1.00,0.00,0.00) f''(0.76)=Vector3D(-6.20,0.00,0.00)
f'(0.79)=Vector3D(-1.00,0.00,0.00) f''(0.79)=Vector3D(-6.91,0.00,0.00)
f'(0.82)=Vector3D(-1.00,0.00,0.00) f''(0.82)=Vector3D(-7.74,0.00,0.00)
f'(0.85)=Vector3D(-1.00,0.00,0.00) f''(0.85)=Vector3D(-8.49,0.00,0.00)
f'(0.89)=Vector3D(-1.00,0.00,0.00) f''(0.89)=Vector3D(-9.27,0.00,0.00)
f'(0.92)=Vector3D(-1.00,0.00,0.00) f''(0.92)=Vector3D(-10.19,0.00,0.00)
f'(0.96)=Vector3D(-1.00,0.00,0.00) f''(0.96)=Vector3D(-11.06,0.00,0.00)
f'(1.00)=Vector3D(-1.00,0.00,0.00) f''(1.00)=Vector3D(-11.98,0.00,0.00) EDIT: Questions: 1) What does the 2nd degree derivative of a cubic Bezier curve actually represent? (found in the title) 2) How can the 2nd degree derivative be variable when the 1st degree derivative is constant? OPTIONAL : 3) If my concept to use $f''(t)$ to orient the wheels is wrong, what is the theoretically correct way to orient them? EDIT 2 : The curve function and 1st derivative work a treat:","['bezier-curve', '3d', 'orientation', 'derivatives']"
1250102,Why does $\frac{1}{r}\frac{dr}{d\theta} = \cot \psi$?,"In the discussion of linear fractional equations in Birkhoff and Rota's Ordinary Differential Equations , the authors assert that if we convert a DE of the form $y' = F\left(\frac{y}{x}\right)$ to polar coordinates, then we have
\begin{align}
\frac{1}{r}\frac{dr}{d\theta} = \cot \psi,
\end{align}
where $\psi = \gamma - \theta$, with $\gamma$ being the tangent direction and $\theta$ the radial direction.  I'm afraid this has me entirely buffaloed -- why on earth is this true?  I have neither an analytic nor geometric intuition as to how this could possibly be.  I'm sure there's some elementaryish fact about $\frac{dr}{d\theta}$ which makes the answer obvious, but I have no clue what said fact is. I do note that 
\begin{align}
\frac{dy}{d\theta} &= r\cos\theta + \frac{dr}{d\theta}\sin\theta\Rightarrow\\
\frac{dr}{d\theta} & = \frac{dy}{d\theta}\csc\theta - r\cot\theta\Rightarrow\\
\frac{1}{r}\frac{dr}{d\theta} & = \frac{1}{y}\frac{dy}{d\theta} - \cot\theta, 
\end{align}
but this is as close as I can come to getting a cotangent anywhere near the expression (and, of course, $\theta \neq \psi$ in general). What gives?","['calculus', 'ordinary-differential-equations']"
1250133,integral of exponential of Brownian motion,"I am currently reading a proof that uses the following fact without proof: If $B$ is a scalar standard Brownian motion, then $\int_0^\infty e^{B_s} \,ds = + \infty$ a.s.. How can we justify this fact? I don't see how this follows from any property of Brownian motion.","['probability-theory', 'brownian-motion']"
1250146,Basic function manipulation and simplification question for $f((x-f(x))^2)$,"I've run into a bit of a wall trying to understand why the following two equations are equivalent: $$f((x-f(x))^2) = f(x^2)-f(x)^2$$ I'm running into this with calculating population variance in statistics, which is an area I understand, but I'm just not seeing the math here. I know at least for this application these two equations are equivalent, but am not familiar enough with function manipulation to see the logic behind it. The farthest I get is to go ahead and square the first function to get the following: $$f(x^2-2xf(x)+f(x)^2)$$ ...how do you continue to manipulate the terms and result in $f(x^2)-f(x)^2$?","['statistics', 'algebra-precalculus']"
1250168,"Assume that for any pair of vertices $P_i$ and $P_j$ , there exists a vertex $P_k$ of the polygon such that $∠P_i P_k P_j = \pi/3.$","Let $P_1 P_2 \dots P_n$ be a convex polygon in the plane. Assume that for any pair of vertices $P_i$ and $P_j$ , there exists a vertex $P_k$ of the polygon such that $∠P_i P_k P_j = \pi/3.$
  Show that $n = 3$ Taken from Romanian Mathematical Olympiad, 2000 Alright, how can you show this one? There may be many solutions of it","['contest-math', 'algebraic-geometry', 'geometry']"
1250177,"Inverse of a mean, exponential distribution, expected value","Could you help me find the expected value of this random variable? Let $X_1, X_2, ... $ be independent identically exponentially distributed with parameter $\lambda$ random variables. What is the expected value of $\frac{n}{X_1 + ... + X_n}$? I've read these questions https://math.stackexchange.com/questions/1246590/expectation-of-inverse-of-sum-of-random-variables-exponential-distribution and Expectation of inverse of sum of random variables but there's nothing helpful there. I know that the sum $X_1 + ... + X_n$ has Gamma distribution with parameters $2n$, $\frac{n}{\lambda}$ but either way I have a problem because $\mathbb{E} (\frac{1}{X}) \neq \frac{1}{\mathbb{E}X}$. Could you tell me what I can do with this?","['probability-theory', 'random-variables', 'expectation']"
1250186,Am I misinterpreting this matrix determinant property?,"I was reading matrix determinant properties from wikipedia . The property reads
$\det(cA) = c^n \det(A)$ for $n \times n$ matrix. However I am not able to realize it. What I find is $\det(cA) = c\det(A)$ For example, multiplying matrix by 2 and then taking the determinant of the resultant matrix: $
2\begin{bmatrix}
4 & 5 & 6 \\
6 & 5 & 4 \\
4 & 6 & 5 \\
\end{bmatrix}=
\begin{bmatrix}
8 & 10 & 12 \\
6 & 5 & 4 \\
4 & 6 & 5
\end{bmatrix}
$
and
$
\begin{vmatrix}
8 & 10 & 12 \\
6 & 5 & 4 \\
4 & 6 & 5
\end{vmatrix}=60
$ Now first taking the determinant and then multiplying by 2 yields the same result: $$
2\begin{vmatrix}
4 & 5 & 6 \\
6 & 5 & 4 \\
4 & 6 & 5 \\
\end{vmatrix}
= 2 \cdot 30 = 60
$$ Where I am mistaking?","['determinant', 'linear-algebra', 'matrices']"
1250192,Closed points are dense in $\operatorname{Spec} A$,"From 3.6.J in Vakil : Let $k$ be a field, and let $A$ be a finitely generated $k$-algebra. We want to show the closed points are dense in $\operatorname{Spec} A$. This is the set of prime ideals of $A$ endowed with the Zariski topology; closed points correspond to maximal ideals. Using distinguished open sets, this exercise amounts to showing that any distinguished open set $D(f) \neq \operatorname{Spec} A$ contains a closed point; i.e. we want a maximal ideal of $A$ not containing $f$. Vakil then gives a hint about using the nullstellensatz and residue fields, but I don't see why we can't just do the following: there's an inclusion-preserving bijection between (i) ideals of $A$ not containing any power of $f$, and (ii) ideals of the localization $A_f$. Then take a maximal ideal of $A_f$; which gives a maximal ideal of $A$ not containing $f$. Is this right? It seems too simple given the hint, so I think I'm botching something.","['algebraic-geometry', 'ideals', 'proof-verification', 'maximal-and-prime-ideals']"
1250251,Upper and Lower Darboux integral of a piecewise function $f(x)=x$ and $f(x)=0$.,"Let $0<a<b$. Find the upper and lower Darboux integrals for the function $$f(x)=x$$ if $x\in[a,b]\cap\mathbb{Q}$ and $$f(x)=0$$ if $x\in[a,b]-\mathbb{Q}$. I am so lost on this problem. Any hints or solutions are greatly appreciated.","['analysis', 'calculus', 'real-analysis']"
1250258,Proving that $3^n<n!$ when $n\geq 7$,"It's been 10 years since my last math class so I'm very rusty. How would I go about proving 
$$3^n < n!$$
where $n \geq 7$? I understand that factorials grow faster than set values with a variable exponent. Just not sure how to start proving it mathematically.","['factorial', 'induction', 'algebra-precalculus', 'exponential-function']"
1250272,Did I do something wrong solving this PDE in MATLAB?,"I have the following PDE problem on a practice exam: I have completed the problem using MATLAB to the best of my ability.  Here is the code I used M = [0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0;
     0 0 0 0 0 0 0 0 0 0 0];

h = 0.1;
k = 0.1;

%bottom row initial condition
for i=1:11
   x = (i-1) * 0.1;
   M(11,i) =  (0.1)*(x^2);
end

%right column initial condition
for i=1:10
   realI = 11-i;
   t = (11-realI) * 0.1;
   M(realI,11) = (0.1) * (1+t)^2;   
end

%n+1 row using u_t boundry condition
for i=2:10
   x = (i-1) * 0.1;
   left = M(11,i-1);
   right = M(11,i+1);
   M(10,i) = (left + right + 0.04*x)/2;   
end

%calculate the remaining n+1 row point (leftmost point)
M(10,1) = 0.1/5; %(1/5)t

%Now, just use the scheme to solve the rest of the points, and the t/5
%to calculate the edges
for n=1:9
   real_n = 10-n; %count from 9 to 1 rather than 1 to 9
   for m=2:10       
       M(real_n,m) = M(real_n + 1, m-1) + M(real_n + 1, m+1) - M(real_n + 2, m);
   end
   %leftmost point
   t = (n+1)/10;
   M(real_n, 1) = t/5; 
end

M
surf(M); The problem is that I have no way of knowing that I am correct as my professor does not release solutions for practice exams. My specific problem is I am not confident that I got the left column correct, but I'm also hoping to get feedback on my answer as a whole.  Can someone either replicate the problem or check over my code? Here are my results with the code that I posted: Did I do the left column correctly? Does my algorithm look correctly matched to the equations outlined in the problem?  Are there any ways I can improve the code that I wrote if it actually is correct?  MATLAB is a bit of a second language to me. (har har)","['calculus', 'matrices', 'numerical-methods', 'matlab', 'ordinary-differential-equations']"
1250275,Let $g: S^2 \to S^2$ be continuous and $g(x) \neq g(-x)\ \forall x$. Prove that $g$ is surjective.,"Let $g: S^2 \to S^2$ be continuous and $g(x) \neq g(-x)\ \forall x$. Prove that $g$ is surjective. The hint that if $p \in S^2$, then $S^2 - \{p\}$ is homeomorphic to $\mathbb{R^2}$. It is pretty obvious that one can use the Borsuk-Ulam Theorem, to prove that if we remove a point in the co-domain, this is homeomorphic to $\mathbb{R}^2$, so there must be an $x$ such that $g(x) = g(-x)$ which is obviously not possible with our assumption. The main question I ask myself is, why does it fail for $g(X) = A \subset S^2$, where $A$ can be a set in the form of $S^2 - \bigcup_\alpha \{p_\alpha\}$. This is not necessarily homeomorphic to $\mathbb{R^2}$ or is it? Kees",['general-topology']
1250305,When do closed subspaces of a Banach space fit together nicely?,"Let $E$ be a Banach space, and let $F_1, F_2, F_3, ...$ be a sequence of closed subspaces of $E$ with $F_i\cap F_j=0$ whenever $i\neq j$.  Denote by $\sum_n F_n$ the (not necessarily closed) subspace consisting of finite sums of elements from $\cup_n F_n$.  Do there exist criteria for telling when the topological closure $\overline{\sum_n F_n}$ is the Banach space sum of the $F_n$'s? By that I mean that every element of $\overline{\sum F_n}$ can be written in a unique way as an absolutely convergent sum $\sum_{n=1}^\infty f_n$ $(f_n\in F_n)$. I'm particularly interested in the case where $F_n =E_n$ in this post https://math.stackexchange.com/questions/1210693/a-question-about-a-proof-in-langs-sl-2-mathbbr .  So $$F_n = \{v\in E : \pi(r_\theta)v=e^{in\theta}v \hspace{3mm} \forall r_\theta \in SO_2(\mathbb{R})\}$$ where $\pi$ is some irreducible strongly continuous representation of $SL_2(\mathbb{R})$ in a Banach space $E$.","['analysis', 'harmonic-analysis', 'functional-analysis']"
1250306,Proving $1+5+9+\cdots+(4n+1) = (n+1)(2n+1)$ by induction (is there a typo?),"Using mathematical induction, prove that $$1+5+9+\cdots+(4n+1) = (n+1)(2n+1).$$ I understand the steps to take in order to prove by induction. It is also to my understanding that step 1 would be to verify that $n=1$ is true. I don't believe that it is true here. When $n = 1$, we have $4n + 1 = 5$ and $(n + 1)(2n + 1) = 6$. Am I missing something or is this a typo on my practice final?","['induction', 'algebra-precalculus']"
1250327,Maximum number of intersection points of two different Bernoulli lemniscates,"What is the maximum number of intersection points of two different Bernoulli lemniscates in the real plane?  (Of course two identical lemniscates share an infinite number of points.) Here are some of my efforts:  a Bernoulli lemniscate is a degree four curve with two nodes on the line of infinity in complex projective plane: $I=(i:1:0), J=(-i:1:0)$. By Bezout's theorem every two of these curves intersect in  16 points (counted with multiplicity) in $\mathbb{P^2(C)}$. But two common nodes in $I,J$ contribute at least (and exactly in the generic case) $8 = 2\times 2 + 2\times 2$  in the intersections. So the number of real intersections (i.e. intersections in $\mathbb R^2$) is at most $8$. However, according to my experience with Mathematica , I think that the maximum number of intersections is at most 6.  So what is the correct answer to this problem?  If the answer is 6, where are the other two complex points, and can we prove their existence algebraically?  (Note I'm interested in the algebraic approach to this problem and not analytic or topological solutions.) Thanks!","['algebraic-geometry', 'plane-curves', 'real-algebraic-geometry', 'algebraic-curves']"
1250350,Limit Ordinals as Infinite Ordinals and other questions,"I am studying set theory and I am confused in the following: Are limit ordinals the same as infinite ordinals? I would say yes since the least non-zero limit ordinal is $\omega$. Infinite limit ordinals are the same as limit ordinals? Yes, by definition of limit ordinals. What are infinite cardinals? Thanks.","['ordinals', 'elementary-set-theory', 'cardinals']"
1250355,Product of any two arbitrary positive definite matrices is positive definite or NOT? [duplicate],"This question already has an answer here : Positive definiteness of the matrix $A+B$ (1 answer) Closed 9 years ago . Suppose that , $A$ and $B$ are $n\times n$ positive definite matrices and > $I$ be $n\times n$ identity matrix. Then which of the followings are positive definite ? (i) $A+B$ (ii) $ABA$ (iii) $A^2+I$ (iv) $AB$ I know the definition of positive definite as : $\color{red}{A_{n\times n}}$ $\color{red}{\text{is positive definite if it's quadratic form}} $ $\color{red}{x^TAx>0}$ Since $A$ and $B$ are positive definite so, $x^TAx>0$ and $x^TBx>0$ . Then, $x^T(A+B)x=x^TAx+x^TBx>0.$ So $A+B$ is positive definite. I am confused about the product.. I saw a lot of questions in this site about the product of positive definiteness. But the answer in those questions it is assume that the matrices are symmetric . For example see the answer of this question. I want to know whether the product of any two arbitrary positive definite matrices is positive definite or NOT with a valid proof or counter example....","['positive-definite', 'linear-algebra', 'matrices']"
1250381,Derivative of the power tower,"May somebody help me to correctly calculate the dervative of the $n$-th power tower function? $$
\begin{align}
f_1(x)&=x\\
f_n(x)&=x^{f_{n-1}(x)}\\
&=x^{x^{x^{...^x}}}\text{ where }x\text{ occurs }n\text{ times}
\end{align}
$$ The solution given here is for the infinite case $f_{\infty}=\lim_{n\to\infty}f_n$.","['analysis', 'derivatives']"
1250420,Bolzano-Weierstrass theorem (complex case),"I'm trying to prove Bolzano-Weierstrass Theorem to the complex case, i.e., if $(z_n)$ a complex sequence is bounded, then there is a subsequence of $z_n$ which converges. I'm trying to use the real case of the Bolzano-Weierstrass theorem to prove the complex case without success. I need help. Thanks",['complex-analysis']
1250444,How should I think of an open vs. closed set?,"I've been studying introductory topology for a little bit now. I came across this video which explains open sets in a way I have never thought of. Even though the video is pretty elementary, I didn't know that open sets worked in this sense. If I were to 'imagine' moving toward the boundary of an open subset, I would just appear on the other side? Is this correct? Is there any kind of intuitive way of thinking about the concept of an open set versus a closed set without just saying one is outlined with a dotted line versus a solid line. I ask this because I have never really understood why something like a domain is generally defined to be a set that is both open and connected. Why does it matter if it is open or closed? Is this just a formality? Or are open sets something that are special. I am curious because I would like to know if I have been thinking about open sets completely wrong. Thanks.",['general-topology']
1250460,Convergence of $ L^{p} $-integrals implies convergence in $ L^{p} $-norm?,"Let $E$ be a measurable set, $\{ f_n \}$ and $f$ are in $L^p(E)$ such that $f_n \to f$ pointwise a.e. If $\lim \|f_n \|_p = \| f \|_p$ , 
is it true that $\lim \| f_n - f \|_p = 0$ ? I have tried using Generalised Lebesgue Dominated Convergence Theorem, 
for all $n$ , $|f_n-f|^p \leq g_n:=(|f_n|+|f|)^p$ , 
then $g_n \to g:=2^p|f|^p$ pointwise a.e. 
But how to show $\lim \int g_n = \int g$ ? Thank you!!","['lebesgue-measure', 'real-analysis', 'lp-spaces', 'convergence-divergence', 'lebesgue-integral']"
1250463,Difference between definitions of $p$-subgroup and Sylow $p$-subgroup,"I'm reading Abstract Algebra by Dummit and Foote and the following
definitions are made: $1$ . A group of order $p^{\alpha}$ for some $\alpha\geq1$ is called a $p$ -group. Subgroups of $G$ which are $p$ -groups are called $p$ -subgroups. $2$ . If $G$ is a group of order $p^{\alpha}m$ , where $p$ does not divide $m$ , then a subgroup of order $p^{\alpha}$ is called a Sylow $p$ -subgroup of G. As I see it the difference seems to be that if $H \leq G$ with $|H|=p^{\beta}$ for $\beta\geq1$ it is called a $p$ -subgroup if $|G|=p^{\alpha}$ and a sylow subgroup of $G$ if its order is not a power of $p$ . But in the wording of the Sylow's theorem in the book it reads that Let G be a group of order $p^{\alpha}m$ , where $p$ is a prime not
dividing $m$ then...If $P$ is a Sylow $p$ -subgroup of $G$ and $Q$ is
any $p$ -subgroup of G... I don't understand the difference between $P$ and $Q$ ..both are
subgroups of $G$ with order of a power of $p$ and I thought that $Q$ can't be called a $p$ subgroup because the order of $G$ is
not a power of $p$ . So it seems that I didn't understand the difference in definitions $(1)$ and $(2)$ after all. Can someone please clarify ?","['sylow-theory', 'p-groups', 'abstract-algebra', 'group-theory', 'finite-groups']"
1250471,a question about undergraduate-level differential geometry(Gauss-Bonnet theorem),"Let $S\subset R^3$ be a regular surface homeomorphic to a sphere. Let $\alpha\subset S $ be a simple closed geodesic in S,let A and B be a regions of S which have $\alpha$ as a common boundary. Let N:$S->S^2$ be the Gauss map of S. prove that N(A) and N(B) have the same area. My thoughts:
I think I need to use Gauss-Bonnet theorem,since the curve $\alpha$ can be mapped into a sphere,and the mapped the curve should be smooth(But I am not sure whether it is still geodesic),so use Gauss-Bonnet Theorem, we have $$\iint_{N(A)}Kds+\int_{0}^lk_{g}ds=2\pi X(s)$$,where X(s) is the Euler-poincare characteristic of a regular surface. if the geodesic curvature $k_{g}$=0,I can know that the area of N(A) should be $2\pi$,since the Gaussian curvature k=1 in the unit sphere,but I have no idea whether the geodesic curve in the original surface is still be geodesic in the sphere. Any help?","['riemannian-geometry', 'differential-geometry', 'real-analysis']"
1250494,Roll eleven dice such that the product is prime,"So the problem is:
What is the probability of rolling eleven dice such that their product is prime.
The dice is numbered from 1 to 6 and there is an equal chance of getting each number. So in order for the product to be prime, all but one of the numbers must be 1. The number that is not 1 must be either 2, 3, or 5. 
So the total number of ways that 2, 3, or 5 can be formed through multiplication is 3*11 = 33. I then divided 33 by the total number of products that can be formed, or $6^{11}$. My original solution yields basically the same numerical value, but I'm doubtful of it's correctness. By the binomial probability theorem, the probability of rolling a 1 ten times and a number besides 1 is $$_{11}C_{10} \left(\frac{1}{6}\right)^{10}\left(\frac{5}{6}\right)^{1} $$ Given that the remaining number is not 1, the probability of rolling 2, 3, or 5 is $\frac{3}{5}$. Hence we multiply them together to get the probability
$$_{11}C_{10} \left(\frac{1}{6}\right)^{10}\left(\frac{5}{6}\right)^{1}\left(\frac{3}{5}\right)$$ This problem was originally a test question, but many of my peers got a different answer of
$$ \left(\frac{(3*11)}{6^{11}}\right)\left(\frac{11!}{10!}\right)$$ If their answer is correct could someone please explain to me why mines is incorrect? I would also greatly appreciate it if you could explain how to get the correct answer.",['probability']
1250504,"Why is $\sinh$ often pronounced ""shine""? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 8 years ago . Improve this question I talked to some guys from the UK and they told me that they would pronounce $\sinh$ as ""shine"". I am not a native English speaker so I don't know, but in my country we call this function ""sintsh"" with a $sh$ as in ""sharp"" and a $s$ as in ""saw"". This seems to be the natural thing to do if you have not a clue how to call this function. Despite, in my country people try to avoid giving this function a name because they are afraid of making a fool out of themselves. My question is: What is the standard name for this function and where does this ""shine"" come from?","['terminology', 'real-analysis', 'functions', 'hyperbolic-functions', 'pronunciation']"
1250506,‘Integral’ of a Weierstrass $ \wp $-function.,"I'm revising for my finals and I've seen a question which asks:
Is there a meromorphic function $f: \mathbb{C}/\Lambda \to \mathbb{P}^1$ such that $f' = \wp$? There is a hint which says consider the poles of such a function, and I'm pretty sure no such function can exist, but if anyone could supply me with a proof or further hint I would be really grateful.","['complex-geometry', 'complex-analysis', 'algebraic-curves']"
1250514,Is the sum of two projections a projection?,"Let $ S $ and $ T $ be two linear subspaces of $ \Bbb{R}^{2} $. Then is the sum of the projections $ P_{S} $ and $ P_{T} $ (i.e., $ P_{S} + P_{T} $) a projection? I don’t think it is since the projection rule doesn’t hold ($ P_{M}^{2} $ does not equal $ P_{M} $), but I was hoping someone could solidify this. It would be very much appreciated!",['linear-algebra']
1250549,"For any 7 different real numbers, there are among them two numbers x and y such that $0<\frac{x-y}{1+xy} < √3$","For any 7 different real numbers, there are among them two numbers x and y such that $\frac{x-y}{1+xy}$ is greater than zeron and less than the square root of 3. I find this fact quite amazing for many reasons. I want to know more about it; the proof for it would be cool, or perhaps some information on who postulated it; i'm particularly interested on how could he have ever come up with the conjecture. I'm also looking for an example of a set of 6 different reals such that no pair of them with the above property can be found. (If it exists, but does it?)",['number-theory']
1250554,Curvature of plane parametric curves,What is the neatest way to derive the following formula for the curvature of a parametric curve? $$\kappa =\frac{\|y'x''-y''x'\|}{(x'^2+y'^2)^{\frac{3}{2}}}  $$,"['plane-curves', 'differential-geometry', 'curvature']"
1250573,A computation related to Hironaka's Example,"My questions are at the very end, first I'll describe the context. Let $f:\mathbb{P}^3\to \mathbb{P}^3$ be an involution whose fixed locus consists of two disjoint lines $L, L' \subset \mathbb{P}^3$. Let P be any plane in $\mathbb{P}^3$ in general position with respect to the lines L and L', that is, $P\cap L=Q$ and $P\cap L'=Q'$. Then $P'=f(P)$ is again a plane, we don't want to look at the trivial case $P'=P$ so assume they are different. Then the line M joining Q and Q' is exactly $P\cap P'$. Let R be a point of M not  equal to Q or Q'. Then R':=f(R) is a point of M not equal to R, Q, and Q' because they are not contained in the lines L and L'. Now let C be a smooth conic in P' with $C\cap M=\{R,R'\}$. Then C':=f(C) is a smooth conic in P' with $C'\cap M=\{R,R'\}$. Let U:=$\mathbb{P}^3\setminus\{R\}$, $U':=\mathbb{P}^3\setminus\{R'\}$, $\widetilde{U}:=B\ell_{\widetilde{C'}}(B\ell_{C}U)$, and $\widetilde{U'}:=B\ell_{\widetilde{C}}(B\ell_{C'}U)$ where we glue the last two along to get a smooth proper threefold X. Let E be the exceptional locus of the morphism $B\ell_{C}U\to U$; here we note that $E\cong (C\setminus R)\times \mathbb{P}^{1}\cong \mathbb{A}^1\times \mathbb{P}^1$. Let E' be the exceptional locus of $B\ell_{C'}U\to U$ and let $A:=E\cap \widetilde{C'}$ we know that this is in $E_{R'}$ where $E_{R'}$ is defined accordingly. Now let $\widetilde{f}:X\to X$ be the lifting of the map $f:\mathbb{P}^3\to \mathbb{P}^3$, and let Y:=X/f. Consider the quotient map $q:X\setminus\{R,R'\}\to Y\setminus\{S\}$ where S=q(R)=q(R'). By SGA 3 Expose 5, we can say that q is ``nice"", i.e. it is an étale map and $Y\setminus\{S\}$ is a scheme. Now my questions are as follows: If $\mathfrak{m}_S$ is the unique of maximal of the stalk $\mathcal{O}_{Y,S}$, then what can we say about $dim_{\mathbb{C}}(\mathfrak{m}_S/\mathfrak{m}^2_S)$? (After going over some correspondences related to tangent space at R, $T_RX$; intuitively, I suppose that it might be 4 but I can't proceed formally.) How can the map $\mathcal{O}_{Y,S}\to \mathcal{O}_{X,R}$ be described explicitly? Thanks in advance for any help.","['algebraic-geometry', 'schemes']"
1250583,How to show that recurrence $T(n) \in \Omega(n^{0.5})$ using proof by induction?,"This is recurrence $T(n)$ $ T(n) =
\begin{cases}
c,  & \text{if $n$ is 1} \\
2T(\lfloor(n/4)\rfloor) + 16, & \text{if $n$ is > 1}
\end{cases}$ This is my attempt to show that $T(n) \in \Omega(n^{0.5})$ with proof by induction Statement: The recurrence $T(n) \ge bn^{1/2}$ for all $n \gt n_0$ Base case($n=1$) : $T(1) = c$ Base case true as long as $c \ge $ b Inductive hypothesis: Assume that $T(k) \ge bk^{0.5}$ for all $k\lt n$ Inductive step ($n\gt1$) $T(n)=2T(\lfloor(n/4)\rfloor) + 16$ $2T(\lfloor(n/4)\rfloor) + 16\ge 2b(\lfloor(n/4)\rfloor)^{0.5} + 16$         By Inductive hypothesis $2b(\lfloor(n/4)\rfloor)^{0.5} + 16 \ge 2b(n/16)^{0.5} + 16$ $2b(n/16)^{0.5} + 16 = \frac{b\sqrt{n}}{2} + 16$ Now to complete the proof by induction, I have to show that $\frac{b\sqrt{n}}{2} + 16 \ge b\sqrt{n}$ Solving for b, I got $b\le\frac{32}{\sqrt{n}}$. My issue here is that I can't find an appropriate $b$ to use to meet the definition of $\Omega(n^{0.5})$ based off the inductive step because in the inductive step, $b$ is in terms of a variable $n$. Does anyone know of a way I can choose $b$ so that it is a constant, like $c$ to meet the definition?","['computer-science', 'discrete-mathematics', 'recurrence-relations', 'recursion', 'recursive-algorithms']"
1250590,"Find when the population is growing the fastest, under the logistic model",The population $P$ of an island $y$ years after colonization is given by the function: $\displaystyle P = \frac{250}{1 + 4e^{-0.01y}}$. After how many years was the population growing the fastest? I tried taking the second derivative and setting it equal to zero. From there I solved for $y$ but kept getting $y = 0$. Which doesn't make too much sense so I was wondering how anyone would go about answering this problem.,"['exponential-function', 'logarithms', 'calculus', 'derivatives']"
1250592,A variation of Lévy's characterization of Brownian motion,"It is shown here , without using stochastic calculus, that if $W_t$ is a standard Brownian motion, then 
$$
f(W_t)-\frac{1}{2}\int_0^t f''(W_s)ds
$$
is a martingale, where $f\in C^2$ and compactly supported. According to Problem 4.4 in Chapter 5 of Karatzas and Shreve's Brownian Motion and Stochastic Calculus , the converse is also true. Namely, if $W$ is a continuous adapted process with $W_0=0$ such that
$$
f(W_t)-\frac{1}{2}\int_0^t f''(W_s)ds\tag{1}
$$
is a martingale whenever $f\in C^2$ and compactly supported, then $W$ is a standard Brownian motion. This is essentially part of the proof of Lévy's characterization of Brownian motion.","['probability-theory', 'brownian-motion', 'martingales', 'stochastic-processes']"
1250593,Could you explain the expansion of $(1+\frac{dx}{x})^{-2}$?,"Could you explain the expansion of $(1+\frac{dx}{x})^{-2}$? Source: calculus made easy by S. Thompson. I have looked up the formula for binomial theorem with negative exponents but it is confusing. The expansion stated in the text is: $$\left[1-\frac{2\,dx}{x}+\frac{2(2+1)}{1\cdot2}\left(\frac{dx}{x}\right)^2 - \text{etc.}\right] $$ Please explain at a high school level.","['calculus', 'algebra-precalculus']"
1250622,Largest subset with no arithmetic progression,"I am trying to find some weak bounds on the largest subset of a set, such that the subset has the property that it contains no three elements in arithmetic progression. The elements of the original set are in an arithmetic progression of length 1, i.e. $S=\{n,n+1,...,n+k-1\}$. For example, if $S=\{5,6,7,8,9,10\}$ then one subset satisfying the property I stated above is $\{5,7,8,10\}$ since no three elements of this set are in arithmetic progression. So we immediately know that a bound for this set is $\ge 4$. I am trying to find a weak bound in general for the set $\{n,n+1,...,n+k-1\}$. In other words, what roughly is the largest possible subset of this set such that no three elements of this subset are in arithmetic progression.","['number-theory', 'elementary-number-theory', 'combinatorics', 'reference-request']"
1250655,If $a=b$ then $a+c=b+c$? [duplicate],"This question already has answers here : Algebra: What allows us to do the same thing to both sides of an equation? (12 answers) Is there a law that you can add or multiply to both sides of an equation? [duplicate] (9 answers) Closed 9 years ago . A friend of mine just asked me how to prove that if $a=b$ then $a+c=b+c$, where $a,b$ and $c$ are real numbers, I'm not sure what I should answer. I have a book called introduction to logic and to the theory of the deductive sciences by Alfred Tarski, which is about propositional logic, and I remember reading that two things $a$ and $b$ are equal if any proposition that is true about $a$ is also true about $b$ and vice-versa. However I think this isn't very formal. I haven't taken any set theory course, I think that another way to justify it is to say that sum is a function and since the ordered pairs $(a,c)$ and $(b,c)$ are equal then $+(a,c)=+(b,c)$. But I'm not too convinced. If we use the standard axioms how would we justify $a+c=b+c$ using the mainstream axioms of today. I think there is something Zermelo-Frankl with choice. Would these be enough, what properties of the real numbers do we need? Can we prove it using the usual construction of the real numbers and Zermelo-Frankl? As you can probably see I am not very knowledgeable about these topics, so I would like a delicate explanation. Many thanks and regards.","['elementary-set-theory', 'axioms', 'terminology', 'predicate-logic', 'reference-request']"
1250672,"$y_{2n}, y_{2n+1}$ and $y_{3n}$ all converge. What can we say about the sequence $ y_n$?","My friend and I are currently debating the following question: Let $y_n$ be a sequence in a metric space and assume that the subsequences 
  $y_{2n}$, $y_{2n + 1}$, and $y_{3n}$ all converge. What can we say about the sequence $y_n$? To me it seems that all the subsequences will converge to a limit say $y$. Then any term in the original sequence will be in one of these subsequences, it follows that the entire sequence $y_n$ converges to $y$. I let $\varepsilon > 0$. Since $y_{2n}$ converges to $y$ there exists an index $2N$ such that $d(y_{2n},y) < \varepsilon$ for $2n \geq 2N$,
and since $(y_{2n+1})$ converges to $y$ there exists $2M + 1$ such that $d(y_{2n+1}, y) < \varepsilon$ for $2n + 1 \geq 2M + 1$. Let $m \geq \max\{2N,2M+1\}$. If  $m$ is even, since $m\geq 2N$ we have $d(y_m,y)<\varepsilon$; if $m$ is odd, since $m\geq 2M+1$ we have $d(y_m,y)<\varepsilon$. Thus $d(y_m,y)<\varepsilon$ for any $m \geq \max\{2N,2M+1\}$, and we conclude that $(y_n)$ converges to $y$. However, my friend does not think that this is completely correct because I didn't use the $y_{3n}$ in the proof. I think he is right, that I do in fact need it, but I am unsure of how to add it in. All in all, I think that since any term in the original sequence will be in one of these subsequences, it follows that the entire sequence $(y_n)$ converges to $y$. $2n+1$ covers all the odd terms and $2n$ converse all the even terms, so is $3n$ even needed? I would like to use it since the proof has it in the question, but I am unsure of what to do. Could someone kindly help me construct this proof in a better manner,and is my line of thinking correct? Thank you!","['sequences-and-series', 'calculus', 'real-analysis', 'convergence-divergence']"
1250691,Prove that $\int (\delta x)=\delta^{-d} \int f$,"Let $f$ be a real-valued integrable function on $\mathbb{R}^d$. Prove that $$\int f(\delta x) = \delta^{-d} \int f.$$ I let $f(x)=\chi_E(x)=\begin{cases} 1 & \text{if }\delta x \in E \\ 0 & \text{if }\delta x \in E \end{cases} = \begin{cases} 1 & \text{if } x \in \delta^{-1} E \\ 0 & \text{if } x \in \delta^{-1}E \end{cases}$. Putting this together, I start with
\begin{align*}
m(\delta^{-1}E)&=\delta^{-d}m(E) \\
\sum_{k=1}^N a_k m(\delta^{-1}E)&=\delta^{-d} \sum_{k=1}^Na_km(E) \\
\end{align*}
And as $N \to \infty$, 
\begin{align*}
\int \chi_{\delta^{-1}E}(x)&= \delta^{-d} \int \chi_E(x) \\
\int f(\delta x) &= \delta^{-d} \int f(x).
\end{align*}
Is this correct?","['proof-verification', 'real-analysis', 'lebesgue-integral', 'measure-theory']"
1250701,a question about differential geometry(Gauss-bonnet theorem and isolated singular point in the surface),"Let C be a regular closed simple curve on a sphere $S^2$. Let v be a differentiable vector field on $S^2$ such that the trajectories of v are never tangent to C. prove that each of the two regions determined by C contains at least one singular point of v. My thoughts:Based on poincare's theorem,we know that $$\sum I_{i}={1\over 2\pi}\iint_{s}Kds$$,where $I_{i}$ is the index of v at the isolated singular point.Then,since the Euler-poincare characteristic of a sphere is 2,so we have $\sum I_{i}=2$. Then. I don't know how to contine to analyze the question,since I think $I_{i}$ is not necessary to be 1. So any help?","['riemannian-geometry', 'differential-geometry', 'real-analysis']"
1250702,Finding the de Rham cohomology of an open subset of $ \Bbb{R}^{n} $ minus a point.,"Here’s my question: Let $ n \in \mathbb{N}_{\geq 2} $. Suppose that $ U \subseteq \Bbb{R}^{n} $ is an open set and that $ x \in U $. Then show that
  $$
{H_{\text{dR}}^{n - 1}}(U \setminus \{ x \}) \neq 0.
$$ My thoughts: I was trying to use that
  $$
                S
\hookrightarrow U \setminus \{ x \}
\hookrightarrow \Bbb{R}^{n} \setminus \{ x \}
$$
  (where $ S $ is a small sphere in $ U $ centered at $ x $) should induce a homotopy equivalence, so
  $$
      {H_{\text{dR}}^{n - 1}}(U \setminus \{ x \})
\cong {H_{\text{dR}}^{n - 1}}(S)
\cong \Bbb{R}.
$$ I get the feeling that there’s something horribly wrong with this line of thought, so I was wanting some help. I’m okay with a direct answer, as long as you think the solution alone would be illuminating. P.S.: This is my first post. Any advice on how I could make my question better would be appreciated as well.","['differential-topology', 'homology-cohomology', 'differential-geometry', 'algebraic-topology']"
1250724,"Find all holomorphic functions, $f: \mathbb{C} \rightarrow \mathbb{C}$. so that $f'(0)=1$ and $f(x+iy)=e^{x}f(iy)$","Find all holomorphic functions, $f: \mathbb{C} \rightarrow \mathbb{C}$. so that $f'(0)=1$ and $f(x+iy)=e^{x}f(iy)$ I've been messing with this problem for most of today and haven't managed to get much from it. I started considering the real and imaginary parts of $f$. So, $f(x+iy) = u(x,y) + i v(x,y)$ and $f(iy) = u(0,y) + iv(0,y)$ Since $f$ is  holomorphic we know that the Cauchy Riemann equations hold for both of those. Since $f$ is holomorphic we also know that $\lim_{x\rightarrow0} \frac{f(x) - f(0)}{x} = \lim_{x\rightarrow0} \frac{e^xf(0) - f(0)}{x} = 1$ Which gives us $\lim_{x\rightarrow0} \frac{e^x - 1}{x} = \frac{1}{f(0)} = 1$ so $f(0) = 1$, so $v(0,0)=0$ and $u(0,0)=1$. Similarly $\lim_{y\rightarrow0} \frac{f(iy) - f(0)}{iy} = \lim_{y\rightarrow0} \frac{f(iy) - 1}{iy} = 1$, but I don't think this is very useful. I tried messing a bit with the Cauchy Riemann equations, but I didn't manage to get much from that. Is my approach the wrong one or is there something I'm missing? Any help would be greatly appreciated!","['analysis', 'calculus', 'complex-analysis']"
1250726,Finding the derivative of the integral using the Fundamental Theorem of Calculus.,"(1 pt) Find the derivative of the following function
  $$F(x) = \int_{x^4}^{x^7} (2t - 1)^3 dt$$
  using the Fundamental Theorem of Calculus. $F'(x) = \ldots $ ( original image ) I'm still not entirely solid on the concept of the Fundamental Theorem of Calculus, but I believe that the first step of the theorem will give us $$2x-1$$ which is the derivative of F(x). Usually, you would then take F(b) - F(a) to solve for the second step, but since its replaced with variables, I'm not sure how to proceed.","['calculus', 'derivatives']"
1250730,Problem with real differentiable function involving both Mean Value Theorem and Intermediate Value Theorem,"Problem: Let $a,b \in \Bbb R$, $a<b$, and let $f$ be a differentiable real-valued function on an open subset of $\Bbb R$ that contains $[a,b]$. Show that if $\gamma$ is any real number between $f'(a)$ and $f'(b)$ then there exists a number $c \in (a,b)$ such that $\gamma = f'(c)$ . So I was trying to use the Mean Value Theorem and the Intermediate Value Theorem for the function $\frac {f(x_1) -f(x_2)}{x_1 - x_2}$ on this set: $\{(x_1,x_2) \in E^2: a \le x_1 < x_2 \le b \}$ but I am stuck how do you go from here (if my thinking is correct).","['real-analysis', 'derivatives']"
1250731,Fourier series of complex diff eq,"Can I just use Euler's identity to construct the Fourier Series since it is complex? I was personally thinking I could, but I wanted to be doubly sure.","['fourier-series', 'ordinary-differential-equations']"
1250787,Which discrete mathematics book do you think is better between Epp's and Rosen's for a clueless self-learner?,"I am a programmer, and I want to become a machine learning researcher and a good software engineer. I dabbled with calculus, linear algebra, and real analysis for a few months when I was enrolled in a university. I majored in biology in the university, by the way. About $7$ years have passed since I dabbled with them, and I seem to have forgotten $99.9\%$. I need to start math from scratch again. I've finished all but $3$ sections of Andrew Ng's machine learning class on coursera. I am going to read 'how to prove it' by velleman and then a discrete mathematics book. After then, I'll learn calculus, linear algebra, probability and statistics. The problem is which discrete mathematics material to use after 'how to prove it'. Amazon reviews say that Epp's book explains the concepts the best but that Rosen's book covers more subjects. According to amazon reviews, 'Concrete mathematics' by Knuth seems to be for students who already know calculus and linear algebra which I have to learn from scratch again. Which learning material do you think is appropriate for a clueless self-learner like me?","['reference-request', 'discrete-mathematics', 'soft-question']"
1250806,A combinatorics question about selection strategies,"I am given a set of balls--red and blue. In each set, there are three kinds of balls--small, medium and large. In each set there are 10 balls of each color: 10 Red balls (2 small + 3 medium + 5 large) 10 Blue balls (2 small + 3 medium + 5 large). Now, given N sets of balls and M balls to be chosen, I've to pick balls in such a way that 1) there have to be equal number of red and blue balls 2) there have to be equal number of medium and large balls I think it is a combinatorics question and I thought the answer should be $2*{3 N \choose M/2}*{5 N \choose M/2}$ But I am not sure of the answer. Please help me. Thanks. :)","['combinatorics', 'permutations']"
1250814,Irrational Numbers : Show that $0.1248163264...$ is irrational,I was working through some basic Number Theory Problems in Rosen and came across the following problem : Show that the real number $0.1248163264...$ represented in base 10 is an irrational number I am slightly stumped. Can someone help me out? A hint would be great.,"['number-theory', 'irrational-numbers', 'decimal-expansion', 'elementary-number-theory']"
1250881,Show that: $\sinh^{-1}(x) = \ln(x + \sqrt{x^2 +1 } )$,could someone Please give me some hint of how to do this question thanks,"['algebra-precalculus', 'trigonometry']"
1250884,How to prove that $ \sin \angle{GAB}+\sin \angle{GBC}+\sin \angle{GCA} \le \frac{3}{2} $ for a triangle $ABC$ with centroid $G$?,"Let $ G $ be the centroid of $ \triangle ABC $ , such that  $ \measuredangle{GAB}=x,\measuredangle{GBC}=y,\measuredangle{GCA}=z $. How do I prove  that :
$$  \sin x +\sin y +\sin z\le \frac{3}{2} $$","['geometry', 'inequality', 'geometric-inequalities', 'trigonometry']"
1250889,"Prob. 1, Sec. 3.3, in Erwine Kreyszig's INTRODUCTORY FUNCTIONAL ANALYSIS WITH APPLICATIONS","Let $H$ be a Hilbert space, $M \subset H$ a convex subset, and $\left( x_n \right)$ a sequence in $M$ such that $\left\lVert x_n \right\rVert \to d$ , where $d = \inf_{x \in M} \lVert x \rVert$ . How to show that $\left( x_n \right)$ converges in $H$ ? What are the most surprising facts about the plane $\mathbb{R}^2$ and the space $\mathbb{R}^3$ that one can derive using the above result?","['inner-products', 'real-analysis', 'functional-analysis', 'hilbert-spaces', 'analysis']"
1250897,Is a circle classified as an ellipse?,"I read that an ellipse had $2$ focal points. So, I thought if a circle had $2$ points that were simply infinitesimally close together wouldn't it be classified as an ellipse?","['intuition', 'geometry', 'circles', 'algebra-precalculus']"
1250925,Sum of two normal numbers need not be a normal one,"Using the translation invariance of Lebesgue measure how to show that sum and difference of two normal numbers need not be normal ? Normal number in $(0,1]$ is a number $\omega$ such that $\lim_{n \to \infty} \frac{1}{n}\sum_{i=1}^{n}d_i(w) = \frac{1}{2}$ Hint Enough.","['probability-theory', 'probability', 'real-analysis']"
1250935,Evaluation of $\int\frac{1}{x^2.(x^4+1)^{\frac{3}{4}}}dx$,"Evaluate the integral
  $$\int\frac{1}{x^2\left(x^4+1\right)^{3/4}}\,dx$$ My Attempt: Let $x = \frac{1}{t}$. Then $dx = -\frac{1}{t^2}\,dt$. Then the integral converts to $$
-\int \frac{t^3}{(1+t^4)^{3/4}}\,dt
$$ Now Let $(1+t^4) = u$. Then $t^3\,dt = \frac{1}{4}du$. This changes the integral to $$
\begin{align}
-\frac{1}{4}\int t^{-3/4}\,dt &= -u^{1/4}+\mathcal{C}\\
&= -\left(1+t^4\right)^{1/4}+\mathcal{C}
\end{align}
$$ So we arrive at the solution $$\int\frac{1}{x^2\left(x^4+1\right)^{3/4}}\,dx = - \left(\frac{1+x^4}{x^4}\right)^{1/4}+\mathcal{C.}$$ Question: Is there any other method for solving this problem?","['calculus', 'indefinite-integrals', 'integration']"
1250963,Spivak's calculus: Chapter 7 problem 18 d),"In cases (a) and (c) [where it was proven that such a number exists for a continous $f$ on $\textbf{R}$], let $g(x)$ be the minimum distance from $(x,0)$ to a point on the graph $f$. Prove that $g(y)\leq g(x)+|x-y|$, and conclude that $g$ is continous. The answer from the answer book By definition, $g(x) = \sqrt{(f(z))^2+(z-x)^2}$ for some $z$ in $[a,b]$. Now $\sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2}+|z-y|$ for all $z$. So $g(y)$, the minimum of all $\sqrt{(f(z))^2+(z-y)^2}$, is less than or equal to $|z-y|+$ the minimum of all $\sqrt{(f(z))^2+(z-x)^2}$, which is $g(x)+|x-y|$. Since $|g(y)-g(x)|<|y-x|$ it follows that $g$ is continous (given $\varepsilon>0$, let $\delta = \varepsilon$). I understand why $\sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2}+|z-y|$ for all $z$ and I see how the continuity of $g$ would follow from the conclusion. But I don't get why the minimum of all $\sqrt{(f(z))^2+(z-y)^2}$, is less than or equal to $|z-y|+$ the minimum of all $\sqrt{(f(z))^2+(z-x)^2}$ and why this is supposed to be $g(x)+|x-y|$. Can someone help me here? Edit: I've now figured out the following things: if for some $z_0$ we have a minimum of $\sqrt{(f(z))^2+(z-y)^2}$, this means that 
$$
g(y) \leq \sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2} +|y-z| 
$$
for all $z$. So we can simply pick a $z=u$ such that $\sqrt{(f(u))^2+(u-x)^2} = g(x)$, so then we have
$$
g(y) \leq g(x)+|u-y|
$$
Does anyone now know how to turn that $|u-y|$ into $|x-y|$?","['continuity', 'calculus', 'limits']"
1250968,Where is Cauchy's wrong proof?,"Allegedly, Cauchy mistakingly ""proved"" that pointwise convergence of continuous functions is continuous. I saw this somewhere in a book, and it is also in wikipedia: Uniform convergence. In his Cours d'analyse of 1821, Cauchy ""proved"" that if a sum of continuous functions converges pointwise, then its limit is also continuous. However, Abel observed three years later that this is not the case. For the conclusion to hold, ""pointwise convergence"" must be replaced with ""uniform convergence"". 1 There are many counterexamples. For example, a Fourier series of sine and cosine functions, all continuous, may converge to a discontinuous function such as a step function. Well, I searched in the book mentioned (or rather, this one ) and didn't find it. Where is it?","['reference-request', 'real-analysis', 'soft-question']"
