question_id,title,body,tags
3579961,"Assuming that "" slope of the tangent at $x=a$ "" and "" $f'(a)$"" are not identical by definition , how can their identity be shown algebraically?","When the concept of the "" derivative number"" of a function $f$ for some $x-$ value , say $x=a$ is introduced - this number is simply $f'(a)$ -  the motivation is often that this number is identical to the slope of the tangent to the graph of $f$ at point $(a, f(a)$ . This is shown visually, by allowing a line passing through point $A =(a, f(a))$ and through some point $B$ on the curve to move gradually ( while $B$ also moves) until this line becomes identical to the tangent ( the slope of which we are supposed to look for). My question is : how to show analytically that the number $\lim_{h\rightarrow0}\frac {f(a+h) - f(a)}{h}$ and the number $\frac{y_{D} - y_C} {x_{D} - x_C}$ (with $C$ and $D$ two arbitrary distinct points on the tangent line) are actually one and the same number? To put it more briefly: assuming there is at least a conceptual difference between "" derivative number"" and "" slope of the tangent"" , how to show that the two expressions denote, in fact, one and the same object ( namely, the same number) ? PS : here I use the expression "" derivative number"" that is common in french mathematics to denote the image of an x-value under the derivative function.","['tangent-line', 'calculus', 'definition', 'derivatives', 'soft-question']"
3580004,How do I go about writing a proof?,"I've decided to self-study math to conquer some old fears--I'm pretty new to the idea of proving overall, and I am stuck on this:  *Explain why there are no real numbers that satisfy the equation: $$|x^2 + 4x| = -12.$$ I've tried to do a proof by induction; but I'm wondering whether this is the right way to approach this, and I frankly do not know how to word it at all. What should I do?","['proof-explanation', 'algebra-precalculus', 'proof-writing']"
3580060,The area of infinitely many circles inside a right angle triangle,"A right angle triangle with sides $s_1$ and $s_2$ , and hypotenuse $h=\sqrt{s_1^2+s_2^2}$ is containing infinity many circles as follows; $\omega_1$ is the circle which is tangential to $s_1,s_2,h$ (i.e. the in-circle). $\omega_2$ is the circle which is tangential to $\omega_1,s_1,h$ . $\omega_3$ is the circle which is tangential to $\omega_2,s_1,h$ . $\omega_4$ is the circle which is tangential to $\omega_3,s_1,h$ . In general, for $n>1$ , $\omega_n$ is the circle which is tangential to $\omega_{n-1},s_1,h$ . Knowing $s_1$ and $s_2$ , how can we determine the total area of these
  infinitely many circles? Any help would be really appreciated. THANKS!","['coordinate-systems', 'circles', 'geometry', 'triangles', 'sequences-and-series']"
3580101,Models of a certain (weird) equational theory,"Consider the following (single-sorted) equational/algebraic theory with one binary operation symbol $\ast$ whose axioms are as follows: $$(x \ast x) \ast (x \ast x) = x$$ $$(x \ast y) \ast (x \ast y) = (x \ast x) \ast (y \ast y).$$ I am interested in models of this theory where $\ast$ is NOT idempotent, i.e. where $x \ast x = x$ is not true for every $x$ in the model. So far, I have come up with the following toy model of this theory, where $\ast$ is not idempotent: the carrier is $\{0, 1\}$ , and the binary operation $\ast$ is defined as follows: $$0 \ast 0 = 1,$$ $$1 \ast 1 = 0,$$ $$0 \ast 1 = 0,$$ $$1 \ast 0 = 1.$$ My question is, are there any more 'natural' models of this theory where $\ast$ is NOT idempotent, i.e. are there any non-idempotent binary operations satisfying the above axioms that have been previously studied in mathematics?","['binary-operations', 'abstract-algebra', 'universal-algebra', 'idempotents']"
3580109,"Why does regression use least ""squares"" instead of least ""absolute values""? [duplicate]","This question already has answers here : Difference between least squares and minimum norm solution (3 answers) Closed 4 years ago . Linear regression uses summation of least squares to find the best fit. Why? I fully understand that we do not want to use actual residuals, otherwise, positive and negative numbers may cancel out each other. Then, why don't we use absolute values? Sorry if this sounds like a duplicate question. I did see many explanations but did not see an easy-to-understand answer. For example, some said that squares made calculation easier. How come? Your insight is highly appreciated!","['machine-learning', 'statistics', 'least-squares', 'regression']"
3580114,Eigenvectors with many rational entries,"Suppose that $A$ is an invertible $3 \times 3$ matrix with integral entries and that $v$ is an eigenvector corresponding to an irrational eigenvalue.  Of course by scaling $v$ we may arrange that it has at least one rational entry.  But is it possible for $v$ to have two rational entries, and only one irrational one? (Feel free to share any higher-dimensional results, of course!)",['linear-algebra']
3580115,What is the area of the smaller right triangle?,"The two diagonal lines are parallel, and the area of the region between them is $42$ What is $A,$ the area of the smaller right triangle? So I named the missing base and height of the smaller right triangle x & y respectively and came up with the solution: $\dfrac{(x + 4)(y + 3)}{2} - \dfrac{xy}{2} = 42$ Solving the equation we get: $3x + 4y = 72$ I don't know what's next here so I just assumed that $x = 12, y = 9$ which satisfies the equation and resulting to $A = 54$ . My question is, am I missing something so that I can solve the equation?",['geometry']
3580160,Problem with a probability measure,"Suppose that $\Omega=\{w_{1},\dots,w_{n}\}$ and define a probability measure $\mathbb{P}$ with the condition that the probability of $w_{j+1}$ is the double of the probability of $w_{j}$ . Let $A_{k}=\{w_{1},\dots,w_{k}\}$ . Compute $\mathbb{P}(A_{k})$ . Could someone give me a hint?","['probability-theory', 'probability']"
3580201,Find limit of $\frac{n(nx_n-\frac{1}{3})}{\ln n}$ knowing that $x_{n+1}=x_n-3x_n^2$,Let $x_n$ a sequence with $\frac{1}{3}>x_1>0$ and $x_{n+1}=x_n-3x_n^2$ . Find the limit $$\lim_{n\to \infty} \frac{n(nx_n-\frac{1}{3})}{\ln n}.$$ I proved that $x_n$ is convergent to $0$ and that $\lim\limits_{n\to \infty} nx_n= \frac{1}{3}$ with Stolz-Cesaro theorem. $$\lim_{n\to \infty} \frac{n}{\frac{1}{x_n}}=\lim_{n\to \infty} \frac{1}{\frac{1}{x_{n+1}}-\frac{1}{x_n}}=\lim_{n\to \infty} \frac{x_{n+1}x_n}{x_n-x_{n+1}}=\lim_{n\to \infty}\frac{x_n(x_n-3x_n^2)}{3x_n^2}=\frac{1}{3}$$ I also know that $\lim\limits_{n\to \infty}\frac{n}{\ln n}=\infty$ . The limit is $\infty \cdot 0$ and I am stuck. Can I get a clue or a hint please?,"['limits', 'sequences-and-series']"
3580213,Is this the Cayley graph of the braid group on three strands?,"I have been attempting to draw the Cayley graph of the braid group $$ B_3 = \langle a, b \mid aba=bab \rangle$$ and I obtained something that almost seems too good to be true; here is a picture. This might require some explanation: The vertices of the graph in question are the little circles. Note that the intersections that do not involve circles are not vertices, they are non-planarity artifacts. Multiplying by the generators $a,b$ corresponds to moving to the top left, to the top right, respectively. Similarly, multiplying by their inverses $a^{-1}, b^{-1}$ corresponds to moving to the bottom right, bottom left, respectively. Of course, the picture does not contain the full graph, but is rather one step in an iteration that yields the full graph after countably many steps. Here is (a zoomed-in version of) one further step in the iteration. Question . Is the graph explained above the Cayley graph of the braid group $B_3$ on three strands? Ideas and strategies on how to proceed are also greatly appreciated.","['geometric-topology', 'abstract-algebra', 'geometric-group-theory', 'group-theory', 'braid-groups']"
3580226,Maximum interval for every initial condition,"Consider the IVP given by: $\frac{dx}{dt}=-\frac{x^3}{1-t},\; x(0)=x_{0}$ WITHOUT solving the equation, show that: a) For every $x_{0}$ , the maximal interval is [0,1) b) $\underset{t\uparrow 1} {\lim}\;x(t)$ exists and calculate it's value My attempt: I know that for item a I need to show that f is continuous on the interval $[0,1)$ , but do I need to show that it's locally lipschitz for every $x_{0}$ ?","['dynamical-systems', 'solution-verification', 'ordinary-differential-equations', 'real-analysis']"
3580253,Proof by induction of inadequacy of a propositional connective,"I have the following truth table of a newly defined logical operator and have to prove its functional incompleteness via structural induction. My idea is that that you cannot express the always true formula $\top$ in terms of this operator.
I just don't know how to go about the proof. Here is the truth table of the new 3-input Operator: $$\begin{array}{|c|c|c|c|} 
 X & Y & Z & <X,Y,Z> \\ \hline
0 & 0 & 0 & 0\\ \hline
0 & 0 & 1 & 0\\ \hline
0 & 1 & 0 & 0\\ \hline
0 & 1 & 1 & 1\\ \hline
1 & 0 & 0 & 1\\ \hline
1 & 0 & 1& 0 \\ \hline
1 & 1 & 0 & 0\\ \hline
1 & 1 & 1 & 0\\ \hline
\end{array}$$","['boolean-algebra', 'propositional-calculus', 'logic', 'discrete-mathematics', 'induction']"
3580277,Complex Analysis Book with Good Exercises?,"I have studied a bit of complex analysis in the past, but I realized that I couldn't really get into it because I didn't really see the motivation; I was spending a lot of time trying to understand proofs, and even though the theorems seemed pretty cool, I never really got to use them. Could you please recommend me some books with applications of Complex Analysis? I don't mean applications to science or engineering, I just mean applications of the theorems in first year Complex Analysis, aka a book with good, interesting problems, not necessarily a book with formal proofs of everything (though that's a bonus). Thank you very much.","['complex-analysis', 'book-recommendation', 'reference-request']"
3580298,Happy $\pi$-day! Is it true that $\sum_{p \;\text{prime} } \frac{1}{{\pi}^p} < \pi -\lfloor \pi \rfloor$?,"Today is a $\pi$ -day and I made this exercise for that purpose (and not only for that!): Let: $$\phi = \sum_{p \;\text{prime} } \frac{1}{{\pi}^p}$$ By applying only knowledge of calculus and, more generally (if needed), real analysis of functions of one variable, and without computational software, determine is it true that we have: $$\phi< \pi - \lfloor\pi\rfloor$$ Where $\lfloor\pi\rfloor=3$ is the floor function of $\pi$ . Is this possible to solve with, for example, some of the formulas for infinite product for $\pi$ or Taylor series for ${\sin}^{-1}$ , without any numerical estimates? Or, if estimates are needed, what is the worst one you need to apply to solve this?","['approximation', 'real-analysis', 'calculus', 'pi', 'sequences-and-series']"
3580325,Are invertible functions more or less common than non-invertible functions? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I was curious whether functions that have an inverse are more or less common than functions that don't. My intuition tells me there are more functions without an inverse.,['functions']
3580457,Insufficient argument in Conway's Proof of Krein Milman,"In the proof of Krein-Milman in A course in functional analysis by John B. Conway p.142. The following argument is used: $K$ is a compact convex set in a locally convex space $X$ and $U\subset K$ is a proper convex subset which is open with respect to the subspace topology inherited from $K$ . Then in the proof it is claimed that if $x\in U$ and $y\in \overline{U}\setminus U$ then the open line segment from $x$ to $y$ is contained in $U$ : that is $(1-t)x+ty\in U$ for $0< t <1$ . However this is not true for any situation. For instance if $K = [-1,1]\times [-1,1]$ and $U = (-1,1)\times (-1,1)\cup (-\frac{1}{2},\frac{1}{2})\times \{1\}$ then $y =(1,1)\in \overline{U}\setminus U$ and $x=(0,1)\in U$ however $(1-t)x+ty\notin U$ for $1/2\leq t<1$ . Can the property that $U$ is a maximal proper open subset of $K$ be used to get around this fact?","['locally-convex-spaces', 'convex-analysis', 'functional-analysis']"
3580553,Dieudonné module associated to the dual of a $p$-divisible group,"Let $k$ be a perfect field of characteristic $p>0$ , and consider $X=(X_m,i_m)$ a $p$ -divisible group of height $h$ over $\operatorname{Spec}(k)$ : it is an inductive system where $X_m$ is a finite group scheme over $k$ of order $p^{mh}$ , such that $X_m$ is identified via $i_m:X_m\rightarrow X_{m+1}$ with the $p^m$ -torsion of $X_{m+1}$ . The « classical » Dieudonné module of $X$ is defined as the inverse limit $\mathbb D(X):=\varprojlim\mathbb D(X_m)$ , where $\mathbb D(X_m)$ is the contravariant Dieudonné module of $X_m$ and the transition maps are induced by the $i_m$ . I want to understand $\mathbb D(^tX)$ , where $^tX$ is the Serre dual of $X$ . This is the $p$ -divisible group induced by Cartier duality applied to each $X_m$ , with $^tX_m\rightarrow\,^tX_{m+1}$ being dual to $p:X_{m+1}\rightarrow X_m$ . It would be nice if $\mathbb D(^tX)$ were related to $\mathbb D(X)$ under some sort of duality property. I know from Chai-Conrad-Oort's book - theorem 1.4.1.1 (5) - that $\mathbb D(^tX_m)\cong \operatorname{Hom}_{W}(\mathbb D(X_m),W[1/p]/W)$ where $W=W(k)$ is the ring of Witt vectors over $k$ . Now, $\operatorname{Hom}$ transforms the inverse limit into a direct limit, so that $$\mathbb D(^tX)=\varprojlim\mathbb D(^tX_m)=\varprojlim\operatorname{Hom}_{W}(\mathbb D(X_m),W[1/p]/W)=\operatorname{Hom}_W(\varinjlim \mathbb D(X_m),W[1/p]/W)$$ Unfortunately, it's the direct limit of the $\mathbb D(X_m)$ with transition maps induced by $p:X_{m+1}\rightarrow X_m$ which appears. Is there any way to relate this direct limit with $\mathbb D(X)$ ? Motivation: I have been thinking about the above discussion because I wish to understand why a polarization $\lambda:X\rightarrow\, ^tX$ should induce a (non-degenerate skew-symmetric) bilinear pairing $\mathbb D_{cov}(X)\times \mathbb D_{cov}(X)\rightarrow W$ , where $\mathbb D_{cov}(X):=\mathbb D(^tX)$ is the covariant Dieudonné module.","['limits-colimits', 'number-theory', 'algebraic-geometry', 'divisible-groups', 'arithmetic-geometry']"
3580600,Standardisation of multivariate normal distribution,"Knowing that random vector $$
\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu) \sim N(0, I)
$$ what is the distribution of random variable $$
(\textbf{Y}-\mu)^T\Sigma^{-1}(\textbf{Y}-\mu)
$$ where random vector $\textbf{Y}$ has a normal distribution with positive semidefinite covariance matrix $\Sigma$ and expected value vector $\mu$ ? My attempt was to $$
(\textbf{Y}-\mu)^T\Sigma^{-1}(\textbf{Y}-\mu) = (\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu))^T(\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu)) = \text{?}
$$ I know that both brackets are $N(0, I)$ but I don't know how to proceed.","['statistics', 'probability-distributions', 'probability']"
3580659,Applications of the exponential law $Z^{X \times Y} \approx (Z^Y)^X$,"Let $B^A$ denote the space of continuous maps $A \to B$ with the compact-open topology. I shall not be specific in the interpretation of compact (i.e. whether it includes Hausdorff or not). You can take your favorite interpretation. It is well-known that for locally compact $Y$ , there is a canonical bijection $$E : Z^{X \times Y} \to (Z^Y)^X .$$ This has a plethora of applications in topology. So let $Y$ be locally compact. Then it is known that the bijection $E$ is even a homeomorphism under suitable additional assumptions (for example $X, Y$ Hausdorff). This is of course an interesting theorem, but does the fact that $E$ is a homeomorphism have any applications in general or algebraic topology? I am not aware of any.","['general-topology', 'algebraic-topology']"
3580671,Do finite unions preserve cardinality?,"Please forgive me if this is a very basic question. I have never studied cardinals, I just need this result for a problem in Linear Algebra. My question is: if $V_1, V_2, ..., V_n$ are infinite sets of the same cardinality, does $V_1 \cup V_2 \cup \cdots \cup V_n$ still have that same cardinality? I can imagine a proof if the sets are countable: we can list the $V_i's$ in $n$ rows, and construct a ""snake"". However, I don't see how to generalize this to uncountable sets.","['elementary-set-theory', 'cardinals']"
3580685,Construct a random variable and probability space for a given distribution,"Given a set of real valued points $C:=\{x_i\colon\ i\in I\}$ where $I$ is a countable index set, I want to  construct a probability space $(\Omega, \mathcal{A}, P)$ and a random variable $X\colon \Omega\rightarrow C$ such that $$P[X=x_i]=p_i$$ with $p_i\ge 0 ,\forall i\in I$ and $\sum_{i\in I} p_i=1$ . Here are my solutions: 1: Set $(\Omega, \mathcal{A}, P)=(C,2^C, \mu)$ where $\mu(A):=\sum_{x_i\in A}p_i$ for a $A\in 2^C$ . Then just pick $X=id$ and since the identity is always measurable we are done. 2: Set $(\Omega,\mathcal{A},P)= (N|_I, \mathcal{B}(\mathbb{N}), \mu)$ with $\mu(A):=\sum_{i\in I} p_i\delta_{\{i\}}$ for $A\in\mathcal{B}(\mathbb{N)}$ . I then define $X(i)=x_i$ . Are these examples correct? Is there a more systematic way to solve this problem (also for the continuous case)? In my book I saw a theorem, that for every distribution function $F$ there is always a random variable and a probability space, such that $F_X=F$ , meaning there is always a random variable which has the given distribution. Now the correspondence principle states that I can find a unique probability measure for every distribution function and vice versa. Do these two theorems combined give me the assurance, that for every probability distribution $P$ I can always find a random variable $X$ such that $P=P_X$ ?","['measure-theory', 'probability-distributions', 'probability-theory']"
3580733,How do I solve this limit without l'Hopital?,"I tried the substitution $t=x-(\pi/3)$ but it doesn't help at all. I have also tried using $\sin(\pi/3)=\sqrt{3}/2$ but couldn't do anything useful then. I tried to factor the denominator and numerator, but it didn't help either. I want a solution without l'Hopital's rule. $$\lim_{x\to \pi/3} \left[\dfrac{\sin^2(x) - \sin^2\left(\dfrac{\pi}{3}\right)}{x^2 -\left(\dfrac{\pi}{3}\right)^2}\right]$$","['limits-without-lhopital', 'analysis', 'functions', 'limits', 'trigonometry']"
3580806,Convolution algebra as a bialgebra?,"Context Let $(A, \mu, \eta, \Delta, \epsilon)$ be a bialgebra over a field $k$ . Consider the vector space $\mathrm{End}(A)$ over $k$ . Define the convolution product $$*: \mathrm{End}(A)\otimes \mathrm{End}(A) \rightarrow \mathrm{End}(A); \qquad f \otimes g \mapsto \mu \circ (f \otimes g)\circ \Delta.$$ Define the unit map $$\overline \eta: k \rightarrow \mathrm{End}(A); \qquad 1 \mapsto  \eta \circ \epsilon.$$ Then $(\mathrm{End}(A), *, \overline \eta)$ becomes an associative, unital algebra. Questions Can $(\mathrm{End}(A), *, \overline \eta)$ be made into a bialgebra? Does it become a Hopf algebra that way? Is there a canonical way?","['abstract-algebra', 'convolution', 'hopf-algebras']"
3580819,Why does an orthogonal matrix have to be square?,"I understand intuitively why this has to be the case (otherwise you could lose a dimension / gain a dimension which changes the length), but what is the formal proof that an orthogonal matrix has to be square?","['orthogonality', 'orthogonal-matrices', 'linear-algebra']"
3580838,Evaluate alternating double series,Does anybody have an idea on how to evaluate the following double series? $$\sum_{n=1}^\infty \sum_{m=1}^\infty\frac{(-1)^{n+m}}{nm(n^2+m^2)}$$ Clearly this is a convergent series but I think it might be hard to find a closed expression for this.,"['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
3580865,How can I prove $\frac{\pi}{4}=\arctan\frac{1}{2}+\arctan\frac{1}{3}$ by using the product $(2+i)(3+i)$?,"How can I prove that $$\frac{\pi}{4}=\arctan\frac{1}{2}+\arctan\frac{1}{3}$$ by using the product $(2+i)(3+i)$ ? What I noticed is that for $2+i$ in polar form, $\arctan\theta_1=\frac{1}{2}$ and for $3+i$ in polar form, $\arctan\theta_2=\frac{1}{3}$ . However, I don't know how to proceed from here.","['trigonometry', 'complex-numbers']"
3580902,Completing the square in matrix form,"I am having trouble understanding how to complete the square in matrix form. I can't find any source online for a clear, final equation for that.
However, I would also like to grasp the intuition behind it. 
Thanks. To give an example: $$ x'Mx-2b'x=(x−M^{−1}b)′M(x−M^{−1}b)−b′M^{−1}b $$ How do I get that solution?","['matrices', 'linear-algebra']"
3580926,What is the inverse of the *divergence* operator?,The inverse of derivation is integral. But what is the inverse of the divergence operator ? Doest it exist ?,"['integration', 'derivatives', 'mathematical-physics']"
3580999,Distribution of sample variance of Bernoulli variables,"I am facing the following problem, given $X_1 ... X_n$ a random sample of $Bernoulli(\theta)$ variables find the distribution of the sample variance $S^2 = \frac{1}{n} \sum_i(\bar{X} - X_i)^2$ . I have demonstrated that $S^2 = \bar{X} (1 - \bar{X})$ and i know $\bar{nX}$ has distribution $Binomial (n, \theta)$ but I have not been able to deduce the distribution of $S^2$ .","['statistics', 'probability-distributions', 'binomial-distribution']"
3581031,What formal mathematical terms are used to talk about different scales of infinity?,"(Sorry, it's a dummy question but I don't have enough math vocabulary!) Example: the set of all odd integers is infinite in size, but still it's ""smaller"" than the set of all integers, yes?  When one has relationships between infinite sets like that, what is this called by mathemeticians? This is going into a children's story, so if you can dumb it down for me then I can dumb it down for the children.  Hopefully.","['elementary-set-theory', 'infinity']"
3581104,"Constructing the center of a circle, straightedge only. Variants on the Poncelet-Steiner Theorem","The Wikipedia Poncelet-Steiner Theorem entry says: Any Euclidean construction possible with straightedge and compass can be done with straightedge alone, provided that at least one circle with its center identified already exists on the plane. I already know this to be true as I've worked the constructions and seen the proof. What interests me and what this question is about are some of the other claims made in the article - variants on the Poncelet-Steiner theorem. As it turns out the one circle with its center identified isn't strictly necessary. Alternative criteria exist, including: Having two concentric circles without a center. Having two distinct intersecting circles without their centers. I have also worked these constructions and am satisfied. They are fairly straightforward.  Proofs attributed to Detlef Cauer.  They culminate in the construction of the center of the circle, thus reducing the scenario to the original Poncelet-Steiner hypothesis. No issue here so far. But still other claims are made, between the Wikipedia, Wolfram's MathWorld , and other sources.  Namely, Two non-intersecting circles (without centers) but with an arbitrary point on the centerline (collinear with the centers). Three non-intersecting circles. I've also seen reference to two congruent circles with an arbitrary point on the meridian between them being sufficient. (thats a point on the perpendicular bisector of the segment connecting centers) All three of these variants supposedly end in the construction of a circle's center point. Another claim is that Any arc of the circle with the center identified is enough (equivalent to the Poncelet-Steiner). Francesco Severi apparently gets credit. But none of claims 3-6 have adequate citation.  I've followed these citations to their inevitable dead-ends and I'm still left without proof or demonstration. For all of them. I've tracked every source down, and the sources that they reference as well, right down to the bitter end, even accessing academic databases and checking out books at the library. I even bought one $100 book that seemed promising.  All they do is cite one another and vaguely refer to ""his work"", sometimes even quoting one another nearly verbatim.  But never a proof. Never a construction. One site I came across claims to provide a construction for one of these claims and to their credit they do show a lot, but it doesnt actually show the complete construction. In fact they use the phrases ""you get the idea"" and ""a few hundred more lines to draw"", leaving it to my imagination to fill in the gaps. Thats not even counting the fact the text is poorly worded and the images are improperly labeled. And yes, I've tried proving them myself but unfortunately my intuition with geometry isn't that great. I also have no delusion about how complex or time-consuming these constructions might be. Does anyone know how to prove variants 3-6? Or provide a citation to actual literature that explicitly proves or demonstrates these? Because, as it stands, it would appear that these are claims made out of thin air with no real backing; assertions that have skimmed by without peer review. And, if so, that needs to be corrected. I have faith that these claims are true but I desperately want to learn them. The best of the best geometers I know cant tell me where to begin. After a few years of searching I finally managed to put in the proper keyword combination to find something that lead me to something else.  A book titled "" Über die Konstruktion des Mittelpunktes eines Kreises mit dem Lineal allein "", by Detlef Cauer, supposedly has the proof for three non-intersecting circles case (bullet point 4).  Unfortunately the book is written in German and its hidden behind your standard academia (anti-education, anti-peer review, knowledge hording) paywall. A translation of this texts proof(s) would be great, but that covers only one of the cases, leaving three still outstanding.","['euclidean-geometry', 'geometry', 'geometric-construction']"
3581134,Is the number of primes equal to the number of integers?,"I understand countable infinities and that any subset of the integers should be an equivalent countable infinity, but the primes seem so odd (sorry, weird!), and I haven't found anything directly addressing this, so I thought the answer might include something interesting. Or is it just that we know there is no largest prime, and that's the end of it? It seems to me that the idea that there is also no largest gap between primes might affect this.","['elementary-set-theory', 'prime-numbers']"
3581188,any real number between $0$ and $1$ is expressible as an (infinite) sum of particular fractions,"If $0 < x \le 1$ then there is one and only one sequence of positive integers $(k_v)$ , with $$1 < k_1 \le k_2\le k_3\le\cdots,$$ for which $$x={1\over k_1}+{1\over k_1k_2}+\cdots+{1\over k_1k_2\cdots k_n}+\cdots$$ $x$ is rational if and only if the $k_v$ are all equal after some index $v_0$ . As far as the last statement is concerned, the if part is easy. I don't know how to build such a sequence. If I knew how to generate the $k_v$ I could probably show also the only if part. Hints? I found that for $x \ne 1$ , $\lfloor{xk_1}\rfloor = 1$ and also $\lfloor{k_2(xk_1-1)\rfloor} = 1$ and so on, so if I can determine $k_1$ from the first equation, I can determine also $k_2$ from the second, provided $(xk_1-1)$ kind of satisfy the same conditions as $x$ . I don't know if this pattern is correct however, for I need to establish uniqueness. Also it doesn't seem so obvious at first glance how to prove that such a sequence gives $x$ . Obviously I can't determine $k_1$ from just the first equation, since for example, if $x = 1/2$ then both $k_1 = 2$ and $k_1 = 3$ can be chosen. Also for $x = 1$ one has $x = {1\over2} + {1\over2\cdot2}+\cdots$ and that's why $\lfloor k_1x\rfloor \ne 1$ Uniqueness is easy as well to prove. For let there exist two such sequences $a_n$ and $b_n$ , and let $m \ge 1$ be the first integer such that w.l.o.g. $b_m > a_m$ . Then $0 = ({1\over a_m}+{1\over a_ma_{m+1}}+\cdots)-({1\over b_m}+{1\over b_mb_{m+1}}+\cdots)$ . We see that the first sum is strictly greater than ${1\over a_m}$ , whereas the second sum is $\le {1\over a_m}$ , because from $b_m \ge a_m+1$ we obtain that the $n$ -th term for $n \ge 1$ is $\le \left({1\over 1+a_m}\right)^n$ . Thus the difference cannot be $0$ .","['sequences-and-series', 'real-analysis']"
3581229,The closed form for $\sum_{n=1}^\infty \frac{H_{n/2}}{n^2}x^n$,"Is there a closed form for $$\sum_{n=1}^\infty \frac{H_{n/2}}{n^2}x^n\ ?$$ Where $H_{n/2}=\int_0^1\frac{1-x^{n/2}}{1-x}\ dx$ is the harmonic number. I managed to find the closed form but had hard time finding the constant. My trial I was able to prove $$\sum_{n=1}^\infty \frac{H_{n/2}}{n}x^n=\operatorname{Li}_2\left(\frac{1}{1-x}\right)+\operatorname{Li}_2\left(\frac{1}{1+x}\right)-\operatorname{Li}_2\left(\frac{1-x}{1+x}\right)$$ $$+\ln(1-x)\ln(1+x)+\ln^2(1-x)-2\ln(x)\ln(1-x)-i\pi\ln(1-x)-\zeta(2)=f(x)$$ If we divide both sides by $x$ then integrate we get $$\sum_{n=1}^\infty \frac{H_{n/2}}{n^2}x^n=\int\frac{f(x)}{x}\ dx$$ Wolfram gave and after tedious manual simplifications I found $$\int\frac{f(x)}{x}\ dx=\operatorname{Li}_3\left(\frac{1+x}{1-x}\right)-\operatorname{Li}_3\left(\frac{1+x}{x-1}\right)+\operatorname{Li}_3\left(\frac{1+x}{2x}\right)-\operatorname{Li}_3\left(\frac{1+x}{x}\right)-\operatorname{Li}_3\left(\frac{1+x}{2}\right)$$ $$-\operatorname{Li}_3(1+x)-2\operatorname{Li}_3(1-x)+\operatorname{Li}_3(x)$$ $$+\ln\left(\frac{1+x}{1-x}\right)\left(\operatorname{Li}_2\left(\frac{1+x}{x-1}\right)-\operatorname{Li}_2\left(\frac{1+x}{1-x}\right)\right)$$ $$-\ln\left(\frac{1+x}{2x}\right)\left(\operatorname{Li}_2\left(\frac{1+x}{2x}\right)-\operatorname{Li}_2\left(\frac{1+x}{x}\right)\right)$$ $$+\ln(x)\left(\operatorname{Li}_2\left(\frac{1}{1-x}\right)+\operatorname{Li}_2\left(\frac{1}{1+x}\right)-\operatorname{Li}_2\left(\frac{1-x}{1+x}\right)+2\operatorname{Li}_2(-x)-\operatorname{Li}_2(x)\right)$$ $$+\ln\left(\frac{1+x}{2}\right)\operatorname{Li}_2\left(\frac{1+x}{2}\right)+\ln(1+x)\operatorname{Li}_2(1+x)+\ln(2x)\operatorname{Li}_2(x)-2\ln(x)\operatorname{Li}_2(-x)$$ $$-\ln(x-1)\operatorname{Li}_2(1-x)+3\ln(1-x)\operatorname{Li}_2(1-x)+\ln2[\operatorname{Li}_2(1-x)+\operatorname{Li}_2(-x)]$$ $$+\ln(x)\ln^2(1-x)-\ln^2(x)\ln(1+x)-2\ln^2(x)\ln(1-x)+\ln^2(x)\ln(1+x)$$ $$+2\ln(x)\ln(1-x)\ln(1+x)+\frac12\ln2\ln^2(x)+\ln^22\ln(x)$$ $$+\frac{i\pi}{2}\left[\ln^2(1+x)+\ln^2\left(\frac{1+x}{1-x}\right)-4\ln(1-x)\ln(1+x)+2\operatorname{Li}_2(x)\right]-\zeta(2)\ln(x)+\color{red}{C}$$ I hope the closed form has no mistake or typo. I set $x=0,1$ to find the constant but failed, any idea? . Thank you","['integration', 'harmonic-numbers', 'polylogarithm', 'closed-form', 'sequences-and-series']"
3581330,How do you prove that the determinant of a 3 by 3 matrix with entries of either 1 and -1 (assume linearly independent rows) will always be 4 or -4?,"Assume that A is a $3\times3$ matrix, where all entries are either $1$ or $-1$ and the rows are linearly independent. Why is it the case that the determinant will always be $4$ or $-4$ ?","['matrices', 'determinant', 'linear-algebra']"
3581355,Evaulate $\lim_{n \to \infty} \int_0^\infty ne^{-nx} \sin(1/x)dx$,"Now, I know that the question was answered here: $\int_0^\infty ne^{-nx}\sin\left(\frac1{x}\right)\;dx\to ?$ as $n\to\infty$ But I'm looking for more of a measure theoretical approach, so if someone can point me in the right direction, I would be grateful. (i.e. use of Dominated Convergence Theorem or Monotone Convergence Theorem) My rough idea has been the following: We can't use MCT because the functions are not pointwise increasing. 
We can't use DCT since there there is no function to bound $ne^{-nx} sin(1/x)$ . But, it seems that on $[\ln 2, \infty)$ , $e^{-x} \geq ne^{-nx}$ , and on $[\ln (\frac{n+1}{n}, \ln \frac{n}{n-1}]$ , $ne^{-nx} \geq me^{-mx}$ for all $n, m \in \mathbb{N}$ (I don't have proof of this, and it seems hard to prove). So we can use DCT on integral restricted such intervals. That is, we can use DCT on the integral $$\int_{\mathbb{R}} ne^{-nx} \sin(\frac{1}{x}) \chi_{[\ln(n+1/n), \ln (n/n-1)]}dx$$ And on these intervals, the integrals are all 0. Since these intervals partitions $[0, \infty)$ , it follows our integral is 0. I don't know if the idea is correct, and even if it was, it wouldn't be an elegant solution. So I'm hoping someone could point me in the right direction for a clean solution. Thanks! EDIT: If we let $u = nx$ , we get the integral $$\int^\infty_0 e^{-u} \sin(\frac{n}{u}) du$$ . We could apply DCT to this to get 0? Another EDIT: But $\sin(\frac{n}{u})$ is not convergent, so we cannot apply DCT.","['integration', 'measure-theory', 'lebesgue-integral']"
3581401,Study of an infinite product,"During some research, I obtained the following convergent product $$ P_a(x) := \prod_{j = 1}^{\infty} \, \cos\left(\frac{x}{j^{a}}\right) \quad (x \in \mathbb{R}, a > 1).$$ Considering how I got it, I know it's convergent and continuous at $0$ (for any fixed $a$ ), but if I look at $P_a$ now, it doesn't seem so obvious for me. Try :
I showed that $P_a \in L^1(\mathbb{R})$ , i.e. it is absolutely integrable on $\mathbb{R}$ . Indeed, by using the linearization of the cosine function and the inequalities $\ln(1-y)\leqslant -y$ (for any $y<1$ ) and $1-\cos\,z \geqslant z^2/2$ (for any real $z$ ), we obtain \begin{eqnarray*}
P_a(x)^2  &=& \prod_{j = 1}^{\infty} \left(1-\frac{1-\cos(x\,j^{-a})}{2}\right) \leqslant \prod_{j > |x|^{1/a}} \left(1-\frac{1-\cos(x\,j^{-a})}{2}\right) \leqslant  \exp\left(-C |x|^{1/a} \right),
\end{eqnarray*} for some absolute constant $C>0$ . However, I have not been able to use this upper bound to prove continuity at $0$ (via uniform convergence for example, if we can). Question : I wanted to know how to study $P_a$ (e.g. its convergence and continuity at $0$ ), if you think it has an other form ""without product"" (or other nice properties) and finally if anyone has already seen this type of product (in some references/articles), please. Thank you in advance.","['analysis', 'reference-request', 'real-analysis', 'continuity', 'infinite-product']"
3581497,"Counting Problem: A group of 30 people consists of 15 women and 15 men, How many ways to:","Hi I am really having trouble trying to work out: A group of 30 people consists of 15 women and 15 men, How many ways to: form 10 pairs from the group? divide the group into two groups (group 1 and group 2) of equal size? divide the group into 2 equal groups, where each group in its own has as many men as women in it? divide the groups into two groups of equal size such that group 1 contains at least 4 men? divide the group into two groups, each having size at least one? My answers: say $p_1, p_2,...,p_{30} \in$ group of 30 people 1)Not sure at all about this one, but I know that it is not ${30\choose 2}*{28\choose 2}*…*{10\choose 2}$ as there will be double counting. 2) ${30 \choose 15}$ Reasoning: Form groups of size 15. thus if group1 is $p_1,p_2,...,p_{15}$ then group2 would be $p_{16},p_{17},...,p_{30}$ . Thus effectively dividing the group into 2 groups of equal size. I believe that each group is NOT arbitrary? so if another case: if group1 is $p_{16},p_{17},...,p_{30}$ then group2 would be $p_1,p_2,...,p_{15}$ this what we want and not double counting. Is this what they are asking? 3)Not to sure about this one, as we can make 15 packs of 1 man and 1 woman, but 15/2 does not make sense here, thus I suppose the best we can do is have 2 groups with 7 men and 7 women: ${15 \choose 7} * {15\choose 7}$ but this is not fully dividing the group. Reasoning: pick 7 men from 15 and 7 women form 15. $m_1,m_2,...,m_7,w_1,w_2,...,w_7$ . Are the groups arbitrary? and thus answer is: ${15 \choose 7} * {15\choose 7}/2$ 4) ${30\choose 15} - {18\choose 15}$ Reasoning: get all the ways to divide the group in half, then remove all the cases where the is not at least 4 men in group 5)if arbitrary groups: ${30\choose 1}+{30\choose 2}+...+{30\choose 15}$ if not arbitrary groups: ${30\choose 1}+{30\choose 2}+...+{30\choose 29}$ Reasoning: add the number of ways to form a group of size 1, to the number of ways to form a group of size 2, to.... I only do to ${30\choose 15}$ if they are asking for arbitrary groups or there would be double counting, This is all the information that they give regarding the questions, and I am so lost. like for question 3, what determines the group size, if they want 15: 15, then it not possible. I would greatly appreciate any help that you can offer to help me to understand how to answer these questions","['combinatorics', 'discrete-mathematics']"
3581498,"How far (for which $p$) can we generalize $\int x^p \mathrm{d}x=\frac{x^{p+1}}{p+1} + C,p\neq-1 $?","Referring to trivial form, sometimes called Cavalieri's formula: $$
  \int x^p \mathrm{d}x=\frac{x^{p+1}}{p+1} + C, \qquad p\neq-1
$$ I was wondering what other restrictions on $p$ exist besides $p \neq -1$ . Initially I thought $p \in \mathbb{Z}\backslash\{-1\}$ , but the formula is also used to obtain forms for radicals and root functions. Then I thought perhaps $p \in \mathbb{R}\backslash\{-1\}$ , but then I doubted: would it work on complex numbers? I carried out some integrations with $p\in \mathbb{C}\backslash\{-1\}$ , and the formula seems to work fine. I could not find a proof with any restrictions on $p$ . Any ideas on how general can $p$ become without breaking the equality? Thank you for the insight.","['integration', 'complex-analysis', 'rational-functions', 'clifford-algebras']"
3581582,Are Disjoint Open Subsets Contained in Disjoint Open Sets in a General Topological Space?,"This was a question that I had while revising metric spaces. For a metric space $X$ , let $A\subset X$ . We know that if $G, H$ are disjoint open sets in $A$ , $\exists$ disjoint open sets $U, V \subset X$ such that $G = U \cap A$ , $H = V \cap A$ . What I was wondering is that if we can generalize it to general topological spaces, that is, for a topological space $X$ and $A$ having subspace topology. Also, if this does not hold for a general topological space, what restrictions (like Hausdorff-ness) do we need to place for this to hold?","['general-topology', 'metric-spaces']"
3581608,What is the point of Hecke $L$-series?,"Let $K$ be a number field and $\mathcal{O}_K$ its ring of integers. For an integral ideal $\mathfrak{m} \subset \mathcal{O}_K$ we let $J^{\mathfrak{m}}$ be the group of fractional ideals coprime to $\mathfrak{m}$ . A Hecke character $(\textrm{mod}\ \mathfrak{m})$ is a group character $\chi: J^{\mathfrak{m}} \to S^1$ , satisfying some conditions. A generalised Dirichlet character $\chi: J^{\mathfrak{m}}/P^{\mathfrak{m}} \to S^1$ is any group character of the ray class group $J^{\mathfrak{m}}/P^{\mathfrak{m}}$ ; $P^{\mathfrak{m}}$ being the subgroup of principal ideals congruent to $1\ (\textrm{mod}\ \mathfrak{m})$ . In his Class Field Theory , J. Neukirch introduces only generalised Dirichlet $L$ -series, defined in terms of generalised Dirichlet characters. He uses these to prove: 1) The generalised Dirichlet density theorem. 2) That Artin $L$ -series of Abelian extensions are in fact generalised Dirichlet $L$ -series. Then in his Algebraic Number Theory , he chooses instead to work with Hecke $L$ -series, as opposed to generalised Dirichlet $L$ -series. But he does not seem to derive any new results using this more general definition. So my question is: What is the point of considering the more general Hecke $L$ -series, as opposed to just restricting one's attention to generalised Dirichlet $L$ -series?","['algebraic-number-theory', 'number-theory', 'ring-theory', 'abstract-algebra', 'group-theory']"
3581671,Examples of groups which are virtually isomorphic but not commensurable,"Let $G_1, G_2$ be groups. We say $G_1$ and $G_2$ are commensurable if there exist finite index subgroups $H_1 \leq G_1$ , $H_2 \leq G_2$ such that $H_1 \simeq H_2$ . We say $G_1$ and $G_2$ are virtually isomorphic if there exist finite index subgroups $H_1 \leq G_1$ , $H_2 \leq G_2$ , and finite normal subgroups $N_1\trianglelefteq H_1$ , $N_2 \trianglelefteq H_2$ such that $H_1 / N_1 \simeq H_2 / N_2$ . It is easy to see that commensurability implies virtual isomorphism, we just take the normal subgroups to be trivial. How can one go about finding a counterexample to the converse?","['geometric-group-theory', 'group-theory', 'infinite-groups']"
3581695,Evaluate $\sum_{r=1}^{\infty} \frac{1 \cdot 3 \cdot \ldots (2r-1)}{r!}\left(\frac{2}{5} \right)^{r}$,"Evaluate $$\sum_{r=1}^{\infty} \frac{1 \cdot 3  \cdots (2r-1)}{r!}\left(\frac{2}{5} \right)^{r}$$ Let $$y=x + \frac{1 \cdot 3 \cdot}{2!} x^2 + \frac{1 \cdot 3 \cdot 5}{3!} x^3+\ldots$$ be the given expression.(replacing $2/5$ with $x$ ) After some manipulations, $$y+1=(1-2x)\frac{dy}{dx}$$ Integrating and substituting $x=\dfrac{2}{5}$ , we get $y=\sqrt{5}-1$ . Is there any other way to solve this question?","['integration', 'summation', 'taylor-expansion', 'sequences-and-series', 'fubini-tonelli-theorems']"
3581737,Numbers from 1 to 10 put in a circle,"Write the numbers from $1$ to $10$ in a circle. Consider all the groups of three consecutive numbers and their sums. Show that we can find a group with sum at least $18$ . Approach 1 ( not usefull ):
The arithmetic mean of all sums of the groups is $\frac{3(1+2+3+\dots+10)}{10} = \frac{165}{10} = 16.5$ so, at least one group has sum $17$ . But that doesn't help. Approach 2:
Suppose that there exist a configuration in which all groups have sums less that $18$ . Therefore, $10$ and $9$ , $10$ and $8$ , $8$ and $9$ , $10$ and $7$ can not be in the same group. From the first three observations between $8$ , $9$ and $10$ there are group of numbers of size, two, two and three. Here I am stuck. I suppose looking at where 7 can be placed and with lots of case work you can get to a contradiction. Is this a good approach ? Do you have a better alternative ? Also feel free to change the tags, I do not know which tags are appropriate","['pigeonhole-principle', 'combinatorics']"
3581789,Estimate $|f’(0)|$ by $Re(f(z))$,"If $f$ is holomorphic in unit disk $B$ , $f(0)=0$ , and $|\operatorname{Re} f(z) |\leq A$ for $A>0$ , prove that $|f’(0)|\leq 4A/\pi$ . Define $g(z)=\frac{f(z)}{f(z)-2A}$ , then I can use Schwarz lemma to prove $|f’(0)|\leq 2A$ , but it seems to be invalid for the sharper constant. Any help will be appreciated.",['complex-analysis']
3581803,What are the extremum points on this graph?,"The graph in question is here. Assuming the inspected interval is $[0, 4]$ : 1- The point $(0, 4)$ does not qualify to be an absolute maximum, but what about say $(0.000\cdots001, 3.9999\cdots)$ ? Why can't we say that the interval $[0, 4]$ has an absolute maximum even though there are relatively bigger values between $x = 0$ and $x = \frac13$ ? 2- Can we say that the point $(0, 1)$ is an absolute minimum for this interval? 3- The point $(1, 3)$ is a local maximum, right? 4- Lastly, what about the point $(4, 3)$ ? Can we say it's a local maximum too? My thoughts are:
Questions 2 and 3 can most likely be answered with ""yes"". I've seen many conflicting answers regarding question 4, so I'm not sure anymore... And question 1 is the one on which I couldn't find any relatable answers. The endpoint x = 0 where the function would normally have a maximum is not continuous. Therefore, appointing the ""next closest"" maximum value $(3.999\cdots)$ seemed logical enough, but apparently it doesn't work that way. But why is that? My guess would be that we can't define it as an exact point, therefore we dismiss it..? I would love some clarification on this.","['maxima-minima', 'functions']"
3581810,"How is the Feynman path integral a sum over paths, and not a product over paths","I am unable to understand how the Feynman path integral is a sum of paths and not a product of paths. I understand a sum of paths as follows: $$
Z=\exp ( i S_1 )+ \exp (i S_2)+...
$$ I do not see how such a sum relates to the Feynman path integral: $$
Z=\int_{-\infty}^\infty \exp(iS(x_1))dx_1\int_{-\infty}^\infty \exp(iS(x_2))dx_2\int_{-\infty}^\infty \exp(iS(x_3))dx_3...
$$ which appears as a product. Is the appellation ""sum over paths/sum over histories"" incorrect?","['physics', 'functional-calculus', 'functional-analysis', 'mathematical-physics']"
3581818,The Veronese Embeddings (Exercise I.2.12 in Hartshorne),"I think I've finally managed to solve the following exercise from Hartshorne but I would really appreciate someone checking it out for me (specifically, I'm looking for someone to say ""looks good"" or ""no it's wrong/is incomplete and here's why...""). Many thanks! Let $\rho:\mathbb{P}^n\to \mathbb{P}^N$ be the Veronese embedding (where $N=\binom{n+d}{d}-1$ ). Let $S$ be the set of multi-indices: $$\{(i_0,i_1,\ldots,i_n) \, : \, \text{each } i_j \in \{0,1,\ldots,d\} \text{ and } i_0+i_1+\ldots+i_n=d\}.$$ Let $\theta:k\big[\{y_I \, : \, I \in S\}\big] \to k[x_0,\ldots,x_n]$ be the $k$ -algebra homomorphism such that $$\theta(y_I)=x_0^{i_0}x_1^{i_1}\ldots x_n^{i_n} \; \; \; \; \forall I \in S.$$ I want to show that $\mathrm{im}\,\rho=Z(\ker\theta)$ and that $\rho$ is a homeomorphism onto its image. My proposed solution follows... 1) I show that $\rho$ maps $\mathbb{P}^n$ injectively into $Z(\ker\theta).$ For any $(a_0:a_1:\ldots:a_n) \in \mathbb{P}^n$ and any $f \in \ker(\theta),$ we have $$f(\rho(a_0:a_1:\ldots:a_n))=\theta(f)(a_0,a_1,\ldots,a_n)=0.$$ Moreover, if $\rho(a)=\rho(b)$ for some $a,b \in \mathbb{P}^n$ with $a_i\neq 0,$ then $$a=(a_0a_i^{d-1}:\ldots:a_i^d:\ldots:a_na_i^{d-1})=(b_0b_i^{d-1}:\ldots:b_i^d:\ldots:b_nb_i^{d-1})=b.$$ Thus $\rho$ realises $\mathbb{P}^n$ as a subset of $Z(\ker\theta).$ 2) I construct local inverses to $\rho.$ Observe that, for each $(i_0,i_1,\ldots,i_n) \in S,$ we have the relation: $$d\cdot(i_0,i_1,\ldots,i_n)=i_0\cdot(d,0,\ldots,0)+\ldots+i_n\cdot(0,\ldots,0,d).$$ It follows from this that the $n+1$ affine-open patches $U_{(d,0,\ldots,0)},\ldots,U_{(0,\ldots,0,d)}$ cover $Z(\ker\theta).$ Define a map $\sigma_0:U_{(d,0,\ldots,0)}\cap Z(\ker\theta)\longrightarrow U_0\subset \mathbb{P}^n$ as follows $$\sigma_0(b)=(b_{(d,0,\ldots,0)}:b_{(d-1,1,0,\ldots,0)}:\ldots:b_{(d-1,0,\ldots,0,1)}).$$ For each $(i_0,i_1,\ldots,i_n) \in S,$ we have the relation: \begin{align*}i_0\cdot(d,0,\ldots,0)+i_1\cdot(d-1,1,0,\ldots,0)+\ldots&+i_n\cdot(d-1,0,\ldots,0,1)\\[1em]
&=(i_0,i_1,\ldots,i_n)+(d-1)\cdot(d,0,\ldots,0).\end{align*} It follows from this that $(\rho\circ\sigma_0)(b)=b$ for all $b \in U_{(d,0,\ldots,0)}\cap Z(\ker\theta).$ Furthermore, it is clear that $(\sigma_0\circ\rho)(a)=a$ for all $a \in U_0,$ and so $\sigma_0$ and $\rho|_{U_0}$ are mutually inverse bijections. In a similar fashion, for each $i=1,\ldots,n,$ we construct a map $\sigma_i:U_{(0,\ldots,0,d,0,\ldots,0)}\cap Z(\ker\theta) \longrightarrow U_j$ inverse to $\rho|_{U_i}.$ 3) I show that the $\sigma_i$ can be glued together to form a global inverse for $\rho.$ If $b \in \mathrm{dom}(\sigma_i)\cap\mathrm{dom}(\sigma_j)$ for $i\neq j,$ then $\rho(\sigma_i(b))=b=\rho(\sigma_j(b))$ and so $\sigma_i(b)=\sigma_j(b)$ since $\rho$ is injective by (1) . Therefore the $\sigma_i$ agree on all overlaps and we patch them together to get $\sigma:Z(\ker\theta) \longrightarrow \mathbb{P}^n,$ a global inverse to $\rho.$ 4) I explain why $\rho$ is a homeomorphism onto its image. Since both $\rho$ and $\sigma$ are defined (locally, in $\sigma$ 's case) by homogeneous polynomials, they are both continuous. It thus follows that $\rho:\mathbb{P}^n \to Z(\ker\theta)$ is a homeomorphism.","['algebraic-geometry', 'solution-verification']"
3581854,‎prove that the sequence ‎$‎\{F(n)\}‎$ ‎converges.‎,"‎‎‎‎Let ‎‎ $‎g:‎\mathbb{R^+}‎‎‎\rightarrow‎‎\mathbb{R^+}‎$ ‎be a function such that $\log g(x)‎$ ‎is ‎concave, and‎ ‎ $‎‎‎‎\displaystyle{\lim_{x\to\infty}}‎\frac{g(x+w)}{g(x)} = 1‎$ ‎‎‎‎‎‎‎‎‎for each ‎ $‎w>0‎$ . ‎‎‎Then‎:‎ Fact 1: ‎‎ $‎g(x)‎$ ‎is ‎increasing‎;‎ ‎‎
Fact 2: ‎‎ $\log g(x)‎$ ‎‎‎‎‎ has derivative ‎‎ $‎‎\frac{g^\prime_{-}(x) + g^\prime_{+}(x) ‎}{2g(x)}‎$ ‎except, possibly, on a countable set, where ‎ $‎g^\prime_{+}(x‏)‎$ ‎and ‎‎ $‎g^\prime_{-}(x)‎$ ‎are ‎right ‎and ‎left ‎derivatives, ‎respectively; ‎ Fact  ‎3:‎‎ $‎‎\frac{g^‎\prime_{-}(x) + g^‎\prime_{+}(x) ‎}{2g(x)}‎$ is ‎decreasing ‎and ‎non-negative on ‎ $‎‎\mathbb{R}‎^+‎$ ‎.‎
‎‎ My question ‎is:‎ ‎‎Let ‎‎
‎‎ \begin{align*}‎‎
‎F(n) = \sum_{i=1}^n ‎‎\frac{g^\prime_{-}(i) + g^\prime_{+}(i) ‎}{2g(i)} - \log g(n),
‎\end{align*} ‎‎‎
‎prove that the sequence ‎ $‎\{F(n)\}‎$ ‎converges.‎‎ ‎Thanks‎ in advance.","['convex-analysis', 'real-analysis', 'sequences-and-series', 'convergence-divergence', 'derivatives']"
3581857,Can a surjective function $f: \mathbb N\to \mathbb N $ be not injective? [duplicate],"This question already has answers here : Finding a function $\mathbb{N} \to \mathbb{N}$ that is surjective but not injective. (3 answers) Closed 4 years ago . Can a surjective function $f: \mathbb N\to \mathbb N $ be not injective? Hi;
I've been breaking my head over this simple question since last night.
It's actually a small sub problem (of a simple Analysis Question) to what I'm trying to solve but essential to me solving it. At first I thought it can not be. 
For example, say there is an infinite number of $ n \in \mathbb N $ that map to some x and an infinite number that doesn't. But then, wouldn't the first have to be finite? Because, for example if I were to arrange that first infinite subset on a line and say that all other terms that ""hit"" every other $n \in \mathbb N $ come afterwards then we'd never get to the other ones. 
Are they there? I apologize if this doesn't make a lot of sense. I'm quite confused by all the scenarios that I can think of. It (the feeling of wonder) makes me excited and kind of happy, but also quite helpless. I appreciate any tip to guide my thinking in the right direction.
Cheers","['elementary-set-theory', 'functions', 'analysis', 'sequences-and-series']"
3581887,Determining the coefficients of divisors under a blowup of smooth varieties along smooth subvarieties.,"Let $ \pi: Y \rightarrow X $ blowup of a smooth variety along a smooth subvariety, with exceptional divisor $ E. $ Then $$ \operatorname{Pic}Y \cong \pi^{*}\operatorname{Pic}X \oplus \mathbb{Z}E $$ (can I find a proof of this fact in most books? ) A challenge for me is how to determine the coefficients of these divisors in explicit cases. I would really appreciate seeing an example of how this works. Edit: After further reflection, I have identified the clearest way to ask my question, but first a bit of background: Consider a log variety $ (V,B), $ and let $ \varphi: V' \rightarrow V $ be birational morphism, and $ E \subset V' $ a prime divisor. Now in general for a divisor $ D $ on $ V, $ I think we can apply a valuation $ \operatorname{ord}_{E}, $ to obtain some multiplicity $ \nu_{E}(D) \in \mathbb{Z}_{\geq 0} $ of an effective divisor $ D $ with respect to $ E. $ If $ \varepsilon $ is the set of exceptional divisors of the birational morphism $ \varphi, $ and $ D' $ the strict transform of $ D $ on $ V', $ then $$ \varphi^{*}D = D' + \sum_{E \in \varepsilon} \nu_{E}(D)E. $$ In the case of the canonical class $ K_{V'} $ we get $$ K_{V'} = \varphi^{*}K_{V} + \sum_{E \in \varepsilon} a(E)E, $$ where the number $ a(E) $ is called the discrepancy of the geometric valuation $ E, $ and is independent of the model $ V'. $ My question is, what is this multiplicity $ \nu_{E}(D) $ and how do we compute it explicitly? I realise that I do not really understand what these coefficients mean.",['algebraic-geometry']
3581896,Existence of a periodic solution,"Consider the differential equation $x'=f(t,x)$ , where $f(t,x)$ is continuously differentiable in $t$ and $x$ . Suppose that $f(t+T,x)=f(t,x)$ for all $t$ . Suppose there are constants $p$ , $q$ such that $f(t,p)\ge0,f(t,q)\le0$ for all $t$ . Prove that there is a periodic solution $x(t)$ for this equation with $p<x(0)<q$ I have seen this question here - Prove that there is a periodic solution $x(t)$ with $p<x(0)<q$ My professor claims that the statement is also true if the inequalities $f(t,p)\gt0,f(t,q)\lt0$ are not strict. However, the proof in the link depicts the idea that a solution for the ODE satisfying $x(0)=p$ satisfies $x(t)>p$ for all $t>0$ and uses the fact that the inequality is strict (otherwise, the point $\tau$ satisfying $\varphi(\tau) = p$ could be an inflection point). I'd appreciate any proof of this claim given the non-strict inequalities or a counterexample if the proposition is false.","['ordinary-differential-equations', 'dynamical-systems']"
3581913,A matrix defined by an operation in a finite group,"Let $G$ be a finite group and $x_1,..., x_n$ be an enumeration of its elements. We consider the matrix $(a_{ij})_{1\le i,j \le n}$ where $a_{ij}=0$ if $x_i x_j^{-1}=x_jx_i^{-1}$ and $a_{ij}=1$ otherwise. Find the parity of $\det(a_{ij})$ . This problem comes from the 2019 District stage of the Romanian Mathematics Olympiad. Let $A=(a_{ij})_{1\le i,j \le n}$ . One of the $x_i$ s is going to be the identity element of $G$ . WLOG we may consider it to be $x_1$ , since changing rows and columns only affects the sign of a determinant. I managed to obseve that $A$ is symmetric since $a_{ij}=a_{ji}$ always. Furthermore, $A$ 's principal diagonal is going to be $0$ because $x_i x_i^{-1}=x_i^{-1}x_i$ , $\forall i=\overline{1,n}$ . Hence, $A$ is a symmetric hollow matrix whose entries are either $0$ or $1$ . Here I got stuck and I would like to know if it is possible to continue along these lines. EDIT: As requested, I will translate the official solution: $\det(a_{ij})$ is even. To prove this, we will show that $\det(a_{ij})$ is divisible by $|S|$ , where $S=\{x | x\in G, x\ne x^{-1}\}$ . Since an element of $G$ is in $S$ if and only if its inverse is in $S$ , $|S|$ is even (possibly zero), so $\det(a_{ij})$ is even. The value of a determinant is not changed if a column is replaced by the sum of all the columns. Hence, to prove the divisibility it is enough to show that every row contains exactly $|S|$ units. If $S$ is empty, then $(a_{ij})=O_n$ , so $\det(a_{ij})=0$ . If $S$ isn't empty, we fix a row $i$ and we consider the set $J_i=\{j |a_{ij}=1\}$ . Since $j \to x_i x_j^{-1}$ defines a bijection from $J_i$ to $S$ , it follows that $|J_i|=|S|$ .","['matrices', 'group-theory', 'linear-algebra', 'contest-math']"
3581971,How can it be shown that $\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}^{2}a^{n-k}$,How can it be shown that: $$\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}^{2}a^{n-k}$$ My try: $$\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\left(a-1\right)^k=\sum_{k=0}^{n}\binom{n}{k}\binom{2n-k}{n}\sum_{j=0}^{k}\binom{k}{j}a^{j}\left(-1\right)^{k-j}$$ $$=\left(-1\right)^{n}\sum_{k=0}^{n}\binom{n}{k}\binom{-n-1}{n-k}\sum_{j=0}^{k}\binom{k}{j}a^{j}\left(-1\right)^{-j}$$ $$=\left(-1\right)^{n}\sum_{j=0}^{n}\binom{n}{j}a^{j}\left(-1\right)^{-j}\sum_{k=j}^{n}\binom{n-j}{k-j}\binom{-n-1}{n-k}$$ $$=\left(-1\right)^{n}\sum_{j=0}^{n}\binom{n}{j}a^{j}\left(-1\right)^{-j}\binom{-j-1}{n-j}$$ $$=\sum_{j=0}^{n}\binom{n}{j}a^{j}\binom{n}{j}=\sum_{\color{red}{j}=0}^{n}\binom{n}{\color{red}{j}}^2a^{n-\color{red}{j}}$$ The problem is that I have $\color{red}{j}$ instead of $k$ . Source : math.wvu.edu,"['summation', 'binomial-coefficients', 'discrete-mathematics']"
3582004,Numerical methods to minimize a matrix function,"I'm faced with the problem \begin{align*}
\min_{A\in\mathbb{R}^{n\times m}}\left\{f(A)+\lambda\lvert\lvert A\rvert\rvert_{S_p}^p\right\},
\end{align*} where $f:\mathbb{R}^{n\times m}\to\mathbb{R}$ is some generic matrix function, $\lambda>0$ is a fixed constant and $\lvert\lvert A\rvert\rvert_{S_p}$ is the $p$ -Schatten norm of $A$ defined as \begin{align*}
\lvert\lvert A\rvert\rvert_{S_p} = \left(\sum_j|\sigma_j(A)|^p\right)^{1/p},
\end{align*} where $\sigma_j(A)$ are the singular values of $A$ (its a norm ony when $p\geq 1$ ; when $p=1$ , is the nuclear norm). There are some special cases when the problem has an explicit and unique solution. For example, if $p=1$ and $f(A)=g(A):=\lvert\lvert A-X\rvert\rvert_F^2$ for some fixed $X$ , where $\lvert\lvert \cdot\rvert\rvert_F$ is the Frobenius norm. Also, there are papers that describe numerical method to solve the problem when $f=g$ and $p<1$ . My question is: Do you know some generic algorithm to solve this problem for any $f$ and any $p$ ? I'm specially interested in the case $p<1$ , when the Schatten norm is not convex (and not a norm).","['numerical-optimization', 'reference-request', 'matrices', 'matrix-norms', 'optimization']"
3582087,Maximum value of $\frac{a}{1+bc} + \frac b{1+ac} + \frac{c}{1+ab}$ given $a^2 + b^2 + c^2 = 1$,"Given that the constraint of $a, b, c$ , for which $a, b, c$ are non-negative real numbers, is $a^2+b^2+c^2=1,$ find the maximum value of $$\frac{a}{(1+bc)}+\frac b{(1+ac)}+\frac{c}{(1+ab)}.$$ For this question I have tried using this geometric method, hopefully it can be logically correct Do you all have actually better method(s) to solve this problem?","['multivariable-calculus', 'calculus', 'maxima-minima', 'optimization']"
3582107,Closed form for $\sum_{k=0}^{n}\binom{n}{k}^{r}$,"One of the most important and basic identities in binomial summations in Vandermonde's identity which states : $$\sum_{k=0}^{r}\binom{m}{k}\binom{n}{r-k}=\binom{m+n}{r}$$ The identity can be generalized to the case when more than two binomial coefficients are multiplied. Setting $m,r \mapsto n$ follows: $$\sum_{k=0}^{n}\binom{n}{k}\binom{n}{n-k}=\binom{2n}{n}=\sum_{k=0}^{n}\binom{n}{k}^2$$ Which is very well-known. One of the questions related to this summation is : $$\sum_{k=0}^{n}\binom{n}{k}^{4}=\sum_{k=0}^{n}\binom{\color{red}{n}}{\color{blue}{k}}\binom{\color{red}{n}}{\color{blue}{k}}\binom{\color{red}{n}}{\color{blue}{n-k}}\binom{\color{red}{n}}{\color{blue}{n-k}}$$ I thought that the answer would be $\binom{4n}{2n}$ , but this is not right in general and I don't know why, since the sum of the red and blue parts is independent of the index (is a fixed number),so that's why I used the convolution (It would be highly appreciated if someone explain where was I wrong). My question is :
Does there exist any closed formula for : $$\sum_{k=0}^{n}\binom{n}{k}^{r}$$ Where $r \in \mathbb N$ . One of the  identities related to this question is Dixon’s Identity which has been mentioned here (page 3). wolframalpha does not give a closed form.","['summation', 'binomial-coefficients', 'closed-form', 'discrete-mathematics']"
3582115,Lefschetz number in terms of Poincaré dual and fundamental class,"We define the Lefschetz number as $L(f)=\sum_n (-1)^n \text{Trace}(f^*\colon H^n(M)\rightarrow H^n(M))$ I want to show that the Lefschetz number can be written as $L(f)=\langle\Delta^*(u_{\Gamma}),[M]\rangle$ . Where $\Delta\colon M\rightarrow M\times M $ is the diagonal map, $\Gamma$ is the graph of $f$ , $u_{\Gamma}$ is the Poincaré dual of $\Gamma$ , and $[M]$ is the fundamental class of $M$ . But I am not sure how to compute $\langle\Delta^*(u_{\Gamma}),[M]\rangle$ .","['algebraic-topology', 'differential-geometry']"
3582122,Are these two notions of convolution the same somehow?,"Given a (locally finite) poset $(P,\leq)$ we can work with its incidence algebra , which is the $\mathbb{C}$ -algebra with a basis element for each interval $[x,y] = \{z ~|~ x \leq z \leq y\}$ . The multiplication is given by ""convolution"", where $$
(\alpha \ast \beta)([x,y]) = \sum_{z \in [x,y]} \alpha([x,z]) \beta([z,y])
$$ Notice the incidence algebra is really a matrix algebra in disguise. If we look at matrices with rows and columns indexed by $P$ , with usual matrix multiplication, then the subalgebra of matrices $A$ satisfying $A_{xy} = 0$ whenever $x \not \leq y$ is exactly the incidence algebra. So ""convolution"" is really matrix multiplication. The other place one commonly sees convolution is on functions. Here we have two complex measurable functions $f$ and $g$ and we define $$
(f \ast g)(x) = \int f(x) g(s-x) d \mu(s)
$$ In the case of a discrete measure, this becomes $$
(f \ast g)(n) = \sum_m f(n) g(m-n)
$$ Now this, at least initially, doesn't look very much like matrix multiplication. We can give it the right number of variables by working with a 2-dimensional convolution : $$
(f \ast \ast g)(x,y) = \sum_m \sum_n f(x,y) g(m-x,n-y)
$$ This still doesn't look much like convolution of poset algebras, though. There is a way to compute a convolution by working with matrices, using a Toeplitz matrix ,
but it doesn't seem to line up with the question I'm asking, and completely saturates the google results for anything to do with convolution and matrix multiplication. Is there a way to see convolution in an incidence algebra and convolution of functions as the same
  thing? If not, why are they named this way? They don't even seem superficially similar to me. Thanks in advance!","['matrices', 'order-theory', 'soft-question', 'convolution']"
3582146,Initial value problem with null surface data,"Let $(M,g)$ be a $d$ -dimensional Lorentzian manifold, i.e., the metric tensor $g$ has signature $(-1,+1,\dots,+1)$ where $-1$ appears only once and $+1$ appears $(d-1)$ times. A null hypersurface $\Sigma\subset M$ is one codimension one embedded submanifold whose normal vector $n$ is null, i.e., $$g(n,n)=0.$$ On the other hand a spacelike hypersurface $\Sigma\subset M$ is one codimension one embedded submanifold whose normal vector $n$ is timelike, $$g(n,n)<0.$$ Now, further suppose that $\Sigma$ is globally hyperbolic so that a Cauchy surface can be defined and an initial value problem can be defined. In that sense, there is a theorem stating what is the appropriate initial value on a spacelike hypersurface. This is presented in Wald's General Relativity as: Theorem 10.1.2: Let $(M,g)$ be a globally hyperbolic spacetime (or a globally hyperbolic region of an arbitrary spacetime) and let $\nabla$ be any derivative operator. Let $\Sigma$ be a smooth, spacelike Cauchy surface. Consider the system of $n$ linear equations for $n$ unknown functions $\phi_1,\dots \phi_n$ of the form $$g^{ab}\nabla_a\nabla_b\phi_i + \sum_j (A_{ij})^a\nabla_a \phi_j + \sum_j B_{ij}\phi_j + C_i = 0\tag{10.1.20}.$$ Then equation (10.1.20) has a well posed initial value formulation on $\Sigma$ . More precisely, given arbitrary smooth initial data, $(\phi_i,n^a\nabla_a \phi_i)$ for $i=1,\dots,n$ on $\Sigma$ there exists a unique solution of equation (10.1.20) throughout $M$ . Furthermore, the solutions depend continuously on the initial data in the sense described above for the Klein-Gordon equation in flat spacetime. Finally a variation of the initial data outside of a closed subset, $S$ , of $\Sigma$ does not affect the solution in $D(S)$ [the domain of dependence]. This tells that given appropriate initial value on a spacelike Cauchy surface, namely, the value of the fields and their first derivatives along the normal, we are granted a unique solution. This paper alludes to such a result when $\Sigma$ is a null surface, but: (1) it just talks about a single scalar field, (2) it never precisely states a theorem and (3) it is not much rigorous really. The claim is on page 14: We emphasize that the initial value data needed for the null surface development consists of the function on a pair of null surfaces ; it is not the same as the data needed in the standard Cauchy problem, which is the function and its first time derivative on an initial surface [14], [15]. I've tried skimming through the papers [14] and [15] mentioned there, but they never even mention null/lightlike surfaces, so if the result is there it is probably phrased differently and I wasn't able to identify it. My question : is there one analogue theorem of Theorem (10.1.2) for null surfaces ? In other words, a theorem stating what is the appropriate initial value data to be specified on null surfaces to find a unique solution of an equation like (10.1.20)? My particular interest would be in null infinity $\mathscr{I}^\pm$ defined in the Penrose completion of an asymptotically flat spacetime, but I believe such theorem would just care about the surface being null. References are highly appreciated!","['semi-riemannian-geometry', 'reference-request', 'partial-differential-equations', 'general-relativity', 'differential-geometry']"
3582218,Clarifying the definition of antisymmetry (binary relation properties),"An anti-symmetric relationship says that there is no pair of distinct elements of set $A$ which are related by $R$ to the other. A relation is anti-symmetric if for every pair of distinct elements in the domain one of the following situations holds: $xRy$ , but it is not true that $yRx$ $yRx$ , but it is not true that $xRy$ Neither $xRy$ nor $yRx$ is true The Formal definitions of anti-symmetry: $$\require{cancel}\forall x,y \in A, (xRy \rightarrow y\cancel{R}x) \vee (yRx \rightarrow x\cancel{R}y) \rightarrow x \neq y$$ Or the logically equivalent way to express this is: $$ \forall x,y \in A, (xRy \wedge yRx) \rightarrow x = y$$ How do the formal definitions of anti-symmetry show the above statements? Alternatively, how do the formal definitions show that there is no pair of distinct elements of set $A$ which are related by $R$ to the other? From my understanding, it's saying that for a relation to be anti-symmetric, $\require{cancel}(xRy \rightarrow y\cancel{R}x) \vee (yRx \rightarrow x\cancel{R}y)$ , then x cannot equal y, and if $(xRy \wedge yRx)$ then x=y. So why does x have to equal y for $(xRy \wedge yRx)$ ?",['discrete-mathematics']
3582249,Surprising fact about a certain number-theoretic function,"Ante suggested the following function : For natural number $n$ we can observe the $n$ remainders $b_1,...,b_n$ by writing $n$ as $n=a_k \cdot k+b_k$ for $1 \leq k \leq n$ Because of the familiar division-with-remainder-theorem we have $0 \leq b_k <n$ Now we can study the sum $$r(n)=\sum_{k=1}^{\lfloor \frac{n-1}{2} \rfloor}b_k$$ After playing around with some values with support of Haran and Ante, we noticed that $$r(b)=r(b+1)$$ seems to hold if and only if $b+1$ is a power of $2$ or $3$ , including $2$ and $3$ There is no counterexmple upto $10^4$ ? r={(p)->su=0;for(j=2,(p-1)/2,su=su+lift(Mod(p,j)));su}
%94 = (p)->su=0;for(j=2,(p-1)/2,su=su+lift(Mod(p,j)));su
? for(j=1,10^4,if(r(j)==r(j+1),print(j,"" "",factor(j+1))))
1 Mat([2, 1])
2 Mat([3, 1])
3 Mat([2, 2])
7 Mat([2, 3])
8 Mat([3, 2])
15 Mat([2, 4])
26 Mat([3, 3])
31 Mat([2, 5])
63 Mat([2, 6])
80 Mat([3, 4])
127 Mat([2, 7])
242 Mat([3, 5])
255 Mat([2, 8])
511 Mat([2, 9])
728 Mat([3, 6])
1023 Mat([2, 10])
2047 Mat([2, 11])
2186 Mat([3, 7])
4095 Mat([2, 12])
6560 Mat([3, 8])
8191 Mat([2, 13])
? Is this in fact true, and if yes, why ?","['number-theory', 'summation', 'elementary-number-theory', 'perfect-powers']"
3582253,8 Vs 10 Axioms / Properties of a Vector Space: Should Closure of Addition and Scalar Multiplication Be Included?,"In every physical textbook on linear algebra that I own, vector spaces are defined as a set $\mathcal{S}$ , along with two operations: (vector) addition $\oplus$ , and scalar multiplication $\odot$ , that, together, satisfy ten properties (5 properties of addition, 5 properties of scalar multiplication). However, the Wikipedia article on Vector Spaces lists only 8 axioms / properties, stating (emphasis added): Vector addition and scalar multiplication are operations, satisfying the closure property: $\vec{u} + \vec{v}$ and $a\vec{v}$ are in $\mathcal{V}$ for all $a$ in $\mathbb{F}$ , and $\vec{u},\, \vec{v}$ in $\mathcal{V}$ . Some older sources mention these properties as separate axioms. This statement seems to suggest that the closure axioms are somehow included in the other 8 axioms. Unfortunately, the reason as to why closure under vector addition and scalar multiplication need not be included is not explained. Further searches online have turned up lists of 8, 9 or 10 properties of Vectors Spaces, so I am a bit confused as to what's going on, here? N.B. when defining vector addition and and scalar multiplication (see the end of this post for the complete quote), the Wikipedia article does specify that the resultant vector is also an element of the set $\mathcal{V}$ so are they basically shifting the ""burden"" of this property onto the operations, themselves? That is certainly what it seems like, but it is not obvious as to why they would make this move with these specific properties, and not the others . Any clarification would be greatly appreciated! Complete Definition from Wikipedia: A vector space over a field ${F}$ is a set $V$ together with two operations that satisfy the eight axioms listed below. In the following, $V × V$ denotes the Cartesian product of $V$ with itself, and → denotes a mapping from one set to another. The first operation, called vector addition or simply addition + : $V × V$ → $V$ , takes any two vectors $\mathbf v$ and $\mathbf w$ and assigns to them a third vector which is commonly written as $\mathbf v + \mathbf w$ , and called the sum of these two vectors. (The resultant vector is also an element of the set $V$ .) The second operation, called scalar multiplication · : $F × V$ → $V$ ， takes any scalar $a$ and any vector $\mathbf v$ and gives another vector $a \mathbf v$ . (Similarly, the vector $a \mathbf v$ is an element of the set $V$ ...)","['linear-algebra', 'vector-spaces', 'axioms']"
3582295,Fisher information in one parameter exponential family.,"We define the one-parameter exponential family of distribution functions as those whose pmf/pdf can be written as $$\exp\{c(\theta)T(x) + d(\theta) + s(x)\}$$ I would like to show that if c is twice differentiable with a positive derivative and $E(T(X))= \theta$ then $I(\theta) = \dfrac{1}{\text{var}(T(X))}$ I tried directly computing the fisher information of theta, but I do not see why the equality holds. Any help would be appreciated","['fisher-information', 'statistics', 'parameter-estimation', 'exponential-distribution']"
3582363,How to know if a 8 puzzle is solvable,"Consider the following $3\times3$ sliding puzzle: This is not solvable from the following state: The explanation is that there are 11 inversions, and therefore it is unsolvable. How do they arrive at that conclusion?","['permutations', 'puzzle', 'permutation-cycles', 'proof-explanation', 'group-theory']"
3582375,Calculating the pullback of a differential form in $\mathbb{R}^n$,"In my course we defined the pullback $f^{*}\omega$ of a differential $k$ -Form $\omega: V \subseteq \mathbb{R}^n \to \bigwedge^k\left(\mathbb{R}^n\right)$ via a differentiable map $f: U \subseteq \mathbb{R}^m \to V$ as $$
(f^{*}\omega)(x)[v_1, ..., v_k] := \omega(f(x))[f'(x)v_1, ..., f'(x)v_k].
$$ However, I have some trouble understanding this definition. In particular I don't quite understand what exactly is meant by the terms $f'(x)v_i$ . I suppose these vectors are supposed to be the new inputs for the resulting $k$ -Form over $U$ . Let me showcase my confusion with the help of an example. Let $\omega = xdx + ydy + zdz$ and $f:[0,2\pi]\to\mathbb{R}^3$ is the curve $f(t) = (e^{t\sin{t}},t^2 - 2\pi t, \cos{\frac{t}{2}})$ .
Then we have $f'(t) = ((\sin{t} + t\cos{t})e^{t\sin{t}}, 2t - 2\pi, -\frac{1}{2}\sin{\frac{t}{2}})$ and the above definition should reduce to: $$
(f^{*}\omega)(t)[v] = \omega(f(t))[f'(x)v]
$$ where $v = (x,y,z) \in \mathbb{R}^3$ . Going further: $$
(f^{*}\omega)(t)[v] = \left(e^{t\sin{t}}dx + (t^2 - 2\pi t)dy + \cos{\frac{t}{2}}dz\right)[f'(x)v].
$$ Now, to me the only sensible way to calculate $f'(t)v$ is calculating the dot product $\langle f'(t), v\rangle$ , since both $f'(t)$ and $v$ are vectors of $\mathbb{R}^3$ and don't really know of another way to multiply two of those (i think the cross product is out of question here). However, the dot product yields only a scalar, but the $1$ -Form is waiting for another 3-vector. So this can't be right. What is the correct way to calculate this pullback?","['calculus', 'differential-geometry', 'differential-forms', 'real-analysis']"
3582388,"Proving the integral $\int{1\over \sqrt{1-x^2}}\,dx$ via substitution","$\int{1\over \sqrt{1-x^2}}\,dx$ How do I solve this without $\sin$ or $\cos$ substitution? I want to try using $u$ substitution because I feel like it will be more intuitive for me. So far, I have tried to make the function to the power of a negative exponent: ${(\sqrt{1-x^2})}^{-1}$ I tried to do $u$ $=$ $1-x^2$ , and do the substitution method, but I keep getting the wrong answer; I'm trying to use this indefinite integral to solve a definite one from $1/2$ to $\sqrt{3}$ / $2$ . I'd rather not use trigonometric substitution because I want to do this assuming I don't already know that this is the derivative of $\sin^{-1}x$ .","['integration', 'calculus', 'trigonometry']"
3582426,How much multivariable calculus do I need to read Evans’ PDE book?,"I am currently in a PDE class using Evans’ text covering roughly chapters 1-6 and have around two weeks off, in which I would like to further my understanding of prerequisite material if possible. I have some experience with functional analysis and have worked through Rudin’s first two books, save for chapter 10 in Rudin’s first text, a chapter on integration of differential forms. However, I have only taken a non rigorous course in multivariable calculus, so my lack of familiarity with multivariable calculus concepts in general, as well as those referenced in sections C.1-C.4. of the appendix in Evans, which cover Green’s formulas, integration by parts, and the coarea formula, have hindered my understanding of the text. For those who have worked through the PDE text, which references would be most practical to supplement my weak areas well enough given the time constraints and background? I have seen similar questions asked and long textbooks that cover multivariable calculus as a whole but spend a long time building up elementary concepts are usually recommended. For now, would it be sufficient to just review chapter 9 (which covers some basic multivariable calculus) and read chapter 10 in Rudin’s first text?","['multivariable-calculus', 'reference-request', 'analysis', 'partial-differential-equations']"
3582430,Need help to prove the positivity of an infinite linear recurrence.,"The sequence $\{a_k\}_{k=1,\cdots,\infty}$ is defined by the following infinite linear recurrence: $$
a_k + \frac{1}{2}a_{k-1} + \frac{1}{3}a_{k-2} + \cdots + \frac{1}{k}a_1 = \frac{1}{k+1} \textrm{ with } a_1=\frac{1}{2}.
$$ Is there any way I can prove that $a_k$ is positive for $\forall k$ ? I have verified it using MATLAB and it should be true at least until very large $k$ . I also tried hard to prove the claim by induction but no luck. I guess some generating function argument may be needed, but I still couldn't figure it out. I would really appreciate it if anyone could give me a suggestion or reference! Thanks in advance!","['convolution', 'combinatorics', 'recurrence-relations', 'discrete-mathematics']"
3582465,Why are the Fourier coefficients of a modular form constant?,"Let $f$ be a holomorphic modular form (of given weight and level one). Since it $1$ -périodic and of moderate growth, it has a Fourier expansion, but this one is a Fourier expansion in $x$ , that is $$f(z) = \sum_{n \geqslant 0} a_n(y) e(nx).$$ I would like to understand why $a_n(y)$ does not depend on $y$ . Many sources just state the holomorphicity, but I do not see the relation with this integral? Is that a question of contour integral expression?","['complex-analysis', 'modular-forms', 'fourier-analysis']"
3582520,Evaluate the sum $\binom{2n}{n}+\binom{3n}{n}+\binom{4n}{n}+\cdots+\binom{kn}{n}$,"Evaluate the sum $$\binom{2n}{n}+\binom{3n}{n}+\binom{4n}{n} + \cdots +\binom{kn}{n}$$ My Attempt: Given sum = coefficient of $x^n$ in the expansion $$\{(1+x)^{n}+(1+x)^{2n}+(1+x)^{3n}+\cdots+(1+x)^{kn}\}-1 \\
= \text{coefficient of $x^n$ in}~~ \frac{(1+x)^n\{(1+x)^{nk}-1\}}{(1+x)^n-1}-1$$ But I am not able to go beyond this or there is some method using combinatorial argument","['summation', 'binomial-coefficients', 'combinatorics']"
3582521,Can $S^k$ be embedded in $S^n$ for all $k>n$?,"In Hatcher's Algebraic Topology, Section 2.B, there is a proposition concerning about computing the homology of $S^n-h(S^k)$ , where $k<n$ and $h:S^k \to S^n$ is an embedding. It is clear that there exists an embedding $S^k \to S^n$ for $k\leq n$ . What I'm curious is, can $S^k$ be embedded in $S^n$ for $k>n$ ? Intuitively this seems not true, but is there a way to show this? Also I'm curious for a similar question: Can the closed disk $D^k$ be embedded to $S^n$ for $k>n$ ? Thanks in advance.","['general-topology', 'algebraic-topology']"
3582527,$\sum _{n=0}^{\infty} \frac{1}{(n+1) (n+2)} \left(\frac{1}{\lfloor n \phi \rfloor +2}+\frac{1}{\lfloor n \phi ^{-1} \rfloor +2}\right)$,"How to prove: $$\sum _{n=0}^{\infty} \frac{1}{(n+1) (n+2)} \left(\frac{1}{\lfloor n \phi \rfloor +2}+\frac{1}{\lfloor n \phi ^{-1} \rfloor +2}\right)=\frac{3}{4}$$ Here $\phi=\frac{1+\sqrt 5}{2}$ and $\lfloor \cdot \rfloor$ the floor function. I suspect this is related to number theory (continued fractions) which I'm not familiar with. Any help will be appreciated. Update: Here is a related problem, solved by similar techniques.","['golden-ratio', 'number-theory', 'sequences-and-series']"
3582554,"Prove that there exists a line passing through M$(\alpha,\beta)$ which is tangent to the graph of $f$.","Let $f:[a,b]\rightarrow\Bbb{R}$ be a function continuous on $[a,b]$ and differentiable on $(a,b)$ . Let M $(\alpha,\beta)$ be a point on the line passing through the points $(a,f(a))$ and $(b,f(b))$ with $\alpha\notin [a,b]$ . Prove that there exists a line passing through M $(\alpha,\beta)$ which is tangent to the graph of $f$ . My Attempt:
I think this is an applicaton of Rolle's or Lagrange's Mean Value theorems but I am not able to frame the proper function","['tangent-line', 'real-analysis', 'calculus', 'rolles-theorem', 'derivatives']"
3582579,"Given that $3^{15a} = 5^{5b} = 15^{3c}$, show that $5ab-bc-3ac=0$","Given that $3^{15a} = 5^{5b} = 15^{3c}$ , show that $5ab-bc-3ac=0$ The only thing I can do is: $3^{5a} = 5^{b} = 15^{\frac{3}{5}c}$ and then i am stuck, I figure that there must be a relationship between 3 and 5? should i utilise $5ab-bc-3ac=0$ ?",['algebra-precalculus']
3582603,"Number of onto functions, why does my solution not work?","I have a set $A$ with $4$ elements and a set $B$ with $3$ elements. 
We need to find all onto functions from $A$ to $B$ . My line of thought: Map each element in $A$ to $B$ , where only one element in $A$ must be mapped to the same element in $B$ . So for the first element in $A$ , we have $3$ choices. For the second element in $A$ , we have $2$ choices. For the third element in $A$ , we have $1$ choice. Now map the fourth element in $A$ to any of the elements in $B$ , hence $3$ choices. Total would be $3 * 2 * 1 * 3 = 18$ . This is wrong however, the solution is $36$ . The solution also uses a different approach. They say a pair of elements needs to map to the same element. Choose this pair in ${4\choose 2}=6$ ways. Then select any of the $3$ elements from $B$ as a mapping target. Then there are $2$ choices left, hence total is $6 * 3 * 2 = 36$ I find my approach more intuitive, however I wonder what I counted wrong. Seems I'm missing half of the possible solutions.","['intuition', 'combinatorics', 'discrete-mathematics']"
3582641,"For non-negative reals $a$, $b$, $c$, show that $3(1-a+a^2)(1-b+b^2)(1-c+c^2)\ge(1+abc+a^2b^2c^2)$","A 11th grade inequality problem: Let $a,b,c$ be non-negative real numbers. Prove that $$3(1-a+a^2)(1-b+b^2)(1-c+c^2)\ge(1+abc+a^2b^2c^2)$$ Do you have any hints to solve this inequality? Any hints would be fine. I tried this: $$3(1-a+a^2)(1-b+b^2)(1-c+c^2)\ge(1+abc+a^2b^2c^2)$$ By Cauchy's inequality, $$a^2+1\ge(2a)$$ and I did the same to $b$ and $c$ and applied it to the problem but the results are $$2abc\ge1+a^2b^2c^2$$ and this is wrong.","['multivariable-calculus', 'symmetric-polynomials', 'holder-inequality', 'inequality']"
3582649,Why do conjugate axes in an ellipse behave so much like the principal axes?,"In Extraordinary Conics: The Most Difficult Math Problem I Ever Solved , 7:36, there are some formulas shown that apply for conjugate axis vectors in general: Area: $\pi|A\times B|$ $C^2$ Invariant: $|A|^2 + |B|^2$ Inside test: $|(P-C)\times A|^2 + |(P-C)\times B|^2 < |A \times B|^2$ Tangent test: $|R\times A|^2 + |R\times B|^2 = |R\times (P - C)|^2$ where, for a real ellipse, $A$ and $B$ are one pair of conjugate axis vectors, and $C$ is the position vector of its center. $P$ is an arbitrary point in the plane, and $R$ is a vector. The ""line"" in the Tangent Test is defined as the line $C + kP$ , where $k \in \mathbb R$ . My first instinct is to use the fact that an ellipse is just an affine transform of a circle, and hope that some kind of tensor transform would show those are scalars, and thus transform invariants. However that obviously doesn't work, especially in the case of $|A|^2 + |B|^2$ , where $|A|^2$ is decidedly not invariant under affine transforms. So, under what viewpoint would these formulas be obvious? I don't want some ad hoc viewpoint, but a symmetric viewpoint, something in the spirit of Klein's program. Basically, I want a viewpoint whereby ""an ellipse equipped with a pair of conjugate axis vectors"" is just a symmetric image of ""a circle equipped with a pair of perpendicular radius vectors"", and the formulas are invariants of the symmetry. The affine transform does not leave the formulas invariant, so it can't be used as it is, although I suspect that it is in fact the correct viewpoint. It's just that the formulas are not written in the right form. If in the right form, they would be invariant. So far I found that the easiest way to show them is: For area being $\pi|A\times B|$ , shear parallel to $B$ , until $A$ is perpendicular to $B$ . For the $C^2$ invariant $|A|^2 + |B|^2$ , take the principal axis vectors $a, b$ , then write $A = a\cos\theta + b \sin\theta$ , $B = -a\sin\theta + b \cos\theta$ , then calculate, using $a \cdot b = 0$ . For the Inside Test, write $P = r(A\cos\theta + C, B\sin\theta + C)$ , where $r > 0$ , then plug in and calculate, to find that the inequality holds iff $ r < 1$ . For the Tangent Test, write $P = (A\cos\theta + C, B\sin\theta + C) + k R$ to check that it works. Then note that if we displace $P$ , the left side stays the same, but the right side changes linearly with displacement of $P$ , with kernel spanned by $R$ .","['conic-sections', 'geometry']"
3582656,Trying to understand a solution to Project Euler #2,"I'm trying to understand the Haskell solution given here (The third of the four solutions given) to Problem 2 to project Euler. I think I've interpreted the code right but I do not think I understand the math involved. I've tried to reduce it to Mathematical terms as much as possible. $(a,b)[1]:=a, (a,b)[2]:=b$ Define $(a,b)\times (c,d)=(ad+bc-4ac,ac+bd)$ Consider the Fibonacci series starting with $1,1$ so that $F_{3n}$ is always even. Fix arbitary natural $k$ Let $l=F_{3k}/2$ Let $m$ be the maximum natural such that $(1,4)^{2^m}[1]\le l$ Consider the sequence $A_i$ $A_1 = (0,1)$ $A_{i+1} = f((1,4)^{2^{m+1-i}},A_i)$ where $f(x,y)=x\times y$ if $(x\times y)[0] \le l$ , else $y$ Then show that $A_m[1]+A_m[2]=F_{3k+2}$ I know the fibonacci Sum formula ( $f_1+f_2+\cdots +f_n=f_{n+2}-1$ ) and the recurrence relation of the even only case $(f_{n+6}=4f_{n+3}+f_n)$ I'm not sure if I'm using the correct tags, feel free to change if required.","['combinatorics', 'discrete-mathematics']"
3582694,$\int_0^\pi\left|\frac{\sin {nx}}{x}\right|dx\ge \frac{2}{\pi}\left(1+\frac{1}{2}+\cdots+\frac{1}{n}\right)$,"Question: Show that $$\int_0^\pi\left|\frac{\sin {nx}}{x}\right|dx\ge \frac{2}{\pi}\left(1+\frac{1}{2}+\cdots+\frac{1}{n}\right).$$ My approach: We know that $$1+\frac{1}{2}+\cdots+\frac{1}{n}=\int_0^1\left(1+x+x^2+\cdots+x^{n-1}\right)dx=\int_0^1\frac{x^n-1}{x-1}dx.$$ Therefore we have $$\int_0^\pi\left|\frac{\sin {nx}}{x}\right|dx\ge \frac{2}{\pi}\left(1+\frac{1}{2}+\cdots+\frac{1}{n}\right) \\ \Leftrightarrow \int_0^\pi\left|\frac{\sin {nx}}{x}\right|dx\ge \frac{2}{\pi}\int_0^1\frac{x^n-1}{x-1}dx.$$ Now substituting $x=\pi t$ , we have $$\frac{2}{\pi}\int_0^1\frac{x^n-1}{x-1}dx=\frac{2}{\pi^{n+1}}\int_0^\pi \frac{t^n-\pi^n}{t-\pi}dt.$$ Thus we have $$\int_0^\pi\left|\frac{\sin {nx}}{x}\right|dx\ge \frac{2}{\pi}\int_0^1\frac{x^n-1}{x-1}dx \\ \Leftrightarrow \int_0^\pi\left|\frac{\sin {nx}}{x}\right|dx\ge \frac{2}{\pi^{n+1}}\int_0^\pi \frac{x^n-\pi^n}{x-\pi}dx\hspace{0.5 cm}...(1)$$ Therefore, if we show that $(1)$ is true, then we are done. Can someone provide me a hint?","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'integral-inequality']"
3582788,Solving a differential equation with one parameter defined by another differential equation,I have a differential equation as below: $$\frac{dx}{dt}=(y-z)x$$ $z$ is constant and $y$ is given by another differential equation as below: $$\frac{dy}{dt}=ay$$ $a$ is a constant How can I solve the equation? I tried to find the value of $y(t)$ and I substituted that in the $\frac{dx}{dt}$ . But I am not sure whether is correct way of doing it. Kindly help.,"['derivatives', 'ordinary-differential-equations']"
3582798,Why is $\int_{0}^{\infty} e^{-x}x^kdx = k!$?,"I was answering some math exercises, and by accident, I 'discovered' the following equation: $$
\int_{0}^{\infty} e^{-x}x^kdx = k!
$$ for instance, if $k=3$ , we have the following (using an online integral calculator, i.e. Wolfram): $$
\int_{0}^{\infty} e^{-x}x^3dx = 3! = 6
$$ However, I could not figure out how the equation makes sense... Is there a way to analytically transform the integral to $k!$ ?","['integration', 'factorial', 'calculus', 'indefinite-integrals', 'algebra-precalculus']"
3582808,The fundamental group of $\mathbb{R}/\mathbb{Q}$,"What is the fundamental group of $\mathbb{R}/\mathbb{Q}$ ? 
Here $\mathbb{R}$ is equipped with general topology and the quotient space is in the meaning of topology instead of additive subgroup. It is not difficult too see $\mathbb{R}/\mathbb{Q}$ is path connected, and $\mathbb{R}/\mathbb{Q}$ is not trivial. Because $\mathbb{Q}$ is dense in $\mathbb{R}$ , $U$ in $\mathbb{R}/\mathbb{Q}$ is open if and only if the preimage $\pi^{-1}(U)$ is a open subset of $\mathbb{R}$ containing $\mathbb{Q}$ , where $\pi$ denote the quotient map.","['general-topology', 'fundamental-groups', 'algebraic-topology']"
3582822,How does the Axiom of Extensionality imply that there is exactly one empty set?,"In his book Notes on Set Theory , Moschovakis begins to list the axioms of $\text{ZFC}$ on p. 24. The first is the Axiom of Extensionality , which he expresses like this: $$
A = B \Longleftrightarrow (\forall x)[x \in A \Longleftrightarrow x \in B].
$$ He then goes on to list Emptyset Axiom : There is a special object $\emptyset$ , which we will call a set, but which has no members. He then goes on to note: The Axiom of Extensionality implies that only one empty set exists, ... Now, here's my problem. In its formulation, the Axiom of Extensionality uses the membership of some existing ""thing"" $x$ to establish ""sameness"" of two sets. But since $x$ is an existing ""thing"", how is Extensionality even relevant to $\emptyset$ , which, by definition, contains no existing ""things""? It seems to me that we cannot establish that there exists exactly one $\emptyset$ , since the very notion of ""sameness"" is built upon existing $x$ 's being members of sets, and $\emptyset$ contains no existent $x$ 's. Addendum So if I understand correctly, my misinterpretation of Extensionality lies in this: I interpreted $x \in A$ as a demand for existing $x$ 's to be a part of sets in order for them to be the same set. But what Extensionality really says is that: $A = B \Longleftrightarrow (\forall x)[x \in A \Longleftrightarrow x \in B]$ holds for all $x$ 's. Then indeed, it follows that: $$
A = \emptyset, \; B = \emptyset' \\
A = B \Longleftrightarrow (\forall x)[x \in A \Longleftrightarrow x \in B],
$$ since it holds for both $A$ and $B$ that they have no members, hence every member that is a member of $A$ will be a member of $B$ — that is to say, no member. While thinking about it, I came up with an interesting ""modification"" of $\text{ZFC}$ . Instead of conceiving of $\emptyset$ as a set without members, let us denote nothing as $\mathfrak{n}$ . $\mathfrak{n}$ is an element of every set. More specifically, we define $\emptyset$ as $\emptyset := \{ \mathfrak{n} \}$ . With this setup, my interpretation of Extensionality holds for all sets. The only drawback is that such a setup contains atoms (one atom, $\mathfrak{n}$ , to be precise), which violates the Principle of Purity . Well, just a thought I wanted to share. ;) Please correct me if I got something wrong.",['elementary-set-theory']
3582947,Combinatoric interpretation of an equality between sums,"I was tasked with proving the following equality for any $n,m\in\Bbb{N}$ . $$\sum_{k=0}^{m}{m \choose k}{{n+k} \choose m}=\sum_{k=0}^{m}{m \choose k}{n \choose k}2^{k}$$ which i have managed to with some ugly double induction. Many problems of this variety can be solved by calculating the power of some set in two ways and I'm sure there is a way of looking at this equality that yields a nice combinatoric solution. However, I was unable to find it. Any thoughts? I'm actually curious what it might be since on the left side of the equation we have $2^k$ that looks like we get to choose some subset of $[k]$ but without its power being relevant, while on the right side we have none such terms.","['combinatorics', 'combinatorial-proofs']"
3583019,How do we know an $ \aleph_1 $ exists at all?,"I have two questions, actually. The first is as the title says: how do we know there exists an infinite cardinal such that there exists no other cardinals between it and $ \aleph_0 $? (We would have to assume or derive the existence of such an object before we label it something like $ \aleph_1 $.) My second question is, can we say for certain if there's any limit to the number of cardinals existing between $ \aleph_0 $ and continuum (i.e. $ 2^{\aleph_0} $)? I mean, how could we know that there's not an infinite number of cardinals between the two - perhaps even more than $ \aleph_0 $?","['cardinals', 'set-theory']"
3583033,Find the area enclosed by $r = 1 + \sin\theta$ and $r = 1 - \sin\theta$,"Find the area enclosed by $r = 1 + \sin\theta$ and $r = 1 - \sin\theta$ So, the curves are given by the following parametrizations: $$ f_1(\theta) = ((1 + \sin \theta) \cos \theta,(1 + \sin \theta) \sin \theta)$$ $$  f_2(\theta) = ((1 - \sin \theta) \cos \theta,(1 - \sin \theta) \sin \theta)$$ It looks logical that I have to find the intersections. How can I find the integral enclosed by the curves?","['multivariable-calculus', 'calculus', 'polar-coordinates']"
3583066,"Is the $\infty$ symbol used in limits an actual mathematical object, or just notation?","My calculus textbook uses $$\lim_{x\to c} f(x) = \infty$$ to express an infinite limit. Does this mean that the expression $\lim_{x\to c} f(x)$ is the same as some mathematical entity symbolized by $\infty$ , or is it just notation used to condense meaning? Also, is this notation really correct/proper (is it used in formal contexts) or is my textbook breaking formality for the sake of learning?","['limits', 'calculus']"
3583128,Solving binomial summation $\sum_{k=0}^{\lfloor{n/2}\rfloor} \binom{n-k}{k} 2^{n-k}$,"How can we solve the sum $$\sum_{k=0}^{\lfloor{n/2}\rfloor} \binom{n-k}{k} 2^{n-k}$$ The problem arose from a counting question, but I am unable to solve this sum. Edit : The counting problem was similar to what @Phicar has written, ie, I looked up and the question is equivalent to fibonacci tiling in two colours .","['algebra-precalculus', 'binomial-coefficients', 'binomial-theorem', 'summation']"
3583157,"Skew-symmetric, Time Dependent, Linear Ordinary Differential Equations","Let $I \subset \Bbb R \tag 1$ be an open interval, not necessarily bounded, and let $A(t)$ be a continuous matrix function of $t \in I$ , taking values in $M(n, \Bbb R)$ ; that is $A(t) \in C^0(I, M(n,, \Bbb R)); \tag 2$ suppose further that $A(t)$ is skew-symmetric for every $t$ : $A^T(t) = -A(t), \tag 3$ and consider the ordinary time-varying linear system $\dot{\vec x}(t) = A(t) \vec x(t), \tag 4$ where $\vec x(t) \in C^1(I, \Bbb R^n). \tag 5$ It is well-known, and easy to see, that when $A$ is a constant matrix the solutions to (4) are given by $\vec x(t) = e^{A(t - t_0)} \vec x(t_0), \tag 6$ where the matrix exponential is orthogonal; indeed we have $(e^{A(t - t_0)})^T e^{A(t - t_0)} = e^{A^T(t - t_0)} e^{A(t - t_0)} = e^{-A(t - t_0)}e^{A(t - t_0)} = I. \tag 7$ The fact that $e^{A(t - t_0)}$ is orthogonal leads to $\langle \vec x(t), \vec y(t) \rangle = \langle e^{A(t - t_0)} \vec x(t_0), e^{A(t - t_0)} \vec y(t_0) \rangle = \langle \vec x(t_0), \vec y(t_0) \rangle; \tag 8$ that is, the evolution of vectors according to (4) preserves inner products. We recall that $e^{A(t - t_0)}$ is a fundamental matrix solution of (4), and we observe that it takes the value $I$ at $t = t_0$ : $e^{A(t_0 - t_0)} = e^{A(0)} = I. \tag 9$ The purpose here is to investigate extending this observation to the case in which $A(t)$ is not a constant matrix. The Question is then:  given a system of the form (4), with $A(t)$ as in (3), show that a fundamental solution matrix $X(t, t_0)$ of the system (4) with $X(t_0, t_0) = I \tag{10}$ is orthogonal.  Conversely, show that a system (4) with orthogonal fundamental matrix satisfies (3).","['lie-algebras', 'linear-algebra', 'lie-groups', 'ordinary-differential-equations']"
3583171,Counting polysticks on the $n$-cube.,"Over at Code Golf Stack Exchange, I put up a challenge asking people to count, among other things, the number of ways to take an $n$ -cube and color $k$ (connected) edges up to isometries of the $n$ -cube. Let's call this number $C(n,k)$ . For example, when $n=3$ (the ordinary cube) and $k=4$ , $C(3,4) = 4$ as there are four such colorings. I'm particularly interested in computing $C(n,n)$ , the case where $n=k$ , because $C(n+1,k) = C(n,k)$ for $k \leq n$ (because you can just project down a dimension), so understanding this case illuminates the limiting case as $n$ goes to infinity. I've computed the first few terms, for $n = k \leq 6$ , $$
  \begin{align}
    C(1,1) &= 1, \\
    C(2,2) &= 1, \\
    C(3,3) &= 3, \\
    C(4,4) &= 7, \\
    C(5,5) &= 27, \text{ and} \\
    C(6,6) &= 121.
  \end{align}
$$ It's computationally expensive to determine $C(7,7)$ , but it's running on my machine now. Looking this up on OEIS, it appears this nearly matches sequence A062363 , that is, $C(n,n) = A062363(n-1)$ for $2 \leq n \leq 6$ . I don't have any reason a priori to expect the sequence I've described to be related to the definition of A062363, to be especially nice, or even to be in the OEIS at all. Does the OEIS sequence actually match the sequence that I'm looking at? Or is this just a coincidence?","['geometry', 'recreational-mathematics', 'oeis', 'combinatorial-geometry', 'polyomino']"
3583228,Understanding Sheaves and Stacks,"I am trying to understand the notion of sheaves and stacks. Intuitively, the former, sheaves are bit easy to understand as a gluing of compatible families of sets assign to opens sets of a topological space. In other words, it is a contravariant functor $\mathcal{F}:\mathbf{Open}(X)^{\operatorname{op}}\to\mathbf{Set}$ such that $$\mathcal{F}(U)=\lim\left(\prod_{i\in I}\mathcal{F}(U_i) \rightrightarrows \prod_{j,k\in I^2}\mathcal{F}(U_j\cap U_k)\right)$$ where $X$ is a topological space, $U$ is an open set of $X$ and $\{U_i\}_{i\in I}$ is any open cover of $U.$ Further, it is easy to imagine a sheaf as a étalé space over $X.$ Then I started reading about stacks using this and nlab as my primary sources. I learned that a stack is a contravariant functor $\mathcal{F}:\mathcal{C}^{\operatorname{op}}\to\mathbf{Grpd}$ satisfying a descent property and, categories fibered in groupoids over $\mathcal{C}$ is an intuitive way to think about stacks, where $\mathcal{C}$ is a site (category equipped with a coverage). Now I have following questions: How can I understand the descent property for stack? To be more specific, how can triple fiber products (intersections) appear in the equalizer fork diagram? What categories fibered in groupoids over $\mathcal{C}$ corresponds to stacks? Is this the correct analogue of étalé space of a stack?","['topological-stacks', 'algebraic-stacks', 'algebraic-geometry', 'homotopy-theory', 'algebraic-topology']"
3583333,Understanding the Voss-Weyl formula for divergence,"The Voss-Weyl formula for the divergence of a vector field $V = V^\mu e_\mu$ is given by $$ \mathrm{div}(V) = \frac{1}{\sqrt{\det g}}\partial_\mu \big(\sqrt{\det g} V^\mu \big)$$ The determinant of a metric $\det g = \det[g_{\mu \nu}]$ depends upon which basis we are working in. My interpretation is that the basis we use to take the determinant in is given by the basis which the components $V^\mu$ are with respect to. If I had an orthonormal basis $\{ e_\mu \}$ , then $ g_{\mu \nu} = g(e_\mu, e_\nu ) = \delta_{\mu \nu}$ . In which case, in this particular coordinate system , $\det g = 1$ and the divergence would be given by $$ \mathrm{div}(V) = \partial_\mu V^\mu$$ For the polar coordinate system $(r,\theta)$ , I can use the basis vectors $\{ e_r = \partial_r, e_\theta = \frac{1}{r} \partial_\theta \}$ which are orthonormal: $g_{\mu \nu} = g(e_\mu,e_\nu)=\mathrm{diag}(1,1)$ , so the Voss-Weyl formula would tell me that, as $\det g =1$ , for $V = V^r e_r + V^\theta e_\theta$ the divergence is given by $$\mathrm{div}(V) = \partial_r V^r + \partial_\theta V^\theta $$ This is incorrect. What have I done wrong here?","['coordinate-systems', 'tensors', 'vector-fields', 'differential-geometry']"
3583334,Evaluating $\int_0^t\frac{1}{\sqrt{x^3}} e^{- \frac{(a-bx)^2}{2x}} dx$,"I've been trying to compute the following integral, but I havent been able to. Mathematica gives me an answer, but I would like to know how to get to that answer. For reference, this is the CDF of first time passage of a brownian motion with drift. $$\int_0^t\frac{1}{\sqrt{x^3}} e^{-\frac{(a-bx)^2}{2x}} dx$$ The answer according to Mathematica is: $$ \sqrt{\frac{\pi}{2}} \frac{1}{a} \operatorname{erfc}\left(\frac{a - bt}{\sqrt{2t}}\right) + \sqrt{\frac{\pi}{2}} \frac{1}{a} e^{2ab}\operatorname{erfc}\left(\frac{a + bt}{\sqrt{2t}}\right) $$ where $\operatorname{erfc}$ is the complementary error function. I've been trying to solve this for weeks, without any success. Here 's a link to a similar question, but the integrals are from $0$ to $\infty$ which helps, but doesn't lead to an answer. Hints would be useful as well, since I want to be able to solve this integral.","['integration', 'definite-integrals', 'calculus', 'brownian-motion', 'probability-theory']"
3583341,A Problem Of Convergence,"I am newly learning about the convergence of sequences and I want to share a problem which I am unable to make through. The problem is as follows:- Find a closed form for the limit $$f(m)=\lim_{n\to\infty} \left(\prod_{i=1}^n \frac{m+i}{n}\right)^{1/n}$$ I have learned a theorem in my book where it was written that if there is a sequence whose terms are all positive and the sequence converges to a finite limit then the Geometric mean of $n$ terms of that sequence will approach the same limit as that of the sequence itself, provided $n$ approaches infinity.
I thought of using the above result somehow to figure out the answer of my question. Though it is not provided here I assumed $m$ as a positive real number to increase the simplicity and to make use of the theorem.
Is the result which I am thinking to make use of (unable to make use of though) will help to solve the problem? If yes then please provide me with a hint else help me with a solution of the problem","['limits', 'means', 'sequences-and-series', 'real-analysis']"
3583351,Is the Jordan content a pre-measure?,"I am currently dealing with the theory of the Jordan content $\iota: \mathcal{J}(\mathbb{R}^n) \rightarrow [0,\infty]$ where $\mathcal{J}(\mathbb{R}^n)$ denotes the ring of Jordan-measurable sets. I asked myself the question, whether it is a pre-measure. Let $(A_k) \in \mathcal{J}(\mathbb{R}^n)^{\mathbb{N}}$ be a disjoint set-sequence such that $\biguplus_{k=1}^\infty A_k \in \mathcal{J}(\mathbb{R}^n)$ . From finite additivity and monotonicity of the Jordan content, we obtain: $$\sum_{k=1}^n \iota(A_k)=\iota \left( \biguplus_{k=1}^n A_k \right) \leq \iota \left( \biguplus_{k=1}^\infty A_k \right)$$ and thus $\sum_{k=1}^\infty \iota(A_k) \leq \iota( \biguplus_{k=1}^\infty A_k)$ . Unfortunately I have no clue how to prove the other ineqality (or provide a counterexample) and would appreciate any hint you could give me.",['measure-theory']
3583357,On Mathematical Induction,"Let's suppose we are asked to prove $1+2+\ldots+n=\frac{n(n+1)}{2}$ , for a natural number $n$ . Is the use of mathematical induction inevitable in this situation? For instance, what makes the following proof not mathematically sound? $S=1+\dots+n$ $S=n+\dots+1$ Adding both sides of the two equations gives $2S=\overbrace{(n+1)+\dots+(n+1)}^{n \text{ times}}$ , and dividing through by $2$ yields the result.","['proof-writing', 'logic', 'induction', 'discrete-mathematics', 'algebra-precalculus']"
3583385,Old USAMO combinatorics problem about distribution of members into committees containing a fixed number of members.,"A certain organisation has n members and it has n+1 three member committees, no two of which have identical membership. Prove that there are 2 committees which share exactly one member. MY ATTEMPT: We have n members, which we can divide into n/3 three member groups. We can 'assign' one committee to each of these groups, leaving us with n/3 filled committees and (n+1-n/3) or 2n/3 - 1 completely empty committees.
Now, if three of the filled committees were to share one member with one unfilled committee, we get one more filled committee, to fill all remaining committees in this manner we'd need 2n - 3 filled committees, which is more than the number of filled committees we have. I think the way to solve this is to consider those cases in which some committees share two members, but I don't know how to express that using equations. Help would be appreciated","['contest-math', 'combinatorics']"
3583401,Sections of the exceptional divisor of a blowup,"Let $C$ be a smooth curve in a smooth threefold $X$ . Denote by $Y$ the blowup of $X$ along $C$ with exceptional divisor $E$ . Then $E \rightarrow  C$ is a $\mathbb{P}^1$ -bundle over $C$ . Is it true that sections of $E \rightarrow  C$ correspond to smooth surfaces $S \subset X$ containing $C$ ? To be more specific: If $S \subset X$ is a smooth surface containing $C$ then the strict transform of $S$ intersects $E$ along a section $\sigma$ . Is the converse true? That is, given $\sigma$ a section of $E \rightarrow C$ can we always find a smooth surface $S$ such that $\sigma = \tilde S \cap E$ ?","['algebraic-geometry', 'blowup', 'birational-geometry']"
3583406,In what sense is $\mathcal L^\infty$ the limit of $\mathcal L^p$ as $p\to\infty$?,"In René Schilling's book Measures, Integrals and Martingales (second edition), a footnote on p. 116 says, Problem 13.21 shows that $\mathcal L^\infty$ is the limit of $\mathcal L^p$ as $p\to\infty$ . This seems wrong to me. In particular, consider the unit function $f(x)=1$ . Clearly $f\in\mathcal L^\infty$ , but $f\notin\mathcal L^p$ for all $p\in[1,\infty)$ . Perhaps Schilling means a different kind of set-theoretic limit from what I am expecting? My understanding is that we can define $\limsup$ and $\liminf$ for set sequences as $$\liminf_{n\to\infty}=\bigcup_{n\geqslant 1}\bigcap_{j\geqslant n}A_j$$ $$\limsup_{n\to\infty}=\bigcap_{n\geqslant 1}\bigcup_{j\geqslant n}A_j$$ and then define the limit to be equal to these sets if they are equal to each other. With this definition, $f(x)=1$ is in neither the $\limsup$ nor the $\liminf$ , so Schilling's claim doesn't seem to hold up. Contrary to the footnote, Problem 13.21 says nothing about this claim. Note: This is a similar topic, but a distinct question, from that of this post , ""Limit of $L^p$ Norm."" That post is about the numerical limit of $\|\cdot\|_p$ , whereas this question is about the set-theoretic limit of $\mathcal L^p$ . And $\lim_{p\to\infty}\|\cdot\|_p=\|\cdot\|_\infty$ does not necessarily imply $\lim_{p\to\infty}\mathcal L^p=\mathcal L^\infty$ .","['measure-theory', 'lp-spaces', 'lebesgue-integral', 'functional-analysis']"
