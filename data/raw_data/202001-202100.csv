question_id,title,body,tags
3975263,"Find a minimal sufficient statistic for $U(\theta,\theta+c)$, where $(\theta,c)$ unknown.","Suppose $X_1,\cdots,X_n$ are $i.i.d$ from a distribution with p.d.f $$\delta_{(\theta,c)}(x)=\frac{1}{c}\mathbb{1}_{(x\in[\theta,\theta+c])},$$ where $\theta\in\mathbb{R}$ and $c\in\mathbb{R}^+$ unknown. Find a minimal sufficient statistic for $(\theta,c)$ . From the range of $x_i$ , i.e. $x_i\in[\theta,\theta+c]$ , we can determine that $\theta\leq x_i$ and $\theta+c\geq x_i$ , $\forall i\in\{1,\cdots,n\}$ . This implies $$\theta\leq x_{(1)}\text{ and }\theta+c\geq x_{(n)},$$ where $x_{(1)}=\underset{i\in\{1,\cdots,n\}}{\min}x_i$ and $x_{(n)}=\underset{i\in\{1,\cdots,n\}}{\max}x_i$ . The plots shows the area of $\theta\leq x_{(1)}\text{ and }\theta+c\geq x_{(n)}.$ It look like that $(x_{(1)},x_{(n)})$ is a minimal sufficient statistic for $(\theta,c)$ because $(x_{(1)},x_{(n)})$ uniquely determines the shape of the log-likelihood function. Is this correct?","['statistical-inference', 'statistics', 'uniform-distribution']"
3975328,Generating a sequence of i.i.d permutations by a single uniform random variable,"I am learning how the Mini-Batch-Gradient-Descent (MBGD) Algorithm works and I came across one thing, that I find a bit weird and dont know how to show this. In the MBGD algorithm we have a loop of $N$ phases. And in each of these phases we are choosing a random permutation on $\{1, \dots, n \}$ . At the end of the algorithm it is then stated, that we only need $\textbf{one}$ random variable $U \sim$ Unif[0,1] to generate these sequence of random permutations $(\sigma_i)_{i \in \mathbb{N}}$ , which is the part I do not know how to show. So I am trying to find a map \begin{align} 
f:[0,1] \to (S_n)^N,
\end{align} with $S_n$ being the symmetric group. But it feels very strange to construct several independent permutations with just one number between 0 and 1. Can anyone give me a hint on how to find the map?","['permutations', 'statistics', 'machine-learning', 'gradient-descent', 'probability-theory']"
3975330,find the best possible bound for $|f(1/4)|?$,"Given $f$ analytic in $|z| < 2,$ bounded there by $2$ , and such that $f(1) = 0,$ find the best possible bound for $|f(1/4)|?$ My attempt : I found the solution here But this solution is  not correct because it contain some mistake Mistake  is $h(z):=\phi(g(\phi^{—1}(z)))$ doesn't satisfy schwarz lemma  since $h(0)\neq0$ My solution : Take $g(z)= \frac{f(2z)}{2}$ and take $\phi(z)= \frac{z-1/2}{1-1/2z}$ then $\phi^{-1}(z)=\frac{z+1/2}{1+1/2z}    $ take $ h(z)= g \circ  \phi^{-1}(z)  = g(\phi^{-1}(z))$ put $z=0 $ , then $ h(0)=                 g(1/2)  $ we have $ g(1/2)= f(1)/2=0  $ Therefor $h(0)=0 $ , and $h$ satisfy the schwarz lemma  i,e $|h(z)|\le |z|$ This implies  that $| g(z)| \le |\phi(z)| $ $g(1/8)  = \frac{1/8-1/2}{1-1/2.(1/8)} =2/5$ $2.g(1/8)=f(1/4)\implies f(1/4)=\frac{4}{5}   $ so the     the best possible bound for $|f(1/4)|$ is $\frac{4}{5}$ Is my solution is correct or not ?","['complex-analysis', 'solution-verification']"
3975360,"Linear relation between three infinite matrices, the first two are symmetric and the third is a matrix of ones plus a diagonal matrix","For $n\geq 1$ , let $G_n$ be the matrix $G_n=(g(i,j))_{1\leq i,j \leq n}$ where $g(i,j)=\max(i,j)$ if $i\neq j$ and $0$ otherwise. If we define $$A_2=\begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}, B_2=\begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix}, H_2=\begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix} \tag{1}\label{1}$$ Then we have the identities $G_2A_2=2H_2$ and $G_2B_2=2I_2$ . Next, if we consider $$
A_3=\begin{pmatrix}1 & 0 & \frac{1}{3} \\ 0 & 1 & \frac{1}{3} \\ \frac{1}{3} & \frac{1}{3} & \frac{10}{9} \end{pmatrix}, B_3=\begin{pmatrix}0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & \frac{2}{3}\end{pmatrix}, H_3=\begin{pmatrix}0 & 1 & \frac{4}{3} \\ 1 & 0 & \frac{4}{3} \\ 1 & 1 & \frac{1}{3} \end{pmatrix}\tag{2}
$$ Then we have $G_3A_3=I_3+3H_3$ and $G_3B_3=5I_3+3H_3$ . Continuing in this vein, if we put $$
A_4=\begin{pmatrix}1 & 0 & \frac{1}{3} & \frac{7}{12} \\
0 & 1 & \frac{1}{3} & \frac{7}{12} \\
\frac{1}{3} & \frac{1}{3} & \frac{10}{9} & \frac{7}{9} \\ \frac{7}{12} & \frac{7}{12} & \frac{7}{9} & \frac{113}{72} \end{pmatrix}, B_4=\begin{pmatrix}0 & 1 & 1 & \frac{5}{4} \\
1 & 0 & 1 & \frac{5}{4} \\ 1 & 1 & \frac{2}{3} & \frac{5}{3} \\
 \frac{5}{4} & \frac{5}{4} & \frac{5}{3} & \frac{43}{24}\end{pmatrix}, H_4=\begin{pmatrix}0 & 1 & \frac{4}{3} & \frac{11}{6} \\ 1 & 0 & \frac{4}{3} & \frac{11}{6} \\ 1 & 1 & \frac{1}{3} & \frac{11}{6} \\  1 & 1 & \frac{4}{3} & \frac{5}{6} \end{pmatrix}\tag{3}
$$ then $G_4A_4=\frac{10}{3}I_4+\frac{16}{3}H_4$ and $G_4B_4=10I_4+8H_4$ . We can now formulate the following conjecture : there are three infinite matrices $A_{\infty}=(a(i,j))_{i,j\in {\mathbb N}}$ , $B_{\infty}=(b(i,j))_{i,j\in {\mathbb N}}$ and $H_{\infty}=(h(i,j))_{i,j\in {\mathbb N}}$ , such that if we denote by $A_n,B_n,H_n$ respectively the upper-left corner submatrices of those matrices (so that $A_n=(a(i,j))_{1\leq i,j \leq n}$ , and so on), then $A_{\infty}$ and $B_{\infty}$ are symmetric (i.e. $a(i,j)=a(j,i),\  b(i,j)=b(j,i)$ ) $h(i,j)=h(j,j)+1$ when $i\neq j$ $A_2,B_2$ and $H_2$ are given by \eqref{1} above, For every $n$ , one has constants $a_n,b_n$ such that $G_nA_n=a_nI_n+(a_n+2)H_n$ , $G_nB_n=b_nI_n+(b_n-2)H_n$ . Any ideas on how to prove that conjecture (or find a counterexample) ? Here are a few possibly useful data for small values : $$
\begin{array}{|c|c|c|c|c|c|c|c|c|c|}
\hline
n & 2 & 3 & 4 & 5 & 6  & 7 & 8 & 9 & 10 \\
\hline
a_n & 0 & 1 & \frac{10}{3} & \frac{91}{12} & \frac{73}{5}  & \frac{9199}{360}   & \frac{13232}{315} &  \frac{147879}{2240}  & \frac{129929}{1296} \\
\hline
b_n & 2 & 5 & 10 & \frac{73}{4} & \frac{175}{5}  & \frac{6197}{120}   & \frac{1228}{15} &  \frac{40273}{320}  & \frac{81427}{432} \\
\hline
h(n,n) & 0 & 0 & \frac{1}{3} & \frac{5}{6} & \frac{3}{2} & \frac{85}{36}  & \frac{871}{252}   & \frac{1083}{224} &  \frac{118939}{18144}  \\
\hline
\end{array}
\tag{4}
$$ Other things I noticed : All the entries of $A_{\infty},B_{\infty}$ and $H_{\infty}$ seem to be positive rationals, except for the zeroes from $A_2,B_2,H_2$ . If we exclude the upper-left $2\times 2$ square, the first two rows of $A_n$ are identical ; same property for $B_n$ .","['symmetric-matrices', 'linear-algebra', 'sequences-and-series']"
3975368,Approach ideas for the integral $\int\frac{dx}{(x^4-16)^2}$,"Well, the title sums it up pretty well. I'm in search for some smart approach ideas for solving this indefinite integral: $$\int\frac{dx}{(x^4-16)^2}$$ I know one that would work for sure, namely partial fraction decomposition, but it gets really heavy when regrouping the coefficients for the powers of $x$ and then solving an $8\times8$ system of linear equations. It will eventually work, but I suspect there is something more ingenuine behind this problem. I also tried all sorts of trigonometric substitutions and formulations, but that added square power really is a bummer to it all. I'm generally open to any exchange on the topic and would be glad to hear some advice in such situations. Many thanks in advance!","['integration', 'calculus', 'partial-fractions', 'real-analysis']"
3975440,Finding the dimension of certain tensor product with flat $A$-algebra,"Assume $A$ is a noetherian local ring with $\mathfrak{m}_y$ being the unique maximal ideal and $\dim A=0$ .  We have the exact sequence $$0\to \mathfrak{m}_y\to A\to k(y)\to 0,$$ where $k(y)$ is the residue field $A_{\mathfrak{m}_y}/\mathfrak{m}_y$ . Let $B$ be a finitely generated flat $A$ -algebra by $\phi:A\to B$ , then $$0\to \mathfrak{m}_y\otimes_A B\to B\to k(y)\otimes_A B\to 0$$ is an exact sequence of $A$ -algebra. From the fact that $\dim A=0$ , $\mathfrak{m}_y$ is nilpotent. Let $\phi^{-1}(\mathfrak{p}_x)=\mathfrak{m}_y$ for a prime ideal $\mathfrak{p}_x$ in $B$ . My question is: Why would this implies $$\dim (k(y)\otimes_A B)_{\mathfrak{p}_x}=\dim B_{\mathfrak{p}_x}?$$ An approach that I can think of is to consider the dimension of the objects in the second exact sequence above. But is it true that $\dim (\mathfrak{m}_{y}\otimes_A B)_{\mathfrak{p}_x}=0$ and does it make sense? This question will be helpful in understanding Hartshorne III.9.5, the dimension formula of fiber of flat morphism.","['algebraic-geometry', 'flatness', 'commutative-algebra']"
3975453,"Is it possible for $x_{n+1}-x_{n}$ to converge to $0$, but the limit of $x_n$ to not exist?","I was reading about subsequences today and I came across an example which said the if $x_{n+1}-x_{n}$ converges to $0$ , it's possible for $x_n$ to not have a finite limit (for example if we take $x_n$ to be the harmonic series). But then I thought ""is it possible for the limit of $x_n$ to not exist at all ?"" and I think the answer is no,because I couldn't find any examples, but I am not sure. Could you please tell me what your opinion is on this? Thanks in advance!","['analysis', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
3975476,"$\int x^{2}\sqrt{a^{2}+x^{2}}\,dx$. Is there another way to solve it faster?","I have to calculate this integral: \begin{align} \int x^{2}\sqrt{a^{2}+x^{2}}\,dx \qquad\text{with}
\quad a \in \mathbb{R} \end{align} My attempt: Using, trigonometric substitution \begin{align}
\tan \theta &= \frac{x}{a}\\ \Longrightarrow  \ x&=a \tan \theta\\ \Longrightarrow  \ dx&=a \sec^{2}\theta\\ \Longrightarrow \ x^{2}&=a^{2}\tan^{2}\theta
\end{align} Thus, \begin{align}
\int x^{2}\sqrt{a^{2}+x^{2}}\,dx&=\int a^2 \tan^{2}\theta \sqrt{a^2+a^2\tan^{2}\theta}\ a\sec^{2}\theta\, d \theta\\&=a^{3}\int \tan^{2}\theta \sqrt{a^{2}(1+\tan^{2}\theta)}\sec^{2}\theta\, d\theta\\&=a^{3}\int \tan^{2}\theta \sqrt{a^{2}(\sec^{2}\theta)}\sec^{2}\theta \, d\theta\\&=a^{4}\int (1-\sec^{2}\theta)\sec^{3}\theta \, d\theta\\&=a^{4}\underbrace{\int \sec^{3}\theta \, d\theta}_{\text{solve by parts}}-a^{4}\underbrace{\int \sec^{5}\theta \, d\theta}_{\text{solve by parts}}
\end{align} My doubt is: Is there any other way to solve it faster? Because by parts is a large process to solve each one. I really appreciate your help","['integration', 'calculus', 'trigonometric-integrals']"
3975482,Can we define a topology on $\mathbb{R}^2$ using lines instead of circles or squares?,"Does it make sense to define a topology on the coordinate grid $\mathbb{R}^2$ using the horizontal and vertical lines as ""building-blocks""? $B_{1, y} = \{ (x,y): y \in \mathbb{R} \}$ vertical lines are closed $B_{2, x} = \{ (x,y): x \in \mathbb{R} \}$ horizontal lines are closed The definition of basis of Topology is a collection of open sets: the base elements cover $X = \mathbb{R}^2$ let $B_1$ and $B_2$ be the basis elements and $I = B_1 \cap B_2$ the there exists a $B_3$ such that $z \in B_3 \subseteq I = B_1 \cap B_2$ . Basically my question is that if we use a basis other than squares or circles can we change the topology of $\mathbb{R}^2$ .  Here we coudl write one possible basis for the Euclidean topology : $B_{(x_0, y_0), \epsilon} = \{ (x^2 - x_0)^2 - (y - y_0)^2 < \epsilon  \}  $ if we have two  bases $(\mathbb{R}^2, \mathcal{B}_1)$ $ (\mathbb{R}^2, \mathcal{B}_2)$ can these two copies of the plane be homeomorphic. This matches the definition on p. 78 of Munkres.  We can define the topology generated by a basis $\mathcal{B}$ .  A subset $U \subseteq X$ is open if for any $x \in U$ there is a basis element $B \in \mathcal{B}$ such that $x \in B \subset U$ . On the next page, he shows that from the basis $\mathcal{B}$ the collections of sets $U$ is a topology. Example:  check that $U_1 \cap U_2 \in \mathcal{T}$ (the intersection of open sets is open).  Given $x \in U_1 \cap U_2$ we can find $x \in B_1 \subset U_1$ and $x \in B_2 \subset U_2$ and then $x \in B_3 \subset B_1 \cap B_2 \subset U_1 \cap U_2$ .  Our open sets might be irregular and yet the basis elements are quite standard. Possible I have to change my question to define a basis of open sets rather than closed .  We do have the result that if $U$ is open then $X \backslash U$ is closed. Related Why $B_3 \subset B_1 \cap B_2$ in the definition of a basis for a Topology in Munkres' Book?",['general-topology']
3975503,Trouble with $I(\alpha) = \int_0^{\infty} \frac{\cos (\alpha x)}{x^2 + 1} dx$,I'm ultimately trying to solve $$I(\alpha) = \int_0^{\infty} \dfrac{\cos (\alpha x)}{x^2 + 1} dx$$ by using differentiation under the integral. I realize that this is most easily done using residues but I'm intending this problem to introduce my advanced calculus 2/differential equations students to some interesting techniques before they take real analysis. Differentiating under the integral a first time leads to $$I'(\alpha) = \int_0^{\infty} \dfrac{-x \sin (\alpha x)}{x^2 + 1} dx = - \dfrac{\pi}{2} + \int_0^{\infty} \dfrac{\sin (\alpha x)}{x(x^2 + 1)}dx$$ by making use of the Dirichlet integral and again to $$I''(\alpha) = \int_0^{\infty} \dfrac{\cos (\alpha x)}{x^2 + 1} = I(\alpha)$$ To solve this second-order ODE we'll need two initial conditions. The integral for $I'(\alpha)$ leads to the incorrect result $I'(0) = 0$ but the rewritten version leads to the correct result of $I'(0) = -\dfrac{\pi}{2}$ . I'm having trouble justifying this. Any help or guidance is appreciated. I'll also settle for simpler arguments as to why $I'(0) \neq 0$ .,"['derivatives', 'leibniz-integral-rule']"
3975527,Convergence of $\sum^\infty_{n=0} \frac{\cos(n + \frac{1}{n^2})}{n \cdot \ln(n^2 + 1)}$ Is my idea correct?,Convergence: $$\sum^\infty_{n=0}\frac{\cos \left(n + \frac{1}{n^2} \right)}{n \cdot \ln \left( n^2 + 1 \right)}$$ Edit (I tried to follow the idea written by @Daniel Fischer): $$\sum_{n=0}^{\infty} \frac{cos(n + \frac{1}{n^2})}{n\cdot ln(n^2 + 1)} = \sum_{n=0}^{\infty} \frac{cos(n)}{n \cdot ln(n^2 + 1)} + \sum_{n=0}^{\infty} \frac{cos(n + \frac{1}{n^2}) - cos(n)}{n \cdot ln(n^2 + 1)}$$ $\sum_{n=0}^{\infty} \frac{cos(n)}{n \cdot ln(n^2 + 1)}$ is convergent because of Dirichlet test and How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? $\sum_{n=0}^{\infty} \frac{cos(n + \frac{1}{n^2}) - cos(n)}{n \cdot ln(n^2 + 1)} = \sum_{n=0}^{\infty} \frac{-2 \left(sin \left( \frac{2n+\frac{1}{n^2}}{2} \right) \cdot sin \left( \frac{\frac{1}{n^2}}{2} \right) \right)}{n \cdot ln \left(n^2 + 1 \right)} = \sum_{n=0}^{\infty} \frac{-2 \left(sin \left( n+\frac{1}{2n^2} \right) \cdot sin \left( \frac{1}{2n^2} \right) \right)}{n \cdot ln \left(n^2 + 1 \right)}$ Then: $$\sum_{n=0}^{\infty} \left| \frac{-2 \left(sin \left( n+\frac{1}{2n^2} \right) \cdot sin \left( \frac{1}{2n^2} \right) \right)}{n \cdot ln \left(n^2 + 1 \right)} \right| \leq \sum_{n=0}^{\infty} \left| 2 \cdot \frac{ \frac{1}{2n^2} }{n \cdot ln \left(n^2 + 1 \right)} \right| \leq \sum_{n=0}^{\infty} \left| \frac{ 1 }{n^3 \cdot ln \left(n^2 + 1 \right)} \right| $$ For $n \geq 3$ : $$\sum_{n=0}^{\infty} \left| \frac{ 1 }{n^3 \cdot ln \left(n^2 + 1 \right)} \right| \leq \sum_{n=0}^{\infty} \left| \frac{1}{n^2} \right|$$ Therefore we know that $\sum_{n=0}^{\infty} \frac{cos(n + \frac{1}{n^2}) - cos(n)}{n \cdot ln(n^2 + 1)}$ it is also convergent. Is that correct?,"['analysis', 'real-analysis']"
3975531,Computing the number of conjugacy-classes in $GL_{n}(\mathbb{F}_{p})$ of elementary abelian p-subgroups by GAP and Magma,"I'm trying to compute the number of conjugacy-classes of elementary abelian p-subgroups of rank $2$ in $GL_{n}(\mathbb{F}_{p})$ by GAP and Magma. So I consider the following GAP function: myfunction:= function(n,p)
local G, S, cclS, cclG;
  G := Image(IsomorphismPermGroup(GL(n,p)));
  S := SylowSubgroup(G,p); 
  cclS := Filtered(ConjugacyClassesSubgroups(S),
    cl->Size(Representative(cl))=p^2
    and not IsCyclic(Representative(cl)));
  cclG := List(EquivalenceClasses(cclS,
    function(cl1,cl2)
      return IsConjugate(G,Representative(cl1),
        Representative(cl2));
  end),Representative);
  cclG := List(cclG,cl->Representative(cl)^G);
  return Sum(List(cclG,Size));
end; Questions: Is there something I missed in this algorithm? Is there a similar algorithm with  Magma which give the required computation? Thank you in advance.","['gap', 'magma', 'combinatorics', 'computer-algebra-systems', 'group-theory']"
3975535,"Is there a reason the word ""collection"" is used in Heine-Borel theorem to describe an open covering instead of ""set""?","The Heine-Borel theorem is stated as follows: Suppose $\mathcal{H}$ is an open covering of a compact set $S \subseteq \mathbb{R}$ . Then $S$ is of an open covering $\tilde{H}$ consisting of finitely many open sets belonging to $\mathcal{H}$ . Here, an open covering $\mathcal{H}$ of $S$ is defined as a collection of open sets such that every point $s \in S$ can be found in a set $H \in \mathcal{H}$ . I am wondering if there is a specific reason why $\mathcal{H}$ is called a collection instead of a set. If this $\mathcal{H}$ cannot be constructed using rules from the set theory, how to interpret the use of it?","['elementary-set-theory', 'terminology']"
3975602,Chi Squared Clarification,"Suppose you have $Z_1, Z_2, Z_3$ which are all independent standard Gaussian variables. Suppose you have $$A=\frac{(Z_1-2Z_2+Z_3)^2}{12}+\frac{(Z_1-Z_3)^2}{4}+\frac{(Z_1-Z_2)^2}{4}+\frac{(Z_1+Z_2-2Z_3)^2}{12}.$$ $A$ is $\chi_2^2$ , but I don't see how this is the case.
Particularly since $\operatorname{Var}\left(\frac{Z_1-2Z_2+Z_3}{\sqrt{12}}\right)$${}=\frac{1}{2}$ , which is the same issue with the other terms, i.e since none of the terms, by themselves, are standard normal before you square them.
However, I do see how: $$B=\frac{(Z_1-2Z_2+Z_3)^2}{6}+\frac{(Z_1-Z_3)^2}{2}.$$ follows the $\chi_2^2$ distribution. I can also see that the first two terms of $A$ multiplied by $2$ is equal to $B.$ Any feedback would be appreciated.","['statistics', 'normal-distribution', 'chi-squared', 'gaussian', 'probability']"
3975661,Calculate radius of an equilateral triangle such that its edges intersect with points of a smaller internal equilateral triangle.,"If I have an equilateral triangle (the black one), with a known circumscribed circle radius R = h1 , and a known angle θ , how can I find the value h2 , which is the R for the outer equilateral triangle with edges that intersect with the points of the inner triangle? I'm using this for a generative art project where I want a sequence of nested triangles.","['trigonometry', 'geometry']"
3975665,Some horrid integrals I am confused with,"$$(1) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x} + 1}{x^3 + 1}}~~dx$$ Speaking as an example on (1). The only thing I could do from here is only to do a u-sub: $$ u = \ln(x) + 1 \\ x = e^{u-1} \\ du = \frac{1}{x} dx \\ dx = x (du) \Rightarrow dx = e^{u-1} (du) $$ And so this becomes: $$ \int \sqrt{ \frac{u}{e^{3u-3} + 1} } ~~ du \\ $$ And from here it's basically a deadend.. I would appreciate if you could give some insights.. Interestingly, these similar integrals have interesting solutions: $$(2) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x} +1}{x^3}}~~dx =  \sqrt{2 e \pi}$$ $$(3) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x}}{x^3 + 1}}~~dx = \text{a complex number ?!}$$ (2) - where and why does the pi comes into play? this looks like an interesting solution.. (3) - why is the solution a complex number if the area is right infront my eyes, and it is real just like every other areas? What is happening here? Mystery solved about the complex number - the lower bound should be $1$ and not $1/e$ my bad! But this is not the main mystery ;) Thank you :-)","['integration', 'calculus']"
3975682,Proof of non-reflexivity of $l^\infty$ by finding a bounded sequence such that it contains no weakly convergent subsequence,"I want to prove that $l^\infty$ is not reflexive, however I do not want to check why canonical inclusion of $l^\infty$ to $(l^{\infty})^{**}$ is not an isometric isomorphism. I know that if a normed space is reflexive then every bounded sequence of its elements has weakly convergent subsequence. In the case of $l^\infty$ which sequence should I take to break this property? Thank you.","['banach-spaces', 'normed-spaces', 'functional-analysis', 'reflexive-space']"
3975703,Maclaurin of $f(x)=\ln\left(\sum_{k=0}^{1000}\frac{x^k}{k!}\right)$,"The 1001st order is required. Here is how I went about the question: We know that near $x=0$ : $$e^x=\sum_{k=0}^{1000}\frac{x^k}{k!}+\frac{x^{1001}}{1001!}+o(x^{1001})$$ So, $$e^x-\frac{x^{1001}}{1001!}+o(x^{1001})=\sum_{k=0}^{1000}\frac{x^k}{k!}$$ And after taking the logarithm of both sides, $$f(x)=\ln\left(e^x-\frac{x^{1001}}{1001!}+o(x^{1001})\right)$$ But what do I do next? I intuitively understand that the answer should be: $$f(x)=x-\frac{x^{1001}}{1001!}+o(x^{1001})$$ But how do I prove it rigorously? Thank you!","['calculus', 'functions', 'taylor-expansion', 'real-analysis']"
3975717,Do exponents in tropical polynomials have to be integers?,"Recently I've been learning about tropical geometry, and every time I see a definition of a tropical polynomial in e.g. $k$ variables $x_1,x_2,...,x_k$ such as $\bigoplus_{i=1}^n a_i x_1^{b_{i1}}x_2^{b_{i2}}...x_k^{b_{ik}}$ , it usually defines the exponents to be integral. Would it be incorrect to define a tropical polynomial with say rational or real valued exponents? Would the object we get by doing so lose any of the nice properties of tropical polynomials? As far as I can tell the definitions would still work out fine.","['algebraic-geometry', 'abstract-algebra', 'tropical-geometry', 'real-algebraic-geometry']"
3975734,precompact coordinate ball v.s. regular coordinate ball,"I was reading Lee's smooth manifold book,there are two different theorem for basis on the manifold one state that : Every topological manifold has countable basis of precompact coordiante basis Anonther one is given as follows: Every smooth manifold has countable basis of regular coordinate ball. Note that the regular coordinate ball needs the chart map be smooth,except this restrition it seems the main condition for regular coordinate ball :given regular coordinate ball $B'$ exist a larger open ball $B$ that $\overline{B'}\subset B$ , need not the condition that manifold is smooth.It seems only depend on the Euclidean topology? What makes these two theorem difference?Why one is stated in smooth manifold while the other is given in topological manifold?","['smooth-manifolds', 'differential-geometry']"
3975737,"Is $\emptyset \subseteq P(A)$ or $\{\emptyset\}\subseteq P(A)$, where $A$ is a set and $P(A)$ is the power set of $A$","I think my professor made an error on his answer key and I'm trying to confirm it before I bring it to his attention. He asserts only 1.) is false. I believe both 1 and 4 are false. This class is only using naïve set theory. $A = \{1,2,3,4\}$ Select the statement that is false 1.) $\{2,3\} \subseteq P(A)$ 2.) $\{2,3\} \in P(A)$ 3.) $ \emptyset \in P(A)$ 4.) $\emptyset \subseteq P(A)$ $P(A)$ is the set of all the subsets of $A$ $P(A) = P(A) = \{\emptyset,\{1\},\{2\},\{3\},\{4\},\{1,2\},\{1,3\},\{1,4\},\{2,3\},\{2,4\},\{3,4\},\{1,2,3\},\{1,2,4\},\{1,3,4\},\{2,3,4\},\{1,2,3,4\}\}$ FALSE $2$ is not an element of $P(A)$ $3$ is not an element of $P(A)$ ∴ $\{2,3\}$ cannot be a subset of $P(A)$ $\{{2,3}\}$ would be a subset of $P(A)$ TRUE The element $\{2,3\}$ can be found in the set $P(A)$ TRUE The element $\emptyset$ can be found in the set $P(A)$ FALSE Both operands of the subset operator requires a set. $\emptyset$ is the empty set were as $\{\emptyset\}$ is an element that is the empty set. Therefore $\emptyset$ is not a subset of $P(A)$ .","['elementary-set-theory', 'discrete-mathematics']"
3975742,A problem about probability theory and set theory,"I'm studying the fact that if $\lambda \in (0,1)$ and $\{Y_{n}\}_{n\geq 1}$ is a sequence of i.i.d. random variables such that $Y_{i}\sim \mathrm{Bernoulli}(\lambda)$ defined in the space $(X, E, P)$ , then $X$ is necessarily uncountable. Approach: Suppose by way of contradiction that $X$ is a countable set. Then we have $X=\{ x_{n} | n\in \mathbb{N},~x_{n} \in \{0,1\} \}$ . Then $\displaystyle X= \bigcap_{n\geq 1} (Y_{n}=x_{n}) \subset T_{k}= \bigcap_{1\leq n \leq k} (Y_{n}=x_{n})$ for all integer $k\geq 1$ . Now maybe I need to look at suitable $k$ ? But how can I continue from here? Maybe a way to complete the proof, in $X$ either the number of ones or zeros is infinite, assume Wlog the we have infinitely many ones?","['independence', 'probability-theory']"
3975777,When does the sequence $1_{A_n} - 1_{A_n ^C}$ weakly converge to $0?$,"Let $(\Omega,f,p)$ be an abstract probability space. Consider the variables $$ X_n = 1_{A_n} - 1_{A_n^C} \in L^p(\Omega)$$ I am interested in charactarizing when $X_n \to 0$ weakly, meaning that $E[Y X_n]\to 0$ for any $Y \in L^q(\Omega).$ If we have that $P(A_n) = \frac{1}{2}$ and they are independent, then $(X_n)_n$ will become an orthonormal sequence. That is $E[X_n X_m] = 0 $ for $n \not = m$ and $E[X_n X_n] =1.$ By weakly compactness of the unit ball, $(X_n)_n$ must at least have a weakly convergent subsequence etc. I believe the weak limit of $X_n$ will be $0$ in this case. We also do not worry too much about what happens in the beginning, so I think it might suffice if one 'eventually approximately' has $P(A_n) = \frac{1}{2}$ and $A_n s$ are 'eventually' independent. So far I have derived some necessary conditions $\colon$ For $Y=1,$ $E[Y X_n] = E[1_{A_n} - 1_{A_n^C}] = P(A_n) - P(A_n^C) \to 0.$ Hence one should have $P(A_n) \to \frac{1}{2}.$ For $Y=1_B,$ $$E[Y X_n] = E[1_B (1_{A_n} - 1_{A_n^C})] = E[1_{B\cap A_n} - 1_{B \cap A_n^C}] = P(B\cap A_n) - P(B \cap A_n^C) \to 0.$$ Hence one should have $P(B\cap A_n) \to \frac{P(B)}{2}.$ Another way of expressing this is that $E[1_B 1_{A_n}]  \to \frac{E[1_B]}{2}.$ In other words, $E[1_B | A_n]  \to E[1_B],$ which can be generalized as $E[Y| A_n]  \to E[Y],$ for any $Y \in L^q(\Omega).$ Back to $P(B\cap A_n) \to \frac{P(B)}{2} \colon$ Intuitively, $A_n$ eventually divide all the sets equally. Another way of seeing this is that $P(B\cap A_n) - P(B) P(A_n) \to 0.$ If we consider this for $B= A_1,$ one has $P(A_1 \cap A_n) - P(A_1) P(A_n) \to 0.$ Similarly for $k_1 \leq \cdots \leq k_m,$ one would have $$ P(A_{k_1} \cap \cdots \cap A_{k_m}) - P(A_{k_1}) \cdots P(A_{k_m}) \to 0  $$ as $k_1 \to \infty.$ This looks like the notion of being eventually independent, or eventually approximately independent if there is one. I have searched for generalizations of Borel Cantelli lemma, yet have not encountered conditions replacing independence, which covers the above case. How can I obtain a complete chracterization of $X_n \to 0$ weakly (when $\Omega$ is nonatomic)? Btw this reminds me of the coin-tossing experiment, where one tosses a fair coin indefinitely and $A_n$ is the event that the $n$ th tossing is heads, or variations of this.","['borel-cantelli-lemmas', 'independence', 'probability-theory', 'weak-convergence']"
3975804,"Real-life, every day applications of number theory?","Are there any day to day situations in which number theory could be applied to? For example, I was trying to make a mosaic and I realized that diophantine equations could be really useful if I needed to find how many pieces of certain dimensions needed to be used. Are there any other real life situations in which number theory would be useful?","['number-theory', 'applications']"
3975812,Combinatorial proof of ${2n\choose n}n!\le (2n)^{n}$,Initially I was supposed to prove the proposition $n^n\ge \prod_{r=1}^{r=n}(2r-1)\forall n\in\mathbb{N}$ . So I have basically simplified this question down to proving ${2n\choose n}n! \le (2n)^{n}$ by carrying out the following operations. $$\begin{aligned}n^{n}\prod_{r=1}^{n}2r&\ge \prod_{r=1}^{n}(2r-1)\prod_{r=1}^{n}2r\\ 2^{n}n^nn!&\ge(2n)!\\ (2n)^{n}&\ge {2n\choose n}n!\end{aligned}$$ Any ideas on how to prove this inequality. The right side of the inequality represents the arrangement of $n$ objects chosen out of $2n$ object. And the left side represents the arrangement of $n$ objects into $2n$ vacancies. Any hints are appreciated. Thanks.,"['inequality', 'solution-verification', 'combinatorics']"
3975853,Application of Sylow Theorems to groups of order $pq^2r$,"Suppose G is a group of order $pq^2r$ , where $p,q,r$ are primes and $p  < q < r.$ Suppose further that $q^2 \not\equiv 1\pmod{r}$ , $pq^2 \not\equiv 1\pmod{r}$ , and $\gcd(q,r-1) = 1$ . Show that either $G$ contains a unique Sylow $r$ -subgroup, or that $Z(G)$ contains an element of order $q$ . Here is my attempt at the problem. Striving for a contradiction, suppose that neither $G$ has a unique Sylow $r$ -subgroup, nor does $Z(G)$ have an element of order $q$ . By the third part of Sylow's Theorem, $n_r \equiv 1\pmod{r}$ and $n_r \in \{1,p,q,q^2,pq,pq^2\}$ . By our assumption that $G$ does not have a unique Sylow $r$ -subgroup, we cannot have $n_r = 1$ . We cannot have $n_r = p$ , since $p \not\equiv 1\pmod{r}$ , and similarly $n_r \neq q.$ Furthermore, by our hypotheses that $q^2, pq^2 \not\equiv 1\pmod{r}$ , we deduce by exhaustion that $n_r = pq.$ Next, we look at possible values for $|Z(G)|.$ By Lagrange's Theorem, we have $|Z(G)| \in \{1,p,q,q^2,r,pq,pq^2,pr,qr,q^2r,pqr,pq^2r\}.$ By Cauchy's Theorem, combined with our assumption that $Z(G)$ contains no element of order q, we immediately reduce this set of possibilities to $\{1,p,r,pr\}.$ Now suppose $R \in \text{Syl}_r(G)$ . Then $[G:N_G(R)] = n_r = pq$ implies $|N_G(R)| = qr$ . Since $Z(G) \leq N_G(R)$ , we must have $|Z(G)|$ divides $qr$ . Thus $|Z(G)| \in \{1,r\}$ . But if $|Z(G)| = r$ , then $Z(G)$ is a normal Sylow $r$ -subgroup, which would imply $n_r = 1$ , a contradiction. We deduce that $G$ has trivial center. Finally, if we look at $n_q$ , we see that $n_q \in \{1,p,r,pr\}$ . Since $n_q \equiv 1\pmod{q}$ , we cannot have $n_q = p$ . If $n_q = r$ , then we may write $r = 1 + kq$ for some $k \in \mathbb{Z}$ . But then $r-1 = kq$ , which implies that $q = \gcd(q,r-q)$ , a contradiction. Thus either $n_q = 1$ or $n_q = pr.$ From here I'm kind of stuck.","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
3975889,Pullback of an $n$-form by the inclusion map.,"Let $\Omega = dx^1 \wedge \ldots \wedge dx^n$ an $n$ -form on $\mathbb R^n$ and $$\alpha = \sum_{j = 1}^n (-1)^{j-1}x^j dx^1 \wedge \ldots \wedge dx^{j-1} \wedge dx^{j+1}\wedge \ldots \wedge dx^n.$$ In order to prove Brouwer fixed point, I've to show that for every smooth function $F: B^n \to \mathbb S^{n-1}$ , with $B^n$ the unit ball in $\mathbb R^n$ , such that $F(x) = x$ for all $x \in \mathbb S^{n-1} \subset B^n$ , we have $d(F^* \circ \iota^*)(\alpha) = 0$ where $\iota: \mathbb S^n \to \mathbb R^n$ is the inclusion map. Since the exterior derivative commute with the pullback, I find $$d(F^* \circ \iota^*)(\alpha) = (F^* \circ \iota^*)(d\alpha)= n (F^* \circ \iota^*)(\Omega).$$ Now here is my problem: As $\Omega$ is an $n$ -form on $\mathbb R^n$ , $\iota ^* \Omega$ is an $n$ -form on $\mathbb S^{n-1}$ which is zero because the dimension $\mathbb S^{n-1}$ is $n-1$ . Is this argument correct ? It seems too easy, I didn't use anywhere the fact $F|_{\mathbb S^{n-1}} = \text{Id}_{\mathbb S^{n-1}}$ . More generally, if we've $N \subset M$ with $\dim N = n < \dim M = m$ , does the pullback by the inclusion map of a $k$ -form (for $k > n$ ) always vanishes ?","['pullback', 'differential-forms', 'differential-geometry']"
3975895,"Let $a,b,c\in\mathbb{Z}$, $1<a<10$, $c$ is a prime number and $f(x)=ax^2+bx+c$. If $f(f(1))=f(f(2))=f(f(3))$, find $f'(f(1))+f(f'(2))+f'(f(3))$","Let $a,b,c\in\mathbb{Z}$ , $1<a<10$ , $c$ is a prime number and $f(x)=ax^2+bx+c$ . If $f(f(1))=f(f(2))=f(f(3))$ , find $f'(f(1))+f(f'(2))+f'(f(3))$ My attempt: \begin{align*}
f'(x)&=2ax+b\\
(f(f(x)))'&=f'(f(x))f'(x)\\
f'(f(x))&=\frac{(f(f(x)))'}{f'(x)}\\
\end{align*}","['calculus', 'quadratics', 'derivatives', 'polynomials']"
3975947,Why do we take the derivative as zero in this question?,"Today, I was solving this KVPY-SA 2017 Question : In an isosceles trapezium, the length of one of the parallel sides, and the lengths of the non-parallel sides are all equal to $30$ . In order to maximize the area of the trapezium, the
smallest angle should be: A) $π/6$ B) $π/4$ C) $π/3$ D) $π/2$ So, I took the angle as $θ$ and after that I found the Area by using the $sin$ and $cos$ functions like this: $$A=900\sin\theta(\cos\theta + 1)$$ And after that I found the derivative of area like this: $$\begin{align*}\frac{dA}{d\theta} &= \frac{d}{d\theta}[900(\sin\theta)(1+\cos\theta)]\\
&= 900\left[(\sin\theta)\frac{d}{d\theta}(1+\cos\theta)+(1+\cos\theta)\frac{d}{d\theta}(\sin\theta)\right]\end{align*}$$ And after many steps I reached here where I put the derivative as equal to $0$ : $$\frac{dA}{d\theta} =900[\sin\theta\cdot(-\sin\theta)+(1+\cos\theta)\cdot(\cos\theta)]=0$$ I don't know why I should put it equal to $0$ but that's how you find the answer. When I searched for answers on google I found this solved paper by Byju's. In their answer, you would see that they've written: Differentiating both sides with respect to $\theta$ , $$\frac{dA}{d\theta} = 900[{\sin\theta\cdot(–\sin \theta) +(1 + \cos\theta)\cdot\cos\theta }] = 0\text{ (for critical points)}$$ What did they mean by differentiation = $0$ for critical points? You know, I'm very bad at calculus so please forgive me if this is a dumb question. Edit: What I did after putting the derivative= $0$ :- $$-sin²\theta+cos\theta+cos²\theta=0$$ $$⇒cos²\theta-1+cos\theta+cos ²\theta=0$$ $$⇒2cos²\theta+cos\theta-1=0$$ $$⇒2cos²\theta+2cos\theta-cos\theta-1=0$$ $$⇒2cos\theta(cos\theta+1)-1(cos\theta+1)=0$$ $$⇒(2cos\theta-1)(cos\theta+1)=0$$","['calculus', 'derivatives']"
3975949,Eliminate $\theta$ and prove $x^2+y^2=1$,We have: $${ \begin{cases}{2x=y\tan\theta+\sin\theta} \\ {2y=x\cot\theta+\cos\theta}\end{cases} }$$ And want to prove $x^2+y^2=1$ My works: I multiplied first equation by $\cos\theta$ and second one by $\sin\theta$ and get: $${ \begin{cases}{2x\cos\theta=y\sin\theta+\sin\theta\cos\theta} \\ {2y\sin\theta=x\cos\theta+\sin\theta\cos\theta}\end{cases} }$$ By extracting $\sin\theta\cos\theta$ we get: $$2x\cos\theta-y\sin\theta=2y\sin\theta-x\cos\theta$$ $$x\cos\theta=y\sin\theta$$ But I don't know whether this helps or not.,"['algebra-precalculus', 'trigonometry']"
3975982,Why is this diagonal matrix not possible over the reals,"Let $\alpha = \begin{pmatrix}
7 &3  &-4 \\ 
 -2&-1  &2 \\ 
 6&2  &-3 
\end{pmatrix}$ over the reals. Show that there does not exist a invertible real matrix $\beta$ , so that $\delta = \beta ^{-1} \alpha \beta$ is a diagonal matrix My ""proof"" the characterisitc polynomial is $-\lambda ^3 + 3\lambda ^2 -\lambda + 3=-(\lambda - 3)(\lambda ^2 +1)$ . The solutions would then be $3,i,-i$ . Now, we have that $\delta = \beta ^{-1} \alpha \beta$ where the diagonal values of $\delta$ would then be eigenvalues of $\alpha$ . if both $\alpha , \beta$ are real $3 \times 3$ -matrices then $\delta$ must also be a real $3 \times 3$ -matrix. But that is not possible since the eigenvalues of $\alpha$ are $3,i,-i$ and thus $\beta$ must be complex..... Now I am stuck since I would think I would have to show that the diagonal of $\delta$ must be the eigenvalues of $\alpha$ . Is this a generel fact or should this be proven? If so - how?","['matrices', 'diagonalization', 'linear-algebra']"
3975997,"MLE for $p$ in Geometric distribution from Exponential distribution (two methods, two results)","Let $Y_n$ given as $\mathrm{ceil}(X_n)$ , where $\mathrm{ceil}(x):=$ the least integer greater than or equal to $x$ and $(X_n)$ is a sequence of iid random variables from $\mathrm{Exp}(\theta),~\theta>0$ . Then $Y_n\sim Geo(p)$ , where $p=p(\theta):=1-e^{-\theta}$ and since the maximum likelihood estimator (mle) for $\theta$ is given as $\frac{1}{\overline{X}}$ , the mle for $p(\theta)$ is $1-e^{-\frac{1}{\overline{X}}}$ . If we compute directly the mle for $p$ using $\mathbb{P}(Y_1=y)=(1-p)^{y-1}p$ for $y\in \mathbb{N}$ , we get that the maximum likelihood estimator for $p$ is given as $\frac{1}{\overline{Y}}=\frac{1}{\overline{\mathrm{ceil}(X)}} $ , which is not the same as the previous result. Is there some contradiction in these two results, or some fallacy? Thank for the help.","['statistics', 'parameter-estimation', 'probability']"
3976014,diameter and radius in graph and disconnected graph,"We have an undirected Graph $G$ . Def $1$ : The diameter of a graph is defined as the maximum of shortest paths between two vertices of $G$ . Def $2$ : we define $L(S)$ as maximum length of shortest paths from $S$ to other vertices. Def $3$ : we define the radius of a graph as minimum value of $L(S)$ between all vertices in $G$ . If $\mathrm{diam}$ and $\mathrm{rad}$ be diameter and radius of graph which of the following was correct always (choose the best option): $\mathrm{rad} \geq \frac{\mathrm{diam}}{2}$ $\mathrm{rad} \leq \mathrm{diam}$ Answer : 1 is the best option. My question is why the author choose the 1 while 2 is also
true. Then my idea is because in the question there is no assumption
for connected graph so on disconnected graph option 1 can handle $\infty$ but option 2 cannot. I think here by using best option words it means there is a case that we can support by one option and cannot support by another ones. I know both of them is upper and lower bound but here there is a trick
by the words ""best option"". is my conclusion about supporting
disconnected graph is correct and reason for choosing $(1)$ is that support connect and disconnected graph at same time? if no is
there any reasonable logic here?","['trees', 'graph-theory', 'discrete-mathematics', 'algorithms', 'computer-science']"
3976046,Find all positive integer solutions for the following equation $5^a + 4^b = 3^c$:,"Find all positive integer solutions for the following equation: $$5^a + 4^b = 3^c$$ My first guess would be to study the equation in mod, but I tried modulo 3, 4, 5, and 9 and I can't find anything.","['contest-math', 'modular-arithmetic', 'number-theory', 'elementary-number-theory', 'discrete-mathematics']"
3976109,"If $p$ and $q$ are solutions of the equation $x \tan x = 1$, show the integral of $\cos^2 px$ entirely in terms of $p$","I am working through a pure maths text book out of interest. I have finished the chapter on integration and differentiation of trigonometric functions and am  doing the end of chapter questions. This is causing me a problem: Given that $p$ and $q$ are solutions of the equation $x \tan x = 1$ , Find an expression for $\int^1_0 \cos^2 px \ dx$ entirely in terms of $p$ , not involving any trigonometric functions. This is my working so far: if $p$ and $q$ are solutions of $x \tan x = 1$ , $$p\frac{\sin p}{\cos p} = 1$$ $$\cos^2px = \frac{1 + \cos 2px}{2}$$ $$\int \cos^2px ~dx = \frac{1}{2}(x + \frac{\sin 2px}{2p})$$ $$= \frac{1}{2}(\frac{2px + \sin 2px}{2p})$$ I need to find $$\left[ 
    \frac{1}{2}((\frac{2px + \sin 2px}{2p})
   \right]_{0}^1$$ But I cannot arrive at the answer in the book which is: $$\frac{2 + p^2}{2(1 + p^2)}$$","['integration', 'definite-integrals', 'calculus', 'trigonometric-integrals', 'trigonometry']"
3976110,Does Hilbert's Nullstellensatz have something to do with the universal property of polynomial rings?,"One basic slogan of category theory is that a mathematical concept is uniquely defined by a universal property . For example, polynomial rings are uniquely characterized by their universal property . Does this mean that every statement about polynomials can be deduced from this universal property? For example, consider the following statement about polynomials, the so-called Hilbert's Nullstellensatz (formulation copied from The Princeton Companion to Mathematics ): Nullstellensatz. The polynomials $f_1,...,f_m$ have no common complex zero if and only if there are polynomials $g_1,...,g_m$ such that $g_1f_1 +···+ g_mf_m = 1$ . Does this statement have something to do with the universal property of polynomial rings? Or should one distinguish between properties of polynomial rings (these should be derivable from the universal property) and concrete statements about polynomials such as Hilbert's Nullstellensatz?","['algebraic-geometry', 'polynomials', 'category-theory']"
3976128,Expected value of sum of two dependent Binomial variables,"Question: Assume we toss a coin in two trials. In the first trial we toss it n times. In the second trial we toss it as many as the number of tails observed in the first trial. Calculate the expectation of total number of tails in both trails: Solution : This is what I have tried but can't find any closed form for the answer when n is not given. I am not sure if I have taken the right approach: $T_1$ = Number  of  tails in the 1st trial $T_2$ =  Number of tails in the 2nd trial T1 ~ Binomial(n,p) T2 ~ Binomial(T1,p) $E(T1 + T2) = 
E(T1) + E(T2) = \\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n p+\sum_{i=0}^{n} E\left(T_{2} \mid T_{1}=i\right) P\left(T_{1}=i\right) =\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n p+\sum_{i=0}^{n} i p \times\left(\begin{array}{l}n \\ i\end{array}\right) p^{i}(1-p)^{n-i}$ I couldn't find any closed form for the answer. Any advice on how to approach this?","['expected-value', 'binomial-distribution', 'conditional-expectation', 'probability']"
3976165,"Calculating $P(\sum X_i < \infty)$ for $X_i\sim U(0,1)$","$\sum X_i < \infty$ is a tail event, $X_i$ 's are independent, so by the Kolmogorov $0-1$ theorem, $P(\sum X_i < \infty)$ can be either $0$ or $1$ . But which one is it? I tend to think it's $0$ . My logic is as follows: $X_i\sim U(0,1)$ Let's find the $P(\lim \sup {X_i>0.5})$ . Using Borel-Cantelli, since the sum $\sum_{i=1}^\infty P(X_i > 0.5) = \sum_{i=1}^\infty 0.5 = \infty$ and since the series of R.V. are independent, then $P(\lim \sup {X_i>0.5})=1$ . Then $\sum_{i=1}^\infty X_i > \sum_{\lim \sup {X_i>0.5}}X_i>\sum_{\lim \sup {X_i>0.5}}\frac{1}{2}=\infty $ i.e. we have infinite elements in the series that will be larger than $0.5$ , and so the series will not converge, hence the probability will be $0$ . Is that correct, or am I missing something?","['solution-verification', 'sequences-and-series', 'borel-cantelli-lemmas', 'convergence-divergence', 'probability-theory']"
3976248,Calculate $\lim_{n\to\infty}\int_0^nf(\frac{x}{n})^ndx$.,"Consider the following problem: Suppose $f:[0,1] \to \mathbb{R}$ is a differentiable function with $f'(0)<0$ , $f(0)=1$ and for all $x\in(0,1]:0<f(x)<1$ . Calculate $$\lim_{n\to\infty}\int_0^nf\left(\frac{x}{n}\right)^ndx.$$ My attempt so far: Let $$f_n:x\mapsto\chi_{[0,n]}(x)\cdot f\left(\dfrac{x}{n}\right)^n,$$ where $\chi_{[0,n]}$ is the indicator function on $[0,n]$ . We wish to do two things: Show that $f_n\to h$ pointwise for some integrable function $h:\mathbb{R}^+\to\mathbb{R}$ and show that $|f_n|\leq k$ for some positively integrable $k:[0,1]\to \mathbb{R}^+$ so that we can use the dominated convergence theorem to show that $$\lim_{n\to\infty}\int_{[0,\infty)}f_n(x) \,dx = \int_{[0,\infty)}h(x)dx.$$ To do this, we first construct the function $$g:[0,1]\to\mathbb{R}:y\mapsto\begin{cases}\dfrac{\ln f(y)}{y}& y\in(0,1],\\ f'(0) & y=0.\end{cases}$$ This is a continuous extention of $\ln f(y)/y$ since $$\lim_{y\to0}\dfrac{\ln f(y)}{y}=f'(0)$$ by l'Hôpital's rule. The idea is to show that $$f\left(\dfrac{x}{n}\right)^n\leq e^{f'(0)x}$$ for all $x\in[0,n]$ . To do this we can use the function $g$ as constructed above. Indeed, taking the natural log of this inequality gives us $$n\ln f\left(\dfrac{x}{n}\right)\leq f'(0)x$$ which is equivalent to $$g(y)\leq f'(0),$$ for all $y\in[0,1]$ . The problem is that I have trouble showing that this last inequality is true. Although I'm convinced it is. I've tried calculating $g'$ to see if it is negative everywhere, but have failed to do so. Suppose it is true. Then, since $f'(0)<0$ , the function $x\mapsto e^{f'(0)x}$ is integrable on $x>0$ , so we have found a dominating function for the $f_n$ . Furthermore, we need to show that there is an integrable function $h$ to which the $f_n$ converge. I cannot see how to show this pointwise convergence. Edit: I have found conclusive proofs for my two problems and have added them as an answer. To conclude the problem, the limit is $$\lim_{n\to\infty}\int_0^nf\left(\frac{x}{n}\right)^ndx = \int_0^\infty e^{-|f'(0)|x}dx = \dfrac{1}{|f'(0)|}.$$","['integration', 'analysis']"
3976249,Question about relations and equivalence classes.,"Hi so we've started learning about relations and I'm completely lost..
I don't get how to represent the equivalence classes and I'm not even sure the way I've proved the equivalence relation is correct.. Question 1 a. Note that if for every $a,b ∈ R$ if $a = b = 0 \ $ ➜ $a*b$ $\not>$ $0$ , but in this case it's already part of the relation. Also note that in order for this inequality to work, $a,b$ must be both negative, or both positive. Reflexive: Since $a$ obviously has the same sign as itself, $a * a > 0$ . Therefore for every $a ∈ R/(0) $ $ \ a R a \ $ Symmetric: By associativity, if $a * b > 0 ➜ b * a > 0$ . Therefore for every $a,b ∈ R/(0) $ if $aRb ➜ bRa$ . Transitive: Since $a,b,c$ must share the same sign, if $a * b > 0$ and $b * c > 0 ➜ a * c > 0$ . Therefore for every $a,b,c ∈ R/(0) $ if $aRb ∧ bRc ➜ aRc$ . Equivalence classes: $\left\{R^{+},R^{-},\left\{0\right\}\right\}$ b. Note that if $8 ∉ XΔY$ then either $8 ∈ X  ∧ 8 ∈ Y \ $ or $ \ 8 ∉ X  ∧ 8 ∉ X$ . Reflexive: Since $XΔX$ is the $∅$ , then it is obvious $8 ∉ XΔX$ . Therefore for every $X ∈ P(NxN)$ $XRX$ . Symmetric: Δ is associative, therefore if $8 ∉ XΔY ➜ 8 ∉ YΔX $ Therefore for every $X,Y ∈ P(NxN) \ XRY➜YRX$ . Transitive: Since $X,Y,Z$ must all contain or all not contain $8$ for the relation to work, then if $8 ∉ XΔY ∧ 8 ∉ YΔZ ➜ 8 ∉ XΔZ$ . Therefore for every $X,Y,Z ∈ P(NxN) \ $ if $XRY ∧ YRZ ➜ XRZ$ . Equivalence class: $\left\{\left\{X\ ∈\ \ P(N)\ :\ 8\ ∉\ \ X\ \right\},\left\{X\ ∈\ \ P(N)\ :\ 8\ ∈\ X\ \right\}\right\}$ c. Note that we're proven in class equality is both reflexive, symmetric and transitive. Reflexive: Obviously $X ∩ {1,2} = X ∩ {1,2}$ . Symmetric: It is also obvious $X ∩ {1,2} = Y ∩ {1,2} ➜ Y ∩ {1,2} = X ∩ {1,2}$ . Transitive: Again, obviously if $X ∩ {1,2} = Y ∩ {1,2} ∧ Y ∩ {1,2} = Z ∩ {1,2} \ ➜ \ X ∩ {1,2} = Z ∩ {1,2}$ . Equivalence classes: $\left\{\left\{X\ ∈\ \ P(N)\ :\ 1,2\ ∉\ \ X\ \right\},\left\{X\ ∈\ \ P(N)\ :\ 1\ ∉\ \ X\ \ ∧\ 2\ ∈\ X\ \right\},\left\{X\ ∈\ \ P(N)\ :\ 2\ ∉\ \ X\ \ ∧\ 1\ ∈\ X\ \right\},\left\{X\ ∈\ \ P(N)\ :\ 1,2\ ∈\ \ X\ \right\}\right\}$","['equivalence-relations', 'relations', 'solution-verification', 'discrete-mathematics']"
3976313,Compactness of the moduli space of representations of fundamental group,"Let $M$ be a compact manifold and $G$ a compact Lie group. I am trying to deduce that the moduli space of flat connections on $M$ is compact, and for that I have shown that there is a correspondence between flat $G$ -connections modulo gauge equivalence and equivalence classes of representations of the fundamental group of $M$ , but now I can't see why this space of representations is compact. I do not have much background in representation theory or algebraic topology, so I am mostly looking for a reference for this result. If this is something that should be clear from more basic results (if I had the background), a sketch of the proof would also be appreciated.","['representation-theory', 'reference-request', 'fundamental-groups', 'gauge-theory', 'differential-geometry']"
3976315,Find the missing angle in triangle,"In the below triangle, we are looking for the value of angle $φ$ . We are given $α=30, β=18, γ=24$ and also that $CD=BD$ . I have solved it with trigonometry (sine law) and found the required angle to be 78 but I need to solve it with Geometry only. What I have tried so far: First of all, the angle is constructible, which means to me that there must be a geometrical solution. I first drew triangle ABC; easy, since we know 2 of its angles. We are not interested in the lengths of the sides. Then, with side AC as a base, and angle of 24 degrees, we can draw a ray from the point A. Then, since $CD=BD$ , triangle DCB is isosceles, therefore D must lie on the perpendicular bisector of CB, which we can draw. The point of intersection of the ray from A and the perpendicular bisector, is point D. From triangle FEB we have that angle AFD = 108. From triangle AFD, $ADC+CDE+54+108=180$ so $ADC+CDE=18$ We also have $24+ACD+ADC=180$ $ACB=132$ $132+φ+ACD=180$ $18+φ+54+ADC+2CDE=180$ I am always one equation short. Any ideas? Many thanks in anticipation! EDIT: Sine law in triangle ABD: $\frac {sin (φ+18)}{AD} = \frac {sin (54)}{BD}$ Sine law in triangle ACD: $\frac {sin (360-132-φ)}{AD} = \frac {sin (24)}{CD} = \frac {sin (24)}{BD}$ so $\frac {sin (φ+18)}{sin (228-φ)} = \frac {sin (54)}{sin (24)}$ hence $φ=78$ .","['euclidean-geometry', 'geometry']"
3976415,How to prove this question related to multi-times composite relation $\mathcal{R}^{n}$,"I found a question somewhat difficult, on An Invitation to Discrete Mathematics , by Matousek et al., which goes as below. $\newcommand{\op}[2]{ \left\langle #1 ,\, #2 \right\rangle }$ $\newcommand{\rel}[1]{ \mathcal{#1} }$ Question : For a relation $\rel{R}$ on a set $X$ we define the symbol $\rel{R}^n$ by induction: $$\rel{R}^1 = \rel{R},\, \rel{R}^{n+1}=\rel{R} \circ \rel{R}^n$$ (a) Prove that if $X$ is finite and $\rel{R}$ is a relation on it, then there exist $r, s \in \mathbb{N}$ , $r < s$ , such that $\rel{R}^r = \rel{R}^s$ . (b) Find a relation $\rel{R}$ on a finite set such that $\rel{R}^n \neq \rel{R}^{n+1}$ for every $n \in \mathbb{N}$ . (c) Show that if $X$ is infinite, the claim (a) need not hold (i.e. a relation $\rel{R}$ may exist such that all the relations $\rel{R}^n$ , $n \in \mathbb{N}$ , are distinct). My Attempt : I had some trouble to define a finite set rigorously. Later, I decided not to struggle with the definition of the finite set. Instead, I chose to use a concept, Adjacency Matrix , to solve the problem. First, I start with observing some examples.
Let $\rel{R} = \left\{ \op{x}{y} \mid x < y \right\} \subseteq A \times A$ , where the set $A = \left\{ 1,\, 2,\, 3,\, 4,\, 5 \right\}$ , while $\op{x}{y}$ is an ordered pair: $\op{x}{y} = \left\{ \left\{ x \right\},\, \left\{ x,\,y \right\} \right\}$ . Now it is possible to make a graphic presentation of the relation $\rel{R}$ on the set $A$ as followed: Furthurmore, the adjacency matrix of the relation $\rel{R}$ is: \begin{align}
J_{\rel{R}^1} =
\begin{bmatrix}
0 & 1 & 1 & 1 & 1 \\
0 & 0 & 1 & 1 & 1 \\
0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{align} Similarly, we can get the graphic presentation and the adjacency matrix of the composite relation $\rel{R}^{2} = \rel{R}\circ\rel{R}$ . \begin{align}
J_{\rel{R}^2} =
\begin{bmatrix}
0 & 0 & 1 & 1 & 1 \\
0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{align} And so forth, the adjacency matrix of the composite relation $\rel{R}^{3}$ , $\rel{R}^{4}$ and $\rel{R}^{5}$ are: \begin{align}
J_{\rel{R}^3} =
\begin{bmatrix}
0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{align} \begin{align}
J_{\rel{R}^4} =
\begin{bmatrix}
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{align} \begin{align}
J_{\rel{R}^5} =
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{align} It's obvious that $\forall i \in \mathbb{N},\, i > 5 :\: J_{\rel{R}^i} = J_{\rel{R}^5} = 0$ , i.e. $\forall i \in \mathbb{N},\, i > 5 :\: \rel{R}^i = \rel{R}^5 = \varnothing$ . Meanwhile, let $\rel{S} = \left\{ \op{x}{y} \mid x = y \right\} \subseteq A \times A$ . We can get $\rel{S} = \left\{ \op{1}{1},\, \op{2}{2},\, \op{3}{3},\, \op{4}{4},\, \op{5}{5} \right\}$ . it's obvious that $\forall i \in \mathbb{N} :\: J_{\rel{S}^i} = I \;\land\; \rel{S}^{i} = \rel{S}$ . After the observation of some special cases as listed above, I started to prove the first sub-question. Suppose $A$ is a finite set with n elements. $$ A = \left\{a_1,\,a_2,\,\ldots{},\,a_n\right\} $$ Suppose $\rel{R}$ is a relation on $A$ . It can be completely described by an $n \times n$ matrix $M = \left(m_{ij}\right)$ , $i,\,j \in \left[1, n\right] \cap \mathbb{N}$ , where \begin{align}
m_{ij} = \left\{ \begin{array}{c}
  1,\ \text{if}\ \op{a_i}{a_j} \in R \\
  0,\ \text{if}\ \op{a_i}{a_j} \notin R
\end{array} \right.
\end{align} I've got so far, but I cannot figure it out how to prove any of three sub-questions at all. Could you please help me? Thx in advance.","['relations', 'discrete-mathematics']"
3976417,Computing explicitly three integrals involving radial functions,"How can I compute the following three (similar)
integrals? $$
\int_{\mathbb R^N} \left(\frac{1}{1+|x|^2} \right)^{\beta} dx
$$ $$
\int_{\mathbb R^N} \left(\frac{1}{1+|x|^2} \right)^{(N+2\alpha)/2} \left(\frac{1}{|x|} -\frac{1}{(1+|x|^2)^{1/2}} \right) dx
$$ $$
\int_{\mathbb R^N} \left(\frac{1}{1+|x|^2} \right)^{(N+2\alpha)/2} |x|^{4\alpha - N} dx
$$ where $\alpha, \beta >0$ . Since the involved functions are radial, one can make a change of variables to reduce the problems to 1-d problems, but then I don't know how the integral can be computed explicitly or it if can be done in an easy way at all or not.","['integration', 'multivariable-calculus', 'calculus']"
3976443,Cycles in algebraic dynamical systems,"Suppose you have an algebraic set $X \subset k^n$ , where $k$ has finite characteristic, and an algebraic function $f: X \to X$ . (A) Is there any cohomological, or more generally geometrical, obstruction to the dynamical system $f$ having finite cycles? (B) Is there a way to count them? Explicitly, I am looking for solutions of the equation $f^k(x) = x$ . Here there are some variants which are harder, but more linked to my motivation: Suppose $X$ is an (affine) ind-variety, i.e. we have $X= \bigcup_{j=1}^{\infty} X_j$ where $X_j \subset X_{j+1}$ are algebraic varieties of finite dimension over $k$ , and $X_j \to X_{j+1}$ is a closed embedding. You can also suppose that $f$ is defined piecewise as $f_j : X_j \to X_{j+1}$ (but note the shift on the indices, so that you can't study the dynamical system on the singular strata). How answers to (A) and (B) change? Is there any simplification if we suppose $k=\bar{k}$ ? In case of a generic field, can we deduce something by base changing to the algebraic closure? Suppose $Y \subset X$ is an invariant subset under the action of $f$ . Can we say something about cycles appearing in $X\setminus Y$ ? I  think that if something exists, it should be really cool. I also think to be partly deceived by the word ""cycles"" appearing both in cohomology and dynamical systems :) However, what makes me guess there could be something is that, in some cases, properties of dynamical systems are determined by the geometry of the underlying object, and I was wondering if 'having a cycle' in the context of algebraic geometry is such a property. Of course, the best case scenario would be having a formula for the cycles of length $d$ in terms of the geometric action of $f$ . Edit. I also recalled that in the proof of Weil conjectures there was a use of the Lefschetz theorem, counting fixed points as an alternating sum of traces in $\ell$ -adic cohomology. In my case $k$ is a finite field, so if this can be generalized to any map we could apply the Lefschetz trace formula to $f^k$ to get the desires result. Not being an expert though, I don't have any idea on how to formalize this, and if this is specific to the Frobenius map or to any map.","['etale-cohomology', 'fixed-points', 'galois-theory', 'algebraic-geometry', 'dynamical-systems']"
3976458,Natural density extended to real density?,"The natural density of the set $A \subseteq \mathbb{N}$ is defined as $$\delta(A)=\lim_{n \rightarrow \infty}\frac{ \# \{k \in A | k \leq n \} }{ \# \{k \in \mathbb{N} | k \leq n \} }.$$ My idea was to generalize this to sets with greater cardinality: For example take the set $B = \{x \in \mathbb{C} | \ \lvert x \rvert \leq \frac{1}{2} \}$ instead of $A$ and the unit disk $U = \{x \in \mathbb{C} | \ \lvert x \rvert \leq 1 \}$ instead of $\mathbb{N}$ . Now we know by some easy geometrical calculations that the ratio is $\frac{1}{4}$ . How do we get this by a concept similar to the natural density or other densities with countable sets? Is there a density concept (with limits) for general sets, including uncountable ones like $\mathbb{R}$ ? Thanks for your ideas, comments and answers!","['measure-theory', 'combinatorics', 'natural-numbers', 'density-function']"
3976459,"$(f_n)$ sequence of differentiable functions on $[0,1]$ and converge pointwise to $0$.","Let $(f_n)$ sequence of differentiable functions on $[0,1]$ converging pointwise to $0$ . Suppose $|f'_n(x)| \leqslant 2015 + \cos(x)$ $\forall x \in [0,1]$ and $\forall n$ . Show that $(f_n)$ converge uniformly to $0$ . ''Proof'' As supposed, $|f'_n(x)| \leqslant 2015 + \cos(x)$ . We can rewrite it: $|f'_n(x)| \leqslant 2015 + \cos(x) \leqslant 2016$ as $\cos(x)\leqslant1$ Since $(f_n)$ is a sequence of differentiable functions and the derivative is bounded, $(f_n)$ is Lipschitz. Hence, $\forall x,y \in [0,1]$ : $|f_n(x)-f_n(y)| \leqslant 2016|x-y|=\epsilon/3$ Moreover, as $(f_n)$ is Lipschitz, it implies that $(f_n)$ is uniformly continuous on $[0,1]$ : $\forall \epsilon>0$ $\exists \delta>0$ such that $\forall x,y \in [0,1]:$ $|x-y|<\delta \Rightarrow |f_n(x)-f_n(y)| \leqslant \epsilon/3$ And we want to show that $\forall \epsilon >0 \exists$ $n_0$ such that $\forall n\geqslant n_0 \forall x \in [0,1]$ : $|f_n(x)|<\epsilon$ . Then i don't really see how to apply the pointwise convergence(i.e create kind a subdivision on $[0,1]$ or?) and conclude the proof using triangular inequality. P.S Im stydying Analysis I right now so if you could explain with much details as possible it would be kind from your part. Thanks in advance ;)","['lipschitz-functions', 'real-analysis', 'uniform-convergence', 'derivatives', 'pointwise-convergence']"
3976464,Spivak's ambiguous popcorn function,"There is a question given in Michael Spivak's Calculus chapter 6 problem 1 section iv that reads as follows. For which of the following functions $f$ is there a continuous function $\mathrm{F}$ with domain $\mathbb{R}$ such that $\mathrm{F}(x)=f(x)$ for all $x$ in the domain of $f$ ? iv) $f(x)=1/q, \;x=p/q$ rational in lowest terms. answer book says iv)
No $\mathrm{F}$ , since $\mathrm{F}(a)$ would have to be $0$ for irrational $a$ , and then $\mathrm{F}$ is not continuous at $a$ is $a$ is rational. (typo intentionally reproduced from the book)
(end section) The function was defined for rational numbers $p/q$ . The function was never defined for $\mathbb{R}$ . $f(x)$ for any irrational number is therefore undefined or unknown to the reader. This seems to be a sloppy example involving the popcorn function. I believe the conclusion that $f(x) = 0$ for any irrational number $x$ is not possible with the information given or maybe there is something that mathematicians know that is implied that I do not understand. Is the function undefined for $x$ where $x$ is an irrational number? This would also result in a discontinuous function but for different reasons then what was concluded by Spivak. I also lack the understanding that the denominator $q$ can be isolated and extracted after $\mathbb{Q}$ has been mapped to $\mathbb{R}$ but that might be off topic. The domain is given as $\mathbb{R}$ not $\mathbb{Q}$ .","['continuity', 'calculus', 'foundations', 'analysis']"
3976473,Prove that the sum of the digits of $9^n$ is not equal to $9$ for $n \ge 3$,"It may seem really easy to solve but almost all of us are stuck on this one. Seems really weird: Prove that, for all $3\leqslant n$ , $S(9^n)\not=9$ . $S(n)$ is the sum of digits of $n$ base $10$ . َAlso, there's no need to check for odd $n$ because in that case the solution is as follows: First of all it's clear that $S(n)$ is divisible by $9$ so if it's not $9$ we're done. Furthermore, if $n$ is odd, the rightmost digit of $9^n$ is $9$ , and there's at least one other non-zero digit, so sum of digits of $n$ is more than $9$ , and that's it. But for even $n$ I'm seriously stuck.","['number-theory', 'elementary-number-theory']"
3976500,Probabilistic modelling,"This question is about how to make sense of a probabilistic model I'm reading about: You have three random variable $A$ , $B$ and $C$ that are all real-valued. You want to model an input-output relationship with these random variables, by assuming the following relationships between them: It is assumed that $A$ is the constant random variable that only takes the value $a\in \mathbb
{R}$ , where $a$ is thought of as input. Furthermore, $P(B=b | A=a)=\mathcal{N}(b;3\cdot e^a,1)$ and $P(C=c | B=b)=\mathcal{N}(c;2\cdot b^2,1)$ , where $\mathcal{N}(x;\mu,1)$ denotes the probability density of a normal distribution with mean $\mu$ and variance $1$ . My questions are: Does an equation like $P(B=b | A=a)=\mathcal{N}(b;3\cdot e^a,1)$ even make sense? If we takes samples, on the left we have a number between $0$ and $1$ but on the right we have a number that can be larger, as the pdf does not need to stay within $[0,1]$ , right? What is the output? In the (not online available) text I'm reading, the above is all that is mentioned. I would assume that to arrive at the output, one needs to proceed in the following way: Given $a$ , draw a number $b$ from a normally distribution with mean $3\cdot e^a$ and unit variance and then similarly draw $c$ , the output, from a normally distribution with mean with mean $2\cdot b^2$ and unit variance. But I'm not sure if that's correct; also, it is not clear to me, in case this interpretation is indeed correct, why conditional probabilities in the model formulation are needed.","['mathematical-modeling', 'probability', 'density-function']"
3976514,How big can a quotient space be?,"Let $X$ be a space of weight $w(X)=\kappa$ . Suppose $q:X\rightarrow Y$ is a quotient map. If $q$ is open, or if $Y$ is compact, then $w(Y)\leq w(X)$ . In general it is possible for $w(Y)$ to be larger than $w(X)$ (consider $\mathbb{R}/\mathbb{Z}$ ). How much larger than $w(X)$ can $w(Y)$ be? Really what I'm looking for is a machine to produce countexamples for any fixed infinite cardinal $\kappa$ . I'm particularly interested in the case that $X$ is second-countable.",['general-topology']
3976570,"Does there exist a circle with EXACTLY two rational points, no more, no less?","Topic title says it all, I think. Does there exist a circle with EXACTLY two rational points, no more, no less? I know that as soon as it has three rational points, its center must be rational too, therefore an isomorphism with the unit circle yields infintely many (dense) rational points. I have examples with only one and zero rational points, but I'm wondering about the case 2. I already know that the center must be irrational, because else one rational point on the circle would suffice to yield infinitely many points.","['circles', 'geometry', 'rational-numbers']"
3976594,"Solutions of $f(k,s)=0$ as $k\to\infty$","Let $f(k,s) = D(s) + kN(s)$ where $D(s)$ and $N(s)$ are polynomials of $s \in \mathbb{C}$ such that $\text{Deg}(D) = n, \ \text{Deg}(N) = m$ and $n\ge m$ . Also $D(s)$ and $N(s)$ doesn't have common factor. Find the values of $s$ such that $$\lim_{k\to \infty}f(k,s) = 0  \tag{1}$$ My try: Assume that $N(s) \not = 0$ . Obviously, in this case $\lim_{k\to \infty}f(k,s)$ is divergent for any $s$ . Now suppose $N(s) = 0$ and we have $\lim_{k\to \infty}f(k,s) = D(s)$ . So the answer is $D(s) = N(s) = 0$ which is impossible since $D(s)$ and $N(s)$ doesn't have common factor. What's wrong in my reasoning? Also is $(1)$ equivalent to find $s$ such that $f(k,s) = 0$ and then $\lim_{k \to \infty} s(k)$ ? I mean that we first find the roots of $f(k,s)$ with respect to $k$ and see what happens to the roots when $k \to \infty$ . Edit: The correct answer is as follows. Divide the equation $D(s) + kN(s) = 0$ by $k$ and let $k \to \infty$ . So we have $$\lim_{k \to \infty}(\frac{D(s)}{k} + N(s)) = N(s) = 0$$ I don't know why my argument is flawed and whether the mentioned equivalence holds. Edit2: Thanks to @Alex Ravsky, it turns out that the true question is What are the solutions of $f(k,s)=0$ as $k\to\infty$ ?","['real-analysis', 'multivariable-calculus', 'polynomials', 'limits', 'convergence-divergence']"
3976615,Suspicious corollary of Lusin’s Theorem,"Suppose $f : [0,1] \to \mathbb R$ is integrable. According to Lusin’s Theorem (as I understand it), for every $\epsilon > 0$ , there is a closed subset $C \subset [0,1]$ for which $f|_C : C \to \mathbb R$ is continuous and $\lambda([0,1] \setminus C) < \epsilon$ , where $\lambda$ is the Lebesgue measure on $[0,1]$ . Furthermore, if $B \subset [0,1]$ is open, then there is a closed $C’ \subset B$ for which $f_{C’} : C’ \to \mathbb R$ is continuous and $\lambda(B \setminus C’) < \epsilon$ . Playing with this, I arrived at the following corollary, which seems way too powerful to be true: Corollary: There is a subset $C \subset [0,1]$ of full measure, for which $f|_C : C \to \mathbb R$ is continuous (in the induced subspace topology on $C$ ). Proof. Let $C_1 \subset [0,1]$ be a closed set for which $f|_{C_1}$ is continuous, with $\lambda([0,1] \setminus C_1) < 2^{-1}$ , so $\lambda(C_1) > 2^{-1}$ . The existence of such a $C_1$ follows from Lusin’s Theorem. Now let $C_2 \subset [0,1] \setminus C_1$ be such that $f|_{C_2}$ is also continuous, and $\lambda\left(\left([0,1]\setminus C_1\right)\setminus C_2\right) < 2^{-2}$ , or $\lambda(C_1 \sqcup C_2) > 2^{-2}$ . The existence of $C_2$ also follows from Lusin’s theorem. Continuing in this way, we get a countable collection of disjoint closed sets $(C_n)_{n \geq 1}$ for which $f|_{C_n} : C_n \to \mathbb R$ is continuous for each $n$ , and for which $\lambda\left(C_1 \sqcup C_2 \sqcup \cdots \sqcup C_n\right) > 1-2^{-n}$ . By lower semicontinuity of $\lambda$ , denoting $C = \bigsqcup_{n\geq 1} C_n$ , we have $$
1 \geq \lambda(C) = \lim_{n \to \infty} \lambda\left(\mathop{\bigsqcup}_{k=1}^n C_k\right) \geq \lim_{n \to \infty}(1-2^{-n}) = 1.
$$ So $\lambda(C) = 1$ . and since $C$ is the countable disjoint union of closed sets, on each of which $f$ is continuous in the subspace topology, it follows that $f$ is continuous on $C$ in its subspace topology. QED. I don’t see an obvious flaw with this proof, but I find this hard to believe. The only place I can see an issue possibly is with the existence of $C_n$ for $n \geq 2$ using Lusin’s Theorem, but Lusin’s Theorem should hold on any Radon measure space $(X, \mathcal A, \mu)$ —in particular it should hold on any measurable subset of $[0,1]$ . Where is the flaw in this proof? Or is this really a corollary of Lusin’s Theorem? EDIT: See the answer below.","['measure-theory', 'lebesgue-measure']"
3976656,"Prove $\int_{-\pi}^\pi F_n(y) \, dy=1$","Prove $\int_{-\pi}^\pi F_n(y)\,dy=1$ , with $$F_n(y)=\frac{1}{2\pi (n+1)}\frac{\sin^2 \left( \frac{(n+1)y}{2} \right)}{\sin^2(\frac{y}{2})}$$ I tried a similar question but there I had given a serie of the function. This time I don't know if there is a serie that can help me with this.
I tried it without a serie: \begin{align}
\int_{-\pi}^{\pi}F_n(y) \, dy &= \int_{-\pi}^\pi \frac{1}{2\pi (n+1)} \frac{\sin^2\left(\frac{(n+1)y}{2}\right)}{\sin^2(\frac{y}{2})} \, dy\\
&=\int_{-\pi}^\pi \frac{1}{2\pi (n+1)}\frac{(e^{\frac{i(n+1)y}{2}}-e^{\frac{-i(n+1)y}{2}})^2}{(e^\frac{iy}{2}-e^\frac{-iy}{2})^2} \, dy\\
&=\int_{-\pi}^\pi \frac{1}{2\pi (n+1)}\frac{(e^{i(n+1)y}+e^{-i(n+1)y}-2)}{(e^{iy}+e^{-iy}-2)} \, dy
\end{align} But now I'm stuck again. I think there needs to be an easier way to prove this. Can someone help me out?","['integration', 'fourier-analysis', 'sequences-and-series']"
3976755,"Derivations of the algebra $K[x,y]/(y^2-x^3)$","Let $K$ be a field of characteristic zero, and let $S=K[x,y]/(y^2-x^3)$ . It is easy to see that $S\cong R:=K[t^2,t^3]$ via the isomorphism induced by the ring homomorphism $K[x,y]\to R$ given by $x\mapsto t^2, y\mapsto t^2$ . It is known that for any $K$ -algebra $A$ and any ideal $J$ , $$
\operatorname{Der}_K(A/J) \cong \operatorname{Der}_J(A)/J\operatorname{Der}_K(A),
$$ where $\operatorname{Der}_K(A)$ is the space of $K$ -linear derivations of $A$ , and $$
\operatorname{Der}_J(A) = \{D\in \operatorname{Der}_K(A) \; | \; D(J)\subseteq J\}.
$$ In Exercise 3.6 of Chapter 3 in the book A primer on Algebraic $D$ -modules by Coutinho, I'm asked to show that the derivations $$
D_1 = 2y\partial_x + 3x^2\partial_y \quad \text{and} \quad D_2 = 3y\partial_y - 2x\partial_x
$$ generate $\operatorname{Der}_K(S)$ as $S$ -module. Then I have to conclude that $\operatorname{Der}_K(R)$ is generated as an $R$ -module by $t\partial_t$ and $t^2\partial_t$ . I have two issues here: First, it seems to me that $D_2$ must be $3y\partial_y + 2x\partial_x$ , as the application of the chain rule gives $$
t\partial_t f = t \frac{\partial f}{\partial x} \frac{dx}{dt} + t \frac{\partial f}{\partial y} \frac{dy}{dt} = 2t^2 \frac{\partial f}{\partial x} + 3t^3 \frac{\partial f}{\partial y} = (2x\partial_x + 3y\partial_y)f
$$ and $$
t^2\partial_t f = t^2 \frac{\partial f}{\partial x} \frac{dx}{dt} + t^2 \frac{\partial f}{\partial y} \frac{dy}{dt} = 2t^3 \frac{\partial f}{\partial x} + 3t^4 \frac{\partial f}{\partial y} = (2y\partial_x + 3x^2\partial_y)f = D_1f.
$$ Is it a typo in the book or am I misunderstanding something? The second one is about the proof that $D_1$ and $D_2$ generates $\operatorname{Der}_K(S)$ as $S$ -module. First of all, an element of $\operatorname{Der_J(K[x,y])}$ , where $J=(y^2-x^3)$ has the form $d=f_1 \partial_x + f_2\partial_y$ , and the condition $d(J)\subseteq J$ means that $$
-3x^2f_1 + 2yf_1 \in J,
$$ and the condition that that $D_1$ and $D_2$ generates $\operatorname{Der}_K(S)$ as $S$ -module means that there are polynomials $g,h\in K[x,y]$ such that $$
f_1 \partial_x + f_2\partial_y - gD_1 -hD_2 \in J\operatorname{Der}_K(K[x,y]),
$$ but I can't manage to show that such $g$ and $h$ would exist. Working a little bit this attempt, I need to find polynomials $u,v\in K[x,y]$ such that $$
f_1 \partial_x + f_2\partial_y - gD_1 -hD_2 = (y^2-x^3)(u\partial_x + v\partial_y).
$$ Taking $D_2 = 3y\partial_y + 2x\partial_x$ with the ""right"" sign, we can see that the above equation is equivalent to the following equalities: $$
f_1 - 2yg - 2xh = (y^2-x^3u) \quad \text{and} \quad f_2 - 3x^2g - 3yh = (y^2-x^3)v,
$$ and, as $-3x^2f_1 + 2yf_2 \in J$ there exists some polynomial $w\in K[x,y]$ such that $-3x^2f_1 + 2yf_2=(y_2-x^3)w$ . A little manipulation gives $$
-6h = -3x^2v + 2yu - w
$$ and I don't know if I can do more, or even if my attempt is correct, so any help will be appreciated.","['algebraic-geometry', 'singularity-theory', 'd-modules', 'partial-differential-equations']"
3976760,The average weight of $46$ weightlifters is $106$ kg; how many can weigh $125$ kg if none may drop below $82$ kg?,"The average weight of $46$ weightlifters is $106$ kg. If none of the lifters weighs less than $82$ kg, at most how many of them can weigh more than $125$ kg? We are given that $$\overline{X}=\dfrac{x_1+x_2+x_3+\ldots+x_{46}}{46}=106.$$ From here we can conclude $$x_1+x_2+x_3+\ldots+x_{46}=106\times46=4876 \text{ kg }$$ So the total weight of the weightlifters is $4876$ kg. We also know that $x_n\ge82$ kg for every $n$ . I don't know what to do next. Thank you in advance!","['average', 'statistics']"
3976764,Existence and the value of $\lim_{x \to 0} \int^{3x}_x \frac{\sin t}{t^2}dt$,"I need the show the existence of the following limit and then calculate the limit $$\lim_{x \to 0} \int^{3x}_x \frac{\sin t}{t^2}dt$$ Since the antiderivative of $\frac{\sin t}{t^2}$ was not nice, I tried to use the approximation $\sin x \approx x$ for $x$ close to $0$ . Then, I can integrate and find the limit as $\ln3$ . Is this a valid solution and can I solve this without using such approximation?","['integration', 'real-analysis']"
3976768,Complete Cayley table for a field,"Let $M=\{0,1,a,b,c\}.$ Can I complete the Cayley tables so that $M$ is a field? My thought was that $(M,+)$ must be an abelian group. This abelian group must be isomorphic to $(\mathbb Z_5,+).$ Correct? I managed to find that if $a=3, b=4$ and $c=2$ it works for addition. But this does not work for the multiplication table. Does that mean that I can´t complete the Cayley table so that $M$ is a field?","['field-theory', 'finite-fields', 'discrete-mathematics']"
3976776,"Finding the functions verifying that for all $x$, we get $g \circ \dots \circ g(x)=x$ where the number of composition depends on $x$.","Let $g:[0,1]\to[0,1]$ a continuous function verifying $g(0)=0$ and for every $x$ in $[0,1]$ , there exists a non zero positive integer $n=n(x)$ such that $g^n(x)=x$ where $g^n$ is $g \circ \dots \circ g$ ( $g$ appears $n$ times, $g^0=Id$ ). I'm asked to show that $g$ in injective and surjective, then deduce that $g$ is the identity. For the surjection, I think it's easy for all $y$ in $[0,1]$ , there exists $n$ such that $g^n(y)=y$ so $g(g^{n-1}(y))=y$ . I'm having trouble showing that it's injective. If I take $x,y$ such that $g(x)=g(y)$ . There will exist $n,m$ such that $g^n(x)=x$ and $g^m(y)=y$ . By symmetry, we can suppose $n>m$ (if $n=m$ , we get directly $x=y$ ), and by Euclidian division, we have $(q,r)$ such that $n=mq+r$ where $0\leq r<m$ , and so : $g^r(y)=x$ . This is what I've thought of so far, to finish the proof, I'll have to show that $r=0$ , or that $n$ divides $m$ . (Maybe I need to use the continuity and that $g(0)=0$ since I haven't used them thus far). Any help/hints for the injection part or deduction part will be appreciated.","['continuity', 'functions']"
3976788,Conditional Expectation for the Exponential Distribution -- solution verification,"A device that continuously measures and records seismic activity is placed in a remote region. The time, $T,$ to failure of this device is exponentially distributed with mean $3$ years. Since the device will not be monitored during its first two years of service, the time to discovery of its failure is $X = \max(T, 2)$ . Determine $E(X)$ . My attempt : $$E[X] = E[X\mid T\ge 2] \cdot P(T \ge 2) + E[X\mid T< 2] \cdot P(T< 2)$$ $$= E[T\mid T\ge 2] \cdot P(T \ge 2) + E[2\mid T< 2] \cdot P(T< 2) $$ Using the memoryless property of the Exponential distribution, we have: $$ = E(T) \cdot P(T\ge 2) + E(2) \cdot P(T<2)$$ $$ = 3[1-P(T<2)] + 2\cdot P(T<2)$$ (Edited based on commments) Now, $P(T<2)=\int_0^2 \frac{1}{3} e^{-t/3} \; dt = 1- e^{-2/3}$ . These calculations do not lead to the correct answer. Can someone please point out what I did incorrectly? As pointed out in the answer by Michael Hardy, for the benefit of anyone who visits this post in the future, this is how the solution should go: $$E[T\mid T\ge 2] \cdot P(T \ge 2) + E[2\mid T< 2] \cdot P(T< 2) = \int_2^\infty \frac{t}{3} e^{-t/3}\; \text{d}t + 2 \cdot [1- e^{-2/3}]$$ $$= 5e^{-2/3} + 2 - 2e^{-2/3} = \boxed{3e^{-2/3} +2}$$","['actuarial-science', 'statistics', 'solution-verification', 'probability']"
3976791,How wide can a unit-length planar curve be?,"The width of a bounded set in the plane is the minimum distance between two parallel lines bounding the set. Suppose that we have some curve $C: [0,1]\to\mathbb{R}^2$ of unit length. How large can its width be? Equivalently, if we would like to bend a wire into a shape of unit width, how much wire do we need? (I'll use the latter framing in this post because it makes the numbers a little nicer.) If one tries forming the wire into a circle or semicircle, $\pi$ units of length are needed. All but one of the sides of a unit square only takes $3$ units. Using $270$ degrees of a circular arc one can do better, with length $\frac{3\pi(2-\sqrt{2})}{2}=2.7604\ldots$ . After playing around with different natural options for a bit, the winner appears to be $\frac{4}{\sqrt{3}}\approx2.3094$ , given by forming the wire into a $60$ -degree angle so that its convex hull is the equilateral triangle of width 1. However, it turns out that this is not optimal! Consider the following construction: Fix $0.5<x<\frac{\sqrt{3}}{2}$ . Start with the triangle formed by the points $(0,1), (-x,0), (x,0)$ . Then, add the circular arcs of radius $1$ from each of the latter two points as they pass through the opposite side of the triangle. Take the convex hull of these three points and two circular arcs, and omit the line segment of length $2x$ at the bottom; the resulting set is our wire. Above is a diagram of this construction: the original triangle is marked in blue, the circular arcs (of which only part make it to the convex hull) are marked in red, the straight-line tangents to said arcs are in black, and the portion of the convex hull not on the wire is marked with a dashed line. It is fairly easy to see that this construction has width $1$ , and that the resulting length is $$2\left(x+\sqrt{4x^2-1}+\arctan(1/x)-\arctan(x)-\arccos(1/2x)\right)$$ As it turns out, this function is minimized around $x=0.521795$ , with a wire length of around $2.2783$ . (In fact, the derivative of the above function is a rational function, so we can be more precise: $x$ is the unique positive real root of the polynomial $3x^6 + 9x^4 + x^2 - 1$ .) Is this construction optimal? I do not believe there are any obvious local improvements one can make, but it's possible that a radically different wire shape could improve on this configuration. Obviously, there is a lower bound of $1$ on the length of any solution, and by considering the width in two orthogonal directions one can increase this to $\sqrt{2}$ . It's tempting to say that the length must be at least $2$ , because there must be a point at distance $1$ from the midpoint of the wire, but this only follows if one makes the assumption that the wire lies on the boundary of its convex hull, which I cannot see a good way to justify. I would be curious to see any improved lower bounds, better solutions than the one given above, or pointers to discussion of this question in the literature.","['optimization', 'geometry', 'curves', 'reference-request']"
3976793,Tensor contraction via universal property of the tensor product,"I'm having a little trouble with the definition of the contraction operation for tensors via the universal property of the tensor product. The construction I've found (for instance, suggested here and outlined here ) goes as follows: suppose we have a commutative ring $R$ (for example, the smooth real valued functions on a manifold) and an $R$ -module $E$ which is finitely generated and projective (for example, the module of smooth sections of the tangent bundle of a smooth manifold), with dual $E^{*}$ . Consider the tensor product $$
\bigotimes_{i=1}^{r}E \otimes \bigotimes_{i=1}^{s}E^{*}
$$ and call $\otimes^r_s$ the corresponding canonical multilinear mapping between the cartesian product to the tensor product. To define the contraction $C^\ell_{k}$ between the $\ell$ -th $E$ factor and the $k$ -th $E^{*}$ factor, one defines the (suppossedly) multilinear mapping: $$
f:\prod_{i=1}^{r}E \times \prod_{i=1}^{s}E^{*}\longrightarrow \prod_{i=1}^{r-1}E \times \prod_{i=1}^{s-1}E^{*} 
$$ $$
f:(U_1,\ldots,U_r,\omega^1,\ldots,\omega^s)\mapsto \omega^k(U_\ell)(U_1,\ldots,\widehat{U_\ell},\ldots,U_r,\omega_1,\ldots,\widehat{\omega^k},\ldots,\omega_s)
$$ where hats mean ommitted arguments, and where (I presume) the product spaces are understood to be $R$ -modules through the usual construction as direct sums/products. Then by the universal property of the tensor product, there exists a unique module homomorphism $$
h:\bigotimes_{i=1}^{r}E \otimes \bigotimes_{i=1}^{s}E^{*}\longrightarrow \prod_{i=1}^{r-1}E \times \prod_{i=1}^{s-1}E^{*}
$$ such that $f = h\circ\otimes^r_s$ ; then the contraction would suppossedly be defined as $C^\ell_k:= \otimes^{r-1}_{s-1}\circ h$ , and the universal property should yield: $$
C^\ell_k(U_1\otimes\cdots\otimes U_r\otimes\omega^1\otimes\cdots\otimes\omega^s) = \omega^k(U_\ell)U_1\otimes\cdots,\otimes\widehat{U_\ell}\otimes\cdots\otimes U_r\otimes\omega_1\otimes\cdots\otimes\widehat{\omega^k}\otimes\cdots\otimes\omega_s
$$ I just can't get this to work. My questions/problems are: How exactly is $f$ suppossed to be multilinear? If addition and multiplication by elements of $R$ on $\prod_{i=1}^{r-1}E \times \prod_{i=1}^{s-1}E^{*}$ are defined component-wise, then it seems that $f$ would only be multilinear in the two arguments that are being contracted. Even if we admit that $h$ exists and is unique, if we understand that multiplication by elements of $R$ acts componentwise, then we should have: $$
\otimes^{r-1}_{s-1}\left(\omega^k(U_\ell)(U_1,\ldots,\widehat{U_\ell},\ldots,U_r,\omega_1,\ldots,\widehat{\omega^k},\ldots,\omega_s)\right) = \omega^k(U_\ell)^{(r-1)(s-1)}U_1\otimes\cdots,\otimes\widehat{U_\ell}\otimes\cdots\otimes U_r\otimes\omega_1\otimes\cdots\otimes\widehat{\omega^k}\otimes\cdots\otimes\omega_s
$$ since the factor $\omega^k(U_\ell)$ multiplies all the components and thus appears $(r-1)(s-1)$ times in the tensor product. What am I missing here?","['modules', 'contraction-operator', 'multilinear-algebra', 'tensor-products', 'differential-geometry']"
3976795,"If $Z\subset Y\subset X$ and $Z$ is closed in $Y$, then $Z=Y\cap\overline{Z}$","Suppose $X,Y,Z$ are topological spaces such that $Z\subset Y\subset X$ and $Z$ is closed in $Y$ . Is it then true that $Z=Y\cap\overline{Z}$ ? (Here $\overline{Z}$ is the closure of $Z$ in $X$ ). If $Z$ is closed in $Y$ , then $Z=C\cap Y$ for some set $C$ closed in $X$ . I'm not sure where to go from here though.",['general-topology']
3976828,$\lim f'(x) = l$,"Let $f : \left]0, +\infty\right[ \to \mathbb R$ a differentiable and bounded function such that $$\lim_{x \to +\infty} f'(x) = l$$ Show that $l = 0$ . My attempt is the following :
Suppose that $l>0$ , then $\forall \epsilon > 0, \exists x_0 > 0, \text{ such that } \forall x>x_0, \lvert f'(x) - l \rvert \leq \epsilon $ .
Taking $\epsilon = \frac{l}{2}$ , we have that $\frac{l}{2} \leq f'(x)$ $\forall x > x_0$ . Then by the mean value theorem, we can say that $\forall x > x_0, f(x) \geq \frac{l}{2}(x-x_0) + f(x_0)$ . Hence, $\lim_{x \to +\infty}f(x)= +\infty$ .
I guess we can do the same for $l < 0$ and deduce that $\lim_{x \to +\infty}f(x)= -\infty$ . So if $f$ is bounded then $l=0$ . Is it correct ?
Is there any direct proof ?","['limits', 'solution-verification', 'derivatives', 'real-analysis']"
3976840,Write the integral $\int_0^\infty \left(\frac{1}{1 + x^2} \right)^\alpha x^\beta dx$ in terms of the Euler Beta Function?,"How can I write the integral $$\int_0^\infty \left(\frac{1}{1 + x^2} \right)^\alpha x^\beta dx$$ with $\alpha, \beta >0$ , in terms of the Euler Beta Function ? For which $\alpha, \beta$ does the integral actually converge? Maybe some change of variable can do the trick?","['integration', 'multivariable-calculus', 'calculus', 'special-functions']"
3976859,Cardinal numbers and Well ordered Set,"(ZF) For every set A we denote with h*(A) the smallest ordinal α for which there is no surjective function from A to α (α is nonzero): h∗(A) = µα[¬(α ≤∗ A)].
Prove that for every set A it is true that: h∗(A) ≤ α ⇒ ¬(α ≤∗ A); h∗(A) is a cardinal number; h(A) ≤ h∗(A); If A can be  well ordered set, then it follows that h(A) = h∗(A). Before I start, I have to say that I am a liitle bit confused of the problem itself. The reason is in the notation of h(A). In previous cases, we have named h as a function of choice for A,but here the meaning is different, so I stick to what is written above,since we are in ZF. However, My ideas are:
To use the following Lemma:
.For every set A there exists an ordinal α such that there is no surjective function from A to α:
(∀A)(∃α)[¬(α ≤∗ A).
/1/ Since we have picked up the smallest such ordinal, I will try to use Transfinite recursion to prove the statement. Namely, Let P(h∗(A),α) be a property defined over all ordinals α in A,satisfying the condition we want. Then:(∃ h∗(A))P(h∗(A),α,u)->(∃ h(A))(P(h(A),α,u) and for every β(β<h(A)->¬(P(h(A),β,u)). This directly proves 1).
/2/ Since for every β(β<h*(A)->¬(P(h*(A),β,u)), a.k.a ¬(Limit(β)) and ord(h*(A)) => Nat(h*(A)). But this means card(h*(A)). To prove (3) I will use the fact that h*(A) is the min cardinal for which there is no surjection. Hence for an arbitrary cardinal number h(A)<h*(A) there is an image with Dom in h(A) and Rng in A. For (4) I think that the direct application of the Definition for well ordered set which states that : if for every subset A' of A there is a smallest element (<), then A is well ordered. But then since we have assumed that h*(A) is the min cardinal satisfying this and h(A)<h*(A), they should be equal. I will be extremely thankful if someone help to verify the correctness of my sttempts to solve it. Thank you.",['elementary-set-theory']
3976867,Evaluating $\lim_{x \to 1} \frac{1 - x^{1/\pi}}{1 - x^{1/e}}$ without de l'Hospital rule,Is it possible to evaluate this limit without de l'Hopital's rule? $$\lim_{x \to 1} \frac{1 - x^{1/\pi}}{1 - x^{1/e}}$$,"['limits', 'calculus', 'functions', 'limits-without-lhopital']"
3976887,Holomorphic differential on the algebraic curve $y^3=(x^2+1)^2(x^3-1)$,"I'm trying to find three holomorphic differential non-constant on the algebraic curve $y^3=(x^2+1)^2(x^3-1)$ in order to obtain a basis for $\mathcal{L}(K)$ . I have found the canonical divisor $$div\left(\frac{z^2}{3y^2}dx\right)=10 [0:1:0]-2[i:0:1]-2[-i:0:1]$$ I'm quite sure that $1,\frac{x^2+z^2}{y^2},\frac{z}{y}\in\mathcal{L}(K)$ , I've showed $\frac{(x^2+z^2)(x-iz)}{y^2z}\in\mathcal{L}(K)$ but it is not useful in order to find the equations of the canonical model. Any ideas?","['algebraic-curves', 'algebraic-geometry']"
3976917,Does a positive definite and radial function imply its Fourier transform is nonnegative?,"I am thinking about this question: Does a positive definite and radial function imply its Fourier transform is nonnegative? I know that the converse is correct. That is, we can apply the inverse Fourier transform formula, and the definition of the positive definite function to show the double finite sum is positive. But for the above statement, I have no further idea. Someone told me considering the Bochner theorem and I searched it that can be stated as below: Bochner's theorem ：  In order that a function $f:\mathbb{R}^d\rightarrow \mathbb{C}$ be positive definite and continuous, it is necessary and sufficient that it be the    Fourier transform of a nonnegative finite-valued Borel measure on $\mathbb{R}^d$ . But I have no idea to prove the Fourier transform of $f$ is positive. Any suggestions would be welcome! Thank you！","['fourier-analysis', 'fourier-transform', 'real-analysis', 'positive-definite', 'radial-basis-functions']"
3976934,Polyhedra which can be perfectly split into self-similar pieces,"A cube can be perfectly split into smaller equally sized cubes.  Similarly, a triangular prism can be perfectly split into smaller equally sized triangular prisms. Is there a name for or list of the set of polyhedra which can be split into smaller self-similar pieces?","['polyhedra', 'geometry', 'packing-problem']"
3976953,"Given a surjection of rings with nilpotent kernel, the root of a polynomial lifts to a unique root.","Let $ \phi : R_1 \rightarrow R_2$ be a surjection of rings such that the kernel is nilpotent, let $f \in R_1[T]$ be such that its image under the map induced by $\phi, \ $ namely $g \in R_2[T], \ $ has a root, $\overline{\alpha}$ , and $g'(\overline{\alpha}) \in R_2^\times$ . I'm trying to show that there's a unique $\alpha \in R_1$ such that: $\phi(\alpha)=\overline\alpha \ $ and $ \ f(\alpha)=0.$ Uniqueness if $ \ \alpha, \beta \in R_1$ are such that $f(\alpha)=f(\beta)=0 \ $ and $ \ \phi(\alpha)=\phi(\beta)=\overline{\alpha},\ $ then $g$ has a double root at $\overline{\alpha}$ , thus $g'(\overline{\alpha}) \notin R_2^\times \ \  \unicode{x21af}$ . Existence I was thinking that we should show that if there's a solution in $\frac{R_1}{(ker \phi)^k}, \ $ then it lifts to a solution in $\frac{R_1}{(ker \phi)^{k+1}},$ and since $$ \exists \ n \text{ with } (\ ker \ \phi \ )^n= (0), \text{ we would get a solution in } \frac{R_1}{(0)} \cong R_1 \text{ as requested}$$ but I've got no clue on how to prove the existence of a lift to $ \frac{R_1}{(ker \phi)^{k+1}}, \  $ any help?","['number-theory', 'ring-theory', 'abstract-algebra', 'polynomials']"
3976959,"Given 3 events, $S_1$, $S_2$, $S_3$, how do I express $((S_1 \cup S_2) \cap (S_2 \cup S_3) \cap (S_3 \cup S_1))$ more concisely?","Suppose I have three events: $S_1$ , $S_2$ , $S_3$ . Is there a way to express $((S_1 \cup S_2) \cap (S_2 \cup S_3) \cap (S_3 \cup S_1))$ in a simpler manner?","['elementary-set-theory', 'probability']"
3976990,Help with deriving information from a generating function,"Sequence of interest I feel like I've got most of the way, I just need some help at the last step. I am considering an integer sequence which encodes information pertaining to certain weighted ordered rooted trees. I won't bore you with the details suffice to say I found a recurrence relation for the sequence and consequently a generating function. Given the arbitrary variables $(c_0, c_1, c_2, c_3)$ , the recurrence relation is: \begin{align}
a_0 &= c_0 \\
a_n &= c_1 a_{n-1} + c_2 \sum_{i=0}^{n-2}a_ia_{n-2-i} + c_3\sum_{i=0}^{n-3}\sum_{j=0}^{n-3-i}a_ia_ja_{n-3-i-j} \hspace{2em} \text{for $n \geq 1$}
\end{align} and the generating function $A(x)$ satisfies: $$A = c_0 + c_1 (Ax) + c_2 (Ax)^2 + c_3 (Ax)^3$$ I'd like to get an asymptotic formula for this sequence, based on the variables $(c_0,c_1,c_2,c_3)$ . Bonus points for an exact formula! Simpler sequence Given the case with no weightings where $c_0 = c_1 = c_2 = c_3 = 1$ , we are just counting the number of ordered rooted trees with outdegree no greater than 3. I found this sequence on OEIS where it says $$a_n = \frac{1}{n+1}\sum_{j=0}^{\left\lfloor n/2\right\rfloor} \binom{n+1}{n-2j}\binom{n+1}{j}$$ and $$a_n \sim \frac{cd^n}{n^{3/2}}$$ where $$d = \frac{(6371+624\sqrt{78})^{2/3}+11(6371+624\sqrt{78})^{1/3}+217}{12(6371+624\sqrt{78})^{1/3}} \approx 3.610718613276\ldots$$ is the root of the equation $4d^3-11d^2-8d-16=0$ and $$c = \sqrt{\frac{f}{\pi}} \approx 0.9102276936417\ldots$$ where $$f = \frac{1}{9984}(9295 + (13(45085576939 - 795629568\sqrt{78}))^{1/3} + (13(45085576939 + 795629568\sqrt{78}))^{1/3})$$ is the root of the equation $3328f^3-9295f^2+1696f-128=0$ . I'm assuming these magical formulae were somehow derived from its generating function? But I'm afraid this is beyond my generatingfunctionology skills. I didn't know if this was more suitable for math stackexchange or mathoverflow. Please feel free to redirect me. Thanks for any help!","['trees', 'asymptotics', 'combinatorics', 'generating-functions', 'sequences-and-series']"
3976991,"Can the ""evaluate"" linear function be represented?","Let $CB(\mathbb{R})$ be the set of Bounded Continuous functions from the real line onto itself. Think of it as a linear subspace of $L^\infty(\mathbb{R})$ . Define $A\colon CB(\mathbb{R}) \to \mathbb{R}$ by $A(f) = f(0)$ .  This is a continuous linear function and $\|A\|=1$ . By the Hahn-Banach Theorem, $A$ can be extended to $A'\colon L^\infty(\mathbb{R})\to \mathbb{R} $ preserving the norm, i.e. $\|A'\|=1$ . The question is: Can $A'$ be represented by some $g \in L^1(\mathbb{R})$ ? That is: Can we find $g \in L^1(\mathbb{R})$ such that for all $f \in L^\infty(\mathbb{R})$ the following equality holds: $$
A'(f) = \int_\mathbb{R} f\cdot g \, d\lambda
$$ All i know so far is that if that $g$ exists then it must satisfy $\|g\|_1\geq 1 $ beacuse $T(f) \leq \|g\|_1\cdot\|f\|_\infty$ .
Any help would be appreciated.","['measure-theory', 'functional-analysis', 'real-analysis']"
3977014,Is the Banach Algebra generated by a separable subset separable?,"Let $A$ be a Banach algebra and $S \subset A$ a subset. Suppose $B$ is the Banach algebra generated by $S$ and that $S$ is a separable subset of $A$ . Does this imply that $B$ is separable? My intuition says the answer is yes , but I can't quite prove it. Here's my progress. For any $T \subset A$ , I define $$
W(T):=\{ t_1\cdots t_m : m \in \mathbb{N}, t_j \in T\} \subset A
$$ By definition of Banach algebra generated by a set we have that $$
B_1:=\left\{ \sum_{k=1}^n \lambda_k w_k  : n \in \mathbb{N}, \lambda_k \in \mathbb{C} , w_k \in W(S) \right\}
$$ is a dense subset of $B$ . Let $D$ be a countable dense subset of $S$ . I claim that $$
B_2:=\left\{ \sum_{k=1}^n \lambda_k w_k : n \in \mathbb{N}, \lambda_k \in \mathbb{Q}+i\mathbb{Q} , w_k \in W(D) \right\}
$$ is a countable dense subset of $B$ . That $B_2$ is countable is clear. I can't quite prove that is dense because I am having issues showing that an any element of $W(S)$ is arbitrarily close to an element in $W(D)$ . I would appreciate any help with this. It might as well be that my intuition is wrong or that I am trying to prove it in a complicated way. Thanks in advance.","['banach-algebras', 'functional-analysis', 'separable-spaces']"
3977081,Does $y = f(x) = ax+b$ actually have two mappings inside it?,"I’m just a high school student, so I may be somewhat logically flawed in understanding this. According to wikipedia, the definition of function requires an input $x$ with its domain $X$ and an output $y$ with its domain $Y$ , and the function $f$ maps $x$ to $y$ . But how about $f(x)$ ? I often see syntaxes such as $f(1) = 0$ in my textbook. Doesn’t that mean it is $f(x)$ being first assigned a value and then transfer the value into $y$ ? So, there must be two transitions/mappings between the input $x$ and the output $y$ right? My conceptual model of function is like this: A definition of function requires an input $x$ with its domain $X$ , a forwarder $f(x)$ with its domain $F$ and an output $y$ with its domain $Y$ . The function $f$ first maps $x$ to $f(x)$ then maps $f(x)$ to $y$ . These two definitions are not quite the same. On 2022.6.29: The picture below had solved my confusion.","['functions', 'logic', 'map-projections']"
3977104,This Geometry problem seems like it should be easier.,"Two ladders are located in and alley between two buildings.  They are leaned up agains the buildings such that they take up the full width of the alleyway and cross at a point 12 ft above the ground.  One ladder is 40 ft long.  The other ladder is 30 ft long. How wide is the alley? I was able to find a quartic equation that gave the height above the ground where the 30' ladder meets the building. $x^4 - 24x^3 + 700x^2 - 16800 x + 100800 = 0$ I did not see an easy way to solve this, and plugged it into wolfram alpha.  WA gives a solution to this quartic of 19.000.
But, 19 can't be a root by the rational root theorem... The root is very nearly, but not exactly 19. And then we can use the Pythagorean theorem to find that $w\approx \sqrt {539}$ On the face of it this problem seems like it should not require quartic equations.  I am curious to know if anyone has a simpler solution, and even better an exact solution.","['algebra-precalculus', 'puzzle', 'polynomials', 'geometry']"
3977144,Double partial derivative proof,"Let $z=f(x,y)$ where $x:=r \cos \theta$ and $y := r \sin \theta$ .
I had to prove that $\frac {\partial ^{2}z}{\partial \ x^{2}} + \frac {\partial ^{2}z}{\partial \ x^{2}} = \frac {\partial ^{2}z}{\partial \ r^{2}} \ + \dots$ The whole equation was given. My doubt: I applied Jacobian and tried to solve this but I ended up in a loop where I was substituting the same things back and forth. The solution provided said this. $\frac {\partial ^{2}z}{\partial r^{2}} \ = \frac {\partial}{\partial r}(\frac {\partial z}{\partial r})  = \frac {\partial}{\partial r}(\cos \theta \frac {\partial z}{\partial x} + \sin \theta \frac {\partial z}{\partial y})$ $ = \cos \theta \ [ \cos \theta \frac {\partial}{\partial x} + \sin \theta \frac {\partial }{\partial y} ](\frac {\partial z}{\partial x}) \ + \sin \theta [ \cos \theta \frac {\partial }{\partial x} + \sin \theta \frac {\partial }{\partial y} ] (\frac {\partial z}{\partial y}).$ I do not understand the last step. What exactly is happening? Why do we use the partial derivative of $z$ with respect to $r$ (and skip the $z$ in the numerator) and multiply it with partial derivative of z with respect to $x$ and $y$ ? Since $x$ and $y$ are functions of $r$ and $\theta$ and since in $\frac {\partial z}{\partial x}$ we have kept $y$ constant are we accounting for that? I am really confused as this relevant theory wasn't taught in class and the professor hasn't been helpful to clear this part. Any insight is highly appreciated.","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
3977151,Immersion and Submersion between Manifolds,"I am reading ""An introduction to Manifolds"" by Loring Tu. There they've first defined immersion and submersion between manifolds and then gave an example. In the last line of the example they've written This example shows in particular that a submersion need not be onto. And i am unable to understand that statement. For reference the following is the way they've defined immersion and submersion:
A $C^\infty$ map $F:N\to M$ is said to be an immersion at $p\in N$ if its differential $F_{*,p}:T_pN\to T_{F(p)M}$ is injective and a submersion at p if $F_{*,p}$ is surjective.We call F an immersion if it is an immersion at every $p\in N$ and a submersion if it is a submersion at every $p\in N$ . I am attaching the screenshot of the example they've given and there i have highlighted the statement that i could not understand. My doubt is that surjective by definition means onto so how can a submersion need not be onto?","['smooth-manifolds', 'manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3977194,Prove $f(x)$ is constant.,"Suppose $ f: \mathbb{R} \mapsto \mathbb{R}$ be continous. For any interval $[a,b]$ , there exists $x_0\in (a,b)$ such that either $f(x_0)=\max\limits_{a\le x \le b} f(x)$ or $f(x_0)=\min\limits_{a\le x \le b} f(x)$ . Prove $f(x)$ is constant. We may consider apply Reductio ad Absurdum . Suppose $f(x)$ is not constant, then there exist $\alpha<\beta$ such that $f(\alpha)\neq f(\beta).$ But how to reduce the contradiction?","['continuity', 'calculus', 'analysis']"
3977216,I am looking for an example of an open set in $\operatorname{Spec}(R)$ equipped with the Zariski topology which is not compact.,"I have learned the basic open sets i.e. the sets of the form $\{P\in\operatorname{Spec}(R): x\notin P\}$ where $x$ is a fixed element of $R$ are compact. Now any open set is union of such basic open sets. For an example I was thinking of taking $R$ as $k[x_1,x_2,x_3,...]$ then letting $X$ =the set of inderminates, the set $U=\{P\in\operatorname{Spec}(R): X\not\subset P\}$ is open in $\operatorname{Spec}(R)$ . I am thinking that this open set will be non compact. Am I right with my example? Please help me with it by commenting on my example or by providing a suitable one.","['zariski-topology', 'ring-theory', 'algebraic-geometry', 'commutative-algebra', 'compactness']"
3977225,Formalizing composition of sequences,"The following first equality is intuitively evident: $$
\lim_{n\to \infty} \left(1+\frac{x+y+\frac{xy}{n}}{n}\right)^n 
= \lim_{n\to \infty} \left(1+\frac{x+y}{n}\right)^n
=e^{x+y}
$$ how can I give a formal argument ? Informally it is something like $$
\lim_{n\to \infty} \left(1+\frac{x+y+\frac{xy}{n}}{n}\right)^n 
=\lim_{n\to \infty} \left(1+\frac{\lim_{n\to \infty}\left(x+y+\frac{xy}{n}\right)}{n}\right)^n 
=\lim_{n\to \infty} \left(1+\frac{x+y}{n}\right)^n 
$$ Is there a "" classical "" property of sequences that backs this argument? Something like limit of composition, but here we speak of sequence only: $$
(b_n),\quad b_n \to b\quad\text{ for }n\to\infty \implies 
\lim_{n\to \infty} \left(1+\frac{b_n}{n}\right)^n
=\lim_{n\to \infty} \left(1+\frac{b}{n}\right)^n
$$ EDIT As Qiaochu Yuan is important to define what I have already defined.
This computation is at the beginning of ""Real Analysis"", lets say in the chapter of sequences. Later, in the notes of complex analysis, I develop formal series with derivation and everything is the standard way (I think). By this question I tried another approach, very early (1) define $$
e^x = \lim_{n\to\infty}\left(1+\frac{x}{n}\right)^n
$$ (2) derive the product as depicted in this question
(3) derive the derivation of the $e^x$ . Thus I have (a) no logarithm, (b) no derivation of $e^x$ yet.","['limits-without-lhopital', 'sequences-and-series', 'exponential-function', 'real-analysis']"
3977255,Stability of Solutions to Linear ODE,"The questions is: Check the stability of the solutions to the following equation: $$
y^{(11)}-|cos(t)|y^{(10)} +3t^3ArcTan(t)y=1
$$ My take: --- Solved--
I used Abel's formula $$ \dot W=|Cos(t)|W$$ and got that (edit: it's wrong) $$ W(t) = W(0) \cdot e^{|sint|} $$ I'm not sure if it's enough to show that $W \not \xrightarrow[t\to\infty]{} \infty $ in order to ensure stability of the ODE. Edit: the Wronskian is NOT what I stated: $W(0) \cdot e^{|Sin(t)|}$ because the integral: $$\int_{0}^{t} |Cos(s)| ds \not =|sin(t)| $$ the limit of that integral when t approaches infinity is $\infty$ , $$, W\xrightarrow[t\to\infty]{} e^\infty =\infty$$ from that we can infer that one of the columns of the fundemental matrix is not bounded (because the determinant of that matrix (the Wronskian) is approaching infinity).
and from that we can say that one solution is not stable, so every other solution is not stable. - (if I made a mistake please correct me)","['stability-in-odes', 'wronskian', 'ordinary-differential-equations']"
3977263,What's the Lie algebra associated to positive-defined Hermitian matrices?,"I'm studying polar decomposition $GL(n,\Bbb C)\cong U(n)\times Herm^+(n)$ , where $Herm^+(n)$ are positive-defined Hermitian matrices. I was trying to understand what happens to the associated Lie algebras, and I was wondering what $Herm^+(n)$ Lie algebra would look like. What I tried: I know that considering $F:SL(n,\Bbb R)\to SL(n,\Bbb R):A\mapsto A^\top A$ , since $SO(n)=F^{-1}(I_n)$ , we can prove that $\mathfrak{so}(n)$ is the space of skew-symmetric matrices by calculating $$\mathfrak{so}(n)=\ker (dF_{I_n})=\left\{A\in\Bbb R^{n\times n} : \left. \frac d{dt}\right\vert_{t=0}F(I_n+tA)=0\right\}.$$ I wondered if I could do something similar for $Herm(n)$ , defining $G:\Bbb C^{n\times n}\to\Bbb C^{n\times n}:A\mapsto A^*-A$ and $Herm(n)=G^{-1}(O_n)$ , but I then realised that being $Herm(n)$ a linear subspace of $\Bbb C^{n\times n}$ I would just find $Herm(n)$ again. Is this a correct answer? Is $Herm(n)$ itself its own associated Lie algebra (with the commutator as Lie bracket)? And what about positive-defined ones? What useful characterization may I take advantage of? Thanks in advance!","['linear-algebra', 'lie-algebras', 'lie-groups', 'differential-geometry']"
3977268,"A mere coincidence? $\tan5^n<0$ for all $1\leq n \leq 23, n \neq 17$","I was playing around with $\tan e^n$ and realized that $\tan5^n$ has an interesting property: $$
\begin{eqnarray}
\tan 5^{1}&=&-3.380515\ldots\\
\tan 5^{2}&=&-0.133526\ldots\\
\tan 5^{3}&=&-0.782060\ldots\\
\tan 5^{4}&=&-0.178807\ldots\\
\tan 5^{5}&=&-1.221283\ldots\\
\tan 5^{6}&=&-3.364104\ldots\\
\tan 5^{7}&=&-0.126782\ldots\\
\tan 5^{8}&=&-0.729953\ldots\\
\tan 5^{9}&=&-0.011144\ldots\\
\tan 5^{10}&=&-0.055778\ldots\\
\tan 5^{11}&=&-0.286042\ldots\\
\tan 5^{12}&=&-5.565505\ldots\\
\tan 5^{13}&=&-0.811792\ldots\\
\tan 5^{14}&=&-0.274453\ldots\\
\tan 5^{15}&=&-4.242139\ldots\\
\tan 5^{16}&=&-0.438533\ldots\\
\tan 5^{17}&=&1.8498218\ldots\\
\tan 5^{18}&=&-1.278866\ldots\\
\tan 5^{19}&=&-5.604437\ldots\\
\tan 5^{20}&=&-0.821873\ldots\\
\tan 5^{21}&=&-0.307247\ldots\\
\tan 5^{22}&=&-12.42162\ldots\\
\tan 5^{23}&=&-2.354334\ldots\\
\tan 5^{24}&=&0.4677197\ldots\\
\tan 5^{25}&=&-1.410674\ldots\\
\tan 5^{26}&=&17.137346\ldots\\
\tan 5^{27}&=&3.3336581\ldots\\
\tan 5^{28}&=&0.1141382\ldots\\
\tan 5^{29}&=&0.6384773\ldots\\
\tan 5^{30}&=&-0.309809\ldots\\
\end{eqnarray}
$$ It is worth noting that the first 16 $n$ s and 22 $n$ s out of the first 23 satisfy $\tan5^n<0$ , in other words, $5^n\bmod\pi>\pi/2$ . If this is completely by chance, it seems like a little too much luck.
I have an explanation for $n=9,10,11,12$ : because $5^9\bmod\pi\approx0$ . But the others seems to be a coincidence, and we can say that $5^9\bmod\pi\approx0$ itself is also a coincidence. Is there any explanation for this?","['trigonometry', 'pi', 'exponential-function', 'modular-arithmetic']"
3977288,"Closed form of $x_{n+1}=x_n-1/x_n$ with $x \neq 0,1$","I have the sequence $x_{n+1}=x_n-1/x_n$ with $x \neq 0,1$ For certain values of $x_0$ this sequence will be periodic. To find these values one can look at the root of: $x_{p} = x_0$ where $p$ is the period. For $p=2$ this can be solved easily. For $p>10$ it's not viable to define the function recursively and search for roots numerically.
To look for the roots at higher values of $p$ I'm searching for a closed form of this formula. I already found an answer to a similar problem , but failed to transfer the solution to my different sequence. I tried using the same approach. By $x=\cot(\theta)$ you get: $x_1=2\cot(2\theta)=\cot(\theta)-\frac{1}{\cot(\theta)}$ I calculated $x_2$ by hand which is: $x_2=\cot(4\theta)+\frac{3}{2}\cot(2\theta)$ But I wasn't able to find a simple formula for $x_3$ Any help with finding a closed form (or an idea how to find the roots more easily) would be appreciated! EDIT: I moved my follow up questions to a seperate topic","['calculus', 'closed-form', 'algebra-precalculus', 'sequences-and-series']"
3977307,Do universally connected spaces exist?,"Let's call a topological space $X$ connected iff it can not be represented as a disjoint union of two non-empty open sets. Now, suppose $X$ and $Y$ are both topological spaces. Let's say $X$ is $Y$ -connected iff $\forall x_0, x_1 \in X$ $\exists y_0, y_1 \in Y$ and a continuous function $f: Y \to X$ such that $f(y_0) = x_0$ and $f(y_1) = x_1$ . Those two variants of connectivity are connected in the following ways: If $X$ is $Y$ -connected and $Y$ is connected then $X$ is also connected. Proof: Suppose, $X$ is not connected. Then it is a disjoint union of two non-empty open sets $U$ and $V$ . Let's take $x_0 \in U$ and $x_1 \in V$ . Then $Y$ will not be connected as a disjoint union of two non-empty open sets $f^{-1}(U)$ and $f^{-1}(V)$ , Q.E.D. Converse is however generally false - for example, $\{(t, \sin(\frac{1}{t})|t \in \mathbb{R})\} \cup \{(0, 0)\}$ is connected, but not $[0;1]$ -connected. If $Y$ is not connected, then all topological spaces are $Y$ -connected. Proof: Suppose, $Y$ is not connected. Then it is a disjoint union of two non-empty open sets $U$ and $V$ . Now, suppose $X$ is an arbitrary topological space and $x_0, x_1 \in X$ . Now we take $y_0 \in U$ , $y_1 \in V$ and define $f$ as $$f(y) = \begin{cases} x_0 & \quad y \in U \\ x_1 & \quad y \in V \end{cases}$$ Those $y_0, y_1$ and $f$ satisfy our conditions. That means, $X$ is $Y$ -connected, Q.E.D. If $X, Y$ and $Z$ are such topological spaces, that $X$ is $Y$ -connected and $Y$ is $Z$ -connected then $X$ is $Z$ -connected. Suppose $x_0, x_1 \in X$ . Thes $\exists y_0, y_1 \in Y$ and and a continuous function $f: Y \to X$ such that $f(y_0) = x_0$ and $f(y_1) = x_1$ . There also $\exists z_0, z_1 \in Z$ and a continuous function $g: Z \to Y$ such that $f(z_0) = y_0$ and $f(z_1) = y_1$ . Then $f(g(z_0)) = x_0$ and $f(g(z_1)) = x_1$ , which means $X$ is $Z$ -connected, Q.E.D. Now let's call a topological space $Y$ universally connected iff a topological space being $Y$ -connected is equivalent to it being connected (equivalently, $Y$ is connected and all connected spaces are $Y$ -connected) My question is: Do universally connected spaces exist?","['continuity', 'general-topology', 'connectedness']"
3977310,Proof of one-side version of Bennett-Bernstein inequality,"I'm going to prove the following: For independent random variables $X_i$ , $i \in [m]$ satisfying $X_i-E[X_i] \le b$ for some constant $b > 0$ . Let $\bar{X} = \dfrac{1}{m}\sum_{i=1}^m X_i$ , we have \begin{equation}
		P(\bar{X}\ge E[\bar{X}]+\varepsilon) 
		\le \exp\left(\dfrac{-m\varepsilon^2}{2(\frac{1}{m}\sum_{i=1}^m Var[X_i]+\frac{1}{3}b\varepsilon)}\right)
	\end{equation} and here is my trial: Lemma: Let $f(u) = 2\cdot\frac{e^u-u-1}{u^2}$ and $f(0) := 1$ . $f'(u) \ge 0$ and for $u \in (0, 3)$ , $f(u) \le \left(1-\frac{u}{3}\right)^{-1}$ . For random variable $X$ with $EX=0$ , $P(X \le b)=1$ and $\lambda \in \left(0, \frac{3}{b}\right)$ , $E[X^2] = Var[X]$ , $f(\lambda X) \le f(\lambda b)$ , \begin{equation}
	E[\exp(\lambda X)]
	=1+\lambda E[X]+\frac{1}{2}\lambda^2E[X^2f(\lambda X)]
	\le 1+\frac{1}{2}\lambda^2(1-\frac{\lambda b}{3})^{-1} Var[X] 
	\le \exp\left(\frac{1}{2}\lambda^2(1-\frac{\lambda b}{3})^{-1} Var[X]\right)
\end{equation} Proof: For independent random variables $X_i$ , $i \in [m]$ satisfying $X_i-E{X_i} \le b$ and $\bar{X} = \frac{1}{m}\sum_{i=1}^m X_i$ , we have \begin{align}
		P\left(\bar{X}\ge E[\bar{X}]+\varepsilon\right)
		&= P\left(\sum_{i=1}^m(X_i-E{X_i})\ge m\varepsilon\right) \\
		&\le E[\exp(\lambda\sum_{i=1}^m(X_i-E{X_i}))] \cdot \exp(-\lambda m\varepsilon) \\
		&= \prod_{i=1}^m E[\exp(\lambda(X_i-E{X_i}))] \cdot \exp(-\lambda m\varepsilon) \\
		&\le \prod_{i=1}^m \exp\left(\frac{1}{2}\lambda^2(1-\frac{\lambda b}{3})^{-1} Var{[X_i]}\right) \cdot \exp(-\lambda m\varepsilon) \\
		&= \exp\left(\frac{1}{2}\lambda^2(1-\frac{\lambda b}{3})^{-1} \sum_{i=1}^m Var[X_i] -\lambda m\varepsilon\right)
	\end{align} Let $\lambda = \dfrac{\varepsilon}{\frac{1}{m}\sum_{i=1}^m Var[X_i]+\frac{1}{3}b\varepsilon}$ (Note that this time $\lambda^2(1-\frac{\lambda b}{3})^{-1} \sum_{i=1}^m Var[X_i] = \lambda m\varepsilon$ and the right hand side takes $\exp\left(\dfrac{-m\varepsilon^2}{2(\frac{1}{m}\sum_{i=1}^m Var[X_i]+\frac{1}{3}b\varepsilon)}\right)$ . $\Box$ This seems fine. But when I try to prove it more directly, I meet some difficulty. $X_i-E{X_i} \le b$ and $\bar{X} = \frac{1}{m}\sum_{i=1}^m X_i$ , so we have $E[\bar{X}] \le b$ and $Var[\bar{X}] = \frac{1}{m^2}\sum_{i=1}^m Var[X_i]$ and \begin{align}
P\left(\bar{X}\ge E[\bar{X}]+\varepsilon\right) &\le \exp\left(\frac{1}{2}\lambda^2(1-\frac{\lambda b}{3})^{-1} Var[\bar{X}]\right) \cdot \exp(-\lambda \varepsilon) \\
&= \exp\left(\frac{1}{2}\lambda^2(1-\frac{\lambda b}{3})^{-1} \sum_{i=1}^m \frac{1}{m^2} Var[\bar{X}_i]-\lambda \varepsilon\right)
\end{align} If we want to get the same result, we may consider multiply $\lambda$ by a factor $m$ , but this is invalid since the $(1-\frac{\lambda b}{3})^{-1}$ term is unchanged and $\lambda$ is bounded by $\lambda < \frac{3}{b}$ . So where's the problem and how should I proceed?","['moment-generating-functions', 'solution-verification', 'inequality', 'probability-theory', 'probability']"
3977367,Question about algebraically equivalent divisors,"I'm trying to do exercise V.1.1.7 in Hartshorne, about algebraic equivalence of divisors, and the first problem is to show that the divisors algebraically equivalent to zero form a subgroup of $Div(X)$ . Here's a recap of Hartshorne's definition: Let us define algebraic equivalence of divisors. We first do it for an effective divisor (i.e. a divisor that actually correspond to an ideal sheaf $\mathscr I$ ). Then it corresponds to some subscheme $C$ of $X$ . A family of effective divisors is an effective divisor $D$ on $X \times T$ , together with a flat map $\pi: X \times T \to T$ , where $T$ is some smooth curve. If $0,1 \in T$ are two points, we say that $D_0$ (setting $t=0$ ) and $D_1$ are prealgebraically equivalent . Arbitrary divisors can be written as differences between effective divisors, and we say that these are prealgebraically equivalent if they can be written as differences between prealgebraically equivalent divisors. Two divisors $D, D'$ are algebraically equivalent if there is sequence $D=D_0D_1, \ldots, D_{n-1}D_n=D'$ with $D_i$ and $D_{i+1}$ prealgebraically equivalent. So to do the exercise, I have to show that if $D \equiv 0$ and $E \equiv 0$ , then $D+E \equiv 0$ . Since $D=D'-D'' \equiv 0$ (with $D'$ and $D''$ effective), we have a family $\pi: X \times T \to T$ as above, and similarly for $E$ , possibly with a different $T$ . Here comes the problem. If I want to show that $D+E=(D'+E')-(D''+E'') \equiv 0$ , then I have to find a family $X \times T^{''} \to T^{''}$ and an effective divisor $\mathscr D \subset X \times T^{''}$ with $\mathscr D_0=D'+E'$ and $\mathscr D_1=D''+E''$ . The problem is I don't see how to do it. It would have been almost trivial if we could use the same curve $T$ in the all the families (then the answer would be just look at the ideal sheaves in the total space and tensor them). Does anyone have a hint/explanation? I sorta feel that I should be able to assume that $T= \mathbb A^1$ , but I dont know how.","['divisors-algebraic-geometry', 'algebraic-geometry']"
3977387,How to rewrite $\int\limits_{x = 0}^{ + \infty } {\frac{{\exp \left( { - ax - \frac{b}{x}} \right)}}{{1 + cx}}dx}$?,"How to rewrite this improper integral in term of any special function $\int\limits_{x = 0}^{ + \infty } {\frac{{\exp \left( { - ax - \frac{b}{x}} \right)}}{{1 + cx}}dx}$ or at least written it as an infinite sum ? This is a follow up post from the previous one How to evaluate $\int\limits_0^\infty {\frac{{{e^{ - x - \frac{1}{x}}}}}{{1 + x}}dx}$ in form of special function? That is $\int\limits_{x = 0}^{ + \infty } {\frac{{\exp \left( { - x - \frac{1}{x}} \right)}}{{1 + x}}}  = {K_0}\left( 2 \right)$ Where ${K_M}\left( x \right)$ denote the modified Bessel function of the second kind I hope that I could generalized the old result ! Notice that $a,b,c$ are all positive number.","['integration', 'improper-integrals', 'special-functions']"
3977414,Simplifying a radical-trigonometric expression for the hendecagon angle,"This question is related to my very first question on this site, on constructing the hendecagon. The Gleason paper I referred to states the following identities, which lead to constructions of a regular heptagon and $13$ -gon with compass/straightedge/angle trisector: $$1+6\cos\frac{2\pi}7=\sqrt{28}\cos\left(\frac13\cos^{-1}\frac1{\sqrt{28}}\right)\tag A$$ $$1+12\cos\frac{2\pi}{13}=\sqrt{13}+\sqrt{104-8\sqrt{13}}\cos\left(\frac13\tan^{-1}\frac{\sqrt3(\sqrt{13}+1)}{7-\sqrt{13}}\right)\tag B$$ Using GAP's RadiRoot package I have derived $$1+10\cos\frac{2\pi}{11}=11(z\omega + (-2+2z-z^4)\omega^2 + (12+6z+10z^2+3z^4)\omega^3 + (26+16z+41z^2+6z^3)\omega^4)\tag1$$ where $$z=e^{2i\pi/5}\qquad\omega=\frac1{\sqrt{11}}e^{i\theta}\qquad\theta=-\frac15\cos^{-1}-\frac{979+275\sqrt5}{4\cdot11^{5/2}}$$ So a hendecagon can be consructed by compass, straightedge and one angle quinsection (cf. here ): construct $z$ with compass and straightedge, construct $\omega$ using the quinsector and perform basic arithmetic operations until you get $\cos\frac{2\pi}{11}$ . However, the construction implied by $(1)$ would be very long and tedious. Can $(1)$ be simplified to something like $(\rm A)$ and $(\rm B)$ , where $1+10\cos\frac{2\pi}{11}$ equals a low-degree (preferably linear) polynomial in $\cos\theta$ with real coefficients? Would the result lead to an easily stated explicit Gleason-type construction?","['geometric-construction', 'radicals', 'polygons', 'galois-theory', 'trigonometry']"
3977466,Find the number of real values of $x$ such that $x^2 + 10000[x] = 10000x$ ($[]$ is the floor function),"Find the number of real values of $x$ such that $x^2 + 10000[x] = 10000x$ ( $[]$ is the floor function) What I Tried : If $x$ is an integer then :- $$x^2 = 0$$ $$\rightarrow x = 0$$ So $x = 0$ is the only integer solution, the problem with me is to look for real solutions. I have no clear idea on how to start doing it. One thing I did was let $[x] = x - \{x\}$ . We have :- $$x^2 + 10000(x - \{x\}) = 10000x$$ $$\rightarrow x^2 - 10000\{x\} = 0$$ $$\rightarrow x^2 = 10000\{x\}$$ Can anyone help me here?","['ceiling-and-floor-functions', 'linear-algebra', 'problem-solving', 'discrete-mathematics']"
3977506,Solve equation $\sin x + \cos x= i$,"Could anyone help with following equation? $$\sin(x) + \cos(x) = i$$ Solution either in C or R . First of all, sorry for dummy question. And even dummier followup. What is wrong with following reasoning? $(\sin(x) + \cos(x))^2 = i^2$ $((\sin(x))^2 + (\cos(x))^2 + 2\sin(x)\cos(x) = -1$ $2\sin(x)\cos(x) = -2$ $\sin(2x) = -2$ Which is out of sine codomain ): ? Really appreciate the help!","['trigonometry', 'complex-numbers']"
3977529,How to prove if the relation R is an equivalence relation?,"Hello so I stumbled upon an exercise where I need to prove that R is an equivalence relation, normally I have no problem doing this, but with this exercise I have absolutely no clue where to begin. I think my biggest problem is understanding what's given. The exercise goes as follows: $X$ and $Y$ are two sets. We notate $Fun(X,Y)$ is the set of all functions $f:X\rightarrow Y$ . Let $R$ be the relation on $Fun(X,Y)$ given by: $(f,g) \in R$ if and only if there exist a bijective function $\sigma:Y \rightarrow Y$ with $\sigma \circ f =g $ . Prove that $R$ is an equivalence relation. What I know $R$ is an equivalence relation when $R$ is reflexive, symmetric and transitive (so this is what I need to prove). $R$ is reflexive if for all $x\in X : xRx$ $R$ is symmetric if for all $x,y\in X : xRy \rightarrow yRx$ $R$ is transitive if for all $x,y,z \in X: xRy \text{ and } yRx \rightarrow xRy$ If someone could help me, it would be very kind of you :) Thank you in advance","['equivalence-relations', 'proof-writing', 'solution-verification', 'discrete-mathematics']"
3977600,Advantages of pathwise stochastic integrals over standard Itô integrals,I am currently reading about Föllmer's construction of a stochastic Integral that is defined in a pathwise sense. But I am not sure what exactly the purpose of such a construction is. The main applications seem to be in the area of Finance. But in my studies in that area I have not run into situations where the fact that the Itö integral is defined probabalistic causes any problems. Could someone maybe provide an intuition as to why such a construction is useful or maybe give an example of when it is?,"['stochastic-integrals', 'finance', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3977637,Invariance of boundary proof attempt,"Problem: Suppose $F:M\rightarrow N$ is a diffeomorphism between manifolds with boundary.
Then $F(\partial{M})=\partial{N}$ . My attempt: Let $F(p)\in F(\partial{M})$ for $p\in \partial{M}$ . This means for any chart $(U,\phi)$ about $p$ , $\phi(p)\in \partial{H^m}$ . Choose any chart $(U,\phi)$ about $p$ .Let $(V,\psi)$ be any chart in $N$ about $F(p)$ . Then notice $\psi(F(p))=\psi(F(\phi^{-1}(\phi(p))=(\psi\circ F \circ \phi^{-1})(\phi(p))$ . As $\psi \circ F \circ \phi^{-1}:\phi(U\cap V)\rightarrow \psi(U\cap V)$ is a diffeomorphism, the result result follows from the following lemma: Suppose $U$ and $V$ are open in $\mathbb{H}^n$ and $f:U\rightarrow V$ a diffeomorphism. Then if $p\in U$ is an interior point of $\mathbb{H}^n$ , then $f(p)$ is an interior points of $\mathbb{H}^n$ . Similarly if $p$ was a boundary point of $\mathbb{H}^n$ . For the converse, let $q\in \partial{N}$ . By assumption, there exists a unique $p\in M$ such that $F(p)=q \iff F^{-1}(q)=p$ . Since $F^{-1}$ is smooth, repeating the same argument above, the result follows. is this correct?","['solution-verification', 'smooth-manifolds', 'differential-geometry']"
3977644,How to show frechet characterization differentiability 2,"Let $U\subset R^{n} $ and $f:U\to R$ . Show that: $f$ is differetiable in $x_0\in U$ iff exist $A\in L(R^{n},R)$ and exist $r>0$ : $\lim_{t\rightarrow 0^{+}}\frac{f(x_0 +tv)-f(x_0)}{t}=Av$ uniformly in $v\in r\mathcal{S}^{n-1}$ with $\mathcal{S}^{n-1}$ is unitary sphere. Attempt $\Rightarrow$ Suppose that $f$ is differentiable in $x_0\in U$ , then exist $A_{x_0}:R^{n}\to R$ linear transformation such that $f(x_0 +y)=f(x_0)+A_{x_0}(y)+||y||E_{x_0}(y)$ where $E_{x_0}(y)\rightarrow 0$ when $y\rightarrow 0$ , equivalently $\frac{f(x_{0} + y)-f(x_{0})}{||y||}-\frac{A_{x_0}(y)}{||y||}=E_{x_0}(y)$ , now if i take $z=r\frac{y}{||y||}$ then $\frac{y}{||y||}\in \mathcal{S}^{n-1}$ and $y=\frac{||y||}{r}z$ , if we will call $t=\frac{||y||}{r}$ imply $\frac{f(x_{0} + tz)-f(x_{0})}{tr}-A_{x_0}(\frac{z}{r})=E_{x_0}(tz)$ and when i take limit when $t\rightarrow 0$ tehn $\lim_{t\rightarrow 0}\left( \frac{f(x_{0} + tz)-f(x_{0})}{tr}-A_{x_0}(\frac{z}{r}) \right)=\frac{1}{r}\left[\lim_{t\rightarrow 0}\frac{f(x_{0} + tz)-f(x_{0})}{t}-A_{x_0}(z)\right]=\lim_{t\rightarrow 0}E_{x_0}(tz)=0$ hence $\lim_{t\rightarrow 0}\frac{f(x_{0} + tz)-f(x_{0})}{t}=A_{x_0}(z)$ with $z\in r\mathcal{S}^{n-1}$ . $\Leftarrow$ Now by hypothesis $\lim_{t\rightarrow 0}\frac{f(x_{0} + tv)-f(x_{0})}{t}=A_{x_0}(v)$ with $v\in r\mathcal{S}^{n-1}$ uniformly, then $v=rw$ with $r>0$ and $w\in \mathcal{S}^{n-1}$ so $\lim_{t\rightarrow 0}\frac{f(x_{0} + trw)-f(x_{0})}{t}=A_{x_0}(rw)=rA_{x_0}(w)$ or the same way $\lim_{t\rightarrow 0}\frac{f(x_{0} + trw)-f(x_{0})}{rt}=A_{x_0}(w)$ , but if we choose $h=tr$ when $t\rightarrow 0$ hence $h\rightarrow 0$ imply $\lim_{h\rightarrow 0}\frac{f(x_{0} + hw)-f(x_{0})}{h}=A_{x_0}(w)$ and this is a definition of differentiablility in $x_0$ . My profesor say that i m not using the condition of uniformly no anywhere and my proof is confuse, therefore i have to proof that exist $r$ , i just take one but i dont know how to show that exist,  can somebody to help me please, thank you","['frechet-derivative', 'multivariable-calculus']"
3977672,Why should we use the fundamental definition of derivative while checking differentiability?,"I have seen in many examples that using the fundamental definition of derivative only gives the correct results while checking for differentiability at a point. But why do we get wrong results while we directly apply the rules of differentiation and taking the limit at the point. Here is an example $$y = \begin{cases}
x^2, &-\infty < x < 1\\
2x, &1\leq x < \infty
\end{cases}
$$ If we check the differentiability at the point $x=1$ then when we apply the rules of differentiation left hand and right hand derivative becomes same. But by using fundamental definition of derivative it will be different. But if I am right the rules of differentiation are in fact derived from the fundamental definition of derivative? So both of these should give correct result. Or it seems like I am missing some basic concept. I have seen same question like this one here . The answer to this question only says it gives wrong result.But it doesn't answer the question of why?","['calculus', 'derivatives']"
3977700,Understanding Complex Operators,"I am not a follower of Schaum's Outline of Complex Variables but for seeking my professor lecture I read the third chapter called Complex Differentiation and the Cauchy-Riemann Equations . And I introduced some of the complex operators which isn't explained well manner in that chapter. Here are those: If $A(x,y)=P(x,y)+iQ(x,y)$ is a complex
continuously differentiable function of $x$ and $y$ (vector? isn't those come from $\mathbb R$ ) then $$\text{grad }A=\nabla A=\frac{\partial P}{\partial x}-\frac{\partial Q}{\partial y}+i\left(\frac{\partial P}{\partial y}+\frac{\partial Q}{\partial x}\right)$$ The $\nabla$ del symbol can be interpreted as a vector of partial derivative operators, and its three possible meanings—gradient, divergence, and curl—can be formally viewed as the product with a scalar, a dot product, and a cross product, respectively, of the del ""operator"" with the field. But I can't relate the above operation with any of those mentioned category (linked statement from Wikipedia). Rather it seems complex multiplication of two number. The divergence of $A$ is, $$\text{div }A=\nabla\cdot A=\text{Re}\{\bar\nabla A\}=\text{Re}\left\{\left(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y}\right)(P+iQ)\right \}$$ The curl of $A$ is, $$|\text{curl }A|=|\nabla \times A|=|\text{Im}\{\bar \nabla A\}|=\left|\text{Im}\left\{\left(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y} \right)(P+iQ) \right\}  \right|=\left| \left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y} \right)\right|$$ There is no reference to how those formulas come from. I really want to know their derivation. Any reference or solution would be great helpful for me.","['complex-analysis', 'multivariable-calculus', 'vector-analysis']"
