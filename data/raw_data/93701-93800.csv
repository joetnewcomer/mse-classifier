question_id,title,body,tags
1280222,Ordinals - motivation and rigor at the same time,Can someone provide a description of ordinals within ZFC in a rigorous way that exhibits motivation? Every description or explanation I see in the literature or on the Internet is either too formal with no motivation provided or too simple with no rigor. I've been truly baffled by the concept of ordinals for the last couple days.,"['motivation', 'elementary-set-theory', 'ordinals', 'logic', 'intuition']"
1280225,Are all groups algebraic?,"I know the definition of a group as a set with an operation that satisfies certain axioms. I have heard that there is something called an algebraic group and that this is a group with a topology such that the multiplication and inverses are continuous (or something like that). My question is: Given a group $G$, can this group always be viewed as an algebraic group? From the comments below, I am pretty sure that O don't mean a topological group. I am thinking about the algebraic variety stuff.","['definition', 'algebraic-groups', 'abstract-algebra', 'algebraic-geometry', 'examples-counterexamples']"
1280241,A trigonometric product,"I have to prove: $$\prod_{i=1}^6 \left(2\cos\left(\frac{2^{i}\pi}{13}\right)-1\right)=1$$ I really have no idea about starting with this one. With the help of Wolfram Alpha, I noticed that: $$\left(2\cos\left(\frac{2\pi}{13}\right)-1\right)\left(2\cos\left(\frac{8\pi}{13}\right)-1\right)\left(2\cos\left(\frac{32\pi}{13}\right)-1\right)=1$$ and $$\left(2\cos\left(\frac{4\pi}{13}\right)-1\right)\left(2\cos\left(\frac{16\pi}{13}\right)-1\right)\left(2\cos\left(\frac{64\pi}{13}\right)-1\right)=1$$ Any help is appreciated. Thanks!","['products', 'algebra-precalculus', 'trigonometry']"
1280272,Group of Order $5$,"Let $G$ be a group of order $5$ with elements $a, b, c, d, 1$ where $1$ is the identity element. This is the definition of the group. We all know that this can't be a group because any group of order $5$ is abelian but according to my definition this group is not abelian. But my question is why can't this be a group when it satisfies all the criteria mentioned in the definition of a group. I wish to find a reason for its ability of not being a group just from the definition of group. For example one can say that the diagonal elements are $1$, which means we have subgroups of order $2$, which is not possible for a group of order $5$. But this is not what I am seeking. Please explain me using nothing more than just the four criteria of the definition of group.",['group-theory']
1280305,"If $A$ is a finite set in $(\mathbb R, \mathfrak T_U)$ then $A' = \emptyset$.","If $A$ is a finite set in $(\mathbb R, \mathfrak T_U)$ then $A' = \emptyset$. My knowledge:
$\mathfrak T_U$ is the usual topology $A'$ is the set of all limit points and my definition for this is: Let $(X, \mathfrak T)$ be a topological space with $A \subseteq X$.  A point $x$ in $X$ is said to be a limit point of $A$ provided that every open set containing $x$ contains a point $A$ different from $x$. Does the set $A$ have to be closed in order for the set of limit points to be empty? That is my thought right now? So I am thinking I need to be looking for counterexample for this false conjecture?","['elementary-set-theory', 'general-topology', 'proof-writing']"
1280329,Properties of the martingale $S_n := S_{n-1} + X_n \sqrt{1+S_{n-1}^2}$,"Let $(X_n)$ be a sequence of IID random variables with $$P(X_i=1)=P(X_i=-1)=\frac{1}{2}$$ and let $(\mathcal{F}_n)$ be the natural filtration of $$\mathcal{F}_n=\sigma(X_1,\dotsc,X_n)$$ Define a sequence of random variables $(S_n)$ by $$S_0=0 \\ S_n = S_{n-1} + X_n\sqrt{1+S^2_{n-1}}\ \ \ \ \ \mbox{  if } n\geq1 $$ (a) Show that $(S_n)$ is a martingale with respect to filtration. (b) Show that if $n\geq1$ then $S_n$ does not take the value $0$. Deduce that if $n\geq2$ then $S_n$ does not take values $1$ or $-1$. (c)Show that for each fixed value of $S_{n-1}$ the two possible values of $S_n$ have a product equal to $-1$ (d)Deduce that for $n\geq2$ $$P(|S_n|<1)=\frac{1}{2}$$ I have done part (a) which i answered myself below and I'm stuck at part (b) Attempted so far (a) Clearly $S_n$ is adapted and $E|S_n|<\infty$. Since $S_n$ is bounded. For $n\geq1$ $$E[S_n| \mathcal{F}_{n-1}]=S_{n-1}+E[X_n]\sqrt{1+S^2_{n-1}}=S_{n-1}+\frac{1}{2}\sqrt{1+S^2_{n-1}}-\frac{1}{2}\sqrt{1+S^2_{n-1}}=S_{n-1}$$ Hence $S_n$ is a martingale. (b) Stuck my attempt was to find $S_1$ and $S_2$ but that does not give me $S_n$","['probability-theory', 'martingales']"
1280354,Integral and derivative,"Let $g(x) = \int_{[0;2^x]}{\sin(t^2)} dt$ for $x \in \mathbb{R}$. I have to calculate $g'(0)$. So, $g'(0) = \lim_{h \to 0}{\frac{g(h) - \int_{[0;1]}{\sin(t^2)} dt}{h}}$. Maybe I should apply the formula $\lim_{n \to \infty} \sum_{k=1}^{n}\frac{1}{k}f\left(\frac{k}{n}\right)=\int_{0}^{1}f(x)dx$, but I don't think it would help. How to end the calculation?","['derivatives', 'integration']"
1280398,"Equivalence of norms: $\|x\|$ and $\|x\|_1=\|x\|+\lvert\,f(x)\rvert$",Let $f: X\to \mathbb{R}$ be a linear functional and $\|\cdot\|_1$ is defined as follow $\|x\|_1=\|x\|+|f(x)|$. Prove or disprove $\|\cdot\|_1$ is equivalent to $\|\cdot\|$ iff $f$ is continuous. I've tested some examples and get the answer is positive.,"['analysis', 'functional-analysis', 'normed-spaces']"
1280444,"If $\mathbb{E}[X] = 0$, then $P[X \geq \lambda] \leq \frac{\sigma^2}{\sigma^2 + \lambda^2}$","Say $X$ is a real random variable, and its expected value is $\mathbb{E}[X] = 0$. 
Denote the variance $\operatorname{Var}[X] = \sigma^2$. Show that $P[X \geq \lambda] \leq \frac{\sigma^2}{\sigma^2 + \lambda^2}$ for any $\lambda > 0$. This is an exercise in The Probabilistic Method (Alon & Spencer) in chapter 4, which focuses on the uses of the Chebyshev inequality - so I assume it is useful here but I'm stuck.","['probability', 'expectation']"
1280454,Limit of a sum of two variables,"Recently at my calculus course we are doing derivatives and integrals. I've stumbled upon a sum that seems to have nothing in common with our current objectives, though I'm sure it does have, but still I have no idea how to solve it. $$ \lim_{n\to\infty} \sum_{k=1}^{n} \frac{1}{4n - \frac{k^2}{n}} $$ I tried to represent it as a $$ f_{n}(x) = \sum_{k=1}^{n} \frac{x}{4n - \frac{k^2}{n}}$$ and to resolve it at a point $x = 1$, but I failed because of the two variables instead of one. EDIT: Of course, I would like to get some CLUES how to solve it, not the whole solution.","['calculus', 'derivatives']"
1280492,Correct statement of Fermat's Last Theorem,"I'm looking at the wikipedia page on Fermat's Last Theorem In the statement it requires $a,b,c$ to be positive integers.  Is that correct?  I always took it to be no solutions in non-zero integers.  But this wiki page makes a big deal out of the bases being positive.  Has some counter-example turned up using negative integers that I'm missing?  Otherwise, I think we should fix the wiki page.","['number-theory', 'diophantine-equations']"
1280495,When is a continuous function differentiable? [duplicate],"This question already has answers here : Why differentiability implies continuity, but continuity does not imply differentiability? (3 answers) Closed 9 years ago . I have been doing a lot of problems regarding calculus. An utmost basic question I stumble upon is ""when is a continuous function differentiable?"" (irrespective of whether its in an open or closed set).","['continuity', 'derivatives']"
1280503,Matrices and Combinatorics are a bad combination.,"Let $\scr A$ be the set of all $n\times n$ symmetric matrices all of whose entries are either $0$ or $1$ and such that if $n$ is even, $n^2/2$ of these entries are $1$ and $n^2/2$ of them are $0$, and if $n$ is odd then $(n^2+1)/2$ of these are $1$ and $(n^2-1)/2$ are $0$. I need to find: The number of matrices in $\scr A$. The number of matrices with non-zero determinant in $\scr A$. (and that also counts up indirectly the matrices with zero determinant.) I have solved this problem for $n=3$ by explicitly writing the $12$ matrices with $6$ and $6$ matrices with zero and non-zero determinant. Is there a general way to do this?","['combinatorics', 'matrices']"
1280516,What seems to be the minors of the Adjugate matrix $\text{adj}(A)$ of a square matrix $A$?,"It is by definition that entries of the adjugate matrix $\text{adj}(A)$ are the corresponding $(n-1)$-minors of $A$ (up to a sign). What can we say about the $k$-minor of $\text{adj}(A)$ in relation to minors of $A$? I have tried some cases starting from the definition of determinant (just like the proof of the Laplace expansion), but so far no luck. But I guess it is some kind of complementary minor in $A$.","['laplace-expansion', 'linear-algebra', 'matrices']"
1280517,Sampling distribution of $\frac{\bar{X}}{S}$,"Suppose that I have a random sample $X_1, â€¦ ,X_n$ from a $N(0,\sigma^2)$ distribution. What is the distribution of $$\frac{\bar{X}}{S}$$ and what is it's standard deviation? Here $\bar{X}$ is the sample mean and $S$ is the sample standard deviation.","['statistics', 'probability-distributions', 'sampling']"
1280521,$ \lim_{n\to\infty} \sum_{k=1}^{n} \frac{1}{4n - \frac{k^2}{n}} $ appears to disagree with $\int_0^1 \frac{dx}{4-x^2}$,"In question 1280454, t was asked how to find
$$ \lim_{n\to\infty} \sum_{k=1}^{n} \frac{1}{4n - \frac{k^2}{n}} $$
and of course, you can write this as 
$$ \lim_{n\to\infty} \frac{1}{n} \sum_{k=1}^{n} \frac{1}{4 - \frac{k^2}{n^2}}
= \int_0^1 \frac{dx}{4-x^2}
$$ by using the variable $x=\frac{k}{n}$ in a Reimann integral. However, 
$$\int_0^1 \frac{dx}{4-x^2} = \frac18\left(\ln(5)-\ln(3) \right) \approx 0.06385$$
while each of the $n$ terms in 
$$
\sum_{k=1}^{n} \frac{1}{4n - \frac{k^2}{n}}$$ exceeds $\frac{1}{4n}$ so the sum must be greater than $\frac{1}{4}$ in all cases.  (Experimentatlly, the limit is about $0.275$) What gives???","['sequences-and-series', 'calculus']"
1280532,Evaluating natural limit $\lim_{n \to \infty} \left( e^{2n} - 1\right) ^\frac{1}{n}$,"Any idea evaluating this
$$
\lim_{n \to \infty} \left( e^{2n} - 1\right) ^\frac{1}{n}
$$ after I raise all to e like so
$$
\exp\left( \frac{\ln\left(e^{2n}-1\right)}{n}\right)
$$
and Hopital's it I get stuck. Thanks","['calculus', 'limits', 'exponential-function']"
1280545,Counting binary strings of length n with no two adjacent 1's,"I need to calculate the total number of possible binary strings of length $n$ with no two adjacent 1's. Eg.
for n = 3
f(n) = 5
000,001,010,100,101 How do I solve it?",['combinatorics']
1280561,"Monic $f(x)\in\Bbb Z[x]$ has no rational root if $f(0)\ \&\ f(1)$ odd [Parity Root Test, Modular Root Test]","A polynomial problem from my old algebra textbook: $f(x)\in\Bbb Z[x]$ with leading coefficient $1$, $\deg f(x)\ge 1$, and both $f(0)$ and $f(1)$ are odd numbers, prove: $f(x)$ has no root within $\Bbb Q$ Eisenstein's criterion seems to be of little help here because we know virtually nothing about the coefficients. So I tried some other approach. Let
$$f(x)=a_0+a_1x+a_2x^2+\cdots+a_{n-1}x^{n-1}+x^n\in \Bbb{Z}[x]$$
What we have known so far is
$$f(0)=a_0\text{ is an odd number}$$
and
$$f(1)=a_0+a_1+a_2+\cdots+a_{n-1}+1 \text{ is an odd number}$$
from which we can also conclude that
$$f(1)-f(0)=a_1+a_2+\cdots+a_{n-1}+1\text{ is an even number}$$
To be honest I don't know how to proceed now. It isn't until just now that I realized ""irreduicible"" is not equivalent to ""has no roots"".. So all my previous attempt is fundamentally wrong.. Can anybody help or drop a hint? Best regards!","['abstract-algebra', 'polynomials', 'elementary-number-theory', 'ring-theory']"
1280582,Gaussian vector multiplied with a matrix is another Gaussian vector: How to show?,"Assume that $w$ is a $M$ dimensional random vector, such that: $w \sim N(w|0,\alpha^{-1} I)$. Now I have a $N \times M$ matrix $\Phi$, which is not random. I want show that the vector $Y= \Phi w$ is another Gaussian vector. What I tried is the following: Each component of $w_i$ is a scalar Gaussian, with zero mean and variance $1/\alpha$. Moreover, these components are independent due to the form of the covariance matrix of the joint distribution. I tried to form the distribution of the following linear combination of deterministic vectors: $$ Y = \sum_{m=1}^{M} w_m\Phi_m$$. $\Phi_m$ is the $m.$ column of the matrix $\Phi$. By using this approach, I can show that each component of the vector $Y_n$ is a Gaussian, but I cannot show that they are jointly Gaussian as well. What should I do instead here? Edit: Note that I just want to show $Y$ is another Gaussian; I am not after showing its mean and covariance, which I can find indeed.","['normal-distribution', 'probability', 'probability-distributions']"
1280588,Extrema of functions of two variables: necessary and sufficient conditions,"I seem to recall my teacher telling us about the necessary and sufficient conditions while finding the maxima/minima of functions. However, I can no longer find those conditions in my booklet and even on the internet. Can someone please tell me about them?",['functions']
1280608,Constructing measure preserving maps between non-atomic measures,"Suppose $(\mu, X,\Sigma)$ and $(\mu^\prime, X^\prime, \Sigma^\prime)$ are non-atomic probability measures. Is it always possible to construct a measure preserving map between the two spaces? (If not, suggestions of other simple conditions that would guarantee the possibility would be welcome.)","['probability-theory', 'measure-theory']"
1280617,How to evaluate the integral $\int_0^\infty \frac{x^{a-1}}{1+bx^a} e^{-x} dx$,"How to evaluate this integral? \begin{equation}
  \int_0^\infty \frac{x^{a-1}}{1+bx^a} e^{-x} dx
\end{equation}
I think it will use a gamma function or a exponential integral. I really need an advice to continue.
$a$ and $b$ are real constants.","['calculus', 'definite-integrals', 'integration']"
1280639,Minimum value of trigonometric equation,"Find the minimum value of the expression $$y=\frac{16-8\sin^{2} 2x +8\cos^{4} x}{\sin^{2} 2x} .$$ When I convert the expression completely into $2x$, cross multiply and make the discriminant of the quadratic equation greater than $0$, I get the minimum value $-\infty$. I know it is wrong, but why?",['trigonometry']
1280655,Find $x$ and $y$,"If $\frac{\tan 8Â°}{1-3\tan^{2}8Â°}+\frac{3\tan 24Â°}{1-3\tan^{2}24Â°}+\frac{9\tan 72Â°}{1-3\tan^{2}72Â°}+\frac{27\tan 216Â°}{1-3\tan^{2}216Â°}=x\tan 108Â°+y\tan 8Â°$, find x and y. I am unable to simplify the first and third terms. I am getting power 4 expressions. Thanks.",['trigonometry']
1280662,Does Bivariate Normal have a monotone likelihood ratio?,"In general, with all parameters unknown I think the answer to this question is no. I think this because in this instance we would have a curved multivariate exponential family. Is this reasoning correct? Now, suppose the only unknown parameters are the correlation, $\rho$, and one of the means, $\mu_1$, then in this (or any other) particular instance does the bivariate normal distribution have a monotone likelihood ratio?","['normal-distribution', 'probability', 'statistics', 'bivariate-distributions']"
1280676,Solving $ \sqrt{x - 4} + \sqrt{x - 7} = 1 $.,"I have the equation $ \sqrt{x - 4} + \sqrt{x - 7} = 1 $. I tried to square both sides, but then I got a more difficult equation:
$$
2 x - 11 + 2 \sqrt{x^{2} - 11 x - 28} = 1.
$$
Can someone tell me what I should do next?","['arithmetic', 'radicals', 'algebra-precalculus']"
1280678,Eigenvalues of a Plane Curve Laplace-Beltrami Operator,"Given a closed plane curve $C$, which is a one-dimentional manifold, what are the eigenvalues of Laplace-Beltrami operator defined on this curve? I know that the LB eigenvalue problem for unit circle is equivalent to the regular Laplacian eigenvalue problem for  the interval of the length $2\pi$ with periodic Boundary conditions. In a sense, the LB operator on circle can be viewed as a Laplacian of a function depending on the arc length. 
Therefore the eigenvalues of LB operator on a circle of arbitrary radius will be equal to the eigenvalues of unit circle LB, rescaled by the square of the radius.
Does this also hold for any ""good"" closed plane curve? To summarize, let me state again the QUESTION : Do the eigenvalues of Laplace-Beltrami operator defined on an arbitrary closed one dimensional smooth manifold embedded in $\mathbb{R}^2$ depend only on the (arc) length of this manifold? I perceive it to be counterintuitive for two distinct closed plane curves of the same total length to always have equal LB eigenvalues, but I could neither prove nor disprove this statement.","['manifolds', 'differential-geometry', 'multivariable-calculus', 'ordinary-differential-equations', 'derivatives']"
1280683,The difference between the algebraic torus and the geometric torus,"I know that the donut-shaped geometric object in $\mathbb{R}^3$ is homeomorphic to a square with identified opposite sites. However, while the latter has a clear symmetry between two dimensions, the former doesn't (as an idea to formalize this, I would think of the fact that you can put a string through the donut hole, and the string then identifies one direction of the two). Just as I was writing this question, I saw a similar question, Why is $S^1 \times S^1$ a Torus? ,
and a comment there says that representing the torus in $\mathbb{R}^4$ in $\mathbb{R}^3$ instead is what breaks symmetry. What I wonder is how this symmetry can be described in geometric terms? That is, which quantity tells us that one of the torus manifolds in $\mathbb{R}^3$ and $\mathbb{R}^4$ has some symmetry and the other doesn't? If you don't agree with my thoughts about symmetry, what other differences are there between the two?","['differential-geometry', 'soft-question']"
1280701,Proof of uniqueness of conditional expectation,"I have a question on the proof Durrett (p. $190$) gives for the uniqueness of the conditional expectation function. If I understand his proof correctly, here is what I think it is saying: Suppose $Y, Y'$ both satisfy the criteria to be a conditional expectation function for a random variable $X$ given a $\sigma$-algebra $\mathcal{A}$.  Then if $A_{\epsilon} := \{ \omega \mid Y - Y' \geq \epsilon \}$, clearly $A_{\epsilon} \in \mathcal{A}$, and so by the criteria we have for conditional expectation, we have: $$0 = \int \limits_{A_{\epsilon}} Y - Y' \,dP \geq \epsilon P(A_{\epsilon}) \geq 0$$ and this shows that $P(A_{\epsilon}) = 0$ for all $\epsilon > 0$. Ok, then we note that $0 \leq P( \{\omega \mid Y - Y' > 0 \} ) = P(\bigcup \limits_{n =1}^{\infty} A_{\frac{1}{n}}) \leq \sum \limits_{n = 1}^{\infty} P(A_{\frac{1}{n}}) = \sum \limits_{n = 1}^{\infty} 0 = 0$.  Thus, $P( \{\omega \mid Y - Y'  \leq 0 \} ) = 1$, so $Y \leq Y'$ almost surely. We can repeat the same proof switching $Y$ and $Y'$ to get $Y' \leq Y$ almost surely, thus they are equal almost surely. My question : I think the following proof is a much simpler one (using the fact that $\int \limits_{\Omega} X \,dP = 0 \implies X = 0$ almost surely).  Is there any flaw in the argument below?  If not, why did Durrett decide to do so many extra steps? Since $\Omega \in \mathcal{A}$, we have $0 = \int \limits_{\Omega} Y - Y' \,dP$, and thus $Y - Y' = 0$ almost surely, so $Y = Y'$ a.s.","['probability-theory', 'conditional-expectation', 'measure-theory']"
1280749,Show limsup/liminf is in tail field,"Given events $X_1, X_2, X_3, ...$, let $\tau = \bigcap_{n\geq1} \sigma(X_n, X_{n+1}, ...)$ be their tail field. 1 How do I show that $\limsup X_n \in \tau$? What I tried: $\limsup X_n = \bigcap_{m\geq1} \bigcup_{n\geq m} X_n$ $= (X_1 \cup X_2 \cup ...)$ $\cap (X_2 \cup X_3 \cup ...)$ $\cap ...$ We note that: $(X_1 \cup X_2 \cup ...) \in \sigma(X_1, X_2, ...)$ $(X_2 \cup X_3 \cup ...) \in \sigma(X_2, X_3, ...)$ and so on. Now, I am stuck. If $A \in \scr{F}$ and $B \in \scr{G}$, I don't think it follows that $A \cap B \in \scr{F} \cap \scr{G}$. 2 How do I show that $\liminf X_n \in \tau$ similarly (that is, without noting that $\liminf X_n \subseteq \limsup X_n$)? Edit: $\liminf X_n \subseteq \limsup X_n$ doesn't cut it. However, if $\limsup >X_n \in \tau$, then $(\limsup X_n)^{C} = \liminf X_n^C \in \tau$ What I tried: $\liminf X_n = \bigcup_{m\geq1} \bigcap_{n\geq m} X_n$ $= (X_1 \cap X_2 \cap ...)$ $\cup (X_2 \cap X_3 \cap ...)$ $\cup ...$ We note that: $(X_1 \cap X_2 \cap ...) \in \sigma(X_1, X_2, ...)$ $(X_2 \cap X_3 \cap ...) \in \sigma(X_2, X_3, ...)$ and so on. I think it is true that if $A \in \scr{F}$ and $B \in \scr{G}$, then $A \cup B \in \scr{F} \cup \scr{G}$ so QED?",['probability-theory']
1280799,Integration Around Part of a Branch Cut,"I am studying the integral, given by a Laplace transform, $$\int_0^\infty\!e^{-\alpha x}\sinh^{-2/3}x\left(1+\frac 12\sinh^2x\right)^{-1/6}\left(1-\beta\sinh^{4/3}x\right)^{1/2}\,\mathrm dx$$ From what I can tell there are three singularities:  one at $x = 0$ (from the second term in the integrand) and two at $x = \pm\sin^{-1}\sqrt 2$ (from the third term).  The only multi-valued term should be the third term since $$\left(1+\frac 12 \sinh^2x\right)^{-1/6} = \left(x-\sin^{-1}\sqrt 2\right)^{-1/6}\left(x+\sin^{-1}\sqrt 2\right)^{-1/6}$$ and the hyperbolic functions are single-valued.  This means I can set up my branch cut along the real axis in the range $x\in\left(-\sin^{-1}\sqrt 2,\sin^{-1}\sqrt 2\right)$, but this makes the choice of contour really confusing.  This integral is not symmetric under the transformation $x\to -x$ or anything else as far as I can see. Here's my question: What is a good choice for a contour for this integral?  Would it even include any of the three poles if it does not go around the branch cut? FIRST EDIT: From what I understand, when hyperbolic functions are involved it is good to use a rectangular contour and exploit symmetries.  Here it would be $\sinh x = \sinh(x+2\pi i)$ and a good contour would be from $i\epsilon$ to $2\pi i$ to $R+2\pi i$ to $R+i\epsilon$ and back along the real axis, taking the limits as $\epsilon\to 0$ and $R\to\infty$. Some new questions with respect to this revelation:  do I pick up a quarter of the residue at the origin?  And am I correct that the branch point at $\sin^{-1}\sqrt 2$ does not contribute any residue?  How is the limit $\epsilon\to 0$ different along the branch cut vs past it? SECOND EDIT: After further study (and the limited help of Mathematica) it turns out this integral is filled with branch points.  See the picture below. Notice how I've connected pairs to form short, finite-length branch cuts which can be integrated around.  This now means there are no removable singularities where the residues may be picked up.  Instead, the path I've previously described needs to be extremely deformed in order to close the contour.  The main concept which confuses me now is how you would integrate over half a dumbbell/dogbone contour (see the branch cut along the portion of the real axis) when the contour continues further past it.","['branch-points', 'contour-integration', 'laplace-transform', 'integration', 'branch-cuts']"
1280804,Solutions of autonomous ODEs are monotonic,"Problem. Let $I,J$ be open intervals, $\,f:I\to \mathbb R$, continuous, $\,\varphi :J\to \mathbb R$,  continuously differentiable, with $\varphi[J]\subset I$, and $\varphi$ satisfying
$$
\varphi'(t)=f\big(\varphi(t)\big),  \quad \text{for all $t\in J$}.
$$
Show that $\varphi$ is monotonic. This becomes rather straight-forward if we further assume the $f$ is continuously differentiable, or even locally Lipschitz continuous, as this implies that IVP for $x'=f(x)$ enjoy uniqueness, and hence if $f\big(\varphi(t_0)\big)=0$, for some $t_0\in J$, then $\varphi$ is constant. In fact something stronger holds in such case: $\varphi$ is either strictly monotonic or constant. This problem is also straight-forward if $f(x)\ne 0$, for all $x\in I$, in which case uniqueness kicks in anew. The hard part is to show monotonicity of $\varphi$ when $f$ is just continuous, and its values include zero.","['analysis', 'calculus', 'real-analysis', 'ordinary-differential-equations']"
1280806,Functional equation $f(x)=\frac{1}{1+f(\frac{1}{1+f(x)})}$,"Problem: Find all continuous real-valued functions $f$ such that
  $$f(x)=\frac{1}{1+f(\frac{1}{1+f(x)})}.\tag{1}$$ Here $f$ is allowed to be defined only on a subset of $\mathbb{R}$. The only solutions I found are the constant functions
$$f(x)=\frac{1}{\varphi},\quad\text{and}\quad f(x)=-\varphi,\tag{2}$$
where $\varphi$ is the golden ratio. I also proved that the only linear functions $f(x)=a+bx$ satisfying $(1)$ are the two above ones. I am tempting to conjecture that these are the only solutions but I failed to either prove or disprove it.",['functions']
1280809,Is this the correct minimum number of coins needed to make change?,"The Problem: On Venus, the Venusians use coins of these values [1, 6, 10, 19]. Use an algorithm to compute the minimum number of coins needed to make change for 42 on Venus. State which coins are used to satisfy this minimum I used Dynamic Programming as the algorithm used to solve this problem. Here my work 1 coin to make 6
  2 coins to make 12 (+6)
  3 coins to make 13 (+1)
  4 coins to make 32 (+19)
  5 coins to make 42 (+10) So my answer would be the minimum number of coins needed to make change for 42 on Venus would be 5 and the coins to satisfy this minimum are {6, 6, 1, 19, 10} Does everyone agree with my answer(5) and my arrangement of coins to satisfy the minimum 5 or is there a better answer?","['computer-science', 'discrete-mathematics', 'dynamic-programming', 'recursion', 'recursive-algorithms']"
1280814,Are convex functions of a random variable themselves random variables?,"I was looking at proofs of Jensen's inequality and noticed that they usually assume that for a convex function $g$ and a random variable $X$, the expression $\mathbb{E}(g(X))$ is well defined, which implies that $g(X)$ is a random variable. I was thinking whether it was possible that all real-valued functions of random variables are random variables themselves, which is why the proofs skip the step of proving that $g(X)$ is a random variable. But then I thought if $A$ is a Borel set, then $(g \circ X)^{-1}(A) = X^{-1}(g^{-1}(A)) $ may not itself be $\mathcal{F}$-measurable  if $g^{-1}(A)$ is not Borel. But it is true if convex functions $g:\mathbb{R} \to \mathbb{R}$ are $\mathcal{B}$-measurable. Is it true that all convex functions are $\mathcal{B}$-measurable, then? I know the sub-level sets of a convex function are convex, so if we can show that a convex set is Borel, that would work too. And is there a counterexample of a real-valued function of a random variable that isn't a random variable?","['probability-theory', 'random-variables']"
1280821,Parametric equation of clock hands,"I am trying to draw a clock with both hour and minute hands in a computer program. The movement of the clock hands would mirror a traditional wall clock (hours from $12, 1, 2, 3,..., 11$ and back to $12$ etc.) Suppose I know the center (starting point) and the radii of both the hour and the minute hands. In order to locate the endpoints (tip) of the clock hands, what parametric equation I should use? The complication seems to be that the hour hands start from $12$ (or we could assume it's ""$0$"") at the top of the clock. So, the traditional parametric equation for finding a point around a circle's circumference (see below) needs to be modified a bit here. If I get the hour hand equation down, I think I can adapt it for minute hand. My trig knowledge isn't that good, so if someone could provide me a solution (or even just a clue), that'd be very helpful. Thank you! The conventional parametric equations of a circle are: \begin{align}
x &= r \cos(t)\\
y &= r \sin(t)
\end{align}
where $r$ is the radius and $t$ is in radian for above equations. I found a document that derives how to graph the hour and minute hands, but the equations there (pasted below) doesn't seem to draw at least the hour hand right. For example, from $12$ to $3$ hour, it draws points in the fourth quadrant of a circle... \begin{align}
x &= r \cos(\frac\pi{360}t)\\
y &= r \sin(\frac\pi{360}t)
\end{align}
where $t$ is time in minutes.","['parametric', 'circles', 'trigonometry']"
1280823,"""Intermediate Value Theorem"" for curves","Let $f$ be a continuous real function defined on the unit square $[0,1]\times[0,1]$, such that $f(x,0)=-1$ and $f(x,1)=1$. If we walk from $y=0$ to $y=1$ on any path, we must cross some point where $f=0$. Intuitively, there is a connected ""wall"" (a curve) that separates $y=0$ from $y=1$, on which $f=0$, like this: My question is: is there a theorem that formalizes this intuition (if it is correct)?  In particular: is there a theorem which implies that there exists a connected line that goes from $x=0$ to $x=1$, on which $f=0$, as in the picture?","['real-analysis', 'general-topology']"
1280838,Finding limits using definite integrals $\lim_{n\to\infty}\sum^n_{k=1}\frac{k^{4}}{n^{5}}$,"Find the limit of $\displaystyle\lim_{n\to\infty}\frac 1 {n^5}(1^4+2^4...+n^4)$ using definite integrals. It's equal to: $\displaystyle\lim_{n\to\infty} \sum^n_{i=1}\frac 1 i$ but now I'm not sure how to turn it to an integral. $\Delta x_i=\frac 1 n, f(x_i)=1$ so the integral would be: $\displaystyle\int 1dx$ ? How can I find the bounds?","['calculus', 'limits', 'riemann-sum', 'integration']"
1280859,Flow of a left invariant vector field on a Lie group equipped with left-invariant metric and the group's geodesics,"I think the answer to my question is known to many other people, but I'm still getting confused. Let $G$ be a (possibly infinite dimensional also) Lie group and $g$ be its Lie algebra. Consider the Lie group exponential map $exp:g\to G$ by defining $exp(tX):=\phi_t \forall t\in \mathbb{R}$, where $\phi:\mathbb{R}\to G$ is a Lie group homomorphism, and $\phi'(0)=X$. Equip $g$ with an inner product and hence construct a left-invariant Riemannian metric on $G$. 1) It's NOT necessarily true that $\phi(t)=exp(tX)\in G$ is a Riemannian geodesic in $G$, right? 2) Can we find a condition on $X\in g$ so that $t \mapsto  exp(tX)$is a geodesic in $G$? 3) Suppose we know that $\phi(t)$ is a Riemannian geodesic, then does it imply that the left invariant metric on $G$ is also right-invariant? If yes, what's an outline of proof? If no, what's a counter example where flow defined by exponential map is a geodesic but the metric on the group is not bi-invariant?","['lie-groups', 'differential-geometry', 'lie-algebras', 'riemannian-geometry']"
1280867,Is $\limsup_{z\to z_0}f(z)=\limsup_{k\to\infty}f(z_k)$?,"Let $\Omega\in\Bbb C$ open, $f:\Omega\to\Bbb R$ a generic function.
Let $(z_k)_k\subset\Omega$ s.t. $\lim_{k}z_k=:z_0\in\Omega$. The question is the following: is true that
$$
\limsup_{z\to z_0}f(z)=\limsup_{k\to\infty}f(z_k)\;\;\;\;\;?
$$ I recall that
$\limsup_{z\to z_0}f(z):=\lim_{r\to0^+}\left(\sup_{B(z_0,r[}f(z)\right)$ and
$\limsup_{k\to\infty}f(z_k):=\lim_{k\to\infty}\left(\sup_{n\ge k}f(z_n)\right)$. My feeling is the answer is yes, but I wasn't able to prove this. Can someone help me? Many thanks!","['analysis', 'limsup-and-liminf']"
1280882,What is the purpose of the compound angle identity in trigonometry?,"This may be a silly question, but one that I am confused about nonetheless. With regards to the compound trig identities such as $\cos(A+B)=\cos A\cos B - \sin A\sin B$ etc., I'd like to know why they are used. What's the purpose? Surely, one would ask themselves that if we can just add $A$ and $B$ together and call it $C$ (degrees or radians) then we could just find cosine of $C$...? I know there's more to it, but that's where I'd love to get your help. Thank you! :)","['algebra-precalculus', 'trigonometry']"
1280901,Is the logarithm of $\aleph_0$ infinite?,"In classical mathematics $2^{\aleph_0}\ge\aleph_1$, right?
So if $2^x=\aleph_0$, what does $x$ equal? In other words, can we define a logarithm for $\aleph_0$, and what should it be.
Is it infinite? Finite? Undefined? Should a definition in a computational context be necessarily the same as in the classical context, or can/should it be modified, like other mathematical definitions are modified to accomodate computability (e.g. limits in the context of computable reals)","['elementary-set-theory', 'terminology', 'computability', 'cardinals']"
1280906,How is $ \cos (\alpha / \beta) $ expressed in terms of $\cos \alpha $ and $ \cos \beta $?,"If it is possible to express  $ \cos n \alpha $ in terms of $ \cos \alpha $  as a power series for integer $n$ ... I like to see an expression for the quotient angle that obviously tallies when $ (\alpha , \beta) $ are swapped. EDIT1: Something like: $$ \cos (\alpha - \beta)= \cos \alpha \cos \beta  + \sin \alpha  \sin \beta $$ EDIT2: Like to know why $ \cos ( \alpha / \beta )$ cannot be expressed in terms of $ \cos \alpha, \cos \beta $, but  $ \cos ( \alpha + \beta) $  can be expressed in terms of  $\cos \alpha $ and $ \cos \beta. $",['trigonometry']
1280946,Prove that the normal to a quadratic curve passes through a specific point,"I've been asked to prove that the normal to the curve $y=2x^2 - 3x^{-1/2}$ at the point $(1,-1)$ passes through the point $(12,3)$. $\frac{dy}{dx} = 4x + \frac{3}{2}x^{-3/2}$ Hence, at the point $(1,-1)$, the gradient of the tangent $=\frac{11}{2}$ Therefore, the gradient of the normal at that point$=-\frac{2}{11}$ So, the equation for the normal is $$y+1=-\frac{2}{11}(x-1)$$ $$11y=-2x-9$$ However, when I substitute the value $12$ in for $x$ I get $y=-3$, rather than $3$, so that equation can't be right. What have I done wrong?","['differential-geometry', 'curves', 'ordinary-differential-equations']"
1280996,$ \frac{1}{2} + \dots + \frac{1}{n} \le \log n $,could anyone give me any hint how to prove this ? $$ \frac{1}{2} + \dots + \frac{1}{n} \le \log n $$ just came acroos this expression in my book.,"['sequences-and-series', 'harmonic-numbers', 'logarithms', 'inequality']"
1281007,Using SVD to approximate matrix-vector multiplication?,"Given some matrix A, is it possible to use Singular Value Decomposition to approximate Ax for some vector x within some error bound? According to Efficient low rank matrix-vector multiplication , it should be possible in O(m+n) time (where A is m by n). I'm not really sure how to get information from that answer though.","['approximation', 'matrices', 'linear-algebra', 'matrix-decomposition', 'svd']"
1281009,Cubic Congruence Solutions,"While I was reading a paper on number theory, there was a claim which wasn't prove there and I couldn't find a way to justify it. The claim is as follows For a prime $p$, when $p\nmid a$, the number of incongruent solutions to $x^3\equiv a \mod p^3$ is $O(1)$. Is there an elementary proof of this? reference to the paper (page 28): BrÃ¼dern, JÃ¶rg. A note on cubic exponential sums. Seminaire de Theorie des Nombres, Paris, 199091, 2334,
Progr. Math., 108, BirkhÃ¤user Boston, Boston, MA, 1993.","['congruences', 'number-theory', 'diophantine-equations']"
1281026,Determine the amplitude and phase shift of $f(x) = \sqrt{3} \cos2x-\sin2x$,"Question: Determine the amplitude and phase shift of $f(x) = \sqrt{3} \cos2x-\sin2x$ Attempted solution: The amplitude can be calculated by: $$A = \sqrt{(\sqrt{3})^2 + (-1)^2} = \sqrt{4} = 2$$ The sine and cosine of the phase shift then becomes $$\sin \delta = \frac{\sqrt{3}}{2}, ~~~~~~~~ \cos \delta = -\frac{1}{2}$$ because the factor before cosine goes into the sine equation and vice versa. The $\delta$ that fulfills these two criteria is $\frac{\pi}{3}$. In other words, $A = 2$ $\delta = \frac{\pi}{3}$ However, the answer to the phase shift actually turns out to be $\frac{2\pi}{3}$. Where did I go wrong? How does the factor in front of $x$ inside the sine and cosine functions affect this kind of calculations in the general case? It is clearly tempting to just multiply by 2 (in this case) because it produces the correct answer, but that is obviously not a mathematically sound approach.","['algebra-precalculus', 'trigonometry']"
1281044,Limit and Integral problem work verification-2,"I have to calculate the following: $$\large\lim_{x \to \infty}\left(\frac {\displaystyle\int\limits_{x^{2}}^{2x}t^{4}e^{t^{2}}dt}{e^{x}-1-x - \frac{x^2}{2}- \frac{x^3}{6}-\frac{x^4}{24}}\right)$$ My attempt: Let $F(x)=\displaystyle\int\limits_0^xt^4e^{t^2}dt$. Then, $$\large\lim_{x\to\infty}\left(\frac{\displaystyle\int\limits_{x^{2}}^{2x}t^{4}e^{t^{2}}dt}{e^{x}-1-x - \frac{x^2}{2}- \frac{x^3}{6}-\frac{x^4}{24}}\right)=\lim_{x \to \infty}\left(\frac {F(2x) - F(x^2)}{e^{x}-1-x - \frac{x^2}{2}- \frac{x^3}{6}-\frac{x^4}{24}}\right)$$ Applying L'HÃ´pital's rule, we have, $$\large\begin{align}\lim_{x \to \infty}\left(\frac {32x^4e^{4x^2} - 2x^9e^{x^4}}{e^{x}-1-x - \frac{x^2}{2}- \frac{x^3}{6}}\right) &= \lim_{x \to \infty}(32x^4e^{4x^2-x} - 2x^9e^{x^4-x}) \\&= \lim_{x \to \infty}\bigg(2x^4e^{4x^2-x}(16-x^5e^{x^4-4x^2})\bigg) = -\infty\end{align}$$ Am I right?","['limits', 'integration']"
1281053,Integral of the ratio of two exponential sums,"I am trying to find a lower bound on the following integral \begin{align*}
\int_{y=-\infty}^{y=\infty} \frac{ (\sum_{n=[-N..N]/\{0\}}n e^{-\frac{(y-cn)^2}{2}})^2} {\sum_{n=[-N..N]/\{0\}} e^{-\frac{(y-cn)^2}{2}}}dy
\end{align*} I have been trying to find the  upper and the lower bounds on the summations in here . I have also look at the Jacobian-Theta functions but I wasn't able to find theta function that would match my cases. Another approach is to look at hyperbolic functions 
\begin{align*}
&\int_{y=-\infty}^{y=\infty} \frac{ (\sum_{n=[-N..N]/\{0\}}n e^{-\frac{(y-cn)^2}{2}})^2} {\sum_{n=[-N..N]/\{0\}} e^{-\frac{(y-cn)^2}{2}}}dy\\
&=\int_{y=-\infty}^{y=\infty} \frac{ e^{-y^2/2}\left(\sum_{n=[1..N]}n e^{-\frac{c^2n^2}{2}} \sinh(ncy)\right)^2} {\sum_{n=[1..N]} e^{-\frac{c^2n^2}{2}} \cosh(ncy)}dy\\
\end{align*} But how to compute or bound the hyperbolic sums? Again, I only require a lower bound on the above integral. Should elliptic functions come into the play here, but I am not sure?
I feel like the sums inside of the integral were already looked at, so I would also be very grateful if you can point me to some references. Thanks in advance for any help or advice you might offer. Please see a very nice  approach by @Dr. MV.   The point of starting a  bounty is to maybe show a tighter result.","['summation', 'definite-integrals', 'sequences-and-series', 'hyperbolic-functions', 'integration']"
1281064,Maximal left ideals $\leftrightarrow$ simple left modules,"Suppose $R$ is a ring with unity. This passage in Lang's Algebra discusses the correspondence $$\text{Maximal left ideals of $R$} \leftrightarrow \text{Simple left $R$ modules},$$ where I corresponds to the left module $R/I$, and $M$ corresponds to $R/\text{Ann}_R(m)$ (the annihilator of $m$ in $R$), where $m$ is a generator of $M$. Lang says it is bijective up to isomorphism. I'd like to understand this correspondence...is it true that $I \cong J$ on the left side implies $R/I \cong R/J$ on the right side? (I know this is not true for arbitrary subgroups of a group, for example). Edit: Commenters have shown that this is not true. I'm now interested mainly in the following: I'm trying to prove that if $m$ and $n$ are two generators of $M$ simple, then $$\text{Ann}_R(m)\cong \text{Ann}_R(n) \tag{1}$$ as left $R$ submodules of $R$. So far I haven't been able. We know that there exist $p,q \in R$ such that $m = pn$ and $n = qm$. Then one map from left to right in (1) is right multiplication by $p$, and from right to left we could take right multiplication by $q$. These are definitely homomorphisms...I'd like to show they're isomorphisms. So far I haven't been successful. Update: It seems there is a counterexample to the above maps being isomorphisms if we choose generators $1,2$ in $5\mathbb{Z}$. So we'll need to use another map to show the isomorphism (if it's correct).","['abstract-algebra', 'ideals', 'ring-theory']"
1281087,"Is $\omega=\sin\varphi\,\mathrm{d}\theta\wedge\mathrm{d}\varphi$ an exact form?","Let $\omega=\sin\varphi\,\mathrm{d}\theta\wedge\mathrm{d}\varphi$ be a $2$-form on $\mathbb{R}^3\setminus\{0\}$. Then $$\int_{\mathbb{S}^2}\omega=\int_{\mathbb{S}^2}\sin\varphi\,\mathrm{d}\theta\,\mathrm{d}\varphi=4\pi\ne0,$$ so $\omega$ is not exact. On the other hand, $$\omega=\mathrm{d}\eta\text{, where }\eta=\cos\varphi\,\mathrm{d}\theta,$$ which contradicts the fact that $\omega$ is not exact. How is this possible?","['differential-geometry', 'differential-forms']"
1281089,"Integrable function $f$ on $(\mathbb N, \mathcal P(\mathbb N),\mu)$ and series","Problem Let $(\mathbb N, \mathcal P(\mathbb N),\mu)$ where $\mu(A)=card(A)$. Show that $f \in L^1(\mathbb N,\mu)$ if and only if $\sum_{n=1}^{\infty} |f(n)|<\infty$, in which case $\int_X f d\mu=\sum_{k=1}^{\infty}f(k)$. I am stuck on one implication. Suppose $\sum_{n=1}^{\infty} |f(n)|<\infty$. If $A_n=\{n\}$, then $f=\sum_{n=1}^{\infty}f(n)\mathcal X_{A_n}$. If I define $g_n=\sum_{k=1}^nf_k\mathcal X_{A_k}$ then $\lim_n g_n=f$. I call $h=\sum_{n=1}^{\infty} |f(n)| \mathcal X_{A_n}$, then $$\int_X hd\mu=\sum_{n \geq 1}\int_X |f(n)| \mathcal X_{A_n}d\mu$$$$=\sum_{n \geq 1}|f(n)|\int_X \mathcal X_{A_n} d\mu$$$$=\sum_{n \geq 1}|f(n)|\mu(A_n)=\sum_{n \geq 1} |f(n)|<\infty$$ Note that $|g_n| \leq h \in L_1(\mathbb N, \mu)$ for all $n$, so $|f| \leq |h|$, which implies $f$ is integrable. By the dominated convergence theorem $$\int_X f d\mu=\lim_n \int_X \sum_{k=1}^n f(k)\mathcal X_{A_k}d\mu$$$$=\sum_{k\geq 1} f(k)\int_X \mathcal X_{A_k}d\mu$$$$=\sum_{k=1}^{\infty}f(k)$$ I don't know what to do to prove the other implication, if $g_n=\sum_{k=1}^n |f(k)| \mathcal X_{A_k}$, where $A_k$ is the set I've already defined, then $g_n \nearrow g=\sum_{n=1}^{\infty} |f(k)|X_{A_k}$, so by the monotone convergence theorem, $$\sum_{k=1}^{\infty}|f(k)|=\int_X g d\mu$$$$=\lim_n \int_X g_nd\mu$$ I would like to affirm $\lim_n \int_X g_nd\mu<\infty$, I would appreciate suggestions to prove this.","['sequences-and-series', 'real-analysis', 'measure-theory']"
1281099,Compute Quotient Space,"I have been struggling with this computation for a while now. I thought I was almost there, but it now results I still have nothing. So here is the initial problem: Let $c=\left\{ (x_j)_j \subset \mathbb{C}: (x_j)_j \ \text{is a convergent sequence }\right\}$ equipped with the supremum norm $\|\cdot\|_\infty$, and $Y=\left\{ (x_j)_j \in c : (x_j)_j \ \text{is a constant sequence }\right\}$. Compute $c/Y$, that is find the Banach space to whom $c/Y$ is isometrically isomorphic. Three things one must know to tackle this problem: 1) The equivalence relation consider here is $x \sim y$ iff $\ x-y \in Y$ 2) The quotient space is $c/Y = \{Â [x]: x \in c \}$ 3) The norm in $c/Y$ is given by $\|[x]\|=\inf_{y \in [x]} \{\|y\|_\infty\}$ My advances: I already have proved that $Y \subset c$ is a closed subspace, so indeed $c/Y$ is a Banach space. Lets now consider $c_0=\left\{ (x_j)_j \in c: x_j \to 0 \text{ as } j \to \infty \right\}$, and define $S \subset c_0$ as follows
$$
S= \left\{ (z_j)_j \in c_0 : \sum_{j=1}^{\infty} z_j \ \text{ converges in } \mathbb{C} \right\}.
$$
I have fisrt conjectured that $c/Y \cong S$, and by defining $\Phi: c/Y \to S$ as
$$
\Phi([(x_j)_j]) : = (x_j-x_{j+1})_j \Â \ \Â \text{for } \Â \ (x_j)_j \in c
$$
I successfully showed that $\Phi$ is i)Linear , ii)Injective and iii) Onto , however, I could not prove the iv)Isometry part. EDIT: I now know thanks to @Jochen comment that proving iv) is impossible since $S$ is not it self a Banach space, and I thought it was, so $c/Y$ and $S$ are only isomorphic, but they are not the same Banach space. So my question now changes, since $S$ is not isometrically isomorphic to $c/Y$ which Banach space must be? It is correct to still looking for a $c_0$ subspace ot it might be something totally different.I am clueless since all my bets where on $S$. I would appreciate it very much any help given here.","['quotient-spaces', 'banach-spaces', 'functional-analysis']"
1281102,Intersection of Hilbert spaces,"Consider two Hilbert spaces $H_1$ and $H_2$ with inner products $\langle \cdot,\cdot\rangle_1$ and $\langle \cdot,\cdot\rangle_2$ generating norms $\Vert \cdot \Vert_1$ and $\Vert \cdot \Vert_2$ respectively. I am trying to understand when $H = H_1 \cap H_2$ becomes a Hilbert space with the inner product $\langle \cdot,\cdot\rangle_1 + \langle \cdot,\cdot\rangle_2$. Or does this always hold? I can see that a Cauchy sequence in $H$ is Cauchy in both $H_1$ and $H_2$, but apriori, it is not clear to me that a common convergent subsequence can be found. Thanks for any help! Edit: Let us assume that $H_1$ and $H_2$ are sitting inside a larger Hilbert space $H$. As pointed out below, otherwise the question doesn't make sense.","['inner-products', 'hilbert-spaces', 'functional-analysis']"
1281115,Expected value of max of three numbers,"This is a combo problem that a friend came up with some time ago, and recently showed to me. He claims he solved it when it first occurred to him, but can no longer remember the solution, and neither we, nor several other people we've asked can solve it now. ""At a certain preschool, there are 30 children, each of whom has a spinner. Each spinner has three colors: red, blue, and green, and lands on each color with equal probability. Every child spins his spinner, then tells the teacher the color they obtained. The teacher then totals how many students got each color (e.g. 9 red, 10 blue, 11 green) and then reads out the largest number (in this case, 11). What is the expected value of the number she reads? (If two numbers are equal, she reads out the common value.)"" The main obstacle I had when working on this question was that none of the standard tools for working with expected values (linearity of expectation, recursion, etc.) seemed helpful, and while it is possible to directly write an expression of the form $\sum x P(x)$ to give the expected value, the result is so unwieldy that it's useless. In particular, it seems hard to neatly incorporate the max condition without resorting to a double sum with very awkward constraints. If this problem has a nice closed-form solution, I'd also be very interested in the general case of $n$ students and $m$ colors, although it seems less likely that has a closed form. Any help is much appreciated.","['expectation', 'combinatorics']"
1281134,query about the cosine of an irrational multiple of an angle?,"de Moivre's identity
$$
(\cos \theta + i \sin \theta)^n = \cos n\theta + i \sin n\theta
$$
only applies as written when $n \in \mathbb{Z}$. if the exponent is a fraction $\frac{m}{n}$ then there will be $n$ values of $(\cos \theta + i \sin \theta)^{\frac{m}{n}}$, whilst for irrational $\alpha$ the set $\{e^{i\alpha (\theta +2\pi k)} \}$ is a dense subset of the unit circle. nevertheless $e^{i \alpha \theta}$
is distinguished amongst the values of $(e^{i\theta})^\alpha$ even when $\alpha$ is not an integer. so can we proceed as follows? when $0 \lt \theta \lt \frac{\pi}4$
$$
(\cos \theta + i \sin \theta)^\alpha = \cos^{\alpha}\theta(1+i \tan \theta)^{\alpha} = \cos \alpha \theta + i \sin \alpha \theta \tag{?}
$$
using the binomial theorem, which converges for the specified range of values for $\theta$, we have: $$
\cos \alpha \theta = \cos^{\alpha}\theta \sum_{m=0}^\infty (-1)^m \binom{\alpha}{2m} \tan^{2m}\theta \tag{1}
$$
if (1) is true, then if $0 \lt \alpha, \beta \lt \frac{\pi}4$ we would have
$$
\cos^{\alpha}\beta \sum_{m=0}^\infty (-1)^m \binom{\alpha}{2m} \tan^{2m}\beta = \cos^{\beta}\alpha \sum_{m=0}^\infty (-1)^m \binom{\beta}{2m} \tan^{2m}\alpha
$$","['complex-analysis', 'trigonometric-series', 'trigonometry']"
1281139,Solve $(2+\sqrt{3})^{x/2}+(2-\sqrt{3})^{x/2}=2^x$.,How to solve $(2+\sqrt{3})^{x/2}+(2-\sqrt{3})^{x/2}=2^x$ for $x$?,"['elementary-functions', 'algebra-precalculus']"
1281142,"What are the closed points of $\mathbb{A}_{\mathbb{R}}^2 = \operatorname{Spec}(\mathbb{R}[x,y])$?","I am trying to find all the closed points of $\mathbb{A}_{\mathbb{R}}^2$. After a quick google research, I found that $\mathbb{A}_{\mathbb{R}}^2 = \operatorname{Spec}(\mathbb{R}[x,y])$ and then all we need to find is the maximal ideals of $\mathbb{R}[x,y]$. However, set-theoretically this equalty does not make sense, as we are talking about points and prime ideals. And more than that, how do I find the maximal ideals of $\mathbb{R}[x,y]$? Seems hard. Any help would be appreciated. Thanks!","['affine-schemes', 'commutative-algebra', 'algebraic-geometry', 'schemes', 'zariski-topology']"
1281147,Proving the combinatorial expression,"Ok I've been reading in my probability book about the different methods on how to count and I'm just trying to dissect the usual combinatorial formula: $$\binom {a} {b} = \frac{a!}{b!(a-b)!}$$ Everything makes sense excpet I can't figure out how the $(a-b)!$ term arises. The other two terms are fine with $a!$ being the number of ordered samples  while $b!$ is the number of permutations for each sample, but that difference is throwing me for a loop.","['elementary-set-theory', 'combinatorics']"
1281164,Proof regarding a probability generating function (Poisson),"Let $f(s)$ be the probability generating function ($pgf$) of a non-negative, integer valued random variable. It is also given that $f(1-p+ps)f(p) = f(ps)$. Prove that $f(s) = e^{\lambda(s-1)}$ for some $\lambda > 0.$ Progress: Since the multiplication of the two instances function $f(s)$ results in another instance of $f(s)$, one can ""guess"" the answer to be a power function of some sort:$b^{ag(s)} \Rightarrow g(1-p+ps) + g(p) = g(ps)$ One can further guess that $g(s) = (1-s)$ instead of $(s-1)$. I have yet to prove that $a>0$ AND $b=e$ AND $g(s) =(s-1)$ AND not $(1-s)$. In fact, I have not proven anything, just guessed! Background information: The $f(1-p+ps)f(p) = f(ps)$ identity is the result of the following information: It is given that the distribution of $Y$ and $X\mid (Y=X)$ are identical, where $Y$ is the number of successes in $X$ binomial trials (each having $p$ probability of success). $f(s)$ is the pgf of $X$.","['real-analysis', 'functions', 'generating-functions', 'functional-equations', 'probability']"
1281171,How to integrate when integration by parts never ends?,"So I have the following integration: $\int{e^{-x}\sin{x}}$ I let u be the $e^{-x}$ and $dv = \sin{x} dx$ After doing the integration by parts I get:$(e^{-x})(-\cos{x})-\int{-e^{-x}*(-\cos{x})}$ From what it looks like, if I continue integration by parts, will it just continue going on forever?","['calculus', 'integration']"
1281182,How many degrees of freedom would a rotation matrix in R5 have?,I understand that a rotation matrix in R3 has three degrees of freedom because there is three linearly independent planes that the rotation can take place in. How does this translate to R5?,"['linear-algebra', 'rotations']"
1281184,Integral Inequality Proof Using HÃ¶lder's inequality,"I'm working on the extra credit for my Calculus 1 class and the last problem is a proof. We have done proofs before, but I'm unsure of how to approach this problem. Any help would be much appreciated, I'm just not entirely sure how to start. Specifically, showing how the continuous function defined by the problem is to taken into account. I understand that it defines the bounds for the integrals, but beyond that I am unsure of how they are affected. My intuition tells me that it implies the use of a specific theorem, but no specific theorem is apparent to me from simple observation. I've found evidence that Holder's Inequality would be helpful, but I'm not certain as to how to apply this. The problem is as follows: Show that for any continuous function $f:[-1,1]\to\mathbb R$ we have that: $$2\int_{-1}^{1} f^2(x) dx \ge \left(\int_{-1}^{1}f(x)dx\right)^2+3\left(\int_{-1}^{1}xf(x)dx\right)^2$$ I've tried multiple approaches essentially yielding nothing though. My understanding of how to manipulate integrals in a general manner is weak at best. I did get a hint from my TA that said the proof is almost a page long and uses results beyond Calculus 1, so technically I shouldn't even be able to do this proof, but it is worth a significant amount of my grade and I could really use all the help I can get. We actually only started integrals about 3 weeks ago. Not to mention it has now started to bother me that I can't solve it despite spending so much time. The extra credit is due Friday, but my Final is tomorrow, so I won't be able to spend much more time on it. Thanks for any help you guys can provide.","['derivatives', 'calculus', 'integral-inequality', 'integration']"
1281186,Proving a trigonometric identity: $\frac{\cos x}{1-\sin x} -\tan x = \sec x$,"I am trying to prove a trig identity that is confusing me. The identity is 
$$\frac{\cos(x)}{(1-\sin(x))}-\tan(x)=\sec(x)$$
Here is my attempt. I did $$\frac{\cos(x)}{(1-\sin^2(x))}=\frac{\cos(x)}{\cos^2(x)}=\frac{1}{\cos(x)}=\sec(x)=(\sec(x)+\tan(x))(1+\sin(x))\\\sec(x)=\sec(x)+\sec(x)\sin(x)+\tan(x)+\tan(x)\sin(x)\\0=\tan(x)+\tan(x)+\tan(x)\sin(x)$$ but this does not make sense to me. Can somebody please help me with this thing?","['calculus', 'trigonometry']"
1281194,Algebraic Manipulation in the Proof of Heron's formula,"A textbook I'm reading gives a proof of Heron's formula, but has lost me in one of its steps. My mathematical foundations are a bit shaky, so I was hoping someone could explain what was done. The jump I don't understand is going from $$\dfrac{1+\dfrac{(a^2+b^2-c^2)}{2ab}}{2}$$ to $$\frac{a^2 + 2ab + b^2 - c^2}{4ab}$$ I tried to simplify the first equation and I ended up with $$\frac{1}{2} + \frac{a^2 + b^2 - c^2}{4ab}$$ Is there something I've done wrong? What am I missing?",['algebra-precalculus']
1281216,"Lebesgue integrable function, convergent series","I am trying to solve the following: Let $(X,\Sigma, \mu)$ be a measurable space, $f:X \to \mathbb R$ measurable and let $A\in \Sigma$. For each $n$ natural number, we define $A_n=\{x \in A: |f(x)| \geq n\}$. Prove that if $f$ is integrable on $A$, then $\sum_{n \geq 1}\mu(A_n)<\infty$. Show that if $\mu(A)<\infty$ and $\sum_{n \geq 1} \mu(A_n)<\infty$, then $f$ is integrable on $A$. I am pretty lost on how should I start. For the first part, maybe I could get a bound for the series. All I could think of is to define $f_n=|f|\mathcal X_{A_n} \searrow  |f|$. Since $f_1$ is integrable, then $\lim_n \int_A f_nd\mu=\int_A  |f|d\mu$, but I don't see how this is related to the series. As for the other part I am completely lost. Any hints would be greatly appreciated.","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1281267,Is there a mathematical way to fold a $20 dollar bill for compactness?,"I had a strange thought. I used to carry a pill fob on my keys with an emergency $20 bill in it, before the whole thing got stolen. I always had some trouble fitting the bill inside the fob and barely managed it each time.  I would fold it a couple times then roll it really tight and put it into the tube before it expanded. Imagine that I don't have the restriction of needing a tube. I know to minimize volume a sphere is best, but you can't fold a paper into a sphere, something about Gaussian Curvature. Is there a math formula or technique where a bill can be folded maximally? Specifically to narrow it down I found this formula online:
$$
  L  = \frac{\pi t}{6}(2^n + 4)(2^n - 1)
$$ Gallivan's formula gives the maximum number of times you can fold a bill going in the same direction.  There is also another formula she came up with for an accordion fold. If I have a finite number of folds that can be done and I know what that number is.  Then is there a way to figure out what the most compact method of folding the bill is without having to try all of them?","['linear-algebra', 'origami']"
1281276,Taking a tricky limit $\lim_{p\to\infty}\int_{\Bbb R^N}\left(\frac{\left\lvert\nabla u\right\rvert}{\left\|\nabla u\right\|_p}\right)^{p-2}\cdots$,"$$
\lim_{p\rightarrow \infty} \int_{\mathbb R^N} 
\left( 
\frac{\left\lvert \nabla u \right\rvert}{\left\| \nabla u \right\|_p}
\right)^{p-2} 
\frac{\nabla u}{\left\| \nabla u \right\|_p}\cdot \nabla v \,dx \label{\star}\tag{$\star$}$$ where $\,\left\lvert\,\cdot\,\right\rvert\,$ is the Euclidean $2$-norm and $\;\left\| \nabla u \right\|_p = \left\|\, \left\lvert \nabla u \right\rvert \, \right\|_p$. Could anyone give me some hint for finding an explicit form for the expression involving $u$? I feel like my approach is not quite correct... First I know the term in the limit is bounded
$$
\begin{aligned}
\eqref{\star} & \leq \int_{\mathbb R^N} \left( \frac{\left\lvert \nabla u \right\rvert}{\left\| \nabla u \right\|_p}\right)^{p-1} \left\lvert \nabla v \right\rvert \,dx 
\\
& = \left\| \nabla u \right\|_p^{1-p} \int_{\mathbb R^N} \left\lvert \nabla u \right\rvert^{p-1} \left\lvert \nabla v \right\rvert \,dx  
\\
&\leq \left\| \nabla u \right\|_p^{1-p} \Bigg(\int_{\mathbb R^N} \Big(\left\lvert \nabla u \right\rvert^{p-1}\Big)^{\frac{p}{p-1}}\,dx\Bigg)^{\frac{p-1}{p}} \Bigg(\int_{\mathbb R^N} \left\lvert \nabla v \right\rvert ^ p \,dx\Bigg)^{\frac{1}{p}} 
\\ 
& = \left\| \nabla u \right\|_p^{1-p}\left\| \nabla u \right\|_p^{p-1} \left\| \nabla v\right\|_p 
\\
& = \left\| \nabla v\right\|_p.
\end{aligned}
$$
with the additional assumption that $ \nabla v \in L^\infty\!\left(\mathbb R^N, \mathbb R^N\right)$. Define the set 
$$
D:= \big\{\left\lvert \nabla u \right\rvert \leq \|\nabla u \|_\infty -\delta\big\},$$
the limit $\eqref{\star}$ is zero on the set $D$. To see this, we know there exists $N\in \mathbb N$ such that 
$$\left|\, \left\|\nabla u \right\|_\infty - \left\|\nabla u \right\|_p \,\right| \leq \frac{\delta}{2} \quad \forall \; p\geq N.$$
On the set $D$ we have 
$$ \left\|\nabla u \right\|_p - \left\lvert \nabla u \right\rvert  \geq \frac{\delta}{2} \quad \forall \; p\geq N$$
which means 
$$\frac{\left\lvert \nabla u \right\rvert}{\left\| \nabla u \right\|_p}  \leq 1 - \frac{\delta}{2} \quad \forall \; p\geq N$$
and the term in the limit $\left(\dfrac{\left\lvert \nabla u \right\rvert}{\left\| \nabla u \right\|_p}\right)^{p-2}$ goes to $0$ uniformly. Next I looked at the set $K: = \big\{\left\lvert \nabla u \right\rvert = \left\|\nabla u \right\|_\infty\big\}$, the term 
$$
\left(\frac{\left\lvert \nabla u \right\rvert}{\left\| \nabla u \right\|_p}\right)^{p-2} = \left(\frac{\left\| \nabla u \right\|_\infty}{\left\| \nabla u \right\|_p}\right)^{p-2}
$$
is in the form $``1^\infty""$, so I tried to use L'Hopital's rule. And we can calculate the limit (assuming the integrals are defined and finite, I just want to see what the limit might look like). 
$$
\begin{aligned}
 \lim_{p\rightarrow \infty} \left(\frac{\left\| \nabla u \right\|_\infty}{\left\| \nabla u \right\|_p}\right)^{p-2} 
&=  \lim_{p\rightarrow \infty} \exp\left( \left(p-2\right)\log\left(\frac{\left\| \nabla u \right\|_\infty}{\left\| \nabla u \right\|_p}\right)\right)
\\
&=\lim_{p\rightarrow \infty} \exp\left( \frac{\log\left(\frac{\left\| \nabla u \right\|_\infty}{\left\| \nabla u \right\|_p}\right)}{\frac{1}{p-2}}\right)
\\
&=\lim_{p\rightarrow \infty} \exp\left( \frac{\frac{d}{dp} \left[-\log\left(\frac{\left\| \nabla u \right\|_p}{\left\| \nabla u \right\|_\infty}\right)\right]}{\frac{-1}{(p-2)^2}}\right)
\\
&=\lim_{p\rightarrow \infty} \exp 
\left( 
  \dfrac{
    \left( 
       \dfrac{\left\| \nabla u \right\|_\infty}{\left\| \nabla u  \right\|_p}
    \right)
    \dfrac{
      \frac{d}{dp} 
      \big( \left\| \nabla u \right\|_p \big)
      }{ \left\|\nabla u \right\|_\infty} }
  { \dfrac{1}{\left(p-2\right)^2 }  }
\right)
\end{aligned}
$$
where
$$ 
\begin{aligned}
\frac{d}{dp}\Big[\left\| \nabla u \right\|_p \Big]  
&= \frac{d}{dp}\left[\left(\int_{\mathbb R^N} \left\lvert\nabla u \right\rvert^p \,dx \right)^{1/p} \right] 
\\
&=\frac{d}{dp}\left[\exp\left(\frac{1}{p} \log\left(\int_{\mathbb R^N} \left\lvert\nabla u \right\rvert^p \,dx \right)\right)\right] 
\\
&=\|\nabla u \|_p \left\{\frac{-1}{p^2}\log\left(\int_{\mathbb R^N} \left\lvert\nabla u \right\rvert^p \,dx \right) 
+ \dfrac{1}{p} \dfrac{1}{\int_{\mathbb R^N} \left\lvert\nabla u \right\rvert^p \,dx } \int_{\mathbb R^N} \left\lvert \nabla u \right\rvert^p \log\big(\left\lvert\nabla u \right\rvert\big) \,dx  \right\}
\end{aligned}
$$ And I am a little bit stuck.
Thank you very much!","['normed-spaces', 'limits', 'real-analysis', 'partial-differential-equations']"
1281289,Solving an integral for a characteristic function,"For $L>0, H>0,\alpha>0,\sigma>0,$
$$f(t)=\int_L^H \frac{ e^{i t x} \alpha  H \left(\frac{\sigma -H \log \left(\frac{H-x}{H-L}\right)}{\sigma }\right)^{-\alpha -1}}{\sigma  (H-x)} \, \mathrm{d}x$$ $\textbf{Background}$ This is the characteristic function of a nonstandard probability distribution.","['probability-theory', 'calculus', 'probability-distributions', 'characteristic-functions', 'integration']"
1281291,Baby Rudin Exercise 4.2,"Can someone check my proof? If $f$ is a continuous mapping of a metric space $X$ into a metric space $Y$, prove that $$f(\overline{E}) \subset \overline{f(E)} $$
  for every set $E\subset X$. ($\overline{E}$ denotes the closure of $E$.) Proof: Suppose $x\in \overline{E} = E\cup E'$, where $E'$ is the set of limit points of $E$. If $x\in E$, then $f(x)\in f(E)\subset \overline{f(E)}$ and we are done. Now suppose $x\in E'$ and let $\epsilon >0$ be given. Since $f$ is continuous, there exists a $\delta >0$ such that $d(x,y)<\delta$ implies $$d(f(x),f(y))<\epsilon. $$
Since $x$ is a limit point of $E$, there is a neighborhood $N_{\delta}(x)$ of radius $\delta$ about $x$ such that $(N_{\delta}(x)\setminus \{x\}) \cap E \neq \emptyset$. Then $p\in N_{\delta}(x)$ implies that $d(f(x),f(p))<\epsilon$. Hence, for any $\epsilon >0$, we can always find a $\delta$ such that
$$\left( N_{\epsilon}(f(x)) \setminus \{f(x)\}\right) \cap f(E) \neq \emptyset.$$ 
Thus $f(x)\in f(E)'\subset \overline{f(E)}$. I'm not really sure about the last part, how can we make certain that if $p\in N_{\delta}(x) \setminus \{x\}$, then $f(p) \in N_{\epsilon}(f(x))\setminus \{f(x)\}$. Since we aren't given that $f$ is injective, we can have $x\neq p$ and $f(x) = f(p)$? Any input or alternative approaches would be greatly appreciated!","['proof-verification', 'real-analysis']"
1281321,Show that $ \sum_{n\in \mathbb {S}} \frac{1}{n} $ is convergent [duplicate],"This question already has an answer here : Sum over all non-evil numbers (1 answer) Closed 9 years ago . Let $\mathbb {S} =\left \{ 1,2,3,...,9,11,12,...,19,21,...99,111,112,113... \right \} $
i.e, the positive integers set which contain zero digit is omitted. Now show that $ \sum_{n\in \mathbb {S}}  \frac{1}{n} $ is convergent . I really don't have no idea about how to prove this","['analysis', 'sequences-and-series', 'real-analysis']"
1281322,limit involving rational function and square root,"When working some exercise problems in my calc book, I came across this limit in which I do not know how to tackle.  It is
$$\lim_{x\to\infty}\frac{1-\frac{x}{x-1}}{1-\sqrt{\frac{x}{x-1}}}$$
I feel like there is a trick to this one, maybe use L'Hopital's rule or something.  I tried to multiplying by the conjugate but it turned ugly real fast.  Any tips will be helpful.","['calculus', 'limits']"
1281323,Limit of sequence and Riemann sum,"I have to calculate $$\lim_{n \to \infty}\sum_{k=1}^{n}\frac{(k-1)^7}{n^8}$$ So, $$\lim_{n \to \infty}\sum_{k=1}^{n}\frac{(k-1)^7}{n^8} = \lim_{n \to \infty}\sum_{k=1}^{n}\frac{1}{n}(\frac{k}{n}-\frac{1}{n})^7$$ But how to get the rid of $-\frac{1}{n}$?","['sequences-and-series', 'limits', 'integration']"
1281362,Function is measurable if and only if it is constant a.e.,"Let $(X,\Sigma,\mu)$ be a measurable space with $\mu(X)=1$ and $\mu(A) \in \{0,1\}$ for all $A \in \Sigma$. Show that $f: X \to \mathbb R$ is $\mu-$ measurable if and only if $f$ is constant a.e.. I think I could show one implication: Suppose $f$ is not constant, then $f$ takes at least to different values on two sets $A$, $B$ of measure greater than $0$. Note that $A \cap B=\emptyset$. So $1=\mu(A \cup B)=\mu(A)+\mu(B)=2$, a contradiction. I am not sure if my proof is correct and I got stuck trying to show the other implication: Suppose $f$ is constant almost everywhere. I want to prove that $\{f>a\} \in \Sigma$ for all $a \in \mathbb R$. Let $E=\{x:f(x)\neq c\}$, then $E$ has measure zero by hypothesis. $$\{f>a\}=\begin{cases}E^c \cup E \cap \{x:f(x)>a\},&\text{if }a< k\\E \cap \{x:f(x)>a\},&\text{if }a\geq k\;.\end{cases}$$ If $(X,\Sigma,\mu)$ is complete, it follows that $f$ is measurable, but if not I don't see why $E \cap \{x:f(x)>a\} \in \Sigma$. Any help would be greatly appreciated.","['real-analysis', 'measure-theory']"
1281372,Why is $\mathbb T\cup\mathbb A = \mathbb Q \cup \mathbb I =\mathbb R$?,"Where $\mathbb T $ is the set of transcendental numbers, and $\mathbb I $ is the set of irrational numbers and $\mathbb A $ is the set of algebraic numbers. The sets $\mathbb Q$ and $\mathbb R$ have their usual meanings. I'm having trouble understanding how the union of the transcendental $\mathbb T $ and algebraic numbers $\mathbb A $ is the same as the real numbers $\mathbb R$ since $\mathbb I ,\mathbb Q\subset\Bbb R$ as well. Put in another way, I think it should be $( \mathbb T \cup \mathbb A) \subset \mathbb R $ and $(\mathbb Q \cup \mathbb I) \subset \mathbb R$ So I'm basically questioning the equality in $\mathbb T \cup \mathbb A  = \mathbb Q \cup \mathbb I =\mathbb R$. The reason I'm asking this question is because those unions I mentioned above don't seem to 'cover' all the Reals $\mathbb R$ . Thanks in advance. Kindest Regards.","['elementary-set-theory', 'intuition']"
1281378,Triangle Center Midpoint,"Consider the following construction of a triangle center: (The method could also be easily generalized to any shape with finite perimeter) For each point $X$ on the triangle, find point $X'$ such that $X$ and $X'$ split the triangle into two sections of equal length (each of length equal to the triangle semiperimeter). Then, let $Y$ be the midpoint of $X$ and $X'$. The locus of all such $Y$ is also triangular, so we can repeat the process on the triangle created by the locus of all such $Y$, ad infinitum until the triangles converge to a point. Through some computer simulation, I was able to determine that this convergence point isn't one of the common triangle centers. Searching through the Encyclopedia of Triangle Centers , I also wasn't able to find this triangle center listed. Does this center have an established name, or is there literature available on the topic?","['geometry', 'triangles']"
1281379,Distributing identical objects into distinct boxes,"The problem I'm trying to solve is: find the number of ways of distributing $r$ identical objects  into $n$ distinct boxes such that no box is empty, where $r  \geq n$. I've found conflicting answers to this in numerous searches, and I'm hoping someone might be able to point me in the direction of how to arrive at the correct one. Thanks so much!","['combinatorics', 'proof-writing']"
1281383,First order differential equation integrating factor is $e^{\int\frac{2}{x^2-1}}$,"So i got the first order ode
$$(x^2-1)\frac{dy}{dx}+2xy=x$$
I divided both sides by $x^2-1$
$$\frac{dy}{dx}+\frac{2}{x^2-1}xy=\frac{x}{x^2-1}$$
in the form $y' + p(x)y = q(x)$ So that means the integrand is...
$$e^{\int\frac{2}{x^2-1}}$$ But i'm not sure what to do i think the $\int\frac{2}{x^2-1}$ = $-\log{(x-1)}+4\log{(x+1)}$ So it's $$e^{-\log{(x-1)}+4\log{(x+1)}}$$
$$e^{\log{(x-1)^{-1}}+\log{(x+1)^4}}$$
$$\frac{1}{x-1}+(x+1)^4$$ Is this right? and then just multiply both sides by this?","['calculus', 'ordinary-differential-equations']"
1281392,How to compute $\cos(x)$ within $n$ digit accuracy when $x = \sqrt{y}$ with $y \in \mathbb{N}$,How does one compute $\cos(x)$ within desired $n$ digit accuracy when $x = \sqrt{y}$ with $y \in \mathbb{N}$ and $x$ is not rational? The reason I am asking this question is that calculators definitely encounter these problems and there should be some method handling this..,"['computer-science', 'numerical-methods', 'trigonometry']"
1281401,Using PoincarÃ©-Bendixson to prove that there is a periodic solution,"I want to use the PoincarÃ©-Bendixson theorem to show that there exists a nontrivial (and periodic) solution to $$z'' + [\log (z^2 +4(z')^2)]z' + z = 0.$$ Therefore I substituted $u = z'$ to get $$u' = - \log(z^2 + 4u^2) u - z, \quad z' = u.$$ We haven't covered the theorem in our classes yet, so I just try to follow the page 10 from these dynamical systems notes . I think that we can differentiate $f$ on every open set disjoint with $(0,0)$, but what would the $\mathcal S$ be here? How to proceed? Here is the plot of dynamical system mentioned above and a sample trajectory starting from $(-5,5)$.","['dynamical-systems', 'ordinary-differential-equations']"
1281415,How to show that if $\prod X_\alpha$ is Hausdorff or normal then so is $X_\alpha $?,"How to show that if $\prod X_\alpha$ is Hausdorff  or normal then so is $X_\alpha $? I will include where I am getting stuck. When $\prod X_\alpha$ is Hausdorff :: To show $X_\alpha $ is Hausdorff let $(x_\alpha),(y_\alpha )$ be two points in  $X_\alpha $. How should I take the corresponding points in $\prod X_\alpha$ in order to use it is Hausdorff? (Note:I don't want to use that Hausdorff is a hereditary property and $X_\alpha $is a subspace of $\prod X_\alpha$). When $\prod X_\alpha$ is normal :: let $U_\alpha,V_\alpha$ be two disjoint closed sets in $X_\alpha$. Since the projection map is continuous so $p_\alpha^{-1}(U_\alpha)$ and $p_\alpha^{-1}(V_\alpha)$ are closed in $\prod X_\alpha$. Then we will get two disjoint closed sets $U,V\in \prod X_\alpha$ such that $p_\alpha^{-1}(U_\alpha)\subset U$ and $p_\alpha^{-1}(V_\alpha)\subset V$ ;$U\cap V=\emptyset\ .$ Can I now use that $(U_\alpha)\subset p_\alpha (U)$ and  $(V_\alpha)\subset p_\alpha (V)$ and the fact that $p_\alpha $ is open? Please say the problems involved here and suggest proper changes.",['general-topology']
1281416,Graphs Approaching Asymptotes,"I've been wondering this for a while. For graphs that approach asymptotes, are there certain formulas that can determine the distance between the graph and the asymptote as $x$ gets infinitely small or large?","['asymptotics', 'graphing-functions', 'functions']"
1281419,To find maximum possible value of this integral,"If $\int_{0}^{1} f dx=3$  and  $\int_{0}^{1} xf dx  =2$, then find the maximum value of $$\int_{0}^{1} f^2 dx.$$ What methods would apply to find this maximum value? I am not approaching the methods...",['real-analysis']
1281421,convergence in $L^p$ implies convergence in measure,"I am trying to show that if $f_n$ converges to $f$ in $L^p(X,\mu)$ then $f_n\to f$ in measure, where $1\le p \le \infty$ . Here is my attempt for $p\ge 1$ : Let $\varepsilon>0$ and define $A_{n,\varepsilon}=\lbrace x: \vert f_n(x)-f(x) \vert \ge \varepsilon\rbrace$ . I want to show $\mu (A_{n,\varepsilon})\to 0$ . $\Vert f_n-f \Vert_p=\left(\int _X \vert f_n-f\vert ^p\right)^{1/p}\ge \left(\int _{A_{n,\varepsilon}}\vert f_n-f\vert ^p\right)^{1/p}\ge \varepsilon \mu (A_{n,\varepsilon})^{1/p}$ so that $\mu (A_{n,\varepsilon})\le \left(\frac{\Vert f_n-f\Vert_p }{\varepsilon}\right)^{p}$ and the RHS tends to $0$ as $f_n\to f$ in the $L^p$ norm. How can I deal with the case $p=\infty$ ?","['lp-spaces', 'analysis', 'solution-verification', 'real-analysis']"
1281431,How do I prove this function is differentiable at 0?,"Define $f:\mathbb{R}\longrightarrow \mathbb{R}$ by
$$f(x) =\begin{cases}
x^{4/3}\cos \left(\frac1x\right) & \text{if } x \neq 0, \\\\
   0       & \text{if } x =0.
  \end{cases}$$
Prove that $f$ is differentiable at $0$. I tried taking a two-sided limit test, but I was unable to simplify it. Can someone help me with this problem?","['derivatives', 'calculus', 'real-analysis', 'functions']"
1281436,Confusion about the null (empty) set being contained in other sets,"I'm having a tough time understanding how the set theory of null sets work. I have:
$$
  X=\emptyset,\quad\quad Y = \{\emptyset\},\quad\quad Z = \{\{\emptyset\}\}.
$$ Some of my self-study exercises include these true or false questions. Now, I'm more concerned with the reasoning behind why they're true or false as opposed to the answers as I already have the answers, I just want the understanding. $\emptyset \in X$. I know this is false because the null set is not an element of any set. $\emptyset \in Y$. I don't know why this is true. $\emptyset \in Z$. I don't know why this is false. $X \subseteq Y$. I know this is true because the null set symbol is directly within the set. $Y \subseteq Z$. I don't know why this is true. $X \in Y$. The same reason why (2) is true, I understand this one. $Y \in Z$. This is true because $\{\emptyset\}$ is directly within the set defined by $Z$.",['elementary-set-theory']
1281453,$x^2y''+(2x^2+x)y'+(2x^2+x)y=0$ A Bessel equation,$$x^2y''+(2x^2+x)y'+(2x^2+x)y=0$$ The solution is $$e^{-x}J_o(x)+e^{-x}Y_o(x)$$ How does one approach a problem like this?,"['bessel-functions', 'ordinary-differential-equations', 'special-functions']"
1281454,Bayes' rule with 3 variables,"I have been using Sebastian Thrun's course on AI and I have encountered a slightly difficult problem with probability theory. He poses the following statement: $$
  P(R \mid H,S) = \frac{P(H \mid R,S) \; P(R \mid S)}{P(H \mid S)}
$$ I understand he used Bayes' Rule to get the RHS equation, but fail to see how he did this. If somebody could provide a breakdown of the application of the rule in this problem that would be great.","['probability', 'bayes-theorem']"
1281467,Why is Octahemioctahedron topologically a torus?,"I'm afraid, that I have a very bad space vision, because I don't see, that Octahemioctahedron is topologically a torus. Could somebody explain it for me, why is it? Scene 2. @aes: Finally, with your help I managed to match the vertices of the polyhedron with the vertices on the topological net, thank you. The result is this:","['polyhedra', 'general-topology']"
1281506,Probability of dice with a cumulative successes,"Needing some Math help! I'm working out part of a system for a game I'm working on, and I need to know if I need to tweak some things, so I'm checking to see if it all adds up (no pun intended). defender has a base of 1, 3, 5, 7, or 11 for the target successes that the attacker has to roll; if the attacker achieves the # of successes required the attacker wins the roll, otherwise the defender wins.
the attacker rolls 1, 2, 3, 4, or 5 10-sided dice based on his/her increasing skill, however only 8-10 count as a success, and each 9-10 granting an additional die to add to the pool. That means, there is a 3/10 chance of at least one success, and 1/5 chance to add another die, to increase the chance for the attacker to hit the defender's number. I feel like this should be really easy, but I can't figure out how to get started...
What is the chance (expressed as a ratio please...) for the attacker to win the roll against a defender with a target of 1? a target of 3, 5, 7, 11?","['dice', 'probability', 'statistics']"
1281538,Test for a $G$-torsor to be trivial?,"I just have a very short question, why is a $G$-torsor trivial precisely when it has a section?","['algebraic-groups', 'algebraic-geometry', 'group-theory']"
1281543,Finite Summation of Fractional Factorial Series,"Is there a closed form solution for the following series? (Without Using Gamma Function):
$$
S=\sum _{i=1}^{n-1} \frac{1}{(i+1)!}
$$","['factorial', 'summation', 'sequences-and-series']"
1281581,A matrix representation for the inverse matrix.,"I have a problem from ""Methods of Algebriac Geometry in Control Theory by Peter Falb"" textbook: Show that if $A$ is $\,n\times n\,$ matrix, then $\displaystyle\,(zI-A)^{-1} = \sum_{j=1}^n \phi_j\left(z\right) A^{n-j} \big/ \det\left[zI-A\right]$. Compute $\phi_j\left(z\right)$. I am using the following formula:
$$
{\left(zI-A\right)}^{-1} = 
\frac{1}{\det \left(zI-A\right)}
\sum_{s=0}^{n-1}\left(zI-A\right)^{s}
\sum_{k_1,k_2,\ldots ,k_{n-1}}
\prod_{l=1}^{n-1} \frac{\left(-1\right)^{k_l+1}}{l^{k_l}\,k_{l}!}\,
\left(\operatorname{tr}\left(zI-A\right)^l\right)^{k_l}
$$ 
where the second summation is over $\displaystyle\,j+\sum_{l=1}^{n-1}lk_l=n-1$.
But I don't see how to find $\,\phi_j\left(z\right)$. Can anyone help me on this?
Thanks in advance. P.S
In the book it's stated that $\phi_j(z)$ is a polynomial of degree $n-j$.","['linear-algebra', 'matrices']"
1281635,$\sum_1^{\infty} \frac{(p+1)(p+2)(p+3)...(p+n)}{(q+1)(q+2)(q+3)...(q+n)}$ convergence,"I need to determine for which values of $p$ and $q$, both greater than $0$, the following series converges: $$\sum_1^{\infty} \frac{(p+1)(p+2)(p+3)...(p+n)}{(q+1)(q+2)(q+3)...(q+n)}$$ I've tried using the ratio test, comparison test, and I've also tried partial fraction decomposition but I can't get to anything. Could you give me a hint on how to solve this? Any help will be appreciated","['sequences-and-series', 'real-analysis']"
1281685,"If $A$ is a square matrix and $Ax = b$ has a unique solution for some $b$, is $A$ necessarily invertible?",Let $A$ be a square matrix. Suppose that $A x = b$ has a unique solution for some $b$. Is $A$ necessarily invertible? I said no because the invertible matrix theorem states that $A x = b$ has a unique solution for each $b$. Is this correct or does the wording not make a difference?,"['linear-algebra', 'matrices']"
1281710,Prove that $\left\lceil \frac{n}{m} \right\rceil =\left \lfloor \frac{n+m-1}{m} \right\rfloor$,"On a discrete mathematics past paper, I must prove that $$\left\lceil \frac{n}{m} \right\rceil = \left\lfloor \frac{n+m-1}{m} \right\rfloor$$ for all integers $n$ and all positive integers $m$. I have started a proof by induction thus: Let $P(m,n)$ be the statement that $$\left\lceil \frac{n}{m} \right\rceil = \left\lfloor \frac{n+m-1}{m} \right\rfloor$$ for all integers $n$ and all positive integers $m$. Then, according to the technique described here , I must prove the following: Base case: I have already proved that $P(a,b)$, where $a=1$ and where $b$ is the smallest value where $n$ is valid.  (Note that this is equivalent to proving that $\lceil n \rceil = \lfloor n \rfloor \space \forall\space n\in\mathbb{Z}.$) Induction over $m$: I must show that $P(k,b) \implies P(k+1,b)$ for some positive integer $k$.  THIS IS THE STAGE AT WHICH I AM STUCK. Induction over $n$: I must show that $P(h,k) \implies P(h,k+1)$ for some positive integer $m$ and for some integer $k$ (I think that I must account for the fact that $k$ could be negative OR non-negative). I will explain why I am stuck. My inductive hypothesis is that $P(k,b)$ - that is, $\left\lceil \frac{b}{k}\right\rceil = \left\lfloor \frac{b+k-1}{k}\right\rfloor$. I want to show that this implies $P(k+1,b)$.  I have tried to do this by attempting to express $\lceil \frac{b}{k+1} \rceil$ in terms of $\left\lceil \frac{b}{k} \right\rceil$, but have not succeeded. Any hints would be appreciated.","['ceiling-and-floor-functions', 'induction', 'discrete-mathematics']"
1281714,Holomorphic function definition. Am I missing something very obvious?,"I'm reading a book of complex analysis in which the definition of holomorphic function is given as follows: Definition : If  $V$ is an open set of complex numbers, a function $f:V \to \mathbb C$ is called holomorphic if the first derivative $z \to f'(z)$ is defined and ""continuous"" as a function from $V$ to $\mathbb C$. Can someone please illustrate why do we need the derivative map to be continuous? I know this may be a easy doubt but I am unable to answer this.Thank you for your help !","['complex-analysis', 'definition']"
1281753,Why are cochains in group cohomology exact as a functor of the coefficients?,"I am stuck with exercise $1$ of section $3$ of chapter $1$ in the book Cohomology of number fields by Neukirch. The exercise is to show that the functor from $A \rightarrow C^n(G,A)$ is exact, where $G$ is a profinite group and $A$ is a $G$ module. By definition $C^n(G,A)=X^n(G,A)^G$. Here $X^n(G,A)$ is defined to be continuous map from $G^{n+1}$ to $A$ with discrete topology on $A$. Now from page $32$ of the same book  using  proposition $1.3.7$, I deduce that $X^n(G,A)=X^n(G,Ind_G(A))^G$ that is I get that $C^n(G,A)=({X^n(G,Ind_G(A))^G})^G$. But $(-)^G$ is left exact and I know that $A \rightarrow Ind_G(A)$ is exact. I am lost after that. Any help will be very favorable.","['number-theory', 'homological-algebra', 'abstract-algebra', 'group-cohomology', 'category-theory']"
