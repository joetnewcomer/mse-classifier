question_id,title,body,tags
3027282,Simple proof of a theorem on convergence of series,"Let $p_j\ge0,\ j=1,2,3,\dots,$ and suppose $\sum_j p_j=1.$ Is there a simple proof that $$\sum_{j=1}^\infty{jp_j}\tag{1}$$ converges?  My question arises from the answer to this question .  Consider a Markov chain with state space $\{1,2,3,\dots\}.$ If the chain is is state $1,$ it transitions to state $j$ with probability $p_j.$ If it is in state $j>1$ then it always transitions to state $j-1$ .  The chain is irreducible and aperiodic, so it has a unique stationary distribution.  The sum $(1)$ arises in computing the stationary probabilities, so it must converge. I've been trying unsuccessfully to find a more direct proof.  There isn't any way to apply standard tests (root test, ratio test, Gauss's test) and I haven't any other ideas.  (It's equivalent to the statement that if N is a random variable that takes positive integer values, then $E(N)$ exists, but I don't see how that helps.  In fact, my intuition would be that this statement is false.) EDIT It has been amply shown that the statement is false.  I would like to know the error in the linked question.","['markov-chains', 'probability', 'sequences-and-series']"
3027289,Does non-uniqueness of solution to 1st order ODE implies the existence of infinitely many solutions?,"Consider the following initial value problem (IVP) to the first order ODE: $$\tag{1} \dot x = f(t, x), \ \ \ x(t_0) = x_0.$$ The Existence and Uniqueness Theorem describes when one has exactly one solutions. This is true (e.g.) when $f$ is continuously differentiable. There are examples where uniqueness fails and existence fails ( here or here ): In all of the examples where I am aware of, whenever one has more than one solutions, one actually has infinitely many. Hence my question: Can an IVP has more than one solutions, but only finitely many solutions?","['initial-value-problems', 'ordinary-differential-equations']"
3027343,$f(a)-f(b)$ is rational iff $f(a-b) $ is rational,"Prove that the continuous function $f:\mathbb{R} \to \mathbb{R}$ satisfying $f\left(x\right)-f\left(y\right)  \in\mathbb{Q} \iff f\left(x-y\right) \in \mathbb{Q}$ is of the form $ 
f\left(x\right)=ax+b.$ My Attempt. I tried considering the function $$g\left(x\right)=\frac{f\left(x\right)-f\left(0\right)}{f\left(1\right)-f\left(0\right)}$$ which also satisfies the property $g\left(a\right)-g\left(b\right)  \in\mathbb{Q} \iff g\left(a-b\right) \in \mathbb{Q}$ , Now I am trying to prove that this function g is identity function and then I can prove that $f\left(x\right)=\left(f\left(1\right)-f\left(0\right)\right)x+f\left(0\right).$ And I am done. Also This function has to be identity function because $g\left(0\right)=0$ and $g\left(1\right)=1$ . I tried assuming that the function g is such that $g\left(a\right)\neq a$ for some $a\in \mathbb{R}$ . Then by continuity $g\left(x\right)\neq x$ for some $\delta>0$ neighborhood of $a$ .
But I cannot move further. Also
Using a previously known result, I was able to prove that f must be monotonic. However I do not want to use any other result which is not known and not trivial. If a function $f $ is continous in $\left[a,b\right]$ and $f\left(a\right)=f\left(b\right)$ then for any $\epsilon >0$ there exists $m,n \in \left[a,b\right] $ such that $f\left(m\right)=f\left(n\right)$ and $m-n=\epsilon$ . In this case choose $\epsilon \in \mathbb{R}-\mathbb{Q} $ and get $m,n \in \left[a,b\right] $ such that $f\left(m\right)-f\left(n\right)=0 \in \mathbb{Q}$ but $m-n \in\mathbb{R}-\mathbb{Q}$ .","['functional-equations', 'fixed-point-theorems', 'real-analysis', 'continuity', 'rational-numbers']"
3027359,Number of discontinuities of $\lfloor\sin ^{-1} x\rfloor+\lfloor\cos ^{-1} x\rfloor$,"Find Number of discontinuities of $$f(x)=\lfloor\sin ^{-1} x\rfloor+\lfloor\cos ^{-1} x\rfloor$$ My try: The floor function $\lfloor x\rfloor$ is discontinuous when $x \in \mathbb{Z}$ Now the integer values $\sin^{-1}x$ takes are ${-1,0,1}$ This means the function $h(x)=\lfloor \sin^{-1} x\rfloor$ is discontinuous at $x=-\sin 1  , 0, \sin 1$ Similarly the integer values $\cos^{-1} x$ takes are $0,1,2,3$ This means the function $g(x)=\lfloor \cos^{-1} x\rfloor$ is discontinuos at $x=\cos 3, \cos 2,\cos 1,1$ but since the domain of $f(x)$ is $[-1, \:\: 1]$ we need to check Left continuity of $f(x)$ at $x=1$ $$\lim _{x \to 1^-}f(x)=\lim_{h \to 0} \lfloor \sin^{-1}(1-h)\rfloor+\lfloor \cos^{-1}(1-h)\rfloor=1=f(1)$$ hence $f(x)$ is continuous at $x=1$ hence number of discontinuities are $6$ is this right approach?","['ceiling-and-floor-functions', 'trigonometry', 'solution-verification', 'limits', 'algebra-precalculus']"
3027381,An example of open but not closed map.,"Exercise : Find an example of mapping which is open but not closed, which is closed but not open. I am thinking of trivial examples with $X=\{1,2,3\}$ however I have no idea on how to build a function that preserves the open interval but no the closed ones. Since this is my first exercise of this kind. Question: Can someone give me a hint? Thanks in advance!","['closed-map', 'general-topology', 'open-map']"
3027390,Product of two lower triangular matrices is a lower triangular matrix,"For my univerity studies I had to prove this: $ Let \,\, n \,\ \in N \,\, and \,\, L1,\, L2 \, \in R(n \times n) \,\, be \,\, both \,\, lower \,\, triangular \,\, matrices.$ $ Show \,\, that \,\, L := L1L2 \,\, is \,\, also \,\, a \,\, lower \,\, triangular \,\, matrix.$ I proved it like this (and I need some verification for the proof): $L_{ij} := (L1L2)_{ij}$ $Now \,\, just \,\, look \,\, at \,\, (L1L2)_{ij} \,\, where \,\, j > i.$ $(L1L2)_{ij} = \sum_{r=1}^n l1_{ir}l2_{rj} = \sum_{r=j}^i l1_{ir}l2_{rj} = \sum_{r=1}^n l1_{ir}l2_{rj} = \begin{cases}
0,  & \text{if $j>i$ is even} \\
a \in R, & \text{else}
\end{cases}
$ $\Rightarrow \text{L is lower triangular}$ $\square$","['matrices', 'proof-verification', 'linear-algebra']"
3027422,Box in a box: will it fit? or whether or not I can take my couch to AK,"Have ""box A"" (U-Haul shipping container) with dimensions length 95 inches, width 56 inches, height 83.5 inches and ""box B"" (couch) with dimensions length 96 inches, width 50 inches, height 34 inches. Will ""box B"" fit in ""box A""? It has been a long time since I took any math class, but I figured the length of the couch can easily fit within the length of the container's diagonal. I am less sure about whether the angle at which the couch would need to be tilted for its length to fit would be possible given its height. Plan on building a scale model if this proves too uninteresting for answers. Will post pics regardless.",['geometry']
3027477,"Prove that If B is open, then $\overline{A} \cap B \subset \overline{A \cap B}$","Let $(X,d)$ be a metric space and let $A, B \subset X$ . Prove that:
If B is open, then $$\overline{A} \cap B \subset \overline{A \cap B}$$ where $\overline{S}$ indicates closure for some set $S$ . For proof I was only able to change the prove part slightly(not sure if this is a correct start): Since $B \subset \overline{B} \implies \overline{A} \cap \overline{B} \subset \overline{A \cap B}$","['general-topology', 'metric-spaces', 'real-analysis']"
3027482,"Give an example of: A group with an element A of order 3, an element B with order 4, where order of AB is less than 12","I'm a mathematics major studying at University as an undergrad.  This is a question on the study guide for the upcoming final in Math 344 - Group Theory: "" Give an example of a group G with an element a of order 3, an element b of order 4, where order of ab is less than 12. "" My understanding is if an element a has order n , it means that if a is combined with itself n times, it results in the identity element e : a^n=e .  It also means that there is no number smaller than n where this is true for a . Two elements a and b can be combined into ab such that ab is the result of whatever operator acts on the group. Example: If the operator is addition, ab=a+b Possible groups I've considered that don't seem to work: - D2n , the group of symmetries of a regular n -sided polygon.  This includes rotations about the center, or flips across lines that go through the center.  It doesn't seem to work because if a rotation has order 3, and another rotation has order 4, their combination should have order 12.  All the flips or combinations of a rotation with a flip have order 2 -Quotient group Z/nZ . Z/12Z doesn't seem to work, since { 12Z +4} is order 3, { 12Z+3 } is order 4, but { 12Z+3+12Z+4}={12Z+7 }, which has order 12.  This seems to hold for other values of n -The group of integers/reals/rationals with the addition operator, or the group of non-zero real numbers with multiplication, or the group of rationals with multiplication.  None of these seem to have elements of order 3 or 4 in the first place These are the main groups we worked with in class.  I've searched this site and others for examples of groups I may have overlooked, with no luck.  I believe the elements I need won't be commutative - such that ab does not equal ba - but I'm not certain. Thank you!","['group-theory', 'quotient-group']"
3027486,Divisibility Tests in Various Bases,"Background One thing that has been on my mind lately is why a number of simple rules work for determining if some large number is a multiple of some other number. In base 10, I was taught the following divisibility rules: 2: Ends with an even digit 3: Sum all the digits. If that number is a multiple of 3, so is the whole number 4: The last two digits are a multiple of 4 5: Last digit is a 5 or 0 6: Number is an even multiple of 3 8: The last 3 digits are a multiple of 8 9: Sum all the digits. If that number is a multiple of 9, so is the whole number 10: Last digit is 0 Multiples of 1 are trivial. I also don't know any rule for 7 in base 10, but I noticed some interesting patterns that might apply to some other bases. In base 6, you get these rules: 2: Ends with even digit 3: Ends with 0 or 3 4: Last two digits are a multiple of 4 5: Sum all the digits. If that number is a multiple of 5, so is the whole number. 6: Last digit is 0 So there are some general rules given some radix R: Multiples of R end in 0 Factors of R can use the last digit only for multiples R-1 and its factors can use the ""sum the digits"" trick You can compose rules from a existing multiples: If A and B have no common multiples, then the rule for AB is the rule for A anded with the rule for B For instance, in base 10, 6 uses both rules for 2 and 3 in conjunction because 2 and 3 are its prime factors If A is a rule that uses the last digit, then A n can use the last n digits. If A has a divisibility rule, then R n A can exclude the last n digits and use the rule for A. Given these rules, 12 rules should work for base 10 as a combination of the 3 rule and the 4 rule. The Question Is my reasoning here sound? Are there any formal proofs already done on the subject? Are there other reasonable rules that could be used for, say, multiples of 7 in base 10?","['number-theory', 'divisibility']"
3027492,Finding a smaller dataset with a similar covariance matrix,"I'm interested in solving the following problem: Given a dataset $\mathcal{X} = \{x_i\}_{i=1}^n\subset\mathbb{R}^p$ , find a smaller set $\mathcal{Y} = \{y_i\}_{i=1}^k\subset{\mathbb{R}^p}$ whose sample covariance matrix, $C_\mathcal{Y}$ , is a good approximation to that of $\mathcal{X}$ , $C_{\mathcal{X}}$ . To make this a little more precise, is there a good way of finding $\mathcal{Y}$ such that $\left\|C_\mathcal{X} - \mathcal{C}_\mathcal{Y}\right\| \le \varepsilon$ , or such that $\left\|C_{\mathcal{X}} - C_{\mathcal{Y}}\right\|$ is near-minimal for fixed $k$ ? One idea would be to choose $\mathcal{Y}$ by sampling $\mathcal{X}$ at random. Perhaps a better way to do this, though, is to make $\mathcal{Y}$ the result of Lloyd's algorithm / $k$ -means on $\mathcal{X}$ , which would help to better summarize the entire dataset. In general, is there a decent way to solve this problem, preferably with good theoretical bounds on $\left\|C_{\mathcal{X}} - C_{\mathcal{Y}}\right\|$ (where $\left\|\cdot\right\|$ is just a common matrix norm, e.g. Frobenius or spectral)? Ideally I could find $\mathcal{Y}$ in time complexity similar to that of Lloyd's algorithm, or at least in time that is sub-quadratic in $n$ (so preferably cheaper than doing something like PCA ). But if you have ideas for methods/algorithms that are more computationally expensive that haven't been mentioned here I'd also appreciate hearing those. Thank you!","['machine-learning', 'statistics', 'probability']"
3027494,The equation $ f'(x)=f(x)$ admits a solution,"let $f :[0,1]→\mathbb R$ be a fixed continous function such that f is differentiable on (0,1) and $ f(0)=f(1)=0$ .then the equation $ f'(x)=f(x)$ admits No solution $x\in (0,1)$ More than one solution $x\in (0,1)$ Exactly one solution $x\in (0,1)$ At least one solution $x\in (0,1)$ Actually, mean value theorem doesn't work for $f'(x)$ .
The function $f$ has a fixed point and at that point $f'(x)=1$ and at some point $x_0 , f'(x)=0$ (by mean value theorem).but it doesn't get me anywhere! What am I missing? Obviously 1. Is false since f(x)=0 (also 3.) Is also false since $f(x)=\sin\pi x$ So 4. Is true, but I stuck to prove. Please help.","['rolles-theorem', 'continuity', 'derivatives', 'real-analysis']"
3027503,"Show that if $H$ is an Hermitian matrix, then $U=(iI-H)(iI+H)^{-1}$ is unitary","How would you prove, that when $H$ is a hermitian matrix, then: $$U=(iI-H)(iI+H)^{-1},$$ where $U$ is unitary, assuming that $(iI+H)$ is invertible. I thought that because $U$ is unitary, $UU^*=U^*U=I$ . So I tried to take the conjugate transpose of $U$ where: $$U^*=(-iI-H)(H-iI)^{-1}.$$ Essentially this is where I am stuck: 1) How do I take the transpose of $U$ , so I don't just have the conjugate -- or does it not matter? 2) How do I get rid of the inverse because I don't know what to do with it and how to eventually prove $UU^*=I$ ? Thank you!","['matrices', 'linear-algebra']"
3027553,Convergence of Sum of Sequences,"This week, I learned a bit more about limits, convergence and divergence. 
I was given a sum of two sequences and asked to tell whether or not it is convergent, and what its limit is: $a_n := (-1)^n + \frac{1}{n^2 +1}$ which I re-wrote into $\lim_{n\to \infty}(-1)^n +\lim_{n\to \infty}\frac{1}{n^2 +1}$ I noticed that $\lim_{n\to \infty}(-1)^n$ isn't convergent, whereas the latter is convergent and has the limit of $0$ . That is why I'm not entirely sure whether $a_n$ is convergent or not, and got confused. I hope someone can clear my doubts and explain their answer to me!
Thank you.","['limits', 'convergence-divergence', 'sequences-and-series']"
3027576,Integral of $\ln(\tanh(x))$,"I'd like a hint toward how I could evaluate this definite integral. I'm aware it's likely to be non elementary and I haven't found a way to evaluate it yet: $$\int_0^\infty \ln(\tanh(x))\,\,\mathrm{d}x$$ If you're curious where this came from, I was looking at an integral involving $\ln(\sin(x))$ and I thought of this one. Thanks.","['integration', 'calculus', 'hyperbolic-functions']"
3027579,"Is there a context-free but non regular language, which still meets the requirements of the regular pumping lemma?","Is there a context-free but non regular language, which still meets the requirements of the regular pumping lemma? Regular Pumping Lemma: $\exists n\in \mathbb{N}:\forall w \in L:{\mid
 w \mid} \geq n: \exists x,y,z\in \Sigma^*$ : \begin{align} i)&w=xyz\\
 ii)& {\mid y \mid} \geq 1\\ iii)& {\mid xy \mid} \leq n\\ iv)& \forall
 i\in \mathbb{N_0}:xy^iz\in L 
\end{align} Is there any $L$ with $L\in CFL$ and $L\notin REG$ but still meets the regular pumping lemma from above?","['discrete-mathematics', 'computer-science']"
3027587,Does a surface with given boundary in $\mathbb{R}^3$ exist?,"Given a (smooth) simple closed curve $C \subset \mathbb{R}^3$ , is there a (smooth) surface $S$ with $\partial S = C$ ? I'm aware there is a variational problem to find among such surfaces the one with minimal area. Here I'm interested in the statement and proof of some existence theorem. Some cases where the existence is clear: if $C$ is planar, and more generally if $C$ is the curve of intersection of a a graph and a cylinder, $x_1=g(x_2,x_3)$ and $f(x_2,x_3)=0$ (This question came up when I read in a calculus book that $\text{curl }\mathbf{F}=\mathbf{0}$ implies $\mathbf{F}=\nabla f$ for some scalar function $f(x,y,z)$ . The proof was: $\mathbf{F}=\nabla f$ iff $\mathbf{F}$ is conservative; to show $\mathbf{F}$ is conservative, consider $\int_C \mathbf{F}\cdot d\mathbf{r}$ for any closed curve $C$ . ""THERE IS"" a surface $S$ with $C$ as its boundary. By stokes theorem, and the fact that $\text{curl }\mathbf{F}=0$ , $\int_C \mathbf{F}\cdot d\mathbf{r} = 0$ . So, my question is why this surface even exists.)","['calculus-of-variations', 'multivariable-calculus', 'differential-geometry']"
3027602,Proving $(\sec^2x+\tan^2x)(\csc^2x+\cot^2x)=1+2\sec^2x\csc^2x$ and $\frac{\cos x}{1-\tan x}+\frac{\sin x}{1-\cot x} = \sin x + \cos x $,"Prove the following identities: $$(\sec^2 x + \tan^2x)(\csc^2 x + \cot^2x) = 1+ 2 \sec^2x \csc^2 x 
\tag i$$ $$\frac{\cos x}{1-\tan x} + \frac{\sin x}{1-\cot x} = \sin x + \cos x
\tag {ii}$$ For $(\mathrm i)$ , I initially tried simplifying what was in the 2 brackets but ended up getting 1 + 1. 
I then tried just multiplying out the brackets and got as far as $$1+ \sec^2x + \frac{2}{\cos^2x \sin^2x}$$",['trigonometry']
3027616,Subset of $\ell^2$ with distance property,"I'd been trying the following problem: Prove that exists an infinite set $A\subset B(0,1)$ such that $\|x-y\|_2>\sqrt{2}$ for all $x,y \in A$ . My ideas always end in points with distance at most $\sqrt{2}$ . I need hints, please.","['hilbert-spaces', 'lp-spaces', 'functional-analysis']"
3027621,Request for crazy integrals,"I'm a sucker for exotic integrals like the one evaluated in this post . I don't really know why, but I just can't get enough of the amazing closed forms that some are able to come up with. So, what are your favorite exotic integral identities, and how do you prove them?","['integration', 'soft-question', 'definite-integrals', 'big-list']"
3027633,Why is this the second derivative here?,"Let $F\colon\mathbb{R}^{2}\to\mathbb{R}$ and $f\colon\mathbb{R}\to\mathbb{R}$ be two $\mathcal{C}^{1}$ functions. Lets say we have a neighborhood
of a point $\left(x_{0},y_{0}\right)$ such that for every $\left(x,y\right)$ we have $F\left(x,y\right)=0$ if and only if $y=f\left(x\right).$ So we can say that in this neighborhood we have $F\left(x,f\left(x\right)\right)=0$ and if we let $g\colon\mathbb{R}\to\mathbb{R}^{2}$ be defined by $g\left(x\right)=\left(x,f\left(x\right)\right)$ then $F\left(g\left(x\right)\right)=0$ and therefore \begin{align*}
0 & =\left[F\left(g\left(x\right)\right)\right]'=D_{F\circ g}\left(x\right)=D_{F}\left(g\left(x\right)\right)\cdot D_{g}\left(x\right)=\\
 & =\left(\frac{\partial F}{\partial x}\left(x,f\left(x\right)\right),\frac{\partial F}{\partial y}\left(x,f\left(x\right)\right)\right)\cdot\begin{pmatrix}1\\
f'\left(x\right)
\end{pmatrix}=\\
 & =\frac{\partial F}{\partial x}\left(x,f\left(x\right)\right)+\frac{\partial F}{\partial y}\left(x,f\left(x\right)\right)\cdot f'\left(x\right)
\end{align*} $$
\Rightarrow\qquad f'\left(x\right)=-\frac{\frac{\partial F}{\partial x}\left(x,f\left(x\right)\right)}{\frac{\partial F}{\partial y}\left(x,f\left(x\right)\right)}
$$ Im trying to compute $f''\left(x\right)$ . I was thinking it
would be something like $$
f''\left(x\right)=-\frac{\frac{\partial^{2}F}{\partial x^{2}}\left(x,f\left(x\right)\right)\cdot\frac{\partial F}{\partial y}\left(x,f\left(x\right)\right)-\frac{\partial F}{\partial x}\left(x,f\left(x\right)\right)\cdot\frac{\partial^{2}F}{\partial x\partial y}\left(x,f\left(x\right)\right)}{\left[\frac{\partial F}{\partial y}\left(x,f\left(x\right)\right)\right]^{2}}
$$ but I know it is wrong. The correct answer is $$
f''\left(x\right)=-\frac{\left[\frac{\partial^{2}F}{\partial x^{2}}\left(x,f\left(x\right)\right)+\frac{\partial^{2}F}{\partial x\partial y}\left(x,f\left(x\right)\right)\cdot f'\left(x\right)\right]\cdot\frac{\partial F}{\partial y}\left(x,f\left(x\right)\right)-\frac{\partial F}{\partial x}\left(x,f\left(x\right)\right)\cdot\left[\frac{\partial^{2}F}{\partial x\partial y}\left(x,f\left(x\right)\right)+\frac{\partial^{2}F}{\partial y^{2}}\left(x,f\left(x\right)\right)\cdot f'\left(x\right)\right]}{\left[\frac{\partial F}{\partial y}\left(x,f\left(x\right)\right)\right]^{2}}
$$ and I don't understand why. Any help please?","['multivariable-calculus', 'derivatives']"
3027638,time difference between 2 geographic coordinates,"The pre-calculus question was:
If it's 10 am in City A, $35.1667^{\circ}$ S, $70.7^{\circ}$ E, what time is it in city B at $24.3^{\circ}$ S, $19.53^{\circ}$ E. I know that the time is based on longitude not latitude, so I found the difference between the 2 longitudes $70.7-19.53=51.17^{\circ}$ . Since I know that there is $1$ hour of time difference for every $15^{\circ}$ of longitude I divided $51.17 $ by $15=3.41$ hours.  Since we were told it was ok to round, I rounded this to $3$ hours = $10-3= 7$ am. Book says $6$ am. !!! So, I worked it the more accurate way of knowing that there is $4$ minutes of time difference for every $1 ^{\circ}$ of longitude. $51.17 * 4=204.68$ minutes.  This would indicate the same $3$ hours and $24$ mintues of time difference.  Technically, this would make it $6:36$ am in City B.  I don't see how I could possibly get $6$ am unless I just drop the minutes entirely and NOT round. Is there a proper way to do this problem, or is it subject to various methods of rounding/dropping?","['algebra-precalculus', 'trigonometry']"
3027664,"If $A$ is invertible and $A^n$ is diagonalizable, then $A$ is diagonalizable.","I'm attempting to understand a proof presented on this Wikipedia page: https://en.wikipedia.org/wiki/Diagonalizable_matrix The claim is as follows: Let $A$ be a matrix over $F$ . If $A$ is diagonalizable, then so is any power of it. Conversely, if $A$ is invertible, $F$ is algebraically closed, and $A^n$ is diagonalizable for some $n$ that is not an integer multiple of the characteristic of $F$ , then $A$ is diagonalizable. This is the provided proof: If $A^n$ is diagonalizable, then $A$ is annihilated by some polynomial ${\displaystyle \left(x^{n}-\lambda _{1}\right)\cdots \left(x^{n}-\lambda _{k}\right)}$ , which has no multiple root (since ${\displaystyle \lambda _{j}\neq 0})$ and is divided by the minimal polynomial of $A$ . Here are my questions: (a) Why is it clear that $A$ is annihilated by that polynomial? $A$ certainly is annihilated by $(x-\lambda_1)\cdots(x-\lambda_k)$ and $A^n$ is annihilated by $(x-\lambda_1^n)\cdots(x-\lambda_k^n)$ (as powers of matrices have powers of eigenvalues as their eigenvalues), but I don't see the connection to Wikipedia's claim. (b) What tells us that there is no multiple root? It's clear to me that $\lambda_j\neq0$ ( $A$ is invertible implies $A^n$ is invertible implies $A^n$ does not have $0$ as an eigenvalue), but why can't two of the $\lambda_j$ 's be equal? What says that we have distinct eigenvalues? (c) Any polynomial that annihilates a matrix certainly is a multiple of the minimal polynomial...but why does this tell us that $A$ is diagonalizable? (d) Earlier in the article, the following is claimed: A matrix or linear map is diagonalizable over the field $F$ if and only if its minimal polynomial is a product of distinct linear factors over $F$ . If questions (a) and (b) are resolved, I can see how this would imply (c), but why is this claim true? Here is another approach to this problem, but this one seems to be more complicated than what is presented on Wikipedia. Positive power of an invertible matrix with complex entries is diagonalizable only if the matrix itself is diagonalizable.","['proof-explanation', 'diagonalization', 'linear-algebra']"
3027679,Ideal of distinct points,"Suppose we work on $k[x_1,\ldots,x_n]$ ( $k$ is algebraically closed and char $k=0$ ). I want to prove that the ideal $$I=(x^{a_n+1}_n-x^{a_n+1}_1,\ldots,x^{a_2+1}_2-x^{a_2+1}_1)$$ with $1\leq a_1\leq\ldots\leq a_n \in \mathbb{N}$ defines $\prod_{i=2}^n (a_i+1)$ distinct points in $\mathbb{P}^{n-1}$ . I did the simplest cases ( $n=2,3$ , $a_i=2,3$ ), but I can't find a general formula per the primary decomposition of $I$ (although I'm pretty sure there exist one). Can someone help me, finding this formula or maybe giving me a reference? Thanks in advance.","['algebraic-geometry', 'commutative-algebra', 'ideals']"
3027704,"Showing $\langle a,b\mid abab^{-1}\rangle$ and $ \langle c,d \mid c^2d^2\rangle$ are isomorphic.","I computed the fundamental group of the Klein bottle in two different ways and obtained two seemingly different answers: $$
\langle a,b \mid abab^{-1}\rangle
$$ and $$
\langle c,d \mid c^2d^2\rangle.
$$ I then tried to show that these two groups are in fact the same: \begin{align*}
\langle a,b \mid abab^{-1}\rangle
=\langle ab,b^{-1} \mid abab^{-1}\rangle
&=\langle ab,b^{-1} \mid (ab)(ab)b^{-1}b^{-1}\rangle\\
&=\langle c,d \mid c^2d^2\rangle
\end{align*} Is my method for doing so valid?","['group-presentation', 'proof-verification', 'fundamental-groups', 'group-theory', 'algebraic-topology']"
3027719,Exercise about the Sturm-Liouville problems,"Under what condition on the constants $c$ and $c'$ are the boundary conditions $$f(b)=cf(a)$$ and $$f'(b)=c'f'(a)$$ self-adjoint for the operator the operator $$\mathcal{L}f=\frac{d}{dx}\left(p_0(x)\frac{df}{dx}\right)+p_2(x)f$$ on $[a,b]$ ?   ( $p_0(x),p_2(x)$ are reals) I don't know how to impose the boundary conditions to the problem, actually I don't know what to do to find that constants. Using the Lagrange identity I found $$\left\langle f|\mathcal{L}|f\right\rangle=\langle f|\mathcal{L}^{\dagger}|f\rangle+\left[p_0(x)\left(\frac{df}{dx}f^{*}(x)-f(x)\frac{df^{*}}{dx}\right)\right]_{a}^{b}$$ and this condition requires that $$\left[p_0(x)\left(\frac{df}{dx}f^{*}(x)-f(x)\frac{df^{*}}{dx}\right)\right]_{a}^{b}=0$$ so $$p_0(b)\left(\frac{df}{dx}(b)f^{*}(b)-f(b)\frac{df^{*}}{dx}(b)\right)=p_0(a)\left(\frac{df}{dx}(a)f^{*}(a)-f(a)\frac{df^{*}}{dx}(a)\right)\,.$$ The answer is $${cc'}^{*}=\frac{p_0(a)}{p_0(b)}$$ where did I go wrong?","['differential-operators', 'ordinary-differential-equations', 'sturm-liouville', 'hilbert-spaces', 'mathematical-physics']"
3027722,Limit Question: a better way to solve this limit? where $x \to -\infty$,"Hey guys so I have this limit: $$\lim_{x \to -∞} f(x) = {(x+\sqrt{x^2+2x})}$$ I solved it by multiplying numerator and denominator by $$x-\sqrt{x^2+2x}$$ and got $-1$ as my answer, but I really don't like how I solved it; any better way to solve it?",['limits']
3027776,Hodge-$\star$ operator computation on a smooth two-dimensional manifold,"Let $(x,y)$ be the local coordinates on a Riemannian manifold $M$ with $\dim(M) =2$ . Let $\star$ denote the Hodge- $\star$ operator, and let $g = g_{ij}$ denote the Riemannian metric on $M$ . I am attempting to compute the formula for the Laplace--Beltrami acting on 1-forms of $M$ . I have been stuck on computing that action of the Hodge- $\star$ operator on $dx$ and $dy$ , and this is what I would like help with. We know: $\star(1) = \sqrt{\det(g)} dx \wedge dy$ and $\star(dx \wedge dy) = \dfrac{1}{\sqrt{\det(g)}}$ . If the metric is simply $\delta_{ij}$ , then we know that $\star dx$ and $\star dy = -dx$ , but I am interested in the case when the metric $g_{ij} \neq \delta_{ij}$ . I would appreciate any help with this, and if you need any further details, please let me know. I have been aware of the following, but has been of little or no avail: \begin{eqnarray*}
dx \wedge \star dx &=& \sqrt{\det(g_{ij})} g^{11} dx \wedge dy,\\
dy \wedge \star dx &=& \sqrt{\det(g_{ij})} g^{12} dy \wedge dx
\end{eqnarray*} From this, it is claimed that we deduce: $$\star dx = \sqrt{\det(g_{ij})}(g^{11} dy - g^{12}dx).$$ This is not clear.","['hodge-theory', 'laplacian', 'riemannian-geometry', 'differential-geometry']"
3027801,Complex Borel Measure and Bounded Variation Functions,"3.29 Theorem in Folland states that: If $\mu$ is complex Borel measure on $\mathbb{R}$ and $F(x)=\mu(-\infty,x])$ , then $F \in NBV$ . Conversely if $F \in NBV$ , there is a unique complex Borel measure $\mu_F$ such that $F(x)=\mu(-\infty,x])$ .
NBV={F is of Bounded Variation: F is right-continuous and $F(-\infty)=0$ }. Now all, of sudden I am confused/completely lost.  My professor writes that: If $F(x)= \chi_{[a, b)}$ , then it is in BV and right continuous so it is in NBV?
and $u_F= \delta_a-\delta_b$ .  I have no idea how $u_F= \delta_a -\delta_b$ .  How was this formulated/come up with? I have no idea how $u_F$ was determined
Also I'm not exactly sure what is meant by $\delta_a$ and - $\delta_b$ Does Dirac measure in this case mean, $\delta_a$ mean $$
\left\{ \begin{array}{c@{,\quad}l} 1 & x=a \\ 0 & x \neq a. \end{array}\right.
$$ $\delta_b$ mean $$
\left\{ \begin{array}{c@{,\quad}l} 1 & x=b \\ 0 & x \neq b. \end{array}\right.
$$ ? Or is this wrong. Why then is $\mu_F=\delta_a- \delta_b$ ? I'm very anxious why I don't understand how this was derived/ why it is true. Like wise, my professor writes that 
if $F(x)= \arctan(x)$ , for $x>0$ , $0$ otherwise
then $F \in$ NBV.
and $d\mu_F= \frac{1}{1+x^2} \chi_{x>0} dm$ . (dm meaning respect to Lebesgue measure).
Then how do I get $\mu_F$ ?
I'm honestly not sure why the expression for $d\mu_F$ is true.  Now I'm very anxious why I'm not understanding these formulations.  Any help would be much appreciated.","['measure-theory', 'analysis', 'bounded-variation', 'real-analysis', 'probability-theory']"
3027839,"Partial derivative of a two variables function, one of which dependent on the other","I found this exercise on the book of multivariable calculus from which I'm studying: ""Find the partial derivative $\frac{\partial{z}}{\partial{x}}$ and the total derivative $\frac{\text{d}z}{\text{d}x}$ of $z(x,y)=e^{xy}$ where $y=\phi(x)$ ."" Now, this to me looks like a function of a single variable $f:\mathbb{R}\to\mathbb{R}$ and so in this case the partial derivative of $f$ with respect to $x$ and total derivative would be equivalent; in particular, I end up with something like: $$\frac{\text{d}z}{\text{d}x}=e^{xy}(\phi(x)+x\phi'(x))$$ In the solution, while the result for the total derivative is the same as mine, the partial derivative of $f$ with respect to $x$ is written as follows: $$\frac{\partial{z}}{\partial{x}}=ye^{xy}$$ Why is this the case?
Since the partial derivative of $f$ with respect to $x$ shows the incremental behaviour of the function as $x$ changes, shouldn't I account for the presence of $x$ in the functional representation of $y$ while computing the derivative with respect to $x$ ? Sorry in advance for the super basic question :)","['partial-derivative', 'multivariable-calculus', 'derivatives']"
3027865,Showing a sequence of functions $f_n$ does not converge uniformly to $f$ on an interval.,"Suppose for each $n \in \mathbb{N}$ we have a function $f_n:[0,1] \to [0,1]$ by $f_n(x)=nx$ on the interval $x \in [0,\frac{1}{n}]$ and $1$ if $x \in (\frac{1}{n},1]$ , and define $f=\lim_{n \to \infty} f_n$ . I want to show that for any Lebesgue measurable $B \subseteq [0,1]$ with Lebesgue measure $\lambda(B)=0$ that the functions $f_n$ do not converge to $f$ uniformly on $[0,1] \backslash B$ . Now clearly we have the the limit $f$ is equal to $0$ at $x=0$ and is equal to $1$ elsewhere, but I am struggling to figure out how to implement the fact that we remove the zero measure interval $B$ . Firstly my thought was to use the uniform convergence theorem, which would work with showing that the functions $f_n$ do not converge uniformly to $f$ as each of the functions $f_n$ is continuous we can use the uniform limit theorem to show that $f_n$ does not converge to $f$ . I am wondering whether there is a simple result that I am missing that ensures this transfers to the same sort of result when we take away a set of measure $0$ , for example does continuity of each $f_n$ still hold in this case in which I can still apply the theorem? Any insight would be much appreciated thanks :)","['measure-theory', 'lebesgue-measure']"
3027877,Analogue to the beta-binomial distribution for sampling without replacement?,"The beta-binomial distribution characterizes the number of successes in $n$ trials, but where the probability of success at each trial is unknown or random. However, suppose that you had finite populations and required that samples occurred without replacement (hypergeometric distribution). Is there an analogue to the beta-binomial distribution which characterizes sampling without replacement from a population of $n$ items, where $b$ are labelled black and $w$ are labelled white ( $n = b + w$ ), but where you do not precisely know what the values of $b$ and $w$ are?","['statistics', 'binomial-distribution', 'beta-function', 'probability-theory', 'probability']"
3027891,"When I'm given $\sin(x)$, what goes inside of the $x$? [duplicate]","This question already has an answer here : Do you use degrees or radians for trig functions? (1 answer) Closed 5 years ago . I don't know if I'm just randomly blanking or if I never really knew and have just been going with the flow, but I'm not sure what x represents. 
In early high school they were degrees, eg. $\sin(30)$ which equaled $0.5$ .
Later on we learned about radians and $\pi$ , and how $\sin {\pi \over 3}$ was equal to $\sqrt 3 \over 2$ . Now I'm in Uni and I'm discovering that I maybe don't know trigonometry as well as I should. For example, when doing the squeeze theorem, and I'm asked to find the limit of $\sin(n) \over n$ , what is the $n$ ? Is it in radians? degrees? It's for graphing so what should I visualize? $n$ as just a $x$ value to try and find any $y$ ??","['notation', 'calculus', 'definition', 'trigonometry']"
3027908,Application of Rouché's Theorem. Show polynomial has exactly one root in each quadrant.,"Show that the complex polynomial given by $z^4+2z^2-z+1$ has exactly one root in each quadrant. I know by the fundamental theorem of Algebra, that the polynomial has exactly four roots. Now, to show it has exactly one root in each quadrant, it suffices to show that there are two non-real roots in the open right and left half planes, since zeros of polynomials come in conjugate pairs, and they're just the reflection about the real axis in the complex plane. I think I have to apply Rouché's theorem and compare $z^4+2z^2-z+1$ to a nice function, but I am not immediately sure what that function may be. Any help would be much appreciated. Thanks in advance!",['complex-analysis']
3027967,Convergence of a series given properties on uniformly bounded functions,"I have the following problem from ""Bollobas, Linear analysis. An introductory course"" Let $\phi_n:[0,1]\to\mathbb{R}^+$ $(n=1,2,\dots)$ be uniformly bounded continuous function such that $$\int_{0}^1\phi_n(x)dx\geq c$$ for some $c>0$ . Suppose $c_n\geq 0$ , $(n=1,2,\dots)$ and $$\sum_{n\geq 1}c_n\phi_n(x)<\infty$$ for every $x\in[0,1]$ . Prove that $$\sum_{n\geq 1}c_n<\infty$$ I don't know how to proceed. Any hints will be useful ! Thanks in advance",['functional-analysis']
3027996,"integrate $F(x)$: NO complex analysis, NO multivariable calculus","Suppose I have an elementary function $F(x)$ for which $\int_{-\infty}^\infty F(x) \, \text{d}x $ has an elementary value. Here 'elementary value' means anything generated by $0,1,+,-,\div,\times,\exp,\sin$ . Suppose, indeed, I can compute this value by means of complex contours or multivariable calculus — the latter being involved, say, in Feynman's trick or in the Fourier transform. Can it be proved that I could have given a proof that the integral has that exact value, by 'single-variable methods' alone? That is to say, without differentiating or integrating anything with two real variables $x,y$ ? Will it suffice to work in the language of single-variable calculus? I don't profess to know any model theory, so do help me to formulate the question more precisely. I'm astounded to learn that for $F(x)=\frac{\sin(x)}{x}$ , there are such methods: Evaluating the integral $\int_0^\infty \frac{\sin x} x \ dx = \frac \pi 2$ ? But a general result would be all the more fascinating.","['integration', 'elementary-functions', 'improper-integrals']"
3028013,$\lim_{x\to 0^+} (\sin x)^ {\tan x}$,"I have stumbled on this question in one of my problem sets from Cal I and I'm not sure how to proceed after the last step. $$\lim_{x\to 0^+} (\sin x)^ {\tan x}$$ // Applying exponential rule $$x=e^{\ln(x)}$$ $$\lim_{x\to 0^+} exp[\,\ln((\sin x)^ {\tan x})\,]$$ // Using natural logarithm property to bring the exponent to the front $$\lim_{x\to 0^+} exp[\,(\tan x)\ln(\sin x)\,]$$ // Using an algebra trick where : $$x= \frac{1}{\frac{1}{x}}$$ $$\lim_{x\to 0^+} exp\left[\,\frac{\ln(\sin x)}{\frac{1}{\tan x}}\,\right]$$ // After this step, we were taught to check for Hospital's rule, however in this case when you plug the value $0$ in the numerator, you get $\ln(\sin 0)$ which is equal to $\ln(0)$ . This is the part that is confusing me since $\ln(0)$ is undefined. // Could someone please explain to me why  this whole limit is equal to $1$ ? Does it have to do with the fact that $x$ is approaching $0$ from the right side?",['limits']
3028019,Seeing that $\lim_{x \to \infty} \sum (-x)^n/n! = 0$,Is there any way to see directly from the power series that $$\lim_{x \to \infty} \sum_{n=0}^\infty \frac{(-x)^n}{n!} = 0$$ ?  I realize that $\displaystyle{\lim_{x \to \infty} e^{-x} = 0}$ .  That's not what I'm asking.,"['power-series', 'limits', 'calculus', 'sequences-and-series']"
3028036,"If I flip a coin $100$ times, what is the probability that I have a stretch of $30$ coinflips where at least $20$ are heads?","CONTEXT: Was wondering if I play $100$ games, how likely is it that I will have a stretch of $30$ games where I think I'm good because I have a $67\%$ winrate but I actually just have a $50\%$ winrate (and am getting lucky). I've done calculations to find out the odds of an individual stretch of $30$ coinflips having at least $20$ heads is roughly $5\%$ ( $0.04937$ ). My initial guess was that you can fit $70$ stretches of $30$ inside of $100$ coinflips, so you could do $1-0.95^{70} = 97\%$ . But this is wrong because overlapping stretches of $30$ have linked probabilities (i.e. if coinflips $1$ - $30$ have $30\%$ heads, it is impossible for coinflips $5$ - $35$ to have $67\%$ heads). If anyone is aware of a general formula for this (for this example $N=100$ , $n=30$ , $x=20$ , $p_i=0.5$ ), that would be great. Thanks.","['statistics', 'probability']"
3028046,Proof that $\cos(2\theta) = \cos^2\theta-\sin^2\theta$ by showing equivalence of derivatives,"It can be shown using trig identities that $\cos(2\theta) = \cos^2\theta-\sin^2\theta$ . But if we let $f(x) = \sin(2x)$ , we can differentiate two ways: 1) $$f(x) = \sin(2x) \rightarrow f(x) = 2\sin(x)\cos(x)$$ Differentiating using the product rule we see that : $$f^{'}(x) = 2[\cos(x)\cos(x)-\sin(x)\sin(x)] = 2[\cos^2(x)-\sin^2(x)]$$ 2) If we differentiate $f(x)$ as is, then : $$\frac{d}{dx}f(x) = 2\cos(2x) $$ Therefore: $2\cos(2x) = 2[\cos^2(x) - \sin^2(x)] \rightarrow \cos(2x) = \cos^2(x) -\sin^2(x)$ Is this a viable proof? Thanks in Advance!","['trigonometry', 'proof-verification', 'derivatives', 'proof-writing']"
3028105,Holomorphism vs Smoothness,"I want to understand the relation between Holomorphism and Smoothness. I want to elaborate the question as there are some underlying intricacies involved in the definitions: Smooth: A function is smooth if it is infinitely differentiable at every point of its domain. ( I have mostly heard this definition when speaking of Real functions) Holomorphism: A function is holomorphic if the function is differentiable at every point in the neighbourhood. (I have never heard this term when reading Real analysis) Analytic: A function is analytic if its power series representation equals the value of the function at that point. I know the subtle difference
1) Smoothness does not imply Analyticity for Real Analysis
2) Holomorphism implies Analyticity for Complex Analysis I want to know if Holomorphism and Smoothness are one and the same thing. Is it that they are just two different notions where one is used in Complex Analysis and the other in Real Analysis.","['complex-analysis', 'differential-topology', 'real-analysis']"
3028125,Volume between cone and sphere of radius $\sqrt2$ with surface integral,"Consider the cone $z^2=x^2+y^2$ between $z=0$ and $z=1$ . Find the volume of the region above this cone and inside the sphere of radius $\sqrt2$ centered at the origin that encloses the cone. The straightforward approach to this problem would have been a triple integral in spherical coordinates, but for practice I tried using the cone as a surface and using a surface integral to find the volume between the cone and the sphere. I first parameterized the surface using cylindrical coordinates $x=r\cos\theta$ , $y=r\sin\theta$ , $z=r$ (since $z^2=x^2+y^2$ ), and then found the intersection points using the equations $z=r$ and $r^2+z^2=2$ : $$2z^2=2\Rightarrow z=1\Rightarrow r=1$$ Now that the bounds of integration have been found I used the function $z=\sqrt{2-r^2}$ as the function to integrate and set up my surface integral as: $$\iint_S \sqrt{2-r^2}\Vert\vec{r_r}\times\vec{r_\theta}\Vert\,\text{d}S$$ I then computed the cross product, for $\vec{r}(r,\theta)=\left<r\cos\theta,r\sin\theta,r\right>$ : $$\begin{vmatrix}
\hat{\imath}&\hat{\jmath}&\hat{k}\\
\cos\theta&\sin\theta&1\\
-r\sin\theta&r\cos\theta&0
\end{vmatrix}=\hat{\imath}(-r\cos\theta)-\hat{\jmath}(-r\sin\theta)+\hat{k}(r\cos^2\theta+r\sin^2\theta)$$ So the surface integral becomes $$\int_0^{2\pi}\int_0^1\sqrt{\left(2-r^2\right)\left(r^2\cos^2\theta+r^2\sin^2\theta+r^2\right)}\,\text dr\,\text d\theta$$ $$=\int_0^{2\pi}\int_0^1\sqrt{\left(2-r^2\right)r^2\left(\cos^2\theta+\sin^2\theta+1\right)}\,\text dr\,\text d\theta$$ $$=\int_0^{2\pi}\int_0^1\sqrt{2r^2(2-r^2)}\,\text dr\text d\theta$$ $$=2\sqrt2\pi\int_0^1r\sqrt{2-r^2}\,\text dr$$ Using a $u$ -substitution of $u=2-r^2$ : $$\sqrt2\pi\int_1^2
\sqrt{u}\,\text du=\sqrt2\pi\left.\left(\frac{2u\sqrt u}{3}\right)\right|_1^2=\sqrt2\pi\left(\frac{4\sqrt2-2}{3}\right)$$ $$=\frac{2\pi}{3}\left(4-\sqrt2\right)$$ However, the answer given in the answer key says that the volume is $\frac{4\pi}{3}(\sqrt2-1)$ , so I would like to know why my answer is incorrect, whether that be a computational mistake or faulty reasoning as to why a surface integral would work here to find the volume. EDIT: Here is the posted solution:","['multivariable-calculus', 'calculus', 'surface-integrals']"
3028167,If $x$ is a set then $\cap x$ is a set,"Consider the following problem: (*) If $A$ is a non-empty set, then $\cap A$ is a set. But I don't think we need the hypothesis "" $A$ is non-empty"". I can simply write $$\{x \in A \mid \forall y (y \in A ) \rightarrow (x \in y)\}$$ This is a set by the separation axiom and it is the intersection set $\cap A$ , isn't it? What did I do wrong?","['elementary-set-theory', 'logic']"
3028215,"Why are open sets denoted $U$, $G$, and measurable sets $E$?","Why are open sets usually denoted by $U$ ?
Is there a reference about this?
Sometimes open set uses the letter $G$ , such as $G_{\delta} $ set.
I also wonder the meaning of $G$ . Additional question: Why do we use or who first used $E$ to denote a subset in measure theory?","['notation', 'general-topology', 'math-history', 'measure-theory']"
3028227,Least and most significant bit calculation using bitwise operations,"I am working on a project and I need to calculate the least significant bit (LSB) and most significant bit (MSB) of integers. Suppose $x$ is an $n$ -bit unsigned integer ( $n=16, 32$ or $64$ ). We know that $y=x \ \& \ ($ ~ $x+1)$ clears all the bits of $x$ except for the LSB. This is lightning fast, just three operations. Is there something similar for the MSB? What is the fastest way to compute it?","['binary', 'discrete-mathematics']"
3028258,"Plotting points on a halfcircle, given diameter and facing direction.","I know the coordinates of point $1$ and $2$ and some radius $r$ at a halfcircle with centerpoint point $1$ , with the gap of the halfcircle pointing towards point $2$ . How do I compute the (lets say $10$ ) points that the halfcircle contains of? Also how do I compute the intersecting point between a line segment following the halfcircle and a line segment lying horizontally towards point $1$ , at point $2$ . (radius $r$ , ( $x1,y1$ ), ( $x2,y2$ ) are known) See below for an example","['euclidean-geometry', 'circles', 'geometry', 'polygons', 'trigonometry']"
3028263,Connected topologies on $\mathbb{R}$ strictly between the usual topology and the lower-limit topology,"It is well-known that the usual order/metric topology on $\mathbb{R}$ is connected, and the lower-limit topology is not connected (it is even totally disconnected). We also know that the lower-limit topology is strictly finer than the usual topology. Are there connected topologies on $\mathbb{R}$ strictly between these two? (That is, is there is a connected topology on $\mathbb{R}$ which is strictly finer than the usual topology, but coarser than the lower limit topology?) I know that given any lower-limit basic open set $[a,b)$ (for $a < b$ ) the topology generated by the subbase consisting of $[a,b)$ and all of the usual open sets is not connected (because $[a,+\infty) = [a,b) \cup ( \frac{a+b}{2} , + \infty )$ and $\mathbb{R} \setminus [a,+\infty) = (-\infty , a )$ are both open in this topology). But perhaps there are more complicated lower-limit-open sets that can be added to yield a connected topology. Definitions A topological space $X$ is connected if the only subsets of $X$ that are clopen (closed and open) are $\emptyset$ and $X$ . The lower-limit topology on $\mathbb{R}$ is the topology generated by the base $\{ [a,b) : a,b \in \mathbb{R} , a < b \}$ .","['sorgenfrey-line', 'general-topology']"
3028341,Geodesics and a general pregeodesic equation,"Let $(M,g)$ be a Riemannian manifold, and let $\nabla$ denote the Levi-Civita connection.  Then we say a smooth curve $\gamma:J\to M, t\mapsto\gamma(t)$ is a geodesic if $$D_t\gamma'=0.$$ We say a smooth curve $\hat{\gamma}:I\to M, s\mapsto\hat{\gamma}(s)$ is a pregeodesic if there exists a diffeomorphism $\phi:J\to I$ such that $\gamma:=\hat{\gamma}\circ\phi$ is a geodesic for some open interval $J\subseteq\mathbb{R}$ . Let's now turn to the local representation of the above, that is, suppose $(U,x^j)$ are coordinates on $M$ with Christoffel symbols $\Gamma_{ij}^k$ .  Then then geodesic equation reads $$\ddot{\gamma}^k+\dot{\gamma}^i\dot{\gamma}^j\Gamma_{ij}^k=0.$$ Then a fairly straightforward application of the chain rule yields the result: A curve $\hat{\gamma}:I\to U$ is a pregeodesic if and only if $$\frac{d^2\hat{\gamma}^k}{ds^2}+\frac{d\hat{\gamma}^i}{ds}\frac{d\hat{\gamma}^j}{ds}\Gamma_{ij}^k=f(s)\frac{d\hat{\gamma}^k}{ds},\qquad (*)$$ for some continuous $f:I\to\mathbb{R}$ .  Indeed (for the relevant direction), suppose $\gamma=\hat{\gamma}\circ\phi$ is a geodesic for some diffeomorphism $\phi:J\to I, s=\phi(t)$ .  Then $\hat{\gamma}$ satisfies the above system $(*)$ with $$f(\phi(t))=-\frac{\frac{d^2\phi}{dt^2}}{\left(\frac{d\phi}{dt}\right)^2}.$$ This leads to my question: I've come across in the literature that $(*)$ is equivalent to the equation $$\frac{d^2\hat{\gamma}^k}{ds^2}+\frac{d\hat{\gamma}^i}{ds}\frac{d\hat{\gamma}^j}{ds}\Gamma_{ij}^k=F(\gamma')\frac{d\hat{\gamma}^k}{ds},\qquad (**)$$ for some continuous $F:TU\to\mathbb{R}$ which is homogeneous of degree $1$ in the tangent variable. I don't understand what this function $F$ is.  Clearly, any curve $\hat{\gamma}$ satisfying $(**)$ is a pregeodesic.  However, the result is saying that there exists some $F:TU\to\mathbb{R}$ with the above properties so that all pregeodesics satisfy $(**)$ with that specific $F$ . Now, the function $f(s)$ depends on the diffeomorphism $\phi$ , which in turn depends on the geodesic $\gamma$ with starting point $(x,\xi)\in TU$ .  There is some homogeneity of geodesics when dealing with the initial condition, so this certainly seems reasonable, but I can't piece all of this together in coherent form. I think this may actually be related to general sprays, and this $F$ is a reformulation of the Liouville vector field associated to the geodesic spray, but this is a bit outside my field (at the moment). Any help or references would be appreciated.","['finsler-geometry', 'geodesic', 'riemannian-geometry', 'differential-geometry']"
3028345,"A simple finite combinatorial sum I found, that seems to work, would have good reasons to work, but I can't find in the literature.","I was doing a consistency check for some calculations I'm performing for my master thesis (roughly - about a problem in discrete bayesian model selection) - and it turns out that my choice of priors is only consistent if this identity is true: $$\sum_{k=0}^{N}\left[ \binom{k+j}{j}\binom{N-k+j}{j}\right] = \binom{N+2j+1}{2j+1}$$ Now, this seems to work for small numbers, but I searched for it a lot in the literature and I can't find it.(I have a physics background so probably my knowledge of proper ""literature"" is the problem here). Neither I can demonstrate it!
Has anyone of you seen this before? Can this be rewritten equivalently in some more commonly seen way? Can it be proven right...or wrong?
Thanks in advance! :)","['summation', 'binomial-coefficients', 'combinatorics']"
3028384,Chain rule when applying L'Hopital's rule,"I have a very basic question regarding derivation function: $$f(\omega(t)) = \frac{2 +x(t)\cdot \frac{d\omega(t)}{dt}}{\omega(t)} $$ when I check for $$= \lim_{\omega(t)\to\ 0}\frac{2 +x(t)\cdot\frac{d\omega(t)}{dt}}{\omega(t)} = \frac{2}{0} $$ now if we apply L'Hopital's rule 
we get $$= \lim_{\omega(t)\to\ 0}(\frac{\frac{d(2)}{d\omega(t)} +[\frac{d(x(t))}{d\omega(t)}\cdot \frac{d\omega(t)}{dt} + \frac{d(\frac{\omega(t)}{dt})}{d\omega(t)}\cdot \frac{dx(t)}{dt}]}{\frac{d\omega(t)}{d\omega(t)}} )$$ So here is my question this $$ \frac{d(x(t))}{d\omega(t)}\cdot \frac{d\omega(t)}{dt}$$ should become $$ \frac{dx(t)}{dt}$$ according to the chain rule , or am I mathematically wrong. Please also let me know if I have done something mathematically wrong during the derivation.","['partial-derivative', 'derivatives', 'limits-without-lhopital', 'chain-rule']"
3028400,Why is the surface area of a sphere equal to $4\pi r^2$ [duplicate],"This question already has answers here : Can the Surface Area of a Sphere be found without using Integration? (4 answers) Closed 5 years ago . I have absolutely no idea where that formula comes from, considering the fact that I am a fifteen year old. According to me, one way to think of it is to arrange $4$ circles having radius equal to that of the sphere on it,  but the curvatures are different so that is not possible. Could someone please explain where the formula comes from? Note: Please remember that I am fifteen years old. P. S. Let me know if there are any other tags for this question except '3d' .","['area', 'geometry', '3d']"
3028561,Does this series converge to a rational multiple of $\pi^2$?,"If we define the sum $$S_2=\sum_{n_2=1}^\infty\frac{1}{(n_2)^2} $$ in which $n_2$ are products of an even number of prime factors, together with 1, so $n_2=1,4,6,...,15,16,21,22,...,24,$ etc., the sum seems to be a rational multiple of $\pi^2$ . Of course it converges by comparison to $\zeta(2).$ The first $k=9,997,745$ of these (including 1) sum to approximately $\frac{7\pi^2}{60}$ and the ratio $S_k/(7\pi^2/60)=0.999999978...$ (there are 7 nines in this decimal). My unscientific test is that if Mathematica rounds to one it bears a second look. In this case I looked at various proofs of the Basel problem and connections with 2-primes $pq$ to see if there was a way of showing this. Is this already known to be true? If not, can someone show it? Also any comments on the likelihood of the relation given the approximation are welcome. How much numerical similarity is enough to guess in this way? I am still working on this, and if I find a proof or a reference I will post it.",['sequences-and-series']
3028611,"Can the median, angle bisector and the altitude of a triangle intersect to form an equilateral triangle?","On a sheet of paper, a blue triangle is drawn. A median, a bisector and an altitude of this triangle (not necessarily from three distinct vertices) are drawn red. The triangle dissects into several parts. Is it possible that one of these parts is an equilateral triangle with red sides? I tried to get the angles of the triangle formed, but failed because I was not able to find the angle formed by the median.",['geometry']
3028661,"If a product of polynomials converges, does some product of their zeros also converge?","Suppose $\{p_k\}$ is a sequence of polynomials with $p_k(0)=1$ .  Let $a_1,a_2,\ldots$ be an enumeration of all of the zeros of the $p_k$ .  Suppose that $$\prod_{k=1}^\infty p_k(z)$$ converges uniformly on compact subsets of $\mathbb{C}$ .  Is there some permutation $\sigma:\mathbb{N}\to\mathbb{N}$ such that $$f_\sigma (z)=\prod_{k=1}^\infty \left(1-\frac{z}{a_{\sigma(k)}}\right)$$ converges uniformly on compact subsets of $\mathbb{C}$ ? This is a follow-up to Factoring a convergent infinite product of polynomials. , in which an example of such $\{p_k\}$ is given along with a permutation $\sigma$ for which the product $f_\sigma (z)$ does $\underline{\text{not converge}}$ .","['complex-analysis', 'infinite-product']"
3028668,Find $\lim_{n\to \infty}((n+1)!)^{\frac{1}{n+1}}-((n)!)^{\frac{1}{n}}.$ [duplicate],"This question already has an answer here : Limit of the sequence $a_n=\sqrt[n+1]{(n+1)!}-\sqrt[n]{n!}$ (1 answer) Closed 5 years ago . Find $\lim_{n\to
 \infty}((n+1)!)^{\frac{1}{n+1}}-((n)!)^{\frac{1}{n}}.$ We need to deal the limit $\lim_{n\to \infty} \frac{\log(1)+\log(2)+...+\log(n)}{n}$ . We know that $\lim_{n\to \infty} \log(n)=\infty \implies \lim_{n\to \infty} \frac{\log(1)+\log(2)+...+\log(n)}{n}=\infty$ (since, By Cauchy's first theorem on limit). Hence we get $\infty-\infty$ . How do I show that there exists finite limit?","['limits', 'sequences-and-series', 'real-analysis']"
3028680,Multiplication of a vector by an orthogonal matrix,"I have a question, consider $V$ an orthogonal matrix, and $u$ and $z$ are vectors, and W is a matrix does : $V'u = W V'z  \implies   u = W z$ ? I want to get rid of the orthogonal matrix $V'$ , my intuition says that I can, but I don't know which property of the orthogonal matrices will help me to do say.
Thank you in advance.","['matrices', 'linear-algebra', 'products']"
3028709,Number of one-one function from sets $A$ to $B$.,"Let $A=\{1,2,3,4,5\}$ and $B=\{0,1,2,3,4,5\}$ . Number of one-one function from $A$ to $B$ such that $f(1) \neq 0$ and $f(i)\neq i$ for $i={1,2,3,4,5}$ is _______ . So I know one one function means for each $x$ there will be only one $y$ . But here if I take for $1$ from $A$ then total number of functions $=480$ as ${{4_C}_1}×{{5_P}_4}$ But for every for every other $i$ from $A$ it will be ${{5_C}_1}×{{5_P}_4}$ so total cases will be $480+2400=2880$ . But I don't know how to further proceed.","['permutations', 'inclusion-exclusion', 'functions', 'combinatorics']"
3028750,"Solution $y(x)$ for $\sin(x) = \int_0^{2\pi} \max(y(t), y(x+t)) dt$","I've been banging my head against a wall for a few weeks to find a feasible solution for $y(x)$ . $$\sin(x) = \int_0^{2\pi} \max(y(t), y(x+t)) dt$$ I don't think there is an unique solution, but I will accept any solution. I've tried various numerical minimization methods, convolution, guess the solution, etc, but nothing seems to work. Does anybody have any ideas?","['integration', 'integral-equations', 'analysis']"
3028756,"Show that $f(x,y,z)=x^2-y^2z$ is irreducible in $\mathbb{C}[x,y,z]$.","Let $p\in\mathbb{C}[x,y,z]$ be defined by $p(x,y,z)=x^2-y^2z$ . Goal: Prove that $p$ is irreducible. Let $I\subset\mathbb{C}[x,y,z]$ be the ideal defined by $$I:=(p).$$ My approach is to show that $$\mathbb{C}[x,y,z]/I,$$ is an integral domain and, hence, $I$ prime ideal or equivalently here, $p$ is irreducible. Let us consider a ring homomorphism $$\varphi:\mathbb{C}[x,y,z]\to\mathbb{C}[t_1,t_2]$$ $$\begin{cases}x\mapsto t_1^2t_2 \\
y\mapsto t_1^2 \\
z \mapsto t_2^2.
\end{cases}$$ Notice that, since $\varphi$ is a ring homomorphism, $$\varphi(p)=\varphi(x^2-y^2z)=\varphi(x^2)-\varphi(y^2)\varphi(z)=t_1^4t_2^2-t_1^4t_2^2=0.$$ Here is a claim, which I think is true (it atleast feels like it), but I don't know how to prove it. My argument relies on this: Claim: Any polynomial $f\in\mathbb{C}[x,y,z]$ can be written as $$f(x,y,z)=f_0(y,z)+xf_1(y,z)+(x^2-y^2z)g(x,y,z).$$ I read on another link that, for any $f(x,y)\in \mathbb{C}[x,y]$ , we can write $$f(x,y)=f_0(x)+yf_1(x)+(x^3-y^2)g(x,y).$$ My approach is inspired by the above identity. $$\text{ }$$ It feels like my claim should be true, since $f_0(y,z)$ takes care of all expressions of the form $\sum_{k=0}^m\sum_{j=0}^nx^0y^jz^k$ and $xf_1(y,z)$ takes care of everything of the form $\sum_{k=0}^m\sum_{j=0}^nx^1y^jz^k$ . Lastly, we have $x^2g(x,y,z)$ which feels like it should take care of any polynomial $$\sum_{k=0}^m\sum_{j=0}^n\sum_{l=2}^o x^ly^jz^k\quad (o \text{ was quite ugly to use in the summation, but anyway)},$$ so I don't really understand what's so special  with the $$-y^2zg(x,y,z)-\text{part},$$ it feels like it doesn't really contribute, or restrict, the polynomial $f$ in any way. So it feels like you could do a similar construction for any polynomial. But probably not. $\text{ }$ My questions now is: Is my claim true? If it is, could you please tell me why? Continuing on the actual problem: Thus, applying $\varphi$ on $f\in\ker\varphi$ gives us $$\varphi(f)=\varphi(f_0)+\varphi(x)\varphi(f_1)+\varphi(x^2-y^2z)\varphi(g)$$ $$=f_0(t_1^2,t_2^2)+t_1^2t_2f_1(t_1^2,t_2^2)=0$$ $$\Rightarrow f_0=f_1=0,$$ Where the last implication holds since $f_0(t_1^2,t_2^2)$ is of even degree while $t_1^2t_2f_1(t_1^2,t_2^2)$ is of odd degree. Hence the only case the sum can be $0$ is if $f_0$ and $f_1$ are identically $0$ . This shows us that $\ker\varphi=I$ . By the first isomorphism theorem, we have $$\mathbb{C}[x,y,z]/I\cong \operatorname{im}(\varphi).$$ But this shows us that $\mathbb{C}[x,y,z]/I$ is a subring of the integral domain $\mathbb{C}[t_1,t_2]$ . Hence $I$ is a prime ideal, so $p$ is irreducible, which is what we wanted to prove. Questions: Does my approach work? In particular, is my claim true and if so, why? If this approach does not work, could you please help me with a better approach and solution? Thanks for your time!","['algebraic-curves', 'irreducible-polynomials', 'several-complex-variables', 'integral-domain', 'algebraic-geometry']"
3028802,An abelian variety not isogenous to a Jacobian,"In the L-functions and Modular Forms Database is an isogeny class of an abelian variety of dimension $2$ over $\mathbb F_5$ . They claim that it is principally polarizable but not the Jacobian of a curve over $\mathbb F_5$ . The two ways they suggest this is usually checked is: Show that a point count of the associated virtual curve of the abelian variety is negative. Show that there is an extension $\mathbb F_{p^d}\subset \mathbb F_{p^n}$ such that the curve has fewer points over the bigger field than over the smaller field. Neither of these hold for the example linked above. I also checked that the Weil bound for a genus $2$ curve over $\mathbb F_{p^d}$ holds for the first few virtual point counts. How are they concluding that this isogeny class doesn't contain a Jacobian? More generally, what other techniques are there that help us rule out a principally polarized abelian variety being isogenous to a Jacobian?","['algebraic-number-theory', 'abelian-varieties', 'finite-fields', 'algebraic-geometry', 'arithmetic-geometry']"
3028864,Proof verification for $\lim_{n\to\infty}(\sqrt{n^2-1} - \sqrt n) = +\infty$,"Show that: $$
\lim_{n\to\infty}\left(\sqrt{n^2-1} - \sqrt n\right) = +\infty
$$ I've started it this way. Lemma : Let $x_n$ and $y_n$ be two sequences. Claim: If: $$
\begin{cases}
&\lim_{n\to\infty} x_n =+\infty \\
&\exists N\in \Bbb N, \ \forall n >N:y_n\ge c > 0
\end{cases}
$$ Then: $$
\lim_{n\to\infty}(x_ny_n) = +\infty
$$ Proof : $\Box$ Start with definition of limit for this case: $$
\forall\varepsilon>0,\ \exists N_1\in\Bbb N: \forall n > N_1 \implies x_n >\varepsilon
$$ Also: $$
\exists N_2\in\Bbb N:\forall n>N_2 \implies y_n \ge c > 0
$$ Let: $$
N = \max\{N_1, N_2\}
$$ Then starting from this $N$ we obtain: $$
x_n\cdot y_n > c\cdot \varepsilon
$$ And we have that: $$
\forall\varepsilon>0,\ \exists N =\max\{N_1, N_2\}\in\Bbb N: \forall n > N \implies x_n y_n > c\varepsilon
$$ Thus: $$
\lim_{n\to\infty}(x_ny_n) = +\infty \ \Box
$$ Now back to the initial problem. Let: $$
z_n = \sqrt{n^2-1} - \sqrt n = \frac{n^2 - n - 1}{\sqrt{n^2 - 1} + \sqrt{n}}
$$ Define: $$
x_n = n - 1 - {1\over n} \\
y_n = \frac{n}{\sqrt{n^2 - 1} + \sqrt{n}}
$$ Obviously $y_n \ge c > 0$ for some $N$ and $n>N$ . Also $x_n \to +\infty$ , then by lemma: $$
\lim_{n\to\infty}z_n = \lim_{n\to\infty}{x_ny_n} = +\infty
$$ I know this is a bit overkill, but i wanted to use that exact lemma for the proof. Apart from that, is it valid? BTW here is a visualization for $x_n, y_n$ Update Since it is not clear where the lemma comes from here is the problem from the problem book right before the limit. Let: $$
\lim_{n\to\infty}x_n = a\ , \text{where}\ a = +\infty \ \text{or} \ a = -\infty
$$ Prove that if for all $n$ starting from some $N$ $y_n \ge c > 0$ then $$
\lim_{n\to\infty}x_ny_n = a
$$ And if for all $n$ starting from some $N$ $y_n \le c < 0$ then $$
\lim_{n\to\infty}x_ny_n = -a
$$ No other constraints are given.","['limits', 'calculus', 'proof-verification', 'epsilon-delta']"
3028868,What is the formula for pi used in the Python decimal library?,"(Don't be alarmed by the title; this is a question about mathematics, not programming.) In the documentation for the decimal module in the Python Standard Library, an example is given for computing the digits of $\pi$ to a given precision: def pi():
    """"""Compute Pi to the current precision.

    >>> print(pi())
    3.141592653589793238462643383

    """"""
    getcontext().prec += 2  # extra digits for intermediate steps
    three = Decimal(3)      # substitute ""three=3.0"" for regular floats
    lasts, t, s, n, na, d, da = 0, three, 3, 1, 0, 0, 24
    while s != lasts:
        lasts = s
        n, na = n+na, na+8
        d, da = d+da, da+32
        t = (t * n) / d
        s += t
    getcontext().prec -= 2
    return +s               # unary plus applies the new precision I was not able to find any reference for what formula or fact about $\pi$ this computation uses, hence this question. Translating from code into more typical mathematical notation, and using some calculation and observation, this amounts to a formula for $\pi$ that begins like: $$\begin{align}\pi 
&= 3+\frac{1}{8}+\frac{9}{640}+\frac{15}{7168}+\frac{35}{98304}+\frac{189}{2883584}+\frac{693}{54525952}+\frac{429}{167772160} + \dots\\
&= 3\left(1+\frac{1}{24}+\frac{1}{24}\frac{9}{80}+\frac{1}{24}\frac{9}{80}\frac{25}{168}+\frac{1}{24}\frac{9}{80}\frac{25}{168}\frac{49}{288}+\frac{1}{24}\frac{9}{80}\frac{25}{168}\frac{49}{288}\frac{81}{440}+\frac{1}{24}\frac{9}{80}\frac{25}{168}\frac{49}{288}\frac{81}{440}\frac{121}{624}+\frac{1}{24}\frac{9}{80}\frac{25}{168}\frac{49}{288}\frac{81}{440}\frac{121}{624}\frac{169}{840}+\dots\right)
\end{align}$$ or, more compactly, $$\pi = 3\left(1 + \sum_{n=1}^{\infty}\prod_{k=1}^{n}\frac{(2k-1)^2}{8k(2k+1)}\right)$$ Is this a well-known formula for $\pi$ ? How is it proved? How does it compare to other methods, in terms of how how quickly it converges, numerical stability issues, etc? At a glance I didn't see it on the Wikipedia page for List of formulae involving π or on the MathWorld page for Pi Formulas .","['computational-mathematics', 'convergence-divergence', 'pi', 'sequences-and-series']"
3028882,Upper Bound on Expected Value of $n$ i.i.d. Poisson random variables.,"Let $\{X_i \}_{i=1}^n$ be i.i.d. from a Poisson random variable with mean $\lambda$ and let $$M_n = \max_{1 \le i \le n} X_i.$$ What is a tight upper bound on $\mathbb{E}[M_n]$ ? I can prove that \begin{equation}
\mathbb{E}[M_n] \le \frac{(\lambda+1) \log n}{\log \log n} + O \left( \frac{1}{\log \log n} \right)
\end{equation} but numerically this bound is not tight. Can someone give a tighter analysis or point to a reference with one? Proof of my bound: Let $s > 0$ . Then by Jensen's inequality, $$ e^{s \mathbb{E}[M_n]} \le \mathbb{E}[e^{sM_n}] \le \sum_{i-1}^n \mathbb{E}[e^{sX_i}] = ne^{\lambda(e^s-1)}$$ from the moment generating function. Then taking the logarithm of both sides gives $$ \mathbb{E}[M_n] \le \frac{\log n}s + \frac{\lambda(e^s-1)}{s}.$$ Finally, the minimum of the function on the right hand side should be around $s = \log \log n$ which gives the bound above.","['expected-value', 'probability-distributions', 'probability']"
3028886,Sum involving binomial coefficients - generalisation of hockey stick identity? [duplicate],"This question already has answers here : Proof of the identity $2^n = \sum\limits_{k=0}^n 2^{-k} \binom{n+k}{k}$ (8 answers) Closed 5 years ago . I am trying to evaluate a sum involving binomial coefficients, and by some manipulations, I have reduced it to $$\sum_{i=0}^{n} \binom{n+i}{i} 2^{n-i}$$ where $n$ is a constant ( $n=1009$ in my particular case). (This looks like the LHS of the Hockey Stick Identity, except for the presence of the $2^{n-i}$ term. I would also be interested in further generalisation, replacing the $2$ by an arbitrary constant). To evaluate this, I attempted writing $$2^{n-i} = \sum_{k=0}^{n-i} \binom{n-i}{k}$$ which gave a more symmetric expression, but otherwise didn't seem to help much. So, given that the answer (according to Mathematica) is $4^n$ , how can this be proved?","['algebra-precalculus', 'combinatorics']"
3028901,Different answers with $\sec(x) = 2\csc(x)$,"My son and I were solving this last night and we get different answers depending on which identities we use.  The question also did specify $0 \leqslant x < 2\pi$ Here's our work: $$\sec x = 2 \csc x$$ $$\frac 1 {\cos x} = \frac 2 {\sin x}$$ cross multiply: $$2 \cos x = \sin x$$ and square both sides (I think this introduces a problem?) $$4 \cos^2 x = \sin^2 x$$ Now we used the identity $\sin^2 x + \cos^2 x = 1$ Let's replace $\sin x$ : $$4 \cos^2 x = 1 - \cos^2 x$$ $$5 \cos^2 x = 1$$ $$\cos^2 x = \frac 1 5$$ $$\cos x = ±\sqrt{\frac 1 5}$$ $$\cos^{-1}\left(±\sqrt \frac 1 5\right) = 1.10, 2.03$$ That gave us two answers within the range requested. But let's replace $\cos x$ instead: $$4 \cos^2 x = \sin^2 x$$ $$4 (1 - \sin^2 x) = \sin^2 x$$ $$4 - 4 \sin^2 x = \sin^2 x$$ $$4 = 5 \sin^2 x$$ $$\frac 4 5 = \sin^2 x$$ $$±\sqrt \frac 4 5 = \sin x$$ $$\sin^{-1}\left(±\sqrt \frac 4 5\right) = x = 1.1, -1.1$$ Two answers, but we can throw out the negative one because it is not within the range specified. Then we used the $\tan x$ identity (which is what we should have done to begin with since squaring obviously seems to introduce invalid answers): $$\tan x = \frac {\sin x} {\cos x}$$ $$2 \cos x = \sin x$$ $$2 = \sin x / \cos x$$ $$2 = \tan x$$ $$\tan^{-1} 2  = 1.1$$ So now I assume $1.1$ is the right answer.  But where did $-1.1$ and $2.03$ come from? They don't show up in the graphs: AH!  But they do show up in the squared version, which I now understand is where the extra answers came from: What is the fundamental mistake here?  How would one use the squaring method, and then at the end know which solution(s) to throw out as a side effect?",['trigonometry']
3028953,How is the Jacobian matrix computed in finite difference problems?,"I have come across many papers which reference the Jacobian when solving certain finite difference inverse problems. And I have seen many articles and textbooks which discuss the mathematical properties of the Jacobian in an abstract sense. I have also seen examples for calculating the Jacobian when the functions are known and analytic. But, amidst all this, I still have no idea how to sit down at my computer and compute a Jacobian for real data and non-analytic functions. For example, I have some predicted data vector, $\mathbf{f}$ and some model vector, $\mathbf{m}$ . The Jacobian is defined as: $$\mathbf{J}_{ij} = \frac{\partial f_i}{\partial m_j} $$ But how can this actually be computed? Note, I have come across many answers that say that you can compute them using finite differences (for example, see this answer here ). In this case, we can say: $$\mathbf{F}(\mathbf{m}) = f_1(\mathbf{m})\mathbf{i}+f_2(\mathbf{m})\mathbf{j}+f_3(\mathbf{m})\mathbf{k}+...$$ and so the Jacobian is defined via finite difference with some model perturbation: $$\mathbf{J}_{ij} = \frac{f_i(m_j+\Delta m)-f_i(m_j)}{\Delta m}$$ However, this method requires me to solve $\mathbf{F}(\mathbf{m})$ for every predicted function for every model perturbation. My particular problem involves thousands of predicted points and millions of model parameters and each function evaluation takes minutes to hours. It is not feasible to use the method suggested. Any explanation or resources are appreciated.","['mathematical-modeling', 'inverse-problems', 'jacobian', 'partial-differential-equations', 'derivatives']"
3028968,Find Minimum value of $\sqrt{58-42x}+\sqrt{149-140\sqrt{1-x^2}}$,"Find Minimum value of $$f(x)=\sqrt{58-42x}+\sqrt{149-140\sqrt{1-x^2}}$$ My try: the domain of the function is $x \in [-1 \,\,\,1]$ Differentiating and equating it to zero we get $$f'(x)=\frac{-21}{\sqrt{58-42x}}+\frac{70}{\sqrt{1-x^2}\sqrt{149-140\sqrt{1-x^2}}}=0$$ but its very tedious to find critical points here. any other approach?","['optimization', 'algebra-precalculus', 'maxima-minima', 'derivatives']"
3028974,Is a linear operator $M$ bounded given that $M^2$ is bounded?,"Proposition (?) Let $M$ be a linear map of a Banach space $X$ into itself. Then $M$ is bounded if and only if $M^2$ is bounded. If $M$ is bounded, it is not difficult to show that $M^2$ is bounded.
What about the converse? Aiming to apply Closed graph, I tried assuming that $x_n \to x$ and $Mx_n \to y$ , and showing that $Mx = y$ , but the best I was able to get from that is that, by the boundedness of $M^2$ , $$ M^2 x_n \to M^2x, \quad M^3x_n \to M^2y, $$ which does not seem very fruitful.
I've also tried assuming that $M$ is unbounded in hope of reaching a contradiction, but to no avail. I'm even not sure if the statement holds, but I can't even imagine what a counterexample might look like. Could someone give a hint on how to proceed with the proof, or present a counterexample otherwise?","['operator-theory', 'functional-analysis']"
3029096,Prove that region under graph of function is measurable,"In the measure theory book that I am studying, we consider the 'area' under (i.e. the product measure of) the graph of a function as an example of an application of Fubini's Theorem for integrals (with respect to measures). The setting: $(X,\mathcal{A}, \mu)$ is a $\sigma$ -finite measure space, $\lambda$ is Lebesgue measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ (Borel $\sigma$ -algebra), $f:X \to [0,+\infty]$ is $\mathcal{A}$ -measurable, and we are considering the region under the graph of $f$ , $E=\{(x,y)\in X \times \mathbb{R}|0\leq y < f(x)\}$ . I need to prove $E \in \mathcal{A} \times \mathcal{B}(\mathbb{R})$ . I thought to write $E=g^{-1}((0,+\infty])\cap(X \times [0,+\infty])$ where $g(x,y)=f(x)-y$ but I can't see why $g$ must be $\mathcal{A} \times \mathcal{B}(\mathbb{R})$ -measurable. Any help would be appreciated.","['measure-theory', 'graphing-functions', 'analysis']"
3029208,Help finding a combinatorial proof of ${kn \choose 2}= k{n \choose 2}+n^2{k \choose 2}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Hi I have been trying to find a way to find a combinatorial proof for ${kn \choose 2}= k{n \choose 2}+n^2{k \choose 2}$ .","['combinatorics', 'discrete-mathematics']"
3029239,"If $f(z)=z+a_2z^2+...+a_nz^n$ is injective on the unit disk, then $|a_2|≤\frac12(n-1)$","Suppose $f(z)=z+a_2z^2+...+a_nz^n$ is injective in $D:=\{z:|z|<1\}$ .  Show that $|a_2|≤(n-1)/2$ and $|a_n|≤1/n$ . Partial Solution Assume without loss of generality that $a_n\ne0$ . If $f$ is injective, then $f'(z)≠0$ in $D$ . Now, $$f'(z)=1+2a_2z+...+na_nz^{n-1}$$ By the fundamental theorem of algebra, $$f'(z)=na_n(z-r_1)...(z-r_{n-1})$$ where $r_1,...,r_{n-1}$ are the roots of $f'(z)$ , and $$f'(0)=1=na_n(-1)^nr_1r_2...r_{n-1}$$ Note that $|r_i|\geq1$ for each $i=1,...,n-1$ , hence $$|r_1r_2...r_{n-1}|\geq1$$ and, finally, $$|a_n|=\frac1{n\,|r_1r_2...r_{n-1}|}\leq\frac{1}{n}$$ What I cannot figure out, though, is how to prove that $|a_2|≤(n-1)/2$ .  I have tried similar arguments, but cannot seem to get it.  Any hints would be greatly appreciated.","['complex-analysis', 'polynomials']"
3029266,Boundary of the set of points away from manifold is a hypersurface,"(This is part of Problem 6-6 from Lee's Introduction to Smooth Manifolds textbook.) Suppose $M\subset \mathbb{R}^n$ is a compact embedded submanifold. For
  any $\epsilon>0$ , let $M_\epsilon$ be the set of all points in $\mathbb{R}^n$ whose distance from $M$ is less than $\epsilon$ . Show
  that for sufficiently small $\epsilon$ , $\partial M_\epsilon$ is a
  compact embedded hypersurface in $\mathbb{R}^n$ . I thought to use the tubular neighbourhood theorem (since we have an embedded submanifold) and showing for some sufficiently small tubular neighbourhood, maybe we can prove that the boundary of the tubular neighbourhood is an embedded $(n-1)$ -dimensional embedded manifold (and relate $\epsilon$ to the distance function in the definition of a tubular neighbourhood). However, I have no idea how to prove that (or if it's even the right approach). For reference, I'm using Lee's definition of a tubular neighbourhood. That is, $E(V)$ where $E(x,v)=x+v$ and $V=\{(x,v)\in NM : |v|<\delta(x)\}$ for positive continuous $\delta: M \rightarrow \mathbb{R}$ .","['manifolds', 'smooth-manifolds', 'differential-geometry']"
3029293,Inverse Fourier transform with a $\delta$-function integrand,"I'm self-studying math and trying to find the inverse Fourier transform of $\frac{4+w^2}{1+w^2}(4\pi * (\delta(w-2)+\delta(w+2)))$ Based on wolframalpha, the result is $32/5\sqrt{2\pi}\cos(2t)$ . But I can't even find the fourier transform of $\frac{4+w^2}{1+w^2}$ because there doesn't seem to have a Fourier transform pair in my table for $w^2$ in the numerator.","['functions', 'fourier-transform']"
3029324,Algebraic proof that $\binom{n+k-1}{k} = \sum\limits_{i=0}^k \binom{(n-1)+(k-i)-1}{k-i}$,"Prove (algebraically) that $$f_k(n) = \binom{n+k-1}{k} = \sum\limits_{i=0}^k \binom{(n-1)+(k-i)-1}{k-i} = \sum\limits_{i=0}^k f_{k-i}(n-1)$$ for $n \geq 2$ and that $f_k(1) = 1$ for all $k$ . Then, show that if $$f_k(n) = \sum\limits_{i=0}^k f_{k-i}(n-1)$$ for $n\geq 2$ and $f_k(1) = 1$ for all $k$ , then $f_k(n) = \binom{n+k-1}{k}$ . Attempting the first one: it's easy to see that $f_k(1) = 1$ for all $k$ by substitution. I'm not so sure about what to so with the summation of binomial coefficients. I'm sure there's a way to use $ \sum\limits_{i=0}^k \binom{k}{i}x^i = (x+1)^k$ , either directly or in a double-sum, but I'm not sure how to manipulate the summand into such a form. For the second one: after the first one is solved, it's trivial, since they agree for $n=1$ and if they agree for $n = N-1$ , they must agree for $n=N$ by the first identity. So the main difficulty in this problem is coming from the first part. Edit: I should also note that I can understand this identity by relating $f_k(n)$ with the number of ways to choose an ordered $n$ -tuple of numbers adding to $k$ , or equivalently the number of $k$ -degree terms in an $n$ -dimensional polynomial. However, my attempts converting that intuition into an algebraic proof haven't gone anywhere.","['induction', 'combinatorics']"
3029342,Series of reciprocal of integers,"This is a question I asked myself today... $ $ Do you know if it is possible to build a strictly-increasing sequence $(u_n)_{n\in\mathbb{N}^\star}$ of positive integers such that $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{u_n}<+\infty$ and such that for any given $0<\varepsilon<1$ , one has $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{u_n^\varepsilon}=+\infty$ ? $ $ This is looking for a Dirichlet series (with reciprocal of $u_n$ coefficients) with abscissa of convergence $\sigma=1$ and that has a finite limit at $s=1$ , does that exist ? It would mean that the corresponding L-function (if the series was extendable around $s=1$ ) would have no pole at $s=1$ . This is tough because the L-function would not be in the Selberg class, and those are hard to study...","['l-functions', 'sequences-and-series']"
3029404,Axiom of Choice implies Well-Ordering Principle,"Axiom of Choice implies Well-Ordering Principle. My textbook only presents the construction of function $F$ and does not provide details on how to define such well-ordering. I try to fill in the remaining blanks in my attempt. Does it look fine or contain logical flaws/gaps? Thank you for your help! My attempt: Let $A$ be a set. By Axiom of Choice, there is a choice function $f:\mathcal{P}(A) \setminus \{\emptyset\} \to A$ such that $f(X) \in X$ for all $X \in \mathcal{P}(A) \setminus \{\emptyset\}$ . Let $V$ be the class of all sets. We define a function $G:V \to V$ as follows: $$G(x)=\begin{cases}
f(A \setminus {\rm ran} (x))&\text{if }x\text{ is a function and }A \setminus {\rm ran} (x) \neq \emptyset\\A&\text{otherwise}\end{cases}$$ By Transfinite Recursion Theorem, there is a function $F: {\rm Ord} \to V$ such that $F(\alpha)=G(F \restriction \alpha)$ for all $\alpha \in {\rm Ord}$ . There do not exist $\alpha_1<\alpha_2 \in {\rm Ord}$ such that $F(\alpha_1)=F(\alpha_2)=a$ for some $a\in A$ If not, $F(\alpha_1)=F(\alpha_2)=a$ for some $a\in A$ . We have $F(\alpha_2)=G(F \restriction \alpha_2)$ . There are only two cases. $F(\alpha_2)=A \neq a =F (\alpha_1)$ $F(\alpha_2)=f(A \setminus {\rm ran} (F \restriction \alpha_2))$ $f(A \setminus {\rm ran} (F \restriction \alpha_2)) \in A \setminus {\rm ran} (F \restriction \alpha_2) \implies f(A \setminus {\rm ran} (F \restriction \alpha_2)) \notin {\rm ran} (F \restriction \alpha_2) \implies$ $F(\alpha_2) \notin {\rm ran} (F \restriction \alpha_2) \implies F(\alpha_2) \neq F(\alpha_1) \in {\rm ran} (F \restriction \alpha_2)$ . Both cases lead to a contradiction. $A=F(\lambda)$ for some $\lambda < h(A)$ where $h(A)$ is the Hartogs number of $A$ If not, $A \neq F(\lambda)$ for all $\lambda < h(A)$ and consequently $F(\lambda) \in A$ for all $\lambda < h(A)$ . Then $F \restriction h(A)$ is an injection from $h(A)$ to $A$ and thus $|h(A)| \le |A|$ . This contradicts the definition of $h(A)$ . $A={\rm ran} (F \restriction \beta)$ for some $\beta \in {\rm Ord}$ Let $\beta = \min \{\lambda \in {\rm Ord} \mid A=F(\lambda)\}$ . Then $F(\alpha) \in A$ for all $\alpha<\beta$ . If not, $F(\alpha) = A$ for some $\alpha<\beta$ . This contradicts the minimality of $\beta$ . It follows that ${\rm ran} (F \restriction \beta) \subseteq A$ . Moreover, $F(\beta)=A \implies G(F \restriction \beta)=A \implies A \setminus {\rm ran} (F \restriction \beta) =\emptyset \implies A \subseteq {\rm ran} (F \restriction \beta)$ . To sum up, ${\rm ran} (F \restriction \beta) = A$ . Hence $F \restriction \beta$ is a bijection from $\beta$ to $A$ . We define an ordering $\prec$ on $A$ by $a\prec b \iff F^{-1}(a) < F^{-1}(b)$ for all $a,b\in A$ . Since $F \restriction \beta$ is a bijection from $\beta$ to $A$ , $F \restriction \beta$ is an isomorphism between $(\beta,<)$ and $(A,\prec)$ . Since $<$ is a well-ordering on $\beta$ , so is $\prec$ on $A$ .","['elementary-set-theory', 'ordinals', 'proof-verification']"
3029458,Solution verification: evaluate $\lim\limits_{n \to \infty}\frac{1^{\lambda n}+2^{\lambda n}+\cdots+n^{\lambda n}}{n^{\lambda n}}$ where $\lambda>0.$,"Problem Evaluate $$\lim_{n \to \infty}\frac{1^{\lambda n}+2^{\lambda n}+\cdots+n^{\lambda n}}{n^{\lambda n}}$$ where $\lambda>0.$ Solution Denote $$S_n:=\sum_{k=1}^{n}\left(\frac{k}{n}\right)^{\lambda n}=\sum_{k=0}^{n-1}\left(1-\frac{k}{n}\right)^{\lambda n}.\tag1$$ On one hand, we choose some $p\in \mathbb{N+}$ , fix it, and let $n>p+1$ . Then $$S_n \geq \sum_{k=0}^{p}\left(1-\frac{k}{n}\right)^{\lambda n}.\tag2$$ Let $n \to \infty$ within $(2)$ . We obtain $$\liminf_{n \to \infty}S_n\geq \liminf_{n \to \infty} \sum_{k=0}^{p}\left(1-\frac{k}{n}\right)^{\lambda n}=\sum_{k=0}^{p}\liminf_{n \to \infty}\left(1-\frac{k}{n}\right)^{\lambda n}=\sum_{k=0}^{p}e^{-\lambda k}.\tag3$$ Notice that $(3)$ holds for all $p$ .  We may let $p \to \infty$ and obtain $$\liminf_{n \to \infty}S_n\geq \sum_{k=0}^{\infty}e^{-\lambda k}=\frac{e^{\lambda}}{e^{\lambda}-1}.\tag4$$ On the other hand, from $1+x\leq e^x$ we may derive $\left(1-\dfrac{k}{n}\right)^{\lambda n}\leq e^{-\lambda k}.$ Thus $$S_n \leq \sum_{k=0}^{n-1}e^{-\lambda k}.\tag5$$ Let $n \to \infty$ within $(5)$ . We obtain $$\limsup_{n \to \infty}S_n \leq \limsup_{n \to \infty}\sum_{k=0}^{n-1}e^{-\lambda k}=\frac{e^{\lambda}}{e^{\lambda}-1}.\tag6$$ See $(4)$ and $(6)$ . We may conclude $$\frac{e^{\lambda}}{e^{\lambda}-1}\leq \liminf_{n \to \infty}S_n\leq \limsup_{n \to \infty}S_n\leq \frac{e^{\lambda}}{e^{\lambda}-1},\tag7$$ which implies $$\lim_{n \to \infty}S_n=\frac{e^{\lambda}}{e^{\lambda}-1}.\tag8$$ Please correct me if I'm wrong. Thanks.","['limits', 'proof-verification', 'limsup-and-liminf']"
3029464,Question about proof of the Rank Theorem from Lee's Smooth Manifolds,"The Rank Theorem : Given a map, $F: M \rightarrow N$ of constant rank, r,
there exist smooth charts $(U,\phi)$ and $(V, \psi)$ such that $\psi \circ F \circ \phi^{-1} (x^1,...,x^r,x^{r+1},...,x^m) = (x^1,...,x^r,0,...,0)$ In the book he defines, $\phi: U_0 \rightarrow \tilde{U}_0$ , where $\tilde{U}_0$ is an open cube, with $\phi(x,y) = (Q(x,y), y)$ where $x$ is short hand for $x^1,...,x^r$ and $y$ is short hand for $x^{r+1},...,x^m$ which he relabels as $y^{r+1},...,y^m$ , with $F(x,y) = (Q(x, y), R(x, y))$ . Then he arrives at $$
D(F \circ \phi^{-1}) = 
\begin{pmatrix}
  I &
    0 \\
  \frac{\partial \tilde{R^i}}{\partial x^j} &
    \frac{\partial \tilde{R^i}}{\partial y^j}
\end{pmatrix}
$$ He mentions that it is necessary for $\tilde{U}_0$ to be an open cube so that $\tilde{R}$ is independent of $(y^1,...,y^{m-r})$ ,  based on $D(F \circ \phi^{-1})$ above, but I thought the same held based on rank arguments alone. He also uses the fact that $\tilde{U}_0$ later on, where he says, Because $\tilde{U}_0$ is a cube and $F \circ \phi^{-1}$ has the form (4.6), it follows that $F \circ \phi^{-1}(\tilde{U}_0) \subseteq V_0$ My question is, why is $\tilde{U}_0$ being a cube needed for the above statements?","['smooth-manifolds', 'differential-geometry']"
3029535,Well-Ordering Principle implies Zorn's Lemma,"Well-Ordering Principle implies Zorn's Lemma Does my attempt look fine or contain logical flaws/gaps? Any suggestion is greatly appreciated. Thank you for your help! My attempt: Let $(A,\preccurlyeq)$ be a partially ordered set in which every chain has an upper bound. By Well-Ordering Principle, there is a well-ordering $\preccurlyeq'$ on $A$ . Let $V$ be the class of all sets and $\rm Ord$ be the class of all ordinals. First, we define function $f:\mathcal{P}(A)\setminus\{\emptyset\} \to A$ by $f(X)=\min X$ (with regard to $\preccurlyeq'$ ). Next, we define function $G:V \to V$ by $G(x)=f(\{a\in A \mid \forall t\in {\rm ran}(x):t \prec a\})$ if $x$ is a function and $\{a\in A \mid \forall t\in {\rm ran}(x):t \prec a\} \neq \emptyset$ , and $G(x)=A$ otherwise. By Transfinite Recursion Theorem, there is a function $F: {\rm Ord} \to V$ such that $F(\alpha)=G(F \restriction \alpha)$ for all $\alpha \in {\rm Ord}$ . It is not hard to verify (by Hartogs number) that $F(\alpha)= A$ for some ordinal $\alpha$ . Let $\lambda=\min\{\alpha \in {\rm Ord} \mid F(\alpha)= A\}$ . Then ${\rm ran}(F\restriction \lambda)$ is clearly a chain in $(A,\preccurlyeq)$ and has an upper bound $u \in A$ . If $u \prec \bar a$ for some $\bar a\in A$ , we have $\bar a\in\{a\in A \mid \forall t\in {\rm ran}(F\restriction \lambda):t \prec a\} \neq \emptyset$ and thus $F(\lambda) \in A$ . This contradicts the fact that $F(\lambda)=A$ . So $u$ is the maximal element of $A$ .","['elementary-set-theory', 'ordinals', 'proof-verification']"
3029557,"Prove that if $a, b, c \in \mathbb{Z^+}$ and $a^2+b^2=c^2$ then ${1\over2}(c-a)(c-b)$ is a perfect square.","Prove that if $a, b, c \in \mathbb{Z^+}$ and $a^2+b^2=c^2$ then ${1\over2}(c-a)(c-b)$ is a perfect square. I have tried to solve this question and did pretty well until I reached the end, so I was wondering if I could get help on that part. Here is what I did. $$a^2+b^2=c^2$$ $$b^2=(c-a)(c+a)$$ Since $a, b, c > 0 \therefore (c+a) \ne 0$ $$\therefore c-a={b^2\over c+a}$$ Similarly we get, $$c-b={a^2\over c+b}$$ $$\therefore {1\over2}(c-a)(c-b)={1\over2}({b^2\over c+a})({a^2\over c+b})$$ $$={(ab)^2\over 2c^2+2ab+2bc+2ca}$$ $$={(ab^2)\over a^2+b^2+c^2+2ab+2bc+2ca}$$ $$={(ab)^2\over (a+b+c)^2}$$ $$=({ab\over a+b+c})^2$$ However, I was unable to prove that ${ab\over a+b+c} \in \mathbb{Z}$ Is there a way to prove it? Thank you","['elementary-number-theory', 'algebra-precalculus', 'pythagorean-triples']"
3029560,Zorn's Lemma implies Axiom of Choice,"Zorn's Lemma implies Axiom of Choice Does my attempt look fine or contain logical flaws/gaps? Any suggestion is greatly appreciated. Thank you for your help! My attempt: Let $S$ be a collection of nonempty sets and $F$ be the collection  of all functions $f$ for which ${\rm dom}(f) \subseteq S$ and $f(X)\in X$ for all $X \in {\rm dom}(f)$ . The set $F$ is ordered by inclusion $\subseteq$ . Assume that $C$ is a chain in $(F,\subseteq)$ . Let $f_0=\bigcup C$ . It is easy to verify that $f_0 \in F$ and $f_0$ is an upper bound of $C$ . Then $F$ has a maximal element $\bar f$ by Zorn's Lemma. To accomplish the proof, we next show that ${\rm dom}(\bar f)=S$ . If not, ${\rm dom}(\bar f) \subsetneq S$ and thus $S \setminus {\rm dom}(\bar f) \neq \emptyset$ . Take some $\bar X \in S \setminus {\rm dom}(\bar f)$ and $\bar x\in \bar X$ . Clearly, $\bar f \bigcup \{(\bar X,\bar x)\}\in F$ . This contradicts the minimality of $\bar f$ . This completes the proof.","['elementary-set-theory', 'axiom-of-choice', 'proof-verification']"
3029568,"Show that $\mathbb{Q}(\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...)$ is algebraic over $\mathbb{Q}$ but not a finite extension.","Show that $\mathbb{Q}(\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...)$ is algebraic over $\mathbb{Q}$ but not a finite extension. I think for the algebraic part, since for every simple extension, each of those elements can be adjoined and each of these simple extensions has a minimal polynomial that cannot be reduced in $\mathbb{Q}$ . For example, the simple extension $\mathbb{Q}(\sqrt{3}, \sqrt[4]{3})(\sqrt[8]{3})$ has minimal polynomial $x^{8}-3$ . And since each simple extension has an increasingly large degree, the degree of the simple extensions over the previous extension gets larger for each attachment. But I am not sure how to express this formally... For the infinite degree part, I was thinking because the set $\left \{\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...\right \}$ is linearly independent?","['field-theory', 'abstract-algebra', 'extension-field']"
3029627,Convolution of a compactly supported function and an $L^1$ function.,"I have these related questions here that I could really use some help on. I believe there is a related question here although I don't think it is exactly the same... 1) Let $f\in L^1(\mathbb R)$ and $\varphi$ a smooth compactly
  supported function. Prove that $f\ast \varphi$ is a smooth function
  whose derivative is $f\ast \varphi'$ . Any help would be much appreciated. I have been trying to work on this for the past couple days but all my ideas didn't lead me very far. Namely, I was trying to use the definition of a convolution. I am not sure though how the smooth and compactly supported $L^1$ function fits into this...","['hilbert-spaces', 'convolution', 'functional-analysis', 'real-analysis']"
3029634,Solving the equation $\frac{\ln (x)}{\ln (1-x)} = \frac{1}{x} - 1$,I'm trying to solve the following equation (which has solution $x = 1/2$ ) $$\frac{\ln (x)}{\ln (1-x)} = \frac{1}{x} - 1 $$ I can't seem to do it analytically. Any ideas?,"['calculus', 'algebra-precalculus', 'logarithms']"
3029646,Conditions when solutions of $\dot{x} = f(x)$ exist for all time,"I am reading the following textbook: Introduction to Applied Nonlinear Dynamical Systems and Chaos by Wiggins 
p.92 (top) Consider $$\dot{x} = f(x)$$ where $f(x)$ is $C^r$ , $r\geq 1$ , on some open set $U\in \mathbb{R}^n$ . Suppose that the solutions exist for all time (Leave it as an exercise to make the necessary modifications when solutions exist only on finite time intervals). My problem is what are the conditions to make solutions exist for all time. Consider and example: $$\dot{x} = x^2, \ \ \ \ x\in \mathbb{R}$$ the solution through $x_0$ at $t = 0$ is $$x(t,0,x_0) = \frac{-x_0}{x_0t - 1}$$ this solution (trajectory) does not exist for all time, since it becomes infinite at $t = 1/x_0$ . So what are the conditions to make solution exist for all time","['ordinary-differential-equations', 'dynamical-systems']"
3029650,Four men go into a restaurant and leave their umbrellas at the door,"Question: Four men go into a restaurant and leave their umbrellas at the door. On their way out, each man picks up an umbrella and they discover when they get outside that no man has his own umbrella. In how many different ways can this situation arise? My logic: total no - the combination that four men take their own umbrella. first one: 1/4 prob choose her's umbrella. second one: 1/3 prob...third 1/2...last 1/1 but it sounds my answer is not correct ... Is there anyone can help? The answer should be 9.","['permutations', 'combinations', 'discrete-mathematics']"
3029712,Every finite $\sigma$-algebra is of the form...?,"Let $\mathcal{F}$ be a finite $\sigma$ -algebra. The problem asks to show there exists a partition $G = \{ G_1,\dots,G_n \}$ of $\Omega$ such that for all $A \in \mathcal{F}$ , $A$ is the union of all or some $G_i$ : $$A = \bigcup_{i \in I} G_i$$ The existence of a partition is immediate from the definition of a $\sigma$ -algebra, but I'm not sure how to use the fact $\mathcal{F}$ is finite to construct the generating set $G$ . Specifically, to show that every member of $\mathcal{F}$ can be generated from a single partition using only union. Can someone give me a hint? Not a homework problem, I am working through a textbook for self-study.","['measure-theory', 'probability']"
3029779,Is it possible to mathematically skip numbers containing 666?,"I once had a project which involved taking actual real social security numbers and anonymizing them into unique real-looking fake SSNs. One of the rules for SSNs is that it cannot contain a run of 666 inside it. That raised the question, is it possible to do this mathematically? More generally, given this sequence $$S = 1, 2, 3, ..., 665, 667, 668, ..., 1665, 1667, ..., 6658, 6659, 6670, ...$$ Is it possible to get the $n$ th term without simply counting up to it?","['integers', 'sequences-and-series']"
3029783,Does this limit exist on $\mathbb R^2$,"$(x,y) \in \mathbb R^2$ $$\lim_{(x,y)\to(1,1)} \frac{(x-y)^{(x-y)}} {(x-y)}$$ Does the limit above exist? Neither I could compute it nor I could find directions which have different limit values. Can someone help me please? If this limit exists how can I compute it if doesn't exist which directions should I use? Thanks a lot in advance","['multivariable-calculus', 'calculus', 'analysis']"
3029789,Proving $\Im\operatorname{Li}_2(\sqrt i(\sqrt 2-1))=\frac34G+\frac18\pi\ln(\sqrt2-1)$,"$\newcommand{\Li}{\operatorname{Li}_2}$ I found, numerically, that $$\Im\Li(\sqrt i(\sqrt 2-1))=\frac34G+\frac18\pi\ln(\sqrt2-1).$$ How can we prove it? My attempt of proving this equation:
Using identity $$\Li(x)=\int_0^1\frac{x}{xt-1}\ln tdt,$$ we can deduce $$\begin{align}\Im\Li(\sqrt i(\sqrt 2-1))&=\frac1{2i}\int_0^1\left(\frac{\sqrt i(\sqrt2-1)}{\sqrt i(\sqrt2-1)t-1}-\frac{\sqrt {-i}(\sqrt2-1)}{\sqrt {-i}(\sqrt2-1)t-1}\right)\ln tdt\\
&=\int_0^1\frac{2-\sqrt{2}}{\left(4 \sqrt{2}-6\right) t^2-2 \left(\sqrt{2}-2\right) t-2}\ln tdt\\
&=\int_0^{2-\sqrt2}-\frac{1}{u^2-2u+2}\ln\frac u{2-\sqrt 2}du\\
&=\frac18\pi\ln(2-\sqrt2)-\int_{-1}^{1-\sqrt2}\frac{\ln(v+1)}{v^2+1}dv\\
&=\frac18\pi\ln(2-\sqrt2)-\int_{\pi/8}^{\pi/4}\ln(1-\tan x)dx\\
&=\frac18\pi\ln(\sqrt2-1)-\int_{\pi/8}^{\pi/4}\ln\sec x+\ln\sin\left(\frac\pi4-x\right)dx\\
\end{align}$$ I have no idea how to deal with the log-trig integral.","['calculus', 'polylogarithm', 'definite-integrals']"
3029823,Intuition of sub sigma-algebra definition,"I am having trouble understanding the sub σ-algebra definition on Wikipedia. I understand the following: Let $X$ be a set, and let $A,B$ be σ-algebras on $X$ . Then $B$ is said to be a sub-σ-algebra of $A$ iff $\mathcal B \subseteq \mathcal A$ . For example, let $X=[0,1]$ and let $A$ be the σ-algebra generated by the sets $[0,1/4), [1/4,1/2), [1/2,3/4), [3/4,1]$ . Then the σ-algebra $B$ generated by the sets $[0,1/2), [1/2,1]$ is a sub σ-algebra of $A$ . Is this correct? And now regarding the wikipedia definition that I have trouble with: Formally, since you need to use subsets of Ω, this is codified as the σ-algebra ${\displaystyle {\mathcal {G}}_{n}=\{A\times \{H,T\}^{\infty }:A\subset \{H,T\}^{n}\}.}$ Observe that then ${\displaystyle {\mathcal {G}}_{1}\subset {\mathcal {G}}_{2}\subset {\mathcal {G}}_{3}\subset \cdots \subset {\mathcal {G}}_{\infty },}$ where ${\displaystyle {\mathcal {G}}_{\infty }}$ is the smallest σ-algebra containing all the others. I don't understand the last observation. My reasoning is that ${\mathcal {G}}_{1}$ (for example a sequence of H, T starting with H) has more elements than ${\mathcal {G}}_{2}$ (a sequence of H, T starting with HH).","['measure-theory', 'intuition']"
3029868,Non unique factorization of integer valued polynomials,"Is there a nice example of a polynomial with non unique factorization in the subring of $\mathbb Q[X,Y]$ of polynomials that defines functions $\mathbb Z^2\to\mathbb Z$ ? I don't think this subring is a UFD because of the possibility to multiply the unique factors in $\mathbb Q[X,Y]$ in different ways to sometimes obtain different irreducible factors in the subring.","['ring-theory', 'abstract-algebra', 'factoring', 'polynomials']"
3029929,find closed form for following double integral containing radicals,"question: To prove : $\displaystyle\int_{0}^{1}\displaystyle \int_{0}^{1}\dfrac{dxdy}{\sqrt{1-x^2}{\sqrt{1-y^2}}{\sqrt{4x^2+y^2-x^2y^2}}}=\dfrac{3\left(\Gamma{\dfrac{1}{3}}\right)^6}{2^{\dfrac{17}{3}}\pi^2}$ i tried  attempting it by transforming into polar co-ordinates but it didn't 
helped i couldn't get rid of radicals and also there is no scope for changing order of integration for it's evaluation. please help . thank you","['integration', 'contest-math', 'definite-integrals', 'multivariable-calculus', 'calculus']"
3029940,"Show that three point $G,H,G_1$ are collinear.","Triangle $ABC$ has centroid $ G$ and orthcenter $H$ . Line (through $A$ ) is perpendicular to $GA$ , line (through $B$ ) is perpendicular to $GB$ , line (through $C$ ) is perpendicular to $GC$ cut at three points which form a new triangle $A_1B_1C_1$ . This new triangle has centroid $G_1$ . Show that three point $G,H,G_1$ are collinear. I have tried to so this problem with lots of theorems. But I can't find the way to solve. Or using any lemma? Help me to find and draw any auxiliary geometry element.","['euclidean-geometry', 'geometry', 'triangles', 'trigonometry', 'problem-solving']"
3029966,Expected value: Is $E|X| = |E(X)|$?,"Is the expectation of absolute value equal to the absolute value of the expectation? $E|X| = |E(X)|$ seems intuitively true to me, but I couldn't find it online. I wanted to check whether this is true.","['expected-value', 'statistics', 'probability']"
3029968,Why is $v(a) \leq v(ab)$ superfluous in Euclidean domain definition?,Can anyone make me understand in simple language why the second condition for being an Euclidean domain is superfluous ? Why $v(a)  \leq v(ab)$ is not needed?  How we can deduce from the first one?,"['euclidean-domain', 'ring-theory', 'abstract-algebra', 'integral-domain']"
3029976,"For what $p,q,r$ $\lim_{x \to 0} f(x)=\frac{p + q\cos x + r\sin x}{x^2}=1/2$?","Let $$f(x)=\frac{p + q\cos x + r\sin x}{x^2}$$ . Then for what values of $p$ , $q$ and $r$ is the limit $$\lim_{x \to 0} f(x)=1/2.$$ I’ve tried using L’Hospital’s rule but couldn’t get anywhere. Any help would be appreciated.","['limits', 'sequences-and-series', 'real-analysis']"
3029977,global max and min as limit to +-infinity equals 0,"In an exercise I have to make I am asked to show that a function $f$ has a global maximum and minimum, given that: $f:\mathbb{R}\to\mathbb{R}$ is continuous and $$\lim_{x\to\infty}f(x)=0.$$ However, in my mind, the function $f(x)=e^{-x^2}$ satisfies those conditions and has an global maximum, but no minimum at all. Am I misinterpreting the given information?","['limits', 'derivatives', 'continuity', 'real-analysis']"
3030026,Rational functions on curve,"Consider the following setting: $X$ an irreducible smooth proj. curve and $f$ a morphism $X \rightarrow \mathbb{P}^1(k)$ , with $k$ algebraically closed. Call $C$ the complement of $f^{-1}\{(1:0)\}$ and assume it non-empty. I am trying to prove that $f|_C$ seen as a map to $\mathbb{A}^1$ (which we can do because we took a point away from $\mathbb{P}^1$ ) defines an element $f^{\vee}$ of $K(X)$ (rational functions on X) and actually $f \mapsto f^{\vee}$ establishes a bijection between the set of morphisms $X \rightarrow \mathbb{P}^1$ whose image is not $(1:0)$ and $K(X)$ . The proof that there is this bijection will probably involve divisors and Riemann-Roch but my problem is actually that I don't see how exactly the restriction to $C$ defines a rational function $f^{\vee}$ . Thanks for your attention.","['algebraic-geometry', 'geometry']"
3030041,Subspace topology and product topology,Let $\tau$ be a topology on a topological space $X \times Y$ which is not a product topology. Consider the subspace topology $\tau_X$ and $\tau_Y$ induced by the topology $\tau$ . My question is would the product topology $\tau_X \times \tau_Y$ on $X \times Y$ coincide with the topology $\tau$ . I tried proving this by showing open sets in one topology is contained in other. I think I can show that $\tau \subset \tau_X \times \tau_Y$ but I am not able to show the other way round.,['general-topology']
