question_id,title,body,tags
3745184,Computing the reduction of a quotient over the $5$-adic numbers,"Let $\alpha_1,\alpha_2,\alpha_3$ be the roots of $f = X^3 - 135 X - 270 \in \mathbb{Q}_5[X]$ over its splitting field $L$ . Because $$g = f/(X-\alpha_1) = X^2 + \alpha_1 X + \alpha_1^2 - 135$$ and $$g = (X-\alpha_2) (X - \alpha_3) = X^2 - (\alpha_2 + \alpha_3) X + \alpha_2 \alpha_3,$$ we obtain the relations $$\alpha_2 \alpha_3 = \alpha_1^2 -135 \quad \text{and} \quad \alpha_2 + \alpha_3 = - \alpha_1.$$ Now let $\lambda = \frac{\alpha_3 - \alpha_1}{\alpha_2 - \alpha_1} \in L$ . Question What is the reduction $\bar{\lambda}$ of $\lambda$ ? Why do I need this? I have an elliptic curve $$
Y^2 = X (X-1)(X-\bar{\lambda})
$$ over $\mathbb{F}_5$ (the residue field of $L$ ) and need to count points over $\mathbb{F}_5$ . Therefore, I need to know what exactly $\bar{\lambda}$ is. What did I do to approach my problem? By computing the Newton polygons of $F$ and $h := g(X+\alpha_1) = (X - (\alpha_2 - \alpha_1))(X - (\alpha_3 - \alpha_1))$ , I was able to compute the valuations of their roots $\alpha_1,\alpha_2,\alpha_3$ (roots of $f$ ) and $n := \alpha_2 - \alpha_1, z := \alpha_3 - \alpha_1$ (roots of $h$ ) which are all $1/3$ (assuming $v(5) = 1$ ). This implies that the valuation of $\lambda$ is $0$ , so $\bar{\lambda} \neq 0$ . Another approach was using $\alpha_2 = \alpha_1 - \alpha_3$ (follows from the observation above) which gives $$
\lambda = \frac{\alpha_3-\alpha_1}{-\alpha_3} = -1 + \frac{\alpha_1}{\alpha_3}.
$$ Here, we also have a fraction where both enumerator and denominator have valuations $1/3$ , respectively, but maybe this is better to work with. Also, similarly as for $g$ , we obtain the relations $$
z + n = -3 \alpha_1 \quad \text{and} \quad zn = 3\alpha_1^2 - 135.
$$ But I do not know how to make the transition to $\lambda = z/n$ . Also, I tried to compute the roots of $h$ in terms of $\alpha_1$ with the formula to compute roots of quadratic polynomials. But there, I cannot get rid of denominators which all seems to have valuations greater than $0$ . Thank you!","['algebraic-number-theory', 'elliptic-curves', 'number-theory', 'p-adic-number-theory', 'abstract-algebra']"
3745188,Looking for a function that is continuous but not sequentially weakly continuous,"Let $(X, \|\cdot\|) $ be a Banach space. A function $g:X \longrightarrow X$ is said to be sequentially weakly continuous if for every sequence $(x_n)$ in $X$ such that $x_n \rightharpoonup x$ , we have $g(x_n) \rightharpoonup g(x)$ . What's an example of a function $g:X \longrightarrow X$ which is strongly continuous (meaning continuous as a map $X \longrightarrow X$ where on both $X$ 's we take the topology induced by $\|\cdot\|$ ) but not sequentially weakly continuous?","['continuity', 'banach-spaces', 'functional-analysis', 'weak-topology']"
3745204,"Proof, derangements, permutations","$n! = \binom{n}0 D_n + \binom{n}1 D_{n-1} + \binom{n}2 D_{n-2} + ….. +\binom{n}n D_0 $ $(D_0 = 1)$ Attempt: The number of permutations of n distinct objects is n factorial. $\binom{n}0 D_n $ means all the objects aren't in their natural place. $\binom{n}1 D_{n-1} $ means we fix one object ( choose 1 from n ) then the rest deranged .
.
. $\binom{n}n D_0 $ means all the objects are in place","['derangements', 'discrete-mathematics']"
3745241,Simplifying $\cot\alpha(1-\cos2\alpha)$. I get $\sin 2\alpha$; book says $-4\sin\alpha$.,"Please help simplify expression \begin{align}\cot\alpha\ (1-\cos2\alpha)\end{align} I tried to solve through this way:
First dividing and multiplying both parts by $2$ \begin{align}\cot\alpha\ (1-\cos2\alpha)= 2\cot\alpha\sin^2\alpha\end{align} Second reducing the degree and sin of cot \begin{align}2\cos\alpha\sin\alpha=\sin 2\alpha\end{align} But in book there is $-4\sin\alpha$ Where is my mistake?",['trigonometry']
3745244,$\iint_{\mathbb{R}^2} \frac{1}{\sqrt{1+x^4+y^4}}$ converges or diverges?,$$\iint_{\mathbb{R}^2} \frac{1}{\sqrt{1+x^4+y^4}}$$ converges or diverges? I've tried to change to polar coordinates but i got stuck really quick $$\int_{0}^{2\pi}\int_{0}^{\infty}\frac{r}{\sqrt{1+r^4(1-2\sin^2(t)\cos^2(t))}}drdt$$ any hint please?,"['multivariable-calculus', 'polar-coordinates', 'multiple-integral', 'trigonometric-integrals', 'convergence-divergence']"
3745261,Prove or disprove that $PQ = P + Q - I$ if $P$ and $Q$ are disjoint permutation matrices whose cycle lengths sum to $n.$,"Prove or disprove that if the matrices $P$ and $Q$ represent disjoint permutation cycles in $S_{n}$ with sum of cycle lengths equal to $n,$ then $PQ = P+Q-I$ . MY TRY: Let's start by an example. Let $P$ and $Q$ be the matrices corresponding to the respective permutations $p = (1 \, 2)$ and $q = (3 \, 4 \, 5)$ in cycle notation. We have that $$
P =
\begin{pmatrix}
0 & 1 & 0 &  0 & 0 \\
1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 &  0 & 0\\ 
0 & 0 & 0 &  1 & 0\\
0 & 0 & 0 &  0 & 1
\end{pmatrix} \text{ and } Q = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0\\ 
0 & 0 & 0 & 0 & 1\\
0 & 0 & 1 & 0 & 0
\end{pmatrix}.
$$ It seems obvious that the matrix $PQ$ representing the permutation $pq = (1 \, 2)(3 \, 4 \, 5)$ will be $P+Q-I,$ as the ""untouched"" $1$ s in the matrices are simply canceled by $I$ and the touched $1$ s create the derangements. But isn't there some clear method to prove it? I am new to group theory. Please ask for clarifications in case of any discrepancies. Any hint will be a great help!","['matrices', 'group-theory', 'abstract-algebra', 'permutations']"
3745267,Morphisms of rings that define morphisms of derivations,"I am not super experienced in (commutative) algebra and in the course of some of my work I noticed that I had a need for morphisms of rings that are compatible with the asssociated module of derivations. Let me set some notation. $ R $ and $ S $ are rings and and $ \phi \colon R \to S $ is a ring homomorphism. Let $ Der(R) $ and $Der(S)$ denote the respective modules of derivations. Since $ S $ is an $ R $ -module, we can also define $ Der(R, S ) $ to be the $R$ -module of derivations on $R$ with values in $S$ . Notice that there are natural $R$ -module homomorphisms $ Der(R) \to Der(R,S) $ and $ Der(S) \to Der(R,S) $ by post- and pre-composition by $\phi$ , respectively. There is also a natural $S$ -module homomorphism $S \otimes_R Der(R) \to Der(R,S)$ . Now let me propose two definitions. My hope is that these definitions exist in the literature and I am just too ignorant to know the actual terminology. Definition 1 : We say that $\phi$ is of the first kind if there exists a unique morphism of $R$ -modules $\alpha \colon Der(R) \to Der(S) $ which makes the following diagram commute: $$
\begin{array}{ccc}
Der(R) & \rightarrow & Der(S) \\
 & \searrow & \downarrow \\
 & & Der(R,S)
\end{array}
$$ Motivating Example : Suppose $M$ is a smooth manifold and $U$ is an open subset. The restriction map $C^\infty(M) \to C^\infty(U)$ is a ring homomorphism of the first kind. I suspect this is actually true for any locally ringed space (?). Definition 2 : We say that $\phi$ is of the second kind if there exists a unique morphism of $S$ -modules $\beta \colon Der(S) \to S \otimes_R Der(R) $ which makes the following diagram commute: $$
\begin{array}{ccc}
Der(S) & \rightarrow & S \otimes_R Der(R) \\
 & \searrow & \downarrow \\
 & & Der(R,S)
\end{array}
$$ Motivating Example : Suppose $M$ and $N$ are smooth compact manifolds and $f \colon M \to N $ is a smooth function. The pull-back map $f^* \colon C^\infty(N) \to C^\infty(M) $ is of the second kind. With the definitions out of the way, let me ask my questions. Question 1 : Is there a nice category of rings where every homomorphism is of the first and/or second kind? Question 2 : Are the uniqueness conditions in the definitions necessary? In my fumbling efforts I have not been able to find counter-examples. ( I have since partially answered this, see edit ) Question 3 : Are morphisms of local rings always of the second kind? Question 4 : If I assume that $Der(R)$ and $Der(S)$ are projective and finitely generated modules does that imply that $\phi$ is of the second kind? Question 5 : When is a morphism of local rings of the first/second kind? In the algebraic geometry universe, which morphisms of schemes induce homomorphisms of the first/second kind? EDIT 1 : Regarding uniqueness I see that there are plenty of examples that fail uniqueness. For instance, if one takes $M$ to be a manifold and $\pi \colon M \times M \to M $ to be projection to the first factor, one can show that there are actually many module homomorphisms $ \mathcal{X}(M \times M) \to \mathcal{X} (M)$ which make the 'first kind' diagram commute. However, none of them are natural/canonical. EDIT 2 : I figured I should include the version in terms of Kahler forms. Let's assume that $R$ and $S$ are $k$ -algebras for some fixed field $k$ . We denote by $\Omega_R$ and $\Omega_S$ the usual modules of Kahler forms. The universal property of the Kahler differential tells us that $$ Der(R) \cong Hom_R(\Omega_R,R) \quad Der(S) \cong Hom(\Omega_S,S) \quad Der(R,S) \cong Hom_R(\Omega_R, S) $$ One can use these isomorphisms to substitute these objects into the above diagrams. The one glimmer of hope is that there is actually a natural homomorphism $\phi_* \colon \Omega_R \to \Omega_S$ obtained by the rule $ \phi_*(dr) = d(\phi(r))$ . Still, this is not enough to get the maps. From this point of view, it seems likely that if one assumes that $\Omega_R$ and $\Omega_S$ are sufficiently nice modules, then $\phi$ will be of the first/second kind. It seems like it could also be related to the structure of $S$ as an $R$ -module. Unfortunately, I haven't been able to show that these conditions suffice. I also have no intuition as to which sorts of rings will have projective/finitely generated/etc modules of Kahler forms.","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'algebras', 'commutative-algebra']"
3745320,Integrate $\int_0^1 \frac{x^2-1}{\left(x^4+x^3+x^2+x+1\right)\ln{x}} \mathop{dx}$,Insane integral $$\int_0^1 \frac{x^2-1}{\left(x^4+x^3+x^2+x+1\right)\ln x} \mathop{dx}$$ I know $x^4+x^3+x^2+x+1=\frac{x^5-1}{x-1}$ but does it help?  I think $u=\ln{x}$ might be necessary some point.,"['integration', 'calculus', 'real-analysis']"
3745322,Prove that $0$ is not an essential singularity (UW Madison Qualifying exam),"I'm trying to do this old qualifying exam problem from UW Madison. Let $D^\ast=\{z\in\mathbb{C},0<|z|<1\}$ and $f$ be a non constant holomorphic function on $D^\ast$ . Assume that $\text{Im} f(z)\geq 0$ if $\text{Im} z\geq 0$ and $\text{Im} f(z)\leq 0$ if $\text{Im} z\leq 0$ . Prove that if $z\in D^\ast$ is not real, then $f(z)$ is not real. Show that if $z\in (-1,0)\cup(0,1)$ , then $f'(z)\not=0$ . Prove that $0$ is either a removable singularity with $f'(0)\not=0$ or $0$ is a simple pole of $f$ . What I have thought of so far: If $z\in D^\ast$ and $\text{Im} z>0$ , but $\text{Im} f(z)=0$ , then apply the maximum modulus principle on $\{z|z\in D^\ast,\text{Im} z>0\}$ to $e^{if}$ to obtain a contradiction. This shows that if $z\in D^\ast$ and $\text{Im} z>0$ , then $\text{Im} f(z)>0$ . Similarly if $z\in D^\ast$ and $\text{Im} z<0$ . Furthermore, the reflection principle shows that $f(\overline{z})=\overline{f(z)}$ . If $z\in(-1,0)\cup(1,0)$ , to show that $f'(z)\not=0$ , we use the following fact: fact: If $f$ is a complex valued function continuous on $\overline{D(0,R)}$ and holomorphic on $D(0,R)$ , then for any $z\in D(0,R)$ , we have $$f(z)=\int_0^{2\pi}i \text{Im} f(\xi)\frac{\xi+z}{\xi-z}\frac{d\theta}{2\pi}+K$$ for some constant $K$ , where $\xi=Re^{i\theta}$ . We can differentiate the expression to get an expression of $f'(z)$ in terms of $\text{Im} f$ . This same fact shows that $f'(0)\not=0$ if $0$ is a removable singularity. If $0$ is a pole, $\text{Im} z$ is dominated by the imaginary part of $\frac{C}{z^n}$ for some $n\in\mathbb{Z}^+$ and $C\in\mathbb{R}$ when $|z|>0$ is small, then unless $n\not=1$ , we can find some $z\in D^\ast$ , $\text{Im} z>0$ such that $\text{Im} f(z)<0$ . So if $0$ is a pole, then it is a simple pole. My question is: how to show that $0$ is not an essential singularity? Thanks!!",['complex-analysis']
3745350,Solution verification: $ \lim _ { x \to 3 } \frac { 2 x - 6 } { \sqrt x - \sqrt 3 } = ? $,"This limit is not too difficult but I was just wondering if my work/solution looked good? Thanks so much for your input!! $$ \lim _ { x \to 3 } \frac { 2 x - 6 } { \sqrt x - \sqrt 3 } = ? $$ $$ 2 x - 6 = 2 x \left( 1 - \frac 6 { 2 x } \right) $$ $$ \lim _ { x \to 3 } \frac { 2 x - 6 } { \sqrt x - \sqrt 3 } =
\lim _ { x \to 3 } \frac { 2 x \left( 1 - \frac 6 { 2 x } \right) } { \sqrt x - \sqrt 3 } =
2 \cdot \lim _ { x \to 3 } \frac { x \left( 1 - \frac 6 { 2 x } \right) } { \sqrt x - \sqrt 3 } =
2 \cdot \lim _ { x \to 3 } \frac { x - 3 } { \sqrt x - \sqrt 3 } $$ By rationalizing the denominator: $$ \frac { x - 3 } { \sqrt x - \sqrt 3 } = \sqrt x + \sqrt 3 $$ $$ 2 \cdot \lim _ { x \to 3 } \frac { x - 3 } { \sqrt x - \sqrt 3 } =
2 \cdot \lim _ { x \to 3 } \left( \sqrt x + \sqrt 3 \right) $$ By plugging in $ x = 3 $ : $$ 2 \cdot \lim _ { x \to 3 } \left( \sqrt x + \sqrt 3 \right) =
2 \left( \sqrt 3 + \sqrt 3 \right) = 4 \sqrt 3 $$","['limits', 'calculus', 'solution-verification']"
3745353,Product of two functions a function?,"For some f to be a function, then for every $x$ in the domain of $f$ , there should be unique image of $x$ in the range of $f$ . $f(x_1) \neq f(x_2) \implies x_1 \neq x_2 \\x_1 = x_2 \implies f(x_1)=f(x_2)$ Say $f(x)g(y)$ is the product of 2 functions. For this product to be again a function $x_1y_1 = x_2y_2 \implies f(x_1)g(y_1) = f(x_2)g(y_2) $ ? How to prove or disprove this? I am not able to get any clue. Please enlighten","['elementary-set-theory', 'functions']"
3745357,"Given a differentiable function $f$, prove that $\lim_{h\to 0}\frac{f\left(x + \frac{h}{2}\right)-f\left(x - \frac{h}{2}\right)}{h} = f'(x)$.","I'm trying to prove the following statement Given a differentiable function $f:\mathbb{R}\to \mathbb{R}$ , prove that $$\lim_{h \to 0} \frac{f\left(x + \frac{h}{2}\right)-f\left(x - \frac{h}{2}\right) }{h} = f'(x)$$ I know $2$ definitions for the derivative of a function $f$ : $$
\lim_{h \to 0} \frac{f\left(x +h\right)-f\left(x\right) }{h} \qquad \text{and} \qquad \lim_{a \to x} \frac{f\left(x \right)-f\left(a\right) }{x-a}
$$ so my idea was to try to arrange the limit in question into one of these $2$ forms. I proceeded to take $x^* = x - \frac{h}{2} $ to do a change of variable, in which case my limit would end up looking like $$\lim_{h \to 0} \frac{f\left(x^* +h\right)-f\left(x^*\right) }{h} = f'(x^*) $$ which would seem to imply that this is equal to $f'\left(x - \frac{h}{2}\right)\neq f'(x)$ using the first definition of the derivative. I know that since $h \to 0$ , then $f'\left(x - \frac{h}{2}\right)$ and $f'(x)$ are the same thing, but since the paramater $h$ is included in the substitution I'm making I don't know how to account for this after I took the limit. I think my problem is just a basic concept misconception, but I can't seem to find a way to rigorously justify the steps I need to take to transform the limit into one of the definitions that I know. Could anyone tell me what I'm doing wrong or how I could correctly structure this argument to make it rigorous? Thank you!","['calculus', 'solution-verification', 'change-of-variable', 'limits', 'derivatives']"
3745360,Show that the total variation distance is equal to the Wasserstein distance with respect to the Hamming distance,"Let $(E,\mathcal E)$ be a measurable space such that $$\Delta:=\{(x,x):x\in E\}\in\mathcal E,$$ $\mu$ and $\nu$ be probability measures on $(E,\mathcal E)$ , $\mathcal C(\mu,\nu)$ denote the set of couplings of $\mu$ and $\nu$ and $$\operatorname W:=\inf_{\gamma\in\mathcal C(\mu,\:\nu)}\int1_{\Delta^c}\:{\rm d}\gamma$$ denote the Wasserstein distance of $\mu$ and $\nu$ with respect to the Hamming distance $1_{\Delta^c}$ . Moreover, let $$\left\|\mu-\nu\right\|:=\sup_{B\in\mathcal E}|(\mu-\nu)(B)|$$ denote the total variation distance of $\mu$ and $\nu$ . How can we show that $\operatorname W=\left\|\mu-\nu\right\|$ ? Since $$(E\times B)\cap\Delta=\{(x,x):x\in B\}=(B\times E\cap\Delta\}\tag1,$$ we have $$\mu(B)-\nu(B)=\gamma((B\times E)\cap\Delta^c)-\gamma((E\times B)\cap\Delta^c)\tag2$$ for all $B\in\mathcal E$ . We should be able to obtain "" $\ge$ "" from that ... Remark : Please come up with a proof which does not rely on considering random variables with marginal distribution $\mu$ and $\nu$ .","['total-variation', 'measure-theory', 'probability-theory']"
3745366,"Show that there is a constant $M$ such that for all $x,y \in X$ we have $|f(x) - f(y)| \leq M |x-y| + \epsilon$.","Full problem statement: Let $X \subset \mathbb{R}^m$ be compact and $f : X \rightarrow \mathbb{R}$ be continuous. Given $\epsilon > 0$ , show that there is a constant $M$ such that for all $x,y \in X$ we have $|f(x) - f(y)| \leq M |x-y| + \epsilon$ . Please check my solution for correctness below: Solution: Assume on the contrary that there exists an $\epsilon > 0$ such that $\forall M \ \exists x,y \in X$ s.t. $|f(x) - f(y)| > M|x-y| + \epsilon$ . First note that $Im\ f = f(X) \subset \mathbb{R}$ is the continuous image of a compact set, so it is compact, and so, closed and bounded. By noting that the left hand side is bounded above and by taking large enough values of $M$ , we see that there are two sequences of points in $X$ - $(x_n)_0^\infty, (y_n)_0^\infty$ such that $d_X(x_n, y_n) < \frac{1}{2^n}$ while $|f(x_n) - f(y_n)| > \epsilon$ for all $n \in \mathbb{N}_0$ . By compactness of $X$ , $(x_n)$ has a subsequence $x_{n_k}$ that converges to a point $l_1 \in X$ . Again, $(y_{n_k})$ has subsequence $(y_{n_{k(l)}})$ that converges to a limit $l_2 \in X$ . Considering the fact that $d_X(x_{n_{k(l)}}, y_{n_{k(l)}}) < \frac{1}{2^n}$ , we conclude that $l_1 = l_2$ . That is, we have, $(x_{n_{k(l)}}) \rightarrow l,\ (y_{n_{k(l)}}) \rightarrow l$ for some $l \in X$ (compactness). By continuity of $f$ , we must have the sequences $f(x_{n_{k(l)}})$ and $f(y_{n_{k(l)}})$ converge to the same limit $f(l) \in \mathbb{R}$ . But this is not possible because $|f(x_{n_{k(l)}}) - f(y_{n_{k(l)}})| > \epsilon$ for all $n_{k(l)}$ . Thus, there cannot exist such an $\epsilon > 0$ , and the proposition follows. $\square$","['metric-spaces', 'real-analysis', 'continuity', 'solution-verification', 'compactness']"
3745378,Integral $\int_0^{\infty} \arctan{\left(\frac{n}{\cosh{(x)}}\right)} \mathop{dx}$,"I want to evaluate the integral $$\int_0^{\infty} \arctan{\left(\frac{n}{\cosh{(x)}}\right)} \mathop{dx}$$ I think the integral evaluates to $$\frac{\pi}{2} \ln{\left(\sqrt{n^2+1}+n\right)}$$ but I dont know how really!  I think $n$ is any number but I dont know for sure!
The answer reminds me of $\int \frac{\pi}{2} \sec{x} \mathop{dx}$ and $n=\tan{x}$ . I got to $$\int_0^{\infty} \arctan{\left(\frac{e^{x} n}{e^{2x}+1}\right)} \mathop{dx}$$ $$\int_0^{\infty} \arctan{\left(\frac{n}{2}\frac{e^{x} +e^x}{e^{x}\cdot e^x+1}\right)} 
\mathop{dx}$$ Reminds me of $\tan{a-b}$ but the $n/2$ factor?","['integration', 'calculus']"
3745400,"What is the Covariance of Two Bernoulli Random Variables coming from the same sample, under design-based approach?","The scenario for the question is as follows:
We draw a sample of size n from a population of size N. Assume a design-based approach (meaning the variable of interest $y_i$ (where $i$ represent the $i^{th}$ unit in the population) has fixed value and is unknown. The random variable $Z_1, Z_2, Z_3, ....Z_i..., Z_N$ represent if the $i_{th}$ unit in the population is in sample or not. In other words: $Z_i = 1$ if unit i is in the sample, and equals $0$ otherwise. We choose an Simple Random Sample (SRS) of size n out of the N population units, and the $Z_i$ 's are identically distributions Bernoulli random variable with $p_i=P(Z_i=1)=P(select\space unit\space i \space\ in\space the \space sample)=n/N$ and $P(Z_i=0)=P(select\space unit\space i \space\ in\space the \space sample)=(1-(n/N))$ The question involves finding the value for $E[Z_iZ_j]$ and $Cov(Z_i, Z_j)$ My questions are the following: 1.) What is the meaning of the random variable $Z_iZ_j$ ? From what I understand, it is a function tha maps from the set of all possible outcomes to the real numbers. There are 4 possible outcomes concerning the combination of the two random variables $Z_i$ and $Z_j$ : 1.) both are in sample, 2.) both are not in sample, 3.) i is in sample, j is not in sample, 4.) i is not in sample, j is in sample. The caluclation of $E[ZiZj]$ given in the textbook (Sampling: Design and Analysis, by  Sharon Lohr, second edition, page 52, if you happen to have the book) considers only the conditional probability of both units in sample when calculating the expectation. I can find the probability for each of the 4 scenarios listed above, but i do not understand what value should they take on. The calculation in the textbook is as follows: $E[Z_iZ_j]=P(Z_i=1 \space and \space Z_j=1) = P(Z_i=1 \space | \space Z_j=1)*P(Z_i =1)
= (\frac{n-1}{N-1})*(\frac{n}{N})$ Why is the other scenarios not considered? And why is the value for this scenario set to 1? Second Question: the calculation for Covariance is given as follows: $Cov(Z_i, Z_j)=E[Z_i Z_j]-E[Z_i]E[Z_j]=(\frac{n-1}{N-1})*(\frac{n}{N}) - (\frac{n}{N})^2=-(\frac{1}{N-1})*(1-\frac{n}{N})*\frac{n}{N}$ How did the derivation from the second last line to the last line happen? Thank you.","['statistics', 'covariance', 'expected-value', 'sampling', 'random-variables']"
3745468,Solving $\int \sqrt {f(x)} \ dx=\sqrt{\int f(x)\ dx}$,"I am trying to solve the following differential equation: $$\int \sqrt {f(x)} \ dx=\sqrt{\int f(x)\  dx}$$ My approach: I started by differentiating both sides and got: $$\sqrt {f(x)}=f(x) \frac{1}{2\sqrt{\int f(x)\  dx}}$$ We can isolate the $2\sqrt{\int f(x)\  dx}$ in the left side: $$2\sqrt{\int f(x)\  dx} = \sqrt{f(x)}$$ We can now square both sides: $$4\int f(x)\  dx = f(x) \ \ \ \ \ \ \ \ \ (1)$$ We can again differentiate both sides and get: $$4f = f'$$ And the solution of this equation is: $f(x)= Ce^{4x}$ My question is the following: In the step where I putted a (1), it should be $$4 \left|\int f(x)\  dx\right| = |f(x)|$$ Instead of $4\int f(x)\  dx = f(x)$ , because $\sqrt{a}^2 = |a|$ . How could I solve this differential equation if I did not make the assumption that $f(x) > 0$ and $\int f(x) dx > 0$ and got rid of the modulus?","['integration', 'ordinary-differential-equations']"
3745518,When to apply complex integration for integral resolutions,"Is there a criterion, a clue that makes me think that certain integrals can also be solved through complex integration and how to solve them? When I can't solve an integral for my students of a high school, I use the numerical methods. If I have these integrals how are they solved used the complex integrations? First integral : $${\displaystyle\int_0^{2\pi}}\dfrac1{2\cos\left(x\right)+5}\,\mathrm{d}x={\displaystyle\int_0^{2\pi}}\dfrac{\sec^2\left(\frac{x}2\right)}{3\tan^2\left(\frac{x}2\right)+7}\,\mathrm{d}x \tag 1$$ I remember that $-2\leq 2\cos x\leq 2 \to 0<3\leq 2\cos x+5\leq 7$ . Hence $2\cos x+5\neq 0, \forall x\in\Bbb R$ . Using the substitution $t=\dfrac{\sqrt{3}\tan\left(\frac{x}2\right)}{\sqrt{7}}$ I will have $$\mathrm{d}x=\dfrac{2\sqrt{7}}{\sqrt{3}\sec^2\left(\frac{x}2\right)}\,\mathrm{d}t$$ Starting from the $(1)$ I will have $$(1)={\displaystyle\int_0^{2\pi}}\dfrac{2\sqrt{7}}{\sqrt{3}\left(7t^2+7\right)}\,\mathrm{d}t$$ and with easy steps I have: $$=\left[\dfrac{2\arctan\left(\frac{\sqrt{3}\tan\left(\frac{x}2\right)}{\sqrt{7}}\right)}{\sqrt{21}}\right]_0^{2\pi}=\dfrac{2{\pi}}{\sqrt{21}}$$ Second integral : remember that $(x^2+1)^2\ne 0, \forall x\in\Bbb R$ . $$\displaystyle\int\limits^{+\infty}_{-\infty} \dfrac{\mathrm{d}x}{\left(x^2+1\right)^2}$$ Apply reduction formula: $$\small{{\displaystyle\int}\dfrac1{\left(\mathtt{a}x^2+\mathtt{b}\right)^{\mathtt{n}}}\,\mathrm{d}x=\class{steps-node}{\cssId{steps-node-1}{\dfrac{2\mathtt{n}-3}{2\mathtt{b}\left(\mathtt{n}-1\right)}}}{\displaystyle\int}\dfrac1{\left(\mathtt{a}x^2+\mathtt{b}\right)^{\class{steps-node}{\cssId{steps-node-2}{\mathtt{n}-1}}}}\,\mathrm{d}x+\dfrac{x}{2\mathtt{b}\left(\mathtt{n}-1\right)\left(\mathtt{a}x^2+\mathtt{b}\right)^{\class{steps-node}{\cssId{steps-node-3}{\mathtt{n}-1}}}}}$$ I have: $$\begin{aligned}&=\dfrac{x}{2\left(x^2+1\right)}+\dfrac12\int_{-\infty}^{+\infty}\frac1{x^2+1}\,\mathrm{d}x\\&=\lim_{p\to+\infty}\left[\dfrac{\arctan\left(x\right)}2+\dfrac{x}{2\left(x^2+1\right)}\right]_{-p}^p=\frac \pi2\end{aligned}$$ Third example : Obviously it must be $\sqrt{x}\left(x+1\right) \neq 0 \iff x>0$ $${\displaystyle\int_0^{+\infty}}\dfrac1{\sqrt{x}\left(x+1\right)}\,\mathrm{d}x$$ If I take $t=\sqrt{x} \to \mathrm{d}x=2\sqrt{x}\,\mathrm{d}t$ . When with simple steps I will find $$=\lim_{p\to+\infty}\left[2\arctan\left(\sqrt{x}\right)\right]_0^p=\pi$$ Thank you all very much and I hope always the best for all users.","['integration', 'definite-integrals', 'complex-analysis', 'contour-integration', 'soft-question']"
3745550,Why is this map between Riemann surfaces a covering map?,"In Donaldson's book http://wwwf.imperial.ac.uk/~skdona/RSPREF.PDF Theorem 3 of Chapter 6 asserts that, given a compact Riemann surface $X$ with a holomorphic 1-form with no zeros $\omega$ , there is a lattice $\Lambda \subset \mathbb{C}$ and isomorphism $\mathbb{C}/\Lambda \cong X$ identifying $\omega$ with $dz$ . The proof starts by considering the universal covering space $p:\tilde{X} \to X$ . We then note that there exists a holomorphic function $F: \tilde{X} \to \mathbb{C}$ such that $dF = p^*\omega$ . This last equation implies in particular that $F$ is a local homeomorphism. The next claim is that $F$ is actually a covering map. I am confused because the proof given in the book doesn't seem to show that $F$ is surjective. Is there a simple way of seeing that?","['complex-analysis', 'riemann-surfaces', 'general-topology']"
3745694,Algorithm to find the chromatic number of a graph (its not greedy)!!,"I have thought of an algorithm to find the chromatic number of a graph but I don't know whether it's right or not. Could someone confirm this for me? So it works like this: Suppose we take the graph with $N$ vertices (say $v_1,v_2,v_3\dots v_n$ ). We denote a chromatic number by $x$ , which is initialised by $0$ for now and take an empty set $z=\{\}$ , which will contain all the nodes that we choose from the graph for finding the chromatic number. Now basically what we do is, we take the node with highest degree (say $v_m$ ) and add it to our set $z$ and increment $x$ by $1$ . Now we take the node adjacent to $v_m$ (say $v_l$ ) and compare it with the nodes present in our set $z$ , for checking its adjacencies. If we find any node non-adjacent to the selected node, we give them the same colour, and $x$ remains the same. But if we don't, then we add the element to our set and increment $x$ by $1$ . Now suppose we don't find any node, so now our set is $z=\{v_m,v_l\}$ and $x=2$ . please note that if we have multiple nodes connected to the node with the our currently selected node i.e the node of the maximum degree for now  then what we do is we compare their degrees(but not the actual ones)we calculate their degree only by making their connections with the nodes that already exist in our set.we don't take into account their connections with the nodes that are not n the set. if after comparison also the degree of the adjacent nodes are same , then what we randomly select any node. Now we take the next node by comparing the degree(degrees are calculated based on the method above) of all the adjacent nodes that are adjacent to our previously selected nodes and in them we select the nodes which have the highest degree or multiple nodes having same degree  we colour them according to the set based method stated above. We repeat the same process for the other nodes, but the thing to note here is whenever we find a node non-adjacent to given node in the set, we first traverse all the elements that are having the same colour to the element which is non-adjacent to the current element. if we can't go to any other node in the latter stages of this process then what we do is search for the next node with the highest degree among all the remaining nodes. For making a record of all the elements which are having the same colour, we are maintaining $z$ . For example, $\{\{v_r,v_m\},v_l\}$ where $v_r$ and $v_l$ have the same colour. Each time we don't find any node non-adjacent to our current node, we add it to our set and increment $x$ by $1$ . After traversing all the nodes, the number of elements in the set $z$ is the chromatic number of the graph. One thing to note here is whenever we find a node non-adjacent to the current node, we insert it in our set $z$ at the position of the non-adjacent node in the form of nested sets in the set $z$ . But firstly we store the current node in the beginning of the nested set, and push back all the nodes available in the nested set. So that next time we compare a node in the set, we first compare the most recent node to save time. If we find any node which is adjacent to the current node in the nested set, we break our check and move to the other nested sets of the parent set $z$ .","['graph-theory', 'coloring', 'discrete-mathematics']"
3745781,Find value of $\dfrac{(1+\tan^2\frac{5\pi}{12})({1-\tan^2\frac{11\pi}{12}})}{\tan\frac{\pi}{12}\tan\frac{17\pi}{12}}$,My attempt : $$\dfrac{\left(1+\tan^2\dfrac{5\pi}{12}\right)\left(1-\tan^2\dfrac{\pi}{12}\right)}{\tan\dfrac{\pi}{12}\tan\dfrac{5\pi}{12}}$$ Change into variable form $$\dfrac{(1+a^2)(1-b^2)}{ab}$$ $$\dfrac{1+a^2-b^2-a^2b^2}{ab}$$ I'm stuck here also I don't think this is the correct way.,['trigonometry']
3745803,Expected number of cards in original position in a shuffled deck of $52$ cards?,Assume is shuffle is quite good that it randomizes the card order. We know that E = $ \sum_{X=1}^n X*P(X) $ We are already know that n=52 and that there are 52! ways to arrange the cards. So probability that exactly 1 card is in correct position is $\frac{1}{52!} {52 \choose 1}*$ (derangements of remaining cards) This will be summed over all the 52 cases. This seems a bit complicated. Is there a simpler way?,"['permutations', 'expected-value', 'combinatorics', 'probability']"
3745883,"Interpretation of $\mathbb R^d \times \{1,2\}$?","I need help with this notation from Wikipedia : Suppose we have pairs $(X_1,Y_1), (X_2,Y_2), \dots, (X_n,Y_n)$ taking values in $\mathbb R^d \times \{1,2\}$ . Does it mean the following: $X_1, X_2, \dots, X_n$ are the first elements in the pairs so they take values in the set $\mathbb R^d$ . \begin{align}
X_1 &\in \mathbb R^d, 
\quad \text{i.e.} \quad 
X_1=(X_{11}, X_{12}, \dots, X_{1d} )
\tag 1
\\
X_2 &\in \mathbb R^d,
\quad \text{i.e.} \quad 
X_2=(X_{21}, X_{22}, \dots, X_{2d} )
\tag 2
\\
&\vdots \\
X_n &\in \mathbb R^d,
\quad \text{i.e.} \quad 
X_n=(X_{n1}, X_{n2}, \dots, X_{nd} )
\tag 3
\\
\end{align} $Y_1, Y_2, \dots, Y_n$ are the second elements in the pairs so they take one value in the set $\{1,2\}$ , i.e. $1$ or $2$ . \begin{align}
Y_1 &\in \{1,2\},
\quad 
\text{i.e.}
\quad
Y_1=1 \quad \text{or} \quad Y_1=2
\tag 4
\\
Y_2 &\in \{1,2\},
\quad 
\text{i.e.}
\quad
Y_2=1 \quad \text{or} \quad Y_2=2
\tag 5
\\
&\vdots 
\\
Y_n &\in \{1,2\},
\quad 
\text{i.e.}
\quad
Y_n=1 \quad \text{or} \quad Y_n=2
\tag 6
\end{align} Is this correct?","['elementary-set-theory', 'calculus', 'notation', 'real-analysis']"
3745912,"Proving $(a+b+c)\left(\frac{1}{a}+\frac{1}{b}+\frac{1}{c}\right)+3\ge 4\cdot \frac{a+b+c}{\sqrt[3]{abc}}$ for positive $a$, $b$, $c$","For $a,b,c>0$ Prove that $$(a+b+c)\left(\frac{1}{a}+\frac{1}{b}+\frac{1}{c}\right)+3\ge 4\cdot \frac{a+b+c}{\sqrt[3]{abc}}$$ My attempt: By AM-GM we obtain $$\frac{a}{b}+\frac{a}{b}+\frac{b}{c}\ge 3\sqrt[3]{\frac{a^2}{bc}}=\frac{3a}{\sqrt[3]{abc}}$$ Thus $$\sum \frac{a+c}{b}\ge \frac{2(a+b+c)}{\sqrt[3]{abc}}$$ So it suffices to show that $$6\ge \frac{2(a+b+c)}{\sqrt[3]{abc}}\Leftrightarrow 3\sqrt[3]{abc}\ge a+b+c$$ Which is clearly wrong. :""( Thank you very much.","['algebra-precalculus', 'symmetric-polynomials', 'a.m.-g.m.-inequality', 'inequality']"
3745925,Is this a sufficient condition for the integral to be greater than $m$?,"It is given that $f:\mathbb R \to \mathbb R$ is positive continuous function. If it is positive then it means that it never goes below the $x-$ axis. I want to find a sufficient condition such that we have $$
\int_{0}^{1} f(x) dx \gt m 
$$ ( $m$ is a positive number). I thought that this problem wants us to find a necessary condition such that the area under $f$ in the interval [0,1] is greater than the area of rectangle of length 1 and height $m$ . I thought that as the function is always positive, so if it ever goes above $m$ for any $x$ , that is $$
\exists x ~~~~~ f(x) \gt m
$$ Then the area will be more than the rectangle. I want to know if my thinking is true?","['integration', 'functions']"
3745985,Seeking some easier method to prove the identity,"I came across the identity Let $n$ and $m$ be natural numbers and $p_{1}, p_{2}, p_{3}...p_{n}$ be real numbers. Prove that if any $a_{1},a_{2},..a_{k}$ for any $ k\le n$ ramdomly chosen from the set $S$ = { $p_{1}, p_{2}, p_{3}...p_{n}$ } follow $$ \prod_{i=1}^{k} a_{i} = \sum_{i = 1}^{k}a_{i}-k+1$$ then $$(\prod_{i=1}^{n} p_{i})^{m} =  (\sum_{i = 1}^{n}p_{i}-n+1)^{m} = \sum_{i=1}^{n}p_{i}^{m}-n+1 $$ MY TRY :- For e.g. for $n=2$ we have $pq=p+q-1$ and we need to prove that $(p+q-1)^{m} = p^{m}+q^{m}-1$ but as pointed out by Wolfgang Kais it is fairly simple as the equation $p+q-1 = pq$ is satisfied if and only if $(p-1)(q-1) = 0\implies$ either $p=1$ or $q=1$ which then is simple to prove. I also proved it for any n using induction. I have written the method in answer. But it took a large calculation to do it. I suppose there will definitely be some easier method to prove it. Any help will be highly appreciated. Please ask for clarifications in case of discrepencies.","['summation', 'solution-verification', 'symmetric-polynomials', 'discrete-mathematics', 'induction']"
3745991,A question on proving an equation to be an $n$-linear system in linear algebra,"While studying Determinants from text book Hoffman and Kunze, I have a in an argument in a theorem whose reasoning is not provided . Questions:
1st question is in underlined part of theorem. It's image : How did authors deduced that $A_{ij} D_{ij}(A) $ is n-linear function of A? Question 2:  How does author derived the last line which is ""Therefore $ E_{j} (A) $ = $(-1)^{k+j} $ .... . Can anyone please give some hints. Any help would be really appreciated",['linear-algebra']
3746061,"A ""paradox"" in the odds of being the minimum variable in a set of IID variables","This question arose when I was trying to find the odds that a customer is served before the customer directly ahead of him in an M/M/m queueing system. For a a RV in a set of IID RV of size N, is the probability of being the minimum value the same as the probability of being less than the minimum value of a set of size N - 1? Let's say you have 10 IID exponentially distributed random variables.
You pick label one variable as ""A"" arbitrarily and ask this question: What is the probability that A is the minimum of the set of 10? Obviously because they are IID, the answer is 1/10. Yet I have an issue. It seems true that the question ""Is A the minimum"" is equivalent to the question ""Is A less than the minimum of the other 9"". The minimum of 9 exponentially distributed variables with parameter lambda has mean $$\frac {1}{9\lambda} $$ So to find the probability of A being less than the other nine, I took the integral $$\int_{0}^{\frac {1}{9\lambda}} \lambda e^{-\lambda x} d x $$ But this evaluates to $$ 1 - e^{\frac{1}{9}} \ne \frac{1}{10}$$ Where have I gone wrong?","['statistics', 'probability-theory', 'probability']"
3746078,For which $k$ does $(a+b+c)\left(\frac{1}{a}+\frac{1}{b}+\frac{1}{c}\right)+k-3\ge \left(2+\frac k3\right)\cdot \frac{a+b+c}{\sqrt[3]{abc}}$ hold?,"By generalizing this (1) and this (2) questions and performing some research $$(a+b+c)\left(\frac{1}{a}+\frac{1}{b}+\frac{1}{c}\right)+k-3\ge \left(2+\frac k3\right)\cdot \frac{a+b+c}{\sqrt[3]{abc}},\hbox{ for }a,b,c>0$$ for all $0\le k<k_0\approx 11.108$ . The main goal was to prove the original inequality from (2), however, letting $a=x^3,\,b=y^3,\,c=z^3$ and clearing the denominator, the inequality becomes $$3 k x^3 y^3 z^3 + 3 \sum\limits_{sym}x^6 y^3 z^0 - \left(3+\frac k2\right)\sum\limits_{sym} x^5 y^2 z^2\ge 0\tag{1}$$ and I'm failing to apply Muirhead's inequality . The method from this answer works only for $k\le 3$ , and even with calculus I don't think that solving system of $3$ equations like $\frac{\partial}{\partial x}$ LHS(1) $=0$ : $$5 k x^3 y^2 z^2 - 9 k x y^3 z^3 + 2 k y^5 z^2 + 2 k y^2 z^5 - 18 x^4 y^3 - 18 x^4 z^3 + 30 x^3 y^2 z^2 - 9 x y^6 - 9 x z^6 + 12 y^5 z^2 + 12 y^2 z^5=0$$ may lead to something neat.) Any help is appreciated. Thanks. The question : what is $k_0$ .","['uvw', 'multivariable-calculus', 'symmetric-polynomials', 'optimization', 'inequality']"
3746084,Evaluate $\int_0^{\infty} x^2\ln(\sinh x)\operatorname{sech}(3 x){\rm d}x $.,"Problem Evaluate $\displaystyle\int_0^{\infty} x^2\ln(\sinh x)\operatorname{sech}(3 x){\rm
 d}x .$ Someone writes as follows \begin{align*}
&\int_0^{\infty} x^2\ln(\sinh x)\operatorname{sech}(3 x){\rm
 d}x\\
=&\frac{1}{27}\int_0^{\infty} x^2\ln\left(\sinh \frac{x}{3}\right)\operatorname{sech}(x){\rm
 d}x\\
 =&\frac{2}{27}\int_0^{\infty} \frac{x^2e^{x}}{e^{2x}+1}\ln\left(\frac{e^{\frac{2x}{3}}-1}{2e^{\frac{x}{3}}}\right){\rm
 d}x\\
 =&\frac{2}{27}\int_0^{\infty} \frac{x^2e^{x}}{e^{2x}+1}\left[\ln\left(e^{\frac{2x}{3}}-1\right)-\frac{x}{3}-\ln2\right]{\rm
 d}x.
\end{align*} This will help?","['integration', 'calculus', 'improper-integrals']"
3746107,Recursive formula for number of $n\times m\times p$ cubes of $0$'s and $1$'s with a special property.,"If $L(n, m)$ denotes the number of $n\times m$ matrices consisting only of $0$ 's and $1$ 's, such that there is no column or row consisting only of $0$ 's, we get a nice recursive formula which enables us to compute them with ease: $$\sum_{j=1}^m \binom{m}{j} L(n, j) = (2^m-1)^n.$$ Now, let's consider two kinds of numbers, $L_1(n, m, p)$ and $L_2(n, m, p)$ . The first kind of numbers will be the amount of $n\times m\times p$ cubes consisting only of $0$ 's and $1$ 's such that if we cross the cube with a line perpendicular to one of the axis, we get a non-zero vector. $L_2(n, m, p)$ is defined the same, expect that instead of taking lines, we take planes orthogonal to one of the axis. Clearly $L_1(n, m, p)\leq L_2(n, m, p)$ . Can we get a similar nice looking recursive formula for these numbers? Perhaps in terms of $L(n, m)$ ? To be more precise, let me try to explain what exactly do I mean with $L_1(n, m, p)$ . For example, you take some $1\leq i\leq n$ , $1\leq j\leq m$ then for the cube $B$ we need to have $B_{ijk} = 1$ for some $1\leq k\leq p$ . Similarly, with $L_2(m, n, p)$ we can take some $1\leq i\leq n$ , then there must be $1\leq j\leq m$ , $1\leq k\leq p$ such that $B_{ijk} = 1$ .",['combinatorics']
3746124,prove $-\frac{c' x}{c(x)}$ is decreasing. falling elasticity.,"Something was asserted without proof in an economics paper but I would like to see it proven. Suppose $$
c(x) = p + v\cdot t(x),
$$ where $t>0$ , $t'<0$ , $t''>0$ , $p>0$ , $v>0$ and $c\rightarrow \infty$ as $x\rightarrow 0$ . It's claimed that $$
-\frac{c'(x)x}{c(x)}
$$ is positive but decreasing---i.e., that the elasticity of $c(x)$ is falling in magnitude. Obviously it is positive (since $c'<0$ ) but I don't know how to prove it's decreasing. I guess that means $$
\frac{d}{dx} \frac{c'\cdot x}{c} = \frac{1}{c}\left[
c'' x + c' - \frac{(c')^2x}{c}
\right]=
\frac{1}{p+v t(x)}\left[
vt''(x) x + vt'(x) - \frac{(vt'(x))^2x}{p+vt(x)}
\right]
>0.
$$ I am unable to prove this to be so.","['economics', 'derivatives']"
3746143,Prove that $TK=TO$,"Given $\triangle ABC$ such that $\angle A=90^\circ$ inscribed in circle with center $O$ . Let $D$ be the feet perpendicular from $A$ to $BC$ and $M$ be the mid-point of $BD$ . Draw the line $AM$ and let it intersect the circumcircle at $X$ . Let $K$ be the point on $AX$ such that $OK//XC$ . Lastly, denote $T$ as the intersection of the perpendicular from $AX$ at $K$ to $XC$ . Prove that $TK=TO$ I do some angle chasing but I haven't use anything that the problem given like the perp and midpoint for example, as I dun know how I could apply it. BTW, my approach is to prove that $\angle{BCA}=\angle{TOC}$ or perhaps prove that $\triangle ABX$ is similar to $\triangle TOC$ . Please help","['contest-math', 'euclidean-geometry', 'geometric-construction', 'geometry', 'plane-geometry']"
3746190,How find this nice minmum of this value $\frac{\prod_{i=1}^{n-1}(a_{i}+a_{i+1})\sum a_{i}}{\prod_{i=1}^{n}a_{i}}$,"Let $n$ be give postive integer number. For any $a_{i}>0 (i=1,2,\cdots,n)$ , find the minimum of the value $$F_{n}(a_{1},a_{2},\cdots,a_{n})=\dfrac{(a_{1}+a_{2})(a_{2}+a_{3})\cdots (a_{n-1}+a_{n})(a_{1}+a_{2}+\cdots+a_{n})}{a_{1}a_{2}a_{3}\cdots a_{n}}.$$ (by wang yong xi) I try when $n=2$ ,then $$F_{2}(a_{1},a_{2})=\dfrac{(a_{1}+a_{2})(a_{1}+a_{2})}{a_{1}a_{2}}=\dfrac{(a_{1}+a_{2})^2}{a_{1}a_{2}}\ge 4$$ when $a_{1}=a_{2}$ is minimum (2):when $n=3$ , $$F_{3}=\dfrac{(a_{1}+a_{2})(a_{2}+a_{3})(a_{1}+a_{2}+a_{3})}{a_{1}a_{2}a_{3}}$$ WLOG $a_{3}=1$ ,so $$F=\dfrac{(a_{1}+a_{2})(a_{2}+1)(a_{1}+a_{2}+1)}{a_{1}a_{2}}$$ I use this find this minimum is $$(F_{3})_{min}=\dfrac{1}{2}(11+5\sqrt{5})$$ when $a_{1}=1,a_{2}=\dfrac{\sqrt{5}-1}{2}$ see links","['inequality', 'real-analysis']"
3746207,Presentation for the product of two cyclic groups,"I'm reading about generators and relations and an example that has come up is the following. Let $A$ and $B$ be two cyclic groups with generators $a$ (of order $j$ ) and $b$ (of order $k$ ), respectively. Their product $A\times B$ is generated by all products of the form $a^m b^n$ with relations $$
a^j = 1 \qquad b^k = 1 \qquad ab = ba
$$ My question is how to understand the last relation, $ab = ba$ . Should I think of this as coming from the isomorphism $A \times B \cong B \times A$ , or is there a more fundamental reason for this relation?","['group-presentation', 'cyclic-groups', 'combinatorial-group-theory', 'abstract-algebra', 'group-theory']"
3746247,Prove that commuting matrices over an algebraically closed field are simultaneously triangularizable.,"Given an algebraically closed field $\mathbb K$ and matrices $A, B \in \mathbb K^{n \times n}$ such that $A B = B A$ , show that $A$ and $B$ are simultaneously triangularizable, i.e., show that there exists a matrix $T$ such that $T^{-1} A T$ and $T^{-1} B T$ are both upper triangular.","['matrices', 'triangularization', 'linear-algebra']"
3746277,a name for a class of cardinals,I'm not a native English speaker; what S in SCar below might stand for ?,"['elementary-set-theory', 'cardinals', 'forcing', 'terminology']"
3746296,Determine the value of ${k}$ for quadratic roots,"Solve for ${k}$ ${kx^2-2kx+5=0}$ ; one root exceeds the other by 3. I tried using the ${x_1 \times x_2 = c/a}$ and the ${x_1+x_2 = -b/a}$ , I don't know if it has something to do with the discriminant somehow but I doubt it. Any help towards my understanding is greatly appreciated.","['algebra-precalculus', 'functions', 'quadratics']"
3746329,"Calculate $\lim\limits_{(x,y) \to (0,0)} \frac{2^{xy}-1}{ |x|+|y| }$","I need to calculate the following limit: $$\lim\limits_{(x,y) \to (0,0)} \frac{2^{xy}-1}{ |x|+|y| }$$ I know that the answer is $0$ , but I don't know how to prove it. I tried to use the squeeze theorem, but got stuck: $$ 0\le \Bigg|\frac{2^{xy}-1}{ |x|+|y|}\Bigg|\le \Bigg|\frac{2^{xy}-1}{ |x|}\Bigg|$$ Is there a way to continue from here?","['limits', 'multivariable-calculus']"
3746408,The sum of these 9! determinants is? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question (image is attached for those who think I have changed the statement of the question while copying from the book) Chose any 9 distinct integers. These 9 integers can be arranged to from 9! determinants each of order 3. The sum of these 9! determinants is? My approach For any Δ, there exist -Δ in arrangements ∴ sum = 0 I am looking for another approach!","['determinant', 'combinatorics']"
3746433,Mollifiers and Banach space valued functions,"In Section 5.9.2 of Evans PDE, it gives some properties of Sobolev space involving time. Suppose $u\in L^2(0,T;H_0^1(U))$ . Extend $u$ to be $0$ on $(-\infty,0)$ and $(T,\infty)$ and then set $u^\varepsilon=\eta_\varepsilon\ast u$ , $\eta_\varepsilon$ denoting the usual mollifier on $\mathbb{R}^1$ . In the proof of Theorem 3, it says that ""Fix any point $s\in (0,T)$ for which $$
u^\varepsilon(s)\rightarrow u(s) \text{ in }L^2(U).""
$$ My questions are: why can we find such $s$ ? Since $u^\varepsilon\rightarrow u$ in $L^2(0,T;H_0^1(U))$ , it seems that we can only get a subsequence of $u^\varepsilon$ converging to $u$ almost everywhere? Why consider convergence in $L^2(U)$ not in $H_0^1(U)$ ?","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
3746454,The Essence of Generation Functions and Coefficient Extraction,"Given the roles generating functions and coefficient extraction play in solving recurrence relations, they are clearly analogous to the Laplace Transform and Inverse Laplace Transform.  A hypothesis would then be that generating functions transform a problem from the time domain to the frequency domain, and coefficient extraction transforms a problem from the frequency domain to the time domain.  However, the integrand of a Laplace Transform multiplies the input function by a decaying exponential, whereas the ""inside"" of a generating function multiplies the input function by a growing polynomial.  The shift between exponential and polynomial is common when switching between ODEs and recurrence relations; the eigenvalues of the same characteristic polynomial go in the exponent for linear ODEs and in the base for linear recurrence relations, but this takes place without sign change.  The shifting VS growing distinction between Laplace Transforms and generating functions remains unexpected.  Thus a generating function behaves more like the Inverse Laplace Transform in this respect, leaving coefficient extraction to perhaps play the role of the Laplace Transform.  What shifts in domain are taking place when generating functions and when coefficient extraction are applied?","['inverse-laplace', 'laplace-transform', 'recurrence-relations', 'discrete-mathematics', 'generating-functions']"
3746503,"If $\forall n \in \mathbb Z_{\ge0} \ $ and $\forall x \in \mathbb R$, we know that $\big|f^{(n)}(x)\big|\le \big|p(x)\big|$, then $f=0$.","If $p(x)$ is an odd degree polynomial such as $\forall   n \in \mathbb Z_{\geq 0}$ and $\forall x \in \mathbb R$ we know that $$\big|f^{(n)}(x)\big|\le \big|p(x)\big|\,.$$ I need to show that $\forall x \in \mathbb R \ $ $f(x)=0$ . My thoughts till now: I tried to use Taylor polynomial but it didn't help. and I really need help. Thanks in advance.","['taylor-expansion', 'calculus', 'derivatives', 'polynomials']"
3746522,Primes Powers and Mods [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question The Question is below: For which primes $p$ is $(p − 1)^p + 1$ a power of $p$ ? I think the answer is $2$ and $3$ , none of the others work. Here is what I have: let $p^k-1=(p-1)^p$ . Then we have $$p^{k-1}+...+p+1 \equiv0 \pmod{p-1}.$$ Please also include a proof of your answer","['number-theory', 'modular-arithmetic', 'elementary-number-theory']"
3746539,How many number of paths are there,"How many number of paths are there from (0, 0) to (4, 4) using the moves R : (x, y) → (x + 1, y),  U : (x, y) → (x, y + 1), D : (x, y) → (x + 1, y + 1) ;
where a path can never rise above the line y = x.  Solve this problem by using Catalan Numbers. I know the n-th Catalan Number formula $$C_n = \left(\frac{1}{n+1}\right) {2n \choose n}$$ but I don't understand the connection between Catalan numbers and to getting (4,4) from (0,0)","['catalan-numbers', 'discrete-mathematics']"
3746615,Is there a matrix $C$ that can make $AB$ return the same result as $BA$ where $C$ is based on $B$?,"I am given an arbitrary matrix $A$ that I will be multiplying by a rotational matrix $B$ ( both $4\times4$ ) Is there any matrix $C$ , based only on manipulation of matrix $B$ , that when doing $A(BC)$ will produce the same result as $BA$ ? $BA = A(BC)$ I am trying to find some sort of abstract solution for making matrix multiplication commutative If it can not only be based on matrix $B$ , is there any way to find that matrix $C$ if using matrix $A$ as well? To clarify, let's define a matrix $D = BC$ . Is there a method to obtain a matrix $C$ such that $BA = AD$",['matrices']
3746630,Two different books are giving two different solutions.,"So I am solving some probability/finance books and I've gone through two similar problems that conflict in their answers. Paul Wilmott The first book is Paul Wilmott's Frequently Asked Questions in Quantitative Finance . This book poses the following question: Every day a trader either makes 50% with probability 0.6 or loses 50% with probability 0.4. What is the probability the trader will be ahead at the end of a year, 260 trading days? Over what number of days does the trader have the maximum probability of making money? Solution: This is a nice one because it is extremely counterintuitive. At first glance it looks like you are going to make money in the long run, but this is not the case.
Let n be the number of days on which you make 50%. After $n$ days your returns, $R_n$ will be: $$R_n = 1.5^n 0.5^{260−n}$$ So the question can be recast in terms of finding $n$ for which this expression is equal to 1. He does some math, which you can do as well, that leads to $n=164.04$ . So a trader needs to win at least 165 days to make a profit. He then says that the average profit per day is: $1−e^{0.6 \ln1.5 + 0.4\ln0.5}$ = −3.34% Which is mathematically wrong, but assuming he just switched the numbers and it should be: $e^{0.6 \ln1.5 + 0.4\ln0.5} - 1$ = −3.34% That still doesn't make sense to me. Why are the probabilities in the exponents? I don't get Wilmott's approach here. *PS: I ignore the second question, just focused on daily average return here. Mark Joshi The second book is Mark Joshi's Quant Job Interview Question and Answers which poses this question: Suppose you have a fair coin. You start off with a dollar, and if you toss an H your position doubles, if you toss a T it halves. What is the expected value of your portfolio if you toss infinitely? Solution Let $X$ denote a toss, then: $$E(X) = \frac{1}{2}*2 + \frac{1}{2}\frac{1}{2} = \frac{5}{4}$$ So for $n$ tosses: $$R_n = (\frac{5}{4})^n$$ Which tends to infinity as $n$ tends to infinity Uhm, excuse me what? Who is right here and who is wrong? Why do they use different formula's? Using Wilmott's (second, corrected) formula for Joshi's situation I get the average return per day is: $$ e^{0.5\ln(2) + 0.5\ln(0.5)} - 1 = 0% $$ I ran a Python simulation of this, simulating $n$ days/tosses/whatever and it seems that the above is not correct. Joshi was right, the portfolio tends to infinity. Wilmott was also right, the portfolio goes to zero when I use his parameters. Wilmott also explicitly dismisses Joshi's approach saying: As well as being counterintuitive, this question does give a nice insight into money management and is clearly related to the Kelly criterion. If you see a question like this it is meant to trick you if the expected profit, here 0.6 × 0.5 + 0.4 × (−0.5) = 0.1, is positive with the expected return, here −3.34%, negative. So what is going on? Here is the code: import random
def traderToss(n_tries, p_win, win_ratio, loss_ratio):
    SIM = 10**5 # Number of times to run the simulation
    ret = 0.0
    for _ in range(SIM):
        curr = 1 # Starting portfolio
        for _ in range(n_tries): # number of flips/days/whatever
            if random.random() > p_win:
                curr *= win_ratio # LINE 9
            else:
                curr *= loss_ratio # LINE 11

        ret += curr # LINE 13: add portfolio value after this simulation

    print(ret/SIM) # Print average return value (E[X]) Use: traderToss(260, 0.6, 1.5, 0.5) to test Wilmott's trader scenario. Use: traderToss(260, 0.5, 2, 0.5) to test Joshi's coin flip scenario. Thanks to the followup comments from Robert Shore and Steve Kass below, I have figured one part of the issue. Joshi's answer assumes you play once, therefore the returns would be additive and not multiplicative. His question is vague enough, using the word ""your portfolio"", suggesting we place our returns back in for each consecutive toss. If this were the case, we need the geometric mean not the arithmetic mean, which is the expected value calculation he does. This is verifiable by changing the python simulation to: import random
def traderToss():
    SIM = 10**5 # Number of times to run the simulation
    ret = 0.0
    for _ in range(SIM):
       if random.random() > 0.5:
                curr = 2 # Our portfolio becomes 2
            else:
                curr = 0.5 # Our portfolio becomes 0.5

        ret += curr 

    print(ret/SIM) # Print single day return This yields $\approx 1.25$ as in the book. However, if returns are multiplicative, therefore we need a different approach, which I assume is Wilmott's formula. This is where I'm stuck. Because I still don't understand the Wilmott formula. Why is the end of day portfolio on average: $$ R_{day} = r_1^{p_1} * r_2^{p_2} * .... * r_n^{p_n} $$ Where $r_i$ , $p_i$ are the portfolio multiplier, probability for each scenario $i$ , and there are $n$ possible scenarios. Where does this (generalized) formula come from in probability theory? This isn't a geometric mean. Then what is it?","['markov-chains', 'expected-value', 'markov-process', 'probability-theory', 'probability']"
3746672,Convergence of $\sum_{n=1}^{\infty} \frac{{(-1)}^n {2n \choose n}}{3^n}$,"Does the series converge absolute, converge conditionally, or diverge. $$\sum_{n=1}^{\infty} \frac{{(-1)}^n {2n \choose n}}{3^n}$$ I am confuse because doesnt $$\lim_{n \to \infty} \frac{{2n \choose n}}{3^n}=0$$ ?  Why doesnt this converge condiitonally at least and maybe absolutely?  Key says it diverges.","['summation', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
3746701,The solutions of $y'' = 2$ don't form a subspace,"""The solutions of $y'' = 2$ don't form a subspace - the right side $b=2$ is not zero."" This is a quote on page 172 of Intro to Linear Algebra by Strang. What does this mean? Can someone explain how a differential equation relates to the idea of subspaces, and then why this statement is correct (e.g. what characteristics of subspaces does $y''=2$ violate).","['linear-algebra', 'ordinary-differential-equations']"
3746713,Expressing logic symbols as words,"Im having a bit of trouble expressing the following into words. The question follows:
Consider the propositional values: $p\left(​n\right): ​n \text{​ is prime} $ $q\left(​n\right): ​n ​\text{ is even} $ $r\left(​n\right): ​n ​>2$ Express the following in words: $$\forall n \in \mathbb{Z} \left[\left(r\left(n\right)\land p\left(n\right)\right)  ⇒ \sim q\left(n\right)\right]$$ So far I have: For all n's that are integers, if both n is greater than 2 and prime then n cannot be even. I know what the symbols mean, but I'm not sure what words are deemed appropriate for statements. Thanks!","['logic', 'discrete-mathematics']"
3746723,Questions about distributing $k$ objects to $n$ recipients,"Rule: Distributions of $k$ objects to $n$ recipients can be done in $n^k$ ways with no restrictions and $n!$ ways when each recipient receives exactly one object. Obvious Examples: In how many ways can we distribute $70$ computers to $6$ schools s.t. no two  schools share a computer? The schools are recipients so for each computer we choose one of six  schools which can be done in $6^{70}$ ways by product rule. In how many ways can we permute the word ""house""? Each word has five places like this: __ __ __ __ __. And each place can receive any one of h, o, u, s, e. So for each letter we choose a place in one of $5, 4, 3, 2, 1$ ways so that there are $5!$ permutations by product rule. Confusing example: How many PINs of length four are there if each symbol in a PIN is chosen from the $26$ uppercase letters in the Roman alphabet and the ten digits? This below is how I thought about the confusing example: Let __ __ __ __ represent an arbitrary PIN where __ is a recipient. Then by the rule above, for every symbol we choose one of four places. But the problem is that after the fourth symbol we run out of places for symbols. Also, the answer given for this problem is $36^4$ which means the symbols are the recipients, not the places in a PIN. My questions: In problems like those above, how do we know which objects are recipients and which ones are receivables(receive-ees?) ? Also, in what way is the confusing example above different from the other two problems? Thanks.","['combinatorics', 'discrete-mathematics']"
3746745,Understanding a computer vision gravity vector detection algorithm/ Solving for an eigenvector,"Supposing we have a depth picture where objects from the picture have estimates $v \in \Bbb R^3$ of their surface normals,
vectors on walls that point horizontally, and vectors on flat surfaces that point either up to the sky or down to the ground. A computer vision algorithm I am reading about available here on page $2$ , right side of the page, explores an iterative algorithm to estimate a gravity vector. The paper is titled Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images . At step $i$ , after obtaining an estimate for our vector, say $g_i$ , we classify our local estimates of surface normal estimates from an image into two categories: $N_{||}$ , the set of vectors within an angle-error $d$ of being parallel to $g_i$ $N_{\perp}$ , the set of vectors within an angle-error $d$ of being perpendicular to $g_i$ , where initially $d$ is broad enough that almost all surface normals will belong to one of the two categories (but iteratively $d$ decreases). The algorithm treats the concatenation of the two categories of surface normals as column vectors of the corresponding matrices $M_{||}, M_{\perp}$ . Next, we solve for a new estimate $g_i^{*}$ , where the authors state without proof that solving for $\min_{ \{g:\|g\|_2=1 \}}\left(\sum\limits_{n \in N_\perp} \cos^2(\theta(n,g)) + \sum\limits_{n \in N_{\|}}\sin^2(\theta(n,g))\right)$ is equivalent to finding the eigenvector with the smallest eigenvalue of the $3 \times 3$ matrix: $M_\perp M_\perp^T- M_{\|}M_{\|}^T$ , where $\theta(n,g)$ is the angle between vectors $n,g \in \Bbb R^3$ . The first expression makes perfect sense, we are computing an optimal unit vector that is perpendicular to our horizontal surface normals, and parallel to the up facing surface normals. I am not sure why solving for the eigenvector solution with minimal eigenvalue is equivalent, and after some attempts manually to write examples I have not progressed any further. Any insights appreciated.","['matrices', 'linear-algebra', 'computer-vision', 'eigenvalues-eigenvectors']"
3746757,"Let $X$ be a normed vector space. Let $T,S$ be bounded linear operators such that $T^2=T,S^2=S,ST=TS$. Show either $T=S$ or $\|T-S\|\geq 1$","Let $X$ be a normed vector space.  Let $T,S$ be bounded linear operators such that $T^2=T,S^2=S,ST=TS$ . Show either $T=S$ or $\|T-S\|\geq 1$ . My observations: $1\leq\|S\|,1\leq \|T\|$ $\|T-S\|=\|T^2-S^2\|\leq\|T-S\|\|T+S\|$ Thus $1\leq \|T+S\|$ I am not sure how to proceed from here.",['functional-analysis']
3746769,Geometry solution involving complex numbers from USAMO,"Quadrilateral $AP BQ$ is inscribed in circle $ω$ with $∠P = ∠Q = 90^{\circ}$ and $AP = AQ < BP$ . Let $X$ be a variable point on segment $P Q$ . Line $AX$ meets $ω$ again at $S$ (other than $A$ ). Point $T$ lies on arc $AQB$ of $ω$ such that $XT$ is perpendicular to $AX$ . Let $M$ denote
the midpoint of chord $ST$ . As $X$ varies on segment $P Q$ , show that $M$ moves along a circle. (USAMO 2015/P2) Okay so, I'm studying geometry from the book EGMO by Evan Chan and this was a practice problem. The solution in the back of the book is the same as the one from Evan's 2015 USAMO notes. I am pretty much a newbie with geometry with complex numbers. Everything in his solution makes sense apart from this one part. Could somebody please explain that? Also was this question supposed to be trivial using complex geometry? (Just askin ). The solution is as follows: Toss on the complex unit circle with $a = −1$ , $b = 1$ , $z=-\frac{1}{2}$ . Let $s$ and $t$ be on the unit circle. We claim $z$ is the center. It follows from standard formulas that $x =\frac{1}{2}(s
 + t − 1 +\frac{s}{t})$ thus, $4 \cdot \mathrm{Re}(x) + 2 = s + t +\frac{1}{s}+\frac{1}{t}+\frac{t}{s}+\frac{s}{t}$ which depends only on $P $ and $Q$ , and not on $X$ . Thus, $4 \left| z − \dfrac{s + t}{2}\right|^2= |s + t + 1|^2 = 3 + (4 \cdot \mathrm{Re}(x )+ 2)$ does not depend on $X$ . Well I guess I get that $\mathrm{Re}(x)$ refers to the real part of $x$ but where does the quantity $4\cdot \mathrm{Re}(x)+2$ come from? Also in the next equation there is $4 \left|z − \dfrac{s + t}{2}\right|^2$ . Where does this come from? And why does not being dependent on $X$ mean done? Please forgive my stupidity in case this is all extremely trivial stuff.
Thanks a lot.","['contest-math', 'analytic-geometry', 'geometry', 'complex-numbers']"
3746826,"Prove $\, _6F_5\left(\{\frac12\}_5,\frac{5}{4};\frac{1}{4},\{1\}_4;-1\right)=\frac{2}{\Gamma \left(\frac{3}{4}\right)^4}$ and another","I found $2$ intersting hypergeometric identities on this site , which ultimately reduces to $$\small \ _4F_3\left(-\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2};1,1,2;1\right)-\frac{1}{8} \  _4F_3\left(\frac{1}{2},\frac{3}{2},\frac{3}{2},\frac{3}{2};2,2,3;1\right)=\frac{8}{\pi ^2}$$ $$\scriptsize \ _5F_4\left(\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2};1,1,1,1;-1\right)-\frac{1}{8} \ _5F_4\left(\frac{3}{2},\frac{3}{2},\frac{3}{2},\frac{3}{2},\frac{3}{2};2,2,2,2;-1\right)=\frac{2}{\Gamma \left(\frac{3}{4}\right)^4}$$ How to prove these identities? Any help will be appreciated. Update: I found another proof for the second result. Due to certain corollary of Dougall formula (see Thm $3.4.6$ in Special functions , Andrews&Askey&Roy), i.e. $$\, _6F_5\left(a,\frac{a}{2}+1,b,c,d,e;\frac{a}{2},a-b+1,a-c+1,a-d+1,a-e+1;-1\right)=\frac{\Gamma (a-d+1) \Gamma (a-e+1)}{\Gamma (a+1) \Gamma (a-d-e+1)} \ _3F_2(a-b-c+1,d,e;a-b+1,a-c+1;1)$$ We may set all $5$ parameters to be $\frac 12$ then recall from Clausen formula that $\, _3F_2\left(\frac{1}{2},\frac{1}{2},\frac{1}{2};1,1;z\right)$ $=\frac{4 K\left(\frac{1}{2} \left(1-\sqrt{1-z}\right)\right)^2}{\pi ^2}$ and special value of $K\left(\frac{1}{2}\right)$ to arrive at $$\, _6F_5\left(\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{5}{4};\frac{1}{4},1,1,1,1;-1\right)=\frac{2}{\Gamma \left(\frac{3}{4}\right)^4}$$ Furthermore the very well-poised parameter pair $\frac{5}{4};\frac{1}{4}$ allows us to decompose the series, completing the proof. Update $2$ : Using Jack's method and FL expansion given here one may prove an important result (also obtainable via Dougall $_5F_4$ ): $$\, _5F_4\left(\frac{1}{2},\frac{1}{2},\frac{5}{4},1-s,1-t;\frac{1}{4},s+\frac{1}{2},t+\frac{1}{2},1;1\right)=\frac{B(s+t-1,s+t-1)}{B(s,s) B(t,t)}$$ Provided that $s+t>1$ . Letting $s\to\frac32, t\to \frac12$ and eliminating the very first term yields $$\, _6F_5\left(\frac{1}{2},1,\frac{3}{2},\frac{3}{2},\frac{3}{2},\frac{9}{4};\frac{5}{4},2,2,2,3;1\right)=\frac{32}{5} \left(1-\frac{8}{\pi ^2}\right)$$ Which is equivalent to the first result after simplifications. In one word, both $2$ identities are not-so-trivial corollaries of Dougall formula.","['closed-form', 'special-functions', 'hypergeometric-function', 'sequences-and-series']"
3746874,Are there invertible functions such that $f=\frac{g}{h}$ and $f^{-1}=\frac{g^{-1}}{h^{-1}}$?,"Note: this question is inspired by this one: Why $\arctan x$ not equal to $\arcsin(x)/\arccos(x)$? In the linked question, it is said that if $f=\frac{g}{h}$ and $f$ , $g$ and $h$ are invertible, then $f^{-1}\neq \frac{g^{-1}}{h^{-1}}$ in general. This is clear that it is almost always the case after considering a few examples, but it may be possible that there exists invertible functions $f$ , $g$ and $h$ such that $f=\frac{g}{h}$ and $f^{-1}=\frac{g^{-1}}{h^{-1}}$ . I tried a few functions (linear functions, exponentials,...) but without an example. Are there any functions satisfying the above property? Mastrem's comment shows that a trivial solution exists with $f=g=h=id:\{1\}\to\{1\}$ . I am looking for a non-trivial example. Functions can have any domain and codomain, including finite ones, as soon as they have more than one point.","['algebra-precalculus', 'functions', 'examples-counterexamples', 'inverse-function']"
3746908,How to solve particular solution of a general differential equation involving $\cos^3 x$?,"My question was to solve, $(D^2 +2D +5) y= e^x \cos^3 x. \space$ I solved complementary function solution but got stuck in solving particular solution. I am attaching my solution where I stuck, please help me to solve it. Thanks a lot. Image of question and my attempt to solve","['calculus', 'ordinary-differential-equations']"
3746916,Finding presentation of subgroup in GAP,"If I have a group $G$ with a known presentation, and a subgroup $H$ generated by known elements in $G$ , is there an algorithm to determine the presentation of $H$ in terms of $G$ ? Is this doable in GAP?","['gap', 'group-theory']"
3746948,Choosing the sign of determinant when taking a square root,"Calculate the determinant $$\det(A)=\begin{vmatrix}a&b&c&d\\ \:\:\:-b&a&d&-c\\ \:\:\:-c&-d&a&b\\ \:\:\:-d&c&-b&a\end{vmatrix}$$ I found that $$\det(A)\det(A^T)=\det(A)^2=(a^2+b^2+c^2+d^2)^4$$ From this we get $$\det(A) = \pm (a^2+b^2+c^2+d^2)^2$$ Now, how to choose the sign? Any help is appreciated.","['matrices', 'determinant', 'linear-algebra']"
3746986,Does convexity at a point imply existence of one-sided derivatives?,"Let $\phi:\mathbb (0,\infty) \to [0,\infty)$ be a continuous function, and let $c \in (0,\infty)$ be fixed. Suppose that "" $\phi$ is convex at $c$ "". i.e. for any $x_1,x_2>0, \alpha \in [0,1]$ satisfying $\alpha x_1 + (1- \alpha)x_2 =c$ , we have $$
\phi(c)=\phi\left(\alpha x_1 + (1- \alpha)x_2 \right) \leq \alpha \phi(x_1) + (1-\alpha)\phi(x_2) .
$$ Assume also that $\phi$ is strictly decreasing in a neighbourhood of $c$ . Do the one-sided derivatives $\phi'_{-}(c),\phi'_{+}(c)$ necessarily exist? Edit: As pointed by Aryaman Maithani if $c$ is a global minimum of $\phi$ , then clearly $\phi$ is convex at $c$ , but there should be no reason to expect for existence of one-sided derivatives. (e.g. $\phi(x)=\sqrt{|x|}, c=0$ ). Edit 2: In the example described here , the left derivative does not exist. Can we create an example where the right derivative does not exist?","['examples-counterexamples', 'real-analysis', 'calculus', 'derivatives', 'convex-analysis']"
3747001,What is the image of $x^{\rm T}Qx\le 1$ under a linear map $x \mapsto Cx$?,"Let $Q$ be a real symmetric positive semidefinite $n \times n$ matrix. Consider a set $$
\Big\{ x \in \mathbb{R}^n \;\Big| \; x^{\rm T}Qx\le 1\Big\},
$$ which can be loosely described as an ""elliptic cylinder"". (It would be an ellipsoid if $Q$ was positive definite). Question. What is the image of this set under a linear map $y = Cx$ ? One can assume that $C$ has full row rank, but no more than that. I think that it will be $$
\Big\{ y \in \mathbb{R}^m \;\Big| \; y^{\rm T}Ry\le 1\Big\},
$$ where $R$ is some positive semidefinite matrix. But that is not enough: I actually want to find an explicit formula for $R$ (in terms of $Q$ and $C$ ) $-$ as elementary as it can be.","['positive-semidefinite', 'linear-algebra', 'linear-transformations', 'positive-definite', 'quadratic-forms']"
3747010,Proving a formula for $\int_{x=0}^\infty \frac{\sin(ax)x}{(x^2+1)^c} dx$ involving Gamma and Bessel K functions,"In Mathematica, $$\int_{0}^\infty \frac{\sin(ax)x}{(x^2+1)^c} dx
=\frac{2^{\frac{1}{2}-c}a^{-\frac{1}{2}+c}\pi^{\frac{1}{2}}\operatorname{BesselK}[-\frac{3}{2}+c,a])}{\Gamma[c]} ,$$ where a is a positive real number and $c>\frac{1}{2}.$ I want to prove this, but I can't. If anyone knows the proof of the above definite integral,
Thank you for your instruction.","['integration', 'trigonometry', 'definite-integrals', 'special-functions']"
3747065,"Modern and classical definitions of continuity of a function at $x_0$. (James R. Munkres ""Analysis on Manifolds"")","I am reading ""Analysis on Manifolds"" by James R. Munkres. Munkres wrote two different definitions of continuity of a function at $x_0$ : Modern(?) definition: Let $X$ and $Y$ be metric spaces, with metrics $d_X$ and $d_Y$ , respectively. We say that a function $f : X \to Y$ is continuous at the point $x_0$ of $X$ if for each open set $V$ of $Y$ containing $f(x_0)$ , there is an open set $U$ containing $x_0$ such that $f(U) \subset V$ . Classical definition: Continuity may be formulated in a way that involves the metrics specifically. The function $f$ is continuous at $x_0$ if and only if the following holds: For each $\epsilon > 0$ , there is a corresponding $\delta > 0$ such that $$d_Y(f(x), f(x_0)) < \epsilon \text{ whenever } d_X(x, x_0) < \delta.$$ This is the classical "" $\epsilon$ - $\delta$ formulation of continuity."" After these definitions, Munkres wrote the following theorem without a proof: Theorem 3.6(b): Let $f, g : X \to \mathbb{R}$ be continuous at $x_0$ . Then $f + g$ and $f-g$ and $f \cdot g$ are continuous at $x_0$ ; and $f/g$ is continuous at $x_0$ if $g(x_0) \ne 0$ . My proof for $f + g$ is the following: Let $V_{f+g}$ be any open set of $\mathbb{R}$ containing $(f+g)(x_0)$ . Then, there exists $\epsilon > 0$ such that if $|y - (f(x_0) + g(x_0))| < \epsilon$ , then $y \in V_{f+g}$ . Let $V_f := \{y \in \mathbb{R} | |y - f(x_0)| < \frac{\epsilon}{2}\}$ and $V_g := \{y \in \mathbb{R} | |y - g(x_0)| < \frac{\epsilon}{2}\}$ . Then, $V_f$ and $V_g$ are open sets of $\mathbb{R}$ . So, there exist open sets $U_f$ and $U_g$ of $X$ containing $x_0$ such that $f(U_f) \subset V_f$ and $g(U_g) \subset V_g$ . Let $U_{f+g} := U_f \cap U_g$ . Then if $x \in U_{f+g}$ , then $f(x) \in f(U_{f+g}) \subset f(U_f) \subset V_f$ and $g(x) \in g(U_{f+g}) \subset g(U_g) \subset V_g$ . So, $|f(x) - f(x_0)| < \frac{\epsilon}{2}$ and $|g(x) - g(x_0)| < \frac{\epsilon}{2}$ . So, $|f(x) + g(x) - (f(x_0) + g(x_0))| \leq |f(x) - f(x_0)| + |g(x) - g(x_0)| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$ . So, if $x \in U_{f+g}$ , then $(f + g)(x) \in V_{f+g}$ . So, $(f+g)(U_{f+g}) \subset V_{f+g}$ . Munkres said: ""Continuity may be formulated in a way that involves the metrics specifically."" and ""This is the classical ' $\epsilon$ - $\delta$ formulation of continuity.'"" Since I don't like the word ""classical"", I didn't want to use metrics specifically in the above proof. But I had to use metrics specifically. So my proof is ""classical"". Please give me a ""modern"" proof if it exists.","['multivariable-calculus', 'general-topology', 'continuity']"
3747121,Smooth maps between manifolds are continuous,"The comments in this question Smooth maps (between manifolds) are continuous (comment in Barrett O'Neill's textbook) seem to suggest that a smooth map ""in charts"", id est satisfying the definition A mapping $\phi:M\rightarrow N$ is smooth provided that for every coordinate system $\xi$ in M and $\eta$ in N the coordinate expression $\eta\circ\phi\circ\xi^{-1}$ is Euclidean smooth. might not be continuous. Here, I'm thinking every meaning every coordinate system in the maximal atlas.
I am not sure if O'Neil uses maximal atlases but I would like to know the answer for maximal atlases all the same. The definition of maximal atlas can be found here: https://en.wikipedia.org/wiki/Smooth_structure . Since in this definition, I am not guaranteed that the domain of $\eta\circ\phi\circ\xi^{-1}$ is open let's say that here smooth means that it is the restriction of a smooth map defined on an open set. Does there exist a counterexample of a map satisfying this property that is not continuous?","['smooth-manifolds', 'differential-geometry']"
3747125,"In this textbook explanation of needing partial derivatives, how is this partial derivative not an indeterminate form?","$$  f(x,y) = x^\frac{1}{3}y^\frac{1}{3} $$ $$\frac{\partial f}{\partial x}(0,0) = \lim_{x \to 0} \frac{f(h,0)-f(0,0)}{h}= \lim_{x \to 0} \frac{0-0}{h} = 0$$ ""and, similarly, $\frac{\partial f}{\partial y}(0,0) =0$ (these are not indeterminate forms!). It is necessary
to use the original definition of partial derivatives, because the functions $x^\frac{1}{3}$ and $y^\frac{1}{3}$ are not themselves differentiable at 0."" This is a portion of textbook explaning why a simple definition of a partial derivative does not work but a linear approximation definition of a partial derivative must be used. However, I'm confused at this part where they seem to be trying to use a counterexample to prove why a simple definition of partial derivatives does not work. Isn't this limit an indeterminate form? Yet, as you can see, the textbook claims this limit is not an indeterminate form to make their case. I would greatly appreciate your help in making sense of this textbook. Reference textbook: Vector Calculus by Marsden and Tromba 5th edition.","['indeterminate-forms', 'multivariable-calculus', 'linear-approximation', 'partial-derivative', 'limits']"
3747156,"Closed form sought for $a_1 = a_2 = 1, a_n = 1 + \frac{2}{n} \sum_{i=1}^{n-2} a_i $ where $n>2$","I've been working through a problem that I've got as far as getting a recursive answer to. I was hoping to turn this into more of a ""closed form"" answer, but haven't really gotten anywhere. I'm hoping that someone can help with this, though anything would be greatly appreciated. The recursive answer I have is a sequence of real numbers given by $$\begin{gather}
a_1 = a_2 = 1 \\
a_n = 1 + \frac{2}{n} \sum_{i=1}^{n-2} a_i \qquad  (n > 2)
\end{gather}$$ The first few non-trivial members of this sequence are $a_3 = \frac{5}{3}$ $a_4 = 2$ $a_5 = \frac{37}{15}$ $a_6 = \frac{26}{9}$ $a_7 = \frac{349}{105}$ I've tried to express these in terms of $a_1$ and $a_2$ and and constants and arrived at $a_3 = 1 + \frac{2}{3} a_1$ $a_4 = 1 + \frac{2}{4} a_1 + \frac{2}{4} a_2$ $a_5 = (1 + \frac{2}{5}) + (\frac{2}{5} + \frac{2^2}{3\cdot5} ) a_1 + \frac{2}{5} a_2$ $a_6 = (1 + \frac{2}{6} + \frac{2}{6}) + (\frac{2}{6} + \frac{2^2}{3 \cdot 6} + \frac{2^2}{4 \cdot 6}) a_1 + (\frac{2}{6} + \frac{2^2}{4 \cdot 6}) a_2$ $a_7 = (1 + \frac{2}{7} + \frac{2}{7} + \frac{2}{7} + \frac{2^2}{5 \cdot 7}) + (\frac{2}{7} + \frac{2^2}{3\cdot7} + \frac{2^2}{4 \cdot 7} + \frac{2^2}{5 \cdot 7} + \frac{2^3}{3 \cdot 5 \cdot 7}) a_1 + (\frac{2}{7} + \frac{2^2}{4 \cdot 7} + \frac{2^2}{5 \cdot 7}) a_2$ I am not seeing a pattern developing here. I also rearranged the above noting that $a_1 = a_2 = 1$ and got $a_3 = 1 + \frac{2}{3} $ $a_4 = 1 + 2 (\frac{2}{4})$ $a_5 = 1 + 3 (\frac{2}{5}) + \frac{2^2}{3\cdot5}$ $a_6 = 1 + 4 (\frac{2}{6}) + \frac{2^2}{3 \cdot 6} + 2 (\frac{2^2}{4 \cdot 6})$ $a_7 = 1 + 5 (\frac{2}{7}) + \frac{2^2}{3 \cdot 7} + 2 (\frac{2^2}{4 \cdot 7}) + 3 (\frac{2^2}{5 \cdot 7}) + \frac{2^3}{3 \cdot 5 \cdot 7}$ Here I do notice a couple of things The expression for $a_n$ begins with "" $1 + (n-2) \frac{2}{n}$ "". The remaining terms of the expression look like "" $k \dfrac{2^{i+1}}{b_1 \cdots b_{i} \cdot n}$ "" where each $b_j$ is between $3$ and $n-2$ and consecutive numbers cannot appear among them. The $k$ seems to be determined by the smallest number among the $b_j$ , but this is more of a guess than anything right now. These observations are not really helping me much at all.","['closed-form', 'sequences-and-series']"
3747158,Is there a proof via Chern-Weil theory that the first Chern numbers of two $\mathbb R$-isomorphic complex vector bundles are equal mod 2?,"Let $M$ be a compact, oriented surface.
If we have a complex vector bundle $E$ over $M$ , then we can define the first Chern number $c_1(E)$ via Chern-Weil theory. More precisely, if $\nabla$ is a connection on $E$ , then for a local frame $u_1,\ldots,u_k$ we can define the $1$ -forms $A_j^i$ by the formula $$\nabla u_j = \sum_i A_j^i u_i,
$$ and then define the curvature by $$F := dA + A \wedge A,$$ where $A$ is the matrix $(A_j^i)$ of $1$ -forms. The first Chern number is defined by $$c_1(E) = \frac{1}{2\pi i}\int_M \mathrm{tr}(F),$$ and this number does not depend on the choice of connection $\nabla$ . Two complex vector bundles $E_1, E_2$ are $\mathbb C$ -isomorphic if there is a diffeomorphism $f:E_1 \to E_2$ such that the diagram commutes and $f$ restricted to the fibers is $\mathbb C$ -linear. Analogously, the complex vector bundles are $\mathbb R$ -isomorphic if the map $f$ restricted to the fibers is $\mathbb R$ -linear. If the $E_1$ and $E_2$ are $\mathbb C$ -isomorphic, then $c_1(E_1) = c_1(E_2)$ , and if they are $\mathbb R$ -isomorphic, then $c_1(E_1) = c_1(E_2) \mod 2$ . Nevertheless, I only know how to prove the second property via Stiefel–Whitney numbers: in short, we have $c_1(E_1) = w_2(E_1) \mod 2$ . Question: If $f:E_1 \to E_2$ is an $\mathbb R$ -isomorphism, how do I prove $c_1(E_1) = c_1(E_2) \mod 2$ direct from Chern-Weil approach, without using general characteristic classes? If $E_1$ and $E_2$ are line bundles, then the proof is actually simple, because in this case we have $$c_1(E) = \frac{1}{2\pi i}\int_M F,$$ that coincides it the Euler number, and it is easy to prove that $c_1(E_1) = c_1(E_2)$ if $f$ preserves orientation, and $c_1(E_1) = -c_1(E_2)$ if $f$ reverses the orientation. I would be satisfied with a proof for rank $2$ .","['connections', 'vector-bundles', 'characteristic-classes', 'differential-geometry']"
3747178,Does $\partial A$ determine $A$?,"Given a bounded closed set $A$ in $\mathbb R^n$ , can $A$ be uniquely determined by $\partial A$ , except for the boundary itself? Or, use it differently, given two bounded closed sets $A_1, A_2$ in $\mathbb R^n$ with $\partial A_1 = \partial A_2$ , $A_1 \ne\partial A_1$ , and $A_2 \ne\partial A_2$ , is it true that $A_1 = A_2$ ? Without the boundedness assumption the assertion is clearly false: the sphere $\{ x \in \mathbb R^n : |x|=1\}$ is the common boundary to $\{ x \in \mathbb R^n : |x| \ge 1\}$ and $\{ x \in \mathbb R^n : |x| \le 1\}$ . note) It was originally intended for the Euclidean compact(bounded and closed) set, but it was incorrectly modified as an open set. I am sorry.",['general-topology']
3747192,$X = f^{-1}(f(X))$ if and only if $X = f^{-1}(Z)$ for some $Z \subseteq B$,"In my study of functions, I found this result in ”Proofs and Fundamentals” by Ethan D. Bloch that I’m attempting to prove. First, I already now that $X \subseteq f^{-1}(f(X))$ and $f(f^{-1}(Y)) \subseteq Y $ and I’m using this two results in my proof. Result: Let $f:A \rightarrow B$ a map and let $X \subseteq A$ and $Y \subseteq B$ . Then $X = f^{-1}(f(X))$ if and only if $X = f^{-1}(Z)$ for some $Z \subseteq B$ . My proof came as following. Proof: $\impliedby$ . Suppose that there exists a set $Z \subseteq B$ such that $X = f^{-1}(Z)$ . Let $Z_0$ be that set. By the result mentioned above, we have that $X \subseteq f^{-1}(f(X))$ . Let $x_0 \in f^{-1}(f(X))$ . By definition, $f(x_0) \in f(X)$ . Since $X = f^{-1}(Z_0)$ , we see that $f(x_0) \in f(f^{-1}(Z_0)).$ By the second result mentioned above, we conclude that $f(x_0) \in Z_0$ . By definition, we have that $x_0 \in f^{-1}(Z_0)$ . Hence $x_0 \in X$ . By definition of equality of sets we conclude that, in these conditions, $X = f^{-1}(f(X))$ . $\implies$ . Suppose that $X = f^{-1}(f(X))$ and let $Z_1$ be the set defined by $Z_1 = f(X)$ . By definition, $f(X) =$ { $b \in B$ | $b = f(x)$ for some $x \in X$ }. Hence $f(X) \subseteq B$ . From here we deduce that $Z_1 \subseteq B$ . By hypothesis, we have that $X = f^{-1}(f(X))$ , therefore $X = f^{-1}(Z_1)$ . We have shown that there exists a subset of $B$ such that the inverse image of this set is $X$ . MY PROBLEM: To me, the first part of the proof seems right but I would like to get some feedback. The second part is making me uncomfortable. It just don’t seem right to me. Is it right? Is there any other approach to prove the second part? In the book, Bloch gives some hints to some exercises. And for this one, he suggests the use of the following theorem: “Let $f:A \rightarrow B$ be a map. Let $S, T \subseteq B$ . If $S \subseteq T$ , then $f^{-1}(S) \subseteq f^{-1}(T)$ ”. Although i don’t see the point is using this theorem here. Do you have any idea? Thank you for your attention.","['elementary-set-theory', 'proof-explanation', 'functions', 'solution-verification']"
3747210,"Find the values of $\theta$ for which the tangent line to the given curve is parallel to $x$ ,$y$ axis","Given the curve $$r(\theta):=\sec\left(\theta\right)+a\cos\left(\theta\right) \tag{$a \in \mathbb R$}$$ Find the values of $\theta$ for which the tangent line to the curve is parallel to the $x$ and $y$ axis. The points for which the tangent line to the curve is parallel to the $y$ axis is given by : $$\frac{dx}{d\theta}=0$$ $$\left(\sec\left(\theta\right)\tan\left(\theta\right)-a\sin\left(\theta\right)\right)\cos\left(\theta\right)-\sin\left(\theta\right)\left(\sec\left(\theta\right)+a\cos\left(\theta\right)\right)=0$$ $$\tan\left(\theta\right)-a\sin\left(\theta\right)\cos\left(\theta\right)-\tan\left(\theta\right)-a\sin\left(\theta\right)\cos\left(\theta\right)=0$$ Assuming $a\ne0$ : $$\sin\left(\theta\right)\cos\left(\theta\right)=0$$ $$\theta=\frac{k\pi}{2}\tag{$k \in \mathbb Z$}$$ On the other hand duo the existence of $\sec$ function we see that the acceptable $\theta$ 's are : $$\theta=\frac{2k\pi}{2}=k\pi\tag{$k \in \mathbb Z$}$$ Implies the points $\left(x,y\right)=\left(r\cos\left(\theta\right),r\sin\left(\theta\right)\right)$ are all in the form: $$\left(\color{red}{\left(\sec\left(k\pi\right)+a\cos\left(k\pi\right)\right)\cos\left(k\pi\right)},\color{blue}{\left(\sec\left(k\pi\right)+a\cos\left(k\pi\right)\right)\sin\left(k\pi\right)}\right)$$ We see that the curves with $a\ne 0$ do have such tangent lines parallel to the $y$ axis.(Moreover for $a=0$ we have the line $x=1$ and the tangent line to the line (curve $r=\sec(\theta)$ ) parallel to the $y$ axis is the line itself.) The points for which the tangent line to the curve is parallel to the $x$ axis is given by : $$\frac{dy}{d\theta}=0$$ $$\left(\sec\left(\theta\right)\tan\left(\theta\right)-a\sin\left(\theta\right)\right)\sin\left(\theta\right)+\cos\left(\theta\right)\left(\sec\left(\theta\right)+a\cos\left(\theta\right)\right)=0$$ $$\frac{1}{\cos^{2}\left(\theta\right)}+2a\cos^{2}\left(\theta\right)-a=0$$ $$2a\cos^{4}\left(\theta\right)-a\cos^{2}\left(\theta\right)+1=0$$ $$\cos^{2}\left(\theta\right)=\frac{a\pm\sqrt{a^{2}-8a}}{4a}$$ Which is true whenever $$0\le\frac{a\pm\sqrt{a^{2}-8a}}{4a}\le1$$ Since $a^{2}-8a \ge 0$ ,we see that the curves with $0<a<8$ does not have such tangent lines parallel to the $x$ axis,moreover $\frac{a\pm\sqrt{a^{2}-8a}}{4a}$ is never between $0$ and $1$ and the inequality is not even sharp,so based on this information,such tangents lines parallel to the $x$ axis don't exist,but this is not true. So where was I wrong?","['curves', 'derivatives']"
3747231,Reduce the differential equation $y= 2px+p^{2}y^{2}$ to Clairaut’s form,"Reduce the following differential equation to Clairaut’s form by using the substitution and hence solve: $y= 2px+p^{2}y^{2}$ where $p={dy\over dx}$ I used $y^{2}=v$ then I get $v-2p_{1}x + {(x p_{1})^{2}\over v}= ({p_{1}\over2})^{4}$ where $p_{1}={dv\over dx}$ so this is not useful to reduce to Clairaut's form, please give me a hint to solve this or give me a suitable substitution Thank you.",['ordinary-differential-equations']
3747258,All solutions of $f(x)f(-x)=1$,"What are all the solutions of the functional equation $$f(x)f(-x)=1\,?$$ This one is trivial: $$f(x)=e^{cx},$$ as it is implied (for example) by the fundamental property of exponentials, namely $e^a e^b=e^{a+b}$ . But there is another solution: $$f(x)=\frac{c+x}{c-x}.$$ Are there any more solutions? How can I be sure?","['functional-equations', 'functions', 'real-analysis']"
3747262,Volume of the region of sphere between two planes.,"I want to find the volume of the region of the sphere $x^2+y^2+z^2=1$ , between the planes $z=1$ and $z=\frac{\sqrt{3}}{2}$ I have used triple integral for calculating this $$\int _0^{2\pi }\int _{0}^{\frac{\pi }{6}}\int _{0 }^1\:\rho ^2sin\phi \:d\rho \:d\phi \:d\theta $$ Are the limits of integral i have chosen correct?? Edit:
As from the comment, my integral is not correct,  so please clarify what region actually the above integral represents.","['multivariable-calculus', 'multiple-integral']"
3747271,$\cos\theta\cos2\theta\cos3\theta + \cos2\theta\cos3\theta\cos4\theta + ...$,"Evaluate: $$\cos\theta\cos2\theta\cos3\theta + \cos2\theta\cos3\theta\cos4\theta + …$$ upto $n$ terms I tried solving the general term $\cos n\theta\cos (n+1)\theta\cos (n+2)\theta$ .First, I applied the formula $2\cos\alpha\cos\beta = \cos(\alpha+\beta)+\cos(\alpha-\beta)$ on the two extreme terms. After solving I applied this once again and after further solving arrived at $$\frac{1}{4}[\cos(3n+3)\theta + \cos(n+1)\theta+\cos(n+3)\theta+\cos(n-1)\theta]$$ which I simplified to $$\frac{\cos n\theta}{2}[\cos\theta+\cos(2n+3)\theta]$$ After this I am stuck as to what else I could do so as to make the telescope or something else to easily calculate the sum using some fact from trigonometry. Or maybe this is a dead end. And help or hints would be appreciated, thanks","['trigonometric-series', 'trigonometry', 'sequences-and-series']"
3747280,Prove: $\tan{\frac{x}{2}}\sec{x}= \tan{x} - \tan{\frac{x}{2}}$,"I was solving a question which required the above identity to proceed but I never found its proof anywhere. I tried to prove it but got stuck after a while. I reached till here: To Prove: $$\tan{\frac{x}{2}}\sec{x}= \tan{x} - \tan{\frac{x}{2}}$$ But I don't know what to do next.
Any help is appreciated
Thanks","['trigonometry', 'euclidean-geometry', 'algebra-precalculus', 'geometry']"
3747334,Does $L^p(\Bbb R^n)$ have Schauder basis?,"I can only find this result for compact subsets for some reason, but it should be true. Does $L^p(\Bbb R^n)$ have Schauder basis?","['functional-analysis', 'real-analysis']"
3747353,Is this claim valid as a proof?,"I have a function $g(x)$ and I need to prove that $\; g(x)-x g'(x)\neq0$ on domain $0<x<a$ , where $a$ is a real positive number. Using Taylor series for the mentioned expression around $x=0$ , we obtain $ \; g(x)-x g'(x)=a x^3+O(x^5)$ . So, does this mean that $\; g(x)-x g'(x)$ is always non-zero over the domain $(0,a)$ ? Can it be considered as a proof?","['functions', 'solution-verification', 'taylor-expansion']"
3747388,Calculate $\int \left(1+\ln \left(1+\ln (...+\left(1+ \ln(x))\right)\right)\right) dx$.,"This is not particularly a useful integral or one asked in an exam or anything. I just really enjoy doing random integrals and derivatives. With that being said, how can I find: $$\int \left(1+\ln \left(1+\ln (...+\left(1+ \ln(x))\right)\right)\right) dx$$ I tried to star with the simple case of: $$\int \left(1+\ln(x)\right)dx=x\ln \left(x\right)+C$$ I then introduced the first nest. Here I did Integration by Parts with $u=1+\ln \left(1+\ln \left(x\right)\right), v'=1$ : $$\int \left(1+\ln \left(1+\ln \left(x\right)\right)\right)dx=x\left(1+\ln \left(1+\ln \left(x\right)\right)\right)-\frac{1}{e}\text{Ei}\left(\ln \left(x\right)+1\right)+C$$ However, these take quite some time and it's only the first nest. Therefore, I'm curious as to if $(a)$ such an integral does have solution and $(b)$ how to derive that situation. PS - Again this is just a fun question and not from an exam, website or anywhere important.","['integration', 'logarithms', 'real-analysis', 'complex-analysis', 'indefinite-integrals']"
3747400,An unexpected pair of almost-Fibonacci and Tribonacci series,"I use a modification of the SEIR model of epidemic spread which yields - for me totally out of the blue - for special parameters an astoninglishly good approximation of the Fibonacci series with a rather well-behaved delta that initially looks like $a(n) = \sum_{k=0}^n T(k)$ where $T(n)$ are the Tribonacci numbers . With $S$ the number of susceptible individuals $E$ the number of exposed individuals $I$ the number of infectious individuals $R$ the number of recovered individuals $P = S + E + I + R$ the total size of the population $\lambda = 1d$ the latency period, i.e. the number of days ( $d$ ) it takes that an exposed individual becomes infectious $\beta = 1/d$ the infection rate, i.e. the number of individuals infected by an infectious individual per day $\delta = 5d$ the duration of infectiousness, i.e. an individual recovers $\lambda + \delta$ days after getting infected In this model, the (dimensionless) basic reproduction number is $R_0 = \beta \cdot \delta = 5$ . The discrete model (with $\Delta t = 1d$ ) looks like this. Let $N(t) = \beta \cdot I(t-1) \cdot S(t-1) / P$ be the number of newly infected individuals at day $t$ . $\Delta S(t) = -N(t)$ $\Delta E(t) = N(t) - E(t-1)/\lambda$ $\Delta I(t) = E(t-1)/\lambda - N(t - \lambda - \delta)$ $\Delta R(t) = N(t - \lambda - \delta)$ or for $\lambda = \beta = 1$ , $\delta = 5$ $\Delta S(t) = -N(t)$ $\Delta E(t) = N(t) - E(t-1)$ $\Delta I(t) = E(t-1) - N(t - 6)$ $\Delta R(t) = N(t - 6)$ with $S(0) = P - 1$ , $E(0) = 1$ , $I(0) = 0$ , $R(0) = 0$ . The modification of the standard SEIR model lies in the handling of the duration of infectiousness $\delta$ . Usually this is handled (just like the latency period above) as a recovering or removal rate $\nu = (\lambda + \delta)^{-1}$ . In our model individuals become recovered not by rate but exactly $\lambda + \delta$ days after getting infected. This means for $\Delta I(t)$ we substract $N(t-6) = I(t-7)\cdot S(t-7)/P$ instead of $I(t-1)/6$ . This is the time series of numbers of currently infected individuals (i.e. exposed or infectious) together with their difference to the corresponding Fibonacci numbers: 0    1        -   1 = 0
1    1        -   1 = 0
2    2        -   2 = 0
3    2.999999 -   3 = 0.00001
4    4.999997 -   5 = 0.00003
5    7.999990 -   8 = 0.0001
6    11.99997 -  13 = 1
7    18.99992 -  21 = 2
8    29.99980 -  34 = 4
9    46.99949 -  55 = 8
10   73.99872 -  89 = 15
11   115.9967 - 144 = 28
12   181.9919 - 233 = 51
13   285.9800 - 377 = 91 The series of deltas $1, 2, 4, 8, 15, 28, ... $ resembles the sequence $a(n) = \sum_{k=0}^n T(k)$ where $T(n)$ are the Tribonacci numbers. This might be an accident - or it has an explanation. For such an explanation I am looking for.","['biology', 'recurrence-relations', 'discrete-mathematics', 'sequences-and-series']"
3747432,Product of block matrices,"Let $A$ be a $(n\times k)$ -matrix, $B$ a $(n\times d)$ -matrix and $M=[A \quad B]$ the block matrix (or the augmented matrix).
Doing the calculations, I obtained that $$M'M=
\left ( \begin{array}{cc}
A'A & A'B\\
B'A & B'B
\end{array}\right ),
$$ where $'$ stands for transposition. Do you have a good justification for this result rather than observe it by brute force?","['matrices', 'linear-algebra', 'block-matrices']"
3747443,Automorphism group of elliptic curve in char 2,"I'm trying to calculate the automorphism group of elliptic curve with $j$ -invariant $0$ in a field $K$ of characteristic $2$ .
Let $ Y^2Z+b_3YZ^2=X^3$ the elliptic curve.
The substitutions preserving this form are: $$X=u^2X+s^2Z$$ $$Y=u^2sX+u^3Y+t$$ $$Z=Z.$$ Then, the automorphisms of $E$ have $$u^3=1 \text{ with $u$ in $K^*$}$$ $$s(b_3+s^3)=0$$ $$s^6+tb_3+t^2=0.$$ So I have $24$ possible triplets $(u,s,t)$ forming a group with the composition law $$(u,s,t)*(v,\gamma,\delta) = (uv,u\gamma+\delta,u^2\gamma^2s+\delta+t).$$ Let $$a=(\xi_3,0,0)\text{ has order 3}$$ $$-1=(1,0,b_3)\text{ has order 2}$$ $$i=(1,\sqrt[3]b_3,b_3\xi_3^2)$$ $$j=(1,\sqrt[3]b_3\xi_3,b_3\xi_3^2)$$ $$k=(1,\sqrt[3]b_3\xi_3^2,b_3\xi_3^2)$$ with $$i^2=j^2=k^2=ijk=-1.$$ So $Q_8$ and $Z/3Z$ are two subgroups.
How could I say that the group of automorphisms of $E$ is the semi-direct product of $Q_8$ and $\Bbb Z/3\Bbb Z$ ?
This is what I've been thinking:
let $\phi:\Bbb Z/3\Bbb Z\to Aut(Q_8)$ such that $\Bbb Z/3\Bbb Z$ acts on $Q_8$ with a permutation of $\pm i,\pm j, \pm k$ and fixing $\pm 1$ $$(\xi_3,0,0)*(1,s,t)*(\xi_3,0,0)^{-1}=(1,s\xi_3,t)$$ $$(\xi_3^2,0,0)*(1,s,t)*(\xi_3^2,0,0)^{-1}=(1,s\xi_3^2,t)$$ so I have $axa^{-1}=\phi(a)(x)$ for all $a\in \Bbb Z/3\Bbb Z \text{ and } x\in Q_8$ .
Is this the presentation of the semi-direct product of $Q_8$ and $\Bbb Z/3\Bbb Z$ ?
I'm not sure it is enough to come to the conclusion.","['automorphism-group', 'elliptic-curves', 'semidirect-product', 'algebraic-geometry', 'group-theory']"
3747457,"Given trigonometric values as coordinates, Find the value of $t$ for which the Quadrilateral has maximum area","In a Cartesian Coordinate System we're given four points: $$A(2\cos(t),2\sin(t))$$ $$ B(-\cos(2-t),-sin(2-t))$$ $$C(-2\cos(t),-2\sin(t))$$ $$ D(\cos(2-t),\sin(2-t))$$ For what value of $t\in(0;1)$ will the Area of quadrilateral $ABCD$ be maximum? Well, this is an unusual problem. The way I tried to solve it is first by noticing that points $A$ - $C$ and $B$ - $D$ are $180^\circ$ apart. Also, We can map them on the circle with center at $(0,0)$ . I think the points $A$ and $C$ will be on the circle with radius $2$ ? So $AC=4$ ? I'm really not sure. Evaluating $\sin(2-t) = \sin(2)\cos(t) - \cos(2)\sin(t)$ . I don't know what to do with this since I've never sin expressed like this before. I mean, I'm guessing $\sin(2)$ means radians, but I don't know how to evaluate that. But perhaps there's no need to... So I'd really like to hear your thoughts on this, how do I go about solving this problem?","['coordinate-systems', 'algebra-precalculus', 'area', 'trigonometry']"
3747535,Why is the axiom schema of replacement formulated like this?,"I know there are multiple different formulations for the axiom schema of replacement, some of which are equivalent and others not or only under other axioms.
But all of them look something like this: If $\phi$ is a well-formed formula where $x$ , $y$ , $A$ , and $\vec w$ are free variables, then $$
\forall A\forall\vec w\quad
(\forall x\in A\,\forall y\forall y'\ \phi(x,y,A,\vec w)\wedge\phi(x,y',A,\vec w)\Rightarrow y=y')
\Rightarrow\exists B\forall y(y\in B\Leftrightarrow\exists x\in A\ \phi(x,y,A,\vec w))
$$ Specifically, all of the formulations that I have come across have $A$ as a variable in $\phi$ . My question is, why is that?
Why is it usefull to do so? And if one were to not put $A$ as a variable in $\phi$ , like so If $\phi$ is a well-formed formula where $\mathbf x$ , $\mathbf y$ , and $\mathbf 
 {\vec w}$ are free variables, then $$
\forall A\forall\vec w\quad
(\forall x\in A\,\forall y\forall y'\ \mathbf {\phi(x,y,\vec w)}\wedge\mathbf {\phi(x,y',\vec w)}\Rightarrow y=y')
\Rightarrow\exists B\forall y(y\in B\Leftrightarrow\exists x\in A\ \mathbf{\phi(x,y,\vec w)})
$$ would that formulation not be equivalent to the one above? I found discussions about this in the answers and comments of this and this question, but ultimately it is never clarified why it is there.",['elementary-set-theory']
3747542,Alternative method of finding a ratio in a parallelogram via composition of two homotheties,"Let $ABCD$ be a parallelogram and let $E\in\overline{AD},\ F\in\overline{CD}$ such that: $$\frac{|AE|}{|ED|}=\frac{|DF|}{|FC|}=\frac12.$$ Find the ratio in which the line segment $\overline{EF}$ divides the diagonal $\overline{BD}$ . One approach I'm familiar with: $\overrightarrow{AB}=\overrightarrow{DC}\ \&\ \overrightarrow{AD}=\overrightarrow{BC}$ Let $S$ be the intersection point of $\overline{EF}$ and diagonal $\overline{BD}$ , then: $\overrightarrow{ES}=\lambda\overrightarrow{EF}\ \&\ \overrightarrow{DS}=\mu\overrightarrow{DB}$ $\overrightarrow{ES}=\lambda\overrightarrow{EF}=\lambda\left(\overrightarrow{ED}+\overrightarrow{DF}\right)=\lambda\left(\frac23\overrightarrow{AD}+\frac13\overrightarrow{DC}\right)=\frac{2\lambda}3\overrightarrow{AD}+\frac{\lambda}3\overrightarrow{AB}$ On the other hand, $\overrightarrow{ES}=\overrightarrow{ED}+\overrightarrow{DS}=\frac23\overrightarrow{AD}+\mu\overrightarrow{DB}=\frac23\overrightarrow{AD}+\mu\left(\overrightarrow{DA}+\overrightarrow{AB}\right)=\left(\frac23-\mu\right)\overrightarrow{AD}+\mu\overrightarrow{AB}$ $\overrightarrow{AD}$ and $\overrightarrow{AB}$ can form a basis, so we have obtain the following system: $$\begin{cases}\frac{2\lambda}3&=\frac23-\mu\\\frac{\lambda}3&=\mu\end{cases}\implies \lambda=\frac23\implies\mu=\frac29$$ So we get that $\overline{EF}$ divides the diagonal $\overline{BD}$ in the ratio $2:7$ My question: How can we solve this problem using the following theorem about the composition of two homotheties ( found here , in the answer by Aqua): If $\mathcal{H}_{M,k_1}$ and $\mathcal{H}_{N,k_2}$ are homotheties then their compostion $\mathcal{H}_{M,k_1}\circ \mathcal{H}_{N,k_2}$ is again some homothety $\mathcal{H}_{S,k}$ with $k=k_1k_2$ (if $k\ne 1$ ) and it center $S$ lies on a line $MN$ . I thought I could do the following: $$\begin{aligned}\mathcal H_{E,-2}&:A\mapsto D\\\mathcal H_{F,-2}&:D\mapsto C\end{aligned}$$ so that the center of the homothety $\mathcal H_{E,-2}\circ\mathcal H_{F,-2}$ lies on the line $EF$ , but this doesn't lead me to the right result. Picture: Thank you very much! Edit: For future readers, picture according to the answer by @MichaelRozenberg:","['euclidean-geometry', 'homothety', 'geometry', 'ratio', 'geometric-transformation']"
3747546,What's a fair way to share fees in a group road trip with a personal and a rental car?,"I'm planning vacations with a group of friends (12 people), and it involves a ~1200km return trip by car. Only one of us owns a suitable car (4 pax), so we've rented a minivan to transport the other 8, and we're debating on how best to share the costs. Normally, if none of the cars were rentals, each car owner would just divide the price of fuel and tolls over their passengers, themselves included. Logically, we could do the same with the rental fees. But as a passenger who could either be in the personal car or in the rented minivan, their share of the cost will be vastly different depending on which car they end up in, for the same trip. That would be unfair to the passengers of the rental car . We could also share the sum of all fees of both cars across all of us. But that would be unfair to the car owner , who ends up paying a higher trip cost than if it were just his car and passengers sharing the cost, despite owning a car and enduring the associated hassles and yearly expenses. If we calculate it that way, we need to include the full, actual cost to him of using his car for the trip, including maintenance, amortization, and insurance. What would be the best way to share these costs? EDIT to avoid opinion-based interpersonal advice: I'm looking for the most ""scientifically fair"" solution, some kind of calculation model. Answers that challenge whether we need to be that precisely fair in a group of friends are absolutely right, and all parties have indeed agreed to a ""simple and imperfect"" solution. We're left with the academical question that is the object of my post: ""but what would be the fairest model?""","['fair-division', 'algebra-precalculus']"
3747571,Does $\phi(a)=n!$ have finitely many solutions in integers?,"I tried to treat solution of $\phi(a)=n!$ in integers such that $\phi(n)$ is the Euler totient function and $a$ is an integer, for $a=n$ it's clear that there is no solution because $\phi(n)<n<n!$ . Some solutions I got by wolfram alpha are mentioned here . For instance, we have $(a,n)=(9,3)$ and $(-9,3)$ , $(7,3)$ and $(-7,3)$ , $(6,2)$ and $(-6,2)$ , $(4,2)$ and $(-4,2)$ , $(3,2)$ and $(-3,2)$ , $(2,0)$ and $(-2,0),(2,1)$ and $(-2,1)$ , $(1,0)$ and $(-1,0)$ . I suspect there are finitely many of them, but this needs a proof. My question here is: When does $\phi(a)=n!$ have a solution in integers? Does it have a finite number of solutions?","['gamma-function', 'number-theory', 'totient-function']"
3747602,Can an $n \times n$ matrix satisfy an $n$ degree polynomial equation other than its characteristic polynomial equation?,"Can an $n \times n$ matrix satisfy an $n$ degree polynomial equation other than its characteristic polynomial equation? I was curious if the characteristic polynomial equation is the only $n$ degree equation that can be satisfied by a matrix.
I have tried by trial and error to make up an equation for $2\times 2$ matrix but always end up with the characteristic polynomial.","['matrices', 'minimal-polynomials', 'linear-algebra', 'characteristic-polynomial', 'matrix-equations']"
3747612,Calculate $\frac{d}{dx}\left(x^x+x^{2x}+x^{3x}+...\right)$.,"Calculate: $$\frac{d}{dx}\left(x^x+x^{2x}+x^{3x}+...+x^{nx}\right), n \in\mathbb{N_{\geq 1}}$$ If I have $x^x$ as my first case, then I get $$\frac{d}{dy}x^x=x^x\left(\ln \left(x\right)+1\right)$$ Likewise, for $n=2$ I get: $$\frac{d}{dx}\left(x^x+x^{2x}\right)=x^x\left(\ln \left(x\right)+1\right)+2x^{2x}\left(\ln \left(x\right)+1\right)$$ For $n=3$ : $$\frac{d}{dx}\left(x^x+x^{2x}+x^{3x}\right)=x^x\left(\ln \left(x\right)+1\right)+2x^{2x}\left(\ln \left(x\right)+1\right)+3x^{3x}\left(\ln \left(x\right)+1\right)$$ If I keep following this logic, I can see that for the last $n$ , I get: $$\frac{d}{dx}\left(x^x+x^{2x}+x^{3x}+...+x^{nx}\right)=x^x\left(\ln \left(x\right)+1\right)+2x^{2x}\left(\ln \left(x\right)+1\right)+3x^{3x}\left(\ln \left(x\right)+1\right) + ...+nx^{nx}(\ln(x)+1)$$ I can then use induction to prove this. However, if instead of the function being finite, what if it was infinite? How would I find: $$\frac{d}{dx}\left(x^x+x^{2x}+x^{3x}+...\right)$$","['integration', 'analysis', 'real-analysis', 'calculus', 'sequences-and-series']"
3747643,Proving that a rectangle with specific vertices is in the opened unit circle,"In an exercise I'm asked to prove that: Let $(a,b)$ be any point in $D=\{(x,y)\in \mathbb R ^2 : x^2 + y^2 < 1\}$ . Put $r=\sqrt{a^2 + b^2}$ . Let $R_{(a,b)}$ be the open rectangle with vertices at the points $\left(a\pm \frac{1-r}{8}, b\pm \frac{1-r}{8}\right)$ . Prove that for every point $(a,b)$ , $R_{(a,b)}\subset D$ . My first attempt was to calculate the distance from the center to each Vertex and show that it is less that $1$ , thus being an element of the set $D$ , but I failed. How can I prove this?","['elementary-set-theory', 'general-topology']"
3747684,Evaluate $\sqrt{x+\sqrt{{x^2}+\sqrt{{x^3}+\sqrt{{x^4}...}}}}$,"I recently became fascinated by infinite nested radicals, first drawn attention to me from a question in my textbook about the value of $\sqrt{1+\sqrt{{1}+\sqrt{{1}+\sqrt{{1}...}}}}$ which turned out to be $\phi$ when I worked it out, a rather beautiful result. I then tried to find a formula to evaluate the general case $$\sqrt{x+\sqrt{{x}+\sqrt{{x}+\sqrt{{x}...}}}}$$ which I succeeded in; it can be evaluated as $$\frac{1+\sqrt{1+4x}}{2}$$ Multiplying the nested radical which was equal to $\phi$ by $x$ produces the following nested radical: $$\sqrt{{x^2}+\sqrt{{x^4}+\sqrt{{x^8}+\sqrt{{x^{16}}...}}}}$$ so this is equal to $x\left(\frac{1+\sqrt5}{2}\right)$ . However, I have tried and failed to find the value of the following infinite square root: $$\sqrt{x+\sqrt{{x^2}+\sqrt{{x^3}+\sqrt{{x^4}...}}}}$$","['nested-radicals', 'convergence-divergence', 'radicals', 'sequences-and-series']"
3747774,Why is $ \frac{5}{64}((161+72\sqrt{5})^{-n}+(161+72\sqrt{5})^{n}-2)$ always a perfect square?,"I'm working on a puzzle, and the solution requires me somehow establishing that $$ f(n):=\frac{5}{64}\Big(\big(161+72\sqrt{5}\big)^{-n}+\big(161+72\sqrt{5}\big)^{n}-2\Big)$$ is a perfect square for $n\in \mathbb{Z}_{\geq 0}$ . I've done a lot of simplification to get to this point, and am stuck here. I can provide the context of the puzzle if necessary, but it's pretty far removed from what I have here. The goal is basically to show that a formula generates solutions to a given equation. Any tips on how to proceed? Here's the first few values: $$\begin{array}{|c|c|}
\hline
n&\text{value}\\ \hline
0&0\\ \hline
1& 5^2 \\ \hline
 2&90^2 \\ \hline
 3& 1615^2\\ \hline
 4& 28980^2\\ \hline
\end{array}$$","['elementary-number-theory', 'recursion', 'combinatorics', 'discrete-mathematics', 'sequences-and-series']"
3747790,Struggling to Understand Algorithm for Displaying Polynomial Matings with Julia Sets,"I'm working on creating a program that visualizes projected Julia Sets on a Riemann Sphere (such as my video here ) when I came across this website visualizing matings between Julia Sets, and I want to recreate them for my own program (such as this video ). However, with any resource that I've read that explains the process, I can't seem to wrap my mind around what's going on... I'm not sure if I simply don't yet have the formal education required (my knowledge of complex analysis is only limited to visualizing iterated fractals), or if these sources are just hard to understand. What I want to learn specifically about is what is described here (from the previous website - what's in bold is what I want to learn, and what's italicized is what I have a hard time conceptually understanding): ""A progressive interpolation was introduced, between the two polynomial Julia sets and their mating. It consists in gluing equipotentials together and gives a holomorphic dynamical system between different spheres (this was observed by Milnor). This dynamical systems gives an easy method for drawing a conformally correct picture of the deformation of the polynomial Julia sets under the equipotential gluing: this method was explained to me by Buff. The result is an image which depends on the potential. This is what the movies show: the potential starts high and slowly approaches 0 ."" Essentially, what I'm looking for is given: some point z on the complex plane (I already know how to project this
onto the Riemann Sphere) two filled Julia Set coordinates $c_1$ and $c_2$ (for example, the Basilica and Rabbit - eventually I hope to move beyond two) some value t that represents the value of the potential that decreases to 0 (for the mating animation) some value n that represents the maximum escape-time iterations some value b that represents the bailout value ... do some math that calculates the color for that point (just like the escape-time algorithm - though this is the limit of my understanding, so I'm hoping that I can visualize the matings in the same way) when it's projected on the Riemann Sphere. Is this possible? I would be grateful for anything to help my understanding with this! If I'm in too far in over my head with this kind of math, then I'd also be satisfied with a copy-and-paste solution for my particular goal here. I already tried reading these papers: Pasting Together Julia Sets: A Worked Out Example of Mating The Medusa Algorithm for Polynomial Matings The Thurston Algorithm for Quadratic Matings Slow mating and equipotential gluing Slow mating of quadratic Julia sets I did consider putting this on StackOverflow instead, but I think this is more of a math question than a programming one. EDIT: After a week of going through Claude's code , I finally figured out an algorithm to which I can display the slow mating in real time! Its implementation in my project is not without a couple of bugs, but I was able to get the basic animation working (I've made some videos to show the mating of Basilica vs. Rabbit , its inverse , and its projection on the Riemann Sphere). The algorithm is as follows: INITIALIZATION Constants R1 >= 5
R2 = R1 * R1
R4 = R2 * R2 Variables # the two Julia Sets to slow mate
Complex p
Complex q

# mating presets
int mating_iterations
int intermediate_steps

# Julia Set presets
int julia_iterations
float bailout

# image presets
int width
int height
    
# intermediate path segments
Complex x [mating_iterations * intermediate_steps]
Complex y [mating_iterations * intermediate_steps]

# store inverse of pullback function (https://mathr.co.uk/blog/2020-01-16_slow_mating_of_quadratic_julia_sets.html)
Complex ma [mating_iterations * intermediate_steps]
Complex mb [mating_iterations * intermediate_steps]
Complex mc [mating_iterations * intermediate_steps]
Complex md [mating_iterations * intermediate_steps]

# what's sent to the GPU
Complex ma_frame [mating_iterations];
Complex mb_frame [mating_iterations];
Complex mc_frame [mating_iterations];
Complex md_frame [mating_iterations];

# Compute potentials and potential radii
float t[intermediate_steps]
float R[intermediate_steps]

for s: the count of intermediate segments
{
    t[s] = (s + .5) / intermediate_steps
    
    R[s] = exp(pow(2, 1 - t[s]) * log(R1))
}


p_i = 0     # nth iteration of the p Julia Set
q_i = 0     # nth iteration of the q Julia Set

# Calculate path arrays (Wolf Jung's equations 20 and 21)
for i: each frame in mating_iterations*intermediate_steps
{
    # i = intermediate_steps * n + s
    # for each n:
    #     for each s
    int s = i % intermediate_steps;
    int n = (i - s) / intermediate_steps;    # this is not needed here
    

    # Equation 20
           1 + ((1 - t[s]) * q / R2)                p_i / R[s]
    x[i] = ------------------------- * -------------------------------------
           1 + ((1 - t[s]) * p / R2)   1 + ((1 - t[s]) * q / R4 * (p_i - p))

    # Alternatively, if R1 = 1e10
    x[i] = p_i / R[s]



    # Equation 21
           1 + (1 - t[s]) * q / R2   R[s]
    y[i] = ----------------------- * ---- * (1 + ((1 - t[s]) * p / R4 * (q_i - q)))
           1 + (1 - t[s]) * p / R2   q_i

    # Alternatively, if R1 = 1e10
    y[i] = R[s] / q_i
          
    

    if (s == intermediate_steps - 1)    # last 's' before new 'n'
    {
        p_i = p_i^2 + p
        q_i = q_i^2 + q
    }
} Prior to point calculation (CPU Render Loop) # This could've be done using a nested for loop, but I needed to be consistent with my notation so I could understand the algorithm easier

for i: each frame in mating_iterations*intermediate_steps
{
    # i = intermediate_steps * n + s
    # for each n:
    #     for each s
    int s = i % intermediate_steps;
    int n = (i- s) / intermediate_steps;
        
    int first = intermediate_steps + s
    int s_prev = (s + intermediate_steps - 1) % intermediate_steps
        
    if (n > 0)
    {
        // Pull back x and y (Wolf Jung's Equation 22)
        for k: count of total mating iterations - current mating iteration (n)
        {
            int k_next = k + 1
            int next = intermediate_steps * k_next + s
            int prev = intermediate_steps * k + s_prev


                         (  1 - y[first]     x[next] - x[first]  )
            z_x[k] = sqrt(  ------------  *  ------------------  )
                         (  1 - x[first]     x[next] - y[first]  )
        
        
                                                                   
                                                     x[first]
                                                 1 - --------
                         (  (1 - y[first])           y[next]   )
            z_y[k] = sqrt(  --------------  *  --------------  )
                         (  (1 - x[first])           y[first]  )
                                                 1 - --------                                                                 
                                                     y[next]
        
            // choose sign by continuity
            if (length(-z_x[k] - x[prev]) < length(z_x[k] - x[prev]))
            {
                z_x[k] = -z_x[k]
            }
            if (length(-z_y[k] - y[prev]) < length(z_y[k] - y[prev]))
            {
                z_y[k] = -z_y[k]
            }
        }
        
        // copy results into path arrays
        for k: count of total mating iterations - current iteration (n)
        {
            x[intermediate_steps * k + s] = z_x[k]
            y[intermediate_steps * k + s] = z_y[k]
        }
    }
    
    a = x[intermediate_steps + s]
    b = y[intermediate_steps + s]
    ma[i] = b * (1 - a)
    mb[i] = a * (b - 1)
    mc[i] = 1 - a
    md[i] = b - 1
    
    for k: 0 to current mating iteration (n)
    {
        ma_frame[k] = ma[intermediate_steps * k + s]
        mb_frame[k] = mb[intermediate_steps * k + s]
        mc_frame[k] = mc[intermediate_steps * k + s]
        md_frame[k] = md[intermediate_steps * k + s]
    }

    # SEND VARIABLES TO GPU
        julia_iterations
        bailout
        p
        q
        R (taken from 'R[s]')
        current_mating_iteration (taken from 'n')
        ma_frame
        mb_frame
        mc_frame
        md_frame
} Apply for each point on the complex plane (GPU Fragment Shader: for each pixel on the screen) z = point on complex plane

for k: starting from current_mating_iteration and decreasing to zero
{
        ma_frame[k] * z + mb_frame[k]
    z = -----------------------------
        mc_frame[k] * z + md_frame[k]
}
    
if (length(z) < 1)
{
    c = p
    w = R * z
}
else
{
    c = q
    w = R / z    # note: this is complex division
}


for i: the rest of the regular Julia Set iterations (julia_iterations - n)
{
    break if (length(z) > bailout)
    
    w = w^2 + c
}

pixel_color = based on w","['complex-analysis', 'recreational-mathematics', 'complex-dynamics', 'fractals']"
3747805,"What are all possible positive integers $k$ such that $k=\frac{a^2+b^2+c^2}{bc+ca+ab}$ for some positive integers $a$, $b$, and $c$?","This question is inspired by this one .  It comes in two parts. Question 1. Determine all positive integers $k$ such that there are positive integers $a$ , $b$ , and $c$ such that $$\frac{a^2+b^2+c^2}{bc+ca+ab}=k\,.\tag{*}$$ Question 2. For each positive integer $k$ discovered in Question 1, what are all triples $(a,b,c)$ of positive integers such that the condition (*) is satisfied? Here are three values of $k$ that have the required property. Case I: $k=1$ . All solutions $(a,b,c)$ are of the form $$(a,b,c)=(n,n,n)$$ where $n$ is a positive integer. Case II: $k=2$ . It can be proven by Vieta jumping that each solution $(a,b,c)$ is a permutation of $$\big(tm^2,tn^2,t(m+n)^2\big)\tag{#}$$ for some positive integers $t$ , $m$ , and $n$ (we can assume that $m$ and $n$ are relatively prime).  A proof of this claim can be seen in the hidden portion below. Case III: $k=5$ .  All solutions can be found in this link . Are there other values of $k$ with the required property?  If so, are there infinitely many of them? Here is a proof sketch for my claim when $k=2$ if you would like to read.  Let $S$ denote the set of solutions $(a,b,c)\in\mathbb{Z}_{>0}^3$ to (*).  Define a similarity relation $\sim$ on $S$ which is an equivalence relation on $S$ generated by requiring that each triple $(a,b,c)\in S$ is similar to any permutation of $(a,b,c)$ , and that $(a,b,c)$ is similar to $(a,b,2a+2b-c)$ , provided that $(a,b,2a+2b-c)$ is also in $S$ .  Pick an equivalence class $C$ of $S$ induced by $\sim$ , and suppose that $(a,b,c)$ is its minimal triple in the sense that $a+b+c$ is the smallest among all triples in $C$ that is not of the form (#).  We may assume without loss of generality that $a\leq b\leq c$ .  Note that either $2a+2b-c\leq 0$ or $(a,b,2a+2b-c)$ is a ""smaller"" triple than $(a,b,c)$ in $C$ that is not of the form (#).  Show that $c=2a+2b$ must holds, and this implies $b=c$ .  It then follows that $(a,b,c)=(t,t,4t)=\big(1^2t,1^2t,(1+1)^2t\big)$ for some positive integer $t$ , and this is a contradiction.","['number-theory', 'elementary-number-theory', 'vieta-jumping', 'diophantine-equations', 'quadratic-forms']"
3747853,Is $f(x) = 0 \implies f'(x) > 0$ a sufficient condition for uniqueness of roots for a smooth (non constant) function $f$?,"Let $f : \mathbb R \rightarrow \mathbb R : x \mapsto f(x)$ a smooth non constant function such that $f(x) = 0 \implies f'(x) > 0.$ Does $f$ have a unique root ? I think this is true but I can't prove it. Here what I've done so far. Case 1. Let $x_1 < x_2$ be two roots with no other root in $(x_1,x_2)$ . Since $f(x_i) = 0$ we have $f'(x_i) > 0$ so by continuity of $f'$ we have that $f' > 0$ on a small interval $(x_i - \delta,x_i + \delta)$ around $x_i$ . Therefore $f$ is strictly increasing on a neighbourhood of each root. In particular $f>0$ on $(x_i, x_i + \delta)$ and $f< 0$ on $(x_i-\delta,x_i).$ Using the intermediate value theorem we can find another root $c$ somewhere between $x_1$ and $x_2$ , a contradiction. In particular $f(x) = 0$ as infinitely many solutions. Here's where I'm not so sure : Case 2. If there are roots between any given given roots $x_1 < x_2$ then we can apply the above reasoning to $x_1,c$ and $c,x_2$ to find new roots between $x_1$ and $x_2$ so we can find infinitely many roots between any given roots $x_1$ and $x_2$ . In don't know how to proceed. It feels like $f$ should be equal to $0$ on some interval which would then contradict $f(x) = 0 \implies f'(x)>0$ Can someone find a counter example or finish the proof ?","['roots', 'derivatives', 'real-analysis']"
3747877,Closed subset of metric spaces,"Let $X$ be a metric space with $p \in X$ a point, $C \subset X$ a subset.
Show $C$ is closed iff $C \cap \overline{B_R(p)}$ is closed for any $R>0$ . Supposing $C$ is closed is pretty easy as intersecting it with closed ball is still closed. So then assume $C \cap \overline{B_R(p)}$ is closed (so it equals its closure) and want to show $C$ is closed, i.e., $C = \overline{C}$ . Is this the way to go about it? Clearly $C \subset \overline{C}$ , so we wish to show $\overline{C} \subset C$ but taking $x \in \overline{C}$ and showing $x \in C$ ? Because then $x$ is a limit point of $C$ so any open ball (for any choice of $R>0$ ) centered at $p$ intersects $C$ nontrivially? Am I on the right track? Just a hint will suffice not an entire solution. Thanks!","['general-topology', 'metric-spaces']"
3747901,Proofs of the Reflection Rules,"I couldn't find a formal proof for the rule:
when a point $(a,b)$ is reflected along $y=x$ , it becomes $(b,a)$ . I tried to prove it by sketching out the situation: However, I still don't know how to prove that $b'=b, a'=a$ . Furthermore, I just want to make sure, for the following two rules: Reflection Across Y-Axis. $(x,y)\to(-x,y)$ Reflection Across X-Axis. $(x,y)\to(x,-y)$ . Do they have formal proofs or do we just prove them by visualizing where a point ends up to be on a cartesian plane?","['analytic-geometry', 'euclidean-geometry', 'algebra-precalculus', 'geometry']"
3747923,Is torsion of an elliptic curve determined by its reductions modulo primes?,"A friend of mine has posed the following question to me: $\newcommand{\Q}{\mathbb Q}\newcommand{\F}{\mathbb F}\newcommand{\Z}{\mathbb Z}$ Let $E$ be an elliptic curve over $\Q$ . Is it the case that $|E(\Q)_{tors}|$ is equal to the greatest common divisor of $|E(\F_p)|$ over all primes $p>2$ of good reduction of $E$ ? The former certainly divides the latter, since $E(\Q)_{tors}$ embeds in $E(\F_p)$ for all odd primes of good reduction. The answer to the above question is no, as illustrated by an elliptic curve $E:y^2=x^3+x$ , which has $E(\Q)_{tors}\cong\Z/2$ , yet $|E(\F_p)|$ is divisible by $4$ for all $p\geq 3$ . However, if we know the structure of $E(\F_p)$ for all $p$ , then we can still recover $E(\Q)_{tors}$ - for instance, $E(\F_3)\cong\Z/4$ and $E(\F_5)\cong\Z/2\times\Z/2$ and so $E(\Q)_{tors}$ , which embeds into both of those, must be equal to $\Z/2$ (it can't be smaller due to the obvious point $(0,0)$ ). This is Example 4.6 from Silverman-Tate's book. Based on this latter observation, the friend has further queried whether it is always necessarily the case, that is whether $E(\Q)_{tors}$ can be always determined to be the largest group which embeds into $E(\F_p)$ for all odd primes of good reduction. I would be quite surprised if that was the case, and I vaguely recall seeing a counterexample, but I had no luck finding it online. We are in particular interested in the following special case, which is the main question in this post: Suppose $E(\Q)_{tors}$ is trivial. Does it follow that there is no nontrivial group which embeds into $E(\F_p)$ for all odd primes of good reduction of $E$ ?","['number-theory', 'torsion-groups', 'elliptic-curves']"
3747938,Definition of compactly supported functions,"Let $X$ be a topological space. Let $f \in C(X)$ . Define the support of $f$ . $$\operatorname{supp}(f) := \overline{\{x \in X: f(x) \neq 0\}}$$ I want to show that $$A:=\{f \in C(X)\mid \exists K \subseteq X \mathrm{\ compact \ }: \forall x \notin K: f(x) = 0\}$$ and $$B:=\{f \in C(X): \operatorname{supp}(f) \mathrm{\ is \ compact}\}$$ coincide. The inclusion $B \subseteq A$ is trivial. Attempt : I managed to show that $A \subseteq B$ if $X$ is Hausdorff: If $f \in A$ , determine a compact set $K$ with $f(x) = 0$ for $x \notin K$ . Then $$\{x \in X: f(x) \neq 0\} \subseteq K$$ and taking closures $$\operatorname{supp}(f) \subseteq \overline{K}$$ Since $X$ is Hausdorff, $K$ is closed so we get $$\operatorname{supp}(f) \subseteq K$$ Then $\operatorname{supp}(f)$ is a closed subset of a compact set and we can conclude. Question : Does the inclusion remain valid without the Hausdorff assumption?","['continuity', 'general-topology', 'functional-analysis', 'compactness']"
3747953,What are some theorems made easier by Stone Duality?,"I have seen a lot of praise for the Stone Duality Theorem, which links the algebraic structure of boolean algebras to the topological structure of stone spaces by a (contravariant) adjoint equivalence of categories. What are some theorems which are made obvious by using duality, or which don't have proofs without duality? I know that it (and its generalizations) have inspired a lot of work in pointless topology , which looks interesting to me, but it's not what I'm looking for. Ideally these proofs should be theorems about boolean algebras or stone spaces - things which someone could have come up with before the duality was known. I'm sure these theorems must exist, because Stone Duality, while independently beautiful, is often cited as a useful and powerful result... So I'm not sure why I'm struggling to find witnesses to its utility. Thanks!","['boolean-algebra', 'category-theory', 'abstract-algebra', 'general-topology', 'duality-theorems']"
3747956,How can i solve $\int \frac{x^3+2x-7}{\sqrt{x^2+1}}\ dx?$,"How can i solve following $$\int \frac{x^3+2x-7}{\sqrt{x^2+1}}\ dx?$$ My work: I substituted $x=\tan\theta$ , $dx=\sec^2\theta d\theta $ integral becomes $\int \dfrac{\tan^3\theta+2\tan \theta-7}{\sqrt{\tan^2\theta+1}}\ \sec^2\theta d\theta$ $\int \dfrac{\tan\theta(\tan^2\theta+1)+\tan \theta-7}{\sec\theta}\sec^2\theta d\theta$ $\int (\tan\theta(\sec^2\theta)+\tan \theta-7)\sec\theta d\theta$ $\int \tan\theta\sec^3\theta\ d\theta+\int \sec\theta \tan \theta\ d\theta-7\int \sec\theta d\theta$ $\int \tan\theta\sec^3\theta+\sec\theta -7\ln|\sec\theta+\tan\theta|+C$ I got stuck here in solving first part of above integral. I can't see the way to solve it. please help me solve it by substitution or other method. thanks","['integration', 'indefinite-integrals', 'calculus']"
