question_id,title,body,tags
1639521,Showing that if $\lim_{x\to\infty}f'(x)=L$ then $\lim_{x\to\infty}\frac{f(x)}{x} = L$. [duplicate],"This question already has an answer here : if $f'(x)\rightarrow L$ as $ x \rightarrow \infty$, $-\infty \leq L \leq \infty $ then $ f(x)/x \rightarrow L $ as $x \rightarrow \infty$ [duplicate] (1 answer) Closed 6 years ago . Let $f:[0,\infty)\to\mathbb{R}$ differentiable and suppose that $$\lim_{x\to\infty}f'(x)=L.$$ How can I prove that $$\lim_{x\to\infty}\frac{f(x)}{x} = L\;?$$ I have solved some similar problems using the Mean Value Theorem, and I am trying to use it again in this one, but nothing works. For example, I tried to apply the MVT in $[x, 2x]$ but it does not work. Some hint?","['derivatives', 'real-analysis', 'limits']"
1639524,Why was the zeta function introduced?,"I know the 'Zeta Function' is very useful in Mathematics, and that it has relations with many other functions (such as the 'Gamma Function' ). I also know the 'Zeta Function' $\zeta(s)$ is defined as: $$\zeta (s) = \sum_{n=1}^{\infty} {1\over {n^s}}$$ But my question is why and how was this even derived? I've studied and understood many proofs regarding $\zeta(s)$, such as: $$\Gamma(s) \zeta(s) = \int_{0}^{\infty} {{u^{s-1}\over {e^u}-1}} \space du$$ $$\zeta(s) = {2^s}{\pi^{s-1}}{sin \bigg({\pi s\over 2}\bigg)}{\Gamma(1-s)}{\zeta(1-s)}$$ But anytime I try search up information regarding the derivation of $\zeta(s)$, all I get is the fact that Leonhard Euler was amongst the first to study it. Nothing more. Is there any article I can read that talks about how $\zeta(s)$ came to be?","['zeta-functions', 'functions']"
1639595,How to calculate the derivative of logarithm of a matrix?,"Given a square matrix $M$, we know the exponential of $M$ is
$$\exp(M)=\sum_{n=0}^\infty{\frac{M^n}{n!}}$$ and the logarithm is $$\log(M)=-\sum_{k=1}^\infty\frac{(I-M)^k}{k}$$ The derivative of $\exp(M)$ should be itself. It is easy to prove if $\frac{dM}{M}=I$. But how to calculate the derivative of $\log(M)$? By the same way of calculation of the derivative of $\exp(M)$, the derivative of $\log(M)$ cannot converge. So what is the derivative of $\log(M)$?","['matrices', 'differential-operators']"
1639643,Name of $\prod_{n = 1}^{\infty}n = 1 \times 2 \times 3 \times 4 \times 5 \times \cdots$,"I already know about the Harmonic series: $$\sum_{n = 1}^{\infty} \frac 1n = 1 + \frac 12 + \frac 13 + \frac 14 + \frac 15 + \frac 16 + \cdot \cdot \cdot$$ But is there a name for this infinite product series: $$\prod_{n = 1}^{\infty}n = 1 \times 2 \times 3 \times 4 \times 5 \times \cdots$$ It is not that I need any help, but I just want to know... what is the name for that above infinite product series?","['terminology', 'infinite-product', 'sequences-and-series']"
1639650,"Seeking non-inductive, combinatorial proof of the identity $1^2 + 2^2 + 3^2 + \cdots + n^2 = \frac{n(n + 1)(2n + 1)}{6}$",How do you prove $$1^2 + 2^2 + 3^2 + \cdots + n^2 = \dfrac{n(n + 1)(2n + 1)}{6}$$ without induction? I'm looking for a combinatorial proof of this.,"['combinatorics', 'combinatorial-proofs']"
1639674,"$H$ be a proper subgroup of finite group $G$ such that $H \cap gHg^{-1}=\{e\} , \forall g \in G \setminus H$ , then $|\cup gHg^{-1}|>\dfrac 12 |G|+1$","Let $H$ be a proper subgroup of finite group $G$ such that $H \cap gHg^{-1}=\{e\}$ for all $g \in G \setminus H$. Then is it true that $$|\cup_{g \in G \setminus H}gHg^{-1}|>\dfrac 12 |G|+1$$ If not, then is it at least true that $$|\cup_{g \in G}gHg^{-1}|>\dfrac 12 |G|+1$$ (I know the upper bound $|\cup_{g \in G}gHg^{-1}|\le [G:H](|H|-1)+1$, but I am not aware of any lower bound. Please help. Thanks in advance.)","['finite-groups', 'group-actions', 'group-theory']"
1639767,About Factorization,"I have some issues understanding factorization. If I have the expression $x^{2}-x-7$ then (I was told like this) I can put this expression equal to zero and then find the solutions with the quadratic formula, so it gives me $x_{0,1}= 1 \pm 2\sqrt{2}$ then $$x^{2}-x-7 = (x-1-2\sqrt{2})(x-1+2\sqrt{2}).$$ That is correct I have checked it. Now for the expression $3x^{2}-x-2$ if I do the same I have $x_{0} = 1$ and $x_1=\frac{-2}{3}$ so I would have $$3x^{2}-x-2 = (x-1)(x+\frac{2}{3})$$
but this is not correct since  $(x-1)(x+\frac{2}{3}) = \frac{1}{3}(3x^{2}-x-2)$, the correct factorization is $3x^{2}-x-2 = (3x+2)(x-1)$. So I guess finding the roots of a quadratic expression is not sufficient for factorizing.",['algebra-precalculus']
1639819,What is meant by a 'pure' wave?,"What is meant by a 'pure' wave? I know it might sound like a basic question, but I've never been taught this. I saw that a sine wave is a pure wave. I tried Googling what a pure wave is, but all I get is links regarding Pure Wave Inverters for sale ...which is not what I'm looking for.",['trigonometry']
1639869,Is $\phi :SL_2(Z) \to SL_2(Z/NZ)$ still surjective if we replace Z with some ring of integers?,"It is well known that the natural map $\phi :SL_2(Z) \to SL_2(Z/NZ)$ is surjective. So that the kernel, i.e. the principal congruence subgroup is of finite index. But what if we replace Z with some ring of integers? Is this map still surjective?","['number-theory', 'algebraic-number-theory', 'modular-forms']"
1639891,"In the context of ordered statistics, each of Y(1),Y(2),...,Y(n) a single observation or distributions that are I.I.D?","In statistics one aspect of the I.I.D. concept that bothers is when I think about it in the context of ordered statistics. As most of you already know, $Y_1,Y_2,Y_3,...,Y_n$ are I.I.D. when the parameters are the same. Now, here are two things I'm confused about. In the context of ordered statistics, each of $Y_{(1)},Y_{(2)},...,Y_{(n)}$ a single observation or distributions that are I.I.D? If they are distributions, how in the world is it possible to order distributions from the least to greatest??",['statistics']
1639945,how to find $\lim_{x\to 0}\sin^2(\frac{1}{x})\sin^2 x$,"How to find $\lim_{x\to 0}\sin^2(\frac{1}{x})\sin^2 x$ ? I tried using taylor expansion: $$((x-\frac{x^3}{6}+\frac{x^5}{120}+O(x^5))(\frac{1}{x}-\frac{1}{6x^3}+\frac{1}{120x^5}+O(x^{-5})))^2$$ but it gets very complex. I am looking for  simple evalutation. Another option that I tried was using $\sin A\sin B =\frac{1}{2}(\cos (A-B)-\cos (A+B))$, but that too got stuck.","['trigonometry', 'limits-without-lhopital', 'limits']"
1639948,Does $\sin^{-1}x$ has a vertical tangent,I read that the function $f(x)$ has a vertical tangent at $x=a$ in the domain of $f$ if $$f'(a^-) \to +\infty$$ and $$f'(a^+) \to +\infty$$ Or both approach to $-\infty$. But for $f(x)=\sin^{-1}x$ $f'(x)=\frac{1}{\sqrt{1-x^2}}$ and we have $$f'(-1^+) \to +\infty$$ and $$f'(1^-) \to +\infty$$ but $f'(-1^-)$ and $f'(1+)$ are not defined. Can we still say that  it has Vertical tangent at $x=\pm 1$,"['algebra-precalculus', 'inverse']"
1639979,Zauner's conjecture,"The conjecture is as follow: In $\mathbb{C}^{n}$, there exists $\{v_1,\cdots,v_{n^2}\}$ such that the following holds: 
$$ \left| \left \langle v_i, v_j \right \rangle \right|  = \begin{cases} 1  & i = j\\ \frac{1}{n+1} & i \ne j\end{cases}$$
I have a prove for when $n = 2$, basically what I did is just assuming without loss of generality that one of the vectors is $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$, and brute force the rest of the vectors. I'm curious where this construction fails when $n \ge 3$, or has the conjecture already been proven? I can't seem to find literature that it has been proven on the Internet though.","['conjectures', 'linear-algebra', 'vector-spaces']"
1640075,Proof of the DKW inequality,"My goal is to prove the following inequality, known as the Dvoretsky-Kiefer-Wolfowitz inequality (1956) : Let $(X_i)_{i \geqslant}$ be iid random variables. Let $\displaystyle F_n(x)= \frac{1}{n}\sum _{i=1}^n 1_{X_i \leqslant x}$ and $F$ the distribution function of $X_1$. Then there exists a constant $C>0$ such that for every $\varepsilon >0$ : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  C e^{-2n\varepsilon ^2}$$ I did not find any proof on the web (only the article of DKW of 1956 but it is not understandable to me due to their notations). The only thing I found was the proof that :  $$\mathbb{E} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| \right) \leqslant  \frac{c}{\sqrt{n}}$$ in this paper : https://www.math.ens.fr/enseignement/telecharger_fichier.php?fichier=474 (theorem 3.3) which is named the DKW inequality. I was not able to prove the DKW inquality from this result btu here is my try  : By the Markov inequality and for every function : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  \frac{\mathbb{E} \left( f \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)|\right) \right)}{f(\varepsilon)} $$. With $f(x)=e^{tx}$ and using the convexity of $f$ the Jensen inequality gives :
$$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  \frac{e^{ctn^{-1/2}}}{e^{t \varepsilon}} $$ But that does not give the correct result. Question. Does anyone can help me with proving the DKW inequality with the estimate  $\mathbb{E} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| \right) \leqslant  \frac{c}{\sqrt{n}}$ for start ? Or maybe just giving me a paper with the proof in modern language. Thank you.","['statistics', 'probability', 'probability-distributions']"
1640076,If A and B are diagonalizable then so is AB,"When we have to n×n matrices that can be made diagonal (maybe not in the same basis), is it true that the same works for their product?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1640092,Polynomial in the components of the curvature tensor,"Consider a closed Riemannian manifold $(M,g)$ of dimension n and let $K(t,x,y)$ be its heat kernel. Then it is known that the heat kernel has an asymptotic expansion as $t\downarrow 0$: $$K(t,x,x)\sim (4\pi t)^{-n/2}\sum\limits_{k=0}^{\infty}u_k(x,x)t^k.$$ Often it is said that the functions $u_k(x.x)$ can be written as $O(n)-$invariant polynomials in the components of $R_x, (\nabla R)_x, (\nabla^2 R)_x,..., (\nabla^{2k-4} R)_x$ where $R$ denotes the Riemannian curvature tensor. The components of these polynomials do only depend on the dimension of $M$. I would really like to understand the above description for the functions $u_k(x,x)$ and need some help with it. My first naive interpretation would be the following: In order to evaluate $u_k(x,x)$, first choose an orthonormal basis $e_1,...,e_n$ of $T_xM$ and consider the 'components' of all the tensors above with respect to this orthonormal basis. The components would be: \begin{align}
R_x &: \lbrace g(R(e_i,e_j)e_k, e_m) \vert i,j,k,m=1,...,n\rbrace \\
 \nabla R_x&: \lbrace g(\nabla R(e_i,e_j,e_k,e_p), e_m)\vert i,j,k,m,p=1,...,n \rbrace ...\text{etc. up to $(\nabla^{4k-4}R)_x$}
\end{align} There exist a polynomial $P_k(x)$ (only depending on $k$), $x\in\mathbb{R}^N$ with $N=N(k)$ sufficiently large and $$p(x)=\sum_{\alpha\in \mathbb{N_0}^N} a_{\alpha}x^{\alpha} $$ such that: 1)  the coefficients $a_{\alpha}\in\mathbb{R}$ do only depend on the dimension $n$ (but not the particular manifold $M$) 2) If we replace formally the variables $x_1,...,x_N$ by all of the components above, we get the value $u_k(x,x)$ 3) The value of the polynomial does not depend on the choice of orthonormal basis in $T_xM$. A different choice of orthonormal basis would obviously give rise to different components, but the values of the polynomial will not be effected by such a change of basis. (This would correspond to the $O(n)$-invariance of the polynomial) I am wondering if my interpretation is correct? Even if my suggestions are right, I am sure my interpretation is not the only possible or best one. So I would be glad if you could share your knowledge and can tell me different or better ways to handle this situation. Best wishes","['riemannian-geometry', 'polynomials', 'heat-equation', 'laplacian', 'differential-geometry']"
1640122,Find the maximum number of people who participated in exactly three games?,"Gauri Apartment housing society organised annual games, 
  consisting of three games: snooker, badminton and tennis. 
  In all, $510$ people were members in the apartments' 
  society and they were invited to participate in the games. 
  Each person participating in as many games as he/she feels like. 
  While viewing the statistics of the performance, Mr Capoor realised the following
  facts. 
  The number of people who participated in at least two games 
  was $52$% more than those who participated in exactly one game. The number of people participating in $1$, $2$ or $3$ games respectively 
  was at least equal to $1$. Being a numerically inclined person, he further noticed an interesting thing: 
  The number of people who did not participate in any of the three games 
  was the minimum possible integral value with these conditions. What was the maximum number of people who participated in exactly three games? (a) $298$ (b) $300$ (c) $303$ (d) $304$ From the question I have drawn this venn diagram and concluded that $a+d+c+x=\dfrac{152\times (s+b+t)}{100} \\
\{s,b,t,a,d,c,x,\}\geq 1$ I don't know how to proceed. I look for a short and simple way. I have studied maths up to $12$th grade.",['combinatorics']
1640151,What is distribution of Poisson multiplied by positive constant,"Let $X$ is poisson distribution. $$f_{X}(n;\lambda)=\frac{\lambda^{n}}{n!}e^{-\lambda}$$ And there is some positive constant $\alpha$. I like to know pmf(probability mass function) of $Z=\alpha X$. I have searched this topic and i could find almost similar post . This post deal with distribution of $Y=\frac{X}{m}$ ($X$ is poisson and $m$ is constant). But it is not easy to understand to me. Especially calculating pgf(probability generating function) of $Y$ part! What is $D_{m,t}p(x)$? Please explain more detail.","['probability-theory', 'probability-distributions']"
1640179,Trigonometric Equation Simplification,"$$3\sin x + 4\cos x = 2$$ To solve an equation like the one above, we were taught to use the double angle identity formula to get two equations in the form of $R\cos\alpha = y$ where $R$ is a coefficient and $\alpha$ is the second angle being added to $x$ when using the double angle identity. Why can't we use the identity $\sin(x) = \cos(x-90)$ to get $3\cos(x-90) + 4\cos x = 2$? Is this equation difficult to simplify further? Additionally, why was the relationship between $sinx$ and $cosx$ in the pythagorean theorem (modified for the unit circle) not put to use? I did the following: $$\sin^2x = 1 - \cos^2x$$ $$\therefore \sin x =  ±\sqrt{1-\cos^2x}$$ If: $$\sin x = y$$ Then, $$y = ±\sqrt{1-\cos^2x}$$ Meaning that, $$\cos x = ±\sqrt{1-y^2}$$ Inputting this into the original equation, $$3y + 4\sqrt{1-y^2} = 2$$ We see, $$3y-2=-4\sqrt{1-y^2}$$
So, $$(3y-2)^2=16-16y^2$$
Therefore, $$9y^2-12y+4=16-16y^2$$
Rearranging gives, $$25y^2-12y-12=0$$
And so the solutions are, $$y_0,y_1=\frac{12}{50}\pm\frac{1}{50}\sqrt{144+1200}$$
And simplifying yields, $$y_0,y_1=\frac{6\pm4\sqrt{21}}{25}$$
Checking these solutions will give us the unique solution: $$y_0=\frac{6-4\sqrt{21}}{25}$$ $$q.e.d.$$ Can the above method be generalised? Has it been generalised?",['trigonometry']
1640208,Solving $(4y+2x-5)dx+(6y+4x-1)dy=0$ using 2 methods produced 2 different answers!,"$$(4y+2x-5)dx+(6y+4x-1)dy=0,y(-1)=2$$ First method: $$\frac{dy}{dx}=-\frac{4y+2x-5}{6y+4x-1}$$ let $Y=y-\frac{9}{2}$, $dY=dy$  and $X=x+\frac{13}{2}$, $dX=dx$;
$$\frac{dY}{dX}=-\frac{4Y+2X}{6Y+4X}$$
let $u=\frac{Y}{X}$ , $Y'=u'X+u$;
$$u'X+u=-\frac{4u+2}{6u+4}$$
$$u'X=\frac{-6u^2-8u-2}{6u+4}$$
$$\int\frac{(6u+4)du}{6u^2+8u+2}=\int-\frac{dX}{X}$$
$$\frac{1}{2}\ln|3u^2+4u+1|=-\ln|X|+Constant$$
$$\frac{1}{2}\ln|3(\frac{y-\frac{9}{2}}{x+\frac{13}{2}})^2+4(\frac{y-\frac{9}{2}}{x+\frac{13}{2}})+1|=-\ln|x+\frac{13}{2}|+Constant$$ Solving for $y(-1)=2$, $Constant=0.89587977346$;
$$\frac{1}{2}\ln|3(\frac{y-\frac{9}{2}}{x+\frac{13}{2}})^2+4(\frac{y-\frac{9}{2}}{x+\frac{13}{2}})+1|=-\ln|x+\frac{13}{2}|+0.89587977346$$ Second method: let $M=4y+2x-5$ , $N=6y+4x-1$
$$\frac{\partial M}{\partial y}=\frac{\partial N}{\partial x}=4\rightarrow Exact$$
$$\varnothing=4xy+x^2-5x+3y^2-y=Constant$$ Solving for $y(-1)=2$, $Constant=8$;
$$\varnothing=4xy+x^2-5x+3y^2-y=8$$ I plotted those two answers on MATHEMATICA and found that result: How could the results be different?",['ordinary-differential-equations']
1640209,Complex differentiability and differentiability in R2,"In $\mathbb R$  for a derivative to exist (or a limit generally) it is necessary that the limit be the same in both directions (from below and above) and this is the same in $\mathbb C$ where for a function to be differentiable at a point the difference quotient limit must be the same independent of the way $h$ approach the point, which is where the Cauchy-Riemann equations come from. Why is this only the case in $\mathbb R$ and $\mathbb C$ and not in $\mathbb R^2$? In $\mathbb R^2$ we just make a matrix/vector of partial derivatives and say the derivative is just a linear map. What is the fundamental difference that requires such different ways of defining differentiability?","['derivatives', 'complex-analysis', 'real-analysis']"
1640279,Sphere homeomorphic to interval times space,"Let $Y$ be any topological space. In my notes I found the exercise to show that: $I \times Y \approx S^n $ via a homeomorphism is not possible, where $S^n$ denotes the $n$-sphere and $I$ the unit interval. It is used in the proof of the Jordan curve theorem, so maybe a proof without using this theorem would be appropriate. Obviously $Y \simeq I \times Y \approx S^n$, hence $Y \simeq S^n  $, but I guess this does not get me any further. Thanks in advance.","['spheres', 'general-topology']"
1640343,What is the integral value of $\frac{\tan 20^\circ+\tan40^\circ+\tan80^\circ-\tan60^\circ}{\sin40^\circ}$?,I have tried possibly all approaches. I first expressed $80$ as $60+20$ and $40$ as $60-20$ and then used trig identities.I later used conditional identities expressing $\tan 20^\circ+\tan40^\circ+\tan120^\circ$ as $\tan 20^\circ \tan40^\circ \tan120^\circ$. But I really can't get to the end of it . Please help.,['trigonometry']
1640349,Number of $n$-digit permutations with exactly $n-2$ digits smaller than the next,"How many permutations of $1,2,\cdots, n$ contain exactly $n-2$ digits that are smaller than the digit immediately to their right? My solution proceeded with recursion. It has some chance of being wrong. We call all such permutations good permutations . We call a digit good if it is  are smaller than the next digit. Let $f(n)$ denote the number of good permutations of $1,2, \cdots ,n$. Note that a good permutation has exactly  $n-2$ digits. Consider any good permutation of $1,2,\cdots ,n+1$. Remove $1$ from the permutation. Note that this can decrease the number of good digits  by at most $1$. We have two cases : $1)$ Number of good digits remain the same: Since the original permutation was good, the new permutation has exactly $(n+1)-2=n-1$ good digits, but has only $n$ digits. But $n+1$ can never be a good digit, since it can never be smaller than any other digit. Hence, after removing $1$, each of $2,3,4, \cdots ,n$ is a good digit. But the only such permutation is $2$ $3$ $\cdots$ $n+1$. Now note that putting back $1$ does not increase or change the number of good digits (unless we put it at the start). Hence, there are exactly $n$ places where $1$ can go. $2)$ Number of good digits decreases: Since the number of good digits can decrease by at most $1$, in this case, the new permutation has exactly $n-2$ good digits. But there are exactly $f(n)$ of these permutations. When we put back $1$, we cannot place it in any of the following positions because then the number of good digits does not increase: A) After a good digit itself B) At the end There are exactly two places to put $1$ in then. So there are $2f(n)$ permutations in this case. Combining, we get, $f(n+1)=2f(n)+n$ Is this right? Thanks in advance","['combinatorics', 'contest-math']"
1640379,Convergence of $a_{n+1}=\sqrt{2-a_n}$,"I'm attempting to prove the convergence (or divergence, though I strongly suspect it converges) of a sequence defined as  $a_{n+1}=\sqrt{2-a_n}$ with $a_1=\sqrt{2}$. I cannot use the monotonic sequence theorem as the sequence is not monotonically increasing. In fact, the first few values of the sequence are: $a_1 =\sqrt{2}\approx 1.4142$ $a_2 =\sqrt{2-\sqrt{2}}\approx .7653$ $a_3 =\sqrt{2-\sqrt{2-\sqrt{2}}}\approx 1.1111$ Thus, it seems that $a_{n \to \infty} \to 1$ It seems that the sequence is behaving similarly to $\frac{\sin x}{x}$, leading me to think that the squeeze theorem may be useful. Still, I cannot seem to make any progress besides numerical computation of successive terms.","['recurrence-relations', 'recursion', 'sequences-and-series', 'convergence-divergence']"
1640394,$\lim_{n \to \infty} \int_{0}^{n}(1-\frac{3x}{n})^ne^{\frac{x}{2}}dx$=?,"$$\lim_{n \to \infty} \int_{0}^{n}\left(1-\frac{3x}{n}\right)^ne^{\frac{x}{2}}dx$$ I thought about using the theorem of monotonic convergence and had $$f_n{(x)}=\left(1-\frac{3x}{n}\right)^ne^{\frac{x}{2}} \lambda_{[0,n]}(x)$$ it is rising. but I don't know where it is valid to write: 
$$\lim_{n \to \infty} \int_{0}^{n}\left(1-\frac{3x}{n}\right)^ne^{\frac{x}{2}}dx= \int_{0}^{\infty}\lim_{n \to \infty}\left(1-\frac{3x}{n}\right)^ne^{\frac{x}{2}}dx=\int_{0}^{\infty}e^{\frac{x}{2}-3x}dx$$","['calculus', 'functions', 'functional-analysis', 'integration', 'measure-theory']"
1640409,Construction of a continuous function which maps some point in the interior of an open set to the boundary of the Range,"I was studying the Inverse function theorem when I came across the following problems : (Let the closed set $V$ i.e the range have non-empty interior) Does there exist a continuous onto function from an open set $U$ in $\mathbb{R}^n $ to a closed set $V$ in $\mathbb{R}^m$  such that some points in the interior of $U$ get mapped to the boundary of $V$? Does there exist a continuous $1-1$ map from an open set $U$ in $\mathbb{R}^n $ to a closed set $V$ in $\mathbb{R}^m$  such that some points in the interior of $U$ get mapped to the boundary of $V$? If there are examples in $C(\mathbb{R})$ i.e continuous functions from $\mathbb{R}$ to $\mathbb{R}$, then that would be great too! Though I do need some example in the general case too. Simpler examples will be really appreciated. Thanks in advance. Edit: The case (1) can be dealt with using any ""cut-off"" function.  e.g  let $U,V$ two balls around $0$ in $\mathbb{R}^n $ with radius $r(>1)$ and $1$, and be open and closed respectively. Let $f: U \rightarrow V $ such that $x \in V \implies f(x)=x$ and $x \in U-V \implies f(x)= x/||x|| $.","['multivariable-calculus', 'real-analysis', 'continuity', 'analysis']"
1640433,"Disentangling $\int_Af(\mathbf{x})\ d\mathbf{x}$, using Fubini Theorem.","Let $\mathcal{B}^n$ be the borel sigma algebra generated by the rectangles in $\mathbb{R}^n$. I can write $f(\mathbf{x})=g_1(x_1)\cdots g_n(x_n)$.
Let $\mu=\mu_1\times \cdots \times \mu_n$ be the Lebesgue product measure. Is it possible to write $\int_Af(\mathbf{x})\ d\mu(\mathbf{x})$, where $A \in \mathcal{B}^n$, as an expression of $\prod^n_{i=1}\int_{A_i}g_i(x_i) \, d\mu_i(\mathbf{x})$, where the $A_i$ are not dependent on each other? So, I was thinking of using the fact that the $\mathcal{B}^n$ can be generated by rectangles of the form $I_1\times \cdots \times I_n$, where $I_i \subset \mathbb{R}$ are intervals; and then use the Fubini theorem, which is valid for rectangles, to reach the expression I desire. However, I don't know how to do this... Any help would be appreciated. P.S.: What if $\mu$ is not lebesgue?","['probability-theory', 'measure-theory']"
1640435,Is there no formula for $\cos(x^2)$?,"I was wondering if there was a ""formula"" or an ""identity"" for $\cos(x^2)$, as there is for $\cos(2x)$. My question is closely related to this one, which was only asking for $\cos(ab)$. For instance $$\cos(x^2)= \frac{\cos^3(x)+\sin^3(x)}{2\cos^2(x)+2016}$$ could be such a formula. More precisely, I would like to know if the function $f : x \mapsto \cos(x^2)$ belongs to $F = \Bbb R(\cos, \sin)$. Here, the space $F$ denotes all the rational functions of the form $$x \mapsto \frac{P(\cos(x), \sin(x))}{Q(\cos(x), \sin(x))}$$ where $P, Q \in \Bbb R[X,Y]$ and $Q(\cos(x), \sin(x))≠0$ for all real numbers $x$.
(Notice that $x \mapsto \cos(nx)$ belongs to $F$ (if $n≥1$). It can be proved by induction on $n$.) My guess is no and here is why : thanks to partial fraction decomposition , every rational function has a primitive. Doing some tangent half-angle substitutions , one can see that every $g \in F$ has an explicit primitive (if I'm not mistaken). But my function $f : x \mapsto \cos(x^2)$ above has no elementary primitive. I think this can be shown thanks to Liouville's theorem . Does my reasoning is correct ? Do you have any easier argument (or counterargument) ? Any comment will be appreciated !",['trigonometry']
1640436,Nullstellensatz to prove Noether Normalization,"In many commutative algebra texts, Noether Normalization Lemma is proved and then Hilbert's Nullstellensatz is obtained as a corollary. Nullstellensatz and Normalization Lemma seem to be non-trivial theorems in their own right.   So, can we prove Noether Normalization Lemma after assuming Hilbert's Nullstellensatz.","['algebraic-geometry', 'commutative-algebra']"
1640471,Emden‐Fowler differential equation,"Good day.
I am trying to solve the following equation:
$$\ddot{y}(x)-\frac{A}{x}\dot{y}(x)+\frac{Bx^2}{2}y(x)=0.$$
WolframAlpha says it is an Emden‐Fowler equation, but I have no idea how to solve this. Can you give me some tips?
In case of $$A=B/2=1$$ WolframALpha gives an analytical solution $$y(x)=c_1 sin\frac{x^2}{2}+c_1 cos\frac{x^2}{2}.$$
If there is no analytical way to solve, can I do it numerical?
Thank you.",['ordinary-differential-equations']
1640496,"Proof that the special linear group $\mathrm{SL}(n,\mathbb{R})$ is a smooth manifold","This is my definition of a smooth manifold I am supposed to work with: Let $\mathcal{M} \subseteq \mathbb{R}^{n}$. The set $\mathcal{M}$ is a $k$-dimensional smooth submanifold of $\mathbb{R}^{n}$ if: $\mathcal{M}$ is given locally as the zero set of a function $F\colon W \to \mathbb{R}^{n-k}$, where $W \subseteq \mathbb{R}^{n}$ is open in $\mathbb{R}^{n}$, $F$ is of class $C^{\infty}$, and so that $\mathcal{M} \cap W = \{\, x \in W \mid F(x)=0\, \}$. My definition also requires that the Jacobian $\mathcal{J}_{F}(x)$ has rank $n-k$ for every point $x \in \mathcal{M} \cap W$. $\ $ The special linear group is the set $\mathrm{SL}(n,\mathbb{R}) = \{\, A \in M_{n \times n}(\mathbb{R}) \mid \det(A)=1\, \}$. I am trying to prove that this set is a smooth submanifold. From my reading online, I have understood that this submanifold has dimension $n^2-1$. I'm going to make the identification $\mathbb{R}^{n^2}\cong M_{n \times n}(\mathbb{R})$. My thoughts on proving this are to define a function $G\colon M_{n \times n}(\mathbb{R}) \to \mathbb{R}$ given by $G(A)=\det(A)-1$. We have obviously $M_{n \times n}(\mathbb{R}) \cap \mathrm{SL}(n,\mathbb{R}) = \mathrm{SL}(n,\mathbb{R})$ where $M_{n \times n}(\mathbb{R}) \cong \mathbb{R}^{n^2}$ is open, and we know that $G$ is smooth since $\det$ is smooth. Furthermore, $\mathrm{SL}(n,\mathbb{R}) = \{\, A \in M_{n \times n}(\mathbb{R}) \mid G(A)=0\, \}$. Finally, the Jacobian of the function $\mathcal{J}_{G}$ is going to be a column vector of length $n^2$, and I will need to show that it has rank $1$. But since its a column vector, isn't this an immeadiate conclusion? So to me it seems like this proof is finished. However, it seems a little too easy. Have I made any errors or omissions?","['manifolds', 'smooth-manifolds', 'differential-geometry', 'lie-groups']"
1640530,"Does there exist $a\in\mathbb N$, $b\in\mathbb Z$ that $2^na+b$ is a square for all $1\le n\le5$?","We consider such $a\in\mathbb N$, $b\in\mathbb Z$, o numbers of the form $2^na+b$ is square to the largest possible number of values of $n=1,2,3,4,\ldots$. It is easy to see that for $a = 60 $, $ b = -119 $ produced four squares: $2a+b=1=1^2$, $4a+b=121=11^2$, $8a+b=361=19^2$, $16a+b=841=29^2$. The next value $ 32a + b = 1801 $ square is no longer. And now the actual questions: a) Does there exist $a\in\mathbb N$, $b\in\mathbb Z$ that $2^na+b$  is a square for all $1\le n\le5$? b) Does there exist $a\in\mathbb N$, $b\in\mathbb N$ that $2^na+b$  is a square for all $1\le n\le4$?",['number-theory']
1640555,For which Lie groups $G$ can one write $g$ as the exponential $\exp X$ of some $X \in {\frak g}$ for every element $g \in G$?,"I am reading a book on matrix Lie algebras (Brian Hall's). Corollary 2.30. says that if  $G$ is a connected matrix Lie group, then every element $A$ of $G$ can be written in the form $$A=e^{X_1}e^{X_2}\ldots{}e^{X_m}$$ for some $X_1$,$X_2$$\ldots$$X_m$ in the Lie algebra. Immeadiately after it is stressed that even if $G$ is connected, it is not true that any every element $A$ of $G$ canbe written $$A=e^{X}$$ where $X$ is a Lie algebra element. My background is on physics, and I have many times seen Lie groups written using ony one exponential with absolute impunity (for example with $SU(2)$). Can anybody tell me when it is true that there is some $X$ Lie algebra element for every $A$ in a Lie group?","['differential-geometry', 'lie-algebras', 'lie-groups']"
1640586,"Why *all* $\epsilon > 0$, in the $\varepsilon-\delta$ limit definition?","Definition of $\lim_{x \to a} f(x) = L$ : $\forall \epsilon > 0, \exists \delta > 0 s.t. |f(x) - L| < \epsilon$ $ if \ 0 < |x-a| < \delta$ Question : Why can't we weaken the assumption to $\exists N > 0$ s.t. $\forall \epsilon \in (0, N), \exists \delta > 0 s.t. |f(x) - L| < \epsilon$ $ if \ 0 < |x-a| < \delta$ ? I think they are not equivalent. If they are, please explain how the latter proves the former and why we still need to have case 1 below. Consider proving $\forall \epsilon > 0, \exists \delta > 0 s.t. |x^2 - 25| < \epsilon$ $if \ 0 < |x-5| < \delta$ We first try to find some $\delta$ . $|x^2 - 25|$ $ = |x - 5| |x + 5| < \epsilon$ if we maybe choose $\delta$ s.t. ...: Let $M > 0$ (further restrictions may be needed). If $|x-5| < M$ , then we have $$- M < x-5 < M$$ $$\to 5 - M < x < 5 + M$$ $$\to 10 - M < x + 5 < 10 + M$$ $$\to (-10 - M) < 10 - M < x + 5 < 10 + M$$ $$|x + 5| < 10 + M$$ So we might choose $\delta = \min\{M, \frac{\epsilon}{10+M} \}$ for the two cases in the proof (it seems no further restrictions on M are needed). Proof: Let $\epsilon > 0$ . Case 1: $$\epsilon > M(10+M)$$ $$\delta = M$$ $$\to |x - 5| |x + 5| < M |x+5| < \frac{\epsilon}{10+M} (10+M) = \epsilon$$ Case 2: $$0 < \epsilon < M(10+M)$$ $$\delta = \frac{\epsilon}{10+M}$$ $$\to |x - 5| |x + 5| < \frac{\epsilon}{10+M} (10+M) = \epsilon$$ Case 3: $$\epsilon = M(10+M)$$ Pick either value of $\delta$ . QED Question in the case of this example : Cases 1 and 3 refer to tolerance levels $\ge M(10+M)$ . Why do we care about those? Why isn't enough that we have proved case 2? I'm thinking that we could just find $\delta$ 's that work for $\epsilon \in (0,N)$ for some $N > 0$ . Why do we care about all $\epsilon$ ie $\epsilon \ge N$ ?","['real-analysis', 'limits', 'calculus', 'convergence-divergence', 'definition']"
1640591,Why doesn't Cantor's diagonalization work on integers? [duplicate],"This question already has answers here : Why doesn't Cantor's diagonal argument also apply to natural numbers? (2 answers) Closed 8 years ago . Why can't you use Cantor's diagonalization argument to prove that the integers are countably infinite?
i.e. 1: 12345.... 2: 42345.... 3: 56903... 4: 46234... 5: 23421... etc. Then we could create a new integer by adding 1 to each number in the diagonal, so the new integer would be 23042. Where did I go wrong in my reasoning?","['logic', 'elementary-set-theory']"
1640599,Subsets of sets containing empty set [duplicate],"This question already has answers here : Is $\{\emptyset\}$ a subset of $\{\{\emptyset\}\}$? (5 answers) Closed 8 years ago . Why is $\{\emptyset\}$ not a subset of $\{\{\emptyset\}\}$? It contains this element, but why is it not a subset?",['elementary-set-theory']
1640641,Is there anything wrong with this definition of discontinuity?,"Is there anything wrong with this definition of discontinuity for a function y = f(x)? $\forall \delta>0\, \exists \varepsilon>0$ such that $\vert x-c\vert < \delta$, but $\vert f(x) - f(c)\vert > \epsilon$.","['epsilon-delta', 'analysis', 'definition']"
1640649,What is a Tail Field and how to interpret it?,"I cannot understand or form a good intuition in my head of what a tail field is. An introduction to rigorous probability theory by Rosenthal gives the following definition: Given a sequence of events $A_1, A_2, ...$, we define their tail field: $$\tau =  \bigcap_{n=1}^\infty\sigma(A_n, A_{n+1}, A_{n+2},\ldots) $$ So if an event A is an element of $\tau$, what does that mean in simple terms?",['probability-theory']
1640695,RQ decomposition,"Can someone explain me how we can compute RQ decomposition for a given matrix (say, $3 \times 4$). I know how to compute QR decomposition. I know the function in MATLAB which computes this RQ decomposition. But, I want to know how we can do that on paper. PS: The practical use of RQ decomposition is in extracting the intrinsic and extrinsic parameters of the camera when the camera matrix $P(3 \times 4$) is given thanks!","['matrices', 'matrix-decomposition', 'linear-algebra']"
1640706,Combinatorial argument for $\sum\limits_{k=i}^{n}\binom{n}{k}\binom{k}{i} = \binom{n}{i}2^{n-i}$,"I need to show that $$\sum\limits_{k=i}^{n}\binom{n}{k}\binom{k}{i} = \binom{n}{i}2^{n-i}$$ I know that $\displaystyle \binom{n}{k}\binom{k}{i}$ is counting the number of ways to pick $k$ elements from $n$ and then $i$ elements from those $k$, so $\displaystyle \sum\limits_{k=i}^{n}\binom{n}{k}\binom{k}{i}$ is counting the number of ways to do that $\forall k$. I know that $\displaystyle \binom{n}{i} = \binom{n}{n-i}$ and that $2^{n-i}$ is the number of elements in the power set for $[n]\setminus[i]$. How do I show that both sides are equivalent? I'm stumped on this one. Could anyone give me a pointer in the right direction?","['combinatorics', 'summation', 'binomial-coefficients']"
1640731,"How do find the numerical average of $x^x$ from $(-4,-2)$ without x-values that give a complex output?","I wanted to find the approximate average of all real points in $(x)^{x}$ from $[-4,-2]$. This means I am ignoring all real inputs that give a complex output and need average to be a real number. To first solve this I found the following defined sets of $x^x$ when $x<0$.
$$x=-\frac{2m}{2k+1}|m,k\in\mathbb{Z}$$ $$x=-\frac{2m+1}{2k+1}|m,k\in\mathbb{Z}$$ Each of the sets coincides with another equation so I got the following peice-wise definition.
$$x^x=\begin{cases} (-x)^x & x=\left\{ -{2m\over 2k+1}\ |\ m, k \in \Bbb Z\right\}\\ -\left(-x\right)^{x} & x=\left\{ -{2m+1\over 2k+1}\ |\ m, k \in \Bbb Z\right\}\ \\ \text{undefined} & x\neq\left\{ -{2m\over 2k+1}\bigcup-{2m+1\over 2k+1}\ |\ m, k \in \Bbb Z\right\} \end{cases} $$ Then I took the limit definition of an integral along with $\frac{1}{b-a}$ to determine the average.
$$\frac{1}{b-a}\lim_{n\to\infty}\sum_{i=1}^{n}{f\left(a+\left(\frac{b-a}{n}\right)i\right)}\left(\frac{b-a}{n}\right)=\frac{1}{b-a}\int_{a}^{b}f(x)$$ where $f(x)=x^x$ (Note that it is possible to skip $x$-values that given an undefined output in an interval. An example is $\{-12/3,-11/3,-10/3,-9/3,-8/3,-7/3,-6/3\}$) When $n\in\left\{\left.{4n+2}\right| n \in \mathbb{Z} \right\}$ there are numbers whose outputs coincide with $(-x)^{x}$ and numbers whose outputs coincide with $-(-x)^{x}$. So I took the probabilty of having numbers whose ouputs coincide with ($(-x)^x$ vs a numbers whose outputs coincide with $-(-x)^{x}$ in $[-4,-2]$. I got $\frac{1}{2}$ for both of them. Thus I found when $n \in \left\{\left.{4n+2}\right| n \in \mathbb{Z} \right\}$ as $n\to\infty$ $$\frac{1}{(-2)-(-4)}\lim_{n\to\infty}\sum_{i=1}^{n}{f\left(-4+\left(\frac{2}{n}\right)i\right)}\left(\frac{2}{n}\right)=\frac{1}{2}\left(\frac{1}{2}\int_{-4}^{-2}{(-x)}^{x}+\frac{1}{2}\int_{-4}^{-2}-{\left(-x\right)}^{x}\right)=0$$ But when $n$ is odd, all numbers in the interval have outputs coinciding only with $(-x)^{x}$. So when $n$ is odd integer and $n\to\infty$ $$\frac{1}{-2+4}\lim_{n\to\infty}\sum_{i=1}^{n}{f\left(-4+\left(\frac{2}{n}\right)i\right)}\left(\frac{2}{n}\right)=\frac{1}{2}\int_{-4}^{-2}{\left(-x\right)}^{x}\approx.062152$$ I have two different numbers depending on which $n$value I choose. So does this mean the average does not exist? If not how could one find the average? What other methods can be used to find a real number average? EDIT Analyzing this I believe that one should choose specific $n's$ despite a limit having to accept all $n's$ I presume that an interval of reimmmen sum interval should be as dense as possible and represent all defined numbers. This leads me to believe the average is 0. Since this goes against the definition of a limit, I think the definition of a reimmen sum should be slightly altered for dense defined inputs with undefined outputs. For example I believe intervals with numerator increase of $1$ in $\{-12/3,-11/3,-10/3,-9/3,-8/3,-7/3,-6/3\}$ can would give an accurate average compared to an numerator increase of $2$ in $\{-12/3,-10/3,-8/3,-6/3\}$. When there is numerator increase of $1$ I end up with zero. Since it represents inputs whose output coincide with both $(-x)^x$ and $-(-x)^{x}$ the average should be zero. Perhaps my reasoning is correct but I would like to find out if this is the case.","['complex-analysis', 'real-analysis', 'calculus', 'recreational-mathematics']"
1640746,"Why doesn't the limit $\lim_{(x,y) \rightarrow (0,0)} \frac{ e^{x+y} - x - y}{\sqrt{x^2 + y^2}}$ exist?","Why is this limit non-existant? $\lim_{(x,y) \rightarrow (0,0)} \frac{ e^{x+y} - x - y}{\sqrt{x^2 + y^2}}$ I can't seem to find $2$ different paths that would show it is non-existant.","['multivariable-calculus', 'real-analysis', 'analysis', 'limits']"
1640763,Show $\cos(x^2)/(1+ x^2)$ is uniformly continuous on $\Bbb R$.,"now here's how I did proceed. By definition a function $f: E →\Bbb R$ is uniformly continuous iff for every $ε > 0$, there is a $δ > 0$ such that $|x-a| < δ$ and $x,a$ are elements of $E$ implies $|f(x) - f(a)| < ε.$ Then suppose $x, a$ are elements of $\Bbb R. $
Now 
\begin{align}
|f(x) - f(a)| 
&= \left|\frac{\cos(x^2)}{1 + x^2} - \frac{\cos(a^2)}{1 + a^2}\right|
\\&= \left|  \frac{\cos(x^2)(1+a^2 )- \cos(a^2)(1+x^2)}{(1 + x^2)(1 + a^2)}\right|
\\&≤ \left|  \frac{a^2 - x^2}{(1 + x^2)(1 + a^2)}\right|
\end{align} can it be written..? the last step?
If not, please help me solve the sum.","['continuity', 'uniform-continuity', 'real-analysis', 'functions']"
1640791,Generalizing the Leibniz rule,"Given the Leibniz rule: $$\frac{d}{dy}\int^a_b f(x,y) dx = \int_b^a \frac{\partial f}{\partial y} (x,y) dx$$ How do I prove a more general case using the chain rule and the above: $$\frac{d}{dy} \int_{g_1(y)}^{g_2(y)} f(x,y) dx =?$$ From the fundamental theorem of calculus we have that: $$\frac{d}{dt} \int_{f_2(t)}^{f_1(t)} g(s) ds = g(f_1(t))f'_1(t) - g(f_2(t))f'_2(t)$$ But when I just apply the fundamental theorem of calculus I get an incorrect answer (because I also need to use Leibniz rule itself...).","['derivatives', 'leibniz-integral-rule', 'calculus', 'multivariable-calculus', 'integration']"
1640829,"Likelihood Function for the Uniform Density. $ (\theta-1,\theta+1)$","Let the random variables $X_1,X_2,\ldots,X_n$  iid $U[\theta-1\,,\theta+1]$. 
So the likelihood function therefore has the form: $$L(\theta\mid X)=\prod_{i=1}^nf(X_i\mid \theta)=\frac{1}{2^n}I(X_1, \ldots , X_n \in [\theta-1\,,\theta+1])\text{ ?}$$ It is correct ?","['statistics', 'statistical-inference', 'random-variables']"
1640870,Frobenius-Perron dimension on a fusion category,"Let $C$ be a fusion category with simple objects $V_i\in I$. The fusion rule is $V_i\otimes V_j \cong N_{i,j}^k V_k$. The Frobenius-Perron dimension of a simple object $V_i$, $\mathrm{FPdim}(i)$, is defined as the largest nonnegative real eigenvalue of a matrix $N_i$, where the $(k,j)$ entry is $(N_i)_{k j}=N_{i,j}^k$. I would like to know if we have the following equality or not. $\sum_{j\in I} \mathrm{FPdim}(j) N_{i j}^k=\mathrm{FPdim}(i) \mathrm{FPdim}(k)$ for any fixed $i, k \in I$. If so, I would like to know how to prove this. Thank you.","['fusion-categories', 'abstract-algebra', 'category-theory', 'group-theory', 'linear-algebra']"
1640913,Proof of $\aleph_0^{\aleph_0} = \mathbb{c}$ without using Cantor's $2^{\aleph_0} = \mathbb{c}$,"Prove that $\aleph_0^{\aleph_0} = \mathbb{c}$ without using Cantor's $2^{\aleph_0} = \mathbb{c}$ Card $\mathbb{N}^\mathbb{N} = \aleph_0^{\aleph_0}$ Card $(0, 1) = \mathbb{c}$ Define: $f: (0, 1) \rightarrow \mathbb{N}^\mathbb{N}\:\:$ , by $f(0.a_1a_2...a_n...) = \langle a_1,a_2...a_n...\rangle$ $f$ is a injective $\Rightarrow \mathbb{c} \leq \aleph_0^{\aleph_0}$ But i am not sure how to finish it form here.","['cardinals', 'elementary-set-theory', 'elementary-number-theory']"
1640916,Composition involving bounded linear operators,"I recently come across the following statement mentioned in a proof: Let $X,Y$ be normed linear spaces and $T:X \rightarrow Y$ be a linear operator. if for every bounded linear functional $U: Y \rightarrow \mathbb{R}$ , $UT$ is bounded, then $T$ is also bounded. How can we justify this statement?","['functional-analysis', 'normed-spaces', 'operator-theory', 'analysis']"
1640926,Counting permutations with given condition,"I need to find number of permutations $p$ of set $\lbrace 1,2,3, \ldots, n \rbrace$ such for all $i$ $p_{i+1} \neq p_i + 1$. I think that inclusion-exclusion principle would be useful. Let $A_k$ be set of all permutation that for every permutation $a$ in this set $a_{k+1} \neq a_k + 1$. So our answer would be $| A_1 \cap A_2 \cap \ldots \cap A_n |$. Could you help me with completing the proof?","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
1640929,application of L'Hopital's rule?,"I am trying to evaluate the following  limit: 
$$
\lim_{x \to 0} \frac{e^x}{\sum_{n = 1}^\infty n^k e^{-nx}},
$$
where $k$ is a large (but fixed) positive integer. I am unsure how to proceed. Can this be done using L'Hopital's rule? Just started learning calculus, thanks guys!!","['derivatives', 'calculus', 'limits']"
1640938,Trapezoidal rule - truncation error,"I am trying to prove that when solving numerically diff. eq.:
$$
y'(t)=f(t,y(t)), \hspace{0.5cm}  y(t_{0})=y_{0}
$$
using trapezoidal rule, namely:
$$
y_{n+1}=y_{n} + \frac{h}{2} \left( f(t_{n},y_{n}) + f(t_{n+1},y_{n+1}) \right)
$$
we get LTE (local truncation error) proportional to $C h^{3}$, $C=const$. Let's denote LTE in $n+1$-th step as:
$$
e_{n+1}= \phi(t_{n+1}) - y_{n+1}
$$
where $\phi(t_{n})$ represents the actual solution of our problem at $t=t_{n}$ and we assume that at the $n$-th step our approximating solution is exact with the real one ($\phi(t_{n}) = y_{n}$). I know that the most common method starts at representing $\phi(t)$ as the Taylor series about $t_{n+1}=t_{n}+h$ and using the fact that $\phi'(t_{n}) = f(t_{n},\phi(t_{n}))$. In this particular example I used two Taylor representations: $\phi(t_{n+1})=\phi(t_{n}+h)$ and $\phi(t_{n+1}-h)=\phi(t_{n})$. Combining them resulted in the formula:
$$
\phi(t_{n+1})=\phi(t_{n}) + \frac{h}{2}(\phi'(t_{n})+\phi'(t_{n+1})) + \frac{h^{2}}{4}(\phi''(t_{n})-\phi''(t_{n+1})) + \frac{h^{3}}{12}(\phi'''(\xi_{n})+\phi'''(\eta_{n+1}))
$$
where:
$$
t_{n}<\xi_{n}<t_{n}+h
$$
$$
t_{n}<\eta_{n+1}<t_{n}+h
$$
So plugging this obtained formula for $\phi(t_{n+1})$ into the equation 
$$
e_{n+1} = \phi(t_{n+1}) - y_{n+1} = \phi(t_{n+1}) -y_{n} - \frac{h}{2} \left( f(t_{n},y_{n}) + f(t_{n+1},y_{n+1}) \right)
$$
and assuming that $\phi(t_{n})=y_{n}$ resulted in:
$$
e_{n+1} = \frac{h^{2}}{4}(\phi''(t_{n})-\phi''(t_{n+1})) + \frac{h^{3}}{12}(\phi'''(\xi_{n})+\phi'''(\eta_{n+1}))
$$
So it would be $e_{n+1}=O(h^{2})$, not $O(h^{3})$ (and we know that it is $O(h^{3})$). I saw in the literature that assuming correctness of approximation at $t_{n}$ means that trapezoidal rule can be represented as:
$$
y_{n+1} = y_{n} + \frac{h}{2} \left( f(t_{n},\phi(t_{n})) + f(t_{n+1},\phi(t_{n+1})) \right)
$$
but it doesn't make sense to me because of the correctness of the term $\phi(t_{n+1})$. I hope that I presented my problem clearly, thanks in advance for any help  with solving it!","['numerical-methods', 'ordinary-differential-equations']"
1640940,Tough definite integral: $\int_0^\frac{\pi}{2}x\ln^2(\sin x)~dx$,Any ideas on evaluating the definite integral $$\int_0^\frac{\pi}{2}x\ln^2(\sin x)\ dx$$ The best numerical approximation I could get is $0.2796245358$ . Is there even a closed form solution?,"['calculus', 'integration', 'definite-integrals', 'harmonic-numbers', 'trigonometric-integrals']"
1640980,Converting programming logic to mathematical notation,"How do I go about converting programming logic to mathematic notation? For example, I read a question that asks: A piece of software is set to run every 35 minutes. The time is now 2.03pm. The software last ran at 1.25pm. Write a solution that checks to see if the software needs to be ran. Easy enough. First convert the current time, and last run time, to timestamps. Add 35 minutes to the last ran timestamp and check if this time is less than the current time. if((last_run_ts + 35 minutes) <= current_time_ts)
    run_software() I was curious on how I would express this in mathematical notation? I know that a lot of algorithms are first written in mathematical notation, and converted to programming code afterwards. I've never had to do this personally. And where can I learn more about this? Would most of this be discrete mathematics?","['computer-science', 'discrete-mathematics']"
1640985,"Prove for all integers n such that n ≥ 3, $ 4^3 + 4^4 + 4^5 … 4^n = \frac{4(4^n - 16)}{3}$","I am trying to prove this using mathematical induction, but I'm lost once I get to comparing the two sides of the equation. Proposition: For all integers n such that n ≥ 3, $ 4^3  + 4^4 + 4^5 … 4^n = \frac{4(4^n - 16)}{3}$ Proof: Let the property P(n) be the equation $P(n) = 4^3  + 4^4 + 4^5 … 4^n = \frac{4(4^n - 16)}{3}$ Show that P(3) is true: $4^3 = \frac{4(4^3 - 16)}{3}$ 64 = 64, thus P(3) is true Show that for all integers where n ≥ 3, if P(k) is true, then P(k + 1) is also true: Suppose that P(k) is true for some particular but arbitrary integer where k ≥ 3.  Suppose that k is any integer where k ≥ 3 such that: $4^3  + 4^4 + 4^5 … 4^k = \frac{4(4^k - 16)}{3}$ We must show that P(k + 1) is true.  That is, we must show that: $4^3  + 4^4 + 4^5 … 4^{k + 1} = \frac{4(4^{k + 1} - 16)}{3}$ The left hand side is: $4^3  + 4^4 + 4^5 … 4^{k + 1}$ $4^3  + 4^4 + 4^5 … 4k + 4^{k + 1}$ $4^3  + 4^4 + 4^5 … \frac{4(4^k - 16)}{3} + 4^{k + 1}$","['proof-verification', 'discrete-mathematics']"
1640991,An explanation of how this solution is derived,"I am having difficulty understanding the solution to this problem. 
Since the solution is in the form of Bayes theorem I expected something along the lines that looked similar to Bayes theorem. Suppose that in each individual of a large population there is a pair of genes that determine eye color. Each of these genes can be x or X and they follow these rules: xx – blue eyes Xx, xX (heterozygote) – brown eyes XX – brown eyes The proportion of blue-eyed individuals is $p^2$ and of heterozygotes
it’s $2p(1-p)$, where $0<p<1$. Each parent transmits one if its own genes to the child. If a parent is a heterozygote, the probability that it transmits the genes of type X is $0.5$. Assuming random mating, show that among brown-eyed children of brown-eyed parents, the expected proportion of heterozygotes is $\frac{2p}{1+2p}$ the solution is set up as follows: $Pr$(child is heterozygote | child has brown eyes and parents have brown eyes) =","['bayes-theorem', 'bayesian', 'machine-learning', 'statistics', 'probability']"
1641036,Is the set of all topological spaces bigger than the set of all metric space?,"I was wondering right that since the notion of a topology is much more general than that of a metric, and that ""neighborhodness"", if you will, and the concept of continuity, is generalized by the notion of a topology. so is the set of all topological spaces actually bigger than that of metric spaces? in other words if $$\mathscr{T}=\{x|x \text{ is a topological space}\}$$
and if $$\mathscr{M}=\{x|x\text{ is a metric space}\}$$ then is $$\text{card}\mathscr{T}>\text{card}\mathscr{M}$$ or are they equal? in both cases how can we prove that? or perhaps the sets $\mathscr{T}$ and $\mathscr{M}$ don't even exist at all similar to how the set of all sets doesn't exist?","['general-topology', 'set-theory']"
1641071,Why is $|V(I)| \leq d_1\cdots d_n$?,"If $I \subset K[x_1,\dots,x_n]$ is a zero dimensional ideal and $$V(I) = \{ (\alpha_1,\dots,\alpha_n) \in K^n: f((\alpha_1,\dots,\alpha_n)) = 0\ \forall f\in I\}$$ (the variety). Then if $G$ is a Groebner Basis for $I$ w.r.t. some monomial order $>$, then $\forall i$ $\exists g_i \in G$ such that $LT(g_i) = x_i^{d_i}$ for some $d_i > 0$. Why is $|V(I)| \leq d_1\cdots d_n$?","['algebraic-geometry', 'groebner-basis', 'ring-theory', 'commutative-algebra', 'ideals']"
1641094,Raising e to the power of both sides of an equation,"I have a simple question: in differential equations, it has been common in several of my homework problems to raise a base $e$ to the power of both sides of an equation to get variables out of natural log functions. My question is what happens if you have a zero term? For example: $$
ln(x) + ln(y) = z
$$
is equivalent to
$$
e^{ln(x)} + e^{ln(y)} = e^z
$$ which simplifies to
$$
x + y = e^z
$$ But what happens if $y=1$? $$
ln(x) + ln(1) = z
$$
$$
ln(x) + 0 = z
$$ At this point, if you removed zero from the equation and then raised both sides by $e$, you would get $x = e^z$ when it should be $x + 1 = e^z$. Thinking about it in this manner, one could claim the following: $$
1 + 0 = 1
$$
$$
e^1 + e^0 = e^1
$$
$$
e + 1 = e
$$
$$
1 = 0
$$
Is there some rule that explains why this algebra breaks down, and when it is wrong to raise both sides of an equation by $e$? This thought experiment is obviously incorrect, but in my first example, it is incorrect if you don't include zero in your raising-by-e operation.",['ordinary-differential-equations']
1641100,Why is a projective variety 'the best kind'?,"In Hartshorne's AG, he discusses the classification of curves by birational equivalence class  says 'based on the idea that a nonsingular projective variety is the best kind..'. What exactly makes a projective variety better than an affine one? I know for each class there is a unique nonsingular projective curve. While this may be a reason projective varieties are special it can't really serve as motivation for that section. I know projective varieties have nice intersection properties but that's not really intrinsic to the birational equivalence classes. Why shouldn't an affine variety serve as our model?","['soft-question', 'algebraic-geometry']"
1641102,Row swapping through matrix multiplication,Let's say I have a matrix \begin{bmatrix}a&b\\c&d\end{bmatrix} What would I have the multiply the matrix above by to obtain the following? **\begin{bmatrix}c&d\\a&b\end{bmatrix},"['matrices', 'linear-algebra']"
1641110,Proof that the Rubik’s Cube group is 2-generated,"Singmaster (1981) writes, on page 32 of his Notes on Rubik’s Magic Cube : Frank Barnes observes that the group of the cube is generated by two moves:
  \begin{align*}
\alpha &= L^2 B R D^{-1} L^{-1} &=(RF,RU,RB,UB,LD,LB,LU,BD,DF,FL,RD)& \\
&&\cdot (FUR,UBR,LDB,LBU,DLF,BDR,DFR)\\
\beta &= UFRUR^{-1}U^{-1}F^{-1} &=(UF,UL)_+(UR)_+(UBR,UFL)_-(URF)_+
\end{align*}
  Observe that $\alpha^7$ is an $11$-cycle of edges and $\alpha^{11}$ is a $7$-cycle of corners, that $\beta$ affects the edge and corner left fixed by $\alpha$, and that $$\beta^2 = (UF)_+(UL)_+(UBR)_-(UFL)_-(UFR)_-$$ [...] The remaining details are left as an exercise. I hadn't seen this notation before, so I'll explain it here. Notation like $(LU, BD, DF)$ means an edge cycle , in which: The $L$-$U$ edge moves to the $B$-$D$ edge's place, with the $L$ half ending up on the $B$ face, and the $U$ half ending up on the $D$ face. Similarly $BD \to DF$ and $DF \to LU$. The notation for corners is similar. Notation like $(UF, UL)_+$ is a twisted cycle : again, $UF \to UL$, but now $UL \to FU$; the final edge gets flipped when cycling back to the first edge. For corners, the notation is similar, but corners rotate , they don't flip. A subscript $+$ means clockwise rotation, a subscript $-$ means counterclockwise rotation. $(UR)_+$ means a single edge is flipped. $(UBR)_-$ means a single corner is rotated counterclockwise. I would like to show that this is indeed true, by writing each element in $\{F,B,L,R,U,D\}$ as a product of elements in $\{\alpha, \beta, \alpha^{-1}, \beta^{-1}\}$ – preferably, having those product be as short as possible. How would I go about finding them? (I'm okay with using software like GAP – if it is at all computationally possible.)","['rubiks-cube', 'group-theory', 'gap']"
1641119,"Prove if $\sum\limits_{n=1}^ \infty a_n$ converges, {$b_n$} is bounded & monotone, then $\sum\limits_{n=1}^ \infty a_nb_n$ converges.","Prove that if $\displaystyle \sum_{n=1}^ \infty a_n$ converges, and {$b_n$} is bounded and monotone, then $\displaystyle \sum_{n=1}^ \infty a_nb_n$ converges. No, $a_n, b_n$ are not necessarily positive numbers. I've been trying to use the Dirichlet's Test, but I have no way to show that $b_n$ goes to zero. If I switch $a_n$ and $b_n$ in Dirichlet's Test, I can show $a_n$ goes to zero, but then I'm having trouble showing that $\displaystyle \sum_{n=1}^ \infty \left\lvert a_{n+1}-a_{n}\right\rvert$ converges (because $a_n$ isn't necessarily monotone).","['real-analysis', 'convergence-divergence', 'sequences-and-series', 'analysis']"
1641178,checking that an initial condition holds for the heat equation,"I'm trying to follow a video lecture on solving the heat equation. $I) \space u_t = ku_{xx}, x \in \mathbb{R}, t > 0$ $II) \space u(x,0)=\phi (x), $ $k$ is const, $\phi (x) $ is a known function. An earlier video in lecture series proved these properties: If $u(x,t)$ is a solution to $I)$ then for each fixed $y$, the translate
  $u(x-y,t)$ is also a solution. If $u$ is a solution then every derivative of $u$ is also a solution. Every linear combination of solutions is also a solution. If $S(x,t)$ is a solution then so is its integral. Thus $S(x-y,t)$ is a
  solution and so is $\int_{-\infty}^{\infty} S(x-y,t)g(y)dy$ for each
  function $g$ that makes the integral converge. If $u(x,t)$ is a solution the for each $a>0$ the dilates function
  $u(\sqrt{a}x,at)$ is also a solution. Using the the translate and integral properties, you can find this solution to $I)$ as $u(x,t)=\displaystyle \int_{-\infty}^{\infty} S(x-y,t)\phi(y)dy $ The first part of the video shows that $I)$ holds. To show that the initial condition $II)$ holds, you begin by doing the following: $S := \frac{\partial }{\partial x}Q$ $u(x,t)=\displaystyle \int_{-\infty}^{\infty} \frac{\partial }{\partial x} Q(x-y,t)\phi(y)dy $ $
\color{green}{\mathbb{\bf*}} \\
=  \displaystyle \int_{-\infty}^{\infty} \frac{\partial }{\partial y}[-Q (x-y,t)]\phi(y)dy     $ Using integration by parts: $- \displaystyle \int_{-\infty}^{\infty} Q_y (x-y,t)\phi(y)dy     $ $\begin{array}{ll}
w &=\phi(y)     & v_y = Q_y(x-y,t) \\
w_y &=\phi'(y)  & v = -Q(x-y,t)
 \end{array}$ $=-  \left[ -Q (x-y,t)\phi(y)\bigg |_{y \rightarrow -\infty}^{y \rightarrow \infty}- \displaystyle \int_{-\infty}^{\infty}  -Q (x-y,t)   \phi'(y)dy  \right]$ $=Q (x-y,t)\phi(y)\bigg |_{y \rightarrow -\infty}^{y \rightarrow \infty}- \displaystyle \int_{-\infty}^{\infty}  Q (x-y,t)   \phi'(y)dy  $ I don't understand what happens on the line labeled $\color{green}{\mathbb{\bf*}}$. Why can you switch from $Q_x$ to $-Q_y$?","['heat-equation', 'ordinary-differential-equations', 'partial-differential-equations']"
1641188,When is the metric completion of a Riemannian manifold a manifold with boundary?,"Let $(M,g)$ be a connected smooth Riemannian manifold and denote by $(M,d)$ the induced metric space following by taking topological metric to be the infimum over length of curves in the standard way. Suppose that $(M,d)$ is not complete and let $(\hat{M},d)$ denote the metric completion. What can be said about $(\hat{M},d)$ being a smooth manifold with smooth boundary? Edit: Take e.g. any open rectangle in Euclidean space. Then the completion will have a boundary that is not smooth (at the corners).","['riemannian-geometry', 'differential-geometry']"
1641214,Are there complex numbers whose sines are zero?,"I recently learned that $\sin(z)$ has an extension into the complex plane, namely: $$\frac{e^{iz}-e^{-iz}}{2i}$$ Is there any complex number $z=a+bi$, with $b≠0$ such that $\sin(z)=0$ ? I am already aware of the 'trivial' zeros when $a=πk$ with $k\in\Bbb Z$ and $b=0$. Is there any way to prove this? Either complete solutions/proofs or hints would both be helpful.","['complex-analysis', 'trigonometry', 'complex-numbers']"
1641263,"Interesting cube subdivisions: what is going on here, and what are these polytopes?","I was messing around recently with a unit cube. If you draw vertices on the midpoint of each edge of the cube, then connect those points by new edges, you will form the wireframe of what I figured out is a cuboctohedron. If you repeat this process on the cuboctohedron (drawing vertices on the midpoints of the edges of the cuboctohedron and connecting them with new edges, you form the wireframe of what I discovered was the rhombicuboctohedron. Repeating this, you end up on the 3rd iteration with another polytope which eludes my identification. I started drawing net maps of these things and I still don't know what the 3rd+ iteration polytopes actually are. The vertices, edges, and faces are as follows for each iteration (if this helps). iteration: 1  ,       2   ,     3    ,      4    ,     5 ... vertices: 8, 12, 24, 48, 96, 192 ... faces: 6, 14, 26, 50, 98, 196 ... edges: 12, 24, 48, 96, 192, 386 ... I can't wrap my mind around why this creates these polytopes. Any ideas?
Also, what are the polytopes in the 3+ iterations? Thanks, in advance.","['polyhedra', 'solid-geometry', 'polytopes', 'geometry']"
1641264,Concavity of the $n$th root of the volume of $r$-neighborhoods of a set,"Let $A$ be a closed subset of $\mathbb{R}^n$. For $r>0$, let $A_r$ be the $r$-neighborhood of $A$, namely the set $\{x:\operatorname{dist}(x,A)\le r\}$. Is the function $f(r) = \mu(A_r)^{1/n}$ concave? ($\mu$ is the Lebesgue measure.) Context This came up in the discussion of George Lowther's answer , where I asserted that the concavity of $f$ follows from the Brunn-Minkowski inequality . As George Lowther pointed out, this approach seems to require $A$ to be convex. Here's a proof for convex $A$. Since $A$ is convex, we have $A=\frac12(A+A)$, using Minkowski/vector addition. Let $B$ be the closed unit ball (also convex). For $r,s>0$ we have 
$$
A+\frac{r+s}{2}B = \frac12 (A+A)+\frac r2 B + \frac s2 B = \frac12(A+rB)+\frac12(A+sB)
$$
Taking the $n$th root of volume on both sides and using the Brunn-Minkowski inequality, we obtain
$$
f((r+s)/2) = \mu\left(\frac12(A+rB)+\frac12(A+sB)\right)^{1/n} \ge 
\frac12 \mu(A+rB)^{1/n}+\frac12 \mu(A+sB)^{1/n}
$$
proving that $f$ is midpoint-concave. Since it's also monotone, it is concave. The proof falls apart when $A$ is not convex, since the inclusion $A\subset \frac12(A+A)$ goes the wrong way. But I don't see a counterexample.","['volume', 'measure-theory', 'convex-analysis']"
1641268,Uniqueness of Smith normal form in Z (ring of integers),"It is a very well known fact that Smith Normal Form has proven useful when dealing with the development of the structure theorem of finitely generated abelian groups. In this context, there is an approach that takes advantage of the next result, which indeed is a very particular case of a much more general theorem related with a special kind of rings. If $A$ is a $m\times n$ matrix with integer coefficients, then there exist two matrices $P$ of size $m\times m$ and $Q$ of size $n\times n$, both having integer entries and $\det =\pm 1$, such that $PAQ$ is a diagonal matrix with diagonal entries $d_1,d_2,\ldots,d_k$ ($k<\min(m,n)$) such that $d_1\mid d_2\mid \ldots\mid d_k$, and each $d_i$ is a positive integer.
Furthermore, $d_1\mid \ldots\mid d_k$ are unique. I have no problem with the proof of the ""existence"" part of the last theorem. However, I can't manage to give a proof of the ""uniqueness"" part; at most, I can only show that if $d'_1\mid\ldots\mid d'_{\ell}$ have the same property, then $d'_1 = d_1$ (they are both the gcd of the entries of $A$). The idea is not to give a proof using structure theorems, but only any kind of ""very elemental"" proof (dealing, if possible, just with $\mathbb{Z}$ properties, and not talking about general rings/modules).","['matrices', 'abstract-algebra', 'linear-algebra', 'smith-normal-form']"
1641323,Multi-stage Probability,"I think the easiest way to explain what I'm having trouble with is to give an example question: A monkey is given 12 blocks: 3 Squares, 3 Rectangles, 3 Triangles, 3 Circles. Calculate the probability of it drawing three of each kind in order - say, 3 triangles, then 3 squares and so on. I have done this question and gotten the right answer, however, I am not happy with my working out: $\frac{2}{11}* \frac{1}{10}* \frac{1}{4}* \frac{1}{7}* \frac{2}{5}* \frac{1}{4} = \frac{1}{15400}$ As you can see, I've basically gone through step by step, calculating the probability of each individual draw. My textbook shows the answer as this: $\frac{(4!)(3!)^4}{12!}=\frac{1}{15400}$ I have been told the reasoning is that firstly, there are $P_4^4$ ways of drawing the pattern in general (i.e. TCSR, CTRS, RTSC, etc.)... I understand this step but not sure as to why it is being done. Secondly, each pattern can be arranged in $P_3^3$ ways (i.e. T1, T3, T2). I understand this but i have no idea as to why the order of drawing these is relevant. Then from there I have absolutely no idea where any of the other part of the calculation arises from. Could someone please walk me through this example?","['permutations', 'probability']"
1641331,Defining the states when we roll one single die repeatedly,"We roll a single die and the game stops as soon as the sum of two successive rolls is either 5 or 7.
  We want to find the probability that the game stops at a sum of 5. It seems like Markov chain with first-step analysis. To find the transition matrix, I first need to define the states. They way I define it is that if we have (1,2) then next state should be (2,x) for x=1,2,3,4,5,6. And (1,2) is different from (2,1). So, there must be 36 states?","['stochastic-processes', 'markov-chains', 'probability']"
1641348,Is there a polynomial such that $F(p)$ is always divisible by a prime greater than $p$?,"Is there an integer-valued polynomial $F$ such that for all prime $p$, $F(p)$ is divisible by a prime greater than $p$?  For example, $n^2+1$ doesn't work, since $7^2+1 = 2 \cdot 5^2$.  I can see that without loss of generality it can be assumed that $F(0) \ne 0$.  Also, it is enough to find a polynomial where the property is true for sufficiently large prime $p$, since we could multiply that polynomial by some prime in the sufficiently large range and fix all the smaller cases. I think it is possible that there are no such polynomials, is there any good hint for proving this? I can't find any solutions to $\text{gpf}(p^4+1) \le p$ for prime $p \le 10000$, where $\text{gpf}$ is the greatest prime factor, but there are plenty for $\text{gpf}(p^3+1) \le p$, for example $\text{gpf}(2971^3+1) = 743 \lt 2971$.  So I guess $F(p) = p^4+1$ might be an example.  I also checked higher powers for small $p$ and couldn't find solutions there either, so $k \ge 4 \rightarrow \text{gpf}(p^k+1) \gt p$ is plausible.","['number-theory', 'polynomials', 'prime-numbers']"
1641364,Proving that the Calkin-Wilf tree enumerates the rationals.,"The Calkin-Wilf tree is an infinite undirected graph (tree) which is constructed as follows: starting from the root at $\frac{1}{1}$, each node $\frac{a}{b}$ has two children: a left child $\frac{a}{a+b}$ a right child $\frac{a+b}{b}$ This tree has the property that every rational appears in it exactly once, in lowest terms. I'm interested in ways to intuitively understand this fact. Most of what I know on this topic comes from this wonderful blog , which gives a proof [*] of the above at the link. He points out that every child uniquely defines a parent, and that every parent has a either a smaller numerator or a smaller denominator than its child. Therefore, if you start from any fraction $\frac{p}{q}$ in lowest terms, you can always trace a path back to $\frac{1}{1}$, the root. This is a really nice proof, but it feels a bit ""backwards"" to me, in that we visualize walking the tree from the bottom up. Does anyone know of alternate proofs of this fact? I don't need rigor, just intuition. Thoughts: Clearly, all children must have either a greater numerator or a greater denominator than any of their ancestors, so they can't be repeats of an ancestor. (We also need ""lowest terms"" for this, but that follows by a separate argument -- see footnote). So I'm only worried about ""cousins"". Perhaps there is some property that all the left children of a node share, which the right children do not? That would solve the problem, I believe. *My summary only covers the part of his argument that proves ""every rational appears in it exactly once."" The ""in lowest terms"" part involves Euclid's Algorithm, and is covered in the next post .","['rational-numbers', 'sequences-and-series', 'elementary-number-theory']"
1641378,Find number of ways to seat $n$ boys and $n$ girls in a row so that every boy has at least one girl sitting beside him.,My attempt: I am getting $2^n(n!)^2$ . First I paired $n$ boys and $n$ girls in $n!$ ways then these pairs can be arranged in $n!$ ways and in each of these pairs boy and girl can arrange themselves in $2!$ ways.,['combinatorics']
1641388,"Does a contractible set have contractible preimage, under a linear map?","Let $T:V\to W$ be a linear map of vector spaces, and let $A\subset W$ be contractible. Then is $T^{-1}(A)$ also contractible?","['functional-analysis', 'linear-algebra']"
1641389,Function with infinite maxima and minima [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Can you please give an example of a function with an infinite number of maxima and minima occurring in any finite time interval? Edit: This question came to me as I was reading on the dirichlet conditions for the fourier transform of a function $g(t)$ to exist. Given that $g(t)$ is a non-periodic and deterministic signal, one of the conditions is that $g(t)$ be a single-valued function, with a finite number of maxima and minima in any finite time interval. Hence the question.","['special-functions', 'functions']"
1641411,Check the proof of $||x||^2$ is not a norm,"Show if $f$ is a norm: For $\mathbb{R}^n$, Define $f: \mathbb{R}^n \rightarrow \mathbb{R} $ by $ f(x) = \|x\|^2$ =$\sum_{n} x_n^2 $ I tried to solve if $f$ satisfies the three properties of a norm: 1) zero vector 2)positive homogeneity 3)Triangle Inequality. It satisfies the 1st property obviously. For the 2nd property, I got $f(ax)= ||ax||^2=ax \cdot ax=a^2||x||^2 \neq |a|||x||^2$, so $f$ does not satisfy the 2nd property. For the 3rd property, I got $f(x+y)=||x+y||^2=(x+y)\cdot (x+y)=||x||^2+2x\cdot y+||y||^2$. In order to satisfy the triangle inequality, it has to be that $||x||^2+2x\cdot y+||y||^2 \le ||x||^2+||y||^2$, i.e, $x \cdot y \le 0$, but there's no guarantee that $x \cdot y \le 0$, therefore the triangule inequality is not satisfied. Since $f$ does not satisfy the second and third property, it is not a norm in $\Bbb R^n$. Is the above proof correct? If it's not right, could someone provide a proof of this problem? Thanks.","['functional-analysis', 'real-analysis']"
1641414,Theorem 2.43 in Baby Rudin: How to understand the proof?,"Here's Theorem 2.43 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Let $P$ be a non-empty perfect set in $\mathbb{R}^k$ . Then $P$ is uncountable. Here's the definition of a perfect set: Let $(X,d)$ be a metric space, and let $P \subset X$ . Then $P$ is perfect if it is closed (i.e. it contains all of its limit points) and every point of $P$ is also a limit point of $P$ . Now here's the proof Rudin gives: Since $P$ has limit points, $P$ must be infinite. Suppose $P$ is countable, and denote the points of $P$ by $x_1, x_2, x_3, \ldots$ . We shall construct a sequence $\{V_n\}$ of neighborhoods as follows: Let $V_1$ be any neighborhood of $x_1$ . If $V_1$ consists of all $y \in \mathbb{R}^k$ such that $\vert y - x_1 \vert < r$ , the closure $\overline{V_1}$ of $V_1$ is the set of all $y \in \mathbb{R}^k$ such that $\vert y - x_1 \vert \leq r$ . Supose $V_n$ has been constructed, so that $V_n \cap P$ is not empty. Since every point of $P$ is a limit point of $P$ , there is a neighborhood $V_{n+1}$ such that (i) $\overline{V_{n+1}} \subset V_n$ , (ii) $x_n \not\in \overline{V_{n+1}}$ , (iii) $V_{n+1} \cap P$ is not empty. By (iii), $V_{n+1}$ satisfies our induction hypothesis, and the construction can proceed. Put $K_n = \overline{V_n} \cap P$ . Since $\overline{V_n}$ is closed and bounded, $\overline{V_n}$ is compact. Since $x_n \not\in K_{n+1}$ , no point of $P$ lies in $\cap_1^\infty K_n$ . Since $K_n \subset P$ , this implies that $\cap_1^\infty K_n$ is empty. But each $K_n$ is non-empty, by (iii), and $K_n \supset K_{n+1}$ , by (i); this contradicts the Corollary to Theorem 2.36. Finally, here's Theorem 2.36: If $\{K_\alpha\}$ is a collection of compact subsets of a metric space $X$ such that the intersection of every finite subcollection of $\{K_\alpha\}$ is nonempty, then $\cap K_\alpha$ is nonempty. And, here's the Corollary to Theorem 2.36: If $\{K_n\}$ is a sequence of nonempty compact sets such that $K_n \supset K_{n+1}$ ( $n=1, 2, 3, \ldots$ ), then $\cap_1^\infty K_n$ is not empty. Now my question is, what exactly is the induction hypothesis that Rudin refers to in the proof? For $V_1$ , he only says that it is any neighborhood of the point $x_1$ . What is the induction hypothesis? Please also proceed from $V_1$ to $V_2$ , and then from $V_2$ to $V_3$ for the sake of illustration. After reading David's comment, I've modified my proof as follows: Since $P$ is nonempty, it has a point $a$ , which is also a limit point of $P$ since $P$ is perfect. But no finite set in a metric space can have a limit point. So $P$ must be infinite. Suppose that $P$ is countable, and let's denote the points of $P$ by $x_1, x_2, x_3, \ldots$ . We shall construct a sequence $V_n$ of neighborhoods such that, for each $n \in \mathbb{N}$ , the intersection $V_n \cap P$ is non-empty and $x_n \not\in V_{n+1}$ . Let $V_1$ be any neighborhood of $x_1$ . Then we can show that if $$V_1  = \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - x_1 \vert < \epsilon_1 \ \right\},$$ where $\epsilon_1$ is some positive real number, then the closure $\overline{V_1}$ of $V_1$ is given by $$ \overline{V_1} = \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - x_1 \vert  \leq \epsilon_1 \ \right\}.$$ Since $x_1$ is a limit point of set $P$ , the nieghborhood $V_1$ of $x_1$ contains a point, say, $y_1$ of $P$ other than the point $x_1$ itself. Now $y_1 \in V_1$ and $V_1$ is an open set in the metric space $\mathbb{R}^k$ . So there is a positive real number $\delta_1$ such that $N_{\delta_1} (y_1) \subset V_1$ , where $$N_{\delta_1} (y_1)  \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - y_1 \vert  < \delta_1 \ \right\}.$$ Let $$\epsilon_2 \colon= \frac 1 2 \min \left( \delta_1, \vert x_1 - y_1 \vert \right).$$ Then $\epsilon_2 > 0$ .
  Let $$V_2 \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - y_1 \vert  < \epsilon_2 \ \right\}.$$ Then $$\overline{V_2} = \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - y_1 \vert  \leq  \epsilon_2 \ \right\}.$$ Thus, $V_2$ is a neighborhood such that $ y_1 \in V_2 \cap P$ so that $V_2 \cap P$ is non-empty, $\overline{V_2} \subset V_1$ , but $x_1 \not\in \overline{V_2}$ . If $ y_1  \not= x_2$ ,  then let $$\epsilon_3 \colon= \frac 1 2 \min \left( \epsilon_2 , \vert p - x_2 \vert \right).$$ Then $\epsilon_3 > 0$ .
  Let $$V_3 \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - y_1 \vert < \epsilon_3 \ \right\}.$$ Then $$\overline{V_3} = \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - y_1 \vert \leq  \epsilon_3 \ \right\}.$$ Thus, $y_1 \in V_3 \cap P$ , and so $V_3 \cap P$ is non-empty; moreover, $\overline{V_3} \subset V_2$ and $x_2 \not\in \overline{V_3}$ . On the other hand, if $y_1 = x_2$ , then since $y_1$ is a limit point of set $P$ , and $V_2$ is a neighborhood of $y_1$ , this neighborhood $V_2$ contains a point $y_2$ , say, of $P$ other than the point $y_1 = x_2$ itself. Now as $y_2 \in V_2$ and $V_2$ is an open set in $\mathbb{R}^k$ , so there is some positive real number $\delta_2  > 0$ such that $$N_{\delta_2 } (y_2) \subset V_2.$$ So if we take $$\epsilon_3 \colon= \frac 1 2 \min \left( \delta_2 - \vert y_2 - x_2 \vert , \  \vert y_2 - x_2 \vert \right),$$ then $\epsilon_3 > 0$ . Let $$V_3 \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - y_2 \vert < \epsilon_3 \ \right\}.$$ Then $$\overline{V_3} \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - y_2 \vert \leq  \epsilon_3 \ \right\}.$$ Thus, $y_2 \in V_3 \cap P$ and so $V_3 \cap P$ is non-empty; moreover, $\overline{V_3} \subset V_2$ , and $x_2 \not\in V_3$ . Thus, in either case we have obtained a neighborhood $V_3$ such that $V_3 \cap P$ is non-empty, $\overline{V_3} \subset V_2$ , but $x_2 \not\in V_3$ . The step from $V_2$ to $V_3$ is redundant in the formal  presentation of the proof, but this step perhaps more vividly illustrates how to proceed. Now suppose that a neighborhood $V_n$ ( $n= 3, 4, 5, \ldots$ ) has been constructed such that $x_{n-1} \not\in \overline{V_n}$ , $\overline{V_n} \subset V_{n-1}$ , and $V_n \cap P$ is non-empty.
  Let $$V_n \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - p \vert < \epsilon  \ \right\},$$ where $\epsilon$ is some positive real number and $p$ is some point in $\mathbb{R}^k$ . We now construct $V_{n+1}$ such that $V_{n+1} \cap P$ is non-empty, $\overline{V_{n+1}} \subset V_n$ , and $x_n \not\in \overline{V_{n+1}}$ . Suppose that $q \in V_n \cap P$ . As $q \in V_n$ and $V_n$ is open, there is some positive real number $\delta_n$ such that $$N_{\delta_n} (q) \subset V_n,$$ where $$N_{\delta_n} (q) \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - q \vert < \delta_n \ \right\}.$$ If $q \not= x_n$ , then let's take $$\epsilon_{n+1} \colon= \frac 1 2 \min \left( \delta_n , \vert q - x_n \vert \right).$$ So $\epsilon_{n+1} > 0$ , and let $$V_{n+1} \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - q \vert < \epsilon_{n+1} \ \right\}.$$ Then $$\overline{V_{n+1}} \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - q \vert \leq  \epsilon_{n+1} \ \right\}.$$ Thus, $V_{n+1}$ is a neighborhood such that $q \in V_{n+1} \cap P$ so that $V_{n+1} \cap P$ is non-empty, $\overline{V_{n+1}} \subset V_n$ , and $x_n \not\in \overline{V_{n+1}}$ . On the contrary, if $q = x_n$ , then since $q$ is a limit point of $P$ , the neighborhood $N_{\delta_n} (q)$ contains a point $b$ , say, of $P$ other than the point $q = x_n$ itself. Now if we take $$\epsilon_{n+1} \colon= \frac 1 2 \min \left( \delta_n - \vert b - x_n \vert, \  \vert b - x_n \vert \right),$$ then $\epsilon_{n+1} > 0$ . Let $$V_{n+1} \colon= \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - b \vert < \epsilon_{n+1} \ \right\}.$$ Then $$\overline{V_{n+1}} = \left\{ \ y \in \mathbb{R}^k \ \colon \ \vert y - b \vert = \epsilon_{n+1} \ \right\}.$$ So, $b \in V_{n+1} \cap P$ , which implies that $V_{n+1} \cap P$ is non-empty, $\overline{V_{n+1}} \subset V_n$ , and $x_n \not\in \overline{V_{n+1}}$ . Thus, from $V_n$ , in either case, we have constructed  a neighborhood $V_{n+1}$ such that $V_{n+1} \cap P$ is non-empty, $\overline{V_{n+1}} \subset V_n$ , but $x_n \not\in \overline{V_{n+1}}$ . Thus, we have inductively obtained a sequence $\{V_n\}_{n \in \mathbb{N}}$ of neighborhoods such that, for each $n \in \mathbb{N}$ , the intersection $V_n \cap P$ is non-empty, $\overline{V_{n+1}} \subset V_n$ , and $x_n \not\in \overline{V_{n+1}}$ . Put $K_n \colon= \overline{V_n} \cap P$ for each $n \in \mathbb{N}$ . Let $n \in \mathbb{N}$ be arbitrary. Now $\overline{V_n}$ , being a closed and bounded subset of $\mathbb{R}^k$ , is compact. Moreover, as both $P$ and $\overline{V_n}$ are closed, so is $K_n$ . Thus, $K_n$ , being a closed subset of the compact set $\overline{V_n}$ , is also compact. Since $V_n \cap P$ is non-empty, so $K_n$ is also non-empty. Moreover, as $$\overline{V_{n+1}} \subset V_n \subset \overline{V_n},$$ so we have $K_{n+1} \subset K_n$ . Finally, as $$P = \left\{ \ x_1, x_2, x_3, \ldots \ \right\}$$ and as $x_n \not\in \overline{V_{n+1}}$ , so $x_n \not\in K_{n+1}$ and hence $$x_n \not\in  K_1 \cap K_2 \cap K_3 \cap \ldots,$$ which implies that this intersection is empty. Let $m_1, m_2, \ldots, m_r \in \mathbb{N}$ , and let's take $$m \colon= \max \left( m_1, \ldots, m_r \right).$$ Then $$K_{m_1} \cap \ldots \cap K_{m_r} = K_m,$$ which is non-empty. Thus, $\{K_n\}_{n\in\mathbb{N}}$ is a sequence of non-empty compact sets in the metric space $\mathbb{R}^k$ such that the intersection of any finitely many of these sets is non-empty but the intersection $\cap_{n \in \mathbb{N}} K_n$ is empty. But this cannot hold in any metric space, by Theorem 2.36 in Rudin. So our suppose that $P$ is a non-empty perfect set in $\mathbb{R}^k$ and $P$ is also countable is wrong. Hence Theorem 2.43 in Rudin holds. Is the above proof correct? If so, is the presentation clear enough (or any clearer than Rudin's presentation)? Where does this proof need improvement?","['real-analysis', 'analysis']"
1641424,Factorise Algebraic Expression,"Background: I came across the following problem in class and my teacher was unable to help. The problem was factorise $x^6 - 1$, if you used the difference of 2 squares then used the sum and difference of 2 cubes you came out with the following factorisation; $(x-1)(x+1)(x^2 +x + 1)(x^2 - x + 1)$. However if you used the sum and difference of 2 cubes first you factorised to the following; $(x-1)(x+1)(x^4 + x^2 + 1)$. How would I factorise further from there? Question How do you factorise $x^4 + x^2 + 1$? Thanks","['algebra-precalculus', 'factoring']"
1641433,Number of ways to partition $40$ balls with $4$ colors into $4$ baskets,"Suppose there are $40$ balls with $10$ red, $10$ blue, $10$ green, and $10$ yellow. All balls with the same color are deemed identical. Now all balls are supposed to be put into $4$ identical baskets, such that each basket has $10$ balls. What is the number of ways to partition these balls? I tried this problem, but it seems very complicated to correctly formulate, because the number of a particular color in a basket determines the partition of other baskets. I wonder someone can help figure out a quick and clean way to solve this problem?","['combinatorics', 'integer-partitions', 'balls-in-bins']"
1641443,How the normal bundle of a divisor changes under a (fnite) quotient map,"Let X be smooth and projective, D is an Cartier divisor of X. $\mathcal{N}_{D/X}$ is the normal bundle of D in X.
Let $q: X\longrightarrow Y$  be a finite quotient map of degree d. And q is totally ramified along D, with ramification index r.  $q(D)$ is the image of D. Let $\mathcal{N}_{q(D)/Y}$ be the normal bundle of $q(D)$ in Y. 
Then what is the relation between $\mathcal{N}_{D/X}$ and $\mathcal{N}_{q(D)/Y}$ Dose anyone know how to do this problem or any material related to this problem ?",['algebraic-geometry']
1641553,moving frame with maple,"I have already ask this question on stackoverflow , but since it concerns as mathematics than computer science, I ask it here too. I would like to make a classical computation using maple. I would like define an abstract moving frame (e_1,e_2), then 1) get the dual frame omega_1, omega_2 (always abstract) omega_i(e_j)=delta_i^j 2) define omega_12 such that d omega_1= omega_12 wedge omega_2 3) define Gauss curvature K such that d omega_12=K omega_1\wedge omega_2 4) Finally I would like to get an abstract formula for \overline{K} the curvature of the a new frame (\overline{e}_1,\overline{e}_2)=e^f (e_1,e_2) , where f is a abstract function, with respect to  K and f. I should use the package Differential geometry but even I don't succeed to define the frame. The exmpale in the description of the library is DGsetup([x,y,z,w],M): Example 1.
Define a 3-dimensional subspace of vectors by the span of S and compute a simpler base for this subspace relative to the coordinate basis T for the tangent space of M. S1:=evalDG([D_x−D_y,D_x+D_y,D_x+D_y+D_w]) But S1 is an explicit frame I want to define an abstract one as I can do for functions.
For instance if I want an abstract Liebnitz rule, diff(f(x)*g(x), x); / d      \             / d      \
           |--- f(x)| g(x) + f(x) |--- g(x)|
           \ dx     /             \ dx     / Here I have tryied the following: with(DifferentialGeometry);
  DGsetup([x, y], M);
  S1 := evalDG([e1, e2]);
  M > B1 := DGbasis(S1);
  Error, (in DifferentialGeometry:-DGbasis) expected 1st argument to be a list of biforms, forms, vectors tensors, matrices, vectors. Received [e1, e2] EDIT: Here is what I have start to do with Atlas. As you see, it doesn't use the symmetries of the Lie derivative. And I don't know how to make my 4)","['cartan-geometry', 'maple', 'differential-geometry']"
1641560,Find all $f:\mathbb {R} \rightarrow \mathbb {R}$ where $f(f(x))=f'(x)f(x)+c$,"Recently, while studying calculus, I have come across multiples problems which asked the following: If $f(x)$ is a polynomial, find all $f(x)$ that $f(f(x))=f'(x)f(x)+c$, where $c$ is a constant. This problem can be solved as so: If $deg(f(x))=n$, the upper equation implies that $n^2=2n-1$, or that $n=1$. This implies that $f(x)=ax+b$, and it is just a matter of calculation from here. But how does one find all $f:\mathbb {R} \rightarrow \mathbb {R}$ where $f(f(x))=f'(x)f(x)+c$? I am asking for solutions whe $f(x)$ is not necessarily a polynomial . Because of my above method, I thought that $f'(x)$ would be a constant. However, I was not able to prove this. Differentiating both sides gave me that $(f'(f(x))-f'(x))(f'(x))=f''(x)f(x)$. This proved no help at all. Since I am young, please use methods that are comprehensible to a high-school student. Any help would be appreciated.","['derivatives', 'calculus', 'functional-equations']"
1641570,"How to prove that for all $k\in\mathbb N$, $h(kx)=kh(x)$ and $h(x+y)\le h(x)+h(y)$?","Suppose $X$ is a commutative monoid and $f:X\to\mathbb R\cup\{\infty\}$ a function
and $$g(x)=\inf\left\{\sum_{i=1}^nf(x_i)~\middle\vert~\sum_{i=1}^nx_i=x,n\in\mathbb N\right\}$$
$$h(x)=\inf\left\{\frac{g(mx)}m ~\middle\vert~ m\in\mathbb N\right\}$$
then how to prove that for all $k\in\mathbb N$, $h(kx)=kh(x)$ and $h(x+y)\le h(x)+h(y)$? I proved that $g(x+y)\le g(x)+g(y)$, so I can write
$$h(kx)=\inf\left\{\frac{g(mkx)}m ~\middle\vert~ m\in\mathbb N\right\}=k\inf\left\{\frac{g(mkx)}{mk} ~\middle\vert~ m\in\mathbb N\right\}$$
since $g(x+y)\le g(x)+g(y)$, we have $\frac{g(mkx)}{mk}\le\frac{kg(mx)}{mk}$
So,
$$h(kx)\le k\frac{g(mx)}m$$
therefore
$$h(kx)\le kh(x)$$
on the other hand
$$kh(x)=\inf\left\{\frac{kg(mx)}m ~\middle\vert~ m\in\mathbb N\right\}$$
and since $\frac{kg(mx)}m\le\frac{km}mg(x)$ we have
$$kh(x)\le kg(x)$$ Any hint to continue?","['real-analysis', 'monoid', 'supremum-and-infimum', 'linear-algebra', 'analysis']"
1641602,"Finding $b-a$ for positive integer $a$, $b$ satisfying $\sum_{x=1}^\infty\frac{3x^2+12x+16}{(x(x+1)(x+2)(x+3)( x+4))^3}=\frac1{4(a!)^b}$","$$
\sum_{x = 1}^{\infty}\frac{3x^{2} + 12x + 16}
{\left[\vphantom{A^{A}}x\left(x + 1\right)\left(x + 2\right)
\left(x + 3\right)\left(x + 4\right)\right]^{\, 3}} =
\frac{1}{4\left(a!\right)^{b}}
$$ Compute $b-a$ if $b$ and $a$ are positive integers. I asked my teacher to help me in solving this sum. But, unfortunately, he said I can't. it is a very hard question, So, I hope you can help me in solving this problem.","['combinatorics', 'summation']"
1641612,Is there a way to find expected value of equation?,"If the random variable $X$ is binomially distributed with parameters $n=6$ and $p=0.3$, what is $$E(4+3X^2)$$ I know $E(X) = np = 1.8$. I solved this problem by finding $P(X)$ of all $X$ using $(^6_x)(0.3)^x(0.7)^{6-x}$ and then apply them with $4+3X^2$ to solve for $E(4+3X^2)$. But this takes too long and I think there should be a formula or another way to solve this. Can anyone tell help me out with this? Thank you in advance!","['binomial-distribution', 'probability', 'discrete-mathematics']"
1641621,Difficult Integral $\int_0^{1/\sqrt{2}}\frac{\arcsin({x^2})}{\sqrt{1+x^2}(1+2x^2)}dx=$,"I have a difficult integral to compute.I know the result, but need to know the method of calculation. How prove this result? $$\int_0^{1/\sqrt{2}}\frac{\arcsin({x^2})}{\sqrt{1+x^2}(1+2x^2)}dx=\frac{\pi^2}{144}$$","['integration', 'definite-integrals']"
1641640,Finding $\lim_{x\to -2}{\frac{x+2}{\sqrt{-x-1}-1}}\;$ without L'Hospital,"I have been trying to find 
$$\lim_{x\to -2}{\frac{x+2}{\sqrt{-x-1}-1}}$$
without L'Hospital's Rule, but I am stuck.
I tried Rationalizationg the denominator Factoring out $\,x$ But it did not work. Finally, I used L'Hospital's Theorem and I got the answer $-2$.
Is there any way to evaluate this without this concept?","['limits-without-lhopital', 'calculus', 'limits']"
1641641,Reflection principle for simple random walk,"Let $(X_n)$ be a sequence of independent random variables, such that $P(X_i=1) = P(X_i=-1) = 1/2$. Then, the reflection principle states that for all $a > 0$, $$P(\max_{1\leq k\leq n} S_k \geq a) = P(S_n \geq a) + P(S_n \geq a + 1).$$ I have looked at many places but I have rarely found a full proof for the simple random walk case (I have found lots of document that state it for stochastic process / brownian motion, etc. ). So just to be sure to understand, I wrote the following proof. Is it correct? Proof : We have, for $a \in \mathbb N$, \begin{align*}P\Big(\max_{k\leq n} S_k \geq a\Big) &= \sum_{k=-n}^n P(\max_{k\leq n} S_k \geq a \cap S_n = k) 
\\ &= \sum_{k=-n}^{a - 1}  P(\max_{k\leq n} S_k \geq a \cap S_n = k) + \sum_{k=a}^n P(\max_{1\leq k\leq n} S_k \geq a \cap S_n = k)
\\ &= \sum_{k=-n}^{a - 1}  P(\max_{k\leq n} S_k \geq a \cap S_n = 2 a - k) + \sum_{k=a}^n P(\max_{1\leq k\leq n} S_k \geq a \cap S_n = k)
\\ &= \sum_{k=-n}^{a - 1}  P(S_n = 2 a - k) + \sum_{k=a}^n P(S_n = k)
\\ &= \sum_{j=a+1}^{2 a + n}  P(S_n = j) + \sum_{k=a}^n P(S_n = k) = P(S_n \geq a + 1) + P(S_n \geq a).
\end{align*} When $a$ is not an integer, the same argument works by replacing $a$ by $\lceil a \rceil$, and we can verify that the equality $P(\max_{1\leq k\leq n} S_k \geq a) = P(S_n \geq a) + P(S_n \geq a + 1)$ still holds.","['random-walk', 'probability-theory', 'random-variables']"
1641671,Product of sums into a sum of products,"Any idea on how I can get an expression in the form of sum of products from the following one?:
\begin{equation}
\prod_{i=1}^M \left(\sum_{n=1}^i x_n\right)
\end{equation}","['combinatorics', 'binomial-coefficients']"
1641674,What does third derivative tell about inflection point?,"I was trying to find the nature (maxima, minima, inflection points) of the function $$\frac{x^5}{20}-\frac{x^4}{12}+5=0$$ But I faced a conceptual problem. It is given in the solution to the problem that $f''(0)=0$ and $f'''(0) \neq 0$ so $0$ is not an inflection point. But why should we check the third derivative? Isn't checking first and second derivative sufficient for verifying an inflection point ? 
Why must the higher order odd derivatives be zero for an inflection point?","['derivatives', 'calculus']"
1641689,What is the probability that two random permutations have same order?,"I am interested in the orders of random permutations. Since the law of the log of the order of a permutation converges to a normal law (for instance Erdös-Turan Statistical group theory III), one expects that the probability for two permutations of $S_n$ to have the same order goes to 0 as n goes to infinity. Indeed experimentally this seems to happen with speed $O(1/n^2)$ I know that Wilf proved an asymptotic for a permutation in $S_n$ to be of order $d$ ( https://www.math.upenn.edu/~wilf/website/Asymptotics%20of%20exp%28P%28z%29%29.pdf ) but I don't think it can be used directly. On the other hand it is clear that the probability that two permutations have same order is more than probability that two permutations are conjugate. This is $K/n^2$ according to Flajolet et al. ( http://arxiv.org/abs/math/0606370 ), but here again I failed to generalize the method for the order. [edit] the question has been answered on mathoverflow https://mathoverflow.net/questions/230276","['asymptotics', 'permutations', 'combinatorics', 'symmetric-groups', 'discrete-mathematics']"
1641761,"How to define ""being inside of something"" in the context of topology?","I'm a Psychologist and Neuroscientist with interest in math and I just started reading about Topology. I have to say it's not easy to grasp the concepts without a practical example, so I'm trying to understand topology in a practical (psychologically applicable) way. I was thinking for example about the concept of something being inside of another thing , like someone being inside a house, tea being inside a cup or a smaller circle lying inside a bigger one asf. Humans can identify those things as being the same (belonging to one equivalence class?), i.e. if I ask someone to identify the object inside the other one, every normal functioning person will be able to identify the object inside, no matter how different the properties (color, size, form asf.) of the objects are. So there must be some general properties the brain uses. But how can I define this concept of being inside another thing topologically/mathematically so that it is applicable for a wide range of objects? And what if it gets even more complex. What if a time factor is included like putting something inside another thing . For example putting a key inside a keyhole, putting a steak in the frying pan, putting food into a shopping bag  asf. So here it's about a processes over time which should belong to the same equivalence class. How can this be defined? I hope it became clear what I mean and I'm looking for some inspirational thoughts. Also if anyone can recommend literature with emphasis on practical applications, I'd be thankful :).","['general-topology', 'soft-question']"
1641766,Why is this system reversible? What does this mean?,"Consider the system
$$
\dot{x}=y,\qquad\dot{y}=-x+y^2.
$$
Then, it is said that the system is reversible $(t\to -t, y\to -y)$. What does this mean? If I put this into the equations, I get
$$
\dot{x}(-t)=y(-t),\qquad \dot{y}(-t)=-x(-t)+y(-t)^2.
$$ So does reversible mean here that when replacing $t$ by $-t$ and $y$ by $-y$, the differential equations still hold?",['ordinary-differential-equations']
1641798,Sequence bounded away from $0$ and $2$,"Suppose I have a sequence of real numbers $\{a_n\}_n$ and I'm told that $\{a_n\}_n$ is bounded away from $0$ and $2$. (1) What does it mean exactly? My thinking is that it means $a_n\neq 0$ and $a_n \neq 2$ $\forall n$. (2) Does it imply that $\lim_{n\rightarrow \infty}a_n \neq 0$ and $\lim_{n\rightarrow \infty}a_n \neq 2$ (assuming that the limit exists)? Question (2) is related to the discussion on rescaling rates at p.211 of van der Vaart ""Asymptotic Statistics"" point (iii) here where it seems that the answer to (2) is ""Yes""","['asymptotics', 'sequences-and-series', 'limits']"
1641823,Median of Medians,"Given a set A with median A m = 10 and set B with median B m = 20 is it true that the median of the combined set C is $10 \le$ C m $\le 20$ ? My first thought was that this wasn't true so I tried to find a counter example but I wasnt able to so I am assuming that it likely is true but I havent been able to find any theorem or other proof for this. Ideally I would like to know if this is true for the general case not just 10,20 I just chose these numbers while trying to find a counter example. Any help would be greatly appreciated.","['statistics', 'data-analysis', 'median']"
1641851,Proving that the exponential inequality $e^x \ge x^e$ holds for all $x \ge 0$ [duplicate],"This question already has answers here : Why $e^x$ is always greater than $x^e$? (8 answers) Closed 8 years ago . How does one prove that $$e^x \ge x^e$$ for all $x \ge 0$? I tried to do this by setting $f(x)=e^x-x^e$ Plotting this function shows this easily, as seen here . However, when I tried to prove this, it proved quite difficult. It seems to be increasing for $0 \le x \le e$, and seems to be increasing for all $x \ge e$. I tried to use that $f'(x)=e^x-ex^{e-1}$ but was not able to. Any help would be appreciated.","['derivatives', 'inequality', 'exponential-function', 'calculus']"
1641867,"Show $ (\int_{-\infty}^\infty \sqrt{p}\sqrt{q}d\mu)^2\leq 2 \int_{-\infty}^\infty \min\{p,q\}d\mu $","Consider a random variable $X$ in $(\Omega, \mathcal{F}, \mathbb{P})$. Let $p,q$ be two densities with respect to a measure $\mu$ in $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ where $\mathcal{B}(\mathbb{R})$ is the Borel $\sigma$-algebra in $\mathbb{R}$. Could you help me to show that
$$
\left(\int_{-\infty}^\infty \sqrt{p}\sqrt{q}d\mu\right)^2\le 2 \int_{-\infty}^\infty\min\{p,q\}d\mu
$$
from van der Vaart ""Asymptotic Statistics"" proof of Lemma 14.31. My attempt : \begin{align}\left(\int_{-\infty}^\infty \sqrt{p}\sqrt{q}d\mu\right)^2&\le  \left(\int_{-\infty}^\infty \min\{\sqrt{p},\sqrt{q}\}\left(\sqrt{p}+\sqrt{q}\right)d\mu\right)^2\\[0.2cm]&
\le \int_{-\infty}^{\infty}\left(\sqrt{p}+\sqrt{q}\right)^2d\mu \int_{-\infty}^{\infty}\min\left\{\sqrt{p},\sqrt{q}\right\}^2d\mu\\[0.2cm]&=\left(2+2\int_{-\infty}^{\infty}\sqrt{p}\sqrt{q}d\mu\right)\int_{-\infty}^{\infty}\min\{p,q\}d\mu=\dots?\end{align}","['integration', 'probability', 'measure-theory', 'proof-verification']"
1641953,Russell's paradox question,"Tao's analysis book uses following example for Russell's paradox:
$$P(x) \Longrightarrow `` x\text{ is a set, and }x \notin  x""\\
\Omega := \{x : P(x)\text{ is true} \} = \{x : x\text{ is a set and }x \notin x\}$$
then conclude that $­\Omega \in \Omega$ and $­\Omega \notin \Omega$ happened same time. so it is a paradox. 
My question is if $x$ is a set, you can't write $x \notin  x$ right? only element belong to a set, isn't the statement wrong at the first place? or this could not be called as a statement.","['paradoxes', 'real-analysis', 'elementary-set-theory']"
1641960,Proving that a function grows faster than another,"I'm told to prove or disprove that $4^{\sqrt{n}}$ grows faster than $\sqrt{4^n}$
As n tends to infinity. From my Previous years Calculus I know that if I take the derivative of two functions, and one is bigger, than it must grow faster. $f(n) = 4^{\sqrt{n}}$ $g(n) = \sqrt{4^n}$ if
$f'(n)$ is > $g'(n)$ Then $f(n)$ grows faster than $g(n)$, as $n\to\infty$ My Attempt: $f'(n) = (\ln(4)\times 4^{\sqrt n)})
 /2^{\sqrt n}$ $g'(n) = (\ln(4)\times 4^{n/2})
             /2$ But Now I'm not sure if f(n) does grow faster, how would I know that it's first derivative is bigger here, just by plugging in numbers?","['functional-analysis', 'discrete-mathematics', 'calculus', 'limits']"
