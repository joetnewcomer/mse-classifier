question_id,title,body,tags
1860629,measure preserving map does not increase distance,"I read a sentence saying ""any measurable subset of $\mathbb{R}$ can be mapped to an interval by a measure-preserving transformation which does not increase distances"" Here the measure is Lebesgue measure and the distance is the standard distance. Is there any reference for this? Thanks!","['reference-request', 'measure-theory']"
1860649,Growth of $\pi(2x) - 2\pi(x)$,"In Hardy & Wright's Theory of Numbers (p. 494 f in 6 th ed.) there's a little discussion following the proof of the prime number theorem. We have 
  $$ \pi(2x) - \pi(x) = \frac{x}{\log x} + o\left(\frac{x}{\log x}\right) \sim \pi(x). \tag{1} $$
  Thus, to a first approximation, the number of primes between $x$ and $2x$ is the same as the number less than $x$. At first sight this is surprising, since we know that primes near $x$ 'thin out' (in some vague sense) as $x$ increases. In fact, $\pi(2x) - 2\pi(x) \to \infty$ as $x \to \infty$ (though we cannot prove this here), but this is not inconsistent with (1), 
  which is equivalent to $$ \pi(2x) - 2\pi(x) = O(\pi(x)). \tag{2} $$ Isn't this just plain wrong? First of all, (1) is not equivalent to (2) but rather to $$ \pi(2x) - 2\pi(x) = o(\pi(x)). \tag{2'}$$
More importantly, how can $\pi(2x) - 2\pi(x)$ go to infinity if $\pi(2x) < 2\pi(x)$ for $x \ge 11$ ? Thus the question is, as $x \to \infty$, what is $\pi(2x) - 2\pi(x)$ actually doing?","['number-theory', 'asymptotics', 'prime-numbers']"
1860675,Problem calculating the sine of a matrix,"Given the matrix $A=\begin{pmatrix}-\frac{3\pi}{4} & \frac{\pi}{2}\\\frac{\pi}{2}&0\end{pmatrix}$, I want to calculate the sine $\sin(A)$. I do so by diagonalizing A and plugging it in the power series of the sine: \begin{align}
\sin (A) = \sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)!} A^{2k+1}.
\end{align} The diagonalization leads to: \begin{align}
A = \frac{1}{5}
\begin{pmatrix}-2 & 1\\1&2\end{pmatrix}
\begin{pmatrix}-\pi & 0\\0&\frac{\pi}{4}\end{pmatrix}
\begin{pmatrix}-2 & 1\\1&2\end{pmatrix}
\end{align}
and thus:
\begin{align}
A^n = \frac{1}{5}
\begin{pmatrix}-2 & 1\\1&2\end{pmatrix}
\begin{pmatrix}-\pi & 0\\0&\frac{\pi}{4}\end{pmatrix}^n
\begin{pmatrix}-2 & 1\\1&2\end{pmatrix}.
\end{align}
Hence:
\begin{align}
\sin (A) &= \begin{pmatrix}-2 & 1\\1&2\end{pmatrix}
\begin{pmatrix}\sin(-\pi) & 0\\0&\sin(\frac{\pi}{4})\end{pmatrix}
\begin{pmatrix}-2 & 1\\1&2\end{pmatrix}\\
&= \begin{pmatrix}-2 & 1\\1&2\end{pmatrix}
\begin{pmatrix}0 & 0\\0&\frac{1}{\sqrt{2}})\end{pmatrix}
\begin{pmatrix}-2 & 1\\1&2\end{pmatrix}\\
&= \frac{1}{5}\begin{pmatrix}\frac{1}{\sqrt{2}} & \sqrt{2}\\\sqrt{2}&2\sqrt{2}\end{pmatrix},
\end{align}
which differs from ""Wolfram Alpha's result"" \begin{align}
\sin(A) &= \begin{pmatrix}-\frac{1}{\sqrt{2}} & 1\\ 1 & 0 \end{pmatrix} .
\end{align} How can this happen?","['matrices', 'power-series', 'functions']"
1860691,Bound for sum of normal distributions,"I have encountered an exercise that was quite puzzling for me. Maybe someone can help me out here?
So let $(X_n)_n $ be $N(-a,1)$ distributed, independent random variables where $a>0$. I need to prove $$P(\sup_{n \in \mathbb N} S_n > x)\leq e^{-2ax}$$
where $S_n= \sum_{k=1}^n X_k$. I am tempted to use Markovs inequality but the supremum kind of irritates me.
Can I somehow use that $e^{h S_n}$ is a Martingale if $h=2a$ which I proved in the first part of the exercise?","['probability-theory', 'probability']"
1860700,$x\in \bar{A}$ iff every neighbourhood of $x$ intersects $A$.,"I read the proof of this theorem from Munkres, however I don't really understand intuitively why this is true. If someone could provide me of intuition of this theorem that would be nice. $\bar{A}$ is defined as the intersection of all closed sets that contain A. Proof. $\ \ $ Consider the statement in $\rm(a)$. It is a statement of the form $P\Leftrightarrow Q$. Let us transform each implication to its contrapositive, thereby obtaining the logically equivalent statement $({\rm not}\, P)\Leftrightarrow({\rm not}\, Q)$. Written out, it is the following. $$x\notin \bar A\iff\text{there exists an open set $U$ containing $x$ that does not intersect $A$.}$$ $\quad$ In this form, our theorem is easy to prove. If $x$ is not in $\bar A$, the set $U=X-\bar A$ is an open set containing $x$ that does not intersect $A$, as desired. Conversely, if there exists an open set $U$ containing $x$ which does not intersect $A$, then $X-U$ is a closed set containing $A$. By definition of the closure $\bar A$, the set $X-U$ must contain $\bar A$, therefore, $x$ cannot be in $\bar A$.",['general-topology']
1860703,Quick question: Extension of vector bundles on a compact Riemann surface,"Given the following short exact sequence of holomorphic vector bundles on a compact Riemann surface: $0\rightarrow M\rightarrow E \rightarrow N\rightarrow 0$ Fix a hermitian metric on $E$ and $n=rank(E)$. Let $\nabla$ be the corresponding unitary connection on the $U(n)-$bundle underlying $E$. Then it splits as $\nabla=\begin{pmatrix}\nabla_M & C \\ B & \nabla_N\end{pmatrix}$ where $\nabla_M=pr_M\nabla$ where $pr_M$ denotes the orthogonal projection with respect to our Hermitian metric. Since $M$ is a holomorphic subbundle of $E$ and $\nabla$ is compatible with $E$ (i.e. $\nabla^{0,1}=\overline{\partial}_E$), $\nabla_M$ is compatible with $M$. Hence $B$ is a ($1,0$)-form. Why must we have $C=-B^\dagger$ (maybe with respect to some orthonormal basis)? Is $\nabla$ being unitary equivalent to the matrix of $\nabla$ above being Hermitian with respect to an orthonormal basis? If this is true, maybe the explanation of $C=-B^\dagger$ has to do with it? Thank you.","['moduli-space', 'algebraic-geometry', 'gauge-theory', 'differential-geometry', 'connections']"
1860733,Are martingales progressively measurable? (Application to square integrable martingales),"This is an incredibly dumb question, but I'm not sure if I know the correct answer, and it doesn't seem to be stated anywhere on the internet, so here goes: Are martingales progressively measurable? (At least up to a modification?) The answer should be yes if it is true, as I have read (for example here ), that every measurable and adapted process has a progressively measurable modification, since obviously martingales are measurable and adapted. I ask because I want to deduce whether or not the space of locally $L^2-$ bounded martingales is closed under integration with respect to Brownian motion. This seems to follow from Definition 3.1.4 p. 25, and Corollary 3.2.6 on p. 33 of Oksendal's Stochastic Differential Equations . EDIT: The answer is almost certainly yes, since Definition 3.14 in Oksendal essentially states that: $f \in \mathcal{V}(S,T)$ if and only if: (1) $f$ is a measurable process, (2) $f$ is an adapted process, and (3) $f$ is bounded in $L^2$ on $[S,T]$ . From (1) and (2) it should follow that $f$ has a progressively measurable version. Then from corollary 3.17 (Ito's Isometry) and condition (3) of Definition 3.14, it follows that the Ito integral with respect to Brownian motion over a finite interval $[S,T]$ is bounded in $L^2$ , and then Corollary 3.2.6 gives us that it is a martingale, hence an $L^2$ -bounded martingale. Does this mean that if we restrict the class of integrands from ""locally bounded progressively measurable processes"" to ""locally bounded and locally $L^2$ bounded progressively measurable processes"" that the Ito integral with respect to Brownian motion is always a (locally) $L^2$ -bounded martingale? Namely we get from the second result that any integral of a locally $L^2-$ bounded progressively measurable process is a martingale. Also Ito's isometry has something to do with $L^2-$ bounded martingales. But anyway the space wouldn't be closed under integration w.r.t. Brownian motion if the resulting martingale wasn't itself integrable w.r.t. Brownian motion. In what follows, we assume the existence of an underlying filtration $(\mathcal{F}_t)_{t\ge 0}$ on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ . adapted process - a process $(X_t)_{t \ge 0}$ such that $X_t : \Omega \to \mathbb{R}$ is measurable with respect to $\mathcal{F}_t$ for all $t \in [0,\infty)$ . measurable process - a process $(X_t)_{t \ge 0}$ such that the induced mapping $$X: \Omega \times [0, \infty) \to \mathbb{R}, \quad (\omega,t) \mapsto X_t(\omega)$$ is measurable (= jointly measurable in $\Omega \times [0, \infty)$ ????) . progressively measurable process - a process $(X_t)_{t \ge 0}$ such that, for every $t \in [0, \infty)$ , the map $$[0,t] \times \Omega \to \mathbb{R}, \quad (s, \omega) \mapsto X_s(\omega)$$ is $\mathcal{B}([0,t])\times \mathcal{F}_t$ measurable.","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'stochastic-analysis', 'stochastic-calculus']"
1860746,Amazing isomorphisms [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question Just as a recreational topic, what group/ring/other algebraic structure isomorphisms you know that seem unusual, or downright unintuitive? Are there such structures which we don't yet know whether they are isomorphic or not?","['abstract-algebra', 'group-isomorphism', 'exceptional-isomorphisms', 'soft-question', 'group-theory']"
1860787,Finding $\int \frac{\mathrm{d}x}{1 + \frac{2}{x} - x}$,"I want to solve: $$\int\frac{1}{1+\frac{2}{x}-x} \mathrm{d}x $$ I don't know how to start, maybe I should use partial fraction?","['indefinite-integrals', 'integration', 'calculus']"
1860796,The size of sets of positive integers not having distinct subsets with equal size and sum,"Let us call a set $S$ of positive integers ""good"" if there does not exist a pair of distinct subsets $A,B\subseteq S$ who have equal size and an equal sum. Equivalently, a set $S$ is good if the function $f:P(S)\rightarrow \mathbb N^2$ defined as
$$f(A)=\left(|A|,\sum_{a\in A}a\right)$$
is injective. Given any $d$, what is the smallest $n$ such that there exists a subset $S$ of $\{1,\ldots,n\}$ which is good and has $d$ elements? I thought of this problem as a variation on a related one where we drop the requirement that $A$ and $B$ have the same size (i.e. ask that $g(A)=\sum_{a\in A}a$ be injective on the power set of $S$). (This post previously claimed this variant was easy; it has been pointed out in the comments by @Shagnik that it is open ). A potentially useful reformulation of the new problem is that one may also define this as looking for subsets of $\{(1,1),(1,2),(1,3),\ldots,(1,n)\}$ such that no two subsets have equal sum. I can get lower bounds on $n$. In particular, note that a $k$ element subset of $\{1,\ldots,n\}$ must have its sum lie between $1+2+\ldots+k$ and $(n-k+1)+\ldots+n$. In particular, it can take on only $k(n-k)+1$ possible sums. However, there are ${d \choose k}$ subsets of $S$ needing distinct sums. Thus, we get the bound:
$${d\choose k}\leq k(n-k)+1.$$
which must hold for all $0\leq k \leq d$. If one sets $k=d/2$ and works through using Stirling's approximation, dropping some lower order terms that crop up, one gets that $n$ should be at least asymptotic to $\frac{2\sqrt{2}\cdot 2^d}{\sqrt{\pi}\cdot d^{3/2}}$. That is, the ratio of $n$ to that expression tends to at least $1$ as $d$ goes to $\infty$. For upper bounds, we can obviously bound that $n\leq 2^{d-1}$ since $\{1,2,\ldots,2^{d-1}\}$ is a good set. However, this still leaves a sizeable gap between upper and lower bounds. I do not know whether it is optimal, but a greedy algorithm where we define a sequence $a_n$ by setting $$a_n=\min\{x:\{a_1,a_2,\ldots,a_{n-1},x\}\text{ is good}\}$$
yields a sequence starting as $1,\,2,\,3,\,5,\,8,\,14,\,25,\,45,\,85,\,162,\,310,\,595,\,1165,\,2285,\,4485,\,8808$. I suspect this is a difficult problem to answer in full, but I would be interested in any refinements of either upper or lower bounds or any literature discussing the problem.","['additive-combinatorics', 'combinatorics', 'sequences-and-series']"
1860803,"Real Analysis, Problem 3.2.14 The Radon Nikodym Theorem","Problem 3.3.14 - If $\nu$ is an arbitrary signed measure and $\mu$ is a $\sigma$ -finite measure on $(X,M)$ such that $\nu\ll \mu$ , there exists an extended $\mu$ -integrable function $f:X\rightarrow [-\infty,\infty]$ such that $d\nu = fd\mu$ . Hints: a.) It suffices to assume that $\mu$ is finite and $\nu$ is positive. b.) With these assumptions, there exists an $E\in M$ that is $\sigma$ -finite for $\nu$ such that $\mu(E)\geq \mu(F)$ for all sets $F$ that are $\sigma$ -finite for $\nu$ . c.) The Radon-Nikodym theorem applies on $E$ . If $F\cap E = \emptyset$ , then either $\nu(F) = \mu(F) = 0$ or $\mu(F) > 0$ and $|\nu(F)| = \infty$ . Attempted proof - Consider $\mu(E)$ where $E$ is a $\sigma$ -finite set for $\nu$ . Since we have that $\mu$ is finite then clearly $\mu(E)$ must be bounded which implies it has a supremum. We will define the supremum as $$L = \sup\{F: F \ \text{is} \  \sigma-\text{finite for} \ \nu\}$$ Now lets take a sequence $\{E_n\}_{1}^{\infty}$ that are $\sigma$ -finite with respect to $\nu$ and $\mu(E_n)\rightarrow L$ as $n\rightarrow \infty$ . Now let $$E = \bigcup_{1}^{\infty}E_n$$ then $\mu(E) \leq L$ since it is taken to be a countable union of $\sigma$ -finite sets. On the other hand, $\mu(E)\geq \mu(E_n)$ for all $n$ and since $\mu(E_n)\rightarrow L$ then $\mu(E) = L$ . Now since $\mu(E) = L$ then clearly by definition of $L$ we have that $\mu(E) > \mu(F)$ for all sets $F$ that are $\sigma$ -finite for $\nu$ . Now we apply the Radon-Nikodym theorem: so, suppose that $F\cap E = \emptyset$ well since $\nu\ll\mu$ then by definition $\nu(F) = \mu(F) = 0$ . If $\mu(F) > 0$ then for sake of contradiction suppose $|\nu(F)|\neq \infty$ . Then since $\mu$ is finite $\mu(F\cup E) > \mu(E)$ then this implies that $E\cup F$ is not $\sigma$ -finite since a $\sigma$ -finite set with a union of a finite set is $\sigma$ -finite. Therefore $|\nu(F)| = \infty$ . Thus I believe we can refer to Radon-Nikidym theorem to conclude that there exists an extended $\mu$ -integrable function $f:X\rightarrow [-\infty,\infty]$ such that $d\nu = fd\mu$ . I am not sure if this is completely correct, any suggestions is greatly appreciated.","['real-analysis', 'measure-theory', 'proof-verification']"
1860812,Proving $\frac{1}{\cos^2\frac{\pi}{7}}+ \frac {1}{\cos^2\frac {2\pi}{7}}+\frac {1}{\cos^2\frac {3\pi}{7}} = 24$,"Someone gave me the following problem, and using a calculator I managed to find the answer to be $24$ . Calculate $$\frac {1}{\cos^2\frac{\pi}{7}}+ \frac{1}{\cos^2\frac{2\pi}{7}}+\frac {1}{\cos^2\frac{3\pi}{7}}\,.$$ The only question left is, Why? I've tried using Euler's Identity, using a heptagon with Law of Cosine w/ Ptolemy's, etc. but the fact that the cosine values are all squared and in the denominator keeps getting me stuck. If $\zeta=e^{\frac{2\pi i}{7}}$ , then the required expression is $$4\left(\frac{\zeta^2}{(\zeta+1)^2}+\frac{\zeta^4}{(\zeta^2+1)^2}+\frac{\zeta^6}{(\zeta^3+1)^2}\right).$$ How do we simplify this result further?","['polynomials', 'complex-numbers', 'trigonometry', 'roots-of-unity', 'geometry']"
1860814,Differentiate and simplify. $m(x) = \frac{x}{\sqrt{4x-3}}$,"My work so far is: \begin{align}
m'(x) &= \frac{(1)(\sqrt{4x-3})-(x)(1/2)(4x-3)^{-1/2}(4)}{(\sqrt{4x-3})^2} \\
&= \frac{\sqrt{4x-3} - 2x(4x-3)^{1/2}}{4x-3}
\end{align}
and now I'm stuck on how to simplify further","['derivatives', 'calculus']"
1860827,Radius and Interval of Convergence for $\sum_{n=1}^{\infty}\frac{5^n}{n^2}x^n$,"$$\sum_{n=1}^\infty \frac{5^n}{n^2}x^n$$ After doing the ratio test I end up with: $$5|x| < 1$$ I'm confused, though, as to what is considered my interval of convergence and what is my radius.  I recognize that $1$ is my limit, so does this mean my radius of convergence is $\frac{1}{5}$ and my interval of convergence is: $$\left(-\frac{1}{5},\frac{1}{5}\right)$$","['real-analysis', 'sequences-and-series', 'limits']"
1860874,"Why is $\{\{1\}\}$ not equal to $\{1,\{1\}\}$?","Determine whether each of these pairs of sets are equal$$A = \{\{1\}\} \qquad \qquad B = \{1, \{1\}\}$$ I believe $A$ is equal to $B$ because all elements in $A$ are in $B$, but the answer says that it's not.","['elementary-set-theory', 'discrete-mathematics']"
1860883,Broken line is NOT diffeomorphic to the real line,"This is from Bredon's Topology and Geometry , page 71. This comes right after the very definition of differentiable manifold, so I think no use of tangent space or 'differential' is permitted. (Bredon gives two defenitions, one the usual chart and atlas definition, the other using the functional structure. He then explains that the two are equivalent.) Let $X$ be the graph of the real valued function $\theta(x) = |x|$ of a real variable $x$. Define a functional structure on $X$ by taking $f \in F(U) \iff f$ is the restriction to $U$ of a $C^\infty$ function on some open set $V$ in the plane with $U = V \cap X$. Show that $X$ with this structure is not diffeomorphic to the real line with usual $C^\infty$ structure. I thinks that if there were any diffeomorphism, something bad happens at $(0,0)$, but I just can't figure out... Please enlighten me.","['algebraic-topology', 'differential-geometry', 'differential-topology']"
1860899,"Have I found all the numbers less than 50,000 with exactly 11 divisors?","The math problem I am trying to solve is to find all positive integers that meet these two conditions: have exactly 11 divisors are less than 50,000 My starting point is a number with exactly 11 divisors is of the form: $c_1p_1 * c_2p_2 * c_3p_3 * ... * c_{11}p_{11}$ where:  $c_i$ is an integer and $p_i$ is prime and noting that 1 can be a divisor but can only be included once in the list of divisors. Therefore the smallest such number is: $1*2^{10} = 1024$ The next such number would be: $2^{11} = 2048$ So far $c_i$ has been 1, but I will now start letting some of them be 2 until I reach the upper bound of 50,000. This gives me: $2^{12}$, $2^{13}$, $2^{14}$ and $2^{15}$ (as $2^{16} > 50,000)$ I feel like I'm onto a useful pattern. So I will start using 3s as well (again until I reach the upper bound): $3*2^{10}$, $3^2*2^9$, $3^3*2^8$, $3^4*2^7$, $3^5*2^6$, $3^6*2^5$, $3^7*2^4$ Now 4s: $4*2^{10}$, $4^2*2^9$, $4^3*2^8$, $4^4*2^7$ Then 5s: $5*2^{10}$, $5^2*2^9$, $5^3*2^8$ Then 6s: $6*2^{10}$, $6^2*2^9$ Then 7s: $7*2^{10}$, $7^2*2^9$ Then 8s: $8*2^{10}$, $8^2*2^9$ Then 9s: $9*2^{10}$, $9^2*2^9$ Then 10s: $10*2^{10}$ I've now reached the point where there's only one number in the sub-sequence. Therefore, I also have: $11*2^{10}, 12*2^{10}, 13*2^{10}, ..., 48*2^{10}$ I now feel I've exhausted my algorithm. However I'm not sure if my answer is correct and complete. So, have I enumerated all such numbers? Or have I missed some or doubled-up?","['combinatorics', 'factoring', 'divisor-counting-function', 'elementary-number-theory']"
1860910,Difficult Functions Evaluation Problem,"I have a question about finding the value of a certain function that I cannot wrap my head around. The question is:  Given a function $f(x)$ satisfying $$f(x) + 2f\left(\frac{1}{1-x}\right) = x,$$ Then find $f(2).$ So far, I have tried plugging 2 into the original equation to yield $f(2) + 2f(-1) = 2.$ Next, I plugged $\displaystyle \frac{1}{2}$ into the original equation to yield $\displaystyle f\left(\frac{1}{2}\right) + 2f(2) = \frac{1}{2}$. However, I do not know how to solve this system of equations for $f(2).$ Please let me know of any hints you may have. Many thanks.",['functions']
1860929,Find the limit of a definite integral,"A definite integral is defined as
$$I(v,\theta)=\int_0^{\pi} e^{v[\cos(\theta-\phi)-1]}\sqrt{\dfrac{v \sin\phi}{\sin\theta}}d\phi$$ My question is how to show that 
$$\lim_{v\to \infty} I(v, \theta)=\sqrt{2\pi}$$
for any given $\theta \in (0, \pi)$. My understanding is like this. Since $v$ goes to infinity, the main contribution of the integral comes from those $\phi$ values which are close to $\theta$ (because of the exponential term). I tried the Taylor expansion of $\phi$ around $\theta$, for example,
\begin{align*}
 \cos (\theta -\phi) &\approx 1-\dfrac{(\theta-\phi)^2}{2!} + \dfrac{(\theta-\phi)^4}{4!} + \cdots \\
\sin \phi & \approx \sin \theta + \cos\theta(\phi-\theta) - \dfrac{\sin \theta}{2}(\phi-\theta)^2 + \cdots
\end{align*}
but still can't go far. I don't know if I am on the right track. Please help.","['taylor-expansion', 'definite-integrals', 'limits']"
1860938,Definition of Ordinals in Set Theory in Layman Terms,"I've taken a huge interest in the mathematical concept of infinity and often been contemplating the same over years. But the fundamental concept of set theory ordinals continues to evade my understanding. The questions below comprise (more or less) the gaps in my comprehension of the mathematical infinite: Ordinal numbers in general (1st, 2nd, 3rd, 4th...) are entirely different from ordinal numbers in set theory, correct? I understand that set theory ordinals are basically sets that contain a least element by definition. But, is it necessary for the elements of an ordinal to be strictly in order? For example, must the ordinal 4 be represented as { ∅, {∅}, {∅,{∅}}, {∅, {∅}, {∅,{∅}}}.... } and not as { {∅,{∅}}, ∅, {∅}, {∅, {∅}, {∅,{∅}}}.... } ? The cardinality of ω is א‎0 (please correct me if I'm wrong), but where exactly is the position of ω along the number line. Is it א‎0th position (so to speak)? I apologize for the naivety of the questions above (honestly, I really don't find a layman explanation of ordinals anywhere on the web. I saw a very good YouTube video though). The objective is to understand the core concept of set theory ordinals (well enough to be able to explain the same to a layman) rather than memorizing formal, mathematical definitions with little to no true comprehension of the same. Thanks in advance!","['elementary-set-theory', 'ordinals']"
1860956,What is the derivative of $x^{x^{x^{x^{.^{.^{.}}}}}}$ [duplicate],"This question already has answers here : derivative of x^x^x... to infinity? (2 answers) Closed 7 years ago . Here is my attempt: Substituting y for infinite x powers: $$x^{x^{x^{x^{.^{.^{.}}}}}}=y → x^y=y $$ Giving:
$$x=y^{\frac{1}{y}}$$ Take natural logs & differentiate with respect to $y$:
$$ln(x)=ln(y^\frac{1}{y}) → ln(x)=\frac{1}{y}ln(y^\frac{1}{y})$$
$$\frac{1}{x}\frac{dx}{dy}=-\frac{1}{y^2}ln(y)+\frac{1}{y^2}$$
$$\frac{dx}{dy}=x\left(\frac{1-ln(y)}{y^2}\right)$$ Sub. in $y^{\frac{1}{y}}$ for $x$:
$$\frac{dx}{dy}=y^{\frac{1}{y}}\left(\frac{1-ln(y)}{y^2}\right)$$
$$\frac{dx}{dy}=y^{\frac{1}{y}-2}\left(1-ln(y)\right)$$ Inverse $\frac{dx}{dy}$ to get $\frac{dy}{dx}$:
$$\frac{dy}{dx}=\left[y^{\frac{1}{y}-2}\left(1-ln(y)\right)\right]^{-1}$$
Therefore: 
$$\frac{dy}{dx}=\frac{y^{2-\frac{1}{y}}}{1-ln(y)}$$ Have I made a mistake anywhere?
Have I made a false assumption? Please kindly provide some guidance, thanks.","['derivatives', 'implicit-differentiation', 'infinity', 'calculus']"
1860963,"If $f,g:X \to Y$ are measurable, is the set on which $f=g$ measurable? What $Y$ does this hold for?","If $f,g:(X,\Sigma_X) \to (Y,\Sigma_Y)$ are measurable, when can we conclude that $\{x \in X: f(x)=g(x)\} \in \Sigma_X$ is a measurable subset of $X$? This is a standard theorem when $Y=\mathbb{R}$ or more generally when $Y$ is a standard measure space (isomorphic to $(F, \mathcal{B}(F))$ for some Borel $F \subseteq \mathbb{R}$). Does this fact hold when $Y$ is any measure space? If no, what is needed to conclude this set is measurable?",['measure-theory']
1860978,Counting: how many ways of climbing a stair?,"You are climbing a staircase. At each step, you can either make $1$ step climb, or make $2$ steps climb. Say a staircase of height of $3$ . You can climb in $3$ ways $(1-1-1,\ 1-2,\ 2-1)$ . Say a staircase of height of $4$ , You can climb in $5$ ways. Given a staircase of height of $n$ , can you figure out how many ways you can climb? Attempt: This is actually a programming problem, I have already written the C++ code in recursion, but I just don't know how to verify my program using mathematical skills. I feel this is not a complicate math problem, but yet I couldn't solve it. So I am asking for your help.","['permutations', 'combinatorics']"
1861007,"Proof validation: complete set, change of variable","Let $\phi(x) \in \mathcal{C}^1([0,1])$ be a real valued function such that:
$$\begin{cases}
\phi'(x) > 0 & \forall x \in [0,1] \\
\phi(0) = 0 \\
\phi(1) = 1.
\end{cases}$$
I'm asked to prove that the set
$$\left\lbrace{f_n(x) \equiv \sin(n\pi\phi(x)}\right\rbrace_1^{\infty}$$
is complete in $L^2([0,1])$. Here is my proof. For the sake of conciseness I'll omit some calculations, stating only their final results. My doubt concerns the legitimacy of the change of variable I perform. Can you tell me if it is right to proceed this way? Also, if there are other mistakes, please point them out. Let $f$ be a function in $L^2([0,1])$ such that 
  $$ 0 = \left\langle f_n, f \right\rangle_{L^2([0,1])} = \int_0^1 \sin(n\pi\phi(x)) f(x) \,dx \quad \forall n \geq 1.$$
  Now, if the change of variable defined by $z(x) = \pi \phi(x)$ (which is possible for the properties of $\phi$) is performed, the former equality becomes:
  $$ 0 = \int_0^\pi \sin(nz) f(x(z)) \dfrac{dx}{dz} \,dz \quad \forall n \geq 1$$
  and, since (from the hypotheses on $f$ and $\phi$) it can be proven that $f(x(z)) \dfrac{dx}{dz} \in L^2([0,\pi]),$ from the completeness of the set ${\left\lbrace{\sin(nz)}\right\rbrace}_1^\infty$ in $L^2([0,\pi])$ and from the hypothesis on $\phi'$ we have:
  $$f(x(z)) \dfrac{dx}{dz} = 0 \quad \Rightarrow \quad f(z) = 0 \ \text{ a. e. } \; \forall z \in [0, \pi] \qquad \Rightarrow \quad f(x) = 0 \ \text{ a.e. } \; \forall x \in [0, 1]$$
  which means that the set ${\left\lbrace{\sin(n\pi\phi(x)}\right\rbrace}_1^\infty$ is complete in $L^2([0,1])$.","['functional-analysis', 'complete-spaces', 'proof-verification']"
1861010,Why am I under-counting when calculating the probability of a full house?,"I was trying to answer this question. Find the probability of getting a full house from a $52$ card deck. That is, find the probability of picking a pair of cards with the same rank (face value), and a triple with equal rank (different from the rank of the pair of course). My idea was this: Take one rank. The number of ways you can get a pair from a rank is $C(4, 2)$. Take another rank. The number of ways you can get a triple from that rank is $C(4, 3)$. Therefore, the number of ways you can get a full house from just $2$ ranks is $C(4, 2) \cdot C(4, 3)$. But there are $13$ different ranks, and the number of ways you can select $2$ ranks out of $13$ is $C(13, 2)$. For each of these pairs of ranks, you can have $C(4, 2) \cdot C(4, 3)$ full houses. Therefore the number of possible full houses is $C(4, 2) \cdot C(4, 3) \cdot C(13, 2)$, and the probability of selecting a full house is $\dfrac {C(4, 2) \cdot C(4, 3) \cdot C(13, 2)}{C(52, 5)} \approx 0.000720288$ However, this is way lower than the actual answer of $.00144$. Where did I go wrong here?","['combinatorics', 'probability', 'discrete-mathematics']"
1861057,Help with the integral $\int x\sqrt{\frac{1-x^2}{1+x^2}}dx$,I would like to know what is $$\int x\sqrt{\frac{1-x^2}{1+x^2}}dx.$$  I put $x=\tan(y)$ to get integral of $\displaystyle \int \frac{\sin(y)}{\cos^3(y)}.\sqrt{\cos(2y)}dy$ I don't know whether $\sin(x)=t$ is a good substitution.,"['integration', 'trigonometry', 'calculus', 'closed-form']"
1861075,Is $\emptyset$ considered as a powerset by itself?,"For example, $X = \{\emptyset, a, \{b\}\}$. Find the power set of $X$. As far as I believe everyone understand, a power set of something means to display whatever element is within the set itself. So for instance, $\{b\}$ contain the element $b$ inside while $a$ is just an element by itself. So in order to conclude a power set of a $\emptyset$, a set that contains element $b$, and a element $a$ itself. Isn't it right to right the power set of $X$ as $$ P\{\emptyset, a, \{b\}\} = \{\emptyset, \{a\}, \{b\}, \{a,b\}\}?$$ However, is $\{\emptyset,a\}$ is logically similar to the $\{a, \emptyset\}$? Or $\emptyset$ should just remain as a $\emptyset$ and should not be placed with other elements in the set like the answer above?","['elementary-set-theory', 'discrete-mathematics']"
1861089,"If domain of $f(x)$ is $[-1,2]$ then what will be the domain of $f([x]-x^2+4)$ $?$","If domain of $f(x)$ is $[-1,2]$ then what will be the domain of $f([x]-x^2+4)$ $?$ Here $[.]$ is for greatest integer function. Attempt: since domain of $f(x)$ is $[-1,2]$ therefore for $f([x]-x^2+4)$ $-1\le[x]-x^2+4\le2$ $\Rightarrow x^2\le[x]+5$ and $x^2\ge[x]+2$ solving first inequality, as $x^2$ is always positive so $x\ge-5$ Now I can start taking intervals of $x$ and solve them but this brute force method is not taking me anywhere near to the correct answer.  Can someone explain me how is this problem solved? Please give an elaborate solution.",['functions']
1861105,Weighted War - Game of Mind and Probability,"Game Weighted War is a game
  of bidding, where: Both players have cards valued from $1$ to $11$ in their hands There is a third pile of cards from $1$ to $11$ face down on the table and shuffled, with one random card being removed from it at the
  beginning of the game Each beginning of a turn one random card from the table pile is turned face up, and the players offer one of their own cards face
  down. When both players decided on their bid card, their cards are flipped and the higher value takes the table card. The bid cards are
  put aside, and new turn begins. If the bid cards are equal, they are put aside and they start a next turn by flipping the next table card. This turn they bid for both
  cards. If the equal value repeats, they continue to add table cards to
  bid pile until someone wins it. (If both players run out of bidding cards and the bid pile hasn't been won yet, it goes to no one and stays aside.) When all cards are won, players count their points by adding the values of the table cards they won. The winner is one with more
  points. I'm wondering what would be the optimal strategy that maximizes your chances of winning and minimizes your chances of losing? I could find barely anything on this game online. One trivial things is that playing $1$ doesn't make sense since there is one card less at the table than in your hand. Also, playing a random card won't be any good for you since cases like bidding $11$ for a low valued card will rarely have any good effects for you. The video also mentions that they found that it's the best to play the same valued card as the table card but I couldn't find any proof of that. A Counter to that would be playing one card higher, and counter to that would be occasionally sacrificing some low cards to gain advantage in end game. Anyway, I'm also interested in how much luck has an effect here. Pattern I attempted to develop the optimal strategy for when there are
  only $2$, $3$ or $4$ cards in hopes of helping me to find a strategy for the $11$ card game. Assuming both players use the optimal strategy: For $2$ card case, there is no point in playing $1$ so both play $2$ and end up in a draw . For $3$ card case, a draw is forced $\frac{2}{3}$ times, and $\frac{1}{3}$ times happens when the first table card is $2$, then both players have equal chance of either winning , losing or ending up in a draw again. That depends on the table card that was removed at the beginning of the game. For $4$ card case, a draw is forced $\frac{3}{4}$ times, and $\frac{1}{4}$ times happens when the first table card is $4$, draw should also be forced since $4$ is the best choice to play for both players, but if a $4$ is countered with a $2$ then both players have again equal chance of either winning , losing or ending up in a draw if they continue to play perfectly. 
($3$ always beats $2$ and $4$ always beats $3$, if the rest of choices are best possible from both players.) That means the safest option in this $\frac{1}{4}$ case is $4$ and also the best option against a random play; but that always results in a draw if both players play perfectly. Thus, if both perfect players play a set of games until the match is resolved, and observe that they both keep drawing with a $4$, one might attempt to break the draw chain by playing $2$ and give both players an equal chance to resolve the match without needing to worry that the opponent might suddenly play $3$, making that the optimal strategy? But if other can predict your $2$ and counter with a $3$ he beats your method. That's why I'm not sure about the strategy for $4$ case if players are going for a win rather than accepting the draw as the best way of minimizing their losing chances, so I decided to post a separate question . All in all, I have solved these $2,3,4$ cases by observing each
  possible game state to determine what would be the optimal play. If
  the pattern holds, the original game of $11$ cards should have a
  optimal strategy which if used by both players, always results in a
  draw and/or equal chances for both players to win , lose or end
  up in a draw . But I still don't know how to create a general optimal strategy other
  than evaluating all possible states by brute force. I wonder If this
  can be solved by a optimal set of rules other than a brute force
  approach? (Either yes or no, I would need a proof of the solution)","['game-theory', 'recreational-mathematics', 'probability']"
1861110,"$f:\mathbb R \to \mathbb R$ be continuously differentiable function such that $f(x),f'(x)>0$ for all real $x$ , then $\lim _{x \to -\infty}f'(x)=0$?","Let $f:\mathbb R \to \mathbb R$ be a continuously differentiable function such  that $f(x)>0 , f'(x)>0 , \forall x \in \mathbb R$ , then is it true that $\lim _{x \to -\infty}f'(x)=0$ ? I can only figure out that $\lim _{x \to -\infty} f(x)$ exists finitely as $f$ is increasing and bounded below . Please help . Thanks in advance","['derivatives', 'real-analysis', 'continuity', 'limits']"
1861118,harmonic series as product over primes,"If we consider the harmonic series written as such $$\sum_{n=1}^\infty\,\frac{1}{n} = \prod_{\substack{p\text{ prime}}} (1+\frac{1}p+\frac{1}{p^2}+\frac{1}{p^3}+…) \tag{1}\label{1} $$ I don’t understand how it can be written in this form
$$\prod_{\substack{p\text{ prime}}} \frac{1}{1−\frac{1}p} \tag{2}\label{2}$$ In the first infinite product (\ref{1}) we have a bunch of power of primes, which are needed to write all the possible integer as a product of primes, but these power of prime don’t seem to appear in (\ref{2}). How do you get from (\ref{1}) to (\ref{2})?","['calculus', 'analysis']"
1861122,Continuous semi-norms on subspace,"Suppose $X$ is a locally convex topological vector space, let $P$ be the set of all continuous semi-norms on $X$. Suppose $M$ is a subspace of $X$, denote $P|_M$ as the set of semi-norms in $P$ restricted on $M$. Is it true that $P|_M$ is the set of continuous semi-norms on $M$?","['functional-analysis', 'locally-convex-spaces', 'topological-vector-spaces']"
1861126,"Why is $\mathbb{C}^2\setminus\{(0,0)\}$ not a basic open set?","Consider the affine variety $\mathbb{C}^2$ equipped with Zariski topology. By the question above, I mean why $X:=\mathbb{C}^2\setminus\{(0,0)\}$ cannot be written as $$
X:=U_f:= \{(x,y)\in \mathbb{C}^2:f(x,y)\neq 0\} \mbox{ for some }f\in\mathbb{C}[x,y]. 
$$
I am trying to do this without computing the ring of regular functions on $X$. My attempt: Suppose $X$ is a basic open set and $X=U_f$ for some $f\in \mathbb{C}[x,y]$. Writing $x,y,z$ for the coordinates of $\mathbb{C}^3$, I have shown that $X$ is isomorphic to an affine algebraic variety $W=Var(zf-1)\subset \mathbb{C}^3.$ Can this help me arrive at a contradiction?",['algebraic-geometry']
1861133,How to get the idea of the formula for the mean value property for the heat equation,"From the mean-value property of the Laplace's equation, we have the following mean-value property:
$$
u(x)=\frac{1}{a(n)r^n}\int_{B(x,r)}u\,dy.
$$
But for the mean-value property of the Heat equation, Evans' book defines a heat ball:
$$
E(x,t,r)=\left\{(y,s)\in R^{n+1}\bigg|s\leq t, \Phi(x-y,t-s)\geq \frac{1}{r^n}\right\}.
$$
Then, the theorem claims that if $u\in C^2_1(U_T)$ solves the heat equation. Then,
$$
u(x,t)=\frac{1}{4r^n}\iint\limits_{E(x,t,r)}u(y,s)\frac{|x-y|^2}{(t-s)^2}\,dy\,ds.
$$ My question is: is there any explanation (or a guessed one) about the discover of this theorem? The mean-value property is intuitive. But how can we know that we can achieve the goal by making the integrand as the multiplication of $u(y,s)$ with such a strange factor, $\frac{|x-y|^2}{(t-s)^2}$, and a nonintuitive heat ball?","['functional-analysis', 'real-analysis', 'partial-differential-equations']"
1861135,Why doesn't coordinate difference between two points correspond to distance between two points?,"I know that in Euclidean geometry, where the manifold is ""flat"" (such that it is isomorphic to an open subset of $\mathbb{R}^{n}$), $M\cong\mathbb{R}^{n}$, one can use Cartesian coordinates, $\phi (p)\equiv x^{\mu}:M\rightarrow\mathbb{R}^{n}$, to cover the entire manifold, and further more, if one has two points $p$ and $q$, then their coordinate difference, $\sqrt{\left[x^{\mu}(p)-x^{\mu}(q)\right]^{2}}$ (summation implied), corresponds to the actual distance between the two points on the manifold. My question is, what is the reasoning for why this is not true in general? i.e. Why doesn't so-called ""coordinate distance"" between two points correspond to the actual distance between them on the manifold?
 For example, the coordinate difference between two points on a sphere does not correspond to the actual distance between two points on the sphere (considering the Earth, one cannot simply naively take the difference  between two points on a map an equate the reply to the actual physical distance between them). Is it simply that the coordinate maps will in general be highly non trivial (and not the simple identity map as in Cartesian coordinates), and so simply subtracting the coordinate values of one point from another will not map back to differences between points on the manifold? Is it also to do with the fact that one needs to define a metric on the manifold in order to measure distances between points on the manifold and such a metric will in general be non-Euclidean, and so the simple subtraction of coordinate values does not equate to the actual metric distance? Apologies if this post is a bit confused, but I'm a bit stuck on how to understand this concept correctly. Any help would be much appreciated.","['manifolds', 'intuition', 'coordinate-systems', 'differential-geometry']"
1861158,L^1 convergence and limsup of convergent sequence,"I have to solve this exercise: let $f_n$ be a sequence of positive real function defined on a measure space $(X,M,\mu)$ such that $f_n\in L^1(\mu)$ $\forall n\in \mathbb{N}$ and $f_n$ is convergent in $L^1$-norm. Is it true that $\limsup_{n\to\infty}f_n$ is a.e. finite? If so, does it have to be Lebesgue-integrable? I know that if $f_n\to f\in L^1(\mu)$ in $L^1$-norm there exists a subsequence $f_{n_k}$ pointwise convergent to the $L^1$-limit of $f_n$, but this does not exclude the existence of a divergent subsequence on a positive measure set, even if I think that the answer to the first question is yes. How can I prove it? I thought about using Reverse Fatou's Lemma but it doesn't seem to help...","['limsup-and-liminf', 'functional-analysis', 'lp-spaces', 'integration', 'measure-theory']"
1861173,solve this 1999 problem with geometry,"if  $\bigodot P\bigcap \bigodot Q=A,B$,and the  common tangent is $C,D$,and $E\in BA$,and $EC\bigcap \bigodot P=F,ED\bigcap \bigodot Q=G$,and if $\angle FAH=\angle  HAG$ show that
$$\angle  FCH=\angle GDH$$ it seem hard, I can't get this answer For Weijie Chen answer,then I have add a fig,let we clear understand",['geometry']
1861197,Circular permutations with repetitions,"$n$ distinct objects have $n!$ (linear) permutations and thus $(n-1)!$ circular permutations. Now consider $n$ objects, some identical, $r_1$ of the first kind, $r_2$ of the second kind, ..., $r_k$ of the $k$ th kind. These $n$ objects have $\frac{n!}{r_1!r_2!\dots r_k!}$ (linear) permutations. Can we likewise reason that these $m$ objects have $\frac{(n-1)!}{r_1!r_2!\dots r_k!}$ circular permutations? I think the answer is no, but can someone explain the intuition why the reasoning that worked earlier doesn't work here? Also, what is the correct number of circular permutations for these $m!$ objects? (I am hoping for an answer that's suitable for high school students. Thanks.)",['combinatorics']
1861202,$\lim_{x\to\infty}(f(x)+f'(x))=0 \rightarrow \lim_{x\to\infty}f(x)=0$? [duplicate],"This question already has answers here : Limit of $y$ if limit of $y+y'$ goes to $0$? [duplicate] (2 answers) Closed 7 years ago . Suppose that $f:[0,\infty)\to\Bbb R$ is differentiable, and $\lim_{x\to\infty}(f(x)+f'(x))=0$.
Prove that $\lim_{x\to\infty}f(x)=0$. I tried to show that $\lim_{x\to\infty}f(x)\neq0\rightarrow \lim_{x\to\infty}(f(x)+f'(x))\neq0$ If $\lim_{x\to\infty}f(x)\neq0, \exists e>0, \forall N\in\Bbb N, \exists x_1, x_2, ...>N,|f(x_i)|\ge e$. So that the possibility for  $\lim_{x\to\infty}(f(x)+f'(x))=0$ is only when $f(x_i)+f'(x_i)=0$ is true for any $i$. So if  $f(x_1)\gt0,$ it must be decreasing, to less than $e$ But there exists $x_2\gt x_1 s.t. |f(x_2)|\ge e$ In conclusion, $f(x)$ has to decrease when $x$ is large enough and $f(x)\ge e$ but there must exists infinitely many points whose function value is no less than $e$. But it cannot happen. Is my idea of proof valid? I don't know how to formally write my idea...please teach me..",['analysis']
1861208,Fourier Series for $f(x)=\sin(x)+\cos(2x)$,"Find the Fourier Series for $$f(x)=\sin(x)+\cos(2x)$$ I got $a_0=0$ which seems correct but I'm struggling with $a_n$ and $b_n$. Here are my attempts: $$\begin{align}
a_n&=\frac{1}{2\pi} \overbrace{\int\limits_0^{2\pi} \cos(nx)\sin(x)dx}^{\text{odd function}}+\int\limits_0^{2\pi} \cos(nx)\cos(2x)dx\\ 
&= \frac{1}{2\pi} \left[\frac{\sin(nx)}{n}\cos(2x)\right]_0^{2\pi}-2\cdot\int\limits_0^{2\pi}\frac{\sin(nx)}{n}\sin(2x)\\
\end{align}$$ If I integrate the second term again I get an even function again and again. I need a fitting addtion theorem or something else. Any hints?","['fourier-series', 'calculus', 'integration', 'trigonometric-integrals', 'analysis']"
1861212,Difference sets without squares of Integers,"I am trying to print numbers occuring in A030193 i.e     Let S = set of square numbers; a(0)=0; a(n) = smallest m such that m - a(i) is not in S for all i < n. but I am unable to do it in better than $O(n^2\log{n})$ for (int i = 1 ; i <= n;i++)
{
    for (j = 0  to T.size())
    {
        if (S.find(i-T[j]))
            goto label;
    }   
    T.insert(i);
    label: ;    
} Here S is Set containing squares and T is set containg numbers of sequence. Does a better approach exists?","['number-theory', 'oeis', 'computer-science', 'discrete-mathematics']"
1861213,Differentiating $\mbox{tr} (ABA^TC)$ w.r.t. $A$ [duplicate],"This question already has answers here : Gradient of $A \mapsto \operatorname{trace} (A B A' C)$ (5 answers) Closed 3 years ago . Why is $\nabla_A \mbox{tr} (ABA^TC) = CAB + C^TAB^T$? Here $A, B, C, D$ are all $n \times n$ matrices. $$\nabla_A f(A) = \left[\begin{matrix}
\frac{\partial f}{\partial A_{11}}... \frac{\partial f}{\partial A_{1n}}\\
...\\
\frac{\partial f}{\partial A_{n1}}... \frac{\partial f}{\partial A_{nn}}\\
\end{matrix}\right]$$ I tried to prove it in this way: $$\begin{align}
\nabla_A \mbox{tr} (ABA^TC) &= \nabla_Atr (BA^TC)A\\ &= \nabla_A \mbox{tr} DA ......let  \ D=BA^TC\\ &= \nabla_A \mbox{tr} AD\\ &=D^T\\ &=B^TAC^T\end{align}$$ Since $B^TAC^T \neq CAB + C^TAB^T$, there must be something wrong in my derivation. How to prove this property?","['derivatives', 'matrices', 'matrix-calculus', 'scalar-fields', 'trace']"
1861256,sigma algebra generated by compacts versus sigma algebra generated by open sets,Let $\Omega$ be a locally compact Hausdorff set. Is the sigma algebra generated by compact sets is the same as the sigma algebra generated by open sets?,['measure-theory']
1861261,Show that there is a subsequence of $(f_n)_n$ that converges to $f$ almost everywhere.,"Let $(X,\mathcal{B}, \mu)$ be a measure space and assume the sequence $(f_n)_n$ converges to $f$ in $L^p(\mu)$, where $1\leq p<\infty$. Show that there is a subsequence of $(f_n)_n$ that converges to $f$ almost everywhere. Isn't it true that for all subsequence of $(f_n)_n$? Attempt: Since $f_n\to f$ in $L^p$, for any $\epsilon>0$, there exists $N\in\mathbb{N}$ such that for all $n,m\leq N$, $\|f_m-f_n\|_p<\epsilon /2$ or $\|f_n-f\|_p<\epsilon /2$ Let $(f_{n_k})_k$ be any subsequence of $(f_n)_n$. Then $$\|f_{n_k}-f\|_p\leq \|f_{n_k}-f_n\|_p+\|f_n-f\|_p< \epsilon /2+\epsilon /2=\epsilon.$$ I don't know what the wrong is here. Can anyone check my proof? Thanks!","['real-analysis', 'measure-theory', 'analysis']"
1861266,Weak problem formulation for PDE and boundary conditions,"Consider the following example:
$$
- \Delta u = f \mbox{ in } \Omega,
$$
$$
u = 0 \mbox{ on } \Gamma,
$$
Here $\Gamma$ is boundary of $\Omega$.
To produce weak formulation we multiply by arbitrary $v$ from $H^1(\Omega)$, integrate over $\Omega$ and apply integration by parts:
$$
\int_{\Omega} \nabla u \nabla v dx - \int_{\Gamma} \frac{\partial u}{\partial n}vds = \int_{\Omega} f v dx.
$$
Because we don't have information about $\partial u /\partial n$ on $\Gamma$ we restrict $v$ to lie in $V = \{ v \in H^1(\Omega): v|_\Gamma = 0 \}$. This new constructed space may not be a complete, so we need to complete it with respect to Sobolev norm (Otherwise we won't be able to apply Lax–Milgram theorem and prove existence of weak solution). But after this procedure we may have functions in $V$ which violate boundary conditions $v|_\Gamma = 0$. Why after completion of $V$ with respect to Sobolev norm we won't run into functions $v|_\Gamma \neq 0$?  All textbooks I've consulted skip this moment, probably because it is obvious.","['hilbert-spaces', 'partial-differential-equations', 'functional-analysis', 'ordinary-differential-equations', 'sobolev-spaces']"
1861288,On the proof $\tan 70°-\tan 20° -2 \tan 40°=4\tan 10°$,I am currently studying in class 10 and I am unable to do this problem. $$\tan 70 ° -\tan 20° -2 \tan 40° =4\tan 10°$$ Can anybody please help me. Thanks!,['trigonometry']
1861294,"Definition of ""smallness"" in Lurie's HTT","In Lurie's Higher Topos Theory , on the first page of the appendix, he writes If $\kappa$ is a regular cardinal, we will say that a set $S$ is $\kappa$-small if it has cardinality less than $\kappa$. Is this really what he intended, or is this a typo and should be rank instead of cardinality ?",['elementary-set-theory']
1861318,Non-constant holomorphic and bounded functions $f:\Omega_j\rightarrow\mathbb{C}$,"Are there holomorphic, non-constant and bounded functions $$f:\Omega_j\rightarrow\mathbb{C}$$
with $\Omega_1=\mathbb{C}\setminus\{0\}$ $\Omega_2=\mathbb{C}\setminus[0,\infty)$? Since $\Omega_2$ is star-shaped I can use the Riemann mapping theorem and find a biholomorphic function $f:\Omega_2\rightarrow\mathbb{D}$. But what about #1? And I have the feeling that using the Riemann mapping theorem is kind of too much here. Are there alternatives? Thank you!",['complex-analysis']
1861371,Show that $\text{rank}(Df)(A) = \frac{n(n+1)}{2}$ for all $A$ such that $A^TA = I_n$,"We identify $\mathbb R^{n \times n}$ with $\mathbb R^{n^2}$ and define $f:\mathbb R^{n^2} \to \mathbb R^{n^2}, A \mapsto A^TA$. Show that $\text{rank}(Df)(A) = \frac{n(n+1)}{2}$ for all $A$ such that $A^TA = I_n$. The solution by Omnomnomnom written in a more accessible (for me) way: We firstly note that $$f(A+H)=(A + H)^T(A + H) = A^TA  + H^TA + A^TH +H^TH$$ Consider the following homomorphismus $\Phi:\mathbb R^{n^2} \to \mathbb R^{n^2}, H \mapsto H^TA + A^TH$ Thus the equation above can be written as: $$f(A+H)= f(A)  + \Phi(H) +H^TH$$ Remember that according to the definition $(Df)(A)$ is a homomorphismus from $\mathbb R^{n^2}$ to $\mathbb R^{n^2}$ such that $$\lim_{H\to 0, H \ne 0} \frac{f(A+H)-f(A)-(Df)(A)H}{\|H\|}=0$$ Because $\lim_{H\to 0, H \ne 0}\|\frac{H^TH}{\|H\|}\| \le \lim_{H\to 0, H \ne 0}\frac{\|H^T\|\|H\|}{\|H\|}=\lim_{H\to 0, H \ne 0}\|H^T\|=0$, it follows that: $$\lim_{H\to 0, H \ne 0} \frac{f(A+H)-f(A)-\Phi (H)}{\|H\|}=\lim_{H\to 0, H \ne 0} \frac{H^TH}{\|H\|}=0$$ and consequently  $Df(A)=\Phi$. Now we note that $\{\Phi(H):H \in \mathbb R^{n^2}\}=\{X\in \mathbb R^{n^2} : X^T = X\}$, because: 1) $(H^TA + A^TH)^T = A^TH^{TT} + H^TA^{TT} = H^TA + A^TH$ 2) $S$ is symmetric, then $\Phi(\frac{1}{2}AS)=\frac{1}{2}(SA^TA+A^TAS)=S$ Now it follows:
$$\frac{n(n+1)}{2}=\dim \{X\in \mathbb R^{n^2} : X^T = X\}=\dim\{\Phi(H):H \in \mathbb R^{n^2}\}=\text{rank}\Phi=\text{rank}(Df)(A)$$","['derivatives', 'matrix-calculus', 'matrix-rank', 'linear-algebra']"
1861378,Can the derivative prove my function has only one root?,"I have a function:
$$f(x)=x-\ln(x^2+1)+2$$ I want to prove my function has exactly one root. If I differentiate:
$$f'(x)=1-\frac{2x}{x^2+1}$$ I can see this value is positive for every $x$. Does this prove that my function is strictly increasing? All the theorems I know about the argument apply for a closed interval, so I don't know if my resolution is valid.  Should I also prove the function has a positive and a negative part?","['calculus', 'functions']"
1861380,Does every power of two arise as the difference of two primes?,"Conjecture: For each $n\in\mathbb N$ there are primes $q<p$ with $p-q=2^n$. Verified for $n\leq 26$: n        p  q
 0        3  2
 1        5  3
 2        7  3
 3       11  3
 4       19  3
 5       37  5
 6       67  3
 7      131  3
 8      263  7  
 9      523 11  
10     1031  7  
11     2053  5  
12     4099  3  
13     8209 17  
14    16421 37  
15    32771  3  
16    65539  3  
17   131101 29  
18   262147  3  
19   524341 53  
20  1048583  7  
21  2097169 17  
22  4194371 67
23  8388619 11  
24 16777259 43  
25 33554473 41  
26 67108961 97 Proofs or counterexamples may be far away, but is something known about this topic?","['number-theory', 'conjectures', 'prime-numbers']"
1861402,Proof of the summation $n!=\sum_{k=0}^n \binom{n}{k}(n-k+1)^n(-1)^k$?,$$n!=\sum_{k=0}^n \binom{n}{k}(n-k+1)^n(-1)^k$$ Could anyone give the proof of the above equation? Thanks in advance!,"['combinatorics', 'factorial', 'summation', 'binomial-coefficients']"
1861413,How to remember Stolz Angle correctly,"The Stolz angle is a condition used in Abel's Theorem: $$|1-z|\leq M(1-|z|)$$ Q1) How do I intuitively remember (and understand this)? Q2) In particular, is there a quick way to see that $$(1-|z|)\leq M|1-z|$$ is the wrong condition? Thanks for any help.",['complex-analysis']
1861442,"Prove that all $t_{n,m}$ are integers","A ""number triangle"" $(t_{n, k})$ $(0 \le k \le n)$ is defined by $t_{n,0} = t_{n,n} = 1$ $(n \ge 0),$
  $$t_{n+1,m} =(2 -\sqrt{3})^mt_{n,m} +(2 +\sqrt{3})^{n-m+1}t_{n,m-1} \quad (1 \le m \le n).$$
  Prove that all $t_{n,m}$ are integers. I find it hard to prove that they are all integers because from the table below there doesn't seem to be a pattern. I think induction might work if we use strong induction on $m$ for a fixed $n$. We know that it holds for $t_{n,0}$ so we have the base case. How should I write the inductive proof? Assume that $t_{n,k}$ are integers for all $n < r$. Now, we have $$t_{r,1} = (2-\sqrt{3})t_{r-1,1}+(2+\sqrt{3})^{r-1}t_{r-1,0} = (2-\sqrt{3})t_{r-1,1}+(2+\sqrt{3})^{r-1}.$$ Then we have $t_{r-1,1} = (2-\sqrt{3})t_{r-2,1}+(2+\sqrt{3})^{r-2}t_{r-2,0} = (2-\sqrt{3})t_{r-2}+(2+\sqrt{3})^{r-2}$, which we know is an integer, but I don't see where to go from here. Here is a table I made: $t_{0,0} = 1$ $t_{1,0} = 1$ $t_{1,1} = 1$ $t_{2,0} = 1$ $t_{2,1} = (2-\sqrt{3})+(2+\sqrt{3}) = 4$ $t_{2,2} = 1$ $t_{3,0} = 1$ $t_{3,1} = (2-\sqrt{3})t_{2,1}+(2+\sqrt{3})^2 t_{2,0} = 4(2-\sqrt{3})+(2+\sqrt{3})^2 = 15$ $t_{3,2} = (2-\sqrt{3})^2 t_{2,2}+(2+\sqrt{3}) t_{2,1} = (2-\sqrt{3})^2+4(2+\sqrt{3}) = 15$ $t_{3,3} = 1$ $t_{4,0} = 1$ $t_{4,1} = (2-\sqrt{3}) t_{3,1}+(2+\sqrt{3})^3 t_{3,0} = 15(2-\sqrt{3})+(2+\sqrt{3})^3 = 56$ $t_{4,2} = (2-\sqrt{3})^2 t_{3,2}+(2+\sqrt{3})^2t_{3,1}= 15(2-\sqrt{3})^2 +15(2+\sqrt{3})^2 = 210$ $t_{4,3}= (2-\sqrt{3})^3 t_{3,3}+(2+\sqrt{3})t_{3,2} = (2-\sqrt{3})^3+15(2+\sqrt{3}) = 56$ $t_{4,4} = 1$ $t_{5,0} = 1$ $t_{5,1} = (2-\sqrt{3})t_{4,1}+(2+\sqrt{3})^4 t_{4,0} = 56(2-\sqrt{3})+(2+\sqrt{3})^4 = 209$ $t_{5,2} = (2-\sqrt{3})^2 t_{4,2}+(2+\sqrt{3})^4 t_{4,1} = 210(2-\sqrt{3})^2+56(2+\sqrt{3})^3 = 2926$ $t_{5,3} = (2-\sqrt{3})^3 t_{4,3}+(2+\sqrt{3})^2 t_{4,2} = 56(2-\sqrt{3})^3+210(2+\sqrt{3})^2 = 2926$ $t_{5,4} = (2-\sqrt{3})^4 t_{4,4}+(2+\sqrt{3}) t_{4,3} = (2-\sqrt{3})^4+56(2+\sqrt{3})^2 = 209$ $t_{5,5} = 1$ $t_{6,0} = 1$ $t_{6,1} = (2-\sqrt{3})t_{5,1}+(2+\sqrt{3})^{5}t_{5,0} = 209(2-\sqrt{3})+(2+\sqrt{3})^5 = 780$ $t_{6,2} = (2-\sqrt{3})^2 t_{5,2}+(2+\sqrt{3})^4 t_{5,1} = 2926(2-\sqrt{3})^2+209(2+\sqrt{3})^4 = 40755$ $t_{6,3} = (2-\sqrt{3})^3 t_{5,3}+(2+\sqrt{3})^3 t_{5,2} = 2926(2-\sqrt{3})^3+2926(2+\sqrt{3})^3 = 152152$ $t_{6,4} = (2-\sqrt{3})^4 t_{5,4}+(2+\sqrt{3})^{2}t_{5,3} = 209(2-\sqrt{3})^4+2926(2+\sqrt{3})^3 = 40755$ $t_{6,5} = (2-\sqrt{3})^5 t_{5,5}+(2+\sqrt{3})t_{5,4} = (2-\sqrt{3})^5+209(2+\sqrt{3}) = 780$ $t_{6,6} = 1$",['number-theory']
1861471,"How to prove the inequalities between $20^{70^2},30^{60^2},40^{50^2}$","Let $$M=\{ 20^{70^2}, 30^{60^2},40^{50^2}\}$$.
What number is the greatest and which is the smallest? I thought about beginning by assuming certain inequalities and trying to prove them, for example: $$20^{70^2} < 30^{60^2}$$
However, I do not know exactly what do from here. I took logarithms and expanded the expressions, this took me nowhere. I could get no obvious identity out of them, is there a clever way to do this?","['algebra-precalculus', 'inequality']"
1861484,When is a stochastic integral a martingale?,"In what follows, let the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ as well as the chosen filtration $(\mathcal{F}_t)_{t \ge 0}$ be known, and let $f$ denote an arbitrary locally bounded progressively measurable process (i.e. bounded on compact intervals and for all $t$ measurable with respect to $\mathcal{B}([0,t])\otimes \mathcal{F_t}$). Consider the process $(Y_t)_{t \ge 0}$ defined by the stochastic integral of $f$ with respect to $(X_t)_{t\ge 0}$: $$Y_t = \int_0^t f(s) \mathrm{d}X_s$$ Which of the following are true? 1. $X_t$ is a martingale $\implies$ $Y_t$ is a local martingale but not necessarily a true martingale. 2. $X_t$ is a locally $L^2-$bounded true martingale $\implies Y_t$  is a locally $L^2$-bounded true martingale. 3. $X_t$ is a local martingale $\implies$ $Y_t$ is a local martingale. 4. $X_t$ is a semimartingale $\implies$ $Y_t$ is a semimartingale. I just want to know which results are true, and then I will supply the proofs on my own later. It seems like 2. only holds when we have the additional condition on $f$ that it is locally $L^2$ bounded. In fact, it seems like I may have had it mixed-up: $X_t$ and $Y_t$ need to be globally $L^2$ bounded i.e. square integrable, but $f$ only needs to be locally $L^2$ bounded i.e. square integrable on compact intervals -- do I have this right? I'm still not sure. https://fabricebaudoin.wordpress.com/2012/09/14/lecture-19-stochastic-integrals-with-respect-to-square-integrable-martingales/ EDIT: OK, fixing the assumptions in the manner mentioned above, this is almost certainly true, see Theorem 19 on p.34 of this document: http://math.bu.edu/people/prakashb/Math/stochint.pdf ; this also follows from Theorem 6.3 and Lemma 6.4 on p.35 here: https://staff.fnwi.uva.nl/p.j.c.spreij/onderwijs/master/si.pdf ; also pp. 137-140 in Revuz and Yor, where being locally bounded also supposedly implies being locally $L^2-$bounded (see the last paragraph of p.140 and consider that $\langle B, B \rangle=t$ and that Brownian motion is a continuous local martingale. So seemingly the condition of being locally bounded is unnecessarily strong in many places where it is used. I am not sure if it can be replaced by locally $L^2-$bounded in all places. Actually a closer reading of Definition 2.1 on p. 137 of Revuz and Yor implies that 2. holds only for square-integrable integrands $f$, not just locally $L^2-$bounded. If we relax the condition to locally $L^2-$bounded, then only Proposition 2.7 on p.140 is applicable (since martingales are local martingales after all), and we can only conclude that the stochastic integral is a local martingale (although the example given between the end of p.139 and the beginning of p.140 about Brownian motion suggests otherwise -- perhaps if both the integrator and the integrand are locally $L^2$-bounded martingales then we get a martingale, but not square-integrable, as the result? Also it is worth noting that a corollary of the Martingale representation theorem and the associativity of the stochastic integral (when applicable) allows us to phrase most of the conditions given in terms of integration w.r.t. $\langle M, M \rangle_s$ as conditions in terms of $s$, i.e. $L^2$-boundedness, because the quadratic variation of Brownian motion is $t$.","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'stochastic-analysis', 'stochastic-calculus']"
1861485,Is there a close form solution for this series?,"I want to find close form solution for this series
$$\sum_{n=1}^{\infty}\cos\left(\frac{x}{3^n}\right)\sin^2\left(\frac{x}{3^n}\right)$$
Thanks for your help.","['sequences-and-series', 'calculus']"
1861580,Notation of the square (or other power) of a function $f(x)$,"How do you notate the square (or other power) of a function $f(x)$?
Is it $f^2(x)$ (similar to $\sin^2(x)$ for example), $f(x)^2$ or do you have to use $(f(x))^2$? Thanks in advance.","['notation', 'soft-question', 'functions']"
1861598,Is it true that if $T$ is a linear operator on a finite-dimensional vector space $V$ then $V=\ker T\oplus \operatorname{im}T$?,"$\newcommand{\im}{\operatorname{im}}$I am trying to prove or disprove the following statement: Let $V$ and $W$ be finite-dimensional vector spaces. If $T:V\rightarrow W$ is a linear transformation then $V=\ker T\oplus \im T$. (By the symbol $\oplus$ I mean the direct sum of two vector spaces.) This statement cannot be true if $V\neq W$ because a vector space can only be a direct sum of its subspaces. However, I am not sure about the case when $V=W$, i.e., when $T$ is a linear operator. I want to use the following proposition: $\textbf{Proposition.}$ Let $V$ be a finite-dimensional vector space and let $U$ and $W$ be subspaces of $V$. Then $V=U\oplus W$ if and only if $V=U+W$ and $U\cap W=\left\{ 0 \right\}$. First I want to show that $V=\ker T + \im T$. I just don't have a clue how to possibly do this, which leads me to believe there must be a counterexample. I believe that $\ker T\cap \im T=\left\{0\right\}$ since $T(0)=0$ for any linear transformation and it is not possible for $Tv\neq 0$ if $v\in \ker T$. Some help? Thank you in advance.","['direct-sum', 'linear-algebra', 'linear-transformations']"
1861612,How to physically model/construct a biased coin?,"A perfectly unbiased coin is one that has the same probability for heads and tails (i.e., 50%/50%). A perfectly biased coin is one that has (as the name suggests) different probabilities for head than for tails. The design of a perfectly unbiased coin is pretty straightforward: a cylinder with height << radius (h << r). However, I'm wondering how the design for a perfectly biased coin would be. Although I'm not a mathematician, I can intuitively think that a perfectly biased coin (with 60% for heads and 40% for heads) would have the heads circle surface area 60% higher than that of the tails' circle surface area. I don't know how true this is and, if true, I'd like to reach the same conclusion using a mathematical approach. Would this problem be much more difficult if we had, for example, a perfectly biased dice (i.e. cube)? How can I start constructing a mathematical model for biased, throwable, generic objects?","['probability-theory', 'probability', 'dice']"
1861614,enumerating polyominos,"Polyominoes are made by gluing together finitely many squares along their edges. They always have connected interiors, but are allowed to have holes. Enumerating polyominoes is a huge subject, and of course the answers depend on whether you are interested in free, one-sided, or fixed polyominoes . I am trying to understand one of the most fundamental algorithms in this area, although I'm aware that faster, but more complicated, algorithms are known now. Specifically, I'm interested in Redelmeier's algorithm for enumerating fixed polyominoes: https://en.wikipedia.org/wiki/Polyomino#Algorithms_for_enumeration_of_fixed_polyominoes You can find the original paper here: https://dx.doi.org/10.1016%2F0012-365X%2881%2990237-5 And in case that link is behind a paywall, the algorithm is described in Section 2 here: https://arxiv.org/pdf/1106.1078.pdf I am having trouble understanding the recursive description of the algorithm in the original paper, and I find the Wikipedia description much easier to understand. Unfortunately, I am not sure if what is on Wikipedia is correct. What is bothering me is that the algorithm described can get stuck sometimes, where no further tiles can be added to the current polyomino. (In fact, if you try to generate a ""random"" polyomino with 1000 tiles, you will almost always get stuck at some point.) The smallest example I have is illustrated below. This seems to follow the rules described on Wikipedia, but now we are stuck.","['combinatorics', 'recreational-mathematics', 'polyomino']"
1861627,circle tangent to three circles,"To-day I want to look at CCC - one circle tangent to three circles whose radii and positions of their centers are known. How does one solve this.. old fashioned ways like ruler and compass, or modern ways like intersection theory? these Apollonius problems are all very classical but good treatments are hard to find. here is a different such problem construct circle tangent to two given circles and a straight line","['conic-sections', 'intersection-theory', 'geometry']"
1861656,"Prove that this is one-one, but not onto $\Bbb R$.","$\Bbb R$ stands for real numbers. $ f(x) =
\begin{cases}
2-x,  & \text{if $x \le 1 \qquad \text{is one to one but not onto } \Bbb R $  } \\
\frac{1}{x} , & \text{if $x >1$ } 
\end{cases}$ I know how to prove that this is one to one by saying that an element in the domain maps too exactly one element in the range set. $x\le1 \;\Rightarrow \; f(x) = f(y) \Rightarrow \; 2-x =2-y \Rightarrow x=y$ $x>1\Rightarrow$ $\frac{1}{x} = \frac{1}{y} \Rightarrow x=y$ We can say from this that this is one-one. I am having trouble understanding why this is not onto. I know that $0 \notin \Bbb x$.  This is where I get lost. I know that a function is onto if every element in the range set has a preimage is the domain set. I am just not too sure what that means in applying to this problem.","['algebra-precalculus', 'functions']"
1861714,Does subtracting a positive semi-definite diagonal matrix from a Hurwitz matrix keep it Hurwitz?,"I am having a linear algebra problem here. I will be grateful if someone can help me. Let $A\in \mathbb{R}^{n\times n}$ be Hurwitz and diagonizable, and let $B$ be a diagonal matrix whose diagonal elements are non-negative. Is $A-B$ still Hurwitz? I know that if $B=cI$, where $c$ is a positive scalar, $A-B$ is a Hurwitz matrix. However, I am not sure whether $A-B$ is still a Hurwitz matrix when some diagonal elements in $B$ are zero and the others are positive. Are there any general results on the similar topic? Thanks in advance!","['matrices', 'linear-algebra', 'hurwitz-matrices']"
1861717,Find surface in $\mathbb{R}^3$ with certain tangent spaces,"By Frobenius Theorem, in $\mathbb{R}^3$ there exists a smooth surface
whose tangent space is spanned by the vector fields $V(x,y,z)=(x^2+y^2,0,-y)$
and $W(x,y,z)=(0,x^2+y^2,x)$. 
How can I find this surface?
Is there in general a way to find it when the vector fields are algebraic?",['differential-geometry']
1861733,"$\int_{-\infty}^\infty \frac{\sin (t) \, dt}{t^4+1}$ must be zero and it isn't","I'm trying to evaluate the integral
$$\int_{-\infty}^\infty \frac{\sin (t) \, dt}{t^4+1}$$ using residue and complex plane integration theory. Let $f(t):=\frac{\sin (t)}{t^4+1}$, $f(z):= \frac{\sin (z)}{z^4+1}$. Then $f(z)$ has four singular points, two of which are in the semicircle $R>2$ in the upper  half of the complex plane: $p_1:=\exp\{i\frac{\pi}{4}\}$ and $p_2:=\exp\{i\frac{3\pi}{4}\}$. We know that $$\int_{-R}^R \frac{\sin (t) \, dt}{t^4+1}+\int_{C_R}\frac{\sin (z) \, dz}{z^4+1}=2\pi i(\operatorname{Res}_{z=p_1}+\operatorname{Res}_{z=p_2})$$ But here's the mysterious part:
$$\lim_{R\to\infty}\int_{C_R}\frac{\sin (z) \, dz}{z^4+1}=0$$
yet $$(\operatorname{Res}_{z=p_1}+\operatorname{Res}_{z=p_2})\ne 0$$
But the original integral must be equal to zero. I'd appreciate if it could be pointed out what I'm not doing right.","['complex-analysis', 'improper-integrals', 'contour-integration', 'residue-calculus']"
1861747,ODE system solving by sequence of functions,"Let $y' = Ay$ where $A = \begin{pmatrix} 0&1 \\ -1& 0 \end{pmatrix}$ and $y( 0 ) = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$. Consider the map $$G: C(\mathbb{R},\mathbb{R}^2) \to C(\mathbb{R},\mathbb{R}^2),  G(\phi)(x) = \begin{pmatrix} 1 \\ 0 \end{pmatrix} + \int_0^x A\phi(t) dt$$. With $\phi_0(x) = \begin{pmatrix} 1\\0\end{pmatrix}$ and $\phi_{n+1} = G(\phi_n)$, how to find and prove the general formula for $(\phi_n)_{n\in\mathbb{N}}$?","['self-learning', 'ordinary-differential-equations']"
1861790,"If $K$ is compact and $C$ is closed in $\mathbb{R}^k$, prove that $K + C$ is closed using a ""direct"" proof","Rudin Exercise 4.25(a) reads: If $K$ is compact and $C$ is closed in $\mathbb{R}^k$, prove that $K + C$ is closed. The hints in the problem suggest a proof by proving that the complement of $K + C$ is open, a path which I was able to follow into a successful proof.  However, I want to prove it ""directly"", by showing that any limit point of $K + C$ must be within $K + C$, however I run into the following problem: My Attempt: Suppose $z$ is a limit point of $K + C$.  Then there is a sequence $\{z_n\} \to z$ in $K + C$.  Since each $z_i$ is an element of $K + C$, we can write $z_i = k_i + c_i$ for sequences $\{k_i\}$, $\{c_i\}$ in $K$ and $C$ respectively. Now, we simply must show that $\{k_i\} \to k \in K$ and $\{c_i\} \to c \in C$ to be done. However, I noticed that $\{k_n\}$ and $\{c_n\}$ do not necessarily converge when their sum does. As an example, in $\mathbb{R}$, take $k_i = (-1)^i$ and $c_i = (-1)^{i+1}$.  Then neither $\{k_n\}$ nor $\{c_n\}$ converge, but their sum does. Are there any suggestions on how to get around this problem and complete this more ""direct"" proof? Thanks!","['real-analysis', 'limits', 'general-topology', 'convergence-divergence', 'analysis']"
1861816,Find a positive integer solution to $xyzw=504(x^2+y^2+z^2+w^2)$,"Find positive integer values of $x,y,z,w$, such that $$xyzw=504(x^2+y^2+z^2+w^2)$$ I found it at some point and now I am unable to find the solution anymore, maybe this equation isn't satisfiable? But how do one prove such thing? Edit @Dashisan found nice example $(x,y,z,w)=(21,63,84,84)$. Now, the problem is if there  exists distinct positive integer solution.","['diophantine-equations', 'polynomials', 'number-theory', 'pell-type-equations', 'vieta-jumping']"
1861829,How to solve $\frac{\mathrm dy}{\mathrm dx}=\frac{x+y}{x}$,"I am looking for a help with the below equation $$\frac{\mathrm dy}{\mathrm dx}=\frac{x+y}{x}$$ I don't get the suggested answer $$y = x\ln(x) + c x$$ My attempt
$$\mathrm dx(1+\frac{y}{x})=\mathrm dy$$
$$c+x+y\ln(x)=y$$
$$y=\frac{c+x}{1-\ln x}$$","['ordinary-differential-equations', 'calculus']"
1861870,Solving $\frac{1}{2} < \cos \theta < \frac{\sqrt{3}}{2}$,"Find the values of theta which satisfy the given condition on a unit circle $$\frac{1}{2} < \cos \theta < \frac{\sqrt{3}}{2}$$ I'm able to plot the points and answer according to me should be $(2n\pi + \frac\pi6, 2n\pi + \frac\pi3)$ which turns out wrong according to my answer key","['inequality', 'trigonometry']"
1861887,Reference needed for Determinant of convex combination of two matrices as a function [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question What can one say about the function $(t,A,B) \mapsto \det(tA + (1-t)B)$, with $t \in [0,1]$, $A$, $B$ square matrices, in my case, say, permutational matrices? Where such a function shows up? Hoping for some references.","['representation-theory', 'reference-request', 'linear-algebra']"
1861958,$f_n \to f$ almost everywhere and $\int |f_n| \to \int |f|$ implies $\int |f_n - f| \to 0$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Suppose $f_n$ and $f$ are integrable, $f_n \to f$ almost everywhere, and $\int |f_n| \to \int |f|$. Does it necessarily follow that$$\int |f_n - f| \to 0?$$","['real-analysis', 'integration', 'measure-theory']"
1861985,$f$ is uniformly continuous only if $g$ is constant,"Let $g:\mathbb R\to\mathbb R$ be continuous and define $f:\mathbb R^2\to\mathbb R$ by $f(x_1,x_2)=g(x_1x_2)$. Show that $f$ is uniformly continuous only if $g$ is a constant function. I'm not sure whether the following is right. I don't use the continuity of $g$, so I guess something in the argument must be wrong.$\newcommand{\norm}[1]{\lVert#1\rVert}$ Proof . Suppose that $g$ is not constant. Then there exist $\gamma_0,\gamma_1\in\mathbb R$ such that $g(\gamma_0)\neq g(\gamma_1)$. Let $\{a_n:=(n,\gamma_0/n)\}_{n\in\mathbb N}$ and $\{b_n:=(n,\gamma_1/n)\}_{n\in\mathbb N}$ be sequences on $\mathbb R^2$. Then
    $$\norm{a_n-b_n}=\norm{\left(0,\frac{\gamma_0-\gamma_1}n\right)}\to\norm{(0,0)}=0$$
    as $n\to\infty$, but
    $$\norm{f(a_n)-f(b_n)}=\norm{g(\gamma_0)-g(\gamma_1)}$$
    is constant and non-zero. Therefore $f$ cannot be uniformly continuous.","['multivariable-calculus', 'uniform-continuity', 'proof-verification', 'limits']"
1861987,Intuition behind proof of bounded convergence theorem in Stein-Shakarchi,"Theorem 1.4 (Bounded convergence theorem) Suppose that $\{f_n\}$ is a sequence of measurable functions that are all bounded by $M$ , are supported on a set $E$ of finite measure, and $f_n(x) \to f(x)$ a.e. $x$ as $n \to \infty$ . Then $f$ is measurable, bounded, supported on $E$ for a.e. $x$ , and $$\int |f_n \to f| \to 0 \text{ as } n \to \infty.$$ Consequently, $$\int f_n \to \int f \text{ as } n \to \infty.$$ Proof. From the assumptions one sees at once that $f$ is bounded by $M$ almost everywhere and vanishes outside $E$ , except for possibly on a set of measure zero. Clearly, the triangle inequality for the integral implies that it suffices to prove that $\int |f_n  - f| \to 0$ as $n$ tends to infinity. The proof is a reprise of the argument in Lemma 1.2. Given $\epsilon > 0$ , we may find, by Egorov's theorem, a measurable subset $A_\epsilon$ of $E$ such that $m(E - A_\epsilon) \le \epsilon$ and $f_n \to f$ uniformly on $A_\epsilon$ . Then, we know that for all sufficiently large $n$ we have $|f_n(x) - f(x)| \le \epsilon$ for all $x \in A_\epsilon$ . Putting these facts together yields \begin{align*} \int |f_n - f(x)|\,dx & \le \int_{A_\epsilon} |f_n(x) - f(x)|\,dx + \int_{E - A_\epsilon} |f_n(x) - f(x)|\,dx \\ & \le \epsilon m(E) + 2M\,m(E - A_\epsilon)\end{align*} for all large $n$ . Since $\epsilon$ is arbitrary, the proof of the theorem is complete. $$\tag*{$\square$}$$ For reference, we include the statement of Lemma 1.2 here. Lemma 1.2 Let $f$ be a bounded function supported on a set $E$ of finite measure. If $\{\varphi_n\}_{n = 1}^\infty$ is any sequence of simple functions bounded by $M$ , supported on $E$ , and with $\varphi_n(x) \to f(x)$ for a.e. $x$ , then: (i) The limit $\lim_{n \to \infty} \int \varphi_n$ exists. (ii) If $f = 0$ a.e., then the limit $\lim_{n \to \infty} \int \varphi_n$ equals $0$ . My question is, could anybody supply me their intuitions behind the proof of the bounded convergence theorem here? What are the key steps I should distill the proof into as to be able to recreate it from scratch?","['measure-theory', 'real-analysis', 'lebesgue-integral', 'sequences-and-series']"
1861997,Is the polynomial $f(x) = x^4 + tx^3 + (t^2 + 1)x^2 + (t^3 + t)x + (t^4 + t^2)$ irreducible over $k(t)$?,Let $k$ be an algebraically closed field of characteristic 2 and let $k(t)$ be rational function field of one variable. Consider the polynomial $f(x) = x^4 + tx^3 + (t^2 + 1)x^2 + (t^3 + t)x + (t^4 + t^2) \in k(t)[x]$. Is $f(x)$ irreducible over $k(t)$?,"['irreducible-polynomials', 'galois-theory', 'polynomials', 'algebraic-geometry', 'field-theory']"
1862025,How to find $\tan x $ from $(a+1)\cos x + (a-1)\sin x=2a+1$?,How do I find $\tan x$ from this equation? $$(a+1)\cos x + (a-1)\sin x=2a+1$$ Thanks for any help!!,['trigonometry']
1862027,"$\lim_{z\to -1} (z+1) \sin(\frac{1}{z+1})$, for complex variable $z$.","I want to find this limit for complex variable $z$ $$\lim_{z\to -1} (z+1) \sin(\frac{1}{z+1})$$ In the real case I know $\sin(z)$ is bounded by $-1, 1,$ and the limit is $0$. But in the complex case $\sin(z)$ is not bounded. How can I find the limit or prove that it doesn't exist?","['complex-analysis', 'convergence-divergence', 'closed-form', 'limits']"
1862083,Find the values of $b$ for which the equation $2\log_{\frac{1}{25}}(bx+28)=-\log_5(12-4x-x^2)$ has only one solution,"Find the values of 'b' for which the equation $$2\log_{\frac{1}{25}}(bx+28)=-\log_5(12-4x-x^2)$$ has only one solution.
= $$-2/2\log_{5}(bx+28)=-\log_5(12-4x-x^2)$$ My try: After removing the logarithmic terms I get the quadratic $x^2+x(b+4)+16=0$ Putting discriminant equal to $0$ I get $b={4,-12}$ But $-12$ cannot be a solution as it makes $12-4x-x^2$ negative so I get $b=4$ as the only solution. But the answer given is $(-\infty,-14]\cup{4}\cup[14/3,\infty)$ .I've no idea how. Help me please.","['algebra-precalculus', 'logarithms', 'functions', 'quadratics']"
1862099,Show the triple integral given is equivalent to $\frac{15\pi}{16}$,"Evaluate $$\iiint_E\;z \, dV$$
where E is enclosed between the spheres $x^2 + y^2 + z^2 = 1$ and $x^2 + y^2 + z^2 = 4$ in the first octant. I'll be honest. My first attempt didn't worked very well. My answer showed for my first attempt was 7pi/12 because the integral I set up was like this: $$\iiint _E\;z\;dV\\
1\leq \rho\leq 2\\
0\leq\theta\leq \frac{1}{2}\pi\\
0\leq\phi\leq \frac{1}{2}\pi$$ Which transforms the integral into $$\int_{0}^{\frac{1}{2}\pi}\int_{0}^{\frac{1}{2}\pi}\int_{1}^{2}(\rho)^2 cos\phi\sin\phi\ d\rho\; d\theta \;d\phi\\$$ This problem was taken from Stewart Calculus 6th Edition. Like I said, I tried to solve this problem on my own and got an answer of $$\frac {7}{12}\pi$$ but when I browsed the answers section, it says its answer was $$\frac {15}{16}\pi$$ Did I do something wrong in my computation?","['multivariable-calculus', 'definite-integrals', 'spherical-coordinates', 'calculus']"
1862116,Bounding $\int_0^1 f(x) dx $ under the condition $\int_0^1 f'(x)^2 dx \le 1$,"Any tips on how to solve this? Problem 1.1.28 (Fa87) Let $S$ be the set of all real $C^1$ functions $f$ on $[0, 1]$ such that $f(0) = 0$ and $$\int_0^1 f'(x)^2 dx \le 1 \;. $$ Define $$J(f) = \int_0^1 f(x) dx \; .$$ Show that the function $J$ is bounded on $S$ , and compute its supremum. Is there a function $f_0 \in S$ at which $J$ attains its maximum value? If so, what is $f_0$ ? I tried using Cauchy-Schwartz and got a bound of $\frac23$ but it doesn't seem strong enough.","['functional-analysis', 'real-analysis', 'calculus']"
1862155,Zeros and poles of some meromorphic 1-forms on the riemann sphere,"Let $X=\mathbb C_{\infty}$ be the Riemann sphere with the local coordinates $\{z\ ,1/z\}$. I want to show the following two statements: i) There does not exist any non-vanishing holomorphic 1-form on $X$. ii) Where are the poles and zeros of the meromorphic 1-forms $dz$ and $d/z$? Also determine their orders. My attempt: i) Let $w$ be a non-vanishing 1-form on $X$. Then we can write $w=f(z)dz$ in the coordinate $z$ for a holomorphic function $f$. In the other chart we have then $w=f(\frac{1}{z})(-\frac{1}{z^2})d/z$. Now the laurent-series of $f$ around $0$ has only non-negative exponents, hence the above function has a pole in $0$, which is a contradiction to the assumption that $f$ is holomorphic. ii) For $w=1 dz$: $1$ has no zeros or poles in $\mathbb C$. Lets consider $\infty:$ In the other char we have $w=-1/z^2$ which has a pole of order two in zero, hence we have $ord_{\infty}w=-2$ and $ord_p(w)=0$ for $p\in\mathbb C$. For $w=dz/z$: $1/z$ has only a pole (of order $1$) in zero. In the other chart we have $w=-1/z$ which has also just a pole of order 1 in zero. Hence we have $ord_0(w)=-1$, $ord_{\infty}(w)=-1$ and $ord_p(w)=0$ otherwise. Since I am a beginner I would like if someone could check my solutions. 
Thanks in advance!:)","['general-topology', 'complex-analysis', 'real-analysis', 'riemann-surfaces']"
1862168,Is the error I noticed a harmless typo?,"Here http://arxiv.org/PS_cache/arxiv/pdf/1002/1002.0442v1.pdf , at page $2$ at the bottom, it is stated that the number of primes not exceeding $x$ , denoted by $\pi(x)$ , satisfies the double-inequality $$\frac{x}{\ln(x)}(1 + \frac{1}{\ln(x)} + \frac{2}{\ln^2(x)})\le \pi(x) \le \frac{x}{\ln(x)}(1 + \frac{1}{\ln(x)} + \frac{2.334}{\ln^2(x)})$$ for $x \ge 2\ 953\ 652\ 287$ However, the right inequality is false for $x = 2\ 953\ 652\ 287$ , but seems to be true for $x>2\ 953\ 652\ 287$ Is this a harmless typo or is the constant $2.334$ in the bounds wrong ? Can anyone approve that the above double inequality actually holds for $x > 2\ 953\ 652\ 287$ ?","['number-theory', 'reference-request', 'inequality', 'prime-numbers']"
1862170,Clarification on asymptotically stability of dynamical systems,"I'm wondering if someone can provide a clarification between 2 seemingly opposing definitions from reputable sources on dynamical systems! My Russian textbook, ""Dynamical Systems I: Ordinary Differential Equations and Smooth Dynamical Systems"" by Anosov, Arnol'd, Aronson, et al., says the following to determine whether a singular point of a dynamical system is asymptotically stable : Theorem 4.2: If all eigenvalues of the linear part of a vector field $v$ at a singular point have negative real part, then the singular point is asymptotically stable. To me, this means for any arbitrary dynamical system, say, $\dot{x} = f(x)$, where $x \in \mathbb{R}^{n}$, one can find where $f(x) = 0$, and solve the corresponding Jacobian for the eigenvalues of to determine stability. Further, if one finds that $\lambda_{i} < 0$, for $i = 1,2,...n$ then, this point is locally stable, by this theorem.  But, is this theorem now suggesting that this is point is now asymptotically stable as well? Almost every single textbook on ODEs that I have checked says to determine whether an equilibrium point is asymptotically stable, some more general method is required like constructing Lyapunov functions, determining limit sets, etc... Why is there such a difference? Is there a difference?","['stability-in-odes', 'ordinary-differential-equations', 'dynamical-systems']"
1862181,Linear separability / Number of positive solutions of a random linear system,"This one is on linear separability of cyclic patterns. The shorter geometric version: Take a ring of length $p$ of  randomly assigned mean-free binary values $x_i = \pm 1$, $i = 1 \cdots p$. Cyclically, form $p$ vectors $V_i$ of length $n$ with components $V_{i,j} = x_i \, x_{((j+i)\bmod p)}$, $j = 1 \cdots n$. For large $p$, what is the smallest $n^* = n^*(p)$ such that all of these $p$ vectors $V_i$ lie in a halfspace? This is to be understood with probabilty at least one half, when averaged over all rings. The longer algebraic version: Consider $p$ many binary values $x_i = \pm 1$, $i = 1 \cdots p$. Consider all choices of the sets {$x_i$}  with the ""mean-free"" condition $\sum_{i=1}^p x_i = 0$, i.e. there  are $p \choose p/2$ many ways to choose the sets of  {$x_i$}. Let $\Theta(q)$ be the indicator function which is $\Theta(q) = 1$ if $q > 0$,  $\Theta(q) = 0$ if $q \leq 0$. Let $n < p$. Consider $n$ many real values $w_j$, $j = 1 \cdots n$. For a given  choice of  {$x_i$}, one would like to find values {$w_j$}, such that $f = 1$ in
$$
f (\left\{ x_i  \right\} ) =  \max_{\{ w_j \}} \prod_{i=1}^p \Theta {\Large\{ }\sum_{j=1}^n w_j \; x_i \, x_{((j+i)\bmod p)} {\Large\} }
$$ In other words, all of the $p$ many linear expressions (for $i = 1 \cdots p$)
$$
\tag{1} \sum_{j=1}^n w_j \; x_i \, x_{((j+i)\bmod p)}
$$ for that choice of  {$x_i$} shall be positive, then $f =1$. Now we ask about the capacity, i.e. the smallest number $n^*$ for which 
$$
g(p,n) = \frac{1}{p \choose p/2}
\sum_{ \left\{ x_i  \right\} }  f (\left\{ x_i  \right\} ) \geq \frac12
$$ The counting function $g(p,n)$ counts the fraction of all sets of  {$x_i$} for which the above linear expressions [1] can be made positive, and we want that to be the case for at least half of all the choices of the sets of  {$x_i$}. For large $p$, what is $n^* = n^*(p)$? Remarks: The relation $n^* = n^*(p)$ will be linear. It is clear that $n^* < p$ since if $n^*=p$,  the above linear expressions [1] would be $p$ expressions in $p$ unknowns {$w_j$}, which could be  solved for {$w_j$} simply by equating all expressions to $1$, say. Large-scale numerical evidence indicates $n^* = p / (1.70 \pm 0.02)$ (Martin Schroeder). If the random variables in the linear expressions [1] would not have the ""ring"" structure (note the ""mod"" in the index), but instead if one would select  $n \times p$ many mean-free variables  $x_{j, i}$ and demand that the $p$ many expressions $\sum_{j=1}^n w_j \; x_{j, i}$ be positive, then $n^* = p / 2$ (Thomas Cover) (the famous function counting theorem).","['combinatorics', 'inequality', 'linear-algebra', 'algebraic-geometry']"
1862189,How to find area of a polygon built on the roots of a given polynomial?,"How to find the area of a (maximum area convex) polygon, built on the roots of a given polynomial in the complex plane? For example, consider the equation: $$2x^5+3x^3-x+1=0$$ It has one real and four complex roots and makes a nice convex pentagon in the complex plane (thanks, Wolfram Alpha): Using the formula for the area of a convex polygon: $$A=\frac{1}{2} \left( \begin{array}| x_1 & x_2 \\ y_1 & y_2 \end{array} + \begin{array}| x_2 & x_3 \\ y_2 & y_3 \end{array} + \dots +  \begin{array}| x_n & x_1 \\ y_n & y_1 \end{array} \right)$$ I obtained for this case (using numerical values of the roots): $$A=1.460144\dots$$ Another simple case - roots of unity. They just make regular polygons and the general formula for the area is well known. However, I would like to know if it's possible to find out this area without computing the roots, using only the coefficients of the polynomial? (The coefficients are meant to be rational). I know that polynomials with only real roots will all have $A=0$ , and for the polynomials with several real roots some of them will be inside our maximum area polygon. There is a useful theorem (see Rouche's theorem ), according to which: For a monic polynomial $$z^n+a_{n-1} z^{n-1}+\dots+a_1 z+a_0$$ All its roots will be located inside the circle $|z|=1+\max |a_k|$ . But this theorem gives relatively large area, and can't be used to approximate the area of the polygon.","['complex-analysis', 'polynomials']"
1862235,"Find the limit of $\lim\limits_{(x,y)\to (0,0)} \frac{x^2y^2}{x^2y^2+(x-y)^2}$","Find the limit of $$\lim\limits_{(x,y)\to (0,0)} \frac{x^2y^2}{x^2y^2+(x-y)^2}$$ So, I know that $$\lim\limits_{x \to x_0} f(x)=c \Leftrightarrow \forall (x_n)\subseteq D\setminus\{x_0\}, x_n\to x_0: f(x_n)\to c \, (n\to \infty)$$ Let $x_n=\left(\frac{1}{n},\frac{1}{n}\right), y_n=\left(\frac{1}{n},0\right):$
$$f(x_n)=\frac{\frac{1}{n}^4}{\frac{1}{n}^4}=1\\
f(y_n)=\frac{0}{...}=0\\
\Rightarrow f(x_n)\neq f(y_n)\, (n\to \infty)$$ So the limit doesn't exist. Correct?","['multivariable-calculus', 'real-analysis', 'calculus', 'limits']"
1862264,Integral of the product $x^n e^x$,"I would be very pleased if you could give me your opinion about this way of integrating the following expression. I think that it has no issues, but just wanted to confirm: $$ \int x^n e^x dx $$
$$ e^x = u $$
$$ e^x dx = du $$
$$ \int x^n e^x dx = \int \ln(u)^n du = nu(\ln(u) - 1) + C $$
$$ \int x^n e^xdx = ne^x (x-1) + C $$ Many thanks!","['integration', 'calculus']"
1862278,Combining Column- and Row-wise meanings of a matrix,A matrix can be thought of in terms of columns (then it represents the basis vectors of an coordinate system) or in terms of rows (then it represents a set of linear equations). How can we combine those two views? Example: Let the matrix $A$ represent a set of linear equations. Then each row is a linear equation. But we can also see the matrix as the basis vectors of a coordinate system. What coordinate system does matrix $A$ represent? What is the link between the column-wise and row-wise viewpoints on matrix?,"['matrices', 'linear-algebra']"
1862326,$\lim_{n \to \infty} \mid a_n + 3(\frac{n-2}{n})^n \mid^{\frac1n} = \frac35$. Then find $\lim_{n \to \infty} a_n$. [duplicate],"This question already has answers here : What is the value of lim$_{n\to \infty} a_n$ if $\lim_{n \to \infty}\left|a_n+ 3\left(\frac{n-2}{n}\right)^n \right|^{\frac{1}{n}}=\frac{3}{5}$? (3 answers) Closed 7 years ago . Let $\{a_n\}$ be a sequence of real numbers such that
$$\lim_{n \to \infty} \mid a_n + 3(\frac{n-2}{n})^n \mid^{\frac1n} = \frac35$$ Then find  $\lim_{n \to \infty} a_n$. Tried very hard yet not able to crack it. Help Needed. Anyone able to do the sum??","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
1862340,What are the hyperbolic rotation matrices in 3 and 4 dimensions?,"So the hyperbola-preserving transformation in 2 dimensional space is given by the matrix 
\begin{pmatrix}
\cosh(\phi) & \sinh(\phi) \\
\sinh(\phi) & \cosh(\phi) \end{pmatrix} I'm wondering what such a matrix would be in 3 dimensional space (so that it preserves 2 dimensional hyperboloids) and 4 dimensional space (so that it preserves 3 dimensional hyperboloids). Sources or derivations would be appreciated. Thank you!","['matrices', 'hyperbolic-geometry']"
1862343,(Non-)Canonicity of using zeta function to assign values to divergent series [duplicate],"This question already has an answer here : Can different choices of regulator assign different values to the same divergent series? (1 answer) Closed 6 years ago . This article http://blogs.scientificamerican.com/roots-of-unity/does-123-really-equal-112/ got me thinking about the ""identity"" $$1 + 2 + 3 + \cdots = -1/12,$$ and I wanted to convince myself there was nothing particularly unique about this identity or the Riemann zeta construction. More precisely, this identity only really makes sense if you think of an integer $n$ as being the specialization at $z=-1$ of the function $n^{-z}$. So here's a question: For any complex number $c$, does there exist a domain $\Omega \subset \mathbb{C}$, and analytic functions $F(n, s)_{n\in\mathbb{N}}$ and $f(s)$ on $\Omega$, such that the following hold i. $F(n,0) = n$ ii. $\sum_{n=1}^\infty F(n,s) = f(s)$ on $\Omega$ in some reasonable sense (maybe converges uniformly on compact subsets of $\Omega$?) iii. $f$ can be extended holomorphically to some domain containing both $\Omega$ and $0$ such that $f(0) = c$. So shifting the Euler series and Riemann zeta would be such a construction for $c=-1/12$. As the question stands, I feel that the answer is almost certainly yes, although to be fair the functions $n^{-s}$ have a lot more structure than ""holomorphic functions on some domain"". So a follow-up question would be: are there ""natural"" additional constraints for which the answer to this question is No ? I apologize that this is kind of open-ended, but the goal is to convince myself that there is nothing particularly canonical about $-1/12$ (or to hear an explanation of why it is canonical).","['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
1862372,Analytic continuation of $\sum (z/a)^n$,"I'm having trouble continuing this function beyond its convergence radius, $R=a$. $$f(z)=\sum (z/a)^n$$ Given the context (a textbook in complex analysis) I suspect it should have a simple closed-form expression. I've tried differentiating and trying to relate it to the geomtric series, but so far I haven't had any success. Any hint or idea on how to analytic continuate it? Thanks in advance!","['complex-analysis', 'analytic-continuation', 'power-series']"
1862399,Trouble finding the inverse of $f(x) = x + \frac{1}{x}$ .,"Let $ f: \Bbb R - \{0\} \rightarrow \Bbb R \;\text{ given by } f(x) = x + \frac{1}{x} . \text{Find} $ $f(f^{-1}(\Bbb R))$ , $\Bbb R = \text{real numbers}$. For this problem I know one needs to find the inverse in order to solve. $ y = x+ \frac{1}{x} \Rightarrow y^2 = \left( x+\frac{1}{x} \right)^{2}$ $y^2 = x^2+2 + \frac{1}{x^2}  $ one should arrive at the conclusion. $$f(x)^{-1} = \frac{x \pm \sqrt{x^2-4} }{2}$$ Yet I am having trouble at arriving at that conclusion. Could anyone show me how to do it arithmetically.","['elementary-set-theory', 'functions']"
1862444,"$\{f_n\}$ is uniformly integrable if and only if $\sup_n \int |f_n|\,d\mu < \infty$ and $\{f_n\}$ is uniformly absolutely continuous?","Let $(X, \mathcal{A}, \mu)$ be a measure space. A family of measurable functions $\{f_n\}$ is uniformly integrable if given $\epsilon$ there exists $M$ such that$$\int_{\{x : |f_n(x)| > M\}} |f_n(x)|\,d\mu < \epsilon$$for each $n$. The sequence is uniformly absolutely continuous if given $\epsilon$ there exists $\delta$ such that$$\left|\int_A f_n\,d\mu\right| < \epsilon$$for each $n$ if $\mu(A) < \delta$. Suppose $\mu$ is a finite measure. How do I see that $\{f_n\}$ is uniformly integrable if and only if $\sup_n \int |f_n|\,d\mu < \infty$ and $\{f_n\}$ is uniformly absolutely continuous?","['real-analysis', 'probability-theory', 'integration', 'measure-theory', 'sequences-and-series']"
1862449,"Do we necessarily have that $\int g\,d\mu_n \to \int_0^1 g\,dx$?","Let $\mathcal{B}$ be the Borel $\sigma$-algebra on $[0, 1]$. Suppose $\mu_n$ are finite measures on $([0, 1], \mathcal{B})$ such that $\int f\,d\mu_n \to \int_0^1 f\,dx$ whenever $f$ is a real-valued continuous function on $[0, 1]$. Suppose that $g$ is a bounded measurable function such that the set of discontinuities of $g$ has measure $0$. Do we have that$$\int g\,d\mu_n \to \int_0^1 g\,dx?$$","['real-analysis', 'probability-theory', 'integration', 'lebesgue-integral', 'measure-theory']"
1862469,"Can the second derivative of a function be interpreted as the slope of its ""concavity lines""?","Can the second derivative of a function be interpreted as the slope of its ""concavity lines""? For example consider the following picture: Does $f''$ for each point $x$ that corresponds to an arrow being drawn (for which there are $9$ in the picature) itself correspond to the slope of the line that would be obtained by extending its concavity arrow into a line?",['derivatives']
1862474,Why aren't these two versions of a two-sample t-test the same?,"I'm looking at two versions of a two-sample t-test that appear equivalent to me -- but when I crunch the numbers they don't seem to actually be equivalent. Consider the model $$\mathbf y = \beta_0 + \beta_1  \mathbf x$$ where $\mathbf x$ is a binary vector. So, for example, where $0$ indicates ""female"" and $1$ ""male"", we would have that $\beta_0$ is the mean response for females, and $\beta_1$ is the mean response for males minus that for females. We assume independent Gaussian errors. So, we can test whether males and females have different means as follows: 
$$ \frac{\widehat\beta_1} {\mathrm{se}(\widehat\beta_1)} \sim t_{n-2} $$ Similary, we can consider the sample means of each of male and female: $\bar y_B$ and $\bar y_G$. These are normal random variables with sample variances respectively $\frac{s^2_B}{n_B}$ and $\frac{s^2_G}{n_G}$. Therefore 
$$ \bar y_B-\bar y_G\sim N\left(\mu_B-\mu_G,\frac{s^2_B}{n_B}+\frac{s^2_G}{n_G}\right)$$
And so under the hypothesis that $\mu_B=\mu_G$, we can test whether males and females have the same mean as follows:
$$
\frac{\bar y_B-\bar y_G}{\sqrt{\frac{s^2_B}{n_B}+\frac{s^2_G}{n_G} } } \sim t_{n-2}
$$
This is testing the same thing as the earlier test, and should be equivalent. I have already proven the numerators are equivalent -- that is, $\widehat\beta_1 = \bar y_B-\bar y_G$. But I cannot prove the denominators equivalent, and in fact when I try calculating the denominators for some test cases in R, I do not get the same values. Is something about my above thinking incorrect? If not, any pointers for how to prove the denominators of these two t-statistics equivalent?","['statistics', 'sampling']"
1862484,"What does ""Borel space"", unqualified, refer to?","For examples of use, Google ""in Borel space"", with the quotes. (Although, at the moment, I'm getting this very question as the top result.) I'm thinking it means either ℝ equipped with its Borel σ-algebra, or to Borel spaces in general (that is, topological spaces with a σ-algebra generated through complements and countable unions of open sets). I've been given to understand that many Borel spaces are isomorphic to each other, but not in what sense they're isomorphic.","['terminology', 'measure-theory']"
1862529,"Is one of $k+1^2,$ $k+2^2,$ ..., $k+N^2$ always prime?","I know that the Bunyakovsky conjecture is still open, so we can't prove that there exist primes of the form $n^2+k$ for a given $k$. But suppose that they do: is the least $n$ such that $n^2+k$ is prime bounded? This seems crazy, but I can't disprove it. More formally: Is there an integer $N$ such that, for all positive integers $k$, either there are no primes of the form $n^2+k$ or one of $k+1^2, k+2^2,\ldots k+N^2$ is prime? (Note that $x^2+k$ is irreducible unless $k=-m^2$ for some integer $m$.)","['number-theory', 'prime-numbers']"
