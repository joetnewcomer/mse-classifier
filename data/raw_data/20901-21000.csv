question_id,title,body,tags
176851,Number of combinations of sets over a function.,"Does anyone know if the following question has been solved in general or has any insight in the question. Let us take for example the sets {0,1} and {1,2} and function multiplication (*) over the sets shall be denoted as *(0,1)=0*1=0. We now want to know the size of the set that can be derived from multiplication over all combinations of such sets. For example: {*(0,0), *(0,1), *(1,0), *(1,1)} = {0,1} where as {*(1,1), *(1,2), *(2,1), *(2,2)} = {1,2,4} This is a simple example but generalisations to combinations of the alphabet larger than two should be progressively more difficult to keep track of.","['elementary-number-theory', 'group-theory', 'functions', 'combinatorics']"
176858,Asymptotic behavior of iterative sequences,"Suppose you have a sequence
$$
a_1<a_2<\cdots
$$
with
$$
a_{n+1}=a_n+f(a_n)
$$
where $f$ is a sufficiently nice nondecreasing function. What can be determined about the asymptotic behavior of $a_n$? For example, suppose $f(x)=\log x+O(1)$ with $f(a_1)>0$. Can we conclude that $a_n\sim Cn\log n$ for some $C$?","['sequences-and-series', 'real-analysis']"
176860,Variance of a max function,"Say $x_1$ and $x_2$ are normal random variables with known means and standard deviations and $C$ is a constant. If $y = \max(x_1,x_2,C)$, what is $\mathrm{Var}(y)$? Well, I forgot to tell that $x_1$ and $x_2$ are independent.","['statistics', 'standard-deviation']"
176889,For which angles we know the $\sin$ value algebraically (exact)?,For example: $\sin(15^\circ) = \frac{\sqrt{6}}{4} - \frac{\sqrt{2}}{4}$ $\sin(18^\circ) = \frac{\sqrt{5}}{4} - \frac{1}{4}$ $\sin(30^\circ) = \frac{1}{2}$ $\sin(45^\circ) = \frac{1}{\sqrt{2}}$ $\sin(67 \frac{1}{2}^\circ) = \sqrt{ \frac{\sqrt{2}}{4} + \frac{1}{2} }$ $\sin(72^\circ) = \sqrt{ \frac{\sqrt{5}}{8} + \frac{5}{8} }$ $\sin(75^\circ) = \frac{\sqrt{6}}{4} + \frac{\sqrt{2}}{4}$ ? Is there is a list of known exact values of $\boldsymbol \sin$ somewhere? Found a related post here .,['trigonometry']
176892,Prove trigonometry identity for $\cos A+\cos B+\cos C$,"I humbly ask for help in the following problem. If 
\begin{equation}
A+B+C=180
\end{equation}
Then prove
\begin{equation}
\cos A+\cos B+\cos C=1+4\sin(A/2)\sin(B/2)\sin(C/2)
\end{equation}
How would I begin the problem I mean I think $\cos C $ can be $\cos(180-A+B)$. But I am unsure what to do next.",['trigonometry']
176901,A trigonometry equation problem,"Let $a,b \in \left(0,\frac{\pi}{2}\right)$, satisfying
$$
\frac{1-\cos{2a}}{1+\sin{a}}+\frac{1+\cos{2a}}{1+\cos{b}}=\frac{1-\cos{(2a+2b)}}{1+\sin{(a+2b)}}
$$
Prove that:
$$
a+b=\frac{\pi}{2}
$$",['trigonometry']
176930,"Show the result of the following infinite sum, based on a binomial random variable conditioned on a Poisson random variable","$$\sum_{n=0}^\infty \binom{n}{k}p^k(1-p)^{n-k}\frac{\lambda^ne^{-\lambda}}{n!} = \frac{(\lambda p)^ke^{-\lambda p}}{k!}$$ That is, given a random variable $X$ with Poisson distribution $X \sim \operatorname{Poisson}(\lambda)$, and, given $X = n$, random variable $Y$ is distributed by a binomial such that $Y \sim B(n,p): p \in [0,1]$. Given $n$, $P(Y = k|X = n) = \binom{n}{k}p^k(1-p)^{n-k}$. Given $\lambda$, $P(X=n) = \dfrac{\lambda^ne^{-\lambda}}{n!}$. Therefore, $P(Y = k|\lambda) = \sum_{n=0}^\infty P(Y = k | X = n)P(X = n | \lambda) = \sum_{n=0}^\infty \binom{n}{k}p^k(1-p)^{n-k}\dfrac{\lambda^ne^{-\lambda}}{n!}$. What properties and identities can be used to demonstrate the equality above?","['probability-theory', 'probability-distributions', 'sequences-and-series', 'probability']"
176937,Prerequisite reading before studying the Collatz $3x+1$ Problem,"Let's assume I am starting college and have just finished calculus.  I've been reading a bit online about the Collatz $3x+1$ Problem and find it to be very intriguing.  However, a lot of what I'm reading uses terms and techniques that I have not seen before.  I'm wondering what prerequisite (text book) reading is required before starting to study this problem? Put another way: I'm thinking about reading The Ultimate Challenge: The 3x+1 Problem by Jeffrey C. Lagarias.  What areas of mathematics will I need to understand first before being able to fully understand this book?","['collatz-conjecture', 'number-theory']"
176956,Why need two directions to make $\sim_{\rm wa}$ an equivalence relation?,"Let $\pi$ and $\sigma$ be representations of a $C^*$-algebra $\mathcal{A}$. They are weak approximately equivalent ($\pi\mathbin{\sim_{\rm wa}}\sigma$) if there are sequences of unitary operators $\{U_n\}$ and $\{V_n\}$ such that \begin{equation}
\sigma(A)=\operatorname{WOT-lim} U_n\pi(A) U_n^*, 
\end{equation} \begin{equation}
\pi(A)=\operatorname{WOT-lim} V_n\sigma(A) V_n^*
\end{equation} for all $A\in\mathcal{A}$. Many books point out that both directions are needed to obtain an equivalence relation but no clue is given why. Since for approximate equivalence ($\mathbin{\sim_{\rm a}}$), only one direction is needed, I wonder why for $\mathbin{\sim_{\rm wa}}$ we need two. Thanks!","['c-star-algebras', 'representation-theory', 'functional-analysis']"
176957,Flat sheaves over a non-flat base $X \rightarrow Y$,"I have a relatively naive question. Suppose that $f: X \rightarrow Y$ is a map of schemes. Then, we get a map of local rings $\mathcal{O}_{Y,f(x)} \rightarrow \mathcal{O}_{X,x}$ and thus for any sheaf $F$ on $X$ we can say that $F$ is flat over $Y$ if the stalk $F_x$ is flat as a $\mathcal{O}_{Y,f(x)}$-module. This notion is important, for example, because it is a prerequisite for applying many theorems of the form ""If $F$ is flat over $Y$ and (hypothesis) then $f_*F$ is locally free on $Y$"". I would like an example of a sheaf $F$ which is flat on $X$ and still flat over $Y$ when $f$ is not flat, if such an example exists. If no such example exists, why not? Bonus points if addressing the specific situation where $f$ is proper and birational (e.g. $X$ is a blow-up of $Y$). Notice that if $G$ is locally free on $Y$ then $F = f^*G$ will be locally free on $X$ but will be flat over $Y$ if only if $f$ is flat so an example will not arise this way.","['modules', 'commutative-algebra', 'algebraic-geometry']"
176967,Distribution function and $L^p$ spaces.,"I saw the result below without a proof and I would like to see it. Result: Let $g$ a nonnegative and measurable function in $\Omega$ and $\mu_{g} $ its distribuction function, i.e.,
  \begin{equation}
\mu_{g}(t)= |\{x\in \Omega : g(x)>t\}|, t>0.
\end{equation}
  Let $\eta>0$ and $M>1$ be constants. Then, for $0<p<\infty,$
  \begin{equation}
g \in L^{p}(\Omega) \Leftrightarrow \sum_{k\ge 1} M^{pk} \mu_{g}(\eta M^k) = S < \infty.  
\end{equation}","['measure-theory', 'analysis']"
176972,Is there a Cantor-Schroder-Bernstein statement about surjective maps?,"Let $A,B$ be two sets. The Cantor-Schroder-Bernstein states that if there is an injection $f\colon A\to B$ and an injection $g\colon B\to A$, then there exists a bijection $h\colon A\to B$. I was wondering whether the following statements are true (maybe by using the AC if necessary): Suppose $f \colon A\to B$ and $g\colon B\to A$ are both surjective, does this imply that there is a bijection between $A$ and $B$. Suppose either $f\colon A\to B$ or $g\colon  A\to B$ is surjective and the other one injective, does this imply that there is a bijection between $A$ and $B$.","['set-theory', 'functions', 'axiom-of-choice']"
176982,basic question on integral schemes,"If $X$ is a (reduced) scheme and $P$ is a point of $X$ (not necessarily closed) such that the local ring $\mathcal{O}_{X,P}$ is a regular domain, then must there exist an open affine neighborhood $U = \text{Spec }A$ of $P$ such that $A$ is an integral domain? I'm almost certain this is true, since the local ring being regular means that it doesn't sit in the intersection of irreducible components, and hence it must be ""locally"" irreducible...but I can't think how to prove it. If needed, we can assume $X$ is also Noetherian.","['commutative-algebra', 'algebraic-geometry']"
176986,Is there a way to exploit the fact that the covariance matrix has a  blocked structure to more easily compute the multivariate normal density?,"I'm trying to minimize the (negative) multivariate normal log likelihood (dropping constants): $$
\log |\boldsymbol\Sigma|\,+(\mathbf{x}-\boldsymbol\mu)^{\rm T}\boldsymbol\Sigma^{-1}(\mathbf{x}-\boldsymbol\mu)$$ where $$ \Sigma_{ij} = \sigma_1 \cdot \mathcal{I}\{i = j \} + \sigma_2 \cdot \mathcal{I}\{ L_i = L_j \} + \sigma_3 \cdot f(||L_i - L_j||)$$ as a function of $\{ \sigma_1, \sigma_2, \sigma_3, {\boldsymbol \mu} \}$. The $L_i$ are known values - in the context of the problem it is the ""location"" of unit $i$. The function $f(\cdot)$ is a known monotonically decreasing function. $\mathcal{I}(\cdot)$ is an indicator function and $|| \cdot ||$ is a distance measure (say, euclidean distance). Each of the $\sigma_i$ parameters are positive so that $\Sigma$ is certainly positive definite. In this problem the dimension of $\Sigma$ is very large, say $1000 \times 1000$, so naively evaluating the log-likelihood is relatively computationally expensive ($\approx$ 2 seconds per evaluation). I'm thinking that, since $\Sigma$ has this blocked structure, there may be some way exploit this fact to significantly speed up computation, but I'm having some trouble figuring how/if this will work. Any tips are appreciated. Update: I can see that $\Sigma$ can be written as $$ \Sigma = \sigma_1 {\bf I}+ {\bf C} \otimes {\bf 1} $$ where ${\bf 1}$ is a matrix of $1$s, ${\bf I}$ is the identity, $\otimes$ denotes the Kronecker product, and ${\bf C}$ is an $N \times N$ matrix, where $N$ is the number of ""locations"" and has the structure $$ {\bf C}_{nm} = \sigma_2 \cdot \mathcal{I} \{ n = m \} + \sigma_3 \cdot f( \delta_{nm} )$$ where $\delta_{nm}$ denotes the distance between location $n$ and $m$. Still not quite sure this helps me a ton. Will be back with more updates perhaps.","['statistics', 'matrices', 'normal-distribution', 'numerical-linear-algebra', 'block-matrices']"
176998,"Solving $5^n > 4,000,000$ without a calculator","If $n$ is an integer and $5^n > 4,000,000.$ What is the least possible value of $n$? (answer: $10$) How could I find the value of $n$ without using a calculator ?",['algebra-precalculus']
177005,Question about Angle-Preserving Operators,"This an exercise out of Spivak's "" Calculus on Manifolds "". Edit:  There was a typo in the exercise as is noted below in the answers.  The statement has been edited to reflect this. Given $x,y\in\mathbb{R}^{n}$, the angle between $x$ and $y$ is defined by $$\angle(x,y) = \arccos\left(\frac{\langle x,y \rangle}{|x|\cdot |y|}\right),$$ where $\langle x,y \rangle$ denotes the standard Euclidean inner product. A linear operator $T:\mathbb{R}^{n}\to\mathbb{R}^{n}$ is said to be angle-preserving if
$\angle(T(x),T(y)) = \angle(x,y)$ for every $x,y\in\mathbb{R}^{n}$. The exercise as stated: Let $\{x_{1},\dots, x_{n}\}$ be a basis for $\mathbb{R}^{n}$.  Then suppose that $\lambda_{1}, \dots, \lambda_{n}\in \mathbb{R}$ are such that $Tx_{j} = \lambda_{j}x_{j}$ for each $j = 1,\dots, n$. Then $T$ is angle-preserving only if (not if and only if!)$|\lambda_{i}| = |\lambda_{j}|$ for every $1\leq i\leq j\leq n$. I'm having problems with the $(\Rightarrow)$ direction. My best attempt (which seems to lead nowhere) is to suppose that $|\lambda_{j}|\neq |\lambda_{k}|$.  Then by assumption,
\begin{align*}
\angle(Tx_{j},Tx_{k}) & = \arccos\left(\frac{\langle Tx_{j},Tx_{k} \rangle}{|Tx_{j}|\cdot |Tx_{k}|}\right)\\
& = \arccos\left(\frac{\langle \lambda_{j}{x_{j}},\lambda_{k}{x_{k}} \rangle}{|\lambda_{j}{x_{j}}|\cdot |\lambda_{k}{x_{k}}|}\right)\\
& = \arccos\left(\frac{\lambda_{j}\lambda_{k}\langle {x_{j}},{x_{k}} \rangle}{|\lambda_{j}|\cdot|\lambda_{k}|\cdot|{x_{j}}|\cdot |{x_{k}}|}\right)\\
& = \arccos\left(\text{sign}(\lambda_{j})\text{sign}(\lambda_{k})\frac{\langle {x_{j}},{x_{k}} \rangle }{|{x_{j}}|\cdot |{x_{k}}|}\right)\\
\end{align*}
may also be calculated as
\begin{align*}
\angle(Tx_{j},Tx_{k}) & =  \angle(x_{j},x_{k})\\
& = \arccos\left(\frac{\langle x_{j},x_{k} \rangle}{|x_{j}|\cdot |x_{k}|}\right).
\end{align*} Then since $\arccos$ is injective, I believe I can make the jump that $\text{sign}(\lambda_{j})\text{sign}(\lambda_{k}) = 1$, which does not resemble the conclusion that I should arrive at. Note:  I wasn't sure what tag to put this under, so anyone who knows better please feel free to adjust. Thanks for any help you can give.","['operator-theory', 'differential-geometry']"
177010,I want to prove $ \int_0^\infty \frac{e^{-x}}{x} dx = \infty $,How can I prove this integral diverges? $$ \int_0^\infty \frac{e^{-x}}{x} dx = \infty $$,"['calculus', 'integration']"
177021,Constructing a local nested base at a point in a first-countable space,"I am trying to prove the following: Let $X$ be a first countable space and $x$ a member of $X$.  Prove that there is a local nested basis $\{S_n\}_{n=1}^\infty$ at $x$. Since $X$ is first countable there is a countable local base  $\mathcal{B}_x$ at $x$.  Constructing a nested sequence of subsets of $\mathcal{B}_x$ is easy.  Let $B_1 \in \mathcal{B}_x$.  Then $B_1$ is an open set containing $x$, and so contains a member $B_2$ of $\mathcal{B}_x$ by the definition of a local base.  Then $B_2$ is an open set containing $x$ and so contains a member $B_3$ of $\mathcal{B}_x$.  Continuing in this fashion we obtain a nested sequence $\{B_n\}_{n=1}^\infty$ of members of $\mathcal{B}_x$ containing $x$. I'm having trouble showing that this is a local base, in that I don't see how to prove that every open set in X contains some member of this sequence.  Of course it's possible that this isn't true, and there's a different way to construct the nested sequence so that this can be done, but I'm having trouble with this as well. Which way do I need to proceed, and how do we complete the proof?  Thanks.",['general-topology']
177045,The orientation of quotient manifold,"If $T$ is a torus and $\mathbb Z_2$ acts on it by $(z_1,z_2)\rightarrow(z^{-1}_1,-z_2)$, then is $T/\mathbb Z_2$ orientable?","['algebraic-topology', 'differential-geometry']"
177053,Formalizing the shift operator,"I hope you can help me formalize some things about the shift operator.
So let $(\theta _{n})_{n\geq0}$ be the shift operator - that is $\theta _{n}\omega(k)=\omega(k+n)$.
I'm using the Durrett setup where $X_n=\omega_n$ which makes $X_n\circ\theta_k=X_{n+k}$, obviously (I hope). Now let $T_A=\inf\{n\gt0|X_n\in A\}$ be the hitting time of $A$, one would expect $T_A\circ\theta_n$ to be ""n times"" after $X_n$ hits $A$. How do I show it? And how do I show it's even a stopping time? (that might follow from the answer to the first question I guess). Now let $\mathcal{F}_n =\sigma(\{X_k|0\le k \le n\})$ one would then expect that $\theta_k^{-1}(\mathcal{F}_n)\subseteq\mathcal{F}_{n+k}$ but how do I show that? (I know I can ""exchange function and sigma"", but I guess I'm not sure what the preimage of a function by the shift operator is, formally). Let me know if I haven't been precise enough with my questions or given enough information. Best regards, Edit:
Thanks David. I think you made a minor error (but helped me do it right) since: $$ T_{A} \circ \theta_{k}\left(\omega\right)=\inf\left\{ m>0\,|\, X_{m}\circ\theta_{k}\left(\omega\right)\in A\right\} \\=\inf\left\{ m>0\,|\, X_{m+k}\left(\omega\right)\in A\right\} \\=\inf\left\{ n>k\,|\, X_{n}\left(\omega\right)\in A\right\} -k$$ - one really has to be careful when substituting i guess. Question update:
Is it possible to get for a general stopping time $S$ that $S\circ\theta_{n}$ is a stopping time - actually I more specifically would like an argument that gives $\{S\circ \theta _k = n-k \}\in\mathcal{F}_n$",['probability-theory']
177062,Differentiation continuous iff domain is finite dimensional,"Let $A\subset C([0,1])$ a closed linear subspace with respect to the usual supremum norm satisfying $A\subset C^1([0,1])$. Is $D\colon A\rightarrow C([0,1]), \ f\rightarrow f'$ continuous iff $A$ is finite dimensional? If $A$ is finite dimensional $D$ is continuous of course. But is the other implication true at all? Wouldn't something like $A:=\overline{\text{span}\{\sin{\left(t+\frac{1}{n}\right)} \ | \ n\in\mathbb{N}\}}$ be a counterexample?","['vector-spaces', 'functional-analysis', 'real-analysis']"
177064,Quaternions and Rotations,"Two of the interesting achievements in Mathematics are Classification of platonic solids, and also classification of finite groups acting on the unit sphere in $\mathbb{R}^3$, and they are very nicely connected to each other. These objects also enter in the classification of finite subgroups of $GL(2,\mathbb{R}), GL(3,\mathbb{R})$. When studying these groups with geometry, I visited their classification by various ways: by solving some Diophantine equations, and also using geometry of complex numbers; in particular multiplication by complex numbers. Some finte subgroups of $GL(3,\mathbb{R})$ can be obtained from a multiplication in quaternions $\mathbb{H}$ by unit quaternions, and these are connected with rotations in $\mathbb{R}^3$; for a pure quaternion $a$, and unit quaternion $q$, the map $a\mapsto qaq^{*}$ is a rotation of $\mathbb{R}^3$, where $\mathbb{R}^3$ is identified with the space of pure quaternions. Many books/notes show this connection, but have not explained ideas behind considering multiplication by only unit quaternion, pure quaternions and multiplication in this specific way ($a\mapsto qaq^{*}$).
Can anybody explains ideas behind them, and suggest good reference for them (except Conway's book).  (Thanks in advance..)","['reference-request', 'quaternions', 'group-theory']"
177067,L'hospital rule for two variable.,"How to use L'hospital rule to compute the limit of the given function $$\lim_{(x,y)\to (0,0)} \frac{x^{2}+y^{2}}{x+y}?$$","['multivariable-calculus', 'limits']"
177068,A question on the compact subset,"This is an exercise from a topological book. Let $X$ is Hausdorff and $K$ is a compact subset of $X$. $\{U_i:i=1,2,...,k\}$ is the open sets of $X$ which covers $K$. How to prove that there exist compact subsets of $X$: $\{K_i:i=1,2,...,k\}$ such that $K=\cup^k_{i=1}K_i$ and for any $i\le k$, $K_i \subset U_i$? What I've tried: I try to let $K_i = K\cap U_i$, then it is obvious $K=\cup^k_{i=1}K_i$, however, I'm not sure such $K_i$ is still compact in $X$. I don't know how to go on. Could anybody help me? Thanks ahead:)",['general-topology']
177087,The metrizable space may be not locally compact,"My text book said: Not every metrizable space is locally compact. And it lists a counterexample as following: The subspace $Q=\{r: r=\frac pq; p,q \in Z\}$ of $R$ with usual topology, i.e., $Q$ is the set of all rationals. It said: for any open ball of any point $r \in Q$, the closure is not compact. I can't understand this sentence. Why the closures of the open balls are not compact. Could anybody help me to understand this sentence. Thanks ahead:)","['general-topology', 'metric-spaces', 'compactness']"
177091,$\int_{-\infty}^\infty e^{ikx}dx$ equals what?,"What would $\int\limits_{-\infty}^\infty e^{ikx}dx$ be equal to where $i$ refers to imaginary unit? What steps should I go over to solve this integral? I saw this in the Fourier transform, and am unsure how to solve this.","['fourier-analysis', 'calculus']"
177099,the rank of an interesting matrix,"Let $A$ be a square matrix whose off-diagonal entries $a_{i,j} \in (0,1)$ when $i \neq j$. The diagonal entries of $A$ are all 1s. I am wondering whether $A$ has a full rank.","['matrices', 'linear-algebra']"
177105,Vector Taylor series,"From pg. 35 of Classical Electrodynamics 3rd edition, Jackson, $$\begin{aligned} \nabla^{2} \Phi_{a}(\mathbf{x}) &=-\frac{1}{4 \pi \epsilon_{0}} \int \rho\left(\mathbf{x}^{\prime}\right)\left[\frac{3 a^{2}}{\left(r^{2}+a^{2}\right)^{5 / 2}}\right] d^{3} x^{\prime} \end{aligned}$$ ""Choose R such that $\rho(\mathbf{x'})$ changes little over the interior of the sphere... With a Taylor series expansion of the well-behaved $\rho (\mathbf{x'})$ around $\mathbf{x'} = \mathbf{x}$ one finds ..."" \begin{align}
\nabla^{2} \Phi_{a}(\mathbf{x}) &=-\frac{1}{\epsilon_{0}} \int_{0}^{R} \frac{3 a^{2}}{\left(r^{2}+a^{2}\right)^{5 / 2}}\left[\rho(\mathbf{x})+\frac{r^{2}}{6} \nabla^{2} \rho+\cdots\right] r^{2} d r+O\left(a^{2}\right),
\end{align} where $r = |\mathbf{x'} -\mathbf{x}|$ . Could someone explain how to derive this Taylor series for a function of a vector? I've never seen this before and am at a loss.","['multivariable-calculus', 'taylor-expansion']"
177123,"How to evaluate $\int \frac{\mathrm dx}{\sqrt[3]{\tan\,x}}$?","Please show me the steps of the following integration. I got an answer in Wolfram, but I need steps.. $$\int \frac{\mathrm dx}{\sqrt[3]{\tan\,x}}$$","['calculus', 'integration']"
177125,holomorphic function on the complex plane,let $ f(z) \in Hol(\mathbb{C}) $ holomorphic function such that for each $ z_0 \in \mathbb{C} $ there exists $ N(z_0) $ such that $ f^{(N(z_0))}(z_0) = 0 $ Prove: that f is a polynom,['complex-analysis']
177135,How to deal with $A^{26}=I$?,"I got stuck in this problem: Let $A:\mathbb{R}^{6}\rightarrow \mathbb{R}^{6}$ be a linear transformation. Assume $A^{26}=I$, prove that $R^{6}=\oplus_{i=1}^{3} V_{i}$, with $AV_{i}\subset V_{i}$(the explicit condition is $V_{i}$ are 2-dimensional invariant subspaces of $\mathbb{R}^{6}$ under $A$). My thought is $A$ must have a minimal polynomial of degree less or equal to 6. Thus since it divides $x^{26}-1$, the only choices are: $$x-1,x+1,x^{2}-1$$ since the rest term $$(x^{13}-1)/(x-1)*(x^{13}+1)/(x+1)$$ has factors irreducible and degree higher than 6. And the claim is trivial in the case $A=\pm I$. But I do not know how to deal with the case $A^{2}-I=0$ - $A$ can only have eigenvalues $1$ and $-1$, but how this helps to solve the problem? Edit: In the light of did's comments $\sum^{12}_{i=0}x^{i}$ and $\sum^{12}_{i=0}(-1)^{i}x^{i}$ can be reducible over the reals in pairs of 6 quadratics, and the corresponding $A$'s are rotations. But I still feel rather confused as if problem is solved at this stage by suggesting $A$'s minimal polynomial must be a product of $$x-1,x+1,x^{2}-1, x^{2}-\cos[\theta]x+1$$
which are dealt with respectively by $I,-I$, selecting linearly independent vectors and run with $A$, and selecting the rotational invariant subspace. Since obviously cases like $$(x\pm 1)(x^{2}-\cos[\theta]x+1)$$ or even $$(x+1)(x-1)^{2}$$ could happen.",['linear-algebra']
177139,Why can we write $B=UAU^{-1}$?,"This question is from the 1979 Berkeley Problems in Mathematics. It asked me to prove that every complex matrix $A$ can be written in the form $$B=UAU^{-1}$$ with $U$ unitary and $B$ upper triangular. The Jordan decomposition only gives me that $U$ invertible, which is not enough in this case. I do not know a simple trick to turn invertible matrices into unitary matrices (like the one that works for the real case $C=\sqrt{DD^{T}}$).","['matrices', 'linear-algebra']"
177143,How to show $A$ cannot have more than one Jordan block for any eigenvalue?,"I got stuck in this problem from Spring 99, Berkeley Problems in Mathematics: Let $A$ be a $n\times n$ matrix such that $a_{ij}\not=0$ if $i=j+1$ but $a_{ij}=0$ if $i\ge j+2$. Prove that $A$ cannot have more than one Jordan block for any eigenvalue. I thought the matrix would satisfy some obvious relationship like $A^{2}=0$, but I realized the entries not listed are not even specified; thus such a gross simplification cannot hold. Working on toy examples does not tell me much, so I decided to ask in here.",['linear-algebra']
177153,Real life applications of general vector spaces,Students familiar with Euclidean space find the introduction of general vectors spaces pretty boring and abstract particularly when describing vector spaces such as set of polynomials or set of continuous functions. Is there a tangible way to introduce this? Are there examples which will have a real impact? I would like to introduce this in an engaging manner to introductory students. Are there any real life applications of general vector spaces?,"['vector-spaces', 'applications', 'linear-algebra', 'education']"
177160,Integral:$ \int^\infty_{-\infty}\frac{\ln(x^{2}+1)}{x^{2}+1}dx $,"How to evaluate: $$ \int^\infty_{-\infty}\frac{\ln(x^{2}+1)}{x^{2}+1}dx $$ Maybe we can evaluate it using the well-known result:$\int_{0}^{\frac{\pi}{2}} \ln{\sin t} \text{d}t=\int_{0}^{\frac{\pi}{2}} \ln{\cos t} \text{d}t=-\frac{\pi}{2}\ln{2}$ But how do I evaluate it, using that ?","['calculus', 'integration']"
177177,Complex polynomial and the unit circle,"Given a polynomial $ P(z) = z^n + a_{n-1}z^{n-1} + \cdots + a_0 $, such that $\max_{|z|=1} |P(z)| = 1 $ Prove: $ P(z) = z^n $ Hint: Use cauchy derivative estimation 
  $$ |f^{(n)} (z_0)| \leq \frac{n!}{r^n} \max_{|z-z_0|\leq r} |f(z)| $$ and look at the function $ \frac{P(z)}{z^n} $ It seems to be maximum principle related, but I can't see how to use it and I can't understand how to use the hint.",['complex-analysis']
177178,On lower bounds for contour integrals and their divergence,"I want to find a lower bound for $\left|\int_\gamma f(z)dz\right|$. I know of the estimation lemma and Jordan's lemma for an upper bound, but I don't know of any for a lower bound. The motivation is that I want to prove that a certain integral diverges on a given contour, and I'm looking for ways to do that. I think that for a given smooth contour $\gamma_R$ that depends on a parameter $R$, and a given function $f(z)$ such that $|f(z)|\rightarrow\infty$ as $R\rightarrow\infty$, one can conclude that $\left|\int_{\gamma_R}f(z)dz\right|\rightarrow\infty$ as $R\rightarrow\infty$. In an attempt to prove that, I use a naive approximation for $\left|\int_{\gamma_R}f\right|$:
$$\left|\int_{\gamma_R}f\right|=\left|\int_If(\gamma_R(t))\dot{\gamma_R}(t)\right|\geq \left|\sum_{j=1}^nf\left(\gamma_R\left(\frac{j}{n}\right)\right)\dot\gamma_R\left(\frac{j}{n}\right)\right|$$
here I use a lower bound of the Riemann integral after the choice of parameterization for $\gamma_R$, without loss of generality and for ease of writing I assumed that the interval of the parameterization is $[0,1]$ and I used the partition of $I$ to $n$ subintervals of length $\frac{1}{n}$. And then using the triangle inequality and the assumption we have that $\left|\int_{\gamma_R}f(z)dz\right|\rightarrow\infty$ (On second thought, we might also need that the derivative of $\gamma_R$ behaves nice enough). So, to be very specific, the 3 questions I have here: a) is there an ""estimation lemma"" for a lower bound? b) is my reasoning correct in the above proof? c) are there criteria for contour integral divergence or similar tests? Thanks","['complex-analysis', 'contour-integration']"
177181,How to measure the volume of rock?,"I have a object which is similar to the shape of irregular rock like this I would like to find the volume of this. How to do it? If I have to find the volume, what are the things I would need. eg., If it is cylindrical, I would measure length and diameter. But, it is irregularly shaped. Like the above rock. Where should I start? Couple of google search says something related to integration and contours. Somebody pls give me some handle :) I would say i'm very beginner level in math. Many Thanks :) Edit:
60 to 70% accuracy would be helpful.","['integration', 'contour-integration']"
177189,Finding $E(N)$ in this question,"suppose $X_1,X_2,\ldots$ is sequence of independent random variables of $U(0,1)$ if 
$N=\min\{n>0 :X_{(n:n)}-X_{(1:n)}>\alpha , 0<\alpha<1\}$ that $X_{(1:n)}$ is smallest order statistic and
$X_{(n:n)}$ is largest order statistic. how can find $E(N)$",['probability']
177190,Is the product of two sets well-defined if one is empty [duplicate],"This question already has answers here : How do the sets $\emptyset\times B,\ A\ \times \emptyset, \ \emptyset \times \emptyset $ look like? (6 answers) Closed 10 years ago . Let $X$ be a set. What is $X\times \emptyset$ supposed to mean? Is it just the empty set?",['elementary-set-theory']
177208,Prove $\sin^2(A)+\sin^2(B)-\sin^2(C)=2\sin(A)\sin(B) \cos(C)$ if $A+B+C=180$ degrees,"I most humbly beseech help for this question. If $A+B+C=180$ degrees, then prove
$$
\sin^2(A)+\sin^2(B)-\sin^2(C)=2\sin(A)\sin(B) \cos(C)
$$
I am not sure what trig identity I should use to begin this problem.",['trigonometry']
177209,A three variable binomial coefficient identity,"I found the following problem while working through Richard Stanley's Bijective Proof Problems (Page 5, Problem 16). It asks for a combinatorial proof of the following:
$$ \sum_{i+j+k=n} \binom{i+j}{i}\binom{j+k}{j}\binom{k+i}{k} = \sum_{r=0}^{n} \binom{2r}{r}$$
where $n \ge 0$, and $i,j,k \in \mathbb{N}$, though any proof would work for me. I also found a similar identity in Concrete Mathematics, which was equivalent to this one, but I could not see how the identity follows from the hint provided in the exercises. My initial observation was to note that the ordinary generating function of the right hand side is $\displaystyle \frac {1}{1-x} \frac{1}{\sqrt{1-4x}}$, but couldn't think of any way to establish the same generating function for the left hand side.","['sequences-and-series', 'binomial-coefficients', 'combinatorics']"
177213,Maximum area of a triangle,"[Edit:I had a couple of links to the original probelm but they have gone the way of all things.] I have been attempting to solve this problem: Given three concentric circles of radii 1, 2, and 3, respectively, find the maximum area of a triangle that has one vertex on each of the three circles. Here is a partial solution (not my own) which I have edited it a little for clarity. Note that $A=1$ , $B=2$ and $C=3$ : Let radii A,B, and C be at angles a,b, and c respectively. Position radius A on the positive x-axis at angle $a=0$ (no loss in generality). From the equation for triangle area (1) area = $\frac12 BC \sin(b-c) + \frac12 CA \sin(c) + \frac12 AB \sin (2\pi -b)$ . Take the total partial of
area w.r.t $b$ and $c$ and set equal to $0$ . This gives (2) $C \cos c = B \cos b$ . Also, from condition (2) extended radii are perpendicular to the triangle side. Next,
the value of angle $b$ is determined. A little fancy geometry shows that $b$ is $225^o$ from $A$ ( $-45^o$ in the third quadrant). From (2) angle $c$ is obtained. I am happy with the expression for the triangle's area, and also with the differentiation and derivation of $C\cos c = B\cos b$ . But I don't see why the extended radii are perpendicular to the triangle's sides, which makes the centre of the concentric circles the orthocentre of the triangle. And I'm also not seeing the ""fancy geometry"" that gives the angle $b$ , nor, indeed, why angle $b$ is constant. Could someone please explain what's happening here?","['geometry', 'triangles', 'trigonometry']"
177239,Derivative of convolution,"Assume that $f(x),g(x)$ are positive and are in $L^1$ . Moreover, they are differentiable and their derivative is integrable. Let $h(x)=f(x)*g(x)$ , the convolution of $f$ and $g$ . Does the derivative of $h(x)$ exist? If yes, how can we prove that $$ \frac{d}{dx}(f(x)*g(x)) = \left(\frac{d}{dx}f(x)\right)*g(x)$$ Thanks","['fourier-analysis', 'functional-analysis']"
177240,Dependence of the Sobolev embedding constants on the domain,"Let $\Omega$ be a sufficiently nice domain in $\mathbb{R}^n$. If $ 1 \leq p < n $ and $ p^* = \frac{np}{n-p} $ then there exists a constant $C_1$ such that for all $ u \in W^{1,p}(\Omega) $ we have
$$ (I)~~~~||u||_{L^{p^*}(\Omega)} \leq C_1||u||_{W^{1,p}(\Omega)}. $$ 
If $ p > n $ then there exists a constant $C_2$ such that for all $ u \in W^{1,p}(\Omega) $ we have
$$ (II)~~~~||u||_{L^{\infty}(\Omega)} \leq C_2||u||_{W^{1,p}(\Omega)}. $$ In general, the constants $C_i$ depend on the domain $\Omega$. Can someone point me to some references that discuss the dependence between the embedding constants and the domain? I'm interested in conditions under which, given some family of domains $ \Omega_\alpha $, I can get Sobolev embedding inequalities as above with a constant that doesn't depend on $\alpha$. To be even more specific, I'm interested in the case $ n = 2 $ and when the domains are families of balls or annuli. For example, if I consider inequality (II) and a family of balls, then an obvious sufficient condition is to have both an upper and a lower bound on the radii of the balls. One can't get away without a lower bound (consider the function $u \equiv 1$) but can get away without an upper bound by using a translation argument. What about inequality (I)? What can I use to answer such questions? Since one way to prove the inequalities above is to use an extension operator, and then ""steal"" the inequality from $\mathbb{R}^n$, this question is related to dependence of the minimal norm of an extension operator $W^{1,p}(\Omega) \rightarrow W^{1,p}(\mathbb{R}^n)$ on the domain","['sobolev-spaces', 'functional-analysis']"
177243,Who came up with the Euler-Lagrange equation first?,"Could someone explain who came up with the specific equation first? http://en.wikipedia.org/wiki/Euler-Lagrange makes it sound like Lagrange got it first, in 1755, then sent it to Euler. but: http://en.wikipedia.org/wiki/Calculus_of_variations sort of makes it sound like Euler got it first in the 1730s. It seems like a straightforward question, but I can't find an answer anywhere. Who came up with the equation, Euler or Lagrange? And what precisely did the other man contribute to get his name on there?","['calculus', 'calculus-of-variations', 'math-history']"
177246,Residue of $\frac{\tan(z)}{z^3}$,"What is the easiest way to calculate the residue of $\dfrac{\tan(z)}{z^3}$ at zero? I could either use the line integral theorem, or expand it out as a series. Is there a right way to do it?",['complex-analysis']
177265,Linear isometry and operator norm $=1$,"For some reason I used to think that if $T$ is a linear operator on normed spaces $V \to W$ then saying $T$ is an isometry is the same as saying $\|T\|_{op} = 1$. Well, I got stuck on a proof and subsequently looked up the definition and realised that the definition of isometry is that a linear operator $T$ is an isometry if $\|Tx\| = \|x\|$. Now I've been wondering whether we have that $\|T\|_{op} = 1$ implies $T$ is an isometry? The other direction holds: if $\|Tx\| = \|x\|$ for all $x$ then $\frac{\|Tx\|}{\|x\|} = 1$ for all $x \neq 0$ and hence $\sup_{\|x\|=1}\|Tx\| = \sup_{\|x\|=1} \frac{\|Tx\|}{\|x\|} = \|T\| = 1$. Thanks for your help.","['normed-spaces', 'functional-analysis']"
177266,On linearly independent matrices,"I have been reading J.S. Milne's lecture notes on fields and Galois theory and came across the normal basis theorem (Thm 5.18 on page 66 of the notes). Trying to find my own proof, the following problem in linear algebra quickly arose: Question: Let $F$ be a field. Given linearly independent matrices $A_1, \dots, A_n \in \operatorname{GL}_n(F)$, does there necessarily exist some $b\in F^n$ such that $A_1b, \dots, A_nb$ are linearly independent over $F$? This is clearly not true if the matrices are not linearly independent. Also, if they are not invertible, the claim is false in general: e.g. set $n=2$ and consider $$A_1 = \begin{pmatrix} 1 & 0 \\ 0& 0\end{pmatrix},\quad  A_2 = \begin{pmatrix} 0 & 1 \\ 0& 0\end{pmatrix}$$ Going through a case-by-case analysis, I think I can prove the claim for $n=2$, so there seems to be some hope... Any help would be appreciated. Thanks!","['linear-algebra', 'abstract-algebra']"
177267,Fast algorithms for calculating the Möbius inversion,"Recall the Möbius inversion formula: if we have two functions $f,g \colon \mathbf{N} \to \mathbf{N}$ such that
$$g(n) = \sum_{k=1}^n f\left(\left\lfloor \frac{n}{k} \right\rfloor\right)$$
holds for every $n \in \mathbf{N}$, then the values of $f$ can be recovered as
$$f(n) = \sum_{k=1}^n \mu(k) g\left(\left\lfloor \frac{n}{k} \right\rfloor\right),$$
where $\mu(k)$ is the Möbius function. I am interested in fast algorithms for calculating a single value $f(n)$, assuming that $g$ can be calculated in $O(1)$ time. The best algorithm I know of is as follows: There are $O(\sqrt{n})$ different values $\left\lfloor \frac{n}{k} \right\rfloor$, $1 \le k \le n$. If we have already calculated $f\left(\left\lfloor \frac{n}{k} \right\rfloor\right)$ for $2 \le k \le n$, then
$$f(n) = g(n) - \sum_{k=2}^n f\left(\left\lfloor \frac{n}{k} \right\rfloor\right)$$
can be calculated in $O(\sqrt{n})$ time by counting the multiplicities of the terms in the sum. By calculating the $f\left(\left\lfloor \frac{n}{k} \right\rfloor\right)$ from bigger to lower $k$ the total time required will then be $O(n^{3/4})$ while using $O(\sqrt{n})$ space. I'm also interested in possible improvements to the above algorithm, even if they reduce the required time just by a constant factor.","['algorithms', 'number-theory']"
177271,Solution space to a functional equation,"This question comes from my attempts at understanding an example presented by Bill Gasarch on his blog . The example is of a continuous strictly increasing function whose derivative is zero almost everywhere. The example is apparently discussed in the book Probability and Measure by Patrick Billingsley, but I currently do not have access to it. Gasarch explains the background very well. Given a parameter $p \in (0,1)$, he describes a continuous function $F:[0,1]\to[0,1]$ which is increasing, $F(0) = 0$, $F(1) = 1$, but such that $F' = 0$ a.e. The derivative $f = F'$, which is only defined almost everywhere , must be nonnegative and should satisfy the following functional equation $$f(x) = \begin{cases} 2pf(2x) & \text{when $x \in (0,1/2)$,} \\ 2(1-p)f(2x-1) & \text{when $x \in (1/2,1)$,} \end{cases}$$ almost everywhere. It would seem, from the claimed example, that a nonnegative measurable function that satisfies this functional equation almost everywhere must be $0$ almost everywhere. However, this is not true since every constant function satisfies this functional equation when $p = 1/2$. Thinking about the dynamic properties of the transformation $$T(x) = \begin{cases} 2x & \text{when $x \in [0,1/2)$,} \\ 1/2 & \text{when $x = 1/2$ (say),} \\ 2x-1 & \text{when $x \in (1/2,1]$,} \end{cases}$$ it does seem that the space of solutions to the above equation is heavily constrained. Is there a nice characterization of the space of solutions to the above functional equation? A general characterization would be best but a characterization for special cases (e.g. $f \geq 0$, $p = 1/2$) would be welcome.","['dynamical-systems', 'ergodic-theory', 'measure-theory', 'functional-equations', 'real-analysis']"
177282,Understanding measures on the space of measures (via examples),"Let $X$ be a Polish space. If it allows for an interesting answer, you may assume $X$ is compact or even $X=[0,1]$. The space $\mathcal{P}(X)$ of Borel probability measures on $X$ is also Polish (via the Prokhorov metric ). Measures on $\mathcal{P}(X)$ (i.e. elements of $\mathcal{P}(\mathcal{P}(X))$) arise, for example in the ergodic decomposition. I'm looking to understand $\mathcal{P}(\mathcal{P}(X))$ better, especially through examples. Q1. Is there a natural example of an element $\mathcal{P}(\mathcal{P}(X))$? Q.1.5 What about when $X=[0,1]$? Q2. What results in mathematics use or refer to an element of $\mathcal{P}(\mathcal{P}(X))$? I'm aware of the ergodic decomposition and its special case, de Finetti's theorem. Q3. Where is $\mathcal{P}(\mathcal{P}(X))$ studied? I'm aware of Billingsley's Convergence of Probability Measures and Parthasarathy's Probability Measures on Metric Spaces . EDIT Regarding Q2, I'm most interested in classical results. The answers given by @NateEldredge and @MichaelGreinecker, while interesting and helpful, seem to regard more modern (i.e. not classical) results. I realize that 'classical' is vague, and I'll try to make what I'm after more precise if necessary. The ergodic decomposition is something I consider 'classical'.","['probability-theory', 'measure-theory', 'reference-request']"
177283,Show $\lim\limits_{n\to\infty}\int_{0}^{\infty}e^{-x}\sin(\frac{n}{x})~\text{d}x=0$,I'm having trouble showing $$\lim_{n\to\infty}\int_{0}^{\infty}e^{-x}\sin\left(\frac{n}{x}\right)~\text{d}x=0$$ The integrand doesn't converge for any $x$ so I don't know how to use the standard Lebesgue convergence theorems. Thank you for any hints.,"['measure-theory', 'integration', 'real-analysis', 'limits']"
177288,How to disprove there exists a real number $x$ with $x^2 < x < x^3$,"I realize that the only method is to show various cases: I must test for $x > 1$, $x < -1$, $0 \leq x \leq 1$, and $-1\leq x \leq0$. But even with this, I don't understand how to inject the properties of these four distinct possible $x$'s into the inequality (from the title) in order to show that none of these work. Thanks for any help","['inequality', 'algebra-precalculus']"
177310,"The probability of a ""double supremum"" of random variable","Let $X_1,X_2,X_3,\ldots$ be IID r.v. with \begin{equation}
P(X_i<-1)=0
\end{equation}
\begin{equation}
P(X_i<0)>0
\end{equation}
\begin{equation}
P(X_i>0)>0.
\end{equation} Define
\begin{equation}
F_t = \prod_{i=1}^t(1+\frac{1}{2}X_i)
\end{equation}
\begin{equation}
G_t = \prod_{i=1}^t(1+\frac{1}{4}X_i).
\end{equation} How can we show, for some integer $S>0$, that
\begin{equation}
P\left(\sup_{s\in[1,S]} \left[\sup_{t\in[1,s]} \frac{F_t-F_s}{F_t}\right] > \frac{1}{3}\right)
> P\left(\sup_{s\in[1,S]} \left[\sup_{t\in[1,s]} \frac{G_t-G_s}{G_t}\right] > \frac{1}{3}\right)
\end{equation} Thanks in advance for any hints to get me started, or possibly a draft of a solution. I simply have no clue about how to proceed. Update: I have been thinking. Instinctvly, this problem seems to hold true because for any negative $X_i$, this holds: \begin{equation}
(1+\frac{1}{2}X_i) < (1+\frac{1}{4}X_i).
\end{equation} This should mean that $F_t$ will usually be dropping faster than $G_t$. I still wonder how to formalize these instincts.","['random-walk', 'calculus', 'probability']"
177313,Zariski topology on prime $\mathrm{Spec}$ of a ring $R$,"Let $R$ be a commutative unital ring. Let $\mathrm{Spec}(R) = \{ \mathfrak p \subset R \mid \mathfrak p \text{ a prime ideal of } R \}$. We define a set $C$ to be closed in this space if and only if there is an ideal $I$ such that $C(I) = \{\mathfrak p \mid I \subset \mathfrak p, \mathfrak p \text{ a prime ideal of } R \}$. Now I'd like to show that these sets form a topology on $\mathrm{Spec}(R)$: (i) For the zero ideal we get $C(0) = \mathrm{Spec}(R)$ and for $R$ we get $C(R) = \varnothing$. (ii) Arbitrary intersections are closed again: $\bigcap_\alpha C(I_\alpha) = \{\mathfrak p \mid \mathfrak p \text{ a prime ideal of } R, I_\alpha \subset \mathfrak p \text{ for all } \alpha  \} = \{\mathfrak p \mid \mathfrak p \text{ a prime ideal of } R, \sum_\alpha I_\alpha \subset \mathfrak p   \} = C(\sum_\alpha I_\alpha)$. (iii) We want to show that finite unions are closed again. It's enough to show it for two ideals $I,J$: $C(I) \cup C(J) = \{\mathfrak p \mid \mathfrak p \text{ a prime ideal of } R, \text{ such that either }  I \subset  \mathfrak p  \text{ or } J  \subset \mathfrak p \}$ Now I'm stuck. How do I express the ""either or"" in terms of operations on ideals? Thanks for your help.","['general-topology', 'commutative-algebra']"
177317,Simple inequality for measures,"Let $(X,\mathscr B_X)$ and $(Y,\mathscr B_Y)$ be two measure spaces and $(Z,\mathscr B_Z)$ be their product space. Consider two finite measures (not necessarily product measures) $\mu,\nu$ on $(Z,\mathscr B_Z)$. Suppose that for any $A\in \mathscr B_X$ and for any $B\in \mathscr B_X$ it holds that
$$
  \mu(A\times B)\geq \nu(A\times B).
$$ 
Does it mean that $\mu(C)\geq \nu(C)$ for any $C\in \mathscr B_Z$? Some thoughts: clearly, the question can be equivalently stated as suppose that a measure $\lambda$ on $(Z,\mathscr B_Z)$ is non-negative on rectangles. It it a non-negative measure? I was going to apply monotone class-like arguments, but I do not know what to do with complements. Clearly, the inequality is preserved under countable disjoint unions, though.",['measure-theory']
177338,Generalized Change of Variables Theorem?,"Is there a generalized form of the differentiable change of variables theorem for Lebesgue integrals? That is, if we consider the well known change of variables theorem: If $\phi : X \rightarrow X$ is a diffeomorphism of open sets in $\mathbb{R}^n$, $X \subseteq \mathbb{R}^n$ is measurable, and $f : X \rightarrow \mathbb{R}$ is measurable, then: $$
\int_X f(y) dy = \int_X f(\phi(x)) d(\phi(x)) = \int_X f(\phi(x)) |\det D\phi(x)| dx
$$ I'de like to weight between some countable set of (simple) diffeomorphic mappings instead of just one, that is, let $\Phi = \{\phi_i \ | \ i \in \mathbb{N}, |\det D\phi_i(x)| = 1\}$.  Additionally, I'de like to weight between these transformations as a convex-combination, so I define a weighting function, $w : X \times \mathbb{N} \rightarrow \mathbb{R}$, where: $\sum_i w(\phi_i^{-1}(y),i)$ = 1.  Then, I'de like to show: $$
\int_X \sum_i w(x,i) f(\phi_i(x)) dx = \int_X f(x) dx
$$ My attempt at a proof is:
\begin{align}
\int_X \sum_i w(x,i) f(\phi_i(x)) dx & = \sum_i \int_X w(x,i) f(\phi_i(x)) dx\\
& = \sum_i \int_X w(x,i) f(\phi_i(x)) |\det D\phi_i(x)|dx\\
& = \sum_i \int_X w(\phi_i^{-1}(y),i) f(y) dy\\
& = \int_X f(y) \sum_i w(\phi_i^{-1}(y),i) dy \\
& = \int_X f(y) dy 
\end{align} Trouble is, I'm not all that familiar with measure theory and I would need to show that my weighting function is measurable in order to invoke the single-mapping change of variables theorem mentioned above.  Perhaps I cannot do this without being more explicit about what this function actually is, but at the same time, it's just a simple weight vector, normalized in some unique way, over a countable set it would be nice if I could say something at this level of generality.  Also, perhaps it makes more sense to start at the case where $\Phi$ is finite, which is fine, but I have the same issues with the proof with this assumption.","['measure-theory', 'integration']"
177345,Series of Maximal Operator,"Let $p\in(1,\infty)$. Assume that we have a sequence of functions $\{f_i:i\in\mathbb{N}\}\subset L^p(\mathbb{R}^n)$ such that
$$
\left(\sum\limits_{i=1}^\infty|f_i|^2\right)^{\frac{1}{2}}\in L^p(\mathbb{R}^n)\qquad
\{\mu (f_i):i\in\mathbb{N}\}\subset L^p(\mathbb{R}^n)
$$
I want to prove that 
$$
\left\Vert\left(\sum\limits_{i=1}^\infty|\mu(f_i)|^2\right)^{\frac{1}{2}}\right\Vert_p \leq A_p\left\Vert\left(\sum\limits_{i=1}^\infty|f_i|^2\right)^{\frac{1}{2}}\right\Vert_p
$$
Here we can assume that $\mu$ is the Hardy-Littlewood's maximal operator (centered or non-centered).","['harmonic-analysis', 'real-analysis', 'analysis']"
177357,Cartesian products of families in Halmos' book.,"I'm studying some set theory from Halmos' book. He introduces the generalization of cartesian products by means of families. However, I can't understand what is going on. I get the first introduction ""The notation..."" to ""... one-to-one correspondence"". What I'm having trouble is with If $\{X_i\}$ is a family of sets $(i\in I)$, the Cartesian product of the family is, by definition, the set of all families $\{x_i\}$ with $x_i\in X_i$ for each $i$ in $I$. Could you explain to me the motivation of this definition? I know families  are itself functions $f:I\to X$ such that to each $i$ there corresponds a subset of $X$, $x_i$. Instead of this we write them succintly as $\{x_i\}_{i\in I}$ to put emphasis on the range (indexed sets) of the function and the domain (indexing set) in question. For example, in my case, the family is $f:I\to X$ with $f(i)=A_i$ with ${\rm dom} f=\{0,1,2,3\}$ and ${\rm ran} f =\left\{ {{A_0},{A_1},{A_2},{A_3}} \right\}$. I'm thinking that we can talk about the cartesian product of sets as a set of tuples. However, I can't understand the definition for families of sets. I leave the page in question: $\hspace{1 cm} $",['elementary-set-theory']
177360,Computing $\frac{d^k}{dx^k}\left(f(x)^k\right)$ where $k$ is a positive integer,Does anyone know a formula for the derivative $$\frac{d^k}{dx^k}\left(f(x)^k\right)$$ where $k$ is some positive integer? I started trying to work it out but it got messy.,"['calculus', 'derivatives']"
177364,Square integrable gradient and equicontinuity,"Background .I have been studying the proof of the unboundedness of the eigenvalues of a quadratic functional
$$I[\phi]=\int_{\Omega}\left(p|\nabla\phi|^2+q\phi^2\right)d\boldsymbol{x}$$
subject to
$$H[\phi]=\int_{\Omega}\rho\phi^2d\boldsymbol{x}=1$$
($p,q,\rho>0$, $p\in C^1(\Omega)$)
The crux of the argument by contradiction as set out in Courant & Hilbert and originally due to Rellich is that assuming the eigenvalues $\lambda_n=I[\phi_n]$ are bounded ($\phi_n$ being the corresponding eigenfunction) it is possible to extract a uniformly convergence subsequence of the eigenfunctions. Thus
$$\lim_{m,n\to\infty}H[\phi_m-\phi_n]=0$$
whereas from orthonormality condition it follows that
$$H[\phi_m-\phi_n]=2$$
for $n\ne m$.
In this they rely on Arzela-Ascoli theorem calling it ""accumulation principle"". In one-dimensional case C&H prove uniform boundedness and equicontinuity directly, for example, using Schwarz inequality
$$f(x_1)-f(x_2)=\int_{x_1}^{x_2}f'(x)dx \le\sqrt{\int_{x_1}^{x_2}f'^2(x)dx\cdot\int_{x_1}^{x_2}1^2dx}$$
Hence, if $\int_{x_1}^{x_2}f'^2(x)dx<M$ we have
$$(f(x_1)-f(x_2))^2<M|x_2-x_1|$$
In case of 2 independent variables C&H refer to a lemma due to Rellich proved in the above mentioned article. This lemma asserts that if a for a set of functions $\phi(x,y)$ defined in the domain $\Omega$ $$\int_{\Omega}\phi^2dxdy\quad \text{and} \quad \int_{\Omega}(\phi_x^2+\phi_y^2)dxdy$$ are uniformly bounded it is possible to select a subsequence $\phi_n$ such that
$$\lim_{m,n\to\infty}\int_{\Omega}(\phi_m-\phi_n)^2dxdy=0$$ What I tried. As opposed to Rellich's procedure I attempted to extend naively the above one-dimensional argument to the case of many variables to prove equicontinuity, hoping to invoke an generalised Arcela-Ascoli theorem to complete the task
Consider the difference of the values of $\phi$
  at two distinct points: $$\begin{aligned}\phi\left(x_{2},y_{2}\right)-\phi\left(x_{1},y_{1}\right) & =\phi\left(x_{2},y_{2}\right)-\phi\left(x_{2},y_{1}\right)+\phi\left(x_{2},y_{1}\right)-\phi\left(x_{1},y_{1}\right)\\
 & =\int_{y_{1}}^{y_{2}}\left.\frac{\partial\phi}{\partial y}\right|_{x=x_{2}}dy+\int_{x_{1}}^{x_{2}}\left.\frac{\partial\phi}{\partial x}\right|_{y=y_{1}}dx
\end{aligned}$$ Writing $\phi_{x}\left(x,y_{1}\right)=\left.\frac{\partial\phi}{\partial x}\right|_{y=y_{1}}$
  and $\phi_{y}\left(x_{2},y\right)=\left.\frac{\partial\phi}{\partial y}\right|_{x=x_{2}}$
  and Applying Cauchy-Schwarz inequality:$$\begin{aligned}\phi\left(x_{2},y_{2}\right)-\phi\left(x_{1},y_{1}\right) & \le\sqrt{\int_{y_{1}}^{y_{2}}\phi_{y}^{2}\left(x_{2},y\right)dy\cdot\int_{y_{1}}^{y_{2}}1^{2}dy}\\
 & +\sqrt{\int_{x_{1}}^{x_{2}}\phi_{x}^{2}\left(x,y_{1}\right)dx\cdot\int_{x_{1}}^{x_{2}}1^{2}dx}\\
 & =\sqrt{\int_{y_{1}}^{y_{2}}\phi_{y}^{2}\left(x_{2},y\right)dy}\cdot\sqrt{y_{2}-y_{1}}\\
 & +\sqrt{\int_{x_{1}}^{x_{2}}\phi_{x}^{2}\left(x,y_{1}\right)dx}\cdot\sqrt{x_{2}-x_{1}}
\end{aligned}$$ Now transform the last expression as follows:$$\begin{array}{cc}
\phi\left(x_{2},y_{2}\right)-\phi\left(x_{1},y_{1}\right) & \le\sqrt{\int_{x_{1}}^{x_{2}}\int_{y_{1}}^{y_{2}}\phi_{y}^{2}\left(x_{2},y\right)dxdy}\cdot\sqrt{\frac{y_{2}-y_{1}}{x_{2}-x_{1}}}\\
 & +\sqrt{\int_{x_{1}}^{x_{2}}\int_{y_{1}}^{y_{2}}\phi_{x}^{2}\left(x,y_{1}\right)dxdy}\sqrt{\frac{x_{2}-x_{1}}{y_{2}-y_{1}}}
\end{array}$$ Applying Hölder's inequality:$$\phi\left(x_{2},y_{2}\right)-\phi\left(x_{1},y_{1}\right)\le\sqrt{\iint_{g}\left[\phi_{x}^{2}\left(x,y_{1}\right)+\phi_{y}^{2}\left(x_{2},y\right)\right]dxdy}\frac{\sqrt{\left(x_{2}-x_{1}\right)^{2}+\left(y_{2}-y_{1}\right)^{2}}}{\sqrt{S\left(g\right)}}$$ Since the integral of the squared gradient is uniformly bounded, we deduce: $$\sqrt{S\left(g\right)}\phi\left(x_{2},y_{2}\right)-\sqrt{S\left(g\right)}\phi\left(x_{1},y_{1}\right)\le C\sqrt{\left(x_{2}-x_{1}\right)^{2}+\left(y_{2}-y_{1}\right)^{2}}$$ Where $S(g)$ is the area of the rectangle. Where I got stuck . Now that I end up with an expression somewhat similar to the one that turns out in Rellich's article, I don't know how to proceed and whether it makes sense to. Will the generalised Arzela-Ascoli be really applicable here? What assumptions am I making, or should I make with regards to $\Omega$? If this draft argument is valid what would be the next step? Iterate the procedure in some way? This article by Terence Tao says that the answer to my attempt is ""barely no"", but what does it actually mean? Many thanks in advance for those who reads this till the end.","['multivariable-calculus', 'analysis']"
177373,Prove $\frac{1}{1 \cdot 3} + \frac{1}{3 \cdot 5} + \frac{1}{5 \cdot 7} + \cdots$ converges to $\frac 1 2 $,"Show that
$$\frac{1}{1 \cdot 3} + \frac{1}{3 \cdot 5} + \frac{1}{5 \cdot 7} + \cdots = \frac{1}{2}.$$ I'm not exactly sure what to do here, it seems awfully similar to Zeno's paradox.
If the series continues infinitely then each term is just going to get smaller and smaller. Is this an example where I should be making a Riemann sum and then taking the limit which would end up being $1/2$?","['sequences-and-series', 'calculus', 'telescopic-series']"
177384,Graphs with a unique $3$-path free acyclic orientation up to isomorphism.,"Let $\Gamma$ be a simple, $3$ -colorable graph such that, up to isomorphism, there exists exactly one acyclic orientation of $\Gamma$ that does not contain a directed 3-path.  (To be clear, when I say $3$ -path, I mean three edges, four vertices.) I require that $\Gamma$ is $3$ -colorable so that at least one such orientation exists (this is an if and only if). The $5$ -cycle is an example of a graph with this property.  Up to isomorphism, the only orientation that meets this requirement is the following: $\overset{\rightharpoonup}{C_5}$ ."" /> I have a few questions about these: I. Can graphs like this be characterized in some other way?  What is it that makes these guys only have one orientation? There may be something to the twisted orbital chromatic polynomial , described briefly at the end of document .  Perhaps this could somehow be adapted to exclude orientations with induced $3-$ paths. II. Are there any more of these other than $C_5$ , apart from trivial examples on less than $4$ vertices? Originally I thought these would constitute an infinite family of graphs, but to my surprise I have been unable to think of even one other example.  Does the condition preclude graphs above a certain order? III.  Can anyone help me construct an algorithm to check for graphs of this type on $6$ or more vertices? I can use MAGMA and Mathematica for the language, or $C$ if that's what you want.  (Though that might be a bit low level for these purposes!)","['abstract-algebra', 'graph-theory', 'combinatorics', 'group-theory', 'algebraic-graph-theory']"
177385,"Is the function $\theta(a,b) = a-2ab+b$ a bijection from $\{0,1\}\times\mathbb{N}$ to $\mathbb{Z}$?","Consider the function $\theta:\{0,1\}\times\mathbb{N}\rightarrow\mathbb{Z}$ defined as $\theta(a,b) = a-2ab+b$. Is this function bijective? For injective, I tried doing the contrapositive by supposing $\theta(a,b)=\theta(c,d)$, then $a-2ab+b=c-2cd+d$, but I have no idea where to go from there. I tried solving for a and b separately and plugging it back in, but that just turned into a huge algebraic mess. I haven't figured what I'm going to do for surjective yet.","['elementary-number-theory', 'functions']"
177388,a question about an infinite series calculation.,"I want to prove that for $y >0$, $ x \in \mathbb R$, 
$$ \sum_{n=-\infty}^\infty \frac{y}{(x+n)^2 + y^2} = \frac{1}{2} \frac{1 - e^{-4 \pi y }}{1 - 2 e^{-2 \pi y} \cos ( 2 \pi  x ) + e^{-4 \pi y}}$$","['complex-analysis', 'sequences-and-series', 'real-analysis']"
177416,Universally measurable sets of $\mathbb{R}^2$,"$$\text{Is }{{\cal B}(\mathbb{R}^2})^u={{\cal B}(\mathbb{R}})^u\times {{\cal B}(\mathbb{R}})^u\,?\tag1$$ Is the $\sigma$-algebra of universally measurable sets on $\mathbb{R}^2$ equal to the 
product $\sigma$-algebra of two copies of the universally measurable sets on $\mathbb{R}$? It is not hard
to see that (1) is true with $\supseteq$ instead of $=$,
and I would be astonished if (1) were true, but I'm not sure. Has anyone encountered this problem, or know a reference that might help?","['set-theory', 'measure-theory', 'reference-request', 'descriptive-set-theory']"
177428,Definition of Cantor Set without AC,"You can see the original text that i thought AC is used here; From Walter Rudin: Principles of Mathematical Analysis, 3rd ed., ISBN 0-07-054235-X, p.41-42. 2.44 The Cantor set The set which we are now going to construct shows
  that there exist perfect sets in $R^1$ which contain no segment. Let $E_0$ be the interval $[0, 1]$. Remove the segment $(\frac13,\frac23)$, and let $E_1$ be
  the union of the intervals
  $$[0,\frac13], [\frac23,1].$$
  Remove the middle thirds of these intervals, and let $E_2$ be the union of the
  intervals
  $$[0,\frac19], [\frac29,\frac39], [\frac69,\frac79],[\frac89,1]$$
  Continuing in this way, we obtain a sequence of compact sets $E_n$, such that (a) $E_1\supset E_2  \supset E_3 \dots $; (b) $E_n$ is the union of $2^n$ intervals, each of length $3^{-n}$. The set
  $$P=\bigcap_{n=1}^\infty E_n$$
  is called the Cantor set . $P$ is clearly compact, and Theorem 2.36 shows that $P$
  is not empty. No segment of the form
  $$\left(\frac{3k+1}{3^m},\frac{3k+2}{3^m}\right)\tag{24},$$
  where $k$ and $m$ are positive integers, has a point in common with $P$.
  Since every segment $(\alpha,\beta)$ contains a segment of the form (24), if
  $$3^{-m}<\frac{\beta-\alpha}6,$$
  $P$ contains no segment. To show that $P$ is perfect, it is enough to show that $P$ contains no isolated
  point. Let $x \in P$, and let $S$ be any segment containing $x$. Let $I_n$ be that interval
  of $E_n$ which contains $x$. Choose $n$ large enough, so that $I_n\subset S$. Let $x_n$ be an
  endpoint of $I_n$, such that $x_n\ne x$. It follows from the construction of $P$ that $x_n\in P$. Hence $x$ is a limit point
  of $P$, and $P$ is perfect. One of the most interesting properties of the Cantor set is that it provides
  us with an example of an uncountable set of measure zero (the concept of
  measure will be discussed in Chap. 11). I really didn't like the definition of Cantor set in my book (It defines cantor set by using AC$_\omega$), so i tried to construct it in more constructive way. (That is, without AC) Let $E_n = [0,1]\setminus \bigcup_{k\in 3^n}(3k+1/3^{n+1}, 3k+2/3^{n+1})$. (Exponentiation here is an ordinal exponentiation) Let $C=\bigcap_{n\in \omega} E_n$. I proved that $C$ is nonempty and compact, and $C$ contains no segment. Now, I'm trying to prove that $C$ is perfect but there's a problem. This is a lemma I made to prove this;
Let $T_n = \{3k/3^{n+1}, 3k+1/3^{n+1}, 3k+2/3^{n+1}, 3k+3/3^{n+1} \in [0,1] | k\in 3^n \}$. 'For every $n,m\in \omega$, if $n<m$, then $T_n\subset T_m$.' Now, fix $x\in C$ and $0<r\in \mathbb{R}$.
Here, i have proved that there exists $m\in \omega$ such that $x$ is in some interval $I$ in $E_m$ and the $I\subset B(r,x)$. Now let $x'$ be an endpoint such that $x'≠x$. By the lemma above, $x'\in E_n$ for every $m≦n$. However, i don't know how to prove this for $m>n$. I tried it and proved that 'If $m>n$ and intersection of an interval $I_n$ in $E_n$ and an interval $I_m$ in $E_m$ is nonempty, the intersection is a set of exactly one endpoint of $I_m$ or $I_m \subset I_n$. (If one holds, the other does not hold)' too.
Here, I have no idea how to derive a contradiction that 'if $x\in I_m \cap I_n$, then $I_m \cap I_n$ is NOT a singleton' ($x\in C$) Help","['general-topology', 'set-theory']"
177432,Combinatorics question: Prove 2 people at a party know the same amount of people,"I recently had an assignment and got this question wrong, was wondering what I left out. Prove that at a party where there are at least two people, there are two people who know the same number of other people there. Be sure to use the variable ""n"" when writing your answer. My answer: n >= 2
  Case1: another person comes to the party, but doesn't know either of the first two. So the original two still only know the same number of people.
  Case2: another person comes, and knows one out of the original 2, so therefore the >newcommer, and the one that doesnt know the newcommer both know the same number of people.
  Case 3: another person comes and knows both of them, implying that they all know each >other, and therefore they all know the same number of people. So therefore if n>=2, where n and n-1 know each other, in either case whether n+1 joins, >there will be at least two people who know the same amount of people. Many thanks in advance. Have a test coming up.","['discrete-mathematics', 'combinatorics']"
177440,Why isn't this square root $+$ or $-$?,"I was tasked with proving the identity $\tan(\frac x 2) = \dfrac {\sin(x)}{1+\cos(x)}$ I used the quotient identity for tangent and the half angle identities for sine and cosine to get $ \pm \dfrac {\sqrt{\dfrac {1-\cos(x)}{2}}}{\sqrt{\dfrac {1-\cos(x)}{2}}}$ which I reduced to $\pm \sqrt{\dfrac {1-\cos(x)}{1+\cos(x)}}$ I multiplied the fraction (within the square root) by $ \dfrac {1+ \cos(x)}{1+\cos(x)}$ Resulting in $\pm \sqrt{\dfrac {1-\cos^{2}(x)}{(1+\cos(x))^2}}$ Using the Pythagorean identity, I get $\pm\sqrt{\dfrac {\sin^{2}(x)}{(1+\cos(x))^2}}$ Taking the square root of the numerator and denominator I further reduced to $\pm \dfrac {\sin(x)}{1+\cos(x)}$ I thought I was done but when I checked my work in the answer book, it showed $ \left|\dfrac {\sin(x)}{1+\cos(x)}\right|$ Where do they get the absolute value from?","['trigonometry', 'absolute-value', 'roots']"
177446,Some exact sequence of ideals and quotients,"I saw an exact sequence of ideals $$0 \rightarrow I \cap J\rightarrow I \oplus J \rightarrow I + J \rightarrow 0$$In this sequence, maps are ring homomorphisms or module homomorphisms? And how the above sequence yield the exact seqeunce $$0 \rightarrow R/I \cap J\rightarrow R/I \oplus R/J \rightarrow R/(I + J) \rightarrow 0$$","['modules', 'abstract-algebra', 'exact-sequence']"
177470,complex function with real values on the real interval,"let $ B(0,1) = \{ z\in \mathbb{C} | |z|<1\} $ and $ f $ be an holomorphic function on $ B(0,1) $ such that $ f(z)\in\mathbb{R} \iff z\in\mathbb{R} $ Prove: $ f $ has at most 1 root in $ B(0,1) $ i think this exercise requires rouche theorem or the argument principle theorem but i cant see how to use it",['complex-analysis']
177471,Supermartingale with constant Expectation is a martingale,"In my lecture notes they use the fact, that every supermartingale $(M_t)$ for which the map $t\mapsto E[M_t]$ is constant is already a martingale. Unfortunately I can't prove it. Some help would be appreciated. By definition of a supermartingale we have: $E[M_0]\ge E[M_s]\ge E[M_t]$ for $t\ge s\ge 0$.
I also know that $M_s\ge E[M_t|\mathcal{F}_s]$. If I would take expectation I  would get an equality by assumption. However I do not see how this helps here to prove $M_s= E[M_t|\mathcal{F}_s]$","['probability-theory', 'martingales']"
177522,Do all angles occur in Hilbert spaces?,"Let $X$ be a Hilbert space with scalar product $(\cdot,\cdot)$. Then for two vectors $v,w$ of norm $1$, we can interpret $(v,w)$ as an angle, so that
$(v,w)=\cos(\varphi)$ for a unique angle $\varphi\in[0,\pi)$. My question is the following: Let $\varphi'\in[0,\pi)$ and $v'\in X$ with $\|v'\|=1$ (norm induced by the scalar product) be given. Is there a vector $w'\in X$ with $(v',w')=\cos(\varphi')$? Thank you in advance!","['hilbert-spaces', 'analysis']"
177530,Range of bounded operator is of first category,"Let $T$ be a bounded operator from a Banach Space $X$ to a normed space $Y$ such that $T$ is not onto, but $R(T)\subset Y$ is dense. Prove that $R(T)$ is of first category and not no-where dense. Since $\mathring{\overline{R(T)}}=\mathring{Y}=Y\not=\emptyset$ the range is not nowhere dense but how to see that it is of first category?","['functional-analysis', 'real-analysis', 'banach-spaces']"
177537,How many 4 worded sentences can a list of 5 words make if two of them must be in that sentence?,"Suppose we have:
I am new at this - (5 words)
how many 4 worded sentences can we make with this if ""new"" and ""this"" must appear in the sentence. I think its : .# of sentences we can make with any word in it  - # of sentences we can make with no mention of ""new"" and ""this"" in them so:
$5^4 - 3^4 
= 544$ Is that the right way of doing these type of questions?
Thanks So we just got the solutions from the professor and it seems the answer was 150
He did it by saying: ""new"" and ""this"" appear once: $3c2 *4!$
""new"" appears twice, ""this"" once: $3c1 * 4!/2! $
""this"" appears once, ""new"" twice: $3c1 * 4!/2! $
""this"", ""new"" appear twice: $4!/(2!*2!)$","['permutations', 'combinatorics']"
177538,Finding the convergence interval of $\sum_{n=0}^\infty\frac{n!x^n}{n^n}$.,"I want to find the convergence interval of the infinite series $\sum\limits_{n=0}^\infty \dfrac{n!x^n}{n^n}$ . I will use the ratio test: if I call $u_n = \dfrac{n!x^n}{n^n}$ , the ratio test says that, if the following is true for some values of $x$ , the series will be convergent for these values of $x$ : $$\lim_{n\to+\infty}\left|\frac{u_{n+1}}{u_n}\right|<1$$ So, I will first calculate the value of $\left|\dfrac{u_{n+1}}{u_n}\right|$ : $$\left|\dfrac{\dfrac{(n+1)!x^{n+1}}{(n+1)^{n+1}}}{\dfrac{n!x^n}{n^n}}\right|=\dfrac{(n+1)!|x|^{n+1}}{(n+1)^{n+1}}\times\dfrac{n^n}{n!|x|^n}=\frac{(n+1)n^n|x|}{(n+1)^{n+1}}=|x|\left(\frac{n}{n+1}\right)^n$$ So, $\lim\limits_{n\to+\infty}\left|\dfrac{u_{n+1}}{u_n}\right|$ becomes: $$\lim_{n\to+\infty}\left|\frac{u_{n+1}}{u_n}\right|=\lim_{n\to+\infty}|x|\left(\frac{n}{n+1}\right)^n=|x|\lim_{n\to+\infty}\left(\frac{n}{n+1}\right)^n$$ Now I must evaluate the value of $\lim\limits_{n\to+\infty}\left(\dfrac{n}{n+1}\right)^n$ . For this, let $y = \left(\dfrac{n}{n+1}\right)^n$ ; so, instead of calculating $\lim\limits_{n\to+\infty}y$ , I will first calculate $\lim\limits_{n\to+\infty}\ln y$ : $$\lim_{n\to+\infty}\ln y=\lim_{n\to+\infty}\ln \left(\dfrac{n}{n+1}\right)^n=\lim_{n\to+\infty}n\ln\left(\frac{n}{n+1}\right)
=\lim_{n\to+\infty}\frac{\ln\left(\frac{n}{n+1}\right)}{\frac{1}{n}}$$ Applying L'Hôpital's rule: $$\lim_{n\to+\infty}\frac{\ln\left(\frac{n}{n+1}\right)}{\frac{1}{n}}
=\lim_{n\to+\infty}\frac{\frac{1}{n(n+1)}}{-\frac{1}{n^2}}
=\lim_{n\to+\infty}\left(-\frac{n}{n+1}\right)=-1$$ Now, since we know that $\lim\limits_{n\to+\infty}\ln y = -1$ , we have that: $$\lim_{n\to+\infty}y=\lim_{n\to+\infty}e^{\ln y} = e^{-1} = \frac{1}{e}$$ . Substituting this back into the expression $\lim\limits_{n\to+\infty}\left|\frac{u_{n+1}}{u_n}\right| = |x|\lim\limits_{n\to+\infty}\left(\frac{n}{n+1}\right)^n$ , we have that the limit of $\left|\dfrac{u_{n+1}}{u_n}\right|$ as $n\to+\infty$ is: $$\lim_{n\to+\infty}\left|\frac{u_{n+1}}{u_n}\right|=\frac{|x|}{e}$$ Therefore, the series will certainly be convergent for the values of $x$ for which $\dfrac{|x|}{e}<1$ , that is, $|x|<e$ . So, I know that the series is convergent for $-e < x < e$ , but I have to test whether the series is convergent at $x = e$ or $x = -e$ . That is, I have to test whether $\sum\limits_{n=0}^{\infty} \dfrac{n!e^n}{n^n}$ and $\sum\limits_{n=0}^{\infty} \dfrac{(-1)^nn!e^n}{n^n}$ are convergent. Since these limits don't approach zero, I know they are both divergent, but I'm not sure how to find the limits, because of the factorial function. Also, I can't use integral test here, because of the factorial. Probably I should use comparison test, but I haven't found any divergent series to which to compare it. Any hints? Thank you in advance. Edit: Using the suggestion by Ragib Zaman in the answer below, since the Taylor polynomial $P_n(x)$ of $e^x$ at $a=0$ is $$e^x = 1 + x + \dfrac{x^2}{2!} + \cdots + \dfrac{x^n}{n!}+\cdots,$$ if we substitute $n$ for $x$ we see that $e^n>\dfrac{n^n}{n!}$ ; therefore, $\dfrac{n!e^n}{n^n} > 1$ , and, thus, we show that $\sum\limits_{n=0}^{\infty} \dfrac{n!e^n}{n^n}$ is divergent, because its term doesn't approach zero. $\sum\limits_{n=0}^{\infty} \dfrac{(-1)^nn!e^n}{n^n}$ is also divergent, because, although the absolute value of the ratio between two successive terms, $|e|\left(\frac{n}{n+1}\right)^n$ , approaches 1 as $n\to\infty$ , it approaches 1 from values bigger than 1; therefore, the absolute value of a term is always greater than the absolute value of the previous term.","['sequences-and-series', 'power-series', 'calculus']"
177549,Subspaces of Hilbert Spaces of finite dimension,"Given a Hilbert space $H$ of finite dimension, why is any subspace of this space closed? I tried bashing out an answer using an arbitrary Cauchy sequence $\{ f_1 , f_2, \ldots \} \subset S \subset H $ and trying to show its limit $f \in S$. I keep getting stuck and  suspect there's an easy answer that I'm missing. Could someone enlighten me on this? Thanks in advance!","['general-topology', 'vector-spaces', 'hilbert-spaces']"
177554,How many equivalence classes does $R$ have?,"Let $A=\{a,b,c,d,e\}$. Suppose $R$ is an equivalence relation on $A$. Suppose also that $aRd$ and $bRc$, $eRa$ and $cRe$. How many equivalence classes does $R$ have? My thoughts: (Not sure if I have the right idea...) UPDATED/EDITED Since $R$ is an equivalence relation on $A$ and $aRd$, $bRc$, $eRa$, and $cRe$, then $$R=\{(a,d),(d,a),(a,a),(d,d),(b,c),(c,b),(c,c),\\
      (b,b),(e,a),(a,e),(e,e),(c,e),(e,c)\}$$
(Did I miss any?) So $R$ has $1$ equivalence class: $[a]=[b]=[c]=[d]=[e]=\{a,b,c,d,e\}$",['discrete-mathematics']
177560,Proving determinant product rule combinatorially,"One of definitions of the determinant is: $\det ({\mathbf C})
      =\sum_{\lambda \in S_n} ({\operatorname {sgn} ({\lambda}) \prod_{k=1}^n C_{k \lambda ({k})}})$ I want to prove from this that $\det \left({\mathbf {AB}}\right) = \det({\mathbf A})\det({\mathbf B})$ What I have so far: $(AB)_{k\lambda ({k})} = \sum_{j=1}^n A_{kj}B_{j\lambda(k)}$ so we have for the determinant of $\mathbf {AB}$ $\det ({\mathbf {AB}})
      =\sum_{\lambda \in S_n} ({\operatorname {sgn} ({\lambda}) \prod_{k=1}^n \sum_{j=1}^n A_{kj}B_{j\lambda(k)}})$ Now I'm not sure how to denote this, but the product of the sum I think is the sum over all combinations of n terms, each ranging from 1 to n, so I'll denote
this set of all combinations $C_n(n)$ for n terms each ranging from 1 to n,
analogous to the permutation set, but all combinations instead of permutations. then I get $\det ({\mathbf {AB}})
      =\sum_{\lambda \in S_n} ({\operatorname {sgn} ({\lambda}) \sum_{\gamma \in C_n(n)} \prod_{k=1}^n A_{k\gamma(k)}B_{\gamma(k)\lambda(k)}} )$ then I can at least seperate the product: $\det ({\mathbf {AB}})
      =\sum_{\lambda \in S_n} ({\operatorname {sgn} ({\lambda}) \sum_{\gamma \in C_n(n)} \prod_{k=1}^n A_{k\gamma(k)} \prod_{r=1}^n B_{\gamma(r)\lambda(r)}} )$ I changed the k to an r in one product because it's a dummy variable so I think it doesn't matter, I don't really know if this thing is helpful but this is my attempt at a solution so far. Thanks to anyone who helps!","['matrices', 'linear-algebra', 'determinant', 'combinatorics']"
177567,Smallest possible rank of an $n×n$ matrix that has zeros along the main diagonal and strictly positive real numbers off the main diagonal,A problem in IMC 2012 in which i'm interested but I have no answer. Can you help me? Many thanks. Problem : Let $n$ be a fixed positive integer. Determine the smallest possible rank of an $n\times n$ matrix that has zeros along the main diagonal and strictly positive real numbers off the main diagonal.,"['matrices', 'linear-algebra']"
177595,An interesting pattern in solutions to differential equations,"OK, watch this: Suppose I have a weight on the end of a spring. Assuming the spring obeys Hooke's law, as the weight is displaced from its rest position, the spring exerts a restoring force in the opposite direction who's magnitude is equal to the displacement multiplied by the spring constant. Suppose that $f(t)$ represents the displacement of the weight at time $t$. If we assume that the spring constant and the mass of the weight are both unity, we have $$f''(t) = -f(t)$$ This is an equation involving both $f$ itself and its derivative $f''$, so this is presumably a ""differential equation"". I don't know how to deal with such a thing. But it is clear that this does not yet tell me what $f$ is , only that it must satisfy a specific property. Thinking about this for a moment, it is clear that $f(x) = 0$ has the requested property. This corresponds to the weight remaining stationary for all eternity - a physically valid, but rather ""boring"" result. Contemplating this further, it occurs to me that the derivative of $\sin$ is $\cos$, and the derivative of $\cos$ is $-\sin$. So if $f(t)=\sin(t)$ then $f''(t)=-\sin(t)$, which satisfies the equation. By nearly identical reasoning, $f(t)=\cos(t)$ would also work. In short, if you ping the weight, it oscillates around zero. Now suppose that, by some bizarre mechanism, the restoring force were to somehow be in the same direction as the displacement. Impossible, I know. But imagine. Now our equation becomes $$f''(t)=f(t)$$ Again $f(t)=0$ would work. But what else? Well, there is exactly one function who's derivative equals itself: $\exp$. This is a stronger property than we need, but still, if $f(t)=\exp(t)$ then every derivative of $f$ (including $f''$) would equal $f$. This describes the weight accelerating away exponentially - rather as you might expect. So far, we have two equations. The solution to one is $\sin$. The solution to the other is $\exp$. Two similar equations, two totally different solutions. Or at least, they look different. But now I'm thinking about something Euler once wrote: $$\exp(ix) = \cos(x) + i \sin(x)$$ Say that, and suddenly these solutions don't look so dissimilar at all. Now they suddenly look suspiciously similar! My question: Is this the result of some deep and meaningful connection? Or is it merely a coincidence? Holy smokes, you guys are right! I know, of course, of $\sinh$ and $\cosh$. (For real numbers, they look utterly unrelated. But in the complex plane, one is a trivially rotated version of the other.) What I didn't know, until I looked it up, was the derivatives of these functions. Since they're defined in terms of $\exp$, I was expecting some really complicated derivative. However, what I actually found (as you presumably all know) is that $\sinh'=\cosh$ and, unlike in the circular case, $\cosh'=\sinh$! So yes, for $f''=-f$ we have $f=\sin$ or $f=\cos$, and for $f''=f$ we have $f=\sinh$ or $f=\cosh$. So flipping the sign of the differential equation rotates the function in the complex plane. Physically, it doesn't look very meaningful to talk about complex-valued seconds, but mathematically it all looks vastly too perfect to be mere coincidence.",['ordinary-differential-equations']
177631,Positive part of the kernel,"Let $(E,\mathscr E)$ be a measurable space and $Q:E\times \mathscr E\to\Bbb [-1,1]$ be a signed bounded kernel, i.e. $Q_x(\cdot)$ is a finite measure on $(E,\mathscr E)$ for any $x\in E$ and $x\mapsto Q_x(A)$ is a measurable function for any set $A\in \mathscr E$. For any fixed $x$, let the measure $Q^+_x$ be a positive part of the signed measure $Q_x$ as in Hahn-Jordan decomposition . Is it true that $Q^+$ is a kernel, i.e. is the function $x\mapsto Q_x^+(A)$ measurable for any $A\in \mathscr E$? It clearly holds if $Q$ is an integral kernel, but I am interested in the general case. Update: after three weeks and 1 bounty I decided to post this question also on MO",['measure-theory']
177635,Set of all functions from a finite set to a finite set,"We consider the set $\mathbb{J}$ of all functions $f_i: \{1,2,...,n \} \to \{1,2,...,n \}$, where $n \in \mathbb{N}, i \in \{1,2,...,n^n \}$. We define two functions: $e_1(k)=k$; $e_2(k)=n-k+1$; here $k \in \{1,2,...,n \}$. Let $f^{(m)}=f \circ f \circ ... \circ f$ is a composition of $m$ functions $f$. For example $f^{(4)}=f\circ f\circ f\circ f$. Let $g_1 (m,n)$ is a number of different functions $f_p \in \mathbb{J}$ for which composition $f^{(m)}_p$ is equal to $e_1(k)$. And $g_2 (m,n)$ is a number of different functions $f_q \in \mathbb{J}$ for which composition $f^{(m)}_q=e_2(k)$. Here $k \in \{1,2,...,n \}$. $g_{1,2}(m,n) - ?$. Upd. Thanks Joriki and Countinghaus!","['elementary-set-theory', 'combinatorics']"
177649,Quadratic field such that a certain finite set of primes split,"Given a finite set $S$ of primes, is it possible to find an imaginary quadratic field $K$ such that all primes in $S$ are split completely in $K$?","['algebraic-number-theory', 'number-theory']"
177661,Use of Legendre's equation.,"For some weeks have been studying Legendre polynomial as a solution to this equation. 
$$ (1-x^2)\frac{d^2}{dx^2}f(x)-2x\frac{d}{dx}f(x)+n(n+1)f(x)=0.$$ I've found them very interesting to learn from purely mathematical perspective but I haven't come across their specific use.  Why are they so important and any example suggesting the use of Legendre polynomial would be appreciated. Thank you.","['ordinary-differential-equations', 'orthogonal-polynomials']"
177692,Birthday paradox for non-uniform distributions,"The classic birthday paradox considers all $n$ possible choices to be equally likely (i.e. every day is chosen with probability $1/n$) and once $\Omega(\sqrt{n})$ days are chosen, the probability of $2$ being the same, is a constant. I'm wondering if someone could point me to an analysis that also works for a non-uniform distribution of days?","['reference-request', 'birthday', 'probability']"
177709,Indefinite Integral of $\sqrt{\sin x}$,$$\int \sqrt{\sin x} ~dx.$$ Does there exist a simple antiderivative of $\sqrt{\sin x}$? How do I integrate it?,['integration']
177725,"If a player is 50% as good as I am at a game, how many games will it be before she finally wins one game?","This is a real life problem. I play Foosball with my colleague who hasn't beaten me so far. I have won 18 in a row. She is about 50% as good as I am (the average margin of victory is 10-5 for me). Mathematically speaking, how many games should it take before she finally wins a game for the first time?",['probability']
177760,"What is the difference between empirical distribution , classical probability and axiomatic definition","Can you tell me what is the difference between empirical distribution and classical probability ?
My teacher has told me that when we take limit empirical distribution will get a constant value $$P(A)=\lim_{N\rightarrow\infty}f(A)=\lim_{N\rightarrow \infty}\frac{N(A)}{N}= \mathrm{constant}$$ where $F(A)$ is the frequency ratio, $N(A)$ is the number of  times Event $A$ is found to occur and $N$ is the number of times random experiment repeated But classical probability will give $$P(A)=\lim_{n\rightarrow \infty }\frac{m}{n}= 0$$ but what I know of limit is like this $$\lim_{x\rightarrow\infty}\frac{1}{x}=0$$ Then how come empirical distribution is giving a constant instead of zero? And last can you explain what and why we use axiomatic definition ? Advance thanks for your help... I am a newb to probability statistics","['statistics', 'probability-distributions', 'probability']"
177769,tangents of sums,"In the identity
$$
\cos \left( \sum_i \theta_i \right) = \sum_{\text{even }n\ge0} (-1)^{n/2} \sum_{|I|=n} \prod_{i\in I} \sin\theta_i \prod_{i\not\in I}\cos\theta_i
$$
one can prove the case of finitely many values of $i$ by induction on the number of such values, and questions of convergence are easy to treat when there are infinitely many (and similarly with sines). In the identity
$$
\tan \left( \sum_i \theta_i \right) = \frac{e_1-e_3+e_5-\cdots}{e_0 - e_2 + e_4 -\cdots}
$$
where $e_k$ is the $k$th-degree elementary symmetric polynomial in the variables $\tan\theta_i$, the finite case is similarly routine. What is known about convergence in the infinite case? LATER EDIT: I derived this odd identity that I have not seen elsewhere (so attribute it to me if you mention it in a publication, unless you find it in something earlier): $$
\csc\left( \sum_{i=1}^n \theta_i \right) = \frac{(-1)^{\lfloor(n-1)/2\rfloor}(\csc\theta_1\cdots\cdots\csc\theta_n)}{f_{(n\operatorname{mod} 2)} - f_{(n\operatorname{mod} 2)+2} + f_{(n\operatorname{mod} 2)+4} - \cdots\cdots}
$$
where $f_k$ is the $k$th-degree elemenary symmetric polynomial in the variables $\cot\theta_i$ $\lfloor a\rfloor$ is the greatest integer $\le a$ $(n\operatorname{mod} 2)$ is the remainder on division of $n$ by $2$ so that the $\pm$ in the numerator is
$$
\begin{cases}
+ & \text{if $n=1$ or $2$} \\
- & \text{if $n=3$ or $4$} \\
+ & \text{if $n=5$ or $6$} \\
- & \text{if $n=7$ or $8$} \\
  & \text{etc.}
\end{cases}
$$
A funny thing about this is that to get the case $n-1$ from the case $n$, you would presumably just set $\theta_n=0$, but then the cosecant and the cotangent both blow up.  So you apply L'Hopital's rule, and fully half of the terms in the denominator vanish, if viewed as terms within $f_k$. Can anything sensible be said about $\csc\left(\sum_{i=1}^\infty \theta_i \right)$? And (also my own)
$$
\cot\left(\sum_{i=1}^n \theta_i\right) = (-1)^{n+1} \left( \frac{f_1-f_3+f_5-\cdots}{f_0-f_2+f_4-\cdots} \right)^{(-1)^{n+1}}.
$$
so we have $\text{even}\leftrightarrow\text{odd}$ alternation between the numerator and the denominator every time $n$ is incremented by $1$.  Similar remarks about L'Hopital apply, and the same question about infinite sums can be asked.","['trigonometry', 'sequences-and-series']"
177774,Derivative of $x^x$ at $x=1$ from first principles,Find the derivative of $x^x$ at $x=1$ by definition (i.e. using the limit of the incremental ratio). The only trick I know is $x^x = e^{x \ln x}$ but it doesn't work.,"['derivatives', 'limits']"
177792,showing almost equal function are actually equal,"I am trying to show that if $f$ and $g$ are continuous functions on $[a, b]$ and if $f=g$ a.e. on $[a, b]$, then, in fact, $f=g$ on $[a, b]$. Also would a similar assertion be true if $[a, b]$ was replaced by a general measurable set $E$ ? Some thoughts towards the proof Since $f$ and $g$ are continuous functions, so for all open sets $O$ and $P$ in $f$ and $g$'s ranges respectfully the sets $f^{-1}\left(O\right) $ and $g^{-1}\left(P\right) $ are open. Also since $f=g$ a.e. on $[a, b]$ I am guessing here implies their domains and ranges are equal almost everywhere(or except in the set with measure zero).
$$m(f^{-1}\left(O\right)  - g^{-1}\left(P\right)) = 0$$ I am not so sure if i can think of clear strategy to pursue here. Any help would be much appreciated. Also i would be great full you could point out any other general assertions which if established would prove two functions are the same under any domain or range specification conditions. Cheers.","['measure-theory', 'real-analysis']"
177801,Bounding the $l_1$ norm of a vector,"Let $x$ be real vector with $\|x\|_1=x_1+\ldots +x_{2n}$. How to bound from above $(x_1+\ldots+x_n)(x_{n+1}+\ldots+x_{2n})$ by $l_2$ norm of the vector $x$. Of course, using $\|x\|\leq\sqrt {2n}\|x\|_2$ I can bound
$$
(x_1+\ldots+x_n)(x_{n+1}+\ldots+x_{2n})\leq\|x\|^2_1\leq 2n\|x\|_2^2
$$ But I would like to get an upper bount not greater then $1/2\|x\|_2^2$.  Is it possible to get such a bound?","['normed-spaces', 'inequality', 'functional-analysis']"
177805,Sums of sums of sums of...of numbers,"If we introduce the following notation $$S_r^q=\overbrace{\sum_{a_{r-1}=1}^q\sum_{a_{r-2}=1}^{a_{r-1}}\cdots\sum_{a_1=1}^{a_2}\sum^{a_1}}^{\mbox{a total of $r$ sums}}1$$ for example, $S^q_1=q$, $S^q_2=q(q+1)/2$ and so on, then one can show that $$S^p_{q-1}=S^q_{p-1},$$ where $p$ and $q$ are positive integers. What is the simplest proof of this? I know of one but suspect that there exists simpler ones. Is there any generalisation of this statement. Can somebody also direct me to some references on related material. Thanks a lot in advance!","['sequences-and-series', 'combinatorics']"
177808,Limit point and interior point,"Is any interior point also a limit point? Judging from the definition, I believe every interior point is a limit point, but I'm not sure about it. If this is wrong, could you give me a counterexample? (Since an interior point $p$ of a set $E$ has a neighborhood $N$ with radius $r$ such that $N$ is a subset of $E$. Obviously any neighborhood of $p$ with radius less than $r$ is a subset of $E$. Also, any neighborhood with radius greater than $r$ contains $N$ as a subset, so (I think) it is a limit point.)",['general-topology']
177819,Proving that a metric space is compact,"Let $H^\infty$ be the set of real sequences such that each element in each sequence has $|a_n|\leq 1$. The metric is defined as
$$d(\{a_n\}, \{b_n\}) = \sum_{n=1}^\infty \frac{|a_n - b_n|}{2^n}.$$
Prove that $H^\infty$ is a compact metric space. To prove this, I want to show that every sequence in $H^\infty$ has a convergent subsequence. I know that if we have a sequence $\{\{a_n\}^{(k)}\}$ in $H^\infty$, then for all $i$, the real sequence $\{a_i^{(k)}\}$ has a convergent subsequence, since it is bounded by 1. So we can get a convergent subsequence $\{a_1^{(k_j)}\}$, and then a convergent subsequence of $\{a_2^{(k_j)}\}$, and continue taking subsequences of subsequences until we have a convergent subsequence of $(a_1, a_2, a_3, ..., a_n)^{(k)}$ with $n$ some positive integer if we stop taking subsequences at the $nth$ subsequence; this gives a sequence $\{x_n\}$ where $x_n$ is the limit of the $n$th convergent subsequence of $\{a_n^{(k)}\}$. Ideally, we could show that the sequence in $H^\infty$ converges to $\{x_n\}$. I know that if we have the $nth$ subsequence of $\{\{a_i\}^{(k)}\}$ defined in the way described above, then for any $\epsilon > 0$ there exist $N_1, ..., N_n$ such that if $k\geq \max_{i\leq n}\{N_i\}$, then for $1\leq i\leq n$, $|a_i^{(k)} - x_i| < \epsilon/2n$. By choosing $n$ sufficiently large that $\sum_{i=n+1}^\infty |a_i^{(k)} - x_i|/2^i\leq \sum_{i=n+1}^\infty 1/2^{i-1} < \epsilon/2$, we can ensure that $d(\{a_n\}^{(k)}, \{x_n\}) < \epsilon$. But the problem here is that for each $\epsilon$, we end up choosing a different convergent subsequence of the first $n$ terms (since we need to choose $n$, which determines how many subsequences of subsequences we take). Any idea on how to proceed?","['proof-writing', 'real-analysis', 'analysis', 'metric-spaces', 'compactness']"
177820,"Olympic Badminton, or How to Design a Tournament","Hearing the recent news about disqualified Badminton players in the ongoing 2012 London Olympics got me wondering about how best to design tournaments to avoid situations where players are incentivized to throw matches.  I have no doubt that much has been written about this but I have no idea where to start. Are there any Arrow-like theorems saying that ""ideal tournament design"" is impossible, i.e. given some short-ish list of generally agreeable desirable features of a tournament, one proves that they are contradictory? I'm a novice in this sort of mathematics so feel free to recommend introductory surveys or books as well.","['economics', 'graph-theory', 'game-theory', 'combinatorics']"
177832,Localization at a prime ideal is a reduced ring,"Here is the question that I came up with, which I am having trouble proving or disproving: Let $A$ be a ring (commutative). Let $p \in Spec(A)$ such that $A_p$ is reduced. Then there exists an open neighborhood of $U \subset Spec(A)$ containing $p$ such that $\forall q \in U$, $A_q$ is reduced. Here is some background to my question: I am basically trying to prove that if the stalks at all closed points of a quasicompact scheme are reduced rings, then the scheme is reduced. Since the closure of every point of a quasicompact scheme contains a closed point of that scheme, proving the above commutative algebra statement (if it is true) will yield a proof of this statement about reducedness of quasicompact schemes. If the statement in bold is true, then I guess the neighborhood $Spec(A)-V(A-p)$ should suffice (this is just a guess), but I am running into some problems trying to use this neighborhood to show that the localization at every point of $Spec(A)-V(A-p)$ gives me a reduced ring. So there might be some other neighborhood of $p$ that I am missing, or the statement in bold is not true. Either way, some help would be appreciated (if the statement in bold is true, then I would appreciate hints and not complete answers).","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
177839,A closed form for $T_N = 1 + \sum\limits_{k=0}^{N-2}{(N-1-k)T_k}$?,"I've narrowed down a problem I am working on to the following recurrence: $$\begin{align*}
T_0 &= T_1 = 1\\
T_N &= 1 + \sum_{k=0}^{N-2}{(N-1-k)T_k}
\end{align*}$$ I'm stuck on how to close it up, or at least make it linear or $O(n\log n)$.  Any clues as to what technique I can use to make the sum into a closed form?","['discrete-mathematics', 'sequences-and-series', 'combinatorics']"
