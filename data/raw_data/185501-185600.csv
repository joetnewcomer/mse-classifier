question_id,title,body,tags
3424755,How to prove existence of directional derivates and discontinuity on same point?,"\begin{align} f(x,y) = \begin{cases} \frac{x^3y}{x^6 +y^2} & \text{ if } (x,y) ≠ (0,0) \\ \\  0 & \text{ if } (x,y) = (0,0) \end{cases}. \end{align} Prove that all directional derivates exist on $(0,0)$ and prove that $f$ is
discontinuous on $(0,0).$ For the first part I used a generic vector $v=(v_1,v_2)$ and the definition I have of a directional derivate: \begin{align}
\frac{\partial f}{\partial v} (x_0,y_0)= \lim_{h\to 0}\frac{f(x_0 + hv_1, y_0 + hv_2) - f(x_0, y_0)}{h}
\end{align} So I have: \begin{align}
\frac{\partial f}{\partial v} (0,0)&= \lim_{h\to 0}\frac{\frac{(hv_1)^3hv_2}{(hv_1)^6 +(hv_2)^2}- 0}{h} \\ \\
& = \lim_{h\to0} \frac{h^3v_1^3v_2}{h^6v_1^6+h^2v_2^2} \\ \\
& = \lim_{h\to0} \frac{hv_1^3v_2}{h^4v_1^6+v_2^2} \\ \\
& = 0
\end{align} Since the limit exist for a generic vector it must be true all directional derivates exist. $(?_1)$ For the second part, since $(0,0)$ is a limit point of the domain, limit and continuity definitions are equivalent. So I looked for paths to get closer to $(0,0)$ that they gave me different results: \begin{align}
\lim_{x\to 0}f(x,x³) &= \lim_{x\to 0}\frac{x³x³}{x⁶+x⁶}=\frac{1}{2} \\ \\
\lim_{x\to 0}f(x,0) &= \lim_{x\to 0}\frac{x³(0)}{x⁶+(0)²}=0 \:(?_2)
\end{align} Since the results are different it must be that $f$ is discontinuous on $(0,0)$ . So, I want to check if my reasoning was correct, and also clarify the two doubts I marked: $(?_1)$ Is this statement correct? $(?_2)$ I reason that the numerator is exactly 0, while the denominator is something that tends to zero. So, no matter how small the denominator is, the result must be 0. Is this correct? Thanks in advance and my apologies if I formatted something wrong, first question here.","['multivariable-calculus', 'limits', 'calculus', 'continuity']"
3424758,Evaluating a Lebesgue Integral,"I have the following integral: $$\lim_{n \to \infty} \int_{0}^{1} \frac{n\sqrt{n}x}{1+n^2x^2} \, \mathrm{d}x
$$ To use the dominated convergence theorem I know that limit of $f_n$ is $0$ and $|f_n|<\frac{n^{1/2}}{2}$ . However, I am having trouble to find a function that is greater than $\frac{n^{1/2}}{2}$ for all n. Can someone help? Thanks in advance.","['integration', 'lebesgue-integral', 'definite-integrals', 'real-analysis']"
3424759,How to prove this combinatorial identity without using committee argument but direct manipulation?,"$C(n,r)=C(r,r)\cdot C(n-r,0) + C(r,r-1)\cdot C(n-r,1)+\ldots+ C(r,1)\cdot C(n-r, r-1)+C(r,0)\cdot C(n-r,r)$ Using the committee argument, it is pretty straight forward:
We are dividing $n$ people into two groups $A$ and $B$ each of cardinality $r$ and $n-r$ and then selecting $r$ from these $n$ people in following way: For $0\leq i \leq r$ , We select $i$ from group $A$ in $C(r,i)$ ways  and the remaining $r-i$ from $B$ in $C(n-r,r-i)$ ways. For fixed $i$ , we henceforth select $r$ people from the lot in $C(r,i)\cdot C(n-r,r-i$ ways so that $i$ come from $A$ and $r-i$ come from B(using rule of product, as both tasks are compulsory). Since the task of selecting $r$ people from the lot so that $i$ come from $A$ and $n-i$ come from $B$ is disjoint for each $i$ , the rule of sum gives the above identity. But how do I prove this identity directly using manipulation.",['combinatorics']
3424769,"About primes and their powers in bases $\{2,3,4,5,6,7,8,9,10\}$","For some prime $p=p_{10}$ , where $p_{10}$ means just that that prime is represented in base $10$ , if: *) In at least one base from the set $\{2,3,4,5,6,7,8,9\}$ the number $p^2$ is prime (carefully now, in this context this means that there exists some base $b \in \{2,3,4,5,6,7,8,9\}$ in which the number $p^2$ is represented as $p^2=(a_1...a_{m_b(p^2)})_b$ , but, ""when viewed in base $10$ "" with exactly the same digits we have that it is prime, that is $\alpha(b,10,p^2)=(a_1...a_{m_b(p^2)})_{10}$ is prime) then proceed further to $p^3$ , and, if again some base $b$ from the set $\{2,3,4,5,6,7,8,9\}$ exists such that $\alpha(b,10,p^3)=(a_1...a_{m_b(p^3)})_{10}$ is prime then proceed further to $p^4$ , and proceed as far as possible until there is some $k(p) \in \mathbb N$ such that for every base $b$ from the set $\{2,3,4,5,6,7,8,9\}$ the number $\alpha(b,10,p^{k(p)})=(a_1...a_{m_b(p^{k(p)})})_{10}$ is composite. Some prime number $p$ for which this procedure never ends could be called prime master of bases . Does at least one prime master of bases exist? Honestly, I am not sure that I´m not asking something trivial here. Because, at every step  there are only $8$ allowed choices of bases so if such a prime exists, that would shatter and shake some of my beliefs in the structure of the set of primes. Although I believe that the set $A=\{\text{nos}(p):p \in \mathbb P\}$ where $\text{nos}(p)$ denotes the maximal number of steps that can be done by this procedure for some prime $p$ is unbounded that still does not imply existence of at least one prime master of bases . This is just amateur recreational research, so, if this is something obvious and trivial, pardon. Edit : The response was given in the form of an answer where this question is formulated differently, here is the whole response: ""Not an answer, but I think the question could be made a little clearer. So, suppose $a$ is a positive integer, with base- $b$ representation $(a_1a_2\ldots a_k)_b$ , where $2\le b\le 9$ . Let $a'$ be the integer obtained by re-interpreting $(a_1a_2\ldots a_k)$ in base $10$ , i.e. $a'=(a_1a_2\ldots a_k)_{10}$ . If $a'$ is prime, then $a$ is said to be $10$ -prime in base $b$ . Now your question is simply: are there any primes $p$ such that for every $n\ge 2$ , $p^n$ is $10$ -prime in base $b$ for some $b$ ?""","['number-theory', 'perfect-powers', 'elementary-number-theory', 'prime-numbers']"
3424807,When is a measure a product measure?,"Let $(\Omega_1, \mathcal{A_1})$ and $(\Omega_2, \mathcal{A}_2)$ be two measurable spaces and lets consider the measure space $(\Omega_1\times \Omega_2, \mathcal{A}_1\times \mathcal{A}_2, \mu_p)$ . Under which conditions is it possible to factorize $\mu_p$ meaning that we have $\mu_p=\mu_1\times\mu_2$ where $\mu_1, \mu_2$ are measure on the spaces mentioned. For example, I know that if $\Omega_1=\mathbb{R}^n,\Omega_2=\mathbb{R}^m$ and $\mathcal{A}_1=\mathcal{B}(\mathbb{R}^n), \mathcal{A}_2=\mathcal{B}(\mathbb{R}^m)$ we can write the $n$ -dimensional Lebesgue measure as the product on the individual spaces, which is $\lambda^{m+n}=\lambda^n\cdot\lambda^m$ I also know that it is not always possible if we pick the measurable spaces arbitrarily. So is it always possible if we have something like $\Omega_1=X^n, \Omega_2=X^m$ and create some $\sigma$ -algebras on $X$ in the same way , e.g. the Borel algebra? What in general do I have to assume for this to work?",['measure-theory']
3424847,Prove that if $a \equiv b\pmod m \land n\mid m \land n>0 \Rightarrow a \equiv b \pmod n$,"$a \equiv b\pmod m \land n\mid m \land n>0 \Rightarrow a \equiv b \pmod n$ I tried: $$n\mid m \Leftrightarrow m = kn \\
a \equiv b\pmod {kn} \\
a/kn = q_1 + b \\
a/m = q_2+b$$ What do I do next?","['elementary-number-theory', 'discrete-mathematics']"
3424992,Computing Lebesgue density,"I want to better understand how to compute the Lebesgue density of points in the plane $\mathbb{R^2}$ . Let me recall that the Lebesgue density of $z=(z_1,z_2)$ in some measurable set $E$ is defined as $$d(z;E)=\text{lim}_{r\to 0}\frac{B_r(z)\cap E}{B_r(z)}$$ Let $E=\big\{(x,y):|x|<R,|y|< R\big\}$ and $F=\big\{(x,y):x^2+y^2< R^2\big\}$ for some $R>0$ What is the Lebesgue density of some point $z\in \mathbb{R^2}$ in these two sets? If $z$ is in the interior of E, we can always find a $\delta$ such that $B_{\delta}(z)$ lies entirely inside $E$ , thus the function $\frac{B_r(z)\cap E}{B_r(z)}$ is constant and equal to $1$ for all $r< \delta$ and hence $d(z;E)=1$ in this case. The same exact reasoning can be applied to $F$ to get the same answer. If $z$ is not in the interior of $E$ and is not the closure of $E$ , then there exists a $\delta$ such that $B_{\delta}(z)$ lies entirely outside of $E$ , whence $\frac{B_r(z)\cap E}{B_r(z)}$ is constant and equal to $0$ for all $r< \delta$ and $d(z;E)=0$ ; same for $F$ It remains the case in which $z$ is in the boundary. For the boundary of E: Let $z$ be in the boundary of $E$ ; if $z=(R,y)$ or $z=(x,R)$ , then intuitively the line of the rectangle should cut any ball centered in $z$ in two halfs, one inside $E$ and one outside. Thus $d(z;E)=1/2$ (same thing for $-R$ ). In the case where $z=(R,R)$ (or the other combinations of $R$ , $-R$ ), then there should be exactly $1/4$ of any ball centered in $z$ lying inside of $E$ , hence $d(z;E)=1/4$ . Is it enough to say? How can I be more rigorous? For the boundary of $F$ : Intuitively it should be $1/2$ because in this case there aren't the points $(R,R)$ . But how to prove it rigorously ?","['measure-theory', 'proof-verification', 'analysis', 'real-analysis', 'general-topology']"
3425049,Yugoslavia team selection for IMO 1987 (functions) [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question $f(x)=\frac{\sqrt{2+\sqrt{2}}\;x\;+\;\sqrt{2-\sqrt2}}{-\sqrt{2-\sqrt{2}}\, x\;+\;\sqrt{2+\sqrt2}}$ . Find: $\underbrace {f(f(\ldots(f(x))\ldots)}_{1987\;times}$ Edit: To include some basic thoughts from $5$ months ago, I tried to find a few consecutive compositions, but back then, it seemed the expressions I got applying a composition a few times in a row, it got complicated and I wasn't proficient enough to notice a pattern.","['contest-math', 'radicals', 'functions']"
3425058,Exact solution $\int_0^1 u'v'=v(1/2)$,"This question concerns a variational form of the Laplace equation with homogeneous Dirichlet boundary conditions: $$-u''=f \text{ on } [0,1], u(0)=u(1)=0.$$ Let $V=H^1_0(\Omega), \Omega=[0,1]$ and $f\in H^{-1}(\Omega)$ . Solve $$u\in H_0^1(\Omega) \text{  such that   } \int_{0}^1 u'v'=f_i(v) \text{ for all } v\in H_0^1(\Omega)$$ for i ) $f_1(v)=\int_0^1 v(x)dx, v\in H_0^1(\Omega)$ ii) $f_2(v)=v(\frac12), v\in H_0^1(\Omega)$ For the first one I integrated by parts to get $-\int_0^1 u''v=\int_0^1 v$ so $u''=-1$ and $u(x)=-x^2/2+x/2$ using the boundary conditions. How can I tackle the second one?","['weak-derivatives', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
3425080,Is the Fréchet filter the single biggest filter contained in any free ultrafilter?,"Preliminaries. Let $S$ be an infinite set. We are only going to consider filters in the powerset algebra $\mathcal P(S)$ . In this setting, a filter over $S$ is a subset $\mathcal F \subset \mathcal P(S)$ such that (Closed under intersections) whenever $A,B \in \mathcal F$ , then $A \cap B \in \mathcal F$ , (Monotonicity) whenever $A \in \mathcal F$ and $A \subset B\subset S$ , then $B \in \mathcal F$ , (Properness) $\emptyset \in \mathcal F$ and $F \neq \emptyset$ . A filter $\mathcal U$ is called an ultrafilter , if it satisfies in addition (Maximality) Whenever $A \subset S$ , either $A \in \mathcal U$ or $S\setminus A \in \mathcal U$ . An ultrafilter $\mathcal U$ is called free if $\bigcap \mathcal U = \emptyset$ . The set $\mathcal P_{\text{cof}}(S)$ of cofinite subsets of $S$ is called the Fréchet filter . The Fréchet filter is a filter, but not an ultrafilter (since $S$ is infinite). It turns out that Any ultrafilter containing the Fréchet filter is free, Any free ultrafilter contains the Fréchet filter. Question. Let $\mathcal F$ be a filter over an infinite set $S$ satisfying the following properties. Any ultrafilter containing $\mathcal F$ is free. Any free ultrafilter contains $\mathcal F$ . Any filter $\mathcal G$ strictly containing $\mathcal F$ does not satisfy property 2. In other words, there exists an ultrafilter $\mathcal U$ such that $\mathcal G$ is not a subset of $\mathcal U$ . Does it follow that $\mathcal F$ is the Fréchet filter? Does the Fréchet filter even satisfy property 3.?","['boolean-algebra', 'model-theory', 'logic', 'general-topology', 'set-theory']"
3425107,When is the number of areas obtained by cutting a circle with $n$ chords a power of $2$?,"Also asked on MathOverflow: When is the number of areas obtained by cutting a circle with $n$ chords a power of $2$ ? Introduction Recently, a friend told me about the following interesting fact: Place $n$ points on a circle and draw a line between every pair of points. Suppose that no three lines intersect at one point. Then the number of regions which are separated by the lines is equal to the sum of the first five numbers in the $n-1$ st row of Pascal's triangle! See this image image (from Wikipedia ). Here, $n$ is the number of points, $c$ is the number of lines and $r_G$ is the number of regions: Here is a great video by 3Blue1Brown on this subject: Circle Division Solution . The series is A000127 in the OEIS. Preliminary results The following is known (see again Wikipedia for instance): For $n$ points, the number of resulting regions is $$1+\binom n2+\binom n4 = \sum_{i=0}^4 \binom{n-1}i=\text{sum of first } 5 \text{ numbers in $n$th row of Pascal's triang.}=\frac{1}{24}n(n^3-6n^2+23n-18)+1.$$ In particular, for $n\in\{1,2,3,4,5,10\}$ , the number of areas is a power of $2$ . My question Is it true that, for any other $n$ , the number of areas is not a power of two? Some attempts First off, we can simply check that for $n\in\{6,7,8,9\}$ , the number of areas is not a power of two. So the question is equivalent to: Is it true that, for any $n\geq 11$ , the number of areas is not a power of $2$ ? The following Proposition is easy to prove: Proposition. For $n> 5$ , we have that $f(n)< 2^{n-1}$ , where $f(n)$ denotes the number of regions. Proof. For $n>5$ we have $$f(n)=\sum_{i=0}^{n-1} \binom{n-1}i-\sum_{i=5}^{n-1}\binom{n-1}i = 2^{n-1}-\sum_{i=5}^{n-1}\binom{n-1}i<2^{n-1}.\square$$ However, this only proves that $f(n)\neq 2^{n-1}$ for any $n>6$ . There could still be some $m\in\mathbb N$ with $m<n$ such that $f(n)=2^m$ .","['number-theory', 'combinatorics', 'circles', 'diophantine-equations']"
3425114,Is there a partial exterior derivative?,The exterior derivative is a map $\text d:\Omega^k\rightarrow\Omega^{k+1}$ . We can divide two differential forms to get the ordinary derivative: $$\dfrac {\text df}{\text dx}=D_xf.$$ Is there an analogous map for partial derivatives? A map $\partial$ such that $$\dfrac {\partial f}{\partial x}=\partial_xf?$$,"['exterior-derivative', 'partial-derivative', 'derivatives', 'differential-forms', 'exterior-algebra']"
3425154,The limit of the ratio of polygamma functions,"I want to calculate this quantity: $$\lim_{x \rightarrow \infty}\frac{\Psi_1 (x)}{\Psi_1 (x + y)}$$ where $$\Psi_1 (x)=\frac{d^2}{dx^2}\log \Gamma (x)=\sum_{k=0}^{\infty}\frac{1}{(x+k)^2}. $$ I guess it is $1$ , but I am not sure about my proof. My proof is following: Let $\epsilon > 0$ be given. Since $\Psi_1 (x)$ is convergent on $(0, \infty)$ and decreasing, for any $x, y >0$ there exist $K=K(\epsilon) < \infty$ such that $\sum_{k=K+1}^{\infty} \frac{1}{(x + y + k)^2} < \sum_{k=K+1}^{\infty} \frac{1}{(x + k)^2} \leq \epsilon$ . Then, we have \begin{align*}
       &\frac{\Psi_1 (x)}{\Psi_1 (x + y)} \leq \Bigg( \sum_{k=0}^{K} \frac{1}{(x + k)^2} + \sum_{k=K+1}^{\infty} \frac{1}{(x + k)^2} \Bigg) \Bigg/ \Bigg( \sum_{k=0}^{K} \frac{1}{(x + y + k)^2} \Bigg)\\
       %&\leq \Bigg( \sum_{k=0}^{K} \frac{1}{(x + k)^2} - \frac{1}{(x + y + k)^2}  \Bigg) \Bigg/ \Bigg( \sum_{k=0}^{K} \frac{1}{(x + y + k)^2} \Bigg) + 2\epsilon\\
       &\leq \Bigg( \frac{K+1}{x^2} + \sum_{k=K+1}^{\infty} \frac{1}{(x + k)^2} \Bigg) \Bigg/ \Bigg( \sum_{k=0}^{K} \frac{1}{(x + y + k)^2} \Bigg)\\
       &= \Bigg( \frac{K+1}{x^2} \Bigg) \Bigg/ \Bigg( \sum_{k=0}^{K} \frac{1}{(x + y + k)^2} \Bigg)
       + \Bigg( \sum_{k=K+1}^{\infty} \frac{1}{(x + k)^2} \Bigg) \Bigg/ \Bigg( \sum_{k=0}^{K} \frac{1}{(x + y + k)^2} \Bigg)\\
       & \leq \Bigg( \frac{K+1}{x^2} \Bigg) \Bigg/ \Bigg( \frac{K+1}{(x + y + K)^2} \Bigg)
       + \Bigg( \sum_{k=K+1}^{\infty} \frac{1}{(x + k)^2} \Bigg) \Bigg/ \Bigg( \sum_{k=0}^{K} \frac{1}{(x + y + k)^2} \Bigg)\\
       & = \frac{(x + y + K)^2}{x^2}
       + \Bigg( \sum_{k=K+1}^{\infty} \frac{1}{(x + k)^2} \Bigg) \Bigg/ \Bigg( \sum_{k=0}^{K} \frac{1}{(x + y + k)^2} \Bigg).
\end{align*} In the last line, the first term goes to $1$ as $x \longrightarrow \infty$ for any fixed $K$ . For the second term, since we can choose arbitrarily large $K$ and $\Psi_1$ is convergent, it goes to $0$ as $K \longrightarrow \infty$ for any fixed $x>0$ . Thus, we have $\frac{\Psi_1 (x)}{\Psi_1 (x + y)} \leq 1$ as $x \longrightarrow \infty$ . On the other hand, since $\Psi_1(x)$ is decreasing in $x$ , \begin{equation*}
    \frac{\Psi_1 (x)}{\Psi_1 (x + y)} \geq 1 \text { for any } x, y >0.
\end{equation*} Thus, \begin{equation*}
    \frac{\Psi_1 (x)}{\Psi_1 (x + y)} \longrightarrow 1  \text { as } x \longrightarrow \infty.
\end{equation*} Am I correct? I think I am cheating somewhere. I can't convince myself.","['polygamma', 'analysis', 'real-analysis', 'power-series', 'limits']"
3425195,Stuck working through example of $\mathbb Q$-Gorenstein variety in Algebraic Geometry V,"I'm looking at the following example on page 8 of Algebraic Geometry V by Iskovskikh. I've been trying to show that $-K_X = 3E$ . I'll outline my work so far. Let the vertex of $X$ be $p$ . Then $X \backslash p$ is equipped with a projection map $\pi$ to $F_4$ , which gives $X \backslash p$ the structure of an $\mathbb A^1$ bundle. Thus $Cl X \cong Cl (X \backslash p) \cong Cl (F_4) \cong \mathbb Z$ . Examination of the isomorphism tells us that $Cl(X)$ is generated by a hyperplane section. We also have a map $\iota: Cl(X) \to Cl(F_4)$ given by restriction to the copy of $F_4$ at infinity (that is, at $Z(x_6)$ ). This map need only be nonzero to be injective. In fact it takes a general hyperplane section to twice a generator of $CL(F_4)$ , which we can see by first intersection with $Z(x_6) \cong \mathbb P^5$ and observing that $F_4 \hookrightarrow \mathbb P^5$ is induced by $\mathcal O(2)$ . My idea now is to calculate $K_X$ and show that $\iota(K_X) = -3\iota(E)$ , which by injectivity will yield the result. By a slight abuse of notation and the adjunction formula $\mathcal O_{\mathbb P^2}(-3) \cong K_{F_4} \cong K_X|_{F_4} \otimes \mathcal O(X \cap Z(x_6))|_{F_4}^\vee$ . Replacing $X \cap Z(x_6)$ by a general hyperplane section, we find that $\mathcal O(-5) \cong K_X|_{F_4}$ . I now seem to have contradicted myself: if $\iota(K_x) = -3\iota(E)$ we would have $-3 | 5$ . What is my mistake? How does one demonstrate that $-K_X = 3E$ ?","['divisors-algebraic-geometry', 'algebraic-geometry', 'projective-space']"
3425196,Is the limit of a recursively defined sequence always a fixed point?,"Let $(x_n)$ be a sequence of real numbers such that $x_{n+1}=f(x_n)$ for all natural numbers $n$ , where $f$ is a function from $\mathbb{R}$ to $\mathbb{R}$ .  And suppose that $(x_n)$ converges to some real number $x$ .  Then my question is, is it necessarily true that $f(x)=x$ ? Clearly it's true if $f$ is continuous, since $f(x_n)\rightarrow f(x)$ and $f(x_n)=x_{n+1}\rightarrow x$ .  But what about the general case?","['fixed-point-theorems', 'real-analysis', 'calculus', 'sequences-and-series', 'convergence-divergence']"
3425231,Prove $\zeta(3)=2\sum_{n=1}^\infty\frac{H_n}{n}\left[\frac1{4^n}{2n\choose n}\left(H_{2n}-H_n-\frac1{2n}-\ln2\right)+\frac1{2n}\right]$,"How to prove $$\zeta(3)=2\sum_{n=1}^\infty\frac{H_n}{n}\left[\frac1{4^n}{2n\choose n}\left(H_{2n}-H_n-\frac1{2n}-\ln2\right)+\frac1{2n}\right]$$ where $H_n$ is the harmonic number and $\zeta$ is the Riemann zeta function. This problem is proposed by Cornel which can be found here and no solution has been submitted yet. I know the following identity $$H_{2n}-H_n-\ln2=-\int_0^1\frac{x^{2n}}{1+x}dx$$ is related but I do not know how to exploit it. I prefer a solution without calculating each sum separately because if we seperate, all these sums are calculated here but the first one $\sum_{n=1}^\infty\frac{H_nH_{2n}}{n4^n}{2n\choose n}$ .","['integration', 'harmonic-numbers', 'calculus', 'sequences-and-series', 'riemann-zeta']"
3425237,Theorem 2.1.5 in Durrett's Probability Theory and Examples- don't understand the proof in the book,"I'm reading Durrett's Probability Theory and Examples (4th ed.) and I am having a hard time understanding the proof of Theorem 2.1.5: Suppose $\mathcal{F_{i,j}}$ , $1\leq i \leq n$ , $1\leq j \leq m(i)$ are independent and let $\mathcal{G_{i}}=\sigma(\bigcup_{j}\mathcal{F_{i,j}})$ . Then $\mathcal{G_{1}},...,\mathcal{G_{n}}$ are independent. Proof in Durrett: 
Let $\mathcal{A_{i}}$ be the collection of sets of the form $\bigcap_{j}A_{i,j}$ where ${A_{i,j}}\in\mathcal{F_{i,j}}$ . $\mathcal{A_{i}}$ is a $\pi$ -system that contains $\Omega$ and contains $\bigcup_{j}\mathcal{F_{i,j}}$ so theorem 2.1.3 implies that $\sigma(\mathcal{A_{i}})=\mathcal{G_{i}}$ are independent. I don't understand a couple of things in this proof: i) why does $\mathcal{A_{i}}$ contain $\bigcup_{j}\mathcal{F_{i,j}}$ ?   I've tried proving that an element of $\bigcup_{j}\mathcal{F_{i,j}}$ must be in $\mathcal{A_{i}}$ , but to no avail as of yet. ii) even if I prove that $\bigcup_{j}\mathcal{F_{i,j}}\subset \mathcal{A_{i}}$ does the fact then somehow imply that $\sigma(\mathcal{A_{i}})=\sigma(\bigcup_{j}\mathcal{F_{i,j}})=\mathcal{G_{i}}$ ? I've been struggling with this for a while and have run out of ideas on how to prove this or what Durrett is doing here. Any insight would be much appreciated!","['measure-theory', 'probability-theory']"
3425247,Finding the order of a group using coset enumeration given the group presentation,"I have the following group presentation: $$G=\langle a,b:a^5=b^3=(ab)^2=1\rangle.$$ I've used MAPLE to determine that $|G|=60$ . I'm now attempting to do this using the Coxeter-Todd algorithm by hand. Using the algorithm, I've found $12$ cosets and that $\langle x,y\rangle$ with $$x=(2,3,4,5,6)(7,10,12,13,8)~~\text{and}~~y=(1,2,3)(4,6,7)(5,8,10)(12,13,14)$$ generates a group of order $60$ satisfying the relations given in the presentation (also checked with MAPLE). Note that I didn't simplify after finding that $7=11$ and $8=9$ . I.e. this could be relabeled with $10=9,12=10,13=11,14=12$ . I'm stuck in justifying that my result does in fact give $|G|$ . My thoughts are to use Lagrange's theorem to put an upper bound on $|G|$ and disjoint cycle enumeration to put a lower bound on $|G|$ . My issue is that I don't actually know the orders of elements in $G$ . If I were sure that the order of $a$ is $5$ , then I could let $H=\langle a\rangle$ so that $|H|=5$ and then $|G|=[G:H]|H|\leq12\cdot|H|=60$ . Similarly, naively assuming the orders of $a$ , $b$ , and $ab$ to be $5$ , $3$ , and $2$ respectively would suggest that a lower bound on $|G|$ is $2\cdot3\cdot5=30<60$ , so I'm stuck here as well.","['group-presentation', 'group-theory']"
3425250,What is the name of this graph theory concept?,"I'm writing notes for my discrete math students and I'm trying to explain transitivity. There's a theorem I want to write down, but I'm not sure if there is a standard name for the object I construct. Let $R$ be a relation on a set $X$ and let us call a path a finite sequence $x_1x_2 \ldots x_n$ where $x_i$ is related to $x_{i+1}$ . If $R$ is transitive then each path has the property that $x_1$ is related to $x_n$ . I'd like to say, ""In a transitive relation every path is [blank]."" I'm not sure what goes in the blank, if there is standard terminology for a path whose beginning is connected by a directed edge to its end. It's not a circuit, since it's not the case that $x_n$ is related to $x_1$ necessarily. It's not just ""closed,"" is it? Thanks in advance. Edit: I apologize if my wording is unclear. I mean to ask if there is a standard name for a directed path $x_1 \to x_2 \to \cdots \to x_n$ where there is also a directed edge $x_1 \to x_n$ .","['graph-theory', 'relations', 'discrete-mathematics']"
3425261,How to evaluate an algebraic function at a place of an algebraic curve?,"Given a field $K$ and an irreducible polynomial $f(x,y) \in K[x,y]$ that defines an algebraic curve, we can construct the maximal order $O$ , consisting of all algebraic function with finite values at all finite points, and define a place as a prime ideal in $O$ . We need to distinguish between points (prime ideals in the coordinate ring $K[x,y] \bmod f$ ) and places (prime ideals in the maximal order $O$ ) in order to handle singularities, where there are multiple places at a single point. For example, the curve $y^2 = x^3+x^2$ has a singularity at the origin; there are two places at a single point: A function like $x/y$ can not be evaluated at the origin just by plugging in values for $x$ and $y$ .  Not only do you get zero divided by zero, but the value is indeterminate because we need to specify which branch of the curve we're on, i.e, which place .  Once we've specified one of the two places/branches, we can then ask for the value of $\lim_{(x,y)\to(0,0)} x/y$ . We can do a lot of this calculation in Sage 9: sage: K.<x> = FunctionField(QQbar); _.<Y> = K[]
sage: A.<y> = K.extension(Y^2-(x^3+x^2))
sage: OA=A.maximal_order()
sage: OA.basis()
(1, 1/x*y)
sage: OA.ideal(x,y)
Ideal (x) of Maximal order of Function field in y defined by y^2 - x^3 - x^2
sage: OA.ideal(x,y).factor()
(Ideal (1/x*y - 1) of Maximal order of Function field in y defined by y^2 - x^3 - x^2) * 
(Ideal (1/x*y + 1) of Maximal order of Function field in y defined by y^2 - x^3 - x^2) This tells us: The basis for the maximal order $O$ as a $K[x,y]$ -module is $\{1,y/x\}$ , i.e, $\{1,y/x\}$ is an integral basis for this curve, and all algebraic functions with finite values at all finite places can be written as $a+b(y/x)$ where $a,b \in K[x,y]$ , There's a singularity at the origin, since the ideal (in $O$ ) generated by $x$ and $y$ is not prime, The prime factors of the ideal correspond to the two places of the curve at the origin, and The value of $y/x$ is $1$ at the one place and $-1$ at the other. So we can conclude that the value of $x/y$ is also $1$ at the place represented by Ideal (1/x*y - 1) and $-1$ at the place represented by Ideal (1/x*y + 1) . My question: given the irreducible polynomial $f(x,y)$ and the generators of one of these prime ideals in $O$ , how to compute the value of an arbitrary algebraic function like $x/y$ ?  The example I gave is easy, but how to do it in general? An obvious way is to approach it as a limit, but I'm not even sure that I can guarantee that L'Hospital's rule always terminates here.  Also, I'm looking for a more algebraic approach.  Obviously, substituting in values for $x$ and $y$ works in some cases, but how do I deal with the cases where that produces $0/0$ ?","['algebraic-curves', 'algebraic-geometry']"
3425303,Asymptotic behavior of piecewise recursive random variable.,"I have sequence of random variables defined by the following recursion: $$X_{n+1} = X_n+\begin{cases} \alpha(S_n - X_n), \text{ if } S_n > X_n \\
\beta(S_n - X_n), \text{ if } S_n < X_n,
\end{cases}$$ where $0<\beta < \alpha <1$ are constants, $(S_n)$ are i.i.d with known distributions. Also, $S_n$ independent of $\sigma(X_1, X_2,\dots, X_n)$ and $X_ 0 = 0.$ Initially, I asked about the convergence/limiting distribution of $X_n,$ but after doing some research, I realize that it is generally considered a very difficult problem - to obtain explicit distribution/asymptotics. Therefore, I want to ask following questions with increasing orders of difficulties (according to my very limited probability theory knowledge.) 1) Can we at least prove that it has a limiting distribution? It looks like one can formulate this as a general state space Markov Chain but there do not seem to be an abundance of sources on this topic. Probability by Durrett has a brief chapter on it and he mentions that discrete Orstein- Uhlehnbeck process: $$V_{n+1} = \theta V_n+\xi_n$$ is an example of a discrete time, general state space Markov Chain. However, most of the resources I could find on the internet refers to the continuous one and as such my hope of modifying proofs for OU did not pan out. 2) If there is a limiting distribution, what kind of qualitative results can I hope to achieve? For example, one has the following for the expected value: $$\mathbb{E}[X_{n+1}] = \mathbb{E}[X_n](1 - \beta ) + \beta\mu + ( \alpha - \beta)\mathbb{E}[\delta_n\mathbb{1}_{\delta_n >0}],$$ where $\delta_n = S_n - X_n,$ and $\mu = \mathbb{E}[S_n].$ But then, the issue I am having is manipulating: $$P(S_n - X_n > t|S_n > X_n)$$ ,
which will come from the last term. I will greatly appreciate if anyone has some ideas or point me to a helpful source. Simulation: I attach some simulations that seem to suggest that there is a bounded, limiting distribution.","['conditional-expectation', 'markov-chains', 'stochastic-processes', 'martingales', 'probability']"
3425349,"Let $f:[a,b] \to \mathbb{R}$ be differentiable s.t. $f'(x) \neq 1 \ \forall x$. Then $f$ has at most one fixed point.","Let $f:[a,b] \to \mathbb{R}$ be a differentiable function s.t. $f'(x)
> \neq 1 \ \forall x \in [a,b]$ . Prove that $f(c)=c$ has at most one
  solution $c \in [a,b]$ . My attempt: Let $f'(x) \neq 1 \ \forall x \in [a,b]$ but suppose $\exists \ c_1, c_2 \in [a,b], c_1 \neq c_2$ s.t. $f(c_1) = c_1$ and $f(c_2) = c_2$ . Then by the Mean Value Theorem $\exists  \ d \in [c_1, c_2]$ s.t. $f'(d) = \frac{f(c_1) - f(c_2)}{c_1 - c_2}$ $= \frac{c_1 - c_2}{c_1 - c_2} = 1$ which is a contradiction since $f'(x) \neq 1 \ \forall x \in [a,b]$ . Hence, there is at most one fixed point. $\Box$ I was able to show that the number of fixed points cannot be greater than $1$ . Do I need to show the possible existence of such a point if at all it exists? Or is this it?","['proof-verification', 'derivatives']"
3425365,Integrating sine and cosine with respect to the triangle legs?,"Consider a circle centered at the origin of the $x$ - $y$ plane with radius $R.$ Then: $$\sin \theta = \frac{y}{R}$$ But say I want to take an integral using this relationship. $$\int\sin \theta \, d\theta$$ Substituting $$\int \frac{y}{R} \, d\theta$$ There is no theta anymore to take the integral with respect to. Does this then become? $$\int\frac{y}{\sqrt{x^2+y^2}} \, dy$$ But when I integrate I get $$\sqrt{x^2+y^2} + c$$ which doesn't look like cosine of anything. What am I missing?","['integration', 'trigonometry']"
3425372,"Is it possible to represent the natural number ""1"" as the sum of p-series in this way?","My argument: $$1=(\frac{1}{2})^2+(\frac{1}{3})^2+\cdots+(\frac{1}{2})^3+(\frac{1}{3})^3+\cdots=\sum_{k=2}^\infty (\frac{1}{k})^2+\sum_{k=2}^\infty (\frac{1}{k})^3+\cdots .$$ Explanation) First, for any natural number $n\geq2$ , the following holds: $$\sum_{k=1}^\infty (\frac{1}{n})^k=(\frac{1}{n})+(\frac{1}{n})^2+(\frac{1}{n})^3+\cdots= \frac{\frac{1}{n}}{1-\frac{1}{n}}=\frac{1}{n-1}.$$ (the infinite geometric series.) So, we obtain $$1=(\frac{1}{2})+(\frac{1}{2})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{2})^k,$$ $$\frac{1}{2}=(\frac{1}{3})+(\frac{1}{3})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{3})^k,$$ $$\frac{1}{3}=(\frac{1}{4})+(\frac{1}{4})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{4})^k,$$ and so on. From above equalities, $$1=(\frac{1}{2})+(\frac{1}{2})^2+\cdots$$ $$=((\frac{1}{3})+(\frac{1}{3})^2+\cdots)+(\frac{1}{2})^2+(\frac{1}{2})^3+\cdots$$ $$=((\frac{1}{4})+(\frac{1}{4})^2+\cdots)+(\frac{1}{3})^2+(\frac{1}{3})^3+\cdots+(\frac{1}{2})^2+(\frac{1}{2})^3+\cdots$$ $$=\cdots .$$ If $p\ge2$ , then p-series absolutely converges. Hence we can change the order of terms in series as follows: $$1=(\frac{1}{2})^2+(\frac{1}{3})^2+(\frac{1}{4})^2+\cdots$$ $$+(\frac{1}{2})^3+(\frac{1}{3})^3+(\frac{1}{4})^3+\cdots$$ $$+(\frac{1}{2})^4+(\frac{1}{3})^4+(\frac{1}{4})^4+\cdots$$ $$=\sum_{k=2}^\infty (\frac{1}{k})^2+\sum_{k=2}^\infty (\frac{1}{k})^3+\sum_{k=2}^\infty (\frac{1}{k})^4+\cdots.$$ Thus, ""1"" becomes the sum of p-series(exactly from $k=2$ to infinity). Is this explanation correct?",['sequences-and-series']
3425415,How to define an Order Preserving Bijection $f$ from rationals to rationals such that $f(0) = 0$ and $f(1) = 1$ that is not the identity function,"I need to define a bijection $f:\mathbb Q\to\mathbb Q$ such that $f(0) = 0$ and $f(1) = 1$ while also preserving order (i.e. if $a < b$ , then $f(a) < f(b)$ ). Also, $f$ cannot be the identity function. Whenever I try to come up with a function, it either becomes not injective, not surjective, or it does not preserve order. Any help would be appreciated.","['elementary-set-theory', 'abstract-algebra', 'logic']"
3425480,Find analytic Functions such that $f'(z)=-2f(z)$,"Find all analytic functions $f:\mathbb{C} \longrightarrow \mathbb{C}$ such that $$f'(z)=-2f(z),~z \in \mathbb{C}$$ and $$f(0)+f'(0)=1$$ the only thing that majorly concerns me is making sure my answer is unique. as i'm sure it's possible that there may be a class of functions anyway the preferred method i believe is to expand these as power series such as $$\sum_{n=0}^{\infty}na_nz^{n-1} = -2\sum_{n=0}^{\infty}a_nz^{n}$$ do a bit of rearranging and then use the fact that co-effecient of power series are uniquely defined. i'm sure theres a bit of rearranging magic to be done as considering the co-effecients at the moment gives $$na_n = -2 a_n$$ which of course only happens at $n=-2$ apparently, but we have it that $n\geq0$ so that doesn't make sense. i can either presume there to be no solution or try the aforementioned rearrangement magic. by all means if you have a hint for how to solve this using the power series i'm all ears. anyway, the method i used.
we have $$f'(z)=-2f(z)$$ and these are meant to be analytic, so they're differentiable and integratable. so considering it to be a first order homogeneous ODE we solve using integrating factor $$f'(z)+2f(z)=0 \implies$$ $$e^{2z}f'(z)+2e^{2z} = 0 \implies$$ $$\frac{d}{dz}\left(e^{2z}f(z)\right) = 0 \implies$$ $$e^{2z}f(z) = C \implies$$ $$f(z) = Ce^{-2z}$$ Differentiating and using the initial conditions given above we have $$f'(z) = -2Ce^{-2z}$$ and $$f'(0)+f(0)=1 \implies -2Ce^{0}+Ce^{0} = 1 \implies$$ $$-C=1 \implies C = -1$$ so $$f(z) = -e^{-2z}$$ which indeed satisfies the requirements of both being analytic and the initial conditions. now, with ODE's we use Initial conditions in order to guarantee uniqueness of solutions but assuming that $$f(z) = -e^{-2z} + D$$ is also a solution, plugging this into the above we obviously get $D = 0$ but.... is this function unique? and is this a valid arguement Cheers for the help. Incidently i've just figured out how to do it via power series. Consider a generating function $$f(z) \leftrightarrow a_0,a_1,a_2,a_3,...a_n$$ then $$2f(z) \leftrightarrow 2a_0,2a_1,2a_3,...,2a_n$$ and $$f'(z) \leftrightarrow a_1,2a_2,3a_3,...,n a_n$$ then for the equation $$f'(z)+2f(z) = 0$$ we collate co-effecients and get $$a_1 + 2a_0 = 0$$ $$2a_1+2a_2 = 0$$ etc...
Rearranging we get $$a_1 = -2a_0$$ $$a_2 = -a_1$$ $$a_3 = -\frac{2}{3}a_2$$ ... etc
back substituting we get $$f(z) \leftrightarrow a_0,-2a_0,2a_0,-\frac{4}{3}a_0,\frac{4}{6}a_0,...,\frac{(-2)^{n}}{n!}$$ this implies then that $$f(z) = a_0\sum_{n=0}^{\infty}\frac{(-2)^{n}}{n!}z^n$$ which is agrees with the above, ie $ f(z) = a_0 e^{-2z} $ using initial conditions again gives us $a_0$ = -1 and so $$f(z) = -e^{-2z}$$ so i was correct i believe. if someone could confirm, i'd greatly appreciate it.","['ordinary-differential-equations', 'proof-verification', 'complex-analysis', 'power-series', 'analytic-functions']"
3425486,"Locating the focus, vertex, and directrix of a conic when viewed as a plane section of a cone","The following image is from the Wikipedia Article on Conic Section : Where are the focus, vertex and the directrix in the above diagram? I know they must lie on the plane which cuts the right circular cone, but I am unable to determine their position. For the circle in the lower cone in $(2)$ , I concluded that the centre is the point where the axis of the cones intersect the slicing plane due to symmetry reasons. But things get tricky when I move on to other conics. Kindly explain in a simple way that could be understood by a High School student. Thank you in advance.","['conic-sections', 'geometry']"
3425523,How do I find the least number tickets from a jar if the number isn't explicitly given?,"The problem is as follows: In a jar there are tickets of the same size and color which have a
  number printed from $10$ to $\left(4n+10\right),\, n\geq 2,\,n \in
> \mathbb{N}$ .How many tickets could be taken out at random from the
  jar the least possible to be certain that among the tickets extracted
  there are $3$ having an odd number printed?. The alternatives given in my book are as follows: $\begin{array}{ll}
1.&2n+1\\
2.&2n+2\\
3.&2n+3\\
4.&2n+4\\
\end{array}$ I'm confused about this problem. What I believe the procedure to solve this is to think about the worst case and add to that the elements requested so we can claim that we have what it is being asked. This task could be much easier if I had known the number of elements explicitly let's say a number belonging to $n \in \mathbb{N}$ , but having it defined by a constant not indicated by a formula. The next thing which I attempted to do was that the worst case would be taking out all even numbers from $10$ to $\left(4n+10\right),\, n\geq 2,\,n \in \mathbb{N}$ and adding to that $3$ as then we can claim we have three odds. But since the number of elements is not given explicitly I could obtain them by subtracting the total from the number of all odds and adding $3$ to that. Thus I counted (considering not making the fencepost error ). Total: $\left(4n+10\right)-10+1=4n+1$ Total of all odds: $11+(n-1)2-11+1=2n-1$ Therefore the total needed to be extrated from that jar would be: $4n+1-(2n-1)+3= 2n+5$ But this answer doesn't appear within any of the alternatives. What could be the part where I got it wrong?. Can somebody help me with this?.","['word-problem', 'algebra-precalculus', 'probability', 'recreational-mathematics']"
3425545,Interpreting probability over 100% and math check,"I'm in no way good at probabilities, so I might have done something terribly wrong. Please bear with me! We are looking at the probability of drawing exactly 3 cards of any suit when you draw 13 cards simultaneously from a full deck of 52 with no replacement. 
I have calculated as follows: $$
4\cdot \frac{  {13 \choose 3} {39 \choose 10 }  }{ {52 \choose 13}  } )= 114~\%
$$ 1) Does my math seem ok? 2) If my math checks out, how do I interpret a probability of more than 100%? That shouldn't even be possible as far as my non-mathematical mind is concerned. I really hope one of you guys have a minute to take a look at it. It would be truly appreciated. Have a nice day.","['card-games', 'probability-distributions', 'probability-theory', 'probability']"
3425552,Is differential geometry related to partial differential equations?,I am doing my PhD in real analysis and besides I am studying differential geometry. I have heard that differential geometry is related to PDE. Can anyone please suggest me some books regarding this? I am also interested to know what kind research work are going on this topic.,"['partial-differential-equations', 'differential-geometry']"
3425573,Are projective modules related to projective spaces?,"I am aware of the possible motivations for calling ""projective"" a projective module (such as, for example, these ). However, I have been asked by a student if there is some connection between projective modules and projective spaces, since they share a common name. After a first moment in which I have been tempted to answer negatively, I realized that I actually don't know if this is the case or not. Does anybody have ever thought about this?","['projective-module', 'abstract-algebra', 'soft-question', 'projective-space']"
3425598,Show $\limsup _{t \to \infty} \frac{B_t}{\sqrt{t \ln t}} \leq 1 $ using the fact that $\frac{e^{B_t ^2 / (1+2t)}}{\sqrt{1+2t}}$ is a martingale.,"For a standard Brownian motion $(B_t)_{t \geq 0}$ , I want to show that $$\limsup _{t \to \infty} \frac{B_t}{\sqrt{t \ln t}} \leq 1 \ \ \text{a.s.}$$ using the fact that $\frac{\exp(B_t ^2 / (1+2t))} { \sqrt{1+2t}}$ is a martingale. It suffices to show $\limsup _{t \to \infty} \frac{B_t ^2}{t \ln t} \leq 1 \ \ \text{a.s.}$ and I know that $\frac{B_t ^2}{t \ln t} \leq \frac{B_t ^2} {1+2t}$ for large $t$ , but I don't see any further. Any help is appreciated.","['stochastic-processes', 'martingales', 'brownian-motion', 'probability']"
3425600,$(z-1)^5 = z^5$ for complex $z$,"So the question asks to find $z \in \mathbb{C}$ such that $(z-1)^5 = z^5$ . I argued that: $(\frac{z}{z-1})^5 = 1 = e^{2k \pi i}$ so $\frac{z}{z-1} = e^{\theta i}$ where $\theta = \frac{2k \pi}{5}$ so rearranging gives $z = \frac{e^{i \theta}}{e^{i \theta} -1} = \frac{e^{i \theta}}{e^{i \phi}(e^{i \phi} - e^{-i \phi})}$ where $\phi = \frac{\theta}{2} = \frac{k \pi}{5}$ $z = \frac{e^{i \phi}}{2i \sin (\phi)} = \frac{ \cos \phi + i \sin \phi}{2i \ sin \phi} = \frac{1}{2} - \frac{i}{2} \cot \phi = \frac{1}{2} - \frac{i}{2} \cot \frac{k \pi}{5}$ for k = 1, ...4 However the answer says that it should be +cot, not -, but I can't see where I have dropped a negative. Can anyone help me? Many thanks",['complex-analysis']
3425613,In how many ways can N squares overlap in the plan?,"We consider the following problem: given a set of $N$ squares in the plan, what is the maximum number of ways they can overlap ? Rules of construction: Two arrangements of squares are considered the same if one can be continuously changed to the other without any vertex passing through an edge. The squares can be re-scaled, rotated and translated but they must keep their square shape. They must be contained in a finite space and cannot be reduced to a point. A vertex cannot be superimposed with an edge or with another vertex. Turning the whole configuration over is allowed (mirror image) and doesn’t change the arrangement. The squares are drawn in an affine plane. Surprisingly I didn’t find anything about this in the literature but maybe I didn't search well... I tried to establish an isomorphism between the geometric objects and their algebraic representations in order to count them. Anytime I generate an arrangements (with a brute force algorithm) I calculate its algebraic representations and check if it's a new one. Basically my method (For N=3) is to calculate 3 matrices: $V(i, j)$ = number of vertices from the square i included in the square j $F(i, j)$ = number of intersections found on the edge j of the
square i $S(i, j)$ = index of the sub-polygon (in the arrangement formed by the 2 other squares) in which the vertex j of square i is included* *The third matrix takes into account the sub-polygons created by the overlapping squares and a certain number of symmetry criterias in order to avoid counting the same arrangement several time. I didn’t prove yet that my model create an isomorphic (for N=3) but I'm pretty sure it can be use to calculate a good lower bound. So far I found $12$ arrangements for $N=2$ (visible below) and more than $4600$ for $N=3$ .
But I cannot make my algorithm converge for $N=3$ because I’m limited by the capacity of my computer... Questions: Has this problem been already solved?
Is it possible to find a formula expressing explicitly the number of arrangements possible for any value of $N$ ?",['geometry']
3425632,Convolution $f*g(x)$ is continuous if $f \in L^1(\mathbb{R}^n)$ and $g \in L^\infty(\mathbb{R}^n)$,"I am stuck in what I believe to be the last part of this problem. If $f \in L^1(\mathbb{R}^n)$ and $g \in L^\infty(\mathbb{R}^n)$ , then $f*g(x):=\int_{\mathbb{R}^n} f(x-y)g(y) \mathrm{d}y$ (Throughout this problem, we integrate with respect to $\mathbb{R}^n$ and the Lebesgue measure) Since $g \in L^\infty(\mathbb{R}^n)$ , then there exists a real number $M$ , such that $g \leq M \ \text{a.e.}$ Therefore, for $x, x_0 \in \mathbb{R}^n$ $$|f*g(x) - f*g(x_0)| = \left| \int f(x-y)g(y) \mathrm{d}y - \int f(x_0-y)g(y)\mathrm{d}y \right|$$ $$\leq M \left| \int \left( f(x-y)-f(x_0-y) \right) \mathrm{d}y \right|$$ and this is finite since $f \in L^1(\mathbb{R}^n)$ But, since we are not making any assumptions about the continuity of $f$ , I am stuck.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'convolution', 'real-analysis']"
3425638,Calculate $\lim_{x\to\infty}\biggr(x\sqrt{\frac{x}{x-1}}-x\biggr)$,"$$\lim_{x\to\infty}\biggr(x\sqrt{\frac{x}{x-1}}-x\biggr)$$ I know this limit must be equal to $\frac{1}{2}$ but I can't figure why. This is just one of the thing I tried to solve this limit: $$\lim_{x\to\infty}\biggr(x\sqrt{\frac{x}{x-1}}-x\biggr)$$ $$\lim_{x\to\infty}x\biggr(\sqrt{\frac{x}{x-1}}-1\biggr)$$ Now I try to evaluate the limit. I know that $\lim_{x\to\infty}\sqrt\frac{x}{x-1}$ is equal to 1 so that means the above limit evaluates to $\infty * 0$ which is indeterminate form. I do not know what to do next, would greatly appreciate some help.","['limits', 'calculus']"
3425660,Centralizer of group of unit quaternions,"Consider the multiplicative group $\Bbb S^0(\Bbb H)$ of unit quaternions as a subgroup of $\mathrm O(\Bbb R^4)$ . I wonder what would be the centralizer of that group, that is, the set of orthogonal matrices that commute with all elements of $\Bbb S^0(\Bbb H)$ : $$C(\Bbb S^0(\Bbb H)) = \{X\in\mathrm O(\Bbb R^4 \mid XT = TX\text{ for all $T\in\Bbb S^0(\Bbb H)$}\}.$$ I somehow believe that (a connected component of) the centralizer is isomorphic to $\Bbb S^0(\Bbb H)$ , but I have no idea how to find this explicitly.","['representation-theory', 'topological-groups', 'orthogonal-matrices', 'group-theory', 'quaternions']"
3425663,What will happen to Dandelin Spheres in case of Degenerate Conics?,"Degenerate conics are obtained when the slicing plane cuts the double right circular cone at the intersecting tips of the two cones (vertex). This gives a pair of straight lines intersecting at the vertex (depending upon the eccentricity). Dandelin spheres are useful in finding the focus, directrix, etc. Focus of a straight line lies at infinity. I don't know what happens to the directrix of the conic when it approaches becoming degenerate. I think the Dandelin sphere gets smaller and smaller when the slicing plane moves towards the vertex of the two cones, but I am unable to explain this in relation to the focus and directrix. So, what will happen to Dandelin Spheres, and their applications (finding focus, directrix, etc.,) in case of degenerate conics? Or is that not defined at all for such cases.","['conic-sections', 'geometry']"
3425664,Using Catalan Numbers for an example,"Situation: We want to build a wall. The lowest level of this wall consists of 9 stones. Every stone ( except the stones of the lowest level) has to be on the middle of two other stones. Moreover we have no gaps regarding the lowest level. Question: how many options do we have for a wall like this? my idea\work: I made a picture of this situation. I think this has to do with the Catalan numbers $C_n$ . Maybe ""up"" is like opening a parantheses and "" going right"" is like closing a parantheses? I think the solution is $C_9$ . Am I right? If I'm Right: Can you please help me to improve my attempt. It is a bit messy and not detailed. * Second Explanation * Maybe just going up is to open a parantheses and going down again is like Closing a parantheses. But I'm not sure if $C_9$ is correct. I mean in my picture Im going only 6 times up and 6 times down.","['catalan-numbers', 'combinatorics', 'discrete-mathematics']"
3425686,Calculating the derivative of a differentiable map between manifolds,"Let $M$ be a smooth manifold. Let $p\in M$ . A tangent vector at $p$ is a an equivalence class $[\gamma]$ of smooth curves $\gamma : (-\epsilon,\epsilon)\rightarrow M$ , with $\gamma(0) = p$ , where the equivalence relation is as follows: $$\gamma_1\sim\gamma_2 \iff \exists \text{ chart } (U,\phi) \text{ such that } (\phi\circ\gamma_1)'(0) = (\phi\circ\gamma_2)'(0)$$ One can now define the tangent space $T_pM$ as the set of all tangent vectors. And define the derivative as follows: Let $f:M\rightarrow N$ be a differentiable map between manifolds, $p\in M$ . The derivative of $f$ at $p$ is $$(f_*)_p:T_pM\rightarrow T_pN: [\gamma]\mapsto[f\circ\gamma] $$ I understand that the derivative at $f$ just changes the tangent vectors at $M$ to tangent vectors at $N$ such that it has nice properties. But I'm having a hard time understanding what this means practically of how to interpret these tangent vectors. The exercise I am trying to solve defines $f:S^2\rightarrow \mathbb{R}:(x,y,z)\mapsto z^2$ and asks for which $p$ $(f_*)_p = 0$ . I have proven that if $F:M\rightarrow \mathbb{R}$ and $N$ a submanifold, that if $f = F\mid_N:N\rightarrow \mathbb{R}$ that for all $p\in N$ : $(f_*)_p = 0\iff T_pN\subset ker(F_*)_p$ . It seems like this can be useful in some way, but then again I think I need to calculate $(F_*)_p$ which I don't know how to do.",['differential-geometry']
3425688,Completing the square to solve limit problems,"There's a trick I've been using to solve a common class of limit problems for a while now.  I've never seen it taught in a textbook, but I once wrote out a few lines of work to justify it to myself in one of my notebooks.  Here is a sample problem to illustrate my technique: $$\lim_{x\to\infty}\sqrt{x^2+x}-x=\lim_{x\to\infty}\sqrt{x^2+x+\frac14}-x=\lim_{x\to\infty}\left(x+\frac12\right)-x=\frac12$$ It's such a shortcut compared to rationalization or however you're ""supposed"" to solve that, and I'm quite certain that it's valid. But I'm starting to feel a little leery posting this as a solution to MSE problems since I don't quite remember the few lines of justification all those years ago.  Could someone please provide a proof that $$\lim_{x\to\infty}\sqrt{x^2+2\alpha x}-\sqrt{x^2+2\alpha x+\alpha^2}=0$$ or whatever equivalent formulation you would prefer?  I'm sure that delta-epsilon drudgery is not necessary at all.  (If nobody gets to this by the end of the day, I'll self-answer just to have something to link to.) Thanks!","['limits', 'calculus', 'real-analysis']"
3425698,Integral $\int_{-\infty}^\infty \frac{\exp{(-x^2)}}{1+x^4}dx$,"I have an integral that I'd like some advice on how to find. 
  It is: $$\int_{-\infty}^{\infty} \frac{\exp(-x^2)}{1+x^4}dx$$ I have some experience with contour integrals so I tried using a contour integral where the contour is a semi-circle of radius R in the upper half of the complex plane. I think the integral along the arc vanishes as $R \to \infty$ so I used the residue theorem and am getting a value of $\tfrac{\pi}{\sqrt{8}}(\cos(1) - \sin(1))$ . But this can't be right as the value is negative whereas the integrand is always positive! I can't work out what is going wrong. Does anyone have an idea about how to evaluate this integral? Contour integration is the preferred method if possible but I am also open to other methods. Any suggestion is appreciated!","['integration', 'complex-analysis', 'calculus', 'improper-integrals']"
3425703,What is the physical significance of the determinant $\Delta$ in the general equation of a conic?,"The determinant $\Delta$ for the general equation of a conic $ax^2+2hxy+by^2+2gx+2fy+c=0$ is given by the following: $$\Delta=\left| \begin{array} {ccc} a & h & g \\ h & b & f \\ g &f &c\\ \end{array} \right|$$ This determinant, when equal to $0$ , the equation represents a pair of straight lines. When non-zero, the equation represents a non-degenerate conic (circle, ellipse, parabola, hyperbola)*. So, what is the physical significance of the determinant $\Delta$ in the general equation of a conic? By physical significance, I mean what happens in the system of intersecting plane and a double right circular cone? I am guessing that the value $\Delta$ represents some kind of distance of the slicing plane from the vertex of the double cone. But it would be great if you could confirm that. Further, is the value of $\Delta$ always positive and zero, or it takes negative value too? Kindly explain your answer in a simple way, so that a high school student could understand. Thank you in advance. *Related : Quadratic Curve","['conic-sections', 'determinant', 'geometry']"
3425710,Fourier series of elliptic F integral,"Question. How to expand $$\mathbf{F}(\theta\mid k)=\int_0^\theta\frac{dt}{\sqrt{1-k^2\sin^2t}} \text{ (where $|k|<1$ and $|\theta|<\pi$)}$$ as a Fourier series w.r.t. $\theta$ ? I noticed that the question boils down to finding the Fourier expansion of $$f(\theta)=\frac1{\sqrt{1-k^2\sin^2\theta}}$$ as we can change the order of integration and differentiation. We can see clearly that $f$ is even, so $$\int_{-\pi}^\pi f(\theta)\sin n\theta d\theta=0.$$ Also, $$\int_{-\pi}^{\pi}f(\theta)\cos(2n+1)\theta d\theta=2\int_0^\pi f(\theta)\cos(2n+1)\theta d\theta\\=2\int_0^\pi f(\theta)\cos((2n+1)(\pi-\theta))d\theta=0$$ So the only hard part left is $$\int_0^{\pi/2}\frac{\cos 2n\theta}{\sqrt{1-k^2\sin^2\theta}}d\theta.$$ For $n=0$ I can clearly see it's $\mathbf{K}(k)$ , the elliptic K integral. Clearly there is a polynomial $P_n(x)$ s.t. $\cos 2nx=P_n(\sin^2x)$ with $\deg P_n=n$ , but note that this does not make the question boil down to evaluating $\displaystyle\int_0^{\pi/2}\frac{\sin^{2n}(t)}{\sqrt{1-k^2\sin^2 t}}dt$ because after evaluating this elliptic-like integral, which I ensure that it evaluates to a form of $a\mathbf{K}(k)+b\mathbf{E}(k)$ by partial fraction expansion, where $a,b\in\mathbb Q$ , there is a hard finite summation left involving the coefficients of $P$ . When $n=1$ , $a_n$ equals $2\mathbf{E}/k^2+(1-2/k^2)\mathbf{K}$ . I don't have any further thoughts. If we cannot find the general term with $k$ varying, can we at least find the coefficients when $k^2=-1$ ?","['integration', 'fourier-series', 'elliptic-integrals', 'definite-integrals']"
3425791,Evaluate the following limit: $\lim_{x \to 0} (1+x)^{\tan(\frac{1}{x})}$,"According to Wolfram Alpha , this limit evaluates to 1. However, I don't know how to prove this fact. My problems are with $\tan(\frac{1}{x})$ . As I understand, when $x \to 0$ , $\tan(\frac{1}{x})$ is not defined, because $\tan(\frac{1}{x}) = \frac{\sin(\frac{1}{x})}{\cos(\frac{1}{x})}$ and both the $\sin$ and the $\cos$ oscillate as they approach infinity, hence there is no definite value for them. Maybe this problem requires an approach that I am not familiar with, but it appears as homework in a Calculus I course, so it should not involve super advanced maths techniques. Thanks for your help!","['limits', 'calculus', 'real-analysis']"
3425998,"Show that any set of $16$ positive integers (not all distinct) summing to $30$ has a subset summing to $n$, for $n= 1,2,\ldots,29$","Show that any set of $16$ positive integers (not all distinct) summing to $30$ has a subset summing to $n$ , for $n= 1,2,\ldots,29$ I have tried it by separately considering $n$ to be $1,2,\ldots,29$ . But the process is becoming large and complicated. Any smart or elegant process/suggestion is welcome.","['combinatorics', 'discrete-mathematics']"
3426002,Prove or disprove that $BC(\Bbb R )$ is a Hilbert space,"I have an exercise that says: Let $BC(\Bbb R )$ the set of bounded and continuous functions from $\Bbb R $ to $\mathbb{F}$ , where $\mathbb{F}$ is $\Bbb R $ or $\Bbb C $ , endorsed with the following inner product $$
\langle f,g \rangle:=\sum_{m\geqslant 1}\frac{f(q_m)\overline{g(q_m)}}{2^m}\tag1
$$ where $(q_m)$ is an enumeration of $\Bbb Q $ . Prove or disprove that $BC(\Bbb R )$ is a Hilbert space with this inner product. I want to check if my counterexample below is correct and maybe if there is a more simple or straightforward counterexample. I used the following theorem to construct my counterexample: Theorem: let $(x_k)$ some sequence in a normed vector space $V$ . Then $V$ is a Banach space if and only if $\sum_{k\geqslant 0}\|x_k\|<\infty\Rightarrow \sum_{k\geqslant 0}x_k$ exists in $V$ . Then assuming that $$
\sum_{k\geqslant 1}\|g_k\|=\sum_{k\geqslant 0}\sqrt{\sum_{m\geqslant 1}\frac{|g_k(q_m)|^2}{2^m}}<\infty\tag2
$$ we want to show that $\sum_{k\geqslant 1}g_k$ doesn't belong to $BC(\Bbb R)$ . Let a sequence $(g_k)$ in $BC(\Bbb R )$ defined by $g_k(x)=0$ if $x\notin [k,k+1)$ and $\|g_k\|_\infty =g_k(k+1/2)=k$ and let $(p_k)$ the increasing sequence of primes (that is, $p_0=2,\, p_1=3,\,p_2=5$ , and so on) and define $N_k:=\{p_k^n: n\in \Bbb N_{>0}\}$ . Then $(N_k)$ is a disjoint sequence of infinite subsets of $\Bbb N $ and because $p_k> k$ for all $k\in \Bbb N_{\geqslant 0} $ then we find that $\sum_{x\in N_k}2^{-x}< 2^{-k}$ . Then there is an injection $b:\Bbb Q \to \Bbb N$ such that the image of $b$ restricted to the set $[k,k+1)\cap \Bbb Q $ is $N_k$ . Then by construction we find that $$
\sum_{q\in \Bbb Q }\frac{|g_k(q)|^2}{2^{b(q)}}\leqslant\frac{k^2}{2^k}\implies  \sum_{k\geqslant 1}\|g_k\|\leqslant \sum_{k\geqslant 1}\frac{k}{2^{k/2}}< \infty\tag3
$$ However $g:=\sum_{k\geqslant 1}g_k$ is unbounded because $g(k+1/2)=k$ for all $k\in \Bbb N $ , then by the theorem stated above $BC(\Bbb R )$ cannot be a Banach space, neither a Hilbert space. UPDATE: As pointed by @Daniel my counterexample is not right because it must work for any enumeration of the rationals and not just for a chosen enumeration. Then I want to show that, for any enumeration of $\Bbb Q $ , we can build a sequence $(f_k)$ with a similar behavior of the sequence $(g_k)$ of above. Let an enumeration $(q_n)_n$ of $\Bbb Q $ and set $Q_n:=\max\{q_1,\ldots ,q_n\}$ and define recursively the sequence of open intervals $$
I_1:=(q_1,q_1+1)\\
I_n:=(\max\{\sup I_{n-1},Q_n\},\max\{\sup I_{n-1},Q_n\}+1)\tag4
$$ Then by construction $(I_n)$ is a sequence of disjoint intervals of length one with the property that $\{q_1,\ldots ,q_n\}\cap I_n=\emptyset $ . Now we set a sequence $(f_k)$ on $BC(\Bbb R )$ by $f_k(x)=0$ when $x\notin I_k$ and $\|f_k\|_\infty =k$ . Then, by construction, each function $f_k$ have disjoint support and $$
\sum_{n\geqslant 1 }\frac{|f_k(q_n)|^2}{2^n}=\sum_{n\geqslant k+1}\frac{|f_k(q_n)|^2}{2^n}\leqslant \sum_{n\geqslant k+1}\frac{k^2}{2^n}=\frac{k^2}{2^k}\\
\therefore \quad \sum_{k\geqslant 1}\|f_k\|\leqslant \sum_{k\geqslant 1}\frac{k}{2^{k/2}}<\infty \tag5
$$ However by construction we have that for each $k\in \Bbb N $ there is some $x\in I_k$ such that $f_k(x)=k$ , hence $\sum_{k\geqslant 1}f_k$ is unbounded, and by the theorem stated above it shows that $BC(\Bbb R )$ cannot be a Hilbert space.","['inner-products', 'proof-verification', 'functional-analysis', 'examples-counterexamples']"
3426075,Evaluating $\sum_{k=0}^\infty\sin(kx)$ and $\sum_{k=0}^\infty\cos(kx)$,"Playing with sines I wanted to find $$
S(x)=\sum_{k=0}^\infty\sin(kx)
$$ Writing it as $$
S(x)=\mathrm{Im}\big(A(x)\big),\quad\text{where}\quad A(x)=\sum_{k=0}^\infty e^{ikx}
$$ and using $z=e^{ix}=\cos(x)+i\sin(x)$ , cheating about $\|z\|=1$ in order to write $$
A(x)=\frac{1}{1-z},
$$ I found that $$
2S(x)=\frac{\sin(x)}{1-\cos(x)}
$$ as WolframAlpha does. My question is: why with the same method I found $$
\sum_{k=0}^\infty\cos(kx)=\frac{1}{2}
$$ while WolframAlpha and G.H.Hardy on the book ""Divergent Series"" (pg. 2) give $-1/2$ ?","['summation', 'trigonometric-series', 'sequences-and-series', 'power-series', 'trigonometry']"
3426080,A set of elements in a reduced unity ring,"Let $(A,+,\cdot)$ be a unity ring with the property that if $x \in A$ and $x^2=0$ then $x=0$ . Consider the set $M=\{a\in A | a^3=a\}$ . Prove that: a) $2a\in Z(A)$ , $\forall a\in M$ , where $Z(A)$ denotes the centre of the ring $A$ ; b) $ab=ba$ , $\forall a,b\in M$ . My attempts revolved around the fact that an idempotent element in a reduced ring is central. So, since for $a\in M$ we have that $(a^2)^2=a^2$ , it follows that $a^2\in Z(A)$ , $\forall a\in M$ . The next thing I wanted to use in order to solve a) was that $Z(A)$ is a subring of $A$ , so if I had proved that $(a+1)^2 \in Z(A)$ , $\forall a\in M$ , then we would have reached the desired conclusion. However, I couldn't prove this and I honestly doubt that it is true. Another idea that I had was to prove that $M$ is a subring of $A$ . Of course, this didn't work out because I cannot even prove that $M$ is closed under addition. Again, I don't know if this is true and it most likely isn't. As for b), I think that a) should be of use, but I don't know how. It is a well-known problem that a ring with $x^3=x$ for any $x$ in that ring is commutative, but since $(M,+,\cdot)$ is almost definitely not a ring, this doesn't help. EDIT: Is there any chance that this question is simply wrong? I tended to believe this before asking it here too, but since nobody has made any progress on it until now I am even more inclined to think so.","['contest-math', 'ring-theory', 'abstract-algebra']"
3426094,Check whether $\sum _{m=1}^{\infty }\sum _{n=1}^{\infty }\frac{1}{\left(m+n\right)^2}$ converges or NOT?,Check whether $$\sum _{m=1}^{\infty }\sum _{n=1}^{\infty }\frac{1}{\left(m+n\right)^2}$$ converges or NOT? My Try:- $\sum _{m=1}^{\infty }\lim_{i\to \infty} \sum _{n=1}^{i}\frac{1}{\left(m+n\right)^2}=\lim_{j\to \infty}\sum _{m=1}^{j }\lim_{i\to \infty} \sum _{n=1}^{i}\frac{1}{\left(m+n\right)^2}=\lim_{j\to \infty}(\lim_{i\to \infty} \sum _{n=1}^{i}\frac{1}{\left(1+n\right)^2}+ \lim_{i\to \infty} \sum _{n=1}^{i}\frac{1}{\left(2+n\right)^2}+ \lim_{i\to \infty} \sum _{n=1}^{i}\frac{1}{\left(3+n\right)^2}+...\lim_{i\to \infty} \sum _{n=1}^{i}\frac{1}{\left(j+n\right)^2})\ge \lim_{j\to \infty}(j\lim_{i\to \infty} \sum _{n=1}^{i}\frac{1}{\left(j+n\right)^2})$ How do I complete the conclusion?,"['double-sequence', 'sequences-and-series', 'real-analysis']"
3426142,Geometric intuition behind this chain homotopy,"Warning: using Lee's Introduction to Topological Manifols notation in what follows. My question has to do with the chain homotopy that appears in Lee's Introduction to Topological Manifols and Rotman's Introduction to Algebraic Topology proofs that the inclusion $$C_\bullet^\mathcal{U}(X)\hookrightarrow C_\bullet(X)$$ Induces an isomorfism in singular homology $$H_p^\mathcal{U}(X)\cong H_p(X)$$ For all $p\geq 0$ . First, a series of definitions If $\alpha=A(v_0,\dots,v_p)$ is an affine singular $p-$ simplex in some convex set $K\subseteq\mathbb{R}^n$ and $w$ is any point in $K$ , we define an affine singular $(p+1)-$ simplex $w*\alpha$ called the cone on $\alpha$ from $w$ by: $$w*\alpha=w*A(v_0,\dots,v_p)=A(w,v_0,\dots,v_p)$$ And we extend this operator to affine chains by linearity: $w*\big(\sum_{i\in I}n_i\alpha_i\big)=\sum_{i\in I}n_i(w*\alpha_i)$ An important formula is proved in both references, regarding the relationship between the boundary and cone operators If $c$ is an affine chain, then $$\partial(w*c)=c-w*\partial c$$ It is obvious that if $c$ is a cycle, the last formula becomes $\partial(w*c)=c$ , and Rotman calls this an intrgration formula . Afterwards, both authors define an operator $s$ that sends affine $p-$ chains into affine $p-$ chains, called the barycentric subdivision operator . This is done by induction: For $p=0$ , $s=\text{Id}$ Suppose that $s$ has been defined for some $p\in\mathbb{N}$ . Then, for any affine $(p+1)-$ simplex $\alpha:\Delta_p\longrightarrow\mathbb{R}^n$ we set $$s\alpha=\alpha(b_p)*s\partial\alpha$$ Where $b_p$ is the barycentre of the standard singular simplex $\Delta_p$ , and we extend this operator to affine chains by linearity: $s\big(\sum_{i\in I}n_i\alpha_i\big)=\sum_{i\in I}n_is\alpha_i$ Now, to extend this operator to arbitrary singular chains, note that if $\sigma$ is a singular $p-$ simplex in any space $X$ , then $\sigma=\sigma_{\#}i_p$ , where $i_p:\Delta_p\longrightarrow\Delta_p$ is the identity map considered as an affine singular $p-$ simplex in $\Delta_p$ , and $\sigma_\#:C_\bullet(\Delta_p)\longrightarrow C_\bullet(X)$ is the chain map obtained from the continuous map $\sigma$ . So the idea is that if we have a singular chain $c$ , then applying sucesively the subdivision operator, we will obtain a chain homologous to $c$ , but whose simplices have images all lying in elements of $\mathcal{U}$ . To prove this, we should find a chain homotopy between the identity and the subdivision operator, that is, a homomorphism $h:C_p(X)\longrightarrow C_{p+1}(X)$ such that $$h\circ\partial+\partial\circ h=\text{Id}-s$$ But Lee and Rotman gives $$h\sigma=\sigma_\#b_p*(i_p-si_p-h\partial i_p)$$ And extend to chains by linearity. However, I am struggling to understand what geometric intuirion is behind this intriguing formula. I tried to draw what $h$ looks like when $\sigma=\text{Id}_{\Delta_1}$ , but it is really hard (impossible?) to imagine this acting on $2-$ simplices In contrast with the chain homotopy that appears in the proof of the homotopy axiom, this is really less intuitive, and relies heavily on what Rotman calls the integration formula . So my questions are How should we understand geometrically this map $h$ ? What is the geometric intuition that allows us to choose this a a good chain homotopy for our purposes? How should we understand the formula $\partial(w*c)=c-w*\partial c$ ? What is the meaning of this equation geometrically speaking? How to come up with such a map in the first place? How has this theorem developed historically? I understand perfectly both demonstrations, since the calculations are easy to follow; I am just concerned with how this map gives no intuition at first glance about the geometry involved.","['homological-algebra', 'geometry', 'general-topology', 'homology-cohomology', 'algebraic-topology']"
3426217,Limit of $ \frac{f(h+k) - f(k) - f(h) + f(0)}{hk}$,"Calculate the following limit when $(h,k)\to (0,0)$ when $f$ is twice differentiable in 0. By removing $f(0) + xf'(0) + x^2f''(0)/2$ to $f$ , we can suppose WLoG that $f(0)=f'(0) = f''(0)=0$ . Let $g:h\mapsto f(h+k) -f(h) - f(k)$ Then $g$ is differentiable around 0 and $g'(h) = f'(h+k) - f'(h)$ . When $f$ is twice continuously differentiable around 0, I managed to conclude by writing the difference as an integral and using the fact that $f''(0) = 0$ to find an upper bound on $g'$ around 0.  So the limit here should be 0. So that in the general case we should  get $f''(0)$ But I am stuck in the general case ! When I try to find an upper bound on this derivative, I can only get something of the form $\varepsilon |h+k| + \varepsilon |h|$ and I cannot conclude with that... Any tips ?","['limits', 'real-analysis']"
3426231,Number of ways to tile a room with $I$-Shaped and $L$-Shaped Tiles,"There is a room of dimensions $2\times n$ . You have to tile it using $2$ types of tiles: I-Shaped Tile ( $2\times1$ ) L-Shaped Tile ( $2\times1 + 1$ ) However, you are forbidden to use any tiling where any four corners of the tiles meet. For example for a $2\times4$ room, the first three will be counted and the last one will not be counted. My Attempt If the condition that four corners cannot meet wasn't given, a pretty neat recurrence can be formed. $$f(n) = f(n-1) + f(n-2) + 2g(n-1)$$ $$g(n) = f(n-2) + g(n-1)$$ with $g(0) = g(1) = 0$ and $f(0) = f(1) = 1$ where $f(n) = $ number of ways of tiling a $2\times n$ rectangle and $g(n)=$ number of ways of tiling  a $2\times n$ rectangle with a square missing on top. Hence, we multiply $g(n-1)$ by $2$ when calculating $f(n)$ because the missing square can be at the top or the bottom. I am unable to find such a recurrence with the extra given condition.","['puzzle', 'combinatorics', 'tiling']"
3426254,Question about time between poisson events,"Suppose that we know the count of Aviation accidents in a specific country in a year has a poisson distribution of $\lambda =5$ . Find probability that 4 or more accident happen in a year? Find probability that no consecutive accidents happen in a 6 month interval We start to count accidents at time $T$ . what is the probability that 5th accident happen before 9th month. My problem is with 2nd and 3rd part. For first part we simply have: $P(X = k) = 5^k e^{-5} / k!$ $answer = 1 - P(X=0) - P(X=1) - P(X=2)- P(X=3) = 0.7412$ For the second part I actually don't know what to do. One approach is that we know in 6 month the distribution is a new poisson with $\lambda = 2.5$ maybe no consecutive accident in 6 month means: $P_{new}(X=0) + P_{new}(X=1)$ For the third part, I think we have poisson with $\lambda = 3.75$ and we want to find $P_{new}(X=5) + P_{new}(X = 6) + ... = 1 -P_{new}(X=0) - P_{new}(X=1) - P_{new}(X=2) - P_{new}(X=3) - P_{new}(X=4) $ Is my approaches right? If not, what should I do?","['poisson-distribution', 'statistics', 'poisson-process', 'probability']"
3426288,Compute $\int_0^1\frac{\ln x\operatorname{Li}_2(x^2)}{\sqrt{1-x^2}}dx$,I need to prove $$I=\int_0^1\frac{\ln x\operatorname{Li}_2(x^2)}{\sqrt{1-x^2}}dx=\frac{5\pi}8\zeta(3)-\pi\ln2\zeta(2)+\pi\ln^32$$ to finish my solution for this probem . What I did is the common sub $x=\sin\theta$ which gives us $$I=\int_0^{\pi/2}\ln(\sin\theta)\operatorname{Li}_2(\sin^2\theta)d\theta$$ and I dont know how to continue. I am not sure if its helpful to use the dilogaritmic identity $\operatorname{Li}_2(z^2)=2\operatorname{Li}_2(z)+2\operatorname{Li}_2(-z)$ which results in $$I=2\int_0^{\pi/2}\ln(\sin\theta)\operatorname{Li}_2(\sin\theta)d\theta+2\int_0^{\pi/2}\ln(\sin\theta)\operatorname{Li}_2(-\sin\theta)d\theta$$ Other try is to write $$\operatorname{Li}_2(x^2)=-\int_0^1\frac{x^2\ln u}{1-x^2u}du$$ but this technique seems to make the problem even harder. So any idea how to crack this integral?,"['integration', 'definite-integrals', 'harmonic-numbers', 'calculus', 'polylogarithm']"
3426309,Definition of very ample line bundle.,"I am reading Vakil's algebraic geometry. He gives a definition of very ample line bundle as followings: Suppose $\pi: X \rightarrow \operatorname{Spec} A$ is a proper morphism, and $\mathscr{L}$ is an invertible sheaf on X. Then we say $\mathscr{L}$ is very ample over $A$ if $X \cong$ Proj $S_{\bullet}$ where $S_{\bullet}$ is a finitely generated graded ring over $A$ generated in degree 1 and $\mathscr{L} \cong \mathscr{O}_{\text {Proj} S_{\bullet}}(1)$ . Then there is one exercise Show that $\mathscr{L}$ is very ample if and only if there exist a finite number of global
  sections $s_{0}, \ldots s_{n}$ of $\mathscr{L},$ with no common zeros, such that the morphism $$
\left[\mathrm{s}_{0}, \ldots, \mathrm{s}_{\mathrm{n}}\right]: \mathrm{X} \rightarrow \mathbb{P}_{\mathrm{A}}^{\mathrm{n}}
$$ is a closed embedding. However, I think the exercise is wrong if we use his definition. For example, considering the closed embedding $
\mathbb{P}^{1} \rightarrow \mathbb{P}^{2}$ given by $[x: y] \mapsto\left[x^{2}: x y: y^{2}\right]$ it pulls $ \mathcal{O}_{\mathbb{P}^{2}}(1) \text { to } \mathcal{O}_{\mathbb{P}^{1}}(2)$ . Obviously, $\mathcal{O}_{\mathbb{P}^{1}}(2)$ satisfies the condition in the exercise, but it is not isomorphic to $\mathcal{O}_{\mathbb{P}^{1}}(1)$ . So I think the definition of very ample line bundle is not proper. And actually we should use the exercise as the definition. Am I right? If not, could you tell me the exact definition of very ample line bundle? Thank you very much.","['algebraic-geometry', 'line-bundles', 'schemes', 'sheaf-theory']"
3426319,Global existence of solutions to a differential equation,"Let $M$ be a (compact) manifold and $\lambda$ a closed 1-form on $M$ . Under which condition on $\lambda$ does there exists a non-trivial (complex) function $F$ such that $$dF = F\lambda \quad \quad ?$$ A couple of remarks : If the equation above has a solution $f$ and $g$ is some function on $M$ , then $e^g f$ is a solution to the equation $$dF = F(\lambda+dg),$$ so any characterization only depends on the cohomology class of $\lambda$ . Since this equation can be written locally as $d \ln (F) = \lambda$ , the condition that $\lambda$ be closed is natural.","['de-rham-cohomology', 'differential-geometry']"
3426372,Proving continuity of a partial derivative,"Let $f(x,y) = xy(x^2-y^2)/(x^2+y^2)$ if $(x,y)\neq (0,0)$ and let $f(x,y) = 0$ if $(x,y)=(0,0)$ Prove that the partial derivative of f with respect to x is continuous at $(0,0)$ . I found the partial derivative to be equal to: $y(x^4+4x^2y^2-y^4)$ / $(x^2+y^2)^2$ Now I know I need to take the limit as x goes to 0. $\lim_{x\to0}$ $y(x^4+4x^2y^2-y^4)$ / $(x^2+y^2)^2$ It follows that this is equal to $-y$ which is continuous on $\mathbb{R}$ for all y . Thus our partial derivative is continuous at $(0,0)$","['multivariable-calculus', 'limits', 'calculus', 'proof-verification']"
3426407,Find the double integral $\int_{0}^1 \int_{y}^1 e^{x^2} \ dx \ dy $ [duplicate],"This question already has an answer here : Evaluate: $ \int_0^1 \int_y^1 e^{x^2 }dxdy$ (1 answer) Closed 4 years ago . I need assistance to solve the double integral $$
\int_{0}^1 \int_{y}^1 e^{x^2} \ dx \ dy. 
$$ So far I have done some poor attempts to rewrite the integral $\int e^{x^2} \ dx$ where I let $t= e^{x^2}, \ $ which lead to $\ln(t)={x^2}$ , differentiating then gives $\frac{dt}{t}\ = 2x \ dx$ . After some back and forth I end up with the not so nice expression $\int e^{x^2} \ dx=\frac{1}{2} \int\left(\frac{1}{\ln(t)}\right)^{1/2} \ dt$ . The answer to the double integral is $$
\int_{0}^1 \int_{y}^1 e^{x^2} \ dx \ dy=\frac{1}{2}(e-1), 
$$ but I would like some one to give me a hint on how to reach the conclusion. Any assistance is appreciated./Pablo","['integration', 'multivariable-calculus', 'calculus', 'definite-integrals']"
3426433,Could a function be applied on a specific set? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I have a set A= $\{( n+2) /( 2n+1) :\ n\in N\}
(\mathbb{N} \longrightarrow \Re )$ . Then I want to apply a function [for example ln() - natural logarithm] on set A that will produce a new set B= $\{ln[( n+2) /( 2n+1)] :\ n\in N\}$ . If it is possible then, should I write it like a composite function? What notation should I use to show that?",['elementary-set-theory']
3426478,Let $f : X → X$ be an injective map such that $f ( X ) \neq X$ . Show that:,"a. The set $X$ is infinite. b. For $x\in X-f(X)$ , the elements $x, f(x), f(f(x)), \ldots$ are pairwise distinct. I came across this problem while looking online for some abstract math problems to do and I have no clue how to solve it. For a, I said:
Suppose that $X$ is finite, meaning that there is a finite number of elements and is injective, then $f(x):X \rightarrow X$ is also contains $n$ distinct elements and is contained in $X$ based on the definition of a finite set. However, the prompt says that $f ( X ) \neq X$ , therefore $X$ cannot be finite. For b, I have no clue.","['abstract-algebra', 'discrete-mathematics', 'real-analysis']"
3426518,Hartogs' theorem for real functions,"Context : Hartogs' theorem says that if a complex function $f:\mathbb{C}^2 \rightarrow \mathbb{C}$ is separately analytic in the two complex variables, then the function is continuous, and analytic. However, this fails when applied to real function. The counterexample given in Wikipedia is $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ , given by $$
f(x,y) = \frac{xy}{x^2+y^2}.
$$ $f$ is not continuous along the lines $x=\pm y$ . Question : This raises two questions: Clearly, being separately analytic in x (i.e. keeping y constant, vary x) and separately analytic in y is not enough to ensure continuity, let alone analyticity of $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ . However, is it true that if $f$ is separately analytic along all directions in the $\mathbb{R}^2$ plane, then $f$ is analytic? Is the converse true? Specifically, if $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ is analytic, then is it analytic along all directions in the $\mathbb{R}^2$ plane? Note : By analytic along a certain direction, I mean the following: Consider the line $y=mx$ in the plane. Along this line, $f(x,y) = \tilde{f}(x)$ , since x completely parametrizes the line. Then, being analytic along this line, in the sense that I'm using it, would mean that $\tilde{f}(x)$ is analytic in x. I apologize if this is a very simple question. I'm new to analysis, and would appreciate it if you could provide references where this has already been proven or disproven.","['complex-analysis', 'real-analysis']"
3426637,Why does modular exponentiation always form a cycle?,"I am not sure my question is linguistically precise with regards to mathematics. I will illustrate what I mean with an example. Consider $2^i \pmod{15}$ . $2^0 = 1 \pmod{15}$ $2^1 = 2 \pmod{15}$ $2^2 = 4 \pmod{15}$ $2^3 = 8 \pmod{15}$ $2^4 \equiv 1 \pmod{15}$ $2^5 \equiv 2 \pmod{15}$ $2^6 \equiv 4 \pmod{15}$ $2^7 \equiv 8 \pmod{15}$ $2^8 \equiv 1 \pmod{15}$ $\vdots$ In this example, $2^i \pmod{15} \in \{1, 2, 4, 8\}$ for $i \geq 0$ . It is true, in general, that for positive integers $a$ , $b$ , $n$ , we have $a^b \pmod n$ is a cycle of a particular sequence. Why? As a follow up: is there any reason that $2^i \pmod{15}$ is a cycle of $\{1, 2, 4, 8\}$ ? Is there any reason that the numbers in a particular sequence are the ones that they are? As a note, I have not studied group theory.","['number-theory', 'modular-arithmetic', 'elementary-number-theory', 'exponentiation']"
3426696,Closed path complex integral with non anaytic function gives me zero,"When i calculate $$\oint_C \left(\overline z\right)^2 \mathbb dz$$ Along $|z|=1$ , it gives me $0$ . Then i remembered with Cauchy's Theorem, "" If we have an analytic function and want to integrate it along closed path, then we have $0$ as the result"". Then i tried to check the analiticity with Cauchy-Riemann Equation, and it's not satisfied. Well, randomly i change the radius to $123$ , and it still gives me $0$ Could i conclude $$\oint_C (\overline z)^2 \mathbb dz$$ Is always $0$ , when it's evaluated along $|z|=R$ ? Where $R$ is any radius? NB : But it fails to be $0$ when around the $|z-1|=1$ But why? What is the best reason?","['complex-analysis', 'contour-integration']"
3426707,Solving the differential equation $\frac{dy}{dt}=R-ry^2$,"I'm working on a problem for my optics class regarding electron-hole recombination in a semiconductor under strong injection. Assuming I haven't done anything wrong, I've arrived at the following equation: $$\frac{dy}{dt}=R-ry^2$$ where $R$ and $r$ are different variables and $y$ stands in for the change in carriers, a function of $t$ . The problem asks for an analytical solution to this equation, but I'm incredibly rusty with diff eqs. Does this have an analytical solution? I don't readily see how it could be separable or anything else. I've looked for similar forms on a few websites, but none of them seem applicable. For example, here ( http://web.uvic.ca/~kumara/econ501/schap22.pdf ), on page 15, it provides a solution for (nonautonomous, separable) equations of the form $$\frac{dy}{dt} = f(y,t),$$ but even though the right side is a function of $y$ and $t$ (constant with $t$ ), I can't seem to separate it. So, I'm thinking that isn't right. I think arriving at this equation might belong on a different forum (physics or somewhere), but I'm more interested in the math for this. Would anyone happen to know if this even has an analytical solution? If so, how does one arrive there? The problem is trying to prove a power-law behavior instead of exponential behavior, if that gives any hint. Thanks for the help",['ordinary-differential-equations']
3426738,"Permutation of the eight letters (i, l, o, v, e, y, o, u)","Determine how many permutations of the eight letters (i, l, o, v, e, y, o, u) begin with you, or end with i, or have the letter e in the fifth position and the letter y in the sixth position. Though it's very easy question, I need to double check the solution. My solution: i) you_ _ _ _ _ = 5! ii) _ _ _ _ _ _ _ i = 7!/2! iii) _ _ _ _ e y _ _ = 6!/2! Removing the duplicates: ii) you _ _ _ _i = 4! iii) _ _ _ _ e y _ i = 5!/2! So, total number of permutations = 5! + 7!/2! + 6!/2! - 4! - 5!/2! Please correct me if I am wrong.","['permutations', 'combinations', 'combinatorics']"
3426758,Showing that Fourier coefficients tend to zero,"Let $f \in L^2[0,1].$ The $n$ th Fourier coefficient of $f$ is given by $$\hat f(n) = \int_0^1 f(t)e^{-2\pi int} \, dt$$ The Fourier exponentials $u_n(t) = e^{2\pi int}$ are orthonormal in $L^2[0,1].$ Using Bessel's inequality, we have $$\sum_n|\hat f(n)|^2=\sum_n\lvert \langle f,u_n\rangle \rvert^2 \leq \lVert f\rVert^2=\int_0^1 
\lvert f \rvert^2 < \infty$$ so $\lvert \hat{f}(n)\rvert ^2  \to 0$ as $\lvert n \rvert \to \infty$ by Cauchy's criterion, which in turn implies that the $\hat{f}(n)$ go to zero. I additionally want to show that for measurable $A \subset [0,1]$ , we have that $$\int_Ae^{2\pi int} \to 0 \text{ as } n \to \infty$$ What is the correct way to approach this? Do we treat this as the Fourier transform of the characteristic function $\chi_A?$ Thank you!","['measure-theory', 'fourier-analysis', 'functional-analysis', 'real-analysis']"
3426761,Is $\frac{x^2}{a^2}+\frac{y^2}{b^2} = \frac{y}{b}$ the equation of an ellipse? Shouldn't it be $\frac{x^2}{a^2}+\frac{y^2}{b^2} = 1$?,"While solving a question today I came across a locus of the form $$\frac{x^2}{a^2}+\frac{y^2}{b^2} = \frac{y}{b}$$ It was told in my book that it is the equation of an ellipse. How is that so? Forgive me if I ask this, this may seem really silly (I'm still in high school) but isn't the general equation of an ellipse of this form? $$\frac{x^2}{a^2}+\frac{y^2}{b^2} = 1$$ Or is it of the form $$ax^2+by^2+2hxy+2gx+2fy+c=0$$ Can someone please confirm this for me.","['conic-sections', 'geometry']"
3426814,Show that $\sum_{i=1}^{k/2} {{k}\choose i}2^i < 3^{k-1}$,"Show that $\sum_{i=1}^{k/2} {{k}\choose i}2^i < 3^{k-1}$ for $k\geq6$ and even. I tried using $(1+2)^k=\sum_{i=0}^k{{k}\choose{i}}2^i$ , the first half has the same binomials as the second and larger powers of two. Also tried induction, but the step is proving that $\dfrac{\sum_{i=0}^{k/2+1}{k+2\choose i}2^i}{\sum_{i=0}^{k/2}{k\choose i}2^i}<9$ .","['inequality', 'combinatorics', 'summation']"
3426906,"Show that $\{0,1\}^{[0,1]}$ is not sequentially compact","Show that $\{0,1\}^{[0,1]}$ is not sequentially compact Obviously, it is taken with the product topology of the subspace topologies (which are, in fact, discrete). Now, the elements are tuples of $0$ 's and $1$ 's with $[0,1]$ as the indexing set. For a sequence to converge in this topology, for any collection of finite indices, $\exists m \in \mathbb{N}$ such that the terms of the sequence match the limit in those indices after that $m$ . I cannot go any further. Hints are welcome rather than complete answers.","['sequence-of-function', 'general-topology', 'compactness']"
3426954,Definition of sample path of stochastic process,"A sample path of a stochastic process $x:\Omega\times T\to\mathbb{R}^n$ is defined as taking $x(\omega,t)$ with fixed $\omega\in\Omega$ , thus $x(\omega,\cdot)$ . However I have the following issue with this definition: the process is supposed to be a sequence of random variables $X_t:\Omega\to\mathbb{R}^n$ , so a sample path, or realization would be a realization for each of the random variables in the sequence, leading to (maybe) different values of $\omega\in\Omega$ , one for each $t\in T$ . For example if $\Omega = \{H,T\}$ and $T=\{0,1,\dots\}$ and all random variables $X_t$ are independent with $P(X_t = H) = p\ \ \forall t\in T$ , then a realization would be something like $\{H,T,T,H,\dots\}$ . But, what am supposed to interpret by ""fixing $\omega\in\Omega$ "", since one would only get sequences like $\{H,H,H,\dots\}$ . I've seen other answers here, and some say that you should not fix $\omega$ for all random variables in the sequence, or that $\omega$ is fixed on sequences in $\Omega^T$ (then $\omega\in\Omega^T$ ?). Of course that seems reasonable, but it doesn't follow the definition. Am I missing something? (Im using ""Introduction to Stochastic Control"" by Åström, Karl Johan and ""Stochastic Differential Equations"" by Øksendal, Bernt)","['stochastic-processes', 'probability-theory']"
3426955,Convergence of Mobius sum to $\frac{1}{\zeta(2)}$,"It is well known that $$\frac{1}{\zeta(s)}=\sum_{n=1}^{\infty}\frac{\mu(n)}{n^s}$$ which for $s=2$ gives a convergence to $6/\pi^2$ . If we consider the partial sum, Apostol gives $$\sum_{n\leq x}
\frac{\mu(n)}{n^2}=\frac{6}{\pi^2}+O\left(\frac{1}{x}\right)$$ This bound is obtained by simply noting that $$ \sum_{n>x} \frac{\mu(n)}{n^2}< \sum_{n>x} \frac{1}{n^2}=O\left(\frac{1}{x}\right)$$ However, experimental calculations on this convergence suggests a  smaller error size. This is also somewhat intuitive, as substituting $\mu(n)$ with $1$ in the estimation of the $O$ term significantly enlarges the true error. Is there any stronger bound for this convergence? I did  not find any useful reference on this issue in the literature.","['number-theory', 'asymptotics', 'mobius-function', 'riemann-zeta', 'convergence-divergence']"
3426993,Is the “sum of all natural numbers” unique?,"A while ago, there was a great hype about the “identity” $$\sum_{n=1}^{\infty} n = -\frac{1}{12}.$$ Apart from some series manipulations where the validity seems to be at least questionable, the derivation of this always goes through the zeta function: Where the series converges, the zeta function is defined by $$\zeta(s) = \sum_{n=1}^{\infty}\frac{1}{n^s}$$ and outside that range by analytic continuation. And it turns out that inserting $s=-1$ formally results in $$\zeta(-1) = -\frac{1}{12} = \sum_{n=1}^\infty n$$ However looking at the series in isolation, there is no indication that the zeta function should be chosen. An obvious way to get an analytic function that at one point gives the sum of all natural numbers is $$f(x) = \sum_{n=1}^{\infty} nx^n$$ at $x=1$ , however (not surprisingly) that function diverges at $1$ . Therefore my question: Is it possible to get another finite value for the series by analytic continuation of another series? Concretely, do there exist continuous functions $f_1, f_2, f_3, \ldots$ such that On some non-empty open subset $S$ of $\mathbb C$ , $f(x)=\sum_{n=1}^\infty f_n(x)$ converges to an analytic function. At some point $x_0$ , $f_n(x_0) = n$ for all positive integers $n$ . The analytic continuation of $f$ is well defined and finite at $x_0$ . $f(x_0) \ne -1/12$ What if we demand the functions $f_n$ to be analytic rather than just continuous?","['divergent-series', 'analytic-continuation', 'sequences-and-series']"
3427049,"Proof that $f(x)= \frac{1}{x}$ is not uniformly continuous on $I= (0,1]$","Let $f:I \to \mathbb{R}$ be a function and $I \subset \mathbb{R}$ an interval. How can one prove that $f_1(x)= \frac{1}{x}$ is not uniformly continuous on $I= (0,1]$ ? I know that $\frac{1}{x}$ isn't continuous nor is it discontinuous at $x_0 = 0$ because it's not defined  and taking $\lim x \to \infty$ would just give $0$ .","['continuity', 'proof-writing', 'functions', 'analysis']"
3427112,Do we need nets to be indexed by directed sets?,"I recently had a look into general topology and now I am trying to wrap my head around the notion of a net. I understand its definition as a map from an upward directed set into our topological space, but I do not get, why it has to be this general. 
As I see it, since we want to characterize our topology by the convergence of its nets, it would be preferable to choose assumptions on our index set as strong as possible in order to have fewer nets we need to work with, while still having as much as needed to be able to transfer the theorems for sequences in metric spaces to the more general setting of a topological space. For example now, after reading the proofs of some of those theorems, to me lattice-indexed nets would appear as a more natural choice of definition, since most of the nets I encountered used families of neighbourhoods as index sets and so, if I am not mistaken, all the proofs would still work. 
So my questions now are:
Is there a theorem that actually needs nets in there most general definition? Or maybe is there just no practical difference between the two? Or is there something completely different I missed?",['general-topology']
3427186,Heptadecagon Derivation,"I am currently very interested in the derivation of the constructability of the 17-gon by Carl Friedrich Gauß.
Has someone got an easy explanation for the solution of $$x^{17} - 1=0?$$ That was the equation he solved with which he showed $$\cos \frac{360^\circ}{17}=\frac{1}{16}\left( -1 + \sqrt{17} + \sqrt{ 2\left(17 -\sqrt{17} \right)}+ 2 \sqrt{ 17 + 3 \sqrt{17} - \sqrt{2 \left(17- \sqrt{17} \right)} - 2 \sqrt{2 \left(17+ \sqrt{17} \right)} } \right) \approx 0.9324722294.$$ Can someone briefly explain his derivation, please?","['euclidean-geometry', 'geometric-construction', 'proof-explanation', 'geometry', 'galois-theory']"
3427206,Almost everywhere equal implies measurable,"I am still new to Lebesgue measure theory. I would like to get a verification on my proof. Statement: Assume a complete measure space. If $f$ is a measurable function and $f=g$ almost everywhere, then $g$ is measurable. Proof: Let $c$ be a real number and $N$ the null set such that $f=g$ on $N^C$ .
Hence, $$g^{-1}(c,\infty)=[g^{-1}(c,\infty)\cap N]\cup[g^{-1}(c,\infty)\cap N^C].$$ The first RHS bracket is measurable since it is the subset of $N$ and the space is complete. The second is measurable because it is equal to $f^{-1}(c,\infty)\cap N^C$ , where $f^{-1}(c,\infty)$ is measurable by assumption and $N^C$ is measurable because $N$ is. Q.E.D. Are there missing details in the proof? Thanks a lot.","['measure-theory', 'lebesgue-measure', 'analysis']"
3427250,Set relation with a biconditional definition.,"Let R be a relation defined by the condition aRb ↔ a $R_1$ b ∧ a $R_2$ b where $R_1$ and $R_2$ are equivalence relations on a set A. Prove that R is an equivalence relation on A . Could I just assume that since $R_1$ and $R_2$ are equivalence relations, then they are both reflexive, symmetric, and transitive, therefore the bicondition a $R_1$ b ∧ a $R_2$ b is true and I only need to prove that aRb is reflexive, symmetric, and transitive to prove that R is an equivalence relation.","['elementary-set-theory', 'equivalence-relations', 'relations', 'discrete-mathematics']"
3427260,Find $n$ such that $n\sqrt5 - \lfloor{n\sqrt5}\rfloor$ is maximised or minimised?,"This question is from number theory : Set $n\in (1,2009)$ , and $n$ is a natural number. Find the values of $n$ such that $$n\sqrt5 - \lfloor{n\sqrt5}\rfloor$$ is minimised and maximised respectively. I tried to convert the expression into an inequality as such: $$m^2<5n^2<(m+1)^2$$ With $m = \lfloor n\sqrt5\rfloor$ . This came to no avail. I have also tried to set $k = n\sqrt5 - \lfloor{n\sqrt5}\rfloor$ . This way, to maximise $k$ , we maximise: $$k(k+2m) = 5n^2-m^2$$ $$n = \frac{k+m}{\sqrt5}$$ But this also turns out to not work.
I tried plotting the function and testing for different values of n. Apparently, for $17$ , the value of the function seems quite minimal, and for $21$ it appears to be more maximal. I have noticed that smaller numbers tend to be more extreme for this function, as $34 = 17\times2$ is also quite minimal, but not so much as $17$ . This appears to show a link, but I cannot identify it. Please help with the problem.","['contest-math', 'number-theory', 'ceiling-and-floor-functions']"
3427332,About the definition of powerful p-groups,"I am reading ""Analytic pro- $p$ groups"" by Dixon, Du Sautoy, Mann and Segal. They define $G$ a finite $p$ -group to be powerful if $[G,G]\leq G^p$ for $p$ odd but in the case $p=2$ they require $[G,G]\leq G^4$ . Why this discrepancy between odd and even $p$ ? Is it related to some substantial fact about $p$ -groups or is this just a technical condition you assume to make the proofs work? This reminds me of the computation $\mathbb{Z}_p^{\times}=\mathbb{F}_p^{\times}\times \mathbb{Z}_p$ for $p$ odd while for $p=2$ we have $\mathbb{Z}_2^{\times}=\{ \pm1\}\times \mathbb{Z}_2$ . But I could not correlate directly these two facts.","['pro-p-groups', 'profinite-groups', 'definition', 'abstract-algebra', 'group-theory']"
3427347,$f:\mathbb{R}\rightarrow\mathbb{R}$ such that $f(f(x))=-x$ non-continous only on a finite set,"I'm looking for a function $f:\mathbb{R}\rightarrow\mathbb{R}$ such that $f(f(x))=-x$ with the nicest (in terms of continuity and differentiability) properties possible. The condition $f^2(x):=f(f(x))=-x$ implies that $f$ is an odd function and, in particular, that $f(0)=0$ . To see this note that $f^3(x)=f^2(f(x))=-f(x)$ and also $f^3(x)=f(f^2(x))=f(-x)$ . Using this property one can see that $f$ cannot be differentiable in general, because then the chain rule applied to $f^2$ leads to $f'(f(x))\cdot f'(x)=-1$ and, for $x=0$ , this would be $f'(0)^2=-1$ . However, I was able to build an $f$ satisfying the desired condition if I allow it to be non-continuous on a numerable set. Namely, let $$A=(0,1]\cup(2,3]\cup(4,5]\cup\cdots$$ $$B=(1,2]\cup(3,4]\cup(5,6]\cup\cdots$$ and define $f$ as follows: $$ f(x)= 0 \mbox{, if } x=0$$ $$ f(x)= x+1 \mbox{, if } x\in A$$ $$ f(x)=-x+1 \mbox{, if } x\in B$$ $$ f(x)= x-1 \mbox{, if } x\in -A$$ $$ f(x)=-x-1 \mbox{, if } x\in -B$$ This definition is inspired by the fact that, for any non-zero $a$ , if we let $f(a)=b$ , then the orbit of $a$ under $f$ is $a\mapsto b\mapsto -a\mapsto-b$ , so we need to decompose the positive numbers into two disjoint bijective sets (here $A$ and $B$ ) and then let $f$ jump from $A$ to $B$ , then to $-A$ , then to $-B$ and finally back to $A$ . So, I understand that in order to find an $f$ that is non-continuous on a finite set we need to decompose the positive reals into two disjoint bijective sets so that each of them is at most a finite union of connected (in the usual topology) subsets. Is this even possible? My first intuition is that the answer is no because the number of discontinuity points that we need doesn't match, but I'm not able to formalize this properly.","['general-topology', 'functions']"
3427371,Expected number of balls to be thrown until one of $N$ urns has $\beta$ more balls than all the other urns [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Given $N$ urns, what is the expected number of balls that need to be thrown until one of the urns has $\beta$ more balls than all the other urns?","['discrete-mathematics', 'statistics', 'combinatorics', 'probability']"
3427382,How to construct a surface of genus $g$ by identifying sides of a $4g$-gon?,"The picture is given below: How we are constructing an orientable surface $M_{g}$ of genus $g$ in case of $g = 2,3$ in the figure? I do not understand how the figures after identifaction are drawn like this, could anyone explains this for me please?","['general-topology', 'cw-complexes', 'surfaces', 'algebraic-topology']"
3427392,Which of the following Can be the set of all discontinuities?,"Let $F:\mathbb R \to \mathbb R$ be a non-decreasing function. Which of the following Can be the set of all discontinuities? $\mathbb Z$ $\mathbb N$ $\mathbb Q$ $\mathbb R$ \ $\mathbb Q$ My Try Considering step function. It is non decreasing. Its discontinuities are set $\mathbb Z$ . Taking the same function and re-defining in the negative axis such a way that those portion is continuous will give 2. True. Taking Thomae function, I get function is discontinues at $\mathbb Q$ . If $F$ would be monotone 4. won't be correct. But here $F$ is only not decreasing. I am confused. Please help me.","['continuity', 'functions', 'real-analysis']"
3427410,"Prove that $\psi_*[X,Y]=[\psi_* X,\psi_* Y]$, for vector fields $X,Y$ and $\psi$ diffeomorphism in $\mathbb R^n$","Let $\psi$ be a diffeomorphism in $\mathbb{R}^{n}$ . I have to proove that for two vector fields $X,Y\in\mathfrak{X}(\mathbb{R}^{n})$ the following property holds $\psi_{\ast}[X,Y] = [\psi_{\ast}X,\psi_{\ast}Y]$ , where $[\cdot,\cdot]$ denotes the Lie-Bracket of vector fields. First of all, I review some definitions: (1) In this context, vector fields are viewed as derivations: $X:C^{\infty}(\mathbb{R}^{n})\to C^{\infty}(\mathbb{R}^{n})$ , where $X$ is linear and fulfills the Leibniz rule. (2) For a vector $v\in T_{p}\mathbb{R}^{n}$ , here also viewed as a derivation $v:C^{\infty}(\mathbb{R}^{n})\to \mathbb{R}$ , the push foward is defined via: $\psi_{\ast}v(f):=v(f\circ\psi)$ , where $f\in C^{\infty}(\mathbb{R}^{n})$ Now to the proof: $\psi_{\ast}[X,Y](f)=[X,Y](f\circ\psi)=X(Y(f\circ\psi)) - Y(X(f\circ\psi)) = X(\psi_{\ast} Y(f)) - Y(\psi_{\ast} X(f))$ But now I don ` t no how to continue the proof.....Is there an error in my calculation?","['vector-fields', 'pushforward', 'lie-groups', 'differential-geometry']"
3427431,Error in Divisor Function Modelled With Waves,"The divisor function counts the number of divisors of an integer. A model is described where the divisor function is seen as summation of repeating continuous waves. The divisor function now has a real and imaginary component. This divisor wave model introduces an error in the solution. The wave divisor function method is presented, also a description of the error is given.
 Last section has some questions I am unable to answer. I cannot summarize more than written below unfortunately. Wave divisor function: $\sigma_{0}(x)$ The integer divisor function can be described as a summation of repeating waves. Each wave filters out numbers. Divisor wave $\mathbb{X}=7$ will filter: 7, 14, 21, 28, 35 etc. The divisor function can be described as: $$ \sigma_{0}(x)=\sum_{\mathbb{X}=2}^{\infty}\cos^{N} \left( \frac{\pi}{\mathbb{X}}x \right)$$ Here from $x$ the number of divisors is determined excluding divisor $1$ . $N$ should be a positive even integer; only then positive pulses occur so $N \in 2 \mathbb{N}$ . If: $N \rightarrow \infty$ discrete pulses with magnitude $1$ occur on the intervals determined by: $\mathbb{X}$ . This definition of the divisor function does not take $1$ in account, for the conventional definition $1$ should be added to the wave divisor function. With Euler’s formula and the binomial theorem, the function can be rewritten as: $$ \sigma_{0}(x)=\sum_{\mathbb{X}=2}^{\infty}e^{i\left( \frac{N\pi}{\mathbb{X}}x \right)} 2^{(-N)} \sum_{k=0}^{N} \binom{N}{k} e^{-i\left( \frac{\pi}{\mathbb{X}}kx \right)}  $$ The solution for the divisor function occurs when the angular component is $0$ only then pulses of magnitude 1 occur. For the divisor function we can set: $$e^{i\left( \frac{N\pi}{\mathbb{X}}x \right)}=1$$ While $N \pi$ will always be a multiple of $2 \pi$ because $N$ must be a positive even integer. So, the ""Wave Divisor Function"" becomes: $$ \sigma_{0}(x)=\sum_{\mathbb{X}=2}^{\infty} 2^{(-N)} \sum_{k=0}^{N} \binom{N}{k} e^{-i\left( \frac{\pi}{\mathbb{X}}kx \right)}  $$ The n choose k notation can be written in a trigonometric formulation. $$ \Re(\sigma_{0})=\sum_{\mathbb{X}=2}^{\infty}\cos^{N} \left( \frac{\pi}{\mathbb{X}}x \right) \cos \left( \frac{N\pi}{\mathbb{X}}x  \right) $$ $$ \Im(\sigma_{0})=-i \sum_{\mathbb{X}=2}^{\infty}\cos^{N} \left( \frac{\pi}{\mathbb{X}}x \right) \sin \left( \frac{N\pi}{\mathbb{X}}x  \right) $$ This is only valid with the following criteria (found by setting above equations equal): $$ \cos^{2} \left( \frac{N\pi}{\mathbb{X}}x  \right) + \sin^{2} \left( \frac{N\pi}{\mathbb{X}}x  \right)=1$$ Thus, the solution of the divisor function is only valid for integer values of $x$ . The wave divisor function consists of repeating wave packages with different frequencies. A wave pulse outline is modulated with a high frequency. When N increases in size the wave packages become narrower and the frequency of the signal increases. One can select a $N$ for every value of $\mathbb{X}$ such that the pulse width for all waves becomes similar. N the pulse width definition. The wave divisor function consists of repeating wave packages. The width of a wave package can be described as the pulse height $L$ at $\Delta x$ : $$ \cos^{N} \left( \frac{\pi}{\mathbb{X}} \Delta x \right)=L$$ From the above equation we can calculate the magnitude of $N$ . The wave package width will also vary depending upon the value of $\mathbb{X}$ . Thus, $N$ is a function of $\mathbb{X}$ . $N(\mathbb{X})$ can derived: $$ N(\mathbb{X})= \frac{\log (L)}{\log \left(  \cos \left(  \frac {\pi}{\mathbb{X} } \Delta x  \right)\right)}  \quad N \in 2 \mathbb{N} $$ For $(\mathbb{X} \rightarrow \infty)$ $N$ can be approximated as Taylor series: $$ N(\mathbb{X}) =   \frac{2 \mathbb{X}^2 \log(L)}{\pi^2 \Delta x^2} + \frac{\log(L)}{3}+ \mathcal{O} \left( \frac{1}{\mathbb{X}^2} \right)$$ Wavepulse outline. The wave divisor function consists of a pulse outline modulated with a high frequency component. The real solution of the wave divisor function is: $$ \Re(\sigma_{0})=\sum_{\mathbb{X}=2}^{\infty}\cos^{N} \left( \frac{\pi}{\mathbb{X}}x \right) \cos \left( \frac{N\pi}{\mathbb{X}}x  \right) $$ The first term $cos^N$ can also be simplified, this is the pulse outline. The pulse outline forms a bell-shaped distribution around the origin for $\mathbb{X} \rightarrow \infty$ : $$ O(x)=\lim_{\mathbb{X} \rightarrow \infty}\cos^{N} \left( \frac{\pi}{\mathbb{X}}x \right)= e^{a x^{2}}$$ $$ a=\frac{\log(L) \space}{\Delta x^{2}}=constant$$ The high frequency component $HF(\mathbb{X})$ scales linear with $\mathbb{X}$ (see link for more information) for: $\mathbb{X} \rightarrow \infty$ . $$ HF(x)= \cos \left( \frac{N\pi}{\mathbb{X}} x \right) \approx \cos (b x)$$ $$ b(\mathbb{X}) = \frac{N}{\mathbb{X}}\pi \approx  - \frac{2 \space \log(L)}{\pi \space \Delta x^{2}} \mathbb{X} = constant \cdot \mathbb{X}$$ So for $\mathbb{X} \rightarrow \infty$ the wave divisor function becomes: $$ \Re(\sigma_{0})\rightarrow \sum_{\mathbb{X}=2}^{\infty}e^{a x^{2}} \cos (b x) $$ Error of the Wave Divisor Function. The error of the wave divisor function is majorly determined by neighbor pulses like: $\sigma(x-1)$ and $\sigma(x+1)$ . The maximum error from a direct neighbor can be determined from the wave pulse outline: $$ max(\varepsilon)=exp \left( \frac{\log(L)}{\Delta x^2}      \right)$$ Error caused by $\sigma(x-m)$ and $\sigma(x+m)$ also contribute to the error. For pulses m steps away from $x$ : $$ \varepsilon(m)=exp \left( \frac{\log(L)}{\Delta x^2}   m^{2}   \right)$$ In between the limits the error will occur. The exact value of the error is determined by $HF(x)$ . The frequency of $HF(x)$ scales almost linear with $\mathbb{X}$ . For direct neighbor divisors the error can be formulated. Where $\mathbb{X}|(x-1)$ means $\mathbb{X}$ divides $(x-1)$ , $k$ is a constant determined by the pulse width. $$ \varepsilon (x) \approx max(\varepsilon) \cdot \left[ \sum_{\mathbb{X}\vert (x-1)}^{} \cos(k \mathbb{X}) + \sum_{\mathbb{X}\vert (x+1)}^{} \cos(k \mathbb{X}) \right]$$ It is assumed that for large values $x$ its divisors are randomly distributed. Also, the rounding of $N$ to its closest even integer causes a randomizing effect. It is expected that the error is picked from an arcsine distribution. The Variance in the case of an arcsine distribution can be calculated. For neighbor pulses at $(x-1)$ and $(x+1)$ the variance is: $$ Var(\mathbb{X})=\frac{1}{2} \cdot  max^{2}(\varepsilon)$$ For other divisors m steps away: $$ Var(\mathbb{X})=\frac{1}{2} \cdot  \varepsilon^{2}(m)$$ The total error is summed. It appears that the error follows a random walk over an arcsine distribution. The total number of neighbor divisors determine the total variation. The total error will be the contribution of direct and neighbor pulses: $$ Var(x) =\frac{1}{2} max^{2}(\varepsilon) \left( \sum_{m=1}^{\infty} \frac{\sigma_{0}(x+m) \cdot \varepsilon^{2} (m)}{max^{2}(\varepsilon)}   +  \sum_{m=1}^{\infty} \frac{\sigma_{0}(x-m) \cdot \varepsilon^{2} (m)}{max^{2}(\varepsilon)}    \right)$$ The error description is not ideal. Errors $m$ steps away can be counted duplet, like divisor of $\mathbb{X}=2$ could be counted double. Though, when the pulse width is small $\Delta x \rightarrow 0$ the error converges. The error will be determined by direct neighbor divisors. Thus, counting duplets is not the case. This relation takes a sort of mean value of the divisor count: $$ Var(x)  \approx  \frac{1}{2} \cdot max^{2}(\varepsilon) \cdot (\sigma_{0}(x+1) +\sigma_{0}(x-1))$$ $$ Var(x) \approx  max^{2}(\varepsilon) \cdot \overline{\sigma_{0}(x)} $$ The mean divisor growth is defined by Dirichlet. For now we do not included the error term $\mathcal{O}(x^{\Theta^{*}})$ . Note that an extra $(-1)$ is added the wave divisor function is excluding divisor: 1. $$ \overline{ D(x)} \approx \log(x) + 2 \gamma -1 -(1)$$ The standard deviation in the wave divisor function than is then proportional to: $$ Stdev(x) \approx max(\varepsilon) \cdot \sqrt{\log(x)+ 2 \gamma -2}$$ Simulation of the error. For a given pulse width $L=0.5$ , $\Delta x=0.2$ the divisor count can be determined. The error in the Wave Divisor can be calculated as: $$\varepsilon (x)=\sigma_{0}(x)_{Wave}-\sigma_{0}(x)_{Discrete}$$ The error is calculated for all integers x till the number 50000 in the presented simulation. The boundaries are determined and plotted as: $3Stdev$ $(99.7 \%)$ . Several observations can be made: There occur more positive errors. 99.606% is counted within the boundaries while 99.7 % is expected. Questions. When plotting the error $\varepsilon (x)$ positive errors occur more often why? Is the error growing as a random walk over an arcsine distribution? (are divisors of large numbers randomly distributed?) More information and references. Jupyter notebook: https://mybinder.org/v2/gh/oooVincentooo/Shared/master?filepath=Wave%20Divisor%20Function%20rev%202.4.ipynb pdf: https://drive.google.com/open?id=1Etu4vOfjsnbaysk_UR6HIA9R7EDybH-n","['number-theory', 'divisor-counting-function', 'brownian-motion']"
3427448,preserving norm map between real normed spaces,"Suppose $X,Y$ are two real normed spaces, $T:X\to Y$ is the bijective map such that $||Tx+Ty+Tz|| = ||x+y+z||$ for any $x,y,z\in X$ .Is $T$ a linear map?","['normed-spaces', 'functional-analysis', 'linear-transformations']"
3427467,Determining Weight function in Sturm Liouville problem,"By choosing the proper weight function $\sigma (x) $ solve the Sturm-Liouville problem and determine its eigenvalues and eigenfunctions. $$ \frac{d}{dx}\left[x\frac{dy(x)}{dx}\right] + \frac{2}{x}y(x) +\lambda \sigma (x)y(x)=0,\; y'(1)=y'(2)=0,\; 1 \leq x \leq 2. $$ I don't understand what it means to ""choose"" the proper weight function. I tried to rewrite the problem in this form. $$\frac{1}{\sigma(x)}\left[\frac{d}{dx}\left[x\frac{dy(x)}{dx} + \frac{2}{x}y(x)\right] +\lambda\sigma(x)=0\right], $$ then calculate it by setting $p(x)=A(x)\sigma (x), p'(x)=B(x)\sigma(x)$ and using this formula: $$\sigma(x)=e^{\int \frac{A-B'}{B}\,dX}, $$ but it doesn't get me anywhere; solving this gives you just $1=1.$ I tried extracting information about the weight function from the boundary condition but i am failing at that too and i tried solving the differential equation using an infinite series but that won't work either because of the unknown weight function. Any tips?","['calculus', 'sturm-liouville', 'ordinary-differential-equations', 'eigenfunctions']"
3427493,Asymptotic distribution of a Maximum Likelihood Estimator using the Central Limit Theorem,"Let $(X_1,\dots,X_n)$ be a random sample from a population $X$ having probability density function $$f(x;\vartheta)=\vartheta\,x^{\vartheta -1}\,I_{(0,1)}(x)$$ $$\vartheta>0\qquad\qquad I_{(0,1)}(x)=
\begin{cases}
1\qquad\text{if }x\in(0,1)\\
0\qquad\text{otherwise}
\end{cases}$$ Find: $\hat{\vartheta}_n$ , the MLE (Maximum Likelihood Estimator) of the parameter $\vartheta$ the approximate distribution of $\hat{\vartheta}_n$ for $n$ big While I'm pretty confident on how to solve the first point, I'd like some advice on the second one. 1. To find the MLE $\hat{\vartheta}_n$ , the likelihood function is calculated: $$\mathscr{L}(\underline{x};\vartheta) = \vartheta^n\,\left( x_1 \times\dots\times x_n \right)^{\vartheta -1} = \vartheta^n\,\left( \prod_{i=1}^n x_i \right)^{\vartheta -1} \qquad\qquad(0<x_i<1,\, \forall\,i=1,2,\dots,n)$$ The first derivative with respect to $\vartheta$ is $$\frac{\partial\mathscr{L}(\underline{x};\vartheta)}{\partial\vartheta} = \vartheta^{n-1}\,\left( \prod_{i=1}^n x_i \right)^{\vartheta -1}\left[ n+\vartheta\,\log{\left(\prod_{i=1}^n x_i\right)}\right]$$ and $\hat{\vartheta}_n$ is obtained solving for $$\frac{\partial\mathscr{L}(\underline{x};\vartheta)}{\partial\vartheta} = 0\quad \implies \quad \hat{\vartheta}_n = -\frac{n}{\log{\left(\prod_{i=1}^n x_i\right)}}$$ To be precise, it should now be checked that $$\left. \frac{\partial^2\mathscr{L}(\underline{x};\vartheta)}{\partial\vartheta^2}\right|_{\vartheta=\hat{\vartheta}_n} < 0$$ In order to do so, the second derivative with respect to $\vartheta$ is calculated: $$\frac{\partial^2\mathscr{L}(\underline{x};\vartheta)}{\partial\vartheta^2} = \underbrace{\vartheta^{n-2}\,\left( \prod_{i=1}^n x_i \right)^{\vartheta -1}}_{\Gamma}\underbrace{\left[ n(n-1)+2n\vartheta\log{\left(\prod_{i=1}^n x_i\right)}+\vartheta^2\log^2{\left(\prod_{i=1}^n x_i\right)}\right]}_{\Delta}$$ $\Gamma$ is always positive, hence we only need to evaluate $$\left.\Delta\right|_{\vartheta=\hat{\vartheta}_n} = -n <0$$ 2. To obtain the approximate distribution of $\hat{\vartheta}_n$ for $n$ big (a.k.a. the asymptotic distribution of $\hat{\vartheta}_n$ for $n\to\infty$ ), I thought of applying Cramér's Theorem for the asymptotic normality of the MLE.
This assures that $$\sqrt{n}\left(\hat{\vartheta}_n-\vartheta\right)\xrightarrow{d}\mathscr{N}(0,1/I(\vartheta))$$ where $I(\vartheta)$ is Fisher information , calculated after simple but tedious algebra: $$I(\vartheta) = \mathbb{E}\left[\left(\frac{\partial}{\partial\vartheta}\log{f(x;\vartheta)} \right)^2\right] = \frac{1}{\vartheta^2}$$ MY QUESTION While the procedure presented above to obtain the asymptotic distribution is completely general and should be correct (please tell me if it's not), I was wondering if there is any way to straightforwardly apply the Central Limit Theorem (CLT) to the variable $$\hat{\vartheta}_n = -\frac{n}{\log{\left(\prod_{i=1}^n x_i\right)}}$$ in order to obtain the same result, since $\hat{\vartheta}_n$ can be almost re-written as the sum of (the $\log$ of) iid variables: $$\hat{\vartheta}_n = -\frac{n}{\sum_{i=1}^n \log{x_i}}$$ Any idea/suggestion would be greatly appreciated!","['statistical-inference', 'statistics', 'central-limit-theorem', 'parameter-estimation', 'maximum-likelihood']"
3427496,How to develop $\frac{1}{1-x}$ into $1+\frac{x}{1+x}+\frac{1\cdot2x^2}{(1+x)(1+2x)}+\dots$,"I know that, by long division, or binomial formula or Taylor formula that this function can be developed into the geometric series: $1/(1-x)=1+x+x^2+x^3+x^4+\ldots $ and I thought that this is the only series that represent the function mentioned above. However, recently, I read ""Traite Elementaire des Series"" by Eugene Catalan and he said, on page 60, that ""The same function can admit multiple expansions"". He gives the series below: $$\frac{1}{1-x}=1+\frac{x}{1+x}+\frac{1\cdot2x^2}{(1+x)(1+2x)}+\frac{1\cdot2\cdot3x^3}{(1+x)(1+2x)(1+3x)}+\dots$$ I am just curious how can we derive this second series. So a function may admit multiple series representation? This is something new that I don't know. Maybe a better way to think about this is that two or multiple series can converge to the same function, which is the same as multiple numerical series may converge to the same sum.","['power-series', 'calculus', 'taylor-expansion', 'real-analysis']"
3427545,Solving the differential equation $y''=\frac{1}{y}$,"I tried to solve the differential equation $\frac{d^2y}{dx^2}=\frac{1}{y}$ by assuming $y(0)=1$ and $y'(0)=0$ and finding a taylor expansion for $y$ at $x=0$ . By differentiating $\frac{d^2y}{dx^2}$ , I got: $\frac{d^3y}{dx^3}=-\frac{1}{y^2}\frac{dy}{dx}$ $\frac{d^4y}{dx^4}=
\frac{2}{y^3}\frac{dy}{dx}
-\frac{1}{y^2}\frac{d^2y}{dx^2}$ $\frac{d^5y}{dx^5}=
-\frac{6}{y^4}\frac{dy}{dx}
+\frac{4}{y^3}\frac{d^2y}{dx^2}
-\frac{1}{y^2}\frac{d^3y}{dx^3}$ $\frac{d^6y}{dx^6}=
\frac{24}{y^5}\frac{dy}{dx}
-\frac{18}{y^4}\frac{d^2y}{dx^2}
+\frac{6}{y^3}\frac{d^3y}{dx^3}
-\frac{1}{y^2}\frac{d^4y}{dx^4}$ Evaluating those, I got the following values: $y^{(3)}(0)=0$ $y^{(4)}(0)=1$ $y^{(5)}(0)=4$ $y^{(6)}(0)=-17$ I then created a Python program to automatically derive more values: $y^{(7)}(0)=84$ $y^{(8)}(0)=-483$ $y^{(9)}(0)=3192$ $y^{(10)}(0)=-23919$ I used the derivatives to get a Taylor series, and I found that the series does not converge when $x>1$ . Did I make a mistake? If not, is there an approach I could use to approximate $y(2)$ or other values where $x>1$ ?","['divergent-series', 'taylor-expansion', 'ordinary-differential-equations', 'sequences-and-series']"
3427551,"Seeking series formula for: $3, 2, 4, 7, 11, 16, 26, 39, 63, 94, 152, 227, 367, 548, 886, 1323, 2139, 3194$","I have a series: $$3, 2, 4, 7, 11, 16, 26, 39, 63, 94, 152, 227, 367, 548, 886, 1323, 2139, 3194, ...$$ which represents values of $m,n$ in Euclid's formula to generate Pythagorean triples where $A-B=\pm17.$ I have found a number of series on MSE and oeis.org/A001333 or oeis.org/A266504 but not this one . I also tried WolframAlpha and it properly continued the series as: $$3, 2, 4, 7, 11, 16, 26, 39, 63, 94, 152, 227, 367, 548, 886, 1323, 2139, 3194, 5164, 7711, 12467, 18616, 30098, 44943, 72663, 108502, 175424, ...$$ but the formula it gave me: $$G_n(a_n)(z) = (-3 z^3 + 2 z^2 - 2 z - 3)/(z^4 + 2 z^2 - 1)$$ generates $$-3
-1, -0.734693878, -0.595818815, -0.50148368, -0.432333577, -0.379503603, -0.337911437, -0.304373698, -0.276791842$$ instead. Since WolframAlpha correctly extend the series from what I entered, it seems that the formula it offered should work so I must be interpreting something incorrectly. Can anyone point me in the right direction for this series or tell me what I'm doing wrong with Wolfram? WolframAlpha extrapolated correctly for $A-B=\pm17$ when I included the first elements but not when I omitted the first two.","['elementary-number-theory', 'pythagorean-triples', 'sequences-and-series']"
3427587,A general formula for the parametrisation of the tangent space (in $\Bbb{R}^n$),"I couldn't find a sufficiently general formula for the tangent plane of a parametric surface, so I derived one. The formula I came up with also defines the tangent line of a parametric curve in $n$ -dimensions, the tangent plane to an explicitly defined surface, and the tangent plane to a parametric surface in $n$ -dimensions: Let $\mathbf{f}:\Bbb{R}^m\to\Bbb{R}^n:m<n$ be a parametrisation of an $m$ -dimensional geometric object (possibly but not necessarily a
  manifold, algebraic variety, etc.) in Euclidean $n$ -space. The parametrisation of the tangent
  space $T_\mathbf{u}\mathbf{f}:\Bbb{R}^m\to\Bbb{R}^n$ at a point $\mathbf{u}\in\Bbb{R}^m$ is given by... $$T_\mathbf{u}\mathbf{f}(\mathbf{x})=\mathbf{J}_\mathbf{f}(\mathbf{u})(\mathbf{x}-\mathbf{u})+\mathbf{f}(\mathbf{u})$$ ...where $\mathbf{J}_\mathbf{f}(\mathbf{u})$ is the Jacobian matrix of $\mathbf{f}$ evaluated at $\mathbf{u}$ . The resulting parametrisation preserves information about local scaling and orientation within the coordinate system. This is particularly noticeable when considering changes to the basis vectors $^*$ of the tangent space between two points $\mathbf{u}$ and $\mathbf{u}'$ along a curve, as shown below (I apologise for the quality, upload limits and all that)... Edit Originally I had written this formula as... $$T_\mathbf{u}f(\mathbf{x})=\sum_i\left(\nabla f_i(\mathbf{u})\cdot(\mathbf{x}-\mathbf{u})+f_i(\mathbf{u})\right)\mathbf{e}^i$$ After Ted Shifrin's comment I realise that this is easier expressed in terms of the Jacobian. Shortly after editing this question, I found this on the Wikipedia article about the Jacobian... $${\displaystyle \mathbf {f} (\mathbf {x} )-\mathbf {f} (\mathbf {p} )=\mathbf {J} _{\mathbf {f} }(\mathbf {p} )(\mathbf {x} -\mathbf {p})+o(\|\mathbf {x} -\mathbf {p} \|)\quad ({\text{as }}\mathbf {x} \to \mathbf {p} )}$$ ...which is very close to my formula. The fact that the Jacobian is the closest linear approximation of vector-valued function explains why $T_\mathbf{u}\mathbf{f}$ is a close linear approximation of $\mathbf{f}$ near $\mathbf{u}$ , but does not explain why this gives the tangent space whenever $m<n$ . Intuitively, this seems like a generalisation of Taylor's theorem to vector-valued functions. Indeed, the equation of the tangent line is given by the Taylor polynomial of degree $1$ ... $$y=f'(a)(x-a)+f(a)$$ I'm not quite sure how to get from here to my formula though, or how to show that $T_\mathbf{u}\mathbf{f}$ is the tangent space of $\mathbf{f}$ for all [differentiable] $f:\Bbb{R}^m\to\Bbb{R}^n$ .","['geometry', 'tangent-spaces', 'multivariable-calculus', 'parametrization', 'differential-geometry']"
3427630,Devise winning strategy to hit moving target,"(Based on a problem from Brilliant). Suppose there is an enemy submarine at unknown location on real number line moving at unknown real-valued  velocity. You can fire one missile per minute in attempt to hit the submarine, and your missile will hit any submarine within fixed radius $\varepsilon>0$ . Is there a strategy to guarantee you hit the submarine in a finite number of steps? Note that if the submarine has integer position and integer velocity, then we can simply enumerate all position-velocity pairs $(x_1,v_1),(x_2,v_2),(x_3,v_3),\dots$ (since $\Bbb Z^2$ is countable) then on the $n$ -th step, fire your missile at position $x_n+nv_n$ , which is where the $n$ -th submarine would be at step $n$ . For integer-valued position and velocity, this is a winning strategy. For real-valued position and velocity, the problem can be formalized like this: Let $\varepsilon>0$ . Does there exist a function $f:\Bbb N\to\Bbb R$ such that for every linear function $s:\Bbb N\to\Bbb R$ , given by $s(n)=x+nv$ for $x,v\in\Bbb R$ , there exists $n\in\Bbb N$ such that $|f(n)-s(n)|<\varepsilon$ ? Attempt. For each $\varepsilon>0$ , $n\in\Bbb N$ , $f\in\Bbb R$ , the set $$\{(x,v)\in\Bbb R^2:|f-(x+nv)|<\varepsilon\}$$ (the set of all submarines you kill by firing at position $f$ and step $n$ )
forms a thin band in $\Bbb R^2$ . The question is whether for $n=1,2,3,\dots$ we can generate sequence of bands that cover the entire $\Bbb R^2$ (thus hitting every possible submarine, a winning strategy). Observe that the width of the bands $\to0$ as $n\to\infty$ , but the width is similar to $1/n$ so it's like the harmonic series which is not finite. This provides good hope that these bands can cover $\Bbb R^2$ but I cannot dream of a sequence $f$ which guarantees this.","['sequences-and-series', 'real-analysis']"
3427645,Does there exist a nonzero ring homomorphism from the ring of square rational matrices to the ring of rational numbers?,"I am wondering if it is possible to construct a nonzero ring homomorphism from $M_n(\mathbb{Q})$ to $\mathbb{Q}$ . So far, I've been unsuccessful in constructing such a nonzero ring homomorphism. Is there a possible construction? If not, how can we prove this? Thanks!","['ring-homomorphism', 'abstract-algebra', 'linear-algebra', 'rational-numbers']"
3427710,Problem from the shortlist of the Romanian Mathematical olympiad,"Let $A,B\in\mathit{M_{n}\left(\mathbb{C}\right)}$ and $c\in\mathbb{C}^{*}$ such that $AB-BA=c\left(A-B\right)$ . Prove that $A$ and $B$ have the same eigenvalues. My idea was to prove that $\operatorname{Tr}(A^k)=\operatorname{Tr}(B^k)$ , $\forall k\in \mathbb{N}$ . For $k=1$ this is obvious since $\operatorname{Tr}(AB-BA)=0$ . I could prove this for $k=2$ by multiplying the given relation by $A$ to the left and to the right respectively and then doing the same thing for $B$ . However, I was not able to use the same technique for higher powers and mathematical induction didn't work either. I think that my idea works because this was shortlisted for Grade 11 students from Romania, who only learn linear algebra, so a solution without abstract algebra should be possible, and the result I mentioned seems suitable for such a question. Furthermore, since it works even for $k=2$ it is just a matter of finding a generalisation.","['matrices', 'linear-algebra', 'contest-math']"
3427744,Solve this integral for free WiFi,"I saw this today, I checked in Mathematica and the integral comes out to $\pi$ , but I have no idea how to solve it. FREE Wi-Fi: The Wi-Fi password is the first $10$ digits of the answer. $$\int_{-2}^2\left(x^3\cos\frac x2+\frac12\right)\sqrt{4-x^2}\ dx$$","['integration', 'definite-integrals']"
3427758,Prove that the following limit equals $f''(a)$ if $f''(a)$ exists,"$1.$ Suppose that $f''(a)$ exists. Show that $\lim\limits_{h\to 0} \dfrac{f(a+h)+f(a-h)-2f(a)}{h^2}=f''(a).$ $2.$ Show by example that this limit may exist even when $f''(a)$ does not. My work: $1.$ By the derivative definition, $$f''(a) = \lim\limits_{h\to 0}\dfrac{f'(a+h)-f'(a)}{h}\\$$ $$=\lim\limits_{h\to 0} \dfrac{f'(a)-f'(a-h)}{h}.$$ To see this, let $k=-h.$ Then $k\to0\Leftrightarrow h\to 0$ and $$\lim\limits_{h\to 0}\dfrac{f'(a)-f'(a-h)}{h} = \lim\limits_{k\to 0}\dfrac{f'(a)-f'(a+k)}{-k}\\
=\lim\limits_{k\to 0}\dfrac{f'(a+k)-f'(a)}{k}\\
=\lim\limits_{h\to 0}\dfrac{f'(a+h)-f'(a)}{h}.$$ So the limit is equivalent to $$\lim\limits_{h\to 0}\dfrac{\frac{f(a+h)-f(a)}{h}-\frac{f(a)-f(a-h)}{h}}{h}\\
=\lim\limits_{h\to 0}\dfrac{f(a+h)+f(a-h)-2f(a)}{h^2}.$$ $2.$ Consider $f(x)=\begin{cases} x^2\sin (1/x)& x\neq 0\\ 0& x=0\end{cases}.$ We have that $f'(x) = 2x\sin(1/x)-\cos(1/x),x\neq 0$ and $f''(x) = 2\sin(1/x)-\dfrac{2}{x}\cos (1/x)-\dfrac{\sin(1/x)}{x^2},x\neq 0.$ Note that $f'(0)=\lim\limits_{h\to 0}\dfrac{h^2\sin (1/h)}{h}\\
=\lim\limits_{h\to 0} h\sin (1/h).$ Also, note that $\forall h>0, -h\leq h\sin(1/h)\leq h$ and $\forall h\leq 0,h \leq h\sin (1/h)\leq -h.$ Hence by the Squeeze Theorem, $\lim\limits_{h\to 0}h\sin (1/h)=\lim\limits_{h\to 0}h = 0.$ In order for $f''(0)$ to exist, we must have that $f'(x)$ is differentiable at $x=0.$ However, we will show that $f'(x)$ is discontinuous at $x=0$ and hence not differentiable there. We will do so by showing that $\lim\limits_{x\to 0^-}f'(x)$ does not exist. Consider the sequence $(x_n)_{n=1}^\infty$ such that $x_n = -\dfrac{1}{\frac\pi2 + 2n\pi}$ and the sequence $(y_n)_{n=1}^\infty$ such that $y_n=-\dfrac{1}{\frac{3\pi}{2}+2n\pi}.$ $\lim\limits_{x\to 0^-}f'(x)$ does not exist because $x_n, y_n\to 0$ as $n\to \infty\Rightarrow \forall \epsilon>0, \exists N (n\geq N \Rightarrow x_n,y_n \in (-\epsilon,0)).$ Since $f'(x_n)<0<f'(y_n)\;\forall n,$ we have that $f''(0)$ does not exist. However, we have that $$\lim\limits_{h\to 0}\dfrac{f(0+h)+f(0-h)-2f(0)}{h^2}=\lim\limits_{h\to 0}\dfrac{h^2\sin (1/h)-h^2\sin(1/h)}{h^2}\\
=0.$$ Thus, the limit exists at $x=0$ but the second derivative does not. edit for the first part (i should've used the taylor series instead). We have that $f(a+h) = f(a) + f'(a)h+f''(a)\dfrac{h^2}{2}+\dots$ and $f(a-h)=f(a)-f'(a)h+f''(a)\dfrac{h^2}{2}+\dots.$ Hence $f(a+h)+f(a-h)-2f(a)=h^2f''(a)$ and the desired limit is $\lim\limits_{h\to 0} \dfrac{h^2f''(a)}{h^2}=f''(a),$ as desired.","['limits', 'calculus', 'derivatives']"
3427776,Prove $\int_0^1\frac{x^{2n}}{1+x}dx=\ln2+H_n-H_{2n}$,"How to prove $$\int_0^1\frac{x^{2n}}{1+x}dx=\ln2+H_n-H_{2n}$$ I used this identity to solve some advanced harmonic series but I didn't provide a proof so I see that it's worth a post so that we can use it as a reference for future solutions if needed. Here is my approach and would like to see alternative ones . \begin{align}
\int_0^1\frac{x^{2n}}{1+x}dx&=\ln2-2n\int_0^1x^{2n-1}\ln(1+x)dx\tag1\\
&=\ln2-2n\sum_{k=1}^\infty\frac{(-1)^{k-1}}{k}\int_0^1 x^{2n+k-1}dx\tag2\\
&=\ln2+2n\sum_{k=1}^\infty\frac{(-1)^{k}}{k(k+2n)}\tag3\\
&=\ln2+4n\sum_{k=1}^\infty\frac{1}{2k(2k+2n)}-2n\sum_{k=1}^\infty\frac{1}{k(k+2n)}\tag4\\
&=\ln2+\sum_{k=1}^\infty\frac{n}{k(k+n)}-\sum_{k=1}^\infty\frac{2n}{k(k+2n)}\tag5\\
&=\ln2+H_n-H_{2n}\tag6
\end{align} Explanation: 1) Apply integration by parts 2) Write $\ln(1+x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}x^{k}$ 3) Use the rule $\int_0^1 x^ndx=\frac1{n+1}$ 4) $\sum_{k=1}^\infty (-1)^k f(k)=2\sum_{k=1}^\infty f(2k)-\sum_{k=1}^\infty f(k)$ 5) Simplify 6) Use $H_n=\sum_{k=1}^n \frac1k=\sum_{k=1}^\infty\frac{n}{k(k+n)}$ A good application for this identity is the following problem proposed by Cornel: $$\zeta(3)=\frac43\sum_{n=1}^\infty\frac{(2H_{2n}-H_n)(H_n-H_{2n}+\ln2)}{n}$$ If we multiply both sides of our identity by $\frac{2H_{2n}-H_n}{n}$ then sum up from $n= 1$ to $\infty$ we get $$\sum_{n=1}^\infty\frac{(2H_{2n}-H_n)(H_n-H_{2n}+\ln2)}{n}=\int_0^1\frac1{1+x}\sum_{n=1}^\infty\frac{x^{2n}}{n}(2H_{2n}-H_n)dx\\=\frac12\int_0^1\frac{1}{1+x}\ln^2\left(\frac{1-x}{1+x}\right)dx=\frac12\int_0^1\frac{\ln^2x}{1+x}dx=\frac34\zeta(3)$$ where the identity $\ln^2\left(\frac{1-x}{1+x}\right)=2\sum_{n=1}^\infty \frac{x^{2n}}{n}(2H_{2n}-H_n)$ was used in our calculations. Another application is calculating $\sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}$ : From our proof above, we can see that $$\int_0^1 x^{2n-1}\ln(1+x)dx=\frac{H_{2n}-H_n}{2n}$$ Replace $2n$ by $n$ then multiply both sides by $\frac{(-1)^n}{n^2}$ and sum up we get $$\sum_{n=1}^\infty \frac{(-1)^nH_n}{n^3}-\sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}=\int_0^1\frac{\ln(1+x)}{x}\sum_{n=1}^\infty \frac{(-x)^n}{n^2}dx\\=\int_0^1\frac{\ln(1+x)\operatorname{Li}_2(-x)}{x}dx=-\frac12\operatorname{Li}_2^2(-1)=-\frac12\left(-\frac12\zeta(2)\right)^2=-\frac5{16}\zeta(4)$$ I managed here to prove $$\sum_{n=1}^\infty \frac{(-1)^nH_n}{n^3}=2\operatorname{Li_4}\left(\frac12\right)-\frac{11}4\zeta(4)+\frac74\ln2\zeta(3)-\frac12\ln^22\zeta(2)+\frac{1}{12}\ln^42$$ Thus $$\sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}=2\operatorname{Li_4}\left(\frac12\right)-\frac{39}{16}\zeta(4)+\frac74\ln2\zeta(3)-\frac12\ln^22\zeta(2)+\frac{1}{12}\ln^42$$","['integration', 'alternative-proof', 'harmonic-numbers', 'calculus', 'sequences-and-series']"
3427794,Taking the derivative of x,"Let's see I have the following equation $$
x=1
$$ I take the derivate of both sides with respect to $x$ : $$
\frac{\partial }{\partial x} x = \frac{\partial }{\partial x}1
$$ Therefore, $1=0$ . Clearly, that is not the right approach. So what is the right way to think of $x=1$ . What kind of object is it?",['derivatives']
