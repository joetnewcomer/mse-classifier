question_id,title,body,tags
2663663,Finding the sin inverse,"Well, so I was finding the value of $\sin 15^{\circ} $. I used the identity $2 \sin x \cos x = \sin 2x $. So solving the quadratic equation and picking the right values simply gave me: $$ \sin 15^{\circ} = \frac {\sqrt {2 - \sqrt {3}}} {2}$$ That was pretty much simple. But I thought what if I was given the value instead, and I was asked to find the angle, whose sine would give me that value. In short, my question is how to evaluate: $$ \sin^{-1} \left( \frac {\sqrt {2 - \sqrt {3}}} {2} \right) $$ I want to solve it thinking that I do not know the value of $\sin 15 $, as if I have been just provided with the problem, and I have no idea what the answer might be. I tried to proceed by converting the $\sin $ to $\tan $ but that seemed to be of no use. Can anybody help?","['trigonometry', 'inverse-function']"
2663665,Understanding the Riemann Surface of the $\sqrt{z}$ [duplicate],This question already has an answer here : Intuitively understanding Riemann surfaces (1 answer) Closed 6 years ago . I have been trying all the day to understand the Riemann Surface of the $\sqrt z$. I Can not understand . Can anyone help me to understand how this picture is Riemann Surface of $\sqrt z$. The other questioner did not ask this question. He already could visualize my question's answer. So I request you not to try to block this question. This is the only source from where I get help.   Please read that question. Intuitively understanding Riemann surfaces Explanation in simple words will be highly appreciated.,"['riemann-surfaces', 'complex-analysis']"
2663712,It is always possible to define a topology in a vector space endow with a semi-norm?,"If $(X,\|\cdot\|)$ is a semi-normed vector space. It is always possible to define a topology on $X$? If it is true What is the definition of a closed subspace of $X$ with respect to $\|\cdot\|$? I guess that a subspace $M$ of $X$ is closed with respect to the semi-norm $\|\cdot\|$ if and only if every $(x_n)_n\subset M$ such that $\|x_n-x\|\to 0$ then $x\in M$.","['general-topology', 'locally-convex-spaces']"
2663726,Negative values in PCA,"I have been trying to understand the meaning of negative values in PCA and what actions/considerations to take when faced with them. The following figure is the scores plot originating from about 6000 variables in four different groups. As it can be seen group 1 clusters nicely in quadrant 2 while the rest are much more scattered. For example, group 3 is both positive and negative along PC2, and one of the samples in the same is almost completly the opposite in quadrant 3. My questions: Should this sample be removed? Could this have arisen as possible mislabeling of original groupings?","['statistics', 'linear-algebra']"
2663745,Compactness for finer topology,"Suppose that we have two topological spaces $(X,T_1)$, $(X,T_2)$ such that $T_1\subset T_2$ and $K\subset X$ is compact in $T_1$ topology. Is it also compact in $T_2$ topology ??? I think that the answer is yes, because we can cover $K$ with a finite collection of open sets that belong in $T_1$ topology, but we know that these open sets belong also in $T_2$, so it is going to be compact in $T_2$. Is this true ??",['general-topology']
2663814,Proving integral identity for solution to Bessel equation,"I read in a book that $$\int_0^1x[J_n(\alpha x)]^2dx = \frac{1}{2}[J_n'(\alpha)]^2$$ where $\alpha$ is a zero of $J_n$ and where $J_n$ is a solution to Bessels equation. The book gives a hint telling me to use the substitution $z=\alpha x$ and then integrating by parts and then use the fact that $J_n$ solves Bessels equation. I tried to use the hint to prove this, but end up going in circles when Integrating by parts.","['bessel-functions', 'ordinary-differential-equations']"
2663824,Pythagorean theorem painting,"I came across this painting( http://www.galleriarusso.com/works/10586-pythagorean-theorem.html ) which clearly shows a dissection proof of the pythagorean theorem. The closest proof I found was #72 on this page . I have two questions.
1) Would someone be kind enough to walk me through a proof of the #72 diagramm on the above page and 
2) Can anyone suggest a proof based on the dissection in the painting.
Thanks in advance!","['art', 'geometry']"
2663857,How to solve $y(\cos x+\ln y )+(x+ye^y)y'=0$?,"Find the general solution of the following differential equation:
$$y(\cos(x)+\ln(y))+(x+ye^y)y'=0$$ I have not even been able to change this equation to a better form.",['ordinary-differential-equations']
2663863,Statement and proof of the sequential characterization of limits,So frequently on this site I will use the sequential characterizations of limits and continuity in my answers only to find the OP is unfamiliar with it. It is such a crucial notion that I am going to write the statement and proof here so that I (and others) can link it in answers.,"['real-analysis', 'limits']"
2663894,Confused as to How I should Interpret the Exponential Distribution and its Probability Density Function,"I'm confused as to how I should be interpreting the exponential distribution and its probability density function (PDF). I'm specifically referring to the fact that it peaks close to $x = 0$ and then tapers off. Does the PDF of an exponential distribution indicate that (some type of) machinery is MOST likely to fail immediately after it is built? In other words, does it indicate that the probability of failure is highest right after the machinery has been built? This doesn't seem to intuitively be correct, since machinery should have the least chance of failure if it is brand new, right? This makes me suspect that I'm misunderstand something. Example #1: Example #2: Example #3: Take examples #2 and #3. Example #2 has had the PDF superimposed on top of it. Since the PDF is largest close to $x = 0$, how do I interpret this? If I compare it to example #3, then it would be saying that the probability is highest that the time to failure is small -- somewhere between 0-80? But that would mean that the machinery is most likely to fail soon after it is brand new! And so it doesn't seem to make intuitive sense. I'm very confused as to how I should be interpreting this, and I would greatly appreciate it if people could please take the time to clarify.","['exponential-distribution', 'probability-theory', 'density-function', 'probability-distributions']"
2663902,How is a parabola related to a circle?,"I know this seems like an incredibly general or even silly/random question, however, please allow me to explain why I'm asking this question. Someone who, for example, didn't understand that trigonometric functions and circles are related, would be missing out on a whole genre of important possible insights about trigonometry and circles. I feel that I am missing a similar important understanding of a connection between parabolas and circles. Here's why. Note that if you plot a pendulum's position against time it would form a sine/cosine function. The force that sets a pendulum in motion is gravity. That same force causes a ball to fall in a parabolic path. Circles -> sine functions -> pendulum -> gravity -> parabola. Something else led me to this question, but this was my way of explaining it. I feel like I'm missing an insight that is deep, beautiful, and important.","['algebraic-geometry', 'physics', 'trigonometry', 'algebra-precalculus', 'geometry']"
2663932,How to compute this constant with high precision $\sum_{n=1}^\infty \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)$,"I'm interested in finding the following constant: $$b=\sum_{n=1}^\infty \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)$$ Where: $$a_1=2$$ $$a_{n+1}=a_n+\log a_n$$ This is related to my recent question where the sequence was first introduced and it was shown in the answer that: $$\lim_{n \to \infty} \frac{a_n}{n \ln n}=1$$ I wanted to see what the constant above looks like, because this is similar to how the Euler-Mascheroni constant is obtained from the harmonic series and the logarithm. The problem is, the convergence of the above series is extremely slow. And I mean so slow, that I'm not even sure what the first digit is. From Mathematica computations it seems that: $$0.1 <b <0.2$$ But I'm only sure about the upper bound, because $b$ becomes smaller as the number of terms increases. Note that even though initial partial sums are negative, $b$ becomes positive soon, because the sequence $a_n$ gets overtaken by $(n+1) \ln (n+1)$, even if they are of the same order. You can see that in the linked question. Then $a_n$ overtakes $(n+1) \ln (n+1)$ again, and partial sums start to decrease. Mathematica gives: $$\sum_{n=1}^{10^7}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.18702446577 \dots$$ But at least the second digit is different from the true value of $b$, as can be seen by adding further terms. $$\sum_{n=1}^{10^8}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.1738163796928 \dots$$ (In case it's important, I was keeping only $100$ digits of each $a_n$ while computing the recurrence terms. Maybe there's some loss of precision there as well). Update $$\sum_{n=1}^{10^9}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.162 \dots$$ (I have more digits, but it's clear they don't matter at this point). And for some $10^9<N<10^{10}$ (aborted computation) we have: $$b<0.1599565$$ Can we find at least a few first digits of $b$? What methods would you suggest for accelerating the series or transforming it somehow for faster convergence? The motivation for this question is not the sequence itself (I don't believe it has any significance) but rather methods for solving this kind of problems. As a side question, can we at least prove that the series converges? I'm rather convinced it does, but just in case. For other series related to the sequence we have, reliably: $$\sum_{n=1}^\infty \frac{1}{a_n^2}=0.57409540\dots$$ $$\sum_{n=1}^\infty \frac{(-1)^{n+1}}{a_n}=0.285408\dots$$ The convergence is quite slow for these cases as well, which was expected by comparison with known series.","['logarithms', 'recurrence-relations', 'sequences-and-series', 'convergence-acceleration']"
2663952,Why this function is undefined at $x=0$ and $x=5$,"According to my understanding, the domain of $\sqrt{x}$ is $x \ge 0$. If this is correct, shouldn't the domain of the function 
$$\frac{1}{(x^2-5x)^{1/4}}$$
be $x \le 0$ or $x\ge 5$ instead of $x<0$ or $x>5$? What am I getting wrong? (the answer is $x<0$ or $x>5$).","['algebra-precalculus', 'functions']"
2664049,Strings not starting and ending with the same number,"Before you mark this as a duplicate, please read! I am having trouble understanding the concept (which I need more clarification on than is provided) rather than just the answer: For any integer $n \ge 2$ , let $S_n$ be the number of bitstrings of length $n$ in which the first bit is not equal to the last bit. The answer is $2^{n-1}$ But why? In my brain, when you say that the first and last bit are the same, that means you are going to set aside two bits and make sure they are equal, hence $2^{n-2}$ . Since we want only the bitstrings that do not start and end with the same bit, we can subtract this from all possible bitstrings, so: $2^{n} - 2^{n-2}$ .
But this is wrong! Similarly: How many bitstrings of length $99$ are there that start with $1010$ and end with $1010$ ? Is the answer for this $2^{99-4}$ like above, or is it $2^{99-8}$ ? If it is the latter, how come?","['combinatorics', 'discrete-mathematics']"
2664062,Why are these two ways of evaluating the curl of a vector field not actually equivalent?,"I was asked to calculate the curl of the vector field $\theta^2\bf e_\theta$ in spherical coordinates . If we use the typical formula for curl in curvilinear coordinates:
$$
\nabla\times \bf F = \left|\begin{matrix}h_1\hat{\bf e_1} & h_2\hat{\bf e_2} & h_3\hat{\bf e_3} \\ \displaystyle\frac{\partial}{\partial q_1} & \displaystyle\frac{\partial}{\partial q_2} & \displaystyle\frac{\partial}{\partial q_3} \\ h_1F_1 & h_2F_2 & h_3F_3\end{matrix}\right|
$$
where, in spherical coordinates, $(q_1,q_2,q_3) = (r,\theta,\phi)$, and $h_1 = 1$, $h_2 = r$, $h_3 = r\sin\theta$, then we get
$$
\nabla\times(\theta^2{\bf e}_\theta) = r\theta^2\sin\theta\bf e_\phi
$$ I wanted to check this, so I thought I'd try converting the original vector field into Cartesian coordinates, taking the curl in Cartesian coordinates, and converting back. Using 
$$
\theta = \arctan\left({\frac{\sqrt{x^2+y^2}}{z}}\right) \\
{\bf e_\theta} = \frac{(x\hat{\bf i} + y\hat{\bf j})z - (x^2+y^2)\hat{\bf k}}{\sqrt{x^2+y^2+z^2}\sqrt{x^2+y^2}}
$$
we get
$$
\theta^2{\bf e}_\theta = \frac{\arctan^2\left(\frac{\sqrt{x^2+y^2}}{z}\right)}{\sqrt{x^2+y^2}\sqrt{x^2+y^2+z^2}}\left(xz,yz,-(x^2+y^2)\right)
$$ After some tedious calculation, this (somewhat remarkably) comes out to 
$$
\nabla\times{\bf F} = \frac{\arctan^2\left(\frac{\sqrt{x^2+y^2}}{z}\right)}{\sqrt{x^2+y^2}\sqrt{x^2+y^2+z^2}}(-y{\bf\hat{i}}+x{\bf\hat{j}})
$$
This takes some work to convert back to polar coordinates, but without converting the unit vectors back immediately we have
$$
\nabla\times{\bf F} = \frac{\theta^2}{r}(-\sin\phi{\bf\hat{i}} + \cos\phi{\bf\hat{j}})
$$
After substituting
$$
{\bf\hat{i}} = \sin\theta\cos\phi{\bf\hat{r}}+\cos\theta\cos\phi\hat{\theta}-\sin\phi\hat{\phi} \\
{\bf\hat{j}} = \sin\theta\sin\phi{\bf\hat{r}} + \cos\theta\sin\phi\hat{\theta} + \cos\phi\hat{\phi}
$$
into the above formula, we get
$$
\frac{\theta^2}r{\bf e}_\theta
$$
which is... not the same. So clearly, my intuition is wrong, or my assumption that these two ""curls"" in different coordinate systems are the same (since, assuming I didn't make any mistakes in my derivation, this would imply that ""spherical curl"" is somehow fundamentally different from ""Cartesian curl""), or I made a mistake somewhere. Or something else. Which is it? Can someone guide me in the right direction please?","['multivariable-calculus', 'curvilinear-coordinates']"
2664085,Tips for finding a closed form from the following unusual recurrence relation,"Consider the following functions: $f_0(x)=1$ $f_1(x)=\sum_{i=2}^x [(i-1) \cdot f_0(i)] = \frac{(x-1)x}{2}$ $f_2(x)=\sum_{i=2}^x [(i-1) \cdot f_1(i)] = \sum_{i=2}^x \frac{(i-1)^2i}{2} = \frac{(x-1)x(x+1)(3x-2)}{24}$ And so on. Essentially: $f_{k}(x)=\sum_{i=2}^x [(i-1) \cdot f_{k-1}(i)]$ and $f_0(x)=1$  as the base case, where $x$ and $k$ are natural numbers and $x\ge2$. I am trying to find a closed form formula for $f_k(x)$ that only depends on $k$ and $x$, but I'm not sure if this is possible at all. Is there a name for this recurrence or is there anything similar I could read on that could be helpful in solving this, I've tried all I could think of, so any tips or advice in the right direction would be great.","['recurrence-relations', 'sequences-and-series', 'discrete-mathematics']"
2664119,Prove $ {(\sum\limits_{i = 1}^{2n + 1} {{a_i}} )^2} \geqslant 4n\sum\limits_{i = 1}^{n + 1} {{a_i}{a_{i + n}}}$ if $a_1 \geqslant â€¦\geqslant a_{2n+1}$,"For any positive integer $n$ , and real numbers (not necessarily positive) $a_1\geqslant a_2 \geqslant â€¦\geqslant a_{2n+1}$ , show that $$
{(\sum\limits_{i = 1}^{2n + 1} {{a_i}} )^2} \geqslant 4n\sum\limits_{i = 1}^{n + 1} {{a_i}{a_{i + n}}}.$$ What I've tried: I set $x_i :=a_i - a_{i+1}$ for $i\leqslant 2n$ and $x_{2n+1}:=a_{2n+1}$ , and calculate the coefficients on both sides, but gradually  find it difficult to go further, perhaps it just can't.
Please help. Something more: if all $a_i=1$ except $a_{2n+1}=0$ , the equality holds.","['algebra-precalculus', 'inequality']"
2664161,Find all points of contact of horizontal tangents to the curve $y = 2\sqrt x + \frac 1{ \sqrt x}$,"Find all points of contact of horizontal tangents to the curve $$y = 2\sqrt x + \frac 1{ \sqrt x}$$ I found the derivative:
$$\frac {dy}{dx} = x^{-1/2} - \frac 12x^{-3/2}$$
Which can be simplified down to
$$ \frac {dy}{dx} = \frac  1{\sqrt x} - \frac 1 {2x\sqrt x}$$ Then I used the Null Factor Law:
$\frac{1}{\sqrt{x}} = 0$ or $\frac{1}{2x \sqrt{x}} = 0$. I got stuck here.","['derivatives', 'tangent-line', 'differential', 'calculus']"
2664171,"Upper bound on P(S_n > a) by mgf, Strong Law Large Numbers Proof Casella, Berger","Having trouble coming up with a proof for a problem related to SLLN using MGFS. I found Strong Law of Numbers for $S_{n}$ Bounded Casella Berger 5.38 but the answer doesn't seem to hint at how we could establish some lower bound. I've put my effort below, but it feels cheap , are there other methods in which I can approach this problem? Problem statement: 
Let $X_1,...,X_n$ be iid random variables with mgf $M_X(t),-h<t<h$, let $S_n=\sum_{i=1}^nX_i$ and $\bar{X}=\frac{1}{n}S_n$ I've already via Markov inequality shown that $$P(S_n>a)\le e^{-at}[M_X(t)]^n$$
and
$$P(S_n \le a) \le e^{-at}[M_X(t)]^n$$
Now we must prove that for $E[X]<0$ and $M_X(0)=1$ there exists $0<c<1$ s.t $P(S_n>a) \le c^n$. Now my first instinct is to use a Taylor expansion: $$M_X(t) \approx M_X(0) + M_X'(0)t =1 + tE[X]$$ However I can only see this bringing us to the upperbound in the link mentioned earlier: 
$$M_X(t) \le 1 + t\frac{E[X]}{2} \le 1$$
Since $E[X]$ is negative, or the second derivative of the mgf is negative near 0. Taking t=0 gives us the 1 as the final upperbound. The nth power of the mgf retains the property of 1 as an upperbound. Since we are confident of the upper-bound on $M_X(t)$ in the neighbourhood of 0 couldn't we just use: $$P(S_n>a) \le c^n = \left[ e^{-at/n}*M_X(t) \right]^n?$$ We've shown that from $E[X]<0$, $M_X(t)$ is bounded above by 1 in the neighbourhood of 0. In addition as n grows, since $0<c<1$, then $0<c^n<1$. Am I missing something here? I should note that nothing about the nature of $a$ is given, I assumed it was positive above. Hints would be appreciated, my analysis skill-set is limited and something I'm working on!","['law-of-large-numbers', 'real-analysis', 'probability-theory', 'statistics', 'moment-generating-functions']"
2664178,Intuition behind proving that $f$ is constant,"Let $f: \mathbb R \to \mathbb R$ is a continuous function such that $\lim_{h \to 0^+} \frac{f(x+2h)-f(x+h)}{h}=0$. Prove that $f$ is constant. This is a question taken from the book Putnam and Beyond, question 389. I looked at the solution, which goes roughly as follows. Suppose on the contrary that there is $a < b$ with different image, say $f(a) > f(b)$. Define $g(x) =f(x)+ \lambda x$ where $\lambda >0$ is sufficiently small to make $g(a) > g(b)$. We have that $\lim_{h \to 0^+} \frac{g(x+2h)-g(x+h)}{h}=\lambda$. Since $g$ is continuous on $[a,b]$ a closed and bounded interval, $g$ attains a maximum, say $c \neq b$. fix $\epsilon >0, \epsilon < \lambda$. Then by continuity there is $\delta$ such that $0 < \lambda - \epsilon < \frac{g(x+2h)-g(x+h)}{h} < \lambda + \epsilon$ for all $0 < h< \delta$. Fix $0< h_0<min\{\delta, (b-c)/2\}$. Then $g(c+2h_0) >g(c+h_0) >...>g(c+\frac{h_0}{2^m})$... for any natural number $m$ so that, by taking the limit as $m$ goes to infinity, $g(c+2h_0) > g(c)$ contradicting the maximality of $g$ on $[a,b]$. Thus it must be that our initial assumption was false, and hence our conclusion. I get the proof, but I was wondering what is the intuition behind this solution. How would a problem solver come up with the idea for this solution? Please be more specific than 'it takes practice to recognize pattern'.","['continuity', 'problem-solving', 'soft-question', 'limits']"
2664200,Prove all values are zero,"Suppose $\lambda_{1,\cdots,n}\in\Bbb C$ and for all $m\in\Bbb N_+$ we have 
$$\sum_{i=1}^n \lambda_i^m=0.$$
Prove that all $\lambda_i$ are zero. Is there any easy approach that doesn't play with algebraic manipulations like symmetric polynomials or Vandermonde determinants? A purely analytical approach would be preferred (e.g. observe the equations as $m$ tends to infinity). Thanks!","['algebra-precalculus', 'real-analysis', 'linear-algebra']"
2664218,How Are the Solutions for Finite Sums of Natural Numbers Derived?,"So, I've been learning set theory on my own (Lin, Shwu-Yeng T., and You-Feng Lin. Set Theory: An Intuitive Approach. Houghton Mifflin Co., 1974.) and have come across infinite sums of natural numbers.  Since I took Algebra II many years ago, I've known of the results of these sums for the purpose of solving summations.  (I also know of the formula (and its flaws) which states the sum of the set of natural numbers is $-1/12$).  Just for reference, I've listed six infinite series of natural numbers below (they are the six listed in the 44 year old textbook I'm using): $$\sum_{k=1}^{n}k=\frac{n(n+1)}{2}$$
$$\sum_{k=1}^{n}k(k+1)=\frac{n(n+1)(n+2)}{3}$$
$$\sum_{k=1}^{n}k^2=\frac{n(n+1)(2n+1)}{6}=\frac{n^3}{3}+\frac{n^2}{2}+\frac{n}{6}$$
$$\sum_{k=1}^{n}k^3=\frac{n^2(n+1)^2}{4}=\frac{n^4}{4}+\frac{n^3}{2}+\frac{n^2}{4}$$
$$\sum_{k=1}^{n}(2k-1)=n^2$$
$$\sum_{k=1}^{n}\frac{1}{k(k+1)}=\frac{n}{n+1}$$ Now that I've started learning set theory, I now know how to prove these results using mathematical induction (which admittedly, I had a lot of fun doing).  However, I still have a few questions about this. Firstly, through my own research, I found a list of mathematical series on Wikipedia , but this list does not have all the series listed in the textbook.  So, is there a list elsewhere of all series of natural numbers, and if so then where?  (Now that I think of it, what if there is an infinite amount of infinite series; although this may be the case, obviously not all of them would be practical, as many maybe could be simplified into general cases).  Second (and most important), although I know how to prove these results using mathematical induction, I do not know how to derive them.  How would one go about actually deriving such a result for an infinite series?  The method could not possibly be trial and error by using mathematical induction on random expressions.  I cannot think of a method myself at this time, but I know there must be some way of doing this.  And lastly, if you can think of a better title for the question, please let me know, since I did have trouble coming up with a suitable title.  Thank you in advance to whoever is able to help!","['number-theory', 'summation']"
2664235,Uniqueness of a solution of $\ x' = Ax + b(t) \ $ that tends to $0$ in $+\infty$,"Let $b : [0,+\infty) \to \mathbb R^n$ continuous and integrable. Prove there exists an unique solution of $x' = Ax + b(t)$ that tends to $0$ in $+\infty$ with $A \in M_n{(\mathbb R)}$. I don't really see how to deal with this problem if not to integrate the equation. Is not a condition on $A$ needed? If a condition is needed, then it would be $A$ is antisymmetric.","['matrices', 'real-analysis', 'ordinary-differential-equations']"
2664300,"For general $n \in \Bbb N$ , how to determine all groups (both finite and infinite) having exactly $n$ conjugacy classes?","I was trying to solve the following problem : Determine all the finite groups having exactly 3 conjugacy classes. My attempt: Among all abelian groups $(\Bbb Z_3,+)$ only satisfies the property , because all other abelian groups of order $n$ , ($n \neq 3$) are having $n$ elements in the center of the group and hence there are exactly $n$ conjugacy classes. In case of non-abelian groups, if we look at the permutation groups it is again clear that $S_3$ is the only permuatation group having the property because collection of conjugacy classes in permutation groups have one-to-one correspondence with the collection of distinct cycle types. And in case of Dihedral groups it clearly follows that $D_3$ has the above property and in fact $D_3 \cong S_3$ . The Quarternion group also does not have the property. So my precise questions are : $(i)$ Now by considering semi-direct products of these non-abelian groups can the argument be extended? $(ii)$ Apart from the Permutation groups, about all other non-abelian groups my attempts are mere observations, so how to give a rigorous argument. I would like to mention that I've gone through this question . It deals with infinte periodic group , but my question is for all infinite groups : $(iii)$ Is there any infinite group having exactly 3 conjugacy classes . I have also seen this question and this one as well. They only discussed about finite groups and I was not quite clear with the answers over there. Hence, trying to generalize the problem : $(iv)$ For general $n \in \Bbb N$ , how to determine all groups (both finite and infinite) having exactly $n$ conjugacy classes ? And about the last question I only can state echoing the arguments for $n=3$ , there is exactly one finite abelian group having the property. Thanks in advance for help.","['abstract-algebra', 'infinite-groups', 'group-theory']"
2664337,A simpler proof of Recursion Theorem,"Recursion Theorem: Let $A$ be a set, $a\in A$, and $f \colon A\to A$ a mapping. Then there exists a unique mapping $g \colon \Bbb N\to A$ such that 1. $g(0)=a$ 2. $g(n+1)=f(g(n))$ I formalize a proof based on the comments of Noah Schweber at here and here . Fix $a\in A$. Let $Y=\{(n,x)\in\mathbb{N}\times A\mid \text{ there exist a sequence of length}$ $n$, in which first term is $a$, last term is $x$, and each term after the first is $f$ of the previous term$\}$. Now we prove by induction: for each $n\in \mathbb{N}$, there exists a unique $y\in A$ such that $(n,y)\in\mathbb{N}\times A$. For $n=0\implies$ only $y=a$ such that $(0,a)\in Y$. Assume that for $n=k$ there exists a unique $y\in A$ such that $(k,y)\in Y\implies$ for $n=k+1$, there exits a unique $f(y)$ such that $(k+1,f(y))\in Y$. $\implies$ For all $n\in \mathbb{N}$, there exists a unique $y\in A$ such that $(n,y)\in Y$ $\implies$ Set $Y$ defines a function $g \colon \Bbb N\to A$ such that 1. $g(0)=a$ 2. $g(n+1)=f(g(n))$ Please check my proof above! Many thanks!","['recurrence-relations', 'elementary-set-theory', 'proof-verification']"
2664348,How to prove/disprove this inequality?,"Given a series of independent random variables $\{X_i\}$, such that: $P(X_i= i^{1/2})=\frac{1}{2i^{1/2}}$ , $P(X_i=-(i^{1/2}))=\frac{1}{2i^{1/2}}$, $P(X_i=0)=1-\frac{1}{i^{1/2}}$.i is a natural number. Prove or disprove:
limit of $P\left(\left|\frac{X_1+X_2...+X_n}{2} - \frac{1}{2}\right|< \frac{1}{100}\right)$ as $n\to \infty$ equals to $1$.
It seems I could use chebychev or the weak law of large numbers somehow (I already managed to see that they all have the same expectation that equals zero) ...any ideas ?","['law-of-large-numbers', 'probability-theory', 'probability']"
2664383,Can a sequence of conformal diffeomorphisms converge to something which is neither a diffeomorphism nor a point?,"This is a follow-up of this question . Let $M$ be a compact oriented Riemannian manifold, of dimension $d\ge2$. Let $f_n \in \text{Diff}^+(M)$ be a sequence of orientation-preserving conformal diffeomorphisms which weakly converges in the Sobolev space $W^{1,p}(M;M)$ to a limit $f$. (for some $p>1$. I am ready to assume $p > \dim M$). Is it true that $f$ must be either a constant map or a diffeomorphism? (Or perhaps $f$ must be either constant or an immersion?). As an element in a Sobolev space, $f$ is only defined up to a measure zero set. So, the question is whether or not there always exists a representative which is smooth and is either constant or a diffeomorphism. In this answer , a sequence of diffeomorphisms $f_n:\mathbb{S}^1 \to \mathbb{S}^1$ is constructed; the limit of $f_n$ maps half of the circle onto $\mathbb{S}^1$, and the other half to a point. I tried to build from this sequence a higher-dimensional example, but couldn't do so in a conformal way. (e.g. $f_n \oplus f_n$ or $f_n \oplus \text{Id}$ are not conformal).","['diffeomorphism', 'riemannian-geometry', 'differential-topology', 'conformal-geometry', 'differential-geometry']"
2664395,Finding the solution to a non-homogeneous matrix exponential.,"Consider $$\frac{d}{du}  \begin{bmatrix}a\\b \end{bmatrix}  = \begin{bmatrix}-x& y\\ -y&-x\end{bmatrix}  \begin{bmatrix}a\\ b\end{bmatrix} + \begin{bmatrix}\cos(zu)\\ -\sin(zu)\end{bmatrix}$$ where $P = \begin{bmatrix}-x& y\\ -y&-x\end{bmatrix}$. And I have it for $u=0:$
$$\begin{bmatrix}a\\b \end{bmatrix} = \begin{bmatrix}0\\0 \end{bmatrix}$$ Having proved that $\exp\left[Pu\right] = \exp\left[-xu\right]$ $$\begin{bmatrix}\cos(yu)& \sin(yu)\\ -\sin(yu) & \cos(yu)\end{bmatrix}.$$ My question is: How do I use this proof to solve this problem using the initial conditions? Having thought about it - I consider that using the double angle formulae may help although I haven't been able to formulate this. Any help would be welcome.","['matrix-exponential', 'ordinary-differential-equations', 'systems-of-equations']"
2664460,When is every direct product of a ring also a free module?,"Let $R$ be a non-zero commutative (unital) ring, such that the direct product $R^X$ is a free $R$-module, for any set $X$. What can be said on $R$ ? 
  For instance, does it have to be a field / artinian / local … ? What happens if we assume that $R$ is an integral domain ? Notice that I'm not imposing any condition on the rank of the free $R$-module $R^X$. (See here for the case where $R$ is a field). 
When $R = \Bbb Z$, it is well-known that $R^{\Bbb N}$ is not a free $\Bbb Z$-module. Also, if any unital $R$-module is free, then $R$ is a field. I saw this question , which tells us that $R$ is a coherent ring. 
The literature calls ""$F$-rings"" the rings I'm looking for, see this very relevant paper When a Ring Is an F-Ring by John D. O'Neill  and this other source .
O'Neill's paper gives a complete characterization in Corollary 3.2, but the conditions are a bit complicated. Even the example 3.7 does not answer completely my question: if $R$ is an integral domain, then is $R$ necessarily a field? Otherwise, what would be some concrete (explicit) counter-examples? Thank you for your comments and remarks.","['abstract-algebra', 'modules', 'free-modules', 'commutative-algebra']"
2664478,Find a distance based on height and angles towards base and top of an object?,"Suppose I know the vertical height of an object and the angles (in relation to horizontal) towards the top and bottom of it. Is it possible to calculate the horizontal distance to the object based on this information? In the image below, the height of the object is y , the horizontal distance is x and the angles between horizontal and the top/bottom of the object are a and b . The knowns are y , a and b , and I want to find x . Is this even possible to do exactly, or do I need to make some kind of estimation (I'm gonna implement this in software).","['angle', 'problem-solving', 'trigonometry', 'estimation', 'triangles']"
2664483,"Why is $\mathcal{C}=\{\{ X_T \in A \} \text{ or } \{ X_T \in A \} \cup \{T=\infty \},A \in \mathcal{B}(R) \}$ closed under complementation","Why is $\mathcal{C}=\{\{ X_T \in A \} \text{ or } \{ X_T  \in A\} \cup \{T=\infty \},A \in \mathcal{B}(R) \}$ closed under complementation where  X is a random measurable process and T a random time? This is (Problem 1.17) in Karatzas and Shreve. My problem : 
If I choose $D=\{ X_T \in A \}$  then clearly $D^c=\{ X_T \in A^c \} \in C$ but when D is of the form $D=\{ X_T \in A \} \cup \{T=\infty \}$ then $D^c=\{ X_T \in A^c\} \cap \{T< \infty \}$ which I cant show is in $\mathcal{C}$ Can you please help?","['stochastic-processes', 'probability-theory', 'measure-theory', 'random-variables']"
2664546,Domain of k in $f(x)=x^3+kx^2+5x+4\sin^2x$,"The question says: Let $f(x)=x^3+kx^2+5x+4\sin^2x$ be an increasing function on $x \in R$. Then domain of k is? This is What I tried: I tried differentiating the expression but $f'(x)$ didn't turn out to be a quadratic(as it has that $\sin2x$ term)
$$f'(x)=3x^2+2kx+5+4\sin2x>0$$ So how else am I supposed to solve this question?","['derivatives', 'calculus']"
2664590,"Absolute values of sums of subsets of nth roots of 1, equalities without obvious symmetry.","I attempt to count the number of different absolute values of sums of subsets of $n$-th roots of 1. Since the $n$-th complex roots of 1 lie on the unit circle and form an $n$-gon, it is immediately obvious that subsets (of roots) show rotation and reflection symmetry. This multiplicity can be eliminated from the count by specifying the subsets using Polya's bracelet (reversible necklace) counting. See OEIS A052307 . Moreover, since the sum of all $n$ roots is zero, we need only consider bracelets with $0$ to $\lfloor n/2 \rfloor$ white beads and the rest black. So, in terms of subset selections, we need only count subsets of upto $\lfloor n/2 \rfloor$ roots. The count of all possible ($0,1$-exchangable) bracelets upto $n=19$ is: $1, 2, 2, 4, 4, 8, 9, 19, 23, 47, 63, 137, 190, 410, 612, 1345, 2056, 4536, 7155$ The count of all different absolute values of sums of subsets of the complex $n$-th roots of 1 for $n$ upto $19$ is: $(2), 2, 2, 3, 4, 4, 9, 10, 17, 18, 63, 24, 187, 96, 281, 241, 1964, 226, 6831$ Surprisingly, for $n$ prime in $(2,3,5,7,11)$ both counts are equal, but for $n$ in $(13,17,19,23, \ldots)$ there are subsets of roots with identical absolute value sums but with no obvious symmetry. Example: for $n=13$, $\{0,0,0,0,0,0,1,0,1,0,0,1,1\}$ and $\{0,0,0,0,0,1,0,0,0,1,1,0,1\}$ sum to $\sqrt3$ $\{0,0,0,0,1,0,0,1,1,0,1,1,1\}$ and $\{0,0,0,1,0,0,1,1,1,1,0,0,1\}$ to $(7+\sqrt{13})/2$ $\{0,0,0,0,1,1,0,1,0,1,0,1,1\}$ and $\{0,0,0,1,0,1,0,0,1,0,1,1,1\}$ to $(7-\sqrt{13})/2$ These $3$ 'doublets' decrease the count for $n=13$ from $190$ to $187$.
For $n=17$ I find $92$ doublets, and $n=19$ has $324$ doublets.
Even better: $n=23$ has $3861$ doublets and $44$ triplets. How can this be? What kind of non-symmetric equivalence is operating here?","['combinatorics', 'discrete-mathematics', 'elementary-number-theory']"
2664612,Differential equation involving cross product.,"I have the differential equation $$f'=c \times f$$ for $f: \mathbb{R} \to \mathbb{R}^3$ and constants $c \in \mathbb{R}^3$. 
How can I solve something like this?","['cross-product', 'ordinary-differential-equations']"
2664643,"What is the number of arrangements in the word ""DAUGHTER"" where vowels are never together?","My approach: Let us suppose any two of the vowels be one letter. So, total no. of letters becomes $7$. Again, the vowels will change position among themselves. Therefore, total no of permutation where at least $2$ vowels are consecutive $= 7!.3!$ Finally, the no. of permutation where at least $2$ of the vowels are consecutive or, in other words, vowels are never together
$=8!-7!.3!=10080$ But the answer is $14400$. Why am I wrong?","['permutations', 'combinatorics']"
2664654,Prove that there is a unique topology given interior operator,"Suppose $f: \mathcal{P}(X) \to \mathcal{P}(X)$ is a function that satisfies, for every set $A,B \subseteq X$ $(I_1): f(X) = X$ $(I_2): f(A) \subseteq A$ $(I_3): f(A \cap B) =f(A) \cap f(B)$ $(I_4): f(f(A)) = f(A)$ Prove that there exists a unique topology $\mathcal{T}$ on $X$ such
  that for all $A \subseteq X$, $int(A) = f(A)$, where $intA := \{a \in A \mid A \in \mathcal{V}(a)\}$ denotes the
  interior of the set $A$, with respect to the topology $\mathcal{T}$ My attempt : I defined $\mathcal{T}:= \{A \subseteq X \mid f(A) = A\}$ and I managed to prove with $I_1, I_2, I_3$ that this set is a topology, and that it is unique, if it exists. So I only need to show that it exists, for which I have to prove that $int(A) = f(A)$ whenever $A \subseteq X$ I know that $I_4$ will be crucial to show this, as I did not use it yet. How would I complete the proof? Edit : I can show that $int(A) \subseteq f(A)$. I just need the other inclusion and I'm done!",['general-topology']
2664675,Find the value of $f(1/4)$?,"Suppose $f: D=\{z \in \mathbb{C}: \vert z \vert <1 \} \rightarrow D$ is analytic and $f(0)=0$ and $f(1/2)=\frac{1}{2\sqrt2}+i\frac{1}{2\sqrt2}$. Find the value of $f(1/4)$? I check $\vert f(1/2)\vert=1/2$,but how I can use this result to find the value of $f(1/4)$?","['complex-analysis', 'analytic-functions']"
2664722,"$\det (A+B)=\det (A-B)$, prove that $B^{-1}$ exists iff $b_{11}\neq b_{21}$","Let $A=\begin{pmatrix}
0 & 1 & 2 \\
0 & 1 & 2 \\
0 & 2 & 3 
\end{pmatrix}\in \mathbb{R}^{3\times 3}$ and let $B=\left [b_{ij}\right ]\in \mathbb{R}^{3\times 3}$ such that $\det \left (A+B\right )=\det \left (A-B\right )$. Prove that $B$ is invertible if and only if $b_{11}\neq b_{21}$. After simplifying by using properties of the determinant, the condition $\det \left (A+B\right )=\det \left (A-B\right )$ becomes $\det \begin{pmatrix}
b_{11} & b_{12} & 2 \\
b_{21} & b_{22} & 2 \\
b_{31} & b_{23} & 3 
\end{pmatrix}=-\det \begin{pmatrix}
b_{11} & 1 & b_{13} \\
b_{21} & 1 & b_{23} \\
b_{31} & 2 & b_{33} 
\end{pmatrix}$, providing that I did not commit any mistake. This does not seem concluding and I don't think it's the right approach to the solution. Any help?","['matrices', 'linear-algebra', 'determinant']"
2664789,Characterizing discontinuous derivatives,"Apparently the set of discontinuity of derivatives is weird in its own sense. Following are the examples that I know so far: $1.$  $$g(x)=\left\{ \begin{array}{ll}
x^2 \sin(\frac{1}{x})  &  x \in (0,1] \\
0 &  x=0  \end{array}\right.$$
$g'$ is discontinuous at $x=0$. $2. $  The Volterra function defined on the ternary Cantor set is differentiable everywhere but the derivative is discontinuous on the whole of Cantor set ,that is on a nowhere dense set of measure zero. $3.$  The Volterra function defined on the Fat-Cantor set is differentiable everywhere but the derivative is discontinuous on the whole of Fat-Cantor set ,that is on a set of positive measure, but not full measure. $4.$  I am yet to find a derivative which is discontinuous on a set of full measure. Some good discussion about this can be found here and here. Questions: 1.What are some  examples of functions whose derivative is discontinuous on a dense set of zero measure , say on the rationals? 2.What are some  examples of functions whose derivative is discontinuous on a dense set of positive measure , say on the irrationals? Update : One can find a function which is differentiable everywhere but whose derivative is discontinuous on a dense set of zero measure here.","['derivatives', 'real-analysis', 'cantor-set']"
2664825,Why is this not a matroid?,"If I recall correctly both of these definitions are equivalent: $(E,I)$ is an independence system and satisfies the augmentation property. $(E,I)$ is an independence system and all maximal independent sets in I have the same size. However I would say that the following system satisfies the second definition but not the first: $(\{1,2,3,4\},\{A|$ all numbers in A have equal parity$\})$ The maximal independent sets are $\{1,3\}$ and $\{2,4\}$, but at the same time if we take $A_1=\{1\}$ and $A_2=\{2,4\}$ we can't find any $a \in \{2,4\} \setminus \{1\}$ so that $(\{1\} \cup a) \in I$. What am I missing here?","['matroids', 'elementary-set-theory']"
2664854,Problem concerning the use of Pigeonhole (Box) principle,"Question: Take any $37$ integers from the set { ${1,2,…,112}$ }. Show that there will always exist two integers $x,y$ out of those $37$ integers such that $ \mid x-y \mid \in \{9,10,19\}$ . Approach: What have I done so far: Let $S=$ { ${1,2,…,112}$ } We partition the set into subsets $S_i$ of the form $\{x, x+9, x+19\}$ . Then the difference of any two elements is in $\{9, 10, 19 \}$ , which is easy to see. The following partitions are made (for $x=1, 2, \cdots , 9$ ): $$\{1, 10, 20 \}, \{2, 11, 21 \}, \cdots, \{9, 18, 28\}$$ Then next we choose $x=29$ to maintain the disjoint sets essential for our proof. This gives the disjoint sets $$ \{29, 38, 48\}, \cdots, \{37, 46, 56 \} $$ and similarly $$\{85, 94, 104 \}, \cdots, \{93, 102, 112 \}$$ However as the quick reader may see that the numbers $\{19, 47, 75, 103\}$ do not occur in any set. However, I decide to do a case by case analysis of the situations. Name this set as $X$ . Suppose, initially, that out of the $37$ integers in our selection, none belong to $X$ . Then it follows from Dirichlet's box principle that at least two elements are from the same set (i.e. from one of the subsets that we partitioned $S$ into) then the claim is valid. Now suppose that one element from $X$ is in our selection, say $19$ then if at least one of $9, 28, 29, 38$ is in our selection, then the claim is valid. Suppose none of these are present, and we are deficit in four integers. We  can now select any four integers from the remaining numbers and the box principle guarantees that at least two are from the same set. For, even if all $3$ other elements of $X$ are now present, there is one empty slot which can be filled using the other subsets from where we already have at least one element in our choice of $37$ numbers. I hope this is comprehensible because my combinatorics proof writing abilities are horrible. I am preparing for Olympiads and also for being a good Mathematician in general. Thank you for the help :) Edit: It seems I didn't enter my main question, apologies. Is my solution correct?","['pigeonhole-principle', 'combinatorics', 'contest-math']"
2664868,On differential polynomials,"Definition: A differential polynomial is a polynomial with indeterminates $y$, $y'$, $y''$, $\ldots$ with coefficients in $K[x]$, algebra of polynomials with coefficients in a field $K$. An example of a differential polynomial is
$$(1+x)y^2y'+(y'')^2(y''')^5-x^4 yy'y''y'''y^{(4)}-2x. $$
Such polynomials are studied in ""Differential Algebraic Geometry"" and solution of this polynomials are called ""Differential Varieties"". My question: Is it possible to express a differential polynomial as an infinite series with terms of linear differential equations? For example, is it possible to have an equality of the form
$$(y')^2=\sum_{n=1}^{\infty}a_n(x)y^{(n)}? $$
Of course, we need a norm to speak about convergence. Note that the Taylor series of $(y')^2 $ does not satisfies the condition.",['ordinary-differential-equations']
2664932,$f^2(x)$ vs $f(x)^2$ vs $f(x^2)$,How does the location of a power in a function adjust its result? For example if $f(x) = 2x$ I assume that $f(x^2)$ would equal $2x^2$. What I am unsure about is if $f^2(x)$ means $f(x)\times f(x)$ or $f(f(x))$. So would the final answer be $(2x)(2x)=4x^2$ or $2(2x)=4x$. And is $f(x)^2$ the same as $f^2(x)$?,"['algebra-precalculus', 'notation', 'functions']"
2664968,Probability puzzle about arrival time,"I recently came up with an interesting probability puzzle and wondered what would be the best way to solve it. It goes as follows: Suppose your friend is to arrive sometime on Monday, with a uniform
  distribution over the full 24 hour day. Whatever time they arrive
  dictates how long they will stay at your place. For example: If your friend arrives exactly at midnight (00:00) on Monday, they won't stay at all, and simply say ""hello"" while passing by. If they arrive at 1:30am (01:30) they will stay for an hour and a half, until 3:00am (03:00). If they arrive at 2:00pm (14:00) they will stay for 14 hours, until 4:00am the next day, Tuesday. If $t$ is a moment in time sometime between the beginning of Monday
  and the end of Tuesday, what is the probability your friend is at your
  house at time $t$? Stated a little more formally, if $a \in [0, 86400)$ is the arrival time (in seconds) of your friend, then the times they will be staying at your house will be given by $[a,2a)$. So the question becomes: Given $t\in[0, 172800)$, what is the probability that your friend is
  at your house at time $t$? Naturally I am interested in the method for arriving at a solution more so than the actual solution itself. I would also like to know how to approach the problem if the distribution on $[0,86400)$ was not uniform, but instead was given by some specific probability density function. Thanks, in advance.","['recreational-mathematics', 'probability', 'probability-distributions']"
2665013,How to find the number of elements which share all the characteristics when there are many sets?,"The problem is as follows: In a toddler's room there are 120 toys, 95 of them uses batteries, 86
  have wheels, 94 are red color, 110 are made of plastic, 100 emit
  sound. How many of the toys share all the characteristics? I'm stuck at this situation since I don't know how should I build up the sets in order they can be arranged in such a way that I can made an intersection of all thus finding the answer. Can somebody help me to be in the right direction?","['algebra-precalculus', 'combinatorics', 'recreational-mathematics', 'elementary-set-theory']"
2665048,"Counting the sets with elements satisfying $k_i\ge0$, $\sum_i k_i=K$, $\sum_i i k_i=N $.","Let $(k_0,k_1,k_2\dots) $ be an ordered set of non-negative integer numbers. Let $A (N,K)$ be the number of distinct $k $ -sets such that $$\sum_i k_i=K, \quad\sum_i i k_i=N.\tag{1} $$ Is there a special name for $A (N,K)$ and what is the most effective way to compute its value for given $K$ and $N$ ? Is there an effective way to construct all $k$ -sets satisfying (1). The following table shows $A(N,K)$ for $0\le N,K\le11$ : $$
\left(\begin{array}{rrrrrrrrrrrr}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
0 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\
0 & 1 & 2 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 3 \\
0 & 1 & 3 & 4 & 5 & 5 & 5 & 5 & 5 & 5 & 5 & 5 \\
0 & 1 & 3 & 5 & 6 & 7 & 7 & 7 & 7 & 7 & 7 & 7 \\
0 & 1 & 4 & 7 & 9 & 10 & 11 & 11 & 11 & 11 & 11 & 11 \\
0 & 1 & 4 & 8 & 11 & 13 & 14 & 15 & 15 & 15 & 15 & 15 \\
0 & 1 & 5 & 10 & 15 & 18 & 20 & 21 & 22 & 22 & 22 & 22 \\
0 & 1 & 5 & 12 & 18 & 23 & 26 & 28 & 29 & 30 & 30 & 30 \\
0 & 1 & 6 & 14 & 23 & 30 & 35 & 38 & 40 & 41 & 42 & 42 \\
0 & 1 & 6 & 16 & 27 & 37 & 44 & 49 & 52 & 54 & 55 & 56 \\
\end{array}\right)
$$ By numerical evidence the following recurrence relation applies: $$
A(N,K)=A(N,K-1)+A(N-K,K),\tag{2}
$$ with the convention $A(N,K)=0$ for $N<0$ .",['combinatorics']
2665062,Solve the following differential equations 2x2 with complex eigenvert,"Solve the following equation:
  $$X'=\pmatrix { 2 & 5
  \\ -5 & 8}X$$
  $$x(0)=(5,5)^t$$ I already got out the followings: $$\lambda_{1,2} = 5 \pm  4i$$
$$v_{1} = \begin{pmatrix} 3 \\ 5 \end{pmatrix} - i\cdot \begin{pmatrix} 4 \\ 0 \end{pmatrix}$$
$$v_{1} = \begin{pmatrix} 3 \\ 5 \end{pmatrix} + i\cdot \begin{pmatrix} 4 \\ 0 \end{pmatrix}$$ And so far I have this(Sry its messy):
$$\begin{align*}\vec{x}_{1}(t) = (3-4i)e^{5t} \begin{pmatrix}a\cos(4t)+b\sin(4t)\end{pmatrix}\end{align*}$$
$$\begin{align*}\vec{x}_{2}(t) = 5\cdot e^{5t} \begin{pmatrix}c\cos(4t)+d\sin(4t)\end{pmatrix}\end{align*}$$ I dont know if this is right so far... but I also tried to sum up x_1: My attend to solve x_1 This is the right answer in the end:$$\begin{align*}\vec{x}(t) = e^{5t} \begin{pmatrix}5\cos(4t)+\frac{5}{2}\sin(4t)\\ 5\cos(4t)-\frac{5}{2}\sin(4t)\end{pmatrix}\end{align*}$$ tyx","['differential', 'complex-numbers', 'matrices', 'trigonometry', 'ordinary-differential-equations']"
2665097,Real Analysis. Suggestions.,"Let $f,g: [a,b] \longrightarrow \mathbb{R}$ continuous in $[a,b]$ and differentiable in $(a,b)$ such that $f(a) = f(b) = 0$, then, theres exist $c \in (a,b)$ such that:
  $$g'(c)f(c) + f'(c) = 0.$$ I tried to use the Rolle's Theorem and Means Value Theorem, but I couldn't define an auxiliary function $\varphi$ to help me. I didn't want a solution of exercise, just a suggestion.","['derivatives', 'real-analysis']"
2665118,"How to derive ecliptic in simplified solar system, with vector math?","Assume the Earth orbits the sun in a fixed circle along the ecliptic (I'd be interested in answers that consider an elliptic orbit as well, but this is the simplest version). What's the simplest way to derive the vector normal to the ecliptic $\vec e$, given the following information? $\vec s$, the direction toward the sun in a local Cartesian coordinate frame ""somewhere"" on Earth, at a single point in time $\vec r$, the Earth's rotation axis pointing through the north pole, in the same coordinate frame Earth's tilt $\mathcal E = 23.44° = 0.4091 \ \mathrm{rad}$ $\vec s \cdot \vec r$ is most positive at the June solstice, most negative at the December solstice, and 0 at the equinoxes We do not have the following information: The longitude of our location on Earth The year, time of year, etc. The local direction of the sun at any time other than now (except rotated around the Earth's axis, which doesn't help) I can get this far: Local latitude = $elevation(\vec e) = asin(\vec e_y)$, where y is the local vertical component $\vec e = (\vec s \times \vec r) \times \vec s$ at the solstices We can in theory tell where we are in orbit by applying some function to $\vec s \cdot \vec r$, but I haven't derived this function, and there are two solutions at every point except the solstices. We can rotate $\vec r$ counter-clockwise around $\vec s$ by $\mathcal E$ at the March equinox to get $\vec e$, or clockwise at the September equinox, though I wouldn't know how to differentiate them without more information. Do we have enough information to solve the problem?  It seems like the answer is right in front of me, but the ambiguity of ""which equinox we're closer to"" gives me pause. Followup question: Furthermore, if we can derive $\vec e$, do we have enough information to define unique basis vectors for an ecliptic coordinate frame, such that the non-$\vec e$ vectors point from solstice-to-solstice and equinox-to-equinox?","['coordinate-systems', 'trigonometry', 'mathematical-astronomy', 'vectors']"
2665119,Voting score paradox,"These is a voting system, where a user can place one of the three types of votes: $NEG, NEUT, POS$ Let's call a voting configuration ( VC for short) total number of NEG, NEUT and POS votes left by the users. (E.g. $N_{neg} = 5, N_{neut} = 10, N_{pos} = 1.$) Let's call a score of the voting system a rational number defined as following: $$score = \frac{(-N_{neg} + N_{pos})}{(N_{neg} + N_{neut} + N_{pos})}$$ In the above example score will be: $$score = \frac{(-5 + 1)}{(5 + 10 + 1)}=-\frac{1}{4}$$ Let's call a random voting configuration the one, where number of votes $N_{neg}, N_{neut}, N_{pos}$ is taken from the uniform distribution on $[0, +\infty)$. The overall decision for the VC is defined as follows: $$decision(score) = \begin{cases} NEG, & \mbox{if } score \in [-1, -T] \\ NEUT, & \mbox{if } score \in (-T, T) \\ POS , & \mbox{if } score \in [T, 1] \end{cases}$$ Q: How to choose T so that a randomly picked VC falls into each of the three types with equal probability? P.S. From the practical point of view the task is to choose such a threshold that classes for $NEG, NEUT, POS$ are balanced in terms of how many VCs do fall into them. My interest to this task came up because the first obvious choice of $T=1/3$ leads to the heavily overloaded $NEUT$ class, when analyzing all VCs with number of votes between 10 and 25 (both inclusive): $|VC_{neg}| = 746$ $|VC_{neut}| = 1564$ $|VC_{pos}| = 746$",['probability']
2665125,Laplace transform of the derivative of the dirac delta function times another function,"I'm trying to solve a DE involving terms of the form $\dot{\delta}(t-k)f(t)$ and $\ddot{\delta}(t-k)f(t)$, where $k>0$. I would therefore like to find the Laplace transform of these terms. My approach so far has been to simply integrate by parts, ie in the case of $\dot{\delta}(t-k)f(t)$ I get $\mathcal{L}\left\{ \dot{\delta}\left(t-k\right)f\left(t\right)\right\} =\int_{0}^{\infty}\dot{\delta}\left(t-k\right)f\left(t\right)\exp\left(-ts\right)dt$ $=\left[\delta\left(t-k\right)f\left(t\right)\exp\left(-ts\right)\right]_{0}^{\infty}-\int_{0}^{\infty}\delta\left(t-k\right)\left[\dot{f}\left(t\right)\exp\left(-ts\right)-sf\left(t\right)\exp\left(-ts\right)\right]dt$ Since $\delta\left(t\right)=0$ for all $t\neq k$ and since $k>0$, it must hold that $\left[\delta\left(t-k\right)f\left(t\right)\exp\left(-ts\right)\right]_{0}^{\infty}=0$, so by the sifting property of $\delta(t)$ I get $\mathcal{L}\left\{ \dot{\delta}\left(t-k\right)f\left(t\right)\right\} = \left(sf\left(k\right)-\dot{f}\left(k\right)\right)\exp\left(-ks\right)$ Using the same approach, I get $\mathcal{L}\left\{ \ddot{\delta}\left(t-k\right)f\left(t\right)\right\} =\left(\ddot{f}\left(k\right)-2s\dot{f}\left(k\right)+s^{2}f\left(k\right)\right)\exp\left(-ks\right)$ My question has two parts: 1) Is this the correct approach? 2) What happens if $k=0$?","['derivatives', 'dirac-delta', 'laplace-transform']"
2665142,A bijection between Motzkin paths and 3-colored signed Dyck path homomorphs,"The generating function $m=m(z)$ for the Motzkin numbers satisfies the functional equation
$$
m=1+zm+z^2m^2
$$
(a Motzkin path $P$ with unit steps $u,d,l$ (up, down, level) is either empty or $lP'$ or $uP'dP''$). A simple manipulation yields
$$
m(1-3z)=m-3zm=1-2zm+z^2m^2=(1-zm)^2,
$$
so that
$$
\frac{zm}{(1-zm)^2}=\frac{z}{1-3z},
$$
i.e.
$$
\frac{z}{(1-z)^2}\circ(zm)=\frac{z}{1-3z},
$$
where $\circ$ denotes the composition of functions. Inverting the left factor on the left, we obtain
$$
zm=\left(zC(-z)^2\right)\circ\frac{z}{1-3z}=\frac{z}{1-3z}C\left(-\frac{z}{1-3z}\right)^2,
$$
where $C=C(z)$ is the generating function for the Catalan numbers. My question is: Is there a known bijective proof of this last equation? That would possibly involve some inclusion-exclusion argument or an involution on $3$-colored signed Dyck path homomorphs (i.e. Dyck paths where each edge is replaced with a path each of whose non-initial steps is assigned one of $3$ colors, while the initial step has weight $-1$). Of course, this is just one choice, the combinatorial classes involved may be different.","['combinatorics', 'catalan-numbers']"
2665188,Eigenvalue and Eigenvector of $\small\pmatrix{0 & 0 \\ 0 & -7}$,"I need help working out the eigenvectors for this matrix. $ \begin {pmatrix} 0 &  0 \\   0 & -7 \end{pmatrix} $ The original matrix is $ \begin {pmatrix} 5 &  0 \\   0 & -2 \end{pmatrix} $ , eigenvalues are 5,-2, but I am not sure how to about the eigenvectors, as for 5 $ \begin {pmatrix} 0 &  0 \\   0 & -7 \end{pmatrix} $ $ \begin{pmatrix} x \\ y \end{pmatrix}$ = $ \begin{pmatrix} 0 \\ 0 \end{pmatrix}$ from the first equation, $x$ and $y$ are both zero, but from the second equation $y = 0$, so what is the eigenvector?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2665227,Motivation behind the definition of ramification in Hartshorne,"Let $f: X \to Y$ be a finite morphism of curves. Hartshorne gives the following definition of what it meas for the morphism $f$ to be ramified at $P$. Let $Q=f(P)$ and $t \in \mathcal{O}_Q$ be the local parameter at $Q$, i.e since $\mathcal{O}_Q$ is a DVR,  $\mathcal{O}_Q$ is a DVR $\frak{m} = (t) \in \mathcal{O}_Q$. We can then view $t$ as an element of $\mathcal{O}_P$ via the natural map $f^{\#}: \mathcal{O}_Q \to \mathcal{O}_P$. The ramification index is then defines to be $$e_p=v_P(t)$$
where $v_p$ is the valuation associated to the DVR $\mathcal{O}_P$. We say that $f$ is ramified at $P$ if $v_p(t) > 1$. Ok. From a figure below, I would guess that, without using any fancy/rigorours language, a ramified point is one at which the number of elements in a fiber abruptly changes. Is my interpretation correct and how would I relate Hartshorne's definition connected to this?",['algebraic-geometry']
2665233,For which values of p would this integral converge?,"I have: $$\int_{0}^{1} \frac1{x^p}dx$$ My question is what values of $p$ would this converge. I know that $$\int_{1}^{\infty} \frac1{x^p}dx$$ 
converges when $p>1$, but I am unsure how that would relate to the question I have.","['real-analysis', 'calculus']"
2665325,Number of roots of a particular polynomial in $F_{121}$,"Question: Determine the number of roots of $f(x)=x^{12}+x^8+x^4+1$ in $\mathbb{F}_{121}$. I was told that a solution to this problem could, or perhaps should, use the fact that $\mathbb{F}_{121}^\times$ is cyclic, but I don't currently see how this helps. My attempt at a solution is written below, but I don't think it's the right approach. How does the fact that $\mathbb{F}_{121}^\times$ is cyclic play a part? My thoughts: First, notice that if $g(x)=x^3+x^2+x+1=(x^2+1)(x+1)$ then $g(x^4)=f(x),$ so $\beta\in  \mathbb{F}_{121}$ is a root of $f$ if and only if $\beta^4=\alpha$ for some $\alpha\in  \mathbb{F}_{121}$ that is a root of $g$. In particular, if $\alpha$ is a root of $g$ and $\alpha\in (\mathbb{F}_{121})^{\times 4}$ then $\alpha$ will correspond to a root of $f$ (the 'fourth root' of $\alpha$ in $\mathbb{F}_{121}$). Since $y^2+1\in\mathbb{F}_{11}[y]$ is irreducible, we know that 
$$
\mathbb{F}_{121}\cong \frac{\mathbb{F}_{11}[y]}{(y^2+1)}\cong \mathbb{F}_{11}(i)
$$
where $i^2=-1$. With this notation, we find that $g(x)=(x+1)(x+i)(x-i)\in \mathbb{F}_{11}(i)$. So we need to check whether $-1,\pm i$ are in $(\mathbb{F}_{121}^\times)^4$. At this point, I am not so sure how to proceed beyond checking for solutions to $(a+bi)^4=c$ for $a,b\in \mathbb{F}_{11}$ and $c\in \{-1,\pm i\}$, but I think there must be a better way... As a side note, I did a computation in PARI/GP and found that $x^{12}+x^8+x^4+1$ has $4$ roots, so we know how many there should be, but I'm at a loss as to how this can be computed nicely by hand.","['finite-fields', 'abstract-algebra', 'factoring', 'number-theory', 'field-theory']"
2665379,Prove that $f(z) = |z|$ is not analytic. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I do not fully grasp what it means to be analytic and therefore do not know the conditions on which I have to show in order to complete the proof.","['complex-analysis', 'analytic-functions']"
2665426,Is this result correct? Limits don't depend on norm.,"Let $\|\cdot\|: \mathbb R \to \mathbb R$ be some norm on $\mathbb R$ which is not the standard absolute value $|\cdot|$ we all know and love. $f: \mathbb R \to \mathbb R, L \in \mathbb R.$ Suppose that $\lim_{t \to 0} f(t) = L$ with respect to $\| \cdot \|$ This means that $\forall \epsilon > 0 \exists \delta >0: \|t\| \leq \delta \implies\|f(t)-L\| \leq \epsilon$ I would like to show that this is also true with respect to $|\cdot |$. The limit does not depend on with respect to which norm does $t$ approach zero. What I did: Fix $\epsilon >0 $ and choose a $\delta$ such that $\|t\| \leq \delta \implies\|f(t)-f(0)\| \leq \epsilon$. All norms are equivalent, so there is $c >0$ such that $c|t| \leq \|t\| \leq \delta$ and $c|f(t)-L| \leq \|f(t)-L\| \leq \epsilon$ So $|t| \leq \frac{\delta}{c} = \delta'$ and $|f(t)-L| \leq \frac{\epsilon}{c} = \epsilon'$ Finally, $|t| \leq \delta ' \implies\frac{\|t\|}{c} \leq\frac{\delta}{c} \implies \|t\| \leq \delta$ That implies by our initial assumption that $\|f(t)-L\| \leq \epsilon$, but then $|f(t)-L| \leq \frac{\epsilon}{c} = \epsilon'$. Since our $\epsilon$ is as small as we would like, so is $\epsilon'$, and that concludes the proof. Is this proof correct? Question number 2 The differential of a function activated on unit vector $h$ is defined to be $D_f(a)h = \lim_{t \to 0} \frac{f(a+th)-f(a)}{t}$. Suppose my proof is correct and it does not matter with respect to which norm does $t$ approach zero here. Does it matter with respect to which norm is $h$ a unit vector? In other words- Does the differential of a function at all depend on the choice of the norms and inner products we work with? If so - why? if not - why not?","['proof-verification', 'calculus', 'limits']"
2665439,Showing $\prod\limits_{p \leq x} p> e^{(1+\epsilon )x}$ and $\prod\limits_{p \leq x} p < e^{(1-\epsilon) x}$ are false for $x$ large enough.,"For every $\epsilon >0$, show that each of the inequalities
  $$\prod\limits_{p \leq x} p> e^{(1+\epsilon )x} \text{ and }
\prod\limits_{p \leq x} p < e^{(1-\epsilon) x}$$
  is false for all sufficiently large $x$. ($p$ is prime and $x \in \mathbb{R}$). This is in Leveque's Fundamentals of Number Theory. Is there a way to show this result using $\pi (x) = \frac{x}{\log x} + O\left(\frac{x}{ \log^2 x}\right)$? If not, how can we proceed/conclude otherwise?","['number-theory', 'analytic-number-theory']"
2665459,What is the radius of convergence of the hypergeometric series?,"Find the radius of convergence of 
  $$F(\alpha,\beta,\gamma,z)=1+\sum_\limits{n=1}^\infty\frac{\alpha(\alpha+1)\cdots(\alpha+n-1)\beta(\beta+1)\cdots(\beta+n-1)}{n!\gamma(\gamma+1)\cdots(\gamma+n-1)}z^n$$
  Here $\alpha,\beta\in\mathbb{C}$ and $\gamma \neq 0,-1,-2,\cdots$. I set 
$$c_n=\frac{\alpha(\alpha+1)\cdots(\alpha+n-1)\beta(\beta+1)\cdots(\beta+n-1)}{\gamma(\gamma+1)\cdots(\gamma+n-1)},\qquad a_n=\frac{c_n}{n!}$$
and 
$$\color{red}{c_n\sim\left(\frac{\alpha\,\beta}{\gamma}\right)^n}, \qquad n\to\infty$$
Thus, the radius of convergence $R$ can be found using Cauchy-Hadamard's formula $$R=\frac{1}{\lim\sup|a_n|^{1/n}}=\left|\frac{\gamma}{\alpha\,\beta}\right|\cdot\lim_\limits{n\to\infty}\sqrt[n]{|n!|}=\left|\frac{\gamma}{\alpha\,\beta}\right|\cdot\infty=\infty.$$ This would conclude that $F(\alpha,\beta,\gamma,z)$ is an entire function, but I do not know if these steps are correct. I realized that the part in red is not true. What would be a better approximation?","['complex-analysis', 'power-series']"
2665500,$|\log (1 + z)| \leq 2 |z|$ Complex inequality,"Prove that for $|z|\leq0.5$, $|\log (1 + z)| \leq 2 |z|$. I know that $|\log (1 + z)|=|\log|1+z|+i\arg(1+z)|$ and $|\arg(1+z)|\leq\pi/6$ for $|z|\leq0.5$, but then I don't know how to proceed. It seems that the it attains ""="" when $z=0$? Thanks!",['complex-analysis']
2665540,Lemma 3 of the Milnor's Topology from the differentiable viewpoint.,"Lemma 3 in Milnor's ""Topology from the differentiable Viewpoint"" (p.12) is stated as below; Let $M$ be a manifold without boundary and let $g:M \to \mathbb{R}$ have 0 as regular value. The set of $x$ in $M$ with $g(x)\geq 0$ is a smooth manifold, with boundary equal to $g^{-1}(0)$. To discuss efficiently, let $M' = \{x \in M: g(x) \geq 0 \}$, and $\dim M = m$. In the book, the proof is omitted. I understand that the Lemma 1 of the book implies that $g^{-1}(0)$ is $(m-1)$-manifold. However, I cannot find a map $f: M' \to \mathbb{H}^{m}$, which gives open set of $M'$ has the diffeomorphism onto open set of $\mathbb{H}^{m}$. Could you help me to understand this lemma? P.S. I also think that $g|_{M'}:M' \to \mathbb{H}$ already gives a $1$-manifold with boundary on the set $M'$, by the definition of Milnor's book. However, if we regard this as a proof of the Lemma 3, then the dimension of $m$ is not meaningful; for example, if we think $D^{m}$, a unit disk, and a map $g:D^{m} \to \mathbb{R}$ by $1- \sum x_{i}^{2}$, then the lemma gives $M'$ a smooth manifold with boundary structure having dimension $m$. To derive such dimension, I think the lemma should be proved by finding a map from $M'$ to $\mathbb{H}^{m}$.","['manifolds-with-boundary', 'general-topology', 'differential-topology']"
2665569,How was the integral formula for the binomial coefficient discovered?,"I found out about integral formulas when reading a book about them and combinatorics. In that book, and Continuous Identities , but they don't explain how they were discovered. I think that is is important. An integral formula for the binomial coefficient, according to Wikipedia, is: $\frac{2^{n-1}}{
\pi} \int_{-\pi}^\pi \cos{((2m-n)x})\cos{(x)}^n dx = \binom{n}{m}$ I understand the proof in the book, but have no clue how the identity was thought up in the first place.","['combinatorics', 'math-history', 'binomial-coefficients', 'sequences-and-series']"
2665570,Why would $L \ + \frac{f_{m}-f_{m-1}}{(f_{m}-f_{m-1}) + f_{m}-f_{m+1}} \cdot w$ correspond to the mode of grouped frequencies? [duplicate],"This question already has answers here : Derivation of Mode of grouped data (2 answers) Closed 3 years ago . $\text{Mode} = L \ + \frac{f_{m}-f_{m-1}}{(f_{m}-f_{m-1}) + f_{m}-f_{m+1}} \cdot w$ where, • L is the lower class boundary of the modal group. • fm-1 is the frequency of the group before the modal group. • fm is the frequency of the modal group. • fm+1 is the frequency of the group after the modal group. • w is the group width. Mode is the most frequently occurring value in a data set - I don't understand why this formula would give the mode of grouped frequencies. Why would the mode even be in the modal group? It could be inside any other group, right!?",['statistics']
2665583,Maximum likelihood for the Brownian Motion with drift,"Given the Brownian Motion with drift $$
dX(t) = \mu dt + \sigma dW(t)
$$ It is well known that its distribution has the following form $$
f_t(x) =  \frac{1}{\sqrt(2 \pi \sigma^2 t)} e^{-\frac{(x -\mu t)^2}{2 \sigma^2 t}} 
$$ So following examples online for the Normal distribution, I get the following formulas for the parameters of the BM distribution $$
\mu = \frac{1}{n} \sum_{i=1}^{n} \frac{x_i}{t_i}  \\
\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i-\mu t_i)^2
$$ Does this look correct? Please let me know if I need to show my work. Thanks Edit 2 - Let's start this over Step 1 - Define the Likelihood function: $$
\mathcal{L}(\mu, \sigma;x)=\prod_{i=1}^{n} Pr(x_i|\mu, \sigma)= \left(2 \pi t_1\right)^{-\frac{1}{2}} \times \left(2 \pi t_2\right)^{-\frac{1}{2}} \times ... \times \left(2 \pi t_n\right)^{-\frac{1}{2}} \left(\sigma^2 \right)^{-\left(\frac{n}{2}\right)}e^{-\frac{1}{2 \sigma^2} \sum_{i=1}^{n}  \frac{(x_i -\mu t_i)^2}{t_i}}
$$ Step 2 - Take the log of the likelihood function $$
\mathcal{l}(\mu, \sigma;x) = -\frac{1}{2}\ln(2 \pi t_1) -\frac{1}{2}\ln(2 \pi t_2) - ... -\frac{1}{2}\ln(2 \pi t_n) -\frac{n}{2} \ln(\sigma^2) -\frac{1}{2 \sigma^2} \sum_{i=1}^{n} \frac{(x_i - \mu t_i)}{t_i} 
$$ So, before we take derivatives - I am not sure how to go from this $$
-\frac{1}{2}\ln(2 \pi t_1) -\frac{1}{2}\ln(2 \pi t_2) - ... -\frac{1}{2}\ln(2 \pi t_n)
$$ to this for the first term $$
- \frac{1}{2} \sum_{i=1}^{n} \ln(2 \pi (t_i - t_{i-1}))
$$ Are we making any assumptions? The algebra does not work out for me.","['stochastic-processes', 'probability-theory', 'probability-distributions', 'maximum-likelihood', 'brownian-motion']"
2665606,Completing the Cayley table given certain information,"Question. Let $G = \{1,2,3,4\}$. Given that $(G, \cdot)$ is a group with identity $3$ and that $o(x) = 2$ for each $x \in G \setminus \{3\}$, complete the Cayley table. I'm trying to break apart each statement in hopes to understand how I should fill in this specific Cayley table. ""$(G, \cdot)$ is a group with identity $3$."" this is pretty basic and I understand it. A group is associative, has identity ($3$) and inverses. ""$o(x) = 2$ for each $x \in G \setminus \{3\}$."" This is saying that each element except ${3}$ has an order of $2$, and this is what is causing confusion. Is this saying that $x^2 = e$ (the identity), except for ${3}$? So $1\cdot1 = 3$, $2\cdot2 = 3$, $4\cdot4 = 3$? I'm guessing $3\cdot3 = 1$ (because $e\cdot e = e$)? My second attempt thanks to everyone's help: Thank you.","['finite-groups', 'abstract-algebra', 'group-theory', 'cayley-table']"
2665625,How does this follows from the maximum principle?,"Suppose $u$ is a holomorphic function in the unit disk and $\lvert u(z)\rvert\leq 1$. It follows from Cauchy's inequality that
$$
\left\lvert u(z) - \sum_0^{2N-1}\frac{u^{(k)}(0)z^k}{k!}\right\rvert \leq (2N+1)
$$ The author claims that from the maximal principle we obtain
  $$
\left\lvert u(z) - \sum_0^{2N-1}\frac{u^{(k)}(0)z^k}{k!}\right\rvert \leq (2N+1)\lvert z\rvert^{2N}
$$
  How? I don't see how it follows. If anyone can show me how to obtain this from the maximum modulus principle I would appreciate it.","['complex-analysis', 'maximum-principle']"
2665636,Is this an elliptic integral or not?,"I am working with the following differential equation:
$$4\left(\frac{dz}{dx}\right)^2+z^4=4$$
On rearrangement, this yields
$$\frac{dz}{dx}=\frac{\sqrt{4-z^4}}{{2}}$$
Using $z=\sqrt{2}\tan \theta$, we further get
$$\frac{d\theta}{\sqrt{1-2\sin^2\theta}}=\frac{dx}{\sqrt{2}}$$ Now, as per this , this , this and other links, the term on the left is an elliptic integral. But Mathworld says that, for an elliptic integral of the form $\frac{d\theta}{\sqrt{1-k^2\sin^2\theta}}$, the bound on $k$ is given by $$0<k^2<1$$ But for my integral, $k^2=2>1$, which is also causing me difficulty in numerically trying to integrate the problem. Can somebody tell me what is correct and what not and how I should proceed to integrate the LHS of the equation, numerically (or if possible analytically)?","['calculus', 'computational-mathematics', 'elliptic-integrals', 'numerical-methods', 'ordinary-differential-equations']"
2665638,Prove that the function $f :\mathbb{Z}\to\mathbb{Z}$ given by $f(x) = 15x − 11$ does not map onto its codomain.,Prove that the function $f : \mathbb{Z} \to \mathbb{Z}$ given by $f(x) = 15x − 11$ does not map onto its codomain. I am quite confused with this as I'm stuck with how to probably disapprove this statement. I need help with the steps of how I can know when something maps onto its codomain and when it doesn't and why it doesn't.,"['elementary-set-theory', 'functions']"
2665644,Does $a_n = n\sin n$ have a convergent subsequence?,"I know that $\sin n$ has a convergent subsequence since it is bounded, but does the unbounded sequence $n\sin n$ have a convergent subsequence? Given a subsequence of $\sin n$ that tends to zero, it is still possible that when we multiply the convergent subsequence $\sin(n_k)$ by $n_k$, the limit may not be $0$.","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
2665655,Computing the sum $\frac{1}{(\frac{1}{n}-p)^{2}}+\frac{1}{(\frac{2}{n}-p)^{2}}+\ldots+\frac{1}{(1-p)^{2}}$,"Let $p\in(0,1)$ and $n$ be a finite positive integer. How to compute the following sum
\begin{equation}
\frac{1}{(\frac{1}{n}-p)^{2}}+\frac{1}{(\frac{2}{n}-p)^{2}}+\ldots+\frac{1}{(\frac{n-1}{n}-p)^{2}}+\frac{1}{(1-p)^{2}}?
\end{equation} I tried substitution and expanding the denominator terms, but it doesn't seem to work. Any hints? Edit $1$: So here is why I want to compute this sum. Let $Z\sim\text{Bin}(n,p)$. I want to compute $\mathbb{E}|\frac{Z}{n}-p|$. Since $U:=|\frac{Z}{n}-p|$ is a non negative random variable taking values in $A:=\{p,|\frac{1}{n}-p|,\ldots,1-p\}$, I have
\begin{align}
\mathbb{E}|\frac{Z}{n}-p|&=\sum_{t\in A}\mathbb{P}(U>t)\\
&\le \text{var}(U)\sum_{t\in A}\frac{1}{t^{2}}\quad (\text{Chebyshev's inequality})
\end{align}
This summation is what appears above. Another way could be to use an exponential bound in the second step. Edit $2$ So a simple upper bound is the following:
\begin{align}
\mathbb{E}|\frac{Z}{n}-p|&\le \frac{1}{n}\sqrt{\mathbb{E}(Z-np)^{2}}\\
&=\frac{\sqrt{p(1-p)}}{\sqrt{n}},
\end{align}
which would be okay for my calculation. Any techniques to compute the sum in question are still welcome.","['expectation', 'algebra-precalculus', 'probability', 'summation', 'sequences-and-series']"
2665698,When can the collapsed Gibbs sampling be applied?,"I understand Gibbs sampling is a means of statistics inference, and it seems that sometimes certain variables can be integrated out in the sampling process, known as collapsed Gibbs sampling. I really want to know in what circumstances the collapsed Gibbs sampling can be applied, and which variables can be integrated out? I did some search on Google, and it appears there are no detailed explanation on it. Though there are some papers on applying collapsed Gibbs sampling on Latent Dirichlet Allocation (LDA), I am no expert of MCMC and have no idea what LDA is, so it may be hard for me to read those papers. Can someone answer this question and it would be better, provide some examples? Much appreciated!","['statistical-inference', 'sampling', 'bayesian', 'statistics', 'monte-carlo']"
2665700,Property of nonnegative integrable function on a finite measure space,"Let $f$ be a nonnegative, measurable and integrable function on measure space $(\mathbb{R},X,\mu)$ with Lebesgue measure $\mu$. Then, is the following true: $$\forall \epsilon>0\exists E(\mu(E)<+\infty):\int_X f d\mu\le\int_E f d\mu+\epsilon$$ I think yes, but am unable to prove it. I think it is related to uniform integrability of $f$ or the simple approximation of integrable functions. Any hints. Thanks beforehand.","['real-analysis', 'measure-theory']"
2665735,How to investigate the uniform convergence of the series,"Given this series: 
  $$\sum_{n=1}^\infty \frac{1}{n(1+x^2)^n}, $$
  for which values of $x$ is it uniformly convergent? Determining the points for which it is point-wise convergent is very easy, by just using the root test, I came up with a result that the series is point-wise convergent for all $x\in\mathbb{R}\setminus\{0\}$. However, I have no idea on how to get the values of $x$ for which this series is uniformly convergent. Am I supposed to use the definition for uniform convergence or the Weierstrass M test?","['sequences-and-series', 'uniform-convergence']"
2665752,"What does ""approach zero"" really mean?","We repeat the phrase ""approach zero"" regularly, but what exactly does it mean to say ""$\delta t$ approaches zero""? P.S. If this a stupid question, then please forgive me.","['calculus', 'definition']"
2665782,Can we always establish whether an infinite series converges or diverges?,"I'm currently working with infinite series for my calculus class, and I'm wondering whether we always (in theory) can establish whether a series is divergent or convergent? Of course, it might be computationally hard, but is there a class of series where we simply lack the tools to determine whether the series converges or diverges?","['convergence-divergence', 'sequences-and-series', 'calculus']"
2665801,Difficulties in stating mean value theorem for functions which are not continuous on a closed interval.,"The mean value theorem is stated as follows Let there be a function $f$ which is continuous on $[a,b]$ and differentiable on $(a,b)$. Then there exists $c$ belonging to $(a,b)$ such that $f′(c)=\frac{f(b)−f(a)}{b−a}$. Now, here it is assumed that the function is continuous on a closed interval. What I don't understand is the use of making the function continuous on a closed interval. I understand that then $f(a)$ and $f(b)$ will not be defined if we use rather an open interval (a,b), but then we can take into account the limits as x approaches a and b of the function (sometimes one-sided limits) instead of the values of the function at $a$ and $b$. I know this would be tedious and would make the theorem complicated, but what I want to ask is that whether there is any other reason for proposing a closed continuous function rather than an open or half-open one.","['real-analysis', 'calculus']"
2665804,"Are the sets $\{(x, y): x^2 + y^2 < 1\}$ and $\{(x, y): 0 < x^2 + y^2 < 1\}$ homeomorphic?","Are the sets $A = \{(x, y): x^2 + y^2 < 1\}$ and $B = \{(x, y): 0 <
 x^2 + y^2 < 1\}$ homeomorphic? My guess is that they are not, but I do not know how to prove this. I have studied some topology only in the context of metric spaces, and I know that connectedness and compactness are topological properties, but I don't know if that applies here.","['general-topology', 'real-analysis', 'metric-spaces']"
2665808,Discontinuity set of derivative,"Let $f$ be a differentiable function and let $J$ and $D$ denote the set of continuity and discontinuity  of $f'$. Then $J$ and $D$ can be characterized as done here. Also $J$ is a $G_{\delta}$ dense set and hence has positive measure (?) Now Volterra function can be used to construct a derivative which is discontinuous on a nowhere dense set with both zero and positive measure by choosing appropriate Cantor sets. Hence $D$ can be a nowhere dense set with positive measure. This is where I am struck. Now if $D$ has full measure, then $J$ has zero measure which is a contradiction that $J$ is a $G_{\delta} $ dense set?.","['derivatives', 'real-analysis', 'measure-theory']"
2665825,"Justify, without evaluating, that the determinant of the following matrix is zero","I am currently stuck at this question and have no idea how to solve.
I just started out learning linear and I'm really weak in this field. Justify, without evaluating, that the determinant of the following matrix is zero Here's the matrix A: $$\begin{pmatrix}
     1 &  0  &  2 &  4\\
    -2 & 3 &   8 &  6\\
    -1 &  3 &  10 & 10\\
     6 &  6 &  -3 &  7\\
\end{pmatrix}$$ I searched online but couldn't find something similar.
What I found though was that if it was skew-symmetric ($A^t= -A$)
then the determinant could directly be said to be equal to zero.
But in this case it didn't work with me. Thank you.","['matrices', 'inverse', 'linear-algebra', 'determinant']"
2665826,Are Wikipedia and Wolfram Mathworld wrong about the CDF of the beta binomial?,"Wikipedia and Mathworld claim that the CDF of the beta-binomial distribution is:
$$1- \tfrac{\mathrm{B}(\beta+n-k-1,\alpha+k+1)_3F_2(\boldsymbol{a},\boldsymbol{b};k)} {\mathrm{B}(\alpha,\beta)\mathrm{B}(n-k,k+2) (n+1)}$$ where $_3F_2(\boldsymbol{a},\boldsymbol{b};k)$ is the generalized hypergeometric function $$_3F_2(1,\! \alpha\! +\! k\!+ \! 1,k\! -\! n\! +\! 1;k\! +\! 2,k\! +\! 2\! -\! \beta\! -\! n;1)\!$$ This is dubious because $_3F_2(\cdot,\cdot,\cdot;\cdot,\cdot;1)$ is a singularity . Using Sympy, I evaluated that generalized hypergeometric function with the last argument changed to different values near $1$, and here's what I got: In [5]: import mpmath as mp

In [7]: n = 1

In [8]: k = 1

In [9]: alpha = 1

In [10]: beta = 1

In [16]: spec = lambda alpha, beta, n, k: mp.hyp3f2(1, alpha + k + 1, k - n + 1, k + 2, k + 2 - beta 
    ...: - n, '1.0001')

In [17]: spec(alpha, beta, n, k)
Out[17]: mpf('-10000.0000000011')

In [18]: spec = lambda alpha, beta, n, k: mp.hyp3f2(1, alpha + k + 1, k - n + 1, k + 2, k + 2 - beta 
    ...: - n, '0.99999999')

In [19]: spec(alpha, beta, n, k)
Out[19]: mpf('99999999.497524068') So it even changes sign. What is the CDF of the beta binomial?","['statistics', 'probability', 'hypergeometric-function']"
2665832,Extension of a conformal mapping to an elliptic function,"Let $\rho$ be the conformal mapping from the interior of the triangle with vertices $-1,i\sqrt{3},1$ onto the upper half-plane. Show that $\rho$ has an elliptic extension. The hypothesis makes sense by invoking the Riemann Mapping Theorem. Furthermore, $\rho$ has an extension to a homeomorphism on the boundary of the triangle to the real line due to Caratheodory extension. In fact, this extension of $\rho$, denoted as $P$, takes the real value on the boundary of the triangle except that one of the vertices is mapped to the point of infinity under compactification. Thereby, $P$ has an analytic continuation across the boundary of the triangle and to a meromorphic function on $\mathbb{C}$ and the vertices are invariant under $P$ by rotations of $\pm \frac{2\pi}{3}$. At this point, I do not know how to continue. Any help is sincerely valued.","['complex-analysis', 'analytic-continuation', 'conformal-geometry', 'elliptic-functions']"
2665843,"prove that exist $c$ at $[a,b]$ ,so that for every $\varepsilon>0$ there is $x$ that $0<|x-c|<\varepsilon$ and $f(x)=0$","Let $f(x)$ Differentiable at $[a,b]$ and have infinity numbers of zero at $[a,b]$ . prove that exist $c$ at $[a,b]$ ,so that for every $\varepsilon>0$ there is $x$ that $0<|x-c|<\varepsilon$ and $f(x)=0$ $f^{(i)}(c)=0$ for every $0\le i$ my answer for the first one : Let $x_n$ sequence with different elements at $[a,b]$ that $f(x_n)=0$ . then i tried to use Bolzano–Weierstrass theorem . so we get that for $x_n$ there is convergent subsequence $a_k\le x_{n_k} \le b_k$ , that  convergent to $c$ when $k\to \infty$ . is that enough to prove that first one ? if not how to continue? for the second : i tried to use Rolle's theorem $f$ Derivative at $[a,b]$ and $f(a)=f(b)=0$ then there is $c$ such that $f'(c)=0$ but how to prove it when $f^{(i)}(c)=0$ ? thanks a lot .","['derivatives', 'real-analysis']"
2665854,"If $M$ maps all probability vectors on a subspace to some probability vectors, is $M$ the restriction of a column stochastic matrix?","For $n \ge 1$, let 
$$\Delta^{n-1} := \left\{ (x_1,\dots,x_{n}) \in \mathbb{R}^{n} \mid \sum_{i=1}^{n} x_i=1,~x_i \ge 0 \right\}$$ 
and let $\mathcal{S},~\mathcal{S}'\subset\mathbb{R}^n$ be subspaces such that $\mathcal{S} \cap \Delta^{n-1} \ne \emptyset$ and $\mathcal{S}' \cap \Delta^{n-1} \ne \emptyset$. Consider a linear map $M:\mathcal{S}\to\mathcal{S}'$ such that $M(\mathcal{S} \cap \Delta^{n-1}) \subseteq \mathcal{S}' \cap \Delta^{n-1}$. The problem is to prove whether or not there exists a linear map $T_Q:\mathbb{R}^n\to\mathbb{R}^n$  given by some column stochastic matrix ($Q_{ij}\geq0$, $\sum_iQ_{ij}=1$, in the standard basis), such that $Q v=M(v)$ for every $v\in \mathcal{S} \cap \Delta^{n-1}$. Has this extension problem been already studied?","['stochastic-processes', 'matrices', 'markov-chains', 'markov-process', 'linear-algebra']"
2665859,conditional expected value given the random variable is less than another random variable,"Assume two independent random variables $X$ and $Y$ with p.d.f. $f(x)$ and $g(y)$. For simplicity, both $X$ and $Y$ are positive. How to find $E[X|X<Y]$? We know  $P(X<Y)=\int_0^\infty\int_0^yf(x)dxg(y)dy$. Is it true that $E[X|X<Y]=\int_0^\infty\int_0^yxf(x)dxg(y)dy$?",['probability']
2665862,Sum of cube roots of complex conjugates,"When solving the following cubic equation: $$x^3 - 15x - 4 = 0$$ I got one of the solutions: $$x = \sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}$$ When I calculated it with a hand calculator, it turned out to be exactly $4$. And indeed, when I substitute $x=4$ into the original equation, it is a solution. So this appears to be true: $$\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i} = 4$$ So we have a sum of cube roots of complex numbers which nevertheless happens to produce a real result. So I presume that these two cube roots must be complex conjugates of each other, which seems to be the case, judging by the fact that the numbers under the cube roots are complex conjugates of each other as well (note the signs I marked with red). Complex conjugates are ""mirror images"" of each other, so when added up, they produce a real result. Cube roots of complex conjugates divide their angles by 3, so the results should remain complex conjugates, and I suppose this is the reason why they add up to a real number as well. Am I right? What bothers me, though, is how can we PROVE that identity with algebra? Here's what I tried: I cubed the equation: $$x \;=\; \sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i} \;=\; 4\\
x^3 \;=\; \left( \sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i} \right)^3 \;=\; 4^3 \;=\; 64$$ expanded the middle one from the binomial theorem: $$x^3 \;=\;
\left(\sqrt[3]{2 {\color{red}+} 11i}\right)^3 +
\left(\sqrt[3]{2 {\color{red}-} 11i}\right)^3 +
3\!\cdot\!\sqrt[3]{2 {\color{red}+} 11i}\!\cdot\!\sqrt[3]{2 {\color{red}-} 11i}\!\cdot\!\left(\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}\right)
\;=\; 4^3 \;=\; 64\\
x^3 \;=\;
2 {\color{red}+} 11i + 2 {\color{red}-} 11i +
3\!\cdot\!\sqrt[3]{\left(2 {\color{red}+} 11i\right)\left(2 {\color{red}-} 11i\right)}\!\cdot\!\left(\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}\right)
\;=\; 4^3 \;=\; 64\\
x^3 \;=\;
4 + 3\!\cdot\!\sqrt[3]{2^2 - (11i)^2}\!\cdot\!\left(\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}\right)
\;=\; 4^3 \;=\; 64\\
x^3 \;=\;
4 + 3\!\cdot\!\sqrt[3]{4 + 121}\!\cdot\!\left(\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}\right)
\;=\; 4^3 \;=\; 64\\
x^3 \;=\;
4 + 3\!\cdot\!\sqrt[3]{125}\!\cdot\!\left(\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}\right)
\;=\; 4^3 \;=\; 64\\
x^3 \;=\;
4 + 3\!\cdot\!5\!\cdot\!\left(\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}\right)
\;=\; 4^3 \;=\; 64\\
x^3 \;=\;
4 + 15\!\cdot\!\left(\sqrt[3]{2 {\color{red}+} 11i} + \sqrt[3]{2 {\color{red}-} 11i}\right)
\;=\; 4^3 \;=\; 64$$ But now the expression that remained in parentheses is just the original $x$ I started with! When trying to find the answer, I run across the original question again :/  Not only that, but replacing it with $x$ gives me the original cubic equation I started with ;/ $$x^3 = 4 + 15x\\x^3 - 15x - 4 = 0$$ Why am I going in circles with this? And what other techniques can I use to crack this and prove that this sum of cube roots indeed equals to the real number $4$? Inb4: I already ascertained geometrically that this sum of cubes is really equal to $4$, but now I'd like to have it proved algebraically, and learn a general method of dealing with such sums of cubes of complex conjugates. Edit: All the answers so far seem to be based on the assumption that I know that this complex expression is equal to 2 already (e.g. by restoring the original cubic equation and finding its rational roots). What I'm rather interested in, is how to find the equivalent real solutions when restoring the original cubic equation doesn't work, because it cannot be solved by the rational roots theorem.","['radicals', 'complex-numbers', 'radical-equations', 'algebra-precalculus', 'cubics']"
2665884,On finding the asymptotic distribution of the coefficient of variation,"Given an IID sample $X_1, \dots, X_n \sim N(\mu, \sigma^2)$ with $\mu \ne 0$ let $$(S_n)^2 = \frac{1}{n} \sum_{i = 1}^n ( X_i - \overline{X_n})^2$$ I want to find the distribution of the coefficient of variation $\frac{S_n}{\bar{X}_n}$ where $\bar{X}_n$ is the sample mean. I have come up with an entire solution but there appears to be an error I can't find. MY SOLUTION : $S_n$ is asymptotically consistent for $\sigma \implies \frac{S_n}{\sigma} \xrightarrow{p}1$ Since $ \sqrt{n}(\bar{X}_n - \mu)$ converges to a normal distribution (by the central limit theorem)  by the delta method we have that $\sqrt{n} \frac{\sigma}{\bar{X}_n}$ converges in distribution to $$  \frac{\sigma^2}{\mu^2}Z $$ where $Z \sim N\left(\frac{\sigma}{\mu}, 1\right) $ this is because we have chosen $\phi(x) = \frac{\sigma}{x} \implies \phi'(x) = -\frac{\sigma}{x^2} $. ($\phi$ is the function we are applying to the sequence of random variables). Now from Slutsky's theorem we have that $$\sqrt{n} \frac{S_n}{\bar{X}_n } = \sqrt{n}\frac{S_n/ \sigma}{\bar{X}_n / \sigma} \xrightarrow{d} N\left( \frac{\sigma}{\mu},\frac{\sigma^4}{\mu^4}\right)$$ Except the solution I am given has $N\left(\frac{\sigma}{\mu},\frac{\sigma^2}{2\mu^2}\right)$ Where is my mistake?","['probability-theory', 'probability', 'normal-distribution', 'asymptotics']"
2665945,Prove $f(x) =0$ for all $x$,"Let $f:[0,1]→\Bbb R$ be continuous with $f(0)=f(1)=0$. Suppose that for every $x ∈ (0,1)$ there exists $δ > 0$ such that both $x−δ$ and $x+δ$ belong to $(0,1)$ and $f(x) = \frac{1}{2}(f(x−δ)+f(x+δ))$ . Prove that $f(x) = 0$ for all $x ∈ [0, 1]$. I have considered several approaches but not had much success with any of them. First, I tried to prove that $f'(x)=0$ for all x, because as we're given $f(0)=f(1)=0$, I think that is sufficient? But I ran into trouble proving that the limit exists for some general $a$ in the domain. So I decided to try and use continuity, specifically around zero: my intuition was that for $x$ sufficiently close to 0, $f(x)$ is approximately zero and I tried to build up that the images of the two perturbations would also be zero but again without much success. Please could I have some help? Ideally, a discussion of the right kind of intuition as well as a sketch solution. Comments on whether my approaches were at all in the right direction would also be appreciated. Edit: Please could this be solved with using connectedness and compactness. Thank you.","['continuity', 'real-analysis', 'analysis']"
2665985,"If $A$, $B$ and $C$ are the angles of a triangle then find the value of $\Delta$","I'll state the question from my book below: If $A$ , $B$ and $C$ are the angles of a triangle, then find the determinant value of $$\Delta = \begin{vmatrix}\sin^2A & \cot A & 1 \\ \sin^2B & \cot B & 1 \\ \sin^2C & \cot C & 1\end{vmatrix}.$$ Here's how I tried solving the problem: $\Delta = \begin{vmatrix}\sin^2A & \cot A & 1 \\ \sin^2B & \cot B & 1 \\ \sin^2C & \cot C & 1\end{vmatrix}$ $R_2 \to R_2 - R_1$ $R_3 \to R_3 -R_1$ $= \begin{vmatrix}\sin^2A & \cot A & 1 \\ \sin^2B-\sin^2A & \cot B-\cot A & 0 \\ \sin^2C-\sin^2A & \cot C-\cot A & 0\end{vmatrix}$ Expanding the determinant along $C_3$ \begin{align}
&= (\sin^2B-\sin^2A)(\cot C-\cot A)-(\cot B-\cot A)(\sin^2C-\sin^2A)  \\
&= \sin(B+A) \sin(B-A) \left[\frac {\cos C}{\sin C} - \frac {\cos A}{\sin A}\right] - \left[\frac {\cos B}{\sin B} - \frac {\cos A}{\sin A}\right]\sin(C+A) \sin(C-A)  \\
&= \frac {\sin(B+A) \sin(B-A) \sin(A-C)} {\cos A \cos C} - \frac {\sin(A-B) \sin(C+A) \sin(C-A)} {\cos A \cos C}  \\
&= \frac {\sin(B-A) \sin (A-C)} {\cos A} \left[\frac {\sin(A+B)} {\cos C} - \frac {\sin(A+C)} {\cos B}\right]  \\
&= \frac {\sin(B-A) \sin (A-C)} {\cos A} \left[\frac {\sin C} {\cos C} - \frac {\sin B} {\cos B}\right]  \\
&= \frac {\sin(B-A) \sin (A-C) \sin (C-B)} {\cos A \cos B \cos C}
\end{align} I tried solving further but the expression just got complicated. I don't even know if the work I've done above is helpful. My textbook gives the answer as $0$ . I don't have any clue about getting the answer. Any help would be appreciated.","['trigonometry', 'determinant', 'triangles', 'geometry', 'linear-algebra']"
2665989,Is it possible to execute line integrals of non-conservative vector fields on curves defined by implicit relation such as $\sin(xy)=x+y$?,"I want to execute the line integral (analytically) of a vector field over the curve defined by implicit function $\sin(xy)=x+y$ for some $x=a$ & $y=c$ to $x=b$ & $y=d$. The difficulties I face executing this problem are: There can no explicit parametrization of $x$ and $y$ wrt to some parameter $t$. Ted Shifrin has pointed to me in chat that this problem has become unsolvable for non-conservative vector fields for this reason. But, for conservative vector fields , the problem becomes trivial to execute. Even if we consider some conservative vector field, this problem is problematic some values of $x$, $y$ has multiple corresponding values. See the pictures. Then, to use the fundamental theorem of line integral we need to divide the curve into several parts where the $\sin(xy)=x+y$ relation becomes a function. And last of all , is this problem really (analytically) unsolvable for non-conservative vector fields? I can always numerically execute the integral (of course, approximately). But, that's not my point here. Is there any novel technique present in the to-date literature to somehow overcome the barrier of the non-conservative vector fields? Any help would be appreciated.","['multivariable-calculus', 'implicit-function', 'vector-fields', 'vector-analysis']"
2665990,Stability types in a homogeneous linear system,I would like to calculate the range of values for which x * (fixed point) = 0 and I want to investigate the type of stability. $$ \frac{d}{du} \begin{bmatrix}x\\y\end{bmatrix} =  \begin{bmatrix}-5&a\\2&1\end{bmatrix} \begin{bmatrix}x\\y\end{bmatrix}$$ I have already satisfied the cases for node and saddle. I want to find the solution for a focus: From my understanding: Focus = eigenvalues which are complex conjugate numbers with a positive real part. In my solution I have obtained that the eigenvalues are: $-2 \pm \sqrt{9+2a}$ However I am unsure of how to satisfy the values for which the stability point is a focus. Any help would be welcome.,"['dynamical-systems', 'matrices', 'calculus', 'multivariable-calculus', 'ordinary-differential-equations']"
2666033,Is there a number of the form $f(n)=7k+6=5p$ with prime $p$?,"Here : Numbers $n$ of the form $10^{m}(2^{k}−1)+2^{k-1}−1$, where $m$ is the number of decimal digits of $ 2^{k-1}$. the numbers $$f(n):=(2^n-1)\cdot 10^d+2^{n-1}-1$$ are introduced , where $d$ denotes the number of digits of $2^{n-1}-1$ in the decimal expansion. So, we simply concatenate two neighboured Mersenne-numbers, for example $f(10)=1023511$. I know no prime $f(n)$ of the form $7k+6$. I also did not find a number $f(n)$ yet which is of the form $7k+6=5p$ with a prime $p$, so a number $f(n)$ with $f(n)\equiv 6\mod 7$ and $\frac{f(n)}{5}$ is a prime number. With PFGW, I passed $n=122\ 000$ without finding such a number. Does such a number exist ?","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2666056,Compute $\lim_{x\to\frac{\pi}{2}} \frac{(1-\sin x)(1-\sin^2x)\dots(1-\sin^nx)}{\cos^{2n}x}$,"$$\lim_{x\to\frac{\pi}{2}} \frac{(1-\sin x)(1-\sin^2x)\dots(1-\sin^nx)}{\cos^{2n}x}=?$$ Here's what I have done so far:
$y=\frac{\pi}{2}-x$ The limit becomes:$$\lim_{y\to 0}\frac{(1-\cos y)(1-\cos^2y)\dots(1-\cos^ny)}{\sin^{2n}y}=\lim_{y\to 0}\frac{1-\cos y}{\sin^2y}\frac{1-\cos^2y}{\sin^2y}\dots\frac{1-\cos^ny}{\sin^2y}$$ Also $1-\cos y=2\sin^2 \frac{x}{2}$ How should i write $1-\cos^2y ,1-\cos^3y,\dots1-\cos^ny$  in order to get the final answer.","['limits-without-lhopital', 'trigonometry', 'calculus', 'limits']"
2666063,Verify an identity of two series,"This question is from Stein's Complex Analysis, and this is the first part of the original question. The original question was posted here but it was only about the remaining part, and I do not really have problems with the remaining part. So, here is the question I wanted to ask: Let $F(z)=\sum_{n=1}^{\infty}d(n)z^{n}$ where $d(n)$ denotes the number of divisors of $n$. Observe that the radius of convergence of this series is $1$. Verify the identity: $\sum_{n=1}^{\infty}d(n)z^{n}=\sum_{n=1}^{\infty}\frac{z^{n}}{1-z^{n}}$ The remaining part of the original question is to use this identity to show something else, but I don't know how to verify this identity.. I have tried some example for some n's, and I believe this identity, but I don't really have a clue about how to verify this identity. Here is what I tried so far: $\frac{1}{1-z^{n}}=1+z^{n}+z^{2n}+z^{3n}+z^{4n}+\cdots$, and then $\frac{z^{n}}{1-z^{n}}=z^{n}+z^{2n}+z^{3n}+z^{4n}+z^{5n}+\cdots$. So, we have $\sum_{n=1}^{\infty}\frac{z^{n}}{1-z^{n}}=\sum_{n=1}^{\infty}\sum_{k=1}^{\infty}z^{kn}$. Then I don't know how to do next. Some hints or detailed explanations are really appreciated!!",['complex-analysis']
2666067,What is the equality of two functions (or maps)?,"Suppose there are two maps $f : A \to B$ and $g : A\to C$ such that $C$ and $B$ can be different sets, but $f(x)=g(x)$ for every $x$ in $A$. Thus, the image of $f$ and $g$ are both contained in the intersection of $B$ and $C$. Then, can it be said that $f=g$?  This seems like a trivial question, but really annoys and confuses me... Here, the function $F$ is defined as $F : M \to N$ but also regarded as $F : M \to F(M)$ to be a homeomorphism. So it still leaves confusion...","['elementary-set-theory', 'functions']"
2666112,Let $f:\Xi\rightarrow\mathbb{R}$ we consider $F$ defined by $F(\nu):=\int_{\Xi}f(\xi)\nu(d\xi)$. Is $F$ continuous with respect to the metric $W_{p}$?,"Before presenting my question (which I already formulate in the title of this post)  is important to establish the context of my problem: Definition: The $p$-Wasserstein metric $W_{p}(\mu,\nu)$ between $\mu,\nu\in\mathcal{P}_{p}(\Xi)$ is defined by
  $$W_{p}^{p}(\mu,\nu):=\min_{\Pi\in\mathcal{P}(\Xi\times\Xi)}\left\{\int_{\Xi\times\Xi}d^{p}(\xi,\zeta)\Pi(d\xi,d\zeta)\: :\: \Pi(\cdot \times\Xi)=\mu(\cdot),\: \Pi(\Xi\times\cdot)=\nu(\cdot)\right\}$$
  where 
  $$\mathcal{P}_{p}(\Xi):=\left\{\mu\in\mathcal{P}(\Xi)\: :\: \int_{\Xi}d^{p}(\xi,\zeta_{0})\mu(d\xi) < \infty\ \mbox{for some }\zeta_{0}\in\Xi\right\}$$
  where $d$ is a metric on  $\Xi$. The question: Given a function $f:\Xi\rightarrow \mathbb{R}$ we consider   the function $F:\mathcal{P}_{p}(\Xi)\rightarrow \mathbb{R}$ defined by $F(\nu):=\int_{\Xi}f(\xi)\nu(d\xi)$. Is $F$ continuous with respect to the metric $W_{p}$? That is, given a sequence $\{\nu_{n}\}_{n=1}^{\infty}\subset \mathcal{P}_{p}(\Xi)$ and $\nu\in\mathcal{P}_{p}(\Xi)$ such that $W_{p}(\nu_{n},\nu)\rightarrow 0$, then do we have $\left|F(\nu_{n})-F(\nu)\right|\rightarrow 0 $? Remark: If $f$ is bounded then the answer to the previous question is affirmative, this is a consequence of Definition 6.8 and Theorem 6.9 of Cedric Villani's book . The problem is when $f$ is not bounded, for example $f(\xi)=\xi^{2}-\xi$ with $\Xi=\mathbb{R}$.","['continuity', 'probability-theory', 'weak-convergence', 'measure-theory']"
2666115,Foliations and groupoids in algebraic geometry,"I am currently studying the theory of foliations and groupoids from a differentiable viewpoint, in particular Haefliger spaces. [See Segal, Classifying spaces related to foliations , and Moerdijk, Classifying toposes and foliations .] I read that there are related notions of groupoids and foliations in algebraic geometry, particulary in the context of schemes. Is there a basic reference where to study this theory? Assume as background a basic course on schemes and several courses in ""classical"" algebraic geometry. Thank you very much.","['schemes', 'groupoids', 'foliations', 'algebraic-geometry']"
2666142,Creating 6 Digit Numbers Whose Adjacent Digits are Relatively Prime,"Six-digit integers will be written using each of the digits $1$ through $6$ exactly once per six-digit integer. How many different positive integers can be written such that all pairs of consecutive digits of each integer are relatively prime? (Note: $1$ is relatively prime to all integers.) The pairs of numbers that are relatively prime from $1-6$ are: $1:2,3,4,5,6$ and 
$2:3,5$ and $3,4,5$ and $4,5$ and $5,6$. Now, what should I do from here.","['combinatorics', 'prime-numbers']"
2666179,Prove that $\sum_{k=0}^{n-1}\frac{n^{k-1}}{k!}(n-k)(n-k+1)=\frac{n^{n-1}}{(n-1)!}+\sum_{k=0}^{n-1}\frac{n^k}{k!}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm having trouble proving the following identity: $$\sum_{k=0}^{n-1}\frac{n^{k-1}}{k!}(n-k)(n-k+1)=\frac{n^{n-1}}{(n-1)!}+\sum_{k=0}^{n-1}\frac{n^k}{k!}$$ I've played with the binomial theorem and other similar identities, but nothing seems to work. I'm sure we can prove it by induction, but I was more looking for a proof which uses other well-known identities.","['summation', 'discrete-mathematics']"
2666222,"The Integral of which the real part is the Poisson Integral of $f$, is Holomorphic","This comes from Rudin's Real and Complex Analysis, in which there is a claim, regarding the integral in the title. (i) Let $0<r<1,\ T$ be the unit circle in $\mathbb C, \ f\in L^1(T),\ $ and $z=re^{it}$. Then the following fact shows that $\int _T\frac{e^{it}+z}{e^{it}-z}f(t)dt$ is a holomorphic function of $z$: (ii) Suppose $\mu$ is a complex measure on $X$ and $\phi:X\to \mathbb C.$ If $\phi(X)$ does not intersect the open set $\Omega$ in $\mathbb C$ then $f(z)=\int _X \frac{d\mu (x)}{\phi (x)-z}$ is holomorphic for $z\in \Omega.$ So in this exercise, $X=T=[-\pi,\pi]$ Here is my attempt at showing that (ii) implies (i), which I would like feedback on. Is it correct? If so, is there an easier way to do it? If not, where is the error? I think a direct approach would also work, although I have not written it out. Take $\gamma (t)=e^{it},$ define $d\mu=\gamma'(t)dt,$ and $d \nu_1=fdt,\ d \nu_2=fd\mu$ where $dt$ is Lebesgue measure on $T$.  Then, we have $\int _T\frac{e^{it}+z}{e^{it}-z}f(t)dt=\int _T\frac{e^{it}}{e^{it}-z}f(t)dt+z\int _T\frac{1}{e^{it}-z}f(t)dt.$ So, with $\phi(t)=\gamma (t)=e^{it},$ the first integral is $\frac{1}{i}\int_T\frac{d\nu_2}{\phi(t)-z}$ and the second is $z\int_T\frac{d\nu_1}{\phi(t)-z},\ $ which proves the claim.","['harmonic-analysis', 'real-analysis', 'fourier-analysis', 'measure-theory']"
