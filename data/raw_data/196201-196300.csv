question_id,title,body,tags
3780291,"Clarification of algebraic ""fallacies"" - Methods of Mathematics by Richard Hamming","I am reading the book ""Methods of Mathematics"" by Richard Hamming. In one section he talks about certain fallacies in algebra to avoid. He gives a very clear example of accidentally dividing by zero, but then follows it with another example which he claims performs such a violation more subtly. $$\frac{1}{x(x-a)}-\frac{1}{x}= \frac{a}{(x-a)}$$ Okay, I see we cannot have x equal to zero, nor can we have x equal to a. No problem here. He then presents the formula ""cleared of fractions"". $$1 - (x-a) = ax $$ $$1-x+a=ax$$ $$1+a=x+ax$$ $$1+a=x(1+a)$$ No problem, I see what he did. He then continues the math to solve for x, yielding $$ x = 1 $$ And this is where the thinking begins. So it seems that he is saying that the equation is not dependent on the value of $a$ . But he says this cannot be true because the original formula is not defined for $x=1$ when $a=1$ because from the original formula we reasoned that $x$ cannot be equal to $a$ .  So my questions are below: 1.) Is he claiming that he's used a fallacy to solve the equation; one that results in an incorrect statement? I don't see one. 2.) Or is it that our system of symbolic manipulation is such that given the ""fractionless"" form initially, we wouldn't have seen the limitation that $x$ cannot equal $a$ ? 3.) Can the given conditions on $x$ and $a$ be readily seen in the fractionless form? 4.) If not, how do we avoid such errors? By trying multiple forms until such constraints are apparent? 5.) Why is $x$ not able to be equal to $a$ ? It seems that of course we cannot divide by zero, but using a different form, e.g. the fractionless form, avoids this issue. So how can changing the form of an equation make certain solutions suddenly valid? I think it probably doesn't since they are equivalent. I must be missing something here. He also notes that when $a=-1$ , all solutions for $x$ are valid except $0$ and $-1$ . So it really seems like he's saying that our solution, independent of $a$ , is not correct. Where did it all fall apart?",['algebra-precalculus']
3780293,"calculate: $\int_0^\infty \frac{\log x \, dx}{(x+a)(x+b)}$ using contour integration","given $ a\neq b;b,a,b>0 $ calculate: $\int_0^\infty\frac{\log x \, dx}{(x+a)(x+b)}$ my try:
I take on the rectangle: $[-\varepsilon,\infty]\times[-\varepsilon,\varepsilon]$ I have only two simple poles outside $x=-a,$ $x=-b,$ therefore according the residue theorem it must be $4\pi i$ .
My problem, is that in the rectangle I left inside there is a pole and when epsilon reaches $0$ the rectangle actually goes through it. Isn't it problematic?","['integration', 'complex-analysis', 'contour-integration', 'residue-calculus']"
3780318,"Prove that $F^{(n)}(z)=\int_{X}\frac{\partial^n f}{\partial z^n}(x,z)\,\mathrm{d}\mu(x)$","This is taken from Problem 4.13 by Christian Berg's Complex Analysis . See also post , not a duplicate! I will copy the problem to show the whole context: src) 4.13. (Requires basic measure theory). Let $(X,\mathbb{E},\mu)$ be a measurable space and let $G\subseteq\mathbb{C}$ be open. Assume that $f:X\times G\to\mathbb{C}$ satisfies (ⅰ) $\forall x \in X$ : $f(x,\cdot)\in\mathcal{H}(G)$ . (ⅱ) $\forall z \in G$ : $f(\cdot,z)$ is measurable on $X$ . (ⅲ) There exists a measurable function $g:X\to[0,\infty]$ satisfying $\int g\,\mathrm{d}\mu<\infty$ , such taht $$\left|f(x,z)\right|\leq g(x) \quad\text{for}\quad x\in X, \ z \in G.$$ $\mathbf{1^{\circ}}$ Prove that $\frac{\partial f}{\partial z}(\cdot, z)$ is measurable for each $z \in G$ . $\mathbf{2^{\circ}}$ Assume that $\overline{K(z_0,r)}\subseteq G$ . Prove that $$ \left| \frac{\partial f}{\partial z}(x,z)\right|\leq\frac{4}{r}g(x), \quad z\in K(z_0,r/2), \ x \in X.$$ and that $$\frac{1}{h} (f(x,z_0+h)-f(x,z_0)) = \int_{0}^{1} \frac{\partial f}{\partial z}(x, z_0+th)\,\mathrm{d}t, \quad 0<|h|<r, \ x \in X. $$ $\mathbf{3^{\circ}}$ Prove that $$ F(z) = \int_{X} f(x, z) \, \mathrm{d}\mu(x), \quad z \in G, $$ is holomorphic in $G$ and $$ F'(z) = \int_{X} \frac{\partial f}{\partial x}(x, z) \, \mathrm{d}\mu(x), \quad z \in G.$$ Remark. Notice that (ⅲ) can be replaced by local conditions: For each $a \in G$ there exists a disc $K(a, r)\subseteq G$ and a ""majorant"" $g$ , both depending on $a$ such taht $$\left| f(x, z) \right| \leq g(x) \quad\text{for}\quad x \in X, \ z \in K(a, r).$$ $\color{red}{\blacksquare[}$ Notice also that in this version the results can be applied to $\frac{\partial f}{\partial z}$ , so the final conclusion is that we can differentiate the integral infinitely often by differentiating under the integral sign: $$ F^{(n)}(z) = \int \frac{\partial^n f}{\partial z^n}(x,z) \, \mathrm{d}\mu(x), \quad z \in G, \ n \in \mathbb{N}. \tag*{$\color{red}{]\blacksquare}$} $$ I have solved this problem. The question is right ind the end, see the red part I have marked. I do not know how it is reached? Seems like one should prove it by induction. If I put $$h(x,z):=\frac{\partial f}{\partial z}(x,z) \quad\text{for}\quad (x,z)\in X\times G, $$ then $h$ clearly satisfies the two first points, but I do not know how to prove the last point (iii). Thank you for your time!","['complex-analysis', 'proof-explanation', 'measure-theory', 'lebesgue-integral']"
3780320,Book recommendation on maximum likelihood estimation with proofs in general settings,"I am looking for a book (or serious notes) that contains a chapter on maximum likelihood estimation with all proofs on consistency, functional invariance, efficiency, second-order efficiency after correction for bias... preferably from a measure theoretic point of view. Any recommendation ?","['statistics', 'book-recommendation', 'maximum-likelihood', 'soft-question', 'probability-theory']"
3780329,Would my proof of induction be accepted in an intro Abstract Algebra Course. Self-studying and New to proofs.,"Hello I'm self studying and I'm also new to proofs and would like to know whether my proof is rigorous enough for a first course in Abstract Algebra. I'm asked to proof Induction of the second kind which states that: Suppose P(n) is a statement about the positive integers and c is some fixed positive integer. Assume i) P(c) is true ii) for every $m > c $ , if P(k) is true for all k such that $c \leq k < m $ , then P(m) is true Then P(n) is true for all $n \geq c $ The proof also has to use the well-ordering principle which states that: Every nonempty subset of the positive integers has a smallest element. My proof: First let $M = \{x\mid x \in N \land x>c \land P(x) \text{ is false} \}$ Now we assume M is nonempty. Then by the well-ordering principle there exists a smallest element of M which we'll call $y.$ We know that $P(n)$ for all $c \leq n < y $ is true thus $P(y)$ is true by ii. This is a contradiction thus $M$ is the empty set which means that $P(n)$ is true for all $n \geq c $ I'm self-studying and do not know whether my proof would be acceptable for a intro abstract algebra class. So my questions are: Is my proof correct? and if it's not correct, why not and how would I prove it then? and if it's correcct, is there anything you would change? Thanks in advance.","['elementary-set-theory', 'induction', 'proof-writing', 'solution-verification']"
3780366,"$f:S\to X$ is generically finite of degree $d$, then $f_*f^*D=dD$","In Beuville's Complex Algebraic Surfaces , chapter 1, he consideres a map $f:S\to X$ between smooth projective varieties over $\Bbb{C}$ ( $S$ is a surface, but I don't think this will be important) which is generically finite of degree $d$ . If $C\subset S$ is an irreducible curve, he defines: $$
f_*C:=\begin{cases}
0,\text{ if }f(C)\text{ is a point;}\\
r\Gamma,\text{ if }f(C)\text{ is a curve }\Gamma\text{ and }f\big|_C:C\to\Gamma\text{ is finite of degree }r.
\end{cases}$$ He also says that it follows from the definition that $f_*f^*D=dD$ for any divisor $D$ in $X$ . Here are my questions: What does he mean by generically finite ? I know Hartshorne defines generically finite as a morphisms of schemes whose preimage of the generic point is finite. But here we have varieties, so how would that translate? I wish he would explain the map $f\big|_C:C\to\Gamma$ better. Is it necessarily finite? When could $r$ be different from $d$ ? Why do we get $d$ in $f_*f^*D=dD$ ?","['morphism', 'algebraic-geometry', 'schemes', 'birational-geometry']"
3780367,Real Projective Space & Quotient of a Sphere,"I have been trying to solve the Exercise 7.11 of Loring Tu's An Introduction to Manifolds (Second Edition, page no. 77). It reads as follows. The way I proceeded to solve it, it has been discussed partly here . But I also wanted to understand the solution supplied by the author given below. I have some questions about this solution. My Questions Here $\pi_2$ is continuous because it is a projection map. How do we deduce that $f: \mathbb{R}^{n+1} - \lbrace 0 \rbrace \to S^n, f(x) = \frac{x}{||x||},$ is continuous so that $\pi_2 \circ f$ is continuous? In the second part of the proof, Tu applies the same technique (which is used to prove $\bar{f}$ continuous) to prove $\bar{g}$ continuous. What is the motivation for defining $g: S^n \to \mathbb{R}^{n+1} - \lbrace 0 \rbrace$ by $g(x) = x$ ? In other words, how do we know that $g$ needs to be defined in this way?","['general-topology', 'differential-geometry']"
3780376,Surjective ring maps always induce isomorphic residue field?,"Context. I am trying to understand why 10.115.4 follows from 10.115.3 . I believe it boils down to the following. Let $(S',m') \rightarrow (S,m)$ be a surjection of finite type local $k$ algebras. Then we have induced isomoprhism of residue fields $$ \kappa(m') \rightarrow \kappa(m) $$ But this seems to be true more general: that we do note need the condition of finite type local $k$ algebras. I believe that If $S' \rightarrow S$ is a surjective ring map, then for all prime $p$ of $S$ with preimage $p'$ , we have induced isomorphism of residue fields. $$ \kappa(p')\rightarrow \kappa(p)$$ The argument is simply because the induced map is surjective, and any field homomorphism is either $0$ or injective. Am I correct?","['field-theory', 'ring-theory', 'algebraic-geometry', 'commutative-algebra']"
3780388,Proving that the Diophantine equation $(11a + 5b)^2 - 223b^2 = \pm 11$ has no solutions,"I am working on an algebraic number theory exercise, which is to prove that $\mathbb Z[\sqrt{223}]$ has three ideal classes. I've run against the following two (really four) Diophantine equations: $$
(11a + 5b)^2 - 223b^2 = \pm 11
$$ $$
(3a + b)^2 - 223b^2 = \pm 3
$$ I think I should be able to prove that neither of these pairs of equations has any solutions in $\mathbb Z^2$ - I have run a program to check all small values of $a$ and $b$ (less than 10,000) and found nothing, but I know that the minimum solutions to equations like this can be quite large. What I've tried doing so far is reducing the first equation mod $11$ and mod $5$ , both of which seem to give tautologies, and reducing the second equation mod $3$ , which also wasn't useful. I don't know much in this area, so I'm not sure how to begin attacking the problem.","['number-theory', 'algebraic-number-theory', 'diophantine-equations']"
3780409,"When evaluating the limit of $f(x, y)$ as $(x, y)$ approaches $(x_0, y_0)$, should we consider only those $(x, y)$ in the domain of $f$?","When evaluating the limit of $f(x, y)$ as $(x, y)$ approaches $(x_0, y_0)$ , we should or should not consider only those $(x, y)$ in the domain of $f(x, y)$ ? I am confused by different practices of Calculus textbooks. Have anyone searched and found some authoritative opinion ? Thomas Calculus 14e §14.2 Example 2 (Page 802-803) $\lim_{(x, y) \to (0, 0)} \frac{x^2 - x y}{\sqrt{x} - \sqrt{y}}$ considers only those $(x, y)$ in the domain. The authors' answer ( $\mathbf{0}$ ) is the same as the answer by WolframAlpha . See textbook page 802 and textbook page 803 . Larson Calculus 10e §13.2 Exercise 27 (Page 887) $\lim_{(x, y) \to (0, 0)} \frac{x - y}{\sqrt{x} - \sqrt{y}}$ considers NOT only those $(x, y)$ in the domain. The authors' answer ( DNE ) is NOT the same as the answer by WolframAlpha ( $\mathbf{0}$ ). See textbook page 887 and solution manual page 1268 .","['limits', 'calculus']"
3780430,What is wrong with the argument $1 = \lim_{n\to \infty} n/n = \lim_{n\to\infty} (1/n+1/n+\dotsb+1/n) = 0 $?,"Let we have \begin{equation*}
n\times\frac{1}{n}=\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}\mbox{ ($n$ times)}.
\end{equation*} Taking $\lim_{n\to\infty}$ to both sides, we get \begin{eqnarray*}
\lim_{n\to\infty}1 &=& \lim_{n\to\infty}\left(\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}\right)\\
\Longrightarrow1&=&0+0+\cdots+0\mbox{ ($n$ times)}\\
&=&0.
\end{eqnarray*} I am not an expert of math, and confused that where the confusion is.","['limits', 'calculus', 'infinity']"
3780456,Morphism from a scheme to the spectrum of global section,"This is exercise II.2.4 in Hatshorne: Let $A$ be a ring and $(X,\mathcal{O}_X)$ a scheme. We have the associated map of sheaves $f^\#: \mathcal{O}_{\text{Spec } A} \rightarrow f_* \mathcal{O}_X$ . Taking global sections  we obtain a homomorphism $A \rightarrow \Gamma(X,\mathcal{O}_X)$ . Thus there is a natural map $\alpha : \text{Hom}(X,\text{Spec} A) \rightarrow \text{Hom}(A,\Gamma(X,\mathcal{O}_X))$ . Show $\alpha$ is bijective. We can find a map $\beta: \text{Hom}(A,\Gamma(X,\mathcal{O}_X)) \rightarrow \text{Hom}(X,\text{Spec} A)$ by sending a map $g: A \rightarrow \Gamma(X,\mathcal{O}_X)$ to a map from $X$ to $\text{Spec} A$ defined as follows: First taking affine open cover of $X = \cup \, \text{Spec} A_i$ , then taking spectrum of the map $g$ (after being composed with the restriction map, i.e. consider $g_i: A \rightarrow A_i$ and take $\text{Spec} g_i$ ), and glue them together. Details are in the post: Prove that the natural map $\alpha : \text{Hom}(X,\text{Spec} A) \rightarrow \text{Hom}(A,\Gamma(X,\mathcal{O}_X))$ is an isomorphism . My question is : How to show the map $\alpha$ and $\beta$ are inverse to each other? The question in affine case is casual, where $\alpha$ is simply ""taking global sections"" and $\beta$ is ""taking spectrum"". These two are ""inverse"" to each other indeed. Yet how to show this in the general case on scheme (not just affine schemes) . In other word, the adjunction of $\Gamma$ and $\text{Spec}$ is in affine case, hence is ""local"". Yet how to ""glue these adjunctions""? Any direct proof on ""the map $\alpha$ and $\beta$ are inverse to each other"" is welcomed :) P.S. I know that there is a proof in broader context on locally ringed space, i.e. https://stacks.math.columbia.edu/tag/01I1 , but I still hope to practice the method of gluing things.","['algebraic-geometry', 'schemes']"
3780478,"Correct my intuition: every Galois group is $S_n$, and other obviously incorrect statements","(I hope that this question is acceptable and within the rules of math.stackexchange. If not, mods should edit at will and let me know if this question must be broken into several different questions. I ask these all together at once because they seem crucially tied together insofar as answers would correct my misunderstandings.) I am currently studying Galois Theory, but I am unable to get a handle on the subject. My intuition leads to me conclusions which are obviously incorrect, so I will ask a brief series of questions which I think will help me correct my course. Let $Q$ be the rationals. Let $f$ be an irreducible polynomial (hence separable) over $Q$ with degree $n$ . Let $F$ be the splitting field of $f$ . So $F/Q$ is Galois. Let $G$ be the Galois group of $F/Q$ . Let $a_1,\dots ,a_n$ be the distinct roots of $f$ . My understanding is that $F=Q(a_1,\dots ,a_n)$ . Question 1: Since every automorphism of $F/Q$ permutes $a_1,\dots ,a_n$ , it is clear that $G$ can be embedded into $S_n$ as a subgroup. Why is it not the case that $G$ is automatically all of $S_n$ ? Surely any permutation of the roots gives an automorphism of $F$ preserving $Q$ ? If not, what might be an instructive minimal example? Question 2: Conceptually speaking, what exactly prevents certain permutations from being acceptable automorphisms of $F/Q$ ? Question 3:  Alternatively, if $f$ is not irreducible, then $F$ is the splitting field of some polynomial which is not irreducible. In this case, I believe that roots from different irreducible components cannot jump to roots of other irreducible components. Why is this the case? Question 4: Again we assume that $f$ is irreducible. What must be unique about the situation in order for $G$ to really be all of $S_n$ ? Question 5: Now set $n=4$ . I know that $A_{4}$ is the only subgroup of $S_4$ with order $12$ . Suppose that $G=S_4$ . Suppose $K=Q(a_1)$ . Why is it not the case that $F/K$ has order $12$ and hence has Galois group $A_4$ ? It seems that the Galois group of $F/K$ could include all permutations of $a_1,\dots ,a_4$ that map $a_1$ to itself. Question 6: Suppose we are in the case of Question 5. Why is it the case that the Galois group of $F/K$ has a transposition?","['field-theory', 'galois-theory', 'abstract-algebra']"
3780497,How to obtain the Klein bottle as a product of manifolds?,"I know the Klein bottle $K$ is a fiber bundle over $S^1$ , but my question is: is it possible to find a manifold $M$ such that $K = S^1 \times M$ without the need to take an equivalence relation afterwards?
My thoughts are, maybe something like taking $M$ as the image of $S^1$ under $z \to z^2$ or something in that direction. Do you think I will be able to get somewhere? Thanks in advance.","['general-topology', 'klein-bottle', 'smooth-manifolds', 'differential-geometry']"
3780500,"Prove that if A has imaginary eigenvalues and the flows $e^{tA}$ and $e^{tB}$ are topologically conjugate, then B has the same imaginary eigenvalues.","Show that if A has eigenvalues of the form $\pm i \beta$ , with $\beta \neq 0$ and the flows $e^{tA}$ and $e^{tB}$ are topologically conjugate, then $\pm i \beta$ also are eigenvalues of $B$ . Definitions: $(i)$ Let $(f^t)_t$ and $(g^t)_t$ be flows of the following autonomous differential equations $x' = F(x)$ , $F: \mathcal{U} \longrightarrow \mathbb{R}^d$ and $y' = G(y), G: \mathcal{V} \longrightarrow \mathbb{R}^d$ , with $F$ and $G$ continuous funtions defined over open sets. The flows $(f^t)_t$ and $(g^t)_t$ are said to be topologically conjugate if there exists a homeomorphism $h: \mathcal{U} \longrightarrow \mathcal{V}$ such that $f^t(x)$ is defined if and only if $g^t(h(x))$ is defined. In such case, $h(f^t(x)) = g^t(h(x))$ . $(ii)$ Two flows $(f^t)_t$ and $(g^t)_t$ in $\mathbb{R}^d$ are said to be linearly conjugate if there exists a linear isomorphism $h: \mathbb{R}^d \longrightarrow \mathbb{R}^d$ such that $h \circ f^t = g^t \circ h,$ for every $t \in \mathbb{R}$ . Attempt: My initial idea was to exhibit a linear isomorphism that conjugates $e^{tA}$ and $e^{tB}$ , because we know that such flows are linearly conjugate if and only if $A$ and $B$ are similar, therefore have the same eigenvalues. I also tried to prove that such flows are $C^1$ -conjugate, but did not succeed. Any help would be appreciated!","['ordinary-differential-equations', 'dynamical-systems']"
3780538,"Different approaches in evaluating the limit $\frac{(x^3+y^3)}{(x^2-y^2)}$ when $(x,y)\to(0,0)$.","Note that this question has been previously asked here . I understood the solutions available there but I have two different approaches to this problem, I'm not sure whether they are correct. I need to know whether both of these solutions are correct and complete. If not, why are they incorrect? Approach 1 Take path 1 as $y=3x$ , hence limit goes to $0$ . Take path 2 as $y=(-x^3+x^2-y^2)^{1/3}$ , hence limit goes to $1$ . Therefore, the limit does not exist. Is the second path a valid path cause $y$ is not necessarily $0$ when $x=0$ ? Approach 2 Take $x=r\cos\theta$ and $y=r\sin\theta$ . We have $r\frac{\cos^3\theta+\sin^3\theta}{\cos^2\theta-\sin^2\theta}$ . Take path $r = \cos^2\theta-\sin^2\theta$ hence limit goes to $\cos^3\theta+\sin^3\theta$ which is different for every $\theta$ and hence limit cannot exist. Is this choice of $r$ allowed?","['multivariable-calculus', 'limits', 'calculus', 'real-analysis']"
3780556,Probability of Getting a Red Ball,"I have a simple and straightforward question. A box contains $n$ balls, of which $r$ are red ( $r$ and $n$ are both positive integers, and $r \leq n$ ; suppose further that $n$ is even). Consider what happens when the balls are drawn from the box one at a time, at random without replacement. Determine: $\quad$ (a) The probability that the first ball drawn will be red; $\quad$ (b) The probability that the $\left(\frac{n}{2}\right)^{\text{th}}$ ball drawn will be red; $\quad$ (c) the probability that the last ball drawn will be red. I'm not sure how to approach questions (b) and (c) . I understand that (a) is $\frac rn$ because the probability of the very first ball being red is the ratio of all the red balls over the total number of balls, but I don't know how to extend this idea to the $i^{\, \text{th}}$ ball. Thank you for your time.",['probability']
3780571,Possibly a variation of the increment theorem for functions of multiple variables,"Suppose that $F:\mathbb R^n\to\mathbb R$ is $C^\infty$ . I'd like to prove that $\forall a=(a_1,\ldots,a_n)\in\mathbb R^n$ , there exist $C^\infty$ functions $G_i,i=1\ldots,n,$ such that $\forall x=(x_1,\ldots,x_n)\in\mathbb R^n$ , we have $$F(x)=F(a)+\sum_{i=1}^n(x_i-a_i)G_i(x).$$ In fact, we have $$G_i(a)=\frac{\partial F}{\partial x_i}(a)$$ for all $i$ . This theorem is quoted in the appendix to my physics textbook, but I'm not sure about its legitimacy. According to my experience in the calculus course, the change in the value of $F$ from $a$ to $x$ should take the form $$\Delta F=\sum_{i=1}^n[(x_i-a_i)\frac{\partial F}{\partial x_i}(a)+\epsilon_i(x_i-a_i)],$$ where each $\epsilon_i$ goes to zero as all $x_i-a_i$ tend to zero. Are these two statements consistent with each other? Thank you.","['multivariable-calculus', 'calculus', 'real-analysis']"
3780573,counting words with a condition,"Suppose we are given a sequence $x_1x_2x_3x_4x_5x_6$ where the $x_i$ are digits 0 to 9, and we want to know how many of them do we have that satisfy $x_1<x_2<x_3<x_4<x_5<x_6$ ? $discussion:$ Notice that $x_1$ can only be a number betwwen $0$ to $4$ so if $x_1=0$ , then we reduce our problem to count number of strings $x_2<x_3<x_4<x_5<x_6$ where $x_i$ are digits $\geq 1$ . And here notice that $x_2$ must be between $1$ and $5$ . So, If $x_2 = 1$ now we have another subproblem... in this counting those that satisfy $x_3<x_4<x_5<x_6$ and now $x_3$ must be between $2$ and $6$ and so if you let $x_3=2$ then $x_4$ can be betwwen $3$ and $7$ and we see that each time we have $4$ choices for the $x_i$ So, we see that there $4 \times 4 \times ... \times 4 = \boxed{4^6}$ such sequences. Now, my question, in general, if we have sequence $x_1x_2...x_n$ there are ${\bf no}$ sequences that satisfy $x_1<x_2 < ... <x_n$ but if $n=9$ say, then we only have $1^9$ choices. if $n=8$ , then we have $2^8$ choices. If $n=7$ , we have $3^7$ choices. if $n=6$ , we have $4^6$ choices and so on... Is this a correct generalization?","['polya-counting-theory', 'combinatorics']"
3780579,Changing limit and derivative operator,"I was trying to solve the following problem: Let $f:\mathbb R\rightarrow \mathbb R$ be a differentiable function such that $\lim_{x \to \infty} f(x)=1$ and $\lim_{x \to \infty}f'(x)=a$ . Then find the value of $a$ . My brother who is not a pure math student suggested that take derivative on first equation you will get $a=0$ .
I am not sure whether we can do that or not. Can we do that? I don't think it's the correct way of solving this.","['limits', 'derivatives', 'real-analysis']"
3780603,Find the minimum positive integer $n$ and the matrix $A^{2020}$,"Let $A=a\begin{pmatrix} 1 & -1\\
1 & 1 \end{pmatrix}$ $(a>0)$ and $I=\begin{pmatrix} 1 & 0\\
0 & 1 \end{pmatrix}$ satisfy $A^4+I=\begin{pmatrix} 0 & 0\\
0 & 0 \end{pmatrix}$ Find $a$ For this I can do. I saw $a=\frac{1}{\sqrt{2}}$ Find the minimum positive integer $n$ such that $A^n\begin{pmatrix} 0\\ 1 \end{pmatrix}= \begin{pmatrix} 1\\ 0 \end{pmatrix}$ Find $A^{2020}$ So please help to tell me about this 2 and 3. Give me some hints or ideas!!",['matrices']
3780665,Existence of 8-fold symmetric domains in higher dimensions,"Let a nonempty set $A \subset \mathbb{R}^N$ (with $N \geq 3$ ) be bounded, open, and connected. (Preferably, the boundary of $A$ has some reasonable smoothness, say, Lipschitz.)
Suppose that $A$ is neither a ball nor a spherical shell. Can such $A$ be 8-fold rotationally symmetric with respect to any pair of coordinate vectors $x_i$ and $x_j$ ? Notice that in the case $N=2$ this is evidently true.
Moreover, the answer would be also affirmative for any dimension if the assumption that $A$ is open and connected is dropped, see an explanation here .
On the other hand, under the imposed assumptions, it seems to me that in the case $N=3$ the existence of such $A$ is not possible. See also a related question .","['group-theory', 'symmetry', 'geometry', 'rotations']"
3780669,Equivalent definition of Cohen-Macaulay Ring,"We suppose all rings are commutative and unital. The most general defition for Cohen-Macaulayness goes as follows: A Noetherian local ring $R$ is $\textit{Cohen-Macaulay}$ if its depth is equal to its Krull dimenion. More generally  a ring is called Cohen–Macaulay if it is Noetherian and all of its localizations at prime ideals are Cohen–Macaulay. In Richard Kane's 'Reflection Groups and Invariant Theory', the definition of Cohen-Macaulay is given as: Let $A$ be an algebra over $k$ , the ring structure on $A$ is Cohen-Macaulay if there exists a polynomial subalgebra $k[a_1,a_2,\ldots,a_n]$ such that $A$ is free and finite over $k[a_1,a_2,\ldots,a_n]$ , where $a_1,a_2,\ldots,a_n \in A$ , in algebraic terms we can choose elements $b_1,\ldots,b_m \in A$ such that $$A = \bigoplus_{i=1}^mk[a_1,a_2,\ldots,a_n]b_i ,$$ then let $G$ be a finite group and $V$ be a linear representation of $G$ , then the algebra of invariants $S(V^*)^G$ is Cohen-Macaulay, this is the Hochster-Roberts theorem. https://en.wikipedia.org/wiki/Hochster%E2%80%93Roberts_theorem Can someone enlighten me as how these two definitions are equivalent?","['algebraic-geometry', 'commutative-algebra']"
3780677,Does a singular Jacobian matrix imply functional dependence?,"I often find the following ""fact"" mentioned in engineering mathematics texts and videos: If $f_1,...,f_n$ are $C^1$ functions from $\mathbb{R}^n$ to $\mathbb{R}$ such that the Jacobian matrix of the map $(f_1,...,f_n)$ vanishes everywhere, then the $f_i$ 's must be functionally related. They seem to use the following definition of functionally related : There is some $C^1$ function $\phi:\mathbb{R}^n \rightarrow\mathbb{R}$ such that $\nabla\phi$ is nonzero everywhere, and $\phi(f_1,...,f_n)=0$ everywhere. It is easy to see (using chain rule and some elementary linear algebra) why this definition of functionally related would lead to the Jacobian being singular everywhere. But what intrigues me is the converse claim. I am unable to come up with a rigorous proof or a counterexample.  All the multivariable calculus books I have seen so far are silent on this point. Any helpful pointer would be greatly appreciated.","['jacobian', 'multivariable-calculus']"
3780693,Decomposition of doubly stochastic matrices,"Suppose $A$ is a doubly stochastic matrix, that is each row and column have the sum of their entries as $1$ and the entries are all nonnegative. Now, suppose $A=BC$ where $B$ is idempotent and $C$ is unitary. Then, it is easy to see that $B$ and $C$ have the row and column sum of entries in each row and/ or column as $1$ . But, does this also imply that $B, C$ are also doubly stochastic? Any hints? Thanks beforehand.","['matrices', 'linear-algebra', 'stochastic-matrices']"
3780699,"If $f(x) + f'(x) + f''(x) \to A$ as $x \to \infty$, then show that $f(x) \to A$ as $x \to \infty$","This problem is an extension to the simpler problem which deals with $f(x) + f'(x) \to A$ as $x \to \infty$ (see problem 2 on my blog ). If $f$ is twice continuously differentiable in some interval $(a, \infty)$ and $f(x) + f'(x) + f''(x) \to A$ as $x \to \infty$ then show that $f(x) \to A$ as $x \to \infty$. However, the approach based on considering sign of $f'(x)$ for large $x$ (which applies to the simpler problem in the blog) does not seem to apply here. Any hints on this problem? I believe that a similar generalization concerning expression $\sum\limits_{k = 0}^{n}f^{(k)}(x) \to A$ is also true, but I don't have a clue to prove the general result.","['ordinary-differential-equations', 'real-analysis', 'calculus', 'limits', 'convergence-divergence']"
3780716,Show that the determinant of a matrix is nonzero [duplicate],"This question already has answers here : Show determinant of matrix is non-zero (5 answers) Closed 3 years ago . Suppose $u,v,w \in \mathbb{Q}$ with $u,v,w \neq 0$ . Show that the
determinant of the following matrix is nonzero. $$M = \begin{bmatrix} u & 2w & 2v \\ v & u & 2w \\ w & v & u \end{bmatrix}$$ Hint: Argue by contradiction, reduce to the case when $u,v,w$ are integers and use some number theory over $\mathbb{Z}$ . I know that the determinant is given by $$ \det M = u^{3} + 2v^{3} + 4w^{3} - 6 \,u\,v\,w $$ It is unclear to me how to utilize the hint. How to convert the problem over $\mathbb{Z}$ ?","['matrices', 'number-theory', 'determinant']"
3780725,Topology question about a special subset in $\mathbb R^2$,"Problem Statement: Let $X = (\bigcup \limits_{n \in \mathbb N} \{\frac{1}{n}\} \times [0,1] ) \cup \{(0,0),(0,1)\}$ have a subspace topology as a subspace of $\mathbb R^2$ . For any separation $U$ and $V$ of $X$ , if $(0, 0) \in U$ , then $(0, 1) \in U$ as well. My attempt: By the result from Munkres, if $U$ and $V$ are a separation of $X$ and $Y$ is a connected subspace of $X$ , then $Y$ is completely contained in either $U$ or $V$ . Hence, to show that $(0, 0) \in U$ would imply $(0, 1) \in U$ , it suffices to show that there exists some connected subspace of $X$ that contains both $(0, 0)$ and $(0, 1)$ . From here, I am having trouble finding some connected subspace of $X$ that contains both points.","['connectedness', 'general-topology', 'real-analysis']"
3780732,Evaluate $\lim_{h\to 0}\frac{1}{h^2}\begin{vmatrix}\tan x&\tan(x+h)&\tan(x+2h)\\\tan(x+2h)&\tan x&\tan(x+h)\\\tan(x+h)&\tan(x+2h)&\tan x\end{vmatrix}$,"Evaluate $$
\lim_{h\to 0}\frac{\Delta}{h^2}=\lim_{h\to 0}\frac{1}{h^2}\begin{vmatrix}
\tan x&\tan(x+h)&\tan(x+2h)\\
\tan(x+2h)&\tan x&\tan(x+h)\\
\tan(x+h)&\tan(x+2h)&\tan x
\end{vmatrix}
$$ Attempt $$
\lim_{h\to 0}\frac{\Delta}{h^2}=\begin{vmatrix}
\lim_{h\to 0}\tan x&\lim_{h\to 0}\dfrac{\tan(x+h)-\tan x}{h}&\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan(x+h)}{h}\\
\lim_{h\to 0}\tan(x+2h)&\lim_{h\to 0}\dfrac{\tan x-\tan(x+2h)}{h}&\lim_{h\to 0}\dfrac{\tan(x+h)-\tan(x+2h)}{h}\\
\lim_{h\to 0}\tan(x+h)&\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan(x+h)}{h}&\lim_{h\to 0}\dfrac{\tan x-\tan(x+2h)}{h}
\end{vmatrix}\\
=\begin{vmatrix}
\lim_{h\to 0}\tan x&\lim_{h\to 0}\dfrac{\tan(x+h)-\tan x}{h}&\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan(x+h)}{h}\\
\lim_{h\to 0}\tan(x+2h)&-2.\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan x}{h}&-1.\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan(x+h)}{h}\\
\lim_{h\to 0}\tan(x+h)&\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan(x+h)}{h}&-2.\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan x}{2h}
\end{vmatrix}\\
$$ $$
\lim_{h\to 0}\dfrac{\tan(x+h)-\tan x}{h}=\frac{d}{dx}\tan x=\sec^2x\\
\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan x}{2h}=\frac{d}{dx}\tan x=\sec^2x\\
\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan(x+h)}{h}=\frac{d}{dx}\tan(x+h)=\sec^2(x+h)
$$ But my reference gives the solution $9\tan x.\sec^4x$ , I think by taking $\lim_{h\to 0}\dfrac{\tan(x+2h)-\tan(x+h)}{h}=\sec^2x$ . Will that make a difference ? It might be silly but could anyone clarify this confusion in my attempt ?","['determinant', 'matrices', 'limits', 'trigonometry', 'derivatives']"
3780756,"Counting the number of non-negative solutions of the equation $a_1+a_2+a_3+...+a_n=n,\ 0\leq a_i \leq i,\ 1\leq i \leq n-1 $","I am trying to count of the number of non-negative integer solution of the equation $$a_1+a_2+a_3+...+a_n=n$$ with the constraint $0\leq a_i \leq i,\ 1\leq i \leq n-1.$ I guess we can use combinations with repetition. Is that a known problem? Is there a recurrence for this problem or closed-form formula?","['combinations', 'combinatorics', 'recurrence-relations']"
3780784,Tiling the plane with non-similar triangles with restictions,"Recently I stumbled upon this question Similar Triangles in Tiling a Plane , and I considered the same problem after imposing some restrictions. In particular I considered the following cases. Find a triangular tiling of the plane where no triangle is similar to another one, and each triangle is rational-sided . Sketch of the proof: we start by tiling the plane with $3-4-5$ right-triangles and then it is possible to split each right-triangle into two rational-sided triangles in infinitely many different ways. Find a triangular tiling of the plane where no triangle is similar to another one, and each triangle is integer-sided . Here I feel quite lost. Any idea? Does this kind of triangular tiling exist?","['triangulation', 'combinatorial-geometry', 'geometry', 'tiling']"
3780839,Groups of order $252 = 4 \cdot 7 \cdot 9$ are solvable,"The goal is to prove that any group of order $252 = 36 \cdot 7$ is solvable, and because I managed to confuse myself, I'm asking here. Let $G$ be a group of order $252$ . By Sylow's Theorems, the number of $7$ -Sylow subgroups of $G$ is either $1$ or $36$ . If it is $1$ , we are done, because the quotient then has order $36$ , and groups of order $7$ and $36$ are solvable. Hence we are left with the much more interesting case in which the number of $7$ -Sylow subgroups is $36$ . One proof to show solvability is the following: By the orbit-stabilizer theorem (since $G$ acts transitively on the set of its $7$ -Sylow subgroups), the normalizer $N_G(P)$ of a $7$ -Sylow $P$ of $G$ has order $7$ , hence $$N_G(P) = Z_G(P) = P,$$ where $Z_G(P)$ is the centralizer of $P$ . By Burnside's Transfer Theorem , we obtain that $G$ contains a normal subgroup $N$ of order $36$ . Since $|G/N| = 7$ , we are done. Questions to the second case (number of $7$ -Sylows is $36$ ): I checked with GAP and saw that there is no group of order $252$ , whose $7$ -Sylow is not normal. Is there an easy way to see this without invoking a computer algebra system? Can one prove in a more elementary way that there is a normal subgroup of order $36$ ? Indeed, there are exactly $36 \cdot 6$ elements of order $7$ , thus there are $36$ elements, whose order is coprime to $7$ . How does one see that these $36$ elements form a subgroup? If we could see that in an elementary way, there is of course a unique subgroup of order $36$ , hence a normal one, and there is no need to invoke Burnside's Transfer Theorem.","['group-theory', 'sylow-theory', 'finite-groups', 'solvable-groups']"
3780895,"If $|f'(c)|<M$, prove $|\int_{0}^{1}f(x)dx-1/n \sum_{k=0}^{n-1}f(x/n)|<M/n$ [duplicate]","This question already has an answer here : $f$ is differentiable in $[0,1]$ ,$\sup_{x\in[0,1]}|f'(x)| \le M\lt+\infty $ (1 answer) Closed 3 years ago . We have a derivative function $f$ with for every $c$ element of $\mathbb{R}: |f'(c)|<M$ . I tried to prove that
prove that $\displaystyle \left|\int_{0}^{1}f(x)\mathrm{d}x-\frac{1}n \sum_{k=0}^{n-1}f\left(\frac{x}n\right)\right|\leq\frac{M}{n}$ . I really have no idea how to start. I'm trying to use integral , derivative, sums ... so my paper is full of definitions but i can't use one. Can someone give me a hint how to start with this question so that i can move on. I'm really sorry i can't give a proper prove that i have already found but i'm stuck at the beginnin already.","['integration', 'summation', 'real-analysis', 'calculus', 'derivatives']"
3780938,a subset of $l_2$.,"the exercise is: show that the set $A=\{x=(x_n)\subset l_2: \sum(1+\frac{1}{i})x_i^2)\leq 1\}$ doesn't contain an element with norm equal to $\sup\{\|x\|_2,x\in A\}$ . My attempt: i showed that $\forall x\in A, \|x\|_2^2=\sum x_i^2< \sum x_i^2+\frac{x_i^2}{i}\leq 1$ . And $\sup_{x\in A} \|x\|=1$ . Using that $l_2$ is a Hilbert space, is there a way to show that, supposing that exists an element that there is norm equal to $\sup\{\|x\|_2,x\in A\}$ , find some contradiction?  This exercise i found at functional analysis and infinite-dimensional geometry- Marián Fabian.","['hilbert-spaces', 'functional-analysis']"
3780950,Square equal to sum of three squares [duplicate],"This question already has answers here : Pythagorean Quadruples: (2 answers) Closed 3 years ago . For which integers $n$ there exists integers $0\le a,b,c < n$ such that $n^2=a^2+b^2+c^2$ ? I made the following observations: For $n=1$ and $n=0$ those integers doesn't exist. If $n$ is a power of 2 those integers doesn't exist. Let $n=2^m$ with $m>0$ the smallest power of 2 for which there exists $a,b,c$ such that $\left (2^m\right )^2=4^m=a^2+b^2+c^2$ . Since $4^m$ is divisible by 4, $a^2+b^2+c^2$ has to be divisible by 4 too. This is only possible if $a^2\equiv b^2\equiv c^2\equiv 0\pmod 4$ , so we can write $a=2a',b=2b',c=2c'$ with $a',b',c'\in \mathbb{N}$ . But then we get $\left (2^{m-1}\right )^2=4^{m-1}=a'^2+b'^2+c'^2$ , so $m=1$ , otherwise $2^m$ wouldn't be the smallest power of two with this property. It is easy to check that $n=2$ doesn't work, so for $n=2^m$ the statement doesn't hold. I suspect (but can't prove) that for all other values the statement holds. It would be enough to prove that for all odd primes $p$ there exists $a,b,c$ such that $p^2=a^2+b^2+c^2$ , since for all other values of $n$ there exist some $p,m$ such that $n=pm$ . Then we get $n^2=(pm)^2=(ma)^2+(mb)^2+(mc)^2$ .","['number-theory', 'square-numbers']"
3780959,How to efficiently sample edges from a graph in relation to its spanning tree,"Consider a connected, unweighted, undirected graph $G$ . Let $m$ be the number of edges and $n$ be the number of nodes. Now consider the following random process. First sample a uniformly random spanning tree of $G$ and then pick an edge from this spanning tree uniformly at random. Our process returns the edge. If I want to sample many edges from $G$ from the probability distribution implied by this process, is there a more efficient  (in terms of computational complexity) method than sampling a new random spanning tree each time?","['graph-theory', 'probability', 'algorithms']"
3780987,Counting the number of integers with given restrictions,"Question: Consider the numbers $1$ through $99,999$ in their ordinary decimal representations. How many contain exactly one of each of the digits $2, 3, 4, 5$ ? Answer: $720$ . Attempt at deriving the answer: We have two cases: four digit numbers and five digit numbers. Five digit numbers: Let $x \in \{2, 3, 4, 5\}$ . If the first position in a five digit number is not $x$ , then there are $5$ possibilities for this position as there are four values for $x$ and $0$ is inadmissable. The rest of the four positions will have the various permutations of four values of $x$ . There are $5 \times 4!$ such numbers. If the non- $x$ value is in the second position, then there are $4$ ways to choose an $x$ -value for the first position, $6$ integers for the second position and $3!$ permutations for the rest of the positions. There are $4\times 6 \times 3!$ such numbers. If the non- $x$ value is in the third position, then there are $\binom 42$ ways to choose two $x$ -values, $2!$ ways to permute them and $6$ integers for the third position meaning there are $6 \times 2 \times 6$ such numbers. When the non- $x$ value is in the fourth position, there are $4 \times 3! \times 6$ such numbers. Finally, if non- $x$ is in the fifth position, there are $4! \times 6$ such numbers. Four digit numbers: We just need to permute the number $2345$ . There are $4!$ such permutations. Thus the number of numbers with the given restrictions is $5\times 4! + 4\times 3!\times 6 + 2\times 6 \times 6 + 4 \times 3! \times 6 + 6 \times 4! + 4! = 648$ . What did I forget to take into account? Thanks.","['combinatorics', 'discrete-mathematics']"
3780992,"I heard there are 48 regular polyhedrons. With what Jan Misali calls regular polyhedrons, are there any more?","I heard there are 48 regular polyhedrons. With what Jan Misali calls regular polyhedrons, are there any more? Assumptions: A polyhedron must lie in 3D Euclidean space. It must be a single connected shape. It's invalid for two vertices edges or faces to have the exact same location while remaining distinct. If there are only 48 polyhedrons, what about 4D polytopes? Watch this video if this info isn't full enough here: https://www.youtube.com/watch?v=_hjRvZYkAgA","['euclidean-geometry', 'geometry']"
3781004,Change integration variable from scalar to matrix,"Suppose $c$ is a scalar, $\mathbf{A}$ is a symmetric positive definite matrix and $g(.)$ is some real-valued function. Define $\mathbf{B} = c \, \mathbf{A}$ . In this integral, $$
\int_{-\infty}^{\infty} g(c) \; det(c \, \mathbf{A}) \; dc = \int ? d\mathbf{B},
$$ how do I change the integration variable to $\mathbf{B}$ ?","['integration', 'substitution', 'matrix-calculus', 'matrices']"
3781030,Lower bound on the rank of a 0-1 matrix: $\mathrm {rank}_\mathbb R(A)\cdot |A|\geq n^2$,"Let $A$ be a square matrix of size $n \times n$ whose entries are all $0$ or $1$ , and its diagonal entries are all $1$ . Denote the total number of $1$ s in the matrix by $|A|$ . So $|A|$ is the sum of all entries. I want to prove the following lower bound on the rank of $A$ over the reals. $$\mathrm {rank}_\mathbb R(A)\cdot |A|\geq n^2.$$ Thoughts. If $A$ is the identity matrix or the all-ones matrix then we get equality. An equivalent interpretation: start with the identity matrix and then try to add more $1$ s efficiently to reduce the rank. The claim is that to reduce the rank by $k$ we must add at least $$\frac {n^2}{n-k}-n = \frac{kn}{n-k}$$ new $1$ s. For small $k$ this can be verified manually. The claim is that the geomtric mean of the rank and the sum is at least $n$ . If we replace the geometric mean by arithmetic mean, meaning $\mathrm {rank}_\mathbb R(A) + |A|\geq 2n$ , then the claim is immediate from the preceding interpretation, because adding $1$ somewhere can reduce the rank by at most $1$ .","['matrix-rank', 'matrices', 'linear-algebra', 'combinatorics', 'inequality']"
3781049,Determine $\sqrt{1+50\cdot51\cdot52\cdot53}$ without a calculator?,"I've tried a lot of things but failed to do it, I've calculated the result inside the square root which is $7027801$ using substitution and factoring but $\sqrt{7027801}$ isn't possible to simplify.","['algebra-precalculus', 'factoring']"
3781071,"Showing $\Gamma = \{(x,y) \in \mathbb{R}^d \times \mathbb{R}: y = f(x)\}$ is measurablle and of measure 0, when $f$ is a measurable function.","Exercise 2.7 (Stein): If $\Gamma \subset \mathbb{R}^d \times \mathbb{R},$ $\Gamma = \{(x,y) \in \mathbb{R}^d \times \mathbb{R}: y = f(x)\}$ , and assume $f$ is measurable on $\mathbb{R}^d$ . Show that $\Gamma$ is a measurable subset of $\mathbb{R}^{d+1}$ and $m(\Gamma) = 0$ . Where my intuition leads me: I know how to show $m(\Gamma) = 0$ if $\Gamma$ is measurable (I think). Essentially we need to slice (and dice, I haven't eaten yet) up $\Gamma$ into a bunch of smaller sets for arbitrary fixed $x \in \mathbb{R}^d$ : \begin{equation*}
\Gamma_x := \{y \in \mathbb{R}: (x,y) \in \Gamma\} = \{f(x)\}.
\end{equation*} It's clear that the measure of a singleton is zero, and thus \begin{equation*}
m(\Gamma) = \int_{\mathbb{R}^d}m(\Gamma_x)dx = 0.
\end{equation*} Remark: This is ensured from a previous Corollary that says we can do this for almost every $x \in \mathbb{R}^d \times \mathbb{R}$ given that $\Gamma \subset \mathbb{R}^d \times \mathbb{R}$ is measurable. Now, I'm kind of stuck on proving that $\Gamma$ is measurable. I'm thinking that I should use some variant of the following Corollary Corollary 2.3.8 : Suppose $f(x)$ is a non-negative function on $\mathbb{R}^d$ , and let \begin{equation*}
A = \{(x,y) \in \mathbb{R}^d \times \mathbb{R}: 0 \leq y \leq f(x)\}
\end{equation*} Then $f$ is measurable on $\mathbb{R}^d$ IFF $A$ is measurable in $\mathbb{R}^{d+1}$ . I imagine I'd have to formulate some sequence \begin{equation*}
E_n := \biggr\{(x,y) \in \mathbb{R}^d \times \mathbb{R}: f(x) - \frac{1}{n} \leq y \leq f(x)\biggr\},
\end{equation*} which converges to $\Gamma$ , and prove each member of this sequence is measurable. My idea is that since $f$ is measurable on $\mathbb{R}^d$ (suffices to assume that it is non-negative), then we know that \begin{equation*}
F(x,y) = y - f(x).
\end{equation*} Now, $F$ is measurable on $\mathbb{R}^{d+1}$ , and $E_n = \{y \geq f(x) - \frac{1}{n}\} \cap \{F \leq 0\}$ . Measurability follows. Is this the right track for proving measurability of $\Gamma$ ? I feel a little shaky on the introduction of $F(x,y)$ as being a valid procedure (I'm basing this off of the proof of the Corollary I'm trying to alter)","['measurable-sets', 'measure-theory', 'measurable-functions']"
3781089,Banach space of continuous and discontinuous functions on R,"The set $C(\mathbb{R})$ of bounded continuous functions on $\mathbb{R}$ is a Banach space when equipped with the sup norm. In my understanding, it just follows from the fact that a Cauchy sequence of continuous functions converges uniformly to a continuous function. How about the set, which I will denote $C_{\rm{d}}(\mathbb{R})$ , of bounded functions, which are continuous except at $x=0$ , where a jump discontinuity is allowed, i.e. $\displaystyle{\lim_{x\rightarrow 0^\pm}f(x)=f^\pm}$ both exist. Is that a Banach space under the sup norm? It seems like yes, since I can apply the Cauchy argument to both intervals $(-\infty,0]$ and $[0,\infty)$ and conclude that a Cauchy sequence on $C_{\rm{d}}(\mathbb{R})$ will uniformly limit to a function, which is continuous on both intervals individually. Am I right or completely wrong? If I am right, is there a name for such a space?","['banach-spaces', 'complete-spaces', 'cauchy-sequences', 'real-analysis', 'functional-analysis']"
3781096,Matrix multiplied by its pseudo-inverse doesn't give the identity matrix. Why?,"Using Matlab, I randomly generate matrix $A \in \Bbb C^{2 \times 1}$ and compute its pseudo-inverse $A^{+}$ . I notice that $AA^{+} \neq I$ , and yet $\mbox{Tr}(AA^{+}) = 1$ . For other sizes it seems like the trace is equal to the smaller dimension of $A$ . I couldn't find this property explained. Could anyone help me understand these two facts?","['trace', 'matrices', 'pseudoinverse', 'linear-algebra', 'inverse']"
3781115,At which points is this complex function differentiable,"I'm making an exercise about the derivative. I needed to prove that $f(x)=|x|$ isn't differentiable at zero. Now I was wondering if we had a function $f:\mathbb{C} \to \mathbb{C} :z \to |z|$ so a complex function, in which points is this $f$ differentiable. If we say $z=a+bi$ , for $a=b=0$ it's not differentiable and for $a$ not equal to zero and $b=0$ it's differentiable (I think) but are there other problematic points for this function?",['derivatives']
3781121,derived map from short exact sequence,"Given an short exact sequence of (coherent) sheaves $0 \to A \xrightarrow f B \xrightarrow g B \to 0$ , on a (smooth) projective variety $X$ over an algebraically closed field $k$ , one can build a long exact sequence of cohomology groups (that turn out to be just vector spaces in this case) $0 \to H^0(X,A) \xrightarrow{\Gamma(f)} H^0(X,B)\xrightarrow{\Gamma(g)} H^0(X,C)\xrightarrow{\delta} H^1(X,A) \xrightarrow{R^1\Gamma(f)} H^1(X,B)\xrightarrow{R^1\Gamma(g)} H^1(X,B) \to \cdots$ where $\delta$ is a $\delta$ fuctor (see Hartshorne's Algebraic Geometry book, Chapter III) $\Gamma$ is the global section functor and $R^i(f)$ is the $i$ -th derived of $f$ . I would like to know if there is a effective method to compute the $\delta$ functor and $R^i(f)$ (or $R^i(f)$ for some specific cases, for instance when $A,B$ and $C$ are sums of line bundles (hence the maps $f$ and $g$ are just matrices with polynomial entries). For instante, let $X = \mathbb{P}^n$ and fix an hyperplane $H \subset \mathbb{P}^n$ we have the restriction sequence: $$0 \to \mathcal{O}_{\mathbb{P}^n}(-1) \xrightarrow{\times H} \mathcal{O}_{\mathbb{P}^n} \to \mathcal{O}_{\mathbb{P}^n}\otimes \mathcal{O}_{H} \to 0$$ Hartshorne says (page 227) that we have the following: $$H^{n-1}(\mathbb{P}^n, \mathcal{O}_{\mathbb{P}^n}\otimes \mathcal{O}_{H}) \xrightarrow{\delta} H^n(\mathbb{P}^n, \mathcal{O}_{\mathbb{P}^n}(-1))\xrightarrow{\times H} H^n(\mathbb{P}^n, \mathcal{O}_{\mathbb{P}^n})\to 0$$ and that $\delta$ is the ""division"" by $H$ . I would like to understand why is that. Thank you in advance. PS: I known that having the matrices $f$ and $g$ for the case where the sheaves are sums of line bundles, I can compute the matrix of the maps in the vector spaces, but I am looking for a more insightfull way to do it.","['vector-bundles', 'algebraic-geometry', 'sheaf-cohomology']"
3781126,Reference for the multiprojective Nullstellensatz?,"Crossposted at MO. I'm looking for a reference to a generalization of Hilbert's Nullstellensatz to the multiprojective setting. This seems to be a basic fact but I'm having trouble finding a statement online or in the literature. Consider the product $$\mathbb P=\mathbb P(\mathbb C^{n_1})\times\dots\times \mathbb P(\mathbb C^{n_k}).$$ Let $R$ be the ring of polynomials in variables $X_i^j$ with $j\in[1,k]$ and $i\in[1,n_j]$ . Let $I\subset R$ be a multihomogeneous ideal meaning that $I$ is homogeneous with respect to degree in the variables $X_1^j,\dots,X_{n_j}^j$ for every $j$ . Then $I$ is seen to define a subset $V(I)\subset\mathbb P$ of points in which all $p\in I$ vanish. Question: where in the literature can I find a necessary and sufficient condition for $I$ to contain all polynomials vanishing on $V(I)$ ? (Preferably in a standard reference such as Hartshorne.) (I suspect that the condition is that $I$ is a) multihomogeneous, b) radical and c) saturated with respect to the irrelevant ideals $\langle X_1^j,\dots,X_{n_j}^j\rangle$ for all $j$ . I think I know how this can be proved but I'm looking for a precise reference.)","['algebraic-geometry', 'reference-request']"
3781135,A question from Halmos' Naive Set Theory,"I'm on Section 10, Inverses and Composites . On page 41, Halmos considers a relation $R$ on a set $X$ and the relation of equality $I$ on $X$ . He then asks the reader whether there is some connection among $I$ , $R\circ R^{-1}$ , and $R^{-1}\circ R$ ? I can't think of any such connection. And the example (see below) I've constructed makes me believe that there isn't any. Am I correct? My example: Consider $R$ on $X=\{0, 1, 2\}$ defined by $R:=\{(0, 1), (1, 2), (0, 2)\}$ . Then $I=\{(0, 0), (1,1), (2,2)\}$ , $R\circ R^{-1} = \{(1, 1), (1, 2), (2, 2), (2,1)\}$ , and $R^{-1}\circ R=\{(0,0), (1, 1), (1, 0), (0, 1)\}$ . I don't see any obvious connection among $I$ , $R\circ R^{-1}$ , and $R^{-1}\circ R$ . For a relation $R$ , Halmos defines the relation $R^{-1}$ as $\forall x, y(yR^{-1}x\iff xRy)$ . For relations $R\subset X\times Y$ and $S\subset Y\times Z$ , Halmos defines $S\circ R$ as $\forall x,z\Big((x,z)\in S\circ R\iff x\in X\wedge z\in Z\wedge\exists y\in Y\big((x, y)\in R\wedge (y, z)\in S)\big)\Big)$ .",['elementary-set-theory']
3781178,Restart mathematics,I am 73 yo who has not been to a math class for 50 years. I know there is a completely new mind set needed to approach math problems and I need a starting point. What is the best Algebra book available to start my journey back?,"['algebra-precalculus', 'advice', 'book-recommendation', 'reference-request']"
3781184,"Show that the set of linear hyperbolic vector fields with $\dim E^{s} = k $ is open in $ \mathcal{L} (\mathbb {R}^{d}, \mathbb {R} ^ {d }) $.","Show that for $k = 1, \ldots, d$ , the set of hyperbolic linear vector fields with $\dim  E^{s} = k$ is open in $\mathcal{L}(\mathbb{R}^{d},\mathbb{R}^{d})$ . Definition $A\colon \mathbb{R}^{d} \longrightarrow  \mathbb{R}^{d}$ is linear hyperbolic if all its eigenvalues ​​have non-zero real part. If $A\colon \mathbb{R}^{d} \longrightarrow  \mathbb{R}^{d}$ is a linear hyperbolic field, then there is a direct sum decomposition $ \mathbb{R}^{d} = E^{s} \oplus E^{u}$ satisfying: the eigenvalues ​​of $A \vert E^{s}$ are the eigenvalues ​​of $A$ whose real part is negative. the eigenvalues ​​of $A \vert E^{u}$ are the eigenvalues ​​of $A$ whose real part is positive. Attempt: I tried to use the fact that the set of hyperbolic linear vectors is open and dense in $\mathcal{L}(\mathbb{R}^{d},\mathbb{R}^{d})$ , but I was unsuccessful. Any help would be appreciated!","['ordinary-differential-equations', 'dynamical-systems']"
3781197,"How to find $a$, $b$, $c$ such that $P(x)=ax^3+bx^2+cx$ and $P\left(x\right)-P\left(x-1\right)=x^2$","I'm trying to find $a$ , $b$ and $c$ such that $P(x)=ax^3+bx^2+cx$ and $P\left(x\right)-P\left(x-1\right)=x^2$ . After expanding the binomial in $P(x-1)$ , I end up getting $3ax^2-3ax+2bx+a-b=x^2$ . What next? Using $3a = 1$ doesn't work.","['algebra-precalculus', 'polynomials']"
3781200,Prove $\lim_{z \to 0} \frac{z}{\overline{z}}$ doesn't exist using $\varepsilon-\delta$.,"I'm trying to prove that the limit $$
\lim_{z \to 0} \frac{z}{\overline{z}} \quad \qquad z \neq 0
$$ doesn't exist. Up to this point, the only definition of a limit for complex functions I know is as that $\lim_{z \to w} f(z) = L$ if and only if $$
\forall \varepsilon >0, \ \exists \delta >0 \text{ such that if }\lvert z-w \rvert < \delta \implies \lvert f(z)- L\rvert< \varepsilon
$$ So I wanted to solve my problem using only this. I know that I could use paths and show that approaching $0$ in different ways
gives different limits, but since I don't know how to rigorously justify this I chose to avoid it. My idea was to argue by contradiction. So I would assume that the limit existed and that it was equal to some complex number $L$ , and then I would show that this assumption would lead to problems. My attempt The first thing I notice is that I can simplify the function as follows $$
\lim_{z \to 0} \frac{z}{\overline{z}} = \lim_{z \to 0} \frac{z^2}{|z|^2} = \lim_{z \to 0} \frac{\left(re^{i\theta}\right)^2}{r^2}= \lim_{z \to 0} e^{i(2\theta)}
$$ where $\theta = \arg(z)$ is a function of $z$ . Now, since we assume that the limit does exist and that it's equal to $L \in \mathbb{C}$ , we can write $L$ as $$
L = r' e^{i \theta'}
$$ where $r'\ge 0$ (i.e. $r' \nless 0$ ) and $\theta'$ are some fixed real numbers. Since we're assuming that the limit exists, if I choose the value $\varepsilon =1 $ I know there exists a $\delta$ such that $\lvert z-0 \rvert < \delta \implies \lvert e^{i(2\theta)}- L\rvert< \varepsilon$ . If I then choose to analyze the complex number $ z =  \frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)}$ I see that $$
\lvert z -0 \rvert = \Biggl\lvert\frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)} -0 \Biggr\rvert =  \Bigl\lvert\frac{\delta}{2} \Bigr\rvert \cdot \Biggl\lvert e^{i\left(\frac{\theta' + \pi }{2}\right)}\Biggl\lvert = \frac{\delta}{2} < \delta
$$ which means that for $\theta = \arg\left( \frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)}\right)$ it should be the case that $\lvert e^{i(2\theta)}- L\rvert< \varepsilon$ , but here we see that \begin{align}
\Bigl\lvert e^{i(2\theta)} - L\Bigr\rvert &=  \Bigl\lvert  e^{i\left(2\frac{\theta' + \pi }{2}\right)} - r' e^{i\theta}\Bigr\rvert = \Bigl\lvert e^{i\theta'}\left( e^{i\pi}  - r'\right) \Bigl\lvert \\
&= \bigl\lvert e^{i\theta'}\bigl\lvert \cdot \bigl\lvert-\left( 1  + r'\right)\bigl\lvert = 1 + r' \nless 1  = \varepsilon 
\end{align} where we get the contradiction we wanted. The idea of my attempt was that I noticed that the function always outputted numbers on the unit circle, which meant that even though I could find a $z$ really close to $0$ , the output couldn't get as close to some limit $L$ as it wanted since it had to be on the unit circle. I'm not sure if my proof used the contradiction correctly, more specifically, I don't know if my final equation implies that my original assumption was wrong or if I can conclude anything from it at all. I'm also unsure if there's a problem with me choosing a specific $z$ which depends on $\delta$ . Could anyone tell me if my attempt is correct? And if it isn't, could someone tell me how I could make a correct proof? Thank you very much!","['epsilon-delta', 'complex-analysis', 'solution-verification', 'limits', 'complex-numbers']"
3781234,If $N \triangleleft G$ is virtually solvable and $G/N$ is virtually infinite cyclic then $G$ is virtually solvable.,"Let $G$ be a group (finitely generated) and let $N \triangleleft G$ be virtually solvable such that $G/N$ is virtually infinite cyclic. We also assume that $N$ is finitely generated (this assumption was omitted in the first version) We aim to show $G$ is virtually solvable (I need a sanity-check for this proof). I won't fill in the calculations but only show the outline. Since $N$ is virtually solvable we have the following short exact sequence: $$1 \longrightarrow N_0 \longrightarrow N \longrightarrow N/N_0 \longrightarrow 1$$ where $N_0$ is solvable and the quotient is finite. Since $G/N$ is virtually infinite cyclic we have the short exact sequence: $$1 \longrightarrow H/N \longrightarrow G/N \longrightarrow G/H \longrightarrow 1$$ where $H \triangleleft G$ , $H/N$ is infinite cyclic and $G/H$ is finite. Now we have that the below s.e.s splits because $H/N$ is free: $$1 \longrightarrow N \longrightarrow H\longrightarrow H/N \longrightarrow 1$$ Therefore, $H \cong N \rtimes H/N $ where the action of the quotient on $N$ is given by conjugation. Consider this theorem by Hall: We have that $N$ is finitely generated and normal in $G$ , $N_0$ has finite index in $N$ so there is $N_1 \subset N_0$ , $N_1$ normal in $G$ and $[N:N_1] < \infty$ . Thus the index, $[N \rtimes H/N:N_1 \rtimes H/N]$ , is finite (because $[N:N_1]< \infty$ - is this accurate?). Using the above theorem again, and with the observation that $N \rtimes H/N$ is finitely generated there is a subgroup $L \subset N_1 \rtimes H/N$ which is normal in $N \rtimes H/N$ and has finite index. Finally, $N_1 \rtimes H/N$ is solvable because $[N_1 \rtimes H/N, N_1 \rtimes H/N] \subset [N_1,1] \cong N_1$ which is solvable, hence $L$ is solvable and of finite index in $H$ , and normal in $G$ . Hence $G$ is virtually solvable. Please correct me if something is off, thanks :)","['group-extensions', 'abstract-algebra', 'free-groups', 'group-theory', 'solvable-groups']"
3781254,"Show that $A\in \mathcal{L}(\mathbb{R}^{d},\mathbb{R}^{d})$ is hyperbolic.","If a linear flow $(e^{tA})_{t}$ is topologically conjugated to any linear flow $(e^{tB})_{t}$ with $B$ close to $A$ , then the vector field $A \in \mathcal{L}(\mathbb{R}^{d},\mathbb{R}^{d})$ is hyperbolic. Definition I. $A\colon \mathbb{R}^{d} \longrightarrow  \mathbb{R}^{d}$ is linear hyperbolic if all its eigenvalues ​​have non-zero real part. II. Let $(f^t)_t$ and $(g^t)_t$ be flows of the following autonomous differential equations $x' = F(x)$ , $F: \mathcal{U} \longrightarrow \mathbb{R}^d$ and $y' = G(y), G: \mathcal{V} \longrightarrow \mathbb{R}^d$ , with $F$ and $G$ continuous funtions defined over open sets. The flows $(f^t)_t$ and $(g^t)_t$ are said to be topologically conjugate if there exists a homeomorphism $h: \mathcal{U} \longrightarrow \mathcal{V}$ such that $f^t(x)$ is defined if and only if $g^t(h(x))$ is defined. In such case, $h(f^t(x)) = g^t(h(x))$ . Attempt: I started assuming that $A$ was not hyperbolic so I would have one of its eigenvalues ​​to be of the form $i\lambda$ with $\lambda \in \mathbb{R}$ . I tried to build a $B \in \mathcal{L}(\mathbb{R}^{d},\mathbb{R}^{d}) $ operator close to $A$ so that its flows were not topologically conjugated and concluded an absurdity. However, I couldn't finish it. Every help is welcome.",['ordinary-differential-equations']
3781258,Are there $k$ for which $\sigma_k$ is an injection?,"Does there exist $k \in N$ such that $ \sigma_k(n) $ is an injective function, where $\sigma_k(n)$ is the sum of the divisors of $n$ raised to the $k$ th power. If so what is the minimum value of $k$ with this property? The cases $k=1$ and $k=2$ are easily seen to be false, but for $k>2$ , is there a known solution?","['number-theory', 'divisor-sum', 'elementary-number-theory']"
3781261,Conditions for bounded solutions to inhomogeneous system of linear ODEs,"Consider the simple autonomous, non-homogeneous system of linear ODE's $$\dot{\mathbf{x}}(t) = M\mathbf{x}(t) + \mathbf{b}$$ where $\mathbf{x} :\mathbb{R}\to\mathbb{C}^n$ is a vector valued function of time, $M$ is a constant $n\times n$ complex matrix, and $\mathbf{b}\in\mathbb{C}^n$ is constant. My main question is the following: Q : What are the necessary conditions placed on $M$ and $\mathbf{b}$ such that all solutions $\mathbf{x}(t)$ are bounded, in norm, for all $t$ ? That is, all solutions satisfy $\|\mathbf{x}(t)\|\leq R$ for all $t$ , with $R\in(0,\infty)$ fixed. When $\mathbf{b} = 0$ , I know the answer: the eigenvalues $\lambda$ of $M$ must satisfy $\text{Re}(\lambda)\leq 0$ and the Jordan blocks (in a Jordan normal form of $M$ ) corresponding to any eigenvalue with $\text{Re}(\lambda)=0$ must size $1\times 1$ . For $\mathbf{b} \neq 0$ , can the Jordan normal form of $M$ alone determine whether all solutions are bounded? Or, does $\mathbf{b}$ play a non-trivial role in diagnosing this notion of ""stability""? I think I can prove that all solutions are bounded whenever $M$ is diagonalizable and has eigenvalues that lie strictly in the left half plane ( $\text{Re}(\lambda)<0$ ) but am not sure how to move beyond. I should also say that I am aware of other notions of stability such as Lyapunov stability, asymptotic stability, etc, and I know various theorems relating the Jordan normal form of $M$ to these notions. I'm simply having trouble finding results relating to this boundedness criterion I state. Thanks to anyone who may be able to answer or point me in the right direction!","['stability-theory', 'linear-algebra', 'ordinary-differential-equations']"
3781278,Prove/Disprove an inner product on a complex linear space restricted to its real structure is also an inner product,"Let $V$ be an $n$ -dimensional linear space and $(\cdot, \cdot)$ be an inner product on it. Define the conjugation map $\sigma: V \to V$ such that for any $\alpha, \beta \in V$ and $\lambda \in \mathbb{C}$ , $\sigma(\alpha + \beta) = \sigma(\alpha) + \sigma(\beta)$ , $\sigma(\lambda\alpha) = 
\bar{\lambda}\sigma(\alpha)$ , $\sigma^2(\alpha) = \alpha$ . The space \begin{align*}
R_\sigma(V) = \{\alpha \in V: \sigma(\alpha) = \alpha\}
\end{align*} is known as the real structure of $V$ . In the link, it has been shown $R_\sigma(V)$ is an $n$ -dimensional real linear space. I felt the inner product $(\cdot, \cdot)$ , which is originally defined on $V$ , when restricted to $R_\sigma(V)$ ,
is also an inner product. While the positiveness and bilinearity are easy to prove, it seems difficult to show the symmetry. In particular, how to show $(\alpha, \beta)$ is a real number when $\alpha, \beta \in 
R_\sigma(V)$ ?","['inner-products', 'linear-algebra']"
3781295,Logarithm over complex numbers,"The logarithm function is not certainly defined for every $\text{Re}(z)\leq0$ , but the question is where is it defined? I also know $\displaystyle \int_{C} \frac{1}{z} dz\neq0$ where $C$ is the unit circle defined by $ \gamma(t)=e^{it} $ for $0\leq t\leq 2\pi$ , which implies that $\frac{1}{z}$ has no antiderivative. Is this true because any set $U\supset C$ contains $z\in \mathbb{C}:Re(z)\leq0$ ? If $U$ does not contain $z\in \mathbb{C}:Re(z)\leq0$ , is $\log(z)$ ""well behaved"" in $U$ ?","['complex-analysis', 'logarithms']"
3781308,"Show that $F(x)=o(x^{1/q} )$, where $x \to +\infty$, whith $q=\frac{p-1}{p}.$","Let $f \in \mathcal{L}^p$ , with $1<p<+\infty$ . For all $x\geqslant 0$ , we define $\displaystyle{F(x)= \int_0^x f(t)dt}$ . Show that $F$ is uniformely continuous on $\mathbb{R}$ . Show that $F(x)=o(x^{1/q} )$ , where $x \to +\infty$ , whith $q=\frac{p}{1-p}.$ My attempt : let $0\leqslant x \leqslant y,$ \begin{align*}|F(y)-F(x)|&=\left|\int_x^yf(t)dt\right|\\&\leqslant\int_{\mathbb{R}}1_{[x,y]}(t)|f(t)|dt\\&  \leqslant (y-x)^{1/q} \left(\int_{\mathbb{R}} |f(t)|^p dt \right)^{1/p} \text{(by Hölder's inequality)} \\&\leqslant(y-x)^{1/q}\; ||f||p.\end{align*} Let $a>0$ (fixed) and $x>a$ , $|F(x)-F(a)|\leqslant (x-a)^{1/q}\; ||f||p$ , then $|F(x)|\leqslant  |F(a)|+(x-a)^{1/q}\; ||f||p$ $\implies $ $\dfrac{|F(x)|}{x^{1/q}}\leqslant  \dfrac{|F(a)|}{x^{1/q}}+(1-\frac{a}{x})^{1/q}\; ||f||p$ . I got stuck here, any help is highly appreciated.","['integration', 'measure-theory', 'lebesgue-integral']"
3781324,Prove: $\int_0^2 \frac{dx}{\sqrt{1+x^3}}=\frac{\Gamma\left(\frac{1}{6}\right)\Gamma\left(\frac{1}{3}\right)}{6\Gamma\left(\frac{1}{2}\right)}$,"Prove: $$
\int_{0}^{2}\frac{\mathrm{d}x}{\,\sqrt{\,{1 + x^{3}}\,}\,} =
\frac{\Gamma\left(\,{1/6}\,\right)
\Gamma\left(\,{1/3}\,\right)}{6\,\Gamma\left(\,{1/2}\,\right)}
$$ First obvious sub is $t = 1 + x^{3}$ : $$
\frac{1}{3}\int_{1}^{9}{\left(\,{t - 1}\,\right)}^{-2/3}\, t^{-1/2}\, \mathrm{d}t
$$ From here I tried many things like $\frac{1}{t}$ , $t-1$ , and more.  The trickiest part is the bounds! Reversing it from the answer the integral should be like $$
\frac{1}{6}\int_{0}^{1}
x^{-2/3}\left(\,{1 - x}\,\right)^{-5/6}\,\mathrm{d}t
$$ I'm not sure where the $1/2$ comes from and the $0$ to $1$ bounds.  Any idea or tip please ?.","['integration', 'definite-integrals', 'elliptic-curves', 'calculus', 'beta-function']"
3781367,Importance of Tannery's theorem,"Tannery's theorem :
Let $S_n=\sum_{k=0}^\infty a_k(n)$ and $\lim_{n\to\infty}a_k(n)=b_k$ . If $|a_k(n)|\le M_k$ and $\sum_{k=0}^\infty M_k\lt\infty$ , then $\lim_{n\to\infty}S_n=\sum_{k=0}^\infty b_k$ . This can be used to prove that $$\lim_{n\to\infty}\sum_{k=0}^n \frac{x^k}{k!}\prod_{m=1}^{k-1}\left(1-\frac{m}{n}\right) =\sum_{k=0}^\infty \frac{x^k}{k!}.$$ But I've never really understood why is the theorem ""needed"", as $\prod_{m=1}^{k-1}\left(1-\frac{m}{n}\right)$ tends to $1$ with increasing $n$ , so the result should be obvious. What could go wrong here? Could someone provide a counterexample to this reasoning?","['sequences-and-series', 'exponential-function', 'real-analysis']"
3781370,Are there applications of martingales other than in finance?,"I’ve only had a brief introduction to martingales and was wondering if there are applications of the theory in other areas of mathematics and in real world applications other than in finance (finance being the obvious one)? Do they come up at all in differential equations, statistics, physics or biology, for example?","['statistics', 'conditional-expectation', 'applications', 'martingales', 'probability-theory']"
3781405,What are the conditions for a path-connected compact set in the euclidean plane to have a path-connected boundary?,"If I have a path-connected compact set of points in $\mathbb{R}^2$ , what are the conditions for such a set of points to have a path-connected boundary?","['general-topology', 'path-connected', 'compactness']"
3781423,How to rationalize multiple terms with fractional exponents,"I'm trying to derive the derivative of $f(x) = x^{2/3}$ using the limit definition: $$f'(x)=\lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$$ $$=\lim_{h \to 0} \frac{(x+h)^{2/3} - x^{2/3}}{h}$$ I suspect I have to rationalize the numerator in order to cancel an $h$ from the numerator and denominator, but I'm not sure how to rationalize the numerator. I've tried multiplying by the conjugate and even tried to render the numerator a difference of cubes and then using $A^3 -B^3 = (A - B)(A^2 +AB + B^2)$ to rationalize, but to no avail. My two questions are: How do I rationalize the numerator? Is there a general formula for rationalizing multiple terms with rational exponents? Is there something I can read or study to learn more about this?","['exponentiation', 'rationalising-denominator', 'calculus', 'radicals', 'algebra-precalculus']"
3781455,A problem from Isaacs's Finite Group Theory,"I was revisiting group theory in detail and reading Isaacs's Finite Group Theory book in my own time. Sorry that I am asking an exercise question but this is the one I am stuck completely. Any help will be really appreciated. The problem is 1F.3 on page 40. Let $G=NP$ be a finite group, where $N$ is a normal subgroup of $G$ , and $P$ is a Sylow $p$ -subgroup of $G$ with $N\cap P=1$ , and assume that the conjugation action of $P$ on $N$ is faithful. Show that $P$ acts faithfully on at least one orbit of this action. The given hint is that we have to consider $x\in N$ with the properly that $P\cap P^x$ is least in size and then to show that $P$ acts faithfully on the $P$ -orbit containing $x$ . My guess is that somehow we have to use Theorem 1.38 of the book but I can not figure out how. I have given Theorem 1.38 below; here $O_p(G)$ stands for the $p$ -core of $G$ that is the unique largest normal $p$ -subgroup of $G$ , and it can be found by taking the intersection of all of the Sylow $p$ -subgroups of $G$ . Thanks in advance.","['group-theory', 'sylow-theory', 'p-groups']"
3781501,Absolutely continuous functions that fix zero and satisfies $f'(x)=2f(x)$,"A past question from a qualifying exam at my university reads:
Let $f$ be a continuous real-valued function on the real line that is differentiable almost everywhere with respect to the Lebesgue measure and satisfies $f(0)=0$ and $$ f'(x)=2f(x)$$ almost everywhere. Prove that there exists infinitely many such functions, but that only one of them is absolutely continuous. I have tried modifying the function $e^{2x}$ , but I cannot satisfy all the conditions given. Once one shows that there are infinitely many such functions, then if we pick 2 such functions $f_1$ and $f_2$ and fix $a>0$ , we can apply the fundamental theorem of Calculus for Lebesgue Integrals on $[0,a]$ and see that if both are absolutely continuous, then $$ f_1(x)=\int_0^x 2f(t)dt=f_2(x) $$ So this would imply that the are the same function on $[0,\infty)$ . I'm not sure how to proceed with the whole real line.","['measure-theory', 'lebesgue-measure', 'ordinary-differential-equations', 'lebesgue-integral', 'absolute-continuity']"
3781502,Why bother with the space $\mathcal{L}^1$ for integration when we can abstractly deal with the completion of a semi-normed space,"I'm studying the Bochner-Lebesue integral, and while I understand the general construction, I have a few questions about the way it is being presented. Typically, the story goes like this: We start with a measure space $(X,\mathcal{A}, \mu)$ , and a Banach space $E$ (over $\Bbb{R}$ or $\Bbb{C}$ ). Then, we can define the space $S$ of simple functions $X\to E$ , and for such simple functions, we can define an integral $I(\cdot):= \int_X (\cdot) \, d\mu : S \to E$ in the usual way. Then, we can define a semi-norm $\lVert\cdot \rVert_1$ on $S$ by setting $\lVert \phi \rVert_1 := \int_X|\phi|\, d\mu$ (this is to be thought of as integration when the Banach space is $E=\Bbb{R}$ , which is of course well-defined). Thus, we have a semi-normed space $(S,
\lVert \cdot \rVert_1)$ . At this point, we note that $S$ need not be complete, which of course very undesirable for analysis. So, all the presentations I've seen start by defining $\mathcal{L}^1$ as the space of functions $X\to E$ which are the almost-everywhere pointwise limit of Cauchy sequences in $S$ . Then, one proves that under these hypotheses, we can extend the integral to a map (pardon the reuse of notation) $I(\cdot)\equiv \int_X(\cdot)\, d\mu:\mathcal{L}^1 \to E$ , and also extend the seminorm $\lVert \cdot \rVert_1$ to $\mathcal{L}^1$ , such that integration is still a continuous map (with operator norm $\leq 1$ ), and that finally, $(\mathcal{L}^1, \lVert \cdot \rVert_1)$ is a complete semi-normed space containing the simple functions $S$ as a dense subspace. Therefore, by taking the quotient space of $\mathcal{L}^1/\{\phi\in \mathcal{L}^1: \, \lVert \phi\rVert_1 = 0\}$ , and calling this $L^1$ , this becomes a Banach space (because by taking this quotient, the semi-norm induces a norm, which is easily verified to be complete). Finally, it is a simple matter of linear algebra to see that we can ""transfer"" the integration map in the sense that we get a map $\tilde{I}:L^1 \to E$ , such that $I = \tilde{I}\circ \pi$ ( $\pi$ being the quotient map $\mathcal{L}^1 \to L^1$ ). The result is that we have an integration operator $\tilde{I}$ , defined on a Banach space $L^1$ , which naturally reduces to what we'd like it to be on simple functions. Now, my question is that why do we bother to introduce the space $\mathcal{L}^1$ along the way. My thinking is that just as every metric space has a completion, which is uniquely determined up to isometry, we can do a similar thing for semi-normed spaces, in the form of this theorem: Theorem Let $(S, \lVert \cdot \rVert)$ be a semi-normed space (over real or complex field), and let $S_0$ be the subspace of elements with $0$ semi-norm. Then, there exists a completion of $S$ , i.e a pair $(V,\gamma)$ , where $V$ is a Banach space (over the same field), and $\gamma:S\to V$ is a map such that $\gamma$ is linear $\ker(\gamma) = S_0$ $\text{image}(\gamma)$ is a dense subspace of $V$ $\gamma$ preserves seminorms and norms; i.e for all $s\in S$ , $\lVert\gamma(s) \rVert_V = \lVert s \rVert_S$ . Also, this completion is determined up to isomorphism (i.e if we had another such pair, then we can make a nice commutative diagram and then obtain an isomorphism of Banach spaces simply by extending the relevant maps from the dense subspaces to the whole space). So, when we have the space of simple functions $S$ , we could apply this theorem to get the Banach space $V$ (which is up to isomorphism the same as $L^1$ constructed above), and using similar linear algebra trickery, we can induce an integral $\tilde{I}$ on a dense subspace of $V$ , and then extend by continuity to the whole space. My questions/concerns: I realize that by the uniqueness aspect of the completion, both these methods give us the same final outcome: a Banach space, and some type of notion of integral, and of course, the first approach is much more concrete and easier to appreciate on first glance. However, I recently read up about completions of metric (semi-)normed spaces, which is why I thought of the second approach. So I guess my question boils down to: is there anything we gain significantly (besides a bit of concreteness) by realizing $L^1$ as a certain quotient space of functions, rather than just thinking of $L^1$ as an abstract completion of the space of simple functions? Is it perhaps because thinking of Banach spaces as being (almost) a space of functions, rather than some abstract construction (like equivalence classes of Cauchy sequences) makes it significantly easier to analyze the space in some sense (hence the term ""functional"" analyis)? If this is the case, I'd appreciate if you could elaborate on why specifically thinking in terms of function spaces makes the analysis easier/clearer/preferable (I'm not too sure what word I should use here).","['banach-spaces', 'measure-theory', 'complete-spaces', 'lebesgue-integral', 'functional-analysis']"
3781510,"Example of a field $F$ and a structure $(V,+,s)$ satisfying all but one of the vector space axioms.","I have to find an example (if there exists one) of a field $F$ and a structure $(V,+,s)$ (where $s$ stands for scalar multiplication)   satisfying all but one of the axioms of a vector space, namely the distributivity  of vector addition: For all $c ∈ F$ and $v,w ∈ V$ , $c(v + w) = cv + cw$ I believe such example exists, but I'm not sure where to start. An exercise I did before asked to show how the axiom follows from the other axioms if $F=\mathbb{Q}$ . So I think perhaps using a different field like $\mathbb{R}$ (or anything similar) could be of use. Could anyone give me some advice or hint to solve it? Thanks!","['abstract-algebra', 'linear-algebra', 'vector-spaces']"
3781562,Does $ \lim_{n \to \infty}\sum_{k = 1}^n \zeta\Big(k - \frac{1}{n}\Big)$ equal the Euler-Mascheroni constant?,"Let $\zeta(s)$ be the Riemann zeta function and $\gamma$ be the Euler-Mascheroni constant. I observed the following result empirically. Looking for a proof or disproof. $$
\lim_{n \to \infty}\sum_{k = 1}^n \zeta\Big(k - \frac{1}{n}\Big) = \gamma
$$ Also, I searched for different summation formulas for the Euler-Mascheroni constant using the Riemann zeta function but could not find it anywhere. Is there any reference to this sum in literature? Update: Applying the method of @Simply Beautiful Art, we can show that $$
\sum_{k = 1}^n \zeta\Big(k + \frac{1}{m}\Big) 
= \gamma + n + m + \mathcal O(n^{-1} + m^{-1})
$$","['summation', 'number-theory', 'analytic-number-theory', 'riemann-zeta', 'limits']"
3781579,Does the following net define a finitely additive probability measure?,"Let $\mathcal X$ be a set, and let $\mathcal F$ be the set of all finite subsets of $\mathcal X$ directed by subset inclusion. For each finite set $F \in \mathcal F$ , let $\mu_F$ be the probability measure defined on every subset $X$ of $\mathcal X$ by $$\mu_F(\{x\})=\begin{cases}1/|F|, \ x \in F,\\ 0, \ \text{otherwise.}\end{cases}$$ Does the net $(\mu_F(X))_{F \in\mathcal F}$ converge for all $X \subset \mathcal X$ ? I am wondering because, if the net does converge, then it can be used to define a finitely additive probability measure $\mu$ on $2^{\mathcal X}$ by $$\mu(X) = \lim_{\mathcal F} \mu_F(X). \tag{1}$$ If $X \in \mathcal F$ , then clearly the net converges. Indeed, for any $Y \in \mathcal F$ such that $Y \supset X$ we have $\mu_Y(X) = |X|/|Y| \to 0$ . So, if $\mathcal A$ is the finite/co-finite algebra, and $\mu$ is any extension to $2^{\mathcal X}$ of the probability on $\mathcal A$ that assigns finite sets measure $0$ , then I can say that (1) holds for $X \in \mathcal F$ , but this doesn't really answer my question.","['measure-theory', 'nets', 'probability-theory']"
3781581,How to evaluate $\int _0^1\frac{\ln ^2\left(1-x\right)\ln ^3\left(1+x\right)}{1+x}\:dx$,"I want to evaluate $$\int _0^1\frac{\ln ^2\left(1-x\right)\ln ^3\left(1+x\right)}{1+x}\:dx$$ Im not sure if this has a closed form, integration by parts is out of the question since there would be divergence issues. I also cant turn any of the terms in the numerator into taylor series since they have powers, expanding the denominator is also useless, could you at least give me a hint on how to tackle it, I've really got no clue.","['integration', 'improper-integrals', 'definite-integrals', 'harmonic-numbers', 'polylogarithm']"
3781590,Proving the variance of the distribution of $m$-fold products of elements of a generating set is asymptotic to $c^m$ without advanced tools,"Let $G$ be abelian with $n$ elements and let $G' = \{g_1 = e, \dots, g_k\} \subsetneq G$ be a (not necessarily minimal) set of generators. An element $g \in G$ is obtained by independently, uniformly at random (repetitions possible) selecting $m$ elements of $G'$ and multiplying them together. Prove there exists $b \in (0,1)$ such that $\lim\limits_{m \to \infty} \frac{1}{b^{2m}} \sum\limits_{x \in G} (\text{Pr}(g = x) - \frac{1}{n})^2$ is finite and non-zero. Fedja remarked here that ""Either you know the basic Fourier analysis on finite groups and then the problem is trivial (the convolution becomes just multiplication on the character group), or you don't and then you have almost no chance."" I don't know basic Fourier analysis on finite groups, but I'm hoping to prove him wrong. My attempt: Let $h_m$ be a random variable indicating the element selected after choosing $m$ elements of $G'.$ Then $\text{Pr}(h_m = x) = \frac{1}{k}\sum\limits_{i=1}^k \text{Pr}(h_m = xg_i^{-1}),$ so $$\left(\text{Pr}(h_m = x) - \frac{1}{n}\right)^2 = \frac{1}{k^2}\left(\sum\limits_{i=1}^k \left( \text{Pr}(h_{m-1} = g_i^{-1}x) - \frac{1}{n}\right)\right)^2 \le \frac{1}{k}\sum\limits_{i=1}^k \left( \text{Pr}(h_{m-1} = g_i^{-1}x) - \frac{1}{n}\right)^2$$ by Cauchy-Schwarz. Since the list of $nk$ elements $g_i^{-1}x, x \in G$ contains every element of $G$ exactly $k$ times, we get $$\sum\limits_{x \in G} \left(\text{Pr}(h_m = x) - \frac{1}{n}\right)^2 \le \sum\limits_{x \in G} \left(\text{Pr}(h_{m-1} = x) - \frac{1}{n}\right)^2.$$ This proves that the limit without the $b^{-2m}$ term exists by monotone boundedness. However, this limit is certainly zero, which is why the term is present in the first place. How do I obtain a finer estimate that allows me to deal with the entire limit?","['finitely-generated', 'group-theory', 'abelian-groups', 'probability']"
3781632,"Evaluating the surface integral $\iint_S {({x^2} + {y^2})} \,dS$ using spherical coordinates","For the integral $$\iint\limits_S {({x^2} + {y^2})} \,dS\quad,\,S:{x^2} + {y^2} + {z^2} = 2z$$ The
correct answer is $${{8\pi } \over 3}$$ I used Spherical coordinate system, it turns to $$\int_0^{2\pi } {d\theta \int_0^{{\pi  \over 2}} {({r^2}{{\sin }^2}\varphi } )({r^2}\sin \varphi )\,d\varphi } ,r = 2\cos \varphi $$ Then use $r = 2\cos \varphi$ , it turns to $$32\pi \int_0^{{\pi  \over 2}} {{{\sin }^3}\varphi {{\cos }^4}\varphi \,d\varphi }  = {{64} \over {35}}\pi $$ Doesn't match the answer, I wonder where am I wrong.","['integration', 'surface-integrals', 'multivariable-calculus', 'spherical-coordinates', 'multiple-integral']"
3781662,measure of set in $\mathbb{R}$ which has only finite number of 4's in decimal expansion,"Given a set $A = \{ x | \text{ $x$ has decimal expansion which has only finite 4's } , x \in [0,1] \,\, \}$ show that $\lambda(A) =0$ Given a set $B = \{ x | \text{ $x$ has decimal expansion which has only finite 4's } , x \in [0,\infty) \,\, \}$ show that $\lambda(B) =0$ EDIT : I have edited answer. Can someone check now. $C_{i} =\{x |\text{x s.t $(0..i-1)$ places can have any digits and 4 in ith place and there are no 4's after  }, x \in [0,1]  \} $ assume $ * \in \{0..9\}  \,\, , @ \in \{0..9\} \backslash 4$ now , it has already been shown here that Measure of  reals in $[0,1]$ which don't have $4$ in decimal expansion . Therefore $C_0 = \{0.@@@... \} , \lambda(C_0) = 0$ $C_1 =\{0.4@@@...\} ,C_1 = 10^{-1} \Big[ 4+C_0 \Big] \implies \lambda(C_1) = 10^{-1} \lambda(4+C_0) = 10^{-1} \lambda(C_0) =0 $ $\displaystyle C_2 = \{0.*4@@...\},C_2 = 10^{-2}\Big[\sum_{i=0}^{9} (i*10 +4 + C_0)  \Big] \implies \lambda(C_2) = 10^{-2} \lambda(C_0) = 0$ $\vdots$ Now, we can say that $A$ $1)\displaystyle A = \bigcup_{i=0}^{\infty} C_i$ (disjoint union) from which we have that $\displaystyle \lambda(A) = \sum_{i=0}^{\infty} \lambda(C_i) = 0$ $2) \displaystyle B = \bigcup_{i=0}^{\infty} (A+i)$ (disjoint union) from which we have that $\displaystyle \lambda(B) = \sum_{i=0}^{\infty} \lambda(A) = 0$ . Is there anything wrong with above argument.","['measure-theory', 'solution-verification', 'lebesgue-measure']"
3781670,Structure of the automorphism group of a group,"I'm looking to represent the automorphism group of a finite group in a small group theory package I'm writing. I was thinking of representing a generic automorphism $a \in \operatorname{Aut}(G)$ as a pair $(o,i)$ representing the composition of an outer automorphism $o \in \operatorname{Out}(G)$ by an inner automorphism $i \in \operatorname{Inn}(G)$ . Thus I can write $i$ as an element of $G / \operatorname{Center}(G)$ , and use a set of coset representatives for $\operatorname{Out}(G)$ . With this information, I can at least enumerate the elements of $\operatorname{Aut}(G)$ . Now, I'd like eventually to use the group structure on $\operatorname{Aut}(G)$ . I guess that I'd need to write $\operatorname{Aut}(G)$ as a semidirect product to be able to compute the composition of elements of $\operatorname{Aut}(G)$ as represented by those pairs. Now, as some automorphism groups do not split in that way, I guess I'm out of luck? I'm not so familiar with the group extension problem.","['automorphism-group', 'group-extensions', 'group-theory', 'semidirect-product']"
3781681,Well-ordering on natural numbers,"Let $\omega=\{0,1,2,3,\ldots\}$ . We say that $\omega$ is a well-ordered set. But I can't understand why. By the definition of well-ordering, there should be no infinite descending chain, but if I start from infinity, how can I reach 0 in finite descents? Or is this not allowed? Is this nonsensical to choose infinity? Then what about $\omega+1$ ? Is this set well-ordered? How can I reach to $0$ from $\omega$ ?",['elementary-set-theory']
3781694,Lots of doubts abot the surface area of a cylinder.,"I recently started to study parametric surfaces, and I come across this exercise that I try to solve but I have a lot of doubts reganding  the correctness of my resolution, and also I don't find similar examples on the internet. I need to find the surface area of the cylinder $$x^{2} + y^{2} = 4x$$ bounded by z=0 and z+ x =4. The cylinder is centered at (2,0) with radius 2. I made the parametrization $$<2+rcos(t) , rsen(t), 2-rcos(t)>$$ with r between 0 and 2, and t between 0 and 2π (First doubt : Is the parametrization right?) Then, if everything is ok, I would proceed to do the formula of a surface area (I would not write the whole formula because I am very bad at MathJax). But you know, the double integral of the norm of the vector (""u"") being ""u"" the cross product of the partial derivatives of the parametrization. The vector u in this case is (r,0,r) and the norm is $$\sqrt{2}r $$ Then, if everything is right, the area of the surface is the double integral $$\int_0^{2π}\int_0^2\sqrt{2}*r^2 dθdr  $$ Is this resolution right? If not, can you help me? Thanks. PS : I know that the cylinder bounded by the plane is half of the full cylinder. This is the main reason that I think this resolution is wrong.",['multivariable-calculus']
3781747,Chern classes of restrictions,"Let $\mathcal{F}$ be a vector bundle on some complex projective variety $X$ and let $D\subseteq X$ be a divisor.
Is there any nice description of the Chern classes $c_i(\mathcal{F}\vert_D)$ of the restriction $\mathcal{F}\vert_D$ of $\mathcal{F}$ as elements of the Chow ring of $D$ in terms of the Chern classes of $\mathcal{F}$ , $D$ and the inclusion map $i:D\hookrightarrow X$ ? This might be a completely trivial question, but at the moment I am completely confused about the appearing notions, so any help would be appreciated.","['complex-geometry', 'algebraic-geometry']"
3781771,Computation of first étale cohomology group on a curve,"I just finished my first time learning étale cohomology, and now would like to compute some simple examples, here is one : Let $k=\overline{\mathbb{F}_p}$ , and let $X$ be the curve $\text{Spec}\,k[X,Y]/(Y^2-X^2(X-1))\subseteq \mathbb{A}_k^2$ , what is the first étale cohomology group $H^1_{ét}(X,\underline{\mathbb{Z}}_X)$ of the constant sheaf $\underline{\mathbb{Z}}_X$ on $X$ ? Here is what I try to do. Let $f:\mathbb{A}_k^1\rightarrow X$ be the normalization morphism, then as $f$ is finite, we have $R^qf_*\mathcal{F}=0$ for every étale sheaf $\mathcal{F}$ on $\mathbb{A}_k^1$ and $q\geq 1$ , hence $H^1_{ét}(\mathbb{A}_k^1,\mathcal{F})=H^1_{ét}(X,f_*\mathcal{F})$ . So if there's a $\mathcal{F}$ with $f_*\mathcal{F}=\underline{\mathbb{Z}}_X$ we will be happy. My first thought was to take $\mathcal{F}=\underline{\mathbb{Z}}_{\mathbb{A}_k^1}$ , but I realized that $f$ corresponds to the map $$f:\mathbb{A}_k^1\rightarrow X,\,\,\,\,\,\,\,\,t\mapsto (t^2+1,t(t^2+1))$$ who is one-to-one except that the two points $t=\pm 1$ maps to $(0,0)$ , so $$(f_*\underline{\mathbb{Z}}_{\mathbb{A}_k^1})_{\overline{(0,0)}}=\mathbb{Z}\oplus\mathbb{Z},$$ that is, this choice doesn't work. Now I don't know how to continue. I would be grateful to anyone answering this question, or, giving any hint.","['etale-cohomology', 'algebraic-geometry']"
3781775,Linear function preserving the Gram determinant,"In Euclidean space $X$ the Gram's  determinant of a system of vectors $x_1,...,x_k\in X$ is called the determinant of $k\times k$ matrix $ [\langle x_i,x_j \rangle]$ : $
G(x_1,..,x_k)=\det[\langle x_i,x_j \rangle].
$ In $n$ dimensional Euclidean space $X$ , let $f: X\rightarrow X$ be a linear mapping and let $k\in \{2,...,n-1\}$ be a fixed number.
I wish to prove not using exterior algebra that if $
G(f(x_1),...,f(x_k))=G(x_1,...,x_k)
$ for each $x_1,...,x_k\in X$ , then $f$ is orthogonal mapping. Thanks",['linear-algebra']
3781790,Book recommendation : Olympiad Combinatorics book,"Can anyone recommend me an olympiad style combinatorics book which is suitable for a high schooler ? I know only some basics like Pigeon hole principle and stars and bars .
I hope to find a  book which contains problems which purely test our originality ( the problems with beautiful constructions like USAMO 2017 -TSTST P2: Which words can Ana pick? , Nim problems, games,tillings, etc ) . More specifically problems which doesn't require theory but requires out of the box thinking . I don't know much about recurrence relations, generating functions or graph theory, so I would also love to see a book which introduces these topics .","['contest-math', 'combinatorics', 'book-recommendation', 'discrete-mathematics']"
3781821,Goldfish in a lake,"It is known that many people dump their pet goldfish into lakes, when they want to get rid of them with no remorse!
We wish to calculate the number of goldfish in a small lake, in which there are several other fish of various species.
For this purpose we pick 20 goldfish and put them a permanent mark and then release them into the lake. After one day (and assuming there are no changes in the population of goldfish or other fish – the system is “closed”), we pick 30 goldfish, of which 5 are found marked. What is the probability that the total population of goldfish in the lake is from 115 to 125? I have found that this is done by using the “mark and recapture” method, by which we calculate the expected population to be $\frac{20*30}{5} = 120$ But how do we calculate the probability for it to be in the requested range? Of course by intuition, I guess it must be close to 100%!",['statistics']
3781841,Why is the blow up of a submanifold of $\mathbb{P}^n$ again projective,"I saw somewhere that the blow up (at any point) of a submanifold of $\mathbb{P}^n$ is still projective. I have the feeling that this is a consequence of the Kodaira embedding theorem, any thoughts?","['blowup', 'differential-geometry', 'complex-geometry', 'manifolds', 'projective-space']"
3781861,Other absolute value definitions in $\mathbb R$,"I know these definitions for the absolute value (or module): given a real number $x$ , then $$\bbox[yellow]
{|x|=\begin{cases}x & \text{if } x\geq 0\\ -x& \text{if } x< 0\end{cases}}$$ or $$\bbox[yellow]
{|x|=\max\{x,-x\}}$$ Are there other definitions in $\mathbb R$ (for example using $\text{sgn}\, x$ )? PS: The question is referred to high school students.","['algebra-precalculus', 'definition', 'absolute-value']"
3781878,Does this almost-group uniquely define a group?,"Consider a quasigroup $(S,+)$ such that for every $a,b,c,d\in S$ , $$(a+(b+c))+d=a+(b+(c+d)).$$ This is almost a group, but not quite. For instance, $(\mathbb Z,-)$ satisfies those axioms. You can easily prove that for any element $x$ , the operation $a+_xb:=a+(x+b)$ yields a group. But I wonder: for any given $(S,+)$ and any pair $x,y \in S$ , are $(S,+_x)$ and $(S,+_y)$ neccessarily isomorphic?","['quasigroups', 'group-theory', 'abstract-algebra']"
3781898,$\sigma(T(X)) = \sigma(X) \iff T$ is bijective,"Consider the following claim: Let $(\mathcal{X},\mathcal{M})$ , $(\mathcal{Y},\mathcal{N})$ and $(\mathcal{Z},\mathcal{O})$ be measurable spaces, and let $f \colon \mathcal{X} \to \mathcal{Y}$ and $g \colon \mathcal{Y} \to \mathcal{Z}$ be measurable functions. Then $\sigma(g \circ f) = \sigma(f)$ if and only if $g$ is bijective, where $\sigma(g \circ f) = (g \circ f)^{-1}(\mathcal{O}) = f^{-1}(g^{-1}(\mathcal{O}))$ and $\sigma(f) = f^{-1}(\mathcal{N})$ . This is false: for the “if” part of the statement, just consider $\mathcal{X} = \mathcal{Y} = \mathcal{Z}$ , $\mathcal{M} = \mathcal{N}$ , $\mathcal{O} = \{ \emptyset, \mathcal{X} \}$ and $f = g = \mathrm{id}_{\mathcal{X}}$ . I was going through Shao’s Mathematical Statistics , and on page 100 it is claimed that if $X$ is a random vector ( $\mathbb{R}^{n}-$ valued) and $T(X)$ is a statistic (which to my understanding means that $T$ is a measurable function from $\mathbb{R}^{n}$ to $\mathbb{R}^{m}$ , both endowed with the Borel $\sigma-$ algebra), then $\sigma(T(X)) = \sigma(X)$ if and only if $T$ is bijective. What makes this statement true, when the previous was not?","['measurable-functions', 'measure-theory', 'probability-theory', 'statistics']"
3781906,Weak maximum principle of strictly elliptic equation with solution in Sobolev space ( Gilberg Trudiger theorem 8.1),"\begin{equation}\label{eq:81}
    Lu=D_i(a^{ij}(x)D_ju+b^i(x)u)+c^i(x)D_iu+d(x)u
\end{equation} with \begin{equation}\label{eq:88}
    \int_{\Omega}(dv-b^iD_iv)dx\leq 0\qquad \forall v\geq 0,v\in C_0^1(\Omega)
\end{equation} Let $u\in W^{1,2}(\Omega)$ satisfy $Lu\geq 0(\leq 0)$ in $\Omega$ . Then \begin{equation}\label{eq:89}
    \sup_{\Omega} u\leq \sup_{\partial \Omega}u^+\quad(\inf_{\Omega} u\geq \inf_{\partial \Omega}u^+)
\end{equation} Proof:
If $u\in W^{1,2}(\Omega)$ and $v\in W_0^{1,2}(\Omega)$ we have $uv\in W_0^{1,1}$ and $D(uv)=vDu+uDv$ . $\mathfrak L(u,v)\leq 0$ $
\int \{(a^{ij}D_ju+b^iu)D_iv-(c^iD_iu+du)v)\}dx\leq 0$ \begin{equation}
    \int_{\Omega}\{a^{ij}D_juD_iv-(b^i+c^i)vD_iu\}dx\leq \int_{\Omega}\{duv-b^iD_i(uv)\}\leq 0 
\end{equation} for all $v\geq 0$ such that $uv\geq 0$ . last inequality.(Here we used coefficient of u negative). Hence , by coefficient bounds ,we have \begin{equation}\label{eq:810}
    \int_{\Omega}a^{ij}D_jD_ivdx\leq 2\lambda\nu\int v|Du|dx
\end{equation} for all $v\geq 0$ such that $uv\geq 0$ . In special case $b^i+c^i=0$ , the proof is immediate by taking $v=\max \{u-l,0\}$ where $l=sup_{\partial \Omega}u^+$ . Suppose on contrary , $\sup_{\Omega} u> \sup_{\partial \Omega}u^+$ For general case choose $k$ to satisfy $l\leq k<\sup_{\Omega}u,$ and we set $v=(u-k)^+.$ ( If no such $k$ exists then we are done.\ $v\in W_0^{1,2}(\Omega)$ and by chain rule \begin{align*}
Dv = \left\{ \begin{array}{cc}
                Du & \hspace{5mm} u>k\qquad(v\neq 0) \\
                0 & \hspace{5mm} u\leq k\qquad(v=0)\\
                \end{array} \right.
\end{align*} Consequently, we obtain above \begin{equation*}
        \int_{\Omega}a^{ij}D_jD_ivdx\leq 2\lambda\nu\int_{\Gamma} v|Du|dx\qquad \Gamma=supp (Dv)\subset v
\end{equation*} and Hence by Strict ellipticity of $L$ , \begin{equation*}
    \int_{\Omega} |Du|^2dx\leq 2\nu\int_{\Gamma} v|Du|dx\leq 2\nu ||v||_{2,\Gamma}||Dv||_{2,\Gamma}
\end{equation*} So that \begin{equation*}
    ||Dv||_2\leq 2\nu||v||_{2,\Gamma}
\end{equation*} By theorem 7.10, $n\geq 3$ \begin{equation*}
    ||v||_{2n/(n-2}\leq C||Dv||_2.
\end{equation*} Also  by Schwartz's inequality \begin{equation*}
    2\nu||v||_{2,\Gamma}\leq C|\Gamma|^{1/n}||v||_{2n/(n-2)}.
\end{equation*} So \begin{equation*}
    ||v||_{2n/(n-2}\leq C|\Gamma|^{1/n}||v||_{2n/(n-2)}.
\end{equation*} where $C=C(n,v)$ so that \begin{equation*}
    |\Gamma|\geq C^{-n}>0
\end{equation*} If $n=2$ \ \begin{equation*}
    \sup_{\Omega}|u|\leq C|\Omega|^{1/2-1/p}||Du||_p
\end{equation*} By replacing $2n/(n-2)$ by any number greater that 2 we get \begin{equation*}
    |\Gamma|\geq C^{-n}>0
\end{equation*} As above inequality is independent of $k$ , we can take $k\to \sup_{\Omega}u$ . $u $ attain its supremum in $\Omega$ on set of positive measure, where $Du=0$ .
This is contradiction to preceding inequality. I do not understand how to come to contradiction.I understand everything except how contradiction came I don't know. Any Help will be appreciated.","['proof-explanation', 'real-analysis', 'functional-analysis', 'partial-differential-equations', 'regularity-theory-of-pdes']"
3781968,If $f$ is Lebesgue integrable on an open set $U$ is it integrable over the surface of a submanifold contained in $U$?,"Let $d\in\mathbb N$ , $U\subseteq\mathbb R^d$ be open and $M\subseteq U$ be a $k$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ Let $f\in\mathcal L^1(U)$ and $\sigma_M$ denote the surface measure on $\mathcal B(M)$ . Are we able to show that $\left.f\right|_M\in\mathcal L^1(\sigma_M)$ ? Let $\lambda$ denote the Lebesgue measure on $\mathcal B(\mathbb R)$ . Maybe we can show $$\sigma_M(B)\le\lambda^{\otimes d}(B)\;\;\;\text{for all }B\in\mathcal B(M)\tag1$$ and use this to conclude the desired claim. In this regard, we may note that, trivially, $U$ is a $d$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ and $$\sigma_U=\left.\lambda^{\otimes d}\right|_U\tag2.$$ Remark : It might be useful to note that there is the following characterization of the surface measure: $\sigma_M$ is the unique measure on $\mathcal B(M)$ with $$\left.\sigma_M\right|_\Omega=\sigma_\Omega\tag3$$ for every open subset (in the subspace topology) $\Omega$ of $M$ .","['measure-theory', 'surface-integrals', 'smooth-manifolds', 'differential-topology', 'differential-geometry']"
3781996,Two sets having the same subset sums.,"I was trying to prove the following Proposition: Let $A=\{a_1,\ldots, a_k\}$ and $B=\{b_1,\ldots, b_k\}$ be two multisets (repetition is allowed)
with $|A|=|B|=k$ . Also $0\le a_1\le a_2\le\ldots \le a_k$ and $0\le b_1\le
 \ldots \le b_k$ . If $A$ and $B$ have the same subset sums, then $A=B$ . Same subset sums means that for every $A_i\subseteq A$ , there is a $B_i\subseteq B$ such that the sum of elements of $A_i$ is equal to the sum of elements of $B_i$ . Also just to clarify, if a number arises $x$ times as a subset sum from $A$ , then it should arise $x$ times from $B$ . I believed that I found a proof: Clearly, $a_1=b_1$ since they are the smallest subset sums of $A$ and $B$ respectively. Let $S(A
_i)$ denote the sum of elements of $A_i$ . We must also have $\sum_{A_i\subseteq A}x^{S(A_i)}=\prod_{i=1}^k(1+x^{a_i})=\prod_{i=1}^k(1+x^{b_i})=\sum_{B_i\subseteq B}x^{S(B_i)}$ (since they have the same subset sums). Since $a_1=b_1$ , we cancel from the products the factors $(1+x^{a_1})$ and $(1+x^{b_1}$ ) and we are left with $\prod_{i=2}^k(1+x^{a_i})=\prod_{i=2}^k(1+x^{b_i})$ . This shows that the sets $A-\{a_1\}, B-\{b_1\}$ have the same subset sums. We repeat this process until $a_k=b_k$ . Question: Is there another more ""simple"" proof of this proposition?
(If the proof I presented is correct)","['elementary-number-theory', 'summation', 'combinatorics', 'additive-combinatorics']"
3782024,Finding probability of Sample standard deviation given population is normally distributed,"For a random sample of size $n,$ if the values are taken from the $N(a, b)$ population, what is the probability that $S$ (where $S^2$ is sample variance) will exceed a particular value?
I had 2 approaches in mind here. Please let me know which one is correct Since $(n-1) S^2/\sigma^2$ is chi square distributed, can I say the square root of term on LHS is normally distributed? Use $x-\mu/(S/\sqrt{n})$ which is t distributed to find the answer","['statistics', 'probability']"
3782035,A variant form of Gronwall's inequality,"Suppose $u(t)$ is a measurable function on $[0,\infty)$ and satisfies $$0\le u(t) \le A + Bt\int_0^t u(s) ds$$ for all $t\ge 0$ ; here $A, B$ are positive constants. Is it possible to derive an upper bound for $u(t)$ ? Thanks for your help.","['reference-request', 'ordinary-differential-equations', 'real-analysis']"
3782063,Two possible equivalent statements regarding iterations of a map on $\mathbb{Z}_+\times\mathbb{Z}_+$,"Consider the map $f:X\to X$ where $X=\mathbb{Z}_+\times\mathbb{Z}_+$ and $\mathbb{Z}_+$ denotes the set of positive integers and $$
f(x,y) := 
\begin{cases}
(2x,y-x)& \text{if $x<y$},\\
(x-y,2y)& \text{if $x>y$},\\
(x,y)   & \text{if $x=y$}.
\end{cases}\;
$$ Question. Let $(a,b)\in X$ . Are the following two statements equivalent? The ratio $\displaystyle\frac{a+b}{\gcd(a,b)}$ is some (positive) power of $2$ , i.e., $$
\log_2\left(\frac{a+b}{\gcd(a,b)}\right)\in \mathbb{Z}_+\tag{0}
$$ There exists a positive integer $n$ such that $$
f^{n}(a,b) = (c,c)\tag{1}
$$ where $c:=(a+b)/2$ , [added: and $f^n$ means function compositions]. Background. This question is closely related to a recent one I asked on MathOverflow (MO). Here, the question focuses on a specific condition ( $0$ ), which is inspired by several exchanges of comments under the linked question on MO. Thanks to some observations of the map $f$ below, one can write a program with any given $(a,b)$ to simulate iterations of $f$ to see if $n$ in ( $1$ ) exists. All the cases I have tested so far say yes to the above question. The statement is particularly true for two simple cases, $(3,13)$ and $(3,9)$ , which were used in some unsuccessful attempts mentioned on MO. Here are some observations of the map; some have been mentioned on MO: The sum of the two components of $f^{n}(x,y)$ is fixed for all $n$ . Since the sum is fixed, by the pigeonhole principle , we must have $$
f^{M}(x,y) \in \{f^{k}(x,y)\mid k = 1,2,\cdots, M-1\}\;.
$$ If ( $1$ ) is ever true, then we must have $2\mid (x+y)$ . The map $f$ is homogeneous: $f(kx,ky) = kf(x,y)$ for any positive integer $k$ .","['combinatorics', 'discrete-mathematics', 'dynamical-systems']"
3782069,"$\triangle ABC$ with a point $D$ inside has $\angle BAD=114^\circ$, $\angle DAC=6^\circ$, $\angle ACD=12^\circ$, and $\angle DCB=18^\circ$.","Let $ABC$ be a triangle with a point $D$ inside.  Suppose that $\angle BAD=114^\circ$ , $\angle  DAC=6^\circ$ , $\angle ACD=12^\circ$ and $\angle DCB=18^\circ$ .  Show that $$\frac{BD}{AB}=\sqrt2.$$ I am requesting a geometric proof (with as little trigonometry as possible). A completely geometric proof would be most appreciated.  I have a trigonometric proof below. Trigonometric Proof Wlog, let $AB=1$ .  Note that $\angle ABC=\angle ACB=30^\circ$ , so $AC=1$ .  Then by law of sines on $\triangle ACD$ , $$AD=\frac{\sin 12^\circ}{\sin 18^\circ}.$$ By law of cosines on $\triangle ABD$ , $$BD^2=1^2+\frac{\sin^212^\circ}{\sin^2{18^\circ}}-2\frac{\sin 12^\circ}{\sin 18^\circ}\cos 114^\circ.$$ As $\cos 114^\circ=-\sin24^\circ$ , we get $$BD^2=2+\frac{-\sin^218^\circ+\sin^212^\circ+2\sin12^\circ\sin18^\circ\sin 24^\circ}{\sin^218^\circ}.$$ Then from the identities $\sin^2\alpha-\sin^2\beta=\sin(\alpha-\beta)\sin(\alpha+\beta)$ and $\sin(2\alpha)=2\sin\alpha\cos\alpha$ , we have $$BD^2=2+\frac{-\sin 6^\circ\sin 30^\circ+4\sin 6^\circ\cos 6^\circ \sin 18^\circ\sin24^\circ}{\sin^218^\circ}.$$ Because $\sin 30^\circ=\frac12$ , we conclude that $BD=\sqrt{2}$ if we can prove $$8\cos 6^\circ \sin 18^\circ \sin 24^\circ=1.$$ This is true because by the identity $2\sin\alpha\cos\beta=\sin({\alpha+\beta})+\sin(\alpha-\beta)$ , we have $$2\sin 24^\circ \cos 6^\circ =\sin 30^\circ+\sin 18^\circ.$$ Since $\sin 30^\circ=\frac12$ , we obtain $$8\cos 6^\circ \sin 18^\circ \sin 24^\circ =2\sin 18^\circ +4\sin^218^\circ=1,$$ noting that $\sin 18^\circ=\frac{\sqrt5-1}{4}$ . Attempt at Geometric Proof I discovered something that might be useful.  Construct  the points $E$ and $G$ outside $\triangle ABC$ so that $\triangle EBA$ and $\triangle GAC$ are similar to $\triangle ABC$ (see the figure below).  Clearly, $EAG$ is a straight line parallel to $BC$ .  Let $F$ and $H$ be the points corresponding to $D$ in $\triangle EBA$ and $\triangle GAC$ , respectively (that is, $\angle FAB=\angle DCB=\angle HCA$ and $\angle FAE=\angle DCA=\angle HCG$ ). Then $\triangle FBD$ and $\triangle HDC$ are isosceles triangles similar to $\triangle ABC$ , and $\square AFDH$ is a parallelogram.  I haven't been able to do anything further than this without trigonometry. Here is a bit more attempt.  If $M$ is the reflection of $A$ wrt $BC$ , then through the use of trigonometric version of Ceva's thm, I can prove that $\angle AMD=42^\circ$ and $\angle CMD=18^\circ$ .  Not sure how to prove this with just geometry.  But this result may be useful.  (Although we can use law of sines on $\triangle MCD$ to get $MD$ and then use law of cosines on $\triangle BMD$ to get $BD$ in terms of $AB$ too.  But this is still a heavily trigonometric solution, even if the algebra is less complicated than the one I wrote above.) I have a few more observations.  They may be useless.  Let $D'$ be the point obtained by reflecting $D$ across the perpendicular bisector of $BC$ .  Draw a regular pentagon $ADKK'D'$ .  Geogebra tells me that $\angle ABK=54^\circ$ and $\angle AKB=48^\circ$ .  This can be proven using trigonometry, although a geometric proof should exist.  But it is easy to show that $KD\perp CD$ and $K'D'\perp BD'$ . In all of my attempts, I always ended up with one of the following two trigonometric identities: $$\cos 6^\circ \sin 18^\circ \sin 24^\circ=1/8,$$ $$\cos 36^\circ-\sin18^\circ =1/2.$$ (Of course these identities are equivalent.)  I think a geometric proof will need an appearance of a regular pentagon and probably an equilateral triangle, and maybe a square.","['euclidean-geometry', 'trigonometry', 'triangles', 'plane-geometry', 'algebra-precalculus']"
3782095,Reference for contracted product $X \times^G Y$,"I've seen a superscript on $\times$ a few times now in the setting of $G$ -spaces, and I can't find any documentation of its definition or basic properties, as I have no idea what to search. Given an algebraic group $G$ , a right $G$ -torsor $X \to S$ , and a left $G$ -space $Y$ , how is the space $X \times^G Y$ defined, and what is it called? An example of its use (from Richarz, ""A new approach to the geometric Satake equivalence""; note that $\mathrm{Gr}_G$ is a right $fpqc$ -quotient $\mathrm{Gr}_G := LG/L^+G$ ): Consider the following diagram of ind-schemes $$
\mathrm{Gr}_G \times \mathrm{Gr}_G \overset{p}{\leftarrow} LG \times \mathrm{Gr}_G \overset{q}{\to} LG \times^{L^+G} \mathrm{Gr}_G \overset{m}{\to} \mathrm{Gr}_G.
$$ Here $p$ (resp. $q$ ) is a right $L^+G$ -torsor with respect to the $L^+G$ -action on the left factor (resp. the diagonal action). The $LG$ -action on $\mathrm{Gr}_G$ factors through $q$ , giving rise to the morphism $m$ . If I want to take this as a definition (quotient a Cartesian product of two $G$ -sets by the diagonal action), I am still not sure what kind of quotient I should be using, and I have some further questions I'd rather not probe alone if I don't have to. When is $X \times^G Y$ a $G$ -torsor, an $fpqc$ sheaf, an algebraic space, an ind-scheme, etc.? Does the side of the $G$ -action on $X$ or $Y$ matter for the definition? Is the notation symmetric in $X$ and $Y$ ? Is it necessary that $X$ be a torsor? Are there other necessary conditions to define the space? Edit: after some random browsing here and on Overflow, I have found two possible names for the object and a possible definition. It is referred to as either a twisted product or a contracted product. I want to point out that none of the questions linked below have answers (outside of some fairly brief comments) or any references, so I would greatly appreciate a basic reference. I still can't seem to find any. What is the algebraic interpretation of a contracted product? (MSE) Twisted product (MSE) Contracted product of torsors (MO) Question 3 includes a definition, and asks some of the same questions I'm interested in, but imposes some more conditions on the spaces involved than I thought would be necessary.","['algebraic-groups', 'principal-bundles', 'reference-request', 'algebraic-geometry', 'group-theory']"
3782117,How does one compute pushforward sheaves?,"For simplicity let's work with smooth projective varieties over $\mathbb C.$ I'm wondering how to compute the pushforward of a sheaf by a finite map $f:X\to Y.$ [The actual example I care about is with the double cover of $\mathbb P^2$ branched over a smooth sextic, but I would rather figure this out on my own. My intuition says that the pushforward of the structure sheaf in this case is $\mathcal O_{\mathbb P^2}\oplus\mathcal O_{\mathbb P^2}(3),$ but the cohomology is not of the correct rank if this were true.] Let's take for example the map $t:\mathbb P^1\to \mathbb P^1$ given by $t(Z:W)=(Z^2:W^2).$ Then I can show that $t_*\mathcal O_{\mathbb P^2}$ is locally free of rank 2 (I know this is a theorem but it's not one I have seen yet). However I'm having trouble figuring out the global picture. For example, near the point $(0:1)$ with $z=Z/W$ we have the induced map $t^*:\mathbb C[z]\to \mathbb C[z]$ which sends $z\mapsto z^2$ and as a module, the codomain splits as $1t^*(\mathbb C[z])\oplus zt^*(\mathbb C[z])$ and hence has rank 2. But now I want to compute how the section $z$ transforms into the other affine piece of $\mathbb P^1$ and I'm at a loss. How do you compute the transition functions in this case? When I told my advisor that I'm trying to look at this simple example to get an understanding for how to do this he looked at it and instantly said that it was $\mathcal O_{\mathbb P^1}\oplus\mathcal O_{\mathbb P^1}(-1).$ I will ask him at our next meeting, but I'm also wondering if there are any good heuristics for computing these pushforwards . Right now I have no intuition for how this should go. I have no knowledge of schemes so if any explanation could avoid that language I would appreciate it.","['pushforward', 'algebraic-geometry', 'coherent-sheaves']"
3782130,Show that $f\in \mathcal{L}^p$ and $||f||_p \leqslant M.$,"Let $(X, \mathcal{B}, \mu)$ be a measured space, $1<p<\infty$ , and $q$ the conjugate exponent of $p$ : $\left(\dfrac{1}{p}+\dfrac{1}{q}=1\right)$ . Show that $f \in \mathcal{L}^p \implies$ $\displaystyle{||f||_p=\sup\left\{ \left|\int_X f(x)g(x)d\mu(x) \right| ; ||g||_q \leqslant1\right\}}$ . We assume here that the measure $\mu$ is $\sigma$ -finite. Let $f : X\to \mathbb{C}$ a mesurable function. we assume that there exists $M\geqslant0$ such that $\displaystyle{\left|\int_X f(x)g(x)d\mu(x) \right| \leqslant M}$ for all $g \in \mathcal{L}^p$ with $||g||_q\leqslant 1$ .
Show that $f\in \mathcal{L}^p$ and $||f||_p \leqslant M.$ My attempt: on the one hand \begin{align*}
\left|\int_X f(x)g(x)d\mu(x) \right| & \leqslant \int_X|f(x)g(x)|d\mu(x) 
\\ & 
\leqslant  \left(\int_X|f(x)|^pd\mu(x) \right)^{\frac{1}{p}} \left(\int_X|g(x)|^q d\mu(x) \right)^{\frac{1}{q}}\\ & =||f||_p||g||_q  \\& \leqslant ||f||_p
\end{align*} on the other hand Let $g_0(x)= \dfrac{|f(x)|^p}{|f(x)|}$ if $f(x)\not=0$ , $g_0(x)=0$ if $f(x)=0$ . so $g_0(x)f(x)=|f(x)|^p$ , for all $x\in X$ , then $|g_0|^q= |f|^{(p-1)q}=|f|^p$ , so $g_0 \in \mathcal{L}^q$ , since $f\in \mathcal{L}^p$ . let's pose now $g=\dfrac{g_0}{||g_0||_q}$ , we notice that $||g||^q=1$ , and $$\int_Xf(x)g(x)d\mu(x) =\int_X f(x)\dfrac{g_0(x)}{||g_0||_q^q}d\mu(x)=\int_X\dfrac{|f(x)|^p}{||g_0||_q^q}= \dfrac{||f||_p^p}{||f||_p^{\frac{p}{q}}} = ||f||_p.$$ 2. I got stuck here ! Any help is highly appreciated.","['measure-theory', 'lebesgue-integral']"
3782158,Calculate :$\int_{0}^{2\pi }e^{R{ {\cos t}}}\cos(R\sin t+3t)\mathrm{d}t$,"Calculate: $$\int_{0}^{2\pi}e^{R{ {\cos t}}}\cos(R\sin t+3t)\mathrm{d}t$$ My try: $\displaystyle\int_{0}^{2\pi}e^{R{ {\cos t}}}\cos(R\sin t+3t)dt\\ \displaystyle \int_{|z|=R}e^{\mathfrak{R\textrm{z}}}\cos(\mathfrak{I\textrm{z}}+3(-i\log z)dz\\
\displaystyle \int_{|z|=R}e^{\mathfrak{R\textrm{z}}}\mathfrak{R\textrm{e}}^{(\mathfrak{I\textrm{z}}+3(-i\log z))i}dz\\ \displaystyle \int_{|z|=R}e^{\mathfrak{R\textrm{z}}}\mathfrak{R\textrm{e}^{\mathfrak{I\textrm{z}}}}z^{3}dz\\ \displaystyle \int_{|z|=R}e^{\mathfrak{R\textrm{z}}}\mathfrak{R\textrm{e}^{\mathfrak{I\textrm{z}}}R}z^{3}dz$ and there is nothing here that is not holomorphic, therefore according to Cauchy theorem it must be exactly $0$ .","['integration', 'complex-analysis', 'calculus', 'contour-integration']"
3782163,"If $(M,g)$ is a Riemannian manifold and $S$ is a regular level set of $f:M\to \Bbb R$ then $\text{grad}f|_S$ is nowhere vanishing","I have a question reading a proof of the following theorem. Theorem. Let $M$ be an oriented smooth manifold, and suppose $S\subset M$ us a regular level set of a smooth function $f:M\to \Bbb R$ . Then $S$ is orientable. Proof. Choose a Riemannian metric $g$ on $M$ , and let $N=\text{grad}f|_S$ . The hypotheses imply that $N$ is nowhere tangent vector field along $S$ , so the result follows. I know that $N$ is normal to $S$ at each point of $S$ , but how do we know that $N$ does not vanish at each point of $S$ ? If $(U,x^1,\dots,x^n)$ is a chart of $M$ near a point in $S$ , then $g$ can be written as $g=g_{ij}dx^i \otimes dx^j$ where $(g_{ij})$ is a positive definite real symmetric matrix. Then $\text{grad}f|_S$ equals $g^{ij} \dfrac{\partial f}{\partial x^i} \dfrac{\partial }{\partial x^j}$ where $(g^{ij})=(g_{ij})^{-1}$ . Since $S$ is a regular level set, some $\dfrac{\partial f}{\partial x^i}$ does not vanish at each point of $S$ , but how do we know that $g^{ij} \dfrac{\partial f}{\partial x^i}$ does not vanish for some $j$ , at each point of $S$ ?","['riemannian-geometry', 'proof-explanation', 'smooth-manifolds', 'orientation', 'differential-geometry']"
3782179,"""Finite-Dimensional-Type-Spectral-Theorem"" for Orthogonal Projections","Let $H$ be a Hilbert space, not assumed separable, and $p$ and $q$ (bounded - not sure if that is important) orthogonal projections. Question 1 : Is it the case that $p$ has an orthonormal eigenbasis for $H$ /is diagonalisable? Question 2 : Is it the case that $p$ and $q$ commute if and only if they share an eigenbasis/are simultaneously diagonalisable? If the answer to question 1 is no, what are some reasonable assumptions on $H$ that guarantee such an eigenbasis exists (it seems to me that separability is enough. I don't think assumptions (such as compactness) on $p$ and $q$ are much good to me.). If the answer to question 1 is no, do these assumptions give a positive answer to question 2? Thanks for your help. I am a little concerned when I work in infinite dimensions. For example I would just say, OK, $$H=\operatorname{ran }p \oplus \ker{p},$$ each are closed and so each are Hilbert spaces and so each have onb... and just union those, bingo-bango, jobs a good 'un... but I am concerned there is an error there.","['operator-algebras', 'eigenvalues-eigenvectors', 'hilbert-spaces', 'linear-algebra', 'functional-analysis']"
3782185,"Convolution of tempered distribution($K$) and gaussian. if $K = K*e^{-\pi |x|^2}$, then $K$ is first degree polynomial.","Q : I need to prove that if $K$ is tempered distribution on $\mathbb{R}$ satisfying: \begin{equation}
K = K*e^{-\pi |x|^2}
\end{equation} then $K$ is first degree polynomial. mean $K(x) = Ax + b$ Remark: The question was changed. The original was to prove that if $K = K * e^{-\pi |x|^2}$ then $K$ is constant, which is false. The first thing I did is to apply fourier transform on both sides to work with multiplication instead of convolution. and I got $\hat{K} = e^{-\pi |x|^2} \hat{K}$ . I succeeded to prove $\hat{K}$ is supported at the origin and by theorem 1.7 at page 110, from Stein and Shakarchi functional analysis(Can't find the pdf online) or theorem 6.25 at page 165 from Rudin Functional analysis : \begin{equation}
\hat{K} =\sum_{|\alpha| \leq N} a_{\alpha} \partial^{\alpha}\delta
\end{equation} . Now, if I apply the inverse fourier transform I get that $K$ is a polynomial. The solution will arise if I will prove that if $p$ is a polyomial in $\mathbb{R}^{d}$ satisfying $p*e^{-\pi |x|^2} = p$ , then $p$ is constant. It sounds true(which is not, please see the comments) but I think it is kind of ""ugly"" to prove and I am pretty sure that there is another way for me to continue. Hot to continue? Thanks :)","['harmonic-analysis', 'convolution', 'distribution-theory', 'functional-analysis', 'gaussian']"
