question_id,title,body,tags
4421255,What is the Probability of Eating a Certain Meal on a Given Day?,"This is a problem that was given during a discussion section in the first week of my statistics class that I might be overthinking and misunderstanding. You prepare 5 meals for the week, 2 with vegetables and 3 without. Starting on Monday, a meal is consumed each day until Friday. What is the probability that you will eat a meal with vegetables on Wednesday? The answer to this problem was simply: $$\frac{(\text{# of Vegetable Meals})}{(\text{Total # of Meals})}$$ or $\frac{2}{5}$ . My confusion stems from, if a meal is consumed each day wouldn't the number of meals that we can choose from get smaller as we near the end of the week? So by Wednesday there would be only 3 meals to pick from. In addition, why do we not have consider the 3 different cases of the meals eaten before Wednesday? If a vegetable meal is eaten on Monday and Tuesday, then there would be a 0 chance of eating one on Wednesday. What about the cases where there was already 1 vegetable meal eaten before Wednesday? Would that not make the probability of eating a vegetable meal on Wednesday be: $$P(\text{Vegetable Meal on Wednesday)} = \frac{2}{5}*\frac{3}{4}*\frac{1}{3}$$ or if no vegetable meals are eaten before Wednesday at all: $$P(\text{Vegetable Meal on Wednesday})=\frac{3}{5}*\frac{2}{4}*\frac{2}{3}$$ Why would we not sum up these prbabilites to get the actual probability of eating a vegetable meal on Wednesday?","['statistics', 'combinatorics', 'probability']"
4421260,Number of ways to color a square graph with diagonal line using principle of Inclusion and Exclusion,"How many ways can we color the graph if adjacent vertices receive different colors ? It's easy to see that the answer is $n(n-1)(n-2)^2 = n^4-5n^3+8n^2-4n$ , where $n$ is the number of colors (fix a color to the top left vertex, for the top right vertex we can choose $n-1$ , for the bottom left we can choose $n-2$ and for the bottom right we can also choose $n-2$ ). But how can I explain this answer or proof it by using the Principle of Inclusion and Exclusion ? (about explain I mean what each of this terms mean $-5n^3+8n^2-4n$ )","['coloring', 'graph-theory', 'inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
4421380,Does a distribution with the moments $E[X^k]=1_{k=2l} l!$ exists?,"Does a distribution on $\mathbb{R}$ exists such that for a random variable $X$ on $\mathbb{R}$ with said distribution we have $$
\mathbb{E}[X^{2l}] = l! \ \ \text{ and } \ \ \mathbb{E}[X^{2l+1}] = 0
$$ for all $l \in \mathbb{N}_0$ ? The equality $\mathbb{E}[X^{2l+1}] = 0$ clearly holds for every symmetric distribution (where the moments exist) but I don't know of a distribution with such even moments. Any help is much apprechiated.","['probability-distributions', 'probability', 'distribution-theory']"
4421420,"Calculate area bounded by $\frac{x^{2}}{16}+\frac{y^{2}}{25}=1$, $y=\pm 3$ and $y=x+4$","In my exam I was asked to find out the area bounded by the ellipse $x^{2}/16+y^{2}/25=1$ , and the lines $y=\pm 3$ and $y=x+4$ . Here is what I did. $$\begin{aligned}A=\iint_{R}\mathrm dA&=\int_{0}^{3}\int_{y-4}^{0}\mathrm dx\mathrm dy+3\int_{0}^{3}\int_{0}^{\frac{4}{5}\sqrt{25-y^{2}}}\mathrm dx\mathrm dy \\ &=\int_{0}^{3}(4-y)\mathrm dy+\int_{0}^{3}\frac{12}{5}\sqrt{25-y^{2}}\mathrm dy \\ &=\frac{15}{2}+\frac{72}{5}+30\arcsin\left(\frac{3}{5}\right)\end{aligned}$$ Could someone check whether I have done it correctly. Any inputs are appreciated. Thanks.","['integration', 'multivariable-calculus']"
4421528,Can the lion protect the sheep from three wolves?,"Generally, in pursuit-evasion games, there's one prey and one or many pursuers. I'd like to know how extending the food chain would change the dynamics of such games. Specifically, let's consider a closed, circular shape arena in $\mathbb{R}^2$ . Three wolves are uniformly distributed at the border. The sheep and his lion friend are at the center. If $d(w(t),s(t))=0$ , the wolf eats the sheep, if $d(l(t),w(t))=0$ , the lion eats the wolf, where w(t), s(t) and l(t) are the trajectories of the animals, and $d$ measures euclidean distance. The pack of wolves work as a group, their goal being to eat the sheep. The goal of the lion-sheep team is to prevent the sheep from being eaten, indefinitely. All animals move continuously in time at equal speed and are intelligent. Can the lion protect the sheep from the wolves? In general, how many lions are necessary to protect the sheep from a pack of $N$ wolves uniformly distributed at the border? This is a puzzle I originally asked here on puzzling.stackexchange. I know already that A single wolf doesn't catch the sheep. Two wolves will catch the sheep. $N-1$ lions are sufficient to fend off $N$ wolves. See here for the proof of those claims. I'm interested in knowing whether $N-2$ or less lions can fend off $N$ wolves.","['geometry', 'calculus', 'optimization', 'game-theory', 'dynamical-systems']"
4421529,Function that makes limit finite,"Question: Let $n > 0$ . How can I find a function $f:\mathbb{N}\rightarrow\mathbb{R}^+$ such that $$
\lim_{n\to\infty} \frac{f(n)^2}{n} \log \left(\frac{f(n)}{n}\right) = L
$$ with $0<L<\infty$ ? Background : The term above appears in my research on subexponential bounds for binary words containing a limited number of ones. I have been able to elimate all other terms, but I am stuck with this one. What I tried so far: I applied L'HÃ´pital's rule to get $$
\lim_{n\to\infty} \frac{\log\left(\frac{f(n)}{n}\right)}{\frac{-n}{f(n)^2}} = \lim_{n\to\infty} \frac{\frac{f'(n)}{f(n)}-\frac{1}{n}}{\frac{1}{f(n)^2}-\frac{2nf'(n)}{f(n)^3}}
$$ which got rid of the $\log()$ . Since the limit should be finite, it seems to me that $\lim_{n\to\infty} \frac{f(n)}{\sqrt{n}} < \infty$ , but I haven't been able to come up with an $f(n)$ that doesn't lead to $L=0$ .","['limits', 'logarithms']"
4421530,Simplifing an equation and solve it for x,"I want to simplify an equation. I have: $$ \sqrt{(x+r*sin(\alpha))^2+(m*x+t-r*cos(\alpha))^2}+r=l$$ and also I know: $$ r=\frac{t+m*x-x*tan(\delta)}{cos(\alpha)+sin(\alpha)*tan(\delta)}$$ If I put the equation of $r$ in my other equation I get: $$ \sqrt{(x+\frac{t+m*x-x*tan(\delta)}{cos(\alpha)+sin(\alpha)*tan(\delta)}*sin(\alpha))^2+(m*x+t-\frac{t+m*x-x*tan(\delta)}{cos(\alpha)+sin(\alpha)*tan(\delta)}*cos(\alpha))^2}+\frac{t+m*x-x*tan(\delta)}{cos(\alpha)+sin(\alpha)*tan(\delta)}=l$$ I now have to solve for x and I don't get a solution for it because it is to complicated. So I tried to simplify the equation with Mathcad and solve it then for x but also this gave me an expression which was too long to display and Mathcad cannot show it to me. Are there any suggestions how to simplify this equation to get a result for x? Best regards,
mk3","['trigonometry', 'linear-algebra']"
4421532,Can a free product of groups be co-Hopfian?,"A group $G$ is called co-Hopfian if it is not isomorphic to a proper subgroup of itself; equivalently, every injective group homomorphism $\varphi : G \to G$ is surjective and hence an isomorphism. Examples of co-Hopfian groups include finite groups, $\mathbb{Q}$ , $\mathbb{Q}/\mathbb{Z}$ , and fundamental groups of closed hyperbolic manifolds. Examples of groups which are not co-Hopfian include free groups, free abelian groups, $\mathbb{R}$ , and $\mathbb{Q}^*$ (take $\varphi(x) = x^3$ ). In this MathOverflow answer , Ian Agol shows that if a group $C$ is freely indecomposable (i.e. not a non-trivial free product) and co-Hopfian, then $A\ast C \cong B\ast C$ implies $A\cong B$ . As all the examples of co-Hopfian groups I have been able to find are freely indecomposable, I wonder if they all must be, in which case the first condition on $C$ is superfluous. Is a co-Hopfian group necessarily freely indecomposable? Note, answering this question is equivalent to answering the question in the title. I've seen it claimed in a couple of papers that the answer is yes, but references weren't provided which makes me think that this should be fairly elementary. If $G \cong A\ast B$ is co-Hopfian, then there is a proper subgroup $H$ with $H\cong G$ . By the Kurosh subgroup theorem, there is a set $X \subseteq G$ , a family of subgroups $(A_i)_{i\in I}$ of $A$ , a family of subgroups $(B_j)_{j\in J}$ of $B$ , and families of elements $(g_i)_{i\in I}$ , $(f_j)_{j\in J}$ of $G$ such that $H = F(X)\ast\left(\ast_{i\in I}g_iA_ig_i^{-1}\right)\ast\left(\ast_{j\in J}f_jB_jf_j^{-1}\right)$ . I don't know where to go from this point. In particular, I don't know if the fact that $H$ is a proper subgroup yields any information about the cardinalities of $X$ , $I$ , and $J$ .","['co-hopfian', 'group-theory', 'free-product', 'reference-request']"
4421550,What do you call third order derivative matrix and what does it geometrically signify?,"The first-order derivatives matrix is known as Jacobian, gives the gradient of the graph.
Similarly, the second-order derivatives matrix is Hessian, which gives the curvature of the plot.
What next? i.e., is there a third-order derivative matrix? If yes, what does it denote?","['gradient-flows', 'matrices', 'jacobian', 'hessian-matrix', 'derivatives']"
4421660,"Given that $ a,b,c$ are positive numbers and $(a+b)(b+c)(c+a)=1$, find the maximum value of $P=ab+bc+ca$","I am stuck with this problem: Given that $ a,b,c$ are positive numbers and $(a+b)(b+c)(c+a)=1$ , find the maximum value of $P=ab+bc+ca$ I tried to use: $(a+b)(a+c)(b+c)=(a+b+c)(ab+bc+ca)-abc \implies  P=\frac{1+abc}{a+b+c}$ but I am stuck. Can anyone help me? Thank you! I'm just 14 years old, so don't use derivative or something like that (my brother uses it but I cant understand).","['maxima-minima', 'algebra-precalculus', 'inequality']"
4421674,Finding the function for a sequence using differences,"I am trying to find a function generating/suitable for the following sequence: ${2,6,12,20,30,42,56...}$ The first order differences are: $4, 6, 8, 10, 12, 14...$ and the second order differences are: $2, 2, 2, 2, 2, 2...$ this means that: $y''= 2 \implies y' = 2\cdot x + c$ and we can see that for $c = 2$ we can get the correct numbers i.e. the first order differences (replacing starting from $x = 1$ ). So $y' = 2\cdot x + 2$ This means that $y = x^2 + 2\cdot x + c$ But I can't find any value of $c$ that would give the original sequence. Now I see that $y'$ could also be $y' = 2\cdot x + 4$ as it gives the correct numbers if we replace starting from $x = 0$ but then we have $y = x^2 + 4\cdot x + c$ and I again can't find any $c$ that matches the original sequence. What am I doing wrong here?","['calculus', 'derivatives', 'sequences-and-series']"
4421682,How to evaluate $\int^{}_{c} y dx + z dy + x dz$,"How to calculate $$\int^{}_{c} y dx + z dy + x dz$$ Where C consists of the segment $C_{1}$ joining $(2,0,0)$ to $(3,4,5)$ followed by the vertical line segment C2 from $(3,4,5)$ to $(3,4,0)$ I'm thinking of parameterizing C1, starting parameterization $(2,0,0)$ to $(3,4,5)$ :
Let $$A(2,0,0)$$ and $$B 
(3,4,5)$$ Parameterization formula: $$(x,y,z)=B.t+(1-t).A$$ $$(x,y,z)=(3,4,5).t+(1-t).(2,0,0)$$ $$(x,y,z)=(3t,4t,5t)+(2-2t,0,0)$$ $$(x,y,z)=(2+t,4t,5t)$$ So our vector $$r(t)=(2+t)\hat{i}+(4t)\hat{j}+(5t)\hat{k}$$ $$r'(t)=(1,4,5)$$ $$ |r'(t) |=\sqrt{1^{2}+4^{2}+5^{2}}=\sqrt{42}$$ I don't know how to continue.the function $f(x,y,z)$ is $x+y+z$ ? then I would apply Line integral","['integration', 'multivariable-calculus']"
4421689,"Does $(1-\cos(x))/x^2$ have or deserve a name, like $sinc$ for $\sin(x)/x$?","i think it's the âdualâ of $\mathrm{sinc}(x)$ , that is, $$f(x) = \begin{cases}
\frac 1 2,  & \text{if $x=0$} \\
\frac{1-\cos{x}}{x^2}, & \text{otherwise}
\end{cases}$$ they share some properties: both have definite integral $\int_{-\infty}^\infty\frac{\sin{x}}{x}dx = \int_{-\infty}^\infty\frac{1-\cos{x}}{x^2}dx = \pi$ on taylor series, both could be regarded as chopping the constant term then divided by x to ""the order the first term""-th power, $\frac 1{1!} - \frac{x^2}{3!} + \frac{x^4}{5!} - \frac{x^6}{7!} + ...$ for the sinc case, and $\frac 1{2!} - \frac{x^2}{4!} + \frac{x^4}{6!} - \frac{x^6}{8!} + ...$ for the cosine case. it also appears in my recent (humble) study about 3D rotation. in a nutshell, to generate a rotation matrix from a rotation vector, let $$\text{rotation vector }\vec{r}=\begin{bmatrix} x\\y\\z \end{bmatrix}, \theta = \lVert \vec{r}\rVert$$ $$\mathbf{C}=\text{âcross product matrixâ of }\vec{r}=\begin{bmatrix} 0&-z&y\\z&0&-x\\-y&x&0 \end{bmatrix}$$ $$\mathbf{R}=\exp(\mathbf{C}) = \mathbf{I} + \frac{\sin{\theta}}{\theta} \mathbf{C} + \frac{1-\cos{\theta}}{\theta^2}\mathbf{C}^2$$ (note that $\mathbf{C}^3=-\theta^2\mathbf{C}$ ) (also $\mathbf{R}=\exp(\theta\mathbf{K}) = \mathbf{I} + (\sin{\theta})\mathbf{K} + (1-\cos{\theta})\mathbf{K}^2$ where $\mathbf{K}$ is from the normalized rotation axis, see wikipedia ) where $\frac{\sin\sqrt{x}}{\sqrt{x}}$ and $\frac{1-\cos{\sqrt{x}}}{x}$ expands similarly and adds up to the whole pretty series of $\exp{(\mathbf C)}$ , allowing us to bypass the normalization step. btw, searching for the definition only gives a bunch of tutorials for evaluating its limit when $x \to 0$ (fyi, $\frac 1 2$ ). there's also a related question asking for the dual. sorry for broken English...","['trigonometry', 'special-functions']"
4421721,When does a $\sigma(X)$-measurable function $Y$ filter through $X$?,"Suppose $\sigma(X)$ is the $\sigma$ -algebra generated by a function $X: \Omega \to (E, \mathcal E)$ and suppose that $Y: (\Omega, \sigma(X)) \to (F, \mathcal F)$ is a function to another measurable space and measurable w.r.t. the generated $\sigma$ -algebra $\sigma(X)$ . When does $Y$ factor through $X$ , i.e. when does there exist a function $Z: E \to F$ such that $Y = Z \circ X$ ? When is $Z$ measurable? I know that such $Z$ always exists for discrete random variables $X$ (i.e. $E = $ countable set, $\mathcal E = \mathcal P(E)$ ) as then $\sigma(X) = \{\bigcup_{x \in S} \{X = x\} \mid S \subset E\}$ and $Y$ is constant on each set $\{X = x\}$ . But what about other measurable spaces $(E, \mathcal E)$ , in particular $(\mathbb R, \mathcal B(\mathbb R))$ and Polish spaces? Thank you.","['measure-theory', 'probability-theory']"
4421764,Prove that $\int_0^1xf(x) dx \leq \frac{2}{3}(\int_0^1f(x)dx)^2$,"Let $f:[0,1] \to [0,+\infty)$ be non negative continuous concave function, such that $f(0) = 1$ . Prove that $$\int_0^1xf(x) dx \leq \frac{2}{3}(\int_0^1f(x)dx)^2$$ Work: My professor left us some hints, but I am not sure if I am using them correctly, also I am not sure how to use all of them. Hints are: First hint, substitute $t=\lambda x$ in integral $$F(x)=\int_0^xf(t)dt.$$ What I have got is $$F(x)=\lambda \int_0^xf(\lambda x)dt.$$ Second hint is, using concavity and $f(0)=1$ prove that $$F(x)\geq \frac{x}{2}(1+f(x)).$$ Okay so, for concave functions there is inequality such as this $$f(y)\leq f(x)-f'(x)(y-x).$$ But I haven't got anything from that. Last hint is, using partial integration, conclude that $$\int_0^1 x f(x) dx \leq F(1) - \frac{1}{4} - \frac{1}{2} \int_0^1 x f(x) dx.$$ I think I have proven that, here is what I did: From partial integration I have got $$\int_0^1 x f(x) dx = x F(x){|}_0^1 - \int_0^1 F(x) dx \leq F(1) - \int_0^1 \frac{x}{2} (1+f(x)) dx \leq F(1) - \frac{1}{4} - \frac{1}{2} \int_0^1xf(x) dx$$ From that we have $$\int_0^1x f(x) dx \leq \frac{2}{3} (F(1) - \frac{1}{4}).$$ Using basic inequality $A^2-A+1/4 \geq 0$ we get $F(1) - \frac{1}{4} \leq F^2(1)$ and proof is finished.
Conclusion: My question is how to prove the second hint and where we use substitution here, is that step necessary? Edit: I have realised that substitution I wrote above was not correct, should be $$\int_0^1 f(\lambda)d\lambda.$$ I guess we use it to make integral be $\int_0^1$ . Still haven't proven second hint. Any help will be welcome.","['integration', 'calculus', 'inequality', 'real-analysis']"
4421772,Show that $\operatorname E\left[\|X\|^n\right]<\infty$ implies that the characteristic function of $X$ is $n$-times differentiable,"If $X$ is a real-valued random variable with characteristic function $\varphi_X$ , then we know that $\operatorname E\left[|X|^n\right]<\infty$ implies that $\varphi_X$ is $n$ -times continuously differentiable with derivative $$\varphi_X^{(k)}=\operatorname E\left[({\rm i}X)^ke^{{\rm i}tX}\right]\tag1$$ for all $k=0,\ldots,n$ . Are we able to generalize this result to random variables $Y$ with values in a Banach (or Hilbert) space $E$ ? In this case, the characteristic function is given by $$\varphi_Y(x')=\operatorname E\left[e^{{\rm i}\langle Y,\:x'\rangle}\right]\;\;\;\text{for all }x'\in E'.$$","['stochastic-analysis', 'stochastic-pde', 'probability-theory']"
4421785,Is there a more straightforward way to define the jet bundle?,"Everywhere I have looked, the jet bundle is defined as the fiber bundle of equivalence classes for the partial derivatives of functions from one manifold to another. However, it is easy to see that the 1-jet bundle for real functions on a manifold $M$ is actually just $\Bbb R \times T ^*M$ , and a function $f \in C^\infty(M)$ will have its 1-jet given by $(f(p), \text d f_p)$ . If $f : M \to N$ were instead a smooth function between manifolds, the differential is now a linear operator from $TM \to TN$ , so at every point $p \in M$ , we could identify it with a tensor in $T_p M \otimes T_{f(p)} ^* N$ . Thus, the 1-jet bundle could be given by $N \times (TM \boxtimes TN)$ where $\boxtimes$ is the external tensor product bundle . More specifically, every element in $TM \boxtimes TN$ has the form $$
(p, q, L) \quad (p, q) \in M \times N, L \in T_p M \otimes T_q N,
$$ so the 1-jet of $f$ could be written as $(f(p), (p, f(p), \text d f_p))$ . Now I have two questions: is this construction correct? If it is, how could we generalize it to k-jet bundles?","['jet-bundles', 'differential-geometry']"
4421801,Explicitly describe the cryptomorphism between greedoids and greedy set operators,"A greedoid $\mathcal{F}$ on a finite ground set $E$ is cryptomorphic to an operator $\sigma$ (usually - and improperly - called the closure operator of the greedoid) such that: $X \subseteq \sigma(X)$ ; $X\subseteq Y \subseteq \sigma(X) \implies \sigma(X)=\sigma(Y)$ ; suppose that $x \notin X$ and $z \notin \sigma(X \cup \{x\}) \setminus \{z\})$ for all $z \in X \cup x$ . Then $x \in \sigma(X \cup \{y\}) \implies y \in \sigma(X \cup \{x\})$ . My intention is to explicit describe the cryptomorphism by means of a bijection between the set system of the feasible sets of the greedoid and the ""closure"" operator. To this end, as $X$ is feasible if and only if $x \notin \sigma(X \setminus \{x\})$ for each $x \in X$ (here $\sigma$ denotes the closure operator of the greedoid), I expect that $\mathcal{F}_\sigma:=\{X: \, x \notin \sigma(X \setminus \{x\}) \,\, \forall x \in X \}$ whenever $\sigma$ is a set operator satisfying the properties 1-3 listed above. Now, I want to construct its inverse, namely a map which associates with the feasible sets of a matroid a set operator satisfying the properties 1-3 listed above. Reasoning by analogy with the case of matroids (whose resulting map is $\mathcal{F} \to \Phi_\mathcal{F}$ , where $$
\Phi_\mathcal{F}(X):=\{z \in E \mid \, \exists Y \subseteq X \,\, s.t. Y \in \mathcal{F} \,\, and \,\, Y \cup \{z\} \notin \mathcal{F}\}
$$ for each $X \subseteq E$ ), I surmise that if $\mathcal{F}$ is a matroid, then $$
\phi_\mathcal{F}(X):=X \cup \left\{\begin{array}{llll}
	\{z \in E \setminus X: \, X\cup \{z\} \notin \mathcal{F}\} & {\rm if \,\,} X \in \mathcal{F} \\ 
	\bigcup\limits_{Y \subseteq X,\,\, Y \in \mathcal{F}} \phi_\mathcal{F}(Y)& {\rm otherwise} \\
	\end{array}	 \right.
$$ is the closure operator of $\mathcal{F}$ and it is the inverse map of the correspondence exhibited above. However, I do not manage to show my claim. Is it correct?","['matroids', 'combinatorial-geometry', 'combinatorics', 'discrete-mathematics', 'discrete-optimization']"
4421818,Looking for a cleaner/quicker way to evaluate the integral of a quadratic,"Looking for a clean/quick way to evaluate $$\int_{2-\sqrt{3}}^{2+\sqrt{3}}{ \left(x^2-4x+1\right)\textrm{d}x}=\left.\frac{x^3}{3}-2x^2+x \right|_{2-\sqrt{3}}^{2+\sqrt{3}}$$ So I evaluated all of this out leaving this expression as it was and there was some pretty nice cancelation that led me to the answer $-\sqrt{3}$ . However, this was a question from a contest so I'm expecting that if we factor out the $x$ and then evaluate at the bounds there is something we can do to make the algebra nicer. $$=\left.x(\frac{x^2}{3}-2x+1) \right|_{2-\sqrt{3}}^{2+\sqrt{3}}$$ Anyone see any quick way to do this? Thanks!","['calculus', 'algebra-precalculus']"
4421859,Lyapunov function to prove globally asymptotically stable,"I have the system $x'=-x^3+2y^3$ and $y'=-2xy^2$ . I need to prove that the point $(0,0)$ is asymptotically globally stable. Here's what I did: if we have a Lyapunov function $v(x,y)=ax^2+bxy+cy^2$ , then \begin{align}
\dot{v}(x,y)&=(2ax+by)(-x^3+2y^3)+(2cy+bx)(-2xy^2)\\
&= 2a(-x^4+2xy^3)+b(-yx^3+2y^4-2x^2y^2)+2c(-2xy^3)
\end{align} Now, I can see that if we let $a=c=1$ and $b=0$ , then $v(x,y)=x^2+y^2$ is positive definite and $\dot{v}(x,y)=-2x^4$ is negative semidefinite. However, this shows $(0,0)$ is stable and not asymptotically stable. How do I prove this stronger result? I know it's true because my textbook says the origin is ""at least"" stable. The only idea I had was to write $\dot{v}(x,y)=-(x+y)^4+...$ but this hasn't gotten me very far.","['stability-theory', 'ordinary-differential-equations', 'lyapunov-functions']"
4421862,Is there any easier proof for derivative of $x^e$,I am trying to prove that $\frac{d}{dx}x^e=ex^{e-1}$ . $\displaystyle \frac{d}{dx}x^e=\lim_{h\to 0}\dfrac{(x+h)^e-x^e}{h}=\lim_{h\to 0}x^e \cdot \dfrac {e^{e  \ln \left({1 + \frac h x} \right)} - 1} {e  \ln {\left(1 + \dfrac h x\right)} } \cdot \dfrac {e  \ln {\left(1 + \dfrac h x\right)}} {\dfrac h x} \cdot \dfrac 1 x = e x^{e - 1}$ since $\displaystyle \lim_{x \mathop \to 0} \frac {e^ x - 1} x = 1$ and $\displaystyle \lim_{x \mathop \to 0} \frac { \ln {(1 + x)} } x = 1$ . Is there any way which is simpler? Thanks a lot in advance!,"['calculus', 'derivatives']"
4421869,"Definitions of the Stratonovich integral and why the ""average"" definition is arguably correct","Notations: Herein: $\mathcal{B} := \{B(t)\}_{t \ge 0}$ denotes a standard Brownian motion, with $B(0) = 0$ . $P := \{x_i\}_{i=0}^n$ denotes a partition of the interval $[0,t]$ , with norm defined in the Riemannian sense. $\Delta B_i := B(x_i) - B(x_{i-1})$ . $\Delta x_i := x_i - x_{i-1}$ . $\mathcal{X} := \{X(t)\}_{t \ge 0}$ denotes a Stratonovich-integrable process, in whatever sense that is needed at the time. $\int_0^t X(s) \circ \mathrm{d} B(s)$ denotes the Stratonovich integral. The Conflicting Definitions: There are two conflicting definitions for the Stratonovich integral, which to my understanding are stated below: $$\begin{align*}
\int_0^t X(s) \circ \mathrm{d}B(s) &:= \lim_{\|P\| \to 0} \sum_{i=1}^n \frac{X(x_i) + X(x_{i-1})}{2} \Delta B_i \tag{1} \\
\int_0^t X(s) \circ \mathrm{d}B(s) &:= \lim_{\|P\| \to 0} \sum_{i=1}^n X \left( \frac{x_i + x_{i-1}}{2} \right) \Delta B_i \tag{2}
\end{align*}$$ The First Definition: Definition $(1)$ seems to be motivated by averaging $X(t)$ over each interval induced by $P$ . In fact we could have a ""more general"" integral by considering, for $\lambda \in [0,1]$ , $$\lim_{\|P\| \to 0} \sum_{i=1}^n \Big( (1-\lambda) X(x_i) + \lambda X(x_{i-1}) \Big)\Delta B_i \tag{1'}$$ where ItÃ´ integration arises from $\lambda = 0$ , as an example, and Stratonovich (in the sense of $(1)$ ) under $\lambda=1/2$ . In my reading, I've seen this used by The Wikipedia article on Stratonovich integrals (link) Apparently this is used in Ioannis Karatzas & Steven Shreve's Brownian Motion and Stochastic Calculus (Amazon link) The Encyclopedia of Math website (link) An article by Jonathan Mattingly on The Probability Workbook (link) The Second Definition: Definition $(2)$ seems to be inspired simply by the Riemann-Stieltjes formulation for deterministic functions: $$\int_0^t f(x) \, \mathrm{d} \varphi(x) = \lim_{\|P\| \to 0} \sum_{i=1}^n f(\xi_i) \Delta \varphi_i \tag{2'}$$ (for $\Delta \varphi_i$ defined similarly as for $\Delta B_i$ ). In this case, $\xi_i \in [x_{i-1},x_i]$ . This second definition of the Stratonovich integral seems to be inspired similarly: take $\xi_i$ to be the midpoints, $\varphi$ your Brownian motion, and $f$ comes from your stochastic process. In my reading, I've seen this definition used by: Bernt Ãksendal in Stochastic Differential Equations: An Introduction with Applications (Amazon link) Dr. Peyam on YouTube (video link) Apparently, this arises in Steven Shreve's Stochastic Calculus for Finance (Amazon link) Lewis Smith on this webpage My Question: It does not seem obvious to me that these would be equivalent definitions. Moreover, I've several times seen on Math Stack Exchange (e.g. here ) the claim that $(1)$ is the ""correct"" definition, though seeing it used elsewhere (e.g. this Math Overflow post) no one objects (openly) to $(2)$ . Hence, I'm seeking a proper, definitive answer, because I am very confused: Which is ""correct"" to call the Stratonovich integral? Is it simply a matter of preference? Is there a particular reason to prefer one over the other if there is no definitive answer? Do any results for one definition break under the other? (Such as: does the conversion to an ItÃ´ integral break? What about properties like the chain rule?) ...or am I just totally missing something here?","['stochastic-integrals', 'probability', 'stochastic-processes', 'brownian-motion', 'stochastic-calculus']"
4421905,Compact integral operator on $H^1(\mathbb{R})$,"Consider the operator $$
{\mathcal{L}}v=e^{-x}\int_{0}^x v(y)\, dy.
$$ Is the operator ${\mathcal{L}}$ compact as an operator from $H^1({\mathbb{R}^+})$ to itself? To give some context to the problem above, let me explain why I am interested in it. I have an operator of the form $$
L\equiv{\mathcal{L}}_0+Q,
$$ where ${\mathcal{L}}_0$ is a differential operator I can deal with, i.e. I can compute the spectrum of it, while $Q$ is an integral operator. I would like to prove $Q$ is compact (or not). I was able to prove most of it is compact. The part above given by the integral operator $\mathcal{L}$ is the only term I could not deal with in $Q$ . The difficulty seems to be that it is on $H^1(\mathbb{R^+})$ .","['compact-operators', 'operator-theory', 'integral-operators', 'functional-analysis', 'spectral-theory']"
4421970,"Can a norm on polynomials be ""almost multiplicative"", even for large degrees?","Definition: A norm on a real algebra is called almost multiplicative if there are positive constants $L$ and $U$ such that, for all $f$ and $g$ in the algebra, $$L\lVert f\rVert\cdot\lVert g\rVert\;\leq\;\lVert f\cdot g\rVert\;\leq\;U\lVert f\rVert\cdot\lVert g\rVert;$$ equivalently, if $$0\;<\;\inf_{f,g}\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\;\leq\;\sup_{f,g}\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\;<\;\infty.$$ Is there an almost multiplicative norm on $\mathbb R[x]$ ? The infimum (or supremum) is the same, whether the polynomials $f$ and $g$ have integer coefficients, or rational coefficients (just factor out a common denominator), or real coefficients (take limits of rationals). I don't know if it's the same for complex coefficients (given that the norm respects the complex absolute value: $\lVert e^{i\theta}f\rVert=\lVert f\rVert$ ). Denote by $\mathbb R[x]_n$ the space of polynomials of degree $n$ or less. This has finite dimension $n+1$ . If we consider multiplication $\mathbb R[x]_m\times\mathbb R[x]_n\to\mathbb R[x]_{m+n}$ , and take the infimum/supremum over these subspaces, then any norm is almost multiplicative. That is because the unit sphere in finite dimensions is compact; the infimum is actually a minimum, and the supremum is actually a maximum. The minimizing polynomials are non-zero, so their product is non-zero: $\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}>0$ . The maximizing polynomials have a defined product, which has finite norm: $\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}<\infty$ . Of course that argument doesn't work for the whole infinite-dimensional space $\mathbb R[x]$ . No norm on polynomials is actually multiplicative; the infimum is not equal to the supremum. Multiplicative norm on $\mathbb{R}[X]$. These bounds on norms of products are useful for factoring polynomials with integer coefficients. Suppose $f\cdot g\in\mathbb Z[x]_n\backslash\{0\}$ is known but $f$ and $g$ are not known. Let $L$ be a lower bound for products as described above. Let $\varepsilon>0$ be the minimum norm on $\mathbb Z[x]_n\backslash\{0\}$ ; this exists because $\mathbb Z[x]_n$ is a lattice in $\mathbb R[x]_n$ , and a lattice intersected with a ball is a finite set. Then there are only finitely many possible factors $f$ , because $$\lVert f\rVert\;\leq\;\frac{\lVert f\rVert\cdot\lVert g\rVert}{\varepsilon}\;\leq\;\frac{\lVert f\cdot g\rVert}{\varepsilon L}.$$ Relevant links: Bombieri Norm Bounds on Factors in $\mathbb Z[x]$ (Abbott) Global optimization: a model problem , or A Model Problem for Global optimization (Rump) I considered weighted $\infty$ -norms; norms of the form $$\Bigg\lVert\sum_ka_kx^k\Bigg\rVert_c=\max_k(c_k|a_k|)$$ where $c=(c_0,c_1,c_2,\cdots)$ is a sequence of positive numbers. The upper bound $\lVert f\cdot g\rVert\leq U\lVert f\rVert\lVert g\rVert$ then is saying that $$\max_l\left|c_l\sum_{j+k=l}a_jb_k\right|\leq U\max_j|c_ja_j|\max_k|c_kb_k|.$$ By scaling the coefficients, $a_j'=c_ja_j$ and $b_k'=c_kb_k$ , this is equivalent to $$\max_l\left|\sum_{j+k=l}\frac{c_l}{c_jc_k}a_j'b_k'\right|\leq U\max_j|a_j'|\max_k|b_k'|.$$ By applying the triangle inequality (for one direction, and by taking particular examples with $a_j',b_k'\in\{0,1\}$ for the other direction), this is equivalent to $$\sum_{j+k=l}\frac{c_l}{c_jc_k}\leq U$$ for every $l\in\mathbb N$ . For the constant weight $c_k=1$ , the $l$ 'th sum here is just $\sum_{j+k=l}(1)=l+1$ which is unbounded. For the factorial weights $c_k=k!$ , the $l$ 'th sum is $$\sum_{j+k=l}\frac{l!}{j!k!}=\sum_k\binom{l}{k}=2^l$$ which is also unbounded. For the inverse factorial weights $c_k=1/k!$ , the $l$ 'th sum is $\sum_k1/\binom lk$ , which has maximum $8/3$ (at $l=3$ or $4$ ) and limit $2$ (as $l\to\infty$ ). So we can take $U=8/3$ as an upper bound. But I think there is no lower bound $L>0$ , considering for example $f_n(x)=(x+1)^n$ and $g_n(x)=(x-1)^n$ (though I'm not sure the norm ratio actually converges to $0$ as $n\to\infty$ ). For the square weights $c_k=(k+1)^2$ , the $l$ 'th sum is $\sum_k\left(\frac{(l+1)}{(l-k+1)(k+1)}\right)^2$ , which seems to have maximum $3.5171$ (at $l=19$ ), and has limit $\pi^2/3$ . So there is an upper bound. It is harder to find lower bounds. I don't know if there's any norm on $\mathbb R[x]$ for which $\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\geq L>0$ . Even if there are norms with lower bounds as well as norms with upper bounds, there isn't necessarily a single norm which is bounded both ways.","['normed-spaces', 'polynomials', 'functional-analysis', 'upper-lower-bounds', 'supremum-and-infimum']"
4422022,Largest possible value for a math test,"Last week, Adam and Bronson sat for a Mathematics test, of which the full mark was 100. Adam scored x marks and Bronson scored y marks, where x and y are whole numbers. Given that 8x = 5y, find the largest possible value of Adam's score. I get the answer x = 60, y = 96 via trial and error but whats the correct way to solve this question?","['algebra-precalculus', 'ratio']"
4422037,Can we prove that $\int_0^{2\pi} e^{r \cos \theta} \cos (r \sin \theta+n \theta) d \theta=0$ without complex analysis?,"In textbooks on complex analysis, a typical example using Cauchy Integral Theorem is shown that $$
\int_{0}^{2 \pi} e^{r \cos \theta} \cos (r \sin \theta+\theta) d \theta=0
$$ Later, I generalized it in my answer that $$\int_{0}^{2 \pi} e^{r \cos \theta} \cos (r \sin \theta+n\theta) d \theta=0,$$ where $r\in R^+,n\in N.$ However, I want to investigate the integral without complex analysis. So I started to try some simple cases using compound angle formula by integration by parts. $$
\begin{aligned}
I_1=\int e^{r \cos \theta} \cos (r\sin \theta+\theta) d \theta =& \int e^{r \cos \theta}[\cos (r\sin \theta) \cos \theta-\sin (r \sin \theta) \sin \theta] d \theta \\
=& \int e^{r \cos \theta} \cos (r\sin \theta) \cos \theta d \theta-  \int e^{r\cos \theta} \sin (r \sin \theta) \sin \theta d \theta
\end{aligned}
$$ Fortunately, \begin{aligned}  \int e^{r\cos \theta} \sin (r \sin \theta) \sin \theta d \theta &\stackrel{IBP}{=}  
-\frac{1}{r} \int \sin (r \sin \theta) d\left(e^{r \cos \theta}\right)\\&=-\frac{e^{r \cos \theta} \sin (r\sin \theta)}{r}+\int e^{r \cos \theta} \cos (r\sin \theta)\cos \theta d\theta\\
\therefore \int e^{r\cos \theta} \sin (r \sin \theta) \sin \theta d \theta&=\frac{e^{r\cos \theta} \sin (r\sin \theta)}{r}+C_1
\end{aligned} Applying the same technique decreases $n$ to $n-1$ yields \begin{aligned}
I_{n} &=\int e^{r \cos \theta} \cos (r \sin \theta+n \theta) d \theta\\
&=\int e^{r \cos \theta}[\cos (r \sin \theta+(n-1) \theta) \cos \theta-\sin (r \sin \theta+(n-1) \theta)\sin \theta] d \theta\\
&=\int e^{r \cos \theta}[\cos (r \sin \theta+(n-1) \theta) \cos \theta d \theta-\int e^{r \cos \theta} \sin (r \sin \theta+(n-1) \theta) \sin \theta d \theta
\end{aligned} Applying integration by parts to the last integral yields \begin{aligned}&\int e^{r\cos \theta} \sin (r \sin \theta+(n-1) \theta) \sin \theta d \theta\\=& -\frac{1}{r} \int \sin (r \sin \theta+(n-1) \theta) d\left(e^{r \cos \theta}\right)\\=&-\frac{1}{r}\left[e^{r \cos \theta} \sin (r \sin \theta+(n-1) \theta)\right] +\frac{1}{r} \int e^{r \cos \theta} \cos (r\sin \theta+(n-1) \theta)(r\cos \theta+(n-1)) d \theta \\=&-\frac{1}{r}\left[e^{r \cos \theta} \sin (r \sin \theta+(n-1) \theta)\right] + \int e^{r \cos \theta} \cos (r \sin \theta+(n-1) \theta) \cos \theta d \theta+\frac{n-1}{r} I_{n-1}\end{aligned} Putting it back yields the reduction formula $$\boxed{I_n = \frac{1}{r}\left[e^{r \cos \theta} \sin (r \sin \theta+(n-1) \theta)-(n-1)I_{n-1}\right]}$$ Now letâs use the reduction formula and Mathematical Induction to prove that $$J_n:=\int_0^{2\pi} e^{r \cos \theta} \cos (r \sin \theta+n \theta) d \theta=0$$ First of all, $$J_1=\left[I_1\right]_0^{2\pi}= \left[ \frac{e^{r \cos \theta} \sin (r \sin \theta)}{r}\right] _0^{2\pi}=0$$ Now assume it is true for some $k$ i.e. $J_k=0$ , then $$
J_{k+1}=\frac{1}{r}\left(\left[e^{r \cos \theta} \sin (r\sin \theta+k \theta)\right]_{0}^{2 \pi}-k J _k\right)=0
$$ Therefore it is also true for $n=k+1$ and hence by the principle of Mathematical Induction, we have $$
\boxed{\int_{0}^{2 \pi} e^{r \cos \theta} \cos (r \sin \theta+n \theta) d \theta
=0}$$ For reference, $$
\begin{aligned}
I_{2} &=\frac{1}{r}\left[e^{r \cos \theta} \sin (r \sin \theta+\theta)-I_{1}\right] \\
&=\frac{1}{r}\left[e^{r \cos \theta} \sin (r \sin \theta+\theta)-e^{r \cos \theta} \sin (r \sin \theta)\right]+C_2
\end{aligned}
$$ $$
\begin{aligned}
I_{3} &=\frac{1}{r}\left[e^{r\cos \theta}(\sin (r \sin \theta+2 \theta))-2 I_{2}\right] \\
& =\frac{1}{r^{2}}\left[r e^{r \cos \theta}(\sin (r\sin \theta+2 \theta))-2 e^{r \cos \theta } \sin (r \sin \theta+\theta)-2 e^{r \cos \theta} \sin (r\sin \theta)\right]+C_3
\end{aligned}
$$ Question: Is there an alternative proof other than MI?","['integration', 'trigonometry', 'trigonometric-integrals']"
4422112,Finding $\sum_{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n2^n \binom{2n}{n}}$,"I want to find the closed form of: $\displaystyle \tag*{} \sum \limits _{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n2^n \binom{2n}{n}}$ Where $H_{k}$ is $k^{\text{th}}$ harmonic number I tried to expand the numerator (Harmonic numbers) in terms of integral, to get: $\displaystyle \tag*{} \sum \limits_{n=1}^{\infty} \frac{(-1)^n}{n2^n\binom{2n}{n}} \int _{0}^{1} \frac{x^n - x^{2n}}{1-x} \ \mathrm dx$ And I found that with the help of series expansion of $\sin^{-1}(x)$ and subsituting $x = i \sqrt{x} /8 $ where $i^2=1$ $\displaystyle \tag*{} -2(\sinh^{-1} (\sqrt{x}/8))^2 = \sum \limits_{n=1}^{\infty} \frac{(-1)^nx^n}{n^22^n \binom{2n}{n}} $ But this has $n^2$ in the denominator, which makes it complicated. EDIT: we can eliminate $n^2$ by differentiating and multiplying by $x$ as mentioned in the comments. But now, how can we solve our sum since $H_{2n}-H_n$ is numerator? And I have the general formula for generating sum: $ \displaystyle \tag*{} \sum \limits _{n=1}^{\infty} \frac{x^n}{n^y \binom{2n}{n}}$ And this doesn't have $n$ in the denominator and also it has closed-form $\forall \ y \geq 2$ Maybe if there is a way of expressing the denominator in the form integral, the sum can be changed in evaluating the double integral. I think there are other easy ways (such as using Hypergeometric functions)? Any help would be appreciated. EDIT 2: From the help of comments and a quora user, $\DeclareMathOperator{\arcsinh}{arcsinh}$ By @Bertrand87, we have: $\displaystyle \tag{1} H_{k} - H_{2k} + \ln (2) = \int _{0}^{1} \frac{x^{2k}}{1+x} \ \mathrm dx$ To make use of this, we express our sum as follows: $\displaystyle \tag*{} S = \sum \limits_{k=1}^{\infty} \frac{(-1)^k(H_{2k}-H_k - \ln2)}{k2^k \binom{2k}{k}}  + \sum \limits_{k=1}^{\infty} \frac{(-1)^k(\ln2)}{k2^k \binom{2k}{k}}$ We know $\displaystyle \tag*{} 2\arcsin^2(x) = \sum \limits_{k=1}^{\infty} \frac{(2x)^{2k}}{k^2 \binom{2k}{k}}$ We differentiate both sides w.r.t $x$ both sides, $\displaystyle \tag*{} \frac{2 \arcsin(x)}{\sqrt{1-x^2}} = \sum \limits_{k=1}^{\infty} \frac{(2x)^{2k-1}}{k \binom{2k}{k}}$ Now, we multiply both sides by $(2x)$ and define $x:= ix/ \sqrt{8}$ to get: $\displaystyle \tag{2} \frac{-2x \arcsinh (x/ \sqrt {8})}{\sqrt{8}\sqrt{1+x^2/8}} = \sum \limits_{k=1}^{\infty} \frac{(-1)^k x^{2k}}{k2^k \binom{2k}{k}}$ We now multiply both sides by $-1/(1+x)$ and integrate from $0$ to $1$ and arrive at: $\displaystyle \tag*{} \frac{2}{\sqrt {8}}\int_{0}^{1}\frac{x\arcsinh(x/ \sqrt{8})}{\sqrt{1+x^2/8} (1+x)} \ \mathrm dx = \sum \limits_{k=1}^{\infty} \frac{(-1)^k(H_{2k}-H_k - \ln2)}{k2^k \binom{2k}{k}}$ Similarly, from $(2)$ if we let $x=1$ and multiply both sides by $\ln 2$ , it yields: $\displaystyle \tag*{} \frac{-2 \arcsinh (1/ \sqrt{8}) \ln 2}{ \sqrt{8} \sqrt{1 + 1/8}} =\sum \limits_{k=1}^{\infty} \frac{(-1)^k(\ln2)}{k2^k \binom{2k}{k}} \approx -0.1601$ Now, our only problem is to evaluate the integral: $\displaystyle \tag*{} \boxed{\frac{2}{\sqrt {8}}\int_{0}^{1}\frac{x\arcsinh(x/ \sqrt{8})}{\sqrt{1+x^2/8} (1+x)} \ \mathrm dx} $ Can anyone help me with this integral?","['integration', 'summation', 'real-analysis', 'harmonic-numbers', 'sequences-and-series']"
4422128,Can we be certain that the only nonzero differentiable function satisfying $g(x+y)=\frac{g(x)+g(y)}{1+g(x)g(y)}$ and $|g|\lt 1$ is $\tanh(kx)$?,"The following question is a question aimed for the Further Maths UK syllabus (it is a Step $2$ question)- i.e. not very formal, so I am certain my solution to the question is correct as the question intended it, but I am uncertain whether it is formally the only, or the right, solution. I am especially uncertain about my application of the Picard existence & uniqueness theorem. The problem: The function $g$ has derivative $g'$ and satisfies: $$g(x+y)=\frac{g(x)+g(y)}{1+g(x)g(y)}$$ For all $x$ and $y$ , $|g(x)|\lt 1$ for all $x$ , and $g'(0)=k\neq0$ . Find $g'(x)$ in terms of $g(x)$ and $k$ , and hence find $g(x)$ in terms of $x$ and $k$ . My solution (but is it unique, and is it rigorously done?): Consider the difference quotient for $y\neq 0$ , some $x\in\Bbb R$ : $$\tag{1}\frac{g(x+y)-g(x)}{y}=(1-g^2(x))\cdot\frac{g(y)}{y(1+g(x)g(y))}$$ First note that $|g(x)|\lt1$ gives $(1-g^2(x))\neq0$ and $1+g(x)g(y)\neq0$ . Secondly, if $g'(0)\neq0$ we must have that the numerator of the difference quotient must be nonzero in some small deleted neighbourhood of $0$ (else we could take a convergent sequence $y_n\to0$ where $g(y_n)=0$ for all $n$ , and then $g'(0)=0$ if the limit exists) so if we set $x=0$ , we may divide by $g(y)$ in the above with $y$ close to $0$ but $g(y)\neq0$ : $$\frac{g(y)-g(0)}{y}=(1-g^2(0))\cdot\frac{1}{\frac{y}{g(y)}+y\cdot g(0)}$$ For the above limit as $y\to0$ to exist, the limit as $y\to0$ of the denominator must exist: as $\lim_{y\to0}y\cdot g(0)$ exists (and equals $0$ ) we conclude $\lim_{y\to0}\frac{y}{g(y)}$ must exist, giving: $$\begin{align}k=\lim_{y\to0}\frac{g(y)-g(0)}{y}&=(1-g^2(0))\cdot\frac{1}{\lim_{y\to0}\frac{y}{g(y)}}\\\lim_{y\to0}\frac{g(y)}{y}&=\frac{k}{(1-g^2(0))}\end{align}$$ This further implies that $g(y)\to0$ as $y\to0$ and by continuity of differentiable functions $g(0)=0$ , so that: $$k=\lim_{y\to0}\frac{g(y)}{y}=\lim_{y\to0}\frac{g(y)-g(0)}{y}$$ Using the same argument that $g(y)\neq 0$ in some small deleted neighbourhood of $0$ and dividing by $g(y)$ in $(1)$ , for now arbitrary $x$ , we get: $$g'(x)=\lim_{y\to0}\frac{g(x+y)-g(x)}{y}=(1-g^2(x))\cdot\lim_{y\to0}\frac{g(y)}{y}=(1-g^2(x))\cdot k$$ The differential equation $g'(x)=k(1-g^2(x))$ has a solution in $g(x)=\tanh(kx)$ . I think that by the Picard existence theorem, the solution is unique since $|g(x)|\lt 1$ gives a Lipschitz bound on $k(1-g^2(x))$ , although even then we only have uniqueness potentially in some small interval around $0$ . Can we really conclude $g(x)=\tanh(kx)$ with certainty? And just how necessary is the condition $|g(x)|\lt1$ ?","['functional-equations', 'ordinary-differential-equations', 'hyperbolic-functions', 'real-analysis', 'solution-verification']"
4422136,Any hint on how to prove that the two given conditions may not be fulfilled simultaneously?,"I have these two conditions for $0<a<2\pi$ and $b>0$ and real. $$ \sin \left(\frac{\pi  a}{2 (\pi -a)}\right)=\frac{a }{2 \pi -a}\;\sin \left(\frac{\pi  (a-2 \pi )}{2 (a-\pi )}\right)+\frac{4 b }{2 \pi -a}\;\sin \left(\frac{\pi ^2}{2 (\pi -a)}\right)  $$ and $$ \cos \left(\frac{\pi  a}{2 (\pi -a)}\right)=\frac{a}{2 \pi -a}  \;\cos \left(\frac{\pi  (a-2 \pi )}{2 (a-\pi )}\right)\qquad\qquad\qquad \qquad\quad\qquad$$ As I check them numerically, I see that these two conditions may not be fulfilled simultaneously; Are there any hopes to prove this analytically?","['calculus', 'solution-verification', 'trigonometry', 'real-analysis']"
4422152,What is the difference between a space dimension and a time dimension?,The simplest case is obviously 4D spacetime composed of 3 space dimensions and 1 time dimension. In some talks i stumbled across physicists and mathematicians who talked about spaces in which you only work with space dimensions or only with time dimensions. So I woundered what excatly is the mathematical difference between space and time dimensions.,"['metric-spaces', 'dimensional-analysis', 'geometry', 'differential-geometry']"
4422267,"Prove that $\sum_{j=1}^{n} f(\frac{n}{j}) = n^2$, where $f(x)$ is the number of coprime pairs $(a, b)$ for which $1 â¤ a â¤ x$ and $1 â¤ b â¤ x$.","For each real number $x > 0$ let $f(x)$ be the number of coprime pairs $(a,b)$ where $a$ and $b$ are integers and $1 â¤ a â¤ x$ and $1 â¤ b â¤ x$ . For example $f(\frac{5}{2}) = 3$ because there exist exactly three coprime pairs $(1,1), (1,2), (2,1)$ where $1 â¤ a â¤ \frac{5}{2} = 2,5$ and $1 â¤ b â¤ \frac{5}{2} = 2,5$ . If $n$ is a positive integer then calculate the sum: $\sum_{j=1}^{n} f(\frac{n}{j}) = f(n) + f(\frac{n}{2}) + f(\frac{n}{3}) + f(\frac{n}{4}) + ... + f(\frac{n}{n})$ . We are supposed to use combinatorics to solve this. I calculated some sums by hand and figured out that $f(x)$ outputs A018805. It seems that $\sum_{j=1}^{n} f(\frac{n}{j}) = n^2$ but I am having problems proving it. If we use double counting, $n^2$ counts all ordered pairs $(a,b)$ where $a$ and $b$ are integers and $1 â¤ a â¤ n$ and $1 â¤ b â¤ n$ . Then $\sum_{j=1}^{n} f(\frac{n}{j})$ should count the same but with more detail. For $j = 1$ we have $f(n)$ which counts all the ordered pairs but with the restriction that they have to be coprime. We can partition the set of all ordered pairs into those that are coprime and those that are not. Then that would mean that if we prove that $\sum_{j=2}^{n} f(\frac{n}{j})$ counts all the ordered pairs that are not coprime then the problem would be solved. That's all I have figured out for now. Keep in mind again that this should be done using combinatorics.","['combinatorics', 'discrete-mathematics']"
4422306,Show that $\mathcal{L}(X_M ) \alpha_X=0$,"Let $M$ be a compact manifold on which act a compact lie group $G$ . Let $\langle\cdot,\cdot \rangle$ be a $G$ -invariant Riemannian metric on M. Let $X \in \mathfrak{g}$ , we denote $X_M$ the vector field on $M$ defined by $$X_M(m) = \frac{d}{dt} \Bigg\vert_{t=0} e^{-tX}.m, \qquad m \in M.$$ Consider the $1$ -form $\alpha_X$ defined by $$\alpha_X(Y): =\langle X_M, Y\rangle , \qquad Y \in TM. $$ $\textbf{Question:}$ Prove that $\mathcal{L} (X_M)\alpha_X  = 0.$ What I've tried so far is the following:
Let $\phi_t: M \rightarrow M$ be the integral curve of $X_M.$ (By the definition of $X_M$ , we know that $\phi_t(m)= e^{-tX}.m$ . ) Applying the definition of the Lie derivative, I get for $m \in M$ and $Y \in T_mM$ \begin{align*}
(\mathcal{L} (X_M)\alpha_X)_m(Y) 
&= \frac{d}{dt} \Bigg\vert_{t=0} (\phi^*_t(\alpha_X))_m(Y))\\
&= \frac{d}{dt} \Bigg\vert_{t=0} {(\alpha_X)}_{\phi_t(m)}({(\phi_t)}_*(Y)) \\
&= \frac{d}{dt} \Bigg\vert_{t=0} \langle X_M(\phi_t(m)), (\phi_t)_*(Y) \rangle \\
&= \left\langle {\frac{d}{dt}}_{t=0}  X_M(\phi_t(m)),Y \right\rangle + \left\langle X_M(m), {\frac{d}{dt}}_{t=0} (\phi_t)_*(Y) \right\rangle.
\end{align*} From here, all what I can say is that $$\frac{d}{dt} \Bigg\vert_{t=0}  X_M(\phi_t(m))= \frac{d}{dt}\Bigg\vert_{t=0} \frac{d}{ds} \Bigg\vert_{s=0} e^{-(t+s)X}.m $$ and $$ \frac{d}{dt} \Bigg\vert_{t=0} (\phi_t)_*(Y) = [X_M(m),Y].$$ But, I don't know how to continue. Any help please!","['ordinary-differential-equations', 'lie-derivative', 'group-actions', 'lie-groups', 'differential-geometry']"
4422336,Prove that nim multiplication is associative and distributive,"Let $\oplus$ represent nim-addition, and let $\otimes$ represent nim-multiplication. We define nim-addition as bitwise exclusive or. We define nim-multiplication recursively as follows: $$
x\otimes y=\text{mex}\{(a\otimes x)\oplus (b\otimes y)\oplus (a\otimes b):0\leq a<x, 0\leq b<y\},
$$ where the $\text{mex}$ of a set $S$ is the minimum nonnegative integer that is not in $S$ . Prove that $(x\otimes y)\otimes z=x\otimes(y\otimes z)$ for all $x,y,z$ ; and $x\otimes(y\oplus z)=(x\otimes) y\oplus (x\otimes z)$ for all $x,y,z$ . In the book I'm reading it says that this is a routine induction. However, I'm not so confident in how to do this. Starting with associativity, my instict was to expand $(x\otimes y)\otimes z$ into $$
\text{mex}\{(a\otimes(x\otimes y))\oplus(b\otimes z)\oplus(a\otimes b):a<x\otimes y, b<z\},
$$ and then try to rearrange this into a form that is similar to the expansion for $x\otimes(y\otimes z)$ . But I cannot see a way of doing this. What am I missing for this 'routine' induction? Any help appreciated!","['induction', 'combinatorics', 'combinatorial-game-theory']"
4422371,Semicontinuity w.r.t. weak convergence of probability measures,"Let $(S, \mathcal{S})$ be a Polish space and consider the space $\mathcal{P}(S)$ of all Borel probability measures on $S$ endowed with the topology of weak convergence of measures. We know that if $f:S\to\mathbb{R}$ is continous and bounded then the map $$\nu\in\mathcal{P}(S) \to \int f d\nu\in\mathbb{R}$$ is continous. What about (upper/lower) semicontinuity? Is there a weaker condition on a continous $f$ that ensures (upper/lower) semicontinuity of the integral operator?
Thanks to anyone that will help!","['continuity', 'measure-theory', 'probability-theory', 'weak-convergence']"
4422396,Every normed space with countable dimension is separable.,"I am trying to figure out if this reult from functional analysis is true. ""Every normed space with countable Hamel dimension is separable."" I know that this hold if the space is of finite dimension and i know that proof using the density of rationals in R, also I am pretty sure that this is true(for the space being of countable dimension) and that the proof of it goes quite similarly as if the space was finite dimensional, with small changes. I just wanted some help for confirmation, not even the proof, just if this is indeed true.","['separable-spaces', 'normed-spaces', 'functional-analysis']"
4422442,Finding $\displaystyle \sum \limits _{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n(2)^n \binom{2n}{n}}$,I want to find the closed form of: $\displaystyle \tag*{} \sum \limits _{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n(2)^n \binom{2n}{n}}$ Where $H_{k}$ is $k^{\text{th}}$ harmonic number Can anyone tell me the value of the sum using Mathematica?,"['summation', 'functions']"
4422454,Does a generalized difference of powers formula exist?,"The identity $$
\left(\frac{n+1}{2}\right)^2-\left(\frac{n-1}{2}\right)^2=n
$$ can be used to represent any number as difference of two squares. (Note that this formula gives integer values when $n$ is odd.) I have been looking for a similar formula for cubes, quartics, etc., but have been unsuccessful in finding them, which leads me to believe that this problem is related to Fermat's Last Theorem, and can be disproven with it. I have been using the similar structure and attempting to find one by trial and error. Here's some example attempts: (that don't work) $$
\left(\frac{n+1}{3}\right)^3-\left(\frac{n-1}{3}\right)^3=n.
$$ $$
\left(\frac{n!+1/3}{n!}\right)^3-\left(\frac{n!-1/3}{n!}\right)^3=n.
$$ After much effort, it seems formulas for higher powers do not exist, so how might one prove it?","['number-theory', 'square-numbers', 'polynomials', 'elementary-number-theory']"
4422588,Why does compound interest exist?,"Background My understanding is that compound interest arises in the following way: The bank offers its clients some interest rate $r$ on an account with principal $P$ that yields $rP$ after some time $t_0$ . But clients, not wanting to wait for $t_0$ to pass before seeing any returns, ask if they can instead have some fraction of the full return every time interval $t_0 / n$ , where $n$ is some natural number. Reasonably, the bank agrees to pay out $r/n$ times the current balance every $t_0 / n$ . The amount of money $A(t)$ in an account with principal $P$ after time $t$ is then the usual compound interest formula \begin{equation}
A(t) = P\left(1 + \frac{r}{n}\right)^{\frac{nt}{t_0}} \label{comp-int}\tag{1}
\end{equation} The Problem? While the deal that the bank offers may seem reasonable for the bank, it results in the interest earned after time $t_0$ exceeding the original offer. Orignally, after $t_0$ , the client would have a total balance of $(1 + r)P$ . With compound interest, after $t_0$ , the client would have a total balance of $A(t_0) = P(1 + r/n)^n$ . The bank overpays (compared to its original promise) by a ratio of $$
\frac{\left(1 + \frac{r}{n}\right)^n}{1 + r}
$$ which is bounded by $$
1 \leq \frac{\left(1 + \frac{r}{n}\right)^n}{1 + r} \leq \frac{e^r}{1 + r} \label{bound}\tag{2}
$$ The problem, it seems to me, is that the offer is all downside for the bank. They give their clients money more often and end up giving them more money than the original offer. Why would a bank ever offer this option? An Alternative? If there were no other reasonable way to compute a partial return on an investment, then of course client demand would eventually force banks to make the compound interest offer. But there is a readily available and (to me) perfectly reasonable alternative. Why not just compute the current balance as $$
A(t) = P(1 + r)^\frac{t}{t_0} \label{alt}\tag{3}
$$ This has a few advantages. It doesn't require a new parameter $n$ . It can be calculated continuously, but unlike the typical limit as $n$ goes to infinity (i.e. $Pe^{rt/t_0}$ ) it doesn't result in the bank overpaying. That is, $A(t_0) = P(1 + r)$ , which was the original offer. Speculation I would speculate that the reason interest isn't calculated as in \ref{alt} is because it doesn't make sense to the mathematical layman. To the layman, the fair amount to be paid after time $t_0/n$ is $r/n$ times the current balance so that the new balance is $1 + r/n$ times the old balance â you just divide both by $n$ . But the mathematically correct (I claim) way to evenly divide the payments would be to multiply the current balance by $(1 + r)^\frac{1}{n}$ every $t_0/n$ , which seems more complicated and results in an effective interest rate less than $r/n$ per $t_0/n$ . I can imagine that would be a tough sell to someone who doesn't understand the math. Instead the bank opts for the more approachable $1 + r/n$ factor, with the understanding that the deviation from the original offer is bounded (as \ref{bound} shows) and so an acceptable loss if clients are more likely to accept the offer. Aside: musicians (or at least piano tuners) have to understand this math. The correct ratio between half-steps for equal temperament is $2^{1/12}$ , not $1 + \frac{1}{12}$ . While the latter would be somewhat close to the correct tuning, it would lead to an octave that is about $31\%$ sharp. TL;DR Why is compound interest calculated with \ref{comp-int} and not the simpler and (I argue) more mathematically correct \ref{alt}?","['algebra-precalculus', 'math-history', 'soft-question', 'finance']"
4422641,Is the induced Fisher information metric equal to the Fisher metric of a submanifold?,"If $M = \{p_\theta : \theta \in \Theta \subset \mathbb R^d \}$ is a statistical manifold parametrized by $\theta$ , with the Fisher information metric \begin{equation*}
g_{ij}(\theta) = \int_{\mathcal X} p_\theta(x) \partial_{i}\log(p_\theta(x)) \partial_{j}\log(p_\theta(x)) dx
\end{equation*} and we take a submanifold $N \subset M$ , then $N$ can be considered as a Riemannian submanifold with the induced metric. But if $N$ is a submanifold parametrized by some parameters $\eta \in H\subset \mathbb R^k$ with $k\le d$ , then there is another construction, which is the Fisher metric of $N$ with parameters $\eta$ . My question: are these two metrics the same?","['statistics', 'geometric-probability', 'information-geometry', 'fisher-information', 'differential-geometry']"
4422654,"Connections between the different characterizations of ideals? (Dedekind's ideal numbers, quotientable subsets, kernels)","Two answers here present two very different approaches to motivating ideals. The first presents the historical motivation for ideals, namely Kummer's idea that in some rings like $\mathbb Z[\sqrt{-5}]$ there are somehow ""ideal numbers"" that allow us to factor products like $2 \cdot 3 = 6 = (1+\sqrt{-5})(1-\sqrt{-5})$ further, and more importantly, uniquely. The second presents the completely abstract construction of an ideal $I$ of ring $R$ to be exactly a subset that $a \sim b \iff a-b\in I$ is an equivalence relation s.t. $R/{\sim}$ inherits the ring structure of $R$ ; or as that answer put it, ""Equations in $R$ give corresponding equations between equivalence classes in $R/{\sim}$ "". An answer here phrased this quotient idea as ""You can think of ideals as subsets that behave similarly to zero"". Again in Intuition behind ""ideal"" , Qiaochu Yuan says ""To me ideals are kernels of ring homomorphisms"". This point of view is very connected to the quotient point of view presented above, essentially by the 1st isomorphism theorem . It also makes rigorous the above idea that ""ideals are subsets that behave similarly to zero"", since kernels are literally the set of elements that get mapped to $0$ by a ring homomorphism. My question is how to connect this latter, more ""abstract"" point of view with the historical/Kummer-Dedekind point of view? I don't really have a good intuition/picture for why the set of all elements ""divisible by some (ideal) number"" should be exactly a subset of elements $S$ s.t. we can ""do exactly the same kind of arithmetic"" with cosets $\{r+S\}_{r\in R}$ as we can with elements $\{r\}_{r\in R}$ .","['algebraic-number-theory', 'ring-theory', 'abstract-algebra', 'intuition', 'ideals']"
4422664,Using Fourier series to compute $1-\frac1{3^2}-\frac1{5^2}+\frac1{7^2}+\cdots$,"(Not to be confused with Catalan's constant ) Evaluate the infinite sum $$S = \sum_{n=0}^\infty \frac{(-1)^{T_n}}{(2n+1)^2} = 1 - \frac1{3^2} - \frac1{5^2} + \frac1{7^2} + \frac1{9^2} - \frac1{11^2} - \frac1{13^2} + \frac1{15^2} + \cdots$$ where $T_n = \frac{n(n+1)}2$ is the $n$ -th triangular number. Equivalently, with $\omega = e^{i\frac\pi4}$ , we can write the series as $$S = \frac1{2\sqrt2} \sum_{n=1}^\infty \frac{\omega^n - \omega^{3n} - \omega^{5n} + \omega^{7n}}{n^2}$$ or $$S = \sum_{n=1}^\infty \frac{a_n}{n^2} \quad \text{ where } \quad \begin{cases}a_{8n}=a_{8n+2}=a_{8n+4}=a_{8n+6}=0\\a_{8n+1}=a_{8n+7}=+1\\a_{8n+3}=a_{8n+5}=-1\end{cases}$$ I see a linear combination of $\mathrm{Li}_2(\cdot)$ terms but I'm not aware of or otherwise familiar with any identities that might be helpful in simplifying the sum. Borrowing inspiration from some other questions, I am hoping to cook up a periodic function $f(x)$ so that I can exploit its Fourier series to evaluate $S$ . Or possibly the sums that make up $S$ . For instance, I've started the hunt with the cosine expansion of $f(x)=\cos\left(\frac x8\right)$ on $[-\pi,\pi]$ , given by $$\cos\left(\frac x8\right) = \frac8\pi \sin\left(\frac\pi8\right) - \frac8\pi \sin\left(\frac\pi8\right) \sum_{n=1}^\infty \left(\frac{(-1)^n}{8n-1} - \frac{(-1)^n}{8n+1}\right) \cos(nx)$$ as well as $\cos\left(\frac{3x}8\right)$ , which has an expansion containing denominators with $8n\pm3$ . I don't know whether having $8n-1$ and $8n-3$ will be a problem, since there is some correspondence between $8n-1$ and $8n+7$ , as well as $8n-3$ and $8n+5$ . For posterity, I also considered the sine expansion of $f$ as well as the co/sine expansions of $\sin\left(\frac x8\right)$ . $$\begin{align*}
\cos\left(\frac x8\right) &= \frac8\pi \sum_{n=1}^\infty \left(\frac{1-(-1)^n \cos\left(\frac\pi8\right)}{8n-1} + \frac{1-(-1)^n \cos\left(\frac\pi8\right)}{8n+1}\right) \sin(nx) \\[1ex]
\sin\left(\frac x8\right) &= \frac{16}\pi \sin^2\left(\frac\pi{16}\right) - \frac8\pi \sum_{n=1}^\infty \left(\frac{1-(-1)^n \cos\left(\frac\pi8\right)}{8n-1} - \frac{1 - (-1)^n \cos\left(\frac\pi8\right)}{8n+1}\right) \cos(nx)\\[1ex]
\sin\left(\frac x8\right)&= -\frac8\pi \sin\left(\frac\pi8\right) \sum_{n=1}^\infty \left(\frac{(-1)^n}{8n-1} + \frac{(-1)^n}{8n+1}\right) \sin(nx)
\end{align*}$$ Next I looked at $x \cos\left(\frac x8\right)$ in an attempt to get the squared denominators, with e.g. cosine expansion $$\begin{align*}
x\cos\left(\frac x8\right) &= \frac8\pi \left(8\cos\left(\frac\pi8\right)+\pi\sin\left(\frac\pi8\right)-8\right) \\ & \qquad - 8\sin\left(\frac\pi8\right) \sum_{n=1}^\infty \left(\frac{(-1)^n}{8n-1} - \frac{(-1)^n}{8n+1}\right) \cos(nx) \\ & \qquad - \frac{64}\pi \sum_{k=1}^n \left(\frac{1 - (-1)^n \cos\left(\frac\pi8\right)}{(8n-1)^2} + \frac{1 - (-1)^n \cos\left(\frac\pi8\right)}{(8n+1)^2}\right) \cos(nx) \\[1ex]
(x-\pi) \cos\left(\frac x8\right) &= \frac{64}\pi \left(\cos\left(\frac\pi8\right)-1\right) - \frac{64}\pi \sum_{n=1}^\infty \left(\frac{1 - (-1)^n \cos\left(\frac\pi8\right)}{(8n-1)^2} + \frac{1 - (-1)^n \cos\left(\frac\pi8\right)}{(8n+1)^2}\right) \cos(nx)
\end{align*}$$ The next move would be to pick a value of $x$ to recover some numerical series, but the right choice - if there is one - isn't obvious to me. I can nearly recover two that I want, namely $$\sum_{n=0}^\infty \left(\frac1{(8n+1)^2} + \frac1{(8n+7)^2}\right)$$ but still have to deal with their alternating variants. Presumably I can do something similar with $\cos\left(\frac{3x}8\right)$ , but one thing at a time. I'm open to other methods for evaluating the series, but I'm more interested in the Fourier approach, if it's tenable.","['fourier-series', 'sequences-and-series']"
4422675,Logarithmic Derivative of the Riemann Zeta Function and its relation to zeros,"I am trying to study the proof to the following theorem:
If $|t| \geq 7/8$ and $5/6 \leq \sigma \leq 2$ , then $$ \frac{\zeta'}{\zeta}(s) = \sum_{\rho}\frac{1}{s-\rho} + O({\log \tau})$$ where $\tau = |t| + 4$ and the sum is extended over all zeros $\rho$ of $\zeta(s)$ for which $|\rho - (3/2 + it)| \leq 5/6$ Using the lemma:
Suppose that $f(z)$ is analytic in a domain containing the disc $|z| \leq 1$ , that $|f(z)| \leq M$ in this disc, and that $f(0) \neq 0$ . Let $r$ and $R$ be fixed, $0 < r < R < 1$ . Then for $|z| \leq r$ we have $$ \frac{f'}{f}(z) = \sum_{k=1}^K \frac{1}{z-z_k}+ O({\log\frac{M}{|f(0)|}})    $$ where the sum is extended over all zeros $z_k$ of f for which $|z_k| \leq R$ . And Let $\delta > 0$ be fixed. Then $ \zeta (s) =
	\frac{1}{s - 1}
	+ O(1)$ uniformly for s in the rectangle $\delta \leq \sigma \leq 2$ , $|t| \leq 1$ , and $\zeta (s) \ll (1 + \tau^{1-\sigma} ) \min\{|\sigma - 1|,\log \tau\}$ ,
uniformly for $\delta \leq \sigma \leq 2, |t| \geq 1.$ And the the proof of the theorem given in the book is:
We apply lemma 1 to the function $f (z) = \zeta (z + (3/2 + it))$ , with $R = 5/6$ and $r = 2/3$ . To complete the proof it suffices to note that $| f (0)|\gg 1$ by the (absolutely convergent) Euler product formula, and that $f (z) \ll \tau$ for $|z| \leq 1$ by Corollary lemma 2 My question is that when does the author use the assumption $|t|\geq 7/8$ or where is it implied? The book I am referring is MULTIPLICATIVE NUMBER THEORY I:CLASSICAL THEORY by HUGH L. MONTGOMERY and ROBERT C. VAUGHAN Edit: Thank you @Gary for pointing out the error of me mentioning the wrong authors of the book
Edit: The theorem can be found in chapter 6 lemma 6.4 pg no.171. of the book mentioned above","['analytic-number-theory', 'number-theory']"
4422728,Three Manifold with (almost) all the Thurston Geometries,"Here $ L(S^1) $ is the unique nontrivial line bundle over the circle (the mobius strip). The manifold $ \mathbb{R}^3 $ (with infinite volume) admits all six of the aspherical Thurston geometries (so not $ S^3 $ or $ S^2 \times E^1 $ ). Are there other three manifolds (without boundary) that admit all six of the aspherical Thurston geometries? My guess is that $ S^1 \times \mathbb{R}^2 $ admits all six, but that's just a hunch. EDIT: This question What are the 8 non-compact Euclidean 3-manifolds? Lists all the noncompact  flat 3 manifolds. So it is enough to figure out which of these eight manifolds admit all six of the eight aspherical geometries. Of these manifolds, 4 are already confirmed see comment from Moishe Kohan $$
\mathbb{R}^3, \mathbb{R}^2 \times S^1,\mathbb{R} \times T^2, \mathbb{R} \times L(S^1) 
$$ One has been ruled out since it has a single end so it cannot admit hyperbolic $ \mathbb{H}^3 $ geometry $$
S^1 \times L(S^1) 
$$ The last three are line bundles over the Klein bottle and it is unclear which geometries they admit (see comment from Lee Mosher) $$
K^2 \times \mathbb{R},X,Y
$$ for description of the manifolds $ X $ and $ Y $ see the question linked above or Flat 3 manifolds and mapping tori of flat surfaces ~End Edit~ Some other background: every closed three manifold admits at most one geometry. A manifold with model geometry $ (X,G) $ has universal cover $ X $ . Thus a manifold can only admit multiple model geometries $ (X_1,G_1) $ and $ (X_2,G_2) $ if $ X_1,X_2 $ are homeomorphic. For the six aspherical geometries the models $ X $ are all homeomorphic, so it is possible for one manifold to admit multiple geometries. But for $ S^3,S^2 \times E^1 $ no other model geometry is topologically equivalent to the model geometries $ S^3 $ and $ S^2 \times \mathbb{R} $ thus a manifold with $ S^3 $ or $ S^2 \times E^1 $ geometry cannot admit any of the other Thurston geometries. a finite volume manifold with any one of $ S^3,S^2\times E^1,E^3,Nil,Sol,\mathbb{H}^3 $ geometry only admits that type of geometry There exist finite volume noncompact manifolds which admit both $H^2\times E^1$ and $ \tilde{SL_2} $ geometry. For example $ SL_2(\mathbb{R})/SL_2(\mathbb{Z}) $ , which is diffeomorphic to the complement of the Trefoil knot in $ S^3 $ , admits both $ \tilde{SL_2} $ and $ H^2\times E^1 $ geometry.
See https://math.stackexchange.com/a/73885/758507 Essentially the idea to show it also has $ H^2\times E^1 $ geometry is that the upper half plane model of hyperbolic plane $ H^2 $ quotienting by the action of the modular group $ SL_2(\mathbb{Z}) $ by Moebius transformations gives a two dimensional orbifold $$
\mathcal{D}= \{ z:Im(z)>0, -\frac{1}{2} \leq Re(z)\leq \frac{1}{2}, |z|\geq 1 \} 
$$ with orbifold points at $ i, e^{\pi i/3},e^{2\pi i/3} $ . Using the natural circle bundle over $ H^2 \cong SL_2(\mathbb{R})/SO_2(\mathbb{R}) $ we can form a natural Seifert fiber bundle over this orbifold, which has geometry $ H^2 \times E^1 $ .","['geometric-topology', 'smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
4422804,"two-dimensional version of ""$F_X(X)$ is uniformly distributed""?","It is a well-known fact in probability theory that if $X$ is a continuous random variable and $F_X$ is a cdf of $X$ , then $F_X(X)$ is uniformly distributed over $[0, 1]$ . Is there a two-dimensional version of this statement? In other words, given a continuous random vector $(X, Y)$ , can we find some function $T: \mathbb{R}^2 \rightarrow [0, 1]^2$ such that $T(X, Y)$ is uniformly distributed over $[0, 1]^2$ ? Thank you.","['statistics', 'uniform-distribution', 'cumulative-distribution-functions', 'probability', 'random-variables']"
4422806,"Given independent $Z_i \sim N(\mu_i, \sigma_i ), i=1,2$ derive the density of $(Z_1, Z_1 + Z_2)$.","Given independent $Z_i \sim N(\mu_i, \sigma_i ), i=1,2$ I would like to derive the distribution of $(Z_1, Z_1 + Z_2)$ and doing so through deriving a density (but not using Characteristic functions). My idea is to show explicitly that for some function $f(x, y)$ one has that $$
P \left [ Z_1 \in (-\infty, a], Z_1 + Z_2 \in (-\infty , b) \right ] = \int_{-\infty}^b \int_{-\infty}^a f(x, y) dx dy.
$$ This would be sufficient to show that $f$ is the density of $(Z_1, Z_1 + Z_2)$ . We may take as known that the sum $Z_1 + Z_2$ of two independent normally distributed random variables follows a $N(\mu_1 + \mu_2, \sigma_1 + \sigma_2)$ -distribution, that the joint density two of independent random variables is the product of their individual densities, as well as results from Calculus . My idea was to do as follows: Considering the following equality of sets $$
\left \{ Z_1 < a, Z_1 + Z_2 < b \right \} = \left \{ Z_1 < a, Z_2 < b - a \right \}
$$ from which it follows that \begin{align*}
P \left [ Z_1 < a, Z_1 + Z_2 < b \right ] &= P \left [ Z_1 < a , Z_2 < b - a \right ] \\
&= \int_{-\infty}^{b-a} \int_{-\infty}^a f_{Z_1}(x)f_{Z_2}(y) dx dy.
\end{align*} Substituting with the transformation $\phi(x, y) = (x, y -a)$ we have that $$
\int_{-\infty}^{b -a}\int_{-\infty}^a f_{Z_1}(x)f_{Z_2}(y)dx dy = \int_{-\infty}^a\int_{-\infty}^b  f_{Z_1}(x)f_{Z_2}(y-a) dx dy,
$$ where $$
f_{Z_2}(y-a) = \frac{1}{\sqrt{2 \sigma_2 \pi}}\exp \left ( -\frac{1}{2}\left (\frac{x- (\mu_2 + a)}{\sqrt{\sigma_2}} \right )^2 \right )
$$ But here I get stuck and do not know how to proceed. Is it possible to do a derivation of the density in this - or a similar - manner? [I believe the general approach to prove that $(Z_1, Z_1 + Z_2)$ follows a normal distribution would be to derive the Characteristic function of the Joint normal distribution, show that the Characteristic function of $(Z_1, Z_1 + Z_2)$ is that of a joint normal distribution, and then refer to the uniqueness of Characteristic functions.] Thanks in advance!","['normal-distribution', 'density-function', 'probability-theory', 'real-analysis']"
4422936,Why does the golden ratio emerge in this primorial-related sequence?,"Let $$f(i):=\left\lfloor\frac{p_i\#}{\varphi(p_i\#)}\right\rfloor,$$ where $p_i$ is the $i$ th prime, $\#$ is the primorial operator, and $\varphi$ is totient. Example $$f(3)=\left\lfloor\frac{5\#}{\varphi(5\#)}\right\rfloor=\left\lfloor\frac{5\cdot 3\cdot 2}{8}\right\rfloor=3.$$ Let $g(n)$ be the smallest value of $i$ for which $f(i)=n$ . Then $g(n)\cdot \phi \approx g(n+1)$ with what seems like a high degree of accuracy. Here, $\phi=\frac{1+\sqrt{5}}{2}$ . Example Since $f(21)=\lfloor 7.93355\rfloor$ and $f(22)=\lfloor 8.03526\rfloor$ , we have $g(8)=22$ . Then $22\cdot \phi\approx 35.597$ , and indeed $g(9)=35$ . The $n$ values seem to roughly trace the Fibonacci sequence with some small error term. However, this may be a transient thing; see second table below, where it appears the correlation might peak around $i=F_{12}=144$ . I can't calculate past $F_{20}$ using my current approach, since even that much is invoking $67931\#/\varphi(67931\#)$ . Before I dumped too much more time into investigating this, I figured I'd ask here in case this has an obvious explanation I don't see. If anyone can shed light on why this happens (or shows that my supposition is erroneous), I'll consider this answered. Table of $(i, f(i))$ Table of $\left(a, \frac{p_{F_a}\#}{\varphi(p_{F_a}\#)}\right)$ (where $F_a$ is $a$ th Fibonacci term)","['golden-ratio', 'prime-numbers', 'elementary-number-theory', 'sequences-and-series', 'primorial']"
4422950,Are all compact subsets of $\mathbb R^{\mathbb R}$ separable?,"The title is the question. I should perhaps add that $\mathbb R$ has its usual topology and the product has the product topology, i.e., $\mathbb R^{\mathbb R}$ is the space of all functions from $\mathbb R$ to $\mathbb R$ with the topology of pointwise convergence. It is easy to see that this space is separable, e.g., the set of polynomials with rational coefficients is dense. However, in general separable topological spaces, subspaces need not be again separable. I guess that the answer to this question is well-known -- however searching, e.g., Engelking's book for such a special question is rather frustrating.","['general-topology', 'examples-counterexamples', 'compactness']"
4423006,Prove that $card(X) \le card(Y) \iff \exists Z \subseteq Y$ such that $card(X)=card(Z)$,"I would just like some guidance on whether my proof is sufficient, or if there are things I should change. Thank you! Prove that $card(X) \le card(Y) \iff \exists Z \subseteq Y$ such that $card(X)=card(Z)\\$ Assume $\exists Z \subseteq Y$ such that $card(X)=card(Z)$ $\Rightarrow card(Z) \le card(Y)$ $\Rightarrow card(X) \le card(Y)$ since $card(X)=card(Z)$ $\therefore$ $card(X) \le card(Y)\\$ Assume $card(X) \le card(Y)$ $\Rightarrow$ There is an injective function $f: X\rightarrow Y$ Now let $Z$ be the image of $f$ $\Rightarrow Z\subseteq Y$ $\Rightarrow$ Then for $\forall a \in X,\exists b \in Z$ such that $f(a)=b$ Let $g:X \rightarrow Z$ be a function from $X$ to $Z$ $\Rightarrow$ Then since the codomain and image of $g$ are equal, $g$ is an onto function $\Rightarrow$ $g$ is bijective function $\Rightarrow$ $card(X)=card(Z)$ $\therefore$ $card(X)=card(Z)$",['elementary-set-theory']
4423055,Probability of crossing between a line on a circle and a line segment inside the circle,"Say that we have a circle centered in $(0,0)$ with a radius $R$ . Inside the circle, we have a vertical line segment of length $2d$ in the center of the circle ( $x_1=-d,x_2=d,y_1=y_2=0$ ). Now let's take two points on the circumference of the circle with angle $\theta_1,\theta_2$ and draw a line between them. You can see it better by the figure below. My question will be what is the probability of having these two lines (the one at the origin and the random one). My first idea is to take $\theta_1,\theta_2$ from a uniform distribution and so I'll just need to find the condition for the crossing and I can then just integrate $\int\int d\theta_1 d\theta_2$ and this will be some function of $d/R$ . Starting from this I could write that for this crossing to happen we should have $-d<y(0)<d$ where $y(x)$ is the line equation for the random line. I can then rewrite this condition as: $|\cos(\theta_1) \cot(\frac{\theta_1 + \theta_2}{2}) + \sin(\theta_1) |\leq \frac{d}{R}$ . Numerically, I can find this probability (I did two things, first I would take a large amount of random line about 10 million and see how many cross on average and change $d/R$ and see how it changes and the other was just to check with the condition above for all values of $\theta_1,\theta_2 \in [0,2\pi]$ and also average and both methods gives the same results). But I'm trying to find an analytical expression and I'm stuck here. My idea is to first fix $\theta_1$ then find a condition for $\theta_2$ and then integrate $\theta_2$ and afterwards integrate $\theta_1$ between $0,2\pi$ and this should in principle give me the probability, but I can't seem to find a way to express the integration condition for $\theta_2$ , I tried doing it with Mathematica as well but it's not working out. Any help will be appreciated. Also, if needed, here's the results that I got from numerics for the probability.","['circles', 'geometry', 'probability']"
4423115,Can a set be a subset of another set but not be contained it the other set?,"Say I have the set $A=\{\{1,2,\{3\}\}\}$ , and so the set cardinality of $A$ is $1$ from my understanding. If $B = \{\{1,2,\{3\}\}, \{\{1,2,\{3\}\}\}$ , then the set cardinality of B is $2$ too? My question is Suppose we have another set $C=\{ \emptyset \} \cdot A$ ï¼and another set $D=\{ \emptyset \} \cdot B $ . Indeed, $ C \subseteq D$ , but why isn't $C \in D$ ï¼ Because from my understanding the set $C$ can be written as $ \{(\emptyset , \{1,2,\{3\})\}$ and $D$ written as $ \{(\emptyset , \{1,2,\{3\}), (\emptyset , \{\{1,2,\{3\}\})\}$ . Sorry if my question isn't clear! Thanks for the help :)",['elementary-set-theory']
4423214,"The commutator $[\Delta, \nabla_i]$ of the Laplacian and covariant derivative","Let $\nabla$ be a Riemannian connection, $\Delta$ be the Laplacian defined as $\text{tr}_g \nabla^2$ . The equation I want to show is $$
\Delta\nabla_i f = \nabla_i\Delta f + \sum_{j} Ric_{ij} \nabla_jf  
$$ where $Ric$ is the Ricci curvature tensor, $f$ is a smooth function.
The proof my text gives is (they use the convention that basically $g_{ij} = \delta_{ij}$ which I am not using) $$
\Delta \nabla_i f = \nabla_j\nabla_i\nabla_j f = \nabla_i\nabla_j\nabla_j f - R_{jijk} \nabla_k f
$$ ...which I understand 0% about it. My guess is that the first interchange $$
  \begin{align*}
    \Delta\nabla_i f &= \sum_{j,k}g^{jk}\nabla_j\nabla_k\nabla_i f = \sum_{j,k}g^{jk}\nabla_j\nabla_i\nabla_k f 
  \end{align*}
$$ is free since $\nabla_i\nabla_j f = \nabla_j \nabla_if$ and $\nabla$ has no torsion. But what about the second one (i.e. how do we interchange $\nabla_j$ and $\nabla_i$ ?) Edit: so I've found and use the Ricci identity for 1-forms $$
  (\nabla_i \nabla_j - \nabla_j \nabla_i) w(\partial_k) = w(R(\partial_j,\partial_i)\partial_k) = \sum_{l} w^l R_{jik}^l
$$ put $w = \nabla f$ says $$
  (\nabla_i \nabla_j - \nabla_j \nabla_i) \nabla f(\partial_k) =
  (\nabla_i \nabla_j - \nabla_j \nabla_i) \nabla_k f =  \sum_{l} (\nabla f)^l R_{jik}^l
$$ and I don't know how to proceed to get $Ric$ .","['tensors', 'riemannian-geometry', 'differential-geometry']"
4423231,binomial coefficient in the inclusion-exclusion principle,"Suppose n people leave their coats at the cloakroom, but on leaving the cloakroom the supervisor randomly gives any coat back to each person. Now to determine the number of permutations in which s persons receive their coat, there is the formula: $$\sum\limits_{t=s}^{n}(-1)^{t-s}\binom{t}{s}\binom{n}{t}(n-t)!.$$ Now I would like to understand the formula. To do this, I will consider the case n=3 and s=1 to be able to illustrate this and determine the subset: N $_{1}$ ={Lists with 1 in position 1} (I mean: person 1 gets his coat back). N $_{2}$ = {Lists with 2 in position 2} and N $_{3}$ = {Lists with 3 in position 3} Then $$\sum\limits_{t=1}^{3}(-1)^{t-1}\binom{t}{1}\binom{3}{t}(3-t)! = \binom{1}{1}\binom{3}{1}(3-1)! - \binom{2}{1}\binom{3}{2}(3-2)! + \binom{3}{1}\binom{3}{3}(3-3)!.$$ Now consider a I multiplication: For example $\binom{1}{1}\binom{3}{1}(3-1)!$ . The part $\binom{3}{1}(3-1)!$ means: I think this is the same as |N $_{1}$ |+|N $_{2}$ |+|N $_{3}$ | and that's mean we fix 1 of 3 that's why $\binom{3}{1}$ and the other 3-1 elements may be anywhere, that's mean (3-1)! I know that the inclusion-exclusion principle applies here. Now I try to understand the coefficient $\binom{1}{1}$ or in general, how can I imagine the coefficient $\binom{t}{s}$ . I am very grateful if you can explain this to me.","['inclusion-exclusion', 'binomial-coefficients', 'combinatorics']"
4423237,Why is the bizarre $f^{-1}(y)=y+\sum_{n=1}^\infty\frac{1}{n!}\frac{d^{n-1}}{dy^{n-1}}[y-f(y)]^n$ equivalent to the Lagrange inversion formula?,"$\newcommand{\d}{\mathrm{d}}$ EDIT: In the nontrivial example $f(x)=x-\frac{1}{4}x^3$ and using either of the two series to produce a result for $f^{-1}(3/4)$ , I find that $(\ast)$ and $(1)$ produce the same result. It would appear that they actually are, by some unseen machinery, equivalent. Why? Op: A collection of past ""Step"" exam questions includes a question based on the following assertion: If $y=f(x)$ , the inverse of $f$ is given by Lagrange's identity : $$\tag{$\ast$}f^{-1}(y)=y+\sum_{n=1}^\infty\frac{1}{n!}\frac{\d^{n-1}}{\d y^{n-1}}[y-f(y)]^n$$ Of course this is not very formally phrased, since the targeted syllabus is pre-university, but let's infer that $f$ is to be a real analytic injection and $y$ in its image (that being said, it still feels as if far too many $y$ s are floating around - is $y$ fixed? Where did $x$ go?) With that, I am still suspicious of this identity. The Lagrange Inversion Theorem as I know it has two forms: Suppose $f:\Bbb C\to\Bbb C$ is analytic at a point $a$ and $f'(a)\neq0$ ; then there is a neighbourhood $V\subseteq\Bbb C$ of $f(a)$ in which the function $g:V\to\Bbb C$ defined by: $$\tag{1}z\mapsto a+\sum_{n=1}^\infty\frac{1}{n!}(z-f(a))^n\cdot\lim_{w\to a}\frac{\d^{n-1}}{\d w^{n-1}}\left[\left(\frac{w-a}{f(w)-f(a)}\right)^n\right]$$ Is a local analytic inverse of $f$ - $f(z)=w\iff z=g(w)$ if $w\in V,z\in f^{-1}(V)$ . There is also a cute combinatorial version, Lagrange-Burmann: Suppose $f:\Bbb C\to\Bbb C$ satisfies $f(w)=w/\phi(w)$ for some analytic $\phi:\Bbb C\to\Bbb C$ with $\phi(0)\neq 0$ . There is a similarly defined as above inverse to $f$ , $g$ , with coefficient formula: $$\tag{2}[w^n]g(w)=\frac{1}{n}[z^{n-1}]\phi(w)^n$$ Let's note that $(\ast)$ is broadly similar but technically different to both $(1)$ and $(2)$ . My question is: I know for a fact $(1),(2)$ are equivalent and correct after many hours of painful research, but $(\ast)$ I have never seen before - how is it equivalent to $(1)$ ? We note that if they are equivalent, this would imply (I think, anyway - the excessive usage of $y$ s is baffling): $$(y-f(x))^n\cdot\lim_{a\to x}\frac{\d^{n-1}}{\d a^{n-1}}\left[\left(\frac{a-x}{f(a)-f(x)}\right)^n\right]\equiv\frac{\d^{n-1}}{\d y^{n-1}}[y-f(y)]^n$$ But this seems ridiculous, especially since no fixed point $x$ is defined, on the right hand side. Moreover a direct equation of coefficients reveals that the centrepoint $x$ should be taken as $y$ , which again seems nonsensical. Is the examiner abusing notation, am I making some mistake, or is $(\ast)$ nonsense as my gut feeling suggests? I surely hope it is not the latter.","['inverse-function', 'complex-analysis', 'calculus', 'lagrange-inversion', 'power-series']"
4423268,"Does there exist a triangle with altitudes $h_a,h_b,$ and $h_c$ for all $h_a,h_b,h_c\in\Bbb{R}^{+}$?","Here's my attempt. If we have a triangle with side lengths $a,b,$ and $c$ and altitudes with length $h_a,h_b$ and $h_c$ , then these must satisfy the following, where $s=\frac{1}{2}(a+b+c)$ : $h_a=\frac{2\sqrt{s(s-a)(s-b)(s-c)}}{a}$ $h_b=\frac{2\sqrt{s(s-a)(s-b)(s-c)}}{b}$ $h_c=\frac{2\sqrt{s(s-a)(s-b)(s-c)}}{c}$ With a bit of reworking, we can say $(ah_a)^2=4s(s-a)(s-b)(s-c)$ $(bh_b)^2=4s(s-a)(s-b)(s-c)$ $(ch_c)^2=4s(s-a)(s-b)(s-c)$ But honestly, I think this might be even more of a headache to work with in general. I will say that the motivating factor here was whether or not you can have a triangle with altitudes of 2, 3, and 6 (which would make the incircle's area a nice, clean $\pi$ units squared)m and for that case, we have $a^2=s(s-a)(s-b)(s-c)$ $9b^2=4s(s-a)(s-b)(s-c)$ $9c^2=s(s-a)(s-b)(s-c)$ which might be a bit easier than the general form, but it still seems intimidating to me. As a system of three equations with three unknowns, I feel like you should be able to solve for it, but I also know that we're dealing with some rather messy quartic equations well, so that could throw a wrench in things. As always, help is appreciated. Thank you!","['triangles', 'systems-of-equations', 'geometry']"
4423277,How many associative binary operations on the integers does $+$ distribute over?,"I am interested in binary operations $\mid: \mathbb{Z} \times \mathbb{Z} \to \mathbb{Z}$ which satisfy: Associativity: $a \mid (b \mid c) = (a \mid b) \mid c$ $+$ distributes over $\mid$ : $(a \mid b) + c = (a + c) \mid (b + c)$ . I know of the following such operations: $\max, \min, (x, y) \mapsto x,$ and $(x, y) \mapsto y$ . Are there others? Over the reals, there is also an infinite family of such operations $(x, y) \mapsto \log_a (a^x + a^y)$ , for any base $a$ . But this operation doesn't restrict to the integers.","['binary-operations', 'abstract-algebra', 'associativity', 'integers']"
4423301,Problems with differential geometry,"I have problems with this statement: ""Let $\pi: \mathbb{R} \to S^1$ given by $\pi (x) = (\cos(x), \sin(x))$ . Let $f\colon[0, l] \to S^1$ a differentiable function where $f(t)=(f_1(t), f_2(t))$ with $f_1$ and $f_2$ real-valued functions on $[0, l]$ . Let $x_0 \in \pi^{-1} (f(0)) \subset \mathbb{R}$ and it defines $$\tilde{f} (t) = x_0 +\int_0^t (f_1 f_2' - f_2 f_1')du$$ Proof that $ \pi \circ \tilde{f} =f $ (this means that it is lifting of f)"" My questions: What is the definition of lifting? Which procedure you would suggest to me to do this proof? Sorry for my English but I'm from latinoamerica","['curves', 'frenet-frame', 'geometry', 'multivariable-calculus', 'differential-geometry']"
4423424,Is $Var(x | x \le \tau)$ weakly increasing in $\tau$?,"I am interested in $Var(x | x\le \tau)$ is increasing in $\tau$ , where $x$ is some random variable with differentiable cdf. I can show that $E[x | x\le \tau]$ is increasing in $\tau$ , which is intuitively obvious, by the following computation: $$
\frac{\partial}{\partial\tau}E[x\mid x\le\tau]=\frac{\partial}{\partial\tau}\left(\int_{-\infty}^{\tau}\frac{xf(x)}{F(\tau)}dx\right)=\frac{f(\tau)}{F(\tau)}(\tau-E[x\mid x\le\tau]).
$$ In a similar vein, I tried the following: $$
\begin{align*}
\frac{\partial}{\partial\tau}Var[x\mid x\le\tau] & =\frac{\partial}{\partial\tau}\left(E[x^{2}\mid x\le\tau]-E[x\mid x\le\tau]^{2}\right)\\
 & =\frac{\partial}{\partial\tau}\left(\int_{-\infty}^{\tau}\frac{x^{2}f(x)}{F(\tau)}dx-(\int_{-\infty}^{\tau}\frac{x f(x)}{F(\tau)}dx)^{2}\right)\\
 & =\frac{f(\tau)}{F(\tau)}\left[\tau^{2}-E[x^{2}\mid x\le\tau]-2(E[x\mid x\le\tau]-\tau)\right]
\end{align*}
$$ Is this correct? I have a doubt because (i) a simulation result does not match with the analytical formula I have here (although the derivative of $E[x\mid x\le \tau]$ is verified by a simulation) and (ii) it is not clear if $Var[x\mid x\le \tau]$ is increasing in $\tau$ from the result, although a bunch of simulation suggests it is increasing.
If $Var(x\mid x\le \tau)$ is not increasing in general, under what conditions are they increasing? For example, what if $x$ is supported on positive values?","['statistics', 'conditional-expectation', 'probability']"
4423466,"If $|ax^2+bx+c|\leq 2\ \ \forall x\in[-1,1]$ then find the maximum value of $|cx^2+2bx+4a|\ \ \forall x\in [-2,2]$.","If $$\left|ax^2+bx+c\right|\leq 2\quad \forall x\in[-1,1]$$ then find the maximum value of $$\left|cx^2+2bx+4a\right|\quad \forall x\in [-2,2].$$ My Attempt Let $f(x)=ax^2+bx+c$ , then $$|cx^2+2bx+4a|=x^2|4\frac{a}{x^2}+2\frac{b}{x}+c|=x^2\left|f\left(\frac{2}{x}\right)\right|$$ But then I couldn't make any headway. I also tried to express $a,b,c$ in terms of $f(-1),f(0),f(1)$ i.e $$c=f(0);b=\frac{f(1)-f(-1)}{2};a=\frac{f(-1)-2f(0)+f(1)}{2}$$ but again couldn't go further","['inequality', 'maxima-minima', 'optimization', 'algebra-precalculus', 'quadratics']"
4423531,Do prime of the form $4k+1$ ever lead the greatest prime factor race?,"Note : Posted in MO since it is unanswered in MSE. Analogous to Chebyshev's race between primes, I examined the race between primes in the greatest prime factors, GPF , of natural numbers. Similar to the regular prime race, in the GPF race, the proportion of prime of both forms is roughly $50\%$ each. However, unlike the regular prime race where the race is equal ( A038691 ) or changes lead between primes of the form $4k+1$ and $4k+3$ ( A096628 ) in the GPF race, $4k+3$ dominates. For $n \le 3 \times 10^{10}$ , there are $14970975209$ numbers the GPF is of the form $4k+1$ and $15029024755$ numbers where $GPF$ is of the form $4k+3$ and up till this point, there is not a single instance where primes of the form $4k+1$ equal or take the lead in the race. Let $f_1(n)$ and $f_3(n)$ be the number of natural numbers $\le n$ in which the GPF is of the form $4k+1$ and $4k+3$ respectively. The difference between the number of GPFs on these two forms appeared to increase in a very orderly manner as shown in the graph below. Question 1 : Does the GPF race ever become equal or change the lead i.e. is there an $n$ such that $f_1(n) = f_3(n)$ ? Clearly, the graph is sub-linear. I applied different curve fitting models to this data to have an idea of the growth rate. The best fit was given by $$
f_3(n) - f_1(n) \approx an^b
$$ where $a \approx 0.1785$ and $b \approx 0.8122$ . This experimental model has a very high $R^2 = 0.9999958$ . If this is close to the true growth rate then, prime of the form $4k+1$ will always lag behind in the GPF race. Question 2 : What is the true growth rate of $f_3(n) - f_1(n)$ ?","['divisibility', 'number-theory', 'elementary-number-theory', 'analytic-number-theory', 'prime-numbers']"
4423632,Why $ \sum _{k=0} ^{n-1} \binom{n-1}{k} x^{k+1} = \sum _{k=1} ^{n} \binom{n-1}{k-1} x^k $?,I'm struggling to understand how to get from this: $$ \sum _{k=0} ^{n-1} \binom{n-1}{k} x^{k+1}  $$ to this: $$ \sum _{k=1} ^{n} \binom{n-1}{k-1} x^k  $$ I always have a problem understand the shifting of limits in general. Does there exist a guide/book somewhere?,"['algebra-precalculus', 'integers', 'summation', 'arithmetic']"
4423674,"Given a finitely generated, residually finite, non-cohopfian group $G$, can the following abelianizations ALL be finite?","Let $G$ be a finitely generated, residually finite, non-cohopfian group. Since $G$ is residually finite, we know that there exists a sequence of nested, normal, finite index subgroups $$G  = N_0 \rhd  N_1  \rhd N_2    \ldots $$ with the trivial intersection. Question : Is it possible that all $N_i$ have finite abelianization, i.e. the quotient group $N_i \big/ [N_i,N_i]$ is finite for every $i$ ? My thoughts so far : It is clear that $G$ can't be finite (finite implies cohopfian) or abelian or free (free groups have infinite abelianization). The closest group I was informed is $D_{\infty} = \; \left<r,s \;|\; srs=r^{-1}, s^2=1 \right>$ , which is finitely generated, residually finite and non-cohopfian. However, for any sequence of nested, normal, finite index subgroups with the trivial intersection $D_{\infty} = N_0 \rhd  N_1  \rhd N_2    \ldots $ , we eventually have $N_i$ contains only rotations, which means $N_i$ is infinite abelian, hence has infinite abelianization.","['geometric-group-theory', 'group-theory', 'abstract-algebra', 'infinite-groups']"
4423687,"$ \dfrac{1}{2 \pi} \int e^{-itx} \phi_K(ht) \phi_X(t) \, dt \overset{?}= \dfrac{1}{h} \int K(u/h) f_X(x - u) \, du$ for kernel $K$","I want to calculate the expected value of the deconvolution kernel density estimator. Delaigle and Hall did this in their paper ""Kernel methods and minimum contrast estimators for empirical deconvolution"", but there is one step which I don't unterstand: $
\dfrac{1}{2 \pi} \int e^{-itx} \phi_K(ht) \phi_X(t) \, dt = \dfrac{1}{h} \int K(u/h) f_X(x - u) \, du
$ with $\phi_K (z)$ characteristic function of a Kernel $K$ and $\phi_X(z)$ characteristic function of a random variable $X$ .
How do I get from the left statement to the right statement? It seems like there was used substitution.","['fourier-transform', 'statistics', 'probability-theory']"
4423750,Need pure geometric solution for proof on 10-20-40-50 angle problem,"$D$ is a point in $\triangle{ABC}$ so that $\angle{ABD}=10^{\circ}$ , $\angle{DBC}=20^{\circ}$ , $\angle{BCD}=40^{\circ}$ , $\angle{DAC}=50^{\circ}$ . Find $\angle{BAD}$ . This problem is easily done with trigonometric Ceva theorem as: $$
\begin{aligned}
&\dfrac{\sin x}{\sin50^{\circ}}
\cdot
\dfrac{\sin(60^\circ-x)}{\sin40^{\circ}}
\cdot 
\dfrac{\sin20^\circ}{\sin10^\circ}=1 
\\
\implies 
&
\sin x \cdot \sin(60^\circ-x)
=
\dfrac
{\sin50^\circ\cdot \sin40^\circ\cdot \sin10^\circ}
{\sin20^\circ}
\\
&\qquad
=
\dfrac
{ \cos40^\circ\cdot \sin40^\circ \cdot \sin10^\circ}
{2\sin10^\circ\cdot \cos10^\circ}
=
\dfrac{\sin80^\circ}{4\cos10^\circ}
=\dfrac{1}{4}
\\
\implies
& -\dfrac{\cos60^\circ - \cos(2x-60^\circ)}2 = \dfrac{1}{4}
\\
\implies &
\cos(2x-60^\circ)=1 
\\
\implies 
&2x-60^\circ=0
\\
\implies 
&x=\boxed{30^\circ}\ .
\end{aligned}
$$ Any idea on how to solve this problem in pure geometric approach? Thanks.","['euclidean-geometry', 'triangles', 'geometry']"
4423781,"If $\alpha\implies\beta$ and $\beta\implies\alpha$ are satisfiable, then $\alpha\iff \beta$ must be satisfiable?","Consider this sentence: If $\alpha\implies\beta$ and $\beta\implies\alpha$ are satisfiable,
then $\alpha\iff \beta$ is satisfiable. I think the above sentence is correct because $$\alpha\iff \beta\equiv   (\alpha\implies\beta)\wedge (\beta\implies\alpha).$$ Is my argument valid?","['logic', 'discrete-mathematics']"
4423787,"An inequality by induction: Engel, Problem 24, page 208","I am reading Arthur Engel's Problem Solving Strategies , Section 8, The Induction Principle, Problem 24 with its solution I do not understand the second inequality in the solution on page 216. This is valid when the sum of the fractions $1/a_i$ is small enough. How do we show that? Is there an alternative proof?","['inequality', 'induction']"
4423812,A Pedoe-like Geometric Inequality,"Problem Given two triangles $ABC$ and $A'B'C'$ where $a,b,c$ and $a',b',c'$ are the corresponding sides and $F, F'$ denotes the areas of the two triangles. Prove: \begin{equation}
a^2a'^2+b^2b'^2+c^2c'^2\geqslant 16FF'.
\end{equation} Solution I know that $ a^2\left(-a'^2+b'^2+c'^2\right)+b^2\left(a'^2-b'^2+c'^2\right)+c^2\left(a'^2+b'^2-c'^2\right)\geqslant 16FF',$ which is the Pedoe's inequality, and $\cot A \left(\cot B'+\cot C'\right)+\cot B \left(\cot A'+\cot C'\right)+\cot C \left(\cot A'+\cot B'\right)\geqslant 2$ , which is an equivalent version of the Pedoe's inequality. Therefore, I was trying to solve this problem by transforming side lengths into cotangents. Because $$\cot A=\frac{\cos A}{\sin A}=\frac{b^2+c^2-a^2}{2bc}\cdot \frac{bc}{2F}=\frac{b^2+c^2-a^2}{4F}\,, \quad \text{(by the law of sines and the law of cosines)}$$ the inequality we desire is equivalent to $$\left(\cot B+\cot C\right)\left(\cot B'+\cot C'\right)+\left(\cot C+\cot A\right)\left(\cot C'+\cot A'\right)+\left(\cot A+\cot B\right)\left(\cot A'+\cot B'\right)\geqslant 4.$$ Expanding it and arrange terms gives us $$2\left(\cot A\cot A'+\cot B\cot B' +\cot C\cot C'\right) + M\geqslant 4$$ where $M=\cot A \left(\cot B'+\cot C'\right)+\cot B \left(\cot A'+\cot C'\right)+\cot C \left(\cot A'+\cot B'\right)$ . We know $M\geqslant 2$ , so I thought if I can prove $\cot A\cot A'+\cot B\cot B' +\cot C\cot C \geqslant 1$ , the problem would be solved. However, this might not be true. After this,  I got stuck. Another inequality related to this problem is $$a^2x+b^2y+c^2z\geqslant 4F\sqrt{xy+yz+zx}\quad \forall x,y,z\in \mathbb{R}^+.\quad\text{(Oppenheim's inequality)} $$ If we set $x=a'^2, y=b'^2, z=c'^2$ , we can get $$a^2a'^2+b^2b'^2+c^2c'^2\geqslant 4F\sqrt{\frac{(2F')^2}{\sin A'}+\frac{(2F')^2}{\sin B'}+\frac{(2F')^2}{\sin C'}}=8FF'\sqrt{\csc^2 A'+\csc^2 B' +\csc^2 C'}.$$ And by Jensen's inequality, we can get $$a^2a'^2+b^2b'^2+c^2c'^2\geqslant 8FF' \cdot \sqrt{3\csc^2\left(\frac{A'+B'+C'}{3}\right)}=16FF'. \square $$ Notice that when $a'=b'=c'$ our inequality is essentially WeitzenbÃ¶ck's inequality, so when both triangles our equilateral triangles, we get an equality. I guess this inequality can also be directly derived from Pedoe's inequality (maybe without trig), but I don't know how to prove this only by Pedoe's. I'm also willing to see other perspectives (maybe pure geometry?...) to this problem. Note/My Opinion : Since Pedoe's inequality had been incorporated in the proof of Oppenheim's inequality, and the proof uses the trig form of it, I don't count my proof as an direct implication of the Pedoe's. Links Proof of Pedoe's Inequality and its equivalent form Proof of the Oppenheim's Inequality","['trigonometry', 'geometric-inequalities', 'geometry']"
4423827,Is every cÃ dlÃ g process locally bounded?,"Setting We work on a filtered probability space with finite time horizon $T$ and let $X=(X_t)_{t\in[0,T]}$ be an adapted cÃ dlÃ g process. Question Is $X$ locally bounded? ""Locally bounded"" means that there exists a sequence of stopping times $(T_n)$ with $T_n \nearrow T$ and $\lim_{n\rightarrow}P[T_n=T]=1$ and a sequence of constants $(c_n)$ such that $X1_{]]0,T_n]]}$ is uniformly bounded by $c_n$ . Motivation Every cÃ glÃ d process is locally bounded. I would like to understand if this still holds for cÃ dlÃ g processes.","['stochastic-processes', 'measure-theory', 'finance', 'probability-theory']"
4423843,How does this definition of a computable function work?,"I have the definitions of computable (from my class notes) over here: $f$ is computable if there is a computable function $\hat{f}:\Bbb N \times \Bbb N \to \Bbb Q$ such that, for all $n,r \in \Bbb N$ $$
\left |\hat{f}(n,r) - f(n) \right|\leq2^{-r}.
$$ I come from a non-math background, so could someone break it down for me? I understand what $\Bbb N$ and $\Bbb Q$ are. I am just mainly confused with the expression above.","['functions', 'turing-machines', 'computability']"
4423902,Attractive problems in Differential Geometry for a talk [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 2 years ago . Improve this question I am preparing a presentation of Differential Geometry aimed to people with moderate knowledge of Mathematics (think about highschool students). I would like to find some concepts or applications of Differential Geometry that are easy to explain and attractive to an audience that may not have heard of the field. My ideas: Speak about the brachistocrone curve. This is a problem both easy to explain and with an interesting historical context, so I think it is ideal for a presentation like this. Egregious Gaussian theorem. Also easy to explain and surprising (I won't be defining formally the concepts of course) I would prefer examples about curves if possible, although every idea is welcome. Any reference is great also, I have been consulting Differential equations with historical notes by Simmons, which provides a very beautiful solution to the brachistocrone problem, based in Snell law. Thanks in advance.","['soft-question', 'ordinary-differential-equations', 'differential-geometry']"
4423961,Calculating the trace of a 3x3 matrix over the rationals when its determinant is 0,"I encountered a problem where I had a $3\times 3$ matrix $A$ with rational numbers entries and it was given that $A^3=2A$ and $A$ could not be the zero matix. I was asked to calculate the trace of the square of $A$ , namely $tr(A^2)$ . I could find that the determinant $\det(A)=0$ because otherwise it had to be $\sqrt8$ or $-\sqrt8$ . This comes from $\det(A)^3=8\det(A)$ . Since $\sqrt8$ is not rational the determinant has to be $0$ . Is there a way to express $tr(A^2)$ in terms of $\det(A)$ ?","['matrices', 'linear-algebra']"
4424036,Group of units of $\mathbb{Z}_3[[x]]$,"I am trying to calculate the group of units of the power series ring $\mathbb{Z}_3[[x]]$ . I know that all the unit elements are of the form $u+\sum_1^{\infty} a_nx^n$ where $u$ is a unit in $\mathbb{Z}_3$ , where $\mathbb{Z}_3$ are the $3$ -adic integers. However I am not sure about the group structure. For example, we have many subgroups $U_i$ which are the set of elements of the form $u+\sum_i^{\infty} a_nx^n$ i.e the power series where the first power of $x$ is $x^i$ . These groups form a filtration on the group of units. Is there a way to relate these groups to the group of units of $\mathbb{Z}_3[[x]]$ similar to the result for the ring $\mathbb{F}_3[[x]]$ ? For the result for $\mathbb{F}_3[[x]]$ look at Thm 4.4 here . Thanks in advance.","['p-adic-number-theory', 'group-theory', 'abstract-algebra', 'formal-power-series']"
4424040,Doubts about Proof of Durrett Theorem 3.7.4. Thinning of Poisson Process,"I am having trouble understanding Durrett's logic in his proof of the thinning of the Poisson process. Here is the statement of the Theorem: $N_j(t)$ are independent rate $\lambda P(Y_i = j)$ Poisson processes. $N(t)$ is assumed to be a Poisson process with rate $\lambda$ (e.g., the number of cars arrive at a store at time t), and $N_i(t)$ is defined as the number of $i \leq N(t)$ with $Y_i = j$ , where $Y_i$ is an additionally defined property associated with the arrivals (e.g., the number of passengers in the arrived cars). In Durrett's proof, he first proved a simple case where this additional property $Y_i$ is binary. He defined $P(Y_i = 1) = p$ and $P(Y_i = 2) = 1 - p$ , which is fine. What I am having problems with are: (1) He asserted that $N_1(t)$ and $N_2(t)$ are Poisson processes without proving it. This is what I do not understand - isn't it part of the statement to be proved that $N_1(t)$ and $N_2(t)$ are Poisson processes? Why is this true? (2) He proved that if $X_i = N_i(t + s) - N_i(s)$ , $X_1 = j$ and $X_2 = k$ , there must be $j + k$ arrivals between $s$ and $s + t$ , so $P(X_1 = j, X_2 = k) = e^{\lambda t} \frac{(\lambda t)^{j+k}}{(j+k)!}\frac{(j+k)!}{j!k!}p^j (1-p)^k = e^{\lambda pt} \frac{(\lambda p t)^j}{j!}e^{\lambda(1-p)}t \frac{(\lambda (1-p) t)^j}{j!}$ . Then he asserted that $X_1 = Poisson(\lambda pt)$ and $X_2 = Poisson(\lambda (1-p)t)$ . My question is, why can you assert that because $P(X_1 = j, X_2 = k)$ factors into two Poisson distributions, so $X_1$ and $X_1$ are independent, $X_1$ must be $Poisson(\lambda pt)$ and $X_2$ must be $Poisson(\lambda (1-p)t)$ ? Thank you very much. Here is the statement and the full proof of the theorem: (the questions are highlighted in blue)","['probability-theory', 'poisson-distribution', 'poisson-process']"
4424101,"Is there any analysis for this series $\phi=\sum_{n_1, n_2,n_3 \in Z}^\infty e^{-\sqrt{n_1^2 + n_2 ^2+n_3^2}}$","Is there any analysis for this series $\phi=\sum_{n_1, n_2,n_3 \in Z}^\infty e^{-\sqrt{n_1^2 + n_2 ^2+n_3^2}}$ ? This one seems like an extension of Riemann Theta Function where it takes a square root for each term. I also see posts from here but it only works for one variable and $0<s<1$ , and I can change this series similarly by Mellin transform as $$
\phi=\sum_{n_1, n_2,n_3 \in Z}^\infty e^{-\sqrt{n_1^2 + n_2 ^2+n_3^2}}=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\sum_{n_1, n_2,n_3 \in Z}^\infty \frac{\Gamma(x)}{(\sqrt{n_1^2 + n_2 ^2+n_3^2})^x} dx
$$ However, I don't know what to do next. Is there any way to solve this integral? Or are there any resources I can refer to? Thank you so much!","['complex-analysis', 'riemann-zeta', 'reference-request', 'sequences-and-series']"
4424280,"Where does this ""proof"" that $\Bbb{R}^\omega$ is normal in the box topology go awry?","James Munkres' Topology, 2nd Edition indicates that the space $$\Bbb{R}^\omega := \{ (x_0, x_1, x_2, ...) | x_i \in \Bbb{R}, \forall i < \omega \}$$ equipped with the box topology is completely regular, but that normality is not known. He points to a result of Mary Ellen Rudin that the box product of countably many $\sigma$ -compact, locally compact metric spaces is, assuming CH , not just normal but paracompact. I thought I had a clean-looking ""proof"" that $\Bbb{R}^\omega$ in the box topology was normal, along the following lines: Let's say we have disjoint closed sets ð¾, ð¿ â $\Bbb{R}^\omega$ in the box topology. If ð¼ := $\Bbb{R}^\omega$ \ ð¿, then ð¼ is open, contains ð¾, and is disjoint from ð¿. Similarly, ð½ := $\Bbb{R}^\omega$ \ ð¾ is open and disjoint from ð¾, and it contains ð¿. For all ð± â ð¾, let ð± â ð¼(ð±) â ð¼ be an open box so that $$ð¼(ð±) - ð± = \prod_i (-ðáµ¢(ð±), ðáµ¢(ð±))$$ with $0 < ðáµ¢( ð±) < 1$ for all ð â â. Similarly, for all ð² â ð¿, let ð² â ð½(ð²) â ð½ be an open box so that $$ð½(ð²) - ð² = \prod_i (-ðáµ¢(ð²), ðáµ¢(ð²))$$ with $0 < ðáµ¢(ð²) < 1$ for all ð â â. By construction, ð¼(ð±) is disjoint from ð¿ and ð½(ð²) is disjoint from ð¾ for all ð± â ð¾, ð² â ð¿. If additionally every ð¼(ð±) was disjoint from every ð½(ð²) for all ð± â ð¾, ð² â ð¿, then we could take $$ð := \bigcup_{ð± â ð¾} ð¼(ð±),$$ $$ð := \bigcup_{ð² â ð¿} ð½(ð²),$$ as our disjoint open sets containing ð¾ and ð¿, respectively. If for some pair ð±, ð², ð¼(ð±) â ð½(ð²) is nonempty, then since ð± â ð½(ð²) and ð² â ð¼(ð±), there must be some index ð for which $$|ð¥áµ¢ - ð¦áµ¢| > \max(ðáµ¢(ð±), ðáµ¢(ð²)),$$ but where $$(ð¥áµ¢ - ðáµ¢(ð±), ð¥áµ¢ + ðáµ¢(ð±)) â (ð¦áµ¢ - ðáµ¢(ð²), ð¦áµ¢ + ðáµ¢(ð²)) â  â.$$ But if we replaced ðáµ¢(ð±) by ðáµ¢(ð±)/3 and ðáµ¢(ð²) by ðáµ¢(ð²)/3, then it would no longer be possible for these to intersect, since $$\frac{a_i(ð±)}{3} + \frac{b_i(ð²)}{3} < \frac{2|x_i - y_i|}{3} < |x_i - y_i|.$$ So if we, as a precautionary measure: replace the open box ð¼(ð±) by the 1/3-scaled open box ð¼'(ð±) := ð± + (ð¼(ð±) - ð±)/3 for every ð± â ð¾, and replace the open box ð½(ð²) by the 1/3-scaled open box ð½'(ð²) := ð² + (ð½(ð²) - ð²)/3 for every ð² â ð¿, then every ð¼'(ð±) is guaranteed to be disjoint from every ð½'(ð²) for all ð± â ð¾, ð² â ð¿, so that we can define $$ð' := \bigcup_{ð± â ð¾} ð¼'(ð±),$$ $$ð' := \bigcup_{ð² â ð¿} ð½'(ð²),$$ as our desired disjoint open sets containing ð¾ and ð¿. $\blacksquare$ I had just about persuaded myself that this argument worked, but then I saw another post explaining that a countable box product of metric spaces need not be normal, with reference to this paper by Erik van Douwen . So now I'm thinking that my argument ""proves too much"", since this line of reasoning could presumably generalize to show that any countable box product of metric spaces ought to be normal. My question is, where specifically did I make a mistake?","['box-topology', 'fake-proofs', 'separation-axioms', 'solution-verification', 'general-topology']"
4424320,Convergence of the Implicitly Restarted Arnoldi Method (IRAM),"I know that the Implicitly Restarted Arnoldi Method (IRAM) consists of using the implicitly shifted QR algorithm to restart the Arnoldi process without losing to much information about the eigenspace. In particular, taking $$p(t) = (t-k_1 I)\cdots(t-k_{m-k}I)$$ where $k_1,\dots,k_{m-k}$ are values we are not interested in, then $$\tilde{u}_1 = \frac{p(A)u_1}{\|p(A)u_1\|}$$ should be a good restarting vector. My question is whether the convergence of the Arnoldi method with this starting new vector is guaranteed by some theorem, or in general is just a good choice according to literature, or there are some sort of bound on the residual norm of the method, i.e $\|AV_ky -V_kH_ky\|$ and why it should converge to zero (where $y$ is the primitive Ritz vector). Any help in understanding this would be appreciated. Matrix $A$ is non-normal (any reference would be as well appreciated though).","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'numerical-linear-algebra', 'numerical-methods']"
4424411,Does there exist a uniform Monte-Carlo Approximation of certain function classes?,"Given a measurable and bounded function $f:X \to \mathbb{R}$ on a metric-measure space $(X, d, \mathcal{P})$ , we can approximate $\int_\chi f$ in terms of $N$ iid samples $X_1, \ldots, X_N \sim \mathcal{P}^N$ , i.e., for $\delta \in (0,1)$ , with probability at least $1-\delta$ , we have $$
|\frac{1}{N}\sum_{i=1}^N f(X_i) - \int_X f| \lesssim \frac{\|f\|_\infty \sqrt{\log(1/\delta)}}{\sqrt{N}}
$$ by Hoeffdings. Are there sufficient conditions on $X$ or $f$ under which this approximation is uniform in the samples, i.e., a result of the form:
Given samples $X_1, \ldots, X_N \sim \mathcal{P}^N$ it holds for all sufficiently regular functions $g$ , $$
|\frac{1}{N}\sum_{i=1}^N g(X_i) - \int_X g| \lesssim R\frac{\|g\|_\infty \sqrt{\log(1/\delta)}}{\sqrt{N}},
$$ where $R$ is a term depending on the regularity of the function class or $X$ ?
If not, do there exists results with a worse rate of convergence?","['monte-carlo', 'probability-theory', 'concentration-of-measure']"
4424436,"Proof that $n(c)$, the number of the roots of the equation $f(x)=c$, is measurable. [duplicate]","This question already has an answer here : Banach Indicatrix Function (1 answer) Closed 2 years ago . The entire question is: Let f be a continuous function on $[a,b]$ . Denote $n(c)$ the number of the roots of the equation $f(x)=c$ , which is finite or infinite. Proof that $n(c)$ is measurable on $\mathbb{R}$ . What I don't understand is how to use the characteristic function to express $n(c)$ and then illustrate $n(c)$ is measurable.","['measure-theory', 'real-analysis']"
4424442,How to calculate the number of paths of minimum length possible a knight can take to get from one corner of a chess board to the opposite one?,"I've written a small Python script to give me the least number of moves it takes a knight to get from one square to any other on a $n{*}n$ chess board. But then I've wondered how many paths the knight can take from one corner to the opposite one that use the minimal number of moves (i.e. on any $n{*}n$ board in $2*\Big\lceil{\frac{n-1}{3}}\Big\rceil$ moves, e.g. on a $8{*}8$ board in 6 moves). So, I added another function to the code to ""calculate"" exactly that number by doing all possible paths from the opposite corner to the start where every step involves a decrease in the minimum number of moves needed to get to that square (which is calculated beforehand with the other function I mentioned at the beginning). By now I have values for all $n$ from $1$ to $34$ (attached the list below). As you can see, the values get pretty big, which means it takes really long to calculate them using ""brute-force"" methods. Do you know of any way to calculate that number without the need of a computer trying all the possibilities?","['chessboard', 'recreational-mathematics', 'combinatorics']"
4424464,"""Any integrable r.v can be viewed as an element of a space that is a bit like Lp for p>1""","(Sorry in advance if this question was asked elsewhere in a different form, and/or if it is trivial.) In the proof of Lemma 4.5 of ""Stochastic calculus and financial applications"" (Steele 2001) the following fact is used with $f(x) = P(|Z| \geq x)$ where $E[|Z|]<\infty$ : (paraphrasing,) if $f: R_+ \to R_+$ is non-negative, decreasing and integrable, and $f(0)=1$ , then we can find a function $a$ such that $a(x) \geq 1$ , $a$ increases to $+\infty$ , and $$\int_0^\infty a(x) f(x) dx < \infty.$$ Is my above statement true, or is there some other important feature of $f(x) = P(|Z| \geq x)$ that I forgot? How does one show that statement? Does the statement remain true if we remove some of the assumptions on $f$ ? My attempt at a proof: Letting such an $f$ and supposing the contrary, if we construct a sequence $a_n$ satisfying the conditions and such that $a_n \to 1$ point-wise, and if we can ensure $\int_0^\infty \lim_n (f \cdot a_n) = \lim_n \int_0^\infty (f \cdot a_n)$ , then we can conclude $\int_0^\infty f = \infty$ , a contradiction. But I didn't manage to construct such a sequence $a_n$ . Thanks in advance!","['integration', 'stochastic-processes', 'probability-theory', 'real-analysis']"
4424521,What is wrong with my reasoning regarding tensor products?,"$\def\Rbb{\mathbf{R}}$ Let $F$ be a subfield of the field $K$ and let $V$ be an $n$ -dimensional vector space over $F$ . Then $K\otimes_FV\cong K^n$ . Considering the case when $F=K=\Rbb$ and $V=\Rbb^1$ , I have $$
\Rbb\otimes_\Rbb\Rbb^1=\Rbb^1(=\Rbb)\;.
$$ On the other hand, let $V$ and $W$ be two (finite-dimensional) vector spaces over the field $F$ . Then $$
V\otimes_F W\cong L(V,W;F)\;,
$$ where $L(V,W;F)$ denotes the set of all the bilinear maps from $V\times W$ to $F$ . If I let $V=W=\Rbb^1$ , and $F=\Rbb$ , then $$
\Rbb^1\otimes_\Rbb\Rbb^1
\cong L(\Rbb^1,\Rbb^1;\Rbb)
\cong \Rbb^2
$$ But $\Rbb^1$ cannot be isomorphic to $\Rbb^2$ . What is going wrong here? I guess one cannot ""identify"" $\Rbb^1$ and $\Rbb$ when talking about tensor products since one is a ""vector space"" while the other is a ""field"".","['multilinear-algebra', 'linear-algebra', 'tensor-products']"
4424534,How can we prove that $\mathbb{N^2}$ has the same cardinality as $2\mathbb{N} + 1$,"How can we prove that $\mathbb{N^2}$ has the same cardinality as $2  \mathbb{N} + 1$ ? I've thought about using Cantor's theorem and mapping every element in a coordinative system, am I going to the right direction or am I wrong?","['elementary-set-theory', 'cardinals', 'discrete-mathematics']"
4424578,Length of line segment from point in circle to circumference,"Given a circle centered at $(0, 0)$ with known radius $r$ , a point in the circle at $(a, b)$ , and an angle $\theta$ (wrt the horizontal axis), is it possible to find the length of the line segment from $(a, b)$ to the circumference of the circle at angle $\theta$ ? My initial approach was to construct a scalene triangle using the radius, the line segment of interest, and a line segment from the origin to $(a, b)$ . With that I would have 2 of the side lengths known, but I don't think it's enough information to solve using law of cosines. Any help would be appreciated.","['trigonometry', 'circles', 'geometry']"
4424618,A problem about set theory in Brezis Functional Analysis (Lemma 3.1's remark 1),"Here we have a family $(U_{\lambda})_{\lambda \in \Lambda}$ . Let $\Phi$ become a family of all $\cap_{\lambda \in \Gamma} U_{\lambda}$ , where $\Gamma \subset \Lambda$ is  finite. Then, in Lemma $3.1$ , we proved the family $\mathcal{F}$ obtained by forming arbitrary unions of elements from $\Phi$ is stable under $\cap_{finite}$ and $\cup_{arbitrary}$ . And the problem is, in the Remark $1$ below. If we reverse the order of operations in the construction of $\mathcal{F}$ , that is, let $\Psi$ become a family of all $\cup_{\lambda \in \Gamma} U_{\lambda}$ , where $\Gamma \subset \Lambda$ is arbitrary. Then $\mathcal{G}$ is obtained by forming finite intersections of elements from $\Psi$ . ""The family $\mathcal{G}$ is not stable under $\cup_{arbitrary}$ ."" I was trying to construct a counterexample to prove it but failed. Any hints will be appreciated. Thank you in advance and kind regards.","['measure-theory', 'real-analysis', 'functional-analysis', 'elementary-set-theory', 'general-topology']"
4424650,Algebraicity of compact Riemann surfaces,"I am taking a course in Riemann surfaces, in which the classical result about algebraicity of compact riemann Surfaces has been proven. However, I think there are some dubious points in the proof. Here is the outline: let X be our compact connected Riemann surface, let g be its genus. If D is a divisor whose degree d satisfies $d\geq2g+1$ , then the associated map $\varphi_{|D|}:X\rightarrow \mathbb{P}^N(\mathbb{C})$ , with $N=d-g$ , is a holomorphic embedding, so $Y=\varphi_{|D|}(X)$ is a closed submanifold of dimension $1$ in $\mathbb{P}^N$ . Now consider the graded $\mathbb{C}$ -algebra $R(D):=\bigoplus_{n\geq0} H^0(X,\mathcal{O}_X(n\cdot D))$ , with multiplication given by the product of global sections. Using what has been presented as the Castelnuovo-Mumford theorem, under these conditions there exists, for every $n\geq0$ , a natural surjection $$
H^0(X,\mathcal{O}_X(D))^{\otimes n}\rightarrow H^0(X,\mathcal{O}_X(n\cdot D))$$ which sends $s_1\otimes\dots\otimes s_n$ to $s_1\dots s_n$ . Indeed, since the product of sections is commutative, we obtain a surjection $$
\mathrm{Sym}^n(H^0(X,\mathcal{O}_X(D)))\rightarrow H^0(X,\mathcal{O}_X(n\cdot D))
$$ whence a surjective map $$
\mathbb{C}[z_0,\dots,z_N]_n\rightarrow H^0(X,\mathcal{O}_X(n\cdot D))$$ where $\mathbb{C}[z_0,\dots,z_N]_n\cong\mathrm{Sym}^n(H^0(X,\mathcal{O}_X(D)))$ is the space of homogeneous polynomials of degree $n$ .
Assembling these maps together, we obtain a surjective homomorphism of algebras $$
\alpha:\mathbb{C}[z_0,\dots, z_N]\rightarrow R(D)$$ whose kernel $I$ is a homogeneous ideal by construction of $\alpha$ ; therefore we can define the projective variety $Z=V(I)\subseteq\mathbb{P}^N$ . Furthermore, since $R(D)$ is a domain, $I$ is prime and $Z$ is irreducible. Using the isomorphism $\mathbb{C}[z_o,\dots,z_N]/I\cong R(D)$ and applying the Riemann-Roch theorem, we can see that the Hilbert polynomial of $Z$ is $p_Z(t)=\mathrm{deg}(D)t+1-g$ , so by the Hilbert-Serre theorem $Z$ has dimension $1$ (here by dimension I mean the supremum of the lengths of chains of irreducible subvarieties). Now a straightforward calculation shows $Y\subseteq Z$ . Furthermore, $Y$ is irreducible in the Zariski topology and has dimension $1$ being the image of $X$ via an embedding (here I mean, a priori, the dimension as a complex manifold). This implies $Y=Z$ . Here are my doubts: Why is $Y$ irreducible? My guess: suppose there exist homogeneous polynomials $F_1,\dots,F_r, G_1,\dots, G_s$ such that $Y=(Y\cap V(F_1,\dots,F_r))\cup (Y\cap V(G_1,\dots, G_s))$ . If $Y\cap V(F_1,\dots,F_r)$ is a proper non empty subset of $Y$ , its complement in $Y$ is open and contained in every $Y\cap V(G_j)$ . Since the restrictions of the $G_j$ on $Y$ , which is a Riemann surface, are holomorphic, they must be identically zero on $Y$ , hence $Y\subset V(G_1,\dots,G_s)$ . $Y$ is certainly a $1$ -dimensional complex manifold, but why is it $1$ -dimensional as a topological space with the Zariski topology? My guess: let $C$ be a Zariski closed subset of $\mathbb{P}^N$ : then $Y\cap C$ is either $Y$ or a finite set of points, by holomorphicity of the functions defining $C$ and compactness and ""one-dimensionality"" of $Y$ . If $Y\cap C$ is a proper Zariski irreducible subset of $Y$ , then it must be a point. Assuming the two previous points, why does the equality of the dimensions imply $Y=Z$ ? It would certainly be true if $Y$ were Zariski closed in $Z$ , but then $Y$ would be Zariski closed in $\mathbb{P}^N$ , which is exactly what we want. In general, a projective variety has the same dimension of any of its proper open subsets. Thank you kindly to anyone who will have the patience to read and help!","['riemann-surfaces', 'algebraic-geometry', 'projective-varieties']"
4424673,Classify groups of squarefree order $pqr$.,"Given distinct primes $p,q,r$ , how many groups of order $n=pqr$ do we have given that: I) $q, r = 1\pmod p$ and $r = 1 \pmod q$ II) $q,r=1\pmod p$ but $r \neq 1 \pmod q$ III) $q = 1\pmod p$ and $r = 1\pmod q$ but $r\neq 1\pmod p$ In any given case, there is always the trivial cyclic group $\Bbb Z_{n}$ . Since $n$ is squarefree, this is the only abelian group of order $n$ . So the interest here is the possible non-abelian groups of order $n$ . In all three cases, since $q=1\pmod p$ , we have the non-abelian group given by $\Bbb Z_{r} \times (\Bbb Z_{q} \rtimes \Bbb Z_{p})$ In case I) and III) there is the group: $\Bbb Z_{p} \times (\Bbb Z_{r} \rtimes \Bbb Z_{q})$ In cases I) and II), since $qr=1\pmod p$ , we have the groups $(\Bbb Z_{q} \times \Bbb Z_{r}) \rtimes \Bbb Z_{p}$ $\Bbb Z_{q} \times (\Bbb Z_{r} \rtimes \Bbb Z_{p})$ There should be more groups, at least in the first case though, so which ones, if any am I missing? For example, when $n=903$ , there should be $7$ non-isomorphic groups of order $n$ , according to this paper . Trivially, we have $\Bbb Z_{903}$ , but there are also the groups $\Bbb Z_{43} \times (\Bbb Z_{7} \rtimes \Bbb Z_{3})$ $\Bbb Z_{3} \times (\Bbb Z_{43} \rtimes \Bbb Z_{7})$ $(\Bbb Z_{7} \times \Bbb Z_{43}) \rtimes \Bbb Z_{3}$ $\Bbb Z_{7} \times (\Bbb Z_{43} \rtimes \Bbb Z_{3})$ This only accounts for $5$ of the $7$ different non-isomorphic groups. $n$ also follows I) one where $p=3$ , $q=7$ , and $r=43$ . Thanks for any help or hints.","['semidirect-product', 'group-theory', 'abstract-algebra', 'finite-groups']"
4424678,Obtaining the higher-order differentials of a function of one variable,"I'm considering the differential of a function of one variable $f$ to be defined as a function of two variables $df$ for which the following holds: $$df(x, h) = f'(x)h$$ All good so far. The extension to higher-order differentials, however, is what puzzles me. This is a passage from Courant: (...) it may be pointed out for the sake of completeness that we may also form second and higher differentials. For if we think of $h$ as chosen in any manner, but always the same for every value of $x$ , then $dy=hf'(x)$ is a function of $x$ , of which we can again form the differential. The result will be called the second differential of y , and will be denoted by the symbol $d^2y=d^2f(x)$ . The increment of $hf'(x)$ being $h\{f'(x+h)-f'(x)\}$ , the second differential is obtained by replacing the quantity in brackets by its linear part $hf''(x)$ , so that $d^2y=h^2f''(x)$ . We may naturally proceed further along the same lines, obtaining third, fourth, ... differentials of y, etc., which can be defined by the expressions $h^3f'''(x), h^4f^{iv}(x)$ , and so on. Two questions arise from this for me: The author writes of the second differential of a function. To arrive at it they had to arbitrarily fix some value of $h$ in order to define a new single-variable function $dy$ such that $dy(x) = hf'(x)$ for the given $h$ , and form the differential of this new function. Doesn't this procedure give rise to an infinite number of different functions, each associated with a different value of $h$ , which would, in turn, lead to an infinite number of different functions, all of which satisfy the definition of the second differential? Given that the first differential is a function of two variables, unlike the single-variable function from which it was formed, speaking of the second (and higher-order) differential as the differential of the differential doesn't seem accurate. Is there a procedure that circumvents the ""fix a value of $h$ "" argument and still leads to a rigorous definition in this context? Why is it simply assumed that the $h$ 's that multiply the higher-order derivatives in the definition of higher-order differentials are all the same ( ""third, fourth, ... differentials of y, etc., which can be defined by the expressions $h^3f'''(x), h^4f^{iv}(x)$ , and so on"" )? Shouldn't each $h$ be independent of the other, such that a more accurate description of the higher-order differentials should be $h_1h_2h_3f'''(x)$ , $h_1h_2h_3h_4f^{(4)}(x)$ ? Thanks.","['calculus', 'derivatives']"
4424692,Symplectic Reduction of 3-D Chern Simons Theory,"So, I'm new to gauge theories and symplectic reduction and was trying to analyze the Chern Simons theory in three dimensions. I have a few questions regarding the steps towards reduction. First off, is it necessary for the bundle to be trivial? Second, how does one explicitly calulate the extremal values of the functional? I know the solution is the curvature but don't even know how to formally work out the variational derivatives. Third, when analyzing the Hamiltonian for a manifold decomposed into a 2-D surface and a time interval, how does the Legendre transform work exactly? Fourth, Atiyah-Bott says that the space of connections of the surface has a symplectic structure and somehow the curvature represents its momentum map. Any insight into this? Finally, the solutions to the system are represented as a moduli space of flat connections. How does this fit in with the previous steps? Thank you very much in advance! Any help is welcome.","['symplectic-geometry', 'gauge-theory', 'moment-map', 'mathematical-physics', 'differential-geometry']"
4424724,What is the reason for the conventions used by modulus notation?,"Apologies in advance for what I anticipate will be a very dumb question. To give some background: I am a software architect thatâs been programming since the age of 8 and professionally for the last 15 years. Never had any formal university-level training; everything I know is self taught. As such, there are unorthodox gaps in my knowledge; for example, I have in-depth knowledge of subjects like set theory or statistics (given that I primarily work on business software), but when it comes to something like calculus the extent of my knowledge is that it exists and that itâs used in advanced graphics. However, now my career may take a turn to where I need an in-depth understanding of crypthography (on a mathematical / theoretical level). So, here I am in my 30âs going back to the roots and learning abstract, theoretical math & comp sci. Iâve hired a tutor for the purpose, who is an undergrad student in a comp sci program thatâs known for being very theory-focused. The question: Recently, he started teaching me modular notation. Being a software engineer, I am obviously deeply familiar with the modulus operator, and in the world of programming we use the % operator for the purpose. I.e. 3 % 5 = 3 . However, I was told that in mathematics, the notation is to arbitrarily add mod X to the end of an equation/problem block. So, everything is written as usual and there is a note at the end of the equation/problem specifying âunder what modulusâ everything in the problem is. This makes no sense to me whatsoever, and when I asked my tutor he said that he asked the same question in his class and the professor replied that âitâs just the way itâs doneâ. I understand that conventions can be unique, but this to me feels like a very radical departure from the way math is usually written down, and because of that â I feel like there has to be an underlying reason for it that I am not seeingâ¦ I am hoping that someone much more knowledgeable than me can help clarify my few questions and help it all make sense. Math is typically written left to right, with parenthesis and/or other symbols defining blocks/scopes. For example, the body of a square root can include massive formulas, but the scope of the square root is still visually defined. Same with parenthesis blocks and global operations done upon the entire block. Numbers and operations also follow in sequence, which have a value that they act on and an argument. For example, to get a sum of 4 numbers, we would write (2+5+7+8) (three individual operations), not (2,5,7,8 +) (apply this operator on all numbers in the set). But with the mod operator, it seems like itâs an arbitrarily-placed footnote at the end of a block, which on top of everything contains extremely vital information. There is no purpose to reading whatever formula is inside the block without first knowing âunder what modulusâ it is, so how does this work out in academia with page-long formulas? How exactly does scoping work? From my understanding, all of the below is syntactically legal: 3x = 15y mod 5 (2x + 8y) - 12z mod 5 (2x + 8y)(12z - 5x) mod 5 What happens if my problem is using a different modulus/base for different parts of the problem? Would this be legal? (3x + 4y mod 5) - (8z - 2a mod 8) ? What if I have nested clauses? I.e. (3x + (2a - 2b mod 7)^2 + 4y mod 5) - 17z mod 3 ? Thanks so much in advance to whoever can help me make sense of this system!","['notation', 'number-theory', 'modular-arithmetic', 'elementary-number-theory']"
4424763,Non-standard proof that every $f\in L^1(\mathbb{R}^k)$ has Lebesgue points almost everywhere,"I have stubbornly been attempting to prove that every Lebesgue integrable function $f$ has Lebesgue points almost everywhere, i.e., satisfies $$
\lim_{r\rightarrow0}\frac{1}{m(B_r)}\int_{B(x,r)}|f(y)-f(x)|\ dy=0
$$ for almost all $x\in\mathbb{R}^k$ , by my own means. Every proof of this result I have found utilizes the Hardy-Littlewood Maximal function, and the related inequality. My question is this: Is there some proof of the above result that doesn't rely on the Maximal function, preferably one with comparable brevity to the proof given in, for instance, Rudin's RCA?","['measure-theory', 'lebesgue-integral', 'real-analysis', 'alternative-proof', 'inequality']"
4424804,Limiting Distribution with Successive Transformations,"I am not sure if this is a new problem but it is one that I thought up and have been working on for some time. Alas, I have been unable to develop a complete solution to the problem and would be interested if there are any useful techniques or insights that the community could provide. I am looking for the continuous PDF $X$ that exists over $[0,1]$ and has the following relationship with is transformation: \begin{equation}
X \sim \frac{n}{n+X}
\end{equation} where $n \overset{iid}{\sim} U(0,1)$ . What I am trying to convey here is that taking any number of transformations of the form $\frac{n_1}{n_1+X}$ , $\frac{n_2}{n_2+X}$ , etc. does not change the distribution $X$ for which we are looking. Furthermore, successive transformations such as $\frac{n_2}{n_2+\frac{n_1}{n_1+X}}$ and so on result in the same distribution $X$ for which we are looking. Attempt 1 The first approach I took was took was to try to solve for $X$ by solving for the combination of random variates $n_1, n_2, ...$ and then performing the transformation on them. This became very messy and very quickly. Alas, this solution did not provide the limiting distribution but it did provide an insight. Each successive addition of a random variate changed the distribution for $X$ . Therefore, it did not seem that standard substitution techniques may be helpful with this type of problem. Attempt 2 I noticed that the distribution on the interval from $[0,\frac{n}{n+1}]$ was always in the form of $\frac{c}{(X-1)^2}$ , where $c$ is some constant. If this was the form of the limiting distribution for that interval, then perhaps I could apply the transformation on that segment of the distribution to gain insight about the remaining distribution $X$ . This too became very messy, very quickly but with the help of Mathematica, I was able to get an approximation of the distribution which would seems much closer to the real distribution than in my first attempt. The results I obtained were (apologies for the math wall): \begin{align}
 \frac{-X+(1-2 X) \log \left(\frac{X}{2 X-1}\right)+1}{2 (X-1)^2 (2 X-1)} && \frac{2}{3}\leq X<1 \\
 \frac{1}{48} (-25) \left(6 \text{Li}_2(-3)-3 \left(\text{Li}_2\left(\frac{1}{4}\right)+6\right)+\pi ^2-6 \log ^2(2)+\log (3) \log (64)+\log (2985984)\right) && 5 X=3 \\
 \frac{\text{Li}_2\left(\frac{1}{4}\right)+4+2 \log ^2(2)-3 \log (3)}{4 (X-1)^2} && 0<X\leq \frac{1}{2} \\
 \frac{12 (2 X-1) \text{Li}_2\left(\frac{X-1}{2 X-1}\right)-48 X+\pi ^2 (2 X-1)+12 ((2 X-1) \log (1-X)-2 X) \log (X)+12 \left((1-2 X) \log \left(-\frac{(X-1) X}{2 X-1}\right) \log (2 X-1)+X \log ((3-2 X) X-1)\right)-24 \tanh ^{-1}(1-2 X)+36}{24 (X-1)^2 (2 X-1)} && \frac{3}{5}<X<\frac{2}{3} \\
 \frac{\text{Li}_2\left(\frac{1}{4}\right) (2 X-1) (2-3 X)^2-2 (2-3 X)^2 (2 X-1) \text{Li}_2\left(\frac{X}{3 X-2}\right)+2 (2 X-1) (2-3 X)^2 \text{Li}_2\left(\frac{1-2 X}{2-3 X}\right)+33 X^2 \log \left(\frac{54}{X}-81\right)+2 \log \left(\frac{1}{X-1}+3\right) \left(21 X^2+\left(33 X^2+4\right) \log \left(\frac{X}{2 X-1}\right)\right)+2 \left(-9 X^3 \log \left(-27 (2-3 X)^2\right)+X \left(9 X^2 \log ((X-1) X)+2 \left(9 X^2+10\right) \log \left(\frac{2}{X}-3\right) \log (2 (X-1))+33 X \log \left(\frac{2 (X-1)}{3 X-2}\right) \log \left(\frac{X}{2-3 X}\right)+10 \log \left(\frac{X}{54-81 X}\right)\right)+\log (X-1) \left(-2 \left(9 X^2+10\right) X \log \left(\frac{2}{X}-3\right)-\left(33 X^2+4\right) \log \left(\frac{1-2 X}{3 X-2}\right)+16 X\right)+\left(\left(33 X^2+4\right) \log \left(\frac{1-2 X}{3 X-2}\right)-16 X\right) \log (3 X-2)\right)-\frac{1}{6} (2 X-1) (2-3 X)^2 \left(\pi ^2-12 \left(3+\log ^2(2)\right)\right)+\log \left(\frac{1}{(X-1)^8}\right)-4 \log (X)+8 \log \left(\frac{2 (X-1)}{3 X-2}\right) \log \left(\frac{X}{2-3 X}\right)+12 \log (6-9 X)}{4 (2 X-1) \left(3 X^2-5 X+2\right)^2} && \frac{1}{2}<X<\frac{3}{5} \\
 0 && X>1\lor X<0 \\
 \text{Indeterminate} && \text{True} \\
\end{align} Unfortunately, this approach does not seem to work well beyond the first two iterations and this is the best approximation I can get. Observation There may not be a feasible closed form solution to this problem. It seems as if the intervals for the individual sections may continue to break in accordance with fractions associated with the Fibonacci numbers: 1/2, 3/5, 8/11, etc. I haven't proven yet that this is indeed the case but if it is that way then a closed form solution is certainly not possible. Additional Desire I am not sure if this is yet possible either but I am trying to track how the maximum value of the distribution progresses over time. Even if there is no closed form for this distribution I wonder if there is a way that you can find a closed form solution for the maximum value of for the values for $x=0,1$ . As always, I appreciate any insights from the math hive mind!","['probability-distributions', 'probability-theory', 'probability']"
4424848,Can a space with $\pi_1(X)=F_2$ have a nontrivial covering space which is homeomorphic to $X$?,"Any finite sheeted connected cover of the circle is again homeomorphic to a circle. On the group level, this is consistent with the fact that subgroups of $\mathbb Z$ are isomorphic to $\mathbb Z$ . This leads to the question of whether one could find nontrivial covers which are still homeomorphic to the base space for other groups that have subgroups isomorphic to themselves. In particular, consider the free group on 2 generators $F_2$ . It has plenty of subgroups isomorphic to $F_2$ , so one can ask Question Is there a space $X$ with $\pi_1(X)\cong F_2$ which has a nontrivial cover $p\colon E\to X$ , where $E\cong X$ ? Clearly the standard example of $X=S^1\vee S^1$ doesn't work, but perhaps starting with $X$ as a graph of infinite valence might work, or perhaps there is an even more clever construction.","['examples-counterexamples', 'free-groups', 'covering-spaces', 'general-topology', 'algebraic-topology']"
4424853,How to evaluate the definite integral $\int _{0}^{\frac{\pi }{2}}\frac{\ln(\tan x)}{1-\tan x+\tan^{2} x}\mathrm{d} x$?,I am struggling with this integral: $\displaystyle \int _{0}^{\frac{\pi }{2}}\frac{\ln(\tan x)}{1-\tan x+\tan^{2} x}\mathrm{d} x$ What I tried so far: $\displaystyle \int _{0}^{\frac{\pi }{2}}\frac{\ln(\tan x)}{1-\tan x+\tan^{2} x}\mathrm{d} x$ $\displaystyle =\int _{0}^{\frac{\pi }{2}}\frac{\cos^{2} x\ln(\tan x)}{1-\sin x\cos x}\mathrm{d} x$ $\displaystyle =\int _{0}^{\frac{\pi }{2}}\frac{-\sin^{2} x\ln(\tan x)}{1-\sin x\cos x}\mathrm{d} x$ $\displaystyle =\frac{1}{2}\int _{0}^{\frac{\pi }{2}}\frac{\cos 2x\ln(\tan x)}{1-\sin x\cos x}\mathrm{d} x$ The answer should come out to be $\dfrac{-7\pi^2}{72}$ . Any help will be appreciated.,"['integration', 'calculus', 'definite-integrals', 'trigonometric-integrals']"
4424872,Solutions to nonlinear PDE derived from the Dirichlet energy in the stereographic plane,"Define a complex valued function $z$ in the stereographic plane and let $z=z(s,s^{*})$ for $s$ a complex valued variable and $*$ denoting the complex conjugate. Define the Dirichlet energy as $$ \int \frac{\lvert z_s \rvert^{2} + \lvert z_{s^{*}} \rvert^{2}}{(1 + \lvert z \rvert^{2})^{2}} \ ds ds^*. $$ Minimizing this with respect to $z^*$ we find that $z$ must satisfy the following nonlinear PDE: $$(1 + \lvert z \rvert^{2}) z_{s s^*} = 2 z^{*} z_s z_{s^{*}}. $$ Some simple solutions to this are $z = f(s)$ or $z = g(s^{*})$ for arbitrary functions $f, g$ . Are there other known solutions to this equation? Edit added: Are these solutions related to the spherical harmonics? If so, how can we compose two solutions in the stereographic plane to find another solution? I see reference to this equation here , but cannot find other useful references. Any tips on work that has been done on this equation are appreciated.","['complex-analysis', 'partial-differential-equations', 'differential-geometry']"
4424893,Is a differentiable function the product of differentiable functions subject to certain conditions?,"Honestly this is just a case of me not being great at constructing 'pathological' differentiable functions and I am not sure how to search for what I am looking for. This is related to an algebraic method of constructing cotangents that I have seen before, but it has been a long time so I don't remember the details. Let $D$ be the set of functions $f$ on $\Bbb{R}$ which are differentiable at $0$ and have $f(0)=0$ . Suppose $f_0\in D$ has $f_0'(0)=0$ . Let $D\cdot D$ be the set of finite sums of products of elements of $D$ . (i.e. the product ideal) Is it the case that $f_0\in D\cdot D$ ? If not is there a counterexample? It is easy to show that $f_0\in C\cdot D$ where $C$ is the set of continuous functions $f$ with $f(0)=0$ but I can't see if it is true in the restricted case. Any help or references would be appreciated","['derivatives', 'real-analysis']"
4424896,Mean Value Theorem question (show that f is constant),"Suppose that $f, g : R â R$ are functions such that $$|f(x) â f(y)| â¤ |g(x) â g(y)| \sqrt{|x â y|}$$ for any $x, y â R$ .
If $g$ is differentiable with bounded derivative on all $R$ , show that $f$ is constant. I know I am meant to be using MVT for this question, I attempted to use $g(x)$ as the function because we know it is differentiable (condition required for MVT): $$\frac{g(b)-g(a)}{b-a}=g'(c)$$ $$|g(b)-g(a)|=|g'(c)|b-a|$$ I am lost, not sure where to start the question.","['continuity', 'derivatives', 'mean-value-theorem']"
4424917,Number of Sylow $p$-subgroup of $\mbox{SL}_n(\Bbb F_p)$.,"What is the number of Sylow $p$ -subgroup of $\mbox{SL}_n(\Bbb F_p)$ where $\Bbb F_p$ is finite field of order $p$ ? This problem is known for $\mbox{GL}_n(\Bbb F_p)$ . By checking the order, strictly upper triangular matrix $P$ is a Sylow $p$ -subgroup of $\mbox{GL}_n(\Bbb F_p)$ . I know the normalizer of $P$ in $\mbox{GL}_n(\Bbb F_p)$ is a group of upper triangular matrices $T$ . Since the order of $T$ is $(p-1)^n p^{1+2+\cdots n-1}$ , the number of Sylow $p$ -subgroup of $\mbox{
GL}_n(\Bbb F_p)$ is $$n_p = {(p^n-1)(p^n-p)\cdots(p^n-p^{n-1})\over (p-1)^np^{1+2+\cdots+(n-1)}}.$$ Since $P$ is also Sylow $p$ -subgroup of $\mbox{SL}_n(\Bbb F_p)$ , all I need to do is compute the number of $\det =1$ elements in $N:=N_{\mbox{GL}_n(\Bbb F_p)}(P)$ . I tried to use the fact that for any given $A\in N$ , I can correct one value in the diagonal to make $\det A =1$ . But I don't know how to get further.","['matrices', 'group-theory', 'abstract-algebra', 'sylow-theory']"
4424919,Is this function monotonically increasing as $x_2$ increases?,"Suppose I have a differentiable and continuous function $f(x)>0$ , the monotonicity of $f(x)$ is unknown. Assume that $x_1< x_2< x_3 \in \mathcal{S}$ , $\mathcal{S}$ is the domain of $f(x)$ . let $g(x)$ be \begin{equation}
g(x_2)=2x_2-\frac{\int_{x_1}^{x_2}xf(x)dx}{\int_{x_1}^{x_2}f(x)dx}-\frac{\int_{x_2}^{x_3}xf(x)dx}{\int_{x_2}^{x_3}f(x)dx}
\end{equation} Actually, $g(x_2)$ is the $2x_2$ minus the sum of centroids in $(x_1,x_2)$ and in $(x_2,x_3)$ . My question is : Is $g(x_2)$ is monotonically increasing as $x_2$ increases? Some MatLab simulation results show that $g(x_2)$ seems to be a monotonically increasing of $x_2$ .
But, can we theoretically show this? I have tried to see if the derivation of $g(x_2)$ is always large than $0$ , but the result is not explicit. ------------------------------------------------------------------------------------------------------------------- Thanks for the answer from @Greg Martin . Actually, in my problem, $f(x)$ is an asymmetrical probability density function with $x\geq 0$ . Now, I still have a question: Does $g(x)=0$ have and only have one root? Thanks for any helpful answers!","['integration', 'functions', 'centroid', 'monotone-functions']"
4424970,Entropy of fair but correlated coin flips,"Consider the joint distribution, $p(\xi_1,...\xi_N)$ , with components defined as $\xi_i=\mathrm{sign}(x_i)$ , with $(x_1,...,x_N)\sim\mathcal{N}(0,\Sigma)$ with $
\Sigma_{ij}=\delta_{ij}+(1-\delta_{ij})\tilde{\rho}
$ , i.e. all off-diagonal entries of $\Sigma$ are $\tilde{\rho}$ . Since all components $x_i$ have unit variance (i.e. diagonal entries of $\Sigma$ are $1$ ), $\tilde{\rho}$ is then the correlation of any pair $(x_i,x_j)$ . Note that all single component marginals $p(\xi_i)=1/2$ , i.e. the coins are unbiased; we can always set the value of $\tilde{\rho}$ so that any pair $(\xi_i,\xi_j)$ has the desired correlation of $\rho$ . What is the formula for the entropy of $p(\xi_1,...\xi_N)$ , denoted $H_N(\rho)$ ? The parametrization of $\tilde{\rho}$ by $\rho$ depends on $N$ and is obtained by calculating the pair marginal probability $p(\xi_i=1,\xi_j=1)$ , denoted $p_{11}$ . Let $f_N(\tilde{\rho})$ be the function of $\tilde{\rho}$ that gives this probability. The formula for the correlation between two binary random variables, $$
\rho=\frac{p_{11}-p_{-1}p_1}{\sqrt{p_{-1}(1-p_{-1})p_1(1-p_1)}}={4}p_{11}-1\;,
$$ with $p_{\pm1}$ denoting $p(\xi_i=\pm 1)=p(\xi_j=\pm 1)=1/2$ , gives the desired parametrization, $$
\tilde{\rho}_N(\rho):=f^{-1}_N\left(\frac{\rho+1}{4}\right)\;.\;\;\;\;(\mathrm{eq}.1)
$$ Solution for $N=2$ : Computing the 2D Gaussian integral using spherical coordinates gives $\tilde{\rho}_{N=2}(\rho)=\sin(\frac{\pi}{2}\rho)$ . In this special case, $(\mathrm{eq}.1)$ and symmetry constraints completely specify the distribution $p(\xi_1,\xi_2)=(1+\xi_1\xi_2\rho)/4$ . Calculation of the entropy from its definition gives $$
H_{N=2}(\rho)=H(\xi_1,\xi_2)=\sum_{\eta=(1\pm\rho)/4}2\left(-\eta\log_2\eta\right).
$$ We have $H_{N=2}(0)=2$ bits and $H_{N=2}(1)=1$ bit. In fact, we know $H_N(\rho=0)=N$ and $H_N(\rho=1)=1$ for all $N$ . For $N>2$ : There are lots of Gaussian integrals to do. Due to the symmetry in the index permutations there are only $N$ distinct integral values among the $2^N$ terms in the entropy. They can be grouped by how many 1s they contain. The pair of all $-1$ s can be grouped with the singleton group of all $1$ s due to the reflective symmetry in the plane normal to the main diagonal. We just need compute the multiplicity and the integral for each of the $N$ terms. E.g. for $N=2$ there are 2 terms (listed above with multiplicity 2). For $N=3$ there are three terms (two for tuples containing one and two 1s), the third being the extreme group having $(-1,-1,-1)$ and $(1,1,1)$ in binary notation. In section 3.2 of this paper , Six gives a recursive solution to the distribution. This could be used to compute the entropy and the parametrization function $\tilde{\rho}_N(\rho)$ . Accepted Answer : In the end, an alternative approach based on expressing $x_i=\sqrt{1-\tilde{\rho}}y_i+\sqrt{\tilde{\rho}}s$ , with $y_i,s\sim\mathcal{N}(0,1)$ , seems to be more straightforward and is the accepted answer below. That answer also indicates that the $f_N(\tilde{\rho})$ does NOT seem to depend on $N$ after all.","['entropy', 'probability-distributions', 'information-theory', 'multiple-integral', 'probability']"
4424999,Showing the polarization of (complex) quadratic form is sesquilinear. [duplicate],"This question already has answers here : Can we define an inner product in terms of the norm induced by it? (1 answer) Polarization of quadratic form yields sesquilinear form (1 answer) Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Let $q: V\times V \to \mathbb{C}$ on a complex vector space $V$ be a quadratic form. Define $\tilde q$ by the polarization identity: $$
\begin{equation}
\tilde q(\phi,\psi)  = \frac{1}{4} [q(\phi + \psi) -q(\phi - \psi) + iq(\phi + i\psi) - iq(\phi - i\psi)]  
\end{equation}
$$ My question is how can I show that $\tilde q$ is sesquilinear? My plan is to show that (1) $\tilde q$ is skew-symmetric, and (2) linear in the second argument. However, to show (2), I'm not exactly sure how to do so given that $q$ is defined in complex space. I found a hint that tells me to show that a. $\tilde q(\phi, 2\psi) = 2\tilde q(\phi, \psi)$ b. $\tilde q(\phi, \psi + \psi') = \tilde q(\phi, \psi) + \tilde q(\phi, \psi')$ c. $\tilde q(\phi, \pm i\psi ) = \pm i\tilde q(\phi, \psi)$ d. $\tilde q(\phi, \alpha\psi ) = \alpha\tilde q(\phi, \psi )$ for all dyadic rationals in $\mathbb C$ . It makes sense to me that we need to take the complex part into account for $c$ and $d$ . However, I have no idea what $d$ means. Also for $a$ , is the number 2 just some random real integer? PS: Here's the definition I want to use for (complex) quadratic form: $q(\lambda x) = |\lambda|^2q(x)\quad \forall \lambda\in\mathbb C, x\in V$ $q(\phi+\psi) + q(\phi-\psi) = 2q(\psi)+2q(\phi)$ From 2, we could rewrite the polarization identity as $$
\tilde q(\phi,\psi) = \frac{1}{2}[q(\phi+i\psi)-q(\phi)-q(\psi)] - \frac{i}{2}[q(\phi+i\psi)-q(\phi)-q(i\psi)]
$$ But I'm unsure if that's helpful for showing $\tilde q$ is sesquilinear. Thanks for the help!","['riesz-representation-theorem', 'hilbert-spaces', 'functional-analysis', 'quadratic-forms', 'sesquilinear-forms']"
4425056,Which categories are useful for representing groups?,"Given a group $G$ and a category $\mathcal{C}$ , we may consider representations of $G$ in $\mathcal{C}$ , i.e. homomorphisms $G \to \text{Aut}_{\mathcal{C}}(X)$ , where $X$ is an object of $\mathcal{C}$ . Representation theory of groups is usually done in the settings when $\mathcal{C}$ is one of the categories $\text{Set}$ , $\text{Vect}$ or $\text{Hilb}$ (the latter having isometries as morphisms). Are there any other categories in which representation theory of groups is done and yields valuable insights? Is it interesting for example to study the case when $\mathcal{C}$ is a category of modules, or a category of Lie algebras?","['group-theory', 'representation-theory', 'category-theory']"
