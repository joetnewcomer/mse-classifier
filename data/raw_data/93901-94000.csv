question_id,title,body,tags
1283700,Understanding why $f(x)=2x$ is injective,"Dr. Charles Pinter's ""A Book of Abstract Algebra"" shows a proof of why a function ' $f$ ' is injective and surjective. Given $$f(x)=2x,$$ we claim $f$ is injective. Proof . Suppose $$f(a)=f(b);$$ that is, $$2a=2b.$$ This implies $$a=b.$$ Therefore $f$ is injective. Intuitively, I understand why $$f(x)=2x$$ is injective, but I don't understand the above proof. Why does showing that $$a=b$$ for $$f(a)=f(b)$$ prove that $f$ is injective?",['functions']
1283702,What is the best way to explain setting a restriction on $\delta$ in $\epsilon$-$\delta$ proofs?,"I'm trying to prepare a somewhat informal lesson striving to provide an intuitive understanding of why for some limit proofs, we have to set an upper bound on $\delta$. For example, here's part of the preliminary analysis of the proof I'm walking through: Problem: Prove that $\displaystyle \lim_{x\to3} 9x^2+6x+1=100$.
  $$\begin{align*}
\left|9x^2+6x+1-100\right|&=\left|9x^2+6x-99\right|\\
&=3\left|3x^2+2x-33\right|\\
&=3|(3x+11)(x-3)|\\
&=3|3x+11||x-3|
\end{align*}$$
  Now if we let $\delta\le1$, we have
  $$|x-3|<1\implies-1<x-3<1\implies17<3x+11<23\implies|3x+11|<23$$
  $$\begin{align*}
\left|9x^2+6x+1-100\right|&=3|3x+11||x-3|\\
&<69|x-3|\\
&<\epsilon
\end{align*}$$
  which means $\delta=\min\left\{1,\dfrac{\epsilon}{69}\right\}$ is sufficient. What's the best way to illustrate why we set $\delta\le1$ in an intuitive way, and why it is sometimes necessary to use a different upper bound?","['proof-explanation', 'limits', 'intuition', 'epsilon-delta']"
1283713,Let $f:U \to V$ be a bijective holomorphic function. Show that inverse of $f$ is also holomorphic.,"Suppose $U$ and $V$ be domains(i.e., open and connected) in $ \mathbb C$.Let $f\colon U \to V$ be a bijective holomorphic function. Show that the inverse of $f$ is also holomorphic. By Open Mapping Theorem it is clear that $f^{-1}$ is also continuous. Please give some ideas to complete the proof. Edit :I'm interested in a proof which comes as a corollary of  open mapping theorem","['complex-analysis', 'functions']"
1283736,$f(x)=3x+4$ - Injective and Surjective?,"As a follow-up to Understanding why $f(x)=2x$ is injective , I'm working on proving/disproving that $$f(x)=3x+4,$$ where inputs/outputs live on real numbers, is injective and surjective. Supposing that $$f(a)=f(b),$$ then $$3a+4=3b+4.$$ Solve for $0$: $$3a+4-4-3b=0$$
$$3(a-b)=0$$ So, $a$ must equal $b$. Therefore, $f$ is injective. With respect to whether it's surjective, I looked at its graph: Since $$3x + 4$$ is linear, then it's continuous, I believe. As a result, is that proof enough that it's surjective, i.e. for all $x$ in $$f(x),$$ the output will cover all real numbers?","['proof-verification', 'functions']"
1283743,Use of Taylor's Theorem to show nonconstant polynomials can't have all prime values,"I'm working through Alan Baker's book A Concise Introduction to the Theory of Numbers , and there's an assertion in there that confuses me. Here's the quote: It is easily seen that no polynomial $f(n)$ with integer coefficients can be prime for all $n$ in $\mathbb{N}$, or even for all sufficiently large $n$, unless $f$ is constant. Indeed, by Taylor's theorem, $f(mf(n)+n)$ is divisible by $f(n)$ for all $m$ in $\mathbb{N}$ How is this an application of Taylor's theorem? It's entirely mysterious to me. Thanks in advance for any insight on this.","['taylor-expansion', 'polynomials', 'number-theory', 'elementary-number-theory']"
1283783,An example of an infinitely differentiable function with compact support,"Could anyone give me a function infinitely differentiable on the real line and having a compact support? And the function must be nonnegative and normalized, i.e. the integration of the function on the real line must be one. I tried to think of one myself, but it seems trickier than expected.",['calculus']
1283844,Showing that ln$(xy)$ = ln $x$+ln $y$,"Let ln $x\  =\ \int_1^x \frac{1}{t}\ dt.$ How do I show that ln$(xy)$ = ln $x$+ln $y$ where $x$ and $y$ are positive reals.
I read the following proof from Limaye book. Fix $y\in (0,\infty).$ Consider $f(x)=$ ln $xy$ -ln $x$. Then 
$f'(x)= \frac{1}{xy}.y-\frac{1}{x}=0 \ \forall\  x \in (0,\infty). $ $\therefore f$ is constant.
 $f(x)=f(1)=$ ln $y$ - ln $1 = $ ln $y.$ $ \therefore f(x) =  $ln$ (xy) - $ln$ x = $ln$  y\ \implies\   $ln$ (xy) = $ln$ \ x + $ ln$\   y$ I feels that this proof is so constructive. Im wondering to know some alternative proofs. Thanks in Advance...","['calculus', 'real-analysis', 'algebra-precalculus']"
1283920,$f(x)=x^{3}+1$ - Injective and Surjective?,"Dr. Pinter's ""A Book of Abstract Algebra"" presents this exercise: Prove/disprove whether the following function $f$ (with inputs/outputs of real numbers) is injective and/or surjective:
  $$f(x)=x^{3}+1.$$ Using this helpful answer , I solved for $$f(a)=f(b)\colon$$ $$f(a)=a^{3}+1$$ 
$$f(b)=b^{3}+1$$
$$a^{3}+1=b^{3}+1$$
$$a^{3}=b^{3} \text{ subtract 1 from each side}$$
$$(a^{3})^{1/3}=(b^{3})^{1/3} \text{ take the cubic root of each side}$$
$$a=b$$ Therefore, $f$ is injective. Again, following that helpful answer, solve for $x$, and then plug into $f(x)$: $$y=x^{3}+1$$
$$y-1=x^{3}$$
$$x=(y-1)^{\frac{1}{3}}$$ Now, plug $x$ into $f$, and check if result equals $y$, which would prove the surjective property. $$f(x)=x^{3}+1$$
$$y=((y-1)^{1/3})^{3}+1 \text{ use $y$ rather than $f(x)$}$$
$$y=y-1+1$$
$$y=y$$ Therefore, it's also surjective. Is this right?","['proof-verification', 'functions']"
1283931,"Let $A = [0,1) \cup (3,4]$ be a subset of $(\mathbb R, \mathfrak T_H)$","Let $A = [0,1) \cup (3,4]$ be a subset of $(\mathbb R, \mathfrak T_H)$ $\mathfrak T_H$ is the collection of all subsets of $U$ of $\mathbb R$ such that either $U = \emptyset$ or for each $x \in U$ there is an interval of the form $[a,b)$  such that $x \in [a, b) \subseteq U$. Find $Int(A)= [0,1)$ $Cl(A)= $ $Ext(A)= (-\infty, 0)\cup (1,3) \cup (4, \infty)$ $Bd(A)= $ I have a really hard time picking out these sets in anything other than the usual topology. My defintions are as follows:
Interior-  Let $(X, \mathfrak T)$ be a topological space and let $A \subset X$ is the set of all points $x \in X$ for which there exists an open set $U$ such that $x \in U \subseteq A$. Closure- Let $(X,\mathfrak T)$ be a topological space and let $ A \subseteq X$ . The closure of $A$ is $Cl(A) = \bigcap \{U \subseteq X: U$ is a closed set and $A \subseteq U\}$ 
Based on this I know $A \subseteq Cl(A)$ Exterior-
Boundary- $A'$ is the set of all limit points and my definition for this is: Let $(X, \mathfrak T)$ be a topological space with $A \subseteq X$.  A point $x$ in $X$ is said to be a limit point of $A$ provided that every open set containing $x$ contains a point $A$ different from $x$.","['elementary-set-theory', 'general-topology']"
1283941,"Suppose $\sum x_n$ converges (not necessarily absolutely), does $\sum \sin x_n$ necessarily converge?","The question is: If $\sum x_n$ converges, does $\sum \sin x_n$ converge? I know that if $\sum x_n$ converges absolutely, then $\sum \sin x_n$ converges. My intuition is that we cannot completely abandon absolute convergence, but I am struggling to come up with a counterexample.","['sequences-and-series', 'limits', 'real-analysis', 'convergence-divergence']"
1283959,Which Lie groups are also symmetric spaces?,"I've scanned some of the literature on this, but couldn't find an answer to the following simple questions (probably because I'm not an expert): Q1: Let G be a Lie group with a left-invariant metric. What are some simple criteria for G to be symmetric, namely, for G to admit, for any point and geodesic through that point, an isometry reversing that geodesic? Q2: In three dimensions, in terms of the structure constants, one can easily work out essentially all simply-connected groups very concretely. Is there a criterion for going through the list of 3D Lie groups, looking at the structure constants, and deciding which ones are symmetric spaces? Thank you for your time!","['lie-groups', 'differential-geometry']"
1283975,Let $A$ be a subset of a topological space. Prove that $Cl(A) = Int(A) \cup Bd(A)$,"Let $A$ be a subset of a topological space.  Prove that $Cl(A) = Int(A) \cup Bd(A)$ Here are my defintions: Closure:    Let $(X,\mathfrak T)$ be a topological space and let $ A \subseteq X$ . The closure of $A$ is $Cl(A) = \bigcap \{U \subseteq X: U$ is a closed set and $A \subseteq U\}$  Based on this I know $A \subseteq Cl(A)$ Interior:Let $(X, \mathfrak T)$ be a topological space and let $A \subset X$ is the set of all points $x \in X$ for which there exists an open set $U$ such that $x \in U \subseteq A$. My definition of boundary is: Let $(X,\mathfrak T)$ be a topological space and let $A \subseteq X$. A point $x \in X$ is in the boundary of A if every open set containing $x$ intersects both $A$ and $X−A$. My proofs start by picking an element to be in each side then showing it must be in the other side.  I have tried to start that here. Let $x \in Cl(A)$ then Let $x \in Int(A) \cup Bd(A)$.  Then $x\in Int(A)$ or $x\in Bd(A)$ If $x \in Int(A)$ then","['elementary-set-theory', 'general-topology', 'proof-writing']"
1283979,"""More"" than nowhere locally bounded function","I describe here a function $g$ (based on Thomae's function) that is nowhere locally bounded. In particular the image of any interval $(a,b)$ under $g$ is an unbounded segment of the integers $\mathbb{N}$. Is it possible to find a function such that the image of any interval $(a,b)$ would be  the full set of the reals?","['real-analysis', 'functions']"
1284039,What function satisfies $f(x)+f(−x)=f(x^2)$?,What function satisfies $f(x)+f(−x)=f(x^2)$? $f(x)=0$ is obviously a solution to the above functional equation. We can assume f is continuous or differentiable or similar (if needed).,"['calculus', 'algebra-precalculus', 'functional-equations']"
1284043,Vector Spaces: Redundant Axiom?,"Question Why are the axioms for vector space independent? More precisely $1x=x$ seems redundant... (I take the axioms from: Wikipedia ) Explanation One has for zero vector:
$$\lambda0+\lambda0=\lambda(0+0)=\lambda0\implies\lambda0=0$$ And for zero scalar:
$$0x+0x=(0+0)x=0x\implies0x=0$$ In familiar form:
$$\lambda x=0\implies\lambda=0\lor x=0$$ Threrefore one calculates:
$$1(1x+x^{-1})=1(1x)+1(x^{-1})=(11)x+1(x^{-1})=1x+1(x^{-1})=1(x+x^{-1})=10=0$$ Hence for nontrivial field:
$$1\neq0\implies1x+x^{-1}=0\implies1x=x$$ But where is the flaw in that check??","['vector-spaces', 'linear-algebra', 'definition', 'axioms']"
1284067,A necessary and sufficient criterion for an element of a multiplier $ C^{*} $-algebra to be positive.,"I am trying to find a reference for the following assertion: Let $ A $ be a $ C^{*} $-algebra, and let $ M(A) $ denote its multiplier algebra. Then $ m $ is a positive element of $ M(A) $ if and only if $ a^{*} m a $ is a positive element of $ A $ for all $ a \in A $. In other words,
  $$
m \in M(A)_{\geq} \iff (\forall a \in A)(a^{*} m a \in A_{\geq}).
$$ The forward implication is trivial because if $ m \in M(A)_{\geq} $, then there exists an $ n \in M(A) $ such that $ m = n^{*} n $, so
$$
\forall a \in A: \quad
    a^{*} m a
=   a^{*} n^{*} n a
=   (n a)^{*} (n a)
\in A_{\geq}.
$$ Note: $ A $ is an ideal of $ M(A) $, so $ n a \in A $ for all $ a \in A $. I have absolutely no idea how to prove the backward implication though. Thank you very much for your gracious help.","['c-star-algebras', 'operator-algebras', 'reference-request', 'functional-analysis']"
1284084,Which of the following collections are topologies for $\mathbb R$? Am I correct?,"Which of the following collections are topologies for $\mathbb R$? I think I have these correct I just want to double check my answers. (a) $\{\mathbb R, \emptyset, (-\infty, 0), (0,\infty)\}$- Yes, empty set and whole line are included, intersections and unions are as well. (b) $\{\mathbb R, \emptyset, (1,4), (2,5)\}$ no as the intersection of $(1,4)$ and $(2,5)$ is not included in the topology. (c) $\{U : U = \emptyset$ or $U = \mathbb R$ or $U = (-\infty, b]$ for some $b \in \mathbb R\}$- I originally thought this was no now I am going back and saying yes.  The other 2 I feel confident about this is the one I am shaky on.","['elementary-set-theory', 'solution-verification', 'general-topology']"
1284090,"""Easier"" way to prove $|X| < |\mathcal P \left({X}\right)|$?","(EDIT: Thanks for the counterexample. The assumption $(\forall f)(sur(f) \iff |Im(f)| = |B|)$ is the major flaw in the proof, since it's only true when $B$ is finite.) I was reading about Cantor's theorem and I think I understood his diagonal argument. However, it seems to me that there's an easier approach (surely I'm wrong, but I don't know why). First, a lemma: Lemma : If there exists a $f_1 : A \to B$ which is injective and not surjective, then there's no surjection between $A$ and $B$. Proof: We want to prove that $[(\exists f_1) (inj(f_1) \land \lnot sur(f_1))]\to [(\forall f)(\lnot sur(f))]$ . Note that if $f: A \to B$, then $(\forall f)(sur(f) \iff |Im(f)| = |B|)\land(inj(f) \iff |Im(f)|=|A|)$. Therefore we want to prove that $ [(\exists f_1) (|Im(f_1)|=|A| \land |Im(f_1)|<|B|)]\to [|A|<|B|]$, what is true. Theorem : $|X| < |\mathcal P \left({X}\right)|$ Proof: Consider the function $f: X \to \mathcal P \left({X}\right)$ given by $f(x)= \{x \}$. Therefore, $f$ is injective ($(\forall x,y\in X)\{ x\} = \{ y\} \to x=y$, by extensionality) and not surjective ($(\forall x,y\in X) x \neq y \to (\forall a \in X)(f(a) \neq \{x,y \})$, by extensionality). Then, $|X| < |\mathcal P \left({X}\right)|$.",['elementary-set-theory']
1284119,Solve the equation $\left|\frac{x}{x-1}\right| = 1$,"Question: Solve the equations $$\left|\frac{x}{x-1}\right| = 1$$ Attempted solution: $$\left|\frac{x}{x-1}\right| = 1 \Leftrightarrow$$ Distributing the absolute value function. $$\frac{|x|}{|x-1|} = 1 \Leftrightarrow$$ Moving up the denominator: $$|x| = |x-1| \Leftrightarrow$$ Critical events may occur at x = 0 and x = 1, so we have three different cases: Case 1: $~~~~x \leq 0$ $$-x = x - 1 \Leftrightarrow 2x - 1 = 0 \Leftrightarrow x = \frac{1}{2}$$ However, this is a false solution, since $\frac{1}{2}$ is not less than 0. Case 2: $~~~~0 < x < 1$ $$x = -(x-1)$$ This leads to 1 = 0 and thus no solution exists here. Case 3: $~~~~x > 1$ $$x = x -1$$ This leads to a -1 = 0 expression and thus no solutions exists here. This line of argument would lead one to conclude that there are no solutions for this, yet a sanity check with $x = \frac{1}{2}$ satisfies the relationship. Where did I go wrong?",['algebra-precalculus']
1284123,"How i can find the fourier transform of $\frac{\sinh(ax)}{\sinh(\pi x)}$ where,$ |a| < \pi$","Using a rectangular contour in the complex plane, bypassing the poles at $z=0$ and $z=i$, i got $$\int_{-\infty}^{+\infty}\frac{\sinh(ax)e^{ikx}}{\sinh(\pi x)}dx - e^{-k}\int_{-\infty}^{+\infty}\frac{\sinh[a(x+i)]e^{ikx}}{\sinh(\pi x)}dx = \sin(a)e^{-k}$$ and now?","['fourier-analysis', 'complex-analysis', 'contour-integration']"
1284141,A limit involving nested trigonometric functions and logarithms,"Evaulate
  $$ L = \lim_{x \to 0} \frac{1-\cos(\sin x)+\ln(\cos x)}{x^4}. $$ I can solve it using Maclaurin series, but I'm trying to figure out a way to the solution without using it. L'Hopital would probably work but needs to be applied 4 times, and the given function in numerator is too complicated for things to work out nicely on paper. I think we can somehow use $\displaystyle\lim_{x\to0}\frac{1-\cos(x)}{x^2}=\frac12$ and $\displaystyle\lim_{x\to0}\frac{\ln(1+x)}{x}=1$. With these, I can lower the degree of denominator to $2$, like this: $$ L = \lim_{x \to 0}\frac{\frac{1 - \cos(\sin x)}{\sin^2 x}\frac{\sin^2 x}{x^2}+\frac{\ln(1+(\cos x-1))}{\cos x - 1}\frac{\cos x - 1}{x^2}}{x^2}. $$ This seems closer because left and right terms in the numerator are made of known limits, but the problem is that the whole expression is still $(1/2 - 1/2)/0 = 0/0$ so I can not break down $L$ into two limits and work things out. I'm looking only for solutions involving manipulating limits in this way. No Maclaurin and no L'Hopital if it's gonna get too messy on paper.",['limits']
1284144,Nonlinear Partial DE,"In my work I have faced with following partial differential equation $$\left(\frac{\partial u}{\partial x}\right)^2-\left(\frac{\partial u}{\partial y}\right)^2+f(x,y)\frac{\partial u}{\partial x}\frac{\partial u}{\partial y}=0$$ where $f(x,y)=\frac{1}{2}\frac{(y^2-x^2)^2}{xy(x^2+y^2)}$, $u=u(x,y)$ I've tried to solve it by method of characteristic , but it was too complicated. Maybe someone knows something about this type of PDE? Anyway I would be grateful for any hints.","['mathematical-physics', 'ordinary-differential-equations', 'partial-differential-equations']"
1284150,Can every infinite cardinal $\mu$ such that $\kappa\leq\mu\leq2^\kappa$ be expressed as $\kappa^\lambda$?,"Let $\kappa$ be an infinite cardinal. Can I reach every intermediate cardinal $\mu$ with $\kappa \le \mu \le 2^\kappa$ as some power $\kappa^\lambda$? If not, is there another construction that allows me to reach every cardinal between $\kappa$ and $2^\kappa$?","['elementary-set-theory', 'cardinals']"
1284159,"Proof of Cauchy-Schwarz inequality from Terry Tao's notes, meaning of ""cancelling the phase""","I was reading Tao's proof of the Cauchy-Schwarz inequality by exploiting certain inherent symmetries and making some transformations.
He says that first we use the fact that the norm is positive, i.e. $$\|u-v\|^2>0$$ to conclude that $\operatorname{Re} (\langle u,v\rangle) \leq \frac{1}{2}\|u\|^2+\frac{1}{2}\|v\|^2$,
 and then he claims that we make a transformation $$v \mapsto ve^{\iota \theta}$$
and the RHS is clearly preserved under the transformation whereas the LHS changes. Now he says that we choose a $\theta$ to make the LHS as high as possible such that it cancels the phase of $\langle u,v\rangle$. The rest of the proof is clear. But I don't get what he means by cancelling the phase. I mean the transformation is such that $\operatorname{Re} (\langle u,v\rangle)e^{\iota \theta} \mapsto |\langle u,v\rangle|$ for the theta which cancels the phase and for this particular theta we are kind of recovering the imaginary part of the complex scalar and then take its length. But how does it work? I don't understand it.","['complex-analysis', 'real-analysis', 'inequality']"
1284161,Visual proof of $\sum_{n=1}^\infty \frac{1}{n^4} = \frac{\pi^4}{90}$?,"In his gorgeous paper ""How to compute  $\sum \frac{1}{n^2}$ by solving triangles"" , Mikael Passare offers this idea for proving $\sum_{n=1}^\infty \frac{1}{n^2} = \frac{\pi^2}{6}$: Proof of equality of square and curved areas is based on another picture: Recapitulation of Passare's proof using formulas is as follows: $$\sum_{n=1}^\infty \frac{1}{n^2} = \sum_{n=1}^\infty \int_0^\infty \frac{e^{-nx}}{n}\; dx\; = -\int_0^\infty \log(1-e^{-x})\; dx\; = \frac{\pi^2}{6}$$ There is also another paper dealing with geometric proof of $\sum_{n=1}^\infty \frac{1}{n^2} = \frac{\pi^2}{6}$, in an entirely different way. I tried to find a similar way to prove: $$\sum_{n=1}^\infty \frac{1}{n^4} = \frac{\pi^4}{90}$$ but didn't succeed. Maybe you will?","['visualization', 'sequences-and-series', 'alternative-proof', 'proof-without-words']"
1284185,Integrate $\int_{-\infty}^\infty \frac{x}{\sinh x}~dx$,"From a Problem Set on residues: Evaluate $$\int_0^\infty \frac{\log x}{(x-1) \sqrt{x}}~dx.$$ After the substitution $x = e^u$ and easy computations, the integral becomes $$\int_{-\infty}^\infty \frac{x}{\sinh x}~dx.$$","['contour-integration', 'complex-analysis']"
1284192,Is this determinant identity known?,"Let $A$ be an $n \times n$ matrix that is 'almost upper triangular' in the following sense: entries on and above the main diagonal can be whatever they want, entries on the diagonal just below the main diagonal all equal -1 and entries on even lower diagonals equal zero. For example:
$$\begin{pmatrix} 
a_{11} & a_{12} & a_{13}  & a_{14} \\ 
-1 & a_{22} & a_{23}  & a_{24} \\
0 & -1 & a_{33}  & a_{34} \\
0 & 0  & -1  & a_{44}
\end{pmatrix}$$ I accidentally found a very nice expression for the determinant of these matrices. For $i \leq j$ in $\mathbb{N}$ let $[i, \ldots, j]$ denote the interval of successive integers starting at $i$ and ending at $j$. There are $2^{n-1}$ ways to partition the interval $[1, \ldots, n]$ into subintervals (e.g. $[1, 2, 3][4][5, \ldots, n]$ would be such a partition): for each of the $n-1$ comma's in $[1, \ldots, n]$ we can decide whether or not to replace it by a ']['. Now in order to compute the determinant of matrix $A$ of the form above, all we need to do is the following: Write down the $2^{n-1}$ partitions of $[1, \ldots, n]$ into subintervals. In each partition replace each subinterval $[i, \ldots, j]$ with the matrix-entry $a_{ij}$ and interpret the resulting string of matrix entries as a product Sum all the $2^{n-1}$ terms. (No minus signs involved!) The result is $\det A$. Weird, huh? As a free bonus we note that the determinant expression for the complete Bell polynomials can be computed in this way. Since this identity is not terribly hard to prove my question is: is this known? But also a more conceptual explanation, perhaps linking the interval partitions here to the set partitions in the definition of Bell polynomial would be welcome. UPDATE: Per request of Darij Grinberg I will give a proof and some easy applications to financial mathematics. Proof by induction on $n$: Write $A_{ij}$ for the matrix obtained by crossing out row $i$ and column $j$ from $A$. We divide the partitions of the interval $[1, \ldots, n]$ into two types: those that end in $[n]$ (short-tailed) and those that end in $[i, \ldots, n]$ for some $i < n$ (long tailed). The long tailed partitions do not contain any intervals starting with $n$ or ending in $n-1$ so if we apply our three step process described above to this set only we obtain an expression in the elements of $A_{n, n-1}$ which (after the right renumberings) can be seen to equal $\det(A_{n, n-1})$ by the induction hypothesis. When we apply our three step procedure to the short tailed partitions we obtain in an even more straightforward application of the induction hypothesis the number $a_{n,n} \cdot \det(A_{n, n})$. So what remains to be shown is that $\det(A) = \det(A_{n, n-1}) + a_{n,n}\det(A_{n,n})$ but this is just Laplace's cofactor expansion formula for the determinant, applied to the last row of $A$. Interpretation of the determinant in case $A$ is constant along diagonals: Suppose $A$ has $1$'s on the first (= main) and second (= the one just above) diagonal and $0$'s everywhere else (except for the $-1$'s on the zeroth diagonal of course) then the above states that $\det A$ equals the number of ways of tiling a path of length $n$ by tiles of length 1 and 2, which is well known to be the $n$'th Fibonacci number. By putting $1$'s on different diagonals we can similarly find determinant identities for the Tribonacci numbers or, more financially interesting, for the number of ways to pay an $n/100$-dollar bill with coins only. Staying in the realm of money: if instead of just $0$'s and $1$'s we fill the diagonals with numbers from the real interval $[0, 1]$ (just one number repeated over and over per diagonal) the above count turns into a probability. For instance if we take $n= 40$, put $0$'s in the main diagonal, $1/12$'s in the second diagonal, $1/6$ in the third diagonal etc, upto $0$'s in diagonals 13 to 40, the determinant of $A$ will give us the probability of landing exactly on Go (rather than just passing it) after one round trip in a game of Monopoly. What I would be really interested in are interpretations of these determinants in case the entries on each diagonal are not constant (but follow some other pattern enabling the interpretation).","['determinant', 'linear-algebra', 'set-partition', 'combinatorics']"
1284234,Volume form on $(n-1)$-sphere $S^{n-1}$,"Let $\omega$ the (n-1) form on $\mathbb{R}^n$
$$\omega=\sum_{j=1}^{n}(-1)^{j-1}x_{j}dx_{1}\wedge\cdots\wedge \hat{dx_{j}}\wedge\cdots dx_{n}$$
Show that the restriction of $\omega$ to $S^{n-1}$ in precisely the volume for this sphere. What I did was: $\omega$ never vanish on the sphere, because, defining $\sigma\in \Omega^{n-1}(S)$ for
$$\sigma_{p}(v_{1},...,v_{n-1})=det(p,v_{1},...,v_{n-1})$$
and $i:S^{n-1}\rightarrow \mathbb{R}^{n}$ the inclusion function, then $\omega=i^{\ast}(\sigma)$ then $\omega\not=0$ and therfore is a volume form. How proof that $\omega$ is the volume form? The first thing that comes to mind is show that $\int_{S^{n-1}}\omega=Vol(S^{n-1})$ but I have serious problems with the definition, I think that is to much. How see that $\omega$ is invariant on $\mathbb{R}^{n}$ under action of $O(n)$","['differential-geometry', 'differential-forms', 'group-actions']"
1284249,An element of $f$ of a function field such that $P$ is the only pole of $f$.,"Let $F$ be a function field in one variable over a field $k$. Let $S$ be a nonempty finite subset of all places of $F$. Prove that if $P \in S$, there is an element $f$ of $F$ such that $P$ is the only pole of $f$.","['abstract-algebra', 'algebraic-geometry']"
1284252,Backwards Heat Equation $ u_{t} = -\lambda^2 u_{xx}$,"Problem Consider the backwards heat equation of the form 
  $$ \left\{ \begin{aligned} u_{t} & = \lambda^2 u_{xx}, & x\in[0,L], \quad t\in[0,T]\\ u(0,t) &= u(L,t) = 0 \\ u(x,T) &= f(x), \end{aligned} \right.\tag{*}\label{*}$$
  Establish whether solution is unique and analyze its stability. Attempt of ( dis )proving stability My attempt to answer the stability question is provided in this post . Attempt of proving uniqueness I know that it is possible to use the energy functional method for proving uniqueness of the solution of backwards heat equation in a way we do that for a regular heat equation, with some additional tweaks. Assume there are two different solutions $u_1$ and $u_2$ of $\eqref{*}$ and define the discrepancy as $w(x,t) : = u_1(x,t) - u_2(x,t)$. By superposition principle $w(x,t)$ is also a solution of \eqref{*}.
Define the energy 
$$
E (t):=\int_0^Lw^2(x,t)\,dx \ge 0,
$$
then
$$\dot{E}(t) := \frac{dE}{dt} = 2\int_0^L w  w_t\,dx, = 2 \int_0^L w  w_{xx}\,dx = 2ww_x\big|_{0}^L - 2\int_0^L w_x^2\,dx=-2\int_0^L w_x^2\,dx,$$
$$
\ddot{E}(t) = \frac{d }{dt}\Big(\dot{E}(t) \Big) = -2\frac{d }{dt}\Bigg(\int_0^L w_x^2\,dx \Bigg) = -4\int_0^L w_x w_{xt}\,dx = 4\int_0^L w_{xx} w_{t}\,dx = 4\int_0^L w_{xx}^2 \,dx
$$
By Cauchy-Schwarz we have 
$$ \dot{E}^2 = 4\Bigg(\int_0^L w  w_{xx}\Bigg)^2\le 4\bigg(\int_0^Lw^2\,dx \bigg)\cdot \bigg(\int_0^Lw_{xx}^2\,dx\bigg)  = E\cdot \ddot{E}$$ What should be the next step in the proof? EDIT : Thanks to this answer , I was able to get the following: $$\dot{E}^2\le E \ddot{E} $$ Define $F(t) := \ln\big(E(t)\big)$, then
$$ \dot{F} = \frac{\dot{E}}{E}, \quad \ddot{F} = \frac{\ddot{E}E - \dot{E}^2}{E^2} > 0, $$
so that $F(t)$ is convex . By definition of convexity, 
$$ \forall t_1, t_2 \in [0,T], \ \forall \theta\in [0,1] \quad F\big(\theta t_1 + (1-\theta) t_2 \big) \le \theta F(t_1) + (1-\theta) F(t_2 )  \implies
\\
\ln\Big(E\big(\theta t_1 + (1-\theta) t_2 \big) \Big) \le \theta \ln\big(E(t_1)\big) + (1-\theta)\ln\big(E(t_2)\big) = 
\ln \Big(E^\theta\left( t_1 \right) E^{(1-\theta)}\left( t_2 \right)  \Big)
\\
E\big(\theta t_1 + (1-\theta) t_2 \big) \le E^\theta\left( t_1 \right) E^{(1-\theta)}\left( t_2 \right) 
 $$
Choosing $t_2 = T$ and assuming arbitrary $t_1 = t$, we get 
$$E\big(\theta t + (1-\theta) T \big) \le E^\theta\left( t \right) \underbrace{E^{(1-\theta)}\left( T \right)}_{=0}  =0 \quad \forall \theta \in [0,1]$$
Since $w(T) = u_1(x,T) - u_2(x,T) = 0$, we know that 
$E(T) =0 $.
But then 
$$
0 \le E\big(\theta t_1 + (1-\theta) t_2 \big) \le E^\theta (t)\! \cdot\!0 \implies 
\\
  \forall t\in (0,T) \quad E(t) \equiv 0 \ \implies w(x,t) \equiv 0  \iff
\\
 u_1(x,t) \equiv u_2(x,t).
$$ Q.E.D.","['analysis', 'heat-equation', 'calculus', 'ordinary-differential-equations']"
1284261,Backwards heat equation (stability analysis),"Problem Consider the backwards heat equation of the form 
  $$ \left\{ \begin{aligned} u_{t} &= \lambda^2 u_{xx}, & x\in[0,L], \quad t\in[0,T]\\ u(0,t) &= u(L,t) = 0 \\ u(x,T) &= f(x), \end{aligned} \right.\tag{*}\label{*}$$
  Establish whether solution is unique and analyze its stability. Attempt of proving uniqueness My attempt to prove uniqueness is provided in this post . Attempt of ( dis )proving stability The general solution of $\eqref{*}$ is of the form 
$$
u(x,t) = \sum_{m=1}^{\infty} A_m \sin\bigg( \frac{\pi m }{L}\,x\bigg) \exp \Bigg(\!\!-\!\bigg(\frac{\pi m }{L}\bigg)^2  \lambda^2 \big(T -t \big) \Bigg)\\
A_m =  \frac{2}{L} \int_0^L \sin \!\bigg( \frac{\pi m }{L}\,x\bigg)\, f(x)\,dx
$$
I think the solution is not stable in $L^p$ sense, so I need to come up with a good counterexample of the sequence of initial data  $f_n(x)\to f(x)$ converging in $L_p$, so that it would not be difficult to show that corresponding solutions do not converge in $L_p$. Could anyone propose such an example?","['calculus', 'analysis', 'convergence-divergence', 'ordinary-differential-equations', 'partial-differential-equations']"
1284298,Integrate $\int_{-\infty}^{\infty} \frac{dx}{1+x^{12}}$using partial fractions,"How do I integrate the improper integral $$\int_{-\infty}^{\infty} \frac{dx}{1+x^{12}}$$ using partial fraction decomposition? I am restricted to use only the principles taught in Calculus 2, which entails partial fraction decomposition. I have tried factoring the denominator but was quickly stumped at the complicated roots. I am unsure of how to proceed. I even thought of looking at it as a series but I don't think I can do that. Thank you very much for your help. I greatly appreciate it.","['calculus', 'integration']"
1284308,True/False: Is it possible that the following limits all hold true?,"For  $g:\ \Bbb{R}\to\Bbb{R}$, it is possible that $$\lim\limits_{x\to -3}\frac{g(x)-g(-3)}{x-(-3)}=5$$ with $\lim\limits_{n\to \infty}g\left(-3+\frac{1}{n}\right)=7$, and
  $\lim\limits_{n\to \infty}g\left(-3+\frac{\pi}{n^2}\right)=5$. Okay, so I know the last two limits are essentially the same thing, so the answer must be false. But how do I prove that using the definition of a limit?","['calculus', 'real-analysis', 'limits']"
1284316,"Singularities, essential singularities, poles, simple poles","Could someone possible explain the differences between each of these; Singularities, essential singularities, poles, simple poles. I understand the concept and how to use them in order to work out the residue at each point, however, done fully understand what the difference is for each of these As far as i understand a simple pole is a singularity of order $1$? then we have poles of order $n$ which aren't simple? not too sure about essential singularity","['singularity', 'complex-analysis']"
1284318,Is every fiber of a morphism between varieties of pure dimension?,"Suppose $f\colon X\to Y$ a morphism of varieties with connected fibers, is it true that all the fibers have pure dimension?",['algebraic-geometry']
1284331,Prove/Disprove $f(x)=e^{x}$ is Injective and Surjective,"Dr. Pinter's ""A Book of Abstract Algebra"" presents the exercise: Prove whether function $f:\mathbb{R} \to (0, \infty)$ denoted by $f(x)=e^x$ is or is not (a) injective and (b) surjective. Claim: $f$ is injective: suppose $f(a)=f(b)$ , then $$e^a=e^b$$ $$\ln(e^{a})=\ln(e^b)$$ $$a=b$$ Thus, the mapping is injective. Claim: $f$ is surjective $$f(x)=e^x$$ $$y=e^x$$ $$\ln(y)=\ln(e^x)$$ $$x=\ln(y)$$ And then plug $x$ into $f(x)$ . $$f(\ln(y))=e^{\ln(y)}$$ $$        =y$$ Thus, the mapping is surjective.","['proof-verification', 'functions']"
1284352,solution of $y^{\prime \prime} + y^n = 1$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I am not able to figure out the solution for the differential solution
$$y^{\prime \prime} + y^n = 1$$
I want to specifically find an answer for $$y^{\prime \prime} + y^2= 1$$and $$y^{\prime \prime} + y^3 = 1$$ If anyone can help!","['calculus-of-variations', 'calculus', 'multivariable-calculus', 'dynamical-systems']"
1284355,"Are $S^1$ and $\mathbb{R}/{\sim}$ the ""same thing""?","I am reading quotient space of topology and I am a little bit confused. I am looking at the relationship between $\mathbb{R},S^1$ and the quotient space $\mathbb{R}/{\sim}$, where the relation $\sim$ corresponds to the partition $\mathbb{R}=\mathbb{Z}\cup(\mathbb{R}-\mathbb{Z})$. Function $f:\mathbb{R}\to S^1$ give by $f(t)=(\cos(2\pi t),\sin(2\pi t))$ is continuous, onto but not one-to-one. We can also define function $g:\mathbb{R}\to \mathbb{R}/{\sim}$ where $g(t)=[t]$. The circle $S^1$ and the quotient space $\mathbb{R}/{\sim}$ is not the same mathematical object, I suppose. But intuitively speaking they should be the ""same thing"". So there should be some relationship (bijective function, I guess) between these two spaces. But I was considering the function $\pi\circ f^{-1}$ and it's not injective. Maybe I should define the equivalence relation in a different way? Like ""$x\sim y$ if $x\equiv y\pmod {2\pi}$"" Also, suppose we can find such a function, can it be a homeomorphism?","['quotient-spaces', 'general-topology']"
1284359,Why do rings appear in regular polygons with diagonals?,"When looking at regular polygons with all the diagonals filled in, I saw that concentric rings seem to form. Why does this occur? It's not so obvious with small $n$, but for larger $n$ it becomes increasingly clear. To show what I mean, I have included the images of some regular polygons (the $n$ used as examples were chosen because I like them, but the pattern shows up for the other $n$s as well).","['geometry', 'polygons']"
1284372,Intuition behind uniformly continuous functions,"I'm trying to have an intuition behind the uniformly continuous functions. Something to show to my students. For example, before giving the formal definition and some examples of continuous functions, we can say to beginners that roughly speaking, continuous functions are functions without ""holes"", that's why the name ""continuous"". What about uniformly continuous functions? is there some ideas to give to the students to give them an intuition behind these functions, before to show to them the formal definition? Thanks",['real-analysis']
1284386,A reference for multi-dimensional characteristic functions,"I'm looking for a well-written, rigorous and self-contained treatment of multidimensional characteristic functions, specifically Lévy's continuity theorem and the uniqueness theorem (which states that distinct multi-dimensional distributions engender distinct characteristic functions). In particular, all necessary results from real and complex analysis should be proved, or else specific references should be given to where proofs can be found. Preferably, it should not be assumed that the theory of one-dimensional characteristic functions is familiar; this theory should be developed as a special case of the multi-dimensional case. References can be in English, German or French. In fact, the German work ""Stochastik: Theorie und Anwendungen"" by Meintrup and Schäffler is very much what I have in mind, except their account of the continuity and uniqueness theorems is not self-contained.","['probability-theory', 'characteristic-functions', 'reference-request']"
1284388,Were did I go wrong in my basic algebra?,Solving for variable $d$: $v = \frac{1}{2}hd^2 + 9.9$ $-2(v - 9.9) = hd^2$ $-2v + 19.8 = hd^2$ $d = \sqrt{\frac{-2v + 19.8}{h}}$ The correct answer is: $d = \pm\sqrt{\frac{2v - 19.8}{h}}$,['algebra-precalculus']
1284436,Algebraic determination of asymmetric unit (aka irreducible wedge) in Brillouin zone of lattice,"In Solid State physics the reciprocal space is of utmost importance to predict the band structure and thus most of the electrical transport parameters like effective mass, etc. The First Brillouin Zone of a certain crystal lattice with its symmetries specified by its space and point groups, is defined as the volume whose points are closer to a lattice point in the reciprocal lattice than to all other reciprocal lattice points (thus the equivalent to the Wigner Seitz cell in real space). In the International Tables for Crystallography and also on the excellent Bilbao Crystallographic Server (listed in the row ""GP""), the asymmetric unit (aka irreducible wedge) is specified as the polyhedron which is the first Brillouin zone reduced by all of the symmetries in the point group of the lattice. The geometry of this zone can be calculated from the given equations by doing a vertex enumeration and can be described by the inequality relation $$\textbf{m}.\vec{r}-\vec{b}\leq0$$ with $\textbf{m}$ being the row matrix of the normal vectors of the surface planes and $\vec{b}$ being the distance of the plane to the coordinate center. A similiar set of inequality relations can be defined for the full first Brillouin zone. Now for my question: One can easily show that by applying all point group operations of the related point group of the lattice to the asymmetric unit we can get back to the first Brillouin Zone of the lattice. However is there an algebraic way how to deduce the asymmetric unit through the space group operations applied to the first Brillouin zone (thus the inverse operation applied on the inequality relation describing the first Brillouin zone)?","['group-theory', 'physics', 'mathematical-physics']"
1284480,Difference between path and vector field,"What is the difference between a path and a vector field? From what I understand the unit vectors $\mathbf i$, $\mathbf j$, and $\mathbf k$ are actually vector fields (constant vector fields to be exact).  Then if we have a path $$\mathbf r(t) = x(t)\mathbf i + y(t)\mathbf j + z(t)\mathbf k$$ it's just a linear combination of vector fields. $1)$ So doesn't that make it a vector field as well? $2)$ So then are paths just a specific type of vector field or are they different concepts?",['multivariable-calculus']
1284494,"graph product that commutes with automorphism, and semi direct","Is there a way to construct a ""product"" of graphs $G\rtimes H$ such that $Aut(G \rtimes H ) \simeq Aut(G) \rtimes Aut(H) $? A related topic is ""Semidirect product"" of graphs? but not quite the same.","['graph-theory', 'group-theory']"
1284508,Lists of negative discriminants by class group?,"Is there a handy listing of the discriminants of imaginary quadratic fields having a given ideal class group? It would be nice to use such a resource as a source of examples. For example, we're all set for class number $4$: A013658 Discriminants with class number $4$ If we want just the cyclic or the non-cyclic groups, we can intersect with these lists: A227735 Discriminants with cyclic class groups of composite order A227734 Discriminants with noncyclic class groups The latter of which results in: A192322 Discriminants whose class group is the Klein $4$-group, $C_2\times C_2$ So that's really convenient! But are there also pre-computed lists to distinguish, say, $C_2\times C_2\times C_2$ from $C_4\times C_2$? (The closest resource I've found is A225365 Discriminants with non-isomorphic class groups , which is still a great source of examples, if not exhaustive.)","['quadratic-integer-rings', 'number-theory', 'oeis', 'reference-request', 'algebraic-number-theory']"
1284512,how to evaluate the product $\prod _{n=2}^\infty (1+ \frac{1}{n^2}+\frac{1}{n^4}+\frac{1}{n^6}+\cdots )$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Evaluating the infinite  product of $\prod _{n=2}^\infty (1+ \frac{1}{n^2}+\frac{1}{n^4}+\frac{1}{n^6}+\cdots )$. Please Help.","['sequences-and-series', 'infinite-product']"
1284531,Proving the existence of $b$ such that $\prod_{k=1}^n(1-\cos(a_k-b))=\frac{1}{2^n}$,"Let $n>0$ and $a_1,\ldots,a_n\in \mathbb R$. Prove there is some $b$ such that $\prod_{k=1}^n(1-\cos(a_k-b))=\frac{1}{2^n}$ This is motivated by this question Finding a point on the unit circle that achieves this equality Numerical trials suggest it is true indeed, and that for any choice of $a_1,\ldots,a_n$, $b\to \prod_{k=1}^n(1-\cos(a_k-b))$ achieves a maximum quite greater that $\frac{1}{2^n}$. EDIT : It may be worth noting that: $$\prod_{k=1}^n(1-\cos(a_k-b))=2^n\prod_{k=1}^n\sin^2(\frac{a_k-b}{2})$$ I attempted induction on $n$, to no avail.","['optimization', 'real-analysis', 'trigonometry']"
1284540,A counter example,"I have this two spaces $$C_{\theta}=\{u\in C(\overline{\Omega}), \sup (|x|^{\theta} |u(x)|)<\infty\}$$ with the norm $\displaystyle\|u
\|_{\theta}=\sup_{\Omega}(|x|^{\theta} |u(x)|)$ and $$L_{1}^{p^*}=\{u ~~\text{measurable};~~\int_{\Omega} (|x|\cdot|u(x)|)^{p^*} dx<\infty\}$$ with the norm $\|u\|_{L^{p^*}_{1}}^{p^*}=\int_{\Omega} (|x|\cdot|u(x)|)^{p^*}dx$ Where $\Omega\subset\mathbb{R}^N$ is bounded with $0\in \Omega$ and $\theta>\frac{N}{p}>1,$ $p^*=\frac{pN}{N-p}$ and $N>p.$ I need a counter example to say that  $C_{\theta}$ is not continuously embeded in $L^{p^*}_{1}$, so i'm searching a function which is in $C_{\theta}$ but not in $L^{p^*}_1$ Or a sequence $u_n$ which converge to $u$ un $C_{\theta}$ but not in $L^{p^*}_{1}$ Please help me thank you","['analysis', 'functional-analysis']"
1284619,"In a metric space, is every convergent sequence bounded?","In $\mathbb{R}$ and $\mathbb{R}^p$, this is true, but is it true in every metric space?
I suppose not, but what other condition would I have to put on the metric space in order for it to have this property? For clarity, a bounded subset $W$ of a metric space $V,d$ is a subset of $W$ with this property:
$$\exists M\in\mathbb{R}_0^+,\forall v,w \in V:\ d(v,w) < M$$","['analysis', 'metric-spaces']"
1284641,"Let $a_{2n-1}=-1/\sqrt{n}$ for $n=1,2,\dots$ Show that $\prod (1+a_n)$ converges but that $\sum a_n$ diverges.","Let $a_{2n-1}=-1/\sqrt{n}$, $a_{2n}=1/\sqrt{n}+1/n$ for $n=1,2,\dots$ Show that $\prod (1+a_n)$ converges but that $\sum a_n$ diverges. What I have found so far is that $\prod_{k=2}^{2n} a_n$=$3(1-\frac{1}{2\sqrt{2}})\cdots (1-\frac{1}{n\sqrt{n}})$ and $\prod_{k=2}^{2n+1} a_n$=$3(1-\frac{1}{2\sqrt{2}})\cdots (1-\frac{1}{n\sqrt{n}})(1-\frac{1}{\sqrt{n+1}})$ I'm considering using the theorem that if each $a_n \ge 0$, then the product $\prod(1-a_n)$ converges if and only if, the series $\sum a_n$ converges. So since $\sum \frac{1}{n\sqrt{n}}$ converges, I think the above product converges as well, but I can't use this theorem right now because of the odd partial products. How can I resolve this problem? Also, I can clearly see that $\sum a_n$ diverges, but how can I prove this rigorously? I would greatly appreciate some help.","['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'infinite-product']"
1284644,Epimorphisms of locally compact spaces,"Let $LCH$ be the category of locally compact Hausdorff spaces with proper continuous maps. Question. What are the epimorphisms in $LCH$? I suspect them to be surjective, but I haven't been able to prove it. Here is an idea: Let $f : X \to Y$ be an epimorphism. The image $f(X)$ is closed . It follows that $f(X)^+$ is closed in $Y^+$, where $+$ denotes the Alexandrov compactification . If $y \in Y \setminus f(X)$, by Urysohn's Lemma there is some $g \in C(Y^+)$ with $g(y)=1$ and $g(f(X)^+)=0$. Now, $g(\infty)=0$ implies that $g$ restricts to some $g \in C_0(Y)$ such that $g(y)=1$ and $g(f(X))=0$. The remaining problem is that $g$ might be not proper. I have also tried to prove it in the dual category, which is the category $CommC^*Alg$ of commutative $C^*$-algebras with non-degenerate $*$-homomorphisms. I already know that surjections become injections under this duality, so that the question would be: Is every monomorphism in $CommC^*Alg$ injective? Again, the restrictive morphisms cause some problems in proving this.","['compactness', 'operator-algebras', 'general-topology', 'category-theory']"
1284655,What is the name of the technique for showing that $\mathbb{N}^2$ is countable?,"In order to show that $\mathbb{N} \times \mathbb{N}$ is countable, we can define a bijection $f : \mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N}$ like this one: $0 \rightarrow (0, 0)$ $1 \rightarrow (1, 0)$ $2 \rightarrow (0, 1)$ $3 \rightarrow (2, 0)$ $4 \rightarrow (1, 1)$ $5 \rightarrow (0, 2)$ $6 \rightarrow (3, 0)$ $7 \rightarrow (2, 1)$ $8 \rightarrow (1, 2)$ ... I need to prove that a set is countable, I know how to use this proof method, but I can't remember its name. Any hints?","['elementary-set-theory', 'terminology']"
1284660,Rolling a certain total with a dice,"Suppose you roll a $k$-sided die repeatedly, totaling your scores as you go, until you reach or surpass $n$. (For a real-world usage ... if you have a non-looping game board and only move forward, what are your odds of landing on a specific square?) What is the probability that you actually hit $n$? I'm trying to solve this myself and have gotten an ugly closed form for $k=2$, and have a pair of interrelated recursion expressions for $k=3$ . But I feel like there ought to be more elegant solutions than the ones I've achieved, so I thought I'd propose the problem to the community to see if someone else comes up with an answer whilst I work on it.","['dice', 'probability']"
1284661,Nilpotents after tensoring with a field,"Let $A \to B$ be a homomorphism of commutative rings with unit. Let $A_{\text{red}}=A/ \sqrt{(0)}$ and $B_{\text{red}}=B/ \sqrt{(0)}$ be the corresponding reduced rings. Now let $A_{\text{red}} \to K$ be a ring homomorphism to a field $K$ (of characteristic zero if you want). This gives us a (surjective) homomorphism of $K$-algebras $B \otimes_A K \to B_{\text{red}} \otimes_{A_{\text{red}}} K$. Now my question: Is every element of the kernel of this map a nilpotent? If it fails for arbitrary $A$, is it perhaps true when $A$ is a finitely generated algebra over a field of characteristic zero?","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'ring-theory']"
1284668,"Is this is the right way to do these one-to-one functions, finding their inverse, if not, how to do it?","Question 1) 
  $f(x) = 1-x$ My answer (1):   $f(x) = 1-x$, $y = 1 - x$, $y + 1 = x$, $x = y + 1$,  $f$ of inverse $f(y) = y + 1$ Question 2) :  $f(x) = \dfrac{2x}{x-1}$ My answer 2) :  $f(x) = \frac{2x}{x-1} = y$, $\frac{2x}{x-1}$,  $y+1=2x$, $\frac{y+1}{2} = x$, $x= \frac{y+1}{2}$, $f$ of inverse $f(y) = \frac{y+1}{2}$ Question 3):  $f(x) = \sqrt{5} - x$ My answer 3) : $f(x) = \sqrt{5} - x = y = \sqrt{5} - x = y + 5 = x = x = y + 5$, f of inverse $f(y) = y + 5$ Question 4):  $f(x) = x^3$ My answer 4): $f(x) = x^3$,  $y=x^3$, $y^3 = x$, $x=y^3$, f of inverse $f(y)  = y^3$",['functions']
1284673,Ramanujan's sum related to $\tan^{-1}(e^{-\pi x/2})$,"While reading Ramanujan's Collected Papers I came across a nice formula which he mentions without proof $$\tan^{-1}(e^{-\pi x/2}) = \frac{\pi}{4} - \left(\tan^{-1}\frac{x}{1} - \tan^{-1}\frac{x}{3} + \tan^{-1}\frac{x}{5} - \cdots\right)$$ where $x$ is any real number. Ramanujan proves similar formulas with terms involving $\tan^{-1}(x^{2})$ but leaves the above one as if it is obvious. I tried to simplify RHS term by term starting with $$\frac{\pi}{4} - \tan^{-1}x = \tan^{-1}\frac{1 - x}{1 + x}$$ and then
\begin{align}
RHS &= \frac{\pi}{4} - \tan^{-1}x + \tan^{-1}\frac{x}{3}\notag\\
&= \tan^{-1}\frac{1 - x}{1 + x} + \tan^{-1}\frac{x}{3}\notag\\
&= \tan^{-1}\left(\dfrac{\dfrac{1 - x}{1 + x} + \dfrac{x}{3}}{1- \dfrac{1 - x}{1 + x}\cdot\dfrac{x}{3}}\right)\notag\\
&= \tan^{-1}\left(\dfrac{3 - 2x + x^{2}}{3 + 2x + x^{2}}\right)\notag\\
\end{align}
My guess is that the argument of $\tan^{-1}$ probably looks like some convergent to a suitable continued fraction expansion of $e^{-\pi x / 2}$ but I am just not able to figure it out. An obvious difficulty is that any expansion of $e^{-\pi x / 2}$ as a continued fraction would involve $\pi$ as well as. Please suggest any other approach to prove the Ramanujan's formula. Update : If I differentiate with respect to $x$ I get the LHS as $$\frac{-\pi e^{-\pi x / 2}}{2(1 + e^{-\pi x})}$$ and the RHS comes out to be $$-\left(\frac{1}{1 + x^{2}} - \frac{3}{3^{2} + x^{2}} + \frac{5}{5^{2} + x^{2}} - \cdots\right)$$ This is similar to the partial fraction expansion of $\tanh(x)$ given by $$\frac{\tanh x}{8x} = \sum_{k = 1}^{\infty}\frac{1}{(2k - 1)^{2}\pi^{2} + 4x^{2}}$$ but not exactly as desired. For the proof of formula for $\tanh x$ see this .",['sequences-and-series']
1284692,Topology induced by seminorms and initial topology,"Let's say we have a family of seminorms $(\rho_\alpha)_{\alpha \in A}$ on
a vector space $V$. There are two ways to topologize $V$ using those seminorms: We define topology $\mathcal S$ by a subbasis consisting of sets of
the form
$$ B_{x, \alpha, \epsilon} =\{v \in V : \rho_\alpha(v - x) < \epsilon \} $$
for some $\epsilon > 0, x \in V, \alpha \in A$. We define topology $\mathcal I$ as the smallest topology in which
the seminorms are continuous. I've showed that the seminorms are continuous in $\mathcal S$, and that 
implies $\mathcal I \subseteq \mathcal S$.
I'm having trouble with the other direction.
It is clear to me that $B_{0, \alpha, \epsilon} = \rho_\alpha^{-1} 
((-\epsilon, \epsilon ))$, so it's enough to show that vector addition
is continuous in respect to $\mathcal I$, but I don't know how to do that.","['functional-analysis', 'general-topology']"
1284709,Prove every group of order less or equal to five is abelian [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Is it possible to prove that every group of order less or equal to five is abelian? We know that groups of prime order are cyclic and therefore commutative. As the number $4$ is the only composite number $\le5$, it basically remains to show this for groups of order four.","['abstract-algebra', 'group-theory', 'normal-subgroups', 'abelian-groups']"
1284723,Is it true that the intersection of a sequence $K_1 \supset K_2 \supset K_3 \dotsm$ of connected subsets of $\mathbb{R}^2$ is also connected?,"I have got one counterexample for this :
Consider the family { D } of closed discs centered at zero having radius $1+1/n$, i.e. disc $D_1$ has radius $1+1=2$, $D_2$ has radius $1+1/2=1.5$, and so on. Now consider the family { D' } of sets of the form $D_i-\{(0,y)\mid -1 \leq y \leq 1 \}$. Each of these sets is connected but their arbitrary intersection is not. Is this example is correct ? If not please provide another one.","['real-analysis', 'sequences-and-series', 'connectedness', 'general-topology', 'examples-counterexamples']"
1284737,solve a fairly simple equation,"this is a really elementary question, my appolgies but I have not studied any math since high school. What is a good method for finding x in this; p / p-d = x / x-r I got to here (which I'm not sure is correct) p * (x-r) / p-d = x problem with this is that there is still and x on the left, then i did this: p * (x-r) / = (p-d) * x then x-r / ((p-d) * x) / p
 x = (((p-d) * x) / p) + r but still the same problem, possibly I'm using the wrong method? I've completely forgotten any keywords or methods that I could search on google to do with solving this kind of equation? (I'm 29 and havent done this since highschool) thanks in advance.",['algebra-precalculus']
1284744,Find the value of : $\cos x \cos 2x...\cos 999x$ given that $x=\frac {2\pi}{1999}$,"Given $x=\frac {2\pi}{1999}$ Find the value of $$\cos x \cos 2x \cos 3x ...\cos 999x$$ So I tried expanding $\sin {2000x}=2\sin 1000x \cos 1000x$ Then rewriting 
$\cos 1000x= \cos {(999x+x)}$ No luck so far.",['trigonometry']
1284801,$ \lim_{x\to o} \frac{(1+x)^{\frac1x}-e+\frac{ex}{2}}{ex^2} $,"$$ \lim_{x\to o} \frac{(1+x)^{\frac1x}-e+\frac{ex}{2}}{ex^2} $$ (can this be duplicate? I think not) I tried it using many methods $1.$ Solve this conventionally taking $1^\infty$ form in no luck $2.$ Did this, expand $ {(1+x)^{\frac1x}}$ using binomial theorem got $\frac13$ then grouped coefficients of $x^0$ and it cancelled with $e$ then took coefficient of $x$ cancelled with $\frac{ex}{2}$ and so on very messy right ? at last I got $\frac13$ but that's not the expected answer! I must have went wrong somewhere can anyone help me with this.","['binomial-theorem', 'calculus', 'limits']"
1284820,How would this differential equation be solved?,"How would this differential equation be solved?
  $$y{\partial z\over \partial x}+z{\partial z\over \partial y}={y \over x}$$ I was taught to solve them like : $${dx \over y}={dy \over z}={dz \over {y \over x}}$$ Then find the constants $c_1$ and $c_2$ and the answer being $F(c_1,c_2)$ but I run into trouble with this one because i can't see a useful technique to get at least one $c$...",['ordinary-differential-equations']
1284830,Reference request: Cohomology of Elliptic Curves,"Is it true that the group
$$H^1(Gal(K^{ab}/K)/\mu_{\nu}(Gal(K_{\nu}^{ab}/K_{\nu})),E_{p^n})$$
is always p-divisible? Or are there any conditions which, when satisfied, guarantee its p-divisibility?
Here, $()^{ab}$ denotes the maximal Abelian extension of a field, $K_{\nu}$ is the localization of a field $K$ at a finite prime $\nu$, $\mu_{\nu}:Gal(K_{\nu}^{ab}/K_{\nu})\rightarrow Gal(K^{ab}/K)$ is induced by the injection $K\rightarrow K_{\nu}$ and $E_{p^n}$ are the $p^n$-torsion points of a (non-singular) elliptic curve $E$, defined over $K$. I am not an expert on the subject, so please have mercy on my soul.","['class-field-theory', 'algebraic-geometry', 'reference-request', 'galois-theory']"
1284843,"$K[x,y]$ (where $K$ is a field) have any bound for the number of generators of ideals?","We know that maximal ideals of $K[x_1,x_2,...,x_n]$ have $n$ generators. But is there any bound for the number of generators of arbitrary ideals? (For example in $K[x,y]$.)","['abstract-algebra', 'ideals', 'ring-theory']"
1284853,Show that $\sum_{k = 0}^{4} (1+x)^k = \sum_{k=1}^5 \binom{5}{k}x^{k-1}$,"Question: Show that: $$\sum_{k = 0}^{4} (1+x)^k = \sum_{k=1}^5 \binom{5}{k}x^{k-1}$$ then go on to prove the general case that: $$\sum_{k = 0}^{n-1} (1+x)^k = \sum_{k=1}^n \binom{n}{k}x^{k-1}$$ Attempted solution: It might be doable to first prove the general case and then say that it is true for the specific case, but for the specific case I decided to write out the term and show that they were identical since they were so few. For the LHS $$\sum_{k = 0}^{4} (1+x)^k = (1+x)^0 + (1+x)^1 + (1+x)^2 + (1+x)^3 + (1+x)^4$$ $$ = (1) + (1 + x) + (x^2 +2x + 1) + (x^3 + 3x^2 + 3x + 1) + (x^4+4 x^3+6 x^2+4 x+1)$$ $$=5 + 10x + 10x^2 + 5x^3 + x^4$$ For the RHS: $$\sum_{k=1}^5 \binom{5}{k}x^{k-1} = \binom{5}{1}x^{1-1} + \binom{5}{2}x^{2-1} + \binom{5}{3}x^{3-1} + \binom{5}{4}x^{4-1} + \binom{5}{5}x^{5-1}$$ $$= \frac{5!}{1!4!} x^0 + \frac{5!}{2!3!} x^1 + \frac{5!}{3!2!} x^2 + \frac{5!}{4!1!} x^3 + \frac{5!}{5!0!} x^4$$ $$ = 5 + 10x + 10x^2 + 5x^3 + x^4$$ That completes the first step of the question. So far so good. For the general case, I started by using the binomial theorem for the binom and then writing out the inner-most sum: $$\sum_{k = 0}^{n-1} (1+x)^k = \sum_{k = 0}^{n-1} \sum_{i = 0}^{k} \binom{k}{i}x^i = \sum_{k = 0}^{n-1} \left( \binom{k}{0}x^0 + \binom{k}{1}x^1 + ... + \binom{k}{k}x^{k}\right)$$ I can imagine that each step in the sum will decide the coefficients for the various powers of x and thus be identical to the RHS of the general case. However, I run of out steam here and do not at the moment see any obvious way forward. What are some productive approaches for the general case? Am I doing things too complicated?","['algebra-precalculus', 'combinatorics']"
1284854,A convolution involving binomials,"Given $$f(i)\gt0,\:g(i)>0,\:i =0,1,2,3,...\:$$and$$\sum_{i=0}^{\infty}f(i) = 1,\sum_{i=0}^{\infty}g(i) = 1$$Prove that, if$$\frac{g(l-k)f(k)}{\sum_{i=0}^{l}f(i)g(l-i)}=\binom{l}{k}p^k(1-p)^{l-k}\: when\:0\le k\le l,\:where\: 0\lt p\lt1$$then$$f(i) = e^{-ru}\frac{(ru)^i}{i!},\: g(i) = e^{-u}\frac{(u)^i}{i!},\:i =0,1,2,3,...\:where\:u\gt 0$$ Progress: Let $F(s)$ and $G(s)$ be the generating functions of $f(i)$ and $g(i)$ then the problem becomes $$\frac{F^{(k)}(0)G^{(l-k)}(0)}{\frac{1}{l!}\sum_{i=0}^{l}\binom{l}{i}F^{(i)}(0)G^{(l-i)}(0)} = p^{k}(1-p)^{(l-k)}$$ So I eliminated one binomial but introduced another!","['summation', 'generating-functions', 'probability', 'binomial-coefficients', 'convolution']"
1284855,"Is the set of all $(x,y,z)$ such that $z^2-x^2-y^2-1 = 0$ open or closed?","As the title says, is the set of all $(x,y,z)$ such that $z^2-x^2-y^2-1 = 0$ open or closed? Moreover, how can I prove it? I understand the definition of open and closed sets, but I don't get this exercise yet. I've been trying this for days. Thanks for all help you can give me. Regards!","['multivariable-calculus', 'real-analysis']"
1284893,How can I prove that any ball in $\mathbb{R}^n$ is connected?,"As the title follows, how can I prove that any ball in $\mathbb{R}^n$ is connected? or can you give me a hint? I have some ideas but I'm not sure about them. I thank any help you can give me! Regards","['multivariable-calculus', 'real-analysis']"
1284900,Finding minimum from matrix,"Consider following $3\times 3$ matrix. $\begin{pmatrix}3&6&9\\
    2& 4 &8\\
    1 &5& 7
    \end{pmatrix}$ I need to find combination of three numbers where each number comes from unique column & row. 
For example $3,6,8$ is not what I want as $3$ and $6$ are from same row. $6,4,7$ is also not right because $6$ and $4$ are from same columns. $3,4,7$ is valid as each number comes from different column and row. Next thing I want, is to find combination whose sum is minimum compared to sum of all other possible combinations. For example $3,4,7$ will be final answer if $3+4+7 = \min$. How do I find this for $n \times n$ matrix?","['matrices', 'summation', 'matrix-decomposition', 'matrix-equations', 'discrete-optimization']"
1284912,Is it known whether any positive integer can be written as the sum of $n$ different squares?,"Is it known whether any sufficiently large positive integer can be written as the sum of four different squares? I know that every positive integer can be written as the sum of four not necessarily different squares. Furthermore, OEIS has a sequence of numbers that can be written as the sum of any number of different squares: A003995. The largest integer not in the sequence is 128. Is there anything known about this? If so, can someone give a reference to the proof or give a sketch how to proof it? Update (Thanks, Mark Bennet!) : From Jacobi's four-square theorem it follows that there are only 24 ways to write a power of two as the sum of four squares.  However, if all those squares are different, there are at least 16*24>24 ways, since there are 16 ways to choose sign and 24 ways to choose order. Therefore a power of two cannot be written as the sum of four different squares. Is this correct? If so, I want to restate my question. Is it, for any integer $n$, known whether any sufficiently large positive integer can be written as the sum of $n$ different squares?","['sums-of-squares', 'number-theory', 'reference-request']"
1284919,The shortest way to prove that $\int_1^\infty \frac{{\arctan \left( x \right)}}{{\sqrt {{x^4} - 1} }}dx $ converges.,"I'm trying to show that the integral $$\int_1^\infty  \frac{{\arctan \left( x \right)}}{{\sqrt {{x^4} - 1} }}dx \quad \text{is convergent}.$$ We know that $$\frac{{\arctan \left( x \right)}}{{\sqrt {{x^4} - 1} }} < \frac{{\sqrt x }}{{\sqrt {{x^4} - 1} }}{\text{  for}}\,\,{\text{all}}\,\,\,x \in \left\langle {1, + \infty } \right\rangle $$
Now this is reduced to prove that $$\int_1^\infty  {\frac{{\sqrt x }}{{\sqrt {{x^4} - 1} }}}dx $$ is convergent,
but the latter integral is difficult to calculate or prove to be convergent. I know that this integral is convergent because when I calculate with Maple is
$$\int_1^\infty  {\frac{{\sqrt x }}{{\sqrt {{x^4} - 1} }}}dx  = \frac{{{\pi ^{3/2}}\csc \left( {\frac{\pi }{8}} \right)}}{{4\Gamma \left( {\frac{7}{8}} \right)\Gamma \left( {\frac{5}{8}} \right)}} \approx {\text{2}}{\text{.327185143}}$$ So my question is: Is there a simpler way of proving that $\int_1^\infty  \frac{{\arctan \left( x \right)}}{{\sqrt {{x^4} - 1} }}dx$ converges?","['calculus', 'real-analysis', 'improper-integrals', 'integration']"
1284940,"Number of generators of prime ideals in $K[x_1,x_2,...,x_n]$","Is there any bound for the number of generators of prime ideals in $K[x_1,x_2,...,x_n]$? (For example in $K[x,y]$.) We know that maximal ideals of $K[x_1,x_2,...,x_n]$ have $n$ generators.","['abstract-algebra', 'commutative-algebra', 'maximal-and-prime-ideals', 'ring-theory']"
1284941,An intriguing relation between two alternating series,This is another intriguing formula coming from Ramanujan's letter to G. H. Hardy dated 16th Jan 1913 $$\frac{\log 1}{\sqrt{1}} - \frac{\log 3}{\sqrt{3}} + \frac{\log 5}{\sqrt{5}} - \cdots = \left(\frac{\pi}{4} - \frac{\gamma}{2} + \frac{\log 2\pi}{2}\right)\left(\frac{1}{\sqrt{1}} - \frac{1}{\sqrt{3}} + \frac{1}{\sqrt{5}} - \cdots\right)$$ where $$\gamma = \lim_{n \to \infty}\left(\frac{1}{1} + \frac{1}{2} + \cdots + \frac{1}{n} - \log n\right)$$ is the Euler's constant. This seems really a different kind of series dealing with $\sqrt{n}$ in the denominator and is so unlike the usual series for $\log (1 + x)$ or $\arctan x$ or even Abel's function $\sum x^{n}/n^{2}$. Please help me out in proving the above identity. Any reference having a proof would also be of great help.,['sequences-and-series']
1284948,Why is it so hard to prove a number is transcendental?,"While reading on Wikipedia about transcendental numbers , i asked myself: Why is it so hard and difficult to prove that $e +\pi, \pi - e, \pi e, 
\frac{\pi}{e}$ etc. are transcendental numbers? Answer by @hardmath : It is generally more difficult to prove a number is transcendental than to prove it is not transcendental, i.e. that it is algebraic. Showing a number x is algebraic amounts to proving it is the root of a polynomial with rational coefficients, and so one often can just exhibit the polynomial and show by computation that a particular x is its root. Proving number x is transcendental amounts to proving no rational polynomial exists with that number as a root, and this requires more work (because we will be ""proving the negative"", i.e. exhausting all possible polynomials). We know that $\pi$ and $e$ are transcendental numbers, why we can't deduce that
$e + \pi \approx 5.859874482048838473822930854632165381954416493075065395941912...$
or $\pi - e \approx 0.423310825130748003102355911926840386439922305675146246007976...$ 
are also transcendental numbers? Answer by @Matt Samuel : For example, $\pi$ and $1−\pi$ are transcendental, but $\pi+(1−\pi)=1$ is not. Since both of you gave imho a great answer, i don't know whom of you should become the credits...","['real-numbers', 'soft-question', 'number-theory', 'transcendental-numbers', 'abstract-algebra']"
1284963,On prime factors with $n^2+n+1$,"Show that: There are infinitely many positive integers $n$  such that all prime divisors of $n^2+n+1$ are not  greater than $c\cdot n^{0.8}$, where $c$ is constant. Maybe this $0.8$ is not best constant?  can you find the smaller number?  This is (Peking University mathematics competition)",['number-theory']
1284973,Dose weak convergence imply tight?,"$X$ is a separable metric space, $\{P_n\}_{n=1}^{\infty}$, $P$ are probability measures on $X$, and $P_n$ converges weakly to $P$, can we conclude that $\{P_n\}_{n=1}^{\infty}$ is tight? I know if $X$ is also complete, then it is right by Prokhorov theorem.","['probability-theory', 'weak-convergence']"
1284977,Product of Compactly Generated and Locally Compact is Compactly Generated,"I'm trying to prove that if $X$ is compactly generated and $Y$ is T2 (Hausdorff) and locally compact then $X\times Y$ is compactly generated. First it is clear that since both $X$ and $Y$ are T2 then $X\times Y$ is also T2 and so the first condition for ""compactly generated"" is fulfilled. For the next condition, we need to show that: $$\forall B\subseteq X\times Y,\,\left[B\in Open(X\times Y)\Longleftrightarrow B\cap K\in Open(K)\forall K\in Compact(X\times Y) \right]$$ So let $B\subseteq X\times Y$ be given. The direction $\Longrightarrow$ follows immediately due to the definition of the subspace topology, so there is nothing to prove. For the $\Longleftarrow$ direction, assume $B\cap K\in Open(K)\forall K\in Compact(X\times Y)$, and the goal is to show $B\in Open(X\times Y)$. My idea was to take an arbitrary point $(x,y)\in B$ and try to find $U\times V \in Open(X)\times Open(Y)$ such that $(x,y)\in U\times V \subseteq B$. Because $Y$ is locally compact, $\exists K_y \in Compact(Y)$ such that $\exists V_y \in Open(Y)$ such that $y\in V_y \subseteq K_y$. However, now I get stuck, because I don't know which compact set $K_x$ of $X$ to find so that $x\in K_x$ and $(x,y)\in K_x \times K_y$. Because there is no obvious choice for a compact set, I'm not sure how to employ the input data.","['general-topology', 'compactness']"
1284983,Strong form of Urysohn Lemma,"Let $A$ and $B$ are two disjoint closed subsets of a connected normal space $X$. Prove there exists a continuous function $f:X\rightarrow [0,1]$ s.t. $f(A)=\{0\}, \space f(B)=\{1\}.$  Also $\forall r\in \mathbb{Q}\cap[0,1]$ , the interior of $f^{-1}(r)$ is not empty. This is an exercise in my textbook and it's about the strong form of the Urysohn lemma. The proof for the lemma in the text book uses the dyadic rationals, so I'm trying to apply it to the above case, but have made no progress. Any help will be appreciated.",['general-topology']
1284989,An expectation inequality,"Let $X$ and $Y$ be iid random variables, and $\mathbb E[|X|]<\infty$, prove that $$\mathbb E[|X+Y|]\geq\mathbb E[|X-Y|]$$ Let $F(x)$ denote the distribution, after calculation, I need to prove 
$$\int_{-\infty}^{+\infty}x[1-F(x)-F(-x)]F(dx)\geq0$$
but I stuck with it. Any help, thanks!",['probability-theory']
1285068,"Given the axiom of choice, are cardinals ordinals?","Given a model of ZFC, is it correct to talk indistinctly about cardinals and initial ordinals, namely, ordinals $\alpha$ such that for every $\beta < \alpha$, there is no bijection between $\alpha$ and $\beta$? In particular, can we write $\omega_n = \aleph_n$? This I think is correct but the literature often seems reticent to do it, and would rather address $\aleph_n$ as the cardinality of $\omega_n$.","['ordinals', 'elementary-set-theory', 'cardinals']"
1285070,$ |f''(x)+2xf'(x)+(x^2+1)f(x)|\leq1 $ for all $x$. Prove $ \lim_{x\rightarrow\infty }f(x)=0$,"Let $f(x):(0, \infty)\rightarrow \mathbb{R} $ be a twice continuously  differentiable function such that | $ f''(x)+2xf'(x)+(x^2+1)f(x) |\leq1 $ for all $x$. Prove $  \lim_{x\rightarrow\infty }f(x)=0$ I think this can be solved by applying  L'Hospital  rule twice on $\frac{e^{x^2}f(x)}{e^{x^2}}$. My problem is, Is it possible to apply the rule without knowing about numerator . Also I like to see different types of proofs",['real-analysis']
1285093,Find minimizer of the functional $l(u)= \int_{-1} ^1 u(t) \mathbb d t$,"Find minimizer of the functional 
$ l(u)= \int \limits _{-1} ^1 u(t) \mathbb d t $ with $u(-1)=u(1)=0 $ subject to $g(u)=\int \limits _{-1} ^1 \sqrt{1+u'(t)} \mathbb d t=π $. I solved it using Lagrange's equations and I found $u(t)=\sqrt{\lambda ^2 -(t+c)^2 }+c$. First I started by $l^*=l- \lambda g$
then I used the Euler-Lagrange equation ($l_u -\frac{d}{dt}l_u'=0$) or first integral ($l-u'l_u'=c$). My problem is how to find value of $c$.","['calculus-of-variations', 'ordinary-differential-equations']"
1285137,Showing that $\mathcal{O}(X_f)\cong\mathcal{O}(X)_f$ without schemes language,"I have seen this question here in the language of schemes, but I never studied this, so I hope someone can help me to solve this problem without schemes (I'm a beginner in this). The problem is to show that $\mathcal{O}(X_f)\cong\mathcal{O}(X)_f$, where we have the following. $\bullet \ X\subset\mathbb{A}^n_K$ is an irreducible variety over an algebraically closed field $K$ $\bullet \ \mathcal{O}(X)$ is the coordinate ring of $X$ $\bullet \ f\in\mathcal{O}(X)$ $\bullet \ X_f=\{p\in X: f(p)\neq0\}$ $\bullet \ \mathcal{O}(X_f)$ is the set of rational functions $g/h:X_f\rightarrow K$, with $g,h\in K[x_1,\ldots,x_n]$ and $h\neq0$ in $X_f$ $\bullet \ \mathcal{O}(X)_f = \{g/f^m\in Q(\mathcal{O}(X)): m\in\mathbb{N}\}$ is the localization of $\mathcal{O}(X)$ in $f$ and $Q(\mathcal{O}(X))$ is the field of fractions of $\mathcal{O}(X)$ I started trying to show that the restriction of functions $g/f^m$ to $X_f$ would give me a map $\mathcal{O}(X)_f\rightarrow\mathcal{O}(X_f)$, which would be the isomorphism. In fact, this the only idea which looks natural to me, I can't think in anything else. But I'm having some problems to show it is injective and mostly to show it is surjective. Thanks.","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
1285148,Solve the equation $\log_{2} x \log_{3} x = \log_{4} x$,"Question: Solve the equations a)
$$\log_{2} x + \log_{3} x = \log_{4} x$$ b)
$$\log_{2} x \log_{3} x = \log_{4} x$$ Attempted solution: The general idea I have been working on is to make them into the same base, combine them and take the inverse to get the solution for x. a)
$$\log_{2} x + \log_{3} x = \log_{4} x \Leftrightarrow$$
$$\log_{2} x + \frac{\log_{2} x}{\log_{2} 3} = \frac{\log_{2} x}{\log_{2} 4} \Leftrightarrow$$ $$\log_{2} x + \frac{\log_{2} x}{\log_{2} 3} = \frac{\log_{2} x}{2} \Leftrightarrow$$ $$\frac{2 \log_{2} 3 \log_{2}x + 2\log_{2} x - \log_{2}3 \log_{2}x}{2 \log_{2}3} = 0 \Leftrightarrow $$ Moving the denominator over and solving for $\log_{2} x$ $$\frac{\log_{2} x (2\log_{2}3 + 1 - \log_{2}3)}{2\log_{2} 3} = 0 \Leftrightarrow$$ $$\log_{2} x = 0 \Rightarrow x = 2^{0} = 1$$ b) $$\log_{2} x \log_{3} x = \log_{4} x$$ $$\log_{2} x \frac{\log_{2} x}{\log_{2} 3} - \frac{\log_{2} x}{\log_{2} 4} = 0 \Leftrightarrow$$ $$\frac{4 (\log_{2}x)^2 - \log_{2}3 \log_{2}x}{4 \log_{2}3} = 0 \Leftrightarrow $$ $$4 (\log_{2}x)^2 - \log_{2}3 \log_{2}x = 0 \Leftrightarrow $$ Substituting $t = \log_{2} x$ gives: $$4t^2 - \log_{2}3t = 0 \Rightarrow$$ $$t^2 - \frac{\log_{2}3t}{4} = 0 \Rightarrow$$ $$t \left(t- \frac{\log_{2}3}{4}\right) = 0$$ $$t_{1} = 0 \Rightarrow x = 1$$
$$t_{2} = \frac{\log_{2}3}{4} \Rightarrow x = 2^{\frac{\log_{2}3}{4}}$$ However, the second solution here should be $\sqrt{3}$, so I must have made a mistake somewhere. Any suggestions?","['algebra-precalculus', 'logarithms']"
1285176,Skew-symmetric matrix subspace dimension and basis,"If $M$ is the vector space of $2\times 2$ real matrices, then I can show that $$ \{A \in M \mid A^\mathrm{T}=-A \} $$ is a subspace of $M$, since $$ \left[ \begin{array}{cc} x & z \\ -z & y \end{array} \right]+\left[ \begin{array}{cc} x' & z' \\ -z' & y' \end{array} \right] = \left[ \begin{array}{cc} x+x' & z+z' \\ -(z+z') & y+y' \end{array} \right] $$ and for some $\lambda\in\mathbb{R}$ $$ \lambda\left[ \begin{array}{cc} x & z \\ -z & y \end{array} \right] = \left[ \begin{array}{cc} \lambda x & \lambda z \\ -\lambda z & \lambda y \end{array} \right] $$ But I'm not sure if I'm correct on finding the dimension and a basis of the subspace: $$ \left[ \begin{array}{cc} x & z \\ -z & y \end{array} \right] = x\left[ \begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array} \right]+y\left[ \begin{array}{cc} 0 & 0 \\ 0 & 1 \end{array} \right]+z\left[ \begin{array}{cc} 0 & 1 \\ -1 & 0 \end{array} \right] $$ This makes me think that a basis is made up of $$ \left(\left[ \begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array} \right],\left[ \begin{array}{cc} 0 & 0 \\ 0 & 1 \end{array} \right],\left[ \begin{array}{cc} 0 & 1 \\ -1 & 0 \end{array} \right]  \right) $$ and so the dimension is three. Is that right?","['linear-algebra', 'matrices']"
1285178,Proof on Intersection of Sets,"I could not understand this property:
NOTE: P(A) is the Power Set. $$P(A\cap B) = P(A)\cap P(B)$$ $$PROOF (\text{ Just the first part})$$ Consider an element say $a\in P(A\cap B)$ . Then, $$a\in P(A\cap B)$$ $$\Longrightarrow a\subseteq A\cap B$$ $$a\subseteq A \text{ and }a\subseteq B$$ $$a\in P(A) \text{ and }a\in P(B)$$ $$a\in P(A)\cap P(B)$$ $$\Longrightarrow P(A\cap B)\subseteq P(A)\cap P(B)$$ Could somebody explain the last step: how we get $P(A\cap B)\subseteq P(A)\cap P(B)$ ? How does the sequence of steps mean that $P(A\cap B)\subseteq P(A)\cap P(B)$ ? How do we get $P(A\cap B)$ as a subset?",['elementary-set-theory']
1285202,Trigonometric root of a polynomial,"If $4\cos^2 \left(\dfrac{k\pi}{j}\right)$ is the greatest root of the equation $$x^3-7x^2+14x-7=0$$ where $\gcd(k,j)=1$ Evaluate $k+j$ I tried factorizing the equation but it wasn't of much help. 
Btw, the answer given in my book is $k=1$ and $j=14$ Any help will be appreciated. Thanks!","['roots', 'algebra-precalculus', 'functions', 'polynomials', 'trigonometry']"
1285222,Prove the Jacobian identity,"How to prove that these Jacobians are equal? $$\dfrac{\partial (x,y)}{\partial(\alpha, \beta)} \cdot \dfrac{\partial(\alpha, \beta)}{\partial(z,w)} = \dfrac{\partial (x,y)}{\partial(z,w)}$$ I don't find it staightforward to cancel $\partial(\alpha, \beta)$ out, as it is operator but not a fraction. But I have tried to express them following the definition, without success though. Thanks.","['partial-derivative', 'multivariable-calculus']"
1285237,Poles of a sum of functions,"The other question is here . Let $F$ be a function field in one variable over a field $k$. Let $S$ a nonempty finite subset of the set of all places of $F$. Prove that if $P \in S$, there is an element $f$ of $F$ such that $P$ is the only pole of $f$. For $P \in S$, let $f_P$ be an element of $F$ such that $P$ is the only pole of $f_P$. Let $$f:= \sum_{P \in S} f_P.$$How do I prove that $S$ coincides with the set of all poles of $f$?","['abstract-algebra', 'algebraic-geometry', 'number-theory', 'algebraic-number-theory']"
1285304,Number of different colourings of nodes,"Consider a tree where each node has 2 subnodes, with a total of 7 nodes. So the maximum level of the tree is 2. Each node can be coloured white or black. Two colourings are equivalent if the one is about to enter in another by changing the left and right subtrees. What is the corresponding permutation group? And what is the total number of different colourings? Now I want to solve this with the theory of Polya. But I don't even know which permutation group belongs to this problem. Any help is appreciated.","['discrete-mathematics', 'polya-counting-theory', 'combinatorics', 'permutations']"
1285317,"If $f'(c) \neq \frac{f(b)-f(a)}{b-a}$, then find number of such $c$.","Let $f(x)=x^3+3x+2$ and $x=c$ is a point such that $$f'(c) \neq \frac{f(b)-f(a)}{b-a}$$ for any two values of $a$ and $b$ , where $a,b$ and $c \in \mathbb R$ . Then find the number of such points $c$ for which this is true. By analyzing the graph of $f(x)$ , I think that such points exist on $f(x)$ (and possibly all doubly differentiable curves) only when $f''(x)=0$ at those points. But I can't seem to prove it. Using that, I got $c=0$ and thus the number of such points is $1$ . Is my claim true ? If so, then how can one prove it ?","['calculus', 'algebra-precalculus', 'functions', 'graphing-functions', 'derivatives']"
1285318,Limit in multivariable-calculus,"Let $\ell$ be a straight line through origo. Determine the limit to the restriction of $$f(x,y)=xye^{-x^2y^2}$$ to $\ell$ when $x^2+y^2 \to \infty$. Also, investigate the limit $$\lim_{x^2+y^2 \to \infty} f(x,y). $$
How should I think about the restriction? As I understand it, we have a line $\ell(t) = kt, k \in \mathbb R$ and I want $f$ to follow this path which would give us $$f(t,kt) = \frac{tkt}{e^{t^2(kt)^2}} $$
and if either $t$ or $kt$ is fixed to its minimum value ($0$) we get, by letting the other variable approach $\infty$, 
$$\lim_{t^2 \to \infty} f(t,0) = \frac{t \cdot 0}{e^{t^2(0)^2}} =0 $$
and
$$\lim_{(kt)^2 \to \infty} f(0,kt) = \frac{0 \cdot kt}{e^{0^2(kt)^2}} = 0$$ 
and so the limit should be equal to 0. Is this correct? And how do I ""realize"" that the second limit doesn't exist?","['calculus', 'limits', 'multivariable-calculus']"
1285350,Calculating integral using Cauchy integral formula in two variables,"I want to compute the integral: $\iint_{\partial_0P}\frac{1}{1-4zw}dzdw$ (or any similar integral) using Cauchy integral formula for two complex variables over polydiscs. The distinguished boundary is given by: $\partial_0P={\{(z,w):|z|=1, |w|=1}\}$. Nowhere online have I found an example of how to calculate such an integral. Would be really grateful if someone could show me how to do it, or give a link to a text with examples.","['several-complex-variables', 'complex-analysis']"
1285370,Why if the columns of a matrix are not linearly independent the matrix is not invertible?,"Why if the columns of a matrix are not linearly independent the matrix is not invertible? I have watched this video about eigenvalues and eigenvectors by Sal from Khan Academy, where he says that for $\lambda$ to be an eigenvalue for the matrix $A$, the following must be true $$A \cdot \vec{v} = \lambda \cdot \vec{v} \\
\vec{0} = \lambda \cdot \vec{v} - A \cdot \vec{v} \\
\vec{0} = (\lambda - A )\cdot \vec{v} \\
\vec{0} = (\lambda \cdot I - A )\cdot \vec{v}$$ and the determinant of $(\lambda \cdot I - A )$ must be $0$, or in other words $(\lambda \cdot I - A )$ is not invertible, or in other words the columns of $(\lambda \cdot I - A )$ are linearly dependent, or the nullspace of $(\lambda \cdot I - A )$ is non trivial. Could someone explain me better these statements? What's the relation between a statement and the other? I understood some stuff, but some other clarifications might help too.","['determinant', 'eigenvalues-eigenvectors', 'matrices']"
1285382,Understanding Adding and Subtracting on both sides of Equation,"In algebra, I take the number on one side of the equal side and put it on the the other side as the opposite, as in $2+x=10$ becoming $x=10-2$. But when I have a negative on one side do I turn it to a positive on the other?",['algebra-precalculus']
1285406,Roots of a polynomial whose coefficients are ratios of binomial coefficients,"Prove that $\left\{\cot^2\left(\dfrac{k\pi}{2n+1}\right)\right\}_{k=1}^{n}$ are the roots of the equation $$x^n-\dfrac{\dbinom{2n+1}{3}}{\dbinom{2n+1}{1}}x^{n-1} + \dfrac{\dbinom{2n+1}{5}}{\dbinom{2n+1}{1}}x^{n-2} - \ldots \ldots \ldots +  \dfrac{(-1)^{n}}{\dbinom{2n+1}{1}} =0 $$ Hence prove that $$\sum_{r=1}^{\infty} \dfrac{1}{r^2}=\dfrac{\pi^{2}}{6}$$ I was stumped on the first sight. Then I tried using complex numbers but it was in vein. I further tried simplifying the equation, but since it contains only half of the binomial coefficients, I wasn't able to get a simpler equation. Any help will be appreciated. Thanks.","['calculus', 'algebra-precalculus', 'functions', 'trigonometry', 'binomial-coefficients']"
1285409,How to find cotangent?,"Need to find a $3\cot(x+y)$ if $\tan(x)$ and $\tan(y)$ are the solutions of $x^2-3\sqrt{5}\,x +2 = 0$. I tried to solve this and got $3\sqrt{5}\cdot1/2$, but the answer is $-\sqrt{5}/5$","['quadratics', 'trigonometry']"
1285411,Roots of a Cubic Polynomial with Elementary Symmetric Polynomial Coefficients,"Let $R_n$ be a set of $n$ distinct nonzero rational numbers. Let $e_k$ be elementary symmetric polynomials over $R_n$---i.e. $e_0=1$, $e_1 = \sum_{1\le i\le n} r_i$, $e_2 = \sum_{1\le i<j\le n} r_i r_j$, etc. For all $n>3$, does there exits an $R_n$ such that $e_3 x^3 + e_2 x^2 + e_1 x + 1$ has distinct rational roots? ($e_3\ne0$) For quadratic polynomial, it is easy to characterize $R_n$ using simple algebra. I don't know how to approach the cubic or higher order polynomials.","['rational-numbers', 'symmetric-polynomials', 'roots', 'number-theory']"
