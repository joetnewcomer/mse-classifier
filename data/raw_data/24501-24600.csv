question_id,title,body,tags
217283,Question about the N/C theorem,"Let $H \leq G$. Define a map $f: N(H) \rightarrow Aut(H)$ given by $f(g) = \phi_g$, where $\phi_g$ is the inner automorphism of H induced by $g$: $\phi_g(h) = ghg^{-1} \forall h \in H$. That this map $f$ is a homomorphism is clear, but I have trouble trying to see why $Kerf = C(H)$. Can someone explain this to me? $N(H)$ is the normalizer of $H$ in $G$ and $C(H)$ the centralizer.","['group-theory', 'abstract-algebra']"
217285,Applications of Abstract Algebra to elementary mathematics,"I'm currently an undergraduate student in mathematics. I am currently taking Algebra. The course is interesting, but I have grown very curious about the usefulness of algebra. I am NOT asking about ""applications of algebra to real-life"". I am asking about how algebra can be used to solve math problems. Unfortunately, Googling ""applications of algebra"" is not all that helpful. Right now I can only recall seeing two instances of ""useful"" applications of algebra -- a proof of Fermat's Little Theorem, and determining whether a polynomial is solvable in radicals by looking at its Galois group. What interests me about both problems is that they are of interest to someone who has not necessarily encountered abstract algebra yet (e.g. what is the remainder when you divide k^p by p? can you write explicitly the roots of some polynomial using only the integers and the specified functions?). At least from the way my course is currently progressing, it feels as though such applications are few and far in between. We are currently making observations about permutations (e.g. if p and q are permutations, then pq and qp have ""similar forms""), which is interesting, but I fail to see how algebra has helped make any interesting deduction -- all interesting results so far about permutations (e.g. the one mentioned above) were all done without any algebraic result. Only when we ask a question using algebraic terminology was algebra required (e.g. show An is a normal subgroup of Sn). If algebra were only used to answer questions about algebra, there would be no real need to study algebra, right? What are some other ""elementary"" applications of algebra? What are some other interesting results I would be able to understand after an introductory course? I have a suspicion that finding answers to these questions would better my understanding of algebra, but I have had difficulty in finding many good answers.","['big-list', 'abstract-algebra']"
217319,Why is the Borel Algebra on R not equal the powerset?,"The borel algebra on the topological space R is defined as the σ-algebra generated by the open sets (or, equivalently, by the closed sets). Logically, I thought that since this includes all the open sets (a,b) where a and b are real numbers, then, this would be equivalent to the power set. For example, the set (0.001, 0.0231) would be included as well as (-12, 19029) correct? I can't think of any set that would not be included. However, I have read that the Borel σ-algebra is not, in general, the whole power set. Can anyone give a gentle explanation as to why this is the case?","['general-topology', 'measure-theory', 'real-analysis']"
217330,Why is the laplacian positive-definite,"Let (M,g) be compact Riemannian manifold (possibly $\partial M\neq\emptyset)$ Now I have read, that ""the laplace-beltrami operator is a positive definite operator"". I have shown, if M is a closed manifold or if we consider dirichlet boundary conditions, $\Delta:=-\nabla^2$ is positive definite, i.e. $(\Delta f,f)_{L^2}\geq 0$. Which setting does the author mean by: ""the laplace-beltrami operator is a positive definite operator""??
Is $\Delta$ always positive definite independent of the boundary conditions? Thank you!","['manifolds', 'functional-analysis']"
217332,Proving vector calculus identity $\nabla \times (\mathbf a\times \mathbf b) =\cdots$ using Levi-Civita symbol,"I want to prove the following relation $$\nabla \times (\mathbf a\times \mathbf b) = \mathbf a\nabla \cdot \mathbf  b + \mathbf  b \cdot \nabla \mathbf  a - \mathbf  b \nabla \cdot \mathbf  a - \mathbf a \cdot \nabla \mathbf  b$$ using the following Levi-Civita definition of cross product
$$\mathbf{a} \times \mathbf{b} =\mathbf{e}_i \epsilon_{ijk}a_ib_j$$
where $\epsilon_{ijk} =\begin{cases}
+1 & \text{if } i,j,k \text{ are in clockwise permutation}, \\
-1 & \text{if } i,j,k \text{ are in counterclockwise permutation, and} \\
\;\;\,0 & \text{if }i=j \text{ or } j=k \text{ or } k=i.
\end{cases}$","['multivariable-calculus', 'vector-analysis', 'index-notation']"
217336,Space Completion Theorem for Normed Spaces,"I went to a functional analysis course this year and my lecturer wrote down this Theorem. Lots of students pointed out it is incorrect, but she insisted it was. I am stating it now and hope someone can give me a good explanation about the confusion. Here is the statement of the Theorem: For any normed vector space $(V,\|\cdot\|_V)$, there exists another normed space $(Z,\|\cdot\|_Z)$ such that a map $i:V\rightarrow Z$ such that (1) $i$ is an isometrical isomorphism (2) $i(V)$ is dense in $Z$ where $Z$ is unique up to isomorphism. In this Theorem, nothing said about $Z$ being complete. The students asked if $V$ is $\mathbb{Q}$, what $Z$ should be? $\mathbb{Q}$ fits the definition for $Z$, because $\mathbb{Q}$ is dense in $\mathbb{Q}$, but the lecturer said $\mathbb{Q}$ is not dense. She said something on the line dense means something different in a normed space. Can someone explain to me what this is about? In the Theorem, do we have to have say $Z$ is complete?","['normed-spaces', 'functional-analysis']"
217341,An equivalent condition for a measure to be invariant,"Why is it true that for a compact metric space $X$ and a continuous function $T:X\rightarrow X$, a measure $\mu$ on $X$ is $T$- invariant iff $\int_X f\circ T \, d\mu=\int_X f \, d\mu$ for every continuous function $f$?
Is it still true without demanding that $X$ is compact or metric?","['measure-theory', 'ergodic-theory']"
217350,How can function fields have different degrees over the projective line,"I'm confused. Let $X$ be a curve over a field $k$. Let $K= K(X)$ be its function field. Then, $K(X)$ is a field. Each non-constant morphism  $f:X\to \mathbf{P}^1_k$ gives a field extension $K(\mathbf{P}^1_k) = k(t) \subset K(X)$ of degree $\deg f$. How is it possible that $\deg f$ can take infinitely many values? Aren't both fields fixed? Maybe I'm not understanding the situation fully. A rational function $f$ on $X$ gives a field extension $k(t) \subset k(t,f)$ of degree $\deg f$. Maybe $k(t,f) \not= K(X)$? No... Can somebody explain?","['arithmetic-geometry', 'riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
217454,Compact subsets in $l_\infty$ (converse of my last question),"(Converse of my last question) If $A \subseteq \ell_\infty$, and $A=\{l\in \ell_\infty: |l_n| \le b_n \}$, where $b_n$ is a sequence of real, non-negative numbers, then if $\lim (b_n) = 0$  it must mean that $A$ is compact subset of $X$. Take any sequence of sequences $(x_n)$, our goal is to construct a subsequence, $(x_{n_k})$ which will converge. Suppose for $n \geq N$ we have $|b_n|<\epsilon$ (by convergence of $(b_n)$). For the first $N-1$ points, however, I thought we could use Bolzanno-Weirstrass on each of the $N-1$ first terms (since $|x_n| \le b_n \forall n$) in the following way: apply Bolzano Weirstrass on all the first terms, then for the second terms apply it on the subsequence we got from the first terms, and so on... and claiming this subsequence will converge to $\{x_1,x_2,...,x_{N},...\}$ - edited, where $x_i$ is the limit of the $i_{th}$ subsequence. However, the subsequence created could have a few cases where we end up with no terms at the end of this inductive argument. My teacher told me to use Cantor Diagonalization to avoid this, but I don't see how this would work.","['sequences-and-series', 'compactness', 'real-analysis', 'metric-spaces']"
217474,the elliptic curves with j-invariant zero,"Let $B\in K^\ast$, where $K$ is a number field. Let $y^2=X^3+B$ be the Weierstrass equation for an elliptic curve $E_B$ over $K$. Note that the $j$-invariant of $E$ is zero. When is $E_B$ isomorphic to $E_{B^\prime}$ over $K$? (Here $B^\prime \in K^\ast$.) Does this happen if and only if $B=B^\prime$? Or does it also happen if $B^\prime = u B$, where $u$ is a unit in $O_K^\ast$? How do I determine the semi-stable reduction of $E_B$? That is, we know that $E_B$ has potential good reduction. How do I determine $L/K$ such that the elliptic curve $E_{B}\otimes_K L$ has good reduction over $O_L$? If $B$ is a unit, then $E_B$ has good reduction. So we may and do assume $B$ is not a unit, i.e., $B$ is a prime. I have a feeling that we must choose $L$ such that its ramification over the primes dividing $B$ is of the ""right"" type. But how do I see what the necessary type is?","['arithmetic-geometry', 'algebraic-geometry', 'elliptic-curves', 'algebraic-curves']"
217484,Prove that a formal language is infinite,"I'm having trouble with the following exercise: Let $\Sigma = \{a,b,c\}$ and $L$ be a formal language, that consists of all words which contain all three letters at least once. Show that $L$ is infinite. I figured out that I could define a word $w_0 = abc, w_0\in L$ so the condition is met, and then say $w_i = w_0\cup_{i = 1}^{\infty}a, w_i \in L$ ..which shows that you could add infinitely many letters(a's in this case) to it and therefore you can get infinitely many words. Now I don't know how to show that the rule above does indeed produce infinitely many words, isn't it just obivous? I'm also not sure about the notation - should I just add ""This shows that L is infinite"" ? And finally I don't know if I'm allowed to use a specific pre-condition like ""abc""","['notation', 'formal-languages', 'infinity', 'elementary-set-theory']"
217486,prove that a function is an inner product,"I would appreciate some assistance in answering the following problems.  We are moving so quickly through our advanced linear algebra material, I can't wrap my head around the key concepts.  Thank you. Let $V$ be the space of all continuously differentiable real valued functions on $[a, b]$. (i)  Define 
     $$\langle f,g\rangle = \int_a^bf(t)g(t) \, dt + \int_a^bf'(t)g'(t) \, dt.$$
      Prove that $\langle , \rangle$  is an inner product on $V$. (ii)  Define that  $||f|| = \int_a^b|f(t)| \, dt + \int_a^b|f'(t)| \, dt$.  Prove that this defines a norm on V.","['normed-spaces', 'linear-algebra', 'inner-products']"
217513,Is there a Möbius torus?,"Does the concept of a Möbius torus make sense: taking a cylinder (instead of a rectangle as in the case of the Möbius strip ) and twisting it before joining its ends? Or will the resulting twisted torus be indistinguishable from the normal torus in any relevant respect? [This equivalent to the well-known Möbius strip should be called Möbius cylinder but it would have so much in common with a torus that I preferred to call it a Möbius torus .] Embedded in Euclidean space the twisted and untwisted torus ""look"" the same - opposed to Möbius strip and cylinder -, the difference would be only in their intrinsic properties. But can there be such differences? And how do I specify them? PS: I posted a follow-up question here .","['geometry', 'mobius-band', 'manifolds', 'klein-bottle']"
217514,Supremum of an union of bounded sets,"Given $A$, $B$ are bounded subsets of $\Bbb R$. 
Prove $A\cup B$ is bounded. $\sup(A \cup B) =\sup\{\sup A, \sup B\}$. Can anyone help with this proof?","['real-analysis', 'analysis']"
217516,Let $X$ be an infinite dimensional Banach space. Prove that every Hamel basis of $X$ is uncountable.,Let $X$ be an infinite dimensional Banach space. Prove that every Hamel basis of $X$ is uncountable. Can anyone help how can I solve the above problem?,"['banach-spaces', 'normed-spaces', 'hamel-basis', 'baire-category', 'functional-analysis']"
217518,What's wrong with the proof,"Result: $(A\times C)-(B\times C)\subseteq (A-B)\times C$ Proof: Let $(x,y)\in (A\times C)-(B\times C)$. Then $(x,y)\in A\times C,\implies x\in A,y\in C$. Since $(x,y)\notin B\times C, x\notin B$. Thus $x\in A-B$ and hence $(x,y)\in (A-B)\times C$","['proof-writing', 'elementary-set-theory']"
217521,What are the eigenvalues of matrix that have all elements equal 1? [duplicate],"This question already has answers here : Determinant of a rank $1$ update of a scalar matrix, or characteristic polynomial of a rank $1$ matrix (2 answers) Closed 9 years ago . As in subject: given a matrix $A$ of size $n$ with all elements equal exactly 1. What are the eigenvalues of that matrix ?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
217522,How do you find the vertex of a (Bézier) quadratic curve?,"Before I elaborate, I do not mean a quadratic function! I mean a quadratic curve as seen here .
With these curves, you are given 3 points: the starting point, the control point, and the ending point. I need to know how to find the vertex of the curve. Also, I am talking about Bézier curves, but just quadratic Bézier curves-the ones with only 3 points.","['geometry', 'quadratics']"
217537,Proof that a piecewise function is invertible.,"Prove that the following function is invertible: $$g:\mathbb{Z}\rightarrow\mathbb{N}$$ $$
  g(x) = \left\{
    \begin{array}{lr}
      -2x & : x\le0\\
      2x-1 & : x>0
    \end{array}
  \right.
$$ I'm having an issue proving that it is one-to-one in all cases. The cases where $x_{1},x_{2}\le0$ and $x_{1},x_{2}>0$ both pass proof by contrapostitive where $g(x_{1})=g(x_{2})$. I'm having a problem proving it is also one-to one if $x_{1}\le0$ but $x_{2}>0$ which would result in: $$
-2x_{1}=2x_{2}-1
$$
$$
x_{1}=-x_{2}+\frac{1}{2}
$$ I know I'm going something wrong in my thinking and I have a sneaking suspicion it has something to do with the fact that I'm mapping to $\mathbb{N}$, but I'm completely unsure of where to go from here.","['relations', 'discrete-mathematics', 'functions']"
217541,Finding the coefficient for binomial expansion,Hello I was trying to find the coefficient for the member $x^5$ for the expansion: $(1-2x)^{-2}$,['discrete-mathematics']
217543,Countable subsets of an uncountable set,"I believe it's true that if I have an uncountably infinite set $X$ and a countable subset $A$, then it's complement, $A^c$ is uncountable. Is it also true that if I have an uncountable subset of $X$, called $B$, the complement of this set, $B^c$, is countable?",['elementary-set-theory']
217579,Proving that $\limsup a_n$ and $\liminf a_n$ are subsequential limits of $\{a_n\}$,"Prove that if $\{a_n\}$ is a sequence, then $\limsup a_n$ and $\liminf a_n$ are subsequential limits of $\{a_n\}$. I don't know the case where $\limsup a_n = \infty$.","['limsup-and-liminf', 'limits', 'sequences-and-series', 'analysis']"
217596,The dual of the direct sum,"Let $X$, $Y$, $Z$ normed spaces If X$\cong Y\oplus Z$ why is $X^*\cong Y^*\oplus Z^*$? where $X^*$ is the dual of $X$. For example ${\ell^\infty}^*\cong\ell^1\oplus\mathrm{Null}\;C_0$ so if we take the double dual we find the ${\ell^\infty}^{**}\cong{\ell^1}^*\oplus (\mathrm{Null}\; C_0)^*$. I am not sure I understand why these equalities should hold?",['functional-analysis']
217597,Number of ways to write n as a sum of k nonnegative integers,"How many ways can I write a positive integer $n$ as a sum of $k$ nonnegative integers up to commutativity? For example, I can write $4$ as $0+0+4$, $0+1+3$, $0+2+2$, and $1+1+2$. I know how to find the number of noncommutative ways to form the sum: Imagine a line of $n+k-1$ positions, where each position can contain either a cat or a divider. If you have $n$ (nameless) cats and $k-1$ dividers, you can split the cats in to $k$ groups by choosing positions for the dividers: $\binom{n+k-1}{k-1}$. The size of each group of cats corresponds to one of the nonnegative integers in the sum.","['integer-partitions', 'combinatorics']"
217601,$aHa^{-1} \subset H$ without $aHa^{-1} = H$,"I'm seeking a normal subgroup $H$ of a group $G$ such that for some element $a \in G$, we have that $aHa^{-1} \subset H$ yet not $aHa^{-1} = H$. Yet it seems to me this is impossible since $|aHa^{-1}| = |H|$ since if $f: H \rightarrow aHa^{-1}$ s.t. $f(h_i) = ah_ia^{-1}$, then $f$ is surjective (any $ah_ia^{-1} \in aHa^{-1}$ gets mapped to by $f(h_i)$) and $f$ is injective (if $h_i \ne h_j$ then $ah_ia^{-1} \ne ah_ja^{-1}$ since to assume otherwise would imply $a^{-1}(ah_ia^{-1})a = a^{-1}(ah_ja^{-1})a$ so that $h_i = h_j$ absurdly). How -- given that such a bijection $f$ exists between $H$ and $aHa^{-1}$  -- could it be that there exists a normal subgroup $H$ of $G$ s.t. $aHa^{-1}$ is a proper subset of $H$? EDIT: In fact, for any normal $H$ and for any $a \in G$, we have that $aHa^{-1} = Haa^{-1} = H$ so that it seems fundamentally impossible for this reason alone that $aHa^{-1} \subset H$.  Here it doesn't seem to matter if $H$ is finite or infinite, doesn't it?",['group-theory']
217606,What does an outer automorphism look like?,"I am working on a project in my group theory class to find an outer automorphism of $S_6$, which has already been addressed at length on this site and others. I have a prescription for how to go about finding this guy, but I have a larger conceptual question - what does an outer automorphism really look like? Is there an intuitive way to understand the difference between an inner and an outer automorphism? Inner automorphisms have always seemed easier for me to understand since we have an explicit representation $ghg^{-1}$ for members of the group. I can also understand this representation in terms of the Rubik's cube - rotate an edge, rotate a perpendicular edge, and the rotate the other edge back (is not the same as just rotating the perpendicular edge). What does an ""outer automorphism"" look like?","['abstract-algebra', 'group-theory', 'group-actions', 'symmetric-groups', 'intuition']"
217626,Minimizing maximum absolute column sum norm of the residual between a matrix and its $k$-rank approximation,Let $X \in \mathbb{R}^{m\times n}$ be a matrix with rank $r$. How can we find the optimal $\tilde{X} \in \mathbb{R}^{m\times n}$ whose rank is $k$ where $k\leq r$ and the reconstruction error in terms of maximum absolute column sum norm is minimized? That is $$e=\|X-\tilde{X}\|_1 = \max_j \sum_i|X_{ij}-\tilde{X}_{ij}|$$ is minimized. I know that the optimal solution is the $k$-reduced SVD when Frobenius-norm or spectral norm is minimized. But I'm not familiar with optimization related to $l_1$-norm and I want to use it to find sparse bases to use in an audio processing project. Is there an analytic closed form solution for this problem? Or can I find the $k$-rank approximation in an iterative numerical method?,"['optimization', 'normed-spaces', 'approximation', 'linear-algebra']"
217645,What does $\binom{-n}{k}$ mean?,"For positive integers $n$ and $k$, what is the meaning of $\binom{-n}{k}$? Specifically, are there any combinatorial interpretations for it? Edit: I just came across Daniel Loeb, Sets with a negative number of elements, Advances in Mathematics. 91 (1992), 64-74 , which includes a combinatorial interpretation for $\binom{n}{k}$ for any $n,k \in \mathbb{Z}$ in theorem 5.2.",['combinatorics']
217649,Uniqueness result in linear differential equation of degree $n$.,"Suppose that $f$ is such that $$f^{(n)}=\sum_{j=0}^{n-1}a_jf^{(j)}$$ Some little work is needed to get to ($a_j=0$ if $j<0$) $${f^{(n + 1)}} = \sum\limits_{j = 0}^{n - 1} {\left( {{a_{j - 1}} + {a_{n - 1}}{a_j}} \right)} {f^{(j)}}$$ and $${f^{(n + 2)}} = \sum\limits_{j = 0}^{n - 1} {\left( {{a_{j - 2}} + {a_{n - 1}}{a_{j - 1}} + {a_{n - 2}}a{  _j} + {a_j}a_{n - 1}^2} \right)} {f^{(j)}}$$ This evidences the increased difficulty in finding a closed form for $f^{n+k}$. However, we can prove by induction that -setting $N=\max(1,|a_0|,\dots,|a_{n-1}|)$ - we have $${f^{(n + k)}} = \sum\limits_{j = 0}^{n - 1} {{b_{jk}}} {f^{(j)}}$$ with each $b_{jk}\leq 2^kN^{k+1}$. Just as an example: $$\left| {{a_{j - 1}} + {a_{n - 1}}{a_j}} \right| \leqslant \left| {{a_{j - 1}}} \right| \cdot 1 + \left| {{a_{n - 1}}} \right|\left| {{a_j}} \right| \leqslant N \cdot N + N \cdot N = 2{N^2}$$ $$\eqalign{
  & \left| {{a_{j - 2}} + {a_{n - 1}}{a_{j - 1}} + {a_{n - 2}}{a_j} + {a_j}a_{n - 1}^2} \right| \leqslant   \cr 
  & \left| {{a_{j - 2}}} \right| \cdot 1 \cdot 1 + \left| {{a_{n - 1}}} \right|\left| {{a_{j - 1}}} \right| \cdot 1 + \left| {{a_{n - 2}}} \right|\left| {{a_j}} \right| \cdot 1 + \left| {{a_j}} \right|\left| {a_{n - 1}^2} \right| \leqslant   \cr 
  & {N^3} + {N^3} + {N^3} + {N^3} = 4{N^3} \cr} $$ Now, I need to show that for each particular $x$ there exists some $M$ such that, $$\left| {{f^{(n + k)}}\left( x \right)} \right| \leqslant {2^k}{N^{k + 1}}M$$ for each $k$. This with some linear algebra establishes a uniqueness theorem and provides the general solution to this equations. Could you hint me so I can finish this?",['ordinary-differential-equations']
217668,Proving that $f(x)$ divides $x^{p^n} - x$ iff $\deg f(x)$ divides $n$,Prove that $f(x)$ divides $x^{p^n} - x$ if and only if $d := \deg f(x)$ divides $n$. I believe that I have the backward direction covered: Let $d \mid n$ say $n = dq$ for some $q$ in $\mathbb{F}_p[x]$. Consider the field $\mathbb{F}_p[x]/(f(x))$ which has $p^d$ elements. Take an element $x+I$ from the field (here $I = (f(x))$) so we have: $(x+I)^{p^n} = (x+I)^{p^{dq}}$. As long as you keep factoring out $(x+I)$ with the $p^d$ power you will get $(x+I)$ so $x^{p^n} - x \in (f(x))$. I am having trouble getting to the other direction.,"['ring-theory', 'abstract-algebra']"
217681,Show that an analytic function in the unit disc satisfies a inequality,"Question: Let $f$ be an analytic function in the unit disc $D={z\in C: |z|<1}$. Consider a point $z_0\in D$. Show that there must be a positive integer n such that the n-th derivative of $f$ at $z_0$ satisfies $|f^{(n)}(z_0)| \leq n!n^n$. Thoughts so far: In class, we discussed power series and their usefulness in proving a variety of facts of complex analysis. Just by rearranging the inequality we see that $\frac{|f^{(n)}(z_0)|}{n!} \leq n^n$. Clearly $\frac{|f^{(n)}(z_0)|}{n!}$ is a term of the Taylor series expansion for $f(z)$, but the $n^n$ term is annoying the royal bananas out of me as I cannot think of a way to get that. I am considering using the ratio ($\lim_{n\to\infty} \frac{\frac{f^{(n)}(z_0)}{n!}}{\frac{f^{(n-1)}(z_0)}{(n-1)!}} = \lim_{n\to \infty} \frac{f^{(n)}(z_0)}{nf^{n-1}(z_0)} \leq 1 \implies \lim_{n\to\infty} \frac{f^{(n)}(z_0)}{f^{n-1}(z_0)} \leq n$) or n root test ($\lim_{n\to\infty} \sqrt[n]{\frac{f^{(n)}(z_0)}{n!}} \leq 1$) for convergence since analyticity implies convergence of the series, but I cannot seem to coax the $n^n$ out of any of my attempts. Also, I am uncertain whether I am using the notion of analyticity and power series correctly. Thank you in advance for any help that you may provide.","['analyticity', 'complex-analysis']"
217702,When can we interchange the derivative with an expectation?,"Let $ (X_t) $ be a stochastic process, and define a new stochastic process by $ Y_t = \int_0^t f(X_s) ds $. Is it true in general that $ \frac{d} {dt} \mathbb{E}(Y_t) = \mathbb{E}(f(X_t))  $? If not, under what conditions would we be allowed to interchange the derivative operator with the expectation operator?","['probability-theory', 'stochastic-processes']"
217705,Uniform Convergence of Difference Quotients to Partial Derivative,"I'm currently reading Evans' PDE book. In it he claims that for $f \in C^2_c(\mathbb{R}^n)$
$$\frac{f(x + he_i) - f(x)}{h} \to \frac{\partial}{\partial x_i}f(x)$$
and
$$\frac{\frac{\partial}{\partial x_i}f(x + he_j) - \frac{\partial}{\partial x_i}f(x)}{h} \to \frac{\partial^2}{\partial x_jx_i}f(x)$$ uniformly as $h \to 0$. My question is why must the convergence be uniform? Thanks in advance.","['partial-differential-equations', 'real-analysis', 'uniform-convergence']"
217738,How to calculate the cost of Cholesky decomposition?,The cost of Cholesky decomposition is $n^3/3$ flops (A is a $n \times n$ matrix). Could anyone show me some steps to get this number? Thank you very much.,"['matrix-decomposition', 'cholesky-decomposition', 'matrices', 'linear-algebra', 'numerical-linear-algebra']"
217758,Minimal set of trig identities to define all the trig functions,"What are a minimal set of trig identities that can uniquely define the trig functions?  I know that you can define, for example, $\sin(x)$ as the unique solution to the differential equation $f''(x) = -f(x), f(0)=0, f'(0)=1$, but I'd like to avoid analytical definitions to as much of a degree as possible (though this definition is interesting in that it nowhere explicitly mentions $\pi$). Obviously, if we define one trig function, then we can define the rest in terms of it (like $\cos(x) = \sin(\frac{\pi}{2} - x)$).  I am just curious if we can give some clever set of trig identities (like half angle formulas or the Pythagorean identity), which completely define the trig functions.  It would then follow that all other trig identities can be derived from these. And is it possible to do this without using any analysis?  My intuition says no, at least for a finite set of identities, because any finite set of identities would only define a countable set of points, so you'd at least have to assert that the functions are continuous.  So what are either a good infinite set of identities to define one of the trig functions, or a good finite set with the addition of the condition that the function is continuous (which to me is the least possible analysis we can get away with in this case)?  Or if you have another clever way that doesn't fit what I said above, I'd like to hear about it too.","['trigonometry', 'definition']"
217779,Prove that $\frac{n-1}{n}>\frac{2a_0a_2}{a_1^2}$,"Given that the following equation $$p(x)=a_0x^n+a_1x^{n-1}+...+a_{n-1}x+a_n=0$$ has $n$ distinct real roots. Prove that
$$\frac{n-1}{n}>\frac{2a_0a_2}{a_1^2}$$","['calculus', 'polynomials']"
217815,Why is intersection of two independent set probability a multiplication process?,"Why is the probability of intersection of two independent sets $A$ and $B$, a multiplication of their respective probabilities i.e. Why is
$$\mathbb{P}(A \cap B) = \mathbb{P}(A) \cdot \mathbb{P}(B)?$$ this question is about the intuition behind the definition of independence of sets in a probability space",['probability']
217836,"Difference between Gilbert Strang's ""Introduction to Linear Algebra"" and his ""Linear Algebra and Its Applications""?","Could someone please explain the difference between Gilbert Strang's ""Introduction to Linear Algebra"" and his ""Linear Algebra and Its Applications""? Thank you.","['linear-algebra', 'reference-request']"
217846,$H$ normal in $G$. Need $G$ contain a subgroup isomorphic to $G/H$,"If $H \trianglelefteq G$, need $G$ contain a subgroup isomorphic to $G/H$? I worked out the isomorphism types of the quotient groups of $S_3, D_8, Q_8$. For $S_3$: $S_3/\{1\} \cong S_3$, $S_3/\langle (1\ 2\ 3)\rangle \cong \mathbb Z_2$, $S_3/S_3 \cong \{1\}$. For $D_8$: $D_8/\{1\} \cong D_8$, $D_8/\langle r\rangle \cong \mathbb Z_2$, $D_8/\langle s, r^2\rangle \cong \mathbb Z_2$, $D_8/\langle sr^3, r^2\rangle \cong \mathbb Z_2$, $D_8/\langle r^2\rangle \cong V_4$, $D_8/D_8 \cong \{1\}$. For $Q_8$ $Q_8/\{1\} \cong Q_8$, $Q_8/\{1, -1\} \cong V_4$, $Q_8/\langle i \rangle \cong \mathbb Z_2$, $Q_8/\langle j \rangle \cong \mathbb Z_2$, $Q_8/\langle k \rangle \cong \mathbb Z_2$, $Q_8/Q_8 \cong \{1\}$. So I'm guessing that the statement is true, but I don't know how to prove it. And if its not true, I haven't found a counter example. Can someone give me a proof or counterexample? Or a HINT :D EDIT: Ahhh. I feel stupid now. Given $\{1, -1\}$ normal in $Q_8$ there is no subgroup of $Q_8$ isomorphic to $V_4$. Correct? So the statement is false?","['finite-groups', 'group-theory', 'abstract-algebra']"
217852,Geodesics in a manifold M diffeomorphic to $\mathbb S^2$,"I am now reading the book Calculus of Variations written by Jost and I encountered the following problem (in Theorem 2.3.3.): Let $M$ be a differentiable submanifold of $\mathbb R^d$ diffeomorphic to $\mathbb S^2$. By the compactness and connectedness of $M$, $\forall\ p, q \in M$ with $p \neq q$, there exists a shortest geodesic connecting $p$ and $q$. Now, what we want to do is to construct a diffeomorphism $$h_0: \mathbb S^2 \rightarrow M$$ with the following properties: $$p = h_0(0, 0, 1), q = h_0(0, 0, -1)$$ and a shortest geodesic arc $c: [0, 1] \rightarrow M$ with $c(0) = p, c(1) = q$ is given by $$c(t) = h_0(0, \sin \pi t, \cos \pi t).$$ This problem is intuitively true and I have tried ""shifting"" the inverse image of a geodesic smoothly to a part of a great circle, but I have yet to write down the proof successfully. Thus, I would really like to know if there is anyone who can help me solving this problem or give me some hints. Thanks in advance!","['calculus-of-variations', 'riemannian-geometry', 'differential-geometry']"
217869,Benford's law with random integers,"I tried testing random integers for compliance with Benford's law, which they are apparently supposed to do . However, when I try doing this with Python, map(lambda x:str(x)[0], [random.randint(0, 10000) for a in range(100000)]).count('1') I get approximately equal frequencies for all leading digits. Why is this the case? Might it have something to do with how the pseudorandom number generator, the Mersenne twister, works?",['statistics']
217890,How to find limit of a sequence defined by recurrence formula,I have the following problem: Let $a_{n}$ be the recurrence $$a_{n+1}=a_{n}+2a_{n-1}$$ with $a_{0}=0$ and $a_{1}=1$. Can you help me find $$\lim_{n\to\infty} \frac{a_{n+1}}{a_{n}}$$ for $n\geq 1$?,"['recurrence-relations', 'sequences-and-series', 'limits']"
217921,Is this binary operation commutative?,"In a set $X$ we define a binary operation $*$ such that $$\forall x, y \in X,\  (x*y)*y=y*(y*x)=x.$$ Is $*$ commutative and why?",['abstract-algebra']
217934,Triple integration in cylindrical coordinates,"Determine the value of $ \int_{0}^{2} \int_{0}^{\sqrt{2x - x^2}} \int_{0}^{1} z \sqrt{x^2 +y^2} dz\,dy\,dx $ My attempt: So in cylindrical coordinates, the integrand is simply $ \rho$.
$\sqrt{2x-x^2} $ is a circle of centre (1,0) in the xy plane. So $ x^2 + y^2 = 2x => \rho^2 = 2\rho\cos\theta => \rho = 2\cos\theta $ Therfore, I arrived at the limit transformations, $ 0 < \rho < 2\cos\theta,\,\, 0 < z < 1, \text{and}\,\,0 < \theta < \frac{\pi}{2}  $ Bringing this together gives $  \int_{0}^{\frac{\pi}{2}} \int_{0}^{2\cos\theta} \int_{0}^{1} z\,\,\rho^3\,dz\,d\rho\,d\theta $ in cylindrical coordinates. Is this correct?",['multivariable-calculus']
217961,Limit of a Recurrence Sequence,"$a_0=c$ where $c$ is positive, with $a_n=\log{(1+a_{n-1})}$,Find
\begin{align}\lim_{n\to\infty}\frac{n(na_n-2)}{\log{n}}\end{align} I'have tried Taylor expansion, but I can't find the way to crack this limit. Thanks alot for your attention!","['limits', 'sequences-and-series', 'analysis']"
217991,Question about Lee's Introduction to Topological Manifolds,"From page 2 in Lee's Introduction to topological manifolds: Question 1: What does ""describe parametrically"" exactly mean? Is it a synonym for
  ""global coordinate chart""? (that is, an atlas consisting of only one
  element, $(M,f)$ where $M$ is the entire manifold and $f$ is a homeomorphism $M \to \mathbb R^n$?) Question 2 : Can you give me an example of a $1$-manifold that does not admit a global coordinate chart? (that is, of a non-orientable curve?) (Is the answer that there cannot be such a manifold since non-orientable means that we can embed a Moebius band in it which we can't do in dimension $1$?) Question 3: Is this definition compatible with this
  one ? What's the domain of
  the map mentioned in the definition on Wolfram Alpha? Any one
  dimensional space? I doubt it since we also want $[0,1]$ to be the
  domain sometimes. Is this Wolfram entry incorrect? Thanks for help!","['manifolds', 'differential-geometry']"
217993,What is reductive group intuitively?,"I am studying Geometric invariant theory and wonder how I should understand linearly reductive algebraic group. We say that an affine algebraic group $G$ is linearly reductive if all finite dimensional $G$-modules are semi-simple. I am not sure if linearly reductive groups are the same as reductive groups, which are defined as algebraic groups $G$ over algebraically closed field such that the unipotent radical of $G$ is trivial. But this definition is still beyond my intuition. Are there any good way to understand (linearly) reductive groups? It would especially be nice if reductive (Lie) groups can be characterized in geometry.","['algebraic-geometry', 'reductive-groups', 'lie-groups', 'abstract-algebra']"
218007,Constructing Riemann surfaces using the covering spaces,"In the paper ""On the dynamics of polynomial-like mappings"" of Adrien Douady and John Hamal Hubbard, there is a way of constructing Riemann surfaces. I recite it as follow: A polynomail-like map of degree d is a triple $(U,U',f)$ where $U$ and $U'$ are open subsets of $\mathbb{C}$ isomorphic to  discs, with $U'$ relatively compact in $U$, and $f: U'\rightarrow U $ a  $\mathbb{C}$-analytic mapping, proper of degree $d$. Let $L \subset U' $be a compact connect subset containing $f^{-1}\left(\overline{U'}\right)$ and the critical points of $f$, and such that $X_0=U-L$ is connected. Let $X_n$ be a covering space of $X_0$ of degree $d^n$, $\rho_n:X_{n+1}\rightarrow X_n$ and $\pi_n:X_n\rightarrow X_0$ be the projections and let $X$ be the disjoint union of the $X_n$. For each $n$ choose a lifting $$\widetilde{f}_n\colon \pi_n^{-1}(U'-L)\rightarrow X_{n+1},$$ of $f$. Then $T$ is the quotient of $X$ by the equivalence relation identifying $x$ to $\widetilde{f}_n(x)$ for all $x\in \pi_n^{-1}(U'-L)$ and all $n=0,1,2,\ldots$. The open set $T'$ is the union of the images of the $X_n, n=1,2,\ldots$, and $F:T'\rightarrow T$ is induced by the $\rho_n$. Why $T$ is a Riemann surface and isomorphic to an annulus of finit modulus? Is there anything special about the $\pi_n,\rho_n$? What kind of background do I need?","['dynamical-systems', 'covering-spaces', 'riemann-surfaces', 'complex-analysis']"
218015,Understanding matrices as linear transformations & Relationship with Gaussian Elimination and Bézout's Identity,"I am currently taking a intro course to abstract algebra and am revisiting ideas from linear algebra so that I can better understand examples. When i was in undergraduate learning L.A., I thought of matrix manipulations as ways of solving $n \times n$ systems of equations. Recently i was exposed to the idea of a matrix being a linear transformation, and matrix multiplication being composition of linear transformations. Im trying to understand this in a more intuitive way and was hoping for some insight... I was thinking of a basic $2\times2$ example and how it affects a point $(x,y)$. 
We could have a matrix : \begin{bmatrix} a & b \\ c & d \end{bmatrix}
When we 'apply' or multiply this to a point $(x,y)$ using matrix multiplication we get new $x' = ax + by$ and $y' = cx + dy$. So if $b,c = 0$, then I can see that what we are doing is 'scaling' both $x \;\& \;y$. I'm guessing that if $b,c \neq 0$, then this becomes some sort of rotation or reflection, but how do you understand this on a fundamental level? How do these operations relate to Gaussian elimination when we are trying to solve systems of equations? Or are are these two seperate applications of matrices? Another observation is that when multiplying a matrix such as this one with a point, we get two equations which remind me of Bézout's identity. Am I overanalyzing this or can I draw connections between these two concepts? Thanks for any input!","['matrices', 'linear-algebra', 'gaussian-elimination']"
218027,"Find the possible values of $a$, $b$ and $c$?","Given $(a,\space b,\space c)\in \mathbb Z^3$ and  that $$\sqrt[3]{\sqrt{a}+\sqrt{b}} + \sqrt[3]{\sqrt{a}-\sqrt{b}} = c$$
Find the possible values of $a $, $b$, and $c$.","['algebra-precalculus', 'diophantine-equations']"
218035,The number of curves of given genus over a field,"Let $k$ be a field. Let $g\geq 0$ be an integer. I have an elementary question. Let $N$ be the ""number"" of $k$-isomorphism classes of smooth projective geometrically connected curves over $k$ of genus $g$. (Note that $N$ can also be $\infty$.) Is $N$ finite if $k$ is finite? When is $N$ finite in general? I'm looking for the ""most elementary"" answer to this question.","['arithmetic-geometry', 'riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
218037,Cauchy Riemann equations for real functions.,"Let $f(x+iy) = x^2 + i.0$. Then $u(x,y) = x^2$ and $v(x,y) = 0.$ Hence $u_x = 2x$, $v_y = 0$, $u_y = 0$, and $v_x = 0.$ Clearly this doesn't satisfy Cauchy Riemann equations, and hence is not differentiable. But we know from calculus that $f'(x) = 2x.$ So my question is, where I went wrong in my analysis?",['complex-analysis']
218046,Relations between p norms,"The $p$ -norm on $\mathbb R^n$ is given by $\|x\|_{p}=\big(\sum_{k=1}^n
|x_{k}|^p\big)^{1/p}$ . For $0 < p < q$ it can be shown that $\|x\|_p\geq\|x\|_q$ ( 1 , 2 ). It appears that in $\mathbb{R}^n$ a number of opposite inequalities can also be obtained. In fact, since all norms in a finite-dimensional vector space are equivalent, this must be the case. So far, I only found the following: $\|x\|_{1} \leq\sqrt n\,\|x\|_{2}$ ( 3 ), $\|x\|_{2} \leq \sqrt n\,\|x\|_\infty$ ( 4 ). Geometrically, it is easy to see that opposite inequalities must hold in $\mathbb R^n$ . For instance, for $n=2$ and $n=3$ one can see that for $0 < p < q$ , the spheres with radius $\sqrt n$ with $\|\cdot\|_p$ inscribe spheres with radius $1$ with $\|\cdot\|_q$ . It is not hard to prove the inequality (4). According to Wikipedia, inequality (3) follows directly from Cauchy-Schwarz, but I don't see how. For $n=2$ it is easily proven (see below), but not for $n>2$ . So my questions are: How can relation (3) be proven for arbitrary $n\,$ ? Can this be generalized into something of the form $\|x\|_{p} \leq C \|x\|_{q}$ for arbitrary $0<p < q\,$ ? Do any of the relations also hold for infinite-dimensional spaces, i.e. in $l^p$ spaces? Notes: $\|x\|_{1}^{2} = |x_{1}|^2 + |x_{2}|^2 + 2|x_{1}||x_{2}| \leq |x_{1}|^2 + |x_{2}|^2 + \big(|x_{1}|^2 + |x_{2}|^2\big) = 2|x_{1}|^2 + 2|x_{2}|^2$ , hence $=2\|x\|_{2}^{2}$ $\|x\|_{1} \leq \sqrt 2 \|x\|_{2}$ .
This works because $|x_{1}|^2 + |x_{2}|^2 \geq 2|x_{1}\|x_{2}|$ , but only because $(|x_{1}| - |x_{2}|)^2 \geq 0$ , while for more than two terms $\big(|x_{1}| \pm |x_{2}| \pm \dotsb \pm |x_{n}|\big)^2 \geq 0$ gives an inequality that never gives the right signs for the cross terms.","['normed-spaces', 'functional-analysis', 'real-analysis']"
218051,Math contest: Find number of roots of $F(x)=\frac{n}{2}$ involving a strange integral.,"Edit summary : A good answer appeared. CW full answer added, based on given answers. Removing my ugly-looking attempts, as they still remain in the rev. history. Here's a final-round calculus contest problem in our district in 2009. Test paper isn't available online. I originally proved $F(n/2)<n/2$ but failed to prove $F(n)>n/2$ and the monotonicity of $F(n)$. Define
      $$F(x)=\int\limits_0^x \mathrm e^{-t} \left(1+t+\frac{t^2}{2!}+\cdots+\frac{t^n}{n!}\right) \mathrm d t$$
    where $n>1, n \in \mathbb N^+$; and an equation: $\displaystyle F(x)=\frac{n}{2}$. Find the number of roots of this equation within the interval $\displaystyle I=\left(\frac{n}{2},n\right)$. Tedious Previous Attempts Removed.","['power-series', 'calculus', 'integration', 'contest-math']"
218074,"Prove: If $A \subseteq C$ and $B \subseteq D$, then $A \cap B \subseteq C \cap D$","Is the form and correctness of my elementwise proof of this correct? I don't have any other way of getting feedback for my proofs and I want to improve. Proof. Suppose $A, B, C, D$ are sets such that $A \subseteq C$ and $B \subseteq D$ and let $x \in A \cap B$. It has to be shown that $x \in C \cap D$. $x \in A \cap B$ means that $x \in A$ and $x\in B$. Because $A \subseteq C$, $x \in C$ and because $B \subseteq D$, $x \in D$. Thus, $x \in C \cap D$. Thus, if $A \subseteq C$ and $B \subseteq D$, then $A \cap B \subseteq C \cap D$.",['elementary-set-theory']
218082,How to reduce the limit one gets when deriving the derivative of the general exponential function?,"When applying the definition of a derivative to $\frac{d}{dx}b^x$ and a little algebra one arrives to $$b^x\times\lim\limits_{h \to 0}\frac{b^h - 1}{h}$$ where of course that limit equals $\ln(b)$. I know this limit can be evaluated with L'Hospitals rule, but that involves using the derivative what I am just about to prove, so that would be a circular proof. I suspect one has to reduce this limit to something that relates to the definition of e as $$\lim\limits_{n \to \infty}(1+1/n)^n$$ but I can not do it. How to show that that limit equals $\ln(b)$, so the proof of the derivative of $b^x$ is complete ? Note: I found that by substituting for $s = b^h-1$, etc, one can separate $\ln(b)$, but than the another indeterminate limit remains: $\lim\limits_{s \to 0}(s/\ln(1+s))$, which must be $1$, and again I do not want to solve it using L'Hospital's rule, but I cannot otherwise.","['logarithms', 'calculus', 'derivatives', 'limits']"
218092,Every Hilbert space has an orthonomal basis - using Zorn's Lemma,"The problem is to prove that every Hilbert space has a orthonormal basis. We are given Zorn's Lemma, which is taken as an axiom of set theory: Lemma If X is a nonempty partially ordered set with the property that every totally ordered subset of X has an upper bound in X, then X has a maximal element. Given a orthonormal set $E$ in a Hilbert space $H$ , it is apparently possible to show that $H$ has an orthonormal basis containing $E$ . I tried to reason as follows:
Suppose $E$ is a finite set of $n$ elements. Then one can number the elements of $E$ to create a totally ordered set of orthonormal elements. Then the span $<E>$ can be identified with $R^n$ , where each element $v = v_1 e_1 + v_2 e_2 + ... + v_n e_n$ is identified with the vector $(v_1, v_2, ..., v_n)$ . On $R^n$ we have a total order, namely the ""lexigraphical order"" $(x_1,x_2,...,x_n) \leq (y_1,y_2,...,y_n)$ if $x_1 < y_1$ or if $x_1 = y_1$ and $x_2 < y_2$ or if $x_1 = y_1$ , $x_2 = y_2$ and $x_3 < y_3$ and so on. Hence $E$ is a totally ordered subset of $H$ and $H$ is a partially ordered set. However, this set doesn't seem to have an upper bound. The set $E$ does have an upper bound. If we define a total order on $E$ only, then X is a partially ordered set satisfying the criteria so X has a maximal element? This is as far as I got, and I am not sure the entire argument is correct. I don't see what kind of maximal element I am seeking, since the orthonormal basis of a Hilbert space can have countably infinity number of elements.","['orthonormal', 'hilbert-spaces', 'functional-analysis', 'axiom-of-choice']"
218093,Skew-triangular (?) matrices and their properties,"By skew-triangular matrices, I mean matrices with the following sparsity patterns. $$\begin{bmatrix}
\times & \times & \times & \times \\
  \times & \times & \times \\
  \times & \times \\
  \times \\
\end{bmatrix} \qquad \text{or}\qquad
\begin{bmatrix}
 &  &  & \times \\
 &  & \times & \times \\
 & \times & \times & \times \\
\times & \times & \times & \times \\
\end{bmatrix}$$ Simple experiments with Mathematica show that the inverse of the first type is a matrix of the second type (and vice versa, of course). Do these matrices have their real name and where do they occur? What other interesting properties do they possess? I am asking this just out of curiosity because a brief googling failed to give me the answer.","['matrices', 'linear-algebra', 'reference-request', 'terminology']"
218113,"$X_n\overset{\mathcal{D}}{\rightarrow}X$, $Y_n\overset{\mathbb{P}}{\rightarrow}Y \implies X_n\cdot Y_n\overset{\mathcal{D}}{\rightarrow}X\cdot Y\ ?$","The title says it. I know that if limiting variable $Y$ is constant a.s. (so that $\mathbb{P}(Y=c)=1)$ then the convergence in probability is equivalent to the convergence in law, i.e. $$Y_n\overset{\mathbb{P}}{\longrightarrow}c \iff Y_n\overset{\mathcal{D}}{\longrightarrow}c,$$ and then Slutsky's theorem asserts that $X_n\cdot Y_n\overset{\mathcal{D}}{\longrightarrow}X\cdot c$. But what about the case when $Y$ is not constant? Does $X_n\overset{\mathcal{D}}{\longrightarrow}X$, $Y_n\overset{\mathbb{P}}{\longrightarrow}Y$ imply $X_n\cdot Y_n\overset{\mathcal{D}}{\longrightarrow}X\cdot Y$ ? I would appreciate any hints.","['probability-theory', 'convergence-divergence']"
218131,Enumerations of the rationals with summable gaps $(q_i-q_{i-1})^2$,"Here is a question from my undergraduate days which I never knew the answer to. I just want to know if anyone can offer me a hint. Consider the rationals in $[0,1]$. Does there exist a (bijective) enumeration of these rationals $q_1,q_2,\ldots$ such that the sum $\sum\limits^\infty_{i=1} (q_i-q_{i-1})^2$ is finite?","['sequences-and-series', 'real-analysis']"
218141,Manifold with different differential structure but diffeomorphic,"I'm new to differential geometry and reading Lee's book Manifold and Differential Geometry . In the first chapter, he mentioned the following two maps on $\mathbb{R}^n$: (1) $id: (x_1,x_2\cdots x_n) \rightarrow (x_1,x_2\cdots x_n)$ (2) $\varphi:  (x_1,x_2\cdots x_n) \rightarrow  (x_1^3,x_2\cdots x_n)$ Then, $\mathcal{A}_1$= { $(\mathbb{R}^n,id)$ } and $\mathcal{A}_2$= { $(\mathbb{R}^n,\varphi)$  } are two differential structure on $\mathbb{R}^n$, and $\mathcal{M}_1=(\mathbb{R}^n, \mathcal{A}_1)$, $\mathcal{M}_2=(\mathbb{R}^n,\mathcal{A}_2)$ are two manifolds. It easy to verify that $\mathcal{M}_1$ and $\mathcal{M}_2$ have the same induced topology, the standard topology. $\mathcal{A}_1$ and $\mathcal{A}_2$ are not compatible, for $id\circ \varphi^{-1}:(x_1,x_2\cdots x_n) \rightarrow (x_1^{\frac{1}{3}},x_2\cdots x_n)$ is not differentiable at origin. Therefore, $\mathcal{M}_1$ and $\mathcal{M}_2$ have different differential structure. My question is: are they diffeomorphic? According to Lee, the author, they are diffeomorphic through $\varphi$ (page 27). But I don't think $\varphi$ is a diffeomorphism between them because $\varphi^{-1}$ is not differentiable at origin. So are they not diffeomorphic? But according the result of Donaldson and Freedman, each $\mathbb{R}^n$ except $n=4$ (with standard topology) only have one diffeomorphism class, so for any $\mathbb{R}^n$ except $\mathbb{R}^4$, $\mathcal{M}_1$ and $\mathcal{M}_2$ are diffeomorphic. But why?","['manifolds', 'differential-geometry']"
218176,An elementary question about gluing affine schemes,"I can understand how $\mathbb{P}^1_{\mathbb{C}}$ is a union of two $\mathbb{A}^1_{\mathbb{C}}$ geometrically. But whenever I hear phrases like ""One can obtain ""$\operatorname{Proj}\mathbb{C}[x_0,x_1]$ by gluing $\operatorname{Spec}\mathbb{C}[x]$ and $\operatorname{Spec}\mathbb{C}[1/x]$ via the map $x\leftrightarrow 1/x$,"" I get a bit confused. I guess the problem is I don't understand exactly what ""gluing"" means in algebraic context. The aforementioned sentence seems to refer to the funtorial relationship between schemes and rings, but I don't see what that has to do with gluing.",['algebraic-geometry']
218185,Differentiating with respect to x and y,"I'm reading a proof and I'm struggling with basic calculus here. 
Given the equation, 
$F[x, F(y, z)] = F[F(x, y), z] $
set  $u = F(x, y)$ and $v = F(y, z)$
so you have $$F(x, v) = F(u, z)$$ Now differentiate with respect to $x$ and $y$ leads to the following $F_{x}(x,v) = F_{x}(u,z)F_{x}(x,y)$ $F_{y}(x,v)F_{x}(y,z) = F_{x}(u,z)F_{y}(x,y)$ I think, according to the chain rule, the derivative of  $F[x, F(y, z)]$ or $F[x, u]$ with respect to x should equal $F_{x}(u,z)F_{x}(x,y)$. So number 1 makes sense. But when you differentiate that with respect to $y$, I don't understand how you get 2.","['multivariable-calculus', 'calculus']"
218225,How to show that a stopped process $X_T$ is $\mathcal{F}$ measurable?,"I'm trying to figure this out, and I feel I'm pretty close to why it's the case. I just can't quite get the details to work. Let $X$ be an adapted process on $(\Omega,\mathcal{F},\mathbb{P})$ and $T$ a finite stopping time. Show that $X_T$ is $\mathcal{F}$-measurable. As I understand it, the process $X_T = \{X^T_n\}_{n\geq1}$ is defined as $X^T_n(\omega) := X_{T(\omega) \wedge n}(\omega)$. Since $X$ is an adapted process we have that $X_n$ is $\mathcal{F}_n$-measurable for all $n$, and since $\mathcal{F}_n \subset \mathcal{F}$ this intuitively should carry over to $X_T$. The $\mathcal{F}_n's$ are from the filtration of $X$. My problem is with $T(\omega)$ being dependant on $\omega$, and that $T$ isn't necessarily bounded which means you can't bound $T(\omega)\wedge n$. Any tips on how I should approach this? EDIT: some clarification","['probability-theory', 'stochastic-processes']"
218229,How do you find this variance?,"$\newcommand{\Var}{\operatorname{Var}} \newcommand{\Cov}{\operatorname{Cov}}$ If I'm given $\Var(\hat {\beta_1}-3\hat {\beta_2})$ how do I find the variance of this? I have gotten this far I'm just not sure about the covariance part. I know that $$\Var(\hat {\beta_1}-\hat {\beta_2})=\Var(\hat {\beta_1})+\Var(\hat {\beta_2})-2\Cov(\hat {\beta_1},\hat {\beta_2})$$ so I came up with the following: $$\Var(\hat {\beta_1}-3\hat {\beta_2})=\Var(\hat {\beta_1})+9\Var(\hat {\beta_2})-{}???$$ I thought it would be $6\Cov(\hat {\beta_1},\hat {\beta_2})$ but I'm just really not sure what I would do for the covariance part.","['probability-theory', 'probability']"
218239,Where does the guassian function/normal or bell curve come from?,"I am confused as to where the function for the normal distribtuion comes from.  Where does the e and pi come from?  In my textbook I am presented with the function,but I am unsure about where it came from.  I have spent hours on google and have yet to find a good proof that i can understand.  Come someone provide a source that shows an elementary proof of the normal curve function.","['statistics', 'normal-distribution']"
218242,Algebraic Geometry studied via Filters,"Is there any research relating varieties with filters instead of radical ideals?  For example, Suppose we have a variety V in C^n, now consider the fixed filter consisting of all algebraic sets (zeroes of polynomials) which contain this variety.  Now instead of considering the spectrum of a ring, perhaps we can look at the set of all these fixed filters, and give it a natural topology (I believe initial topology should work). It is well known that for a compact space X, the set of all ultrafilters on X corresponds to the set of points in X.  However, for a locally compact space Y (Like R), this isn't true.  Instead, we need to look at the Stone-Cech Compactification of this space to give us all of our Ultrafilters. Is there any useful analogy with this?  For example, can an affine scheme be defined by the corresponding filters (with initial topology) of the prime ideals of some commutative ring?  And if so, is this of any use?","['analytic-geometry', 'algebraic-geometry']"
218246,Combinatorics questions about binary strings of length $10$,"I'm just running through my midterm review.. I'm usually pretty bad at applying simple combinatorics to word problems.. So I just was wondering if anyone could confirm the following answers. We're dealing with binary strings of length 10. a) How many binary strings of length 10 have at least three 0's? So, this is equal to the total number of binary strings of length 10 minus the number of binary strings of length 10 with zero, one, and two 0's. zero 0's: There is only 1 string like this: 1111111111 one 0: There are ten places to place the one 0, and thus there are ten of such cases two 0's: There are ten places to place the first 0 and nine places to place the second 0.  However, there is an overlap so we divide by $2!$. b)How many binary strings of length 10 have an even number of 1's? So here I just applied the method I used for the number of strings with two 0's. zero 1's: 1 string two 1's: $\dfrac{10*9}{2!}$ four 1's: $\dfrac{10*9*8*7}{4!}$ six 1's: $\dfrac{10*9*8*7*6*5}{6!}$ eight 1's: $\dfrac{10*9*8*7*6*5*4*3}{8!}$ ten 1's: $\dfrac{10!}{10!}$ So if you sum all of that up, you get 512 strings which makes sense because $2^{10} = 1024$.. c) The number of binary strings of length 10 with alternating 0's and 1's This one's really easy... There are only two options: $1010..$ and $0101..$ d) Four consecutive 0's Here, there are $7$ places to put the block of zeros, then $2$ ways to fill in each remaining space, for a total of $7 * 2^6$ possible strings. Any help / comments are greatly appreciated. Cheers",['combinatorics']
218257,Probability of winning an arbitrary game,"I would like to know how to find the answer to this probability problem. Two players, $A$ and $B$, are playing an arbitrary game (no draw is possible). The winner is the player who wins two consecutive games. Player $A$ has $2/3$ chances of winning a single game and player $B$ $1/3$. Example: Player $A$ loses the first game, but wins the two next games, so he wins the overall game. What is the probability that Player $A$ wins the overall game?",['probability']
218269,To determine if$f^{-1}(x)$ is periodic function or not? $f(x)=\int_1^{x} \frac{1}{\sqrt[m]{P(t)}}\;dt$,"$$f(x)=\int_1^{x}  \frac{1}{\sqrt[m]{P(t)}}\;dt$$ $P(x)$ is polynomial with degree $n$. $m$ is an positive integer and $m>1$ What is the algoritm to determine $f^{-1}(x)$ is periodic function via using  $P(x)$ and $m$ without evaluting the integral ? Is there also a way to find period without evaluting the integral? Example 1:
$P(x)=x^2$ , $m=2$ $$f_1(x)=\int_1^{x}  \frac{1}{t}\;dt=\ln x$$ $$f_1^{-1}(x)=e^x$$ $$f_1^{-1}(x+2k\pi i)=e^{x+2k\pi i}=e^x=f_1^{-1}(x)$$   $k$ is an integer
$$f_1^{-1}(x+2k\pi i)=f_1^{-1}(x)$$
$f_1^{-1}(x)$ is a periodic function Example 2:
$P(x)=1-x^2$ , $m=2$
$$f_2(x)=\int_1^{x}  \frac{1}{\sqrt{1-t^2}}\;dt=\arcsin x-\frac{\pi}{2}$$ $$f_2^{-1}(x)=\sin {(x+\frac{\pi}{2})}$$ $$f_2^{-1}(x+2k\pi )=\sin{(x+\frac{\pi}{2}+2k\pi )}=\sin{(x +\frac{\pi}{2})}=f_2^{-1}(x)$$   $k$ is an integer
$$f_2^{-1}(x+2k\pi )=f_2^{-1}(x)$$
$f_2^{-1}(x)$ is a periodic function Example 3:
$P(x)=(1+x^2)^2=1+2x^2+x^4$ , $m=2$
$$f_3(x)=\int_1^{x}  \frac{1}{1+t^2}\;dt=\arctan x -\frac{\pi}{4}$$ $$f_3^{-1}(x)=\tan (x+\frac{\pi}{4})$$ $$f_3^{-1}(x+k\pi )=\tan{(x+\frac{\pi}{4}+k\pi )}=\tan{(x+\frac{\pi}{4} )}=f_3^{-1}(x)$$   $k$ is an integer
$$f_3^{-1}(x+k\pi )=f_3^{-1}(x)$$
$f_3^{-1}(x)$ is a periodic function Example 4:
$P(x)=x^4$ , $m=2$ $$f_4(x)=\int_1^{x}  \frac{1}{t^2}\;dt=\frac{x-1}{x}$$ $$f_4^{-1}(x)=\frac{1}{1-x}$$ $f_4^{-1}(x)$ is not periodic function Thanks a lot for answers","['integration', 'functions']"
218284,Proof of Pitt's theorem,I'm reading the book Topics in Banach Space Theory by Albiac F. Kalton N. J. I got stuck at the proof of Pitt's theorem. In the second paragraphs authors tries to prove ad absurdum that for weakly nuul sequence $\lim\limits_{n\to\infty}\Vert T(x_n)\Vert=0$. They say that without loss of generality one may suppose that $\{x_n\}_{n=1}^\infty$ is a weakly null sequence with $\Vert x_n\Vert=1$ and $\Vert T(x_n)\Vert>\delta$ for all $n\in\mathbb{N}$. I think they normalized original sequence $\{x_n\}_{n=1}^\infty$ and claims that it is also weakly null. Why is weakly null sequence remains weakly null after normalization? Another place I got stuck is the place where authors claims that passing to subsequence in $\{T(x_n)\}_{n=1}^\infty$ gives subsequence equivalent to the natural basis of $\ell_p$. And they also assume that after passing to subsequence $\{x_n\}_{n=1}^\infty$ remains to be equivalent to natural basis of $\ell_p$. Why is $\{x_n\}_{n=1}^\infty$ remains to be equivalent to natural basis of $\ell_p$? Thank you.,"['lp-spaces', 'compact-operators', 'functional-analysis', 'banach-spaces']"
218302,A conjugacy class $C$ is rational iff $c^n\in C$ whenever $c\in C$ and $n$ is coprime to $|c|$.,"Let $C$ be a conjugacy class of the finite group $G$. Say that $C$ is rational if for each character $\chi: G \rightarrow \mathbb C$ of $G$, for each $c\in C$, we have $\chi(c) \in \mathbb Q$. I am trying to show that $C$ is rational if and only if whenever $c\in C$ and $n$ is relatively prime to $|c|$, we have $c^n \in C$. Any suggestions?","['finite-groups', 'group-theory', 'abstract-algebra', 'representation-theory']"
218319,Show something using the Mean Value Theorem,"I've got an exercise about differentiability, mean value theorem and suprema. To be honest I don't understand the structure of this question. Maybe you guys are so kind to help me out :) Let $f: [0,1] \rightarrow \mathbb{R}$ be differentiable with $f(0) = 0$ , and satisfying $$|f'(x)|\le M|f(x)|, x\in[0,1]  $$ for some $M>0$ a.) Use the Mean Value Theorem to show that for all $x  \le x_0 \in[0,1], y\in[0,x_0]:$ $$ |f(x)|\le x_0 \text{ sup} |f'(y)|\le M x_0 \text{ sup} |f(y)|$$ b.) Use the previous part to show that f is the zero-function on [0,1]. ( Hint : What happens if we choose $x_0$ such that M $x_0<1$ ?) Known definitions, theorems: Mean Value Theorem (There is a c for which f'(c) equals f(b)-f(a)/(b-a) if [a,b] is the domain, and f is continuous on [a,b], differentiable on (a,b) Differentiable function means that that for all points c $\in$ A, the limit of f(x)-f(c)/(x-c) exists. Interior Extremum Theorem (Intermediate Value theorem). States that if f attains a maximum or minimum value on a open interval, then at some point c $\in$ (a,b), f'(c)=0 Darboux Theorem : If f is differentiable on an interval [a,b] and if $\alpha$ satisfies $f'(a) < \alpha < f'(b)$ , then there exists a point c $\in$ (a,b) where $ f'(c) = \alpha $ .","['derivatives', 'real-analysis']"
218327,Statistic Missing Value [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question A professor has recorded exam grades for $30$ students in his class, $1$ of the $30$ grades is unreadable. The mean score on the exam was $82$, and the mean score of the $29$ available scores is $84$, What is the value of the unreadable score?","['statistics', 'average']"
218377,Why does the column space of a linear transformation equal its image?,I'm having trouble understanding this. Why does the column space of the matrix of a linear transformation equal the image of the linear transformation?,['linear-algebra']
218383,Sums of independent random variables converging almost surely,"I am working through Achim Klenke's text entitled ""Probability Theory"", and I came across the following interesting exercise: Let $(X_i)_{i\in\mathbb{N}}$ be independent, square-integrable random variables with $\mathbb{E}(X_i)=0$ for all $i$. Suppose that $\sum_{i=1}^\infty \mathbb{E}(X_i^2)<\infty$. Conclude that there exists a real random variable $X$ with $\sum_{i=1}^n X_i \xrightarrow{n\to\infty} X$ almost surely. I attempted to prove this via Borel-Cantelli, namely, I tried to show that $\mathbb{P}(\{\omega:\sum_{i=n}^\infty X_i(\omega)\xrightarrow{n\to\infty}0 \})=1$, since the sequence will be summable if and only if the remainders are going to zero. In the details of B-C, though, for a fixed $\epsilon>0$ this requires showing that $\mathbb{P}(|\sum_{i=n}^\infty X_i| > \epsilon \;\;\;i.o.) =0$. An application of Chebyshev's inequality and using independence then gives $$\mathbb{P}\left(\left|\sum_{i=n}^\infty X_i\right|>\epsilon\right) \leq \frac{1}{\epsilon^2}\sum_{i=n}^\infty \mathbb{E}(X_i^2)<\infty.$$ But now we certainly need not have that this is summable over all $n$ (take $X_i$ to be Bernoulli with possible values $\pm 1/i$). I imagine my choice of Chebyshev's wasn't strong enough, or the entire approach is off. Suggestions?","['sequences-and-series', 'convergence-divergence', 'measure-theory', 'random-variables', 'probability-theory']"
218421,What are the practical applications of the Taylor Series?,"I started learning about the Taylor Series in my calculus class, and although I understand the material well enough, I'm not really sure what actual applications there are for the series. Question: What are the practical applications of the Taylor Series? Whether it's in a mathematical context, or in real world examples.","['calculus', 'taylor-expansion']"
218428,Proving a necessary and sufficient condition for compactness of a subset of $\ell^p$,"Let $A \subset \ell^p$, where $1 \le p \lt \infty$.  Suppose the following conditions are true: 1) $A$ is closed and bounded 2) $\forall \epsilon \gt 0, \: \exists \: N \in \mathbb{N}$ such that $\forall x \in A$, we have $\sum_{n \ge N}|x_{n}|^{p} \lt \epsilon$. Then show that $A$ is compact. Also, show that the converse is true.","['sequences-and-series', 'functional-analysis', 'real-analysis', 'compactness']"
218440,$f$ has a zero at $z_o$ and $g$ has a pole at $z_o$. Prove that $fg$ has a removable singularity at $z_o$?,"Problem:
Suppose that $f:D(z_o,R)\to C$ is analytic and has a zero of order $m\ge1$ and that $g:D(z_o,R)\to C$ is analytic and has a pole of order $l\le m$ at $z_o$. Prove that $fg$ has a removable singularity at $z_o$. My approach: In order to show that $fg$ has a removable singularity at $z_o$, we can show that $fg$ is bounded as $z \rightarrow z_o$, or $|f(z_o)g(z_o)|\lt n \in N$. But because $f(z_o)=0$ with order $\ge 1$, we only have to show that $g(z)$ does not approach infinity as $z \rightarrow z_o$. My question: How do I show that $g(z)$ is bounded as $z \rightarrow z_o$? I know that $g$ has a pole of order $l\le m$ at $z_o$, so $ \frac{1}{g} $ has a zero of order $l\le m$ at $z_o$. It'd be easy to show that $ \frac{1}{g} $, and therefore $ \frac{f}{g} $, has a removable singularity, but I'm stuck on proving it for $fg$.",['complex-analysis']
218441,Generate a polynomial w/ integer coefficients whose roots are rational values of sine/cosine?,"I'm a high school calculus/precalculus teacher, so forgive me if the question is a little basic. One of my (very gifted) students recently came up with a construction yielding a quartic, one of whose roots was sin(80º) -- which led me to the startling discovery that this (and, indeed, all rational values of sine/cosine (in degrees; that is, rational multiples of π)) are algebraic. I've come across a number of proofs that the numbers are algebraic since, which, as I understand it, goes back to complex roots of unity. What I -haven't- seen, and would very much like to see/understand, is some general method for generating/constructing polynomials (w/ integer coefficients) whose roots are sine/cosine of rational values (in degrees). (My student's method only works for 80º/10º, 70º/20º, and 75º/15º, unfortunately). Would much appreciate...","['trigonometry', 'polynomials', 'number-theory']"
218485,Integral domains are PID $\!\iff\!$ Bezout & ACCP,"Let R be a commutative ring with identity. If every ideal generated by two elements of R is principal, then can we conclude that R is a PID? Also, if every finitely generated ideal of R is principal, can we conclude that R is a PID?","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
218493,"Finding an example for $\mathrm{Hom}\left ( \prod A_{j} ,B\right )\ncong \prod \mathrm{Hom}\left ( A_{j} ,B\right ) $","I've been trying to find concrete examples to prove that these statements aren't true: Let $B$ be an $R$-module and $(A_{j})$ a family of $R$-modules then: $$
\mathrm{Hom}\left ( \prod A_{j} ,B\right )\cong \prod\mathrm{Hom}\left ( A_{j} ,B\right )$$ $$
\mathrm{Hom}\left ( \prod A_{j} ,B\right )\cong \ \bigoplus\mathrm{Hom}\left ( A_{j} ,B\right )$$ For the first statement, I know that if we change the direct product with direct sum in the left side, then it is true. What I've been trying to do is to find an example where the left side is different from zero and when computing the right side, the direct product of Hom's, we get zeros, but I have had no success. Specifically, I've been struggling to find an example where the left side is nonzero. Any idea in both cases would be appreciated.","['modules', 'abstract-algebra']"
218502,How do I determine Heavy Tails on an empirical distribution?,"How do you determine if an empirical distribution has a heavy tail? 
What would I have to do in order to determine that?
I'm currently using mathematica, so if you know of any coding, that would be very helpful. If not, then that's alright.","['statistics', 'probability-distributions']"
218510,Showing $\left\lvert \frac{\sin(nx)}{n\sin(x)} + \frac{\cos(nx)}{n\cos(x)} \right\rvert \le\left\lvert\frac{n+1}{n}\right\rvert $,"It was shown in here that  $$\left\lvert \frac{\sin(nx)}{n\sin(x)}\right\rvert \le1\,\,\forall x\in\mathbb{R}-\{\pi k: k\in\mathbb{Z}\}$$ iff $n$ is a non-zero integer. Using the similar argument in the same post, we are able to show that $$\left\lvert \frac{\cos(nx)}{n\cos(x)}\right\rvert \le1\,\,\forall x\in\mathbb{R}-\{\frac{(2k+1)\pi}{2} : k\in\mathbb{Z}\}$$ iff $n$ is an odd non-zero integer (Please alert me if this is wrong). Now, by some graph sketching, it seems that $$\left\lvert \frac{\sin(nx)}{n\sin(x)} + \frac{\cos(nx)}{n\cos(x)} \right\rvert \le\left\lvert \frac{n+1}{n}\right\rvert \,\,\forall x\in\mathbb{R}-\{\frac{k\pi}{2} : k\in\mathbb{Z}\}$$ iff $n$ is an odd non-zero integer. I am not sure if the above inquality is true. Please enlighten me!","['trigonometry', 'inequality']"
218512,Show that a function that is locally increasing is increasing?,"A function $f : \mathbb{R} \to \mathbb{R}$ is locally increasing at a point $x$ if there is a $\delta > 0$ such that $f(s) < f(x) < f(t)$ whenever $x-\delta < s < x < t < x+\delta$. Show that a function that is locally increasing at every point in $\mathbb{R}$ must be increasing, i.e., $f(x) < f(y)$ for all $x < y$.","['real-analysis', 'analysis']"
218519,Ways $S_3$ can act on a set of 4 elements.,"Describe all ways in which $S_3$ can operate on a set of four elements. My approach : This question can be broken down into: How many homomorphisms exist from $S_3$ to $S_4$. Say $\varphi : S_3 \to S_4$ is a homomorphism. Then we have three possibilities for $\text{ker }\varphi$: $\{1\}, \{1, (1\ 2\ 3), (1\ 3\ 2)\}$, and $S_3$. The case in which $\text{ker }\varphi = S_3$ is the trivial homomorphism that maps everything to the identity. Now, the case in which $\text{ker }\varphi = \{1\}$ is the same as saying that the mappings are injective. This comes down to picking three of the four elements and permutating them and leaving the fourth one fixed. There are $\binom43 = 4$ ways of doing this. Say $\text{ker }\varphi = \{1, (1\ 2\ 3), (1\ 3\ 2)\}$. This means that $\varphi((1)) = \varphi((1\ 2\ 3)) = \varphi((1\ 3\ 2)) = (1)$. Morover we can observe the following two properties immediately: $\varphi((1\ 2\ 3)) = \varphi((1\ 3))\varphi((1\ 2)) = (1)$. Equivalently $\varphi((1\ 2)) = \varphi((1\ 3))$. $\varphi((1\ 3\ 2)) = \varphi((1\ 3))\varphi((2\ 3)) = (1)$. Equivalently $\varphi((1\ 3)) = \varphi((2\ 3))$. and thus $\varphi((1\ 2)) = \varphi((1\ 3)) = \varphi((2\ 3))$. But we know by properties of homomorphisms that $\vert \varphi((1\ 3)) \vert \mid \vert (1\ 3) \vert = 2$. So $\vert \varphi((1\ 3)) \vert$ is 1 or 2. But if the order of $\varphi((1\ 3))$ were 1 it would be in the kernel, which would be a contradiction to the kernel we chose, so it must be 2. We can map $(1\ 3)$ to any 2-cycle in $S_4$, of which there are 6, as well as any product of disjoint 2-cycles, of which there are 3. Hence we have 9 possible homomorphic mappings given this kernel. Adding up all the possible homomorphisms from $S_3$ to $S_4$ that we counted, we get 14 different ways in which $S_3$ can act on four elements, as described above. Is this correct ? Are there 14 homomorphisms from $S_3$ to $S_4$? Is my reasoning correct? Or are there any hidden assumptions I made that I shouldn't have made?","['permutations', 'group-theory', 'abstract-algebra']"
218529,Are two identical sets each other's subsets / supersets?,"Given two sets: $a = \{1,2,3\} $ $b=\{1,2,3\}$ Are they supersets of each other? Are they subsets of each other?",['elementary-set-theory']
218532,"Why the spectral theorem is named ""spectral theorem""?","""If $V$ is a complex inner product space and $T\in \mathcal{L}(V)$. Then $V$ has an orthonormal basis Consisting of eigenvectors of T if and only if $T$ is normal"". I know that the set of orthonormal vectors is called the ""spectrum"" and I guess that's where the name of the theorem. But what is the reason for naming it?",['linear-algebra']
218571,Is $\{g \in G : |g| < \infty\}$ always subgroup of a group $G$? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: $T(G)$ may not be a subgroup? Let $G$ be a group, and consider $H = \{g \in G : |g| < \infty\}$. Question : Must $H$ necessarily be a subgroup of $G$? Here, $|g|$ denotes the order of the element $g$.","['group-theory', 'abstract-algebra']"
218580,"What are the analytic isomorphisms of $\Omega = \mathbb{C} \setminus \{p_1,\ldots,p_n\}$?","By an analytic isomorphism of $\Omega$, I mean an analytic function $\Omega \to \Omega$, with an analytic inverse.","['analyticity', 'complex-analysis']"
218584,Continuously Differentiable Curves in $\mathbb{R}^{d}$ and their Lebesgue Measure,"Show that the image of the curve $\Gamma\in\mathscr{C}^{1}\left([a,b]\to\mathbb{R}^{d}\right)$ has d-dimensional Lebesgue measure zero (of course, $d\geq2$). This can be proved using the absolute continuity of $\Gamma'$ (since $[a,b]$ is compact and $\Gamma'$ is assumed continuous, hence in $L^{1}([a,b])$) together with the fundamental theorem of calculus to obtain an $\epsilon$-small cover of $\Gamma$ by balls. But I am trying to prove this using more elementary means (i.e. without integration).  Intuitively, since $\Gamma$ is smooth, we ought to (for fine enough partitions) be able to cover $\Gamma$ by boxes which arise from its tangent line.  And by taking the partition of $[a,b]$ to be finer and finer, the ""tangent box"" cover ought to also get smaller and smaller. More rigorously, the vector-version of the mean value theorem can be applied:
$$|\Gamma(t_{i-1})-\Gamma(t_{i})|\leq(t_{i}-t_{i-1})|\Gamma'(t_{i}^{\star})|\leq M_{i}\Delta t$$
where $t_{i}^{\star}\in(t_{i-1},t_{i})$ and $M_{i}=\sup_{t\in[t_{i-1},t_{i}]}|\Gamma'(t)|$ which exists and is finite since $\Gamma'$ is continuous. But to me, it's not quite clear how to rigorously construct a cover by boxes from here. NOTE: In the proof I mentioned (using integration), essentially you sum the left hand side over all partition intervals of uniform length $\delta$ (which depends on the $\Gamma'$), and ""integrate"" the right hand side. Actually, to be more specific, for each $\epsilon>0$ there exists a $\delta>0$ such that $||P||<\delta$ implies $\int_{t_{i-1}}^{t_{i}}|\Gamma'(t)|dt<\epsilon$ (e.g. absolute continuity).  This allows you to define numbers $\epsilon_{i}=\sup_{t,\bar{t}\in[t_{i-1},t_{i}]}|\Gamma(t)-\Gamma(\bar{t})|\leq\epsilon$ so that $\sum_{i=1}^{\#P}\epsilon_{i}\leq||\Gamma'||_{L^{1}([a,b])}$.  Then you can use these $\epsilon_{i}$ to put balls at each point $\Gamma(t_{i})$ of radius (say) $2\epsilon_{i}$, thus giving you an $\epsilon$-small cover.  Again though, this is harder to establish without integration theory.","['measure-theory', 'analysis']"
218611,Weak star closedness in dual space,"Let $(X, \|.\|)$ be a Banach space and $(X^*, \|.\|_{X^*})$ its dual space. Suppose that $E^*$ is convex and closed in the norm topology of $X^*$. Suppose that $X$ is not reflexive, I would like to ask whether $E^*$ is weak$^*$ closed in $X^*$.",['functional-analysis']
218623,Why continuous paths implies smooth path on the manifold?,"On the page 32 of Lee's book Manifolds and differential geometry , he writes: In the definition of path connectedness..., we used continuous paths, but it is not hard to show that if two points on a smooth
  manifold can be connected by a continuous path, then they can be
  connected by a smooth path. I do not quite understand. First of all, what does a path being smooth mean? A path on a manifold is a function:
$$
p:[0,1]\rightarrow M
$$ I think to be continuous is in the topological sense. But what does smooth mean? Is it in the diffeomorphic sense? Do we regard $[0,1]$ as a set in the manifold $\mathbb{R}$ and applying the definition of smoothness of function between manifolds? After all, I wonder how to prove this statement.",['differential-geometry']
218653,Understanding the assumptions in the Reverse Fatou's Lemma,"Fatou's Lemma says the following: If $(f_n)$ is a sequence of extended real-valued, nonnegative, measurable functions defined on a measure space $\left(\mathbf{X},\mathcal{X},\mu\right)$, then
  $$
\int\lim\inf f_n d\mu \leq \lim\inf \int f_n d\mu.
$$ In the statement of the Reverse Fatou's Lemma there's an addtional requirement that the given sequence be dominated by an integrable function.  I'm interested in understanding what breaks down if this condition is not satisfied.  For the sake of clarity and notation, here's the statement of the Reverse Fatou's Lemma: Let $(f_n)$ be a sequence of extended real-valued functions defined on a measure space $\left(\mathbf{X},\mathcal{X},\mu\right)$.  If there exists an integrable function $g$ on $\mathbf{X}$ such that $f_n \leq g$ for all $n$, then
  $$
\lim\sup\int f_n d\mu \leq \int\lim\sup f_n d\mu.
$$ Again, I'm curious to know what happens if this additional condition that the sequence be dominated is not satisfied.  In the proofs that I've seen of the Reverse Fatou's Lemma they've all taken advantage of the fact that the functions are dominated, but I just don't see why there can't be a proof of the inequality that doesn't use this assumption. My interest was further piqued by the following problem I came across in Bartle's Elements of Integration and Lebesgue Measure: Let $(f_n)$ be a sequence of extended real-valued, nonnegative functions defined on $\left(\mathbf{X},\mathcal{X},\mu\right)$, $f_n \to f$, and let $\int f d\mu =\lim \int f_n d\mu < \infty.$  Show that for any $E \in \mathcal{X},$ $$\int_E f d\mu =\lim \int_E f_n d\mu.$$ I was able to prove this through two applications of Fatou's Lemma and use of the nice identity $\lim\sup(-f_n) =-\lim\inf(f_n)$.  But there was another proof I abandoned after I failed to prove that the Reverse Fatou's Lemma held with the given hypotheses. Any insight is much appreciated.","['measure-theory', 'integration', 'real-analysis']"
218674,Ratio of Boys and Girls,"In a country where everyone wants a boy, each family continues having babies till they have a boy. After some time, what is the proportion of boys to girls in the country? (Assuming probability of having a boy or a girl is the same)",['probability']
218676,dense subspace of $ c_0( \mathbb N)$,Prove that $$Y= \left\{ x=(x_n)_{n \in\mathbb{N}} \in c_{0}(\mathbb N )~ \Bigg | ~\sum_{n=1}^{\infty} x_n = 0 \right\}$$ is a dense linear subspace of $ c_0( \mathbb N)$. where $ \displaystyle{c_0( \mathbb N) = \left\{  x=(x_n)_{n \in\mathbb{N}} \in \mathbb R ^{\mathbb N} : \lim_{n \to \infty} x_n =0 \right\}}$ I cannot prove that it is dense. Any help? Thank you in advance!,['functional-analysis']
218691,Chances of avoiding the diagonal,"A circle of radius 1 is randomly placed in a rectangle $ABCD$ so that the circle lies completely inside the rectangle. Length and breadth of rectangles are 36 and 15 respectively. Let the probability that the circle will not touch diagonal $AC$ be $\dfrac mn$.
Here $m$ and $n$ are relatively prime positive integers. Find the value of $m + n$. I think this can be done by calculating area . 
But I am unable to get it how.
Also the diagonal length will be 39 . How can I achieve this?","['geometry', 'probability', 'rational-numbers']"
218716,Probabilty of picking an irrational number,I've started to learn some probabilty and it made think about this question: let us assume we randomize virtually any number between 0 and 1. What is the probability for this number to be irrational?,['probability']
218721,Global dimension of quasi Frobenius ring,"Let $R$ be a quasi-Frobenius ring (so $R$ is self-injective and left and right noetherian). I want to prove that $lD(R)=0$ or $\infty$, where $lD(R)$ denotes the left global dimension. I'm unsure about how to go about proving this; the only thing I can think of is to somehow show that if we assume that some $R$ module $A$ has a finite projective resolution then it is in fact projective and hence has global dimension $0$. I tried to do this using the fact that a module over a quasi Frobenius ring is projective if and only if it is injective, but I didn't get far.","['homological-algebra', 'ring-theory', 'abstract-algebra', 'noetherian']"
218722,What is the limit of this function as $n$ tends to infinity?,"$\lim_{n\rightarrow\infty}\sqrt{n}\cos(\frac{\pi}{2}-\frac{1}{\sqrt{n}})$ I'm having a lot of trouble figuring it out.
My first step is always to convert $\cos(\frac{\pi}{2}-\frac{1}{\sqrt{n}})$ to  $\sin(-\frac{1}{\sqrt{n}})$ and then I get stuck here. Because I'm not quite sure where  $\lim_{n\rightarrow\infty}\sqrt{n}(-\sin(\frac{1}{\sqrt{n}})$ leads....:/ Please help. EDIT My Thomas' Calculus text book (12th Edition) lists the identity as being $$cos(A-\frac{\pi}{2}) = sin(A)$$ so naturally (or perhaps, naively?) I went ahead and took my A to be $-\frac{1}{\sqrt{n}}$","['trigonometry', 'calculus', 'real-analysis', 'limits']"
