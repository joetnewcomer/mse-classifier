question_id,title,body,tags
548118,"Distinction between a vector and a tensor of type (1,0)","Let's say I have a differentiable manifold $\mathscr{M}$. A vector $v$ on this manifold is a map from $\mathscr{F}$ to $\mathbb{R}$, where $\mathscr{F}$ is the set of all smooth functions from $\mathscr{M}$ to $\mathbb{R}$. A tensor of type (1,0) is a map from $V^{\ast}$ to $\mathbb{R}$, which we identify as a vector (because $V^{\ast\ast}$ is isomorphic to $V$). So how do we make this association, between a map that takes an element from $V^{\ast}$ and gives a number, to a map that takes an element from $\mathscr{F}$ and gives a number? Does that mean $V^{\ast}$ and $\mathscr{F}$ are isomorphic?","['manifolds', 'linear-algebra', 'differential-geometry']"
548127,Expansion of $ \frac{1}{|\vec r -\vec r'|} $,"I would like to show that:
$$ \frac{1}{|\vec r -\vec r'|} =\frac{1}{r} + \frac{\vec r'\cdot r'}{r^3}+\frac{3 ((\vec r \cdot \vec r)^2 -\vec r^2 \vec r'^2 )}{2r^5} +\dots$$ What I derived so far is:
$$\frac{1}{|\vec r -\vec r'|}= \sum_{n=0}^{\infty} \frac{1}{n!} (-\vec r' \cdot \nabla_r )^n \frac{1}{r} $$ The last part is however unclear to me, since I don't know how to rewrite, e.g. $(-\vec r' \cdot \nabla_r )$","['multivariable-calculus', 'calculus']"
548156,Does Proj induce some equivalence of categories involving graded rings?,"The opposite category of the category of rings is equivalent to the category of affine schemes, via the Spec functor. Is there a similar result if we consider the Proj construction, that takes a graded ring and returns some scheme? This is a question from a beginner in algebraic geometry, trying to understand how things fit together.",['algebraic-geometry']
548168,Relative sizes of Skorokhod and product topologies on space of sample paths,"Let $E$ denote a compact metric space. Let $T$ denote the non-negative reals. 
Let $E^T$ denote the class of all functions from $T$ to $E$. 
Let $C$ denote the subset of $E^T$ consisting of càdlàg functions (i.e. continuous from the right, limits exist from the left). On $C$ we can define the Skorokhod metric; and this metric induces the corresponding Borel sigma algebra. On the other hand, we have the usual product sigma algebra on the space $E^T$, and restricting this sigma algebra to $C$ in the natural way yields a second sigma algebra on the space $C$. My question is this: Is there any relation in size (with respect to inclusion) of these two sigma algebras defined on $C$. Many thanks for your help.","['stochastic-processes', 'skorohod-space', 'general-topology', 'measure-theory', 'probability-theory']"
548182,Help on three combinatorics questions?!,"I was having trouble on these combinatorics questions, would anyone be able to help? (P.S. I'm new to this forum, so bear with the editing - I know it sucks, but I tried to make it as readable as possible) $1a)$ How many ways are there to distribute 18 different toys among four children... i) Without restrictions ii) If two children get seven toys and two children get two toys? $1b)$ How many ways are there to distribute eight (identical) apples, six (identical) oranges, and seven(identical) pears among three different people... i) Without restrictions? ii) With each person getting at least one pear? $2)$ Suppose that 30 different computer games and 20 different toys are to be distributed among three different bags of Christmas presents. The first bag is to have 20 of the computer games. The second bag is to have 15 toys. The third bag is to have 15 presents, any mixture of games and toys. How many ways are there to distribute these 50 presents among the three bags? $3a)$ What fraction of all arrangements of EFFLORESCENCE has consecutive Cs and consecutive Fs, but no consecutive Es? $3b)$ Among all arrangements of WISCONSIN without any pair of consecutive vowels, what fraction have W adjacent to an I? My attempts: $1a)$ $i) 4^{18}$ $ii) \frac{18!}{2!\times2!}$ $1b)$ $i)\binom{8+3-1}{8}\times\binom{6+3-1}{6}\times\binom{7+3-1}{7} = \binom{10}{8}\times \binom{8}{6}\times\binom{9}{6}$ $ii)$ $\binom{8+3-1}{8}\times\binom{6+3-1}{6}\times(7\times6\times5)\times\binom{4+3-1}{4} = \binom{10}{8}\times\binom{8}{6}\times210\times\binom{6}{4}$ $2) {30P20}\times{20P 15}$ $3a)$ total $ = \frac{13!}{4!2!2!}$ with restrictions = $\binom{3+5-1}{3}\times{6!} = \binom{7}{3}\times 6!$ fraction $= \frac{\text{with restrictions}}{\text{total}} = \frac{1}{2574}$ $3b)$ total = $\frac{3!}{2!1!}\times\frac{6!}{2!2!}\times\binom{7}{3}$ with restrictions $= \frac{6!}{2!2!}\times\left(\binom{5}{3}+\binom{2}{1}\right)$ answer = total - with restrictions I'm not sure that I'm doing it correctly. I can explain any of my answers as needed. Detailed and good explained answers would be very much appreciated!","['solution-verification', 'combinatorics']"
548232,How to calclulate a derivate of a hypergeometric function w.r.t. one of its parameters?,"Is it possible to take a derivative of a hypergeometric function w.r.t. one of its parameters and express it in a closed form? I am particularly interested in this case:
$$\large\left[\frac{d}{da}{_2F_1}\left(1/2,\,a;\,3/2;\,-1\right)\right]_{a=2}$$","['closed-form', 'special-functions', 'calculus', 'hypergeometric-function', 'derivatives']"
548233,How does one make real functions a differentiable field?,"If you want to apply the results of differential field theory to actual $\Bbb R\to\Bbb R$ functions, then first of all you have to find operations that make these functions a field. The trouble is that with the standard definition of function multiplication, many functions don't have inverses. You can't really say that the inverse of $x$ is $1/x$, because strictly speaking $x\cdot(1/x)$ is only defined on $\Bbb R - \{0\}$. I imagine the answer is to define multiplication as first multiplying in the traditional sense, and then completing by continuity, but I can't quite work out the details, and either way, I'd like to know what the conventional way of doing it is. Exactly what set of real functions are usually treated as differential fields? The set of differentiable functions defined on all but a set of isolated points of $\Bbb R$? The set of differentiable functions defined on a set dense in $\Bbb R$? What field might we work with if we were trying to prove Liouville's theorem? How is multiplication defined on that (those) field(s)?","['differential-field', 'analysis']"
548252,Cardinality of set-Discrete math,"Take $A=\{1,2,3\}$ and $B=\{1,2,5\}$. If we unionized them together it would be $A\cup B=\{1,2,3,5\}$ and if we intersected them it would be $A\cap B=\{1,2\}$. However, if we change $B$ to $B=\{\{1,2\},2,5\}$ would a set within a set change the previous answers and why?","['discrete-mathematics', 'elementary-set-theory']"
548321,"Is there always a prime number in the form of $4k+1$ between $[n, 2n]$ for every large enough $n$?","Is there always a prime number in the form of $4k+1$ between $[n, 2n]$ for every large enough $n$? I guess it is known as a classical result. Is there any reference for it? Thanks!","['prime-numbers', 'number-theory']"
548339,Did I take the derivative correctly? $x^y=y^x$,"Need to differentiate following equation:
$$x^y=y^x$$
My attempt:
$$x^y\log(x) \cdot y' = y^x\log(y)\cdot1;  $$
$$y'=\frac{y^x\log(y)}{x^y\log(x)}$$
Please tell me if I've made a mistake.","['derivatives', 'real-analysis', 'solution-verification']"
548355,Commutativity of iterated limits,"The following is a weird result I've obtained with iterated limits.
There must be a flaw somewhere in someone's reasoning but I can't discover what it is. 
The problem is that, in general, iterated limits are not supposed to be commutative. However, the purported proof below seems to indicate that they always are.
Did I make a mistake somewhere? Let $F$ be a real valued function of two real variables defined in
some region around $(a,b)$. Then the standard limit [ correct? ] of $F$ as $(x,y)$ approaches $(a,b)$ equals $L\,$ if and only if
for every $\epsilon > 0$ there exists $\delta > 0$ such that $F$ satisfies:
$$
  | F(x,y) - L | < \epsilon
$$
whenever the distance between $(x,y)$ and $(a,b)$ satisfies:
$$
  0 < \sqrt{ (x-a)^2 + (y-b)^2 } < \delta
$$
We will use the following notation for such limits of functions of two
variables:
$$
   \lim_{(x,y)\rightarrow (a,b)} F(x,y) = L
$$
Note. At this moment, we do not wish to consider limits where (one of) the independent
variable(s) approaches infinity. Next we consider the following iterated limit:
$$
  \lim_{y\rightarrow b} \left[ \lim_{x\rightarrow a} F(x,y) \right] = L
$$ Theorem. Commutativity of iterated limits.
$$
  \lim_{y\rightarrow b} \left[ \lim_{x\rightarrow a} F(x,y) \right] =
  \lim_{x\rightarrow a} \left[ \lim_{y\rightarrow b} F(x,y) \right] =
  \lim_{(x,y)\rightarrow (a,b)} F(x,y)
$$ Proof. We split the first iterated limit in two pieces:
$$
  \lim_{x\rightarrow a} F(x,y) = F_a(y)
$$
And:
$$
  \lim_{y\rightarrow b} F_a(y) = L
$$
Thus it becomes evident that the (first) iterated limit is actually defined as follows. For every $\epsilon_x > 0$ there is some $\delta_x > 0$ such that:
$$
  | F(x,y) - F_a(y) | < \epsilon_x \quad \mbox{whenever}
             \quad 0 < | x - a | < \delta_x
$$
For every $\epsilon_y > 0$ there is some $\delta_y > 0$ such that:
$$
  | F_a(y) - L | < \epsilon_y \quad \mbox{whenever}
             \quad 0 < | y - b | < \delta_y
$$
Applying the triangle inequality $|a| + |b| \ge |a + b|$ gives:
$$
  | F(x,y) - F_a(y) | + | F_a(y) - L | \ge | F(x,y) - L |
$$
Consequently:
$$
  | F(x,y) - L | < \epsilon_x + \epsilon_y
$$
On the other hand we have:
$$
   0 < | x - a | < \delta_x \qquad \mbox{and} \qquad 0 < | y - b | < \delta_y
$$
Hence:
$$
    0 < \sqrt{ (x-a)^2 + (y-b)^2 } < \sqrt{ \delta_x^2 + \delta_y^2 }  
$$
This is exactly the definition of the above standard limit of a function of two
variables if we put:
$$
\epsilon = \epsilon_y + \epsilon_y \qquad \mbox{and} \qquad \delta = \sqrt{\delta_x^2 + \delta_y^2}
$$
Therefore:
$$
  \lim_{y\rightarrow b} \left[ \lim_{x\rightarrow a} F(x,y) \right] =
  \lim_{(x,y)\rightarrow (a,b)} F(x,y)
$$
In very much the same way we can prove that:
$$
  \lim_{x\rightarrow a} \left[ \lim_{y\rightarrow b} F(x,y) \right] =
  \lim_{(x,y)\rightarrow (a,b)} F(x,y)
$$
QED","['functions', 'real-analysis', 'limits']"
548358,"Is the number $333{,}333{,}333{,}333{,}333{,}333{,}333{,}333{,}334$ a perfect square?","I know that if the number is a perfect square then it will be congruent to $0$ or $1$ (mod $4$).  Now since the number is even, I know that it is either $0$ or $2$ (mod $4$).  How would I go about answering this?","['discrete-mathematics', 'divisibility', 'modular-arithmetic', 'elementary-number-theory', 'congruences']"
548375,"$X=\{a,b,c\}$ and $\mathcal{T}=\{X, \emptyset, \{a\}, \{b\}, \{a,b\}\}$. Determine if $f:X \rightarrow X$ is $\mathcal{T}-\mathcal{T}$ Continuous","$X=\{a,b,c\}$ and $\mathcal{T}=\{X, \emptyset, \{a\}, \{b\}, \{a,b\}\}$. Assume $f: X \rightarrow X$ is given by $f(a)=a, f(b)=c,$ and $f(c)=b.$ Determine if $f:X \to X$ is $\mathcal{T}-\mathcal{T}$ continuous What I got: For $f$ to be continuous, then for each $\mathcal{T}$-open subset $V$ of $X,$ $f^{-1}(V)$ is a $\mathcal{T}$-open subset of $X$. Since $f:(X,\mathcal{T}) \to (X,\mathcal{T})$, then $\{b\}$ is an open set but $f^{-1}(\{b\})=\{c\}$ which is not an open since $\{c\}$ $\notin \mathcal{T}$ Thus $f$ is not continuous. Does that sound correct?","['general-topology', 'proof-verification']"
548395,radical of I is the entire ring R implies I=R?,"Can anyone prove that:
radical of I (ideal) is the entire ring R implies I=R?
The ring has a unit and commutative.
Thanks...","['ring-theory', 'abstract-algebra']"
548403,Number Theory: Solutions of $ax^2+by^2\equiv1 \pmod p$,"Assume $p$ is a prime number and $\gcd(ab, p)=1$. Show that the number of integer solutions $(x, y)$ of $ax^2+by^2 \equiv 1 \pmod p$ is
  $$p - \left(\dfrac{-ab}{p}\right)$$ where $\left(\dfrac{x}{y}\right)$ is the Legendre symbol. Ok, so here's my partial solution to the above question. Suppose that $-ab$ is a quadratic residue of $p$, then $-ab\equiv c^2 \pmod p$ for some $c$. Then $(ax)^2+aby^2\equiv(ax)^2-(cy)^2\equiv a \pmod p$ by multiplying both sides by $a$. Then $(ax+cy)(ax-cy)\equiv a \pmod p$. Considering every possibility, it is not hard to see that there are $p-1$ solutions $(x, y)$ for the equation. The problem is that I couldn't figure out how to prove this when $-ab$ is a quadratic nonresidue. And even the solution I had shown to you is not truly mine; I got some help from my peers. So I was wondering if there is a simpler solution to this question that includes the case when $-ab$ is a quadratic nonresidue. Nevertheless, I would also be really glad if someone could show me how to treat the nonresidue case separately. Thanks!","['quadratic-reciprocity', 'elementary-number-theory', 'congruences', 'number-theory']"
548417,Dyck paths with $k$ peaks,"There are $n$ $1$'s and $n$ $0$'s.
We have to arrange them in a row such that at no position in this row the number of $0$'s from the beginning exceed the number of $1$'s from the beginning.
Also the number of occasions when a $1$ is immediately followed by a $0$ should be exactly $k$.
In how many ways can they be arranged?","['catalan-numbers', 'combinatorics']"
548431,How to find the height of a 2D coordinate on a four-sided 3D polygon plane?,"How do I find the height of a given 2D coordinate on a four-sided 3D polygon plane? The polygon has no volume. I'm trying to match 3D terrain vectors to a 3D polygon. I'll always know that the 2D version of the 3D poly contains the 2D coordinate, but I need to get the height at that 2D coordinate on the polygon surface. How can I figure out the height of point F1 in the image example?",['geometry']
548467,Serre duality as a right adjoint functor,"As stated on the wikipedia page , Grothendieck generalized Serre duality by stating that there exists a right adjoint functor $f^!$ to the functor $Rf_!$ when one works within the correct category. Serre Duality [Hartshorne]: Let $X$ be a projective scheme of dimension $n$ over an algebraically closed field $k$. Let $\omega_X^\circ$ be the dualizing sheaf on $X$. Then for any coherent sheaf $\mathcal{F}$ on $X$, there are natural functorial maps $$\theta^i : \operatorname{Ext}(\mathcal{F}, \omega_X^\circ) \rightarrow H^{n-i}(X, \mathcal{F})'.$$ How can one recast the above theorem in terms of an adjoint functor?","['algebraic-geometry', 'duality-theorems']"
548476,Formula for determinant of block matrix with commuting blocks,"On Wikipedia , I saw the following formula $$\det\begin{bmatrix}A & B\\ C & D\end{bmatrix} = \det(AD-BC)$$ if $C$ and $D$ commute. Is this always true? Or is there a good counter example for each $2 \times 2$ block matrices?","['matrices', 'block-matrices', 'determinant']"
548477,How much math do we need to prove all simple numeric identities?,"Consider real numeric expressions build only from integers, operators $+,-,\times,/$ and taking a positive expression to a power (no variables involved), e.g.
$$\frac{2}{7},\ 2^{1/2},\ \sqrt[5]{2+\sqrt{11}},\ 2^{\sqrt{3}},\ ...$$
Now we can write identities between such expressions that are either true, e.g. $\sqrt{3+\sqrt{8}}=1+\sqrt{2}$, or false, e.g. $\frac{3}{5}=\frac{2}{7}$. Is it possible to prove all such true identities and disprove all false identities using only usual ""high-school"" algebra rules?","['logic', 'axioms', 'algebra-precalculus', 'elementary-functions']"
548511,find the general integrals of the given P.D.E,"I tried to find the general integrals of the given P.D.E in the yellow box. And I found $c_1$. But I cannot find another one, say $c_2$. Please help me finding $c_2$. Thank you. $$\color{#F3D159}{\boxed{\displaystyle\,\,\color{black}{px(z-2y^2)=(z-9y)(z-y^2-2x^3)}\,\,}} \\ \begin{gather*}
P=x(x-2y^2)\\
Q=+y(z-y^2-2x^3)\\
R=z(z-y^2-2x^3)
\end{gather*}\\\frac{\mathrm dx}{x(z-2y^2)}=\frac{\mathrm dy}{+y(z-y^2-2x^3)}=\frac{\mathrm dz}{z(z-y^2-2x^3)}\\\frac{\mathrm dy}y=\frac{\mathrm dz}z\implies\ln y=\ln z+\ln c_1\\\boxed{ \frac y z = c_1}$$","['ordinary-differential-equations', 'self-learning', 'partial-differential-equations']"
548514,Could someone explain me the significance of Brouwer's Fixed Point Theorem?,"Well, I've been reading the proof of Sperner's Lemma and its use in proving Brouwer's Fixed Point Theorem (including the Coffee stiffing analogy ;-)). But I fail to understand the significance of this theorem. Could someone explain me how it can be applied in other important applications?","['general-topology', 'combinatorics']"
548520,Show that $\frac{|F(z)-F(a)|}{|F(z)-\bar{F(a)}|}\le\frac{|z-a|}{|z-\bar{a}|}$ if $z\in\Pi^{+}=\{z\in\mathbb{C}:Im(z)>0\}$,"Consider $\Pi^{+}=\{z\in\mathbb{C}:Im(z)>0\}$ and let $a\in\Pi^{+}$. Suppose that $F:\Pi^{+} \rightarrow \Pi^{+}$ is holomorphic. Prove that for all $z\in\Pi^{+}$ we have:
$$\frac{|F(z)-F(a)|}{|F(z)-\bar{F(a)}|}\le\frac{|z-a|}{|z-\bar{a}|}$$
Also, show that:
$$|F´(z)|\le\frac{Im(F(a))}{Im(a)}$$","['complex-numbers', 'complex-analysis']"
548525,How to compute the sum of random variables of geometric distribution,"Let $X_{i}$, $i=1,2,\dots, n$, be independent random variables of geometric distribution, that is, $P(X_{i}=m)=p(1-p)^{m-1}$. How to compute the PDF of their sum $\sum_{i=1}^{n}X_{i}$? I know intuitively it's a negative binomial distribution $$P\left(\sum_{i=1}^{n}X_{i}=m\right)=\binom{m-1}{n-1}p^{n}(1-p)^{m-n}$$ but how to do this deduction?","['probability-distributions', 'probability', 'random-variables']"
548528,On odd perfect numbers $N$ given in the Eulerian form $N = {q^k}{n^2}$,"Note: This question was cross-posted from MO . Preamble:  I apologize in advance if this particular MSE post would appear to be a bit of a polymath approach, I just had to put down all the details to present my argument for this particular math problem. A positive integer $N$ is said to be perfect if $\sigma(N)=2N$, where $\sigma(x)$ is the sum of the divisors of $x$. An odd perfect number $N$ is said to be given in Eulerian form if $N = {q^k}{n^2}$, where $q$ is prime, $q \equiv k \equiv 1 \pmod 4$ and $\gcd(q,n)=1$. Since $\gcd(q,n)=1$ and prime powers are deficient, we have $q \neq n$ and $q^k \neq n$. In an earlier version of the paper The Abundancy Index of Divisors of Odd Perfect Numbers (see here ), it was conjectured that the biconditional $$q^k < n \Longleftrightarrow \sigma(q^k) < \sigma(n) \Longleftrightarrow \frac{\sigma(q^k)}{n} < \frac{\sigma(n)}{q^k}$$ is true.  (Note that the proof of the inequation $$\frac{\sigma(q^k)}{n} \neq \frac{\sigma(n)}{q^k}$$ is trivial.) Recently, an attempt to prove the said biconditional appears to have been completed in this preprint . I present here the highlights of the said proof: One direction of the biconditional is trivial: $$q^k < n \Longrightarrow \frac{\sigma(q^k)}{n} < \frac{\sigma(n)}{q^k}.$$ This is proved by noting that $I(q^k) < \sqrt[3]{2} < I(n)$ (where $I(x) = \sigma(x)/x$ is the abundancy index of $x$), from which the following chain of implications follow: $$q^k < n \Longrightarrow \sigma(q^k) < \sigma(n)$$
    $$q^k < n \Longrightarrow \frac{1}{n} < \frac{1}{q^k}$$
    $$\{\sigma(q^k) < \sigma(n)\} \land \{\frac{1}{n} < \frac{1}{q^k}\} \Longrightarrow \frac{\sigma(q^k)}{n} < \frac{\sigma(n)}{q^k}$$ Therefore: $$q^k < n \Longrightarrow \sigma(q^k) < \sigma(n) \Longrightarrow \frac{\sigma(q^k)}{n} < \frac{\sigma(n)}{q^k}.$$ For the other direction: The implication $$\frac{\sigma(q^k)}{n} < \frac{\sigma(n)}{q^k} \Longrightarrow \sigma(q^k) < \sigma(n)$$
    can be proved, again by observing that $I(q^k) < \sqrt[3]{2} < I(n)$. Now, to prove the last implication: $$\sigma(q^k) < \sigma(n) \Longrightarrow q^k < n$$ we take an indirect approach. First we show that: If $N = {q^k}{n^2}$ is an odd perfect number given in Eulerian form and $$I(q^k) + I(n) < \frac{\sigma(q^k)}{n} + \frac{\sigma(n)}{q^k},$$ then $q^k < n \Longleftrightarrow \sigma(q^k) < \sigma(n)$. Similarly, we can prove that: If $N = {q^k}{n^2}$ is an odd perfect number given in Eulerian form and $$\frac{\sigma(q^k)}{n} + \frac{\sigma(n)}{q^k} < I(q^k) + I(n),$$ then $q^k < n \Longleftrightarrow \sigma(n) < \sigma(q^k)$. Observe that $$I(q^k) + I(n) = \frac{\sigma(q^k)}{n} + \frac{\sigma(n)}{q^k}$$ if and only if $$\sigma(q^k) = \sigma(n).$$ Also, observe that if we assume $$\frac{\sigma(q^k)}{n} + \frac{\sigma(n)}{q^k} < I(q^k) + I(n)$$ then the biconditional $$q^k < n \Longleftrightarrow \sigma(n) < \sigma(q^k)$$ will contradict $I(q^k) < \sqrt[3]{2} < I(n)$. Therefore, the following inequality must be true: $$I(q^k) + I(n) \leq \frac{\sigma(q^k)}{n} + \frac{\sigma(n)}{q^k}.$$ It suffices to consider the case when $$I(q^k) + I(n) = \frac{\sigma(q^k)}{n} + \frac{\sigma(n)}{q^k}$$ which is true if and only if $$\sigma(q^k) = \sigma(n).$$ This last equation, together with the inequality $I(q^k) < \sqrt[3]{2} < I(n)$, implies that $$1 = \frac{\sigma(q^k)}{\sigma(n)} < \frac{q^k}{n}$$ from which it follows that $n < q^k$. Thus, $1/q^k < 1/n$, which then gives, together with the equation $\sigma(n) = \sigma(q^k)$, the inequality $$\frac{\sigma(n)}{q^k} < \frac{\sigma(q^k)}{n}.$$ But this last inequality, together with $I(q^k) < \sqrt[3]{2} < I(n)$, is known to imply $$n < q^k.$$ Consequently, if $$I(q^k) + I(n) = \frac{\sigma(q^k)}{n} + \frac{\sigma(n)}{q^k}$$ then $$n < q^k \Longleftrightarrow \frac{\sigma(n)}{q^k} < \frac{\sigma(q^k)}{n}$$ Now, here is the part where I am a bit unsure about logical solidity : Lastly, note that since $$\sigma(q^k) = \sigma(n)$$ implies $n < q^k$, the biconditional $$q^k < n \Longleftrightarrow \sigma(q^k) < \sigma(n)$$ is vacuously true, under this case. NOW HERE IS MY QUESTION (and this is also the main reason for this MSE post): I have been told that there is a gap in the last part of this proof.  As I
    myself am having a hard time spotting where that particular error is, would
    somebody be kind enough as to help by skimming through this argument and then 
    (after glossing over the details) give it either a PASS or a FAIL ?","['divisor-sum', 'perfect-numbers', 'proof-verification', 'number-theory']"
548538,Clarification on a proof involving cluster point,"Definition of cluster point- Let $A \subseteq \mathbb{R}$. A point $c\in\mathbb{R}$ is a cluster point of $A$ if for evert $\delta>0$ there exists at least one point $x\in A$, $x\neq c$ such that $|x-c|<\delta$. Theorem- A number $c\in\mathbb{R}$ is a cluster point of a subset $A$ of $\mathbb{R}$ iff there exists a sequence $(a_n)$ in A such that lim$(a_n)=c$ and $a_n \neq c$ for all $n\in\mathbb{N}$. I'm stuck on understanding the foward direction. Proof: $(\rightarrow)$""If $c$ is a cluster point of $A$ then for any $n\in\mathbb{N}$ the $\frac{1}{n}$-neighborhood $V_{\frac{1}{n}}(c)$ contains atleast one point $a_n\in A$ distinct from $c$. Then  $a_n\in A$, $a_n \neq c$, and $|a_n-c|<\frac{1}{n}$ implies  lim$(a_n)=c$."" What I understand is that if we let $\delta>0$ then it follows by the Archimdean property that there exists a $k\in\mathbb{N}$ such that $\frac{1}{k}<\delta$. It follows if $n\geq k$ then $\frac{1}{n}<\frac{1}{k}<\delta$. Since $c$ is a cluster point there exists a $x_{n}\in A$ where $x_{n}\neq c$ such that $|x_{n}-c|<\frac{1}{n}<\delta$ since $\frac{1}{n}>0$. Thus by the definition of convergence we have $lim (a_n)=c$. Would this be a correct way of understanding the proof to this theorem?","['real-analysis', 'analysis']"
548552,Manipulating quotients and direct sums of abelian groups,"I'm studying homology from Hatcher's Algebraic Topology . I feel that there is a gap in my group theory knowledge that is making me struggle with this chapter. In particular, the book (and material online) use the following without proof: If $A/B \cong C$ , where $A,B$ are abelian groups and $C$ is abelian and free, then $A \cong B \oplus C$ . If $\mathbb{Z}^n/A \cong \mathbb{Z}$ , then $A \cong \mathbb{Z}^{n-1}$ . These two seem very related. I'm looking for a proof that doesn't use exact sequences or Category Theory (not introduced in the book at that point yet). I know the fundamental theorem of finitely generated abelian groups, Sylow theorems, and the basics of ring theory (ideals, domains, CRM, etc). Basically, I read most of Artin's Algebra . Thank you.","['group-theory', 'abstract-algebra', 'abelian-groups']"
548554,One to one and bijection in $\mathbb{Z}^2$,"I have the following: $f(m,n) = (3m+7n, 2m+5n)$ and I want to know if it is a bijection and if so, fine the inverse as well. Here's my approach: Suppose $f(m_1,n_1)=f(m_2,n_2)$
then: $$ (3m_1+7n_1,2m_1+5n_1)=(3m_2+7n_2,2m_2+5n_2)$$
$$3m_1+7n_1=3m_2+7n_2 $$ and $$2m_1+5n_1=2m_2+5n_2$$ Now my issue begins here and don't know what the next step should be... Perhaps adding both equations? I'm not sure.",['functions']
548563,Calculate $\sum\limits_{k=0}^{\infty}\frac{1}{{2k \choose k}}$,Calculate $$\sum \limits_{k=0}^{\infty}\frac{1}{{2k \choose k}}$$ I use software to complete the  series is  $\frac{2}{27} \left(18+\sqrt{3} \pi \right)$ I have no idea about it.  :|,"['sequences-and-series', 'analytic-number-theory', 'calculus', 'number-theory']"
548568,Relation between standard deviation and mean in random processes,"In a Poisson distribution the square of the standard deviation $\sigma$ is equal to mean $\mu$ ($\sigma^2=\mu$) and in a binomial distribution $\sigma ^2=\mu\,(1-p)$ (with $p$ the probability of success). I wonder what relations exist between the mean and the standard deviation in other random processes. Does the standard deviation always increase with the mean? Are they always related or may be independent? Particular cases are also welcome.","['stochastic-processes', 'statistics', 'random-variables', 'standard-deviation', 'probability']"
548578,Changing operator to polar coordinates,"Let $$\Delta=\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}$$ be the Laplace operator on the $(x,y)$-plane. Consider the polar coordinates with $x=r\cos\theta$ and $y=r\sin\theta$. Show that $$\Delta=\frac{\partial^2}{\partial r^2}+\frac1r\frac\partial{\partial r}+\frac1{r^2}\frac{\partial^2}{\partial \theta^2}.$$ I don't know how to change the coordinates for an operator like this one. What is the method that should be used?","['polar-coordinates', 'calculus', 'partial-derivative']"
548587,"A quotient map from $[0,1]$ to $S^1$","I would like to show that the function $f(x) = (\textrm{cos}2 \pi x, \textrm{sin}2 \pi x)$ is a quotient map; I have already shown that it is surjective and continuous (the latter by invoking the universal property for functions into a product topology (I am considering $S^1$ as a subspace of $\mathbb{R} \times \mathbb{R}$)). However, I'm stuck trying to prove the final condition for $f$ to be a quotient map. Here's my work so far: Let $U \subset S^1$. Suppose $f^{-1}[U]$ is open in $[0,1]$. Then we need to show that $U$ is open in $S^1$. Let $\bar{y} \in U$; either $\bar{y} = (1,0)$ or $\bar{y} \neq (1,0)$. If $\bar{y} = (1,0)$, then by using the openness of $f^{-1}[U]$, we can deduce that there exists $\epsilon, \epsilon' \in \mathbb{R}_{> 0}$ such that $[0,\epsilon) \cup (\epsilon',1] \subset f^{-1}[U]$ (since $f^{-1}[\{ (1,0) \}] = \{0, 1 \}$). Similarly, if $\bar{y} \neq (1,0)$, there exist $\delta, \delta'\in \mathbb{R}_{> 0}$ such that $(\delta,\delta') \subset f^{-1}[U]$. Of course these sets, $[0,\epsilon) \cup (\epsilon',1]$ and $(\delta,\delta')$ are open in $[0,1]$. How do I (or can I) proceed from here to show that $U$ is open in $S^1$? On the other hand, I'd also love to hear of some more general methods for showing that the function is a quotient map (maybe certain theorems or something). Thanks in advance for the help!",['general-topology']
548589,Sum of reciprocals of primes factorial: $\sum_{p\;\text{prime}}\frac{1}{p!}$,"The series
$$\sum_{p\;\text{prime}}\frac{1}{p}=\frac{1}{2}+\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\frac{1}{11}+\cdots$$
diverges as is well known. How about the following?
$$\sum_{p\;\text{prime}}\frac{1}{p!}=\frac{1}{2!}+\frac{1}{3!}+\frac{1}{5!}+\frac{1}{7!}+\frac{1}{11!}+\cdots$$
Its convergence is easily obtained by comparing with the series $e=\sum_{n=0}^\infty\frac{1}{n!}$. Numerically, we get
$$\sum_{p\;\text{prime}}\frac{1}{p!}\simeq 0.675198$$
Can we find the specific value?","['prime-numbers', 'sequences-and-series']"
548594,Let $f : X \to Y$ be a function and $E \subseteq X$ and $F \subseteq X$. Show that in general,Let $f:X\to Y$ be a function and $E\subseteq X$ and $F\subseteq X$. Show that in general $f(E − F)\nsubseteq f(E) − f(F)$. I have no idea about how to prove this; and could anyone please explain the basic theory of functions(by relating to this question. Thank you.,"['functions', 'analysis']"
548597,How to prove: $-\frac{1}{\sec2x}=\frac{\cos^3x-\sin^3x}{\cos x +\sin x}+\frac{\cos2x}{(\cos x +\sin x)^2}$,"How do you do it?
I'm really stuck on this proof. Can someone please explain? Thanks","['trigonometry', 'algebra-precalculus']"
548621,Can the Poisson Distribution be used to find the expected value of time of arrival given an expected arrivals per unit time?,"My understanding of the Poisson Distribution is that its PMF $P(x=k) = \dfrac {\lambda^k e^{-\lambda}} {k!}$ refers to the probability of finding k events given an expected arrival expectancy $\lambda$. This gives me, rather trivially, that the expected value for the number of arrivals is equal to the average number of arrivals $\lambda$. However, suppose I know $\lambda$ is 3 events per day. How can I calculate the expected number of days before $n$ events happen? Can I just invert my $\lambda$, so that my units are now days/event, and use the same distribution? A supplemental question: Currently, the units in my exponent appears to be events/time. Shouldn't I have to multiply by some time $t$, so that the distribution looks like $P(x=k) = \dfrac {(\lambda t)^k e^{-\lambda t}} {k!}$? (I'm taking ""events"" to be unitless...) If so, I would expect my new distribution to be $P(t=k) = \dfrac {(\frac n {\lambda})^{k} e^{ \frac {-n} {\lambda}}} {k!}$, where $n$ is the number of events, $k$ is the amount of time, and $\lambda$ is still in events/time. Thus if, in the above example, I want to know the probability that it would take 1 day for 5 arrivals, I would set $k$ = 1, $n$ = 5, and $\lambda$ = 3. Is there anything wrong with this formulation?",['probability']
548631,Finding the Hopf Algebra Coproduct coming from an Affine Group Scheme,"I was wondering if anyone could help with how to, strictly from Yoneda's Lemma, obtain the coproduct map on the Hopf Algebra for an Affine Group Scheme. Particularly for something like $\text{SL}_2$ So if $G=\text{SL}_2$, let  $m:G \times G \to G$ be the multiplication map. Yoneda'e lemma tells us that this induces a map $\Delta:A \to A \otimes A$ and there is a specific construction: $m: G\times G(A \otimes A) \to G(A \otimes A)$ which (since $G$ is representable is just a map $\text{Hom}(A \otimes A, A \otimes A) \to \text{Hom}(A, A \otimes A)$ and element-wise $id$ gets sent to $\Delta$. This is hypothetically how you should ""find"" $\Delta$. In the case of $\text{SL}_2$ I guess the part I am having trouble with is finding the corresponding element in $G\times G(A \otimes A)$ that goes with $id$. That way I can just do the multiplication map and see what the entries are to get the $\Delta$ map.","['algebraic-geometry', 'algebraic-groups']"
548633,transition kernel,"I've got some trouble with transition kernels. We look at Markov process with statspace $(S,\mathcal{S})$ and initial distribution $\mu^0$. We have a transition kernel $P:S\times \mathcal{S}\to[0,1]$ Now I have to show that $P^n(x,B):=\int_{S}P^{n-1}(y,B)P(x,dy)$ for $n\geq 2$ and $P^1:=P$ is also a transition kernel. How do I proof that $P^n$ is measuable for every fixed $x\in S$? can I write $\int_{S}P^{n-1}(y,B)P(x,dy)=\int_{S}P^{n-1}(y,B)dP(x,y)$ and now look at the measurable function $f(x):=1_{A_1\times A_2}$ so I have $f(x)P^{n-1}(y,B)P(x,dy)$ is measurable. I take a family $f_n$ of elementary functions with $f_n\to f$ for $n\to\infty$. I'm not realy sure, measure theory wasn't my best course. And I hope that anyone is able to understand me, because I'm not realy able to write english in a nice way.","['probability-theory', 'stochastic-processes', 'measure-theory', 'markov-process']"
548640,Any continuous group homomorphism $\mathbb{R}\to \mathbb{R}^n$ is $C^\infty$,"Show that any continuous homomorphism $\mathbb{R}\to \mathbb{R}^n$, with respect to the usual abelian group structure, is actually $C^\infty$. My attempt: Let $\varphi$ be such a map. $$\lim_{h\to 0}\frac{\varphi(x+h) - \varphi(x)} {h} = \lim_{h \to 0} \frac{\varphi (h)}{h},$$ so if $\varphi'$ exists, it is constant on $\mathbb{R}$, and it is sufficient for it to exist at zero. Now note that $h\mapsto \frac{\varphi(h)}{h}$ is continuous for $h \neq 0$ since it is the product of a continuous scalar-valued function and a continuous vector-valued function. Now $$ \frac {\varphi \left(\frac{h}{m/n} \right ) } {\frac{h}{m/n}} = \frac{(n/m)\varphi(h)}{\frac{h}{m/n}} = \frac{\varphi(h)}{h}, \;\;\; m,n \in \mathbb{Z}$$ so $h\mapsto \frac{\varphi(h)}{h}$ is constant on $\mathbb{Q}$. Since it is continuous, it is constant on $\mathbb{R}$, and it has a limit at zero. I would appreciate it if you could let me know if there are parts of the argument I could explain better, or point out any errors.","['calculus', 'group-theory', 'proof-verification']"
548665,Is Euclid's Fourth Postulate Redundant?,"Euclid's Elements start with five Postulates, including the fifth one, the famous Parallel Postulate .  Less well, known however is the Postulate that forms the basis for motivation behind the fifth: the fourth one , which states that ""all right angles are equal.""  Students who see this for the first time might find this puzzling, because obviously two angles which are equal to a 90 degree angle are equal to each other, since Common Notion 1 says that ""things which are equal to the same thing are are also equal to one another"".  But then they realize that the matter is so straightforward: the definition of a right angle is an angle produced when two lines intersect each other and produce equal adjacent angles, and it's not clear why an angle produced by one such pair of lines should bear any relation to an angle produced by another such pair of lines. So Euclid's fourth Postulate is not redundant for the reason that beginning students might think.  But my question is, is it nevertheless a redundant postulate, although for far less trivial reasons?  David Hilbert, in his Foundations of Geometry (Grundlagen der Geometrie in German), claims to prove Euclid's fourth Postulate in theorem 15 (on page 19 of the PDF or page 13 according to the book's internal page numbering), prefacing the proof by saying ""it is possible to deduce the following simple theorem, which Euclid held - although it seems to me wrongly - to be an axiom."" Now it's fair to say that Hilbert was working in a different (and more rigorous) system of axioms than Euclid was, but I think Hilbert's proof should be seriously considered for two reasons.  First of all, why would he dub Euclid's decision to call ""all right angles are equal"" a Postulate as ""wrong"" if it merely reflected a stylistic difference concerning what you choose as starting assumptions and what you consider theorems?  But more importantly, by tracing back all the assumptions used in the proof of theorem 15, it seems to me that only four of Hilbert's axioms are ultimately used: IV 3, IV 4, IV 5, and IV 6.  And I don't think Euclid would have objected to any of these statements: IV 3 follows directly from Euclid's Common Notion 2. IV 4 is partly stated in Euclid's Book I Proposition 23 , which doesn't depend on the fourth postulate, and the part of IV 4 which (I think) is not stated is easily provable in Euclid's system. IV 5 follows from Euclid's Common Notion 1 . IV 6 is just part of Euclid's Book I Proposition 4 , which doesn't depend on the fourth postulate at all. So could Euclid have proven his fourth Postulate as a theorem instead of just assuming it? Any help would be greatly appreciated. Thank You in Advance. EDIT: It seems to me that the key idea driving Hilbert's proof is that Euclid's Book I Proposition 4, i.e. the Side-Angle-Side (SAS) congruence theorem, implies that the supplements of equal angles are equal.  Can anyone confirm or deny that this implication is in fact valid, and if it is valid, that the conclusion can be used to show that all right angles are equal?","['geometry', 'math-history', 'axioms', 'proof-verification', 'euclidean-geometry']"
548669,Determinant of block matrices with non-square blocks,"Let $A$ be $m \times n$ matrix, and $B$ be $n \times m$ matrix. Then Show that $$\det\begin{bmatrix}I_{n} & B\\ A & I_{m} \end{bmatrix}=\det\begin{bmatrix}I_{m} & A\\ B & I_{n}\end{bmatrix}$$ Show that $$\det(I_{m}-AB)=\det(I_{n}-BA)$$ Is it true that $I_{m}-AB$ and $I_{n}-BA$ have the same rank? Someone please show me a way to start proving. I tried to use formulas for calculating block matrix with square matrices, but it didn't help me on this one. I really don't know where to start.","['matrix-rank', 'matrices', 'linear-algebra', 'block-matrices', 'determinant']"
548681,Simply connected does not imply contractible. Is there a nice counter example in $R^2$?,"The standard counter example to the claim that a simply connected space might be contractible is a sphere $S^n$, with $n > 1$, which is simply connected but not contractible. Suppose that I were interested in a counter example in the plane - does anyone know of a subset of $R^2$ which is simply connected but not contractible?","['general-topology', 'examples-counterexamples', 'algebraic-topology']"
548689,Is there a continuous function $f$ from {$x\in \mathbb{R}^n :||x||\le 1$} onto $\mathbb{R}^n$,"True or False:- There is a continuous function $f$ from {$x\in \mathbb{R}^n :||x||\le 1$} onto $\mathbb{R}^n$. where $||x||=(x_1^2+...+x_n^2)^{1/2}$. I think it is not possible as the domain is compact set and $f$ is continuous , so range set will also be compact.But $\mathbb{R}^n$ is not compact. Am I right?",['multivariable-calculus']
548696,$n$th derivative of $(x^2-1)^n$,"Define $R_n(x)=\dfrac{d^n}{dx^n}(x^2-1)^n$. Show that $R_n(x)$ is orthogonal to $1,x,\ldots,x^{n-1}$ in $L^2([-1,1])$. Also, what is the value of $R_n(1)$? By definition we have to show that $$\int_{-1}^1R_n(x)x^k=0$$ for $k=0,1,\ldots,n-1$. This looks a lot like integration by parts, so suppose $S_k$ is the $k$-th derivative of $(x^2-1)^n$. Then $$\int_{-1}^1R_n(x)x^k=x^kS_{n-1}(x)\mid_{-1}^1-k\int_{-1}^1x^{k-1}S_{n-1}(x)$$. It looks like the second term can be integrated by parts again, but what is the first term? Also, how would it be possible to compute $R_n(1)$?","['orthogonal-polynomials', 'measure-theory', 'calculus', 'real-analysis']"
548713,Polynomials are dense in $L^2$,"I know that the function $e^{inx}$ can be uniformly approximated on $[-\pi,\pi]$ by polynomials in $x$. I want to use this to show that polynomials are dense in $L^2([-\pi,\pi])$. Suppose that $f\in L^2([-\pi,\pi])$. I want to show that for any $\epsilon>0$, there is a polynomial $p$ such that $|\int_{-\pi}^\pi (f(x)-p(x))^2dx|<\epsilon$. I was thinking about writing $f$ in terms of its coefficients, i.e. $$f(x)=\sum_{n=-\infty}^\infty \hat{f}(n)e^{inx}$$ But I'm still not sure how this can lead to the polynomial $p$.","['measure-theory', 'real-analysis']"
548715,Computing second partial derivative with polar coordinates,Consider the polar coordinates with $x=r\cos\theta$ and $y=r\sin\theta$. I can show using the chain rule that $$\frac{\partial}{\partial x} = \frac{x}{r} \frac{\partial}{\partial r} -\frac{y}{r^2} \frac{\partial}{\partial \theta}$$ What is the method to compute $\dfrac{\partial^2}{\partial x^2}$? I don't know how to do it.,"['calculus', 'partial-derivative']"
548732,Is it true that $A\cup(B\mathbin{\triangle}C)=(A\cup B)\mathbin{\triangle}(A\cup C)$?,"Prove or disprove: $$A\cup(B\mathbin{\triangle}C)=(A\cup B)\mathbin{\triangle}(A\cup C)$$ for all sets $A,B,C$. I'm confused as to how to do the steps here logically.",['elementary-set-theory']
548749,"Question from ""An introduction to measure theory"" by Terence Tao [duplicate]","This question already has an answer here : Summablity and countability [duplicate] (1 answer) Closed 10 years ago . If $(x_α)_{α \in A}$ is a collection of numbers $x_α ∈ [0, +\infty]$ such that $\sum_{α∈A}{x_α} < \infty$, show that $x_α = 0$ for all but at most countably many $α \in A$, even if $A$ itself is uncountable.","['statistics', 'measure-theory', 'real-analysis']"
548763,Sum of exponentials with Fourier coefficient,"Let $f$ be a continuous function with period $2\pi$. Define $$u(r,\theta)=\sum_{n=-\infty}^\infty r^{|n|}\hat{f}(n)e^{in\theta}$$ for $r\in[0,1)$, where $\hat{f}(n)$ is the $n$th Fourier coefficient of $f$. a) Express $u$ as a series in $z=x+iy$ and $\bar{z}=x-iy$. b) Show that $u$ is infinitely differentiable in $x^2+y^2<1$. For a), I want to substitute in $r=\sqrt{x^2+y^2}$ and $\theta=\tan^{-1}(y/x)$. But this doesn't seem to yield a nice expression in terms of $z$ and $\bar{z}$. For b), since this is an infinite sum, if we take the derivative term by term, we have to worry about convergence. Also, there are two variables to differentiate with respect to ($r$ and $\theta$), which makes it more complicated.","['fourier-analysis', 'sequences-and-series', 'derivatives']"
548771,How to show that $\Bbb{P}^n$ is birational to $\Bbb{A}^n$ but they are not isomorphic?,Let $\Bbb{P}^n$ be the projective $n$-space and $\Bbb{A}^n$ the affine $n$-space. It is said that $\Bbb{P}^n$ is birational to $\Bbb{A}^n$ but they are not isomorphic. In the case of $\Bbb{P}^1$ and $\Bbb{A}^1$. I think that we can define rational maps $\varphi: \Bbb{P}^1 \to \Bbb{A}^1$ by $\varphi(x_0 : x_1) = x_1/x_0$ if $x_0 \neq 0$ $\varphi(x_0:x_1)= 0$ if $x_0=0$. Define $\psi: \Bbb{A}^1 \to \Bbb{P}^1$ by $\psi(x) = (1:x)$ if $x\neq 0$ and $\psi(x)=(0:1)$ if $x = 0$. Then $\psi$ and $\varphi$ are inverse of each other. Therefore $\Bbb{P}^1$ and $\Bbb{A}^1$ are birational. Is this true? How to show other cases and the fact that they are not isomorphic? Thank you very much.,['algebraic-geometry']
548798,"Accumulation points of the set $S=\{(\frac {1} {n}, \frac {1} {m}) \space m, n \in \mathbb N\}$","The exercise is to find the accumulation points of the set  $S=\{(\frac {1} {n}, \frac {1} {m}) \space m, n \in \mathbb N\}$ I'm trying to prove that if $A$={accumulation points of the set $S$}, then $A=\{(0,0), (\frac {1} {n},0),(0,\frac {1} {m}) \space n,m \in \mathbb N\}$. I could prove that the set of the right side of the equality is included in $A$. I don't know how to prove the other inclusion, which means that if $x$ is an accumulation point of $S$, then $x$ has to be $(0,0)$, or of the form $(\frac {1} {n},0)$ or $(0,\frac {1} {m})$.","['general-topology', 'analysis']"
548799,Algebraic Basis vs Hilbert basis,"I am confused between algebraic basis and hilbert basis. How do they differ exactly?
Can you give me examples (possibly in infinite dimensions) on when they are the same and when they are not the same? Thanks in Advance","['linear-algebra', 'real-analysis']"
548806,A finite set always has a maximum and a minimum.,"I am pretty confident that this statement is true. However, I am not sure how to prove it. Any hints/ideas/answers would be appreciated.","['elementary-set-theory', 'real-analysis', 'order-theory']"
548812,Good Pairs in Algebraic Topology,"Hatcher’s book says that $ \left( \mathbb{D}^{n},\mathbb{S}^{n - 1} \right) $ is a good pair; that is, there exists an open neighborhood $ V $ of $ \mathbb{D}^{n} $ containing $ \mathbb{S}^{n - 1} $ that deformation retracts onto $ \mathbb{S}^{n - 1} $. What is the open neighborhood $ V $ in this case? Is it an annulus (without its boundary, of course)? Thanks!","['general-topology', 'algebraic-topology']"
548832,How find this limit $\lim\limits_{x\to 0^{+}}\frac{\sin{(\tan{x})}-\tan{(\sin{x})}}{x^7}$,"Find the limit $$\lim_{x\to 0^{+}}\dfrac{\sin{(\tan{x})}-\tan{(\sin{x})}}{x^7}$$ My attempt: Since $$\sin{x}=x-\dfrac{1}{3!}x^3+\dfrac{1}{5!}x^5-\dfrac{1}{7!}x^7+o(x^7)$$ $$\tan{x}=x+\dfrac{1}{3}x^3+\dfrac{2}{15}x^5+\dfrac{1}{63}x^7+o(x^3)$$ So $$\sin{(\tan{x})}=\tan{x}-\dfrac{1}{3!}(\tan{x})^3+\dfrac{1}{5!}(\tan{x})^5-\dfrac{1}{7!}(\tan{x})^7+o(x^7)$$ Though this method might solve, I think this problem has nicer methods. Thanks.",['limits']
548865,Topology: Example of a compact set but its closure not compact,Can anyone gives me an example of a compact subset such that its closure is not compact please? Thank you.,"['general-topology', 'compactness']"
548876,Find the Area of the ellipse,"Given $$\frac{x^2}{a^2} + \frac{y^2}{b^2}=1$$ where $a>0$ , $b>0$ I tried to make $y$ the subject from the equation of the ellipse and integrate from $0$ to $a$ . Then multiply by $4$ since there are $4$ quadrants. $$Area=4\int^a_0\left(b^2-x^2\left(\frac{b^2}{a^2}\right)\right)^\frac{1}{2}dx$$ I can't get the answer $\pi ab$",['calculus']
548890,"$m \in \{2,6,42,1806,...\} $ - a problem of sum-of-$m$'th powers modulo $m$","(continuing the work for an answer for a question here in MSE and also in MO ) I'm (re-)viewing the function 
$$ f(m) = \sum_{k=0}^{m-1} k^m $$ 
considering its residue modulo $m$:
$$ r(m) \equiv f(m) \pmod m $$ It is easy to see why for odd m $$ r(m) = 0 \qquad \text{  for odd } m$$
Not so easy is it for even m . 
I tried to determine for what m we get $$ r(m) = 1 $$ It seems highly nontrivial; and after some brute force it seems this is very rarely the case, and seemingly for $m_k$ where $m \in \{2,6,42,1806,?? \} $ but interestingly not for the next $m=3263442 $ when we follow that pattern. The recursive pattern says
$$ \begin{array} {} m_0=&= 2 & \to & r(m_0)=1 & 2 \in \mathbb P\\
   m_1=m_0 \cdot (m_0+1) &= 2 \cdot 3 & \to & r(m_1)=1 & 3 \in \mathbb P\\
   m_2=m_1 \cdot (m_1+1) &= 2\cdot 3 \cdot 7 & \to & r(m_2)=1 &  7 \in \mathbb P\\
   m_3=m_2 \cdot (m_2+1) &= 2 \cdot 3 \cdot 7 \cdot 43 & \to & r(m_3)=1 & 43 \in \mathbb P\\
   m_4=m_3 \cdot (m_3+1) &=2 \cdot 3 \cdot 7 \cdot 43  \cdot 1807 & \to & r(m_4)=1807 &  1807 \notin \mathbb P\\
   m_5=m_4 \cdot (m_4+1) &=m_4 \cdot 3263443 & \to & r(m_5)=?? & 3263443  \in \mathbb P\\
  \vdots
 \end{array} \\
$$
However, I could not compute the last entry $r(m_5)$ because the sum expression for $f(m_5)$ is too huge. Also it seems to be an interesting question to answer this analytically. Q1: is $r(m_5) = 1$ ? Q2: does the pattern continue, in the sense that if the cofactor is/is not prime, the residue is/is not 1? Q3: are the other numbers $w$ outside of this pattern for which $r(w)=1$ ? The sequence $2,3,7,43,1807,... $ is in the OEIS in different variants The sequence $2,6,42,1806,...$ is also in the OEIS in different variants [update] Ah I see now, that in a comment at OEIS-sequence A014117 Max Alekseyev states (Aug 2013) that this sequence is even finite - however it is not yet clear to me, whether my problem-definition and the OEIS'-definition match. So this problem has possibly been solved...","['modular-arithmetic', 'sequences-and-series', 'number-theory']"
548918,Inequality with determinants problem,"Let $A,B \in M_{2}(\mathbb{R})$ with $AB=BA.$ Prove that: $$\det(A^{2}+AB+B^{2})\geq (\det(A)-\det(B))^{2}$$","['matrices', 'inequality', 'determinant']"
548949,$\alpha \wedge \beta = 0$ iff $\beta = \alpha \wedge \gamma$,"I have been given the following problem: Let $\alpha$ be a nowhere-zero 1-form. Prove that for a (p+1)-form $\beta$ $(p\geq0)$, one has $\alpha \wedge \beta = 0$ if and only if $\beta = \alpha \wedge \gamma$ for some p-form $\gamma$. [Hint: You might like to do it on $\mathbb{R}^n$ fist. Partition of unity is useful in the general case]. It is true that $\alpha \wedge \alpha = 0$ for 1-forms (and $k$-forms whenever $k$ is odd I believe), so the if statement is easy.
However, for the converse, I couldn't find an argument even on $\mathbb{R}^n$. I tried to do this locally first by writing $\alpha = \sum_i \alpha_i(x) dx_i$, $\beta = \sum_J \beta_J(x) dx_J$ where $J = j_1j_2...j_{p+1}$ and $1 \leq j_1 \leq j_2 \leq...\leq j_{p+1} \leq dim(M)$ for whatever the dimension of M might be. Then $\alpha \wedge \beta = \sum_{i,J} \alpha_i(x) \beta_J(x) dx_i\wedge dx_J$. It is given that $\alpha$ is nonvanishing, but nothing is known about $\beta$. The sum seems to be a combinatorial thing if you want to arrange it into a form with $dx_i\wedge dx_J$ all distinct. Anyhow, I cannot see how to rewrite this expression in such a form that it becomes clear that one can sort of factor out $\alpha$.","['differential-forms', 'multilinear-algebra', 'differential-geometry']"
548961,"Number of groups of order $p^n$, where $p$ is prime","for $n=1$, it is cyclic. so, the number is $1$ for $n=2$, it is Abelian. so, the number is $2$ for $n\geq 3$, I don't know. Can you recommend a book or link which can be helpful for understanding this? Not just the result. I want to know the process of proving","['reference-request', 'finite-groups', 'group-theory']"
549028,Deriving Maclaurin series for $\frac{\arcsin x}{\sqrt{1-x^2}}$.,"Intrigued by this brilliant answer from Ron Gordon, I was attempting to find the Maclaurin series for 
$$f(x)=\frac{\arcsin x}{\sqrt{1-x^2}}=g(x)G(x)$$ with $g(x)=\frac{1}{\sqrt{1-x^2}}$ and $G(x)$ its primitive. So I attempted to multipy series, which yielded this: $$f(x)=\sum_{n=0}^{\infty}x^{2n+1} (-1)^n\sum_{k=1}^{n}\frac{1}{k+1} { -\frac{1}{2}\choose n-k}{ -\frac{1}{2}\choose k},$$ which I'm unable to simplify further. How to proceed? Or is this approach doomed?","['power-series', 'sequences-and-series']"
549085,Laplacian operator,"I need to find A,$\alpha$,C $\in \mathbb{R}$ so that $u:\mathbb{R}^n \to \mathbb{R}$ of the form $u(x) = A||x||^\alpha + C $
satisfies $\Delta u(x) = ||x||^2$ and $u(0) = -1$. This question gets very messy. I end up with terms that can potentially cancel but they both depend on A and $\alpha$ and i cannot satisfy what is required.","['multivariable-calculus', 'partial-derivative', 'derivatives']"
549092,"Writing $f\in L^2([-\pi,\pi])$ as a power series.","Consider the space $L^2([-\pi,\pi])$. I want to show that every function $f\in L^2([-\pi,\pi])$ can be written as a power series. I remember a result that polynomials are dense in $L^2([-\pi,\pi])$. I thought about extending it (since power series are polynomials with infinite number of terms), but it is not clear how to do that. Density means that polynomials can get arbitrarily close to a function $f$, but here we want an exact representation. (Note: See also my previous question )","['power-series', 'measure-theory', 'real-analysis']"
549099,What is a good book to study classical projective geometry for the reader familiar with algebraic geometry?,"The more I study algebraic geometry, the more I realize how I should have studied projective geometry in depth before. Not that I don't understand projective space (on the contrary, I am well versed in several different constructions of it), but I lack the familiarity with basic results as cross-ratios, how projective linear transformations act on projective space (as in how many points determine one transformation), Desargues' theorem, etc. I also sometimes feel that it wouldn't hurt to get more practice with hard (as in Olympiad-style) classical geometry problems that may or may not use some facts of projective geometry. To summarize, I am looking for a reference that covers classical results of projective geometry, and yet assumes the maturity of a reader who has already started studying algebraic geometry. It would be only better if such a book could help me understand where those amazing solutions to Olympiad problems come from. Does anyone have a suggestion?","['algebraic-geometry', 'self-learning', 'projective-geometry', 'reference-request', 'soft-question']"
549101,Confused about notation: difference between $\prod_{i=1}^np(x_i)$ and $\prod_{i=1}^np(x)$,"In my information theory book by Cover and Thomas, at the beginning of the channel coding theorem, it's written: ""Each entry in this matrix"" (the matrix of the randomly generated code) ""is generated i.i.d according to p(x). Thus, the probability that we generate a particular code $C$ is "" $Pr(C)=\prod_{w=1}^{2^{nR}} \prod_{i=1}^np(x_i(w))$ Now, I get what they're saying, but the notation is very confusing to me. $1-$First of all, since we are generating entries i.i.d why can't we simplify $\prod_{i=1}^np(x_i)$ to $\prod_{i=1}^np(x)=p(x)^n?$ $2-$Also, instead of writing $p(x_i(w))$ couldn't we just write $p(x_{i,w})$? It seems as if there's something about the notation that's crucial that I'm not getting.. Any help would really be appreciated!! Thanks in advance","['statistics', 'information-theory', 'probability']"
549111,What is $\lim\limits_{n\to\infty}(\sqrt2-\sqrt[3]2)\cdots(\sqrt2-\sqrt[n]2)$? How to approach? [duplicate],"This question already has answers here : Finding the limit of roots products $(\sqrt{2}-\sqrt[3]{2})(\sqrt{2}-\sqrt[4]{2})(\sqrt{2}-\sqrt[5]{2})\cdot \cdot \cdot (\sqrt{2}-\sqrt[n]{2})$ (2 answers) Closed 10 years ago . $$\lim\limits_{n\to\infty}(\sqrt2-\sqrt[3]2)(\sqrt2-\sqrt[4]2)(\sqrt2-\sqrt[5]2)\cdots(\sqrt2-\sqrt[n]2)$$ Could you tell me how to approach this kind of question? How do I find the limit of this sequence? I know that for very large $n$ the each bracket is more than $1$, so my guess is its going to infinity, how do I prove such a thing?","['sequences-and-series', 'calculus', 'infinite-product', 'limits']"
549135,Construction of a function which is not the pointwise limit of a sequence of continuous functions,"This is somewhat linked to a prior question of mine which was looking to see if a proof of mine regarding the Dirichlet function was correct (it wasn't). I now have an answer to the question which can be answered without using directly using the Baire category theorem or the likes; as it is sufficiently different to my original approach, I feel that a new question would be the best way of going about this. The question is to Construct a function $f:[0,1] \rightarrow \mathbb{R}$ which is not the pointwise limit of any sequence $(f_n)$ of continuous functions to which I will have an answer below (while I didn't come up with much of this myself, I feel it's an interesting result to discuss). Finally, as a warning to those who are seeing this as a result of searching for answers to their example sheet/homework questions, please have a think about the question before reading the answer below.",['real-analysis']
549143,Infinite Series $\sum\limits_{n=-\infty}^{\infty}\frac{1}{(x+n\pi)^m}$,"How can we find a closed form for the following infinite series for any $m\in\mathbb N$?
$$\sum_{n=-\infty}^{\infty}\frac{1}{(x+n\pi)^m}$$","['closed-form', 'sequences-and-series', 'riemann-zeta', 'real-analysis', 'complex-analysis']"
549154,An integral from Peskin & Schroeder's QFT (2.51),"How would you solve the following integral:
$$ \int_1^\infty dx \sqrt{x^2-1} \, e^{-itx}$$ where $t$ is a constant such that $t>0$?","['definite-integrals', 'improper-integrals', 'integration', 'complex-analysis']"
549186,The product (or composition) of permutation groups in two-line notation?,"This question has been asked before, I know: Product of Permutations However, his did not resolve my problem. Here's an example I've been looking at, which is to find the product of two permutations in two-line notation: $$ \left( \begin{array}{cc}
1 & 2 & 3 & 4 & 5 \\
3 & 4 & 5 & 1 & 2
\end{array} \right)
%
\left( \begin{array}{cc}
1 & 2 & 3 & 4 & 5 \\
3 & 5 & 1 & 2 & 4
\end{array} \right)
$$ Now this is how the two functions compose: $$1 \mapsto 3 \mapsto 4$$
$$2 \mapsto 5 \mapsto 2$$
$$3 \mapsto 1 \mapsto 3$$
$$4 \mapsto 2 \mapsto 5$$
$$5 \mapsto 4 \mapsto 1$$ That is: \begin{pmatrix}
  1 & 2 & 3 & 4 & 5 \\
  4 & 2 & 3 & 5 & 1 \\
 \end{pmatrix} But since it has been a while that I last looked at permutations, I can't quite see how this works? I can see, for a single permutation, i.e.
\begin{pmatrix}
  1 & 2 & 3 & 4 & 5 \\
  3 & 5 & 4 & 1 & 2 \\
 \end{pmatrix} we have $$1 \mapsto 3 \mapsto 4 \mapsto 1$$
        $$2 \mapsto 5 \mapsto 2 $$ which includes all the elements in the group, so at this point we stop. This can then be written in cycle notation as:  (134)(25). However, how do I work through two permutations this way. Would I look at the elements in the top row of the second permutation which I didn't start with before? What happens during the process of composition? Some illumination would be great. (I know this is a very straight forward technique, but I've somehow got stuck!)","['permutations', 'group-theory', 'abstract-algebra']"
549203,Tangent of implicit function (of two variables),"Wikipedia has the following : equation of the tangent line at a point $(a,b)$ such that $f(a,b) = 0$ (the implicit function) is given by: ${\partial f \over \partial x} (x-a) + {\partial f \over \partial y}(y-b) = 0$ I guess it's related to the implicit function theorem, which I know (that the said theorem exists, not that I can prove it myself or even be acquitted with it). Explanation or non-rigorous outline of proof would suffice.","['multivariable-calculus', 'partial-derivative', 'calculus', 'real-analysis']"
549211,Complex solutions within unit circle,"How many solutions within a unit circle $|z| < 1$ does the equation $(1 +
z)^{n + m} = z^n$ have for $z$ complex, and $n$, $m$ positive integers?","['complex-analysis', 'polynomials']"
549215,Why does this integral vanish? $\int_C \frac{e^{az}}{1+e^z}dz$,"I'm looking for an argument that would prove that the integral $$I=\int_C \frac{e^{az}}{1+e^z}dz$$ vanishes for $R \to \infty$, where $C$ is the horizontal line segment from $(1+i)R$ to $(-1+i)R$, and $a \in (0,1)$. Here $R$ goes to infinity 'discretely', so as to avoid the singularies at $(2n+1)\pi i$, the line segment is placed between the subsequent singularities. Parametrizing the contour with $z(t)=iR+t, \ t\in[-R,R]$ and attempting to bound the integral gives me: $$|I| \le \int_{-R}^{R} \frac{e^{at}dt}{|1+e^{t+iR}|}$$ but I don't know what to do with this, using the reverse tringle inequality doesn't help because the denominator becomes $e^t -1$, and the integral goes through zero... Additional information: This problem cropped up when doing the following exercise: ""By choosing a suitable contour, show that  $$\int_\mathbb{R} \frac{e^{ax}}{1+e^x}dx = \frac{\pi}{\sin(a\pi)},$$ where $0<a<1$. I managed to solve this integral now, by choosing the integration contour to be a rectangle with vertices $\pm R, \pm R + 2\pi i$. But originally, I was trying the verteces $\pm R, (\pm 1+i)R$, where the values of $R$ are restricted so the contour doesn't go through a singularity. Letting $R$ to infinity will then have the contour capture all of the residues on the positive imaginary axis, the sum of which (times $2 \pi i$) is precisely $\frac{\pi}{\sin(a\pi)}$, meaning the top part has to tend to zero. Letting $R$ change in discrete steps, $R_n = 2\pi n$ gives a nonzero value of the top integral though, namely $$I_{top} = e^{2\pi i a n} I_n$$ where $$I_n = \int_{-2\pi n}^{2 \pi n} f(x)dx.$$ So, in the limit, things don't actually work out because of the weird oscillatory term. But apparently, taking the limit is not even necessary, as the top integral is always proportional to the bottom one, so their sum is equal to the residues contained inside, which are calculated easily enough.",['complex-analysis']
549225,Proof of sandwich/squeeze theorem for series.,"I am interested in proving a theorem, which I suppose one may call a sandwich or squeeze theorem for series. Suppose we have three series: $\sum^{\infty}_{n=1}a_{n}$, $\sum^{\infty}_{n=1}b_{n}$ and $\sum^{\infty}_{n=1}c_{n}$. We know that $\sum^{\infty}_{n=1}a_{n}$ and $\sum^{\infty}_{n=1}c_{n}$ converge; furthermore, let us assume that for all $n\in\mathbb{N}$, the following inequality holds: $a_{n}<b_{n}<c_{n}$. Then, the series $\sum^{\infty}_{n=1}b_{n}$ will also converge. The only way that I can think of to approach the proof of the above would be via the Cauchy criterion, i.e. showing that $$\forall_{\varepsilon>0}\,\exists_{n_{\varepsilon}}\,\forall_{m>k>n_{\varepsilon}}\quad|b_{k+1}+...+b_{m}|<\varepsilon.$$ As I understand, in order to show that, we would have to somehow bound $\left|\sum^{m}_{n=k+1}b_{n}\right|$ by $\left|\sum^{m}_{n=k+1}c_{n}\right|$ and/or $\left|\sum^{m}_{n=k+1}a_{n}\right|$. If we assume nonnegativity of the terms of $\sum{}b_{n}$ and $\sum{}c_{n}$, the task becomes trivial. However, without this assumption, I am having problems with finding the right bound. I would be thankful for some hints on how this could be done, or possibly advice on a different approach to the proof. Thank you in advance.","['sequences-and-series', 'calculus', 'real-analysis']"
549226,Why is the undergraph definition of Lebesgue integral so rare?,"So in Pugh's Real Mathematical Analysis, the initial definition of the Lebesgue integral is as the Lebesgue measure of the undergraph of the function (where the function is nonnegative, with the usual extension to functions whose sign changes). This is extremely intuitive, and immediately justifies all the abstract work of extending our notion of volume with the concept of measure. Another definition is given in the main exposition, and yet another is given in the exercises. i.e. the undergraph definition is: $\int_Ef = m(Uf)$, where $Uf = \{(x, y) \mid x \in E, \ \ 0 \leq y \leq f(x)$ Now I'm working through the more advanced Real Analysis by Folland, where the integral is defined as the supremum of integrals of simple functions, whose integrals are fairly obvious. Additionally, in a graduate course, we used an equivalent definition as the Riemann integral of the measure of the superlevel sets, i.e. $\int_E f = \int_0^\infty m(\{ x \mid f(x) > t\})dt$ Nowhere in the book does it seem to mention the undergraph definition, and googling around it's very hard to find mention of the undergraph definition at all. I realize why the simple function definition might be better to work with in developing the theory (since it often suffices to prove our theorems for simple functions that approximate much uglier ones), but I'm wondering if there's any particular reason why the undergraph definition seems so neglected, given that the main motivation we're given for the very first time we're introduced to the concept of integration is to compute the area below a curve. Perhaps the definition suffers from a serious limitation?","['soft-question', 'integration', 'real-analysis', 'lebesgue-integral']"
549230,is $p \land (p \lor q)$ a tautology?,"I would just like to know whether my work is correct before I continue on with the rest of the questions. $$p \land (p \lor q)$$ $$p \land (\lnot p \rightarrow q)$$ $$(p \land \lnot p) \rightarrow q$$ $$F \rightarrow q$$ with this, I'm going to say it is not a tautology.","['logic', 'propositional-calculus', 'discrete-mathematics']"
549231,"French metro metric: difficulty to prove that $d(x, y) = 0\iff x = y$.","I think that it is related to the special definition of the metric in my book:
$$d(x, y) = \begin{cases}||x - y||,\mbox{ if }\exists \alpha\in\mathbb{R}: \alpha x + (1-\alpha) y = 0;\\ ||x|| + ||y||, \mbox{ otherwise.}\end{cases}$$ This way, for $x = y$, we have $\alpha x + (1 - \alpha) x = 0$, which is true only if $x = 0$, so we fall into the second case: $d(x, x) = ||x|| + ||x|| = ||x||^2 \neq 0$ if $x\neq 0$. Seems like it doesn't satisfy the axioms of a metric. The case described in Woflram MathWorld is simpler, because the condition for the first case is: $x = \alpha y$. This way, for $d(x, x)$, we have $\alpha = 1$, and everything works fine! Am I missing something or is there an error in the problem statement?
Thanks in advance!",['analysis']
549253,"Hartshorne, exercise II.2.18: a ring morphism is surjective if it induces a homeomorphism into a closed subset, and the sheaf map is surjective","Let $\phi:A\to B$ be a ring morphism, and let $f:X=Spec(B)\to Y=Spec(A)$ be the induced map of affine schemes. I'm trying to show that if $f$ is a homeomorphism onto a closed subset of $Y$ and $f^\#:\mathcal{O}_Y\to f_*(\mathcal{O}_X)$ is surjective, then $\phi$ is surjective. Hartshorne suggests to factor the map through the quotient. So let $\pi:A\to A/ker \phi$ and $\tilde \phi:A/ker \phi\to B$ be the canonical maps. $\tilde \phi$ induces a map $\tilde f:X\to Y'=Spec (A/ker\phi)$, and $\pi$ induces a map $g:Y'\to Y$. My idea is: prove that $g_*\tilde f^\#$ is an isomorphism. Then, if we apply the global sections functor to it, we get $\tilde \phi$ which is then also an isomorphism. First, $g_*\tilde f^\#$ is surjective, since $f^\#=g_*\tilde f^\# \circ g^\#$, and $f^\#$ is surjective by hypothesis. Now, since $\tilde \phi$ is injective, we get get that $\tilde f^\#$ is injective (previous part of the exercise). The direct image functor $g_*$ is left exact (since it is the right adjoint to the inverse image functor $g^{-1}$), so $g_*\tilde f^\#$ is also injective. Thus $g_*\tilde f^\#$ is an isomorphism. Then $(g_*\tilde f^\#)_Y=\tilde f^\#_{Y'}=\tilde \phi$ is an isomorphism. QED Something must be wrong with my argument since I didn't use the hypothesis that $f$ is an homeomorphism onto a closed subset of $Y$. I've seen solutions online that do the following: prove that $\tilde f$ is an homeo, then somehow (not explicited) from surjectivity of $g_*\tilde f^\#$ we get surjectivity of $\tilde f^\#$. Then $\tilde f$ is an isomorphism of affine schemes, thus $\tilde \phi$ is an isomorphism of rings. How do they deduce surjectivity of $\tilde f^\#$ from surjectivity of $g_*\tilde f^\#$?",['algebraic-geometry']
549298,Condition number of a product of two matrices,"Given two square matrices $A$ and $B$, is the following inequality
$$\operatorname{cond}(AB) \leq \operatorname{cond}(A)\operatorname{cond}(B),$$ where $\operatorname {cond}$ is the condition number, true? Is this still true for rectangular matrices? I know this is true: $$||AB|| \leq ||A|| \cdot ||B||$$ The definition of condition number of matrix is as follows: $$\operatorname{cond}(A)=||A|| \cdot ||A^{-1}||$$","['matrices', 'normed-spaces', 'linear-algebra', 'condition-number']"
549302,Showing a function is bijective and finding its inverse,"The function $f: \mathbb{R}^2 \rightarrow\mathbb{R}^2$ is defined by $f(x,y)=(2x+3y,x+2y)$ . Show that $f$ is bijective and find its inverse. I've got so far:
Bijective = $1-1$ and onto. $1-1$ if $(2x_1+3y_1,x_1+2y_1)=(2x_2+3y_2,x_2+2y_2)$ Then $$2x_1+3y_1=2x_2+3y_2 \qquad (1)$$ $$ x_1+2y_1=x_2+2y_2 \qquad (2)$$ $(1)-(2)$ $$x_1+y_1=x_2+y_2$$ $$ x_1=x_2+y_2-y_1$$ Substituting into equation 1: $$ 2(x_2+y_2-y_1)+3y_1=2x_2+3y_2$$ $$ y_1=3y_2-2y_2 $$ $$ y_1=y_2$$ Substituting into equation 2: $$ x_1+2y_1=x_2+2y_1$$ $$ x_1=x_2$$ $$ (2x_1+3y_1,x_1+2y_1)=(2x_2+3y_2,x_2+2y_2)$$ Thus 1-1 Onto if $(u,v) \in \mathbb{R}^2$ (codomain) we want $(x,y)$ with $f(x,y)=(u,v)$ $$ (2x+3y,x+2y)=(u,v)$$ $$2x+3y=u$$ $$ x+2y=v$$ Eliminating x: $$ y=2v-u$$ Substituting: $$ 2x+3(2v-u)=u$$ $$ 2x+6v-3u=u$$ $$ 2x=4u-6v$$ $$ x=2u-3v$$ Therefore: $$ f(2u-3v,2v-u)=(u,v)$$ Now how do you find it’s inverse? And is that correct what I have done?","['inverse', 'functions']"
549310,Discrete math logic question,"I have the following two questions. For all real numbers x, there is a real number y such that $2x+y=7$ would this be true or false? I think true because if you put $2(7)+y=14$ $2(8)+y=14$ there will always be a specific y that will make it work is this logic correct. There is a real numbers x that for all real number y, $2x+y=7$ will be true. would this be false because if you say $x=6$ then you get $2(6)+2=14$ only if $y=2$ would it work but it would not work for every y.","['logic', 'quantifiers', 'discrete-mathematics']"
549329,Probability task (Find probability that the chosen ball is white.),"I have this task in my book: First box contains $10$ balls, from which $8$ are white. Second box contains $20$ from which $4$ are white. From each box one ball is chosen. Then from previously chosen two balls, one is chosen. Find probability that the chosen ball is white. The answer is $0.5$. Again I get the different answer:
There are four possible outcomes when two balls are chosen: $w$ -white, $a$ - for another color $(a,a),(w,a),(a,w),(w,w)$. Each outcome has probability: $\frac{2}{10} \cdot \frac{16}{20};  \frac{8}{10} \cdot \frac{16}{20}; \frac{2}{10} \cdot \frac{4}{20}; \frac{8}{10} \cdot \frac{4}{20};$ In my opinion the probability that the one ball chosen at the end is white is equal to the sum of last three probabilities $\frac{8}{10} \cdot \frac{16}{20} + \frac{2}{10} \cdot \frac{4}{20} + \frac{8}{10} \cdot \frac{4}{20}=\frac{21}{25}$. Am I wrong or there is a mistake in the answer in the book?",['probability']
549340,"If $G, H, K$ are divisible abelian groups and $G \oplus H \cong G \oplus K$ then $H \cong K$","This is an exercise in Hungerford. But can somebody explain why is the following not a counter-example? Let $G$ be the direct sum of $|\mathbb{R}|$ copies of $\mathbb{Q}$. Let $K$ be the direct sum of $|\mathbb{N}|$ copies of $\mathbb{Q}$. Then $G \oplus \mathbb{Q} \cong G \oplus K$ but $\mathbb{Q}$ is not isomorphic to $K$. Indeed, suppose $f : \mathbb{Q} \rightarrow K$ is a $\mathbb{Z}$-module isomorphism. We may show that $f$ is a $\mathbb{Q}$-module isomorphism obtaining thus a contradiction. For any $v \in Q$ non-zero and a non-zero natural $b$ there is a unique $w$ such that $bw = v$, that is $w = (1/b)v$. We have $b[(1/b)v] = v$ so $b f((1/b) v) = f(v)$. The same uniqueness argument applies in $K$ since it is torsion-free, so $f((1/b) v) = (1/b) f(v)$. Hence $f$ is a $\mathbb{Q}$-module isomorphism.","['divisible-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
549361,Advantages to continuity at a point,"A scalar field $f : \mathbb{R}^n \to \mathbb{R}$ is said to be continuous at a point $\boldsymbol{a}$ if $$ \lim_{\boldsymbol{x} \to \boldsymbol{a}} f(\boldsymbol{x}) = f(\boldsymbol{a}) $$ So in other words, $f$ has to be defined at $\boldsymbol{a}$ and also has to have a limit at $\boldsymbol{a}$. But isolated points are also defined to be continuous. It seems to me like, given this definition, there isn't really an advantage to having a function continuous at a point, and continuity is only useful on an set or interval, because of the following: $f$ can be continuous at a point but not differentiable (e.g. $f(\boldsymbol{x}) = \|\boldsymbol{x}\|$ at $\boldsymbol{0}$) $f$ can be continuous at a point but the limit doesn't exist (e.g. $f(\boldsymbol{x}) = \sqrt{-\|\boldsymbol{x}\|}$ at $\boldsymbol{0}$ if $f(\boldsymbol{x}) \subset \mathbb{R}$) $f$ can be continuous at a point but the first-order partials don't exist So if $f$ is continuous at a point $\boldsymbol{a}$, is there anything we can say about $f$ at $\boldsymbol{a}$? Or is it just a nice-to-have?","['multivariable-calculus', 'continuity']"
549370,Proving a few things about $ L^{p} $-spaces,"I am new to $ L^{p} $-spaces and am trying to prove a few things about them. Therefore, I would like to ask you whether I have gotten the following right. Prove that $ {L^{\infty}}(I) \subseteq {L^{p}}(I) $ for all $ p \in (0,\infty) $, where $ I = [a,b] $ is a closed bounded interval, by showing that
$$
\text{$ \forall $ measurable functions $ f $ defined on $ [a,b] $}: \quad
\| f \|_{L^{p}} \le (b - a)^{\frac{1}{p}} \| f \|_{L^{\infty}}.
$$
My idea was to invoke the fact that
$$
                         \| f \|_{L^{p}}
\stackrel{\text{def}}{=} \left( \int_{I} |f|^{p} \, d{\mu} \right)^{\frac{1}{p}}
\le                      \| f \|_{\infty} \left( \int_{I} 1 \, d{\mu} \right)^{\frac{1}{p}}
$$
for all measurable functions $ f $ defined on $ [a,b] $. Is this correct? Prove that $ \displaystyle {L^{\infty}}(I) \subsetneq \bigcap_{p \in (0,\infty)} {L^{p}}(I) $. Inclusion is clear from (1), and a function that illustrates why the inclusion is strict is $ f(x) \stackrel{\text{def}}{=} \dfrac{1}{x^{x}} $ on the interval $ [0,1] $ (its $ L^{p} $-norm exists for each $ p \le \infty $, but it is not bounded). Prove that $ {L^{p}}(\mathbb{R}) $ is not a subset of $ {L^{\infty}}(\mathbb{R}) $ and vice-versa. Take the function $ f(x) \stackrel{\text{def}}{\equiv} 3 $. It is not integrable over $ \mathbb{R} $, but it is bounded. For the reverse implication, take the function
\begin{equation}
f(x) \stackrel{\text{def}}{=} \left\{
\begin{array}{ll}
\frac{1}{\sqrt{x}} & \text{if $ 0 \le x \le 1 $}; \\
0                  & \text{if $ x \in (- \infty,0) \cup (1,\infty) $}.
\end{array} \right.
\end{equation}
It is integrable over $ \mathbb{R} $, but it is not bounded. Maybe I have made some mistakes here or maybe I am missing something, so I appreciate any kind of help!!! P.S.: I have just noticed that my example $ \dfrac{1}{x^{x}} $ does not work, since this function is actually bounded on $ [0,1] $.","['integration', 'measure-theory', 'lp-spaces', 'lebesgue-integral', 'functional-analysis']"
549395,Intersection of $\{ [n\sqrt{2}]\mid n \in \mathbb{N}^* \}$ and $\{ [n(2+\sqrt{2})]\mid n \in \mathbb{N}^* \}$,"Find the intersection of sets $A$ and $B$ where
$$A = \{ [n\sqrt{2}]\mid n \in \mathbb{N}^* \}$$
$$B = \{ [n(2+\sqrt{2})]\mid n \in \mathbb{N}^* \}.$$ ([$x$] is the integer part of $x$) Using the computer, we found common elements. Does anyone have an idea to solve?","['elementary-number-theory', 'discrete-mathematics']"
549405,Derive asymptotic behavior of inverse of the normal cdf with respect to 2^n,"I have a normal distribution $\mu = 0$ and $\sigma = 0.58n$ where $n > 0 $ and I am trying to derive the asymptotic behavior of the following equation:
$$\Phi\left(\frac{x}{0.58n}\right)\;=\;2^{1-n}$$
Follows:
$$
\DeclareMathOperator\inverfc{inverfc}
x = -0.58 \sqrt{2}n \inverfc{({2^{2 - n}})}
$$
So I want to find $O( n\inverfc{({2^{2 - n}})}) $.
More specifically I want to confirm my suspicion that it is in $O(n \log{n})$. However since Inverf is a special function I can't wrap my mind around to analyse it. I gave complete context since another derivation might be more helpful here.","['statistics', 'asymptotics', 'real-analysis', 'analysis']"
549411,Generalizing the Product Rule,"How would I go about generalizing the product rule to the product of $n$ functions $\psi_1(x), \ \psi_2(x), ..., \ \psi_n(x)$? That is, I'm hoping to obtain an expression for $$
\frac{d}{dx} \prod_{j = 1}^n \psi_j(x)
$$","['calculus', 'products', 'derivatives']"
549428,Convergence of $x_{n+1} = \frac12(x_n + \frac2{x_n}).$ [duplicate],"This question already has answers here : Proof of Convergence: Babylonian Method $x_{n+1}=\frac{1}{2}(x_n + \frac{a}{x_n})$ (9 answers) Closed 3 years ago . Let $x_1=1$ and $$x_{n+1} = \frac12\left(x_n + \frac2{x_n}\right).$$ Prove or disprove $(x_n)$ is convergent and show the limit. When I tried working on it I found the sequence was bounded by
square root of 2 and it is was monotone. But apparently the sequence is not bounded by square root of two and is not monotone. But I have no idea why. Any help would be greatly appreciated! Thanks!","['sequences-and-series', 'convergence-divergence', 'calculus', 'limits']"
549429,Absolute Value inequality help: $|x+1| \geq 3$,"Find the solutions to the inequality: $$|x+1| \geq 3$$ I translate this as: which numbers are at least $3$ units from $1$? So, picturing a number line, I would place a filled in circle at the point $1$. The solutions would then be on the interval $(-\infty,-2] \cup [4,\infty)$. But this is wrong, because: Why do they rewrite $|x+1|$ as $|x-(-1)|$?","['inequality', 'absolute-value', 'algebra-precalculus']"
549438,How do I take the limit with invoking L'Hospital's rule? $\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{\ln(x)}\right)$,"Need to take the limit:
$$\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{\ln(x)}\right) = \lim_{x \to 1}\left(\frac{x\cdot \ln(x)-x+1}{(x-1)\cdot \ln(x)}\right)=(0/0)$$
Now I can use L'Hospital's rule:
$$\lim_{x \to 1}\left(\frac{1\cdot \ln(x)+x\cdot \frac{1}{x}-1}{1\cdot \ln(x)+(x-1)\cdot\frac{1}{x}}\right)= \lim_{x \to 1}\left(\frac{\ln(x)+1-1}{\ln(x)+\frac{(x-1)}{x}}\right)=\lim_{x \to 1}\left(\frac{\ln(x)}{\frac{(x-1)+x \cdot \ln(x)}{x}}\right)=\lim_{x \to 1}\frac{x\cdot \ln(x)}{x-1+x\cdot \ln(x)}=\frac{1\cdot 0}{1-1+0}=(0/0)$$
As you can see I came to $(0/0)$ again. So what I have to do to solve this problem?","['derivatives', 'real-analysis', 'limits']"
549480,Help with proof of Frobenius Theorem,"Let $D$ be a finite dimensional associative division algebra over $\mathbb{R}$ with unit $1_{D}$. For all $a\in\mathbb{R}$ we identify the elements of the form $a\cdot1_{D}$ with $a$ itself and consider $\mathbb{R}$ to be a sub-ring of $D$. We will also idenitfy $1_{D}$ with $1\in\mathbb{R}.$ Theorem (Frobenius): Every finite dimensional associative division algebra over $\mathbb{R}$
  is isomorphic to $\mathbb{R},
 \mathbb{C}$
 or $\mathbb{H}$
  (the quaternions) Guidance: Given $x\in D$
show than the mapping $m_{x}:D\to D$
defined by $m_{x}\left(d\right)=x\cdot d$
is a linear transformation. Conclude using Cayley-Hamilton Theorem that $x$
is a zero of a polynomial with real coefficients. (Done) Use the Fundamental Theorem of Algebra to show $x$
is a zero a real polynomial of degree 1 or 2 (Done) Show that if each $x\in D$
is a zero of real polynomial of degree 1 then $D\cong\mathbb{R}$
(Done) Show than if the following claim is unture then there is an $x\in D$
satisfying the equation $x^{2}=-1$
(identifying $-1$ of the ring with the real $-1$
) - (No clue) Show that if in the conditions of the previous claim $D$
is a vector space of dimension $2$ over $\mathbb{R}$ then $D\cong\mathbb{C}$
(Done) Show that if $\dim D>2$
then the collection $V=\left\{ x\in D\,|\, x^{2}\leq0\right\}$
is a sub-space of $D$ of codimension $1$. (When writing for $d\in D$
that $d\leq0$
we assume that $d$
is in $\mathbb{R}$
as a subring of $D$
) - (No idea how to show the part about the dimension) Show that the mapping $B:V\to V$
given by $B\left(a,b\right)=-ab-ba$ is an inner product on $V$
(Done). Given an orthonormal basis of $V$
relative to $B$
denoted $\left\{ e_{1},....,e_{n}\right\} 
  (n\geq2)$
if $n=3$
then $D\cong \mathbb{H}$
and otherwise there is no such algebra $D$
for which the conditions of the theorem hold (No clue) I'd really appreciate help (or really a proof) for parts 4,6,8. Thanks in advance!","['algebras', 'abstract-algebra']"
549493,"Find an example of a sequence $\{f_k\}$ such that $f_k\in L^p$ for $1\le p <\infty$, $f_k\to0$ in $L^p$ for $1\le p < p_0$","Let $1<p_0<\infty$. Find an example of a sequence $\{f_k\}$ such that $f_k\in L^p$ for $1\le p <\infty$, $f_k\to0$ in $L^p$ for $1\le p < p_0$, but $f_k$ does not converge in $L^{p_0}$. I thought of $f_k = k^{1/p_0}\chi_{(0,1/k)}$. Then $||f_k||_p=k^{1/p_0- 1/p}$. So $f_k\in L^p$ for $1\le p <\infty$. Also for $1\le p <p_0$, $||f_k||_p\to0$. For $p_0<p$, $||f_k||_p\to\infty$. So suppose there exists $f$ such that $||f_k-f||_p\to 0$. Then by Minkowski's inequality, $||f_k||_p \le ||f_k-f||_p +||f||_p$. That means $||f||_p$ is unbounded. A contradiction. Is my proof correct? Is there any flaw? Thanks! EDIT: OK. I realized this shows $f_k$ doesn't converge in $L^p$ for $p>p_0$. But it's inconclusive when $p=p_0$. Any suggestion? Thanks.","['measure-theory', 'real-analysis', 'analysis', 'lebesgue-integral', 'lp-spaces']"
549503,MRB constant proofs wanted,"This article has been edited for a bounty. $C$ MRB, the MRB constant, is defined at http://mathworld.wolfram.com/MRBConstant.html . There is an excellent 56 page paper whose author has passed away. You can find it in Google Scholar ""MRB constant,"" Better yet, use the following link http://web.archive.org/web/20130430193005/http://www.perfscipress.com/papers/UniversalTOC25.pdf . You find a cached copy there. Just before the author, Richerd Crandall, died I wrote him about a possible small error. What I'm worried about is formula 44 on page 29 and below. When I naively worked formula 44 it needed a negative sign in front of it. Crandall did write me back admitting to a typo, but he died before he had a chance to correct it. 
  Is there anyone out there competent enough to check, correct and prove the corrected 
formulas for me? Thank you. I will use the proofs often and try to get the formulas published more. Here is how I worked formula 44 and got -B: (*define the Dirichlet eta function*) eta[s_] := (1 - 2^(1 - s)) Zeta[s]; (*define the higher derivatives of the eta(0)*) a[i_] := Derivative[i][eta][0]; (*Define c:*) c[j_] := Sum[Binomial[j, d] (-1)^d d^(j - d), {d, 1, j}] (*formula (44)*) N[Sum[c[m]/m!*a[m], {m, 1, 40}], 100]","['constants', 'sequences-and-series', 'recreational-mathematics']"
549527,help me understand derivatives and their purpose,"I am only starting learning calculus and it's difficult for me to understand the main concept behind calculus ideas particularly differentiation
I have searched many resources but most of them are very similar explaining things with words like ""speed"", ""rate of change"", ""tangent"" and ""function change in respect to input change""...
I know the rules of computation but  the purpose is not very clear for me I would be very grateful if somebody could help me grasp this concept and explain why one would want to compute the ""rate of change"" of a function and what exactly problem do derivatives solve. Pretend that I am very stupid (unfortunately I am :) ) and don't use any abstract concepts (even if they are  intuitive to a human being )  as ""speed"" if possible
Thanks","['calculus', 'derivatives']"
549533,Can any subset of $x$ be moved out of $x$?,"Let $x$ be a set and let $y\subset x$. Does there exist a set $z$ such that: (1) $z\cap x=\emptyset$ and (2) there exists a bijection $y \to z$ ? It is quite intuitive that the answer should be yes. My first attempt was to take a set $x'\notin x$ and to consider $z=y\times \{ x'\}$. But I am unable to show $z\cap x=\emptyset$. I could imagine a proof with the axiom of choice, but I'd prefer to avoid it if possible.",['elementary-set-theory']
549538,What does abstract algebra have to say about the determinant?,"The determinant is a homomorphism from the multiplicative monoid of matrices to the multiplicative monoid of a field (right?). I find this to be the most intuitive way to interpret some of the determinant's properties (notably the invertibility condition: obviously a matrix is only invertible if a homomorphism maps it to an invertible element of the field). So from an algebraic point of view, can anything interesting be said about the determinant? Some fairly specific technical questions: How does it fit into the big picture of all homomorphisms $M_n(\Bbb K)\to\Bbb K^\star$? Is it the only one? How are the others related to it? The invertibility condition is one of the most useful things about the determinant, but any homomorphism would give the same condition, so why use the determinant? Are there any ring homomorphisms $M_n(\Bbb K)\to\Bbb K^\star$? How does the determinant relate to them? Some vaguer, softer questions: Are there any intuitive proofs for the formulae for calculating determinants based on the fact that it's a homomorphism? This one's pretty out there. The characteristic polynomial is a polynomial with coefficients in a field which is the homomorphic image of a polynomial with coefficients in the ring of matrices. Is there any way of explaining the various relationships between a matrix and its characteristic polynomial based on the structure-preserving properties of the determinant?","['linear-algebra', 'abstract-algebra', 'determinant']"
549565,Proving that the graph of a operator is closed,"Let $E$ be a Banach space and let $T:E\mapsto E'$ be a linear operato satisfying 
$\langle Tx,x\rangle\geq0$ for all $x\in E$. How to prove that the graph of $T$ is closed?",['functional-analysis']
549579,Decomposition formulas for rotational symmetries of a cube,"I have a problem that I would like to check my work on. I am also stuck on the verifications for $E$ and $F$. Any help would be greatly appreciated. Thanks in advance. Problem statement: Let $G$ be the group of rotational symmetries of a cube, let $G_v, G_e, G_f$ be the stabilizers of a vertex $v$, an edge $e$, and a face $f$ of the cube, and let $V, E, F$ be the sets of vertices, edges, and faces, respectively. Determine the formulas that represent the decomposition of each of the three sets into orbits for each of the subgroups. Proposed solution: ...so if $G$ acts transitively on the vertices, the orbit of one (and thus any) vertex $v$ has order $8$, which means that the index of the stabilizer $[G:G_v]$ = $8$, so there are $8$ cosets of $G_v$ in G. If one knows that the rotational symmetry group of the cube is $S_4$, this tells you that $G_v$ has order $3$. $G$ also acts transitively on the faces, so $G_f$ (for any face $f$) has order 4. Finally, $G$ also acts transitively on the edges, so $G_e$ (for any edge $e$) has order $2$. The class equation for these subsets of {faces, vertices, edges} is particularly simple. It occurs to me, that I'm being asked to compute the orbits of $V,F,E$ under the respective actions induced by each group: $G_v,G_f,G_e$ for some particular stabilizer in each set. This is somewhat of a different matter. For example, say $V = {v_1,v_2,v_3,v_4,v_5,v_6,v_7,v_8}$. $G_{v_1}$ fixes $v_1$, so it's orbit is: ${v_1}$. If the opposite vertex is $v_7$, $G_{v_1}$ also fixes $v_7$, so its orbit is: ${v_7}$. The other two orbits have to have order $3$, since there are no other points fixed by $G_{v_1}$, except $v_1$ and $v_7$ and the size of the orbits has to divide $|G_{v_1}|$ (it helps to think about WHICH rotations $G_{v_1}$ must be: rotations about the axis between $v_1$ and $v_7$). What about for E and F?","['symmetry', 'abstract-algebra', 'combinatorics']"
