question_id,title,body,tags
272998,Easiest way to simplify very big complex number,"I don't know if this question has a solution, but I'll ask it anyway.I often come across complex numbers in the form $$
   \frac{(a_0 + ib_0)}{(a_1 + ib_1)(a_2 + ib_2)(a_3 + ib_3)}
$$ but I need these in the normal form of $$
    a + ib
$$ Now the way I solve this is that I multiply out the denominator and then rationalise the result but the problem is because the factors $a_i$ and $b_i$ are often a little complex this method is prone to mistakes.So I would like to know if there is an easier way I can do this by hand or if there is a way that I can check that my final answer is correct.","['complex-numbers', 'complex-analysis']"
273000,Is it possible to reverse this sequence of permutations?,"Let 
$ S = (a_1, a_2, ..., a_N) $ be a finite (arbitrarily long) sequence of elements, and let $p_1, p_2, ..., p_n $ be the first $n$ prime numbers, with $n \ge 3$. We apply a sequence of permutations to $S$ as follows. First, we take every element in $S$ whose index is congruent with 1 modulo 2, and we rotate them within themselves $A^2_1$ positions (where $A^2_1$ is an integer in $[0, N/2)$). For instance, if $S = (a,b,c,d,e,f)$, and $A^2_1=2$, the result would be $(\mathbf c,b,\mathbf e,d,\mathbf a,f)$. In the second place, we take every element in the sequence obtained whose index is congruent with $0$ (that is, the rest), and rotate them within themselves $A_0^2$ positions (where $A^2_0$ is an integer in $[0,N/2)$); that will be $S_1$. Following the previous example, rotating with $A^2_0 = 1$ would bear $S_1 = (c,\mathbf f,e,\mathbf b,a,\mathbf d)$. Now, we take every element in $S_1$ with index congruent with 1 modulo 3, and we rotate them within themselves $A^3_1$ positions; afterwards, every element with index congruent with 2 modulo 3, $A^3_2$ positions, and finally, every element with index congruent with 0 modulo 3, $A^3_0$ positions. $A_i^3$ is an integer in $[0,N/3)$. Continuing the example, assuming $A^3_1 = 1, A^3_2 = 0, A^3_0 = 1$, we would obtain $(b,f,d,c,a,e)$. This process is repeated for every prime up to $p_n$, and let $S_n$ be the result. (Edited: see below)
My question is: assuming $n$ and $S_n$ are known, how much additional information would be necessary to calculate the coefficients ? (Edited: see below) By additional information I mean, for example, knowing the initial positions (in $S$) of some elements in $S_n$. I have been working for days on this, but my current option, which is straightforward using systems of equations, does not seem t otake me anywhere since I don't know which coefficients are being used in each case. Is there any other approach that I should consider? Apologies for my English, and sorry if this is not the correct stackexchange site for this question. EDIT: As Alexander pointed, coefficients would not be unique (see his example below), so to state it more accurately: would it be possible to obtain the original $S$ given $n, S_n$, and some additional information? This problem is related to a cryptography project, where I intend to cypher a message by rearranging it, using coefficients as a key. This means that, even if the original permutation (or any complete set of coefficients) were impossible to find, any way to determine information on them, or bounding them, would greatly hurt the scheme. I know this is not the place for crypto problems, but maybe explaining the objective would be useful to anyone trying to answer.","['permutations', 'linear-algebra', 'finite-groups']"
273004,Irrational Numbers Containing Other Irrational Numbers,Does $ \sqrt{2} $ contain all the digits of $ \pi $ in order? Does it contain all the digits of $ \pi $ in order an infinite number of times? Does $ \pi $ contain all the digits of $ \sqrt{2} $ in order?,"['pi', 'sequences-and-series', 'irrational-numbers', 'real-analysis']"
273013,Cauchy's Integral Formula - Related,"We know from Cauchy's Integral formula that if $f:D \rightarrow \mathbb C$ is holomorphic and $\gamma$ is some closed simple curve in the disc $D$, that
$$
f(z) = \frac{1}{2\pi i}\int_\gamma \! \frac{f(\zeta)}{\zeta-z} \, d\zeta
$$
for all $z \in D$ with $z$ inside of the image of $\gamma$.  If instead of being holomorphic $f$ is merely continuous on the image of $\gamma$, we still get a holomorphic function
$$
F(z) = \int_\gamma \! \frac{f(\zeta)}{\zeta-z} \, d\zeta.
$$
My question is: what do we know about how $f$ and $F$ will relate?",['complex-analysis']
273015,Martingale preservation under independent enlargement of filtration,"I think this is probably a very easy question but I haven't worked with $\sigma$-algebras in depth for a long time now so am finding myself a little rusty. Would be very grateful if someone could give me a (careful) proof of the following (I'm pretty sure it's true!). I guess I'm missing the right way of characterising the elements of the join of two $\sigma$-algebras appropriately. Let $M_t$ be a martingale with respect to the filtration $\mathcal{F}_t$ on some probability space $(\Omega, \mathcal{F}, P)$. Assume that $\mathcal{G}_t \subseteq \mathcal{F}$ where for each $t \geq 0$, $\mathcal{G}_t$ is independent of $\mathcal{F}_t$ and let $\mathcal{H}_t := \mathcal{F}_t \vee \mathcal{G}_t$. Then $M_t$ is also a martingale with respect to $\mathcal{H}_t$. Thanks!","['probability-theory', 'martingales', 'measure-theory', 'probability']"
273042,Does $\int_0^\infty \frac{x\arctan x}{\sqrt[3]{1+x^4}}dx$ converge?,"I have to determine whether $$\int_0^\infty \frac{x\arctan x}{\sqrt[3]{1+x^4}}dx$$ converges or not. I suspect it doesn't because $\arctan x$ is very close to $\pi/2$ as $x$ goes to infinity, and $$\int_0^\infty \frac{x}{\sqrt[3]{1+x^4}}dx=\infty$$ because, for example, $$\frac{x}{\sqrt[3]{1+x^4}}>\frac{x}{\sqrt[3]{2x^4}}=(2x)^{-1/3}$$ for sufficiently large $x$. But I don't know how to bound $\arctan x$ from below for this to work. I also suspect that there is something more refined than the comparison test to this problem. I don't really know the context in which this integral came up, because I don't attend the course, so I don't know what methods I should try.","['improper-integrals', 'real-analysis']"
273054,How to find Matrix Inverse over finite field?,"How to find matrix Inverse over finite field? I am using MATLAB, and I know gf() in MATLAB can enable me to do linear algebra operations over finite field $F_{2^m}$ for some m. However, if I want to find the matrix inverse over finite field $F_p$ for some prime $p\neq 2$, how should I do in MATLAB and on the paper? For example, if $p=11$ and if matrix A is: $$\begin{bmatrix}2&1&2\\1&2&9\\1&2&7\end{bmatrix}$$ I need to derive its inverse $A^{-1}$ as: $$\begin{bmatrix}8&6&1\\7&9&10\\0&6&5\end{bmatrix}$$","['finite-fields', 'linear-algebra']"
273056,"Calculate $\int_{\pi^2}^{4\pi^2} \frac{\cos(\sqrt{x})}{\sqrt{x}} \,dx$","I am trying to calculate $$\int_{\pi^2}^{4\pi^2} \frac{\cos(\sqrt{x})}{\sqrt{x}} \,dx.$$
I calculated the integral and got $2\sin(\sqrt{x})$ as a result, but for $x=\pi^2$ and $x=4\pi^2$ we get that $2\sin(\sqrt{\pi^2})=0$ and $2\sin(\sqrt{4\pi^2})=0$ So the Riemann integral will be $0-0=0$ which is not true, as you can see from ploting $2\sin(\sqrt{x})$. Any help will be much appreciated!","['calculus', 'integration']"
273061,How to randomly construct a square full-ranked matrix with low determinant?,"How to randomly construct a square (1000*1000) full-ranked matrix with low determinant? I have tried the following method, but it failed. In MATLAB, I just use: n=100; A=randi([0 1], n, n); while rank(A)~=n A=randi([0 1], n, n); end The above code generates a random binary matrix, with the hope that the corresponding determinant can be small. However, the determinant is usually about 10^49, a huge number. Not to mention when n>200, the determinant is usually overflowed in MATLAB. Could anyone have comments how I can generate matrix (could be non-binary) with very low determinant (e.g. <10^3)?","['linear-algebra', 'matlab', 'random', 'determinant']"
273068,Self-maps of the Cantor set,"Let $X$ and $Y$ be homeomorphic to the Cantor set and pick $x_0\in X$. Suppose $f\colon X\to Y$ is a continuous function such that $f\upharpoonright X\setminus\{x_0\}$ is injective. Must $f$ be injective? Well, $X$ is disconnected so we can't apply the Darboux property directly.","['general-topology', 'continuity', 'real-analysis']"
273081,Problem 4 chapter 2: functional analysis (Rudin),"$L^1$ , $L^2$ : usual Lebesgue spaces on the unit interval. Show that $L^2$ is of the first category (meager) in $L^1$ , in three ways: (a) Show that $F_n:=\{f:\int|f|^2 \leq n\}$ is closed in $L^1$ but has empty interior. (b)Put $g_n=n$ on $[0,n^{-3}]$ , and show that $\int fg_n \rightarrow 0$ $\forall f \in L^2$ , but not for every $f\in L^1$ . (c) Note that the inclusion map  of $L^2$ into $L^1$ is continuous but not onto. Do the same for $L^p$ and $L^q$ if $p<q$ .","['general-topology', 'lp-spaces', 'functional-analysis', 'real-analysis']"
273087,Are there non-Hausdorff examples of maximal compact topologies in the lattice of topologies on a set?,"In the lattice of topologies on a set $X$, the compact topologies are a lower set in the lattice, while the Hausdorff topologies are an upper set. A result of this theorem is that the compact Hausdorff topologies are maximal elements in the set of compact topologies and minimal elements of the set of Hausdorff topologies in this lattice. I have been failing to construct an example of a maximal compact topology that is not Hausdorff, but I feel like I am just lacking imagination - it seems unlikely that all maximal compact topologies are Hausdorff. Finite topologies won't work, since the only Hausdorff topology on a finite set is the discrete topology, and, as the maximal element in the lattice, the only maximal compact topology. My intuition is that there must be such examples, but it seems just possible that if a compact set is not Hausdorff, we might be able to create a new compact topology that is larger in the lattice. There is the obvious dual question, too: Is there a minimal element of the set of Hausdorff topologies which is not compact? Just to make the problem self-contained, the result referenced above is: A continuous bijection from a compact space to a Hausdorff space is a
  homeomorphism. If $(X,\tau)$ is compact and Hausdorff, and $\tau\subseteq \tau'$ with $\tau'$ also a compact topology, then the identity function $(X,\tau')\to(X,\tau)$ is a continuous bijection from a compact space to a Hausdorff space, so it must be a homeomorphism, which implies $\tau=\tau'$. Similarly, a compact Hausdorff topology is minimal Hausdorff topologies.","['general-topology', 'compactness']"
273088,Second-Order Differential Equation--Frobenius Method,"I'm studying for a qualifying examination and am stuck on the following question.  Could anyone give me some help? $$y''+\frac{\sin x}{x}y'+\frac{2\cos(x+x^2)-\frac{2}{(x-1)^2}+4x}{x^2}y=0$$ Find all singular points of the equation and classify them as regular/irregular.  Then find the first term in a series in powers of $x-1$ for each of two linearly independent solutions as $x\rightarrow1$. I think the singular points are 0 and 1, and they are both regular.  But I am having some trouble with the series solution.",['ordinary-differential-equations']
273091,Rudin Theorem 3.27,"Theorem 3.27 of Rudin's book Principles of mathematical analysis at pages 61-62 states that, Suppose $a_1\ge a_2\ge a_3\ge \cdots \ge 0.$ Then the series $\sum_{n=1}^{\infty}a_{n}$ converges if and only if the series
$\sum_{k=0}^{\infty}2^{k}a_{2^{k}}=a_{1}+2a_{2}+4a_{4}+8a_{8}+\cdots$ converges. I could follow all of the arguments except the the last sentence, which is By (8) and (9), the sequences $\left\{ s_{n}\right\}$ and $\left\{ t_{k}\right\}$ are either both bounded or both unbounded. Here (8) and (9) are (8) For $n<2^k$, $s_n \le t_k$. (9) For $n>2^k$, $2s_n \ge t_k$. where 
$s_{n}=\sum_{i=1}^{n}a_{i}$, $t_{k}=\sum_{i=0}^{k}2^{i}a_{2^{i}}.$ Why are the two sequences either both bounded or both unbounded? The (8) seems to imply that if $t_k$ converges, then $s_n$ converges. The (9) seems to imply that if $s_n$ converges, then $t_k$ converges. I could not further more arguments to see how the last sentence works. Thank you for any help. BTW, for $n=2^k$, it seems like $s_n \le t_k$.",['real-analysis']
273092,Is the zero set of a non zero real valued harmonic function discrete?,"It is a basic fact that the zero set of a non zero holomorphic function defined on a open set $A$ is discrete. By a result in Rudin's textbook on ""Real and Complex Analysis"", we know that any real valued harmonic function $u$ is locally the real part of some holomorphic function, so I ask the following question: Is the zero set $Z(u)$ of a non zero real valued harmonic function $u$ defined on open set $A\subset \mathbb{C}$ discrete? Note that if $u$ vanishes on a nonempty open set $O\subset A$, then write $f=u+iv$ to be the holomorphic function, then Cauchy-Riemman's theorem implies that $v=0$ on $O$, so $f=0$ on $O$, then $f=0$ on $A$.","['harmonic-analysis', 'complex-analysis', 'analysis']"
273097,Interpolating between Krull-Schmidt and Jordan-Holder,"Define a group $G$ to be semidirect-simple if it cannot be written as a semidirect product in a nontrivial way. (This is not a standard term.) Suppose that
$$G_1 \ltimes (G_2 \ltimes (G_3 \ltimes ( \cdots \ltimes G_r ) \cdots ) ) \cong H_1 \ltimes (H_2 \ltimes (H_3 \ltimes ( \cdots \ltimes H_s ) \cdots ) )$$
with $G_1$, $G_2$, ..., $G_r$, $H_1$, $H_2$, ..., $H_s$ semidirect-simple. (Of course, the notation $\ltimes$ implicitly includes choices of various actions.) Is it true that $r=s$ and $(G_1, G_2, \ldots, G_r)$ is a permutation of $(H_1, H_2, \ldots, H_s)$? As mentioned in a previous question , I'm brainstorming group theory problems and tossing up the ones I don't know the answers to.",['group-theory']
273099,"For $n∈ N$, determine the real part of $(1 + i\sqrt{3})^{n}$","For $n∈ N$, determine the real part of $(1 + i\sqrt{3})^{n}$. I just can't find the regularity within it. Thanks.",['complex-analysis']
273100,"For a first order inhomogenous system of linear differential equations, what is a good way of defining resonance?","I apologize for the title being slightly unclear (at least to me it seems so), so if anyone has a better suggestion feel free to change it. Anyways, for example, when dealing with a second order differential equation of the form:
$$ ay'' + by' + cy = f(x) $$
with solutions $y_1(x)$ and $y_2(x)$ we can say that there is resonance in the system provided that $f(x)$ is linearly dependant on $y_1(x)$ and/or $y_2(x)$. Now consider the linear system 
$$\textbf{x}' (t)  + \textbf{P}\textbf{x}(t) = \textbf{z}(t)$$
where $\textbf{x}(t)$, $\textbf{z}(t)$ are n-vectors, $\textbf{P}$ is a n-by-n matrix and $\textbf{z}(t)$ is a forcing term of the system. As the solutions are then of the form
$$\textbf{x}_i(t)=a_i \textbf{v}_i e^{\lambda_i t} $$
where the $\lambda_i$ and $\textbf{v}_i$ are eigenvalues and eigenvectors of $\textbf{P}$ respectively (assuming the eigenvectors are orthogonal), can we say that resonance is occuring when the $\textbf{z}(t)$ is linearly dependant of the solutions $\textbf{x}_i(t)$?","['matrices', 'linear-algebra', 'ordinary-differential-equations']"
273117,Compact subspace of a Banach space .,"The following statement doesn't make sense to me, can someone justify it to me ? If $K$ is a compact subset of a Banach space $Y$ then there exists for  $\epsilon > 0 $ a finite dimensional subspace $Y'$ of $Y$ such that $d(x, Y') < \epsilon $ for every $x \in K $ , where as usual , $d(x, Y')=\inf \{\|x-y\|,  y \in Y'\}$ . This is pretty surprising ! (if it's true)","['compactness', 'functional-analysis', 'banach-spaces']"
273120,Notation for probability density,"On one of my other questions here, I was criticized (and rightly so, as it was the source of my mistake) for using this notation for a continuous random variable $X$ with pdf $f(x)$:
$$\mathbb{P}\{X\in dx\} = f(x) \mathop{dx} .$$
I was taught this notation by my teacher. The purpose of this notation is to stress the fact that technically, $\mathbb{P}\{X=x\}=0$ if $X$ is continuous. I believe the notation is shorthand for $\mathbb{P}\{X\in [x, x+dx)\} = f(x) \mathop{dx}$. As I am only familiar with this notation and didn't know that other people did not use it, I would really appreciate it if someone could give me a better sense of what notation is more accepted/used. Is the $f$ and $F$ notation of pdf and cdf respectively widely used? Given a pdf $f(x)$ for a continuous random variable $X$, its cdf is $F(x)=\int_{-\infty}^x f(t)dt=\mathbb{P}\{X<x\}$ (thanks for catching the typo, André!), which corresponds to the discrete case where $F(x) = \sum_{k=0}^x f(x) = \mathbb{P}\{X\le x\}$. Is there just no continuous analog for the discrete expression of $\mathbb{P}\{X=x\}=f(x)$? One piece of advice that I was given by another user was to deal primarily with cdfs and not with pdfs. Thank you in advance, and apologies if this was not the right place to ask this question.","['notation', 'probability']"
273155,Where have I made my mistake in calculating $P^{-1}AP$?,"I have $$Q = \begin{pmatrix} -\mu & \mu \\ \lambda & -\lambda \end{pmatrix}$$ and I want to work out the value of $\mathbb{P}(t) = \exp(Qt)$ So I diagonalised $Q$ and then worked out the exponential of the diagonal matrix. I got this to be: $${Q}t = \pmatrix{-\mu t &\mu t \\ \lambda t & -\lambda t} = \pmatrix{1 & -\frac{\mu }{\lambda } \\ 1 & 1}^{-1} \cdot \pmatrix{0 & 0 \\ 0 & -t(\lambda + \mu)} \cdot \pmatrix{1 & -\frac{\mu }{\lambda } \\ 1 & 1}.$$ So using the middle matrix, I got $$\exp (Qt) = \pmatrix{1 & 0 \\ 0 & \exp(-t(\lambda + \mu))} = \pmatrix{1 & 0 \\ 0 & \exp(T)},$$ where $T = -t(\lambda + \mu)$. Then, using $\exp (P^{-1}AP) = P^{-1}e^AP$, I was supposed to get $$\mathbb{P}(t) = \exp({Q} t) = \frac{1}{\lambda + \mu}\pmatrix{\lambda + \mu \exp(T) & \mu - \mu \exp(T) \\ \lambda - \lambda\exp(T) & \mu + \lambda\exp(T)}.$$ This is what I did. To first work out $P^{-1}$ I got $$P^{-1} = \frac{1}{1 + \frac{\mu}{\lambda}} \pmatrix{1 & \frac{\mu}{\lambda} \\ -1 & 1} = \frac{\lambda}{\lambda + \mu} \pmatrix{1 & \frac{\mu}{\lambda} \\ -1 & 1}$$ Then doing $P^{-1}e^A$ gave me $$\frac{\lambda}{\lambda + \mu} \pmatrix{1 & \frac{\mu}{\lambda} \exp (T) \\ -1 & \exp (T)}$$ Then doing this times $P$ gave me $$\frac{\lambda}{\lambda + \mu} \pmatrix{1 + \frac{\mu}{\lambda} \exp (T) & -\frac{\mu}{\lambda} + \frac{\mu}{\lambda} \exp (T) \\ -1 + \exp (T) & \frac{\mu}{\lambda} + \exp (T)}$$ Multiplying through by $\lambda$ gives me $$\frac{\lambda}{\lambda + \mu} \pmatrix{\lambda + \mu \exp (T) & - \mu - \mu \exp (T) \\ - \lambda + \exp(T) & \mu + \lambda \exp (T)}$$ Clearly it's started going wrong in the matrix before this but I can't see where I've made my mistakes. Can someone help please? Thank you","['matrices', 'linear-algebra']"
273169,Number of Homomorphisms from $\Bbb{Z}_m$ to $\Bbb{Z}_n$,"This question coutesy of Allan Clark's ""Elements of Abstract Algebra"" (60$\zeta$). Find the number of homomorphisms from $\Bbb{Z}_m\to \Bbb{Z}_n$ as a function of $m$ and $n$. This is stumping me, can anyone help?","['finite-groups', 'group-theory', 'abstract-algebra']"
273174,Homotheties and Geodesics,"A homothety is a smooth map between Riemannian manifolds $f:(M,g)\rightarrow (N,h)$ such that $f^*h=cg$ for some $c\ne 0$. My questions is: how are the geodesics on these two spaces related? Can we say that the geodesics on $(N,h)$ are given by $\beta (t)= (f\circ \alpha)(t/\sqrt{c})$ where $\alpha $ is a geodesic on $(M,g)$?",['differential-geometry']
273181,"If $M$ is an artinian module and $f : M\to M$ is an injective homomorphism, then $f$ is surjective.","If $M$ is an artinian module and $f: M\to M$ is an injective homomorphism, then $f$ is surjective. I somehow found out that if we consider the module $\mathbb Z_{p^{\infty}}$ denoting the submodule of the $\mathbb{Z}$-module $\mathbb{Q/Z}$ consisting of elements which are annihilated by some power of $p$, then it is artinian, but if we have the homomorphism $f(\frac{1}{p^{k}})=\frac{1}{p^{k+1}}$, then we get a $\mathbb{Z}$-module homomorphism, but this map is not surjective, because $\frac{1}{p}$ has no preimage. I would be very grateful if someone can tell me what is wrong with this counterexample? And how to prove the proposition above if it is correct? Thanks.","['modules', 'abstract-algebra']"
273184,Can you identify the shape of this curve?,"The following curve shows an initial segment of smooth decline, followed by a set of nearly equal data points, followed by another smooth decline. I am looking for a function that could best fit these data points. Any suggestions?",['functions']
273188,Proof of a trigonometric inequality,"Does anyone know the proof of the following inequality $$\sin(A)\sin(B)\sin(C)\le\left(\frac{3\sqrt{3}}{2\pi}\right)^3ABC$$ where $A,B,C$ are the vertex angles of a triangle.","['geometry', 'trigonometry', 'inequality']"
273204,Exercise on a holomorphic $f$ on a strip satisfying $|f(z)|\leq A(1+|z|)^\eta$,"Consider the following problem: If $f$ is a holomorphic function on the strip $S=\{z=x+iy:-1<y<1,x\in{\Bbb R}\}$ with $$
|f(z)|\leq A(1+|z|)^{\eta} \tag{1}
$$ for all $z\in S$ , where $\eta$ is a fixed real number, show that for each integer $n\geq 0$ there exists $A_n\geq 0$ so that $$
|f^{(n)}(x)|\leq A_n(1+|x|)^{\eta}\tag{2}
$$ for all $x\in{\Bbb R}$ . Let $C_R=\{z\in{\Bbb C}:|z|=R\}$ . Then for every $0<R<1$ , by Cauchy inequality, we have $$
|f^{(n)}(x)|\leq\frac{n!}{R^n}\|f\|_{x+C_R}\leq \frac{n!}{R^n}A(1+|x|+R)^\eta\tag{3}
$$ where $x+C_R=\{x+z:z\in C_R\}$ and $\|f\|_{x+C_R}=\sup\{f(z):z\in x+C_R\}$ . But I don't see how I can get rid of the $R$ here. Any help?",['complex-analysis']
273225,Why the number of points where $f$ ramifies is finite?,"I know roughly that there is a theorem in complex analysis saying that if $f$ has degree $e_x>1$ at point $x$, which is $f(z)=(x-z)^{e_x}g(z)$, then $f^{-1}(y)$ has $e_x$ different preimages in a neighborhood of $y$. In a complex Riemann surface, we have the same result considering $f$ in the local coordinates. We call that $f$ ramifies at point $x$ if $e_x>1$. I was told that the number of points where $e_x>1$ is finite. Can anyone tell me why? Is this result valid only in compact Riemann surface or generally? update: I realized that $f$ has digree $e_x$ at $x$ sould be $f(z)-f(x)=(z-x)^{e_x}g(z)$ rather than what I originally posted. Sorry for trouble..",['complex-analysis']
273226,Outward vectors to an Ellipsoid and Euclidean metrics,"I'm reading Arnold's proof of the topologically equivalence of the equations $\dot{x}=Ax$ and $\dot{x}=x$ when all the eigenvalues of the $n \times n$-matrix $A$ have positive real part. The proof is based in the construction of a Lyapunov function and the equivalence of these statements: There exists and Euclidean metric $g$ on $R^n$ such that $g(Ax,x)>0$ (for $x \neq 0$). There exists a positive-definite quadratic form $F$ on $R^n$ whose directional derivative in the direction of $Ax$ is positive. There exists an ellipsoid in $R^n$ with center at $0$ such that at each point $x$ the vector $Ax$ is directed outward. I can see the equivalence of the first two but I don't really understand the third one, I guess the ellipsoid is defined by $F(x)=g(x,x)=$constant, but I can't see why it is equivalent to the first statement for example.","['geometry', 'linear-algebra', 'ordinary-differential-equations', 'differential-geometry']"
273227,Helping my daughter with her homework: solving an algebra word problem. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Three bags of apples and two bags of oranges weigh $32$ pounds. Four bags of apples and three bags of oranges weigh $44$ pounds. All bags of apples weigh the same. All bags of oranges weigh the same. What is the weight of two bags of apples and one bag of oranges?",['algebra-precalculus']
273231,Why there is no meromorphic function of degree $d=1$ on any compact Riemann surface of positive genus?,"We have the Riemann-Hurwitz formula: $$
2g_X-2=d(2g_Y-2)+\sum_{x\in X}(e_x-1)
$$ It is said that from this we can deduce that there is no meromorphic function of degree $d=1$ on any compact Riemann surface of positive genus. I wonder how? If I let $d=1$, I can get
$$
2(g_X-g_Y)=\sum_{x\in X}(e_x-1)
$$ but what's next? Maybe I lack some knowledge about meromorphic function on Riemann surface, anyone can help?","['riemann-surfaces', 'complex-analysis']"
273239,two problems on compactness and connectedness of the space of matrices,"Consider the set of all $n×n$ matrices with real entries as the space $\mathbb{R}^{n^2}$. Which of the following sets are compact? (a) The set of all orthogonal matrices. (b) The set of all matrices with determinant equal to unity. (c) The set of all invertible matrices. In the set of all $n×n$ matrices with real entries, considered as the space $\mathbb{R}^{n^2} $, which of the following sets are connected? (a) The set of all orthogonal matrices. (b) The set of all matrices with trace equal to unity. (c) The set of all symmetric and positive definite matrices. determinant mapping is continuous.
so 1.(c) is not true as the image is not compact. but not sure for others.
and 2.(a) is not true as the image is not connected. but not sure for others.",['general-topology']
273252,Calculating a limit in two variables by going to polar coordinates.,"I have this limit to calculate: $$l=\lim_{(x,y)\to(0,0)}\frac{\sin(x^2y+x^2y^3)}{x^2+y^2}$$ I solve it by going to the polar coordinates. Since $(x,y)\to 0$ means the same as $\sqrt{x^2+y^2}\to 0$, I get (after dealing with the sine in a standard way), $$l=\,\lim_{r\to0}\frac{r^3\cos^2\theta\sin\theta+r^5\cos^2\theta\sin^3\theta}{r^2}
=\lim_{r\to0}\,r(\cos^2\theta\sin\theta+r\cos^2\theta\sin^3\theta)=0.
$$ I'm quite sure this actually works, but the free variable $\theta$ bothers me. It seems to me that some explanation for it is needed since it's not ""for every fixed $\theta$"", which I think would be the standard interpretation of this formula. How should I phrase this solution so it's rigorous?","['polar-coordinates', 'limits']"
273267,"Is my solution correct to prove that $f (x) = 0$ for all $x \in [a, b]$? [duplicate]","This question already has answers here : Closed 11 years ago . Possible Duplicate: $f\geq 0$ and $\int_a^b f=0$ implies $f=0$ everywhere on $[a,b]$ Is this a correct solution? Thanks for your help",['real-analysis']
273275,Generating function for the divisor function,"Earlier today on MathWorld (see eq. 17)  I ran across the following expression, which gives a generating function for the divisor function $\sigma_k(n)$: $$\sum_{n=1}^{\infty} \sigma_k (n) x^n = \sum_{n=1}^{\infty} \frac{n^k x^n}{1-x^n}. \tag{1}$$ (The divisor function $\sigma_k(n)$ is defined by $\sigma_k(n) = \sum_{d|n} d^k$.) How would one go about proving Equation (1)? (For reference, I ran across this while thinking about this question asked earlier today.  The sum in that question is a special case of the sum on the right side of Equation (1) above.)","['generating-functions', 'analytic-number-theory', 'number-theory']"
273276,Understanding a proof in Spivak,"This is from Spivak's chapter 23. He wants to show that the function $$f(x) = \sum_{n=1}^{\infty} \frac{1}{10^n}\{10^nx\}$$ is continuous everywhere, but differentiable nowhere I have only an excerpt of the proof and that is all I need because my question lies in his choice of $h_m = 10^{-m}$. I know he wants a decreasing sequence such that it converges to $0$ as he stated, but why $10^{-m}$ in particular? Why not something like $1/m^2$? And why is the difference quotient $$\lim_{m\to\infty}\dfrac{f(a+h_m)-f(a)}{h_m}$$, but not $$\lim_{n\to\infty}\dfrac{f(a+h_n)-f(a)}{h_n}$$ Why the dependence on a new number $m$? Also why does he think it is sufficient for $0 < a \leq 1$? Finally, I may be wrong but he set $$\{ 10^n (a + h_m)\} + \{ 10^n a\} = 0$$ for the reason that the partial sums of the convergent sequence (though it is finite) must go to $0$? EDIT : I will write out the rest of the proof later today.","['calculus', 'real-analysis']"
273285,Failure criteria for a collection of independent evolving discrete random variables,"I have built a computer model that contains a collection of independent discrete random variables. They each have values of between $0$ and $k$ where $k$ is between $4$ and $15$ and is constant for each variable. These variables initially start at a certain value (different for each) with a probability of $1$ and evolve probabilistically in discrete time steps based on another discrete random variable. So, in symbols (this is my first try at this and my math notation is rather rusty so any feedback would be appreciated, if anyone can tell me why I get $t-1$ when I put in $t+1$ in the second equation that would be good) $$\mathcal{T}_{(t)}=\sum_{i=1}^{35}\mathcal{X}_{i(t)}$$ and $$\mathcal{X}_{i(t+1)}=\mathcal{X}_{i(t)}\times\mathcal{Y}_{i(t)}$$ where $X_{i(t)}$ is the $i$th random variable at time $t$ and has a range of 0 to $k$ $\mathcal{T}_{(t)}$ is the a discrete rendom variable total at time $t$ and has a range of $0$ to $290$. $Y_{i(t)}$ is another (well known but changeable) random variable that acts on $X_{i(t)}$ to evolve the solution The model is working quite nicely and each variable happily evolves in ignorance of all the others. What I am interested in is the probability of the sum of these random variables falling below a threshold value of $90$ for time $t$. In the real world these variables represent the status of a game and if the total falls below the threshold then one of the players wins and the game is over. In symbols $$P(\mathcal{T_{(t)}})\lt90 $$ If I simply continue the evolution, then there will be some states at $t+1$ with $\mathcal{T_{(t)}}\ge90$ that were derived from a state at $m$ with $\mathcal{T_{(t)}}\lt90$. In a naive treatment these would be considered non-winning states even though they derived from a state where the game ended the turn before. I think that the evolution of each variable needs to take into account the sum of all the other variables (or derive it from the sum of all the variables less its own contribution) but I am not sure how to proceed. Any guidance would be appreciated. My thinking on this so far: At each time $t$ calculate each $$S_{j(t)}=\sum_{i=1}_{i{\neq}j}^{35}\mathcal{X}_{i(t)}$$ and $$P_j(P(\mathcal{T_{(t)}})\lt90|S_{j(t)}) $$ for each possible value of $X_{j(t)}$ and modify $X_{j(t)}$ by this probability so that $$P(X_{i(t)})=1-P_j(P(\mathcal{T_{(t)}})\lt90|S_{j(t)}) $$ this would be the distribution given that the game had not ended and could be used to move on to $t=t+1$. So we can then calculate $$P(E_{(t)})=P(E_{(t-1)})+P(\mathcal{T_{(t)}})\lt90 $$ where $E_{(t)}$ is the event end of the game at or before time $t$ Is this a sound approach?","['probability-theory', 'stochastic-processes', 'probability']"
273295,Solve differential equation y'' + 4y' + 5 =0,"How to go about solving this: $$y'' + 4y' + 5 = 0$$ $$y = Ae^{px} + Be^{qx}$$ I know the following: p and q are solutions to the characteristic equation 
$am^2 + bm + c = 0$ So in this case
$m^2 + 4m + 5 = 0$ However I do not know what to do after this.",['ordinary-differential-equations']
273298,Derivative of $\sin^4(x) -\cos^4(x)$,Find the derivative of $\sin^4(x) -\cos^4(x)$. My attempt: $\frac{d}{dx}(\sin^4(x) -\cos^4(x)) = 4\sin^3(x)\cos(x) +4\cos^3(x)\sin(x). $ The problem is I need to simplify this to its simplest form and I just do not know how to do it to this equation. Update: $4\sin^3(x)\cos(x) +4\cos^3(x)\sin(x) =\sin(x)\cos(x)[4(\sin^2(x)+\cos^2(x))] = 2\sin(2x).$,"['algebra-precalculus', 'derivatives']"
273307,What is the probability that the resulting four line segments are the sides of a quadrilateral?,"Question: Divide a given line segment into two other line segments. Then, cut each of these new line segments into two more line segments. What is the probability that the resulting line segments are the sides of a quadrilateral? I am stuck on this problem. I think I am close, but I am not sure if it is correct. Any help or conformation on this would be helpful. My thoughts on the problem: Let us say that the line segment is of length 1. The only restriction for these for line segments to form a quadrilateral is that no one side > .5 (correct me if I am wrong). With our first cut we have two smaller line segments, one larger than the other. We only need to look at the longer on of these two line segments. Let us call $y$ the smaller line segment and $x$ the larger one. $x$ will be between 0.5 and 1. When we cut each of these new line segments we need to find where it does not work for it to be a quadrilateral. We only have to look at $x$. Let us call $a$ the length that we cut. If we use the example $x=0.6$ we can see that $a$ cannot be less than 0.1 or greater than 0.5. We can generalize this for any $x$. $a$ cannot be less than $(x-1/2)$ or greater than $1/2$. This is where I get stuck. I believe that the probability for any $x$ value that these four line segments will not be a quadrilateral is $$\frac{2(x-1/2)}{x}$$ If this is correct is the total probability that it cannot be a quadrilateral $$\int\limits_{1/2}^1\frac{2(x-1/2)}{x}\mathrm{d}x?$$ Any help is much appreciated. Thank you","['geometry', 'calculus', 'probability']"
273327,Determining if something is a characteristic function,"Suppose $X$ is a continuous random variable with pdf $f_X(x)$. We can compute its characteristic function as $\varphi_X(t)=\mathbb{E}[e^{itX}].$ Question: Given a function, say $\psi(t)$, how does one show that it is a characteristic function? (Typed this on my phone - my apologies if there's poor formatting)","['probability-theory', 'fourier-analysis', 'characteristic-functions']"
273330,"why is a nullary operation a special element, usually 0 or 1?","Does a nullary operation mean an operation not taking any argument? Then why is a nullary operation a special element, usually 0 or 1, in an algebraic structure? Thanks!","['abstract-algebra', 'universal-algebra']"
273395,Linear Algebra Text Problem,"We have specified number of light bulbs. In addition to the array there are buttons.  Pressing the button changing state of light bulbs which are connected to the switch. It is known that for each set of lamps exist button that is connected with the odd-number of bulbs from this set. Prove that properly pressing the buttons we can turn off all bulbs. Very nice task, but hard. I think that I can make a $Z^n$ space of bulbs, but how to prove that we have a basis of it? Or that's not a correct way? I'm looking for hints.",['linear-algebra']
273398,I want to prove that the following set is closed,"Let $A\subseteq R$ be a compact set and $B\subseteq R$ closed. Then $S=\{b\sin a;b\in B,a\in A\}$ is closed. What I have done is to consider the continuous function $$f:\mathbb{R}\times \mathbb{R}\to \mathbb{R}$$ defined by $f(x,y)=x\sin y.\;$ Then $\;S=f(B\times A).\;$ If $\,f\,$ is closed, then $\,S\,$ is closed. Is $\,f\,$ closed? ($\mathbb{R}$ is the real numbers) Thanks!",['real-analysis']
273404,"Binomial Theorem past exam question, what do I do?","I have trouble understanding what I'm supposed to do in some of these math questions. 
Here's an exam question from an old exam: Let $A$ be a set with $n$ elements. The number of subsets of $A$ with $k$ elements is ${n \choose k}$, or:
$$ C(n,k) = \frac{n!}{k!(n - k)!} $$
Show that there are as many subsets having an odd number of elements as there are subsets with an even number of elements.
HINT: use the Binomial Theorem in the form:
$$ (1 + x)^n = \sum_{k = 0}^n {n \choose k} x^k$$
Then set $x = -1$. Do I just choose an arbitrary number for $n$ then set $x = -1$ and work it out?
I don't know why I have such a problem understanding these questions. Thanks for your help.","['binomial-coefficients', 'combinatorics']"
273417,"If $f(x)+f'(x)-\frac{1}{x+1}\int_{0}^{x}f(t)dt=0$ and $f(0)=0$, then what is $f'(x)$?","$f\in C^{1}[0,\infty)$, $f(0)=0$ and 
$$
f(x)+f'(x)-\frac{1}{x+1}\int_{0}^{x}f(t)dt=0
$$
then $f'(x)=$ ? I'v tried in the following ways. First, let $F(x)=\int_{0}^{x}f(t)dt$, then we are left to solve a second order ODE with initial condition $F(0)=0$, and $F'(0)=0$, but the problem is it seems to me that it's not that easy to solve it. I hope there are some other ways to handle it that a one year students can understand. (I have tried to write $g(x)=f(x)e^x$ to rewrite the equation, but it doesn't make it easier)","['ordinary-differential-equations', 'calculus', 'integral-equations']"
273421,Finding integral $\int_{- \pi}^{\pi} \cos(mt) \cos(\lambda t) dt$,"I am a little stuck on the following problem: Prove that: $$\int_{- \pi}^{\pi} \cos(mt) \cos(\lambda t) dt = -2 \frac{(-1)^{m} \lambda \sin(\pi \lambda)}{m^2 - \lambda ^2}$$ I have used the fact that: $$\cos(mt + \lambda t) + \cos(mt - \lambda t) = 2 \cos(mt) \cos(\lambda t)$$ to set up: $$\int_{- \pi}^{\pi} \cos(mt) \cos(\lambda t) dt = \frac{1}{2} \left[\int_{- \pi}^{\pi} \cos(m + \lambda)t dt + \int_{- \pi}^{\pi} \cos(m - \lambda)t dt \right ]$$ Solving the integrals on the right, I have managed to obtain: $$\int_{- \pi}^{\pi} \cos(mt) \cos(\lambda t) dt = \frac{(m- \lambda)\sin((m + \lambda) \pi) + (m + \lambda) \sin((m- \lambda) \pi)}{m^2 - \lambda ^2}$$ However, I don't see where I go from here to get the final expression $$-2 \frac{(-1)^{m} \lambda \sin(\pi \lambda)}{m^2 - \lambda ^2}.$$ If anyone can help me out here, I would be very grateful!","['definite-integrals', 'trigonometry', 'calculus']"
273446,Convergence of the $\sum \frac{\ln(n!)}{n^{\alpha}}$,"I'm preparing to my calculus exam (it's not a homework). So I have a sum: 
$$\sum_{n=1}^{\infty} \frac{\ln(n!)}{n^{\alpha}}$$
I need to find for which values ​​of the parameter $\alpha$ the sum converges and diverges.
I tried to find some inequality to apply the comparison test, but I failed.","['sequences-and-series', 'calculus']"
273458,Regression with arbitrary norm,"I have a function $f(X,Y,Z)$, which I know is polynomial of degree $3$. I have a set of samples $(X_i,Y_i,Z_i)$ and corresponding values of $f$. My task is to find (the best approximation of) the coefficients of the polynomial with the data in hand. I can do this with least-squares approximation in Matlab but the problem is that least-squares minimizes the Euclidean distance from points to the model (i.e. the error) and I need to use totally different norm for the error than Euclidean distance. How should I approach this? In a high level the polynomial handles input and output in some space $A$ but I should choose the coefficients in such a way that the distance (error) in space $B$ would be minimal. The transformation between $A$ and $B$ is not linear, but it doesn't look too complicated (I haven't figured out all the details yet). If it matters, $X$, $Y$ and $Z$ are in the range $[0,255]$ (in $A$).","['statistics', 'matlab', 'optimization']"
273467,Brownian motion interesting question,"I found this interesting question on the internet, but unfortunately I could not solve it. What is probability that Brownian motion (starting at origin) has value 1 before having value -2?","['stochastic-processes', 'probability', 'brownian-motion']"
273475,Derived Sets in arbitrary metric space,"Edited Let us take any set $E$ in a metric space. Is it possible to find a $E'$ and $E''$ such that $E$ and $E'$ are non empty but $E''$ is empty. If so, Let us now say $E^n$ is $n$th derived set of $E$. Is a generalization possible when we can find a set $E$ such that $E^n$ is nonempty but $E^{n+1}$ is empty? P.S. By arbitrary I mean it is at least possible to find one such metric space and one such Set $E$, where the first statement might be satisfied.","['general-topology', 'real-analysis']"
273484,Why function $j(\tau)$ has degree 1?,"We have $$
j(\tau)=\frac{1}{q}+\sum_{n=0}^{\infty}a_nq^n, a_n\in\mathbb{Z},q=e^{2\pi i\tau}
$$ Then it is said that because $j$'s only pole is simple, $j$ has degree 1 as a map $j:X(\text{SL}_2(\mathbb{Z}))\rightarrow\mathbb{C}\cup\{\infty\}$. My question is, why can we deduce this from that ""$j$'s only pole is simple""?","['riemann-surfaces', 'algebraic-geometry', 'complex-analysis']"
273491,Must a meromorphic function on a compact set have same number of zeros and poles?,Let $f:X\rightarrow\mathbb{C}\cup\{\infty\}$ be a meromorphic function while $X$ is compact. Must $f$ have same number of zeros and poles?,"['meromorphic-functions', 'complex-analysis']"
273497,For which p the series converge?,$$\sum_{n=0}^{\infty}\left(\frac{1}{n!}\right)^{p}$$ Please verify answer below,"['convergence-divergence', 'real-analysis']"
273499,Show that every group $G$ of order $175$ is abelian and list all isomorphism types of these groups,"Show that every group $G$ of order 175 is abelian and list all isomorphism types of these groups. [HINT: Look at Sylow $p$-subgroups and use the fact that every group of order $p^2$ for a prime number $p$ is abelian.] What I did was this. $|G| = 175$. Splitting 175 gives us $175 = 25 \cdot 7$. Now we want to calculate the Sylow $p$-groups, i.e we want $$P= n_7: n_7 \equiv 1 mod 7 \hspace{1.5cm} n_7|25$$
$$Q= n_{25}: n_{25} \equiv 1 mod 25 \hspace{1.5cm} n_{25} | 7$$ After listing all elements that are $\equiv 1 mod 7$ and $1 mod 25$ you see that the only (avaliable) ones are $n_7 = n_{25} = 1$. This tells us that both groups $P,Q$ are normal subgroups of $G$. I think, by definition of a normal subgroup, they are abelian and so this tells us that $G$ is abelian. To list all the isomorphism types, we want the semidirect product (SDP) such that $$P \rightarrow Aut(Q) = C_7 \rightarrow C_{20}$$ As there are no elements of order 7 in $C_{20}$, the only SDP we have is the trivial SDP, i.e the direct product $$C_7 \times C_{25} \cong C_{175}$$ We know that $175 = 5^2 \cdot 7$ and so multiplying the powers shows us that there are 2 non-isomorphic groups: $$C_{25} \times C_7$$
$$C_5 \times C_5 \times C_7$$ My question for this is is my reasoning also correct for things like showing the abelian groups? I saw something which said something about $P \cap Q = I_G$ and they used this but I don't understand what it was. The next question, assuming that I had to possibilites for my $p$ subgroup, i.e $n_p = 1 or x$, how would I go about answering this question? (I am doing a question like this now and am stuck as I have two Sylow $p$-subgroups).","['group-theory', 'abstract-algebra']"
273512,Classify up to isomorphism the groups of order $203$,"Classify up to isomorphism the groups of order $203$ . Assume the face that the least $ k \geq 1$ such that $$2^k \equiv 1 \mod{29}$$ is $k = 28$ . [HINT: Look at the Sylow subgroups and represent a group $G$ of order $203$ as a semi-direct product of two cyclic groups.] I know that $203 = 7 \cdot 29$ . To find my Sylow subgroups I want $$P = n_7: n_7 \equiv 1 \mod 7 \hspace{1.5cm} n_7\mid 29$$ $$Q = n_{29}: n_{29} \equiv 1 \mod{29} \hspace{1.5cm} n_{29} \mid 7$$ From the hint, we see that $2^k > 203$ and so the only possibility for $n_{29} = 1$ . Writing out all the elements for $n_7$ , we see that there are two possibilities $n_7 = 1$ or $29$ . Because there's two possibilites for $n_7$ , I'm now stuck on what to do. I know that $Q$ is a normal subgroup and so would if I let $P_1 = n_7 = 1$ and $P_2 = n_7 = 29$ , would I have to workout the semidirect products such that $Q \rightarrow \mathrm{Aut}(P_1)$ and $Q \rightarrow \mathrm{Aut}(P_2)$ ? EDIT: The reason I'm doing the SDP from $Q$ is because I thought in order to calculate it, you need to go from the normal subgroup to the other subgroup. If both are normal, then it shouldn't make any difference (I think),","['sylow-theory', 'groups-enumeration', 'group-theory', 'abstract-algebra']"
273516,Is it proper to multiply both sides of a differentiated equation by dx?,"I started Calculus 2 on Monday, where we're beginning with Integration. As somewhat of a refresher, the professor is having us find the derivative of several equations and writing them in the form $$\frac{d}{dx}(x^2-4x)=2x-4 \to d(x^2-4x)=(2x-4)dx$$ I understand that this has something to do with preparing us to understand why you see integrals in the form of $$\int(2x-4)dx = x^2-4x+C$$ but I was led to believe that you can't do this, because $\frac{d}{dx}$ is not a fraction.","['integration', 'derivatives']"
273526,Am I missing something in Rudin' PMA Theorems 2.38 - 2.40?,"So I'm reviewing Rudin's Principles of Mathematical Analysis in studying for an Intro Exam for PhD program. I'm in Chapter 2, specifically theorems 2.38 - 2.40. Having independently done the proofs prior to these theorems, I am wondering why a simpler approach is not warranted. Consider Theorem 2.38: If $\{I_n\}$ is a sequence of intervals in $R^1$ , such that $I_n$ contains $I_{n+1}$ ( $n = 1, 2, 3, \dots$ ), then infinite intersection of the sets $I_n$ is not empty. By Rudin's definition of interval in definition 2.17, the interval is a closed set in $R^1$ . Since $R^1$ is a metric space, the intervals $I_n$ are thus compact sets. So isn't Theorem 2.38 just the corollary to Theorem 2.36 directly above on the page (see below)? Why go through the proof Rudin uses to prove Theorem 2.38. 2.36  Theorem : If $\{K_\alpha\}$ is a collection of compact subsets of a metric space $X$ such that the intersection of every finite
subcollection of $\{K_\alpha\}$ is nonempty, then $\bigcap K_\alpha$ is nonempty. [proof omitted] Corollary : If $\{K_n\}$ is a sequence of nonempty compact sets such that $K_n \supset K_{n+1}\, (n = 1, 2, 3, \dots)$ , then $\bigcap K_n$ is
not empty. I must be missing something basic?","['general-topology', 'real-analysis']"
273538,Simplest Possible Closed Figure in an N-Dimensional Space?,"The students in my physics class were playing with Rubik's Cubes this morning before class. This got us talking about solids. The traditional Rubik's Cube is a six-sided closed solid in a three dimensional space. Another student had a Rubik's Dodecahedron, which got us talking about the ""simplest"" possible Rubik's Solid. We decided that what we meant by simplest was ""possessing the smallest number of sides"". We settled on a tetrahedron (which apparently does exist in Rubik's form). Then we got to talking about the simplest possible closed figure in spaces of varying dimension. It seems like the simplest possible closed figure composed of straight sides in a two dimensional space has three sides, a triangle. Similarly, the simplest possible closed figure composed of straight sides in a one dimensional space would be a line segment, with two sides (is this a stretch?). Then class began. Intuitively, it seems like the simplest possible closed figure whose sides are all straight in an $n$ dimensional space will have $n+1$ sides. Is that intuition correct? My formal training is in the Classics, so I'm not sure whether I've asked the question properly. What branch of mathematics thinks about questions like that, and is there a good introductory text for it?",['geometry']
273540,How to prove the inequality $|x|^{r-1} \leq |x|^r + 1$,$|x|^{r-1} \leq |x|^r + 1$ of a convex function? Thanks.,['functions']
273546,What is the difference between open ball and neighborhood in real analysis?,"I'm learning real analysis. Open ball: The collection of points $x \in X$ satisfying $|x - x_{0}| < r$ is called the open ball of radius $r$ centered at $x_{0}$ Neighborhood: A neighborhood of  $x_{0} \in X$ is an open ball of
  radius r > 0 in $X$ that is centered at $x_{0}$ I'm using Real and Complex Analysis written by Christopher Apelian and Steve Surace.
In my mind, open ball = a collection of points satisfy certain requirement = neighborhood. I do not find out any differences between open ball and neighborhood. Could any one explain it? Thanks!",['real-analysis']
273559,Convergence of $\sum_{n=1}^\infty \frac{\sin^2(n)}{n}$,"Does the series $$ \sum_{n=1}^\infty \frac{\sin^2(n)}{n} $$
  converge? I've tried to apply some tests, and I don't know how to bound the general term, so I must have missed something. Thanks in advance.","['convergence-divergence', 'sequences-and-series']"
273560,Do determinants of binary matrices form a set of consecutive numbers?,"While pondering a solution for the problem of generating random 0-1 matrices with small absolute determinants, I once again realise how little I know about 0-1 matrices. My initial idea was to pick a random determinant, construct a 0-1 matrix to match this determinant and then permute the matrix's rows and columns. But I quickly abandoned this idea because I simply know no way to construct a 0-1 matrix with a given determinant. In fact, I don't even know how large the determinant of a 0-1 matrix can be. The Hadamard's bound for the absolute determinant of an $n\times n$ 0-1 matrix is $\frac{(n+1)^{(n+1)/2}}{2^n}$ (online ref. 1 and ref. 2 ), and the bound is sharp if and only if there exists a Hadamard matrix of order $n+1$. Yet, to my knowledge, there is no known sharp upper bound for the absolute determinant of a general $n\times n$ 0-1 matrix. While I have abandoned the aforementioned idea, the determinants of 0-1 matrices still intrigues me. So, here is my question: Let ${\cal B}^{n\times n}$ denotes the set of all $n\times n$ 0-1 matrices and let $M=\max_{A\in B}\det A$. Is it true that for every $d\in\{0,1,\ldots,M\}$, there exists $A\in{\cal B}^{n\times n}$ such that $\det(A)=d$? For $n\le6$, the answer is positive, but I have no idea about the general case. Edit: The answer doesn't need to be complete. If this question has been recognised as an open problem in the literature, I am glad to know the references.","['linear-algebra', 'reference-request', 'determinant']"
273563,How to prove that $\lVert \Delta u \rVert_{L^2} + \lVert u \rVert_{L^2}$ and $\lVert u \rVert_{H^2}$ are equivalent norms?,How to prove that $\lVert \Delta u \rVert_{L^2} + \lVert u \rVert_{L^2}$ and $\lVert u \rVert_{H^2}$ are equivalent norms on a bounded domain? I hear there is a way to do it by RRT but any other way is fine. Thanks.,"['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
274567,On inner automorphisms group of a $p$ group,Let $G$ be a $p$-group of class 2 and $\exp(\operatorname{Inn}(G))=p^c$. Then prove  $\frac{G} {Z (G)}$ has the form $C_{ p^c}\times C_{ p^c}\times C$ for some (possibly trivial) abelian $p$-group $C$. $C_n$ denotes the cyclic group of order $n$. Thank you,"['finite-groups', 'group-theory', 'p-groups']"
274569,How to prove $ \space B-(A-C) \subseteq (B-C) \cup A \Leftrightarrow B \cap C \subseteq A $,"Let $A,B$ and $C$ be any sets. To prove $ \space B-(A-C) \subseteq (B-C) \cup A \Leftrightarrow B \cap C \subseteq A \space$ I began proving the implication $ \space B-(A-C) \subseteq (B-C) \cup A \Rightarrow B \cap C \subseteq A \space$. I started with the direct method, but after a few trys I changed the method. So, let $B \cap C \subseteq A$ be false, then $B \cap C \nsubseteq A$. There exists a $x \in B \cap C$ such that $x \notin A$. My goal is to prove that $B-(A-C) \subseteq (B-C) \cup A$ is also false. Let be $\space x \in B \cap C$, so $x \in B \space $ and $ \space x \in C$. Then, by the hypothesis $x \in  B-(A-C)$. But if $x \in B \space $,$ \space x \in C$ and $ \space x \notin A \space$, then $ \space x \notin (B-C) \cup A$. So $B-(A-C) \subseteq (B-C) \cup A$ is false and then the implication is true. My problem is to prove the reverse implication. $B \cap C \subseteq A \Rightarrow B-(A-C) \subseteq (B-C) \cup A$. I'm not figure it out how to start. Thanks again.","['discrete-mathematics', 'elementary-set-theory']"
274570,Simple chain rule application $y = (1-x^{-1})^{-1}$,"I am not sure what is going wrong here. I have been doing other applications of the chain rule to cross check that I understand it properly ,but I still do not get a correct answer on this problem while I do on all others. $$y = (1-x^{-1})^{-1}$$ $$y' = -(1-x^{-1})^{-2} \cdot x^{-2}$$ This is wrong and it  gives a wrong answer, according to wolfram and my book the answer should just be the first part which breaks the chain rule and I do understand why this is acceptable in this specific case but no others.","['calculus', 'derivatives']"
274586,"$\sum_{n=2}^\infty \frac{1}{(\ln\, n)^2}$ c0nvergence","$$\sum_{n=2}^\infty \frac{1}{(\ln\, n)^2}$$ The series converge? Please verify my solution below","['limits', 'convergence-divergence', 'real-analysis', 'analysis']"
274594,"$\epsilon$-$\delta$ proof that $f(x) = x \sin(1/x)$, $x \ne 0$, is continuous","I'm doing an exercise that asks me to prove that $f$ is continuous using a $\epsilon$-$\delta$ proof. I have that
$$
  f(x) = \begin{cases}
x\cdot \sin \frac1x,&x\neq 0
\\
0,&x = 0
\end{cases}
$$
I've already managed to show this property for $x=0$. How can I show it for $x \ne 0$, also using a $\epsilon$-$\delta$ proof? Thank you very much.","['epsilon-delta', 'calculus', 'continuity', 'real-analysis', 'limits']"
274597,Check convergence of $\sum^{\infty}_{n=1} \frac{1}{(\ln\ln n)^{\ln n}}$,Check convergence of $$\sum^{\infty}_{n=1}\frac{1}{(\ln \ln n)^{\ln n}}.$$ Please verify my solution below.,"['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis']"
274604,Term for a group where every element is its own inverse?,"Several groups have the property that every element is its own inverse.  For example, the numbers $0$ and $1$ and the XOR operator form a group of this sort, and more generally the set of all bitstrings of length $n$ and XOR form a group with this property. These groups have the interesting property that they have to be commutative . Is there a special name associated with groups with this property?  Or are they just ""abelian groups where every element has order two?"" Thanks!","['terminology', 'group-theory', 'abstract-algebra']"
274606,Multiplicative Euclidean Function for an Euclidean Domain,"Does there exist an Euclidean domain with no multiplicative Euclidean function? An Euclidean domain, denoted $R$, is an integral domain with an Euclidean function $d : R\setminus \{0\} \to \mathbb{N}$ such that $1)\quad d(a) \leq d(ab)$, and $2)\quad a = bq + r$ with either $r = 0$ or $d(r) < d(b)$. I am interested in multiplicative Euclidean functions. That is, $d(ab) = d(a)d(b)$. For example, one can choose $\mathbb{Z}$ with $d(n) = |n|, \quad \mathbb{Z}[i]$ with $d(\alpha) = N(\alpha), \quad F[X]$ with $d(f) = 2^{\deg(f)}$ for a field $F$, or, kind of a stupid example, any field $F$ with $d(a) = 1$. I am new here. Thank you in advance.","['ring-theory', 'abstract-algebra', 'number-theory']"
274608,Translational invariance of Brownian motion,"Let $(\Omega,\mathcal{A},\mathbb{P})$ a probability space, $(X_t,\mathcal{F}_t)_{t \geq 0}$ a time-homogeneous Markov process. A paper I read defines a probability measure $\mathbb{P}^x$ by $$\mathbb{P}^x(C) := \mathbb{P}(C \mid X_0=x) \qquad \qquad (C \in \mathcal{A})$$ Applying this in particular to a Brownian motion $(B_t)_{t \geq 0}$ we obtain $$\mathbb{P}^x(C) = \mathbb{P}(C \mid B_0 = x)$$ so in particular for $C:=[B_t \in B]$ (where $B \in \mathcal{B}(\mathbb{R})$) $$\mathbb{P}^x[B_t \in B] = \mathbb{P}[B_t \in B \mid B_0=x] \tag{1}$$ But I know the following definition of $\mathbb{P}^x$: $$\mathbb{P}^x[B_t \in B] := \mathbb{P}[x+B_t \in B] \tag{2} $$ But I don't see why the measures defined in (1) and (2) are the same (for $x \not= 0$)... Edit: Let $x \mapsto g(x):=\mathbb{P}[B_t \in B \mid B_0=x]$. Then $g$ is only $\mathbb{P}_{B_0}$-a.s. uniquely defined, i.e. $\delta_0$-a.s. uniquely defined. Therefore an arbritary measurable function $h: \mathbb{R} \to \mathbb{R}$ such that $h(0) = \mathbb{P}[B_t \in B]$ would fulfill $h(B_0)=\mathbb{P}[B_t \in B|B_0]$ - and this would imply that (1) is (for $x \not= 0$) not well-defined. Am I correct...?","['probability-theory', 'stochastic-processes', 'brownian-motion']"
274624,What is the difference between two variables being proportional versus being directly proportional? [duplicate],"This question already has answers here : What is the difference between proportional and directly proportional in differential equations? (3 answers) Closed 12 months ago . I hear these expressions being thrown around, and realize that ""proportional"" may also incorporate inverse proportion, but are there any other differences?","['statistics', 'terminology']"
274625,Manifolds are paracompact,"Every manifold is paracompact. I tried: $M$ is an $n$--manifold with open covering $U_\alpha$ and $\varphi_\alpha$ local homeomorphisms; $\varphi_\alpha (U_\alpha)$ are open in $\mathbb R^n$. Adding $B(x, \varepsilon)$ for $x \in (\bigcup_\alpha \varphi_\alpha (U_\alpha))^c$ yields an open covering of $\mathbb R^n$. $\mathbb R^n$ is paracompact hence there is a refinement $V_\alpha$. We discard $V_\alpha \subseteq B(x,\varepsilon)$ and observe that $\varphi_\alpha^{-1}(V_\alpha)$ are a refinement of $U_\alpha$. Fix $p \in M$ and $\alpha_0$ with $p \in U_{\alpha_0}$. Then there is an open nbhd $N$ of $\varphi_{\alpha_0} (p)$ such that $N$ intersects only finitely many $V_\alpha$. Let $N' = \varphi_{\alpha_0}^{-1}(N \cap \varphi_{\alpha_0} (U_{\alpha_0}))$. Then $N'$ is an open nbhd of $p$. My intended finish was ""$N'$ only intersects finitely many $\varphi_\alpha^{-1}(V_\alpha)$"". Alas, it appears that one cannot argue like this since $\varphi_\alpha$ and $\varphi_{\alpha_0}$ map $\varphi_\alpha^{-1}(V_\alpha)$ to different sets. How to salvage the proof? Thank you.","['general-topology', 'manifolds', 'compactness']"
274633,"If you toss $1000$ fair coins $10$ times each, what is the probability the *some* coin will get $10$ heads?","The answer to this is supposedly close to $0.63$. However, I get approximately $0.9765625$ for the following reason: The probability of a fair coin flipped $N$ times resulting in all heads is $1/2^N$. In this case, $1/2^{10}=1/1024$. If I flip $M$ coins, $N$ times each, there are $M$ ways for some coin to result in all heads (from the binomial coefficient ""$M$ choose $1$""), so the probability of some coin resulting in all heads is $M(1/2^N)$. In this case, $1000\times 1/1024 \approx 0.9765625$. Can someone please explain the flaw in my reasoning?","['probability-theory', 'probability']"
274649,What do cycle decompositions mean?,"I am reading about cycle decompositions where a cycle $(a_1 a_2 a_3\cdots a_m)$ is defined as the permutation which sends $a_i$ to $a_{i+1}$, $1\leq i\leq m-1$ and sends $a_m$ to $a_1$. But I am unable to understand this particular notation: $(1 2 3)\circ ( 1 2)(3 4)$. What is this supposed to mean and how do we compute it?",['group-theory']
274658,Variety of pairs of product-zero matrices,"Here's an old qualifying exam question I got stuck on. Consider the variety $X$ of pairs of matrices $(A,B)$ satisfying $AB = BA = 0$ (with entries in some field). What are the irreducible components of $X$? According to the question, they all have dimension $n^2$. A related question: are the irreducible components smooth away from their loci of intersection with other components?","['linear-algebra', 'algebraic-geometry']"
274674,Calculate speed an object is moving towards another direction,"The title probably sucks because this is a really hard question to word properly, so I apologize for that. Basically I have these two variables: moveSpeed and moveDirection . I'm using these to move an object at that speed in that direction. However, I want to find out how much of that speed is going in another direction. So, for example moveSpeed=10
moveDirection=80
otherSpeed=x
otherDirection=70 We have an object moving 80 degrees at 10 pixels per frame. How much of that speed is it moving 70 degrees? Also I realize (and expect) that this number will be negative when the direction is on the opposite side of the circle. Also, here's a picture to make a little more sense. Common sense tells us the speed is ~9 since the other direction is very close to the initial direction. And if I still did too terrible of a job explaining, some static examples: With 10 moveSpeed in 0 moveDirection , I'd get -10 otherSpeed at 180 otherDirection With 10 moveSpeed in 0 moveDirection , I'd get 0 otherSpeed at 90 otherDirection With 10 moveSpeed in 0 moveDirection , I'd get 5 otherSpeed at 45 otherDirection So, what formula would I plug moveSpeed , moveDirection , and otherDirection into to get otherSpeed ?",['trigonometry']
274683,"Convergence of $\sum_{n=2}^{\infty}\frac{\sqrt{a_{n}}}{\ln\, n}(n^{a_{n}}-1)$","If $\sum_{n=2}^{\infty}a_n$ converge, then also converge this series?
$$\sum_{n=2}^{\infty}\frac{\sqrt{a_{n}}}{\ln\, n}(n^{a_{n}}-1)$$ Please verify my answer below Counterexample: $$a_{n}=\begin{cases}
\frac{1}{k^{2}} & n=k!^{k^{2}}\\ \\
0 & \text{All other cases}
\end{cases}$$ When our infinites sum is equal to $$\sum_{k=1}^{\infty}\frac{1}{k}\cdot\frac{1}{2\, \ln\, k}\cdot(k!-1)$$","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
274687,Second Order Cosine Differential Equation,"Can one think of a solution to: $$ \lambda f''(x)=f(x)\cos x$$ s.t. $f(0)=0$ and $f(\frac \pi 2)=0$, $\lambda>0$?",['ordinary-differential-equations']
274690,Argument principle: number of zeroes of $f(z)=\cos(z)-1 +z^2/2$ in the unit disk,"I am trying to work on this old qual exam. Here is the question: Find the number of roots (counting multiplicities) of the function
  $$f(z)=\cos(z)-1 + \frac{z^2}{2}$$  inside the domain $\vert z \vert <1$. My work: I first thought of Rouché's theorem. But then I figured that
$f(z)=z^4\left(\frac{1}{4!}-\frac{z^2}{6!}+\cdots\right)$. So $f(z)=z^4 g(z)$ for some analytic
function $g(z)$ such that $g(0)\neq 0$. And then I used the argument principle to conclude that the number of zeroes is $4$. Is this correct? Also, how do I know for sure that there are no other zeroes of $g$ inside the unit disk centered at $0$.
Any hints?
Thanks","['residue-calculus', 'roots', 'complex-analysis']"
274696,How to use the Prontrjagin-Thom construction to obtain the Gysin map?,"I need help to understand the diagram in Miller's script Vector Fields on Spheres, etc. Chapter 23, p.82 on the bottom of the page. Before, Miller introduces the Prontrjagin-Thom construction: It is for a locally compact Hausdorff space $X$ and an open subspace $U\subseteq X$ the collaps map $P:\bar X\to \bar X/(\bar X\setminus U)\simeq \bar U$ where the upper bar denotes the one-point compactification. For the diagram in question, he takes a smooth fibration of compact mainfolds $F\to E\to B$, an embedding $E\subset \mathbb{R}^n$ and the induced map
\begin{equation}
E\xrightarrow{i} B\times  \mathbb{R}^n
\end{equation}
over $B$. Moreover, $\nu(i)$ is the normal bundle of $i$ and $N\subseteq B\times  \mathbb{R}^n$ a tubular neighbourhood. The Prontrjagin-Thom construction provides a map $P:\overline{B\times  \mathbb{R}^n}\to \overline{N}$. There is a nice picture on top of page 83: $B=[0,1]$ is an interval, $n=1$ and $E=B+B+B$ is just a trivial $3$-sheeted covering. Then, $\overline{B\times  \mathbb{R}^n}\simeq S^2$ and $\overline{N}\simeq S^2\vee S^2\vee S^2$, so far I understand. Now in the diagram on the bottom of page 82, it is claimed that $B^{n\epsilon}\simeq \overline{B\times  \mathbb{R}^n}$ and that $E^{\nu(i)}\simeq \overline{N}$ where the exponent refers to the Thom space construction and $n\epsilon$ is the $n$-dimensional trivial bundle over $B$. I don't understand that. In the example above, the Thom space of $1\epsilon:\mathbb{R}^1\times [0,1]\to [0,1]$ is homotopy equivalent to $S^1$ (and not to $S^2$!): One-point compactification in every fiber gives a cylinder and collapsing $\infty\times [0,1]$ to a point is homotopy equivalent to $S^1$. Where is my misunderstanding?","['differential-topology', 'algebraic-topology', 'differential-geometry']"
274702,Integral vanishes on all intervals implies the function is a.e. zero [duplicate],"This question already has answers here : If $\int_0^x f \ dm$ is zero everywhere then $f$ is zero almost everywhere (6 answers) Closed 4 years ago . I am having trouble with the following problem: $f:\mathbb{R}\to \mathbb{R}$ is a measurable function such that for all $a$:
  $$\int_{[0,a]}f\,dm=0.$$
  Prove that $f=0$ for $m$ almost every $x$ (here $m$ is the Lebesgue measure). I have no problem proving this for $f$ non-negative, or under the assumption that $f$ is integrable. But the question only assumes that $f$ is measurable and no more. My idea was the usual thing; we look at the set of points where $f$ is positive and negative and assume one of these has measure greater than zero. Then I wanted to estimate one of these by an open set, look at the integral on the open set and show that it had to be greater than zero, a contradiction. But a key part of this attack is the assumption of the absolute continuity of the integral, which only holds in the case where $f$ is integrable. Alternatively, if it were integrable one could simply estimate $f$ by a continuous function, where the result is quite obvious. Ultimately we are going to show that $f$ is integrable, but it is not clear to me how to show this before showing it is zero a.e. So there must be a simpler way. Does anyone have suggestions?","['lebesgue-integral', 'measure-theory', 'real-analysis']"
274704,Order of growth of the entire function $\sin(\sqrt{z})/\sqrt{z}$,"Show that $$f(z)=\frac{\sin\sqrt z}{\sqrt z}$$ is an entire function of finite order $\rho$ and determine $\rho$ . I observed that the two determinations of the square root differ only for the signum. Since $\sin(-z)=-\sin z$ , we have that $f(z)$ is well defined, and entire because it's the ratio of two entire functions with denominator never vanishing.
For the order i use the Taylor expansion $$\sin z=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n+1}}{(2n+1)!}$$ which for $z=\sqrt z$ gives $$\sin\sqrt z=\sum_{n=0}^{\infty}(-1)^n\frac{z^{n}\sqrt z}{(2n+1)!}$$ Thus $$\frac{\sin\sqrt z}{\sqrt z}=\sum_{n=0}^{\infty}(-1)^n\frac{z^{n}}{(2n+1)!}$$ Then we have $$(2n+1)!\geq2^n n!$$ hence $$\bigg|\frac{\sin\sqrt z}{\sqrt z}\bigg|\leq\large\sum_{n=0}^{\infty}\left(\frac{|z|}{2}\right)^{n}\cdot\frac{1}{n!}=e^{|z|/2}$$ This (if correct) shows that $\rho\leq\frac{1}{2}$ . How can be shown the identity?","['asymptotics', 'complex-analysis', 'entire-functions']"
274712,Calculate on which side of a straight line is a given point located?,"I am a programmer without really good knowledge in math. :/ So I have to write an algorithm that changes the color of pixel(dot) P to opposite if it's on left side of the straigt line in   coordinate system (and the line is not vertical, with that I mean, x2-x1 can't be 0). The values of x1, y1 and x2, y2 dots are known (and they can also be negative). Does anyone have an idea how could this be solved?","['geometry', 'calculator']"
274742,"Evaluate $\int_0^1\ln(1-x)\ln x\ln(1+x)\,\mathrm dx$","What would you recommend me for the integral below? $$
\int_{0}^{1}\ln(1 - x)\ln(x)
\ln(1 + x)\,\mathrm dx
$$ For instance, for the version without the last logarithm would work to use Taylor series, but in this case things are a bit more complicated and it doesn't seem to work.","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
274760,Question about quotient group - is the operation defined or is it a consequence?,"Given a normal subgroup $N \le G$.  Do we define the operation $*$ on $G/N$ to be $$(aN) * (bN) = abN$$ or is the group operation the usual product, $$aNbN = \{an_1bn_2 : n_1, n_2 \in N \}$$ with the above being $abN$ due to normality?","['group-theory', 'abstract-algebra']"
274764,Inequality regarding norms and weak-star convergence,"Let $X$ be a normed space and $(x'_n) \subseteq X'$ a sequence of functionals where $x_n'$ has $x'$ has its limit in the *-weak topology in $X'$. Show that
$$
  ||x'|| \le \operatorname{lim inf}_{n\to \infty} ||x'_n||.
$$
I have no glue how to show this, do you have any hints?","['convergence-divergence', 'functional-analysis']"
274773,"Given a real valued $C^1$ function $f$, show there exists a continuous vector-valued function $F$ with $f(X) = X \cdot F(X)$","Assume $f:\mathbb{R}^{n} \rightarrow \mathbb{R}$ is a function with continuous first order partial derivatives such that $f(0)=0$. Show there exists a continuous function $F:\mathbb{R}^{n}\rightarrow \mathbb{R}^{n}$ such that $f(X)=X \cdot F(X)$ on $\mathbb{R}^{n}$. It seems like the function $F(X):=(\int_{0}^{1} (\partial_{j}f)(tX)dt))_{1\leq j \leq n}$ is the right idea, but it doesn't seem to work out. I think I'm missing something...would appreciate any help.","['multivariable-calculus', 'analysis']"
274787,Prove that $f$ is not continuous for any value in $\mathbb R$.,"I'm having some trouble in the following proof: Let $f:\mathbb{R\to R}$ be given by:
$$
  f(x) = \begin{cases}
1,&x\in\mathbb Q
\\
0,&x\notin\mathbb Q
\end{cases}
$$ Prove that $f$ is not continuous for any value in $\mathbb R$. Can anyone please help me with this? Thank you!","['calculus', 'functions', 'continuity', 'real-analysis', 'limits']"
274789,Meaning of different Orders of Derivative,I have been trying to analyse the meaning of higher order derivatives and their geometrical significance. Given a function $f(x)$ what are the unique geometric interpretation of its higher orders? $f'(x)$ - slope (rate of change of x w.r.t y) $f''(x)$ - convexity / concavity of $f(x)$ based on $sign(f''(x))$ $f'''(x)$ - increasing / decreasing slope of $f'(x)$ $f''''(x)$ - ?? ... $f^n(x)$ - ?? I apologize if this question is rudimentary.,"['derivatives', 'functions']"
274803,Primes in a Power series ring,Let $\mathbb Z$ be the ring of rational integers. Consider the power series ring $\mathbb Z[[x]]$. It is known that $\mathbb Z[[x]]$ is unique factorization domain. What are the primes in $\mathbb Z[[x]]$?,"['commutative-algebra', 'ring-theory', 'abstract-algebra', 'number-theory']"
274810,"Is a closed set with the ""unique nearest point"" property convex?","A friend of mind had a question that I couldn't answer. It is well-known that if $K$ is a closed, convex subset of a Hilbert space $H$ (say over the reals) then, for any point $p \in H$ , there exists a unique point $p'$ in $K$ closest to $p$ . We would like to know whether the following converse is true. If $K \subset H$ is a closed subset such that, for all points $p \in H$ , there exists a unique point $p' \in K$ closest to $p$ , does it follows that $K$ is convex? I'm not sure what the answer is - even when $H$ is the plane! OK, I found some time to read/understand the document that Michael Biro
linked below, so I thought I would add a summary. In what follows, $K$ is a subset of the finite-dimensional Hilbert space $\mathbb{R}^n$ such that, for all $x \in \mathbb{R}^n$ , there is a unique $P(x) \in K$ as close as possible to $x$ . That is, $P(x)$ is the only point in $K$ with $\| x-P(x)\| = \mathrm{dist}(x,K)$ . In particular, $\mathrm{dist}(x,K)$ is positive when $x \notin K$ , so $K$ is clearly closed. Another easy observation is given below. Lemma 0. For $x,y\in \mathbb R^n,\, |d(y,K)-d(x,K)|\le \|y-x\|$ . Proof : For any $z\in K$ , $$d(y,K)\le \|y-z\|\le \|y-x\|+\|x-z\|.$$ Taking the infimum over $z\in K$ both sides of the inequality, we have $$d(y,K)\le \|y-x\|+d(x,K).$$ By the symmetry between $x$ and $y$ , we obtain the lemma. Lemma 1. If $x \in \mathbb{R}^n \setminus K$ , then $P(y) = P(x)$ for all $y$ on
the line segment joining $x$ to $P(x)$ . Proof. We have $$ \|x - P(y)\| \leq \|x - y\| + \|y - P(y)\| \leq \|x-y\| + \|y-P(x)\| =
\|x - P(x)\|$$ whence $P(y) = P(x)$ . The final equality above uses the assumption that $y$ is on the line segment joining $x$ to $P(x)$ . It is reasonable to expect Lemma 1 to hold when $y$ is merely on
the ray extending from $P(x)$ through $x$ . This is true, but far less simple to prove. In fact, the proof seems to need the Brouwer fixed point theorem. To apply Brouwer, we shall need continuity of the projection. Lemma 2. $P$ is continuous. Proof. Suppose $x_n \to x$ in $\mathbb{R}^n$ . We want to show $P(x_n) \to P(x)$ . $P(x_n)$ are bounded by the triangular inequality and Lemma 0.
Use the Bolzano-Weierstrass theorem to reduce proving $P(x_n) \to P(x)$ to proving $P(x_{n_k}) \to P(x)$ for every subsequence such that $P(x_{n_k})$ converges. If $P(x_{n_k}) \to y \in K$ , then $$ \|x-y\| = \lim_{k \to \infty} \|x_{n_k} - P(x_{n_k})\| = \lim_{k \to
\infty} \mathrm{dist}(x_{n_k}, S) = \mathrm{dist}(x,K)$$ which implies $y=P(x)$ . We now use the Brouwer fixed point theorem to improve Lemma 1. Lemma  3. If $x \in \mathbb{R}^n \setminus K$ , then $P(y) = P(x)$ for all $y$ on the ray extending from $P(x)$ through $x$ . Proof. Suppose the whole ray does not project to $P(x)$ . Using Lemmas 1 & 2, argue that $x$ can be moved out along the ray until everything on the closed segment from $P(x)$ to $x$ projects to $P(x)$ , but everything further out on the ray does not project to $P(x)$ . Let $B$ be a closed ball centred on $x$ disjoint from $K$ . Define a map $\Phi : B \to \partial B$ by sending $y \in B$ to the unique point $\Phi(y) \in \partial B$ such that $x$ is on the segment joining $P(y)$ to $\Phi(y)$ . It is easy to derive an explicit formula and continuity of $\Phi$ follows from Lemma 2. By Brouwer, $\Phi$ has a fixed point. It turns out there can only be one fixed point and we will say exactly what it is. Suppose that $y$ is a fixed point of $\Phi$ . Then $x$ is on the segment from $P(y)$ to $y=\Phi(y)$ so $P(y) = P(x)$ by Lemma 1. But, this determines $y$ uniquely to be the point on $\partial B$ antipodal to $P(x)$ . But, now we have a contradiction since this $y$ is beyond $x$ on the ray from $P(x)$ through $x$ and should therefore have $P(y) \neq P(x)$ by assumption. With Lemma 3 out of the way, it is easy to prove Motzkin's theorem using the idea in Rahul's comment below. Motzkin's Theorem. Every subset of $\mathbb{R}^n$ with the ""unique nearest point property"" is convex. Proof. Suppose that $x \in \mathbb{R}^n \setminus K$ . By Lemma 3, for any point $y$ on the ray from $P(x)$ through $x$ , we have $P(x) = P(y)$ so that the open ball $B_y$ centred on $y$ with $P(x)$ on the boundary is disjoint from $K$ . As $y$ becomes unbounded, we see that $K$ is separated from $x$ by the half-plane through $P(x)$ with normal vector $x-P(x)$ . Obviously this precludes the possibility that $x$ is a convex combination of two points in $K$ .","['geometry', 'hilbert-spaces']"
274815,"Entire function. Prove that $f(\bar{z})=\overline{f(z)}, \forall z\in C$","Let $f$ a entire function: $f(R)\subset R.\;$ Prove that $f(\bar{z})=\overline{f(z)}, \forall z\in C$",['complex-analysis']
274817,"Is $W_0^{1,p}$ weakly closed?","Is $W_0^{1,p}(\Omega)$ weakly closed? $W_0^{1,p}(\Omega)$ is the closure of $C_0^{\infty}(\Omega)$ with respect to the norm of $W_0^{1,p}(\Omega)$ , and I've been trying to figure out if it is true that if we have a sequence $u_n\in W_0^{1,p}(\Omega)$ that converges weakly to $u\in W^{1,p}$ then $u\in W_0^{1,p}$ . (By weak convergence in $W^{1,p}$ I mean weak convergence in $L^p$ of both $u_n$ and $\nabla u_n$ ) The only thing I could think of was to approximate each $u_n$ with a sequence $(u_n^k)_k\in C_0^{\infty}$ . Then by the Sobolev embedding theorems we have that weak convergence of $\nabla u_n$ in $L^p$ implies strong convergence of $u_n$ in $L^p$ , so it should be possible to approximate $u$ with $C_0^{\infty}$ functions in the $L^p$ norm. But what about the derivatives?
I hope I have not been too confusing. Thank you.","['sobolev-spaces', 'partial-differential-equations', 'functional-analysis', 'real-analysis']"
274824,Three kinds of spectra,"In commutative algebra while proving the Nullstellensatz one introduces for a while the Rabinowitsch sprectrum as: $$\operatorname{Spec}_{\rm Rab}(R)=\{R\cap \mathfrak m: \mathfrak m \text{ is a maximal ideal of } R[X]\}.$$ There is a quite easy to see the inclusion list: $\operatorname{Spec Max}\subseteq\operatorname{Spec}_{\rm Rab}\subseteq \operatorname{Spec}$. I'm asked to prove that the inclusions are strict, by considering $R=K[[Y]]$, $K$ a field, and $S=R[Z]$ by using the ideals $(Y)$ and $(Z)$ in $S$. Im kinda stuck, any kind of help would be helpful, and not very familiar with the ring of formar series. Thank you This is an exercise in the book A Course in Commutative Algebra from George Kemper, page 20 number 1.4.","['commutative-algebra', 'algebraic-geometry']"
274841,Show that $\mathbb{R}/\mathbb{Z}$ is isomorphic to $\{e^{i\theta} : 0 \le \theta \le 2\pi \}$,"This question is asking to prove that the quotient group $\mathbb{R}/\mathbb{Z}$ is isomorphic to the group of complex numbers with modulus 1 (under multiplication).   It's hard for me to visualize the structure of $\mathbb{R}/\mathbb{Z}$, so I can't think of an isomorphism. I feel like the first isomorphism theorem can help? Help is appreciated.",['group-theory']
274849,Ambiguous Curve: can you follow the bicycle?,"Let $\alpha:[0,1]\to \mathbb R^2$ be a smooth closed curve parameterized by the arc length. We will think of $\alpha$ like a back track of the wheel of a bicycle. If we suppose that the distance between the two wheels is $1$ then we can describe the front track by $$\tau(t)=\alpha(t)+\alpha'(t)\;.$$ Suppose we know the two (back and front) trace of a bicycle. Can you determine the orientation of the curves? For example if $\alpha$ was a circle the answer is no. More precisely the question is: Is there a smooth closed curve parameterized by the arc length $\alpha$ such that $$\tau([0,1])=\gamma([0,1])$$ where $\gamma(t)=\alpha(1-t)-\alpha'(1-t)$? If trace of $\alpha$ is a circle we have  $\tau([0,1])=\gamma([0,1])$. Is there another?","['geometry', 'plane-curves', 'differential-geometry', 'analysis']"
274856,Counting the number of paths through a grid graph traversing all vertices exactly once,"So I asked a question on stack overflow and they suggested I migrate over here. I'm writing a program to solve the following problem: Given a grid of x by y dimensions, calculate the number of paths through it that start in one corner (let's say top right) and end in another (bottom right) and pass through every vertex exactly once I've just been brute forcing it but it gets slow quickly and people on StackOverflow said I didn't even need to bother with traversal, and that this was just a math problem. Does anyone have any insight into how I could solve it this way?","['algorithms', 'combinatorics']"
