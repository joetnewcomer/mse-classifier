question_id,title,body,tags
976879,Finding Lipschitz for trigonometric functions,how would i find the Lipshitz constant for  $$\sin(x)\times \cos(x)$$ or other trigonometric functions? How would I get my $\operatorname{abs}{x_1 - x_2}$,"['trigonometry', 'calculus', 'lipschitz-functions']"
976902,Special feature of the function f(z) = $|i + z|^2 + az + 3$,"I have to solve following problem:
Find all the values of a (a is a real number) that the function f :
$f(z) = |i + z|^2 + az + 3$ (z is a complex number, i is an imaginary unit) 
has a following feature:
if $f(u) = 0$ then $f(u') = 0$ (where u' is a complex conjugate of u).
Do you have any ideas what is the best approach to solve it?","['complex-numbers', 'functions', 'problem-solving']"
976905,"Prove that if $(X,d)$ is a compact metric space, and $K$ is an infinite set in $(X,d)$, then if $K$ has no limit point, $K$ is a closed set.","Prove that if $(X,d)$ is a compact metric space, and $K$ is an infinite set in $(X,d)$, then if $K$ has no limit point, $K$ is a closed set. Idea : Just like most topology proofs, the way I want to approach this problem is to show that $X - K$ is open however I am unsure how to do this. I actually have an idea that does not involve open sets which I show below, but it would be nice if I could show $X - K$ is open. The help would be appreciated! Suppose $K$ has no limit points. If $K'$ is the set of limit points of $K$ then $K' = \emptyset$. $K$ is closed if every limit point of $K$ is a point of $K$. Then $K$ is closed if $K' \subset K$. Since $K' = \emptyset$, $K\ \subset K$ since $\emptyset \subset K \forall K$. Then $K$ is closed.",['general-topology']
976914,Family of sequences in a Hilbert space with certain property,"Suppose $\mathcal{F}$ is a family of sequences on the unit sphere of $l_2$ with the following property: For any sequence $\varepsilon_n\downarrow 0$ but which is not eventually identically $0$, there exists $(x_n)\in\mathcal{F}$ and $z\in S_{l_2}$ such that, for any $n$, $\langle z, x_n\rangle\leq \varepsilon_n$. Can we find a sequence $(y_n)\in\mathcal{F}$ and $z\in S_{l_2}$ such that for any $n$ $\langle z, y_n\rangle=0$?","['hilbert-spaces', 'functional-analysis', 'analysis']"
976943,Closed Form for Factorial Sum,"I came across this question in some extracurricular problem sets my professor gave me: what is the closed form notation for the following sum: $$S_n = 1\cdot1!+2\cdot2!+ ...+n \cdot n!$$ I tried computing some terms, and the only ""vague"" thing I noticed was that maybe I should be subtracting a term, but I'm really not sure. I went around looking on StackExchange's archives for a closed form of $S_n = 1!+2!+ ...+ n!$ but that didn't help me with my problem much. Any pointers?","['factorial', 'summation', 'discrete-mathematics', 'contest-math']"
976966,Subsets of $ \mathbb Q $ of order type $ \omega^{\alpha}$ for each countable ordinal $\alpha $.,"My introductory text in Set Theory (Stillwell) includes an exercise (6.3.1) asking for an explicit example of a subset of $ \mathbb Q $ or order type $ \omega^2 $.  This seems straight forward enough.  I wish to generalize this, first by explicitly defining a sequence of sets $ A_n \subset \mathbb Q $ such that $ A_n $ has order type $ \omega^{n} $ and then seeing where we can go from there. (See Details below.) Taking the $limsup \{A_n\}$, I believe we get $A_{\omega} = \cup A_n$.  While my intuition carries me through $A_n$ for finite $n$, it is not entirely clear to me what $A_{\omega}$ looks like , or indeed if $A_{\omega}$ has order-type $\omega^{\omega}$.  I think it does.  If so, we should be able to carry on to generate $A_{\alpha}$ for each countable ordinal $\alpha$. Is this correct?  This is self-learning, so I don’t have anyone to refer to.  What is a better way of doing this so that intuition holds up past $\omega^{\omega}$? I am reading an introductory text but my question is more intermediate than introductory .  This is why I am unsure and seeking help.  For example, the text does not cover set-theoretic limits . DETAILS This is what I have done so far : First, let $A_1 = \mathbb N$. Clearly $A_1$ has order-type $\omega^1$. To make clear my approach I shall write $A_2$ in long hand .$$A_2 = \{ 1 - \frac12, 1 - \frac13, 1 - \frac14, \dots, 2 - \frac12, 2 - \frac13, \dots \} .$$ To generalise, given $A_n$, write $A_n = \{ a_1, a_2, \dots \}$, where $a_n \lt a_{n+1}$. Define $a_0 = 0$ and $d_i = a_i  - a_{i-1}$ for $i \gt 1$. Next, for each $i > 0$, let $$B_i = \{ a_i - (d_i \cdot \frac{1}{k}) : k \in \mathbb N \}.$$
Finally, we define $$A_{n+1} = \cup_i B_i$$ Defining our $A_n$ in this way should mean $A_n$ has order-type $\omega^n$.  Does this extend to infinite ordinals?","['self-learning', 'ordinals', 'elementary-set-theory', 'order-theory']"
976970,$ \sum a_n \sin (nx)$ converges uniformly iff $na_n\to 0$ as $n \to \infty$,"Let $\{a_n\}$ be decreasing sequence of positive terms then prove that $\displaystyle \sum a_n \sin (nx)$ converges uniformly on $\Bbb{R}$ iff $na_n \to 0$ as $n\to \infty$. I proved that convergence of $ \sum a_n \sin (nx)$ implies $na_n \to 0$ as $n\to \infty$ . I got stuck while prove the converse,  I tried ussing Dirichlet's test but the problem here is that partial sums of  $\displaystyle \sum^{n}_{k=1} \sin (kx)$ are bounded by $\displaystyle \frac{1}{|\sin (\frac{t}{2})|}$ , so as per Dirichlet's test requirement I'm not getting uniform bound.","['sequences-and-series', 'real-analysis']"
976977,Expected number of sides of a dice,"I have two dice, one with m sides (labeled $1,2,...,m$) and one with $n$ sides (labeled $1,2,...,n$). I roll both three times. The $m$-sided one comes up $1, 2, 9$ and the $n$-sided one comes up $7, 7, 8$. Which is higher: the expected value of $m$ or the expected value of $n$? Now compute both expected values and give their approximate value with a $95\%$ confidence interval. Part (a) of the question seems pretty straightforward and I tried approaching part (b) using MLEs but that didn't turn out too well because the likelihood function of this involves a $n!$ term, namely $$P(x_1,x_2,...x_n|n)=\frac{n!}{x_1!x_2!...x_n!}\Big(\frac{1}{n}\Big)^{x_1+x_2+...x_n}$$ Any suggestions? Thanks!","['statistics', 'statistical-inference']"
976987,"Proof of the conjecture that the kernel is of dimension 2, extended","Pursuing my research, I am now looking for a proof of an extension of the problem proposed here and answered. It's an extension in the sense that I'm now considering two different $t_1$ and $t_2$. The ""conjecture"" still stands though. ""Experimentally"", I found that the kernel (null space) of the following matrix is of dimension 2. I'd like to prove it, but haven't managed yet:
\begin{equation}
\text{for almost all } t_1>0,\quad \text{dim}\,\text{ker}\left(\mathbf{Q}_2\mathbf{Q}_1(t_1)-\mathbf{Q}_1(t_2)^{-1}\mathbf{Q}_2\right)\overbrace{=}^?\;2 
\end{equation} where $t_2$ is chosen such that $$\text{det}\left(\mathbf{Q}_2\mathbf{Q}_1(t_1)-\mathbf{Q}_1(t_2)^{-1}\mathbf{Q}_2\right)=0$$
We assume that such a $t_2$ exist.
where: $\mathbf{Q}_2$ is the following matrix:
\begin{equation}
\mathbf{Q}_2=\begin{bmatrix} \mathbf{I}_n & \mathbf{0}_n \\  \mathbf{0}_n & \mathbf{P}^{-1}\begin{bmatrix}1 & && \\ & \ddots && \\ & & 1& \\ &&& -1 \end{bmatrix}\mathbf{P}  \end{bmatrix}\in\mathbb{R}^{2n\times2n}
\end{equation}
where $\mathbf{P}\in\mathbb{R}^{n\times n}$ is any invertible matrix. $\mathbf{Q}_1(t)$ is defined by: \begin{equation}
\forall t>0,\quad\mathbf{Q}_1(t)=\begin{bmatrix}\textbf{cos}(\boldsymbol \Omega t) & \boldsymbol \Omega^{-1}\,\textbf{sin}(\boldsymbol \Omega t) \\  -\boldsymbol \Omega\,\textbf{sin}(\boldsymbol \Omega t) & \textbf{cos}(\boldsymbol \Omega t)\end{bmatrix}\in\mathbb{R}^{2n\times2n}
\end{equation}
and:
\begin{equation}
\boldsymbol\Omega=\begin{bmatrix} \omega_1 & & \\  & \ddots & \\  & & \omega_n  \end{bmatrix}\in\mathbb{R}^{n\times n},\quad \forall i\in\lbrace 1,\dots, n\rbrace, \omega_i>0
\end{equation} and the four blocks are diagonal, for example:
\begin{equation}
\mathbf{cos}(\boldsymbol\Omega t)=\begin{bmatrix} \cos(\omega_1t) & & \\  & \ddots & \\  & & \cos(\omega_n t)  \end{bmatrix}\in\mathbb{R}^{n\times n}
\end{equation} Interesting properties of $\mathbf{Q}_1$ and $\mathbf{Q}_2$ : Obviously, $\mathbf{Q}_2$ is invertible and $\mathbf{Q}_2=\mathbf{Q}_2^{-1}$. Also, $\det(\mathbf{Q}_1)=1$ ($\omega_i>0$ and for proper $t>0$) and:
\begin{equation}
\mathbf{Q}_1(t)^{-1}=\begin{bmatrix}\textbf{cos}(\boldsymbol \Omega t) & -\boldsymbol \Omega^{-1}\,\textbf{sin}(\boldsymbol \Omega t) \\  \boldsymbol \Omega\,\textbf{sin}(\boldsymbol \Omega t) & \textbf{cos}(\boldsymbol \Omega t)\end{bmatrix}
\end{equation} Any clues would be greatly appreciated. Why I'm not able to extend loup blanc's solution to the present problem with two different $t_1$ and $t_2$. Let's define $A:=\mathbf{Q}_2\mathbf{Q}_1(t_1)-\mathbf{Q}_1(t_2)^{-1}\mathbf{Q}_2$ and $\phi(x):=\det(A-xI)$. The problem is to prove that $0$ is a zero of $\phi$ with multiplicity 2. By definition of $t_2$, $\phi(0)=\det(A)=0$. So I now have to prove that $\phi'(0)=0$ (and then than $\dim(\ker(A))\leqslant 2$). $\phi'(0)=-\operatorname{tr}(\operatorname{adjoint}(A))$ from Jacobi's formula. The calculation of $A$ gives:
$$A=\begin{bmatrix} c_1-c_2 & \Omega^{-1}s_1+\Omega^{-1}s_2 P^{-1}DP \\ -P^{-1}DP\Omega s_1-\Omega s_2 & P^{-1}DPc_1-c_2P^{-1}DP\end{bmatrix}$$
where $c_i=\textbf{cos}(\Omega t_i)$, $s_i=\textbf{sin}(\Omega t_i)$ and $D=\operatorname{diag}(1,\dots,1,-1)$. This time, the determinant of $A$ is harder to calculate because the upper-left block is non-zero. So I'm stuck with proving that $\operatorname{tr}(\operatorname{adjoint}(A))=0$. I also tried to apply things such as $A\operatorname{adjoint}(A)=\det(A)I$ but there is no mystery: I have to use the properties of $A$, and that's what I'm not managing to do. EDIT I still did not manage to prove that for $t_1,t_2$ such that $\det(Q_2Q_1(t_2)Q_2Q_1(t_1)-I_{2n})=0$,  $\dim(\ker(Q_2Q_1(t_2)Q_2Q_1(t_1)-I_{2n})=2$. I though of proving it by induction but I am still stuck with the inductive step. Do you think this is a good idea? Would you have some relevant references to help me?","['matrices', 'linear-algebra', 'determinant']"
977011,$\sum_{a^2<p\leq (a+1)^2}p$ Summation of primes,$$\sum_{a^2<p\leq (a+1)^2}p$$ where p is prime. Are there some known bounds for this sum?,"['reference-request', 'number-theory']"
977040,Variety of Connected Components,"In Milne's text http://www.jmilne.org/math/CourseNotes/iAG.pdf (A71), he introduces the ""variety of connected components"" of a finite type scheme $X$ over $k$ as the universal example of a zero dimensional variety $\pi_0(X)$ with a map $X\rightarrow \pi_0(X)$. In particular, the fibers of the maps will be the connected components of $X$. (Milne's definition of a variety is a finite type $k$ scheme that is also geometrically reduced and separable.) In particular, he claims that 1) $\pi_0(X)$ exists 2) the map $X\rightarrow \pi_0(X)$ commutes
with extension of the base field 3) $\pi_0(X\times_k Y) = \pi_0(X)\times_k\pi_0(Y)$. This is used to show that a connected algebraic group is irreducible by allowing us to reduce to the case $k=\overline{k}$ by base change (after which our group would still be connected). However, these facts are not obvious to me, and I wondered if there was a reference or an explanation. Attempts: 
To approach 1) I thought above associating a field ${\rm Spec}K$ to each connected component of $X$. If $X$ is connected, here $K$ is the largest field, separated over $k$ with a map $K\rightarrow \Gamma(X,\mathscr{O}_X)$. (If you have two such fields, you can take the composite, so there's a unique maximal one.) However, then 2) and 3) are not obvious. In particular, for 2), if I take an inseparable extension $L$ of $k$ and base change by that, $\pi_0(X)\times_k L$ might have points that aren't separable over $k$ (so not geometrically reduced), which means something went wrong. If I assume that he meant for $\pi_0(X)$ to just be a scheme and not geometrically reduced, then I have to think of what the right nonreduced structure is, and I'm not sure how to do that. Anyways, I think I spent more time on a small technical detail than I should have, and I should just ask for help.","['algebraic-geometry', 'algebraic-groups']"
977063,"exactly k consecutive heads, n tosses","What is the expected number of strings of exactly k consecutive heads if a fair coin is tossed n times? My current answer is $$ {n-1\choose k} (\frac{1}{2})^{(k-1)} $$ Is this correct? A possible string : HTHHHTHH. This has 3 strings for 2 consecutive heads. The string for 3 Hs, is also 2 strings for 2 consecutive Hs.","['statistics', 'probability', 'statistical-inference']"
977093,Prove that $\int_{0}^{+\infty} u^{s-1} \cos (a u) \:e^{-b u}\:du=\frac{\Gamma(s)\cos\left(s\arctan \left(\frac{a}{b}\right)\right)}{(a^2+b^2)^{s/2}}$,"From the answer of this OP: Ramanujan log-trigonometric integrals , I found the following formula $$\begin{align}
& \int_{0}^{+\infty} u^{s-1}  \cos (a u) \:e^{-b u}\:\mathrm{d}u = \Gamma (s)\frac{\cos \left(\! s \arctan \left(\frac{a}{b}\right)\right)}{(a^2+b^2)^{s/2}}, \, \left(\Re(s)>0, b>0, a>0 \right)
\end{align}$$ How one proves that formula? I am interested in knowing the approach without using contour integration method. Thanks in advance.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
977141,Compact projection on Banach space has finite rank,Let $E$ be a Banach space. Show that every compact projection has finite rank. I have no idea where to start.,"['operator-theory', 'compact-operators', 'functional-analysis']"
977146,Prove that $2 \le \int_0^1 \ \frac{{(1+x)^{1+x}}}{x^x} \ dx \le 3$,"I need some starting ideas, hints for proving that $$2 \le \int_0^1 \ \frac{{(1+x)^{1+x}}}{x^x} \ dx \le 3$$ I already checked that with Mathematica that numerically says that $$\int_0^1 \ \frac{{(1+x)^{1+x}}}{x^x} \ dx \approx 2.577632915067858 $$","['inequality', 'calculus', 'definite-integrals', 'integral-inequality', 'real-analysis']"
977184,Getting the cumulative distribution function for $\sqrt{X}$ from the cumulative distribution function for $X$,I've a data set $X$ which consists of randomly generated numbers. My aim is to plot the cumulative distribution function for square root of $X$ without generating data set for square root of $X$ . I'm using Mathematica tool. I'm confused and could not think of a solution. Can somebody let me know how to take the approach here ?,"['statistics', 'discrete-mathematics', 'probability']"
977232,Graph and in-Degree and Drawing [duplicate],"This question already has an answer here : Graph and one Sequence challenge (1 answer) Closed 3 years ago . We have in and out degree of a directed graph G. if G does not includes loop (edge from one vertex to itself) and does not include multiple edge (from each vertex to another vertex at most one directed edge), we want to check for how many of the following we have a corresponding graph. the vertex number start from 1 to n and the degree sequence are sort by vertex numbers. a) $d_{in}=(0,1,2,3), d_{out}=(2,2,1,1)$ b) $d_{in}=(2,2,1), d_{out}=(2,2,1)$ c) $d_{in}=(1,1,2,3,3), d_{out}=(2,2,3, 1,2)$ I want to find a nice way instead of drawing graph. for (C):","['discrete-mathematics', 'trees', 'graph-theory', 'computer-science', 'algebraic-graph-theory']"
977247,Hartshorne II prop 6.9,"I feel completely in the dark, like I am totally missing what is going on behind the scenes in this section.  I apologize in advance. Prop. 6.9: Let $X \to Y$ be a finite morphism of non-singular curves, then for any divisor $D$ on $Y$ we have $\deg f^*D=\deg f\deg D$. I don't understand some of the statements in the second paragraph: Why are points $P_i$ of $X$ such that $f(P_i)=Q$ in 1-1 correspondence with maximal ideals $m_i$ of $A'$?  Somehow we have killed the other maximal ideals by localizing? And why is $\dim_k \mathcal{O}_{P_i}/t\mathcal{O}_{P_i}=v_{P_i}(t)$? I'm confused about some other things but I figure if I ask too many details nobody will want to answer so I'll stop here ;-) EDIT:  I think I actually figured out my first question, using that $B\hookrightarrow A$, that $f(I)=I\cap A$ and the ideal correspondence.  Second question stands (and a bunch of other stuff I'm still trying to figure out).",['algebraic-geometry']
977266,Multiple Integration order doesn't agree.,"Let $0<x,y,t,z<1$ with the additional condition: $$\begin{align*}
x &< t\\
\wedge & \ \\
y &<z
\end{align*}$$ Call the set of all $x,y,t,z$ satisfying the above conditions $S$. I want to evaluate $\int_S dxdydtdz$. One way of doing it is first integrating out $z$ and then integrating along columns down up. This ordering gives: $$\int_0^1\int_0^t\int_x^1\int_y^1 dzdydxdt=\int_0^1\int_0^t\int_x^1(1-y) dydxdt=\frac{1}{8}.$$ Another way is to just integrate up along columns without first integrating $z$: $$\int_0^1\int_0^1\int_0^t\int_x^zdydxdzdt=\frac{1}{12}.$$ Why do these not agree? It seems like the second way is wrong. I think maybe in the second way one needs to integrate $x$ from $0$ to $\min(x,z)$, but then again I thought the $y$ variable ensures this.","['multivariable-calculus', 'calculus', 'integration', 'real-analysis']"
977267,"Yoneda implies $\text{Hom}(X,Z)\cong \text{Hom(}Y,Z)\Rightarrow X\cong Y$?","I came across a result on the page Theorems implied by Yoneda's lemma? which said that Yoneda's Lemma implies the isomorphism of the title; namely, if we have $\text{Hom}(X,Z)\cong \text{Hom}(Y,Z)$, then $X\cong Y$. However my knowledge of category theory is limited at best. I was wondering if anyone could explain how this works, or under what conditions (if any) it fails to work? In particular I want to use it for modules whose underlying abelian groups are simply copies of $\mathbb{Z}$","['modules', 'category-theory', 'abstract-algebra']"
977304,How to generate a single instance of multichoose (stars and bars),"So we know that if I have $k$ balls and $n$ buckets, I have $\binom{n+k-1}{k}$ unique ways to allocate the balls. Let's say $n=4$ and $k=2$ then I have $\binom{5}{2}=10$ ways. All possible allocations are shown below. 0002
0011
0020
0101
0110
0200
1001
1010
1100
2000 My question is, then, given $n$ and $k$, how can I generate each allocation based on some index? Input would be $n$,$k$, and some $i$ and the output would be the allocation. For example, code(4,2,1) would return 0002, the first instance of $n=4$ and $k=2$ and code(4,2,8) would return 1010. Any help on where to look would be great. Thank you","['permutations', 'discrete-mathematics', 'combinatorics']"
977305,Joint PDF of Chi-Square & Normal Distribution,"Let the independent random variables X1 and X2 be N(0,1) and $\chi^2(r)$, respectively. Let $Y_1$ = $X_1/sqrt(X_2/r)$ and $Y_2$ = $X_2$ a) Find the joint pdf of $Y_1$ and $Y_2$. b) Determine the marginal pdf of $Y_1$ and show that $Y_1$ has a t distribution. Thoughts: So beyond confused I don't even know where to start. I assume there must be a trick because creating a joint pdf with a chi-square distribution and a normal distribution using the traditional method seems really strenuous.","['statistics', 'descriptive-statistics', 'random-variables']"
977313,Proof of ${F(n+4)}^{4} - {4F(n+3)}^{4} - {19F(n+2)}^{4} - {4F(n+1)}^{4}+{F(n)}^{4} = -6$,Observe: \begin{matrix} F(n)|&{F(n)}^{4}& - {4F(n+1)}^{4}& - {19F(n+2)}^{4}&- {4F(n+3)}^{4}&{F(n+4)}^{4}& = -6\\ 1|& 1& -4& -304& -324& 625&=-6\\ 1|& 1& -64& -1539& -2500& 4096&=-6\\ 2|& 16& -324& -11875& -16384& 28561&=-6\\ 3|& 81& -2500& -77824& -114244& 194481&=-6\\ 5|& 625& -16384& -542659& -777924& 1336336&=-6\\ 8|& 4096& -114244& -3695139& -5345344& 9150625&=-6 \end{matrix} I see that the proof is true but I cant quite grasp the pattern.  I'm more interested in hints rather than a solution. Ive read through this website about Fibonomials a couple times and have a decent understanding but I cant figure how to apply it in this situation. It may not even be necessary. I've tried proving through induction  but ended up with almost exactly the same problem. I think there may be a proof through some sort of recursive sequence but I don't know enough to prove something like that. I'm more interested in hints rather than a solution.,"['fibonacci-numbers', 'sequences-and-series']"
977325,The uniqueness of the Einstein metric on $\mathbb CP^n$,"Is the Fubini-Study metric the unique Einstein metric (up to scaling by a constant) on $\mathbb CP^n$? More restrictively, Is the Fubini-Study metric the unique Kahler-Einstein metric (up to scaling by a constant) on $\mathbb CP^n$?","['riemannian-geometry', 'differential-geometry', 'kahler-manifolds']"
977364,Tangent space and implicit function theorem,"Let's say we have a $C^1$-function $f:X\to\mathbb{R}^m$ ($X\subset\mathbb{R}^{n+m}$ an open set) and the rank of the matrix $Df(x)$ is $m.$ We'll let $Z=\lbrace x\in X:f(x)=0\rbrace$ and take some $x_0\in Z.$ In addition, we let $T$ be the set of $u\in\mathbb{R}^{n+m}$ such that there is an open $Y\subset\mathbb{R}$ with $0\in Y$ and continuously differentiable $c$ with $c(Y)\subset Z,$ $c(0)=x_0$ and $Dc(0)=u.$ I aim to show that $T$ is an $n$-dimensional subspace of $\mathbb{R}^{n+m},$ and I've got to a point where I'm a bit stuck, so I'm looking for help on where to go next. I wanted to use the implicit function theorem, first taking the $m$ rows that were linearly dependent to the end WLOG, so that they make an $m\times m$ (sub)matrix which must be invertible. Then I could use the implicit function theorem and find some set $X'$ containing $x_0,$ and a set $U\subset\mathbb{R}^n,$ with a $C^1$ $g:V\to\mathbb{R}^m$ so that $Z\cap X'=\lbrace (v,g(v)):v\in V\rbrace.$ The fact that $T$ should be a vector space is more or less straightforward but I can't quite prove that the dimension should be $n,$ but I believe the implicit function theorem can be used for this. I've also shown, since $T$ looks a lot like a tangent space at $x_0$ or something of the sort, that $\langle Df(x_0),u\rangle=0$ for any $u.$ I'm kind of tempted to let $u$ run over unit vectors or something like that, but I'm not entirely sure if it would be useful here, it would tell me more about the orthogonal complement. I get the feeling I'm quite close to completing the proof, but I just need some help knowing which way to go from here (ie. hints greatly appreciated).","['multivariable-calculus', 'implicit-function-theorem', 'real-analysis']"
977366,Trouble understanding Cosets and Lagrange's Theorem,Let $G$ be a group and $H$ a subgroup of $G$ I think all the elements of $h \in H$ multiplied (on the left or right) by one element $g\in G$ forms a coset. Intuitively I can see that $|H|$ = $|gH|$=$|Hg|$ -multiplying all the elements of $H$ does not change the number of elements So the size of each coset depends on the size of $H$ you chose. And yet it turns out that the the size of $H$ always divides the size of $G$ (Lagrange's Theorem) What if you choose $H$ such that its order will not divide the order of $G$?,['group-theory']
977388,Limit of a 0/0 function,"Let's say we have a function, for example,
$$
f(x) = \frac{x-1}{x^2+2x-3},
$$
and we want to now what is 
$$
\lim_{x \to 1} f(x).
$$
The result is $\frac{1}{4}$. So there exists a limit as $x \to 1$. My teacher says that the limit at $x=1$ doesn't exist. How is that? I don't understand it. We know that a limit exists when the one sided limits are the same result. Thank you!","['calculus', 'functions', 'limits']"
977402,Evaluating a limit by Riemann sums,"I'm having some issues with understanding exactly how to see that a given limit/sum is a Riemann sum. For example: $\lim_{n \to \infty} \frac{1}{\sqrt{n}} \sum_{k=1}^n \frac{1}{\sqrt{k}}$. I recognize that $\frac{1}{\sqrt{n}}$ is the length of the partitions, and the other fraction is $f(c_k)$, where $c_k$ is a value picked in the k'th interval of the n'th partition, but to me it looks like $f(x) = \frac{1}{\sqrt{x}}$ and so $c_k$ should be just $k$, but $k$ is a lot bigger than most of the partitions' length. Another type of problem I see is where $c_k$ depends on $n$, and again it seems to me that there isn't a $c_k$ for each k'th interval. For example this problem: $\lim_{n \to \infty} \frac{1}{n} \sum_{k=1}^n sin(\frac{k\pi}{2n})$. Here the length of each partition is $\frac{1}{n}$, but $c_k = \frac{k\pi}{2} \frac{1}{n}$, and since the ""multiplier"" is greater than one, it looks to me like $c_k$ is bound to skip some intervals eventually, and so there isn't a $c_k$ to each interval, and then it's no longer a Riemann sum. But, obviously it is, I just don't understand it.. can anyone explain this to me? My textbook has a few problems like this, but no explanations. Thanks a lot in advance.","['riemann-sum', 'calculus', 'limits']"
977410,Can someone explain how to calculate the third order partial derivative of $f.$,"$f(x,y)=\sin(xy).$ I calculated that $ \dfrac{\partial^2f}{\partial x\,\partial y}=\dfrac{\partial^2f}{\partial y\,\partial x}=\cos(xy)-xy\sin(xy)$. I also calculated $$ \frac{\partial^3f}{\partial x^2\partial y}= -2y\sin(xy)-xy^2\cos(xy)$$ and  $$\frac{\partial^3f}{\partial y^2\partial x}=-2x\sin(xy)-x^2y\cos(xy).$$ However I am not sure whether this is the correct method to calculate the third order partial derivative because $$ \frac{\partial^3f}{\partial x^2\partial y} \neq \frac{\partial^3f}{\partial y^2\partial x}.$$ Can someone explain how to calculate the third order partial derivative of $f.$","['partial-derivative', 'derivatives']"
977445,Is This Set a Group? Ring?,"If we consider the set of linear functions that map reals to reals: $$G = \ \{ \ f(x)=mx+b \mid m,b \in \mathbb{R} \}$$ Is $\langle G, + \rangle$ a group under function addition? Is $\langle G, +, * \rangle$ a ring under function addition and function multiplication? I am sure that the answer to the first question is yes, but I am unsure if this set comprises a ring? From looking at the ring axioms I would say no, but any hints or solutions would be appreciated.","['group-theory', 'abstract-algebra']"
977446,Two sets are disjoint if and only if one is contained in the complement of the other,Prove that $A\cap B = \emptyset$ iff $A\subset B^C$. I figured I could start by letting $x$ be an element of the universe and that $x$ is an element of $A$ and not an element of $B$.,['elementary-set-theory']
977455,Gossip problem proof by induction,"Question Suppose there are $n$ people in a group,
  each aware of a scandal no one else in the group knows
  about. These people communicate by telephone;
  when two people in the group talk, they share
  information about all scandals each knows about. For
  example, on the first call, two people share information, so
  by the end of the call, each of these people knows about two
  scandals. The gossip problem asks for $G(n)$ , the minimum
  number of telephone calls that are needed for all $n$ people to
  learn about all the scandals. Prove that $G(n)\leq2n-4$ where $n\geq4$ Attempt using proof by induction Basis step: $\text{when }n=1$
$$\text{by phone calls } (A\rightarrow B,C\rightarrow D),(AB\rightarrow CD,AB\rightarrow CD)=(ABCD,ABCD)(ABCD,ABCD)\\
\text{Thus, 4 phone calls needed, so since }2(4)-4=4\\ \therefore \text{true for n=4} 
$$
Assumption
$$\therefore G(k)\leq2k-4 \text{ by assumption}$$ Inductive step
$$G(k+1)\leq 2k-4+2 $$ And this is where I'm stuck. Can I say that since
$$G(k)\leq2k-4 $$
$$G(k+1)\leq2k-4 
\\\text{ since adding +2 makes the right side larger so G(k+1) is still smaller than 2k-4}$$
And how do I go on from there?","['induction', 'discrete-mathematics']"
977474,Infinite Sum of Sines With Increasing Period,"A while ago, I was thinking about the Weierstrass function , which is a sum of sines with increasing frequencies in such a way that the curve is a fractal. However, I wondered what would happen if one took the sum where the frequencies decreased; in particular, noting that $|\sin(x)|\leq x$, it is clear that the function
$$f(x)=\sum_{n=1}^{\infty}\sin\left(\frac{x}{s_n}\right)$$
converges pointwise for any sequence $s_n$ such that the sum of $\frac{1}{s_n}$ converges absolutely - and, in fact, yields an $f$ which is analytic. Of particular interest to me is the sequence of square numbers - that is, the function
$$f(x)=\sum_{n=1}^{\infty}\sin\left(\frac{x}{n^2}\right).$$
I created the following plot of the function from the first 10,000 terms in the series: What I find interesting here is that, for some reason I can't determine, it looks like $f(x)$ might be asymptotic to $\sqrt{x}$. I've checked numerically for higher arguments and this seems to continue to be the case. This strikes me as odd, since I had expected it to appear more or less periodic, with long-term variation in amplitude and frequency. So, I am interested in a pair of questions about this series, neither of which I can answer: Is $f(0)=0$ the only (real) zero of $f$? Does $f$ grow without bound? What is it asymptotic to?","['asymptotics', 'trigonometry', 'sequences-and-series', 'real-analysis']"
977490,Best Rigorous Probability Theory Textbook 'without' Measure Theory?,"This question follows from my previous question . I want a book that deals probability theory rigorously (and cover as many topics as possible) yet not involving much about measure theory. There are too many books totally geared to students majoring in other fields, so it's a shame that actually for mathematicians it became so hard to find a good book on probability theory(same as in the field of linear algebra). I got a recommendation of Ash's Basic Probability Theory, which I'm reading a bit. Just wanted to buy a book for me to be well prepared for further learning in this field. I've searched and these books also look pretty decent: Introduction to Probability Theory(Paul G. Hoel, Sidney C. Port, Charles J. Stone) Probability and Random Processes (Geoffrey R. Grimmett, David R. Stirzaker) Elementary Probability(David Stirzaker) I think the second book also deals with a bit of stochastic probability theory, but anyway I'm currently taking the class (check my previous question up there) and it really deals with a lot of different subjects so I was thinking of buying the book. My question is: Granted that I've taken basic probability theory before(so I don't need too much easy textbook), what is your best recommended textbook for a rigorous treatment of probability theory yet not involving much about measure theory? The more subjects it covers, the better as far as this condition is satisfied. Please remember that I'm not an engineer: my first probability class used the textbook 'A first Course in Probability' by Sheldon Ross, and I hate the book with passion. Thanks in advance.","['probability-theory', 'book-recommendation', 'reference-request']"
977495,Incongruencies with derivatives and differencials,"I read in Piskunov that the increment $\Delta y$ of a function can be written as: $\Delta y = f'(x) \Delta x + \alpha \Delta x$ And, when ${\Delta x\to 0}$ , $dy=f'(x)dx$ The problem is, doesn't that mean that it is possible to write the derivative of $f$ as the quocient $f'(x)=dy/dx$   ? It is my understanding that a derivative can be written as the limit of a quocient $\lim\limits_{h\to 0} \frac {f(x+h)-f(x)}{h}$ But not as a quocient of limits, because the denominator would be zero. I started this month my first calculus course, and I am very confused by some of these details, specially with those that have to do with notions of infinitesimals. I also have a lot of doubts in regards to Leibniz notation, as it is repeatedly used as a quocient when, according to every source, $\frac {df(x)}{dx}$ is just notation for $f'(x)$, and not a quocient. An example of this is the following deduction from my physics course (in portuguese) Where de ""denominator"" is transfared. Any light shed on this would be greatly appreciated.","['notation', 'calculus', 'derivatives']"
977500,Time for all ants to traverse cube,"Let $n$ be a positive integer, and consider a hypercube of dimension $2n$ with $2^{2n}$ points given by $(a_1,a_2,\ldots,a_{2n})$, where $a_i\in\{0,1\}$. Two points are connected by an edge if and only if they differ in exactly one coordinate. At the beginning, exactly one ant is at each of the vertices of the hypercube. An ant at point $(a_1,a_2,\ldots,a_{2n})$ wants to get to the point $(a_{n+1},a_{n+2},\ldots,a_{2n},a_1,a_2,\ldots,a_n)$. At the beginning of each second, it considers the foremost bit (i.e., the earliest bit from the left) in which its current position differs from its destination, and wants to take the edge to fix that bit. However, each edge can be traversed by at most one ant in a second. The traversal of one edge takes exactly one second. What is the minimum time for all ants to reach their destination? Asymptotics or bounds are also welcome.",['combinatorics']
977517,"$f^2$ holomorphic polynomial on the disc, $f$ entire, then $f$ is a polynomial.","I know this question will look similar to this link's question: https://math.stackexchange.com/questions/278397/f22f1-is-a-polynomial-implies-that-f-is-a-polynomial# = However, I am not entirely satisfied with either answer here. The first answer uses a fact we have not proven in class, and the second one is a little ambiguous and unclear to me (Why could we not have both roots of $a$? And why does the newly defined function have a zero at $z_{n_j}$?) Anyway, my question is, if $f$ is an entire function, and $f^2$ is a holomorphic polynomial on the open unit disc in $\Bbb C$, then prove that $f$ is in fact a polynomial. I am specifically trying to replicate, with perhaps more clarity, the second answer in the link above. Can any expound on that solution?",['complex-analysis']
977533,Break up $\mathbb{R}P^2$ into a part homeomorphic to Mobius band & part homeo. to the 2-disc,"The claim is that $\mathbb{R}P^2 = A \cup B$ where $A \simeq$ Mobius band, $B \simeq D^2$, and $A \cap B \simeq S^1$. I understand this intuitively with a gluing type argument, similar to the arguments here https://math.stackexchange.com/questions/77569/bbb-rp2-as-the-union-of-a-möbius-band-and-a-disc , stating generally that if you take a disc away from the projective plane the result should be a mobius strip. But I'm wondering if there is a way to explicitly write things down, giving rules for homeomorphisms, and if anyone has a hint for how I can start thinking about this in a more precise way.",['general-topology']
977571,Is there a 3D equivalent of a 2D matrix?,"Just thinking, is there a 3D 'equivalent' of a matrix. I know it's possible to get matrices that only have one row or column (i.e. vectors) thus making there a sort of 1D equivalent, but is there a 3D equivalent of a matrix?",['matrices']
977588,Finding unknown matrices in a set of simultaneous matrix equations,"I've come across a thorny problem in my research, which is too complicated and specific to ask here. However, it bears some similarity to the following problem, and understanding how to solve this ""toy"" version might help me to solve my actual problem. So, suppose I have three real matrices $X$ $(n\times p)$, $Y$ $(m\times n)$ and $Z$ $(p\times m)$, and I wish to find another three (real) matrices $A$ $(n\times m)$, $B$ $(m\times p)$ and $C$ $(p\times n)$ such that $$
AB = X\\
BC = Y\\
CA = Z.
$$ How can I find $A$, $B$ and $C$? This is effectively $mn+np+pm$ equations in $mn+np+pm$ unknowns, so it seems like it might have a unique solution, but the equations are not linear. We can't assume the matrices are invertible, because in general they're not square. How could such a problem be approached? If there's no analytical solution, hints on how to do solve this sort of thing numerically would be appreciated.","['matrix-equations', 'matrices', 'linear-algebra']"
977614,Show that the ring of continuous functions $f:\mathbb R\to\mathbb R$ is not Noetherian,"Prove that the ring of continuous functions $f:\mathbb R\to\mathbb R$ is not Noetherian. I know that to be Noetherian, every ideal is generated by finitely many elements or equivalently R satisfies the ascending chain condition. So, if I can find an ideals that are contained in each other that don't terminate then it is not Noetherian. My professor briefly touched on Noetherian rings so it is still a little bit confusing. How do I go about finding these ideals? Or should I show that every ideal is generated by finitely generated elements? Any help is much appreciated!","['commutative-algebra', 'ring-theory', 'abstract-algebra', 'noetherian']"
977623,Normalization of a variety,"I'm currently in a number theory course and this question popped up. As I'm not super familiar with algebraic geometry, I was wondering if my reasoning is correct: Show that $\mathbb{C}[X,Y]/(Y^2 - X^2 - X^3)$ is a one-dimensional noetherian ring which is also an integral domain. Determine the normalization of this ring. Now, my strategy was to let $t = X/Y$ and define a map from $\mathbb{C}[X,Y] \to \mathbb{C}[t]$ where $X \mapsto t^2 -1$ and $Y \mapsto t(t^2 -1)$. Since this map has kernel $(Y^2 - X^2 - X^3)$, the two rings are isomorphic. Thus, since $\mathbb{C}[t]$ is noetherian and an integral domain, so is the quotient ring. However, I'm not sure how to determine its normalization, or really how to determine the normalization of $\mathbb{C}[X,Y]/(f)$ in general, where $f \in \mathbb{C}[X,Y]$. Could someone explain how normalization works over rings defined in such a way? By normalization I mean the integral closure of $\mathbb{C}[X,Y]/(f)$.","['commutative-algebra', 'algebraic-geometry']"
977653,Proof of: if $x^2+y^2=2xy$ then $x=y$,"I am trying to prove $x^2+y^2=2xy$ then $x=y$ What I have done is suppose $x^2+y^2=2xy$
then $x^2+y^2+(-2xy)=0\iff
x^2+(-xy)+(-xy)+y^2=0
\iff (x+(-y))\cdot x+(x+(-y))\cdot-y=0
\iff (x+(-y))^2=0$
i then square root both sides but i'm not sure if that's mathematically correct?
which gives me: $(x+(-y))=0$
so $x=y$",['algebra-precalculus']
977656,Determinant of specific infinite matrix,"What is the limit, as n approaches infinity, of the determinant of an n x n matrix where each cell has the value $\cos(n * row + column)$? My friend and I believe the answer to be 0, but can't figure out a method of finding the solution without n! steps. We are interested in how this can be solved as well as the answer.","['matrices', 'determinant', 'limits']"
977678,Canonical isomorphism between vector bundle and dual?,"So, we've been asked to show, given a real vector bundle equipped with a metric, that there is a canonical isomorphism from the vector bundle and its dual. Now, there's a theorem that says two vector bundles are isomorphic iff their transition functions satisfy $\mu_i g_{ij} = f_{ij} \mu_j$, where $\mu_i$ is a map $U_i \rightarrow GL(r, \mathbb{R})$ and $g_{ij}$ and $f_{ij}$ are the two bundles transition functions. I was going to say the following:  Given a metric and Gram-Schmid one can always arrange for orthonormal frames, and hence orthogonal transition functions.  Therefore (since the dual bundle transition functions equal the inverse transpose of the bundles transition functions), the above is satisfied trivially. My question is:  Is this still 'canonical'?  I mean, the fact you can do this is a 'universal property' of vector bundles equipped with metrics, so it should be a canonical iso (according to wikipedia).  But, I'm confused by the meaning of 'canonical isomorphism' as meaning ""independent of a basis"".  In the above, I'm specifying a basis.","['vector-spaces', 'vector-bundles', 'differential-geometry']"
977679,Toss a fair die until the cumulative sum is a perfect square-Expected Value,"Suppose we keep tossing a fair dice until we want to stop, at which point the game ends and our score is the cumulative sum, or until the cumulative sum is a perfect square, in which case we lose and end up with a score of $0$. We can set up a Markov-style recurrence. Define $f(k)$ to be the expected value of the game if the current cumulative sum is $k$. Clearly, $f(k)$ is $0$ if $k$ is a perfect square. In addition, $f(k)=\text{max}\{k,\sum_{i=1}^6 f(k+i)\}$. How can we solve such a recurrence to find a good estimate/bounds of the expected score ($f(0)$) and the optimal strategy? Can these methods be extended to a game where we lose if the cumulative sum is an even number, or a perfect cube?","['dice', 'game-theory', 'probability', 'combinatorics']"
977692,Solve the integral $\int_0^\infty x/(x^3+1) dx$,"I'm new here! The problem: integrate from zero to infinity x over the quantity x cubed plus one dx. I checked on wolfram alpha and the answer is that the indefinite integral is this: $$\int \frac{x}{1+x^3} dx = \frac{1}{6}\left(\log(x^2-x+1)-2 \log(x+1)+2 \sqrt{3} \arctan((2 x-1)/\sqrt{3})\right)+\text{constant}$$ and the definite integral is this: $$\int_0^\infty \frac{x}{1+x^3} dx = \frac{2 \pi}{3 \sqrt{3}}\approx 1.2092$$ I am trying to figure out all the steps in between. I see that there are logs, which are equivalent to the ln variant that i am more familiar with, which means it was integrating $1/x$ at some point; I also see an inverse tangent in there. I started with long division to simplify and I got (which could be wrong because I am very tired right now) $x/(x^3+1) = x^2+ 1/(x^3+1)$ which seems to be a step in the right direction. Wolfram Alpha thinks I definitely did that step wrong. The two equations do not evaluate as equal. Then I cheated and took the wolfram alpha factorization of $(x^3+1) = (x+1)(x^2-x+1)$...I probably should have known that but didn't offhand. Now it is looking like $x^2$ plus the partial fraction decomposition $1/(x^3+1) = A/(x+1)+(Bx+C)/(x^2-x+1)$. Am I heading in the right direction with this? At this point do I just plug in and crunch?",['calculus']
977729,Calculating marginal probability density when multivariate pdf's support is $0<y<2$ and $y<x<3$,"Suppose that multivariate pdf $f(x,y)$'s support is in $0<y<2$ and $y<x<3$. I now want to calculate marginal probability density function $f_X(x)$ and $f_Y(y)$. But arranging terms only get me to $0<y<x<2$. How do I apply calculus here?","['multivariable-calculus', 'probability']"
977783,Canonical embedding,I'm reading the second chapter of this paper and I need help to understand what exactly this canonical embedding is: Remark: $C$ is a smooth non-hyperelliptic complete irreducible algebraic curve of genus $g\ge 4$.,"['algebraic-geometry', 'algebraic-curves']"
977789,Using $\lim\limits_{x \to 0} \frac{\sin x}{x} = 1$ evaluate the limit,Use $$\lim_{x\to 0} \frac{\sin x}{x} = 1$$ to evaluate the limit $$\lim_{x\to 0} \frac{x\tan (x^2)}{\cos(3x)\sin^3(2x)}$$ I'm really not sure how to go about this apart from trig identities and using the limit $=1$ to simplify it. Can anyone even get me started on it please?,"['limits-without-lhopital', 'calculus', 'limits']"
977793,Koch snowflake versus $\pi=4$,"The only proof I could find of the Koch snowflake having infinite perimeter was by calculating the perimeter $P_n$ after the $n$th iteration $$P_n = 3s\left(\frac{4}{3}\right)^n,$$
where $s$ is the length of each side of the original equilateral triangle, and then taking the limit as $n$ approaches infinity (which is obviously infinity). I was satisfied with this proof until I remembered the infamous ""proof"" that $\pi$ is equal to $4$ (see the link below). The length of the limit curve (a circle) is $\pi$ which is not the limit of the perimeter of the zig-zaged curve after the $n$th iteration because that's always $4$. This explanation http://qntm.org/trollpi of the false proof states that ""the limit of a sequence need not necessarily share any properties with the members of that sequence"" and that ""we've seen a sequence of curves of length 4, whose limit does not have length 4"". So how come I can use this argument for proving that the Koch snowflake has an infinite perimeter? Is one of these derivations wrong or am I just missing something?","['geometry', 'fractals', 'analysis']"
977819,"Why is the reduced echelon form of a set of independent vectors, the identity matrix?","If a matrix has linearly independent rows, then its  reduced echelon form is  the identity matrix. I haven't found a concise explanation for this... I have the whole notion in my head but I cannot express this in words.  Can someone explain it?","['matrices', 'linear-algebra']"
977821,"If $f(x) = \sqrt{x}$, what is the domain of $f^4(x)$?","I am unclear if I should consider the function's domain before or after raising it to the power. My textbook gives the following definition of raising a function to a power: By $f^n$, we mean the function that assigns to $x$ the value $[f(x)]^n$.",['algebra-precalculus']
977871,Covering $\mathbb{R}^2$ with uncountably many disjoint non-degenerate line segments,"Is it possible to cover $\mathbb{R}^2$ with uncountably many disjoint non-degenerate line segments? If a formal definition is necessary, let's define a line segment as a set $\{(x, mx+c): x \in [a, b]\}$ for some fixed constants $m, c, a, b \in \mathbb{R}$ with or a set $\{(u, x): x \in [a, b]\}$ for some fixed constants $u, a, b \in \mathbb{R}$. We say a line segment so defined is non-degenerate if $a \neq b$, i.e. the line segment is not a point. This question was vaguely motivated by the observation that it's possible to cover $\mathbb{R}$ with uncountably many disjoint non-degenerate points. YuvalFilmus points out that the answer is negative in the one-dimensional case.",['general-topology']
977882,Proving that $ω_1$ is locally compact,"I'm trying to show that $ω_1$ is locally compact, but when doing so, I need to show something else, which got me a bit stuck on. I'm taking a $\alpha\in ω_1$, so $\{\alpha\}$ is an open set. Since $ω_1$ is Hausdorff, the closure of $\{ \alpha \}$ is $\{ \alpha \}$ itself. Now I want to show that $\{ \alpha \}$ is compact, and this is where I got stuck - I want to show that for every cover of $\{ \alpha \}$ I can find a finite sub-cover, but I don't see how to prove this, what made me wonder if I'm not trying to prove something which is false?","['general-topology', 'ordinals', 'compactness']"
977895,Involution on Cantor space with exactly one fixed point,"Let $X=\{0,1\}^{\mathbb{N}}$ be the Cantor space. What is an example of a continuous map $\sigma : X \to X$ with $\sigma^2=\mathrm{id}$ and $\# \{x \in X : \sigma(x)=x\} = 1$? This has to exist, since $X$ is homeomorphic to $\mathbb{Z}_p$ by Brouwer's Theorem, and there we can take $x \mapsto -x$.","['general-topology', 'logic', 'group-actions']"
977898,Why open unit ball in any infinite dimensional Banach space is finitely chainable?,"In paper ""Pointwise products of uniformly continuous functions"" by Sam B. Nadler, Jr., He defined the finitely chainable as followings : Let $(X,d)$ be a metric space. An $\varepsilon$-chain in $X$ from $x$ to $y$ of length $m$ is a finite sequence $$ x_0 =x,x_1,x_2, \dots, x_m = y $$ such that $d(x_{i-1},x_i) < \varepsilon$ for all $i = 1,2, \dots, m $. We say that $(X,d)$ is finitely chainable  provided that for each $\varepsilon > 0$, there are finitely many points $p_1,p_2, \dots , p_n \in X$ and a positive integer $m$ such that  there is an $\varepsilon$- chain in $X$ of length $m$ from any point $x$ of $X$ to one of the points $p_1,p_2 , \dots , p_n$. Why open unit ball in any infinite dimensional Banach space is finitely chainable?
Note that he hinted by using points on radial lines from the center of open unit ball to form the required chains.","['general-topology', 'metric-spaces', 'functional-analysis', 'real-analysis']"
977926,"$\dfrac1a+\dfrac1b=\dfrac1c$, $a, b, c \in \mathbb{N}$ with no common factor, find all solutions [duplicate]","This question already has answers here : ""If $1/a + 1/b = 1 /c$ where $a, b, c$ are positive integers with no common factor, $(a + b)$ is the square of an integer"" (6 answers) Closed 9 years ago . Given $\dfrac1a+\dfrac1b=\dfrac1c$, where $a, b, c \in \mathbb{N}$ with no common factor, find all solutions. Actually, you can think this question as a follow up of this one . Today, I saw this question and thought whether such numbers really exits! And quickly I found some solutions: $(2,2,1), (3, 6, 2),$ $(4, 12, 3),$ $ (5, 20, 4),$ $(6, 30, 5), (7, 42, 6), (8, 56, 7), (9, 72, 8) \ldots$ (see my comments). Clearly, $(n+1, $ $n(n+1),$ $n)$ for $n \in \mathbb{N}$ is a solution. Interestingly these are the only solutions I found. (Irrelevant after paw88789's comment) So, my question is: Is $(n+1, $ $n(n+1),$ $n)$ for $n \in \mathbb{N}$ the characterization of the above problem? Update After paw88789 's answer, I realize that there are solutions of other form also. So, I get back to my original question: Find all solutions to the above problem.","['elementary-number-theory', 'divisibility', 'number-theory']"
977938,Areas between intersecting chords,"In the circle below let the two chords be called $C_1$ and $C_2$ , and their intersection be some point that is not the center. The chord power theorem tell us that $a \cdot b = c \cdot d$ . I am interested in knowing if there is some similar result for the area of the divided up parts of the circle as well. That is, is there some sort of meaningful relationship between the colored areas? For example, what is the ratio of the total red area to the total area of the circle? What is the ratio of the large red area to the small red area? What information is needed to calculate these/how could I calculate them if I had all the required information? I have not done any geometry for many years, and I am unsure on how to approach these questions. I was trying to find the ratio between the two red areas, and my idea was to divide the red areas up so that each one consists of a segment and a triangle. Then the two triangles are similar to each other, but I was not sure how to find the area of the segmented areas that remain.","['geometry', 'circles', 'area']"
977956,Simplify: $\sin \frac{2\pi}{n} +\sin \frac{4\pi}{n} +\ldots +\sin \frac{2\pi(n-1)}{n}$. [duplicate],This question already has answers here : How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? (8 answers) Closed 9 years ago . Can you help me solve this problem? Simplify: $\sin \dfrac{2\pi}{n} +\sin \dfrac{4\pi}{n} +\ldots +\sin \dfrac{2\pi(n-1)}{n}$.,['trigonometry']
977965,"Matrix A has eigenvalue $λ$ , Prove the eigenvalues of Matrix $(A+kI)$ is (λ + k)","The matrix A has an eigenvalue $λ$ with corresponding eigenvector $e$. Prove that the matrix $(A + kI)$, where $k$ is a real constant and I is the identity matrix, has an eigenvalue $(λ + k)$ My Attempt: $$(A + kI)e$$ $$= Ae + kIe = λe + ke = (λ + k)e$$ Yes I proved it, but I'm not happy with the proof and I don't think its a good proof. Reasons: I started out assuming this : $(A + kI)e$ , But It should be : $$(A + kI)x$$ And I don't know how to prove this way ^^^ Even though it might seem obvious to some of you (not for me) and after the proof it's obvious that $x=e$ , it wasn't right for me  to start my proof with it (since its not mentioned that x=e. So How do I prove this?","['linear-algebra', 'eigenvalues-eigenvectors']"
977998,How calculate the shaded area in this picture?,Let the centers of four circles with the radius  $R=a$ be on 4 vertexs a square with edge size $a$. How calculate the shaded area in this picture?,"['geometry', 'circles', 'area']"
978036,What are the odds of hitting exactly 100 rolling a fair die,"I roll a fair die and sequentially sum the numbers the die shows. What are the odds the summation will hit exactly 100? More generally, what are the odds of hitting an exact target number t while summing the results of numbers sequentially drawn uniformly from a set S . I have experimentally tested this and the result is (warning - spoilers ahead): 1 over the expectation of the drawn numbers. In the case of the fair die 1/((1+2+3+4+5+6)/6) = 6/21 = 2/7 However I do not have a strong intuition, let alone a formal proof, why this is the case. I'll be happy to get your thoughts!","['dice', 'probability']"
978037,"Logic behind the multiplicative form of ""Gauss trick""?",I was going through $ \lim\limits_{n \to{+}\infty}{\sqrt[n]{n!}}$ is infinite I don't follow why/how this is true $(n!)^2 = (1 \cdot n) (2 \cdot (n-1)) (3 \cdot (n-2)) \cdots ((n-2) \cdot 3) ((n-1) \cdot 2) (n \cdot 1)\ge n^n$ I read that At least half the terms in the product for n! will be at least n/2 .. so ? Please advise.,['sequences-and-series']
978051,Find diagonal of inverse matrix,"I have computed the Cholesky of a positive semidefinite matrix $\Theta$ . However, I wish to know the diagonal elements of the inverse of $\Theta^{-1}_{ii}$ . Is it possible to do this using the Cholesky that I have computed? Or will finding the eigenvalues alone (without the orthonormal matrices of a SVD) help this cause? Are there any other suggestions or alternative decompositions that will aid finding the inverse matrix diagonal? I've seen that random projections does wonders for inverting matrices. Could something like this be applied here?","['projective-space', 'matrices', 'random-matrices', 'matrix-decomposition']"
978065,How prime numbers are related to special functions?,"We know that the Riemann zeta function is defined as $$\zeta(s)=\sum_{n=1}^\infty\frac{1}{n^s},$$ for all $\Re(s)>1$. Because of Euler product formula we also know that $$\zeta(s) = \sum_{n=1}^\infty\frac{1}{n^s} = \prod_{p \text{ prime}} \frac{1}{1-p^{-s}},$$
for all $\Re(s)>1.$ There are a lot of functions related to Riemann zeta function. For example $\zeta(s)=\zeta(s,1)$ where $\zeta(s,q)$ is the Hurwitz zeta function . $\zeta(s)=\operatorname{Li}_s(1)$, where $\operatorname{Li}_s(z)$ is the polylogarithm . $\zeta(s)=(1-2^{-s})^{-1}\chi_s(1)$, where $\chi_s(z)$ Legendre chi function $\zeta(s)=\Phi (1,s,1)$, where $\Phi(z, s, \alpha)$ is the Lerch zeta function $ \zeta(s) = (1-2^{1-s})^{-1}\eta(s)$, where $\eta(s)$ is the Dirichlet eta function $\dots$ and there are lot of other related functions such as multiple zeta function , Barnes zeta function , the Clausen function , etc. Question. Are there Euler product formula type statements to other special functions?","['special-functions', 'riemann-zeta', 'number-theory', 'prime-numbers', 'polylogarithm']"
978096,Is $\omega_1$ metrizable?,"Following Urysohn's metrization theorem, I would like to prove or disprove that $\omega_1$ is metrizable. I know it is hausdorff, but I'm not sure whether or not it is second countable, and I'm at loss on how I can prove or disprove it is second countable. And if I'll disprove it, will it tell me that $\omega_1$ is not metrizable, or is Urysohn's theorem only an 'if' and not an 'iff'? Or perhaps there is a more comfortable-to-use in here theorem to prove/disprove $\omega_1$ being metrizable?","['general-topology', 'ordinals']"
978159,"Looking for an example of a bijective continuous function $f:\mathbb{Q} \to \mathbb{Q}$ such that $f(-1)=0$, $f(0)=1$ and $f(1)=-1$?","Clearly such a function does not exist from $\mathbb{R}$ to itself, but apparently it does in $\mathbb{Q}$ and I don't see how it could... Can you give me an example and explain to me how you thought of this one? Thank you very much! I first simply thaugh of putting the values of $f$ at the three special values of $x$ and making it $f(x)=x$ everywhere else, or constant, but it doesn't work...","['continuity', 'real-analysis', 'analysis']"
978167,Finding all natural $n$ such that $2^n+2^{2n} +2^{3n}$ has only $2$ prime factors.,"Find all natural $n$ such that $2^n+2^{2n} +2^{3n}$ has only $2$ prime factors. I've tried checking the first 6-7 $n$'s on wolframalpha, but I don't see any patterns for even nor odd $n$'s. At first I thought for all odd $n$'s it was divisible by $2,3,7$, but $n=5$ doesn't work ($n=1,3,7$ do work). How are these $n$ found?","['prime-numbers', 'factoring', 'algebra-precalculus']"
978174,"If $x$ is a positive rational but not an integer, is $x^x$ irrational?","Let $x$ be positive, rational, but not an integer. That means $x$ can be written as $\frac{p}{q}$ with $p,q$ coprime, $p,q \neq 0$ and $q \neq 1$. Is $x^x$ always irrational? I think that this has to be the case, but I can't prove it. $x^x = (\frac{p}{q})^\frac{p}{q} = \frac{p^\frac{p}{q}}{q^\frac{p}{q}}$ I know that $p^\frac{p}{q}$ and $q^\frac{p}{q}$ can't both be rational, but there are cases where the division of two irrational numbers gives us an rational number. For example $\frac{\sqrt{2}}{\sqrt{2}} = 1$","['exponentiation', 'rationality-testing', 'number-theory']"
978177,Integrate $\int\frac{dx}{(x^2+1)\sqrt{x^2+2}}$,"I would like some guidance regarding the following integral:
$$\int\frac{dx}{(x^2+1)\sqrt{x^2+2}}$$ EDIT: The upper problem was derived from the following integral $$\int\frac{\sqrt{x^2+2}}{x^2+1}dx$$ Where I rationalized the numerator which followed into: $$\int\frac{dx}{\sqrt{x^2+2}}+\int\frac{dx}{(x^2+1)\sqrt{x^2+2}}$$","['calculus', 'integration', 'indefinite-integrals']"
978181,"If $f\in A_k(V)$ and $g\in A_l(V)$ show $i_v(f\wedge g)=i_vf\wedge g+(-1)^kf\wedge i_vg$ - I've got the gist, not sure how to write","If $f\in A_k(V)$ and $g\in A_l(V)$ show $i_v(f\wedge g)=i_vf\wedge g+(-1)^kf\wedge i_vg$ With $A_k(V)$ being the vector space of alternating k-tensors. for $f\in A_k(V)$ for some $v\in V$ we define $i_vf\in V_{k-1}(V)$ by $i_vf(v_1,v_2,...,v_{k-1})=f(v,v_1,v_2,...,v_{k-1})$ My ""answer"" This is similar to combinatorics, we all know Pascal's relation: $(n+1)Cr=nC(r-1)+nCr$ the proof is simple, given a set of $\{a_1,...,a_n,b\}$ (b is the $n+1$th thing) and tasked with choosing r things from it We may have b then $r-1$ things from the remaining $n$, or! We do not have b then $r$ things from the remaining $n$ I think that's at play here. why: Well $$f\wedge g(a_1,...,a_{k+l})=\sum_{\sigma\in S_{k+l}}\text{sign}(\sigma)f(a_{\sigma_1},...,a_{\sigma_k})g(a_{\sigma_{k+1}},...,a_{\sigma_{k+l}})
$$ So $$i_v(f\wedge g)(a_1,...,a_{k+l-1})=f\wedge g(v,a_1,...,a_{k+l-1})$$ For a permutation of $\{v,a_1,...,a_{k+l-1}\}$ either v is an argument to f or it is not. If the $v$ is an argument to $f$ then we're somewhere with the $i_vf\wedge g$ part. Otherwise the $v$ is one of g's argument. This is what I mean by ""gist"" of argument, I'm struggling to form this into the expression I want as a result.","['vector-spaces', 'manifolds', 'differential-geometry']"
978194,What is the maximal size of an equal-distance set in $\mathbb{R}^n$?,"Let $A\subseteq \mathbb{R}^n$ with the casual metric and $c\in\mathbb{R}^+$ be a real positive number, such that for every $a_1, a_2\in A$ if $a_1\neq a_2$ then $d(a_1,a_2)=c$. What is the maximal size of such a set $A$? My intuition says that it's $n+1$, i.e. the dimension of the euclidean space we're working with plus one, but I'm not sure on how to prove this - assuming this is correct? It's most easy to see this in $\mathbb{R}$  - two points on the real line, and in $\mathbb{R}^2$ - a triangle, but I'm not sure it's true for every $n\in \mathbb{N}$.","['general-topology', 'geometry', 'metric-spaces']"
978246,What is the quickest way to find the characteristic polynomial of this matrix?,"Let $e_k$ be the $k$-th vector of the canonical base of $\mathbb R^n$ and let $$B = [e_2 \mid e_3 \mid \dots \mid e_n \mid e_1]$$ What it the quickest way to show that the charachteristic polynomial of $B$ is $\lambda^n - 1$? My work I can show that if $\lambda$ is an eigenvalue of $B$, then $\lambda^n = 1$ (trivially because $B^n = I$)but this does not suffice as those $\lambda$ can all be equal to one; I want to show that they are distinct. As I did not know how to do that, I resorted to use the fact (which is obvious, altough it should be proved more formally) that $tr(B^k) = 0$ for all $k < n$. Then, as the coefficients in the characteristic polynomial of $B$ (except the first and last one) are all polynomials in the variables $tr(B), tr(B^2), \dots , tr(B^{n-1})$ they are all equal to $0$.
And since $\det(B) = (-1)^{n+1}$, we have $$P_B(\lambda) = \lambda^n + (-1)^n(-1)^{n+1} = \lambda^n - 1$$ But it seems like an overkill, especially because I do not know how to prove that those coefficients are indeed polynomials in $tr(B^i)$.
Can someone suggest a more elegant way?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'polynomials']"
978251,Hartshorne II Prop 6.8,"My weaknesses with commutative algebra are really slowing down my progress through Hartshorne.  I hope someone can help me understand some statements in the proof of the proposition below. Prop 6.8: Let $X$ be a complete nonsingular curve over $k$, let $Y$ be any curve over $k$, and let $f:X\to Y$ be a morphism.  Then either (1) $f(X)=$ a point, or (2) $f(X)=Y$.  In case (2), $K(X)$ is a finite extension field of $K(Y)$, $f$ is a finite morphism, and $Y$ is also complete. I am confused about two statements in the proof, when we have case (2):  First, how do we know that $K(X)$ and $K(Y)$ finitely generated extension fields of $k$?  Second, why is it clear that $U=f^{-1}V$? Also, Hartshorne then goes on to define the degree of any finite morphism $f:X\to Y$ of curves as the degree of the field extension $[K(X):K(Y)]$.  But how do we know that $K(X)$ contains $K(Y)$?","['commutative-algebra', 'algebraic-geometry']"
978266,Show $\sum_n \frac{z^{2^n}}{1-z^{2^{n+1}}} = \frac{z}{1-z}$,Show $\displaystyle\sum_{n=0}^\infty \frac{z^{2^n}}{1-z^{2^{n+1}}} = \frac{z}{1-z}$ for $|z|<1$. This is an additional problem for my complex analysis class and I've attempted it for a few hours but ended up taking wrong routes. All of my attempts I haven't used complex analysis at all and I don't see how I could here. edit: this is meant for a BEGINNER complex analysis course so please try keep the solutions to that (if you could) Any help would be great,['complex-analysis']
978279,Failing to reproduce specific Functional derivative,"I'm failing to reproduce an (indirect) result in a paper, namely $${δF[g]\overδg(x,y,z)}={r^4\over\ell^5} $$
where $F[g]=\iiint \frac{2dxdydz}{\ell g(x,y,z)}    $ and $g(x,y,z)=-{\ell^2 \over r^2} $. Note that $\ell$ and $r$ do not depend on $x$, $y$ or $z$. I'm not terribly familiar with functional derivatives, but it seems to me that this is a simple example, since no derivatives of $g$ appear in $F$, and hence, when $F$ is of the form $F[ρ]=\int f(ρ(\mathbf x)) d\mathbf x $, the following should hold [e.g. from wiki] :
$${δF[f]\overδρ(\mathbf x)}=\frac {\partial f}{\partial ρ}$$
In this particular case, this gives
$$\begin{align}
{δF[g]\overδg(x,y,z)} &= \frac\partial{\partial g}\left(\frac {2}{\ell g(x,y,z)}\right)\\
&=- \frac {2} {\ell g^2(x,y,z)}\\
&=-2\frac {r^4} {\ell^5}
\end{align}$$ This isn't what the authors find. The weird thing about this derivation is that the function derived with respect to, $g$, doesn't depend on its arguments but on $r$, and so does the functional. It is as if I'm looking for a generalized relation for when $F$ of the form $F[ρ]=\int f(ρ(\mathbf x, r)) d\mathbf x $ rather than of the form $F[ρ]=\int f(ρ(\mathbf x)) d\mathbf x $, 
$${δF[f]\overδρ(\mathbf x, r)}=?$$ What am I doing wrong, and more generally, does this dependence on $r$ even make a difference? This is the paper I'm referring to, page 11, eq. (46) and line below. The calculation is the $AdS_4$ case, with $F \to S_{ct}=-\frac 2\ell\int dtdx_idx_i \sqrt{-γ}, g \to γ^{tt}=-\frac {\ell^2}{r^2}$ and  $\sqrt {-γ}=-(γ^{tt})^{-1}$. They claim $8πGT_{tt}=0=-2\frac {r^2}{\ell^3}+\frac 2{\sqrt{-γ}} \frac {δS_{ct}}{δγ^{tt}}$ from which I get the 'indirect' statement (at top): $\frac {δS_{ct}}{δγ^{tt}} =\frac {r^4}{ \ell^5}$","['functional-analysis', 'derivatives', 'functional-equations']"
978291,Quadratic Irrationality of the Periodic points of the Gauss map,"If $G:[0,1] \rightarrow [0,1]$ is the Gauss map which is defined as
$$G(x) = \left\{\frac{1}{x}\right\} = \frac{1}{x} - \left\lfloor\frac{1}{x}\right\rfloor,$$
show that if $x$ is periodic of order $n$ for $G$ then it must be an quadratic irrational. I am looking for a quadratic equation I believe. One can solve $G(x)=x$ for $n=1$ quite easily and with some more work can solve $G^2(x)=x$. However, this method does not generalise well to general $n$, due to the number of terms. Moreover, I could not see a formula that induction could be used upon that may make the problem easier. Can anyone solve this problem?","['dynamical-systems', 'continued-fractions', 'functions', 'quadratics', 'periodic-functions']"
978314,What is the equation of the reflections of a fixed point across all the tangents to a fixed circle?,"Given a fixed circle "" c "" and a fixed point "" A "" (in the plane of the circle), draw the tangent to the circle at a variable point "" X "" (movable, but constrained to be on the circle), reflect "" A "" across the tangent to obtain point "" A' "", what is the equation of the geometric locus traced by "" A' "" as "" X "" performs a full rotation on the circle?","['analytic-geometry', 'geometry']"
978351,Selfadjointness of the Dirac operator on the infinite-dimensional Hilbert space,"I am a physicist, so my background in functional analysis is limited only to basics. However, I would like to prove that the free Dirac operator is selfadjoint (or Hermitian, or neither). The free Dirac operator is a differential operator of the following form: $D = -i\alpha \nabla + \beta$, where $\alpha$ and $\beta$ are just Hermitian $4 \times 4$ matrices. This operator acts on a state of 4-component' functions from $\mathbb{R}^3$ to $\mathbb{C}^4$. The inner product is defined as integral of the product of two functions from this space (one of them being a complex conjugate). I suppose that these functions should also be square-integrable, i.e. from $L^2$. (If they should also be defined on some bounded interval, then the boundary conditions could just be: $f(0) = f(1) = 0$.) From a mathematical point of view, what else is needed to formally prove that this operator is self adjoint?","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
978355,Can $\mathbb{R}$ be partitioned into $n$ dense sets with same cardinality?,"Are there sets $S_i\subseteq\mathbb{R}$ with $i\leq n$ such that $S_i$ are disjoint, $S_i$ have same cardinality, $S_i$ are dense in $\mathbb{R}$?",['elementary-set-theory']
978384,Area of octagon constructed in a square,"The following picture is constructed by connecting each corner of a square with the midpoint of a side from the square that is not adjacent to the corner. These lines create the following red octagon: The question is, what is the ratio between the area of the octagon and the area of the square. One is supposed to find the solution without a ruler. By removing some lines, I find it easy to see that the ratio between the yellow area and the square is 1/4. But I am not sure if this helps.",['geometry']
978385,$A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset$ holds for all $n$. Must it be that $\bigcap_{n = 1}^{\infty} A_n \ne \emptyset$?,"Let $A_1, A_2, A_3, \,\ldots$ be sets such that $A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset$ holds for all $n$ . Must it be that $\bigcap_{n = 1}^{\infty}A_n  \ne \emptyset$ ? I answered no. Here is my ""proof"". Define $A_n = \{n+1, n+2, \,\ldots\}$ . Then $A_1 \cap A_2 \cap \cdots \cap A_n = \{n+1, n+2, \,\ldots\}$ . For all integers $n$ , $\{n+1, n+2, \,\ldots\} \ne \emptyset$ , since it contains $n+1$ , and there is no largest integer. Now consider $\bigcap_{n = 1}^{\infty} A_n$ . Suppose it contains an integer $m$ . But $m \notin A_{m}$ by definition, hence $m \notin \bigcap_{n = 1}^{\infty} A_n$ , so $\bigcap_{n = 1}^{\infty} A_n = \emptyset$ . $$\tag*{$\blacksquare$}$$ Is that correct? I ask because in my lecture notes, the definition of $\bigcap_{n = 1}^{\infty} A_n$ is $\{x : x \in A_n \ \forall n \}$ which (to me) seems to be equivalent to "" $A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset$ holds for all $n$ "", which would of course mean the answer is yes.",['elementary-set-theory']
978405,why is $\{x\} \in \{x\}$ false?,"I apologise for this simple question. 
So if {x} is a subset of {x, {x}}, then why isn't {x} belong to {x}?",['elementary-set-theory']
978423,If $E[X|Y]=Y$ almost surely and $E[Y|X]=X$ almost surely then $X=Y$ almost surely,"Assume that $X$ and $Y$ are two random variables such that $Y=E[X|Y]$ almost surely and $X= E[Y|X]$ almost surely. Prove that $X=Y$ almost surely. The hint I was given is to evaluate:
$$E[X-Y;X>a,Y\leq a] + E[X-Y;X\leq a,Y\leq a]$$ which I can write as: $$\int_A(X-Y)dP +\int_B(X-Y)dP$$ where $A=\{X>a, Y\leq a\}$ and $B=\{X\leq a,Y\leq a\}$. But I need some more hints.","['probability-theory', 'conditional-expectation']"
978486,Parametric form of square,"What is the appropriate parametric equation of the boundary of a square? For example, the unit circle has a parametric equation $x(t)=\cos(t)$ and $y(t)=\sin(t)$.","['geometry', 'parametric', 'derivatives']"
978490,"Why is the outer measure of the set of irrational numbers in the interval [0,1] equal to 1?","Just learned Lebesgue outer measure from Royden's Real Analysis. Let me give my proof. First, let $A$ be the set of irrational numbers in [0,1]. So $A\subset [0,1]\Rightarrow m^*(A)\le m^*([0,1])=1$. Then I want to show $m^*(A)\ge 1$ by using $\sum_{k=1}^\infty l(I_k)\le m^*(A)+\epsilon$. $\{I_k\}_k$ covers $A$, then add $I_0$ to this collection. $[0,1]\subset I_0$. So $l(I_0)+\sum_{k=1}^\infty l(I_k)\le m^*(A)+\epsilon\Rightarrow m^*(A)\ge l(I_0)+\sum_{k=1}^\infty l(I_k)-\epsilon\ge 1+\sum_{k=1}^\infty l(I_k)-\epsilon$ We can always choose a small enough $\epsilon>0$ such that $\sum_{k=1}^\infty l(I_k)-\epsilon>0$. Therefore, $m^*(A)=1$.","['measure-theory', 'proof-verification', 'real-analysis', 'analysis', 'lebesgue-measure']"
978519,Countable Union to Countable Disjoint Union,"In many texts, the construction of a countable disjoint union of sets from a sequence of sets, $E_1, E_2,E_3,\ldots$ follows from: Let $F_1 = E_1, F_2 = E_2\setminus E_1,F_3 = E_3\setminus (E_1\cup E_2),\ldots,F_n=E_n \setminus \bigcup\limits_{k=1}^{n-1} E_k$, etc. I'm wondering how to show that $\bigcup\limits_{n=1}^{\infty}F_n = \bigcup\limits_{k=1}^\infty E_k$. I can visualize why this is true, but analytically, I find it boggling.",['elementary-set-theory']
978556,How are these definitions of the limit superior and limit inferior equivalent?,"I have come across these three definitions of the limit superior (or upper limit) and the limit inferior (or lower limit) of a sequence of real numbers and I wonder how to establish the equivalence of these. Walter Rudin: PRINCIPLES OF MATHEMATICAL ANALYSIS, 3rd edition: 
Definition 3.16: Given a sequence $\{s_n\}$ of real numbers, let $E$ be the set of numbers $x$ (in the extended real number system) such that $s_{n_k} \to x$ for some subsequence $\{s_{n_k}\}$. This set contains all subsequential limits ..., plus possibly the numbers $+\infty$, $-\infty$. We now ... put 
$$s^{*} = \sup E,$$
$$s_{*} = \inf E.$$
The numbers $s^{*}$, $s_{*}$ are called the upper and lower limits of $\{s_n\}$; we use the notation 
$$ \lim_{n \to \infty} \sup s_n = s^{*}, \, \, \, \lim_{n \to \infty} \inf s_n = s_{*}.$$ Tom M. Apostol: MATHEMATICAL ANALYSIS, 2nd edition: 
Sec. 8.3: Definition 8.2: Let $\{a_n\}$ be a sequence of real numbers. Suppose there is a real number $U$ satisfying the following conditions: i} For every $\epsilon > 0$ there exists an integer $N$ such that $n > N$ implies $$a_n < U + \epsilon.$$
ii) Given $\epsilon > 0$ and given $m > 0$, there exists an integer $n> m$ such that $$a_n > U - \epsilon.$$ Then $U$ is called the limit superior (or upper limit) of $\{a_n\}$, and we write $$U = \lim_{n \to \infty} \sup a_n.$$
Statement (i) implies that the set $\{a_1, a_2, a_3, \ldots \}$ is bounded above. If this set is not bounded above, we define $$\lim_{n\to\infty}\sup a_n = +\infty.$$ If the set is bounded above but not bounded below and if $\{a_n\}$ has no finite limit superior, then we say $\lim \sup_{n\to\infty} a_n = -\infty$. The limit inferior (or lower limit) of $\{a_n\}$ is defined as follows: $$\lim_{n\to\infty}\inf a_n = -\lim_{n\to\infty}\sup b_n,$$ where $b_n = -a_n$ for $n= 1, 2, 3, \ldots$. Robert G. Bartle and Donald R. Sherbert: INTRODUCTION TO REAL ANALYSIS, 3rd edition: Exercises for Section 3.3: Problem 10: Let $(x_n)$ be a bounded sequence of real numbers, and for each $n\in \mathbb{N}$ let $s_n \colon= \sup \{x_k \colon k \geq n\}$ and let $t_n \colon= \inf \{x_k \colon k \geq n\}$. Prove that $(s_n)$ and $(t_n)$ are monotone and convergent. Also prove that if $\lim (s_n) = \lim (t_n)$, then $(x_n)$ is convergent. [One calls $\lim (s_n)$ the limit superior of $(x_n)$ and $\lim (t_n)$ the limit inferior of $(x_n)$.] Now how can one show that the above three definitions are equivalent (i.e. these three definitions are of the same pair of numbers)?","['sequences-and-series', 'calculus', 'real-analysis', 'analysis', 'limits']"
978558,Integrate $\int_0^{\infty } \frac{\cos x}{x} dx$,"Although I have known that $\displaystyle\int_0^\infty {{\sin x} \over x} \, dx = {\pi  \over 2}$, I have no idea how to work out $\displaystyle\int_0^{ + \infty } {{\cos x} \over x} \, dx$. How can I?","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'analysis']"
978560,Evaluating $\int_0^\infty \frac{dx}{\sqrt{x}[x^2+(1+2\sqrt{2})x+1][1-x+x^2-x^3+...+x^{50}]}$,"My brother's friend gave me the following wicked integral with a beautiful result \begin{equation}
{\Large\int_0^\infty} \frac{dx}{\sqrt{x} \bigg[x^2+\left(1+2\sqrt{2}\right)x+1\bigg] \bigg[1-x+x^2-x^3+\cdots+x^{50}\bigg]}={\large\left(\sqrt{2}-1\right)\pi}
\end{equation} He claimed the above integral can be generalised to the following form \begin{equation}
{\Large\int_0^\infty} \frac{dx}{\sqrt{x} \bigg[x^2+ax+1\bigg] \bigg[1-x+x^2-x^3+\cdots+(-x)^{n}\bigg]}=\ldots
\end{equation} This is a challenging problem. How to prove it and what is the closed-form of the general integral?","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
978561,Convergence tests for a complex series?,"For $\sum_{i=1}^{\infty} z_i$, where $z_i \in \mathbb{C}$, how should the convergence tests be performed? I read somewhere that the tests applied for convergence of complex series are same as that for real series, but I am wondering if this is so, does that mean that imaginary part of the complex numbers doesn't play any role?",['sequences-and-series']
978618,Most elementary proof that a determinant is divisible by $m$,"So a challenge problem states that you have an $n \times n$ matrix, where each entry is an integer between $0$ and $9$, and when each row is read as a base-10 number the number is divisible by a common factor $m$. The problem is to prove that the determinant of the matrix is also divisible by $m$. So far I have two proofs: If $m$ is a power of a prime, then we can consider the field ${\mathbb F}_m$ and the vector $(10^{n-1}, 10^{n-2}, \ldots, 1)$ is a non-zero vector in the kernel of the matrix over ${\mathbb F}_m$ so the determinant is $0$ over the field by general linear algebra. Or, for arbitrary $m$, we can add $10^{n-1}$ times the first column and $10^{n-2}$ times the second column and so forth and add it all to the last column without changing the determinant, and then we get the the last column is all numbers divisible by $m$ so the determinant is divisible by $m$ by expanding the determinant along the last column. However are there any more elementary proofs, say that just use the basic full expansion formula of the determinant, without using so many properties of the determinant?","['linear-algebra', 'determinant', 'abstract-algebra', 'number-theory']"
978642,How to sort vertices of a polygon in counter clockwise order?,How to sort vertices of a polygon in counter clockwise order? I want to create a function (algorithm) which compares two vectors $\vec v$ and $\vec u$ which are vertices in a polygon. It should choose the vertex which counter clockwise index inside the polygon is higher. The first index should be the bottom left vertex. I this example it should choose $\vec u$. For the first quadrant I can say that $\vec u > \vec v$ if $|\vec u| > |\vec v|$ and $\forall\vec u > \forall\vec v$. The length should be weighted more than the angle in order that vertex 1 gets a lower index than vertex 2. But this rule only works for the first quadrant. I could first move the whole polygon into the first quadrant but I want to find a better solution. Any ideas?,"['geometry', 'polygons', 'vectors']"
978683,Invariance of domain in $\mathbb{R}^2$,"Let $U \subseteq \mathbb{R}^2$ an open subset and let $f:U\rightarrow \mathbb {R}^2$ is be a continuous function. I have the following version of Invariance of Domain Theorem (in  $\mathbb{R}^2$): If $f$ is injective then $f$ is homeomorphism. I need to show: a) If $f$ is locally injective then $f$ is open map. b) If there is $a\in U$ such that $f^{-1}(a)$ is discrete subset, and $f$ is locally injective in $U\setminus {a}$, then $f$ is open map. For (a) I tried: If $f(U)=\emptyset$ then there is nothing to prove. So I took some $y\in f(U)$, $y=f(x)$ for an $x\in U$. then there is an open subset $V\subseteq U$ such that $x\in V$ and $f|_V$ is injective. I tried to look at $\overline V$ and somehow use the invariance of domain theorem above, but I can't figure what to do. For (b) - I'm lost. can someone help me?",['general-topology']
978696,Continuity of $a^x$ when it's defined by the ordinary way,"I've searched for the discussion of proving the continuity of exponential function, in most cases the function is defined by power series or inverse of log function where the log is defined by integration of $1/x$. Does anyone know the prove (or sketch of prove) of $a^x$ being continuous when considered as real values function, where $a^x$ is defined the ordinary way, that is, When $x$ is positive integer, $a^x$ is $a$ multiply x times, $a^{-x}=\frac{1}{a^x}$, $a^{1/x}$ is the unique number $b$ that satisfies $b^x=a$. For general real number r, define $a^r=sup\{a^q, q\in Q, q\leq r\}$","['functions', 'calculus', 'real-analysis', 'supremum-and-infimum']"
978717,Is there a complete orthornomal basis of a Hilbert space which takes positive values on a discrete set?,"Is there a complete orthonormal basis $\{f_n\}$ (of continuous functions) of the Hilbert space of square integrable functions on $[0,\,\infty)$ for which there exists a countable set $S\subset [0,\,\infty)$ such that $\forall x \in S$ we have $f_n(x)\geq 0,\, \forall n?$ Or could anyone point me to a paper on a similar topic? Thank you in advance.","['fourier-analysis', 'functional-analysis', 'analysis']"
978724,"Let $a$ be an element of order $n$ in a group $G$. If $a^m$ has order $n$, then $m$ and $n$ are relatively prime.","Let $a$ be an element of order $n$ in a group $G$ . If $a^m$ has order $n$ , then $m$ and $n$ are relatively prime. Assume $a^m$ has order $n$ and, $m$ and $n$ are not relatively prime.  Then $m$ and $n$ have a common factor, say $q$ . So, $m=m'q$ and $n=n'q$ . So, $$(a^m)^{n'}=(a^m)^\frac nq= (a^{mn})^\frac 1q= e^\frac 1q=e$$ So, $(a^m)^\frac nq=(a^m)^n=e$ . Since $a^m$ has order $n$ : $e \neq (a^m)^\frac nq = (a^m)^n$ . Contradiction.","['proof-verification', 'finite-groups', 'group-theory', 'abstract-algebra']"
978726,How do I make sense of $\{ n \} \cap n$?,"I've been learning set theory, and I've come across an exercise in which I'm trying to prove that $\forall x \forall y x \in y \rightarrow y \neq x$. I want to use the axiom of foundation to prove this, but I'm stuck making sense of that axiom for the base case in which a set contains something like a single integer. If I have $x=\{ y, 5 \}$ for example, and $y=\{5\}$, the axiom of foundation seems to require that $x\cap5=\emptyset$, but it seems like this set should intersect 5. How do I make sense of this? Is the intersection of a set and an integer just always defined as $\emptyset$? Is it even possible to define the intersection of the set and a non-set member of the set?",['elementary-set-theory']
978734,Bound on number of breakable sets,"Let $\mathcal{S}$ be a finite family of finite sets. A finite set $A$ is called breakable if for every $B\subseteq A$, there exists $S\in \mathcal{S}$ such that $A\cap S=B$. Show that at least $|\mathcal{S}|$ sets are breakable. [Source: Hungarian competition problem]","['contest-math', 'combinatorics']"
