question_id,title,body,tags
228010,Solving the recurrence relation $a_n=\frac{a_{n-1}^2+a_{n-2}^2}{a_{n-1}+a_{n-2}}$,"I would like to know if there is a way to get the recurrence relation
$$a_n=\frac{a_{n-1}^2+a_{n-2}^2}{a_{n-1}+a_{n-2}},\qquad (a_1=1,a_2=2)$$
in closed form, or if there is no such way, how one could proceed to find the limit of $(a_n)$ to by some sort of estimation (or some other method I don't know about).","['recurrence-relations', 'sequences-and-series']"
228014,Mass of wire described by curve with specified density function (Double integral),"Mass of the wire of a curve described by $$y = x^2 +1 $$ where $0\le x\le 1$
with density $$ \rho(x,y) = 12x $$ I couldn't get the correct answer for this one. What I did: $$ m = \int^{0}_{1}\int^{1}_{x^2} 12 x dy dx $$ that gives me $3$, which is not correct.","['multivariable-calculus', 'integration']"
228045,Relative maximum and minimum of function of three variables,"I know that how to find relative maximum and minimum of function of two variables. How can I determine function when $f(x,y,z)=x^2+y^2-z^2 $ has relative maximum or relative minimum? Please give me hint. In general when does $f(x,y,z)$ have relative minimum or relative maximum? Thanks in advance.","['multivariable-calculus', 'calculus']"
228054,Fitting normal distribution to the data,"I have been given a set of data points. How can I find the best fit of the form $$\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{\sigma^2}}?$$
Even better if Sage can do it. And how can I approximate how good the fit is?","['statistics', 'normal-distribution', 'sagemath']"
228063,Proj construction and fibered products,"How to show, that
$Proj \, A[x_0,...,x_n] = Proj \, \mathbb{Z}[x_0,...,x_n] \times_\mathbb{Z} Spec \, A$?
It is used in Hartshorne , Algebraic geometry , section 2.7.","['commutative-algebra', 'algebraic-geometry', 'schemes', 'projective-schemes']"
228080,$|\operatorname{Im}f(z)|\leq |\operatorname{Re}f(z)|$ then $f$ is constant,"Let $f\colon\mathbb C \to \mathbb C$ be entire. Show that if
$|\operatorname{Im}f(z)|\leq |\operatorname{Re}f(z)|$ for all $z \in \mathbb C$, then $f$ is constant on $\mathbb C$. How I can answer this by  considering the distance between $f(z)$ and $i$.",['complex-analysis']
228088,Spectrum of a block matrix,"Let $A$ be real , symmetric of order $n$ with $A > 0$ and the eigenvalues of $A$ are $a_1 \ge a_2 \ge \cdots \ge a_n > 0$. Let $B$ be a real matrix of order $n\times m$ ($m\le n$), $\operatorname{rank}B=m$ and
whose singular values are $b_1 \ge \cdots \ge b_m > 0$.
If \[X = \begin{pmatrix} A   &  B \\
        B^t &  0\end{pmatrix}\]
then show that the spectrum of $X$ is a subset of $P \cup Q$
where $$P =\left [ \frac 12\left(a_n-\sqrt{a_n^2+4b_1^2}\right) , \frac 12\left(a_1-\sqrt{a_1^2+4b_m^2}\right)\right]$$ and $$
      Q = \left[ a_n , \frac 12 \left(a_1+\sqrt{a_1^2+4b_1^2}\right)\right].$$ Thanks for any help.","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'singular-values', 'block-matrices']"
228093,Dependent chances using Bayes' rule,"The chance that somebody get's mad cow disease is 0.01 (1%). If someone visits the USA this chance becomes 0.05 (5%). The chance that somebody goes to the USA is 0.01 (1%). If someone goes to the USA, he'll most likely buy the flag as a souvenir, the chance that somebody does this is 0.7 (70%). Because the flag is well known, people who never have been to the USA have a chance of 0.3 (30%) to have the flag.
Now given that somebody has the mad cow disease and he has the flag of the USA, what are the chances he has visited the USA? Thus: P(USA) = 0.01 P(MCD) = 0.01 P(MCD|USA) = 0.05 P(flag|!USA) = 0.3 P(flag|USA) = 0.7 Following bayes' rule we can calculate the chance that somebody has been to america given the knowledge this person has MCD: P(USA|MCD) = P(MCD|USA)*P(USA)/P(MCD) = 0.05 *0.01 / 0.01 = 0.05. Now the problem is how do we calculate the chance that someone has visited the USA given he has the american flag, and after that given somebody has and mad cow disease and the american flag the chance he has been to america. How does one does this? Cheers!","['statistics', 'probability']"
228123,Negative integral on intervals implies negative function?,"Let $f \in L^1([0,1])$ be such that for all $t \geq s$, $\displaystyle \int_s^t f(u)du \leq 0$. Is it true that $f\leq 0$ almost everywhere?","['measure-theory', 'integration', 'lp-spaces']"
228131,Normal subgroup and Lie algebra,"I have an exercise of Lie group as follows: ""Let $G,H$ be closed connected subgroup of $GL_n(\mathbb{R})$ , and $H$ be subgoup of $G$ . Suppose that $\operatorname{Lie}(H)$ is an ideal of $\operatorname{Lie}(G)$ . Prove that $H$ is a normal subgroup of $G$ .""
I get stuck to solve this problem. Also I have no idea to use the connectedness of $G$ and $H$ . Some one can help me? Thanks a lot!","['lie-groups', 'differential-geometry']"
228153,First Order Homogeneous Differential Equation (with a Linear shift),"Is there a simpler method to this solve this equation $$(x-2y+1)\text dx+(4x-3y-6)\text dy=0$$ $$\frac{\text dy}{\text dx}=\frac{2y-x-1}{4x-3y-6}$$ $$\frac{\text d Y}{ \text d X}=\frac{2(Y+k)-(X+h)-1}{4(X+h)-3(Y+k)-6}$$ $$\frac{\text d Y}{ \text d X}=\frac{2Y-X+(2k-h-1)}{4X-3Y+(4h-3k-6)}$$ $$2k-h-1=0\qquad4h-3k-6=0$$
$$h=2k-1\qquad 4(2k-1)-3k-6=0$$
$$5k-10=0\qquad k=2\qquad h=2(2)-1\qquad h=3$$
$$y=Y+2\qquad\qquad x=X+3$$
$$Y=y-2\qquad\qquad X=x-3$$ $$\frac{\text d Y}{\text d X}=\frac{2Y-X}{4X-3Y}=\frac{2\left(\frac{Y}{X}\right)-1}{4-3\left(\frac{Y}{X}\right)}$$ $$\left(\frac{Y}{X}\right)=V\qquad Y=VX$$ $$\frac{\text d Y}{\text d X}=X\frac{\text d V}{\text d X}+V$$ $$X\frac{\text d V}{\text d X}+V=\frac{2V-1}{4-3V}$$ $$X\frac{\text d V}{\text d X}=\frac{2V-1}{4-3V}-V$$ $$X\frac{\text d V}{\text d X}=\frac{2V-1}{4-3V}-V\left(\frac{4-3V}{4-3V}\right)$$ $$X\frac{\text d V}{\text d X}=\frac{3V^2-2V-1}{4-3V}$$ $$\frac{\text dX}{X}=\frac{4-3V}{3V^2-2V-1}\text dV$$ $$\int\frac{\text dX}{X}=\int\frac{4-3V}{3V^2-2V-1}\text dV$$ $$\ln X=\int\frac{4-3V}{3V^2-2V-1}\text dV$$ $$3V^2-2V-1=(V-1) \overline {\bigg)3V^2-2V-1}$$ $$\qquad3V+1$$$$=(V-1) \overline {\bigg)3V^2-2V-1}$$$$\quad\qquad3V^2-3V$$$$\qquad\qquad\qquad\qquad V-1$$$$\qquad\qquad\qquad\qquad \underline{V-1}$$$$\qquad\qquad\qquad\qquad 0$$ $$3V^2-2V-1=(V-1)(3V+1)$$ $$\frac{4-3V}{3V^2-2V-1}=\frac{4-3V}{(V-1)(3V+1)}=\frac{\alpha}{(V-1)}+\frac{\beta }{(3V+1)}=\frac{(3V+1)\alpha+(V-1)\beta}{(V-1)(3V+1)}$$ $$4-3V=(3V+1)\alpha+(V-1)\beta$$ 
$$4-3V=3V\alpha+\alpha +V\beta-\beta$$
$$4-3V=\alpha-\beta+(3\alpha +\beta)V$$
$$4=\alpha-\beta$$
$$-3=3\alpha+\beta$$
$$4+\beta=\alpha$$
$$-3=3(4+\beta)+\beta$$
$$-15=4\beta$$
$$\beta=\frac{-15}{4}$$
$$4=\alpha-\left(\frac{-15}{4}\right)$$
$$\alpha=4-\frac{15}{4}=\frac{16}{4}-\frac{15}{4}=\frac14$$ $$\ln X=\int\frac{1/4}{V-1}-\frac{15/4}{3V+1}\text d V$$ $$\ln X=\frac{1}{4}\int\frac{1}{V-1}-\frac{15}{3V+1}\text d V$$ $$4\ln X=\ln(V-1)-5\ln(3V+1)+c$$ $$\ln \left(X^4\right)=\ln\left({\frac{(V-1)}{(3V+1)^5}}\right)+c$$ $$X^4=\frac{V-1}{(3V+1)^5}\times e^c$$ $$(3V+1)^5X^4=e^c(V-1)$$ $$(3V+1)^5X^5=AX(V-1)$$ $$(3XV+X)^5=A(XV-X)$$ $$(3X\tfrac{Y}{X}+X)^5=A(X\tfrac{Y}{X}-X)$$ $$(3Y+X)^5=A(Y-X)$$ $$(3(y-2)+(x-3))^5=A((y-2)-(x-3))$$ $$(3y+x-9)^5=A(y-x+1)$$",['ordinary-differential-equations']
228154,Show that $\left(\frac{1}{2}\left(x+\frac{2}{x}\right)\right)^2 > 2$ if $x^2 > 2$,"Okay, I'm really sick and tired of this problem. Have been at it for an hour now and we all know the drill: if you don't get to the solution of a simple problem, you won't, so ... I'm working on a proof for the convergence of the Babylonian method for computing square roots. As a warming up I'm first using the sequence $(x_n)$ defined by: $$
x_1 = 2\\
x_{n+1} = \frac{1}{2} (x_n + \frac{2}{x_n})
$$ Now for the proof, I want to show that: $\forall n \in \mathbb{N}: x^2_n > 2$. I want to prove this using induction, so this eventually comes down to: $$
x_n^2 > 2 \implies x_{n+1}^2 = \frac{1}{4}x_n^2 + 1 + \frac{1}{x_n^2} > 2
$$ And I can't seem to get to the solution. Note that I don't want to make use of showing that $x=2$ is a minimum for this function using derivatives. I purely want to work with the inequalities provided. I'm probably seeing through something very obvious, so I would like to ask if anyone here sees what's the catch. Sincerely,
Eric","['inequality', 'mental-arithmetic', 'sequences-and-series', 'analysis']"
228155,Why arent $\mathbb{R}$ and $\mathbb{R}²$ isomorphic?,"Let $a,b\in (0,1)\subset\mathbb{R}$, $a=0,a_1 a_2 ...$; $\;b=0,b_1 b_2 ...$ Why is $\pi:\mathbb{R}²\rightarrow\mathbb{R}: (a,b)\mapsto 0,a_1 b_1 a_2 b_2...$ not bijective, if the constraint $\forall N\in\mathbb{N}\exists i>N:a_i\neq9$ is applied?",['elementary-set-theory']
228162,Is double quantifying a variable possible in predicate logic?,"I read it as ""Everyone is either a student or has read every book"". But what's the use of the existential y outside the bracket? R(x, y): “x has read y.”
S(x): “x is a student.”
Domain for x: all people
Domain for y: all books
∀x∃y(S(x) ⋁ ∀yR(x, y))","['logic', 'propositional-calculus', 'quantifiers', 'discrete-mathematics']"
228165,A question related to Helly's Theorem on convex sets,"I have one  question  related to differential geometry. Initilally, I am giving some background and my question is after that. Helly's Theorem Let C be a finite family of convex sets in $R^n$ such that, for $k ≤ n + 1$, any $k$ members of C have a nonempty intersection. Then the intersection of all members of C is nonempty. As an application of Helly's therore we have: Corollary : Given $s (s > 0)$ points in the plane such that every three of them are contained in a disk of radius $1$. Prove that all $s$ points are contained in a disk of radius $1$. Proof Consider the set C of unit disks with centers at the points from a given set. Since every three of the given points are contained in a unit disk, any three disks from C have a nonempty intersection. By Helly's Theorem, all the disks have a nonempty intersection. Let $q$ be a point from the intersection. Then $q$ belongs to every disk from C and is, therefore, at a distance less than $1$ from there centers. In other words, all the centers of the disks from C lie in a disk of radius $1$ centered at $q$. Now like previous corollary does the follwoing  also true ? Given $s (s > 0)$ points in the plane such that every $6$ or $7$ of them are contained in two disk of radius $1$. Then all $s$ points are contained in two disk of radius $1$.","['convex-analysis', 'discrete-mathematics', 'combinatorial-geometry']"
228169,What is the significance of the Increment Theorem in non-standard analysis?,"A bit of background: I'm an engineer, not a mathematician, and I need to review and improve my calculus.  In college, I never liked how they said $dy/dx$ was a single symbol, not a ratio; and then proceeded to write things like $dy = f(x) dx$ and integrate.  So I'm trying a different angle this time, and reading the textbook Elementary Calculus: An Infinitesimal Approach , by H. Jerome Keisler, which is available online. I'm at the part (p.55) that discusses the Increment Theorem .  It says: Let $y = f(x)$. Suppose $f'(x)$ exists at a certain point x, and $\Delta x$ 
  is infinitesimal.  Then $\Delta y$ is infinitesimal, and $\Delta y = f'(x)\Delta x + \epsilon\Delta x$ for some infinitesimal $\epsilon$, which depends on $x$ and $\Delta x$. And then he works some examples, finding $\epsilon$. For example, with $y = x^3$... $$
y' = 3x^2 \\
\Delta y = (x + \Delta x)^3 - x^3 \\
\epsilon = \Delta y / \Delta x - y' \\
...\\
\epsilon = 3x \Delta x + (\Delta x)^2
$$ I'm left wondering... what is the point?  Where are we going with this? We seem to be revisiting the definition of the derivative, where $\epsilon$ is the part of the equation that we were able to discard because it was infinitesimal.  For example, to get the derivative of $y = x^3$ $$
st( \frac{\Delta y}{\Delta x} ) = st(\frac{(x + \Delta x)^3 - x^3}{\Delta x}) \\
= st(3x^2 + 3x\Delta x + (\Delta x)^2) \\ 
= 3x^2
$$","['nonstandard-analysis', 'calculus']"
228178,Sum over squared index,"Is there any way to compute the finite series $$S_M = \sum_{n=1}^{M} r^{n^2}, $$ for some real $r$, integer $M$?","['summation', 'sequences-and-series']"
228182,How many solutions does $\cos(97x)=x$ have?,How many solutions does $\cos(97x)=x$ have? I have plot the function. However I don't know how to solve the problem without computer. Can anyone give a fast solution without a computer?,"['trigonometry', 'functions']"
228184,How to calculate the maximum value of: $\frac{25x}{x^2+1600x+640000}$?,"Wolfram says it's 800, but how to calculate it? $$
\frac{25x}{x^2+1600x+640000}
$$","['optimization', 'functions']"
228203,Convergence of Lebesgue integrable functions in an arbitrary measure.,"I'm a bit stuck on this problem, and I was hoping someone could point me in the right direction. Suppose $f, f_1, f_2,\ldots \in L^{1}(\Omega,A,\mu)$ , and further suppose that $\lim_{n \to \infty} \int_{\Omega} |f-f_n| \, d\mu = 0$. Show that $f_n \rightarrow f$ in measure $\mu$. In case you aren't sure, $L^1(\Omega,A,\mu)$ is the complex Lebesgue integrable functions on $\Omega$ with measure $\mu$. I believe I have to use the Dominated convergence theorem to get this result, and they usually do some trick like taking a new function $g$ that relates to $f$ and $f_n$ in some way, but I'm not seeing it. Any advice?","['measure-theory', 'analysis']"
228222,"Differentiable $\mathbf{f}:\Bbb R \to \Bbb R^3$, $|\mathbf{f}(t)| = 1$ implies $\mathbf{f}(t)\cdot\mathbf{f}'(t) = 0$","This question comes from Rudin's PMA problem 9.13. For a differentiable function $\mathbf{f} : \Bbb R \to \Bbb R^3$ and $|\mathbf{f}(t)|=1$ for all $t$, I want to prove that $\mathbf{f}(t)\cdot\mathbf{f}'(t) = 0$. Notionally, this makes sense to me. $|\mathbf{f}(t)|=1$ means that $\mathbf{f}(t)$ describes a curve on the unit sphere in $\Bbb R^3$. Of course, the tangent to this curve at any point will lie in the tangent plane to that point on the unit sphere, which is normal to the vector from the origin to that point. Therefore, by orthogonality, the dot product will be zero. However, I am struggling to prove it rigorously using the definition of derivatives. I have $$\mathbf{f}(t)\cdot\mathbf{f}'(t) = \lim_{h\to 0} \frac{1}{h} \left(\mathbf{f}(t) \cdot \left(\mathbf{f}(t+h)-\mathbf{f}(t)\right)\right)$$ by applying properties of limits, etc., but this seems to bring me right back in a circle (no pun intended). I also know that $|\mathbf{f}(t)| = 1$ means that $\mathbf{f}(t)\cdot\mathbf{f}(t) = 1$. I'm just not sure how to proceed from here. I want to argue that the numerator of the limit must be zero, but I can't; evaluation of the limit just brings me back to $\mathbf{f}\cdot\mathbf{f}'$. This is a homework problem, so please just provide a nudge in the right direction. Edit: I also don't ""know"" that $\mathbf{a \cdot b} = |\mathbf{a}||\mathbf{b}|\cos \theta$. I suppose I could prove it, but I feel as if that's avoiding the intent of the question.","['multivariable-calculus', 'derivatives', 'real-analysis']"
228229,Is division of matrices possible?,"Is it possible to divide a matrix by another? If yes, What will be the result of $\dfrac AB$ if
$$
        A = \begin{pmatrix}
        a & b \\
        c & d \\
        \end{pmatrix},
        B = \begin{pmatrix}
        w & x \\
        y & z \\
        \end{pmatrix}?
$$","['matrices', 'divisibility']"
228232,Three ball-spring system,"So here is a crazy  problem for you all. Imagine there is a system of three balls in a line. The first and last balls have a larger mass M and the middle ball is a smaller mass m. Inbetwen the two larger balls and the middle ball are springs with spring constant of k. Now I would like to model this confusing heap of a system and solve the resulting eigenvalue problem . Trouble is, I don't k ow where to start. Normally, I would set up a differential relation, but since none of the balls are connected to walls, I don't know what is moving where? The problem doesn't even mention an external force. Also, what aould the eigenvalue solution to this problem even mean? I can't seem to grasp the meaning behind this problem. Please help.","['ordinary-differential-equations', 'classical-mechanics', 'physics']"
228246,Is 3 ever a seventh power mod a prime $p$ if $p\equiv 1 (7)$,"I had a question asking when is 3  a seventh power modulo a prime $p$ if $p=1(7)$. However, I tried to find just one example using mathematica but I went up to primes in the thousands and I still couldn't find an example, so I began thinking this was a trick question. We were learning about quadratic reciprocity, but I wasn't sure how to extend what we learned about quadratic powers to seventh powers.","['quadratic-reciprocity', 'number-theory']"
228270,"Showing A Relation Is Reflexive, Symmetric, and Transitive.","The question is, ""Show that the relation R = ∅ on the empty set S = ∅ is reflexive, symmetric, and transitive."" I was told by my teacher that you could simply say it can't be shown that each property isn't true; and that would show that the relation had those three properties. To me, this answer isn't very satisfying. Could someone, perhaps, elaborate on this idea more? Thank you!","['relations', 'elementary-set-theory']"
228273,Solving the complex equation $z^6=(1+3i)^{12}$ for $z$,"I got stuck while solving the following equation: $$z^6=(1+3i)^{12}.$$ I think that right side must (at least should) be transformed to the form $$z_{1}=1+3i=\sqrt{10}(\cos \theta+i\sin\theta ),$$ and then we can use De Moivre's formula. However, I have no idea how to use it when $\cos\theta=\frac{1}{\sqrt{10}}$ and $\sin\theta=\frac{3}{\sqrt{10}}$ . It is clear how to make power of complex numbers when $\theta$ is a ""nice"" angle, but what if it is not (and that is the case)? Thanks in advance!","['complex-numbers', 'algebra-precalculus', 'roots', 'polynomials']"
228287,Surface integral (Flux),"Evaluate the surface integral $  \int_{S}\int \vec{F} \cdot \vec{n}\,
 dS,$ with the vector field $ \vec{F} = zx\vec{i} + xy\vec{j} +
 yz\vec{k} \ $. $S$ is the closed surface composed of a portion of the
   cylinder $ x^2 + y^2 = R^2 $ that lies in the first octant, and
   portions of the planes $ x=0, y =0, z = 0\,\,\text{and}\,\, z = H $. $\vec{n}$ is the outward unit normal vector. Attempt: I said $S$ consisted of the five surfaces $ S_1, S_2, S_3, S_4 $ and $ S_5$ $S_1 $ being the portion of the cylinder, $S_2$ being where the plane $ z=0$ cuts the cylinder and similarly, $ S_3, S_4 ,S_5 $ being where the planes $ x = 0, y = 0 $ and $z = H $ cut the cylinder. For $ S_2 $, the normal vector points in the -k direction. so the required integral over $S_2$ is: $$ \int_{0}^{R} \int_{0}^{\sqrt{R^2-x^2}} -yz\,dy\,dx $$ Am I correct? I think for the surface $ S_5$ the only thing that would change in the above would be that the unit normal vector points in the positive k direction? I need some guidance on how to set up the integrals for the rest of the surfaces. I tried $ \int_{0}^{R} \int_{0}^{H} -xy\,dz\,dx $ for the y = 0 plane intersection with the cylinder, but I am not sure if this is correct. Any advice on how to tackle the remaining surfaces would be very helpful.
Many thanks.",['multivariable-calculus']
228299,Finding the area of an annulus with one measurement,"Suppose you have a circular pool of lava (the reason for the contents will be clear in a moment) and in the center of the pool is a circular lawn. With a single straight-line measurement, determine the area of the lawn lava . The measuring instrument you have is a laser transit, with which you can look through a telescope, point it to a pole your assistant is holding, and read off the distance from the transit to the pole. Because you and your assistant can't stand in the lava, you can't use the obvious strategy of measuring the diameter of the lawn, but you can find the distance between any two points outside of the lava. How can you find the area of the lawn lava? EDIT: An apology is in order here. I was apparently passing a brain stone when I posted the original question. I should have asked what the area of the lava was. The comments have already answered the question. My real purpose was to observe that measuring the chord will give you the area of the lava, regardless of what the diameter of the pool and the lava were , so you could shrink the lawn diameter to zero and the chord would allow you to compute the area of the lava. In this way, the problem is like the question spatial geometry hole in sphere . My eventual question was to be, does anyone know of similar problems, where the answer doesn't require one of parameters of the problem and so can be solved by setting that parameter to zero?",['geometry']
228302,Subgroups of $\mathbb{Z}_2 \times \mathbb{Z}_{12}$ of order $6$,"what are the subgroups of $\mathbb{Z}_2 \times \mathbb{Z}_{12}$ of order $6$? I know that there are three such subgroups,
and two subgroups are clear to me, namely the subgroup isomorphic to $\mathbb{Z}_6$ and the subgroup isomorphic to $\mathbb{Z}_2\times \mathbb{Z}_3$. But I can't see the other one. Please help!","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
228319,Probability two people will talk at the same time,"The other day, I was talking to a friend, and then one of those lulls in the conversation came, where we had nothing more to say on the current subject and a new topic didn't immediately come to mind. We both decided to end the gap and start talking at the same time, as sometimes happens. What are the odds of that happening? I thought. I tried to work it out, but my lack of knowledge in probability and statistics (a class I'm taking next semester, though) prevented me from getting very far. First, let's count two people talking within one second of each other as breaking the gap. That seems like a reasonable number. Second, it seems that the average length of these gaps between topics is only a few minutes, and more often than not, they're broken by one person or the other, rather than both attempting it simultaneously. I assume there's some reasonable first approximation formula $p(t)$ to model the probability that a given person will talk at time $t$, then those probabilities are somehow combined (addition? multiplication?) for the number of people in the conversation, and you get the result. How can I find the solution from here?",['probability']
228326,Counting permutations of students standing in line,"Say I have k students, four of them are Jack, Liz, Jenna and Tracy. I want to count the number of permutations in which Liz is standing left to Jack and Jenna is standing right to Tracy. I define $A = ${Liz is left to Jack} so $|A| = \frac{k!}{2}$. The same goes for $B$ with Jenna and Tracy. I know that $$|A \cap B| = |A| + |B| - |A \cup B|$$ But how do I find the union? I'm guessing it involves inclusion-exclusion, but I can't remember how exactly. Any ideas? Thanks!","['permutations', 'discrete-mathematics']"
228339,Prove the following relation:,"I must prove the relation $$\sum_{k=0}^{n+1}\binom{n+k+1}{k}\frac1{2^k}=2\sum_{k=0}^n\binom{n+k}{k}\frac1{2^k}.$$ I got this far before I got stuck: $\begin{eqnarray*}
\sum_{k=0}^{n+1}\binom{n+k+1}{k}\frac1{2^k} & = & \sum_{k=0}^{n+1}\left\{\binom{n+k}{k}+\binom{n+k}{k-1}\right\}\frac1{2^k}\\
& = & \sum_{k=0}^n\binom{n+k}{k}\frac1{2^k}+\sum_{k=0}^n\binom{n+k}{k-1}\frac1{2^k}+\binom{2n+1}{n}\frac1{2^k}.
\end{eqnarray*}$ If I can combine the second and third terms and get something same as first term, I am done but I could not do that.","['induction', 'binomial-coefficients', 'combinatorics']"
228349,Quasi-coherent ideals and subschemes,"Let $X$ be a scheme. Let $\mathcal{I}$ be a quasi-coherent ideal of $\mathcal{O}_X$.
Let $Y = Supp(\mathcal{O}_X/\mathcal{I})$.
Let $f\colon Y \rightarrow X$ be the canonical injection.
Then how do we prove that $(Y, f^{-1}(\mathcal{O}_X/\mathcal{I}))$ is a scheme and $f$ is a closed immersion?",['algebraic-geometry']
228356,How to find solutions of $x^2-3y^2=-2$?,"According to MathWorld , Pentagonal Triangular Number: A number which is simultaneously a pentagonal number $P_n$ and triangular number $T_m$. Such numbers exist when
  $$\frac{1}{2}n(3n-1)=\frac{1}{2}m(m+1).$$
  Completing the square gives
  $$(6n-1)^2-3(2m+1)^2=-2.$$
  Substituting $x=6n-1$ and $y=2m+1$ gives the Pell-like quadratic Diophantine equation
  $$x^2-3y^2=-2,$$
  which has solutions $(x,y)=(5,3),(19,11),(71,41),(265,153), \ldots$. However, it does not state how these solutions for $(x,y)$ were obtained. I know that the solution $(5,3)$ can be obtained by observing that $1$ is both a pentagonal and a triangular number. Does obtaining the other solutions simply involve trial-and-error? Or is there a way to obtain these solutions?","['pell-type-equations', 'diophantine-equations', 'number-theory']"
228365,Bernoulli vs. uniform distribution,"Here's a question that I'm struggling with: Jack, John and Tom given 20 brownies by their mom, in a random manner. They are arguing: what are the odds that Jack will get all of them? Jack says that there are $\binom{20+2}{2}$ different ways to give the brownies, so his chances are $\frac{1}{\binom{20+2}{2}}$ John say that they all have the same chances for each brownie, so the chances are $(\frac{1}{3})^{20}$. Who is right? I think Jack is wrong because he didn't count similar divisions in which the brownies were given in a different order. But I think the real issue here is - when do I choose Bernoulli with $\frac{1}{3}$ success chance, and when do I choose a uniform distribution and count all possible divisions? Thanks!","['discrete-mathematics', 'probability', 'combinatorics']"
228415,To Interpret Solving Systems of Linear Equations Geometrically in Terms of Linear Algebra,"I never really understood basic Gaussian elimination & solving systems of equations once I learned some actual linear algebra. I thought this was due to me missing some fundamental aspect of the subject that some book would eventually illuminate for me or that things would just click but no they haven't & I can't stand being told something along the lines of Kaplansky quote ""we think basis-free, we write basis-free, but when the chips are down we close the office door and compute with matrices like fury"" as a rationale for the apparent disconnect between the theory & application of linear algebra when I view things as I'll describe below. Lets say I have this square system: $ax + by = e$ $cx + dy = f$ I think there are four ways we can geometrically understand this picture, & I have questions about all of them (note that nothing will be said about bigger or non-square systems in this post). $01:$ VECTORS & LINEAR MAPS If I want to understand this exclusively in terms of vectors & linear maps I can write this system as a linear combination: $x(a,c) + y(b,d) = (e,f)$ $xT(\hat{e_{1}}) + yT(\hat{e_{2}}) = (e,f)$ $T(x\hat{e_{1}} + y\hat{e_{2}}) = (e,f)$ $T(\vec{v}) = \vec{z}$ Now we can see that solving this system of linear equations is equivalent to determining which vector in the domain of $T$ is mapped to the vector $(e,f)$. Furthermore, using the fact that a linear map on a FDVS is completely determined by it's action on a basis, if we arrange things such that T acts on the standard basis then we can use linearity to determine the scalar multiples x & y. I think that's the general gist of what's going on (this is all correct so far, right?), & from a distance this is very geometric & conceptually intuitive. In the best case scenario (unique solution to the system) this is the image I think most people have. The thing I don't like about this perspective is how divorced it is from all computations that I know of, it basically has nothing to do with Gaussian or Gauss-Jordan elimination as far as I can tell. My first question is whether or not you can use this interpretation, i.e. linear maps, in a computational sense because it seems to me you have to revert to another interpretation I'll outline below & I'm wondering whether the concepts are actually so apparently divorced or whether I'm missing something, maybe I just don't see how all of this is actually related to basic linear algebra. Also it just seems strange to me to whip out new vectors that, while admittedly contain something from both equations, geometrically has no obvious connection with the lines. 02: NORMAL VECTORS This interpretation uses the fact that the vector $(a,b)$ is the normal vector to $ax + by = e$ (i.e. $(a,b)\cdot(x - x_0,y - y_0) = 0$ such that $ax_0 + by_0 = e$) & is basically a geometric interpretation of (every step of) both Gaussian & Gauss-Jordan elimination, giving some soul & feeling to the algebraic computations. Here you're using the second most obvious vectors associated with the lines (the normal, with the first most obvious vector being that one parallel to the line). Thus when you have $ax + by = e$ $cx + dy = f$ & you add a scalar multiple of one to the other you get $(a + \lambda c)x + (b + \lambda d)y = e + \lambda f$, you can interpret this as nothing other than adding normal vectors to end up with a new 'normal vector' $(a + \lambda c,b + \lambda d)$ (what it is 'normal' to I don't know but I think it just a convenient vector we use as a means to eliminate coefficients, as done next) & end up with: $(a + \lambda c,b + \lambda d)\cdot(x - x_0,y - y_0) = 0$ s.t. $(a + \lambda c)(x - x_0) + (b + \lambda d)(y - y_0) = 0$ $a(x - x_0) + \lambda c(x - x_0) + b(y - y_0) + \lambda d(y - y_0) = 0$ $ax + \lambda cx + by + \lambda dy - ax_0  - \lambda cx_0  - by_0 - \lambda dy_0 = 0$ $(a + \lambda c)x + (b + \lambda d)y = ax_0  + \lambda cx_0  + by_0 + \lambda dy_0 $ Thus as long as $(a,b)$ & $(c,d)$ are not linearly dependent you can't choose $\lambda$ such that the above becomes $(0,0)\cdot(x - x_0,y - y_0) = 0$. Now the standard route is to choose $\lambda$ such that you eliminate one of the variables & solve for the other, say $\lambda = - \frac{a}{c}$, gives $(a + \lambda c,b + \lambda d)\cdot(x - x_0,y - y_0) = 0$ $(a  - \frac{a}{c} c,b - \frac{a}{c} d)\cdot(x - x_0,y - y_0) = 0$ $(0,b - \frac{ad}{c})\cdot(x - x_0,y - y_0) = 0$ $(b - \frac{ad}{c})(y - y_0) = 0$ $bc(y - y_0) - ad(y - y_0) = 0$ $bcy - bcy_0 - ady + ady_0 = 0$ $(ad - bc)y_0 = (ad - bc)y$ $y_0 = y$ which can also be done using: $(a + \lambda c)x + (b + \lambda d)y = ax_0  + \lambda cx_0  + by_0 + \lambda dy_0 $ since you get $(a - \frac{a}{c} c)x + (b - \frac{a}{c}d)y = ax_0  - \frac{a}{c}(cx_0)  + by_0 - \frac{a}{c} dy_0 $ $(b - \frac{a}{c}d)y = (b - \frac{a}{c} d)y_0 $ $y = y_0 $ Similarly for finding $x = x_0$, however we want to understand this geometrically. My second question is as to whether it right to interpret the above as saying that we're going to take $(x_0,y_0)$ as the hypothetical point of intersection of the two lines & in the situation that no $\lambda$ can be chosen such that the dot product will contain a zero vector (i.e. if we can be sure the normal vectors are linearly independent) we know it uniquely exists & from then on we are doing nothing other than choosing $\lambda$ such that, say when we're solving for $y = y_0 $, the vector $(a + \lambda c,b + \lambda d)$ points in the y axis direction, i.e. it's a vertical vector in the cartesian plane, of the form $(0,y_0)$, i.e. pointing to the y component of the intersection of the two lines? 
Similarly for finding the $x_0$ term, we just use vector addition to eliminate a coefficient then find $(x_0,0)$, then through finding both $(x_0,0)$ & $(0,y_0)$ we simultaneously find $(x_0,y_0)$. Unless I'm deluded I'm pretty sure all of the above is a geometric way to understand every step of those furious computations with matrices so I don't see how this can be wrong... My third question is to how any of this discussion relates to linear maps? It seems to me that interpreting a system of linear equations in terms of normal vectors is far superior to interpreting them in terms of linear maps, at least in the square $n x n$ case. Am I missing something? 03: DETERMINANTS & LINEAR MAPS: Let $\Psi$ be an alternating bilinear form such that $\Psi(e_1,e_2) = 1$. For an operator $T$ we note the number $\lambda$ such that $\Psi(T(e_1),T(e_2)) = \lambda\Psi(e_1,e_2)$ is known as the determinant, i.e. $\Psi(T(e_1),T(e_2)) = det(T)\Psi(e_1,e_2)$. Again this way of looking at things is very intuitive from a distance, the determinant of an operator is nothing but the number such that the area between $T(e_1)$ & $T(e_2)$, i.e. $\Psi(T(e_1),T(e_2))$, is just a multiple of the area between $e_1$ & $e_2$, i.e.$\Psi(e_1,e_2)$ (disregarding signs). In fact we have no problem in more generally writing $\Psi(T(u),T(v)) = det(T)\Psi(u,v)$ for arbitrary vectors $u$ & $v$. Note that $\Psi$ has nothing to do with normal vectors here, it's exploiting the properties of the first way of looking at this system (in terms of matrices we're dealing with the determinant as a linear function of the columns basically). The reason I bring this topic up here is to find out about how to relate these concepts to the geometry of the situation. Again we are introducing seemingly arbitrary vectors $T(e_1)$ & $T(e_2)$ that don't relate to the geometry of the lines (though of course the vectors contain algebraic information). With that said my fourth question comes from solution's determined via Cramer's rule.
If you use this notation, $\Psi(T(e_1),T(e_2)) = det(T)\Psi(e_1,e_2)$, you see 
$\Psi(\vec{z},T(e_2)) = \Psi(xT(e_1) + yT(e_2),e_2)$ implies $x = \frac{\Psi(\vec{z},T(e_2))}{\Psi(T(e_1),T(e_2))}$. This term simply must have some fascinating interpretation... I would love to know what it means to say that the $x$ component of the point of intersection of two lines is the ratio of the area between the vectors whose components are the solutions to both of the equations (I can't see a nice way to talk about or interpret this) & the vector $T(e_1)$ (whatever this vector is supposed to be interpreted as) to the area contained within $T(e_1)$ & $T(e_2)$. My fifth question is almost the same as the above except it modifies the interpretaton of the last sentence ""to the area contained within $T(e_1)$ & $T(e_2)$"". If we exploit the fact that for matrices: $det(T) = det(T^t)$ we can interpret the determinant in a whole new manner intimately related to the geometry of the lines , we can now interpret the determinant as containing the (signed) area between the normal vectors to the lines (which immediately gives meaning to the situations of either a zero or non-zero determinant). To restate the question I would love to know what it means to say that the $x$ component of the point of intersection of two lines is the ratio of the area between the vectors whose components are the solutions to both of the equations & the vector $T(e_1)$ (whatever this vector is supposed to be interpreted as) to the area contained within the normal vectors to the two lines. My sixth question is whether I'm right to make all these distinctions. 
I don't know whether I should be going so far as to even delineate between two separate interpretations of the denominator
in the solution to cramer's rule & asking for two different interpretations but it really seems like you have to be able to think
about this in two different ways, one extremely geometric on every level (normal vectors), the other geometric only
at the start. I am just not sure, I think you just have no intuitive geometric interpretation in terms of linear maps, you have to use these almost arbitrary vectors $T(e_1)$ divorced from the geometry of the lines if you think in terms of linear maps whereas when you do it in terms of normal vectors you get something nice. 04 LINEAR FUNCTIONALS & LINEAR MAPS My seventh & final question is about the relationship of linear functionals to solving systems of linear equations.
Given the system: $ax + by = e$ $cx + dy = f$ i.e. $xT(\hat{e_{1}}) + yT(\hat{e_{2}}) = (e,f)$` we ask how linear functionals interact with this setup. 
By introducing $\psi_1(xe_1 + ye_2) = e$ & $\psi_2(xe_1 + ye_2) = f$ we see $\psi_1(xe_1 + ye_2) = x\psi_1(e_1) + y\psi_1(e_2) = ax + by = e$ $\psi_2(xe_1 + ye_2) = x\psi_2(e_1) + y\psi_2(e_2) = cx + dy = f$ I really don't know how to interpret this or fit it into the general scheme of things.
It seems to be saying that a linear functional maps the solution vector to a line,
& that the action of a linear functional on a basis results in coefficients of the normal vectors
(i.e. in some way you're mapping the solution of the system to the normal vectors) but I don't
know what you're supposed to do with this & would appreciate any help on how to interpret this
in light of everything I've asked. I really appreciate any help with this, I know it's a long post but the questions are, in my mind, all tied together so I sincerely appreciate any help.",['linear-algebra']
228417,How to solve $\sin(x)\frac{d}{dx}\beta \left ( x \right )+\cos(x)\beta (x)=1$?,"I'm trying to solve $$\sin(x)\frac{d}{dx}\beta \left ( x \right )+\cos(x)\beta (x)=1$$
What I get is : 
$$\beta (x)=\beta \left ( \alpha  \right )e^{\sin(\alpha )-\sin(x)}+e^{-\sin(x)}\int_{\alpha }^{x}e^{\sin(t)}dt$$
But I think that this solution is incorrect .The textbook says that there's exactly one solution that has a finite limit as $x$ tends to $0$ . But all the solutions I get have a finite limit . So what's the correct solution?",['ordinary-differential-equations']
228422,Showing that $R(x)$ is a proper subset of $R((x))$ if $R$ is a field,"I would like to show that if $R$ is a field, then $R(x)$ is a proper subset of $R((x))$, where $R(x)$ is the ring of rational functions, and $R((x))$ is the ring of formal Laurent series. If $f \in R(x)$, then $f(x) = f_1(x)f_2^{-1}(x)$, where $f_1(x), f_2(x) \in R[x]$. So I wrote this as $$f(x) = \frac{\sum_{i=0}^{n}a_ix^i}{\sum_{j=0}^{m}b_jx^j}\;,$$ and I would like to show that I can write $f$ in the form $\sum_{k=r}^{\infty}c_kx^k$. However, I am unsure how to manipulate $f$ in order to show this. What I was thinking was to find some formal power series expansion for $f_2^{-1}(x)$, multiply out the summation with $f_1(x)$, then rearrange the coefficients and terms to obtain the desired form. However, I can't seem to derive a formula for the inverse of a polynomial in general that I could use for this. How can I go about manipulating $f_2^{-1}(x)$ to show this? Any suggestions? Thanks!","['power-series', 'abstract-algebra', 'field-theory']"
228427,Limit and Lebesgue integral in a compact,"I have problem with the exercise that follows. Let $(z_m)_m \in R^n$ so that $\Vert z_m \Vert \rightarrow \infty$ when $m\to \infty$.
  Let $f:R^n \rightarrow [-\infty;+\infty]$ integrable. Show that if $K \subset R^n$ is a compact $\lim_{m\rightarrow\infty} \int_{z_m+K}f d\lambda=0$. I manage to find the result for $\vert f \vert$.
But I can find a way to get to result for f, as asked in the exercise.I thought about using the result for $\vert f \vert$ but then I stuck..so maybe there's another way If someone can help me. Update: Also because then I've another problem related to the first one and I found a way to show it related to the exercise before with $\vert f \vert$ instead of $f$.But maybe there's a better way to show it.","['lebesgue-integral', 'measure-theory', 'convergence-divergence']"
228451,Can we always find a normal subgroup isomorphic to a Quotient group?,I'm not very good with English terms of group theory but here is the question : $$\forall H\trianglelefteq G \rightarrow \exists H' \trianglelefteq G : {G\over H} \approx H'$$ is above statement always true? or should there be some other constraints?,['group-theory']
228488,What are the different ways to prove a function is onto,you take $f(x)$ and isolate $x$? For instance $f(x) = x^2 = \sqrt{y} = x$ Set A = all rational numbers Set B = all rational numbers The function is not onto because $\sqrt{y}$ is an irrational number. Is this the only way to prove that a function is onto? What are the different techniques?,"['discrete-mathematics', 'functions']"
228500,Orthogonal Projection Proof,"Let $w_1,...,w_n$ be any basis of the subspace $W \subset
 \mathbb{R^m}$. Let $A = (w_1,...,w_n)$ be the $m$ x $n$ matrix whose
  columns are the basis vectors, so that $W = rngA$ and $rankA=n$. Let
  $P = A(A^TA)^{-1}A^T$ be the corresponding projection matrix. a.) Prove that the orthogonal projection of $v \in \mathbb{R^n}$ onto
  $w \in W$ is obtained by multiplying by the projection matrix: $w=Pv$. b.) Show that if $A=QR$, then $P = QQ^T$. Why is $P \ne I$? How will I be able to prove these?",['linear-algebra']
228501,Invariant vector field by group action,"in a solved exercise, there is a point in the solution that I can't work out. I would be grateful if somebody could give me the detailed steps. Consider the trivial principal bundle $P = M\times U(1)$ over a $C^\infty$-manifold $M$. Let $\Phi_t$ be the flow of a vector field $\mathfrak{X}(P)$. Apparently, if $R_z$ designates the group action of $z \in U(1)$ on $M$, $X$ is $U(1)$-invariant ($R_z \cdot X=X$) if and only if $R_z$ commutes with $\Phi_t$ ($R_z \circ \Phi_t= \Phi_t \circ R_z$). Can somebody confirm this and help me with the proof ? Thanks, JD",['differential-geometry']
228502,Top deRham cohomology group of a compact orientable manifold is 1-dimensional,"Let $M$ be a compact smooth orientable manifold of dimension $n$ . I am looking for a simple proof that $H_\mathrm{dR}^n(M) \cong \mathbb R$ . Equivalently, an $n$ -form which integrates to 0 is exact. I can show this via a rather indirect argument as follows: we know $H_\mathrm{dR}^n(M) \cong H^n(M, \mathbb R)$ , where $H^n$ denotes the singular cohomology. By the universal coefficient theorem (and the fact that $\mathbb R$ is a field) this is isomorphic to $\operatorname{Hom}(H_n(M, \mathbb Z) , \mathbb R)$ . From the (rather lengthy) proof in Section 3.3 of Hatcher's Algebraic Topology, we find that $H_n(M, \mathbb Z)$ is isomorphic to $\mathbb Z$ , and so $\operatorname{Hom}(H_n(M, \mathbb Z) , \mathbb R) \cong \mathbb R$ . However, it seems like there should be a simpler way to prove this. Does anyone know of one?","['differential-forms', 'de-rham-cohomology', 'algebraic-topology', 'differential-geometry']"
228514,"Entire function, Liouville and zeroes","Suppose $f:\mathbb{C}\rightarrow\mathbb{C}$ is an entire function. Let $g:\mathbb{C}\rightarrow\mathbb{C}$ be an entire function, which has no zeros. I have shown that $\vert f(z) \vert \leq \vert g(z) \vert$ for all $z\in\mathbb{C}$ implies $f(z)=Cg(z)$ for some constant $C\in\mathbb{C}.$ I have to decide if this also holds if $g$ is allowed to have zeros. Help?",['complex-analysis']
228516,Matrix of a quadratic form?,"What exactly is the matrix of a quadratic form? I have seen this notation occuring in a few papers (e.g. Siegel's unreadable German papers), with particular reference to the trace of a quadratic form. I'm at a loss as to what this means, and as a bonus question in passing I'd be interested if the trace of a quadratic form was interesting for an ""obvious"" reason (echoes of character theory, maybe?) For example what is the matrix of the quadratic form $x^2+y^2+z^2$? Or $x^2+xy+y^2$?","['matrices', 'quadratic-forms']"
228520,Question regarding Nested Interval Theorem,"Theorem Consider a family of closed intervals, $I_1 = [a_1, b_1], I_2 = [a_2, b_2], \ldots$. 
  If $a_n \leq a_{n+1}$ and $b_{n+1} \leq b_n$ for all $n$ then there is an $x$ which is in every $I_n$, that is, there is an $x \in \displaystyle\bigcap_{n=1}^{\infty} I_n$. If, however $I_n$ is an open interval, then the Theorem would fail. A counterexample from the book is $\bigg(0, \dfrac{1}{n}\bigg)$ which ""kinda"" makes sense but honestly I don't fully understand it yet since it is slightly different with what I came up with. My counter example was $\bigg(\dfrac{-1}{n}, \dfrac{1}{n}\bigg)$ which base on the assumption that if $x \in I_n$, then $a_n < x < b_n$ for all $n$. And my reasoning was, if these two sequences $\dfrac{-1}{n}$ and $\dfrac{1}{n}$ meet at the same limit, then there no such $x$ can satisfy $0 < x < 0$. So my question is, is my counterexample correct? Any suggestion or idea would be greatly appreciated.","['sequences-and-series', 'real-analysis', 'analysis']"
228529,Find laurent expansion of $\frac{z-1}{(z-2)(z-3)}$ in annulus {$z:2<|z|<3$}.,"Find the Laurent expansion of $\frac{z-1}{(z-2)(z-3)}$ in annulus { $z:2<|z|<3$ }. So far I have the following; I'm not 100% sure if it is right. $\frac{z-1}{(z-2)(z-3)}$ = $\frac{2}{(z-3)}$ - $\frac{1}{(z-2)}$ For $\frac{1}{(z-2)}$ = $\frac{1}{z}$ $\frac{1}{1-(\frac{2}{z})}$ = $\frac{1}{z}$$\sum_{k=1}^n\frac{2^k}{z^k}$ = $\sum_{k=1}^n\frac{2^k}{z^{k+1}}$ for $|z|<1$ . I am having trouble with the other fraction.  I have seen similar questions asked, but I cannot seem to get the information I need.  Any input would be much appreciated!",['complex-analysis']
228553,Number of nodes in an infinite binary tree,"I know the number of nodes in an infinite binary tree is countably infinite, but I don't understand why. There are $\aleph_0$ levels, and the number of nodes in a binary tree is $2^{\text{number of levels}}$, so there should be $2^{\aleph_0}$ nodes, which is uncountable. This is wrong, but I can't see why. Bonus question cause I can't get it either : In an infinite tree where each node has an infinite number of children, what is the number of nodes ? I guess it's the cardinality of the continuum but I'm not sure, and anyway I don't know how to prove it.","['graph-theory', 'elementary-set-theory']"
228558,"If integration of arbitrary polynomial with respect to Borel measure $\mu$, over $[0,1]$ vanishes, is it true that $\mu$ equals to $0$ on $ [0,1]$?","I am having difficulties to deal with following problems; Assume $ \displaystyle\int_{[0,1]} x^n d \mu =0$ for all $n$, 
then is it true that $\mu=0$ on [0,1]? I think it is definitely true.. but I don't know how to proceed.. Can anybody help me?",['measure-theory']
228559,Prove complex polynomial has roots inside unit circle,"Given: $p(x)=z^{2012}-z^{1010}+2z^{1006}+20243z^8-2z^4+1$ I need to prove the polynomial has a root $|z_0|<1$. What I have so far: Plugging $p(0)=1$ we get (from the fundamental theorem of algebra) that $|z_0|...|z_n|=1$, were $z_0,...,z_n$ are the roots of the polynomial. So this means the polynomial's roots are either all on the unit circle, or at least one of them is inside of it. (Maybe an 'assume for the sake of contradiction' is good here?) Also, because $p(-1), p(1)$ aren't roots we know all the roots are complex. I was thinking of using the intermediate value theorem somehow here, but it doesn't seem applicable (for one, I'd need to prove $p(A)$ is open for some choice of $A$, but we haven't learned any theorem that would make this very obvious). Also, this polynomial's exponent coefficients are all even, which kind of feels like it should mean something, but I don't know. This being homework, I'd appreciate hints moreso than answers, but I'll accept either. Thanks!",['complex-analysis']
228572,Reconstructing space curves from its curvature and torsion,"I have to write a program which gets two functions (curvature and torsion) and 3 vectors of the Frenet-Serret ""frame"" at the starting point - and I have to reconstruct the space curve from this given input data. So I've written some Octave code, which works fine, for example on the curve Phi(t) = (cos(t/sqrt(2)), sin(t/sqrt(2)), t/sqrt(2))  % natural parametrization (it's some kind of spiral) and I was happy because when I plotted results, the original curve was almost the same as the reconstructed one. But when I tried out some other parametrization, there was huge difference between the reconstructed and the original one: Phi(t) = (cos(t), sin(t), t)  % other parametrization of the same curve I can't really find what I did wrong in my code... Maybe my idea was completely wrong, and I can only reconstruct curves which is naturally parametrized? % note: this returns a vector
% K : curvature
% T : torsion
function equation = f(s, gvect, K, T, velocity)
    gs = toStruct(gvect);
    e_v = velocity(s)*K(s).* gs.n;
    n_v = -velocity(s)*K(s).* gs.e + velocity(s)*T(s).* gs.b;
    b_v = -velocity(s)*T(s).* gs.n; 
    equation = [e_v; n_v; b_v];
    return;
endfunction

% returns a struct
function str = toStruct(vect)
    str.e = vect(1:3);
    str.n = vect(4:6);
    str.b = vect(7:9);
endfunction

% returns a vector
function vect = toVect(str)
    vect = [str.e; str.n; str.b];
endfunction

% numerical integration
function p = nintegrate(x, fx)
    acc = 0;
    for i = [1:length(x)-1]
            p(i) = acc;
            delta_x = x(i+1) - x(i);
            acc += delta_x * fx(i);
    endfor
endfunction

% K : curvature
% T : torsion
function gvals = RungeKutta4(S, g, K, T, velocity, delta)
    for i = [1:length(S)-1]
            g_i = toVect(g(i));
            k1 = f(S(i), g_i, K, T, velocity);
            k2 = f(S(i)+delta/2, g_i+delta/2*k1, K, T, velocity);
            k3 = f(S(i)+delta/2, g_i+delta/2*k2, K, T, velocity);
            k4 = f(S(i)+delta, g_i+delta*k3, K, T, velocity);
            g(i+1) = toStruct( g_i + delta/6*(k1+2*k2+2*k3+k4) );
    endfor
    gvals = g;
endfunction

function drawPlots(xs, ys, zs, orig_xs, orig_ys, orig_zs)
    plot3(xs, ys, zs, "";reconstructed;"", orig_xs, orig_ys, orig_zs, "";original;"");
endfunction

function Phi = reconstruct(K, T, e0, n0, b0, alpha, beta, start, delta = 0.1, velocity = @()1)
    S = [alpha:delta:beta];
    g(1).e = e0;    % unit tangent vector 
    g(1).n = n0;    % principal normal vector 
    g(1).b = b0;    % binormal vector
    g = RungeKutta4(S, g, K, T, velocity, delta);

    e_x = cellfun(@(v)v(1), {g.e});
    e_y = cellfun(@(v)v(2), {g.e});
    e_z = cellfun(@(v)v(3), {g.e});

    Phi.x = nintegrate(S, e_x) + start(1);
    Phi.y = nintegrate(S, e_y) + start(2);
    Phi.z = nintegrate(S, e_z) + start(3);
    return;
endfunction

% works OK for this
function spiralNaturalParametrized()
    L = sqrt(2)*4*pi;
    e0 = [ 0,  1/sqrt(2), 1/sqrt(2)]';  % unit tangent vector 
    n0 = [-1,          0,         0]';  % principal normal vector 
    b0 = [ 0, -1/sqrt(2), 1/sqrt(2)]';  % binormal vector
    Phi = reconstruct(@()1/2, @()1/2, e0, n0, b0, 0, L, [1 0 0], 0.05);

    t = [0:0.05:L];

    drawPlots(Phi.x, Phi.y, Phi.z, 
          cos(t./sqrt(2)), sin(t./sqrt(2)), t./sqrt(2));              
endfunction

% another parametrization: huge error
function spiralAnother()
    L = 4*pi;
    e0 = [ 0,  1/sqrt(2), 1/sqrt(2)]'; 
    n0 = [-1,          0,         0]'; 
    b0 = [ 0, -1/sqrt(2), 1/sqrt(2)]';
    Phi = reconstruct(@()1/2, @()1/2, e0, n0, b0, 0, L, [1 0 0], 0.05, @(v)sqrt(2));

    t = [0:0.05:L];
    drawPlots(Phi.x, Phi.y, Phi.z, cos(t), sin(t), t);
endfunction I included my code. 
Any help is appreciated! Update: I have created another test which reveals the fact that the algorithm has some bug inside even when it deals with the natural parametric case: function YetAnotherTest()
    L = 10*pi;
    e0 = [       0,    2/sqrt(13),   3/sqrt(13)]'; 
    n0 = [      -1,             0,            0]'; 
    b0 = [       0,   -3/sqrt(13),   2/sqrt(13)]';
    Phi = reconstruct(@()(2/13),        % curvature
                      @()sqrt(3/13),    % torsion
                      e0, n0, b0,       % initial frame
                      0, L,             % interval
                      [2 0 0], 0.05);   % start point and step size

    t = [0:0.05:L];

    drawPlots(Phi.x, Phi.y, Phi.z, 
              2*cos(t./sqrt(13)), 2*sin(t./sqrt(13)), t*(3/sqrt(13)));
endfunction Note: this is a test for $$Phi(t) = ( 2*\cos(t/sqrt(13)),  2*\sin(t/sqrt(13)),  3t/sqrt(13) )$$ which is a natural parametric curve.
If you take a look at this plot , you can see that the reconstructed curve is totally different than the original one. Update2: I have a suspicion that maybe I solve the differential equations wrong, and that causes the error. I have the differential equation system (my solver can be found in the RungeKutta4 and the f functions above): Frenet–Serret formulas : e'(t) =  K(t)*velocity(t)*n(t)
n'(t) = -K(t)*velocity(t)*e(t) + T(t)*velocity(t)*b(t)
b'(t) = -T(t)*velocity(t)*n(t)

given the initial values:
  e(0) = e0
  n(0) = n0
  b(0) = b0

where
K : curvature
T : torsion Maybe I misuse Runge-Kutta... Update3: If I change my own Runge-Kutta algorithm to the built-in Octave function lsode and I rewrite the numerical integration code to use trapz (trapezoid rule), nothing changes. So I think the bug is not in these functions...But where?","['octave', 'differential-geometry', 'plane-curves', 'curvature', 'matlab']"
228580,On 'backslash-forward slash' notation,"I am curious about a notation that I have seen, but I have only seen it in contexts beyond my current level of ability and so haven't learned its meaning.  Also, it's often difficult to search for the meaning of notations.  It appears to be group theoretic in nature. The notation uses a backslash followed by a forward slash, like so: $\text{SL}_n\mathbb{Z} \setminus \text{SL}_n\mathbb{R} \,/ \,\text{SO}(n)$. Of course it may be a 'set minus' followed by a 'modded by', but I'm not so sure.  So what's the meaning of this notation, and in what contexts is it most often used?  Thanks.","['notation', 'abstract-algebra', 'group-theory', 'lie-groups', 'terminology']"
228588,How to prove $\det(e^{\lambda_ix_j})\not=0$ where $\lambda_i\not=\lambda_j$ and $x_i\not=x_j$ if $i\not=j$,"In try to figure out the exercise: Let
  $$f(x)=\sum_{k=1}^{n}c_ke^{\lambda_kx}$$where $\lambda_i \not=\lambda_j,i\not=j$,and $c_1^2+c_2^2+\dots+c_n^2\not=0$, then the number of $f(x)$'s roots is strictly less than $n$. My approach(this way can't deal with $f(x)$ has repeated root): assume $x_1,x_2,\dots,x_n$ are $f(x)$'s roots,and $x_i\not=x_j$ if $i\not=j$.
then I get a linear equations about $c_1,c_2,\dots,c_n$:
$$e^{\lambda_1x_1}c_1+e^{\lambda_2x_1}c_2+\dots+e^{\lambda_nx_1}c_n=0$$
$$e^{\lambda_1x_2}c_1+e^{\lambda_2x_2}c_2+\dots+e^{\lambda_nx_2}c_n=0$$
$$\dots\dots\dots\dots\dots\dots$$
$$e^{\lambda_1x_n}c_1+e^{\lambda_2x_n}c_2+\dots+e^{\lambda_nx_n}c_n=0$$
I want to show that the solution to this linear equations are $0$,it will be a contradiction.but i can't figure out its determinant of coefficient:
$$\begin{vmatrix}
 e^{\lambda_1x_1}& e^{\lambda_2x_1} &\dots &e^{\lambda_nx_1}\\ 
 e^{\lambda_1x_2}& e^{\lambda_2x_2} &\dots&e^{\lambda_nx_2} \\ 
 \dots&\dots  &\dots&\dots \\
e^{\lambda_1x_n}&e^{\lambda_2x_n} &\dots &e^{\lambda_nx_n}
\end{vmatrix}\not=0$$","['linear-algebra', 'calculus', 'determinant']"
228593,"Measure of a set in $[0,1]$","Let $E \subset [0,1]$ be measurable set. Suppose for each interval $I \subset [0,1]$, $m(E \bigcap I)>1/4 m(I) $. Show that $m(E)=1$. Any hints would be  appreciated.",['measure-theory']
228605,"Let $E$ be measurable and define $f:E\rightarrow\mathbb{R}$ such that $\{x\in E : f(x)>c\}$ is measurable for all $c\in\mathbb{Q}$, is $f$ measurable?","Let $E$ be measurable and define $f:E\rightarrow\mathbb{R}$ such that $\{x\in E : f(x)>c\}$ is measurable for all $c\in\mathbb{Q}$, is $f$ measurable? There are a number of equivalent definitions for the measurability of a function and the most obvious one would be to show that $\{x\in E : f(x)>c\}$ is measurable for all $c\in\mathbb{R}$. Thus my strategy has been to consider an arbitrary irrational $y$ and use the density of the rationals in the reals to show that there exists some open set $O$ such that $m^*(O-\{x\in E : f(x)>y\})< \varepsilon$.  I would do this by choosing some rational $q<y$, close enough to $y$, such that the set of values in $E$ which get sent under $f$ to values strictly greater than $q$ and less than or equal to $y$ is small enough.  But that doesn't in general seem possible since I could keep sending intervals of some fixed positive length to smaller and smaller regions just beneath $y$.  However conversely, such a function would not be enough for a counter example, since finding such a function only rules out this strategy, but doesn't necessarily entail non-measurability. Is there a better definition of the measurability of a set I should use? or does the statement actually not imply measurability?  Thanks.","['measure-theory', 'real-analysis']"
228609,Can a batsman's score be predicted in the sport of cricket?,"I was browsing The Signal and the Noise in bookstore and chanced upon a chapter about predictions in baseball and found out about Moneyball and sabermetrics . I understand the closest to predicting a cricket match score comes via Duckworth-Lewis method and Jayadevan's system but going over these two following references: ( 1 ) ( 2 )  no work was found on an individual's innings . Probably this question is too soft for this site, but problem is I have basically no knowledge about statistics and I do not know what to search for to find out how bettors use algorithms to predict scores. Any help would be appreciated. Edit: Forgot to add this link which was a further inspiration for the question.","['statistics', 'reference-request', 'soft-question']"
228629,Solve the trigonometric equation,"Solve the equation $$\cos x -2\cos 2x+3 \cos 3x -4\cos 4x = \dfrac{1}{2}.$$ I tried, put $t = \cos x$.",['trigonometry']
228630,Finding a conformal map from unit disk to half-plane,"I'm trying to find a conformal map $f$ from the open unit disk to the set $\mathbb{C}-[-1/4,-\infty)$ (I think this means the half-plane Re$(w)>-1/4$ with the properties $f(0)=0$ and $f'(0)>0$. I know that the mapping
$$f(z)=\frac{i+z}{i-z}$$
returns the right half-plane Re$(w)>0$ from the open unit disk, but subtracting 1/4 from it doesn't satisfy $f(0)=0$. I can't seem to find a lot of other examples. Are there any other conformal maps that I should try?","['conformal-geometry', 'complex-analysis']"
228672,"As shown in the figure: Prove that $a\,+\,b\,+\,c=d$","Geometry: Auxiliary Lines As shown in the figure: Prove that $a\,+\,b\,+\,c=d$","['geometry', 'trigonometry']"
228687,Products of quotient topology same as quotient of product topology,"Let $X$ be a topological space, $p:X\to Y$ be a quotient map, and $q:X\times X\to Y\times Y$ be the quotient map defined by $q(x,y)=(p(x),p(y))$. Prove that the topologies on $Y$ is the same as the topology on $Y\times Y$ as a quotient of the product topology on $X\times X$.","['general-topology', 'quotient-spaces', 'product-space']"
228696,Alice and Bob Game,"Alice and Bob just invented a new game.
The rule of the new game is quite simple. At the beginning of the game, they write down N
random positive integers, then they take turns (Alice ﬁrst) to either: Decrease a number by one. Erase any two numbers and write down their sum. Whenever a number is decreased to 0, it will be erased automatically. The game ends when all numbers are ﬁnally erased, and the one who cannot play in his(her) turn loses the game. Here's the problem: Who will win the game if both use the best strategy?","['combinatorial-game-theory', 'combinatorics']"
228700,Finding an unknown angle,Geometry: Auxiliary Lines As shown in the figure:,"['geometry', 'trigonometry']"
228711,What are the strategies I can use to prove $f^{-1}(S \cap T) = f^{-1}(S) \cap f^{-1}(T)$?,"$f^{-1}(S \cap T) = f^{-1}(S) \cap f^{-1}(T)$ I think I have to show that the LHS is a subset of the RHS and the RHS is a subset of the LHS, but I don't know how to do this exactly.","['elementary-set-theory', 'functions']"
228718,"If $f(x)\leq f(f(x))$ for all $x$, is $x\leq f(x)$?","If I have $f(x)\leq f(f(x))$ for all real $x$, can I deduce $x\leq f(x)$? Thank you.","['functions', 'functional-inequalities']"
228722,Evaluate the integral by converting to polar coordinate,"$$ \int^{\pi/2}_{\pi/4} \int^{\sqrt{2-y^2}}_y 3(x-y) dx dy$$ I attempted the following: $$ \int_{\pi/4}^{\pi/2} \int_{0}^{1} 3r^2 (\cos\theta - \sin\theta) dr d\theta $$
which is wrong apparently. I think I might have got the wrong drawing of the curve.","['polar-coordinates', 'integration']"
228735,Sheafs and closed immersion,"Let $f:X \rightarrow Y$ be a continuous map of topological spaces, such that it is closed immersion. Let $\mathfrak{F}$ and $\mathfrak{G}$ be sheafs on $X$ and $Y$ respectively.
How to show, that canonical morphisms
$$
\mathfrak{G} \rightarrow f_* f^{-1} \mathfrak{G}, \; f^{-1} f_* \mathfrak{F} \rightarrow \mathfrak{F}
$$
are isomorphisms? Is it true, that taking stalk doesn't commute with direct image, but commutes with inverse image?","['general-topology', 'sheaf-theory', 'algebraic-geometry']"
228737,Differences between Real Matrices and Complex matrices.,"I am going through a course in linear algebra. Most of the time I learn that ""this concept can be generalized to complex matrices without loss of generality"" or ""since it holds for complex matrices, it holds for real matrices also"". I was curious if there are any concepts that holds for real matrices and doesn't hold for complex matrices and vice-versa. Some trivial ones are Determinant and trace of a real matrix is real Eigen values occurs in complex conjugate pairs. Fundamental spaces associated with a real matrix are all real. thats it!!, that's all I could remember now. Any help would be appreciated.","['matrices', 'linear-algebra']"
228744,Value of Summation of $\log(n)$,"Context: I am learning Dijstra's Algorithm to find shortest path to any node, given the start node. Here, we can use Fibonnacci Heap as Priority Queue. Following is few lines of algorithm: For each vertex in PriorityQueue{
    do_something()
} If $V$ is the number of vertices, the subsequent lookup times in the priority queue will be:
$$O(\log V), O(\log V-1), \ldots$$ Question: What would the value of $O(\log V) + O(\log V-1) + O(\log V-2) + .. + O(\log 1)$?","['asymptotics', 'logarithms', 'summation', 'complex-analysis']"
228750,Arithmetic progressions of units in a domain,"Let $R$ be a domain with unity, and suppose that $R^\times$ has finite rank as an abelian group. Can $R^\times$ contain infinitely long arithmetic progressions? Can $R^\times$ contain arithmetic progressions of arbitrarily long (unbounded) length? I suspect that the answer to each of these questions is no, but I have been unable to prove either. A brief note by Morris Newman (PDF) discusses this question for $R$ a number field (for which our question applies by the Dirichlet unit theorem).  For $R$ a number field with degree $n \geq 4$ the lengths of such progressions are bounded by $n$ (and this bound is sharp).  For $n=2,3$ our progressions are instead bounded of length $4$.  Thus each of our numbered claims hold for number fields. Edit: This edit reflects some recent thoughts I've had on this problem.  Suppose that $R^\times$ is free on $\alpha_1,\ldots, \alpha_m$ (so we've simplified by ignoring torsion elements).  Then an arithmetic progression
$$ \beta_1:=\prod^m \alpha_i^{k_i(1)},\beta_2:=\prod^m \alpha_i^{k_i(2)},\beta_3:=\ldots$$
encodes a number of polynomial relations in the $\alpha_i$, given by
$$p_i(\alpha_1,\ldots, \alpha_m):=\beta_{i+1}-2\beta_i+\beta_{i-1}=0.$$
If the zero sets of these polynomials have no common component, then the fact that $(\alpha_1,\ldots,\alpha_m)$ lies in the intersection of the zero sets should imply a bound on the number of relations that may hold (perhaps $m+1$ such, e.g.).  Because of this tentative connection, I have added the tag ""algebraic geometry"" to this question. Edit 2: I've posted a solution below which addresses all aspects of my original questions, save the following (which remains open): Question: Let $R$ be a domain with characteristic $0$.  If $R^\times$ has finite rank, does there exist a constant $c(R)$ such that any arithmetic progression in $R^\times$ has length at most $c(R)$?","['ring-theory', 'algebraic-geometry', 'abstract-algebra']"
228755,Cayley graphs on small Dihedral and Cyclic group,"Consider the following problem Let $n \leq 5$ and let $\Gamma = \mathrm{Cay}(C_{2n},S)$ be the Cayley graph with Cayley set $S$. Show that $\Gamma$ is isomorphic to
  $\mathrm{Cay}(D_{2n},S')$ for a suitable $S'.$ Recall that $\Gamma = \mathrm{Cay}(G,S)$ is a Cayley graph with vertex set $G$ if $G$ is a group, $S$ is a subset of $G\setminus\{e\}$ closed for taking inverses and two vertices $u,v \in G$ are adjacent iff $uv^{-1} \in S.$ It is not very hard to solve the above problem by bruteforcing. The case when $n = 1$ is trivial. For the other cases we observe for example that if $|S| = 1$ then $\Gamma$ is a disjoint union of $K_2$ and similarly if $|S| = |G|-1$ then $\Gamma$ is the complete graph. One is then left to consider specific values of $|S|$ to deduce that the stated problem is indeed true for $n \leq 5.$ What I was wondering is if there is any other, shorter, way to prove this exercise perhaps employing some properties of small groups and Sabidussi's Theorem?","['graph-theory', 'cayley-graphs', 'group-theory', 'algebraic-graph-theory']"
228771,Proving the sequence is convergent [duplicate],"This question already has answers here : Sufficient condition for convergence of a real sequence [duplicate] (3 answers) Closed 6 years ago . Consider a sequence $\{x_n\}$ in $S$. Where $S$ is a metric subspace. Given that every convergent subsequence of $\{x_{k(n)}\}$ converges to the same point say $x$. Prove that if S is compact, show that $\{x_n\}$ converges to $x$. Is my answer correct?","['convergence-divergence', 'sequences-and-series']"
228772,Proper subgroups of non-cyclic p-group cannot be all cyclic?,"Prove or disprove? I'm leaning towards it being true but not sure. Any hint would be greatly appreciated. In case of it being false, i.e a non-cyclic p-group can have all cyclic proper subgroups, is there any way to count them?","['group-theory', 'abstract-algebra']"
228791,Extending a Set of Linearly Independent Vector Fields to a Basis,"My question is this. Suppose we are given some smooth vector fields $X_1, X_2,..., X_k$ which are linearly independent at all points in a neighborhood $U$ (EDIT: diffeomorphic to a ball) of $R^n$. Do there necessarily exist smooth vector fields $X_{k+1},...,X_n$ such that $X_1,...,X_n$ are linearly independent on $U$? Of course at any point $p$, one can complete $X_1(p),...,X_k(p)$ to a basis for $R^n$, but there are infinitely many choices, and one can't hope to get smooth vector fields choosing arbitrarily at each point. If the result is true, there must be some algorithm by which to assign vectors in a smooth way, and this algorithm is what I would like to know. I should add that I am in the situation where $X_1,...,X_n$ do not necessarily commute, so they cannot be said to be coordinate fields. Thanks.","['manifolds', 'vector-bundles', 'differential-geometry']"
228803,An elementary question on Sobolev space,"I have a question on Sobolev space. 
This is one of exercises in Evans PDE textbook. 
Let $U=\{(x,y) | |x|<1, |y<1|\} \subset \mathbb{R}^2$.
Define a function $u(x,y)$ by
$$
u(x,y)=\begin{cases}
1-x & \text{if } x>0, \ |y|<x \\
1+x & \text{if } x<0, \ |y|<-x \\
1-y & \text{if } y>0, \ |x|<y \\
1+y & \text{if } y<0, \ |x|<-y
\end{cases}
$$
I would like to know for which $p$ the function $u$ in $W^{1,p}(U)$. It seems to me that weak derivatives are given by
$u_x(x,y)=-1,1,0,0$ and $u_y(x,y)=0,0,-1,1$ in each region respectively,
but then this question is too trivial. Could someone point out any mistake I made?","['sobolev-spaces', 'functional-analysis']"
228811,Understanding the chain rule in probability theory,"When my teacher told us about the chain rule I found it quite easy, but when I am trying to prove something based on this rule I kind of get confused about what are the allowed forms of this rule. For example, I can't understand why I can say: $$
p(x,y\mid z)=p(y\mid z)p(x\mid y,z)
$$ I can not understand how one can end up to this equation from the general rule! Can you please help how to think correctly about this rule? I found this post useful for my question: Is order of variables important in probability chain rule","['chain-rule', 'probability']"
228840,Is the tangent bundle the DISJOINT union of tangent spaces?,"Let $M$ be a smooth manifold and consider the Lee's definition of the tangent space $T_pM$ (so $T_pM$ is the vector space of derivations at $p$). The canonical definition of tangent bundle (as set) of $M$ is: 
$$TM=\bigcup_{p\in M}\{ p\}\times T_pM$$
so it is the disjoint union of all tangent spaces; but L.W.Tu in his ""Introduction to Manifolds"" says that the tangent spaces are already disjoint and for this reason he defines
$$TM=\bigcup_{p\in M} T_pM$$ Why we can't find a common derivation between $T_pM$ and $T_qM$ if $q\neq p$? I think that Tu's statement  is not true.","['differential-topology', 'differential-geometry']"
228852,Prove that the following series is convergent for all $z\in\Bbb C$ such that $|z|<1$.,"$$\sum_{n=1}^\infty z^{n!}$$ Here is what I've got so far Claim: The above series converges for $|z|<1$. Pick $|z|<r<1$. Then for all $n$, $|z^{n!}|<=r^{n!}$. So $\sum\limits_{n=1}^\infty r^{n!}$ is a majorant for $\sum\limits_{n=1}^\infty z^{n!}$. $\sum\limits_{n=1}^\infty r^{n!}$ is a real series so we can test for convergence. This is where I get stuck, I've tried the ratio test but that doesn't seem to work and I can't think of a function that would work for the comparison test.",['complex-analysis']
228860,proving a simple function is bijective,"This is more of a ""How to write"" question than a ""help me solve"" one, sorry if these are unaccepted/closed, let me know and I won't open anymore like this. I need to prove that $A:=\{x\in \mathbb{N}|$ exists $n\in\mathbb{N}$ such that $x=n^2 \}$ is countable.
This obviously requires me to prove that exists a bijective function from N to it. Which sounds very simple, but I don't really know how to write it. Edit: Well, this is what I had written before asking: Proof. We'll notice that this set is equal to $\left\{ n^{2}|n\in\mathbb{N}\right\}$ 
 , since for each n
  we can find $n^{2}$
  and say it's equal to $x$
 . In order to prove that a set is countable we need to find a bijective function from $\mathbb{N}$
  to it. We'll look at: $$f:\mathbb{N}\to \mathbb{N}^{2},f\left(n\right)=n^{2}$$ Since multiplication is well defined we can say this function is injective. 
Now how do I explain surjective?",['functions']
228866,Example of strictly subadditive lebesgue outer measure,"One of the properties of the Lebesgue outer measure is that it is subadditive and not countably additive. In fact, I have read that even when the sets A_i  are disjoint, there is still generally strict inequality. I was just wondering if anyone can give me an example of this, any set of disjoint real number intervals that I can think of always lead to a equality (hence countable additivity).","['measure-theory', 'elementary-set-theory']"
228873,"How many ""equators"" and ""poles"" 4-sphere has?","I mean 3-sphere (normal, like Earth) has 3 euators: namely equator, 0h meridian circle and 6h meridian circle. So, ""pole"" is a point, where all coordinates equal zero, except one, which equals to sphere radius. Can't factor out, how many such equators 4-sphere has? On 3-sphere each equator intersects with 2 other equators in 4 poles. In each pole 2 equators intersect. On 4-sphere there should be 3 equators intersecting in a pole. These 3 equators should also intersect at opposite pole. So we have $E_1=\{P_1, \bar{P_1},...\}$ $E_2=\{P_1, \bar{P_1},...\}$ $E_3=\{P_1, \bar{P_1},...\}$ where equator $E_i$ is represented with a set of poles it contains, while pole is denoted by $P_j$, having $\bar{P_j}$ as opposite pole. There should be at least one more equator, which intersects with three previous: $E_4=\{P_2, \bar{P_2}, P_3, \bar{P_3}, P_4, \bar{P_4},...\}$ poles $P_2...P_4$ should be on previous equators, so we have $E_1=\{P_1, \bar{P_1}, P_2, \bar{P_2}, ...\}$ $E_2=\{P_1, \bar{P_1}, P_3, \bar{P_3}, ...\}$ $E_3=\{P_1, \bar{P_1}, P_4, \bar{P_4},...\}$ What we should have at ellipsis? Seems that it should be $E_1=\{P_1, \bar{P_1}, P_2, \bar{P_2}, P_3, \bar{P_3}\}$ $E_2=\{P_1, \bar{P_1}, P_3, \bar{P_3}, P_4, \bar{P_4}\}$ $E_3=\{P_1, \bar{P_1}, P_4, \bar{P_4}, P_2, \bar{P_2}\}$ but I can't imagine, how 2 equators can intersect 4 times???",['geometry']
228898,How to check whether a relation is transitive from the matrix representation?,"$$\begin{bmatrix}1&0&1\\0&1&0\\1&0&1\end{bmatrix}$$ This is a matrix representation of a relation on the set $\{1, 2, 3\}$. I have to determine if this relation matrix is transitive. I know that the ordered-pairs that make this matrix transitive are $(1, 3)$, $(3,3)$, and $(3, 1)$; but what I am having trouble is applying the definition to see what the $a$, $b$, and $c$ values are that make this relation transitive. I am sorry if this problem seems trivial, but I could use some help. Thank you!","['relations', 'matrices', 'elementary-set-theory']"
228918,Probability poser,"We play a variation of 6 card brag but have a debate over the accurate ranking of the hands. 6 cards are dealt to each player.
2 hands of 3 cards must be made. Bearing in mind that each 3 card hand is derived from 6 cards, what is the correct ranking of hands using the traditional ideas of straight flush, straight, flush, three-of-a-kind, pair and high card? Thank you for your help.","['statistics', 'probability']"
228927,Triangle angles,"How would I prove that, in any triangle, any of the exterior angles is bigger than any of the remote interior angles? Help would be much appreciated!","['geometry', 'triangles']"
228928,Radon-Nikodym derivative of product measure,"For $j=1,2$, let $\nu_{j},\mu_{j}$ be $\sigma$-finite measures on $(X_{j},\mathcal{M}_{j})$ such that $\nu_{j}\ll\mu_{j}$. I want to show that $\nu_{1}\times\nu_{2}\ll\mu_{1}\times\mu_{2}$ and that $\frac{d(\nu_{1}\times\nu_{2})}{d(\mu_{1}\times\mu_{2})}(x_{1},x_{2})=\frac{d\nu_{1}}{d\mu_{1}}(x_{1})\frac{d\nu_{2}}{d\mu_{2}}(x_{2})$. I tried to show that if $E\in\mathcal{M}_{1}\otimes\mathcal{M}_{2}$ and $\mu_{1}\times\mu_{2}(E)=0$, then $\nu_{1}\times\nu_{2}(E)=0$. This criterion holds for measurable rectangles so then I tried considering $\{E\in\mathcal{M}_{1}\otimes\mathcal{M}_{2}|\mu_{1}\times\mu_{2}(E)>0\;\text{or}\;\nu_{1}\times\nu_{2}(E)=0\}$ and show that it is a $\sigma$-algebra containing all measurable rectangles but I guess it didn't quite work.","['measure-theory', 'real-analysis']"
228935,prove $f(z)=cz^n$ for some $c$.,"If $f$ is entire and $|f|=1$ on $|z|=1$,then $f(z)=cz^n$ for some $c$. First consider $g(z)=f(z)/\prod(z-a_i)/(1-\overline{a_i}z)$,where $a_i$ are zeros of $f(z)$. Then I want to apply the maximum and minimum modulus theorem to argue that all $a_i$'s are zero. But what am I supposed to do? Do I need to first show that $g(z)$ is constant?",['complex-analysis']
228938,Complex Analysis textbook - specific criteria,"I'm looking for a text (textbook, lecture notes etc.) on Complex Analysis that meets some very specific desiderata. I've already searched through books recommended here and on MathOverflow, but so far I haven't found anything to suit my needs. (I should mention that I took a one-semester course in C.A. two years ago which was presented in this way, so I may be a little bit partial here.) Firstly, the terms ""holomorphic"" and ""analytic"" should not be used interchangeably. Although there is no mathematical mistake as long as the power series expansion theorem is not implicitly assumed, it's good to have some distinction of meaning. Complex integrals should be done in their general form, i.e. with Riemann sums over arbitrary (rectifiable) curves, not just over $\mathcal{C}^1$ curves (with the integral defined as $\int_a^b f(\gamma(t)) \gamma^\prime(t)\;\mathrm{d}t$). Definitions (like the integral one above) should emphasise the conceptual side of a notion, not the computational side. E.g. in the course I took the winding number was defined like this , not like this . The Cauchy integral theorems should be presented using homotopy/homology theories. (As a counterexample, the Stein/Shakarchi book proves them only on particular cases of contours.) It would be nice to have short introductions to topics which stem from complex function theory - like sheaf theory, Riemann surfaces or analytic number theory - but I think that I already narrowed the answer space too much. What can you recommend?","['reference-request', 'complex-analysis']"
228939,Which Fourier series formula is correct,"I'm getting started on Fourier series but I'm confused over the formulae involved. My lecturers notes, including Wikipedia state that, for the interval $(-\pi \le x \le \pi)$ $$a_0 = \frac1\pi \int \cdots $$ whereas videos on Youtube and other tutorials I've found seem to be using: $$a_0 = \frac1{2\pi} \int \cdots $$ Which one am I supposed to use?","['fourier-series', 'calculus']"
228941,"How to show that x, y and z are equal?","I would really appreciate help with this system of equations:
$$
\left\{ 
\begin{array}{c}
x^2 +3y=-2 \\ 
y^2 +3z=-2 \\ 
z^2+3x=-2 
\end{array}
\right. 
$$ It seems quite obvious that $x, y$ and $z$ are all equal and then the equation can be solved easily, but I don't know how to show that they are equal mathematically.",['algebra-precalculus']
228969,How to convert formula to disjunctive normal form?,"Convert $$((p \wedge q) → r) \wedge (¬(p \wedge q) → r)$$ to DNF. This is what I've already done: $$((p \wedge q) → r) \wedge (¬(p \wedge q) → r)$$ $$(¬(p \wedge q) \vee r) \wedge ((p \wedge q) \vee r)$$ $$((¬p \vee ¬q) \vee r) \wedge ((p \wedge q) \vee r)$$ And from this point I'm not sure how to proceed. Help would be appreciated. Sorry, but the last line was written badly (I think). It's fixed now.","['disjunctive-normal-form', 'propositional-calculus', 'discrete-mathematics']"
228971,"What's the relationship between singular, nontrivial and linear dependent?","I understand that if a matrix is singular, it has no inverse. 
If it has nontrivial solutions, it means at least one solutions exists.
If it is linearly dependent, it means that for $a_1 \mathbf{v_1}+a_2  \mathbf{v_2} + ... + a_n \mathbf{ v_n} =\mathbf{ 0}$. Not all the $a$'s are 0. (Not all the coefficients of v_k are zero to satisfy the equation.
How does singular relate to nontrivial solutions and nontrivial solutions relate to linear dependent? Let's say you have 3 vectors:
$$\vec p_1(x)=a_1x^2+b_1x+3$$
$$\vec p_2(x)=a_2x^2+b_2x+4$$
$$\vec p_3(x)=a_3x^2+b_3x+99$$ We multiply all the stuff with c and get
$$c_1\vec p_1(x)+c_2\vec p_2(x)+c_3\vec p_3(x)=0$$ Then, we make
$$a_1c_1+a_2c_2+a_3c_3=0$$
$$b_1c_1+b_2c_2+b_3c_3=0$$
$$3c_1+4c_2+99c_3=0$$ This coefficient matrix can be singular hence there are nontrivial solutions . So, $\vec p_1$, $\vec p_2$ and $\vec p_3$ are linearly dependent . OR This coefficient matrix can be nonsingular hence there are trivial solutions . So, $\vec p_1$, $\vec p_2$ and $\vec p_3$ are linearly independent .","['vector-spaces', 'matrices', 'linear-algebra']"
228983,Hard math contest trigonometry type problem,"How to solve this problem: Also, most people would use trigonometry, but is there a way to use derivative to solve this too?","['geometry', 'trigonometry', 'contest-math']"
228995,Evaluating a double integral: $\iint \exp(\sqrt{x^2+y^2})\:dx\:dy$?,How to evaluate the following integral? $$\iint \exp\left(\sqrt{x^2+y^2} \right)\:dx\:dy$$ I'm trying to integrate this using substitution and integration by parts but I keep getting stuck.,"['multivariable-calculus', 'integration']"
228998,Approximating a $\sigma$-algebra by a generating algebra,"Theorem. Let $(X,\mathcal B,\mu)$ a finite measure space, where $\mu$ is a positive measure. Let $\mathcal A\subset \mathcal B$ an algebra generating $\cal B$ . Then for all $B\in\cal B$ and $\varepsilon>0$ , we can find $A\in\cal A$ such that $$\mu(A\Delta B)=\mu(A\cup B)-\mu(A\cap B)<\varepsilon.$$ I don't think there is a proof in this site. It's a useful result for several reasons: We know what the algebra generated by a collection of sets is, but not what the generated $\sigma$ -algebra is. The map $\rho\colon \cal B\times\cal B\to \Bbb R_+$ , $\rho(A,A')=\mu(A\Delta A')$ gives a pseudo-metric on $\cal B$ . This makes a link between generating for an algebra and dense for the pseudo-metric. We say that a $\sigma$ -algebra is separable if it's generated by a countable class of sets. In this case, the algebra generated by this class is countable. An with the mentioned result, we can show that $L^p(\mu)$ is separable for $1\leq p<\infty$ , which makes a link between the two notions. In ergodic theory, we have to test mixing conditions only an a generating algebra, not on all the $\sigma$ -algebra.",['measure-theory']
229001,Area fractal pentagrams I,"When I saw this image I was a little curious.
How can I find the area of this fractal?","['geometry', 'fractals']"
229033,$L^p$ norm of multivariate standard normal random variable,"Given $X_i\sim \mathcal{N}(0,1)$ what is the behaviour of 
$$ ||X||_{l^p}=(\sum_{i=1}^n|X_i|^p )^{1/p}$$
as $n\rightarrow \infty$?
For $p=2$ results about $\chi$-distribution tell us that 
$$\mathbb{P}(||X||_{l^2}\le 2n^\frac{1}{2} )\rightarrow 1.$$ I am interested in analgous statments for $p\ne1$,i.e. $$\mathbb{P}(||X||_{l^p}\le Cn^{e(p)} ),$$
where $C$ is allowed to depend on $p$.","['probability-theory', 'asymptotics', 'normed-spaces', 'probability-distributions', 'lp-spaces']"
229045,The relation between order isomorphism and homeomorphism,"Let $X$ be a set and let $<_1,<_2$ be order relations on $X$. Let $T_1,T_2$ be the topologies induced on $X$ respectively. If $(X,T_1)$ is homeomorphic to $(X,T_2)$, does that imply that $(X,<_1)$ and $(X,<_2)$ are order isomorphic? And a derived philisophical question: The other way around is easy to prove, so if this holds this means that, in some sense, homeomorphism between order topologies is equivalent to order isomorphism. What does that mean?","['general-topology', 'set-theory', 'order-theory']"
229046,A rigorous book (or preferrably set of notes) on classic multivariable calculus-analysis?,"This is different to (Theoretical) Multivariable Calculus Textbooks as I want a classical treatment of line and surface integrals without the notion of a differential form. Prerequisites: Paths, line integrals, the interior of a curve, orientation, surfaces etc. must be rigorously defined . The theorems of Green, Divergence, Stokes must be rigorously proven in some (or all) of their generality. Finally computational aspects of the theory must be kept to a minimum You can suggest any book you want but I would prefer a set of notes (pdf format) accessible for free on the internet. Thank you for your answers","['big-list', 'multivariable-calculus', 'self-learning', 'reference-request']"
229064,Non-closed compact subspace of a non-hausdorff space,I have a topology question which is: Give an example of a topological (non-Hausdorff) space X and a a non-closed compact subspace. I've been thinking about it for a while but I'm not really getting anywhere. I've also realised that apart from metric spaces I don't really have a large pool of topological spaces to think about (and a metric sapce won't do here-because then it would be hausdorff and any compact set of a metric space is closed) Is there certain topological spaces that I should know about (i.e. some standard and non-standard examples?) Thanks very much for any help,"['general-topology', 'compactness']"
229065,If $f \circ g$ is onto then $f$ is onto and if $f \circ g$ is one-to-one then $g$ is one-to-one,"I am trying to make a picture in my head so I can understand and remember the rules. So if $f \circ g$ is onto, it is onto because the function $f$ maps every element from a set $B$ to a set $C$ (thus $f$ is onto) and if $f \circ g$ is one-to-one then every element from set $A$ is mapping an element of set $B$ (and thus is one-to-one). If both $f$ and $g$ is onto then $f \circ g$ is onto and if both $f$ and $g$ is one-to-one then $f \circ g$ is one-to-one and if both $f$ and $g$ are bijective then $f \circ g$ is bijective? If $f \circ g$ is bijective, we can't say anything, but that $f$ is onto and that $g$ is one-to-one? If $f$ is onto and $g$ is one-to-one, nothing can be said? If $g$ is one-to-one and $g$ is onto, nothing can be said?","['elementary-set-theory', 'functions', 'function-and-relation-composition']"
