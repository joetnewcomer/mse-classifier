question_id,title,body,tags
3273860,$(\omega+1)\cdot \omega=\omega ^2$ by definition,I'm trying to show that: $(\omega+1)\cdot \omega=\omega ^2$ by definition: $(\omega+1)\cdot \omega= \text{sup}\{(\omega+1)\cdot n: n \in \omega\}$ I can see is that $(\omega+1) \cdot n = (\omega+1)+(\omega+1)+...+(\omega+1)= \omega+\omega+...+\omega+1$ how do i prove that sup is $\omega^2$ ?,"['elementary-set-theory', 'ordinals']"
3273874,Can a nowhere continuous function have a connected graph?,"After noticing that function $f: \mathbb R\rightarrow \mathbb R $ $$ f(x) = \left\{\begin{array}{l} \sin\frac{1}{x} & \text{for }x\neq 0 \\ 0 &\text{for }x=0 \end{array}\right. $$ has a graph that is a connected set, despite the function not being continuous at $x=0$ , I started wondering, doest there exist a function $f: X\rightarrow Y$ that is nowhere continuous, but still has a connected graph? I would like to consider three cases $X$ and $Y$ being general topological spaces $X$ and $Y$ being Hausdorff spaces ADDED: $X=Y=\mathbb R$ But if you have answer for other, more specific cases, they may be interesting too.","['continuity', 'general-topology', 'examples-counterexamples', 'connectedness']"
3273876,Radical equation solve $\sqrt{3x+7}-\sqrt{x+2}=1$. Cannot arrive at solution $x=-2$,"I am to solve $\sqrt{3x+7}-\sqrt{x+2}=1$ and the solution is provided as -2. Since this is a radical equation with 2 radicals, I followed suggested textbook steps of isolating each radical and squaring: $\sqrt{3x+7}-\sqrt{x+2}=1$ $(3x+7=(1-\sqrt{x+2})^2$ # square both sides (Use perfect square formula on right hand side $a^2-2ab+b^2$ ) $3x+7=1^2-2(1)(-\sqrt{x+2})+x+2$ # lhs radical is removed, rhs use perfect square formula $3x+7=1+2(\sqrt{x+2})+x+2$ # simplify $3x+7=x+3+2\sqrt{x+2}$ # keep simplifying $2x+4=2\sqrt{x+2}$ # simplify across both sides $(2x+4)^2=(2\sqrt{x+2})^2$ $4x^2+16x+16=4(x+2)$ # now that radical on rhs is isolated, square both sides again $4x^2+12x+14=0$ # a quadratic formula I can use to solve for x For use int he quadratic function, my parameters are: a=4, b=12 and c=14: $x=\frac{-12\pm\sqrt{12^2-(4)(4)(14)}}{2(4)}$ $x=\frac{-12\pm{\sqrt{(144-224)}}}{8}$ $x=\frac{-12\pm{\sqrt{-80}}}{8}$ $x=\frac{-12\pm{i\sqrt{16}*i\sqrt{5}}}{8}$ $x=\frac{-12\pm{4i*i\sqrt{5}}}{8}$ $x=\frac{-12\pm{-4\sqrt{5}}}{8}$ #since $4i*i\sqrt{5}$ and i^2 is -1 This is as far as I get: $\frac{-12}{8}\pm\frac{4\sqrt{5}}{8}$ I must have gone of course somewhere further up since the solution is provided as x=-2. How can I arrive at -2?","['algebra-precalculus', 'quadratics', 'radicals']"
3273888,Is there any formula for $(\bigcup_{i\in I}A_i)\bigcap(\bigcup_{j\in J}B_j)$?,I came up with this question when doing some argument in topology. Is there any formula for $(\bigcup_{i\in I}A_i)\bigcap(\bigcup_{j\in J}B_j)$ ? Can it be reduced in another form?,['elementary-set-theory']
3273934,"Show that $f(x,y) = \frac{x^3+y^3}{x-y}$ when $x \neq y$ is discontinuous at the origin","Show that the following function is discontinuous at the origin $(x,y)=(0,0)$ $$
\begin{equation}
f(x,y) = 
\begin{cases}
\frac{x^3+y^3}{x-y} &x\neq y\\
0  &x = y
\end{cases}
\end{equation}
$$ Now I am taking $x=my\ (m \neq 1)$ and getting $f(x,y)$ as $$\lim_{(x,y) \to (0,0)}f(x,y)=\lim_{x \to 0}\frac{x^3+m^3x^3}{x-mx} = \lim_{x \to 0}\frac{x^2+m^3x^2}{1-m}$$ which tends to zero showing that the function is continuous. But we need to show discontinuance, I am not getting any other substitution for $y$ that will prove discontinuity.","['limits', 'multivariable-calculus', 'continuity']"
3274010,"$f$ entire, $g(x, y) := |f(x+iy)|$ integrable on $\mathbb{R}^{2}$ $\implies$ $f \equiv 0$. [duplicate]","This question already has an answer here : An entire function whose integral is bounded is identically zero (1 answer) Closed 5 years ago . Let $f \in H(\mathbb{C})$ and $g(x, y) := |f(x+iy)|$ , and assume $g$ is integrable on $\mathbb{R}^{2}$ . Show then that $f \equiv 0$ . Things I Know: $f$ is bounded on each $D(0, R)$ for $R > 0$ , but the bounds must increase as $R \rightarrow \infty$ . Intuitively, this should mean $\int_{\partial D(0, R)} |f(z)| dz \rightarrow \infty$ as $R \rightarrow \infty$ (assuming $f \not\equiv 0$ ), which could say something about $g$ . But here I'm talking about upper bounds, which don't help. I could consider the infimum $f$ takes on $\partial D(0, r)$ to bound below, but these inf's don't necessarily grow larger as $R$ does. My intuition tells me Liouville will come into play, but I'm not sure... Any ideas? Thank you! Edit: Though this is the same as this question essentially, I want to include proofs that use any complex analytic tools, while the linked question wants a solution based only in elementary calculus.","['integration', 'complex-analysis']"
3274013,Integral from infinity to infinity,"My physics professor today wrote on the blackboard: $$ \int_{\infty}^{\infty} f(x) dx = 0 $$ for every function $f$ . 
And the proof he gave was: $$ \int_{\infty}^{\infty} f(x) dx = \int_{\infty}^{a} f(x) dx + \int_{a}^{\infty} f(x)dx = - \int_{a}^{\infty} f(x) dx + \int_{a}^{\infty}f(x)dx = 0$$ However I'm still not convinced, for me an integral from infinity to infinity has no meaning. Therefore, what I'm asking is: does the above equations make sense? If not, are there cases where they do make sense? I'm thinking about functions that converge to 0 in $+\infty$ . EDIT: Actually, the function f considered was a density, i.e.: $$ \int_{-\infty}^{+\infty} f(x)dx = 1 $$ and $f(x) \geq 0$ for all $x$ .",['integration']
3274039,Sudoku: Maximal minimum number of starting clues,"It is well known (as shown here ) that the minimum number of starting clues a Sudoku puzzle may have to generate a unique solution is 17. My main question is Given a completed Sudoku grid, is it always possible to find a subset of 17 starting clues which generate the grid uniquely? I suspect the answer might be 'no' as, accounting for symmetries, there are 3,359,232 distinct Sudoku grids and I think there are only around 50,000 known 17-clue Sudoku puzzles. This leads me to a follow-up question. Let $\mathbb{S}$ be the set of all completed Sudoku grids. For a given $S \in \mathbb{S}$ , let $m(S)$ be the minimum number of starting clues required to generate $S$ uniquely. What is $$M = \max\{ m(S) | S \in \mathbb{S}\}?$$ If the answer is not known, do we have an upper bound for $M$ ? What do I know so far? We can demonstrate, by hand, that $M \leq 60$ . Take any completed Sudoku grid and remove the following entries (marked by an X): The solution to this Sudoku is fully determined and some subset of the remaining clues will constitute a minimal set of starting clues. I am almost certain that $M < 40$ . According to the mathematics of Sudoku , ""The most clues for a minimal Sudoku is believed to be 40, of which only two are known."" One way of generating Sudoku puzzles would be to start with a completed grid and remove entries using some algorithmic procedure until a minimal set of clues was reached. So much analysis has been done on this that, in my opinion, if somebody encountered a grid where they could not generate a set of starting clues with less than 40 entries, this would be of considerable note. I suspect that $M$ is around $20$ and it's conceivable to me that somebody may have indirectly encountered a much better upper bound for $M$ while trying to generate puzzles from completed grids. Update: A proof that $M \leq 48$ was given here on Puzzling SE Also, $M \geq 18$ , as verified by examples given here","['sudoku', 'combinatorics']"
3274050,A more rigorous way to show that $x^5 - 3x = 1$ has at least $3$ roots in $\Bbb R$,"Given an equation: $$
x^5 - 3x = 1
$$ Show that: It has at least $1$ root on $(1, 2)$ ; It has at least $3$ roots on $\Bbb R$ I've started with considering a function $f(x)$ for $x\in [1, 2]$ : $$
f(x) = x^5 - 3x - 1
$$ Then calculating its value on the left and right sides of the closed interval yields: $$
f(1) = -3\\
f(2) = 25
$$ Applying the Intermediate Value Theorem yields that there exists a point for $x_0 \in [1, 2]$ such that $f(x_0) = 0$ . Which means that indeed at least one root exists. However, for the second part of the question if we consider $f(x)$ for $x \in \Bbb R$ , the only way I see is to try and guess the intervals where the function changes its sign and then apply IVT again. Consider for example $f(x)$ for $x \in \{-2, -1, 1, 2\}$ . I see how derivatives could be to the rescue here, the problem is that I'm not allowed to use derivatives . Is there a rigorous way to prove what's stated without guessing and without using derivatives? Thank you!","['calculus', 'roots', 'polynomials', 'real-analysis']"
3274099,Please help me understand the following transition in the limit,"I was trying to figure out how a limit was calculated and got stuck when trying to understand one of the proposed solutions: (note that this is just a small part of the solution, but the one that got me in trouble) $$\lim_{n\to\infty}\frac{1}{\sqrt{n}}\left|\sum\limits_{k=1}^n (-1)^k\sqrt{k}\right|   
= \lim_{n\to\infty}\frac{1}{\sqrt{2n}}\sum\limits_{k=1}^n \frac{1}{\sqrt{2k-1}+\sqrt{2k}} $$ In my opinion, whether $n$ is odd or even has an impact on the sum. Plugging a few random $n$ -s doesn't help to prove the validity of the formula for me. I guess this is one of the cases when I am puzzled and can't see something obvious. If someone could clarify it for me, that would be great. Thanks!","['limits', 'summation', 'sequences-and-series']"
3274116,Examples of $C^*$-algebras without strict comparison,"$\textbf{Definition: }$ Let $\mathcal{A}$ be a unital $C^*$ -algebra and $$\mathcal{T}(\mathcal{A})=Tracial~States~of~\mathcal{A}$$ $\mathcal{A}$ has strict comparison for projections if for all projections $p,q \in \mathcal{A}$ $$\tau({p})<\tau(q)~~~~~~\forall~\tau \in \mathcal{T}(\mathcal{A}) \implies p\leq q$$ I am trying to find a $C^*$ -algebra which does not have strict comparison for projections. I want to find a simple , unital AF algebra without strict comparison that is $\textbf{GOAL:}~~~~~$ Find a simple unital AF-algebra $\mathcal{A}$ and $p,q \in \mathcal{A}$ projections such that $\tau(p)=\tau(q)$ for all $\tau \in \mathcal{T}(\mathcal{A})$ but $p \not\sim q$ . Thanks in advance for your help.","['c-star-algebras', 'trace', 'functional-analysis', 'examples-counterexamples']"
3274118,Packing of parallelograms with sides $1$ and $\sqrt{2}$ and angle $45^{\circ}$ in a rectangular container,"If $ABCD$ is a parallelogram such that $\angle BAD=\frac{\pi}{4}$ , $AB=\sqrt{2}$ , $AD=1$ then we shall say that $ABCD$ is a good parallelogram. Parallelograms can be rotated by any angle. a) Prove that in a rectangular container $2 \times n$ ( $n \ge 2$ ) cannot be packed more than $2n-2$ good parallelograms (packing must be without overlaps between parallelograms). b) Prove that in a rectangular container $4 \times 4$ cannot be packed more than $12$ good parallelograms (packing must be without overlaps between parallelograms). My work. It is easy to pack $2n-2$ good parallelograms into rectangular container $2 \times n$ . The area of the good parallelogram is $1$ . The area of the rectangular container $2 \times n$ is $2n$ . Obviously, parallelograms will not be able to cover every region of the rectangular container. Therefore, in a rectangular container $2 \times n$ ( $n \ge 2$ ) cannot be packed more than $2n-1$ good parallelograms. But I have no idea how to improve the evaluation for one parallelogram.","['contest-math', 'packing-problem', 'geometry', 'plane-geometry']"
3274246,"How to interpret $(x(t_1), x(t_2), \dots, x(t_n)) \in (a_1,b_1] \times (a_2,b_2] \times \dots \times (a_n,b_n]$?","I need help with the following, how should I interpret this notation? $$
(x(t_1), x(t_2), \dots, x(t_n)) \in (a_1,b_1] \times (a_2,b_2] \times \dots \times (a_n,b_n] 
$$ 1. Does it mean "" $x(t_1)$ is a element of the set $(a_1,b_1]$ "" and "" $x(t_2)$ is a element of the set $(a_2,b_2]$ "", and so forth? 
So we have \begin{align}
x(t_1)&\in (a_1,b_1] \\
x(t_2)&\in (a_2,b_2] \\
&\vdots \\
x(t_n)&\in (a_n,b_n] 
\end{align} 2. Or does the notation mean something like this \begin{align} 
x(t_1)&\in (a_1,b_1] \times (a_2,b_2] \times \dots \times (a_n,b_n] \\
x(t_2)&\in (a_1,b_1] \times (a_2,b_2] \times \dots \times (a_n,b_n]  \\
&\vdots \\
x(t_n)&\in (a_1,b_1] \times (a_2,b_2] \times \dots \times (a_n,b_n] 
\end{align} I don't know how to phrase this notation. Does it have a meaning in this context? 3. Or maybe something like this \begin{align}
(x(t_1), x(t_2), \dots, x(t_n)) &\in (a_1,b_1] \\
(x(t_1), x(t_2), \dots, x(t_n)) &\in (a_2,b_2] \\
&\vdots \\
(x(t_1), x(t_2), \dots, x(t_n)) &\in (a_n,b_n] 
\end{align} Same here, I don't know how to phrase this notation. Does it have a meaning in this context? Thanks!","['elementary-set-theory', 'notation']"
3274291,Does multiplication by a test function stay in a Sobolev space?,"Let $u \in D^{1,\vec{p}}(\Omega)$ and $\phi \in C_c^{\infty}(\Omega)$ .
  Then do we necessarily have $u\phi \in D^{1,\vec{p}}(\Omega)$ ? My attempt What we need to show is that $\partial_i (u \phi) \in L^{p_i}(\Omega)$ for each $i$ . We can try to break up the integral as: \begin{align*}
\int_{\Omega} |\partial_i (u \phi)|^{p_i}
&=
\int_{\Omega} |\partial_i u \cdot \phi + \partial_i \phi \cdot u|^{p_i}
\leq
\int_{\Omega} |\partial_i u \cdot \phi|^{p_i} + \int_{\Omega} |\partial_i \phi \cdot u|^{p_i}
\\
&=
\int_{\Omega} |\partial_i u|^{p_i} |\phi|^{p_i} + \int_{\Omega} |\partial_i \phi|^{p_i} |u|^{p_i}
\end{align*} The first term is easily bounded given the nature of $\phi$ and $u$ . But, the second term is more troublesome. We can bound the size of $|\partial_i \phi|$ and restrict the integral to a compact set. Then if $p_i \leq p^*$ , we can easily bound our integral by $|\operatorname{supp} \partial_i \phi| + \|u\|_{p^*}$ , which is finite since $D^{1,\vec{p}}(\Omega)$ is embedded in $L^{p^*}(\Omega)$ . But we don't necessarily always have $p_i \leq p^*$ ; in this case, I don't know what to do. Background For $\vec{p} = (p_1, ..., p_N)$ and $\Omega \subseteq \mathbb{R}^N$ , the Sobolev space $D^{1,\vec{p}}(\Omega)$ is defined as the completion of $C_c^{\infty}(\Omega)$ with respect to the norm: \begin{align*}
\|u\|_{\vec{p}} = \sum \limits_{i=1}^N \|\partial_i u \|_{p_i}
\end{align*} We think of this space as being continuously embedded into $L^{p^*}(\Omega)$ via the Sobolev inequality given here , where $p^* = Np/(N-p)$ and $1/p = \sum 1/p_i$ .","['integration', 'smooth-functions', 'lp-spaces', 'sobolev-spaces', 'functional-analysis']"
3274331,Surface area of spheres not seen by any other.,"I found this question recently looking around the internet, apparently it was on the IMO shortlist many years back. I haven't been able to solve it, and I am looking for hints and/or full solutions. Apparently it can be done very elegantly. Consider N non overlapping spheres of equal radius placed in 3D space. Let $S$ be the set of points on the surface of these spheres which are not visible from any other sphere. Show that the total area of $S$ is equal to the surface area of one sphere. Thoughts so far: the problem is trivial in one dimension, and likely equivalent in difficulty in 2D and 3D (it looks like it still holds in 2D, hence I imagine it works for any number of dimensions). It is also obviously true for 2 spheres, and can be verified with some effort for 3. I've had many ideas but none of them have yet led me anywhere I thought promising.","['contest-math', 'geometry']"
3274399,Is there a proof that any curve can be built from very small line segments?,"It seems to me (who is quite the math novice) that a very important ‘statement’, for a lack of a better word , that is foundational to many mathematical topics is that a given curve, which is continuous and differentiable, can be built from a bunch of straight lines as long as we make those lines ‘small enough’. For a 2D case, I interpret this as being able to build a curve that traverses through a 2D plane by only using little $\Delta x$ ’s and little $\Delta y$ ’s. I am wondering how one goes about proving this statement. It seems to me a good starting point can be illustrated using the following picture: I suppose I should clarify that I am simply using this circle as a starting point for this argument...this could be any arbitrary curve (not just the circumference of a circle...though I suppose there is probably a proof out there that shows tiny sections of a curve can also be approximated by an arc length of a circle with a certain radius...but that's another question for a different time). So the question I want an answer to is the following:
As $\Delta x$ becomes very small (and its corresponding $\Delta y$ , based on the behavior of the curve, or, more specifically, based on the function that describes the curve, also becomes very small ), does $(r*\Delta \theta) / (\sqrt{(\Delta y)^2+(\Delta x)^2)}$ approach 1.0? How would one go about proving this? I feel like most arguments that I can think of are rather circular…in that I have to use a property that is based off of what I want to prove in order to prove it! Is there a proof for this limit? Or is this just an axiom we accept to be true? Edit 1: It has been brought to my attention that including the word ""differentiable"" as a characteristic of a curve creates a circular argument for what I would like to prove. The logic behind that claim is ""if the curve is differentiable, then of course a curve can be decomposed into line segments because that is the definition of differentiable"". Assuming this is true, please disregard the word 'differentiable'. I am interested in solving the previously referred to limit as if I never knew that calculus existed!","['curves', 'calculus', 'geometry']"
3274409,How many numbers of $4$ digits $x_1x_2x_3x_4$ satisfy $x_1\leq x_2 \leq x_3 \leq x_4$?,"How many numbers of $4$ digits $x_1x_2x_3x_4$ satisfy $x_1\leq x_2 \leq x_3 \leq x_4$ ? What I've worked so far: I have identified this situation with distributing $4$ equal objects among $9$ different boxes (digits from $1$ to $9$ ). Therefore, solving the question proposed should be equivalent to solving the number of integer solutions of the following equation: $$y_1+y_2+y_3+y_4+y_5+y_6+y_7+y_8+y_9=4\\
y_i\geq0 \quad \forall i\in\{1,2,...,9\}$$ The total solutions for this equations are: $$\text{CR}_{9}^{4}={4+9-1 \choose 4}={12 \choose 4}=\frac{12!}{4!\cdot8!}=11\cdot9\cdot5=495\text{ posibilities}$$ Is there any other approach you think it's more practical? Is this reasoning correct? Clarifications: If one distribution of the objets is $6292$ (box nº 6 is the first box where I distribute an object; box nº $2$ the second; box nº $9$ the third and box nº $2$ the fourth). The order in which boxes I distribute the objects doesn't really matter because the objects are identical, so I can rearrange the result to get $2269$ which is a combination that verifies the restriction given.","['combinations', 'combinatorics']"
3274438,How is the Jacobian derived using this method?.,"My course notes say the following: $$\left[\begin{array}{l}{d x} \\ {d y}\end{array}\right]=\left[\begin{array}{ll}{x_{u}} & {x_{v}} \\ {y_{u}} & {y_{v}}\end{array}\right]\left[\begin{array}{l}{d u} \\ {d v}\end{array}\right]\\$$ $$d A=\left|\begin{array}{ll}{x_{u}} & {x_{v}} \\ {y_{u}} & {y_{v}}\end{array}\right| d u d v\\$$ Apparently the second line follows from the first, but expanding out the algebra of the two equations from the first line and multiplying both equations together (as $dA = dx dy$ ) I don't get the same as calculating the determinant in the second line and multiplying by $dudv$ . So how does the second line follow from the first?","['jacobian', 'multivariable-calculus']"
3274460,Show that these Kähler forms are $\sqrt{-1}\partial \overline{\partial}$-cohomologous,"I have decided to rewrite my question almost entirely: Let $Y$ be a compact (without boundary) Calabi-Yau manifold, i.e., $c_1(Y)=0$ in $H^2(Y, \mathbb{R})$ . Let $\omega$ be a Kähler form on $\mathbb{C}^m \times Y$ and let $\omega_P = \omega_{\mathbb{C}^m} + \omega_Y$ . It can be shown (see, e.g., the first statement of [1, Theorem A]) that $\zeta = \omega - \omega_P$ is an exact $(1,1)$ -form, i.e., $\zeta = d\xi$ for some real $1$ -form $\xi$ on $\mathbb{C}^m \times Y$ . My question concerns obtaining a more direct proof of Statement (ii) of [1, Theorem A]. That is, I am attempting to prove that there exists an automorphism $T$ of $\mathbb{C}^m$ such that $$\omega = T^{\ast} \omega_{\mathbb{C}^m} + \omega_Y + \sqrt{-1}\partial \overline{\partial} \varphi,$$ for some smooth $\mathbb{R}$ -valued function $\varphi$ . The proof given in [1, Proposition 3.1] is too abstract, and I would like a proof along the same lines as the Poincaré lemma and the Dolbeault lemma. In [2], the authors write $\omega$ can be expressed in local coordinates as \begin{eqnarray*}
\omega &=& \hat{\omega}_{\mathbb{C}^m} + \omega_Y + \frac{1}{2} \sum_{i=1}^n dz^i \wedge \eta^i + \frac{1}{2} \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i,
\end{eqnarray*} where $\eta^i = \left( \frac{\partial}{\partial z^i} \ \llcorner \ \omega \right) $ (here $\llcorner$ denotes the interior product), and $\hat{\omega}_{\mathbb{C}^m} = \frac{1}{2} \sum_{i,j=1}^m u_{i \overline{j}} dz^i \wedge d\overline{z}^j$ for some Hermitian matrix $(u_{i \overline{j}})$ . I might be able to make a lot of progress if $\sum_{i=1}^m dz^i \wedge \eta^i + \sum_{i=1}^m d\overline{z}^i \wedge \overline{\eta}^i$ could be written as $\partial \overline{\partial}\varphi$ for some smooth function $\varphi$ . References: [1] Hein, H.-J., A Liouville theorem for the complex Monge-Ampère equation on product manifolds , arxiv: 1701.05147. ( https://arxiv.org/abs/1701.05147 ) [2] Li, C., Li, J., Zhang, X., A mean value formula and a Liouville theorem for the complex Monge-Ampère equation , arxiv: 1709.05754. ( https://arxiv.org/abs/1709.05754 ) An attempt: Let $(z_1, ..., z_m, z_{m+1}, ..., z_{m+n})$ denote the local coordinates on $\mathbb{C}^m \times Y$ . Since the Kähler forms $\omega$ and $\omega_{\mathbb{C}^m} + \omega_Y$ are cohomologous, there exists a real $1$ -form $\xi$ such that $$\omega = \omega_{\mathbb{C}^m} + \omega_Y + d \xi.$$ Comparing the degrees of these forms, it is clear that if we decompose $\xi = \xi^{1,0} + \xi^{0,1}$ according the decompositon $\Lambda^1 = \Lambda^{1,0} \oplus \Lambda^{0,1}$ , then $\partial \xi^{1,0} = 0 = \overline{\partial} \xi^{0,1}$ . Hence, we see that \begin{eqnarray*}
\omega &=& \omega_{\mathbb{C}^m} + \omega_Y + \partial \xi^{0,1} + \overline{\partial} \xi^{1,0}.
\end{eqnarray*} Following [2], set $\eta^i = \left( \frac{\partial}{\partial z^i} \ \llcorner \ \omega \right) \Bigg \vert_{\{ z \} \times Y}$ . If we write $\omega = \frac{\sqrt{-1}}{2} \sum_{i,j=1}^{m+n} g_{i \overline{j}} dz^i \wedge d\overline{z}^j$ , then \begin{eqnarray*}
\eta^i &=& \frac{\sqrt{-1}}{2} \sum_{j=m+1}^{m+n} g_{i \overline{j}} d\overline{z}^j.
\end{eqnarray*} Hence, we see that \begin{eqnarray*}
&&\sum_{i=1}^n dz^i \wedge \eta^i + \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i \\
&=& \frac{\sqrt{-1}}{2} \sum_{i=1}^n \sum_{j=m+1}^{m+n} g_{i \overline{j}} dz^i \wedge d\overline{z}^j+ \frac{\sqrt{-1}}{2} \sum_{i=1}^n \sum_{j=m+1}^{m+n} g_{j \overline{i}} dz^j \wedge d\overline{z}^i. 
\end{eqnarray*} The claim from [2] is that there now exists a Hermitian matrix $(u_{i \overline{j}})$ such that $\omega = \hat{\omega}_{\mathbb{C}^m} + \omega_Y + \frac{1}{2} \sum_{i=1}^n dz^i \wedge \eta^i + \frac{1}{2} \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i$ .","['complex-analysis', 'complex-geometry', 'kahler-manifolds', 'riemannian-geometry']"
3274493,"$p^2 - 2 q^2 = 5039$ for primes $p, q$","Are there primes $p$ and $q$ for which $p^2 - 2 q^2 = 5039$ ?
This is the least prime $r$ for which I don't know whether $p^2 - 2 q^2 = r$ has a solution in primes. The solutions of the Pell-type equation $x^2 - 2 y^2 = 5039$ are $x_n, y_n$ given by the recurrences $x_{n+4} = 6 x_{n+2} - x_n$ with initial values $x_0 = 71, x_1 = 209, x_2 = 217, x_3 = 1183$ and $y_{n+4} = 6 y_{n+2} - y_n$ with initial values $y_{{0}}=1,y_{{1}}=139,y_{{2}}=145,y_{{3}}=835$ .  Both $x_n$ and $y_n$ have lots of prime values. I haven't found any cases where they are both prime for the same $n$ (having tested up to $n=10000$ ).  There are some ""near misses"", e.g. neither $x_{179}$ nor $y_{179}$ is prime but they have no small factors. Thus there doesn't appear to be any   modular reason for solutions not to exist. Heuristically, since $x_n$ and $y_n$ increase exponentially, each has probability $O(1/n)$ of being prime, so the probability of both being prime
is $O(1/n^2)$ , and since $\sum_n 1/n^2 < \infty$ , we might expect finitely 
many $n$ with both $x_n$ and $y_n$ prime.  So maybe there just happen to be none, but there's no way to actually prove that.  Still, I thought I'd put this to MSE in the hope that there's something clever that I'm missing. EDIT: I might mention that in order for $p^2 - 2 q^2 = r$ to have prime solutions, where $r$ is prime, either $q=2$ or $3$ (so $r + 8$ or $r + 18$ is the square of a prime) or $r \equiv 23 \mod 24$ .  Of the primes $\equiv 23 \mod 24$ less than $10000$ , the only ones for which I haven't found prime solutions are $4079$ , $5039$ and $7703$ , but I can prove there are no prime solutions for $4079$ and $7703$ (all solutions to $x^2 - 2 y^2 = r$ in those cases have $x$ or $y$ divisible by $5$ , $7$ or $11$ ). EDIT: See OEIS sequence A308816 . Miracles do happen.  For $r = 96431$ the least primes $p$ and $q$ for which $p^2 - 2 q^2 = r$ have $685$ digits each.","['number-theory', 'elementary-number-theory', 'diophantine-equations']"
3274570,Frullani integral $\int_0^\infty \frac{\text{csch}(x)-\frac1x}{x} {\rm d}x$,"$$
\int_0^\infty \frac{\text{csch}(x)-\frac1x}{x} {\rm d}x.
$$ This integral was from a recent contest like two weeks ago and I still can't crack it. Well, to be exact it was in the form of $$
\int_0^\infty \frac{2}{x^2} \left( \frac{x}{e^x - e^{-x}} - \frac12 \right) {\rm d}x.
$$ The hint was to turn it into Frullani integral , but nothing i've tried worked out, by-parts leaves you with something that doesn't converge and I can't find a way to turn the numerator into $f(ax)-f(bx)$ . I noted that it can also be written in the form $$\int_0^\infty \frac{\text{csch}(\frac1x) - x}{x} {\rm d}x.$$","['integration', 'contest-math', 'improper-integrals', 'definite-integrals', 'calculus']"
3274605,Find $ \frac{1}{2^2 –1} + \frac{1}{4^2 –1} + \frac{1}{6^2 –1} + \ldots + \frac{1}{20^2 –1} $,"Find the following sum $$
\frac{1}{2^2 –1} + \frac{1}{4^2 –1} + \frac{1}{6^2 –1} + \ldots + \frac{1}{20^2 –1}
$$ I am not able to find any short trick for it.
Is there any short trick or do we have to simplify and add it?",['sequences-and-series']
3274629,Find the range of the function $f(x)=\frac{x}{\sqrt{1-\lfloor x \rfloor} }$,"Find the range of the function $$f(x)=\frac{x}{\sqrt{1-\lfloor x \rfloor} }$$ My try : I know that $1-\lfloor x \rfloor >0$ So $\lfloor x \rfloor < 1  
  \ ; x <1$ now what ?","['calculus', 'functions']"
3274630,Interchange limit and (definite) integral,"I'm trying to calculate the following limit \begin{equation}\label{eq}\large\lim_{R\to\infty}\,i\,\int_{-\pi/2}^{\pi/2}\frac{e^{-\alpha(R+i\,w)}e^{t\,e^{R+i\,w}}}{(R+i\,w)^{\beta}}dw\end{equation} with $\alpha\geq0$ , $\beta, t>0$ . The problem is that (I think, I'm not sure...) I can't change limit by integral. Then, I have 2 doubs: Can I change limit by integral? If the answer is not, another way to manipulate this limit is welcomed. Update 1: Using the generating function of Bell polynomials of first kind $B_n(t)$ $$\large e^{t(e^u-1)}=\sum_{n=0}^\infty\frac{B_n(t)}{n!}u^n$$ reemplacing $u \rightarrow R+i\,w$ we have $$\lim_{R\to\infty}\,i\,\sum_{n=0}^\infty\frac{e^t\,B_n(t)}{n!}\int_{-\pi/2}^{\pi/2}e^{-\alpha(R+i\,w)}\,(R+i\,w)^{n-\beta}dw=$$ $$\large\lim_{R\to\infty}\sum_{n=0}^\infty\frac{e^t\,B_n(t)}{n!\,\alpha^{n-b-1}}\left[\,\Gamma(n-\beta-1,\alpha(R-i\,\pi/2))-\Gamma(n-\beta-1,\alpha(R+i\,\pi/2))\,\right]$$ Update 2: Changing the variable $R+i\,w\rightarrow u$ we have $$\large\lim_{R\to\infty}\,i\,\int_{-\pi/2}^{\pi/2}\frac{e^{-\alpha(R+i\,w)}e^{t\,e^{R+i\,w}}}{(R+i\,w)^{\beta}}dw=\lim_{R\to\infty}\,\int_{R-i\,\pi/2}^{R+i\,\pi/2}\frac{e^{-\alpha\,u}e^{t\,e^u}}{u^{\beta}}du$$ and maybe we can apply complex integration (Cauchy theorem,...) in the last one.","['integration', 'complex-analysis', 'limits', 'definite-integrals']"
3274643,Estimate parameter $a$ such that $tr \left[ A (B- (I-aC)B(I-aC) ) \right] > 0$.,"Suppose $A, B, C$ are all real symmetric and positive definite matrices. Consider the function $f: \mathbb R \to \mathbb R$ given by $$ a \mapsto {\bf tr}\left[ A (B- (I-aC)B(I-aC) ) \right],$$ where $I$ is identity matrix. It is clear $f(0) = 0$ and further assume there exists some $\tau > 0$ such that $f(x) > 0$ for every $x \in (0, \tau)$ . We may as well assume the maximal interval such that $f(x) > 0$ to be $(0, \tau)$ . That is, $f(x) > 0$ for $x \in (0, \tau)$ and $f(0) = f(\tau) = 0$ . I am wondering with these information, is it possible to deduce $\tau \ge \frac{1}{\lambda_{\max}(C)}$ ? Essentially I am in the situation that I know for small $a$ , the trace is positive and by continuity there should be some maximal interval the trace is always positive. I want to estimate this interval. I tried to use a crude bound \begin{align*}
{\bf tr}\left[ A (B- (I-aC)B(I-aC) ) \right] \ge \lambda_{\min}(A) {\bf tr}(B) - \lambda_{\max}^2(I-aC)\lambda_{\max}(A) {\bf tr}(B).
\end{align*} But this gives us meaningless bound since if we set above bound to be greater tha $0$ , $a$ could be possibly unsolvable. On the other hand, I feel that $a$ must be related to $\lambda_{\max}(I-aC)$ so we can choose $a$ to minimize this quantity and this would give us $a'=\frac{2}{\lambda_{\min}(C) + \lambda_{\max}(C)}$ . Intuitively, I would imagine over $[0, a']$ , $f$ should be positive.","['matrices', 'matrix-analysis', 'linear-algebra']"
3274706,"If $h(n+1)=h(n)+3$ and $h(0)=1$ , give an explicit expression for $h(n)$ without ""guess"" $h(n)=3n+1$ first .","Let $\omega$ denote the natural numbers (intersection of all inductive set) . Assume $h$ is the function from $\omega$ into $\omega$ for which $h(0)=1$ and $h(n^+)=h(n)+3$ . Give an explicit (not recursive) expression for $h(n)$ . Informally , we have $h(n^+)+h(n)+...+h(1)=h(n)+3+...+h(0)+3$ then we find that $h(n^+)$ ""should be"" $3n+4$ , so we guess $h(n)=3n+1$ . Then we can apply induction and recursion theorem to get the desired conclusion . However , I don't like the proof above since we have to guess what $h(n)$ might be first . Can we prove it directly ? Note: This is an exercise of set theory , so the proof need to be rigorous . Sentence such as "" $0+1+...+n$ "" should be avoid .",['elementary-set-theory']
3274711,Can we recover all matrix minors from some of them?,"Let $k,n$ be natural numbers, $1<k<n$ . Suppose we have an ""unknown"" invertible $n \times n$ matrix $A$ over a field of characteristic zero. (we do not know the entries of $A$ ). Can we recover all the $k$ -minors of $A$ from a fixed, ordered partial list of them? That is, suppose that we are given the values of $r$ of the minors- i.e. we are given an indexed list of $r$ numbers, and we are told which number corresponds to which minor. Can we recover the other minors? Comment: Some non-degeneracy conditions on $A$ are necessary here: We at least need to assume that $\text{rank}(A)>k$ . Otherwise, if $\text{rank}(A)\le k$ , then even if we know all the $k$ -minors of $A$ except one, we cannot recover the last unknown minor. Indeed, take $A=\pmatrix{D&0\\ 0&0}$ where $D$ is any diagonal matrix of size $k$ . We can't recover the $k$ -minor corresponding to the first $k$ rows and columns (which is $\det D$ ) from the other $k$ -minors (which are zeroes). This example was suggested by user1551 .","['determinant', 'matrices', 'algebraic-geometry', 'linear-algebra', 'exterior-algebra']"
3274714,Convolution proof (symmetric),"I want to show, that for some functions $ f,g \in L^1(\mathbb{R^n})$ hold: $$f*g=g*f$$ My proof so far: $ f*g= \int_{\mathbb{R^n}} f(x-y)f(y) dy$ Substitution: $\phi(y) =x-y$ This leads to: $$\int_{\mathbb{R^n}} f(\phi(y)) g(y) | Det(D \phi(y)| = \int_{\mathbb{R^n}} f(\phi(y)) g(y) (-1)^n dy$$ How can I go on from there?","['integration', 'convolution', 'analysis', 'real-analysis']"
3274718,Elementary example of Baire spaces whose product is not Baire,"It is known that there are Baire spaces $X$ and $Y$ whose product is not Baire, the simplest construction I know is due to Cohen and goes as follow: Let $S$ be a stationary subset of $\omega_1$ , then forcing with the poset $\Bbb P_S$ of countable subsets of $S$ closed in $\omega_1$ ordered by $p\leq q$ iff $q\subseteq p$ and $(p\setminus q)\cap(\cup q)=\varnothing$ adds a club contained in $S$ to $\omega_1$ . The proof of this fact shows that $\Bbb P_S$ is ${<\omega_1}$ -distributive (hence Baire in the topology whose open sets are the initial segments). Now let $S_1$ and $S_2$ be two disjoint clubs in $\omega_1$ , then the poset $\Bbb P_{S_1}\times\Bbb P_{S_2}$ is not Baire otherwise forcing with it would add two disjoint clubs to $\omega_1$ . The whole proof uses a bunch of set theoretic facts: forcing with a ${<\kappa}$ -distributive poset does not add sequences of length ${<\kappa}$ to the ground model. the filter $G\times H$ is $\Bbb P\times\Bbb Q$ -generic over $M$ iff $G$ is $\Bbb P$ -generic over $M$ and $H$ is $\Bbb Q$ -generic over $M[G]$ . If $\Bbb P$ and $\Bbb Q$ are separative posets then $\Bbb P\times\Bbb Q$ is Baire in $M$ iff $\Bbb P$ is Baire in $M$ and for every filter $G$ which is $\Bbb P$ -generic over $M$ , $\Bbb Q$ is Baire in $M[G]$ . There is another construction due to Kunen and Fleissner who, for every cardinal $\kappa$ , constructed a family $\{X_\alpha\mid \alpha<\kappa\}$ of metrizable Baire spaces such that $\prod_{\alpha<\kappa}X_\alpha$ is nowhere Baire, meaning that it contains a countable family of dense open sets whose intersection is empty, while for every $\lambda<\kappa$ , $\prod\{X_\alpha\mid\alpha\neq\lambda\}$ is Baire. This construction also uses stationary sets and set theoretic tools. Suppose I want to show an example of two Baire spaces $X$ and $Y$ whose product is not Baire to a person who knows point-set topology but not a lot of set theory, is there a simple explicit construction of two spaces with that property? (Bonus points is the spaces are metrizable, or $X=Y$ or $X\times Y$ is nowhere Baire)","['general-topology', 'forcing', 'baire-category', 'set-theory']"
3274730,Write the functional derivative of the Dirichlet energy,"I have the following functional: $J(u) = \int_{\Omega} \frac{|\nabla u|^p}{p}\,d\Omega$ and I want to compute its functional derivative along the direction of an arbitrary test function $v\in H_0^1$ . I tried applying the limit definition $J'(u)v = \lim_{\varepsilon \to 0} \frac{J(u+\varepsilon v)-J(u)}{\varepsilon}$ but I have some problems with the non linear part of the integral. I know that the expected result should be $J'(u)v=\int_{\Omega}|\nabla u|^{p-2}\nabla u \cdot \nabla v \,d\Omega$ since imposing $J'(u)v=0$ is equivalent to solve weakly the homogeneus p-Laplace equation, but I don't know how to proceed computing this derivative.","['derivatives', 'functional-analysis', 'vector-analysis', 'partial-differential-equations']"
3274757,Is the Lie derivative along the normal well defined?,"This question is cross-posted at the physics stack exchange at https://physics.stackexchange.com/q/488358/83357 Let $(\Sigma, q)$ be a non-degenerate submanifold of a Lorentzian manifold $(M,g)$ . Let $N$ be the section of $T\Sigma ^g$ . Physicists often talk about the evolution of $q$ along $N$ as $\mathcal{L}_Nq$ . But this expression makes no sense as $N$ does not belong to $\mathfrak{X}(\Sigma)$ . As such, Lie derivatives are defined using flows of vector fields; I don't see any natural way of extending it to arbitrary vector bundles $^{[1]}$ . What is happening here? What do physicists mean when they construct quantities like these $^{[2]}$ ? Even a link to a reference that treats this on a mathematically justifiable level is welcome. [1] Naively, I would even expect that one would require some sort of a connection on the vector bundle to make this question tractable. [2] The only argument I can think of is that the operation is actually being performed on the ambient manifold. Say $tan:\mathfrak{X}(M)\to \mathfrak{X}(\Sigma)$ is the canonical projection operation associated to the embedding ( $tan:=q^{\sharp}\circ\iota \circ g^\flat$ ). Now, $tan^*(q)\in \Omega^2(M)$ , so $\mathcal{L}_N(tan^*(q))\in\Omega^2(M)$ is well defined. But this feels like an incomplete picture, and possibly even wrong.","['semi-riemannian-geometry', 'general-relativity', 'lie-derivative', 'differential-geometry']"
3274785,Let $A=\begin{bmatrix} 1 & 2\\ 3& 4 \end{bmatrix}$ then det$(A^3-6A^2+5A+3I)=3$,"Let $A=\begin{bmatrix}
1 & 2\\ 
 3& 4
\end{bmatrix}$ then det $(A^3-6A^2+5A+3I)=3$ det $(A^3-6A^2+5A+3I)=$ det $((A^2-5A-2I)(A-I)+2A+I)= $ det $(2A+I)=3$ , Since a matrix satisfies its characteristic polynomial. Is this right?","['matrices', 'determinant', 'linear-algebra', 'cayley-hamilton']"
3274790,Notation for element-wise multiplication of vector and matrix columns,"What is a clear and concise notation for the element wise multiplication (Hadamard product) of a column vector $v$ and each column of a matrix $F$ . What I want to achieve it this: $$
v\odot F=
\begin{bmatrix}
v_1\\ 
v_2 \\ 
v_3
\end{bmatrix} \odot 
\begin{bmatrix}
f_{1,1} & f_{1,2}  & f_{1,3}\\ 
f_{2,1} & f_{2,2}  & f_{2,3}\\
f_{3,1} & f_{3,2}  & f_{3,3}
\end{bmatrix} =
\begin{bmatrix}
v_1f_{1,1} & v_1f_{1,2}  & v_1f_{1,3}\\ 
v_2f_{2,1} & v_2f_{2,2}  & v_2f_{2,3}\\
v_3f_{3,1} & v_3f_{3,2}  & v_3f_{3,3}
\end{bmatrix}
$$ My question is essentially the same as this one , but I don't think the answer there actually answers the question and I don't have enough reputation to comment.","['matrices', 'notation', 'vectors']"
3274815,Writing a matrix as a product of two matrices,"Consider the matrix $$ A = \begin{pmatrix}
0 & y & -x\\
y & y^2 & -xy\\
-x & -xy & x^2 
\end{pmatrix}. $$ Is it possible to find matrices $X = X(x)$ and $Y=Y(y)$ such that $A = XY$ (or $A = YX$ )? A possibly unrelated observation of mine is that if we consider the vector $v = \begin{pmatrix}y\\-x\end{pmatrix}$ , then we can write $A$ in block form as $$ A = \begin{pmatrix}
0 & v^t\\
v & vv^t
\end{pmatrix}, $$ which allows us to write $$ A = \begin{pmatrix}
1 & 1\\
0 & v
\end{pmatrix}\cdot
\begin{pmatrix}
-1 & 0\\
1 & v^t
\end{pmatrix}, $$ but this is not really what I want since now the factors depend on both $x$ and $y$ . EDIT: As suggested in the comments, setting $z = -x$ yields $$ A = \begin{pmatrix}
0 & y & z\\
y & y^2 & yz\\
z & yz & z^2 
\end{pmatrix}. $$","['matrices', 'matrix-decomposition']"
3274831,Does $C_c(X)$ separate points in $X$ when $X$ is a Banach space?,"Suppose that $X$ is a separable, infinite dimensional Banach space. We say that a set of functions $\{f_\alpha\}_{\alpha \in A}$ separates points in $X$ if for every $x,y \in X$ , there is an $\alpha$ such that $f_\alpha(x) \neq f_\alpha(y)$ . Is it the case that $C_c(X)$ separates points in $X$ ? I have made some attempts to construct functions in $C_c(X)$ that separate distinct points $x,y$ in $X$ using the characterisation as compact subsets of $X$ as exactly the closed, bounded and flat subsets (where $K$ is flat if for every $\varepsilon > 0$ there is a finite dimensional subspace $F$ of $X$ such that $K \subseteq F + B(0,\varepsilon)$ ) but these attempts ultimately didn't get anywhere. If it is helpful, I am really interested in the case where $X$ is a separable subspace of a Besov space $B_{\infty,\infty}^\alpha$ so would be happy with an answer using any other properties of that space.","['general-topology', 'besov-space', 'functional-analysis', 'separable-spaces']"
3274867,Series of product of Bessel functions,The Christoffel-Darboux formula applied to Bessel functions states that $$\sum\limits_{j=0}^{+\infty}J_{j+n}(t)J_{j+m}(t)=\frac{t}{2(m-n)}\left(J_{m-1}(t)J_n(t)-J_m(t)J_{n-1}(t) \right)$$ See for instance Sum of Bessel functions Is there a similar simplification for the following sum ? $$\mathcal{I}=\sum\limits_{j=0}^{+\infty}J_{2j+n}(t)J_{2j+m}(t)$$ The sum is taken over all even integers. The best I could find is this series which is close http://functions.wolfram.com/Bessel-TypeFunctions/BesselJ/23/01/0016/ but there is no reference or proof of this identity.,"['bessel-functions', 'sequences-and-series']"
3274887,Tensor product of holomorphic functions and density,"Let $\Omega_1, \Omega_2$ be two open subsets of $\mathbb{C}.$ Is the image of $$\Phi : \mathcal{O}(\Omega_1) \times \mathcal{O}(\Omega_2) \to \mathcal{O}(\Omega_1 \times \Omega_2), (f,g)\mapsto ((z,w) \mapsto f(z)g(w))$$ dense in $\mathcal{O}(\Omega_1 \times \Omega_2)$ ? (Here the topology is the uniform convergence on compact subsets.) I know the result for test functions but I wonder if it is true for holomorphic functions. Maybe with some extra-conditions on the open subsets ? Thanks for any help/suggestion.","['complex-analysis', 'functional-analysis']"
3274908,Is Lipschitz space finite dimensional?,"Let $X=C([a,b])$ equipped with the norm $\Vert.\Vert_{\infty}$ . The closed subspace $F$ of $\alpha$ -Holder continuous ( $0\lt\alpha\le1)$ functions $F\subset X$ is finite dimensional because if I take a closed unit ball in it, the ball is compact (using Ascoli-Arzelà). What can we say about Lipschitz continuous functions space? Can we argue this way and conclude that it is finite dimensional?","['arzela-ascoli', 'lipschitz-functions', 'continuity', 'functional-analysis', 'compactness']"
3274924,Line bundle defined by exceptional divisor; $\mathcal O(E) = \pi^*\mathcal O(-1)$,"In Huybrechts book (Cor 2.5.6), it is shown: Let $X=\mathbb C^{n}$ and $\hat X$ its blow-up at $0$ . Then locally $\mathcal O(E) = \pi^*\mathcal O(-1)$ , where $\pi: \hat X \to \mathbb P^{n-1}$ . I have trouble understanding the proof: Its clear, that $\bigcup_{(\ell,z)\in \hat X} \ell$ is a line
bundle. But why is it isomorphic to $\mathcal O(E)$ ? Why does the section $t(\ell,z)=((\ell,z),z)$ vanish with
multiplicity $1$ ? Why does 2. imply $\mathcal O(E) = \pi^*\mathcal O(-1)$ ? I think 2. is simply because the function $z$ vanishes with multiplicity $1$ at $0$ , but for the rest I have no clue.","['complex-geometry', 'blowup', 'differential-geometry']"
3274925,"How to determine whether $\Bbb P ( B_{t_1} \in [x - c , x + c ], \ldots , B_{t_n} \in [x -c , x + c ])$ is decreasing in $x$?","Let $\phi_t (z) := \frac{1}{\sqrt{2\pi t}} e^{-\frac {z^2} {2t}}$ . By intuition $\omega : [0,\infty ) \to [0,1]$ \begin{align}
\omega (x) &:= \Bbb P ( B_{t_1} \in [x - c , x + c ], \ldots , B_{t_n} \in [x -c , x + c ])\\ &=\int_{x-c}^{x+c} \phi_{t_1} (y_1) \int_{x-c}^{x+c} \phi_{t_2-t_1} (y_2 - y_1) \ldots \int_{x-c}^{x+c} \phi_{t_n -t_{n-1}} (y_n - y_{n-1}) \text d y_n \ldots\text d y_1
\end{align} should be decreasing in $x$ . For $n=1$ this is easily done by derivating in $x$ . Does anyone see a better way for this case here?","['integration', 'derivatives', 'normal-distribution', 'probability']"
3274953,Let $f : \mathbb{R}^{2} \to \mathbb{R}$ be of class $C^{1}$. Show that $f$ not is injective. [duplicate],"This question already has answers here : Show that no application $f: \mathbb{R}^2 \rightarrow \mathbb{R}$, of $C^k$ class, $k \geq 1$ can be injective [duplicate] (3 answers) Closed 5 years ago . Let $f : \mathbb{R}^{2} \to \mathbb{R}$ be of class $C^{1}$ . Show that $f$ not is injective. Well, I know that $f$ is injective when $f(x) = f(y)$ implies $x = y$ . Since $f$ is of class $C^{1}$ then $f$ is differentiable in $\mathbb{R}^{2}$ such that its derivative is continuous. I can not figure out the ideas. This question seems to suggest a counter example, but none is working. Thanks for the help!","['derivatives', 'analysis', 'real-analysis']"
3274961,Operator norm of semigroup operator,"Let $P_{t}$ be a self-adjoint operator such that $P_{t+s}=P_{t}P_{s}$ . I want to show that $$\|P_{t}\|_{1\to \infty}\leq \|P_{t/2}\|_{1\to 2}\|P_{t/2}\|_{2\to \infty}.$$ For that, I am trying to prove that $$\|P_{t}f\|_{\infty}\leq \|P_{t/2}\|_{1\to 2}\|P_{t/2}\|_{2\to \infty}\|f\|_{1}$$ using that $$\|P_{t}f\|_{\infty}=\sup_{g}\frac{(P_{t}f, g)}{\|g\|_{1}}=\sup_{g}\frac{(P_{t/2}f, P_{t/2}g)}{\|g\|_{1}},$$ but then I am stuck. Can someone help?","['operator-theory', 'functional-analysis']"
3274993,Limit of integral over iterated image tending to $0$,"Let $f:\mathbb{R}^m\to\mathbb{R}^m$ be a difeomorphism such that $f(B)\subset B$ , where $B$ is the unit closed ball and $|\det f'(x) |<1,\,\forall x \in B$ . Then, if $g:B\to\mathbb{R}$ is any continuous function, show that: $$\lim_{n\to \infty}\int_{f^n(B)}g(x)dx=0$$ I'm attempting to use the change of variables formula, but I'm having trouble since we dont have that $f$ is $C^1$ and thus we can't guarantee $|\det f'(x) |$ attains maximum, say $\lambda<1$ ... That is, we only have that: $$|\det (f^{n})'(x) |=|\det f'(f^{n-1}(x)) |\dots|\det f'(x) |<1$$ So that $\int_{f^n(B)}g(x)dx = \int_B g\circ f^n(x)|\det (f^{n})'|dx<\int_B g\circ f^n(x) dx$ ...Where do I go from here?","['integration', 'volume', 'multivariable-calculus', 'calculus', 'riemann-integration']"
3275005,Find $\int_{0}^{\frac{r}{2}} {\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}^{-1}} \ \text{d}p$,"Now also asked on MathOverflow and answered affirmatively there . Let there be $n$ pairs of shoes in a box.
The the probability that from the $r \le n$ shoes I am taking out of the box there are exactly $p$ pairs is given by \begin{equation*}
        \mathbb{P}_{n}^{(r)}(p)
        = \frac{\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}}.
\end{equation*} For $n = 15$ and $r \in \{6,8,10\}$ . The function (assuming the continuous factorial equivalents) looks like this: I am interested in finding the area under that curve, namely $$\int_{0}^{\frac{r}{2}} \frac{\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}} \ \text{d}p$$ According to numerical estimates in the comments I suspect that it converges to 1 for $n = r \to \infty$ . I consulted this question but could derive how that would help me. I also thought about writing the first product of binomial coefficients as $$
\binom{n}{n - p}\binom{n - p}{r - 2p}
$$ which is similar to the form $\binom{f(x)}{f(y)} \binom{f(y)}{f(x)}$ mentioned in this question .","['integration', 'combinatorics', 'probability']"
3275012,"On a pair of pants, complete geodesics do not cover the whole surface","I am reading a thesis by Jenya Sapir. In her thesis, she mentions that ""on a pair of pants, complete geodesics no longer cover the whole surface"". I could not figure out how can we come up with this claim but I knew that, when the length of each geodesic at the boundary of the surface is long enough, then this claim is true obviously. Further questions, whether this property holds when we consider any hyperbolic surface with boundary?
Thank you in advance!","['geometric-topology', 'hyperbolic-geometry', 'differential-geometry']"
3275017,Solve $x^7=e$ in a group,"Let $(G,\cdot)$ be a group having the property that $\exists a \in G$ such that $\forall x \in G$ , $ax=x^4a$ . Solve the equation $x^7=e$ . I started by observing that for $x=a$ we have that $a^2=a^5$ , so $a^3=e$ . Then I tried to left multiply the relation in the hypothesis by $x^3$ , but it didn't help and now I am stuck. EDIT: This is what the answer key says ""take $a=x^7$ to get that $x^8=x^{11} \implies x^3=e$ . Hence, $a=x^7=(x^3)^2 x=x \implies x=a$ , which satisfies $x^7=e$ "". To me, this seems blatantly wrong. Firstly, I don't think we can set $a$ to be equal to anything because we are only told that it exists, nothing more. Secondly, $a^7=a$ since $a^3=e$ . Could it be possible that this problem is wrong and the equation in fact has no solution?","['group-theory', 'abstract-algebra']"
3275021,$L^{p}$ is separable for second countable space,I showed that $L^{p}$ is seprable when $X$ is a topological space with countable base and $\mu$ a radon measure on $T$ . Do you think it's the right assumptions ? I mean does it exist a counter exemple when the basis of $T$ is not countable ? I wish you a very good day.,"['measure-theory', 'second-countable', 'separable-spaces', 'borel-measures']"
3275023,Etymology: Reduced Rings,"If I may request the knowledge of the community on a point of trivia again, I was wondering if anyone could explain to me the etymology of reduced rings , that is, rings with no non-zero nilpotent elements. In what sense is it actually reduced ? In what sense has a process of reduction from an earlier state of things taken place?","['ring-theory', 'abstract-algebra', 'terminology']"
3275042,proof that $\frac{a_{4n}-a_2}{a_{2n+1}}$ : integer,"I would appreciate if somebody could help me with the following problem: Q: How to proof? If $\{a_n\}$ satisfy $a_{1}=a$ , $a_2=b$ , $a_{n+2}=a_{n+1}+a_{n}$ ( $a,b$ : positive integers) then proof that $\frac{a_{4n}-a_2}{a_{2n+1}}$ : integer I try  start by mathematical induction but....,
find $f(n)=\frac{a_{4n}-a_2}{a_{2n+1}}$ $f(1)=1$ , $f(2)=4$ , $f(3)=11$ , $f(4)=29$ ,...",['sequences-and-series']
3275052,A proper subspace of a normed vector space has empty interior clarification,"So every proper subspace of a normed vector space has empty interior. I'm not asking for the proof, my problem is that this seems to me very strange. 
So if I have a normed vector space, in any proper subspace I can't take any ball inside the subspace? For example suppose we work on a set with finite measure, $[a,b]$ for example. Let's take $L^{P}$ spaces over $[a,b]$ . We know that now $L^{\infty}$ is included in $L^{1}$ . So $L^{\infty}$ is a proper subspace of $L^{1}$ . Now this means that $L^{\infty}$ is nowhere dense?","['lp-spaces', 'functional-analysis']"
3275077,Eigenvalues and Eigenvectors of Selfadjoint Operators,"I am trying to show the following: Let $H$ be a Hilbert space. Suppose that $\|Tx\| = \|T\|$ for some unit vector $x \in H$ and for some bounded self-adjoint operator T on H . Then x is an eigenvector for $T^2$ with corresponding eigenvalue $\|T\|^2\; (= \|T^2\|)$ . Moreover, either $Tx = \|T\| x$ or $Tx = \|T\| y$ , where $y = \|T\| x - Tx$ .","['operator-theory', 'linear-algebra', 'functional-analysis']"
3275081,Evaluate using Stokes' Theorem,"To evaluate $\oint_{C} -y^3dx+x^3dy+z^3dz,$ where $C$ is the intersection of cylinder $x^2 + y^2 =1$ and plane $x+y+z=1$ . The orientation of $C$ is counter-clockwise motion in the $xy$ plane. Now I have computed $\nabla \times\mathbf{F} = \left(0,0,3\left(x^2+y^2\right)\right).$ I am having difficulty finding out the curve $C$ of intersection and also I am confused about projection on the $xy$ plane. Should I take part inside $x+y=1 $ only or part between $x+y=1$ and $x^2+y^2=1?$","['integration', 'multivariable-calculus', 'vector-analysis']"
3275113,Alternative proofs for the higher product rule (differentiation),"Let $f,g$ be smooth functions. I'm looking for proofs for the formula $$
\left(\frac d {dx}\right)^n f(x)\cdot g(x) =
 \sum_{i=0}^n \binom{n}{ i} f^{(i)}(x)\cdot g^{(n-i)}(x) 
$$ , where $f^{(i)}$ denotes the $i$ -th derivation of $f$ . The classical proof uses induction, and runs analogue to the proof of the binomial theorem. It can be found here: Proof 1 The second proof that is easily possible is by creating a bijection between $$
\binom{\{1,..,n\}}{k} = \{M\subseteq \{1,..,n\}\mid |M| =k\}
$$ and the ways to create a single term $f^{(k)}(x)\cdot g^{(n-k)}(x)$ . The argument is roughly this: We can view each set $M\in \binom{\{1,..,n\}}{k} $ as list of all the times we derived $f$ instead of $g$ : Say e.g. $M =\{1,2,4\}\in \binom{\{1,..,4\}}{3}$ , i.e. especially $n=4, k=3$ . Then that 'traces' the path $\begin{align*}
 &f^{(0)}(x)\cdot g^{(0)}(x)\\
\to &f^{(1)}(x)\cdot g^{(0)}(x)\\
\to &f^{(2)}(x)\cdot g^{(0)}(x)\\
\to &f^{(2)}(x)\cdot g^{(1)}(x)\\
\to &f^{(3)}(x)\cdot g^{(1)}(x)
\end{align*}$ Each such path tracks one summand in the expanding of $\left(\frac d {dx}\right)^n f(x)\cdot g(x)$ if we don't simplify the terms (i.e. add up terms of the same type). One then has only to show that the paths are injective and surjective. Proof 3: We define $M:=\{f:\mathbb R \to \mathbb R \mid f \text{ smooth}\}$ . Using this set, we now define the polynomial ring $\mathbb R[M]$ . In other words, we look at the functions now as nothing more than formal objects, equipped with a commutative and associative addition. The idea is now this: Instead of looking at the product $f\cdot g$ , we look at formal pairs $(f,g)$ , which we interpret as a multiplication of its elements. On these we then define a differentiation, construct a recursion, and then solve it. First, we formalize the differentiation-operator to a function $\partial:\mathbb R[M]^2 \to \mathbb R[M]^2$ (we'll only formalize the parts of it that we need). For this, we define: $$
\partial_l:\mathbb R[M]^2\to \mathbb R[M]^2,\qquad (f^{(i)},g^{(j)})\mapsto 
(f^{(i+1)},g^{(j)})
\\
\partial_r: \mathbb R[M]^2\to \mathbb R[M]^2
,\qquad (f^{(i)},g^{(j)})\mapsto 
(f^{(i)},g^{(j+1)})
$$ I.e. $\partial_l$ is the differentiates the left element of the tuple, and $\partial_r$ the right element of the tuple. On the pairs $\mathbb R[M]^2$ we define a commutative & associate addition as well, which though can only be simplified if both summands are identical: $$
(f^{(i)},g^{(j)}) +(f^{(i)},g^{(j)}) = 2 (f^{(i)},g^{(j)})
\\
(f^{(i)},g^{(j+1)}) + (f^{(i)},g^{(j)}) = (f^{(i)},g^{(j+1)}) + (f^{(i)},g^{(j)})
$$ Now $\partial$ is simply: $$
\partial = \partial_l + \partial_r
$$ One can show, that $\partial$ is linear, and that $\partial_l,\partial_r,\partial$ all are commuting with each other. If we define $\partial^n$ as applying $\partial$ $n$ times, the original problem now is: $$
\partial^n (f,g) =   
 \sum_{i=0}^n \binom{n}{ i} \partial_l^i \partial_r^{n-i} (f,g)
$$ We can use the definition of $\partial$ to formulate the recursion: $$
\begin{align*}
\partial^n (f,g) &= \partial^{n-1} (\partial_l(f,g)+\partial_r(f,g)) = 
\\ &=
\partial_l\partial^{n-1}(f,g) + \partial_r\partial^{n-1}(f,g)
\\
&=(\partial_l + \partial_r)\partial^{n-1}(f,g)
\end{align*}
$$ This is equivalent to $$
\partial^n (f,g) -(\partial_l + \partial_r)\partial^{n-1}(f,g) = 0
$$ This leads to the closed formula of the generating function $\sum_{n\ge 0} a_n x^n$ : $$
\sum_{n\ge 0} a_n x^n = \frac{1}{1-(\partial_l + \partial_r)x}
$$ It is now easy to obtain $a_n = (\partial_l + \partial_r)^n (f,g)$ , which is what we wanted to show, albeit in a totally different notation. (This proof is still far from perfect, and any improvements/suggestions are welcome) What are other proofs to show the higher product rule?","['alternative-proof', 'derivatives']"
3275121,How to embed random walk into Brownian Motion (Donsker's Invariance Principle)?,"I am trying to understand the proof of Donsker's invariance principle: First some definitions
Let $X_1,X_2,...$ be i.i.d. real-valued random variables with mean 0 and variance 1. We define $S_0=0$ and $S_n= X_1+ ... + X_n$ for $n \geq 1$ . To get a process in continuous time, we interpolate linearly and define for all $t \geq 0$ $$
S_t = S_{[t]}+ (t-[t])(S_{[t]+1}- S_{[t]}).
$$ Then we define for all $t \geq 0$ $$
S^*_n(t)= \frac{S_{nt}}{n}.
$$ Let $C([0,1])$ be the space of real-valued continuous function defined on $[0,1]$ and endow space with the supremumnorm. Then $(S^*_n(t))_{0 \leq t \leq 1}$ can be seen as a random variable taking values in $C([0,1])$ . Now let $\mu_n$ be its law on that space of continuous functions and let $\mu$ be the law of Brownian motion on $C([0,1])$ . Then the following holds: Theorem (Donsker): The probability measure $\mu_n$ converges weakly to $\mu$ , i.e. for every $F: C([0,1]) \rightarrow \mathbb{R}$ bounded and continuous, $$
\int F d\mu_n \rightarrow \int F d\mu
$$ as $n \rightarrow \infty$ . The proof I saw in class, is very similar in spirit to the one that can be found here (Theorem 12, page 23). The idea is to start with a given Probability space $(\Omega, \mathcal{F},P)$ where a Brownian Motion $(B_t)_{t \geq 0}$ already exists and then embedd a random walk into the Brownian Motion. To do that, let $(\mathcal{F}_t)_{t \geq 0}$ be the filtration generated by Brownian motion, i.e. $\mathcal{F}_t := \sigma(B_s: 0 \leq s \leq t)$ . Then we define $\tau_0 := 0$ and for $i \geq 0$ we define inductively $$
\tau_{i+1}:= \inf \{ t > \tau_i : |B_t - B_{\tau_i}| = 1\}
$$ I could show that $(\tau_i)_{i \geq 0}$ is an increasing sequence of stopping times. And due to the fact that for a Brownian Motion we have $\limsup_{t \rightarrow \infty}B_t= \infty$ almost surely, there exists a set of probability 1 where for every $i \geq 0$ the stopping time $\tau_i$ is finite. Then it is claimed that due to the strong Markov property applied at time $\tau_i$ , the random vector $(\tau_{i+1}-\tau_i, B_{\tau_i +1}- B_{\tau_i})$ is independent of $\mathcal{F}_{\tau_i}$ (the stopped sigma-algebra at $\tau_i$ ) and distributed as $(\tau_1,B_{\tau_1})$ . This is the part I do not understand . The strong Markov property I know of is the following: Theorem (Strong Markov property) Let $T$ be a stopping time such that $P[T < \infty] > 0$ . For every $t \geq 0$ we put $$
B_t^{(T)} = \mathbb{1}_{\{T < \infty\}}(B_{t+T}-B_T).
$$ Then under $P[\cdot | T < \infty]$ the process $B^{(T)}$ is a Brownian Motion independent of $\mathcal{F}_T$ So the questions I have are the following: Why is $(\tau_{i+1}-\tau_i, B_{\tau_i +1}- B_{\tau_i})$ independent of $\mathcal{F}_{\tau_i}$ ? Why is $(\tau_{i+1}-\tau_i, B_{\tau_i +1}- B_{\tau_i})$ distributed as $(\tau_1, B_{\tau_1})$ ? Sorry for the long post, I wanted to include all the details. Thanks a lot in advance!","['probability-limit-theorems', 'stochastic-processes', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
3275151,Coefficient of Generating Function,Determine the coefficient of $~x^n~$ in: $$(x^2 + x^4 + x^6 + ... + x^{n-1})(x + x^3 + x^5 + ... + x^{n-2})$$ Where $~n~$ is an odd number. How to describe the possible combinations of coefficients that result in $~x^n~$ ?,"['integer-partitions', 'combinations', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
3275159,Useful theorems on eigenvalues of matrices summation,"Suppose we have $M\geq 3$ numbers of symmetric matrices $\mathbf{A}_1, \mathbf{A}_2, \cdots, \mathbf{A}_M \in \mathbb{R}^{n\times n}$ . Each of them has $n$ numbers of real eigenvalues: $$
\lambda_1^1\leq \lambda^1_2 \cdots\leq \lambda^1_n\\
\lambda_1^2\leq \lambda^2_2 \cdots\leq \lambda^2_n\\
\vdots\\
\lambda_1^M\leq \lambda^M_2 \cdots\leq \lambda^M_n,
$$ fortunately, we also have $\lambda^1_1>0$ and $\lambda^M_1>0$ ( $\mathbf{A}_1$ and $\mathbf{A}_M$ are positive definite). Then, we are interested in the eigenvalues of $$
\mathbf{S} = \mathbf{A}_1 + \mathbf{A}_2+ \cdots+ \mathbf{A}_M.
$$ I have questions: If I want $\lambda_\text{min}(\mathbf{S})$ to be positive, are there any sufficient and necessary conditions on the eigenvalues of $\mathbf{A}_1, \mathbf{A}_2, \cdots, \mathbf{A}_M$ ? (i.e. Find the lower bound of $\lambda_\text{min}(\mathbf{S})$ ) more soft question: are there any useful theorems for the analysis of this?","['eigenvalues-eigenvectors', 'vector-spaces', 'real-analysis', 'matrices', 'linear-algebra']"
3275191,Monomorphisms in the category of perfect groups,"Let P be the full subcategory of the category of groups ( Grp ) whose objects are the perfect groups, i.e. those groups for which every element is a product of commutators (but not necessarily itself a commutator). Then it is a well-known fact that P is a coreflective subcategory of Grp . Does there exist a monomorphism in P that is not an injective function? If so, is there a full characterization of the monomorphisms in P ? In the case of DivAb , the category of divisible abelian groups, one well-known example of a non-injective monomorphism is the quotient map $\mathbb{Q} \twoheadrightarrow \mathbb{Q}/\mathbb{Z}$ . In general, the monomorphisms in DivAb are exactly those for which the kernel in Ab , the category of all abelian groups, is reduced (i.e. has no nontrivial divisible subgroups). Dually, of course, there are also many categories with non-surjective epimorphisms, with one well-known example being the inclusion $\mathbb{Z} \hookrightarrow \mathbb{Q}$ in the category of rings.","['group-theory', 'category-theory']"
3275222,I need assistance trying to simplify a logic statement,The statement I am trying to simplify is: $\lnot(p\lor\lnot q)\to(p\to(p\land\lnot p))$ First thing I did was use the Material Implication Law resulting: $\lnot\lnot(p\lor\lnot q)\lor(\lnot p\lor(p\land\lnot p))$ $(p\lor\lnot q)\lor(\lnot p\lor(p\land\lnot p))$ Then I distributed the right side resulting in: $(p\lor\lnot q)\lor((\lnot p\lor p)\land(\lnot p\lor\lnot p))$ And since $(\lnot p\lor\lnot p)=\lnot p$ : $(p\lor\lnot q)\lor((\lnot p\lor p)\land\lnot p)$ And since $\lnot p\lor p=\top$ : $(p\lor\lnot q)\lor(\top\land\lnot p)$ Up to there is where I feel stucked and I am not sure if I did it correctly and would like appreciate some feedback if its correct or wrong and what can I do to solve it better. Thanks in advance!,"['logic', 'discrete-mathematics']"
3275289,Good test statistic,"If we have a hypothesis $H_0$ and alternative hypothesis $H_1$ , a test statistic $T$ and a data set $x_1, ..., x_n$ taken from some random sample $X_1, ..., X_n$ , we use $T(x_1, ..., x_n) = t$ to decide whether or not to reject $H_0$ . What I thought is, if we choose adequate $T$ , we can make the probability of observing an event at least as extreme as $t$ ( $P(T>t)$ , for example ), be low, and thus in favor of $H_1$ . So if we choose an appropriate $T$ we can deny $H_0$ . My question is: is this an easy job, is it reasonable to search for such $T$ and how can we say that a test statistic is efficient?","['statistics', 'hypothesis-testing']"
3275313,Looking for solutions of the following differential equation,"I obtained the following, apparently clean-looking differential equation, while solving a problem, but cannot find any efficient way to solve it analytically. The equation is of the form, $$[A - B\cos (q\phi)]y'' + \frac{qB}{2}\sin(q\phi)y' + [C + D\cos(q\phi)]y = 0$$ Where, $q$ is an integer, and $0 \lt \phi \lt 2\pi$ , and $y = y(\phi)$ . The only boundary condition I know would be, $y(0) = y(2\pi)$ . My first idea for simplifying this was to consider the function to be of the form, $y = G\psi$ , and substitute it, to remove the first-order derivative. Taking $F = [A-B\cos(q\phi)]$ , this results in $G = \frac{ln F}{4}$ and the modified differential equation looks like, $$[\frac{F\ddot{F} - \dot{F}^2}{4F} + \frac{\dot{F}^2}{8F} + (C + D\cos(q\phi))ln F]\psi + F\frac{lnF}{4}\ddot{\psi} =0$$ This isn't helpful. Any other ideas, how to tackle this equation? Hints or ideas are welcome. Also, if there is any link to existing literature on this type of equation, please share. I could'nt find any.",['ordinary-differential-equations']
3275316,What exactly is topology?,"So I was reading this , about the practical application of topology. I wanted to ask what exactly is in it---as a subject what is studied in this field. I have seen videos wherein they oversimplify tell us that in topology, you squeeze and stretch but don't cut, or how a donut and a mug is equivalent. (I think it must be like simplifying calculus and saying that it's just fancy addition.) How does it help in mathematics, because it is studied as a full fledged course, it must have its perks and used too.... [ Also considering that there are so many tags under this topic on SE ] ?? (I am still in high school so I don't have a lot of information, but I consider myself to be a curious math enthusiast)","['general-topology', 'soft-question']"
3275330,Evaluate $\int\limits_0^{1}\frac{\sqrt{1+x^2}}{1+x}dx$,"Evaluate: $I=\int\limits_0^1 \frac{\sqrt{1+x^2}}{1+x}dx$ My try: Let $x=\tan y$ then $dx=(1+\tan^{2} y)dy$ As for the integration limits: if $x=0$ then $y=0$ and if $x=1$ then $y=\frac{π}{4}$ So: $I=\int\limits_0^{\frac{π}{4}}\frac{1+\tan^{2} y}{(1+\tan y)\cos y}\,dy$ $I=\int\limits_0^{\frac{π}{4}}\frac{1}{\cos^{3} y+\cos^{2} y\sin y}\,dy$ But I don't know how to continue.","['integration', 'calculus', 'trigonometry']"
3275354,dimension of invertible sheaves quadric surface (Riemann-Roch),"On the quadric surface $xy = zw$ in $\mathbb{P}^3$ the divisor class group is isomorphic with $\mathbb{Z} \oplus \mathbb{Z}$ . I want to see what the dimension of $\mathcal{L}(D)$ is for a divisor $D$ . I have an idea about it, but I don't find any references about this. My idea is the following. Let $D$ be a divisor of type $(a,b)$ , thus given by the union $l^a \cup m^b$ for the lines $l = \mathbb{P}^1 \times P, m = Q \times \mathbb{P}^1$ for some points $P,Q \in \mathbb{P}^1$ . Then $\mathcal{L}(D)$ consists of all rational functions $f$ on $\mathbb{P}^1 \times \mathbb{P}^1$ such that $(f) \geq -a l - bm$ . Let the coordinates on $\mathbb{P}^1 \times \mathbb{P}^1$ be given by $(x_0,x_1) \times (y_0,y_1)$ . Then the space $\mathcal{L}(D)$ is generated by all rational functions of the form $F/x_0^a + G/y_0^b$ for $F(x_0,x_1),G(y_0,Y-1$ homogeneous of degree $a$ and $b$ , thus $l(D) = \dim_k \mathcal{L}(D) = \binom{a+1}{1} \binom{b+1}{1} = (a+1)(b+1)$ if $a \geq 0, b \geq 0$ and $l(D) = 0$ if $a < 0$ or $b< 0$ . Then $K-D$ is of type $(-2-a,-2-b)$ and thus $l(K-D) = (-1-a)(-1-b) = (a+1)(b+1)$ if $a \leq -1, b \leq - 1$ and $l(K-D) = 0$ if $a > -1$ or $b > -1$ .
Does anyone with more background about this can confirm this or give a reference where to look? 
Thank you!",['algebraic-geometry']
3275356,Evaluate $\frac{9}{1!}+\frac{19}{2!}+\frac{35}{3!}+\frac{57}{4!}+\frac{85}{5!}+......$,"Prove that $$\frac{9}{1!}+\frac{19}{2!}+\frac{35}{3!}+\frac{57}{4!}+\frac{85}{5!}+......=12e-5$$ $$
e=1+\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+\frac{1}{4!}+\frac{1}{5!}+......
$$ I have no clue of where to start and I am not able to find the general expression of the nth term.","['power-series', 'sequences-and-series']"
3275385,"A ""proof"" for $0=1$ by integrating $\int \frac{dx}{x\ln x}$ by parts [duplicate]","This question already has answers here : Fallacious proof involving trigonometry (6 answers) Using Integration By Parts results in 0 = 1 (5 answers) $-1 = 0$ by integration by parts of $\tan(x)$ (3 answers) Closed 5 years ago . Let's consider the indefinite integral $$\int \frac{dx}{x\ln x}.$$ We will compute it by integrating by parts: $$\int \frac{dx}{x\ln x}=\int (\ln x)'\frac{dx}{\ln x}=1+\int \frac{dx}{x\ln x}.$$ Hence, $0=1$ . The question is : is there anything wrong in these computations? Note: I came across this example while reading a book on counterexamples in real analysis. I thought that the people here would find this funny, especially because the error is not so obvious to everyone.","['integration', 'fake-proofs', 'real-analysis', 'calculus', 'recreational-mathematics']"
3275432,Reflexive and Irreflexive,"I've seen an example that goes as follows: Let $R$ be an irreflexive, anti-symmetric, and transitive relation on a set $A$ . $A = \{1,2,3\}$ $R = \{(1,1)(1,2),(2,3)(1,3)\} $ How can the relation $R$ include $(1,1)$ ? Wouldn't that just make it neither reflexive or irreflexive. I thought for relations to hold they were required to hold for all $x \in A$ . Therefore it isn't irreflexive anymore because the condition $(x,x) \notin R$ is broken by $(1,1)$ .","['relations', 'discrete-mathematics']"
3275438,Solving a Fractional Equation Involving a Logarithm,"I may be being stupid right now, so I've come to Stack to see if this elementary algebra holds up. Suppose I have the equation $$\frac{\ln x}{(1+ \ln x)^2} = \frac{1}{4}$$ My chosen way to solve this would be to cross multiply and expand brackets, solve the quadratic and get the value of $x$ . However, a student I am helping got this by saying $\ln x = 1$ gives $x = \mathrm{e}$ and at $x= \mathrm{e}$ , the denominator $(1+ \ln x)^2 = 4$ . Hence $x= \mathrm{e}$ . Is this approach always correct or is it just luck here? In general if I have $\frac{f(x)}{g(x)} = \frac{m(x)}{n(x)}$ , can I solve it by finding the common solutions of $f(x) = m(x)$ and $g(x) = n(x)$ ? [Edit: clearly not because if I have $\frac{x}{x+2} = \frac{1}{x+3}$ , then $x= 1$ and $x+2 = x + 3$ don't give you anything..., so why does it work in this case?]",['algebra-precalculus']
3275468,Positive square rationals equidistant to 1,"Can there be two square rational numbers that are equidistant to $1$ i.e. there is a rational number $a \in [0,1]$ such that both $1-a$ and $1+a$ are square rationals?","['number-theory', 'diophantine-equations']"
3275502,The derivative of a unit vector with respect to itself,"I just saw an engineering paper which claims that $$\frac{\partial \hat{\mathbf{x}}}{\partial \hat{\mathbf{x}}} \stackrel{?}{=} -S(\hat{\mathbf{x}})^2 = I - \hat{\mathbf{x}}\hat{\mathbf{x}}^T$$ where $\hat{\mathbf{x}}$ is a unit vector, $S(\hat{\mathbf{x}})$ is the skew symmetric matrix packing of $\hat{\mathbf{x}}$ for use in the cross-product, and I've used the $\stackrel{?}{=}$ symbol to represent the equality I'm calling into question. Is this right? I would have guessed that $$\frac{\partial \hat{\mathbf{x}}}{\partial \hat{\mathbf{x}}} = I$$ just like it is for the vector $\mathbf{x}$ , but I'm not sure if the fact that $\hat{\mathbf{x}}$ is a constrained vector somehow explains the appearance of the $-\hat{\mathbf{x}}\hat{\mathbf{x}}^T$ term. Any confirmation or correction is greatly appreciated.","['multivariable-calculus', 'matrix-calculus', 'derivatives', 'projection-matrices']"
3275538,"Calculus, water poured into a cone: Why is the derivative non-linear?","If water is poured into a cone at a constant rate and if $\frac {dh}{dt}$ is the rate of change of the depth of the water, I understand that $\frac {dh}{dt}$ is decreasing. However, I don't understand why $\frac {dh}{dt}$ is non-linear. Why can't it be linear? I am NOT asking whether or not the height function is linear. Many are telling me that the derivative of height is not a constant so thus the height function is not linear, but this is not what I am asking. This is my mistake, because I had used $h(t)$ originally to denote the derivative of height which is what my book used. Rather I am asking if $\frac {dh}{dt}$ is linear or not and why. It would be nice if someone could better explain what my book is telling me: At every instant the portion of the cone containing water is similar to the entire cone; the volume is proportional to the cube of the depth of the water. The rate of change of depth (the derivative) is therefore not linear.","['calculus', 'derivatives']"
3275539,"Given two positive numbers $x,\,y$ so that $32\,x^{6}+ 4\,y^{3}= 1$. Prove that $\frac{(2\,x^{2}+ y+ 3)^{5}}{3(x^{2}+ y^{2})- 3(x+ y)+ 2}\leqq 2048$ .","Given two positive numbers $x,\,y$ so that $32\,x^{6}+ 4\,y^{3}= 1$ . Prove that $$p(x)\equiv p= \frac{(2\,x^{2}+ y+ 3)^{5}}{3(x^{2}+ y^{2})- 3(x+ y)+ 2}\leqq 2048$$ My solution in VMF : (and I'm looking forward to seeing a nicer one(s), thanks for your interests !) $$32\,x^{6}+ 4\,y^{3}= 1\,\therefore\,(y- 2\,x^{2})\left ( x- \frac{1}{2} \right )\leqq 0,\,\left ( x- \frac{1}{2} \right )\left ( y- \frac{1}{2} \right )\leqq 0,\,{y}'= -\,\frac{16\,x^{5}}{y^{2}}$$ Thus, we have $${p}'(x)=$$ $$= \frac{{\left (\!(\!2 x^{2}+ y+ 3\!)^{5}\!\right )}'\{\!3(\!x^{2}+ y^{2}\!)- 3(x+ y)+ 2\!\}- {\left (\!3(\!x^{2}+ y^{2}\!)- 3(x+ y)+ 2\!\right )}'(\!2 x^{2}+ y+ 3\!)^{5}}{\left (\!3(\!x^{2}+ y^{2}\!)- 3(x+ y)+ 2\!\right )^{2}}=$$ $$\frac{5(\!2 x^{2}+ y+ 3\!)^{4}\left (\!4 x- \frac{16 y^{5}}{x^{2}}\!\right )\{\!3(\!x^{2}+ y^{2}\!)- 3(x+ y)+ 2\!\}- \left (\!6 x- 3- \frac{96 x^{5}}{y}+ \frac{48 x^{5}}{y^{2}}\!\right )(\!2 x^{2}+ y+ 3\!)^{5}}{\left (\!3(\!x^{2}+ y^{2}\!)- 3(x+ y)+ 2\!\right )^{2}}$$ $$= \frac{\left ( 20\,x(y- 2\,x^{2})(y+ 2\,x^{2})\{\!3(x^{2}+ y^{2})- 3(x+ y)+ 2\!\}- 3[x^{5}(16- 32\,y)+ y^{2}(2\,x- 1)] \right )}{y^{2}\left ( 3(x^{2}+ y^{2})- 3(x+ y)+ 2 \right )^{2}}$$ $$\times (2\,x^{2}+ y+ 3)^{4}$$ Using derivatives, the equation of the tangent line can be stated as follows: $$p(x)- p\left ( \frac{1}{2} \right )= {p}'(x)\left ( x- \frac{1}{2} \right )\leqq 0\,(\!easy\,to\,see\,immediately\,!\!)\,\therefore\,p(x)\leqq p\left ( \frac{1}{2} \right )\leqq 2048$$","['tangent-line', 'a.m.-g.m.-inequality', 'substitution', 'inequality', 'derivatives']"
3275549,Inner product space two subspaces proofing question,"The question is as follows: Let $V$ be an inner product space of dimension $n$ , and let $U$ and $W$ be two $m$ -dimensional subspaces of $V$ . Assume there is some nonzero vector $v$ in $U$ , such 
    that $v$ is orthogonal to $W$ . (that is $\langle v,w\rangle =0$ for all $w$ in $W$ ). 
    Prove that $w$ is orthogonal to $U$ for some nonzero $w$ in $W$ . So I got a hint that it helps to fix a basis $B$ and $A$ for $V$ and $W$ and write $v$ as a linear combination of it. Then
   explore what it means for $v$ to be perpendicular to every vector in $W$ . This is what I have done so far:
Let $B= \{b_1,...,b_m\}$ and $A = \{a_1,...,a_m\}$ be basis for $U$ and $W$ .
I found an $m\times m$ matrix $M = [\langle b_i,a_j\rangle]$ such that $\langle v,w \rangle = [w]_A M [v]_B = 0$ for any $w$ , so $[v]_B$ is in the nullspace of $M$ . From here, I don't know how to keep going. Can someone kindly suggest? Thanks, and sorry for the messy notation.","['inner-products', 'linear-algebra']"
3275574,"Given a positive number $t$, prove that $7>\frac{4t^{3}+56t^{2}+191t+188}{\sqrt{t^{2}+2t+8}\left (7\sqrt{t^{2}+2t+8}+2(6t-2+t^{2})\right )}$ .","Given a positive number $t$ , prove that $$7> \frac{4\,t^{3}+ 56\,t^{2}+ 191\,t+ 188}{\sqrt{t^{2}+ 2\,t+ 8}\left ( 7\sqrt{t^{2}+ 2\,t+ 8}+ 2(6\,t- 2+ t^{2}) \right )}$$ Original problem is: Given two positive numbers $x,\,y$ so that $x^{2}+ 2\,y^{2}= \frac{8}{3}$ . Prove that $$v(x)\equiv v= 7(x+ 2\,y)- 4\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}}\leqq 8$$ 1st solution: (with Cauchy-Schwarz) We need to prove $v(\!x\!)\leqq 7(x+ 2\,y)- (3 x+ 10\,y)= 4(x+ y)$ . Then $4(x+ y)\leqq 4\sqrt{\left ( 1+ \frac{1}{2} \right )(x^{2}+ 2\,y^{2})}= 8\,\therefore\,v(x)\leqq 8$ / q.e.d The 2rd solution is my one without C-S : $$x^{2}+ 2\,y^{2}= \frac{8}{3}\,\therefore\,(x- 2\,y)\left ( x- \frac{4}{3} \right )\geqq 0,\,2\,{y}'= -\,\frac{x}{y}$$ Thus, we have $${v}'(x)= 7(1+ 2\,{y}')- \frac{4(2\,x+ 2\,y+ 2\,x{y}'+ 16\,y{y}')}{2\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}}}=$$ $$= 7\left ( 1- \frac{x}{y} \right )- \frac{2\left ( 2\,x+ 2\,y- \frac{x^{2}}{y}- 8\,x \right )}{\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}}}= 7\left ( 2- \frac{x}{y} \right )+ \frac{2(\,6xy- 2\,y^{2}+ x^{2})}{y\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}}}- 7=$$ $$= \frac{1}{y}\left \{ -7(x- 2\,y)+ \frac{4(6\,xy- 2\,y^{2}+ x^{2})^{2}- 49\,y^{2}(x^{2}+ 2\,xy+ 8\,y^{2})^{2}}{\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}}\left ( 2(6\,xy- 2\,y^{2}+ x^{2})+ 7\,y\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}} \right )} \right \}=$$ $$= -\,\frac{x- 2\,y}{y}\left \{ \underbrace{7- \frac{4\,x^{3}+ 56\,x^{2}y+ 191\,xy^{2}+ 188\,y^{3}}{\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}}\left ( 2(6\,xy- 2\,y^{2}+ x^{2})+ 7\,y\sqrt{x^{2}+ 2\,xy+ 8\,y^{2}} \right )}}_{> 0\,(we\,need\,to\,prove\,that\,it\,holds\,!)} \right \}$$ Indeed, for $t= -\,2\,{y}'= \frac{x}{y}> 0$ , we have $$\frac{\mathrm{d} }{\mathrm{d} t}\left ( \underbrace{2(6\,t- 2+ t^{2})+ 7\sqrt{t^{2}+ 2\,t+ 8}}_{> 0\,\because\,its\,derivative\,is\,positve\,and\,t> 0} \right )= \frac{14(t+ 1)}{2\sqrt{t^{2}+ 2\,t+ 8}}+ 4(t+ 3)> 0$$ Or $$14(6 t- 2+ t^{2})\sqrt{t^{2}+ 2 t+ 8}> 4 t^{3}+ 56 t^{2}+ 191 t+ 188- 49(t^{2}+ 2 t+ 8)\,(\!original.problem\!)$$ My solution in VMF : (and I'm looking forward to seeing a nicer one(s), thanks for your interests !) For $0< t\leqq 2$ $$14(6\,t- 2+ t^{2})\sqrt{t^{2}+ 2\,t+ 8}\geqq 4\,t^{3}+ 241\,t^{2}+ 192\,t+ 188- 49(t^{2}+ 2\,t+ 8)>$$ $$> 4\,t^{3}+ 56\,t^{2}+ 191\,t+ 188- 49(t^{2}+ 2\,t+ 8)$$ For $t\geqq 2$ $$14(6\,t- 2+ t^{2})\sqrt{t^{2}+ 2\,t+ 8}\geqq 4\,t^{3}+ 56\,t^{2}+ 562\,t+ 188- 49(t^{2}+ 2\,t+ 8)>$$ $$> 4\,t^{3}+ 56\,t^{2}+ 191\,t+ 188- 49(t^{2}+ 2\,t+ 8)$$ Therefore $(x- 2\,y){v}'(x)\leqq 0\,\therefore\,\left ( x- \frac{4}{3} \right ){v}'(x)\leqq 0\,\therefore\,v(x)\leqq v\left ( \frac{4}{3} \right )= 8$ / q.e.d","['inequality', 'cauchy-schwarz-inequality', 'derivatives', 'tangent-line']"
3275579,The Similarity Matrix of graph Laplacian Matrix has different names. What's the difference between these names?,"The graph Laplacian is defined: $$L=D-W$$ Where $W$ is the Similarity Matrix of the graph and $D$ is a diagonal matrix whose entries are column sums of $W$ (or row sums, by symmetry of $W$ ). $W$ has multiple names: the similarity matrix the weight matrix the affinity matrix the adjacency matrix  etc. Are these names equivalent? Or are there subtle differences in their use? References: Graph Regularized Nonnegative Matrix Factorization for Data Representation (p.3) The $W$ is called the weight matrix. Co-Clustering on Manifolds (p.2) The $W$ is called the affinity matrix.","['graph-theory', 'matrices', 'laplacian', 'graph-laplacian', 'manifolds']"
3275613,"Is it possible to upper bound ${\bf tr}(ABXBA)$ in terms of ${\bf tr}(AXA)$ for positive definite $A, B, X$?","Suppose $A, B, X$ are all real, symmetric and positive definite matrices. I want to upper bound ${\bf tr}(ABXBA)$ in terms of ${\bf tr}(AXA)$ ? Is it possble? My guess would be ${\bf tr}(ABXBA) \le \lambda_{\max}(BB) {\bf tr}(AXA)$ ? This is obviously true if $A, B$ commute. I am wondering whether it still holds if $A, B$ does not commute. I don't have any insight to prove this. But I tried a numerical simulation and it seems to be true. I would not trust numerical simulations as often they cannot capture good counterexamples. The bound I guessed is wrong as pointed out by user293121. But actually there is a very crude bound, i.e. \begin{align*}
{\bf tr}(ABXBA) \le \lambda_{\max}(A^2) {\bf tr}(BXB) \le \lambda_{\max}^2 (A) \lambda_{\max}^2 (B) {\bf tr}(X) \le \frac{\lambda_{\max}^2 (A) \lambda_{\max}^2 (B)}{\lambda_{\min}^2(A)} {\bf tr}(AXA).
\end{align*}","['matrices', 'inequality', 'linear-algebra', 'trace']"
3275622,Property of Veronese Embedding,"I am working on the following problem: Let $Y$ be the image of $\mathbb{P}^2$ in $\mathbb{P}^5$ by the Veronese embedding. Let $Z$ be a closed subvariety of $Y$ of dimension 1. Show that there exists a hypersurface $V$ of $ \mathbb{P}^5$ such that $V\cap Y = Z$ This is what I have done so far: As $Z$ is a subvariety of $Y$ and the Veronese embedding is an injection, I can see the preimage of $Z$ , noted $X$ , as a closed subvariety of $\mathbb{P}^2$ . This means that $X=V(f)$ where $f$ is an irreducible polynomial in $k[X_0,X_1,X_2]$ . Now, I have that $f^2 = g \in k[X_0^2,X_1^2,X_2^2,X_0X_1,X_0X_2,X_1X_2]$ . Then $V(f) \subset V(g)$ . I can factor $g$ into irreducible $g=g_1\dots g_n$ where each $g_i \in k[X_0^2,X_1^2,X_2^2,X_0X_1,X_0X_2,X_1X_2]$ . I know there should be one $g_i$ such that $Y\cap V(g_i)=Z$ . I don't know how to continue Is this reasoning right? I have found ""easier"" ways to proof this but I can't see them clearly (Example Why this property holds in a Veronese surface ) How do I know there is one $g_i$ with such property?","['algebraic-geometry', 'projective-geometry']"
3275767,Finding paths in a subdivision of $K_5$,"Some years ago (during my master's thesis), I studied a problem known as Kotzig's conjecture (however not this famous one , but the lesser known one on $k$ -paths in graphs). Anyway, there was no way to solve the problem, but I was able to distill one specific instance of a sub-problem, that seemed easy enough.
Still, I was not able to solve it. Here it is. Question. Take the $K_5$ (complete graph on $5$ vertices), and subdivide its edges by inserting new vertices (see the image below). There is only one condition: as you can see, I suggestively used different colors for the edges to divide the graph into an ""outer cycle"" and an ""inner cycle"". The condition now is, that both cycles must have the same number of vertices in it, i.e., both cycles must have the same length, say $k+1$ . Do there always exists two (not necessarily intersection-free) paths $P_1$ and $P_2$ of length $k$ , that start in the same vertex, and end in the same vertex? I made the experience, that given any specific instance of the problem, I had no trouble finding such a double- $k$ -path.
But I found it very hard (even impossible), to give a general construction of such one.
I had a lot of heuristics, but the conditions for their applications where complicated. The following image shows two 12-paths in the above subdivision with 13-cycles.","['graph-theory', 'combinatorics']"
3275770,"How to integrate $\int_{0}^{2\pi} \frac{1}{\sin^4x + \cos^4 x} \,dx$","So I followed the explanations made in this post and I got that: $$\int \frac{1}{\sin^4x + \cos^4 x} \,dx = \frac{\sqrt{2}}{2}\arctan\left(\frac{\sqrt{2}}{2}\tan\left(2x\right)\right) + C$$ But when I try to use the Leibniz-Newton formula and evaluate the integral from $0$ to $2\pi$ I get that it's $0$ because $\tan\left(2x\right)$ evaluates to $0$ at both $x=0$ and $x=2\pi$ . Is there another way to solve this integral and get the correct answer ( $2\pi\sqrt2$ )?","['integration', 'calculus', 'definite-integrals', 'real-analysis']"
3275793,Unions and Intersections,"Will I be correct in stating the following? The intersection of a collection of sets need not be a subset of its union. This is what I’m thinking while positing the above: $\bigcup \varnothing =\varnothing,$ but $\bigcap \varnothing$ is not even a set. But I think that my proposition will be false for a nonempty collection of sets, correct?",['elementary-set-theory']
3275811,exercise about some field extensions,"Let $E = \mathbb{C}(x, y, z)$ , $F = \mathbb{C}(x^2y, y^2z, z^2x)$ , $L$ the subfield of $E$ fixed by $S_3$ , and $K = F \cap L$ .
  Then, (1) Is $E/F$ Galois? And what is its Galois group $G$ ? (2) What is $[E:K]$ ? (3) Calculate the number of intermediate fields of $L/K$ . Here is what I have tried:
Since $E = F(x)$ and $x^9 \in F$ , for $\sigma_i : x \mapsto \zeta^i x$ , $G = \{ \sigma_i \}_{i=0, \dots, 8}$ (where $\zeta$ is a primitive 9th root of unity).
And $\operatorname{Gal}(E/K) = H := \left< S_3, G\right>$ (the group generated by these two groups).
But I don't understand what is this group, and its cardinality.","['field-theory', 'galois-theory', 'abstract-algebra']"
3275853,Is $A$ the $2 × 2$ identity matrix?,"If $A$ is a $2 × 2$ complex matrix that is invertible and diagonalizable, and such that $A$ and $A^2$ have the same characteristic polynomial, then $A$ is the $2 × 2$ identity matrix. My claim:
Eigenvalues of $A^2$ are square of eigenvalue of $A$ $$\lambda=\lambda^2$$ Since invertible $\lambda=1$ hence similar to identity matrix. But only matrix similar to identity is identity itself. But answer is given as FALSE. please explain me why i'm wrong","['eigenvalues-eigenvectors', 'fake-proofs', 'matrices', 'characteristic-polynomial', 'linear-algebra']"
3275870,Is there any way to avoid using Axiom of Choice in proving this theorem?,"I asked for proof verification of a proof about nest of intervals here , where I appeal to a theorem: Theorem: Let $a,b \in \mathbb R$ such that $a <b$ and $X := \{p \in \mathbb Q \mid a<p<b\}$ . Then $|X| = \aleph_0$ . Here is my attempt that appeals to Axiom of Choice : Lemma: For all $a,b \in \mathbb R$ such that $a <b$ , there exists $p \in \mathbb Q$ such that $a<p<b$ . Since $X \subseteq \mathbb Q$ , $|X| \le |\mathbb Q| = \aleph_0$ . Thus $|X| \le \aleph_0$ . Let $\mathcal I$ be the collection of all intervals in $\mathbb R$ . By Axiom of Choice and our lemma, there is a function $f:\mathcal I \to \mathbb Q$ such that $f(I) \in I$ for all $I \in \mathcal I$ . We define a function $g:\mathbb N \to X$ recursively by $g(0) = f((a,b))$ and $g(n+1) = f((g(0),b))$ . It is easy to verify that $g$ is injective and thus $\aleph_0 = |\mathbb N| \le |X|$ . As a result, $|X| = \aleph_0$ . My questions: Does my attempt contain logical gaps/errors? Is there any way to avoid using Axiom of Choice in proving my theorem?","['elementary-set-theory', 'axiom-of-choice', 'rational-numbers', 'real-analysis']"
3275963,Prove $\lim_{n\to \infty} \sum_{k=0}^{n} 2^{\frac{-kn}{k+n}}=2$,"I'm asked to prove $$\displaystyle\lim_{n\to \infty} \sum_{k=0}^{n} 2^{\frac{-kn}{k+n}}=2$$ Define $$b_{k,n} = \begin{cases}
0,& n \le k\\
2^{\frac{-kn}{k+n}},& n \ge k\\
\end{cases}$$ Our limit is equivalent to finding $\displaystyle\lim_{n\to \infty} \sum_{k=0}^{\infty} b_{k,n}$ . It's appealing to write $$\displaystyle\lim_{n\to \infty} \sum_{k=0}^{\infty} b_{k,n}=^?\sum_{k=0}^{\infty}\lim_{n\to \infty} b_{k,n}=\sum_{k=0}^{\infty} 2^{-k}=2$$ Question 1: Can we justify the swapping of sum and limit here? ( solved ) Question 2: Is there any alternative approach?","['alternative-proof', 'limits', 'sequences-and-series', 'real-analysis']"
3275966,"Guaranteed to guess two numbers in one from twelve lottery tickets, if falls $6$ balls with numbers from $1$ to $36$","During the drawing lottery falls six balls with numbers from $1$ to $36$ . The player buys the ticket and writes in it the numbers of six balls, which in his opinion will fall out during the drawing lottery. The player wants to buy several lottery tickets in order to be guaranteed to guess at least two numbers in at least one ticket. Will there be enough to buy $12$ lottery tickets? My work . The maximum number of numbers pairs in $12$ tickets is equal to $12 \binom{6}{2}=12 \cdot 15$ . During the drawing lottery falls $ \binom{6}{2}=15$ numbers pairs. The total number of numbers pairs is equal to $\binom{36}{2}=18 \cdot 35$ . I have no ideas of solving the problem.","['contest-math', 'combinatorics', 'lotteries']"
3276001,"Given a sequence of spaces $X \subset Y \subset Z$ with $X$ dense in $Z$, is $X$ dense in $Y$?","Let $X \subset Y \subset Z$ be three vector spaces. Suppose that $Y$ and $Z$ are complete metric spaces and that the injective map $Y \rightarrow Z$ is continuous (but not neccessarily open). Now suppose that $X$ is dense in $Z$ . Under what conditions is $X$ dense in $Y$ ? One condition that I came up with is that $Z$ is locally compact and the inclusion $Y \rightarrow Z$ is proper. In that case the following argument works. Let $y \in Y$ be arbitrary. Then there exists a sequence $\{x_{n}\}_{n \in \mathbb{N}} \in X$ which converges to $y$ with respect to the topology on $Z$ . Now let $U \subset Z$ be a pre-compact open neighbourhood of $y$ . For $n$ larger than $N$ , say, we know that $x_{n} \in U$ . By the assumption that the inclusion of $Y$ in $Z$ is proper, we know that $U \cap Y$ is pre-compact. The sequence $\{ x_{n} \}_{n > N}$ lies in $U \cap Y$ , and hence has a subsequence convergent with respect to the topology on $Y$ , which must converge to $y$ . Hence, for any $y \in Y$ there exists a sequence in $X$ which converges to $y$ , hence $X$ is dense in $Y$ . I am particularly interested in the case that $Z$ is an infinite dimensional Hilbert space and that $Y$ is a Fréchet space. (Also, I think that in general it's not true that $X$ is dense in $Y$ , but I haven't been able to come up with a counter-example, I'd be happy to know one if it exists.)","['complete-spaces', 'metric-spaces', 'hilbert-spaces', 'functional-analysis', 'general-topology']"
3276030,A simple compactness argument?,"I am still trying to figure out how to construct positive line bundles on the blow up of a Kähler manifold and thus a Kähler form. In Voisin's book (Hodge Theory and Complex Algebraic Geometry), it is written: I fail to see the logic of the argument. Assuming $X$ is compact, then $\lambda$ is bounded, so everywhere where $\tau^* \omega_X$ is positive, $C \tau^* \omega_X + \lambda$ is positive for some fixed constant $C>0$ . This is the case everywhere but on the tangent space of the fibers of $\tau$ . But there $\lambda$ is positive and $\tau^* \omega $ vanishes. Did I understand it right, that the argument is this simple? The additional complexity should then come from the assumption of $X$ not neccesarily being compact. But I could still apply the same argument as above replacing $X$ with $K$ , a compact nbhd of $Y$ where $\lambda$ is zero. The fact that I did not use compactness of $Y$ at all, indicates that
I did miss some subtlety. But I cannot figure out which one. Update: I can make the argument work if $\lambda$ is semi-positive on a neighbourhood of $\tau^{-1}(Y)$ . Does it work without this assumption? I don't think so.","['complex-geometry', 'proof-verification', 'compactness', 'differential-geometry']"
3276055,Derivative when $(\sqrt{x})^2$ is involved?,"Problem: If $f(x)=\frac{1}{x^2+1}$ and $g(x)=\sqrt{x}$ , then what is the derivative of $f(g(x))$ ? My book says the answer is $-(x+1)^{-2}$ . This answer seems flawed because $(\sqrt{x})^2$ is being simplified to $x$ when it should really be simplified to $|x|$ . If $(\sqrt{x})^2$ is simplified to $|x|$ then the answer I get is instead $-\frac{x}{|x|(|x|+1)^2}$ . But the book is probably right so is there something I'm overlooking?","['calculus', 'derivatives', 'radicals', 'absolute-value']"
3276096,What is the range of $g(x)=\cos^{2n+1}(x)+\sin^{2n+1}(x)?$,"We have that the range of $f(x)=\cos^{2n}(x)+\sin^{2n}(x),\; n\in \mathbb{N},\; n\geq 2,\;x\in \mathbb{R}$ is $$f(x)\in[2^{1-n},1]$$ since with $t=\cos^2(x)$ such that $0\le t\le 1$ , then $$t^n+(1-t)^n.$$ The stationary points are the roots of $$t^{n-1}-(1-t)^{n-1}=0$$ or $$t=\frac12.$$ What about the range of $g(x)=\cos^{2n+1}(x)+\sin^{2n+1}(x)?$ I have to find $b$ that $(b+1) f(x)-b g(x)=1$",['trigonometry']
3276101,"The Joy of Sets, by Keith Devlin. Is it a typography error or did I not understand?","I'm studying Axiomatic Set Theory with my reference book The Joy of Sets, by Keith Devlin. I'm reporting the text on p.25: Exercise 1.7.3. I have introduced the notation $\alpha + 1$ for the next ordinal after $\alpha$ . Let us denote by $\alpha + n$ the $n$ -th ordinal after $\alpha$ , where $n$ is any natural number. Show that if $\alpha$ is any ordinal, either $\alpha$ is a limit ordinal or else there is a limit ordinal $\beta$ and a natural number $n$ such that $\alpha = \beta + n$ I think that Prof. Devlin meant $\beta = \alpha +n$ , here. If I'm wrong, please help me understand.","['elementary-set-theory', 'ordinals']"
3276102,Does convergence for Cauchy sequence fail only when the limit is not in the domain?,"I am trying to understand how important is the distinction between Cauchy sequences and convergent sequences in normed vector spaces $E$ . So far I have only come across examples where the Cauchy sequence $\{x_n\}$ where $x_n\in E$ fails to converge only because the limit point is not in $E$ and an extension to $E$ typically by completion fixes the problem. For example: $$x_n\colon[0,1]\to\Bbb R, \quad t\mapsto \sum_{k=0}^n\frac{t^k}{k!},$$ where $E\triangleq \mathcal{P}([0,1])$ is the space of polynomial functions on $[0,1]$ with uniform convergence norm. I want to know if this is the only kind of failure mode for the convergence of a Cauchy sequence.","['convergence-divergence', 'normed-spaces', 'cauchy-sequences', 'real-analysis']"
3276180,Connection matrix for the Poincare disk,"This a problem from Loring Tu, 'Differential Geometry': Problem: The Poincare disk is the open unit disk $$ \mathbf{D} = \left\{ z = x + iy \in \mathbb{C} \mid | z| < 1 \right\} $$ in the complex plane with metric $$ \langle , \rangle_z = \frac{ 4 (dx \otimes dx + dy \otimes dy)}{ (1- |z|^2)^2}. $$ An orthonormal frame for $\mathbf{D}$ is $$e_1 = \frac{1}{2} (1 - |z|^2) \partial_x, \qquad e_2 = \frac{1}{2} (1 - |z|^2) \partial_y. $$ Find the connection matrix $ \omega = [\omega_j^{i}]$ relative to the orthonormal frame $e_1, e_2$ of the Riemannian connection $\nabla$ on the Poincare disk (Hint: first find the dual frame $\theta^{1}, \theta^{2}$ and then solve the first structural equation). Attempt: The dual frame satisfies $\theta^{i} (e_j ) = \delta_{j}^{i}$ . So that means $$ \theta^{1} = \frac{2}{ 1 - |z|^2} dx, \qquad \theta^{2} = \frac{2}{ 1 - |z|^2} dy. $$ We have zero torsion so the first structural equation reads $$ d \theta^{i} + \omega_j^{i} \wedge \theta^j = 0 $$ for $ i = 1, 2$ and summation is implied. I calculated $$ d \theta^1 = \partial_y \left( \frac{2}{ 1 - x^2 - y^2} \right) dy \wedge dx = \frac{ - 4y}{ (1 - x^2 - y^2)^2} dx \wedge dy $$ and $$ d \theta^2 = \frac{ 4 x}{ (1 - x^2 - y^2)^2} dx \wedge dy. $$ Since we have an orthonormal basis, I know that the connection matrix should be skew-symmetric. So this means $\omega^{1}_{1} = \omega_2^{2} = 0$ . Then I need to solve e.g. $$ d \theta^1 + \omega_2^{1} \wedge \theta^2 =0$$ for $\omega_2^{1}$ . Since I have a dual frame, I can always expand (right?) $$ \omega_2^{1} = a_1 \theta^1 + a_2 \theta^2 $$ for some coefficients $a_1$ and $a_2$ . So the above equation becomes $$ d\theta^1 + a_1 \theta^1 \wedge \theta^2 = 0. $$ In other words : $$ - \frac{4y}{ (1 - |z|^2)^2} dx \wedge dy + \frac{ 4 a_1}{ (1 - |z|^2)^2} dx \wedge dy = 0 $$ so that $a_1 = y$ . So $\omega_2^{1} = y \theta^1$ . Similarly, I found $$ \omega_1^{2} = x \theta^2. $$ But this doesn't seem correct to me since I should have $\omega_1^{2} = - \omega_2^{1}$ ? Where am I going wrong? Thanks for any help.","['connections', 'riemannian-geometry', 'differential-geometry']"
3276199,$\cos^2 \alpha + \cos^2 \beta + \cos^2 \gamma =1$ [duplicate],"This question already has answers here : ""Show"" that the direction cosines of a vector satisfies... (3 answers) Closed 5 years ago . Let be $\alpha, \beta, \gamma$ the angles between a generic direction in 3D and the axes $x,y,z$ , respectively. Prove that $\cos^2 \alpha + \cos^2 \beta + \cos^2 \gamma =1$ . PS: the 2D case is trivial. But I can't prove the 3D case.","['trigonometry', 'angle', '3d']"
3276249,Does any (right) triangle exist such that $a^3+b^3=c^3$?,"Does any right triangle exist such that $a^3+b^3=c^3$ ? Does any triangle exist such that $a^3+b^3=c^3$ ? I'm stuck on this problem; I tried applying the Pythagorean theorem in three dimensions, but in vain. Any tips?",['geometry']
3276251,"Fourier coefficients are exponentially bounded for a real analytic, periodic function","This question popped up in my exam today, I am curious for a solution.
Let $f:\mathbb{R}\to\mathbb{C}$ a real analytic, $2\pi$ -periodic function that is integrable on $[-\pi,\pi]$ . Its Fourier coefficients $c_k$ for $k\in\mathbb{Z}$ are given by $$
c_k=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)e^{ikx}dx
$$ Then there exists $\Gamma>0$ and $\eta>0$ such that $|c_k|\leq \Gamma e^{-\frac{1}{2}|k|\eta}$ for all $k\in\mathbb{Z}$ .","['complex-analysis', 'fourier-series', 'fourier-analysis', 'real-analysis']"
3276257,"Combinatorics Question, Bay Area Mathematics Olympiad 2016, Finding a General Formula","The corners of a fixed convex (but not necessarily regular) n-gon are labeled with distinct letters. If an
observer stands at a point in the plane of the polygon, but outside the polygon, they see the letters
in some order from left to right, and they spell a “word” (that is, a string of letters; it doesn’t need
to be a word in any language). Determine, as a formula in terms of $n$ , the maximum number of distinct $n$ -letter words which may be read in this manner from a single $n$ -gon. Do not count words in which some letter is missing because it is directly behind another letter from the viewer's position. //My attempt// First I notice that there is a bijection between number of words and {sides and diagonals}: On extending each edge to both its sides, outside the polygon, the plane is divided into $2n$ parts. Standing in each of these sides, gives a different word. Further, extending each diagonal to both its sides adds more division of the plane, equal to twice the number of diagonals of $n$ -gon, which is $$2\left(\binom{n}{2}-n\right)$$ Adding these two gives $$2\binom{n}{2}$$ I don't know, but this seems to work for triangles, quadrilaterals and maybe even pentagons. On the official site's solution page, two solutions are given: One is ugly and well, seems complicated. The other one is given to be: $$2\binom{n}{2}+2\binom{n}{4}$$ which my solution is closer to. Any help to get it would be appreciated. And, please point out if I've done something wrong.","['contest-math', 'combinatorics']"
3276259,Integral of a polynomial over a three-dimensional ball,"Let $f$ be a polynomial of total degree at most three in $(x,y,z)\in\mathbb{R}^3$ . Prove that $$\int\limits_{x^2+y^2+z^2\leq1}f(x,y,z)\,dx\,dy\,dz = \frac{4\pi
 f((0,0,0))}{3} + \frac{2\pi(\Delta f)((0,0,0))}{15}$$ Here $\Delta =
 \frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} +
 \frac{\partial^2}{\partial z^2}$ is the Laplacian operator on $\mathbb{R}^3$ . I even don't know how to approach this problem. Since the LHS of the equality is given by a volume integral, I thought about applying the divergence theorem, but wasn't able to do it. Any help?","['integration', 'multivariable-calculus', 'multiple-integral', 'analysis']"
3276290,How is a prime a product of primes? [singleton products],"In my discrete math my textbook is now covering prime factorization. It states that the Fundamental Theorem of Arithmetic states: Every positive integer other than 1 can be expressed uniquely as a product of prime numbers where the prime factors are written in non-decreasing order. My confusion is how can you write a prime number as a factor of prime numbers? Take  7 for instance. You cannot write 7 as the product of prime numbers, right? Since 1 is not a prime number, you cannot express 7 as 7 * 1. Is my misunderstanding something with the definition of ""product""? Can only one number be considered a product? Example: 7 can be written as the product of 7. (This doesn't sound right to me) Hopefully someone can help.","['prime-factorization', 'discrete-mathematics', 'prime-numbers']"
3276306,Find $\frac{1}{1.2.3.4}+\frac{4}{3.4.5.6}+\frac{9}{5.6.7.8}+\frac{16}{7.8.9.10}+\dots$,"Prove that $$
\frac{1}{1.2.3.4}+\frac{4}{3.4.5.6}+\frac{9}{5.6.7.8}+\frac{16}{7.8.9.10}+\dots=\frac{1}{6}\log2-\frac{1}{24}
$$ My Attempt $$
T_n=\frac{n^2(2n-2)!}{(2n+2)!}=\frac{n^2}{(2n+2)(2n+1)(2n)(2n-1)}\\
=\frac{1}{24}\Big[\frac{-2}{n+1}+\frac{3}{2n+1}+\frac{2}{2n-1}\Big]\\
$$ $$
S=\frac{1}{24}\Big[{-2}\big[\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\dots\big]+{3}\big[\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\dots\big]+{2}\big[1+\frac{1}{3}+\frac{1}{5}+\dots\big]\Big]\\
=\frac{1}{24}\Big[{2}\big[1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\dots\big]+{3}\big[\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\dots\big]-{2}\big[\frac{1}{3}+\frac{1}{5}+\dots\big]\Big]\\
=\frac{1}{24}\Big[2\log2+\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\dots\Big]=\frac{1}{12}\log 2+\frac{1}{24}\Big[\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\dots\Big]
$$ I dont think that the last term series converges so I think I'm stuck, and what does it mean? How do I proceed further and evaluate the infinite series ? Thanx to @Robert Z for the correction. Method 1 $$
S=\frac{1}{24}\Big[-2[\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\dots]+3[\frac{1}{3}+\frac{1}{5}+\dots]+[1+\frac{1}{3}+\frac{1}{5}+\dots]\Big]\\
=\frac{1}{24}\Big[\color{red}{-2\big[\frac{1}{3}+\frac{1}{5}+\dots\big]}+2\big[-\frac{1}{2}-\frac{1}{4}-\dots\big]+\color{red}{2\big[\frac{1}{3}+\frac{1}{5}+\dots\big]}+\big[\frac{1}{3}+\frac{1}{5}+\dots\big]+\big[1+\frac{1}{3}+\frac{1}{5}+\dots\big]\Big]\\
=\frac{1}{24}\Big[2(-\frac{1}{2}-\frac{1}{4}-\dots)+2(1+\frac{1}{3}+\frac{1}{5}+\dots)-1\Big]\\
=\frac{1}{24}[2\log2-1]\implies\boxed{S=\frac{\log2}{12}-\frac{1}{24}}
$$ Method 2 $$
S=\frac{1}{24}\Big[-2[\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\dots]+3[\frac{1}{3}+\frac{1}{5}+\dots]+[1+\frac{1}{3}+\frac{1}{5}+\dots]\Big]\\
=\frac{1}{24}\Big[-4[\frac{1}{4}+\frac{1}{6}+\frac{1}{8}+\dots]+4[1+\frac{1}{3}+\frac{1}{5}+\dots]-3\Big]\\
=\frac{1}{24}\Big[4[1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\dots]+4.\frac{1}{2}-3\Big]=\frac{1}{24}\Big[4[1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\dots]-1\Big]\\
=\frac{1}{24}[4\log2-1]\implies\boxed{S=\frac{\log2}{6}-\frac{1}{24}}
$$ Why do I seem to get a different solution in Method 1 ?. And what is so different in methods 1 and 2 ?","['power-series', 'sequences-and-series']"
3276332,Find closed formula without using induction for $\sum_{k=0}^n k^3$,"I'm studying for my exam in discrete mathematics and found the following problem on last years exam: Find a closed formula without using induction for $\sum_{k=0}^n k^3$ . I tried it by finding the Generating Function first: $F(x) = F_0 + \sum_{k=1}^nF_nx^n = \sum_{k=1}^n (F_{n-1}+n^3)x^n = \sum_{k=1}^n F_{n-1}x^n + n^3x^n = \sum_{k=0}^n F_n x^{n+1} + \sum_{k=1}^n n^3x^n = xF(x) + \sum_{k=1}^nn^3x^n$ The problem seems to be, that I lack an actual recursive definition of $\sum_{k=0}^n k^3$ which is, as far as I know, needed to find a generating function. Above, I pretty much used, that $X_n = X_{n-1}+n^3$ , but obviously, that ` s not enough. Because a recursive definition was always given in our lectures, I don't now other possibilities to solve this, except for finding the Generating Function with help of recursive definitions.","['closed-form', 'discrete-mathematics', 'generating-functions']"
3276351,Subset of knight's move in chess.,"A particle is allowed to move in the $\mathbb{Z}\times \mathbb{Z}$ grid by choosing any of the two jumps: 1) Move two units to right and one unit up 2) Move two units up and one unit to right. Let $P=(30,63)$ and $Q=(100,100)$ , if the particle starts at origin then? a) $P$ is reachable but not $Q$ . b) $Q$ is reachable but not $P$ . c) Both $P$ and $Q$ are reachable. d) Neither $P$ nor $Q$ is reachable. I could make out that the moves given are a subset of that of a knight's in chess. 
I think that it'd never be able to reach $(100,100)$ but I'm not sure of the reason. It has got to do something with the move of the knight but I cannot figure out what. I don't have a very good idea about chess, so I'd be glad if someone could answer elaborately.","['chessboard', 'combinatorics']"
