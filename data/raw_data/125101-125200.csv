question_id,title,body,tags
1894329,"Show that if $f'(a)<y<f'(b)$ for some $a<b$ in $I$ and $y\in \mathbb R$, then there exists $x\in I$ with $a<x<b$ and $f'(x)=y.$","Let $f:I\rightarrow \mathbb R$ be a differentiable function on the
  open interval $I$. Show that if $f'(a)<y<f'(b)$ for some $a<b$ in $I$
  and $y\in \mathbb R$, then there exists $x\in I$ with $a<x<b$ and
  $f'(x)=y.$ [Note that $f'$ is not assumed to be continuous.] I can't see why the question has specified $f'$. What I mean is, why can't we set $g(x)=f'(x)$? We then still have that $g:I\rightarrow \mathbb R$ and everything that applies to $f$ applies to $g$ (except that $g$ is not necessarily continuous). Are we not then trying to find $g(x)=y$ where $g(a)<y<g(b)$? Why did the question not simple ask this of $f$ and simply omit the detail that $f$ is differentiable? Hopefully this query makes some sense. Regardless I cannot do the question. We could simply apply the Intermediate Value Theorem if it were given that $f'$ is continuous, so I have thought about somehow showing that $f'$ is continuous but I don't think that's right. I have also tried splitting $f'$ up into continuous blocks and applied the Intermediate Value Theorem but that doesn't seem to be getting me anywhere. I am asking for help in understanding why it has to be a derivative but also would like some assistance on the question. Any help is appreciated, Thank you.","['real-analysis', 'functions']"
1894342,What is $\Bbb Z[X]/(aX+b)$ isomorphic to?,"Let $a,b$ be integers. I would to know what other ring is $R=\Bbb Z[X]/(aX+b)$ isomorphic to? If $a$ is a unit of $\Bbb Z$, then $R \cong \Bbb Z$.
If $a=0$, then $R \cong (\Bbb Z/b\Bbb Z)[X]$.
If $a=2,b=0$, then $R \cong \Bbb Z \oplus \Bbb F_2[X]$ as abelian groups at least, but I'm not sure as rings.
If $b$ is a multiple of $a$, we could use the Chinese remainder theorem, I think. But in general, for instance $\Bbb Z[X]/(2X+3)$ or $\Bbb Z[X]/(6X+4)$ I don't know how to manage. It would also be interesting to know what happens if we replace $\Bbb Z$ by any other commutative ring (and $a,b$ elements of that ring)... Thank you!","['abstract-algebra', 'ring-theory', 'quotient-spaces']"
1894356,Integral ${\large\int}_0^1\frac{dx}{(1+x^{\sqrt2})^{\sqrt2}}$,"Mathematica claims that
$${\large\int}_0^1\!\!\frac{dx}{(1+x^{\sqrt2})^{\sqrt2}}=\frac{\sqrt\pi}{2^{\sqrt2}\sqrt2}\cdot\frac{\Gamma\left(\frac1{\sqrt2}\right)}{\Gamma\left(\frac12+\frac1{\sqrt2}\right)},\tag{$\diamond$}$$
and it also confirms numerically. How can we prove $(\diamond)$? This result seems interesting, because no such nice answer seems to occur for other algebraic powers, except trivial cases, when the antiderivative is an elementary function, e.g. 
$${\large\int}\frac{dx}{(1+x^\alpha)^\alpha}=\\
\small\frac{x\left(x^\alpha+1\right)^{1-\alpha}}{18}\left[\vphantom{\large|}\left(15(\alpha-1)+4\left(5(\alpha+1)+\left(6\alpha+(\alpha-3)x^{2\alpha}+2(\alpha+2)x^\alpha-3\right)x^\alpha\right)x^\alpha\right)x^\alpha+18\right],$$
where $\alpha=3+\sqrt{10}$.","['closed-form', 'hypergeometric-function', 'integration', 'definite-integrals', 'gamma-function']"
1894367,What is the physical meaning behind the surface integral,"For example, I know that the physical meaning behind a standard, single integral is the area under the curve (with respect to the x or y axes). 
Likewise, the a line integral can be physically visualized as a ""wall"" with the base of the wall bordering along the line and the top bordering the surface of interest--the line integral is the area of that wall. A double integral is the volume under the surface of interest (with respect to the xy/xz/yz plane). What is the surface integral then? If the surface integral is the 3d analog of the line integral, is it then the volume under one surface with respect to another surface, instead of the xy/xz/yz plane? If anybody could help me physically visualize the surface integral, I would be extremely grateful!!","['multivariable-calculus', 'surface-integrals', 'intuition']"
1894378,"For any subset $S$ of $\mathbb{R}$, the distance function $d_s(x) = d(x,S)$ is continuous","Let $S \subset \mathbb R$ be any set, and define for any $x \in \mathbb R$ the distance between $x$ and the set $S$ by $d(x,S) = \inf\{|x-s| : s \in S\}$. Prove that the function $d_s: \mathbb R \to [0,+\infty)$ given by $d_s(x) = d(x,S)$, is Lipschitz continuous. Prove that if $S$ is compact then for every $x$ in $\mathbb R$, there is $s$ in $S$ such that
$|x-s| = d(x,S).$","['real-analysis', 'analysis']"
1894387,"A net $\varphi : [0, \omega_1) \to M$ on a metric space $M$ converges $\iff \varphi$ is eventually constant","I want to prove that If $M$ is a metric space, then a net $\varphi : [0, \omega_1) \to M$ converges if and only if $\varphi$ is eventually constant. ($[0, \omega_1)$ is the set of ordinals less than $\omega_1$, where $\omega_1$ is the first uncountable ordinal, with the order topology). $(\Leftarrow)$ is clear. My trouble is with $(\Rightarrow)$. Suppose that $\varphi \rightarrow x$. Let $U = \{ \alpha \in [0, \omega_1) \, \mid \varphi(\alpha) \neq x \}.$ If $U = \emptyset $ we are done, so assume $U \neq \emptyset$. Since $[0, \omega_1)$ is well ordered, there is a $\alpha_1 \in U$ such that $ \alpha_1 \leq \alpha \, \, \forall \alpha \in U.$ If $ U \setminus \alpha_1 = \emptyset$ we are done. If not, we repeat the procedure. It is clear that if $card(U) = n$ for some $n \in \omega$ then we only have a finite set of ordinals $\{\alpha_1, \ldots, \alpha_n\}=U$ so $\varphi$ is constant for $\alpha > \alpha_n.$ If $U$ is countably infinite, then $U = \{\alpha_n\}_{n \in \omega}$ and since $[0, \omega_1)$ is sequentially compact and the $\alpha_n$'s are countable ordinals  we obtain a convergent subsequence $\{\alpha_{n_k}\}$ of $U$ to some countable ordinal $\beta \in [0, \omega_1)$ $[\beta = \cup_{n_k \in \omega}\alpha_{n_k}???],$ hence $\varphi$ is constant for all $ \alpha > \beta.$ But what if $U$ is uncountable? Idea: If $U = [0, \omega_1),$ then since $\varphi \rightarrow x$, for every $n \in \omega$ there is $\alpha_n \in U$ such that $\alpha \geq \alpha_n \implies \varphi(\alpha) \in B_{\frac{1}{n}}(x).$ This is a countable sequence, so since $[0, \omega_1)$ is sequentially compact, there is a subsequence converging to a countable ordinal $\beta \in [0, \omega_1)$.
Clearly, $\beta$ satisfies that $\phi(\beta) \in B_{\frac{1}{n}}$(x) for every $n \in \omega.$ We can conclude that $\varphi(\beta)= x$ right? For if $\varphi(\beta) \neq x$, then taking $n$ such that $0 < \frac{1}{n} < d(x, \varphi(\beta)),$ we would have that $\varphi(\beta) \not \in B_{\frac{1}{n}}(x),$ contradicting the hypothesis. I feel pretty confident about this, but If someone sees an error in the argument, please comment. Thanks.","['nets', 'proof-verification', 'general-topology', 'metric-spaces', 'convergence-divergence']"
1894403,Number of subfields of splitting fields of $x^5-5$ over $\mathbb{Q}$.,"I want to find the number of subfields of splitting fields of $x^5-5$ over $\mathbb{Q}$ . By Eisenstein Criterion, $x^5-5$ is irreducible over $\mathbb{Q}.$ Then splitting field $K$ of $x^5-5$ is Galois extension of $\mathbb{Q}$ . Let $\zeta$ be primitive 5th root. Then Roots of $x^5-5$ consist of exactly $\zeta \root5\of5$ , $\zeta^2 \root5\of5$ , $\zeta^3 \root5\of5$ , $\zeta^4 \root5\of5$ , $\root5\of5$ .
So $$K=\mathbb{Q}(\zeta \root5\of5, \zeta^2 \root5\of5, \zeta^3 \root5\of5, \zeta^4 \root5\of5) = \mathbb{Q}(\zeta,\root5\of5)$$ Since $K=\mathbb{Q}(\zeta)\mathbb{Q}(\root5\of5)$ and $[\mathbb{Q}(\zeta):\mathbb{Q}] = 4 \mbox{ and } [\mathbb{Q}(\root5\of5):\mathbb{Q}]=5$ , $$|Gal(K/F)|=[K:F]=5\cdot 4=20.$$ Therefore $Gal(K/F)$ is group of order 20. So If I can find number of subgroups of $Gal(K/F)$ , then I can find number of subfields of the field. What shall I do?","['abstract-algebra', 'galois-theory']"
1894412,How many positive integers < 10^6 have sum of digits equal to 19,"$$ x_1 + x_2 + x_3 = 19 $$
$$ 0\leq x_i\leq9, x_1\geq1$$ In case of three digits the constraint on first digit being greater than one doesn't matter as there is no combinations of digit with a zero. 
So in this case it will be ${21\choose19}-{3}{11\choose9}=45$ In the following step we have $$x_1 + x_2 + x_3 + x_4 = 19$$ Similarly ${22\choose19}-{4}{12\choose9}=660$ but this time we are counting also all the strings with 0 in front so one option is to simply remove them by subtracting all the length 3 combinations that sum up to 19. And so we can proceed to the final answer. My question is - can this be done in some other way? If yes, then how?","['combinatorics', 'discrete-mathematics']"
1894450,How can I solve this equation with sine and $x^2$ without graphing it?,"I have this math problem: $f(x)=\sin{x}+x^2$ and I have to find the function's zeros. Obviously, I could graph this function or use CAS to learn the zeros are $x\approx-0.8767\text{ or } x=0$. However, how can I use pencil and paper to work out the zeros? I was able to get $x=0$ as an answer by the following
\begin{align}
0=&\sin x+x^2\\  
-\sin x=&x^2\\ 
\sin^2x=&x^4
\end{align} \begin{align}
0&=(\sin x+x^2)^2=\sin^2x+2x^2\sin x+x^4\\  
0&=x^4+2x^2\sin x+x^4=2x^4+2x^2\sin x\\  
0&=x^2(\sin x+x^2)\\  
x^2&=0\quad\text{or}\quad \sin x + x^2=0\\  
x&=0
\end{align} I do not know if my method resulting in 0 is a happy coincidence or not, since the second quantity is the same as the original function. I'm sorry if my high school-level knowledge of math offends you. Maybe it's because I'm in high school.",['algebra-precalculus']
1894526,what am i doing wrong here? calculating standard deviation,"I keep getting 2.02 for the standard deviation but the answer is 0.28?
  I'm not sure what I'm doing wrong, I even followed a step-by-step way
  to calculate it and I'm stilling get it wrong haha :^(",['statistics']
1894564,Under what circumstances can one divide by a variable?,"In light of recent responses to my other questions, I would like to know when it is mathematically acceptable to undergo division by a variable or a function of a variable, i.e., $x$ or $\cos x$. From what I sort of understand, it is only acceptable to divide by $x$ when $x$ is known not to be $0$. For all other cases, division cannot be undergone. In addition, I believe my Precalculus teacher said diving by $\cos x$ also should not occur because $\cos x$ can equal $0$ at $x=\frac{(2n-1)\pi}2$ where $n\in \mathbb{Z}$. How can I avoid dividing by $0$? Under what other circumstances could I accidentally divide by $0$?",['algebra-precalculus']
1894569,Suppose that a measure on $X \times Y$ is given. In what situations can one define a measure on $\{x\} \times Y$ to imitate conditional probability?,"Suppose that a measure on $X \times Y$ is given. In what situations can one define a measure on $\{x\} \times Y$ to imitate conditional probability? More generally, if a measure on $Z$ is given, and $C$ is a (nice, but maybe measure zero) subset of $Z$, then can one define the conditional probability measure, conditioned on lying in $C$. A reasonable litmus test for a general procedure should be: If $G$ is a compact group, and $\mu$ is the Haar measure, then if $H$ is a compact subgroup, the measure conditioned to being in $H$ should be the Haar measure of $H$. In ""geometric"" situations, like $\mathbb{R} \times \mathbb{R}$, one can imagine a procedure that takes the measure of tubular neighborhoods of subsets of $0 \times \mathbb{R}$ and renormalizes them appropriately. In the case of $G$ a topological group from before, assuming that $G$ has some metric structure, then given some $U \subset H$, one could define $\mu(U | H)$ as $\lim_{\epsilon \to 0} \frac{ \mu(U + B_{\epsilon}(e))} {\mu(B_{\epsilon(e)})}$, where $B_{\epsilon}(e)$ is an epsilon ball around the identity element of the group. Another test for the correct notion: In the case of $G$ and $H$ above, if $T$ is a (nice) set of transversals, then there ought to be a Fubini type theorem for integrating a function on $G$ in terms of integrating it over cosets of $H$ and then over $T$, using these kind of induced measures. (And something similarly for a bundles.) (Therefore, it should also be the case that this ""undoes"" the product measure construction.) Is there a general theory for this situation that someone can recommend or describe to me? -- Additional thoughts - given a family of measures $\rho_x$ on $Y$ parametrized by the measure space $(X, \Sigma, \mu)$, so that for an open $U$ in $X \times Y$, the function  $x \to \rho_x(U \cap \{x \} \times Y)$ is $\mu$-integrable, we can define a measure on $X \times Y$ by Fubini's theorem. Running over all such families, what is the image of this map into the space of all measures on $X \times Y$? (In particular, it should include the product measures, but should also be larger, since the measure on the fibers can vary in some fashion.)","['measure-theory', 'haar-measure']"
1894579,"Clarification on Ravi Vakil's AG notes, Exercise 13.3.H","Let me first write what this exercise is: [...] Suppose $X$ is a quasicompact quasiseparated scheme, $\mathscr{L}$ is an invertible sheaf on $X$ with section $s$, and $\mathscr{F}$ a quasicoherent sheaf on $X$. [...] Let $X_s$ be the open subset of $X$ where $s$ doesn't vanish. [...] Note that $\bigoplus_{n\geq 0}\Gamma(X, \mathscr{L}^{\otimes n})$ is a graded ring,  and we interpret $s$ as a degree one. Note also that $\bigoplus_{n\geq 0} \Gamma(X,\mathscr{F}\otimes_{\mathscr{O}_X}\mathscr{L}^{\otimes n})$ is a graded module over this ring. Describe a natural map
  $$\left[\left(\bigoplus_{n\geq 0}\Gamma(X,\mathscr{F}\otimes_{\mathscr{O}_X}\mathscr{L}^{\otimes n})\right)_s\:\right]_0\to \Gamma(X_s, \mathscr{F})$$
  and show that it is an isomorphism. I'm going to list the things I'm confused about (mostly trying to understand what this question means) and what I think might be the answer to each: ""Let $X_s$ be the open subset of $X$ where $s$ doesn't vanish."" The only way I can make sense of $X_s$ is as follows: There is a an affine open covering of $X$, $U_i$ with a sheaf isomorphism $\phi_i:\mathscr{L}|_{U_i}\simeq \mathscr{O}_{U_i}$. Define $\sigma_i:=\phi_i(U_i)(s|_{U_i})$. Vanishing or non-vanishing of $\sigma_i$ is meaningful so we define $X_s=\bigcup_{i\in I} D_i(\sigma_i)$ where $D_i(f)\subset U_i:=\mathrm{Spec} R_i$ is the distinguished open subset of affine scheme $U_i$ coming from $f\in R_i$. Is this indeed what $X_s$ means? The second issue is the grading structure on $\bigoplus_{n\geq 0} \Gamma(X,\mathscr{L}^{\otimes n})$ and $\bigoplus_{n\geq 0} \Gamma(X,\mathscr{F}\otimes\mathscr{L}^{\otimes n})$. The only kind of of multiplication I can think of is the tensor product. Thankfully if $\mathscr{G}, \mathscr{G}'$ are two $\mathscr{O}_X$-modules, then the sheafification morphism
$$
\eta: [\mathscr{G}\otimes \mathscr{G}']_\text{pre}\to \mathscr{G}\otimes \mathscr{G}'
$$
induces a natural map $\Gamma(X,\mathscr{G})\otimes_{\Gamma(X,\mathscr{O}_X)}\Gamma(X, \mathscr{G}')\to \Gamma(X, \mathscr{G}\otimes \mathscr{G}')$. So in our case we have maps
$$
\begin{aligned}
&\Gamma(X,\mathscr{L}^{\otimes n})\otimes_{\Gamma(X,\mathscr{O}_X)}\Gamma(X, \mathscr{L}^{\otimes m})\to \Gamma(X, \mathscr{L}^{\otimes (n+m)})\\
&\Gamma(X,\mathscr{L}^{\otimes n})\otimes_{\Gamma(X,\mathscr{O}_X)}\Gamma(X, \mathscr{F}\otimes \mathscr{L}^{\otimes m})\to \Gamma(X, \mathscr{F}\otimes\mathscr{L}^{\otimes (n+m)})
\end{aligned}
$$
This looks promising, for a good grading structure... But one problem: Are these maps necessarily injective/inclusion ? Of course I haven't even begun yet to actually solve this problem. But this question has already become too long, so I'll leave it at that.","['quasicoherent-sheaves', 'algebraic-geometry']"
1894593,The covariance of two squared normal variables,"Let $X\sim\mathcal N(μ_1,σ_1^2)$ and $Y\sim\mathcal N(μ_2,σ_2^2)$ and $\mathsf{Cov}(X,Y)=c$ How can we compute $\mathsf {Cov}(X^2,Y^2)$? I think the answer should be something like $c^2$ and I think the joint PDF is really not necessary here. I think the approach is using some independent standard normal random variables by variable changing. But I can't make it out. Thanks.","['normal-distribution', 'covariance', 'statistics', 'probability', 'random-variables']"
1894628,The large-$N$ limit of eigenvalues of matrices with non-diagonal elements scaling as $1/N$,"Define a series of matrices$$H_N=
\begin{bmatrix}
1&1/N&1/N&\cdots&1/N\\
1/N&2&1/N&\cdots&1/N\\
1/N&1/N&3&\cdots&1/N\\
\vdots&\vdots&\vdots&&\vdots\\
1/N&1/N&1/N&\cdots&N
\end{bmatrix}$$
My question is, when $N\to+\infty$, would the eigenvalues of $H$ be different from $\{1,\ldots,N\}$ ?
The answer is not obvious, as,  for the matrix series
$$G_N=\begin{bmatrix}
1&1/N&1/N&\cdots&1/N\\
1/N&1&1/N&\cdots&1/N\\
1/N&1/N&1&\cdots&1/N\\
\vdots&\vdots&\vdots&&\vdots\\
1/N&1/N&1/N&\cdots&1
\end{bmatrix}$$
You can verify that $G_N$ has an eigenvalue of $2$.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1894632,Show that $(k!)^2$ divides $(2k+2)!$,Show that $(k!)^2$ divides $(2k+2)!$ We have $\binom{2k+2}{k+2}=\dfrac{(2k+2)!}{k!(k+2)!}\in \Bbb Z$ say $=p$ Now $k!$ divides $(k+2)!\implies (k!)^2$ divides $(2k+2)!$. Is the arguement correct?Please help.,"['permutations', 'combinatorics', 'combinations', 'elementary-number-theory']"
1894684,What is the chance of rolling a specific number after a certain amount of rolls?,"Say I roll a $6$ sided dice and I want to roll a $6$. what is the probability that I will have rolled the number I want after $6$ rolls? I have been using this: $\displaystyle1-\left(1-\frac{1}{x}\right)^y$ where $x$ is the number of sides and $y$ is the amount of rolls, so it would be $\displaystyle1-\left(1-\frac{1}{6}\right)^6$ for rolling a specific number in $6$ rolls, which is $\approx66.5\%$ is this the correct way of calculating the probability of something like this, if not what is the proper way? i'm not really sure why that formula works(if it does) so some elaboration on that would be nice. sorry for lack of technical language thanks in advance",['probability']
1894688,"If $xy+yz+zx=1$ , show that $\dfrac x{1-x^2}+\dfrac y{1-y^2}+\dfrac z{1-z^2}=\dfrac{4xyz}{(1-x^2)(1-y^2)(1-z^2)}$. [duplicate]","This question already has answers here : If xy + yz + zx = 1, ........... (2 answers) Closed 7 years ago . It is to be solved using trigonometry. I tried taking $x$, $y$ and $z$ as $\sin(a)$, $\sin(b)$ and $\sin(c)$ respectively, but could get no further.","['algebra-precalculus', 'trigonometry']"
1894702,Cantor sets of positive measure,"The perfect set property theorem states that every uncountable Borel set contains a compact subset homeomorphic to Cantor set. Now suppose that $\mu$ is a regular Borel measure (on some measurable space) such that each set of cardinality smaller than continuum is of measure zero. By the definition of regularity, every Borel set of positive measure has a compact subset of positive measure. Is it possible to somehow combine the two results above by proving that every Borel set of positive measure contains a compact subset of positive measure which is homeomorphic to Cantor set?","['measure-theory', 'cantor-set']"
1894709,"If $\langle a,b \rangle=0$, then $a,b$ are perpendicular?","This is something that bothered me in my lectures on analytics geometry (because it was given without proof). I can see that $\langle (x,0),(0,y) \rangle=0$ easily, but what about when these two vectors are rotated? I believe I've been able to prove it for $2$-dimensions: $$\langle A,B \rangle=\langle (|A|\cos\theta ,|A| \sin \theta ),(|B|\cos\psi ,|B| \sin \psi)\rangle\\ = |A||B|cos \theta \cos \psi+|A||B|\cos \theta \cos \psi\\=|A||B|(\cos\theta \cos\psi+ \sin \theta \sin \psi)\\=|A||B|\cos (\theta - \psi)$$ Now $\cos( \theta - \psi) =0$ exactly when $ \theta - \psi=n\pi  +\cfrac{\pi}{2}, n\in \Bbb{Z}$. That is basically , when the difference of the two angles is $\cfrac{\pi}{2},\cfrac{3\pi}{2}$.","['analytic-geometry', 'proof-verification', 'geometry']"
1894734,Construct a matrix $M$ from $A$ and $B$ such that $\det(M)=\det(A)-\det(B)$,"Given two $n \times n$ symmetric matrices $A$ and $B$, is there a generic way to construct a larger block matrix $M$ such that $\det(M) = \det(A) - \det(B)$? A simple block expression is desired, in the sense that the block components of $M$ are constant matrices or obtained by solving matrix equations involving $A$ and $B$.  Constructions of $M$ involving short algebraic expressions for its components in terms of the components of $A$ and $B$ would also be interesting, but not something that expands to an exponential number of terms in the components of $A$ and $B$ like just sticking $\det(A)$ in as a term of $M$. If this is not possible in the general case, what restrictions can be placed on $A$ and $B$ to make this possible? The only case I know of is when the difference of $B$ and $A$ can be written as a product of a column vector $C$ and its transpose: $B-A = CC^T$. This allows us to construct a matrix $M$ such that: $$ M = \begin{bmatrix} A & C \\ C^T & 0 \end{bmatrix} $$
$$ \det(M) = \det(A) - \det(A + CC^T) = \det(A) - \det(B) $$ I'm curious if there is some way to construct an appropriate block matrix to make this possible for arbitrary symmetric matrices $A$ and $B$. The first comment to this question Find a matrix with determinant equals to $\det{(A)}\det{(D)}-\det{(B)}\det{(C)}$ suggests the answer is trivial by choosing
$$M = \begin{bmatrix} A & B \\ I & I \end{bmatrix}$$
but that doesn't appear to work when I tried some numerical examples.","['matrices', 'linear-algebra', 'determinant']"
1894802,A rigorous proof of L'Hôpital's rule (∞/∞ case for infinite limit),"I am looking for a rigorous proof of the following statement: Fix $f,g : \mathbb{R}\to\mathbb{R}$ with $\lim_{x\to 0^+} f(x) = \lim_{x\to 0^+} g(x) = \infty$. Assume that $f', g'$ are differentiable in the right neighbourhood of $0$ and $g'(x)\neq 0$ everywhere sufficiently close to $0$. Then, if $$\lim_{x\to 0^+} \frac{f'(x)}{g'(x)} = \infty\ ,$$ we also have $$\lim_{x\to 0^+} \frac{f(x)}{g(x)} = \infty\ .$$ All proofs I was able to find seem to either ignore that case or contain mistakes or omissions. One possible route would be to apply the ∞/∞ case of L'Hôpital for a finite limit to $g(x)/f(x)$ (which tends to $0$), but in order to show that $f(x)/g(x)$, one would need something stronger, nemaly that $g(x)/f(x)$ tends to $0^+$, which is not something any version of L'Hôpital's rule that I know of provides. In fact, what I would ideally like to have is a more ‘unified’ proof of the ∞/∞ case without all these case distinctions (for the 0/0 case, that is possible and quite easy), but I don't think such a proof exists. UPDATE: Okay, I must have had a momentary blackout. If both $f$ and $g$ tend to infinity, then of course $g(x)/f(x)$ must be positive in a righ neighbourhood of $0$. However, two interesting questions remain: Does the statement still hold if only one of $f$ and $g$ tends to infinity? For the case where the limit of $f'(x)/g'(x)$ is finite, only $g$ needs to tend to infinity, as shown e.g. in Walter Rudin's proof of L'Hôpital in ""Principles of Mathematical Analysis"". Is there some alternative ‘unifying’ approach that avoids all these case distinctions altogether?","['real-analysis', 'proof-explanation', 'limits']"
1894849,If $f'(z)$ exists does this mean that $f'(\bar{z})$ exists?,"Suppose we know that a complex function $f$ is differentiable in some region, $D$. Then how can we show that $f'(\bar{z})$ also exists? I tried using the definition of the derivative: $$f'(\bar{z}) = \lim _{h \rightarrow 0} \frac{f(\bar{z}+h)-f(\bar{z})}{h}$$ and then relating this to the limit for $f'(z)$ but I haven't gotten very far with that. How should I proceed?",['complex-analysis']
1894856,"Fourier series $\sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)^2} \cos \left(\pi \left(k+\frac{1}{2} \right)x \right)$ for $x \in (-1,1)$","What is the closed form for this Fourier series: $$f_2(x)=\sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)^2} \cos \left(\pi \left(k+\frac{1}{2} \right)x \right)$$ For $x \in (-1,1)$. The reason I'm asking is this. For $x \in (-1,1)$ we have: $$f_1(x)=\sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)} \cos \left(\pi \left(k+\frac{1}{2} \right)x \right)=const=\frac{\pi}{4}$$ $$f_3(x)=\sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)^3} \cos \left(\pi \left(k+\frac{1}{2} \right)x \right)=c (1-x^2)=\frac{\pi^3}{32} (1-x^2)$$ So we have a square wave for $f_1$ and parabolic wave for $f_3$. By the same logic I expected to have a linear (sawtooth) wave for $f_2$, but Wolfram Alpha gives a very smooth plot: This looks a lot like half a circle, but it's not $c \sqrt{1-x^2}$. For $x=0$ we have: $$f_2(0)=G$$ Where G is the Catalan constant.","['fourier-series', 'sequences-and-series']"
1894868,Is $\cos(x) \geq 1 - \frac{x^2}{2}$ for all $x$ in $R$?,I encountered this question: Is $\cos(x) \geq 1 - \frac{x^2}{2}$   for all $x$ in  $R$  ? I draw to myself the function graphs but i can't find the right way to answer this type of questions. Cosx function graph 1-x^2/2 function graph,"['inequality', 'limits', 'trigonometry', 'functions', 'calculus']"
1894913,looking for motivation in teaching algebra,"I am going to teach some grade 9 students about solving linear and quadratic equations. I am looking for a question from every day life (of a teenager) or a puzzle which is hard to solve without using algebra. There are of course loads out there in textbooks and the internet, but I haven't yet found one which is really intriguing and which could arouse the interest even of a student who has other things on his/her mind and who has a general dislike for school-mathematics. For example questions concerning the respective speeds, distances and time-periods of two vehicles with respect to each other are classic examples motivating linear equations, but they don't really seem to be relevant for real life (from the perspective of a teenager) nor are they particularly fascinating (at least for someone who isn't interested in mathematics anyway). I'd like to begin the subject with such a question and let the students work on it together for maybe half an hour or so (i.e. the question shouldn't be too easy to solve); hopefully this way they will see themselves how useful it can be to introduce variables. Any ideas?","['education', 'linear-algebra', 'soft-question']"
1894918,"what's the probability that in a building of 10 floors and 5 people in elevator, the elevator would reach exactly until the 5th floor and no higher?","the question goes like this:
""In a building of 10 floors, 5 people get inside an elevator on the entry floor. every one of them push independently a button of one of the 10 floors. what's the probability that the elevator would get exactly to the 5th floor and no higher?"" I thought of two ways to solve it, and each one gets me another result. so probably I do something wrong, would appreciate your help. first solution - let's choose the person that hits the 5th floor such that the elevator will reach this floor. $\binom{5}{1}$ options for that. for the rest, there're $5^4$ options to choose a floor. the probability space is $10^5$ for number of ways to choose floors (out of 10 floors) independently for 5 people. so the final result would be $\frac{\binom{5}{1} 5^4}{10^5}$ second solution - let's notice there're $5^5$ ways to hit buttons in elevator such that the elevator would get at the most to 5th floor, and $4^5$ ways to hit buttons in elevator such that the elevator would get at the most to 4th floor. so the number of ways the elevator would reach exactly the 5th floor is $5^5-4^5$ and then the result is $\frac{5^5-4^5}{10^5}$","['combinatorics', 'statistics', 'probability']"
1894943,Regarding the proof that similar matrices have the same characteristic polynomial,The proof is: $$|\lambda I-P^{-1}AP|=|P^{-1}(\lambda I)P-P^{-1}AP|=|P^{-1}((\lambda I)P-AP)|=|P^{-1}((\lambda I)-A)P)|=|P^{-1}|\cdot|((\lambda I)-A)|\cdot|P|=|\lambda I-A|$$ What I do not understand is why $|\lambda I-P^{-1}AP|=|P^{-1}(\lambda I)P-P^{-1}AP|$ why can we multiple $|\lambda I|=|P^{-1}(\lambda I)P|$?,['linear-algebra']
1894983,Inequality of skew-symmetric matrix,Let $A$ be a $n\times n$ skew-symmetric real matrix.Prove that $\forall v \in \mathbb{R^n}　\ \|(E-A)v\| \geq \|v \| $ where $\|v\|$ is the Euclid norm of $v$ and $E$ is the $n \times n$ identity matrix. I have no idea. How to prove this inequality? Many thanks.,"['matrices', 'inequality', 'linear-algebra']"
1894996,ordinary differential equation of third order using substitution,How one can solve ODE in the following form? $$y''' y +(y'')^{2} =0$$ It looks like some kind of substitution. I did try some substitution but they were useless. thanks in advance.,['ordinary-differential-equations']
1895060,A linear transformation preserving volume,"This is ex. from Munkers book: \
find a linear  transformation $h: \mathbb{R}^n \rightarrow \mathbb{R}^n$ that preserves volumes but is not an isometry. It's clear that $n$ should be greater than 1, but even in 
case $n=2$ I'm not able to provide an example.","['volume', 'linear-algebra']"
1895096,"Two limits involving integrals: $\lim_{\varepsilon\to 0^+}\left(\int_0^{1-\varepsilon}\frac{\ln (1-x)}{x\ln^p x}dx-f_p(\varepsilon)\right)$, $p=1,2$.","By applying the Taylor series expansion to $\ln x$, as $x \to 1$, one has the Laurent series expansion, 
$$
\frac1{\ln x}=-\frac1{1-x}+\frac{1}{2}+O\left(1-x\right)
$$ then clearly
$$
\begin{align}
&\lim_{\varepsilon \to 0^+} \int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln x}\:dx=\infty 
\\\\&\lim_{\varepsilon \to 0^+} \int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln^2 x}\:dx=-\infty.
\end{align}
$$ Thus I'm designing the following related limits. Question . Find $f_1(\varepsilon)$, $f_2(\varepsilon)$ and find a closed form of $c_1$, $c_2$ such that
  $$
\begin{align}
&\lim_{\varepsilon \to 0^+} \left(\int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln x}\:dx-f_1(\varepsilon)\right)=c_1
 \tag1
\\\\&
\lim_{\varepsilon \to 0^+} \left(\int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln^2 x}\:dx-f_2(\varepsilon)\right)=c_2. \tag2
\end{align}
$$ Edit . A complete answer is now given below.","['limits', 'calculus', 'improper-integrals', 'integration', 'definite-integrals']"
1895119,How many ways to reach $Nth$ number from starting point using any number steps between $1$ to $6$,"In a board game, dice can roll either $1, 2, 3, 4, 5$ or $6$. The board has $N$ number of space. Every time of dice roll randomly, pawn moves forward exactly to dice rolled a number. Now the problem is how many possible ways or combination of jump can be possible to reach start to end point of a board? For an example end point is 100: 1+2+6+...+1 = 100 -> 1 way
1+3+1+...+3 = 100 -> 2 ways
...
i+i+....+i  =  100 -> N ways Is there any algorithm of recursion?","['combinatorics', 'algorithms', 'recursion', 'recursive-algorithms']"
1895141,How to prove combinatorial identity $\frac{(n+1)n}{2} \cdot n! = \sum\limits_{k=0}^{n} (-1)^k \cdot \frac{n!}{k!\cdot(n-k)!} \cdot (n-k)^{n+1}$,"Today when I solve a counting problem using different methods I find the following (seemingly correct) combinatorial identity, but I can't find it on the Internet and I can't prove its correctness neither. But I have verified its correctness with positive integer $n$ within $[0, 1000]$ using a simple computer program. Anyone can give a proof to this identity (or any link to its proof)? $$\frac{(n+1)n}{2} \cdot n! = \sum\limits_{k=0}^{n} (-1)^k \cdot \frac{n!}{k!\cdot(n-k)!} \cdot (n-k)^{n+1}$$ And equivalently if you want, $$\frac{(n+1)n}{2} = \sum\limits_{k=0}^{n} (-1)^k \cdot \frac{1}{k!\cdot(n-k)!} \cdot (n-k)^{n+1}$$",['combinatorics']
1895147,What's the probability that space shuttle will fly?,"Ques. NASA is developing two top-secret space shuttles. One has two engines,
the other has four. All the engines are identical, and have the same probability of
failure. Each is designed to fly if at least half of its engines work. A visiting scientist
says, ""The four-engine shuttle is more reliable, isn't it?"" The NASA technician
replies that the probability of failure is top secret, but that in fact both shuttles
have the same probability of flying. The visitor then says, ""Aha! Never mind, now
I know both the probability an engine will fail and the probability that the shuttle
will fly."" How did he figure this out, and what are the two probabilities? Attempt: Let $x$ be the probability that an engine will work. Then the probability that an engine won't work is $1-x$. Space shuttle $1$ will fly when at least one engine will work= probability that one engine will work + probability that both engine will work Probability that space shuttle $1$ (with two engines) will fly $=x(1-x)+x^2$ Probability that space shuttle $2$ (with four engines) will fly $=x^2(1-x)^2+x^3(1-x)+x^4$ Now, we are given that both shuttles have same probability of flying  $\Rightarrow x(1-x)+x^2=x^2(1-x)^2+x^3(1-x)+x^4$ On solving we get $(x^2-x)(x^2+1)=0$ As $x$ should be real no. we get $x=0$ or $1$. Am I right ?",['probability']
1895187,Minimum and maximum with $1+\frac{a+x}{b+x}+\frac{a+x}{c+x}$,"Let $a,b,c\geq 1$ and $x,y,z\geq 0$. What are the minimum and maximum of
$$f(a,b,c,x,y,z)=\frac{1}{1+\frac{a+x}{b+x}+\frac{a+x}{c+x}}+\frac{1}{1+\frac{b+y}{a+y}+\frac{b+y}{c+y}}+\frac{1}{1+\frac{c+z}{a+z}+\frac{c+z}{b+z}}?$$ Since each term is no more than $1$, the maximum is not more than $3$. When $a=b=c$, $f(a,b,c,x,y,z)=1$.","['algebra-precalculus', 'inequality', 'optimization']"
1895196,Derive a UMP test,"Let $F$ and $G$ be two known absolutely continous c.d.f's on the real line with p.d.f's $f$ and $ g$. Assume we have a single observation $X$ drawn from the c.d.f:
$$\theta F(x)+(1-\theta)G(x),~~\theta\in(0,1)$$
Given $0<\theta_{0}<1$, how to derive a UMP test of size $\alpha$ for testing:
$$H_0:\theta\leq\theta_0~~vs.~~H_1:\theta>\theta_0$$
My thought was to find a LRT, or to use Karlin–Rubin theorem, but didn't see a way to work it out.","['statistics', 'probability', 'hypothesis-testing']"
1895204,Help with this trigonometry problem,"Prove the given identity. $$\left(\sin\frac {9\pi}{70}+ \sin\frac {29\pi}{70} - \sin\frac {31\pi}{70}\right) \left(\sin\frac {\pi}{70}-\sin\frac {11\pi}{70} - \sin\frac {19\pi}{70}\right) =\frac {\sqrt {5} -4}{4}$$ Please help, I could not gather enough ideas, even on how to get to the first step. I thought of using the transformation formula (from sum to product) but did not find a fruitful result. UPDATE 1.: $\left(-\frac{1 +\sqrt{5}}{8} + \frac{1}{8} \sqrt{14\left(5 - \sqrt{5} \right)}\right)\left(-\frac{ 1+ \sqrt{5}}{8} -\frac{1}{8} \sqrt{14 \left(5 -\sqrt{5} \right)}\right) $, I noticed that Alexis had got to this point.  Can anyone explain me how did he get here, with calculations. Please help. Thanks in Advance.",['trigonometry']
1895206,"There exists a lattice point $(a,b)$ whose distance from every *visible* point is greater than $n$.","Question - A lattice point $(x,y)\in\mathbb{Z}^2$ is called visible if $gcd(x,y)=1$. Prove that given a positive integer $n$, there exists a lattice point $(a,b)$ whose distance from every visible point is greater than $n$. I am totally nowhere near progress on this. I was thinking of trying pigeon hole principle, but cant find any appropriate candidate pigeons. Please give any hints to start.","['number-theory', 'contest-math', 'elementary-number-theory']"
1895225,"Explanation of a deduction in ""On $L^{\infty}$ norms of holomorphic cusp forms""","I am reading the article On $L^{\infty}$ norms of holomorphic cusp forms . I am particularly interested to the following : I don't see how we can get from
$$ |y^k f(z)|     \ll \frac{y^k k^\epsilon(4\pi)^{k-1/2}}{\sqrt{\Gamma(2k)}(2\pi y)^{k-1/2}}\sum_{n\ge 1}(2\pi ny)^{k-1/2+\epsilon}e^{-2\pi ny}$$
that  : $|y^kf(z)|\ll k^{{1/4}+\epsilon}$ for $y\gg k.$ Can someone clarify to me it ?","['number-theory', 'analytic-number-theory', 'modular-forms', 'automorphic-forms']"
1895231,Maximum area of a rectangle inscribed in a triangle is $1/2$ the area of triangle,"Show that the maximum area of a rectangle which can be inscribed in a triangle of area $A$ is $\dfrac{A}{2}$. I was trying to solve this as an application of maxima/minima, but it becomes a little clumsy. From the figure,
$AH=\frac{x}{\tan A}$ and $BK=\frac{x}{\tan B}$ , where $FH=GK=x$ (say) $\therefore$ Area $(\Delta)$ of rectangle $FGKH=x\times HK=x(AB-(AH+BK))$ $=x\left(c-\left(\frac{x}{\tan A}+\frac{x}{\tan B}\right)\right)$ $\qquad$$(AB=c)$ Then simplifying $\dfrac{d(\Delta)}{dx}=0$ to get the answer becomes somewhat tiresome. This answer gives a nice approach for the solution. Is there any simple yet rigorous alternative proof of this proposition?","['euclidean-geometry', 'triangles', 'geometry']"
1895239,Reasoning about finite sums,"Let $X$ denote a finite set, and $q:X \rightarrow \mathbb{R}$ denote a function. Then $$\sum_{x \in X}q(x) \in \mathbb{R}.$$ Now suppose we have a function $f : X \rightarrow Y$. Then we can use $f$ to break up the above sum as follows: $$\sum_{x \in X}q(x) \overset{*}{=} \sum_{x \in X, y \in Y, y = f(x)} q(x) = \sum_{y \in Y}\sum_{x \in X, y = f(x)} q(x) = \sum_{y \in Y} \sum_{x \in f^{-1}(y)} q(x)$$ Seems legit, but to be honest, I don't really understand the $\overset{*}{=}$ step at a purely logical level; all I can say about it is: ""Its obvious!"" So define $\Phi = (x \in X)$ and $\Psi = (x \in X \wedge y \in Y \wedge y=f(x))$. It would be nice if it were true that: $$(*)\qquad \forall x\forall y(\Phi \iff \Psi),$$ but that just isn't true. Question. If not $(*)$, then what relationship between $\Phi$ and $\Psi$ allows us to deduce $$\sum_{\Phi} q(x) = \sum_{\Psi} q(x),$$ and why does it work? Please don't remove the abstract algebra tag; the above question makes sense for $\mathbb{R}$ replaced by an arbitrary commutative monoid, and I'd like to see what that community has to say about the issue.","['abstract-algebra', 'summation', 'logic', 'soft-question']"
1895277,Troubles understanding solution to $\cos(\arcsin(\frac{24}{25}))$,"I am having troubles understanding how the answer key to my Pre-Calculus and Trigonometry document got to the answer it did from this task/question: Find the exact value of the expression $$\cos(\arcsin(\frac{24}{25}))$$ At first, I tried to find the value of $\arcsin(\frac{24}{25})$ and then find the cosine of that value, but it seemed way too hard to do without a calculator. I peeked at the answer key, and I saw this: Let $y=\arcsin(cos(\frac{24}{25})$ Then, $\sin(y)= \frac {24}{25}$ and $\cos(y)= \frac{7}{25}$ I do not understand how they came to this answer or the route to it. Could someone please guide me in the right direction or show me how the document came to this answer?","['algebra-precalculus', 'trigonometry', 'inverse-function']"
1895307,Proof of standard limit $\lim_{x \to 0}(1 - \cos x)/x^{2}$ [duplicate],"This question already has answers here : Finding the limit of $\frac{1-\cos x}{x^2}$ (3 answers) Closed 5 years ago . $$\lim_{x\to 0} \frac{1-\cos(x)}{x^2}=\frac{1}{2}$$ Proof:
$$\lim_{x\to 0} \frac{1-\cos (x)}{x^2} \times \frac{1+\cos (x)}{1+\cos(x)}$$
$$\lim_{x\to 0} \frac{1-\cos^2(x)}{x^2(1+\cos (x))}$$
$$\lim_{x\to 0} \frac{\sin^2(x)}{x^2(1+\cos (x))}$$
$$=\frac{1}{2}$$
Hence we prove it.
But I try to use $\varepsilon$  & $\delta$ method but I was not able to complete the proof. Some one help me to prove it using $\varepsilon$ and $\delta$ method.
Thanks in advance.","['alternative-proof', 'limits', 'calculus', 'epsilon-delta', 'limits-without-lhopital']"
1895320,Unique rational normal curve through d+3 points,"We define a rational normal curve to be the image of a map $$\mathbb P^1\rightarrow \mathbb P^d, [x:y]\mapsto [P_0(x,y):P_1(x,y): \ldots :P_d(x,y)]$$ where $P_0(x,y),P_1(x,y), \ldots P_d(x,y)$ are linearly independent homogeneous degree $d$ polynomials. Prove that through any $d+3$ points in $\mathbb P^d$ in general position (i.e. any $d+1$ of them span $\mathbb P^d$) there exists a unique rational curve passing through them. While I am able to prove the existence, I don't know how to prove the uniqueness part.",['algebraic-geometry']
1895323,A confusing question related to three variables with fractions..,"Recently, I had a mock-test of a Mathematics Olympiad. There was a question which not only I but my friends too were not able to solve. The question goes like this: If, 
$$ \frac{1}{a} + \frac{1}{b} + \frac{1}{c} = \frac{1}{a+b+c} $$ Then what is the value of $$ \frac{1}{a^5} + \frac{1}{b^5} + \frac{1}{c^5} $$ To, solve this question, I used a variety of ways like: 1) transposing variables in the first equation and, 2) putting a whole power of five to both the sides of the equation one. But, I was unable to find the solution. The options were -- (a) 1 , (b) 0 , (c) $ \frac{1}{a^5 + b^5 + c^5} $ , (d) None of them. So, I require any possible help. And, a complete answer would be most welcome. Thanks in advance.","['algebra-precalculus', 'contest-math']"
1895336,Is uncountable union of $\sigma$-algebra necessarily algebra?,"It is well known that infinite union of $\sigma$-algebra is not necessarily a $\sigma$-algebra. But then I read this: The countable union of a non-decreasing sequence of σ-algebras is an algebra. I am not sure why countable union is needed here.
Is there any example that uncountable union of $\sigma$-algebra that is not an algebra ?","['probability-theory', 'measure-theory']"
1895360,Calculating $\lim_{n\to\infty}\sqrt{n}\sin(\sin...(\sin(x)..)$,"I was asked today by a friend to calculate a limit and I am having
trouble with the question. Denote $\sin_{1}:=\sin$ and for $n>1$ define $\sin_{n}=\sin(\sin_{n-1})$.
Calculate $\lim_{n\to\infty}\sqrt{n}\sin_{n}(x)$ for $x\in\mathbb{R}$
(the answer should be a function of $x$ ). My thoughts: It is sufficient to find the limit for $x\in[0,2\pi]$ , and it is
easy to find the limit at $0,2\pi$ so we need to find the limit for
$x\in(0,2\pi)$. If $[a,b]\subset(0,\pi)$ or $[a,b]\subset(\pi,2\pi)$ we have it
that then $$\max_{x\in[a,b]}|\sin'(x)|=\max_{x\in[a,b]}|\cos(x)|<\lambda\leq1$$
hence the map $\sin(x)$ is a contracting map. We know there is a unique fixed-point but since $0$ is such a point
I deduce that for any $x\in(0,2\pi)$ s.t $x\neq\pi$ we have it that
$$\lim_{n\to\infty}\sin_{n}(x)=0$$ So I have a limit of the form ""$0\cdot\infty$"" and I can't figure out
any way on how to tackle it. Can someone please suggest a way to find that limit ? Note: I am unsure about the tags, please change them if you see fit.","['numerical-methods', 'real-analysis', 'limits']"
1895364,"Show if $f,g:S^n \to S^n$ and $|\text{deg}(f)| \neq |\text{deg}(g)|$ there is some $x$ with $f(x), g(x)$ orthogonal.","More specifically, I want to show if f and g are maps from $S^{n} \to S^{n}$ with $|\text{deg}(f)| \neq |\text{deg}(g)|$ show that there is some $x \in S^{n}$ with $f(x), g(x)$ orthogonal. One way I think the hypothesis could be used is the standard ""contrapositive"" trick for these sorts of proofs where I assume $h(x) = \langle f(x), g(x)\rangle$ is never zero. Then it either is always positive or negative. But otherwise I'm not really sure where to go from there.","['algebraic-topology', 'general-topology', 'homology-cohomology']"
1895369,Reference text for Hilbert space theory.,"I am searching for a reference that contains a detailed discussion of most of the topics in Hilbert space theory. I am both interested in the geometry of Hilbert spaces and operators on Hilbert spaces. I am familiar with several excellent texts on Banach space theory; for example, Megginson's An Introduction to Banach Space Theory and Albiac & Fanton's Topics in Banach Space Theory . However, I am not aware of similar types of books for the theory of Hilbert spaces. The book that comes most closely to what I have in mind is probably Halmos' A Hilbert Space Problem Book . However, as the title of this book indicates, this book is meant as a problem book and not really a reference text. I am familiar with general topology, abstract measure theory, and functional analysis; so it is no problem if the book has these topics as a prerequisite (as Halmos' book has). All suggestions and comments are welcome.","['functional-analysis', 'reference-request', 'book-recommendation', 'hilbert-spaces']"
1895371,Rational approximation using only odd numerators.,"Dirichlet's simultaneous approximation theorem says: Given any $n$ real numbers $\alpha_1,\ldots,\alpha_n$ and for every natural number $N \in \mathbb{N}$, there exist integers $q \leq N$, and  $p_1,\ldots,p_n \in \mathbb{Z}$, such that: $$ \Bigg|\alpha_i - \frac{p_i}{q}\Bigg| < \frac{1}{qN^{1/n}} \text{    for } i=1,\ldots,n $$ I would like to prove a similar theorem, but want to insist that the $p_i$ all be odd.  It's easy to prove a version which has all the $p_i$ even, because the set of points in $\mathbb{R}^n$ with even coordinates is a lattice. The general version of Minkowski's Theorem say that a symmetric region containing the origin, if it's volume is sufficiently large, must contain a nonzero lattice point.  But the set of points with odd coefficients is only a coset of the lattice of points with even coefficients. This seems obviously true that one should be able to replace ""lattice"" with ""coset of the lattice"" in Minkowski's Theorem, but I sure don't see how to do it.  I can get the result I want in one dimension by modifying the continued fraction construction, but that doesn't export to $n$ dimensions.  References and insights welcome.","['number-theory', 'diophantine-approximation']"
1895373,"Prove if $t = W(-\log z)$, $|t| = 1$, and $t^n \ne 1$ than $z^{z^{z^{...}}}$ does not converge","Let $z \in \mathbb{C}$ and let $W$ be the Lambert W function.  I am trying to prove that: If $t = W(-\log z)$, $|t| = 1$, and $t^n \ne 1$ for all $n \in \mathbb{N}$ (ie, $t$ is not a root of unity) then $z^{z^{z^{...}}}$ does not converge. I have investigated this numerically in previous posts and I am almost certain my conclusion is correct, but I am not sure how to actually prove it. My first thought was to use the definition of a non-convergent sequence: there exists $\epsilon > 0$ for every $N \in \mathbb{N}$ such that if $n > N$ than $|a_n - L| \ge \epsilon$.  But I am having a hard time getting started on this, because I am not sure what sort of $\epsilon$ would work. It may also help to use this: $z^c = c\implies z = c^{1/c} \implies z^{-1} = c^{-1/c} \implies 1/z = (1/c)^{1/c} \\
\implies -\log z = \frac{\log(1/c)}{c} \implies -\log z = e^{\log(1/c)}\log(1/c) \\ 
\implies \log(1/c) = W(-\log z) \implies 1/c = e^{W(-\log z)} \\
\implies \frac{1}{c} = \frac{-\log z}{W(-\log z)} \\ 
\implies c = \frac{W(-\log z)}{-\log z}$ If I understand correctly, this shows that if the sequence $z^{z^{z^{...}}}$ converges, than it must converge to $\frac{W(-\log z)}{-\log z}$.","['complex-analysis', 'lambert-w', 'complex-numbers', 'tetration']"
1895376,If $T\colon \mathbb R^n \to \mathbb R^n $ linear and $T^2 = kT$   [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question It is given that $T$ is a linear transformation from $\mathbb R^n$ to $\mathbb R^n$ such that $T^2 = k T $  for some $k\in \mathbb R$. Then, one or more of the options are true $\|T(x)\| = |k| \|x\|$ for all $x\in \mathbb R^n$. If $\|T(x)\| = \|x\|$ , for some non- zero vector $x\in \mathbb R^n$ then $ k =\pm 1 $. $\|T(x)\|  >  \|x\|$ for some non- zero vector $x\in \mathbb R^n$, then T is singular. $ T = k I $ where I is an identity transformation. Please suggest how to proceed.","['linear-algebra', 'linear-transformations']"
1895398,"Is $\Bbb Q(\sqrt 2, e)$ a simple extension of $\Bbb Q$?","My general question is to find, if this is possible, two real numbers $a,b$ such that $K=\Bbb Q(a,b)$ is not a simple extension of $\Bbb Q$.
  $\newcommand{\Q}{\Bbb Q}$ Of course $a$ and $b$  can't be both algebraic, otherwise $K$ would be a separable ($\Q$ has characteristic $0$) and finite extension, which has to be simple. So I tried with $\Q(\sqrt 2, e)$ but any other example would be accepted. The field $\Q(\sqrt 2, e)$ has transcendence degree $1$ over $\Q$, but I'm not sure if this imply that it is isomorphic to $\Q(a)$ for some transcendental number $a$ (the fact that two fields have the same transcendence degree over another field shouldn't imply that the fields are isomorphic). I'm not sure about the relation between the algebraic independence of $a$ and $b$, and the fact that $\Q(a,b)/\Q$ is a simple extension.
Notice that $\Q(\pi, e)$ is probably unknown to be a simple extension of $\Q$. Thank you for your help!","['transcendence-theory', 'abstract-algebra', 'extension-field', 'field-theory']"
1895407,Prove that $\lim_{x\to\infty}\frac{f(x)}x=\lim_{x\to\infty}f'(x)$ [duplicate],"This question already has an answer here : If $\lim_{x \to +\infty} f'(x) = L$, then $\lim_{x \to \infty} \frac {f(x)}{x} = L$ (1 answer) Closed 6 years ago . I have come up with a theorem. (It probably doesn't qualify as a theorem, but I don't know what else to call it) This is what it states: If 
$$\lim_{x\to\infty}f'(x)$$ exists (is finite), then $$\lim_{x\to\infty}\frac{f(x)}x=\lim_{x\to\infty}f'(x)$$
I have yet to find a counterexample, and it just seems to make sense to me, but I can't actually prove it. This ""theorem"" is crucial to an answer to a question that I was asked to give, but my answer won't be a very good one if I can't prove why it works. What I've tried: I have been able to prove it if $f(x)$ has a linear asymptote (I think my terminology is correct). If: $$\lim_{x\to\infty}f(x)=\lim_{x\to\infty}mx+b$$ Then: $$\lim_{x\to\infty}\frac{f(x)}x=\lim_{x\to\infty}\frac{mx+b}x=m$$ But that doesn't work if there is no asymptote. Take $f(x)=\ln(x)$ for example. the $b$ in $mx+b$ would be infinite.","['derivatives', 'calculus', 'limits']"
1895412,Left and right multiplication of a matrix A with an upper triangular matrix U,"Let A and $U$ are two square matrices where A is invertible. If
$$AU=UA$$
In partitioned form 
$$\begin{bmatrix}A_{11}&A_{12}\\A_{21}&A_{22}\end{bmatrix}\begin{bmatrix}U_{11}&0_{12}\\0_{21}&U_{22}\end{bmatrix}=\begin{bmatrix}U_{11}&0_{12}\\0_{21}&U_{22}\end{bmatrix}\begin{bmatrix}A_{11}&A_{12}\\A_{21}&A_{22}\end{bmatrix}$$
$\implies$
$$A_{21}U_{11}=U_{22}A_{21}$$
where $U_{11}$ and $U_{22}$ are upper triangular square matrices (dimension can be different) and $U_{11}$ and $U_{22}$ cannot have same diagonal elements Then how to prove $A_{21}$ is a zero matrix and similarly $A_{12}$",['matrices']
1895452,On divisors of $p^n-1$,"This question raised from discussions around my previous question . This may seem trivial or easy, but I am so confused and can't see the answer. So I will be so grateful if you would help me please. For the natural number $n$ and prime number $p$, it is likely possible that there exists a polynomial $f(x)\in\mathbb{Z}[x]$ of the form $f(x)=\prod_{i=1}^{m}(x^{\lambda_i}-1)$ such that $deg(f)>n$ and $f(p)\mid p^n-1$. For example, take $p=3$, $n=2$ and $f(x)=(x-1)^3$ we have $(3^1-1)(3^1-1)(3^1-1)\mid 3^2-1$. However, with assumptions $p\geq 3$ and $n\geq 4$, I could not find any such polynomial $f$ with $\deg(f)>n$ and $f(p)\mid p^n-1$. So it made me to claim that the following statement might be true: Let $p\geq 3$ be a prime number and $n\geq 4$. Then for every $f(x)\in\mathbb{Z}[x]$ of the form $f(x)=\prod_{i=1}^{m}(x^{\lambda_i}-1)$ such that $\deg(f)>n$, we have $f(p)\not\mid p^n-1$. Is the above assertion true? If yes, would you please hint me how to prove it (or refer me to a reference)? Thank you in advance.","['abstract-algebra', 'divisibility', 'algebraic-number-theory', 'elementary-number-theory']"
1895457,Operators with compact resolvent,"This should be a basic, or even stupid, question, but I am really confused, and I cannot find any webpage that addresses my question. From wikipedia ( https://en.wikipedia.org/wiki/Resolvent_formalism ), an operator $A$ has compact resolvent iff $(A - zI)^{-1}$ is compact for some $z$. My confusion is that, compact operators cannot be invertible if the domain is infinite dimensional, but clearly $(A - zI)^{-1}$ is invertible by definition. Then this definition would not make sense!",['functional-analysis']
1895459,Zariski topology in projective space agrees with Zariski topology in affine,"I'm browsing through my notes in algebraic geometry and I'm struggling with a theorem. So recall that in the Zariski topology in the affine space $\mathbb A^n$ the closed sets are zero loci of polynomials in $k[x_1, x_2,\ldots, x_n]$. Now consider the projective space $\mathbb P^n$ and its standard cover with affine open sets $\mathbb P^n=U_0\cup U_1\cup \ldots \cup U_n$, where $U_i=\{[x_0, x_2,\ldots, x_n], x_i\ne 0\}$. Now define the Zariski topology on $\mathbb P^n$ to be the glueing topology, i.e. $X\subset \mathbb P^n$ is closed iff each $X\cap U_i$ is Zariski closed in $U_i$ as an affine set. I want to show that the closed sets in $\mathbb P^n$ are precisely the zero loci of homogeneous polynomials. While it is easy to show that zero loci of homogeneous polynomials are closed sets in this sense, I cannot show that the converse is also true and I would appreciate some help.",['algebraic-geometry']
1895467,Is there a classification of infinite simple groups?,"The classification of finite simple groups is known to be very very long. But I was wondering: is there somehow a classification of the infinite simple groups, or at least a beginning of a classification? Here are a few examples. Such a classification might appear far more difficult than the one for finite simple groups, but sometimes the infinite case is easier, as shown there . For instance, the classification of algebraically closed fields of cardinality $2^{\aleph_0}$ is just based on the characteristic, if I'm not mistaken. Any comment is welcome. Thank you!","['group-theory', 'soft-question', 'simple-groups']"
1895471,Generating uniformly distributed random elements of $SU(3)$,"Say I need to generate a uniformly distributed collection $\{X\}$ of elements of $SU(3)$.  (For concreteness, I will consider the distribution to be uniform if the distribution of  $X$ is identical to the distribution of $gX$ where $g$ can be any element of $SU(3)$.) I know how to generate uniform random elements of $SU(2)$ because it is isomorphic with $SO(3)$ and I know how to generate random rotations.  In past work, I (and other Lattice Gauge Theory people doing Monte-Carlo simulations) needed to generate random $SU(3)$ elements such that the probability of an element is the same as that of its inverse, and such that the probability density near at $SU(3)$ element is non-zero.   However, these are weaker conditions than uniformity, and what we did was to take the product of three elements in three different $SU(2)$ subspaces of $SU(3)$.  We could get arbitrarily close to a uniform distribution by multiplying several such products. But I would like to know how to generate $SU(3)$ elements with uniform distribution, not just almost-uniform distribution.","['probability', 'haar-measure', 'lie-groups']"
1895482,"Showing that $\frac{a + c}{b + d} \leq \max(\frac{a}{b},\frac{c}{d})$ [duplicate]","This question already has answers here : Given 4 integers, $a, b, c, d > 0$, does $\frac{a}{b} < \frac{c}{d}$ imply $\frac{a}{b} < \frac{a+c}{b+d} < \frac{c}{d}$? (6 answers) Closed 7 years ago . I need help in proving (or disproving) the following assumption: $$\frac{a + c}{b + d} \leq \max(\frac{a}{b},\frac{c}{d})$$ where $a,b,c,d \geq 0$ are positive integers. Both fractions $\frac{a}{b}$ and $\frac{c}{d}$ are between 0 and 1 and therefore the conditions $a \leq b$ and $c \leq d$ hold. Any help or ideas are appreciated, thank you!","['algebra-precalculus', 'inequality']"
1895485,Can someone please help me understand Implicit Differentiation?,"I have seen how people implicitly differentiate the equation $x^2 + y^2 = c$. $$d/dx(x^2) + d/dx(y^2) = d/dx(c)$$ treating ""$y$"" as ""$f(x)$"" and using the chainrule we get $$2x + 2y(y') = 0$$ and solving for $y'$ $$y'= -2x/2y$$ The problem is that I just don´t understand implicit differentiation, I do know the rules but they don´t make any sense to me. The fact that it is valid to differentiate both ""$x$"" and ""$y$"" on the same side of the equation is what´s bothering me and even if I see ""$y$"" as a function of ""$x$"" I just end up imagining $$x^2 + (-x^2 + c) = c$$ which doesn´t help me. I also don´t know very much about partial derivatives but I´m willing to learn about them if that helps me understand implicit differentiation. I really appreciate any thoughts or ideas. Thank you!","['multivariable-calculus', 'implicit-function-theorem', 'implicit-differentiation']"
1895498,Possible Boolean functions in n-dimensional space,"Each unique assignment of 0-1 values to the $2^n$ possible inputs in $n$ dimensions represents a Boolean function. Therefore, in $n$ dimensions, there are $2^{2^n}$ such unique assignments that can be made, and this $2^{2^n}$ possible functions. Why are there $2^{2^n}$ such unique assignments not $2\cdot2^{n}$?","['boolean-algebra', 'functions']"
1895507,Show a C-infinity function is a polynomial,"Suppose $f\in C^\infty(\mathbb{R})$ and for any $x\in\mathbb{R}$, there exists $N\in\mathbb{N}$ such that $f^{(N)}(x)=0$. Show that $f$ is a polynomial. This is from one of the Analysis qualifying exam problems. I can show there exists an interval $(a,b)$ on which $f$ is a polynomial by using Baire category theorem, but I can't extend it to the real line. Any suggestion? I think I get some new ideas about this problem. First I can find an interval $I=(a,b)$ by using Baire theorem (same idea from the question that Clement C. added.) where $f$ coincides with a polynomial $g$ on $I$. Then we consider $f^{(i)}(a), i\leq N_g$ where $N_g$ is the degree of $g$. We must have $f^{(N_g)}(a)=0$ because $f^{(i)}(a^+)=f^{(i)}(a)=g^{(i)}(a), i\in\mathbb{N}$. So if we apply the Taylor's theorem at $x=a$, we can extend $I=(a,b)$ to $I_\epsilon=(a-\epsilon,b)$ such that $f=g$ on $I_\epsilon$. Following the same idea, we can show that
$$\inf\{a:f=g \text{  on  } (a,b) \}=-\infty$$
Similarly we can show $f=g$ on $\mathbb{R}$. Update: I just found that the idea above might not work after I was trying to write down a rigorous proof. The main problem is $C^\infty$ function is not neccesarily analytic. (For example, let $f(x)=0$ on $(-\infty,0]$ and $f(x)=e^{-1/x}$ on $(0,\infty)$). So I can only extend $(a,b)$ to some larger (or equal) interval $(c,d)$ if I only use the $C^\infty$ property. So the claim above
$$\inf\{a:f=g \text{  on  } (a,b) \}=-\infty$$
might not be true. I really have no idea how to extend this interval to the real line now.","['functional-analysis', 'baire-category', 'polynomials', 'calculus']"
1895516,"$xy$ is a quadratic residue mod $p$ iff $x$ is a quadratic residue mod $p$, where $y$ be a (nonzero) quadratic residue mod $p$","Let $x,y$ be integers and $y$ be a (nonzero) quadratic residue modulo $p$ ($p$ is a prime). Prove that $xy$ is a quadratic residue modulo $p$ if and only if $x$ is a quadratic residue modulo $p$. If $x$ is a quadratic residue modulo $p$, then the result is trivial. How do we prove the other direction?","['number-theory', 'quadratic-residues']"
1895525,Intuition/motivation/why should I care about (definition of) support,"Let $X$ be a metric space. If $f: X \to \mathbb{R}$, the support of $f$ is the closure of the set $\{x: f(x) \neq 0\}$. What is the intuition/motivation/why should I care about the (definition of) support?","['general-topology', 'real-analysis', 'calculus']"
1895559,Question on proof that closed subset of compact metric space is compact,"Proposition. If $K$ is a compact metric space, $F \subset K$ , and $F$ is closed, then $F$ is compact. Proof. Suppose $F$ is a closed subset of the compact set $K$ . If $\mathcal{G} = \{G_\alpha\}$ is an open cover of $F$ , then $\mathcal{G}' = \mathcal{G} \cup \{F^c\}$ will be an open cover of $K$ . We are given that $K$ is compact, so let $\mathcal{H}$ be a finite subcover of $\mathcal{G}'$ for $K$ . If $F^c$ is one of the open sets in $\mathcal{H}$ , omit it. The resulting finite subcover of $\mathcal{G}$ will be an open cover of $F$ . I have a question. So I understand that we can throw out $F^c$ , as it's disjoint from $F$ . But how do we know that a finite subcover of $\mathcal{G}' = \mathcal{G} \cup \{F^c\}$ (which for all purposes and intents, just consider $\mathcal{G}$ ) for $K$ is actually an open cover of $F$ ? How do we know we aren't missing any part of $F$ , i.e. there's a part of $F$ that hasn't been covered?","['real-analysis', 'calculus', 'proof-explanation', 'general-topology', 'metric-spaces']"
1895568,"""Spreading out"" a smooth, connected $\mathbb{C}$-scheme of finite type.","I have been reading the article "" A conjecture in the arithmetic theory of differential equations "" of Katz and I have a doubt regarding the ""spreading out"". My question is about the following paragraph, in section VI, which says Let $X$ be a connected, smooth $\mathbb{C}$-scheme of finite type. It is standard that we can find a subring $R\subseteq\mathbb{C}$ which is finitely generated as a $\mathbb{Z}$-algebra, and a connected smooth $R$-scheme $\mathbb{X}/R$ of finite type, with geometrically connected fibres, from which we recover $X/\mathbb{C}$ by making the extension of scalars $R\hookrightarrow\mathbb{C}$. I don't understand why it holds and wasn't able to find any concrete reference. My attempt was to first try to understand this locally, that is, for the coordinate ring $\mathbb{C}[x_1,\ldots,x_n]/(f_1,\ldots,f_r)$ of an affine variety over $\mathbb{C}$ and I thought that one may take $R$ as the ring obtained by adjoining the coefficients of the $f_i$ to $\mathbb{Z}$. However in another article, ""Nilpotent connections and the monodromy theorem: applications of a result of Turritin"", Katz considers the following example For instance, the Legendre family of elliptic curves, given in homogeneous coordinates by $$Y^2 Z - X(X-Z)(X-\lambda Z) \;\;\text{ in }\mathrm{Spec}\left(\mathbb{C}\left[\lambda,\dfrac{1}{\lambda(1-\lambda)}\right]\right)\times\mathbb{P}^2$$ is (projective and) smooth over $\mathrm{Spec}\left(\mathbb{C}\left[\lambda,\dfrac{1}{\lambda(1-\lambda)}\right]\right)=\mathbb{A}^1\smallsetminus\{0,1\}$. A natural thickening is just to keep the previous equation, but replace $\mathbb{C}\left[\lambda,\dfrac{1}{\lambda(1-\lambda)}\right]$ by $\mathbb{Z}\left[\lambda,\dfrac{1}{2\lambda(1-\lambda)}\right]$, and replace $\mathbb{C}$ by $\mathbb{Z}[1/2]$. and in that example he adds a more than just the coefficients to $\mathbb{Z}$. Edit: The main part that bugs me in this construction is that I don't see why the fibers are geometrically connected. When I saw the Legendre family example I thought that maybe one needed to add more things to the ring. Any help for how to do this? Thanks in advance for any hints, reference or anything that will help me to better understand this.","['fiber-bundles', 'algebraic-geometry', 'number-theory', 'arithmetic-geometry', 'schemes']"
1895587,Convergence of $\sum_{n=1}^\infty\frac{n}{(n+1)!}$,Can someone give an explanation using the definition of convergence in partial sum to show how the above infinite sum converges to 1? Thanks,"['sequences-and-series', 'telescopic-series', 'factorial', 'convergence-divergence', 'analysis']"
1895590,Spherical Schubert Variety,"I am studying Schubert variety and I came across a problem understand a particular detail. Let $G$ be a reductive group, and $\mu\in X_{\bullet}(T)$ a coweight i.e. $\mu\in Hom(\mathbb{G}_m,T)$, where $T$ is the abstract Cartan of $G$. Then the Schubert variety $Gr_{\leq\mu}$ is defined to be $$Gr_{\leq\mu}:=\{(E,\beta)\in Gr_G|Inv(\beta)\leq\mu\},$$ where $Gr_G$ is the affine Grassmannian of $G$ and $Inv(\beta)\in G(\mathcal{O})\backslash G(F)/G(\mathcal{O})$ via the Cartan decomposition. I am interested in the following special case. Let $G=GL_n$, for $\mu=(u_1,u_2,\cdots,u_n)$, how can we describe the Schubert variety $Gr_{\leq\mu}$ in terms of lattices? Thank you in advance for any comments and answers! I also appreciate if you would like to provide some reference which helps to solve this problem.","['algebraic-groups', 'schubert-calculus', 'representation-theory', 'algebraic-geometry']"
1895591,"Show that, for all $n > 1: \log \frac{2n + 1}{n} < \frac1n + \frac{1}{n + 1} + \cdots + \frac{1}{2n} < \log \frac{2n}{n - 1}$","I'm learning calculus, specifically limit of sequences and derivatives, and need help with the following exercise: Show that for every $n > 1$ , $$\log \frac{2n + 1}{n} < \frac1n + \frac{1}{n + 1} + \cdots + \frac{1}{2n} < \log \frac{2n}{n - 1} \quad \quad (1)$$ Important: this exercise is the continuation of a previous problem showing that, for every $n > 1$ , $$\frac{1}{n + 1} < \log(1 + \frac1n) < \frac1n \quad \quad (2)$$ A detailed solution of the latter inequality using the MVT can be found here . Now back to inequality $(1)$ . My first guess was to use mathematical induction in order to prove it but I didn't get far. I think I should make use of inequality $(2)$ from the previous exercise but I'm stuck here.","['derivatives', 'inequality', 'sequences-and-series', 'calculus']"
1895604,Prove or give a counterexample: $V=\text{null}T+\text{range}T$,"If $V$ is a finite-dimensional vector space and $T:V\rightarrow V$ is linear then $$V= \text{null}(T) + \text{range} (T).$$ I know a counterexample if the sum is replaced with a direct sum. However I can't see why the statement above would be false. Both $\text{null}(T)$ and $\text{range} (T)$  are subspaces of $V$ and $\text{null}(T) \cup\text{range} (T)=V$, so why wouldn't this statement be true? I just want to know if there is something I am missing here...","['direct-sum', 'linear-algebra', 'linear-transformations']"
1895654,Defining a trace-class operator with a Bochner integral,"For complex numbers $z$ consider the system of $L^2(\mathbb{R})$-vectors with norm equal to $1$
\begin{equation}
\psi_z=e^{-\frac{1}{2}|z|^2}\sum_{n=0}^{\infty}\frac{z^n}{\sqrt{n!}} |n\rangle,
\end{equation}
where $|n\rangle$ is an orthonormal basis of the hilbert space $L^2(\mathbb{R})$. (Actually I'm only interested in the special case where the orthonormal basis is given by
\begin{equation}
|n\rangle (x)= \frac{\pi^{\frac{1}{4}}}{\sqrt{2^n n!}}H_n(x)\exp({-\frac{x^2}{2}})
\end{equation}
with the Hermite-Polynomials $H_n$.
This is the eigenbasis of the quantum harmonic oscillator with $m\omega =1=\hbar$. To add further background, the system $\psi_z$ are called coherent states and are closely linked to Segal-Bargmann spaces. I don't think the exact choice of basis matters though, in any case it doesn't seem to matter for calculations of the type needed to solve the problem below) I'm trying to solve the following problem: Let $P$ be a signed (real) measure on the Borel sets of $\mathbb{C}$, such that $P(\mathbb{C})=1.$
  Consider the linear operator defined by
  $$R:L^2(\mathbb{R})\ni\phi\mapsto \int_{\mathbb{C}} \psi_z \langle \psi_z, \phi\rangle dP(z).$$
  What are additional, sufficient conditions to the measure $P$, such that this operator becomes self-adjoint, positive and trace class with trace equal to $1$? (This representation for a density operator is called ""Glauber–Sudarshan P representation"" and used in quantum optics)
I am a physicist, and (no implication implied) my ability to make rigorous mathematical statements is somewhat lacking, especially when it comes to Bochner-integrals, as used in the definition of $R$ and, even worse, signed measures. Nevertheless I decided to get the math right on this one, which I need a little help for. Here is what I have done so far: I'm already failing to prove that the operator is even well-defined as a bounded map. The main problem seems to be that any decomposition theorem for the measure will prevent me from using the fact that the measure of the whole plane is one. If the measure were positive, I would say (to prove that $R$ is a well-defined bounded operator) \begin{equation}
\|R\phi\|\leq \int_{\mathbb{C}} |\langle \psi_z, \phi \rangle |dP(z)\leq \int_{\mathbb{C}} \| \phi\| dP(z)=\|\phi\|
\end{equation}
using Cauchy-Schwarz on the second inequality, but I don't think the first inequality holds with a signed measure... Next I would naively say that the operator is obviously self-adjoint, since $P$ is real. Also I would compute the trace of $R$ to be the reassuring
\begin{align}
\operatorname{tr} R=\sum_n \langle n, Rn\rangle&=\int_\mathbb{C}\sum_n  \langle n,\psi_z\rangle \langle \psi_z , n\rangle dP(z)=\int_\mathbb{C}e^{-|z|^2}\sum_{n,m,k} \frac{z^m\overline{z}^k}{\sqrt{m!k!}}\langle n,m\rangle\langle k,n\rangle dP(z) \\ 
&= \int_\mathbb{C} dP(z)=1.
\end{align}
However none of this is mathematically rigorous. What do I need to assume, so that my arguments work? I'm also unsure what exactly I need to make the resulting operator positive. It seems the continuous part of the measure (w.r.t. Lebesgue) needs to be positive, that isn't enaugh however and I'm also not sure if it's true. I expect conditions for the measure will include that it can be decomposed into two sigma-finite (positive) measures to even define the Bochner integral; it seems reasonable that both the positive and negative parts should be finite on compact sets and have vanishing ""part"" which is both absolutely continuous and singluar w.r.t. the Lebesgue measure on $\mathbb{C}$ in their unique decompositions. It is less of a problem to add too many conditions in this case, as I don't expect finding the sufficiant and necessary conditions will be doable. (I would also be very interested in finding conditions for replacing integration against the measure by the action of certain (probably tempered) distributions, that seems even harder though)
Thank you all very much in advance for the help! Since I still don't know the answer several months later, I decided to try asking this question in MathOverflow . Since I still don't know the answer several months later, I decided to try asking this question in MathOverflow . I created this answer to complete this particular question topic and make sure it doesn't show up as on open question to avoid parallel discussions.","['hilbert-spaces', 'mathematical-physics', 'operator-theory', 'functional-analysis', 'measure-theory']"
1895667,"Can someone help me have a deeper understanding of ""$i$""?","I have seen many explanations of $i$, this include comparing the understanding of the imaginary unit with negative numbers, fractions, etc. to solve polynomials and using the geometric interpretation of $i$ in the complex plane. I´m starting to study complex analysis (basic differentiation at the moment) and noticed that everything makes sense if I just accept that $i^2=-1$, but that is my only problem, none of the explanation above totally clarify to me why $i$ works. Real life examples such as $(s)(t)=d$ where $s$ stands for ""speed"", $t$ stands for ""time"" and $d$ stands for ""distance"", provide a good understanding on why $(-1)^2=(+1)$; (negative time would be seen as the time needed to reach distance $0$ at velocity $s$ (starting at a negative distance), or, if we are creative enough, we could imagine it as going at velocity $s$ just that time would be going backwards for $t$ seconds, or whatever time measure we want to use). Other example would be multiplying ""deposit made"" with ""times made"" to get ""money in bank account"". And if we dare to say that $(-1)^2=(-1)$, not only it would be illogical, but the math would just break, taking a derivative or using the binomial theorem would give us crazy results, plus we could prove that any number is equal to any other number. Parallel to the first example, we could imagine a ball rolling in a hill. Representing the ball accelerating towards the right direction as $+$, and representing a slope such that it gets higher as we go to left as $-$, we can say that. $(-s)(+t)=(+a)$ Where $s$ stands for slope, $t$ stands for time and $a$ stands for acceleration. Notice that in this ""system"" $(-1)(+1)=(+1)$, $(+1)(+1)=(-1)$ and $(-1)(-1)=(-1)$. And like this any number of ""systems"" with the same properties can be created. My idea is that, since we can create a ""system"" in which some positive unit squared, lets call it $i$, gives us a different negative unit, let´s call it $u$ ($i^2=-u$), and if $u$ satisfy the property of $(+1u)^2=(+1u)$, this unit $u$ would work just as $+1$ so we could just omit it and get imaginary and complex numbers. The problem with this explanation is that it isn´t satisfying enough, I don´t even know if it´s right or if it just depends on how I see it, that´s why I´m asking for a better explanation. Thank you for reading this unending text, I really would appreciate any other explanation of complex numbers.","['complex-analysis', 'complex-numbers']"
1895668,if $\frac{\theta_1-\theta_2}{2\pi}$ is irrational then $f$ is a constant.,"Let $f: B(0,1)\to\mathbb{C}$ be analytic with the property that there exists $\theta_1, \theta_2\in\mathbb{R}$ such that $$|f(re^{i\theta_1})|=|f(0)|=|f(re^{i\theta_2})|$$ for all $r\in(0,1)$. Show that if $\frac{\theta_1-\theta_2}{2\pi}$ is irrational then $f$ is a constant. Could anyone kindly help? I have been thinking for a long time and still have no clue. How to use $\frac{\theta_1-\theta_2}{2\pi}$ is irrational to prove $f$ is constant? Thanks so much!","['complex-analysis', 'analysis']"
1895679,"Is there such a thing as ""total differential equations""?","As is well known, the theory of partial differential equations is much more difficult than the theory of ordinary differential equations, because PDEs don't behave as nicely. I was thinking, however, that the generalization of regular derivatives to the higher-dimensional case is usually best thought of as the total (i.e. Frechet) derivative, rather than partial derivatives. Question: Is there a theory of total differential equations? If not, why not? And if so, does the theory allow one to sidestep around a lot of the problems which arise in the theory of PDEs? The main problem I could think of is ""type-checking""; namely the original function will be a first-order tensor field, the first derivative would be a second-order tensor field, the second derivative would be a third order tensor field , and so on... Is there not a way to circumvent this problem? Note: Just so everyone is clear, I am not arguing against the usefulness of the  theory of PDEs; on the contrary, they were even used by Perelman to prove the Poincare Conjecture. I'm just wondering, if total differential equations would be easier to study, why no one has studied them. The existence of partial derivatives is only necessary but not sufficient for the existence of the total derivative. So my conjecture is that solving PDE's restricted to the solution space of total differential equations would be much easier and would have to account for far fewer pathological cases, since the existence of the total derivative implies far more regularity properties than one gets by assuming the existence of the partial derivatives alone. ( In fact, the existence of partial derivatives does not even imply the existence of all directional derivatives, which in turn does not even imply Gateaux differentiability, which in turn does not even imply total differentiability , so one should expect the general theory of PDEs to have far more pathological cases than the specific theory of total differential equations.) In other words, it seems like studying total differential equations might make it easier to identify which classes of PDE are easy to solve and would help explain in part why some PDEs are more difficult to solve, since it would make much more explicitly clear how analogies with ODEs break down in those cases. So even though total differential equations would arguably be a sub-case of the field of PDEs, the additional regularity properties would still make it a worthwhile object of study, the same way that the study of symmetric or diagonalizable matrices illuminates the whole of linear algebra.","['derivatives', 'ordinary-differential-equations', 'partial-differential-equations']"
1895706,"Can a rectangle be tiled with $6$ smaller rectangles, such that no smaller set of those rectangles forms a rectangle?","Here on puzzlingSE is an interesting question about tiling a rectangle with smaller rectangles.
I will restate the question: For which $n \in \mathbb{N}$ can a rectangle $R$ be tiled with $n$ smaller rectangles, $r_1, r_2, r_3, \ldots, r_n$, such that the only rectangle formed by the union of two or more smaller rectangles is $R$ itself? This has already been answered for all but $n = 6$: $n = 1$ is trivially possible. Examples given in the post show that $n = 2$ and $n = 5$ are possible. The top answer shows that all $n \ge 7$ are possible. It is not too hard to show that $n = 3$ and $n = 4$ are impossible. So the question is, is it possible to do this when $\boldsymbol{n = 6}$? I expect the answer is no. I'm looking for a solution which is as elegant as possible. Partial results: for a tiling of $R$ with six rectangles, the following are true: No vertical line or horizontal line can cut $R$ in half. There can be no four rectangles meeting at a point in the interior of $R$.","['combinatorial-geometry', 'recreational-mathematics', 'geometry']"
1895828,"If $ \sum\frac{a_n}{n}$ converges, then $\frac{a_1+\cdots+a_n}{n}$ converges to 0?","I'm studying Strong Law of Large Numbers proof, and I think above statement is a non-trivial one, so I want to know whether the above statement is true or not. Thanks for the help and suggestions.","['real-analysis', 'sequences-and-series']"
1895866,How to write exponential function for curve that pass 4 or more points,"Given 3 points, we could write exponential function for a curve that would pass those points in $y = ax^n + b$ form So I wonder that, could we write a function in exponential form that would pass 4 points, which is not quadratic or cubic bezier Or are there any formula that could construct a function for curve to pass any given points? Edit : Sorry I was misunderstand the word exponential function. What I really mean is rational exponent function I don't know what it called but it not polynomial. Something like $y = ax^{1.5} + b$ but can pass any 4 or more points","['roots', 'curves', 'functions', 'exponentiation']"
1895923,degree of K(x) over K(F/G),"This is an ungraded assignment from a course on Galois theory on Coursera, so I hope it's OK to ask the question here. ""Let $F(x)/G(x) \in K(x)$ be a rational function over a field $K$ . Show that the extension $K(x)/K(F/G)$ is algebraic and compute its degree."" Ok, the first part was easy for me: the polynomial $p(y) = F(x)/G(x) \cdot G(y) - F(y)$ has $x$ as its root. This shows algebraicity. For the second part, my guess is that $p(y)$ is also the minimal polynomial, so if I assume that $F,G$ are coprime, then the degree is a $\max(\deg F,\deg G)$ . Is that right? And if it is, how to prove that $p(y)$ is in fact minimal?","['minimal-polynomials', 'abstract-algebra', 'field-theory']"
1896108,Proof that no natural number can be subset of any of its elements.,"in order to proof that: ""no natural number can be subset of any of its elements"" as showed in Halmos's book, is used the following passage: if $n$ contains $n$ then $n$ can not be member of $n$ , and $n$ is a natural number, using the definition of number to be a collection of sets, with $0$ to be the empty set, and $n^{+}$ = $n$ (union) ${n}$, where $n^{+}$ is the sucessor of n.","['alternative-proof', 'proof-verification', 'proof-writing', 'elementary-set-theory', 'proof-explanation']"
1896116,Higher order derivatives of the binomial factor,"Let $p$,$l$ be positive integers and $\theta$ be a parameter. The question is to compute the following quantity:
\begin{equation}
\kappa^{(p)}_l := \left. \frac{\partial^p}{\partial \theta^p} \binom{\theta}{l} \right|_{\theta=0}
\end{equation}
With the help of Mathematica we found the result for consecutive values of p. We have:
\begin{equation}
\kappa^{(p)}_l = \left\{
\begin{array}{rr}
\delta_{l,0}           & \quad \mbox{if $p=0$} \\
\frac{(-1)^{l+1}}{l}   & \quad \mbox{if $p=1$} \\
2 (-1)^l \cdot \frac{H_{l-1}}{l} & \quad \mbox{if $p=2$} \\
3 (-1)^l \cdot \frac{H^{(2)}_{l-1} - H_{l-1}^2}{l} & \quad \mbox{if $p=3$} \\
4 (-1)^l \cdot \frac{2 H^{(3)}_{l-1} - 3 H^{(2)}_{l-1} H_{l-1}+H_{l-1}^3}{l} & \quad \mbox{if $p=4$} \\
5 (-1)^l \cdot \frac{6 H^{(4)}_{l-1} - 8 H^{(3)}_{l-1} H_{l-1}-3 H^{(2)}_{l-1} H^{(2)}_{l-1}+6 H^{(2)}_{l-1} H_{l-1}^2 - H_{l-1}^4}{l} & \quad \mbox{if $p=5$} \\
\end{array}
\right.
\end{equation}
if $l\ge 1$ and $\kappa^{(p)}_0=\delta_{p,0}$.
Here $H^{(p)}_l$ is the harmonic number of order $p$.
Now, the obvious question would be to find the result for generic values of $p$.",['derivatives']
1896134,Applications of group theory to classical mechanics,"Today, a friend and I solved a classical mechanics problem using group theory. The problem was the following: Around a circumference, there are $N$ children evenly spaced. In the center, there is a tire. Each children pulls the tire by a rope with equal forces. Is the resultant force always zero? My friend associated each force vector with a complex root of unity, and using the fact that the group of the $N$-roots of unity is cyclic, showed the identity:
$$1 + \zeta + \zeta^2 + \cdots + \zeta^{n-1} = 0$$
which equals saying that the resultant force is zero. I considered the set $\Omega$ of all permutations of the children, with a group action $\pi\colon \mathbb{Z}/N\mathbb{Z}\times \Omega \to \Omega$ by cyclic permutations. I considered the ""force"" function $f\colon \Omega \to \mathbb{R}^2$ which associated each system with it's resultant force vector. I also considered the group action $\varphi\colon \mathbb{Z}/N\mathbb{Z} \times \mathbb{R}^2 \to \mathbb{R}^2$ by rotations of the plane. Then, I argumented the following identities for all $S \in \Omega, x \in \mathbb{Z}/N\mathbb{Z}$:
$$f(\pi(x, S)) = \varphi(x, f(S))$$
$$f(\pi(x, S)) = f(S)$$
which implied $f(S)$ is a fixed point of $\varphi$, and thus is always the zero vector. I never expected a application of group theory to classical mechanics (though I know about it's uses in crystallography). Are there other well know examples of this?","['physics', 'soft-question', 'applications', 'classical-mechanics', 'group-theory']"
1896143,Probability : Two dice are thrown r times.,"Two dice are thrown r times. Find the probability $p_r$ that each of the six combinations $(1,1),\ldots,(6,6)$ appears at least once. My approach : As per my understanding will this be 1 - Pr(at least one of the pair does not occur in $r$ trials) ? 
So will this be $1 - (\Sigma_{i=1}^6\frac{(-1)^{(i-1)} * {^6}C_i*(36-i)^r}{36^r})$ ?","['probability-theory', 'probability', 'probability-distributions']"
1896174,Geometric Intuition of Eigenvalues of Hessian Matrix,"I have a very simple question, which I suspect speaks more to my lack of intuitive understanding of parts of linear algebra than anything calculus related. I have come across this statement (or variants thereof) in the context of the Morse Index of a critical point on various occasions: Statement : The number of negative eigenvalues of the Hessian matrix of a function $F:M\to N$ at a point $p$ is equal to the dimension of the maximal subspace of the tangent space $TM_p$ of $M$ at $p$ on which $F$ is negative definite. My question is: Question : Why do the eigenvalues of the Hessian encode this information? As I stated above, this almost certainly is the result of a lack of comfort in dealing with eigenvalues (rather than anything differential) that I have put off confronting far too long into my mathematical education, but it is not clear to me how to make the jump from in the statement.","['eigenvalues-eigenvectors', 'differential-topology', 'multivariable-calculus', 'morse-theory', 'linear-algebra']"
1896209,Conditional expectation continuous in the conditioning argument?,"Let $X$ and $Y$ be random vectors defined on a common probability space. $X$ takes values in a finite-dimensional space $\mathcal{X} \subset \mathbb{R}^p$, while $Y$ takes values in $\mathbb{R}$. The conditional expectation $E(Y \mid X)$ is then a random variable that is uniquely defined up to null sets. I am seeking a set of sufficient conditions on the joint distribution of $(X,Y)$ for the following statement to be true: Given any point $x_0 \in \mathcal{X}$, there exists a function $f \colon \mathcal{X} \to \mathbb{R}$ such that (i) $f(X)$ is a version of $E(Y \mid X)$, and (ii) $f(\cdot)$ is continuous at $x_0$. Obviously, the continuity part is the non-trivial one. By Lusin's theorem , any measurable function (such as any version of the conditional expectation function) is ""nearly continuous"", but this is not quite enough for me. Ideally the sufficient conditions for the above statement would not involve restrictions on the densities or conditional densities of $X$ and $Y$. The problem that motivates this question has a complicated geometry, so it is difficult to characterize densities with respect to fixed dominating measures. If you require more structure to the problem (but ideally the question would be answered in more generality), you may assume: $Y = g(A)$ for a continuous function $g(\cdot)$, $X = A + B$, and the random vectors $A$ and $B$ are independent. However, $A$ and $B$ may concentrate on different subspaces of $\mathbb{R}^p$, each of which is a complicated manifold. Thank you in advance for your time!","['continuity', 'probability-theory', 'conditional-expectation', 'measure-theory']"
1896221,How do I make an exponential regression on data with noise?,"I have some measurements that should, logically, be fit to an exponential formula. Problem is, there is some uncertainty in the measurements, so some of them are negative. Since both negative and 0 are illegal in exponential models, I can't just do a headless regression on Excel, say; even if the fit is quite obvious. Let's just say my data looks like this: The blue dots are exponential decay, the orange are exponential decay plus/minus up to 0.1. That's not a lot initially, but when the numbers drop low enough, I get negative values quite randomly; so no exponential regression for me. I could of course delete the negative values, which would give a sampling bias. Not a good solution. Any obvious solutions I'm missing?","['exponential-function', 'statistics', 'probability', 'regression']"
1896226,The inverse of Laplace operator,"Let $\Delta$ denote the Laplace operator in $\mathbb R^2$, and let $u_1$ and $u_2$ be two orthogonal eigenfunction of $-\Delta$, i.e., $-\Delta u_1=\alpha_1 u_1$ and $-\Delta u_2=\alpha_2 u_2$, where $\alpha_1$ and $\alpha_2$ are the corresponding eigenvalue. I am wondering do we have
$$
\Delta^{-1}(u_1+u_2)=\Delta^{-1}u_1+\Delta^{-1}u_2\tag 1
$$
and if yes, how we proof it? I know $(1)$ does not hold for general function, but I think it might work for orthogonal functions...
PS: by orthogonal I mean
$$
\int u_1 u_2dx=0.
$$
PPS: by $\Delta^{-1}$ I mean the inverse of Laplace operator, i.e., $\Delta^{-1}\Delta=I$","['functional-analysis', 'laplacian', 'sobolev-spaces', 'partial-differential-equations']"
1896238,How to calculate curvature of Earth per surface kilometer,"I was watching a video regarding Flat Earthers giving curvatures of Earth that sounded way too big, so I decided to calculate how much the surface of Earth would drop with respect to a line perpendicular to the ground per a certain distance from this point. I'll use variables as defined in my awfully drawn diagram. Let $s = 1km$. Given that the radius of Earth is 6371km, we can find $\theta = \frac sr = \frac {1km}{6371 km} = \frac {1}{6371} rad = 1.56*10^{-4} rad$ I think h could found by $h = 6371\sin(\frac{\pi}{2}) - 6371\sin(\frac{\pi}{2}-1.56*10^{-4}) = 7.84*10^{-5} km$ which converted to meters would result in a curvature of $0.07\frac{m}{km}$. EDIT Note that the formula is not linear, so in order to get the ""fall"" of Earth for 2 kilometres, multiplying the result by 2 is not enough. The formula is $h = 6371-6371*\sin(\frac{\pi}{2} - s/6371)$ where $s$ is the distance to the object in kilometers. Did I make any mistake? This value seems quite small and I'd like to make sure. Thanks in advanced.","['trigonometry', 'curvature']"
1896244,Does the converse to Kronecker's lemma hold?,"Odds are that this question has been answered already and even that the argument is not too complicated, but here it goes: Assume that $(a_{k})_{k\in\mathbb{N}}$ is a sequence of real numbers and $(b_{k})_{k\in\mathbb{N}}$ is a sequence of positive numbers with $\lim_{n}b_{n}=\infty$. Can we infer from the hypothesis $$\sum_{k}a_{k}$$ is not convergent that $$\limsup_{n}|\frac{1}{b_{n}}\sum_{k=1}^{n}a_{k}b_{k}|>0?$$
 In other words, does the converse to Kronecker's lemma hold? For the purpose of my question, you can assume that $(a_{n})_{n}$ is positive and decreasing and that $b_{n}=n$.","['cesaro-summable', 'sequences-and-series', 'convergence-divergence', 'limits']"
1896245,Loxodromics (curves with fixed angle with meridians) of a revolution surface,"I am trying to find the curves with a fixed angle $\phi$ with meridians for the revolution surface given by the revolution of the graph of $z=\frac{1}{x}$ around the $z$ axis. The surface is easily parametrized as
$$(x,\theta)\mapsto(x \cos \theta, x\sin \theta,\frac{1}{x}) \qquad x\in \mathbb R_{>0},\theta \in (0,2\pi)$$
Now, some tedious computations (I hope they are correct) show that the first and the second fundamental form for this parametrization are
$$G_{I}=\begin{pmatrix}1+\frac{1}{x^4} &0 \\ 0 & x^2 \end{pmatrix} \qquad G_{II}=\frac{1}{\sqrt{x^4+1}}\begin{pmatrix}\frac{1}{x} & 0 \\ 0 & -x \end{pmatrix}$$
Recall that the angle $\phi$ between two $C^1$ curves $\gamma_1,\gamma_2$ is given by
$$\cos \phi=\frac{\gamma_1'^TG_I \gamma_2'}{\sqrt{\gamma_1'^T G_I \gamma_1'}\sqrt{\gamma_2'^TG_I\gamma_2'}}$$
Since we are looking for curves $(x(t),\theta(t))^T$ with constant angle with meridians, we want that
$$\frac{\begin{pmatrix}1 & 0 \end{pmatrix}\begin{pmatrix} 1+\frac{1}{x^4(t)} &0 \\ 0 & x^2(t)\end{pmatrix}\begin{pmatrix} x'(t) \\ \theta'(t) \end{pmatrix}}{\sqrt{\begin{pmatrix} x(t) & \theta(t)\end{pmatrix}\begin{pmatrix}1+\frac{1}{x^4(t)} &0 \\ 0 & x^2(t) \end{pmatrix}\begin{pmatrix} x'(t)\\ \theta'(t) \end{pmatrix}}\sqrt{\begin{pmatrix} 1 & 0\end{pmatrix}\begin{pmatrix}1+\frac{1}{x^4(t)} &0 \\ 0 & x^2(t) \end{pmatrix}\begin{pmatrix} 1 \\ 0\end{pmatrix}}}=K$$
which, dropping the dependency on $t$, yields the differential equation
$$x'\left (1+\frac{1}{x^4}\right )=K\sqrt{1+\frac{1}{x^4}}\sqrt{x'^2\left ( 1+\frac{1}{x^4}\right)+x^2\theta'^2}$$
Not looking very good. Through a few manipulations, I brought this to the form
$$x'(t)=K\sqrt{x'^2+\frac{x^6\theta'^2}{x^4+1}}$$
Since this is an exercise from an exam, I would expect the solution to have a nice closed form, but maybe I am mistaken. Is there any elementary way of solving such differential equation or of finding an explicit equation for the loxodromics?","['curves', 'ordinary-differential-equations', 'differential-geometry', 'surfaces']"
1896258,$R ≅ R/I$ prove that for any two-sided ideals $A$ and $B$ we have $A⊆B $ or $B⊆A$,Assume that $R$ is a ring such that for any two-sided ideal $I$ of $R$ we have $R ≅ R/I$. Prove that for any two-sided ideals $A$ and $B$ we have $A⊆B$ or $B⊆A$ . I try to solve with proof by contradiction and this property that $A∩B$ is also an ideal but i could not find any thing useful.,"['abstract-algebra', 'ring-theory', 'ideals']"
1896336,Infinite Series Sum: $\sum_{n=1}^{\infty} \frac {1}{2^n}\tan\left(\frac{x}{2^n}\right) = \frac1x - \cot x$,"$$\sum_{n=1}^{\infty} \dfrac {1}{2^n}\tan\left(\dfrac{x}{2^n}\right) = \dfrac 1x - \cot x$$ I used an identity $\tan(1/2x) = \text{cot }\left(\dfrac{1}{2x}\right) - 2\text{cot}(x)$ and input $x= \dfrac{X}{2^n-1}$ into the summation. I get a telescoping sum. When I look at the telescoping sum, I assume that all other terms cancel out except $-\cot x$. But that wasn't the right answer it's $\dfrac 1x- \text{cot}\,x$. Why? I know they looked at the telescoping sum and took the limit of the nth term of the telescoping sum as $n\to\infty$ which became $\dfrac 1x$ and added the $-\text{cot }x$. Logically to me this doesn't make sense. The sum reduces (the way I remembered (if I'am correct) 
$$\sum_{n=1}^{\infty} (\text{cot}\left(\dfrac{1}{2^n}\right) - \text{cot}\,\left(\dfrac{1}{2^n-1}\right)).$$ $2n$ is ahead of $2^{n-1}$. Shouldn't all there terms cancel all the way to infinity out except $-\text{cot }x$. But instead, we take the sum of the telescoping sum to the nth term and take the limit? That doesn't add up all the terms. Please help.","['infinity', 'trigonometry', 'sequences-and-series']"
1896367,Does S-equivalence imply a deformation relation?,"Let $V$ and $V'$ be two semi-stable vector bundles, on some algebraic curve, that are S-equivalent. My question is whether it follows that $V$ and $V'$ are related by a deformation, i.e. whether they sit in a single extension group (hopefully this is the correct way to phrase this). In particular, I'm interested in the case where $V$ and $V'$ are vector bundles on an elliptic curve $E$. I suspect this is true because, on $E$, the direct sum $\mathcal{O}_E\oplus\mathcal{O}_E$ is S-equivalent to the unique non-trivial extension of $\mathcal{O}_E$ by itself, and I believe this is meant to be a very representative case. However I don't have an intuition for the general case, and I'm not sure how to go about a proof.","['algebraic-geometry', 'deformation-theory', 'elliptic-curves', 'algebraic-curves', 'vector-bundles']"
1896369,Special linear group is a simple algebraic group,"I am looking for a reference for the proof that the special linear group over an algebraically closed field is a simple algebraic group, i.e., a connected algebraic group that has no proper normal connected subgroups. Can anyone help me? Thanks in advance.","['matrices', 'linear-algebra', 'algebraic-geometry', 'lie-groups']"
1896395,Generalizing pullback of cycles and intersection products as suggested in Serre's local algebra,"Chapter V in the book Local algebra by Serre,
introduces the notion of a ""relative intersection product"" meaning that if $f: X \to Y$ is a morphism of varieties with $Y$ regular and $x,y$ are cycles on $X$ and $Y$ respectively then we can define a cycle on $X$ denoted $x \cdot_f y$ and this product is stated in terms of a formula involving $Tor$ functors. In the case where $x = X$ one then denotes the aforementioned product by $f^{*}y$ which is then defined to be the pullback of the cycle $y$ to $X$. Since this is a book on commutative algebra, it is perhaps not very surprising that this last section concerning applications to algebraic geometry is very sketched and lacking in several ways. By this I mean that for instance some properties of the pullback are mentioned, a projection formula being one of them, but the reader is only given a vague idea of how spectral sequences can be applied to prove this. Another point I would like to make is that only varieties over algebraically closed fields are considered, but there doesn't seem to be any reason why this should not work more generally. The book is concluded by mentioning that the Tor formula can be used to extend intersection theory, regular schemes being one class of objects this should work for, so I suppose that it should be possible to develop the ideas introduced in chapter V in more generality. However from what I understand even the Stacks-project does this in the same settings as Serre. My question: Is there any reference that introduces the ""$Tor$""-formula and uses it to define the pullback of a cycle $y$ by any morphism of schemes $f: X \to Y$ with $Y$ regular (and possibly $X$,$Y$ integral and of finite type over a field $k$ which is not necessarily algebraically closed) and also proves the projection formula $f_{*}(x \cdot_f y) = f_{*}(X) \cdot y$ when $f$ is proper and both sides are defined? I would like to add that Suslin and Voevodsky use this aforementioned machinery in their article ""Singular homology of abstract algebraic varieties"" in the case where $f: X \to S$ is a finite surjective morphism of integral ($k$)-schemes with $Y$ regular, so it should at least hold in that case. Note: I have only skimmed parts of ""Local algebra"", so I am aware of the possibility that my questions can have been thoroughly dealt with in some disguise already earlier in the book, or perhaps what I am seeking can easily be done if one is more familiar with intersection theory and homological algebra.","['algebraic-geometry', 'reference-request', 'intersection-theory', 'homological-algebra', 'schemes']"
1896399,derivative $\frac{\ln{x}}{e^x}$,"Im asked to solve find the derivative of: $$ \frac{\ln x}{e^x}$$ my attempt $$D\frac{\ln x}{e^x} = \frac{\frac{1}{x}e^x + \ln (x) e^x}{e^x} = e^x \frac{\frac{1}{x}+\ln x}{e^{2x}} = \frac{\frac{1}{x}+\ln x}{e^x}$$ But this is apparently wrong and the correct answer is: 
$$\frac{\frac{1}{x} - \ln x}{e^x}$$ Where do I go wrong?",['ordinary-differential-equations']
1896462,Rooks attacked by at most one other rook,"Some rooks are placed on an $n\times n$ board. Each rook is attacked by at most one other rook, and every unoccupied cell is attacked by some rook. What is the smallest $k$ such that no matter how we set up the board, every $k\times k$ subboard contains at least one rook? $k=\lfloor n/2\rfloor$ is too small, because we can take the board with a rook on each square of the main diagonal. In this board the bottom-left (or top-right) $\lfloor n/2\rfloor\times\lfloor n/2\rfloor$ subboard does not contain any rook. Is it true that every $(\lfloor n/2\rfloor+1)\times (\lfloor n/2\rfloor+1)$ subboard must contain some rook?",['combinatorics']
1896464,Is the series $\sqrt{1} - \sqrt{2} + \sqrt{3} - \sqrt{4} + \dots$ summable?,"Is the series $\sqrt{1} - \sqrt{2} + \sqrt{3} - \sqrt{4} + \dots$ summable?  I think it diverges although: $$ \sqrt{n+1} - \sqrt{n} \approx \frac{1}{2\sqrt{n}}$$
for example by the Mean Value Theorem $f(x+1)-f(x) \approx f'(x)$ and then I might argue:
$$ \sum_{n \geq 1} (-1)^{n+1} \sqrt{n} = \frac{1}{2}\sum_{m \geq 1} \frac{1}{\sqrt{2m}} = \infty $$
Are these Cesaro summable ? For an even number of terms:
$$\sqrt{1} - \sqrt{2} + \sqrt{3} - \sqrt{4} + \dots - \sqrt{2n}
\approx - \frac{1}{2\sqrt{2}}\left( \frac{1}{\sqrt{1}} + 
 \frac{1}{\sqrt{2}} + \dots +  \frac{1}{\sqrt{n}} \right)
\approx  \sqrt{\frac{n}{2}}$$
so the Cesaro means tend to infinity.  Does any more creative summation method work? The result is from paper called ""The Second Theorem of Consistency for Summable Series"" in Vol 6 of the Collected Works of GH Hardy the series $1 - 1 +1 - 1 \dots$ is summable $(1,k)$ for any $k$ but not summable $(e^n, k)$ for any value of $k$. The series  $\sqrt{1} - \sqrt{2} + \sqrt{3} - \sqrt{4} + \dots$ is summable $(n,1)$ but not $(e^{\sqrt{n}},1)$ and so on... Here things like $(1,k), (n,1)$ refer to certain averaging procedures, IDK","['radicals', 'real-analysis', 'divergent-series', 'sequences-and-series']"
