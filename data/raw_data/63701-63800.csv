question_id,title,body,tags
733922,Constructing a Möbius strip using a square paper? Is it possible?,"I understand that, from a topological perspective, it is irrelevant whether we choose the quotient of the square $[0,1]\times [0,1]$ (by identifying points $(0,t)$ and $(1,1-t)$) or the quotient of the rectangle $[0,1]\times[0,a]$, $a>1$ (where the obvious points are identified), as a model of the Möbius strip. However, it seems pretty hard, if not impossible, to actually physically construct a Möbius stirp using a square like paper. I wonder if it is possible to determine the least $a\geq 1$, such that he Möbius strip is physically constructible using a paper congruent to $[0,1]\times[0,a]$. I guess that this answer may depend on factors such as the size and the thickness of the paper that we use.  This may be related to the mathematics of paper folding . Is there a general answer to this question, taking relevant qualities of a paper into account? Does anyone know of a source answering this question?","['general-topology', 'recreational-mathematics']"
733934,Finding the matrix exponantial,"I have to calculate the following: $e^{xA} ,  A= 
\begin{pmatrix}1 & 1 & 1 \\
1&1&1\\
1&1&1\\
\end{pmatrix}$ I use the following rule: $e^{xA} = \sum \frac{x^k}{k!}A^k$ Now I'm looking for a matrix such that:
$A=S D S^{-1}$. So I calculated the eigenvalues and eigenvectors of A, these are: $\lambda _0=3 , \lambda_{1,2} = 0 $ $\vec{y_0} = \begin{pmatrix}
1\\
1\\
1
\end{pmatrix} $,$\vec{y_1} = \begin{pmatrix}
1\\
-1\\
0
\end{pmatrix} $,$\vec{y_2} = \begin{pmatrix}
1\\
0\\
-1
\end{pmatrix}$ So I have the following 3 matrices: $ 
S = \begin{pmatrix}
1&1&1\\
1&-1&0\\
1&0&-1
\end{pmatrix}
, D = \begin{pmatrix}
3&0&0\\
0&0&1\\
0&0&0
\end{pmatrix} , S^{-1}=
\begin{pmatrix}
 \frac{1}{3} & \frac{1}{3} & \frac{1}{3} \\
 \frac{1}{3} & \frac{1}{3} & -\frac{2}{3} \\
 \frac{1}{3} & -\frac{2}{3} & \frac{1}{3} \\
\end{pmatrix}
$ But when I calculate $SDS^{-1}$ I don't get A. Can someone help me where I have gone wrong. I thought I understood it up until this point, but there must be something wrong with my reasoning because I have checked every thing with mathematica. I also don't know what to do when I have found the correct S and D.","['matrices', 'linear-algebra']"
733939,Set-theoretic notion of differentiation and integration?,"Since set-theory is said to be one of the foundations of mathematics, I would think that every mathematical concept is definable in set-theoretic terms, right? 
How would you define differentiation and integration? How would you define the limit concept? Thanks.","['elementary-set-theory', 'integration', 'derivatives', 'limits']"
733942,Help with the Probabilty of Rolling Two Ten-Sided Dice Multiple Times Until 100 is Reached,"I need some help figuring out the probability of reaching or exceeding 100 based on a number of rolls of two, ten-sided dice. Here's the scenario. I am starting from zero. I am rolling two (fair) ten-sided dice, to generate a result between 2 and 20. After the roll, I'm recording the number rolled as the 'total' and then rolling again. I'm taking the new result and adding it the total, then rolling again and so on. I'm trying to have the total reach or exceed 100. Example:
On my first roll, I get 12. I record 12 and roll again.
On my second roll, I get 7. I add 7 to the current total of 12 to have a new total of 19. Then I roll again. How many rolls must I make to have a 25% chance of reaching or exceeding 100? How many rolls must I make to have a 50% chance of reaching or exceeding 100? How many rolls must I make to have a 75% chance of reaching or exceeding 100? How many rolls must I make to have a 90% chance of reaching or exceeding 100?",['probability']
733946,"If $\lim \limits_{n \to \infty} nb_n = 0 $, construct a convergent series such that $\lim \limits_{n \to \infty} \frac{b_n}{a_n} =0$.","The question asks to prove that if $b_n = o(\frac 1n)$ as $n \to \infty$, one can always construct a convergent series $\sum_{n=1}^{\infty} a_n$ such that $b_n = o(a_n)$  as $n \to \infty$. What I have tried so far: If I choose an $N \in \Bbb N$ such that $|nb_n|<1$ for all $n>N$, then $b_n < \frac 1n$. By the completeness axiom I can choose an $a_n$ such that $b_n < a_n < \frac 1n$. With some $a_n$ within these bounds for each $n$, $$ 0 < \left| \frac {b_n}{a_n} \right|  < \left|\frac{b_n}{\left (\frac 1n\right)}\right| = |\ nb_n| $$ for all $n> N $ so $\lim \limits_{n \to \infty} \frac{a_n}{b_n} = 0.$ At this point I'm stuck as I don't know if what I've done is valid or how to formulate $a_n$ more precisely if it is. Also, showing that the limit above converges to 0 seems like a circular argument. However, since $\sum_{n=1}^{\infty} \frac{1}{n^p}$ does converge for all $p > 1$, I should be able construct $a_n$ so that the sum converges using the comparison theorem and ensuring each $a_n$ is non negative. Edit: looking at the question again, it does not specify that $b_n = o( \frac 1n)$ for the base $n \to \infty$. But since it gives no other base I assume this one was implied.","['convergence-divergence', 'sequences-and-series']"
733947,"Confusing verse in ""Axiomatic Set Theory"" by Patrick Suppes","While searching for prime ordinals, I found this: Goldbach’s Hypothesis is that every even natural number $> 2$ is the
  sum of two prime numbers. On the basis of the obvious definition of prime
  ordinal numbers, the hypothesis is false for ordinal numbers. It can be
  shown that $\omega+10$ is not such a sum. The definition of prime ordinal numbers obvious for me is an ordinal $> 1$ that is not the product of two smaller ordinals. This does not make any sense to me since $\omega+10$ can be written as $(\omega+5)+5$ . Am I mistaken?","['elementary-number-theory', 'elementary-set-theory']"
733966,What is the main defferences between nets and ordinary sequences,"I know that there are many results in metric spaces (or first-countable topological spaces) can be describe in the language of sequences but these results might not be true in general topological spaces. So that we should extend the definition of sequences to nets (generalized sequences). Let $I$ be an directed set, i.e., $I$ with an order relation $\leq$ such that for any $\alpha, \;\beta \in I$, there exists $\gamma\in I$ such that $\alpha\leq \gamma$ and $\beta \leq \gamma$. A nets on $X$ is defined as a mapping $x$ from $I$ to $X$: for each $\alpha \in I$, $x(\alpha)=x_\alpha \in X$. Are there any natural ways to know this definition? What about sub-nets? Is every ordinary sub-sequence is sub-net? Thanks in advance!","['sequences-and-series', 'functional-analysis', 'nets']"
733983,"Sigma-algebra requirement 3, closed under countable unions.","The requirement for sigma-algebra is that. It contains the empty set. If A is in the sigma-algebra, then the complement of A is there. 3. It is closed under countable unions. My question relates to 3. When we define the measure-function, it has to be disjoint countable unions, but not when we define a sigma-algebra. I have tried to prove that if we require instead that the sigma algebra is closed under countable unions of disjoint sets, then it is closed under sets that are not disjoint. But this must be false, I think. Is there a way to prove this? That is I want to show that if I define a sigma algebra to be: It contains the empty set. If A is in the sigma-algebra, then the complement of A is there. It is closed under countable unions of disjoint sets. Then it is not nececarrily closed under countable unions if the sets are not disjoint. I guess this can be shown by creating a a set that satisfies the new definition, but is not closed under countable unions where what we take union over is not disjoint. But is it difficult to create a counterexample like this? If they don't exist then the definitions are equal, but I don't think they are?","['measure-theory', 'examples-counterexamples', 'real-analysis']"
733990,mean value theorem: $ | \cos x-1 | \leq | x | $,"I've been studying mean value theorem, and I was told that I should use MTV for solving problems with $\leq$. So I've been trying to show that $ | \cos x - 1 |  \leq  | x | $ for all x values, using MTV, but I just don't get how MTV can be used... I've been stuck on this for days now and I would be really grateful for any help.","['inequality', 'trigonometry', 'calculus', 'real-analysis']"
734032,Real world situation with System of Equation with 3 variables?,"Where do you run into a real world situation involving 3 variables and 3 equations?  Can someone think of a specific example from business, etc?  I recall taking an operations research course that seemed to involve optimization of 3 variables, but do not recall a single example or theme.  Any help is appreciated.","['applications', 'calculus', 'algebra-precalculus', 'matrices', 'systems-of-equations']"
734058,"If a sequence of continuous functions converges pointwise to a continuous function on $ [a,b] $, it converges uniformly","If a sequence of continuous functions converges pointwise to a continuous function on $ [a,b] $, it converges uniformly. Looking at other theorems on the relationship between continuity and uniform convergence and how they require significant additional assumptions to assure uniform convergence, it seems like the above statement should be false in general. However I'm unable to find a counterexample. Any suggestions?","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'uniform-convergence']"
734059,"triangle construction given side, angle and median","I can't figure out the solution to this, it looks to me like it doesn't have any solution but I need some proof. problem: Construct a triangle ABC with given $a=6 cm$ $\alpha=75^\circ $ and $m_{a}=4cm$.","['geometry', 'triangles', 'geometric-construction']"
734162,An expression equal to its reciprocal (but not really),"""Everybody knows"" that
\begin{align}
\tan\theta & =\frac{2\tan\frac\theta2}{1 - \tan^2\frac\theta2} = \frac{2\sin\frac\theta2\cos\frac\theta2}{\cos^2\frac\theta2-\sin^2\frac\theta2} \tag 1 \\[10pt]
& = \dfrac{\text{2 times a product}}{\text{a difference of two squares}}. \tag 2
\end{align} In the course of thinking about a geometry problem, it became natural to write
$$
\tan\dfrac\theta2=\dfrac{J-K}{J+K}.
$$ Plugging this into $(1)$, we get
\begin{align}
\tan\theta & = \dfrac{J^2-K^2}{2JK} \\[10pt]
& = \dfrac{\text{a difference of two squares}}{\text{2 times a product}}. \tag 3
\end{align} So I am struck by the fact that the expression in $(3)$ looks like the reciprocal of that in $(2)$, although of course they are equal; and the thought that such a seemingly trivial thing is probably thought of by some people as something they've known since infancy and that they see repeatedly every day without giving it a thought, starting before breakfast and lasting until they're sipping their cognac in the evening. So Is the second thought that strikes me correct; and In what contexts does this curious but trivially derived inversion arise? To put it another way, is the inversion in some sense non-trivial even though its derivation is trivial? PS: Here's a bit more about the context in which this came up.  The circle $|z|=1$ in $\mathbb C$ is invariant under $z\mapsto w=g(z)=\dfrac{Jz+K}{Kz+J}$, for $J,K\in\mathbb R$, and that mapping has two fixed points: $\pm1$.  The image of the imaginary unit $i$ under this mapping is therefore $e^{i\theta}$ for some $\theta\in\mathbb R/2\pi\mathbb Z$.  It follows that $J=1+\tan\frac\theta2$ and $K=1-\tan\frac\theta2$.  If we let $z=e^{i\alpha}$ and $w=g(z)=e^{i\beta}$ for some $\alpha,\beta\in\mathbb R/2\pi\mathbb Z$, then
\begin{align}
\tan\frac\beta2 & = \tan\frac\theta2\cdot\tan\frac\alpha2 \\[12pt]
& = \frac{J-K}{J+K}\tan\frac\alpha2.
\end{align}
I've actually forgotten whether there was a reason why I wanted $\tan\theta$ in terms of $J$ and $K$.  There is a yet broader context in which I had occasion to do this, but that would be quite off topic for the present question.",['trigonometry']
734194,Counting problem involving Hat Check experiment with n hats,"The question is a spin on the Hat Check problem . ""There are n= 2k hats (an even number). Find the probability of B = { $h_{i} = i$ if $i$ is even and $h_{i} \neq i$ if $i$ is odd)."" My interpretation for what the problem is asking is to find the probability that at least one ""even numbered"" person gets their own hat back AND at least one ""odd numbered"" person does not get their own hat. An earlier part asked to find A = {$h_{i} = i$ if $i$ is even} which, as I understood, needed to be rewritten as $ A = \bigcup_{i= 1}^k A'_{2i}$ where $A'_i = \{h_i = i\}$ in order to apply the inclusion exclusion principle. Then $S_i = \dbinom{k}{i}\dfrac{(2k-i)!}{(2k)!} $ and $P(A) = \sum_{i=1}^{k} (-1)^{n+1}\dbinom{k}{i}\dfrac{(2k-i)!}{(2k)!}$ I'm stuck on how to do something similar with the second conditional statement in the mix.","['discrete-mathematics', 'combinatorics']"
734205,Verify that $\nabla(A\cdot B) = (B\cdot\nabla)A + (A\cdot\nabla)B + B\times(\nabla\times A) + A\times(\nabla\times B)$,"I'm trying to verify the following identity
$$\nabla(\textbf{A}\cdot\textbf{B}) = (\textbf{B}\cdot\nabla)\textbf{A} + (\textbf{A}\cdot\nabla)\textbf{B} + \textbf{B}\times(\nabla\times\textbf{A}) + \textbf{A}\times(\nabla\times\textbf{B})$$ To make this, I'm using the $BAC-CAB$ expansion of the triple vector product. Then, I get these two equations $ \textbf{A}\times(\nabla\times\textbf{B}) =  \nabla(\textbf{A}\cdot\textbf{B}) - (\textbf{A}\cdot\nabla)\textbf{B}$ and $ \textbf{B}\times(\nabla\times\textbf{A}) =  \nabla(\textbf{A}\cdot\textbf{B}) - (\textbf{B}\cdot\nabla)\textbf{A}$. Adding these equations I obtained that $$ 2\nabla(\textbf{A}\cdot\textbf{B}) = (\textbf{B}\cdot\nabla)\textbf{A} + (\textbf{A}\cdot\nabla)\textbf{B} + \textbf{B}\times(\nabla\times\textbf{A}) + \textbf{A}\times(\nabla\times\textbf{B}) $$ What am I doing wrong?","['multivariable-calculus', 'physics']"
734217,WKB and asymptotic behavior of second order differential equation,"I want to study the large $x$ solution to a Riccati equation.  After listening to the lectures on Mathematical Physics by Carl Bender, I have fallen in love with asymptotic analysis.  But, by no means do I have a full understanding of it. I transformed the Riccati equation into the following second order differential equation: $$u''(x)-Q(x) u(x)=0\qquad Q(x)=\frac{n(n+2)}{4x^2}+\frac{a^2 b^2\,e^{-2x}}{x^{2n+1}},\enspace\text{with}\,\, a,b>0, \,\,n=\{0,1,2,\ldots\}$$ defined on $0<x<\infty$, subject to the initial condition: $u(1)=1$, $u'(1)=1$. 
The solution to this differential equation gives the solution y(x) to the Riccati equation:
$$
y_\text{sol}(x)=-\frac{(n+2)}{2a}x^{n+1} + \frac{x^{n+2}}{a}\frac{d}{dx}\ln u(x)
$$ For concreteness take $n=0$ and $a=100$, $b=1$. My Attempt My numerical investigations revealed that the large $x$ behavior of $u$ is very insensitive to the initial conditions.  (The hunch I got from this is that the dependence on the initial condition would appear in the negligible part of the solution).  And $y_\text{sol}$ at large $x$ tends to a non-zero constant which I am interested in. I apply WKB.  But, before doing so I recognized this problem as arising from a 3-dimensional QM problem where $x$ is a radial coordinate.  I recalled some obscure claim by Langer (1937) that in order to get an 'accurate WKB result' we must rescale $x$ by putting $x=e^z$ to make the domain of the problem over the entire real numbers $-\infty<z<\infty$. [I have no understanding of why this must be done from an asymptotic analysis point of view; can someone help me with this?].  Then if I put $u(x)=e^{z/2}w(z)$, I get a new second order differential equation $$w''(z) - P(z)w(z)=0\qquad P(z)=\frac{(n+1)^2}{4}+e^{2z}\frac{a^2b^2\,e^{-2(e^{z})}}{(e^{z})^{2n+1}}$$ for which I can apply WKB.  The end result (after transforming back to $u$ in $x$-space) is: $$
u(x)\sim A \frac{1}{Q_L(x)^{1/4}}\Big(e^{\int_1^x dx' \sqrt{Q_L(x')}}+B e^{-\int_1^x dx' \sqrt{Q_L(x')}}\Big)
$$
Here, $Q_L = \displaystyle\frac{(n+1)^2}{4x^2}+\frac{a^2 b^2\,e^{-2x}}{x^{2n+1}}$ is slightly different from $Q$ due to the brief transformation to $z$-space, and $A$ and $B$ are constants fixed by boundary conditions. Problems When I plot this result against the numerically integrated solution for $u(x)$ and also for $y(x)$, I find that WKB does a fantastic job approximating the small $x$ behavior of the exact solution, but doesn't get quite get the large $x$ behavior correctly.  WKB does get leading the asymptotic behavior: $u'(x)/u(x) \sim \frac{n+2}{2}\frac{1}{x}$ as $x\rightarrow\infty$.  But I need the next-to-leading asymptotic form which I expect to be $\sim 1/x^{n+2}$. But WKB approximation tells me that it is $\sim e^{-2x}$, which is very subdominant compared to what I am expecting.  I am puzzled by this because I thought WKB was supposed to uniformly get the right answer for all $x$!  I tried even tried taking the WKB approximation to next to leading order in hopes of getting the expected next-to-leading order asymptotic behavior, but I still keep getting highly subdominant terms...  what's going on?? Perhaps I should follow a different strategy to determine the asymptotic behavior? Plot Here is a plot of $y(x)$ satisfying $y(1)=1$ for $n=0$ and $a=100$, $b=1$: Magenta curve: numerically integrated.
Blue curve: WKB result.","['asymptotics', 'ordinary-differential-equations', 'self-learning']"
734248,Example of two open balls such that the one with the smaller radius contains the one with the larger radius.,Example of two open balls such that the one with the smaller radius contains the one with the larger radius. I cannot find a metric space in which this is true. Looking for hints in the right direction.,"['general-topology', 'metric-spaces', 'examples-counterexamples']"
734253,Number of subsets without consecutive numbers,"Consider $S=\{1,2,\ldots,15\}$. Let $X$ denote the number of subsets of $S$ of four elements which contain no consecutive numbers. The claim is that $X$ equals the coefficient of $x^{14}$ in $\dfrac{x^6}{(1-x)^5}$. How would I prove this?",['combinatorics']
734267,Probability a random walk is back at the origin,"I have a symmetric random walk that starts at the origin. With probability $1/6$ it goes right by one and with probability $1/6$ it goes left by one. With probability $4/6$ it stays put.  After $n$ time steps, what is the probability that it is at the origin? The answer should be the probability that you go left by the same amount you go right.  I am having difficulty working this out however.","['random-walk', 'probability']"
734276,Linear Homogeneous Recurrence Relations and Inhomogenous Recurrence Relations,"I'm having some difficulty understanding 'Linear Homogeneous Recurrence Relations' and 'Inhomogeneous Recurrence Relations', the notes that we've been given in our discrete mathematics class seem to be very sparse in terms of listing each step taken to achieve the answer and this makes it incredibly hard for people like myself who are not of a maths background to understand (I'm a computer science student, not a maths student) and I guess my main problem is that I don't understand the notes, as they some to jump steps due to assumed maths knowledge and this is troubling for me coming from a purely computer science background. I was wondering if somebody could write out the steps in order to achieve the answers for these types of questions? I've searched around on youtube and google on guides of how to do them, but they all differ slightly from the one's that we are supposed to learn, and I don't want to learn the wrong thing. I'm not sure if maybe my lecturer has called it something slightly different, but if somebody could help me out, that'd be great. An example question in the notes for Linear Homogeneous Recurrence Relations is: 1. Find the solution of: with And an example of Inhomogeneous Recurrence Relations would be: 2. Find a particular solution of: Here is a second example for a more complicated linear homogeneous recurrence relation: 3. Find the solution: $ a_{n} = a_{n-1} + a_{n-2}$ with $a_{0} = 0 \ and \ a_{1} = 1 $ The lecturer came up with the general solution of $a_{n} = c\left ( \frac{1+\sqrt{5}}{2} \right )^{n} + d\left ( \frac{1+\sqrt{5}}{2} \right )^{n}$ And I just can't see how he got here, is there some way that he has worked this out, or is it pure deduction?","['computer-science', 'recurrence-relations', 'discrete-mathematics', 'education']"
734391,"Alternative Proof for ""Roots of Mertens Function-Farey Sequence-Cosines Relations""","You can write Merten's function as
$$
M(n)= \sum_{a\in \mathcal{F}_n} e^{2\pi i a}   ,
$$
where   $\mathcal{F}_n$   is the Farey sequence of order $n$. The sum may be split into imaginary and real parts, due to $e^{2\pi i a}=\cos(2\pi a)+i\sin(2\pi a)$. Now when you plug in a root of $M(n)$ (I listed some here ), you can easily see that the imaginary part is zero since the Farey sequence is symmetric around $\frac12$. Further when you take $n$ to the limit of infinitely large roots of $M(n)$, the single addends approach the cosine function, $\hskip1.8in$ which again makes it easy to determine the value of the sum resp. integral, but is it possible to prove by other means than Farey and Mertens, like for example trigonometric identities, that the real part is zero? For the non-believers, here the simplest non-trivial example: $$\scriptstyle{
\cos{6/23 \pi}+\cos{2/39 \pi}+\cos{14/39 \pi}-\cos{19/39 \pi}-\cos{5/39 \pi}-\cos{17/39 \pi}+\cos{2/21 \pi}+\cos{2/37 \pi}-\cos{13/37 \pi}-\cos{11/27 \pi}\\
+\cos{6/29 \pi}-\cos{17/37 \pi}+\cos{16/33 \pi}+\cos{10/27 \pi}+\cos{4/29 \pi}+\cos{4/25 \pi}-\cos{9/31 \pi}-\cos{11/37 \pi}-\cos{15/37 \pi}-\cos{7/33 \pi}\\-\cos{13/33 \pi}+\cos{8/39 \pi}+\cos{2/33 \pi}+\cos{8/37 \pi}-\cos{3/35 \pi}-\cos{9/23 \pi}+\cos{14/37 \pi}+\cos{8/23 \pi}+\cos{8/33 \pi}+\cos{2/35 \pi}\\-\cos{1/21 \pi}+\cos{8/21 \pi}+\cos{4/23 \pi}+\cos{14/33 \pi}-\cos{1/37 \pi}+\cos{4/31 \pi}-\cos{7/27 \pi}+\cos{4/37 \pi}-\cos{9/25 \pi}+\cos{8/25 \pi}\\-\cos{3/31 \pi}+\cos{10/31 \pi}+\cos{4/35 \pi}-\cos{7/23 \pi}+\cos{12/37 \pi}-\cos{13/35 \pi}+\cos{12/25 \pi}+\cos{12/35 \pi}+\cos{10/21 \pi}-\cos{9/37 \pi}+\cos{16/39 \pi}+\cos{10/37 \pi}-\cos{7/29 \pi}+\cos{2/29 \pi}-\cos{13/29 \pi}-\cos{11/23 \pi}-\cos{11/35 \pi}+\cos{10/33 \pi}-\cos{3/25 \pi}+\cos{10/23 \pi}+\cos{2/25 \pi}-\cos{5/27 \pi}+\cos{8/29 \pi}-\cos{3/29 \pi}+\cos{6/37 \pi}+\cos{6/31 \pi}+\cos{16/35 \pi}-\cos{3/37 \pi}-\cos{5/23 \pi}-\cos{7/31 \pi}\\-\cos{11/39 \pi}+\cos{2/23 \pi}-\cos{5/33 \pi}+\cos{8/27 \pi}-\cos{13/31 \pi}-\cos{1/27 \pi}+\cos{10/29 \pi}-\cos{1/35 \pi}-\cos{5/21 \pi}+\cos{10/39 \pi}\\-\cos{5/29 \pi}-\cos{1/33 \pi}+\cos{18/37 \pi}+\cos{12/29 \pi}+\cos{4/27 \pi}-\cos{1/31 \pi}+\cos{4/33 \pi}-\cos{7/25 \pi}+\cos{2/27 \pi}+\cos{2/31 \pi}\\+\cos{6/25 \pi}+\cos{14/29 \pi}-\cos{5/37 \pi}+\cos{14/31 \pi}-\cos{17/35 \pi}-\cos{1/29 \pi}+\cos{8/35 \pi}-\cos{13/27 \pi}-\cos{15/31 \pi}-\cos{1/23 \pi}\\+\cos{6/35 \pi}+\cos{4/39 \pi}-\cos{11/31 \pi}-\cos{11/29 \pi}+\cos{16/37 \pi}-\cos{11/25 \pi}-\cos{7/39 \pi}+\cos{12/31 \pi}+\cos{8/31 \pi}-\cos{9/29 \pi}\\+\cos{4/21 \pi}-\cos{7/37 \pi}-\cos{1/25 \pi}-\cos{5/31 \pi}-\cos{1/39 \pi}-\cos{9/35 \pi}-\cos{3/23 \pi} \overset{!}{=}0}
$$","['alternative-proof', 'trigonometry', 'farey-sequences', 'number-theory']"
734395,How to prove that $\frac{r}{R}+1=\cos A+\cos B+\cos C$?,"How do we prove that for any triangle this holds: $$\frac{r}{R}+1=\cos A+\cos B+\cos C$$ I can use this beautiful identity to prove several geometric inequalities, but I have no idea how to prove the identity itself. Can anyone give me hints?","['geometry', 'triangles', 'trigonometry']"
734405,There are no maximal $\mathbb{Z}$-submodules in $\mathbb{Q}$,Is it true that $\mathbb{Q}$ viewed as  $\mathbb{Z}$-module (i.e. abelian group) has no maximal $\mathbb{Z}$-submodules? Why ?,"['modules', 'group-theory', 'abstract-algebra', 'abelian-groups']"
734407,Show $f$ is a complex polynomial of degree at most 2,"Suppose $f:\mathbb{C}\rightarrow\mathbb{C}$ is an entire function and $$\displaystyle\min\{\left|f'(z)\right|,\left|f(z)\right|\}\leq \left|z\right|+2$$ for all $z\in\mathbb{C}$. How to see that $f$ is a polynomial in $z$ of degree at most 2? I can only see it when $\left|f(z)\right|\leq \left|z\right|+2$ by using Cauchy estimate. How to handle $f'(z)$ part together?",['complex-analysis']
734431,Find $\int \limits_0^\pi \sin(\sin(x))\sin(x)\mathrm dx$,Compute $\displaystyle \int \limits_0^\pi \sin(\sin(x))\sin(x)\mathrm dx$. I have no idea how to integrate of this. I do need some help. Thanks,"['definite-integrals', 'calculus', 'integration']"
734453,Is this function monotonically non-decreasing?,"I am wondering if the function $L[n]$ defined on $n=0,1,2,\ldots,N$ below is ""monotonically"" non-decreasing in $n$.  I put monotonically in quotes because the function is not continuous and I am not sure if I can safely use the usual definition of monotone function here. $$\begin{array}{rcl}L[n]&=&\frac{1}{\binom{N}{n}}\sum_{t=0}^{\min(n,M)}\binom{M}{t}p^{t-n}(1-p)^{M-t-N+n}\binom{N-M}{n-t}q^{n-t}(1-q)^{N-M-n+t}\\
&=&\frac{(f_A\ast f_B)[n]}{f_X[n]}\end{array}$$
where $M$, $N$ are integers satisfying $0\leq M\leq N$, and $p$ and $q$ satisfy $0<p<q<1$. The second line gives the definition of $L[n]$ as the likelihood ratio between likelihoods of an observation of a random variable $X\sim\text{Binomial}(N,p)$ and $Y=A+B$, where $A\sim\text{Binomial}(M,p)$ and $B\sim\text{Binomial}(N-M,q)$ (hence the convolution).  This is related to a question I posted on stats.SE .  Any ideas? WHAT I'VE DONE I took the difference $L[n+1]-L[n]$ and came up with the following form: $$L[n+1]-L[n]=\left[\frac{1}{\binom{N}{n}}\sum_{t=0}^{\min(n,M)}l[t]\left(\frac{(N+1)(N-n-M+t)}{(N-n)(n+t+1)}\frac{q(1-p)}{p(1-q)}-1\right)\right]+\frac{\binom{M}{n+1}}{\binom{N}{n+1}}\left(\frac{1-q}{1-p}\right)^{N-M}$$ where $l[t]=\binom{M}{t}p^{t-n}(1-p)^{M-t-N+n}\binom{N-M}{n-t}q^{n-t}(1-q)^{N-M-n+t}$ is the summand in $L[n]$.  It's easy to show that $\frac{q(1-p)}{p(1-q)}>1$ when $q>p$, and if I can show that $\frac{(N+1)(N-n-M+t)}{(N-n)(n+t+1)}>1$ then I am done.  However, I am not sure if that is always true.  Perhaps there is a different way, or I am overlooking something?","['convolution', 'summation', 'probability', 'functions']"
734476,Ideals in direct product of rings [duplicate],"This question already has answers here : Structure of ideals in the product of two rings (5 answers) Closed 7 years ago . I am trying to solve this problem: Let $ R_1,...,R_n$ be rings with identity. Every ideal of $R=\prod_{i=1}^n R_i$ is of the form $\prod_{i=1}^n I_i$  where $ I_i$ is an ideal of $R_i$. The first part is clearly if $J$ an ideal of $R$ then $J\subset \prod_{i=1}^n I_i$, but i can complete the rest..any help..","['ideals', 'abstract-algebra']"
734537,Solve differential equation with variation of parameters?,$$(1-x)y'' +xy' - y = 1-x$$ i) Check if $y_1(x)=e^x$ and $y_2(x) = x$ is a solution to the differential equation (homogeneous). ii) Use variation of parameters to find a general solution to the inhomogeneous equation.  :) Any tips/solution on this one? :D,['ordinary-differential-equations']
734558,Non-Intersecting up-right lattice paths and standard Young Tableaux,"Consider the Lattice $\mathbb{Z}^2$ and an initial set of points with coordinates $(0,u_1)$, $(0,u_2)$, $\cdots$ $(0,u_n)$, final set of points $(m,v_1),(m,v_2),\cdots,(m,v_n)$, where $v_i,u_i$ are strictly increasing and $v_i\leq u_i$. The horizontal axis represents time. I'm considering configurations of up-right paths starting at the points $u$ and ending at $v$ such that: 1) No two paths intersect or overlap at any given time 2) Each path can move only right or up one unit step at a given time 3) Only one path can go up at a given time $t$. Furthermore, after a particular path has taken a vertical step, it must take one horizontal step (so a path cannot go up two vertices at one time step). Taken from wikipedia, here's a configuration (rotated 90 degrees, with time on the vertical axis) that's NOT allowed: this is NOT allowed because the red path jumps twice at time 4. I've seen literature on ""vicious"" walkers but none of them seem to satisfy condition 3. My set of paths bijects strictly to standard Young tableaux. Whereas vicious walkers biject to semi-standard tableaux. Question: is there a general term for such walkers in the literature?","['young-tableaux', 'reference-request', 'combinatorics']"
734607,Showing $\int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \log(\cos(\phi))\cos(\phi) \ d\phi = \log(4) - 2 $,"This is a minor detail of a proof in 'Chaotic Billiards' by Chernov and Markarian which I foolishly decided to verify. It's page 44 of the book, during the proof that lyapunov exponents exist almost everywhere in the collision space (Theroem 3.6) in case anyone is familiar. Though the integral problem stated is independent of any knowledge of this field. I've tried integration by parts but I end up with: $\int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \sin(\phi)\tan(\phi) \,d\phi$ which is non-convergent on the given interval. All help is appreciated! quick edit: log is the natural logarithm","['improper-integrals', 'ergodic-theory', 'integration', 'definite-integrals', 'chaos-theory']"
734615,Proving $\left(\sum_{n=-\infty}^\infty q^{n^2} \right)^2 = \sum_{n=-\infty}^\infty \frac{1}{\cos(n \pi \tau)}$,"The so-called ""two squares theorem"" can be proven by establishing the following identity: $$\left(\sum_{n=-\infty}^\infty e^{\pi i \tau n^2}\right)^2 = \sum_{n=-\infty}^\infty \frac{1}{\cos(n \pi \tau)}$$ where $\Im \tau>0$. Stein and Shakarchi give a lengthy proof in their complex analysis book.  The proof is quite complicated and the motivation is unclear.  I would be interested in a more intuitive (or at least concise) proof of the above identity.","['theta-functions', 'sequences-and-series', 'complex-analysis']"
734649,Derivative of a matrix: Outer product chain rule,"I ran into a seemingly simple matrix calculus question that I can't seem to find the solution to. Suppose I have the following matrices: $X_{(t \times n)}, V_{(n \times m)}$, and $\Phi_{(t\times m)} = f(XV)$ for some differentiable function $f$, which is applied element-wise to the argument $XV$. I would like to calculate $\frac{\partial}{\partial V} \|1^T\Phi\|_2^2$, which I expanded to the outer product (hopefully correctly) as $\frac{\partial}{\partial V} 1^T \Phi\Phi^T 1 = \frac{\partial}{\partial V} 1^T f(XV) f(XV)^T 1^T$. The Matrix Cookbook states that $\frac{d}{dx} \|x\|_2^2 = \frac{d}{dx} \|x^Tx\|_2 = 2x$. However, I'm not 100% certain I can use this in my case. So far I have that $\frac{\partial}{\partial V} 1^T f(XV) f(XV)^T 1 = 2X^T[f(XV) \circ f^\prime(XV)]$ but my gradient checker (gradest in Matlab) is saying this is incorrect. I've been stuck on this all day, can anyone help? I'm trying to figure out a vectorized solution (not involving for loop summations) since this piece of code will be called iteratively for optimization. Edit : I've confirmed that $\frac{d}{d\Phi} \|1^T \Phi \|_2^2 = 2 \cdot 1 1^T \Phi$.","['matrices', 'normed-spaces', 'calculus']"
734664,"How does Hilbert's Nullstellensatz generalize the ""fundamental theorem of algebra""?","What is Hilbert's Nullstellensatz in the sense of the generalization of ""fundamental theorem of algebra""? I've seen that in some texts it was referred to as the generalization of the fundamental theorem of algebra in several variables. How exactly does Hilbert's Nullstellensatz relate to the fundamental theorem of algebra? Also could you please provide some examples to show that it is related?","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra', 'polynomials']"
734689,The fixed points of analytic self-maps of $\mathbb{D}$,"So far, I have assumed that $z_1$ is a fixed point of an analytic self map of $\mathbb{D}$. Then, I summoned the conformal self map of $\mathbb{D}$, $\phi$ to take $z_1\to 0$. It follows from Schwarz Lemma that the composition $\phi \circ f \circ \phi^{-1}$ is either a rotation or $|(\phi \circ f \circ \phi^{-1} )(z)|<|z|$. In either case, $\phi \circ f \circ \phi^{-1}$ has exactly one fixed point: zero. How do I show that if $\phi \circ f \circ \phi^{-1}$ has at most one fixed point in $\mathbb{D}$ then $f$ also has at most one fixed point?","['linear-fractional-transformation', 'conformal-geometry', 'complex-analysis']"
734700,Draws from the uniform distribution are taken until the sum exceeds 1. What is the expected value of the final draw?,"I was thinking about this question after a related problem: what's the expected number of draws for the sum to exceed 1? For that problem, the answer is known and is a surprising result http://mathworld.wolfram.com/UniformSumDistribution.html My intuition is the final draw will be larger than the average draw. This is because larger draws are more likely to make the sum exceed 1, skewing the expectation to be above average. I did a simulation in a spreadsheet with 1 million draws and the estimate I found was the final draw was about 0.655. I have tried many techniques to try and solve this analytically. But none of my answers are close to 0.655, so either my simulation is wrong or my math is wrong (I'm thinking it's my math). Anyone able to help how to write out this expectation? My current method is this: the expectation of the final draw will be the sum from k=2 to infinity of the probability the kth draw makes the sum exceed 1 (this is 1/[k(k-2)!] as explained here ) times the expected value of the final draw--which would range from a lower value of 1 - (sum on turn k-1, given this sum is less than 1) to the upper value of 1. It's this term that is giving me trouble. Or maybe I'm approaching this completely wrong. Any pointers would be great. Also, I'm planning on using this as a puzzle for my blog. I will definitely credit anyone that helps. Thanks.","['probability-theory', 'uniform-distribution', 'expectation']"
734705,Does the inverse of a function from $\mathbb{R}^n$ to $\mathbb{R}^m$ exist?,"Suppose $T:\mathbb{R}^2 \to \mathbb{R}^3$ is defined by $T(x,y) = (x,y,xy).$  What then is the inverse of $T$?  Is it $$T^{-1}: \mathbb{R}^3 \to \mathbb{R}^2; (a,b,c) \mapsto (a,b)?$$  It is clear that, in this case, $T^{-1}(T(x,y)) = (x,y).$ But then $$T(T^{-1}(x,y,z)) = (x, y, xy) \neq (x,y,z).$$  It doesn't seem that this function has an inverse.  This problem seems to extend to any map from $\mathbb{R}^n \to \mathbb{R}^m$ when $n \neq m.$  When are such functions invertible?",['multivariable-calculus']
734762,Proving $\nabla_A tr(ABA^T C) = CAB + C^T A B^T$ [duplicate],"This question already has answers here : How is $\nabla_X \operatorname{Tr}\left\{ X^T A X B\right\} = AXB + A^TXB^T$? (4 answers) Closed 3 years ago . The above equation appears without proof on page 9 (equation 3) of Andrew Ng's notes on Machine Learning I have tried various approaches to prove this to no avail. From the notes it seems that it should be provable from first principles. I tried using the ordinary chain rule on an element by element basis, but this quickly gets unwieldy. Any hint on the approach to resolve this would help a lot.","['trace', 'multivariable-calculus', 'linear-algebra']"
734771,How many ways can six of the letters of the word ALGORITHM be selected and written in a row if the first letter must be A?,"As the title states, the question is: ""How many ways can six of the letters of the word ALGORITHM be selected and written in a row if the first letter must be A?"" I don't really get what the problem is asking me. I know I have to solve it with permutations, but I really don't know where to start or when to know I've come up with the right answer. I know it has to be done through permutations. I'm honestly a little confused on the question they are asking though, if it's saying that it must be ALGORI[][][] where three can be anything in which case it would be (9 + 8  + 7 + 6 + 5 + 4) * 3! Or is it something like P(9,3) = 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2 * 1 / 6 * 5 * 4 * 3 * 2 * 1??","['permutations', 'discrete-mathematics']"
734800,Is there a cipher that yields two separate but valid results depending on the key?,"Suppose the following. Someone wishes to encrypt a message so it is not intercepted.  With traditional ciphers, if the key is guessed correctly, the message is revealed.  This cipher is similar– except that if an incorrect, but intentionally weaker key is guessed, a valid decoy message is revealed to deceive the adversary. So ciphertext + realPassword = ""We attack at 14:30 sharp."" chiphertext + weakPassword = ""We attack at dawn."" Does such a cipher exist, and if so what is its name.","['discrete-mathematics', 'cryptography']"
734836,Maximum and minimum values of intersection of sets,"I know how to do this problem, but my question is more on the proving the inequality and the extreme values. So here is the problem: Of the 24 students in a class, 18 like to play basketball and 12 like to play volleyball. It is given that $\epsilon=\{\text{students in the class}\}$ $B=\{\text{students who like to play basketball}\}$ and $V=\{\text{students who like to play volleyball}\}$. Find the smallest possible value of $n(B\cap V)$ and the largest possible value of $n(B\cap V)$. Answer: $n(B\cap V)$ is smallest when $B\cup V=\epsilon$, so $n(B\cap V)=6$. and $n(B\cap V)$ is largest when $V\subset B$, so $n(B\cap V)=12$. It makes sense and I know how to do this problem, my question is not how to get 6 and 12, but how to prove that: 1. $n(B\cap V)$ is smallest when $B\cup V=\epsilon$ 2. $n(B\cap V)$ is largest when $V\subset B$ I can use the common sense to explain those facts, but is there any formula or inequality that we can use to prove them? Thanks.",['elementary-set-theory']
734866,Convergence in probability to a non-measurable limit,"Let $(\Omega, \mathcal{F}, P)$ be a probability space. Denote the Borel field on $\mathbb{R}$ by $\mathcal{B}$ . Let $\mu: \Omega \rightarrow [0,\infty)$ be a not-necessarily-measurable function and, for every $n \in \mathbb{N}_1 := \{1, 2, \dots\}$ , let $\mu_n:\Omega \rightarrow \mathbb{R}$ be $\mathcal{F}/\mathcal{B}$ -measurable. For every $n \in \mathbb{N}_1$ let $\overline{\mu}_n:\Omega \rightarrow [0,\infty)$ be a not-necessarily-measurable function, such that $\mu, \mu_n \leq \overline{\mu}_n$ and $\lim_{n \rightarrow \infty}\overline{\mu}_n = \mu$ , point-wise, and let $E_n \in \mathcal{F}$ be such that $\lim_{n \rightarrow \infty}P(E_n) = 1$ and such that for every $\omega \in E_n$ , $\mu(\omega) \leq \mu_n(\omega)$ . Does $\mu_n$ converge in probability to $\mu$ , in the sense that for every $\varepsilon \in (0,\infty)$ there is a sequence of events $(F_1, F_2, \dots) \in \mathcal{F}^\infty$ , such that $\lim_{n \rightarrow \infty} P(F_n) = 1$ and such that for all $n \in \mathbb{N}_1$ and all $\omega \in F_n$ , $|\mu_n(\omega) - \mu(\omega)| < \varepsilon$ ? Suppose that for every $\varepsilon \in (0,\infty)$ there is a sequence of events $(F_1, F_2, \dots) \in \mathcal{F}^\infty$ , such that $\lim_{n \rightarrow \infty}P(F_n) = 1$ and such that for all $n \in \mathbb{N}_1$ and all $\omega \in F_n$ , $|\mu_n(\omega) - \mu(\omega)| < \varepsilon$ . Is $\mu$ necessarily $\mathcal{F}/\mathcal{B}$ -measurable? Remark: The motivation for this question is that these two claims (if I understand correctly, as I have paraphrased a little) are stated without proof in the paper Le mouvement Brownien plan (1940) by Paul Lévy (p. 533) as part of Lévy's proof of the fact that a planar Brownian motion's area is $0$ almost surely. $\mu$ is the area of the Brownian motion, $\mu_n$ are measurable approximations to the area and $\overline{\mu}_n$ are non-measurable, convergent approximations. The point is to demonstrate that $\mu$ is measurable as the limit in probability of a sequence of measurable functions.","['probability-theory', 'convergence-divergence']"
734897,Definition/existence/uniqueness of a minimal projective resolution,"I'm reading Dave Benson's book ""Representations and Cohomology,"" Volume I, and I'm trying to understand the following discussion on page $32$ in which he introduces the notion of a minimal projective resolution.  Let $\Lambda$ be a ring and $M$ a left $\Lambda$-module.  The book reads: We write $\tilde{\Omega}^n(M)$ for $\ker(\partial_{n-1})$ in a projective resolution of $M$.  Note that by Schanuel's lemma, if $\tilde{\Omega}^n(M)'$ is similarly defined using another projective resolution of $M$ then there are projective modules $P$ and $P'$ with $\tilde{\Omega}^n(M)\oplus P'\cong\tilde{\Omega}^n(M)'\oplus P$.  If $M$ is finitely generated and the Krull-Schmidt theorem holds for finitely generated $\Lambda$-modules then there is a unique minimal resolution of $M$, and we write $\Omega^n(M)$ for $\ker(\partial_{n-1})$ in this particular resolution. For reference, the Krull-Schmidt theorem holds for a module $M$ if it is a finite direct sum of indecomposable modules, unique up to isomorphism and ordering of summands.  I understand the discussion above except for the phrase ""If $M$ is finitely generated and the Krull-Schmidt theorem holds for finitely generated $\Lambda$-modules then there is a unique minimal resolution of $M$.""  Benson does not define what a minimal resolution is, and it is not clear to me why he introduces the notion in the middle of this discussion.  I have many related questions: What is a minimal projective resolution, why does it exist, and why is it unique? Why do we need the Krull-Schmidt theorem to hold for there to exist a (unique) minimal resolution? Is the initial part of this discussion useful in showing there is a unique minimal resolution, or is Benson introducing the notion of a minimal resolution here to give a definition of $\Omega^n(M)$, that is, is the point of this discussion minimal resolutions or $\Omega^n(M)$?","['homology-cohomology', 'representation-theory', 'abstract-algebra', 'homological-algebra', 'modules']"
734909,Missing solution in quadratic equation,"This is a reformulation of this question to better fit this forum. I removed the mentioning of sage math and this question is now 100% math. Given, the following quadrilateral: I want to describe the position of point X in terms of a multiple $t$ of the vector $HG$. The points $H$ and $G$ themselves are described by multiples $s$ of the vectors $DC$ and $AB$, respectively. We end up with the following equations: $$
X = H + t(G-H) \\
H = s(C-D)+D \\
G = s(B-A)+A \\
$$ As an example, lets take the following quadrilateral: $$
A=(1,2) \\
B=(3,2) \\
C=(2,0) \\
D=(0,0) \\
$$ We want to find $s$ and $t$ describing the point $X=(1.25,0.5)$ in the quadrilateral. Here a sketch of the geometric setup: One can easily see that $X$ cuts $HG$ at $t=0.25$ and that $H$ and $G$ cut $DC$ and $AB$ at $s=0.5$, each. This is also affirmed by inserting $s=0.5$ and $t=0.25$ into the formulas above. It will result in $H=(1,0)$ and $G=(2,2)$ and $X=(1.25,0.5)$ (the original point). Now I want a formula which, given any point $X$ inside the quadrilateral gives me $s$ and $t$. To that end I rearrange the above three formulas and solve for $s$ and $t$. After plugging in $H$ and $G$ into $X$, there are two equations, one for the x-coordinates and one for the y-coordinates of the points. Since there are two missing variables $s$ and $t$ this should be solvable. Since the derivation is super lengthy I started out with letting sage math solve it for me. I wrote about my experience and failure in this question I already mentioned above. To rule out any problem with sage math I ended up doing it by hand. Here is the derivation for $s$: $$
X = H + t(G-H) \\
H = s(C-D)+D \\
G = s(B-A)+A \\
s = \frac{X_x +t(D_x- A_x) - D_x}{C_x-D_x+t(B_x-A_x-C_x+D_x)} \\
t = \frac{X_y +s(D_y- C_y) - D_y}{A_y-D_y+s(B_y-A_y-C_y+D_y)} \\
$$ Plugging in $t$ into $s$ we arrive at a quadratic equation (my full derivation exists but is commented out for readability - it is the same solution sage math gives): $$
0 = as^2 + bs + c \\
s_{1,2} = \frac{-b\pm\sqrt{b^2-4ac}}{2a} \\
a = (D_x-C_x)(B_y-A_y-C_y+D_y)-(D_y-C_y)(B_x-A_x-C_x+Dx) \\
b = (D_y-A_y)(C_x-D_x)+(X_x-D_x)(B_y-A_y-C_y+D_y)-(X_y-D_y)(B_x-A_x-C_x+D_x)-(A_x-D_x)(D_y-C_y) \\
c = (A_y-D_y)(X_x-D_x)-(A_x-D_x)(X_y-D_y) \\
$$ As you can see, one ends up with a quadratic equation with parameters $a$, $b$ and $c$ given in the last lines. My derivations should be correct because as far as I can see they equal the result I got in sage math. Now, when one plugs in the example values for $A$, $B$, $C$ and $D$ into $a$, then the result will be zero. This will result in a division by zero. My question: clearly from a geometric point of view, there is a solution for $s$ and $t$ for the example values of $A$, $B$, $C$ and $D$. Why is there none when solving the equation for $s$ and $t$? And more practically: how can I determine $s$ and $t$ for any given $A$, $B$, $C$, $D$ and $X$ without running into this problem? If I can find the solution for this, then it would solve this question . Here the values $a$, $b$ and $c$ that solve $0=at^2+bt+c$: $$
a = (D_y-A_y)(B_x-A_x-C_x+D_x)-(D_x-A_x)(B_y-A_y-C_y+D_y) \\
b = (D_y-A_y)(C_x-D_x)+(X_y-D_y)(B_x-A_x-C_x+D_x)-(X_x-D_x)(B_y-A_y-C_y+D_y)-(C_y-D_y)(D_x-A_x) \\
c = (C_x-D_x)(X_y-D_y)-(C_y-D_y)(X_x-D_x) \\
$$ Unsurprisingly, the solution for $t$ works analogous to $s$.","['geometry', 'quadratics', 'vectors']"
734957,Characteristic function of the Binomial distribution converges to that of the Poisson,"Find conditions on $\lambda, n, p$, so that the characteristic function of the Binomial converges to that of the Poisson Binomial distribution is given as $P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}$ Poisson distribution is given as $P(X=k)=\frac{\lambda^ke^{-\lambda}}{k!}$ So characteristic function of binomial: $\phi_X(t)=E(e^{itX})=\sum_1^n \binom{n}{k} e^{itk} p^k(1-p)^{n-k}=\sum \binom{n}{k} (e^{it}p)^k (1-p)^{n-k}=(pe^{it}+(1-p))^n$ and that of Poisson in a similar way:$\quad$$e^{\lambda(e^{it}-1)}$ Now my questions: 1) We defined Expectation with integral, why here with a sum ? 2) Can you give me a hint to solve the problem ?","['probability-theory', 'probability-distributions']"
734963,How much close should two spaces be in the Gromov-Hausdorff distance to be homeomorphic?,"Here I am considering the Gromov-Hausdorff convergence for metric spaces. I know two compact metric spaces are isometric if and only if $d_{GH}(X,Y)=0$, where $d_{GH}$ denotes the Gromov-Hausdorff (pseudo)distance. I was wondering if a weaker assumption (e.g. $d_{GH}(X,Y)$ small enough) could imply homeomorphism between $X$ and $Y$. To be more concrete, I am especially interested in the following problem: let $(X,d)$ be a metric space and let $d_n$ a sequence of metrics on $X$ such that $(X,d_n)$ converges to $(X,d)$ in the Gromov-Hausdorff convergence. Can I say that the topology induced by $d_n$ is equivalent to the native topology (induced by $d$) of $X$, at least for $n$ large enough?","['general-topology', 'convergence-divergence', 'metric-geometry', 'metric-spaces']"
734976,Exactness of the pullback of the Euler sequence,"Let $(L,V)$ be a base point free $g^r_d$ on a curve $C$. Then we have an exact sequence $0\rightarrow M_{L,V}\rightarrow\mathcal{O}_C^{r+1}\xrightarrow{\theta} L\rightarrow 0$, where we just let $M_{L,V}$ to be the kernel of $\theta$. People usually consider this sequence as the pullback of the (first twist of) Euler sequence $0\rightarrow \Omega_{\mathbb{P}^r}(1)\rightarrow \mathcal{O}_{\mathbb{P}^r}^{r+1}\rightarrow\mathcal{O}_{\mathbb{P}^r}(1)\rightarrow 0$ via the morphism $\varphi\colon C\rightarrow \mathbb{P}^r$, which is induced by $(L,V)$. I could not see that so far. Pulling back the Euler sequence with $\varphi$ clearly yields the exact sequence, $\varphi^*(\Omega_{\mathbb{P}^r}(1))\rightarrow\mathcal{O}_C^{r+1}\xrightarrow{\theta} L\rightarrow 0$. So showing exactness of the left most map would yield the claim, but I don't see why this should be the case. Any ideas? Actually this is my general problem. If I pullback an exact sequence with a non-flat map then I have no clue about the exactness of the resulting sequence. What is a good way to analyze this problem in general? Considering the long exact sequence with Tor sheaves or trying to right down the explicit map and making a brute force calculation?","['vector-bundles', 'algebraic-geometry', 'algebraic-curves']"
734985,Product of Hölder and Sobolev functions,"Here $C^{\kappa , \lambda} ( \overline{\Omega} ) = \left\{
h|_{\overline{\Omega}} :h \in C^{\kappa , \lambda} ( \mathbb{R}^{n} ) \text{ 
and } h \text{  has compact support} \right\}$ denotes $\kappa$ times Hölder continuously differentiable functions in $\overline{\Omega}$ and $W^{s,p}(\Omega)$ is the usual Sobolev space with possibly non-integer exponent $s\geq0$. Proposition: Let $\Omega \subset \mathbb{R}^{n}$ be open, bounded and Lipschitz. Let $s
  \geq 0 ,1 \leq p< \infty$ and $v \in W^{s,p} ( \Omega ) ,h \in C^{\kappa
  , \lambda}_{c} ( \overline{\Omega} )$ where $\kappa \in \mathbb{N}_{0} ,
  \lambda \in ( 0,1 ]$ and $\kappa + \lambda \geqslant s$ if $s \in
  \mathbb{Z}$ and $\kappa + \lambda >s$ otherwise. Then the product $hu \in
  W^{s,p} ( \Omega )$ and there exists a constant such that
  $$ \| hu \|_{W^{s,p} ( \Omega )} \leqslant C \| u \|_{W^{s,p} ( \Omega )}. $$ Attempt at proof: The case $s \in \mathbb{N}_0$ is easy since the Sobolev norm doesn't involve the Slobodecijk seminorm and I can use that all partial derivatives of $h$ are uniformly bounded. However, for non integer $s=\lfloor s \rfloor+t, t \in (0,1)$ this seminorm does appear: $$ \| u \|_{W^{s,p} ( \Omega )} := \sum_{| \alpha | \leqslant \lfloor s
\rfloor} \| D^{\alpha}  u \|^{p}_{L^{p} ( \Omega )} + \sum_{| \alpha | =
\lfloor s \rfloor} \underset{\Omega \times \Omega}{\int \int} \frac{|
D^{\alpha}  u ( x ) -D^{\alpha}  u ( y ) |}{| x-y |^{n+tp}} d x d
y. $$ And I don't know how to handle the double integrals. Even in the simplest situation where $\lfloor s \rfloor=0$, I don't know how to bound above the integral $$ \underset{\Omega \times \Omega}{\int \int} \frac{| h ( x ) u ( x ) -h ( y ) u
( y ) |}{| x-y |^{n+tp}} d x d y. $$ I fear this might be some trivial inequality, but I just can't see it. Any help would be greatly welcome.","['sobolev-spaces', 'holder-spaces', 'analysis']"
734988,Why does $f(x)=ax^2 + bx + c \ge 0\ \forall x \in \mathbb R$ imply $f$ has at most one real distinct root and discriminant $D \le 0$?,"Why does $f(x)=ax^2 + bx + c \ge 0 \ \forall x \in \mathbb R$ imply $f$ has at most one real distinct root and discriminant $D \le 0$? I've been wondering why the following result is true. Intuitively it seems to be true if you consider the graph of a polynomium of degree 2 that doesn't intersect the $x$-axis twice. However this is by no means rigorous and I think the answer should be simple, since the text is introductory.","['calculus', 'algebra-precalculus']"
735024,"Why is $-\Delta+1$ an isomorphism between Sobolev space $W^{2,p}$ and $L^p\,$?","Consider the linear elliptic operator $L: W^{2,p}(\mathbb{R}^N)\to L^p(\mathbb{R}^N)$ defined by $Lu=-\Delta u + u$. Can we prove that $L$ is an isomorphism for all $p\geq 1$? It can be proved that it is true when $p=2$ (by classical Fourier analysis), however when $p\neq2$ the usual Fourier analysis does not work well (Fourier transform is not a isomorphism on $L^p(\mathbb{R}^N)$ if $p\neq2$).","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations', 'analysis']"
735031,First order differential equation confusion,I have a differential equation $$y' + e^{y'}-x=0$$ that I have simplified like so $$e^{y'}=x-y'$$ $$\ln e^{y'}=\ln (x-y')$$ $$y'= \ln (x-y')$$ but I do not know how to solve this further to obtain the general solution. I have done first order linear differential equation strategies so far. How should I get about doing this question with the strategies I have?,['ordinary-differential-equations']
735041,Limit of a recursive sequence $s_n = (1-\frac{1}{4n^2})s_{n-1}$,"I have $$s_1 = 1, s_n = (1-\frac{1}{4n^2})s_{n-1}.$$ I see that its limit exists, but cannot figure out what the limit is. How do I find its limit? The only way I used (know) is:
$$\lim s_n = \lim s_{n+1}$$
But here, I am just getting $L = L$. Also, when I program this sequence on computer it's approaching to $0.636619...$ and Wolfram Alpha is giving me complicated recurrence equation solution.","['sequences-and-series', 'limits']"
735066,Vector spaces and intersections,"I was thinking of the following problem lately: Suppose $V_1,V_2,V_3,V_4$ are vector subspaces of $\Bbb{R}^4$ of dimension $2$ such that $V_i\cap V_j=\{0\}$ for $i \neq j$. Is it true that we can find a two dimensional vector subspace of $\Bbb{R}^4$ such that $\dim V_i\cap W =1$ for $i=1,2,3,4$? The same problem with all dimensions doubled was given to a Miklos Schweitzer competition in 2012. Using a linear automorphism of $\Bbb{R}^4$ we can assume that $V_1=span\{e_1,e_2\},V_2=span\{e_3,e_4\}$ where $(e_1,e_2,e_3,e_4)$ is the canonical base. It is rather easy to construct $W$ which satisfies $\dim W\cap V_i = 1$ for $i=1,2,3$ but I didn't manage connecting it to the fourth space.","['vector-spaces', 'linear-algebra']"
735071,Compute the density of $Y=|X|$ when $X$ is normally distributed,"When $X$ has the normal distribution $\mathcal N(\mu,\sigma^2)$
  , compute the density of $Y=|X|$ I know $\displaystyle\int_{-\infty}^{\infty}\frac{1}{\sigma\sqrt{2\pi}}\exp\Big(-\frac{-(x-\mu)^2}{2\sigma^2}\Big)dx=1$ but the choice of $\mu$ doesn't change the result (integral is always 1), So if we take $\mu=0$ then the function gets even and since $Y$ supports only the positive part we have to multiply the distribution by 2, but can we then translate it back and this is our function ? $2^{nd}$ Question: what is the difference between distribution and density, in this case they seem to be the same or not ?","['probability-theory', 'normal-distribution', 'probability-distributions']"
735075,Statistics Primer for the Unwary Mathematician,"I have a new position in a biology department (after being housed in a maths department) working on cognitive and population modeling. People in my lab are asking for help with applying statistical tests to their data set, but when people say ""chi-squared"", I say, ""wikipedia"". I'd like to pick up a statistics book that is aimed at teaching someone with a fairly solid background in math and probability theory how to apply standard statistical tests to real data sets, and that goes into some of the practical issues with doing so. Ideally I'd like a book that focuses on frequentist statistics -- my own research deals with Bayesian modeling, and (ironicly) I have a far easier time understanding and working with the more complex Bayesian data analyses that people bring to me than simpler frequentist analyses e.g. ANOVA hybrids","['statistics', 'applications', 'book-recommendation', 'reference-request']"
735085,difference between weak* convergence and convergence,"I am trying to prove the following: If $X$ is a finite-dimensional space, then for sequences $\left\{x_n\right\}\subseteq X$ and $\left\{f_n^*\right\}\subseteq X^*$, if there exists an $x\in X^*$ such that $x_n \rightharpoonup x$ and $f_n\stackrel{*}{\rightharpoonup} f$, then we have $x_n\rightarrow x$ and $f_n \rightarrow f$. I already figured out how to prove that weak convergence implies regular convergence: Suppose $x_n \rightharpoonup x$ and that $X$ is of finite dimension $m$. Let $\left\{e_1, \ldots, e_m\right\}$ be the basis of $X$. Then we can write any $x_n=\displaystyle \sum_{i=1}^m c_{i,n}e_i$ and $x=\displaystyle \sum_{i=1}^m c_ie_i$, where $c_{i,n}, c_i \in \mathbb{R}$. Let $\left\{f(e_1), \ldots , f(e_m)\right\}$ be the basis of $X^*$. Since $f(x_n)\rightarrow f(x)$ in $X^*$, this implies that 
$$\left\|f(\sum_{i=1}^m c_{i,n}e_i)-f(\sum_{i=1}^m c_ie_i)\right\|=\left\|f(\sum_{i=1}^m (c_{i,n}-c_i)e_i) \right\| \rightarrow 0,$$ which is true if and only if $c_{i,n}\rightarrow c_i$ for all $i\in \left\{1, \ldots, m\right\}$. Thus, $\left\|x_n-x\right\|=\left\|\sum_{i=1}^m (c_{i,n}-c_i)e_i\right\|\leq \sum_{i=1}^m |c_{i,n}-c_i|\left\|e_i\right\| \rightarrow 0$, that is, $x_n \rightarrow x$. \ I don't know how to show that $f_n\stackrel{*}{\rightharpoonup} f$ implies $f_n \rightarrow f$ and I think it's mostly because I don't see the difference between the two. Can someone show me how to prove this? Thank you!","['linear-algebra', 'functional-analysis', 'real-analysis', 'analysis']"
735092,Cofinite topology on an infinite set $X$ is connected?,"Here is my proof of that the cofinite topology on an infinite set $X$ is connected. $X$ is connected $\iff$ There are no non-empty disjoint open subsets $U, V \subseteq X$ such that $U \cup V = X$. Let $U, V \in X$ be non-empty disjoint open subsets of $X$ such that $U \cup V = X$. As $U \cup V = X$ and $U \cap V = \emptyset$, $\implies U^c = V$ and $V^c = U$. $\implies U$ and $V$ are finite sets. $\implies U \cup V$ is finite. But $U \cup V = X$ which is infinite so we have a contradiction. Hence there are no non-empty disjoint open subsets $U, V \subseteq X$ such that $U \cup V = X$. So $X$ is connected. Is my understanding correct?","['general-topology', 'connectedness']"
735093,Method of solving extended Euclidean algorithm for three numbers?,"I already got idea of solving gcd with three numbers. But I am wondering how to solve the extended Euclidean algorithm with three, such as: 47x + 64y + 70z = 1 Could anyone give me a hint? Thanks a lot.","['elementary-number-theory', 'number-theory']"
735121,"$g$ a restriction of a homeomorphic function $f$, $g$ also homeomorphic?","Let $f:X \to Y$ be a homeomorphism between topological spaces $X$ and $Y$. Let $A \subseteq X$ and $B = f(A) \subseteq Y$ (given the subspace topology) and let $g: A \to B$ be the restriction of $f$ given by $g(a) = f(a)$ for $a \in A$. Showing that $g$ is a homeomorphism. $g$ injective Let $g(a_1) = g(a_2)$, $a_1, a_2 \in A$. $\implies f(a_1) = f(a_2)$ $\implies a_1 = a_2$ as $f$ homeomorphic. g surjective Let $y \in B$ $\implies y = f(a)$ for some $a \in A$. $\implies y = g(a)$ for some $a \in A$. $g$ continuous Let $U \subseteq B$ be an open set in $B$. $f(a) = g(a)$ for all $a \in A => f^{-1}(b) = g^{-1}(b)$ for all $b \in B$. So $g^{-1}(U) = f^{-1}(U)$ which is open in $A$ as $f$ homeomorphic. $g^{-1}$ continuous Let $U \subseteq A$ be an open set in $A$. $g(U) = f(U)$ which is open in $B$ as $f$ homeomorphic. So $g$ is homeomorphic. Is my understanding correct, this seems almost too straightforward so I was wondering have I overlooked something?",['general-topology']
735163,"Order and element set of the group with presentation $\langle a,b \;|\; a^9=1, b^3=a^3, [a,b]=a^3\rangle$","If we have a group presentation $G=\langle a,b \;|\; a^9=1, b^3=a^3, [a,b]=a^3\rangle$, how we will get the following values: The order of the group. The elements of the group written in terms of the generators","['gap', 'finite-groups', 'group-theory', 'p-groups']"
735164,Lebesgue measurable homework problem,"Let $X \subseteq \mathbb{R}$. A subset $E \subseteq \mathbb{R}$ is called a hull of $X$ if $E$ is measurable $X \subseteq E$ If $F$ is any measurable set such that $X \subseteq F$, then $E$\ $F$ is a zero set A hull of $X$ should be thought of as a sort of ""smallest"" measurable set containing $X$.
This is made precise in the problem. (a) Prove that every subset of $\mathbb{R}$ has a hull (b) Prove that if $E_{1}$ and $E_{2}$ are both hulls of $X$, then $E_{1}$\ $E_{2}$ and $E_{2}$\ $E_{1}$ are zero sets. Thus the hull of $X$ is unique up to zero sets (c) Let E be a hull of X. Prove that $m(E)=m^{*}(X)$ The hint says to consider the case $m^{*}(X)< \infty$, then consider the case let $R_i=(i,i+1)$ for $i \in \mathbb{Z}$. Let $X_i=X \cap R_i$. Then $X=\cup_{i \in \mathbb{Z}} X_{i} \cup \mathbb{Z}$. I need help to prove this.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
735217,What is the remainder when 4 to the power 1000 is divided by 7,"What is the remainder when $4^{1000}$ is divided by 7?
In my book the problem is solved, but I am unable to understand the approach. Please help me understand - Solution  - To find the Cyclicity, we keep finding the remainders until any
  remainder repeats itself. It can be understood with the following
  example: No./7    ->    $4^1$  $4^2$  $4^3$  $4^4$  $4^5$  $4^6$  $4^7$  $4^8$ Remainder -> 4 2 1 4 2 1 4 2 Now $4^4$ gives us the same remainder as $4^1$, so the Cyclicity is of
  3 (Because remainders start repeating themselves after $4^3$ So any power of 3 or multiple of 3 will give the remainder of 1. So,
  $4^{999}$ will give remainder 1. Final remainder is 4. Now I don't understand the last line. Please explain, how the remainder comes down to 4?","['modular-arithmetic', 'elementary-number-theory', 'divisibility', 'number-theory']"
735245,Coding Theory Problem to save Humanity,"For starters, this problem doesn't originate from me, it's a friend's coding theory problem and I got interested, thinking about it, but I can't think of any as I only have very basic coding theory knowledge. (I'm not taking that course btw) So the problem goes as follows~ A perverse extra terrestrial force has captured 7 humans, out of desire to get a clue about the intelligence of the human race. The next day, they will be put to a test; if they succeed, they will be returned home safely and humanity will probably not be bothered anymore, however if they fail, they will all be disposed of, and humans will be seen as weak and suitable for enslaving.... They are told the following: The next day, each of them will get a hair-coloring, at random, either blond or black, without knowing which. After hair-coloring, they will be all brought together. At that moment, each person will be able to see everyone's hair-color except their own. Then, every person is required to either guess their own hair-color by writing the color on a piece of paper, or to refrain from guessing. All pieces of paper are collected; if all guessers guess correct, with at least one person guessing , they succeed the test, but if at least one guesser guesses it wrong, they fail. Then they are sent off to discuss their strategy... What should they do? An obvious strategy is to design one person to randomly guess a color; that will save the humanity half of the times. However, they can do (much) better. Imagine you are one of the seven, provide the team with a good strategy.... (Hint: Think of the coloring as an unknown binary word, and think of the missing color as a possible error) So, what could possibly be a good method?","['coding-theory', 'recreational-mathematics', 'probability']"
735249,"real analysis, chebyshev's inequality","Suppose $f$ is a non negative integrable function on a measure space $(X,M,μ)$. Prove that:
$$\lim_{t \rightarrow \infty} t\cdot \mu(\{x:f(x)\geq t\} )=0.$$ Can you help me please?","['measure-theory', 'integration', 'real-analysis']"
735253,"In Fermat's little theorem, if mod is not prime?","Today I learned about Fermat's little theorem It says - Fermat's little theorem states that if p is a prime number, then for
  any integer a, the number a p − a is an integer multiple of p. In the
  notation of modular arithmetic, this is expressed as $a^p \equiv a \mod p$ It considers ""p"" as a prime numbers. But what if ""p"" is not prime? Then if those cases how to solve this type of problems?",['number-theory']
735283,Convergence of an alternating series : $ \sum_{n\geq 1} \frac{(-1)^n|\sin n|}{n}$,"Study the convergence of $$\displaystyle \sum_{n\geq 1} \frac{(-1)^n|\sin n|}{n}.$$ I am stuck with this series, we need probably some measure of irrationally of $\pi$, unfortunately I am unfamiliar with this. So here is my attempt : Let $f(x) = \sum \frac{|\sin{n}|}{n} x^n, |x| < 1$ It's not difficult to compute the Fourier series of $|\sin(x)|$ : $$
\displaystyle|\sin(x)|=\frac{2}{\pi}-\frac{4}{\pi}\sum_{n=1}^{+\infty}\frac{\cos(2nx)}{4n^2-1}
$$ Then Fubini's theorem ( Series Version ) works very well (because the previous series converges absolutely at $x$ fixed ) and all calculations made, we find that for all $x\in( -1,1)$: $$
\displaystyle f(x)=\frac{2}{\pi}\sum_{n=1}^{+\infty}\frac{x^n}{n}-\frac{4}{\pi}\sum_{p=1}^{+\infty}\frac{x^2-2x\cos(p)}{(4p^2-1)(x^2-2x\cos(p)+1)}
$$ However, the second sum I have not been able to show the convergence. I feel the series diverge because the following series
$$
\displaystyle\sum\frac{1}{p^2\sin^2\left(\frac{p}{2}\right)}
$$ diverge because  $0$ is an accumulation point of $\displaystyle (n\sin(n))$ sequence. Any ideas (for the original series) ?","['sequences-and-series', 'real-analysis']"
735287,Need help to solve taylor series of $e^{\sin x}$,"How to derive the taylor series of $e^{\sin x}$, up to $x^5$? i just don't know how to get the answer
$$f(x) = 1 + x + \frac{x^2}{2} - \frac{x^4}{8} -\frac{x^5}{15}$$ really need some help. Thanks",['algebra-precalculus']
735290,Show that $g\in\mathcal{L}^q(\mu)$.,"Let $(X,\mathcal{A},\mu$) be a finite measure space and $p,q\in(0,\infty)$ such that $1/p+1/q=1$. Let $g\in\mathcal{M}(\mathcal{A})$ measurable function such that $$\int |fg|d\mu\leq C\|f\|_p$$ for all $f\in\mathcal{L}^p(\mu)$ and some constant $C$. Show that $g\in\mathcal{L}^q(\mu)$ I understand that Holder's Inequality does the reverse argument with $C=\|g\|_q$, but i don't know how to bend this into a proof.","['measure-theory', 'integration']"
735320,compactness in topology of pointwise convergence,"I started reading about the topology of pointwise convergence. So far I do not feel quite comfortable with this theory. Maybe one can help me out in a more concrete example case. Let's consider sequences, so $a : \mathbb{N} \to \mathbb{R},x \mapsto a(x)$. In the topology of pointwise convergence it holds now that $$(a)_n \to (A) \iff (a(x))_n \to A(x),\forall x \in \mathbb{N} \quad (1)$$ I hope so far I somehow boiled it down correctly to that concrete case. Now I wonder what it means for a set $\mathcal{S} \subseteq \mathbb{R}^\mathbb{N}$ of sequences to be compact in the topology of pointwise convergence. First, I need to get a feeling about ""open sets"" in that topology and how (1) defines those open sets -- I do not quite get the link. After that I would need to show, that every open cover of $\mathcal{S}$ has a finite subcover, right? What would that mean precisely, I mean in doing.. ADDED STUFF Consider we want to show, that $\mathcal{S} \subseteq \mathbb{R}^\mathbb{N}$ is compact in the topology of pointwise convergence. By, $S_n$ we denote the projections. Assume we know, that all $S_n$ are bounded. Further assume, that for every sequence in $\mathcal{S}$ we know, that the resulting projected sequences have a convergent subsequence of which the limit lies in the corresponding $S_n$. Does this suffice to show that $\mathcal{S}$ is compact?","['general-topology', 'convergence-divergence', 'compactness', 'analysis']"
735340,how to determine a function of a specific shape,"I have become very passionate about mathematics lately, but one question is really irritating me, HOW do you determine a function for ANY specific shape ? Is there a certain procedure that enables me to get a function out of a random shape or curve ? I use this a lot in machine learning but all i do is apply some functions and formulas made by some mathematician and i really would like to know if initially i could get to at least have a vague idea of how a function would look like or even how a shape would be if written in a function","['algebra-precalculus', 'functions', 'polynomials']"
735344,"An exercise from Revuz, Yor; equality in distribution of 2 integrals.","Here is the exercise I have been struggling to solve. It is taken from this book by Revuz and Yor: link . Here is the full text of the problem ( Exercise 3.32, chapter 4). Exercise (3.32) . Let $B$ and $C$ be two independent Brownian Motions started at $0$. Prove that $$
\int _0 ^1 (B_t + C_{1-t})^2 dt \,{\buildrel (d) \over =}\, 
\int _0 ^1 (B_t ^2 + (B_1 - B_t)^2) dt
$$ [Hint: The Laplace transform in $(\frac{\lambda ^2 }{2})$ of the right-hand side is the characteristic function in $\lambda$ of the sum of two stochastic integrals; see Exercise (2.19)] I have been trying to apply formula 
$E \exp(\lambda M_t) = E \exp (\frac{\lambda ^2}{2} \langle M , M \rangle _t)$ for a continiouos martingale $M$, but I wasn't able to come up with a good idea what should be $M$. For example, we may write $$
 E \exp\left(\frac{\lambda ^2 }{2} \int _0 ^1 B_t ^2  dt\right) =
E \exp\left(\frac{\lambda ^2 }{2} \int _0 ^1 (B_1-B_t) ^2  dt\right)=
  E \exp\left(\lambda \int _0 ^1 B_t dB_t\right)
$$
but it did not help me. Addition Here are some 
computations. Set $W_t = C_1 - C _{1-t}$. $W$ is a BM independent on $B$, and $$
 E \exp\left(\frac{\lambda ^2 }{2} \int _0 ^1 (B_t + C_{1-t}) ^2  dt\right) =
  E \exp\left(\lambda \int _0 ^1( B_t + C_{1-t} )dB_t\right)
$$
$$
=E \exp\left(\lambda \int _0 ^1( B_t + W_1 - W_t )dB_t\right)
=E \exp\left(\lambda \int _0 ^1 B_t dB_t+ \lambda B_1 W_1
- \lambda \int _0 ^1 W_t dB_t\right) :=F
$$ Because $W$ and $B$ are independent, we have 
$B_1W_1 = \int _0 ^1 W_t dB_t +\int _0 ^1 B_t dW_t$, so $$
F = E \exp\left(\lambda \int _0 ^1 B_t dB_t
+ \lambda \int _0 ^1 B_t dW_t\right) = 
$$
$$
= E \exp\left(\lambda \int _0 ^1 B_t d(B_t + W_t)\right) = 
E \exp\left(\frac{\lambda ^2 }{2}2\int _0 ^1 B_t ^2 dt\right),
$$
the last equality due to relation $\langle B+M,B+M \rangle_t = 2t$. So, it should be $$
\int _0 ^1 (B_t + C_{1-t})^2 dt \,{\buildrel (d) \over =}\, 
2\int _0 ^1 B_t ^2  dt.
$$ May it be true?","['stochastic-processes', 'stochastic-integrals', 'probability-theory', 'stochastic-calculus', 'brownian-motion']"
735380,Is there a name for the group of complex matrices with unimodular determinant?,"Does the group
$$
G
=
\left\{ A \in \mathbb{C}^{n \times n} : |\det(A)| = 1 \right\}
$$
have a name?  It obviously contains the unitary group $U(n)$ and the special linear group $SL(n,\mathbb C)$. After googling a few variantions of ""matrices with unimodular determinant"" and coming up empty, I thought that I would see what people here think. Edit: Notice that $G$ is strictly larger than both $U(n)$ and $SL(n)$.  Consider
$$
A=\begin{pmatrix} 1 & 1 \\ 0 & -1 \end{pmatrix}.
$$
We have $A \in G$, but $A$ is not unitary and $A \notin SL(2,\mathbb C)$. Even though $G \neq SL(n,\mathbb C)$, they are related in the sense that $S^1 \times SL(n,\mathbb C) $ is an $n$-fold cover of $G$ -- the covering is defined by $(z,A) \mapsto z \cdot A$.  (This is an $n$-to-1 map because $\det(zA) = z^n \det(A)$ for $n \times n$ matrices $A$).","['linear-algebra', 'lie-groups']"
735395,Generate correlated random numbers precisely,"Let's assume I want to generate k samples of n random numbers, that are correlated according to a given correlation matrix C (e.g. $n = 3$): 1    0.3  0.3
0.3    1  0.3
0.3  0.3    1 Using Cholesky Decomposition (Python implementation from NumPy), I can calculate L so $C = LL^T$: L = [[ 1.          0.          0.        ]
     [ 0.3         0.9539392   0.        ]
     [ 0.3         0.22013982  0.92819096]] Generating n (uncorrelated) random numbers (using numpy.random.normal($\mu$, $\sigma$) ) and multiplying each the vector with L should result in one sample with n correlated random variables. – So far my understanding of the algorithm. When I check the random numbers with SPSS, the ""observed"" correlations differ from the ones given in C . Example: I choose $n = 3$, $k = 10 000$ and $r = 0.99$. The observed correlations are: V1        V2        V3
V1     1          .774      .578
V2      .774     1          .443
V3      .578      .443     1 For my use-case I will need random numbers, that represent the given correlation matrix precisely. Did I make a mistake in this process or did I misunderstand the algorithm? Some insight is much appreciated.","['statistics', 'correlation', 'random']"
735400,"If p $\equiv$ 3 (mod 4) with p prime, prove -1 is a non-quadratic residue modulo p.","If p $\equiv$ 3 (mod 4) with p prime, prove -1 is a non-quadratic residue modulo p. I suppose this would not be true if p $\equiv$ 1 (modulo 4). 
To prove something is a non-square I find to be tricky. It's difficult to see any straightforward way to do this using only the definition of congruence for example.","['elementary-number-theory', 'number-theory']"
735407,"Rank two vector bundle on $\mathbb P^1$, with trivial canonical bundle","I would like to show that the total space $X$ of the rank $2$ vector bundle $E=\mathscr O_{\mathbb P^1}(-1)\oplus\mathscr O_{\mathbb P^1}(-1)$ on $\mathbb P^1$ has trivial canonical bundle $\omega_X$. So we have the structure morphism $p:X=\textbf{Spec }(\textrm{Sym }E)\to \mathbb P^1$, and the exact sequence
$$0\to p^\ast\Omega_{\mathbb P^1}\to \Omega_{X}\to \Omega_{X/\mathbb P^1}\to 0,$$
which may be rewritten as 
$$0\to \mathscr O_X(-2)\to \Omega_X\to \Delta^\ast(I/I^2)\to 0,$$
where $I\subset \mathscr O_{X\times_{\mathbb P^1}X}$ is the kernel of the canonical map $\mathscr O_{X\times_{\mathbb P^1}X}\to \Delta_\ast\mathscr O_X$ induced by the diagonal morphism $\Delta:X\to X\times_{\mathbb P^1}X$. We have
$$\omega_X=\wedge^3\Omega_X=\mathscr O_X(-2)\otimes \wedge^2\Delta^\ast(I/I^2)=\mathscr O_X(-2)\otimes\Delta^\ast\bigl(\wedge^2(I/I^2) \bigr),$$ but I am not able to show that $\wedge^2(I/I^2)\cong \mathscr O_{X\times_{\mathbb P^1}X}(2)$. Thank you for your help!",['algebraic-geometry']
735461,Unit in the image of a cp map,"This is another question which looks non-trivial to me. Suppose that we have a completely positive map $f\colon M_n \to M_m$ such that $f(a) = I_m$, the identity matrix on $M_m$. Is there a positive element $b\in M_n$ such that $f(b)=I_m$?","['operator-algebras', 'functional-analysis']"
735462,Projective points of a Fermat Curve,This is a problem from my coding theory book which I am trying to wrap my head around. Consider the curve $f_3F(q)$ given by $x^3+y^3+z^3=0$ A) Find the three projective points (x:y:z) of $P^2(F_2)$ on $f_3(F_2)$ B) Find the nine projective points (x:y:z) of $P^2(F_4)$ on $f_3(F_4)$ Attempt: A) I think the answer is (1:0:1);(1:1:0);(0:1:1). B) I am getting a little stuck here since there are 16 points which hold with the curve. I know that we have to concern ourselves with equivalences here but when I look at equivalences I end up with only 6 points not 9. Work part B) Since $1^3 = 1$  $2^3 = 0$ and $3^3 = 3$ over $F_4$ (1:0:3)~(2:0:2)~(3:0:1) ; (1:2:3)~(2:0:2)~(3:2:1) ; (1:3:0)~(2:2:0)~(3:1:0) ; (1:3:2)~(2:2:0)~(3:1:2) ; (0:1:3)~(0:2:2)~(0:3:1) ; (2:1:3)~(0:2:2)~(2:3:1) ; (3:1:0)~(2:2:0)~(1:3:0) So what am I missing/doing wrong here?,"['algebraic-geometry', 'coding-theory']"
735486,A $2\times2$ Matrix inequality,"$M,N$ are  $2\times2$ real matrices, and $MN=NM$. Then, for any three real numbers $x,y,z$, we have $$4xz\det(xM^2+yMN+zN^2)\geq(4xz-y^2)\big(x\det(M)-z\det(N)\big)^2 $$ some thought: 1). calculate directly, we got
 $$ \det(A-xB)=x^2\det(B)-\big(\operatorname{Tr}(A)\operatorname{Tr}(B)-\operatorname{Tr}(AB)\big)x+\det(A) $$ 
(where $A,B$ are $2\times2$  matrices). 2). $ 4xz\cdot \det(xM^2+yMN+zN^2)= 4x^3z\cdot \det(M-mN)\det(M-nN) $ But I don't know how to go ahead. Thanks a lot!","['matrices', 'linear-algebra', 'inequality', 'determinant']"
735499,I need someone to explain this proof from James Munkres' Topology.,"The author writes $(X-C)\cap Y = Y-A,$ and, also, $A=Y \cap (X-U)$. I was wondering how is that something anyone writing an original proof of the theorem saw and if there is an analytic proof that the equalities holds true. Thanks for your help.",['general-topology']
735515,Learning Mathematics through Programming.,"I am about to embark on a 'comprehensive' and thorough study of undergraduate mathematics. In the interests of efficiency and a desire to improve my programming skills, I ask: In oppose to the pen and paper approach, would it be advisable to implement all of the problems I encounter in the textbooks in a programming language?
Would there be any downside to this with regards to understanding the material?
I am not talking about allowing the computer to solve the problem for me, just that I would like to implement the step by step process in a programming language.I will be using Python and later on C++, Haskell, Lisp and Java. Thanks in advance.",['discrete-mathematics']
735550,Equivalence of weak forms of Hilbert's Nullstellensatz,"The version of the Nullstellensatz with which I am familiar states that if $K$ is an algebraically closed field, and $f_1,\dots,f_n\in K[X_1,\dots,X_m]$, then the family $\{f_i\}$ has a common zero iff $\langle f_1,\dots,f_n\rangle\neq K[X_1,\dots,X_m]$. However, another form I have heard of states that if $K$ is algebraically closed, then the maximal ideals of $K[X_1,\dots,X_m]$ are precisely those of form $(X_1-a_1,\dots,X_m-a_m)$ for some $a_i\in K$. Can anybody explain how the first form implies the second?","['algebraic-geometry', 'abstract-algebra']"
735556,Tensor fields and vector bundles,"Let $M$ be a differentiable manifold, $TM$ and $T^*M$ a tangent and cotangent bundle of $M$ and let $\Gamma (TM),\ \Gamma (T^*M)$ be spaces of smooth sections of $TM$ and $T^*M$. Let $T_s^r (M)$ denote a space of smooth tensor fields on $M$. Since vector field on $M$ is a smooth section of $TM$, clearly $$T_0^1 (M)=\Gamma (TM)$$ and similarly 
$$T_1^0 (M)=\Gamma (T^*M).$$ My question is related to something I saw in some lecture notes on differential geometry. 
There was a definition of a tensor field as a smooth section of 
$TM \otimes \dots \otimes TM \otimes T^*M \otimes \dots \otimes T^*M$. But since these bundles are not vector spaces, it seems a little suspicious to me. I think the product of (co)tangent bundles may be DEFINED ""fiber-wise"" in the following sense $$ TM \otimes TM \equiv \bigcup_{p \in M} \{T_pM \otimes T_pM\} \ \tag{*}$$
(disjoint union). This would also correspond with the definition of tensor field I know. Since tensor field of some type is a map which assigns to every point $p \in M$ a tensor from $T_pM \otimes \dots \otimes T_pM \otimes T_p^*M \otimes \dots \otimes T_p^*M$ smoothly,
one has $$ T_s^r (M) = \Gamma \left( \bigcup_{p \in M} \{T_pM \otimes \dots \otimes T_pM \otimes T_p^*M \otimes \dots \otimes T_p^*M\}\right).$$ So my question is whether the following equalities are true: $$ \bigotimes^r TM \otimes \bigotimes^s T^*M  = \bigcup_{p \in M} \{\bigotimes^r T_pM  \otimes \bigotimes^s T_p^*M\}\ \tag{1}$$ $$\Gamma \left( \bigotimes^r TM \otimes \bigotimes^s T^*M \right) = 
  \bigotimes^r \Gamma (TM) \otimes  \bigotimes^s \Gamma (T^*M) \ \tag{2}$$ and if the tensor product of (co)tangent bundles is not defined the way I proposed in $(*)$, what is the correct definition or from which more general concept it follows?","['notation', 'tensors', 'differential-geometry']"
735558,For which $m$ is this sum of roots of unity $0$?,"A professor at my university gave me the following problem: For what real values of $m$ do we have
  $$L=\lim_{N\to\infty}\frac{1}{N}\sum_{k=1}^Ne^{2\pi ik^3m}=0$$ If $m$ is rational, expressed as $\frac{a}{b}$, then let $$\sum_{k=1}^be^{\frac{2a\pi ik^3}{b}}=c$$ Then we have that $L$ is equal to $\frac{c}{b}$, so that $L=0$ if and only if $c=0$.  However, I don't find it an easy problem to determine what rational numbers give $c=0$.  And I'm really unsure how to solve the problem for irrational $m$. Any ideas?","['exponential-sum', 'convergence-divergence', 'sequences-and-series', 'number-theory', 'complex-numbers']"
735592,Examples of contractions between functional spaces,"Define $\mathcal{F}$ as the following set of continuous functions: $$ \mathcal{F} := \left\{ f: \mathbb{R} \rightarrow \mathbb{R}^n \mid f(\cdot) \  \text{contin.}, \ f(x) \in K(x) \subset \mathbb{R}^n \ \forall x \in \mathbb{R}, \ K(x) \neq \varnothing \ \text{compact, } K(\cdot)  \ \text{contin.}  \right\} $$ I am looking for examples of contractions operator $\mathcal{C}: \mathcal{F} \rightarrow \mathcal{F}$.","['continuity', 'functional-analysis', 'functions']"
735618,A variation of the isoperimetric problem in the plane,"The isoperimetric problem in the plane : « The classical isoperimetric problem dates back to antiquity. The
  problem can be stated as follows: Among all closed curves in the plane
  of fixed perimeter, which curve (if any) maximizes the area of its
  enclosed region? This question can be shown to be equivalent to the
  following problem: Among all closed curves in the plane enclosing a
  fixed area, which curve (if any) minimizes the perimeter? » The solution is well-known to be the circle, so, a way for varying the problem is to add constraints preventing the circle as solution.  Of course, there are plenty of possibilities, here is one: A well-known theorem in geometry of the plane : Given three distinct points, there is a circle crossing these points iff they are non-collinear. Problem : Among all closed curves in the plane of fixed perimeter $p$ and crossing three distinct collinear points $A$, $B$ and $C$,
  which curve (if any) maximizes the area of its enclosed region? Example : $p=8$, $A=(-1,0)$, $B=(0,0)$ and $C=(1,0)$ Candidate : let the cardioid of parametric equation $z=\frac{i}{2}(e^{i \theta}-i)^2$, $\theta \in [0, 2 \pi]$: This curve  of perimeter $8$ and area $6\pi/4 \simeq 4.71$, crosses the points $A$, $B$ and $C$. Is it a solution of the problem? the unique solution (up to reflection)?","['geometry', 'calculus', 'calculus-of-variations', 'analysis']"
735621,"Collection of half open intervals is an algebra, why?","I have to show, why the collection of all finite unions of such half open intervals $(a,b]$ is an algebra and not a sigma algebra. I know that $−∞≤a≤b≤∞$, and have: $$
(a,b)=\bigcup_{n=1}^∞ \left(\right.a,b−\frac1n\left.\right]
$$
But how can I say from this, that it is an algebra? I will say that it is a sigma-algebra, since the union has the limits to infinity.",['measure-theory']
735638,Fermat last theorem,Can someone please give the original paper by Prof. Wiles of the proof of Fermat's Last Theorem? I cannot find it.,['number-theory']
735653,consecutive prime power,"I'm interesting on consecutive prime power numbers. I see that there is the Mersenne primes and the Fermat Primes that give solutions and $(8,9)$. In Sloane collection it is referred on A006549 and it is written: David W. Wilson and Eric Rains found a simple proof that in this case of Catalan's conjecture either n or n+1 must be a power of 2 and the other number must be a prime, except for n=8. But I can't find this proof on the web (and I don't find it myself...). I tried the first case. I get a proof for $2^k+1=3^q$, but found it complicated. If someone has something simple? Simple: I see that it's enough to consider the case $(2^k, q^n)$ because... ok it's clear I see that it's enough to show that $2^k=-1$ mod $q$ or $q^2$ is impossible. But for exemple that give nothing for $2^k+1=5^q$ because $2$ is primite modulo $5$ and $25$ and so modulo all the $5^q$.","['arithmetic', 'elementary-number-theory', 'number-theory']"
735656,Integral inequality problem,"Let $f:[0,1]\to\mathbb R$ be a differentiable function with $f(0)=0$ and $f'(x)\in(0,1)$ for every $x\in(0,1).$  Show that
$$\left(\int_0^1f(x)dx\right)^2>\int_0^1(f(x))^3dx$$
I am not even sure how to begin to solve this problem.  Any help/hints is appreciated.  Thanks.","['integration', 'analysis']"
735663,Evaluating $\int_0^{2 \pi} \sin^4 \theta\: \mathrm{d} \theta$,Evaluate the following integral: $$\int_0^{2 \pi} \sin^4 \theta \:\mathrm{d} \theta$$ My approach: Parametrize and obtain $$\frac{1}{(2i)^4} \int_{|z|=1} \left (z-\frac{1}{z} \right)^4 \frac{1}{iz}\:\mathrm{d}z=\frac{1}{(2i)^4} \int_{|z|=1} \left (\frac{(z+1)(z-1)}{z} \right)^4 \frac{1}{iz}\:\mathrm{d}z$$ Can I directly use the residue theorem from here with a residue at $z=0$?,['complex-analysis']
735665,Why is cosine a sine function with offset pi/2?,"I was looking at this question and stumbled across this answer stating that the picture proves ""Why cosine is simply sine but offset by pi/2 radians"" I realized I don't know why this is true. So! Why is cosine sine with an offset pi/2?",['trigonometry']
735679,What is the Coxeter diagram for?,"I understand that  Coxeter diagrams are supposed to communicate something about the structure of  symmetry groups of  polyhedra, but I am baffled about what that something is, or why the Coxeter diagram is clearer, simpler, or more useful than a more explicit notation.  The information on Wikipedia has not helped me. Wikipedia tells me, for example, that the Coxeter diagram for a cube is , but I don't understand why it is this, in either direction; I don't understand either how you could calculate the Coxeter diagram from a knowledge of the geometry of the cube, or how you could get from the Coxeter diagram to an understanding of the geometric properties of the cube. I gather that the three points represent three reflection symmetries, and that the mutual angles between the three reflection planes are supposed to be $45^\circ, 60^\circ, $ and $90^\circ$, but I can't connect this with anything I know about cubic symmetry. Nor do I understand why it is perspicuous to denote these angles, respectively, with a line marked with a 4, an unmarked line, and a missing line. My questions are: What information is the Coxeter diagram communicating? Why is this information useful? How does it relate to better-known geometric properties? What are the applications of the diagram? What makes it a good notation?  Is it used for its concision, or because it is easy to calculate with, or for some other reason? Where is a good place to start understanding this?","['coxeter-groups', 'geometry', 'notation', 'polyhedra', 'reference-request']"
735695,Function whose inverse is also its derivative?,"What are some good examples of a function  $f : \mathbb{R} \to \mathbb{R}$ where its derivative is equal to its inverse? I attempted to find a monomial that satisfied it by starting with $f(x) = ax^b$ and showing that $f^{-1}(x) = f'(x) \implies b-1=\frac{1}{b} \implies b=\phi$ and got
$$f(x) = \frac{x^\phi}{\sqrt[\phi]{\phi}}$$
Which seems to work according to WolframAlpha, but I'm having trouble double-checking it. Any other ideas?","['ordinary-differential-equations', 'functional-equations']"
735703,Lebesgue integrability and measurable functions,"Let $f$ be a nonnegative function on the reals. What does the (Lebesgue) measurability of $f$ have to do with the (Lebesgue) integrability of $\int f$? I've spent some time studying the definition at Wikipedia , and I don't see how measurability enters the equation (other than the fact that it is explicitly mentioned at the start). If $f$ is such that every simple function less than $f$ has integral less than some $x\in\Bbb R$, then $\int f\in\Bbb R$ is defined, regardless of the measurability of $f$. What ""essential properties"" are lost without the assumption of $f$ being measurable? Full discosure: I've asked this question before , but I put too much tangentially-related text on the page, and so probably lost some viewers.","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
735728,Question about soluble and cyclic groups of order pq,"I'm trying to solve the following problem: If $p>q$ are prime, show that a group $g$ of order $pq$ is soluble. If $q$ doesn't divide $p-1$, show that $pq$ is cyclic. Show that two non abelian subgroups of order $pq$ are isomorphic. Progress: Let's show that $G$ is soluble. Let $n_p$ be the number of $p$-Sylows of $G$ and $q$ be the number of $q$-Sylows of $G$ By the Sylow theorems, there is only one $p$-Sylow since $n_p\equiv 1 (mod\,p)$ and $n_p | q<p$. Therefore there exists only one $p$-Sylow normal subgroup $P$. Therefore we know that: $\{e\}\unlhd P \unlhd G$. $P/\{e\}\approx P$ is abelian since $P$ is cyclic (because $|P|=p$) and $G/P$ is abelian since $|G/P|=q$. Now suppose $q$ does not divide $p-1$. We know that $q|(n_q-1)$ and that $n_q|p$, therefore $n_q=1$ or $p$. $n_q$ cannot be $p$ since $q$ doesn't divide $p-1$. Therefore there is only one $Q$ $q$-Sylow subgroup and $G\approx P \times Q \approx \mathbb Z_p\times \mathbb Z_q$. Since $\mathbb Z_{pq}$ is abelian it's the product of all it's Sylow subgroups $P'$ and $Q'$, therefore $\mathbb Z_{pq}=P'\times Q'\approx \mathbb Z_p\times \mathbb Z_q$. It follows that $G$ is cyclic. It remains to show that two non abelian groups of order $pq$ are isomorphic. That's where I'm stuck. Strategy: Let $G, H$ with $|G|=|H|=pq$ be two non abelian groups. By the preceding paragraph, it's easy to see that both have a single $p$-Sylow and $p$ $q$-Sylows. I tried to build an isomorphism by sending a generator of each of these subgroups of $G$ into a generator of a subgroup of $H$, but I'm not managing to prove it works. Can someone help me with this last part and say if my solution for the preceeding parts is ok?","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
735770,An awful identity,"We take place on $\mathbb C(x_1,...,x_r,x'_1,...,x'_p,u_0,...,u_r,u'_0,...,u'_p)$ with $r,p\in \mathbb N$ Show that :
  $$\displaystyle{\sum_{i=1}^r \left(   \frac{\prod_{j=0}^r (u_j-x_i) \prod_{j=1}^p (x'_j-x_i) }{  \prod_{1\leq j\leq r, j\neq i     }(x_j-x_i) \prod_{j=0}^p (u'_j-x_i)}      \right)}-\displaystyle{\sum_{i=0}^p \left(   \frac{\prod_{j=0}^r (u'_i-u_j) \prod_{j=1}^p (u'_i-x'_j) }{  \prod_{0\leq j\leq p, j\neq i     }(u'_i-u'_j) \prod_{j=1}^r (u'_i-x_j)}      \right)}=\displaystyle{\sum_{i=1}^p x'_i +\sum_{i=0}^r u_i -\sum_{i=1}^r x_i-\sum_{i=0}^p u'_i}$$ I have seen this exercise in an old book at the library. Unfortunately there was no indication how can I solve the problem. Anyway if someone can give me some ideas it will be greatful. NB: Sorry for the title, I have not had other ideas","['polynomials', 'calculus', 'analysis']"
735782,Find all natural numbers such that $\sum_{k=1}^{n} \frac{n^k}{k!}$ is an integer,"Find all natural numbers such that $\sum_{k=1}^{n} \frac{n^k}{k!}$ is an integer. I've tried to bring all fractions under commmon denominator and it didn't helped me much. With guessing I find out that only $n=1,2,3$ satisfy the condition, but I can't prove that they are the only ones. I tried to evaluate the series and then work with the result, but I didn't made any progress.","['sequences-and-series', 'number-theory', 'fractions', 'elementary-number-theory', 'summation']"
735793,Supremum of $\{\sqrt[n]{n}:$ $n \in \mathbb{N}\}$ and $ \{\sqrt[x]{x}:$ $x \in \mathbb{R}_{>0}\}$,"I would like to calculate the supremums of these sets: $\{\sqrt[n]{n}:$ $n \in \mathbb{N}\}$ and $ \{\sqrt[x]{x}:$ $x \in \mathbb{R}_{>0}\}$ I don't know how to start, any help is appreciated.","['calculus', 'limits']"
735794,Series for envelope of triangle area bisectors,The lines which bisect the area of a triangle form an envelope as shown in this picture It is not difficult to show that the ratio of the area of the red deltoid to the area of the triangle is $$\frac{3}{4} \log_e(2) - \frac{1}{2} \approx 0.01986.$$ But this is also $$\sum_{n=1}^{\infty}\frac{1}{(4n-1)(4n)(4n+1)}.$$ Is there any connection between the series and the deltoid? Or is it just a coincidence? ( I asked this at MathOverflow almost 18 months ago and got no response),"['geometry', 'triangles', 'sequences-and-series', 'area']"
735796,Any ring is integral over the subring of invariants under a finite group action,"I need to prove that if $G$ is a finite group that acts on ring $A$, and $A^G$ is the subring consisting of elements of $A$ which are invariant under all $g\in G$, then $A$ is integral over $A^G$. (Atiyah and Macdonald, Chapter 5, Exercise 12) The hint with the problem is to state that each $x\in A$ must be a root of the polynomial $\prod_{g\in g}(t - g(x))$, but this is only guaranteed to be in $A[t]$. I can't think of any reason why this product, or some important factor of it such as $t - x$ where the $g$ involved is the identity, would only have coefficients in $A^G$, which is the only way I know of to finish the proof. Is there a better way, or am I missing some obvious fact about the groups/rings involved here?","['commutative-algebra', 'ring-theory', 'group-actions', 'abstract-algebra']"
735842,Function $f: \mathbb{R} \to \mathbb{R}$ that takes each value in $\mathbb{R}$ three times,"Does there exist a function $f: \mathbb{R} \to \mathbb{R}$ that takes each value in $\mathbb{R}$ three times? If not, how could I prove that such a function does not exist?","['functions', 'examples-counterexamples', 'real-analysis']"
