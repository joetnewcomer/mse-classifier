question_id,title,body,tags
3820936,How many $ax^2+bx+c=0$ with distinct pairs of rational roots can be made from integers $N=|ac|=|\alpha\beta|$ and $b=\alpha+\beta$?,"Only for illustration, let's choose an integer $N=6$ . I want to create a collection of all possible quadratic equations in the form of $ax^2+bx+c=0$ where $|ac|=|\alpha\beta|=N=6$ , and $\alpha+\beta=b$ . Note that all constants are integers but $x$ is not necessarily integer. Here is my attempt. How many ways to specify $a$ and $c$ The prime factors of $N$ is $$
P=\{2,3\}
$$ The all possible pairs of $(a,c)$ are $$
\{(1,\pm 6), (6,\pm 1), (2,\pm 3), (3,\pm 2)\}
$$ Here I don't need to consider the case in which $a<0$ because, for example, $6x^2+5x-1=0$ is actually identical to $-6x^2-5x+1=0$ . Only the sign of $b$ and $c$ do matter here.
From $2^2=4$ subsets of $P$ , we can create $\frac{2^2}{2}=2$ ""partitions"", each ""partition"" can be assigned to $(a,c)$ in $2!=2$ ways, and $c$ can have two choice of signs. Thus there are $$
\frac{2^2}{2}\times 2! \times 2 = 8
$$ ways to create $(a,c)$ . How many ways to specify $b$ The all possible pairs of $(\alpha,\beta)$ are $$
\{(\pm 1,\pm 6), (\pm 2,\pm 3)\}
$$ Therefore  the all possible values of $b$ are $$
\{\pm |1+6|, \pm |1-6| = \pm |2+3|, \pm |2-3|\} = \{\pm 7, \pm 5, \pm 1 \}
$$ I cannot find an easier way to calculate how many possible ways to determine $b$ because the same $b$ can be obtained from two (or possibly more) ""partitions"". For example, partition $\{1,6\}$ and $\{2,3\}$ can produce $b=\pm 5$ as follows. $$
\pm |1-6| = \pm |2+3|
$$ As we can see, there are $3\times 2=6$ ways to assign $b$ . Final Thus in total, we have $8\times 6=48$ quadratic equations. I have not checked programmatically whether all of these equations have distinct pair of roots. Question Generally speaking, for any positive integer $N$ , how many quadratic equations (with the constraints given above) are possible to make?",['combinatorics']
3821043,Is there a meaning to $\mathrm{e}^{H(p_{i})}$ or $2^{H(p_{i})}$?,"In my research I find an equation featuring the ""exponential entropy"" term $\mathrm{e}^{H(p_{i})}$ and I wonder if it has a specific meaning. I have only found rare references to that term (usually in terms of dispersion or ""spread of the distribution"") so I'm looking for more insights. I work with natural logarithms and in my case the entropy is Shannon's: $H(p_{i})=-\sum{ p_{i}\ln p_{i}}$ ... My question is: what is $\mathrm{e}^{H(p_{i})}$ ? Note: I assume that the same question would arise if I were to work in log-base 2... So  is there a meaning to $2^{H(p_{i})}$ when entropy is now defined by $H(p_{i})=-\sum{p_{i}\log_{2} p_{i}}$ ?","['descriptive-statistics', 'statistics', 'entropy', 'statistical-mechanics']"
3821061,Solve differential equation: $y' = \frac{y^2}{x^3} + 2\frac{y}{x} - x$,"I need to solve this differential equation: $y' = \frac{y^2}{x^3} + 2\frac{y}{x} - x$ . My attempt I found that $y = x^2$ is a solution. Then I tried to put $y = x^2f(x)$ , and solved this way: $$2xf(x) + x^2f'(x) = xf^2(x) + 2xf(x) - x \implies x^2f'(x) = xf^2(x) - x \implies$$ $$xf'(x) = f^2(x) - 1 \implies \frac{df(x)}{f^2(x) - 1} = \frac{dx}{x} \implies$$ $$\frac{1}{2}\ln\left|\frac{f(x) - 1}{f(x) + 1}\right| = \ln|x| + C_* \implies \frac{f(x) - 1}{f(x) + 1} = Cx^2 \implies$$ $$f(x) = \frac{1 + Cx^2}{1 - Cx^2}$$ And we lost a solution $f(x) = -1$ . So finally we have $$y = x^2\frac{1 + Cx^2}{1 - Cx^2}, y = -x^2$$ Now I have 3 questions: $\quad 1)$ Is my solution correct? I'm not sure that all solutions were found. $\quad 2)$ When can we use particular solution to find all other solutions? I mean doing something like $y = g(x)h(x)$ , where $g(x)$ is a particular solution. $\quad 3)$ Is there an easier method to solve this equation?","['solution-verification', 'ordinary-differential-equations']"
3821101,compact operator between $L^{p}(\mu)$ and $C(X)$,"I'm solving the exercise of Conway's functional analysis.
I'm trying this question. Let $X$ be a compact space and let $\mu$ be a positive Borel measure on $X$ . Let $T \in \mathcal{B}(L^p(\mu) , C(X))$ where $1<p<\infty$ . Show that if $A :  L^p(\mu) \to L^p(\mu)$ is defined by $Af = Tf$ then $A$ is compact. I think that if we use fact that $L^p(\mu)$ is reflexive and if $A$ is completely continuous, then we can solve this problem because this indicate $A$ is compact operator. So, I assumed that $f_n \to 0$ weakly, i.e. ( $\int_X f_n g d\mu \to 0$ for every $g \in L^q(\mu)$ ) and tried to show that $\int_X (Tf_n)^p d\mu \to 0$ .
However, I cannot approach to next step. Thank you.","['lp-spaces', 'compact-operators', 'functional-analysis']"
3821150,Is the multiplication in the ring of functions which are flat at the origin a surjective map?,"Denote by $C^{\infty}_0(\mathbb{R}^n)$ the ring of all smooth functions which are flat at the origin, i.e \begin{align}C^{\infty}_0(\mathbb{R}^n):=\{f\in C^{\infty}(\mathbb{R}^n)|\forall i_1, \dots ,i_n \in \mathbb{N}_0 : \partial_1^{i_1}\dots \partial_n^{i_n}f(0)=0\} 
\end{align} In particular we have \begin{align}f\in C^{\infty}_0(\mathbb{R}^n) \ \Rightarrow f(0)=0
\end{align} Let $C^{\infty}_0(\mathbb{R}^n)$ be equipped with the standard ring structure induced from the ring of functions. Is the multiplication \begin{align}C^{\infty}_0(\mathbb{R}^n)\times C^{\infty}_0(\mathbb{R}^n)&\to C^{\infty}_0(\mathbb{R}^n)\\(f,g)\ \ \ \ \ \ \ \ \ \ \ \ &\mapsto \ \ \ f\cdot g
\end{align} a surjective map? What are (standard) references in the literature, where this type on non-unital rings are discussed?","['abstract-algebra', 'reference-request', 'real-analysis']"
3821185,Let $a$ be an integer. Prove that the following equation cannot have more than one integer $x^4+7x^3+(a+2)x^2-11x+a=0$,"Let $a$ is a interger. Prove that the following equation cannot have more than one integer $$x^4+7x^3+(a+2)x^2-11x+a=0$$ $$x^4+7x^3+(a+2)x^2-11x+a=0$$ Or $$-\frac{x^4+7x^3+2x^2-11x}{x^2+1}=x^2+7x+1-\frac{18x+1}{x^2+1}=a$$ When $a\in \mathbb{Z}$ that means $$(x^2+1)\mid (x^4+7x^3+2x^2-11x)$$ Or $$(x^2+1)\mid (18x+1)\rightarrow 18x+1\ge x^2+1$$ Or $$0\le x\le 18$$ Now i tried all value and got only $x=0$ and $x=18$ are roots that satified. $$x=0\rightarrow a=0 \text{   or   } x=18\rightarrow a=-450 $$ Now i tried to solve this equation egain with $a=0$ and $a=-450$ and each value of $a$ get only one integer root of $x$ and it is done. I don't know if my solution is correct.Help me check it and give me some solution,ty..","['algebra-precalculus', 'solution-verification']"
3821223,Problem finding the normal bundle,"Consider the quadric hypersurface $C=V(x_0x_3+x_1x_4+x_2x_5)\subset\mathbb{P}^5$ . It is obvious $C$ containes two $\mathbb{P}^2$ 's given by the equation $\mathbb{P}^2_a=V(x_3,x_4,x_5)$ and $\mathbb{P}^2_b=V(x_0,x_1,x_2)$ . I'd like to compute the normal bundle $\mathcal{N}_{\mathbb{P}^2_a\mid C}$ , so I thought I could use the sequence $$\mathcal{N}_{\mathbb{P}^2_a\mid Y}\to \mathcal{N}_{\mathbb{P}^2_a\mid C} \to \mathcal{N}_{Y\mid C}|_{\mathbb{P}^2_a}$$ where $Y$ is a subvariety of $C$ containing $\mathbb{P}^2_a$ . The problem is that I can't find a suitable subvariety, and I'm quite stuck since I don't know much on how to compute the normal bundle, outside this formula (and the one for the case of an hyperplane). Thanks in advance!","['vector-bundles', 'algebraic-geometry']"
3821249,"How to understand the meaning of ""extension"" in Caratheodory extension theorem","We are studying Caratheodory extension theorem at the moment, in the note, we stated that A measure $\mu$ on a field $\mathcal{C}$ can be extended to a measure
on the $\sigma$ -field generated by $\sigma[\mathcal{C}]$ generated by $\mathcal{C}$ , by defining $$\mu(A)\equiv\mu^*(A) \text{ for each } A\in\mathcal{A}\equiv\sigma[\mathcal{C}].$$ If $\mu$ is $\sigma$ -finite on $\mathcal{C}$ , then the extension is unique on $\mathcal{A}$ and is also $\sigma$ -finite. The $\mu^*$ is defined in the previous text where stated: Let $\Omega$ be arbitrary: Let $\mu$ be a measure on a field $\mathcal{C}$ of subsets $\Omega$ . For each $A\in 2^\Omega$ $$\mu^*=\inf\{\sum^\infty_{n=1}\mu(A_n):A\subset\cup^\infty_{n=1}A_n\text{
 with all } A_n\in\mathcal{C}\}$$ I am struggled to understand what really the word ""extension"" means. So far we have: defined the outer measure on $2^\Omega$ which is by construction a $\sigma$ -field and a largest possible one. We know so long as $\mu:\mathcal{A}\rightarrow[0,+\infty)$ satisfies three conditions it is a well-defined measure: 1) $\mu(\emptyset)=0$ ; 2) $\mu(A)\geq0, \forall A\in \mathcal{A}$ ; 3) countably additivity $\mu(\sum^\infty A_n)=\sum^\infty\mu(A_n)$ for all disjoint $A_n\in\mathcal{A}$ ; defined outer measure which is defined on $2^\Omega$ instead of an arbitrary field. For outer measure, we have three conditions to hold 1) $\mu^*(\emptyset)=0;2)\mu(A)\leq\mu(B)\text{ for all } A\subset B;3)$ countably subadditivity: $\mu(\cup^\infty A_n)\leq\sum^\infty \mu(A_n)$ for all $A_n\in2^\Omega$ ; defined $\mu^*$ -measurable: let $A\subset\Omega$ , $A$ is measuable if $\mu(T)=\mu(TA^c)+\mu(TA)$ for all $T\subset\Omega$ . The theorem in its literal meaning means we have first defined $\mu$ on $\mathcal{C}$ which is a field (yes, I understand) and we can EXTEND it to define it on $\sigma[\mathcal{C}]$ . I am struggling to understand such extend is to what extend? I think we made several extensions in mathematical analysis as well but I never felt I understand the meaning of extension. Does that mean a certain property is preserved? Does that mean we can simply use what we have defined so far to define something new? Or does it mean something else? I checked some wiki pages as well but none helped me understand the term. I hope my question makes sense!","['measure-theory', 'probability-theory']"
3821268,"Prove that $\inf\limits_{z \in S^{\perp}} \| x - z \| = \sup \left \{ \lvert \langle x , y \rangle \rvert\ \big |\ y \in S, \|y \| \leq 1 \right \}.$","Let $H$ be a Hilbert space and $S$ be a subspace of $H.$ Let $x \in H$ and $\left \|x \right \| = 1.$ Prove that $$\inf\limits_{z \in S^{\perp}} \left  \|x - z  \right \| = \sup \left \{\left \lvert \left \langle x , y \right \rangle \right \rvert\ \big |\ y \in S, \left \|y \right \| \leq 1 \right \}.$$ My attempt $:$ Let $L = \inf\limits_{z \in S^{\perp}} \left  \|x - z  \right \|$ and $M = \sup \left \{\left \lvert \left \langle x , y \right \rangle \right \rvert\ \big |\ y \in S, \left \|y \right \| \leq 1 \right \}.$ If $x \in S^{\perp}$ then clearly $L = 0$ and $M = 0$ (because if $x \in S^{\perp}$ then for any $y \in S$ we have $\left \langle x,y \right \rangle = 0$ ). Also if $x \in S$ then we have \begin{align*} L & = \inf\limits_{z \in S^{\perp}} \sqrt {\|x\|^2 + \|z\|^2} \\ & = \inf\limits_{z \in S^{\perp}} \sqrt {1 + \|z\|^2} \\ & = \sqrt {1 + \inf\limits_{z \in S^{\perp}} \|z\|^2} \\ & = 1 \end{align*} and for all $y \in S$ with $\|y\| \leq 1$ we have by Cauchy Schwarz's inequality $$\left \lvert \langle x,y \rangle \right \rvert \leq \|x\| \|y\| \leq 1.$$ This shows that $M \leq 1.$ Also since $x \in S$ with $\|x\| = 1$ we have by taking $y = x$ $$\langle x,x \rangle = \|x\|^2 = 1.$$ So $M = 1.$ Therefore $L = M$ holds if $x \in S \cup S^{\perp}.$ Now $H = S \oplus S^{\perp}.$ So every element of $H$ can be written as $x = u + v,$ where $u \in S$ and $v \in S^{\perp}.$ For this case \begin{align*} \|(u+v) - z \|^2 & = \|u+v\|^2 + \|z\|^2 - \langle v , z \rangle  - \langle z , v \rangle \\ & = \|u+v\|^2 + \|z\|^2 - 2 \mathfrak {R} \left ( \langle v,z \rangle \right ) \\ & \geq \|u+v\|^2 + \|z\|^2 - 2 \left \lvert \langle v , z \rangle \right \rvert \\ & \geq \|u+v\|^2 + \|z\|^2 - 2\|v\| \|z\| \\ & = \left (\|u+v\|^2 - \|v\|^2 \right ) + \left (\|z\| - \|v\| \right )^2 \\ & \geq \|u+v\|^2 - \|v\|^2 \end{align*} So by taking $z = v$ we have $$L = \sqrt {\|u+v\|^2 - \|v\|^2} = \sqrt {\|u\|^2 + 2 \mathfrak {R} \langle u,v \rangle} = \|u\|\ \ (\text {since}\ u \perp v).$$ Now for any $y \in S$ with $\|y\| \leq 1$ we have \begin{align*} \left \lvert \langle u + v , y \rangle \right \rvert & = \left \lvert \langle u , y \rangle + \langle v , y \rangle \right \rvert \\ & = \left \lvert \langle u,y \rangle \right \rvert\ \ \ \ \ \ \ \ (\text {Since}\ v \perp y ) \\ & \leq \|u\| \|y\| \\ & \leq \|u\| \end{align*} Now if $u = 0$ then $x = v \in S^{\perp}$ in which case we have already proved that $L = M.$ So WLOG we may assume that $u \neq 0.$ Then by taking $y = \dfrac {u} {\|u\|}$ we have $M = \|u\|.$ So in this case also we have $L = M,$ as required. QED Does my proof hold good? Please check it. Thanks in advance. EDIT $:$ I don't think that what I did is correct. Because Hilbert space can't have such decomposition unless $S$ was given to be closed.","['hilbert-spaces', 'solution-verification', 'vector-spaces', 'functional-analysis']"
3821272,What is the meaning of this set notation?,"I am studying discrete mathematics using Rosen Discrete Mathematics 7th Edition. I am doing sets. I don't understand what this means. I don't understand why the intersection of all these sets is {1} . I thought it would be all {1,2,3,...., i} .",['discrete-mathematics']
3821322,"How do I interpret the ""d"" in derivative notation? [duplicate]","This question already has answers here : What am I doing when I separate the variables of a differential equation? (5 answers) What do the symbols d/dx and dy/dx mean? (5 answers) Closed 3 years ago . I recently decided to declare as an applied math major and I've realized that I don't think I fully understand what derivative notation actually means. I'm kinda worried that I might have missed something and it may affect my progress in more advanced math classes like ODE which I'm taking right now. I have always assumed that $\frac{dy}{{dx}}$ is just notation for a specific operation: $$
\frac{dy}{{dx}} = \mathop {\lim }\limits_{h \to 0} \frac{{y\left( {x + h } \right) - y\left( x \right)}}{h}
$$ I understand that this is the definition of a derivative but this doesn't seem to be the full story. For example what does $dx$ mean by itself? In practice it seems like $\frac{dy}{{dx}}$ is a ratio between two values $dy$ and $dx$ that have a mathematical meaning on their own. For example, its common to multiply both sides of an equation by $dx$ . People say that $dx$ is just a small change in $x$ but what does that actually mean? One possible answer that I've just sorta assumed without thinking about it too much was $$dx = \mathop {\lim }\limits_{a \to 0} (x + a) - x $$ But this seems wrong because it just evaluates to $dx =  \mathop {\lim }\limits_{a \to 0} a = 0$ . Reading wikipedia articles about differential notation isn't helping much but it sounds like the meaning of $dx$ has changed over time? The specific thing that prompted my question was a problem in my ODE class. Take a linear differential equation that looks something like this: $$
\frac{dy}{{dx}} + y = x^2
$$ I know what to do in order to solve this but the solution feels hand wavey. If you multiply both sides by the integrating factor $e^{x}dx$ and then integrate both sides you get $$
\int e^{x}dy + e^{x}ydx = \int e^{x}x^2 dx
$$ I just don't know how to interpret the RHS of the equation. Do I integrate with respect to x or y? Do I just integrate the $dx$ and $dy$ terms separately? Doing that doesn't give you $e^{x}y$ which is the actual answer. Edit: some people are suggesting that in integral notation $dx$ is just sort of syntactical, it just shows where the end of the integration operation is. I am unsatisfied with this answer. If its just syntactical, then you would evaluate the ODE like this $$
\int (e^{x}\frac{dy}{{dx}} + e^{x}y) dx \\
$$ If I am understanding the syntax argument correctly, you should be able to split this integral into two parts like this: $$ \int e^{x}\frac{dy}{{dx}}dx + \int e^{x}y dx =  e^xy + e^xy = 2e^xy
$$ But this doesn't appear to be consistent with my ODE textbook, which says the actual answer is $e^xy$ . They justified that by saying that the derivative of $e^yx$ is $e^{x}\frac{dy}{{dx}} + e^{x}y$ by the chain rule. This feels handwavey and leads me to believe that $ \int e^{x}\frac{dy}{{dx}}dx + \int e^{x}y dx $ is not notationally equivalent to $\int (e^{x}\frac{dy}{{dx}} + e^{x}y) dx$","['notation', 'calculus', 'derivatives']"
3821340,Is a vertical line injective?,"Pretty much just the title. Obviously a vertical line isn't a function (doesn't pass the vertical line test), but technically it passes the horizontal line test for injectivity. But, I thought that an injective map needed to have distinct outputs corresponding with distinct inputs, which a vertical line doesn't have (multiple y outputs for our x input). Or does an injective map also have to be a function by definition?","['algebra-precalculus', 'functions']"
3821407,Is Lie group cohomology determined by restriction to finite subgroups?,"Consider the restriction of the ordinary group cohomology $H^*(BG,\mathbb{Z})$ , where $G$ is a compact Lie group and $BG$ is its classifying space, to finite subgroups $F < G$ . If we consider the product of all such restrictions $$H^*(BG,\mathbb{Z}) \to \prod_F H^*(BF,\mathbb{Z}),$$ is this map injective? EDIT: I asked this question at mathoverflow , and Tim Campion provided an argument for the torsion elements, which together with Qiaochu's answer below one has a complete solution to the question, so yes the map is injective.","['abstract-algebra', 'lie-groups']"
3821431,The equation $|z-\omega|^2+|z-\omega^2|^2=\lambda$ will represent a circle if,"If $\omega$ is a complex cube root of unity and $\lambda$ belongs to real numbers, then the equation $$|z-\omega|^2+|z-\omega^2|^2=\lambda$$ will represent the circle for what range of $\lambda$ ? My Attempt: $\Rightarrow 2|z|^2+|\omega|^2+|\omega^2|^2-(z\omega^2+\bar z\omega+z\omega+\bar z\omega^2)=\lambda$ $\Rightarrow 2|z|^2+2-(\omega^2)(z+\bar z)-(\omega)(z+\bar z)=\lambda$ $\Rightarrow 2(|z|^2+1)+(z+\bar z)=\lambda$ $\Rightarrow 2[|z|^2+Re(z)+1]=\lambda$ $\Rightarrow x^2+y^2+x+1-\lambda/2=0$ For a general conic to be a circle, the determinant must be non zero, coefficient of $xy$ must $=0$ , and coefficient of $x^2$ and $y^2$ must be $=1$ . Conditions $2$ and $3$ are satisfied, so I checked for condition $1$ ,and got the answer as $\lambda$ belongs to the real numbers except $-{3/2}$ . However the answer is $[3/2,\infty]$ . I have already checked with another method and the given answer seems to be correct (involves locus of circle in complex form for diametric endpoints) Where have I gone wrong?","['algebra-precalculus', 'solution-verification', 'conic-sections', 'complex-numbers']"
3821443,Continuous Fibonacci number F(n),"How is a continuous Fibonacci number $F_n$ defined? (like the Gamma function for factorials) Tried with Binet's formula (Wiki) , but to no luck. F[n_] = N[GoldenRatio^n - 1/GoldenRatio^n]/Sqrt[5]
Plot[F[n], {n, 3., 12.}, GridLines -> Automatic]
FibonRatio[n_] = N[Fibonacci[n + 1]/Fibonacci[n]];
Plot[{FibonRatio[n], N[GoldenRatio], 1.7}, {n, 3., 12.}, 
 GridLines -> Automatic] Also using this continuous function definition how is it proved that $$\lim _{n\rightarrow \infty}\dfrac{F_{n+1}}{F_n} = \phi$$ ( where $\phi$ is the GoldenRatio) ? Appreciate your comments.","['fibonacci-numbers', 'sequences-and-series']"
3821445,Is there a bijection between normal subgroups and quotient groups?,"Let $G$ be a group. Is there a bijection from the collection of all normal subgroups of $G$ , $\{ N: N \trianglelefteq G \}$ , to the collection of all quotient groups of $G$ by normal subgroups, $\{ G/N: N \trianglelefteq G \}$ ? My attempt: I tried to consider the obvious map $f$ that sends $N$ to $G/N$ . Then $f$ is clearly surjective. However, I don't know whether it is injective. If $f(N_1) = G/N_1 = G/N_2 = f(N_2)$ , we want to show that $N_1 = N_2$ . I tried to show the contrapositive, i.e. let's suppose that $N_1 \neq N_2$ . WLOG suppose that there is $g_1 \in N_1$ but $g_1 \notin N_2$ . Since $G/N_1 = G/N_2$ , we know that $N_1g_1 = N_2g_2$ for some $g_2$ . This is where I am stuck. I don't know if that tells me anything.","['quotient-group', 'group-theory', 'normal-subgroups']"
3821486,$\int_1^\infty \frac{\ln(t)}{t}dt$ is divergent?,"How to show that $\int_1^\infty \frac{\ln(t)}{t}dt$ is divergent? I know how to show that $\int_1^\infty \frac{1}{t}dt$ is divergent So maybe $$
\int_1^\infty \frac{\ln(t)}{t}dt
 = \int_1^e \frac{\ln(t)}{t}dt + \int_e^\infty \frac{\ln(t)}{t}dt
 \geq \int_1^e \frac{\ln(t)}{t}dt + \int_e^\infty \frac{1}{t}dt = \infty
$$ so it diverges by comparison test? is this right? THANKS!","['integration', 'calculus']"
3821565,Deriving solution to matrix equation $AV + VA - tAVA = I$,"Consider the matrix equation $$
AV + VA - tAVA = I,
$$ with $V$ square. Here we assume that $A$ and scalar $t$ are given, with $A$ symmetric positive definite and $0 < t < \tfrac{2}{\lambda_{\rm max}(A)}$ . Here, $\lambda_{\rm max}(A)$ denotes the largest eigenvalue of $A$ . We consider solutions of this equation in matrix variable $V$ . Apparently, a solution to this equation is $V = (2A - tA^2)^{-1}$ .  And indeed, it is easy to verify this solution is valid: $$
AV + VA -tAVA = 2(2I - tA)^{-1} - t(2I - tA)^{-1}A = (2I - tA)^{-1}(2I - tA) = I. 
$$ (This calculation follows since $A$ is nonsingular under the stated hypotheses.) But I wonder if there is a clean/intuitive/straightforward way to derive this. One can see this easily if one knows that $AV = VA$ , i.e., that they commute. It is also clear to see this if the dimension is 1: $$
av + va - tava = 1 \quad \mbox{implies} \quad (2a - ta^2)v = 1.
$$ But is there a nice way to see this in general?","['matrices', 'matrix-equations', 'linear-algebra']"
3821582,Evaluate $S=\sum_{k=1}^\infty \frac{(-1)^{k-1}} k \sum_{n=0 }^\infty \frac 1 { k \cdot 2^n+1 } $,"I am stuck in this problem, which is to evaluate the following series: $$\sum _{k=1}^\infty \frac {(-1)^{k-1} } k \sum_{n=0}^\infty \frac 1 {k \cdot 2^n +1}.$$ I have to solve it using high school methods. I tried to by expanding the inner sum. I also thought in the direction of limit of infinite sum but not able to proceed, even the first step. Please help.","['limits', 'sequences-and-series']"
3821610,"If a sequence is in $\ell_p$, then it's also in $\ell_{p'}$ for all $p'\ge p$","I need to prove something that feels rather intuitive but I'm not sure if my reasoning is sufficient. Prompt: suppose $x \in \ell_p$ for some $p \in [1,\infty)$ . Show that $x \in \ell_{p'}$ for all $p' \geq p$ This is pretty intuitive because I know that larger $p$ -norms get smaller. This made me think that it was a good idea to take the derivative of a p-norm, but he derivative contains the definition of a $p$ -norm multiplied by more terms... $$
\begin{align*}
\cfrac{d}{dp}\|x\|_p &= \cfrac{d}{dp}(|x_1|^p+|x_2|^p+\cdots)^{1/p} \\
                     &= \frac{d}{dp}
e^{\ln(|x_1|^p+|x_2|^p+\cdots)\cdot 1/p}\\
                     &= e^{\ln(|x_1|^p+|x_2|^p+\cdots)\cdot 1/p} \cdot \frac{d}{dp} \ln(|x_1|^p+|x_2|^p+\cdots){1/p}
\end{align*}
$$ and I eventually ended up with $$
\begin{align*}
   (|x_1|^p+|x_2|^p+\cdots)^{1/p}\cdot \left(\cfrac{\ln(|x_1|^p+|x_2|^p+\cdots)}{p^2} \right)
+ \cfrac{1}{p}\cdot \frac{\ln(|x_1|)\cdot|x_1|^p+ \ln(|x_2|)\cdot|x_2|^p+ \cdots}{|x_1|^p+|x_2|^p+\cdots}
\end{align*}
$$ Which I'm not finding super helpful. Guidance on how to show the prompt would be wonderful.","['lp-spaces', 'normed-spaces', 'functional-analysis']"
3821657,How is this fraction simplified?,"Based on the snapshot image, I don't understand how they got to the numerator: −1/13h
I actually don't understand how they got to the denominator either? I appreciate a step by step on how they did it. It's figuratively making pull my hairs out. Thank you in advance.","['algebra-precalculus', 'functions']"
3821677,Tossing 12 different valued coins at the same time,"I toss $3$ dimes, $4$ nickels, and $5$ pennies all at the same time. What is the chance that all of the ones that land heads up is $30$ cents? This is from a timed competition, fastest answers are the best. My answer: The denominator should be $2^{12}$ since we are throwing $12$ coins. There are $5$ cases of getting $30$ cents. $3$ dimes $2$ dimes, $2$ nickels $2$ dimes, $1$ nickels, $5$ pennies $1$ dimes, $4$ nickels $1$ dimes, $3$ nickels, $5$ pennies For #1, there is only one option For #2, there is $3\choose 2$ $\cdot$ $4\choose 2$ $= 18$ , since we are picking $2$ out of $3$ dimes and $2$ out of $4$ nickels. For #3, it would be $ 3 \cdot 4 = 12$ , since we are picking $2$ out of $3$ dimes and $1$ out of $4$ nickels. For #4, it would be be $3$ For #5, it would be $ 3 \cdot 4 = 12$ . My final answer is $\frac{46}{2^{12}}$ I'm not sure this is 100% correct, and this definitely isn't the fastest way. Can anyone check if I'm correct, and if not, tell me what is wrong? Faster answers is greatly appreciated.","['combinatorics', 'probability']"
3821750,Understanding Standard Error ($\frac{\sigma}{\sqrt{n}}$) from the definition,"In the ""normal"" sense, I have understood standard error to be the standard deviation of the means. Hence, you would need to calculate multiple averages ( $\bar{x}_1,..., \bar{x}_n$ ) and calculate the standard deviation (let $u$ be the average of the average): $$SE = \sqrt{\frac{\sum\limits_{i=1}^{n} (\mu - \bar{x}_i)^2}{n-1}}$$ I do not understand how this eventually becomes $(1) \ SE = \frac{\sigma}{\sqrt{n}}$ . Afterall, don't you need multiple averages to get this value? How are we able to calculate it with just one set of data? An explanation on how $(1)$ is derived would be greatly appeciated.","['statistics', 'standard-deviation']"
3821758,"Notation: Why Is the ""Is Member of"" Symbol in These Sets? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Questions: Given $ A = \{ \in, a \} $ , $ B = \{ ab \} $ , find $ A^2 $ , $ B^3 $ , and $ AB $ Given $ A = \{ \in, a \} $ , $ B = \{ ab \} $ , determine $ A^* $ , $ B^* $ , and $ B+ $ So I was given these two questions to solve. I think I know how to solve them in general, but I am confused as to why set A has a ""is member of"" symbol ( $\in$ ) in it. I've never seen this before and was wondering if it's some special type of notation or if rather the symbol is merely an arbitary element.","['elementary-set-theory', 'notation']"
3821767,"Continuous functions from $\Bbb{N}$ to $\Bbb{N}$ in the ""co-small"" topology","In a related post, I asked about the ""co-small"" topology on $\Bbb{N}$ . One of the questions was about characterizing the continuous functions from $\Bbb{N}$ to itself in this topology. Some examples of continuous functions include $f(n) = an + b$ , $f(n) = \lfloor n^p \rfloor$ for $0 < p \leq 1$ , the prime counting function $f(n) = \pi(n)$ ; some functions that are not continuous would be $f(n) = \lfloor \log_2(n) \rfloor + 1$ , $f(n) = p_n$ (the $n$ th prime), $f(n) = \lfloor e^{\sqrt{\ln n}} \rfloor$ . Other users have given partial results. Ben shows that if $f: \Bbb{N} \to \Bbb{N}$ is continuous and $f(A)$ is small for any large set $A$ , then $f$ is constant. Greg Martin shows that if $f: \Bbb{N} \to \Bbb{N}$ satisfies $\lim_{n \to \infty} f(n)/n = \infty$ on any large set $A$ , then $f$ must map some large subset of $A$ to a small set, and therefore cannot be continuous in this topology. I think I'm prepared to give a characterization of how quickly or slowly a non-constant continuous function $f: \Bbb{N} \to \Bbb{N}$ can grow: (Proposed) Theorem. A function $f$ from $\Bbb{N}$ to itself is continuous in the co-small topology iff only if there exist positive constants $M, p$ such that: $f(n) \leq Mn$ for all but a small set of positive integers $n$ ; $f(n) \geq n^p$ for all but a small set of positive integers $n$ . Greg Martin's answer dispatches of (1), and Ben's answer implies that $f(n) \to \infty$ except possibly on a small set of positive integers $n$ (finite sets are small, so the preimage of any finite set under a continuous function cannot be large). My answer for the last part is based on thinking about, e.g. $f(n) = \lfloor \sqrt{n} \rfloor$ vs. $f(n) = \lfloor \log_2(n) \rfloor + 1$ . For $f(n) = \lfloor \sqrt{n} \rfloor$ , for any integer $k$ , $$\sum_{n \in f^{-1}(k)} \frac{1}{n} \approx \frac{2}{k},$$ and so the preimage of any large set is also large. This generalizes to any $\lfloor n^p \rfloor$ with $0 < p \leq 1$ as in this case $\sum_{n \in f^{-1}(k)} \frac{1}{n} \approx \frac{1}{pk}$ . OTOH, for $f(n) = \lfloor \log_2(n) \rfloor + 1$ , for any integer $k$ , $$\sum_{n \in f^{-1}(k)} \frac{1}{n} \approx \frac{1}{2},$$ and so any infinite set (even a small one) has large preimage. Question: Is it true that for any $f: \Bbb{N} \to \Bbb{N}$ , if $1/k = o(\sum_{n \in f^{-1}(k)} \frac{1}{n})$ on a large set of positive integers $k$ , that $f$ maps a large set to a small set? And, if this is not equivalent to (2) above, what is an explicit counterexample? I've tried to demonstrate the equivalence above, but I'm having a hard time giving a solution in full generality. Any help would be appreciated. Thanks! Edit: Hanul has shown that the above conditions are not sufficient to establish continuity. Are they necessary?","['number-theory', 'real-analysis', 'solution-verification', 'general-topology', 'convergence-divergence']"
3821774,what is derivative of $\exp(X\beta)$ w.r.t $\beta$,"I am using the Denominator layout, i.e. $$\frac{\partial X\beta}{\partial \beta} = X^T,$$ where $X$ is $n\times p$ and $\beta$ is $p\times 1$ . What is the result of $$\frac{\partial \exp(X\beta)}{\partial \beta} \text{ ?}$$ Since $\exp(X\beta)$ is $n\times1$ and $\beta$ is $p\times 1$ , the derivative should be a $p\times n$ matrix. However, this is what I derived: $$\frac{\partial \exp(X\beta)}{\partial \beta} = \frac{\partial X\beta}{\partial \beta}\frac{\partial \exp(X\beta)}{\partial X\beta} = X^T\exp(X\beta),$$ which is a $p\times1$ . Where did I make a mistake?","['self-learning', 'matrix-calculus', 'derivatives']"
3821779,Converse to Hurwitz Theorem,This is problem 17 from chapter 14 of Papa Rudin. Suppose we have a region $\Omega$ (open connected subset of the plane) and some $f_n$ that are holomorphic on $\Omega$ and converge to $f$ uniformly on compact subsets of $\Omega$ where $f$ is some one-to-one function. Fix $K \subset \Omega$ where $K$ is compact. Is is possible for infinitely many of the $f_n$ to be NOT one-to-one when restricted to $K$ ? Thanks in advance!,['complex-analysis']
3821785,$R/I\cong R/\text{Ann}_R(R/I)$ but $I\neq\text{Ann}_R(R/I)$,"Most of my experience with rings is with commutative rings, so I lack some intuition about the nature of noncommutative rings. Does there exist a noncommutative unital ring $R$ and left ideal $I$ such that $R/I\cong R/\text{Ann}_R(R/I)$ as left $R$ -modules but $I\neq \text{Ann}_R(R/I)$ ? I suspect that such an $R$ and $I$ do exist but are awkward to construct. Note that $$\text{Ann}_R(R/I)=\{r\in R:\forall x\in R,\ rx\in I\}\subseteq I$$ and that $\text{Ann}_R(R/I)$ is always a two-sided ideal. As such, if $I$ is not two-sided then we already get $I\neq \text{Ann}_R(R/I)$ . There is also a surjection $\pi:R/\text{Ann}_R(R/I)\to R/I$ induced by canonical surjection $R\to R/I$ , but this induced map obviously won't be an isomorphism when $I\neq \text{Ann}_R(R/I)$ . Any ideas would be appreciated. My question is equivalent to this question with the additional constraint that $J$ must be two-sided.","['abstract-algebra', 'noncommutative-algebra', 'modules']"
3821800,Derive an expression for Airy Bi function?,"I am looking to find an explicit integral formula for $\operatorname{Bi}(x)$ via solving Airy's equation: $${\mathrm d^2y\over\mathrm dx^2}-xy=0\tag1$$ Currently I am able to solve for $\operatorname{Ai}(x)$ using the means of Fourier transform: Let $F(\omega)$ denote the Fourier transform of $y(x)$ . If we take Fourier transform on both side of (1), then $$
-\omega^2F(\omega)-iF'(\omega)=0\tag2
$$ Solving (2) yields $$
F(\omega)=F(0)e^{i\omega^3/3}\tag3
$$ Take inverse Fourier transform on (3) gives $$
y={F(0)\over2\pi}\int_{-\infty}^\infty e^{i(\omega x+\omega^3/3)}\mathrm d\omega
$$ Due to the fact that $\int_{-\infty}^\infty f(x)\mathrm dx=\int_0^\infty[f(x)+f(-x)]\mathrm dx$ , we are able to get rid of the complex exponential: $$
y={F(0)\over\pi}\int_0^\infty\cos\left(\omega x+{\omega^3\over3}\right)\mathrm d\omega\tag4
$$ and (4) is identical to $y=F(0)\operatorname{Ai}(x)$ . Fourier transform is only valid for square-integrable funcntion, so the particular solution $\operatorname{Ai}(x)$ is only the square-integrable branch of the more general solution: $$
y=C_1\operatorname{Ai}(x)+C_2\operatorname{Bi}(x)
$$ However, I would like to derive an explicit integral formula for $\operatorname{Bi}(x)$ , so I plug $y=f(x)\operatorname{Ai}(x)$ back into (1) and obtain $$
f''(x)\operatorname{Ai}(x)+2f'(x)\operatorname{Ai}'(x)+f(x)\operatorname{Ai}''(x)-xf(x)\operatorname{Ai}(x)=0 \\
f(x)[\operatorname{Ai}''(x)-x\operatorname{Ai}(x)]+f''(x)\operatorname{Ai}(x)+f'(x)\operatorname{Ai}'(x)=0
$$ $$
f''(x)\operatorname{Ai}(x)+2f'(x)\operatorname{Ai}'(x)=0\tag5
$$ Via some basic algebraic operation, I arrived at $$
{f''(x)\over f'(x)}=-2{\operatorname{Ai}'(x)\over\operatorname{Ai}(x)}\tag6
$$ Integrate and exponentiate on both side of (6) gives $$
f'(x)={C\over\operatorname{Ai}^2(x)}
$$ and eventually I got stuck on $$
f(x)=C\int{\mathrm dx\over\operatorname{Ai}^2(x)}
$$ Although this integral became a simple business if we made use of the Wronskian of $\operatorname{Ai}(x)$ and $\operatorname{Bi}(x)$ , but I wonder if it is possible for me to obtain an explicit integral formula $\operatorname{Bi}(x)$ via this integral. Alternatively, could somebody provide some other ways for me to find this integral formula","['airy-functions', 'special-functions', 'ordinary-differential-equations', 'real-analysis']"
3821820,Cardinality of the collection of measurable subsets of metric outer measures,"It is a well known fact that $\left | B_{\mathbb{R}} \right | = \left | \mathbb{R} \right |$ , the standard proof involving transfinite induction. However, the next 2 statements are also true: If $u$ is a metric outer measure over a metric space $X$ , then every open set of the space is $u$ -measurable. Then, we have as a direct corollary: The Borel sets of $X$ are contained in the collection of $u$ -measurable sets, for every metric outer measure $u$ over $X$ . So, if we could prove the existence of a metric outer measure $u$ (over $\mathbb{R}$ ) such that $\left | M_u \right | = \left | \mathbb{R} \right |$ , with $M_u = \left \{ u- measurable \:sets \right \}$ , then the cardinality of $B_{\mathbb{R}}$ would be immediately deduced. However, this last statement seems at least a little interesting by itself. I gave some thought to it, but what i tried did not work. So, is it possible to prove the existence of such $u$ ? Edit : I decided to start a bounty for this question, so i'm also posting my attempt. I understand that this problem is probably either easier than this, or it is too complex for me to understand fully, but i would still be more comfortable with an answer. I'm not exactly an expert in this field, so please forgive me if this attempt is dumb. I tried other ideas, but they ended up being false. I tried to prove by contradiction that for every metric outer measure over $\mathbb{R}$ we have $\left | M\left ( u \right ) \right | = 2^{\left | \mathbb{R} \right |}$ (i think i had to assume AC and CH, sorry for that). So, by contradiction, suppose that $\left | M\left ( u \right ) \right | < 2^{\left | \mathbb{R} \right |}$ . This means that it is not possible that every uncountable (again, i had to assume CH) set is of infinite $u$ -measure, because if that were the case then we could conclude by the caratheodory condition that $\left | M\left ( u \right ) \right | = 2^{\left | \mathbb{R} \right |}$ . Also (because of CH), none of this uncountable sets can be of $u$ -measure $0$ , because then every subset of this set would be $u$ -measurable, and so (because it is uncountable and CH) we would have again $\left | M\left ( u \right ) \right | = 2^{\left | \mathbb{R} \right |}$ . So then, there exists $E \subseteq \mathbb{R}$ uncountable such that $ 0 < u\left ( E \right ) < \infty$ . Now, if the next statement is true, then a contradiction can be given (I don't know if it is true, but i think i could show it for several particular cases): ('Borelian decomposition') For very uncountable (i'm assuming CH, as stated above) subset $E \subseteq \mathbb{R}$ , there exist $\left \{ E_{\alpha} \right \}_{\alpha \in \mathbb{R}} \in B_{\mathbb{R}}$ such that $\left | E_\alpha  \right | = \left | \mathbb{R} \right |$ for every $\alpha$ and $\coprod_{\alpha}^{}E_\alpha = E$ (by this i mean disjoint union) . Now, this statement is true if we remove the condition that each $E_{\alpha}$ is borelian (to see this, take a bijection between $E$ and $\left [ 0, 1 \right ] \times \left [ 0, 1 \right ]$ and take preimages of vertical strands $\left \{ t \right \} \times \left [ 0, 1 \right ]$ for $t$ in the unit interval), but for the final contradiction i need Borelian sets, because they are $u$ -measurable by hypothesis ( $u$ is a metric outer measure). However, i think I could prove this ' Borelian decomposition for the following cases: $E = \mathbb{R}$ : using the same idea of vertical strands but this time with Peano curves. $E$ is a $G_{\delta}$ set (again, always uncountable): In Counterexamples in probability and real analysis , by Gary Wise, it is proven  ( problem 1.20) that for every $A \in G_{\delta}$ uncountable, there exists $B \subseteq A$ closed, nowhere dense, and such that can be mapped continously onto the unit interval (also, it is a null set in lebesgue measure, but i won't be using this property). Applying the same idea of the previous case for $B$ , then we can give a 'Borelian decomposition' for $B$ , and so for $A$ (if $A - B$ is uncountable, then just distribute it´s points over the borelians that constitute the Borelian decomposition of $B$ ) $E \in F_{\sigma}$ The method for this case is similar to the previous one, noticing that every closed set is a $G_{\delta}$ . $E$ is lebesgue measurable with positive measure: This is because in this case there exists a $F \in F_{\sigma}$ and a null set $Z$ such that $E = F \coprod Z$ , and the previous case gives the 'Borelian decomposition'. $E$ is the cantor set : I thought of this in an attempt for a counterexample, but using the Cantor -Lebesgue function i found a 'Borelian decomposition'. I could not prove the decomposition for Lebesgue measure 0 sets, and of course not for Lebesgue non-measurable sets. But, it is still a LITTLE close. Now, to the contradiction, assuming this statement is true: Because of the decomposition, there exist $\left \{ E_{\alpha} \right \}_{\alpha  \in \mathbb{R}}$ with the properties given in the 'Borelian decomposition' statement. Because each $E_{\alpha}$ is uncountable, it must be $u\left ( E_\alpha  \right ) > 0$ , because of the first comments on my attempt (if not true for some $\alpha$ , subsets of this set would be $u$ -measurable). But then, consider the sets $F_n := \left \{ \alpha, u\left ( E_\alpha  \right )> 1/n \right \}$ . Their union form the totality of the $\alpha \in \mathbb{R}$ , but because of the decomposition, al least ONE of this subsets (name it $F_{n_0}$ ) must be infinite. But then, there exists $\left ( \alpha_i \right )_{i \in \mathbb{N}} \subseteq F_{n_0}$ such that $u\left ( E_{\alpha _i} \right ) > 1/n$ . But, this implies that $E$ would be of infinite $u$ - measure (we can decompose the measure of the disjoint union of the $E_{\alpha _i}$ in a sum of measures because these sets are borelian and thus u-measurable), a contradiction. However, none of the cases true for the 'Borelian decomposition' necessarily work for $E$ , because, $E$ can eventually be of Lebesgue measure $0$ , or also not Lebesgue measurable. Another idea i had was: suppose that $u$ is a regular metric outer measure (additional hypothesis), so the problem can be reduced to measures over $B_{\mathbb{R}}$ and induced outer measures. Then, because of the first comments for the previous attempt, $u\left ( A \right )= 0 \Rightarrow m\left ( A \right )=0$ for every subset $A$ , because only countable subsets can be of $u$ -measure $0$ . So, if WLOG we could suppose that the induced measure over $B_{\mathbb{R}}$ is $\sigma$ -finite, arguments involving (for example) Radon- Nikodym could be used (i tried but got nowhere). However, i think that proceeding this way would only give an answer for regular metric outer measures. If this is wrong, please notify me. Any reference to this problem is also greatly appreciated.","['measure-theory', 'cardinals', 'descriptive-set-theory', 'real-analysis']"
3821831,Improving an approximation for the inverse of the Riemann–Siegel θ-function,"Recall the Riemann–Siegel θ -function : $$\theta(z) = \arg\Gamma\left(\frac{1}{4}+\frac{i\,z}{2}\right) - \frac{z\,\log \pi}{2},$$ that describes the complex phase of the Riemann $\zeta$ -function on the critical line. There is a known approximation for its inverse: $$\theta^{\small(-1)}(x)=\frac{\pi+8{\tiny\text{ }}x}{4\,W\!\left(\frac{\pi+8{\tiny\text{ }}x}{8{\tiny\text{ }}\pi{\tiny\text{ }}e}\right)}+o(1),$$ where $W(x)$ is the Lambert W-function , which becomes more precise as $x$ grows. I wonder if it is possible to improve this approximation by including higher-order terms, so that the remaining error term decays as $o(x^{-1})$ , $o(x^{-2})$ , etc. Can those higher-order terms be expressed using only elementary functions and $W(x)$ ?","['complex-analysis', 'riemann-zeta', 'approximation', 'laurent-series']"
3821901,What is $\sum^{\infty}_{n=1}\frac1{n(n+x)}$ equal to?,"I was wondering how we could calculate the sum $S(x)=\sum^{\infty}_{n=1}\frac1{n(n+x)}$ for any real $x$ . I've noted the following properties regarding the sum (which may or may not be useful to actually finding $S(x)$ ): We have the identity $\sum^{\infty}_{n=1}\frac1{n(n+x)}=\frac1x\sum^{\infty}_{n=1}\frac1{n}-\frac1{n+x}$ for $x\neq0$ . If we rearrange the terms in the sum, we find that for $x\in\mathbb{Z}_+$ , $S(x)=\frac{H_x}{x}$ , where $H_x$ is the xth harmonic number . This means $S(x)\sim\frac{\ln x}x$ for positive $x$ . The case $x=0$ is  the Basel Problem, so we know $S(0)=\frac{\pi^2}6$ . For $x\in\mathbb{Z}_-$ , there is an $n$ such that $n+x=0$ and $\frac1{n(n+x)}=\pm\infty$ . So $S(x)=\pm\infty$ for $x\in\mathbb{Z}_-$ . $S'(x)=-\sum^{\infty}_{n=1}\frac1{n(n+x)^2}$ . As $\frac1{n(n+x)^2}$ is negative, this means that (ignoring discontinuities) $S(x)$ is strictly decreasing. However, I have no idea how to actually get a closed form of $\sum^{\infty}_{n=1}\frac1{n(n+x)}$ for non-integer $x$ . How could I calculate this sum?",['sequences-and-series']
3821914,"Consider the ODE $\frac{dy}{dx}=f(x,y)$, where $f:\mathbb{R}^2\to \mathbb{R}$","Consider the ODE $\frac{dy}{dx}=f(x,y)$ , where $f:\mathbb{R}^2\to \mathbb{R}$ defined as follow $$ f(x,y) =
\left\{
	\begin{array}{ll}
		\frac{xy}{x^2+y^2}  & (x,y)\neq(0,0), \\
		0 & (x,y)=(0,0)
	\end{array}
\right.$$ a) Show that the given ODE admits solutions for arbitrary initial conditions $y(x_0)=x_0$ b) ¿Does $f$ locally satisfiy the conditions for Picard's Theorem?, c) ¿And what about Peano's existence theorem? Justify My attemps: To solve the ODE $\frac{dy}{dx}=f(x,y)$ for $(x_0,y_0)\neq(0,0)$ I tried it by separable variable method and the solution was $$ \ln(y)=\frac{x^2}{2y^2}+C$$ How do I conclude a),b) and c). Can somebody give me a hint?",['ordinary-differential-equations']
3821917,How do I know if a given set of points on a convex quadrilateral are valid tangent points for an ellipse fitting inside that quadrilateral?,"There is one point designated for each side of the quadrilateral.
The ellipse is contained within the quadrilateral. I am curious about this because when using linear perspective to plot ellipses in my drawings I first make quadrilaterals, then deduce the tangent points, then plot the ellipse. It would be nice to have some way of checking those tangent points to make sure they are valid. Take for example the image below, given points E,F,G, & H on the convex quadrilateral ABCD I don't see a way to construct an ellipse that is tangent to all those points. Is there a formulaic/algorithmic way of knowing if a given set of points can/cannot construct an ellipse on a given quadrilateral without trial and error (In an app like GeoGebra)?","['projective-geometry', 'conic-sections', 'geometry']"
3821949,"An equation with angles of triangle satisfies 60 degrees triad, can we say that the triangle is equilateral?","Question: In a triangle ABC, the equation $2\cos A \sin C=\sin B $ holds true. What type of triangle is it? Choices available are: a) isosceles b) equilateral Solution: $$2\cos A \sin C=\sin B $$ $$\Rightarrow \sin(A+C) -\sin (A-C)=\sin B$$ $$\Rightarrow \sin(A+C) -\sin (A-C)=\sin(180º - (A+C))$$ $$\Rightarrow \sin(A+C) -\sin (A-C)=\sin (A+C)$$ $$\Rightarrow \sin (A-C),  A = C$$ Hence isosceles. Confusion: But, using $A=B=C=\frac{\pi}{3}$ in the original equation, we get $2*\frac{1}{2}*\frac{\sqrt3}{2}=\frac{\sqrt3}{2}$ which is true. I tried to obtain a proof for both ""the triangle is equilateral"" and ""the triangle is not equilateral"", but I end in deadlock situation, so could not obtain any proof for any of the two claims.
So, just because the equation satisfies, $A=B=C=\frac{\pi}{3}$ , can we say that the triangle is equilateral? Textbook has ""isosceles"" as the answer.","['trigonometry', 'algebra-precalculus', 'triangles', 'geometry']"
3821961,$n^{th}$ derivative of $\log(x)/x$,"The problem Given: $$x\, f(x) = \log(x) \qquad \forall\; x > 0$$ we need to prove that the $n^{th}$ derivative of $\,f(x)\,$ at $\,x = 1\,$ is: $$f^{(n)}(1) = (-1)^{n+1}\, n! \, \left( 1 + \frac{1}{2} + \ldots + \frac{1}{n} \right)$$ What I tried Proved for $\,n=1, 2\,$ and tried applying mathematical induction, wherefrom I am getting $\,f^{(n)}(x)\,$ from $\,f^{(n-1)}(x)$ , $\:$ but $\,f^{(n)}(1)\,$ seems underivable from $\,f^{(n-1)}(1)$ .",['derivatives']
3822099,Normal distribution magic,"Let $X$ and $Y$ be independent random variable, such that $X-Y$ and $X+Y$ are independent.
Prove that $X$ and $Y$ are normal random variable. Hint: Use characteristic functions to find a functional equation, and to find the modulus of $\phi_{X+Y}$ and the corresponding argument. We have $$\phi_{(X+Y,X-Y)}(x,y)=\phi_{X+Y}(x)\phi_{X-Y}(y)=\phi_X(x)\phi_Y(x)\phi_X(y) \overline{\phi_Y}(y) \ \ \  \ (1)$$ $$\phi_{(X+Y,X-Y)}(x,y)=\phi_{(X,Y)}(x+y,x-y)=\phi_{X}(x+y)\phi_Y(x-y) \ \ \ \ (2)$$ we obtain, $$\phi_{X}(x+y)\phi_Y(x-y)=\phi_X(x)\phi_Y(x)\phi_X(y) \overline{\phi_Y}(y) \ \ \ \ (3)$$ replacing $y$ with $-y$ in $(3)$ : $$\phi_{X}(x-y)\phi_Y(x+y)=\phi_X(x)\phi_Y(x)\phi_Y(y) \overline{\phi_X}(y) \ \ \ \ (4)$$ multiplying $(3)$ with $(4):$ $$\phi_{X+Y}(x+y)\phi_{X+Y}(x-y)=(\phi_{X+Y}(x))^2|\phi_{X+Y}(y)|^2 \ \ \ \ (5)$$ So, $$|\phi_{X+Y}(x+y)||\phi_{X+Y}(x-y)|=|\phi_{X+Y}(x)|^2|\phi_{X+Y}(y)|^2 \ \ \ \ (6)$$ So we obtain a functional equation which need to be solved: $$f(x+y)f(x-y)=(f(x))^2(f(y))^2$$ $f$ is continuous and positive, This functional equation was solved (see @Ravsky reply below) (beginning with integers, rational, then real numbers via density), we should obtain: $$\exists \sigma>0;|\phi_{X+Y}(x)|=|\phi_{X-Y}(x)|=e^{-\sigma^2x^2/2}.$$ If so, it remains to prove that $\exists \mu \in \mathbb{R}; \phi_{X+Y}(x)=e^{i \mu x -x^2\sigma^2/2}.$ Any suggestions?","['measure-theory', 'characteristic-functions', 'normal-distribution', 'real-analysis', 'probability-theory']"
3822152,"Is the projection onto the tangent space smooth and what's the general definition of the ""tangential derivative""?","Let $d\in\mathbb N$ , $k\in\{1,\ldots,d\}$ , $\alpha\in\mathbb N$ , $M$ be a $k$ -dimensional embedded $C^\alpha$ -submanifold of $\mathbb R^d$ with boundary, $\nu_{\partial M}$ denote the outward pointing unit normal field on $\partial M$ and $\operatorname P_M(x)$ denote the orthogonal projection of $\mathbb R^d$ onto the tangent space $T_x\:M$ of $M$ at $x\in M$ . Question 1 : I would like to show that $M\ni x\mapsto\operatorname P_M(x)$ is $C^{\alpha-1}$ -differentiable. Moreover, I would like to find a formula for the pushforward $T_x(\operatorname P_M)$ , $x\in M$ . Question 2 : Moreover, I would like to understand the concept of the tangential gradient . To be precise, if $E$ is a $\mathbb R$ -Banach space (assume $E=\mathbb R$ if it's easier to follow for you) and $f:\partial M\to E$ is $C^1$ -differentiable, isn't the tangential differential (or ""gradient"", if $E=\mathbb R$ ) of $f$ at $x\in\partial M$ precisely equal to $${\rm D}_{\partial M}f(x):={\rm D}f(x)\circ\operatorname P_{\partial M}(x)\tag1,$$ where ${\rm D}f(x)=T_x(f):T_x\:\partial M\to T_{f(x)}f(\partial M)$ denotes the pushforward of $f$ at $x$ ? Regarding question 1 : It's sufficient to consider the dependence on $x\in M$ of $\operatorname P_M(x)$ locally. So, let $\Omega$ be an open subset of $M$ and $\phi$ be a $C^\alpha$ -diffeomorphism from $\Omega$ onto $\mathbb H^k:=\mathbb R^{k-1}\times[0,\infty)$ . Note that $$T_x\:M=T_x(\phi)^{-1}\mathbb R^k\;\;\;\text{for all }x\in\Omega\tag2.$$ Let $(e_1,\ldots,e_k)$ denote the standard basis of $\mathbb R^k$ . By $(5)$ , $$\sigma_i(x):=T_x(\phi)^{-1}e_i\;\;\;\text{for }i\in\{1,\ldots,k\}$$ is a basis of $T_x\:M$ for all $x\in\Omega$ . Since $\phi$ is a $C^\alpha$ -diffeomorphism, $$\Omega\ni x\mapsto T_x(\phi)^{-1}=\left({\rm D}\phi^{-1}\circ\phi\right)(x)\tag3$$ is $C^{\alpha-1}$ -differentiable and hence $\sigma_1,\ldots,\sigma_k$ are $C^{\alpha-1}$ -differentiable. Now let $(\tau_1(x),\ldots,\tau_k(x))$ denote the orthonormal basis of $T_x\:M$ obtaine from $(\sigma_1(x),\ldots,\sigma_k(x))$ by the Gram-Schmidt orthonormalization process for $x\in\Omega$ . Noting that this process does not decrease regularity and noting that $^1$ $$\left.\operatorname P_M\right|_\Omega=\sum_{i=1}^k\tau_i\otimes\tau_i\tag4,$$ we are done. Or did I made a mistake at some point? And how can we compute $T_x(\operatorname P_M)$ , $x\in M$ ? Regarding question 2 : Note that $$\nu_{\partial M}(x)\in T_x\:M\cap N_x\:\partial M\tag5\;\;\;\text{for all }x\in\partial M$$ and, by definition, the tangential differential of $f$ at $x\in\partial M$ in direction $v\in T_x\:M$ should be given by $$T_x(f)\left(v-\langle v,\nu_{\partial M}(x)\rangle\nu_{\partial M}(x)\right),\tag6$$ but in the special case $k=d$ , where $T_x\:M=\mathbb R^d$ . Now, if $(\Omega,\phi)$ and $(\tau_1(x),\ldots,\tau_k(x))$ are as above, $$T_x\:\partial M=T_x(\phi)^{-1}\partial\mathbb H^k\tag7$$ and hence $(\tau_1(x),\ldots,\tau_{k-1}(x))$ is an orthonormal basis of $T_x\:\partial M$ for all $x\in\partial\Omega$ . Let $x\in\partial\Omega$ . Since $\nu_{\partial M}(x)\in N_x\:\partial M=\left(T_x\:\partial M\right)^\perp$ , $$\langle\nu_{\partial M}(x),\tau_i(x)\rangle=0\;\;\;\text{for all }i\in\{1,\ldots,k-1\}\tag8$$ and it should follow that $(\tau_1(x),\ldots,\tau_{k-1}(x),\nu_{\partial M}(x))$ is an orthonormal basis of $T_x\:M$ . Moreover, for what it's worth, it should hold $$\tau_k(x)=\frac{\nu_{\partial M}(x)}{\left|\langle\nu_{\partial M}(x),\tau_k(x)\rangle\right|^2}\tag9.$$ In particular, it should hold $$\operatorname P_{\partial M}=\left.\operatorname P_M\right|_{\partial M}-\nu_{\partial M}\otimes\nu_{\partial M}\tag{10},$$ i.e. $\operatorname P_M(x)-\nu_{\partial M}(x)\otimes\nu_{\partial M}(x)$ should be the orthogonal projection of $\mathbb R^d$ onto $T_x\:\partial M$ and the tangential differential of $f$ at $x$ should be equal to $(1)$ . Did I made any mistake at some point? $^1$ As usual, $u\otimes v:=\langle\;\cdot\;,u\rangle v$ for $u,v\in\mathbb R^d$ .","['submanifold', 'manifolds-with-boundary', 'smooth-manifolds', 'differential-topology', 'differential-geometry']"
3822162,"If $H$ is a subgroup of infinite index and $G = H \cup H_1 \cup H_2 \cup \cdots \cup H_p$, show that $G = H_1 \cup H_2 \cup \cdots \cup H_p$.","Let $G$ be a group, $H$ a subgroup of infinite index (that is there exists a sequence $(x_n) \in G^\mathbb{N}$ of distinct elements such that $\forall i \neq j, x_i H \neq x_j H$ ), $H_1, \ldots, H_p$ subgroups of $G$ such that $G = H \cup H_1 \cup H_2 \cup \cdots \cup H_p$ , show that $G = H_1 \cup H_2 \cup \cdots \cup H_p$ . By posting this exercise, I am looking for different approches to this problem. What I've done so far (draft): The property verified by $(x_n)$ is equivalent to $\forall i\neq j, x_i^{-1} x_j \notin H$ . So if $x_0 \in H$ therefore $\forall n \ge 1, x_n \notin H$ . Let's say that if $\exists i, x_i \in H$ we take $i=0$ . I studied the case $p=1$ with $G= (\mathbb{R}, +), H = \mathbb{Z}, (x_n) = (\frac{2}{3})^n$ but my proof isn't generalizable. For $p=1$ , we have $G = H_1 \cup H$ . Suppose $H_1 \neq H \cup H_1$ ie. there exists $h \in H - H_1$ . We have $x_1 \notin H$ so $x_1 \in H_1$ , so $h x_1 \notin H_1$ , so $hx_1 \in H$ , so $x_1 \in H$ which is absurd. I tried to use the same method for $p=2$ but it's harder: suppose there exists $h \in H-H_1-H_2$ , we still have $x_1 \notin H$ so let's say $x_1 \in H_1$ , therefore $hx_1 \notin H_1$ so $hx_1 \in H_2-H_1-H$ ... Back to the general case: Using 1. we see that $\forall n \ge 1, \exists j, x_n \in H_j$ so there exists $i_1$ such that $H_{i_1}$ contains an infinite number of images of the sequence $(x_n)$ . Let's call $(x^{(i_1)}_n)$ a sequence of distinct terms such that $\forall n \ge 1,x^{(i_1)}_n \in H_{i_1}$ . Suppose there exists $h \in H-H_1 - \cdots - H_p$ , we see that $h x^{(i_1)}_n \in H-H_{i_1}$ so by induction we can find a sequence $(y_n)$ of distinct terms such that $\forall n, y_n \in H-H_1 - \cdots - H_p$ . Reference: Exercise 2.13 in Exercices de mathématiques: oraux X-ENS (Algèbre I) , by Francinou, Gianella, and Nicolas.","['contest-math', 'group-theory', 'abstract-algebra']"
3822214,Eigenvalues of complex Hessian and real Hessian,"Let $f:\mathbb{C}^n\rightarrow \mathbb{R}$ be a smooth function. The complex Hessian is given by $$\left(\frac{\partial^2f}{\partial z_i\partial \bar{z}_j}\right)_{ij}$$ and the real Hessian by $$\begin{pmatrix}
\dfrac{\partial^2f}{\partial x_i\partial x_j} & \dfrac{\partial^2f}{\partial x_i \partial y_j}\\
\dfrac{\partial^2f}{\partial x_j\partial y_i} & \dfrac{\partial^2f}{\partial y_i \partial y_j}
\end{pmatrix}.$$ Is it true that any (real) eigenvalue of the complex Hessian is an eigenvalue of the real one? If yes why? Edit: In light of Giuseppe's comments and checking with $f=|z|^2$ this seems to be straight up wrong. What I am really interested in is to show that if the complex Hessian has $n$ negative (or positive) eigenvalues, so does the real Hessian. EDIT 2.0: I may have something, I think this is correct:
Denote by $L=\left(\dfrac{\partial f}{\partial z_i\partial \bar{z_j}}\right)$ the Levi matrix of a smooth function $f$ , by $H(f)$ its Hessian and by $X\in M_{2n,n}(\mathbb{C})$ the matrix \begin{equation*}
X=\begin{pmatrix}
Id\\
iId
\end{pmatrix}.
\end{equation*} We then have \begin{equation*}
L=\overline{X}^tH(f)X
\end{equation*} It follows that if $v\in\mathbb{C}^n$ verifies $\bar{v}^tLv = \lambda |v|^2$ for $\lambda\in\mathbb{R}\setminus \{0\}$ then \begin{eqnarray*}
\overline{(Xv)}^tH(f)(Xv) &=& \bar{v}^tLv \\
                          &=& \lambda |v|^2\\
                          &=& \dfrac{\lambda}{2}|Xv|^2
\end{eqnarray*} We deduce that if $L$ is negative (positive) then $H(f)$ has $n$ negative (positive) eigenvalues.","['complex-analysis', 'several-complex-variables', 'linear-algebra', 'eigenvalues-eigenvectors']"
3822237,Simplifying the Willmore energy of an ellipsoid,"Willmore energy measures how ""non-spherical"" a smooth surface $S$ is. It is defined by $$W(S)=\int_SH^2\,dA$$ where $H$ is the mean curvature. For a torus of revolution with major and minor radii $a$ and $b$ respectively where $a>b$ , if we let $p=b/a$ then its Willmore energy is easily shown to be $\frac{\pi^2}{p\sqrt{1-p^2}}$ , which attains its minimum at $p=1/\sqrt2$ . The (proved) Willmore conjecture states that the torus thus obtained has the minimum energy among all genus- $1$ surfaces of $2\pi^2$ . I took Blender out for a ride and produced a render of this ""perfect doughnut"": Now I want to calculate the Willmore energy of an ellipsoid. In this genus- $0$ case the extremal results are easy to get: $W(S)\ge4\pi$ and equality is attained iff $S$ is a sphere. But I still want numerical results for the fun of it. Using fundamental forms (and cross-checking with this ), I found that for an ellipsoid $E$ with semi-axes $1,a,b$ : $$W(E)=\frac{a^2b^2}4\int_0^{2\pi}\int_0^\pi\frac{(a^2+b^2+(1-(a\cos u)^2-(b\sin u)^2)\sin^2v)^2\sin v}{((ab\cos v)^2+((a\sin u)^2+(b\cos u)^2)\sin^2v)^{5/2}}\,dv\,du$$ which I cannot seem to simplify further. Does the double integral above have a simpler or even closed form? Or am I doing it wrong, whereby I would have an easier time using implicit equations as mooted here ? Edit : Using Zhou's ellipsoidal coordinates as suggested by Jean Marie in the comments I have got an expression using only single integrals. For an ellipsoid $E$ with semi-axes $a>b>c>0$ let $$R_\eta(k)=\int_{c^2}^{b^2}\frac{\eta^k}{\sqrt{(a^2-\eta)(b^2-\eta)(\eta-c^2)\eta}}\,d\eta$$ and $$R_\zeta(k)=\int_{b^2}^{a^2}\frac{\zeta^k}{\sqrt{(a^2-\zeta)(\zeta-b^2)(\zeta-c^2)\zeta}}\,d\zeta$$ Then $$W(E)=\frac{(abc)^2}2(R_\eta(-2)R_\zeta(1)+R_\eta(-1)R_\zeta(0)-R_\eta(0)R_\zeta(-1)-R_\eta(1)R_\zeta(-2))$$ Edit 2 : The above expression can be simplified to $$W(E)=\frac{(abc)^2}2(R_\eta(-2)R_\zeta(1)-R_\eta(1)R_\zeta(-2))+\pi$$","['ellipsoids', 'elliptic-integrals', 'definite-integrals', 'differential-geometry']"
3822264,Composition of transpositions to solve a simple tile puzzle,"I'm teaching myself group theory by means of studying tile puzzles. One very simple puzzle has a 3x3 grid containing the numbers 1-9, and the only available move is to swap the tiles in any 2 positions, with the goal of having the tiles in order from 1-9 as shown below: +---+---+---+
| 1 | 2 | 3 |
| 4 | 5 | 6 |
| 7 | 8 | 9 |
+---+---+---+ First of all, I need to know that my basic understanding of cycle notation for permutations is correct. Is it correct to say that this arrangement: +---+---+---+
| 2 | 6 | 8 |
| 5 | 4 | 7 |
| 9 | 3 | 1 |
+---+---+---+ is represented by the permutation (1 9 7 6 2) (3 8) (4 5) ? If so, is there any need to distinguish this as representing a state vs an action that has been performed? Next, I understand that certain combinations of permutation produce predictable results. E.g. (a b) (c d) = (a b c) (a d c) My question is, how can I use results such as this to solve the problem - i.e. to perform a minimal sequence of transpositions which will create the winning state? Is this the kind of thing that is amenable to some equivalent of solving an equation in ""normal"" algebra? Is there a systematic approach which can be applied, or is it more a case of applying known transformations using educated guesswork?","['group-theory', 'puzzle', 'permutation-cycles']"
3822308,Why are the functions $y=x^{\sin^2(x)}+x^{\cos^2(x)}$ and $y=(x-2\sqrt{x}+1)\cos^2(2x)+2\sqrt{x}$ so similar?,I was just playing around with functions and plotting them in Desmos and I found that these functions are remarkably similar despite their totally different expressions. The functions are $$y=x^{\sin^2(x)}+x^{\cos^2(x)}$$ and $$y=(x-2\sqrt{x}+1)\cos^2(2x)+2\sqrt{x}$$ Link to Desmos page: https://www.desmos.com/calculator/meyktbtz0i Edit: They aren't exactly the same if you zoom in closer as pointed out to me.,"['trigonometry', 'functions']"
3822311,Construct a function with pre-specified behaviour,"Could you suggest a function $f:\mathbb{N}^+\setminus\{1\}\rightarrow \mathbb{N}^+$ such that $\lim_{x\rightarrow \infty}\frac{f(x)}{x}=0$ $\lim_{x\rightarrow \infty}f(x)=\infty$ $f(x)<x$ $\forall x \in \mathbb{N}^+$ $f(500)=340$ where $\mathbb{N}^+$ denotes the strictly positive natural numbers (zero excluded), $\mathbb{N}^+\setminus\{1\}$ denotes $\mathbb{N}^+$ without $1$ . See a related question here which imposes less constraints on the desired function.
For example, the answer to that question suggests $$
f(x)=340*(\log(x^2+1)/\log(500^2+1))
$$ which does not work here because $f(x)>x$ .",['functions']
3822312,Is affine $\mathscr O$-connected morphism an isomorphism?,"If $\pi :C\to C'$ is an affine $\mathscr O$ -connected morphism,then by definition,pull back map $\mathscr O_{C'}(U)\to \mathscr O_C(\pi^{-1}(U))$ is an isomorphism for every affine $U$ of $C'$ ,since $\pi^{-1}(U)$ is affine,this means $\pi|_{\pi^{-1}(U)}$ is an isomorphism,so $\pi$ is and isomorphism,right?But it seems that we need some big machines to do this,like: coming from vakil's FOAG,Page736.Here $\pi$ is finite,hence affine by definition.So what I miss?",['algebraic-geometry']
3822317,Is the strong topology on $B(H)$ first countable?,"Let $H$ be a separable Hilbert space and consider the strong operator topology (SOT) on $B(H)$ , that is the topology on $B(H)$ generated by the seminorms $$p_x: u \mapsto \Vert ux \Vert, \quad x\in H$$ Is this topology first countable? Attempt: It suffices to find a countable neighborhood basis of $0$ . Let $(x_n)_n$ be a dense sequence of $H$ . Then I believe the topology generated by $$u \mapsto \Vert u x_n \Vert, \quad n \geq 1$$ agrees with SOT. Hence, the collection $$\left\{\bigcap_{i=1}^k p_{x_{n_i}}^{-1}([0, \epsilon[): k \geq 1; n_1, \dots, n_k \geq 1, \epsilon \in \Bbb{Q}\cap(0, \infty) \right\}$$ is a countable basis of $0$ of $SOT$ . Is the above proof outline correct? EDIT: This question was accidentally closed by a misunderstanding. Please read the comments and reopen the question. Thanks!","['general-topology', 'first-countable', 'topological-vector-spaces', 'functional-analysis']"
3822404,Rendering Lawson's comparison surfaces for the Willmore problem,"The sphere minimises Willmore energy for genus $0$ ; the stereographic projection of the Clifford torus – major radius $1$ , minor radius $1/\sqrt2$ – does so for genus $1$ . While corresponding minimisers for higher genera have not been proven, there are already some good guesses. This page says (in French): Blaine Lawson and Rob Kusner predicted that the analogue of the Clifford torus for genus $2$ is the following ""button"" and all its conformal transformations [Willmore energy is preserved under such transformations]: Just as I rendered the Clifford torus for genus $1$ in Blender – see this other question of mine – I now want to render this genus- $2$ surface, particularly the one marked L which is most symmetric. The problem is that I have no idea how to do so with the given equations. The relevant paper is R. Kusner, Comparison surfaces for the Willmore problem, Pacific J. Math. 138, no. 2 (1989), 317–345 . The construction of the surface above – as well as other Willmore energy minimisers for higher genera – is described as follows: Fix integers $m,k\ge0$ and let $$A_p=(e^{ip\pi/(k+1)},0),B_q=(0,e^{iq\pi/(m+1)})$$ in $\mathbb S^3$ (which we regard as the unit sphere in $\mathbb C^2=\mathbb R^4$ ). These are the endpoints of a (unique) shortest geodesic arc $A_pB_q$ in $\mathbb S^3$ . The geodesic polygon $$\Gamma_{m,k}=A_0B_0\cup B_0A_1\cup A_1B_1\cup B_1A_0$$ bounds an area minimising disc $\delta_{m,k}\subset\mathbb S^3$ . Repeated reflection of $\delta_{m,k}$ around the geodesics $\{A_pB_q|0\le p\le k,0\le q\le m\}$ produces [Lawson's] compact surface $\xi_{m,k}$ . … Recall from section 3 the compact minimal surface $\xi_{g,1}\subset\mathbb S^3$ . Let $M_g\subset\mathbb R^3$ denote its compact stereographic image. Clearly $M_1$ is a standard torus and in fact, $[M_g]=g\mathbb S$ [which means that $M_g$ is topologically equivlent to the sum of $g$ tori]. By Fact 1.5 and Proposition 3.2 we deduce immediately $$W_O=4\pi\text{ and }W_{g\mathbb S}\le W(M_g)=\operatorname{area}(\xi_{g,1})<8\pi.$$ [ $W_x$ means the minimal Willmore energy attained by surfaces topologically equivalent to $x$ .] In brief, what I want to do is to represent Lawson's $\xi_{2,1}$ surface in $\mathbb S^3$ . After I do this, I can stereographic-project this down to $\mathbb R^3$ , obtaining $M_2$ which should look like surface L in the image above after a rotation. I should be able to render $M_3,M_4,\dots$ surfaces analogously. How can I get an exact representation of $\xi_{2,1}$ , using the description above, as an explicit set of equations that will generate all points on the surface? 2023 edit : Lawson's original paper clarifies some things. In four dimensions $\xi_{m,k}$ 's fundamental domain's boundary comprises four geodesic arcs connecting $\left(\cos\frac\pi{2(m+1)},\pm\sin\frac\pi{2(m+1)},0,0\right)$ and $\left(0,0,\pm\sin\frac\pi{2(k+1)},\cos\frac\pi{2(k+1)}\right)$ . The arcs become circles passing through antipodes of the unit $2$ -sphere upon stereographic projection to three dimensions, and by symmetry we only need a quarter of the domain. Surface Evolver with a custom surface energy integrand $(1+r^2)^{-2}$ (so that the integral gives the four-dimensional area up to a constant) followed by postprocessing transformations finally allowed me to render accurate $\xi_{m,k}$ surfaces for arbitrary $m,k$ : I still have no idea of how to get an exact parametrisation though. I can derive the formula for mean curvature of a surface embedded in the $3$ -sphere in terms of the 3D parametric equations (involving a ternary 4D cross product), but it is far too complicated to be useful.","['minimal-surfaces', 'surfaces', 'differential-geometry']"
3822426,"Number of $3$-tuples $(A,B,C)$ if $A\subseteq B\subseteq C\subseteq S$ with $|S|=n$","What is the number of $3$ -tuples $(A,B,C)$ if $A\subseteq B\subseteq C\subseteq S$ with $|S|=n$ ? I imagine I can solve this by defining 4 possibilities for each element in $\{1,\dots,n\}$ : $e\in A$ $e\in B\setminus A$ $e\in C\setminus B$ $e\in S\setminus C$ and then the answer would be $4^n$ . But how can I prove this by using more appropriate mathematical techniques?","['elementary-set-theory', 'combinatorics']"
3822449,"If $f\in \mathbb{Z}[X]$ has the property that $|f(x)|<1, \forall x\in (-2, 2)$, then prove that $f=0$.","Let $f\in \mathbb{Z}[X]$ such that $|f(x)|<1, \forall x\in (-2, 2)$ . Prove that $f=0$ . I couldn't make too much progress on this problem. I tried considering $f=a_nX^n+a_{n-1}X^{n-1}+...+a_1X+a_0$ and by setting $x=0$ in the hypothesis I got that $|a_0|<1$ and this doesn't look useful. Then I thought about looking at $f$ 's degree, but I couldn't make any observations on this. I believe that the key of the problem should be that the polynomial's coefficients are integers, but I don't know how to use that. Apart from the Rational Root Theorem (which doesn't seem useful here) I don't have in mind other results regarding polynomials with integer coefficients.","['abstract-algebra', 'polynomials']"
3822540,Question about a functor related to projective space,"If $V$ is a vector space over $k$ , then the classical way of defining $\mathbb{P}(V)$ is as $(V\backslash\{0\})/k^\times$ . When generalizing this notion to schemes, and in particular if we wish to view projective space as a functor, then this point of view is somewhat abandoned (although of course is always ""in the background""). I was wondering, if $R$ is a fixed ring and $M$ is a fixed (finitely generated) $R$ -module, what can be said about the functor that takes an $R$ -algebra $S$ and sends it to $((M\otimes_{R}S)\backslash\{0\})/S^\times$ ? Here the quotient is taken to mean the orbit space of the natural action of $S^\times$ and so the functor can be seen as going from the category of $R$ -algebras to the category of sets.","['algebraic-geometry', 'category-theory', 'reference-request']"
3822556,"Prove that 4 points are concyclic in a shape which includes right-angle triangles, bisectors, and circumcircles of triangles","I have come across the following question: Let $\triangle ABC$ be right-angled at $A$ and let $AE \perp BC$ . Let $Z\neq A$ be a point on the line $AB$ with $AB=BZ$ , $(c)$ the circumcircle of $\triangle AEZ$ , $D$ the second point of intersection of $(c)$ with $ZC$ , $F$ the antidiametric point of $D$ with respect to $(c)$ , $P=FE\cap CZ$ . If the tangent to $(c)$ at $Z$ meets $PA$ at $T$ , prove that the points $T, E, B, Z$ are concyclic I made the following observations: $\angle EZD=\angle EFD$ (as $DEFZ$ is cyclic) $\angle AZE=\angle AFE$ ( $AFZE$ cyclic) $\angle FED=90^\circ$ ( $FD$ diameter) $B$ is the point where the perpendicular bisector of $AZ$ from $O$ intersects $AZ$ $\angle BAC=\angle AEC=90^\circ$ , and $\angle ACE$ is common, $\implies \triangle BAC\sim \triangle AEC$ Radii $OZ=OD \implies \triangle OZD$ is isosceles We also have that $\angle OAB=\angle AZT$ This is all I managed to think of for this question. Is there anyway to solve it based on some or all of my observations?","['contest-math', 'euclidean-geometry', 'proof-writing', 'geometry', 'problem-solving']"
3822564,Prove $\lim\limits_{x^2 + y^2 \to +\infty} x^2 -2xy + 2y^2 = +\infty$,"Prove that $$\lim_{x^2 + y^2 \to +\infty} x^2 -2xy + 2y^2 = +\infty$$ My attempt: $$x^2 + 2y^2 = x^2+y^2 + y^2 	\implies \lim_{x^2 + y^2 \to +\infty}x^2 +2y^2 = +\infty$$ Then, from Cauchy-Schwarz: $$x^2 + 2y^2 \geq 2\sqrt2xy \geq 2xy $$ Thus, $$x^2+2y^2 -2xy \geq 0$$ I think I am on the correct path, but I don't know how to proceed.","['multivariable-calculus', 'limits', 'calculus', 'real-analysis']"
3822612,ODE $f''''(x)+f(x) = \cos{x} - \left( \sin{x} \right)^2$ with boundary conditions $f(0)=f(\pi); \quad \quad f'(0)=f'(\pi)$,"Today I've attended a Mathematical Methods for Physicist exam and I've found an ordinary differential equation that I could not solve. The exercise asked to find a solution to the equation $$ f''''(x)+f(x) = \cos{x} - \left( \sin{x} \right)^2$$ with boundary conditions $$ f(0)=f(\pi); \quad \quad f'(0)=f'(\pi)$$ First of all, I've written $\sin^2{x}$ = $\frac{1}{2}-\frac{1}{2} \cos{2x}$ ; then I've tried to expand $f(x)$ in Fourier series between $0$ and $\pi$ : $$f(x)=\sum_{n=0}^{\infty} \left( a_n \cos{nx} + b_n \sin{nx}\right)$$ Then I've imposed the first boundary condition. Since $f(0)$ is just the sum of $a_n$ , and $f(\pi)$ is the sum of $a_n (-1)^n$ , the condition is fulfilled if only the even terms are non-zero; hence: $$f(x) = \sum_{n=0}^{\infty} \left( a_{2n} \cos{2nx} + b_n \sin{nx} \right)$$ $$f'(x) = \sum_{n=0}^{\infty} \left( n b_n \cos{nx} - 2n \; a_{2n} \sin{2nx} \right)$$ At this point imposing the second boundary condition gave me a result specular to the first one (only even terms for $b_n$ ): $$f(x) = \sum_{n=0}^{\infty} \left( a_{2n} \cos{2nx} + b_{2n} \sin{2nx} \right)$$ Then I've finally substituted the expanded form of $f(x)$ into the differential equation in order to find the coefficients: $$f''''(x)+f(x) = \sum_{n=0}^{\infty} \left( a_{2n} (16n^4+1) \cos{2nx}  +  b_{2n} (16n^4+1) \sin{2nx} \right) = \cos{x}-\frac{1}{2}+\frac{1}{2}\cos{2x}$$ And now I'm stuck... I can find the coefficients for $n=0$ and $n=1$ , but I don't know what to do with the $\cos{x}$ term. Thanks in advance for any help or suggestion you may give, Lorenzo","['fourier-series', 'mathematical-physics', 'ordinary-differential-equations']"
3822663,Multiple solutions to the Riccati equations?,"Closed form solutions of the Riccati equations are used to find the bond price function for specific one factor short rate interest rate models such as the Vasicek and CIS model. Example taken from Filipović, Damir; Mayerhofer, Eberhard , Affine diffusion processes: theory and applications , Albrecher, Hansjörg (ed.) et al., Advanced financial modelling. Berlin: Walter de Gruyter (ISBN 978-3-11-021313-3/hbk; 978-3-11-021314-0/ebook). Radon Series on Computational and Applied Mathematics 8, 125-164 (2009). ZBL1205.91068 . The state space is $\mathbb{R}$ , and we set $r=X$ for the Vasicek short rate model $$
dr=(b+\beta r)dt+\sigma dW.
$$ The affine system  reads $$
\Phi(t,\ u)=\frac{1}{2}\sigma^{2}\int_{0}^{t}\Psi^{2}(s,\ u)ds+b\int_{0}^{t}\Psi(s,\ u)ds
$$ $$
\partial_{t}\Psi(t,\ u)=\beta\Psi(t,\ u)-1,
$$ $$
\Psi(0,\ u)=u
$$ which admits a unique global solution with $$
\Psi(t,\ u)=\mathrm{e}^{\beta t}u-\frac{\mathrm{e}^{\beta t}-1}{\beta}
$$ $$
\Phi(t,\ u)=\frac{1}{2}\sigma^{2}(\frac{u^{2}}{2\beta}(\mathrm{e}^{2\beta t}-1)+\frac{1}{2\beta^{3}}(\mathrm{e}^{2\beta t}-4\mathrm{e}^{\beta t}+2\beta t+3)
$$ $$
-\ \frac{u}{\beta^{2}}(\mathrm{e}^{2\beta t}-2\mathrm{e}^{\beta t}+2\beta))+b(\frac{\mathrm{e}^{\beta t}-1}{\beta}u+\frac{\mathrm{e}^{\beta t}-1-\beta t}{\beta^{2}})
$$ for all $u\in \mathbb{C}$ . Hence (4.6) holds for all $u\in \mathbb{C}$ and $t\leq T$ . In particular, by Corollary 4.2, the bond prices $P(t,\ T)$ can be determined by $A$ and $B,$ $$
B(t)=-\Psi(t,\ 0)=\frac{\mathrm{e}^{\beta t}-1}{\beta},
$$ $$
A(t)=-\Phi(t,\ 0)=-\frac{\sigma^{2}}{4\beta^{3}}(\mathrm{e}^{2\beta t}-4\mathrm{e}^{\beta t}+2\beta t+3)+b\frac{\mathrm{e}^{\beta t}-1-\beta t}{\beta^{2}}.
$$ Problem: For certain values $b=0.0012587$ , $β=0.00022$ and $σ=0.0041$ , and with $r_0=-0.0031$ , the closed form solution of $P(t,T)$ does not make economical sense, as in general investments will increase in value in a exponential way (except from actually losing money in the first years). The bond price at $t$ is equal to the amount invested at $t$ to receive EUR 1 at $T$ . The blue line depicted in this plot is made using the observed forward rate (the rate at which the investment increases in a time period) and shows this exponential form. If I use the bond price formula obtained with the Riccati equations, I get the orange line, a related but 'wrong' form. By wrong I mean that the starting point and endpoint are the same, but In the same way you can walk the edges of a rectangle in two ways, two paths are possible from start to end. The small difference at $t=0$ can be ignored and it can safely be assumed that the solution is correct at $t=0$ for all $T$ . I ask myself if its possible that the Riccati equations may have more than one solution to choose from?","['ordinary-differential-equations', 'finance', 'stochastic-processes', 'closed-form', 'stochastic-calculus']"
3822708,Solve $y'''-6y''+11y'-3y=2\frac{e^{3x}}{e^{x}+1}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Solve the following differential equation $$y'''-6y''+11y'-3y=2\frac{e^{3x}}{e^{x}+1}~.$$ This question was asked during a test at Toronto University. I tried to find a homogeneous solution and I got very bizarre numbers, which seems to hint this is not the way to solve this ode. I gave to WA as it is to try to solve it, it surrendered (at least without pro)
Does anyone have any suggestions?",['ordinary-differential-equations']
3822726,When is a multivariable limit path independent?,"When I had calculus I was taught that the limit of a multivariable limit can be path-dependent.
So In order to check if a limit exists, you should, in theory, check every possible path, which is infinitely many. So how do I actually calculate a multivariable limit? Just because I have checked one path, it doesn't necessarily mean the limit would be the same at every path? Is there an easy way to know whether a limit is path independent, or when a multivariable limit might be path dependent? Consider the limit: $$\lim _{(x, y) \rightarrow(2,3)} 2x^3-y^{2}=16-9=7$$ How do I know that I can just put in the values in this case? $$\lim _{(x, y) \rightarrow(0,0)} \frac{x^{2} y}{x^{4}+y^{2}}$$ I know this limit does not exist, because if you go along the path $y=mx$ the limit is 0. But if you go along the parabola $y=\pm x^2$ the limit is $\pm \frac{1}{2}$ . How are these two cases different. I mean how can you immediately see that the first case is path independent, but the second case may not be?",['multivariable-calculus']
3822734,Unifying abstraction of duality between $A - B$ and $A + B$,"I'm wondering whether there's an abstraction that unifies the special cases of dual or complementary equations of the form $A - B$ and $A + B$ that I've seen in math. Here are some examples: 1: Even and Odd Parts of Functions If $A = f(x)$ and $B = f(-x)$ then $\frac{A + B}{2}$ is the even part of $f$ and $\frac{A - B}{2}$ is the odd part of $f$ . For instance if $f(x) = e^x$ then $\frac{f(x) + f(-x)}{2} = \cosh x$ and $\frac{f(x) - f(-x)}{2} = \sinh x$ . 2: Real and Imaginary Parts of Complex Numbers If $A$ and $B$ are conjugate complex numbers, then $\frac{A + B}{2}$ is the real part of $A$ and $\frac{A - B}{2 i}$ is the imaginary part of $A$ . 3: Lagrangian and Hamiltonian This example is from physics, but I'm posting on this stackexchange (not physics) because I'm looking for a mathematical answer. In classical mechanics, two useful formulations are the Lagrangian and the Hamiltonian. The Lagrangian of a given system is the kinetic energy of the system minus the potential energy, $L = T - V$ . The Hamiltonian is the kinetic energy plus the potential energy, $H = T + V$ . So I'm wondering if anybody knows of any unifying abstractions of which some of the above are special cases.  Or if anybody has more diverse examples of dualities between $A - B$ and $A + B$ to add, please comment.","['classical-mechanics', 'algebra-precalculus', 'systems-of-equations']"
3822754,"Prove that a transitive relation can be ""shortcutted""","I want to prove the following theorem and already spent a lot of time on doing this, but almost unsuccessfully: Let $R$ be a transitive relation over the set $A$ . Prove that in the graphical representation of the relation (that is, the graph $(A, R)$ ), that $(u, v) \in R$ if $v$ is reachable from $u$ . So, reachability here I think means that there is a path from $u$ to $v$ . What I tried so far: I tried to prove that "" $v$ is reachable from $u$ $\implies uRv$ "" using contradiction that $u \not R v$ . I thought that if there is a path, then we can find some $x$ , where $uRx$ , but $x \not R v$ , otherwise it would mean that $uRv$ . And this led me to the conclusion that it must be at least one more point between $x$ and $v$ and so on ad infinitum. Another attempt was hiring contrapositive with further contradiction (if $u \not R v \implies v$ is not reachable from $u$ . Then for the sake of contradiction assuming that there is a path between $u$ and $v$ ). But this also led me to the same result as the first one. Since the first and the second attempts led me to an ""endless"" path between $u$ and $v$ I thought that induction can be a solution here. First of all, let's assume that any set, constructed of the elements of the path $uRx_1, x_1Rx_2, ..., x_nRv$ have the greatest element in respect to $R$ .  (I will prove it if my proof of the original theorem is correct). So let $P(n)$ is true when ""if there is $n$ -length path between $u$ and $v$ , then $uRv$ "" is true. I'm not sure but it seems that $P(0)$ is true, because there is always a zero-path between any elements. Let's consider any $n+1$ -length path and remove the greatest element $x_{n+1}$ from it. The resulting path has length $n$ , so that we sure know that $uRx_n$ . Now put the $x_{n+1}$ back and since we know that $x_{n + 1}$ is the greatest it means that $x_{n} R x_{n+1}$ . Then by transitivity we have that $uRx_{n+1}$ . UPDATE: First of all, let's assume that any set, constructed of the elements of the path $uRx_1, x_1Rx_2, ..., x_nRv$ have the greatest element in respect to $R$ Now I think that this lemma above is another way to prove the theorem. So if I proved it, I could prove that the greatest element is $v$ and then we would have $uRv$ . I'm sorry for a lot of text, but I'd like you to look at all my attempts and, probably, suggest how I can improve all of them to prove the theorem (if this is possible). So does my induction hypothesis seem good or is there a better one for this theorem? Is it correct to say that $P(0)$ is true? And could you please provide any hints how this theorem can be proved without induction (like I tried in my first and second attempts) if this is possible? I'd be also grateful if you can criticize my conclusions and assumptions.","['proof-writing', 'relations', 'solution-verification', 'elementary-set-theory', 'induction']"
3822755,"For a martingale $M$, $\lim_{a\to\infty}\lim_{t\to\infty} \mathbf E( M_t; \int_0^t M_s ds > a ) = 0$?","Does the following equality right? \begin{equation}
  \lim_{a\to\infty}\lim_{t\to\infty} \mathbf E\left( M_t; \int_0^t M_s ds > a \right) = 0,
\end{equation} where $M = \{M_t\}_{t\ge0}$ is a martingale. Intuitively, I think it is right. Because $\mathbf E(M_t) = \mathbf E(M_0)$ is a finite time-independent constant. And as $a\to\infty$ , $\mathbf P(\int_0^t M_s ds > a)$ is expect to vanish. But I don't know how to prove it rigorously. Can anyone give some hints? Or if the equality does not hold true, some counterexamples will be appreciated. TIA... PS: By $\mathbf E(X;A)$ , I mean $\mathbf E(X\mathbf 1_A)$ . EDIT: As answered by @user159517 through a trivial counterexample, this is wrong in general. However, is there any possibility that it does hold for some non-trivial martingales, say, for example, the exponential martingale which is crucial in the Girsanov theorem ?","['stochastic-analysis', 'stochastic-processes', 'martingales', 'probability-theory', 'stochastic-calculus']"
3822762,Is it possible to approximate any Borel measure with Dirac's Deltas?,"Given a complete separable metric space $(X,d)$ .
My question is if it is true that for any finite positive Borel measure $\mu\in\mathcal{M}^+_b(X)$ there exists a sequence of finite atomic measures $a_n\in\mathcal M^+_b(X)$ such that $$
a_n\rightharpoonup \mu,
$$ i.e. $a_n$ converges narrowly to $\mu$ . The most obvious guess is that given $x_n$ a dense sequence in $X$ and $U^i_n$ are disjoint open sets such that $$
\bigcup_i U^i_n=B(x_0,n)
$$ we define $$
a_n=\sum_{i=1}^{g(n)}\delta_{x_i}\mu(U^i_n),
$$ where $g$ should have the property $$
\lim_n \frac{g(n)}{\mu(B(x_0,n))}=C.
$$ Then we should have that for any continuous bounded function we have $$
\int_X f\ da_n=\sum_{i=1}^{g(n)} f(x_i)\mu(U^i_n)\rightarrow\int_Xf\ d\mu.
$$ It should happens because $$
\sum_{i=1}^{g(n)} \min_{U_n^i}(f)\chi_{U^i_n}\leq f\leq\sum_{i=1}^{g(n)} \max_{U_n^i}(f)\chi_{U^i_n}
$$ but there is no reason to infer that the choice of $U_n^i$ is good enough to refine the step functions from above and below well enough to obtain the integrals.
Because we would need the choice to be independent of the function $f$ . What am I missing? Is it possible to begin with? Where can I find this result in the literature?","['integration', 'measure-theory', 'borel-measures', 'real-analysis']"
3822770,Showing Holder's inequality holds for $p=\infty$ and $q=1$,"We're asked to show that Holder's inequality (for the case when $1/p + 1/q = 1$ ) holds for the case when $p=\infty$ and $q=1$ . The inequality is given to us in the following form. $\sum\limits_{i=0}^\infty \vert a_ix_i \vert \leq \vert \vert a \vert \vert_q \vert \vert x \vert \vert_p$ Here's my proof and I'd like to make sure that the logic is sound. $$
\begin{align*}
   \sum \vert a_i x_i \vert &\leq \vert \vert a \vert \vert_\infty \vert \vert x \vert \vert_1 &&\text{plug in variables} \\
                            &= \max(\vert a \vert) \vert \vert a \vert \vert_1 &&\text{value of infinite norm}
\end{align*}
$$ Now divide by $\max(\vert a \vert)$ $$
\sum \cfrac{\vert a_i x_i \vert}{\max(\vert a \vert)} \leq \vert \vert x \vert \vert_1
$$ We know that $\sum\limits_{i=o}^\infty \cfrac{\vert a_i x_i \vert}{\max(\vert a \vert)} \leq \sum \vert x_i \vert $ because $\cfrac{|a_i|}{\max(|a|)} \leq 1\, \forall a_i \in a \in \ell_\infty $ . Now we have that $\sum \vert x_i \vert \leq \vert \vert x \vert \vert_1$ . These are, in fact, equal to each other. So we see that our case when $p=\infty$ and $q=1$ holds. If there something I ought to do to make the proof easier to understand, please let me know.","['holder-inequality', 'solution-verification', 'functional-analysis']"
3822789,Can the set of all sets be vacuously determined?,"Can I say that the empty set is vacuously the set of all sets since there isn’t anything in it to disprove such statement? But in this case, I guess it would turn out to be an impossibility to vacuously determine the set of all sets since its power set would reveal to be an infinite not vacuous set: $\mathcal{P}(\emptyset)$ , $\mathcal{P}(\mathcal{P}(\emptyset))$ , $\mathcal{P}(\mathcal{P}(\mathcal{P}(\emptyset))))$ , $\dots$",['elementary-set-theory']
3822792,$dh/dt$ given $dV/dt$,"I have a textbook problem whose answer is different from the one I got. The problem goes: A conical egg timer is letting sand through from top to bottom at a rate of $0.02\,\mathrm{cm^3s^{-1}}$ .
find an expression for the rate of change of height ${\dfrac{dh}{dt}}$ . (There is a diagram showing the full height of the conical egg timer as $5\,\text{cm}$ and the radius of its base as $2\,\text{cm}$ . The value of $h$ is the height of the sand in the conical egg timer.) My Attempt: What I understand from this question is that: The conical egg timer is an upside-down cone, so its volume is ${V={\frac{1}{3}{\pi}r^{2}h}}$ , which is also the same as the volume of the sand within it at the beginning. The rate of change of volume of the sand within the conical egg timer with respect to time is ${\dfrac{dV}{dt}}=-0.02$ . The diagram shows the radius at the base of the conical egg timer (or ""top"" since it is upside-down) to be ${2}$ and its full height from base to ""point"" to be ${5}$ . The sand exits from the ""point"" so its height decreases from its base (the top). The question is asking me to find the rate of change of the height of the sand within the timer with respect to time, or ${\dfrac{dh}{dt}}$ . Given this information, I attempted to answer the problem: If I am correct, the values given at the start are: ${\dfrac{dV}{dt}}=-0.02$ and (at the very beginning, when the cone is full of sand, assuming it starts full) $h=5$ and $r=2$ . First, I differentiated the volume ${V}$ with respect to ${h}$ , giving ${\dfrac{dV}{dh}={\frac{1}{3}}{\pi}{r^{2}}}$ (using the power rule for differentiation) . $\to {\dfrac{dV}{dh}={\frac{1}{3}}{\pi}{r^{2}}}$ Secondly, I used the relationship of the derivative of a function and the derivative of its inverse to get ${\dfrac{dh}{dV}}={\dfrac{1}{\dfrac{dV}{dh}}}={\dfrac{1}{\frac{1}{3}{\pi}r^{2}}}={\dfrac{3}{{\pi}r^{2}}}$ (using the inverse function theorem (I don't fully understand why derivatives of inverses are reciprocals to one another but that's the rule I used)) . $\to {\dfrac{dh}{dV}}={\dfrac{3}{{\pi}r^{2}}}$ Thirdly, I multiplied ${\dfrac{dV}{dt}}$ and ${\dfrac{dh}{dV}}$ to get ${\dfrac{dh}{dt}}=-0.02 \times{\dfrac{3}{{\pi}r^{2}}}={\dfrac{-0.06}{{\pi}r^{2}}}={\dfrac{-3}{50{\pi}r^{2}}}$ (using the chain rule for differentiation) . $\to {\dfrac{dh}{dt}}={\dfrac{-3}{50{\pi}r^{2}}}$ Then, I used the initial values of the height and radius of the sand in the cone to write ${\dfrac{dh}{dt}}$ in terms of $h$ . The initial values of $h$ and $r$ are the values found in the diagram: $h=5$ and $r=2$ $\to {\dfrac{dh}{dt}}={\dfrac{-3}{50{\pi}r^{2}}}={\dfrac{-3}{50{\pi}({2})^{2}}}={\dfrac{-3}{200{\pi}}}={\dfrac{-3}{40h{\pi}}}={\dfrac{-3}{8{h^{2}}{\pi}}}={\dfrac{-3}{8{\pi}h^{2}}}$ (replacing $r$ in the equation with $2$ and then replacing every multiple of $5$ in the equation with $h$ ) . $\to$ my answer is ${\dfrac{dh}{dt}}={\dfrac{-3}{8{\pi}h^{2}}}$ . C) The answer given in the textbook however, is ${\dfrac{dh}{dt}}={\dfrac{-1}{8{\pi}h^{2}}}$ . Question: I'd like to ask for help with regards to finding where I made my error(s), so I hope my working is easy to follow- I am also unsure about whether this is the correct way to answer the question in the first place - thanks.","['volume', 'derivatives', 'ordinary-differential-equations']"
3822847,Establishing a bijection between subgroups of the domain that contain the kernel and subgroups of the codomain,"Let $\phi: G \to \overline{G}$ be a surjective homomorphism with kernel $K$ . I am wondering if there is a bijection from the collection of subgroups of $G$ that contain $K$ , $\{ S: S \leq G, S \supseteq K \}$ , and the collection of subgroups of $\overline{G}$ , $\{\overline{S}: \overline{S} \leq \overline{G} \}$ . My attempt: Let $A := \{ S: S \leq G, S \supseteq K \}, B := \{\overline{S}: \overline{S} \leq \overline{G} \}$ .  I considered the function $f: B \to A$ that sends $\overline{S}$ to $\phi^{-1}(\overline{S})$ , the preimage of $\overline{S}$ under $\phi$ . We need to check three things: that this function is well-defined, that it is surjective, and that it is injective. [TL;DR: I think I have showed well-defined-ness and surjectivity, but I'm not sure about injectivity.] Well-defined : Given a subgroup $\overline{S}$ of $\overline{G}$ , we need to show that its preimage (under $\phi$ ), call it $S$ , is a subgroup of $G$ that contains $K$ . This would show that $f$ is indeed well-defined. $S$ contains $K$ because given $g \in K$ , we have $\phi(g) = \overline{e} \in \overline{S}$ . Since $K$ is nonempty, so is $S$ , and so to show that $S$ is a subgroup, all that remains is to show closure under the operation and closure under inverses. Thus, let $x, y \in S$ . Then $\phi(xy) = \phi(x)\phi(y) \in \overline{S}$ , which shows closure under the operation. Finally, $\phi(x^{-1}) = \phi(x)^{-1} \in \overline{S}$ , which shows closure under inverses. Surjective : Given $S \leq G, S \supseteq K$ , we want to show that $S$ is the preimage of some subgroup $\overline{S}$ of $\overline{G}$ . I claim that the image of $S$ , $\phi(S)$ , satisfies this. That is, I claim that $\phi(S)$ is a subgroup of $\overline{G}$ and $\phi^{-1}(\phi(S)) = S$ . First, we prove that $\phi(S)$ is a subgroup of $\overline{G}$ . Well, $\phi(S)$ is nonempty because it contains $\overline{e} = \phi(e)$ . It is closed under the operation because given $s, t \in S$ , we have $\phi(s)\phi(t) = \phi(st) \in \phi(S)$ . It is closed under inverses because $\phi(s)^{-1} = \phi(s^{-1}) \in \phi(S)$ . Next, we show that $(\phi^{-1}(\phi(S)) = S$ . The containment $S \subseteq (\phi^{-1}(\phi(S))$ is a standard fact about images/preimages. As for $(\phi^{-1}(\phi(S)) \subseteq S$ , suppose $x$ is in the LHS, so that $\phi(x) \in \phi(S)$ , so that $\phi(x) = \phi(s)$ for some $s \in S$ . So $\overline{e} = \phi(x)\phi(s)^{-1} = \phi(xs^{-1})$ , hence $xs^{-1} \in K$ . Since $K \subseteq S$ by assumption, this means $xs^{-1} \in S$ , so $x \in S$ . Injective : This is where I am stuck. I think I should show that no subgroup $S$ of $G$ that contains $K$ can be the preimage of two different subgroups of $\overline{G}$ , which I've tried to do but am not sure how.",['group-theory']
3822962,Computing the genus of $y^2=x(x^2-1)$ using 1-forms,"I'm trying to compute the genus of the projective curve $C:=V(Y^2Z-X(X^2-Z^2))\subset\Bbb{P}^2_\Bbb{C}$ explicitly using differential forms. I know beforehand that this is an elliptic curve, so the expected answer is $g=1$ . So I must find a globally defined differential $1$ -form $\omega\in\Omega_C$ . In $U_Z:=\{Z\neq 0\}$ , we define $x:=\frac{X}{Z}$ and $y:=\frac{Y}{Z}$ , so that $y^2=x(x^2-1)$ $(*)$ . I've read in more than one source that the desired form is $\omega:=\frac{dx}{y}$ . Using $(*)$ , we have $\frac{dx}{y}=\frac{2dy}{3x^2-1}$ and since $3x^2-1\neq 0$ at the points $(0:0:1),(1:0:1),(-1:0:1)\in C$ , we see that $\omega$ has no poles in $U_Z$ . We still have to check that $\omega$ has no pole at infinity $(0:1:0)$ . So we restrict to $U_Y$ and define $u:=\frac{X}{Y}, v:=\frac{Z}{Y}$ , so that $v-u^3+uv^2=0$ $(**)$ . This way: $$\frac{dx}{y}=v\cdot d\left(\frac{u}{v}\right)=du-\frac{dv}{v}$$ I still can't see how to use $(**)$ to rewrite $\frac{dv}{v}$ so that the pole will vanish. Am I missing something?","['elliptic-curves', 'algebraic-geometry', 'differential-forms']"
3822987,Give an example of a function that is solution of $y'=f(x)$ and you can't express it as $ y=\int_{a}^{x}f(s)ds$,"Give an example of a function that is solution $y'=f(x)$ and you can't express it as $ y=\int_{a}^{x}f(s)ds$ This is a question that my ODE's theory professor asked to us and he said that the ""trick"" is to find a proper domain and a proper function such that the funcion has derivative on that domain but the derivative is not an integrable function. My professor said that the purpose is to show the reason why the fundamental theorem of calculus asks for the integrability of the derivative function.","['integration', 'calculus', 'ordinary-differential-equations']"
3823048,Is the line created by the minor axis of an ellipse concurrent to the lines running to the opposite vanishing point?,"My questions needs more context than what can fit into the title so let me elaborate. In pretty much all the art textbooks I am reading on linear perspective they state that the correct way of placing an ellipse is to imagine the minor axis of an ellipse as an axel of a wheel running to the opposite vanishing point. Here are examples for the various types of perspective the textbooks mention. One point perspective: In one point perspective only one set of parallel lines of a cuboid are concurrent, the other two sets are parallel (one set parallel to the horizon, the other perpendicular to it). If we plot an ellipses inside a one-point square the minor axis' should all run vertical (to the non-concurrent vanishing point). We find that only ellipses whose major axis are perpendicular to the vanishing point (A`) have this property. Two point perspective: In two point perspective two of the sets of parallel lines of a cuboid are concurrent (meeting at R3 & S3 in the image) and the other set are not concurrent (parallel). I tried placing an ellipse such that the perspective center points of the sides of the quadrilateral are the tangent points of the ellipse but the minor axis does not seem concurrent with the lines running to the opposite concurrence (vanishing point). It should be stated that the two quadrilateral and their concurrences are a mirror reflection of each other, but this is not always the case in two point perspective. If I adjust the size of the bounding quadrilateral I can make the minor axis concurrent with the lines running to the opposite vanishing point... but what if I want an ellipse placed inside a different sized quadrilateral? Am I missing something in my plotting of ellipses or are the authors of these textbooks mistaken?","['projective-geometry', 'conic-sections', 'geometry']"
3823059,Wronskian type of equation,"I am reviewing some old notes on dynamical system and came across a result that reminds me to the Wronskian equation except that here we are dealing with a nonlinear equation: Let $\phi(t;{\bf x})$ be a solution to the
equation $\dot{{\bf x}}(t)= f(t,{\bf x}(t))$ ,
with $\phi(0;{\bf x})={\bf x}$ .
Define the function $W$ by $$
\begin{align}
W(t,{\bf x})&=\det\left[\frac{\partial \phi}{\partial {\bf x}}(t;{\bf x})\right].
\end{align}
$$ Then, $W$ satisfies the differential equation $$
\dot{W}(t)=W(t)\, (\nabla_{\bf x}\cdot f)(t,\phi(t;\mathbf{x})); \qquad W(0)=1,
$$ where $\left(\nabla_{\bf x}\cdot f\right)(t,\phi(t;{\bf x})) =\sum_{j=1}^n \frac{\partial f}{\partial x_j}(t,\phi(t;{\bf x}))$ I am trying to prove this result but I am completely at odds. Any hints or a sketch of a solution will be appreciated.","['ordinary-differential-equations', 'dynamical-systems']"
3823112,Solving $\sin80^\circ\sin20^\circ\sin x = \sin 10^\circ\sin60^\circ\sin(30^\circ+x)$,Solve: $$\sin80^\circ\sin20^\circ\sin x = \sin 10^\circ\sin60^\circ\sin(30^\circ+x)$$ I tried cancelling $\sin10^\circ$ $$\sin80^\circ\cdot 2\cos10^\circ\cdot\sin x=\sin60^\circ\sin(30+x)$$ $$\frac{2\sin^280^\circ}{\sin60^\circ} = \frac{\sin(30^\circ+x)}{\sin x}$$ Then I'm stuck.,"['euclidean-geometry', 'trigonometry', 'geometry']"
3823153,"If $\frac{1}{2y} \int_{x-y}^{x+y} f(t) \space \mathrm{d}t = f(x)$, then $f$ is linear","The problem is: $f : \mathbb{R} \to \mathbb{R}$ is a twice differentiable function such that $$ \frac{1}{2y} \int_{x-y}^{x+y} f(t) \space \mathrm{d}t = f(x) \quad [x \in \mathbb{R}, \space y>0] $$ Show $f(x) = ax + b$ for some $a, b$ for all $x \in \mathbb{R}$ I have seen various solutions to this problem online, but I found one that does not use the twice-differentiable property, and was wondering if I had made a slip somewhere. Solution By differentiating w.r.t. $y$ , we get $$\frac{f(x+y) + f(x-y)}{2} = f(x)$$ This means that $f$ has the property that if any two points lie on the graph of $f$ , so does their midpoint. As a corollary, if $P_1, P_2$ lie on this graph, then if $P_3$ is a point such that the midpoint of $P_1P_3$ is $P_2$ , then $P_3$ lies on the the graph also. So now let $A = (0, f(0)), \space B = (1, f(1))$ , and the line joining them be given by $y = g(x) = ax+b$ . By the property described above, this means that $f(\pm 2^n) = g(\pm 2^n) \space [n \in \mathbb{Z}]$ . So by a 'binary search' procedure, we can, for any $k$ , construct a sequence $a_n$ with $\lim a_n = k$ and $f(a_n) = g(a_n)$ . But then, since $f$ and $g$ are both continuous, we wind up with $f(k) = g(k)$ , which is what we wanted to prove.","['calculus', 'solution-verification']"
3823166,Divisor of a rational section in Ravi Vakil's notes,"The following is from Exercise 14.2.A of Ravi Vakil's algebraic geometry notes (page 401 here ). The exercise asks us to consider the rational section $\frac{x^2}{x+y}$ of the sheaf $\mathcal{O}(1)$ on $\mathbb{P}_{k}^1$ and to compute the corresponding Weil divisor of poles and zeroes. I have a solution but it seems to go against what I think should be intuitively true so I was hoping someone could check it for me. First of all, it seems to me that intuitively the resulting Weil divisor should be $2[(x)] - [(x+y)]$ . However, let me explain my reasoning that led to a different result. To compute the divisor of a rational section of an invertible sheaf we first have to choose a trivialisation. The obvious choice here is to trivialise on the open subset $D_+(x+y)$ of $\mathbb{P}^{1}$ . This gives a trivialisation, $$
\Psi: \mathcal{O}(1)|_{D_{+}(x+y)} \stackrel{\times \frac{1}{x+y}}{\longrightarrow} \mathcal{O}|_{D_{+}(x+y)}.
$$ On sections, we obtain a map on the ring of homogenous polynomials, $$
\Psi_{D_{+}(x+y)}: k \Big[ \frac{x}{x+y}, \frac{y}{x+y}    \Big] \cdot (x+y) \longrightarrow k \Big[\frac{x}{x+y} , \frac{y}{x+y}\Big].
$$ Then under this trivialisation, we obtain a section of the field of rational functions on $\mathbb{P}^{1}$ . Namely we obtain the quotient of homogenous polynomials of the same degree, $$
\frac{x^2}{(x+y)^2}.
$$ This then of course gives a Weil divisor of poles and zeroes of $2[(x)] - 2[(x+y)]$ . My confusion is that Ravi seems to say that you need to choose a trivialisation to compute this Weil divisor. But then of course a result of this is that ever single rational section of a line bundle on $\mathbb{P}^{1}$ gives a Weil divisor of degree $0$ , since after choosing a trivialisation we will always have a quotient of homogenous polynomials of the same degree. I thought that was only true for principle Weil divisors, not locally principal. So which answer is correct, my initial intuition, or the answer I obtained by doing the calculation through a trivialisation?","['projective-schemes', 'divisors-algebraic-geometry', 'algebraic-geometry', 'schemes', 'line-bundles']"
3823177,why $\bigcap\mathscr A= A ?$,Taken from General Topology by stephen willard My confusion given in red box My attempt : here its given $\bigcap\mathscr A= A$ I think it should be $\bigcap\mathscr A = \emptyset$ Note : Im not able to write  that letter in mathsjax,"['elementary-set-theory', 'general-topology']"
3823203,A problem on subspaces,I was studying for some quals and I remember running into this problem last year and I couldn't get anywhere with it. Even now I'm kind of stumped. I was wondering if you guys had any ideas. Here's the problem: Let $ V $ be a vector space and let $ 1\leq n< \operatorname{dim}(V) $ be an integer. Let $ \{V_i\} $ be a collection of $ n $ -dimensional subspaces of $ V $ with the property that $$ \operatorname{dim}(V_i\cap V_j) = n-1 $$ for every $ i\neq j $ . Show that at least one of the following holds: (i) All $ V_i $ share a common $ (n-1) $ -dimensional subspace. (ii) There is an $ (n+1) $ -dimensional subspace of $ V $ containing all $ V_i $ .,['linear-algebra']
3823304,Find the value of $k$ which minimises $F(k)= \int_{0}^{4} |x(4-x)-k|dx$,"QUESTION: Find the value of $k$ which minimises $$F(k)=\int_{0}^{4} |x(4-x)-k|dx$$ MY APPROACH: Clearly $4x-x^2$ is a downward concave parabola with the roots $0$ and $4$ . And $y=k$ is a line parallel to the $x$ axis. Now, the modulus of the area bounded by these two curves can be divided into two parts - A- the area under the parabola and above the line. B- the area above the parabola and under the line. Now, the line intersects the parabola at $4x-x^2=k$ . Call the two roots of this equation $\alpha_k$ and $\beta_k$ (obviously, $\alpha$ and $\beta$ are functions of $k$ ). Without loss of generality, assume that $\alpha_k \le \beta_k$ (equality is achieved when the line is tangential to the parabola, at $(2,4)$ ) $$\therefore F(k)= \underbrace{ \int_{0}^{\alpha_k} \big( k - x(4-x) \big) dx}_{m}  + \int_{\alpha_k}^{\beta_k} \big( x(4-x) - k \big) dx + \underbrace{\int_{\beta_k}^{4} \big( k - x(4-x) \big)}_{n} dx$$ Now, due to symmetry of the problem, $m$ and $n$ must have the same value. Hence, we can write, $$F(k)= 2 \int_{0}^{\alpha_k}\big( k - x(4-x) \big) dx +  \int_{\alpha_k}^{\beta_k} \big( x(4-x) - k \big) dx $$ And the rest of the problem can be solved by Leibniz rule of differentiating under the integral sign. But the problem is $$\alpha_k=\frac{4-\sqrt{16-4k}}{2}$$ and $$\beta_k= \frac{4 + \sqrt{16-4k}}{2}$$ which obviously doesn't look very nice.. I am stuck here..
Am I even going in the right direction ? Your help to complete this sum and/or any alternate (hopefully simpler) solution is much appreciated.. Thank you so much 😊.. (I attach a graph below, for better clarity on whatever I have said above.. Note that: the green line is variable, that's $y=k$ )","['integration', 'maxima-minima', 'calculus', 'functions', 'solution-verification']"
3823326,Determinant of a certain Toeplitz matrix,"Compute the following determinant $$\begin{vmatrix} x & 1 & 2 & 3 & \cdots & n-1 & n\\ 1 & x & 1 & 2 & \cdots & n-2 & n-1\\ 2 & 1 & x & 1 & \cdots & n-3 & n-2\\ 3 & 2 & 1 & x & \cdots & n-4 & n-3\\ \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\ n-1 & n-2 & n-3 & n-4 & \cdots & x & 1\\ n & n-1 & n-2 & n-3 & \cdots & 1 &x \end{vmatrix}$$ I tried the following. I subtracted the second row from the first, the third from the second, the fourth from the third, and so on. I got: \begin{vmatrix} x-1 & 1-x & 1 & 1 & \cdots & 1 & 1\\ -1 & x-1 & 1-x & 1 & \cdots & 1 & 1\\ -1 & -1 & x-1 & 1-x & \cdots & 1 & 1\\ 3 & 2 & 1 & x & \cdots & n-4 & n-3\\ \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\ -1 & -1 & -1 & -1 & \cdots & x-1 & 1-x\\ n & n-1 & n-2 & n-3 & \cdots & 1 &x \end{vmatrix} I did the same thing with the columns. I subtracted the second row from the first, the third from the second, the fourth from the third, and so on. And I got: \begin{vmatrix} 2x-2 & -x & 0 & 1 & \cdots & 0 & 1\\ -x & 2x-2 & -x & 1 & \cdots & 0 & 1\\ -2 & -x & 2x-2 & 1-x & \cdots & 0 & 1\\ 1 & 1 & 1-x & x & \cdots & -1 & n-3\\ \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\ -2 & -2 & -2 & -1 & \cdots & 2x-2 & 1-x\\ 1 & 1 & 1 & n-3 & \cdots & 1-x &x \end{vmatrix} I hope I didn’t make a mistake somewhere. With this part I don't know what to do next. I don't know if I'm doing it right. Thank you in advance !","['matrices', 'toeplitz-matrices', 'determinant']"
3823382,Homotopy Classification of Torus Maps,"In problem 8-11 of Lee's ""Intro to Topological Manifolds"", the reader is asked to show that for every continuous $\phi:\mathbb{T}^2\to\mathbb{T}^2$ , there is a $2\times 2$ integer matrix $D(\phi)$ with the following properties: $\phi,\psi$ are homotopic iff. $D(\phi)=D(\psi)$ $D(\psi\circ\phi)=D(\psi)D(\phi)$ For every $2\times 2$ integer matrix $E$ , there is a continuous $\phi$ with $D(\phi)=E$ $\phi$ is homotopic to a homeomorphism iff. $D(\phi)\in GL(2,\mathbb{Z})$ This is clearly some analogue of the degree of a map, as introduced in the book for maps from the circle to itself. Since $\mathbb{T}^2=S^1\times S^1$ , the fundamental group is $\mathbb{Z}\times\mathbb{Z}$ and so endomorphisms of $\pi_1(\mathbb{T}^2)$ are indeed $2\times 2$ integer matrices. I have shown, without constructing such a matrix explicitly, that they satisfy 1) and 2). For 3), however, I am not sure how to do this without explicitly constructing the matrix for a given map $\phi$ , and I am unsure how to construct this matrix. It is clearly related to the winding number of the map around the torus, but from that I can only extract two integers, as far as I can tell. How would I construct this matrix, or alternatively, how could I prove that every endomorphism has at least one associated map?","['general-topology', 'fundamental-groups', 'algebraic-topology']"
3823417,Periodic orbits enclosing fixed points in a differential equation,"Suppose we have a differential equation $\mathbf{\dot{x}}=\mathbf{f(x)}$ for $\mathbf{x}\in \Bbb{R}^2$ . Suppose further that there are three fixed points, of which one is a saddle and two are sinks. I am not sure how to determine examples of the following scenarios or to prove they do not exist: There exists a periodic orbit enclosing precisely one sink. There exists a periodic orbit enclosing all three fixed points. The index test does not rule out either of these possibilities and I am unsure how to construct examples demonstrating existence. Any help would be much appreciated!","['stability-in-odes', 'ordinary-differential-equations', 'dynamical-systems']"
3823421,"The probability of picking a rational number in the segment $ [0,1] $","I'm interested in something that came to my mind regarding the probability function. We know that the probability function is additive over countable sets. Now, let's take the set $ A $ to be the set of all rational numbers in the segment $ [0,1] $ . Assume I want to calculate the probability to pick $ 0.5 $ . My initial thought would be that the probability would be $ 0 $ , because there are infinity rational numbers in the segment $ [0,1] $ , and intuitively I cannot see a reason that the probability to pick $ 0.5 $ would be different from the probability to pick $ 0.23 $ . So I'll assume that the probability of any rational number in the segment should be equal, thus, it has to be $ 0 $ . In the other hand, if it is indeed $0$ probability for any rational number, since $ A $ is a countable set we can sum the probabilities of all the rational numbers in $ [0,1] $ and get that the sum equal to $ 0$ . That's of course a contradiction because $ P(A)=1 $ . So I guess my first assumption that the probability of any rational number is equal, is incorrect. It means that some rational numbers has a higher probability to be picked than others. Can someone explain, intuitively, how can it be? And is there a way to calculate the probability of each rational number to be picked? Thanks in advance.","['probability-theory', 'probability']"
3823431,Isomorphism of $S^1$.,"Define $S^1 = \{ z \in \mathbb{C^*} \: : \: |z| = 1 \}$ . My question is, does there exist some ring $R$ such that $(R, + )$ is isomorphic to $S^1$ ? My intuition says no but how would I go about showing that.","['complex-analysis', 'ring-theory', 'group-theory', 'abstract-algebra']"
3823478,How to prove $L^{\infty}(\mathbb R) \cap L^{1} (\mathbb R) \subset L^{2}(\mathbb R)$,"How to prove $$L^{\infty}(\mathbb R) \cap L^{1} (\mathbb R) \subset L^{2}(\mathbb R),$$ $\mathbb R$ being the real value domain. Why is it that having the function upper-bounded and lower bounded with integrability allows the square to be integrable. L of course are Lp norms for functions.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'lp-spaces', 'functional-analysis']"
3823503,"For a non-vanishing field $X$ and $a\in C^1(\mathbb R^n;\mathbb C)$, how to reduce the study of $X\cdot \nabla u +au= f$ to the study of $Xv=g$?","I'm doing exercises in the first chapter of Serge Alinhac's ""Hyperbolic Partial Differential Equations"", and while most of the other exercises for this chapter are straightforward, I'm stuck on Q3: Let $X$ be a non-vanishing field in $\mathbb R^n$ and $a\in C^1(\mathbb R^n)$ a complex function. Explain how the study of the equation $Xu+au = f$ can be (locally) reduced to the study of the equation $Xv=g$ . Here, Serge is using the notation $Xu \triangleq X\cdot\nabla u$ ; $u$ is a scalar function (presumably, due to $a$ , taking values in $\mathbb C$ ). I would assume $f,g$ can be taken to be smooth. Things I've tried: The ""(locally)"" that appears in the question suggests to me a change of variables. But if I say let tildes mean composition with some nice $\phi$ , e.g. $\tilde u=u\circ \phi$ and so on, all I end up with is $(\tilde X \cdot ((\nabla \phi)^{-1}\circ \phi)\nabla \tilde u) +  \tilde a \tilde u = \tilde f$ which doesn't seem helpful. I tried to consider the real and imaginary parts. (Earlier in the book, it is remarked that $\partial_t + i\partial_x$ is the Cauchy-Riemann operator; the real and imaginary parts of $\partial_tu + i\partial_xu =0$ form precisely the standard system called the Cauchy-Riemann equations) But I don't see any way to continue from the resulting system. If say $u=v+iw$ , $f=g+ih$ , and $a=b+ic$ , then the two equations you get for $(v,w)$ are $$ Xv+bv - cw = g, \\ Xw + cv + bw = h.$$ I tried to use what I know from basic ODE theory, namely integrating factors. If I could solve $Xz = az$ , with $z\neq 0$ everywhere, then by Leibniz rule, $$ X  (uz) = zXu + uX z = z Xu + au z $$ Then $$Xu + au = f\iff zXu + auz = fz \iff X(uz) = fz$$ Of course, one takes $uz=v$ and $fz=g$ , to match the question's notation, so this feels like the most promising approach. But I don't get what the complex part of $a$ is supposed to do for me, and the book did not consider solving things like $Xz = az$ yet, nor am I 100% sure its always possible to solve this equation. Are any of these a step in the right direction, and does anyone have some pointers? (edit after sleeping) So in the case where $X=\partial_1$ and $a$ takes purely imaginary values, it works out like this. You start the solution of $Xz=az$ at whatever $z_0$ say $z_0=1$ . The solution is $z(x) = z_0 \exp(\int_0^{x_1} a(s,x_2,\dots,x_n) ds)$ . My stronger assumption on $a$ means that $$\partial_1\left( \frac{|z|^2}2 \right) = \Re(\partial_1 z\overline z)= \Re ( a |z|^2) = 0$$ so that $|z|^2$ is a constant, and in particular $z\neq 0 $ everywhere. My lack of formal training in differential geometry is showing, but I suppose from try #1 above, the nonvanishing of $X$ allows me to reduce to this case? I guess I need to solve $\partial_1 = \tilde X \cdot ((\nabla \phi)^{-1}\circ \phi)$ ? And also, my hunch now is that the result is false if $a$ can take  more general complex values...","['real-analysis', 'complex-analysis', 'partial-differential-equations', 'hyperbolic-equations', 'characteristics']"
3823541,A wrong corollary of Kolmogorov's $0-1$ Law,"I either broke Probability Theory, or what is more likely, I am confused. Let $X_{n}$ be a sequence of i.i.d random variables. Then by Kolmogorov's $0-1$ Law, the probability that $S_{n}=\sum_{k=1}^n X_{k}$ converges is $\in \{0,1\}$ . Furthermore, the random variables $\lim \sup S_{n}$ and $\lim \inf S_{n}$ are measurable with respect to the terminal sigma-field generated by the $X_{n}$ and hence a.s. constant (a consequence of the 0-1 law) - is this true? Now if $S_{n}$ converges a.s. then $\lim \sup S_{n} = \lim \inf S_{n}$ a.s. Does this mean that if $S_{n}$ converges it does so to a constant? It can't...",['probability-theory']
3823612,How and what do I assume for my induction? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 years ago . Improve this question Hi I wrote a formula to know the 100th term for the following sequence: $$3, 10, 17, 24, 31$$ Note that each following number in the sequence will be 7 more than the previous number. And here is the formula: $$7N - 4$$ $$
\begin{array}{c|c}
Term   & 1 & 2  & 3  & 4  & 5  & Nth       & 100 \\ \hline
Number & 3 & 10 & 17 & 24 & 31 & 7\times N - 4 & 696 \\
\end{array}
$$ I proved it with the base case $$5 \times 7 - 4 = 31$$ which is correct.
And I proved it with $$100\times7 - 4 = 696,$$ which is correct. Also I was looking at this induction example: So that I can apply on my own induction. But the problem is I can't really apply it, because I don't know what to assume/claim to prove it. This is where I'm stuck: $$
\mathrm{Induction \enspace step;  \enspace Assume  \enspace true  \enspace for  \enspace n=k,  \enspace show \enspace true \enspace n=k+1}
$$ $$
\mathrm{Assume: 3,10,17,24,...,[WHAT \enspace DO \enspace I \enspace NEED \enspace TO \enspace WRITE \enspace HERE?] = 7N-4}
$$ Does someone has any idea what I need to write in the above assumption? Thanks in advance.","['induction', 'sequences-and-series', 'discrete-mathematics', 'real-analysis']"
3823734,Riemannian geometry before semi-Riemannian geometry?,"I am interested in getting acquainted with semi-Riemannian geometry for application in general relativity. For this, it seems O'Neill's book is considered the ""gold standard"". I am acquainted with basic smooth manifold theory on the level of Tu's Introduction to Manifolds but am concerned my preparation may be inadequate. Is it recommended that the reader have an acquaintance with Riemannian geometry, e.g. the first 8 chapters of Lee's Introduction to Riemannian Manifolds , before attempting to tackle the more general semi-Riemannian geometry? Is there a compelling reason to (or not to) study Riemannian geometry first?","['riemannian-geometry', 'semi-riemannian-geometry', 'reference-request', 'soft-question', 'differential-geometry']"
3823740,"Let $A$ be a binary $n \times n$ matrix, such that $A^2=0$. What is the max num of $1$'s that $A$ could have?","I noticed: Fixing $A_{ij}=1$ would imply $i$ -th column and $j$ -th row are all $0$ 's From there, I constructed a few matrices with small $n$ and hypothesized $f(n) = \lfloor{n/2}\rfloor \cdot \lceil{n/2}\rceil$ Interpreting $A$ as an adjacency matrix: $A^2=0$ implies you can't get from $i$ to $j$ in 2 hops. This reminds me of the max number of edges in a bipartite graph of n nodes; if you consider the edges as directed and the two sets as source/sink sets. I wonder if this relates to max flow. Searching ""nilpotent binary matrix"" got me to Nilpotent binary matrices over finite fields . I realized directed edges are not necessary in bipartite graph interpretation -- the problem could be considered as Maximum number of edges in a bipartite graph I feel there are multiple proof approaches. There is something very classic and familiar going on which I can't put my finger to, and I wonder what non-graph approaches would be especially.","['matrices', 'graph-theory', 'extremal-graph-theory', 'linear-algebra']"
3823795,sigma-algebra generated by two-sigma algebras is generated by the intersection of sets from these two sigma-algebra,"Let $\mathcal{G}$ and $\mathcal{H}$ be two $\sigma$ -algebras on a set $\Omega$ . Does it hold that $$\sigma(\mathcal{H},\mathcal{G}) = \sigma\{G\cap H: G\in\mathcal{G}, H\in \mathcal{H}\}?$$ How to prove it or disapprove it?",['measure-theory']
3823901,Technicality in proof of $\binom{m+n}{l} = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k}$,"This is from Analysis I by Herbert Amann, Joachim Escher. I want to make sure I understand everything correctly, so I'm sorry if this seems nitpicky. After introducing formal power series $R[X]$ (functions in $R^{\mathbb{N}}$ ) of a ring $R$ with unity and polynomials as a subring of $R[X]$ , there is a proof of the identity $$\binom{m+n}{l} = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k},\quad l,m,n\in\mathbb N$$ as an application of $R[X]$ being a ring.
Let $X$ denote the polynomial with $x_1=1$ and $x_i=0$ for $i\neq 1$ .
Their proof is as follows: Since $X$ and $1\in R[X]$ commute, we can use the binomial theorem for rings to compute $$(1+X)^j=\sum_{i=0}^j\binom{j}{i}X^i,\quad j\in\mathbb{N}.$$ Now we compute the two sides of $(1+X)^m(1+X)^n=(1+X)^{m+n}$ .
We have $$\begin{align}(1+X)^m(1+X)^n &= \left(\sum_{k=0}^m\binom{m}{k}X^k\right)\left(\sum_{j=0}^n\binom{n}{j}X^j\right)\\
&=\sum_l\left( \sum_{k=0}^l\binom{m}{k}\binom{n}{l-k} \right)X^l\end{align}\tag{A}$$ where the second equality is the definition of multiplication of polynomials. Also $$(1+X)^{m+n}=\sum_{l=0}^{m+n}\binom{m+n}{l}X^l.\tag{B}$$ Comparing coefficients in (A) and (B) gives the identity. My issue is that the binomial coefficients which lie in $\mathbb N$ are not technically the coefficients of the polynomial, which lie in $R$ . Given $r\in R$ and $n\in\mathbb N$ , $n\cdot r$ is the $n$ -fold sum of $r$ . So, for example, isn't the $l$ th coefficient of the polynomial in (B) really $\binom{m+n}{l}\cdot 1_R$ ?
Then the proof is really asserting that $$\binom{m+n}{l}\cdot 1_R = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k}\cdot 1_R$$ for any ring $R$ . If my understanding is correct so far, I think letting $R=\mathbb Z$ recovers the original identity since $n\cdot 1_{\mathbb Z}=n$ . It's just that the integers haven't been introduced yet.","['ring-theory', 'abstract-algebra', 'binomial-coefficients']"
3823902,A root system of vectors in R^n admits a simple system; but does every finite set of vectors,"I'm reading about root systems in the context of finite reflection groups. As I understand it, every root system (a set $\Phi$ of vectors in $R^n$ with some nice properties) admits a simple system , i.e. a subset of $\Phi$ such that the vectors in $\Phi$ are linearly independent; every vector in $\Phi$ expressed as linear sum of the simple vectors has all non-negative or all non-positive coefficients. My question is, forgetting about root systems, does every arbitary finite set of vectors in $R^n$ admit a simple system: ie some subset satisfying the two conditions above? I'm struggling to prove it, or to find a counter-example! I'm not insisting that the coefficients be integers: partly because I can see this wouldn't be true generally, and partly because the book I'm following (Humphrey's) doesn't insist on it, and if I understand correctly we get some root systems where the integer condition isn't satisfied (eg Dihedral groups). Thoughts I've had so far: If my intuition serves me right, then what we are trying to prove is that from any finite set of vectors, we can pick a linearly independent set such that all the other vectors fall into the ""double cone"" of the chosen vectors. To this end, we would want to pick nicely spread out vectors with obtuse angles so the cone is really wide. Hence, a counter example might use a set of vectors with lots of acute angles. A proof, if it exists, might follow the proof for root systems, and take a smallest subset of vectors satisfying condition 2) above. We would then have to show linear independence. We require the set of vectors to be finite, as some infinite sets of vectors won't have simple systems (eg, all of them in $R^n$ ). Thank you for reading my question. Any thoughts appreciated!","['group-theory', 'root-systems', 'vector-spaces']"
3823954,Equivalence relation on a group and normal subgroups,"Let $G$ be a group and define an equivalence relation $R$ on it. Let $G/R$ be the set of equivalence classes of this relation. Then is $G/R$ equal to $G/N$ for some normal subgroup $N$ of $G$ ? Sorry, not even sure if the question makes sense. I am trying to basically ask if there is a connection between any equivalence relation defined on a group and normal subgroups of $G$ ? Or rather, does an equivalence relationship give rise to a normal subgroup? Thank you.","['equivalence-relations', 'logic', 'abstract-algebra', 'normal-subgroups', 'group-theory']"
3823970,Find angle a path makes with the horizontal given magnitude and angle made with other paths.,"Given this information: ""The elevation along a straight path up the side of a hill increases at a rate of 1/3 meter per horizontal meter. At point P, a new path at an angle of 𝜋/6 with the original path goes off more steeply uphill. The steepest uphill direction at P makes an angle of 𝜋/3 with the original path."" ""What angle does the new path make with the horizontal?"" It seems to be a standard directional derivative and gradient question, but I can't seem to get any definitive answer, because no direction of the original path or the new path/steepest path is given. For example, it seems valid to say the original path is along x-axis, in which case the horizontal angle would be 𝜋/6 , or I could have the original path be have an angle 5𝜋/6 with the x-axis, in which case it seems my new path would have a horizontal angle of 𝜋/2. I'm either misunderstanding the question and visualizing it wrong, or I need more information. Anyone have an idea about this?","['partial-derivative', 'multivariable-calculus', 'vectors']"
3824001,Probability measures only equivalent on a subset of the sample space,"Question: Suppose $X = \{1,2,3,4\}$ and consider $$2^X = \{\emptyset, X, \{1\}, \{2\}, \{3\}, \{4\}, \{1,2\}, \{1,3\}, \{1,4\}, \{2,3\}, \{2,4\}, \{3,4\}, \{1,2,3\}, \{1,2,4\}, \{1,3,4\}, \{2,3,4\}\}.$$ Let $B \subset 2^X$ such that $\sigma(B) = 2^X$ . Is it possible to construct two probability measures $m_1, m_2$ over $X$ such that $m_1 \neq m_2$ on $2^X$ , but $m_1 = m_2$ on some $B$ ? My idea: I figure the smallest $B$ under such constraints would be a good start. So, $B = \{\emptyset, \{1\},\{2\}, \{3\}\}$ , and $\sigma(B) = 2^X$ , Then $m_1(A) = m_2(A), \forall A \in B$ .  Also, our measures must satisfy: $m_i(\emptyset) = 0$ , $m_i(X) = 1$ For any disjoint combination $A_1, A_2, \dots \in 2^X$ we have $$m_i\left(\bigcup A_j\right) = \sum m_i(A_j), ~~~ \bigcup A_j \in 2^X,$$ $~~~~~~~$ for each $i \in \{1,2\}$ . I tried to play around with the left out singleton $\{4\}$ . So, something like, $m_1(A) = \frac{\#(A\setminus \{4\})}{\#(X \setminus \{4\})}$ , and letting $m_2(\{n\}) = \frac{1}{3}$ for $n \in \{1,2,3\}$ . But I haven't found an $m_2$ in this way that satisfies the disjointness property above. Perhaps I should choose a different $B$ ?","['measure-theory', 'probability-theory']"
3824086,Intuition behind numerical solutions to ODE,"Something that has always bothered me about numerical solutions to ODE is that it isn't clear to me how well the discretization scheme can be assumed to really approximate a local derivative. The most basic Euler discretization gives: $$ x_{n+1} \approx h*f(t_n,x_n)+x_n,$$ $$ t_{n+1} = t_n + h$$ In the even simpler autonomous case you get: $$ x_{n+1} \approx h*f(x_n)+x_n,$$ But it's not clear to me how well the first approximation actually holds, in particular it seems there needs to be some global bound on $f$ in order to claim any type of error bound. This is because the ODE could possibly wildly oscillate or explode. Could someone explain to my the intuition behind why these schemes work for most problems that are seen in applied mathematics?","['numerical-methods', 'ordinary-differential-equations', 'dynamical-systems']"
3824124,Using Qualifiers to Describe Multiples,"I was recently solving some questions about quantifiers when I came across an example I didn't quite understand. The universe of discourse is the set of natural numbers $\{1,2,3,\dots\}$ (i.e. all variables represent natural numbers). The statement being converted to logic format was ""Every multiple of $4$ is a multiple of $2$ "", which was then represented with the following symbolization: $$∀n((∀m\space n≠4m) ∨ (∃r\space n = 2r)).$$ When I read the symbolization, I translate it as follows: ""For all numbers $n$ , $n$ is either not a multiple of $4$ * all values of $m$ , or there exists an $r$ such that $n$ is a multiple of $2r$ "". Is this an accurate translation and if not, what's a better way to word it? Also, is the symbolization truly the best way to represent the concept of ""Every multiple of 4 is a multiple of 2""?","['quantifiers', 'logic', 'discrete-mathematics', 'logic-translation']"
3824246,Find the range of $f(x)=\cos(\sin x)+\sin(\cos x)$,"Find the range of $$f(x)=\cos(\sin x)+\sin(\cos x)$$ My try:
Evident that $f$ is $2\pi$ periodic. Let us assume $\cos x=t$ $\implies$ $t \in [-1,1]$ So the equivalent function of $f(x)$ is now: $$g(t)=\sin t+\cos\left(\sqrt{1-t^2}\right)$$ Case $1.$ Let $t \in [0,1]$ Now $$g'(t)=\cos t+t \times\frac{\sin\left(\sqrt{1-t^2}\right)}{\sqrt{1-t^2}}$$ $\implies$ $g'(t) >0$ So $g$ is increasing from $\cos 1$ to $1+\sin 1$ in $t \in [0,1]$ Case $2.$ When $t \in [-1,0]$ I came to know from the graph of $g(t)$ that it is decreasing. But how to prove it is decreasing formally i could't do it.","['algebra-precalculus', 'functions', 'trigonometry']"
3824358,How to prove $P\left(\cup_{i=1}^{\infty}A_i\right)=1$ implies that $P(\{A_i\ i.o.\})=1$,"Suppose that $\{A_i\}$ is a sequence of independent events with $P\left(\bigcup_{i=1}^\infty A_i\right) = 1$ and $P(A_i)<1$ for all $i\in \mathbb{N}$ . Show that $$
P(A_i \text{ occurs infinitely often})=1 
$$ My attempt:
We only need to show $P\left(\cap_{i=1}^{\infty} A_i^c \right)=0 \Longrightarrow P(A_i\ i.o.)=1$ . Note that $$
\begin{aligned}
P\left(\cap_{i=1}^{\infty} A_i^c \right)&= \prod_{i=1}^{\infty}P(A_i^c)&&\text{(independence)}\\
&= \prod_{i=1}^{\infty}(1-P(A_i))
\end{aligned}
$$ For any $k$ , we have \begin{aligned}
P\left(\cap_{i=1}^{k} A_i^c \right)&= \prod_{i=1}^{k}P(A_i^c)\\
&= \prod_{i=1}^{k}(1-P(A_i))\\
&\leq \prod_{i=1}^k e^{-P(A_i)}\quad(1-x\leq e^{-x}) \\
&=e^{-\sum_{i=1}^kP(A_i)}
\end{aligned} Let $k \to \infty$ , then $0=P\left(\cap_{i=1}^{\infty} A_i^c \right)\leq e^{-\sum_{i=1}^{\infty}P(A_i)}$ . If we can show $e^{-\sum_{i=1}^{\infty}P(A_i)}=0$ , which implies that $\sum_{i=1}^{\infty}P(A_i)=\infty$ , then the result follows by the second Borel-Cantelli Lemma.
My question is how to show $e^{-\sum_{i=1}^{\infty}P(A_i)}=0$ . If we cannot, is there any other way to prove this result? I would appreciate if you could explain in details.","['probability-theory', 'probability']"
3824361,Two equivalent series converge on different limits,"Consider the series: $$
\sum_{n=0}^{\infty} \left({\dfrac{(-1)^n}{2n+1}}\right)^3  = \dfrac{1}{1^3}-\dfrac{1}{3^3}+\dfrac{1}{5^3}-\dfrac{1}{7^3} \dots = \dfrac{\pi^3}{32}
$$ Now suppose I wish to represent this series with the following equivalent summation: $$
\sum_{n=1}^{\infty} \left[\left({\dfrac{1}{4n-3}}\right)^3-\left({\dfrac{1}{4n-1}}\right)^3 \right]=  \left[\dfrac{1}{1^3}-\dfrac{1}{3^3}\right]+\left[\dfrac{1}{5^3}-\dfrac{1}{7^3}\right] \dots 
$$ I know that changing order of summation in infinite series might affect the limit, but in this example the order of summation is not really changed, and all of the terms are exactly the same.One can even prove by induction that both series term by term are equivalent - i.e that the second is a compressed version of the first. So can I state that the limit of the second series is equal to $\dfrac{\pi^3}{32}$ ? If not, I would be happy to find some explanation as to why we even pretend to assign values to infinite series if we can see that certain examples of infinite series break basic axioms of arithmetic.","['sequences-and-series', 'real-analysis']"
3824396,Prove that $\int_0^{2\pi} \lvert \sum_{n=0}^{\infty} A_n (re^{i\theta})^n \rvert^2=2\pi \sum_{n=0}^{\infty} \lvert A_n\rvert ^2 r^{2n}$,"Suppose $f:B_1(0)\to \mathbb{C}$ is a holomorphic function, which is given by its Taylor series $$f(w)=\sum_{n=0}^{\infty} A_n w^n,\,\,A_n\in \mathbb{C}.$$ I want to show that $$\int_0^{2\pi}\lvert f(re^{i\theta})\rvert^2\,d\theta=2\pi\sum_{n=0}^{\infty} \lvert A_n\rvert^2 r^{2n},\,\,r\in (0,1).$$ $\textbf{Proof}$ : Because of $$\lvert f(re^{i\theta})\rvert^2=\left\lvert\sum_{n=0}^{\infty} A_n r^n e^{i\theta n}\right\rvert^2=\left(\sum_{n=0}^{\infty} A_n r^n e^{i\theta n}\right)\overline{\left(\sum_{n=0}^{\infty} A_n r^n e^{i\theta n}\right)} \\ =\left(\sum_{n=0}^{\infty} A_n r^n e^{i\theta n}\right)\left( \sum_{n=0}^{\infty} \overline{A_n} r^n e^{-i\theta n}\right),$$ it follows from the Cauchy product formula that $$\lvert f(re^{i\theta})\rvert^2=\sum_{n=0}^{\infty} \sum_{k=0}^{n} A_k r^k e^{i\theta k} \overline{A_{n-k}}r^{n-k} e^{-i\theta(n-k)}=\sum_{n=0}^{\infty} r^n\sum_{k=0}^{n} A_k \overline{A_{n-k}} e^{i\theta(2k-n)}.$$ Since both of the series converge uniformly on the compact set $\{(r,t):t\in [0,2\pi]\}$ and are bounded, their product also converges uniformly and we can interchange the integral and the sum. But the integral from $0$ to $2\pi$ of $e^{i\theta(2k-n)}$ is not equal to zero iff $2k-n=0$ or $2k=n$ . But $k$ is a whole number, so for uneven $n$ , this equation can't be fulfilled. This means that we can just sum over all even natural numbers: $$\sum_{n=0}^{\infty} r^{2n} \sum_{k=0}^{2n} A_k \overline{A_{2n-k}}e^{i2\theta(k-n)}.$$ Again, the integral won't vanish iff $n=k$ , which finally yields $$\int_{0}^{2\pi} \sum_{n=0}^{\infty} r^{2n}\sum_{k=0}^{2n}A_k \overline{A_{2n-k}}e^{i2\theta(k-n)}\,d\theta=\sum_{n=0}^{\infty} r^{2n}\int_{0}^{2\pi} A_n \overline{A_{2n-n}} e^{i2\theta(n-n)}\,d\theta \\ =\sum_{n=0}^{\infty} r^{2n}\int_0^{2\pi} A_n \overline{A_n}\,d\theta=2\pi \sum_{n=0}^{\infty} \lvert{A_n}\rvert^2 r^{2n}.$$","['complex-analysis', 'solution-verification', 'alternative-proof']"
3824397,"How many functions $f(x)$, $f:N→N$ exist such that $LCM(f(n),n)-HCF(f(n),n)<5$?","How many functions $f(x)$ , $f:N→N$ exist such that $LCM(f(n),n)-HCF(f(n),n)<5$ ? After understanding the helpful comment by @player3236, I have realised that the reasoning I used to try and solve this question was wrong. However I have still added it below for reference. Any method or hints on how to solve this question? My flawed reasoning : I thought that since the domain and region of the functions are both $N$ , the possible operations must include addition, multiplication and exponential functions (where power is a positive integer).
Let us assume the function is $f(x)=x+c$ where $c$ is a natural number. In that case, there will always be some cases where the LCM is much greater than the HCF and the inequality will not be satisfied.Same goes for multiplication. Let us assume the function is some $f(x)=cx$ where $c$ is a natural number. The $LCM$ of $f(n),n$ will be $f(n)$ and $HCF$ will be $n$ . In cases where $cn-n>5$ , this inequality wont hold.I used similar reasoning for exponential functions.
Thus the only case where this works out is $f(x)=x$ , in which case $LCM(f(n),n)=HCF(f(n),n)=n$ and thus the inequality will hold.
So only one function is possible. Thanks in advance! Regards","['gcd-and-lcm', 'functions']"
3824429,Writing logic statements using quantifier,"I was given two predicates $\text{Prime}(x)$ and $\text{Even}(x)$ and is required to write the following statements: For every odd natural number there is a different natural number such that their sum is even. My attempt: $(\forall x):(x \in \mathbb{N} \wedge \neg \text{Even}(x) \to (\exists y):(x \neq y \wedge \text{Even}(x+y))).$ and The sum of any two prime numbers except the prime number $2$ is even. My attempt: $(\forall x,y):(x \neq 2 \wedge y\neq 2 \wedge \text{Prime}(x,y) \to \text{Even}(x+y)).$ Is my attempt correct? And Am I allowed to write $\text{Prime}(x,y)$ or should I write $(\text{Prime}(x) \wedge \text{Prime}(y))?$","['quantifiers', 'logic', 'discrete-mathematics', 'logic-translation']"
3824471,Let $\varphi : G \rightarrow G/N$. Prove/Dis-prove that there exists a right inverse of $\varphi$ that is *homomorphic*.,"Statement: Let $G$ be a finite group, $N$ be a normal subgroup of $G$ and let $\varphi: G \rightarrow G/N$ be the cannonical map. Prove/Dis-prove that there exists a right inverse of $\varphi$ that is homomorphic. Testing the statement with $C_n$ and $D_n$ , we see that there is a right inverse which is an homomorphism, for every quotient map. How does one think about the statement for a general group. Any hints/ideas are highly appreciated.","['group-homomorphism', 'quotient-group', 'group-theory', 'normal-subgroups']"
