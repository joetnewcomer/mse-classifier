question_id,title,body,tags
3152189,Does this recursive function have a function in terms of n?,"I am trying to convert the following recursive function to a non-recursive equation: $$f(2) = 2$$ For $n>2$ : $$f(n)=nf(n-1)+n$$ I have calculated the results for n=2 through to n=9: $$\begin{align}
f(2)&=2\\
f(3)&=9\\
f(4)&=40\\
f(5)&=205\\
f(6)&=1236\\
f(7)&=8659\\
f(8)&=69280\\
f(9)&=623529
\end{align}$$ I've tried graphing the function, but have got nowhere Any help is appreciated!","['recursive-algorithms', 'functions', 'recurrence-relations']"
3152216,$\Delta u=3u$ then $u\equiv0$,"I have the following question in which it is easy to use Fourier transform to get the answer if the function is nice enough, for example $u\in C_{0}^{\infty}(\mathbb{R}^{n})$ , however here $u$ is only in $L^{1}$ . How can I get through this? The question: Let $u\in L^{1}\left(\mathbb{R}^{n}\right)$ so that $\Delta u=3u$ in the distribution sense. Prove that $u\equiv0$ . Thanks.","['regularity-theory-of-pdes', 'distribution-theory', 'functional-analysis', 'real-analysis']"
3152217,Lower Bound on the Sum of Reciprocal of LCM,"While reading online, I encountered this post which the author claims that \begin{align}
S(N, 1):=\sum_{1\le i, j \le N} \frac{1}{\text{lcm}(i, j)} \geq 3H_N-2
\end{align} and $S(N, 1) \geq H_N^2$ where $H_N$ is the partial harmonic sum . The prove of the latter inequality is already given in the post. For the former, we see that \begin{align}
S(N, 1) 
=&\ 2\sum^N_{j=2}\sum^{j-1}_{i=1}\frac{1}{\text{lcm}(i, j)} +H_N\\
\geq&\ 2\sum^N_{j=2} \frac{1}{\text{lcm}(1, j)}+H_N=\ 3H_N -2.
\end{align} My question is whether there exists $C$ , independent of $N$ , such that the following bound holds \begin{align}
s(N):=\sum_{N \leq i, j \leq 2N} \frac{1}{\text{lcm}(i, j)} \geq C \log N.
\end{align} Actually, I know for a fact that this is true by $(1.7)$ in this paper but couldn't prove it. Another question: How does one show \begin{align}
\sum_{N^2/4< k< N^2/3} (\#\left\{N/3<q<N/2 \big|\   q\mid k\right\})^2\sim  \sum_{N/3<q, q'<N/2} \frac{N^2}{\text{lcm}(q,q')}.
\end{align} I started by \begin{align}
\sum_{N^2/4< k< N^2/3} (\#\left\{N/3<q<N/2 \big|\   q\mid k\right\})^2 =&\ \sum_{N^2/4< k< N^2/3}\left( \sum_{\substack{N/3<q<N/2\\ q\mid k}}1  \right)^2\\
=&\ \sum_{N^2/4< k< N^2/3} \sum_{\substack{N/3<q,\ q'<N/2\\ q\mid k,\ q'\mid k}} 1.
\end{align} Here I know I should interchange the order of summation, but I don't know how to get the lcm to show up. Any help/suggestion is highly welcome.","['analytic-number-theory', 'least-common-multiple', 'sequences-and-series']"
3152240,How to prove that $\mathbb{Z}[X]/g\mathbb{Z}[X]$ is not a field? [duplicate],"This question already has answers here : Nonconstant polynomials do not generate maximal ideals in $\mathbb Z[x]$ (4 answers) Closed 5 years ago . How to prove that $\mathbb{Z}[X]/g\mathbb{Z}[X]$ is not a field, where $g$ is a non constant polynomial in $\mathbb{Z}[X]$ ? (The key is to show that $f : \mathbb{Z}[X]/g\mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z}$ is not injective.) edit 1:
Now I'm trying to find the characteristic of the given ring.
Consider the map: $g: \mathbb{Z} \to \mathbb{Z}[X]/g\mathbb{Z}[X]$ , where $m \mapsto 1 + 1 + \cdots + 1 $ (m times). Since the $\ker f$ is an ideal of $\mathbb{Z}$ , it has to be of the form $n\mathbb{Z}$ , where $n$ is the characteristic. So I guess the characteristic is $0$ ...no? edit 2: Thank you for all the replies below! I looked through the answer but it's a little advanced for me... I figured it out eventually using some more basic ideas and I'll put it here when I get some time...Thanks again! edit 3: My solution: Step 1: Prove there is a $a \in \mathbb{Z}$ such that $g(a) \neq 0, \pm 1$ and let $p$ be a prime number that divides $g(a)$ . Suppose $g(X) = \sum_{i = 1}^na_iX^i$ , then $g(X) = 0$ has at most $n$ integer solutions, $p(X) = g(X) -1 = 0$ has at most $n$ integer solutions, and so is $q(X) = g(X)+1 = 0$ . There are at most $3n$ integers that satisfy $g(a) = 0,\pm1$ , but $\mathbb{Z}$ is infinite, so there has to be a $a \in \mathbb{Z}$ such that $g(a) \neq 0, \pm 1$ . Step 2: Prove that there is a unique well-defined surjective morphism of rings $f: \mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z}$ sending $X$ to $a$ mod $p$ and that it yields a homomorphism of rings $\phi: \mathbb{Z}[X]/g\mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z}$ . Observe that $g\mathbb{Z}[X]$ is in the kernel, so the map factor through $\mathbb{Z}[X]/g\mathbb{Z}[X]$ . Step 3: Show that the resulting map is not injective. Note that the map $\phi$ is injective if and only if $\ker f = g\mathbb{Z}[X]$ , but actually $g\mathbb{Z}[X] \subset \ker f$ . Alternatively, according to my prof, if the map was injective, $\mathbb{Z}[X]/g\mathbb{Z}[X]$ would identify with a subring of $\mathbb{Z}/p\mathbb{Z}$ so it would have characteristic $p$ , contradiction! Step 4: We use that if $g: K \to A$ where $K$ is a field, then $g$ is either injective or the zero map.
Since the above map is not a zero map and we proved that it's not injective, $\mathbb{Z}[X]/g\mathbb{Z}[X]$ can't be a field.","['abstract-algebra', 'maximal-and-prime-ideals']"
3152251,Derive the general solution of the ODE $x^3y'''-3x^2y''+6xy'-6y=x^4$,"a) Obtain the general solution for $y=y(x)$ to $x^3y'''-3x^2y''+6xy'-6y=0, x>0$ b) Derive the general solution of $x^3y'''-3x^2y''+6xy'-6y=x^4, x>0$ I can do part a) by looking for a solution in the form $y=x^r$ and differentiating, obtaining the general solution $y(x)=c_1x+c_2x^2+c_3x^3$ . How would I proceed to answer part b)?","['calculus', 'ordinary-differential-equations']"
3152268,Leibniz rule for expression containing derivative.,"I have found the following algebraic manipulation in a solution to a homework problem, and I don't understand it. The claim is (assume continuous, differentiable $f$ ): $$ \frac{x^2}{2} f^\prime(x) = \int_0^x f^\prime(x)(x-t)\,dt $$ I find this confusing, because it seems to me that I can write $$\int_0^x t f^\prime(x)\,dt = \left[\frac{t^2}{2} f^\prime(x)\right]_0^x = \frac{x^2}{2} f^\prime(x),$$ since $f^\prime(x)$ does not depend on $t$ , which does not agree with the expression above (where does the $-x$ part come from)? What am I missing?","['integration', 'derivatives']"
3152271,Find the number of solutions in integers to the following problems,"I don't quite understand the answer to this problem, and would like help explaining it, if my understanding isn't correct. $$x_1 +x_2 +x_3 +x_4 < 40, x_1 > 0, x_2 > 0, x_3 \geq 0, x_4 > 5$$ I checked in the back of the book and it shows that it's $C(4+32-1,32)$ then says (the number of solutions to $x_1' +x_2' +x_3 +x_4' = 32$ , where $x_1' = x_1 - 1$ , $x_2'= x_2 - 1$ , and $x_4'= x_4 - 6$ ) This is what I think is going on, please correct my logic if I'm wrong. $x_4' = x_4 - 6$ comes from the fact that $x_4 > 5$ . Then, $x_1' = x_1 - 1$ and $x_2' = x_2 - 1$ is because both $x_1$ and $x_2$ are $> 0$ . And since $x_3 \geq 0$ , I don't have to worry about it since it can possibly be $0$ . Then it becomes $$x_1 +x_2 +x_3 +x_4 +x_1 < 40-1-1-6 = 32$$","['combinations', 'discrete-mathematics']"
3152277,"G is a group and $(ab)^3=a^3b^3$ for all $a,b \in G$. Prove (or disprove with a counterexample) that if $(ab)^3=(ba)^3$, then $ab=ba$.","Proposition. Let $G$ be a group such that $(ab)^3=a^3b^3$ for all $a,b \in G$ . If $(ab)^3=(ba)^3$ , then $ab=ba$ . Is it true or false? So far I've only been able to prove that powers of $a$ commute with $b^3$ and powers of $b$ with $a^3$ .","['group-theory', 'abstract-algebra', 'abelian-groups']"
3152434,"Why does $\int_0^R 2 \pi r \,\mathrm d r$ give the area of a circle?","There's a method of computing the area of a circle by dividing it in concentric rings with infinitesimal width. Let $R$ be the radius of the circle and $r$ be the radius of the rings. The area of the circle is $$\int_0^R 2 \pi r \,\mathrm d r$$ My questions are: I do not understand, though, how to justify the $2 \pi r \,\mathrm d r$ approximation for the area of each ring. Its actual area would be $$\pi (r + \mathrm d r)^2 - \pi r^2 = 2 \pi r \,\mathrm d r + \pi \left( \mathrm d r \right)^2$$ right? Could I use this more precise formula if I wanted to? How? The area on the integral above looks more like the lateral area of a cylinder of height $\mathrm d r$ , which is different from the actual area between two concentric circles. So why does that work? Would the lateral area of a truncated cone (which seems to be the intermediate between the ring area and the cylinder lateral area) also work as an approximation? Also, how do you come up with such an idea for an approximation that makes the calculation so beautifully simple (i.e. adopting the lateral area of a cylinder as the area of the rings)? It is considered a trivial integral, but there is a huge and mostly ignored step to be taken there.","['integration', 'area', 'definite-integrals', 'calculus', 'polar-coordinates']"
3152441,"If $F(x) = f(x)g(x)$, what is th nth derivative of F, that is $F^{n}(x)$, if $f$ and $g$ have derivatives of all orders?","This problem seems really problematic, checking the pattern from the first $5$ derivatives of F, I proceeded to form a general formula, but failed. I did this - $f^{n}(x)g(x) + nf^{n-1}(x)g'(x) + \frac{n(n-1)}{2}f^{n-2}(x)g''(x) + \frac{2 + 3(n-2)(n-3)}{2}f^{n-3}(x)g'''(x) + ...... + g^n(x)$ First $5$ derivatives of F are given here Can someone please help me find the correct answer to this question?","['calculus', 'functions', 'derivatives']"
3152464,Solving a PDE ( wave equation ),"$$u_{tt}- \Delta u= e^{t}, 0<x<2\pi, 0<y<1, t>0$$ $$u_x(0,y,t)=u_x(2\pi,y,t)=0, 0<x<2\pi, t>0$$ $$u_y(x,0,t)=u_y(x,1,t)=0, 0<x<2\pi, t>0$$ $$u(x,y,0)=0, 0<x<2\pi, 0<y<1$$ $$u_t(x,y,0)= 1+\cos(x), 0<x<2\pi, 0<y<1$$ Can anyone please help me? I am learning PDE and I have no idea how to solve this problem. Thanks.","['multivariable-calculus', 'wave-equation', 'partial-differential-equations']"
3152474,"Can we allow $f$ to be undefined at finitely many points in $(a,b)$ when formulating $\int_a^b f(x)\ dx=F(b)-F(a)$, ($F$ is the antiderivative of $f$)","Let $f$ be a real-valued function on a closed interval $[a,b]$ undefined only at finite points in $(a,b)$ . Let $F$ be antiderivative of $f$ . Then: $$\int_a^b f(x)\ dx=F(b)-F(a)$$ Is the theorem true? How shall we prove it? I ask this because I have read that function undefined at finite points in the interval $(a,b)$ doesn't effect integration i.e. we can take the antiderivatives and apply the limits as usual to get the definite integral.","['integration', 'definite-integrals', 'calculus', 'functions', 'limits']"
3152506,Intuitive explanation of $y' = y \implies y = Ce^x$,"I understand why $f : \mathbb{R} \to \mathbb{R}$ with $f'(x) = f(x)$ and $f(0) = 1$ must be $f (x) = e^x$ , but I don't really feel it is super intuitive. Intuitively, why would you expect such a function to satisfy $$f(a)f(b) = f(a+b)$$ or have exponential growth? To build intuition, I tried the discrete case first, i.e., $$\frac{f(x+h) - f(x)}{h} = f(x) \implies f(x+h) = f(x)(h+1)$$ so $$f(y) = f(0) (1+h)^{\frac{y}{h}} = f(0) c_h^{y}$$ where $c_h = (1+h)^{\frac{1}{h}}$ and saw what happens when $h \to 0$ . However, I'm interested in a more intuitive explanation, if there's one. Bonus if it also explains $y' = P'y \Rightarrow y = Ce^P$ in a nice intuitive way.","['ordinary-differential-equations', 'real-analysis', 'calculus', 'intuition', 'exponential-function']"
3152511,"Let $(G,\odot)$ be a finite group with identity element $e$. Show that for each $g \in G$, there is $k \in \Bbb N^+$ such that $g^k= e$","This is Exercise $7.$ from Section 7: Groups and Homomorphisms , Chapter 1 : Foundation , textbook Analysis I by Herbert Amann and Joachim Escher . Exercise $7$ : Let $(G,\odot)$ be a finite group with identity element $e$ . Show that for each $g \in G$ , there is $k \in \Bbb N^+$ such that $g^k := \underbrace{g \odot \cdots \odot g}_{k \text{ times}} = e$ . My attempt: Assume the contrary that $g^k \neq e$ for all $k > 0$ . Then $g^n \neq g^{n+p}$ for all $p>0$ . If not, $g^n = g^{n+p}$ for some $p>0$ and thus $(g^{-1})^n \odot g^n = (g^{-1})^n \odot g^{n+p}$ . It follows that $e = g^p$ , which is a contradiction. So the set $\{g^k \mid k \in \Bbb N\}$ is infinite. This contradicts the fact that $G$ is finite. At the end of this exercise, the authors give a hint Use Exercise $1.$ where Exercise $1$ : Let $N$ be a subgroup of a finite group $(G,\odot)$ . Show that $|G| = |N| \cdot |G/N|$ where $G/N$ is the set of left cosets of $G$ modulo $N$ . My questions: Does my attempt look fine or contain gaps/flaws? How to utilize Exercise $1$ to do Exercise $7$ as suggested by the authors? Thank you for your help!","['group-theory', 'proof-verification', 'finite-groups']"
3152512,Does convergence of polynomials imply that of its coefficients?,"Let $\{p_{n}\}$ be a sequence of polynomials and $f$ a continuous function
on $[0,1]$ such that $\int\limits_{0}^{1}|p_{n}(x)-f(x)|dx\to 0$ .
Let $c_{n,k}$ be the coefficient of $x^{k}$ in $p_{n}(x)$ . Can we conclude
that $\underset{n\rightarrow \infty }{\lim }c_{n,k}$ exists for each $k$ ?. What I know so far: if the degrees of $p_{n}^{\prime }s$ are bounded then
this is true. In fact, we can replace $L^{1}$ convergence by convergence in
any norm on $C[0,1]$ ; to see this we just have to note that for fixed $N$ , $%
\sum_{k=0}^{N}c_{i}x^{i}\rightarrow (c_{0},c_{1},...,c_{N})$ is a
linear map on a finite-dimensional subspace and hence it is continuous. My
guess is that the result fails when there is no restriction on the degrees.
But if $p_{n}(z)$ converges uniformly in some disk around $0$ in the complex
plane then the conclusion holds. To construct a counterexample we have to
avoid this situation. Maybe there is a very simple example but I haven't been
to find one. Thank you for investing your time on this.","['convergence-divergence', 'polynomials', 'functional-analysis']"
3152515,Proof $X_n\xrightarrow{D}X$ and $Y_n \xrightarrow{P}0$ then $X_n + Y_n \xrightarrow{D}X$,"I am having trouble proving this theorem. I know that I am given $$\lim_{n \rightarrow \infty }Pr[X_n<x] = Pr[X<x]$$ and $$\lim_{n \rightarrow \infty }Pr[|Y_n| > \epsilon] = 0, \quad\forall\epsilon>0$$ where I have to show that $$\lim_{n \rightarrow \infty }Pr[X_n+Y_n<t]=Pr[X<t] \qquad(1)$$ Editted: I know that I have to use the squeeze theorem, but I am not too strong in limit problems... I cannot use Slutsky's Theorem because I am actually trying to prove it.",['statistics']
3152529,Combinatorial argument for solution of recursion behaving similarly as Pascals triangle?,"Given the following recursion: $$ F(n,d) = F(n-1,d) + F(n-1,d-1) + 1 $$ With initial conditions $F(0,d)=1,F(n,1)=1$ and $n\in\mathbb N_0, d\in\mathbb N$ . I noticed that it holds (By writing out the table for $n,d$ and doing some tweaking): $$ F(n,d)=2\sum_{k=1}^{d-1}\binom{n}{k}+1$$ Can this solution be justified (proven) by a combinatorial argument? I want to avoid proving it by solving the above recursion in two vairables. The recursion seems similar to the one for diagonals in Pascals triangle .","['combinatorics', 'combinatorial-proofs', 'recurrence-relations']"
3152541,Two PDE for one unknown?,"Let $x \in (0,L)$ , $t \in (0,T)$ , and let $f_1 = f_1(x,t) \in \mathbb{R}$ , $f_2 = f_2(x,t) \in \mathbb{R}$ , $u^0 = u^0(x) \in \mathbb{R}$ and $g= g(t) \in \mathbb{R}$ be continuous functions. My question is: Can we find a function $u = u(x,t) \in \mathbb{R}$ that satisfies \begin{equation} 
\partial_t u(x,t) = u(x,t) f_1(x,t) \qquad \text{in } (0,L)\times(0,T)
\end{equation} and \begin{equation} 
\partial_x u(x,t) = u(x,t) f_2(x,t) \qquad \text{in } (0,L)\times(0,T)
\end{equation} with additional initial and boundary conditions: \begin{align*}
u(x,0) &= u^0(x) \qquad \text{for }x \in (0,L)\\
u(0,t) &= g(t) \qquad \text{for }t \in (0,T).
\end{align*} (Here $\partial_t$ and $\partial_x$ denote the partial derivative with respect to time and space respectively.) I had though about choosing $u$ as the solution of the transport equation \begin{align*}
\begin{cases}
\partial_t u + \partial_x u = (f_1+f_2)u & \text{in }(0,L)\times (0,T)\\
u(x,0) = u^0(x) & \text{for }x \in (0,L)\\
u(0,t) = g(t) & \text{for }t \in (0,T).
\end{cases}
\end{align*} However, I do not know if some supplementary assumption may allow to have $u$ satisfying both equations $\partial_t u = u f_1$ and $\partial_x u = u f_2$ separately. Any suggestion, reference (e.g. where a function has to satisfy two separate equations as for here), explanation of why it is/is not possible, would be welcome. Thank you.","['linear-pde', 'functional-analysis', 'partial-differential-equations']"
3152544,Integrating $1/z$ over unit circle,"I am having trouble with this (This is copied from Howie Complex Analysis): Theorem: Let $\gamma(t)=e^{it}\,(0\leq t\leq 2\pi)$ . Then $\int_{\gamma} z^ndz=2\pi i$ if $n=-1$ . Proof : $$\int_{\gamma}z^n\,dz=\int_0^{2\pi}r^ne^{nit}ie^{it}dt=i\int_0^{2\pi}r^ne^{(n+1)it}dt.$$ If $n=-1$ this becomes $i\int_0^{2\pi}dt=2\pi i$ . I wonder why not $i\int_0^{2\pi}r^{-1}dt=2\pi i/r$ in last line.","['integration', 'complex-analysis']"
3152580,Best constants for Gagliardo–Nirenberg inequality in the case: p=q=2,"Given a function $u$ with compact support and a bounded area $\Omega\subset\mathbb{R}^n$ with $n \geq 3$ . We have the well know Gagliardo–Nirenberg inequality $$
\|u\|_{L^2} \leq C \|Du\|_{L^2}.
$$ What is the best (known) constant $C\in\mathbb{R}$ , such that this inequality holds?","['partial-differential-equations', 'functional-analysis', 'real-analysis']"
3152627,"Why is that $\int_a^b \frac{\partial f}{\partial x}(x,t)dt = \frac{\partial}{\partial x}\int_a^b f(x,t)dt$","This question is concerned with the integral with parameter, so let's assume that every function below is smooth. To find the formula for the derivative of an integral with parameter, say $$g(x) = \int_{a(x)}^{b(x)}f(x,t)dt$$ for some function $f: \mathbb{R}^2 \to \mathbb{R}$ , one would define $$ F: \mathbb{R}^3 \to \mathbb{R}, F(a,b,x) = \int_a^b f(x,t)dt $$ and then use the multivariable chain-rule to determine $g'$ . Thus, we would have that $$g'(x) = \frac{\partial F}{\partial a} \cdot \frac{\partial a}{\partial x} + \frac{\partial F}{\partial b} \cdot \frac{\partial b}{\partial x} + \frac{\partial F}{\partial x}.$$ It is easy so see that $$\frac{\partial F}{\partial a} \cdot \frac{\partial a}{\partial x} = -f(x,a(x)) \cdot a'(x)$$ and that $$\frac{\partial F}{\partial b} \cdot \frac{\partial b}{\partial x} = f(x,b(x)) \cdot b'(x). $$ What I don't understand is why we have that $$\frac{\partial F}{\partial x} = \int_a^b \frac{\partial f}{\partial x}(x,t)dt. $$ Shouldn't it be $$\frac{\partial F}{\partial x} = \frac{\partial}{\partial x}\int_a^b f(x,t)dt ? $$ Could you please tell me why we are allowed to interchange the partial derivative and the integral?","['integration', 'derivatives', 'chain-rule', 'real-analysis']"
3152645,Algebra operations as natural transformations,"Apologies in advance if the following makes little to no sense, but here goes .. Denote $m_G : G\times G\to G$ the multiplication of a group $G$ . Does it make sense to think of the map $m_G$ as some kind of morphism in a (at the moment unspecified) category? Even more, could we think of the family $m_G$ (indexed by the class of groups) as a natural transformation of some or other functors? Let's call our mystery categories $\mathcal A$ and $\mathcal B$ with mystery functors $X,Y :\mathcal A\to\mathcal B$ such that the natural transformation condition holds: $$ m_HX(f) = Y(f)m_G $$ where $f$ is a morphism in $\mathcal A$ and $G,H$ are groups. For this to make sense, we need a category with objects $G\times G$ and $G$ . So, we extend (?) the category of groups by $\mathcal B_0 := \mbox{Grp}_0 \cup \{G\times G \mid G\in\mbox{Grp}_0\}$ . Morphisms in 'separate components' remain as they are in $\mbox{Grp}$ and $\mbox{Grp}\times\mbox{Grp}$ respectively. There would be no morphisms of the form $G\to H\times H$ and $$\mathcal B(G\times G,H) := \{\varphi m_G \mid \varphi \in \mbox{Hom}(G,H)\} $$ where for every $x,y\in G$ $\varphi m_G (x,y) := \varphi (xy) = \varphi (x)\varphi (y) =: m_H(\varphi,\varphi)(x,y)$ . The identities are $1_G$ or $(1_G,1_G)$ depending on the component and composition of the morphisms would happen naturally. Is it guaranteed $(A,B) \neq (A',B') \implies \mathcal B(A,B)\cap\mathcal B(A',B') =\emptyset, A,A',B,B'\in\mathcal B_0$ ? Taking $\mathcal A = \mbox{Grp}$ with $X :\mathcal A\to\mathcal B$ given such that $X(G) = G\times G$ and for every morphism $f:G\to H$ , $X(f) = (f,f)$ . Put $Y:\mathcal A\to\mathcal B$ as the embedding, then we would have $m_G$ as a natural transformation $X\Rightarrow Y$ . I omit the routine checks here, for they aren't important for this discussion. I am interested in whether this idea of regarding families of operations as natural transformations is, call it, well-founded Questionnaire. Would such an approach be the only one? How else (if at all) would we regard the family $m_G$ as a natural transformation? Is this a more general thing in universal algebra? Given a class of algebras with certain operations of various arities, could we regard every family of operations as a natural transformation? (For instance, inverse operation or unit element operation of groups)","['universal-algebra', 'group-theory', 'natural-transformations', 'category-theory']"
3152646,Integral of $\sin^5x\cdot\cos^{14}x$,I just don't understand what I'm doing wrong. I'm doing it exactly like it was taught to me but I'm getting a completely different answer from the correct answer. $$\int\limits_0^{\frac{\pi}{2}}\sin^5(x)\cos^{14}(x)dx$$ My work: $$\int\limits_0^{\frac{\pi}{2}}[\sin^2(x)]^2\cos^{14}(x)\sin(x)dx$$ $$\int\limits_0^{\frac{\pi}{2}}[1-\cos^2(x)]^2\cos^{14}(x)\sin(x)dx$$ substitute $\cos(x)$ for $u$ . $du=\sin(x)dx$ $$\int\limits_0^{\frac{\pi}{2}}(1-u^2)^2u^{14}du$$ $$\int\limits_0^{\frac{\pi}{2}}(1-2u+u^4)u^{14}du$$ $$\int\limits_0^{\frac{\pi}{2}}u^{14}-2u^{16}+u^{18}du$$ $$\frac{1}{15}u^{15}-\frac{2}{17}u^{17}+\frac{1}{19}u^{19}\Bigg|_{-1}^0=$$ $$\frac{1}{15}\cos^{15}\left(\frac{\pi}{2}\right)-\frac{2}{17}\cos^{17}\left(\frac{\pi}{2}\right)+\frac{1}{19}\cos^{19}\left(\frac{\pi}{2}\right) - \left(\frac{1}{15}\cos^{15}(0)-\frac{2}{17}\cos^{17}(0)+\frac{1}{19}\cos^{19}(0)\right)$$ $$0-0+0-(1-1+1)$$ $$-1+1-1=-1$$ The correct answer is $\frac{8}{4845}$ Where did I go wrong?,"['integration', 'definite-integrals']"
3152656,Do Carmo 3.4. exercise 8: Vector Field on a Surface,"I'm having trouble trying to start this. Here is the problem statement: Show that if $w : S \to \mathbb{R^3}$ is a differentiable vector field on a regular surface $S \subset \mathbb{R}^3$ , and $w(p) \neq 0$ for some $p \in S$ , then it is possible to parametrize a neihghborhood of $p$ by $x(u,v)$ in such a way that $x_u = w$ . How do I start this? What do I need to show to prove this?","['vector-fields', 'parametrization', 'differential-geometry']"
3152661,"Sturm-Liouville, find normalized eigenfunction","I want to find the eigenvalues and normalized eigenfunctions of the problem $$-y'' = \lambda y, y'(0) = y(1) = 0. $$ By solving $r^2 + \lambda = 0$ I found the general solution $y(x) = c_1\cos(\sqrt{\lambda} x) + c_2 \sin(\sqrt{\lambda} x)$ , and using that $y'(0) = 0$ , I found that we must have $c_2 = 0$ . Using $y(1) = 0$ , I obtained the eigenvalues $\lambda_n = \frac{(2n+1)^2 \pi}{4}$ . Since $c_2=0$ , we have $y(t) = c_1 \cos(\sqrt{\lambda} x)$ and that made me believe that the normalized eigenfunctions were $u_n(x) = \cos \left(\frac{(2n+1)\pi}{2}x\right),$ but apparently the correct answer is $u_n(x) = \sqrt{2} \cos \left(\frac{(2n+1)\pi}{2}x \right)$ . Where did the $\sqrt{2}$ come from?","['sturm-liouville', 'ordinary-differential-equations', 'eigenfunctions']"
3152675,"Prove or disprove: If $A$ is $n\times n$ and $\exists\;m\in \Bbb{N}:\;A^m=I_n$, then $A$ is invertible.","Is this statement true? If $A$ is an $n\times n$ matrix and $A^m=I_n$ for some $m\in \Bbb{N}$ , then $A$ is invertible. My trial Let $n\in \Bbb{N}$ be fixed. Then, $$[\det(A)]^m=\det(A^m)=I_n=1.$$ Hence, $$\det(A)=1\neq 0.$$ Thus, $A$ is invertible since $\det(A)\neq 0.$ . I'm I right or is there a counter-example?","['matrices', 'algebra-precalculus', 'matrix-equations']"
3152696,Integration of $\int^{1}_{-1} \frac {1}{3} \sinh^{-1} \left( \frac {3\sqrt 3}{2} (1-t^2) \right) dt$,"Recently I came across with respect to this post of mine hyperbolic solution to the cubic equation for one real root given by $$
t=-2\sqrt \frac {p}{3} \sinh \left( \frac {1}{3} \sinh^{-1} \left( \frac {3q}{2p} \sqrt \frac {3}{p} \right) \right)
$$ Intuitively I sought to find the related definitely integral, $$
I=\int^{1}_{-1} \frac {1}{3} \sinh^{-1} \left( \frac {3\sqrt 3}{2} (1-t^2) \right) dt
$$ Unfortunately, there was no closed form solution. However, the Integral is amazingly near $\sqrt 2$ . $$
I=0.8285267994716327, \frac {I}{2} +1=1.4142633998
$$ To investigated more, I tried a heuristic expansion of the integral into Egyptian fractions. Although it gets problematic after the 4th term,
The first four terms are, $$
\frac {I}{2} +1 = 1+ \frac {1}{2} - \frac {1}{12}-\frac {1}{416}
$$ Here the denominators can be given by, $$
a_n = \sum_{k=0}^{n} { }^nC_k (2^n - 2^kq)^{n-k}q^k , q=\sqrt 2
$$ (Likewise, the denominators in the expansion for $\sqrt 2$ are related to Pell numbers, which makes me believe that my integral too is somewhat related to the numbers $a_n$ .) Therefore, I am finding either a closed form or possibly a fast converging infinite series solution to the integral, just any of these. Thanks for any help. The indefinite integral For $t=\sin z$ and applying integration by parts, I get another, somewhat simpler, indefinite integral, $$
\frac {\sin z}{3} \sinh^{-1} \left( \frac {3\sqrt 3}{2} \cos^2 z \right) + 2\sqrt 3 \int \frac {\sin^2 z \cos z dz}{\sqrt {27\cos^4 z + 4}}
$$ Then again I am stuck. Moreover, this expression ensures that my definite integral is an improper one. Update A closed solution in terms of incomplete elliptic integrals with complex arguments is, as given by a user in the comments section, $$
\frac {4}{9} (9+2\sqrt 3 i) \left[ F \left( \sin^{-1} \sqrt {\frac {3}{31}(9+2\sqrt 3 i)} ; \frac {1}{31} (23-12\sqrt 3 i) \right)-
E \left( \sin^{-1} \sqrt {\frac {3}{31}(9+2\sqrt 3 i)} ; \frac {1}{31} (23-12\sqrt 3 i) \right) \right]
$$ However, I am still wondering how to transform this into a real number, especially the $a_n$ connection of the integral is fascinating my mind.","['integration', 'calculus', 'definite-integrals', 'hypergeometric-function']"
3152723,limit of the sequence $(n+1)^\alpha - n^\alpha$,"Let $u_n$ be defined as : $u_n = (n+1)^{\alpha} - n^\alpha$ .
  Now I would like to compute $\lim_{n \to \infty} u_n$ (this limit depends on the choice of $\alpha$ ). Here is what I found so far : If $\alpha \in [0,1[$ then $\lim_{n \to \infty} u_n = 0$ . If $\alpha = 1$ then $\lim_{n \to \infty} u_n = 1$ . If $\alpha \geq 2$ , $\lim_{n \to \infty} u_n = +\infty$ . Now for $\alpha = 1$ and $\alpha \geq 2$ it's really easy to get the result. For $\alpha \in [0,1)$ I found it hard and here is what I do : we use the mean value theorem to say that : $$\mid (n+1)^\alpha - n^\alpha \mid \leq \alpha n^{\alpha-1} \to 0$$ And we get the desired result. Now my question is : 1- Is it possible to get the limit when $\alpha\in [0,1)$ with an other technique (without using the mean value theorem) ? 2- How to get the limit when $\alpha \in (1, 2)$ ? Thank you !","['limits', 'sequences-and-series', 'real-analysis']"
3152727,What is actually a Determinant?,"The way I've been introduced to determinants is that if there is a system of  two linear equations then we can represent the coefficients of the variables and the constants in the form of a matrix. Now if we plot the matrices on the coordinate system then we will get a parallelogram and if we calculate the area of the parallelogram then we will get the determinant of the given matrix.
For eg if A is the matrix then its determinant will be: $ad-cb$ . i.e. |A|= $ad-cb$ . if A= $\begin{bmatrix}a & b\\c & d\end{bmatrix}$ Now the questions I want to ask: 1)What is a determinant actually what does it tells us about a system of equations? 2)The area found by the formula $ad-cb$ , how is it telling us a determinant? Basically how the area of parallelogram telling the value of determinant? 3)In my book its given that: system of equations has a unique solution or not is determined by the number of ab-cd .What does this mean?","['matrices', 'systems-of-equations', 'determinant']"
3152752,Computation of a limit involving a series (related to Poisson distribution),Consider $\lambda >0.$ I am reading a paper and the author states that $$ \displaystyle\lim_{v \rightarrow +\infty} \sum_{n=0}^{+\infty} \frac{\lambda^{n}}{(n !)^v}  = 1 + \lambda$$ I tried to compute such limit but I am getting anywhere. Someone could help me? Thanks in advance!,"['statistics', 'analysis']"
3152801,Is Hamiltoncycle and Euler cycle NP-complete or not?,"Question: Determine which of these computational problems are NP-complete. Determining whether a number with $n$ digits is a prime number. Determining whether a graph with $n$ nodes has a hamiltoncycle. Determining whether a graph with $n$ nodes has an eulercycle. Determining whether a graph with $n$ nodes can be coloured with $2$ colors. Determining whether a graph with $n$ nodes can be colored with $3$ colors. My Attempts: 1) I'm not sure if this is correct because the question specifies the number of digits to be $n$ and not that the actual prime number is $n$ . So in the latter case, we only need to check the division of $n$ with primes that are less than $\sqrt{n}$ . This reasoning doesnt feel correct. 2) So if we first choose one node we can choose among $n$ of them, then we can choose to go to $n-1$ other nodes, and then $n-2$ and so on. So we get $n!$ which is not in polynomial time, thus it is NP-complete. 3) This one is trickier, i can't really use a similar argument as for the hamiltoncycle. I don't know the number of edges. How should I think here? 4) I assume that a coloring here should be such that no neighbouring/connected nodes have the same colour. But I have no idea how these $n$ nodes are connected in order to figure this out? 5) Same question as 4) essentially.","['graph-theory', 'np-complete', 'discrete-mathematics']"
3152811,Notational way to say that something is a set,"When you want to say, for example, that $a$ is an integer, you write it as $a \in \mathbb{Z}$ , which is read as "" $a$ is an element of the set of all integers"".
But, because of the notorious nonexistence of the set of all sets, you can't say something like $S \in \mathbb{S}$ , where $\mathbb{S}$ is my goofy nonce-glyph for said nonexistent set. Is there any valid notational way to indicate that $S$ is a set? If I'm writing a mathematical paper, I'll just write out "" $S$ is a set"" in English for the sake of clarity, but for my own notes I prefer to lean on notation as much as possible for the sake of brevity and unambiguity. Notes being notes, I do take liberties, but I'd like to adhere to standards if the standards are there. Is it possible to quantify something as a set without simply saying, in natural language, that it is a set?","['elementary-set-theory', 'notation']"
3152826,If $f(a)=f(b)=0$ and $|f''(x)|\le M$ prove $|\int_a^bf(x)\mathrm{d}x| \le \frac{M}{12}(b-a)^3$,"If $f(a)=f(b)=0$ and $|f''(x)|\le M$ . Prove $$|\int_a^bf(x)\mathrm{d}x| \le \frac{M}{12}(b-a)^3$$ I have thought about that since $f(a) = f(b) = 0 $ there is $\xi$ such that $f'(\xi) = 0$ . Then when $x \le \xi$ , $|f'(x)| \le (\xi - x)M$ and when $x \ge \xi$ , $|f'(x)| \le (x-\xi)M$ . After that $|f(x)| \le \frac{\xi^2 - (\xi -x)^2}{2}$ when $x \le \xi$ and $|f(x)| \le \frac{(b-\xi)^2 - (x - \xi)^2}{2}$ when $x \ge \xi$ . Therefore $$|\int_a^b f(x)\mathrm{d}x| \le \int_a^\xi |f(x)| + \int_\xi^b |f(x)| = \frac{\xi^3}{3} + \frac{(b-\xi)^3}{3}$$ If $x = \frac{a+b}{2}$ , we have $$\frac{x^3}{3}+\frac{(b-x)^3}{3} = \frac{(b-a)^3}{12}$$ But in this situation $\frac{x^3}{3}+\frac{(b-x)^3}{3}$ is the minimal value. So I can't go on.","['inequality', 'integral-inequality', 'analysis']"
3152873,Pullback of Fubini-Study form on $\mathbb {CP}^1$,"Question: Let $\varphi_S: S^2\setminus \{N\} \to \mathbb C$ be given by $\varphi_S (x_1, x_2, x_3) = \left(\frac{x_1}{1 - x_3}, \frac{x_2}{1 - x_3}\right)$ , i.e., the stereographic projection. Also let $\varphi_0^{-1}: \mathbb C \to \mathcal U_0$ be given by $\varphi_0^{-1} (z) = [1,z]$ , where $\mathcal U_0 = \{[z_0, z_1] \in \mathbb {CP}^1; z_0 \neq 0\}$ . Show that $$(\varphi_0^{-1} \circ \varphi_S)^*\omega_{FS} = \frac{1}{4} \omega_{std}$$ where $$\omega_{FS} = \frac{dx \wedge dy}{(1 + x^2 + y^2)^2}\ \ , \ \ \text{on} \ \ \mathcal U_0 \ \ \ \text{and} \ \ \ \omega_{std} = d\theta \wedge dh $$ where $0 \leq \theta \leq 2\pi$ and $-1\leq h \leq 1$ are cylindrical coordinates on the 2-sphere. Attempt: The composition $\varphi_0^{-1} \circ \varphi_S$ is given by, $$\varphi_0^{-1} \circ \varphi_S (z) = \left[1, \frac{x_1}{1-x_3} + i\frac{x_2}{1 - x_3}\right]  $$ Then, identifying $z = x + i y$ , $$x = \frac{x_1}{1 -x_3} \implies dx = \frac{1}{1-x_3} dx_1 + \frac{x_1}{(1-x_3)^2}dx_3 \\y = \frac{x_2}{1 -x_3} \implies dy = \frac{1}{1-x_3} dx_2 + \frac{x_2}{(1-x_3)^2}dx_3$$ So it follows that $$dx \wedge dy = \frac{1}{(1-x_3)^2}dx_1 \wedge dx_2 + \frac{x_2}{(1-x_3)^3}dx_3 \wedge dx_2 + \frac{x_1}{(1- x_3)^3} dx_3 \wedge dx_2$$ On the other hand $$(1 + x^2 + y^2)^2 = \frac{4}{(1 - x_3)^2}$$ Therefore $$\begin{aligned}(\varphi_0^{-1} \circ \varphi_S)^* \omega_{FS} &= \frac{1}{4}\left(dx_1 \wedge dx_2 + \frac{x_2}{1- x_3}dx_1 \wedge dx_3 + \frac{x_1}{1- x_3}dx_3 \wedge dx_2 \right) \\&= \frac{1}{4}\left(dx_1 \wedge dx_2 + \frac{x_2}{x_3 - 1}dx_3 \wedge dx_1 + \frac{x_1}{x_3 - 1}dx_2 \wedge dx_3 \right) \end{aligned}$$ I know that we may write $\omega_{std}$ as the pullback of the inclusion $\iota : S^2 \to \mathbb R^3$ as $$\omega_{std} = x_3 dx_1 \wedge dx_2 + x_2dx_3 \wedge dx_1 + x_1dx_2 \wedge dx_3  $$ What am I missing? I couldn ` t get any further than this. Any ideas?","['pullback', 'symplectic-geometry', 'differential-forms', 'differential-geometry']"
3152875,Recurrence of Brownian Motion,"I am reading a proof of recurrence of Brownian Motion from the book of Morters and Peres. I have a question about a particular step in the proof of neighborhood recurrence for Brownian Motion in dimension 2. He has proven that if the Brownian Motion starts at $x\in {\Bbb R}^2$ then with probability 1 it enters any annulus in finite time. I have no problem with the way he proves this. Using this fact, he begins to prove the neighborhood recurrence for dimension 2. The proof is as follows. By the above property and shift-invariance the stopping time $ t_1$ = inf $\{t >
0: B(t) ∈ B(x, ε)\}$ is almost surely finite. Using the strong Markov property at time $t_1+1$ we see that this also applies to $t_2$ = inf $\{t > t_1 + 1: B(t) ∈ B(x, ε)\}$ , and continuing like
this, we obtain a sequence of times $t_n ↑ \infty$ such that, almost surely, $B(t_n ) ∈ B(x, ε)$ for all $n ∈ {\Bbb N}$ . Taking an intersection over a countable family of balls $(B(x_i, ε_i): i = 1, 2, . . .)$ ,
forming a basis of the Euclidean topology, implies that in $d = 2$ Brownian motion is
neighbourhood recurrent. My issue is with the application of the Strong Markov Property (SMP) in this proof. I assume we are applying the SMP for the stopping time $t_1+1$ . So now we consider the Brownian Motion starting at $t_1+1$ i.e we will consider the process $\{B^{(1)}(t)=B(t+t_1+1)-B(t_1+1):t\geq0\}$ . Since $\{B^{(1)}(t):t\geq0\}$ is a Brownian Motion starting at the origin, with probability 1, it will enter the ball $B(x,\epsilon)$ in finite time. However, $B^{(1)}$ only measures the displacement of $B(t)$ after the stopping time $t_1+1$ . How does $B^{(1)}(t)\in B(x,\epsilon)$ (or in fact $B^{(1)}(t)$ being in any other open ball) produce a new time point, say $t'\geq t_1+1$ such that $B(t')\in B(x.\epsilon)$ ? Once this issue is resolved, the rest of the proof I am fully on board with. It's just this part that is bugging me. I can intuitively see what the author is getting at but I'm looking for some rigorous justification. Clearly there is a step here but I cannot figure it out. Any help would be great. Thanks.","['stochastic-processes', 'proof-explanation', 'brownian-motion', 'probability']"
3152886,Is a distribution whose mean and variance are its only non-zero cumulants neccesarily Gaussian?,"I have a distribution. Its cumulants are all zero except for its mean and variance. Does that necessarily mean that my distribution is Gaussian? Or in other words, are there non-Gaussian distributions whose only non-zero cumulants are mean and variance.","['statistics', 'probability-distributions', 'cumulants', 'probability']"
3152988,"Let $G,H$ be groups and $\varphi:G \times H\to G$ and $H'=\ker(\varphi)$. Show that $(G\times H)/H'\cong G$","This is Exercise 10 from Section 7: Groups and Homomorphisms , Chapter 1 : Foundation , textbook Analysis I by Herbert Amann and Joachim Escher . Let $(G,\odot)$ and $(H,\circledast)$ be groups, and let $$\varphi: G \times H \to G \space, \quad \langle g,h \rangle \mapsto g$$ be the projection onto the first coordinate. Show that $\varphi$ is a surjective homomorphism. Let $H' := \ker(\varphi)$ . Show that $(G \times H)/H'$ and $G$ are isomorphic. While the proof of 1. is quite easy, that of 2. is complicated to me. Please help me check it out. Thank you for your help! My attempt: In order to prove that $\varphi$ is a surjective homomorphism, $G \times H$ must be a group. It is confusing that the authors do not say anything about the operation on $G \times H$ . As a result, I guess $$\oplus: (G \times H) \times (G \times H) \to G \times H \space, \quad (\langle g_1, h_1 \rangle, \langle g_2, h_2 \rangle) \mapsto \langle g_1 \odot g_2, h_1 \circledast h_2 \rangle$$ is the operation on $G \times H$ . $\varphi$ is a surjective homomorphism First, $\varphi (\langle g_1, h_1 \rangle \oplus \langle g_2,h_2 \rangle) = \varphi (\langle g_1 \odot g_2, h_1 \circledast h_2 \rangle) = g_1 \odot g_2$ . Second, $\varphi (\langle g_1, h_1 \rangle) \odot \varphi (\langle g_2,h_2 \rangle) = g_1 \odot g_2$ . As a result, $$\varphi (\langle g_1, h_1 \rangle \oplus \langle g_2,h_2 \rangle) = \varphi (\langle g_1, h_1 \rangle) \odot \varphi (\langle g_2,h_2 \rangle)$$ and thus $\varphi$ is a homomorphism. Clearly, $\varphi$ is surjective. $(G \times H)/H'$ and $G$ are isomorphic Since $\varphi$ is a homomorphism, $H'$ is a normal subgroup of $G \times H$ . Then $(G \times H)/H'$ with the induced operation is a group, the quotient group of $G \times H$ modulo $N$ . $$\begin
{array}{lrcl}
& ((G \times H)/H') \times ((G \times H)/H') & \longrightarrow & (G \times H)/H' \\ & (\langle g_1, h_1 \rangle \oplus H' , \langle g_2, h_2 \rangle \oplus H') & \longmapsto & (\langle g_1, h_1 \rangle \oplus \langle g_2,h_2 \rangle) \oplus H' \end{array}$$ I will use the same symbol $\oplus$ for this induced operation. It follows from $H' = \ker(\varphi)$ and $\varphi$ is a homomorphism that $$\langle g, h \rangle \oplus H' = \varphi^{-1}[\{\varphi(\langle g, h \rangle)\}] = \varphi^{-1}[\{g\}]$$ and that $$\langle g_1, h_1 \rangle \sim \langle g_2, h_2 \rangle \iff \varphi (\langle g_1, h_1 \rangle) = \varphi (\langle g_2, h_2 \rangle) \iff g_1 = g_2$$ Consider $$\begin
{array}{lrcl}
\psi : & (G \times H)/H'
 & \longrightarrow & G \\
    & \langle g, h \rangle \oplus H' & \longmapsto & g \end{array}$$ Then $\psi$ is well-defined. First, $\psi ((\langle g_1, h_1 \rangle \oplus H') \oplus (\langle g_2, h_2 \rangle \oplus H')) = \psi ((\langle g_1, h_1 \rangle \oplus \langle g_2,h_2 \rangle) \oplus H') = \psi (\langle g_1 \odot g_2, h_1 \circledast h_2 \rangle \oplus H') = g_1 \odot g_2.$ Second, $\psi (\langle g_1, h_1 \rangle \oplus H') \odot \psi (\langle g_2, h_2 \rangle \oplus H') = g_1 \odot g_2.$ As a result, $$\psi ((\langle g_1, h_1 \rangle \oplus H') \oplus (\langle g_2, h_2 \rangle \oplus H')) = \psi (\langle g_1, h_1 \rangle \oplus H') \odot \psi (\langle g_2, h_2 \rangle \oplus H')$$ and thus $\psi$ is a homomorphism. Clearly, $\psi$ is surjective. If $\psi (\langle g_1, h_1 \rangle \oplus H') = \psi (\langle g_2, h_2 \rangle \oplus H')$ , then $g_1 = g_2$ . Hence $\varphi (\langle g_1, h_1 \rangle) = \varphi (\langle g_2, h_2 \rangle)$ and thus $\langle g_1, h_1 \rangle \sim \langle g_2, h_2 \rangle$ . So $\langle g_1, h_1 \rangle \oplus H' = \langle g_2, h_2 \rangle \oplus H'$ . As a result, $\psi$ is injective. To sum up, $\psi$ is a bijective homomorphism and thus an isomorphism.","['group-theory', 'proof-verification', 'group-isomorphism']"
3153007,Nested trig functions (incl. inverse trig functions),"Edit: Although this problem has received a kind answer, I would still appreciate more comprehensive explanation. I am still rather confused. This problem has confused me a bit: The standard method is one I know well: Draw a right triangle, set the adjacent and hypotenuse to: $(2x+1)$ and $\sqrt {17}$ , respectively; then use the Pythagorean theorem to solve for the third side. Then it is easy to find the sine by taking the opposite over the hypotenuse. Alas, I feel uncomfortable about this method -- it feels like it's glossing over something. Why can we assume that $\arccos(2x+1/\sqrt {17})$ describes an angle in a RIGHT triangle? The range of $\arccos$ is, after all, zero to $\pi$ -- which obviously includes some values that are too large for a right triangle. So what gives? Why does the method mentioned above work? Shouldn't we be using unit circle trigonometry rather than the basic right triangle definition? And, while we're at it, I may as well bring up another similar problem that confused me: $$\sec(\arctan(\frac{x}{x-1})$$ The teacher said the answer was $\frac{\sqrt{2x^2+1}}{\lvert x-1\rvert}$ Why the absolute value on the denominator? I still can't figure that out. Of course, in a triangle all sides must have positive length, but that doesn't mean we can't have negative values for trig functions!","['algebra-precalculus', 'trigonometry']"
3153018,Solution to this ODE that tends to a constant at infinity,"I started with the following 2nd order PDE $$ -\frac{x}{x-1}\partial_y^2\phi+\frac{1}{x^2} \partial_x (x(x-1)\partial_x \phi) = \mu^2 \phi$$ which is clearly separable. I want a solution that asymptotes to a $y$ -dependent constant at $x$ -infinity. I therefore tried the form $\phi = X(x)Y(y)$ , with $X(x\rightarrow \infty) \rightarrow1$ . Looking at this limit above we see that it can only hold if $\partial_y^2 Y = -\mu^2 Y$ . Subbing this back in, I end up with an ODE for $X$ : $$ \frac{1}{x^2} \partial_x (x(x-1)\partial_x X) = -\frac{\mu^2}{x-1} X$$ I've tried solving this numerically (obviously staying away from $x=1$ ) on Mathematica. For any initial conditions I give at some finite $x$ , the solution seems to always die off oscillating around zero, as in plot. So I'm wondering why it seem like the boundary condition at infinity $X\rightarrow $ constant seems allowed. Have I fooled myself? If I expand the ODE for large $x$ to 'first order' I have $$\left( 1- \frac{1}{x}\right)\partial_x^2 X + \frac{2}{x} \partial_x X = -\frac{\mu^2}{x} X, \quad \quad x \rightarrow \infty$$ Mathematica gives exact solutions for this in terms of Bessel functions and these indeed match the asymptotic behaviour in the plot above.
However if I stopped at 'zeroth order' I would just have $\partial_x^2 X = 0$ and a self-consistent solution $X=$ constant (a term linear in $x$ would not be self-consistent with ignoring the first derivative term). Where is my reasoning wrong? Is there no solution with the boundary condition I desire? (If there is a way of enforcing a boundary condition at infinity numerically I am unaware of it)","['asymptotics', 'ordinary-differential-equations']"
3153033,An application of Kolmogorov $0$-$1$ law,"I need to approve or to disapprove the following statement : if $(X_n)_{n \in \mathbb{N}}$ is a sequence of independent random variables and identically distributed, and $(u_n)_{n \in \mathbb{N}}$ is a sequence of real numbers such that $$\mathbb{P}(\limsup_n|\frac{1}{n}\sum_{k=1}^nX_k-u_n|<+\infty)>0$$ then $\mathbb{P}(\limsup_n\frac{1}{n}|X_{2n+1}-X_{2n}|<+\infty)=1$ I know that by kolmogorov $0$ - $1$ law (since $(\frac{1}{n}|X_{2n+1}-X_{2n}|)_{n \in \mathbb{N}}$ is a sequence of independent random variable), we have $\mathbb{P}(\limsup_n\frac{1}{n}|X_{2n+1}-X_{2n}|<+\infty)=0 \ \ or \ \ 1,$ So which value does it take?","['borel-cantelli-lemmas', 'measure-theory', 'probability-theory', 'probability']"
3153051,Going from the differential to the derivative (Frechet and matrix calculus),"For a function $f: A \rightarrow B$ , Frechet differentiability tells us that we want to find a linear operator that satisfies $$\lim_{H\rightarrow 0} \frac{||f[X+H] - f[X] - G[H]||}{||H||} = 0$$ This would mean that $G$ is a good approximation of the change in $f$ at $X$ for some small $H\in A$ . That is for the operator $df: A \rightarrow B$ $$df(X)[H] = G[H]$$ Wikipedia says that $G$ is defined as the Frechet derivative of $f$ at $X$ . But I have a litte trouble connecting this to the traditional notion of the derivative, where we have a fraction i.e. something like $\frac{dy}{dx}$ . For example, consider a standard formula from the matrix cookbook $$\frac{dTr(XA)}{dX} = A^T$$ The Frechet differentiability definition gets me up to $$dTr(XA)[H] = G[H] = Tr(HA).$$ What is then done is \begin{align}
dTr(XA)[H] &= Tr(HA) \\
&= A^T :H,
\end{align} where we just use the notation $A:B = Tr(A^TB)$ . What is the correct way to go from here to the conclusion that $$\frac{dTr(XA)}{dX} = A^T$$ and what does the LHS even represent exactly since it's not a fraction in the traditional sense? More generally, what is involved in going from the differential form i.e. $df(X)[H] = G[H]$ to the derivative form $G = \frac{df(X)}{dX}$ ?","['frechet-derivative', 'matrix-calculus', 'derivatives']"
3153111,$\sum_{k=0}^\infty\frac{ (-1)^{\left\lfloor\frac kn\right\rfloor}}{k+1}$,"While testing a program I came across an interesting equality: $$
\sum_{k=0}^\infty\frac{ (-1)^{\left\lfloor\frac kn\right\rfloor}}{k+1}
=\frac1n\left[\log2+\frac\pi2\sum_{k=1}^{n-1}\tan\frac{k\pi}{2n}\right],
$$ which generalises the well-known identity for $n=1$ . Is there a simple way to prove it?","['calculus', 'sequences-and-series']"
3153119,Does the closest point on a subset change continuously?,"$\newcommand{\til}{\tilde}$ Let $(X,d)$ be a metric space, and let $S \subseteq X$ . Suppose that every point in $X$ has a unique closest point in $S$ , which we denote by $\tilde s(p)$ . Is it true that the map $\tilde s:X \to S$ is continuous? I know that the answer is positive when $S$ is compact. What happens when it is non-compact? Here is a proof for the compact case: Let $d_S:X \to \mathbb R$ denote the distance function from $S$ , i.e. $d_S(p):=\text{dist}(p,S) = \inf_{s \in S} d(p,s)$ . We will use the Urysohn property: Let $p_n \in X$ be a sequence which converges to $p$ in $X$ . We want to prove that $\tilde s(p_n) \to \tilde s(p)$ . Let $p_{n_k}$ be a subsequence; Then $\til s\left( p_{n_k} \right) \in S$ , hence by compactness of $S$ it has a convergent subsequence $s_l:=\tilde s\left( p_{n_{k_l}} \right)$ with limit $\til s \in S$ . It suffices to prove that $\til s = \tilde s(p)$ .
Taking the limit $l \to \infty$ of both sides of the equality $$
d( p_{n_{k_l}}  , s_l)=  d ( p_{n_{k_l}},\til s(p_{n_{k_l}}) )= d_{S}( p_{n_{k_l}}  )
$$ and using the facts that $d,d_S$ are continuous,  and $p_{n_{k_l}} \to p,s_l \to\tilde s $ , we obtain $$
d(p,\tilde s) = d_{S}(p),
$$ which by the assumed uniqueness forces $\til s = \til s\left( p \right)$ .","['projection', 'metric-spaces', 'continuity', 'general-topology', 'compactness']"
3153176,How many possibilities can a 10x5 grid with somewhat even distribution produce?,"Imagine a 10 x 5 grid where each square can be either 1 or 0. However, each row (10 squares) must contain five 1's and five 0's. Therefore, each grid (of 50 squares) has twenty five 1's and twenty five 0's but their distribution is somewhat controlled in that each row must contain five of each. How many possible combinations of grids can this produce?",['statistics']
3153187,Is a square zero matrix positive semidefinite?,Does the fact that a square zero matrix contains non-negative eigenvalues (zeros) make it proper to say it is positive semidefinite?,"['matrices', 'linear-algebra', 'positive-semidefinite']"
3153197,"Does $ \sum_{i=1}^n n^{k_i} $ determines $(k_1,...,k_n)$?","Let $k_1,...,k_n\in\mathbb{N}$ . Does the power sum $$
\sum_{i=1}^n n^{k_i}
$$ uniquely determines the $n$ -tuple $(k_1,...,k_n)$ ? Remark : In the case $n=2$ , this is true. However, when trying to generalize to an arbitrarily sized sum, it doesn't hold. For example, $$
2^0+2^0+2^2=2^1+2^1+2^1.
$$ I then thought of a fixed sum size, equal to the considered base, but I don't know exactly how to argue or build this bijection. The motivation behind this question comes from trying to determine the $n$ -tuple $(k_1,...,k_n)$ from the sum $$
\sum_{i=1}^n g(k_i),
$$ where $g$ is some constructible function.","['power-series', 'number-theory', 'summation', 'sequences-and-series']"
3153244,"$a,b \in \mathbb Z$ we have that $a+ b\phi \in \mathbb Z[\phi]^* \iff a^2 +ab-b^2 = \pm 1$","I am thinking about the following question: Let $\phi= \frac{1+ \sqrt 5}{2}$ be the golden ratio, and define: $$ \mathbb Z [\phi]=\{a+ b\phi  : \quad a, b \in \mathbb Z\} $$ We wish to prove that for $a,b \in \mathbb Z$ we have that $a+ b\phi \in \mathbb Z[\phi]^*  \iff  a^2 +ab-b^2 = \pm 1$ . 
  Note: the star indicates the multiplicative group of our ring. This exercise comes with a hint: let $\bar{\phi}=\frac{1-\sqrt 5}{2}$ , You may use without proof that $(a + b \phi)(c + d\phi) = 1$ if and only if $(a + b\bar{\phi})(c + d\bar{\phi}) = 1$ . I have trouble interpreting how the hint plays out.","['golden-ratio', 'ring-theory', 'group-theory', 'abstract-algebra']"
3153246,Number of Sequences of $1$'s $2$'s and $3$'s with Restriction,"We want to write down a sequence of $n$ numbers, where each number
  must be a $1,2$ or a $3$ . The restriction is that there must be a $1$ between each two $2$ 's and a $2$ between each two $1$ 's. In how many
  ways can this be done? Starting with $n=1$ we have simply $1,2$ or $3$ so these are only 3 ways. for $n=2$ we can write $12,13,21,23,31,32,33$ so we have 7 ways. For $n=3$ we have $$121,123,133,212,213,233,312,321,333,323,313,332,331,132,231$$ which is counted to be $15$ . So we have the number of ways as the sequence $3,7,15,...$ for $n=1,2,3,...$ . Proceeding like this is not a smart way since we start getting lots of different permutations of these sequence. Is there any smart way of thinking?","['permutations', 'combinatorics', 'discrete-mathematics']"
3153287,How to prove that function $f(p)= \frac{1}{(p^2 - 1)} \sum_{q=3}^p \frac{q^2-3}{q}[q\text{ is prime}]$ is less than 0.3 for all $p$?,"How to prove that function $f(p)= \frac{1}{(p^2 - 1)} \sum_{q=3}^p \frac{q^2-3}{q}[q\text{ is prime}]$ is less than 0.3 for all $p$ ? Let's suppose that we have a function defined as follows: $f(p) = \frac{1}{(p^2 - 1)} \sum_{q=3}^p \frac{q^2-3}{q}[q\text{ is prime}]$ where $p$ is a prime number and $[...]$ are Iverson brackets . Here are the first few values of $f(p)$ : $f(3) = \frac{1}{(3^2 - 1)} \times \frac {(3^2-3)}{3}$ $f(3) = \frac{1}{8} \times  \frac{6}{3}$ $f(3) = 0.25$ $f(5) = \frac{1}{(5^2 - 1)} \times [ \frac{(3^2-3)}{3} +\frac{(5^2-3)}{5} ]$ $f(5) = \frac{1}{24} \times [ \frac{6}{3} +\frac{22}{5} ]$ $f(5) = 0.26667$ $f(7) = \frac{1}{(7^2 - 1)} \times [ \frac{(3^2-3)}{3} +\frac{(5^2-3)}{5} +\frac{(7^2-3)}{7}]$ $f(7) = \frac{1}{48} \times [ \frac{6}{3} +\frac{22}{5} +\frac{46}{7}]$ $f(7) = 0.273214286$ $f(11) = \frac{1}{(11^2 - 1)} \times [ \frac{(3^2-3)}{3} +\frac{(5^2-3)}{5} +\frac{(7^2-3)}{7}+\frac{(11^2-3)}{11}]$ $f(11) = \frac{1}{120} \times [ \frac{6}{3} +\frac{22}{5} +\frac{46}{7}+\frac{118}{11}]$ $f(11) = 0.198679654$ How to prove that $f(p)$ is always less than 0.3 for all prime numbers $p$ ? I wrote a program to calculate $f(p)$ for the first $1000$ primes up to $p = 7,927$ and graphically it appears to approach $0$ with a maximum value of $0.2732$ at $p=7$ . From the graph, it looks like it should be easy, but for some reason, I cannot figure it out. Notice that $f(3) < f(5) < f(7)$ , but $f(7) > f(11)$ so a proof by induction may not work.","['number-theory', 'proof-writing', 'prime-numbers']"
3153305,Density of test functions in the space of distributions -- a clarification,"Let $U \subseteq \mathbb{R}^n$ be open and denote by $\mathcal{D}(U)$ the space of all compactly supported smooth functions $U \to \mathbb{R}$ . Let $\mathcal{D}^\prime(U)$ be the space of all distributions $\mathcal{D}(U) \to \mathbb{R}$ with the standard topology. Given a distribution $T$ , I would like to prove that there exists a sequence $(\psi_n)$ in $\mathcal{D}(U)$ such that \begin{equation}\label{eq:1}\tag{$\ast$}
\lim_{n \to \infty} \left\langle \psi_n, \varphi \right\rangle  = \left\langle T , \varphi\right\rangle
\end{equation} for all $\varphi \in \mathcal{D}(U)$ . I became interested in this question while the following paragraph from this Wikipedia article: The test functions are themselves locally integrable, and so define distributions. As such they are dense in $\mathcal{D}^\prime(U)$ with respect to the topology on $\mathcal{D}^\prime(U)$ in the sense that for any distribution $T \in \mathcal{D}^\prime(U)$ , there is a sequence $\psi_n \in \mathcal{D}(U)$ such that $$
\left\langle \psi_n, \varphi \right\rangle \to \left\langle T, \varphi \right\rangle
$$ for all $\varphi \in \mathcal{D}(U)$ . This fact follows from the Hahn-Banach theorem, since the dual of $\mathcal{D}^\prime(U)$ with its weak*-topology is the space $\mathcal{D}(U)$ . My question is as follows: how does this follow from the Hahn-Banach theorem ? I understand why $(\mathcal{D}^\prime(U))^\ast \cong \mathcal{D}(U)$ when the former is given the weak*-topology, but I fail to see how \eqref{eq:1} follows from the Hahn-Banach theorem.","['topological-vector-spaces', 'distribution-theory', 'functional-analysis', 'real-analysis']"
3153331,Number of ways to distribute 20 identical pencils to 6 non-identical children with restrictions,"How many ways are there to pass out 20 pencils (assume all the pencils are identical the same) to six children? Based on the following condition: a) No restriction. ( i.e. each kid may receive zero to 20 pencils.) b) Every child receives at least one pencil. c) None of child receives the same number of pencils. d) If the pencils are given out randomly. What is the probability that there are at least two kids receive the same number of pencils if every kids receives at least one pencil? I have calculated a) using C(25,20) = 53,130 I calculated b) using C(19,14) = 11,628 for c) I get answer 840 using the following program class final34{
    public static void main(String[] args){
        int u,v,x,y,z;
        int count = 0;
        int last=0;

        for(u =1;u<11;u++){
            for(v = 1;v<11; v++)
                if(u!=v)
                    for(x = 1;x<11;x++)
                        if(x!=u && x!=v)
                            for(y = 1; y<11;y++)
                                if(y!=u && y!=v && y!=x)
                                    for(z=1;z<11;z++)
                                        if(z!=u && z!=v && z!=x && z!=y)
                                            if(u+v+x+y+z == 20){
                                                System.out.println(u+"" ""+v+"" ""+x+"" ""+y+"" ""+z);
                                                count++;
                                            }
        System.out.println(""Count after iteration ""+u+"": ""+(count-last));
        last = count;
        }
        System.out.println(""Total Count: ""+count);
    }
} I see the output: Count after iteration 1: 144 Count after iteration 2: 144 Count after iteration 3: 120 Count after iteration 4: 120 Count after iteration 5: 96 Count after iteration 6: 72 Count after iteration 7: 48 Count after iteration 8: 48 Count after iteration 9: 24 Count after iteration 10: 24 Total Count: 840 But I don't know how to prove this using discrete mathematics. Also I need help on d).","['permutations', 'combinations', 'discrete-mathematics', 'probability']"
3153357,"Smooth, approximately space-filling curves in high dimensions","I'm looking for smooth (infinitely differentiable everywhere) functions (curves) $\mathbb{R}\rightarrow\mathbb{R}^d$ that are approximately space-filling, i.e. scaling allows the curve to eventually get arbitrarily close to all points in $\mathbb{R}^d$ . An intuitive example for $\mathbb{R}\rightarrow\mathbb{R}^2$ would be the Archimedean Spiral , e.g.: Example function: $$
\mathrm{f}(t)=
\rho\cdot
\begin{pmatrix}
  \cos(t) \cdot t \\
  \sin(t) \cdot t
\end{pmatrix}
$$ As $\rho$ approaches zero, the spiral will eventually get arbitrarily close to every point in $\mathbb{R}^2$ . It would also be great if the computational complexity of calculating such a function only increases linearly with the dimension $d$ .","['curves', 'analytic-geometry', 'smooth-functions', 'differential-geometry']"
3153414,Example of a Manifold which only has Ricci Curvature in One Direction,"I was wondering if anyone had a simple example of a manifold which only has Ricci curvature in one direction ie. such that the Ricci tensor only has one non-zero component. Intuitively, I would expect such a thing to be possible somehow just from the definition of Ric but could not think of an example.","['riemannian-geometry', 'differential-geometry']"
3153437,"Completeness of a Normed Space of Smooth, Bounded Functions","As part of a proof of the Picard–Lindelöf theorem, I am using the following space: $X = \{ u \in C([0,T]) : u(0) = \alpha , || u - \alpha || \leq K\}$ where $K \in \mathbb{R}_{> 0} , \ \alpha \in \mathbb{R}$ and the norm is defined as follows: $|| u || = ^{\text{sup}}_{t \in (0,T)} |u(t)|$ . I have read and understood the proof just fine, but no version I have read so far has provided a proof for whether or not $X$ is actually complete, which is necessary to make use of the Banach Fixed Point Theorem. I have shown in previous exercises that such $X$ is complete under the norm: $||u|| = ^{\text{sup}}_{t \in (0,T)} ( |u(t)| + |u'(t)| ) $ but I cannot figure out how to do so without the derivative included in the norm. Here is my progress so far: Let $u_{n}$ be a Cauchy sequence in $X$ . I have shown that there is a function, $u$ , to which $u_{n}$ converges pointwise, and thus $u$ is continuous. I have also shown that $||u|| \leq K$ . However, I have not figured out how to show that $u$ is differentiable, and thus inside $X$ . I would like to prove the following claim: if $u_{n}$ is a Cauchy sequence in $X$ , then $u_{n}'$ is also Cauchy in $X$ . I would surely be done then. Can someone guide me as to how I can prove this claim? Or if by any chance I am completely mistaken here and $X$ is in fact not complete at all? In that case, how does one make use of such a set to prove the Picard–Lindelöf theorem? Thank you very much.","['complete-spaces', 'cauchy-sequences', 'metric-spaces', 'functions', 'functional-analysis']"
3153451,"Every connected orientable smooth manifold has exactly two orientations, Lee Proposition 15.9","The proof of Proposition 15.9 from John Lee's book ""Introduction to Smooth Manifolds"" is left as an exercise. Here is the statement: Let $M$ be a connected, orientable, smooth manifold with or without boundary. Then $M$ has exactly two orientations. If two orientations of $M$ agree at one point, they are equal. Here is my argument Let $\mathcal{O}=\{\mathcal{O}_p:p\in M\}$ and $\tilde{\mathcal{O}}=\{\tilde{\mathcal{O}}_p:p\in M\}$ be orientations for $M$ . Let $\mathcal {C}=\{p\in M:\mathcal O_p=\tilde{\mathcal O}_p\}$ , and let $p\in \mathcal C$ . By definition there exist $(E_i:U\to TM)$ and $(\tilde E_i:\tilde U\to TM)$ (continuous) local frames such that $p\in U\cap \tilde U$ and $(E_i)$ is positively oriented with respect to $\mathcal O$ and $(\tilde E_i)$ is positively oriented with respect to $\tilde {\mathcal O}$ . We can suppose $U\subseteq \tilde U$ and $U$ connected. Since $\mathcal O_p=\tilde{\mathcal O}_p$ we have that the ordered basis $(E_1|_p,\dots,E_n|_p)$ and $(\tilde E_1|_p,\dots,\tilde E_n|_p)$ are consistently oriented, meaning that the transition matrix $A(p)=(A_i^j(p))$ has positive determinant. The map det $_A:U\to \mathbb{R}, q \mapsto$ det $A(q)$ is continuous (where $A(q)$ is the transition matrix between the ordered basis $(E_1|_q,\dots,E_n|_q)$ and $(\tilde E_1|_q,\dots,\tilde E_n|_q)$ ) and since $U$ is connected and det $A(p)>0$ we have that det $_A$ is always positive on $U$ . This implies that $U\subseteq \mathcal C$ , and thus $\mathcal C$ is open in $M$ . Analogously we show that $M-\mathcal C$ is open in $M$ . Since $M$ is connected we have $\mathcal C=\emptyset$ or $\mathcal C=M$ . In the second case we have $\mathcal O=\tilde{\mathcal O}$ . In the first case $\mathcal O$ and $\tilde{\mathcal O}$ are two distinct orientations of $M$ and any other orientation $\hat{\mathcal O}$ of $M$ would have $\hat{\mathcal O_p}=\mathcal O_p$ or $\hat{\mathcal O_p}=\tilde{\mathcal O_p}$ , and thus we would have $\hat{\mathcal O}=\mathcal O$ or $\hat{\mathcal O}=\tilde{\mathcal O}$ . $\qquad\square$ To be precise I should also prove the existence of two distinct orientations. But if $\mathcal O$ is the orientation which exists by hypothesis, then $-\mathcal O$ is another orientation. So we have at least two (distinct) orientations of $M$ . Please let me know if my proof is correct and if it can be shortened/ simplified.","['manifolds', 'orientation', 'smooth-manifolds', 'differential-geometry']"
3153491,Lubin-Tate formal groups are $p$-divisible groups,"I am trying to understand how to see whether a given formal group is $p$ -divisible.
Let $A$ be a complete noetherian local ring with maximal ideal $\mathfrak{m}$ and residue field $k$ of characteristic $p$ and let $F \in A[[X,Y]]$ be a formal group law. Is there a nice criterion to see whether the map $$[p]^* \colon A[[X]] \to A[[X]], f(X) \mapsto f([p](X))$$ is injective and makes $A[[X]]$ into a finite free module over $A[[X]]$ ? (This is the definition of $F$ being $p$ -divisible.) My main case of interest is when $A=\mathfrak{o}$ is the ring of integers in a finite extension of $\mathbb Q_p$ . Lubin's answer to the question How is the $p$-adic Tate module of a formal group defined? seems to imply that $$F \,\,\text{    is } p\text{ -divisible } \iff [p] \text{  mod } \pi \neq 0 \text{ in } k[[X]]$$ where $\pi$ denotes a uniformizer of $\mathfrak o$ . Is this true? I would very much be thankful for a proof of this!","['algebraic-number-theory', 'p-adic-number-theory', 'algebraic-geometry', 'abstract-algebra', 'power-series']"
3153500,Do the Prime Number Theorem and/or Riemann Hypothesis predict a limit on the accuracy of this formula for $\gamma$?,"This question is related to the following formula for Euler's constant $\gamma$ where $A$ is Glaisher's constant. (1) $\quad\gamma=12\,\log(A)-\frac{\pi^2}{6}\sum\limits_{n=1}^N\frac{\mu(n)}{n^2}\,\log\left(\frac{2\,\pi}{n}\right),\quad N\to\infty$ The discrete plot in the following figure illustrates the error in formula (1) above as a function of $N$ . The red evaluation points illustrate the error in formula (1) above where the Mertens function $M(N)=\sum\limits_{n=1}^N\mu(n)$ evaluates to zero. Figure (1) : Error in Formula (1) as a function of $N$ Question : Do the Prime Number Theorem and/or Riemann Hypothesis predict a limit on the accuracy of formula (1) for $\gamma$ as a function of $N$ ? 3/30/2019 Update: Since $\sum_{n=1}^\infty\frac{\mu(n)}{n^2}=\frac{6}{\pi^2}$ , formula (1) above can be simplified as follows. (2) $\quad\gamma=12\,\log(A)-\log(2\,\pi)+\frac{\pi^2}{6}\sum\limits_{n=1}^N\frac{\mu(n)}{n^2}\,\log(n),\quad N\to\infty$ Formulas (1) and (2) above can be simplified further as follows. (3) $\quad\gamma =12\,\log(A)-\log(2\,\pi)+\frac{6}{\pi^2}\,\zeta'(2)$","['number-theory', 'riemann-hypothesis', 'euler-mascheroni-constant', 'mobius-function', 'sequences-and-series']"
3153522,Why are eigenvectors important for Deep Learning applications?,"I know it is quite of a trite question to ask about the importance of eigenvectors, but I do not understand how they can be relevant for Deep Learning and when we can use them. Any reference to the literature as well is of course appreciated.","['machine-learning', 'linear-algebra', 'neural-networks', 'eigenvalues-eigenvectors']"
3153565,Evaluate $\int \frac{ 2\exp\left((-\tan^2(t))/a^2\right) }{\cos^3(t)a^2}dt$ using substitution.,Evaluate : $\displaystyle\int \frac{ 2\exp\left((-\tan^2(t))/a^2\right) }{\cos^3(t)a^2}dt$ The hint was to use $x=\cos(t)$ and the fact that $\int f'(x)e^f(x)dx=e^f(x)$ . Since $$x=\cos(t)\;\text{then}\;\tan^2(t)=\dfrac{(1-t^2)}{t^2}$$ and $$x = \cos(t) \implies \dfrac{dx}{dt} = -\sin(t) \implies dt = \dfrac{dx}{-\sin(t)}$$ If it weren't for division by $-\sin(t)$ then it would have been easy to solve as I could have used the fact that the integral of $f'(x)e^f(x)$ is $e^f(x)$ as the derivative of $\dfrac{-(1-x^2)}{x^2}$ is $\dfrac{2}{x^3}$ and everything fits nicely. I would appreciate it if anybody can help or point out something that I did incorrectly.,"['indefinite-integrals', 'trigonometry']"
3153566,If zero is an eigenvalue are dimensions lost?,"This is likely a silly question so sorry in advance. However, I am wondering if I am right in thinking that if zero is an eigenvalue, then some dimension must be lost. My understanding is that eigenvectors are the vectors that are only scaled when some matrix A is applied. Then, eigenvalues are the amount those vectors are scaled. So, therefore is it true that if an eigenvalue is zero, that vector has been sent to the origin and therefore the dimension of the image is smaller than the original dimension? Would that not also imply that any vector in the kernel of a transformation is an eigenvector?","['diagonalization', 'linear-algebra', 'eigenvalues-eigenvectors']"
3153652,Principal Part of Laurent Series Converges in Punctured Disc,"I'm trying to work through the following problem: Prove that if the holomorphic function $f$ has an isolated singularity at $z_{0}$ , then the principal part of the Laurent series of $f$ at $z_{0}$ converges in $\mathbb{C}\setminus\{z_{0}\}$ . My Thoughts: If $f$ has the Laurent series expansion $f(z)=\sum_{n=-\infty}^{\infty}a_{n}(z-z_{0})^{n}$ , then the principal part of the Laurent series is $\sum_{n=-\infty}^{-1}a_{n}(z-z_{0})^{n}$ . I'm assuming that I need to break this up to consider all possible types of singularities that could occur at $z_{0}$ (i.e., a removable singularity, a pole, or an essential singularity). If $z_{0}$ is a removable singularity, the principal part of the Laurent series is trivial ( $a_{n}=0$ for all $n<0$ ), so there is nothing to show. If $z_{0}$ is a pole (say of order $k$ ), then $a_{-k}\neq 0$ , but $a_{n}=0$ for all $n<-k$ . Then the principal part is $\sum_{n=-k}^{-1}a_{n}(z-z_{0})^{n}$ . If $z_{0}$ is an essential singularity, then the principal part of the Laurent series has infinitely many non-vanishing terms. Then the principal part is $\sum_{n=-\infty}^{-1}a_{n}(z-z_{0})^{n}$ . My Questions: Am I right in saying that the convergence is trivial in the case that $z_{0}$ is a removable singularity? Also, how would I go about the case where $z_{0}$ is a pole or an essential singularity? Is it some sort of Cauchy-Hadamard argument? Thanks in advance for any suggestions.","['complex-analysis', 'holomorphic-functions', 'singularity', 'laurent-series']"
3153677,A question about the definition of regular surfaces in Manfredo do Carmo's book,"I have a question in Manfredo do Carmo 's book: Differential geometry of curves and surfaces . According to the explanation of definition of regular surfaces, the condition 2 can avoid some kind of ""self-intersection"" which are shown with a figure in the book as the following: However, at any point except those on the line made by the self-intersection, the surface is locally satisfies the definition of regular surface. At any point $p$ on that line, We can define two different differentiable maps x $_1$ , x $_2$ which can parametrize the two pieces of self-intersection respectively. Because the definition of regular surface allows more than one parametrization x for the same point on the surface. It makes we can conclude the above figure is still regular. Therefore, what kind situation of self-intersection of a surface does the condition 2 want to avoid? I can't understand it by myself.",['differential-geometry']
3153692,Smaller neighborhood around the identity of Lie Group,"This is the problem 7-6 of Lee's Introduction to Smooth Manifolds (2nd edition): Suppose G is a Lie group and U is any neighborhood of the identity. Show
  that there exists a neighborhood V of the identity such that $V \subset U$ and $gh^{-1} \in U$ whenever $g, h \in V$ . How do I approach this problem? I tried using the smoothness of $(g,h) \mapsto gh^{-1}$ or the open subgroup generated by $U$ , but it didn't get me anywhere.","['manifolds', 'smooth-manifolds', 'lie-groups', 'differential-geometry']"
3153777,How to find the angle in a protein which is inside of a triangle which appears inscribed in a circle?,"I'm confused at which property or identity can be used to find the angle in a triangle when it looks inscribed in a circle but one of its sides doesn't appear to pass through the center. I'm also confused about the other angles, particularly to the ones which are near the tangent line. The problem is as follows: A certain serum protein is under research for its optical properties
  in a medical laboratory in Taichung. The results shown a circumference
  whose points $A$ , $B$ , $C$ , $D$ and $E$ represent the atoms of the
  protein crystal. In order to find the protein's optical properties a
  technician uses a set of beams which draw lines and form angles in the
  circumference. One beam is tangent to the circumference, while the
  others drawn an angle labeled as $\omega$ which are congruent. What
  would be the angle represented by $\phi$ ? The given alternatives in my book are: $\begin{array}{ll}
1.& 36^{\circ} \\
2.& 45^{\circ} \\
3.& 53^{\circ} \\
4.& 72^{\circ} \\
5.& 108^{\circ} \\
\end{array}$ What I tried to do is to draw the known information in the sketch as shown below. Since the line (beam) is tangent to the circumference, then this should make a $180^{\circ}$ angle with it. So I assumed all the $\omega$ angles cover the whole tangent beam colored with blueberry therefore: $\omega+\omega+\omega+\omega+\omega=180^{\circ}$ $5\omega=180$ $\omega=\frac{180}{5}=36^{\circ}$ Then I traced a chord between $CD$ and from then the other identity which I could identify was that the arc given between $\overset{\frown}{AED}$ covers the angle on $\angle ABD$ and $\angle ACD$ therefore: $\angle ABD = \angle ACD$ Now the part where I'm still doubtful is if there was a way to prove that $\angle ADB = \angle BAD = \angle CDB$ ? The only thing that I could come up with was to establish that the segment $AB = CD$ . But this is which I don't know if its right. By doing this triangle congruence can be used and state that the angles mentioned earlier are the same, but again I don't know if that's right. Assuming that what I did was okay, the rest would be just using the triangle formula for the sum of its interior angles as follows: $2\omega + \phi + \omega = 180^{\circ}$ $3\omega\left(36^{\circ}\right)+\phi=180^{\circ}$ $\phi=180-108=72^{\circ}$ Which correspond to the fourth alternative. But as mentioned I'm not very sure if what I did was the right thing. Therefore. Can somebody help me with this and clear out my doubts?.","['euclidean-geometry', 'algebra-precalculus']"
3153808,Are $c_0$ and $c$ duals of some spaces?,"The (continuous) dual of a normed vector space is always a Banach space, but the converse is not true.  That is, not all Banach spaces are isomorphic to the dual space of some normed vector space.  For instance $L^1$ is not isomorphic to any dual space. My question is, are the sequence spaces $c_0$ and $c$ isomorphic to the duals of any spaces?","['banach-spaces', 'normed-spaces', 'lp-spaces', 'functional-analysis', 'dual-spaces']"
3153815,Kummer sequence etale topology,"Consider the category $C=Sch/S$ of schemes over $S$ and let $n \in \Gamma(S,\mathcal{O}_S)^{*}$ . It is possible to show that $$0 \rightarrow \mu_{n,S} \rightarrow \mathbb{G}_m \rightarrow \mathbb{G}_m \rightarrow 0$$ is exact in the etale topology, where the last map is given by $x \to x^n$ . As an exercise, I should show with a counterexample that this is not true anymore if now does not give the condition $n$ being invertible as a global section. I tried to take $S=Spec(\mathbb{Z})$ and what I was looking for was a scheme $U$ , a section $s \in \mathcal{O}_U(U)$ such that for every etale cover $U_i \to U$ there is no $x \in \mathbb{G}_m(U_i)$ such that $x^m=s|_{U_i}$ . Let's take $U=Spec(A)$ and let's strike to standard etale cover(which should be enough to check). So what I 've got now is $U_i=Spec(A[t]_h/(f))$ for some monic $f$ with $(f,f')= (A[t]_h/(f))$ . Now i tried to take $s=1$ and write down the condition explicitly but I couldn't come up with anything.","['etale-cohomology', 'algebraic-geometry', 'grothendieck-topologies']"
3153845,When is composition of meromorphic functions meromorphic,"When I compose a meromorphic and a holomorphic function, I get a meromorphic function. Are there other cases when a composition of two meromorphic functions is meromorphic? For example, if I compose a holomorphic and a meromorphic function? Or does it hold that the composition is meromorphic in general?","['complex-analysis', 'holomorphic-functions', 'meromorphic-functions', 'function-and-relation-composition']"
3153910,A problem about number of functions and homomorphism,"I'm trying to solve this problem. How many functions $f: \Bbb Z_{10}\rightarrow \Bbb Z_3$ are there such that $|f^{-1}([0]_3)| = 3$ or $|f^{-1}([1]_3)| = 4$ ?
How many of them are such that the restriction to the multiplicative group of $Z_{10}$ is a homomorphism (basically the domain is the multiplicative group of $\Bbb Z_{10}$ and the codomain the multiplicative group of $\Bbb Z_{3}$ ). I start from the assumption that I'm not sure I understood the problem and that I have some difficulties for the second question. Anyway, this is my reasoning. Any help is welcome. Since $|f^{-1}([0]_3)| = 3$ we know that only three elements in $\Bbb Z_{10}$ are associated by the function to $[0]_3$ . So I exclude these three elements since they are already associated and for the definition of function, I can not associate them further. I exclude $[0]_3$ because otherwise if I could associate other elements $|f^{-1}([0]_3)| \neq 3$ . So basically I have now $7$ elements of $\Bbb Z_{10}$ which I can associate to $1,2 \in \Bbb Z_3$ . For this reason, there are $2^7$ possible function. Same reasoning for $|f^{-1}([1]_3)| = 4$ . Is that correct? For the second question, I found online that the number of homomorphism between two cyclic groups is the GCD of their order. First of all, can someone explain to me why the GCD? It is an information that I miss from the study of group theory or that I have neglected.
So I need to know the order of the two multiplicative groups. I use the Euler totient function to do this and I obtain $4$ for the multiplicative group of $\Bbb Z_{10}$ and $2$ for $\Bbb Z_3$ . Now $gcd(2,4) = 2$ so there are two homomorphism (?). Is my reasoning correct?","['group-homomorphism', 'functions', 'abstract-algebra', 'discrete-mathematics', 'group-theory']"
3153922,An example of incompleteness?,"Is it fair to suggest that the fact a base's symbol which would exist in a higher base but is never truly reflected in the base itself is an example(see below) of incompleteness along the ideas of the theorems? My apologies as I'm mostly self-teaching in these areas and feel I've skipped a lot of interim understanding. I don't know logic notation yet so can't follow any raw work. My example would be as follows; In binary, base 2, we only ever feature the numbers 0 and 1 in all our numerical representations. Despite the fact it's base 2 the numerical symbol of 2 itself never actually appears in this system as this is instead 10. Is this an example of the theories of incompleteness? Have I just made a random naive or arbitrary correction or is this a fair conclusion of sorts, if even very simplistic? Thanks in advance.","['number-theory', 'incompleteness', 'logic']"
3153946,Blow up of plane curve is Normalization of local ring?,"I have a question concerning normalizations of plane curves, which I know little about. Consider the simple node $V(f = y^2 - x^3 - x^2)$ . Then $t=y/x$ is integral over $k[x,y]$ so that $(k[x,y]/f) \to k[x,y,t]/\langle y-tx, t^2 - (x+1) \rangle$ is the normalization, where the right ring is the coordinate ring from the blow up after setting $s=1$ . Consequently it is $S^{-1}( k[x,y,t]/\langle y-tx, t^2 - (x+1) \rangle)$ the integral closure of $(𝑘[𝑥,𝑦]/𝑓)_{\langle x,y \rangle}$ , where $S = A \backslash \langle x,y \rangle$ . My question is whether I can generalize this in the following way: Let $A$ be the coordinate ring of an affine irreducible plane curve $c$ , with maximal ideal $\mathfrak{m}$ corresponding to the origin.  Blow up $c$ at the origin and we get a strict transform $s$ with coordinate ring $B$ and a ring homomorphism $A \to B$ . Assume now $s$ is nonsingular at all points lying over the origin, i.e. $B_{\nu_i}$ is regular for all maximal ideals $\nu_1, \ldots, \nu_k$ lying over $\mathfrak{m} B$ . Now let $S = A \backslash \mathfrak{m}$ . Then $S^{-1}B$ is integrally closed, since it is integrally closed at the localization of all maximal ideals. Is it true that the integral closure $\overline{A_{\mathfrak{m}}}$ is isomorphic to $S^{-1}B$ ? If not how are those rings related? My problem is with the cases where I can't see from the equation of $A$ that $t = y/x$ is integral over $k[x,y]$ . Can I maybe make a coordinate transformation such that this is the case. Thank you very much.","['algebraic-curves', 'algebraic-geometry', 'blowup', 'commutative-algebra']"
3153959,Existence of functionals on $L^0$,"Studying a paper about risk measures by F. Delbaen, I bumped into this statement: Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space: if $\mathbb{P}$ is atomless, then there exists no functional $\rho:L^0\to\mathbb{R}$ such that: $\rho(X+a)=\rho(X)-a \quad \forall a \in \mathbb{R},$ $\rho(X+Y)\le \rho(X)+\rho(Y),$ $\rho(\lambda X)=\lambda\rho(X), \quad \forall \lambda>0,$ $X\ge 0 \implies \rho(X)\le 0,$ for every $X\in L^0.$ Here we denote by $L^0$ the linear space of all random variables on $\Omega$ with the metric of the convergence in probability. Then the author assesses that this is a consequence of the analytic Hahn-Banach theorem and of the fact that a continuous functional on $L^0$ must be necessarily null if $\mathbb{P}$ is atomless. Now, I'm full of doubts: first of all I didn't know the statement about the linear functionals on the $L^0$ space: could you give me some reference where to read about it? I tried to google something but didn't find anything. Secondly I didn't really undestand how to use in a clever way the Hahn-Banach theorem: this risk functionals were previously introduced on the space $L^\infty,$ where it is easy to check that they are continuous (wrt to $\|\cdot\|_\infty$ ), so I thought it was natural to use $L^\infty$ as subspace where to use Hahn-Banach, but I don't know which linear functional on $L^\infty$ I shoul use to be sure that it will be continuous on $L^0$ when extended. Any help would be a lot appreciated. Thanks to everybody.","['risk-assessment', 'measure-theory', 'lp-spaces', 'functional-analysis', 'probability']"
3154022,Homeomorphism and equivalent metrics,"Let $d_1$ and $d_2$ be two metrics on a space $M$ such that the metric spaces $(M, d_1)$ and $(M, d_2)$ are homeomorphic to each other. I know that if the identity map is continuous, then metrics are equivalent. However, I am not able to go beyond this. In other words, I can neither prove nor able to produce a counterexample to the statement that homeomorphism between the spaces implies the metrics are equivalent. My definition of equivalence of metrics is there exists $\alpha,\beta$ such that for every $x,y\in M$ , $$\alpha d_1(x,y)\leq d_2(x,y)\leq \beta d_1(x,y).$$ As the spaces are homeomorphic, an open set in one space is open in other. But this may not imply that a $\epsilon$ -ball in one space is a $\delta$ -ball in other. Can someone help me the clarifying this? -- Mike P.S.: Does the situation become different in the case of normed linear spaces?","['general-topology', 'metric-spaces']"
3154040,What is $ \sin(x)+\sin(x−π)+\sin(x+π) $?,So I have this trig question: $ \sin(x)+\sin(x−π)+\sin(x+π) = $ _____ The answer is $- \sin(x)$ I can't figure out how to solve it. Any help?,['trigonometry']
3154056,Strong markov property vs usual markov property.,"I was trying to understand the difference between strong Markov property and the usual Markov property for a discrete number of states. I think I understand why the strong Markov property implies the usual one : We have to consider a deterministic stopping time $T(\omega)=t_0$ , right? But what would be a simple example (like coin toss, dice toss,...) where we have the Markov property but not the strong Markov property?","['stopping-times', 'probability-theory', 'markov-chains', 'random-variables']"
3154128,The quadrature of the circle: comparing Archimedean and Ulam spirals,"There are two closely related arrangements of the natural numbers that allow to show patterns in the distribution of some sets of numbers (multiples of 2, 4, 8, square numbers, prime numbers): the Archimedean spiral and the square spiral ( Ulam -like). [Click here to see an animated transition between these two
  arrangements.] It turns out that some sets of numbers can be better grasped in the Archimedean spiral, others in the Ulam spiral (while this is subjective, I admit). For example, a general pattern in the distribution of Euler's totient function can be slightly better seen in the Archimedean spiral (left) than in the Ulam spiral (right): $\frac{\varphi(n)+1}{n}$ is depicted as shades of gray. The prime numbers in turn – those with $\varphi(n)+1 = n$ – lie slightly more obviously on diagonals of the Ulam spiral than on any lines of the Archimedean spiral: Other sets of natural numbers only look different (but regular in both spirals). For example the even numbers: Or the square numbers: Or the multiplies of 4 and 8: Or the ""crystallographic defects"" when highlighting those numbers with $\varphi(n) + 1 \leq \frac{n}{2}$ — compare with the numbers divisible by $2$ above: Animated transitions for all the examples above can be seen here . For those who want to play around: have a look here . My question is: Which bijective mapping of the plane – considered as $\mathbb{R}^2$ or $\mathbb{C}$ – does the transition from the
  Archimedean to the Ulam spiral correspond to? Furthermore: How can this mapping ""explain"" the commonalities and differences as
  observed above? Addendum : To give you a better feeling how the mapping I'm looking for maps the points of the Ulam spiral to the points of the Archimedean spiral I created a ""stream plot"". The question is: What would be a closed expression for this mapping?","['number-theory', 'conformal-geometry', 'visualization', 'prime-numbers']"
3154141,Solving a system of ODE,"Solve $$\eta_k\frac{d^2C_k}{dz}(z)=-e_k, k = 1,2,3$$ $$C_1(0)=0, C_2(0)=A, C_3(0)=0$$ $$C_1(L)=B, \frac{dC_2}{dz}(L)=0, \frac{dC_3}{dz}(L)=0$$ where $A,B,\eta_k$ some known constant. $e_k, k=1,2,3$ are some functions we do not know the exact form, but we know the values of $e_k$ at the discretization points. The thing bothers me is the right boundary condition for $C_2,C_3$ is the Neumann type. My question is is there any references for solving this kind of equations?
Is there any way I can convert this to a Dirichlet boundary value condition problem? I am thinking about using a shooting type method to convert this into a Dirichlet boundary condition problem, but I do not know if this will work.
I could not find any references for this kind of equations. Any help is appreciated!
Many thanks!","['boundary-value-problem', 'ordinary-differential-equations']"
3154228,$G$ has Kazhdan's property (T) $\iff$ $G$ has a Kazhdan pair,"A locally compact group $G$ is said to be Kazhdan or have Property (T)  if for any unitary representation $\rho$ that has almost invariant vectors (a.i.v) it has an invariant vector. Meaning of a.i.v - for all $K \subseteq G$ compact and $\epsilon > 0$ there exists a $(K, \epsilon)$ invariant vector - $\left\lVert v \right\rVert =1$ such that $$\left\lVert\rho (g)v-v \right\rVert < \epsilon$$ $(K, \epsilon)$ is said to be a Kazhdan pair if for all unitary representations of $G$ that has a $(K, \epsilon)$ invariant vector it has an invariant vector. Apparently $G$ is Kazhdan if and only if it has a Kazhdan pair. It's easy to see that existence of Kazhdan pair implies Kazhdan, but I did not manage to prove the opposite direction. I know that $G$ is compactly generated and that if I can show that $G$ has a $(K,\epsilon)$ invariant vector for all $\epsilon>0$ and for the generating set $K$ then I'm finished, but I don't know haw to choose my $\epsilon$ . I hope I was clear, thank you in advance.","['group-theory', 'functional-analysis']"
3154239,How To Find The Unit Eigenvectors,"I have the matrix $$\begin{pmatrix}3&-9\\-9&27\end{pmatrix}.$$ I found the eigenvalues of $0$ and $30.$ However, when I try to plug in $0$ for the Eigenvalues and row reduce, I get $0,0$ as my solutions for find $x_1$ and $x_2.$ This is not correct and when I tried to do it with the eigenvalue of $30,$ it also came out to $0,0.$ I know to find the unit you have to take the length of $0$ and $30.$ Any help would be appreciated.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3154275,Find all $A$ such that $f(x) = \sum_{n \in A} \frac{x^n}{n!}$ is bounded for $x<0$,"Let $\mathbb{R}_- = \{ x \in \mathbb{R} \mid x \leq 0 \}$ , $\mathbb{N} = \{0,1, 2, ...\}$ . Find all subsets $A \subset \mathbb{N}$ such that the function $f : \mathbb{R}_- \to \mathbb{R}$ , $$f(x) := \sum_{n \in A} \frac{x^n}{n!}$$ is bounded. Note that the function $f$ is defined on $\mathbb{R}_-$ and not all of $\mathbb{R}$ . Moreover $f$ looks like a lot $x \mapsto e^x$ . So one set for which $f$ is bounded is $A = \mathbb{N}$ , as well as $A=\{0\}$ . Moreover we need to find an equilibrium in $A$ in the following sense: if there are too many even numbers $f$ will not be bounded, and if there are too many odd numbers $f$ also can't be bounded. So I think there is a $K \in \mathbb{R}$ such that if we want $f$ to be bounded then the number of even numbers in $A$ is at most $K \times$ the number of odd numbers in $A$ . Thank you.","['power-series', 'limits', 'sequences-and-series', 'real-analysis']"
3154278,Suppose $N\trianglelefteq G$ and $H\leqslant G$. If $\vert G/N \vert$ is prime prove $H\subseteq N$ or $ NH=G$,"Suppose $N\trianglelefteq G$ and $H\leqslant G$ . If $\vert G/N \vert$ is prime prove $H\subseteq N$ or $ NH=G$ I believe I want to make use of this fact that if $H,K\leqslant G$ that $HK=H \iff K\subseteq H$ . So here I would proceed by cases either $H\subseteq N$ or it is not. Case 1 there is nothing to prove. For $H\not\subseteq N$ then $NH\not = H$ but I'm not sure how to proceed from here. I'm thinking something about $N$ being normal should give me a reason that $NH=G$ .","['group-theory', 'normal-subgroups']"
3154285,Definition linear ODE,"An ordinary differential equation is said to be linear if $$F(t,y(t),...,y^{(n)}(t))=0$$ is linear in every derivative. I run into a little problem when using this definition for the equation $$y'y=0$$ because we have that $$F(t,\alpha y_1(t)+\beta y_2(t),y'(t))=(\alpha y_1(t)+\beta y_2(t))y'(t)=\alpha y_1(t)y't(t) + \beta y_2(t)y'(t)\\
=\alpha F(t,y_1(t),y'(t)) + \beta F(t,y_2(t),y'(t))$$ and vice versa for $y'(t)$ . This shows that the ODE is linear. But an equivalent definition of linearity states that it has to have the form $F(t,y(t),...,y^{(n)}(t))=\sum_{k=0}^n a_i(t)y^{(i)}(t) - g(t)=0$ With this definition the ODE is not linear anymore. Not sure what my mistake is there.",['ordinary-differential-equations']
3154301,Is there a name for this class of 'surfaces'? Have they been studied?,"I found a page in one of my notebooks describing a particular class of 'surfaces' which are given by the implicit equations: $$\frac{1}{x}+\frac{1}{y}+\frac{1}{z}=\frac{1}{x+y+z}$$ Or, more generally $$\sum_i \left(a_ix_i+b_i\right)^{-1}=\left(\sum_ia_ix_i+b_i\right)^{-1}\quad:\quad\mathbf{x}\in\mathbb{R}^n$$ I only have notes on $\mathbf{x}\in\mathbb{R}^2,\mathbb{R}^3$ and I'm not sure what the context was at the time I wrote it, but it looks interesting enough and I would like to know more. Do these objects have a name? Have they been studied before? Edit: After working on it for a bit, it occurred to me that in three dimensions this is the same as $$(u_1+u_2)(u_1+u_3)(u_2+u_3)=0\quad:\quad u_i=a_ix_i+b_i$$ Which is a particular case of $$({u_1}^n+{u_2}^n)({u_1}^n+{u_3}^n)({u_2}^n+{u_3}^n)=0$$ For whatever reason, this last bit seems incredibly familiar. I'm not sure why, but it brings to mind something about quaternions, vector norms, and general relativity. Where have I seen this before?","['complex-geometry', 'algebraic-geometry', 'terminology', 'reference-request']"
3154314,Absolutely continuous function not differentiable on uncountable set,"From real analysis one knows that an absolutely continuous function is differentiable a.e.. Is there a function showing that this statement cannot be made into ""every AC function is differentiable except on a countable set of points""?","['absolute-continuity', 'derivatives', 'analysis', 'real-analysis']"
3154337,Yet another difficult logarithmic integral,"This question is a follow-up to MSE#3142989 . Two seemingly innocent hypergeometric series ( $\phantom{}_3 F_2$ ) $$ \sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^2\frac{(-1)^n}{2n+1}\qquad \sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^2\frac{1}{2^n(2n+1)}$$ can be reduced to the logarithmic integrals $$ \int_{0}^{1}\frac{\text{arctanh}(\sqrt{x})}{\sqrt{(1-x)(2-x)}}\,dx,\qquad\int_{0}^{1}\frac{\frac{1-x}{1+x}\log(x)}{\sqrt{x(1+x^2)}}\,dx\tag{A,B}$$ by FL-expansions and Fourier series, or directly by semi-integration by parts. The issue is that neither (A) or (B) seem to be manageable through standard substitutions, the help of computer algebra systems or prayers to special deities, so I hope human beings are able to provide better insights. A promising substitution for (A) is $x=\frac{3-\cosh z}{2}$ .","['integration', 'special-functions', 'polylogarithm', 'sequences-and-series', 'hypergeometric-function']"
3154378,Evaluating a Polynomic-Trigonometric-Hyperbolic Integral,"Within this AoPS thread it is asked to evaluate the following integral $$\mathfrak I~=~\int_0^\infty \frac{x\sin x}{\cos x+\cosh^2 x}\mathrm dx\tag1$$ In order to be precise there is also a possible closed-form conjectured which is given by $$\mathfrak I~=~G-\frac12\tag2$$ But as it is pointed out within the linked thread this seems to be only a reasonable approximation off after the $5$ th decimal digit. I have to admit that it is highly improbable that there exists a nice looking closed-form for $(1)$ since the integrand involves polynomials, trigonometric aswell as hyperbolic functions. I am not even sure how to get started, i.e. which substitution to choose or which technique at all to start with. A related, but perhaps more handable integral, would be the following $$\mathfrak J~=~\int_0^\infty \frac{\sin x}{\cos x+\cosh^2 x}\mathrm dx\tag{1$'$}$$ Out of experience I could imagine that $(1')$ may has a closed-form in terms of known constants $($ or series $)$ since it only contains the two closely connected trigonometric and hyperbolic functions. Is it in fact possible to deduce a closed-form for $(1)$ and $(1')$ ? For myself I cannot offer an approach since everything I tried was not helpful at all hence I was not even able to perform one or two steps in order to simplify the given integrals. I would be glad to see a full solution or even attempts in evaluating $(1)$ and $(1')$ since I have no idea how to deal with such integrands. Thanks in advance! EDIT Out of pure chance I just stumbled upon a related MSE question dealing with the integral $$\int_0^\infty\frac{x\sin^2x}{\cosh x+\cos x}\mathrm dx=1$$ Which on the other hand motivates me to believe that there may be a closed-form for $(1)$ .","['integration', 'definite-integrals', 'closed-form']"
3154380,Every measure on a discrete space is $\Sigma$-finite?,"I was trying to solve the exercise of the book ""E. Cinlar - Probability and Stochastics"" on page 18, No. 3.13 (c) but on the second part I lack ideas. EX.  Let $E$ be a countable set and $\mathcal{E}=2^E$ . Show that every measure, $\mu$ on $(E,\mathcal{E})$ is $\Sigma$ -finite, i.e. there is a sequence $(\mu_n)_n$ of measures on $(E,\mathcal{E})$ such that $\mu=\sum_{n}\mu_{n}$ and every $\mu_{n}$ is finite.","['measure-theory', 'probability']"
3154386,Magnifying glass in hyperbolic space,"My grandmother used to read with a magnifying glass. What (an ideal) magnifying glass does, is basically a homothety: it scales the picture by some factor. Now, in a hyperbolic space there is no such thing as homothety. So, what a person living in a hyperbolic space would do to improve poor vision?","['hyperbolic-geometry', 'geometry']"
3154394,Bounding a polynomial from below,"Let $\sigma >0$ be fixed. For even $k \in \mathbb{N} \cup \{0\}$ , we consider the polynomial \begin{equation}
\varphi_k(x) = \sum_{j=0}^{k} (-1)^j {k \choose j} b_j \, x^{2j} \quad x \in (-1,1),
\end{equation} where \begin{equation}
b_j = \frac{\Big(k+\sigma+\frac12\Big)_j}{\Big(\frac12 \Big)_j}
\end{equation} and for $s \in \mathbb{R}$ , $(s)_j$ denotes the Pochhammer symbol \begin{equation}
(s)_{j}={\begin{cases}1&j=0\\s(s+1)\cdots (s+j-1)&j>0.\end{cases}}
\end{equation} In particular, $\varphi_0(x) =1$ . My question is the following. For $-1 < a < b < 1$ , does there exist $c = c(a, b, \sigma)>0$ such that \begin{equation}
\int_a^b \varphi_k(x)^2 dx \geq c \quad
\end{equation} for any even $k \in \mathbb{N} \cup \{0\}$ ? Unless I am mistaken, a straightforward computation yields \begin{equation}
\int_a^b \varphi_k(x)^2 dx = \sum_{j=0}^k \sum_{\ell=0}^k (-1)^{j+\ell} {k \choose j} {k \choose \ell} \frac{b_j b_{\ell}}{2(j+\ell)+1} \, (b^{2(j+\ell)+1}-a^{2(j+\ell)+1}).
\end{equation} But I do not see how I may bound this double sum from below. Remark 1: I dont know if it is of any use, one may notice that $\varphi_k$ is a hypergeometric function of the form ${}_{2}F_{1}(-k,k+\sigma+\frac12;\frac12;x^2)$ (see https://en.wikipedia.org/wiki/Hypergeometric_function ). Remark 2: Using this interpretation as a hypergeometric function (which terminates), it is in fact possible to relate $\varphi_k$ to the Jacobi polynomials ( https://en.wikipedia.org/wiki/Jacobi_polynomials ): \begin{equation}
\varphi_k(x) = {}_{2}F_{1}(-k,\sigma +\frac12 +k;\frac12; x^2)={\frac {k!}{(\alpha +1)_{k}}}P_{k}^{(-\frac12 ,\sigma )}(1-2x^2).
\end{equation} Perhaps this observation may be of use. Comment : The same question is open for any odd $k \in \mathbb{N}$ , but this time one considers \begin{equation}
\varphi_k(x) = \sum_{j=0}^{k} (-1)^j {k \choose j} c_j \, x^{2j+1},
\end{equation} with $
c_j = \frac{\Big(k+\sigma+\frac32\Big)_j}{\Big(\frac32 \Big)_j} $ . I suspect that the methodology is similar as for the case where $k$ is even.","['special-functions', 'inequality', 'polynomials', 'real-analysis']"
3154403,"Let me assume that the function $f(x,y,z,w)$ is continuous. Is the $\max_{w} f(x,y,z,w)$ continuous?","Let me assume that the function $f(x,y,z,w)$ is continuous. Is the $\max_{w} f(x,y,z,w)$ continuous? Since $f(x,y,z,w)$ is continuous, it is seperately continuous for each $x,y,z,$ and $w$ .","['continuity', 'multivariable-calculus', 'maxima-minima']"
3154464,A sum of a product of binomial coefficients,"I am trying to simplify the following summation of products of binomial coefficients: $$\sum_{k=0}^n \binom{k+b}{a} \binom{y+n-k}{y}$$ where $b > a$ (specifically, $b = 2a+1$ ). I have searched through some of the usual resources (Gradshteyn and Ryzhik, HW Gould, the DLMF, Abramowtiz and Stegun, Wolfram's online resources) and have come up empty so far. If anyone has any ideas on how to approach this problem, I would be very thankful!","['binomial-coefficients', 'combinatorics']"
3154488,"Is there a well known function which has $7, 8, 21$ among its first values?","In other words, function similar to the exponential one or Gamma or anything that has $7, 8, 21$ in its first values (not necessarily $7$ for $x = 1$ ), but say like: $f(x) = 7; $ $f(x + 1) = 8;$ $f(x + 2) = 21;$ where $x$ is natural number, ideally the function should give such results as above for the first numbers: $\{1, \ldots, 10\}$ . Also: the function also produces only natural numbers and other primes, not just $7$ .","['number-theory', 'functions', 'prime-numbers']"
3154576,"The isotropy subgroup of the action of Spin(7) on the Grassmannian G(3,8)","The group Spin $\left( 7\right) \ $ is the universal cover of $SO\left(
7\right) $ and is characterized as the subgroup of $SO\left( 8\right) $ consisting of the automorphisms of the triple cross product $X:\mathbb{R}%
^{8}\times \mathbb{R}^{8}\times \mathbb{R}^{8}\rightarrow \mathbb{R}^{8}$ (see for instance [SW]). In particular, Spin $\left( 7\right) $ acts
canonically on the Grassmannian $G\left( 3,8\right) $ of oriented 3-dimensional subspaces of $\mathbb{R}^{8}=\mathbb{O}$ . We would like to know
the isotropy subgroup $K$ of this action at $1\wedge i\wedge j$ . What we know: Theorem 9.3 in [SW] asserts that Spin $\left( 7\right) $ acts transitively on \begin{equation*}
\{(u,v,w,x)\in \mathbb{R}^{8}\mid u,v,w,X(u,v,w),x\text{ are orthonormal}\}%
\text{.}
\end{equation*} This implies the following: The action of Spin $\left( 7\right) $ on $G\left( 3,8\right) $ is
transitive and so the dimension of $K$ must be $6$ . Given a positively oriented orthonormal basis $w_{1},w_{2},w_{3}$ of $%
1\wedge i\wedge j$ , then there exist $g\in $ Spin $~\left( 7\right) $ satisfying $g\left( 1\right) =w_{1}$ , $g\left( i\right) =w_{2}$ and $g\left(
j\right) =w_{3}$ (we recall that $X\left( 1,i,j\right) =k$ ). On the other hand, we know that the group $S^{3}\times S^{3}\subset
G_{2}\subset $ Spin $\left( 7\right) $ acts on the octonions as follows: \begin{equation*}
\left( u,v\right) \cdot \left( x,y\right) =\left( ux\bar{u},vy\bar{u}\right) 
\text{,}
\end{equation*} where $\left( x,y\right) \in \mathbb{H}\times \mathbb{H}=\mathbb{O}$ (as
sets). This gives us a 4-dimensional subgroup of $K$ given by \begin{equation*}
\left\{ \left( e^{tk},v\right) \mid t\in \mathbb{R},v\in S^{3}\right\}, 
\end{equation*} since conjugation by $e^{tk}$ fixes 1 and rotates the oriented plane $
i\wedge j$ through the angle $2t$ . In particular, if $w_{1}=1$ , $w_{2}=\cos
t~i+\sin t~j$ and $w_{3}=\cos t~j-\sin t~i$ , then $g$ as above can be taken
to be $g\left( x,y\right) =\left( e^{tk/2},1\right) \cdot \left( x,y\right) $ . We would prefer to have the elements of $K$ explicit as linear isometries of $\mathbb{R}^{8},$ but, of course, it would be interesting to us to know the Lie algebra of $K$ as a subset of $o(8)$ or the isomorphism type of $K$ . [SW] D.A. Salamon, T. Walpuski, Notes on the octonions. Proceedings of the Gökova Geometry-Topology Conference 2016, 1--85, Gökova Geometry/Topology Conference (GGT), Gökova, 2017. Also: arXiv:1005.2820
[math.RA]","['octonions', 'differential-geometry']"
3154610,Solve tan(x)+cos(x)=1/2,"Is it possible (not numerically) to find the $x$ such as: $$
tan(x)+cos(x)=1/2
$$ ? All my tries finishes in a 4 degree polynomial. By example, calling c = cos(x): $$
\frac{\sqrt{1-c^2}}{c}+c=\frac{1}{2}
$$ $$
\sqrt{1-c^2}+c^2=\frac{1}{2}c
$$ $$
1-c^2=c^2(\frac{1}{2}-c)^2=c^2(\frac{1}{4}-c+c^2)
$$ $$
c^4-c^3+\frac{5}{4}c^2-1=0
$$",['trigonometry']
3154621,Is it true that the sum of zero mean i.i.d. random variables oscillates around $0$ infinitely often?,"Is this true in general? (Without assuming existence of variance etc.). Only thing we know is that the r.v.s are positive with a non-zero probability and that they are integer valued, integrable with mean 0. Only thing I could come up with was that $S_n/n$ goes to 0 (where $S_n$ is the partial sum). But this can happen even if $S_n$ was always positive. My intuition is that this should be true because it happens with Simple Random Walks (which have a unit step size), and a larger step size should only increase the probability of it becoming negative if it was positive before. I am not sure how to formalize this. Can someone please help?",['probability-theory']
3154663,When is the product of closed sets closed in the product topology?,"I have a specific example below and i think my proof is wrong because it seems too simple, it would work for the general case which I doubt is true.   I would also be interested in the general answer as well; when is the product of closed sets closed in the product topology? Show that the set $ \prod_{\alpha\in\mathbb{R}} \mathbb{N} $ is a closed subset of the topological space $ \prod_{\alpha\in\mathbb{R}} \mathbb{R} $ (endowed with the product topology) My attempt: $\mathbb{N}$ is a closed subspace of $\mathbb{R} $ with the canonical topology. In particular, $\overline{\mathbb{N}}=\mathbb{N}$ .  Also since we are in the product topology, it a known fact that closure of a product is the product of the closures. These 2 facts together mean $$
\overline{ \prod_{\alpha\in\mathbb{R}} \mathbb{N} }= \prod_{\alpha\in\mathbb{R}} \overline{\mathbb{N}} =  \prod_{\alpha\in\mathbb{R}} \mathbb{N} 
$$ Since $ \prod_{\alpha\in\mathbb{R}} \mathbb{N} $ contains its closure, it is closed","['general-topology', 'product-space']"
3154683,L'Hospital's Rule and indeterminate form $\frac{\infty}{-\infty}$,"Suppose I have a limit of the form \begin{align*}
\lim\limits_{x \to -\infty} \frac{x}{e^{x^2}}.
\end{align*} As $x \to -\infty$ , $x \to -\infty$ and $e^{x^2} \to \infty$ . Now, if we were subtracting this limit (suppose, for example, we're evaluating some term in the integration by parts formula from $\infty$ to $-\infty$ ), it doesn't quite matter. We can move constants outside a limit, and can surely move them back in as well. $-x \to \infty$ as $x \to -\infty$ , so that is our $\frac{\infty}{\infty}$ indeterminate form which allows us to apply L'Hospital's rule. But, what if this weren't the case? Is $\frac{\infty}{-\infty}$ an indeterminate form? I suppose I could multiply the limit by $1 = \frac{-1}{-1}$ and pull one of $-1$ 's outside the limit to turn this limit into the form $\frac{\infty}{\infty}$ , though this feels like cheating. I'm really concerned with whether this is valid. I'd appreciate any insights on this.","['limits', 'calculus']"
3154727,Is there a tensor product of $G$-sets?,"We can take the tensor product of two vector spaces, and the tensor product of two modules.  I'm wondering if the same can be done for group actions. Let $G$ be a group which acts on two sets $X$ and $Y$ .  My question is there a definition for the tensor product of $X$ and $Y$ ? If so, what kind of object will it be?  The tensor product of modules need not be a module, it can just be an abelian group.  Similarly, is it possible that the tensor product of $X$ and $Y$ can just be a group rather than another $G$ -set?","['modules', 'abstract-algebra', 'tensor-products', 'group-theory', 'group-actions']"
3154781,Non-Borel set in arbitrary metric space,"Most sources give non-Borel set in Euclidean space. I wonder if there is a way to construct such sets in arbitrary metric space. In particular, is there a non-borel set in $C[0,1]$ all continuous functions on $[0,1]$ where metrics is supremum.","['general-topology', 'functional-analysis', 'measure-theory', 'real-analysis']"
3154786,Find the ratio between the radius and the height,"A coffee filter has the shape of an inverted cone. Water drains out of the filter at a rate of 10 cm $^3$ /min. When the depth of water in the cone is 8 cm, the depth is decreasing at 2 cm/min. What is the ratio of the height of the cone to the radius? So, ${dV \over dt} = -10$ $h=8$ ${dh \over dt}= -2$ Now, $${V}= {1 \over 3} \pi r^2h$$ However, it seems like I am not given enough information. What do I do? I tried: $${dV \over dh} = {2\over 3} \pi r {dr \over dh}$$ However, it feels like I am not given enough information since I don't have ${dr \over dh}$","['related-rates', 'calculus', 'derivatives']"
3154881,An identity for Fourier transform of measure,"Consider a finite Borel measure $\mu$ on $\mathbb R$ . The Fourier transform $\hat{\mu}$ of $\mu$ is defined by $\hat{\mu} (\xi)= \int _{\mathbb R} e^{-ix\xi} d\mu(x)$ . I would like to prove the following identity: $$\lim_{R\to \infty}\frac{1}{2R}\int_{-R}^R {|\hat{\mu}(\xi)|}^2d\xi=\sum_{x\in \mathbb R} \mu({\{x\}}) ^2$$ . My attempt: By Jensen's inequality, $$\int_{-R}^R {|\hat{\mu}(\xi)|}^2d\xi=\int_{-R}^R|\int _{\mathbb R} e^{-ix\xi} d\mu(x)|^2d\xi\leq\int_{-R}^R\int _{\mathbb R} e^{-2ix\xi} d\mu(x)d\xi$$ By Fubini, $$\int_{-R}^R\int _{\mathbb R} e^{-2ix\xi} d\mu(x)d\xi=\int _{\mathbb R}\int_{-R}^R\ e^{-2ix\xi} d\xi d\mu(x)$$ But I don't know how to proceed from here. Any advice will be appreciated.","['fourier-analysis', 'functional-analysis', 'real-analysis']"
