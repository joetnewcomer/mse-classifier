question_id,title,body,tags
652472,Inequalities on kernels of compact operators,"Suppose we have a $\sigma$-finite positive measure $\mu(v)$ on $\Bbb R^d$ and we have two positive kernels on $\Bbb R^d\times \Bbb R^d$ $k_1(v,u)>0$, $k_2(v,u)>0$. We define integral operators
$$K_i[f](v) =\int_{\Bbb R^d}k_i(v,u)f(u)d\mu(u).$$ We know by some external argument that $K_2:L^2(d\mu)\to L^2(d\mu)$ is a compact operator; furthermore, we know that there exist two strictly positive constants $C_+$ and $C_-$ such that $$C_-k_2\le k_1\le C_+k_2.$$ I want to deduce from these conditions that $K_1$ is a compact operator, but I can't see an evident path to prove it. It's possible to show that $K_1$ is bounded by examining negative and positive parts of $f$. It's important to say that neither $k_1$ nor $k_2$ satisfies the Hilbert-Schmidt criterion (i.e. they are not $L^2(d\mu(v)d \mu(u))$). We can additionally suppose that $K_i$ are symmetric. So, is there a way to prove that $K_1$ is compact (or to prove that it can be non-compact)?  Any help will be appreciated.","['operator-theory', 'integral-operators', 'compact-operators', 'functional-analysis']"
652522,Can you prove this recursive multiple $n$-sided dice throwing statement?,"Let $W_{s,r,n}$ be the total number of ways that the sum $s$ can be displayed after throwing $r$ number of $n$-sided dice. Define $$W_{s,0,n} =
\begin{cases}
1,  & \text{if s = 0} \\
0, & \text{if s $\neq$ 0} \\
\end{cases}
$$ for all $s \in \mathbb Z$ and $n \in \mathbb N^*$. Can you prove that $$W_{s,r,n} =W_{s-1,r,n} + W_{s-1,r-1,n} - W_{s-(1+n),r-1,n}$$ for all $s \in \mathbb Z$, $r \in \mathbb N^*$, and $n \in \mathbb N^*$?","['probability', 'recursion', 'number-theory']"
652535,Limit of an integral with changing domain,"I'm trying to figure out the limit : $$\lim_{n\rightarrow \infty} \int_{0}^{\sqrt{n}} \left(1-\frac{x^2}{n}\right)^{\!n}dx$$ Now the problem is that as $n$ rises so does the range of integration, otherwise I could use Dini's theorem to show uniform convergence to $\int_0^{\infty} \mathrm{e}^{-x^2}dx=\frac{\sqrt{\pi}}{2}$, but from what I gather the idea of taking the limit of a sequence of integrals into the integral only works if the domain remains static. My intuition however tells me that I would get $\frac{\sqrt{\pi}}{2}$ as a result, since obviously the expression above would behave almost exactly like  $\int_0^{\infty} \mathrm{e}^{-x^2}dx$ for large enough $n$'s - my problem is hereby with the formality. Thanks a million!","['calculus', 'real-analysis', 'analysis']"
652545,"Jech's axiom of choice, problem 2 first chapter","I have a question stemming from Jech's book on the axiom of choice., chapter 1 exercise 2. We are asked to show that a family of sets of natural numbers has a choice function. Now the version of the axiom of choice we are given in this chapter is the following: let F be a family of sets X. Then there exists an f(X) for every such X in F. I can't decide whether he means the more general countable case, or the more particular finite case. But if finite, I would think he would say so. And it would be an inductive proof. But if countable, I would think he would present the countable axiom of choice (axiom of dependent choice) in that chapter. But he doesn't do that either. The proof I have, for the finite case, is an induction on the cardinality of the family F. Basis: |F| = 1, I.e. There is one set in the family. Since the family is finite, regardless of whether |X| for X in F is countable or finite, we can e.g. order X so that X has a Least element and that element will be the choice function on X (this follows from the fact that there exists a bijection between a finite or countable set and the naturals which are strictly ordered). . Induction step: Suppose claim holds for m, to show m+1. Then F has m choice functions or {f(X1) ... f(Xm)}, as |F| = m. Now let F be a subfamily of F', and suppose for contradiction that F' has no choice function f', with |F'| = m + 1. Now if a choice function f' for F' did exist, it would agree with f for subfamily F, and there is such an f by hypothesis. But this latter contradicts the fact that F' has no choice function at all, and so for no subfamily could there be an f' agreeing with f. . This proof looks like it could be correct to me, but I'm not entirely sure it's adequate for the claim at hand -- I took my best guess and went with it.","['elementary-set-theory', 'axiom-of-choice']"
652550,A function takes every function value twice - proof it is not continuous,"I want to prove the following nice statement I've found: A function $f: [0,1] \rightarrow \mathbb{R}$ takes every function value twice - proof it is not continuous I've already found an answer to my question but one thing is still not clear to my mind. The answer I found was here on math.StackExchange posted by Arthur : Whole post: ""Assume that you have a function $f$ that does take every real value exactly twice. Let $f(a) = f(b) = 0$ with $a < b$. Let $c \in (a,b)$ be given, and assume without loss of generality $f(c) > 0$. Then for every $0 < \epsilon < f(c)$ there exist $d \in (a,c)$ and $e \in (c,b)$ such that $f(d) = f(e) = \epsilon$. So on the intervals $[0,a)$ and $(b,1]$ our function cannot go any higher than zero. That means that $f$ should take every positive real value on the interval $[a,b]$. However the restriction of $f$ to $[a,b]$ is continuous from a closed interval to $\mathbb{R}$ and thus bounded. Contradiction."" Now everything is clear here except for: ""However the restriction of $f$ to $[a,b]$ is continuous from a closed interval to $\mathbb{R}$ and thus bounded. Contradiction."" Well I think know what Arthur is telling there: Because of the boundary there is always at least one function value that can't be taken twice by the function, e.g. just like the peak of $-x^2$. But that is exactly where I was stuck before I started researching that issue. Is it really possible to just say it the way Arthur did? I thought that I'd have to further somehow prove the statement that boundary leads to that contradiction. I hope that it is clear what I was trying to express here... Anyways as always - thank you for your help! FunkyPeanut","['continuity', 'soft-question', 'limits']"
652581,Showing $\frac{x}{1+x}<\log(1+x)<x$ for all $x>0$ using the mean value theorem [duplicate],"This question already has answers here : Intuition behind logarithm inequality: $1 - \frac1x \leq \log x \leq x-1$ (4 answers) Closed 6 years ago . I want to show that $$\frac{x}{1+x}<\log(1+x)<x$$ for all $x>0$ using the mean value theorem. I tried to prove the two inequalities separately. $$\frac{x}{1+x}<\log(1+x) \Leftrightarrow \frac{x}{1+x} -\log(1+x) <0$$ Let $$f(x) = \frac{x}{1+x} -\log(1+x).$$ Since $$f(0)=0$$ and $$f'(x)= \frac{1}{(1+x)^2}-\frac{1}{1+x}<0$$ for all $x > 0$,  $f(x)<0$ for all $x>0$.  Is this correct so far? I go on with the second part:
Let $f(x) = \log(x+1)$. Choose $a=0$ and $x>0$ so that there is, according to the mean value theorem, an $x_0$ between $a$ and $x$ with $f'(x_0)=\frac{f(x)-f(a)}{x-a} \Leftrightarrow \frac{1}{x_0+1}=\frac{ \log(x+1)}{x}$. Since $$x_0>0 \Rightarrow  \frac{1}{x_0+1}<1.$$ $$\Rightarrow 1 > \frac{1}{x_0+1}= \frac{ \log(x+1)}{x} \Rightarrow x> \log(x+1)$$","['inequality', 'logarithms', 'calculus', 'real-analysis']"
652582,Evaluating $\int_{\pi/3}^{\pi/2}\frac{1}{\sin\left(x\right)-\cos\left(x\right)+1} \operatorname dx$,$$\int \limits_{\pi/3}^{\pi/2}\dfrac{1}{\sin\left(x\right)-\cos\left(x\right)+1} \operatorname dx$$ If I try solving this integral with universal substitutions: $$\tan\left(\frac{x}{2}\right)=t;\:\sin\left(x\right)=\frac{2t}{1+t^2};\:\cos\left(x\right)=\frac{1-t^2}{1+t^2};\:dx=\frac{2dt}{1+t^2}$$ $$\implies 2\int \limits_{\frac{\sqrt{3}}{3}}^1 \frac{\left(\dfrac{dt}{ 1+t^2}\right)}{ \left(\dfrac{2t-1+t^2+1+t^2}{1+t^2}\right)} $$ I get: $\displaystyle \int \limits_{\frac{\sqrt{3}}{3}}^1\:\dfrac{dt}{t\left(t+1\right)}$ The final solution reached according to my calculations is: $-\ln\left(\frac{\sqrt{3}}{3}\right)-\left(\ln\left(2\right)+\ln\left(\frac{\sqrt{3}}{3}\right)+1\right)$ That is incorrect taking into account the answer given by Symbolab: $\:\ln \left(\frac{1+\sqrt{3}}{2}\right)$ Could the mistake be the approach or something with the calculations?,"['definite-integrals', 'integration']"
652584,Find a real $2\times 2$ matrix $A$ (other than $A = I$ ) such that $A^5 = I $.,"I found the question in an online a source of challenging linear algebra problems, unfortunately there are no answers. Question: Find a real $2\times 2$ matrix $A$ (other than $A = I$ ) such that $A^5 = I$. I'm beginning to think no such matrix exists, but the way the question is posed it doesn't seem they would pull a trick like that.",['linear-algebra']
652607,Harmonic function as real part of any analytic function,"I denote with $\phi(x,y)$ a hamornic function. I would like to show that $\phi$ is the real part of any analytic function $f(z)$ of the form $$f(z)=2\phi\left(\frac{z+1}{2},\frac{z-1}{2i}\right)-\phi(1,0)+ic$$ where c is a real constant and provided that the RHS exists. My idea was to consider $$g(z,\bar{z})=\phi\left(\frac{1}{2}(z+\bar{z}),\frac{1}{2i}(z-\bar{z})\right)+i\psi\left(\frac{1}{2}(z+\bar{z}),\frac{1}{2i}(z-\bar{z})\right)$$ and set this equal to $f(z)=g(z,\bar{z})$ with $\bar{z}=1$, but is this helpful? Remark: In the end I would like to find an analytic function whose real part is $\tan^{-1}y/x$, my lecture notes states that the obvious function is $-i\log z$ but I do not see why this is so obvious.",['complex-analysis']
652611,Does anyone have a copy of SGA 4?,"It's not on Laszlo's site, although the latest message says that it is indeed going to be published, that was way back in 2010.","['algebraic-geometry', 'reference-request']"
652687,Can one exchange fibre and base space in a fibre bundle?,"The first trivial example of a fibre bundle $E$ is a product bundle $E=F \times B$, with fibre $F$ and base space $B$. Of course in this trivial example, one can exchange base space and fibre and think of the product bundle $E$ as a fibre bundle with fibre $B$ and base space $F$. Under which necessary conditions can one exchange fibre and base space, i.e. regard $E$ as an $F$-bundle over $B$ as a $B$-bundle over $F$? It seems that when one has a flat connection, one ""knows"" how to move from fibre to fibre (that is, from $F_x$ to $F_y$) and makes sure that one ends up in the same place after a small loop. When global loops also end up in the same spot and not on the other side of the fibre (i.e. the holonomy is not just discrete, but trivial), then it looks like given any point in the fibre, one can trace out the base space $B$, i.e. one could interpret $E$ as a $B$-bundle over $F$. So, is a flat $F$-bundle over $B$ with trivial holonomy also a $B$-bundle over $F$? If not, could someone provide a counter-example?","['holonomy', 'fiber-bundles', 'connections', 'differential-geometry']"
652695,Is 'limit' synonymous with 'radius of convergence'?,"I of course read the Wikipedia article , but it sounded like such an abstract idea, that I could interpret only as a limit. The term appeared in a recent lecture apparently out of nowhere (though I was slightly late) - an example the lecturer has now given online makes it seem just like a limit to me (found the radius of convergence by doing a ratio test) but I wonder if there is some distinction in the terminologies, otherwise one wonders why anyone would favour the term over simply 'limit' - perhaps it is a series vs sequence distinction?","['convergence-divergence', 'sequences-and-series', 'limits']"
652696,Prove $x^n$ is not uniformly convergent,"This question pertains to the sequence of functions $f_n(x)=x^n$ on the interval $[0,1]$. It can be shown this sequence of functions ${f_n}$ converges point-wise to the limit $f$ where $f$ is defined by $f(x)=0$ on $[0,1)$ and $f(x)=1$ at $x=1$. However, this sequence of functions ${f_n}$ does not converge uniformly to $f$. One way to prove this (which I have seen) is via a theorem which proves that if a sequence of functions ${f_n}$ converges uniformly to $f$, then $f$ is continuous. And clearly it is not the case that $f$ is continuous in our example, so our convergence is not uniform. However, I have seen another test for uniform convergence on an interval $s$. That is that: $${\rm lim}\ [{\rm sup}\ \{ |  f_n(x)-f(x)|\ :\ x\in S\ \}]=0$$ This conception of uniform convergence can be found in my Walter Rudin analysis book for example. My question is, how can we use this definition of uniform convergence to show $x^n$ is not uniformly convergent? I am having trouble seeing how to apply this definition to this example, especially since the limit $f$ is defined piece-wise. But I know I need to find the sup of the difference between $f_n$ and $f$ over the interval $[0,1]$ (how do I find this sup?). And then once I find it, I need to take the limit as $n\to\infty$ and show it does not equal $0$. Thank you for your help!","['convergence-divergence', 'sequences-and-series', 'uniform-convergence', 'real-analysis', 'analysis']"
652704,Simplifying the sample variance,"Let $Y_1$ and $Y_2$ be i.i.d. R.V.s sampled from a $N(\mu,\sigma^2)$, with $n=2$ it is shown that the sample variance: $$ S^2=\sum_{i=1}^n \frac{(Y_i- \overline Y)^2}{(n-1)} $$ simplifies to $$ S^2=\sum_{i=1}^n (\frac{(Y_1- Y_2)}{\sqrt2})^2 $$ I know this must be a simple question, but I do not understand how if $n=2$, the expression get simplified. Substituting $n=2$ for the first expression just gives: $$ S^2=\sum_{i=1}^n {(Y_i- \overline Y)^2}{} $$ so how do we go from here to the second equation? EDIT I expanded the first equation and now I have: ($Y_2^2-2\bar{Y}Y_2+\bar{Y^2})$ + ($Y_1^2-2\bar{Y}Y_1+\bar{Y_2}$) but I am unable to move forward, any hints or tips would be appreciated :)","['statistics', 'probability']"
652714,How to prove the validity of this argument using rules of inference?,"The premises are: (P $\rightarrow$ J) $\rightarrow$ ($\lnot$C $\rightarrow$ M) $\lnot$J $\rightarrow$ $\space$ $\lnot$P ($\lnot$ J $\land$ E) $\rightarrow$ $\space$ $\lnot$C $\lnot$M $\rightarrow$ $\space$ P The conclusion is: $\lnot$(J $\land$ $\space$ $\lnot$P) $\rightarrow$ C You don't necessarily have to answer the question, but I would like to know whether there is such a thing as being too complex for proving with rules of inference. I believe checking the validity would be much easier with a truth tree. If it can be done with rules of inference, how would I go about doing it? Thanks.","['logic', 'discrete-mathematics']"
652722,Fast calculation for $\int_{0}^{\infty}\frac{\log x}{x^2+1}dx=0$,"I want to show that $\int_{0}^{\infty}\frac{\log x}{x^2+1}dx=0$, but is there a faster method than finding the contour and doing all computations? Otherwise my idea is to do the substitution $x=e^t$, integral than changes to $\int _{-\infty}^{\infty}\frac{t e^t}{1+e^{2t}}dt$. Next step is to take the contour $-r,r,r+i\pi,-r+i\pi$ and integrate over it...","['integration', 'complex-analysis']"
652723,Canonical and terminal singularities,"Let $Y$ be a normal variety such that $K_Y$ is $\mathbb{Q}$-Cartier, and $f:X\to Y$ a resolution of singularities. Then, 
$$
K_X = f^\ast(K_Y) +\sum_i a_iE_i
$$
where $a_i \in \mathbb{Q}$ and the $E_i$ are the irreducible exceptional divisors.  Then the singularities of $Y$ are terminal, canonical, log terminal or log canonical if $a_i > 0, \geq 0, >-1$ or $\geq -1$, respectively. Question: Using this definition, can you give some examples of log terminal singularities that are not canonical and log canonical singularities that are not log terminal? From Reid's ""Young Peron's Guide to Canonical Singularities"" I have nontrivial examples of the first two types: A canonical singularity: Let $Y = \lbrace xz=y^2 \rbrace \subset \mathbb{A}^3$. There is an ordinary double point at the origin, and when we blow up we get a (-2)-curve $E$. By adjunction, $K_X = f^\ast K_Y$, i.e., $a = 0$, so by definition, $Y$ has a canonical singularity. Terminal Singularities: The cone over the Veronese surface has a resolution $X$ with exceptional locus $E\simeq \mathbb{P}^2$. One can show (adjunction again) $K_X = f^\ast K_Y + \frac{1}{2}E$, and so the singularities are terminal but not canonical.",['algebraic-geometry']
652730,Laplacian identity.,"Consider $f$ and $g$ smooth functions. How to prove the following identity: $$\Delta\left(\frac{f}{g}\right)=\frac{1}{g}\Delta f-\frac{2}{g}\nabla\left(\frac{f}{g}\right).\nabla g-\frac{f}{g^2}\Delta g, \ \ \ \ \ g\neq0$$ Thank you very much.","['calculus', 'partial-differential-equations', 'analysis']"
652743,I'm having trouble understanding this derivation,"In my notes I came across an equation: $$\ddot\theta = \frac{\mathrm d\dot\theta}{\mathrm dt} = \frac{\mathrm d}{\mathrm dt}\left(\frac{v\sin(\theta)}{r}\right) = \frac{\dot v \sin (\theta) }{r} + \frac{v\dot \theta \cos(\theta)}{r} - \frac{v\sin(\theta)}{r^2}\dot r$$ The last term doesn't make sense to me. The two terms before that clearly come from the chain rule, but how was the third derived? $v$ here is velocity, and $r$ is radius. If this isn't enough information, even knowing that would be very helpful. Thanks in advance for any help!","['calculus', 'derivatives']"
652752,Show suspension of differentiable n-manifold is (n+1) manifold.,"I've been trying to solve a problem for a while. Let $W$ be an $n$-manifold and $F:M\to M$ be a diffeomorphism. The suspension of $F$ is defined by taking $M\times [0,1]$ and identifying every point $(x,0)\in M$ with $(F(x),1)$, and is denoted $M_F$. Show that $M_F$ is an $(n+1)$-manifold. Here's what I've done so far: Assume $\mathcal{A}=\{(U_\alpha, \varphi_\alpha)\}$ is an $n$-atlas on $M$. I was able to show that $\mathcal{B}=\{(F(U_\alpha),\varphi\circ F^{-1})\}$ is an $n$-atlas on $M$ as well. Given this, the problem comes down to showing that $\{(U_\alpha, \varphi_\alpha)\}$ and $\{F(U_\alpha),\varphi_\alpha\circ F^{-1})\}$ are compatible, but I can't seem to show this. Any help would be great. Thanks.",['differential-geometry']
652786,Number of 'unique' one bit binary functions with N-bit inputs,"Consider the set of binary functions that takes an N-bit input -> 1 bit output.  There are 2^(2^N) elements in this set. Now potentially reduce this set by restricting to only considering functions which have a dependence on every input bit (ie. there is no bit such that inverting the bit on the input never effects the output: there is no bit such that f(x XOR bit)=f(x) for all x). And finally, also define two functions to be equivalent if they differ only by a permutation of the input bits. How large is this equivalence class? I've worked out the first few by hand and found for N=0 there are 2 unique functions, N=1 results in 2 unique functions, N=2 results in 8.  Beyond this I made a computer program which found N=3 gives 68, N=4 gives 3904. I have a feeling that even if one cannot give a simple closed formula, that there is some kind of recursive definition that can give the results.  But I'm not sure how to set it up without accidentally double counting.","['binary', 'combinatorics']"
652789,Does Fermat's Little Theorem work on polynomials?,"Let $p$ be a prime number. Then if $ f(x) = (1+x)^p$ and $g(x) = (1+x)$, then is $f \equiv g \mod p$? I'm trying to prove that for integers $a > b > 0$ and a prime integer $p$, ${pa\choose b} \equiv {a \choose b}.$ To do this I use FLT to show that  $(1+x)^{pa} \equiv (1+x)^a \mod p$ and compare the coefficients of $x^b$ to complete the proof. Am I applying FLT correctly? In general, do most theorems regarding integers/reals generalize to polynomials over the integers/reals? Are there some common pitfalls that I could make when trying to generalize such theorems?","['polynomials', 'algebra-precalculus', 'abstract-algebra', 'number-theory']"
652798,Double Integral Confusion,"A buddy was asking me for help with one of his MV Calc problems, and I ended up getting the same answer as him so I figured I'd ask it here... Question Find $$\iint_{R} (x-1) \, dA$$ where $R$ is the region enclosed by $y=x$ and $y=x^3$ in the first quadrant. So naturally I told him to compute $$\int_{0}^{1} \int_{x^3}^{x} (x-1) \, dy \, dx$$ as $x$ varies from $0$ to $1$ and $y$ from $x^3$ to $x$. Using this integral, we got $\frac{-7}{60}$. His textbook gives an answer of $\frac{-1}{2}$.","['multivariable-calculus', 'calculus', 'integration']"
652820,Prove $\lim_{x \to \infty} f(x) = L \iff \lim_{x \to 0} g(x) = L$,"Let $f(x) = g(1/x)$ for $x>0$. Prove: $\lim_{x \to \infty} f(x) = L \iff \lim_{x \to 0} g(x) = L$ for some $L \in \mathbb{R}$. I assume I am supposed to use l'Hopital's rule in some way (considering that is what section we are in). I've tried looking at the definition of a limit and the sequential criterion for limits, but I have no idea where to go. Just a push in the right direction would be awesome. Thanks in advance.","['real-analysis', 'limits']"
652821,Classifying the singularity of $( e^{\sqrt{z}} - e^{-\sqrt z})/\sin \sqrt{z}$ at zero,"I have a function, $$ \frac{ e^{\sqrt{z}} - e^{-\sqrt z}}{\sin \sqrt z} $$ Does this function have removable singularities? to me it seems like there is a branch point at $z=0$. Thanks for any inputs.",['complex-analysis']
652860,prove that a map $g: M \to N$ is smooth,"Let $A$ be an $n \times n$ orthogonal matrix (that is, the columns of $A$ are perpendicular to one another and have length $1$). Then multiplication by $A$  defines a map $f:\mathbb{R}^n \to \mathbb{R}^n$, which restricts to a map $ f|_{S^{n-1}} := g:S^{n-1} \to S^{n-1}$. Prove that $g$ is smooth. It is not difficult to show that image of the restriction of $f$ is $S^{n-1}$. I know that to prove that a map $g: M \to N$  is smooth, I need to find two charts $(X,u)$ and $(Y,v)$ in the respective atlases of $M$ and $N$, such that $X^{-1}\circ \ g \ \circ \ Y$ be smooth. As $X$ and $Y$, I used stereographic charts from $S^{n-1}$ to $\mathbb{R}^{n-1}$, but it turns out that the composition $X^{-1}\circ \ g \ \circ \ Y$ is not smooth at several points... My calculations Let $\psi_N : S^{n-1} \to \mathbb{R}^{n-1}$ be the stereographic projection, with the formulas $$\psi_N ( x_1 ,..., x_n ) =  ( \frac{x_1}{1- x_{n} },\frac{x_2}{1- x_{n} },...,\frac{x_{n-1}}{1- x_{n} } )$$ And $$\psi^{-1}_N ( y_1 ,..., y_{n-1} ) =  ( \frac{2y_1}{y^2_1 + y^2_2 + ... + y^2_{n-1} +1 },\frac{2y_2}{y^2_1 + y^2_2 + ... + y^2_{n-1} +1 },...,\frac{2y_{n-1}}{y^2_1 + y^2_2 + ... + y^2_{n-1} +1 },\frac{y^2_1 + y^2_2 + ... + y^2_{n-1} -1}{y^2_1 + y^2_2 + ... + y^2_{n-1} +1 } )$$ $A=(a_{ij})$, $\beta_k=\frac{2y_{k}}{y^2_1 + y^2_2 + ... + y^2_{n-1} +1 } \ \ \ (1\leq k \leq n-1)$ and $\beta_n=\frac{y^2_1 + y^2_2 + ... + y^2_{n-1} -1}{y^2_1 + y^2_2 + ... + y^2_{n-1} +1 }$ Now computations regarding $ \psi_N \circ \ g \ \circ \ \psi^{-1}_N$ leads to $$ \psi_N \circ \ g \ \circ \ \psi^{-1}_N ( y_1 ,..., y_{n-1} ) = \left( \frac{\sum^n_{i=1} a_{1i}\beta_i}{1-\sum^n_{i=1} a_{ni}\beta_i},\frac{\sum^n_{i=1} a_{2i}\beta_i}{1-\sum^n_{i=1} a_{ni}\beta_i}, ... , \frac{\sum^n_{i=1} a_{(n-1)i}\beta_i}{1-\sum^n_{i=1} a_{ni}\beta_i} \right)$$
Is this the standard approach ? Can I use something else instead of stereographic charts? Thank you in advance.","['manifolds', 'differential-geometry']"
652875,Why does a multiplicative subgroup of a field have to be cyclic?,"The book ""A First Course in Abstract Algebra"" by Fraleigh says If $G$ is a finite subgroup of the multiplicative group $\langle F^*,\cdot\rangle$ of a field $F$, then $G$ is cyclic. In particular, the multiplicative group of all nonzero elements of a finite field is cyclic. I wonder why that is. Take $a,b\in F$ such that $a^2=b^2=1$. Then $\{1,a,b,ab\}$ is a non-cyclic subgroup of $F$. Where am I going wrong? Thanks in advance!",['abstract-algebra']
652904,Pinching of the eigenvalues in Hamilton's first Ricci flow paper,"This may seem like a crappy question, so I'll be upfront about my motives. I'm reading some sections in Hamilton's first Ricci flow paper, ""Three-manifolds with Positive Ricci Curvature."" In particular, I'm interested in section 10, ""Pinching the eigenvalues."" I'm supposed to present this section of the paper in isolation, but I would like to understand how it is used in the larger context of the paper for my own understanding. My question: Can anyone who happens to know, in as much or as little detail as they like, give a high level summary of how the result of this section is used in the rest of the paper? Any amount of information or perspective would be appreciated.","['ricci-flow', 'differential-geometry']"
652915,"How to show $F(\vec{x})$ is lipschitz on $[0,1] \times [0,1]$","We know that $f(x)=x^2$ is lipschitz on [0,1]; intuitively the steepest the graph of $f$ gets is at $x=1$, and I can find the lipschitz constant by a simple factoring argument. Now say $\theta=(x,y,z)$ and $F(\theta)=(x(x+y+z),0)$. Intuitively, I think this function should be lipschitz as well, but I can't seem to figure out how to prove it. Suppose I'm using the euclidean norm. $||F(\theta)-F(\theta')||= \sqrt{[x(x+y+z)-x'(x'+y'+z')]^2}...$ n.t.s. $...\leq K \sqrt{(x-x')^2+(y-y')^2+(z-z')^2}$ and I can't figure out how to get there. All attempts have failed so far.","['ordinary-differential-equations', 'continuity', 'real-analysis']"
652932,distance between sets in a metric space,"I was given this innocent looking homework question. Given two nonempty sets $A,B \subseteq X$ where $(X,d)$ is a metric space. Show that $\mathrm{dist}(A,B) = \inf \{d(x,y) \mid x \in A, y \in B \}$ is well-defined. Suppose $A \cap B = \emptyset$ . Suppose $A$ is closed and $B$ is compact. Show that $\mathrm{dist}(A, B) > 0$ . Aren't both (1) and (2) properties of the fact that $S = \{ d(x,y) \mid x \in A, y \in B \}$ is a subset of $P = \{ x \mid x \ge 0 \}$ , which is bounded? for (1): $S \subseteq P$ and $P$ bounded implies $S$ is bounded. Hence $\mathrm{inf} S$ exists. Since $\mathrm{inf} S$ is unique, we conclude that $\mathrm{dist}(A, B)$ is well defined. for (2): Since $\mathrm{inf} P \ge 0$ and $S \subseteq P$ , $\mathrm{dist}(A, B) \ge 0$ . Since $A \cap B = \emptyset$ , $x \ne y$ $\forall x \in A, y \in B$ . Then $d(x,y) \ne 0$ . Hence $\mathrm{dist}(A,B) > 0$ . Am I missing something very very obvious? Where does compactness come into play?","['metric-spaces', 'real-analysis']"
652946,"There are $u$ in $W^{1,p}(D)$ and a weakly converging subsequence $\left\{ u_{m_{k}}\right\} $ to $u$.","Let $D$ be a bounded open subset with smooth boundary in $\mathbb{R}^n$,  $p \in (1,\infty)$, and {$u_m$} be a bounded sequence in $W^{1,p}(D)$. Then there are $u$ in $W^{1,p}(D)$ and a 
subsequence {$u_{m_{k}}$} such that {$u_{m_{k}}$} weakly converges to $u$. Help me some hints to start.","['convergence-divergence', 'sobolev-spaces', 'real-analysis', 'analysis', 'functional-analysis']"
652958,Recommendation on studying Smooth Manifold & Differential Geometry and related subjects.,"My major was physics, but i'm changing my major to mathematics this year. I took 2 years off to study mathematics myself and now i'm going back in this year. Here's the list of books i have studied for last 2 years: Elementary Set Theory - Jech (I have studied one more set theory text, but i don't remember its name) Linear Algebra - Friedberg / Linear Algebra - Hoffman & Kunze Principle of Mathematical Analysis - Rudin (Only First 8 Chapters: I have not studied multivariable calculus) Topology - Munkres (Only Point-set-topology, NOT algebraic topology) Real & Complex Analysis - Rudin (First 3 chapters) I'm sure that i have a concrete understanding of books listed above. I really like abstract approach, so i didn't study multivariable calculus since i thought it could be done in differential manifold. (BUT i'm not sure if this is possible to study differential manifold WITHOUT studying multivariable calculus). For example, I really feel comfortable with Measure theory than basic calculus. Here's the course descriptions in my school: Differential Geometry - ""In this course, we understand the theory of curves and surfaces, then we investigate differential and integral calculus on surfaces"" Differential Manifold - "" Linear Algebra, calculus and 1 year analysis are prerequisites to this course "" My questions: is it possible to study differential manifold without studying differential geometry, complex analysis and multivariable calculus? This is a very important question to me.. When i studied RCA-rudin, it's written in the index that ""only first 8 chapters of PMA are enough to start this book"", but frankly it was not. It required concrete understanding of linear algebra and topology.","['soft-question', 'manifolds', 'smooth-manifolds', 'differential-geometry']"
652978,Tricky trignometric integral. Any ideas?,"I have been scratching my head with this integral. Any ideas that I could try?
$$ \int_0^{\pi}\sin(\theta) \cos(\theta)^{n+m}\left(1-a\tan(\theta)\right)^m d\theta$$","['definite-integrals', 'trigonometry', 'integration']"
653016,proving that $\vec{a} \times \vec{b} + \vec{b} \times \vec{c} + \vec{c} \times \vec{a}$ is the normal to the plane.,"$P$, $Q$, and $R$ are points in $ \mathbb{R}^3 $ which are not on the same line. if $\vec{a} = \vec{OP}$, $\vec{b} = \vec{OQ}$, and $\vec{c} = \vec{OR}$, show that  $\vec{a} \times \vec{b} + \vec{b} \times \vec{c} + \vec{c} \times \vec{a}$ is perpendicular to the plane containing $P$, $Q$, and $R$. So far, I have defined: $\vec{a} = <a_1, a_2, a_3>
, \vec{b} = <b_1, b_2, b_3>
, \vec{c} = <c_1, c_2, c_3>
$ The lines spanning between the points a, b, and c. $
\vec{ab} = <b_1 - a_1, b_2 - a_2, b_3 - a_3>
$ $
\vec{bc} = <c_1 - b_1, c_2 - b_2, c_3 - b_3>
$ $
\vec{ca} = <a_1 - c_1, a_2 - c_2, a_3 - c_3>
$ The perpendicular lines to the planes ab, bc, and ca. $
\vec{a \times b} = <a_2b_3 - a_3b_2, a_3b_1 - a_1b_3, a_1b_2 - a_2b_1>
$ $
\vec{b \times c} = <b_2c_3 - b_3c_2, b_3c_1 - b_1c_3, b_1c_2 - b_2c_1>
$ $
\vec{c \times a} = <c_2a_3 - c_3a_2, c_3a_1 - c_1a_3, c_1a_2 - c_2a_1>
$ Adding them I get: $
<a_2b_3 + b_2c_3 + c_2a_3 - a_3b_2 - b_3c_2 - c_3a_2, a_3b_1 + b_3c_1 + c_3a_1 - a_1b_3 - b_1c_3 - c_1a_3, a_1b_2 + b_1c_2 + c_1a_2 - a_2b_1 - b_2c_1 - c_2a_1>
$ Dot-producting the vectors $\vec{ab}$, $\vec{bc}$, and$\vec{ca}$ with the vectors $\vec{a \times b}$, $\vec{b \times c}$, and $\vec{c \times a}$ expands like crazy. What I have been going for so far is that since vectors $\vec{ab}$, $\vec{bc}$, and$\vec{ca}$ make up the plane, if I dot product each one with the cross-product, $\vec{a} \times \vec{b} + \vec{b} \times \vec{c} + \vec{c} \times \vec{a}$, it should result in zero, or at least everything cancelling out since this is supposed to be the perpendicular to the plane. Maybe I'm just tired, but it doesn't seem to be resulting in that. I feel like I'm getting close, but not quite getting the result that I am looking for. What exactly am I missing? Am I going in the right direction even or is there something completely obvious that I am missing?",['multivariable-calculus']
653021,Applications of conformal mapping,"The idea is through conformal transformations satisfying the conditions requested of the problem  make this an easier problem to deal,but i don't know which be this transformation. I would appreciate any hint how to solve this. thank you very much",['complex-analysis']
653054,Question about sup norm,"Let $x \in \mathbb{R}^n$. Define $|x| = \max\{ |x_1|,...,|x_n|\} $. I want to show that this is a norm on $R^n$. This is my reasoning. First, notice $$ |x| = \max\{ |x_i| \} \geq |x_i| \; \forall i ,\;\; |x_i| \geq 0 \implies |x| \geq 0$$ $$ |cx| = \max\{ |cx_i| \} = \max\{ |c||x_i| \} = |c| \max\{ |x_i| \} = |c| |x|$$ $$ |x + y| = \max\{ |x_i + y_i| \} = |x_i +y_i| \; \text{for some i} \leq |x_i| + |y_i|  \leq \max\{|x_i|\} + \max\{|y_i|\} = |x| + |y| $$ Hence, this is indeed a norm on $R^n$. Is this correct? Thanks in advance for your help. Also, I have a bit of trouble seeing if this inequality is true: $$ \max\{ |x_1|,...,|x_n|\} \leq \sqrt{ \sum x_i^2} \leq \sqrt{n} \max\{ |x_1|,...,|x_n|\} $$ Can I show this by induction? Thanks","['calculus', 'normed-spaces', 'proof-verification', 'real-analysis', 'analysis']"
653059,Help with Spivak Calculus Ch3 Problem 6a,"Yet again I find myself stuck on a Spivak question. This time it is simply the question that isn't clear to me. It states: If $x_1, ..., x_n$ are distinct numbers, find a polynomial function $f_i$, of degree $n-1$ which is 1 at $x_i$ and 0 at $x_j$ for $j\neq i$. Hint: the product of all $(x-x_j)$ for $j\neq i$, is 0 at $x_j$ if $j\neq i$. This product is usually denoted by:
$$\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x-x_j)$$ To be honest I don't know where to begin. I understand how to create a polynomial equation for a given set of results but this is quite strange. I'm not sure exactly what the author is expecting. The answer book shows: $$f_i(x)={\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x-x_j)}/{\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x_i-x_j)}$$ Which I have expanded out just fine but don't know what to do with.","['calculus', 'polynomials']"
653068,How to sum the divergent series $1+2+2+3+3+3+\cdots$ and $1+3+2+6+5+4+\cdots$?,"In a different context, I encountered the divergent series $1+2+2+3+3+3+\cdots$, and I was wondering about its summation. Putting $f(x)=1+2x+2x^2+3x^3+3x^4+3x^5+\cdots$, we have $$(1-x)f(x)=1+x+x^3+x^6+\cdots=\frac12 x^{-1/8}\theta_2(0, \sqrt{x}).$$ This doesn't seem to help a lot, but made me wonder: Is there such a thing as ""theta regularisation""? And how to go about the original series? A similar question concerns the ""summing"" of $1+$ $3+2+$ $6+5+4+$ $10+\dots$","['divergent-series', 'sequences-and-series']"
653089,"How to prove all $c_{n},d_{n}$ to be integers if $(n+1)c_{n}=nc_{n-1}+2nd_{n-1}$ and $d_{n}=2c_{n-1}+d_{n-1}$?","Let sequences $(c_n)$ and $(d_n)$ be given by $$c_0=0,\:d_0=1$$ and recursively for $n\ge 1$ by $$\begin{align}
c_n & =\frac{n}{n+1}c_{n-1}+\frac{2n}{n+1}d_{n-1} \\[2ex]
d_n & =2c_{n-1}+d_{n-1}
\end{align}$$ I'd like to show that all $c_{n},d_{n}$ are integers. (Creat by wang yong xi） My try： Since $$\begin{align}(n+1)c_n & =nc_{n-1}+2nd_{n-1}\\[1ex]
d_n & =2c_{n-1}+d_{n-1}
\end{align}$$ we easily find $$c_{1}=1,\:d_{1}=1,\\
c_{2}=2,\:d_{2}=3,\\
c_{3}=6,\:d_{3}=7,$$ a.s.o.   How to prove that all the $c_{n},d_{n}$ are integers?","['recurrence-relations', 'sequences-and-series', 'systems-of-equations']"
653100,Difference between continuity and uniform continuity,"I understand the geometric differences between continuity and uniform continuity, but I don't quite see how the differences between those two are apparent from their definitions. For example, my book defines continuity as: Definition 4.3.1. A function $f:A \to \mathbb R$ is continuous at a point $c \in A$ if, for all $\epsilon > 0$, there exists a $\delta > 0$ such that whenever $|x-c| < \delta$ (and $x \in A$) it follows that $|f(x)-f(c)| < \epsilon$. Uniform continuity is defined as: Definition 4.4.5. A function $f:A \to \mathbb R$ is uniformly continuous on $A$ if for every $\epsilon > 0$ there exists a $\delta > 0$ such that $|x-y| < \delta$ implies $|f(x)-f(y)| < \epsilon$. I know that in Definition 4.3.1, $\delta$ can depend on $c$, while in definition 4.4.5, $\delta$ cannot depend on $x$ or $y$, but how is this apparent from the definition? From what appears to me, it just seems like the only difference between Definition 4.3.1 and Definition 4.4.5 is that the letter $c$ was changed to a $y$. My guess is that the first definition treats $c$ as a fixed point and it is only $x$ that varies, so in this case, $\delta$ can depend on $c$ since $c$ doesn't change. Whereas for the second definition, neither $x$ or $y$ are fixed, rather they can take on values across the whole domain, $A$. In this case, if we set a $\delta$ such that it depended on $y$, then when we pick a different $y$, the same $\delta$ may not work anymore. Is this somewhat a correct interpretation? Anymore clarifications, examples, would be appreciated.","['self-learning', 'real-analysis']"
653106,Is the Cartesian product of two open sets open?,"Just a quick question: If you have two sets $A,B \subset \mathbb{R}$ that are open, that is, for every $p \in A$, there exists an $\varepsilon > 0$ such that $B(p;\varepsilon) \subset A$, is the Cartesian Product of these sets also open? I am trying to think of a proof, but I am stuck rather quickly. So far I have this: Proof: Let $A$, $B \subset \mathbb{R}$ be open sets. Let $C = A \times B$. Since $A$ is open, there exists an $\varepsilon > 0$ such that for all $p \in A$, $B(p;\varepsilon ) \subset A$. Since $B$ is open, there exists an $\varepsilon ' > 0$ such that for all $q \in B$, $B(q;\varepsilon ') \subset B$. In other words, we can make a ball around a point in the $x$ or $y$ direction, but can we also make a ball in both at the same time? Some guidance would be lovely. Thanks in advance!","['general-topology', 'metric-spaces', 'real-analysis', 'product-space']"
653119,Ext -vanishing for sheaves,"For $X$ a smooth, projective variety one has that for two coherent sheaves $\mathcal{F}$ and $\mathcal{G}$, $\mathrm{Ext}^i(\mathcal{F},\mathcal{G})=0$, for $i>>0$. Do we really need projectivity of $X$ or does this hold also for quasi-projective varieties? I somehow feel that smooth is enough...",['algebraic-geometry']
653133,Eigenvalues in orthogonal matrices,"Let $A \in M_n(\Bbb R)$. How can I prove, that 1) if $ \forall {b \in \Bbb R^n}, b^{t}Ab>0$, then all eigenvalues $>0$. 2) if $A$ is orthogonal, then all eigenvalues are equal to $-1$ or $1$","['orthogonal-matrices', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
653141,Finding a general formula for integrating factor,"Consider the following problem: Show that if $\frac{N_x-M_Y}{xM-yN} = R$, where $R$ depends on the quantity $xy$ only, then the differential equation $$M + Ny' = 0$$ has an integrating factor of the form $\mu(xy)$. Find a general formula for this integrating factor. Note that $A_x$ denotes the derivate of the function $A(x, y)$ with respect to $x$. I am familiar with the concept of proving that a differential equation is exact and solving it, and using a given integrating factor to make a differential equation exact. I have considered stating $y'$ explicitly and try to deduct an answer from there, but it doesn't seem like an adequate method.",['ordinary-differential-equations']
653154,"The branching process $\mu^{-n}Z_n = \mu^{-n}\sum_{k=1}^{Z_n{-1}}X_{n,k}$ is a martingale","Let $\{X_{n,k} : n,k \geq 1\}$ be a collection of i.i.d.
  $\mathbb{Z}_+$-random variables with finite variance $\sigma^2 >
 0$ and mean $\mu > 0$. Define $(Z_n)_{n\geq 0}$ recursively by $Z_0 =
 1$ and $$Z_n = \sum_{k=1}^{Z_{n-1}} X_{n,k}.$$ Prove that the process $M$ defined by $M_n = \mu^{-n}Z_n$ is an
   $(\mathcal{F}_n)$-martingale where $\mathcal{F}_n = \sigma(Z_0, \dots,
 Z_n)$. First we show that each $M_n \in \mathcal{F}_n$. This follows trivially since $Z_n \in \mathcal{F}_n$ by construction. How do I show that $M_n \in \mathcal{L}^1$ and the martingale property $$\mu^{-n}Z_n \overset{a.s.}{=} \mu^{-(n+1)}\mathbb{E}[Z_{n+1} | \mathcal{F}_n] ?$$ We have that $$\mathbb{E}|M_n| = \mathbb{E}[M_n] = \mu^{-n}\sum_{k=1}^{Z_{n-1}}\mathbb{E}[X_{n,k}] = \dots ?$$ For the martingale property, $$\mathbb{E}[M_{n+1} | \mathcal{F}_n] = \mu^{-(n+1)} \mathbb{E}[\sum_{k=1}^{Z_n} X_{n+1,k} | \mathcal{F}_n] = \dots ?$$ The main problem is that the $Z_{n}$'s in the index set of the sum confuses me, and I am not sure how to handle these. Any explanation of this problem will be appreciated. After a bit of googling, I found that we should have $\mathbb{E}[Z_n] = \mu\mathbb{E}[Z_{n-1}] = \mu^n$ and $\mathbb{E}[Z_{n+1}|\mathcal{F}_n] = \mu Z_{n}$ but for the same reason as above I do not understand the justification. EDIT So, $$\mathbb{E}[Z_{n}] = \mathbb{E}[\sum_{k=1}^{Z_{n-1}} X_{n,k}] = \sum_{j=1}^\infty\mathbb{P}(Z_{n-1} = j)\sum_{k=0}^{j}\mathbb{E}[X_{n,k}] = \mu\sum_{j=1}^\infty\mathbb{P}(Z_{n-1} = j)j = \mu\mathbb{E}[Z_{n-1}] = \mu^n\mathbb{E}[Z_0] = \mu^n.$$ Still don't get the martingale property. If we apply the same reasoning as above, we should get $$\mathbb{E}[Z_{n+1}|\mathcal{F}_n] = \mathbb{E}[\sum_{k=1}^{Z_{n}} X_{n+1,k} | \mathcal{F}_n] = \sum_{j=1}^\infty \mathbb{P}[Z_n = j]\sum_{k=0}^j \mathbb{E}[X_{n+1, k} | \mathcal{F}_n] = \overset{?}{\cdots} = \mu Z_{n}$$","['probability-theory', 'stochastic-processes', 'martingales']"
653159,"If $A$ is positive definite, then $\int_{\mathbb{R}^n}\mathrm{e}^{-\langle Ax,x\rangle}\text{d}x=\left|\det\left({\pi}^{-1}A\right)\right|^{-1/2}$","Let $A$ be a positive definite real $n\times n$ matrix. How can I prove that
$$
\int_{\mathbb{R}^n}\mathrm{e}^{-\langle Ax,x\rangle}\text{d}x=\left|\,\det\left(\pi^{-1}{A}\right)\right|^{-1/2}=\pi^{n/2}\lvert\,\det A\rvert^{-1/2}\!,
$$ where $\langle\cdot,\cdot\rangle$ denotes the inner product in $\mathbb R^n$, i.e. $\langle x,y\rangle =x^Ty$.","['integration', 'matrices', 'real-analysis', 'normal-distribution', 'determinant']"
653178,Is $\cos(x^2)$ the same as $\cos^2(x)$? [duplicate],"This question already has answers here : What are the meanings of $\operatorname{trig}(x)^n$ and $\operatorname{trig}^n(x)$? (4 answers) Closed last year . I want to know something about trigonometrical functions, is $\cos(x^2)$ the same as $\cos^2(x)$ ?",['trigonometry']
653226,Variance of sum of square differences corrupted by noise,"I've been trying to extend a proof I have for a univariate function $f(x)$ to a
multivariate function $f(x,y)$ but the result I get looks weird. I'm wondering
whether there is a mistake in any step I'm making. The background is that $f(x,y)$ is an image that is superimposed with some
gaussian noise $n\sim\mathcal{N}(0,\sigma^2)$. This image is shifted by a true
but unknown offset $d_x$ and $d_y$ and the goal is to find an estimate $(\Delta
x,\Delta y)^\mathsf{T}$ for this offset and to estimate its variance. This leads
to the following expression that is to be minimized: $$
e(\Delta x,\Delta y) = \iint \left(f(x-d_x+\Delta x+\lambda, y-d_y+\Delta y+\eta) - f(x+\lambda,y+\eta) + n_1(x+\lambda,y+\eta) - n_0(x+\lambda,y+\eta)\right)^2\text{d}\lambda\text{d}\eta
$$ I am computing the second order taylor expansion around $d_x=\Delta x$ and
$d_y=\Delta y$. This yields $$
a(\Delta x - d_x)^2 + b(\Delta y - d_y)^2 +\\ c(\Delta x - d_x)(\Delta y - d_y) + d(\Delta x - d_x) + e(\Delta y - d_y) + f
$$ where \begin{eqnarray*}
a \approx \iint f_{xx}(x+\lambda,y+\eta)^2\text{d}\lambda\text{d}\eta\\
b \approx \iint f_{yy}(x+\lambda,y+\eta)^2\text{d}\lambda\text{d}\eta\\
c \approx \iint 2 f_{x}(x+\lambda,y+\eta)f_y(x+\lambda,y+\eta)\text{d}\lambda\text{d}\eta\\
d = \iint 2(n_1(x+\lambda,y+\eta)-n_0(x+\lambda,y+\eta)f_x(x+\lambda,y+\eta)\text{d}\lambda\text{d}\eta\\
e = \iint 2(n_1(x+\lambda,y+\eta)-n_0(x+\lambda,y+\eta)f_y(x+\lambda,y+\eta)\text{d}\lambda\text{d}\eta\\
f = \iint (n_1(x+\lambda,y+\eta)-n_0(x+\lambda,y+\eta)^2 \text{d}\lambda\text{d}\eta
\end{eqnarray*} Subscripts denote partial derivatives. The second order partial derivative terms  have been omitted in the formula above. This is the only step I don't feel very comfortable with, but it is also done in the original, univariate proof. Note that $a$, $b$ and $c$ are constants and only $d$, $e$ and $f$ are random variables. The vertex of this paraboloid -- if it exists -- is found by the equating the partial derivatives of the paraboloid to 0, which results in $$
\Delta x - d_x = -\frac{2bd-ce}{4ab-c^2},\;
\Delta y - d_y = -\frac{2ae-cd}{4ab-c^2}\;.
$$ I am interested in the variance of the estimate, $$
\text{Var}\left(\begin{pmatrix}\Delta x\\\Delta y\end{pmatrix}\right) = \text{Var}\left(\begin{pmatrix}d_x\\d_y\end{pmatrix} - \begin{pmatrix}\frac{2bd-ce}{4ab-c^2}\\\frac{2ae-cd}{4ab-c^2}\end{pmatrix}\right) = 
\text{Var}\left(-\begin{pmatrix}\frac{2bd-ce}{4ab-c^2}\\\frac{2ae-cd}{4ab-c^2}\end{pmatrix}\right)
$$ In the next few steps, I will use $\text{Var}(AX)=A\text{Var}(X)A^\mathsf{T}$ repeatedly. First I pull out the denominator: $$
\text{Var}\left(\begin{pmatrix}\Delta x\\\Delta y\end{pmatrix}\right) = 
\frac{1}{\left(4ab-c^2\right)^2}\text{Var}\left(\begin{pmatrix}2bd-ce\\2ae-cd\end{pmatrix}\right)
$$ Then I put back the definitions of the polynomial coefficients. I'm using a short-hand notation here where I omit the function arguments and abbreviate $n_1(x+\lambda,y+\eta)-n_0(x+\lambda,y+\eta)$ with $\delta n$. $$
\text{Var}\left(\begin{pmatrix}\Delta x\\\Delta y\end{pmatrix}\right) = 
\frac{1}{\left(4\iint f_{xx}^2\iint f_{yy}^2 - 4(\iint f_{xy})^2\right)^2}\text{Var}\left(\begin{pmatrix}4\iint f_{yy}^2\iint f_{x}\delta n-4\iint f_{xy}\iint f_{y}\delta_n\\4\iint f_{xx}^2\iint f_{y}\delta n-4\iint f_{xy}\iint f_{x}\delta n\end{pmatrix}\right)
$$ Now I decompose the matrix and pull it out of the variance. $$
\text{Var}\left(\begin{pmatrix}\Delta x\\\Delta y\end{pmatrix}\right) = 
\frac{1}{\left(4\iint f_{xx}^2\iint f_{yy}^2 - 4(\iint f_{xy})^2\right)^2}\text{Var}\left(4\begin{pmatrix}\iint f_{yy}^2 & -\iint f_xf_y \\ -\iint f_xf_y & \iint f_{xx}^2\end{pmatrix}\begin{pmatrix}\iint f_x\delta_n\\\iint f_y\delta_n\end{pmatrix}\right)=
\frac{16}{\left(4\iint f_{xx}^2\iint f_{yy}^2 - 4(\iint f_{xy})^2\right)^2}\begin{pmatrix}\iint f_{yy}^2 & -\iint f_xf_y \\ -\iint f_xf_y & \iint f_{xx}^2\end{pmatrix}\text{Var}\left(\begin{pmatrix}\iint f_x\delta_n\\\iint f_y\delta_n\end{pmatrix}\right)\begin{pmatrix}\iint f_{yy}^2 & -\iint f_xf_y \\ -\iint f_xf_y & \iint f_{xx}^2\end{pmatrix}
$$ Then I proceed similarly for the remaining integral: $$
\text{Var}\left(\begin{pmatrix}\Delta x\\\Delta y\end{pmatrix}\right) = 
\frac{32\sigma^2}{\left(4\iint f_{xx}^2\iint f_{yy}^2 - 4(\iint f_{xy})^2\right)^2}\begin{pmatrix}\iint f_{yy}^2 & -\iint f_xf_y \\ -\iint f_xf_y & \iint f_{xx}^2\end{pmatrix}\begin{pmatrix}\iint f_x\\\iint f_y\end{pmatrix}\begin{pmatrix}\iint f_x\\\iint f_y\end{pmatrix}^\mathsf{T}\begin{pmatrix}\iint f_{yy}^2 & -\iint f_xf_y \\ -\iint f_xf_y & \iint f_{xx}^2\end{pmatrix}
$$ Now here is the problem: I would expect the solution $$
\text{Var}\left(\begin{pmatrix}\Delta x\\\Delta y\end{pmatrix}\right) = 
\frac{k\sigma^2}{\iint f_{xx}^2\iint f_{yy}^2 - (\iint f_{xy})^2}\begin{pmatrix}\iint f_{yy}^2 & -\iint f_xf_y \\ -\iint f_xf_y & \iint f_{xx}^2\end{pmatrix}
$$ where $k$ is some constant. This could be achieved if the square in the denominator would cancel out with the first three matrices. However it does not, I always get these cross-terms. Hence I am wondering whether there is any mistake in my derivation, or alternatively if I could use some approximation that escapes me to get the desired result. Thank you very much!","['statistics', 'probability', 'probability-theory']"
653235,prove that a function is an immersion,"How I can show that $F \colon \mathbb{R} \to \mathbb{R}^2$ defined by $F(t)= (\cos (t), \sin(t))$ is an immersion? In my definition $F$ is an immersion if $\forall p$,$dF_p$ is injective.
I have compute $dF_p=(-\sin (t), \cos(t))$. But now?","['differential-topology', 'differential-geometry']"
653240,Variance of Time-Integrated Ornstein-Uhlenbeck Process,"I'm attempting to filter white noise from a deterministic, finite-power signal using a low-pass filter. This filter can be described using an exponentially-decaying response function: $$ h(t) = \gamma \exp (-\gamma t) $$ Evaluating the Wiener integral for the filtered noise results in a zero-mean Ornstein-Uhlenbeck process, whose variance is: $$\sigma^2_{OU}  =\frac{\gamma}{2}\left( 1-\exp(-2\gamma t)\right)$$ The task now is to find the variance of the time-integrated process. My question is whether the following procedure, based on Wiener integrals, is correct, and if not, what is the correct procedure? First, we use the fact that Gaussian random variables are determined by their means and variances to express the zero-mean OU process as the product of a deterministic function and a Wiener process: $$ \sigma^2_W = t \quad \therefore \quad \sigma^2_{F\times W} = F^2(t)\times t $$
$$ F(t) = \frac{\gamma}{2} \sqrt{\frac{1-\exp(-2\gamma t)}{t}} \quad \rightarrow \quad \sigma^2_{F\times W} = \sigma^2_{OU}$$ We perform integration by parts: $$ \int_0^t W(\tau)F(\tau)d\tau = \left. \left[W(\tau)\int_{0}^{\tau}F(\tau ')d\tau ' \right] \right \vert_0^t - \int_0^t \left( \int_{0}^{\tau}F(\tau ')d\tau ' \right)dW(\tau)$$ Labelling $\int_{0}^{\tau}F(\tau ')d\tau '$ as $\tilde{F}(\tau)$, we write the variance of the integrated process as the sum of the variances of the two terms above. The variance of the left term is $ \tilde{F}^2(t)\times t$, since this is just the Wiener process, multiplied by a deterministic function. The term on the right is a Wiener integral, whose variance is $\int_0^t \tilde{F}^2(t) dt$. I'll leave $\tilde{F}(t)$ unspecified here, since the integral is difficult. So, have I made some error in deriving the variance?","['stochastic-calculus', 'stochastic-processes', 'stochastic-integrals', 'probability']"
653243,How to verify that this is a submanifold,"Let $ g: \mathbb{R}^2 \to \mathbb{R}^2 $ , $ g (x, y) = (x^2-y^2, y) $ be a differentiable map. Let $ r $ the line passing through $(1, 0) $ parallel to the $ y-$axis. Prove that $ g^{-1}(r) $ is a submanifold of $ \mathbb{R}^2 $ I don't have many instruments to prove this fact, and the only theorem which involves the inverse of a differential function is this one: Theorem: Suppose $ X, Y $ are manifolds and $ f:X \to Y $ a differentiable map. Let $ y \in Y $. If $ f $ is a submersion at each point of $ f^{-1}(y) $, then $ f^{-1}(y) $ is a submanifold. I think this is the result to use, but $ r $ is not a point of $\mathbb{R}^2 $, so I don't know whether i can use the theorem. Maybe there is something else to use, but these are my first exercises involving manifolds so I don't have much practice.","['manifolds', 'differential-geometry']"
653264,Proving the area of a square and the required axioms,"I recently realized the area formula of all polygons, and most basic figures can be proven from the areas of square and rectangle. For example if we know the area of rectangle, we can the area formula of parallelogram, then triangle and so on. That brings us to the question how to prove that the area of the square with side $a$ is $a^2$. I just came upon ProofWiki article ( http://www.proofwiki.org/wiki/Area_of_Parallelogram/Rectangle ), which showed me to get the area of rectangle from that of the square, which completes the rest of the link. But the square? I see that for such a basic figure we need some axioms to get our foot down. One that I think is absolutely essential that that of a square of $1$ units has an area of $1$ unit square, from which we can generalize to bigger squares. Another I think which we used in the rectangle proof that, if a figure $A$ is divided into different pieces then the area of $A$ is the sum of the area of the different pieces. So my first question: what set of axioms are needed that best and unambiguously describe the area of figures? Anyway, the one informal proof we are show in primary schools, that divided for example a $5 \cdot5
$ square into $25$ pieces of $1$ cm$^2$ (intuitively very plausible) fails to convince me. Somehow, we may generalize it to rational numbers, but what if the side is $\pi$? We cannot keep dividing it infinitely many times. So the second question: How do we using the axioms find the area of the square? And is there any gap, when we move forward, for example with the rectangle? Thanks.","['geometry', 'area']"
653265,Two functions that are derivatives of each other,Is there a pair of functions such that: $D f(x) = g(x)$ $D g(x) = f(x)$ The functions are not the same function (without this 0 and $e^x$ would work) In case that there isn't such pair of functions: What is the proof that such pair of functions can't exist?,"['derivatives', 'functions']"
653333,Absolute continuity preserves measurability,"In studying absolutely continuous function, I knew that if $f:[a,b]\to\mathbb{R}$ is absolutely continuous, then $f(N)$ has measure zero if $N$ is, and $f(E)$ is measurable if $E$ is.
Suppose continuous function $f:[a,b]\to\mathbb{R}$ is such that if $E$ is measurable, then $f(E)$ is measurable. Then does it follow that if $N$ has measure zero, then $f(N)$ has measure zero?","['measure-theory', 'real-analysis']"
653338,Prime ideals and sagbi bases,"I'm trying to understand the following passage in Combinatorial Commutative Algebra by Miller and Sturmfels: If $R$ is any subalgebra of a polynomial ring that possesses a finite sagbi basis, then this sagbi basis defines a flat degeneration from $R$ to its initial algebra in($R$). The initial algebra is generated by monomials, so it corresponds to a toric variety. Hence, geometrically, a finite sagbi basis provides a flat family connecting the given variety Spec($R$) to the affine toric variety Spec(in($R$)) - Chapter 14.3, Page 281. I'm sadly a bit naive about algebraic geometry so my main question is about the last sentence: Does it imply that if $P$ is a prime ideal of $R$, then in$(P)$ is a prime ideal of in$(R)$? I haven't been able to prove that statement using just the usual definitions of the terms involved, and, honestly, it seems too good to be true, but hopefully someone out there has some insight. If it's not true in general, are there any known non-trivial cases in which it holds?","['algebraic-geometry', 'groebner-basis']"
653366,Integral Using Harmonic Functions,"Evaluate the integral: $$\int^{2 \pi}_0 \dfrac{\cos^2 \theta}{|2e^{i\theta}-z|^2} \, d \theta \qquad \mbox {when} \, |z| \neq 2.$$ Now, I thought about trying to change this to look like a Poisson Kernel: $$ \dfrac{\zeta +z}{\zeta-z} = \Re \left(\frac{|\zeta|^2-|z|^2}{|\zeta-z|^2}\right).$$ That way, I can use the Mean Value Property. But I am having no luck there. Any suggestions?","['residue-calculus', 'integration', 'definite-integrals', 'complex-analysis', 'contour-integration']"
653371,When does the difference between a vector bundle and the associated frame bundle matter?,"In the comments to this question How a principal bundle and the associated vector bundle determine each other , it was remarked that while there is a bijective correspondence between rank $n$ vector bundles with structure group $GL(n,\mathbb{R})$ and principal $GL(n,\mathbb{R})$ bundles, there are situations in which working with one or the other is not equivalent. I would like to understand why is this the case.","['fiber-bundles', 'principal-bundles', 'vector-bundles', 'differential-geometry']"
653378,"Show, there exists exactly one operator with $\int_A P_T(f)\, d\lambda=\int_{T^{-1}(A)}f\, d\lambda$","Let $T\colon\mathbb{R}\to\mathbb{R}$ be a non-singular function, i.e. a measurable function with the property that
    $$
\forall A\in\mathcal{B}: \lambda(A)=0 \implies \lambda(T^{-1}(A))=0.
$$
    Show: There exists exactly one linear operator  $P_T\colon L_{\lambda}^1\to L_{\lambda}^1$ so that for all $f\in L_{\lambda}^1$ and all $A\in \mathcal{B}$ it is
    $$
\int_A P_T(f)\, d\lambda=\int_{T^{-1}(A)}f\, d\lambda.
$$ Hello, I would really prefer to present you my own recent ideas but I do not have own ideas. To be honest, I am rather helpless. Can you pls give me help? Greetings. math12 New Edit : The only thing I already know is that $A\mapsto\int_{T^{-1}(A)}f\, d\lambda$ is a signed measure. Now one can apply Radon-Nikodým or something like that?",['measure-theory']
653412,Area under parabola using geometry,"We have to find the area of the pink region. As we all know this can be evaluated using limiting its Riemann sum, of which its a standard example. However I want to know if this can be done without using calculus, with directly using geometry. I think it would be very interesting challenge, but I am not able to think of a way out.","['definite-integrals', 'geometry', 'conic-sections', 'area']"
653416,Metric space and continuous function,"Background: This is an exercise problem from Munkres's Topology (Exercise 3 of Section 20 ""The Metric Topology"", 2nd edition). It has been posted at this site: Topology induced by metric space . However, I am confused about some basic conceptual problems which have not been mentioned there. The Exercise: Let $X$ be a metric space with metric $d$. (a) Show that $d: X \times X \to \mathbb{R}$ is continuous. (b) Let $X'$ denote a space having the same underlying set as $X$. Show that if $d: X' \times X' \to \mathbb{R}$ is continuous, then the topology of $X'$ is finer than the topology of $X$. I am quite confused about the underlying concepts in the exercise: Problem: (1) Why to use the word ""if"" in (b) (i.e., if $d: X' \times X' \to \mathbb{R}$ is continuous), since that any metric $d$ has been proved continuous in (1)? (2) In (b), are $X$ and $X'$ both metric spaces? If so, what are their metrics, respectively? If not, how to compare two topologies if one is a metric space while the other one not?","['general-topology', 'metric-spaces']"
653433,How to divide solutions of system of ODE,"If I have the following system of ODEs:
\begin{align}
F'_1=aF_1+bF_2 \nonumber\\
F'_2=-bF_1+cF_2 \nonumber
\end{align}for which I know the solutions of $F_1$ and $F_2$ as sums of exponential of eigenvalues. My question is can I find an ODE for $z=\dfrac{F_1}{F_2}$ . I want this so that I can find the following integral $$\int_{t_0}^t\dfrac{F_1(s)}{F_2(s)}ds$$ explicitly.","['dynamical-systems', 'ordinary-differential-equations', 'integration', 'definite-integrals', 'systems-of-equations']"
653473,Closest Pair between 2 sets of powers,"Assume $a$ and $b$ are natural numbers, $A=\{a,a^2,a^3,\cdots\}$ and $B=\{b,b^2,b^3,\cdots\}$, find $\min\left|a_i-b_j\right|$ where $a_i\in A$ and $b_j\in B$. For example, if $a=3$, $b=10$, then $\min\left|a_i-b_j\right|=\left|3^2-10^1\right|=1$. Variation: what if $a$ and $b$ are both prime numbers?","['optimization', 'sequences-and-series', 'number-theory']"
653504,Christoffel Symbols as Tensors,"If you define a ""generalized"" Christoffel tensor as the following: $Chris(\omega; u, v) := (\nabla_u(\omega))(v) - (\tilde{\nabla}_u(\omega))(v)$ where $\omega$ is a dual vector, $u,v$ are vectors, and $\nabla$ and $\tilde{\nabla}$ are two covariant derivatives, then is $Chris$ a tensor field if you take $nabla$ to be the metric covariant derivative and $\tilde{\nabla}=\mathcal{L}$ to be the lie derivative? (as opposed to the Christoffel symbol not being a tensor when $\tilde{\nabla}$ is the ordinary partial derivative $\partial$) I guess also with $\tilde{\nabla}=\partial$, $Chris$ is a tensor (a multinear map from duals and vectors to the reals), but some people insist on defining a tensor as something that transforms in a certain way under a change of charts. I guess my question is then will it ""transform like a tensor"" in this case?",['differential-geometry']
653507,Proof that $\omega^\omega$ is completely metrizable and second countable,"I have almost solved the following problem but am stuck at the very end, can you help me finish it? Thank you for your help. Let $n<\omega$ and $t\in {}^n\omega$. We define $U_t=\{s\in {}^\omega\omega : t\subseteq s\}$. The family
  $\mathcal B=\{U_t : t\in\bigcup {}^n\omega\}$ is a basis for a topology $\tau$ on ${}^\omega\omega$. This means that a set $X$
  is in $\tau$ if and only if $X$ is a union of elements of $\mathcal B$. EXERCISE 50 (PG): Show that $\langle {}^\omega\omega,\tau \rangle$ is a second countable completely metrizable space. Hint: For $r,s\in {}^\omega\omega$ such that $r\ne s$, the $\varrho(r,s)=1/\min\{n : r(n)\ne s(n)\}$. Moreover, let $\varrho(r,r)=0$. 
  Show that $\varrho$ is a complete metric on ${}^\omega\omega$ that induces the topology $\tau$. (i) Second countable: the set of $n$-tuples is countable since it is a finite union of countable sets. (ii) complete with respect to $$ d(f,g) = \frac{1}{\min \{n \mid f(n) \neq g(n) \}}$$
Let $f_k$ be a Cauchy sequence. This means that the index at which $f_k, f_i$ differ gets larger as $i,k$ get larger. Let $f(n)$ denote the pointwise limit, that is, $\lim_{k \to \infty} f_k(n)$. Then $f(n) \in \omega$ for every $n$ since $f_k(n)$ is eventually constant. Hence $f \in \omega^\omega$. (iii) $d$ induces the same topolgy as $U_t$: $\tau_t \subset \tau_d$: Let $s \in U_t$. Then $B(s, \frac{1}{n+1})$ is an open ball contained in $U_t$ hence $U_t$ is open in $\tau_d$. $\tau_t \supset \tau_d$: Let $B(s, \frac{1}{k})$ be an open balls. If $k < n$, $s \in U_s \subset B(s, \frac{1}{k})$. But if $k \ge n$ then I'm stuck. The ball $B(s, \frac{1}{k})$ consists of all sequences that agree with $s$ on the first $k$ coordinates. So it is quite small. How do I make the $U_t$ small enough to fit in this ball? I have thought of intersection but since I'm only allowed to do finite intersections I don't see what to do.","['general-topology', 'metric-spaces', 'functional-analysis', 'the-baire-space']"
653512,Prove $(\vec A \times \vec B) \cdot (\vec C \times \vec D) = (\vec A \cdot \vec C)(\vec B \cdot \vec D) - (\vec A \cdot \vec D)(\vec C \cdot \vec B)$,"Prove that $(\vec A \times \vec B) \cdot (\vec C \times \vec D) = (\vec A \cdot \vec C)(\vec B \cdot \vec D) - (\vec A \cdot \vec D)(\vec C \cdot \vec B)$. The problem asks to prove this only using the properties: $
\text{(i)}\space (\vec a \times \vec b) \times \vec c = (\vec a \cdot \vec c)\vec b - (\vec b \cdot \vec c)\vec a \\
\text{(ii)}\space \vec a \times (\vec b \times \vec c) = (\vec a \cdot \vec c)\vec b - (\vec a \cdot \vec b)\vec c \\
\text{(iii)}\space \vec u \cdot (\vec v \times \vec w) = \vec v \cdot (\vec w \times \vec u) = \vec w \cdot (\vec u \times \vec v) = -\vec u \cdot (\vec w \times \vec v) = -\vec w \cdot (\vec v \times \vec u) = -\vec v \cdot (\vec u \times \vec w)$ I've tried manipulating the left hand side in all the ways I could think of, and I can't seem to reach the right hand side. Can someone please point me in the right direction?",['multivariable-calculus']
653519,Interesting first order ODEs in applied science,"I'm teaching first and second order ODEs this term and would like some nice examples that are easy enough to solve. I have plenty of second order ODEs, e.g. simple/damped/driven harmonic motion. As for first order ODEs, I have alreay used the following: $M' = - kM$ (nuclear half-life) $\theta' = -k(\theta-R)$ (Newton's law of cooling in a room of temperature $R$) $P' = kP(T-P)$ (Infection in a population of $T$) Can anyone suggest any other first order ODEs which can be solved and that are used in applied sciences? Any help would be greatly appreciated.","['ordinary-differential-equations', 'soft-question']"
653529,Two branch cuts,With $f(z)$ I denote the branch of $(z^2-1)^{1/2}$ defined by branch cuts in the $z$-plane along the real axis from $-1$ to $-\infty$ and from $1$ to $\infty$ with $f(z)$ real and positive above the latter cut. $g(z)$ denotes the branch of $(z^2-1)^{1/2}$ defined by a cut along the real axis from $-1$ to $+1$ with $g(z)$ real and positive for $(x-1)$ real and positive. Now I do not understand why $f(z)=f(-z)$ and $g(z)=-g(-z)$? Any ideas how this can be derived?,['complex-analysis']
653531,Sequence is periodic $x_{n+2}=|x_{n+1}-x_{n-1}|$,"How to show that the sequence $$x_n, n \geq 0, x_{n+2}=|x_{n+1}-x_{n-1}|, n \geq 1$$
with $x_0, x_1, x_2$ positive integers, not all null,  is periodic? I tried to pick up the square but obtained equalities not helped. Thanks so much for any suggestion.","['sequences-and-series', 'algebra-precalculus']"
653544,Does there exist a surface homemomorphic to a torus with positive Gaussian curvature?,"This is a problem from the my last exam in Differential Geometry II and I didn't solve it.
I'm studying again, but without success. So I need help. Does there exist a surface $S \subset \mathbb{R}^3$ which is homeomorphic to the torus $\mathbb{T}^2$ and has Gaussian curvature $K \geq 0$? What I have to work with: Differential forms, Gauss-Bonnet Theorem, Stokes Theorem, Euler characteristic, etc. Can someone help me?",['differential-geometry']
653562,How to show that the limit of this sequence is $L=4$ (ex.8.11 Mathematical Analysis 2nd ed.- Apostol),"Show that the sequence given by $$\begin{aligned}a_1&=2\\a_2&=8\\a_{2n+1}&=\frac{a_{2n}+a_{2n-1}}2\\a_{2n+2}&=\frac{a_{2n}a_{2n-1}}{a_{2n+1}}\end{aligned}$$ has limit $L=4$ . I know the principle of mathematical induction could be useful, but I can't understand the way I should use this principle to prove the limit is $L=4.$ I am interested in understanding how I should think when I face this kind of problems.
Could you help me,  please? Any hint or help will be welcome.","['sequences-and-series', 'real-analysis']"
653575,"Examples of non-Riemann integrable functions that appear ""in nature""?","I am teaching an honours calculus class, and am looking for examples on non-integrable functions that occur somewhere real in mathematics. (The standard example of 1 on $\mathbb{Q}$ and 0 elsewhere always felt slightly manufactured to me. If you can give a context for it, I would be happy about that, too).","['calculus', 'examples-counterexamples', 'soft-question']"
653608,Existence of a measure with given marginals on product space,"Let $X_1,...,X_n$, $n\geq 2$ be Polish spaces. I have a given compatible family of probability measures $\{\pi_{ij} \in X_i\times X_j \}$ (here each measure is defined on the space of the form $X_i\times X_j$ for some pair $(i,j)\in \{1,..,n\}^2)$. Is it always possible to construct measure $\pi$ on $X_1 \times ... \times X_n$ with given projections: $(Proj_{X_i\times X_j})_\#\pi = \pi_{ij}$? If not, are there any known sufficient conditions on a family of marginals? Does the answer change, if we consider countable number of $X_i$ instead of a finite one?","['measure-theory', 'probability-distributions', 'probability']"
653650,Infinite series of nth root of n factorial,"Why is this not correct:
$$
\begin{align}
\lim_{n\to \infty}\sqrt[n]{n!} &=
\lim_{n\to \infty}\sqrt[n]{n(n-1)(n-2)(n-3)\cdots(1)} \\
&=\lim_{n\to \infty}\sqrt[n]{n} \cdot \lim_{n\to \infty}\sqrt[n]{n-1} \cdot \lim_{n\to \infty}\sqrt[n]{n-2}\cdots \lim_{n\to \infty}\sqrt[n]{1} \\
&=1 \cdot 1 \cdot 1 \cdot 1 \cdots 1 \\
&=1
\end{align}
$$
Therefore, $\lim_{n\to \infty} \sqrt[n]{n!}=1$. It is clear that $\lim_{n\to \infty} \sqrt[n]{n}= 1$ as and that $n! = n(n-1)!$ Yet wolframalpha gives me infinity as the limit and not $1$! If you have Rudin's Principles of Mathematical Analysis refer to Theorem $3.3$ c) and Theorem $3.20$ c)",['real-analysis']
653682,"Find period of power sequence $a^k \mod m$, with $a, m$ not coprime","Let $a, m$ be positive integers and $m > 1$. I'm interested in the sequence $(a^k)_{k 
\in \mathbb{N_0}} \mod m$. Since there are only $m$ different values that can occur in the sequence and since $a^k = a \cdot a^{k-1}\ \ \forall k > 0$ is only dependent on the previous element, I conclude that there exist $i, C \leq m$, such that $a^{k + C} = a^k\ \ \forall k \geq i$. Example: $a = 2, m = 12$, we get the sequence $1, 2, 4, 8, 4, 8, 4, 8... \mod 12$ with $x = 2, C = 2$. Given $a$ and $m$, I want to algorithmically find some $i$ and $C$ with the above property. I'm especially interested in the case where $gcd(a,m) \neq 1$, since otherwise a trivial solution is $i = 0, C = \phi(m)$ according to Euler's theorem , if I'm not mistaken. The obvious algorithm is naive in that it just evaluates the sequence element by element and stops as soon as it hits a duplicate. I'm sure we can do better than $O(m)$ exponentiations by using the Chinese Remainder Theorem and factorizing $m$ or something, but since I don't have a math background it's a bit hard for me to put my finger on it. The ultimate goal is to evaluate ""exponential-tower""-type expressions of the form ${a_1}^{{a_2}^{a_3^{a_4^{\ldots}}}}$ modulo some prime $p$, as asked in an algorithm question on Stack Overflow I tried to contribute my two cents there by applying some observations, but I'm personally interested in this problem and pretty sure the algorithm can be improved if we can solve the particular problem of finding the cycle length faster. If somebody has another general idea of solving the exponential-tower problem, that's very interesting as well and I'd love to hear it, but it's not the primary point of this question :)","['modular-arithmetic', 'group-theory', 'number-theory']"
653691,Why is $C_c^\infty(\Omega)$ not a normed space?,"I am watching a Coursera video on Théorie des Distributions and I am trying to understand one of the slides. Let $\Omega \subset \mathbb{R}^N$ be an open set and 
$C_K^\infty(\Omega) = \{ \phi \in C^\infty(\Omega) : \mathrm{supp}(\phi)\subset K  \}$. This space has has an infinite family of norms for each $p \in \mathbb{N}$, and compact $K \subset \Omega$ - the maximum of the partial derivative: $$ ||\phi||_{p,K} = \max_{|\alpha|\leq p} \max_{x \in K} |\partial^\alpha \phi(x)|$$ Why is $C_c^\infty(\Omega)$ not a normed space , if we can compute a norm of a function in any compact subset? Here "" compact "" means closed and bounded since we are dealing with $\mathbb{R}^n$.","['normed-spaces', 'distribution-theory', 'compactness', 'functional-analysis']"
653743,Finding a disjoint subvariety,"Given sub-variety $X\subset \mathbb{A}^{2k}$ of dimension $k-1$, how can I find a sub-variety $Y\subset \mathbb{A}^{2k}$ of the same dimension which is disjoint to $X$? Perhaps I should mention I read Kempf's 'algebraic varieties' up to chapter 5.",['algebraic-geometry']
653748,How to calculate $\begin{cases}y''+4y = \cos{2t}+t^2 \\y(0) = 1;y'(0) = 0\end{cases}$,"I'm trying to solve this Cauchy Problem $$\begin{cases}y''+4y = \cos{2t}+t^2 \\y(0) = 1;y'(0) = 0\end{cases}$$ So far, i made the following steps: Solutions of the characteristic equation $$\lambda^2+4\lambda = 0$$ $$\lambda_{1} = 0 , \lambda_{2} = -4$$
$$Y_{om}(t) = a_1\cos{2t}+a_2\sin{2t}$$ Looking for the particular solution and then $Y_{gen}(t) = Y_{om}(t)+Y_p(t)$ $$Y_1p(t) = a\cos{2t}+b\sin{2t}$$ $$Y_2p(t) = ct^2+dt+e$$
$$Y_p(t) = a\cos{2t}+b\sin{2t}+ct^2+dt+e$$ Now i should calculate the first derivative and the second derivative of the particular solution and then replace in the equation in order to find the values ​​of the coefficients $$a,b,c,d,e$$ I tried many attempts but i can't get the result. What am I doing wrong?",['ordinary-differential-equations']
653764,How to either prove or disprove if it is possible to arrange a series of numbers such the sum of any two adjacent number adds up to a prime number,"I'm wondering if it's possible to write a theorem to prove or disprove the possibility of arranging a sequence of numbers (1,2,...n) such that the sum of any two numbers adds up to a prime number. An Example: Input: Say n=7. The sequence is 1,2,3,4,5,6,7 Output: 7,6,5,2,1,4,3 Here are a few numbers where a program I wrote seems to fail for n=71
solution sequence:
36 37 52 61 18 19 54 55 58 45 56 11 26 27 44 53 60 67 6 7 10 13 30 31 48 49 64 3 4 15 16 21 22 25 28 33 34 39 40 43 46 51 62 65 66 71 2 5 8 9 14 17 20 23 24 29 32 35 38 41 42 47 50 63 68 69 70 1 12 59 
 But unable to fit: 57 

n=50
solution sequence:
19 12 49 30 31 48 11 50 3 4 15 38 41 42 47 6 7 10 13 18 23 24 29 32 35 44 45 2 5 8 9 14 17 20 21 22 25 28 33 34 39 40 43 46 1 36 
But unable to fit: 37 27 26 16 Successful attempts: n=17
3 4 7 10 13 6 11 12 17 2 5 8 9 14 15 16 

n=25
23 24 19 12 11 18 25 6 7 10 13 16 3 4 15 2 5 8 9 14 17 20 21 22 1 Here is the program (very dirty I warn you!) I wrote to be able to generate the above output. Hint: Change max to the number you want and try it out.","['prime-numbers', 'summation', 'sequences-and-series', 'primality-test']"
653768,Grassmannian bundle: any good reference?,"I have met the notion of Grassmannian bundle of a vector bundle over a variety in intersection theory, but anywhere I look I just find a brief recall of how the stalks look like (my references so far are ""3264 and all that"" by Eisenbud and Harris, ""Intersection Theory"" by Fulton).
I was wondering whether there is any good reference to see the actual definition and construction and the universal properties of this object...","['intersection-theory', 'algebraic-geometry', 'grassmannian', 'vector-bundles']"
653825,"Determine the number of positive integer x where $x\leq 9,999,999$ and the sum of the digits in x equals 31.","Determine the number of positive integer x where $$x\le 9,999,999$$ and the
  sum of the digits in x equals 31 How do you approach this question? TEXTBOOK SOLUTION: Let x be written in base 10. 
  The answer to this problem is the number of nonnegative integer solutions to 
  $$x_1+x_2+x_3+x_4+x_5+x_6+x_7 = 31,\text{ } 0\le x_i,\text{ } 1\le i\le7 \text{
but } x_j \gt 9$$ How does this make sense?, why are there 7 terms of x. This could be arbitrary large, no? Maybe a bad question?  Or a bad solution?","['combinations', 'inclusion-exclusion', 'discrete-mathematics', 'combinatorics']"
653829,"What function can be differentiated twice, but not 3 times?","In complex analysis class professor said that in complex analysis if a function is differentiable once, it can be differentiated infinite number of times. In real analysis there are cases where a function can be differentiated twice, but not 3 times. Do anyone have idea what he had in mind? I mean specific example where function can be differentiated two times but not three? EDIT. Thank you for answers!
but if we replace $x\to z$ and treat it as a complex function. Why are we not getting in the same problem? Why according to my professor it is still differentiable at $0$?","['complex-analysis', 'calculus', 'derivatives', 'real-analysis']"
653839,An other tricky one. Tigonometric integral.,"How should I attack this ?
$$ \int_0^{\pi} \cos(ax)^m \cos(x)^n dx$$","['definite-integrals', 'trigonometry', 'integration']"
653863,"Proof help. Core-compactness, Hausdorff, Locally Compact","While reading about topologies on continuous function spaces, I've seen remarks that core-compact and locally compact are equivalent for Hausdorff spaces. Now I can clearly see that locally compact always implies core-compact, so the Hausdorff condition comes into the proof of the converse. Let $K$ be a core-compact Hausdorff space. Let $x\in U\subseteq K$ with $U$ open. I need to show that $U$ contains a compact neighborhood of $x$ . Since $K$ is core-compact there is an open neighborhood $V$ such that $x\in V\subseteq U$ with $V\ll U$ . I don't know where to go from here. EDIT Here are the two papers which make make me believe this is a theorem: Core Compactness and Diagonality in Spaces of Open Sets Topologies on Spaces of Continuous Functions I have found another source which claims something better: every sober core-compact space
is locally compact (although I can't see the proof of the theorem; I might buy it). Non-Hausdorff Topology This hints that the property of Hausdorff spaces that we want to exploit is the fact that the intersection of all closed neighborhoods of a point is precisely that point. EDIT I am now asking for help in completing the proof. This has been bothering me for too long.","['general-topology', 'compactness']"
653864,"Given the graph of a relation R on a set of real numbers, how can you visually determine if R has the reflexive, anti/symmetric properties?","Answers: a. It must contain all points on the line $y=x$ where $x$ is in the domain of the relation. From a
point on the graph, move vertically to the line $y = x$ and that point must be on the graph. b. If $(a,b)$ is on the graph, its reflection about the line $y = x$ must also be on the graph. c. If $(a,b)$ is on the graph and $a \neq b$, then the reflection of $(a,b)$ about the line $y = x$
cannot be on the graph. Please, elaborate on these answers. I have no idea what they mean. Thanks.","['logic', 'functions']"
653894,Show that $f$ is increasing when $\alpha=0$ and decreasing when $\alpha=1$,"Let $$f(x)=(x+\alpha)\log\left(1+ {1 \over x}\right)$$ 
Show that $f$ is increasing when $\alpha=0$ and decreasing when $\alpha=1$  on $[1,\infty)$ The derivative is: $$f'(x)=\log\left(1+{1 \over x}\right) - {{x+\alpha} \over x(x+1)}$$ for $\alpha=0$: $f'(x)=\log(1 + {1 \over x}) - {1 \over x+1}$ for $\alpha=1$: $f'(x)=\log(1 + {1 \over x}) - x$ Now, I thought using Taylor Expansion in order to prove it, but is it necessary? Is there a simple way showing it?","['calculus', 'derivatives', 'functions']"
653903,"Center of Mass, Multivariable Calculus","I have a solid with the bounds $z=2x^2+2y^2$ where $z=c$ and this solid has a uniform density of B. I need to find the mass and the center of mass of this solid. I know how to find a normal center of mass, but I do not know how to set up an integral for this problem, but I think it involves change of coordinates (Also, assume c>0). Thanks.","['multivariable-calculus', 'integration']"
653921,What is the Bi-affine plane,"I want to know the definition of the Bi-affine plane. In an article it says that semi-symmetric plane is same as bi-affine plane. But I want to the exact definition and axioms. Also There are two types of Bi-affine planes Type I and Type II. It defines only in one paper, that is in German, but I don't know German and difficult to translate with math symbols (using google and other online translations). Can you help me to find  the definitions of the Bi-affine plane of type I and II, pls.. If there are any references, pls tell me... Thanks.","['geometry', 'algebraic-geometry', 'reference-request']"
653943,What's the probability of someone winning Warren Buffett's March Madness challenge?,"Billionaire Warren Buffett is giving away $1 billion (references 1 , 2 , 3 ) to anyone who can pick a perfect March Madness bracket. Roughly speaking, what is the probability that Buffett will have to pay up?",['probability']
653966,Central limit theorem inequality with binomial distribution,"In a theater there are 600 seating's and only two cloakroom's. Every person independently from others randomly leaves a cloak in one of them. At least how many ticket's should there be in each of the cloakroom's so the probability of directing guest's to the other one is less or equal to 0.01 ? So we have 600 Bernoulli trials. $n = 600, p =  \frac{1}{2}$ 
So to obtain a solution I have to estimate this: 
$P(X  > k ) \le 0.01$?","['statistics', 'binomial-theorem', 'probability']"
654007,"Why does $\exists x\,\ x = x$?","The Wikipedia article on ZFC insists that the empty set exists since it suffices for any set to exist, since the Axiom of Specification for which we always specify ""false"" will construct the empty set. I agree that in the end everything works out because the Axiom of Infinity guarantees the existence of $\mathbb{N}$, but apparently this is not needed. Directly paraphrasing the article, ZFC is ""formalized,"" the ""domain of discourse"" must be nonempty, and therefore $\exists x\,\ x = x$. I don't completely understand this. Why is the assertion $\exists x$ even true (reflexivity I can accept)?",['elementary-set-theory']
654009,Equation of a plane from cross product,"I'm working from Do Carmo, and I ran into another snag. More specifically, 1.4.5: Given points $p_1, p_2, p_3 \in \mathbb{R}^3$ , show that the following expression gives the equation for the plane containing these points: $((p-p_1) \wedge (p-p_2)) \bullet (p-p_3) = 0$ for an arbitrary point on the plane $p=(x,y,z)$ My issue is that Do Carmo doesn't mention any equation for planes, so I'm not sure what he wants here.  Furthermore, I think I may be missing some nuance of it as direct computation was very messy and unfruitful. One may simplify the expression to $(p \wedge p_2 + p_1 \wedge p) \bullet p_3 + (p_1 \wedge p_2) \bullet (p-p_3)$ but the usefulness of this is questionable at best. Note that $u \wedge v$ here is equivalent to the cross product. Any help or clarification is appreciated.",['differential-geometry']
654013,Express $(1+\cos(x-1))^3$ as a trigonometric polynomial in x.,"Express $(1+\cos(x-1))^3$ as a trigonometric polynomial in x. I keep doing this problem and somehow I keep messing up the constants, and it just jumbles up in my head. $$(1+\cos(x-1))^3$$ 
$$= (1+\cos(x-1))(1+\cos(x-1))(1+\cos(x-1))$$
$$= (1+\cos(x-1))(1+2\cos(x-1)+\cos^2(x-1))$$ 
$$= 1+3\cos(x-1)+3\cos^2(x-1)+\cos^3(x-1)$$ Now I hope I've got this correct so far, but after this I making some kind of mistake. $$=1+3(\cos1\cos x+\sin1\sin x) + 3/2+3/2\cos2(x-1) +3/4(\cos1\cos x+\sin1\sin x) +1/4\cos3(x-1)$$ But then how do I do $\cos2(x-1)$ and $\cos3(x-1)$ ?","['boundary-value-problem', 'trigonometry', 'fourier-analysis']"
654026,Real numbers and positive real numbers have same cardinality,How to prove that real numbers and positive real numbers have same cardinality?  I know you have to construct a bijective function mapping one to the other.  But I have trouble finding this particular function.  Thanks!,"['elementary-set-theory', 'functions']"
654042,Some questions about Banach's proof of the existence of continuous nowhere differentiable functions,"Im reading Continuity and Category of Chapter11, Carothers' Real Analysis, 1ed. Here is a reading material at the end of this chapter, talking about Banach's proof of the existence of continuous nowhere differentiable functions, I have 4 questions here, I cannot understand the sentence in paragraph3 that is "" In particular, any f∈$C$[0,1] having a right-hand derivative at most n in magnitude at even one point in [0, 1-(1/n)] is in $E_n$"". I mean what is ""at most n in magnitude ""? Im not an english native speaker. How did he guarantee that |f(x+h)-f(x)| =< nh for all 0 < h < 1-x ? Why does the proof merely focus on right-hand derivatives? What is the quotients involved in?","['real-analysis', 'analysis']"
654157,Help with a pigeonhole principle?,"Let $n \geq 1$ be an integer. Use the Pigeonhole Principle to prove that in any set
of $n + 1$ integers from $\{1, 2, . . . , 2n\}$, there are two integers that are consecutive (i.e., differ by one).","['pigeonhole-principle', 'discrete-mathematics']"
654173,Finding limit of sequence to converge to the $L^1$ norm of $f$.,"If $f \in L^1(m)$ ($m$ is Lebesgue measure on $\mathbb R$), I'd like to show that $$\sum_{-n^2}^{n^2} \left|\int_{j/n}^{(j+1)/n} f \,dm\,\right| \xrightarrow{n \rightarrow \infty} \int_\Bbb R |\,f\,| \,dm$$. Intuitively I see why this is true. As $m$ gets larger we're covering both a wider and finer evaluation of the integral of $f$. I suppose we can somehow compare $f$ to a simple $\phi$ in $L^1$: $\int |\phi - f| < \epsilon$. We also have that for sufficiently large $m\in \mathbb N$, $$\sum_{-m^2}^{m^2} \left|
\int_{-j/n}^{(j+1)/n} f \,dm\,\right| \leq \int_\Bbb R |f| \,dm$$. Therefore $$ \int_\Bbb R |f| \,dm - \sum_{-n^2}^{n^2} |\int_{j/n}^{(j+1)/n} f \,dm| = \int_{(-\infty,-n]\cup [n,\infty)} |f| \,dm + \int_{-n}^n |f| - \sum_{-n^2}^{n^2} |\int_{j/n}^{(j+1)/n} f | < $$ $$< \varepsilon + \sum_{-n^2}^{n^2} \int_{j/n}^{(j+1)/n} |f| - |\int_{j/m}^{(j+1)/m} f |$$. I am not sure where to go from here.","['measure-theory', 'real-analysis']"
654198,"Find the value of A, B and C in the identities.","$6x^3 -11x^2 + 6x + 5 \equiv (Ax-1)(Bx - 1)(x - 1) + c$ Find the value of A, B and C. I started it like this: $6x^3 -11x^2 + 6x + 5 \equiv (Ax-1)(Bx - 1)(x - 1) + c$ Solving the right hand side: $ (ABx^2 - Ax - Bx + 1)(x - 1) + C$ $ ABx^3 - ABx^2 - Ax^2 + Ax - Bx^2 + Bx + x - 1 + C$ $ABx^3 - (AB + A + B)x^2 + (A + B + 1)x - 1 + C$ Comparing the coefficients: $AB = 6$ $A = \frac6 B$ $AB + A + B = 11$ Then substitute the value of A in the above equation...is this right? Is there any error?",['algebra-precalculus']
654206,Why is the special linear group generated by elementary matrices that add a multiple of row $j$ to row $i$? [duplicate],"This question already has an answer here : Transvection matrices generate $ \operatorname{SL}_n(\mathbb{R}) $ (1 answer) Closed 5 years ago . The general linear group is generated by elementary matrices that add a multiple of row $j$ to row $i$ and elementary matrices that multiply row $i$ by a scalar. This is because you can write an invertible matrix as the product of elementary matrices, and a row swap matrix can be written as a product of the other two types of elementary matrix. So far, I've worked out that all matrices that are products of this type of elementary matrix are in the special linear group, but I don't know how to proceed.","['linear-algebra', 'group-theory']"
654214,Tao's proof of Szemeredi-Trotter theorem on incidences,"In Tao's proof of Szemeredi-Trotter theorem on Point-Line incidences , he uses a lemma which decomposes the real plane into cells. During the proof of this lemma, the final step of getting rid of the logarithmic factor involves a induction on the ""Bad cells"" which violate the bound. My question is if we use the statement of the lemma as the induction hypothesis, then we apply this to the bad cells. Now what happens to the partition that actually resulted in these bad cells? http://terrytao.wordpress.com/2009/06/12/the-szemeredi-trotter-theorem-and-the-cell-decomposition/#cell",['combinatorics']
654218,one-to-one functions question,"Let $A$ be a set of size $m$, let $B$ be a set of size $n$, and 
assume that $n \geq m \geq 1$. 
How many functions $f : A \rightarrow B$ are there that are ${not}$ 
one-to-one? 
Justify your answer.",['discrete-mathematics']
