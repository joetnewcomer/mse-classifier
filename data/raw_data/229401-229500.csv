question_id,title,body,tags
4752584,Isosceles trapezium question,"Let ABCD be an isosceles trapezium with parallel sides AB and CD, where AB>CD.  P is a point inside ABCD such that the areas of triangles PCD, PBC, PBA and PAD are 3 $cm^2$ , 4 $cm^2$ , 5 $cm^2$ , 6 $cm^2$ respectively.  What is the ratio of AB:CD ? My attempt :- I can get total area in terms of A1 and A2  [where A1 = area of $\Delta$ AOB and A2= area of $\Delta$ COD as per figure] $\sqrt{A1} + \sqrt{A2} = 3\sqrt{2}$ Also I know $(\frac{AB}{CD})^2$ = $\frac{A1}{A2}$ since $\Delta$ AOB $\sim$ $\Delta$ COD How do I proceed further now ? Apart from this I know that all isoscles trapezoids are cyclic quadrilaterals as well, I am not sure if it could be used here",['geometry']
4752608,Finding the function that satisfies $\lim_{t\to x} \frac{t^2f(x)-x^2f(t)}{f(t)-f(x)}=1$,"I have been provided that a function satisfies this given condition: $$\lim_{t\to x} \frac{t^2f(x)-x^2f(t)}{f(t)-f(x)}=1$$ I need to find the value of $$L=\lim_{x\to 1}\frac{\ln(f(x)-\ln2)}{x-1}$$ where the limit has a non zero finite value. My attempt Since this is a $\frac00$ indeterminate form, I apply L'Hôpital's rule and obtain $$\lim_{t\to x}\frac{2tf(x)-x^2f^\prime(t)}{f'(t)}=1$$ I write this as $$\lim_{t\to x}\frac{2tf(x)}{f'(t)}-x^2=1$$ Putting $t=x$ $$\frac{2xf(x)}{f'(x)}-x^2=1$$ Putting f(x)=y and $f'(x)=\frac{dy}{dx}$ , we obtain $$\frac{dy}{dx}=\frac{2xy}{1+x^2}$$ $$\frac{dy}{y}=\frac{2xdx}{1+x^2}$$ Integrating on both sides $$\int\frac{dy}{y}=\int\frac{2xdx}{1+x^2}$$ $$\ln(y)=\ln(1+x^2)+c$$ $$y=e^{\ln(1+x^2)+c}$$ $$y=k(1+x^2)$$ Since $L$ is a non zero finite value, and the denominator tends to $0,$ the argument inside the logarithm should tend to $1$ $$\begin{align}f(1)-\ln2=1 &\implies 2k=1+\ln2\\&\implies f(x)=\frac{(1+\ln2)}{2}(1+x^2).\end{align}$$ Applying L'Hôpital's rule on $L$ $$L=\lim_{x\to 1}\frac{f'(x)}{f(x)-\ln2}$$ $$L=\frac{f'(1)}{f(1)-\ln2}$$ $$L=1+\ln2$$ However according to the answer key, the answer is $1.$ Can anyone tell me at what point I made a mistake in my solution, or if maybe the answer key is incorrect? Thank you. PS: This is is my first question on this site so I'm sorry for any formatting issues in advance and would gladly fix them if you point them out to me.","['limits', 'functions', 'ordinary-differential-equations']"
4752618,Number of partitions of $n$ into distinct even parts.,"Question from my last exam: Let $r_n$ denote the number of partitions of $n$ into distinct parts. Prove that $$
\sum_{i=0}^n(-1)^i r_i r_{n-i}
$$ is the number of partitions of $n$ into distinct even parts. For odd $n$ , the sum has an even number of parts and each of them has a pair with the opposite sign.
The signs will be opposite because at the beginning with the first element on the left there will be a plus, with the first element on the right there will be a minus.
Then we can remove these elements and the signs will reverse. In this way, for odd $n$ , the sum is $0$ . That was the easy part. How can this be shown for even $n$ ? Thanks.","['integer-partitions', 'summation', 'discrete-mathematics']"
4752619,How to understand the Posterior hyperparameters for Bernoulli in Beta conjugate prior?,"From here: https://en.wikipedia.org/wiki/Conjugate_prior#When_the_likelihood_function_is_a_discrete_distribution I know $\text{posterior} = \frac{\text{proir} \cdot \text{likelyhood}}{\text{evidence}}$ , but how it get $\alpha +\sum _{i=1}^{n}x_{i},\,\beta +n-\sum _{i=1}^{n}x_{i} $ from that formula and what does sum of $x_{i}$ means? Given Bernoulli is : $$
p(x,\mu) = \mu^x(1-\mu)^{1-x} x \in \{0,1\}
$$ Can some one give me some intuition about the posterior hyperparameters? e.g. explain how those term could help me get something from $\text{posterior} = \frac{\text{proir} \cdot \text{likelyhood}}{\text{evidence}}$ .","['statistics', 'probability-distributions', 'bayesian', 'probability-theory', 'probability']"
4752628,"Can I Start Studying Probability and Statistics After Algebra $1$, Geometry, Algebra $2$, and Linear Algebra? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 2 months ago . Improve this question I have a question regarding my mathematical background and its readiness for studying Probability and Statistics. I have completed Algebra $1$ , Geometry, Algebra $2$ , and  Linear Algebra (half done). After completing Linear Algebra, I want to dive into Probability and Statistics (skipping calculus for now). However, I am uncertain whether my current foundation is sufficient to grasp the concepts presented in Probability and Statistics. Please advise me on whether I am adequately prepared to begin studying Probability and Statistics at this stage? Should I expect to encounter any significant challenges due to my background? Or should I start calculus first then Probability and Statistics?. The book I choose for Probability and Statistics are: Probability and Statistics by Morris H. DeGroot, Mark J. Schervish https://www.amazon.com/Probability-Statistics-4th-Morris-DeGroot/dp/0321500466 Introduction to Probability and Statistics by William Mendenhall, Robert J. Beaver, Barbara M. Beaver https://www.amazon.com/Introduction-Probability-Statistics-William-Mendenhall/dp/1133103758 Recommendations for resources for Probability and Statistics would be appreciated.","['self-learning', 'statistics', 'reference-request', 'soft-question', 'probability']"
4752631,Prove that set of matrices is dense in $U(2)$,"Consider the group of matrices $B$ generated by taking products of the matrices \begin{equation}
\rho_1 = \begin{pmatrix}\exp(-4\pi i/5) & 0\\ 0 & \exp(3\pi i/5)\end{pmatrix}\\
\rho_2 = \begin{pmatrix}\frac{1}{\phi}\exp(4\pi i/5) & \frac{1}{\sqrt{\phi}}\exp(-3\pi i/5)\\ \frac{1}{\sqrt{\phi}}\exp(-3\pi i/5) & -\frac{1}{\phi}\end{pmatrix},
\end{equation} where $\phi=\frac{1+\sqrt{5}}{2}$ . Prove that $B$ is dense in $U(2)$ . This problem comes from the braiding of Fibonacci anyons in topological quantum computing and the above statement is equivalent to saying that braiding of Fibonacci anyons can produce any single qubit quantum gate. I was wondering how one would typically go about proving such a density statement. Edit:
I was thinking of the following argument: $\rho_1$ and $\rho_2$ are non-commuting matrices and $\rho_1$ has order 10 and I think that $\rho_2$ has infinite order. Hence $B$ would be an infinite nonabelian subgroup of $U(2)$ . The only non-abelian subgroups are $SU(2)$ and $U(2)$ , since $\rho_1$ and $\rho_2$ are not in $SU(2)$ , $B$ must be $U(2)$ .","['unitary-matrices', 'dense-subspaces', 'algebraic-geometry', 'group-theory', 'quantum-computation']"
4752640,Show that a convergent sequence exists within any uncountable set of reals,"Assume $A$ is an uncountable set of reals, show there exists a convergent sequence $a_n$ such that $(\forall n \ a_n\in A) \land (\forall n,m \ n\neq m\implies a_n\neq a_m)$ Please check the validity of my proof: The equistence of such a sequence implies that there is a point $a$ in $A$ such that in any neighbour-hood around $a$ , there is infinitely many points within it. Assume for a contradiction, the contrary, that is assume: for every point in $a$ there is a neighbour-hood around $a$ in which only finitely many points lie within. Now we will develop a method to count the elements of $A$ via the above assumption, finishing our proof by contradiction. Chose any element say $v_0$ , by the assumption choose a neighbourbood which contains finitely many other points (such that $v_0$ is not the smallest or largest element of this neighbourhood.). Call this set $V_0$ . Define $v_{-1}:=\text{min}(V_0)$ and $v_{1}:=\text{max}(V_0)$ , find a suitable neighbourhood for points $v_1$ and $v_2$ and inductively continue. The countably many finite sets $\cdots,V_{-2},V_{-1},V_0,V_1,V_2,\cdots$ union to make another countable set $V$ . It is easy to prove $A=V$ . $\square$ NEW CLEANER PROOF TO CHECK: Notice that if there exists a neighbourhood with infinitely many elements from $A$ , then the desired sequence exists by Bolzano-Weierstrass. Assume that such a neighbourhood does not exist, chose any $v\in A$ , notice the amount of $a\in A$ and $a\in V_1=(v-1,v+1)$ is finite, $V_2=(v-2,v+2)/V_1$ is finite, and generally $V_n=(v-n,v+n)/V_{n-1}$ is finite. The union of countably many finite $V_n$ is countable, the obvious bijection between $A$ and $V=V_1\cup V_2\cup\cdots$ proves $A$ is countable, we have our contradiction.","['proof-writing', 'analysis', 'real-analysis', 'solution-verification', 'sequences-and-series']"
4752676,Does convergence in probability imply deterministic convergence for non-random sequences?,"Suppose we know that an estimator $\hat{\theta}_n$ , which is a function of a random sample $X = (X_1, \dots, X_n)$ , converges in probabiltiy to some constant $\theta$ , i.e., $$\forall \varepsilon > 0: \lim_{n \rightarrow \infty} P( | \hat{\theta}_n - \theta | > \varepsilon ) = 0$$ Now, we perform bootstrapping, i.e., resampling with replacement from $X$ . Thereby, we consider the data as given, and thus, $\hat{\theta}_n$ becomes a non-random sequence conditional on $X$ . Can we show that $\hat{\theta}_n$ given $X$ converges to $\theta$ in a deterministic sense? That is, $$\lim_{n \rightarrow \infty} \hat{\theta}_n = \theta$$ The reason for asking this question is that I want to use some properties of $\theta$ in a proof about a bootstrapped test statistic. Any help is appreciated.","['conditional-probability', 'probability-limit-theorems', 'probability-theory', 'bootstrap-sampling']"
4752678,Intriguing Tridiagonal Matrix,"Given a positive sequence $\{a_n\}_{n=1}^N$ , please consider the matrix $$  \begin{bmatrix}
a_1 & -a_1 & & & &   \\ 
-a_1 & a_2 + a_1 & -a_2 & & & \\ 
 & - a_2 & a_3 + a_2 & \ddots & &   \\ 
 & & \ddots& \ddots & \ddots  &    \\ 
 & & & \ddots & a_{N-1} + a_{N-2}&  -a_{N-1}  \\ 
 & & & & -a_{N-1}&  a_{N-1}  
\end{bmatrix}$$ where blank areas denote null matrix elements. Does this type of matrix have a name, or resembles others from contexts you know of? It is real, symmetric, tridiagonal. All its rows sum to zero. All its columns sum to zero as well. Can anything nontrivial be said on its eigenvalues? I believe (correct me if I'm wrong) that the kernel is one-dimensional, generated by the vector $(1,1,\ldots$ ). In the 3d case, I see that the nonzero eigenvalues are simply $a_1 + a_2 \pm \sqrt{a_1^2 - a_1 a_2 + a_2^2}$ . So I am trying to guess a generalization of this formula - of which several come to mind. But there may be smarter way to go about it? Thank you very much for any tip you may have.","['3d', 'eigenvalues-eigenvectors', 'matrices', 'diagonalization', 'tridiagonal-matrices']"
4752729,How is this collection of open balls a covering of the first quadrant in the Euclidean $n$-space?,"Let $$ 
S \colon= \left\{ \left( x_1, \ldots, x_n \right) \in \mathbb{R}^n \colon \, x_1 > 0, \ldots, x_n > 0 \right\}. \tag{Definition 0}
$$ For each positive real number $\alpha$ , let $$
A_\alpha \colon= \left\{ \left( x_1, \ldots, x_n \right) \in \mathbb{R}^n \colon \sqrt{ \sum_{i=1}^n \left( x_i - \alpha \right)^2 } < \alpha \right\}, \tag{Definition 1}
$$ that is, $A_\alpha$ is the open $n$ -ball with center $( \alpha, \ldots, \alpha ) \in \mathbb{R}^n$ and radius $\alpha$ . Finally, let $$
\mathscr{A} \colon= \left\{ A_\alpha \colon \alpha \in \mathbb{R}, \alpha > 0 \right\}. \tag{Definition 2}
$$ Then how to show that the collection $\mathscr{A}$ covers $S$ ? That is, how to show that $$
S \subseteq \bigcup_{\alpha > 0} A_\alpha? \tag{0}
$$ And, can we be even so precise as to state that $$
S = \bigcup_{\alpha > 0} A_\alpha? \tag{1} 
$$ My Attempt: Let $\left( x_1, \ldots, x_n \right)$ be an arbitrary point of $S$ . Then $x_1, \ldots, x_n \in \mathbb{R}$ such that $$ 
x_1 > 0, \ldots, x_n > 0. \tag{2} 
$$ Let us put $$
\alpha \colon= \frac{ x_1 + \cdots + x_n}{n}. \tag{Definition 3}
$$ Then we note that \begin{align}
\sqrt{
     \sum_{i=1}^n \left( x_i - \alpha \right)^2 
} 
&= 
\sqrt{ 
     \left( 
          \frac{(n-1) x_1 - x_2 \cdots - x_n}{n} 
     \right)^2 
     +  
     \left( 
          \frac{-x_1 + (n-1)x_2 - \cdots - x_n}{n}  
     \right)^2 
     + \cdots + 
     \left( 
          \frac{-x_1 - x_2 - \cdots - x_{n-1} + (n-1) x_n}{n} 
     \right)^2 
}
\end{align} Is what I have done so far correct? If so, then how to proceed from here? Or, is there some other way around this problem?","['elementary-set-theory', 'analytic-geometry']"
4752738,Joint pdf of the two highest values extracted from a uniform distribution,"An observable $x$ follows a uniform distribution U([0,m]), where $m$ is a known parameter.
Given $N$ independent observation, we retain only the two highest values among the N observations (let's call them $x_1$ and $x_2$ ).
My goal is to determine the joint probability distribution $P(x_1,x_2)$ of $x_1$ and $x_2$ .
I am aware that according to the definition, I can express this joint probability as \begin{equation}
P(x_1,x_2)=P(x_1)P(x_2|x_1)=P(x_2)P(x_1|x_2),
\end{equation} where $P(x_1)=\frac{N}{m^N}x_1^{N-1}$ is the probability of extracting the highest value, $P(x_2)=\frac{N(N-1)}{m^N}x_2^{N-2}(m-x_2)$ is the probability of extracting the second highest value, $P(x_1|x_2)$ or $P(x_2|x_1)$ are the conditional probabilities. How can I determine these two conditional probabilities?  Alternatively, is there a more effective method to calculate this joint probability?","['conditional-probability', 'probability']"
4752770,Is there an infinite-dimensional normed vector space in which the set complement of a bounded set may have more than one unbounded component?,"Let $n \ge 2$ . Using the fact that $\{x \in \mathbf R^n : \lVert x\rVert > R\}$ is connected for each $R > 0$ , we can show that if $B \subseteq \mathbf R^n$ is bounded, then $\mathbf R^n \setminus B$ has at most one unbounded connected component. The same obviously then holds for $\mathbf C^n$ for $n \ge 1$ , and this fact is used to prove the spectral permanence theorem for Banach algebras. It is however not true in $\mathbf R$ , since $[-R, R]^c = (-\infty, -R) \cup (R, \infty)$ has two unbounded connected components. Does this theorem extend to infinite-dimensional normed vector spaces as well? (over say $\mathbf R$ or $\mathbf C$ ) Is there a slick description of the spaces in which this theorem does hold?","['connectedness', 'normed-spaces', 'functional-analysis']"
4752808,"Finding a closed form for the recursive sequence $a_n=\frac13(10-2a_{n-1})$, with $a_0=3$","I've got following recursive sequence: $$
a_n=\frac13(10-2a_{n-1})
$$ With $ a_0=3$ I have found following expression: $$ a_n=3+ \sum_{n=0}^n{2^{n-1}\cdot\frac{5}{3^n}\cdot (-1)^n} $$ Is there maybe a better form?
Thank you for your help!
I would appreciate hints","['calculus', 'sequences-and-series', 'real-analysis']"
4752840,Why is a Countable Basis Needed in This Proof?,"My question is regarding the Theorem in Munkres that states: Every Regular Space with a Countable Basis is Normal. Before reading the proof in Munkres, I tried to prove it myself and came up with a ""proof"" that is clearly wrong, but I am not exactly sure why it fails. Here is my attempt:
Let $X$ be a Regular topological space with a countable basis. Consider two disjoint closed sets $C, D$ . Then $\forall x \in C$ , use regularity to find disjoint open neighborhoods $U_x, V$ such that $x \in U$ and $D \subset V$ . Then $\bigcup U_x \forall x \in C$ is an open set containing $C$ that is disjoint from $V$ . I know this proof is incorrect because it never uses the fact that $X$ has a countable basis and would imply that all regular spaces are normal, which we know is not true. However, I am having a difficult time seeing where exactly my proof fails. My thought is that it has to do with the idea of choosing an open $ U_x \forall x \in C$ . I fear this may not be possible in a case where there are uncountable many elements in $C$ . However, I would think that the Axiom of Choice would allow me to make such a statement. So, where exactly is my logic failing here?","['general-topology', 'solution-verification', 'second-countable', 'separation-axioms']"
4752901,Is the Converse of the Radon-Nikodym Theorem true?,"I'm curious as to whether the converse of the Radon-Nikodym theorem holds: Converse Theorem: let $\mu.\nu$ be measures on $(\Omega,\Sigma)$ such that $$\nu : A\mapsto \int_A f \ d\mu$$ for some measurable function $f$ . Then $\nu\ll\mu$ , and $\mu$ and $\nu$ are $\sigma$ -finite. Proof: the first part is easy, as $$\mu(A) = 0\implies \int_A f \ d\mu = 0.$$ Does the second part, regarding $\sigma$ -finiteness, hold?","['measure-theory', 'radon-nikodym']"
4752927,Answer with no trigonometry... Let $\triangle ABC$ be isosceles with $AB=AC$. Let $D$ such that $BD=AD$. Calculate the angles of the triangle $AED$.,"PROBLEM Let $\triangle ABC$ be isosceles with $AB=AC$ . On the extension of side $BC$ , a point $D$ is considered such that $C$ belongs to side $BD$ and $BD=AD$ . If the bisector $\angle ACD$ forms with the side $AB$ an $\angle AEC$ with a measure of $30$ , calculate the measures of the angles of the triangle $AED$ . WHAT I THOUGHT OF First of all, the drawing : Ok, so as you can see I noted $\angle BAC=x$ and $\angle CAD=y$ Using the fact that $AB=AC$ and $BD=AD$ we can simply show that $30=\frac{y}{2}$ $=>$ $y=60$ , $x=20$ We found out that $\angle EAD=80$ . Now, I don't know how to calculate the other angles. I thought of using the intern bisector or extern bisector theorem or Ceva's theorem, but it didn't send me any useful ideas. Hope one of you can help me!","['euclidean-geometry', 'triangles', 'angle', 'geometry']"
4752960,Extension of PDE's to critical strip,"Introduction: In statistics, distributions in the exponential family are very natural to consider. One famous example is the Gaussian. It shows up in the heat equation, in probability theory, and in many other fields. While the Gaussian may be most important due to the central limit theorem, distributions in the exponential family have properties that may be connected to the properties of the Gaussian itself.  So, consider the exponential family, the close cousin of the Gaussian, $f_s(x)=e^{sT(x)}$ for parameter $s$ and sufficient statistic $T(x)=\frac{1}{\log x}.$ Relating $f_s(x)$ to the Riemann zeta function: Viewing $f_s(x)$ geometrically: The function $f_s(x)$ is a particular solution to a linear parabolic diffusion equation (use an exponential ansatz): $$s \frac{\partial ^2f(s,x)}{\partial s^2}=-x \frac{\partial f(s,x)}{\partial x} \tag{2}$$ and the Mellin transform can be used to transform that equation to (transform the solution $f_s(x)$ and use a CAS to verify): $$r^2 \frac{\partial ^3\Psi(r,s)}{\partial r^3}=s^2 \frac{\partial \Psi(r,s)}{\partial s} \tag{3}$$ where a particular solution Bessel function, $K_1$ appears: $$\Psi(r,s)=2 \sqrt{\frac{r}{s}}K_1(2\sqrt{r s})$$ We recover a connection with the Riemann zeta function and the Gamma function: $$\frac{1}{\Gamma(w-1)\Gamma(w)}\int_0^\infty \sum_{r \in \Bbb N} \Psi(r,s) s^{w-1}~ds=\zeta(w-1) \tag{1}$$ convergent for $\Re(w)>2.$ We can recover the symmetric functional equation about the critical strip $\xi(s)=\xi(1-s)$ through this integral relationship and analytic continuation, although it is calculation intensive. A more fundamental approach: Another, perhaps more fundamental, way to obtain the symmetric functional equation is to start with any Schwartz function. Usually the self dual Gaussian is used to obtain the Gamma factor $\Gamma(s/2)\pi^{-s/2}.$ Here I ask for a closed form for the Gamma factor associated to the Schwartz class $f_s(x):$ Obtaining the correct Gamma factor for this Schwartz function . We are looking for a functional equation of this form: $$\Gamma(f,r,s)\cdot \zeta(s) \;=\; \Gamma(\hat{f},r,1-s)\cdot \zeta(1-s)\tag{4}$$ Here, $\Gamma$ is the Gamma factor and $\hat f$ denotes the Fourier transform. Note however, that the fundamental domain of $f$ is $(0,1)$ so the Fourier transform will act on this bounded domain. Here I will show the calculation of $\Gamma(f,r,s):$ $$\Gamma(f,r,s)=\int_{\mathbb R^\times \cap ~(0,1)} |x|^r~f_s(x)~{dx\over |x|}=2 \sqrt{\frac{r}{s}}K_1(2\sqrt{r s})$$ for modified Bessel function of the second kind $K_1.$ Informal discussion and remarks: In terms of geometric analysis $\Psi(r,s)$ has an interpretation as a $1$ -parameter family of Riemannian metrics which can be shown using the Fisher methodology and information geometry, and this is how I initially started thinking about $\Psi(r,s)$ . I initially thought of it as a Fisher metric. With this linear geometric flow we have essentially summed discrete pieces of the metric, over a spectrum, in this case the natural numbers, and then taken the Mellin transform to recover the zeta function. That is to say, $f_s(x)$ seems to be ""weakly"" tied to the Riemann zeta function. If you start with $f_s(x)$ and pretend that you can take two Mellin transforms in a row and sum over the natural numbers you recover the Riemann zeta i.e. formula $(1).$ Of course it doesn't make sense to take iterative Mellin transforms like this. But already, you can see that $f_s(x)$ is deeply linked to $\zeta(s)$ . And this really isn't that surprising, given the modern viewpoint of things as in Iwasawa-Tate theory. Now I claimed above, that $f_s(x)$ was Schwartz $\forall s >0.$ You may be very skeptical about this and rightfully so. This is a delicate situation and I'll explain why. The Schwartz space is classically defined for functions on the real line and so there must be some functional analysis work done to show that $f_s(x)$ can legitimately be thought of as a kind of Schwartz function. I believe things will work out just fine, under the appropriate modifications, but I personally do not know enough functional analysis to tie everything up neatly here. Question: At this point I'd like to state my question. As the title says I am looking to extend the two PDE's $(2)$ and $(3)$ to the critical strip as defined through $(4).$ How do you extend $(2)$ and $(3)$ to the critical strip as defined by $(4)?$ Explorations of the literature: Here are some other attempts of mine to educate myself on the approaches that have already been developed. Most relevant I think is the de Bruijn constant: I've read Tao's article about freezing and vaporizing the Riemann zeta function. Also see de Bruijn constant . Here is Tao's presentation: https://terrytao.files.wordpress.com/2018/08/webinar.pdf . This seems related since $f_s(x)$ obeys a strange kind of ""backwards heat equation"" $$s \frac{\partial ^2f(s,x)}{\partial s^2}=-x \frac{\partial f(s,x)}{\partial x}$$ I do know that the Mellin transform by definition maps some function $\psi : (0,\infty) \to \mathbb{C}$ with $\mathcal{M}(\psi)(s) = \int_{0}^{\infty} \psi(x) x^s  \frac{dx}{x}$ that's absolutely convergent on the vertical strip $\lbrace s \in \mathbb{C} : a < \Re(s) < b \rbrace$ . So it seems to me that this sum of the metric over a particular spectrum of the naturals, is being converted from a real $s$ to a complex $w$ through the Mellin transform. So, I guess that's where I'm stuck. I don't know how to connect that complex object to the $1$ -parameter family of real metrics. It seems closely related to this too: https://mathoverflow.net/q/139863/123449 , but I don't know if the argument applies since the operator of my PDE is not a second order p.d.o. (it's third order) among other things. I mean I guess it could be reduced to second order through a Fourier transform but I don't know how to proceed exactly. Final remarks: $(A).~f_s(x)$ is a $1$ -parameter class, and therefore we should have a varying, or $1$ -parameter class of functional equations. $(B).~$ The Gamma factor is also a $1$ -parameter class. $(C).~$ I think there is a way to unify $(A)$ and $(B)$ on the critical strip, using existing mathematical methods. $(D).~$ Any argument showing that $f_s(x)$ cannot be used to obtain $(4)$ would also answer this question, essentially providing a counterexample.","['harmonic-analysis', 'analytic-number-theory', 'functional-analysis', 'partial-differential-equations', 'riemann-zeta']"
4752982,Is it possible to explain geometrically why $\arctan (1/2) +\arctan (1/3) = 45$ degrees?,"$\arctan(1/2)$ seems to be some strange, irrational angle, and the same goes for $\arctan(1/3)$ , but those two angles seem to sum up to $45$ degrees. This seems like a mystery to me even though I can derive the result algebraically as follows, by using the summation formula for the tangent function. $\tan\big(\arctan(1/2)+\arctan (1/3)\big)=\dfrac{5/6}{1 - 1/6}=1\,.$ Can someone come up with a geometric explanation? A remark: I started thinking about the described arctan puzzle while I was trying to solve a problem in complex analysis, namely this one: How to find a conformal mapping which maps the region between |z + 3| < √ 10 and |z − 2| < √ 5 onto the interior of the first quadrant?","['triangles', 'proof-without-words', 'trigonometry', 'geometry']"
4752984,Why doesn't this argument prove every nonsingular curve embeds into the projective plane?,"It is a statement that some curves can never be embedded in the plane, but only in projective 3-space. Why does the following argument not prove that every nonsingular curve can be embedded in the projective plane, though? Let $X$ be a nonsingular complete curve over an algebraically closed field $k$ , with function field $F.$ We prove that $X$ can be embedded in $\mathbb{P}^2_k.$ $F$ has transcendence degree 1 over $k,$ and so we may find some $x \in F$ so that $F/k(x)$ is an algebraic extension. In fact, since $F$ is finite type over $k,$ $F/k(x)$ is even a finite extension. As $F/k(x)$ is a finite extension, and as $k(x)$ is separable, we deduce that $F/k(x)$ is a finite separable extension. The primitive element theorem then tells us that $F = k(x, y)$ for some $y \in F.$ Let $P \in k(x)[T]$ denote the monic minimal polynomial of $y$ over $k(x).$ Then $P(y) = 0$ looks like some polynomial equation $$y^n + f_{n-1}(x)y^{n-1} + \cdots + f_0(x) = 0,$$ where each $f_i\in k(x).$ Clearing denominators, we find that there is some polynomial $Q \in k[T_1, T_2]$ so that $Q(x,y) = 0.$ Let $X'$ denote the subscheme of $\mathbb{P}^2$ cut out by $Q$ . In the standard affine chart, $X'$ looks like $\operatorname{Spec} k[T_1, T_2]/(Q).$ The fraction field of the ring $k[T_1, T_2]/(Q)$ is just $F.$ Thus $X'$ is a projective curve with fraction field $F,$ implying it is isomorphic to $X.$ Where does this argument go wrong? I can think of two possible problems. In step 4, is it possible that $X'$ is a singular curve? Also in step 4, is it possible that $F$ is not isomorphic to the field of fractions of $k[T_1, T_2]/(Q)?$ I don't have any indication of why either 1 or 2 would fail; maybe someone could clarify if these are the problem, or if there was something else I missed?",['algebraic-geometry']
4752993,Rigorous definition of Cartesian product,"Recall the 'rigorous' definition of the Cartesian product $A\times B$ is the set of all functions $\phi:\{1,2\}\to A\cup B$ such that $\phi(1)\in A$ and $\phi(2)\in B$ . To show there is a bijective correspondence between the sets $A_1\space\times ...\times\space A_n$ and $\left(A_1\space\times...\times\space A_{n-1}\right)\times A_n$ , I'd like to appeal to this definition. Now I know the bijection is 'clearly' $\left(a_1,...,a_n\right)\to\left(\left(a_1,...,a_{n-1}\right), a_n\right)$ , but I'd like to interpret the bijection in terms of the definition first, because it's not actually clear what $\left(\left(a_1,...,a_{n-1}\right), a_n\right)$ even means. So first, $A_1\space\times ...\times\space A_n$ is clearly the set of all functions $f:\{1,...,n\}\to A_1\space\cup...\cup\space A_n$ such that $f(i)\in A_i $ . To form an element of $\left(A_1\space\times...\times\space A_{n-1}\right)\times A_n$ , we first need to form an element of $A=A_1\space\times...\times\space A_{n-1}$ , which is the set of all functions $g:\{1,...,n-1\}\to A_1\space\cup...\cup\space A_{n-1}$ such that $g(i)\in A_i$ . Then from the first paragraph, $A\times A_n$ is the set of all functions $h:\{1,2\}\to A\space\cup A_n$ such that $h(1)\in A$ and $h(2)\in A_n$ . This is where I'm concerned since the function $h$ is sending elements of its domain to different types of objects. So $h(1)$ is not an element of any single $A_i$ but is a $n-1$ tuple or an arbitrary function $g$ . However, $h(2)$ is just any element of $A_n$ . I guess this makes the notation $\left(\left(a_1,...,a_{n-1}\right), a_n\right)$ make sense since $h$ consists of two coordinates, the first coordinate value being a function and the second coordinate value being an element of $A_n$ . Is this thinking correct?",['elementary-set-theory']
4752995,"If $G=(A×B)\rtimes(C×D);$ $|A|=5,|B|=7,|C|=2,|D|=3,$ $C$ induces inversion on $A×B$, & $D$ acts nontriv on $B$, then ${\rm cs}^*(G)=\{2,6,7,14,35\}$","I'm trying to understand how the author calculates the conjugacy sizes here: Consider $G= (A \times B) \rtimes (C \times D)$ , where $A$ , $B$ , $C$ , $D$ are cyclic groups of order 5, 7, 2, 3,
respectively, $C$ induces the inversion map on $A \times B$ , and $D$ acts nontrivially on $B$ . Then $\operatorname{cs}^*(G)=\{2, 6, 7, 14, 35\}$ . Here the $\operatorname{cs}^*(G)$ is the set of all sizes of conjugacy classes of $G$ except $1$ . I am somehow new to semidirect products but I think I understand the semidirect product here. I tried to check when an element commutes with another. But it gets so complicated and confusing and I can't get anywhere. I appreciate any tip on how to approach this.","['semidirect-product', 'group-theory', 'abstract-algebra']"
4753003,Little-$o$ notation in CLT proof using Levy Continuity Theorem,"I am stuck at understanding the little- $o$ notation used in the proof of CLT using Levy's theorem. Specifically, I want to understand why for fixed $n$ , $$
1 - \frac{t^2}{2n} + o\left( \frac{t^2}{n} \right) = \exp\left( -\frac{t^2}{2n} + o\left( \frac{t^2}{n} \right) \right).
$$ Being new to the little $o$ notation, I understand the above equality is saying for any $f$ such that $\frac{n}{t^2}f(t) \to 0$ as $t \to 0$ , there exists $g$ such that $\frac{n}{t^2}g(t) \to 0$ as $t \to 0$ and $$
1 - \frac{t^2}{2n} + f(t) = \exp\left( -\frac{t^2}{2n} + g(t) \right).
$$ Knowing $\exp(x) = 1 + x + o(x) = 1 + x + h(x)$ for some $h \sim o(x)$ , I see $$
1 - \frac{t^2}{2n} + f(t) = \exp\left( -\frac{t^2}{2n} + f(t) \right) - h\left( -\frac{t^2}{2n}+f(t)) \right) \stackrel{?}{=}\exp\left( -\frac{t^2}{2n} + o\left( \frac{t^2}{n} \right) \right).
$$ My question is why is the last equality true? i.e. What is the function $g$ here?","['central-limit-theorem', 'asymptotics', 'real-analysis', 'taylor-expansion', 'probability-theory']"
4753029,Simplified expression for the nth derivative of the n+1th power of a function,"$$\frac{d^n}{dx^n}(f(x))^n \text{ and similar expressions}$$ I was trying to work out the Taylor series for the solution to the general cubic using Lagrange Inversion (out of curiosity: I was wondering which of the roots the series would give for different cubics) and got stuck on finding the $n^{th}$ derivative of $ (\frac{1}{ax^2+bx+c})^{n+1} $ . First I tried working it out by hand but I couldn't see any obvious pattern that would allow me to compute the general case. Wolfram Alpha was able to calculate the next few values of n and I noticed some things but there was no obvious pattern for the general term. I realized I could do it by employing the Laplace Transform (or the Fourier Transform or maybe even directly from the Taylor Series) where taking n+1 derivatives is trivial but found it rather difficult to compute any of these in general since the powers of $ \frac{1}{ax^2+bx+c}$ are rather chaotic. I am a bit stuck on this. Also, if someone knows how to do this, I'm now curious if there is a way to get the general ${n-1}^{th}$ , $n^{th}$ , or ${n+1}^{th}$ derivatives of the $n^{th}$ or ${g(n)}^{th}$ powers of a function f(x) for some function g(n), and as to where the coefficients of these terms come from (some sort of analogue of Pascal's or one of Stirling's triangles maybe?). For example, the coefficients of the $n^{th}$ derivatives of $(f(x))^n$ can be arranged in a triangle like this when you arrange them in increasing order in each row: $$\text{1}$$ $$\text{2  2}$$ $$\text{3  6  18}$$ $$\text{4  24  36  48  144}$$ But I don't remember seeing these numbers anywhere and couldn't even find this sequence (read out by rows) in the OEIS.","['laplace-transform', 'lagrange-inversion', 'taylor-expansion', 'sequences-and-series', 'derivatives']"
4753175,On Sixth Powers $x_1^6+x_2^6+x_3^6+\dots+x_7^6 = z^6$ revisited,"While answering this question , I decided to revisit the equation, $$x_1^6+x_2^6+x_3^6+\dots+x_7^6 = z^6$$ which I asked about in an old post and, with today's faster computers, might yield some new insights. Primitive solutions to the equation, $$x_1^k+x_2^k+x_3^k+\dots+x_{k+1}^k = z^k$$ where k+1 is a prime p come in two kinds: 1st, $z$ is integrally divisible by $p$ , or 2nd, it is not. The 1st kind has smaller solutions than the 2nd kind, but it is the latter we are interested in since there is a possibility one of its terms is $x_i=0$ . I. 4th powers: $(k+1 = 5)$ $$2^4 + 2^4 + 3^4 + 4^4 + 4^4 = 5^4$$ $$10^4 + 10^4 + 10^4 + 17^4 + 30^4 = 31^4 = z_1^4$$ $$\;\color{red}{0^4} + 30^4 + 120^4 + 272^4 + 315^4 = 353^4 = z_2^4$$ Note that for the 2nd kind, then $z_2=353$ is more than 10x the smaller solution $z_1=31$ (which is prime). This may give us a rough idea of what to expect for 6th powers. II. 6th powers: $(k+1 = 7)$ $$74^6 + 234^6 + 402^6 + 474^6 + 702^6 + 894^6 + 1077^6 = 1141^6 =(7\times163)^6$$ $$42^6(195^6 + 260^6 + 440^6 + 506^6 + 580^6) + 19229^6 + 33354^6 = 34781^6$$ $$\color{red}{0^6}+x_1^6+x_2^6+x_3^6+x_4^6+x_5^6+x_6^6 = z_2^6$$ Based on 4th powers, we could assume that $z_2$ is more than 14x the smaller solution $z_1=34781$ (which is also prime), or roughly $z_2 > 480000$ . In fact, according to a 2002 paper, Meyrignac claims no solutions with $z_2 < 730000$ . Edit : I just noticed that $730000/34781 \approx 20.99$ , so it seems $z_2$ is more than 21x the smaller solution $z_1$ . If the trend continues, it does not bode well for $10$ th powers. III. Tables for 6th powers In Meyrignac's site http://euler.free.fr/database.txt , there are exactly $100+78=178$ known solutions to the equation (6,1,7) with $z<412000$ . We are interested in the $78$ solutions of the 2nd kind . Statistics are, $$\begin{array}{|c|c|c|c|}
\hline
\text{Range name}&\text{Range of z}&\text{Solutions}&\text{Year}\\
\hline
R_1& \qquad 1-100000& 12 &2000\\
\hline
R_2& 100001-200000& 17&2000\\
\hline
R_3& 200001-300000& 32&2006-2008\\
\hline
R_{4a}& 300001-350000& 16&2008-2012\\
\hline
R_{4b}& 350001-400000& 0&\text{(gap)}\\
\hline
R_5& 400001-500000& 1&2010\\
\hline
\text{Total}& \;\qquad 1-500000 &78& 2000-2012^{\large{*}}\\
\hline
\end{array}$$ Large $z$ with $z<350000$ were found mostly by Rolan Christofferson between 2006-2012. But recently in 2021 , Ian Stopher found an additional solution in that range, namely $z=319799$ . So obviously it was not an exhaustive search. IV. Questions Assume solutions of the 2nd kind . The first twelve known are $R_1$ = (34781, 38191, 39779, 54347, 59819, 63631, 66029, 67681, 70513, 78919, 89797, 97081). Do we now have the computing power to do an exhaustive search for $z<200000$ ? (It is expected $R_1 = 12,\,R_2 = 19$ will be sparse, but they seem too sparse compared to $R_3= 32$ . And $R_1$ doesn't seem to be evenly spread with nothing for 40000-50000.) Or power even for $z<400000$ ? Since $R_{4a} = 16$ , then $R_{4b}$ may be similar and the total could be $R_4 > (R_3 = 32)$ .","['computational-mathematics', 'number-theory', 'prime-numbers', 'diophantine-equations']"
4753177,"Given regular decagon $ABCDEFGHIJ$, and midpoint $M$ of $AB$, prove that $AD$, $CJ$, $EM$ concur","Let there be a regular decagon $ABCDEFGHIJ$ , and $M$ the midpoint of $AB$ . Prove $AD$ , $CJ$ , and $EM$ are concurrent. I was going to do this problem by making AD and CJ pass through a point K, and construct EK and EM, and prove EKM is a straight line, as shown in the diagram below. But I got stuck because I cannot prove that JC is parallel to AB, and AD is parallel to BC - this is the only step I need to prove in order to solve the question. Is there a quick way to do this? Any help is appreciated. PS I also need to prove triangles KDC and AJK are congruent, but I think that this will be easier if I prove the parallel lines first.","['geometry', 'polygons']"
4753193,Lagrange Multipliers Question - some extremum points are missed (not detected) by the method,"I was reading about Lagrange multipliers. My book says that if $f(x,y,z)$ has in the point $(x_0, y_0, z_0)$ an extremum under the condition that $g(x,y,z) = k$ , and if $\nabla g \ne (0,0,0)$ , then there exists a number $\lambda$ such that $$\nabla f (x_0, y_0, z_0) = \lambda \nabla g (x_0, y_0, z_0) \tag{1}$$ and $$g(x_0, y_0, z_0) = k \tag{2}$$ But then I was working through this simple example. Find the extremums of $f(x,y,z) = xyz$ under the condition $g(x,y,z) = x+y+z = 1$ where $x,y,z \ge 0$ I noticed that here the Lagrange method (i.e. solving the system $(1), (2)$ ) misses to detect/find the  extremum points $P (x,y,z)$ , such that e.g. $x = 0$ and $y+z = 1$ and $y,z$ are positive. It only detects/finds the four points $(1/3, 1/3, 1/3), (0,0,1), (0,1,0), (0,0,1)$ . So what am I missing here? I guess in my book the theorem is stated somewhat informally, and that's why the Lagrange method is missing to detect these points. So why are these points $P$ missed? I mean, they are obviously extremum (minimum) points of $f$ but they do not satisfy the system $(1), (2)$ for any $\lambda$ .","['multivariable-calculus', 'calculus', 'lagrange-multiplier']"
4753198,The definition of $C_0^\infty(\overline{\Omega})$ and $C^\infty(\overline{\Omega}).$,"I am reading a famous book Introduction to the Theory of Linear Partial Differential Equation written by Chazarain and Piriou. In page 63, the authors define $C^\infty(\overline{\Omega})$ is the space of functions $\phi \in C^\infty(\Omega)$ such that $\partial^\alpha\phi \in C^0(\overline{\Omega})$ , for any multi-index $\alpha$ .
Here $\Omega$ is a regular open subset of $\mathbb{R}^n.$ (For the definition of regular open set, see also page 63. But it is not important here.) The authors then define $C_0^\infty(\overline{\Omega})$ for the functions $\phi \in C^\infty(\overline{\Omega})$ with compact support in $\overline{\Omega}.$ I am confused about the definition of $C^\infty(\overline{\Omega}).$ We only know $\phi \in C^\infty(\Omega),$ how can we define $\partial^\alpha \phi(x)$ for $x \in \partial \Omega$ ? Besides, for $\phi \in C_0^\infty(\overline{\Omega}),$ is $\phi(x)$ for $x\in \partial \Omega$ necessarily $0$ ? We know that $\text{supp}\phi \subset \overline{\Omega}$ and $\text{supp}\phi$ is $K \cap \overline{\Omega},$ where $K$ is a compact set in $\mathbb{R}^n.$ I don't think it can assure $\phi(x)=0$ for $\in \partial \Omega.$ Am I right?","['partial-differential-equations', 'functional-analysis', 'analysis', 'real-analysis']"
4753203,How to find the limit: $\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}$,"I have this limit: $$\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}.$$ I think I know how to solve it using L'Hôpital's rule (please correct me if this is wrong): $$\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}=
\lim\limits_{x \to \infty} \frac{8x^7+4+2^x\cdot \ln{2}}{2^x\cdot  \ln{2} +6x^5}=
\lim\limits_{x \to \infty} \frac{56x^6+2^x\cdot (\ln{2})^2}{2^x\cdot (\ln{2})^2 +30x^4}=
\lim\limits_{x \to \infty} \frac{336x^5+2^x\cdot (\ln{2})^3}{2^x\cdot (\ln{2})^3 +160x^3}=
\lim\limits_{x \to \infty} \frac{1680x^4+2^x\cdot (\ln{2})^4}{2^x\cdot (\ln{2})^4 +480x^2}=
\lim\limits_{x \to \infty} \frac{6720x^3+2^x\cdot (\ln{2})^5}{2^x\cdot (\ln{2})^5 +960x}=
\lim\limits_{x \to \infty} \frac{20160x^2+2^x\cdot (\ln{2})^6}{2^x\cdot (\ln{2})^6 +960}=
\lim\limits_{x \to \infty} \frac{40320x+2^x\cdot (\ln{2})^7}{2^x\cdot (\ln{2})^7}=
\lim\limits_{x \to \infty} \frac{40320+2^x\cdot (\ln{2})^8}{2^x\cdot (\ln{2})^8}=
\lim\limits_{x \to \infty} \frac{2^x\cdot (\ln{2})^9}{2^x\cdot (\ln{2})^9}=1.$$ This seems overly complicated though. I think an easier way would be to factor out the ""dominating"" term. I'm a bit new to that so I would appreciate some guidance. $x^8$ grows faster than $2^x$ when $x$ is small. But in this limit, $x$ is approaching $\infty$ . I'm not sure, but I think $2^x$ will have passed $x^8$ at that point. Does that mean I should factor out $2^x$ and if so how do I do that? Thanks in advance.","['limits', 'calculus']"
4753316,Alternating sum of the length of intervals,"Here's the problem For two odd $m$ and $n$ , which are coprime, consider the interval $[0, mn]$ and let $$
A = \{0, m, 2m, \dots , nm\} 
\quad\text{and}\quad 
B = \{0, n, 2n, \dots , mn\}. 
$$ Consider the intervals divided by the elements of $A \cup B$ . Prove that the alternating sum of the lengths of these intervals is equal to $1$ . For example, for $m=3$ and $n=5$ the intervals will be $$
[0,3],\, [3,5],\, [5,6],\, [6,9],\, [9,10],\, [10,12],\, [12,15],
$$ and $3-2+1-3+1-2+3 = 1$ . Equivalently, it is enough to prove that $$
\sum_{p=0}^{mn-1} 
(-1)^{\left\lfloor\frac{p}{n}\right\rfloor + \left\lfloor\frac{p}{m}\right\rfloor} = 1.
$$ My Attempt. For $m \geq 3n$ case, the intervals created by $(m,n)$ can be easily extended from the intervals created by $(m-2n, n)$ . For $m=n+2$ case, it can be proved with direct computation. So I separated the problem into 2 cases: $n \leq m < 2n$ and $2n \leq m < 3n$ . If $n \leq m < 2n$ , let $m=n+r$ . Then $r$ is even. For $n \leq m < 2n$ case, let $a_k = \bigl\lfloor\frac{kn}{r}\bigr\rfloor$ . Then by direct calculation, I showed that the result is $$
\sum_{k=1}^{r}{(-1)^{k-1}(a_k -a_{k-1}-1) 
\bigl( (2k-1)n - (a_k + a_{k-1} +1)r \bigr)}
$$ but I couldn't simplify this result...","['elementary-number-theory', 'integers', 'combinatorics', 'euclidean-algorithm']"
4753404,A (possible) generic spectral property in one dimensional dynamics,"This question was previously posted on MathOverflow . Context and Definitions Consider the interval $I=[0,1]$ . We say that $T:I\to I$ satisfies the axiom A (I am following [MvS]) if: $T$ has a finite number of hyperbolic periodic attractors; and defining $B(T)$ as the union of the basins of the hyperbolic attractors of $T$ , the set $\Lambda = I \setminus B(T)$ is a hyperbolic set, i.e. there exists $C >0$ and $\lambda>1$ such that $$ |(T^n)'(x)| > C  \lambda^n\ \text{for every }x\in \Lambda.$$ It is well known that the set $\mathcal A = \{T: I\to I\in\mathcal C^1; \ T\ \text{satisfies the axiom A}\}$ is open and dense in the $\mathcal C^1$ -topology (see [Chapter IV,1]). Defining $R = \overline{\{p\in\Lambda;\ p\ \text{is a periodic orbit of }T\}}$ we know from the dynamical decomposition [Theorem 11.2.15, OV] that there exists a (finite) partition of $R$ in non-empty compact sets $R^{1},R^2,\ldots, R^k$ such that: $R^{i}$ is a $T$ -invariant set for every $i$ ; $T:R^i\to R^i$ is uniformly hyperbolic and topologically transitive. Also, from the thermodynamic formalism for expanding maps, we obtain that the operators \begin{align*}\mathcal L_i : \mathcal C^0(R^i) &\to \mathcal C^0(R^i)\\
f&\mapsto \left(x\mapsto\sum_{T(y)=x}\frac{f(y)}{|T'(y)|}\right),
\end{align*} satisfy $\mathrm{dim}\,\mathrm{ker}(\mathcal L_i - r(\mathcal L_i)) = 1,$ where $r(\mathcal L_i)$ is the spectral radius of $\mathcal L_i$ . My Question: Let us now consider the operator \begin{align*}\mathcal L : \mathcal C^0(R) &\to \mathcal C^0(R)\\
f&\mapsto \left(x\mapsto\sum_{T(y)=x}\frac{f(y)}{|T'(y)|}\right),
\end{align*} we have that $\mathcal L(f) = \sum_{i=1}^k \mathcal L_i (\mathbf 1_{R^i} f)$ and therefore $r(\mathcal L) = \max\{r(\mathcal L_1),\dots, r(\mathcal L_k)\}.$ It seems to me that (generically) we have that $\mathrm{dim}\, \mathrm{ker}(\mathcal L - r(\mathcal L)) = 1.$ Equivalently, the set $\{r(\mathcal L_1), r(\mathcal L_2), \ldots, r(\mathcal L_k))\}\subset \mathbb R$ (generically) has a unique maximal element. In this way, I would like to prove the following theorem: Possible Theorem: The set $$\mathcal B = \{T:I\to I \in \mathcal C^1;\ T \text{ satisfies the axiom A} \ \text{and }\mathrm{dim}\,\mathrm{ker}(\mathcal L - r(\mathcal L)) =1 \},$$ is open and dense in open and dense (or at least residual) in the $\mathcal C^1$ topology. I feel that this result is known in the literature however I am neither able to find nor prove it. Can anyone please help me? [MvS] One-dimensional Dynamics - W. de Melo and S. van Strien ( https://link.springer.com/book/10.1007/978-3-642-78043-1 ) [OV] Foundations of ergodic theory - M. Viana and K. Oliveira ( https://www.cambridge.org/core/books/foundations-of-ergodic-theory/F5AE11B50B16D9FF32909EA4BBA1E7CE )","['dynamical-systems', 'ergodic-theory', 'functional-analysis', 'real-analysis']"
4753413,Homeomorphism vs Homotopy Equivalence,"Is the following informal way of thinking about the difference of homeomorphisms and homotpy equivalence valid: Let $f\colon X \to Y$ be a homotopy equivalence, then $$f\text{ is a homeomorphism} \Leftrightarrow  f \text{ doesn't change the ''dimension'' of } X.$$ Where by dimension I mean for example take $S^1 \subset \mathbb{C}$ and the ''thick circle'' $A:=\lbrace z \in \mathbb{C} ; 1\leq |z| \leq 2 \rbrace \subset \mathbb{C}$ . I can't name a specific homotopy equivalence from $S^1 \to A$ but it is obvious to me that there is one. The homotopy equivalence goes from a 1D object to a 2D object. If this is true what I'm saying can I replace the informal meaning of dimension above with the formal Hausdorff dimension ? $$f\text{ is a homeomorphism} \Leftrightarrow  f \text{ doesn't change the the Hausdorff dimension of } X.$$","['manifolds', 'general-topology', 'geometry', 'algebraic-topology']"
4753443,Existence of minimum for a nonlinear functionnal [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 months ago . Improve this question How would you show that the functional $F$ defined as $$F : u \mapsto \int_{(-1,1)} \big(u^{\prime \prime}(x)+u^{3}(x)\mathbb{1}_{u^{\prime}\neq0}(x) \big)^2dx$$ with $\mathbb{1}_{X}$ the indicator function of $X$ , over the set $$Y=\left\{u \in H^{2}((-1,1)),\quad \int_{\Omega}u(x)dx=0 \right\}$$ has a minimum? The first thing I can say is that, since $F \geq 0$ then $\mu:=\inf_{u\in Y}F(u)$ exists and we have a sequence $(u_{n})_{n}\in Y^{\mathbb{N}}$ such that $\lim_{n \to \infty}F(u_{n})=\mu$ . To conclude I would like to have some compactness properties and lsc, which I think I don't have. So, my question is, does anybody know of any other method with which to approach this problem? Thank you.","['calculus-of-variations', 'real-analysis', 'functions', 'functional-analysis', 'optimization']"
4753451,Integral $\int_{0}^{\infty}\frac{\ln\left(x\right)\left(e^{-x}-\cos x\right)}{x\left(1+x^{4}\right)}dx$,"$$I=\int_{0}^{\infty}\frac{\ln\left(x\right)\left(e^{-x}-\cos x\right)}{x\left(1+x^{4}\right)}dx=\frac{\pi^{2}}{8}\left(1-e^{-\frac{1}{\sqrt{2}}}\cos\left(\frac{1}{\sqrt{2}}\right)\right)$$ I got this Integral from one of my friends, he used Wolfram to get the closed form of the Integral.
Well, here is my attempt: Using Partial Fraction Decomposition: $$I=\displaystyle{\underbrace{\int_{0}^{\infty}\frac{\ln\left(x\right)\left(e^{-x}-\cos x\right)}{x}dx}_{I_1}-\underbrace{\int_{0}^{\infty}\frac{\ln\left(x\right)\left(e^{-x}-\cos x\right)x^{3}}{1+x^{4}}dx}_{I_2}}$$ For $I_1$ Wolfram Gives: $$I_1=
\frac{\pi^2}{8}$$ Wolfram can not evaluate $I_2$ but as we already know $I$ , this gives: $$I_2=\frac{\pi^{2}}{8}e^{-\frac{1}{\sqrt{2}}}\cos\left(\frac{1}{\sqrt{2}}\right)$$ How can we evaluate these? Preferably without Complex Analysis if possible!","['calculus', 'definite-integrals']"
4753502,Gershgorin Circle Theorem in Infinite Dimensional Vector Spaces,Do there exist any generalizations of the Gershgorin Circle Theorem to infinite dimensional vector spaces?,"['linear-algebra', 'reference-request']"
4753503,"Do all perfect subsets of [0,1] contain a sequence such that the ratio of its increments converges?","Fix a perfect set $D\subseteq[0,1]$ . Does there necessarily exist a monotone sequence $\{x_m\}_{m\in\mathbb{N}}\subseteq D$ such that $x_m\rightarrow x\in D$ with the property that: \begin{equation}
\frac{x_m-x_{m-1}}{x_{m-1}-x_{m-2}}\rightarrow c
\end{equation} for some $c\in(0,\infty)$ ? As all elements of $D$ are accumulation points, this seems natural, but I could not find a reference to such a property nor find a clear counterexample. Any help is much appreciated! For example, the Cantor set satisfies this property. Take $x_n=(1/3)^n$ . For all $n\in\mathbb{N}$ , $x_n$ is in the Cantor set. So too is $0$ . Moreover, the ratio of the increments is always c=1/3.",['analysis']
4753504,When are homomorphisms automatically continuous?,"Let $A$ and $B$ be topological groups. Sometimes there exist neighborhoods of the identity $U\subseteq A$ and $V\subseteq B$ such that any homomorphism $f\colon A\to B$ satisfying $f(U)\subseteq V$ is automatically continuous. Here are a couple examples of this: Let $B=\mathbb{R}$ . Let $U_0,U_1,\ldots\subseteq A$ be a neighborhood basis at the identity satisfying $U_{n+1}\cdot U_{n+1}\subseteq U_n$ . Let $V_n=(-2^{-n},2^{-n})$ . If $f\colon A\to B$ is a homomorphism satisfying $f(U_0)\subseteq V_0$ , then $f(U_n)\subseteq V_n$ , which implies continuity. I suspect that this sort of idea might work whenever $B$ is a Lie group. The case when $B$ is the circle group is important for proving local compactness of the Pontryagin dual ( https://math.stackexchange.com/a/1510226/ ). Let $A=B=\mathbb{Z_p}$ . If $f\colon A\to B$ is a homomorphism, then $f(p^n\mathbb{Z}_p)\subseteq p^n\mathbb{Z}_p$ , which implies continuity (without having to impose $f(U)\subseteq V$ ). Do all locally compact Hausdorff topological groups have this continuity property? Or is there a nice condition that implies this equicontinuity property?","['general-topology', 'topological-groups']"
4753519,On the ratio test for power series; Hunter,"This is a small detail, but I'm stuck nevertheless. In these lecture notes , there is the following theorem and proof on the ratio test for power series: Theorem 10.5. Suppose that $a_n\neq0$ for all sufficiently large $n$ and the limit $$R=\lim _{n\to \infty }\left|\frac{a_n}{a_{n+1}}\right|\tag1$$ exists or diverges to infinity. Then the power series $\sum_{n=0}^\infty a_n (x-c)^n$ has radius of convergence $R$ . Proof. Let $$r=\lim_{n\to\infty}\left|\frac{a_{n+1}(x-c)^{n+1}}{a_n(x-c)^n}\right|=|x-c|\lim_{n\to\infty}\left|\frac{a_{n+1}}{a_{n}}\right|.\tag2$$ By the ratio test, the power series converges if $0\leq r<1$ , or $|x-c|<R$ , and diverges if $1<r\leq\infty$ , or $|x-c|>R$ , which proves the result. I'm confused about factoring out $|x-c|$ in $(2)$ . According to the same lecture notes, this is only possible if $\left|\frac{a_{n+1}}{a_{n}}\right|$ converges. The author has specifically written that $\lim_{n\to\infty}\left|\frac{a_n}{a_{n+1}}\right|$ exists or diverges to infinity. This makes me wonder what $\left|\frac{a_{n+1}}{a_{n}}\right|$ converges to in those cases. To elaborate, consider the case $0<R<\infty$ . Then $$\lim_{n\to\infty}\left|\frac{a_{n+1}}{a_{n}}\right|=\lim_{n\to\infty}\frac1{\left|\frac{a_{n}}{a_{n+1}}\right|}=\frac1{R}.$$ Here I've used the rule that if $\lim_{n\to\infty} a_n$ and $\lim_{n\to\infty} b_n$ converge, and $\lim_{n\to\infty} b_n\neq0$ (which implies that there is some $N$ such that $b_n\neq0$ for $n>N$ ), then $\lim_{n\to\infty} (a_n/b_n)=\lim_{n\to\infty} a_n/\lim_{n\to\infty} b_n$ . But what about $R=0$ and $R=\infty$ ? Then what is $\lim_{n\to\infty}\left|\frac{a_{n+1}}{a_{n}}\right|$ ? Can we pull out $|x-c|$ nevertheless? Is the statement of the theorem complete as it is or does it lack anything?","['real-analysis', 'calculus', 'sequences-and-series', 'power-series', 'limits']"
4753585,Why are sine values in the 3rd quadrant negative?,"According to Sine - Wolfram Mathworld , Sine is defined as $$\sin(\theta) = \frac{\operatorname{opposite} (a)}{\operatorname{hypotenuse} (b)}$$ From that definition, I don't understand why the sine value in the unit circle in the 3rd quadrant is negative; after all, $a$ and $b$ should both be negative there and a positive quotient follows from this: People have already explained to me that b is always positive in this case, since it represents the radius and not a vector like a or c (not drawn in here now). Which leads me to the final question, how is one supposed to actually know that, based on the above definition? I mean it must be explicitly mentioned somewhere that $b$ in this case represents a length and $a$ , $c$ vectors that can take on both positive and negative values; the only thing I see on many pages is that a coordinate system is drawn into the unit circle and hence my obviously wrong assumption.",['trigonometry']
4753615,"Questions on $f(x)=\sum\limits_{n=1}^{\infty} \frac{(-1)^n\, (2 n+1)}{2 n!}\, \pi^n\, \frac{\zeta''(-2 n)}{\zeta'(-2 n)}\, x^{-2 n}$","Question (1) : Is there a closed form representation for the function $f(x)$ defined in formula (1) below? $$f(x)=\underset{N\to\infty}{\text{lim}}\left(\sum\limits_{n=1}^N \frac{(-1)^n\, (2 n+1)}{2 n!}\, \pi^n\, \frac{\zeta''(-2 n)}{\zeta'(-2 n)}\, x^{-2 n}\right)\tag{1}$$ Figure (1) below illustrates formula (1) for $f(x)$ above evaluated at $N=100$ . I suspect $f(x)$ defined in formula (1) converges for $x>0$ as $N\to\infty$ . Figure (1) : Illustration of formula (1) for $f(x)$ I know the values of $\zeta'(-2 n)$ are related to the values of $\zeta(2 n+1)$ as follows $$\zeta'(-2 n)=\frac{(-1)^n\, (2 n)!\, }{2\, (2 \pi)^{2 n}}\, \zeta(2 n+1)\tag{2}$$ which leads to the equivalent formula $$f(x)=\sum\limits_{n=1}^{\infty} \frac{4^n\, (2 n+1)}{n!\, (2 n)!}\, \pi^{3 n}\, \frac{\zeta''(-2 n)}{\zeta(2 n+1)}\, x^{-2 n}\tag{3}.$$ Question (2) : Is there a relationship between $\zeta''(-2 n)$ and $\zeta'(-2 n)$ (or $\zeta(2 n+1)$ ) analogous to formula (2) above? I'm not sure if it's making much progress, but I noticed the values of $\zeta''(-2n)$ seem to be related to $\zeta(2 n+1)$ and $\zeta'(2 n+1)$ as illustrated in the following table. $$\begin{array}{cc}
 s & \zeta ''(s) \\
 -2 & \frac{2 \zeta '(3)+\zeta (3) (3-2 (\gamma +\log (2 \pi )))}{4 \pi ^2} \\
 -4 & \frac{\zeta (5) (12 (\gamma +\log (2 \pi ))-25)-12 \zeta '(5)}{8 \pi ^4} \\
 -6 & \frac{180 \zeta '(7)-9 \zeta (7) (20 \gamma -49+20 \log (2 \pi ))}{16 \pi ^6} \\
 -8 & \frac{9 \left(\zeta (9) (280 (\gamma +\log (2 \pi ))-761)-280 \zeta '(9)\right)}{16 \pi ^8} \\
 -10 & \frac{45 \left(2520 \zeta '(11)+\zeta (11) (7381-2520 (\gamma +\log (2 \pi )))\right)}{32 \pi ^{10}} \\
 -12 & \frac{135 \left(\zeta (13) (27720 (\gamma +\log (2 \pi ))-86021)-27720 \zeta '(13)\right)}{32 \pi ^{12}} \\
 -14 & \frac{945 \left(360360 \zeta '(15)+\zeta (15) (1171733-360360 (\gamma +\log (2 \pi )))\right)}{64 \pi ^{14}} \\
 -16 & \frac{14175 \left(\zeta (17) (720720 (\gamma +\log (2 \pi ))-2436559)-720720 \zeta '(17)\right)}{32 \pi ^{16}} \\
 -18 & \frac{382725 \left(4084080 \zeta '(19)+\zeta (19) (14274301-4084080 (\gamma +\log (2 \pi )))\right)}{64 \pi ^{18}} \\
 -20 & \frac{9568125 \left(\zeta (21) (15519504 (\gamma +\log (2 \pi ))-55835135)-15519504 \zeta '(21)\right)}{64 \pi ^{20}} \\
\end{array}$$ I also noticed the integer part of the denominators in the table above seems to correspond to OEIS entry A189007 . After further investigation I believe the series representation of $f(x)$ defined in formula (1) above can be split into $f(x)=g(x)+h(x)$ where $$g(x)=\sum\limits_{n=1}^\infty \frac{(-1)^{n+1}\, (2 n+1)}{n!}\, \pi^n\, \frac{\zeta'(2 n+1)}{\zeta(2 n+1)} x^{-2 n}\tag{4}$$ which is the subject of my follow-on question and $$h(x)=\sum\limits_{n=1}^\infty \frac{(-1)^n\, (2 n+1)}{n!}\,  \pi^n \left(\gamma+\log(2 \pi)-H_{2 n}\right)\, x^{-2 n}\tag{5}$$ which I believe can be evaluated as $$h(x)=\frac{1}{2 x^2} e^{-\frac{\pi }{x^2}} \left(x^2 \, _1F_1^{(1,0,0)}\left(0,\frac{1}{2},\frac{\pi }{x^2}\right)-2 \pi  \, _1F_1^{(1,0,0)}\left(0,\frac{3}{2},\frac{\pi }{x^2}\right)+e^{\frac{\pi }{x^2}} \left(2 \pi  \, _1F_1^{(1,0,0)}\left(2,2,-\frac{\pi }{x^2}\right)-x^2 \, _1F_1^{(1,0,0)}\left(1,1,-\frac{\pi }{x^2}\right)\right)-2 \left(e^{\frac{\pi }{x^2}}-1\right) x^2 (\gamma +\log (2 \pi ))+\pi  (-4 \gamma +6-4 \log (2 \pi ))\right)\tag{6}.$$ This question is related to the inverse Mellin transform $\mathcal{M}_s^{-1}\left[\pi^{-\frac{s}{2}}\, (s-1)\, \Gamma\left(\frac{s}{2}+1\right) \frac{\zeta'(s)}{s\, \zeta(s)}\right]\left(\frac{1}{x}\right)$ which is clarified further in my follow-on question mentioned above.","['number-theory', 'closed-form', 'sequences-and-series', 'riemann-zeta', 'mellin-transform']"
4753625,Is $S_n=1!^{1!}+2!^{2!}+3!^{3!}+\cdots+n!^{n!}$ a perfect power if $n\geq2$,"Is $S_n=1!^{1!}+2!^{2!}+3!^{3!}+\cdots+n!^{n!}$ a perfect power when $n\geq2$ ? I know that: $S_n\equiv2\pmod{3}$ if $n\geq2$ , so $1!^{1!}+2!^{2!}+3!^{3!}+\cdots+n!^{n!}$ is never a perfect square if $n\geq2$ . $S_n\equiv5\pmod{9}$ if $n\geq2$ , so it is not a perfect cube if $n\geq2$ . The last 2 digits of $S_n$ is $37$ if $n\geq5$ , so $S_n$ cannot be a perfect 5th power, since $37$ is not a 5th power residue $\pmod{100}$ . But can $S_n$ be a higher odd prime perfect power?","['number-theory', 'perfect-powers']"
4753629,"Example of a sequence that is Cauchy in a stronger norm and convergent in a weaker norm, but not convergent in the stronger norm?","A norm $\|\cdot\|_1$ on a normed vector space is called stronger than $\|\cdot\|_2$ when $\|x\|_2\leq M\|x\|_1$ for some $M>0$ and all $x$ . It is a standard trick (e.g. in proving completeness) to find the limit in a weaker sense first, and then prove that it is a stronger limit, e.g. Cauchy in Norm and Weakly converge Implies Norm convergent . But it always uses some extra information beyond one convergence being weaker than the other. Examples in Cauchy sequence converge for one metric while not converging for another? are not for norm metrics, hence the question.","['cauchy-sequences', 'convergence-divergence', 'normed-spaces', 'functional-analysis']"
4753667,"When we say limit in probability, what do we mean?","We have a parameter $\theta$ and an estimator $\hat{\theta}$ . There are various ways to define consistency, this is one I've seen often. $\hat{\theta_n}$ , where $n$ indexes the sample size, is consistent for $\theta$ if $$
\lim_{n \to \infty} P( |\theta - \hat{\theta}| > \epsilon) = 0, \forall \epsilon >0.
$$ Now $\hat{\theta}$ is a random variable with a distribution, so it's a ``spread out'' thing, and I don't see any way for the distribution (even in probability) to equal a single value. Do we mean by this statement that the probability that the difference between a value drawn from $\hat{\theta_n}$ and $\theta$ is greater than $\epsilon$ is zero? If yes, then good, I can understand that. If not, I'm lost.","['limits', 'statistics']"
4753730,Asymptotics of $\displaystyle{\sum_{i=0}^n\sqrt{i(n-i)}}$ as $n\to+\infty$,"I am studying a bit of asymptotics and for practice I decided to find the asymptotic of the following, $$s(n)=\sum_{i=0}^n\sqrt{i(n-i)}$$ as $n\to\infty$ . This comes directly from this post , where @Gary provided some hints in the comments: $${\rm Li}_{-1/2}^2(z)=\left(\sum_{n=0}^\infty \sqrt nz^n\right)\left(\sum_{n=0}^\infty \sqrt n z^n\right)=\sum_{n=0}^\infty\underbrace{\sum_{i=0}^n \sqrt{i(n-i)}}_{s(n)}z^n$$ but I am unable to finish the problem with this method  as I don't know how to find the $n$ th Maclaurin coefficient. Feel free to also use any other methods to find the asymptotics (maybe Euler-Maclaurin), but such an answer will preferably come after the original issue is resolved . As a bonus, a derivation of the complete asymptotic expansion of $s(n)$ will also be nice to see. Sorry for the long question. To outline: How to find the $n$ th Maclaurin Coefficient? Alternative methods to find asymptotics? Complete asymptotic expansion? My attempt is below. By $(25.12.12)$ , $$\begin{align*}{\rm{Li}}_{-1/2}(z)&=\frac{\sqrt\pi}{2}(-\log\left(z\right))^{-3/2}+\sum_{n=0}^\infty\frac{\zeta(-1/2-n)}{n!}\log^n(z)
\end{align*}$$ which by Taylor's formula, $$\begin{align*}
{\rm Li}_{-1/2}^2(z)&=-\frac{\pi}{4\log^3(z)}+\sum_{n=0}^\infty(-1)^n\sqrt\pi\frac{\zeta(-1/2-n)}{n!}(-\log(z))^{n-3/2}+F(z) \\
&=\frac{\pi}{4(1-z)}+\sum_{n=0}^\infty(-1)^n\sqrt\pi\frac{\zeta(-1/2-n)}{n!}(-\log(z))^{n-3/2}+G(z)
\end{align*}$$ as $z\to1$ , where $F(z),G(z)$ are holomorphic at $z=1$ . Expanding the first term by its geometric series, $$\sum_{n=0}^\infty\left(s(n)-\frac{\pi}{4}\right)z^n=\sum_{n=0}^\infty(-1)^n\sqrt\pi\frac{\zeta(-1/2-n)}{n!}(-\log(z))^{n-3/2}+G(z)$$ as $z\to 1$ . Now the RHS is, $$\sqrt\pi\zeta(-1/2)(-\log(z))^{-3/2}-\sqrt\pi\zeta(-3/2)(-\log(z))^{-1/2}+O\left(\sqrt{\log(z)}\right)$$ as $z\to1$ , which by Taylor's formula, $$\sqrt\pi\zeta(-1/2)(1-z)^{-3/2}+\sqrt\pi\left(\zeta(-3/2)-\frac{3}{4}\zeta(-1/2)\right)(1-z)^{-1/2}+O\left((1-z)^{1/2}\right)$$ as $z\to1$ . Now all that is left is to extract the $n$ th Maclaurin coefficient of the function above as, $$s(n)=[z^n]{\rm Li}_{-1/2}^2(z).$$","['special-functions', 'singularity', 'asymptotics', 'taylor-expansion', 'sequences-and-series']"
4753739,The directional derivative equals dot product of gradient and a unit vector. But what if the function is not totally differentiable?,"The directional derivative is the dot product of gradient and a unit vector. But what if the function is not totally differentiable? Is it an implicit assumption that formula only applies to totally differentiable functions? Apostol Volume 2 does not really explicitly spell it out, and I am convinced that the formula only holds when the function is totally differentiable, I just want some confirmation in this regard. Furthermore, in many problems when the directional derivate is being asked to be computed, the author simply invokes the above formula, without PROVING total differentiability. So this then begs the question: Does the formula make any sense if the function is not totally differentiable? In other words, is the gradient a concept that 'exists' on its own or is defined 'through' total differentiability, and therefore implicitly subsumes the prerequisite of total differentiability?","['partial-derivative', 'multivariable-calculus', 'vector-analysis', 'real-analysis']"
4753783,Why is the following limit not 1?,"Consider $$\lim_{n\to\infty} f(n)=\lim_{n\to\infty}\frac{(n!)!}{(n!-n)!}\tag{1}$$ For large $n$ , one can ignore $n$ wrt. $n!$ in the denominator. The limiting value should therefore approach $1$ . However, as the plot shows, the limit blows up. Why is that?","['limits', 'factorial', 'approximation']"
4753793,"Given the function $f(x)=\left(3x^{\frac75}\!-\!\frac{\pi}x\right)\!\cdot\!\cos\left(\frac{\pi}2\!-\!x\right)$. Calculate $\,\lim\limits_{x\to0}f(x)$","Given the function $f(x)=\left(3x^{\frac75}\!-\!\dfrac{\pi}x\right)\!\cdot\!\cos\left(\dfrac{\pi}2\!-\!x\right)$ . Calculate the limit $\,\lim\limits_{x\to0}f(x)\;.$ So I started by using the definition of the derivative that $$f'(x_{0})=\lim_{x \to x_{0}}\frac{f(x)-f(x_{0})}{x-x_0}$$ after doing that I tried to set $x_{0} = 0$ since then u get the limit to $x \to 0$ , but the problem is that $f(0)$ is not defined, because if I substitute $x=0$ in the function I get $f(0)=(0-\infty)\cdot{}0$ which is undefined, same goes for $f'(0)$ Now I can't seem to find the solution, so I'm asking the question here","['limits', 'calculus', 'derivatives']"
4753835,How to find the speed to maximise the distance travelled,"I'm given that a car travels at speed along its track it uses fuel at a rate of $R(v)=17‌v^2 –7v+7$ , in litres per sec. Where $v$ is the speed in metres per second.
The fuel tank holds $Y$ litres of fuel: $$Y = \int_{0}^{T}  R(v(t))\,dt$$ $v(t)$ is the speed as a function of the time. I found the speed to maximise the time the car travels under power which was $v = 7/34$ . How should I find the what constant speed the car must run to maximize the distance $vT$ that it runs under power? Any help would be great, thank you. Edit: I integrated $Y = \frac{17T^3}{3} - \frac{7T}{2} +7T$ , I'm not sure what else to do, after following Nurator's suggestion. Calculus is my weakest topic.","['integration', 'multivariable-calculus', 'calculus', 'partial-differential-equations', 'derivatives']"
4753891,"Integral: $\displaystyle\int_0^1\!\frac{x}{\operatorname{artanh} x} \, {\rm d}x\overset{?}{=}\frac{7\zeta(3)}{\pi^2}$","I cannot prove that: $$ \int_0^1 \! \frac{x}{\operatorname{artanh} x} \, {\rm d}x = \frac{7 \, \zeta(3)}{\pi^2} $$ where $\operatorname{artanh}$ is the inverse hyperbolic tangent function, and $\zeta$ is the Rieman zeta function. This integral is equivalent to the following integrals: $$ \int_1^\infty \! \frac{{\rm d}x}{x^3 \operatorname{arcosh}x} ,\quad \int_0^1 \! \frac{x}{\operatorname{arsech}x} \, {\rm d}x $$ Also, increasing the order of the integrand yields: $$ \begin{align} \int_0^1 \! \frac{x^2}{\operatorname{artanh}^2 x} \, {\rm d}x &= \frac{124 \, \zeta(5)}{\pi^4} - \frac{14 \, \zeta(3)}{3\pi^2} \\[3pt] \int_0^1 \! \frac{x^3}{\operatorname{artanh}^3 x} \, {\rm d}x &= \frac{1905 \, \zeta(7)}{\pi^6} - \frac{124 \, \zeta(5)}{\pi^4} \\[3pt] \int_0^1 \! \frac{x^4}{\operatorname{artanh}^4 x} \, {\rm d}x &= \frac{28616 \, \zeta(9)}{\pi^8} - \frac{2540 \, \zeta(7)}{\pi^6} + \frac{124 \, \zeta(5)}{5\pi^4} \end{align} $$ Sorry for my bad English.","['integration', 'riemann-zeta', 'discrete-mathematics']"
4753908,Show that $\arcsin(\frac{x-1}{x+1})=2\cdot\arctan(\sqrt{x})-\frac{\pi}{2}$,"So I started by saying that $$y=\arcsin\left(\frac{x-1}{x+1}\right)$$ Then you could say that $$\sin(y)=\frac{x-1}{x+1}$$ Then calculating $\cos(y)$ with the trigonometric identity, I found the following: $$\cos(y)=\frac{x-1}{2\sqrt{x}}$$ If I then calculate $\tan(y)$ and take the inverse of that I hoped to find the right hand side, but instead I found $$\arctan\left(\frac{x-1}{2\sqrt{x}}\right)$$ Now I used wolfram to check if they are equal and it gives a solution so I'm guessing an intersection at $x=1$ . There also is an extra question that asks for what real value of $x$ this expression makes sense.","['calculus', 'inverse-function', 'trigonometry', 'transcendental-functions']"
4753929,Is the equation $\sec (\pi/2)$= $\tan (\pi/2)$ true?,"While both $\sec (\pi/2)$ and $\tan (\pi/2)$ are undefined they are both basically $1/0$ . In case anyone is unaware of how they equal $1/0$ what we can do is represent $\sec (\pi/2)$ as $\dfrac {1}{\cos (\pi/2)}$ and $\tan (\pi/2)$ as $\dfrac {\sin \pi/2}{\cos \pi/2}$ and once you put in the value they both become $\dfrac {1}{0}$ . The problem is that if $\sec (\pi/2)$ does equal $\tan (\pi/2)$ then the following should be true as well: $\sec (\pi/2)$ = $\tan (\pi/2)$ $\sec^2 (\pi/2) = \tan^2 (\pi/2)$ [By squaring both sides] $\sec^2 (\pi/2) - \tan^2 (\pi/2)$ = 0 [By subtracting $\tan^2 \pi/2$ from both sides] $1 = 0$ [By using the formula $\sec^2 \phi - \tan^2 \phi$ = 1] This is obviously false and from my understanding the problem is either - (i) As I first said, maybe $\sec \pi/2 \neq \tan \pi/2$ (ii) We cannot use the formula $\sec^2 \phi - \tan^2 \phi$ for $\phi = k \pi  + \pi/2$ (where $k \in \mathbb {Z}$ ). This is all from my side, I would still like to mention that I am an highschool kid and might be unaware of rules as school only teaches very limited things and I don't have an consistent method of self studying topics like trigonometry, calculus (please suggest beginner books for calculus if you can), etc. Also this was my first ever question so if there is something that could be changed in the way I am submitting the question please suggest that. Thank you.","['limits', 'trigonometry']"
4753935,Simplifying a summation. Binomial theorem.,"Simplify the sum $$
\sum_{
\substack{
i, j, k \geq 0 \text{ and }
i+j+2k=r
}}
(-1)^i \binom{n}{i} \binom{n}{j} \binom{n}{k} 
$$ for n, r $\in$ N . I know that it can be simplified to $$
[x^r] (1+x)^n(1-x)^n(1+x^2)^n = [x^r] (1-x^2)^n(1+x^2)^n = [x^r] (1-x^4)^n
$$ which gives $\binom{n}{\frac{r}{4}} (-1)^{\frac{r}{4}}$ if $4|r$ and $0$ otherwise. But how do I get to that point? I tried writing $$
\sum_{n} \left( \sum_{i} (-1)^i \binom{n}{i}   \sum_{j}   \binom{n}{j}   \sum_{k}  \binom{n}{k} \right)x^n
$$ so I can use binomial theorem, but then I would need three $x^n$ 's total to use theorem three times. Thanks.","['summation', 'binomial-theorem', 'discrete-mathematics']"
4753942,Evaluating $\int_{0}^{\infty}\frac{\ln\left(x\right)\left(e^{-x}-\cos x\right)}{x}dx$,"From here after the partial fractions in the question : $$I = \int_{0}^{\infty}\frac{\ln\left(x\right)\left(e^{-x}-\cos x\right)}{x}dx$$ I tried this via contour integration but ran into some problems with the choice of contours and the convergence of the circular arcs. I'm not sure if I need a branch cut yet, but that doesn't affect this integral. Going anticlockwise and having $z=Re^{i\theta}$ : $$\begin{align}\int_{\Gamma}&=\int_{0}^{\pi}{\frac{\ln(Re^{i\theta})(e^{-Re^{i\theta}}-e^{iRe^{i\theta}})}{Re^{i\theta}}iRe^{i\theta}\, d\theta}\\&=i\int_{0}^{\pi}(\ln(R)+i\theta)(e^{-Re^{i\theta}}-e^{iRe^{i\theta}})\,d\theta\end{align}$$ But I don't think this converges given $R\to\infty$ . Should a different contour be used or can this be continued?","['complex-analysis', 'contour-integration']"
4753963,Problem solving strategies for Measure theory (soft question),"I'm a beginner in learning Measure theory. I would like to ask are there some common problem solving tricks in Measure theory. For example, usually when I'm doing a measure theory problem, once I rewrite a set into simpler sets, the question is basically solved. So I guess an example trick would be ""measure theory problems are mostly about rewriting sets"". Also, the following seems to be a general procedure for proving integral identities/theorems: prove it for indicators $1_A$ linearity proves it for simple functions monotone convergence theorem proves it for non-negative measurable functions Are there any other tricks? Also, are my tricks common/useful? Many thanks in advance.","['measure-theory', 'lebesgue-integral', 'analysis', 'real-analysis', 'soft-question']"
4754018,"Sum of two random variables as a sum of functions, fallacy in logic","This might be a silly newbie question, but could you please help me find the fallacy in my logic? Consider binomial distributions X ~ Bin(10, p) and Y ~ Bin(15, p). Since random variables are functions taking a random outcome as input, X + Y is also a function. If we view it as a sum of functions, (X + Y)( a ) = X( a ) + Y( a ) where a is a random outcome in the sample space. As I understand, in binomial distribution the outcome a could be some number of successes (e.g. 5). But since we are evaluating X and Y at the same point a how could we view this sum as the total number of successes in the combined experiment? Or should I view a different for both X and Y? How should I think about it as a sum of two functions?",['probability-theory']
4754021,Two perpendicular diameters $AB$ and $CD$ are considered on a circle. Let $M$ be a point on $BC$. Prove that $AN=MN+MB$.,"Problem Two perpendicular diameters $AB$ and $CD$ are considered on a circle with centre $O$ . Let $M$ be a point on the small arc $BC$ . The parallel drawn through $O$ to $MD$ intersects $AM$ in $N$ . Prove that $AN=MN+MB$ . The drawing My idea As you can see I noted $\angle OMD=x$ . Because $NO$ is parallel with $MD$ , we can say that $\angle OMD= \angle NOM=x$ $MO=OD=R => \angle OMD= \angle ODM= x$ We can simply realise that $ \angle COM= \angle ODM*2 => \angle NOC=x$ Because $NO$ bisects $\angle MOP$ we can apply the bisector theorem: $\frac{PN}{MN}=\frac{PO}{MO}$ I also thought that triangles $NOA$ and $MBD$ are similar. I don't know what to do forward. Hope one of you can help me! Thank you!","['triangles', 'angle', 'circles', 'geometry']"
4754023,Saveliev Illustrated Topology question on locked hands,"Exercise 1.4 on Saveliev ""Illustrated Topology"" gives a picture of locked hands and asks how can we unlock them without breaking the loops. I've thought about it and couldn't find a way. I'd appreciate a hint. Is it even possible?",['general-topology']
4754054,"Re-arrangements of $(1,1,2,2,3,3,4,4)$ with $(1,2,3,4)$ as a subsequence","In how many ways is it possible to re-arrange the sequence $(1,1,2,2,3,3,4,4)$ , such that $(1,2,3,4)$ is a subsequence of it? In case the question is not clear: what is the number of functions $f\negthinspace : [8]\to [4]$ , such that for all $j \in [4]$ there exist exactly two elements $i_1,i_2\in [8]$ s.t. $f(i_1)=f(i_2)=j$ , and s.t. there exists $i_1<i_2<i_3<i_4$ in $[8]$ with $f(i_1)<f(i_2)<f(i_3)<f(i_4)$ ? I have tried to solve this using the inclusion-exclusion principle, but I couldn't really find the appropriate sets to take. I also tried to give it a recursive formula, but again failed. I brute-force calculated the final result to be $641$ . EDIT: the code I used is import numpy as np
from collections import Counter

def has_subsequence(sequence, subseq, start_index=0):
    if len(subseq) == 1:
        return sequence.find(subseq[0], start_index) >= 0
    if len(sequence) <= len(subseq):
        return sequence == subseq

    char_index = sequence.find(subseq[0], start_index)
 
    if char_index == -1:
        return False
    return has_subsequence(sequence, subseq[1:], char_index + 1)

def count_perms_of_00112233_with_substring_0123():
    count = 0
    for sequence in (np.base_repr(i, base=4).zfill(8) for i in range(4**8 + 1)):
        if all(count_i == 2 for count_i in Counter(sequence).values()):
            if has_subsequence(sequence, ""0123""):
                count += 1

    print(""Number of valid sequences:"", count)","['inclusion-exclusion', 'combinatorics']"
4754077,How many paths of length $n$ with given beginning and end are there in the graph?,"Given a graph $G = (V, E)$ , with a set of vertices: $V = \mathcal{P}( \{1, 2, 3 \})$ and a set of edges: $$E = \{ \{A, B \} : A, B \subseteq \{1, 2, 3 \} \wedge |A \bigtriangleup B| = 1 \}$$ *where: $A \bigtriangleup B = (A \setminus B) \cup (B \setminus A)$ is the symmetric difference of sets $A$ and $B$ $\mathcal{P}(X)$ is a set of all subsets of $X$ How many paths $(A_0, A_1, ... A_n)$ of length $n \geq 3$ are there in the graph $G$ with a beginning at vertex $A_0 = \{ 1, 2, 3 \}$ and an end at vertex $A_n = \emptyset$ (all vertices, including the end vertex, may repeat)? As I understand it - we have vertices $8$ vertices, those are: { {1, 2, 3}, {1, 2}, {1, 3}, {2, 3}, {1}, {2}, {3}, { } }. We have $12$ edges and those are: $\{1, 2, 3\} - \{1, 2\}$ , $\{1, 2, 3\} - \{1, 3\}$ , $\{1, 2, 3\} - \{2, 3\}$ , $\{1, 2 \} - \{1 \}$ , $\{1, 2 \} - \{2 \}$ , $\{1, 3 \} - \{1 \}$ , $\{1, 3 \} - \{3 \}$ , $\{2, 3 \} - \{2 \}$ , $\{2, 3 \} - \{3 \}$ , $\{1 \} - \{ \}$ , $\{2 \} - \{ \}$ , $\{3 \} - \{ \}$ . The graph should therefore look like that: The paths that I see working for $n = 3$ are: $\{1, 2, 3\} - \{1, 3\} - \{ 3 \} - \{ \}$ , $\{1, 2, 3\} - \{1, 3\} - \{ 1 \} - \{ \}$ , $\{1, 2, 3\} - \{2, 3\} - \{ 3 \} - \{ \}$ , $\{1, 2, 3\} - \{2, 3\} - \{ 2 \} - \{ \}$ , $\{1, 2, 3\} - \{1, 2\} - \{ 1 \} - \{ \}$ , $\{1, 2, 3\} - \{1, 2\} - \{ 2 \} - \{ \}$ , There are $6$ of them. Hovever, I don't see any clever way to count them for a chosen $n$ . Edit: The adjacency matrix of that graph looks like that: the rows / columns: $\{1, 2, 3\}$ $\{1, 2\}$ $\{1, 3\}$ $\{2, 3\}$ $\{1 \}$ $\{2 \}$ $\{3 \}$ $\{ \}$ Therefore the matrix looks like that: $
M = 
\begin{pmatrix}
0 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 1 & 1 & 0 & 0\\
1 & 0 & 0 & 0 & 1 & 0 & 1 & 0\\
1 & 0 & 0 & 0 & 0 & 1 & 1 & 0\\
0 & 1 & 1 & 0 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 1 & 0 & 0 & 0 & 1\\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 1 & 1 & 1 & 1\\
\end{pmatrix}
$ But then it's tp hard to diagonalize...","['graph-theory', 'discrete-mathematics']"
4754080,Counting problem about polygon triangulations,"I have the following question about triangulations (by non-intersecting diagonals, and edges) of regular polygons. What is the number of triangulations of a regular n-gon, up to all symmetry (i.e. the whole dihedral group)? For instance, if one discards symmetry, then the answer is the (n-2) Catalan number. If one only considers rotational symmetry, answer is given here . The obvious approach is to apply Burnside/Polya, but I don't see a clear pattern on the cases that would show up for an arbitrary n. I would like to know where to go from here. Thanks!!","['triangulation', 'geometry', 'polya-counting-theory', 'combinatorial-geometry', 'combinatorics']"
4754088,Definition of a non-split root subgroup,"I've been reading through Tits's Corvallis survey ""Reductive groups over a local field"" and something that surprised me that was taken for granted about the definition of root subgroups. Let $G$ be a reductive group over a local field $K$ with $K$ -split maximal torus $S$ . Given a relative root $\alpha \in \Phi(G,S)$ , we of course have a root subgroup $U_\alpha$ . However, none of the possible definitions of root subgroups I am aware of are adequate in general, in particular if both $\alpha$ and $2\alpha$ are relative roots. The thing that surprised me most initially is the implication that always $U_{2 \alpha} \subset U_\alpha$ , which is something I don't see how to justify in general. So the main question I'm asking is, how is $U_\alpha$ defined? To illustrate the issue, consider the simplest case possible: Let $G$ be the quasi-split form of $\mathrm{SU} _3$ for a quadratic, separable extension $L/K$ . Then $G$ consists of the $L$ -linear transformations of $L^3$ preserving the hermitian form $h(v_1, v_2, v_3) = v_1 \bar v_3 + v_2 \bar v_2 + v_3 \bar v_1$ , where $\bar v$ is the Galois conjugate of $v \in L$ . In terms of matrices, we have $g \in G$ if $g \in \mathrm{Res} _ {L/K} (\mathrm{SL} _3)$ and $g^\dagger J g = J$ where $g^\dagger$ is the transpose-Galois conjugate of $g$ and $$
J = \begin{bmatrix}
0&0&1\\
0&1&0\\
1&0&0
\end{bmatrix}.
$$ One maximal $K$ -split torus $S$ consists of the matrices of the form $$
\begin{bmatrix}
a & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1/a
\end{bmatrix},
\qquad
a \in K.
$$ Then $\Phi(G, S)$ is of type $BC_1$ : there are $4$ relative roots of $(G, S)$ , and the two positive roots differ by a scalar multiple of $2$ . Denote the non-divisible positive root $\alpha$ the divisible one $2\alpha$ , where $B$ is taken as the upper triangular matrices in $G$ . In $\mathfrak g$ , the Lie algebra of $G$ , the root subalgebra $\mathfrak g_\alpha$ consists of matrices of the form $$
\begin{bmatrix}
0 & -\bar c & 0 \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix},
\qquad
c \in L,
$$ and $\mathfrak g_{2\alpha}$ consists of matrices of the form $$
\begin{bmatrix}
0 & 0 & d \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\qquad
d \in L
\text{ such that } d + \bar d = 0.
$$ There are 3 ways I'm aware of to define $U_\alpha$ : one using the exponentials of the Lie algebra, one using root homomorphisms, and one using the semisimple subgroup $G_\alpha$ given as the derived subgroup of a certain Levi (but this last one is certainly not correct for non-reduced root systems). From what I've seen, the exponential definition gets closest, but I'm still not happy with it. I would like to define $U_\alpha$ as $\exp{(\mathfrak g_\alpha)}$ in general for a relative root $\alpha$ . This would always lead to $U_\alpha \cap U_{2\alpha} = \{1\}$ , as $\mathfrak g_\alpha \cap \mathfrak g_{2\alpha} = 0$ . However, working through the example above, one can see that $\exp{(\mathfrak g_\alpha)}$ is not a subgroup of $\mathrm{SU} _3$ for the non-divisible $\alpha$ . So the next guess would be to define $U_\alpha$ as the subgroup of $G$ generated by $\exp{(\mathfrak g_\alpha)}$ . If this is the correct definition, why is it always true that $U_{2\alpha} \subset U_\alpha$ ? Although that's true in this case, it seems totally plausible that for a non-divisible root $\alpha$ , sometimes $\exp{(\mathfrak g_\alpha)}$ might be closed under group multiplication. It's also a bit unsatisfying because the exponential map is not defined in general in positive characteristic, and in particular if $\mathrm{char}(K) = 2$ , then it's not defined for $\mathfrak g_{\alpha}$ above. The next definition involves root homomorophisms. If one can find a define an injective homomorphism $u_\alpha: \mathbb G_a^n \to G$ such that $t u_\alpha(x) t^{-1} = u_\alpha(\alpha(t)\cdot x)$ for all $t \in S$ and $x \in \mathbb G_a^n$ , then the image of $u_\alpha$ would seem to be a pretty good candidate for $U_\alpha$ . However, in $\mathrm{SU} _3$ , this is not possible for the non-divisible root $\alpha$ . I think in general there's a scheme map from the additive group on $\mathfrak g_\alpha$ to $G$ that coincides with the exponential (or the closest thing possible given $K$ ), but since $\exp{(\mathfrak g_\alpha)}$ isn't necessarily a subgroup, this map is not a homomorphism. The root homomorphism Tits uses for $\mathrm{SU} _3$ is $$
u_1(c, d) =
\begin{bmatrix}
1 & -\bar c & d \\
0 & 1 & c \\
0 & 0 & 1
\end{bmatrix},
\qquad
c, d \in L
\text{ such that }
c\bar c + d + \bar d = 0,
$$ which has the property that $t u_1(c, d) t^{-1} = u_1(\alpha(t) \cdot c, 2\alpha(t) \cdot d)$ . This is clearly almost as good as the property I defined above and is consistent with $U_{2\alpha} \subset U_\alpha$ . However, it seems to take this subset property for granted, and doesn't seem ideal for a definition of a root homomorphism for a non-divisible root—it seems more like a consequence of a different definition like exponentiation. So what is the correct definition? Should I start with a root homomorphism or the Lie algebra, and either way, how can I make sure my definition always works?","['lie-algebras', 'reductive-groups', 'representation-theory', 'local-field', 'algebraic-geometry']"
4754162,Prove Kepler's second law of planetary motion,"An object moves in $\mathbb R^3$ it's position $r(t)$ satisfies $$r''(t) = s(t)r(t)$$ for some scalar function $s$ (a central force field, in which all acceleration is directly towards or opposite the origin).  Show that (i) it's motion is confined to a plane and (ii) it sweeps out equal areas in equal time (Kepler's second law). My solution is below, to which I request verification and suggestions. Of course, solutions exist, as this problem is centuries old; this question is to verify or improve this solution. Solution: We first prove claim (i): the object's motion is confined to a plane. The object starts with arbitrary position $r(0)$ and velocity $r'(0)$ .  Let their span (which is a plane, a line, or the origin) be $S$ .  Clearly, $r''(0) \in S$ .  Since $r''$ has no component orthogonal to $S$ , $r'$ remains in $S$ , and therefore $r$ remains in $S$ . [1] To prove claim (ii), we introduce $x(t), y(t), z(t),$ and $s(t)$ and, to lighten notation, will omit writing the $(t)$ .  Assume WLOG that the object's plane is the $xy$ plane so $z = 0$ .  We then have $$\frac{\partial^2 x}{\partial t^2} = sx \\ \frac{\partial^2 y}{\partial t^2} = sy \\ z = 0.$$ The rate that area is swept, $a(t)$ , is proportional to $r(t) \times r'(t)$ , so $$a(t)k = x \frac{\partial y}{\partial t} - y \frac{\partial x}{\partial t}.$$ But $$\begin{align*}
\frac{\partial a}{\partial t} &= x\frac{\partial^2 y}{\partial t^2}+\frac{\partial x}{\partial t}\frac{\partial y}{\partial t} - \frac{\partial y}{\partial t}\frac{\partial x}{\partial t} -  y\frac{\partial^2 x}{\partial t^2}\\
&= xsy - ysx \\
&= 0
\end{align*}$$ and therefore $a(t)$ is constant, completing the proof. Note: [1] While geometrically clear, I'm having trouble making this point rigorous.  I believe it requires the MVT, but I couldn't apply it successfully.  I also tried some form of ""continuous induction"" using arbitrary small values of $\Delta t$ , but this failed to achieve rigor as well.  Or is how I've written it good enough?","['mathematical-astronomy', 'multivariable-calculus', 'solution-verification', 'vector-analysis', 'physics']"
4754198,Find points on internally tangent circle,"I'm working on an algorithm to allow a vehicle to reverse and then line up and stop on a given spot facing a specific direction. The best approach I've been able to come up with involves two internally tangent circles with the larger extending from the point of tangency of the vehicle. Vehicle starts at point A and is parallel with tangent line T. Vehicle reverses to B, then moves forward to C, then to A so that it is parallel with the vector displayed instead. r represents the minimum turning radius of the vehicle Given that line AC is always arranged vertically and knowing point A, but that the tangent line T can vary, is it possible to be able to determine points B and C? If not what other info is needed? Medium tangent Steep tangent Shallow tangent For simplicity I've made it so that the radius of the larger circle is twice the radius of the smaller. If this restriction is not required to solve the problem how could this larger radius be determined as well?","['tangent-line', 'circles', 'geometry']"
4754224,How did Scott Chase find the only solution to eighth powers $x_1^8 + x_2^8 + x_3^8 + x_4^8 + \dots + x_8^8 = 1409^8$ back in 2000?,"This is a follow-up to $6$ th powers of form $(6,1,7)$ in this post . For $8$ th powers of form $(8,1,9)$ , we already have a solution with $x_1=0$ , $$190^8 + 284^8 + 348^8 + 366^8 + 558^8 + 560^8 + 1040^8 + 1094^8 + 271^8 = 1167^8$$ $$\quad \color{red}{0^8} + 90^8 + 478^8 + 524^8 + 748^8 + 1088^8 + 1190^8 + 1324^8 + 223^8 = 1409^8$$ with the first by Nuutti Kuosa, and the second by Scott Chase found in 2000. ( Update : My thanks to John Ca for bringing to my attention the first which was not in Meyrignac's database http://euler.free.fr/database.txt but was in Mathworld .) Note that $1167 \equiv 0\, \text{(mod 3)},$ while $1409 \not\equiv 0\, \text{(mod 3)}$ and I assume it is the $2$ nd type that we can find a zero term, a result semi-analogous to $(6,1,7)$ . Re-arranging terms, we get the more informative, $$4^8(71^8 + 87^8 + 140^8 + 260^8) + 2^8(95^8 + 183^8 + 279^8 + 547^8) + 271^8 = 1167^8$$ $$4^8(131^8 + 187^8 + 272^8 + 331^8) + 2^8( \color{red}{0^8}+ 45^8 + 239^8 + 595^8) + 223^8 = 1409^8$$ with the unexpected (?), $$1167-271 \equiv \text{0 mod 32}\quad$$ $$1409+223 \equiv \text{0 mod 32}\quad$$ and the expected, $$z^8-x_9^8 \equiv \text{0 mod 256}\quad$$ Assume primitive solutions. Compare to the more hefty congruence restrictions for $6$ th powers of form $(6,1,6)$ , $$42^6(x_1^6+x_2^6+x_3^6+x_4^6)+(7x_5)^6+x_6^6 = z^6$$ with the huge constraint, $$\qquad z^6-x_6^6 \,\equiv\, \text{0 mod 117649}$$ where $7^6=117649.\,$ This huge mod $(k+1)^k$ constraint for $(k,1,k)$ exists when $k+1 = p$ is prime which partly explains why $k=6$ hasn't been found yet. For $k=4$ , the smallest is, $$15^4(2^4 + 8^4 + 21^4) + 272^4 = 353^4$$ where $272+353 = 625 = 5^4.$ This special case has a $(6,1,7)$ analogue, $$42^6(32^6 + 554^6 + 1145^6 + 1289^6) + 7^6(3609^6 + 5584^6) + 54018^6 = 63631^6$$ where $54018+63631 = 117649 = 7^6.$ Questions: Assume a primitive solution to $(8,1,8)$ . Did S. Chase found this only solution with the slow computers of more than 20 years using brute force and/or some congruence $x_8^n\pm z^n \equiv \text{0 (mod w)}$ to speed up the search? If so, with more computing power nowadays, surely  we can find another one for both (8,1,8) and (8,1,9)?","['computational-mathematics', 'number-theory', 'modular-arithmetic', 'diophantine-equations']"
4754276,Can we generalize the idea of spatially coupled gaussian matrices to rotationally invariant matrices?,"Setup: An $(\omega,\Lambda)$ base matrix $W\in\mathbb{R}^{R\times C}$ is described by the coupling width $\omega\geq1$ and the coupling length $\Lambda\geq2\omega-1$ . The matrix has $R=\Lambda+\omega-1$ rows and $C=\Lambda$ columns, with the $(r,c)$ -th entry of the matrix, where $r\in\{1,\dots,R\}$ and $c\in\{1,\dots,C\}$ , given by $$
W_{rc}=
\begin{cases}
1/\omega &\text{if $c\leq r\leq c+\omega-1$,} \\
0 &\text{otherwise.}
\end{cases}
$$ It is known that we can create a Gaussian spatially coupled matrix $A\in\mathbb{R}^{n\times p}$ (visually, a band diagonal matrix), in the following way: First specify a base matrix $W$ of dimensions $R\times C$ . Replace each entry of the base matrix $W_{rc}$ with an $\frac{n}{R}\times\frac{p}{C}$ matrix with entries drawn i.i.d. $\sim N\big(0,\frac{W_{rc}}{n/R}\big)$ . I would like to extend this idea to rotationally invariant matrices $A$ where $$
A=O^\top\Gamma Q \in\mathbb{R}^{n\times p},
$$ where $\Gamma=\text{diag}(\lambda)$ where $\lambda$ are the singular values, and $O$ and $Q$ are independent Haar orthogonal matrices. Motivation: This would allow us to design more general codes for communication etc. Question: Can we use the same approach of replacing entries of the base matrix $W$ to produce a band diagonal (spatially coupled) matrix $A$ where each sub-matrix of non-zero entries $\widetilde{A}$ in $A$ can be written in the form of $\widetilde{A}=\widetilde{O}^\top\widetilde{\Gamma}\widetilde{Q}$ (where $\widetilde{O}$ , $\widetilde{\Gamma}$ , and $\widetilde{Q}$ are some matrices)? Refer to the image below for a visual representation of my question. If so, then how can I do it? Thanks.","['statistics', 'information-theory', 'matrices', 'random-matrices', 'coding-theory']"
4754307,Proof that a recursively defined sequence is divergent,"Let $x_1=1$ and $x_{n+1}=\frac{3}{x_n}$ for $n\ge 2$ (correction: $n\ge 1$ ). Then $(x_n)$ diverges. I have gone through the proof of convergent sequences generally in this format and they are proved using monotone convergence theorem, through mathematical induction it is proven that all the elements are below a said value and then proven to be increasing or decreasing and thereby convergent. I am confused on how to go about applying a similar approach over here, the sequences is most definitely bounded and has lower bound 1 and upper bound 3, but how do I prove the same and then later on prove that the function is not monotonic therefore not convergent?","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
4754310,Prove that $\lim\limits_{n\to+\infty}\sum\limits_{i=1}^n\prod\limits_{j=1}^i\frac{3j}{3j+4}=3$,"Prove that $\lim\limits_{n\to+\infty}\sum\limits_{i=1}^n\prod\limits_{j=1}^i\frac{3j}{3j+4}=3$ . I can't think of any method to prove it. But here's how I made this problem. Firstly we know $\lim\limits_{n\to+\infty}\sum\limits_{i=1}^n\frac1n$ does not exist. But what if we consider something smaller? Since $\frac1n=\prod\limits_{i=1}^{n-1}\frac i{i+1}$ , and $\frac{3i}{3i+4}<\frac{3i}{3i+3}=\frac i{i+1}$ , I came up with the problem at the beginning. Input to Mathematica: Limit[Sum[Product[(3 j)/(3 j + 4), {j, 1, i}], {i, 1, n}], 
 n -> +\[Infinity]] and the output was $\frac{7~ \Gamma \left(7/3\right)}{\Gamma \left(10/3\right)}=3$ .","['limits', 'sequences-and-series']"
4754325,Estimation of exponential distribution parameter from smallest $n$ out of N observations,"I am interested in estimating the parameter $\lambda$ of an exponential distribution based on the smallest $n$ out of a total of $N$ observations. In mathematical terms: let $X$ be distributed according to $\text{Exp}(\lambda)$ and $x_1, \dots, x_N$ be random samples of X ordered, wlog, such that $x_1 < x_2 < \dots < x_N$ . How can I estimate the parameter $\lambda$ if I know the first $n$ observations $x_1, \dots, x_n$ and the total number of observations $N$ ? I thought I could write down a likelihood function by considering that the first observation is coming from the minimum of a sequence of $N$ i.i.d.r.v. and writing the corresponding probability, then the second from the minimum of the remaining $N-1$ and so on and so forth, but this approach seems pretty cumbersome and impractical if $n$ and $N$ are relatively large. Is there any other way I could approach this problem?","['statistics', 'probability-distributions', 'parameter-estimation', 'exponential-distribution', 'maximum-likelihood']"
4754347,Distribution of concominant order statistics,"Motivating problem: We have $n$ students writing a mock test, and a day after, they write a final test. Let $X_i$ represent the grade (continuous from $0$ to $\infty$ ) of $i$ -th student from the first test, and $Y_i$ from the second test. Let $S$ be the set of $k<n$ best students from the mock test, i.e. $S:=\{i\leq n: X_i> X_{(n-k)}\}$ . Here, $X_{(i)}$ denotes the i-th order statistic, i.e. $X_{(n)} = max(X_1, \dots, X_n)$ . The question is about the distribution of the final grade from the second test between the students in $S$ . In particular, I would like to know the (asymptotic) distribution of $$
\Psi = \frac{1}{k}\sum_{i\in S}F(Y_i), 
$$ where $F$ is the distribution of $Y_1$ . More detailed mathematical notation: Let $(X_1, Y_1), \dots, (X_n, Y_n)$ be iid random vectors. Assume some statistical model, for example let $$Y_i = X_i +\varepsilon_i, $$ where $\varepsilon_i$ are iid independent of $X_i$ . Let $F$ be a df of $Y_1$ and let $k<n$ . My question : What is the distribution (or mean) of $$
\Psi = \frac{1}{k}\sum_{i=1}^nF(Y_i)1[X_i> X_{(n-k)}]?
$$ Here, $X_{(i)}$ denotes the i-th order statistic, i.e. $X_{(n)} = max(X_1, \dots, X_n)$ . My approach : Consider the case when $\varepsilon_i = 0$ for all $i$ . Then, $\Psi = \frac{1}{k}\sum_{i=1}^kF(Y_{(n-i+1)})=$ average of $k$ largest order statistics. Since $F(Y_i)\sim U(0,1)$ , this is a sum of beta distributions (since it is well-known that order statistics of uniform variables have beta distribution). However, if $\varepsilon_i \neq 0$ , then we are averaging not nessesarily $k$ largest statistics. Do you have any idea what might help with solving this? I heard about concominants of order statistics (section 6.8 in David, H. A.; Nagaraja, H. N. (2003). Order Statistics. Wiley Series in Probability and Statistics), but I am not sure if there is a theorem that can help with this.","['statistics', 'uniform-distribution', 'order-statistics', 'maximum-likelihood']"
4754383,All groups of order $112$ have an element of order $14$ [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 months ago . The community reviewed whether to reopen this question 10 months ago and left it closed: Original close reason(s) were not resolved Improve this question In finite groups there exists a very important class as Frobenius groups. We know that there exists a Frobenius group as $2^3:7$ which has an elementary abelian $2$ -group. By the Properties of Frobenius groups there is no Frobenius group of order $2^4\times 7$ , Since $ 7 \nmid 16-1$ . When I checked by GAP it seems that all groups of order $112= 2^4\times 7$ have an element of order $14$ . Could you please help me about the proof of it?","['gap', 'group-theory', 'finite-groups']"
4754392,Is the axiom of choice needed for constructing surjection from a subset?,"Consider the statement 'Let $X \subseteq Y$ . If $X$ is non-empty, then there exists a surjection $f : Y \to X$ '. We prove this by showing there is a family of functions $\{f_a\}_{a \in X}$ where $$
  f_a(x) = \begin{cases}
    x & \text{if $x \in X$} \\
    a & \text{otherwise}.
  \end{cases}
$$ My question is: is the axiom of choice needed to either 1) construct this family of functions, or 2) prove the statement?","['axiom-of-choice', 'functions', 'set-theory']"
4754416,Graphical user interface for 4-dimensional visualisation,"Does anyone know a research / programming literature that explores computer-graphics visualisation of 4-dimensional geometry? Here is a simple method that I was considering to implement by myself. I suspect that this was tried before, so I wanted to know if anyone saw this implemented or explored before. Given a compact set $M \subset \mathbb{R}^{d+1}$ and a pair of vectors $v = (v_{\text{pos}}, v_{\text{view}}) \in \mathbb{R}^{d+1} \times \mathbb{S}^d$ , let $\pi_v \subset \mathbb{R}^{d+1}$ be the affine $d$ -dimensional plane that passes through $v_{\text{pos}}$ and is orthogonal to $v_{\text{view}}$ . Then we may define $M_v \subseteq \mathbb{R}^d$ to be the orthogonal projection of $M$ onto $\pi_v \simeq \mathbb{R}^d$ . For $d=2$ , this is the familiar way in which 2-dimensional shadows are produced. For $d=3$ , we get 3-dimensional objects $M_v \subseteq \mathbb{R}^3$ that are shadows of the 4-dimensional object $M$ . My goal is to design a computer graphical interface that allows intuitive exploration of these objects $M_v$ . In the methods described above, this means designing a computer interface that allows users to easily explore the viewing parameter space $v = (v_{\text{pos}}, v_{\text{view}}) \in \mathbb{R}^{4} \times \mathbb{S}^3$ . Ignoring $\mathbb{R}^4$ for the moment, there is a rich variety of choices to make a user interface to move on the 3-sphere $\mathbb{S}^3$ . $\mathbb{S}^3$ is the quotient space obtained by identifying all boundary points of the solid 3-dimensional ball. This way, the 4-dimensional viewing angles can be visualised by exploring a 3-dimensional ball, which is intuitive to humans. $\mathbb{S}^3$ is the double cover of the $SO(3)$ , so that an interface for exploring the 3-dimensional rotations can be used to explore $\mathbb{S}^3$ . Doing this would require lifting a path on $SO(3)$ to a path on $\mathbb{S}^3$ . $\mathbb{S}^3$ is a $\mathbb{S}^1$ -bundle over $\mathbb{S}^2$ ; this is the Hopf fibration $\mathbb{S}^1 \rightarrow \mathbb{S}^3 \rightarrow \mathbb{S}^2$ . Equipped with  a way to lift a path in $\mathbb{S}^2$ to a path in $\mathbb{S}^3$ , a user would be able to separately control the $\mathbb{S}^2$ -part and the $\mathbb{S}^1$ -part of the $\mathbb{S}^3$ .","['differential-topology', 'geometry', 'reference-request']"
4754434,Does differentiation change the units of measurement in mathematical equations?,"While i'm doing the math homework, I find something very strange. I am confused by a textbook's answer. The Question The textbook's answer So, Does differentiation change the units of measurement in mathematical equations?",['derivatives']
4754436,Number of colourings of the necklace.,"I want to count the number of ways to color beads of a necklace green and red, such that two adjacent beads cannot both be red. The necklace cannot be turned or reflected, the beads are labelled. Initially, I tried for a fixed number of red beads. Let there be $n$ beads in total, $r$ of which are red, so $n-r$ are green. Every bead can have a red bead to its right, so the places for red beads are $n-r$ . Hence, the number of possibilities is $$ \binom{n-r}{r}$$ Summing up for all the numbers of red beads, we get $$ \sum_r \binom{n-r}{r} = F_{n+1} $$ However, this is not correct, mainly because for $ n = 5 $ , and $r = 1$ , the result is $4$ instead of $5$ . Writing $\binom{n-r+1}{r}$ doesn't fix the situation. How can these colorings be correctly counted?","['combinations', 'combinatorics', 'necklace-and-bracelets', 'discrete-mathematics']"
4754440,Prove or disprove $f'(x)=f(\dfrac{x}{2})$ and $\lim\limits_{x\to0}f(x)=0$ implies $f(x)\equiv 0$,"$f:\mathbb{R}^+\to\mathbb{R}$ , $f'(x)=f(\dfrac{x}{2})$ and $\lim\limits_{x\to0}f(x)=0$ , prove that: $f(x)\equiv 0$ . I have tried for it but I do not give an solution without any possible error. First, I tried to integrate $f(x)$ for $$f(x)=\int_0^xf'(t)\mathrm{d}(t)=\int^x_0f(\dfrac{t}{2})\mathrm{d}t=2\int_0^{\frac{x}{2}}f(t)\mathrm{d}t$$ But I have no way to show the proposition. Then I want to analyse the monotony of $f$ . I assume that $f(x)$ is increasing. To be honest, if $f(x)>0$ then we can prove $f$ is increasing clearly. Then $0=f'(x)-f(\dfrac{x}{2})>f'(x)-f(x)$ , then consider $g(x)=e^{-x}f(x)$ and $g'(x)=e^{--x}(f'(x)-f(x))<0$ so $g(x)$ is decreasing then a contradiction clearly shows. But when I want to show that $f$ must be non-negative or non-positive, I found nothing to show it. After that, I consider a counter-example, through my thoughts, I think the sum forms the linear combination of $e^{-c^nx}$ , for a common c instead of $\dfrac{1}{2}$ . But when I construct it, I found when $c<\dfrac{1}{2}$ , the series with functions diverges. All my efforts is useless. So if there is any solution to this problem?","['integration', 'analysis']"
4754485,Closed form for $\int_0^\infty\frac{x-1}{(x+1)^3(x^t-1)}dx $ and explicit form for $\zeta(3)$?,"Here $t$ is a real positive parameter, and I am trying to solve the following integral: $$I_t=\int_0^\infty\frac{x-1}{(x+1)^3(x^t-1)}dx $$ This evaluation could lead (maybe) to an explicit form for $\zeta(3)$ , given the following relation: $$\zeta(3)=\frac{2\pi^2}{7}\lim_{t\to 0}t\cdot I_t $$ I tried letting $x\to\frac1{x}$ , leading to $$I_t=\int_0^\infty\frac{x^t(x-1)}{(x+1)^3(x^t-1)}dx$$ but seems to be worse. So I tried evaluating first the integral from $0$ to $1$ with $x$ in the numerator: \begin{align}
\int_0^1\frac{x}{(x+1)^3(x^t-1)}dx & =-\int_0^1\frac{x}{(x+1)^3}\left(\sum_{k=0}^\infty x^{kt}\right)dx \\
& =-\sum_{k=0}^\infty\int_0^1\frac{x^{kt+1}}{(x+1)^3}dx \\
\end{align} but now the integrals of the form $\int_0^1\frac{x^{\alpha}}{(x+1)^3}$ are tough themselves, and result in messy digamma functions, together with other terms, so I believe this is not the way . I should add that I am not looking for a proof of the limit as I already have it. I am looking only for a closed form of the integral . Any ideas or hints?","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'sequences-and-series']"
4754495,Choosing equally spaced points on a circle,"Consider the sequence $A_1,A_2,A_3, ..., A_{2n-2}, A_{2n-1}, A_{2n}$ of $2n$ points, spaced equally and clockwise on a circle. For which $n \geq 2$ can you choose $n$ pairs of points $(A_i, A_j)$ such that every point is part of exactly one pair and every distance from $\{0,1, ..., n-1\}$ is covered by some pair $(A_i, A_j)$ .
A distance of a pair is defined by the smallest number of points that lie between $A_i$ and $A_j$ . For example, $n=4$ works:
The sequence beeing $A_1, A_2, A_3, A_4, A_5, A_6, A_7, A_8$ , we can choose pairs $(A_2, A_3), (A_6, A_8), (A_4, A_7), (A_1, A_5)$ with distances $0,1,2,3$ respectively, satisfying the condition.","['graph-theory', 'combinatorics']"
4754512,Intuition behind the multiplication and possibility of an alternative method,"Evaluate, with a practical approach, $$\int\frac{\cos(9x)+\cos(6x)}{2\cos(5x)-1}dx$$ The solution that I have first multiplies both numerator and denominator by $\cos\left(\frac{5x}{2}\right)$ then uses the famous formula for $\cos C+\cos D$ . Then the integral is reduced to a very basic one. My question is how did we just randomly multiplied both numerator and denominator by that $\cos\left(\frac{5x}{2}\right)$ . Is there some reason behind it? Or is it cause the question is framed in such a way? Also, is there any other alternative (elementary) method to this? Any help is greatly appreciated.","['integration', 'indefinite-integrals', 'calculus', 'trigonometric-integrals']"
4754527,Does cyclical monotonicity imply almost everywhere differentiability?,"By a theorem due to Lebesgue, it is known that monotonicity of a univariate, real-valued function defined on an interval implies that it must be differentiable almost everywhere. $\textbf{Question:}$ Can we conclude almost everywhere differentiability of a function $f:\mathbb{R}^n\to \mathbb{R}^n$ given that it is $\textit{cyclically monotone}$ ?, i.e., for every $j\geq 2$ and every set of points $x_1,x_2,\dots, x_j\in \mathbb{R}^n$ with $x_1=x_j$ that $$\sum_{k=1}^{j-1}\langle x_{k+1}, f(x_{k+1})-f(x_k)\rangle  \geq 0$$ where $\langle \cdot, \cdot \rangle$ denotes the usual inner product on $\mathbb{R}^n$ . It is easy to see that this property generalizes univariate monotonicity (increasing), hence my question.","['real-analysis', 'multivariable-calculus', 'calculus', 'functions', 'convex-analysis']"
4754539,Does reinterpreting the base of a number leave transcendence unchanged?,"Define the 'reinterpret $x$ from base $a$ to base $b$ ' function $R_{a,b}(x)$ as $$
R_{a,b}(x)=\sum_{i\in\mathbb{Z}}b^iD_{a,i}(x)
$$ where $D_{m,i}(x)$ is the $i$ -th term in the $m$ -ary expansion of $x$ , $$
D_{m,i}(x) = \left\lfloor m(m^{i-1}x - \lfloor m^{i-1}x\rfloor) \right\rfloor.
$$ For integers $a,b>1$ , is it true that $x$ is transcendental iff $R_{a,b}(x)$ is transcendental? For example, is 3.050330051415124105234414053125321..., $\pi$ reinterpreted from base 6 to base 10, transcendental? Jyrki Lahtonen suggests a useful reformulation: write the base- $a$ digits of a number $x$ as a Laurent polynomial $f$ such that $f(1/a)=x$ . Then the question is whether $f(1/a)$ is transcendental if and only if $f(1/b)$ is transcendental, for integers $a,b>1.$ This is probably asking too much; my hope was to prove that, say, $R_{a,b}(\pi)$ is transcendental for all integers $a,b>1$ (or substitute your favorite transcendental number). Any movement in this direction would be appreciated.","['number-theory', 'transcendental-numbers', 'reference-request']"
4754562,An alternative definition of the limit of a function,"In a course on real analysis one usually comes across the definition of the limit of a function: Given a function $f:A\to \mathbb{R}$ where $A\subseteq\mathbb{R}$ , then if $c\in A$ is an limit point of $A$ , we say that \begin{align}
\lim_{x\to c}f(x) = L
\end{align} If \begin{align}
\forall_{\varepsilon>0}\exists_{\delta>0} 
0<|x-c|<\delta \implies |f(x)-L|<\varepsilon 
\end{align} When one uses this definition of a limit in a proof, it tends to get a bit messy, sometimes you have to do this ""trick"" where you restrict $\delta$ to always be less than a certain constant, to get some constant lower bounds in either of the inequalities. It also happens frequently that one starts with a $\delta$ and investigates what happens to $|f(x)-L|$ , and then from that guess what a suitable relationship between $\varepsilon$ and $\delta$ should be. This approach seems to be a bit convoluted at times, so I propose an alternative definition which I believe is more rational Given $f:A\to\mathbb{R}$ with $c\in A$ as before, then if there is a surjective function \begin{align}
g:(0,a)\to(0,b)
\end{align} That satisfies \begin{align} 
0<|x-c|<\delta \implies |f(x)-L|<g(\delta)
\end{align} Then \begin{align}
\lim_{x\to c}=L
\end{align} This seems superficially more complicated, because now suddenly we have to check the surjectivity of a function, but what is interesting is that both quantifiers and a whole variable ( $\varepsilon$ ) is now imbedded into a single statement about a function. The motivation behind the definition is that if one can find such a $g$ , then given any $\varepsilon>0$ , one can find $0<\varepsilon'<\varepsilon$ where $\varepsilon'\in(0,b)$ , and since it is in the image of $g$ there is some $\delta$ such that $g(\delta)=\varepsilon'$ and from there you can prove that the limit holds in the traditional sense. Note that one can also prove surjectivity by proving that a function is bijective, and you can prove the latter by constructing the inverse, thereby entirely avoiding the use of quantifiers. My questions then are:
Does this alternative definition seem correct, and useful?
Is there something analogous to this that is already used?","['alternative-proof', 'limits', 'real-analysis']"
4754577,Difficult algebra problem involving multiple square roots and proving a statement,"Question is as follows: Prove that, when $$y=\frac{\sqrt{(1+x)}+\sqrt{1+2x}+\sqrt{x}}{\sqrt{(1+x)}-\sqrt{1+2x}+\sqrt{x}}$$ then $$4y^2(1+2x)^2=(y-1)^4x(x+1)$$ Despite several attempts at this, I have been unable to derive the required result. My main line of attack has been to use: If $\frac{a}{b}=\frac{c}{d}$ then $\frac{a+b}{a-b}=\frac{c+d}{c-d}$ . So from above: $$\frac{y}{1}=\frac{\sqrt{(1+x)}+\sqrt{1+2x}+\sqrt{x}}{\sqrt{(1+x)}-\sqrt{1+2x}+\sqrt{x}}$$ gives $$\frac{y+1}{y-1}=\frac{\sqrt{(1+x)}+\sqrt{x}}{\sqrt{1+2x}}$$ I've tried squaring etc after this but can't seem to get the result. I also tried working backwards from the required result. After taking positive square roots and rearranging I was left with: $$\frac{2y}{(y-1)^2}=\frac{\sqrt{(1+x)}*\sqrt{x}}{\sqrt{1+2x}}$$ I'm finding this more than a little tricky so if anyone can offer any help I would be extremely grateful. There is a second line of a attack using the following substitutions: $$1+x=u^2, 1+2x=v^2, x=w^2$$ This method apparently dispenses with the root but I can't get the result using this method either. Many thanks in advance for any advice given and I hope I've given enough information in my attempted solution.",['algebra-precalculus']
4754584,Union of two open paracompact subspaces is paracompact?,"Is the union of two open paracompact subspaces of a space $X$ paracompact? A space is called paracompact if every open cover of the space has a locally finite open refinement. Proof attempt : Suppose $X=O_1\cup O_2$ with each $O_i$ open and paracompact.  Given an open cover $\mathcal U$ of $X$ , intersect every element of $\mathcal U$ with $O_1$ to get an open cover of $O_1$ .  Then take a refinement of that cover that is locally finite in $O_1$ .  And similarly for $O_2$ .  The union of the two refinements is an open cover of $X$ that refines $\mathcal U$ .  But I am having difficulty showing the result is locally finite. Presumably the union is not paracompact in general. What would be a (Hausdorff if possible) counterexample?","['general-topology', 'paracompactness']"
4754595,Calculating $ \lim_{n \to \infty} \sum_{i=0}^n \frac{i\pi}{n^2}\sin{(\frac{i^2\pi^2}{4n^2})} $,"The problem: $$
\lim_{n \to \infty} \sum_{i=0}^n \frac{i\pi}{n^2}\sin{(\frac{i^2\pi^2}{4n^2})}
$$ My attempt: Removed constants $$
\pi\lim_{n \to \infty} \frac{1}{n^2}\sum_{i=0}^n i\sin{(\frac{i^2\pi^2}{4n^2})}
$$ Considered l'Hospital's Rule since $n^2 \to \infty$ and $\sum_{i=0}^n i\sin{(\frac{i^2\pi^2}{4n^2})}$ does not converge by the limit convergence test.
L'Hospital's Rule gives $$
\pi\lim_{n \to \infty} \frac{1}{2n}\sum_{i=0}^n i\sin{(\frac{i^2\pi^2}{4n^2})}(-2)\frac{i^2\pi^2}{4n^3}
$$ $$
=\frac{-\pi^3}{4}\lim_{n \to \infty} \frac{1}{n^4} \sum_{i=0}^n i^3\cos{\frac{i^2\pi^2}{4n^2}}
$$ Which once again has an indeterminant form. I don't see myself getting anywhere with l'Hospital's Rule again, and I'm not really sure what I can do. Any tips would help tons! Thanks.","['limits', 'calculus', 'summation']"
4754625,"Define $\ell:C[-1,1]\to\mathbb{R}$ such that $\ell(f)=\int_{-1}^0f-\int_0^1 f$ and let $\|f\|=\max_{t\in[-1,1]}|f(t)|$. Is $\|\ell\|=2$?","$\newcommand{\R}{\mathbb{R}}$ I'm doing a practice exam for Real Analysis and am wondering about this specific question: Let $C[-1,1]$ be the set of all real-valued continuous functions on $[-1,1]$ . For $f,g\in C[-1,1]$ and $\lambda\in\mathbb{R}$ , define $$(f+g)(t)=f(t)+g(t),\,(\lambda f)(t) = \lambda f(t),\,t\in[-1,1].$$ Then $C[-1,1]$ is a vector space over $\R$ with the given operations. For $f\in C[-1,1]$ , define $$\|f\|=\max\{|f(t)|\,|\, t\in[-1,1]\}.$$ (b) Define $\ell:C[-1,1]\to\R$ by $\ell(f)=\int_{-1}^0 f(t)\,dt-\int_0^1 f(t)\,dt$ for $f\in C[-1,1]$ . Prove that $\ell$ is a bounded linear function and find $\|\ell\|$ . I think that $\|\ell\|=2$ , but I'm not 100% sure and I want to see if I'm right. I got so far that $\|\ell\|\leq 2$ , because if we let $\|f\|=1$ we find $$\begin{align*}
            |\ell(f)|&=\left|\int_{-1}^0 f(t)\,dt-\int_0^1 f(t)\,dt\right|\\
            &\leq \left|\int_{-1}^0 f(t)\,dt \right|+\left|\int_0^1 f(t)\,dt\right|\\
            &\leq \int_{-1}^0 |f(t)|\,dt+\int_0^1 |f(t)|\,dt\\
            &\leq \int_{-1}^0 1\,dt+\int_0^1 1\,dt\\
            &=2.
        \end{align*}$$ I'm thinking that to show $\|\ell\|\geq 2,$ I can use the sequence $\{f_n\}$ in $C[-1,1]$ defined by $$f_n(t)=\begin{cases} 1 & \text{if }-1\leq t\leq -1/n,\\
-nt & \text{if }-1/n<t<1/n,\\
-1 & \text{if }1/n\leq t\leq 1.
\end{cases}$$ We find that for each $n$ , $\|f_n\|=1$ . Also, $|\ell(f_n)|=2-1/n$ so that $\lim_{n\to\infty}|\ell(f_n)|=2$ . Does this mean $\|\ell\|\geq 2$ ?","['normed-spaces', 'functional-analysis', 'linear-transformations', 'real-analysis']"
4754675,Rearrangement property of diagonal matrices [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 11 months ago . Improve this question Is it true that for a diagonal matrix $B\in\mathbb{R}^{n\times n}$ , a matrix $A\in\mathbb{R}^{n\times p}$ , the following property holds: $$
A^\top B A = A^\top A B,
$$ where in essence I am asking this: Can diagonal matrices be rearranged in matrix multiplications (we know this is not true in general from the basic laws of linear algebra)? The motivation for knowing this is that it helps to simplify the analysis of machine learning algorithms that uses singular/eigen value decomposition. Thanks.","['matrices', 'machine-learning', 'linear-algebra']"
4754693,Integral $\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx$,"$$I=\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx$$ $$I=2\int_{0}^{1}\frac{\ln\left(x\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx$$ Substituting $x\to\frac{1}{x}$ : $$I=-2\int_{1}^{\infty}\frac{\ln\left(x\right)}{\left(x^{2}+1\right)\left(\pi^{2}+\ln^{2}x\right)}dx$$ This would imply: $$\int_{0}^{\infty}\frac{\ln\left(x\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=0$$ After searching the Integral on Approach0, I found various sources where an Incorrect Value is given: $$\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=\ln2-\frac{1}{2}$$ This is wrong, as can be checked numerically.
But a user on AoPS gave the following Correction ( AoPS ) with the Solution as Well: $$\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1\color{red}{-}x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=\frac{1}{2}-\ln2$$ Trying out the Solution Step by Step, I was able to get till here: $$I=-2\int_{0}^{\infty}e^{-\pi u}\sum_{n=0}^{\infty}\left(\left(-1\right)^{n}\frac{u}{u^{2}+\left(2n+1\right)^{2}}\right)du$$ Now the problem is that factor of $(-1)^n$ which is not present in the corrected problem, without it the sum evaluates to: $$\sum_{n=0}^{\infty}\left(\frac{u}{u^{2}+\left(2n+1\right)^{2}}\right)=\frac{\pi}{4}\tanh\left(\frac{\pi u}{2}\right)$$ But I am not sure how to evaluate it with the $(-1)^n$ factor. Wolfram only gives a Partial Sum Formula in terms of Lerch Transcendent. In the Post Here ( AoPS ), the Integral has a Series form as follows: $$I=-\frac{4}{\pi}\sum_{m=0}^{\infty}\left(\frac{\left(-1\right)^{m}\left(2m+1\right)}{\left(2m+1\right)^{2}-4}\ln\left(m+\frac{1}{2}\right)\right)$$ Another Post where the Wrong Integral Equality is given: Problem #67 I also think I saw this Integral before on MSE, but I am not able to find it.","['integration', 'calculus', 'definite-integrals']"
4754706,Summation $\sum_{n=0}^{\infty}\left(\frac{x^{2n}\left(n+1\right)^{x}\ }{n!}\right)$,"$$f\left(x\right)=\sum_{n=0}^{\infty}\left(\frac{x^{2n}\left(n+1\right)^{x}\ }{n!}\right)$$ This is a self made problem I came across while researching something, so I do not have high hopes for it having a closed form. First of all, Wolfram Does Not give a Closed Form for the Function.
But it does give the function value for values of $x$ as follows: $$f(-2)=\frac{\text{Ei}(4)-\gamma-\ln4}{4}$$ $$f(-1)=e-1$$ $$f(0)=1$$ $$f(1)=2e$$ $$f(2)=29e^4$$ $$f(3)=1279e^9$$ $$f(4)=113137e^{16}$$ Now, for $f(n)$ , $n\in \mathrm N$ : $$f(n)=a_ne^{n^2}$$ The Sequence "" $2, 29, 1279, 113137$ "" led to no results on OEIS. EDIT:
Using Binomial Expansion: $$f(x)=\sum_{r=0}^{x}\frac{x!}{\left(x-r\right)!r!}\sum_{n=0}^{\infty}\frac{x^{2n}n^{r}}{n!}$$ Now you could say the Problem Comes Down to Expanding $\frac{n^r}{n!}$ : Example: $$\frac{n^4}{n!}=\frac{1}{\left(n-4\right)!}+\frac{6}{\left(n-3\right)!}+\frac{7}{\left(n-2\right)!}+\frac{1}{\left(n-1\right)!}$$ But then, although I can do this by hand, how do I write it as a function of $r$ . Second Edit: Using @SangchulLee's help, I was able to deduce this form for natural numbers: $$f(n)=\left(\sum_{r=0}^{n}\binom{n}{r}\text{T}_r\left(n^2\right)\right)e^{n^{2}}$$ where, $\text{T}_r(x)$ are Touchard Polynomials . Then after browsing through I found a wonderful property: $$\frac{T_{n+1}\left(x\right)}{x}=\sum_{k=0}^{n}\binom{n}{k}T_{k}\left(x\right)$$ This leads to the closed form in terms of Touchard Polynomial: $$f(n)=\frac{\text{T}_{n+1}\left(n^2\right)}{n^{2}}e^{n^2}$$ $$\color{green}{f(x)=\frac{\left(x+1\right)!}{\pi x^{2}}\int_{0}^{\pi}\left(e^{x^{2}\left(e^{\cos\left(t\right)}\cos\left(\sin\left(t\right)\right)\right)}\cos\left(x^{2}e^{\cos\left(t\right)}\sin\left(\sin t\right)-\left(x+1\right)t\right)\right)dt}$$ Well this seems to be the closed form. This needs verification though.","['calculus', 'summation']"
4754712,Average of Gaussian Converge to One almost Surely [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 11 months ago . Improve this question I am trying to solve for the following problem: Let $g_1, g_2, \cdots$ be i.i.d. standard Gaussian random variables. Let $(a_{ij})_{i < j}$ be in $\ell^2$ i.e. $\sum_{i < j} a_{ij}^2 < \infty$ . Let $X_n = \frac{1}{n}\sum_{i = 1} ^n g_i^2 + \frac{1}{\sqrt{n}}\sum_{1 \leq i < j \leq n} a_{ij}g_ig_j$ . Show that the sequence $(X_n)_{n \geq 1}$ converges to $1$ a.s. I am really stuck on this problem and need some hints to at least move in the right direction. I am thinking this might be related to Komogorov's zero-one law, but my class has not covered the theorem. Any hints to help me move in the right direction would be appreciated.","['normal-distribution', 'probability-theory', 'real-analysis']"
4754762,Properties of modular arithmetic without equivalence classes,"With modular arithmetic, it seems possible to define the addition operation without imposing equivalence classes. That is, with the set of remainders when dividing by $n$ as $\{0, ..., n - 1\}$ , we can define the addition between members of this set to be the usual integer sum in $\mathbb{Z}$ , reduced modulo $n$ . My university notes say that, with this definition, addition is well-defined but that its properties are difficult to glean. As a result, equivalence classes are imposed and addition occurs between these classes. My questions are: (1) why is it difficult to glean the properties of the original addition (please provide examples to make it clearer) and (2) how does the introduction of equivalence classes solve this problem? Below is an excerpt from the notes I am referring to: Another group with a different flavor is $(\mathbb{Z}/(n\mathbb{Z}), +)$ , the integers modulo $n ≥ 2$ integer: as a set, this can be identified with $\{0, 1, . . . , n − 1\}$ (the remainders when dividing by $n$ in integers), and addition gives the usual sum in $\mathbb{Z}$ , reduced modulo $n$ , so e.g. in $(\mathbb{Z}/(5\mathbb{Z}), +)$ , $2 + 4 = 1$ . It is less confusing though to write $\{[0], . . . , [n − 1]\}$ for the set, and $[2] + [4] = [1]$ then; below we see why this is a good notation. With this definition, addition is well defined on $(\mathbb{Z}/(n\mathbb{Z}), +)$ , but it can be quite awkward to check its properties. It is usually better to proceed as follows: we partition (divide into disjoint sets) $\mathbb{Z}$ into equivalence classes, and say that $a$ and $b$ are in the same class, or $a ∼ b$ , if $a − b$ is divisible by $n$ , i.e. if $a$ and $b$ differ by a multiple of $n$ . Then there are $n$ equivalence classes, namely exactly the remainders when dividing by $n$ . We write the equivalence class of $a ∈ \mathbb{Z}$ as $[a]$ ...","['group-theory', 'modular-arithmetic']"
4754788,"About $I(a,b)=\int_{a}^{b}\sqrt{1+x+x^2+x^3+x^4}\text{ d}x$","The following is an MCQ question, one should answer it without a calculator, within $3$ minutes. $\text{Consider the expression}$ $$I(a,b)=\int_{a}^{b}\sqrt{1+x+x^2+x^3+x^4}\text{ d}x.$$ $\text{Which of the following is true?}$ $\space\space\space\space\space\text{I.}$ $I(2,3)+I(3,4)=I(4,5)$ $\space\space\space\space\space\text{II.}$ $I(2,3)+I(3,4)<I(4,5)$ $\space\space\space\space\space\text{III.}$ $16<I(4,5)<25$ $\text{(A) }$ $\text{I only}$ $\text{(B) }$ $\text{II only}$ $\text{(C) }$ $\text{III only}$ $\text{(D) }$ $\text{I and III}$ $\text{(E) }$ $\text{II and III}$ My Attempt (which, I think, is not a feasible way since it is not that accurate and also time consuming): $\sqrt{1+x+x^2+x^3+x^4}\bigg|_{x=2}=\sqrt{1+2+2^2+2^3+2^4}=\sqrt{1+2+4+8+16}=\sqrt{31}\approx 6$ and $\sqrt{1+x+x^2+x^3+x^4}\bigg|_{x=5}=\sqrt{1+5+5^2+5^3+5^4}=\sqrt{1+5+25+125+625}=\sqrt{781}\approx 28$ Now considering the integrand, approximately, as the straight line joining the points $(2,6)$ and $(5,28)$ . The equation of the line can be found by first determining the slope, $m$ : $$m=\frac{28-6}{5-2}=\frac{22}{3}\approx 7$$ The equation of the line is therefore $$y-6=7(x-2) \implies y=7x-8$$ now $I(a,b) \approx \int_{a}^{b} (7x-8)\text{ d}x=\frac{7}{2}x^2-8x \bigg|_{x=a}^{x=b} = \dots$ and $I(2,3) \approx \int_{2}^{3} (7x-8)\text{ d}x=9.5$ and $I(3,4) \approx \int_{3}^{4} (7x-8)\text{ d}x=16.5$ and $I(4,5) \approx \int_{4}^{5} (7x-8)\text{ d}x=23.5$ From these approximations, we can say, with low confidence, that $\text{(C)}$ is the correct option, which is not. In fact $\text{(E)}$ is the correct option. Noting that we can do better approximations, but that will cost time. Attempt $\text{#}2$ (Not sure if it is a correct way): In the interval $[2,5]$ , function $f(x)=\sqrt{1+x+x^2+x^3+x^4}$ is always (positive), is always (increasing), and is always (concaving up). In that case, the inequalities will be the same when we do not consider the radical. So simply we evaluate: $$\int_{2}^{3}(1+x+x^2+x^3+x^4)\text{ d}x$$ which gives $(x+x^2/2+x^3/3+x^4/4+x^5/5) \bigg|_{x=2}^{x=3}\approx 68$ Similarly, we evaluate: $$\int_{3}^{4}(1+x+x^2+x^3+x^4)\text{ d}x \text{ and } \int_{4}^{5}(1+x+x^2+x^3+x^4)\text{ d}x$$ which give $\approx 217$ and $\approx 538$ , respectively. Clearly $68+217 < 538$ . Hence II is true. AND $16^2 = 256 < 538 < 625 = 25^2$ . Hence III is true. Well, this attempt may also require time, but still it would be nice to know if it is a correct way. So, the approach (which might be wrong) is to observe that; between the limits of integration, the integrand is positive, increasing, and concaving up, the we deal with it without the radical. If this is wrong, please support by giving a counter-example. Your help would be appreciated. Thanks!","['integration', 'definite-integrals', 'calculus', 'numerical-calculus', 'gre-exam']"
4754791,Finding the PMF of a discrete ordered statistic,"Question Let $X_0,X_1,X_2 \dots$ be independent and identically distributed continuous random variables with density $f(x)$ . Let $N$ be the first index $k$ such that $X_k > X_0$ . For example, $N = 2$ if $X_2 > X_0$ and $X_1 \leq X_0$ . Determine the PMF of $N$ and its expectation. Also, explain how your answer would change if the random variables $X_0,X_1,X_2 \dots$ were discrete rather than continuous. I came across this post , where the question is the same as mine except for the second part where the random variables $X_0,X_1,X_2 \dots$ change to discrete. My thoughts for the second part $$\begin{aligned}
\mathbb{P}(N= n | X_0 = x) &= \mathbb{P}(X_1 \leq x,X_2 \leq x,\dots, X_{n-1}\leq x, X_n>x)\\
& = F(x)^{n-1}[1-F(x)]\\
\implies \mathbb{P}(N=n) & = \sum_{x}\mathbb{P}(N = n |X_0=x)\mathbb{P}(X_0 = x)\\
&= \sum_{x}F(x)^{n-1}[1-F(x)]p_X(x)
\end{aligned}$$ Am I on the right track? Also, my professor said that he is looking more for a qualitative answer rather than a quantitative one for this part, but I am unable to come up with anything, so any intuitive explanation will be greatly appreciated!","['independence', 'statistics', 'probability-distributions', 'probability']"
4754812,"Counting $\{a,a,b,b,c,c,d,d,d \}$ derangements. [duplicate]","This question already has an answer here : Derangement formula for multisets (1 answer) Closed 11 months ago . Exam question:
Let $D(d_{1},d_{2},...,d_{k})$ denote the number of derangements of a multiset where there are $d_{i}$ copies of elements of the $i$ -th kind, for $i=1,...,k$ .
This means the arrangements of elements of this multiset in a sequence such that in the first $d_{1}$ positions there is no element of the first kind, in the next $d_{2}$ positions there is no element of the second kind, and so on.
For example: $D(1,2)=0, D(2,2)=1, D(1,1,2)=2$ .
The only derangements of the multiset $\{a,b,c,c\}$ are $\langle c,c,a,b \rangle$ and $\langle c,c,b,a \rangle$ . Find $D(2,2,2,3)$ . The WolframAlpha website might be useful for calculations. Initially, I was thinking about the principle of inclusion and exclusion: $
\frac{9!}{2! \cdot 2! \cdot 2! \cdot 3!} - 6 \binom{8}{1} \binom{7}{2} \binom{5}{2} - 3 \binom{8}{2} \binom{6}{2} \binom{4}{2} + \left( 3 \cdot 2 \cdot 2 \cdot \binom{6}{1} \cdot \binom{6}{1} \cdot \binom{5}{2} + 3 \binom{7}{2} \binom{5}{2} \right) + \left( 3 \cdot 3 \cdot 2 \cdot \binom{7}{1} \binom{6}{2} \binom{4}{2} + 3 \cdot \binom{7}{1} \binom{6}{2} \binom{4}{2} \right)-...
$ Where in the first parenthesis I subtract situations when one of the letters a, b, c is in the wrong position, in the second parenthesis when d is in the wrong position, in the third parenthesis pairs but without the letter d and dividing into situations when the pair consists of two identical letters (both letters a, a are in the wrong positions) or two different ones (e.g., a, b). The fourth is the same as the third but is a case for pairs with the letter d. The problem is that there are still seven cases to consider left, and each subsequent one is worse. Brute force approach gives me $D(2,2,2,3)= 564$ . I have found similar questions Derangement formula for multisets , Derangements of a multiset with ""don't cares""? and I tried using the given formula but it doesn't seem to work: WolframAplha . How can one count these combinations?","['derangements', 'inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
4754841,Why study probabilities in deterministic dynamical systems?,"When studying hyperbolic dynamics and ergodic theory, one often come with probabilities (measures that give to the total space measure 1) even in deterministic systems. Do these have some intuitive interpretation as a probability? Because it seems rather strange to me to put probabilities in deterministic systems, since it hardly seems to mean anything: any probability that you would put on it seems to be arbitrary and not actually meaning anything about the system. Or should it just be viewed (intuitively) as a usual measure (that is finite so you can make calculations easier but normalizing it)?","['measure-theory', 'ergodic-theory', 'soft-question', 'probability', 'dynamical-systems']"
4754854,Find $\lim_{n \to \infty} a_n$ when $a_1 := \sqrt{2}$ and $a_{n+1} := \sqrt{2 + \sqrt{a_n}}$,"Let $\{a_n\}$ be the sequence defined by: $a_1 = \sqrt{2}$ , $a_{n+1}=\sqrt{2+\sqrt{a_n}}$ Show that $\{a_n \}$ is convergent and find $\lim_{n \to \infty} a_n$ My attempt I have already shown that $a_n$ is increasing and is upper bounded by $3$ and therefore the sequence is convergent, but I'm having trouble finding the limit of convergence. Let $L= \lim_{n \to \infty} a_n$ Then since the subsequence $\{ a_{n+1} \}$ also converges to the same limit we have: $L = \lim_{n \to \infty} a_{n+1} = \lim_{n \to \infty} \sqrt{2+\sqrt{a_n}} = \sqrt{2+\sqrt{L}}$ (since $\sqrt{2+\sqrt{x}}$ is a continuous function for $x \geq 0$ ).
Then: $L = \sqrt{2+\sqrt{L}} \Rightarrow L^2 = 2+ \sqrt{L} \Rightarrow L^4-4L^2-L+4=0 \Rightarrow (L-1)(L^3+L^2-3L-4)=0$ The limit can not be $1$ since the sequence is increasing and $a_1 > 1$ , but I'm not able to find the roots of $L^3+L^2-3L-4$ . ¿Is there another way to compute the limit? (It is a problem presented in a test so It would be convinient to solve it whitout using a calculator or computer)","['limits', 'calculus']"
4754864,What is interesting about random variable from a mathematical point of view?,"I'm studying probabilities and I'm wondering if I'm missing something. It turns out that I don't see the significance of the concept of a random variable. Indeed, from what I've understood, it's a measurable function defined on a slightly more general space than usual (not necessarily equipped with an algebraic or topological structure). The term ""random variable"" comes from the fact that each element of the starting space corresponds to the occurrence or non-occurrence of an event, which is identified with a subset of $\Omega$ and is an element of the considered sigma-algebra. But I don't see the point of discussing ""random variables"" (instead of measurable functions) in mathematics since the entire probabilistic analysis is a particular case of classical analysis on measurable spaces. So, I'm wondering if there's a reason or subtlety that I'm unaware of. Lastly, this leads me to question what mathematical concept is purely probabilistic? Thank you a lot","['measure-theory', 'analysis', 'probability-theory', 'probability', 'random-variables']"
4754894,Find the volume of a pyramid,"Consider the triangle drawn on a sheet of paper, along with the coordinate axes, whose vertices are the points $(0,0)$ , $(34,0)$ and $(16,24)$ .
The vertices of your middle triangle are the midpoints of their sides. A triangular pyramid isformed by folding the triangle along the sides of its middle triangle. Determine the volume of this pyramid.(S: $408$ ) I calculated the area of ​​the base but how to find the height of the pyramid? $$S_{base}=\dfrac{DE\cdot h}{2}=\dfrac{12\cdot 17}{12}=102.$$","['geometry', 'volume']"
4754950,A domain is convex if and only if it is contained in its tangent half spaces.,"Let $D$ be an open domain in $\mathbb{R}^{2}$ whose boundary $\partial D$ is a 1-dimensional C ${}^{\infty}$ -submanifold of $\mathbb{R}^{2}$ . Given a boundary point $x$ in $\partial D$ , let $\nu(x)$ denote the outward normal vector of $D$ at $x$ and let $H_{x}$ be the closed half plane in $\mathbb{R}^{2}$ with $\nu(x)$ as outward normal vector at $x$ . Thus $$H_{x}=\{v\in\mathbb{R}^{2} \ | \ \langle \nu(x),v-x\rangle\leq0\},$$ where $\langle\cdot,\cdot\rangle$ is the notation for the inner product on $\mathbb{R}^{2}$ . Is it true that $\overline{D}$ is convex if and only if $\overline{D}\subset H_{x}$ for all $x\in \partial D$ ? Intuitively this is true. However, I can't find a reference for this, nor prove this. Any references or suggestions would be greatly appreciated. Remark: The above easily generalizes to open domains $D$ in $\mathbb{R}^{n}$ .","['convex-geometry', 'geometry', 'reference-request', 'real-analysis', 'convex-analysis']"
4754965,why do pullbacks of closed forms along homotopic functions only differ by an exact one?,"I am trying the get a deeper understanding of the following lemma: Let $V \subset \mathbb{R}^{n+1}$ be open; and let futhermore $U \subset \mathbb{R}^{n}$ be open with $U \times [0,1] \subset V$ . We also define $i_t: U \rightarrow V$ by $x \mapsto (x,t)$ for $t \in [0,1]$ . By $\Omega^k(V)$ we denote the space of differential k-forms on V. Then for each closed $\varphi \in \Omega^k(V)$ there exists a $\psi \in \Omega^k(U)$ such that $$i_1^* \varphi - i_0^* \varphi =d\psi $$ This lemma was originally introduced as a mere technical construction to package away the heavy lifting of the proof of the Poincarè-lemma, but we have used it multiple times since and i came around to taking it as a quite deep result, since it of course yields that pullbacks of closed forms along homotopic functions only differ by an exact form, thereby establishing a connection between forms and notions from topology. I would therefore like to get a bigger picture of what is happening here, why the above lemma should be true morally . I feel that I'm not quite grokking what is going on. I skimmed through wikipedia and a couple of textbooks and came across de Rham-Groups, which we did not cover in our lecture, but that seem to have something to do with this (because you look at forms modulo the exact ones). I also tried throwing Stokes Theorem at the last equation, but it did not yield anything illuminating. As a post-script, answers like ""the only way to get intuition on this is to wait for an actual differential geometry/algebraic topology class"" would be fine, as well as links or just some key-words to look up. Thanks!","['differential-topology', 'differential-forms', 'differential-geometry']"
4754973,Show that integral $\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}\left(1+\frac{y^2}{x^2}\right)\ dy\ dx=\left(\pi+\frac{8}{3}\right)a^2$,"Show that the integral $$\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}\left(1+\frac{y^2}{x^2}\right)\ dy\ dx=\left(\pi+\frac{8}{3}\right)a^2$$ by changing the coordinates $x,y$ to $r$ , $\theta$ where, $x=r\cos^2\theta , y=r\sin\theta \cos\theta$ . Solution: $\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx
{=
{\int_{0}^{2a}\int_{0}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx}
-{\int_{0}^{2a}\int_0^{\sqrt{2ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx}
}=I_1+I_2.$ The Jacobian is $J=r cos^2(\theta)$ for the transformation $x=r\cos^2\theta , y=r\sin\theta \cos\theta$ . Hints is given in the link Evaluate the integral $\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx$ by changing the coordinates to r,$\theta$ Q1: Please help me to solve the problem. How to transform $I_1,I_2$ using the given transformation $x=r\cos^2\theta, y=r\sin\theta \cos\theta$ . I evaluate concern Jacobian, but unable to understand the limits in $r-\theta$ plane. Q2: I understand the Fig in x-y plane which is the common portion of two circles in the 1st quadrant which are $(x-a)^2+y^2=a^2$ (inner) and $(x-2a)^2+y^2=(2a)^2$ . But I cannot understand the Fig in $r-\theta$ plane. Please explain the transformation $x=rcos^2θ,\,y=rsinθ\,cosθ$ .","['multivariable-calculus', 'multiple-integral']"
4754992,Is this set of natural sequences countable?,"Let $X$ be the set of all natural sequences such that the next term is at least twice as large as the previous one, that is $$X = \{x_n: x_n \in \mathbb{N} \text{ and } x_{n+1} \geq 2x_n \text{  }\forall n\}$$ Is this set countable? I think it isn't, and I would like some feedback on my proof below. Tentative proof : We will construct a surjective function $f: X \rightarrow \{0, 1\}^{\mathbb{N}}$ , where $\{0, 1\}^{\mathbb{N}}$ is the set of all binary sequences. For every sequence $x_n \in X$ , we map it into the sequence $f(x_n) = s_n = \mathbb{1}\{x_{n+1} > 2x_n\}$ . That is, $$ s_n = 
\begin{cases}
1, & x_{n+1} > 2x_n \\
0, & x_{n+1} = 2x_n
\end{cases}
$$ We now show that $f$ is a surjection: take any $s_n \in \{0, 1\}^{\mathbb{N}}$ , and consider the sequence defined as $x_1 = 1$ and $$ x_{n+1} = 
\begin{cases}
2x_n +1 , & s_n = 1 \\
2x_n, & s_n = 0
\end{cases}
$$ By construction, $x_n \in X$ and $f(x_n) = s_n$ . So for any $s_n \in \{0, 1\}^{\mathbb{N}}$ there exists a $x_n \in X$ such that $f(x_n) = s_n$ . Therefore, $f$ is a surjection. We know that $|\{0, 1\}^{\mathbb{N}}| > |\mathbb{N}|$ (the set of all binary sequences is not countable); since we constructed a surjection from $\{0, 1\}^{\mathbb{N}}$ to $X$ , we have that $$|X| \geq |\{0, 1\}^{\mathbb{N}}| > |\mathbb{N}| $$ Therefore, $X$ is not countable. Is this proof correct?","['elementary-set-theory', 'sequences-and-series', 'real-analysis']"
