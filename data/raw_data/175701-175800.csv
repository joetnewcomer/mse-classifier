question_id,title,body,tags
3146748,How to show that a particular distribution is the Lebesgue measure,"Let $X_1 , X_2,..$ be independent r.v's, defined on some probability space $(\Omega, \mathcal{F},P)$ , s.t. $$P(X_n = 0) = P(X_n = 1) =1/2 \text{ } \forall n$$ Let $U = \sum_{n=1}^{\infty}X_n 2^{-n}$ . (i) Show that the distribution of $U$ is the Lebesgue measure. 
  (ii) Construct an independent sequence $U_1,U_2,..$ on $((0,1),\mathcal{B},\lambda)$ s.t. the distribution of each $U_i$ is $\lambda$ where $\lambda$ is Lebesgue. My attempt: Let $E_n = \{ X_i = T_i | i=1,..,n \text{  } \& X_{n+1}<T_{n+1}\}$ . To find the distribution of $U$ , I need $P(X_1 X_2... < T_1 T_2...)$ where $X_i , T_i \in \{0,1\}$ . Then $$\{X_1 X_2... < T_1 T_2...\} = \coprod_{n=1}^{n=\infty}\{E_n \cap \{T_{n+1}=1\}\}$$ where $\coprod$ is the disjoint union. $$P\{E_n \cap \{T_{n+1}=1\}\} = 1_{\{T_{n+1}=1\}}.(\frac{1}{2})^{n+1}$$ and thus: $$P\{X_1 X_2... < T_1 T_2...\} = \sum_{n=1}^{\infty}1_{\{T_{n+1}=1\}}.(\frac{1}{2})^{n+1}$$ Am I thinking in the right direction? and if yes, I'm not sure which set on $\mathbb{R}$ I should be looking at to take it's Lebesgue measure to be equal to the distribution obtained above? Thanks and appreciate a hint.","['statistics', 'probability-theory', 'measure-theory', 'real-analysis']"
3146767,Area of triangle in $\mathbb R^3$ given $3$ coordinates,"I know that if we have $3$ points $a$ , $b$ ,and $c$ in $\mathbb R^3$ , the area of the triangle is given by: $\frac{1}{2}\|\vec{ab}\times \vec{ac}\|$ . This means that the area of the triangle equals half the length of the normal of the plane on which the triangle lays. I don't quite understand how this can be. What other geometrical interpretation can be made of $\frac{1}{2}\|\vec{ab}\times \vec{ac}\|$ ?","['linear-algebra', 'geometry']"
3146771,Applying Pick's Theorem,"Let's say that $X$ is a parallelogram with vertices that have integer coordinates, how could I prove that $X$ 's area is an integer? The vertices are $0, A, B$ and $A + B$ . How would I do this?",['geometry']
3146815,"For $P$ an arbitrary point in $\triangle ABC$, show that $\sum_{cyc}c(\sin \angle CAP+\sin\angle CBP)\leq a+b+c$","In the interior of $\triangle ABC$ we take the arbitrary point $P$ . Prove that the following inequality holds: $$\small c(\sin\angle CAP + \sin\angle CBP) + a(\sin\angle ABP +\sin\angle ACP) + b(\sin\angle BCP + \sin\angle BAP)\\ \le a + b + c$$ I tried to draw the distances from $P$ to the sides of the triangle and write the sines from the right angled triangles, but I couldn't get anything out of it. I saw that a case of equality is when the triangle is equilateral and $P$ is its center. Can you help me?","['inequality', 'geometry', 'triangles', 'geometric-inequalities', 'trigonometry']"
3146824,Proof that there exist only 17 Wallpaper Groups (Tilings of the plane),"I had a professor who once introduced us to Wallpaper Groups. There are many references that exist to understand what they are (example Wiki, Wallpaper group ). The punchline is $$There \,\, are \,\, exactly \,\, 17 \,\, wallpaper \,\, groups \,\,(17 \,\, ways \,\, to \,\, tile \,\, the \,\, plane)$$ My question is $2$ -fold: Can someone sketch out the proof or at least give some high level ideas of why this may be true? Can someone refer me to a website or a textbook that develops the proof in detail?","['tessellations', 'geometry', 'reference-request', 'group-theory', 'symmetry']"
3146841,Number of words in which all the vowels are not together of the word GANESHPURI?,"Number of words in which all the vowels are not together of the word GANESHPURI? The options available are $21\cdot 7!$ $42\cdot 8!$ $84\cdot 7!$ None I have found words with vowels always together to be equal to $7!\cdot 4!$ and subtracted total number of words from it $(10!-7!×4!)$ but it seems wrong. Also;
2:) Number of words with any two of the letters E,H and  P are never together?","['permutations', 'combinations', 'combinatorics']"
3146855,Find a basis $A$ of space $\mathbb R^{4}$ and basis $B$ of space $\mathbb R^{3}$,"Let $\varphi: \mathbb R^{4} \rightarrow \mathbb R^{3}$ : $$\varphi(x_{1},x_{2},x_{3},x_{4})=(x_{1}+x_{3}+x_{4},x_{1}+x_{2}+2x_{3}+3x_{4},x_{1}-x_{2}-x_{4})$$ Find a basis $A$ of space $\mathbb R^{4}$ and basis $B$ of space $\mathbb R^{3}$ such that $M(\varphi)^{B}_{A}={\begin{bmatrix}1&0&0&0\\0&1&0&0\\0&0&0&0\end{bmatrix}}$ I think that I know how to do this task. However I really need an assessment if it is correct. My try: $M(\varphi)^{st}_{st}={\begin{bmatrix}1&0&1&1\\1&1&2&3\\1&-1&0&-1\end{bmatrix}}$ After elementary operations on the matrix $M(\varphi)^{st}_{st}$ I have system of equations: $\begin{cases} 
x_{1}+x_{3}+x_{4}=0 \\ 
x_{2}+x_{3}+2x_{4}=0\end{cases}$ So $\ker \varphi=lin\left\{(-1,-1,1,0),(-1,-2,0,1)\right\}$ . This vectors are in a basis $A$ but I need two more vectors. $\dim(\ker\varphi)=2$ so $\dim(im \varphi)=2$ and it can be: $(1,1,1),(0,1,-1)$ (I take $2$ linearly independent vectors from the matrix $M(\varphi)^{st}_{st}$ columns). This vectors are in a basis $B$ . In this moment I have $A=\left\{\alpha_{1}, \alpha_{2},(-1,-1,1,0),(-1,-2,0,1)\right\}$ and $B=\left\{(1,1,1),(0,1,-1),\beta_{3}\right\}$ From $M(\varphi)^{B}_{A}$ I have: $\varphi(\alpha_{1})=1 \cdot \beta_{1}$ $\varphi(\alpha_{2})=1 \cdot \beta_{2}$ $\varphi(\alpha_{3})=0$ $\varphi(\alpha_{4})=0$ That is why: $\varphi(\alpha_{1})=(1,1,1)$ and $\alpha_{1}=(1,0,0,0)$ $\varphi(\alpha_{2})=(0,1,-1)$ and $\alpha_{2}=(0,1,0,0)$ $\beta_{3}$ I can choose anyway because I do not have any dependencies on it. It can be linerly indipendent from other basis vectors, so it can be $\beta=(0,0,1)$ I will be extremely grateful for checking this solution and indicating any errors.",['linear-algebra']
3146859,Diagonal argument applied to computable numbers [duplicate],"This question already has an answer here : A paradox related to computable reals? (1 answer) Closed 4 years ago . Upon applying the Cantor diagonal argument to the enumerated list of all computable numbers, we produce a number not in it, but seems to be computable too, and that seems paradoxical. For clarity, let me state the argument formally.
It suffices to consider the interval [0,1] only.
Consider $0 \leq a \leq 1$ , and let it's decimal representation be found as $$
a =\sum_{n=1}^\infty 10^{-n} a^{(n)}
$$ We say that $a$ is computable, if there is a Turing machine $T_a$ which receives $n$ and outputs $a^{(n)}$ in finite time, i.e., it always halts. Let $A$ be the set of all computable numbers.
A moment's reflection shows that $A$ is countably many.
For example, we can implement $T_a$ in (say) Python, always choosing the program with the shortest string length, and we sort $T_a$ by their program according to the ASCII characters' dictionary order.
If two programs, which both implement $T_a$ , have the same string length, choose the one with foremost dictionary order.
This gives a sorting function of $A$ . Let $A$ be enumerated with $a_1, a_2, a_3 \dotsc$ . Now, construct a number $b$ so that: $$
b =\sum_{n=1}^\infty 10^{-n} b^{(n)} \\
b^{(n)} =\begin{cases}
4,\quad a_n^{(n)} =3 \\
3,\quad \rm{otherwise}
\end{cases}
$$ We see $b \notin A$ .
Moreover, $b^{(n)}$ is obtained within finite time, since we only need to know $a_n^{(n)}$ 's value.
Thus $b \in A$ , but $b \neq a_n$ for all $n =1,2,3, \dotsc$ , a contradiction. This post is related, but I don't think it's a duplicate.
The post applies the diagonal argument on the reals, rather than the computable numbers.","['cardinals', 'computability', 'turing-machines', 'real-analysis']"
3146911,"Does any book now in print define the meaning of $\lim_{x\to a}f(x)=b$ for $f\colon E\to Y$, $E\subseteq X$, $X$ a topological space, $Y$ Hausdorff?","It is surely common knowledge, more general than the $\epsilon, \delta$ definition of a limit of a function on a subset of a metric space at a
limit point of the subset - see for example page 83f. of Walter Rudin, Principles of Mathematical Analysis (third edition, McGraw-Hill 1976) -
that if $X$ is a topological space, $Y$ is a Hausdorff space, $E$ is a
subset of $X$ , $f \colon E \to Y$ is a function, $a$ is a limit point
[equivalently: cluster point, accumulation point] of a subset $K$ of $E$ (this does not imply $a \in K$ , or even $a \in E$ ), and $b$ is a point
of $Y$ , then a notation such as $$
\lim_{\substack{x \to a \\ x \in K}} f(x) = b,
$$ or similar, means that every neighbourhood of $b$ in $Y$ contains the $f$ -image of the intersection of $K$ with a punctured neighbourhood of $a$ in $X$ . A recent question asked about a special case of this ( $E = X = \mathbb{R}$ , $K = \mathbb{R}
\setminus\{a\}$ , $Y = \mathbb{R} \cup \{+\infty, -\infty\}$ ), and I have
been seeking an authoritative reference for this ""common knowledge"". The only definition I have managed to find is on page 63 of Horst Schubert, Topology (Macdonald 1968). The book is sadly out of print. (Used copies
of it don't seem to be very easy to find.) Also, the definition is given
in terms of filters. Although not complicated, the definition requires the
reader to apply quite a large number of prior definitions in order to arrive
at the characterisation in terms of neighbourhoods of $b$ in $Y$ and
punctured neighbourhoods of $a$ in $X$ . (I quoted the necessary definitions
in my answer to the question cited earlier.) Is there a book in print that gives an explicit definition of $\lim_{x\to a} f(x) = b$ in the general case? It would be ideal if
the book gave the simple definition in terms of neighbourhoods in $Y$ and
punctured neighbourhoods in $X$ , but a more elaborate definition in terms
of filters or nets is also acceptable. The fiddly details
concerning the subsets $E$ and $K$ are relatively unimportant; what
matters is that the definition applies to topological spaces in
general, not just metric spaces.","['analysis', 'reference-request', 'definition', 'limits', 'general-topology']"
3146913,product= $\exp\left[\frac{47\mathrm G}{30\pi}+\frac34\right]\left(\frac{11^{11}3^3}{13^{13}}\right)^{1/20}\sqrt{\frac{3}{7^{7/6}\pi}\sqrt{\frac2\pi}}$,"$\mathrm G$ is Catalan's constant. I recently found the product $$
\alpha=\prod_{n=1}^{\infty}\frac{E_n(\frac12)E_n(\frac7{12})E_n(\frac1{20})E_n(\frac{13}{20})}{E_n(\frac14)E_n(\frac1{12})E_n(\frac3{20})E_n(\frac{11}{20})}=\\
\exp\left[\frac{47\mathrm G}{30\pi}+\frac34\right]\sqrt{\frac{33}{91\pi}\sqrt{\frac2\pi\frac{\sqrt[5]{11}}{\sqrt[3]{7}}\sqrt[5]{\frac{3^3}{13^{3}}}}}$$ (an alternate form of the product in the title) Where $$E_n(x)=\frac{j(n+x)}{(en)^{2x}j(n-x)}\qquad x\in(0,1)$$ and $j(x)=x^x$ . Could I have some numerical evidence, or better yet an alternate proof? My tools are limited to desmos, which cannot really handle infinite products. Thanks. My Proof. We define $$\mathrm L(x)=\frac1\pi\int_0^{\pi x}\log(\sin t)dt$$ And we use $$\sin t=t\prod_{n\geq1}\left(1-\frac{t^2}{\pi^2 n^2}\right)$$ To see that $$\log(\sin t)=\log(t)+\sum_{n\geq1}\log\frac{\pi^2n^2-t^2}{\pi^2n^2}$$ Then integrate both sides over $[0,x]$ to get $$\pi\mathrm L(x/\pi)=x(\log x-1)+\sum_{n\geq1}x\log\bigg(1-\frac{x^2}{\pi^2n^2}\bigg)-2x+\pi n\log\frac{\pi n+x}{\pi n-x}$$ $$\pi\mathrm L(x/\pi)=\log\left[\frac{j(x)}{e^x}\right]+\sum_{n\geq1}\log\left[\frac{j(\pi n+x)}{(e\pi n)^{2x}j(\pi n-x)}\right]$$ $x\mapsto \pi x$ : $$\pi\mathrm L(x)=\log\left[\frac{j(\pi x)}{e^{\pi x}}\right]+\sum_{n\geq1}\log\left[\frac{j(\pi n+\pi x)}{(e\pi n)^{2\pi x}j(\pi n-\pi x)}\right]$$ $$\mathrm L(x)=\log\left[\left(\frac\pi{e}\right)^xj(x)\right]+\sum_{n\geq1}\log E_n(x)$$ Then we define $$U(x)=\prod_{n\geq1}E_n(x)$$ To see that $$U(x)=\left(\frac{e}{\pi x}\right)^x\exp\mathrm L(x)$$ Where we used $$\sum_{n}\log(a_n)=\log\left[\prod_{n}a_n\right]$$ and the neat rules $$\log(a^b)=\log(e^{b\log a})=b\log a$$ $$\log(a)\pm b=\log\left(e^{\pm b}a\right)$$ to simplify the expressions. Next, we define $$P_{\mu,\nu}(a_1,a_2,\dots,a_\mu;b_1,b_2,\dots,b_\nu)=\frac{\prod_{i=1}^\mu U(a_i)}{\prod_{i=1}^\nu U(b_i)}$$ And we see that $$P_{\mu,\nu}(a_1,\dots,a_\mu;b_1,\dots,b_\nu)=\prod_{n\geq1}\frac{\prod_{i=1}^\mu E_n(a_i)}{\prod_{i=1}^\nu E_n(b_i)}$$ This gives $$P_{1,1}(x_1;x_2)=\left(\frac{e}{\pi}\right)^{x_1-x_2}\frac{j(x_2)}{j(x_1)}\exp\left[\mathrm L(x_1)-\mathrm L(x_2)\right]$$ Then we define $$\mathrm{T}(x)=\frac{1}{\pi}\int_0^{\pi x}\log(\tan t)dt=\mathrm L(x)-\mathrm L(x+1/2)-\frac12\log2$$ To get that $$P_{1,1}\left(x;x+\frac12\right)=\sqrt{\frac{2\pi}e}\,\frac{j(x+1/2)}{j(x)}\exp\mathrm T(x)$$ So we have $$P_{2,2}\left(x_1,x_2+\frac12 ;x_2,x_1+\frac12\right)=\frac{j(x_1+1/2)j(x_2)}{j(x_2+1/2)j(x_1)}\exp\left[\mathrm T(x_1)-\mathrm T(x_2)\right]$$ Then using the identities $$\mathrm L(1/2)=-\frac12\log2$$ $$\mathrm L(1/4)=-\frac{\mathrm G}{2\pi}-\frac14\log2$$ We get $$P_{1,1}\left(\frac12;\frac14\right)=\frac1{(2\pi)^{1/4}}\exp\left[\frac{\mathrm G}{2\pi}+\frac14\right]\tag{1}$$ From here , the identity $$-\mathrm T(1/12)=\frac{2\mathrm G}{3\pi}$$ which gives $$P_{1,1}\left(\frac7{12};\frac1{12}\right)=\sqrt{\frac6{7\pi\sqrt[6]{7}}}\exp\left[\frac{2\mathrm G}{3\pi}+\frac12\right]\tag{2}$$ Then from here , the identity $$\mathrm T(1/20)-\mathrm T(3/20)=\frac{2\mathrm G}{5\pi}$$ gives $$P_{2,2}\left(\frac1{20},\frac{13}{20};\frac3{20},\frac{11}{20}\right)=\left(\frac{j(11)j(3)}{j(13)}\right)^{1/20}\exp\frac{2\mathrm G}{5\pi}\tag{3}$$ Then multiplying $(1),(2),$ and $(3)$ , we have the desired result, namely $$P_{4,4}\left(\frac12,\frac7{12},\frac1{20},\frac{13}{20};\frac14,\frac1{12},\frac3{20},\frac{11}{20}\right)=\alpha$$","['integration', 'alternative-proof', 'calculus', 'infinite-product', 'constants']"
3146983,"Show that the ""algebra generated by a semi-algebra"" is actually an algebra",We know that algebra F generated by semi-algebra A of a set X is the collection of subsets of X which can be written as finite disjoint union of sets from A. The question was to prove this is an algebra. I was able to show all things except the property that it is closed under complements. Idea is clear to me as it seems I have to take union of many sets from A but I am not getting how to put it down on paper.,['measure-theory']
3147009,Prove that the mapping of a number to its XOR with some constant c is bijective,"Prove that $x \mapsto x \oplus c$ is a bijection over the range $[0, b]$ , regardless of the value of constant $c$ , where $b = 2^{k} - 1, k \in I^{+}$ .","['binary', 'functions', 'discrete-mathematics']"
3147034,Subclass of ordinals is a set iff it is bounded,"Let $X\subseteq \text{Ord}$ . Then $X$ is a set if and only if there exists an ordinal $\beta$ such that for all $\alpha \in X$ , $\beta\ge \alpha$ . I am really having trouble with proving that something is a set or using the fact that we have a set. How does one approach problems like this, when you have to prove something is a set?","['elementary-set-theory', 'ordinals']"
3147059,real valued functions that are invariant under convolution,"Consider the function $f(x) = e^{-x^2}$ , notice that $f$ convoluted with itself is of the form $a\cdot f(bx+c)$ for reals $a, b$ and $c$ . Another way of saying this is that the shape of the function $f(x)$ does not change when convoluted with itself. It only gets stretch and shifted. Here is another such function: $f(x) = \frac1{1+x^2}$ I am interested in a categorization of all such functions. Is such a categorization known? I am interested in any resources discussing this topic. If you are unable to do either, I would still be interested in any example of such a function other than the two I listed.","['calculus', 'probability-distributions', 'convolution']"
3147096,Determine numbers written on a chessboard with the fewest number of questions.,"You have a standard chessboard with 64 squares with each square having a different number written on it (say from 1 to 64), but in no particular order. You are allowed to ask questions. A single question has the following form: ""Give me the numbers written on squares $d5,b2,c4,c8,...,h6$ "". You can specify as many different squares as you want in a single question. The answer provides you with a list of numbers (like 12,43,11,62,...,53) but the numbers are returned in an arbitrary order (so you cannot say that number 12 belongs to square $d5$ , for example). What is the minimum number of questions that you have to ask in order to determine the number on each square? My effort? I have a fairly simple proof that you can ""decrypt"" the board with only 6 questions. But the trick is to prove that you cannot do the same with 5 or 4 questions. That's something that I'm still struggling with.","['chessboard', 'combinatorics']"
3147139,Probability no one needs to wait for changes when buying tickets .,"There are $2 \cdot n$ people in the queue to the theater office; n people on only banknotes worth $20$ zlotys, and the remaining n people only have banknotes worth $10$ zlotys . At the beginning of the sale at the box office there is no money. Each person buys one ticket worth 10 zlotys. If one with only $20$ -zlotys banknotes is in the first of the queue, then he/she needs to wait for another guy with only 10-zlotys banknote to complete his/her transaction, because the ticket office does not have any change to offer at that time. What is the probability that no one will wait for the change? $A$ = no one will wait for the rest. $P (A) = 1-P (A ')$ , that is, it subtracts the waiting persons from the whole and will leave me without waiting, but I do not know how to calculate it.",['probability']
3147181,Is there a term for the opposite of an interpolation?,"The question is specifically about linear Interpolation , which is usually defined to be a function $$
f : V \times V \times \mathbb{R} \rightarrow V \\
f(v_0,v_1,\alpha) = v_0 + (v_1-v_0) \cdot \alpha
$$ So it takes the arguments $v_0$ and $v_1$ and a real value $\alpha$ (often, but not necessarily, in $[0,1]$ ), and computes the linearly interpolated value. Conversely, there may be a function like this: $$
g : V \times V \times V \rightarrow \mathbb{R} \\
g(v_0,v,v_1) = (v - v_0) / (v_1 - v_0)
$$ For the given arguments, it computes the ""relative position"" of one element between the others - namely, the value that could be used as the $\alpha$ value in the interpolation function, so that $f(v_0, v_1, g(v_0, v, v_1)) = v$ . It's not an ""inverse"", and the term ""opposite"" in the title was just for lack of a better term. Right now, I'm calling it ~""interpolation parameter function"", but I wonder whether there is a commonly used term for that.","['functions', 'terminology']"
3147222,"If all powers of two random variables are uncorrelated, are they independent?","Let $X$ and $Y$ be random variables on a common probability space. If $$\def\E{\mathbb E}\E[X^nY^m]=\E[X^n]\,\E[Y^m]<\infty $$ for all integers $n,m\ge 0$ , does it follow that $X$ and $Y$ independent? I strongly suspect the answer is no. In the same way that the a random variable is not determined by its moments, a random vector is not determined by its joint moments. I have looked at several counter-examples of distinct random variables with the same moments, which I found here . The examples are derived by looking at characteristic functions, but I am not sure if they can be generalized to multivariate characteristic functions. This question shows that $\E[f(X)g(Y)]=\E[f(X)]\,\E[g(Y)]$ for all bounded and continuous $f$ and $g$ implies $X$ and $Y$ are independent. My question is if we get the same result when we restrict $f$ and $g$ to be polynomials.","['moment-problem', 'examples-counterexamples', 'probability-theory', 'probability']"
3147225,Relationship between Archimedean and Divisible ordered groups,"Let $(G,+,\leq)$ be a linearly ordered abelian group (i.e. the order is total and compatible with the sum) and $n\cdot x$ denote the classical action of $\mathbb{Z}$ over $G$ (i.e. $0$ for $n=0$ , sum of $|n|$ copies of $x$ if $n>0$ and of $-x$ if $n<0$ ). I was interested in the relationship between the following properties: Archimedean property: $\forall a,b\in G\:\:\:\exists n\in \mathbb{Z}|a\leq n\cdot b$ Divisible group: $\forall n\in \mathbb{Z}, a\in G\:\:\:\exists b\in G|n\cdot b =a$ At a first glance, to me they look pretty similar. In fact, so far, I've encountered examples that satisfies both of them or neither of them but I stil didn't find anything that satisfies exactly one of them. I've read about hyperreal and surreal numbers which are not Archimedean but are divisible however they are proper classes and to me this seems a bit cheating so I'd prefer only group lying on a set rather then a proper class. EDIT: Apparently the examples were pretty simple so I'll change my original question to: under which condition are they equal?","['group-theory', 'order-theory', 'abstract-algebra', 'divisible-groups', 'abelian-groups']"
3147248,Sample Space of a Geometric Distribution,"Let's say I have an experiment where I repeatedly toss a coin; each toss is independent. I would like to define a random variable $X: \omega \rightarrow R$ . $X$ is the number of failures before the first success. I would like to visualize the sample space of this experiment, but I'm having trouble. Is the sample space an infinite set containing potentially infinitely long sequences?","['statistics', 'probability-distributions', 'probability-theory']"
3147250,"If $f$ is integrable, then $\| f\|$ is also integrable.","As usual, a partition of a compact interval $[a, b]$ is, by definition, an strictly increasing family $\Pi = (t_k)_{k = 0}^m$ ( $m \geq 0$ ) of points in the interval such that $t_0 = a$ and $t_m = b;$ $\tilde\Pi$ is refining $\Pi$ if $\Pi$ is subfamily of $\tilde\Pi$ and $\tilde\Pi$ is also a partition. A valid selection of tags $\tau$ for the partition $\Pi = (t_k)_{k = 0}^m$ is, by definition, a family $(\tau_k)_{k = 1}^m$ for which $\tau_k \in [t_{k - 1}, t_k],$ as $k$ runs from $1$ until $m.$ Definition of Banach space valued Riemann integral. A function $f:[a, b] \to \mathrm{X},$ $\mathrm{X}$ being a Banach space, is Riemann-integrable if there exists a vector $I \in \mathrm{X}$ obeying the following law: for all $\varepsilon > 0,$ there exists a partition $\Pi_\varepsilon$ such that for whatever the partition $\Pi$ of $[a, b]$ refining $\Pi_\varepsilon$ and whatever valid selection of tags $\tau$ for the partition $\Pi$ may be, the Riemman sum of $f$ associated with the partition $\Pi$ under the valid selection of tags $\tau,$ $S(f, \Pi, \tau) = \sum\limits_{k = 1}^m f(\tau_k)(t_k - t_{k - 1}),$ satisfies $\|I - S(f, \Pi, \tau)\| < \varepsilon.$ Problem. How to show that $\|f\|$ will be integrable whenever $f$ is? There is the following ""fundamental criterion"" for Riemann-integration that may be useful but I just couldn't find a way to apply it. Fundamental criterion for existence. For the function $f:[a, b] \to \mathrm{X}$ to be Riemann-integrable it is necessary and sufficient that the following conditions should hold, for every $\varepsilon > 0,$ there exists a partition $\Pi_\varepsilon,$ such that $\left\| S \left(f, \Pi^{(1)}, \tau^{(1)} \right) - S \left(f, \Pi^{(2)}, \tau^{(2)} \right) \right\| < \varepsilon$ for all refinements $\Pi^{(1)}$ and $\Pi^{(2)}$ of $\Pi_\varepsilon$ and all corresponding valid selections of tags $\tau^{(1)}$ and $\tau^{(2)}.$ Sketch of proof of the fundamental criterion. Necessity is obvious. For sufficiency, consider, for each $n,$ a partition $\Pi^{(n)},$ refining all previous $\Pi^{(k)},$ and consider valid tags $\tau^{(n)}$ such that $$\left\| S \left(f, \Pi^{(n)}, \tau^{(n)} \right) - S \left(f, \Pi^{(k)}, \tau^{(k)} \right) \right\| < \dfrac{1}{k}.$$ Set then $I_n = S \left(f, \Pi^{(n)}, \tau^{(n)} \right)$ and notice this defines a fundamental sequence is $\mathrm{X}$ and therefore, converging to some vector $I \in \mathrm{X},$ which can be shown, using triangle inequality, to be the Riemann integral of $f.$ $\square$","['banach-spaces', 'normed-spaces', 'real-analysis', 'functional-analysis', 'riemann-integration']"
3147272,If $\sin(x) - \cos(x) = 1/3$ then determine $\sin(x)\cos(x)$,"If $$\sin(x) - \cos(x) = \frac{1}{3}$$ then determine $$\sin(x)\cos(x)$$ I know that the expected solution is squaring both sides of equation and solving it this way: \begin{gather}
\sin^2(x)+\cos^2(x)= 1 \\[4px]
(\sin(x) - \cos(x))^2 = \left(\frac{1}{3}\right)^2 \\[4px]
\sin^2(x) - 2\sin(x)\cos(x) + \cos^2(x) =\frac{1}{9} \\[4px]
-2\sin(x)\cos(x)=\frac{1}{9} -\sin^2(x)-\cos^2(x) \\[4px]
2\sin(x)\cos(x)=-\frac{1}{9} +\sin^2(x)+\cos^2(x) \\[4px]
2\sin(x)\cos(x)=-\frac{1}{9} +1\\[4px]
2\sin(x)\cos(x)=\frac{8}{9} \\[4px]
\sin(x)\cos(x)=\frac{4}{9}
\end{gather} But assume I haven't noticed that I can solve it by squaring both sides in the first place. I can't figure it out how to solve it any other way.",['trigonometry']
3147318,Probability of the Champions League quarter final draw featuring at least one all-English clash.,"Four English teams have progressed to the Champion's League quarter finals this year (for the first time since 2008). What is the probability that at least one quarter final will be an all-English tie? My attempt Obviously this is the complement of there being no all-English ties. Suppose the order of the teams (and the fixtures) matters (i.e. $AB,\;CD,\;EF,\;GH$ is a different draw from $DC,\;AB,\;HG,\;EF$ ). Then there are $8!$ total possible draws. If we try to count the number of possible draws with no all-English ties, we have $8$ choices for the first team and $4$ for the second; $6$ choices for the third team and $3$ for the fourth; $4$ choices for the fifth team and $2$ for the sixth; $2$ choices for the seventh team and $1$ for the eighth. This makes $8\times4\times6\times3\times4\times2\times2\times1=9216$ draws with no all-English ties, so the probability of at least one all-English tie is \begin{equation}
1-\frac{9216}{8!}=\frac{27}{35}.
\end{equation} Two questions: Have I got the right answer? What would be a more elegant way of going about this? Even if it is correct, I think my argument is 'lucky' in the sense that it wouldn't work for any other number of English teams.","['combinatorics', 'probability']"
3147324,"An optimization problem in $L^1(0,1)$","Is there any non-negative function $f(t)$ that minimizes $\int_0^1e^{\int_0^tf(s)ds}dt$ and satisfies $\int_0^1sf(s)ds =1$ ? I guess there is not, because the exponential is minimized if $\int_0^tf(s)ds$ is as small as possible. However, for such functions there can never be $\int_0^1sf(s)ds\neq 0$ .","['convex-optimization', 'real-analysis', 'functional-analysis', 'optimization', 'convex-analysis']"
3147333,"Recurrence relation for the number of strings of length $n$ over the alphabet $\{1, 2,3,4,5,6,7\}$ such that there are no consecutive $1$'s or $2$'s.","Find a recurrence relation for the number of strings of length $n$ over the alphabet $\{1, 2,3,4,5,6,7\}$ such that there are no consecutive $1$ 's or $2$ 's. I have no idea where to start. I've been stuck for some time. Any help is appreciated, Thanks.",['combinatorics']
3147334,"Prime ideals in $\mathbb{Z}[X], \mathbb{Q}[X], \mathbb{F}_{19}[X]$.","Old exam question Consider the following ideals : $I = (X^{2018}+3X+15)$ ; $J = (X^{2018}+3X+15, X-1)$ ; $K = (X^{2018}+3X+15, 19)$ . Determine whether they are prime ideals in $\mathbb{Z}[X], \mathbb{Q}[X], \mathbb{F}_{19}[X]$ , respectively. As $\mathbb{Z}[X]$ is a UFD, $X^{2018}+3X+15$ satisfies Eisenstein's criterion at $p=3$ , so is it irreducible in $\mathbb{Z}[X]$ . Now for PIDs , we know that all irreducibles are prime, but as $\mathbb{Z}[X]$ is not a PID, we cannot invoke the equivalence $$(p) \text{ is a prime ideal} \iff p \text{ is a prime element} \iff p \text{ is irreducible}.$$ Is there another way to determine that $I$ is prime? If so, would that imply it is irreducible in $\mathbb{Q}[X]$ ? 
For $\mathbb{F}_{19}[X]$ I'm not sure whether it's different then for $\mathbb{Z}[X]$ , as ""reduction modulo 19"" does nothing in this case. I do see that for $K$ , the case $\mathbb{F}_{19}[X]$ reduces to the same case for $I$ , as $\bar{19} = \bar{0}$ , so this does not add anything to the ideal. For $J$ , I see no feasible strategy at all.","['maximal-and-prime-ideals', 'unique-factorization-domains', 'ring-theory', 'abstract-algebra', 'polynomial-rings']"
3147369,"Let $x_1$ and $x_2$ be independent uniform variables from [0, 2]. What is the probability that $|x_1-x_2| \leq 1$?","What I have so far for the solution Since they are both continuous uniform variables. And because they are independent, we can say that $$f(x_1, x_2)=\frac{1}{4}$$ $$P(|x_1-x_2| \leq 1) = P(x_1-1 \leq x_2 \leq x_1+1)$$ $$P(x_1-1 \leq x_2 \leq x_1+1) = \int_{-\infty}^{+\infty} \int_{x_1 - 1}^{x_1 + 1}\frac{1}{4}dx_2dx_1$$ What I am having trouble with However, when I compute the aforementioned integral, I get a probability of $1$ or $100\%$ $$\int_{-\infty}^{+\infty} \int_{x_1 - 1}^{x_1 + 1}\frac{1}{4}dx_2dx_1 = \int_{0}^{2} \int_{x_1 - 1}^{x_1 + 1}\frac{1}{4}dx_2dx_1 = 1$$ I know that I am supposed to get $\frac{3}{4}$ . But I have no idea how.","['statistics', 'probability']"
3147371,Identity involving product of two binomial coefficients,"Emprically it looks like the following identity holds, but I haven't been able to prove it. Can anyone find a proof? $$
¥binom{m+k}{k}¥binom{n+k}{k}=¥sum_{i¥geq0}¥binom{m}{i}¥binom{n}{i}¥binom{m+n+k-i}{k-i}
$$ For some context, a corollary would be that the generating function for the LHS keeping $m$ and $n$ fixed is $$
¥sum_{k¥geq0}¥binom{m+k}{k}¥binom{n+k}{k}x^k=¥frac{¥sum_{i¥geq0}¥binom{m}{i}¥binom{n}{i}x^i}{(1-x)^{m+n+1}}
$$","['binomial-coefficients', 'combinatorics', 'generating-functions']"
3147382,How to maximize the expected number of corrected guesses?,"A, B are to play heads or tails for $N$ rounds. They win a round if both guess correctly. A and B are allowed to communicate their strategy before the game starts. A knows the full sequence of $N$ results right after the game starts, before making the first guess. A and B make their guesses simultaneously, and know each others' previous guesses, as well as the correct results of previous rounds. How to design an algorithm that maximizes the expected number of correct guesses in this game? An obvious solution that's better than random guessing would be for A to  spend the first $\lceil{N/2}\rceil$ rounds communicating the results of the last half of the game to B, giving an expected $N/2\times (1/2)^2+N/2=5N/8$ wins. Would there be better solutions?","['information-theory', 'compression', 'probability', 'algorithms']"
3147394,Null spaces and invertible matrix,"If $A$ and $B$ are $n×n$ matrices, show that they have the same null
  space if and only if $A = UB$ for some invertible matrix $U$ . I started the question by saying $Ax = 0$ for some vector $x$ in $\text {null}(A)$ . Now I'm lost.
Could someone please help me out with this question? Thank you very much.",['linear-algebra']
3147418,distributive law of set in this book seems incomplete,"I saw this equation from a Chinese math book: $$ (A\setminus B) \cap C = (A \cap C) \setminus (B \cap C) $$ IMO, the equation can be more general like this, which is actually the law of commutation. $$ (A\setminus B) \cap C = (A \cap C) \setminus B$$ Am I correct? And even more, I think this equation is also correct: $$ (A\setminus B) \cap C = (A \cap C) \setminus (A \cap B)$$",['elementary-set-theory']
3147423,Differentiate $11x^5 + x^4y + xy^5=18$,"I am not sure how to differentiate $11x^5 + x^4y + xy^5=18$ . I have a little bit of experience with implicit differentiation, but I'm not sure how to handle terms where both variables are multiplied together. I have tried $$\frac{d}{dx}(11x^5 + x^4y+xy^5) = \frac{d}{dx}(18)$$ $$\frac{d}{dx}(11x^5)+\frac{d}{dx}(x^4y) + \frac{d}{dx}(xy^5)=0$$ differentiating each term $$\frac{d}{dx} (11x^5)=11\frac{d}{dy}(5x^4) = 55x^4$$ $$\frac{d}{dx} (x^4y) = [4x^3 \cdot y] + [1 \cdot x^4] = 4yx^3+x^4$$ $$\frac{d}{dx}(xy^5) = [1 \cdot y^5] + [x \cdot 5y^4] = y^5 + 5xy^4$$ finding $\frac{dy}{dx}$ $$\frac{dy}{dx}=\frac{-x}{y} = \frac{-[4yx^3+x^4] + [y^5+5xy^4]}{55x^4}$$ According to the website I'm using, ""WebWork"", this is wrong.","['calculus', 'implicit-differentiation', 'derivatives']"
3147433,"Prove that among any set of 34 different positive integers that are at most 99, there is always a pair of numbers that differ by at most 2.","Alright, so I'm pretty new at this. I feel like this should be a pretty simple solution, but I don't know how to start. So here's where I was going If we have a set $\{1,2,...,99\}$ and then I start making groups that have a pair of integers that differ by 2 at the most. $$
\text{group}_1 = (1,2)\\
\text{group}_2 = (3,4) \\
\vdots \\
\text{group}_{49} = (97,98)
$$ Now I know I don't use $99$ but it says at most $99$ . Another thing I could do is make the groups like so \begin{align}
\text{group}_1 &= (1,3) \\
\text{group}_2 &= (2,4)\\
\text{group}_3 &= (5,7)\\
\text{group}_4 &= (6,8)\\
&\vdots\\
\text{group}_{48} &= (94,96)\\
\text{group}_{49} &= (95,97)\\
\text{group}_{50} &= (98,99)
\end{align} and I think this works better. Now from here I'm not sure how to progress, in fact I think this is the wrong path to go down but I don't know how to solve this in a different way. Maybe I could use the pigeon hole principle but I don't know how.","['combinatorics', 'discrete-mathematics', 'computer-science']"
3147491,Matrices Inequality Proof,"Recently, I read a paper and there is a step which turns out not obvious to me. The statement is as follows: All matrices here are real matrices. $F$ is an arbitrary square matrix. $\Psi$ is a symmetric positive definite matrix. Let $$\lambda_{\max}(A)\equiv\text{The maximum eigenvalue of symmetric matrix A}$$ (The ambiguity comes when $A$ is not symmetric. Here I guess if $A$ is not symmetric, then $\lambda_{\max}(A)=\sqrt{\text{Maximum eigenvalue of }A^TA}$ ). Then the following inequality holds: For all $x\in \mathbb R^n$ $$x^T(I-F)^T\Psi(I-F)x\le\lambda_\max(\Psi^{-1}(I-F)^T\Psi(I-F))x^T\Psi x
$$ rewrite it, $$x^T\Big[(I-F)^T\Psi(I-F)-\lambda_\max(\Psi^{-1}(I-F)^T\Psi(I-F))\Psi\Big]x\le0
$$ or $$x^T\Psi\Big[\Psi^{-1}(I-F)^T\Psi(I-F)-\lambda_\max(\Psi^{-1}(I-F)^T\Psi(I-F))I\Big]x\le0\tag{*}
$$ and if $\Psi$ commutes with $(I-F)^T\Psi(I-F)$ , then, $\Psi^{-1},\,(I-F)^T\Psi(I-F)$ can be simultaneously diagnolized. Then $$\Psi^{-1}(I-F)^T\Psi(I-F)-\lambda_\max(\Psi^{-1}(I-F)^T\Psi(I-F))I
$$ is negatively semi-definite and diagnolized under certain basis, same as $\Psi$ . Then under the basis, since $\Psi$ is positive definite, $\Psi\Big[\Psi^{-1}(I-F)^T\Psi(I-F)-\lambda_\max(\Psi^{-1}(I-F)^T\Psi(I-F))I\Big]$ is negative semi-definite $\Rightarrow$ the inequality holds. However, in general, $\Psi$ may not commute with $(I-F)^T\Psi(I-F)$ . Are there any answers to that?","['matrices', 'inequality', 'positive-semidefinite', 'lie-groups']"
3147533,Crossing time(meeting time) of a gaussain random walk,"Assume $\{S_n\}_1^\infty$ is a random walk, where $S_n=\sum_{i=1}^n X_i$ and $X\sim N(1,1)$ , where N(1,1) is normal distribution with mean 1 variance 1. Define stopping time when it cross a positive threshold $a$ and a negative threshold $-a$ . $$T^+(a)=\inf\{t\in Z^+, S_t>a\}$$ $$T^-(a)=\inf\{t\in Z^+, S_t<-a\}$$ And the crossing time of the random walk is defined as the earlier cross $T(a)=min\{T^-(a),T^+(a)\}$ . 
We already know $\lim_{a\to+\infty}E[T^+(a)]/a=1$ (equals to expectation of $X$ ). The first question is how to make it clear that $\lim_{a\to+\infty}E[T(a)]/a=1$ . Since the probability of hitting negative threshold is greater than zero (although very small), it should be considered when quantifying $E[T(a)]$ . The second question is that if there are more that one independent random walk, will this result still hold for the minimal or maximal stopping time among those random walks? For example, there are two random walks, $\{S^1_n\}_1^\infty$ and $\{S^2_n\}_1^\infty$ , define $T_1(a)$ and $T_1(a)$ the same as $T(a)$ . And the minimal or maximal stopping time is $$\underline{T}(a)=min\{T_1(a),T_2(a)\},\overline{T}(a)=max\{T_1(a),T_2(a)\}$$ Do we have $\lim_{a\to+\infty}E[\overline{T}(a)]/a=1$ and $\lim_{a\to+\infty}E[\underline{T}(a)]/a=1$ ? Can we prove it?","['stochastic-processes', 'random-walk', 'probability-theory', 'asymptotics']"
3147620,"Is there a way to describe the structure of $Aut(UT(3, p))$?","Is there a way to describe the structure of the automorphism group of $$C_{p}^2 \rtimes C_p \cong \langle x, y, z | [x,y]=z, [x,z]=[y,z]=x^p=y^p=z^p=e \rangle \cong UT(3, p)?$$ Here $p$ is an odd prime. The only thing I know about it is, that $Inn(UT(3, p)) \cong \frac{UT(3, p)}{Z(UT(3, p))} \cong C_p \times C_p$ , however $UT(3, p)$ is also very likely to have outer automorphisms, which I do not know how to describe. Also, one can see, that all inner automorphisms of $UT(3, p)$ are of the form $$\begin{pmatrix}
  1 & x & y \\
  0 & 1 & z\\
  0 & 0 & 1 
 \end{pmatrix} \mapsto \begin{pmatrix}
  1 & x & y + (a-c)z -ac\\
  0 & 1 & z\\
  0 & 0 & 1
 \end{pmatrix}$$ for some $a, c \in \mathbb{F}_p$ . However, this does not help much.","['automorphism-group', 'group-presentation', 'finite-groups', 'matrices', 'group-theory']"
3147645,Two forms related by an automorphism are in the same cohomology class?,"Let $f: M \to M$ define an automorphism on the smooth manifold M. Given a differential form $\omega \in \Omega^k$ is it true that the de Rham cohomology class of $\omega$ and $f^*\omega$ are the same? That is, does $[\omega]=[f^*\omega]$ .","['de-rham-cohomology', 'differential-geometry']"
3147655,population distribution & sampling distribution [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question What is the difference between the population distribution of a random variable X and the sampling distribution of a random variable that is a sample statistic? This is a question I got from my econometrics teacher, but I'm very uncertain about the terms that she uses.
It would help me greatly if some simple and straightforward explanation can be given.
Thank you in advance.","['statistics', 'probability-distributions', 'sampling']"
3147674,Is there a fiber bundle/espace-etale interpretation of sheaves on a Grothendieck site,"Whenever I'm doing sheaf things and I have a construction that involves sheafifying, I find it convenient to think ""the thing that has the same stalks but sections must be locally trivial sections to espace etale"" - it's a nice way to think of/characterize sheafification, sections of sheaves, define pullbacks, etc. Can we do the same thing on a general, reasonable site (e.g. etale, flat, etc), i.e. for say $\mathscr{F}$ a sheaf on a scheme $X$ on the etale site, can we form something like $\coprod \mathscr{F}_x$ as $x$ runs over geometric points, suitably ""Grothendieck topologized"" so that the Grothendieck continuous sections over $U \to X$ are precisely $\mathscr{F}(U \to X)$ ?","['etale-cohomology', 'grothendieck-topologies', 'category-theory', 'algebraic-geometry', 'sheaf-theory']"
3147683,Group automorphism of multiplicative group of real number field,"Let $\mathbb{R}$ be the real number field and $\mathbb{R}^{\times}$ be the multiplicative group of it. $\mathrm{Aut}(\mathbb{R}^{\times})$ denotes the group automorphism of $\mathbb{R}^{\times}$ . [My Question $(*)$ ] Do all elements $\phi \in \mathrm{Aut}(\mathbb{R}^{\times})$ have the form $\mathbb{R}^{\times} \rightarrow \mathbb{R}^{\times} , x \mapsto x^r$ , where $r$ is a real number. I'm trying to solve this question $(*)$ .
But I have no idea how to solve it. Can you answer this question $(*)$ and explicitly write $\mathrm{Aut}(\mathbb{R}^{\times})$ ?","['real-numbers', 'automorphism-group', 'field-theory', 'multiplicative-function', 'group-theory']"
3147687,"If $z=\sqrt{3}+i=(a+ib)(c+id)$, then find $\tan^{-1}\dfrac{b}{a}+\tan^{-1}\dfrac{d}{c}$","If $z=\sqrt{3}+i=(a+ib)(c+id)$ , then $\tan^{-1}\dfrac{b}{a}+\tan^{-1}\dfrac{d}{c}=$ _______________ $$
\arg z=\theta,\quad\arg(a+ib)=\theta_1,\quad\arg(c+id)=\theta_2\implies\arg(z)=\theta=\theta_1+\theta_2=\frac{\pi}{6}\\
\tan\theta=\tan\frac{\pi}{6}=\frac{1}{\sqrt{3}},\quad\tan\theta_1=\frac{b}{a},\quad\tan\theta_2=\frac{d}{c}\\
\implies\theta_1=n\pi+\tan^{-1}\frac{b}{a},\quad\theta_2=m\pi+\tan^{-1}\frac{d}{c}\\
\theta=\frac{\pi}{6}=(n+m)\pi+\tan^{-1}\frac{b}{a}+\tan^{-1}\frac{d}{c}\\
\tan^{-1}\frac{b}{a}+\tan^{-1}\frac{d}{c}=\frac{\pi}{6}-(n+m)\pi=\frac{\pi}{6}+k\pi
$$ Is it the right way to prove that $\tan^{-1}\dfrac{b}{a}+\tan^{-1}\dfrac{d}{c}=n\pi+\dfrac{\pi}{6}$ ?","['trigonometry', 'complex-numbers']"
3147730,Proof of identity for $\pi$: $\frac{\pi}{3} = \frac{2}{\sqrt{2+\sqrt{3}}}\frac{2}{\sqrt{2+\sqrt{2+\sqrt{3}}}}\cdots$,"While browsing the internet today, I came across the following picture: (full image can be found here - credit to Цогтгэрэл Гантөмөр) Now, it would naturally seem we can extend this to an infinite product; specifically, I would guess from this post that we have $$\bbox[5px,border:2px solid red]{ \frac{\pi}{3} = \frac{2}{\sqrt{2+\sqrt{3}}}\frac{2}{\sqrt{2+\sqrt{2+\sqrt{3}}}}\frac{2}{\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{3}}}}} \cdots}$$ where we define this product formally by $$\frac{\pi}{3} = \prod_{n=1}^\infty \frac{2}{a_n} $$ where $a_n$ is defined by $a_n = \sqrt{2+a_{n-1}}$ with initial value $a_0 = \sqrt{3}.$ However, I have never seen this expression for $\pi$ in the literature. Given this product comes from a geometric argument bounding the value of $\pi,$ I would fully expect this product to be studied, but I do not know where to look. The most similar product I am aware of is $$\frac{2}{\pi} = \sqrt{\frac{1}{2}}\sqrt{\frac{1}{2} + \frac{1}{2}\sqrt{\frac{1}{2}}}\cdots$$ namely formula $(65)$ on this page . I would imagine that, like this similar looking formula for $\frac{2}{\pi},$ the above product for $\frac{\pi}{3}$ should be the result of evaluating some rational function of trigonometric functions, but how to go about this is not immediately clear to me. Is anyone aware of an existing proof or refutation of this product in the literature, or else can provide one? Edit 1: I have numerically checked this with the following quick and dirty Javascript code, which seems to imply convergence is decently rapid: a = Math.sqrt(3);
piEstimate = 1;
for (i = 0; i < 100; i++) {
  a = Math.sqrt(2 + a);
  piEstimate *= 2/a;
}
console.log(3 * piEstimate)","['infinite-product', 'calculus', 'pi', 'trigonometry']"
3147735,"Show that $\lim_{n\rightarrow\infty}\int_{0}^{n}\frac{\sqrt x\ln x}{(1+x)^2}\,dx=\pi$","Show that $\lim_{n\rightarrow\infty}\int_{0}^{n}\frac{\sqrt x\ln x}{(1+x)^2}\,dx=\pi$ . This limit puzzled me as I never worked on this kind before and I am inclined to think that, as the $n$ is in the integral's boundary, there is a theorem involved like the dominant convergence theorem. I tried integrating by parts, but the $0$ of the integral prevented me from applying $log0$ . How should I handle it?","['integration', 'limits', 'calculus']"
3147737,Continuity for the composition of 2 functions,"Q) Consider the following functions $f(x) = \left\{\begin{matrix} 1, & |x| \leq 1 \\ 0, & |x| > 1 \end{matrix}\right.$ and $g(x) = \left\{\begin{matrix} 1, & |x| \leq 2 \\ 2, & |x| > 2 \end{matrix}\right.$ Define $h_{1}(x) = f(g(x))$ and $h_{2}(x) = g(f(x))$ . Which of the following statements is correct ? (A) $h_1$ and $h_2$ are continuous everywhere (B) $h_1$ is continuous everywhere and $h_2$ has discontinuity at $\pm 1$ (C) $h_2$ is continuous everywhere and $h_1$ has discontinuity at $\pm2$ (D) $h_1$ has discontinuity at $\pm2$ and $h_2$ has discontinuity at $\pm1$ My Attempt :- I can rewrite $f(x)$ and $g(x)$ as :- $f(x) = \left\{\begin{matrix} 1, & 0 \leq x \leq 1 \;\cup\; -1 \leq x < 0  \\ 0, & x > 1\; \cup\; x <-1 \end{matrix}\right.$ $g(x) = \left\{\begin{matrix} 1, & 0 \leq x \leq 2 \;\cup\; -2 \leq x < 0  \\ 2, & x > 2\; \cup\; x <-2 \end{matrix}\right.$ Here, $f$ has jump discontinuity at $ \pm 1$ and $g$ has jump discontinuity at $ \pm 2$ . Now, For $h_1=f(g(x)),$ $f(-1 \leq g(x) \leq 1) =1 $ when $-2 \leq  x \leq 2 $ and $f(g(x) >1 \; \cup\; g(x) < -1) =0 $ when $x>2 \; \cup \;   x < -2 $ So, $h_1=f(g(x))$ has discontinuity at $ \pm 2$ Now, For $h_2=g(f(x)),$ $g(-2 \leq f(x) \leq 2) =1$ when $-\infty < x< \infty$ So, $h_2=g(f(x))$ is continuous everywhere. So, I am getting answer as $(C).$ Please verify whether it is correct or not.","['continuity', 'calculus', 'functions']"
3147742,Mapping of Complex function,"Let $w = f(w)=(3+4i)z- 2 +i$ Find the images of the disk $|z-1|<1$ and the half-plane $Im(z)>1$ For the first mapping of the disk I attempted the following : $$z = \frac{w+2-i}{3+4i}$$ which then gives us $$|\frac{w+2-i}{3+4i} - 1| < 1$$ $$|w-(1+5i)| < |3+4i|$$ $$|w-(1+5i)| < 5$$ And this is just a circle with origin (1,5) with a radius of 5 For the second image I did the following : Let $z=x+iy$ thus $$w =(3+4i)(x+iy)-2+i=(3x-4y-2)+i(3y+4x+1)$$ Then $y=1$ gives $u=3x-2$ and $v=4+4x$ which leads to the line $u=\frac{3}{4}v-5$ Are these mappings correct ?",['complex-analysis']
3147774,"Show that if all solutions of $\frac{dy}{dx}=A(x)y$ are periodic with period $T$, than $\int_0^T \text{Trace }A(t) dt=0$","Let $A:\mathbb R \rightarrow L(\mathbb R ^n, \mathbb R^n)$ be
  continuous and periodic  with period $T$ . Show that if all solutions
  of $\frac{dy}{dx}=A(x)y$ are periodic with period $T$ , than $\int_0^T
 \text{Trace }A(t) dt=0$ Intuitively I can see why this is true, but I'm not really sure if I'm on the right track with showing it formally. If we know all solutions are periodic, we have that for all $x$ , $y(x)=y(x+T)$ and thus $$\frac{dy(x)}{dx}=\frac{dy(x+T)}{dx}$$ From this it follows that $$A(x)y(x)=A(x+T)y(x+T)$$ So we also have that $A(x)=A(x+T)$ . So now I know $\int_0^T
 \text{Trace }A(t) dt=\int_0^T
 \text{Trace }A(t+T) dt$ and I want to show that this is $0$ . I don't really know where to go from here. This chapter we did learn things about the fundamental matrix, so I think I might need to use something like $det \psi(x)= e ^{\text{trace } A(x) x}$ , but so far I don't know how to.","['integration', 'linear-algebra', 'ordinary-differential-equations']"
3147807,Minimum Elementary row/column transformations to find Inverse of given Matric,"While working out some elementary transformation to find Inverse of matrix, it get in my mind, what is the minimum number of elementary transformations needed to find the inverse of a matrix? Editor's note: see Finding the inverse of a matrix by elementary transformations. for the method of elementary transformation EDIT. Here is a detailed description of the studied issue. We are interested in the inversion of matrices, defined on a field (finite or not), by methods of Gauss type; we know the maximum complexity of these methods. We ask which are the matrices whose inversion requires the complete progress of the algorithm; in particular, do we find ourselves in the worst case almost always?",['matrices']
3147967,$\int_A fd\mu=0$ for all $A$ in a generator of the $\sigma$-algebra $\Rightarrow$ $f=0$ $\mu$-almost everywhere?,"Assume I have a measurable signed function $f$ for which the integral with respect to a measure $\mu$ , on some measurable sets $\mathcal{C}$ generating the sigma algebra $\mathcal{E}$ , is zero (maybe a $\pi$ -system). Is this enuough to imply the function is zero almost everywhere, if not what is needed?
Thanks.","['measure-theory', 'lebesgue-integral', 'real-analysis']"
3147977,Computing the limit of a function given the limit of its derivative,"Let $f:\mathbb{R}\to\mathbb{R}$ such that $f\in C^\infty$ and $f'(x)>0$ for all $x\in\mathbb{R}$ . Then, is it true that $$\lim_{x\to+\infty}f'(x)=0\Rightarrow\lim_{x\to+\infty} f(x)=a$$ for some $a\in\mathbb{R}$ ? I believe this is true due to the mean value theorem but I can't seem to properly show it, any help on where to start?","['limits', 'calculus', 'derivatives', 'real-analysis']"
3148006,How many of these lines lie entirely in the interior of the original cube? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question A portion of a wooden cube is sawed off at each vertex so that a small equilateral triangle is formed at each corner with vertices on the edges of the cube. The $24$ vertices of the new object are all connected to each other by straight lines. How many of these lines (with the exception, of course, of their end-points) lie entirely in the interior of the original cube?","['combinatorics', 'geometry']"
3148052,Definition of convexity via probability measure,"I found this alternative definition of convexity in a set of lecture notes on convex optimization: A subset $K \subset \mathbb R^n$ is convex if and only if for every probability measure $\mathbb P$ supported on $K$ , $\mathbb E [x] \in K$ . Here, $x$ is the coordinate function (i.e. the identity). I was unable to find any more information on this definition. I would like to know if it is equivalent (also: when is it equivalent? What about infinite-dimensional Banach spaces?) and how equivalence is proven. It's clear that this definition implies convexity defined in the usual way. For the converse, I tried a bit myself and came up with the following proof relying on the martingale convergence theorem, but it only shows that a compact set is convex if and only it fulfills the above condition. Also, I'm assuming that $\mathbb P$ is a Borel measure. Let $$\mathcal F_n := \sigma \left( \lbrace K \cap ( m_1 2^{-n},(m_1+1) 2^{-k}] \times \dots \times (m_n 2^{-n}, (m_n+1) 2^{-n}] \vert m_1,\dots ,m_n\in\mathbb Z \rbrace \right)$$ .
Then $\mathcal F_1 \subset \mathcal F_2 \subset \dots \subset \mathcal F_\infty \subset \mathcal B(K)$ is a filtration, w.r.t. which $$X_n :=  \mathbb E[x \vert  \mathcal F_n]$$ is a martingale, which, due to boundedness of $K$ , is uniformly bounded in the $L^2 (\mathbb P)$ norm.  Hence, it converges almost surely and in $L^2$ to $$X_n \to X_\infty = \mathbb E[x \vert \mathcal F_\infty ] = x$$ Therefore, $\mathbb E[X_n]=\mathbb E[\mathbb E[x\vert \mathcal F_n]]\in K$ (due to convexity of $K$ ) converges to $\mathbb E[x]$ . Since $K$ is closed, it implies that $\mathbb E[x] \in K$ . I'm grateful for all references.","['convex-geometry', 'probability-theory']"
3148066,Why do we run in diagonals when proving that $\mathbb{Q}$ is countable?,Why do we index the elements like this but not finishing the 1/x elements and then going through 2/x then 3/x...,"['elementary-set-theory', 'discrete-mathematics', 'rational-numbers']"
3148079,Proof of proper subsets,"I know that the procedure for formulating this proof is to let x $\in$ $B$ be arbitrary and then I need to show that x $\in$ $A$ . I've started with $2$ $<$ $x$ $\leq$ $3$ and separated it into two inequalities, $2$ $<$ $x$ and $x$ $\leq$ $3$ , but I am stuck on how I can make these look like $x^2$$-$$9$ $\leq$ $0$ and $x^2$ $-$ $4$ $>$ $0$ .",['elementary-set-theory']
3148132,Eccentricity of conic given by a complicated equation with trigonometric coefficients such as $\tan 10^\circ$,"Find the eccentricity of the conic given by: $$\left(x\tan 10^\circ+y\tan 20^\circ+\tan 30^\circ\right)\left(x\tan 120^\circ+y\tan 220^\circ+\tan 320^\circ\right)+2018=0$$ What I have tried $$\bigg(x\tan10^\circ+y\tan 20^\circ+\frac{1}{\sqrt{3}}\bigg)\bigg(\sqrt{3}\; x +y\tan 220^\circ+\tan 320^\circ\bigg)+2018=0$$ $$\begin{align}\Longrightarrow\quad 
&\sqrt{3}x^2+\sqrt{3}xy\tan 20^\circ+x+xy\tan 10^\circ\tan 220^\circ+y^2\tan 20^\circ\tan 220^\circ \\[4pt]
&+\frac{y}{\sqrt{3}}\tan 220^\circ+x\tan 10^\circ\tan 220^\circ+y\tan 20^\circ\tan 320^\circ+\frac{1}{\sqrt{3}}\tan 320^\circ \\[4pt]
&+2018=0
\end{align}$$ How do I solve it? Help me, please.","['analytic-geometry', 'trigonometry', 'conic-sections', 'geometry']"
3148263,Every Banach limit on $l_{\mathbb{C}}^{\infty}(\mathbb{N})$ is an extension of some Banach limit on $l_{\mathbb{R}}^{\infty}(\mathbb{N})$,"Let $l_{\mathbb{C}}^{\infty}(\mathbb{N})$ be the space of bounded complex-valued sequences, $l_{\mathbb{R}}^{\infty}(\mathbb{N})$ the subspace of real-valued sequences. Given any Banach limit $L_1: l_{\mathbb{R}}^{\infty}(\mathbb{N}) \to \mathbb{R}$ , you can define a Banach limit $L: l_{\mathbb{C}}^{\infty}(\mathbb{N}) \to \mathbb{C}$ by letting $L((a_n + i b_n)) = L_1((a_n)) + i.L_1((b_n))$ . However, the converse is also true - that any Banach limit on $l_{\mathbb{C}}^{\infty}(\mathbb{N})$ is an extension of some Banach limit on $l_{\mathbb{R}}^{\infty}(\mathbb{N})$ . This is equivalent to saying that any Banach limit on $l_{\mathbb{C}}^{\infty}(\mathbb{N})$ takes only real values on $l_{\mathbb{R}}^{\infty}(\mathbb{N})$ . The proof that I know uses contradiction to show that if a Banach limit takes (wlog) the value $i$ at some bounded real sequence, then it cannot have operator norm $1$ , so it is more technical than intuitive. I was wondering if there are any other intuitive proofs, or even some reasoning for why this should be true? EDIT: Say we define a Banach limit as a linear functional $L$ with the following properties: $||L||_{op}=1$ $ker(L) \supset M = \{x-Sx: x \in l_{\mathbb{C}}^{\infty}(\mathbb{N})\}$ , where $Sx$ is the left shift $S(x_1,x_2, ...) = (x_2, x_3, ...)$ $L(\mathbb{1}) = 1$ In the real-valued case, the usual definition of a Banach limit follows from these three properties. In particular, positivity is proved by scaling the sequence $x$ to lie between $0$ and $1$ , but the proof that $L(\frac{x}{||x||_{\infty}}) = 1 - L(\mathbb{1}-\frac{x}{||x||_{\infty}}) \geq 0$ seems to use the fact that $L$ is real-valued. So what is it about these three properties that forces the Banach limit to take real values on $l_{\mathbb{R}}^{\infty}(\mathbb{N})$ ? I hope this question is not too vague! I'm just curious about the differences in the theory of real and complex vector spaces in functional analysis.","['operator-theory', 'soft-question', 'functional-analysis', 'real-analysis']"
3148281,"Evaluating $\int_0^{\pi/2} \log \left| \sin^2 x - a \right|$ where $a\in [0,1]$.","How to evaluate $$
\displaystyle\int_0^{\pi/2} \log \left| \sin^2 x - a \right|\,dx
$$ where $a\in[0,1]$ ? I think of this problem as a generalization of the following proposition $$
\displaystyle\int_0^{\pi/2} \log  \left(\sin x\right)\,dx =-\frac12\pi\log2
$$ My try Put $$
I(a)=\displaystyle\int_0^{\pi/2} \log \left| \sin^2 x - a \right|\,dx
$$ From the substitution $x \to \frac{\pi}{2}-x$ , we get $$
\displaystyle\int_0^{\pi/2} \log \left| \sin^2 x - a \right|\,dx
=
\displaystyle\int_0^{\pi/2} \log \left| \cos^2 x - a \right|\,dx
$$ Thus $$
\displaystyle\int_0^{\pi/2} \log \left| \sin^2 x - a \right|\,dx
=
\displaystyle\int_0^{\pi/2} \log \left| \sin^2 x - (1-a) \right|\,dx
$$ which means $$I(a)=I(1-a) \tag{1}$$ On the other hand, \begin{align}
2I(a) &=
\displaystyle\int_0^{\pi/2} \log \left| (\sin^2 x - a)(\cos^2 x -a) \right|\,dx
\\ &=
\displaystyle\int_0^{\pi/2} \log \left| a^2-a+\sin^2 x \cos^2 x \right|\,dx
\\ &=
\displaystyle\int_0^{\pi/2} \log \left| 4(a^2-a)+\sin^2 (2x) \right|\,dx
-\pi \log 2
\\ &=
\frac{1}{2}\displaystyle\int_0^{\pi} \log \left| 4(a^2-a)+\sin^2 x \right|\,dx
-\pi \log 2
\\ &=
\displaystyle\int_0^{\pi/2} \log \left| 4(a^2-a)+\sin^2 x \right|\,dx
-\pi \log 2
\\ &=
\displaystyle\int_0^{\pi/2} \log \left| 1+4(a^2-a)-\sin^2 x \right|\,dx
-\pi \log 2
\\ &=
I((2a-1)^2)
-\pi \log 2
\end{align} Thus $$
2I(a)=I((2a-1)^2)-\pi \log 2 \tag{2}
$$ Let $a=0$ we get the proposition mentioned above $\displaystyle\int_0^{\pi/2} \log  \left(\sin x\right)\,dx =-\frac12\pi\log2.$ But how to move on ? Can we solve the problem only by $(1)$ and $(2)$ ? Or what other properties should we use to evaluate that? Looking forward to your new solutions as well. Thank you in advance! Added: As pointed out in the comments, it seems like that the integral is identical to $-\pi\log 2$ . From $(1)$ and $(2)$ we can also find many numbers such that $I(a)=-\pi\log 2$ .","['integration', 'definite-integrals', 'logarithms', 'calculus', 'trigonometry']"
3148290,Why is the definition of sin and cos in terms of exponentials is similar to the definition of $L_x$ & $L_y$ in terms of raising & lowering operators?,"I noted a similarity outlined below: The angular momentum operators in $x$ and $y$ direction can be written: $$L_x=\frac{1}{2}(L_++L_-)$$ $$L_y=\frac{1}{2i}(L_+-L_-)$$ $cos(x)$ and $sin(x)$ can be written: $$\cos(x)=\frac{1}{2}(e^{ix}+e^{-ix})$$ $$\sin(x)=\frac{1}{2i}(e^{ix}-e^{-ix})$$ Is there a particular reason for this manifest similarity, or it is just a mere coincidence, without much depth in it? Note: this question has been asked here as well: https://physics.stackexchange.com/q/466480/212053","['quantum-mechanics', 'trigonometry', 'exponential-function', 'complex-numbers']"
3148304,Set equality proof,"I know that for this proof I need to show that $A$ $\subseteq$ $B$ and $B$ $\subseteq$ $A$ . Starting with $A$ $\subseteq$ $B$ , I started by setting the equations equal to each other and solving for $x$ . $2x$ - $y$ + $7z$ = $x$ - $y$ + $5z$ gives, $x$ = $-2z$ . Plugging $x$ back into one of the equations, you get $(-2z)$ - $y$ + $7z$ = $0$ . Simplifying, I get $y$ = $3z$ . So, for all ( $x$ , $y$ , $z$ ) $\in$ $A$ , ( $x$ , $y$ , $z$ ) = ( $-2z$ , $3z$ , $z$ ). That is, ( $x$ , $y$ , $z$ ) = ( $-2c$ , $3c$ , $c$ ) since we took ( $x$ , $y$ , $z$ ) to be arbitrary. So ( $x$ , $y$ , $z$ ) $\in$ $B$ and $A$ $\subseteq$ $B$ . Now, I'm having trouble going in the other direction and showing that $B$ $\subseteq$ $A$ . I have the following thus far: Assume ( $x$ , $y$ , $z$ ) $\in$ $B$ . Thus, ( $x$ , $y$ , $z$ ) = ( $-2c$ , $3c$ , $c$ ). I'm not sure how to get from here to showing that $B$ $\subseteq$ $A$ .",['elementary-set-theory']
3148321,Small & Balanced family of sets,"I have the following problem: Let $\epsilon >0$ , and $[n] = \{ 1,2,...,n\}$ the set of positive integers up to $n$ .
  There exists a family of subsets $\mathcal{F} \subseteq 2^{[n]}$ , such that $|\mathcal{F}| = O(n)$ , and for every non-empty $S \subseteq [n]$ , one has $$ \epsilon |\mathcal{F}|  \hspace{0.2cm} \leq \hspace{0.2cm}
 | \{ F \in \mathcal{F} : |F \cap S| \mbox{ is odd } \}|
 \hspace{0.2cm} \leq \hspace{0.2cm} (1-\epsilon)|\mathcal{F}| ?$$ Maybe it is also a ""famous"" problem, maybe a trivial one, I don't know. Do you know something about this?","['ramsey-theory', 'combinatorics', 'extremal-combinatorics', 'discrete-mathematics']"
3148342,Some questions about additive groups of matrices,",I'm trying to solve this problem. I have two additive groups $G, H$ . The first is the group of matrices $4x1$ with coefficients in $\Bbb Z_{11}$ . The second is the group of matrices $3x1$ with coefficients in $\Bbb Z_{11}$ . Let a = $\left(\begin{matrix}
2 & 7 & 2 & 4 \\
3 & 5 & 1 & 2 \\
5 & 1 & 8 & 5
\end{matrix}\right)$ (coefficients in $\Bbb Z_{11}$ ) and $f: G \rightarrow H$ defined as $x \rightarrow a*x$ . Prove that $f$ is a homomorphism of additive groups. Tell which is the kernel and its order. Is $\left(\begin{matrix}
4 \\
6 \\
10
\end{matrix}\right)$ $\in H$ in the image of $f$ ? Since it is a very long and mechanical approach, I don't write my attempt to try that the function is a homomorphism (it is, maybe someone could confirm). Now I'm trying to find its kernel. I reasoned in a similar way to the approach used to verify the first point. First of all, I consider a general matrix $\in G$ : $\left(\begin{matrix}
x_1 \\
x_2 \\
x_3 \\
x_4
\end{matrix}\right)$ then I need to do the multiplication a $*$ b. I obtain the matrix: $\left(\begin{matrix}
2x_1+7x_2+2x_3+4x_4 \\
3x_1+5x_2+x_3+2x_4 \\
5x_1+1x_2+8x_3+5x_4
\end{matrix}\right)$ Now, by the kernel definition, I need to find when for certain matrices $\in G$ : $\left(\begin{matrix}
0 \\
0 \\
0 
\end{matrix}\right)$ It is sufficient to solve a system of three linear equations? In particular: $2x_1+7x_2+2x_3+4x_4=0 \\ 
3x_1+5x_2+x_3+2x_4=0\\
5x_1+1x_2+8x_3+5x_4=0$ If this is a good approach, how do I need to continue after I solved the system? How can I find the order of the kernel? Can I apply the same approach to answer the last question? If yes, which tells me that the element belongs or not the image of the function?","['matrices', 'group-theory', 'linear-algebra', 'discrete-mathematics']"
3148348,What are the possible solutions of $x+y+ {1\over x}+{1\over y}+4=2 (\sqrt {2x+1}+\sqrt {2y+1})$?,"I encountered a question in an exam in which we had: Find all possible solutions of the equation $$x+y+ {1\over x}+{1\over y}+4=2 (\sqrt {2x+1}+\sqrt {2y+1}) $$ where $x $ and $y$ are real numbers. I tried squaring both sides to eliminate the square roots but the number of terms became too many, making the problem very difficult to handle. I am not really able to understand how to find an easier approach or handle the terms efficiently. Would someone please help me to solve this question?",['algebra-precalculus']
3148354,What is the average distance of point in hypercube to its center?,"How do I compute the average distance of point inside an hypercube to the center of the hypercube as a function of the dimensionality of the space? Here I consider the hypercube defined as $C_n=\{x\in\mathbb{R}^n: -\frac{1}{2}\leq x_i\leq\frac{1}{2}, \forall_{i\leq n}\}$ with center $(0, ..., 0)\in\mathbb{R}^n $ Since for a random point in $C_n$ we have that each component $X_i$ is uniformly distributed between $-\frac{1}{2}$ and $\frac{1}{2}$ . And since all such components are independent, does it follow that: $$E\left[\sqrt{\sum_{i=1}^n X_i^2}\right] = \sqrt{E\left[\sum_{i=1}^n X_i^2\right]}=\sqrt{\sum_{i=1}^n E\left[X_i^2\right]}=\sqrt{\sum_{i=1}^n \frac{1}{12}}=\sqrt{\frac{n}{12}}$$ ? Edit:
Of course my calculation is wrong! the square root of the expected value is not the expected value of the square root! But the question remains: What is the correct expression? If we don't have closed form, could we even try to get the value recursively? as $\begin{align}
A(n) &= \int_0^{\frac{1}{2}}...\int_0^{\frac{1}{2}}\sqrt{x_1^2 + ... + x_n^2}dx_1...dx_n\\
&= \int_0^{\frac{1}{2}}...\int_0^{\frac{1}{2}}x_n\sqrt{\frac{x_1^2 + ... + x_{n-1}^2}{x_n^2}+1}dx_1...dx_n \\
&= \int_0^{\frac{1}{2}}x_n\left(\int_0^{\frac{1}{2}}...\int_0^{\frac{1}{2}}\sqrt{\frac{x_1^2 + ... + x_{n-1}^2}{x_n^2}+1}dx_1...dx_{n-1}\right)dx_n \\
&=? \int_0^{\frac{1}{2}}x_ng(A(n-1), x_n)dx_n
\end{align}$",['geometry']
3148481,Multivariable Limit - Converting to Polar Coordinates [duplicate],"This question already has answers here : Limit $\frac{x^2y}{x^4+y^2}$ is found using polar coordinates but it is not supposed to exist. (4 answers) Closed 4 years ago . I am new to this concept, but I do know that, using Cartesian coordinates,  if the limit is different for 2 different ""routes"", then it does not exist. I need to show that $$\lim_{(x,y)\to(0,0)}\frac{xy^2}{x^2+y^4}$$ DNE by converting to polar. However, the result I've got is that the limit does exists, and it's equal to $0$ . Here's what I did: $$
x=r\cos\theta\\
y=r\sin\theta\\
$$ $$
\lim_{(x,y)\to(0,0)}\frac{xy^2}{x^2+y^4}=
\lim_{r\to0}\frac{r\cos\theta (r\sin\theta)^2}{(r\cos\theta)^2+(r\sin\theta)^4}
=\lim_{r\to0}\frac{r^3\cos\theta \sin^2\theta}{r^2\cos^2\theta+r^4\sin^4\theta}
=\lim_{r\to0}\frac{r^\require{cancel}\cancel{3}\cos\theta \sin^2\theta}{\require{cancel}\cancel{r^2}(\cos^2\theta+r^2\sin^4\theta)}
=\lim_{r\to0}\frac{r\cos\theta \sin^2\theta}{\cos^2\theta+r^2\sin^4\theta}=\frac{0}{\cos^2\theta}=0
$$ Apparently no dependency on $\theta$ ? I mean, it is possible that $\cos^2\theta=0$ . How do I continue from here? Am I missing something? Thank you very much.","['multivariable-calculus', 'limits', 'calculus', 'polar-coordinates']"
3148581,Hausdorff metric and connectedness [duplicate],"This question already has an answer here : Connectedness of the Hausdorff distance. (1 answer) Closed 5 years ago . Let $(X, d)$ be metric space. Define $B_\epsilon = \{ x \in X : \exists b \in B \; d(x, b) \le \epsilon\} $ . Let $F(X)$ be a family of all nonempty compact subsets of $X$ (so $\emptyset \notin F(X)$ ). We shall define Hausdorff metric by: \begin{equation}
  D(A, B) = \inf \{ \epsilon \in \mathbb{R}^+ : A \subset B_\epsilon \; \land B \subset A_\epsilon \}.
\end{equation} Then $(F(X), D)$ is a metric space. What I would like to know is what is the relation between connectedness of $(X, d)$ and connectedness of $(F(X), D)$ . So far I was able to prove that if $(X, d)$ is not connected, then $(F(X), D)$ also is not connected. Here the main idea was that if (A, B) is a pair of nonempty subsets of $X$ such that $A\cup B = X$ and $A \cap B = \emptyset$ and $A, B$ are open, then $(2^A \cap F(X), F(X) \setminus 2^A \cap F(X))$ is a pair of nonempty, open subsets of $F(X)$ which sum to $F(X)$ and have empty intersection. (Which by contraposition means that connectedness of $(F(X), D)$ implies connectedness of $(X, d)$ ). Is the opposite implication true, that is, does connectedness of $(X, d)$ imply connectedness of $(F(X), D)$ ?","['general-topology', 'metric-spaces', 'hausdorff-distance']"
3148596,A monotonic function that intersect with all lines in $\mathbb R^2$,"Let $f:\mathbb R\to\mathbb R$ be a monotone function. Let $\gamma=\{(x,y)\ |\ y=f(x)\}$ is a curve in $\mathbb R^2$ . Does there exists a $f$ such that $\gamma\cap L\neq \emptyset \ \forall L\subset\mathbb R^2$ ; that is, $\gamma$ intersects with all lines? Intuitively there must exist some $f$ ; imaging a ""ladder"" bouncing between $y=x$ and $y=1.1x$ . But I failed to rigoroze this. What is the sufficient and necessary condition for a curve that does not intersect with at least one line (which means: $\exists L\subset\mathbb R^2$ such that $\gamma\cap L=\emptyset$ )?","['geometry', 'functions', 'functional-analysis', 'analysis']"
3148606,How to reconcile difference in notation used in probability and statistics by different authors,"After learning probability for so many years, I still have trouble with the notation whenever I encounter a new reference. I have pinpointed my confusion to this ""two-culture"" of probability: one is the probability done by often-times engineers and people who write introductory textbooks on probability (e.g., Sheldon Ross), the other is done by statisticians and more recently practitioners of machine learning. For the former (engineers and textbook writers), random variables are denoted as $X$ , pdf are written as $f_X(x)$ , jointed pdf are written as $f_{X,Y}(x,y)$ , where $x,y$ are in the range of random variables $X$ and $Y$ . Example: Sheldon Ross, Papolis and Pillai, Leon-Garcia, Bertsekas and Tsitsiklis, Feller, Kobayashi I found some notes online to illustrate this first culture of probability For statistics and machine learning, random variables are not denoted as anything, they are suppressed, pdf is written as $p(x)$ , where $x$ is the realization of this underlying unspecified random variable, joint pdf are written as $p(x,y)$ . Capital letters are almost never used, always lowercase. However, sometimes lower case letter is used to denote a random variable, e.g., $x \sim \mathcal{N}(\mu, \Sigma)$ Example: Bishop, David MacKay, Hastie, Mohri I found some online notes to illustrate this second culture of probability Am I correct in my assessment? Can someone who is familiar with this ""two-culture"" of probability provide a possible reconciliation between these notations?","['self-learning', 'statistics', 'machine-learning', 'soft-question', 'probability']"
3148635,Rademacher complexity definition,"I am learning the Rademacher complexity and have a question on the definition of it.
Let $\mathcal{H}$ be a hypothesis class and $m$ is the number of iid samples from a distribution $\mathcal{D}$ , say, $S=\{x_i\}_{i=1}^m$ . Then the Rademacher complexity is defined to be $$
R_s(\mathcal{H}) := \mathbb{E}_{\sigma} \sup_{h \in \mathcal{H}} \frac{1}{m}\left|\sum_{i=1}^m \sigma_i \ell(h,x_i) \right|,
$$ where $\sigma_i$ 's are iid uniform on $\{-1, 1\}$ .
It seems that the more appropreate definition should be $$
\tilde{R}_s(\mathcal{H}) := \mathbb{E}_{\sigma} \sup_{h \in \mathcal{H}}\left| \frac{1}{|S_+|}\sum_{i \in S_+} \ell(h,x_i) - \frac{1}{|S_-|}\sum_{i \in S_-} \ell(h,x_i)\right|,
$$ where $S_+ = \{i \in [m] | \sigma_i = 1\}$ and $S_+ = \{i \in [m] | \sigma_i = -1\}$ .
This is because the cross-validation should take the normalization constants into account. But I am not sure why the definition does not reflect the normalization constants. Any comments/suggestions/answers will be very appreciated.","['machine-learning', 'statistics']"
3148643,Example of a Non-negative Martingale Satisfying Certain Conditions,"Question The question is to find an example of a non-negative martingale $(X_n)$ with $EX_n=1$ for all $n$ such that $X_n$ converges almost surely to a random variable $X$ where $EX\neq 1$ and $\text{Var}(X)>0$ . My attempt An example of a martingale that I thought could fit the bill was the product martingale with $X_n=\prod_{i=1}^n Y_i$ where $(Y_{i})$ are i.i.d non-negative random variables with mean $1$ and $P(Y_i=1)<1$ . Unfortunately $X_n\to 0$ a.s and hence the limit is degenerate. Other examples, I tried to cook up (e.g. branching process with one individual) all had degenerate limits. I am having trouble coming up with an example that does not have a degenerate limit.","['martingales', 'convergence-divergence', 'probability-theory', 'probability']"
3148645,Proof that $x\sin(x)$ has infinite accumulation points,"I have to find a sequence with infinite many accumulation points and intuitively I thought about $\sin(x)$ - since it is periodic, it has points from its codomain that get repeated infinite many times. However, not infinite many points since all the y values that come from a sine function are bounded in the interval [-1,1]. 
But what about $xsin(x)$ ? The definition of accumuation point is: let $(a_n$ ) 
be a sequence of real numbers. The number a is said to be an accumulation point of $(a_n)$ if there exists a subsequence $(an_k)$ such that $\lim\limits_{k\to\infty} an_k=a$ .
If my intuition is correct from the plots it looks like each point get repeated infinite many times, together with the growth of the x value (in both directions). However I also need to come up with a formal proof to back up (or destroy) my intuition and here is where I got stuck. I thought about trying to describe a subsequence by exploiting the periodical behaviour, like I can say that 0 is an accumulation point of $sin(x)$ by choosing the subsequence $sin (\pi 
k),k\in\ \Bbb{Z}$ .
Am I on the wrong path or does it make some sense? Any feedback would be greatly appreciated.","['limits', 'periodic-functions', 'proof-verification', 'real-analysis']"
3148650,Material Derivative in Cylindrical Coordinates,"I'm testing myself on my knowledge from this book by taking the material derivative of velocity in cylindrical coordinates: $$\frac{D\mathbf u}{Dt}=\mathbf u\cdot \nabla \mathbf u$$ Which, in tensor notation, can be written as: $$\frac{\partial u^ig_i}{\partial t} + u^jg_j\cdot g^k\nabla_k u^i g_i$$ Which can be simplified to: $$\frac{\partial u^ig_i}{\partial t} + u^j\delta^k_j\nabla_k u^i g_i$$ And further: $$\frac{\partial u^ig_i}{\partial t} + u^j\nabla_j u^i g_i$$ Finally, the contravariant components can be written as: $$\frac{\partial u^i}{\partial t} + u^j(u^i_{,j}+\Gamma^i_{jk}u^k)$$ The expression above yielded the correct expressions for the $r$ and $z$ coordinates. For the $\theta$ -coordinate, however, I get the following expression: $$\frac{\partial u^\theta}{\partial t}+u^r(\frac{\partial u^\theta}{\partial r}+\frac{u^\theta}{r})+u^\theta(\frac{\partial u^\theta}{\partial r}+\frac{u^r}{r})+u^z(\frac{\partial u^\theta}{\partial r})$$ Which can be simplified to: $$\frac{\partial u^\theta}{\partial t}+u^r\frac{\partial u^\theta}{\partial r}+u^\theta\frac{\partial u^\theta}{\partial r}+\frac{2u^r u^\theta}{r}+u^z\frac{\partial u^\theta}{\partial r}$$ The physical components to this velocities are: \begin{align}
u^{(r)} & =u^r \\ 
u^{(\theta)} &= ru^\theta \\
u^{(z)} &= u^z
\end{align} However, putting the physical components back into the last expression, I end up with: $$\frac{1}{r}\frac{\partial u^{(\theta)}}{\partial t}+\frac{1}{r}u^{(r)}\frac{\partial u^{(\theta)}}{\partial r}+\frac{u^{(\theta)}}{r^2}\frac{\partial u^{(\theta)}}{\partial r}+\frac{u^{(r)} u^{(\theta)}}{r^2}+\frac{u^{(z)}}{r}\frac{\partial u^{(\theta)}}{\partial r}$$ Which is almost the definition for the material derivative, except that it is divided by $r$ for some reason. Any ideas where I might have gone wrong?","['derivatives', 'tensors', 'linear-algebra', 'fluid-dynamics']"
3148661,Why Cantor's diagonal proof applies to real but not to natural numbers (specific reason for repost),"I am aware that a very similar question was asked here before, but I still fail to understand the exact reason why Cantor's argument is applicable in one case and not in the other. In order to clarify my point, I wish to present two parallel attempted proofs - one more or less equivalent to Cantor's own (proving that the real numbers can't be listed) and one that will attempt to prove by an equivalent method that the natural numbers can't be listed/counted (which of 
course would make no sense if true). Could you please help me better understand Cantor's argument by telling me at which step my attempted parallel breaks down? I am not a mathematician - just someone trying to make sense of how infinite sets work. Step 1 - Cantor's Argument-CA): Let the number of members (cardinality) of the infinite set of Natural numbers be defined as aleph-0. Let any infinite set that is bijective with the set of Natural numbers be called countably infinite/listable. Step 1 - Parallel Argument-PA): Let the infinite set of Countable Numbers (C) be defined as follows {1*, 2*, 3*, 4*, 5*...}. (I am aware this is not a very formal definition, but I think it should be possible to formally and independently define an infinite set that is equivalent to the set of natural numbers). Let the number of members (cardinality) of the set of Countable numbers be defined as aleph-0. Let any infinite set that is bijective with the set of Countable numbers be called countably infinite/listable. Step 2 - Cantor's Argument): Let M be defined as the list of all infinite two-bit sequences. Let L denote a subset of M, constructed as an unbounded list of its members Li: L1, L2, L3 etc. Match each member of L with a member of N (Natural Numbers). The result would be something like: L1 - 10111101110110001... L2 - 0010110011101010... L3 - 1001011010101010... ...(it is not necessary for the list to be
complete) Step 2 - Parallel Argument) Let N be defined as the list of all finite two-bit sequences starting with 1. Let K denote a subset of N, constructed as an unbounded list of its members Ki: K1, K2, K3 etc. Match each member of K with a 
member of C (Countable Numbers). The result would be something like: -1* - K1 - 1 -2* - K2 - 10 -3* - K3 - 100010 -4* - K4 - 1000 -5* - K5 - 11101 -...(it is not necessary for the list to be complete) Step 3 - Cantor's Argument) For any number x of already constructed Li, we can construct a L0 that is different from L1, L2, L3...Lx, yet that by definition belongs to M. For this, we use the diagonalization technique: we invert the first member of L1 to get the first member of L0, then we invert the second member of L2 to get the second member of L0 and so on. In our case L0 = 011... -L0 belongs to M -L0 does not belong to L={L1, L2, L3...Lx} for any x. It follows that:
L={L1, L2, L3...Lx} for any x cannot be M. Given that L1, L2, L3... was each matched to a Natural number, it follows that there are more members of M than members of the Natural number set, therefore the set M is not countably 
infinite. It is possible to show that the set of real numbers is bijective with M, therefore the set of Real numbers is also not countably infinite. Step 3 - Parallel Argument) For any number x of already constructed Ki, we can construct a K0 that is different from K1, K2, K3...Kx, yet that by definition belongs to N. For that we use the copying and addition technique: going over the list sequentially, we copy the digits of each Kr (r=1 to x) into the corresponding digits of K0, always overwriting existing entries. After that we add one additional {0} at the end. In our case we get K0=111010...0. -K0 belongs to N -K0 does not belong to K={K1, K2, K3...Kx} for any x. It follows that: K={K1, K2, K3...Kx} for any x cannot be N. Given that K1, K2, K3... was each matched to a Counting number, it follows that there are more members of N than members of the Counting number set, therefore the set N is not countably infinite. It is possible to show that the set of Natural numbers is bijective with N, therefore the set of Natural numbers is also not countably infinite. Concluding remark: My problem with Cantor's argument is that the second premise in the syllogism in step 3 seems to fail because that premise seems to presuppose under L both an actually infinite list, and a constructed list {L1,
L2, L3...Lx} which is by definition finite. I would conclude that L is not defined and that therefore the conclusion doesn't really hold. Which would explain why, in my exposition, the argument paradoxically ""works"" for natural numbers as well. I am sure I am misconstruing something though and I will be grateful for your corrections. Thank you.",['elementary-set-theory']
3148688,Reparametrization of a curve in opposite direction and find intersection of two particles travelling in opossite directions on the same curve.,"Hi I need help with this problem: Given $$r(t)=(e^t,e^t\cos t, e^t \sin t),\quad t\in[0,2\pi]$$ It represents the trajectory of a particle $P$ . Draw the curve. Reparametrize $r$ such that it represents a particle $Q$ moving  in the opposite direction. If $P$ starts at one end of the curve and $Q$ starts at the other end (at the same time), find the point of the trajectory when they both crash. 1.- I first tried to draw the curve, but I don't know how to exactly do it with those $e^t$ in there. I tried by factoring them out like $e^t(1, \cos t, \sin t)$ , so I think that the that it would be like an spiral, because of $e^t$ , but I really don't know how to draw it. 2.- Then I tried to reparametrize r, so I put $-t$ instead of $t$ on $r$ , but I don't know if I'm correct. 3.- I don't know how to find the point when both particles collide, I was thinking of setting both parametrizations as equal and then finding the time $t$ that satisfies that, but I'm not sure.","['curves', 'multivariable-calculus', 'vector-analysis']"
3148705,"Calculus II Professor will not accept my correct integral evaluation that uses a different method, should I bring this up further?","I am a freshman enrolled at an American University. Recently, I took an examination in which the following problem appeared: Evaluate the following integral: $\int_0^4\sqrt{16-x^2}dx$ My answer: 4 $\pi$ , was correct. However, I received reduced credit for this answer because I did not solve it correctly (according to the professor). The exams are time-limited and have a fair amount of content, so when I saw this problem, I noticed it was the equation of the top half of a circle centered at (0, 0) and with radius 4. Knowing this, and my knowledge of the integral indicating the signed area under a curve, I merely took the area of a quarter-circle of radius 4, $\frac{1}{4}$$\pi$$r^2$ and wrote my answer of 4 $\pi$ . The context of the test was surrounding our unit on inverse trigonometry and integration by parts. This section of the test did not list any other instructions besides evaluating the definite integrals. I've talked to my professor about it and his only response was that I solved it wrong: To receive full credit, you would have had to evaluate an integral, as the instructions indicated. Is my interpretation of evaluating the integral different? Does the instruction ""Find the antiderivative and then evaluate"" not need to exist for that to be required? Thank you.","['integration', 'calculus']"
3148720,Showing that not all reals are algebraic using countability,"Definition : A number $z\in\mathbb{C}$ is said to be algebraic if there exist integers $a_0,a_1,\dots,a_n$ not all zero, such that $$
a_nz^n+a_{n-1}z^{n-1}+\cdots+a_1z+a_0=0
$$ I want to show that not every real number is algebraic. I thought in a simple argument but don't feel it's right: if every real was algebraic, for any $x\in\mathbb{R}$ we can find a sequence of integers $(a_0, a_1,\dots,a_n)\in\mathbb{Z}^{n+1}$ such that the equality above holds for $z=x$ . So we can define a function $f:\cup_{n\in\mathbb{N}}\mathbb{Z}^n\to\mathbb{R}$ that for each real associate a sequence of integers as described in the definition. So $f$ would be surjective, then once $\cup_{n\in\mathbb{N}}\mathbb{Z}^n$ is countable, so would be $\mathbb{R}$ , a contradiction because $\mathbb{R}$ is uncountable. So not all real numbers are algebraic. Is this line of reasoning right? Thanks in advance.","['elementary-set-theory', 'abstract-algebra', 'proof-verification', 'real-analysis']"
3148754,Is $e^{\int \frac {1}{x}dx}$ equal to $x$ or $|x|$?,"I encountered this expression quite a lot of times as a part of the integrating factor while solving linear differential equations. $$e^{\int \frac {1}{x}dx}$$ For sometime, I wrote it as $x$ , and was satisfied as even the answer given in my textbook had $x$ instead of $|x|$ . But after realising the possibility to be $|x|$ , I am confused. What should be the answer, and why? Edit: (My reasoning) $\int \frac {1}{X} dx = log |x|$ and $e^{logt} = t$ if I'm not wrong. So in this case, $t = |x|$ so the answer should be $|x|$ . What is wrong with this reasoning? And could you please provide a mathematical proof if the answer should be $x$ ? Edit 2: Wolfram Alpha evaluates e^(∫(1/x)dx) to $x$","['integration', 'indefinite-integrals', 'calculus', 'exponential-function']"
3148770,I'm having a hard time rationalizing the proof that $2^n > n^2$ if $n >4$,"I'm not sure how to apply $n > 4$ in the proof, when I work it out I get that $n >2$ ... Basis Step $P(5) = 2^5 > 5^2 = 32 > 25 $ which is True Hypothesis assume $P(k) = 2^k > k^2$ is true. Prove that $P(k+1)$ is true. Substituting $k+1$ into the hypothesis yields: $2^{k+1} > (k+1)^2$ $2 \bullet 2^k > k^2 +2k +1$ $2^k > \frac{k^2 +2k +1}{2}$ Since I assume $2^k > k^2$ I then try to find the conditions where $k^2 > \frac{k^2 +2k +1}{2}$ $2k^2 > k^2 +2k +1$ $k^2 -2k - 1 > 0$ which is true when $k > 4$ (and also $k >2$ ). Therefore the proof is true via mathematical induction?","['induction', 'discrete-mathematics', 'recursion']"
3148787,"Let $A, B$ be two positive definite $2 \times 2$ matrices. Prove or disprove: $AB+BA$ is positive definite.","I know that $AB+BA$ is not necessarily positive definite, as this question has been asked before on here. What I don't understand is how one would go about constructing counter-examples. Previous answers to this question just state the counter-examples, such as $A = \begin{bmatrix} 6 & 0 \\
0 & 1 \\ \end{bmatrix}$ , $B = \begin{bmatrix} 2 & 1 \\
1 & 1 \\ \end{bmatrix}$ . Is there some intuition behind how these matrices are chosen, or is it more a matter of just fiddling with $2 \times 2$ matrices until we find a counter-example? Thanks in advance.","['matrices', 'linear-algebra', 'positive-definite']"
3148800,Is Kaplansky's radical same as Jacobson radical?,"For a ring $R$ , Kaplansky defines $x\circ y= x+y+xy$ and an element $x$ is s.t.b. right quasi-regular (r.q.r) if $x\circ y=0$ for some element $y$ . He defines radical to be set theoretic join (sum) of all right quasi regular (r.q.r) ideals where an ideal is r.q.r if all its elements are r.q.r. Jacobson radical $J(R)$ is the intersection of maximal left (or right) ideals of a ring. Does either of these radical implies other or are they completely unrelated? I can't see any connection here.","['ring-theory', 'abstract-algebra']"
3148803,Does this property of comaximal ideals always hold?,"I am reading a paper in which the following result is used, but I can’t see the proof of this. Let $R$ be a commutative ring with only two maximal ideals, say $M_1$ and $M_2$ . Suppose $m_1 \in M_1$ is  such that $m_1 \notin M_2$ . Then can we always find $m_2 \in M_2$ such that $m_1+m_2=1$ ? Any ideas?","['ring-theory', 'abstract-algebra', 'maximal-and-prime-ideals']"
3148842,Solving an optimization problem involving a differential equation?,"I am trying to solve what I think is a single variable calculus optimization problem.  The actual problem I’m trying to solve is rather hard to describe, but I think it’s isomorphic to this one. Suppose there are two linked containers, container A and container B. Rain is falling on container A for the next hour, at the rate of $1$ liter per hour.  (Rain is not falling on container B.)  And water flows from container A to container B at a rate of $r(t) = \frac{q(t)}{1-t}$ , where $q(t)$ is the amount of water currently in container A.  Now at any time in the next hour, you can dump out all the water currently in container A (after which rain will continue to fall on container A).  But you can only do it once.  So what is the best time to do it if you want to minimize the amount of water that ends up in container B at the end of the hour? I think the basic situation is described by the differential equation $\frac{dq}{dt} = 1 - r = 1 - \frac{q(t)}{1-t}$ where $q(0)=0$ , whose solution according to Wolfram Alpha is given by $q(t)=(t-1)ln(1-t)$ .  And if the water in container A is dumped at time $T$ , then I think the amount of water in container B at the end of the hour is given by $P(T)= \int_0^T r(t) dt + 1 - q(T) = T - 2q(T) +2$ .  And we want to find the time $T$ between $0$ and $1$ which minimizes $P(T)$ . Yet there must be an error somewhere, because if I plug in $q(t)=(t-1)ln(1-t)$ into the expression for $P(T)$ , then for any value of $T$ between $0$ and $1$ , it looks like $P(T)>1$ .  But that makes no sense, because if only $1$ liter of water falls on container A over the course of the hour, there’s no way that there will be more than a liter of water in container B at the end of the hour.  So where am I going wrong?","['integration', 'optimization', 'calculus', 'ordinary-differential-equations']"
3148847,"Trigonometric series vanishes implies that we can ""group"" elements.","Define $$
 f_i(x) = A_i\sin(a_i x + \alpha_i) + B_i\cos(a_i x + \beta_i)
$$ and suppose that $$
\sum_{i=1}^\infty f_i(x) = \sum_{i=1}^\infty \left[A_i\sin(a_i x + \alpha_i) + B_i\cos(a_i x + \beta_i)\right] = 0
$$ for all $x\in \mathbb{R}$ . I am reading a proof in which the author claims that if the above is true, then element $f_i \not\equiv 0$ cancel out in ""groups"". That is, if $f_i\not\equiv 0$ , then there exists a subset $I\subseteq \mathbb{N}$ containing $i$ such that $\lvert a_j\rvert$ is constant over $j\in I$ and $$
\sum_{j\in I}^\infty f_j(x) = 0 \qquad\forall x\in\mathbb{R}.
$$ In the text, this is simply stated without justification. While the result does make some sense, it is not clear to me why it has to be true. How could I go about proving this? I'm not even sure how to go about a proof if the sum is finite, let alone infinite.","['sequences-and-series', 'real-analysis']"
3148874,"If $\frac{dy}{dx} = -0.02y^2+0.2y$ and $y(0)>0$, what is $\lim_{x\to\infty}y(x)$?","If $\frac{dy}{dx} = -0.02y^2+0.2y$ and $y(0)>0$ , what is $\lim_{x\to\infty}y(x)$ ? I thought that the answer was unsolvable since we don't know our value of y(0) but apparently the answer is 10 and I have no clue how to go about this","['integration', 'calculus', 'derivatives', 'algebra-precalculus']"
3148894,A Hard Combination Probability Equation From A Reality T.V. Show,"I was watching the T.V. show Survivor tonight and miserably failed at wrapping my mathematically out-of-practice post-college brain around a probability equation. Background: At the start of the show, 18 people are randomly divided into 2 tribes (red & blue) of equal size, so 9 each. Then tonight the 15 remaining people (6 red & 9 blue) found out that they would be randomly splitting again...but this time into 3 tribes of 5 (red, blue, & green). When they finished the random tribe swap, they were shocked to find that 5 of the 9 old blue team members remained together on the new blue team, 5 of the 6 old red team members all stayed together (but moved to green...not sure if it's relevant), and finally the remaining 4 of the 9 old blue team members and the 1 remaining old red team member ended up on the red team together. Long story short to the non-mathematically inclined viewer...wow nothing changed (rigged reality tv). But what is the probability of that actually happening? More specifically what is the probability that after all the randomization of teams, 2 of the 3 newly created teams would have 5 people that had previously been on a team together (when there were only 2 teams). Thanks ahead of time!","['random', 'statistics', 'probability', 'combinations']"
3148918,Prove that $\int_0^\infty e^{-x} \ln x d x = - \gamma $ [duplicate],"This question already has answers here : Showing that $\gamma = -\int_0^{\infty} e^{-t} \log t \,dt$, where $\gamma$ is the Euler-Mascheroni constant. (3 answers) Closed 5 years ago . I can see it is right by using some knowledge of the Gamma function. We have $$ \Gamma(\alpha ) = \int_0^\infty e^{-x} x^{\alpha - 1 } dx  . $$ Differentiating with respect to $\alpha$ , we get $$ \frac{d\Gamma}{d \alpha} = \int_0^\infty e^{-x} x^{\alpha - 1 }\ln x dx  .  $$ Setting $\alpha = 1 $ , we get $$ \int_0^\infty e^{-x} \ln x dx = \frac{d\Gamma}{d\alpha }\bigg|_{\alpha = 1 }= - \gamma.   $$ But the knowledge $d \Gamma/d \alpha |_{\alpha = 1}=-\gamma$ is a mystery to me. Can anyone find an elementary proof?","['integration', 'improper-integrals', 'gamma-function']"
3148923,All the roots of $5\cos x - \sin x = 4$ in the interval $0^{\circ} \leq x \leq 360^{\circ}$?,"This is a problem that I stumbled upon in one of my books. Representing $5\cos x - \sin x$ in the form $R\cos(x + \alpha)$ (as demanded by the question): $
\rightarrow R = \sqrt{5^2 + ({-}1)^2} = \sqrt{26}\\
\rightarrow R\cos x \cos \alpha - R\sin x \sin \alpha = 5\cos x - \sin x \\
\rightarrow ➊\hspace{0.25cm}5 = \sqrt{26}\cos \alpha \\
\rightarrow ➋\hspace{0.25cm}{-}1 = \sqrt{26}\sin \alpha \\
$ So here are my question(s): $\\$ • Why is only ➊ working out? • When I find one solution in the interval, which is 27°, why is another solution like $(360 - x)$ not working out (in this case 333°)? • I see 310.4° as a solution to this equation in my book. How do you get to 310.4° from 27° (which is the solution I got)? Which $\cos$ identity am I missing? And surprisingly, my book doesn't include 27° as a solution!",['trigonometry']
3148984,How to solve harmonic progression,This question was actually derived from a time complexity recurrence relation question. Please also explain how is this a harmonic series.? $$\frac 1{\log (n)- i}$$,"['discrete-mathematics', 'sequences-and-series']"
3149026,Prove the existence of countable unions,"I recently picked up the elementary set theory and I have reached the concept of sequences. The text then asks to prove the existence of the the set of all finite sequences of elements of a set , i.e., for any set $A$ , the set, $$\bigcup_{n\in \mathbb N}A^n$$ exists. Further, if this does exist, I suspect that countable union of existing set also exist. Can anyone prove this? I tried to prove that there is such a set $S\in \mathbb N$ that $\{A^n | n \in S\}$ exists, and $0 \in S$ , $n \in S$ implies $n+1 \in S$ , so that together with the axiom of union the prove is complete. But I failed to construct such a set. BTW, the farthest axiom I have reached is the axiom of infinity that basically grants the existence of inductive set. So it would be helpful if a proof given is based on that and anything before (axiom of union, power set, schema of comprehension, pair, existence and extensionality).",['elementary-set-theory']
3149066,Sum of random variables dependent on an ODE,"Let us assume we divide a piece of membrane into $n$ parts. Every part contributes with a specific electric potential, which is represented by $X_i\ $ $(i=1,\dots,n)$ random variables. So with probability $p_i$ the part $X_i$ is sending an impulse (mostly this impulse should be in the range of $[0,1]$ ). All $X_i$ are independent - maybe we can assume a $N(0,1)$ distribution. The $X_i$ are dependent on the total membrane voltage $V(t)$ . I want to show that the standard deviation of the sum $$\sum_{i=1}^{n}X_i$$ grows proportional to $\sqrt{n}$ . I can show that the standard deviation grows proportional to $\sqrt{n}$ , when neglecting the dependency on $V(t)$ . But I don't know how to deal with the dependency on a function. Maybe it would be a good idea to model the dependency regarding $dV/dt$ ? Shall I look at $\sum_{i=1}^{n}V(X_i)$ ? I don't know how to handle this issue.","['statistics', 'probability-theory', 'probability']"
3149086,Trace of product of semidefinite matrices is nonnegative,"I want to prove this: $A$ is a symmetric positive semi-definite matrix $\Leftrightarrow$ $tr(AB) \geq 0$ $\forall $ B positive semi-definite. I tried using eigenvalues, because they all have to be non-negative, but that didn't help me too much, as the eigenvalues of $AB$ are different from those of $A$ or $B$ . I would like some tips about where to start.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3149128,"Proof that $(\sin(x),\cos(x))$ describe a circle?","In my analytics class $\sin$ and $\cos$ were defined as follows: $$ \sin(x) =  \sum_{n=0}^\infty \frac{(-1)^{n}x^{2n+1}}{(2n+1)!} \text{ and } \cos(x) =  \sum_{n=0}^\infty \frac{(-1)^{n}x^{2n}}{(2n)!}$$ But how does one prove that $\sin$ and $\cos$ are actually the functions that are defined by triangles? In particular I  want to prove that $$t \to (\sin(t),\cos(t))$$ describes a circle for $t$ between $0$ and $2\pi$ where $\pi$ is defined as below. Here are things that have been proven in the class: Also it was proven that $$ \sin(x)^2  + \cos(x)^2 = 1$$ And a lot of formulas like this: $ \cos(x)=\cos(-x) \text{ and } \sin(x)=-\sin(-z)$ $\sin(x+y) = \sin(x) \cos(y) + \sin(x)\cos(y)$ Also it was shown that $\cos(x)$ has a zero point in [0,2] which we  defined as $\frac{\pi}{2} $ . Then we showed: $\sin(\pi)=0, \, \cos(\pi)=-1$ $\cos(\pi+x) = -\cos(x), \, \sin(\pi+x) = -\sin(x)$ $\sin(\frac{\pi}{2} + x) = \cos(x)$",['trigonometry']
3149153,Conditional probability with MLE of Poisson variable,"I'm having some trouble with this study question and would appreciate any help. This may be a duplicate but I have not been able to find any others. Question: Leaves of plants are examined for bugs. The number of bugs on a leaf follows a Poisson distribution with mean $\mu$ . However, many leaves have no bugs because they are unsuitable for feeding and not simply because of the chance variation allowed by the Poisson law. Therefore the empty leaves are not counted. a) Find the conditional probability that a leaf contains $x$ bugs, given that it contains at least one. b) Let $x_i$ be the number of bugs found on leaf $i$ (after the leaves with zero bugs are ignored).
Show that the MLE of $\mu$ satisfies the equation $$\hat{\mu}=\bar{x}(1-e^{-\hat{\mu}}).$$ c) Determine $\hat{\mu}$ numerically for the case $\bar{x}=3.2.$ My attempt: a) If X is the number of bugs on a leaf and Y is the number of observed bugs on a leaf, then the probability is given by \begin{align}
P(Y=x)&=P(X=x|X>0) \\
&=\frac{P(X=x)}{P(X>0)} \\
&=\frac{P(X=x)}{P(X>0)} \\
&=\frac{P(X=x)}{1-P(X=0)} \\
&=\frac{P(X=x)}{1-e^{-\mu}} \\
\end{align} b) Having some trouble with this. First I found the regular MLE of $\hat{\mu}$ for Poisson and got $\bar{x}=\hat{\mu}$ , so I'm assuming I need to use $$\frac{\mu}{1-e^{-\mu}}$$ in some way? Is this what my answer to a) is supposed to be? I tried finding the MLE of $\hat{\mu}$ again using this instead of $\mu$ but couldn't get the answer I needed. c) Not sure what to do here...","['statistics', 'maximum-likelihood', 'probability', 'estimation']"
3149212,A second order nonlinear differential equation,"How should I start to solve the following differential equation? $$
xy''+(n-1)y'-Cxy^\frac{n+2}{n-2}=0, 
$$ where $x>0$ , and $C$ is some constant. I have very little knowledge in differential equations, tried some substitutions that did not work. I guess if the zero order term was not raised to the power, than it would be a more standard task, because we could re-write this to get a system of ODEs.",['ordinary-differential-equations']
3149215,All definite integrals evaluate to 0 using periodic functions. [duplicate],"This question already has answers here : Why doesn't every integral from 0 to $2\pi$ equal zero? (4 answers) Closed 5 years ago . I know that my reasoning is incorrect, I just don't know where I went wrong. I did discuss this with my Maths teacher, and even she could not find what I did wrong. Let us begin by assuming a function, $f(x)$ that is continuous and has an antiderivative in the interval $[0, 2\pi]$ . Let $A$ be the area under the curve for $f(x)$ in the interval $[0, 2\pi]$ $A = \displaystyle \int_{0}^{2\pi}{f(x)\space\mathrm{d}x}$ Now there must exist a function, $g(x)$ such that: $f(x) = g(x)\cdot \cos(x)$ Substituting the value of $f(x)$ : $A = \displaystyle\int_{0}^{2\pi}{g(x)\cdot \cos(x)\space\mathrm{d}x}$ Using t substitution: Let $t = \sin(x)$ Then: $\mathrm{d}t = \cos(x)\space\mathrm{d}x$ And: $x = \arcsin(t)$ Changing the limits: $t = \sin(x)$ $0$ becomes $\sin(0) = 0$ $2\pi$ becomes $\sin(2\pi) = 0$ Substituting in the definite integral: $A = \displaystyle \int_{0}^{0}{g(\arcsin(t))\space\mathrm{d}t}$ But Definite Integral where the lower and upper bounds are the same is $0$ . So: $A = 0$ , which is not possible. Thanks for the help.","['integration', 'definite-integrals', 'inverse-function', 'calculus', 'trigonometry']"
3149245,"Writing a centered distribution function as $F(x)=\iint \frac{w } {u+w }1_{[u,w) }(x)+1_{([w,\infty)}(x) \nu(du,dw) $","I'm asked to write a centered distribution function $F(x) $ ( centered meaning that $\int x dF(x)=0 $ ) as $$F(x)=\iint \frac{w } {u+w }1_{[u,w) }(x)+1_{([w,\infty)}(x) \nu(du,dw) $$ where $\nu(du,dw)=\frac {1 }{\alpha } (w-u)1_{u \le 0 \le w }(u,v)dF(u)dF(w)$ I'm trying to motivate two things. 1) That the introduced measure $\nu $ really is a measure and 2) the equivalence of the distribution function $F $ with the repeted integral of the point mass distrubution function w.r.t. the introduced measure $\nu $ . For 1) Since $\frac{w } {u+w }1_{[u,w) }(x)+1_{([w,\infty)}(x) $ is the distribution function of the point mass $\frac{w } {u+w }\delta _u + \frac{u } {u+w }\delta_w$ the above then is some kind of average (integral) of point mass distributions. If we put $\nu(du,dw)=\frac {1 } {\alpha } (w-u)1_{u \le 0 \le w }(u,w)dF(u)dF(w)$ how do we motivate this is a measure? I believe $dF(u)dF(w)$ corresponds to the usual product measure of $P_X $ with itself, where $P_X $ is the probability measure corresponding to $F $ . What do we get when we multiply this with $1_{u \le 0 \le w }(u,w) $ ? Is it equivalent to concentrating $P_x \otimes P_X $ on the second quandrant by defining a new measure on $R^2 $ , $\mu(A) = P_X \otimes P_X(A \cap B )$ where $B=\{(x,y):x \le 0 \le y \} $ ? For 2) In my calculations I would like to claim that $$
\iint_{u \le 0 \le w } w1_{[u,\infty)}(x)-u1_{([w,\infty)}(x)dF(u)dF(w) 
\\= \iint_{u \le 0 \le w } w1_{(-\infty,x]}(u)-u1_{((-\infty,x]}(w)dF(u)dF(w)
$$ And I'm not sure how to motivate, even tough I can see that $x \in [u,\infty ) \iff u \in (-\infty ,x]$ . The rest of the verification I'm able to do so you don't have to supply it! Many thanks in advance!",['probability-theory']
3149357,General conditions for a measurable set,"Let $A \subset [0, 1]$ and suppose $A$ has finite, strictly positive Lebesgue measure. Is it possible that for all $x, y \in A$ it happens that $ x - y \in \mathbb{Q}$ ? My proposed solution: Since $A$ has strictly positive measure, $A$ cannot be countable, and so $A$ cannot consist solely of rational numbers. Since the difference of an irrational and a rational is irrational, the answer to the question is no in this case. Now if $A$ consists solely of irrationals, then I want to say that it is impossible for every difference to be rational. How do I prove this last statement?","['measure-theory', 'real-analysis']"
3149359,Criteria of a real vector bundle to be Stably trivial,"I am interested to know the general condition for a real vector bundle $V$ over an unorientable manifold $X$ ( $X$ can be either 4d or 5d) to be stably trivial. The case I've heard of is when $X$ is 4d unorientable, then $V$ is stably trivial iff $w_1(V)=w_2(V)=w_4(V)=0$ all vanish. Then what is the corresponding ""iff"" condition when $X$ is 5d unorientable? (I am also interested to know a reference where the proof for 4d $X$ is presented. ) Any comments, references are welcome.","['algebraic-topology', 'vector-bundles', 'general-topology', 'differential-topology', 'characteristic-classes']"
3149374,Characterization of torsion-free sheaves,"In ""The Geometry of Moduli Spaces of Sheaves"" by Huybrechts and Lehn a torsion-free sheaf is defined as coherent sheaf $E$ on an integral Noetherian scheme $X$ s.t. for every $x\in X$ and every non-zero germ $s\in O_{X,x}$ , multiplication by $s$ $E_x\to E_x$ is injective. It is then stated that this definition is equivalent to $T(E)=T_{d-1}(E)=0$ where $d=\dim X$ and $T_{d-1}(E)$ is the maximal subsheaf of $E$ of dimension $\leq d-1$ . I am trying to prove this equivalence. I first restricted to the case of $X=\text{Spec} A$ affine and so $E=\widetilde{M}$ for $M$ a finitely generated $A$ -module. In this case I think I was able to prove that $E$ is torsion-free if and only if $\forall m\in M$ we have $\text{Ann}(m)={0}$ , which is equivalent to $V(\text{Ann}(m))=X$ (since $A$ is an integral domain) and thus to $\text{Supp}({mM})=X$ , which amounts to say $\dim \widetilde{mM}=d$ (since $\text{Supp}({mM})$ is closed). Since every submodule of $M$ contains a cyclic submodule of the form $mM$ we should be done. Is this argument correct? And is it enough restricting to the affine case? Of course the definition of torsion-freeness is local but I am not sure about the vanishing of $T(E)$ .","['coherent-sheaves', 'affine-schemes', 'algebraic-geometry', 'sheaf-theory', 'schemes']"
3149406,Tangents of the Means of the Roots of $n$th Order Polynomials,"In Stewart's Calculus w. Early Transcendentals 8th Ed. Chapter $3$ Problems Plus Question 26 we establish that the tangent of the mean of any two roots of a third order polynomial passes through the third root. Does this hold for an nth order polynomial? If so how does one go about deriving the product given as $$\prod_{k=0}^n (x-a_k)$$ where $a_k$ is the $k$ th root of the $n$ th order polynomial. The means of the roots can be taken as $$\mu_{a_0,a_{n-1}}=\frac{a_0+a_1+a_2+\ldots+a_n-1}{a_n}=\frac{\sum_{k=0}^{n-1} a_k}{a_n}$$ any help would be appreciated.","['calculus', 'geometry', 'statistics']"
3149428,Does $(n+1)(n-2)x_{n+1}=n(n^2-n-1)x_n-(n-1)^3x_{n-1}$ with $x_2=x_3=1$ define a sequence that is integral at prime indices?,"My son gave me the following recurrence formula for $x_n$ ( $n\ge2$ ): $$(n+1)(n-2)x_{n+1}=n(n^2-n-1)x_n-(n-1)^3x_{n-1}\tag{1}$$ $$x_2=x_3=1$$ The task I got from him: The sequence has an interesting property, find it out. Make a conjecture and prove it. Obviously I had to start with a few values and calculating them by hand turned out to be difficult. So I used Mathematica and defined the sequence as follows: b[n_] := b[n] = n (n^2 - n - 1) a[n] - (n - 1)^3 a[n - 1];
a[n_] := a[n] = b[n - 1]/(n (n - 3));
a[2] = 1;
a[3] = 1; And I got the following results: $$ a_4=\frac{7}{4}, \ a_5=5, \ a_6=\frac{121}{6}, \ a_7=103, \ a_8=\frac{5041}{8}, \ a_9=\frac{40321}{9}, \\ a_{10}=\frac{362881}{10}, \ a_{11}=329891, \ a_{12}=\frac{39916801}{12}, \ a_{13}=36846277, \ a_{14}=\frac{6227020801}{14}\dots$$ Numbers don't make any sense but it's strange that the sequence produces integer values from time to time. It's not something that I expected from a pretty complex definition like (1). So I decided to find the values of $n$ producing integer values of $a_n$ . I did an experiment for $2\le n \le 100$ : table = Table[{i, a[i]}, {i, 2, 100}];
integers = Select[table, (IntegerQ[#[[2]]]) &];
itegerIndexes = Map[#[[1]] &, integers] ...and the output was: {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 
59, 61, 67, 71, 73, 79, 83, 89, 97} Conjecture (pretty amazing, at least to me): $a_n$ is an integer if and only if $n$ is prime. Interesting primality test, isn't it? The trick is to prove that it's correct. I have started with the substitution: $$y_n=n x_n$$ ...which simplifies (1) a bit: $$(n-2)y_{n+1}=(n^2-n-1)y_n-(n-1)^2y_{n-1}$$ ...but I did not get much further (the next step, I guess, should be rearrangement).","['elementary-number-theory', 'recurrence-relations', 'primality-test', 'sequences-and-series', 'prime-numbers']"
3149459,Finite rank operators on Hilbert spaces,"Let $H$ be a Hilbert space. Question 1: Are all rank one operators from $H$ to $H$ is of the form $$T:H\rightarrow H, x \mapsto \langle x,u\rangle v $$ For some $u,v \in H$ . Question 2: Suppose $I \subseteq L(H)$ is an ideal and contains all the rank one operators, how do we show it contains all the finite rank operators? These two statements seem to be true, but I could not  find any reference. After some thought: Let us fix orthonormal basis $\{u_i\}$ of $H$ . We have two observations: Operator $T^*$ exists. So $$ Tx = \sum \langle Tx , u_i \rangle u_i = \sum \langle x, T^*u_i \rangle u_i $$ $$x \mapsto \langle x,v \rangle w$$ are rank one if $v \not=0, w \not= 0$ . Combining the above two, $T$ is rank one if and only if it is of the form $x \mapsto \langle x,v \rangle w $ . Any finite rank operator, must again be of the form $\sum_j \langle x, v_j \rangle w_j$ (finite sum). These are generated by the rank one operators. I would be happy if anyone point some possible pitfalls / mistake I made in my proof.","['compact-operators', 'operator-algebras', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
