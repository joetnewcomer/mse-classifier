question_id,title,body,tags
1749035,"Let $a_{n}=(1-\frac{1}{\sqrt{2}})\ldots(1-\frac{1}{\sqrt{n+1}}), n \geq 1 $. Then $\lim_\limits{n \rightarrow \infty} a_{n} $ [duplicate]","This question already has answers here : How can I find $\lim_{n\to \infty} a_n$ [duplicate] (2 answers) Closed 5 years ago . Options are  (A) equals 1 (B) does not exist (C) equals $\frac{1}{\sqrt{\pi}}$ (D) 0.
I have multiplied each numerator with $\sqrt{n+1}+1$, $\forall n = 1$ to $\infty$ and then got $a_{n}=\frac{n!}{(2+\sqrt{2})(3+\sqrt{3})\ldots((n+1)+\sqrt{n+1})}$. So this must converge to 0 right since the fraction comes as $\frac{n!}{(n+1)!+\mathrm{something}}$ ?","['sequences-and-series', 'calculus', 'limits']"
1749042,"Without using prime factorization, find a prime factor of $\frac{(3^{41} -1)}{2}$",Not sure how to go about this. Law of quadratic reciprocity and Euler's Criterion is recently learned material but I'm not sure how this applies.,"['number-theory', 'quadratic-residues', 'elementary-number-theory']"
1749043,"Given a planar graph with minimum cycle length 8, show that $|E| \le \frac{4}{3}|V| - \frac{8}{3}$","Here's what I've got so far. I'm stuck on how to proceed. I believe I need to plug back into Euler's formula, but I'm not getting what I'm looking for by doing that. Where is the denominator of $3$ coming from in the result? Can you please check over my proof for any incorrect statements, and help me move forward? Proof . Let $G$ be a connected planar graph with at least two edges, and a cycle with length $\ge 8$. Pick a crossing-free embedding of $G$; this embedding has $f$ faces. By Euler's formula, $$f = 2 - |V| + |E|\;.$$
  We calculate the sum of the degrees of the faces in this embedding. On the one hand, the sum of the face degrees is $2|E|$ by proposition. On the other hand, since there is a cycle of at least length $8$, the sum of the face degrees is at least $8f$. That's where I'm stuck at. Any ideas?","['graph-theory', 'planar-graphs', 'discrete-mathematics']"
1749045,"You cast a pair of dice. If you get a 6 and an 8 before 7 comes up twice, you win. What is the probability of winning?","You cast a pair of dice. If you get a 6 and an 8 before 7 comes up twice, you win. What is the probability of winning? What I tried was 
\begin{align*}
 P(X=6) & = \frac{5}{36}\\
 P(X=8) & = \frac{5}{36}\\
 P(X=7) & = \frac{6}{36} = \frac{1}{6}
\end{align*} I try finding the probability of getting $6$ and $8$ and not $7$ $$P(X=6)+P(X=8)+P(X \neq 7) = \frac{5}{26} + \frac{5}{36} + \frac{5}{6} = 1.11$$ I stick since I know that the probability cannot be greater than one. The solution key says the answer is $0.5456$.","['probability', 'dice']"
1749064,Double integral were y is negative and positive,I'm trying to evaluate: $\int\int xydA$ Where D is the region bounded by the line $y=x-2$ and $x=y^2$ Does the integral need to be set up as: $$\int_{-1}^{2} \int_{y+2}^{y^2} xydxdy$$ or do I need to evaluate the double integral of the area above the y-axis and below separately and add them together like this? $$\int_{-1}^{0} \int_{x-2}^{\sqrt x} xydydx + \int_{0}^{2} \int_{x-2}^{\sqrt x} xydydx$$ Or am I completely wrong and it's something totally different?,['multivariable-calculus']
1749066,What is the second derivative of $Tr(A^T(\alpha)BA(\alpha))$?,"What is the second derivative $\frac{d^2}{d\alpha}Tr(A^T(\alpha)BA(\alpha))$? Here, $B$ is square matrix and $A(\alpha)$ is a parameter dependent matrix that is rectangular. All entries of $B, A$ are always real.","['derivatives', 'matrix-calculus', 'calculus', 'linear-algebra', 'implicit-differentiation']"
1749128,How to compute taylor series $f(x)=\frac{1}{1-x}$ about $a=3$?,"How to compute taylor series $f(x)=\frac{1}{1-x}$ about $a=3$? It should be associated with the geometric series. Setting $t=x-3,\ x=t+3$, then I don't know how to continue, could someone clarify the procedure?","['taylor-expansion', 'summation', 'calculus', 'functions']"
1749130,Notation to define an element with maximum occurrence in a set,"I have a set of sets of natural numbers which is as follows: $A=\{ \{1,1\},\{1,2\},\{3,1\}\}$ . I want to express the natural number with maximum occurrence. For example, 1 has the highest occurrence in $A$ because 1 appeared 4 times whereas 2 and 3 appeared only one time. How to express this with set theory notations?","['notation', 'elementary-set-theory']"
1749182,Proving $n - \frac{_{2}^{n}\textrm{C}}{2} + \frac{_{3}^{n}\textrm{C}}{3} - ...= 1 + \frac{1}{2} +...+ \frac{1}{n}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Prove that $n - \frac{_{2}^{n}\textrm{C}}{2} + \frac{_{3}^{n}\textrm{C}}{3} - ... (-1)^{n+1}\frac{_{n}^{n}\textrm{C}}{n} = 1 + \frac{1}{2} + \frac{1}{3} +...+ \frac{1}{n}$ I am not able to prove this. Please help!","['combinations', 'sequences-and-series', 'closed-form']"
1749203,Number of paths of length three in $K_4$,"How many paths of length $3$ can be made from $K_4$ where $4$ represents the number of vertices? I believe the answer is $12$ just by counting the number of different combinations of paths with length $2$. I don't know how to relate this to combinations though. I was thinking $4 \choose 3$ determines the number of ways $4$ vertices can be chosen for a path of length $3$ to be out together, but I think I'm missing something conceptually.","['combinatorics', 'graph-theory', 'discrete-mathematics']"
1749205,covariance of random variables,"Suppose X, Y, W are independent random variables such that X ∼ GAM(2,3), Y ∼ N(1,4) and W ∼ BIN(10,1/4). Let U = 2X − 3Y and V = Y − W . Find cov(U, V ). I know that cov(U, V) = E(U, V) - E(U)E(V). I've found E(U) and E(V) but I don't know how to find E(U, V).","['statistics', 'probability', 'covariance']"
1749211,Up-to-date Matrix Cookbook,"My copy of the Matrix cookbook is dated November 15, 2012, and is the newest copy I've been able to find. Identities may not change overtime, but the approach to an error-free presentation can be asymptotic, and some topics may be missing. Where can I find an up-to-date copy? The address ""matrixcookbook.com"" listed in the 2012 book is defunct, the email in the book doesn't work, and the 2302.dk website seems to be out of commission, and I haven't found personal sites for the authors.","['matrices', 'reference-request', 'reference-works', 'online-resources']"
1749231,Trying to prove that $\lim_{N \rightarrow \infty} \frac{1}{N} \Sigma_{n=1}^N f(n\alpha) = \int_0^1 f(x) dx$ [duplicate],"This question already has answers here : Prove that $\lim_{N\rightarrow\infty}(1/N)\sum_{n=1}^N f(nx)=\int_{0}^1f(t)dt$ (2 answers) Closed 7 years ago . Let $\alpha$ be an irrational number. Let $f: \mathbb{R} \rightarrow \mathbb{C}$ be a continuous periodic function with period 1. Show that $\lim_{N \rightarrow \infty} \frac{1}{N} \Sigma_{n=1}^N f(n\alpha) = \int_0^1 f(x)\,dx$ The beginning (but probably not the end) of my confusion with this problem has to do with the irrational inputs. Why would that be necessary? Any help is appreciated!","['equidistribution', 'real-analysis', 'analysis']"
1749250,SmoothStep: Looking for a continuous family of interpolation functions,"Background: SmoothStep is a simple sigmoid-like function defined as S(x) = 3x^2 - 2x^3.  It is monotonically increasing from (0, 0) to (1, 1), is rotationally symmetric over that interval, and has flat tangents at both endpoints.  This function is useful for generating an interpolation parameter when you would like to ease in and out between an initial and final value. S(S(x)) will yield a function that has a longer ease-in/ease-out with a sharper transition in the middle, and S(S(S(x))) makes the middle steeper still.  The more times the function is nested, the more protracted the ease is and the steeper the tangent at the midpoint becomes. Question: I would like to be able to drive this curve from shallow to steep continuously using some kind of 'steepness' parameter, but repeated iteration only allows discrete curves to be evaluated.  Additionally, the cost of evaluating the function grows with the number of nested iterations.  Is there any similar function which could be tuned continuously in this manner?","['functions', 'interpolation']"
1749267,Brownian Motion hitting time is finite yet has infinite expectation?,"I've read that a hitting time of a Brownian motion (defined as $T_a = \inf\{t\ge0:W_t=a\}$ where $W_t$ is a standard Brownian Motion, i.e. a Wiener process), has the following two properties, which I am trying to understand: $$ \mathbb{P}(T_a \lt \infty ) = 1 $$ $$ \mathbb{E}[T_a]=\infty $$ These are from pg 6 of http://www.pstat.ucsb.edu/faculty/ludkovski/bmNotes.pdf , for example. My question is what these mean and how they are not in conflict.  I interpret the first one to say that with probability one the hitting time for any $a$ is finite.  I interpret the second one to say that the expectation of the stopping time for any $a$ is infinite.  This seems in conflict to me (i.e. saying that something is finite with probability one yet has infinite expectation?).  Please help me gain some intuition here, and correct me if I am misunderstanding one or both of these properties.","['stochastic-processes', 'probability-theory', 'brownian-motion', 'stopping-times']"
1749279,Why are the Trig functions defined by the counterclockwise path of a circle?,"My understanding is that $\cos$ is defined by the value of $x$ as you trace the graph of a circle counterclockwise, starting at the point $(1, 0)$. Similarly, $\sin$ traces the $y$ value. I understand HOW the trigonometric functions work. The issue that has been gnawing at me for years is WHY they are defined that way. There's probably a totally reasonable explanation, I know the history of Trig goes back thousands of years, but I don't understand the reasoning behind defining the Trig functions with the most arbitrary, least intuitive possible rules. If I had been the person to invent $\cos$ and $\sin$, I would have defined them by starting at the topmost point of a circle, and trace it clockwise. Is that not the most intuitive method? Maybe it's just a modern preference, but it seems to me that we humans like to read things left-to-right, and yet the trig functions are defined starting from a circle's right-most point. Furthermore, $\cos$ and $\sin$ start at $x = 1$ on a circle's graph. Why not start at $x = 0$? I think this is why so many people have no intuitive understanding of $\sin$ and $\cos$, and why many students get through high school and college by simple rote memorization of what a handful of $x$ values evaluate to in $\sin$ or $\cos$.","['math-history', 'trigonometry']"
1749296,Rings that cannot be representations rings,"Given a monoidal category $\mathcal{C}$ one can define the Green ring (or representation ring) $r(\mathcal{C})$ as the abelian group generated by the isomorphism classes $[V]$ of $\mathcal{C}$ modulo the relations $[M\oplus V]=[M]+ [V]$, and the multiplication is given by the tensor product. Not all rings can be realized as the representation ring of some monoidal category $\mathcal{C}$. However I cannot seem to find some nice examples of this fact in literature. I'd very much like to see an example and the reasoning why this is true. Any references are very welcome. Thank you.","['abstract-algebra', 'reference-request', 'monoidal-categories', 'representation-theory', 'category-theory']"
1749306,Evaluate: $\csc^2\left(\frac{\pi}{9}\right)+\csc^2\left(\frac{2\pi}{9}\right)+\csc^2\left(\frac{4\pi}{9}\right)$,"$$\csc^2\left(\frac{\pi}{9}\right)+\csc^2\left(\frac{2\pi}{9}\right)+\csc^2\left(\frac{4\pi}{9}\right) \;=\; \text{???}$$ $\bf{My\; Try::}$ Let $\displaystyle \frac{\pi}{9} = \theta\;,$ Then $9\theta = \pi\Rightarrow 6\theta = \pi-3\theta$ So $\sin (6\theta) = -\sin (3\theta)\Rightarrow 2\sin 3 \theta \cdot \cos 3 \theta+\sin 3 \theta =0$ So we get $\displaystyle \sin 3 \theta \cdot \left[2\cos 3 \theta +1\right] =0$ So we get $\sin 3\theta = 0$ or $2\cos 3 \theta+1=0$ Now i did not understand how can I convert into $\sin^2$ form, Help me Thanks",['trigonometry']
1749333,Finding the envelope of the family $(x-c)^2+y^2=1+c^2$,"I have this family of circles: $(x-c)^2+y^2=1+c^2$. I'm to find the envelope of this family. Going by what I know, I write $$F(x,y,c)=(x-c)^2+y^2-1-c^2=x^2-2xc+y^2-1=0.$$
Then, $$\frac{\delta F(x,y,c)}{\delta c}=-2x=0.$$ Ideally, I should get a function in $c$ in the second step, and then substitute that value in the original equation to get the envelope. But here, the $c$ cancels. What should I do now?","['differential-geometry', 'geometry']"
1749340,Calculate $\sin\frac{3\pi}{14}-\sin\frac{\pi}{14}-\sin\frac{5\pi}{14}$,"I have interesting trigonometric expression for professionals in mathematical science. So, here it is:
$$\sin\dfrac{3\pi}{14}-\sin\dfrac{\pi}{14}-\sin\dfrac{5\pi}{14};$$
Okay! I attempt calculate it:
\begin{gather}
\sin\dfrac{3\pi}{14}-\left(\sin\dfrac{\pi}{14}+\sin\dfrac{5\pi}{14}\right)=\\
=\sin\dfrac{3\pi}{14}-\left(2\sin\dfrac{3\pi}{14}\cdot\cos\dfrac{\pi}{7}\right)=\\
=\sin\dfrac{3\pi}{14}\left[1-2\cdot\cos\dfrac{\pi}{7}\right]=...
\end{gather}
Tried everything... Here deadlock. I really do not know what to do next. Help somebody, please.",['trigonometry']
1749370,joint distribution of x with..itself,"I have a weird question about probability and density functions : 
Let's take a random variable X whose p.d.f exists and let's denote it $f_{X}\left(x\right)$.
Does the definition of the joint probability $f_{X,X}\left(x,x\right)$ exist ?
clearly it's not continuous but i wanted to ""check"" that the marginal of X ($f_{X}\left(x\right)$) would be the integral of this joint distribution... Can you give me more insight about it? thanks, Romain","['probability', 'functions']"
1749410,Question on ideal triangle and hyperbolic distance,"I'm asking a question about a construction due to Thurston. Let's consider a hyperbolic triangle (I'm considering the Poincarè disc model of the hyperbolic plane) and from each one of the three vertices let's foliate the triangle with horocycles untill we reach the central zone bounded by three horocycles. I made a (bad) picture: the geodesics are in red and the horocycles in blu. Now let's choose one spike on the triangle and the horocycle at hyperbolic distance $t$ from the central, unfoliated zone. My question is: How do I compute the hyperbolic length of this horocycle? Does it vary linearly with $t$? I made another picture: I'm new to hyperbolic geometry so I apoligise if my question is trivial. And I'm sorry if I'm not explaining my attempt to solve the problem, but this seems rather complicated to me, so I really need some help understanding where to start to solve it. Thank you!","['hyperbolic-geometry', 'differential-geometry']"
1749434,Motivating the Cross-Ratio and 'the ratio of ratio's' in $\mathbb{R}\mathbb{P}^2$,"Trying to come across the idea of the cross ratio naturally by thinking about the projective plane $\mathbb{R} \mathbb{P}^2$, using ideas from Brannan's Geometry book: given 4 collinear points $A,B,C,D$ we note ( for the vectors respresenting these points ) that
$$C = aA + bB$$ 
$$D = cA + dB$$ so that the cross ratio is defined as $(b/a)/(d/c)$. Why is this obvious, and why is it obvious it should be a projective invariant without big calculations? My guess is that you take $$C = aA + bB = a[A + (b/a)B] \sim A + (b/a)B$$ 
and 
$$D \sim A + (d/c)B$$ so that, for some reason, we want to define the discrepancy between these terms, i.e. we want to find the $\lambda$ that would turn $(b/a)$ into $(d/c)$: $$(b/a) = \lambda (d/c)$$ so that $$\lambda = (b/a)/(d/c)$$ tells us that, given two generators of a line ($A$ and $B$) we have a third point specified by the ratio $b/a$ and a fourth point specified by the ratio $d/c$ but because we just consider the factor that turns, for our given starting generators, a third point into a fourth point we expect it to be preserved when we project between lines: This is the best I can do to make the statement that the ratio of ratio's (Stillwell's 4 Pillar's book) is preserved under projections, because it seems to be saying you use this term to turn a third point into a fourth point given two staring points. Still not 100% clear on why it should also make sense when you start taking projections from points in perspective :\ Any thoughts? Any pictures to make it nicer? Any ideas on making the ratio of ratio's , along with the cross-ratio, more obvious? There are some great answers on here, such as https://math.stackexchange.com/a/1023055/82615 or https://math.stackexchange.com/a/627396/82615 but I have not come away with a child-like grasp of this yet, lets hope it can be achieved!","['complex-analysis', 'conformal-geometry', 'projective-geometry']"
1749458,Solving $x^2+\frac{81x^2}{(9+x)^2}=40$ [duplicate],This question already has answers here : How one should solve $x^2+\frac{81x^2}{(x+9)^2}=40$ [closed] (6 answers) Closed 2 years ago . Solve the following equation: $$x^2+\dfrac{81x^2}{(9+x)^2}=40$$ Unfortunately I have no ideas because after expanding I get an equation of 4 degree.,['algebra-precalculus']
1749491,"How can I prove the concavity of $f(p_1,p_2,\ldots,p_n) = \sum_{i = 1}^n p_i(1-p_i)$?","Assume $p_n$ is the probability of being in class $n$ 
which mean that $f(0) = 0$ , $f(1) =0$ , and  $p_1+p_2 = 1$ I need to come up with a concave function that show the relation between $p_1$ and $p_2$ The function $f(p) = p(1-p)$ is a concave function. It's easily to proof its concave by $f''(x) <0 $ But after I generalized with $p_n$,
how can I prove the concavity of $$f(p_1,p_2,\ldots,p_n) = \sum_{i = 1}^n p_i(1-p_i)$$ What is the best way to prove a function (with several variables) is a concave function?","['summation', 'convex-analysis', 'calculus', 'functions']"
1749506,Uniform convergence of sequence,"Let $$f_{n}(t) = \frac{n^2t^2}{(1+t^2)^{n}}$$ I have to count limits $$ \lim_{n \to +\infty}(\lim_{t \to 0} f_{n}(t))$$ $$ \lim_{t \to 0}(\lim_{n \to +\infty} f_{n}(t))$$ $$\lim_{n \to +\infty}f_{n}(\frac{1}{n})$$ My results: 1st and 2nd are equal to 0, 3rd is equal to 1.
My question, is this sequence uniformly convergnent for all real values of t?
I think it won't be because of this $\frac{1}{n}$ points, but how to write it formally?","['analysis', 'functions']"
1749509,Convert a piecewise linear non-convex function into a linear optimisation problem.,"Update: Problem and solution found here (p. 17, 61), although my prof's solution (formulation) is different. Convert $$\min z = f(x)$$ where $$f(x) = \left\{\begin{matrix}
1-x, & 0 \le x < 1\\ 
x-1, & 1 \le x < 2\\ 
\frac{x}{2}, &  2 \le x \le 3
\end{matrix}\right.$$ s.t. $$x \ge 0$$ into a linear integer programming problem. What I tried: It seems that according to this , $$\min \ f(x) = \max(a_1x + b_1, a_2x + b_2, ..., a_mx + b_m), x \ge 0$$ is equivalent to $$\min \ t \ \text{s.t.}$$ $$a_1x + b_1 \le t$$ $$a_2x + b_2 \le t$$ $$\vdots$$ $$a_mx + b_m \le t$$ $$x \ge 0$$ Following that, I tried $$g(x) = \max(1-x, x-1, x/2) = \left\{\begin{matrix}
1-x, & 0 \le x \le 2/3\\ 
x-1, & x \ge 2\\ 
\frac{x}{2}, &  2/3 \le x \le 2
\end{matrix}\right.$$ If we allow only integer $x$, then we have $$g(x) = \max(1-x, x-1, x/2) = \left\{\begin{matrix}
1-x, & x=0\\ 
x-1, & x=2\\ 
\frac{x}{2}, &  x=1 or 2
\end{matrix}\right.$$ If we allow only integer $x$ for $f$, then we have $$f(x) = \left\{\begin{matrix}
1-x, & x=0\\ 
x-1, & x=1\\ 
\frac{x}{2}, &  x=2 or 3
\end{matrix}\right.$$ It doesn't look like $f(x) = g(x)$, w/ or w/o integer constraint. How can I approach this? (The following is copied from an answer I deleted and comments on it) Prof's answer (assuming I remembered question right): Let Xi = X for ith constraint. Minimise $$z = (1-x_1)+(x_2-1)+(1/2)(x_3)$$ s.t. $$0 \le x_1 \le y_1$$
$$y_2 \le x_2 \le 2y_2$$
$$2y_3 \le x_3 \le 3y_3$$
$$y_1, y_2, y_3 \in \{0,1\}$$
$$x_1,x_2,x_3 \ge 0$$ Comments below it: (You should probably annotate this to indicate the source.) Anyway, if you suspected something was off about this solution, then you're right: it's incorrect. This formulation is similar to Kuifje's Option 3, but it incorrectly encodes the objective function. The minimum value occurs at $(y_1,y_2,y_3)=(1,0,0)$, presumably as expected, but here $(x_1,x_2,x_3)=(1,0,0)$ giving $z=−1$. The value $−1$ is never taken by the original function! The $(x_2−1)$ term should have been chosen to minimize at $0$ in the case that $y_2=0$, but it wasn't. – Erick Wong 1 hour ago @ErickWong I was lacking one thing: 'let xi=X for the ith constraint.' what about now? Thanks for the feedback XD honestly I haven't yet bothered to analyse any of these. We didn't discuss boolean logic. I'm about to ask my prof about this. I could have remembered the question wrong. I do remember that function and something about an integer linear programming problem – BCLC 11 mins ago That extra line shouldn't make a difference: it just declares the Intent of the variable $x_i$ (as an aid to the reader) but it doesn't change its value. Good luck, I do believe if the function is exactly as you remember then this answer is flawed. I haven't carefully analyzed Kuifje's answers and there may be minor typos there too :) – Erick Wong 5 mins ago @ErickWong Edit: Thanks for the feedback XD honestly I haven't yet bothered to analyse any of these. I mean I guess I could understand if I analysed, but the point is that I don't think average student in my class can come up with this without boolean logic because we didn't discuss boolean logic. I'm about to ask my prof about this. I could have remembered the question wrong. I do remember that function and something about an integer linear programming problem. – BCLC 2 mins ago   edit @ErickWong THANK YOU XD – BCLC 2 mins ago   edit","['optimization', 'linear-programming', 'operations-research', 'integers', 'linear-algebra']"
1749558,Solve this problem on functions,"Let $f$ be a bijection from the set of non-negative integers to itself. Show that there exist integers $a$,$b$,$c$ such that $a < b < c$ and $f(a)+f(c)=2f(b)$. I don't know how to approach this problem. I think I'll have to show some kind of contradiction. But, I haven't managed to do anything fruitful yet. Any help would be appreciated.","['arithmetic-progressions', 'functions', 'elementary-number-theory']"
1749560,Show that $f(z)=\sum_{n=0}^{\infty}z^{2^n}$ can't be analytically continued past the unit disk.,"I'm reading the problems of Stein and Shakarchi's Complex Analysis, Chapter 2 Problem 1 asks to show that $$f(z)=\sum_{n=0}^{\infty}z^{2^n}$$ cannot be analytically continued past the unit disk. (Hint: Suppose $\theta =\frac{2\pi p}{2^k}$ for $p,k$ positive integers, let $z=re^{i\theta}$ and show $\mid f(z)\mid\rightarrow\infty$ as $r \rightarrow1$ ). I understand from the hint they want me to ""pepper"" the unit circle with points where the power expansion explodes so that it is dense with poles. I do not understand why they choose such particular points, but I assume that in retrospect it will show that those are the ones that I can show divergence for the easiest and are dense in the unit circle, so plowing ahead: $$\lim_{r \rightarrow 1}\left| \sum_{n=0}^\infty r^{2^n}e^{ i2\pi p 2^{n-k}}\right| = \left| \sum_{n=0}^k e^{ \frac{i2\pi p}{2^{k-n}}} + \sum_{n=k+1}^\infty e^{ i2\pi p2^{n-k}} \right|  $$ Where do I go from here? Is there some oversimplification of these sinusoids that I'm not seeing? Furthermore, once I manage to show this explodes, if I show that these numbers are dense on the unit circle I'm done, right? Any insight is much appreciated.","['complex-analysis', 'analytic-functions', 'analytic-continuation', 'divergent-series', 'sequences-and-series']"
1749585,"Perfect Pairing, non-degeneracy and dimension.","On this wikipedia entry https://en.wikipedia.org/wiki/Bilinear_form#Different_spaces it tells us that if $B: V \times W \to K$ is a bilinear map, then In finite dimensions, [a perfect pairing] is equivalent to the pairing being
  nondegenerate (the spaces necessarily having the same dimensions). My question is why does non-degeneracy imply that the induced linear map from $V$ to $W^*$ is an isomoprhism? And, why do $V$ and $W$ necessarily have the same dimension?","['bilinear-form', 'linear-algebra', 'duality-theorems']"
1749635,Does a factorable joint CDF/PDF always imply independence?,"Say we have two random variables, x and y , with $F_{xy}(x,y)$ and $f_{xy}(x,y)$ denoting their joint CDF and PDF respectively. If they can be written such that $$F_{xy}(x,y)=G(x)H(y)$$
$$f_{xy}(x,y)=g(x)h(y)$$ is that enough to guarantee x and y are independent? My intuition suggests that it should be possible to construct a counterexample (either where none of the possible $g$/$G$ and $h$/$H$ functions are the marginal statistics or where $F$ might be factorable while $f$ is not), but so far I've had no luck. I've also had a hard time proving that it is always the case if it is in fact true.",['statistics']
1749687,Can I compare real and complex eigenvalues?,"I'm calculating the eigenvalues of the matrix    $\begin{pmatrix} 2 &0 &0& 1\\
     0 &1& 0& 1\\
     0 &0& 3& 1\\
    -1 &0 &0 &1\end{pmatrix}$, which are $1$,$3$, $\frac{3}{2}+\sqrt{3}i$ and $\frac{3}{2}-\sqrt{3}i$. I wish to recognize the biggest and smallest of these. But how can I compare real and complex numbers?","['matrices', 'eigenvalues-eigenvectors', 'complex-numbers']"
1749730,"How many faces of a solid can one ""see""?","What is the maximum number of faces of totally convex solid that one can ""see"" from a point? ...and, more importantly, how can I ask this question better? (I'm a college student with little experience in asking well formed questions, much less answering them.) By ""see"" I mean something like this: you point a camera from a point at the solid, and look at the picture. How many of the faces of the solid look like faces and not just lines? Let's assume that the lens is just a point in space (no lenses wider than the solid itself) and that the camera is a finite distance from the solid. I know this is a crude definition... if you have any ideas for a more rigorous definition, this would be awesome, then maybe there's ways to prove the answer to my question mathematically. For example, in the picture of this cube , you can see 3 faces. This is the maximum you can see for a cube. How can that be proved? What methods might you use to prove this for a convex solid of any size and shape? Are there ways to do so using only relatively basic math (Multivariable calc, linear algebra, high school geometry)?","['platonic-solids', 'proof-writing', 'geometry']"
1749769,"Reference request for Grothendieck's work on ""Integration with values in a topological group""","Recently I was reading the available part of the second part of W. Scharlau's book on Alexandre Grothendieck (see here ). There I found, An anecdote survives about Grothendieck's arrival in Nancy: the story of his rude reception at the hands of Dieudonné when, on their very first contact, he showed him a dense handwritten manuscript on ""generalized integrals"". He had already mentioned this work in writing to Dieudonné, and had received a warm and friendly response in which Dieudonné praised his ""ardor for mathematics"". But Dieudonné's initial receptiveness did not outlast a first look at the actual text. Those who recall this incident (or rather, who recall Dieudonné's telling them about it) claim that Dieudonné gave Grothendieck a
  rather sharp dressing down, finding that the work displayed a reprehensible tendency to gratuitous generality. Later it is also mentioned that (as Schwartz recounts in his autobiography), He first gave Dieudonné an article of fifty or so pages, on ""Integration with values in a topological group"". It was correct, but absolutely uninteresting. Dieudonné, with the (always temporary) aggressiveness he was capable of, gave him a memorable scolding, claiming that one shouldn't work that way, generalizing just for the pleasure of generalizing. The problem one considered had to be difficult, and applicable to the rest of mathematics
  (or other sciences); his results would never be useful to anyone for anything. Questions. Does anyone know how Grothendieck treated the problem of integration with values in a topological group which he submitted to Dieudonné (I can't seem to find anything on internet)? Why was Grothendieck's work on ""Integration with values in a topological group"" has been referred to as ""would never be useful to anyone for anything"" by Dieudonné? Has there been any future research on this topic? Where can I find (if possible at all) Grothendieck's original paper in the internet?","['math-history', 'reference-request', 'integration', 'soft-question', 'topological-vector-spaces']"
1749770,Median of a multinomial variable,"Let $k\in\mathbb N^+$ be a positive integer. Consider a set of i.i.d. random variables $X_1,X_2,\ldots, X_n$, each of which is distributed uniformly over $\{1,2,\ldots,2k+1\}$. For $i\in \{1,2,\ldots,2k+1\}$, let $Y_i\triangleq|\{j\mid X_j=i\}|$ denote the number of variables with the value $i$. Notice that each $Y_i$ is distributed $Bin\left(n,\frac{1}{2k+1}\right)$. Finally, let $Z\triangleq \text{Median}(\{Y_1,Y_2,\ldots,Y_{2k+1}\})$ be the median of the $Y_i$ variables. Does $\mathbb E(Z) = \frac{n}{2k+1}$? How could we prove it? and more importantly: What is the variance of $Z$? is it $o(np(1-p))$, where $p\triangleq\frac{1}{2k+1}$ is the probability that a single $X_j$ takes a specific value $i$? i.e., is the variance of the median asymptotically smaller than $Var(Y_i)=np(1-p)$? by how much? The special case of $k=1$, where we have only 3 $Y_i$ variables is also interesting for me.","['median', 'probability-theory', 'binomial-distribution', 'probability', 'random-variables']"
1749776,Chern class of ideal sheaf,"Let $X$ be a smooth projective surface . Let $Z$ be a dimensional $0$ subscheme of length $l$. Suppose $I_Z$ is the ideal sheaf of $Z$. Then it claimed that $c_1(I_Z) = 0$ and $c_2(I_Z) = l$. (1)Why this is true? (Here the Chern class is about a sheaf rather than vector bundles. Hence, we use a resolution of $I_Z$ by vector bundles to define its Chern classes. I want to use $0 \to I_Z \to \mathcal{O}_X \to i_*\mathcal{O}_Z \to 0$ to compute Chern classes. This means that at least I have to show that $c_2(i_*\mathcal{O}_Z) = -l$, this seems very wired to me because $i_*\mathcal{O}_Z$ supported in dimensional $0$.) (2) Besides, I want to know how to define the length of zero dimensional scheme (may be reduced)? Edit I found that the post https://mathoverflow.net/questions/106148/chern-classes-of-ideal-sheaf-of-an-analytic-subset related to this problem, but I am still looking for an elementary proof (just use HRR theorem).","['complex-geometry', 'algebraic-geometry', 'commutative-algebra']"
1749784,Zeroes of exact differential forms on compact manifold,Let $M$ be a $n$ dimensional compact differentiable manifold. I would like to show that any exact differential form of degree $n$ vanishes at at least one point. I think it is a generalization of the following fact : if $f$ is a diffferentiable function on $M$ then it either has a maximum or is constant so it's differential vanishes at at least one point. edit I'm looking for a direct answer if possible maybe in the spirit of the above remark.,"['differential-forms', 'differential-geometry']"
1749787,What is an intuitive explanation of the combinations formula? [duplicate],"This question already has answers here : How to understand the combination formula? (3 answers) Closed 6 years ago . I perfectly understand the permutations formula i.e. if you have $n$ things how many ways can you rearrange it if taken $k$ at a time (or if you have $k$ slots)? So you draw the following tree. And the formula comes out naturally. $$^nP_k = \frac{n!}{(n-k)!}$$ I get that it is including all of the duplicates, too. And to get rid of them we use the combinations formula: $$^nC_k = \frac{n!}{k!(n-k)!}$$ Can somebody explain why we have to divide by the ""number of ways to re-arrange the slots"" to get rid of the duplicates? I understand that it works and the division is used to scale a number down but I am not getting that ""aha moment"" of why we do it. Can somebody explain it?","['permutations', 'combinatorics', 'combinations']"
1749812,"If $x+y+z=3k$, where $x, y, z, k$ are integers, prove that $x!y!z! \geq (k!)^3$","If $x+y+z=3k$, where $x, y, z, k$ are integers, prove that 
$x!y!z! \geq (k!)^3$
Well I was able to prove this intuitively, but what i need is a rigorous mathematical proof. I shall explain my intuitive proof.
Let us take $L=x!y!z!$ at at $x=y=z=k$. Thus, $L=(k!)^3$. Now, to attain any other case, you would have to multiply by a number greater than $k$ and divide by a number less that $k$. Which in short means we would have to multiply by a number greater than $1$. This would imply that it's  magnitude would become greater than $L$. Thus using this algorithm, all cases can be obtained and they would all be greater than or equal to $L$. Thus, $L$ is the lowest possible value. 
Well, this is easy to explain. The problem would be to write it down as a proper mathematical proof. Please help me achieve that...","['combinatorics', 'inequality', 'factorial']"
1749822,"Prove partial derivatives exist, but not all directional derivatives exists.","During my analysis course my teacher explained the difference between partial derivatives and directional derivatives using the notion that a partial derivatives looks at the function as approaching a point along the axes (in case of of the plane), and a directional derivative as approaching a point from any direction in the plane. He also explained that the existence of directional derivatives is a stronger notion than the existence of partial derivatives exists: if all directional derivatives exist, then the partial derivatives exist too. I am to show (not necessarily prove) a case where the partial derivatives exist, but not all directional derivatives exist (hence, f is not differentiable).","['derivatives', 'partial-derivative', 'analysis']"
1749831,How do I solve $\lim_{x\to 0}\frac{\sin2x-2x(1+x)^{1/3}}{1-\cos x}$?,"I'm trying to get my head around this equation, $$\lim_{x\to 0}\frac{\sin2x-2x(1+x)^{1/3}}{1-\cos x}$$ but nothing I do seems to make it any more clearer. Do any one know how to do it?",['limits']
1749853,"If there are $74$ heads and $196$ legs, how many horses and humans are there? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . The community reviewed whether to reopen this question 4 months ago and left it closed: Original close reason(s) were not resolved Improve this question I was going through some problems then I arrived at this question which I couldn't solve. Does anyone know the answer to this question? One day, a person went to a horse racing area. Instead of counting the number of humans and horses, he counted $74$ heads and $196$ legs. How many humans and horses were there?","['algebra-precalculus', 'problem-solving', 'word-problem']"
1749863,Graph to model the order of different tasks in construction,"I have this question: During the construction of a house there are certain tasks that have
  to be completed before another one can commence, e.g., the roof has to
  be installed before work on electrical wiring or plumbing can begin.
  How can a graph be used to model the different tasks during the
  construction? Should the edges be directed or undirected? By analyzing
  the graph model, how can we find tasks that can be done at any time?
  Knowing the amount of time that each task takes, what do we need to
  compute to find the minimum time necessary to build the whole house
  (assuming enough resources are always available)? Right off the bat, I know the the graph that depicts the ordered tasks should have directed edges, because the order is important. If we are trying to find the processes that can be done in any order, then we could use undirected edges. From there, though, I'm lost. It's talking about analyzing the graph model, but how am I supposed to know how many points to plot, or how to connect them? Any advice here? Thanks!","['graph-theory', 'discrete-mathematics']"
1749864,Can the real vector space of all real sequences be normed so that it is complete ?,Let $X$ be the vector space of all real sequences . Does there exist a norm on $X$ which makes it complete ?,"['banach-spaces', 'normed-spaces', 'complete-spaces', 'functional-analysis', 'metric-spaces']"
1749910,Does there exist a continuous function whose composition with itself is the exponential map?,"All of the maps $$
F(x) = x^4 \\
G(x) = \exp (\exp x) \\
H(x) = \sin (\sin x)
$$ can be expressed as the self-compositions of the functions $$
f(x) = x^2 \\
g(x) = \exp x \\
h(x) = \sin x
$$ So this led me naturally to the question whether other functions can be expressed as the self composition of another function. So this led me naturally to the question: Does there exist a continous function $f : \mathbb{R} \rightarrow \mathbb{R}$ such that, for all $x \in \mathbb{R}$, $f(f(x)) = \exp (x)$?",['analysis']
1749982,An operation on a whole is equal to an operation on each part?,"I've been pondering this question as to how and when you can perform an operation on a complete ""unit"" and the answer is the same when performing the operation on the individual parts of the ""unit"" For example: $$
\sqrt{25\div4} = \sqrt{25}\div\sqrt{4}.
$$
We took the square root operation and applied it to $25$ and $4$ separately to get the same result. However this is not the case for: $$
(4+1)^2 \neq 4^2 + 1^2
$$ However this is true again for: $$
\frac{2(7-6)}{2^2} = \frac{2(7)}{2^2} - \frac{2(6)}{2^2}.
$$ We took multiplication by $2$ and division by $2^2$ and applied them to $7$ and $6$ individually. My question is: Can you always distribute operations to the parts of a unit and get the same result as when you would perform the operation on the whole unit.",['algebra-precalculus']
1749996,Number of vertices of a random convex polygon,"Take $n>2$ random points, chosen independently with uniform probability on $[0,1]\times[0,1]$. What is the probability $P(n,k)$ that the convex hull of these points is a polygon with exactly $2<k\leq n$ vertices? It seems that $P(3,3)=1$, since after choosing two points, the probability that the third point will be on the line between them is $0$. For $P(4,4)$, assume 3 points have already been chosen, then their convex hull is a triangle which is the intersection of 3 half spaces. The fourth point will create a quadrilateral if and only if it lies in the intersection of exactly two of the above half spaces. But how can we calculate this area? And what if $n>4$? Then things get really tricky!","['plane-geometry', 'geometric-probability', 'probability', 'puzzle', 'combinatorics']"
1750015,What is the most general/abstract way to think about Tensors,"In their most general and abstract definitions as Mathematical Objects : A Scalar is an element of a field used to define Vector Spaces A Vector is an element of a Vector Space. Since a Scalar is a Tensor of rank-0 and a Vector is a Tensor of rank-1, then what Space are Tensors an element of? Can you even think of Tensors abstractly as elements of a Mathematical Space?","['vector-spaces', 'abstract-algebra', 'tensors', 'linear-algebra', 'vector-analysis']"
1750046,Real roots of $x^6+15x^2-60x+1$,How can I prove that $f(x)= x^6+15x^2-60x+1=0$ can't have three real roots. First I derive two times for see the signs of derivatives and got that  $ 6x^5+30x-60=0$ and $ 30x^4+30=0$ which is always positive but hoe can I conclude that $f$ can't have three roots. Thanks for your help and time.,"['algebra-precalculus', 'calculus']"
1750077,Theorem 3.7 in Baby Rudin: The subsequential limits of a sequence in a metric space form a closed set,"Here's Theorem 3.7 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition. The subsequential limits of a sequence $(p_n)$ in a metric space $X$ form a closed subset of $X$. And, here's Rudin's proof. Let $E^*$ be the set of all subsequential limits of $(p_n)$ and let $q$ be a limit point of $E^*$. We have to show that $q \in E^*$. Choose $n_1$ so that $p_{n_1} \neq q$. (If no such $n_1$ exists, then $E^*$ has only one point, and there is nothing to prove. ) Put $\delta = d(q, p_{n_1})$. Suppose $n_1, \ldots, n_{i-1}$ are chosen. Since $q$ is a limit point of $E^*$, there is an $x \in E^*$ with $d(x, q) < 2^{-i} \delta$. Since $x \in E^*$, there is an $n_i > n_{i-1}$ such that $d(x, p_{n_i}) < 2^{-i} \delta$. Thus $$d(q, p_{n_i}) \leq 2^{1-i} \delta$$ for $i = 1, 2, 3, \ldots$. This says that $(p_{n_i})$ converges to $q$. Hence $q \in E^*$. Now here's my reading of Rudin's proof. If the set $E^*$ of all the subsequential limits of the sequence $(p_n)$ has no limit points, then the set of all the limit points of the set  $E^*$ is empty and is therefore contained in $E^*$. So let's suppose that $q$ is a limit point of the set $E^*$. If $p_n = q$ for all $n \in \mathbb{N}$, then the sequence $(p_n)$, being a constant sequence, converges to $q$, and so every subsequence of $(p_n)$ also converges to $q$; therefore the set $E^*$ consists of a single point $q$ and thus cannot have limit points. So there is a natural number $n$ for which $p_n \neq q$. Let $n_1$ be the smallest such natural number. Let's put $\delta = d\left(q, p_{n_1}\right)$. Then $\delta > 0$. Now since $q$ is a limit point of the set $E^*$, there exists a point $x_1 \in E^*$ such that $$0 < d\left(q, x_1\right) < \frac{\delta}{4}.$$ Now since $x_1$ is a subsequential limit of the sequence $(p_n)$, there is a strictly increasing function $\varphi_1 \colon \mathbb{N} \to \mathbb{N}$ such that $$x_1 = \lim_{n \to \infty} p_{\varphi_1(n)}.$$ So there exists a natural number $N_1$ such that $$d\left( \ x_1\ ,\  p_{\varphi_1(n)} \ \right) < \frac{\delta}{4} $$ for all natural numbers $n$ such that $n > N_1$. We note that, for each $n \in \mathbb{N}$, the inequality $n \leq \varphi_1(n)$ holds. Let $n_2$ be the natural number defined as $$n_2 \colon= \max \left( \ \varphi_1(n_1 + 1)\ , \ \varphi_1(N_1 + 1) \ \right).$$ Then $n_2 > N_1$ and so $$ d\left( \ q \ , \  p_{n_2} \ \right) \leq d\left( \ q,\  x_1 \ \right) + d\left(\ x_1\ , \  p_{n_2} \ \right) < \frac{\delta}{4} + \frac{\delta}{4} = \frac{\delta}{2}.$$ Now as $q$ is a limit point of $E^*$, there exists a point $x_2 \in E^*$ such that $$0 < d(q, x_2) < \frac{ \delta}{8}.$$ Moreover, since $x_2$ is a subsequential limit of the sequence $(p_n)$, there is a strictly increasing function $\varphi_2 \colon \mathbb{N} \to \mathbb{N}$ such that $$x_2 = \lim_{n \to \infty} p_{\varphi_2(n)}.$$ So there is a natural number $N_2$ such that $$ d\left( \ x_2 \ , \  p_{\varphi_2(n)} \ \right) < \frac{\delta}{8}$$ for all natural numbers $n > N_2$. Note that, for each $n \in \mathbb{N}$, we have $n \leq \varphi_2 (n)$. Now let $$n_3 \colon= \max \left( \ \varphi_2(n_2 + 1) \ , \  \varphi_2 ( N_2 + 1) \  \right).$$ Then $n_3$ is a natural number greater than $N_2$ and so we have  $$d\left( \ q\ ,\  p_{n_3} \ \right) \leq d\left( \ q \ , \  x_2 \ \right) + d\left( \ x_2 \ , \  p_{n_3} \ \right) < \frac{\delta}{8} + \frac{\delta}{8} = \frac{\delta}{4}.$$ We note that $$n_3 \geq \varphi_2(n_2 + 1) > \varphi_2(n_2) \geq n_2 \geq \varphi_1 (n_1 + 1) > \varphi_1 (n_1) \geq n_1.$$ That is, $n_1, n_2, n_3$ are all natural numbers such that $$n_1 < n_2 < n_3.$$ Continuing in this way, we obtain a subsequence $(p_{n_i})$, where $n_1, n_2, n_3, \ldots \in \mathbb{N}$  and $n_1 < n_2 < n_3 < \cdots$, such that $$d\left(\ q \ , \  p_{n_i} \ \right) \leq \frac{2\delta}{2^i}$$ for all $i \in \mathbb{N}$. We now show that this  subsequence $(p_{n_i})$ converges to $q$. Let $\varepsilon > 0$ be given. Then we can find a natural number $$K > \frac{2\delta}{\varepsilon}.$$ Then $$2^K > K > \frac{2\delta}{\varepsilon}.$$ So for any natural number $i > K$, we have $$2^i > 2^K > \frac{2\delta}{\varepsilon}$$ and so $$ d\left( \ q \ , \  p_{n_i} \ \right) \leq \frac{2 \delta}{2^i} < \varepsilon. $$ Thus every limit point $q$ of the set $E^*$ is also an element of $E^*$. Hence  $E^*$ is closed. Is my reading of Rudin's proof correct? If not, what is it that I'm missing?","['real-analysis', 'proof-verification', 'metric-spaces', 'sequences-and-series', 'analysis']"
1750104,Difficult Inverse Laplace Transform,"I've had this question in my exam, which most of my batch mates couldn't solve it.The question by the way is the Laplace Transform inverse of $$\frac{\ln s}{(s+1)^2}$$ A Hint was also given, which includes the Laplace Transform of ln t.","['laplace-transform', 'ordinary-differential-equations', 'calculus']"
1750144,Quotient of measurable functions is measurable,"I need to show that if $f,g : X \to \mathbb{R}$ are measurables with respect to  the $\sigma$ -algebra $S$ of $X$ , and $g(x) \neq 0,  \forall x \in X$ , then $f/g: X \to \mathbb{R}$ is measurable.
So far what i got is:
I need to show that { $x \in X: (f/g)(x) \leq c$ } $\in S$ . First Proof: { $x \in X: (f/g)(x) < c$ } $\in S$ Without loss of generality I can write this set as $$\{x \in X: f(x) < c \cdot g(x)\}
\implies
\exists q \in \mathbb{Q}: \{x \in X: f(x) < q < c \cdot g(x)\}
\implies \bigcup_q [ \{x \in X: f(x) < q\} \cap \{x \in X: q < c \cdot g(x)\} ] 
$$ Here's where i'm stuck. I know that $\{x \in X: f(x) < q \} \in S$ but, how do i prove that $\{x \in X: q < c \cdot g(x)\} \in S$ ? I'm thinking the rest of the proof isn't that complicated, but if someone has more ideas, better!","['real-analysis', 'measure-theory']"
1750170,"Comparing Patrick Billingsley's Aniversary Edition to previous editions, and to Robert B. Ash's book.","I'm reading some of the reviews at amazon to the Anniversary edition of Billingsley's 'Probability and Measure', and several users state that the book is riddled with new typos, and plain errors, inexistent in previous editions. Is this true? Are these problematic for someone who intends to use the book for self-study? Also, I've read some good reviews on Robert Ash's 'Probability & Measure Theory'. Is this book self-contained, or does it also refer to Billingsley? Does it misses out on some important aspect? Usually most books that use measure/probability theory eventually refer to Billingsley's book, and so I'm left wondering which one is better. I've read previously Capinsky's book and I've had no difficulty in understanding everything. In fact, I thought that the book took too much freedom in some parts. I'm asking this question because both books Bill and Ash are really expensive, and one much more than the other. So, I would really like to be sure that I'll not be wasting my precious money... Any help would be appreciated.","['reference-request', 'probability-theory', 'book-recommendation', 'measure-theory', 'soft-question']"
1750185,Simplify an integral formula,"I stuck on a statement in the book Mixed Boundary Value Problems - Dean G. Duffy . In page 107, he gives
$$
h(t) = \dfrac{2}{\pi} \dfrac{d}{dt}\left\lbrace \int_0^t \dfrac{\cos(x/2)}{\sqrt{\cos(x) - \cos(t)}} \left[\int_0^x f(\xi) d\xi \right]dx\right\rbrace
$$
then he claims
$$
h(t) = \frac{2}{\pi}\cot\left(\frac{t}{2}\right) \int_0^t \frac{\sin(x/2)f(x)}{\sqrt{\cos(x) - \cos(t)}}dx
$$
Here we assume $f$ is continuous on $\mathbb{R}$. I don't understand how he simplified $h(t)$ from the first equation to the second equation. Can anyone help me out?","['derivatives', 'integration']"
1750204,Embedding Complex Tori in Projective Space,"When we talk about projectively embedding complex tori $\mathbb{C}^{g}/\Lambda$ (i.e in Lefshetz Embedding Theorem), what exactly do we mean by an embedding. Is it in the differential geometry sense of needing to be immersive (injective on tangent spaces), or is less required ? I suppose what I'm really asking is, what do we actually need the embedding to do to call our complex tori an abelian variety?","['abelian-varieties', 'complex-analysis', 'complex-geometry', 'algebraic-geometry']"
1750215,Why is the image of the implicit function in the implicit function theorem not open?,"We have a continuously differentiable function $f$ from $\mathbb{R}^{n+m}$ to $\mathbb{R}^n$, and we find a continuously differentiable function $g$ which maps points from $\mathbb{R}^m$ into $\mathbb{R}^n$ (this function defines $x \in \mathbb{R}^n$ ""implicitly"" in terms of $y \in \mathbb{R}^m $). What regularity properties must the image of $g$ have as a direct result of the proof of the implicit function theorem (if any) in order to allow meaningful differentiable geometry (e.g. manifolds) to ""happen""? In the proof of the Inverse (not implicit) function theorem, we need to care about the properties of the image of $f$. Yet for some reason the properties of the image of $g$ in the Implicit (not inverse) function theorem don't matter? Why is that? What properties, if any, of $g$ in the implicit function theorem, then, are important for the definitions of manifolds and tangent spaces and bundles? This question seems to address a related issue, but the discussion seems to assume that the image of g is open. However, Rudin does not mention this in his proof, nor does it seem to necessarily follow from his proof (we only show the existence of two open sets in $\mathbb{R}^{n+m}$ and one in $\mathbb{R}^m$, but I'm asking about the image of the latter as a set in $\mathbb{R}^n$). EDIT: "" Isn't this unsatisfactory? How can we use the conclusions of the implicit function theorem if the implicit function is neither a homeomorphism nor a diffeomorphism? "" --- I realize now that it can't be a diffeomorphism except for the case where $n=m$, because otherwise we would have a contradiction. Context: This is in some sense the sequel to a question I asked here . In that question I asked why we wanted the image of the continuously differentiable function $f$ to be open. The answer seemed to come down to having a sufficiently meaningful/useful definition of derivative apply to the inverse function so that we had in particular continuity of the inverse function and a homeomorphism. That having the image be open is necessary for this seems somewhat unclear, but appears to be justifiable using Brouwer's invariance of domain theorem. However, in Rudin's proof of the implicit function theorem, it does not seem like it is necessary that the image of the ""implicit function"" $g$ be open. Why don't we have the same problem for the implicit function theorem? Wouldn't we need the image to be open for the inverse image of some set under $g$ to be a manifold? (Assuming it is supposed to somehow be a manifold?)","['real-analysis', 'implicit-function-theorem', 'smooth-manifolds', 'manifolds', 'differential-geometry']"
1750218,A clean way to obtain an (analytic or numeric) solution for this integral?,"A friend and I have been looking at the crazy integral 
$$\iiiint \limits^{\infty}_{-\infty}\exp\left[-(x-t)^2-(x-h)^2-(y+t)^2-(y-h)^2-10\right]\mathrm{d}V$$
and can't come up with a decent method on how to obtain a solution. ($x,y,t,h$ are all variables, not constants) Fubini's theorem would let it split into 4 integrals, but those aren't the cleanest either. I can't think of another method that will work (of course u-sub/parts, etc). Could residue theorem/contour integration work? Fourier integral? Any hints would be appreciated. Edit -- changed $y-t$ to $y+t$","['multivariable-calculus', 'improper-integrals', 'integration']"
1750232,Prove that $e^x$ is not a tempered distribution on $\mathbb{R}$,"Consider the following sequence of functions $\psi_n(x) = e^{-(1+\varepsilon)x} \dfrac{1_{|x|\leq n}}{n}$. Clearly, $|\psi_n^{(m)}(x)|\leq\dfrac{(1+\varepsilon)^m}{n}$. Hence, the $\psi_n$-s are convergent to $0$ in $\mathscr{S}(\mathbb{R})$. However, it is easily computed that $\int_{\mathbb{R}} \psi_n(x)e^xdx = \int_{-n}^{n} e^{-\varepsilon x}dx = \dfrac{1}{\varepsilon}\dfrac{e^{n\varepsilon} - e^{-n\varepsilon }}{n}\geq\dfrac{e^\varepsilon - 1}{\varepsilon}$. Therefore, $v(x) = e^x$ is not a tempered distrubition. Can anybody check if my attempt at proving the claim correct? My idea was based on this discussion","['functional-analysis', 'distribution-theory']"
1750236,Pairwise independence implies independence for normal random variables,"I'm reading a book on Brownian Motion. In the proof of the existence of such random function (Wiener, 1923), the following is stated: Indeed, all increments $B(d)-B(d-2^{-n})$, for $d\in \mathcal{D}_n\setminus \{0\}$, are independent. To see this it suffices to show that they are pairwise independent. as the vector of these increments is Gaussian. The last part of this quote is the claim that pairwise independent normal variables from a Gaussian family are independent. Could anyone provide/direct me to a proof of this claim? Thanks!","['independence', 'probability', 'normal-distribution']"
1750254,"If $\frac{\sin\alpha}{\sin\beta} \le 1+\epsilon$, then $\frac{\alpha}{\beta} \le 1+\sqrt\epsilon\;\;$ (for acute $\alpha$ and $\beta$)","Prove the following: For $0 \le \alpha,\beta \le \frac{\pi}{2}$, if 
  $$\frac{\sin \alpha}{\sin \beta} \le 1+\epsilon$$
  then $$\frac{\alpha}{\beta} \le 1+\sqrt\epsilon$$ This is from this paper , page no 5.","['inequality', 'trigonometry']"
1750267,Local Truncation Error of Implicit Euler,"The LTE of an implicit Euler method is $O(h^2)$ because the method has order $O(h)$, but I'm not sure where to get started in proving this arithmetically. Any help would be appreciated. Thank you!","['numerical-methods', 'ordinary-differential-equations', 'fixed-point-iteration']"
1750276,Dynamically two-coloring a finite graph,"Let $G=(V,E)$ be a finite graph whose vertices are going to be colored dynamically. More precisely, consider time periods $t \in \left\{0,1,2\ldots,\right\}$ and for each time $t$ and $i \in V$, let $X_{t}(i) \in \left\{-1,+1\right\}$ be the color of vertex $i$ at time $t$. Define
$$X_{t+1}(i) = \operatorname{sgn} \sum_{j \in N(i)} {X_{t}(j)},$$
where $N(i)$ is the set of neighbors of $i$ in $G$. If the sum on the right-hand side is $0$ add a self-loop at $i$ and put $X_{t}(i)$ in the sum as well. In other words, the color of $i$ at time $t+1$ is the color that's predominant among its neighbors at time $t$ (and if it is a tie, its color at time $t$ breaks this tie). I have a complicated proof that for any configuration of initial colors $\left\{X_{0}(i)\right\}_{i \in V}$ and any vertex $i$ it holds that $X_{t+2}(i)=X_{t}(i)$ for all sufficiently large $t$, but I'd like to see if there are any elementary approaches since this sounds to me like a very fun olympiad problem.","['combinatorics', 'graph-theory', 'algorithms']"
1750305,"Which surface is homotopy equivalent to $\Bbb{R}^4$ minus the planes $x=y=0$, $z=w=0$?","In completing an exercise I have shown that $\Bbb{R}^3$ minus the axes $x=0$, $y=0$, and $z=0$ is homotopic equivalent to the cube graph $Q_3$. To visualize this, $\Bbb{R}^3-0$ is homotopy equivalent to $S^2$; then, remove the $x=0$ axis and we have a space equivalent to ""a cylinder""; finally,remove the $y=0$ and $x=0$ axes and we have a punctured cylinder: expanding the punctures gives the graph. The next part of the question asks me to consider $\Bbb{R}^4$ minus the planes $x=y=0$, $z=w=0$. I tried a similar approach, however $\Bbb{R}^4$ is much more difficult to imagine. Start with $\Bbb{R}^4-0\simeq S^3$. I think that removing the $x=y=0$ axis gives a surface in $\Bbb{R}^4$ somewhat like a cylinder but ""enclosing"" the $x=y=0$ plane. The next cut/puncture I have no idea with, however. I cannot think how to remove $z=w=0$, without leaving the resulting surface disconnected. Another idea I had was by trying to construct something analogous to $Q_3$. Where $Q_3$ had eight vertices, one corresponding to each octant, perhaps my surface in $\Bbb{R}^4$ will have sixteen edges with thirty-two surfaces corresponding to the adjacent orthants (sharing a hyperplane).","['general-topology', 'homotopy-theory']"
1750317,Interview Question Asked In yahoo,"Can you find the smallest positive number such that if you shuffle the digits of the number in a particular order, the shuffled number becomes twice the original number. Source: http://gpuzzles.com/mind-teasers/very-hard-maths-riddle/ I understand the answer is $125874 => 251748$ $251748$ is twice the $125874$ and have same digits $1,2,4,5,7$ & $8$ but how to solve this non programmatic ?","['puzzle', 'discrete-mathematics']"
1750362,Complex roots of quartic polynomial,"This is a question from an undergraduate course on Galois theory: Find all complex numbers which are  roots of $P(T)=T^4+2T^2-\sqrt{6}T+\frac{3}{4}$ Can we use Galois theory to solves this? Or do we just do soem long calculations to get quadratic polynomials $A(T)$ and $B(T)$ such that $P(T)=A(T)B(T)$ and then use quadratic formula? $P(T)=T^4+2T^2-\sqrt{6}T+\frac{3}{4}=(T^2+aT+b)(T^2+cT+d)=T^4+(c+a)T^3+(d+ac+b)T^2+(ad+bc)T+bd$ $\implies $ $c+a=0 \implies a=-c$ $ d+ac+b=2 \implies d-c^2+b=2 \implies c=\sqrt{d+b-2}$ $ad+bc=-\sqrt{6} \implies -d\sqrt{d+b-2}+b\sqrt{d+b-2}=-\sqrt{6}$ $bd=\frac{3}{4} \implies b=\frac{3}{4d}$ This leads to: $-d\sqrt{d+\frac{3}{4d}-2}+\frac{3}{4d}\sqrt{d+\frac{3}{4d}-2}=-\sqrt{6}=(\frac{3}{4d}-d)\sqrt{d+\frac{3}{4d}-2}$ Squaring both sides gives: $(\frac{3}{4d}-d)^2({d+\frac{3}{4d}-2})=6$ Then we have a cubic in $d$ which I can not solve So this would us a value of $d$ and , in turn, a value of $b$, $c$ and $a$, then we could use the quadratic formula to find complex roots. This is very lengthy (not ideal under exam timed conditions) Is there a more efficient way to solve this problem?","['abstract-algebra', 'galois-theory', 'complex-numbers', 'quadratics']"
1750371,"if $g|ab$ , $g|cd$, $g|ac+bd$, show $g|ac$ and $g|bd$.","Struggling to solve this problem.  Professor suggest we look at $p^n$ as one of the prime factorizations of $g$ (note $p^{n+1}$ doesn't divide $g$) and likewise the number of $p$'s in $a, b, c,$ and $d$ respectively are exactly $r, s, t, u$. His hint is to look at the inequalities among $n, r, s, t, u$ that follow from the divisibility assertions.",['number-theory']
1750432,Equivalence relation on $\mathbb{N}$ with infinitely many equivalence classes,"Does there exist an equivalence relation, defined on $\mathbb{N}$, with infinitely many equivalence classes, all of which contain infinitely many elements? I see no reason for such a relation not to exist, but I'm having trouble finding an example.","['equivalence-relations', 'set-partition', 'elementary-set-theory']"
1750435,Isolating $y$ in $\sin(xy)=\cos(xy)$,"Given $\sin(xy)=\cos(xy)$, what is the best way to isolate $y$? Since $\sin(\frac{\pi}{2}) = \cos(\frac{\pi}{2})$ it would seem intuitive to say that $xy=\frac{\pi}{2}$ and thus that $y=\frac{\pi}{2x}$ Is this the correct approach, or am I missing something important?",['trigonometry']
1750455,Gradient Of Complex Least Squares,"I want to find the gradient of $f : \mathbb{C}^{N} \rightarrow \mathbb{R}$, where $$
f(\mathbf{x}) = \frac 1 2 \Vert \mathbf{Ax} - \mathbf{b} \Vert_2^2,
$$ and $\mathbf{A}\in\mathbb{C}^{M \times N}$, $\mathbf{x}\in\mathbb{C}^{N}$, $\mathbf{b}\in\mathbb{C}^{M}$. For real matrices, it's straightforward, but I am getting stuck with the complex case: $$
f(\mathbf{x}) = \frac 1 2 ( \mathbf{Ax} - \mathbf{b} )^\mathrm{H} ( \mathbf{Ax} - \mathbf{b} ) = \frac 1 2 ( \mathbf{x}^\mathrm{H} \mathbf{A}^\mathrm{H} \mathbf{Ax} - \mathbf{x}^\mathrm{H} \mathbf{A}^\mathrm{H} \mathbf{b} - \mathbf{b}^\mathrm{H} \mathbf{Ax} + \mathbf{b}^\mathrm{H} \mathbf{b} ).
$$ For the first and thirds terms, the gradient is $2 \mathbf{A}^\mathrm{H} \mathbf{Ax}$ and $\mathbf{b}^\mathrm{H} \mathbf{A}$, respectively. For the fourth term it is $\mathbf{0}$. However, it's the gradient of the second term that has me puzzled and I am wondering if there is something fundamental that I have forgotten. How do I account for the conjugation of $\mathbf{x}$ in the gradient? Is that even possible? Any help is greatly appreciated.","['multivariable-calculus', 'several-complex-variables', 'matrix-calculus']"
1750554,"$m+ni+k\lambda,\,\Re(\lambda),\Im(\lambda)\notin \mathbb{Q}$ is dense in $\mathbb{C}$!","As said in the comments below, it's needed to suppose $\{1,\Re(\lambda),\Im(\lambda)\}$ linearly independent over $\mathbb{Q}$, otherwise the result is false, according to Christian's example. This is an exercise of the book Funções de uma Variável Complexa, by Alcides Lins Neto and, well, let's see it before I explain my doubt: Consider $\lambda\in \mathbb{C}$ such that $\Re(\lambda)$ and $\Im(\lambda)$ are NOT rational numbers. Prove that the set
  $$\{m+ni+k\lambda; m,n,k\in \mathbb{Z}\}$$
  is a dense subset of $\mathbb{C}$. This is exercise 19 of the very first section of exercises in the book. At exercise 18 is given a suggestion (which, I suppose, may also be used at the 19th) that is: If $a\notin\mathbb{Q}$ then the set $\{m+na;m,n\in \mathbb{Z}\}$ is dense in $\mathbb{R}$. Let's see what I've tried. Let $z_0$ be any complex number and $\varepsilon>0$ be any ""radius"". In order to show that that set is dense in $\mathbb{C}$ is sufficient to show that there is an element of it in the square
$$R_\varepsilon(z_0)=\left\{u+iv\in \mathbb{C};|u-\Re(z_0)|<\varepsilon,\,\,\, |v-\Im(z_0)|<\varepsilon\right\}.$$
It is sufficient because the collection of ""open squares"" is a basis for topology on $\mathbb{C}\cong\mathbb{R}^2$. Now, using the suggestion, we have that there are $m_1,n_1,m_2,n_2\in \mathbb{Z}$ such that
$$\begin{array}{c}\Re(z_0)-\varepsilon<m_1+n_1\Re(\lambda)<\Re(z_0)+\varepsilon\\
\Im(z_0)-\varepsilon<m_2+n_2\Im(\lambda)<\Im(z_0)+\varepsilon\end{array}.$$
So we have that the number $u+iv$ given by
$$\begin{array}{rcl}u&=&m_1+n_1\Re(\lambda),\\
v&=&m_2+n_2\Im(\lambda),\end{array}$$
is in the square $R_\varepsilon(z_0)$ ""near"" $z_0$.
But now we have the following:
$$u+iv=m_1+m_2i+n_1\Re(\lambda)+n_2\Im(\lambda)i,$$
and this IS NOT NECESSARILY a point of the form $m+ni+k\lambda$, since $n_1$ mights be different from $n_2$. After this I've tried to think something about least common multiple, tried to find a pair to which $n_1=n_2$, or tried to fix $n_1=n_2$ and then to search for suitable $m_1$ and $m_2$: all of them without any success... How to garantee $n_1=n_2$?? Or maybe there is a completely different way of proving it... Thank you guys!","['general-topology', 'complex-analysis', 'real-analysis', 'complex-numbers']"
1750558,What is the skew-symmetric part of the covariant derivative of a one-form?,"This is a followup question to here . Let $E \to M$ be a vector bundle with connection $D := \nabla$. Extend $D$ to $E^*$ and $\text{Hom}(E, E)$. Let $E = TM$ here, and suppose that the torsion is $0$: $$T(X, Y) = \nabla_XY - \nabla_YX - [X, Y] = 0.$$ Does it follow that $d\theta$, the exterior derivative of a $1$-form $\theta$, is the skew-symmetric part of $D\theta$?","['connections', 'tensors', 'differential-forms', 'manifolds', 'differential-geometry']"
1750563,Defining sine and cosine via ODE's,"So I read in Simmons book on Differential Equations that via the equation y''+y=0 One can define s(x), c(x) as their solutions with some given initial conditions, that is s(0)=0 s'(0)=1 ; c(0)=1, c'(0)=0 These are of course sine and cosine, but you don't actually need to know it beforehand. Now, what the book says is that just with these information you can deduce all of the trigonometric identities, I've tried out the simplest ones: s'=c , c'= -s, s^2+c^2=1 and also that they are linearly independent, but I'm having trouble with the other identities such as: s(x+2pi)= s(x) ; 
s(2x)=2s(x)c(x) ; 
s(x+a)=s(x)c(a)+c(x)s(a) With pi defined as the point where s' crosses the x axis. Any help will be deeply appreciated.","['trigonometry', 'ordinary-differential-equations']"
1750574,Applied Mathematics Book on Integro-Differential Equations,"I'm interested in teaching a course on integro-differential equations and their applications. I was wondering if anyone could suggest a decent book on the subject. I'm currently looking at ""Nonlocal Diffusion Problems"" by Andreu-Vaillo, Mazón, Rossi, and Toledo-Melero. Is there a better book or would this be sufficient for a course? Any advice is greatly appreciated.","['integral-equations', 'integro-differential-equations', 'ordinary-differential-equations']"
1750624,What are the solutions of $|x+y|=|x|+|y|$?,"So I am having a problem in solving this type of equation. 
The problem I am dealing with is... $$\left|(2x-1) + \frac{3x-1}x\right| = \left|2x-1\right| + \left|\frac{3x-1}x\right|$$ Please help me with this problem. 
Thank you so much.","['algebra-precalculus', 'absolute-value']"
1750625,Stein and Shakarchi potential typo?,"I'm working through Chapter 6 in Complex Analysis by Stein and Shakarchi, and problem 3 is as follows: If $Q(x)=\lbrace x\rbrace-1/2$, then we can write the expression in the previous problem as $$\zeta(s)=\frac{s}{s-1}-\frac{1}{2}-s\int_1^\infty\frac{Q(x)}{x^{s+1}}\mathrm{d}x$$ The expression in the previous problem is $$\zeta(s)=\frac{s}{s-1}-s\int_1^\infty\frac{\lbrace x\rbrace}{x^{s+1}}\mathrm{d}x$$
which I've already shown to be true.  Also, the notation $\lbrace x\rbrace$ denotes the ffractional part of $x$. My issue is in the $-1/2$ term in the first equation.  Shouldn't it have a factor of $s$ in it?  I just want to make sure that there is a typo before I assume so, as I'd rather not have future work rendered useless by a wrong assumption.",['complex-analysis']
1750645,How to prove $\lim\limits_{x\to 0}xf(x)=0$ suppose we know $\lim\limits_{x\to 0}f(x)=1$?,"How to prove $\lim\limits_{x\to 0}xf(x)=0$ suppose we know $\lim\limits_{x\to 0}f(x)=1$? So we know that $\forall\epsilon\gt 0,\ \exists\delta\gt 0:0\lt|x|\lt\delta\implies|f(x)-1|\lt\epsilon$ We want to prove $\forall\epsilon\gt 0,\ \exists\delta\gt 0:0\lt|x|\lt\delta\implies|xf(x)|\lt\epsilon$ In my personal opinion, it's equivalent to prove $|xf(x)|\lt |f(x)-1|$. (Not sure) What steps should I take to do the formal proof?","['epsilon-delta', 'calculus', 'limits']"
1750669,Topologized by convergence in probability?,"What is the topology when it is refered to the topology of convergence in probability, or ""the space is topologized by convergence in probability""? Let say you have a space $(\Omega, \mathcal{F},P)$, and a sequence of random variables $X_n$ converging in probability to X. Then for any $\epsilon$, $P(\{\omega : |X_n(\omega)-X(\omega)| > \epsilon \})\rightarrow 0$. But what does it mean that we equip the space of random variables with the topology of convergence in probability? What are the actual open sets in this topology? All I see is for instance that for any open set around $X$ then there exists an N such that for $n \ge N$ the sequence $X_n$ is in this open set. But this is just an observation, how are the open sets actually constructed, and is the topology unique? A reference for my question is Protter: Stochastic integration and differential equations. On page 52 he writes: "" We also write $\textbf{L}^0$ for the space of finite-valued random variables topologized by convergence in probability.""","['general-topology', 'probability-theory']"
1750682,How to evaluate $\lim\limits_{x\to 0}\frac{e^{\arctan{(x)}}-xe^{\pi x}-1}{(\ln{(1+x)})^2}$?,How to evaluate $\lim\limits_{x\to 0}\frac{e^{\arctan{(x)}}-xe^{\pi x}-1}{(\ln{(1+x)})^2}$? So I think we expand to $x^2$ since the lowest term for $\ln(1+x)$ is $x$ Let $u=\arctan{(x)}$ $\lim\limits_{x\to 0}\frac{e^{\arctan{(x)}}-xe^{\pi x}-1}{(\ln{(1+x)})^2}=\lim\limits_{x\to 0}\frac{1+u+\frac{u^2}{2}+o(u^2)-(x+\pi x^2+o())-1}{x^2+o()}=\lim\limits_{x\to 0}\frac{1+x+o(x^3)+\frac{x^2+o()}{2}+o(u^2)-(x+\pi x^2+o())-1}{x^2+o()}=\frac12-\pi$ My answer is rather messy and likely incorrect. Could someone provide an easier way to solve such problem?,"['taylor-expansion', 'limits', 'calculus', 'summation', 'power-series']"
1750701,Converting Permutations to Combinations: Simple Stats in Practise,"In a popular text book there is a question that has bothered me that I am sure is very simple for others and I'm just missing something..... So image $100$ songs and we have $10$ as Beatles songs. We want to pick $5$ songs where only the last one we pick is a Beatles song. The probability of that happening expressed as a permutation is ... $\dfrac{ (90 * 89 * 88 * 87) * 10 }{ 100 * 99 * 98 * 97 * 96 } = \dfrac{ P(4,90) * 10 }{ P(5,100) }$. This makes sense to me. But then they translate it to a combination to show us another way of thinking about it. $\dfrac{C(95,9)}{C(100,10)}$ This part is hard for me to grasp. Initially I thought that it describes the chance that $9$ would appear in $90$ if there are $10$ in $100$. That got clarified by a friend of mine when he explained it actually is a sort of logical implication because the last Beatles song will never be in the 95 set so the probability of $9$ in $95$ should somewhat match the probability of $1$ in the last $5$. So here is my REAL question... How is it that the combination also expresses the last song being the beatles song as opposed to it being one of the first four. If there is any clarification that is needed please let me know!! I would really love to answer this question. I'm doing this out of deep interest for the game of Mathematics.","['permutations', 'combinatorics', 'statistics']"
1750709,The absolute value of a sum of two numbers is less than or equal to the sum of the absolute values of two numbers [duplicate],This question already has answers here : Proof of triangle inequality (11 answers) Closed 8 years ago . I am trying to prove (or this could be false) that $|x+y| \leq |x| + |y|$,['discrete-mathematics']
1750731,"Calculate $\int_{\mathbb{R}^2} uvf(u,v)dudv$","For my probability course I have to work out the following integral and I want to be sure that I did it properly since my last calculus-related course was at least 2 years ago. The integral is this one: $$ I = \int_{\mathbb{R}^2} uvf(u,v)\mathrm{d}u\mathrm{d}v$$ $$ f(u,v) = \frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}g(u,v)$$ $$ g(u,v) = \exp\left( -\frac{1}{2} \frac{1}{1-\rho^2}\left\{\left(\frac{u}{\sigma_1}\right)^2 -2\rho\left(\frac{u}{\sigma_1}\right)\left(\frac{v}{\sigma_2}\right)+\left(\frac{v}{\sigma_2}\right)^2\right\}\right) $$ First, if I define: $U = \frac{u}{\sigma_1}$ amd $V = \frac{v}{\sigma_2}$ I can rewrite the integral the following way: $$ I = (\sigma_1\sigma_2)^2\int_{\mathbb{R}^2}UVf(U\sigma_1,V\sigma_2)\mathrm{d}U\mathrm{d}V $$ The current problem is that we can't separate the two integrals because of the term $UV$ in $g(U\sigma_1,V\sigma_2).$ So, that means that I have to find a change of variables so that I can separate $U$ and $V$. For that purpose, I want to find a base in which $h(U,V) = U^2 - 2\rho UV + V^2$ is free from the term $UV$. $$h(U,V) = \pmatrix{U & V} \pmatrix{1 & -\rho \\ -\rho & 1} \pmatrix{U \\ V}$$ Its eigenvalues are:
  $$ \lambda_1 = 1+\rho \text{ and } \lambda_2 = {1-\rho}$$
and its eigenvectors are:
  $$ \vec{\lambda_1} = \pmatrix{1 \\ 1} \text{ and } \vec{\lambda_2} = \pmatrix{1 \\ -1}$$ From there I understand that the variable change $X = U + V$ and $Y = U - V$ will do what I want. Indeed, $$ h(X+Y, X-Y) = 2(X^2(1-\rho) + Y^2(1+\rho)) $$ Since $U$ and $V$ ranged over $\mathbb{R}$ it will be the same for $X+Y$ and $X - Y$. I switch back to lowercase. The integral can now be written: $$ J = \frac{2\pi\sqrt{1-\rho^2}}{\sigma_1\sigma_2}I = \int_{\mathbb{R}^2}(x^2 - y^2)\exp\left\{- \frac{x^2}{1+\rho} - \frac{y^2}{1-\rho} \right\}\mathrm{d}x\mathrm{d}y  $$ I can then write, $$J = J1 - J2 $$ $$ J1 = \int_{\mathbb{R}^2} x^2\exp\left\{- \frac{x^2}{1+\rho} - \frac{y^2}{1-\rho} \right\}\mathrm{d}x\mathrm{d}y$$ $$ J2 = \int_{\mathbb{R}^2} y^2\exp\left\{- \frac{x^2}{1+\rho} - \frac{y^2}{1-\rho} \right\}\mathrm{d}x\mathrm{d}y$$ Before working out $J1$ and $J2$ I remind that: $$ \int_{\mathbb{R}^2} \exp(-ax^2)\mathrm{d}x = \sqrt{\frac{\pi}{a}} $$ and $$ \int_{\mathbb{R}^2} x^2\exp(-ax^2)\mathrm{d}x = \sqrt{\frac{\pi}{4a^3}}$$ First let's work out $J1$. $$\begin{align*}
J1 &= \int_{\mathbb{R}^2} x^2\exp\left\{- \frac{x^2}{1+\rho} - \frac{y^2}{1-\rho} \right\}\mathrm{d}x\mathrm{d}y \\
&= \int_{\mathbb{R}} x^2\exp\left\{- \frac{x^2}{1+\rho}\right\}\mathrm{d}x\int_{\mathbb{R}} \exp\left\{-\frac{y^2}{1-\rho} \right\}\mathrm{d}y \\
&= \frac{\sqrt{(1+\rho)^3\pi}\sqrt{(1-\rho)\pi}}{2}
\end{align*}
$$ Then, I obtain: $$ J2 = \frac{\sqrt{(1-\rho)^3\pi}\sqrt{(1+\rho)\pi}}{2} $$ Thus, $$ J = \frac{\pi (1-\rho^2) (\sqrt{1-\rho} + \sqrt{1+\rho})}{2}$$ Finally,
  $$ I = \frac{\sigma_1\sigma_2}{4} \left( (1-\rho)\sqrt{1+\rho} + (1+\rho)\sqrt{1-\rho} \right) $$ Is this calculation right? I found that question really mean for a starter in a probability class where the lecturer do not know anything about the background of the students. Maybe there is a shorter and simplier solution but I did not saw it.","['multivariable-calculus', 'probability', 'proof-verification']"
1750814,Mirror Symmetry of Elliptic Curve,"I'm a little bit unsure about the mirror symmetry statement for elliptic curves; specifically, how the flipping of the Kähler and complex moduli works.  Perhaps I should say at the outset, the reason I've been thinking about this, is that I'm doing a computation involving a torus with parameter $\tau \in \mathbb{H}$ , and my answer in invariant under $\tau \to \tau+1$ , but not $\tau \to -1/\tau$ .  So I'm thinking that maybe I'm only using the Kähler structure, not the complex structure. Of course, the complex structure is given by $\tau \in \mathbb{H}/\rm{PSL}(2, \mathbb{Z})$ .  I think for the Kähler structure, we choose a class $[\omega] \in H^{2}(X,\mathbb{C})$ , which we can parameterize by Kähler parameter $$t=t_{1} + i \, t_{2},\ t=\frac{1}{2\pi i } \int_{X} [\omega]$$ We identify $t_{2}>0$ with the area of the torus.  So unlike the complex structure, Kähler structures related by $\rm{PSL}(2,\mathbb{Z})$ , aren't necessarily identical, correct?  After all, one will have small area, the other large. So I'm confused about how the mirror symmetry acts .  If mirror symmetry is some mysterious equivalence of the torus under interchange of the complex and Kähler moduli, doesn't that imply that the space of equivalent Kähler structures is also $\mathbb{H}/\rm{PSL}(2, \mathbb{Z})$ .  Is this correct? Thank you.","['symplectic-geometry', 'mirror-symmetry', 'complex-geometry', 'algebraic-geometry']"
1750851,"Some inequalities between 1- norm, 2- norm and infinity-norm: $\|x\|_2\leq\sqrt{\|x\|_1\| x\|_\infty}\leq\frac{1+\sqrt{n}}{2}\|x\|_2$","Let $x\in\mathbb{C}^n$. Do the following inequalities hold?
$$\lVert x\lVert_2\leq\sqrt{\lVert x\lVert_1\lVert x\lVert_\infty}\leq\frac{1+\sqrt{n}}{2}\lVert x\lVert_2.$$
I think the first inequality is the Holder inequality with $p=1$ and $q=\infty$.","['complex-analysis', 'inequality', 'normed-spaces', 'linear-algebra']"
1750854,"how to calculate double sum of GCD(i,j)?","I stumbled upon a programming question which wanted me  to calculate :
$$G(n) = \sum _{i=1}^{n} \sum _{j=i+1}^{n} gcd(i, j).$$
now I wrote a code to solve this problem but it takes polynomial time to solve this .I asked this question here but I think I need more mathematical insight before solving this algorithmicly. So can someone tell me how should I solve this equation in sublinear time .I think this problem has to do something with dirichlet-convolution but I don't understand how .So please help me understand this. this is anothe one $$S(A,B) = \sum _{a=1}^{A} \sum _{b=1}^{B} {a*b } \ f(gcd(a,b))$$
Here, f(n)=n, if n is square free otherwise 0. Also f(1)=1.
for this one also I was able to write _CACHE = {}
def G(a, b):
    a = a % DIVISOR
    b = b % DIVISOR
    key = (a, b) if a > b else (b, a)
    if key not in _CACHE:
        _CACHE[key] = (a * b * F(fractions.gcd(a, b))) % DIVISOR
    return _CACHE[key]

def S(A, B):
    s = 0
    for a in range(1, A+1):
        for b in range(1, B+1):
            s += G(a, b)
    return s

#there is also a code for checking square free number but I have not posted it ,
Here I just wanted to show the time comlexity of the real code which computes here also as you can see I have polynomial time complexity .Maybe there is a mathematical way to reduce this where it is solvable in linear or sublinear time .Please help me out.","['number-theory', 'summation', 'gcd-and-lcm', 'elementary-number-theory']"
1750889,Why does the product of adjugates equal an adjugate of the product?,"How can I show that $\mathrm{adj} (AB) = \mathrm{adj}(B)\ \mathrm{adj}(A)$? It is obvious if determinants are non-zero, but if any of the matrices are singular, I just don't get it. UPD. I've just tried to simply expand (i,j)-th element in both sides, but it seems to be (unnecessarily) complicated and I couldn't figure out the proof.","['matrices', 'products', 'linear-algebra']"
1750909,completion of $C^{\infty}\left(S\right)$ is $L^2(S)$?,"I have the space of infinitely derivable functions, i.e. $C^{\infty}\left(S\right)$ with the following inner product
$$\left\langle f,g\right\rangle =\intop_{0}^{2\pi}\intop_{0}^{2\pi}\left(\overline{f\left(\theta,\varphi\right)}g\left(\theta,\varphi\right)\sin\theta\right)d\theta d\varphi,$$
I would like to understand what does it mean that the completion of this space is $L^2(S)$? Edit : If it's possible I would also like to understand why $L^2(S)$ is the completion of $C^{\infty}\left(S\right)$ with this inner product. I found that this might be a quite general statement so I'd like to know if there's a theorem of some kind abou it. Thanks","['functional-analysis', 'banach-spaces', 'hilbert-spaces', 'analysis']"
1750913,The tangent space of the moduli space of connection?,"I'm reading one of Floer's paper. (An Instanton-Invariant for 3-Manifold). Let $M$ be a $3$-manifold. A principal $SU_2$-bundle P over $M$ must be trivial. Fixed a trivialization $P \cong M \times SU_2$  and we can regard the space of connection as $su_2$-valued $1$-forms on $M$. Denote $L_1^4(\Omega^1(M)\otimes su_2)$ by $\mathcal{A}(M)$. The gauge group $L_1^4(M,SU_2)$ (denoted by $\mathcal{G}(M)$) atcs on $\mathcal{A}(M)$ by $$ g(a) = g a g^{-1} + (dg) g^{-1}.$$ Denote $\mathcal{A}(M)/\mathcal{G}(M)$ by $\mathcal{B}(M)$. For $a \in \mathcal{A}(M)$ such that $\operatorname{Fix}(a)$ is the center $\mathbb{Z}_2$. There is an identification for the tangent space $$ T_{[a]} \mathcal{B}(M) = \{ \alpha \in L(\Omega(M) \otimes su_2) | d_a^\ast \alpha = 0 \}$$ where $d_a$ extend $d$ on $M$ by the connection $a$ and $d_a^\ast$ is its $L^2$-adjoint. My question is that how we can get the identification for the tangent space? Or is there any more detailed text about this type of objects? (Moduli spaces, Banach manifolds, etc.) Thank you.","['moduli-space', 'connections', 'differential-geometry', 'differential-topology']"
1750914,Monte Carlo with non uniform weighting,"So, I just want to check if what is in my mind is in fact true. Assume, that we have are given a distribution $p_{z}(k)$ over the whole $\mathbb{Z}^+$. We are interested in approximating $p_v(v)$ over some observed variable $v$. However, we are not given $p_v$ directly, but rather a joint $p(v,h) = p(h)p(v|h)$ such that the marginal $p_v(v)$ is intractable. Thus we seek to approximate $p_v(v)$ via importance sampling - e.g. taking sample from some $q(h)$ and using the fact that $$p_v(v) = \mathbb{E}\left[\frac{p(v,h)}{q(h)}\right]_q$$
Thus usually what is done is to use MC to approximate p(v) via:
$$p_v(v) \approx \sum_{k=1}^K \frac{1}{K} \frac{p(v,h_k)}{q(h_k)}$$
According to the strong law of large numbers, the approximation will be exact when $K \to \infty$, under some mild conditions, which we assume are true. However, I can re write this as:
$$ p_v(v) \approx \sum_{k=1}^K \frac{p_z(k)}{\sum_{i=1}^K p_z(i)}  \frac{p(v,h_k)}{q(h_k)}$$
Where in the MC case $p_z(k)$ is a degenerate uniform distribution, however the limit still exists and converges, assuming we define appropriately $\frac{p_z(k)}{\sum_{i=1}^K p_z(i)}$.
Now in the limit of infinite examples essentially we have:
$$ \lim_{K \to \infty} \sum_{k=1}^K \frac{p_z(k)}{\sum_{i=1}^K p_z(i)}  \frac{p(v,h_k)}{q(h_k)} = \mathbb{E}\left[\frac{p(v,h)}{q(h)}\right]_{p_z* q} = p_v(v)$$ Thus I have two questions. First, is my reasoning correct or is there some major flaw? Secondly, if there is no mistake, is it possible to pick better weights for the MC sampling (I think not) and why?","['monte-carlo', 'statistics', 'law-of-large-numbers', 'convergence-divergence']"
1750968,Pade approximant for the function $\sqrt{1+x}$,"I'm doing the followiwng exercise: The objective is to obtain an approximation for the square root of any given number using the expression $$\sqrt{1+x}=f(x)\cdot\sqrt{1+g(x)}$$ where g(x) is an infinitesimal. If we choose $f(x)$ as an approximation of $\sqrt{1+x}$ , then we can calculate $g(x)$ : $$g(x)=\frac{1+x}{f^2(x)}-1$$ $f(x)$ can be chosen as a rational function $p(x)/q(x)$ , such that $p$ and $q$ have the same degree and it's Mclaurin series is equal to the Mclaurin series of the function $\sqrt{1+x}$ until some degree. Find a rational function $f(x):=p(x)/q(x)$ , quotient of two linear polynomials, such that the McLaurin series of $p(x)-\sqrt{1+x}\cdot q(x)$ have the three first terms equal to $0$ . How can I do this? Has something to be with the Pade approximant? Any hint would be really appreciated. Thanks for your time.","['numerical-methods', 'calculus', 'functions']"
1750975,Question about Vitali Covering (from a Lemma in Royden and Fitzpatrick's book),"Definition. For a real valued function $f$ and an interior point $x$ of its domain, the upper derivative of $f$ at $x$ denoted by $\overline{D}f(x)$ is defined as follows: $$\overline{D}f(x)=\lim_{h\rightarrow0}\left[ \sup \left \{\frac{f(x+t)-f(x)}{t}: 0<|t|\leq h \right \} \right]$$ A Lemma in Royden and Fitzpatrick's Real Analysis book says: Lemma. Let $f$ be an increasing function on the closed, bounded interval $[a,b]$ . Then for each $\alpha>0$ , $$m^*\{x\in (a,b) : \overline{D}f(x) \geq 
\alpha \} \leq \frac{1}{\alpha}[f(b)-f(a)].$$ The book proceeds to prove this by: Let $\alpha>0$ . Define $E_{\alpha}:=\{x\in (a,b): \overline{D}f(x)\geq\alpha \}$ . Choose $\alpha' \in (0,\alpha)$ . Let $\mathscr{F}$ be the collection of closed, bounded intervals $[c,d]$ contained in $(a,b)$ for which $f(d)-f(c)\geq \alpha ' (d-c)$ . Since $\overline{D}f\geq \alpha$ on $E_{\alpha}$ , $\mathscr{F}$ is a Vitali covering for $E_{\alpha}$ . I can follow the rest of the proof, but why is the statement above true? In particular, why is $\mathscr{F}\neq \emptyset$ , and why is it a Vitali covering for $E_{\alpha}$ ? I have an inkling that it might be due to the fact that $f$ is increasing in $(a,b)$ and thus it can only have a countable number of discontinuity on it, but I can't quite get a solid grasp of it.",['measure-theory']
1751037,$\det(ABC) = \det(B)\det(AC)$?,"Suppose $A$, $B$, and $C$ are $(n \times m)$, $(m \times m)$, and $(m \times n)$ matrices respectively, with $m\gt n$. What are the most general conditions under which $$ \det(ABC) = \det(B)\det(AC)$$ holds?","['matrices', 'linear-algebra', 'determinant']"
1751038,Intuitive interpretation of negative probabilities,"I have heard that in quantum physics, negative probabilities show up in certain distributions. Could you give an example that aids in the intuitional interpretation of a negative probabilities? For example, what does $X \sim N(0,1) -\delta$ mean, and how does it relate to $Y \sim N(0,1)$ . Can we say anything about the relationship between $Y$ and $X$ ?","['quantum-mechanics', 'probability-theory']"
1751052,"For the function $f(X) = x+ \frac 1x$, if maxima is found using second derivative test we get $x=1$ as the answer. But isn't $x = -1 $ the answer?","$$f(x) = x +\frac 1x$$ $$f'(x) = 1- x^{-2}=0 $$ $$\implies x= \pm 1$$ $$f''(x)= 2x^{-3}$$ $$f''(-1)<0$$ $$f''(1)>0$$ Therefore $x = 1 $ is the minimum. but $f(1)= 2 > f(-1) =-2.$
which means $-1$ is the minimum. How is it possible?
Please explain if there is a mistake.","['derivatives', 'functions']"
1751059,An interesting puzzle from Jiří Matoušek's book,"There is an interesting puzzle from Jiří Matoušek's book Invitation to Discrete Mathematics , problem 1.2.8 , which confused me lots of time. Divide the following figure into $7$ parts, all of them congruent (they only differ by translation, rotation, and possibly by a mirror reflection). All the bounding segments in the figure have length $1$, and the angles are $90$, $120$, and $150$ degrees.","['puzzle', 'combinatorics', 'discrete-mathematics']"
1751081,Solving the Diophantine Equation $x^2 - y! = 2001$ and $x^2 - y! = 2016$,"I had recently faced a problem: Solve the Diophantine Equation $x^2 - y! = 2001$. Solving it was quite easy. You show how $\forall y \ge 6$, $9|y!$ and since $3$ divides the RHS, it must divide the LHS and if $3|x^2 \implies 9|x^2$ and so the LHS is divisible by $9$ and the RHS is not. Contradiction. Hence, the only solution is $(45, 4)$. That made me wonder, how we can solve the Diophantine Equation $x^2 - y! = 2016$. We cannot apply the same logic here. $2016$ is a multiple of $9$ and it is clear that $3|x$ and $9 \nmid x$. How do I proceed from here?","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
1751106,"Continuity of Banach limit and existence of $\Lambda_0\in(\ell^\infty/c_0)^*$ such that $\Lambda=\Lambda_0\circ q_0$, with $q_0$ the quotient map","Let $\Lambda$ be any Banach limit on $\ell^\infty$ , where $\ell^\infty$ denotes the space of bounded real sequences. A Banach limit is defined as a linear functional $\Lambda$ such that $$ \Lambda(\tau x)=\Lambda(x), \forall x\in\ell^\infty$$ $$ \liminf_{n\rightarrow\infty}x_n\leq\Lambda(x)\leq\limsup_{n\rightarrow\infty}x_n$$ where we write $x=(x_n)_{n\in\mathbb{N}}$ for a sequence $x\in\ell^\infty$ and we define left translation on $\ell^\infty$ by $(\tau x)_n=x_{n+1},n=1,2,\dots$ . I would like to show that $\Lambda\in(\ell^\infty)^*$ , which means that $\Lambda$ is a continuous, linear functional on $\ell^\infty$ . Thus I need to show that $\Lambda$ is continuous. How do I do this? Furthermore I wish to show that there exists a continuous, linear functional $\Lambda_0\in(\ell^\infty/c_0)^*$ such that $\Lambda=\Lambda_0\circ q_0$ , where $$q_0:\ell^\infty\rightarrow\ell^\infty/c_0$$ is the quotient map and $$c_0=\{(x_n)\in\ell^\infty\mid \lim_{n\rightarrow\infty}x_n=0\}$$ I can't seem to get anywhere with these questions. Any help is greatly appreciated.","['functional-analysis', 'real-analysis', 'analysis']"
1751118,"A is an antisymmetric matrix (of even size). B is another matrix such that $b_{i,j}=a_{i,j}+c$. Prove that |A|=|B|","I know that B would look something like this:
$$\begin{bmatrix}
c & a_{12}+c  &...&&a_{1n}+c
\\
-a_{12}+c & c &...&&a_{2n}+c 
\\
.
\\
.
\\
.
\\
-a_{1n}+c & -a_{2n}+c & &...&c 
\end{bmatrix}$$ And that if it was of uneven size the determinant would be $0$.
I also know that $|B|=|B^t|$ and $|A|=|A^t|=|-A|=(-1)^n|A|$. Any hint?","['matrices', 'determinant']"
1751176,Solve the equation $1 / \cos x = \cos x + \sin x$,"I'm having trouble solving the equation $$
\frac{1}{\cos x} = \cos x + \sin x
$$ For what I understand I have to make the equation $= 0$ So I get 
$$
\frac{1}{\cos x} - \cos x -\sin x = 0
$$ Any help is greatly appreciated :)","['trigonometry', 'functional-equations']"
1751187,What does the function f: x ↦ y mean?,"I am doing IGCSE Maths , and am having a few problems with function notation. I understand the form $f(x)$ . What does the form $f: x ↦ y$ mean? Could you also give one or two examples? And, if possible, state your source. Thank you.","['notation', 'functions']"
1751196,What is a probability that at 2nd turn you will pick green ball?,"I have an interesting question that I certainly don't know how to solve it. I've already read many topics on probability, eg: Probability that someone will pick a red ball first? and Comparing probabilities of drawing balls of certain color, with and without replacement etc. But unfortunately, I can't apply the same methodology in this case and get the right answer from the given ones (it seems I'm really silly one). So here is the question: There are 5 balls in a bucket: green, blue, red, orange and black. Each turn you take a random ball from the bucket. What is a probability that at 2nd turn you will pick blue ball? The answers: 1/2 2/3 1/3 2/5 1/5 The first way I thought is to add probability of each turn like this: $\frac{1}{5} + \frac{1}{4}$ - 1/4 because at 2nd turn we have only four balls. However, the answer become $\frac{9}{20}$ which is not correct. I know there is something to do with either factorial or combination (just my assumption).",['probability']
