question_id,title,body,tags
451917,"If $f<1$, $f(0)^2 + f'(0)^2=4$, exists $x_0$ s.t. $f''(x_0) + f(x_0)=0$","Suppose $f:\mathbb{R}\to\mathbb{R}$ is $C^2$, $f < 1$ for all $x$, and $f(0)^2 + f'(0)^2=4$. Show that $\exists x_0$ s.t. $f''(x_0) + f(x_0)=0$. So far, I have let $\phi(x) = f(x)^2 + f'(x)^2$. Then $$\phi'(x) = 2f(x)f'(x) + 2f'(x)f''(x) = 2f'(x)(f(x) + f''(x)).$$ So we need to show that there's a critical point of $\phi$ that is not a critical point of $f$. I believe this is supposed to be an exercise in the mean value theorem, but I don't know where to find another value of $\phi(x)$. Any ideas? (This is a problem from a teacher's set of notes, so of course there could be a typo. Could it be that $|f|<1$ is what he meant, for instance?)","['calculus', 'derivatives']"
451924,"taking the limit of $f(x)$, questions",How do I take the limit of the following functions? I had included some of my thoughts with them. $\lim_{x\to\infty}\dfrac{4x^3 - 2x + 1}{8x^3 + \sin(x^2) - x^{-1}}$; my thoughts: I am not sure about the bottom since there are the sine function and $-1$ power $\lim_{x\to\infty}\dfrac{e^x}{x^{x-1}}$; my thoughts: isn't $e^x$ faster since $x^{x-1}$ is one power lower than the top? $\lim_{x\to\infty}\dfrac{x^x}{x^{x+1}}$; my thoughts: the bottom is faster since is one power higher than the top. Ty!,"['calculus', 'limits']"
451941,Need help calculating this determinant using induction,"This is the determinant of a matrix of ($n \times n$) that needs to be calculated: \begin{pmatrix}
3 &2 &0 &0 &\cdots &0 &0 &0 &0\\
1 &3 &2 &0 &\cdots &0 &0 &0 &0\\
0 &1 &3 &2 &\cdots &0 &0 &0 &0\\
0 &0 &1 &3 &\cdots &0 &0 &0 &0\\
\vdots &\vdots &\vdots&\ddots &\ddots &\ddots&\vdots &\vdots&\vdots\\
0 &0 &0 &0 &\cdots &3 &2 &0 &0\\
0 &0 &0 &0 &\cdots &1 &3 &2 &0\\
0 &0 &0 &0 &\cdots &0 &1 &3 &2\\
0 &0 &0 &0 &\cdots &0 &0 &1 &3\\
\end{pmatrix}
The matrix follows the pattern as showed.
I have to calculate it using induction (we haven't learnt recursion so far). Thanks","['matrices', 'induction', 'linear-algebra', 'determinant']"
451943,Angles between two vertices on a dodecahedron,"Say $20$ points are placed across a spherical planet, and they are all spaced evenly, forming the vertices of a dodecahedron. I would like to calculate the distances between the points, but that requires me to find out the angles between the vertices. From the origin of the dodecahedron, how would I find the angle between two adjacent vertices on the same face, and the angle between two vertices on the same face but not connected by an edge?","['geometry', 'polyhedra']"
451944,A doubt over a differentiation problem.,"The question is: Find the equation of the tangent to the curve $y^2=8x$ at a point $(x_0,y_0)$ . My teacher's approach : Differentiate the equation. we get $2y\cdot \dfrac {dy}{dx}=8 $ which gives us : $\dfrac {dy}{dx}=\dfrac4y$ . At a point $(x_0,y_0)$ , slope of the tangent = $\dfrac4{y_0}$ So the equation of the tangent is $\dfrac{y-y_0}{x-x_0}=\dfrac4{y_0}$ What bothers me here is the differentiation. According to wikipedia : the derivative is the ratio of the infinitesimal change of the output over the infinitesimal change of the input producing that change of output. For a real-valued function of a single real variable, the derivative at a point equals the slope of the tangent line to the graph of the function at that point. But, $y^2=8x$ is NOT a function. Then, how can one find the derivative?
This bothers me a lot.. Can someone help me? Thank you.","['calculus', 'derivatives']"
451977,Question about linear non-autonomous ode,"I am currently learning about ode's and I am on the topic of linear non-autonomous ode's. The professor is deriving the solution to the following ode using some integrating factor $I$. $$\frac{dx}{dt} = A(t)x+B(t)$$ So these are the steps that he makes in finding $x$. $$\begin{align}
I\left(\frac{dx}{dt} - Ax = B \right) \\
I\frac{dx}{dt} - AIx = IB \\
I\frac{dx}{dt} - \frac{dI}{dt} x = IB \\
d(Ix) = IB \\
\frac{dI}{dt} = -AI
\end{align}$$ I understand all of those steps and now, since this a simple ode we can separate it and arrive at solution for $I$ as $$I = \exp (\int -Adt) = e^{-\int A}$$ Now, takes this solution of $I$ and uses it in $d(Ix) = IB$ by integrating both sides and subbing in $I$. $$\begin{align}
Ix &= \int IB \\
x &= \frac{1}{I} \int IB \\
x &= e^{\int A} (\int B e^{-\int A}) & \text{?!} \\
\end{align}$$ That last bit is where my confusion is. How did he arrive at the last step because if we sub in $I$, should it not be $\frac{1}{e^{-\int A}}$? Where did the negative go and why is it reciprocal? Thanks!","['ordinary-differential-equations', 'calculus']"
451979,Prove that the centre of the nine-point circle lies on the midpoint of the Euler line,"In $\Delta ABC$, $AD, BE, CF$ are the altitudes and $\Delta A'B'C'$ is the medial triangle. $K, L, M$ are the midpoints of $AH, CH, BH$. Consider the nine-point circle with centre $G$ (not to be confused with the centroid) and diameters shaded in yellow. Prove that $G$ is the midpoint of the Euler line $HO$. This, frankly, is an amazing result. The fact that the nine-point circle exists at all is amazing in itself. But, I haven't seen a convincing proof for this fact yet.","['geometry', 'triangles', 'circles']"
451980,Multiplicative groups,"Consider the multiplicative groups $\def\R{{\mathbb R}}(\R^\ast,\cdot)$ and $(\R^+, \cdot)$.  Show that $\R^\ast \cong\R^+\times\Bbb Z_2$. Consider the  multiplicative group $\def\Q{{\mathbb Q}}(\Q^+,\cdot)$. List the elements of the cyclic subgroup $H=\langle4\rangle$. Is $H$ normal?  List the elements of the cosets $\frac13H$ and $2H$. Describe the quotient $\Q^+/H$ by picking a representative for each coset of $H$.  In the quotient $\Q^+/H$, what is the order of $\frac13H$? What is the order of $2H$?  What is $(2H)\Bigl(\frac23H\Bigr)$? For $(1)$, I thought if $a$ is in $\mathbb{R}^*$, then we can find function $F$ such that $F(a) = a \times 1$ if $a>0$, 
and $F(a) = -a \times 0$ if $a<0$. Maybe this function shows they are isomorphic? Is this right? For $(2)$, how $H=\langle 4\rangle$ is cyclic subgroup? Is $H$ all $\mathbb{Q}*$, since if $a$ is in $\mathbb{Q}*$, we can always find $\frac14a$ in $\mathbb{Q}*$ or is $H$ just $\{4,8,12,16,\dots\}$ or $\{\dots,-8,-4,0,4,8.12,\dots\}$ ? I'm not sure what $H$ is. To describe the quotient $Q^+$/H, maybe it is a set of aH such that 
$0 < a\leq 1$ and $a= \dfrac{x}{y}$ such that x and y are integers and $gcd(x,y) = 1$. Thank you! (Original image of questions: https://i.sstatic.net/wRRUJ.png )","['group-theory', 'abstract-algebra']"
452007,how to draw graphs of ODE's,"In order to solve this question How to calculate $\omega$-limits I'm trying to learn how to draw graphs of ODE's. For example, let $p\in \mathbb R^2$ in the case of the field $Y=(Y_1, Y_2)$, given by: $Y_1=-y_2+y_1(y_1^2+y_2^2)\sin\left(\dfrac{\pi}{\sqrt{y_1^2+y_2^2}}\right)$ $Y_2=y_1+y_2(y_1^2+y_2^2)\sin\left(\dfrac{\pi}{\sqrt{y_1^2+y_2^2}}\right)$ I need help. Thanks so much",['ordinary-differential-equations']
452028,"Evaluate $\sum\limits_{(m,n) \in D,m < n} \frac{1}{n^2 m^2} $ where $\gcd(m,n)=1$","i have no clue on how to evaluate:
$$\sum\limits_{(m,n) \in D,m < n} \frac{1}{n^2 m^2} \text{ where }D = \{ (m,n) \in (\mathbb{N}^*)^2 \mid \gcd(m,n) = 1\} $$ If someone is able to give me a hint...
Thanks much in advance.","['modular-arithmetic', 'sequences-and-series']"
452029,Range of a nonconstant polynomial over complex numbers,"If $ P : \mathbb{C} \rightarrow \mathbb{C} $ is a nonconstant polynomail,  what is the range of $P$?  Prove this. Wouldn't the range be all of $\mathbb{C}$? If so, I believe I can prove it using contradiction, by assuming the range is $\mathbb{R}$, and then show there exists some $z_0$ such that $P(z_0)$ is not in $\mathbb{R}$ Any help would be great. Thanks.",['complex-analysis']
452053,Is there a slowest rate of divergence of a series?,"$$f(n)=\sum_{i=1}^n\frac{1}{i}$$
diverges slower than
$$g(n)=\sum_{i=1}^n\frac{1}{\sqrt{i}}$$
, by which I mean $\lim_{n\rightarrow \infty}(g(n)-f(n))=\infty$. Similarly, $\ln(n)$ diverges as fast as $f(n)$, as $\lim_{n \rightarrow \infty}(f(n)-\ln(n))=\gamma$, so they 'diverge at the same speed'. I think there are an infinite number of 'speeds of divergence' (for example, $\sum_{i=1}^n\frac{1}{i^k}$ diverge at different rates for different $k<1$). However, is there a slowest speed of divergence? That is, does there exist a divergent series, $s(n)$, such that for any other divergent series $S(n)$, the limit $\lim_{n \rightarrow \infty}(S(n)-s(n))=\infty$ or $=k$? If so, are there an infinite number of these slowest series?","['asymptotics', 'divergent-series', 'sequences-and-series']"
452065,Properties of the Fourier transform of a certain function,"In my research I met the Fourier transform of the function $f(x)=(1+x^2)^{-1/2}$. I was not able to find its explicit formula. Is this a function known as a 'special function'? I would like to know if it is nonnegative, summable, etc.","['special-functions', 'analysis']"
452101,Derive $\frac1n \|x\|_p^p \leq \|x\| \leq n^{p/2}\|x\|_p^p$ from Holder's inequality?,"Given a vector $x = (x_1, \dotsc, x_n)\in \mathbb{C}^n$, I wanted to compare $|x_1|^p + \dotsb + |x_n|^p$ to $\|x\|^p$. I discovered that if $m=\max_i|x_i|$, we have $$m^p \leq \|x\|^p \leq n^{p/2}m^p$$ and $$m^p \leq |x_1|^p + \dotsb + |x_n|^p \leq nm^p,$$ which gives us $$\frac1n (|x_1|^p + \dotsb + |x_n|^p) \leq \|x\|^p \leq n^{p/2}(|x_1|^p + \dotsb + |x_n|^p).$$ Then I noticed I could just express this as $$\frac1n \|x\|_p^p \leq \|x\|^p \leq n^{p/2}\|x\|_p^p.$$ Could I have derived this easily from Holder's inequality in a way I'm missing?","['multivariable-calculus', 'calculus', 'measure-theory', 'normed-spaces', 'linear-algebra']"
452106,"$(a,b)$ is saddle point if $f_{xy}(a,b)\not= 0$","Suppose that $V$ is open in $\Bbb R^2$ that $(a,b)\in V$$\ \ \ \ \ f:V\to\Bbb R$ has second order partial total differential on $V$ with $f_x(a,b)=f_y(a,b)=0$ If the second order partial derivatives of f are continuous and exactly two of three numbers $f_{xx}(a,b)$ $f_{xy}(a,b)$ and $f_{yy}(a,b)$ are zero, Then prove that (a,b) is saddle point if $f_{xy}(a,b)\not= 0$ I think that Since $f_{xy}(a,b)\not=0$ $$f_{xx}(a,b)=f_{yy}(a,b)=0$$ I want to solve this question by using the theorem. Thm: let $A,B,C\in \Bbb R$ and $D=AC-B^2$ and $\varphi $(h,k)=$Ah^{2}+2Bhk+Ck^2$ if (i) $D>0$ and A, $\varphi(h,k)$ have same sign $\forall (h,k)\not= 0$ (ii) ıf $D<0$ then $\varphi (h,k)$ takes on both positive and negative valuesas (h,k) varies over $\Bbb R^2$ But, after here, I dont have any idea. Show me the solution? Thank you.","['calculus', 'self-learning', 'real-analysis', 'analysis', 'derivatives']"
452108,Can anyone give me a counterexample to this statement? [duplicate],"This question already has answers here : Can an irrational number raised to an irrational power be rational? (7 answers) Closed 10 years ago . Statement:  Let $n$ and $m$ be two irrational numbers. Then $n^m$ is always irrational. I think this statement is correct, otherwise can someone give me a counterexample? Thanks!","['real-analysis', 'number-theory']"
452146,"Understanding ""Divides"" aka ""|"" as used logic","What are the rules for using the divides operator aka ""$\mid$""? Is it false to say $2\mid5$ since $5/2$ = $2.5$ and $2.5\notin\mathbb{Z}$? Or does my question imply a misunderstanding? I am seeing this for the first time in the 6.042J, Lecture 2: Induction on MIT OCW . Thanks for the help.","['logic', 'algebra-precalculus']"
452162,is there a difference between counting those better than you vs counting those worse than you in relative scoring games with ties allowed,"This is my first question so let me know if I am doing something wrong. Imaging a relative scoring game. What I mean by this is a game with a set number of players... lets just say 100 where the score a player gets for a round is based upon the ranking they achieve.  The game consists of multiple rounds.  So for instance first place in any round would get 100 points and second place would get 99 then 3rd place 98...and so on and so forth until the last player gets 1 point.  At the end of the game the person with the most overall points wins. If there is a tie both players get the higher value.  So for example a tie for second place would result in two people getting a score of 99 and then 4th place would get 97 points. My friend is incorrectly trying to suggest that counting the amount of players you have beaten and counting the amount of players that have beaten you refers to the exact same thing, however I think that because it is possible to tie, these are different. In a very mathematical sort of way, how can I prove to him that they are different.  My thinking is that if you beat 80 people it does not necessarily mean that 19 people have beaten you...(or vice versa)  Perhaps only 10 people beat you because you are in the middle of a 9 way tie.","['game-theory', 'discrete-mathematics', 'descriptive-statistics']"
452173,Finding the limit of roots products $(\sqrt{2}-\sqrt[3]{2})(\sqrt{2}-\sqrt[4]{2})(\sqrt{2}-\sqrt[5]{2})\cdot \cdot \cdot (\sqrt{2}-\sqrt[n]{2})$,"I need to find: $$
\lim_{n \to \infty } (\sqrt{2}-\sqrt[3]{2})(\sqrt{2}-\sqrt[4]{2})(\sqrt{2}-\sqrt[5]{2})\cdot \cdot \cdot (\sqrt{2}-\sqrt[n]{2}) 
$$ So far, I think that $0<\sqrt{2}-\sqrt[n]{2}<1$, and it seems to me that the limit will approach zero but I can't figure how to show it mathematically.","['calculus', 'infinite-product', 'limits']"
452175,Calculating % Grade from latitude and longitude,"I am trying to calculate % Grade from GPS points.  I am using the basic equation of $$\dfrac{\text{Rise}}{\text{Run}} \times 100$$ The problem is I am getting spikes in my GPS data (example $1$ meter rise for $3$ meter run), I am guessing because of the fluctuation of the Vertical Accuracy of the GPS. Has anyone dealt with this scenario or know of a way of weeding out the anomalies?","['geometry', 'trigonometry']"
452180,Which unordered partition of $n$ gives rise to the largest number of ordered partitions?,"A quick look at the wikipedia article on partitions of $n \in \mathbb{N}$ shows that the number of ordered partitions is $2^{n-1}$, and the number of unordered partitions is asymptotically $ \sim \frac{1}{4n\sqrt{3}} e^{\pi \sqrt{\frac{2n}{3}}}$. We can write an unordered partition of $n$ as an $n$ length vector $[a_1, a_2, ..., a_n]$ where $a_i$ is the number of parts of size $i$. For this to be a valid partition of $n$, we must have
$$\sum_{i=1}^n ia_i = n.$$
Each such unordered partition gives rise to $\frac{(\sum a_i) !}{\Pi a_i!}$ ordered partitions of $n$. For a given $n$, let $\mbox{argmax}_a \frac{(\sum a_i) !}{\Pi a_i!} = a^*(n)$, where the maximum is taken over all valid unordered partitions of $a$ of $n$. My question is, as $n \to \infty$ does the vector $\frac{1}{n}[a^*_1, a^*_2, ..., a^*_n]$ converge in some sense? If so, this would mean that the unordered partitions that lead to the largest number of ordered partitions tend to have a fixed fraction of size $i$ blocks for each $i$.","['integer-partitions', 'number-theory', 'combinatorics']"
452182,Matrix differential equation and closed orbits,"everyone. I am asking for a reference for the nonexistence of closed orbits (periodic orbits) of Matrix differential equations of the form
\begin{equation}
v\prime = M(v)\cdot v
\end{equation}
where $M(v)$ is a (nonconstant) matrix depending smoothly on $v \in \mathbb{R}^n$. I am really not an expert in Differential Equations. Advanced thanks for any help/suggestion/reference.","['dynamical-systems', 'ordinary-differential-equations', 'reference-request']"
452193,Finding a Liapunov function. Is my analysis correct?,"Consider the following system of differential equations $x'=f(x)$:
\begin{equation}
x_1' = -x_1 -x_2^3 \\
x_2' = x_1-x_2
\end{equation} Here is the Liapunov function I wish to use: $V(x_1, x_2) = \alpha x_1^2 + \beta x_2^4$. So I need to find $\alpha$ and $\beta$ that satisfy the following 3 Liapunov conditions: The conditions to be a Liapunov funtion w.r.t the origin $x_0$: 1) $V(0, 0) = 0$ Condition 1) is clearly true. 2) $V(x) > 0$ for all $x\neq x_0$ This is clearly true for $\alpha \geq 0$ and $\beta \geq 0$ but not both equal to $0$. 3) $\nabla V\cdot f \leq 0$ for all $x$: \begin{align}
\nabla V\cdot f &= 2\alpha x_1(-x_1-x_2^3) + 4\beta x_2 (x_1-x_2)\\
                &= -2\alpha x_1^2 -2\alpha x_1x_2^3 + 4\beta x_1x_2 - 4\beta x_2^2\\
                &= -4\beta x_2^2 -2\alpha x_1^2 -2\alpha x_1x_2^3 +4\beta x_1x_2\\
                &= -4\beta x_2^2 -2\alpha + x_1x_2(-2\alpha x_2^2+4\beta)
\end{align} In order for condition 3) to hold, that is $\nabla V(x)\cdot f \leq 0$ for all $x$, then the third term must equal $0$. That is we need:
\begin{equation}
-2\alpha x_2^2+4\beta =0
\end{equation}
If this is the case, all solutions depend on $x_2$ unless both $\alpha$ and $\beta$ equal $0$ which cannot happen as condition 2) would not be satisfied. This is where I am stuck. Please help!","['lyapunov-functions', 'ordinary-differential-equations']"
452205,IFT application.,"Suppose that $f:=(u,v):\Bbb R\to \Bbb R^2$ is $C^2$ and $(x_0,y_0)=f(t_0)$ A) prove that if $f'(t_0)\not=0$ then $u'(t_0)$ and $v'(t_0)$cannot both be zero. B) if $f'(t_0)\not=0$ show that either there is $C^1$ function $g$ such that $g(x_0)=t_0$ and $u(g(x))=x$ for $x$ near $x_0$ or there is $C^1$ function $h$ such that $h(y_0)=t_0$ and $u(g(y))=y$ for $y$ near $y_0$ I guess, I need to use Implicit Function thm. But I dont know how to use this therem to solve these two parts. I just have been starting to learn this theorem by myself. Please explicitly show me. Thank you :)","['calculus', 'self-learning', 'real-analysis', 'analysis', 'derivatives']"
452218,Negative binomial distribution - deriving of the p.m.f. combinatorially,"Let $X$ be the number of trials preceding the $k$th success in a sequence of independent Bernoulli trials each with probability of success $p$. Then $X$ has a negative binomial distribution with p.m.f. $p(x) = \binom{x+k-1}{k-1}p^{k}(1-p)^{x}$. Please explain this pmf using a combinatorial argument. I get why we need to choose $k-1$ successes, but the rest of the pmf is eluding me.","['combinations', 'probability-distributions', 'probability', 'combinatorics']"
452220,First order partial derivatives,"Suppose that $f:\Bbb R^2\to \Bbb R^2$ has $C^1$ partial derivatives in some ball $B_r(x_0,y_0)$ $r>0$. Prove that if $\Delta_f(x_0,y_0)\neq 0$, then $\displaystyle\frac{\partial f_1^{-1}}{\partial x}(f(x_0,y_0))= \displaystyle\frac{\partial f_2/\partial y(x_0,y_0)}{\Delta_f(x_0,y_0)}$ $\displaystyle\frac{\partial f_1^{-1}}{\partial y}(f(x_0,y_0))= \displaystyle\frac{\partial f_1/\partial y(x_0,y_0)}{\Delta_f(x_0,y_0)}$ $\displaystyle\frac{\partial f_2^{-1}}{\partial x}(f(x_0,y_0))= \displaystyle\frac{\partial f_2/\partial x(x_0,y_0)}{\Delta_f(x_0,y_0)}$ $\displaystyle\frac{\partial f_2^{-1}}{\partial xy}(f(x_0,y_0))= \displaystyle\frac{\partial f_1/\partial x(x_0,y_0)}{\Delta_f(x_0,y_0)}$ Please can someone show me only one equation? And then I Will beraber to solve second equation by myself. Thank you","['calculus', 'derivatives', 'real-analysis', 'analysis']"
452243,I don't understand this remark regarding Weierstrass' Theorem (Ahlfors' Complex Analysis),"In Ahlfors' text of Complex Analysis, chapter 5 theorem 1, he proves the following: Theorem I.    Suppose that $f_n(z)$ is analytic in the region $\Omega_n$, and that the sequence $\{f_n(z)\}$ converges to a limit function $f(z)$ in a region $\Omega$, uniformly on every compact subset of $\Omega$. Then $f(z)$ is analytic in $\Omega$. Moreover, $f_n'(z)$ converges uniformly to $f' (z)$ on every compact subset of $\Omega$. In the proof he examines a closed disk $|z-a| \leq r$ which is contained in $\Omega$. He claims that from the assumptions of the theorem the disk lies in all $\Omega_n$ for $n>n_0$ for some $n_0$.( I think this is clear, due to the uniform convergence on compact subsets.) Under this sentence there is a footnote which states: In fact, the regions $\Omega_n$. form an open covering of $|z - a| \leq r$. The disk is compact and hence has a finite subcovering. This means that it is contained in a fixed $\Omega_{n_0}$. I don't see the need for this footnote: above we already saw that the disk lies in each of the domains $\Omega_{n_0+1},\Omega_{n_0+2}, \dots$, so clearly it lies within some domain of the $\Omega_n$'s. What am I doing wrong here? Thanks. EDIT: actually, I can't see how it that remark correct. Even if there is a finite subcovering of the disk $\{\Omega_{n_k} \}_{k=1}^N$, why should it lie in a single disk $\Omega_{n_0}$?","['sequences-and-series', 'compactness', 'complex-analysis', 'uniform-convergence']"
452246,Trying to prove that cardinality of power sets are equal,"So if we have two sets $X$ and $Y$, we know that if $|X| = |Y|$, then $|P(X)| = |P(Y)|$.  This means that there is a bijection $f: X → Y$. What would a function be that maps elements of $P(X)$ to elements of $P(Y)$? I can try to use the existing function $f$ to prove this new function.","['logic', 'elementary-set-theory']"
452269,Integral in Polar Co-ordinates: Can you help evaluate it?,I have $$\int_{0}^{r_{0}}\int_{a}^{b}r_{1}e^{-\beta(r_{1}^{2}+r_{2}^{2}-2r_{1}r_{2}\cos(\theta))}d\theta dr_{1}$$ Can anyone help me break it down for general $a$ and $b$? Alex,"['multivariable-calculus', 'integration']"
452292,Limit of Lebesgue measure of interesection of a set $E$ with its translation,"Let $E$ be a Lebesgue measurable set in $\mathbb{R}$. Prove that
$$\lim_{x\rightarrow 0} m(E\cap (E+x))=m(E).$$",['measure-theory']
452297,Closure of a certain subset in a compact topological group,"Suppose that $G$ is a compact Hausdorff topological group and that $g\in G$. Consider the set $A=\{g^n : n=0,1,2,\ldots\}$ and let $\bar{A}$ denote the closure of $A$ in $G$. Is it true that $\mathbf{\bar{A}}$ is a subgroup of $\mathbf{G}$? From continuity of multiplication and the fact that $A\cdot A\subseteq A$ it is clear that $\bar{A}\cdot\bar{A}\subseteq\bar{A}$. therefore, $a,b\in \bar{A}$ yields $a\cdot b\in \bar{A}$. However, I am having trouble showing that inverses of elements in $\bar{A}$ are also in $\bar{A}$.","['general-topology', 'topological-groups', 'group-theory']"
452301,First step in statistics: something-like-a-mode for a sequence where each value is different from another,"Sorry but I'm not a statics expert at all, but I'm following some on line course and it is fascinating me. I just found the existence of the mode: The mode is the value that appears most often in a set of data. (Wikipedia) What about a sequence where the values are different one from each other? Like l = [1, 1.2, 1.3, 0.9, 12, 5] I'd like to take out from this sequence a value that is not the average (that is 3.5) because it is not explicative enough so I thought to discretize (like [1, 1, 1, 1, 12, 5] ) them and then take the mode (that would be 1) but I'm sure that there is a better way.",['statistics']
452305,Validity of my proof about $A \preceq B$ if and only if $\#A \le \#B$,"I'd like to know if my proof of the next theorem is correct or maybe need some adjustments to be correct. Definition: Let $A,B$ be sets. We write $A\preceq B\iff$ there exists an injection $A\to B$. Theorem: Let $A, B$ be finite sets. Then, $A \preceq B$ if and only if $\#A \le \#B$. Proof: ($\Rightarrow$)
Let $\varphi(n)$ be the statement ""B is a set of size $\,n\,$ and $A \preceq B \rightarrow \#A \le n$."" $$S = \left\{\,n\in \omega:\varphi(n)\, \right\}.$$ For $n = 0\,$, B is the empty set, and the only injection is to itself. So, clearly $0 \in S.$ Assume $n \in S $ we need to show that $n^{+} \in S$. Suppose  $ \#B =n^{+}$ and $\,f: A \rightarrow B\,$ is an injective map. We choose an element $b\in B$. If $\,b \in f[A] $ therefore $ f(a) = b\,$ for a unique $a\in A$. Let $A^{*} = A-\left\{a \right\}$ and $\,B^{*} = B -\left\{b \right\}$. We define the function $g: A^{*} \rightarrow B^{*}$ to be the restriction of $f$ in $A^{*}$, i.e., $\,g = f\restriction_{A^{*}}$. Then, $g\,$ is a one-to-one function and by our inductive hypothesis $\#A^{*} \le \#B^{*}.$ But since $\#A^{*} = \#A-1\,$ and $\#B^{*} = n$. Then, $\#A-1 \le \ n \rightarrow \#A \le n^{+} .$ If $b \notin f[A]$. Let $B^{*} = B-\left\{b \right\}$. Where $f: A \rightarrow B^{*}$ is a one-to-one function, and by inductive hypothesis $\#A \le \#B^{*}.$ But since $\#B^{*} = \#B-1 = n$. Then, $\#A \le n^{+} $. Hence $n^{+} \in S$ which close the induction. ($\Leftarrow$) We need to show that $\#A \le \#B$ implies the existence of an injective map $f: A\rightarrow B$. For $\#B = 0\,$, that means $\#A = 0$. And clearly $f: \emptyset \rightarrow \emptyset $ is an injection. Suppose our claims holds for n, we need to show that also holds for $n^{+}$. For $\# B = n^{+}$, as $n^{+} \not = 0\,$ the set is nonempty, so  there exist an element $b \in B$. Let $B^{*} = B -\left\{b \right\}$, then we have that $\#B^{*} = n$. If $\#A \le \#B^{*}$ by our inductive hypothesis, there exist a injective map $g : A \rightarrow B^{*}$. Let $i_{ B^{*} \rightarrow B}$ be the inclusion map, i.e., $i_{ B^{*} \rightarrow B}: B^{*} \rightarrow B : j \mapsto j\,$, which is an injection. Therefore, the composition $\, i_{ B^{*} \rightarrow B} \circ g: A \rightarrow B\,$, is an injection as desired. If $\, \#A \not\le \#B^{*}$ but $ \#A \le \#B $, i.e., $ \#A = n^{+}$. We set $A^{*} = A-\left\{a \right\}$. Then $\#A^{*}\le \#B^{*}$ and by the inductive hypothesis there exist an injective map $h': A^{*} \rightarrow B^{*}$. We can define the function $h: A \rightarrow B$, by adding the ordered pair $ \langle a, b \rangle $ to the function $h'$. That is, $h: = h' \cup \left\{\,  \langle a, b \rangle  \, \right\}$ (as $ \langle a, b \rangle $ is a genuine extra element, the map $h$ is one-to-one).  $\;\;\ \Box$ As always thanks in advance.",['elementary-set-theory']
452313,Identity makes every matrix invertible?,"I have found this in a proof and do not understand where this comes from: If A is singular, then there exists $\delta \in \mathbb{R}_{>0} \forall \epsilon\in (0,\delta): \epsilon \operatorname{Id}+A $ is nonsingular. It sounds similar to some corollary from the definition of continuous functions but I do not see how to proof this.","['matrices', 'linear-algebra', 'continuity', 'real-analysis', 'analysis']"
452320,Is matrix diagonalization unique?,"From the following statement, it seems matrix diagonalization is just eigen decomposition. Diagonalizing a matrix is also equivalent to finding the matrix's eigenvalues, which turn out to be precisely the entries of the diagonalized matrix. Similarly, the eigenvectors make up the new set of axes corresponding to the diagonal matrix. http://mathworld.wolfram.com/MatrixDiagonalization.html However, from what I have learned, Spectral Theorem is closest to this conclusion. But how the spectral theorem is related to it, or is there some other theorem grants this statement? Spectral Theorem: Suppose that $V$ is a complex inner-product space and $T \in L(V)$. Then $V$ has an orthonormal basis consisting of eigenvectors of $T$ if and only if $T$ is normal.",['linear-algebra']
452336,Examples of a commutative ring without an identity in which a maximal ideal is not a prime ideal,"In a commutative ring with an identity, every maximal ideal is a prime ideal.
However, if a commutative ring does not have an identity, I'm not sure this is true.
I would like to know the counterexamples, if any.
The more examples, the better. EDIT I would like to know the counterexamples other than $2\mathbb{Z}$.
The more examples, the better. EDIT I also would like to know the counterexamples that are not given in the Arturo Magidin's answer if any, namely an example of a non-prime maximal ideal which does not contain $R^2$.","['commutative-algebra', 'ring-theory', 'rngs', 'abstract-algebra']"
452337,Suppose $H \le G$ and $g^2\in H$ for all $g\in G$. Show $H$ is a normal subgroup of $G$ [duplicate],"This question already has answers here : Let $H$ be a subgroup of a group $G$ such that $x^2 \in H$ , $\forall x\in G$ . Prove that $H$ is a normal subgroup of $G$ (2 answers) Closed 10 years ago . Let $G$ be a group and $H$ a subgroup of $G$. Suppose $g^2\in H$ for all $g\in G$. Show $H$ is a normal subgroup of $G$. I tried lots of methods, but failed. Any suggestion? Thanks.","['group-theory', 'abstract-algebra']"
452346,Solving for $x$: $3^x + 3^{x+2} = 5^{2x-1}$,"$3^x + 3^{x+2} = 5^{2x-1}$ Pretty lost on this one. I tried to take the natural log of both sides but did not get the result that I desire. I have the answer but I would like to be pointed in the right direction. Appreciated if you can give me some hints to this question, thanks!","['logarithms', 'algebra-precalculus']"
452361,Symmetric polynomials,"I've got a seemingly simple question that I've become curious about as a result of supervising some undergraduate research.  Let's suppose we have some sequence of polynomials $f_0, f_1, f_2, \cdots \in \mathbb{Z}[X]$, where $f_0=1$.  Now, define the following sequence of symmetric polynomials on variables $x_1, \ldots x_n$: $$P_m(x_1, \ldots, x_n)=\sum\limits_{m_1+\cdots+m_n=m}f_{m_1}(x_1) \cdots f_{m_n}(x_n)$$ If you want, you can think of this as the coefficient of $y^m$ in the two-variable generating function $\prod\limits_{i=1}^{n}\left(\sum\limits_{j \ge 0}f_j(x_i)y^j\right)$.  Now my question is, if you know $x_1, \ldots, x_n$ are positive integers, and you know the values of $P_m(x_1, \ldots, x_n)$ for $m=0, 1, \ldots$, what conditions need to be true on $f_1, f_2, \ldots$ in order for the values of of $x_1, \ldots, x_n$ to be completely determined (up to ordering)?  I think it's key that we need to work with inputs in $\mathbb{Z}^+$ - if we work over $\mathbb{C}$, the answer may be different (see the edit below). For example, if $f_1(x)=x$, and $f_2=f_3=\cdots=0$, then $P_m$ is just the $m$-th elementary symmetric polynomial $\sigma_m$, and then obviously, $x_1, \ldots, x_n$ are determined by $\sigma_1, \sigma_2, \ldots$, being the roots of the polynomial with coefficients $(-1)^i\sigma_i$.  If $f_i(x)=x^i$ for each $i$, then it's a little less straightforward, but still not hard: $P_m=\sum\limits_{j=1}^{m}(-1)^{j-1}\sigma_j P_{m-j}$, and so we can show by induction on $m$ that $P_1, \ldots, P_m$ together determine $\sigma_1, \ldots, \sigma_m$, and hence, $x_1, \ldots, x_n$ are again determined.  For the general case, we can equivalently ask whether the values of $P_1, P_2, \ldots$ uniquely determine the values of $\sigma_1, \sigma_2, \ldots$ (and this is perhaps a more natural question). As long as the polynomials $f_1$ aren't all constants, I don't, off the top of my head, know any sequences of polynomials $f_1, f_2, \ldots$ for which the values of $P_1, P_2, \ldots$ don't determine $x_1, \ldots, x_n$.  So I'm wondering if it's true given that at least one of the $f_i$'s is nontrivial. EDIT: I feel it's worth pointing out that what I'm asking isn't the same thing as asking that the $P_i$ generate the ring of symmetric polynomials.  For example, if the values of the $P_i$ were to determine the values of $\sigma_1^2, \sigma_2^2, \ldots$, that would determine the values of $\sigma_1, \sigma_2, \ldots$, even if the $P_i$ don't generate the ring.  This is why the condition that the $x_i$'s are positive integers is important.  That said, I don't know the answer over $\mathbb{C}$ either.","['symmetric-polynomials', 'combinatorics']"
452373,Automorphisms of a structure as a powerful tool for studying the structure,"This is just an arbitrary testimony of an often repeated slogan: ""The group of automorphisms of a given structure is often a powerful
  tool for studying this structure."" D. Lascar, On the Category of
  Models of a Complete Theory I wonder why this should be so when thinking of the fact that (for example) almost all graphs have a trivial automorphism group. And only very few - if any - graphs have an automorphism group that allows literally to tell the graph from it. How then is this slogan to be understood? For which kinds of structures does it make sense, resp. in which sense? Side question : Is it true, that when the automorphism group of a graph is isomorphic to the full symmetric group $S_n$, then the graph has to be the complete graph $K_n$ or its complement?","['geometry', 'symmetry', 'graph-theory', 'symmetric-groups']"
452388,Intuition on Wald's equation without using the optional stopping theorem.,"The Wald's equation even at its simplest form as stated below simplifies many problems of calculating expectation. Wald's Equation: Let $(X_n)_{n\in\mathbb{N}}$ be a sequence of real-valued, independent and identically distributed random  variables and let $N$ be a nonnegative integer-value random variable that is independent of 
   the sequence $(X_n)_{n\in\mathbb{N}}$. Suppose that $N$ and the $X_n$ have finite expectations. Then
  $$
\operatorname{E}[X_1+\dots+X_N]=\operatorname{E}[N] \cdot\operatorname{E}[X_n]\quad \forall n\in\mathbb{N}\,. 
$$ I am looking for an intuitive explanation of Wald's equation without using the optional stopping theorem.
I'm not interested in explanations for the error 
$
\operatorname{E}[X_1+\dots+X_N]=N\cdot \operatorname{E}[X_1] 
$
or explanations to discuss only the hypotheses. We could have, for exemple, a function $\varphi$ of two or more variables such that $\operatorname{E}[X_1+\dots+X_N]=\varphi\big(\operatorname{E}[N]\, ,\,\operatorname{E}[X_n]\big), \quad\forall n\in\mathbb{N}\,$.
The question then becomes for what reason $\varphi(x,y)$ equals $x\cdot y$? More generally we could have  two linear functional $F : L^1(\Omega,\mathcal{A},P)\to \mathbb{R}$ and $G : L^1(\Omega,\mathcal{A},P)\to \mathbb{R}$ such that $\operatorname{E}[X_1+\dots+X_N]=\varphi\big(\operatorname{F}[N]\, ,\,\operatorname{G}[X_n]\big), \quad\forall n\in\mathbb{N}\,.$ So the question would be for what reason $\operatorname{F}=\operatorname{G}=\operatorname{E}$ and $\varphi(x,y)$ equals $x\cdot y$? The interest is on the intuition of the equation. An answer based on a good example will be very welcome. Thanks in advance.","['probability-theory', 'intuition']"
452412,Showing that the zero vector has norm zero,"I need to show that this is a property of a norm.  I know this is supposed to be straightforward but I am somehow not seeing it. The property is 
$$\lVert 0\rVert = 0$$ I was trying to use the fact that for norms $$ \lVert\lambda \cdot x\rVert = |\lambda|\cdot  \lVert  x\rVert $$ but it seems to be lacking any real reasoning. EDIT I am using the following for the definition of a norm: 1) $||x|| > 0$ if $x\neq 0$ 2) $||\lambda x|| = |\lambda|||x||$ for $\lambda \in \mathbb{R}$ 3) $||x+y|| \leq ||x|| + ||y||$ Let me know if you need any more information!","['vector-spaces', 'normed-spaces', 'linear-algebra']"
452418,On the automorphisms of the Klein Quartic,"I am trying to solve a problem from Miranda's book, Algebraic Curves and Riemann Surfaces.  On page 84, problem K gives the Klein curve $X$ as a smooth projective plane curve defined by the equation $xy^3+yz^3+zx^3=0$.  The problem asks us to show that this Riemann surface, of genus g=3, realizes the Hurwitz bound by finding 168 automorphisms of $X$. I have found an automorphism subgroup of order 3 (cyclically permuting the variables), and one of order 7 (multiplying the coordinates by appropriate 7th roots of unity), but I just can't figure out how to get a subgroup of order 8, or 4, or 2.  Could somebody please give me a hint. I've spent the last little while reading up on this subject, and most of the discussions involve using a heptagonal tiling etc.. Given where this problem is placed in the book, I can't appeal to that kind of reasoning, so I'm asking for a way to find these automorphisms directly from the defining equation of $X$. Any help or hint would be appreciated.  Even an involution :)","['geometry', 'algebraic-curves', 'riemann-surfaces', 'finite-groups', 'invariant-theory']"
452484,Distance between the product of marginal distributions and the joint distribution,"Given a joint distribution $P(A,B,C)$, we can compute various marginal distributions. Now suppose:
\begin{align}
P1(A,B,C) &= P(A) P(B) P(C)  \\
P2(A,B,C) &= P(A,B) P(C)  \\
P3(A,B,C) &= P(A,B,C)
\end{align}
Is it true that $d(P1,P3) \geq d(P2,P3)$ where d is the total variation distance? In other words, is it provable that $P(A,B) P(C)$ is a better approximation of $P(A,B,C)$ than $P(A) P(B) P(C)$ in terms of the total variation distance? Intuitively I think it's true but could not find out a proof.","['statistics', 'probability-distributions', 'inequality', 'probability']"
452500,Mean Value Theorem for Several Variables,"Please see the mean value theorem stated here: MVT . Note that the MVT stated there requires that the segment connecting $x$ and $y$ lies in $G$. So clearly, MVT works for any pair of points if $G$ is made a convex open set. Here are my questions: What happens if $G$ is not convex, but connected? Looking at the proof of MVT, I think the MVT will still work as long as there is a path (a continuous map) from $x$ to $y$. And this is the case in a connected set. Am I right in thinking this? Suppose the answer to (1) is yes. (Of course, if I am wrong in (1), please ignore this question.)Assume that $G$ is open and connected and let $x,y \in G$. Then there is some path (not necessarily a line segment) connecting $x$ and $y$ in $G$. MVT guarantees that there is a $z$ on this path such that 
$$f(x) - f(y) = \nabla f(z) \cdot (x - y).$$
Can we say something about the distance between $z$ and the points $x$,$y$? If the path is a line segment, then certainly,
$$|x-z|\leq |x-y| \quad \text{and} \quad |y-z| \leq |x-y|.$$
If the path is not a line segment, what happens?","['connectedness', 'multivariable-calculus', 'calculus']"
452504,"When is There a Solution to ""Pullback Equation"" of Differential Forms","All: Let $f: M \to N$ be a smooth map between manifolds, and let $w$ be a $1$-form on $M$. Under what conditions is there a $1$-form $z$ defined on $N$ so that  $w=f^*z$, i.e., so that $w$ is the pullback of the form $z$ by the 
map $f$? All I can think of is considering the respective cohomologies
of $M$, $N$, so that, e.g., if $H^1(N)=0$, then this would not be possible,
or maybe we can use the (contravariant)  map induced  by $f$ in cohomology,
but I cannot think of more general conditions. Thanks for any suggestions.",['differential-geometry']
452505,Zassenhaus Lemma,"In (almost) all books of Algebra/ Group Theory, the Zassenhaus Lemma is used only to prove Schreier Refinement Theorem (or to prove Jordan-Holder Theorem ). What are other applications of Zassenhaus Lemma in group theory?",['group-theory']
452507,"On the proof of deformation lemma ""boundedness""","Book- Evans partial differential equation. In the proof of deformation lemma how to say that  $V(u)=-g(u)h(\lVert I'(u)\rVert)I'(u)$ is bounded. And how to say that the mapping $u \to \operatorname{dist}(u,A)+\operatorname{dist}(u,B)$ is bounded.","['general-topology', 'partial-differential-equations']"
452524,An inequality involving multi-index,"I came across these inequalities while learning about Schwartz functions (Classical Fourier Analysis, Grafakos) and I have no idea how to prove this: For $x \in \mathbb{R}^{n}$ and $\alpha = (\alpha_{1}, \ldots, \alpha_{n}) \in \mathbb{N}^{n}$, we set $$ x^{\alpha} = x_{1}^{\alpha_{1}}\cdots x_{n}^{\alpha_{n}}.$$ Then prove that there exists a constant $c_{n,\alpha}$ such that $$\left| x^{\alpha}\right| \leq c_{n,\alpha}|x|^{|\alpha|}$$ where $|\alpha| = \alpha_{1} + \cdots + \alpha_{n}$. Conversely, for every $k \in \mathbb{N}$, there exists a $C_{n,k}$ such that $$|x|^{k} \leq C_{n,k}\sum\limits_{|\beta| = k}|x^{\beta}|$$ Any help would be appreciated.","['multivariable-calculus', 'inequality', 'real-analysis']"
452531,Finding $\lim_{x \to \infty} x^{1/x}$ [duplicate],"This question already has answers here : How to show that $\lim_{n \to +\infty} n^{\frac{1}{n}} = 1$? (13 answers) Closed 10 years ago . I set $\lim_{x \to \infty} x^{1/x}=L$  What I tried is this: $$\lim_{x \to \infty} \frac 1x \ln x=\ln L$$ $$\lim_{x \to \infty} \ln e^{\large \ln \frac 1x} \ln x=\ln L$$ We substitute in $e=\lim_{x \to \infty} (1+\frac 1x)^x$ $$\lim_{x \to \infty} \ln (1+\frac 1x) \ln x=\ln L$$ $$L= \lim_{x \to \infty} (1+\frac 1x)^{\ln x}$$ This looks a lot like the definition of $e$ and from here I think I could make an argument that $L=1$ because $\ln x$ increases slower than $ax$ for any $a$ after a certain point, but I would like to have a proof that is more direct. How should I proceed from here? Thanks. P.S. No L'hopital's rule please","['calculus', 'algebra-precalculus', 'limits']"
452550,What is this ambiguous computational existence in the positive integers?,"I'm reading From Sets and Types to Topology and Analysis: Towards Practicable Foundations for Constructive Mathematics. The authors mention Bishop’s Foundations of Constructive Analysis : The successful formalization of mathematics helped keep mathematics on a wrong course. The
  fact that space has been arithmetized loses much of its signiﬁcance if space, number, and everything else are ﬁtted into a matrix of idealism where even the positive integers have an ambiguous computational existence. What is this ambiguous computational existence in the positive integers?","['logic', 'foundations', 'analysis']"
452560,How to construct a cube,"My friend has asked me this question. I have no idea how to answer, but I think the question is  interesting enough to be noted here: Consider 3 pieces of wire (not necessary of equal length). Is it possible to construct a cube from them by only bending or pasting them ?? (no cutting is allowed)","['geometry', 'education']"
452563,the definition of autocorrelation,"I find the definition of autocorrelation from wiki:
$$
R(s,t)=\frac{E\left[ \left( {{X}_{t}}-{{\mu }_{t}} \right)\left( {{X}_{s}}-{{\mu }_{s}} \right) \right]}{{{\sigma }_{t}}{{\sigma }_{s}}}
$$
But I also find the definition of autocorrelation as below somewhere:
$$
R(s,t)=E\left[ X(s)X(t) \right]
$$ Are these two definitions equal? Can anyone provide the proof?",['probability-theory']
452596,Is a Bijection From a Group to Itself Automatically an Isomorphism If It Maps the Identity to Itself?,"I am looking at $\operatorname{Aut}(V)$, where $V$ is the Klein 4-group. I noticed that $\operatorname{Aut}(V)$ is comprised of all the permutations of the elements of $V$ where $1$ is mapped to itself. Although it is clear that any such permutation must be a bijection, I am struggling to see how this guarantees that the structure of the group is preserved. It is even enough to verify by hand for $V$, but I cannot seem to prove the claim in general. Thanks!","['group-theory', 'functions']"
452627,"How to prove that $f$ is $1-1$ from $E$ on $\{ (s,t) : s> 2\sqrt{t} >0\}$","Question: Let $E=\{(x,y): 0<y<x \}$ set $f(x,y)=(x+y, xy)$ for $(x,y)\in E$ a) How to prove that $f$ is $1-1$ from $E$ on $\{ (s,t) : s> 2\sqrt{t} >0\}$ And how to find formula for $f^{-1}(s,t)$ b) compute $Df^{-1}(f(x,y))$ for $(x,y)\in E$ by using inverse function theorem. answer for part b) I firstly compute $D(f(x,y))$ $$D(f(x,y))=\begin{pmatrix} 1 && 1 \\ y && x\end{pmatrix} $$ Then $$Df^{-1}=\begin {pmatrix} \frac{-x}{y-x} && \frac{1}{y-x} \\ \frac{y}{y-x} && \frac{-1}{y-x}\end{pmatrix}$$ I did part-b. Hopefully it is true. Please check my answer. Also I could not do part-a. Please help me to solve this. Thank you.","['calculus', 'inverse', 'real-analysis', 'analysis', 'derivatives']"
452631,"If $\sin\theta+\sin\phi=a$ and $\cos\theta+ \cos\phi=b$, then find $\tan \frac{\theta-\phi}2$.","I'm trying to solve this problem: If $\sin\theta+\sin\phi=a$ and $\cos\theta+ \cos\phi=b$, then find $\tan \dfrac{\theta-\phi}2$. So seeing $\dfrac{\theta-\phi}2$ in the argument of the tangent function, I first thought of converting the left-hand sides of the givens to products which gave me:
$$2\sin\frac{\theta+\phi}2\cos\frac{\theta-\phi}2=a\quad,\quad2\cos\frac{\theta+\phi}2\cos\frac{\theta-\phi}2=b$$ But then, on dividing the two equations (assuming $b\ne0$), I just get the value of $\tan\dfrac{\theta+\phi}2$. I don't know how else to proceed.
Any help would be appreciated!",['trigonometry']
452635,Which of these numbers is greater: $\sqrt[5]{5}$ or $\sqrt[4]{4}$?,I know that this is the question of elementary mathematics but how to logically check which of these numbers is greater: $\sqrt[5]{5}$ or $\sqrt[4]{4}$? It seems to me that since number $5$ is greater than $4$ and we denote $\sqrt[5]{5}$ as $x$ and $\sqrt[4]{4}$ as $y$ then $x^5 > y^4$.,"['inequality', 'algebra-precalculus', 'number-comparison']"
452637,"$(n+1)x_{n+2}-nx_{n+1}-x_n=0$ ,prove the sequence converges","Sequence $x_n$ for which $$(n+1)x_{n+2}= nx_{n+1}+x_n$$ for every $n\in\mathbb{N}$. Prove that it converges. Its not decreasing or increasing, i checked with some random initial values.So, i dont know how to proceed with this. Any help?",['sequences-and-series']
452653,domain of initial $f : X \rightarrow Y$ in Haus equipped with coarsest topology?,"If $f:X\rightarrow Y$ is initial in category Top then
it is easy to proof that (!) the topology on $X$ is the set of preimages of open sets in $Y$. Just construct topology $Z$ having
the same underlying subset as $X$ and let the set of these preimages
serve as topology on it. Then from $g:Z\rightarrow X$ with $x\mapsto x$
it is clear that $fg$ is continuous so the conclusion that $g$ is
continuous can be made. Then we are ready. 
But now my question: what if we do not work in $\textbf{Top}$ but in category $\textbf{Haus}$? The constructed topology $Z$ does not have to be a Hausdorff space (or am I overlooking something here?) and if the fact that $f$ is initial in $\textbf{Haus}$ would work then it would justify the conclusion that $g$ can be recognized as an arrow in $\textbf{Haus}$. Is there a way out? Or - even stronger - is statement (!) not true in $\textbf{Haus}$?","['general-topology', 'category-theory']"
452655,Prove that the distance between a black and a white dot is one,"I just read this article about some tough interview questions . One of the questions (allegedly given in an interview for a Technology Analyst position in Goldman Sachs) was: There are infinite black and white dots on a plane. Prove that the
  distance between one black dot and one white dot is one unit. I'm not sure how I should interpret this. Is something missing from the question, or can it be proven?","['geometry', 'infinity']"
452681,Simple explanation of lagrange multipliers with multiple constraints,"I'm studying support vector machines and in the process I've bumped into lagrange multipliers with multiple constraints and Karush–Kuhn–Tucker conditions. I've been trying to study the subject, but still can't get a good enough grasp on the subject. In wikipedia: ( http://en.wikipedia.org/wiki/Lagrange_multiplier#Multiple_constraints ) it says that in order to find the extremum points of a function $f$, (with constraints $g_1, ..., g_m$), we must find a point $\text{x}$ such that $$\sum_{i=1}^{m}\lambda_{i}\nabla g_i(\text{x}) = \nabla f(\text{x})$$ I understand lagrange multipliers when there is only one constraint, but this is hard to grasp for some reason... :( Could anyone give me easy-to-understand explanation, why the equation above is true? Thank you for any guidance :) P.S. If it is not a big job to do, I'd be very grateful If someone could also explain the Karush–Kuhn–Tucker conditions which generalize my question :) That would be super!","['karush-kuhn-tucker', 'multivariable-calculus', 'calculus', 'lagrange-multiplier']"
452692,Proof that the symmetric difference is associative [duplicate],"This question already has answers here : Associativity of symmetric difference of sets (5 answers) Closed 10 years ago . I know that the symmetric difference looks like that when having three sets A,B,C : I want to make a prove with Venn diagrams to prove the associativity of the symmetric difference. What are some good ways to create this proof in a clear way? I really appreciate your answer!",['elementary-set-theory']
452695,function with minumum in geometric mean,"I have two real constants (in my case 3 and 15). I need a function that has minimum in the geometric mean and rises to infinity as I come closer to the end points. It only needs be defined on (3, 15). In other words: I want a fitness function that will prefer the geometric mean and will symetrically (well kinda symetrically) penalize values differing from that point.","['optimization', 'continuity', 'functions']"
452696,Schanuel conjecture and its set theoretic status,"I have once been told that Schanuel's conjecture (which is a transcendence statement about tuples of complex numbers and their exponentials) is set theoretically absolute, which means that its truth (or falsity) is independent of the set theoretical model (or assumptions), because it is a $\Pi^1_2$ statement. Is this correct?","['set-theory', 'number-theory']"
452700,Prove that a proper subset $E$ of $\Bbb R^n$ is connected $\iff$ it contains exactly two relatively clopen sets.,"Prove that a proper subset $E$ of $\Bbb R^n$ is connected $\iff$ it contains exactly two relatively clopen sets. I researched the meaning of ""clopen set"". And I reached the result that so as to for a set $A$ be clopen, the set $A$ need to be both closed and open. I cannot do this proof. Please help me to do this. Thank you","['calculus', 'general-topology', 'self-learning', 'real-analysis', 'analysis']"
452722,How can it be proved that the geometric mean function is concave?,"A function $f: \mathbb R^n \rightarrow \mathbb R$ is said to be concave if $$\left(\forall x,y \in \mathbb{R}^n \right) \left( \forall \lambda \in [0,1] \right) \left(\lambda f(x) + (1-\lambda)f(y) \le f(\lambda x + (1- \lambda)y)\right)$$ In the case of the geometric mean function (defined below), how would we prove concavity? $$f(x_1,\dots,x_n) := \left(\prod_{i=1}^n x_i \right)^\frac1n$$ I have been trying all day to find a proof, mostly by induction, but also considering the Hessian, which if always negative semidefinite implies concavity. Any tips, please?","['convex-analysis', 'multivariable-calculus', 'induction', 'means']"
452727,Tough Legendre Integral,"I am currently fighting with the following integral. I have simplified it to this one here:
$\int_{-1}^{\cos(\alpha)} P_l(t)P_{l'}(t) dt$, where $P_l$ is the l-th Legendre polynomial. unfortunately you cannot use orthogonality, so this is somewhat hard to do, but maybe somebody here has an idea.","['calculus', 'integration', 'real-analysis', 'analysis']"
452730,Change of variables in 3 dimensions,"Consider the following integral: $$\int_{|x| = \epsilon} \phi(x) \frac{e^{-m|x|}}{4 \pi |x|^2} d^3x.$$ I wanna show that this integral goes to $\phi(0)$ for $\epsilon \rightarrow 0$. The idea is to swap to spherical coordinates: $$\int_{|x| = \epsilon} \phi(x) \frac{e^{-m|x|}}{4 \pi |x|^2} d^3x = \frac{1}{4 \pi} \int_{S^2} \phi(x) \frac{e^{-m\epsilon}}{\epsilon^2} \epsilon^2 d\Omega = \frac{1}{4 \pi} \int_{S^2} \phi(x) {e^{-m\epsilon}} d\Omega $$ Now we wanna substitute $$y = x/|x|$$ $\frac{1}{4 \pi} \int_{S^2} \phi(x) {e^{-m\epsilon}} d\Omega = \frac{1}{4 \pi} \int_{S^2} \phi(\epsilon y) {e^{-m\epsilon}} d\Omega $ The last step is where I'm not sure what happens. Somehow the infinitesimal variable should change aswell, but I'm not quite sure how. Could somebody make that clear for me? Cheers!","['multivariable-calculus', 'calculus', 'integration']"
452737,Proving that $\sum (-1)^{n+1} n^{-z}$ defines an analytic function in $Re z>0$,"I want to show that the series $\sum_{n=1}^\infty (-1)^{n+1} n^{-z}$ converges to an analytic function for $\Re z>0$. For $\Re z>1$ the terms are dominated by $n^{-x}$ so that we have absolute and uniform convergence on compact sets, and by Weierstrass' theorem the sum is analytic there. For $\Re z \leq 1$ however I can't show absolute convergence. I tried splitting into real and imaginary parts:
$$\sum_{n=1}^\infty (-1)^{n+1} n^{-z}=\sum_{n=1}^\infty (-1)^{n+1} n^{-x}\cos(-y \ln n)+i\sum_{n=1}^\infty (-1)^{n+1} n^{-x}\sin(-y \ln n),$$
and showing convergence for both using Leibniz's test (or even the more general Dirichlet's test) without success. I'd love to have any hints about how to do this right.","['convergence-divergence', 'sequences-and-series', 'riemann-zeta', 'complex-analysis']"
452741,Find the sum of series $\sum_{n=0}^\infty\frac{(4n)!}{(4n+4)!}$,I wanted to know how can I start to find the sum of the series: $$\sum_{n=0}^\infty\frac{(4n)!}{(4n+4)!}=\frac{1}{4!}+\frac{4!}{8!}+\frac{8!}{12!}\cdots$$ I am having no clue. Thanks.,"['factorial', 'summation', 'sequences-and-series']"
452742,Proof of the potential function representation of Complex lamellar vector field,"Given a continuously differentiable vector field $\bf a$, demonstrate the equivalence (iff) between the requirement that it satisfies ${\bf a}\cdot(\nabla \times {\bf a})=0$ and that it has the representation ${\bf a}=\lambda \nabla \phi$, where $\lambda, \phi$ are scalar functions. Stated in another way, why is ${\bf a}\cdot(\nabla \times {\bf a})=0$ a necessary and sufficent condition for vector fields to have normal congruences. Many reference cites Lord Kelvin as the source of this theorem, but his proof, though classical, is too magnetism-oriented to readily understand. Thanks!",['multivariable-calculus']
452753,Property for Norms of Matrices,"I am having trouble with the following problem: Show that the vector norm $||x||_1$ gives the subordinate matrix norm:
\begin{equation}
||A||_1 = \max_{1\leq j\leq n}\sum_{i=1}^n|a_{ij}|
\end{equation} I really do not have any starting point for this question. I though maybe we could use $||x||_1$ norm for the rows or columns of $A$ but I did not get anywhere with that. Note: \begin{equation}
||A|| = \sup{||Au||: u\in \mathbb{R}^n, ||u||=1}
\end{equation} All help is greatly appreciated! EDIT: This is what I have so far:
\begin{align}
||A||_1 =& \sup_{||u||_1=1}||Au|| \\
        =& \sup_{||u||_1=1}||\sum\limits_{i=1}^n|(Au)_i|\,||
\end{align} Here is where I am having trouble. The maximum value depends on the entries in $A$. It just seems to make sense that we would pick the largest values in each row. 1.How do I finish the proof from here?","['matrices', 'normed-spaces', 'linear-algebra', 'matrix-norms']"
452766,supremum of uncountable families of Borel measurable functions,"Show that the supremum of an uncountable family of $[-\infty, \infty]$- valued Borel measurable functions on $\mathbb{R}$ can fail to be Borel measurable. Does this mean that I need to find some kind of family such that the intersection of the 
sets $$\{x\in A | f_n(x) \leq t \}, $$ for all $t$, fails to be an Borel set?
Or is there some easier way?",['measure-theory']
452788,Valuations on a field and ramification,"For $K\subseteq L$, where $L$ is a finite number field extension of $K$, we consider $p\subset R_K$ and $p'\subset R_L$ where $p'$ lies over $p$, where $R_K$ is the ring of integers of $K$ and $R_L$ defined likewise. Then valuations on $K$ and $L$ are associated with the primes of the fields, so there is a valuation associated with $p$ and $p'$. My question is how would the way $p$ behave in $L$ (i.e. whether it is inert, split or ramified) affect the relation between $v_{p}(x)$ in $K$ and $v_{p'}(x)$ in $L$? For example, if $L$ is a quadratic extension of $K$, I think that if: $p$ is inert in $L$, then $v_p(x)=v_{p'}(x)$ (Note that this means $v_{p}(x)$ in $K$ is equal to $v_{p'}(x)$ in $L$). $p$ splits in $L$, so that $pR_L=p'p''$, then $v_p(x)=v_{p'}(x)+v_{p''}(x)$. $p$ ramifies in $L$, so that $pR_L=p'p'$, then $v_p(x)=2v_{p'}(x)$. I'm would like to know how this is generalised to general finite extensions $L$ of $K$ using inertia degree and a proof or a reference to something containing a proof would be much appreciated. Thank you!","['valuation-theory', 'extension-field', 'algebraic-number-theory', 'abstract-algebra']"
452789,Prove that every closed ball in $\Bbb R^n$ is sequentially compact.,"Question: Prove that every closed ball in $\Bbb R^n$ is sequentially compact. A subset $E$ of $\Bbb R^n$ is said to be squentially compact $\iff$ every sequence $x_k\in E$ has convergent subsequence whose limit belongs to $E$ Solution: Let $B_R(a)$ be closed ball. Let $x_k$ be a sequence in $B_R(a)$ Then, $$\vert\vert x_k-a\vert\vert \le M$$ for $M>0$ By the triangle inequality, $$\vert\vert x_k-a\vert\vert \le \vert \vert x_k\vert \vert +\vert\vert a\vert \le M \ \  \Rightarrow \vert\vert x_k\vert\vert \le \vert\vert a\vert\vert +M $$ So the sequence $x_k$ is bounded. By Bolzano W. Theorem, $x_k$ has convergent subsequences. Now I need to show that these convergent subsequences have a limit point in $B_R(a)$. But how? Please explain this part. Thank you:)","['general-topology', 'sequences-and-series', 'calculus', 'real-analysis']"
452795,Quantifiers as Adjoints in Generalized Logics,"It is a well known fact that the classical universal and existential quantifiers can be seen as adjoints in certain categories. In the continuous model theory of metric structures (see http://ptmat.fc.ul.pt/~alexus/papers/mtfms.pdf ) and more generally, the continuous model theory developed by Chang and Keisler ( http://books.google.co.uk/books/about/Continuous_Model_Theory.html?id=uTGdPSI5rI4C&redir_esc=y ), sets of truth values are (roughly) ordered, compact, Hausdorff spaces with two distinguished elements (0 and 1) that act like true and false. In this setting, the analogues of $\forall$ and $\exists$ are $\sup$ and $\inf$. I have a two part question: 1) In the continuous model theory setting, how does one describe quantifiers in a similar categorical way? 2) Is there a natural analogue of quantification in the setting of truth values in a non-ordered, compact, (and Hausdorff if you really want it) topological space. I appreciate that if there is, it might be quite strange since I'm not requiring there be a ''true'' and ''false''","['general-topology', 'logic', 'category-theory', 'model-theory']"
452835,Function zero almost everywhere if $\int fg=0$,"Assume $f$ is an integrable function on $\mathbb{R^n}$.  Assume for every bounded continuous function g on $\mathbb{R^n}$, $\int_\mathbb{R^n}fg=0$.  Prove $f$ must equal $0$ almost everywhere. I am really not sure how to do this problem.  I have tried simple stuff but that is not currently working.","['lebesgue-integral', 'integration', 'real-analysis', 'analysis']"
452841,Show the sequence $(1 - \frac{1}{n})^{-n}$ is decreasing.,"How do you show the sequence $(1 - \frac{1}{n})^{-n}$ is decreasing? I understand that the binomial theorem should be used here but I don't see how we can use it to prove that $a_{n+1} < a_n$. I will rewrite the sequence as,
\begin{align*}
(1 - \frac{1}{n})^{-n} &= (\frac{n-1}{n})^{-n} \\
&= (\frac{n}{n-1})^n \\
&= (1 + \frac{1}{n-1})^n
\end{align*} Then I can apply binomial theorem to it. This is as far as I got now.",['sequences-and-series']
452867,On computing a conditional expectation for countable-co-countable sigma-algebras,"Let $S=[0,1]$  equipped with its Borel $\sigma$-algebra ${\cal B}. $ 
Assign on it a purely atomic probability measure, $P $.
Let ${\cal A} $ be the sub-$\sigma$-algebra generated by the countable and co-countable sets.
Now, take $B=[0, 1/2]. $
What is $E_{P}[I_B \mid {\cal A}] $ ? 
Since there is a countable set $A =\{x\in S: P({x}) > 0\} $ and ${\cal A} $ contains all singletons, I am tempted to say that   $E_{P}(I_B \mid {\cal A})(x) =I_B(x) $ for all $x \in A. $ However, I do not seem to be able to make this argument rigorous.
Any help would be appreciated.","['probability-theory', 'measure-theory', 'conditional-probability']"
452897,"Does this inner product on $L^1([0,1])$ have a name?","Math people: For $f, g \in L^1([0,1])$, define $$\langle f,g \rangle = \int_0^1 \int_0^1 f(t)g(t')\exp(-|t-t'|)dt'\,dt.$$ Although we don't normally think of $L^1([0,1])$ as an inner product space, this is an inner product on $L^1([0,1])$.  The only requirement that is not trivial to verify is positive-definiteness: $\langle f, f \rangle > 0$ for $f \neq 0$. This requires a straightforward argument that leads to integration by parts. My question is, has this been done before?  Does this have a name?  You can use an interval other than $[0,1]$ and use a sum of several positively weighted exponential functions if you want, but I wanted to give the simplest possible example.","['reference-request', 'inner-products', 'functional-analysis', 'integration']"
452908,Is every operator unitary equivalent to a banded operator?,"Let $H$ be an infinite dimensional separable Hilbert space and $B(H)$ the algebra of bounded operators. Definition : Let $(e_{n})_{n \in \mathbb{N}}$ be an orthonormal basis. $T \in B(H)$ is banded if $\exists r \in \mathbb{N}$ such that $
(Te_{n}, e_{m})\ne 0 \Rightarrow \vert n-m \vert \leq r$. Is every operator unitary equivalent to a banded operator ? Remark : A banded operator is a thick generalization of a diagonal operator. It's also a finite sum of finite product of weight shift operators.","['operator-theory', 'reference-request', 'functional-analysis']"
452927,What is the number of real solutions of the following? $ \sqrt{x + 3 - 4\sqrt{x-1}} + \sqrt{x + 8 - 6\sqrt{x-1}} = 1 $,"What is the number of real solutions of the following? 
$$ \sqrt{x + 3 - 4\sqrt{x-1}} + \sqrt{x + 8 - 6\sqrt{x-1}} = 1 $$ My solution:
$$ \sqrt{x + 3 - 4\sqrt{x-1}} + \sqrt{x + 8 - 6\sqrt{x-1}} = 1 $$
$$ \implies \sqrt{(\sqrt{x-1}-2)^2} + \sqrt{(\sqrt{x-1}-3)^2} = 1 $$
$$ \implies (\sqrt{x-1}-2) + (\sqrt{x-1}-3) = 1 $$
$$ \implies \sqrt{x-1} = 3$$ So, $ x = 10$ is the only solution. But the answer key (and Wolfram alpha too) says there are infinite number of solutions to this equation. Where I am going wrong?",['algebra-precalculus']
452963,"Show that if $f$ is integrable on $[a,b]$, then $|f|$ is also integrable.","The problem suggests doing it by showing that $U(P,|f|) - L(P,|f|) \le U(P,f)-L(P,f)$ for some partition $P$ .  I can get the other steps after that, but I've tried proving this inequality on my own and multiple tutors at my university couldn't figure it out using the material in my book.  Every time I've attempted it on my own, I've gotten the arrow in the opposite direction.  Doesn't $\displaystyle\sup_{i \in [x_{i-1},x_i]} |f(x)| \ge \displaystyle\sup_{i \in [x_{i-1},x_i]} f(x)$ hold? Note that my class is using a pretty simplified Analysis (question 5.5.2a) book that doesn't cover metric spaces or Lebesgue integrals.  Everything is Riemann and we show a function is Riemann integrable if and only if its upper and lower Darboux integrals are equal.","['riemann-integration', 'absolute-value', 'integration', 'real-analysis']"
452972,A fair 6 sided dice is rolled 4 times. What is the probability that at least 3 of the numbers will be either 1 or 6?,I'd really love a sanity check here as I walk through what I believe is the solution. Total possible outcomes = $6^4 = 1296$ Possible combinations of 3 rolls being either 1 or 6 = $({}_4C_3)\cdot2 = (4)\cdot2 = 8$ Also take into account all 1's and all 6's = $1 + 1 = 2$ Answer = $\frac{8+2}{ 1296} = \frac{10}{1296} = \mathbf{\frac{5}{648}} $ Really appreciate the help! :),"['probability', 'combinatorics']"
452980,The Effect of Perspective on Probability,"My friend and I are tearing each other to bits over this, hope someone can help. Coin flip experiment: Define a single trial as 10 coin flips of a fair coin. Perform an arbitrarily large number of trials. At some number of trials n, you notice that your distribution is extremely skewed in one direction (i.e., the ""average"" of your 10-flip sets is far away from 5 heads and 5 tails). My reaction: Because you are guaranteed to hit a 5H/5T mean as n approaches infinity, the probability that the next n trials contains an equal skew in the opposite direction increases. In other words, given 2*n* trials, if the first n are skewed in one direction, than the remaining n are probably skewed in the other direction such that the overall distribution of your 2*n* trials is normal and centered around 5H/5T. My friend's reaction: It doesn't matter if your first n trials is skewed, the next n trials should still represent an unmodified 5H/5T distribution regardless. The probability of the next n trials being skewed in the opposite direction is unchanged and low. Who's right, and why?","['probability-theory', 'probability']"
452992,Correct spaces for quantum mechanics,"The general formulation of quantum mechanics is done by describing quantum mechanical states by vectors $|\psi_t(x)\rangle$ in some Hilbert space $\mathcal{H}$ and describes their time evolution by the Schrödinger equation
$$i\hbar\frac{\partial}{\partial t}|\psi_t\rangle = H|\psi_t\rangle$$
where $H$ is the Hamilton operator (for the free particle we have $H=-\frac{\hbar^2}{2m}\Delta$). Now I have often seen used spaces like $\mathcal{H}=L^2(\mathbb{R}^3)$ (in the case of a single particle), but I was wondering whether this is correct or not. 
In fact shouldn't we require to be able to derivate $\left|\psi_t\right>$ twice in $x$ and thus choose something like $\mathcal{H} = H^2(\mathbb{R}^3)$? If we treat directly $\psi(t,x) := \psi_t(x)$, shouldn't we require them to be in something like $H^1(\mathbb{R};H^2(\mathbb{R}^3))$? i.e., functions in $H^1(\mathbb{R})$ with values in $H^2(\mathbb{R}^3)$, e.g. the function $t\mapsto\psi_t$.","['partial-differential-equations', 'mathematical-physics', 'quantum-mechanics', 'hilbert-spaces', 'functional-analysis']"
452996,Optimizing a Dynamic Balanced Tournament,"I would like to create a schedule for a set of players to play a tournament.  The players are divided into a number of teams, and each round consists of the matches between these teams. The type of schedule I would like to make should conform to Balanced-Tournament Design.  This means: each team plays at each location Sometimes, locations are not always equal.  For example, the centre court at Wimbledon.  A balanced tournament should let everyone play at every location a fair number of times. each team plays every other team A staple of most round robin tournaments each team is ""home"" and ""away"" and equal number of times In team sports, often there needs to be a home and away team.  In baseball, for example, the home team gets to bat last in each inning.  This can be an advantage, so a balanced tournament should let every team have this opportunity an equal number of times. I've had a lot of success using Orthogonal Latin Squares and Factored Balanced Tournament Design, and found a decent way to generate such tournaments. However, I would like to now do something a little different: Players are grouped (e.g. based on skill or position).  A team needs one player of each group (e.g. one player of each position or skill level) Each round, the teams and matches are recreated such that The number of times two people play with each other is minimized The number of times two people play against each other is minimized This is similar to Individual-Pairs tournaments, but in my problem, the teams can have more than 2 players and the players are grouped such that each team requires a player from each group.  By changing the teams each round, a single player from each group (e.g. position or skill level) can ""win"" the tournament by winning more games than any other player. More formally, this could be described as follows (I am open to changing this notation should anyone have a better way to represent this): There are p players, divided up into g groups, each consisting of t=p/g players. Groups of players are labelled Gi={Pi1, Pi2, ... Pit} where i is the number of the group ( 0<=i<=g ) All players in this group are the same position/skill level, so a team will have exactly one player from each group. Players are labelled Pij where i is the group the player belongs to ( 0<=i<=g ) j is the number of the player within group i ( 0<=j<=t ) The schedule will contain r=t-1 rounds This will let everyone play against everyone else within their group. Each round, t teams and m=t/2 matches must be created Teams are labelled Tij={P1a, P2b, ... Pgc} where i is the round this team is for ( 0<=i<=r ) j is the number of the team within round i ( 0<=j<=t ) Each team consists of exactly one player from each group Matches are labelled Mij={Tia, Tib} where i is the round this match is for ( 0<=i<=r ) j is the number of the match within round i ( 0<=j<=m ) Minimize the following The number of times two players in the same group play together a team can only have one player from each group, so this must be 0 The number of times two players in different groups play together Through the course of the tournament, two players shouldn't be on the same team more than once The number of times two players in the same group play against each other Should be exactly 1 if r=t-1 The number of times two players in different groups play against each other In my experience, this might have to be twice Should this prove too complicated, I am more than willing to discuss the more specific case where: each team consists of 4 players ( g=4 ) the number of teams is ""low"", between 5 and 12 (20 to 48 players) the number of rounds does not need to be t-1 . If it is t-1 , then a player could (and should) play against all the other players of the same group exactly once.  This may not be possible to create, so I would accept a solutions where r is maximized such that a player never plays against another player in the same group more than once (i.e. some players in a group may never play against each other). While methods dealing generic problem are great, I am most interested in these specific cases since those are what motivated me to look at this problem in more detail. Thanks!","['discrete-mathematics', 'combinatorics']"
452997,"Prove that f is constant on $K$ that is, if $a \in K$ then $f(x)=f(a) \ \ \forall x\in K$","Suppose that $f: \Bbb R^n \to \Bbb R^m$ and that $a\in K$, where $K$ is a compact connected subset of $\Bbb R^n$  suppose for each $x\in$ $K$, $\exists$ $\delta_x >0$ such that $f(x)=f(y)$ $\forall$ $y\in$ $B_{\delta_x}(x)$ Prove that f is constant on $K$ that is, if $a \in K$ then $f(x)=f(a) \ \ \forall x\in K$","['general-topology', 'calculus', 'real-analysis', 'analysis']"
453005,Orthogonal projection onto an affine subspace,"If we want to find the distance from a vector $x$ to a subspace $S$, we take $\| (I-P_S) x\|$, where $P_S$ is the orthogonal projection onto the subspace $S$. Obviously we could do the same thing for an affine subspace $A$, although $P_A$ would now not be a linear operator. But how can we find $P_A$? Or perhaps we need not go to the trouble of finding $P_A$ in order to calculate the distance from a point $x$ to $A$? Once we find $(I - P_A)(0)$, whose norm is the distance from the affine subspace to the origin, we're good, because then if $v = (I - P_A)(0)$, we have $\{a - v \mid a\in A\}$ is a subspace, and the distance from $x$ to $A$ is the distance from $x-v$ to $\{a - v \mid a\in A\}$. But is there an easier way? What is the easiest way to describe a projection onto an affine subspace? What is the easiest way to find the distance from a point to an affine subspace? I ask because I am afraid this will come up on some exams in the fall, so I am biased toward ""calculation"" type answers... (I apologize if this is a repeat... I didn't find this on the site)","['matrices', 'linear-algebra']"
453030,The smallest group with 3 generators,What is the smallest (in terms of the number of elements) nonabelian group such that any presentation requires at least 3 generators? Most of the nonabelian finite groups I know seem to require only 2 generators.,"['finite-groups', 'group-theory']"
453035,Is there a splitting field for multivariate polynomials over $\mathbb{Q}$?,"Let $f(X,Y) = X^2 + Y^2 - c$.  Does there exist a field $F$ such that $f(X,Y) = \prod_{i=1}^n(a_1^i X + a_2^i Y + a_3^i)$, where $a^i$'s are in $F$?","['galois-theory', 'algebraic-geometry', 'polynomials']"
453044,Finding $\frac{a+b}{a-b}$ such that $a^2+b^2=6ab$,"For $a,b > 0$ such that $a^2+b^2=6ab$ .How to find $\frac{a+b}{a-b}$",['algebra-precalculus']
453071,Show that every group of order 48 has a nontrivial normal subgroup.,"Show that every group of order $48$ has a nontrivial normal subgroup. Proof Let $G$ denote a group of order $48$ . Let $P_k$ denote the k-sylow subgroup, and $n_k$ denote the number of conjugates of $P_k$ . Let $N(P_k)$ be the normalizer of $P_k$ . Then, $n_3 \equiv 1 \mod 3$ and $n_3 | 16 \implies n_3=1,4,16$ $n_2 \equiv 1 \mod 2$ and $n_2|3 \implies n_2=1,3$ Suppose that $n_3 = 4$ or $16$ , and let $n_2=3$ for contradiction. Then $n_3 = 3 \implies |N(P_3)|=16$ . So we have a subgroup of order 16 in $G$ . There is a theorem in Rotman's textbook (Advanced Modern Algebra): (Representation of Cosets). If H is a subgroup of finite index n in a group G, then there exists a homomorphism $\phi: G \rightarrow S_n$ with $\ker \phi \subseteq H$ . Using this theorem for $N(P_2)$ , we know that there is a homomorphism $\phi: G \rightarrow S_3$ with kernel in $N(P_2)$ . $P_3$ can only be sent to the 3-sylow subgroup of $S_3$ , since the image of an element must divide the order of the pre-image. Since the 3-sylow subgroup of $S_3$ is normal, its image must also be normal. So $P_3$ is normal, a contradiction. So $n_2=1$ and we're done. Do you think my proof is correct? Thank you in advance","['sylow-theory', 'group-theory', 'abstract-algebra']"
453085,Is almost any group generated by two generators?,"What is the asymptotic probability that a randomly chosen finite group can be presented with $2$ generators? More precisely, what is $$ \lim _{n \to \infty} \frac{\text{number of 2-generated groups of order} \le n}{ \text{number of groups of order} \le n}$$ if it exists?","['asymptotics', 'finitely-generated', 'finite-groups', 'group-presentation', 'group-theory']"
453099,Prove that $H$ is compact $\iff$ every cover $\{E_{\alpha}\}_{\alpha \in A}$ has a finite subcovering.,"Let $H \subseteq \Bbb R^n$. Prove that $H$ is compact $\iff$ every cover $\{E_{\alpha}\}_{\alpha \in A}$ where $E_{\alpha}$'s are relatively open in $H$ has a finite subcovering. $\bf{Solution \ trial:}$ For $\Rightarrow$ Suppose $H$ is compact. Suppose $\{E_{\alpha}\}$ are relatively open covering of $H$.
Since $\{E_{\alpha}\}$ are relatively open covering of $H$, $\exists$ open set $U_{\alpha}$ such that $U_{\alpha} \cap H= E_{\alpha}$ Then,$\  U_{\alpha}$ is open covering of $H$ Since $H$ is compact, $\exists $ finite subset $A_0 \subset A$ such that $$H\subseteq \bigcup_{\alpha \in A_0} \{U_{\alpha}\}$$ Then, $\{E_{\alpha}\}_{\alpha\in A_0} $ is a finite subcovering of  $\{E_{\alpha}\}_{\alpha\in A} $ For $\Leftarrow$ Since  $\{E_{\alpha}\}_{\alpha\in A} $ is relatively open subcovering of H, $$\{E_{\alpha}\cap H\}_{\alpha\in A}$$ is relatively open covering. $\exists$ a finite subset $A_0 \subset A$ such that $\{ V_{\alpha} \cap H\}_{\alpha \in A_0}$ covers H. $$\{ V_{\alpha} \}_{\alpha \in A_0}$$ covers H. i.e H is compact. Is the proof enough? Does There exist any mistake or missings in the detail of the solution? Please correct them. Thank you.","['general-topology', 'compactness', 'real-analysis', 'solution-verification']"
453113,How to merge two Gaussians,"I have two multivariate Gaussians each defined by mean vectors and Covariance matrices (diagonal matrices). I want to merge them to have a single Gaussian i.e. I assume there is only one Gaussian but I separated observations randomly into two groups to get two different Gaussians which are not too different than each other. Since I know the number of observations in each of two Gaussians, combined mean estimation is straight forward : $\frac{n_1\mu_1 + n_2\mu_2}{n_1+n_2}$ But, what about the Covariance matrix? Thanks EDIT: The question was confusing in the original post, especially the ""merging Gaussians"" part. Maybe the following paragraph would be a better choice. I have two sets of observations drawn from two multivariate Gaussians each defined by mean vectors and Covariance matrices (diagonal matrices). I want to merge the observations to have a single sample, and I assume to have another Gaussian (i.e. I assume initially there was only a single Gaussian, and observations were separated into two groups to get two different Gaussians).","['normal-distribution', 'probability']"
453138,Minimization problem as PDE,"In the article ""An Image Interpolation Scheme for Repetitive Structures"" Luong, Ledda and Philips propose the following approach to denoising digital image. They consider that regularized total variation minimization problem
$$\hat I(x)=\arg\min_{I(x)}[f(\nabla I(x))+\lambda\cdot g(H*I(x)-I_0(x))] \tag{3}$$
can be transformed to the partial differential equation:
$$\frac{\partial I(x, t)}{\partial t}=f_{I}' (\nabla I(x, t))+\lambda \cdot g_{I}'(H*I(x, t)-I(x, 0))) \tag{4}$$
I can't find foundation of such transformation and I can't agree with the equivalence of these two problems. Moreover the researchers believe appropriate to take $f(\cdot)=||\cdot||_{L^2}$ (or maybe $||\cdot||_{L^1}$) and $g(\cdot)=||\cdot||_{L^1}$. And I can't understand how they're going to find corresponding derivatives in such case. Could you help me understand these considerations?","['optimization', 'partial-differential-equations', 'image-processing', 'gradient-flows', 'functional-analysis']"
453139,Limit of $n^2\sqrt{1-\cos(1/n)+\sqrt{1-\cos(1/n)+\ldots}}$ when $n \to \infty$,Compute the limit: $$\lim_{n \to \infty} n^2\sqrt{1-\cos(1/n)+\sqrt{1-\cos(1/n)+\sqrt{1-\cos(1/n)+\ldots}}}$$,['limits']
453150,Does a compact connected complete linear order have the fixed point property?,"Would the same arguments used for showing $[0,1]$ has the fixed point property hold in this general case?  What could go wrong? EDIT: The fixed point property can be interpreted in two ways that I am now aware of: i) A partially ordered set has the fixed point property if every increasing self-map has a fixed point. ii) A linearly ordered topological space has the fixed point property if every continuous self-map has a fixed point. My question has been answered positively in the case of (i). I am also interested in knowing what happens if we interpret FPP as in (ii).","['fixed-point-theorems', 'order-theory', 'general-topology', 'connectedness', 'compactness']"
453163,Proving Every open set in $\Bbb R$ is a countable union of open intervals. [duplicate],This question already has answers here : Any open subset of $\Bbb R$ is a countable union of disjoint open intervals (17 answers) Closed 10 years ago . This question is from William R. Wade's Introduction to Analysis book: Prove that every open set in $\Bbb R$ is a countable union of open intervals. I have no ideas honestly. Thank you.,"['calculus', 'general-topology', 'self-learning', 'real-analysis', 'analysis']"
