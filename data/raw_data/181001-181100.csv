question_id,title,body,tags
3297525,How to derive derivative of the logarithm of a summation?,"I'm currently reading the book Deep Learning (Goodfellow et al., 2015) and had a question regarding the calculation of a gradient when explaining backpropagation for a certain example. For anyone who's curious, this is from section 6.5.9: Differentiation outside the Deep Learning Community . Suppose we have variables $p_1, p_2, ... , p_n$ representing probabilities and variables $z_1, z_2, ... , z_n$ representing unnormalized log probabilities. Suppose we define $$q_i = \frac{e^{z_i}}{\sum_i e^{z_i}}$$ where we build the softmax function out of exponentiation, summation and division operations, and construct a cross-entropy loss $J = -\sum_i p_i \log{q_i}$ . A human mathematician can observe that the derivateive of $J$ with respect to $z_i$ takes a very simple form: $q_i - p_i$ . I don't know how this result was derived, and was hoping that someone could give me some tips or advice. What I have so far is $$\log{q_i} = \log{e^{z_i}} - \log({\sum_i e^{z_i}})$$ $$
\begin{align}
p_i\log{q_i} & = p_i \log{e^{z_i}} - p_i \log({\sum_i e^{z_i}}) \\
& = p_iz_i - p_i\log(\sum_i e^{z_i})
\end{align}$$ If we take the derivative of $J = p_i\log{q_i}$ then I can understand that $d/dz_i (p_i z_i) = p_i$ , but how do we differentiate the second term that contains the logarithm of the summation? Thank you.","['summation', 'derivatives', 'logarithms']"
3297565,Regularization of $\sum_{n=2}^\infty (-1)^n \log n$,"I accidentally stumbled on the following regularization of this divergent series: $$\sum_{n=2}^\infty (-1)^n \log n ""="" \frac{1}{2} \log \frac{\pi}{2}$$ I'm not familiar enough with regularization, so I wanted to ask if this result agrees with any other known regularization method? I derived this result in the following way: $$\log n=\int_0^\infty \frac{dx}{x} (e^{-x}-e^{-n x})$$ Now consider the function: $$\sum_{n=2}^\infty (-1)^n (\log n) s^n=\int_0^\infty \frac{dx}{x} \left(e^{-x} \frac{s^2}{1+s}-\frac{s^2 e^{-2 x}}{1+s e^{-x}} \right)$$ $$\sum_{n=2}^\infty (-1)^n (\log n) s^n= \frac{s^2}{1+s}\int_0^\infty \frac{e^{-x}dx}{x} \frac{e^x-1}{e^x+s} $$ The right hand side converges for any $s>0$ , and in particular, for $s=1$ we have: $$\frac{1}{2}\int_0^\infty \frac{e^{-x}dx}{x} \frac{e^x-1}{e^x+1}=\frac{1}{2} \log \frac{\pi}{2}$$ I got the result with Wolfram Alpha, but I'm sure there's a proof somewhere on this site. There's an interesting corollary here. If we write: $$\sum_{n=2}^\infty (-1)^n (\log n) s^{n-1}= \frac{s}{1+s}\int_0^\infty \frac{e^{-x}dx}{x} \frac{e^x-1}{e^x+s} $$ And then integrate w.r.t. $s$ from $0$ to $1$ , we obtain: $$\sum_{n=2}^\infty (-1)^n \frac{\log n}{n}= \int_0^\infty \frac{\log(1+e^{-x})-e^{-x} \log 2}{x} dx= \gamma \log 2- \frac{\log^2 2}{2}$$","['logarithms', 'regularization', 'sequences-and-series']"
3297567,Square-integrable functions tend to zero at $\pm \infty$,Is it true that all differentiable square-integrable functions tend to zero at $\pm \infty$ ? If that is not true could you give a counterexample?,"['integration', 'measure-theory', 'hilbert-spaces']"
3297573,Are manifold subsets submanifolds?,"New question: Can manifold subsets always be made into submanifolds? My book is An Introduction to Manifolds by Loring W. Tu. A. Regular/embedded submanifolds are manifolds. My question is about the converse. In algebra: B. Subset groups are equivalent to subgroups (at least with the same law, but I believe ""same identity"" is not required because they'll just turn out to have the same identity anyway). C. Rings not so much: For (commutative unital) rings, if $B$ is a ring and if $A \subseteq B$ and $A$ is a subring of $B$ , then $A$ is a ring (with the same laws and identity as $B$ because this is how subring is defined anyway). However conversely, if they are both rings (NOT necessarily with the same laws or identity), then $A$ is not necessarily a subring of $B$ . D. For example, $B$ has an idempotent element $e$ besides identity, and $A$ is the principal ideal generated by $e$ , where we have $e$ as the identity of $A$ but not of $B$ ( Algebra by Michael Artin Proposition 11.6.2 ). I think the laws of $A=(e)$ are the same as the one of $B$ , and the only thing lacking for $A$ to be a subring of $B$ is that $A$ has a different identity from $B$ (I understand that $A=(e)$ has a different identity from $B$ if and only if $A$ doesn't contain the identity of $B$ ). E. Based on what I think is the issue in (D) and based on my guess that manifolds have no such analogue for ""identity"", I expect manifold subsets to be regular/embedded submanifolds. Update : Based on Eric Wofsey's answer, I guess since there are indeed ways, that subset rings are not subrings, besides not sharing identity. I guess the ways are to do with the laws $+$ and $\times$ differing between $A$ and $B$ , kind of like in the above parenthetical remark for groups. Question: Let $A$ and $B$ be manifolds with respective dimensions $a$ and $b$ . If $A \subseteq B$ (given the subspace topology because apparently people don't just assume this), then is $A$ a regular / an embedded $a$ -submanifold of $B$ ? I'll just attempt to prove embedded (I won't prove regular directly). Please verify. $A$ is the image of the inclusion map $\iota: A \to B$ . I will show $\iota$ is an embedding, with this definition (Using this equivalent definition would be circular since such definition says ""smooth submanifold"" and not ""smooth manifold""): Smooth: An inclusion between two smooth manifolds is smooth. Edit: I guess this is the problem. I can't quite use Theorem 11.14 , but i think one can somehow modify the proof of Theorem 11.14 to prove ""If N is a (smooth) manifold subset of M, then the inclusion $i: N \to M, i(p) = p$ , is an embedding"" Immersion: Inclusions are the prototype of immersions. Edit: Oh, at least for Euclidean spaces. Topological embedding: The restriction $\tilde{\iota}: A \to \iota(A)=A$ is identity on $A$ , a homeomorphism of $A$ (because of subspace topology).","['proof-verification', 'smooth-manifolds', 'manifolds', 'differential-topology', 'differential-geometry']"
3297576,Group schemes vs abstract groups in GIT,"In studying GIT I encounter the same problem at multiple occasions of confusing group schemes for abstract groups . There is a natural example: Take an affine scheme $X=Spec(A)$ and an (affine) group scheme $G=Spec(B)$ over some field $k$ (not necessarily algebraically closed) acting on $X$ . That is a k-morphism $\alpha:G\times X\to X$ or equivalently a morphism $$ \alpha^*: A\to A\otimes B  $$ such that the action (resp. coaction) conditions are fulfilled. With this set up I often see the notation $Spec(A^G)$ (not only for finite groups!) and I really don't see what this means. My interpretation: In these lecture notes the following is indicated (Remark 3.6.): For $g\in G$ and $f\in A$ , we have $\alpha^*(f)=\Sigma f_i\otimes h_i$ . Then $g$ acts as follows $$ f\mapsto \Sigma h_i(g)f_i .$$ But this expression only makes sense to me if we speak about $G(k)$ and not $G$ . Thus one should rather write $Spec(A^{G(k)})$ instead of $Spec(A^G)$ . Am I missing something here or is the above approach correct and this is simply an abuse of notation?","['notation', 'geometric-invariant-theory', 'algebraic-geometry', 'algebraic-groups']"
3297618,"Calculating $\lim_{(x,y) \to(0,0)} \frac{x^2y}{x^2+y^4}$","I can't figure out how to calculate this limit (or prove it does not exist) $$
\lim_{(x,y) \to(0,0)} \frac{x^2y}{x^2+y^4}
$$ I've tried with restrictions on $y=mx$ and curves of the form $y=x^n$ . 
The limit should not exist but even with polar coordinates I can't figure it out","['limits', 'multivariable-calculus']"
3297691,"Prove ${_4 F_3} \left(\frac12, \frac12, 1, 1; \frac34, \frac54, \frac32; \frac14 \right)= \frac14 \left(\frac{\pi^2}{4}+\log^2 (2+\sqrt{3} ) \right)$","I was experimenting with series and numerically found this gem: $$S=\sum_{n=0}^\infty \frac{2^{2n+1}}{(2n+1)^2 \binom{4n+2}{2n+1}}= \frac14 \left(\frac{\pi^2}{4}+\log^2 (2+\sqrt{3} ) \right)$$ Or, rewriting in hypergeometric form: $${_4 F_3} \left(\frac12, \frac12, 1, 1; \frac34, \frac54, \frac32; \frac14 \right)= \frac14 \left(\frac{\pi^2}{4}+\log^2 (2+\sqrt{3} ) \right)$$ How can we prove this result? I know that: $$\int_0^\infty \frac{t^{2n}}{(1+t)^{4n+2}}dt=\frac{2}{(2n+1) \binom{4n+2}{2n+1}}$$ This gives us: $$S=\int_0^\infty \frac{dt}{(1+t)^2} \sum_{n=0}^\infty \frac{(2t)^{2n}}{(2n+1) (1+t)^{4n}}$$ $$S=\frac12 \int_0^\infty \frac{dt}{t} \tanh^{-1} \left(\frac{2t}{(1+t)^2} \right)$$ Not sure how to find the closed form from here.","['integration', 'closed-form', 'hypergeometric-function', 'sequences-and-series']"
3297710,Proof that every field is perfect?,"The following must be wrong, since it shows that every field is perfect, which I gather is not so. But I can't find the error: Suppose $E/K$ is a field extension and $p\in K[x]$ is irreducible (in $K[x]$ ). Then every root of $p$ in $E$ is simple. Proof: Suppose OTOH that $\lambda\in E$ and $(x-\lambda)^2\mid p(x)$ . Then $(x-\lambda)\mid p'$ , so $\gcd_E(p,p')\ne1$ . But the euclidean algorithm shows that $\gcd_K(p,p')=\gcd_E(p,p')$ , hence $p$ is not irreducible.","['field-theory', 'fake-proofs', 'abstract-algebra', 'extension-field']"
3297711,"Example of a Random Measure on $[-a,a]$ which is non-degenerate","I just started reading about random measures and I'm trying to get a concrete example going for illustrative purposes. Let $a>0$ and let $\mathcal{P}([a,a]^d)$ be the collection of Borel probability measure on the cube $[-a,a]^d$ in $\mathbb{R}^d$ ; where the topology is induced by the Levi-Prokhorov metric . What is an example of a random measure $$\nu:([-a,a]^d,\mathcal{B}([-a,a]^d),P)\rightarrow (\mathcal{P}([-a,a]^d),\mathcal{B}(\mathcal{P}([-a,a]^d))$$ of Borel-measures on the cube $[-a,a]^d$ which satisfies $$
\begin{align}
& P\left( \omega \in [-a,a]^d: \,
\nu(\omega) \in U
\right)>0;\qquad &(\mbox{for every non-empty open subset $U$ of $\mathcal{P}([-a,a]^d)$})
\end{align}
$$ Here $P$ is a uniform probability measure on the cube $[-a,a]^d$ and $\mathcal{B}([-a,a]^d)$ is the corresponding Borel $\sigma$ -algebra (and we are viewing $\nu$ as a random element in $\mathcal{P}([-a,a]^d)$ ) .","['measure-theory', 'probability-theory', 'random-variables']"
3297724,Proof of $Z(I(X))=X$ for $X\subset \mathbb{P}^n$ a projective algebraic set.,"Let $X\subset \mathbb{P}^n$ be a projective algebraic set. That $X \subset Z(I(X))$ is clear. For the other inclusion, let's take $x\in Z(I(X))$ and we want to see that $x\in X$ . Since $x\in Z(I(X))$ , then $f(x)=0$ for all homogeneous $f\in I(X)$ . My question is, how does that necessarily imply that $x\in X$ ? We know that for homogeneous $f\in I(X)$ , $f(x)=0$ for all $x\in X$ , but how do we know that there isn't a point $q\in \mathbb{P}^n \setminus X$ such that all homogeneous $f\in I(X)$ vanish at said point $q$ ?","['algebraic-curves', 'algebraic-geometry', 'polynomials', 'projective-varieties']"
3297763,Number theoretical function with logarithmic properties,"Introduction This is all about the function $v_a(x)$ , what i could find about it and what questions i still have. First of all, I define $v_a(x)$ as the function that counts how often $x$ is divisible by $a$ with $x>0,a>1$ and $x,a \in \mathbb{N}$ . For example $v_2(24)=3$ because $24$ is $3$ times divisible by $2$ , whereas $v_2(3)=0$ because $3$ is not divisible by $2$ . To make $v_a(x)$ a little more general, I introduced the rule, that $v_a(a^n) = n$ iff $a^n \in \mathbb{N}$ and $n\in\mathbb{Q}$ Now things as $v_4(2) = \frac 12$ are possible (Which, if you think about it, makes kind of sense). I first thought about it when i was playing a little bit with the Collatz-conjecture ( here ). I noticed that Collatz function can be redefined involving $v(x)$ as $3\frac x{2^{v(x)}}+1$ ( $v(x)$ without a base always refers to $v_2(x)$ ). Logarithmic properties One of the most important properties of the $v$ function is that $$v_a(x*y)=v_a(x)+v_a(y)$$ and its trivial to see why. If you look at the properties of $v_a(x)$ so far, they are very similar to the logarithmic function. And we can even prove that $$\max(v_a(x))=\log_a(x)$$ Proof: Assume that there exist $n\in\mathbb{N}$ so that $$v_a(n) > log_a(n)$$ Note that we can write every natural number as $ka^b$ with $k,a,b\in\mathbb{N}; a,k>0; \gcd(a,k) =1$ Therefore $$v_a(ka^b)>\log_a(ka^b)$$ $$v_a(k)+v_a(a^b)>\log_a(k)+\log_a(a^b)$$ $$0+b>\log_a(k)+b$$ $$0>log_a(k)$$ $\unicode{x21af}$ This is a contradiction simply because $k\in\mathbb{N}$ Other results Here are all my resuts about the $v$ function: By definition, the equality $$\prod_{p\in\mathbb{P}} p^{v_p(x)}=n$$ holds for every $n\in\mathbb{N}$ $$\implies \sum_{p\in\mathbb{P}} \frac {v_p(x)}{\log_p(x)}=1$$ Other things that I managed to prove are $$\sum_{n=1}^x v_n(x)=\sum_{n=1}^\infty v_n(x)$$ or that $$\sum_{n=1}^\infty \frac1{v_a(n)+1}$$ diverges (not very hard to prove results). But the more interesting things are $$\sum_{n=1}^\infty \frac {z^{v_a(n)}}{n^s} = \zeta(s)\frac {a^s-1}{a^s-z}$$ for $s>1;a\neq1;z\neq0;a^s\neq z$ which is also quite easy to prove using the Euler product ( here ) My most recent result is $$-\sum_{n=1}^\infty \frac {v_a(n)}{n^s}=\zeta(s)^2\sum_{n=1}^\infty \frac {v_a(n)}{n^s}\mu(n)$$ where $\mu(x)$ is the Möbius function ( here ) (Which is equal to - $\frac {\zeta(s)}{a^s-1}$ see Edit 4 ). This equality can be proved using Möbius inversion ( here ) altough the proof is not that easy. If anyone wants to prove it, they are welcome to try and share. I would love to see someone find a simple proof. Last note and open question Even though it's not really much I found and im not a real mathematician, I think it's quite interesting. I dont know, if this function has already been studied, I couldn't find it anywhere. But if someone knows where to search, I would be happy about references and known results. Or maybe you can come up with other interesting or related stuff. If I´ll find anything else, I´ll make an edit and write it in here. The only thing I couldnt figure out was a closed form expression of $v_a(n)$ or a formula to calculate it's value. And I really tried. That was frustrating. So if you find a formula, please share it. Share any of your thoughts about $v_a(n)$ if you like. Edits Edit 1 if you plot $v(x)$ for natural number it gives a fractal-like structur. I think maybe $v(x)$ could be calculated iteratively.
Also, here is the python code: def v(a, x):
    if a > 1 and x > 0:
        count = 0
        while x % a == 0:
            x /= a
            count += 1
        return count
    else:
        return False Edit 3 Here is the wikipedia page to this function Edit 4 See @reuns comment","['conjectures', 'divisibility', 'logarithms', 'number-theory', 'riemann-zeta']"
3297796,Geometric-Harmonic Mean,"Context: Recently, I got interested in the Arithmetic-Geometric mean $\mathrm{AGM}(x,y)$ because it had the surprising property that $$\int_0^{\pi/2}\frac{dt}{\sqrt{x^2\cos^2t+y^2\sin^2t}}=\frac{\pi}{2\mathrm{AGM}(x,y)}.$$ I say this is surprising because it has such a complicated definition: If the sequences $(a_n)$ and $(g_n)$ are defined by $$\begin{align}
a_{n+1}&=\tfrac12(a_n+g_n) &a_0&=x\\
g_{n+1}&=\sqrt{a_n g_n} &g_0&=y
\end{align}$$ then $$\mathrm{AGM}(x,y):=\lim_{n\to\infty}a_n\ .$$ After I messed around with $\mathrm{AGM}$ and was able to prove its relation to the above elliptic integral, I asked myself the question ""is there an artihmetic-harmonic mean?"" The answer: yes. The Arithmetic-Harmonic Mean: We define the sequences $$\begin{align}
a_{n+1}&=\tfrac{1}{2}(a_n+h_n)  &a_0&=x\\
h_{n+1}&=\frac2{\frac1{a_n}+\frac1{h_n}}  &h_0&=y
\end{align}$$ and the Arithmetic-Harmonic mean is then defined as $$\mathrm{AHM}(x,y):=\lim_{n\to\infty}a_n\ .$$ Amazingly enough, we are able to find a closed-form evaluation for $\mathrm{AHM}(x,y)$ assuming $x,y>0$ . We do so by noticing that $$h_{n+1}=\frac{2a_nh_n}{a_n+h_n}=\frac{a_nh_n}{a_{n+1}}$$ so that $$a_nh_n=a_{n-1}h_{n-1}=a_0h_0=xy$$ giving $$a_{n+1}=\frac12\left(a_n+\frac{xy}{a_n}\right)$$ which converges to $$\lim_{n\to\infty}a_n=\mathrm{AHM}(x,y)=\sqrt{xy}\ .$$ That being established, I wanted to know if there is a geometric-harmonic mean. The Geometric-Harmonic Mean: I first should define it. Let the sequences $(h_n)$ and $(g_n)$ be defined as $$\begin{align}
h_{n+1}&=\frac{2}{\frac1{h_n}+\frac1{g_n}} &h_0&=x\\
g_{n+1}&=\sqrt{h_n g_n}  &g_0&=y
\end{align}$$ then, assuming convergence, define $$\mathrm{GHM}(x,y):=\lim_{n\to\infty}h_n\ .$$ It seems as if it will be harder to find out things about $\mathrm{GHM}$ because I cannot seem to sufficiently simplify the relationship between the two sequences as I was able to with $\mathrm{AHM}$ . I feel though, that there may be a really interesting integral relationship here. I did a little investigation of my own. One notable value of $\mathrm{AGM}$ is Gauss's Constant: $$\mathbf{g}=\mathrm{AGM}(1,\sqrt2)=\frac{(2\pi)^{3/2}}{\Gamma^2(\tfrac14)}.$$ I found $h_4$ and $g_4$ for $h_0=1$ , $g_0=\sqrt{2}$ on Desmos : $$h_4\approx g_4\approx 1.18034059902$$ for which Wolfram suggests the closed form $$1.18034059902\approx \sqrt{2}\,\mathbf{g}$$ which is definitely very fishy... So my questions: Is there some connection between $\mathrm{AGM}$ and $\mathrm{GHM}$ ? Is there a nice integral relationship for $\mathrm{GHM}$ ? Is there a closed for for $\mathrm{GHM}$ ?","['means', 'special-functions', 'sequences-and-series']"
3297854,Prove that if $A ∩ C ⊆ B$ and $a \in C$ then $a \not \in A\setminus B$,Suppose $A ∩ C ⊆ B$ and $a \in C$ . Prove that $a \not \in A\setminus  B$ . Need to prove that $a \in C \implies a \notin A\setminus B$ $$\tag1 A ∩ C ⊆ B$$ $$\tag2 (a \in A \land a \in C) \implies a \in B$$ $$\tag3 \lnot(a \in A \land a \in C) \lor a \in B$$ $$\tag4 (a \notin A \lor a \notin C) \lor a \in B$$ $$\tag5 a \notin C\lor (a \notin A \lor a \in B)$$ $$\tag6 a \notin C\lor \lnot(a \in A \land a \notin B)$$ $$\tag7 a \in C \implies a \notin A\setminus B$$ $(1) \implies (2) \implies (3) \implies (4) \implies (5) \implies (6)  \implies (7) $ Is it accurate?,"['elementary-set-theory', 'proof-writing', 'proof-verification']"
3297867,For every function field $L$ there is a smooth projective curve $C$ with $L\simeq k(C)$,"Let $k$ be an algebraically closed field. It is well-known that: The category of smooth (i.e., non-singular) projective curves with dominant morphisms is equivalent to the category of functions fields over $k$ in one variable with morphisms of $k$ -algebras. I'm trying to formalize the bijective correspondence between smooth projective curves and fields in one variable. The map $C\mapsto k(C)$ which sends a smooth projective curve $C$ to its function field is the natural way to do it. It is injective (up to isomorphism), because $k(C)\simeq k(C')\Rightarrow C\simeq^{\text{birr}} C'\Rightarrow C\simeq^{\text{isom}} C'$ . But surjectivity is tricky. Let $L$ be a function field over $k$ in one variable. Then $\exists\, x\in L$ such that $L\mid k(x)$ is a finite extension. Letting $A$ be the integral closure of $k[x]$ in $L$ , then $A$ is a finitely generated $k$ -algebra and a domain, so $A\simeq k[x_1,...,x_n]/I(X)$ for some affine variety $X\subset \mathbb{A}^n$ . Now since $k(X)\simeq\text{Frac}(A)=L$ , which has transcendence degree $1$ , we have $\dim X=1$ , so $X$ is a curve. Besides, since $A$ in integrally closed by construction, $X$ must be normal. But $\dim X=1$ , so $X$ must be non-singular. Since the projective closure $\overline{X}$ is birrationally equivalent to $X$ , it seems like I'm almost there. The problem is that $\overline{X}$ may be singular at some point. How do I treat this generally?","['algebraic-curves', 'function-fields', 'algebraic-geometry']"
3297886,Differentiable functions and existence of limits,"If a function is differentiable everywhere, does it imply that the limit at $\pm \infty$ is either finite or it diverges to $\pm \infty$ ?","['limits', 'derivatives', 'real-analysis']"
3297901,"For any $n\in\mathbb{N}$, $\mathbb{Q}^n$ is countable.","I would like to know if this is a valid application of the Enumeration Principle. Thanks in advance. Claim: For any natural number $n$ , $\mathbb{Q}^n$ is countable. Proof. Let $n\in\mathbb{N}$ . Consider the set $\mathcal{L} = \left\{ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, -, /, * \right\}$ . For any $x = (x_1, \ldots, x_n)\in\mathbb{Q}^n$ , each $x_i$ can be labelled by elements of $\mathcal{L}$ and therefore each $x$ can be labelled by elements of $\mathcal{L}$ . For example, we can label $(\frac{1}{2}, -30, 4)$ by the sequence $(1, /, 2, *, -, 3, 0, *, 4)$ , where the asterisk is used to separate components. Hence, $\mathbb{Q}^n$ can be labelled by a countable set. By the Enumeration Principle, $\mathbb{Q}^n$ is countable. For anyone who's interested: A set $A$ can be labelled by a set $B$ if there is an injection from $A$ to the set of finite sequences of elements of $B$ . That is, each element of $A$ can be assigned a unique finite sequence of elements of $B$ . The Enumeration Principle: Any set that can be labelled by a countable set is countable.",['elementary-set-theory']
3297905,Confusion on locally compact Hausdorff,"I am confused on the following theorem. Let X be a space. Then X is locally compact Hausdorff if and only if there exists a space Y satisfying the following conditions: 
(1) X is a subspace of Y
(2) The set $Y-X$ consists of a single point.
(3) Y is a compact Hausdorff space. Consider $\mathbb{R}$ under the usual topology and the subspace topology on $(0,1)$ . The interval $(0,1)$ is locally compact, however the compactification requires two points, namely $0$ and $1$ . Therefore $Y - (0,1)$ will consist of 2 points not one. I am very confused, where did I go wrong? Also, I am having trouble showing that the compactification of $\mathbb{R}$ is homomorphic to $S_{1}$ . I can show that the circle is compact and Hausdorff under the supspace topology of $\mathbb{R}^2$ where $\mathbb{R}^2$ is equipped with the topology that is induced by the Euclidean metric. But I need a continuous function from $\mathbb{R}$ into the circle.",['general-topology']
3297914,Functions $f$ such that for any polynomial $P$ the equation $f(x) = P(x)$ has at most $\deg P + 1$ solutions,"I would like to characterize the set $S$ of continuous functions $f \colon I \to \mathbb R$ such that for any $n \ge 0$ and for any polynomial $P$ of degree $n$ , the equation $f(x) = P(x)$ has at most $n+1$ solutions. Here $I$ is a generic non-degenerate interval of $\mathbb R$ , i.e. two functions in $S$ might be defined on different intervals. In order to do so, I found it useful to recall the following: Lemma . Let $g \colon I \to \mathbb R$ be continuously differentiable. If $g'$ has at most $n$ zeros in $I$ , then $g$ has at most $n+1$ zeros in $I$ . Proof : Since $g'$ has at most $n$ zeros, there exists $m \le n$ and there exist $m+1$ intervals $[x_0 = \inf I, x_1], [x_1, x_2], \dotsc, [x_m, x_{m+1} = \sup I]$ such that $g'$ keeps the same sign in any $[x_i, x_{i+1}]$ . Therefore, $g$ is monotonic in each $[x_i, x_{i+1}]$ , and thus has at most one zero in each $[x_i, x_{i+1}]$ . What I have found so far about $S$ : If $f \in S$ , then $f$ is injective (and so monotonic). Proof : Let $y \in \mathbb R$ . Since $P(x) = y$ is a polynomial of degree $0$ and $f \in S$ , the equation $f(x) = y$ has at most $1$ solution. If $f$ is injective and $f' \in S$ , then $f \in S$ . Proof : Let $P$ be a polynomial of degree $n > 0$ . Since $P'$ has degree $n-1$ and $f' \in S$ , then $f'(x) - P'(x)$ has at most $n$ zeros, so by the lemma $f(x) - P(x)$ has at most $n+1$ zeros. $e^x \in S$ . Proof : By induction on $n$ . The case $n = 0$ follows by injectivity. Let $n > 0$ and $P(x)$ be a polynomial of degree $n$ . By the inductive hypothesis, $e^x - P'(x)$ has at most $n$ zeros, so by the lemma $e^x - P(x)$ has at most $n+1$ zeros. $\ln x \in S$ . Proof : Let $n \ge 0$ and $P(x)$ be a polynomial of degree $n$ . Then $1 - x P'(x)$ is a polynomial of degree $n$ and therefore has at most $n$ zeros, and so $\frac 1 x - P'(x)$ also has at most $n$ zeros. Again, by the lemma it follows that $\ln x - P(x)$ has at most $n+1$ zeros. If $f \in S$ and $g(x) = a f(x) + b$ for some $a, b \in \mathbb R$ with $a \neq 0$ , then $g \in S$ . If $f \in S$ and $g(x) = f(a x + b)$ for some $a, b \in \mathbb R$ with $a \neq 0$ , then $g \in S$ . Clearly, no polynomial belongs to $S$ . Also, $\arcsin x$ , $\arccos x$ , and $\arctan x$ don't belong to $S$ . Is there a simple characterization of $S$ ? I don't mind restricting $S$ to differentiable or even smooth functions if it proves necessary to provide a simple characterization.","['functions', 'polynomials']"
3297924,Numerical methods for finding the roots of $f(x)=\left(\cos{\frac{33}{x}\pi}\right) (\cos{x \pi})-1$,"I have a trigonometric function; for instance $$f(x)=\left(\cos{\frac{33}{x}\pi}\right) (\cos{x \pi})-1$$ I wanted to know the zeroes of this particular function, so I thought I could look into some root-finding algorithms (Newton's, Halley's, Secant...). However, they don't seem to work as $f'(x)=0$ at the roots of $f(x)$ , so all those methods are not guaranteed to converge. So, I was thinking, is there some type of root-finding algorithm for this particular trigonometric equation? Or at least transform this equation into one that the roots would go through the x-axis rather than ""bouncing"" off it, so Newton's method would apply. Also, I am focused on roots $>1$ and $<33$ . Note: Although the given example can be solved with trigonometric techniques, I am specifically looking for numerical methods . The example was chosen to make it easy to check the roots. I can generalize it to say for any $$f(x)=\left(\cos{\frac{n}{x}\pi}\right) (\cos{x \pi})-1$$ and an interval $$[a,b]$$ where there is only one root in that interval, is there a way to use numerical methods that are guaranteed to converge at the root to find that root?","['trigonometry', 'functions', 'roots', 'numerical-methods']"
3297943,"Is $\mathcal G_t = \sigma(\int_{0}^{s} W_s \,du:s\leq t)$ a right-continuous filtration?","As the question states: Is $$\mathcal G_t = \sigma\left(\int_{0}^{s} W_s \,du:s\leq t\right)$$ where $W_s$ is the Brownian motion, a right-continuous filtration? I think the answer is no, as $\mathcal G_t \neq \bigcap_{n=1}^{\infty}\mathcal G_{t+\frac{1}{n}}$ ; it is possible for more information to be gained infinitesimally far into the future. Is my understanding correct? Thanks!","['stochastic-processes', 'brownian-motion', 'probability-theory']"
3297953,Looking for Distinct Solutions to $x_1 + x_2 + x_3 + x_4 = 100$ Given Certain Conditions,"How many distinct solutions to the equation does the following have? $$x_1 + x_2 + x_3 + x_4  = 100$$ such that $x_1 \in \{0,1,2,... 10 \}, x_2, x_3, x_4 \in \{0,1,2,3,...\}$ My attempt: Ordinarily if the range of all the $x_i$ s were the set of natural numbers including zero, I could just do $_{103}C_3$ . However since $x_1$ is bound from $0$ to $10$ inclusive, I can't do that. What I attempted was to set $x_1$ to each value from $0$ to $10$ and then take the summation of all the distinct solutions for each x_1. Hence, $$\sum^{10}_{i=0}(_{102-i}C_2)$$ So for each value of $x_1$ I find how many distinct solutions to the equation $$x_2 + x_3 + x_4  = 100 - x_1$$ there are and then sum them together. Is this the right approach? It feels kinda awkward to me? Is there a more efficient option?","['number-theory', 'combinatorics', 'discrete-mathematics']"
3297989,Dependency of the expectation,"I have read a few times now in some books the following sentence: ""Expectation depends only on its distribution."" I only had the case that $X$ is a real-valued random variable on a countable space Ω. What does this sentence mean and how can one show it?","['expected-value', 'probability-theory', 'probability']"
3297995,Recurrence relation for the Thue–Morse sequence,"I made a curious observation. Let $a_n$ be the sequence of numbers determined by a recurrence relation $$\begin{cases}
\vphantom{\large|}a_0=0\\ 
\vphantom{\large|}a_1=1\\
\vphantom{\Large|}n\,a_n=(5-2 n)\,a_{n-1}+3{\tiny\text{ }}(n-1)\,a_{n-2}+1
\end{cases}\tag{$\small\spadesuit$}$$ It also can be generated using an equivalent homogeneous recurrence relation $$\begin{cases}
\vphantom{\large|}a_0=0\\ 
\vphantom{\large|}a_1=a_2=1\\
\vphantom{\Large|}n\,a_n = (4-n)\,a_{n-1}+(n-2)\left(5{\tiny\text{ }}a_{n-2} - 3{\tiny\text{ }}a_{n-3}\right)
\end{cases}\tag{$\small\clubsuit$}$$ 0, 1, 1, 2, 1, 4, -2, 13, -23, 68, -164, 439, -1146, 3067, -8231, 22306, -60791, 166684, ... It appears that this sequence modulo $2$ gives the Thue–Morse sequence , meaning that if we denote $t_n=(-1)^{a_n}\,$ then it satisfies $$t_0 = 1,\quad t_n = (-1)^n \, t_{\lfloor n/2\rfloor}.\tag{$\small\diamondsuit$}$$ How can we prove this?","['number-theory', 'conjectures', 'recurrence-relations', 'sequences-and-series']"
3298019,"Generating Calkin-Wilf sequence in Python, but I don't understand the math","This correctly generates the Calkin-Wilf sequence: def calkin_wilf():
    a, b = 1, 1
    while True:
        yield a, b
        a, b = b, a - 2*(a%b) + b

g = calkin_wilf()
ret = [next(g) for _ in range(5)]
print(ret)

# [(1, 1), (1, 2), (2, 1), (1, 3), (3, 2)] I understand the Python code itself, but I'm struggling with how they arrived at that math formula for the next denominator in the sequence. I know that the next numerator of a number in the Calkin-Wilf sequence is the denominator of the previous number.  That's easy. But given a number $\frac{a}{b}$ , why does $a- 2 \cdot (a \bmod b) + b$ give the next denominator in the sequence? The only clues I have is that it is a manipulation of this formula: and that the modulo operator can somehow be used to calculate the floor of a number: I've tried to work things out on paper but I can't figure it out.  Could someone walk through the math for me? Sources: [1] https://en.wikipedia.org/wiki/Calkin%E2%80%93Wilf_tree [2] https://en.wikipedia.org/wiki/Floor_and_ceiling_functions#Mod_operator","['number-theory', 'python']"
3298039,Where does $\pi^2$ appear spontaneously within Physical Phenomenon and Mathematics Equations?,"The term $\pi$ is found to appear in many equations and natural phenomenon; however my question is related to $\pi^2$ . While trying to figure out the reason for some $\pi^2$ terms appearing in certain equalities that I came across, I have a question. And the question is this: In which all mathematics/physics equation or contexts does $\pi^2$ appear inherently? -- and (now this second part is merely a follow up question that did not form part of the original query but added later)  where that $\pi^2$ term can lend some interpretation of the underlying phenomenon, just like does $\pi$ whereby we can interpret (in most cases i.e.) that some type of circular ambulation in 1 dimension is involved?? As you can understand, the $\pi^2$ term is more complex and does not directly lend itself to an interpretation -- as opposed to $\pi$ which is very intuitive. Thanks","['pi', 'big-list', 'soft-question', 'geometry']"
3298056,Questions on a formula for the Mertens function,"The Mertens function $M(x)$ is defined as follows. (1) $\quad M(x)=\sum\limits_{n=1}^x\mu(n)$ I've noticed the Merten's function can also be evaluated as follows which is related to OEIS entry A087003 and the Collatz conjecture . (2) $\quad M(x)=\sum\limits_{n=\left\lfloor\frac{x-2}{4}\right\rfloor+1}^{\left\lfloor\frac{x-1}{2}\right\rfloor}\mu(2\,n+1)$ I've verified formula (2) above for the first $10,000$ positive integer values of $x$ . Question (1) : Has formula (2) above been proven (or disproven) and if not, can it be? I've read the following conjecture on the growth of $M(x)$ for any $\epsilon<1/2$ is equivalent to the Riemann hypothesis (see Weisstein, Eric W. ""Mertens Conjecture."" From MathWorld--A Wolfram Web Resource ). (3) $\quad M(x)=O\left(x^{1/2+\epsilon}\right)$ Question (2) : Assuming formula (2) above is correct, does it show any promise with respect to improving upon the fastest known algorithm for computing $M(x)$ and/or the tightest known error bound on the growth of $M(x)$ ?","['collatz-conjecture', 'number-theory', 'mobius-function', 'riemann-hypothesis']"
3298069,solving license plate equations,"When I'm a passenger in a car and don't have anything to do, I try to turn the strings of numbers on license plates into equations (I call this solving the license plate). For example, $$4161 \ \Longrightarrow \ 4 + 1= 6 - 1$$ $$333 \ \Longrightarrow \ 3 = 3 = 3$$ However, if I only allow addition and subtraction there are some license plates I can't solve. $119$ is one such example. I was wondering if there is a string length long enough so that every license plate of that length can be solved. More precisely, is there an $n$ so that for all $a_1, ..., a_n$ with $a_i \in \{1, ..., 9\}$ can we find a sequence of operations (only allowing addition, subtraction, and equality) that can solve the license plate problem? Note that I excluded $0$ from the problem because any license plate that goes $00...001$ is unsolvable. I have no idea how to approach this problem so any help would be greatly appreciated.",['combinatorics']
3298099,References on derived categories for schemes,"I want to study derived categories to show the theorems in this page (the non-noetherian case of the theorems in Hartshorne III.12),
and the theorems about spectral sequences
(I've heard that the Grothendieck spectral sequence theorem is old theory, and it is better to use derived category than to use spectral sequences). But I'm not familiar with the theories.
So please suggest me some references. Is the stack project good for those who study derived categories for the first time? Any help will be much appreciated!","['algebraic-geometry', 'category-theory']"
3298116,The integral $\int\limits_0^\infty\frac{x^4e^x}{(e^x-1)^2} \mathrm{d}x$,"How to calculate the following integral $$\int_0^\infty\frac{x^4e^x}{(e^x-1)^2}\mathrm{d}x$$ I would like to solve this integral by means of two different ways: for example, integration by parts and using Residue Theorem.","['integration', 'calculus', 'improper-integrals']"
3298137,Proving that $\lVert u \rVert_{L^2} \leq Ce^{-\nu t}$ for certain pde,"Given that $$\frac{\partial u}{\partial t}+\sin(y)\frac{\partial u}{\partial x}=\nu\Bigl(\frac{\partial^2u}{\partial x^2}+\frac{\partial^2u}{\partial y^2}\Bigr)$$ With the following periodic boundary conditions: $$u(-\pi,y,t)=u(\pi,y,t) \\ u(x,-\pi,t)=u(x,\pi,t) \\u_x(-\pi,y,t)=u_x(\pi,y,t)\\
u_y(x,-\pi,t)=u_y(x,\pi,t)\\
u(x,y,0)=F(x,y)$$ Prove that $$\lVert u \rVert_{L^2} \leq Ce^{-\nu t}$$ I have used the finite Fourier transform to get that $$\frac{du_{mn}}{dt}=-\nu (n^2+m^2)u_{mn} -\int_{-\pi}^{\pi}\sin(y) u_ne^{-imy}dy$$ Where $$u_{mn}=\int_{-\pi}^{\pi} \int_{-\pi}^{\pi} u(x,y,t)e^{-imx} *e^{-iny} dxdy$$ Second I tried Energy method Multiply by u and then integrate, still I didn't get the required result. How to get the required result ?
Any Hint ?","['integration', 'partial-differential-equations', 'functional-analysis', 'real-analysis']"
3298181,Algorithms for untying knots?,"A typical problem I run into while doing anything involving ropes (e.g. climbing or sailing) is how to eliminate tangles efficiently, preferably without having to feed one end of the rope back through all the gnarls. Do there exist algorithms for unknotting ropes efficiently? Wikipedia alludes to an algorithm to determine whether two knots are equivalent, but this is slightly different than the practical problem I am interested in.  What I would like would be something like the following: An algorithm that can be implemented by hand to reduce the complexity of a tangle of rope.  E.g. something like ""First identify a half hitch, then follow it until you find another half hitch, then do something else..."". An algorithm that I could program into an app, which would look at a picture of a rope and say something like ""If you pull on this doubled strand, the whole tangle will fall apart."" The latter option could presumably be phrased as a combinatorial problem along the lines of ""find the minimum number of moves (suitably defined) to reduce this knot to the unknot (where rope ends are identified for purposes of recognizing knots).""","['knot-theory', 'general-topology', 'algorithms']"
3298186,Prove $\int_0^1 \frac{\tanh^{-1} (\beta t) dt}{t\sqrt{(1-t)(1- \alpha t)}}=\log (a) \log (b)$,"If we set: $$\alpha= \frac{(ab-1)^2+(a-b)^2}{(ab+1)^2+(a+b)^2}$$ $$\beta= \frac{(ab+1)^2-(a+b)^2}{(ab+1)^2+(a+b)^2}$$ Then it follows that: $$\int_0^1 \frac{\tanh^{-1} (\beta t) dt}{t\sqrt{(1-t)(1- \alpha t)}}=\log (a) \log (b)$$ I have derived this result in a very roundabout way, most of the details you can see in this post , however from the symmetry of it I suspect there may be better and more clear ways to prove it, which is why I'm asking a separate question. Aside from the proof, I'm interested in deeper reasons or implications for this identity (if they exist) and some references to similar ones.","['integration', 'hyperbolic-functions', 'definite-integrals', 'logarithms']"
3298210,"Is there a continuous function $f$ satisfying $f(x)^2=f\left(x^2\right)$, $f(0)=1$ and $ f(1)=0$?","I was wondering if there is a continuous function $f:[0,1]\to\mathbb R$ satisfying $$f(x)^2=f\left(x^2\right)\text,$$ for all $x\in[0,1]$ , $f(0)=1$ and $ f(1)=0$ . Clearly, some easy functions like polynomials are not satisfied. I guess there is a way to construct an example since it only needs a continuous function.","['functional-equations', 'real-analysis']"
3298329,Covariance between sum of iid random variables and sum of indicator functions,"The question is- Let $X_1,X_2,..,X_n$ be iid random variables from a continuous distribution whose density is symmetric about $0$ . Suppose $\mathbb{E}(|X_1|)=2$ and define $Y=\sum_{i=1}^{n}X_i$ and $Z=\sum_{i=1}^{n}I(X_i>0)$ . Then calculate covariance between $Y$ and $Z$ . My attempt: $E(X_i)=0$ for all $i=1(1)n$ because $X$ is symmetric about $0$ and $E(|X|) $ exists. Now, $Cov (Y,Z)=E(YZ)-E(Y)E(Z)$ $=E(YZ)-0$ $=E[(\sum_{i=1}^{n}X_i)(\sum_{i=1}^{n}I(X_i>0)]$ $=(\sum_{i=1}^{n}E[(X_i.I(X_i>0))]$ $+\sum\sum_{i \neq j}E(X_i)E(I(X_j>0)$ as $X_i,X_j$ are independent. $=\sum_{i=1}^{n}E[(X_i.I(X_i>0)] +0 $ as $E(X_i)=0$ $ =\sum_{i=1}^{n}\{E[X_i.I(X_i>0)|I(X_i>0)=1]×1/2] + E[X_i.I(X_i>0)|I(X_i>0)=0]×1/2]\}$ $=\sum_{i=1}^{n}E[X_i.I(X_i>0)|I(X_i>0)=1]×1/2] +0$ $=\sum_{i=1}^{n}E[X_i|X_i>0]×1/2]$ $=2n×(1/2)$ $=n$ Is my reasoning correct ? Thanks in advance!","['expected-value', 'statistics', 'covariance', 'probability']"
3298341,Geometry problem about two externally touching circles,"Two circles of radius $~12~$ and $~3~$ touch externally. A line intersecting both of them intersects first circle at points $P$ and $Q$ , second circle - at points $R$ and $S$ . Three resulting line segments, two inside the circles and the one between them, are equal: $PQ=QR=RS$ . Find their common length. I have prepared a picture with Geogebra to illustrate I was trying to solve this with no luck. After formulating it as a system of equations based on coordinates, with the origin being circles' common point and $X$ -axis on the line connecting their centers, Wolfram Alpha helped me to find that the answer should be $\frac{3}{2}\sqrt{13}~$ . Can you give any hints on how to solve this?","['euclidean-geometry', 'circles', 'geometry']"
3298344,Prove that $P$ lies on line $CC'$.,"Semicircles diameters $PA$ and $PB$ are drawn such that they intersect at point $Q$ $(P \not\equiv Q)$ and $PA \perp PB$ . $M$ and $N$ are points lying on line segment $PA$ and $PB$ respectively. $MQ$ and $NQ$ intersect semicircles diameters $PB$ and $PA$ at $M'$ and $N'$ in that order $(N' \not\equiv Q \not \equiv M')$ . Given midpoints $C$ and $C'$ of respectively $MN$ and $M'N'$ $(CP > CQ)$ . Prove that $P$ lies on line $CC'$ . This problem is said to be an application of Newton's line, which I found to be reluctant. Perhaps there might more points to be set up that I didn't know. As the answer by Oldboy suggests, there's a condition that needs to satisfied for the problem to be correct but I haven't found it out yet. I hope someone can help me. As the comment by Blue points out, a possible condition is that $$\left(\frac{PA}{PB}\right)^2 = \left|\frac{AM \cdot PN}{BN \cdot PM}\right|$$",['geometry']
3298403,Prove a tough limit involving the digamma function,"Here I have a limit to which I arrived while working on a seperate integral through  Mellin Transforms. $$\lim\limits_{s\to -1^{-}}\Big[\psi_{(0)}(s)-\frac{\pi}{2}\tan\left(\frac{\pi s}{2}\right)\Big]$$ Here, we have $\psi_{(0)}(s)$ which represents the digamma function. I graphed the whole thing on Desmos to see what it looked like approaching $-1$ , and it seems very likely that the limit approaches $$1-\gamma$$ Here, $\gamma$ is the Euler-Mascheroni constant. I would like to know if there is a concrete way of evaluating this limit. I tried doing some work with it: $$=\lim\limits_{x\to 0}\Big[\psi_{(0)}(x-1)-\frac{\pi}{2}\tan\left(\frac{\pi}{2}(x-1)\right)\Big]$$ $$=\lim\limits_{x\to 0}\Big[\frac{1}{1-x}+\psi_{(0)}(x)-\frac{\pi}{2}\tan\left(\frac{\pi}{2}(x-1)\right)\Big]$$ I don't really know where to go from here. I figure maybe a Taylor expansion could do the trick. However, the expansions for both the digamma and tangent functions are largely unrelated, it seems. I'm curious to see a solution to this problem, and wish you all good luck! A natural extension of this question would be to find: $$\lim\limits_{s\to (-1-2k)^{-}}\Big[\psi_{(0)}(s)-\frac{\pi}{2}\tan\left(\frac{\pi s}{2}\right)\Big]\,\,\forall\,\,k\in Z^{+}$$ This generalized limit might be the bane of my existance.","['digamma-function', 'real-analysis', 'complex-analysis', 'calculus', 'limits']"
3298463,"Let $g$ be a differentiable, continuous function $[0,1]$ and $a≤g'(x)≤b$ for all $x\in [0,1]$","Let $g$ be a differentiable, continuous function $[0,1]$ and $a≤g'(x)≤b$ for all $x\in [0,1]$ Then prove that : $$\frac{b^2}{12}≥\int_0^{1}g^{2}(x)dx-\left(\int_0^{1}g(x)dx\right)^{2}≥\frac{a^2}{12}$$ I'm trying using Hölder ? But I don't know how. I don't have any ideas to prove this inequality ? I think this is related with measure theory. If any one have idea please tell me.","['measure-theory', 'holder-inequality', 'integral-inequality']"
3298488,Integration using partial fraction is wrong,"$$\int_{2}^{\infty} \frac{1}{x-x^{3}}dx$$ I think the way to solve this, is using partial fraction. For some reason I can't get to the answer... $$\frac{A}{x}+\frac{B}{1-x}+\frac{C}{1+x}=\frac{1}{x-x^{3}}$$ $$A(1-x)(1+x)+Bx(1+x)+Cx(1-x)=1$$ $$x=1: 2B=1=>B=0.5$$ $$x=-1:-2C=1=>C=-0.5$$ $$x=0: A=1$$ Then rewriting the integral: $$\int \frac{1}{x}+\frac{0.5}{1-x}-\frac{0.5}{1+x} $$ $$\ln x+0.5\ln(1-x)-0.5\ln(1+x)|_{2}^{\infty}$$ Inserting 0.5 into the brackets and using log rules I get: $$\ln x+\ln(\sqrt\frac{1-x}{1+x})$$ $$x \to \infty $$ inside the square root the result is -1 as 'X' approaches infinity, and I can't sqrt of a negative number. Perhaps I was wrong somewhere along the lines, maybe my way of integration is wrong... Answer: 0.5*ln(3/4)","['integration', 'improper-integrals', 'calculus', 'partial-fractions', 'limits']"
3298516,"Let $X,Y \in L_{2} ( \Omega, P)$. Then $ | \mathbb{E} (XY) | \leq \sqrt{\mathbb{E} X^{2} \mathbb{E} Y^{2}}$","I have trouble with understanding proof of next theorem: Let $X,Y \in L_{2} ( \Omega, P)$ . Then $$ | \mathbb{E} (XY) | \le \sqrt{\mathbb{E} X^{2} \mathbb{E} Y^{2}} .$$ Proof:
Let $\Omega = \{ \omega_{n} \colon n \in\mathbb{N} \}$ . Then, for every $n \in\mathbb{N}$ $$  | \mathbb{E} (XY) |  \le  \mathbb{E} | XY |  = \sum_{k=1}^{n} | X (\omega_{k}) | \cdot | Y (\omega_{k}) | \cdot P(\{\omega_{k}\})$$ Futher, using Cauchy Schwartz inequality, and tending $n \to \infty$ proof is done. This $$ | \mathbb{E} (XY) | \le  \mathbb{E} | XY | = \sum_{k=1}^{n} |X (\omega_{k})| \cdot |Y(\omega_{k})| P(\{\omega_{k}\})$$ is what is bothering me. How can we observe $
\mathbb{E} | XY | $ as a sum of finite numbers?",['probability-theory']
3298534,Two kinds of Metrics of Convergence in Measure,"There are many kinds of metrics that can induce the topology of convergences in measure. Two most common metrics are Here is the first one . $ 
d(f,g) := \inf_{\delta > 0} \big(\mu(|f-g|>\delta) + \delta\big)
$ Here is the second one , which is the most common. $
d(f,g) = \int \frac{|f-g|}{1+ |f-g|}d\mu
$ I have three questions: Q1 I am trying to prove the Triangle inequality of the first metric. I have done so far: $
		\mu\left\{ x\in X:\left|f\left(x\right)-g\left(x\right)\right|>\delta\right\} +\delta
\le	\mu\left\{ x\in X:\left|f\left(x\right)-h\left(x\right)\right|>\frac{\delta}{2}\right\} +\frac{\delta}{2}+\mu\left\{ x\in X:\left|h\left(x\right)-g\left(x\right)\right|>\frac{\delta}{2}\right\} +\frac{\delta}{2}
$ But I have no idea what to do next. Q2 What is the difference between the two metrics? Both metrics can induce the topology of convergence in measure. As far as I am concerned,  the second metric is used only in probability contexts or in the case the measure is finite. I wonder whether this statement is right. If it is true, what's wrong with the second metric when the measure is not finite? Q3 Given a measure space $\left(X,\mathscr{F},\mu\right)$ and let $L^{0}\left(X,\mathscr{F},\mu\right)$ be the vector space of all real-valued measurable functions on $\left(X,\mathscr{F},\mu\right)$ .
If both metrics can be defined on $L^{0}\left(X,\mathscr{F},\mu\right)$ , are the topologies of these two spaces the same? Can anyone help me out? Thanks in advance.","['measure-theory', 'metric-spaces', 'functional-analysis', 'general-topology', 'convergence-divergence']"
3298570,Find modulus and argument of $\omega = {\frac {\sin (P + Q) + i (1 - \cos (P + Q))} {(\cos P + \cos Q) + i (\sin P - \sin Q) }} $,"A past examination paper had the following question that I found somewhat difficult. I tried having a go at it but haven't come around with any possible double angle identities. How would one go about tackling it? Given: $$\omega = {\frac {\sin (P + Q) + i (1 - \cos (P + Q))} {(\cos P + \cos Q) + i (\sin P - \sin Q) }} $$ To prove: $$|\omega| = \tan \frac {P + Q} {2} \qquad\text{and}\qquad \arg(\omega) = Q $$ A guideline on how/ which identity to use would be greatly appreciated. To give an idea how one would start it is by; Proof: $$|\omega| = {\frac {\sqrt{\sin^2 (P + Q) + (1 - \cos (P + Q))^2}} 
{\sqrt{(\cos P + \cos Q)^2 + (\sin P - \sin Q)^2 }}} $$ I'm still unsure about the above or how the square root come about","['calculus', 'trigonometry']"
3298581,path of light in disc where speed varies according to distance from boundary,"I'm struggling to answer one of the problems in the book Notes on Geometry by Elmer Rees. The question is as follows: Consider a disc $D^2$ made of a material such that the speed of light
  at a point $p$ is proportional to the Euclidean distance of $p$ from
  the boundary. Prove that the light rays are the hyperbolic lines of
  the Poincaré model. After trying to solve this using purely mathematical ideas (the book is a classic mathematical geometry graduate text), I found the only way to proceed was by using a Snell's Law (a law of physics and so not in the book). This makes me nervous that I'm perhaps missing the point! However this does allow me to relate $r$ (the general distance of $p$ from the centre of the disc O, $k$ (the distance of $p$ from O when the light is travelling parallel to the boundary) and the general angle $\theta$ between Op and the direction of motion. The relationship I have derived is: $$1-r = (1-k)\sin\theta$$ Which looks really promising since then $\theta=\pi/2$ when $r=k$ and $\theta=0$ or $\pi$ when $r=1$ , as required for a circular path (i.e. hyperbolic lines of Poincaré model). However I still can't show the path of the light is actually circular. So I have a few questions: Am I using the right approach, or is there a better way that avoids Snell's Law? If my approach is correct, is my equation relating $r$ and $\theta$ correct? If this is right, how can I show the motion is along a circular path? Many thanks in advance!","['hyperbolic-geometry', 'geometry']"
3298584,How to find a prime $p$ from only knowing $x^2\bmod p$ for suitably chosen (small and few) value of $x$?,"This question is related to the CodeChef problem Guess The Prime of the now closed July 2019 competition. It seems to have caused some stir-up recently during and even shortly after the contest. However, I suppose that a treatment of the mathematical aspects of the problem is appreciated. Additional answers with different approaches or handling different aspects are welcome. Player $A$ picks a prime number $p$ below some given bound $N$ . Player $B$ has the task of finding $p$ , for which purpose $B$ may only name an integer $x$ and $A$ will reply with the value $x^2\bmod p$ . (Note that $a\bmod b$ is the remainder $\in\{0,\ldots, b-1\}$ not a coset modulo $b\Bbb Z$ ; so for example $17\bmod 3=17\bmod 5 = 2$ even though $2+3\Bbb Z\ne 2+5\Bbb Z$ ) Q1: How many queries are needed for $B$ to succeed with guarantee? Q2: How many queries are needed if we require $x<N$ ? Q3: How large must we allow $x$ to be so that $B$ can succeed with a single query? Q4: What are the smallest possible queries in order to succeed with two queries? ... and many more questions can be thought of in this context (the second question is the generalized essence of the original  CodeChef problem). Even more variations are obtained by considering other (finite, of course) sets of primes instead of all primes below some threshold.","['contest-math', 'number-theory', 'big-list']"
3298602,How can I solve the differential equation $ \frac{\mathrm d^2y}{\mathrm dx^2}(y\frac{\mathrm dx}{\mathrm dy}+x) = -A^2\frac{\mathrm dy}{\mathrm dx} $?,"I came across this differential equation while investigating how the concentration of a fluid varies with position $ x $ ( $ A $ is a constant). I tried to solve this by using a substitution, but I was unable to actually solve the equation for y. Wolfram Alpha did not come up with anything useful, either. Does anyone have any idea how to solve this? I would greatly appreciate if anyone could help me with this.",['ordinary-differential-equations']
3298630,What is/are the definitions of local diffeomorphism onto image?,"In summary : Actually, I think the confusion arises from a distinction between (local diffeomorphism)-onto image and local-(diffeomorphism onto image). See (C1) at the end. Firstly, I believe this is the definition for local homeomorphism onto image : Let $M$ and $N$ be topological spaces. Let $F: N \to M$ be a map. We say $F$ is a local homeomorphism onto its image , $F(N)$ (under the subspace topology) if $\tilde F: N \to F(N)$ is a local homeomorphism Now, any subset $A$ of a topological space $B$ can always be made into a topological space by making $A$ a topological subspace of $B$ with the subspace topology. This does not hold for (smooth) manifolds: If $B$ is now a manifold, then we can't always make $A$ into a manifold too. However apparently, we can discuss whether or not $A$ is ""diffeomorphic"" to other manifolds or any subset of any manifolds by this . My issue then is translating the above definition for local homeomorphism onto image to ""local diffeomorphism onto image"": I'm not sure if $F(N)$ is a manifold, specifically a regular/an embedded submanifold (I guess we need this specifically just as we need subspace topology for local homeomorphism onto image). I have the seen the term ""local diffeomorphism onto image "" in 3 separate posts, and I would like to clarify the definition. From this question: Does the Riemannian metric induced by a diffeomorphism $F$ exist for a reason other than the existence of vector field pushforwards? You can pull back the metric as long as $F_∗$ is injective on the tangent space (so $F$ is a local diffeo onto image). Injectivity of $F$ only matters if you want global isometry. – user10354138 Jun 20 at 12:09 From this question: Confusion with immersions, embeddings, local homeomorphisms, and local diffeomorphisms. Asking for $f:X\to Y$ to be a local homeo/diffeomorphism onto its image means there's a cover such that $f|_{U_i}$ are topological/smooth embeddings and that $fU_i\subset fX$ is open. From this question: Embedding, local diffeomorphism, and local immersion theorem. However, by the local coordinates condition you've imposed, the differential is full-rank, and so $f$ is a local diffeomorphism onto its image. I notice the definition from the second post above doesn't seem to specify whether or not "" $fX$ "" is a (regular/an embedded) submanifold or even manifold. I'm not sure all 3 posts have the same definition. Question: The following is my understanding of what's going on. Is this correct? There are 2 definitions of local diffeomorphsim onto image here. Let $M$ and $N$ be smooth manifolds with dimensions . Let $F: N \to M$ be a smooth map. We say $F$ is a local diffeomorphism onto its image , $F(N)$ (under the subspace topology) if A1. $F(N)$ is a regular/an embedded submanifold of $M$ , and $\tilde F: N \to F(N)$ is a local diffeomorphism. A2. $F(N)$ may or may not be a regular/an embedded submanifold, but $\tilde F: N \to F(N)$ is still a ""local diffeomorphism"", defined based on An Introduction to Manifolds by Loring W. Tu Definition 22.1 and Remark 22.5 or ""Diffeomorphisms of subsets of manifolds"" from Wikipedia , where such definition may or may not imply $F(N)$ is a regular/an embedded submanifold. Other I think (A1) is equivalent to all of the following A1.1. the definition in the second link above , as I try to prove here . A1.2. a local embedding that is open onto its image. In particular I think this is precisely what the definition in the second link above is. A1.3. an immersion that is open onto its image, since immersions are equivalent to local embeddings. With (A1), we have for $X$ and $Y$ smooth manifolds with dimensions . Local diffeomorphism: A map $f:X\to Y$ ,
is a local diffeomorphism , if for each point x in X, there exists an open set $U$ containing $x$ , such that $f(U)$ is a submanifold with dimension of $Y$ , $f|_{U}:U\to Y$ is an embedding and $f(U)$ is open in $Y$ . (This says nothing about the manifold status of $f(X)$ explicitly, but it will turn out $f(X)$ is open in $Y$ . Similarly, each $f(U)$ is an open submanifold of $Y$ , a.k.a. regular/embedded submanifolds, of $Y$ , of codimension 0.) Local diffeomorphism onto image: A map $f:X\to Y$ ,
is a local diffeomorphism onto image , if for each point x in X, there exists an open set $U$ containing $x$ , such that $f(U)$ is a submanifold with dimension of $Y$ , $f|_{U}:U\to Y$ is an embedding and $f(U)$ is open in $f(X)$ . (This says nothing about the manifold status of $f(X)$ explicitly, but it will turn out $f(X)$ is a regular/an embedded submanifold of $Y$ . Similarly, each $f(U)$ is a regular/an embedded submanifold of $Y$ , in addition to of $f(X)$ .) Local embedding/Immersion: A map $f:X\to Y$ ,
is a local embedding /an immersion , if for each point x in X, there exists an open set $U$ containing $x$ , such that $f(U)$ is a submanifold with dimension of $Y$ and $f|_{U}:U\to Y$ is an embedding. (This says nothing about the manifold status of $f(X)$ explicitly, but it will turn out $f(X)$ is an immersed submanifold of $Y$ . However, each $f(U)$ is a regular/an embedded submanifold of $Y$ .) Note: Depending on your definition of embedding , "" $f(U)$ is a submanifold with dimension of $Y$ "" may be redundant in the 3 preceding definitions. Therefore, (A1) gives us: B1. $\text{local diffeomorphism} \implies \text{local diffeomorphism onto image} \implies \text{immersion and image is submanifold} \implies \text{immersion} \iff \text{local embedding}$ B2. $\text{surjective local diffeomorphism} \iff \text{surjective local diffeomorphism onto image}$ B3. $\text{local diffeomorphism onto image} \iff \text{immersion and open onto image} \iff \text{immersion and image is submanifold}$ (B3) is related to this and this , I guess. B4. $\text{local diffeomorphism onto image} \nLeftarrow \text{immersion}$ B5. $\text{local diffeomorphism} \iff \text{local diffeomorphism onto image and image is open} \iff \text{local diffeomorphism onto image and open map}$ (B5) is related to this and this , I guess. However, the first and third posts above suggest immersions are ""local diffeomorphisms onto images"" , contrary to(B4). Thus, I think the definition in those is different from the one in the second post unless those immersions have submanifold images, by (B3). Since immersions are equivalent local embeddings and embeddings are equivalent to diffeomorphisms onto submanifold images, we might say immersions are local-(diffeomorphisms onto images). Therefore, my understanding of what's going on is that there is a distinction between $$\text{(local diffeomorphism)-onto image} \ \text{and} \ \text{local-(diffeomorphism onto image).} \tag{C1}$$ The first and third posts above describe immersions as local embeddings and so use definition (A2) or of local embedding (I didn't check if (A2) is equivalent to immersion) unless those immersions have submanifold images, by (B3) while the second link above uses definition (A1) which is stronger and not equivalent to immersion by (B4). In the first post, I think the idea is weakening a diffeomorphism $F$ not to an immersion $F$ but to an immersion $F$ with submanifold image , i.e. a local diffeomorphism onto image. Update : I think this is what happened. It's really just immersion, and the comments in the first post, both the one of user10354138 and the one of lEm, are mistaken unless they define ""local diffeomorphism onto image"" as local-(diffeomorphism onto image), i.e. local embedding, i.e. immersion. However their idea is right. Their idea was still to define the pushforward of vector fields. Since $F$ is not a diffeomorphism, get another diffeomorphism to define pushforward. For each $p \in N$ , we hope that there exists a $U$ such that $F(U)$ is a submanifold of $M$ and $\tilde{F|_{U}} : U \to F(U)$ is a diffeomorphism. We have $\tilde{F|_{U}}$ as our required diffeomorphism not only when $F$ is a local diffeomorphism or a local diffeomorphism onto image but also when $F$ is an immersion, i.e. a local embedding (where $F(U)$ is not necessarily open in either $F(N)$ or in $M$ but is still a submanifold of $M$ ): This is because $F(U)$ is a submanifold of $M$ in all 3 cases! In the third post, there may be an additional assumption besides just immersion. I may have missed something.","['smooth-manifolds', 'manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3298688,Is it legal to say $f(E)=\emptyset$ if set $E$ not in the function $f$ domain,"In many inverse functions, I have seen $f^{-1}(E)=\emptyset$ , where the set $E$ is not in the function $f$ range. So, is it also right to say $f(E)=\emptyset$ if set $E$ not in the function domain.",['functions']
3298695,What is the mistake in this solution?,"Problem: Solve the initial value problem $y’=3y; y(0)=a>0$ . My solution: Exploiting variable separable method, $${dy\over y}=3\, dx$$ $$\implies\ln |y|=3x+C$$ where $C$ is the constant of integration. Now using $y(0)=a$ and $a>0$ , $\ln a=C$ . $$\therefore\ln |y|=3x+\ln a$$ $$\implies |y|=e^{3x+\ln a}$$ $$\implies y=\pm ae^{3x}$$ But clearly $y=-ae^{3x}$ isn’t a solution for the given problem. So what went wrong?",['ordinary-differential-equations']
3298733,"Differentiability of $ G(x)=\int_{\mathbb R} e^{tx}f(t)dt $ on $ (0,1) $","Let $f\colon\mathbb R\to\mathbb R$ be a non-negative and measurable function, and assume that both $$\int_{\mathbb R} f(t)dt<\infty\ \ \text{and}\ \ \int_{\mathbb R}e^tf(t)<\infty.$$ Show that the integral $G(x)=\int_{\mathbb R} e^{tx}f(t)dt$ is finite when $0\le x\le 1$ . Then prove that the funtion $G(x)$ is continuous on $0\le x\le 1$ , and differentiable on $0<x<1$ . My attempt: It is trivial to show that $G(x)<\infty$ when $0\le x\le 1$ . To show that $G(x)$ is continuous on $0\le x\le 1$ , we need to consider the difference: \begin{align}
G(x_2)-G(x_1)&=\int_{\mathbb R}e^{tx_2}f(t)dt-\int_{\mathbb R}e^{tx_1}f(t)dt\\
&=\int_{\mathbb R}(e^{tx_2}-e^{tx_1})f(t)dt
\end{align} where $x_1,x_2\in [0,1]$ . Note that $$ |(e^{tx_2}-e^{tx_1})f(t)|\le\max\{2f(t), 2e^tf(t),f(t)+e^tf(t)\}\in L^1(\mathbb R), $$ it follows that $$ \lim_{x_2\to x_1} [G(x_2)-G(x_1)]=\int_{\mathbb R}0\cdot f(t)dt=0 $$ i.e., $G(x)$ is continuous on $0\le x\le 1$ . Next, we study the differentiability of $G(x)$ on $(0,1)$ . We have \begin{align}
\frac{G(x_2)-G(x_1)}{x_2-x_1}=\int_{\mathbb R}\frac{e^{tx_2}-e^{tx_1}}{x_2-x_1}f(t)dt
\end{align} and $$ \frac{e^{tx_2}-e^{tx_1}}{x_2-x_1}f(t)=\frac{e^{tx_2}-e^{tx_1}}{tx_2-tx_1}tf(t) .$$ If we let $x_2\to x_1$ , then $$\lim_{x_2\to x_1}\frac{e^{tx_2}-e^{tx_1}}{x_2-x_1}f(t)=e^{tx_1}tf(t).$$ But this time, I cannot find a dominating integrable function $g(t)$ such that $|e^{tx_1}tf(t)|<g(t)$ on $\mathbb R$ . Then how to prove the differentiability of $G(x)$ on $(0,1)$ ?","['derivatives', 'real-analysis']"
3298737,Submersions from $\Bbb T^2$ to $\Bbb S^1$.,"I have a smooth submersion $p:\Bbb T^2\to\Bbb S^1$ . I want to prove the following assertion, with possibly all the details. There is a diffeomorphism $\phi :\mathbb S^1\times \mathbb S^1\to \Bbb T^2$ and an integer $d\geq 1$ such that $$p\circ \phi(z_1,z_2)=z_1^d.$$ This means that $p\circ \phi$ is like projecting onto the first coordinate and applying a  covering space of finite degree $d$ . What I did so far: Since $p$ is a submersion (hence an open map) and $\Bbb T^2$ is compact, $p(\Bbb T^2)$ is both an open subset of $\Bbb S^1$ and compact, so $p$ is onto. Also since $\Bbb T^2$ is compact, $p$ is proper. I think that Ehresmann's lemma says something like "" a proper surjective submersion is a fiber bundle "", so using this fact I know that $p$ is a fiber bundle. The fiber $F$ of this fiber bundle has to be a compact $1$ -dimensional manifold, so there is $d\geq 1$ such that $$F\simeq \coprod_{i\in\{1,\dots,d\}}\Bbb S^1.$$ Here I am stuck because the rest of the proof should use techniques of fiber bundle which I don't really master. I think I can fixe a covering space $q:\Bbb R\to \Bbb S^1$ and I can pull back $p$ as follows: $$\require{AMScd} \begin{CD} X @>{f}>> \Bbb T^2\\ 
@V{h}VV @VV{p}V\\ \Bbb R @>q>> \Bbb S^1 \end{CD}$$ Then $h:X\to \Bbb R$ has to be a trivial $F$ bundle so there is a diffeomorphism $\Phi:\Bbb R\times F\to X$ such that $h\circ \Psi=\pi_1$ . Also I think I am supposed to use the fact that $f$ is a covering space but I'm not even sure this is true. It would be great if somebody coud explain me the details and tell me if I maid a mistake somewhere. A related question I asked before.","['differential-topology', 'fiber-bundles', 'differential-geometry']"
3298744,Mistake in (french) wikipedia on definition of limit?,"In the french wikipedia they say that (for $f:U\to \mathbb R$ where $U$ open) that $\displaystyle \lim_{x\to a}f(x)= \ell$ (where $a\in U$ ) if $$\forall \varepsilon >0, \exists \delta >0: \forall x\in U, |x-a|<\delta \implies |f(x)-L|<\varepsilon .$$ Isn't it wrong ? For example, take $\displaystyle f(x)=\boldsymbol 1_{\{0\}}(x)$ . Then, $\lim_{x\to 0}f(x)=0$ , but according to the french wikipedia definition, it doesn't converges to $0$ since if $\varepsilon <1$ , if $\delta >0$ , then for $x=0$ , we have that $|x-0|<\delta $ , but $|f(x)-0|=1>\varepsilon $ . Is this a mistakes or is it a more general definition that is more restrictive ?","['limits', 'definition', 'real-analysis']"
3298757,Evaluate the limit the following series,"Evaluate the limit $$\lim_{n\to \infty} \sum_{j=1}^n \frac{4j^{2}}{n^3}.$$ I was under the assumption that this would just tend to $0$ after expanding everything because the denominator will grow quicker than the numerator, but apparently this is not the case.","['limits', 'limits-without-lhopital', 'sequences-and-series']"
3298762,Find the range of $f(x) = \sqrt{\log(\cos(\sin x))}$,Find the range of the function $$f(x)=\sqrt{\log(\cos(\sin(x))}.$$ What I did was: $$\log(\cos(\sin(x))) \geq 0$$ Then $$\log_e\cos(\sin(x)) \geq 0$$ The next step of the problem is $$\cos(\sin(x)) \geq e^0$$ This is the part I didn’t understand. Please explain it to me.,"['functions', 'logarithms']"
3298790,Intuition for Riemannian submersions,"Definition: A submersion $f:M\to N$ between Riemannian manifolds is called a Riemannian submersion if for each $p\in M$ , $d_pf:(\ker d_pf)^\perp\to T_{f(p)}N$ is an isometry. In contrast to  Riemannian immersions I find it difficult to get an intuitive understanding of what Riemannian submersions  are. At the moment I think of them as something  like  orthogonal projections but I am not sure if this intuition is always correct. So my questions are: $\bullet$ How can one think of  Riemannian submersions? $\bullet$ What nice properties do Riemannian submersions have in contrast to arbitrary submersions?","['intuition', 'smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
3298797,Even function that is injective,"I have heard/read multiple times that an even function can't be injective. And the proof I see for this is the following: An even function can never be injective because for every $x\neq 0$ we have $x\neq -x$ and $f(x)=f(-x)$ But what about the function: $f(x)=\sqrt{-|x|}+73$ $f$ is defined in $A_f=\{0\}$ For every $x$ and $-x$ in the domain of $f$ , the equation $f(x)=f(-x)$ is true, so the function is even. For every $a,b\in A_f$ , the sentence $f(a)=f(b) \Rightarrow a=b$ is true(since $True \Rightarrow True$ is $True$ ) (and of course the contrapositive sentence is also true). So the function is injective. Am I wrong somewhere? If not, why do so many people(even mathematicians) say that there can't be an even function that is injective even though there are many simple examples like the above?","['even-and-odd-functions', 'functions']"
3298808,Do $3\times3$ matrices with this multiplication property exist?,"I'm doing some novice exploration in what I think is basic abstract algebra and for curiosity reasons, I'm trying to find a matrix representation similar to $a+bi\cong\bigl(\begin{smallmatrix}a&-b\\b&a\end{smallmatrix}\bigr)$ for the complex numbers, for some elements that multiply like this: $$\mathbf{e}_a\cdot\mathbf{e}_b = \mathbf{e}_{(2b-a)\text{ mod }3}$$ That is, there are 3 basis elements that we could call $\mathbf{i}, \mathbf{j}, \mathbf{k}$ , each of which are idempotent, but when one is multiplied by another, it results in the third. For example, $\mathbf{i}^2 = \mathbf{i} = \mathbf{jk}$ . I've tried a couple of different matrix ""representations"" but the product hasn't matched my expectation for the equivalent entries. Does such a representation exist?","['matrices', 'abstract-algebra']"
3298809,linear algebra : show that $~f~$ is a linear map.,"We say that a sequence $(U_n)_{n \in \Bbb N} \subset \mathbb{R}$ is Fibonacci if it satisfies $\ U_{n+2} = U_{n+1} + U_n, \ \forall n \in \mathbb{N}$ .  Let $F$ be the set of all Fibonacci sequences. We have the function $f: F \to \mathbb{R} \times \mathbb{R}$ that exists: $f(U_n) = (U_0,U_1)$ We must demonstrate that $f$ is a linear isomorphism between $F$ and $\Bbb R \times \Bbb R$ . It's it easy to show that $f$ is a linear map. In order to prove that it is an isomorphism, we must demonstrate also that $f$ is one-to-one and and onto. For the injectivity of $f$ , we have $f$ is a linear map so all we have to show is that $\operatorname{ker}(f) = \{0 \}$ . Let $U_n \in \operatorname{ker}(f)$ : then $$
f(U_n) =(0,0) = (U_0,U_1)
$$ since if $n=2:\  U_2 = 0 + 0$ and by double recurrence: $U_{n+1} = U_n = 0$ - so it's easy to show that $U_{n+2} =U_{n+1}= 0$ (the hypothesis of the exercise). Now, since $U_n = 0$ we have $\operatorname{ker}(f)= \{0\}$ then $f$ is one to one. To prove the surjectivity of $f$ we must show that $\operatorname{Im}(f) = \mathbb{R} \times \mathbb{R}$ : now the inclusion $\operatorname{Im}(f) \subseteq \mathbb{R} \times \mathbb{R}$ is trivially true but the second is not. I spend so much time without getting nothing: in sum, how can I prove that $$
\operatorname{Im}(f) \supseteq \mathbb{R} \times \mathbb{R}\;?
$$",['linear-algebra']
3298810,"Let G be a group of order $pqr$,where $p<q<r$ are primes. Prove that the Sylow r-group is normal. [duplicate]","This question already has an answer here : Group of order $pqr$, $p < q < r$ primes (1 answer) Closed 4 years ago . I need to show that there exist unique r-Sylow subgroup. I know that the number of Sylow r-groups denoted by $n_r$ is congruent to $1mod  \ r$ . Also $n_r$ divides $pq$ . So $n_r$ can be $1,p,q,pq$ . But $n_r$ can not be $p$ or $q$ since $r$ is greater than $p$ and $q$ . Now I need to get a contradiction when $n_r$ is $pq$ . Could you please help me on this problem.","['group-theory', 'abstract-algebra', 'sylow-theory']"
3298827,"Does an integral of the form $\int f(x) \, \sqrt{dx}$ have any meaning?","If $f(x)$ is a Riemann-integrable function, what meaning is there to an integral of the form $$\displaystyle\int f(x) \, \sqrt{dx}~?$$ I have read that stochastic processes like Brownian motion may be described by integrals of somewhat unusual forms as $\displaystyle\int dW^2$ . I suppose that $\displaystyle\int f(x) \, \sqrt{dx}$ doesn't represent a random process since $f(x)$ here is defined and deterministic. Any insight would be helpful.","['calculus', 'measure-theory', 'real-analysis']"
3298833,"Given a bit string $x$ of length $n$, how many strings are there that differ from $x$ in exactly $k$ positions?","Given a bit string $x$ of length $n$ , how many strings are there that differ from $x$ in exactly $k$ positions? Also, if we replaced the case with decimal strings, how would it change? I'm a bit stuck. I'm not sure which method to use to solve this question. I'm between whether to use regular permutation, or difference  method, but both of those could still be incorrect. Any insight would be helpful, thank you!","['combinatorics', 'discrete-mathematics']"
3298839,Every Cover of a Compact Real Interval by Open Intervals Has a Finite Subcover where only Consecutive Sets Overlap?,"Intuitively this seems true and would be a useful lemma in proving the fundamental theorem of calculus without assuming continuity of the derivative, i.e. that if $f$ is differentiable on $[a, b$ and the derivative is Riemann integrable then $\int_a^b f' = f(b) - f(a)$ . But is it true and if so is there any standard terminology for such a cover ? My attempt at a proof follows. Let $I = [a, b]$ be a closed bounded interval in $\mathbb R$ . Then (Hiene-Borel theorem) every open cover of open intervals has a finite sub-cover. We can assume that the open intervals have distinct R-endpoints, as for any two with the same R-endpoint one must be contained within the other and the smaller one (or either if the same L-endpoint) can be discarded without affecting the cover. Then these open intervals $\{O_i\ = (a_i, b_i)\}_{i = 1, n}$ can be ordered by their R-endpoints $\{b_i\}_{i = 1, n}$ in a strictly ascending sequence $b_1 < b_2, ...< b_n$ . Claim : from such a set $\{O_i = (a_i, b_i)\}_{i = 1, n}$ we can select a subset which covers $[a, b]$ , renumbered as $\{O'_j = (a'_i, b'_1)\}_{j = 1, m}$ in strictly ascending sequence $b'_1 < b'_2, ...< b'_m$ such that for $|i - j| > 1$ then $O'_i \cap O'_j = \emptyset$ and for $|i - j| = 1$ then $O'_i \cap O'_j \not= \emptyset$ . Construction: Choose $O'_1$ from intervals $O_i$ having $a \in O_i$ and maximizing $b_i$ among such intervals. Iteratively, stop if $b$ is in the last chosen interval $O'_j$ , otherwise, ... Chose $O'_{j+1}$ from intervals $O_i$ having $b'_j \in O_i$ and maximizing $b_i$ among such intervals. Then the set $\{O'_j\}  $ fulfills the requirements. Proof: Since the set $\{O_i\}  $ covers $[a, b]$ then for $a$ in step1 and for every $b'_j$ in the iteration there is an $O_i$ which contains it and since the endpoints are unique there is exactly one which maximizes $b_j$ . Since the $O_i$ chosen as $O'_{j+1}$ contains $b'_j$ and is open then it has a non-empty intersection with $O'_j$ . I.e. consecutive open intervals intersect. The $O_i$ chosen as $O'_{j+1}$ cannot intersect any interval prior to $O'_j$ as this would require it to have been chosen previously in order to maximize $b_j$ .","['general-topology', 'proof-verification', 'real-analysis']"
3298906,Proving that $I+A$ is invertable when $A$ is nilpotent: What intuition leads to a particular approach?,"In an answer to this question , it has been suggested to consider the following: $$(I+A)(\sum_{j=0}^n(-A)^j)$$ Through a series of algebraic operations, it can be shown that $\sum_{j=0}^n(-A)^j$ is in fact the inverse of $I+A$ . How would we have known to multiply by $\sum_{j=0}^n(-A)^j$ ? If there isn't an identity or formula that would indicate such a multiplication is a reasonable avenue of inquiry, then how would we otherwise derive $\sum_{j=0}^n(-A)^j$ ?","['advice', 'matrices', 'abstract-algebra', 'inverse', 'intuition']"
3298993,Generalized limits,"Cross-posted to Mathoverflow . $\DeclareMathOperator{\Lim}{Lim}$ $\DeclareMathOperator{\dom}{dom}$ $\DeclareMathOperator{\shift}{\sigma}$ $\DeclareMathOperator{\cesaro}{C}$ After reading Terry Tao's post on generalizations of the limit functional , I'm interested in the concept of a ""generalized limit"", which agrees with the ordinary limit when the latter exists, but also extends it to new sequences. Let $X$ be a metrized module. A generalized limit is a partial function from sequences of elements of $X$ to $X$ : $$\Lim : \bigcup_{S \subseteq X^\mathbb{N}} X^S$$ Let $\lim$ be the Cauchy limit. That is, $\lim x = a$ iff $$\forall \varepsilon \in \mathbb{R}^+ : \exists N \in \mathbb{N} : \forall n \in \mathbb{N} : n > N \rightarrow d(x(n),a) < \varepsilon$$ $\Lim_1$ is weaker than $\Lim_2$ iff $$\Lim_1 \subseteq \Lim_2$$ $\Lim$ is regular iff it is stronger than $\lim$ . $\Lim_1$ is consistent with $\Lim_2$ iff $$\forall x \in (\dom \Lim_1 \cap \dom \Lim_2) : \Lim_1(x) = \Lim_2(x)$$ $\Lim$ is homogeneous iff $$\forall a \in X : \forall x \in \dom \Lim: \Lim(a x) = a \Lim(x)$$ $\Lim$ is additive iff $$\forall x, y \in \dom \Lim : \Lim(x + y) = \Lim(x) + \Lim(y)$$ $\Lim$ is linear iff it is homogeneous and additive. $\Lim$ is stable iff $$\Lim = \Lim \circ \shift$$ where $\shift : X^\mathbb{N} \rightarrow X^\mathbb{N}$ is the shift transform defined by $$\shift(a)(n) = a(n+1)$$ If $a \neq 1$ and $\Lim$ is stable and homogeneous, then $\Lim (n \mapsto a^n) = 0$ . Proof: \begin{align}
    \Lim (n \mapsto a^n)
    &= (\Lim \circ \shift) (n \mapsto a^n) & \text{(stability)} \\
    &= \Lim(\shift(n \mapsto a^n)) \\
    &= \Lim(n \mapsto a^{n+1}) \\
    &= \Lim(a (n \mapsto a^n)) \\
    &= a \Lim(n \mapsto a^n) & \text{(homogeneity)} \\
    (1 - a) \Lim(n \mapsto a^n) &= 0 \\
    \Lim(n \mapsto a^n) &= 0
\end{align} Note that if $a$ is prime then this yields the correct $a$ -adic limit . This also yields the expected generalized sum of a geometric series: \begin{align}
    \sum_{n=0}^\infty a^n
    &= \Lim\left(m \mapsto \sum_{n=0}^m a^n\right) \\
    &= \Lim\left(m \mapsto \frac{1-a^{m+1}}{1-a}\right) \\
    &= \frac{1 - \Lim(m \mapsto a^{m+1})}{1-a} \\
    &= \frac{1}{1-a} \\
\end{align} Consequently, if $\Lim$ is stable and linear then \begin{align}
  \Lim_{n \rightarrow \infty} \cos n
  &= \Lim_{n \rightarrow \infty} \frac{\mathrm{e}^{in} + \mathrm{e}^{-in}}{2} \\
  &= \frac{\Lim_{n \rightarrow \infty} (\mathrm{e}^{i})^n + \Lim_{n \rightarrow \infty} (\mathrm{e}^{-i})^n}{2} \\
  &= 0
\end{align} and the same is true of $\sin$ , we also have \begin{align}
  \Lim_{m \rightarrow \infty} \sum_{n=0}^m \cos n
  &= \Lim_{m \rightarrow \infty} \left(\frac{1}{2} + \frac{\cos(m)}{2} + \frac{1}{2} \cot \frac{1}{2} \sin m\right) \\
  &= \frac{1}{2} \\
  \Lim_{m \rightarrow \infty} \sum_{n=0}^m \sin n
  &= \Lim_{m \rightarrow \infty} \left(\frac{1}{2} \cot \frac{1}{2} + \frac{\sin m}{2} - \frac{1}{2} \cos m \cot \frac{1}{2}\right) \\
  &= \frac{1}{2} \cot \frac{1}{2}
\end{align} More generally, if $a \neq 1$ and $\Lim$ is stable and linear then \begin{align}
  \Lim_{m \rightarrow \infty} \sum_{n=0}^m a^n n^b
  &= \Lim_{m \rightarrow \infty} (\mathrm{Li}_{-b}(a) - a^{m+1} \Phi(a,-b,m+1)) \\
  &= \mathrm{Li}_{-b}(a) + \Lim_{m \rightarrow \infty} a^{m+1} \Phi(a,-b,m+1) \\
  &= \mathrm{Li}_{-b}(a)
\end{align} \begin{align}
  \Lim_{m \rightarrow \infty} \sum_{n=0}^m a^n n!
  &= \Lim_{m \rightarrow \infty} \left( -\frac{\mathrm{e}^{-1/a} \Gamma(0,-1/a)}{a} + (-1)^{m+1} \frac{\mathrm{e}^{-1/a} \Gamma(-m-1,-1/a) (m+1)!}{a} \right) \\
  &= -\frac{\mathrm{e}^{-1/a} \Gamma(0,-1/a)}{a} + \Lim_{m \rightarrow \infty} (-1)^{m+1} \frac{\mathrm{e}^{-1/a} \Gamma(-m-1,-1/a) (m+1)!}{a} \\
  &= -\frac{\mathrm{e}^{-1/a} \Gamma(0,-1/a)}{a}
\end{align} where $\mathrm{Li}$ is the polylogarithm and $\Phi$ is the Lerch transcendent. Thus the properties of stability and linearity alone make the generalized limit quite powerful. Question: Is there a $\Lim$ such that $\Lim$ can be explicitly defined in terms of the Cauchy limit, e.g. $\Lim = \lim \circ f$ where $f$ is some sequence transform. $\Lim$ is stronger than (i.e. contains) the stable and linear closure of the Cauchy limit. The Cesàro transform $\cesaro : X^\mathbb{N} \rightarrow X^\mathbb{N}$ yields the sequence of partial averages: $$\cesaro(a)(n) = \frac{1}{n+1}\sum_{k=0}^n a(k)$$ For $n \in \mathbb{N}$ , let the $n$ -Cesàro limit be the Cauchy limit of the Cesàro transform iterated $n$ times: $$\lim \circ \cesaro^n$$ The $n$ -Cesàro limit is regular, linear, and stable. Moreover, $$\lim \circ \cesaro^n \subsetneq \lim \circ \cesaro^{n+1}$$ The inclusion is proper as can be seen by taking the sequence $$k \mapsto (-1)^k k^n$$ which is in the domain of the latter but not the former. Let the $\omega$ -Cesàro limit be the union of all such limits: $$\bigcup_{n < \omega} \lim \circ \cesaro^n$$ That is, the $\omega$ -Cesàro limit is the closure of the Cauchy limit under Cesàro transforms. My question is this: Are there any interesting examples of linear limits that are (non-strictly) stronger than the $\omega$ -Cesàro limit? What about stronger than the closure of the $\omega$ -Cesàro limit under stability (shift transforms)? This last property would allow it to regularize geometric limits. Note: It would not have to be stable itself, just stronger than the stable closure of the $\omega$ -Cesàro limit. I suspect sequence transformations used to accelerate the rate of convergence of sequences, like the Shanks transformation and Aitken's delta-squared process , might be useful here.","['convergence-acceleration', 'functional-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
3298998,"Prove that if $23 ∣ (3a + 5b + 7c)$, then $23 ∣ (14a + 8b + 2c)$. [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Prove that if $23 ∣ (3a + 5b + 7c)$ , then $23 ∣ (14a + 8b + 2c)$ . My attempt: I am trying to use the fact that $$gcd(23,3)=gcd(23,5)=gcd(23,7) = 1,$$ but I don't know how to proceed from there.","['number-theory', 'divisibility', 'discrete-mathematics']"
3299017,How to prove that $\lim_{x\to 0+}\left[\frac{1}{x^{3/2}}-\frac{1}{x^{1/2}\sin(x)}\right]=0$?,"This exercise $$\lim_{x\to 0+}\left[\frac{1}{x^\frac{3}{2}}-\frac{1}{x^\frac{1}{2}\sin(x)}\right]$$ was in my calculus III test at college, after trying hard to solve it I was not really able to do so, I know intuitively that this limit equals 0 but did not find an appropriate way to prove it, as the limit gives an indeterminate form $\infty - \infty$ . I worked out the fractions and got $$\lim_{x\to 0+}\frac{x^\frac{1}{2}\sin(x) - x^\frac{3}{2} }{x^2\sin(x)}$$ which gives me an indeterminate form $\frac{0}{0}$ , then using L'hopitals rule, the limit starts getting uglier as more indeterminate forms keep showing up. My college test is over, but, still I want to find out how to solve this limit, any help would be highly appreciated.","['limits', 'calculus', 'trigonometry']"
3299097,Help understanding separation of variables technique,Find the general solution of $$(x_{}^2 + 4)\frac{{dy}}{{dx}} = xy$$ After separating variables $$\frac{dy}{y} = \frac{x}{x^2 + 4}dx$$ What I don't understand is my textbook's result after integrating... $$\int \frac{dy}{y} = \int \frac{x}{x^2 + 4}$$ $$\ln \left| y \right| = \frac{1}{2} \ln(x^2 + 4) + C_1$$ which they said resulted in... $$\ln \left| y \right| = \ln \sqrt{x^2 + 4}  + C_1$$ What I want to know is how the $\frac12$ disappeared after integrating and how they came to simplifying it with a square root. I appreciate any constructive insight. Thank you!,"['multivariable-calculus', 'ordinary-differential-equations']"
3299172,Resistant integral $\int_0^1\left(\frac{\ln^2(1-x)\ln^2(1+x)}{1-x}-\frac{\ln^2(2)\ln^2(1-x)}{1-x}\right)\ dx$,"Prove, without using harmonic series, that $$I=\int_0^1\left(\frac{\ln^2(1-x)\ln^2(1+x)}{1-x}-\frac{\ln^2(2)\ln^2(1-x)}{1-x}\right)\ dx$$ $$=\frac18\zeta(5)-\frac12\ln2\zeta(4)+2\ln^22\zeta(3)-\frac23\ln^32\zeta(2)-2\zeta(2)\zeta(3)+\frac1{10}\ln^52+4\operatorname{Li}_5\left(\frac12\right)$$ This problem was proposed by Cornel and can be found here . The main reason behind such constraint is that this integral can be simplified into $S=\sum_{n=1}^\infty\frac{H_n}{n^42^n}$ which was calculated here using real and complex methods. So evaluating $I$ without using harmonic series means we are providing a third solution to $S$ . I have already computed this integral ( will be posted soon) but I would like to see variant approaches. Thanks. Added: In case the reader is curious about how this integral is related to $\sum_{n=1}^\infty\frac{H_n}{n^42^n}$ , here is the steps By integration by parts we have \begin{align}
I&=\frac23\int_0^1\frac{\ln^3(1-x)\ln(1+x)}{1+x}\ dx\overset{\color{red}{1-x\ \mapsto\ x}}{=}\frac13\int_0^1\frac{\ln^3x\ln(2-x)}{1-x/2}\ dx\\
&=\frac{\ln2}{3}\int_0^1\frac{\ln^3x}{1-x/2}\ dx+\frac13\int_0^1\frac{\ln^3x\ln(1-x/2)}{1-x/2}\ dx\\
&=\frac{\ln2}{3}\sum_{n=1}^\infty\frac{1}{2^{n-1}}\int_0^1x^{n-1}\ln^3x\ dx-\frac13\sum_{n=1}^\infty\frac{H_n}{2^n}\int_0^1x^n\ln^3x\ dx\\
&=\frac{\ln2}{3}\sum_{n=1}^\infty\frac{1}{2^{n-1}}\left(-\frac{6}{n^4}\right)-\frac13\sum_{n=1}^\infty\frac{H_n}{2^n}\left(-\frac{6}{(n+1)^4}\right)\\
&=-4\ln2\sum_{n=1}^\infty\frac{1}{n^42^n}+2\sum_{n=1}^\infty\frac{H_n}{(n+1)^42^n}\\
&=-4\ln2\operatorname{Li}_4\left(\frac12\right)+4\sum_{n=1}^\infty\frac{H_n}{n^42^n}-4\operatorname{Li}_5\left(\frac12\right)
\end{align}","['integration', 'real-analysis', 'alternative-proof', 'harmonic-numbers', 'calculus']"
3299184,Why is the mean curvature usually denoted by $H$?,"Soft question. For surfaces in $\Bbb R^3$ (for example), there are two relevant curvatures: the Gaussian curvature $K$ , and the mean curvature $H$ . Thinking here, I realized that while calling the Gaussian curvature $K$ makes sense (since in German curvature is Krümmung ), I have no idea why is the mean curvature denoted by $H$ . Is there any historical reason, or some word in German (or any other language) I'm missing?","['notation', 'math-history', 'riemannian-geometry', 'differential-geometry']"
3299202,Evaluate $\int_{0}^{\infty} \frac{\sin x-x\cos x}{x^2+\sin^2x } dx$,"The integral $$\int_{0}^{\infty} \frac{\sin x-x\cos x}{x^2+\sin^2x } dx$$ admits
a nice closed form. The question is: How to evaluate it by hand.","['integration', 'definite-integrals']"
3299303,d(vector)/d(matrix) in neural-network-deep-learning context,"When learning about Neural Networks, you are bound to stumble upon the technique of backpropagation/gradient descent. To give a brief explanation of the scenario we are to look at, $$L = g(Wx+b) = g(a).$$ L is a scalar, W is a matrix of appropriate size, x is a vector given as input, b is a vector of appropriate size. g is a function that takes a vector of appropriate size and evaluates a scalar. W and b are to be updated in the opposite direction of the gradient,    so that L can be minimized . Many textbooks, lectures and blogs, including Speech and Language Processing (3rd ed. draft) or CS231n, use notations(See page 5) that look like this. $$\frac{\partial L}{\partial V} = \frac{\partial L}{\partial a} \frac{\partial a}{\partial z} \frac{\partial z}{\partial V}$$ here, L is the ""loss function"" defined above, a, z are vectors of appropriate size, and V is a matrix of parameters, like W discussed above. Overall this equation was written so that we may find the derivative of L by ""the weights"" V. From this, it seems only logical to assume that we may attempt to get $\frac{\partial L}{\partial W}$ in this manner. $$\frac{\partial L}{\partial W} = \frac{\partial g}{\partial a} \frac{\partial a}{\partial W}$$ But here is the problem I have with both expressions: on the right-hand side, there is a derivation of a vector by a matrix. Now, from a few sources I know that the notation nor the multiplication of this Frankenstein is not defined rigorously, if it is defined at all. Since we typically add $\eta \frac{\partial L}{\partial W}$ to $W$ directly, we must be following the Denominator-layout notation as explained here , but I can't seem to figure the $\partial a/\partial W$ part out. I did look over as many blogposts as I can, but virtually none of them actually show how the calculation should be done. So my question is as follows. Is that kind of notation(da/dW) even legal? If it is legal, how should it be evaluated and multiplicated in this context? Can you give an example? Is da/dW possible to evaluate without doing it term-by-term?(evaluating da/dW11, da/dW12, ... and compiling them up later in some way.) What about dL/dW? Thank you in advance.","['neural-networks', 'multivariable-calculus', 'matrix-calculus', 'gradient-descent', 'derivatives']"
3299315,Is a function differentiable if it has a removable discontinuity,"There are many questions on Math Stack Exchange asking if a function is differentiable if it has a removable discontinuity at $x=a$ .  But, I'm having trouble following the answers. I get the impression, from reading here on Stack Exchange and elsewhere that such a function is not differentiable but I don't understand why. Consider the following equation: $f(x)=\frac{x^3}{x}$ .  The function is undefined at $x=0$ but it is clearly differentiable.  First by simplifying: $\frac{d}{dx}\frac{x^3}{x}=\frac{d}{dx}x^2=2x$ Or, using the quotient rule: $\frac{d}{dx}\frac{x^3}{x}=\frac{3x^2\cdot x-x^3\cdot 1}{x^2}=\frac{3x^3-x^3}{x^2}=\frac{2x^3}{x^2}=2x$ And, finally, my calculator agrees. Therefore, it is established that the function is differentiable and has a derivative at every x-value in its domain, including the troublesome $x=0$ . I conclude that a function is differentiable at $x=a$ if the discontinuity is removable . The only thing I can think of that would make this untrue is the idea that I have changed the original function $f(x)$ by removing the discontinuity with some algebra and I am really differentiating a different function (call it $g(x)$ ) that is not quite the same at the one point of interest.  That argument would be more persuasive if I had simply simplified first and then differentiated.  There I was clearly differentiating a different equation.  But, I did not simplify when applying the quotient rule and I obtained the same answer.  So, the argument seems weak, at best.","['continuity', 'calculus', 'derivatives']"
3299369,Is an Uncountable Set and a Continuous Set the Same Thing?,"An Uncountable set is a set that has no existence of bijection with $Z$ . Is it the same as a continuous set ? Suppose $[0,1]$ is both uncountable and continuous. If both are different, please provide an example to clarify it. Background : I got this doubt because of the following statement from Introduction To Probability by Dimitri P. Bertsekas Probabilistic models with continuous sample spaces differ from their
  discrete counterparts in that the probabilities of the single-element
  events may not be sufficient to characterize the probability law","['elementary-set-theory', 'definition']"
3299395,Comparing two close numbers,"How to compare these two numbers without using a calculator ? $A=\left(\dfrac{11}{10}\right)^{\sqrt{5}}$ and $\;B=\left(\dfrac{12}{11}\right)^{\sqrt{6}}$ . Thanks for your help ! Here is what I tried for example : $$\left(\frac{A}{B}\right)^{\sqrt6-\sqrt5}=\frac{11}{10^{\sqrt{30}−5}12^{6−\sqrt{30}}}.$$ ln is concave, so $$10^{\sqrt{30}−5}12^{6−\sqrt{30}}\leq10(\sqrt{30}−5))+12(6−\sqrt{30})=22−2\sqrt{30}.$$ But $$22−2\sqrt{30}\approx11,05...$$","['contest-math', 'inequality', 'number-comparison', 'analysis']"
3299419,"Using Cauchy's integral formula to solve $\int_{|z| = 2} \frac{e^z}{z^2(z-1)}\,dz$","On p. 116 in Complex Analysis by Gamelin, he has just introduced some examples of the application of the Cauchy Integral Formula (CIF). He then considers the integral $$\int_{|z| = 2} \frac{e^z}{z^2(z-1)}\,dz$$ which cannot immediately be solved using CIF. He introduces a way to solve this by cutting out two discs of radius $\epsilon$ centered at $0$ , and $1$ to obtain, $$\int_{|z| = 2} \frac{e^z}{z^2(z-1)}\,dz = \int_{|z| = \epsilon} \frac{e^z}{z^2(z-1)}\,dz + \int_{|z-1| = \epsilon} \frac{e^z}{z^2(z-1)}\,dz.$$ What makes it ok to do this cut out of discs? He do not mention his reasoning.My guess is that since we want the theorem to be applicable we need to take care of the singularities in some way and I do agree with him in applying the theorem to the two new integrals around the two epsilon discs. Is the ""formal"" argument for doing what he did that since the discs with radius $\epsilon$ union with the disc $\{|z| = 2\}$ 1 is a bounded domain with piecewise smooth boundary, and since the integrands $f(z) = \frac{e^z}{z-1}$ and $f(z) = \frac{e^z}{z^2}$ are analytic on $\{|z|=\epsilon\}$ and $\{|z-1|=\epsilon\}$ respectively, we can be guaranteed that it works? However, what is meant by it ? Do we let $\epsilon \to 0$ ? All help is appreciated, thank you!","['complex-analysis', 'contour-integration', 'cauchy-integral-formula']"
3299509,"Why have we defined ""average"" as $a_1 + a_2 + \cdots + a_N\over N$ only?","I am graduate student in Physics and I have taken a graduate level course called Probability and Statistics as an elective. The professor told me that in this course will take a Measure theoretic perspective to the theory of Probability and Statistics. In the first lecture, he posed a problem (among others) that why do we define ""averages"" as $a_1 + a_2 + \cdots + a_N\over N$ ? One may say that is our intuition, but is it really the average ? By an Average , we tend to find a number that roughly tells us the ""general"" picture about the data we have at hand. With averages, of course, we need to have another information about the variance , that is how spread our data is? But does our formal definition of ""sum divided by the number of data points"" really does what it is intended to do? Why don't we have any of the following as the definition of averages? $\sqrt{a_1^2 + a_2^2 + \cdots + a_N^2\over N}$ (we use this in physics a lot) $\left(\frac{a_1^p + a_2^p + \dots + a_N^p}{N}\right)^{1/p}$ $(a_1a_2\cdots a_N)^{1/N}$ $\exp{(\ln{a_1}\ln{a_2}\cdots\ln{a_N})^{1/N}}$ I assume that there must be a way to quantify the effectiveness of these averages and there must be a more effective measure of our intutive average than just $a_1 + a_2 + \dots + a_N\over N$ . Can someone help me out with this? Thank you in advance!","['statistics', 'measure-theory', 'probability']"
3299525,Showing that the $T: \operatorname{dom}(T) \to \ell^{2}$ is closed,"Let $T:\operatorname{dom}(T) \to \ell^{2}$ where $T(x^{n})=(mx_{m}^{n})_{m \in \mathbb N}$ Let $\operatorname{dom}(T):=\{x^{n}\in \ell^{2}: (mx_{m}^{n})_{m \in \mathbb N} \in \ell^{²}\}$ Determine whether $T$ is closed or not: Initially I attempted to show that $T$ is closed, by assuming a $(x^{n})_{n} \subseteq \ell^{2}$ where $x^{n}\xrightarrow{n \to \infty, \vert \vert \cdot \vert \vert_{2}} x$ and $T(x^{n})\xrightarrow {n \to \infty, \vert \vert \cdot \vert \vert_{2}}y$ . In order to show that $x \in \operatorname{dom}(T)$ , note that from $x^{n}\xrightarrow{n \to \infty, \vert \vert \cdot \vert \vert_{2}} x$ that it follows: $\lim\limits_{m \to \infty}x^{m}_{i}=x_{i}$ for all $ i \in \mathbb N$ and hence let $N \in \mathbb N$ arbitrary: First question: convergence in $\ell^{p}, 1\leq p<\infty$ of $(x^{n})_{n}$ to $x$ does imply convergence in each respective
  coordinate, correct? $\sum\limits_{i=1}^{N} \vert x_{i} \vert^{2}=\lim\limits_{m\to \infty}\sum\limits_{i=1}^{N} \vert x_{i}^{m} \vert^{2}\leq\lim\limits_{m\to \infty}\vert\vert x^{m}\vert\vert_{2}^{2}$ , but this estimate does not help me. So, I now believe that it may not be closed. Any ideas on showing that it is not closed.","['operator-theory', 'real-analysis', 'lp-spaces', 'functional-analysis', 'closed-graph']"
3299590,Prove: $(A-B)\cup(B-C)=(A\cup B)-(B\cap C)$,"The first part is not that of a problem, but the second part: $$(A\cup B)-(B\cap C)\to (A-B)\cup(B-C)$$ is giving me a hard time. Trying to solve $(A-B)\cup(B-C)=(A\cup B)-(B\cap C)$ using set operations is equally confusing, as I reach this part: $$(A\cup (B-C))-(B\cap C)$$ But don't know how to go from there to $(A\cup B)-(B\cap C)$ . Your help is appreciated. Thank you","['elementary-set-theory', 'discrete-mathematics']"
3299619,"Let $\mathbb F$ be a field, find a necessary and sufficient condition on $\mathbb F$ such that the only semi-polynomial maps are the polynomials.","Let $\mathbb F$ be a field. A map $f : \mathbb F^2 \rightarrow \mathbb F$ is semi-polynomial if for every fixed $y$ the map $ x \rightarrow f(x,y)$ is a polynomial and for every fixed $x$ the map $y \rightarrow f(x,y)$ is a polynomial. I'm trying to find a necessary and sufficient condition on $\mathbb F$ such that the only semi-polynomial maps are the polynomials. Any ideas would be appreciated.","['field-theory', 'abstract-algebra', 'polynomials']"
3299625,Conjugate transpose of matrix is the adjoint intuition,"I'm having a bit of trouble understanding this fact from Linear Algebra Done Right Let T $\in \mathcal{L}(V, W)$ Suppose $e_{1}, \dots, e_{n}$ is an
  orthonormal basis of $V$ and $f_{1}, \ldots, f_{m}$ is an orthonormal
  basis of $W$ . Then then adjoint $T^{*}$ is the conjugate transpose of $T$ in $\langle T v, w\rangle=\left\langle v, T^{*} w\right\rangle$ I went through the proof and did an example but I can't get a clearer picture as to why this must be true intuitively or geometrically. What is so special about a transpose that makes the transformation act in this bridge-like fashion? Also, I am also not able to appreciate the fact that we have an orthonormal basis, while it is important in the proof, what would go wrong if we didnt? Here's the entire proof for reference:","['matrices', 'abstract-algebra', 'linear-algebra']"
3299636,Is is incorrect to integrate multiple surfaces when using Stokes Theorem,"So far, I have understood that when using Stokes Theorem to find the flux of the curl on a solid that has a boundary, one can use any of the surfaces of that solid. For example in my book for this problem (Transcendental Functions, Smith and Minton 14.8 #13) $C$ is the boundary of the portion of the paraboloid $y = 4 − x^2 − z^2$ with $y > 0$ , $\mathbf n$ to the right, $F = \langle x^2z, 3 \cos y, 4z^3 \rangle$ . the solution is to just integrate over the disc $x^2+z^2 \le 4$ . However, elsewhere it says to integrate multiple surfaces! For example, here (Transcendental Functions, Smith and Minton 14.8 #23) $ S$ is the boundary of the solid bounded by the hyperboloid $x^2 + y^2 − z^2 = 4$ , $z = 0$ and $z = 2$ with $z < 2$ , $\mathbf n$ downward
  at bottom, $F = \langle 2^y − x \cos x, y^2 + 1, e^{−z^2} \rangle$ it says to integrate two surfaces, the portion of the hyperboloid and the circle with radius 2. Is there something different about the second problem causing them to integrate over two surfaces, or is there a mistake?","['vector-fields', 'multivariable-calculus', 'surface-integrals', 'stokes-theorem']"
3299669,A multitude of challenging logarithmic integrals (Second part),"In this post I list another group of integrals from the new preprint ""The derivation of eighteen special challenging logarithmic integrals"" by Cornel Ioan Valean where they are nicely evaluated. The following equalities hold: \begin{equation*}
i) \ \int_0^1 \frac{x \log ^3(x)\log (1-x) }{1+x^2} \textrm{d}x=\frac{1761}{512} \zeta (5)-\frac{3}{32} \pi ^2 \zeta (3)-\frac{9}{256}\log (2)\pi ^4;
\end{equation*} \begin{equation*}
ii) \ \int_0^1 \frac{x \log ^3(x)\log (1+x) }{1+x^2} \textrm{d}x=\frac{7}{256}\log (2)\pi ^4+\frac{3}{64} \pi ^2 \zeta (3)-\frac{1215}{512} \zeta (5);
\end{equation*} \begin{equation*}
iii) \ \int_0^1 \frac{x\log^5(x)\log (1-x) }{1+x^2} \textrm{d}x=\frac{129495}{2048}\zeta (7)-\frac{75 }{128}\pi ^2 \zeta (5)-\frac{\pi ^4}{8} \zeta (3)-\frac{33}{512} \log (2)\pi ^6;
\end{equation*} \begin{equation*}
iv) \ \int_0^1 \frac{x\log^5(x)\log (1+x) }{1+x^2} \textrm{d}x=\frac{31}{512}\log(2)\pi ^6+\frac{7}{64} \pi ^4 \zeta (3)+\frac{75}{256}\pi^2 \zeta (5)-\frac{114345 }{2048}\zeta (7);
\end{equation*} \begin{equation*}
v) \ \int_0^1 \frac{x\log^7(x)\log (1-x) }{1+x^2} \textrm{d}x
\end{equation*} \begin{equation*}
=\frac{42010605}{16384}\zeta (9)-\frac{6615}{1024} \pi ^2 \zeta (7)-\frac{105}{64} \pi ^4 \zeta (5)-\frac{\pi ^6 }{2}\zeta (3)-\frac{2193}{8192}  \log (2)\pi ^8;
\end{equation*} \begin{equation*}
vi) \ \int_0^1 \frac{x\log^7(x)\log (1+x) }{1+x^2} \textrm{d}x
\end{equation*} \begin{equation*}
=\frac{2159}{8192}\log(2)\pi ^8+\frac{31}{64} \pi ^6 \zeta (3)+\frac{735}{512} \pi ^4 \zeta (5)+\frac{6615}{2048} \pi ^2 \zeta (7)-\frac{40403475}{16384} \zeta (9).
\end{equation*} Question : How would you calculate the integrals by using harmonic series? Are these integrals known in the mathematical literature? For people that took interest in the Problem 11966 from The American Mathematical Monthly, \begin{equation*}
 \int_0^1 \frac{x\log (1+x) }{1+x^2} \textrm{d}x,
\end{equation*} you might want to observe that the integrals from this post contain some additional logs, and in a way can be viewed as more advanced integrals of the one from AMM. The Problem 11966 may also be found in the book (Almost) Impossible Integrals, Sums, and Series , and in the same book there is the identity 3.62 , page 97, (possibly new in the mathematical literature) which has been used for the calculation of these integrals in the present preprint.","['integration', 'real-analysis', 'complex-analysis', 'calculus', 'sequences-and-series']"
3299713,What is the difference between the stalk of a sheaf at a point and the section of said sheaf over that point?,"I'm asking this question with a particular regard to the geometric aspect(s) of the difference(s). Let there be a sheaf $\mathcal{F}: Top(X)^{op} \rightarrow \mathfrak{Ab}$ , with $Top(X)$ being the category whose objects are open subsets of X, and whose morphisms are inclusions, and $\mathfrak{Ab}$ is the usual category of abelian groups. What then, is the difference between the section $\mathcal{F}(P)$ and the stalk $\mathcal{F}_P$ , where $P$ is some point in the topological space $X$ . I suspect that they might be the same, perhaps up to isomorphism, but I don't have a good way of confirming this. Would I be correct in suspecting this, and even if not, why ? Thank you for your time.","['algebraic-geometry', 'sheaf-theory']"
3299717,A multitude of challenging logarithmic integrals (Third part),"In this post you'll find the last group of logarithmic integrals from the new preprint ""The derivation of eighteen special challenging logarithmic integrals"" by Cornel Ioan Valean which are evaluated beautifully by fruitfully combining the Fourier series and the integral representation of the Polylogarithm given in Section 1.6, page 4, from the book (Almost) Impossible Integrals, Sums, and Series (it is also stated in the preprint - see Lemma 4), to turn the single integrals into double integrals. The following equalities hold: \begin{equation*}
i) \ \int_0^1 \frac{\log ^2(x)}{x}\operatorname{Li}_2\left(\frac{2 x}{1+x^2}\right) \textrm{d}x=\frac{3}{64}\log (2)\pi ^4 +\frac{5}{48}\pi ^2 \zeta (3)-\frac{31}{128} \zeta (5);
\end{equation*} \begin{equation*}
ii) \ \int_0^1 \frac{\log ^2(x)}{x}\operatorname{Li}_2\left(-\frac{2 x}{1+x^2}\right) \textrm{d}x=-\frac{7}{192}\log (2)\pi ^4-\frac{1}{12}\pi ^2\zeta (3)-\frac{31}{128} \zeta (5);
\end{equation*} \begin{equation*}
iii) \ \int_0^1 \frac{\log^4(x)}{x}\operatorname{Li}_2\left(\frac{2 x}{1+x^2}\right) \textrm{d}x=\frac{33}{640} \log (2)\pi ^6+\frac{89}{960} \pi ^4 \zeta (3)+\frac{13}{32} \pi ^2 \zeta (5)-\frac{381}{512} \zeta (7);
\end{equation*} \begin{equation*}
iv) \ \int_0^1 \frac{\log^4(x)}{x}\operatorname{Li}_2\left(-\frac{2 x}{1+x^2}\right) \textrm{d}x=-\frac{31}{640}\log (2) \pi ^6-\frac{91}{960}\pi ^4 \zeta (3)-\frac{19}{64} \pi ^2 \zeta (5)-\frac{381}{512} \zeta (7);
\end{equation*} \begin{equation*}
v) \ \int_0^1 \frac{\log^6(x)}{x}\operatorname{Li}_2\left(\frac{2 x}{1+x^2}\right) \textrm{d}x
\end{equation*} \begin{equation*}
=\frac{2193}{14336}\log(2)\pi ^8+\frac{215}{768}\pi ^6 \zeta (3)+\frac{113}{128} \pi ^4 \zeta (5)+\frac{825}{256}\pi ^2 \zeta (7)-\frac{22995}{4096} \zeta (9);
\end{equation*} \begin{equation*}
vi) \ \int_0^1 \frac{\log^6(x)}{x}\operatorname{Li}_2\left(-\frac{2 x}{1+x^2}\right) \textrm{d}x
\end{equation*} \begin{equation*}
=-\frac{2159}{14336}\log (2)\pi ^8-\frac{217}{768}\pi ^6 \zeta (3)-\frac{7}{8}\pi ^4 \zeta (5)-\frac{1185}{512}\pi ^2 \zeta (7)-\frac{22995}{4096}\zeta(9).
\end{equation*} Question: Is it possible to avoid completely the use of Fourier series and calculate it by another route involving harmonic series and generating functions with harmonic series? A note: Starting from these forms and getting integrals from the previous two posts, A multitude of challenging logarithmic integrals (First part) and A multitude of challenging logarithmic integrals (Second part) might be an easier task. However, starting from the previous two groups of integrals and reducing the calculations to the integrals from this post is not something obvious at all. Good to know where we start from! This is assured by the identity: A special dilogarithmic identity . Let $x<1$ be a real number. Then the following equality holds: \begin{equation*}
\int_0^x \frac{t \log (1-t)}{1+t^2} \textrm{d}t=\frac{1}{4} \left(\frac{1}{2} \log^2(1+x^2)-2 \operatorname{Li}_2(x)+\frac{1}{2}\operatorname{Li}_2\left(-x^2\right)+\operatorname{Li}_2\left(\frac{2 x}{1+x^2}\right)\right),
\end{equation*} where $\displaystyle \operatorname{Li}_2(x)=-\int_0^x\frac{\log(1-t)}{t}\textrm{d}t$ is the Dilogarithm function.","['integration', 'real-analysis', 'complex-analysis', 'calculus', 'sequences-and-series']"
3299724,The rank of a symmetric matrix equals the number of nonzero eigenvalues.,"I am wondering why the rank of a symmetric matrix equals its number of nonzero
  eigenvalues. I have tried showing it like this: A symmetrix matrix A can be written: $$A=PDP^T$$ , where P is an orthogonal matrix. It is not difficult to see that for a vector x: $PDP^Tx=0 \leftrightarrow DP^Tx=0$ , 
since P is invertible. So what we need to show is that dimension of the nullspace of $DP^T$ equals the number of eigenvalues with value zero. Do you see how to do this?","['matrices', 'linear-algebra', 'symmetric-matrices']"
3299743,On an asymptotic improvement of AMM problem 11145 (April 2005),"Motivation Motivated by this question , I tried improve the inequality $$\sum_{k=1}^{n}\dfrac{k}{a_{1}+a_{2}+\cdots+a_{k}}\le2\sum_{k=1}^{n}\dfrac{1}{a_{k}}$$ asymptotically. In other words, with support of some numerical evidence, I want to find the value of the following limit. Question Numerical experiment indicates that $$\lim_{n\to \infty}\ln n\left( 2-\sup_{a_k>0 (k=1\ldots n)}\frac{\sum_{k=1}^n{\frac{k}{a_1+a_2+\cdots +a_k}}}{\sum_{k=1}^n{1/a_k}} \right) $$ exists. The limit seems to be approximately $1.5$ . How can we prove it and find its value? Some Trivial Results From this answer we can see that this limit is of form $\infty\cdot0$ . One can apply $\frac{\partial}{\partial a_k}$ to the formula in the $\sup$ and get a simultaneous equation, which is extremely complex and hence almost unsolvable with unknown $n$ .","['summation', 'real-analysis', 'limits', 'inequality', 'supremum-and-infimum']"
3299749,How do you solve $[x]+[2x]+[3x]=4x$ on $\Bbb R$?,"Find the arithmetic average of all solutions $x\in\Bbb R$ of the equation $$[x]+[2x]+[3x]=4x,$$ where $[x]$ denotes the integer part of $x$ (e.g. $[2.5]=2$ , $[-2.5]=-3$ ). I tried solving this problem by looking at $\{x\}$ and writing for example $[2x]$ as $2[x]$ when $\{x\}<1/2$ and $2[x]+1$ when $\{x\}\ge1/2$ . This lead to a lot of cases and after half an hour I literally couldn't go on any longer. I was thinking maybe I can somehow find the arithmetic average without actually knowing the solutions, but couldn't find any way to do that. Any help would be appreciated. :) Thanks!",['algebra-precalculus']
3299809,"What is the intuitive motivation for defining equivalence relations with the properties of reflexivity, symmetry, and transitivity?","I am trying to understand why equivalence relations are defined using the three properties of reflexivity, symmetry, and transitivity. Using an example set of $S = \{1,2,3,4,5,6,7,8,9\}$ It seems to me like a good first intuition is the following: Reflexive An equivalence relation's reflexive property basically ensures that every element in the set under examination can be partitioned (i.e. occupy its own equivalence class). For example, if we had $R_1$ be a relation on $S$ defined as $x-y$ is divisible by $10$ , then, because $(1,1)$ , $(2,2)$ , $(3,3)$ , $etc$ are order pairs that will all satisfy $R_1$ , we will end up with 10 different equivalence classes ( $e.g. [1],[2],[3], etc)$ . Therefore, all elements are partitioned...which makes sense because each of these elements $mod(10)$ have a unique remainder...namely $1$ , $2$ , $3$ , $etc$ Transitive An equivalence relation's transitive property basically allows you to ""unidirectionally"" (my meaning will be understood shortly) link all elements belonging to the same equivalence class. For example, if we had $R_2$ be a relation on $S$ defined as $x-y$ is divisible by $2$ , then the following ordered pairs (non-exhaustive) are certainly in the set: $(2,4)$ , $(4,6)$ , $(6,8)$ . Pretend I do not know any other ordered pairs. Now, if I choose as my representative element $[2]$ , I can build my equivalence class by starting with $2\ R_2\ n$ . Well, $(2,4)$ is in $R_2$ therefore, $4$ belongs to the same equivalence class as $2$ . What works with $4\ R_2\ n$ ? Well $(4,6)$ is in $R_2$ and therefore $6$ is in the same equivalence class as $2$ and $4$ . However, let's say that I start with $[8]$ instead of $[2]$ . Which of the elements in set $S$ are in the same equivalence class? Namely, for which value of $n$ is $8\ R_2\ n$ true? Well, I know I have the ordered pair $(6,8)$ ...but that is not the same form as $8\ R_2\ 6$ . If only I knew that $(8,6)$ was also in the set describing $R_2$ ...and this is where symmetry comes into play. Symmetric An equivalence relation's symmetry property, in conjunction with the transitive property , allows you to bidirectionally link all elements belonging to an equivalence class (regardless of which 'starting element' you choose to represent your equivalence class). For example, incorporating the symmetry property with the above transitivity example, I now know that if $(2,4)$ , $(4,6)$ , and $(6,8)$ are in my $R_2$ set, then I also know that $(4,2)$ , $(6,4)$ , and $(8,6)$ are in my $R_2$ set. Consequently, if someone asks me what are the other elements that belong to $[8]$ , without hesitation I can say $2$ , $4$ , and $6$ . Are these the correct ways (at a very basic level) of intuitively understanding the motivation behind using these 3 properties to define equivalence relations?","['equivalence-relations', 'abstract-algebra']"
3299825,"1025th term of the sequence $ 1,2,2,4,4,4,4,8,8,8,8,8,8,8,8, ... $","Consider the following sequence - $$ 1,2,2,4,4,4,4,8,8,8,8,8,8,8,8, ... $$ In this sequence, what will be the $ 1025^{th}\, term $ So, when we write down the sequence and then write the value of $ n $ (Here, $n$ stands for the number of the below term) above it  We can observe the following - $1 - 1$ $2 - 2 $ $3 - 2$ $4 - 4$ $5 - 4$ . . . $8 - 8$ $9 - 8$ . . . We can notice that $ 4^{th}$ term is 4 and similarly, the $ 8^{th}$ term is 8.
So the $ 1025^{th}$ term must be 1024 as $ 1024^{th} $ term starts with 1024. So the value of $ 1025^{th}$ term is $ 2^{10} $ . Is there any other method to solve this question?",['sequences-and-series']
3299863,Finding the $18th$ Derivative of a Particular Product at $x = 0$,"Let $f_{1}(x) = e^{x^5}$ and $f_{2}(x) = e^{x^3}$ . Let $g(x) = f_{1}f_{2}$ . Find $g^{(18)}(0)$ . By series expansion at $x = 0$ : $f_{1}(x) = \sum_{k \ge 0} {x^{5k} \over k! }$ and $f_{2}(x) = \sum_{m \ge 0}{x^{3m} \over {m!}}$ , then $$g(x) = \sum_{k, m \ge 0}{x^{5k + 3m} \over {m!k!}}.$$ Substituting $5k + 3m = n$ we get $g(x) = \sum_{n \ge 0} \left( \sum_{5k + 3m = n}{1 \over {m!k!}} \right) x^{n} $ . Solving diophantine equation $5k + 3m = 18$ , there are two ordered pairs of non - negative integers $(k, m)$ : $(3, 1), (0, 6)$ . Thus, $g^{18}(0) = 18! \left[ { {1 \over {3!1!}} + {1 \over {0!6!}}} \right].$ Is there a general method for finding $n^{th}$ derivative of functions $\prod_{1 \le i \le n}f_{i}$ ? Obviously, if there are no solutions then a derivative of a function at some point will be $0$ . But what can be said when there are  infinitely many solutions? UPD: 01.08.2019 Consider function $f(x) = e^{1 \over 1 - x}$ . Then by expansion at 0: $$f(x) = e\sum_{n \ge 0} \sum_{x_{1} + 2x_{2} + \cdots  = n} {{1} \over {x_{1}!x_{2}!\cdots}} x^{n},$$ which gives an infinite diophantine equation. More general, it can be applied to functions of a form: $f(x)^{g(x)}.$ Referring  to my early question, what can be said about a derivative at $x = 0$ of a such function?","['power-series', 'solution-verification', 'derivatives', 'diophantine-equations']"
3299864,How to show that a mapping is a 2-Lipschitz retraction from $l_\infty$ to $c_0$?,"In the book ""Geometric Nonlinear Functional Analysis"" by Benyamini and Lindenstrauss, I came across an example (Example 1.5) in which the authors construct a retraction from $l_\infty$ to $c_0$ (both equipped with the supremum metric) and claim it is a Lipschitz mapping with constant 2. I give the definition below For a sequence $x=(x_n)_{n\in\mathbb N}\in l_\infty$ , denote $d(x)=\limsup|x_n|$ . We define $r:l_\infty\to c_0$ as follows. For $x=(x_n)_{n\in\mathbb N}$ and $n\in\mathbb N$ $$r(x)_n = \begin{cases} 0 &, |x_n|<d(x) \\
                      (|x_n|-d(x))sign(x_n)&, |x_n|\geq d(x).\end{cases}$$ I can see why it is a well-defined retraction. However I cannot obtain the Lipschitzness at constant 2. Could you please give a solution or a hint?","['retraction', 'functional-analysis', 'lipschitz-functions', 'metric-spaces']"
3299893,Space of algebraic curves of degree $d$ is compact,"In an article I am reading it states ""the space of algebraic curves of a given degree $d$ is compact"". It seems to take this as a basic fact, as there is no explanation on this. I was wondering could someone please explain what this means?",['algebraic-geometry']
3299910,A selection of objects (with replacement) using combination formula,"Consider an example where a pack contains 4 blue, 2 red, and 3 black pens. If a pen is drawn at random from the pack, replaced, and the process repeated 2 more times, what is the probability of drawing 2 blue pens and 1 black pen? Now I am aware that a every single draw is an independent event and so we can use the multiplication rule of probability. $$\text{Pr(drawing a blue pen)} = \frac{4}{9}$$ $$\text{Pr(drawing a black pen)} = \frac{3}{9}$$ $$\text{Pr(drawing a blue pen on first draw AND drawing a blue pen on the second draw AND drawing a black pen on the third draw)} = \frac{4}{9}\cdot\frac{4}{9}\cdot\frac{3}{9}$$ 2 blue pens and 1 black pen can be arranged in $\frac{3!}{2!}$ ways so the total probability is $3\cdot\frac{4}{9}\cdot\frac{4}{9}\cdot\frac{3}{9}$ . My question is whether this can be done using just the combination formula? I learned that you can select $r$ objects out of $n$ with replacement using $${n+r-1 \choose r}.$$ So we can select 2 blue balls out of 4 in ${4+2-1 \choose 2}$ ways and 1 black ball out of 3 using ${3 \choose 1}$ ways. We can choose 3 balls out of a total of 9 (with replacement) in ${9+3-1 \choose 3}$ ways. According to me the probability using the combination formula should be $$\frac {{5 \choose 2}{3 \choose 1}}{11 \choose 3}.$$ But this is not the same as what I got using the multiplication rule. I would be really thankful if someone could guide me where I went wrong.","['discrete-mathematics', 'combinatorics', 'probability']"
3299924,How many 3 digit numbers have the property that the middle digit is the product of the first and last digits?,"I have a problem that goes like this: How many 3 digit numbers have the property that the middle digit is the product of the first and last digits? 
I figured that the answer might be 648, but I feel like this is too large of a number. I am probably a couple hundred off. Can someone confirm or help me with this problem? 
My work is as follows:
1st digit numbers = 1,2,3,4,5,6,7,8,9
3rd digit numbers = 1,0 since the middle number is less than 10
9*2 = 18 numbers for middle, some repeating
18 * 18 = 324
324 * 2 = 648","['permutations', 'combinatorics', 'products']"
3299944,Why is the derivative of scalar with respect to vector a vector and not a scalar?,"I'm really confused about matrix calculus and especially partial derivatives. When do we need to sum up partial derivatives to get a total derivative and when do we get a vector of partial derivatives as our derivative? I struggle with differentiating between the two. I'll make an example to make it clear: L is a scalar, $\mathbf{o}$ is a vector of size $K$ and $\mathbf{y}$ is a vector of size $K$ . $$L = -\sum_{k} \log(y_k)$$ $$\mathbf{y} = \text{softmax}(\mathbf{o})$$ So if we want to have the derivative of L with respect to $\mathbf{o}$ , we would need to sum over all the partial derivatives with respect to the terms $\mathbf{y}$ so that we get the total derivative, that is as much as I understood from reading about multivariate calculus: $$\frac{\partial L}{\partial \mathbf{o}} = \frac{\partial L}{\partial \mathbf{y}}\frac{\partial \mathbf{y}}{\partial \mathbf{o}} = \sum_{k}\frac{\partial L}{\partial y_k}\frac{\partial y_k}{\partial \mathbf{o}} = 
-\sum_{k} \frac{1}{y_k} \frac{\partial y_k}{\partial \mathbf{o}}$$ However, then $\frac{\partial L}{\partial \mathbf{o}}$ seems to be a vector of the partial derivatives of L with respect to every term of $\mathbf{o}$ , i.e.: $$ \frac{\partial L}{\partial \mathbf{o}} = \left< \frac{\partial L}{\partial o_1}, \frac{\partial L}{\partial o_2}, ..., \frac{\partial L}{\partial o_K} \right> $$ But shouldn't the derivative be the sum of all the partial derivatives of $\mathbf{o}$ to get the total derivative? i.e. shouldn't the solution be: $$\frac{\partial L}{\partial \mathbf{o}} = \frac{\partial L}{\partial \mathbf{y}}\frac{\partial \mathbf{y}}{\partial \mathbf{o}} = -\sum_{k} \frac{1}{y_k} \sum_{i} \frac{\partial y_k}{\partial o_i}$$ and then its just a scalar?","['partial-derivative', 'calculus', 'derivatives']"
3299947,An exact sequence related to adeles,Let $K$ be a number field and let's denote with $O_K$ its ring of integers. Moreover we indicate with the letter $p$ the generic non-archimedean place of $K$ and with $\sigma$ the generic archimedean place. A few days ago a speaker in a talk said that there is the following extension of topological groups: $$(\ast)\quad 0\to\prod_{p}\mathcal O_p\to\mathbf A_K/K\to \left(\prod_\sigma K_\sigma\right)\big/ O_K\to 0$$ where $\mathbf A_K$ is the ring of adeles and $K\hookrightarrow \mathbf A_K$ diagonally. $\mathcal O_p$ is the completion of $O_K$ w.r.t. the place $p$ . $K_\sigma$ is the completion of $K$ w.r.t. $\sigma$ . Where does the sequence $(\ast)$ come from? I don't understand theconstruction of the surjective map. The existence of such a sequence should be a consequence of the strong approximation theorem. Thank you in advance.,"['number-theory', 'algebraic-number-theory', 'adeles', 'topological-groups']"
3299952,Relation defined on $\mathbb{R}$,"Started studying relations and attempted a very basic problem which I think I have done correctly, can somebody tell me if there are any flaws?Also if a relation is reflexive or transitive can it have trichotomy?I know that if it is symmetric it cannot. Consider the relation on $\mathbb{R}$ defined by $n \simeq m$ iff $n-m \in \mathbb{Z}$ Is the relation Reflexive,symmetric,and transitive? Attempt: $n-n=0$ and $0 \in \mathbb{Z}$ So reflexive Suppose $n-m \in \mathbb{Z}$ Then $-(n-m) \in \mathbb{Z}$ So symmetric Suppose $n-m \in \mathbb{Z}$ and $m-p  \in \mathbb{Z}$ then $(n-m)+(m-p) \in   \mathbb{Z}$ so transitive. Does the relation of trichotomy? Relation does not have trichotomy since the relation is symmetric so $nRm$ and $mRn$ are true which contradicts trichotomy",['elementary-set-theory']
3299960,A space with an isometry group of $\operatorname{Spin}(d)$?,A space which has an isometry group of $O(n)$ is $S^{n-1}$ . A space which has an isometry group of $U(n)$ is $\mathbb{C}^{n}$ excludes an origin. Which space has an isometry group of $\operatorname{Spin}(d)$ : When $d$ is even? When $d$ is odd? Note that $Spin(d)/(\mathbf{Z}/2\mathbf{Z})=SO(d)$ -- $Spin(d)$ is a universal cover of $SO(d)$ .,"['manifolds', 'differential-topology', 'isometry', 'lie-groups', 'differential-geometry']"
3299980,What exactly is a cofactor and how is the sign chart derived?,"Given \begin{equation*}
\begin{bmatrix}
a_{11} & \dots & a_{1j} \\
\vdots & \ddots & \vdots \\
a_{i1} & \dots & a_{ij}
\end{bmatrix}
\end{equation*} I know the cofactor is $A_{ij}=M_{ij}(-1)^{i+j}$ where $M_{ij}$ is the minor of an element. But what does that even mean? What does it mean to take the cofactor of a matrix, is there a geometric visualization of this or anything? Second, where does the sign chart below come from, and why do I have to use it to take the row cofactor sum to find the determinant of the matrix? \begin{equation*}
\begin{bmatrix}
+ & - & + \\
- & + & - \\
+ & - & +
\end{bmatrix}
\end{equation*} I have a decent understanding of why $\Delta x=\Delta_1$ , but it's cofactor expansions and the sign chart that I don't understand (but can do/use).","['matrices', 'algebra-precalculus', 'linear-algebra']"
3300014,Probability of two sets of items containing common subset of items,"I've recently been pondering about the following problem: Kyle and his best mate Chad head over to the game shop to purchase
  some new games. After squabbling over which games to purchase, Kyle
  and Chad eventually limit their options to ten games. Kyle and Chad
  have individual orders of preference which are independent of each
  other and which the other person does not have any information about. To ensure they choose a game as fairly as possible, they agree that
  Kyle randomly removes five options from the list, and then Chad
  randomly chooses a game from the remaining five. What is the
  probability that the game which Chad chooses is not in the top three
  of either person's list of preferences? The obvious thing to me is that the probability that Kyle's top three are in the five he chose is just ${7\choose 2}/{10\choose 5}$ . What I am unsure about is the probability that Chad's random choice is in his top three for a given sample of five. Is this a joint probability (in Chad's top three AND from Kyle's selection) or a conditional one (in Chad's top three GIVEN Kyle's selection)? How do I account for the intersection of their preferences? More generally, for two identical sets of $n$ items, if we select $m$ items out randomly from each set, how do we calculate the probability that the $m$ -element subsets share $k$ elements in common? Is there a well-known distribution for this? Thanks!","['statistics', 'combinatorics', 'probability']"
3300019,limit of $\sin^{-1} (\sec x) $ as $x$ tends to $0$,What is the limit of $\sin^{-1}  (\sec x) $ as $x$ tends to $0$ . By direct substitution the value of $\sec x $ at $x =0$ is $1$ . So limit should be $1$ . But answer is given that limit doesn't exist. How $?$,"['limits', 'inverse-function', 'analysis']"
