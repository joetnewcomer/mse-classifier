question_id,title,body,tags
2254543,Finding number to make this inequality work,"I have the following as given: $p \in (0,1]$, 
$n$ a positive integer I would like to make the inequality $$\frac{(np)^k}{k^k} e^{-np} \geq n^{-1/3}$$ true. I am constrained to picking $k \in  (0,n]$, and preferably $k$ should depend on $np$. Does anyone have ideas on how to go about picking $k$?","['inequality', 'discrete-mathematics']"
2254544,"Particular case of Gauss-Bonnet for polygons in $\mathbb{R}^2, \mathbb{H}^2$ and $\mathbb{S}^2$","(Exercise 5.16, Bonahon, Low-dimensional geometry) Let $X$ be a bounded polygon in $\mathbb{R}^2, \mathbb{H}^2$ or $\mathbb{S}^2$ consisting of finitely many disjoint convex polygons $X_1, X_2,\dotsc, X_m$. Let $\bar{X}$ be obtained by gluing together pairs of edges of $X$. We assume that for every vertex $P$ of $X$, the angles of $X$ at the vertices that are glued together to $P$ add up to $2\pi$, so that $\bar{X}$ is a euclidean, hyperbolic, or spherical surface. The quotient space $\bar{X}$ is now decomposed into $m$ images of the convex polygons $X_i$, $n$ images of the $2n$ edges of $X$ and $p$ point images of the vertices of $X$. The Euler characteristic of $X$ is defined as the integer 
$$\chi(\bar{X})=m-n+p$$ I have shown the second part of the question which states: For each of the convex polygons $X_i$, $$\sum_{j=1}^{v_i} \theta_j = (v_i-2)\pi + K \text{Area}(X_i),$$ where $X_i$ has $v_i$ vertices, and $\theta_j$ are the angles of $X_i$ at the vertices. For the euclidean case we mean the usual are and $K=0$, for the hyperbolic case we have in mind the hyperpolic area and $K=-1$, whereas for the spherical case $K=1$ and Area$(X_i)$ denotes the spherical area. We shall use the above result in order to show that $$2\pi \chi(\bar{X}) = K \text{Area}(X)\enspace (*)$$ I have tried to write down what I know, namely $K\text{Area}(X)= K\sum_{i=1}^{m} \text{Area}(X_i)= (\sum_k \theta_k)[(\sum_i v_i)-2m]\pi $, where $k$ ranges over all the vertices in $X$ so that we sum all the angles of the polygons in $X$ and 
$\sum_i v_i$ represents the sum of all the vertices in $X$. The term $-2\pi m$  in the latter expression and the term $2\pi m$ of the left hand side in $(*)$ differ by a sign, so this may be a good start. Do you have any suggestions how to proceed?","['low-dimensional-topology', 'hyperbolic-geometry', 'spherical-geometry', 'geometry']"
2254550,Cardinality of $\mathbb R/\mathord{\sim}$ when the equivalence classes are measurable,"Let $\sim$ be an equivalence relation on $\mathbb R$ such that each equivalence class is Lebesgue measurable. Can we prove that we do not have
$$
\operatorname{card}(\mathbb N) < \operatorname{card}(\mathbb R/\mathord{\sim}) < \operatorname{card}(\mathbb R)\ ?
$$
(By $\operatorname{card}(S)$ I denote the cardinality of $S$.) [Thanks to arjafi their edit! arjafi removed the logic tag. I put it back not to start an edit war, but because of the connection with the continuum hypothesis, which is usually considered as belonging to mathematical logic.]","['set-theory', 'logic', 'measure-theory']"
2254601,"It is given that $z_o\in \mathbb{C}$ is a point such that $|z_0-i|=2$, and $f$ is a function which is analytic in $\mathbb{C}$ \ $ \{z_0\}$.","It is given that $z_o\in \mathbb{C}$ is a point such that $|z_0-i|=2$, and $f$ is a function which is analytic in $\mathbb{C}$ \ $ \{z_0\}$. It is also given that $f$ has a pole at $z_0$ and $f^{(k)}(i) \ge 0$ for each non-negative integer $k$. Prove that $z_0=2+i$",['complex-analysis']
2254603,"How to solve the differential equation $\dfrac{\partial f}{\partial t}(x,t) = c_1 f(x,t)+c_2f(x-1,t)-c_2 f(x+1,t)$?","I am trying to solve the differential equation$$\frac{\partial f}{\partial t}(x,t) = -ix^3f(x,t)+Cf(x-1,t)-C f(x+1,t)$$ where $C$ is a purely imaginary constant. I am not sure how to go about this as normally when solving differential equations the first coordinate is the same. I can't seem to think of any strategy to employ.","['ordinary-differential-equations', 'partial-differential-equations']"
2254620,Proof of determinants for matrices of any order,"I was told that the determinant of a square matrix can be expanded along any row or column and given a proof by expanding in all possible ways, but only for square matrices of order 2 and 3. Is a general proof for any order even possible ? If so, how is this done ? On a similar note, how can we prove the various properties of determinants for square matrices for any order like the following: Swap two rows/columns and all we get is a minus sign as a result. $R_1 \to  R_1+ aR_2$ does not change the determinant. Determinant of the transpose is the same as the determinant of the original matrix.","['matrices', 'proof-writing', 'determinant']"
2254633,"Let $\mu_n$ be $\text{Uniform}(\alpha_n,\beta_n)$ distribution. What condition on both sequences makes $\left\{\mu_n\right\}_n$ relatively compact?","Let $\mu_{n}$ be the $\text{Uniform}(\alpha_{n},\beta_{n})$ probability distribution for $\alpha_{n}< \beta_{n}$ , $n = 1,2,3,\ldots$ What condition on these two sequences makes $\left\{\mu_{n}\right\}_{n}$ relatively compact? I know that using Prokhorov's Theorem we can show conditions for tightness. (If $\Omega$ is a complete separable metric space then a family of distributions is relatively compact if and only if it is tight.) Using this theorem I will want to show, $$\mu_{n}\{[-m,m]\} > 1-\varepsilon$$ for any $\varepsilon>0$ and $m>0$ . But I don't really know how to go about doing this. Any help would be greatly appreciated!","['uniform-distribution', 'probability-theory', 'compactness']"
2254650,"Prove there exists two sub-sets of indices $I,J\subseteq [2n]$ such that $\sum_{i\in I}a_i=\sum_{j\in J}b_j$","Let $(a_i)_{i=1}^{2n}, (b_i)_{i=1}^{2n}$ be two sequences of size $2n$ of integers such that for every $1\leq i \leq 2n$ : $1\leq a_i \leq n, 1\leq b_i \leq n$ . Prove there exists two nonempty sub-sets of indices $I,J\subseteq [2n]$ such that $\sum_{i\in I}a_i=\sum_{j\in J}b_j$ . I tried to work with pigeonhole principle, but got stuck. Any help appreciated.","['combinatorics', 'pigeonhole-principle']"
2254651,How to determine the weights in the asymmetric Lovasz Local Lemma,"The application of the asymmetric Lovasz Local Lemma requires finding a weight function $x$ on the bad events satisfying the property in the link.  Often, one uses a constant weight function, giving rise to symmetric LLL. Suppose this fails.  Is there a systematic way to search for a better choice of $x$?","['combinatorics', 'probability', 'probabilistic-method', 'discrete-mathematics']"
2254667,"${N}\times{N}$ chessboard, adjacent squares differ by one","Suppose we have ${N}\times{N}$ chessboard such that two squares are adjacent if they share a common side. Populate all squares with integer numbers so that numbers in adjacent squares differ by $1, 0$ or $-1$. Prove that some number appears at least N times.","['combinatorics', 'chessboard']"
2254694,If $\lim_{n \rightarrow \infty} (a_{n+1}-\frac{a_n}{2})=0$ then show $a_n$ converges to $0$. [duplicate],"This question already has answers here : Show that $x_{n+1}-\dfrac{x_n}{2}$ converges to zero implies that $(x_n)_n$ also converges to zero. (2 answers) Closed 4 years ago . I have been stuck on this question for a while now. I have tried many attempts. Here are two that I thought looked promising but lead to a dead end: Attempt 1: Write out the terms of $b_n$: $$b_1=a_{2}-\frac{a_{1}}{2}$$
$$b_2=a_{3}-\frac{a_{2}}{2}$$
$$b_3=a_{4}-\frac{a_{3}}{2}$$
$$\cdots$$
$$b_n=a_{n+1}-\frac{a_{n}}{2}$$ Adding up the terms you get: $$\sum_{i = 1}^n b_i=a_{n+1}+\frac{a_n}{2}+\frac{a_{n-1}}{2}+\cdots+\frac{a_2}{2}-\frac{a_1}{2}.$$ But a dead end here. Attempt 2: For $ε=\dfrac{1}{2}$, $\exists K$ such that $\forall n>K$, $$\left|a_{n+1}-\frac{a_n}{2}\right|<\frac{1}{2}.$$ Now I attempt to prove $\{a_n\}$ is Cauchy and hence converges. For $m>n>K$,
\begin{align*}
|a_m-a_n|&=\left|a_m-\frac{a_{m-1}}{2}+\frac{a_{m-1}}{2}-\frac{a_{m-2}}{2^2}+\cdots -+\frac{a_{n+1}}{2^{m-n-1}}-a_n\right|\\
&\leq \left|a_m-\frac{a_{m-1}}{2}\right|+\frac{1}{2}\left|a_{m-1}-\frac{a_{m-2}}{2}\right|+\cdots+\left|\frac{a_n}{2^{m-n}}-a_n\right|\\
&\leq \frac{1}{2}+\frac{1}{2} × \frac{1}{2}+\cdots+\left|\frac{a_n}{2^{m-n}}-a_n\right|\\
&<1+\left|\frac{a_n}{2^{m-n}}-a_n\right|,
\end{align*}
and a dead end.","['cauchy-sequences', 'convergence-divergence', 'limits']"
2254728,Integral depending measurable on a parameter,"Let $(\Omega, \Sigma, \mu)$ be a measurable space and let $f\colon [0,1] \times \Omega \to \mathbb R$ be such that $x\mapsto f(t,x)$ is integrable for all $t\in [0,1]$. Then $$F\colon [0,1] \to \mathbb R,\quad t\mapsto F(t) = \int_\Omega f(t,x) d\mu(x)$$ is well-defined. Question : Are there mild conditions on $t\mapsto f(t,x)$ such that $F$ is measurable (perhaps even if $[0,1]$ is replaced by some measurable space)? I have found the following well-known statements: If $t\mapsto f(t,x)$ is continuous for a.e. $x\in \Omega$ and if $|f(t,x)| \leq g(x)$ for all $(t,x)$ and some integrable $g$, then $F$ is known to be continuous. If $\Omega$ is $\sigma$-finite and $(x,t)\mapsto f(t,x)$ is integrable on the product-space, then $F$ is integrable and one can interchange the order of integration by Fubini's theorem. Now I wonder, if one can drop continuity in $t$ without asking $f$ to be product-measurable.","['integration', 'measure-theory']"
2254729,Rotating sets apart in a regular n-gon,"Given a regular $n$-gon ($n \geq 3$ integer), consider $t$ subsets $S_1,..,S_t$ of the vertices. Depending on $n, t$, and on the size of the sets $S_i$ one may find rotations $r_i , i = 1 .. t$ of the $n$-gon such that $r_i(S_i) \cap r_j(S_j) = \emptyset$ for all $i \neq j$ in $1 ..  t$. In this case we say that the sets can be rotated apart . In my paper ""Shuffled equi-$n$-squares"" available at http://arxiv.org/abs/1701.02325 I proved that if $n = (t-1)*m^2$ with $t \geq 3$ and $m \geq 2$, then any $t$ sets of size $m$ can be rotated apart in a regular $n$-gon. The proof uses cyclotomic polynomials. As to the sharpness of this result I have a Question. Given $n = 2*m^2 - 1$ with $m \geq 2$, is it true that every three sets of size $m$ can be rotated apart? My special interest goes to a regular 127-gon and three sets of size $8$. A negative answer to the Question with $n = 127$ would also confirm the sharpness of another, general, argument proving that $t$ sets can be rotated apart in a regular $n$-gon if the sum $s$ of the sizes satisfies $(t - 1)*s^2/t^2 < n$ (lemma 3.11). Any answer is welcome, however. Note: The question has been reformulated in a more general way to gain clarity.","['cyclotomic-polynomials', 'combinatorics', 'discrete-mathematics']"
2254737,Intuition of invariance of power of point,"Power of a point is a famous proof in elementary geometry, which states that: For a circle $\omega$ and a pont $P$  outside it, for any line through $P$ which intersects $\omega$ at $A$ and $B$, the quantity $PA.PB$ is invariant for any $A$, $B$. I can find the proof in wikipedia, and in all other places, but I am not finding the proof intuitive enough to see the invariance of the multiplication at a glance, and have an ""Aha! Gotcha"" insight. Don't get me wrong, I understand the proof perfectly; But it's like the well mentioned sum $\sum_{i=0}^{n}n^3 = [\sum_{i=0}^{n}n]^2 $ - you can prove that it's correct, but you can't see it at a glance. (For that particular equation, some Proof-without-words gives the proper intuition). Is there any proof/explanation which clearly demonstrates the invariance of the power of a point ? Update : The other answer (which doesn't provides any new insight, but) poses another good spinoff question, for circle $\omega$, and arc ${AB}$ and any point $P$ on $\omega$, $\angle {APB}$  is constant. Same situation as above, I know the proof, but I don't have any a-glance insight on its truth.","['intuition', 'invariance', 'alternative-proof', 'geometry']"
2254740,derive $\delta _{tt} y=y$ without guessing,"Say we have a second order differential equation $\delta _{tt} y=y$ We can on the basis of our intuition say that the functions $e^t$ and $e^{-t}$ satisfy this second order ODE. We can then reason that the superposition must also satisfy the ODE. But is there a way to derive directly from the ODE, without make the abovementioned educated guess, the general solution of that ODE? (I don't have much experience with second order ODE's).",['ordinary-differential-equations']
2254780,how to prove two groups are NOT isomorphic?,"I have two groups defined by presentations
$$\langle x, y \mid x^p = y^q       \rangle$$
$$\langle x, y \mid x^{p'} = y^{q'} \rangle$$
where $p,q,p',q'$ are all integers greater then $1$, and $\gcd(p,q) = 1$, $\gcd(p',q')=1$. I'm not 100% sure, but i think they are not isomorphic. But I don't know how to prove it. Any ideas?","['abstract-algebra', 'group-presentation', 'group-theory', 'group-isomorphism']"
2254788,Differential equation $y'=\frac{y}{2y\ln y+y+x}$,"Solve the differential equation
  $$y'=\frac{y}{2y\ln y+y+x}$$ This doesn't look hard, but the problem is how to spot the right substitution. This seems like a linear differential equation, but I couldn't transform it to the right form. This is what I did instead: Firstly, I transformed the equation to the following form:
$$y-\left(2y\ln y+y+x\right)y'=0$$
Then I noticed that if I divide it with $y^2$ and recombine the terms in the numerator, I can end with the something like this:
$$\frac{y-xy'-y(1+\ln y)y'-y\ln yy'}{y^2}=0$$
which is indeed
$$\left(\frac{x-y\ln y\left(1+\ln y\right)}{y}\right)'=0$$
and thus the solution is
$$x-y\ln y\left(1+\ln y\right)-c_1y=0$$
My approach works in this particular case. I spent a lot of time trying to figure out how to recombine the terms in the fraction in order to artificially create a derivative of a fraction. Of course, this is not how the general approach should look like. My question is how to deal with equations like this? Is there a more general algorithm which can be used to lead us to the solution with less effort? What substitution would be in this particular equation and how to spot the right substitution?","['derivatives', 'logarithms', 'functions', 'integration', 'ordinary-differential-equations']"
2254801,Let $f(z)$ be an entire function satisfying $z\dfrac{f^{'}(z)}{f(z)} = z^{2}\dfrac{f^{'}(z^{2})}{f(z^{2})}$ show that $f(z) = cz^{m}$.,"a) Let $f(z)$ be an entire function satisfying the condition $$z\dfrac{f^{'}(z)}{f(z)} = z^{2}\dfrac{f^{'}(z^{2})}{f(z^{2})}$$
whenever $f(z) \neq 0$. Show that if $f(0) = 0$, then $$z\dfrac{f^{'}(z)}{f(z)}$$ 
is a function that is analytic at $z=0$. b) Show that $$f(z) = cz^{m}$$
for some constant $c \in \mathbb{C}$ and positive integer $m$. For part a), please see if i did correctly,since we are given that $f(0) = 0$, we know that $f$ has a zero of order $m$ at $0$. Hence we can write $$f(z) = z^{m}g(z)$$ where $g(z)$ is analytic at $0$ and $g(0) \neq 0$. It follows that $$f^{'}(z) = mz^{m-1}g(z)+z^{m}g^{'}(z)$$ Hence by subsituting we derive $$z\dfrac{f^{'}(z)}{f(z)} =m+\frac{zg^{'}(z)}{g(z)}$$ Hence this function is analytic at $z=0$ because $g(z)$ is analytic at $0$. (Can someone explain to me: $g(z)$ analytic at $0$  means $g(z)$ is analytic in a small neighborhood of $0$. But how can i ensure that $g(z)$ does not have zeroes in this small neighborhood? If $g(z)$ has zero inside, then the expression $m+\frac{zg^{'}(z)}{g(z)}$  is not analytic at $0$. And for part $b$, anyone can write out their solution? I do have a model answer from my professor but find it hard to understand.","['complex-analysis', 'ordinary-differential-equations', 'functional-equations']"
2254817,How to find in a more formal way $\lfloor{(2+\sqrt3)^4}\rfloor$,"Problem Statement:- The largest integer which is less than or equal to $(2+\sqrt3)^4$ is $\text{(A)}192\qquad\qquad \text{(B)}193\qquad\qquad \text{(C)}194\qquad\qquad\text{(C)}195\qquad\qquad$ My Solution:- I started with the binomial expansion but as I was not able to think of any manipulation which would make my life easier so I just did the following. $$(2+\sqrt3)^2=\binom{4}{0}2^4+\binom{4}{1}(2^3)(\sqrt3)+\binom{4}{2}(2)^2(\sqrt3)^2+\binom{4}{3}(2)(\sqrt3)^3+\binom{4}{4}(\sqrt3)^4$$ On arranging the integers and the irrational terms separately I ended up with $$(2+\sqrt3)^4=97+56\sqrt3=97+56+56(\sqrt3-1)=153+56(\sqrt3-1)$$ At this point still no manipulation was obvious to me that I can do that would give me answer to $\lfloor{(2+\sqrt3)^4}\rfloor$ , so I just used a rough estimate of $(\sqrt3-1)\approx0.732$ to get $56(\sqrt3-1)=40.992$ . The rough estimate of $56(\sqrt3-1)\approx40.992$ is dangerously close to $41$ so at this point I was pretty confused as to how to ascertain that $56(\sqrt3-1)\lt 41$ or $56(\sqrt3-1)\gt 41$ , which had left me with the answer as one of the options out of (C) and (D). Your help is needed for resolving this doubt of mine. Also, what would have been a more subjective approach.","['algebra-precalculus', 'binomial-theorem']"
2254821,"Evaluate $\int \frac{\log(1+x^2)}{\sqrt{1-x^2}} \,\mathrm dx$","$\def\d{\mathrm{d}}$Evaluate $$\int \frac{\log(1+x^2)}{\sqrt{1-x^2}}\,\d x.$$ I have used Integration by parts as follows: $$I=\log(1+x^2) \: \sin^{-1}x-\int \frac{2x \sin^{-1}x}{1+x^2}\,\d x=\log(1+x^2) \: \sin^{-1}x-J,$$ where $$J=\int \frac{2x \sin^{-1}x}{1+x^2}\,\d x$$ In this put $x=\sin y$ we get $$J=\int \frac{y \sin2y}{1+\sin^2y}\,\d y.$$ Any clue here?","['indefinite-integrals', 'integration']"
2254838,"Confused with the proof that the total variation is a positive measure, how to write a double infinite series as one infinite series,","I am confused with a step in the proof of Theorem 6.2 in Rudin's Real and Complex Analysis which is in page 117. It claims that $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$ since $A_{ij}$ is a partition of $E$, by the definition of the total variation, which is, $|\mu|(E)=$sup$\sum_i|\mu(E_i)|$ where the supremum is taken over all partitions $E_i$ of $E$, it seems that we should write $\sum_{i,j}|\mu(A_{ij})|$ as an infinite series rather than a double infinite series to get the conclusion. By Cantor's diagonal argument, $\{A_{ij},i,j=1,...\}$ can be written as $\{A_{11},A_{12},A_{21},A_{31},A_{22},A_{13},...\}$, denote it by $\{A_1,A_2,...\}$, is it true that $\sum_{i,j}|\mu(A_{ij})|=\sum_i|\mu(A_i)|$? Rudin says it uses the Corollary of Theorem 2.17 in the step $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$, which is, $\sum_i\sum_ja_{ij}=\sum_j\sum_ia_{ij},a_{ij}\ge0$, it does not make any sense to me, how can that lead to $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$, can anyone explain it to me? Here are the Theorem 6.2 with its proof: click here . Apologize for my poor language, I am not a native speaker. And this is my first question, appreciate for your help. UPDATE: Suppose $a_{ij}\ge0,a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ converges. Let $b_k=\sum_{i+j=k}{a_{ij}}$, then $\sum_ib_i=(a_{11})+(a_{12}+a_{21})+(a_{31}+a_{22}+a_{13})=a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ since $a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ is convergent, so my first question can be restated as: is it true that $\sum_i\sum_ja_{ij}=\sum_ib_i$?","['measure-theory', 'real-analysis', 'sequences-and-series']"
2254867,Q: Trigonometry Bearings: Find distance between 2 points based on separate bearings,"Just finished a trig exam with the following problem and most everyone in the class arrived at a very different answer than me. The Professor and most of the class determined that to solve for side AB you would simply use the law of sines: Problem: A land developer wants to find the distance across a small lake in the middle of his proposed development. The bearing from A to B is N15°W. The developer leaves point A and travels 66 yards perpendicular to AB to point C. The bearing from C to point B is N75°W. Determine the distance, AB, across the small lake. Round distance to nearest yard. Class Solution: (using law of sines) step1: 66 yards / sin15° = AB / sin75° step2: (66)(sin75°) / sin15° = AB step3: 246.32 ≈ AB My Confusion with this is that the angles are not directly stated in the problem, at least from my understanding of trig bearings. It seems like the Professor and the students assumed that (angle B = 15°) and since (angle A = 90°) then (angle C = 75°). So I created a little diagram using actual measured angles to figure out what the triangle looked like based on my understanding of bearings (for N15°W = start at North or 90° on a unit circle and move counter clockwise 15°) and from my diagram I determined that (angle C = 30°), (angle A = 90°), therefore (angle B = 60°). I ran through this problem multiple times and even looked at similar problems both in the book and online, and basically want to validate which answer is correct. Thanks for playing! My solution: (Using law of sines) step1: 66 yards / sin60° = AB / sin30° step2: (66)(sin30°) / sin60° = AB step3: 38.11 ≈ AB","['trigonometry', 'geometry']"
2254873,One-step transition probabilities for a markov chain?,"Imagine m balls being exchanged between two adjacent chambers (left and right) according to the following rules. At each time step, one of the m balls is randomly selected and moved to the opposite chamber, i.e., if the selected ball is currently in the right chamber, it will be moved to the left one, and vice versa. Let $X_n$ be the number of balls in the left chamber after the nth exchange. For m=3 I want to find all the one step transition probabilities. I know the state space will be {0,1,2,3} and that I am looking for Probabilities, when it goes from 0->1, 1->0, 2->1, 1->2, 3->2, 2->3. I am struggling with how to account for the fact that the balls can have different starting positions? For example going from 1->0 you can either pick the one ball in the left chamber and move it, or pick one of the two balls in the right chamber and move it to the left making it a 1->2 transition, so what would the probability for something like that look like?","['markov-chains', 'probability', 'discrete-mathematics']"
2254887,$\cos^2(\frac{\pi}{101})+\cos^2(\frac{2\pi}{101})+\cos^2(\frac{3\pi}{101})+...+\cos^2(\frac{100\pi}{101})=?$,"Find the value: $$\cos^2\left(\frac{\pi}{101}\right)+\cos^2\left(\frac{2\pi}{101}\right)+\cos^2\left(\frac{3\pi}{101}\right)+\cos^2\left(\frac{4\pi}{101}\right)+\cos^2\left(\frac{5\pi}{101}\right)+\cdots \\ \cdots+\cos^2\left(\frac{99\pi}{101}\right)+\cos^2\left(\frac{100\pi}{101}\right)$$ My attempt:I've tried it by considering the sum 
$$\sin^2\left(\frac{\pi}{101}\right)+\sin^2\left(\frac{2\pi}{101}\right)+\sin^2\left(\frac{3\pi}{101}\right)+\sin^2\left(\frac{4\pi}{101}\right)+\sin^2\left(\frac{5\pi}{101}\right)+\cdots \\ \cdots+\sin^2\left(\frac{99\pi}{101}\right)+\sin^2\left(\frac{100\pi}{101}\right)$$ along with $$\cos^2\left(\frac{\pi}{101}\right)+\cos^2\left(\frac{2\pi}{101}\right)+\cos^2\left(\frac{3\pi}{101}\right)+\cos^2\left(\frac{4\pi}{101}\right)+\cos^2\left(\frac{5\pi}{101}\right)+\cdots \\ \cdots +\cos^2\left(\frac{99\pi}{101}\right)+\cos^2\left(\frac{100\pi}{101}\right)$$ which gives $ 100$ as resultant but failed to separate the sum of
 $$\sin^2\left(\frac{\pi}{101}\right)+\sin^2\left(\frac{2\pi}{101}\right)+\sin^2\left(\frac{3\pi}{101}\right)+\sin^2\left(\frac{4\pi}{101}\right)+\sin^2\left(\frac{5\pi}{101}\right)+\cdots\\ \dots+\sin^2\left(\frac{99\pi}{101}\right)+\sin^2\left(\frac{100\pi}{101}\right)$$ at last. I tried the next approach by  using de Movire's theorem but failed to separate the real and imaginary part. I've invested a great amount of time in the so it would be better if someone please come up with an answer.","['complex-analysis', 'trigonometry', 'sequences-and-series', 'trigonometric-series']"
2254939,Fundamental solution for Helmholtz equation in higher dimensions,"The fundamental solution for Helmholtz equation $(\Delta + k^2) u = -\delta$ is $e^{i k r}/r$ in 3d and $H_0^1(kr)$ in 2d (up to normalization constants).
Is there an explicit expression (eventually in terms of special functions) for the fundamental solution in dimension $\geq 4$? How can one derive it?","['fundamental-solution', 'partial-differential-equations', 'greens-function', 'special-functions', 'analysis']"
2255018,$\mathbb{R}$ under the metric $|\tan^{-1}x - \tan^{-1}y|$,"I'm trying to show that the real numbers with the metric described above is an incomplete metric space.  To do this, I want to come up with an example of a sequence that is Cauchy but does not have a limit in $\mathbb{R}$ under this metric.  First of all, would this be enough?","['functional-analysis', 'metric-spaces']"
2255035,"On proof of $ \lim\limits_{k\to\infty} \int_a^b | \cos{kx}|\,\mathrm{d} x = \frac{2(b-a)}{\pi}$","$\def\d{\mathrm{d}}$I need to prove that 
$$ \lim_{k\rightarrow\infty} \int_a^b | \cos{kx}|\,\d x = \frac{2(b-a)}{\pi}.$$
The answer goes as follows: 
\begin{align*}
\lim_{k\rightarrow\infty} \int_a^b | \cos{kx}|\,\d x &= \lim_{k\rightarrow\infty} \frac{1}{k} \int_{ka}^{kb} | \cos{x}|\,\d x\\
&= \lim_{k\rightarrow\infty}\frac{1}{k} \frac{k(b-a)}{\pi} \int_{0}^{\pi} | \cos{x}|\,\d x = \frac{2(b-a)}{\pi}.
\end{align*} But I'm little confused at the second step. I understand that the first step is a change of variable and I assume that the second is the same, but I didn't see why the $x$ in the integrand remains unchanged. As far as I see, it should be multiplied by $\dfrac{k(b-a)}{\pi}$, as it is multiplied by $k$ at the first step. Thanks in advance!","['integration', 'calculus']"
2255038,Proving the derivative of a certain point using the sequence definition,"Using this derivative definition If $f$ is a function and has derivative $f'(c)$ at the point $c$ in the domain of $f$ means that if ($a_n$)$_{n=1}^{\infty}$ is any sequence converging to $c$ such that $a_n$ $\not= c$is in the domain of $f$ for all $n \in \mathbb{N},$ then: $$(\,\frac{f(x_n)-f(c)}{x_n-c}) \,_{n=1}^{\infty}$$converges to $f'(c)$ prove that $f'(c)=-6,$ where $f(x)=x^2 +2$ I feel like this should be fairly straight forward, but I'm having trouble. My attempt: Plugging in $a_n$ for $x,$ and using $f(c)=f(-3)=11,$ $(\,\frac{f(x_n)-f(c)}{x_n-c}) \,_{n=1}^{\infty}$<=> $\frac{[(a_n)^2+2]-11}{a_n-3}$<=>$\frac{(a_n)^2-9}{a_n-3}$<=>$a_n-3$ Because we are using sequences, I'm not sure if this is a correct approach, and I am not sure how to complete the proof. Do I need to choose a certain epsilon to show that this sequence converges to $f'(c)$?","['derivatives', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
2255072,Incorrect ways to determine if a piecewise function is differentiable at a point?,"Given a piecewise function, let's say: $$f(x)=
\begin{cases}
x^2 \quad x < 0 \\
x^3 \quad x \ge 0
\end{cases}$$ Let's say we know the function is continuous and we only deal with real numbers. I have seen people check if it's differentiable at 0 in two different ways, but I'm not sure if all are correct. So help me out figuring out which are actually correct ways to do it. Method 1: Use the definition of the derivative, one for x>0 and one for x<0. Check if the the limits you get are the same. Method 2: Simply differentiate the function like this: $$f(x)=
\begin{cases}
2x\quad x < 0 \\
3x^2 \quad x > 0
\end{cases}$$ Then check if it's continuous in 0 by checking the limit from both sides. Which methods are correct? And are there other (analytic) methods?","['derivatives', 'piecewise-continuity']"
2255080,Motivation for orbifold base points,"I have been reading Hain's notes Lectures on Moduli Spaces of Elliptic Curves , and would like some ""philosophical"" intuition on the definition of orbifold basepoints. Let $X$ be a simply connected topological space, and let $\Gamma$ be a discrete group acting on $X$. We denote by $\Gamma\backslash\backslash X$ the corresponding (basic) orbifold . The space $X$ can be regarded as the orbifold $1\backslash\backslash X$ under the action of the trivial group. On p.18 Hain says that the natural orbifold ""universal covering"" map $p:X\to\Gamma\backslash\backslash X$ should be regarded as a base point of the orbifold $\Gamma\backslash\backslash X$. I understand how pointed morphims of orbifolds (Defintion 3.1) preserve such ""base points"", but I was wondering: is there an intuitive reason for calling such a map a base point of the orbifold? For example, we can look at the analogy with geometric base points in algebraic geometry. By definition a geometric base point of a scheme $X$ is a morphism $\text{Spec}(\bar{k})\to X$ where $\bar{k}$ is an algebraically  closed field. Now in the theory of the etale fundamental group, the universal cover of $\text{Spec}(k)$ (for $k$ perfect, at least) is
$$\text{Spec}(\bar{k})\to\text{Spec}(k),$$
induced by the choice of an embedding $k\hookrightarrow\bar{k}$. So in this case a base point of $\text{Spec}(k)$ is the same as a universal cover. But this doesn't generalise to schemes of higher dimension. To motivate the above idea for orbifolds, therefore, I am wondering: are there any other analogies/results in geometry or topology where regarding the universal cover of a space as an abstract base point makes sense? Perhaps such a thing comes from the worlds of stacks/topoi? Or is this just a convenient notation?","['intuition', 'algebraic-geometry', 'soft-question', 'algebraic-topology', 'orbifolds']"
2255094,Showing a measure is $\sigma$-finite,"Let ${(X_n, \mathcal A_n, \mu_n)_{n \in \mathbb N}}$ be measure spaces. Let $X_n$ be pairwise disjoint.
Define $(X, \mathcal A, \mu)$ by$X=\bigcup_{i=1}^{\infty} X_n$ $\mathcal A=\{E \subset X: E \cap X_n \in \mathcal A_n \; \forall n \in \mathbb N\}$ and $\mu(E)=\sum_n \mu_n(E \cap X_n)$ I want to show that if all $\mu_n$ are $\sigma$-finite than $\mu$ is $\sigma$-finite aswell. My attempt: 
I wanted to take the sequence of the unions of the sequences that make $\mu_n$ sigma finite. So the first element is the union of all the first parts of the each sequence and so on. Showing that the union is of all these equals $X$ is easy, but I fail at showing that each element has finite measure and that each element is contained in $A$ and hoped that someone could help me here.",['measure-theory']
2255132,Set of All Points at which $X$ is Locally Connected,"The following question came to me as I was reading about local connectedness: Let $$S := \{x \in X \mid X \text{ is locally connected at } x \},$$ where $X$ is some topological space. Is $S$ generally open in $X$? If not, suppose it is. Would this tell us much about the space $X$? Here is the definition of local connectedness I am working with: A space $X$ is said to be locally connected at $x$ if for every neighborhood $U$ of $x$, there is a connected neighborhood $V$ of $x$ contained in $U$.","['general-topology', 'locally-connected', 'connectedness']"
2255139,Why does $\log(\tan(x/2))=-\ln|\csc(x)+\cot(x)|$,"Background: This ""identity"" (if it is one) is motivated by Harris Mathematics for Physical Science question 2.5.4 asking to produce the series for 1/sin(x). The integral of $\csc(x)$ is $-\ln|\csc(x)+\cot(x)|$, I have never seen it given as $\log(\tan(x/2)$. What identity converts one into the other? series = Integrate[Series[Csc[x], {x, Pi/2, 10}], x]
series2 = Series[Log[Tan[x/2]], {x, Pi/2, 12}] If you plot them with wolfram alpha you might be confused because the imaginary graph displays different branches of the log function for the two, but they are the same. What likely simple identity am I forgetting or not understanding? Putting the $-\ln|\csc(x)+\cot(x)|$ over a common denominator I think I get $-\ln\mid\frac{2}{\sin(2x)}\mid$",['trigonometry']
2255163,equidistant points in $\mathbb{R}^n$ equipped with $\|.\|_p$,"My question is inspired by another question that was asked here. Question How many points $x_1,x_2,\dots,x_m \in \mathbb{R}^n$ can I find such that $\|x_i-x_j\|_p = 1$ for all $i\neq j$. For $p=2$ the answer is $n+1$. you can find the prove in the thread of my inspiration .
However I though that the result holds for an arbitrary $p\in[1,+\infty]$. Then I found a counterexample for $p=1$ and $p=\infty$: you can choose the points \begin{align*} x_1 = \left(\begin{matrix} 0
 \\ 0\end{matrix}\right),\; x_2 = \left(\begin{matrix} 1 \\
 0\end{matrix}\right),\; x_3 = \left(\begin{matrix} 0 \\
 1\end{matrix}\right)\;\text{and}\; x_4 = \left(\begin{matrix} 1 \\
 1\end{matrix}\right) \end{align*} then you have four points in
   $\mathbb{R}^2$ which fulfill $\|x_i-x_j\|_\infty = 1$ for $i\neq j$. There is a very similar example for $p=1$.
I think that this follows from the special geometry of the balls in these norms.
So I think there are three cases $p = 1$ $p = \infty$ $p \in (1,+\infty)$ In the first case I think the solution is $m\leq 2n$ in the second it is $m\leq 2^n$ and in the third $m\leq n+1$. Unfortunately I couldn't prove it maybe someone has a tipp. Update I found out that the cases $p=1$ and $p=\infty$ have different solutions as I already have edited. I can also prove that my guesses are lower bounds for the maximum of points that can exist. One has just to regard the corners of a ball $B_r(x)$ with radius $r=\frac{1}{2}$ in the desired norm.","['linear-algebra', 'geometry']"
2255173,Mean of squared $ L_2 $ norm of Gaussian random vector,"In my studies of probability, I have recently came across the following task: Let us assume we have an $N$ dimensional Gaussian random vector $ X $ with zero mean and known (not necessarily diagonal) covariance matrix $ \Sigma $. I am interested in the mean of the following random variable $ \lvert \lvert X \rvert \rvert _2 ^2 $. In simple words, is there an expression for the mean of the squared $ L_2 $ norm of an $ N $ dimensional Gaussian random vector with general covariance matrix? I certainly appreciate all help on this.","['normed-spaces', 'probability-theory', 'probability', 'normal-distribution']"
2255177,Suppose $ \sum_{n=1}^{\infty} b_n x^n= \frac{x^3}{(x^4-1)^2}$. What could be an expression of $b_n$?,"A practice problem reads: Suppose $$\sum_{n=1}^{\infty} b_n x^n = \frac{x^3}{(x^4-1)^2}.$$ What could be an expression of $b_n$? Some of the possible answers read $ 2^{3n}nx^{3n-1}, nx^{3n-1}, nx^{4n-1}$ There are a few other answers. I was just not sure how to start this problem?","['taylor-expansion', 'sequences-and-series', 'generating-functions', 'power-series', 'geometric-series']"
2255186,$\mathbb{A}^1/(0\sim 1)$ (with pushforward sheaf) has the same distinguished opens as $\mathbb{A}^1$?,"I just read something in Eisenbud and Harris' The Geometry of Schemes that I am having trouble believing. I must be missing something. Can you help me figure out what? Let $(X,\mathscr{O})$ be a ringed topological space. Let $R = \mathscr{O}(X)$. For given $f\in R$, let $U_f$ be the set of points $x$ of $X$ such that $f$ is a unit in $\mathscr{O}_x$. Eisenbud and Harris say $(X,\mathscr{O})$ is affine if: (i) $\mathscr{O}(U_f) = R_f$. (ii) $\mathscr{O}_x$ is a local ring for all $x\in X$. (iii) The natural map of topological spaces $X\rightarrow\operatorname{Spec} R$ given by mapping $x$ to the pullback in $R=\mathscr{O}(X)$ of the maximal ideal of $\mathscr{O}_x$ is a homeomorphism. (This is on pp. 21-22.) Then, Exercise I-24(a) reads: Take $Z=\operatorname{Spec}\mathbb{C}[x]$, let $X$ be the result of identifying the two closed points $(x)$ and $(x-1)$ of $|Z|$, and let $\varphi:Z\rightarrow X$ be the natural projection. Let $\mathscr{O}$ be $\varphi_*\mathscr{O}_Z$, a sheaf of rings on $X$. Show that $(X,\mathscr{O})$ satisfies condition (i) above for all elements $f\in \mathscr{O}(X) = \mathbb{C}[x]$, but does not satisfy condition (ii). I don't see that $(X,\mathscr{O})$ satisfies condition (i) either. It seems to me that if $p^\star\in X$ is the image of the two identified closed points, then $\mathscr{O}_{p^\star}$ is the ring obtained by localizing $\mathbb{C}[x]$ at the complement of the union $(x)\cup (x-1)$. (This is the failure of (ii) because this ring has two maximal ideals.) Then let $f$ be any function in one but not the other of $(x),(x-1)$; $f=x$ for example. The set $U_f$ of $p\in X$ such that $f$ is a unit in $\mathscr{O}_p$ does not include $p^\star$. In the case $f=x$ it is precisely the complement of $p^\star$. Then $$\mathscr{O}(U_f) = \mathscr{O}_Z(\operatorname{Spec}\mathbb{C}[x]\setminus \{(x),(x-1)\})= \mathbb{C}[x]_{x(x-1)} \neq \mathbb{C}[x]_x = R_x.$$ Thus I conclude that $\mathscr{O}(U_f) \neq R_f$ in this case. What am I missing?","['schemes', 'algebraic-geometry']"
2255188,Definitions of an Algebraic Variety,"I often find the following definition of an algebraic variety: Let $A$ be a commutative ring with unity, $I\subset A$ an ideal, then the algebraic variety associated to $I$ is defined as $V(I):=\{\mathfrak{p}\in \text{Spec(A)}\mid \mathfrak{p}\supset I\}$ In other textbooks, there is also this one: For an algebraically closed field $K$, $A:=K[x_1,...,x_n]$ and an ideal $I\subset A$, the algebraic variety associated to $I$ is the set $V(I)=\{(a_1,...,a_n)\in K^n\mid p(a_1,..,a_n)=0\,\,\forall p\in I\}$. Since every maximal ideal of $K[x_1,...,x_n]$ is of the form $(x_1-a_1,...,x_n-a_n)$, the last definition is, morally speaking, the same as $V(I)=\{\mathfrak{m}\in \text{Maxspec}(A)\mid\mathfrak{m}\supset I\}$. The second one seems more concrete, since maximal ideals are like points, but I don't know what is the motivation for the first one, which adds up more elements to the variety. What is the need for two different definitions? Why not just stick with one of them? What are the advantages/disadvantages of each?","['abstract-algebra', 'maximal-and-prime-ideals', 'algebraic-geometry', 'commutative-algebra']"
2255193,Is there a characterisation of irreducibility via ideals/quotient ring?,"In an integral domain $R$, we have the following characterisation of prime elements: $p  \in R$ is prime $\iff$ $pR$ is a prime ideal $\iff$ $R/pR$ is an integral domain. I was wondering whether there is a similar characterisation of irreducible elements and would appreciate any suggestions on this matter.","['abstract-algebra', 'ring-theory', 'ideals']"
2255211,Difficult triangle problem,"In $△ABC$,  point $E$ on $AC$ such that $AE = 2 EC$ and $\angle ABE = 2 \angle EBC$, point $F$ on $BE$ such that $AF \perp BE$, and point $D$ on $AC$ such that $AD=DC$. Prove that $DF \perp BC$. I (Michael) tried to prove that $\overrightarrow{DF}\cdot\overrightarrow{BC}=0$, but it gives very ugly computations.","['triangles', 'geometry']"
2255254,What triangles do the $p-$adic numbers generate?,"What triangles do the $p-$adic numbers generate? Every pair of parameters $m>n$ of Euclid's formula for generating unique, prime, pythagorean triples, when arranged as $x=\frac{m}{n}$ forms a unique $2-$adic rational number satisfying $x>1$ and $\lvert x\rvert_2\neq 1$. I understand that the $2-$adics include irrrational numbers which makes me curious as to how this analog is extended into these.  A little experimentation seems to show that these generate further prime triangles, with non-integer sides. It would seem likely the $p-$adics are closely related to various fields in which the right angled triangles are prime. What sets of triangles do the $3-$ adic and $p-$adic numbers in general, generate?  Is this observation used to help visualise and solve problems in number theory?","['number-theory', 'trigonometry', 'p-adic-number-theory', 'algebraic-geometry']"
2255272,"if $2^n+1$ is prime, then n = $2^r$ and $(x - y) \mid(x^k - y^k$) only with natural numbers","I need to prove that if $2^n + 1$ is prime, then $n = 2^r$ for a natural number $r$. I do know how to prove it with the lemma $(x - y) \mid (x^k - y^k)$, but in order to prove it with this lemma, I need to substitute $y$ with $-1$ and my problem is, that in my case, this lemma is only given if $x$, $y$, $k$ are natural numbers. Could you please tell me how to prove it without needing a number from $Z$ to prove this theorem?! Thank you!","['divisibility', 'prime-numbers', 'discrete-mathematics']"
2255302,Possible values of $\int_\gamma{\frac{1}{z}}dz$,"What are the possible values $\int_\gamma{\frac{1}{z}}dz$ where $\gamma$ is a path that starts at $z=-i$  and ends $z=2i$ and avoids the origin? I pick a specific branch cut, for example negative x axis, so $-\pi \leq \theta \leq \pi$. $\mathbb{C} -$branch cut is a simply connected region so integral will be the same over all the paths. Then I have $\int_\gamma {\frac{1}{z}dz} = \int_\gamma{\frac{d}{dz}(\log(z))dz} = Log(2i) - Log(i) = \ln2 -i\frac{\pi}{2} - \ln(1) - i\frac{\pi}{2} = \ln(2) - i\pi$ Is this correct? I am confused about the 'possible values' in the problem statement",['complex-analysis']
2255316,Expectation of increasing transformation of random variables,"Suppose that $X$ is a positive continuous random variable with infinitely differentiable pdf $f_\theta (x)$ and suppose that its expectation is increasing in $\theta$. That is, the function
$$
g_{1}(\theta) = \mathbb{E} [X] = \int_{\mathbb{R}_+} x \, f_\theta(x) \, \mathrm{d} x  
$$
is increasing in $\theta$. Now suppose that $h$ is infinitely differentiable, positive, and increasing ($h$ doesn't depend on $\theta$, either). Is it true that the function
$$
g_2 (\theta) = \int_{\mathbb{R}_+} h(x) \, f_\theta(x) \, \mathrm{d} x
$$
is increasing in $\theta$? (or are there any extra restrictions, such as convexity or concavity, which might ensure that the statement is correct?). I've tried some examples, like $X \sim $ Normal$(\mu,1)$ along with some increasing transformations, and it seems to work. I've started taking derivatives inside the integral, but I haven't succeeded in proving it. Any help would be much appreciated, thanks!","['expectation', 'probability', 'probability-distributions']"
2255358,Injective derivative implies locally injective function,"I am working on a proof for my real analysis class, and got stuck. Let $U$ be an open subset of $\mathbb{R}^n$. Let $f: U \to \mathbb{R}^m$ be a continuously differentiable map, and further suppose that $Df(x_0)$ is injective for some $x_0 \in U$. Show that there exists an open set $U_1 \subset U$ containing $x_0$ such that $f$ restricted to $U_1$ is injective. I have already shown that for $x, y, x_0 \in U$, we have that $||f(x) - f(y) - Df(x_0)(x-y)|| \leq ||x-y||\sup||Df(v)-Df(x_0)||$ (*) by using the mean value inequality. Here I am taking the supremum over $v$, where $v$ is in the line segment connecting $x$ and $y$. I was given a hint to apply this inequality to show that for some open ball $B_r (x_0)$, we have that $||f(x_1) - f(x_2)|| \geq C||x_1 - x_2||$ (**) for some constant $C$. It is clear to me that injectivity follows from the second inequality (**), but I am struggling to show that this inequality is true. The injectivity of $Df(x_0)$ gives us that $Df(x_0)(x-y) \neq 0$ for $x \neq y$, and I tried using this fact to break up the left hand side of (*) by, e.g., using the triangle inequality, but was unable to make much progress.","['multivariable-calculus', 'real-analysis', 'derivatives']"
2255364,Crazy Iterated Square Roots,"I was messing around with infinite square root nesting problems like
$$w_1=\sqrt{1+\sqrt{1+\sqrt{...}}}$$
which is an easy example. I decided to try one where the terms inside of the square roots form a geometric sequence:
$$w_2=\sqrt{2^{-1}+\sqrt{2^{-2}+\sqrt{2^{-3}+\sqrt{...}}}}$$
but I can't figure it out. I figured that I probably have to set it equal to $x$ and define $x$ as a function of itself, but I'm not sure how to do that. A similar problem that I did figure out how to do was
$$w_3=\sqrt{2^{-1}+\sqrt{2^{-2}+\sqrt{2^{-4}+\sqrt{2^{-8}+\sqrt{...}}}}}$$
because if you multiply it by $\sqrt{2}$, it collapses to a problem of the first form that I mentioned. Any ideas about that second problem?","['radicals', 'function-and-relation-composition', 'nested-radicals', 'sequences-and-series', 'geometric-series']"
2255369,"Have any of you seen anything like this before? Where should someone go to publish a ""new"" function?","I'm just some random bum calculus II student who was tinkering around with calculus and I think I came up with some new function on my own.
so the tl;dr of my function is that you take some function and project that function onto another one. The function is called $b(f(x),g(x))$ where $f(x)$ is the function, and $g(x)$ will be treated as the axis. Here are some picture examples. $b(sin(.5x),5sin(.1x))$ $b(sin(x),.01x^2)$ If it turns out that this is something new, where should I send it to to spread the word? Thank you!","['proof-writing', 'publishing', 'calculus', 'functions']"
2255371,Non conjugate points on a Riemannian manifold with two connecting minimizing geodesics,"We know that for a point $q$ in the cut locus of a point $p$ in a complete Riemannian manifold there are two possibilities: the point $q$ is conjugate to $p$ or they are connected by (at least) two minimizing geodesics. I have been told that there is an example of two conjugate points with a unique minimizing geodesic, and, conversely, of two non conjugate points connected by two minimizing geodesics. Can someone provide me some hints about the latter? I suspect that something on the torus can help me, but I can't say anything precise.","['riemannian-geometry', 'differential-geometry']"
2255375,How to solve this series with a log on the denominator?,"So I stumbled upon a series I can't quite solve: $$S=\sum_{n=2}^\infty\frac{(-1)^n}{n\ln(n)}\approx0.526418$$ Notice that if we generalize this: $$S(x)=\sum_{n=2}^\infty\frac{(-1)^n}{n^x\ln(n)}$$ and differentiate with respect to $x$ , we get $$S'(x)=\sum_{n=2}^\infty\frac{(-1)^{n+1}}{n^x}=\eta(x)-1$$ where $\eta$ is the Dirichlet eta function.  It then seems natural to try and integrate backwards: $$S(x)=S(x_0)+x_0-x+\int_{x_0}^x\eta(x)\ dx$$ But I'm not sure how to compute this into some sort of closed form. Also accepting any proofs that this series doesn't have a closed form. By closed form, I mean something involving well-known constants such as $\pi,e,\gamma$ , the Gamma function, the Reimann zeta function, and solutions to algebraic differential equations with algebraic initial conditions.","['definite-integrals', 'sequences-and-series', 'calculus']"
2255388,"Find a non-zero integer matrix $X$ such that $XA=0$ where $X,A,0$ are all $4 \times 4$","Let $A$ be the following $4 \times 4$ matrix.
\begin{bmatrix}1&2&1&3\\1&3&2&4\\2&5&3&7\\1&4&1&5\end{bmatrix} How can we find a non-zero integer matrix $C$ such that $CA = 0_{4 \times 4}$ Note that $0$ is a $4 \times 4$ matrix.","['matrices', 'linear-algebra']"
2255407,Is the property of being an inner product space a topological notion?,"Let $(E,\lVert\cdot\rVert)$ denote a normed vector space. Recall that an inner product space $E$ is a NVS with an additional gadget, namely an inner product that induces the norm. But, a NVS space $E$ is an IPS if and only if the norm satisfies the parallelogram law, i.e. if for all $x,y\in E$, $$\lVert x+y\rVert^2 + \lVert x-y\rVert^2 = 2\lVert x\rVert^2 + 2\lVert y\rVert^2$$ which allows us to define an inner product by letting
$$\langle x,y\rangle = \frac12\left(\lVert x+y\rVert^2-\lVert x\rVert^2 - \lVert y\rVert^2\right).$$
Now, this tells us that the inner product is uniquely determined by the NVS structure. Can we take this further? Can we say that the IPS structure on $E$ is uniquely defined by the structure of $E$ as a topological vector space? Or do there exist non isomorphic IPS's that are isomorphic as topological vector spaces?",['functional-analysis']
2255453,One die is rolled three times,"One die is rolled three times. What is the probability that you get a strictly increasing sequence of rolls (meaning roll 1 < roll 2 < roll 3)? The total number of possible outcomes is 216. I was shown the answer to this question, but not the steps taken to get the answer. I would like to know how visually, if that makes sense. If it says increasing , it means I can't have, for example: (1 < 4 < 6)? Or does it have to be in order, like: (1 < 2 < 3), (2 < 3 < 4), (4 < 5 < 6)?","['statistics', 'probability']"
2255456,Eigenvalues of symmetric orthogonal matrix,Can we say that Eigenvalues of symmetric orthogonal matrix must be $+1$ and $-1$ ? Since eigenvalues of symmetric matrices are real and eigenvalues of orthogonal matrix have  unit modulus. Combining both result eigenvalues of symmetric orthogonal matrices must be $+1$ and $-1$ . Please clarify whether I am correct? Is there any other approach to solve this problem? Thanks,"['eigenvalues-eigenvectors', 'matrices', 'symmetric-matrices', 'orthogonal-matrices', 'linear-algebra']"
2255508,Conformal Mapping #5,"I am studying for my final exam and am really struggling on this question #5.  I have attached both the question and the answer listed in the book.  I am really trying to get the ideas down so that I do well on the final. My attempt (Finding a conformal map of the part of the upper half-plane outside a circle of radius r onto the entire upper half plane): I want to use a known conformal map to map the domain to the first quadrant.  I then want to use w=z^2 to map to the first quadrant to entire half plane.  Finally I want to use a linear fractional transformation that maps the upper half-plane to itself.  The only thing is I don't know how to map the domain to the first quadrant and what the linear fractional transformation should be, but this is my general idea that I am thinking. Any help, suggestions, tips would be much welcomed, as I am struggling with these concepts.","['complex-numbers', 'calculus', 'complex-analysis', 'conformal-geometry', 'analysis']"
2255523,Existence of translations dilations compactifying set,"I am reading the book J. Krieger, W. Schlag Concentration Compactness for critical Wave Maps , in which one of the key preliminary reductions is Corollary 9.36 on pg. 315, which I have reproduced below. Corollary 9.36 There exist continuous functions $\bar{x} : I \rightarrow\mathbb{R}^{2}$ and $\lambda : I \rightarrow\mathbb{R}^{+}$ so that the family of functions $\{\lambda(t)^{-1}\Psi_{\alpha}^{\infty}(t,(\cdot-\bar{x}(t))\lambda(t)^{-1})\}_{t\in I}\subset L_{x}^{2}$ is pre-compact. Since I believe my issue can be stated without specifying exactly what the function $\Psi_{\alpha}^{\infty}$ defined on the interval $I$ is, I will not do so. Also, I am content with showing the existence of (possibly) discontinuous functions $\bar{x}$ and $\lambda$. The proof of Corollary 9.36 is by contradiction. I.e. the authors first assume that there do not even exist discontinuous such functions $\bar{x}$, $\lambda$, from which they claim there exists $\varepsilon>0$ and a sequence of times $\{t_{n}\}\subset I$ so that
  $$\inf_{\lambda>0, \bar{x}\in\mathbb{R}^{2}}\|\lambda^{-1}\Psi_{\alpha}^{\infty}(t_{n}, (\cdot-\bar{x})\lambda^{-1})-\Psi_{\alpha}^{\infty}(t_{m},\cdot)\|_{2}\geq\varepsilon \tag{*}$$
  for any $n\neq m$. I do not see why ( * ) follows from the authors' assumption. I looked at the cited works [14] and [15] in the proof, but these papers did not answer my question, as they state ( * ). I have been struggling with this issue for a while now and would appreciate any clarification.","['functional-analysis', 'compactness', 'partial-differential-equations']"
2255539,"Kernel of ""polynomial evaluation map"" for finite fields","For a field $k$ and $n$ a natural number (at least $1$) define the 'evaluation at a point' $k$-homomorphism $$
\varphi_{k, n} : k[X_1, \ldots, X_n] \to k^{k^n} : f \mapsto (f(a))_{a \in k^n}.
$$ One easily shows by induction on $n$ that for $f \in k[X_1, \ldots, X_n]$ with $\deg_{X_i}(f) < \lvert k \rvert$ for all $i = 1, \ldots, n$ either $f = 0$ or $\varphi_{k, n}(f) \neq 0$. In particular it follows that $\varphi$ is injective if $k$ is infinite. If $k$ is the finite field with $q$ elements, it follows that the kernel of $\varphi_{k, 1}$ is the ideal generated by $X^q - X$. Can a description of the kernel of $\varphi_{k, n}$ be given for finite fields $k$ and $n > 1$? Clearly it contains $X_i^q - X_i$ for all $i$, but is it the ideal generated by those polynomials?","['finite-fields', 'abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
2255591,Step-by-step derivative of $\left ( \frac{c_1 x}{c_2 x + c_3 + c_4 \sqrt{c_5 x}} \right)^{c_6x + c_7 + c_8 \sqrt{c_9 x}}$,"Can someone please walk step by step on how to calculate the derivative $\left ( \frac{c_1 x}{c_2 x + c_3 + c_4 \sqrt{c_5 x}} \right)^{c_6x + c_7 + c_8 \sqrt{c_9 x}}$ Where the $c_i$ are constants, which are positive.",['derivatives']
2255598,Combination Q : How many combinations of $5$ cards contain only diamonds?,"Question 1a) How many possible combinations of $5$ card poker hands are there? Answer : $\binom{52}5$ - basically the combination formula : $$\frac{N!}{(N-r)!r!}$$
(this is correct because we did it in class) I need help on this question : How many combinations of $5$ cards contain only diamonds? My Answer : $\binom{52}5 - \left[\binom{52}{13}+\binom{52}{13}+\binom{52}{13}\right]$ Is it correct? If not, what is the correct answer?","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2255607,Homomorphism between two rings,"Is homomorphism between two rings a symmetric relation? That is, suppose $\exists \phi:R\rightarrow R'$ a ring homomorphism. Then does there exist a ring homomorphism from $R'$ to $R$?","['abstract-algebra', 'ring-theory']"
2255634,Solve the differential equation IVP,"Solve $\displaystyle x \frac{dy}{dx} = 2y + x^2, y(1) = 2$ We can use the homogeneous form, $y = vx$, so $dy/dx = xdv/dx + v$ $x^2dv/dx + vx = 2x(v + x) \implies x^2 dv/dx = vx + x \implies x dv/dx = v + 1 \implies (v+1) dv = xdx \implies v^2/2 + v = x^2 + C$ Then we would just substitute $v = y/x$ But is there a simpler method?","['ordinary-differential-equations', 'calculus']"
2255659,Cartesian product of 3 sets,"I'm not sure on how to do the Cartesian product of the 3rd set. But this is how I have done it not sure if I'm correct. A = {0,1} 
B = {1,2} 
C = {0,1,2} 
Calculate (A X B ) X C 

A X B = { (0,1),(0,2),(1,1), (1,2) } 

(A X B) X C = {(0,1,0) , (0,2,1) , (1,1,2) , (1,2,0) , (1,1,1), (1,2,2), (1,2,0), (1,2,1) }","['products', 'elementary-set-theory']"
2255665,Can it be useful to think of operations on subspaces in terms of operations in elementary set theory?,"This question is something that I have been thinking about on and off for a while. The basic premise is that, in Linear Algebra, a lot of the basic operations performed on subspaces have corresponding familiar operations that are performed on subsets of general sets. The operations on sets just have to be changed slightly to ensure that we always get subspaces. Below are some examples (in each example $V$ is a vectorspace and $U,W$ are subspaces of $V$): In a general set there is the concept of the empty set ($\emptyset$), which contains no elements and is a subset of every other set. However, $\emptyset$ is not a subspace. The subspace that corresponds to the $\emptyset$ would be $\{0\}$ where $0$ is the additive identity in $V$. This is clealy the smallest subspace and, like $\emptyset$, we have that $\{0\} \subseteq U$ for every subspace $U$. The set $U \cap W$ is a subspaces of $V$ for all subspaces $U,W$ so this does not need to be changed. $U \cup W$ may not be a subspace of $V$. The set $U + W$ can be thought of the corresponding subspace. $U \cup W$ is the smallest subset that contains both $U$ and $W$. Similarly $U + W$ is the smallest subspace that contains $U$ and $W$. We also have this relation. If $U \subseteq W$, then $U \cup W = W$ and $U + W = W$. If $U$ is a subspace, then $U^c$ will never be a subspace (as it does not contain $0$). One way to think about $U^c$ is that it is the unique subset of $V$ such that $U \cup U^c = V$ and $U \cap U^c = \emptyset$. We have subspace notions of $\cup$ and $\emptyset$, so we will want the subspace $W$ that corresponds to $U^c$ to be such that $U+W=V$ and $U \cap W = \{0\}$. Clearly there could be many such subspaces $W$ but, if we are working in an inner-product space, then $W=U^\perp$ is an obvious choice. I understant that this is quite a long post (thank you to those you have read this far). I would like to hear what people think about this, in particular: Do you think that this is a useful\interesting way to think about subspaces and operations defined on them? Could this way of thinking be perhaps be used as motivation when first introducing the concept of a subspace? How misleading could this way of thinking end up being? Thank you. Any answers/comments are greatly appreciated.","['soft-question', 'elementary-set-theory', 'education', 'linear-algebra', 'vector-spaces']"
2255673,n-Meta tic tac toe strategy,"We all know how 1-Meta tic tac toe works-standard tic tac toe. 2-Meta tic tac toe works by placing tic tac toe grids in a tic tac toe grid. Players can go in any grid at any time, and the player who wins a grid has placed his gone in the larger grid. If the game is a tie, a fair coin is flipped to determine the winner of the square. extending this, n-Meta tic tac toe works by putting n-1-Meta tic tac toe grids in a tic tac toe grid. The question is, what is the optimal strategy(or what are some interesting conclusions we can make about strategy) and what conclusions can we make about the game itself. I have no idea how to approach this.","['combinations', 'combinatorics', 'combinatorial-game-theory', 'game-theory']"
2255738,Differentiate $\displaystyle y = a^{x ^{a^{x^\cdots}}}$. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Could anyone help with this question: Edit: Reducing it to one of these options would be great!","['derivatives', 'infinite-product', 'calculus']"
2255767,Why doen't we consider nonlinear estimators for the parameters of linear regression models?,"The Gauss-Markov theorem tells us that the ordinary least-squares (OLS) estimator is the best linear unbiased estimator (BLUE) for the coefficients in a linear regression (given some conditions on the errors). I can understand why we want an unbiased and minimum-variance (""best"") estimator, but why linear? Why not an estimator that depends on any other power (square, square root, etc) of the data? More specifically, for an $n\times m$ data matrix $X$ predicting an $n \times 1$ response vector $y$ in the model $y = \beta X + \epsilon$, the OLS estimator for the coefficients $\beta$ is, $$\hat\beta = (X^TX)^{-1}X^Ty = Cy = c_0 y_0 + c_1 y_1 + c_2 y_2 + \cdots $$ Note that $\hat\beta$ is defined linearly in terms of $y_i$ and thus a linear estimator. Is there a particular reason we don't consider estimators of the form,
$$ \tilde\beta = Cy^a = c_0 y_0^a + c_1 y_1^a + c_2 y_2^a + \cdots $$",['statistics']
2255768,Proving differentiability implies continuity using sequential definition of derivatives,"I have seen many proofs using this approach: Let us suppose that $f$ is differentiable at $x_0$. Then
$$ \lim_{x\to x_0} \frac{f(x) - f(x_0)}{x-x_0} =  ‎f^{\prime} ‎(x) $$ and hence $$ \lim_{x\to x_0} f(x) - f(x_0) = lim_{x\to x_0} \left[ \frac{f(x) - f(x_0)}{x-x_0} \right] \cdot lim_{x\to x_0} (x-x_0) = 0$$ We have therefore shown that, using the definition of continuous, if the function is differentiable at $x_0$, it must also be continuous. However, I was wondering if you can use this same proof using the sequential definition of differentiability that states: If $f$ is a function and has derivative $f'(c)$ at the point $c$ in the domain of $f$ means that if ($a_n$)$_{n=1}^{\infty}$ is any sequence converging to $c$ such that $a_n$ $\not= c$is in the domain of $f$ for all $n \in \mathbb{N},$ then: $$\left[ \frac{f(x_n)-f(c)}{x_n-c}\right]_{n=1}^{\infty}$$converges to $f'(c)$ My attempt using this definition: $\left(\frac{f(x_n)-f(c)}{x_n-c}\right)_{n=1}^{\infty}$. Let $\epsilon >0.$ Then $|\frac{f(x_n)-f(c)}{x_n-c}-$$f'(c)$$| < \epsilon$ <=> |$f(a_n)-f(c)$|<($\epsilon + |f'(c)|$)|$a_n-c$| I thought this could be the start to a proof similar to the one above, but I am stuck after this point. I'm not sure if I have to use the delta-epsilon or sequential definition of continuity to continue with this proof, or if there is another way. Any suggestions would be appreciated.","['derivatives', 'real-analysis', 'continuity', 'proof-verification']"
2255769,Probability: What is the probability that sum of elements in array is greater than or equal to 10?,"I want to calculate probability such that the sum of N array elements is greater than or equal to M number . Where in N array the first element of array is N while other are 1 to N-1 (can be repeating). For example: My array size is N=5 and M=10 , first element is always 5 while others from 1 to 4. So it looks like in below iteration. Since except 1st, other elements get generated randomly and I need to find probability for Sum>=10 ? Random_Iteration1: Arr=[5, 3, 2, 1, 3] Sum = 13
    Random_Iteration2: Arr=[5, 1, 1, 1, 1] Sum = 9
    Random_Iteration3: Arr=[5, 1, 2, 2, 1] Sum = 11 I have written below code in Python: import numpy as np
    N=5 #array size
    M=10 
    arr = []
    arr.append([N])
    arr.append(np.random.choice(np.arange(1, N), size=N-1).tolist()) 
    arr = sum(arr,[]) #generates array such that 1st element is N, rest are randomly generated elements from 1 to N-1
    arr_sum = np.sum(arr) #gives array sum

    possibilities = N*N
    #numerator = I am not sure what to take here I would really appreciate any help. Please let me know if any details in explanation are required.
Thank you.","['discrete-mathematics', 'probability-theory', 'probability-distributions', 'probability', 'python']"
2255772,What are some examples of Idempotent functions?,"I'd just like to know for my own experimentation a list of known functions in algebra that satisfy $$ f(f(x))=f(x), $$ like how there's a list of known involution functions on wikipedia. But somehow, I can't find a single example anywhere on the internet of even one idempotent function.","['algebra-precalculus', 'functions', 'functional-equations']"
2255782,Parametric integration problem,"If $$I_n = \int_0^1{x^n\sqrt{1-x^2}}\, \mathrm{d}x,$$ then find $$\lim_{n\to\infty}\frac{I_n}{I_{n-2}}.$$","['definite-integrals', 'limits']"
2255856,Find minimum value of the function [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question If $g(x) = \max|y^2 - xy|$ for $0\leq y\leq 1$. Then the minimum value of $g(x)$ is? I am not being able to proceed. Tried drawing the graph.","['algebra-precalculus', 'maxima-minima', 'absolute-value']"
2255873,The unit ball $S^n$ is homeomorphic to the one-point compactification of $R^n$,"I saw many different proofs in the community of the statement in the title. And I want to demonstrate my proof of the general case. I have tried to show the one-point compactification is homeomorphic to $S^n$ directly, but encountered difficulty in showing the continuity. So I found another clean proof which I want to share with you.",['general-topology']
2255879,Difficult Calculus(?) problem,"For the function $f(x)$, find the constant n where $f(x)$ has a maximum at $(n,1)$$$f(x)=\frac{x^{n-x}}{(n-x)!}$$
It is roughly $0.561459...$, but this is through numerical guess and check work. I'm fairly confident that the solution will be some infinite series that involves the Euler-Mascheroni constant and the digamma function, along with the Reimann-Zeta function, but I haven't been able to work anything out that leads to any kind of evidence to suggest it even has a way to express $n$ as anything more than a numerical value. Some of you may be wondering how I know that it can even have a maximum at $(n,1)$. you'll notice that when $n=x$, $f(x)=1$ and I'm not sure how to describe this so just play with the value of $n$ on https://www.desmos.com/calculator/jb8x3n0cya and you'll see how the graph works. The values that intercept with $y=1$ are what I've found to be important. P.S. Should $f(x)$ be $f(x,n)$? I'm really not sure.",['multivariable-calculus']
2255930,"Vector spaces ""over"" a topological space","The definition of a vector bundle includes a map $\pi : E \rightarrow X$ and an assignment to each $x \in X$ a vector space structure on $\pi^{-1}(x)$. However, I find this viewpoint a little strange and hard to work with. So, I was just wondering if we can recast this in slightly different terms. Given a commutative ring object $R$ in the category $\mathbf{Top}$, it seems to me that we can get a corresponding commutative ring object $R$ in the slice category $\mathbf{Top}/X$, namely $(X \times R, (x,r) \mapsto x).$ My idea was then to study $R$-module objects in the category $\mathbf{Top}/X$, and with a bit of luck, these will turn out to be the same as maps $E \rightarrow X$ that are equipped with $R$-module structures on each fiber. Question. Does this work, and if not, what goes wrong? Also, is there a slick way of expressing the local triviality condition in this framework, so as to recover the usual definition of a vector bundle?","['differential-topology', 'category-theory', 'general-topology', 'vector-bundles', 'topological-vector-spaces']"
2255939,Does absolute integrability imply integrability?,"I am quite confused about the notion of integrability. In the context of an introduction to complex analysis and Fourier transforms, I am told that if $f$, a complex or real valued function, satisfies the following: $$ \int_{-\infty}^{\infty} \lvert f(x) \rvert dx<\infty$$ then it is absolutely integrable. However, does this also imply that $f$ is integrable? What can we conclude about $f$ given the above condition on its absolute value (or modulus). I have no notions of Lebesgue integrability.","['complex-analysis', 'real-analysis', 'lebesgue-integral']"
2255968,$1 + \frac 64 + \frac {14}8 + \frac {30}{16} + \ldots$,"I have to calculate the sum upto n terms of the following: $$1 + \frac 64 + \frac {14}8 + \frac {30}{16} + \ldots$$ I found the general term as: $$T_n = \frac {an^2+bn+c}{2^{n}},$$ where a, b and c are determined as follows: $$a+b+c=2; 4a+2b+c=6; 9a+3b+c=14.$$ Solving and applying: $$T_n = \frac {2n^2-2n+2}{2^{n}} = \frac {n^2-n+1}{2^{n-1}}.$$ Now, how to compute: $$\sum_{k=1}^{n} \frac {k^2-k+1}{2^{k-1}}$$","['summation', 'sequences-and-series']"
2255981,Conditions on a topological space implying that it has a minimal basis,"This is a question I've had in the back of my mind for a while, motivated by curiosity. Let $(X,\tau)$ be a topological space, and consider $\mathfrak{F}=\{B\subseteq\mathcal{P}(X):B \text{ is a basis for }\tau\}$ partially ordered by inclusion. Are there reasonable conditions on $\tau$ that ensure the existence of minimal elements in $(\mathfrak{F},\subseteq)$?  (I know that if $\tau$ is finite, then there is a minimal basis for $\tau$, but this is hardly interesting.) In particular, does $\Bbb R$ with the standard topology have a minimal basis?",['general-topology']
2256019,Expectation of nonlinear combination of t-distributions,"Let $\varepsilon$ be distributed according to the following $t$-distribution: $$p(\varepsilon) = \frac{\Gamma\left(\frac{\nu+1} 2\right)}{\Gamma\left(\frac \nu 2\right)[(\nu-2) \pi\sigma^2]^{1/2}}\left[1+\frac 1 {\nu-2}\left(\frac \varepsilon \sigma \right)^2\right]^{-\frac{\nu+1} 2}$$ so that $\operatorname{E}[\varepsilon]=0$ and $\operatorname{Var}[\varepsilon] = \sigma^2$. Consider the r.v. $\zeta = \frac \varepsilon \sigma$ which has unit variance. Is it possible to compute in closed form
$\operatorname{E}\left[\frac{\zeta^2}{(a+\zeta^2)^2}\right],\quad a\in\mathbb{R}$?","['probability-theory', 'computational-mathematics', 'statistics', 'probability-distributions']"
2256031,character table and commutator,"It is well-known that an element of commutator subgroup may not be a commutator. Now there is a character-theory technique to check if an element of a group is a commutator. An element $g\in G$ is a commutator in $G$ if and only if 
  $$\sum_{\chi} \frac{\chi(g)}{\chi(1)}\neq 0.$$ The examples of finite groups in which some element of $G'$ is not a commutator are not so easy to produce (many examples are constructed by some ad-hoc method). For such groups, it may be difficult to quickly obtain its character table with minimum tools of character theory. The above theorem appears in chapter 3 of character theory by Isaacs, and so I will consider only these chapters. Question: Is there simple example of a finite group, for which, we can easily determine its character table, and illustrate that some element of its commutator subgroup is not a commutator.","['finite-groups', 'representation-theory', 'group-theory', 'characters']"
2256072,An almost classic inequality,"It is a classical exercise to prove that $e^\pi>\pi^e$. But... is there a way to prove $\sin(e^\pi)<\sin(\pi^e)$ without calculator? I was trying to prove that $13\pi/2<\pi^e$ and $e^\pi<15\pi/2$ and use monotone decreasing property of $\sin$ in $[13\pi/2,15\pi/3]$, but i couldn't prove the last inequalities.","['real-analysis', 'inequality', 'exponential-function', 'pi']"
2256081,Sporadic Groups for non-mathematician,"I am fascinated by the classification of finite simple groups , and would like to understand a bit more about the involved elements. I have some idea what cyclic and alternating groups stand for, and I understand several of the (at least classical, not necessarily exceptional) Lie groups. What I would really like to understand what sporadic groups are. As a non-mathematician, I am interested in practical properties such as: Do they correspond to specific symmetries? If yes, a symmetry of what kind of object? If yes, what is that symmetry? How can I imagine it? What is the dimension (and other property) of those objects which have that symmetry? Can these questions made concrete with the example of some of the smallest groups, such as the Mathieu group ? What group theoretical concepts are neccessary to understand sporadic groups? I would apprechiate every literature suggestion (whether its a book or a review paper), or maybe some video-recorded lectures etc, with the restriction that it should be simple to understand (i.e. understandable for non-mathematicians). That would be super-great, in particuar as I failed to understand it from conventional group-theoretical books/papers, and I wasn't able to find a lecture on that topic.","['finite-groups', 'reference-request', 'group-theory']"
2256083,How to find if this function is always zero?,"The question I faced was: Let $f(x)$ be a non-negative continuous and bounded function for all $x \ge 0$. If $$(\cos x)f'(x) \le (\sin x - \cos x)f(x), \; \forall \; x \ge 0$$
  then which of the following is/are correct? (A) $f(6) + f(5) > 0$ (B) $x^2 - 3x + 2 + f(9) = 0$ has two distinct solutions (C) $f(5)f(7) - f(6)f(5) = 0$ (D) $\lim\limits_{x \to 4} \dfrac{f(x) - \sin(\pi x)}{x-4} = 1$ The answer is: (B), (C) By observation, $f(x)=0$ satisfies the given conditions. But is it the only solution? If so, how to prove it is? After rearranging the terms and combining them, I converted the inequality to this form:
$$ \left( f(x)\,\cos x \right)' + f(x)\,\cos x \le 0 $$
Despite its allure, this inequality isn't getting me anywhere! It doesn't seem to have any information about $f(x)$, since it is stuck with a ""$\cos x$"". Even then, I don't see where I can go with it. So how to solve this problem? Thank you.","['derivatives', 'functions', 'functional-equations']"
2256117,What theorem would be false if the span of empty set is not $\lbrace \mathbf{0}\rbrace$,"I know that many books define that the span of empty set is $\lbrace\mathbf{0}\rbrace$. However, I came across this definition of spanning set from many places (like Roman Steven's Advanced Linear Algebra or even Proofwiki: Let $M$ be a left $R$-module, let $E\subseteq M$, and let $I_n$ be the set $\lbrace x\in\mathbb{N}\mid 1\leq x\leq n\rbrace$ for each natural number $n$. The set span $E$
   (or $\langle E\rangle$) is defined by \begin{equation}  \langle
 E\rangle:=\left\{\mathbf{a}\in
 M\Bigg|\exists(n\in\mathbb{Z}^+)\left[\exists(r:I_n\rightarrow
 R)\exists(\mathbf{u}:I_n\rightarrow E)\left[\mathbf{a}=\sum_{i=1}^n
 r(i)\mathbf{u}(i)\right]\right]\right\}. \end{equation} In other words, the set $\langle E\rangle$ is the set of all possible linear combinations of elements of $E$. My problem is, according to the definition, we must have this: A set $E$ is empty if and only if $\langle E\rangle$ is empty. Why? I will only prove the forward case: Suppose that $E$ is empty, and we assume for the sake of contradiction that $\langle E\rangle$ is not empty. Since $\langle E\rangle$ is not empty, there must exist $\mathbf{a}\in\langle E\rangle$. This implies that there must exist a positive integer $n$ such that $\mathbf{a}=\sum_{i=1}^n r(i)\mathbf{u}(i)$ for some function $r:I_n\rightarrow R$ and some function $\mathbf{u}:I_n\rightarrow E$. Since $I_n$ is not empty, it follows that $E$ must not be empty, which is a contradiction to the assumption that $E$ is empty. QED. So, according the definition, the span of empty set is EMPTY! It's like we have two conventions here. The first one is that the span of empty set is the zero vector space while the second one is that the span of empty set is empty. My problem is, which convention should I stick with (and no, not according to my prof, he doesn't care anyway, but I care). So, I'm considering the consequence of having $\langle\emptyset\rangle=\emptyset$. Well, it has the nice property that $E$ is empty iff $\langle E\rangle$ is empty. But if $\emptyset$ does not span the zero vector space, then the zero vector space would not have a basis, and that's pretty big drawback. So, it would not be true anymore that every vector space has a basis. What other theorems would be false from this basic definition? If there are many drawbacks, should I discard this definition and the book itself?","['linear-algebra', 'vector-spaces']"
2256122,"Can I, by looking at scores from a game, decide how much luck and how much skill is involved?","My wife and I play a lot of rummy against each other, and we keep a record of the score for each game, as well as the accumulated score. Since I have a substantial lead at his point, I claim that I'm a better rummy player than she is, while she argues that it's pure luck. Most people agree that rummy is a game that combines luck and skill, but for many other games it can be hard to decide. Assume we have the following list of scores from a game, but we know nothing about the game. Round   :  1   2   3   4   5   6   7   8   9  10  | Sum  Avg Wins
Player A:  -   -   5   2   -   -  17   -   -   -  |  24  2.4   3
Player B: 12   3   -   -   8   4   -   5  17   4  |  53  5.3   7 Is it possible to examine the scores and decide how much luck/skill is involved? It seems reasonable to me that both the total points and number of wins are important, but are there also other factors?","['statistics', 'hypothesis-testing']"
2256132,Fundamental theorem of finite abelian groups proof,"Can someone give a proof of the ""technical part"" of the following proof? One direction seems pretty trivial, but the other I am having trouble with. Why does it matter that the subgroup $H$ we choose is maximal?","['finite-groups', 'abstract-algebra', 'group-theory']"
2256142,If $\alpha$ and $\beta$ are the roots of $x^2-2x+4=0$ then the value of $\alpha^6+\beta^6$ is,"If $\alpha$ and $\beta$ are the roots of $x^2-2x+4=0$ then the value
  of $\alpha^6+\beta^6$ is I know that, here, $\alpha\beta=4$ and $\alpha + \beta = 2$ and use that result to find $\alpha^2 + \beta^2$ using the expansion of $(a+b)^2$
But how to find $\alpha^6+\beta^6$ ?","['calculus', 'quadratics']"
2256143,Symmetric compatibility between a bundle map and a connection,"Let $E$ be a vector bundle over a smooth manifold $M$, equipped with a connection $\nabla$. 
Let $A:TM \to E$ be a bundle homomorphism. We say $A$ is symmetric-compatible with $\nabla$ if for every $X,Y \in \Gamma(TM)$ $$
A([X,Y])=\nabla_X^E \big(A(Y)\big) - \nabla_Y^E \big(A(X)\big). \tag{1}
$$ Here is the basic example: Let $N$ be a manifold, and let $\nabla^{TN}$ be any symmetric connection on $TN$. Suppose $f:M \to N$ is a smooth map. Take $E=f^*{TN}$, $A=df$. Then, indeed $$ df([X,Y])= \nabla^{f^*TN}_X df(Y) -  \nabla^{f^*TN}_Y df(X). $$ Question: Fix a bundle $E$. Does every connection $\nabla$ on $E$ admit a non-zero symmetric-compatible operator? What are the possible dimensions of the vector space $$\{ A \in \operatorname{Hom(TM,E)} \,|\, \text{ is symmetric-compatible with $\nabla$} \}?$$ Can it be zero? Can it be infinite? I tried to write condition $(1)$ locally in coordinates. Is this notion has been studied? Are there any other ""natural"" examples besides the one I described above? I am mostly interested in the case where the rank of $E$ equals $\dim M$. Edit: The first reasonable thing to do is to understand the local version of the problem: Suppose $\operatorname{rank}(E)=\dim M=d$: Let $U\subset M$ be a neighborhood on which $M$ and $E$ are trivial. Let $x_1,\ldots,x_d$ be coordinates on $U$, and let $e_1,\ldots,e_d$ be a frame of $E$ on $U$. Let $\Gamma_{ij}^k$ represent the connection $\nabla$ on $U$. That is, $$\nabla_ie_j=\Gamma_{ij}^ke_k.$$ For the bundle morphism $A$, write $$A\left(\frac{\partial}{\partial x^i}\right)=A_i^ke_k.$$ So, $$\nabla_iA\left(\frac{\partial}{\partial x^j}\right)=\nabla_iA_j^ke_k=\frac{\partial A_j^k}{\partial x^i}e_k+A_j^k\Gamma_{ik}^le_l=\left(\frac{\partial A_j^l}{\partial x^i}+A_j^k\Gamma_{ik}^l\right)e_l.$$ Finally, $A$ is symmetric compatible with $\nabla$ if and only if the equality $$\frac{\partial A_j^l}{\partial x^i}+A_j^k\Gamma_{ik}^l=\frac{\partial A_i^l}{\partial x^j}+A_i^k\Gamma_{jk}^l$$ holds for every $1\leq i<j\leq d$ and $1\leq l\leq d$. (Since it is enough to verify condition $(1)$ on different pairs of coordinate fields, as observed by Amitai Yuval). In general this is a system of $\frac{d^2(d-1)}{2}$ scalar equations. Let us consider the first non-trivial case: $d=2$: In that case the only surviving pair is $(i,j)=(1,2)$: $$l=1: \, \,\frac{\partial A_2^1}{\partial x^1}+A_2^1\Gamma_{11}^1+A_2^2\Gamma_{12}^1=\frac{\partial A_1^1}{\partial x^2}+A_1^1\Gamma_{21}^1+A_1^2\Gamma_{22}^1,$$ and $$l=2: \frac{\partial A_2^2}{\partial x^1}+A_2^1\Gamma_{11}^2+A_2^2\Gamma_{12}^2=\frac{\partial A_1^2}{\partial x^2}+A_1^1\Gamma_{21}^2+A_1^2\Gamma_{22}^2$$ I still need to think how many degrees of freedom do we have for this system? Note that even if we can solve this locally, it is not clear how to extend a ""symmetric morphism"" defined locally to a global symmetric morphism (bumb functions won't work I think).","['partial-differential-equations', 'symmetry', 'differential-geometry', 'vector-bundles', 'connections']"
2256172,The KKM lemma implies Sperner's lemma: a direct proof?,"It seems fairly well-known that the KKM lemma of Knaster-Kuratowski-Mazurkiewicz implies Sperner's lemma (definitions below). However, I only know of indirect proofs, for instance that KKM can be used to prove Brouwer's fixed point theorem, and that the latter can be used to prove Sperner's lemma. Question: Can Sperner's lemma be proved directly from the KKM lemma, without ""intermediate stops"" at for instance Brouwer, by suitably defining the sets $C_i$ in the KKM lemma below so that points in their intersection must lie in a completely labeled simplex? What I tried: I searched the net without success. I thought it might work to define $C_i$ as the set of points in simplices with label $i$, but run into problems: if a point lies in the intersection of the $C_i$, it lies in a simplex with label $i$ for each $i$, but these simplices may be different for different $i$ and not necessarily, as desired, a single simplex with all labels. Definitions: fix $n$ and let $\Delta = \{x \in \mathbb{R}^n: x_1, \ldots, x_n \geq 0, \sum_i x_i = 1\}$ denote the simplex. For each nonempty $J \subseteq \{1, \ldots, n\}$, let $\Delta_J = \{x \in \Delta: x_j = 0 \text{ for all } j \notin J\}$. KKM lemma: If $C_1, \ldots, C_n$ are closed subsets of $\Delta$ such that $\Delta_J \subseteq \cup_{j \in J} C_j$ for each nonempty $J \subseteq \{1, \ldots, n\}$, then $\cap_{i=1}^n C_i \neq \emptyset$. For Sperner's lemma, a simplicial subdivision of $\Delta$ is a finite collection of smaller closed simplices of the same dimension whose union is $\Delta$; the intersection of any two such smaller simplices must be empty or a face of both. A Sperner labeling assigns a label $1, \ldots, n$ to each vertex of the subsimplices in this subdivision in such a way that $x_i = 0$ implies that its label is not $i$. Sperner's lemma: Consider a simplicial subdivision of $\Delta$ and a Sperner labeling; this subdivision contains a simplex whose vertices have all labels $1, \ldots, n$.","['fixed-point-theorems', 'general-topology', 'simplicial-complex']"
2256192,Counterexample in connected set,"I'm asked to find an example of two connected sets $X$ and $Y$, $X\subset Y$ and $C$ a component of $Y\setminus X$ such that $X\cup C$ is not connected. I figured $X$ must not be closed because then $X\cap C\neq \emptyset$ and $C\cup X$ would be connected. But that's all I got. Any hints would be appreciated.",['general-topology']
2256253,The equivalence of different forms of Baire's category theorem in Rudin's Real and Complex Analysis,"In Rudin's Real and Complex Analysis , Theorem 5.6 (i.e., Baire's Theorem, page 97) states that If X is a complete metric space, then the intersection of every countable collection of dense open subsets of X is dense in X.(1) After the proof, he says that Theorem 5.6 is equivalent to the statement: No (non empty) complete metric space is of the first category.(2) And he points out that to see this, only need to take complements in the statement of Theorem 5.6. But I do not see how that works, by taking complements in the statement of Theorem 5.6, I can only have that Theorem 5.6 is equivalent to the statement: If X is a complete metric space, $\{A_i\}$ is a countable collection of nowhere dense closed subsets of X, then int$(\cup A_i)=\emptyset$.(3) (Or see corollary to baire category theorem ) Of course, (3) or (1) implies (2), but I don't know how to prove that (2) implies (1) or (3). I also know that Theorem 5.6 is equivalent to the statement: If X is a complete metric space, then every non empty open subset of X is of second category.(4) (See About the equivalence of definitions of a Baire Space ) But I do not see this would be helpful. How to prove that (2) implies (1) or (3) or (4)? Any help would be appreciated.","['general-topology', 'real-analysis']"
2256263,How many pairs of clock hands?,"An (imaginary) company producing parlor games for children wants to produce a novel game with pairs of clock hands. Each pair can be fixed at certain non-zero angles and must be placed on a clock face to point at two numbers. At each round player One sets a pair at some angle and player Two must put it on the clock face such that no number is pointed at twice. To this end player Two may consider relocating some of the earlier pairs without changing the fixed angle. The game ends when player Two got stuck or placed all pairs.
The game must be produced for several levels: e.g. a $12$-hours clock for beginners and a $24$-hours clock for advanced players. Aiming at low prices, how many pairs of hands must at least be included in the package for each level? In mathematical terms, the question may be phrased like this: Given an integer $n$ (e.g., $n = 12$, or $n = 24$, or whatever), what is the maximal number $b$ such that $b$ pairs of (distinct) vertices can always be rotated apart in a regular $n$-gon. Note the word ""always"". By way of illustration, it is sometimes possible to locate n/2 pairs with all different angles up to a stretched angle, which is a specification of the pairs. (The phenomenon happens for $n$ of type $8$-fold or $8$-fold plus $2$, and only for these.) So, the company is not inclined to include up to $\lfloor n/2 \rfloor$ pairs of hands. I found that
$$b = \left\{
\begin{array}{rl}
n/3 & n \text{ a multiple of } 3 \\
\lceil (n+2)/3 \rceil & \text{otherwise}
\end{array} \right.$$
is sharp for $n \leq 12$,  for $n$ a multiple of $3$, and for $n = 14, 20$,
but not otherwise in case $n \leq 32$. Part of this knowledge was obtained with computer assistance. I think that problems of this type should be settled by reasoning alone. Anyone? NB: $\lceil x \rceil$ and $\lfloor x \rfloor$ denote upper- and lower integer approximation of a real number $x$.",['combinatorics']
2256264,1998 USAMO problem #4,"A $98 \times 98$ chess board has the squares colored alternately black and white in the usual way. A move consists of selecting a rectangular subset of the squares (with boundary parallel to the sides of the board) and changing their color. What is the smallest number of moves required to make all the squares black? The solution given is: There are $4 \cdot 97$ adjacent pairs of squares in the border and each pair has one black and one white square. Each move can fix at most 4 pairs , so we need at least 97 moves. However, we start with two corners one color and two another, so at least one rectangle must include a corner square. But such a rectangle can only fix two pairs, so at least 98 moves are needed. I have difficulty in understanding the solution specially the bold part. Please can someone help. I understand how 98 can be achieved but cant prove its the minimum, other proofs are welcome as well.","['combinatorics', 'contest-math', 'discrete-mathematics']"
2256286,Definition of groups,"This seems like a very basic question but got me confused. When defining a group we introduce the unit element $e$ which has the following property
$$ge = eg = g \quad \forall g\in G$$ and then the inverse for which we need the unit: $$gg^{-1} =g^{-1}g = e$$ Is it possible to do it the other way around? Can we construct the unit element from the inverse? I think not but haven't found a convincing argument except that we use the unit in the definition of the inverse. But perhaps it is thinkable to conceive a completely different way.","['inverse-semigroups', 'semigroups', 'group-theory', 'definition']"
2256324,Let R be a commutative ring in which $a^2 = 0$ only if $a = 0$ ...,"I've been doing some practice problems for an upcoming intro level abstract algebra class and came across this problem (in Herstein 3rd edition, Ch 4.5 #26 & #28). I had some help from my professor with reasoning through the first part but am unsure if I got it or not. i) Let $R$ be a commutative ring in which $a^2 = 0$ only if $a = 0$. Show that if
$q(x) \in R[x]$ is a zero-divisor in $R[x]$, then, if
$q(x) = a_{n}x^n + a_{n-1}x^{n-1} + ... + a_1x + a_0$
there is an element $b \neq 0$ in $R$ such that $ba_0 = ba_1 = ... = ba_n = 0$. ii) Show that the element b must exist even if the condition ""$a^2 = 0$ only if $a = 0$"" does not hold My figuring thus far:
Let $h(x) \in R[x]$ such that $h(x)q(x) = 0 = q(x)h(x)$ , where $h(x) = c_mx^m+c_{m-1}x^{m-1} + ... + c_1x+c_0$. We know that the product of these polynomials is zero, so we know that every coefficient of the product must be zero: $q(x)h(x) = a_nc_mx^{m+n} + (a_nc_{m-1} + a_{n-1}c_m)x^{n+m-1} + ... + a_0c_0 = 0 \rightarrow a_n$ and $c_m$ are zero divisors in $R$ (as we will have written $h(x)$ and $q(x)$ such that their leading coefficients are nonzero). We also know that $a_nc_{m-1} + a_{n-1}c_m = 0 \rightarrow c_m(a_nc_{m-1}+a_{n-1}c_m) = 0 \rightarrow 0 = (c_ma_n)c_{m-1} = -c_m^2a_{n-1}$. Following this line of reasoning it seems that $b= c_m^k$ for some appropriate k (I think k=n+1?). Does this seem correct? In my mind this is an appropriate proof for i) and ii) but I suspect something more nuanced is going on in ii) that I'm missing. EDIT: I think in part two the issue is that I can't say $c_m^2a_{n-1} = 0$ because I haven't shown that $a_{n-1} \neq j^2$ for some $j \in R$, but I'm still not really sure. Thanks for any and all input. (Meta: First post. Was this appropriate? If not let me know how I can improve)","['abstract-algebra', 'ring-theory']"
2256360,Proof that sum over autocorrelations is -1/2,"I am trying to understand a proof that shows, that the sum over the autocorrelation starting with lag=1 is always equal -1/2, for a stationay time series. The sum looks like this: $$ S_{\rm{afc}}=\sum_{h=1}^{T-1} \hat \rho(h)=\sum^{T-1}_{h=1}\Big( \frac{\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y) } {\sum^{T}_{t=1} (y_t - \overline y)^2 }\Big)$$ with $\hat \rho(h)=\frac{\hat \gamma(h)}{\hat \gamma(0)}=\frac{\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y) } {\sum^{T}_{t=1} (y_t - \overline y)^2 }$ the autocorrelation function defined in terms of an estimate $\hat \gamma = \sum^{T-h}_{h=1} (y_t - \overline y)(y_{t+h} - \overline y)$ of the the autocovariance and $\overline y= { 1  \over T} \sum^T_{t=1} y_t$ the sample mean. The proof is short: 
$$ S_{\rm{afc}}=\sum^{T-1}_{h=1}\Big( \frac{\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y) } {\sum^{T}_{t=1} (y_t - \overline y)^2 }\Big)=\Big( \frac{ \sum^{T-1}_{h=1}\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y) } {\sum^{T}_{t=1} (y_t - \overline y)^2 }\Big)\\=\Big( \frac{ \sum^{T-1}_{h=1}\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y) } {\big(\sum^{T}_{t=1} (y_t - \overline y)\big)^2-2 \sum_{h=1}^{T-1}\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y)}\Big)$$
until here I can understand everything but the last step is a mystery to me:
$$\Big( \frac{ \sum^{T-1}_{h=1}\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y) } {\big(\sum^{T}_{t=1} (y_t - \overline y)\big)^2-2 \sum_{h=1}^{T-1}\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y)}\Big)=\Big( \frac{ \sum^{T-1}_{h=1}\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y) } {-2 \sum_{h=1}^{T-1}\sum^{T-h}_{t=1} (y_t - \overline y)(y_{t+h} - \overline y)}\Big)$$
which is of course -1/2. Why would $\big(\sum^{T}_{t=1}(y_t - \overline y)\big)^2$ vanish? I have no earthly Idea how this might be. In case you want to look at the paper is  ""Sum of the sample autocorrelation function"" by Hossein Hassani DOI: https://doi.org/10.1515/ROSE.2009.008","['statistics', 'summation', 'covariance', 'correlation']"
2256361,Adjoint of an operator on $L^2$,"Consider the Hilbert space $L^2 (1,\infty)$ and a real function $g(x)=x^2$ defined on the interval $(1,\infty)$. Define an operator $T$ by the formula $T(f)=f \cdot g$ for all $f$ in the domain $$D(T)=\{ f \in L^2 (1,\infty); \space  \space f \cdot g \in L^2 (1,\infty), \space \int_1^{\infty}f(x)\mathrm{d}x=0\}.$$ I'm trying to find the adjoint operator $T^*$, i.e. the operator defined on the set $$D(T^*)=\{h \in L^2 (1,\infty); \space  \space  \mathrm{the \space mapping \space} f \mapsto \langle Tf,h \rangle \mathrm{\space is \space continuous \space on \space} D(T)\}$$
such that $\langle Tf,h \rangle = \langle f,T^* h \rangle$ for every $f \in D(T), \space h \in D(T^*)$. I managed to prove that the operator $T$ is densely defined (therefore $T^*$ is well-defined and uniquely determined) and closed (i.e. it has a closed graph). Unfortunately, I'm unable to find a nice characterisation of the set $D(T^*)$. My approach is following: Suppose that $h \in D(T^*)$. Then there exists a uniquely determined (thanks to the density of the domain) function $\Psi \in L^2 (1,\infty)$ such that $\langle 
Tf,h \rangle = \langle f,\Psi \rangle$ for all $f \in D(T)$. Using the definition of the inner product on $L^2 (1,\infty)$ we find out that for all $f \in D(T)$ $$\int_1^{\infty}f \cdot \left( \bar{h} \cdot g \space - \space \bar{\Psi}  \right )=0.$$
But now I'm stuck because I can't guarantee that the function $\bar{h} \cdot g$ is in $L^2(1,\infty)$. If I knew that, then I would just say that $\bar{h} \cdot g$ is equal to $\Psi$ almost everywhere, but without that I don't know how to continue. Thanks for any advice.","['functional-analysis', 'lebesgue-integral', 'linear-algebra', 'analysis']"
2256379,"Show that $\sum^k_{i=0} \binom{n}{i} \leq 2 \binom{n}{k}$, sum of 'the first k' binomial coefficients","I was reading an article on information theory and I came across this upper bound for the sum of 'the first k' binomial coefficients Consider $n \in \mathbb{N}$. For $0 \leq k \leq \lceil\frac{n}{3}\rceil$ we have $\sum^k_{i=0} \binom{n}{i} \leq 2 \binom{n}{k}$ I found this article on mathoverflow about upper bounds for the sum of 'the first k' binomial coefficients, but I haven't been able to work out a proof for it.","['combinatorics', 'inequality', 'summation', 'binomial-coefficients']"
2256389,Finding the preimage,"I want to find the preimage of $]-2,4]$ for the function $f(x)=x^2-x$ This is what I have done so far: We have $0=x^2-x-y$ and therefore the inverse is: $$f^{-1}(y)=\frac{-1\pm \sqrt{1+4y}}{2}$$ And how do I find out the boundaries of the preimage? If I put the boundaries $-2$ and $4$ into the function $f^{-1}$, I will probably not get them. Also I'm not sure which function I have to take when, the one with plus sign or the one with a minus?","['algebra-precalculus', 'calculus']"
2256398,$\dfrac{1}{2\pi i}\int_{C}\dfrac{e^{z}}{z^{3}-1}dz = \sum_{n=0}^{\infty}\dfrac{1}{(3n+2)!}$,"a) Use residue at infinity to solve the problem: If $C$ is a circle $C(0,2)$ traversed in the counter clockwise direction, then $$\dfrac{1}{2\pi i}\int_{C}\dfrac{e^{z}}{z^{3}-1}dz = \sum_{n=0}^{\infty}\dfrac{1}{(3n+2)!}$$ b) By evaluating $$\dfrac{1}{2\pi i}\int_{C}\dfrac{e^{z}}{z^{3}-1}dz$$
using Cauchy's integral formula, show that $$\sum_{n=0}^{\infty}\dfrac{1}{(3n+2)!} = \dfrac{1}{3}(e-\dfrac{2}{\sqrt{e}}\cos(\dfrac{\pi}{3}-\dfrac{\sqrt{3}}{2}))$$ Hint: One may use the identity $\prod_{j=1,j\neq k}^{m}(e^{2\pi ij/m}-e^{2\pi ik/m}) = \dfrac{m}{e^{2\pi ik/m}}$ a) Note that the function $f(z) = \dfrac{e^{z}}{z^{3}-1}$ and we see that there will be 3 singularity, namely $z =1, z = e^{2\pi i/3}\text{ and } z = e^{4\pi i/3}$. All of which are contained in the $C(0,2)$. Well since we are given the hint to solve the first part with residue at infinity, we will follow it. $$\dfrac{1}{2\pi i}\int_{C}f(z)dz = \text{Res}\left[\dfrac{1}{z^{2}}f\left(\dfrac{1}{z}\right),0\right] = \text{Res}\left[\dfrac{1}{z^{2}}\dfrac{e^{1/z}}{\dfrac{1}{z^{3}}-1},0\right] = \text{Res}\left[\dfrac{ze^{1/z}}{1-z^{3}},0\right]$$ We want to find the reside of $\dfrac{ze^{1/z}}{1-z^{3}}$ at $0$. Hence we expand this equation about $0$ in Laurent Series form, $$ze^{1/z}\dfrac{1}{1-z^{3}} = z\sum_{k=0}^{\infty}\dfrac{1}{k!z^{k}}\sum_{m=0}^{\infty}z^{3m} = \sum_{m=0}^{\infty}\left(\sum_{k=0}^{\infty}\dfrac{1}{k!}z^{3n-k+1}\right)$$ We want to find the coefficient of $z^{-1}$ and it happens when $3n-k+1 = -1 \Rightarrow k = 3m+2$. Hence the residue is $$\sum_{m=0}^{\infty}\dfrac{1}{(3m+2)!}$$ First question is part a), why can't i get the answer if i interchange the summation????? By right it should be the same answer. b) We easily find out that the three singularities for the function is $z=1,z=e^{2\pi i/3},z=e^{4\pi i/3}$ And hence we are solving for $$\dfrac{1}{2\pi i}\int_{C}\dfrac{e^{z}}{(z-1)(z-e^{2\pi i/3})(z-e^{4\pi i/3})}dz$$ Since we are required to use CIF to solve, we construct 3 circles $C_1,C_2,C_3$ of radius $\epsilon_1,\epsilon_2,\epsilon_3$ and centered at $z=1,z=e^{2\pi i/3},z=e^{4\pi i/3}$. Then from here, i can only use brute force (REALLY TOOK ME VERY LONG) to solve it, anyone knows how to solve it with the hint?","['complex-analysis', 'contour-integration', 'residue-calculus']"
2256454,"Combinatorial Species, significance and problems can be solved with it.","Combinatorial Species , is a subject I recently came across when just out of curiosity's sake, looked out for possible interaction between category theory and combinatorics. After awhile I ended up here Learning Combinatorial Species. , and later on to this book Combinatorial Species and tree-like structures . For someone comfortable in Category Theory, this may be a very beautiful thing to mull over indeed and creates a flexibility to the theory of generating functions as well, and the latter is of important significance. Though, in any instance of book/notes I can come up with, didn't find out an ""intuitive"" application of combinatorial species. Combinatorics, is definitely not about counting anymore, but arguably someone declares that the most funny stuff in it has to do with counting problems (because those sort of problems have more intuition I guess). So my question has to do with that; Could you give me please an instance of application of Combinatorial Species in Enumerative combinatorics? Any other example of application is welcome too of course! Last comment: I ain't have problem with it becuse its definition or significance. I'm looking for an intuitive approach of the aforementioned notion
(I mentioned the latter, because I want to avoid any possible duplication with other possibly related question on MSE, because I think checked them all and not such an answer/question has been showed up. If such a duplication does exist with an answer though, please feel free to mention it!) Thank you!","['category-theory', 'combinatorics', 'combinatorial-species', 'generating-functions']"
2256488,Any solutions to the functional equation $f(x) = f(x-1)-f(x+1)-ix^3f(x)$?,"Are there any solutions to this functional equation: $$f(x) = f(x-1)-f(x+1)-ix^3f(x)$$ I am not familiar with functional equations and have no idea where to start. All I can say is that $f(0) = f(-1)-f(1)$. Wolfram alpha gives a recurrence relation for $f(n), n\in \mathbb{N}$ provided we know $f(0),f(1)$. Any suggestions?","['recurrence-relations', 'functions', 'functional-equations']"
