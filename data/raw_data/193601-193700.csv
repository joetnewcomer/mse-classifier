question_id,title,body,tags
3711156,discrete metric converges iff it is eventually constant,"I have read previous answers about the proof but there is a small point I want to be sure of. First if we assume that the sequence converges $x_n \to x$ there for all $N\leq n$ there is $\varepsilon >0$ s.t $d(x_n,x)< \varepsilon$ Let $\varepsilon = \frac{1}{2}$ , because $x_n$ converges there is $N\leq n_0$ such that $d(x_{n_0},x)< \frac{1}{2}$ , now if $x_{n_0}\neq x$ then by definition of the discrete metric $d(x_{n_0},x)= 1$ with is a contradiction and therefore it must be that $x_{n_0}=x$ which means that $x_n$ is eventually constant. Second if $x_n$ is eventually constant that means that there is $N\leq n_0$ such that $x_{n_0}=x_{n_0+1}=...$ why can we assume that $x_{n_0}=x_{n_0+1}=...=x$ ?","['general-topology', 'metric-spaces']"
3711175,Hilbert polynomials of closed subschemes $Y \subset \mathbb{P}^n_k$,"Let $k$ any field and $Y \subset \mathbb{P}^n_k$ closed subscheme. We are going
to study the Hilbert polynomials in reversal sense: Let recall a Hilbert polynomial associated to a coherent sheaf $F$ on $X=\mathbb{P}^n_k$ together with line bundle $O_X(1)$ is a polynomial $$\Phi(t) = \sum_{i=0} ^n (-1)^i h^i(X, F \otimes O_X(1)^{\otimes t} )=
\sum_{i=0} ^n (-1)^i h^i(X, F (t))
\in \mathbb{Q}[t]  $$ The Hilbert polynomial associated to a closed subscheme $Y \subset \mathbb{P}^n_k$ as in our case defined by homogeneous ideal sheaf $I_Y$ it the Hilbert polynomial
   of the quotient sheaf $O_Y= O_X/I_Y$ . Two examples $Y \subset \mathbb{P}^n_k$ can be easily computed: (i) $Y \cong \mathbb{P}^r_k$ embedded linearly in $\mathbb{P}^n_k$ over $k$ has Hilber polynomial $\Phi^Y(t)= \binom{r+ t}{r}$ (ii) $Y$ is a hypersurface $H_d$ of degree $d$ in $\mathbb{P}^n_k$ defined
by a homogeneous polynomial $f \in k[x_0,...,x_n]$ obtains HP $\Phi_d^Y(t)= \binom{n+ t}{n}- \binom{n-d+ t}{n}$ The (ii) follows easily from exact sequence $ 0 \to O_{\mathbb{P}^n_k}(-d) \to O_{\mathbb{P}^n_k} \to O_{H_d} \to 0 $ , the additivity of Hilbert polynomials for exact sheaf sequences and previous case (i). Now the question is how to show that cases (i) & (ii) can be reversed: (i) If closed subscheme $Y \subset \mathbb{P}^n_k$ has Hilbert polynomial $\Phi^Y(t)= \binom{r+ t}{r}$ , 
why $Y \cong \mathbb{P}^r_k$ and embedded linearly in $\mathbb{P}^n_k$ over $k$ ? (ii) if $Y \subset \mathbb{P}^n_k$ has Hilbert polynomial $\Phi_d^Y(t)= \binom{n+ t}{n}- \binom{n-d+ t}{n}$ , why $Y$ is a hypersurface $H_d$ of degree $d$ . On (ii) the paper by Nitsure on the construction of Hilbert scheme that originally motivates this question 
has a hint (page 6): If $Y \subset \mathbb{P}^n_k $ is a closed subscheme with
Hilbert polynomial of degree $n âˆ’ 1$ , then show that the schematic 
closure $Z$ of the
height $1$ primary components is a hypersurface in $\mathbb{P}^n_k$ with $\operatorname{deg}(Z) = \operatorname{deg}(Y)$ . Contextually the ""height $1$ primary components"" of $Y$ seems to be 
the irreducible components of $Y$ of codimension $1$ . Why the author called it ""primary""
I not know. The Zariski topology don't draw a difference between prime ideals
and primary ideals having primes as their radicals. Nevertheless I assume that 
the hint refers to irreducible components $C_{i, max} \subset Y$ of maximal dimension. Set $Z:= \overline{\bigcup_i C_{i, max}}$ and the claim is $\operatorname{deg}(Z) = \operatorname{deg}(Y)$ . Why does this equality hold?
And why this implies that $Y$ is hypersurface of degree $d$ ?","['algebraic-geometry', 'hilbert-polynomial', 'sheaf-theory']"
3711210,Convergence of integral of function of Brownian Motion,"Let $B$ be a Brownian motion in $\mathbb{R}^2$ and $f$ be a continuous bounded probablity density function in $\mathbb{R}^2$ . Define $$
A_t = \int_0^t f(B_s) ds
$$ Show that: i) $\mathbb{E} [\frac{A_t}{t}] \to 0$ as $t \to \infty$ ; ii) $A_t \to \infty$ as $t \to \infty$ . I tried to exploit neighbourhood recurrence and the strong markov propertyf or part (ii) but couldn't conclude, while I'm completely lost on (i). Any help/hint?","['stochastic-processes', 'brownian-motion', 'probability-theory', 'probability']"
3711247,Can you define $f(x)$ such that $2^{x}<f(f(f(x)))<2^{2^x}$?,"Can you define a real-valued function $f$ using standard arthimetical operations such that $2^{x} < f(f(f(x))) < 2^{2^x}$ for sufficiently large $x\in \mathbb{R}$ ? I know that the rule $f(f(x))=2^{x}$ can't be established with standard arthimetical operations, but is it possible to find a function using standard arthimetical operations such that $2^{x}<f(f(f(x)))<2^{2^x}$ for sufficiently large $x\in \mathbb{R}$ ?","['exponentiation', 'functions', 'problem-solving']"
3711261,Books on linear algebra more focused towards matrices and determinants rather than vector spaces,"In my syllabus of a competitive exam, we have matrices and determinants and solving linear equations with them instead of linear algebra but during examinations a lot of the times questions are derived from linear algebra and presented such that they can be tackled by matrices and determinants but are tedious. Eg, they will give a 2Ã—2 matrix and then give 4 polynomial as options , where one of them would be a characteristic polynomial. So anyone who know about Cayley-Hamilton Theorem, will easily solve this quickly. So are there any books  available that have a lot of these properties like properties of eigenvectors, idempotent, nilpotent matrices,symmetric, skew symmetric etc. Most of the popular books revolve around teaching the vector spaces and that part really well. I have studied linear algebra from MIT OCW by Gilbert Strang and have partially read his book on the subject too, so even if the book has some parts from vector spaces (which it probably will) , I believe, I will probably be able to comprehend what the author is trying to convey. 
Thanks","['determinant', 'book-recommendation', 'matrices', 'linear-algebra', 'soft-question']"
3711305,Sequence problem : Find $|a_1|$,Given a sequence such that $$a_1a_2=1\ ; \  a_2a_3=2 \  ; \  a_3a_4=3  \ ; \ \dots$$ and $$\lim_{n\to \infty} \frac{a_n}{a_{n+1}}=1$$ find $|a_1|$ . My attempts : We can deduce from this $a_1a_2=1 \  ; \  a_2a_3=2 \  ; \  a_3a_4=3  \ ; \ \dots$ that : $$\prod_{n=k}^{n+1} a_n=n$$ Thus : $$\begin{align}a_n \times a_{n+1}&=n \\ a_{n+1}&=\frac{n}{a_n} \end{align}$$ Therefore : $$\begin{align} \lim_{n\to \infty} \frac{a_n}{a_{n+1}}&=\lim_{n\to \infty} \frac{a_n}{\frac{n}{a_n}} \\ &=\lim_{n\to \infty} \frac{a_n^2}{n} \\&=1 \end{align} $$ Is this can lead us to say that : $$\begin{align} |a_n^2|&\sim n \\ |a_n|&\sim \sqrt{n} \end{align} $$ If this is true we can say that : $$|a_n| =1$$ But I don't know if this is true or not. Any tips or hints ? Thanks in advance !,"['limits', 'calculus', 'sequences-and-series']"
3711384,"$ X_n\stackrel{P}\rightarrow X\text{, }Y_n\stackrel{P}\rightarrow Y \Rightarrow X_nY_n\stackrel{P}\rightarrow XY $. How to show this?","Let $\{X_n\}$ and $\{Y_n\}$ be two sequences of random variables such that $X_n$ converges to $X$ in probability and $Y_n$ converges to $Y$ in probability. Show that $X_n Y_n$ converges to $XY$ in probability. Hence, we have to show that: $$
X_n\stackrel{P}\rightarrow X\text{, }Y_n\stackrel{P}\rightarrow Y \Rightarrow X_nY_n\stackrel{P}\rightarrow XY
$$ I was thinking about some way to 'rewrite' $X_nY_n$ . In particular, $$X_nY_n=X_n(Y_n-X_n)+X_n^2$$ At this point, I was thinking that, for a sufficiently large $M\in\mathbb{N}$ , for $n\geq M$ , since $\lim(a\cdot b)=\lim(a)\cdot\lim(b)$ and $\lim(a+b)=\lim(a)+\lim(b)$ , $$\lim\limits_{n}(X_nY_n)=\lim(X_n)\cdot\lim(Y_n)-\lim(X_n)\cdot\lim(X_n)+\lim(X_n^2)=$$ $$=\lim(X_n)\cdot\lim(Y_n)-\lim(X_n)\cdot\lim(X_n)+\lim(X_n)\lim(X_n)=$$ $$=X\cdot Y -X^2 +X^2=XY$$ However, I am pretty sure this is not the right way for the following reason: convergence in probability of $X_nY_n$ to $XY$ requires that $\lim\limits_{n}\mathbb{P}\left(|X_nY_n-XY|>\varepsilon\right)=0$ and I think that my reasoning - should it be correct - is not sufficient. How could I proceed to solve such an exercise alternatively?","['solution-verification', 'limits', 'convergence-divergence', 'probability-theory', 'random-variables']"
3711389,"$f(x)= \sqrt{\frac{(x+1)^3}{x}}$ find constant values $a,b,c \in\mathbb{R}$ such that $f(x)=ax+b+\frac{c}{x}+o(\frac{1}{x})$ when $x \to +\infty$",Would anyone be kind to explain to me how to do this types of problems? My proffessor gave us couple of this problems for homework and we dont have solutions. This is my first time to do something like this. This is the easiest of them. Please write me a solution and I will find pattern myself. Thanks in advance.,"['functions', 'asymptotics']"
3711428,"Proving $X$ is $\mathcal{A}^{\prime}$-measurable if and only if $Y$ is $\mathcal{A}^{\prime}$-measurable, provided that $X=Y$ a.s.","Let $(\Omega, \mathcal{A}, P)$ be a probability space and $\mathcal{A}^{\prime}$ be the $P$ -completion of $\mathcal{A}$ . Let $X,Y$ be real-valued random variables defined on $\mathcal{A}^{\prime}$ . I need to show that $X$ is $\mathcal{A}^{\prime}$ -measurable if and only if $Y$ is $\mathcal{A}^{\prime}$ -measurable. I have looked up for any hints on this website or google and it seems that you can decompose the set $X^{-1}(A)$ into $$(Y^{-1}(A) \cap (Y^{-1}(A) \cap X^{-1}(A)^c)^c) \cup (X^{-1}(A) \cap Y^{-1}(A)^c)$$ However, I cannot find any explanation of why this is true. Also, what is the set $A$ ? Is it an arbitrary subset of $\mathbb{R}$ ? How come that $X^{-1}(A) \cap Y^{-1}(A)^c$ is a null set? I know that $\{\omega : X(\omega) \neq Y(\omega)\}$ is a null set by the assumption.","['measurable-functions', 'measure-theory', 'probability-theory']"
3711441,"Calculating $\int_A \frac{z}{y^2}$ with $A:=\{z\ge0,x\ge1,y\ge 0, x^2+z^2<\min(2x,y^2)\}$","I want to calculate the following improper integral: $$\int_A \frac{z}{y^2}\\
A:=\{z\ge0,x\ge1,y\ge 0, x^2+z^2<\min(2x,y^2)\}$$ First I noticed that the conditions imply $x^2<2x\rightarrow x<2;1<x^2<y^2\rightarrow y>1$ , and thus $B=A\cap \{y>2\}=\{z\in(0,2),x\in(1,2), x^2+z^2<2x\}$ . Thus this part of the integral is fairly easy: $$\int_B\frac{z}{y^2}=\int_2^\infty\int_1^2\int_0^\sqrt{2x-x^2}\frac{z}{y^2}dzdxdy=\int_2^\infty\frac1{y^2}dy\int_1^2\frac{2x-x^2}{2}dx=\frac{1}{6}$$ We are now left with a ""proper"" integral (i.e. the region on which we are integration is finite, and the integrand is bounded): $$\int_{A\cap\{y\in(1,2)\}}\frac{z}{y^2}$$ I tried to split the domain in two regions: $A'=\{x\in[1,2);y\in(x,\sqrt{2x});z\in [0,\sqrt{y^2-x^2})\}, A''=\{x\in[1,2);y\in[\sqrt{2x},2];z\in[0,\sqrt{2x-x^2})$ Is my approach correct (I'm not sure, since the computations that follow bring me to an uncorrect result)? Is there any other approach to computing this integral, perhaps less messy?","['integration', 'improper-integrals', 'multivariable-calculus', 'solution-verification', 'multiple-integral']"
3711487,Is this a 'legal' way to show two sets not equal?,"Part A. Suppose that for all $x$ , $x$ is in a set $X$ iff it is not in another set $Y$ . Neither $X$ nor $Y$ is the empty set. And there is a background set Z in which these sets lurk and to which everything is relative. So when we say 'not in another set Y' this is a relative complement between Y and Z, not an absolute complement. From these assumptions, can we derive that $X \neq Y?$ Proof. If $X=Y,$ then $x$ is a member of $X$ if it is not a member of $X$ -- a contradiction. QED. From the definition, did we prove that $X$ can't equal $Y$ and put a proper restriction on what those sets can be? Or did we show that $X$ is just not well-defined? Part B. Can this method be 'scaled' to show a set V is not in a certain set R? I reference a set of sets $R$ in my definition of a set $V$ . Any $v$ is a member of $V$ iff it is not a member of any of the sets in the set $R$ . It seems that, similar to how we showed inequality before, by definition, we have forced $V$ not be in the set $R$ ; otherwise, we have a contradiction: $v$ is a member of $V$ if it is not a member of $V$ .
Here is the specific example: For all $v$ , $v$ is in $V$ iff $v$ is not in any of these sets: $(W,S,U,T)$ which form a set called $R$ . From this assumption can we derive that $V$ is not in the set $R$ ? And again, not being in $W, S, U, T$ is relative to a background set $Z$ .","['elementary-set-theory', 'logic']"
3711598,Function whose inverse is also its derivative?,"What are some good examples of a function  $f : \mathbb{R} \to \mathbb{R}$ where its derivative is equal to its inverse? I attempted to find a monomial that satisfied it by starting with $f(x) = ax^b$ and showing that $f^{-1}(x) = f'(x) \implies b-1=\frac{1}{b} \implies b=\phi$ and got
$$f(x) = \frac{x^\phi}{\sqrt[\phi]{\phi}}$$
Which seems to work according to WolframAlpha, but I'm having trouble double-checking it. Any other ideas?","['functional-equations', 'ordinary-differential-equations']"
3711615,Example of application of KomlÃ³s theorem,"Let $(E,\mathcal {A}, \mu ) $ be a finite measure space and $X$ be a Banach space. The set of all Bochner-integrable functions from $E$ into $X$ is denoted by $\mathcal{L}_X^1$ . If $X$ is reflexive , we have the following theorem Theorem 1 Let $ (f_n)_{n\geq 1} \subset \mathcal {L}_{X}^1$ is a sequence  with : $$\sup_n \int_{E}{\|f_n\| d\mu} < \infty .$$ Then there exist $ h _{\infty} \in  \mathcal {L}_{X}^1 $ and a sub-sequence $ (g_k)_k $ of $(f_n)_n $ such that for every sub-sequence $ (h_m)_m $ of $(g_k)_k$ : $$ \frac{1}{i}\sum_{j=1}^{i}{h_j(t)}\to   h _{\infty}(t) \text{ weakly in }X\text{ a.e. }$$ Proof of this result exists in the article "" Infinite-dimensional extension of a theorem of Komlos "" by Erik J. Balder ( Theorem A ). If $X$ is Hilbert , we have the following theorem Theorem 2 Let $ (f_n)_{n\geq 1} \subset \mathcal {L}_{X}^1$ is a sequence  with : $$
\sup_n \int_{E}{\|f_n\| d\mu} < \infty.
$$ Then there exist $ h _{\infty} \in  \mathcal {L}_{X}^1 $ and a sub-sequence $ (g_k)_k $ of $(f_n)_n $ such that for every sub-sequence $ (h_m)_m $ of $(g_k)_k$ : $$ \frac{1}{i}\sum_{j=1}^{i}{h_j(t)}\to   h _{\infty}(t) ~~\text{in }X\text{ a.e. }$$ Proof of this result exists in the article "" An elementary proof of KomlÃ³s-RÃ©vÃ©sz theorem in Hilbert spaces "" by  Mohamed Guessous. ( Theorem 3.1 ). My problem: I want an example of a reflexive Banach space $X$ not Hilbert space and a sequences $\{f_n\}$ in $\mathcal{L}_X^1$ , such that: There exist $ h _{\infty} \in  \mathcal {L}_{X}^1 $ and a sub-sequence $ (g_k)_k $ of $(f_n)_n $ such that for every sub-sequence $ (h_m)_m $ of $(g_k)_k$ : $$ \frac{1}{i}\sum_{j=1}^{i}{h_j(t)}\rightarrow   h _{\infty}(t) \text{ weakly in }X\text{ a.e. }$$ But: $$ \frac{1}{i}\sum_{j=1}^{i}{h_j(t)}\nrightarrow   h _{\infty}(t) \text{  in }X\text{ a.e. }$$","['hilbert-spaces', 'banach-spaces', 'measure-theory', 'probability']"
3711643,Why is it the (group) morphisms that matter?,"I often hear people saying things like: one only really understands groups if one looks at group homomorphisms between them one only really understands rings if one looks at ring homomorphisms between them ... Of course, these statements are just special cases the category theoretic slogan that what really counts is the morphisms not the objects. I can appreciate that it's quite cool that one can characterize constructions such as the free group or the direct product of groups just in terms of their relation to other groups (and in this sense, the morphisms from and to that construction help to understand the construction better). But besides, I'm struggling to appreciate the usefulness of homomorphisms. I understand that what one is interested in is groups up to isomorphism (one wants to classify groups ), so the notion of isomorphism seems to me to be very fundamental, but the notion of a homomorphism seems to me in some sense just to be a precursor the fundamental notion of an isomorphism. I guess it would help if some of you could point me to bits and pieces of group theory where homomorphisms (instead of isomorphisms) are essential. In which sense do group homomorphisms help us to understand groups itself better? Of course, I could ask the same question about ring theory or some other subfield of mathematics. If you have answers why morphisms matter in these fields, then feel free to tell me! After all, what I'm interested in is examples of the usefulness of homomorphisms from down to earth concrete mathematics, so what I don't want is just category theoretic philosophy jabbering (this is not to say I don't like category theory, but for the purpose of this question I'm interested in why morphisms matter in specific subfields of mathematics such as group theory).","['group-homomorphism', 'group-theory', 'soft-question', 'category-theory']"
3711644,Use CLT to find approximation,"We are given $X_1,\dots,X_n$ i.i.d. Poisson( $\lambda$ ) r.v.s. and assume $\lambda = 1$ . We need to use CLT to find an approximation for: $$P(X_1+X_2+\dots+X_{100} \leq 90)$$ What I have done: Let $Y = X_1+X_2 +\dots+ X_{100} $ Therefore $Y\sim$ Poisson(100) (assuming $\lambda=1$ ) Also, if $\lambda$ is sufficiently large, $Y \sim N(100, 100)$ Therefore: $ P(X_1+X_2+\dots+X_{100} \leq 90) = P\left(Z \leq \frac{90-100}{10}\right) = P(Z \leq -1) = P(Z \geq 1) = \Phi(1)$ I need to know if this is okay?","['statistics', 'central-limit-theorem', 'probability']"
3711648,Why is the recurrence $f_n=\frac{5f_{n-1} + 1}{25 f_{n-2}}$ cyclic?,Given: $f_1 = a$ $f_2 = b$ and $f_n =  \dfrac{5f_{n-1} + 1}{25 \cdot f_{n-2}}$ You can just start doing the algebra to show $f_3 = \dfrac{5b + 1}{25a}$ $f_4 = \dfrac{5a + 5b + 1}{125ab}$ $f_5 = \dfrac{5a + 1}{25b}$ $f_6 = a$ $f_7 = b$ ..... But why is this happening i.e. what in the definition of the recurrence makes this cyclic and determines the cycle length?,"['algebra-precalculus', 'recurrence-relations']"
3711678,How far have we got towards proving Catalan's constant is irrational?,"While it is not know if Catalan's constant is irrational,what progress has been made on this problem?For example is there a reformulation of the problem ? (this maybe a criteria, using continued fractions, that can be used to prove if Catalan's constant is irrational-or a different reformulation not using continued fractions).","['irrational-numbers', 'catalans-constant', 'analysis']"
3711714,Spivak Calculus Limit Intuition Clarification,"This is from page 94 of Spivak's ""Calculus"" 4th edition. He builds up the definition of a limit from examples, but I am confused about this paragraph: Let $f(x) = \frac{1}{x}$ (for $x \neq 0$ ) To show in general that $f$ approaches $1/a$ near $a$ for any $a$ we proceed in basically the same way, except that, again, we have to be a little more careful in formulating our initial stipulation. It's not good enough simply to require that $|x-a|$ should be less than 1, or any other particular number, because if $a$ is close to 0 this would allow values of $x$ that are negative (not to mention the embarrassing possibility that $x=0$ , so that $f(x)$ isn't even defined!). Why would negative values of $x$ be bad in this example? Couldn't the value of $a$ be negative, since $f(x)$ is defined for $x < 0$ ?","['limits', 'calculus']"
3711733,Differential of Derivative,"I have encountered with a problem, and I can't follow the intermediate steps. Consider the following differential equation: $$ y^{\prime \prime} = -2y + f(y)-0.5y^3 $$ Here, the first derivative is expressed as the following integral: $$ (y^{\prime})^2 = 2\int_0^{y^\prime} y^\prime dy^\prime  $$ Without giving the details of the intermediate steps, this equation is converted into the following equation using the differential equation given above: $$ (y^{\prime})^2 = -2 \int_{Y}^{y} \left( 2y - f(y)+0.5y^3 \right) dy$$ where $Y$ is the maximum value of $y$ when $y^\prime$ is zero. Here, I would like to learn how to express differential of a derivative $ dy^\prime $ in terms of $dy$ , and end up with the above equation. If I am not wrong, the following equality must hold: $$ y^\prime dy^\prime = y^{\prime \prime} dy $$ How can I prove this equality? I am confused to think a differential like $ dy^\prime = d(\frac{dy}{dx}) $ . Any help would be appreciated. Thanks.","['differential', 'ordinary-differential-equations']"
3711800,Uniform almost sure convergence of the partial sum process,"Suppose $X_i$ , $i=1,2,...$ , are iid random variables with $EX_i=0$ and $EX_i^2 < \infty$ . For each $x \in (0,1)$ , $\frac{1}{\lfloor n x \rfloor} \sum_{i=1}^{\lfloor n x \rfloor} X_i  \stackrel{a.s.}{\to} 0$ by the standard strong law of large numbers. Clearly though $\sup_{x \in (1/n,1)} \left| \frac{1}{\lfloor n x \rfloor} \sum_{i=1}^{\lfloor n x \rfloor} X_i \right|  \stackrel{a.s.}{\nrightarrow} 0$ . My question is: on what domain can the partial average argument be restricted to so that the maximally selected partial average does converge almost surely to zero? Namely, does there exist a sequence $a_n \to 0$ so that $\sup_{x \in (a_n,1)} \left| \frac{1}{\lfloor n x \rfloor} \sum_{i=1}^{\lfloor n x \rfloor} X_i \right|  \stackrel{a.s.}{\to} 0$ ? What is the smallest $a_n$ one can take so that this holds? How does the choice of $a_n$ depend on the distribution of the $X_i's$ ? A minimal requirement when $a_n \to 0$ would seem to be $na_n \to \infty$ . My only thought was to apply the law of the iterated logarithm, which would seem to imply $a_n\sqrt{n}/\sqrt{\log \log (n)} \to \infty$ is required. Is this required or optimal?","['empirical-processes', 'stochastic-processes', 'probability-theory', 'real-analysis']"
3711801,"Finding norm of $Tf(t)=\int_0^1k(s,t)f(s)ds$ if $k$ is continuous functional defined on a unit square and $T:C[0,1]\to C[0,1]$","Since $k$ is continuous and defined on $[0,1]\times[0,1]=J$ compact domain so it is bounded. Therefore there exists $c\in \mathbb R$ such that $|k(s,t)|\le c,\quad \forall (s,t)\in [0,1]\times[0,1]=J$ So $$||Tx||=\sup_{t\in [0,1]}\left|\displaystyle\int_0^1 k(s,t)x(s)ds\right|$$ $$\le \sup_{t\in [0,1]}\displaystyle\int_0^1 \left|k(s,t)\right|\left|x(s)\right|ds$$ $$\le c||x||$$ My gut says that we need to specify this constant $c$ in a way and then for a special $x$ (which depends on the k(s,t)) and then we need to say that $\displaystyle\int_0^1 k(s,t)x_k(s)ds=c_k$ So that we finally find that $||T||=c_k$ for this $T$ defined as above. But how to do that? If $k$ is given as in Norm of $T:(C[0,1],||.||_{\infty})\to \mathbb R,$ $T(f)=\int_0^1tf(t)$ I can do it like in the answers but how to do that for an arbitrary $k(s,t)$ function in $[0,1]\times[0,1]$",['functional-analysis']
3711808,Locally constant sheaf on irreducible space is constant,"Let $X$ be an irreducible space, and let $\{U_{i}\}_{i\in I}$ be an open covering of $X$ . Let $\mathcal{F}$ be a sheaf on $X$ such that the restriction of $\mathcal{F}$ to each open $U_{i}$ is constant. I want to show that $\mathcal{F}$ has to be constant. Note that the constant sheaf is the sheafification of the constant presheaf with value $A$ which assigns to every open the value $A$ . Notice that since $X$ is irreducible every pair $U_{i}$ and $U_{j}$ from the open covering have non-empty intersection. Define for $i\in I$ the sheaf $\mathcal{F}_{i}:=\mathcal{F}|_{U_{i}}$ , I tried to show that we have isomorphisms $\mathcal{F}_{i}|_{U_{i}\cap U_{j}}$ to $\mathcal{F}_{j}|_{U_{i}\cap U_{j}}$ which satisfies the desired properties such that we can glue them uniquely to the constant sheaf. But I failed doing this. Any help would be appreciated! I think my main struggles is how to deal with the sheafification here. Do I have a explicit description of the sets $\mathcal{F}_{i}(V)$ for $V\subset U_{i}$ ?","['algebraic-geometry', 'category-theory', 'sheaf-theory']"
3711852,Differential of $\log$ mapping on manifolds and Lie groups,"Suppose $M$ is a finite dimensional $C^\infty$ -manifold and $\nabla$ is an affine connection on $M$ , we know that exponential mapping and logarithm mapping are well-defined locally. Fix a point $p_0\in M$ , $\log_{p_0}(\cdot):M\to T_{p_0} M$ is well-defined on a neighborhood of $p_0$ . Now my questions are: Is $\log_{p_0}(\cdot)$ differentiable or differentiable almost everywhere? If it is, is there a closed form? Intuitively, I guess that it's the parallel transport from $T_p M$ to $T_{p_0}M$ , where $p$ represents the argument. Is this correct in general? Does it hold in any special cases? So far, I mainly focus on two cases, but I welcome any more general results. $M$ is a Riemannian manifold and $\nabla$ is the Levi-Civita connection. $M$ is a Lie group and $\nabla$ represents the canonical left-invariant connection, so the exponential mapping is the usual one on Lie group. Please enlighten me with any related results, examples or references. Thank you!","['riemannian-geometry', 'lie-groups', 'differential-geometry']"
3711910,"Will orientation-preserving diffeomorphisms of the plane preserve ""positively oriented"" domains?","Background: Let $T:\mathbb{R}^2\rightarrow \mathbb{R}^2$ be an orientation-preserving diffeomorphism, i.e. $\det(T')$ is everywhere positive in $\mathbb{R}^2$ . Let $\gamma:[a,b]\rightarrow \mathbb{R}^2$ be a simple closed smooth regular plane curve such that it is positively oriented : the bounded component of $\mathbb{R}^2\backslash\gamma([a,b])$ , call it D, lies on the left-hand side of $\gamma.$ More rigorously, $\forall t\in[a,b], \exists \epsilon=\epsilon(t)>0$ such that $\gamma(t)+i\cdot\epsilon(t) \dot\gamma(t)\in D$ . Similarly we can define orientation-reversing diffeomorphisms and negatively oriented domains. Question: $T^{-1}\circ\gamma$ be positively oriented with respect to $T^{-1}(D)$ ? Moreover, if $T$ is orientation-reversing ( $\det(T')<0$ everywhere), will $T^{-1}\circ\gamma$ be negatively oriented with respect to $T^{-1}(D)$ ? Motivation: This fact is used in a proof of change of variable formula (for double integrals) via Green's theorem which requires the domain of integration to be positively oriented. For details see Exercise 15 of Section 7, Chapter 1 of Manfredo do Carmo's differential geometry book . Edit: $i\cdot\epsilon(t)\dot{\gamma}(t)$ means $\begin{pmatrix}0&-1\\ 1& 0\end{pmatrix}\epsilon(t)\dot{\gamma}(t)$","['general-topology', 'vector-analysis']"
3711921,Equinumerosity: Proof Validation,"Synopsis In my studying of Set Theory, I've had the privilege of being able to compare much of my work to a solutions manual. This solutions manual, however, ended after the chapter on the various number systems. As such, I'm going to start posting a lot of my own personal solutions or questions onto the site for either proof validation or proof hints (if I'm unable to find the solution in other places), and I would greatly appreciate any feedback on my mathematical writing. Thank you. Exercise Show that the equation $$f(m, n) = 2^m(2n + 1) - 1$$ defines a one-to-one correspondence between $\omega \times \omega$ and $\omega$ . Proof First, we show that $f$ is injective. Consider $(m, n)$ and $(m', n')$ in $\omega \times \omega$ . Now suppose that $f(m, n) = f(m', n')$ . Then $2^{m}(2n+1) - 1 = 2^{m'}(2n' + 1) - 1$ and $2^{m}(2n+1) = 2^{m'}(2n' + 1)$ . Note that every value of this equation will only have one odd factor, mainly $(2n + 1)$ . As such, $n = n'$ and $2^m = 2^{m'}$ . So, $m = m'$ and $f$ is injective. Next, we wish to show that $f$ is surjective. Consider any $x \in \omega$ . If $x$ is even, take $m = 0$ and $n = x/2$ . If $x$ is odd, note that $x = 2k + 1$ for some $k \in \omega$ . So $2k = 2^m(2n + 1)$ if $m$ and $n$ exist, and since every even number contains a factor that is odd (for powers of two, we consider the factor one), there is always a $m$ and $n$ that satisfies the equality. Therefore, for any $x \in \omega$ , there is always a $m$ and $n$ such that $f(m, n) = 2^m(2n + 1) - 1$ and $f$ is surjective. As such, because $f$ is both surjective and injective, $f$ is bijective, and the equation $f(m, n) = 2^m(2n + 1) - 1$ defines a one-to-one correspondence between $\omega \times \omega$ and $\omega$ .","['elementary-set-theory', 'solution-verification']"
3711941,"Why did Spivak choose this definitions? (""Calculus on Manifolds"", the definition of the norm, the definition of open sets)","I am reading ""Calculus on Manifolds"" by Michael Spivak. In this book, the norm of $x \in \mathbb{R}^n$ is defined by $|x| := \sqrt{(x^1)^2 + \cdots + (x^n)^2}$ . In this book, a set $U \subset \mathbb{R}^n$ is called open if for each $x \in U$ there is an open rectangle $A$ such that $x \in A \subset U$ . Why did Spivak choose this definitions? What are the advantages of these definitions? I wonder if we define the norm of $x \in \mathbb{R}^n$ as $|x| := \sqrt{(x^1)^2 + \cdots + (x^n)^2}$ , then it is natural we define a set $U \subset \mathbb{R}^n$ is open if  for each $x \in U$ there is an open ball $B$ such that $x \in B \subset U$ . And I wonder if we define the norm of $x \in \mathbb{R}^n$ as $|x| := \max \{|x^1|, \cdots, |x^n|\}$ , then it is natural we define a set $U \subset \mathbb{R}^n$ is open if  for each $x \in U$ there is an open rectangle $A$ such that $x \in A \subset U$ .","['multivariable-calculus', 'general-topology', 'definition', 'normed-spaces']"
3711989,Function from $\mathbb{Z^+}$ to $\mathbb{Z^+}$ that is neither one-to-one nor onto?,"I am thinking of something like $f(x) = 8$ Does this make sense? It seems a bit simple to me so I'm not sure. My reasoning is that  this function is not one-to-one because f takes same value for all domain.
It's also not onto because range isn't equal to codomain since here the range is just the number 8. Thanks!","['functions', 'solution-verification']"
3712017,Countability of a sequence of natural numbers [duplicate],"This question already has answers here : Is the set of all functions $f:Z_+\rightarrow Z_+$ that are eventually constant countable. (2 answers) Closed 4 years ago . I am trying to determine if that the set, $T$ , of all eventually constant sequences of natural numbers is countable. My intuition: The set $T$ is countable. . Let $T_j$ denote the set of sequences of natural numbers so that $t_i=t_j$ for all $i>j$ .
If we can show that $\mathbb{N}^k$ for all $k\in\mathbb{Z}^+$ is countable, then the union $$T=\bigcup_{j\in\mathbb{N}}T_j$$ is countable as a countable union of countable sets is also countable. Is my intuition correct?","['elementary-set-theory', 'proof-writing', 'real-analysis']"
3712025,"Is there a smooth, preferably analytic function that grows faster than any function in the sequence $e^x, e^{e^x}, e^{e^{e^x}}...$","Is there a smooth, preferably analytic function that grows faster than any function in the sequence $e^x, e^{e^x}, e^{e^{e^x}}$ ? Note: Here the answer is NOT required to be an elementary function, as I already know that otherwise the answer would be no. Edit: Michael has mentioned interpolating a series of functions, but exactly how do I do that in a smooth manner?","['interpolation', 'smooth-functions', 'elementary-functions', 'functions', 'recreational-mathematics']"
3712057,Coronavirus test probability given two tests,"So I'm curious about something relevant to me in real life, but it's been forever since I took prop/stats so I don't remember how to calculate it. The accuracy of a COVID test is 70%. Like, if you have the virus, there is a 70% chance the test will come back positive, but a 30% chance you'll get a false negative. If you don't have the virus, there is a 100% chance it will come back negative (I don't think this is strictly true, but false positives with these tests are unlikely, so I'm ignoring them, and I'm fairly certain it's not relevant to this question). I'm almost certain if I had the virus, I would have transmitted it to my girlfriend. Let's assume for the sake of this problem that that's true. If I had the virus, she had it as well. We each took a test, and they each came back negative. What is the probability my negative result is accurate given this information, instead of if I was the only one who had taken the test?","['statistics', 'probability']"
3712081,There are $20$ females and $15$ males in a party. In how many ways can $15$ couples be created?,There are $20$ females and $15$ males in a party. In how many ways can $15$ couples be created? I think it is $P^{20}_{15}$ but I feel I'm wrong.,"['combinatorics', 'discrete-mathematics']"
3712115,"If $a$, $b$, $c \geq 1$; $y \geq x \geq 1$; $p$, $q$, $r > 0$ Prove the insane inequality",$$\left(\frac{1+y\left(a^pb^qc^r\right)^{\frac{1}{p+q+r}}}{1+x\left(a^pb^qc^r\right)^{\frac{1}{p+q+r}}}\right)^{\frac{p+q+r}{\left(a^pb^qc^r\right)^{\frac{1}{p+q+r}}}}\left(\frac{1+xa}{1+ya}\right)^{\frac{p}{a}}\left(\frac{1+xb}{1+yb}\right)^{\frac{q}{b}}\left(\frac{1+xc}{1+yc}\right)^{\frac{r}{c}}\geq \prod \limits_{cyc}\left(\frac{1+y\left(a^pb^q\right)^{\frac{1}{p+q}}}{1+x\left(a^pb^q\right)^{\frac{1}{p+q}}}\right)^{\frac{p+q}{\left(a^pb^q\right)^{\frac{1}{p+q}}}}$$ This is a inequality problem from 2019 Jozsef Wildt International Mathematics Competition . For this problem i almost tried in all ways with AM-GM and Cauchy-Schwarz but i am unable to do it. Honestly i don't even know how to start thinking for this problem. Please help. I know i have not uploaded my attempts. But what i shall attempt. I am completely blank about this problem,"['jensen-inequality', 'analysis', 'multivariable-calculus', 'inequality', 'exponential-function']"
3712173,Evaluate the derivative of a function at $x=1$ and find a given limit at $\infty$,"QUESTION: Suppose $f : \mathbb{R} \to \mathbb{R}$ is a function given by $$f(x)=e^{(x^{10}âˆ’1)}+(xâˆ’ 1)^2 \sin(\frac{1}{x-1})$$ $(a)$ Find $f'(1)$ . $(b)$ Evaluate $$\lim_{u\to\infty} [100u-u\sum_{k=1}^{100}f(1+\frac{k}u)]$$ MY ANSWER: For the first part I have tried it in two ways, and the second in one.. let me explain what I have done- Method 1/1 $f(x)=e^{(x^{10}-1)}+(x-1)^2\sin(\frac{1}{x-1})$ Therefore, $$f'(x)=10x^9e^{(x^{10}-1)}+(x-1)^2\cos\bigg(\frac{1}{x-1}\bigg)\frac{(-1)}{(x-1)^2}+\sin\bigg(\frac{1}{x-1}\bigg)2(x-1)$$ Now when $xâ†’1$ , since $\sin\theta$ is an oscillating number between $[-1,1]$ therefore $\sin\big(\frac{1}{x-1}\big)2(x-1)$ becomes $0$ . Hence, $$f'(1)=10-\cos(\infty)$$ This is a finite value oscillating between $[9,11]$ but how do I find that? So here I am stuck.. Method 1/2 From the fundamental theorem of calculus $$f'(x)=\frac{f(x)-f(a)}{x-a}$$ Here $a=1$ and substituting $x$ to $1+h$ where $hâ†’0$ we get- $$\lim_{hâ†’0}\frac{f(1+h)-f(1)}{1+h-1}$$ $$\lim_{hâ†’0}\frac{e^{[(1+h)^{10}-1]}+(1+h-1)^2\sin\bigg(\frac{1}{1+h-1}\bigg)}{h}$$ Now the second part becomes $\frac{h^2\sin(\frac{1}h)}{h}$ which is $\frac{\sin(\frac{1}h)}{\frac{1}h}$ when $hâ†’0$ . Therefore that is clearly $0$ . Coming to the first part we get- $$\frac{e^{\big((1+h)^{10}-1\big)}}{h}$$ Expanding $(1+h)^{10}$ using binomial expansion, we obtain $$(1+h)^{10}= \binom{10}{0}+\binom{10}{1}h+\binom{10}{2}h^2+....$$ From here I cannot take it. The $\binom{10}{0}$ gets cancelled by $1$ , but what will I do with the rest? I did a little further although illegally $:$ P, that since $hâ†’0$ therefore I completely ignored the terms containing $h^2$ or higher powers of $h$ . So we are left with $e^{10h}$ . Expanding this using Taylor expansion (Maclaurin to be precise) we get $$e^{10h}= 1 + 10h+ \frac{(10h)^2}{2!} + \frac{(10h)^3}{3!} +......$$ Since we have an $h$ in the denominator, only $10h$ becomes $10$ and remaining all $0$ except $1$ which becomes $\frac{1}h$ . As you can see, $\frac{1}h$ creates problem here. we remember that we did illegal assumptions, so mathematics always arrests anyway $:$ P Any help in this part? Coming to the second part of the question- Method 2/1 $$\lim_{uâ†’\infty}[100u-u\sum_{k=1}^{100}f\bigg(1+\frac{k}u\bigg)]$$ Let's break this and see it in parts.. second part $$\bigg(1+\frac{k}u-1\bigg)^2\sin\bigg(\frac{1}{1+\frac{k}u-1}\bigg)$$ $$\implies \bigg(\frac{k}u\bigg)^2\sin\bigg(\frac{u}k\bigg)$$ Now when $uâ†’\infty$ this becomes $0$ due to clear reasons stated previously.. So every term of this summation becomes $0$ . first part $$e^{\big((1+\frac{k}u)^{10}-1\big)}$$ When $uâ†’\infty$ this becomes $e^{(1-1)}$ or $e^0$ therefore $1$ . Therefore the summation upto $100$ terms becomes nothing but $100$ . Therefore, our limit becomes $$\lim_{uâ†’\infty}[100u-100u]$$ $$=0$$ Am I correct? If not where is the mistake that I have committed? Any help will be much appreciated. Thank you so muchðŸ˜Š.","['limits', 'calculus', 'functions', 'derivatives']"
3712179,Limit $\lim_{n\to \infty} \frac{1}{n^{n+1}}\sum_{k=1}^n k^p$,"The evaluation of $$\lim_{n\to \infty} \frac{1}{n^{n+1}}\sum_{k=1}^n k^p$$ as an integral ( evaluating this as a right Riemann sum ) requires the form $f(a + k\cdot \Delta x_i)$ , where $a$ is our lower bound of integration, and $\Delta x_i$ is the length of our subinterval, on some partition of the interval of integration. However, the given expression does not seem to give way to any meaningful expression for this. I think it's safe to assume our lower bound is $0$ though. The bigger problem is the interpretation of $\frac{1}{n^{n+1}}$ . I tried $$\frac{1}{n^{n+1}}=\frac{1}{e^{\ln(n^{n+1})}}=\frac{1}{e^{(n+1)\cdot \ln(n)}}$$ and since the inverse of $e^{x}$ is $\ln(x)$ , we'd have $$\ln((n+1) \cdot \ln(n)=\ln(n+1)+\ln(\ln(n))$$ which doesn't seem very useful either. I'd appreciate any advice.","['limits', 'riemann-sum', 'real-analysis']"
3712262,Smooth Sylvester's law of inertia,"Let $Q(x)$ be a smooth symetric matrix with constant signature $(p,q,k)$ where $x$ belong in $\mathbb{R}^n$ and $p+q+k=m$ . Question: Locally around $x_0$ , does an invertible matrix $P(x)$ of size $m$ exists such that, $$
P^T(x) Q(x) P(x) = \begin{pmatrix} Id_p &0&0\\0&-Id_q&0\\ 0&0&0_k\end{pmatrix}
$$ /!\ I do not require that $P(x)$ is the jacobian of some diffeormorphism. Proposition of Proof: If $Q(x_0)$ is invertible and all its eignevalue are simple, then this property is locally preserved. Hence the basis of orthonormal vectors depend smoothly on the point. If $Q(x_0)$ has a multiple eigenvalue, then locally the eigen hypersurface can split into multiple eigen hypersurfacesof smaller dimension. However because the bilinear form asociated with $Q$ is symmetric the vectors spanning the multiple smaller hypersurfaces will converge to a basis of the eigenhypersurface. Hence the transformation is still smooth. If $det(Q(x_0))=0$ , then locally we have $\mathbb{R}^n=\ker Q \oplus^{\perp}rg(Q)$ . The kernel of $Q$ is determined by a set of equations, by the implicit functions theorem we can express the vector spanning this kernel by smooth functions. As the image of $Q$ is orthogonal to the kernel, then it is also spanned by smooth functions and we can express $Q$ in this subspace and repeat the previous argument.","['smooth-functions', 'real-analysis', 'bilinear-form', 'matrix-calculus', 'differential-geometry']"
3712272,Why do both $\iint_R(x^2+y^2)\ dA$ and $\iiint_E 1\ dxdydz$ give the volume of $z=x^2+y^2$? What is the difference between $R$ and $E$?,"I can't understand how do we calculate volume  with triple integral. for example $z =x^2+y^2$ , we can calculate its volume with both: $$\iint\limits_R (x^2+y^2)\ dA$$ and $$\iiint\limits_E 1\ dxdydz$$ what is difference between $E$ and $R$ here?","['multivariable-calculus', 'calculus', 'definite-integrals', 'volume']"
3712287,Mean value theorem for Improper Integrals,"If $f$ is continuous on $[a,\infty)$ and $\phi(x)\geq0$ and be integrable in $[a,\infty) $ then there exists some $c\in(a,\infty)$ such that $$\int_{a}^{\infty} f(x)\phi(x) dx = f(c)\int_{a}^{\infty}\phi(x) dx$$ I tried $\int_{a}^{\infty} f(x)\phi(x) dx = \lim_{n\to\infty}   \int_{a}^{n} f(x)\phi(x)dx$ . Can we apply mean value theorem for proper integrals to the latter integral and then take limit?","['improper-integrals', 'calculus', 'definite-integrals', 'real-analysis']"
3712358,Prove that $\lim_{n \to \infty} a^{\frac{1}{n}} = 1$ when $a > 0$,"The question is in the title. I will present the argument that I have for this. Proof Attempt: Let $a = 1$ . Then, $a^{\frac{1}{n}} = 1$ for all $n \in \mathbb{N}$ so the limit is clearly equal to 1. Let $a > 1$ . Define $x_n = a^{\frac{1}{n}} - 1$ . Then, we have: $$a = (1+x_n)^n$$ I claim that $x_n > 0$ for all $n \in \mathbb{N}$ . To show that this is true, suppose that $x_n \leq 0$ . Then, $a^{\frac{1}{n}} < 1$ and that implies that $a \leq 1$ . This is false under the given hypothesis that $a > 1$ . Now, we use Bernoulli's inequality and deduce that: $$a = (1+x_n)^n \geq 1+nx_n \geq 1$$ $$\frac{a-1}{n} \geq x_n \geq 0$$ By the Squeeze Theorem, it follows that $x_n \to 0$ as $n \to \infty$ . That is, $a^{\frac{1}{n}} \to 1$ as $n \to \infty$ . Suppose that $0 < a < 1$ . Then: $$b = \frac{1}{a} > 1$$ Clearly, the sequence defined by $x_n = b^{\frac{1}{n}}$ converges to 1. So: $$\lim_{n \to \infty} b^{\frac{1}{n}} = 1$$ $$\lim_{n \to \infty} \frac{1}{b^{\frac{1}{n}}} = \frac{1}{\lim_{n \to \infty} b^{\frac{1}{n}}} = \lim_{n \to \infty} a^{\frac{1}{n}} = 1$$ That proves the desired result. Is the proof above correct? If it isn't, why? How can I fix it? Edit: Since one individual has voted for this question to be closed, I want to explain why it's not a duplicate and the suggestion that it should be closed makes no sense. This question requires a solution to be verified. Namely, my solution to the given problem is what needs to be verified. It needs to be criticized and holes need to be pointed out so that I may fix the proof. That's actually explicitly what I've asked in the last line of the original question. Since I'm self-studying mathematics, it stands to reason that I may believe I have a proof but, in reality, do not have one. If someone can point out the mistake in my argument and if I can fix it without having to refer to another person's proof, then that would be more fruitful. Let $a > 1$ and $x > 0$. Prove that $a^x > 1$ Please refer to the above link for another question I asked, where I believed that I had a proof of the result and several individuals chipped in to help me fix it. The mistake with respect to my proof was explicitly pointed out to me and that ended up being very useful. The question that was linked, while containing useful and insightful information that I would be interested in AFTER I proved the result, does not answer the question as I had asked it.","['calculus', 'solution-verification']"
3712369,Finding a nonexact closed $1$-form on a surface embedded in $\Bbb R^3$,"Consider the subset $S=\{(x,y,z):x^2-y^2-z^2+1=0\}$ of $\Bbb R^3$ . Defining a function $f:\Bbb R^3\to \Bbb R$ by $f(x,y,z)=x^2-y^2-z^2+1$ , it is easily seen that $0$ is a regular value of $f$ , so it follows that $S=f^{-1}(0)$ is an embedded submanifold of $\Bbb R^3$ of codimension $1$ . I am trying to find a closed $1$ -form on $S$ which is not exact. It is easy to find a closed $2$ -form on $S$ which is not exact: Since $S$ is an embedded submanifold of codimension $1$ of the orientable manifold $\Bbb R^3$ , it follows that $S$ is also orientable, so we can take an orientation form of $S$ . But how can I find a non-exact closed $1$ -form on $S$ ? Using wolframalpha.com, I saw how $S$ looks like; it clearly seems that $S$ is homotopy equivalent to the circle $S^1$ , so $H^1(S)\neq 0$ . Thus $S$ must indeed have a non-exact closed $1$ -form but I have no idea to find it. Any hints?","['differential-forms', 'smooth-functions', 'smooth-manifolds', 'differential-geometry']"
3712386,"Calculating value of function at middle of interval, given integrals of the function on the interval.","I was asked the following question : $$I = \int_0^1 xf(x) \,dx =\frac{1}{6}$$ $$J = \int_0^1 (f(x))^2\,dx =\frac{1}{12}$$ $$f\left(\frac{1}{2}\right) = \ ? $$ Here, $f(x)$ is a continuous function My try: I couldn't find a good starting point to solve the function. Firstly I tried to draw some graphs of a random function $xf(x)$ and $2(f(x))^2$ so that the area under the two curves is the same, but it didn't reach any conclusive point. Next, I tried using : $$\int_0^{2a} f(x)\,dx = \int_0^a f(x) + f(a-x)\,dx$$ to get $\frac{1}{2}$ as one of the limits, but that just complicated things more, as I cannot comment much about $f(1-x)$ . Any help would be appreciated. Thanks. EDIT: It is given that the function is continuous.","['integration', 'calculus', 'definite-integrals']"
3712483,The best way to put balls into boxes,"There are $36$ identical balls, $12$ boxes numbered $1$ to $12$ , and two $6$ -sided dice. You start by placing each of the balls into one of the boxes. You then repeatedly roll the dice and take a ball from the box numbered with their sum. If there isn't any ball in that box, you just skip the round. What is the best strategy to assign the balls to minimize the expected number of rounds needed to take all balls out? I know how to use min-max Inclusionâ€“exclusion principle to solve the problem which the balls are already assigned. But is there an effecient way to find out the best strategy? And if there is a way to answer the question when the possibility to take a ball from the i-th box is $p_i$ . Thank you for your time.","['expected-value', 'combinatorics', 'probability']"
3712485,$x^2 + 2y^2=3^k$,"Let $x,y \in \mathbb Z$ such that both $x$ and $y$ are not factor of $3$ . Prove that $\forall k \in \mathbb N$ there exists $(x , y)$ that $x^2 + 2y^2 = 3^k$ . I know that $x^2 + 2y^2$ is divisible by $3$ always. But how can we prove that there exists a solution $\forall k \in \mathbb N$ ? Thank you!","['contest-math', 'number-theory', 'elementary-number-theory', 'diophantine-equations']"
3712514,Smallest $\sigma$-algebras generated by finite Cartesian products of sets from the coordinate $\sigma$-algebras. Which is the meaning?,"Suppose we want to construct an infinite sequence of independent random variables of given distributions. Specifically, for each $n$ let $X_n$ be defined on $\left(\Omega_n\text{, }\mathcal{A}_n\text{, }\mathbb{P}_n \right)$ and let us set $$
\Omega=\prod\limits_{n=1}^{\infty}\Omega_n\hspace{0.8cm}(\text{Countable Cartesian product})
$$ and $$
\mathcal{A}=\displaystyle\otimes_{n=1}^{\infty}\mathcal{A_n}
$$ where $\displaystyle\otimes_{n=1}^{\infty}\mathcal{A_n}$ denotes the smallest $\sigma$ -algebra on $\Omega$ generated by all sets of the form $$A_1\times A_2\times \ldots\times A_k\times \Omega_{k+1}\times\Omega_{k+2}\times\ldots\text{,}\hspace{0.4cm}A_i\in\mathcal{A}_i\text{;}\hspace{0.4cm}k=1,2,3,\ldots$$ That is, $\mathcal{A}$ is the smallest $\sigma$ -algebra generated by finite Cartesian product of sets from the coordinate $\sigma$ -algebras $\bf{Questions:}$ why is $\displaystyle\otimes_{n=1}^{\infty}\mathcal{A_n}$ generated by finite product of sets $A_i$ with $i$ ranging from $1$ to $k$ times product of $\Omega_i$ with $i$ ranging instead from $k+1$ to $\infty$ ? In other terms, what do they mean when stating that $\mathcal{A}$ is the smallest $\sigma$ -algebra generated by finite Cartesian products of sets from coordinate $\sigma$ -algebras? What are coordinate $\sigma$ -algebras?","['tensor-products', 'independence', 'probability-theory', 'random-variables']"
3712551,Proof of differential operator identity in DLMF $16.3.5$,"DLMF $16.3.5$ gives the differential operator identity $$
(z\partial_z z)^nf(z)=z^n\partial_z^nz^nf(z),\quad n=1,2,\dots
$$ where $\partial_z$ is differentiation w.r.t. $z$ . I am having some issues proving this identity.  It seems like this is a candidate for induction.  Clearly, the identity holds for $n=1$ so assuming for $n$ we have $$
(z\partial_z z)^{n+1}=z\partial_z z^{n+1}\partial_z^nz^n.
$$ At this point all I had to go on was trying to somehow use the product rule.  I wrote $$
(z\partial_z z)^{n+1}=z\partial_z (z^{n+1}\partial_z^nz^n)=z((n+1)z^n\partial_z^nz^n+z^{n+1}\partial_z^{n+1}z^n),
$$ which seems to lead to a dead end. How do I prove this identity? Perhaps a different proof technique altogether?","['differential-operators', 'calculus', 'derivatives']"
3712559,Continuous map of differentiable manifolds is differentiable if differentiable functions pull back to differentiable functions,"This is Exercise 3.1.A. in Vakil's notes Suppose that $\pi: X\rightarrow Y$ is a continuous map of differentiable manifolds. Show that $\pi$ is differentiable if differentialble functions pull back to differentiable functions, i.e., if pullback by $\pi$ gives mpa $\mathcal{O}_Y\rightarrow \pi_*\mathcal{O}_X$. Let $f: V\subseteq Y\rightarrow \mathbb{R}$ be a differentiable function on an open subset of $Y$. Let $(U,\phi)$ be a chart of $X$, $(V,\psi)$ be a chart of $Y$. Then $f\circ\pi(\phi^{-1})$ is differentiable and $f\circ\psi^{-1}$ is differentiable. We need to show that $\psi\circ\pi\circ\phi^{-1}$ is differentiable. I don't know how to prove this. Can we say that since $(U,\psi\circ\pi)$ constructs a chart of $X$, by the compatibility, $\psi\circ\pi\circ\phi^{-1}$ is differentiable? This seems true but this does not use the fact that $f$ is differentiable. Sorry I have no background of Differentiable Manifolds. Any help would be appreciated. I also saw this post: pullback of continuous maps of manifolds , but I don't understand how $\gamma$ is smooth in the answer. $\gamma=\beta\circ\rho$, where $\rho$ is defined to be smooth, but $\beta$ is not.","['manifolds', 'algebraic-geometry', 'smooth-manifolds', 'differential-geometry']"
3712587,"Expectation of a binomial random variable raised to a non-integer power? (""non-integer moment"" of a probability distribution)","Does anyone know if there's a closed-form expression of the expectation of the maximum likelihood estimator of a binomial variable raised to a non-integer power? Concretely, setting $$
P(m\mid N,p) = \binom{N}{m} p^m (1-p)^{N-m},\\
\hat{p} = \frac{m}{N}.
$$ What is $E[\hat{p}^w]$ , where $0<w<1$ ? Specifically $$
E[\hat{p}^w]
 = \sum_{m=0}^N \binom{N}{m} p^m (1-p)^{N-m} \left(\frac{m}{N}\right)^w =~?
$$ If $w$ was integer we could use the moment-generating function. Is there an analogous function that generates the ""non-integer moments"" of probability distributions?","['probability-distributions', 'binomial-distribution', 'expected-value', 'moment-generating-functions', 'probability']"
3712627,Express $\operatorname{trace}(B'XB)$ in terms of $A$ and $B$,"Given $A\in\Bbb R^{n\times n}$ , $B\in\Bbb R^{n\times m}$ , and $X>0$ , s. t. $X=A'XA-A'XB(I+B'XB)^{-1}B'XA,$ where $A'$ is $A$ transpose. Is it possible to express $\operatorname{trace}(B'XB)$ in terms of $A$ and $B$ only (without $X$ )? If it helps, $(A,B)$ is stabilizable . Even for diagonal $A$ , the answer is not obvious. My attempt: I only have few equalities that I managed to deduce: $\operatorname{trace}(B'XB)=\operatorname{trace}(AX^{-1}A'X)-\operatorname{trace}(I)=\operatorname{trace}(AX^{-1}A'X)-n.$ $\operatorname{trace}(B'XB)=\sum\limits_{i=1}^m(B_i'XB_i)$ , where $B_i$ is the $i$ 'th column of $B$ . Let $A=\begin{bmatrix}a_1&&\\&a_2&\\
&&a_2\end{bmatrix}$ , then $\operatorname{trace}(B'XB)=a_1^2a_2^2 + a_2^2 -2$ . (i.e. independent of $B$ ) $\det(A_1)^2+\cdots+\det(A_m)^2\geqslant \operatorname{trace}(AX^{-1}A'X)\geqslant m\sqrt[m]{\det(A)^2}$ . To prove this part, we can do Wonham decomposition on $(A,B)$ then use 1 and 2 together with geometric mean. Is there any tighter bound than 4?","['linear-algebra', 'control-theory']"
3712642,Children with torches puzzle,"It's almost nighttime and some children are trying to light up their backyard. They have $n$ torches ( $n \in  \mathbb{N}$ ) and want to distribute themselves on the $n \text{ } \text{x} \text{ }n$ -Meter backyard in such a way, that no two torches illuminate each other. Each torch sends light in 8 different directions, as in the following picture: There are horizontal beams (marked in red), vertical beams (marked in green) and diagonal beams (marked in yellow). We suppose that $n \geq 5$ and that $n$ is not divisible by $2$ nor $3$ . Prove that the following positioning of $n$ children with torches $T_0, T_1, ..., T_{n-1}$ works, i.e no two torches light the same position in the backyard: For $0 \leq i \leq n-1$ we position the torch $T_i$ on the field ( $i, 2i \text{ } \text{mod } n).$ Here, we use the ( $x$ -coordinate, $y$ -coordinate) coordinate system, where $x$ describes the horizontal position, and $y$ the vertical. For example: The three torches in the picture are placed on the fields $(3, 1), (2, n-3)$ and $(n-2, n-2).$ My idea was to prove by contradiction and break up each case on how the torches light up their path (horizontally, vertically and diagonally), but I can't see what follows. Can someone offer their thoughts or point me in the right direction?","['proof-writing', 'combinatorics']"
3712707,"Combinatorial interpretation of the identity $(f \circ f \circ f)(x) = x$ where $f(x) = 1/(1-x)$ for $x\in(-1,1)$","Let $f(x) = 1/(1-x)$ . We can interpret this as the generating function of an infinite list of $1$ s: $(1, 1, 1, \cdots)$ . Now, let's consider $(f \circ f \circ f)(x)$ . We first compute $(f \circ f)(x)$ , and use this to compute $f \circ f \circ f$ . \begin{align*}
&(f \circ f)(x) = \frac{1}{1 - \frac{1}{1-x}} \\
&=  \frac{1}{\frac{(1 - x) - 1}{1-x}}
= \frac{1-x}{-x} = \frac{x-1}{x} 
= 1 - \frac{1}{x} \\
\end{align*} \begin{align*}
&(f \circ f \circ f)(x) = (f \circ f)(f(x)) = 1 - \frac{1}{f(x)} = 1 - (1 - x) = x
\end{align*} What is going on? It's cool that $f^{\circ 3} = id$ , but I don't have an explanation for this. I lose the ability to interpret this as a generating function at step $(2)$ : When we compute $f \circ f= 1 - 1/x$ , it's unclear to me what this represents. I have an explanation, but it's not very enlightening.  We can consider $f$ as a mobius transform: $f(z) = (0\cdot z + 1)/(-z+1)$ . This gives the matrix $F$ such that $F^3 = I$ . So there should be some complex analytic explanation that I am unable to divine. $$
F = \begin{bmatrix} 0 & 1 \\ -1 &1 \end{bmatrix}; \quad 
F^3 = -I \underset{\small{\text{(projectively)}}}{\simeq} I
$$ I was hoping to view either some Riemann sphere-based explanation (I don't know this very well) or a combinatorial explanation of the above phenomenon.","['complex-analysis', 'mobius-transformation', 'combinatorics', 'generating-functions']"
3712732,What Is the meaning of the residue of a complex function?,"Studying complex analysis I saw that, in many cases, the residue's theorem comes really handful. I learned how to find it and how to use it, but I didn't quite understand what it really means ""geometrically"", if this makes any sense. Is there an intuitive way to explain what a residue is, or is it just a mathematical tool?","['complex-analysis', 'complex-integration', 'laurent-series']"
3712734,Prove that the number $\lfloor (2+\sqrt5)^{2019} \rfloor$ is not prime.,"Prove that the number $\lfloor (2+\sqrt5)^{2019} \rfloor$ is not prime. My approach for this went as follows: Letting $a_n = (2+\sqrt5)^n +(2-\sqrt5)^n$ would result in $a_0 = 2$ , $a_1=4$ and $a_2= 18$ from here it seems that we could prove by induction that all the terms $a_n$ are even. If that's the case we would have that $a_n$ is even and since $2-\sqrt5 < 1 \Rightarrow (2-\sqrt5)^n < 1 \Rightarrow$ $(2+\sqrt5)^n +(2-\sqrt5)^n = \lfloor (2+\sqrt5)^{2019} \rfloor$ this would imply that $\lfloor (2+\sqrt5)^{2019} \rfloor$ is even as well and hence not a prime. However, I have a couple of questions regarding this. I'm not entirely sure if I can set $a_n = (2+\sqrt5)^n +(2-\sqrt5)^n$ . The only reason why I did this was that in a similar problem I posted previously I got educated a bit and the reason was that this would result in $a_0, a_1$ and $a_2$ to be integers and from there I could find the recurrence relation. I'm not sure if this is the way to solve these problems in general. Also it seems that from here I could deduce that instead of $a_n = (2+\sqrt5)^n +(2-\sqrt5)^n$ it should actually be $a_n=4a_{n-1}+a_{n-2}$ why is this the case?","['contest-math', 'elementary-number-theory', 'algebra-precalculus', 'recurrence-relations']"
3712752,How to find geometrical figures areas?,"Find the area of the region that lies inside the circle $r = 1$ and outside the cardioid $r=1-cos\alpha$ We know that area can not be negative value(at least basic calculus). I wonder where I made a mistake,I tried to show equations. $$ 1=1-cos\alpha $$ $$\alpha = \pi/2,3\pi/2$$ \begin{equation}
\frac{1}{2}\int_{3\pi/2}^{\pi/2}f(x)^2d\alpha
\end{equation} \begin{equation}
\frac{1}{2}(\int_{\pi/2}^{3\pi/2}1^2d\alpha-\int_{\pi/2}^{3\pi/2}(1-cos\alpha)^2d\alpha)  
\end{equation} $$ \int_{3\pi/2}^{\pi/2}1^2d\alpha = $$ $$ \frac{3\pi}{2} -\frac{\pi}{2}=\pi $$ $$ \int_{\pi/2}^{3\pi/2}(1-cos\alpha)^2d\alpha = $$ $$ 9\pi/2 - 3\pi/2 + 2 - (-2) + 0 - 0 $$ $$ 2\frac{1}{2}(\pi - 3\pi - 4)$$ $$ Answer: (-2\pi-4) $$ symmterical no required multiple by 2.","['integration', 'calculus', 'area', 'derivatives']"
3712770,Checking which distributions are infinitely divisible,"I have got this homework to check which distributions with the following characteristic functions are infinitely divisible: $\frac{1}{1-it}$ $\frac{1}{1+t^2}$ $e^{-t^2}\cos t $ I literally have no idea how to approach it. All I know is the definition of infinite divisibility. Could you show me how to deal with tasks like that? The definition I was given at the lecture: Distribution of random variable $X$ is infinitely divisible if for every $n \in N$ there exist $X_{1,n},.., X_{n,n}$ i.i.d such that $X \stackrel{D}{=} X_{1,n}+\cdots+X_{n,n}$","['characteristic-functions', 'probability-distributions', 'probability-theory']"
3712823,How to find the number of solutions of $6|\cos x|=x$?,"Now, I think the only way to solve this problem for a high school student was graphically. However using pen and paper to draw the graph, it was virtually impossible to justify or refute the existence of the ""Fourth"" solution. Using desmos, I realised that we must must work on the the existence of the Fourth solution analytically because $ y=x$ is really close to $6|\cos x|$ at the potential Fourth solution. You can see for yourself. So, this being a high school problem, is there any way to predict whether $y=x$ will intersect $6|\cos x|$ or not? With enough zoom we can see that $y=x$ does not intersect $y=6|\cos x|$ . However, how could have I predicted this with a pen and paper? I am acquainted with calculus but had no clue how to go about it. Thanks for your time!","['calculus', 'functions', 'algebra-precalculus', 'graphing-functions']"
3712922,A sequence of quadratic equations,"Let $p\le q$ be roots of the (real) quadratic equation $x^2+ax+b=0$ , $|p|+|q|\ne 0.$ Form the new equation $x^2+px+q=0$ , find its real roots (if exist), etc. For example, if $a=3, b=2$ , then $p=-2,q=-1$ , $x^2-2x-1=0$ has two real roots $p_1= 1 - \sqrt{2}$ and $q_1= 1 + \sqrt{2}$ (note that $p_1\le q_1$ ) but the equation $x^2+p_1x+q_1$ does not have real roots, the process ends. Question: What is the longest possible sequence of quadratic equations we can get?","['algebra-precalculus', 'quadratics']"
3712954,Bounded Maximal Solutions of ODE System,"Let $(x(t), y(t))$ be a maximal solution of the following diferential equation: $(x,y)' = (-x + y, \hspace{0.2cm} log(10+|x|) - y)$ and consider $t_0 \in \mathbb{R}$ a point in its domain. Show that both real functions $x(t)$ and $y(t)$ are limited for $t \geq t_0$ . Attempts : I've tried to write $x(t)$ and $y(t)$ in a way that makes it possible to apply Gronwall's Lemma for each one of them, but the inequalities don't work quite right. Trying to solve this ode system without using exponencial of matrices (which we can't use) seems difficult enough. Any help is appreciated!","['analysis', 'ordinary-differential-equations']"
3713010,Exactness of (full) group $C^*$-algebra,"Let $\Gamma$ be a discrete group. It is well known that if $\Gamma$ is amenable, then its full $C^*$ algebra $C^*(\Gamma)$ is exact. Moreover, if $\Gamma$ is residually finite then the converse also holds: if $C^*(\Gamma)$ is exact then $\Gamma$ is amenable (e.g. proposition 3.7.11. Brown-Ozawa "" $C^*$ -algebras and finite dimensional approximations""). Do we need to asumme that $\Gamma$ is residually finite? Or in other words, is there a discrete group $\Gamma$ which is not amenable but has exact full $C^*$ algebra $C^*(\Gamma)$ ?","['c-star-algebras', 'group-theory', 'functional-analysis', 'operator-algebras']"
3713056,Show that $\text{Im}(\tfrac{e^{i \theta}}{1-xe^{i \theta}})=\frac{\sin(\theta)}{x^2-2x \cos(\theta)+1}$,"Let $0<\theta<\frac{\pi}{2}$ and $0\le x \le1$ , show that : $$\text{Im}\left(\frac{e^{i \theta}}{1-xe^{i \theta}}\right)=\frac{\sin(\theta)}{x^2-2x \cos(\theta)+1}$$ I tried to look for the exponential form of $1-xe^{i \theta}$ , so i've found $1-xe^{i\theta}=re^{i(-\alpha)}$ where $r = \sqrt{1+x^2-2x\cos(\theta)}$ and $\alpha= \arctan(\frac{x\sin(\theta)}{1-x\cos{\theta}})$ . Thus $\frac{e^{i \theta}}{1-xe^{i \theta}}=\frac{1}{r}e^{i(\theta-\alpha)}$ , and i'm stuck here. Is there a way to easily compute $\alpha$ , or another way to solve this ?","['trigonometry', 'complex-numbers']"
3713061,Non-isomorphic graphs with 2 vertices and 3 edges,"Are there any non-isomorphic graphs with 2 vertices and 3 edges? From my understanding of what non-isomorphic means, I don't think there are any, but I'm not sure.","['graph-theory', 'discrete-mathematics']"
3713069,Why can we treat Cox's partial likelihood as a full likelihood?,"I am doing some self study on Cox regression, and am trying to figure out how we can derive the partial likelihood for the Cox model from the full likelihood.  Generally, I know that to get a partial likelihood, we can just use proportionality, but here, this doesn't seem as intuitive. Consider the Cox full log likelihood: $$l(\theta) = \sum_{i=1}^n \delta_i log h_i(T_i;\theta) - \int_0^{T_{i}}h_i(s;\theta)ds$$ where $h_i(T_i;\theta)$ is the hazard: $h_i(T_i;\theta) = h_0(t)exp(\gamma^Tw_i)$ . The corresponding partial log likelihood would be: $$ pl(\gamma) = \sum_{i=1}^n \delta_i \bigg[\gamma^Tw_i - log \bigg\{\sum_{T_j\geq T_i}exp(\gamma^tw_j) \bigg\} \bigg] $$ Of course, the first apparent step I see is to substitute in the hazard function into the full likelihood: $$l(\theta) = \sum_{i=1}^n \delta_i log (h_0(t)exp(\gamma^Tw_i)) - \int_0^{T_{i}}h_0(t)exp(\gamma^Tw_i)ds$$ $$ = \sum_{i=1}^n \delta_i \bigg[\gamma^Tw_i+ log (h_0(t))\bigg] - \int_0^{T_{i}}h_0(t)exp(\gamma^Tw_i)ds$$ From here, any advice in the derivation or intuition would be much appreciated!","['statistical-inference', 'statistics', 'log-likelihood', 'regression-analysis', 'maximum-likelihood']"
3713079,"Solve the following equation in integers $x,y:$ $x^2+6xy+8y^2+3x+6y=2.$","Question: Solve the following equation in integers $x,y:$ $$x^2+6xy+8y^2+3x+6y=2.$$ Solution: For some $x,y\in\mathbb{Z}$ $$x^2+6xy+8y^2+3x+6y=2\\\iff x^2+2xy+4xy+8y^2+3x+6y=2\\\iff x(x+2y)+4y(x+2y)+3(x+2y)=2\\\iff(x+4y+3)(x+2y)=2.$$ Now if $(x+4y+3)(x+2y)=2$ , then either $$\begin{cases} x+4y+3=1\\ x+2y=2\end{cases}\text{ or }\begin{cases} x+4y+3=2\\ x+2y=1\end{cases}\text{ or }\begin{cases} x+4y+3=-1\\ x+2y=-2\end{cases}\text{ or }\begin{cases} x+4y+3=-2\\ x+2y=-1\end{cases}.$$ We have $$\begin{cases} x+4y+3=1\\ x+2y=2\end{cases}\iff (x,y)=(6,-2), \\\begin{cases} x+4y+3=2\\ x+2y=1\end{cases}\iff (x,y)=(3,-1), \\\begin{cases} x+4y+3=-1\\ x+2y=-2\end{cases}\iff (x,y)=(0,-1),\\\begin{cases} x+4y+3=-2\\ x+2y=-1\end{cases}\iff (x,y)=(3,-2).$$ Now since, all the four pairs $(6,-2),(3,-1),(0,-1),(3,-2)$ satisfies the integer equation $(x+4y+3)(x+2y)=2$ , thus we can conclude that $(x+4y+3)(x+2y)=2\iff (x,y)=(6,-2),(3,-1),(0,-1),(3,-2).$ Hence, we can conclude that the integer equation $x^2+6xy+8y^2+3x+6x=2$ is satisfied if and only if $(x,y)=(6,-2),(3,-1),(0,-1),(3,-2)$ , and we are done. Is the solution correct and rigorous enough? And, I am always confused while solving equations regarding the usage of the if and only if arguments, which I feel is very necessary in order to have a complete and rigorous solution, but I rarely find it's usage in any book while solving equations of any kind. So, is it necessary? Also, is there a better solution than this?","['number-theory', 'elementary-number-theory', 'diophantine-equations']"
3713148,Expected number of matching pairs from a random list,"Question A random list of length $n$ (even number) consists of $n_1$ stars $\star$ and $n_2$ squares $\square$ . Suppose we randomly put these shapes into $n/2$ pairs, denote: $X_1$ to be the number of matching pairs of $\star$ $X_2$ to be the number of matching pairs of $\square$ What is the expected number of $X_1$ and $X_2$ ? Example For example, if $n=10$ , $n_1=7, n_2=3$ , suppose we have a random pattern of 5 pairs \begin{align*}
\star ~\square \\
\star ~\star \\
\square ~\square \\
\star ~\star \\
\star ~\star
\end{align*} Because there are 3 matching pairs for $\star$ and 1 matching pair for $\square$ , we have $X_1=3, X_2=1$ . If we repeat this process many times, we should have different patterns of pairs, and produce different values of $X_1$ and $X_2$ . I'm wondering how to calculate their expected values $E[X_1]$ and $E[X_2]$ , which should be functions on $n_1$ and $n_2$ . The problem comes from my research project. Thank you in advance.","['expected-value', 'combinatorics', 'probability']"
3713183,Prove that a function $u: u= \ln\|x\|{_{2}}$ has $\Delta u = 0$.,"I had a similar case some time ago and following the advices there I tried to solve this one too.
I tried to find its first partial derivative and I got: $\frac{\partial}{\partial x_{i}}=\frac{1}{2\cdot \|x\|_{2}^{1/2}}$ Now i have to find the second derivative of this and I got $\frac{1+4\cdot (\sum x_{i}^{2})^{5}}{8\cdot(\sum x_{i}^{2})^{5/4} }$ . And now I am stuck,I have no idea if my calculations are okay or how can I continue to solve this.
I would be incredibly thankful for some help. Annalisa","['functions', 'analysis', 'ordinary-differential-equations', 'real-analysis']"
3713206,Question about Spivak's proof of how to use u-substitution when the derivative of the inner function does not appear in the integral,"Spivak (3rd edition) proposes solving the integral $$\int \frac{1+e^x}{1-e^x} dx$$ by letting $u=e^x$ , $x=\ln(u)$ , and $dx=\frac{1}{u}du$ . This results in the integral $$\int \frac{1+u}{1-u}\frac{1}{u}du\\=\int \frac{2}{1-u}+\frac{1}{u}du=-2\ln(1-u)+\ln(u)=-2\ln(1-e^x)+x$$ From this example, Spivak argues that a similar method will work on any integral of the form $\int f(g(x))dx$ whenever $g(x)$ is invertible in the appropriate interval. Because this method is not a simple application of the substitution theorem, Spivak provides the following justification for his claim. Consider continuous $f$ and $g$ where $g$ is invertible on the appropriate interval. Applying the above  method to the arbitrary case, we let $u=g(x)$ , $x=g^{âˆ’1}(u)$ , and $dx=(g^{âˆ’1})â€²(u)du$ . Thus, we need to show that $$âˆ«f(g(x))dx=âˆ«f(u)(g^{âˆ’1})â€²(u)du$$ To prove this equality Spivak uses a more typical substitution $u=g(x)$ , $du=gâ€²(x)dx$ and applies it by noting that $$âˆ«f(g(x))dx=âˆ«f(g(x))gâ€²(x)\frac{1}{gâ€²(x)}dx$$ Presumably using the substitution theorem, which roughly states that $âˆ«f(g(x))g'(x)dx=âˆ«f(u)du$ , Spivak asserts that $$âˆ«f(g(x))gâ€²(x)\frac{1}{gâ€²(x)}dx=âˆ«f(u)\frac{1}{gâ€²(g^{âˆ’1}(u))}du$$ Then, because $(g^{-1})'(u)=\frac{1}{g'(g^{-1}(u))}$ Spivak concludes $$âˆ«f(u)\frac{1}{gâ€²(g^{âˆ’1}(u))}du=âˆ«f(u)(g^{âˆ’1})â€²(u)du$$ I lose track of the argument when Spivak argues that $$âˆ«f(g(x))gâ€²(x)\frac{1}{gâ€²(x)}dx=âˆ«f(u)\frac{1}{gâ€²(g^{âˆ’1}(u))}du$$ In the original example, it was clear to me how we could apply the substitution theorem to make this equality true because $\frac{1}{g'(x)}$ was in fact a function of $g(x)$ as $g'(x)=g(x)$ . But this is not necessarily true in all cases, or so it seems. How do we know that $f(g(x))\frac{1}{g'x}$ can be written in the form $h(g(x))$ for some continuous function $h$ ? To sum up, my main questions is, how do we use the substitution theorem to justify the equality $$âˆ«f(g(x))gâ€²(x)\frac{1}{gâ€²(x)}dx=âˆ«f(u)\frac{1}{gâ€²(g^{âˆ’1}(u))}du$$","['calculus', 'real-analysis']"
3713294,On the density of a certain sequence of integers,"A BogotÃ¡ number is a positive integer equal to some smaller number, or itself, times its digital product, i.e. the product of its digits. For example, 138 is a BogotÃ¡ number because 138 = 23 x (2 x 3). Here is the list of BogotÃ¡ numbers not greater than 1000: 0, 1, 4, 9, 11, 16, 24, 25, 36, 39, 42, 49, 56, 64, 75, 81, 88, 93, 96, 111, 119, 138, 144, 164, 171, 192, 224, 242, 250, 255, 297, 312, 336, 339, 366, 378, 393, 408, 422, 448, 456, 488, 497, 516, 520, 522, 525, 564, 575, 648, 696, 704, 738, 744, 755, 777, 792, 795, 819, 848, 884, 900, 912, 933, 944, 966, 992. What is the density of these numbers? Another issue regarding these numbers has been dealt with at https://puzzling.stackexchange.com/questions/98998/pairs-of-bogot%c3%a1-numbers/99006#99006 https://oeis.org/A336826","['number-theory', 'sequences-and-series']"
3713341,Why does the Boolean equation A.B' + B = A + B hold?,"I have pretty good amount of knowledge in Boolean algebra. However, I struggled with the equality $(1)$ more than I should have. $$x'z' + z = x' + z\tag{1}$$ How is it that this holds, algebraically? I can assure you that I've tried it enough. I just cannot get it right now. Thanks.","['boolean-algebra', 'logic', 'discrete-mathematics']"
3713384,Which is greater $\frac{13}{32}$ or $\ln \left(\frac{3}{2}\right)$,"Which is greater $\frac{13}{32}$ or $\ln \left(\frac{3}{2}\right)$ My try: we have $$\frac{13}{32}=\frac{2^2+3^2}{2^5}=\frac{1}{8}\left(1+(1.5)^2)\right)$$ Let $x=1.5$ Now consider the function $$f(x)=\frac{1+x^2}{8}-\ln x$$ $$f'(x)=\frac{x}{4}-\frac{1}{x}$$ So $f$ is Decreasing in $(0,2)$ any help here?","['inequality', 'number-comparison', 'analysis', 'limits', 'algebra-precalculus']"
3713406,Continuous path of Fredholm operators,"Let $H$ be a (infinite dimensional) Hilbert space and denote by $\mathcal{F}(H)$ the semigroup of bounded Fredholm operators in $H$ . Let $S,T\in\mathcal{F}(H)$ and let $I=id_{H}$ be the identity map in $H$ .
I know that $ST\oplus I$ and $S\oplus T$ are both elements of $\mathcal{F}(H\oplus H)$ and that they have the same index. Question. How can one explicitly construct a continuous map $\alpha\colon[0,1]\to\mathcal{F}(H\oplus H)$ such that $\alpha(0) = ST\oplus I$ and $\alpha(1)=S\oplus T$ ? Writing $A\oplus B = \begin{bmatrix} A & 0 \\ 0 & B \end{bmatrix}$ , I already notice that $$\alpha(t) = \begin{bmatrix} ST & 0 \\ 0 & I \end{bmatrix}
\begin{bmatrix} \cos(\pi t/2) & -\sin(\pi t/2) \\ \sin(\pi t/2) & \cos(\pi t/2) \end{bmatrix}
\begin{bmatrix} I & 0 \\ 0 & S^{-1} \end{bmatrix}
\begin{bmatrix} \cos(\pi t/2) & \sin(\pi t/2) \\ -\sin(\pi t/2) & \cos(\pi t/2) \end{bmatrix}
\begin{bmatrix} I & 0 \\ 0 & S \end{bmatrix}$$ seems to do the job, though I do not know how to check that $\alpha(t)\in\mathcal{F}(H\oplus H)$ for all $t\in[0,1]$ . Besides, in the above formula I've assumed that $S$ is invertible, and I could not find a solution without that assumption. Any ideas? Thanks in advance.","['hilbert-spaces', 'operator-theory', 'functional-analysis', 'analysis']"
3713465,Gradient in level-set coordinates.,"If f: $\mathbb{R}^n \to \mathbb{R}$ is a smooth function and $x_0$ is a regular point, we know there is a diffeomorphism $\phi:U \to \phi(U)\subset \mathbb{R}^n$ , with $x_0 \in \phi(U)$ such that $$f(\phi(x)) = x_n, \quad \text{for } x=(x_1,\ldots,x_n) \in U.$$ Using Riemannian Geometry notation, can we say that that the coordinate frame induced by the local chart $(U,\phi)$ satisfies $\partial_n = \text{grad} f$ ? It seems to me that this should be the case, since the composition with $\phi$ depends only on the last variable.","['calculus', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
3713487,Properties of set of positive Lebesgue measure in $\mathbb{R}^2$,"Let $A,B\subset \mathbb{R}$ be such that they are positive Lebesgue measure in $\mathbb{R}$ . Let $C\subset \mathbb{R}^2$ is closed, nowhere dense, measure zero set in $\mathbb{R}^2$ . Does there exists $E,F \subset \mathbb{R}$ satisfying $$EÃ—F\subset AÃ—B\setminus C,$$ such that $E,F$ are positive Lebesgue measure in $\mathbb{R}?$ Edit: I worked out the problem (though I am not sure whether it is correct or not, that's why I am editing the question instead of posting in answer section) $\textbf{ My try:}$ It is enough to assume that $C$ is closed and measure zero set in $\mathbb{R}^2$ .  So $AÃ—B\setminus C$ is an open set in $AÃ—B$ and hence there exists a sequence of almost disjoint ( i.e. intersection of their interior are disjoint) closed squares $\{A_k\}$ in $\mathbb{R}^2$ such that $$AÃ—B\setminus C= \cup_{k\in \mathbb{N}}A_k\cap AÃ—B.$$ Since $AÃ—B\setminus C$ is again a set of positive measure and $A_k$ 's are almost disjoint we must get $m\in \mathbb{N}$ such that $A_m\cap AÃ—B$ is positive measure. Now let us consider $$E=\{ \text { projection of }A_m \text{ onto } x\text{-axis}\}\cap A,$$ $$F=\{ \text { projection of }A_m \text{ onto } y\text{-axis}\}\cap B.$$ Then $EÃ—F=A_m\cap AÃ—B$ and $E,F$ are positive measure in $\mathbb{R}$ as $A_m\cap AÃ—B$ is positive measure in $\mathbb{R}^2.$","['measure-theory', 'lebesgue-measure', 'real-analysis']"
3713490,Congruence mod p involving a product,"Let $p$ be a prime, $p\equiv 3$ mod $4$ . Numerically it appears that $$
\prod_{n=1}^{p-1}\left(1+n^2\right)\equiv 4\mod p.
$$ How can one prove this? For $p\equiv 1$ mod $4$ , the product is $0$ mod $p$ because $-1$ is a quadratic residue.","['number-theory', 'modular-arithmetic', 'products']"
3713531,"Prove that $|AUC| = |A|$, where $A$ is an uncountable set and $C$ is a countable set.","Let $A$ be an uncountable set and let $C$ be a countable set with $A \cap C = \{\}$ . Show that $|A\cup C| = |A|$ . I'm quite lost as to how to approach solving this problem. I know that CSB theorem is involved to conclude there is a bijection, but still confused. Any help is appreciated!","['elementary-set-theory', 'proof-explanation', 'proof-writing']"
3713540,"Nonisomorphic quotient rings $k[x,y]/(x^2-y^{2n+1})$ for different values of $n$","I want to prove the following proposition: For $n\neq m\in\mathbb{Z}_{\geq 0}$ the, $k$ -algebras $R_n$ and $R_m$ are non-isomorphic, where $R_n=k[x,y]/(x^2-y^{2n+1})$ , at least when $k=\mathbb{C}$ . In this case being the exponent of $y$ odd, I can see that all the $R_n$ are integral domains. But also as $k[x,y]$ -modules they have the same length of free resolutions, thus the same projective dimension, etc., so I'm not sure what kind of invariant should I use to prove they're not isomorphic. I think that for $n>0$ none of the rings are UFDs and that $R_0\cong k[t]$ so that would be one case.","['algebraic-geometry', 'commutative-algebra']"
3713657,A condition on function $f(x+a)+f(x+b)=\frac{1}{2}f(2x)$ implies periodicity,"I stumbled upon the following question (I will provide more information about its source at the end): Let $a$ and $b$ be distinct real numbers. Suppose $f:\mathcal{R}\to\mathcal{R}$ is continuous such that $f(x) = o(x^2)$ as $x\to\pm\infty$ , and $$f(x+a)+f(x+b)=\frac{1}{2}f(2x),\ \forall x.$$ Then, $f$ must be periodic. Here are my thoughts on this problem: if we could take the Fourier transform of the above equation, we get $$\left(e^{iak}+e^{ibk}\right)\hat f(k) = \frac{1}{4}\hat f(k/2)$$ $$\Rightarrow |\hat f(k)| = \frac{|\hat f(k/2)|}{8|\cos\left(k\cdot(a-b)/2\right)|}.$$ Applying the above recursively, we see $\hat f(k) = 0$ for all $k$ except when $\cos\left(k\cdot (a-b)/2^n\right) = 0$ , some $n$ . This looks like the spectrum of a periodic function with period $2|a-b|$ . This makes sense but it is far from an actual proof. Moreover, the Fourier approach could be the wrong way to go about this problem. So, any ideas? About the source of this problem, it was published in Nieuw Archief voor Wiskunde 23(1975) p.176 (problem number 409) and I believe there is a solution published in the same journal issue 24(1976) p.101 . Unfortunately, I don't have access to this journal (I found the problem on another site first and then in a book which referenced its proper source). If anyone has access to this journal and is willing to post the solution, I'd be very thankful.","['functions', 'fourier-analysis', 'problem-solving', 'real-analysis']"
3713667,An example of a complete metric space $X$ and a function $f: X \to X$ which is a continuous bijection such that $f^{-1}$ is not continuous.,"Give an example of a complete metric space $X$ and a function $f: X \to X$ which is a continuous bijection such that $f^{-1}$ is not continuous. This is an offshoot of the following: Finding an (easy) example of a bijective continuous self mapping whose inverse is not continuous There are examples where the domain and range are not the same and examples where completeness is not a requirement. Of course, OMT shows that we cannot take  a linear map between Banach spaces.  I tried some non-linear maps on Banach spaces but I didn't succeed in finding an example. Thank you for your time.","['continuity', 'general-topology', 'inverse-function']"
3713668,Is a 99% confidence level more precise than 95%?,"Hi.
I'm confused by 'significance level'.
If significance level is lower, is the result of test more reliable? I think it's the opposite, so it makes me so confused. Look at the picture and assume that $H_0$ is null hypothesis, $\alpha$ is the 'significance level'.
Let's test this, by sample size is 40, as a result sample mean is $\mu_1$ .
If the given 'confidence level'( $1-\alpha$ ) is 95%, z value of 'c' would be 1.96. 
If given 99%, 'c' would be 2.56 Here is the problem.
If confidence level is 99%, is the result more reliable than confidence level 95%?
If c level is 99%, more error would be included in null hypothesis area, than level 95%.
if c level is 99%, it means '99% of deviation would be regarded as in the null area anyway. So actually, c level 99% means it's less precise than 95%, right?
Rather, if confidence level is very small like 5%, so the 'c' value goes closer to $\mu_0$ , it would mean that we will regard more values to be error. So it must be more precise. Am I wrong? The textbook seems to say i'm wrong. And hope you genius explain it..
Thank you!","['statistical-inference', 'statistics', 'confidence-interval', 'hypothesis-testing']"
3713759,Gebrane's Hanoi,"I need some help to solve a modification of the Tower of Hanoi problem found on a french forum. The classic problem is described here . This modification is called Gebrane's Hanoi problem (from the name of its inventor), the $n$ disks are numbered from top to bottom from $1$ to $n$ and are also placed on peg $A$ , and the goal is to move all the disks to pegs $B$ and $C$ to form two towers: the tower on peg $B$ is formed with all the even-numbered disks and the one on peg $C$ is formed with all the odd ones (obviously).
The other rules are the same: each move consist in displacing an upper disk of a tower on top of another tower or on an empty peg, and no disk may be placed on a smaller one.
Let $HG(n)$ be the minimum number of moves to solve Gebrane's Hanoi problem. Prove that: $$HG(n)=-\frac 1{21}\cos\left(\frac2 3n\pi\right)+\frac 1 7\sqrt 3\sin\left(\frac2 3n\pi\right)+\frac 5 7 2^n-\frac 2 3.$$","['recursive-algorithms', 'recurrence-relations', 'trigonometry', 'algorithms', 'recreational-mathematics']"
3713810,Explaination of proof of Property of cyclic subgroup.,"Let $G$ be a group and let $g\in G$ be an element of finite order n. (i) For $m\in \Bbb Z$ , $g^m=g^r$ where $r$ is the remainder on division of $m$ by $n$ . (ii)The order of the cyclic subgroup $\langle g\rangle$ generated by $g$ is $n$ . Proof of (ii): By (i), every power $g^m$ of $g$ is equal to one of the $n$ elements $e,g,...,g^{n-1}$ .No two of these elements are equal, for if $0\le j<i\le n-1$ are such that $g^i=g^j$ then $0<i-j<n$ and $g^{i-j}=e$ , contradicting the definition of the order of $g$ . Thus, $\langle g\rangle={e,g,...,g^{n-1}}$ has order $n$ . My problem is I literally don't understand this proof. First statement is bit cryptic for me what does ""every power $g^m$ "" of $g$ "" actually means? Does it mean $g^{m+1}$ or $g$ with power $m$ ? Well if it is $g$ with power $m$ then this statement is might be true since $0\le r<n$ so there might exist $g^r$ such that $g^m$ equal to it . Second statement says that it is contradicting the definition of the order of $g$ and I don't know how the hell does it do contradiction I really don't get it. Now third statement is just a result which everyone knows. (I know this question might sound dumb but I really don't have ability to understand it myself anyway thanks for taking time to read it I hope you can explain. Good Luck!)","['proof-explanation', 'group-theory', 'cyclic-groups']"
3713832,Derivative of Mean Squared Error,"I'm studying with a book and I'm at the Linear Regression part. The author is showing that we have to calculate the derivative of each part of the equation that leads to the loss. But he's using the MSE to calculate the loss and so, I tried to calculate the derivative of MSE: the derivative of $ (y-p)^2 $ with respect to y (the target) is equal to $2(y-p)$ but  in the book it is written $-1*(2(y-p))$ which is simplified as $-2(y-p)$ . Why do I have different values ? Where is this $-1$ coming from?","['machine-learning', 'calculus', 'neural-networks', 'linear-regression']"
3713835,"If $f$ is measurable, can we write $f = r \cdot \exp(i\varphi)$ for $r, \varphi$ measurable?","It is well known, that if we have an interval $[a,b] \subset \mathbb{R}$ and a continuous curve $c \colon [a,b] \to \mathbb{R}^2$ with $c(t) \neq 0$ for all $t$ , then there exist continuous functions $r \colon [a,b] \to (0,\infty)$ and $\varphi \colon [a,b] \to \mathbb{R}$ so that $$c(t) = r(t)(\cos(\varphi(t)), \sin(\varphi(t)))$$ holds for all $t \in [a,b]$ . This motivates the following question: If $(X, \mathcal{A}, \mu)$ is a measure space and $f \colon X \to \mathbb{C}$ is measurable, do there exist measurable functions $r \colon X \to [0, \infty)$ (note that $r$ is allowed to be 0) and $\varphi \colon X \to \mathbb{R}$ so that $$f(x) = r(x)(\cos(\varphi(x)) + i \sin(\varphi(x)))$$ I know that $\varphi$ (if existent) certainly will not be unique and that $r$ can indeed be found quite easily by $$r(x) = |f(x)|$$ So the main struggle is with finding $\varphi$ . Can we prove that there always exists such a measurable $\varphi$ ? Edit: As pointed out in the comments, the statement holds for simple functions $f = \sum \alpha_k \chi_{A_k}$ , by simply setting $r = |f|$ and $\varphi = \sum \varphi_k \chi_{A_k}$ , where the $\varphi_k \in \mathbb{R}$ are chosen such that $f(x) = r(x) \exp(i\varphi_k)$ , since then by construction $$f = r \cdot \exp(i\varphi)$$ Now it is clear, that if we have an arbitrary measurable function $f$ , then we can approximate $f$ by simple function, thus by what we have seen before, we may find a sequence of simple functions $\{\varphi_n\}$ such that $$r(x)\exp(i\varphi_n(x)) \to f(x)$$ for all $x \in X$ . However, this does not guarantee, that there exists some $\varphi \colon X \to \mathbb{R}$ so that $\varphi_n(x) \to \varphi(x)$ and $r(x)\exp(i\varphi(x)) = f(x)$ for all $x$ .","['measure-theory', 'polar-coordinates']"
3713836,Inverse trignometry ineqality.,"The question is - $$sin^{-1}(x)>cos^{-1}x   âˆ¨\  x\ âˆƒ (0,1)$$ I am getting two different answers by two different methods.I know which method is wrong and which one is right, as i plotted the solution of this inequality on Desmos. I am only posting the wrong solution and wish to find out what's wrong in my method. $$sin^{-1}(x)+cos^{-1}(x) = \frac {\pi}{2}  $$ Substituting $$sin^{-1}(x)= - cos^{-1}(x) + \frac {\pi}{2}  $$ and if we substitute this in the original question we get $$  2cos^{-1}(x) < \frac {\pi}{2}  $$ or $$  cos^{-1}(x) < \frac {\pi}{4}  $$ taking  cos and we get $$  x <cos( \frac {\pi}{4} ) $$ and get the solution $$ x \ âˆƒ\  (0,\frac{1}{\sqrt2})  $$ If i replace $$ cos^{-1}(x)\ with\ sin^{-1}(x)$$ then i am getting $$ x \ âˆƒ\  (\frac{1}{\sqrt2},1)  
$$ which apparently  is the correct answer.  At which step i am wrong?","['trigonometry', 'functions', 'inverse-function', 'inequality']"
3713900,For $f(x) = e^x + x^3 - x^2 + x$ find the limit $\lim\limits_{x\to \infty} \frac{f^{-1}(x)}{\ln x}$.,"I have the function: $$f : \mathbb{R} \rightarrow \mathbb{R} \hspace{2cm} f(x) = e^x + x^3 -x^2 + x$$ and I have to find the limit: $$\lim\limits_{x \to \infty} \frac{f^{-1}(x)}{\ln x}$$ (In the first part of the problem, I had to show that the function is strictly increasing and invertible. I don't know if that's relevant to this, since I could show that the function is invertible, but I can't find the inverse.) So this is what I tried: I showed $$\lim_{x \to \infty} f(x) = \infty$$ and so I concluded that $\lim\limits_{x \to \infty} f^{-1}(x) = \infty$ . I'm not sure if this is correct, it might be wrong. But if would be right, then we could use l'Hospital, knowing that: $$(f^{-1})'(x) = \frac{1}{f'(f^{-1}(x))}$$ but after trying to use all of this on paper, I got nowhere. It just complicated thing a lot more. So how should I solve this limit?","['limits', 'calculus', 'inverse-function', 'derivatives']"
3713910,Modification of Law of Cosines,"How should the Law of Cosines $$\cos c = \cos a \cos b + \sin a \sin b \cos C$$ be modified  if sides $(a,b,c) $ are not geodesics but are small circles with geodesic curvatures $k_a,k_b,k_c?$ It may be useful for navigation on the globe as airplanes and ships  do not always take the shortest path. EDIT1: Parallelly could we consider using radii ( of curvatures instead of curvatures directly? ... like $(R_a,R_b,R_c) $ along with triangle sides because there seems to be a possible advantage for direct spherical trigonometric calculations and simplifications on each triangle side. A schematic with a rough hand sketch of small circles:","['spherical-geometry', 'differential-geometry']"
3713962,A problem regarding the value of the derivative of a real valued function,"$\mathbf {The \ Problem \ is}:$ Does there exist a differentiable function $f : \mathbb R \to \mathbb R$ such that $|f(x)-f(y)| \lt 1$ whenever $|x-y| \lt 1$ but $|f'(x)|$ is not necessarily less than or equal to $1$ for all $x \in \mathbb R ?$ $\mathbf {My \ approach} :$ Actually,I have thought of a lot of examples specially manipulating the trigonometric functions, but I couldn't find anything to assert a positive answer to the above question . Obviously, the converse is true and no linear functions can satisfy the above requirements. A small hint is warmly appreciated.","['functions', 'derivatives', 'real-analysis']"
3713991,"Counting ordered pairs $(a,b)$ satisfying $a^2+b^2=(a+b)^2$, with $a$ and $b$ in the interval $[-100,100]$","A lazy mathematician believes that $$a^2+b^2 = (a+b)^2.$$ If $a$ and $b$ are both integers from the interval $[-100, 100]$ , find the number of ordered pairs $(a,b)$ that satisfy the equation above. The equation implies that $2ab = 0$ , hence either $a=0$ or $b=0$ . This would result in the following pairs. When $a=0$ $$(0,-100), (0, -99), \dots, (0, 100).$$ When $b=0$ $$(-100, 0), (-99, 0), \dots, (100, 0)$$ Since we have twice the pair $(0, 0)$ we should subtract $1$ from the total counts. For me it seems that there's $200$ possible choices in each scenario. This would imply that the total would be $400-1 = 399$ , but the correct answer was $401$ . What am I missing in the countings?","['algebra-precalculus', 'solution-verification', 'integers']"
3714039,$f(2-x)=f(2+x)$ and $f'(1/2)=0=f'(1)$. Find minimum number of roots of $f''(x)=0$.,"Let $f$ be a non constant twice differentiable function satisfying $f(2-x)=f(2+x)$ and $f'(1/2)=0=f'(1)$ . Find the minimum number of roots of $f''(x)=0$ in the interval $(0,4)$ . Answer: $4$ I managed to rewrite the given equation as $f(x)=f(4-x)$ . Using this, I obtained $$f'(x)+f'(4-x)=0$$ And $$f''(x)=f''(4-x)$$ So it suffices to show that $f''(x)=0$ has at least $2$ roots in the interval $(0,2)$ but I'm unsure what's gonna happen at $x=2$ here. Also, I have $f'(7/2)=0=f'(3)$ from the given info and the first equation I obtained, but I don't know how to use this. Any help would be great.","['calculus', 'derivatives']"
3714053,Does localisation of a faithful retraction induce an isomorphism between adjointables of Hilbert modules?,"The title is quite a mouthful, so let me develop some context. All of this is from the book on Hilbert Modules by C. Lance. If $A$ is a $C^*$ -algebra, $M(A)$ its multiplier algebra and $B$ a sub-algebra of $M(A)$ then a positive linear map $\tau: A\toÂ B$ is called a retraction if: For all $a\in A, b\in B$ : $\tau(ab)= \tau(a)b$ $\tau(A)$ is dense in $B$ relative to the strict topology. There is an approximate identity $e_\alpha$ in $A$ so that $\tau(e_\alpha)$ converges to a projection in $B$ . A retraction is additionally called faithful if $\tau(a)>0$ for all positive $a>0$ in $A$ . If $E$ is a Hilbert $A$ -module and $\tau: A\to B$ is a faithful retraction one can also give $E$ the structure of a Hilbert $B$ module via: $$x\cdot b := \lim_\alpha x\cdot e_\alpha \cdot b,\qquad \langle x,y\rangle_\tau := \tau(\langle x,y\rangle) \quad\text{for all $x,y\in E$, $b\in B$}.$$ Any adjointable map (wrt $\langle \cdot,\cdot\rangle$ ) $t:E\to E$ is also adjointable wrt $\langle\cdot,\cdot\rangle_\tau$ , giving a $*$ -morphism $$\pi_\tau:\mathcal L_A(E, \langle \cdot,\cdot\rangle)\to \mathcal L_B(E, \langle\cdot,\cdot\rangle_\tau),$$ $\pi_\tau$ is called the localisation of $\tau$ . In the above case of a faithful retraction this map is clearly injective. On page 58 of his book Lance remarks without comment that it is actually an isomorphism. Is the localisation $\pi_\tau$ also surjective for faithful $\tau$ ? I think a simple (finite dimensional) counter-example is possible, but the above book is quite well regarded and it would be strange to have such an error, so I do not trust my counter-example.","['c-star-algebras', 'hilbert-modules', 'operator-algebras', 'operator-theory', 'functional-analysis']"
3714069,Volume / measure of Minkowski sum $C+C$ (e.g. if $C$ is star-shaped),"Let $C \subset \Bbb R^d$ be a Lebesgue-measurable subset such that $C+C = \{x+y \mid  x,y\in C\}$ is measurable. What can we say about the measure (the volume) of $C+C$ ? I know that if $C$ is convex, then $C+C=2C$ , so $m(C+C)=2^d m(C)$ . Is this still true if $C$ is star-shaped , i.e. $[x,y] \subset C$ for every $x,\in C$ ? This is the most interesting case to me. (Some other questions are: What are some other sufficient conditions to have $m(C+C)=2^d m(C)$ ? I know that $2C \subset C+C$ so $2^d m(C) \leq m(C+C)$ always holds).","['convex-geometry', 'measure-theory', 'lebesgue-measure']"
3714221,"Weak formulation, Variational formulation, Solution of a PDE.","Ok, I'm struggling with some basic stuff. My question is: given a PDE are the concepts of a variational formulation and weak formulation the same? Take a PDE (letting $\phi : \mathbb{R}\to \mathbb{R}$ say convex) $$ 
\partial_t u(t,x)=-\nabla_x \phi(u(t,x)),\quad u(0,x)=u_{(0)}(x)\label{1}\tag{1}
$$ A strong solution $u:([0,T] \times \mathbb{R}^d) \to \mathbb{R}$ satisfies the above equation for all $t$ and $x$ . Upon multiplication by a test function $\psi$ and integration of \eqref{1} and moving the derivatives onto $\psi$ via integration by parts one can obtain the weak formulation. $\textbf{Question :}$ My question is sometimes instead of writing down the weak formulation of a PDE an author will claim it has an associated variational formulation, for instance see this book chapter , where Eq. $(1)$ is the PDE, and eq. $(5)$ is its variational formulation. What does a variational formulation mean? And where does it come from?","['calculus-of-variations', 'analysis', 'real-analysis', 'partial-differential-equations', 'convex-analysis']"
3714245,New norm with strictly coarser induced topolgy,"Let $(V,\|\cdot\|)$ be an infinite dimensional normed space. Does there alway exist a norm $|||\cdot|||$ on $V$ which induces a strictly coarser topology than $\|\cdot\|$ ? I know, that there is always a norm  which induces a strictly finer topolgy: We can  choose an unbounded linear functional $l:V\to\mathbb K$ and define a new norm as $\|\cdot\|+|l(\cdot)|$ . Then $$\text{Id}:(V,\|\cdot\|+|l(\cdot)|)\to(V,\|\cdot\|)$$ is bounded with unbounded inverse, so $\|\cdot\|+|l(\cdot)|$ induces a strictly finer topolgy. But what about the converse?","['topological-vector-spaces', 'normed-spaces', 'vector-spaces', 'functional-analysis']"
3714249,"Let $\{X_n\}$ be i.i.d $N(0,1)$ random variables. Show that $\limsup_{n\rightarrow\infty} \frac{|X_n|}{\sqrt{\log n}}=\sqrt2$ a.s.","Let $\{X_n\}_{n\ge1}$ be independent $N(0,1)$ random variables. Show that $$\limsup\limits_{n\to\infty} \frac{\left|X_n\right|}{\sqrt{\log(n)}}=\sqrt{2} \qquad \text{a.s.}$$ I aim to prove this using the fact that $$\limsup\limits_{n\to\infty} X_n = b \quad \iff \quad \text{for all } \varepsilon>0 \ : \ \Biggl\{ \begin{array}{l}
\mathbb{P}(X_n \le b+\varepsilon \text{ eventually})=1, \text{ and} \\
\mathbb{P}(X_n > b-\varepsilon\text{ i.o.})=1.
\end{array}$$ I show the first of these two conditions as follows: \begin{align*}
&\hspace{-2em}\mathbb{P}\left(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\right)\\
&= \mathbb{P}\bigl(|X_1|>(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}\bigr) & \text{as $X_n$'s are identically distributed}\\
&=\int_{(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}}^{\infty} |x|\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \, dx\\
&=\int_{(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}}^{\infty} x\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \, dx\\
&=\frac{1}{\sqrt{2\pi}}\int_{(\sqrt{2}+\varepsilon)^2\log(n)}^{\infty} e^{-u}du & \text{by making the substitution $u=\frac{x^2}{2}$}\\
&=-\frac{1}{\sqrt{2\pi}}\bigl[e^{-\infty}-e^{-\log(n)(\sqrt{2}+\varepsilon)^2}\bigr]\\
&=\frac{1}{\sqrt{2\pi}}n^{-(\sqrt{2}+\varepsilon)^2}
\end{align*} Thus, we have: \begin{align*}
\sum_{n=1}^\infty \mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\Biggr)&=\sum_{n=1}^{\infty}\frac{1}{\sqrt{2\pi}}n^{-(\sqrt{2} + \varepsilon)^2}\\
&<\infty \qquad \text{ since $\sqrt{2}+\varepsilon>1$}
\end{align*} So, by the Borelâ€“Cantelli Lemmas: \begin{align}
&\mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\text{ i.o.}\Biggr)=0\\
&\implies \mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} \le \sqrt{2} + \varepsilon\text{ eventually}\Biggr)=1
\end{align} It remains then to show that $$\mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} - \varepsilon \text{ i.o.}\Biggr)=1.$$ To do this, I would like to run a symmetric argument to the one above but here we need the final series to diverge which will happen if and only if $\sqrt{2}-\varepsilon \le1$ , which happens if and only if $\varepsilon\ge \sqrt{2}-1=0.414\ldots$ and so $\varepsilon$ is getting away from zero, which we can't have. Unless I am making a stupid mistake or missing something obvious, I don't see a way around this issue. Is this approach doomed to fail or is there a way to fix it up? Or is there just a better approach in general for such a problem. Thanks in advance. The problem is #1 (a) from this exam","['self-learning', 'probability-limit-theorems', 'probability-theory', 'probability']"
3714328,Why do absorbing Markov chains appear to violate the law of total expectation?,"Following up on two previous questions: Expected number of steps for reaching a specific absorbing state in an absorbing Markov chain and Expected time till absorption in specific state of a Markov chain Suppose you have an absorbing Markov chain with two absorbing states. You can calculate the probability of reaching either absorbing state, you can calculate the expected number of steps before being absorbed, you can construct a conditional matrix that removes an absorbing state, and you can calculate expected step count for that. For example, consider a minimal drunkard's walk with four states, A, B, C, and D, where A and D are absorbing. We have $$
P = \begin{bmatrix}0 && 0.5 && 0.5 && 0 \\ 0.5 && 0 && 0 && 0.5 \\ 0 && 0 && 1 && 0 \\ 0 && 0 && 0 && 1 \end{bmatrix}, N = \begin{bmatrix}4/3 && 2/3 \\ 2/3 && 4/3\end{bmatrix}, NR = \begin{bmatrix}2/3 && 1/3 \\ 1/3 && 2/3\end{bmatrix} 
$$ Or if we eliminate column three $$
P = \begin{bmatrix}0 && 1 && 0 \\ 0.5 && 0 && 0.5 \\ 0 && 0 && 1 \end{bmatrix}, N = \begin{bmatrix}2&&2\\1&&2\end{bmatrix}, NR = \begin{bmatrix}1\\1\end{bmatrix} 
$$ Skipping some of the other math, we eventually get P(reach A from B) = 2/3, P(reach D from B) = 1/3, E(steps starting from B) = 2, E(steps starting from B|end in A) = 3, and E(steps starting from B|end in D) = 4. But 2/3 * 3 + 1/3 * 4 is an expected 10/3 steps, not the 2 from the unconditional matrix. Is there something wrong about the conditional matrix logic? Or else why does this appear to violate the law of total expectation?","['statistics', 'markov-chains', 'probability']"
3714335,"If $u\in H^s$, is $v=u^2$ gaining or losing ""regularity""?","Let's consider a function $u\in H^s(\mathbb{R})$ for some $s\geq0$ , where $H^s$ denotes the standard $L^2$ -based Sobolev space. Now consider the function $v(x)=u^2(x)$ . I am wondering if $v(x)$ is gaining or losing regularity with respect to $u(x)$ . Specifically, I am wondering if $v\in H^m(\mathbb{R})$ with $m\geq s$ or $m\leq s$ ?. Is there any example of $u(x)$ such that $v(x)\notin H^s(\mathbb{R})$ ? Edit: Does the fact that $s\geq0$ plays any role in these kind of properties?","['analysis', 'partial-differential-equations']"
3714375,Proving $A - B \subset A - (B - A)$,"I believe I have been able to prove that for sets $A$ and $B$ , $A - (B - A) \supset A - B$ , but my proof is not particularly elegant. I was hoping someone knew of a more clever or straightforward way to show this. My proof is: Let $x \in A - B$ . Then $x \in A$ and $x \not \in B$ . So $x \not \in \{y \mid y \in B, \; y \not \in A    \}$ , so $x \not \in B - A$ . Since $x \in A$ and $x \not \in B-A$ , $x \in A - (B - A)$ , so $A - B \subset A - (B - A)$ .","['elementary-set-theory', 'proof-explanation', 'solution-verification']"
3714413,Making a vector field divergence-free,"I have a feeling that this is not true, but I'm not sure how to construct a counter-example. Given a non-vanishing smooth vector field $X$ on $\mathbb{R}^n$ , is there a positive smooth function $f$ such that the re-scaled vector field $fX$ is divergence-free? This involves solving the following PDE for $f$ , with coefficients depending on $X$ and its first derivatives: $$df(X) + f\text{div}(X) = 0.$$","['partial-differential-equations', 'differential-geometry', 'real-analysis']"
3714415,"Substitution with $a = x$, $b=\frac{y-x^2}{x} $ in differential equation gives me $ u = a \frac{\partial u}{\partial a} $ - Why?","If $$
\cases{a = x\\
b=\frac{y-x^2}{x}}
$$ and $$
x\frac{\partial u}{\partial x}+\left(y+x^2\right)\frac{\partial u}{\partial y}=u
$$ Why do we get $$
u = a \frac{\partial u}{\partial a}
$$","['substitution', 'derivatives']"
3714425,Euler-Lagrange-type equation for a more natural variational problem,"In mechanics, the application of Euler Lagrange equations always feels a bit odd to me as they are a necessary condition on extrema of functionals on trajectories with fixed endpoints. This is weird as there seems to be no reason to fix endpoints. I would propose the following as a more natural variational problem: Minimize $\int_a^b \mathscr{L}(t, x(t), x'(t))\, dt$ subject to $x(a) = x_0$ , $x'(a) = v_0$ . Hopefully we still get the Euler Lagrange equation as a necessary condition in this case, but I don't know of a proof. Can anyone give a literature reference or prove/disprove the conjecture that we get the Euler Lagrange equation?","['functional-analysis', 'mathematical-physics', 'calculus-of-variations']"
3714506,how to solve this inhomogeneous second order differential equation,"I want to solve this inhomogenenous differential equation of second order: $$ x''+2x'+x= \sqrt{t+1}e^{-t} $$ with initial conditions $ x(0)= \pi $ and $ x'(0)=  \sqrt{2} - \pi $ The solution is $ y= y_p+y_h $ , so the particular solution added with the homogenous solution. Because $ D:= 2^2-4 =0 $ the solution to the homogeneous part is $$ y(x)=(C_1+C_2x)e^{-x} $$ How do I solve the particular solution?",['ordinary-differential-equations']
3714516,Extension of a map holomorphic on the unit disk to map holomorphic on the complex plane,"I want to prove a statement regarding the holomorphic extension of a function holomorphic on the unit disk. Let $D \subset \mathbb{C}$ be the (open) unit disk and $f: \bar{D} \to
> \mathbb{C}$ be a continous map, such that $f$ restricted to $D$ is
  holomorphic and $|f(z)|=1$ for all $z \in \partial D$ . Show that $f$ can be extended to a function holomorphic on $\mathbb{C}$ up to
  finitely many isolated singularities, i.e. there are finitely many
  points $z_1,..., z_n \in \mathbb{C}$ and a holomorphic function $g:
 \mathbb{C} \setminus \{z_1,...,z_n \} \to \mathbb{C}$ such that $f=g$ on $D$ . Let $C_0=\partial D$ . Then $C_0$ is the unit circle. Consider $f|_D: D \to \mathbb{C}$ . Then $f|_D$ is holomorphic because $f$ is holomorphic. Let $K \subset C_0$ be a circular arc. Because $|f(z)|=1 $ for all $z \in \partial D$ it follows $f(K) \subset C_0$ . Let $\sigma_0$ be the inversion with respect to $C_0$ . Consider \begin{align*}
g: D \cup K \cup \sigma_0(D),  \ F(z)=\begin{cases}
f(z)                       & , \ z \in D          \\
\sigma_0(f(\sigma_0(z)))   & , \ z \in \sigma_0(G) \\
\sigma_0(f(\sigma_0(z)))   & , \ z \in K    
\end{cases}
\end{align*} Then $f(z)=\sigma_0(f(\sigma_0(z)))$ for all $z \in K$ . Because $f|_D$ can be extended to a function that is conitnous on $\bar{D}$ it follows from the Schwarz reflection principle that the function $g$ is holomorphic. The function $g$ has a singularity at $a \in \mathbb{C}$ if and only if $a\in \sigma_0(G)$ and $f(\sigma_0(a))=0$ . Define $S:=\{z \in \sigma_0(D) \ | \ f(\sigma_0(z))=0 \}$ . Then $S$ is the set of singularities of $g$ . Suppose that $S$ contains infinitely many elements. Because $\sigma_0$ is bijective it follows that there are infinitely many elements $z \in D$ such that $f(z)=0$ . Thus $f$ has infinitely many zeros. For every zero of order $m \geq 1$ there is a neighborhood and a holomorphic function $h$ such that $f(z)=(h(z))^m$ in that neighborhood. But I do not see how to proceed.",['complex-analysis']
3714524,Proving $A \cap (B - C) = (A \cap B) - (A \cap C)$,"I am trying to prove that $A \cap (B - C) = (A \cap B) - (A \cap C)$ using biconditionals, but I cannot seem to get the proof to work out. \begin{align*}
x \in A \cap (B - C) & \iff x \in A \text{ and } x \in B - C \\
& \iff x \in A \text{ and } (x \in B \text{ and } x \not \in C) \\
& \iff (x \in A \text{ and } x \in B) \text{ and } (x \in A \text{ and } x \not \in C) \\
& \iff x \in A \cap B \text{ and } x \in A - C \\
& \iff x \in (A \cap B) \cap (A-C).
\end{align*} I cannot figure out how to get from $(A \cap B) \cap (A - C)$ to $(A \cap B) - (A \cap C)$ .","['elementary-set-theory', 'proof-explanation']"
