question_id,title,body,tags
3283086,Covering of genus 2 of elliptic curve,"I am reading this paper and I get confused somewhere: https://link.springer.com/chapter/10.1007%2F978-1-4612-0457-2_7 So the set up is the following: Let $C$ be a genus 2 curve. Suppose $C$ admits a degree $n$ covering of elliptic curve $E_{1}$ over a field $K$ : $$\phi_{1}: C \to E_{1}$$ where $n$ prime to char $K$ . Assume there is no non tirivial unramified covering between $E_{1}$ and $C$ . Let $J$ be the jacobian of $C$ . Then there are induced maps by $\phi_{1}$ : $$\phi_{1}^{*}:E_{1} \to J$$ $$\phi_{1,*}:J \to E_{1}$$ (The authors didn't say how these maps work explicitly, my understanding of these two maps are: $\phi_{1}^{*}$ is the pullback from $E_{1}$ to $C^{n}$ and then map to $J$ ; $\phi_{1,*}$ maps $J$ to $C^{n}$ then each factor of $C^{n}$ maps to $E_{1}$ and add up in $E_{1}$ .) The author said that the maximality of $C \to E_{1}$ implies that $\phi_{1}$ is injective and that $ker(\phi_{1,*})$ is an elliptic curve $E_{2}^{*}$ (cf. Serre). Why this $\phi_{1}$ is injective? Isn't it a degree $n$ covering so one should expect $n$ preimages generically? The projection map $\phi_{2,*}: J \to J/E_{1}^{*}=:E_{2}$ induces a covering $$\phi_{2}:C \to E_{2}$$ of degree $n$ . And the map $$h:\phi_{1}^{*} \times \phi_{2}^{*}:E_{1} \times E_{2} \to J$$ is an isogeny of degree $n^{2}$ . Why it is of degree $n^{2}$ ? I've tried the sum of pullbacks but it looks not easy to find (explitcitly) the $n^{2}$ kernel. Anyone knows how this map works on elements? I very appreciate your help!","['algebraic-geometry', 'abelian-varieties']"
3283105,An easy way to solve this limit of a sum? [duplicate],"This question already has answers here : How can I evaluate $\sum_{n=0}^\infty(n+1)x^n$? (24 answers) Closed 4 years ago . $$\lim _{n\to\infty}\sum_{k=0}^n\frac{k+1}{10^k}$$ What I've tried is to create a function out of it in order to derivate it, but I am getting nowhere. I would like to know if there is an easier way to it (I would like a high school level method for this, if there is one).",['sequences-and-series']
3283121,Continuity of mean and quantile functionals,"We say the functional $\gamma$ is continuous if for all $\varepsilon>0$ and two cdfs $F$ and $G$ , there exists a $\delta>0$ such that $\|G-F\|_\infty=\sup_{t\in\mathbb{R}}|G(t)-F(t)|\leq\delta$ implies $|\gamma(G)-\gamma(F)|\leq\varepsilon$ . Now try to prove or disprove the continuity of mean and quatile functional, which are mean: $F\to\int xdF(x)$ ; quantile: $Q_{\alpha}(F)=\inf \{t\in\mathbb{R}|F(t)\geq \alpha\}$ . Intuitively, I think mean functional is continuous however I don't know how to bound the integral as it contains the derivative and then control it via the sup-norm $\|\cdot\|_\infty$ between $F$ and $G$ . While quantile seems to be more complicated and I wonder if there exist some tricks to transfer the definition to a more direct form with respect the the sup-norm. Thanks for the reading.:)","['statistics', 'probability-distributions', 'functional-analysis', 'probability']"
3283138,Why is this set empty?,"Consider for $S^2$ the map $\Phi: (0, \pi) \times (0, 2 \pi) \rightarrow  \mathbb{R^3} $ with $( \theta, \phi)) \rightarrow (\cos \phi \sin \theta, \sin \phi \sin \theta, \cos \theta) $ Why is $$ S^2 \setminus \Phi( (0, \pi) \times (0, 2 \pi))  $$ the empty set.","['elementary-set-theory', 'calculus', 'real-analysis']"
3283233,Olympiad Geometry | Homothety 2,"Two noncongruent circles intersect at $X$ and $Y$ . Their common (external) tangents intersect at $Z$ . One of the common tangents touches the circles at $P$ and $Q$ . Prove that $ZX$ is tangent to the circumcircle of triangle $PXQ$ . I let $M$ be a point that is the intersection of XZ and the smaller circle, connecting $Q$ and $M$ gives us trapezium $XMQP$ where $XP||MQ$ . But now I'm stuck what should I do next? I know I can move forward with angle chasing but I don't see how.","['contest-math', 'homothety', 'circles', 'geometry', 'geometric-transformation']"
3283257,Prove that two randomized algorithms approach the same expected value,"I am given two randomized algorithms $f$ and $g$ , that take as input a positive integer $m$ and produce a random non-negative integer. The algorithms are the same except that $g$ receives an small ""advantage"" with a very low probability. I need to prove or disprove that as $m$ grows, the two algorithms tend to behave the same. More concretely, if $h(m):=g(m)-f(m)$ , to show or refute that $$\lim_{m\to\infty} E[h(m)] = 0$$ But I'm stuck because the algorithm is a complex stochastic process. What methodologies can be used to formally prove that the hypothesis holds? Attachments : This is the algorithm. Arrays are 0-indexed, randint is inclusive and [0]*m means an array of m zeroes. def algorithm(m, advantage):
    h = [0] * m
    i = 1
    while i < m:
        if advantage and randint(0, m-1) == 0:
            prev = h[i-1]
        else:
            prev = h[i-1] - 1
        j = randint(0, i-1)
        h[i] = max(prev, h[j]+1)
        i += 1
    return h[m-1]

def f(m): return algorithm(m, advantage=False)
def g(m): return algorithm(m, advantage=True)
def h(m): return g(m) - f(m) And the plots of some Monte Carlo simulation plots, which show that the hypothesis might hold:","['stochastic-processes', 'statistics', 'algorithms']"
3283299,Contraction of indices of connection coefficients: Levi-Civita connection vs other connections,"I am wondering in what sense the formula of contraction of indices for the connection coefficients of the Levi-Civita connection (i.e. the Christoffel symbols) is valid for other connections. \begin{equation} \tag{1}
\Gamma ^{i}{}_{ki}={\frac {\partial \ln {\sqrt {|g|}}}{\partial x^{k}}}
\end{equation} My questions: Is (1) specifically valid for the Levi-Civita connection or does it also hold for other (metric) connections, maybe if they have certain properties like being torsion free?
(I learned that torsion-free is equivalent to the connection coefficients being symmetric in the lower indices, so I suspect it is crucial for (1) to hold.) Is there a more general contraction law for other connections (maybe with certain properties), e.g. (1) extended by some additional term?","['connections', 'riemannian-geometry', 'differential-geometry']"
3283303,Terence Tao uncountability of $\mathbb{R}$,There is a small detail I would like to understand. In the proof presented by Tao below: I don't understand why do we have the following cancellation: $\Sigma_{n < n_0 : n \in A} 10^{-n} - \Sigma_{n < n_0 : n \in B} 10^{-n}$ ? I mean we could have elements $n \in \mathbb{N}$ such that $n < n_0$ for which $n \in A - B$ or vice versa.,"['elementary-set-theory', 'real-analysis']"
3283348,"$\lim\limits_{h\to(0,0)}\frac{\sqrt[3]{h_1h_2+h_2+h_1+1}-1-\frac{h_1}{3}-\frac{h_2}{3}}{\sqrt{h_1^2+h_2^2}}$","I am trying to show that a function has a total derivative at $(1,1)$ but I got stuck trying to show $$\lim\limits_{h\to(0,0)}\frac{\sqrt[3]{h_1h_2+h_2+h_1+1}-1-\frac{h_1}{3}-\frac{h_2}{3}}{\sqrt{h_1^2+h_2^2}}=0$$ Where $h=(h_1,h_2)\in\mathbb{R}^2$ . Since $h$ approaches $(0,0)$ $h_1$ and $h_2$ have to approach $0$ aswell but I am relatively new to multivariable limits so I need some help.",['multivariable-calculus']
3283394,Kullback-Leibler divergence from mixture distribution to its components,"Suppose $f$ is the density of a mixture distribution with half the weight on a standard normal distribution and half the weight on a logistic distribution rescaled to have standard deviation $1$ . Now let $g$ be the density of the standard normal distribution and $h$ the distribution of this rescaled logistic distribution. Then $$g(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}$$ $$h(x) = \frac{\pi}{\sqrt{3}} \frac{e^{-\pi x/\sqrt{3}}}{(1+e^{-\pi x/\sqrt{3}})^2}$$ $$f(x) = \frac{1}{2}g(x) + \frac{1}{2}h(x).$$ I am wondering about the Kullback-Leibler divergences $KL(f, g)$ and $KL(f, h)$ . In particular, I'd like to know which one is smaller. I have simulated a time series from this mixture distribution and performed Bayesian model averaging on it, where I also included Gaussian and logistic models. In theory, I should end up with the posterior of the distribution with smallest divergence converging to 1, but it seems that the posteriors do not actually converge, even after a sample of $7500$ observations. Hence, this made me want to attack this problem analytically. Could it perhaps be that the divergences are equal or at least very close? I am struggling to calculate the divergences myself, since I either end up with a very nasty integral or a very nasty expectation. Could someone help me figure this out?","['statistics', 'bayesian', 'probability']"
3283405,Problem in solving questions with Algebra,"I was trying to solve a question: Income of A and B is 3:5 respectively and their expenditures are 1:5. If both saves $100 each. Then find their income? $$\frac{3x-y}{5x-5y}= \frac{100}{100}$$ $$300x - 100y = 500x - 500y$$ $$400y = 200x$$ $$\frac xy = \frac{200}{400}$$ 400 x 3 = 1200 400 x 5 = 2000 But that was wrong, and I asked my friend he said that two variables can't be in only single side. For eg. 2x + 4y =16 //can't be solved But  2x+4y=8y can be solved The Answer is: $$\frac {3x - 100}{5x - 100} = \frac {1}{5}$$ $$15x - 500 = 5x - 100$$ $$10x = 400$$ $$x = 40$$ 40 x 3 = 120 40 x 5 =200 I can now solve problem using the correct method, but i remember I have solved many questions which had two variables on one side and RHS no variable at all. For eg. a question:
Find the number that must be added to the terms of the ratio 7:13 to make it equal to 2:3 How I solved it: $$\frac{7x+y}{13x+y} = \frac{2}{3}$$ $$21x +3y = 26x +2y$$ $$Y = 5x$$ $$\frac yx = 5$$ $$y=5$$ And the answer is correct. Now, clearly I used the same method in the first problem but it didn't work why? EDIT: I added the answer using the correct method",['algebra-precalculus']
3283409,Is the structure morphism flat?,"Let $X$ be a smooth projective variety over $k$ . Variety here meaning a separated geometrically integral $k$ -scheme of finite type. Is the structure morphism $f : X \to \text{Spec}\;k$ flat? I guess this means we should check that for any $x \in X$ the induced map $f_x : k \to \mathcal O_{X,x}$ is flat, so for any $x \in X$ the stalk of the structure sheaf should be a flat $k$ -module. But then a $k$ -module is just a $k$ -vector space, which is always flat. Am I missing something?",['algebraic-geometry']
3283413,"Let $I=(y^2-x^2,y^2+x^2)$. Find $V(I)$ and $\text{dim}_{\mathbb{C}}(\mathbb{C}[x,y]/I)$","To find $V(I)$ we note that the only point $(x,y)\in \mathbb{C}$ satisfying both $y^2-x^2=0$ and $y^2+x^2=0$ is $(0,0)$ , so $V(I)=(0,0)$ . Now, to find $\text{dim}_{\mathbb{C}}(\mathbb{C}[x,y]/I)$ , we have the following relations: $$y^2-x^2\equiv 0 \mod I$$ $$y^2+x^2\equiv 0 \mod I$$ From where it follows that $y^2 \equiv 0 \mod I$ , and consequently $x^2\equiv 0 \mod I$ . From this, I understand that every monomial with degree 3 or more, like $xy^2$ for example, is $0$ . The polynomials in $\mathbb{C}[x,y]/I$ then are just a linear combination of $\lbrace 1,x,y,xy \rbrace $ , and so $\text{dim}_{\mathbb{C}}(\mathbb{C}[x,y]/I)=4$ . Is this correct? I would like to know a more general way of doing this, given that this felt like a very rudimentary approach, and only possible given that the ideal was very simple. If I had any other ideal generated by a couple of polynomials in $\mathbb{C}[x,y]$ , how could I find $\mathbb{C}[x,y]/I$ ? This is a problem from William Furton's Algebraic Curves, and I think the author's intention was for the student to find a most sophisticated approach.","['algebraic-curves', 'algebraic-geometry', 'polynomials', 'affine-varieties']"
3283436,"Show that $ P(A \cap B \mid A \cup B) \le P(A \cap B \mid A) $, where $A$ and $B$ are events and $P(A) > 0$","Show that if $A$ and $B$ are events and $P(A) > 0$ , then $P(A \cap B \mid A \cup B) \le P(A \cap B \mid A)$ . I have proceeded as follows: \begin{align}
& P(A \cap B \mid A \cup B)
\le P(A \cap B \mid A) \\
\iff & \frac{P((A \cap B) \cap (A \cup B))}{P(A \cup B)}
\le \frac{P((A \cap B) \cap A)}{P(A)} \\
\iff & \frac{P([(A \cap B) \cap A] \cup [(A \cap B) \cap B])}{P(A \cup B)} \le \frac{P(A \cap B)}{P(A)} \\
\iff & \frac{P((A \cap B) \cup (A \cap B)}{P(A \cup B)}
\le \frac{P(A \cap B)}{P(A)} \\
\iff & \frac{P(A \cap B)}{P(A \cup B)}
\le \frac{P(A \cap B)}{P(A)} \\
\iff & \frac{1}{P(A) + P(B) - P(A \cap B)}
\le \frac{1}{P(A)} \\
\iff & P(A)
\le P(A) + P(B) - P(A \cap B) \\
\iff & 0 \le P(B) - P(A \cap B) 
\end{align} which is obviously true. Also, I am dividing by $P(A \cap B)$ in the $5^{th}$ implication, since in the case that $P(A \cap B) = 0$ the inequality trivially holds true. I just wanted to verify the correctness of my work, and if, perhaps, there is a more succinct demonstration.","['elementary-set-theory', 'proof-verification', 'probability']"
3283440,How does one find the systole of the $2$-manifold?,"The minimal length of a non-contractible loop on a surface is known as the systole. I'm trying to find the systole of a $2$ -manifold. This $2$ -manifold is constructed by revolving the piece of the arc of $x^2+y^2=1$ passing through the unit square, and then making $3$ more copies of that surface of revolution and placing these $4$ copies inside a unit cube, such that all cusps touch the corners of the cube. The minimal non-contractible loops are highlighted in blue. My guess is that the systole can be found by finding the length of an equation of the form $x^4+y^4=k$ but I can't prove this. I perused the Wikipedia page on systolic geometry and it was helpful but I still couldn't get the answer. If someone can give me a few hints, I think I can figure it out.","['surfaces', 'geometry']"
3283452,Integral $\int_0^1\frac{\ln(1+x)}{1+x^2}\left(\frac{3\arctan x}{x}+2\ln x\right)dx$,"I was playing around with PARI GP to generate a challenging integral. The method:
The function lindep is intended to detect integer dependence. The constants used: $\text{G}\ln 2,\pi^3,\pi\ln^2 2,\ln^3 2,\pi^2\ln 2,\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx$ . All these numbers are of ""degree"" $3$ . To get a challenging integral you multiply, $\ln(1+x),\ln(1+x^2),\dfrac{1}{1+x^2},\arctan x,\dfrac{1}{1+x},\dfrac{1}{x}$ The idea is to sum up two integrals to cancel out the awful term $\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx$ After ten minutes, I have found: \begin{align}A&=\int_0^1 \frac{\ln x\ln(1+x)}{1+x^2}\,dx\\
&=-3\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx+...\\
B&=\int_0^1\frac{\ln(1+x)\arctan x}{x(1+x^2)}\,dx\\
&=2\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx+...\\
\end{align} Now, if you take $2A+3B$ you cancel out the term $\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx$ .
The result is: \begin{align}\int_0^1\frac{\ln(1+x)}{1+x^2}\left(\frac{3\arctan x}{x}+2\ln x\right)dx=\frac{5}{128}\pi^3-\frac{7}{4}\text{G}\ln 2+\frac{3}{16}\pi \ln^2 2\end{align} The question is: How to prove this? Addendum :
My first candidate for $B$ was: $\int_0^1\frac{\ln(1+x)\arctan x}{1+x^2}\,dx$ but it's not expressible as an integer linear combination of the chosen constants. Probably not related to constants of ""degree"" $3$ .
To decrease the ""degree"" i have multiply by $\dfrac{1}{x}$ and voilÃ  !","['integration', 'definite-integrals']"
3283477,Rank of Products of Matrices,"This is somewhat of a reference request. In several posts on the rank of products of matrices (e.g. Full-rank condition for product of two matrices ), it is stated that $$ \mathrm{rank}(AB) = \mathrm{rank}(B) - \dim \big(\mathrm{N}(A) \cap \mathrm{R}(B)\big)$$ It appears that this is a classic result, though I am not familiar with it. If anyone can point me to a textbook that discusses it and other rank inequalities, that would be much appreciated!","['matrix-rank', 'linear-algebra', 'reference-request']"
3283491,"The digital root of a tower of exponents, $d(\underset{\text{The number of }2 \text{'s is }2013}{\underbrace{2^{2^{2^{.^{.^{.^{2}}}}}}}})$","For a natural number $n$ , the digital root of $n$ is the value obtained by an iterative process of summing digits. The digital root of $n$ is denoted by $d(n)$ . Examples; $d(142)=7$ , $d(123785)=8$ In $2013$ , I attended a hard mathematical tournament. In this tournament, no one answered this question, and I am curious to know the key of solving it. Any help will be appreciated. If $d(n)=n-9\left \lfloor \frac{n-1}{9} \right \rfloor$ , find the
value of $$d(\underset{\text{The number of }2 \text{'s is
> }2013}{\underbrace{2^{2^{2^{.^{.^{.^{2}}}}}}}})$$","['ceiling-and-floor-functions', 'modular-arithmetic', 'number-theory', 'elementary-number-theory', 'power-towers']"
3283519,Conjectured formula for the Fabius function,"The Fabius function is the unique  function ${\bf F}:\mathbb R\to[-1, 1]$ satisfying the following conditions: a functionalâ€“integral equation $\require{action}
\require{enclose}{^{\texttip{\dagger}{a poet or philosopher could say ""it knows and replays its own future""}}}$ $\displaystyle{\bf F}(x)={\small\int_0^{2{\tiny\text{ }}x}}{\bf F}\left(t\right)dt,\,$ and a normalization condition ${\bf F}(1)=1.$ It is noteworthy that despite being smooth (class $C^\infty$ ) ${^{\texttip{\dagger}{i.e. continuous and having continuous derivatives of any order}}}$ everywhere, ${\bf F}(x)$ is not real-analytic at any point $x\ge0$ â€” its Taylor series there is either divergent , or a polynomial with a finite number of terms. ${^{\texttip{\dagger}{the latter happens at dyadic rational points}}}$ Unlike some other functions that appear specifically constructed for that purpose, the Fabius function naturally occurs in research of several seemingly unrelated problems â€” perhaps, this is why it has been discovered and re-discovered independently many times by several mathematicians. It also has some practical applications in computational mathematics. The Fabius function ${\bf F}(x)$ is constant $0$ for all $x\le0,$ but some authors prefer to define it only on $[0,\infty)$ or only on $[0,1].$ Some authors study a very closely related Rvachev ${^{\texttip{\dagger}{also variously spelled as RvachÃ«v or Rvachyov, a.k.a. ""atomic function""}}}$ function $\operatorname{up}(x)$ defined as $\operatorname{up}(x) = {\bf F}(x+1)$ for $-1\le x\le1$ and $\operatorname{up}(x) = 0$ otherwise. It is known that the Fabius function assumes rational values at dyadic rational arguments â€” efficient algorithms to compute those values have been published or posted online, and have been discussed on this site. $^{[1]}$ $\!^{[2]}$ $\!^{[3]}$ $\!^{[4]}$ $\!^{[5]}$ $\!^{[6]}$ $\!^{[7]}$ $\!^{[8]}$ $\!^{[9]}$ I have been looking for a non-recursive, self-contained formula for the Fabius function for quite a long time. After lots of experimentation and looking for patterns in its values I came up with a conjectured empirical formula. Let ${^{\texttip{\dagger}{the superscript ð‘š is just an index here, not to be confused with a power}}}$ $$\mathscr F^m_n = \frac1{2^{n^2}\left(\frac12;{\tiny\text{ }}\frac12\right)_n}\,\sum _{k=0}^n\frac{\binom n k_{1/2}}{2^{{\tiny\text{ }}k{\tiny\text{ }}(k-1)}(n+k)!}\,\sum _{\ell=0}^{2^k{\tiny\text{ }}m-1}\,(-1)^{s_2\left(\ell\right)}\,\left(\ell-2^km+\tfrac12\right)^{n+k}{\small,}\tag{$\small\spadesuit$}$$ where $k,\,\ell,\,m,\,n$ are non-negative integers, $\displaystyle\small\left(a;{\tiny\text{ }}q\right)_n=\prod_{k=0}^{n-1} (1-a{\tiny\text{ }}q^k)$ is the q -Pochhammer symbol ${^{\texttip{\dagger}{it assumes only rational values in this formula}}}$ , ${\binom n k}_q=\displaystyle\small\frac{\left(q;{\tiny\text{ }}q\right)_n}{\left(q;{\tiny\text{ }}q\right)_k\left(q;{\tiny\text{ }}q\right)_{n-k}}\vphantom{\Huge|}$ is the q -binomial coefficient ${^{\texttip{\dagger}{it assumes only rational values in this formula}}}$ , and $s_2(n)\vphantom{\Huge|}$ is the sum of binary digits ${^{\texttip{\dagger}{i.e. the number of 1's in the base-2 representation}}}$ of $n$ (note that $(-1)^{s_2\left(n\right)} = t_n\vphantom{\Huge|}$ is just the signed version of the Thueâ€“Morse sequence , satisfying recurrence $t_0 = 1,\,t_n = (-1)^n \, t_{\lfloor n/2\rfloor};\vphantom{\Huge|}$ see also ${^{[10]}}$ ${\!^{[11]}}$ ${\!^{[12]}}$ ). I conjecture that for all non-negative integers $m,\,n,$ the following identity holds: $${\bf F}\!\left({\small\frac m{2^n}}\right)=\mathscr F^m_n.\tag{$\small\diamondsuit$}$$ Note that there is no requirement for $\frac m{2^n}$ to be a proper irreducible fraction â€” it might well be that $m$ is even, or $m>2^n$ . I have not been able to rigorously prove it yet, but it produces exact rational values that agree with those computed using known correct algorithms for all dyadic rational arguments I have tried. Of course, this formula did not just appear out of the blue â€” its structure was inspired by known algorithms, and it went a long way to this relatively concise form (at some point it had about $5$ levels of nested summations/products). Can we prove that $\small(\diamondsuit)$ is indeed a correct representation of the Fabius function at dyadic rationals? If the conjecture is difficult to tackle at once, we can try to at least prove that the function defined by $\small(\spadesuit)$ shares some known properties with the Fabius function, e.g.: $0\le\mathscr F^m_n\le1,$ $\mathscr F^m_n = \mathscr F^{2{\tiny\text{ }}m}_{n+1}\vphantom{\Large|}$ â€” the result is the same across all representations of a rational number $\frac m{2^n}$ , $\mathscr F^m_n = 1-\mathscr F^{(2^n-m)}_n\vphantom{\Large|}$ for all $\small0\le m\le2^{n}$ â€” rotation symmetry, $\mathscr F^m_n = \mathscr F^{(2^{n+1}-m)}_n\vphantom{\Large|}$ for all $\small0\le m\le2^{n+1}$ â€” reflection symmetry, for a fixed $n,$ and $\small0\le m\le2^n$ the values of $\mathscr F^m_n\vphantom{\Large|}$ strictly increase, all points $\small\left(\frac m{2^n},\,\mathscr F^m_n\right)\vphantom{\Large|}$ lie on a continuous curve â€” for any convergent sequence of dyadic rationals $\frac m{2^n}\vphantom{\Large|}$ , the sequence of corresponding values $\mathscr F^m_n\vphantom{\Large|}$ also converges. If the conjecture $\small(\diamondsuit)$ it true, then for all $0\le x\le1$ (not necessary rational) $${\bf F}\!\left(x\right)=\lim_{n\to\infty}\,\frac1{2^{n^2}\left(\frac12;{\tiny\text{ }}\frac12\right)_n}\,\sum _{k=0}^n\frac{\binom n k_{1/2}}{2^{{\tiny\text{ }}k{\tiny\text{ }}(k-1)}(n+k)!}\,\sum _{\ell=0}^{\left\lfloor2^{n+k}{\tiny\text{ }}x-1\right\rfloor}\,(-1)^{s_2\left(\ell\right)}\,\left(\ell-2^{n+k}{\tiny\text{ }}x+\tfrac12\right)^{n+k}.\tag{$\small\heartsuit$}$$ For dyadic rational $x$ the limit is trivial, because the sequence under the limit becomes constant for large enough $n$ . Also, there is a known series (by Rvachev) that expresses values of the Fabius function for all $0\le x\le1$ via its values at negative powers of $2$ : $${\bf F}\!\left(x\right)=\sum _{n=1}^\infty\frac{(-1)^{\left\lfloor 2^n{\tiny\text{ }}x\right\rfloor }-1}{2}\,(-1)^{s_2\left(\lfloor2^n{\tiny\text{ }}x\rfloor\right)}\;\sum_{k=0}^n\frac{2^{\frac{k{\tiny\text{ }}(k+1)}2}}{k!}\,\left(x-2^{-n}\left\lfloor 2^n{\tiny\text{ }}x\right\rfloor\right)^k\;{\bf F}\!\left(2^{{\tiny\text{ }}k-n}\right).\tag{$\small\clubsuit$}$$ Again, for dyadic rational $x$ this series terminates after a finite number of terms, producing an exact rational value.","['conjectures', 'q-analogs', 'real-analysis', 'experimental-mathematics', 'sequences-and-series']"
3283552,Category of Banach spaces and bounded linear maps is not abelian,"Let $\mathbf{Ban}_{\infty}$ be the category of Banach spaces and bounded linear maps. I want to show that this category is not abelian. It is obviously additive, and every bounded linear map has kernels and cokernels in $\mathbf{Ban}_{\infty}$ . So I must show that the first isomorphism theorem doesn't hold in $\mathbf{Ban}_{\infty}$ (I'm using Bass definition of abelian category). For every $T \in \mathscr{L}(E,F)$ , the canonical morhpism is $$
 \begin{array}{rcl}
 \widetilde{T} \colon F/ker(T) & \longrightarrow & \overline{im(T)}\\
  \left[x\right] &\longmapsto & T(x)
\end{array}
 $$ $\widetilde{T}$ is mono and epi in $\mathbf{Ban}_{\infty}$ (in fact, this holds in any quasi-abelian category). Any idea to show that $\widetilde{T}$ is not an iso of $\mathbf{Ban}_{\infty}$ in general? Maybe it's easier to take any bounded linear map epi and mono that is not an iso of $\mathbf{Ban}_{\infty}$ : that can't happen in an abelian category. I don't care if you use another equivalent definition of abelian category (Peter Freyd's definition, for example), my goal is to show that $\mathbf{Ban}_{\infty}$ can't be abelian!","['abelian-categories', 'banach-spaces', 'functional-analysis', 'category-theory']"
3283559,Prove that the diophantine equation $2x^2-5y^2=7$ has no integer solutions.,"My attempt: I rewrote it as $2x^2=5y^2+7. 2x^2$ is always even, so in order for the RHS to be even, this means that $5y^2$ must be odd since an odd number plus $7$ is even. If I evaluate when y is odd, so if $y=2k+1$ for some integer $k$ , I get: $2x^2=20k^2+20k+12$ . This is the same as $x^2=10k^2+10k+6$ , which implies that $x^2$ is congruent $6$ (mod $10$ ). Here, I arrive at an issue because if $x=4$ , then I get that $x^2$ is congruent to $6$ (mod $10$ ), but I am supposed to show that the equation does not have a $6$ (mod $10$ ) congruency.","['number-theory', 'discrete-mathematics', 'diophantine-equations']"
3283623,Show that a function satisfies $|f(z)|<1$ for all $z$ in the open left half plane.,"I've been stuck in problem stating that Let $a>0$ .Show that the function $$f(z)=\dfrac{1+z+az^{2}}{1-z+az^{2}}$$ satisfies $|f(z)|<1$ for all $z$ in the open left half plane. Denote the open left half plane by $\mathbb{H}_{L}$ . Since this question deals with something on the $\mathbb{H}_{L}$ , the first idea for me was to use conformal mapping so that we can sort of connect the open $\mathbb{H}_{L}$ to $\mathbb{D}$ . However, the thing here is that we have no idea where $f(z)$ maps $\mathbb{H}_{L}$ to, so the I compose in the following way. Cleary the maps $$g:\mathbb{H}\longrightarrow\mathbb{H}_{L},\ \text{by}\ z\mapsto iz$$ and $$F:\mathbb{D}\longrightarrow\mathbb{H},\ \text{by}\ z\mapsto i\dfrac{1-z}{1+z}$$ are conformal. Then, I compose $f\circ g\circ F:\mathbb{D}\longrightarrow \text{unknown}$ . I hoped that the composition map would finally look like an automorphism of $\mathbb{D}$ . However, it seems impossible to get rid of the $z^{2}$ . On the other hand, I tried to compose as $$F^{-1}\circ g^{-1}:\mathbb{H}_{L}\longrightarrow\mathbb{D}, $$ which gives us a map $$z\mapsto\dfrac{1+z}{1-z}.$$ This one is closer to $f(z)$ except for there is no $az^{2}$ on either the numerator or the denominator. Currently I have no idea about how to proceed. Any idea or hints? Thank you!","['complex-analysis', 'complex-numbers']"
3283642,"If a rational map extends, is the extension unique?",Can a rational map of schemes $X\leadsto Y$ be extended to more than one morphism $X\rightarrow Y$ ?,"['algebraic-geometry', 'schemes']"
3283713,Probability Doubt about selection,"A bus contain 10 tickets 5 printed with 'I' and 5 printed with 'T', 3 tickets are drawn without Replacement and arrange in the same Order in which they are drawn on the table. Find the Probability that IIT is formed. 1st approach: $\frac{5}{10} \times\frac{4}{9}\times\frac{5}{8}= \frac{5}{36}$ 2nd Approach: $\left (\binom{5}{2}\times\binom{5}{1}  \right )/ \binom{10}{3}$ which is equal to 5/12 My doubt is why they aren't equal can you please explain the concept I missed in this question?","['combinations', 'probability']"
3283774,How to bound this integral with the Hardy-Littlewood maximal function,"Let $\Omega$ be a bounded Lipschitz domain in $\mathbb{R}^d$ and consider the following situation. $$\phi(x) = \int_{\partial \Omega} \frac{x-y}{|x-y|^d} f(y) d\sigma(y)$$ Where $\partial \Omega$ denotes the boundary of $\Omega$ and $\sigma$ denotes the surface measure. I want to show that the nontangential maximal function of $\phi$ is bounded on $L^p(\partial \Omega)$ when $f \in L^p(\partial \Omega)$ for $1 < p < \infty$ . To do so we look at the definition of the nontangential maximal function (denoted by $(\phi)^{*})$ . Let $P \in \partial \Omega$ denote a point on the boundary. Then $$ (\phi)^*(P) = \sup_{\substack{x \in \Omega \\ |x-P| < C_1 \operatorname{dist}(x,\partial \Omega)}} \left| \int_{\partial \Omega} \frac{x-y}{|x-y|^d} f(y) d\sigma(y) \right|$$ I have split the integral in multiple parts and managed to bound some of them by the maximal function of $f$ in $P$ . However I'm missing one part. I want to show that $$ \sup_{\substack{x \in \Omega \\ |x-P| < C_1\operatorname{dist}(x,\partial \Omega)}} \left| \int_{|P-y| > 2|P-x|} \frac{|P-y|}{|P-y|^d} f(y) d\sigma(y) \right|  \leq C_2 \mathcal{M}_{\partial \Omega}(f)(P)$$ With the maximal function defined as $$\mathcal{M}_{\partial \Omega}(f)(P) = \sup_{(B\cap \partial \Omega) \ni P}\frac{1}{\sigma\{B\cap \partial \Omega\}}\int_{B \cap \partial \Omega} |f(y)| d\sigma(y)$$","['harmonic-analysis', 'potential-theory', 'real-analysis']"
3283775,The notation $\frac{\partial}{\partial x}$,"In Jost's Riemannian Geometry and Geometric Analysis (Sect. 1.2, Chap. 1), the tangent space at a point $x_0$ in $\mathbb{R}^d$ is defined as $$T_{x_0}\mathbb R^d=\{x_0\}\times E$$ where $E$ is the vector space spanned by $\frac{\partial}{\partial x^1},\cdots,\frac{\partial}{\partial x^d}$ . Then the books says: ""Here, $\frac{\partial}{\partial x^1},\cdots,\frac{\partial}{\partial x^d}$ are the partial derivatives at the point $x_0$ ."" This is where I get confused. They are the partial derivatives of what? The only partial derivative I know is that of a function, but no function is given here. Sure, if one wants to argue that $\frac{\partial}{\partial x^1},\cdots,\frac{\partial}{\partial x^d}$ are just formal notations here that don't mean anything other than a formal basis of $E$ , then I can accept that even though I have doubts. But then there comes something that confuses me even more. If $f:\mathbb R^d\to\mathbb R^c$ is a differentiable map, then the derivative of $f$ at $x_0$ is defined to be (Einstein convention is used below) $$df(x_0):T_{x_0}\mathbb R^d\to T_{x_0}\mathbb{R}^c\\
\quad v^i\frac{\partial}{\partial x^i}\mapsto v^i\frac{\partial f^j}{\partial x^i}\frac{\partial}{\partial f^i}$$ So apparently $\frac{\partial}{\partial f^j}$ here depend on $f$ and are not arbitraily selected, so the notation cannot simply be a formal one, which brings me back to the original question: what does $\frac{\partial}{\partial x^i}$ and $\frac{\partial}{\partial f^j}$ mean?","['notation', 'multivariable-calculus', 'derivatives', 'differential-geometry']"
3283826,I need contacts to help me,Are there groups maybe here that will read a particular mathematics text at a certain pace and discuss the more difficult pages? I am struggling with Visual Complex Functions - by Wegert. Great if there was people who are reading this or have done that I could turn too for help.,['complex-analysis']
3283862,Pdf of joint independent random variables yield strange results,"I have the following problem: I want to compute the value of $<P_T>$ as a function of $P_L$ meaning $$ <P_T> = f(P_L) $$ Where $P_T = Psin(\theta)$ and $P_L = Pcos(\theta)$ . 
P has a uniform distribution in [0, 10] and so do $\theta$ in [0, 2 $\pi$ ]. For simplicity let's call $P\rightarrow x$ : $$f_X(x) = \begin{cases}\frac{1}{10} & x \in [0, 10] \\ 0 & otherwise \end{cases} $$ Now: $$f_\theta(\Theta) = \begin{cases}\frac{1}{2\pi} & \Theta \in [0, 2\pi] \\ 0 & otherwise \end{cases} $$ Let's now call $sin(\theta) \rightarrow y$ then, thanks to Jacobian formula: $$f_Y(y) = \begin{cases}\frac{1}{\pi\sqrt{(1-y^2)}} & y \in [-1,1] \\ 0 & otherwise \end{cases} $$ I want to compute the pdf of $P_T \rightarrow z = xy$ using the formula: $$f_Z(z) = \int_{-\infty}^{\infty} f_X(x)f_Y(\frac{z}{x})\frac{1}{|x|}dx $$ This means to me: $$f_Z(z) = \int_{0}^{10} \frac{1}{10\pi}\frac{1}{\sqrt{(1-\frac{z^2}{x^2}})}\frac{1}{|x|}dx = \frac{1}{10\pi} \big[log(\sqrt{x^2-z^2} + x)\big]_{x = 0}^{x = 10}$$ Now I have a problem meaning that for $x = 0$ the right hand side of the previous equation evaluates to: $$log(\sqrt{x^2-z^2} + x) |_{x=0} = log(\sqrt{-z^2}) $$ As $z=P_T$ takes real values in the range [0,10] I think that the formula is wrong but I can't find a way to make it right. Can someone spot the error? BTW to compute $<z>$ I thought of doing $<z> = \int zf_Z(z)dz$ hoping to find some dependence only on $P_L$ . That's why, with this reasoning I need the pdf of $z$ . Thank you everyone for your help.","['statistics', 'probability', 'probability-distributions', 'physics', 'mathematical-physics']"
3283914,what is the cardinality of the injective functuons from R to R?,"what is the cardinality of the injective functuons from R to R?
lets say A={he injective functuons from R to R}
obviously, A<= $2^×$ I have no Idea from which group I have to find an injective function to A to show (The Cantor-Schroeder-Bernstein theorem) that A=> $2^×$","['elementary-set-theory', 'cardinals']"
3283922,Composition of matrices - eigenvectors,"Say $\lambda$ is an eigenvalue of $\textsf{ST}$ . There exists $ð‘¥ \ne \textbf{0}$ such that $\textsf{ST}x=  \lambda x$ .
Multiply both sides by $\textsf T$ : $$\textsf{TST}x=\textsf{T} (\lambda x)$$ $$\textsf{TS}(\textsf{T}x)=\lambda(\textsf{T}x)$$ Thus $\textsf{T}x$ is an eigenvector for $\textsf{TS}$ . Why is there such a potent relation between the eigenvectors of $\textsf{ST}$ and $\textsf{TS}$ ? How come one is just the transform of the other? Looking for geometric/intuitive explanation.
Hints welcome.","['matrices', 'abstract-algebra', 'linear-algebra']"
3283938,Euler characteristic on torus,"I'm trying to compute $\chi(T^2)$ : I know that the sectional curvature of $T^2$ is $\dfrac{\cos(t)}{2+\cos(t)}$ with the parametrization: $F(t,s)=((2+\cos(t))\cos(s),(2+\cos(t))\sin(s),\sin(t))$ Now I want to compute $\int\limits_{T^2} K \ dx$ , where $K$ is the sectional curvature of the torus. Is that the correct approach? And how does this computation work?","['semi-riemannian-geometry', 'riemannian-geometry', 'algebraic-topology', 'differential-geometry']"
3283947,How to generate the shortest possible equation that has exactly one solution for specified integer?,"I'm basically trying to create a function that converts a positive integer n into an equation that has exactly one solution which can be computed back into the n . So if n = 1282388557824 the function should convert it to n = 264 ^ 5 since it's the shortest (or at least one of the shortest) equation and has only 1 solution. The function can use any mathematical operators that a computer can calculate. How would we even go about finding the shortest possible equation (or one of the shortest) without a slow brute-force? Any smart tricks we can use? Let's say we have n = 6415607 , then how can we quickly find that the shortest equation for it is (23 ^ 5) - (12 ^ 4) and not something short like 186 ^ 3 ? (it's not, it's just an example) It's fine if some of the integers cannot be compressed into an equation. There's 2 preferred conditions: The equation should be as short and as easy to compute as possible. For example, for n = 17 it should generate something like n = 2 ^ 4 + 1 Computation speed should not grow exponentially with integer length, the function should generate the equation relatively quickly, regardless of the integer's length. Let's say, something like under 0.1 ms for a 10 digit long integer and under 1 sec for a 100,000 digit long integer. It would be nice if you could write the answer in a form of a function written in any programming language. I understand the algorithms better this way, math language is often too hard for me.","['number-theory', 'abstract-algebra', 'logic', 'analysis']"
3283961,Derivative of matrix expression involving Kronecker products,"Given the matrix expression $C(f) = R  \left(  X f \otimes I \nonumber +I \otimes X f \right) X$ , where $R$ is $n\times n^2$ , $X$ is $n\times k$ , $f$ is $k\times 1$ and $I$ is an $n \times n$ identity matrix. What is $\frac{\partial C(f)}{\partial f}$ ? Thanks in advance!","['matrices', 'multivariable-calculus', 'derivatives', 'kronecker-product']"
3283965,Your friend has given you his list of 115 best Doctor Who episodes in order of greatness,"Your friend has given you his list of 115 best Doctor Who episodes (in
order of greatness). It turns out that you have seen 60 of them. Prove
that there are at least two episodes you have seen that are exactly four
episodes apart on your friendâ€™s list",['combinatorics']
3283966,Does a group of order $400$ always have a subgroup of order $200$?,"Does a group of order $400$ always have a subgroup of order $200$ ? I was considering some simple applications of Sylow theorems. I have made some questions. Among them, there was one which asks to prove that a group of order 200 always have a subgroup of order 100. This question has a simple solution since the Sylow group of order $25$ is unique and hence normal. After this, I became curious about the existence of normal subgroups of order $2^k p^l$ of groups of order $2^{k+1} p^l$ . The following two paragraphs are about my failed attempt which may not helpful. For a group of order $400$ , say $G$ , let $n_5$ be the number of Sylow group of order $25$ . If $n_5 =1$ , we are done. So suppose that $n_5 = 16$ . Let $A$ and $B$ be two Sylow subgroups of order $25$ . Analysing the number of elements in the set $AB$ , one can conclude that the order of $A \cap B$ to be $5$ . This forced $A \cap B$ to be normal subgroup in $A$ and $B$ . I was considered the normalizer $N(A \cap B)$ . For this should contain $A$ and $B$ , the order of $N(A \cap B)$ should be $200$ or $400$ . If it was $200$ , we are done. So suppose that for every pair of different Sylow groups of order $25$ $A$ and $B$ , $A \cap B$ is normal. If there occur two different intersections of order $5$ , we are done since the product of two such normal subgroups of order $5$ will provide a normal subgroup of order $25$ . The point I was stuck is there. Specifically, if a counterexample exists, it should have $16$ Sylow subgroups or order $25$ whose intersection is of order $5$ . The followings are just some consideration for generalization which may ""not even wrong"" Most generally, I'm curious about the condition of $n$ which forces to exist a subgroup of order $n$ of a group of order $2n$ .
Note that as all of you know, there are some groups of even order without having subgroups of index $2$ .
All simple groups of even order have this property since a subgroup of index $2$ is automatically normal.
Anyway, let me just state the general question. Find a simple criterion for a positive integer $n$ to have the property that every group of order $2n$ has a subgroup of index $2$ . Finally, thank you for your attention.","['finite-groups', 'normal-subgroups', 'abstract-algebra', 'sylow-theory', 'group-theory']"
3283973,Trouble justifying moving the limit inside the following integral,"The question is: Find the following limit $$\lim\limits_{\epsilon \rightarrow 0} \int_0^{\infty} \frac{\sin{x}}{x}\arctan{(\frac{x}{\epsilon})}dx$$ I know that if I can move the limit in the integral the arctangent will become $\frac{\pi}{2}$ and then the remaining problem is just the Dirichlet integral. However, I am having trouble justifying that step.","['limits', 'analysis']"
3283990,Derivative of a Rotation Matrix with changing rotation axis,"Just to introduce the background of this question: As many of you know a Rotation Matrix can transform a point $^{B}\textrm{p}$ described in a rotated Coordinate Frame {B} into the point $^{A}\textrm{p}$ described in the Coordinate Frame {A} by: $^{A}\textrm{p}$ = $^{A}\textrm{R}_B \ ^{B}\textrm{p}$ The Rotation Matrix's $^{A}\textrm{R}_B$ columns are the unit vectors of {B}'s axis described in Frame {A}. Also the Rotation about a given axis can be given by: $^{A}\textrm{R}_B$ = $e^{[\hat{w}]_x\theta}$ , whereas $[\hat{w}]_x$ is the skew-symmetric 3x3 matrix of the unit vector of $\hat{w}$ (deschribed in Frame A), around which the Frame is being rotated. $\theta$ is the rotation angle (and a scalar). Now my question:
Almost every book and paper i found states that the time-derivative of the Rotation Matrix is the following: $\frac{d}{dt}(^{A}\textrm{R}_B)$ = $[w]_x \  ^{A}\textrm{R}_B \qquad (1)$ Does the solution require that the direction of $\hat{w}$ remains constant at all times? Because if we use the chain rule on with a (1): $\frac{d}{dt}e^{[\hat{w}]_x\theta}$ = $\frac{d}{dt}([\hat{w}(t)]_x\theta(t)) \cdot e^{[\hat{w}]_x\theta}$ = $\frac{d}{dt}([\hat{w}(t)]_x)\theta(t) e^{[\hat{w}(t)]_x\theta(t)} + [\hat{w}(t)]_x)\dot{\theta}(t) e^{[\hat{w}(t)]_x\theta(t)}$ which can be further simplified to: $\frac{d}{dt}e^{[\hat{w}]_x\theta}$ = $(\frac{d}{dt}([\hat{w}(t)]_x)\theta(t)  + [w(t)]_x)^{A}\textrm{R}_B$ Whereas $[w(t)]_x=[\hat{w}(t)]_x\theta(t)$ Thus this is not equal to (1) and an addition term is generated. So which of these equations is true now, when the rotation is not being done around a constant axis? Or did i do something wrong? Greetings, 1lc","['matrices', 'linear-algebra', 'robotics']"
3283993,Integral $\int_0^1 \frac{dx}{\sqrt[3]{x(1-x)}(1-x(1-x))}$,"Prove, using elementary methods, that $$\int_0^1 \frac{dx}{\sqrt[3]{x(1-x)}(1-x(1-x))}=\frac{4\pi}{3\sqrt 3}$$ I have seen this integral in the following post , however all answers presented exploits complex analysis or heavy series. But according to mickep 's answer even the indefinite integral possess a primitive in terms of elementary functions. I'm not that insane to try and find that by hand, however it gives me great hope that we can find an elementary approach for the definite integral. Although I kept coming back to it for the past months, I still got no success, or relevant progress and I would appreciate some help.","['integration', 'alternative-proof', 'definite-integrals']"
3284018,"If $\int_ {0}^ \infty (\frac{ \sin x}{x})^3 = A$, then $\int_ {0}^ \infty \frac{ x- \sin x}{x^3} = ??$","If $\int_ {0}^ \infty (\frac{ \sin x}{x})^3 = A$ , then $\int_ {0}^ \infty \frac{ x- \sin x}{x^3} = k A $ . Find the value of k The main problem is how to get started as in the given integral , there is a term of $(\sin x)^3$ , where as in the integral to be computed , there is no cube. Please help :) Edit :I'm still in highschool so don't know how to compute this integral and that is why the first one was given","['integration', 'improper-integrals', 'definite-integrals']"
3284056,"Prove that for x in [0,1] the inequality..","Prove that for $x_i\in [0, 1],\,i=1,\dots,n$ , the following inequality holds: $$n+x_1x_2...x_n \geq 1+x_1+x_2+...+x_n$$ I have tried Bernoulli's inequality which says $(1+x_1)(1+x_2)...(1+x_n)\geq 1+x_1+x_2+...+x_n$ for $x_i>-1$ and $x_i$ with the same sign.","['multivariable-calculus', 'convexity-inequality']"
3284126,Is there a smaller set $S$ than $\mathbb Q$ that is dense in $\mathbb R$ ? And if such set exist does $S$ dense in $\mathbb Q$?,"I know that $\mathbb Q$ is dense in $\mathbb R$ and then $\mathbb Q$ is countable (so it's a quite small set). But is there a smaller set $S$ than $\mathbb Q$ s.t. $S$ is dense in $\mathbb R$ ? And if yes, does such a set is dense in $\mathbb Q$ ?",['elementary-set-theory']
3284133,"What's the difference between ""in"" and ""on""?","This may be just a grammatical question. I have seen the following two representations: This function is continuous in $D.$ This function is continuous on $D.$ Is there any difference between them?
I thought that ""in $D$ "" means the inside of $D$ while ""on $D$ "" contains its boundary, but
I have faced many exceptions. Could anyone explain the difference?
I would appreciate if you could tell me 
other cases where this kind of difference matters.","['functions', 'terminology']"
3284204,$bc(b-c) + ca(c-a) + ab(a-b) = -(b-c)(c-a)(a-b)$,"My book has used the equality $$bc(b-c) + ca(c-a) + ab(a-b) = -(b-c)(c-a)(a-b)$$ But its proof is not given. When I open the LHS, I get $b^2c-bc^2+c^2a-ca^2+a^2b-ab^2$ . I do not know how to proceed next.","['algebra-precalculus', 'factoring']"
3284218,"Combinatorial and Algebraic Topology: Brouwer Theorem, Sperner's Lemma and KKM lemma","I am studying some very basic fixed point theory and I bumped into this interesting Wikipedia table https://en.wikipedia.org/wiki/Sperner%27s_lemma#Equivalent_results . Here Sperner's Lemma, Brouwer Fixed Point Theorem, KMM lemma are presented as equivalent, and indeed I have read about this, moreover I know about the homotopy theory proof of Brower theorem. What I would like to learn about is the other equivalences anf relations presented in the table, but more in general about any other results and correspondences linking discrete, combinatorial, structures (such as simplicial subdivisions) and algebraic topology. Is there some general result ? Can the fundamental group or the homology group be seen as a means to give a discrete structure to the space? I beg pardon for having maybe formulated this question in a vague way, but I am just at the begininning. Finally any link to notes/references, especially if not too technical would be definetly appreciated.","['fixed-point-theorems', 'reference-request', 'discrete-mathematics', 'soft-question', 'algebraic-topology']"
3284279,Why is the cotangent bundle (phase space) usually defined to be the prototipic symplectic manifold?,"I've seen that in order to introduce the Hamiltonian approach to the analysis of a mechanical system, the notion of symplectic manifold and symplectomorphism are fundamental. Moreover, I've read a lot of references that define the cotangent bundle to be the perfect prototype of a symplectic manifold and hence endow it with the canonical 2-closed form $\omega=\sum_{i=1}^n dq_i\wedge dp_i$ . So my question is, why is the pair $(T^*Q,\omega)$ , defined in this way with $Q$ configuration manifold, so important from the point of view of Hamiltonian mechanics and Symplectic Geometry? I think I don't get even how such a 2-closed form $\omega$ is constructed starting from the local coordinates of the manifold $q_1,...,q_n$ and the projections between the various tangent and cotangent spaces. So if you can explain to me even that construction or reference me to a simple explanation it would be very helpful.","['symplectic-geometry', 'differential-geometry', 'classical-mechanics', 'symplectic-linear-algebra', 'dynamical-systems']"
3284320,Demystify the Hilbert Function,"Let $I \subseteq k[x_1,\dots,x_n]$ be an ideal for a field $k$ and let $A = k[x_1,\dots,x_n]/I$ . For $d \geq 0$ let $$ A_{\le d} := \{f + I : f \in k[x_1,\dots,x_n], \deg{f} \leq d \}.$$ The Hilbert function of $I$ is $$ h_I: \mathbb{N}_0 \to \mathbb{N}_0, \ h_I(d) = \dim_k(A_{\leq d}). $$ This object seems quite random (at least to me) at first but after some ""magic"" happens, it somehow turns out to have great properties. For instance, it's a polynomial $p_I$ for all sufficiently large $d$ and we get $\deg(p_I) = \dim(A)$ . This begs the question: Why? Why should we have expected $h_I$ to be nice? How did people (probably Hilbert?) conjecture these things?","['algebraic-geometry', 'hilbert-polynomial', 'commutative-algebra']"
3284323,Solve $3x(2+\sqrt{9x^2 + 3}) + (4x-2)(\sqrt{x^2 - x +1}+1) = 0$ for $x\in \mathbb{R}$,"Solve the equation in $ \mathbb{R}$ : $$3x(2+\sqrt{9x^2 + 3}) + (4x-2)(\sqrt{x^2 - x +1}+1) = 0$$ I've been tried to solve this question for  3 hours, but can't find out any answers. Just like I running in the maze, if I represent $\sqrt{9x^2 + 3} = A$ , $ \sqrt{x^{2}-x+1}= B$ Finally we've got $2A^{2} -15 = 18B^2 + 9\sqrt{4B^2 +1}$ , which is not help me to find relation between $A$ and $B$ anymore. I just wonder if we have a nice solution approaches to the problem. I appreciate any suggestion and help. Thank you.","['roots', 'analysis', 'functions', 'polynomials', 'algebra-precalculus']"
3284332,Systematic Way to find System of Parameters of Local Rings,"In Noetherian local rings $(R,\mathfrak{m})$ one can always find a system of parameters $a_1, \dots, a_n \in \mathfrak{m}$ , i.e. elements such that $$ \dim(R) = \min \left\{n \in \mathbb{N} : \exists a_1, \dots, a_n \in \mathfrak{m}: \mathfrak{m} = \sqrt{(a_1,\dots,a_n)} \right \}.$$ We had an exercise, where we were supposed to find a system of parameters. As an example, let $X = \{(x,y) \in \mathbb{C}^2 : xy = 0 \}$ . Then, we were supposed to find such a system for $\mathbb{C}[X]_{(0,0)}$ . It turns out that it's not too difficult to guess a solution ( $x+y$ does the job). However, is there a more systematic way?","['local-rings', 'algebraic-geometry', 'commutative-algebra', 'noetherian']"
3284374,The ApÃ©ry's constant and the Airy function,"Several weeks ago, while I was playing with a CAS, Wolfram Alpha online calculator I found the closed-form that provided this calculator for $$\int_0^\infty\operatorname{Ai}(x)\log^3(x)dx,\tag{1}$$ involving the Airy function $\operatorname{Ai}(x)$ , see this special function from the Wikipedia Airy function. But I don't know nor if it is in the literature neither nor any hint to get the corresponding indefinite integral (if it is feasible). Question. Do you know if the closed-form for $$\int_0^\infty\operatorname{Ai}(x)(\log(x))^3dx,\tag{1}$$ in terms of well-known constants and $\zeta(3)$ is in the literature? Provide the reference, and if I can I search it. In other case, can you provide an hint to calculate this kind of definite integral? Many thanks.","['integration', 'definite-integrals', 'special-functions']"
3284402,Powerful Integral $\int_0^x\frac{t\ln(1-t)}{1+t^2}\ dt$,"This integral can be found in Cornel's book, (Almost) Impossible Integral, Sums and Series page $97$ where he showed that $$\int_0^x\frac{t\ln(1-t)}{1+t^2}\ dt=\frac14\left(\frac12\ln^2(1+x^2)-2\operatorname{Li}_2(x)+\frac12\operatorname{Li}_2(-x^2)+\operatorname{Li}_2\left(\frac{2x}{1+x^2}\right)\right)$$ by differentiating $\operatorname{Li}_2\left(\frac{2x}{1+x^2}\right)$ then integrating back. How magical is that? My approach: \begin{align}
I&=\int_0^x\frac{t\ln(1-t)}{1+t^2}\ dt\overset{IBP}{=}\frac12\ln(1+x^2)\ln(1-x)+\frac12\int_0^x\frac{\ln(1+t^2)}{1-t}\ dt\\
&\overset{1-x=u}{=}\frac12\ln(1+x^2)\ln(1-x)-\frac12\int_{1}^{1-x}\frac{\ln(2+2u+u^2)}{u}\ du\\
&=\frac12\ln(1+x^2)\ln(1-x)-\Re\int_{1}^{1-x}\frac{\ln((1+i)-u)}{u}\ du
\end{align} and by using $\displaystyle\int \frac{\ln(a-x)}{x}\ dx=\ln(a)\ln x-\operatorname{Li}_2\left(\frac{x}{a}\right)\ $ , we get \begin{align}
I&=\frac12\ln(1+x^2)\ln(1-x)-\Re\left(\ln(1+i)\ln u-\operatorname{Li}_2\left(\frac{u}{1+i}\right)\right)_{u=1}^{u=1-x}\\
&=\frac12\ln(1+x^2)\ln(1-x)-\Re\left(\ln(1+i)\ln(1-x)-\operatorname{Li}_2\left(\frac{1-x}{1+i}\right)+\operatorname{Li}_2\left(\frac{1}{1+i}\right)\right)\\
&=\frac12\ln(1+x^2)\ln(1-x)+\frac12\ln2\ln(1-x)+\Re\operatorname{Li}_2\left(\frac{1-x}{1+i}\right)-\frac{\pi^2}{16}\\
&\boxed{=\frac12\ln\left(2(1+x^2)\right)\ln(1-x)+\Re\operatorname{Li}_2\left(\frac{1-x}{1+i}\right)-\frac{\pi^2}{16}}
\end{align} where I used $\ \Re\ln(1+i)=\frac12\ln2\ $ and $\ \Re\operatorname{Li}_2\left(\frac{1}{1+i}\right)=\frac{\pi^2}{16}$ . I tested my solution numerically and all is good but as we can see it does not match Cornel's answer. any idea how to make it match? Thanks, Its worth to mention that by comparing the two results proved above, we find the new interesting identity: $$\Re\operatorname{Li}_2\left(\frac{1-x}{1+i}\right)
=\frac14\left(\frac12\ln^2(1+x^2)-2\ln\left(2(1+x^2)\right)\ln(1-x)-2\operatorname{Li}_2(x)+\frac12\operatorname{Li}_2(-x^2)\\+\operatorname{Li}_2\left(\frac{2x}{1+x^2}\right)+\frac{\pi^2}{4}\right)$$","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'polylogarithm']"
3284451,Elementary (high school-level) estimate of the number of prime numbers,"Let $\pi(x)$ be a prime-counting function (the function counting the number of prime numbers less than or equal to some real number $x$ . For example $\pi(5)=3$ , $\pi(4)=2$ ). Prove by elementary (high school-level) methods that there is a function $f: \mathbb{N} \to \mathbb{R}$ and there is $N_0 \in \mathbb{N}$ such that for all $n \ge N_0$ the inequality $\pi(n) \ge f(n)$ holds and $\lim \limits_{n \to \infty} \frac{f(n)}{\sqrt{n}}=\infty$ . My work . Well known that $\pi(n) > \frac{n}{\ln n}$ . But the proof of this inequality is not elementary (high school-level). I searched, but did not find other estimate. For example, it would be a good idea to prove that $\pi(n) \ge n^{0.6}$ for all $n \ge N_0$ .","['contest-math', 'number-theory', 'prime-numbers']"
3284459,What are equations such as $dz = dx + dy$ called?,"These look like differential equations: $$dz = dx + dy,$$ $$dU = TdS - PdV,$$ and many other equations in physics, but they aren't ordinary differential equations or partial differential equations . What are they then?",['ordinary-differential-equations']
3284473,"Simple question about ""vacuous truth"".","In my homework there is an exercise that asks to show the following result: Let $(E,d)$ be a metric space. Show that a subset $A$ is dense in $E$ iff every open set in $(E,d)$ contains an element of $A$ . I was thinking in the case of the empty set. My question: "" $\emptyset$ contains an element of $A$ "" is false or is vacuously true? If it is false, then the necessary condition for the denseness of $A$ will always be false, because there will always be the (open) empty set in $E$ which does not contain any element of $A$ . In this case, logically, $A$ would never be a dense subset of $E$ . Is my argument right or am I going crazy? Thanks in advance.","['general-topology', 'logic', 'metric-spaces']"
3284475,Max mutual information with variance constraint,"Let $x_1$ and $x_2$ be two independent random variables with the same probability distribution $p(x)=p(x_1)=p(x_2)$ , and let $z$ be a normal random variable which is independent of $x_1$ and $x_2$ . Consider the following problem: $$\tag{1} \label{1}
\max_{p(x):\ \  \mathbb{E}[x^2]\le 1} I(x_1;x_1+x_2+z),
$$ where $I(\cdot;\cdot)$ denote the mutual information between two random variables. My question. Is it true that the optimal probability distribution $p(x)$ in \eqref{1} is Gaussian? If we consider $I(x_1;x_1+z)$ instead of $I(x_1;x_1+x_2+z)$ , then it is easy to show (using a maximum entropy argument) that the optimal distribution must be Gaussian. However it is not clear if a similar argument applies to my case. Any help is very appreciated. Thank you.","['entropy', 'probability-theory', 'information-theory']"
3284506,Derivatives Problem: Why is second term's coefficient less than zero?,"Problem: If $f(x)=cx^2+dx+e$ for the function shown in the graph, then what values can $c$ , $d$ , and $e$ take on? The answer is $c<0$ , $d<0$ , $e>0$ . I just don't understand why $d<0$ . Since the slope of $f(x)$ is always negative, $f'(x)<0$ and since $f'(x)=(2c)x+d$ , $(2c)x+d<0$ . Since $c<0$ , let's choose $c=-1$ , and let's choose $x=3$ . $(2)(-1)(3)+d<0$ which leads to $-6+d<0$ which leads to $d<6$ . And the maximum value (in this case 6) of this open inequality can change based on what $c$ and $x$ values are chosen. So where am I wrong?","['calculus', 'derivatives']"
3284527,A difficult double integral $\int_{0}^{1}\int_{0}^{1}\frac{x\ln x \ln y }{1-xy}\frac{dxdy}{\ln(xy)}$,How to evaluate $$\int_{0}^{1}\int_{0}^{1}\frac{x\ln x\ln y}{1-xy}\frac{dxdy}{\ln(xy)} ?$$ Any ideas on how to even start with this integral? It seems impossible to me. There's a similar integral that originates from this site .,"['integration', 'calculus', 'multiple-integral', 'definite-integrals']"
3284535,Trouble with the definition of the cross product,"Throughout the question, please keep in mind that I know very little differential geometry. I.e., just the intrinsic definitions of differentiable/Riemannian manifolds and the metric tensor, etc. I am trying to understand the definition of the cross product given by Wikipedia here: https://en.wikipedia.org/wiki/Cross_product#Index_notation_for_tensors The article says that we can define the cross product $c$ of two vectors $u$ , $v$ given a suitable ""dot product"" $\eta^{mi}$ as follows $c^m := \sum_{i=1}^3\sum_{j=1}^3\sum_{k=1}^3\eta^{mi}\epsilon_{ijk}u^jv^k$ To demonstrate my current understanding of this definition, I will introduce some notation and terminology. Then I will show where my confusion arises with an example. I do apologize in advance for the length of this post. Let $M$ be a smooth Riemannian manifold on $\mathbb{R}^3$ with the metric tensor $g$ . Pick a coordinate chart $(U,\phi)$ with $\phi$ a diffeomorphism. We define a collection $\beta = \{b_i:U \to TM | i\in\{1,2,3\}\}$ of vector fields, called coordinate vectors, as follows $b_i(x) := \Big(x,\big(\delta_x \circ \frac{\partial{\phi^{-1}}}{\partial{q_i}} \circ \phi\big)(x)\Big)$ where $\delta_x:\mathbb{R}^3 \to T_xM$ denotes the canonical bijection. The coordinate vectors induce a natural basis $\gamma_x$ at each point $x \in U$ for the tangent space $T_xM$ . Let $[g_x]_S$ denote the matrix representation of the metric tensor at the point $x$ in the standard basis for $T_xM$ and let $[g_x]_{\gamma_x}$ denote the matrix representation in the basis $\gamma_x$ . My understanding of the above definition of the cross product now follows. Let $u,v \in T_xM$ be tangent vectors and let $[u]_{\gamma_x}=\begin{bmatrix}
u_1\\
u_2\\
u_3
\end{bmatrix}$ $\space \space \space \space \space \space [v]_{\gamma_x}=\begin{bmatrix}
v_1\\
v_2\\
v_3
\end{bmatrix}$ denote the coordinates of $u,v$ in the basis $\gamma_x$ . Then we define the $m$ th coordinate of the cross product $u \times v \in T_xM$ in the basis $\gamma_x$ as $\big([u \times v]_{\gamma_x}\big)_m := \sum_{i=1}^3\sum_{j=1}^3\sum_{k=1}^3\big([g_x]_{\gamma_x}\big)_{mi}\epsilon_{ijk}u_jv_k$ Now I will demonstrate my apparent misunderstanding with an example. Let the manifold $M$ be the usual Riemannian manifold on $\mathbb{R}^3$ and let $\phi$ be given by $\phi(x_1,x_2,x_3) = (x_1,x_2,x_3-x_1^2-x_2^2)$ $\phi^{-1}(q_1,q_2,q_3)=(q_1,q_2,q_3+q_1^2+q_2^2)$ The Jacobian matrix $J$ of $\phi^{-1}$ is $J=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
2q_1 & 2q_2 & 1
\end{bmatrix}$ $\space \space \space \space \space \space J^{-1}=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
-2q_1 & -2q_2 & 1
\end{bmatrix}$ And the matrix representation of the metric tensor in the basis $\gamma_x$ is $[g_x]_{\gamma_x} = J^T[g_x]_SJ = \begin{bmatrix}
1+4q_1^2 & 4q_1q_2 & 2q_1 \\\
4q_1q_2 & 1+4q_2^2 & 2q_2 \\\
2q_1 & 2q_2 & 1
\end{bmatrix}$ Now choose $x=(1,1,-1)$ . The coordinates of $x$ are evidently $\phi(x) = (1,1,1)$ and the three matrices above become $J=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
2 & 2 & 1
\end{bmatrix}$ $\space \space \space \space \space \space J^{-1}=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
-2 & -2 & 1
\end{bmatrix}$ $\space \space \space \space \space \space [g_x]_{\gamma_x} = \begin{bmatrix}
5 & 4 & 2 \\\
4 & 5 & 2 \\\
2 & 2 & 1
\end{bmatrix}$ Now we compute the cross product in the basis $\gamma_x$ . Using my understanding of the definition as outlined above, I get $[u \times v]_{\gamma_x} = \begin{bmatrix}
36 \\\
35 \\\
16
\end{bmatrix}$ If we instead compute the cross product in the standard basis, then using my understanding of the definition, I get $[u \times v]_S = \begin{bmatrix}
0 \\\
-1 \\\
2
\end{bmatrix}$ Naturally, these results ought to agree if we perform a change of basis on $[u \times v]_{\gamma_x}$ . Doing just that, I get $[u \times v]_S = J[u \times v]_{\gamma_x} = \begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
2 & 2 & 1
\end{bmatrix} \begin{bmatrix}
36 \\\
35 \\\
16
\end{bmatrix} = \begin{bmatrix}
36 \\\
35 \\\
158
\end{bmatrix}$ Clearly, these do not agree. I can think of several reasons for this. Perhaps the definition given on Wikipedia is erroneous or only works for orthogonal coordinates. Perhaps I am misinterpreting the definition given on Wikipedia. Or maybe I have made an error somewhere in my calculation. My question is then as follows. How should I interpret the definition given on Wikipedia, and how should one express that definition using the notation provided here?","['coordinate-systems', 'cross-product', 'riemannian-geometry', 'differential-geometry']"
3284564,Constructing the identity element of a matrix algebra generated by a single matrix,"Setup : Let us define the matrix algebra $\mathcal{A}$ generated by a single self-adjoint matrix $M$ to be the span of all natural powers of $M$ (the matrix and the span are over complex numbers) $$\mathcal A :=\left<M\right>=span\{M,M^2,M^3...\}.$$ Question : Is there an element $I_\mathcal{A}\in\mathcal{A}$ that acts as the multiplicative identity on the elements of $\mathcal{A}$ ? Is there a constructive way to show it? Remarks : I know that when we have the identity matrix as part of the algebra $\left<I,M\right>$ the algebra is just the span of spectral projections (including the kernel projection) of $M$ . I expect the same to be true for $\left<M\right>$ (excluding the kernel projection) and the identity $I_\mathcal{A}$ to be just the sum of all the spectral projections. The problems start when I try to construct the spectral projections in $\left<M\right>$ without using the identity or construct the identity $I_\mathcal{A}$ without using the spectral projections (if I have one it is easy to construct the other). Thank you.","['matrices', 'von-neumann-algebras', 'linear-algebra', 'operator-algebras']"
3284590,Why is there zero holonomy around a geodesic?,"I'm reading about the Gauss-Bonnet theorem, and in the beginning of the section I'm studying I saw: Why is this true? I know this should be trivial but I'm not seeing it.",['differential-geometry']
3284638,Matrices with a certain property,"Suppose $A$ is a $n\times n$ matrix having the following properties $A$ is invertible all the entries in $A$ are either $-1$ , $0$ , or $1$ if a column has more than one non-zero entry, then the non-zero entries are strictly below the diagonal Suppose $A^{-1}$ has the same properties. Does it follow that every row and column in $A$ must contain exactly one entry which is $1$ or $-1$ ?","['matrices', 'linear-algebra', 'functional-analysis']"
3284665,Can $\mathbb{QÃ—Q}$ be embedded in $\mathbb{R}$ as group?,I think ans is NO : if possible let that is true hence there is a monomorphism from $H= \mathbb{QÃ—Q}$ to $\mathbb{R}$ .  as $\mathbb{R} $ has only subgroups which is cyclic or dense and $H$ is not cyclic hence dense but it's proper subgroup $\mathbb{ZÃ—Z}$ is neither cyclic nor  dense in $\mathbb{R}$ hence contradiction.  Hence the claim. Is my proof correct?? Thanks.,"['group-theory', 'abstract-algebra', 'solution-verification']"
3284682,Triangle law of vector addition,"I've been running my fingers through the internet and books probing why does the triangle law of vector addition works, but I've failed to find a satisfactory answer, rather, any answer at all, for that matter. Where ever the law is mentioned, they consider finding $R = âˆš(AÂ² + BÂ² + 2AB \cos\theta)$ and $\tan\alpha$ to be the proofs the law, however I am unable to understand why does the law work? Is there a mathematical proof that the third side of the triangle will always actually be the the sum of other two vectors? Why does the triangle law of vector addition work, at all?","['geometry', 'vectors']"
3284686,"Tenenbaum and Pollard, Ordinary Differential Equations, Exercise $3.2$(e)","I'm working through Exercise $3$ in Tenenbaum and Pollard's ODE book. The question is about determining whether functions are solutions to differential equations, and to state the interval where the differential equation makes sense. The part I'm stuck on is: $$\text{(e) }xy'=2y, \text{  } y=x^2$$ The actual calculation to demonstrate that this is true is simple enough. $$y'=2x\rightarrow xy'=2y\rightarrow 2x^2=2(x^2)\text{    }$$ However, the solution states that the interval where it makes sense is $x\neq 0$ , which is confusing to me. I don't understand why the interval isn't $-\infty<x<\infty$ , as neither the function nor the differential equation have any discontinuties at $x=0$ . Am I missing something, or is this a mistake in the solutions? Any input would be greatly appreciated.","['self-learning', 'ordinary-differential-equations']"
3284692,Proof that $X \subseteq Y$ if and only if $X \cup Y = Y$,"This exercise (2.1.49) was taken from An Infinite Descent into Pure Mathematics . Question Let $X, Y$ be sets. Prove that $X \subseteq Y$ if and only if $X \cup Y = Y$ . Proof Towards a contradiction, assume $X \not \subseteq Y$ if and only if $X \cup Y = Y$ . For $X \not \subseteq Y$ , then $X$ must be non-empty and contain a set of elements, $N$ such that $N$ is disjoint with $Y$ . Therefore, assume $X = \{x : x \in Y \vee x \in N\}$ . For $X \cup Y = Y$ , $N = \{\}$ . This is a contradiction with the assumption that $N$ is inhabited. Therefore, the assumption $X \subseteq Y$ if and only if $X \cup Y = Y$ cannot be true. We have shown that $X \subseteq Y$ if and only if $X \cup Y = Y$ . $\Box$ Is this proof rigorous enough, and are there any improvements that can be made?","['elementary-set-theory', 'proof-writing', 'proof-verification']"
3284703,"$I_n(t,a) = \int_0^\infty \frac{\cos(xt)}{\left(x^2 + a^2\right)^n}\:dx$","Spurred on by this , here I'm hoping to resolve the following integral: \begin{equation}
I_n(a,t) = \int_0^\infty \frac{\cos(xt)}{\left(x^2 + a^2\right)^n}\:dx
\end{equation} Where $a,t \in \mathbb{R}^+$ and $n \in \mathbb{N}$ . To begin with we observe that: \begin{equation}
I_n(a,t) =  \int_0^\infty \frac{\cos(xt)}{\left(a^2\left(\frac{x^2}{a^2} + 1\right)\right)^n}\:dx = \frac{1}{a^{2n}}  \int_0^\infty \frac{\cos(xt)}{\left(\left(\frac{x}{a}\right)^2 + 1\right)^n}\:dx
\end{equation} Let $u = \frac{x}{a}$ : \begin{align}
I_n(a,t) &= \frac{1}{a^{2n}} \int_0^\infty \frac{\cos(uat)}{\left(u^2 + 1\right)^n}\cdot a\:du = a^{1 - 2n}\int_0^\infty \frac{\cos(uat)}{\left(u^2 + 1\right)^n}\:du  \\
&=a^{1 - 2n}I_n(1, at)
\end{align} Thus, we need only resolve the following integral to solve $I_n(a,t)$ : \begin{equation}
J_n(s) = \int_0^\infty \frac{\cos(su)}{\left(u^2 + 1\right)^n}\:du
\end{equation} Noting $I_n(a,t) = J_n(at)$ . Here we will proceed by forming a differential equation for $J_n(s)$ . To do so, we employ Leibniz's Integral Rule and differentiate under the curve twice w.r.t $s$ : \begin{align}
\frac{d^2J_n}{ds^2} &= \int_0^\infty \frac{-u^2\cos(su)}{\left(u^2 + 1\right)^n}\:du = -\int_0^\infty \frac{\left(u^2 + 1 - 1\right)\cos(su)}{\left(u^2 + 1\right)^n}\:du \nonumber \\
&=-\left[\int_0^\infty \frac{\cos(su)}{\left(u^2 + 1\right)^{n - 1}}\:du -  \int_0^\infty \frac{\cos(su)}{\left(u^2 + 1\right)^n}\:du\right] \nonumber \\
&=-\left[J_{n - 1}(s) - J_n(s) \right] = J_n(s) - J_{n - 1}(s)
\end{align} Thus we form the recursive differential equation: \begin{equation}
\frac{d^2J_n}{ds^2}- J_n(s) = -J_{n - 1}(s)
\end{equation} In order for a solution to be obtained, the following is required: $I_1(s)$ , $I_n(0)$ , and $I_n'(0)$ . Thankfully these are all easy to obtain. Starting with $I_1(s)$ we find: \begin{equation}
I_n(s) = \frac{\pi}{2}e^{-s}
\end{equation} For $I_n(0)$ we have: \begin{equation}
I_n(0) = \int_0^\infty \frac{1}{\left(u^2 + 1\right)^n}\:du
\end{equation} Using the subsitution $u = \tan(w)$ we obtain a solution in terms of the Beta (and by extension Gamma) function: \begin{align}
I_n(0) &= \int_0^\frac{\pi}{2} \frac{1}{\left(\tan^2(w) + 1\right)^n}\cdot \sec^2(w)\:dw = \int_0^\frac{\pi}{2} \cos^{2n - 2}(w)\:dw \nonumber \\
&= \frac{1}{2}B\left( \frac{2n - 1}{2}, \frac{1}{2} \right) = \frac{1}{2}\frac{\Gamma\left(\frac{2n - 1}{2}\right)\Gamma\left( \frac{1}{2} \right)}{\Gamma\left(\frac{2n - 1}{2} + \frac{1}{2} \right)} = \frac{\sqrt{\pi}}{2}\frac{\Gamma\left(\frac{2n - 1}{2}\right)}{\Gamma(n)}
\end{align} For $I_n'(0)$ we have: \begin{equation}
I_n'(0) = \int_0^\infty \frac{-x\sin(x \cdot 0)}{\left(x^2 + 1\right)^n} = 0
\end{equation} Now, and here is where I'm unsure about my process - for our recursive differential equation we take the Laplace Transform: \begin{align}
\mathscr{L}_{s \rightarrow p}\left[ \frac{d^2J_n}{ds^2} \right] - \mathscr{L}_{s \rightarrow p}\left[J_n(s) \right] &= -\mathscr{L}_{s \rightarrow p}\left[ J_{n - 1}(s) \right] \nonumber \\
p^2 \overline{J}_n(p) - pJ_n(0) - J_n'(0) - \overline{J}_{n}(p) &= -\overline{J}_{n - 1}(p) \nonumber \\ 
\left(p^2 - 1\right)\overline{J}_n(p) &= pJ_n(0) -\overline{J}_{n - 1}(p)
\end{align} Thus, \begin{equation}
\overline{J}_n(p) = \frac{p}{p^2 - 1} J_n(0) - \frac{1}{p^2 - 1}\overline{J}_{n - 1}(p)
\end{equation} We now take the Inverse Laplace Transform: \begin{align}
\mathscr{L}_{p \rightarrow s}^{-1} \left[\overline{J}_n(p)\right] &= \mathscr{L}_{p \rightarrow s}^{-1} \left[\frac{p}{p^2 - 1}\right]J_n(0)  - \mathscr{L}_{p \rightarrow s}^{-1} \left[\frac{1}{p^2 - 1}\overline{J}_{n - 1}(p)\right] \nonumber \\
J_n(s) &= J_n(0)\cosh(s) - \int_0^s \sinh(s - a)J_{n - 1}(a)\:da \nonumber \\
 &= J_n(0)\cosh(s) - \int_0^s \left[\sinh(s)\cosh(a) - \sinh(a)\cosh(s)\right]J_{n - 1}(a)\:da \nonumber \\
&= J_n(0)\cosh(s) - \sinh(s)\int_0^s\cosh(a) J_{n - 1}(a)\:da \nonumber \\
&\quad+ \cosh(s)\int_0^2 \sinh(a)J_{n - 1}(a)\:da
\end{align} Now whilst we have a recursive integral form that governs $J_n(s)$ I am unsure how to solve it!. Does anyone have any pointers about how to move forward? Another approach (I believe) is to employ the linear D-operator. Here if we define $D = \frac{d}{ds}$ then our governing differential equation is given by: \begin{equation}
\left(D - 1\right)\left(D + 1\right)\left[ J_{n}(s)\right] = -J_{n - 1}(s)
\end{equation} Thus, \begin{equation}
J_n(s) = -\left(\left(D - 1\right)\left(D + 1\right)\right)^{-1}\left[ J_{n-1}(s)\right]
\end{equation} Which is my reasoning is correct implies that \begin{align}
J_n(s) &= (-1)^n \left(\left(D - 1\right)\left(D + 1\right)\right)^{-(n - 1)}\left[ J_1(s)\right] = (-1)^n \left(\left(D - 1\right)\left(D + 1\right)\right)^{-(n - 1)}\left[ \frac{\pi}{2}e^{-s}\right] \nonumber \\
&= (-1)^n \frac{\pi}{2} \left(\left(D - 1\right)\left(D + 1\right)\right)^{-(n - 1)}\left[ e^{-s}\right]
\end{align}","['integration', 'definite-integrals', 'laplace-transform', 'recursion', 'real-analysis']"
3284709,"If $q$ is prime, can $\sigma(q^{k-1})$ and $\sigma(q^k)/2$ be both squares when $q \equiv 1 \pmod 4$ and $k \equiv 1 \pmod 4$?","This is related to this earlier MSE question . In particular, it appears that there is already a proof for the equivalence $$\sigma(q^{k-1}) \text{ is a square } \iff k = 1.$$ Let $\sigma(x)$ denote the sum of divisors of the positive integer $x$ . Here is my question: If $q$ is prime, can $\sigma(q^{k-1})$ and $\sigma(q^k)/2$ be both squares when $q \equiv 1 \pmod 4$ and $k \equiv 1 \pmod 4$ ? MY ATTEMPT Suppose that $$\sigma(q^{k-1}) = a^2$$ and $$\frac{\sigma(q^k)}{2} = b^2$$ for $q \equiv 1 \pmod 4$ and $k \equiv 1 \pmod 4$ . Since $\sigma(q^k) = q^k + \sigma(q^{k-1})$ , it follows that $$2b^2 = \sigma(q^k) = q^k + \sigma(q^{k-1}) = q^k + a^2.$$ Additionally, congruence-wise we obtain $$a^2 = \sigma(q^{k-1}) \equiv 1 + (k-1) \equiv k \equiv 1 \pmod 4,$$ from which it follows that $a$ is odd, and $$2b^2 = \sigma(q^k) = q^k + \sigma(q^{k-1}) \equiv 1^1 + 1 \equiv 2 \pmod 4,$$ which implies that $b$ is likewise odd. Now, using the definition of $\sigma(q^k)$ and $\sigma(q^{k-1})$ for $q$ prime, we derive $$\frac{1}{2}\cdot\frac{q^{k+1} - 1}{q - 1} = b^2$$ and $$\frac{q^k - 1}{q - 1} = a^2.$$ Assume to the contrary that $$\frac{1}{2}\cdot\frac{q^{k+1} - 1}{q - 1} = b^2 \leq a^2 = \frac{q^k - 1}{q - 1}.$$ This assumption leads to $$q^{k+1} - 1 \leq 2(q^k - 1)$$ which implies that $$16 = {5^1}(5-2) + 1 \leq q^k(q - 2) + 1 = q^{k+1} - 2q^k + 1 \leq 0,$$ since $q$ is a prime satisfying $q \equiv k \equiv 1 \pmod 4$ .  This results in the contradiction $16 \leq 0$ .  Consequently, we conclude that $a < b$ . Furthermore, I know that $$(q+1) = \sigma(q) \mid \sigma(q^k) = 2b^2$$ so that $$\frac{q+1}{2} \leq b^2.$$ Finally, I also have $$\frac{q^{k+1} - 1}{2b^2} = q - 1 = \frac{q^k - 1}{a^2}.$$ Alas, here is where I get stuck. CONJECTURE (Open) If $q$ is a prime satisfying $q \equiv k \equiv 1 \pmod 4$ , then $\sigma(q^{k-1})$ and $\sigma(q^k)/2$ are both squares when $k = 1$ . SUMMARY OF RESULTS SO FAR zongxiangyi appears to have proven the implication $$\sigma(q^k)/2 \text{ is a square} \implies k = 1.$$ The proof of the following implication is trivial $$k = 1 \implies \sigma(q^{k-1}) \text{ is a square}.$$ The truth value of the following implication is currently unknown: $$\sigma(q^{k-1}) \text{ is a square} \implies k = 1.$$ Together, the two results give $$\sigma(q^k)/2 \text{ is a square} \implies k = 1 \iff \sigma(q^{k-1}) \text{ is a square},$$ so that $\sigma(q^{k-1})$ is a square if $\sigma(q^k)/2$ is a square . Therefore, $\sigma(q^{k-1})$ and $\sigma(q^k)/2$ are both squares (given $q \equiv 1 \pmod 4$ and $k \equiv 1 \pmod 4$ ) when $\sigma(q^k)/2$ is a square .","['conjectures', 'number-theory', 'elementary-number-theory', 'square-numbers', 'divisor-sum']"
3284731,Is the set of all characteristic functions on a set A equivalent to its power set P(A) [duplicate],This question already has an answer here : How can I form a bijection between $\mathcal P(A)$ and $2^A$. (1 answer) Closed 4 years ago . Recently I studied something known as characteristic function (Indicator function). After going through it deeply I want know if the set of all characteristic functions on A will be equivalent to its power set P(A)?,['elementary-set-theory']
3284768,Can every closed differential form be expressed via constant coefficients?,"Let $M$ be a smooth $n$ dimensional manifold, and let $1 \le k < n$ . Let $\omega \in \Omega^k(M)$ be a closed $k$ -form on $M$ . Let $p \in M$ . Do there exist coordinates around $p$ , such that $\omega=a_{i_1i_2\dots i_k}dx^{i_1} \wedge dx^{i_2} \dots \wedge dx^{i_k}$ , where $a_{i_1i_2\dots i_k}$ are constants ? That is, I ask whether every closed differential form be locally expressed via constant coefficients. Edit: I forgot to require that $\omega$ should be everywhere non-zero . Otherwise, as mentioned by Paulo MourÃ£o , one can take $xdx$ on $M=\mathbb{R}$ .","['linear-pde', 'partial-differential-equations', 'tensor-decomposition', 'differential-forms', 'differential-geometry']"
3284790,Why is $\log(f(z))$ entire if $f(z)\ne0$ and $f$ is entire? [duplicate],"This question already has answers here : $f$ is entire without any zeros then there is an entire function $g$ such that $f=e^g$ (1 answer) Where is the topology hiding in this theorem on entire functions? (1 answer) Closed 4 years ago . Let $f:\mathbb{C}\to\mathbb{C}\setminus\{0\}$ be an entire function. Why is $\log(f(z))$ entire? I don't understand the answer because if we have log with any branch $B=\{Re^{i\theta}:R\geq0\}$ , (and assume we choose for example the principal branch, $\theta=0$ ), then it may be that $f(z_0)\in B$ for some $z_0\ne0$ and then $\log(f(z_0))$ is not defined.","['complex-analysis', 'entire-functions', 'logarithms']"
3284793,On dual cones: $(K\cap L)^+\subseteq K^+ + L^+$,"I am trying to derive the conditions under which $(K\cap L)^+\subseteq K^+ + L^+$ where $K^+$ (and $L^+$ ) denotes the dual cone of convex cone $K$ (and $L$ ), and $K+L$ denotes the Minkowski sum of $K$ and $L$ . (I've read somewhere that the condition is $K\cap \textrm{int} L\neq \emptyset.$ ) To start off, suppose $x\in(K\cap L)^+ $ . Then, $\langle\ x, \phi\rangle \geq 0,\ \forall \phi\in K\cap L$ . In order for $x$ to be in $K^+ + L^+$ , it should be decomposable into $x=x_1+x_2$ such that $x_1\in K^+,\ x_2\in L^+$ . One way I can think of to find such a decomposition is to project $x $ on to $K^+$ and $L^+$ and (since dual cones are cones themselves) use appropriate scalars on the respective projections to get $x_1$ and $x_2$ such that their sum is equal to $x$ . For these projections to add up nicely to $x$ , I'm thinking that: either $x\in K^+ \cap  L^+$ or if $ x\notin K^+ \cap  L^+$ , $x$ should make an acute angle with the closest boundaries/faces of the dual cones. Where am I going wrong?","['geometry', 'abstract-algebra', 'linear-algebra', 'optimization', 'convex-analysis']"
3284861,Intuition/Significance of adjoint representation of a Lie group,"I understand the definition of the adjoint representation of a Lie group. But why is that important? In particular, why is it a natural choice of group representation?","['lie-algebras', 'intuition', 'group-theory', 'lie-groups', 'differential-geometry']"
3284875,How many 5-letter words can we make if the letters are in order?,"Using the $26$ English letters, the number of $5$ -letter words that can be made if the letters are distinct is determined as follows: $26P5=26\times25\times24\times23\times22=7893600$ different words. What if the letters in each word are in alphabetical order? For example, the word JLOQY is valid, but the word JUMPY is invalid since U can not be before M","['permutations', 'statistics', 'combinatorics', 'combinations']"
3284889,"Limit as $(x,y)$ approaches $(0,0)$ of $(1+x^2+y^2)^{\frac{1}{x^2+y^2+xy^2}}$","I have the function $$f(x,y)=(1+x^2+y^2)^{\frac{1}{x^2+y^2+xy^2}}$$ and I want to evaluate the limit as $(x,y)$ approaches zero. I have started thinking of a solution but get stuck.
Taking the direct limit is not possible since that would make an undefined function. Approaching $(0,0)$ from different lines e.g $y=x$ and $y=0$ both gives hints that the limit could be $e$ but that does not really show anything. 
I tried switching to polar coordinates which gives me $$(1+r^2)^{\frac{1}{r^2+r^3\cos(t)\sin^2(t)}}$$ Was it a good idea to switch to polar coordinates, can it be solved continuing with this approach, or could the function $f$ maybe be simplified and solved in a different way?","['limits', 'multivariable-calculus']"
3284892,A set $X$ containing 2 elements that are also subsets of $X$,"The question is pretty much summed up in the title.
I am taking an introductory Discrete Mathematics course and our teachers asked us to find a set $X$ containing only 2 elements where those elements are also subsets of X.
The teacher also said that there is a unique answer to this question, meaning there can't be more than 1 correct answer. $X = \{a, b\} \ : a \subset X, b \subset X$ An option I thought of is $X = \{\phi, Xâˆ \}$ (the 2nd element is the complement of X)
Is this correct? If not, what would be the correct answer?","['elementary-set-theory', 'discrete-mathematics']"
3284908,Find intersection of $|\cos(x)/2|$ and $|\arctan(x)|$,"I want to find the intersection for: $$\left|\frac{\cos(x)}{2}\right| = |\arctan(x)|, \  \forall x> 0$$ my attempt: I tried to find the value of $x$ as follows; $$\frac{\cos(x)}{2} = \frac{\cos(x)}{\sin(x)}$$ Then $$\frac{1}{\sin(x)} = \frac{1}{2}$$ $$\csc(x)=\frac{1}{2}$$ Then $x$ does not have any answer. 
Is it correct or I made a mistake?",['trigonometry']
3284915,Character Variety; why is it a variety?,"Let $\pi$ be a finitely generated group. Its character variety is defined as $$Ch(\pi) := \operatorname{Hom}(\pi ,\mathbb C^*) .$$ Why is this a variety? This can be generalised by replacing $\mathbb C^*$ , but I think it would be helpful for me to understand this example first. I noted, that $\operatorname{Hom}(\pi ,\mathbb C^*) = \operatorname{Hom}(\pi_{ab} ,\mathbb C^*) = (\mathbb C^*)^n \oplus T$ , wtih $T$ the torsion part. But still, why is this a variety? 
First of all, is it an affine or projective variety, and what are the defining polynomials?","['algebraic-geometry', 'group-theory', 'abstract-algebra', 'algebraic-groups']"
3284966,Determinants through dot products,"Thanks for reading! So, in Paulo Buchsbaum's answer to this question on Quora... https://www.quora.com/What-is-the-mathematical-intuition-behind-the-determinant-of-a-matrix-How-was-its-definition-conceived-and-why-is-it-important-What-does-it-mean-intuitively ...he defines a beautiful way to calculate the determinant of a matrix through dot products. One I hadn't seen before. He goes through the process of calculating this determinant for a $(3,3)$ matrix. I know this is a long request, but I was wondering if someone could take me through the process of doing it for a $(4,4)$ dimensional matrix, as (as you can see from my comment to his answer) I'm getting really confused. I would really appreciate it! Thank you! Edit: After reading @MatthewTowers comment (thanks), here is my explanation of what he's done for the $(3,3)$ case: Let's say we've got a $(3,3)$ matrix with a left column vector $\vec{a}$ , a middle column vector $\vec{b}$ , and a right column vector $\vec{c}$ . These three vectors create a parallelepiped. The volume of that parallelepiped is the determinant of the matrix. As you read, here's a picture (taken from Paulo's answer) for reference: Each vector has three components since they exist in three-dimensional space (aka the matrix has three rows) . $\vec{a} = \begin{bmatrix}a_1 \\ a_2 \\ a_3 \end{bmatrix} \vec{b} = \begin{bmatrix}b_1 \\ b_2 \\ b_3 \end{bmatrix} \vec{c} = \begin{bmatrix}c_1 \\ c_2 \\ c_3 \end{bmatrix}$ Note that $\vec{b}$ and $\vec{c}$ create a parallelogram. This parallelogram is the ""base"" of the parallelepiped created by all three column-vectors, and the component of $\vec{a}$ perpendicular to this parallelogram is the height of the parallelepiped. Let's ignore $\vec{a}$ for now. The first step is to find a vector $\vec{n}$ that's orthogonal to both $\vec{b}$ and $\vec{c}$ . We set $\vec{n} \bullet \vec{b}=0$ and $\vec{n} \bullet \vec{c}=0$ . Or, in other words, $n_1b_1 + n_2b_2 + n_3b_3 = 0$ and $n_1c_1 + n_2c_2 + n_3c_3 = 0$ That's three unknowns and only two equations. However, we can choose $n_1$ to be whatever we want, which allows us to solve for $\vec{n}$ . The second step is to find a vector $\vec{o}$ that's orthogonal to $\vec{b}$ and $\vec{n}$ . Notice that $\vec{o}$ will be in the same plane as $\vec{b}$ and $\vec{c}$ , but will be perpendicular to $\vec{b}$ . We set $\vec{o} \bullet \vec{b}=0$ and $\vec{o} \bullet \vec{n}=0$ . Once more, that gives us three unknowns and only two equations. However, we can choose $o_1$ to be whatever we want, which allows us to solve for $\vec{o}$ . We now set the magnitude of $\vec{o}$ to be equal to the magnitude of $\vec{b}$ . $\left \| \vec{o} \right \| := \left \| \vec{b} \right \|$ Note that this makes $\vec{o}$ a vector orthogonal to $\vec{b}$ but in the same plane as $\vec{b}$ and $\vec{c}$ , whose magnitude is the magnitude of $\vec{b}$ . If we take the dot product of $\vec{o}$ and $\vec{c}$ , that gives us the area of the parallelogram created by $\vec{b}$ and $\vec{c}$ . That's because $\vec{c} \bullet \vec{o}$ is the magnitude of the projection of $\vec{c}$ onto $\vec{o}$ multiplied by the magnitude of $\vec{o}$ . The projection of $\vec{c}$ onto $\vec{o}$ is the height of the parallelogram with $\vec{b}$ taken as the base, since $\vec{o}$ is orthogonal to $\vec{b}$ . And, the magnitude of $\vec{o}$ is equal to the magnitude of $\vec{b}$ . So, the dot product $\vec{c} \bullet \vec{o}$ is the height times the base, aka the area of the parallelogram created by $\vec{b}$ and $\vec{c}$ . Now, we set the magnitude of $\vec{n}$ equal to the area of that parallelogram. $\left \| \vec{n} \right \| :=  \vec{c} \bullet \vec{o} $ And finally, we compute $\vec{a} \bullet \vec{n} $ , and get the determinant of the matrix! Why does this last step work? For the same reason as the previous dot product - $\vec{n}$ is orthogonal to the parallelogram created by $\vec{b}$ and $\vec{c}$ . Taking the dot product of $\vec{a}$ and $\vec{n}$ is the same thing as taking the projection of $\vec{a}$ onto $\vec{n}$ and multiplying it by the magnitude of $\vec{n}$ . The projection of $\vec{a}$ onto $\vec{n}$ is the height of the parallelepiped, with the parallelogram created by $\vec{b}$ and $\vec{c}$ taken to be the base, and the magnitude of $\vec{n}$ is the area of the parallelogram, aka the area of the base. Once again, height times base equals volume. The volume of the parallelepiped is the determinant of the matrix! To conclude, I have two questions: I can see that what he's doing is getting a matrix with $n$ column vectors, calculating the cross-product of the last $n-1$ vectors, and then taking the dot product of the first vector with that cross product. However, how does this connect with the ""normal"" way to calculate determinants? Is there a way to derive the cross-product formula from his method? Secondly, if someone could just carry out the process for $n=4$ , I'd really appreciate it! I'm getting two equations with four unknowns... Thanks! Edit 2: This is just to show what I've done so far, in regards to my second question (the request for someone to take me through this guy's process for a $(4,4)$ matrix) : Calculate $det(\vec{a},\vec{b},\vec{c},\vec{d})$ Take out the $\vec{a}$ , and calculate $det(\vec{b},\vec{c},\vec{d})$ To do so, we take out the $\vec{b}$ , and calculate $det(\vec{c},\vec{d})$ To do so, we declare an $\vec{n}$ such that $\vec{n} \bullet \vec{c} = 0$ and $\vec{n} \bullet \vec{d} = 0$ . In other words, $\vec{n}$ is orthogonal to the parallelogram created by $\vec{c}$ and $\vec{d}$ . (And hereâ€™s where I'm stuckâ€¦should $\vec{n}$ be orthogonal to $\vec{a}$ as well? Right now, I have two equations, but four unknowns, and Iâ€™m not sure what to doâ€¦","['determinant', 'linear-algebra', 'vectors', 'intuition']"
3284971,Does flat and locally free on the fibres imply locally free on the total space?,"Let $Z$ and $Y$ be complex analytic spaces, and let $p : Z \to Y$ be a surjective proper morphism, which is flat. Let $\mathcal{F}$ be a coherent sheaf on $Z$ , flat over $Y$ , whose restriction to each fibre $p^{-1}(y)$ of the morphism is an invertible sheaf. Does this imply that $\mathcal{F}$ itself is invertible (i.e. locally free of rank 1) as a sheaf on $Z$ ? More generally, if $\mathcal{F}$ is locally free on the fibres, does it imply that it is locally free on the total space $Z$ ? If this does not hold in full generality, what about the special case when $Z = X \times Y$ , where $X$ is a compact complex manifold, and $p : X \times Y \to Y$ is the usual projection?","['complex-geometry', 'algebraic-geometry', 'flatness']"
3284975,"Minimize $\frac{\int_0^1 f(x)\phi''(x)\phi''(x)\,\text{d}x} {\int_0^1 g(x) \phi'(x)\phi'(x)\,\text{d}x}$","Below is a situation I came across during solving problems using energy method in mechanics. I have formulated it in question form, omitting details I think are unnecessary. Question: Given positive continuous diffenertiable functions $f(x)$ and $g(x)$ , find non-trivial $\phi(x)$ that minimizes the functional $F$ : $$
F[\phi,\phi',\phi'';x]=
\frac{\displaystyle\int_0^1 f(x)\phi''(x)\phi''(x)\,\text{d}x}
{\displaystyle\int_0^1 g(x) \phi'(x)\phi'(x)\,\text{d}x}
$$ with boundary conditions $\phi(0)=\phi''(0)=\phi(1)=\phi''(1)=0$ . For $f(x)=1$ and $g(x)=1$ , prove that $\phi(x)=C\sin(\pi x)$ , where $C$ is arbitrary constant, minimizes $F$ . For $f(x)=1$ and $g(x) = x$ , find $\phi(x)$ . For general $f(x)$ and $g(x)$ , find $\phi(x)$ . Comments One source claims that the functional $F$ is called the Rayleigh-Ritz quotient. Some special cases of the original problem can be solved exactly from differential equation, so there is some information regarding the expected solution: For $f(x)=1$ and $g(x)=1$ , the function $\phi(x)=C\sin(\pi x)$ corresponds to the exact solution, but not proven in terms of minimizing the functional $F$ . For $f(x)=1$ and $g(x)=x$ , a similar case with different boundary condition has the exact solution $\phi(x)$ in the form of Bessel function of the first kind $J_{-1/3}$ . Physically I believe Bessel function should also be the solution form in this case, but mathematically I am not sure. For general $f(x)$ and $g(x)$ , we normally resort to numerical methods such as finite element, because we believe that the closed-form solution is not possible. Here I am asking merely for curiosity. Would it be possible to express $\phi(x)$ in some form, such as using infinite series or special functions? May be imposing certain conditions for $f(x)$ and $g(x)$ ? Sorry for being vague, I can add more information if required. Edited: 2019-07-07 I would like to add the numerical results for case 2 where $f(x)=1$ and $g(x)=x$ . The mode shape $\phi(x)$ is expressed in power series: $$\phi(x)=a_0+a_1 x+a_2 x^2+\cdots + a_n x^n + \cdots$$ where $$a_0=0,\quad a_1=1,\quad a_2=0,\quad a_3\approx -0.7272$$ $$a_{3n+1}=\frac{(-1)^n\xi^n}{(3n+1)!}\prod_{k=1}^n (3k-2),\quad n\ge 1$$ $$a_{3n+2}=0,\quad n\ge 1$$ $$a_{3n+3}=-6a_3\frac{(-1)^n\xi^n}{(3n+3)!}\prod_{k=1}^n (3k),\quad n\ge 1$$ $$\xi \approx 18.5687 $$ The functional $F$ is calculated as $$F=\xi\approx 18.5687$$ It seems that my physical belief is wrong: the shape of $\phi(x)$ is not like a Bessel function, and not even symmetrical on domain $[0,1].$ For comparison, if $\phi(x)=\sin(\pi x)$ , then $F=2\pi^2\approx1 9.7392.$","['integration', 'optimization', 'calculus-of-variations']"
3284978,Generalized Behrend version for Grothendieck-Lefschetz trace formula,"The statement of the Grothendieck-Lefschetz fixed point theorem is well-known. For a proper algebraic variety $X$ over $\mathbb F_q$ , $$\#X(\mathbb F_q) =\sum_i (âˆ’1)^i Tr(Fr_X, H^i_c(X, \mathbb Q_l)).$$ Also known is the version for general constructible l-adic sheaves $\mathcal F$ : $$\sum_{x\in X(\mathbb F_q)} Tr(Fr_x,\mathcal F_x)=\sum_i (âˆ’1)^i Tr(Fr_X, H^i_c(X, \mathcal F)).$$ Thirdly, K. Behrend proved an analog for the first formula in the context of algebraic stacks (replacing the scheme $X$ by a Noetherian algebraic stack $\mathcal X$ ). Now my question is: is there a version of the second formula for an
  algebraic stack $\mathcal X$ (with nice hypotheses if necessary)? It would seem natural, since the second formula is a generalization of the first, and the first is true in the context of algebraic stacks by Behrend's work. However, the second formula does not follow directly from the first in the case of schemes (as far as I know: I would be glad if it were true!), so I am not in the position to easily extend the proof of the second formula in the more general context of stacks. Thank you in advance.","['etale-cohomology', 'algebraic-stacks', 'algebraic-geometry', 'trace-map']"
3284981,Solve for $(5x-1)(x-3)<0$,"The inequality $(5x-1)(x-3)<0$ is true when $(5x-1)<0$ and $(x-3)>0$ or $(5x-1)>0$ and $(x-3)<0$ . If I solve for $x $ in the first scenario, $x < \frac{1}{5}$ and $x > 3$ which is wrong. But if I solve for $x$ in the second scenario, $x > \frac{1}{5}$ and $x < 3$ which is correct. Why is such kind of contradiction occurring in the first scenario?","['algebra-precalculus', 'inequality']"
3285017,Representation of $x \bmod a$ with Trigonometric Functions,"After fidgeting around with the compositions of trigonometric functions and inverses of them, I realized that the following function gives a graph strongly resembling a sawtooth wave (you can check from desmos.com or a graphing calculator): $$ f(x) = \arctan(\cot(x))$$ This function has a period of $\pi$ , an amplitude of $\frac \pi 2$ , and a constant negative slope, so with the help of transformations, we can turn it into a function with a period and amplitude of $a$ as follows: $$ f(x) = \frac a 2 - \frac {a \arctan(\cot(\frac {\pi x} a))} \pi$$ If looked carefully at this function, for all $x,a \in \mathbb{Z}$ , it is exactly the same as the function $g(x) = x \bmod a$ . To give an example, if we let a be 4: $$ f(6) =  2 - \frac {4 \arctan(\cot(\frac {6 \pi} 4))} \pi = 2 - \frac a \pi \arctan(0) = 2 $$ $$ g(6) = 6 \bmod 4 = 2$$ $$ f(6) = g(6) =
 2$$ My question is about the usefulness of this fact. What could be some applications of this identity, if any? Would it be of any use when dealing with modular arithmetic or trigonometric functions?","['trigonometry', 'modular-arithmetic']"
3285030,Is every $2$-generated simple group $\frac{3}{2}$-generated?,"Letâ€™s call a group $\frac{3}{2}$ -generated iff for every $g \in G \setminus \{1\}$ there is some $h \in G \setminus \langle g \rangle$ with $G = \langle g,h \rangle$ . Is every $2$ -generated simple group $\frac{3}{2}$ -generated? This happens to be true for finite simple groups and for Tarski monster groups, but is it true in general? I do not know how to prove that, but neither do I know any counterexamples.","['finitely-generated', 'group-theory', 'abstract-algebra', 'simple-groups']"
3285032,Center of wreath product $\mathbb{Z_n} \wr \mathbb{Z_m}$ and $\mathbb{S_m} \wr \mathbb{Z_n}$,"I have a problem with calculate center of wreath products $\mathbb{Z_n} \wr \mathbb{Z_m}$ and $\mathbb{S_m} \wr \mathbb{Z_n}$ . I was trying to write definitions and try do calculate something, but I don't have any idea how to do it. Could someone help me with some ideas?","['group-theory', 'abstract-algebra']"
3285046,Integral $\int_{0}^{\pi/3}\ln^4\left(\frac{\sin x}{\sin(x+\pi/3)}\right)dx$,Calculate $$\int_{0}^{\pi/3}\ln^4\left(\frac{\sin x}{\sin(x+\pi/3)}\right)\mathrm dx$$ My try: $$\sin(x+\pi/3)=\sin x\cos(\pi/3)+\sin(x+\pi/3)\cos x=\frac{1}{2}\sin x+\frac{\sqrt{3}}{2}\cos x$$ $$\int_{0}^{\pi/3}\ln^4\left(\frac{2\sin x}{\sin x+\sqrt{3}\cos x}\right)\mathrm dx$$ $$\int_{0}^{\pi/3}\ln^4\left(\frac{2}{1+\sqrt{3}\cot x}\right)\mathrm dx$$ $u=\frac{2}{1+\sqrt{3}\cot x}$ $u^{'}=\frac{2\sqrt{3}}{\sin^2 x(1+\sqrt{3}\cot x)^2}$ $$\frac{1}{2\sqrt{3}}\int_{0}^{1}\sin^2 x(1+\sqrt{3}\cot x)^2\ln^4(u)\mathrm du$$ $$\frac{2}{\sqrt{3}}\int_{0}^{1}\sin^2 x u^{-2}\ln^4(u)\mathrm du$$ $\cot^2 x=\frac{(2-u)^2}{3u^2}$ using $1+\cot^2 x=\frac{1}{\sin^2 x}$ $$\frac{2}{\sqrt{3}}\int_{0}^{1}\frac{3u^{2}}{3u^2+(2-u)^2} u^{-2}\ln^4(u)\mathrm du$$ $$\frac{6}{\sqrt{3}}\int_{0}^{1}\frac{1}{3u^2+(2-u)^2}\ln^4(u)\mathrm du$$ $$\frac{3}{\sqrt{3}}\int_{0}^{1}\frac{1}{u^2-u+1}\ln^4(u)\mathrm du$$ I am not sure what to do next...,"['integration', 'definite-integrals']"
3285081,Upper Triangular and Diagonal Matrices,"I'm trying to understand the difference between Upper Triangular and Diagonal Matrices for square matrices. There is a theorem that says every matrix can be made into an upper triangular matrix. Now if my matrix as the same number of eigenvectors as its dimension then I can make a Diagonal matrix by changing the basis to the eigenspace. So in this case, why will I ever prefer to make a matrix Upper Triangular(and not diagonal)  when I can make it diagonal?","['matrices', 'diagonalization', 'abstract-algebra', 'linear-algebra']"
3285175,Verifying a property about ordered pairs: Terence Tao - Analysis I,"So I was doing the exercise for section 3.5 and am having a hard time understanding a question. Firstly, he defines an ordered pair as: ""If $x$ and $y$ are any objects (possibly equal), we define the ordered pair $(x, y)$ to be a new object, consisting of $x$ as its first component and $y$ as its second component. Two ordered pairs $(x, y)$ and $(x' , y')$ are considered equal if and only if both their components match, i.e. $(x, y)=(x', y') \iff (x = x' \& \ y = y')$ "" Now in the question he asks: Suppose we define the ordered pair $(x, y)$ for any objects $x$ and $y$ by the formula $(x, y) := \{ \{x\}, \{x, y\}\}$ . Show that such a definition indeed obeys the property of an ordered pair. For an additional challenge, show that the alternate definition $(x, y) := \{x, \{x, y\}\}$ also verifies the property and is thus also an acceptable definition of ordered pair. My problem is understanding the difference in the question he is asking. What is the difference between showing the new definition obeys the property and verifying the property? Why will verifying the property help in allowing the new definition to be a acceptable one? Any help answering my questions will be extremely appreciated! :)",['elementary-set-theory']
3285222,Show that $\sqrt[i]{i}$ is a real number [duplicate],"This question already has answers here : How to raise a complex number to the power of another complex number? (3 answers) What is $i^i$ and $(i^i)^i$ (3 answers) What is $i^{1/i}$ [duplicate] (4 answers) Closed 4 years ago . How can one show that $\sqrt[i]{i}$ is a real number; $\sqrt[i]{i}\in\mathbb{R}$ . I know for the number to be real given that a calculator produces a value of $4.810477...$ . I thought it might be smart to relate the problem to the complex plane, given that the contains the imaginary unit $i$ . But I do not where to start and how to show this algebraically. Does someone know how to solve this problem?",['complex-analysis']
3285230,Are these continued fractions of integrals known?,"Crossposted on MathOverflow Motivated by Bowman and McLaughlin (2000) on polynomial continued fractions, I considered an extension to functional continued fractions, where the numerator of each fraction is the integral of the previous fraction. That is, define the continued fraction integral transform (CFIT) as \begin{align}\{\mathcal If(t)\}(s)=\dfrac{f(s)}{1+\dfrac{\int_0^s f(x)\,dx}{1+\dfrac{\int_0^s\int_0^u f(x)\,dx\,du}{1+\cdots}}}=\dfrac{f(s)}{1+\dfrac{f^{(-1)}(s)}{1+\dfrac{f^{(-2)}(s)}{1+\cdots}}}={\large{\mathop{\mathrm{K}}_{n=0}^{\infty}}}\frac{f^{(-n)}(s)}1\end{align} where $f\in C^\infty(\Bbb R)$ and $f^{(-k)}$ is Lagrange's notation for the $k$ th antiderivative of $f$ . Some elementary properties of the transform include $\{\mathcal I(0)\}(s)=0$ ; $\{\mathcal If\}(0)=f(0)$ ; $\{\mathcal If\}(s)=\dfrac{f'(s)}{\{\mathcal If'\}(s)}-1$ for all non-constant $f$ such that $f(0)=0$ . Considering the simplest, non-trivial case $f(t)\equiv1$ , we have $f^{(-k)}(t)=t^k/k!$ so that $$\{\mathcal I(1)\}(s)=\dfrac{1}{1+\dfrac s{1+\dfrac{s^2/2!}{1+\cdots}}}.$$ We can see that as $n$ increases, $\mathcal I(1)$ produces more waves. As @PeterForeman mentioned in the comments, the limit $\lim\limits_{s\to-\infty}\mathcal I(1)$ does not exist since it is zero for odd $n$ and $+1$ for even $n$ . However, I believe there are more things that can be investigated. Questions Has the CFIT already been studied/discovered? If so, reference to literature would be appreciated. Going back to the example of $\{\mathcal I(1)\}(s)$ , is it true that the maximum value of each wave increases as $s$ increases up to the first wave? Are there an infinite number of such waves, and is there a closed form for $\max\mathcal I(1)$ ? The period of the oscillations of $\mathcal I(1)$ appears to converge to $$\dfrac4e=1.4715\cdots$$ Can this be proven? Empirically, the argmins are -2.12897, -3.73409, -5.26940, -6.78494, -8.29119, -9.79168, -11.2881, -12.7814, -14.2723,
-15.7613, -17.2487, -18.7348, -20.2198, -21.7038, -23.1870, -24.6695, -26.1513, -27.6326,
-29.1133, -30.5937, -32.0736, -33.5531, -35.0323, -36.5111, -37.9897, -39.4680, -40.9461,
-42.4239, -43.9015, -45.3790, -46.8562, -48.3332, -49.8101, -51.2869, -52.7635, -54.2399,
-55.7162, -57.1924, -58.6685, -60.1445, -61.6203, -63.0961, -64.5717, -66.0473, -67.5228,
... with consecutive differences 1.60512, 1.53531, 1.51554, 1.50625, 1.50049, 1.49642, 1.49330, 1.49090, 
1.48900, 1.48740, 1.48610, 1.48500, 1.48400, 1.48320, 1.48250, 1.48180, 1.48130, 
1.48070, 1.48040, 1.47990, 1.47950, 1.47920, 1.47880, 1.47860, 1.47830, 1.47810, 
1.47780, 1.47760, 1.47750, 1.47720, 1.47700, 1.47690, 1.47680, 1.47660, 1.47640, 
1.47630, 1.47620, 1.47610, 1.47600, 1.47580, 1.47580, 1.47560, 1.47560, 1.47550, ...","['integration', 'maxima-minima', 'continued-fractions', 'reference-request']"
3285257,Show that a finite abelian group is cyclic if and only if every Sylow-p-subgroups are cyclic.,"For the first part i used the result of ""subgroup of cyclic group is cyclic"", then it is clear that every sylow-p-subgroup of G is also cyclic. But in the converse i'm a little bit stuck.","['cyclic-groups', 'finite-groups', 'abstract-algebra', 'sylow-theory', 'abelian-groups']"
3285279,Polynomial expansion (plus/minus trick in statistics),"Suppose the random variables $X_1, ..., X_n$ are independent and identically distributed. Let $\mu_x$ denote the expected value of $X$ , and let $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$ . I often see the following plus/minus trick used in statistics, i.e. \begin{align*} \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2 &= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_X + \mu_X - \bar{X})^2 \\
&= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_x)^2 - (\bar{X} - \mu_x)^2\end{align*} Can someone formulate this into an identity for me? That is, something like $(a - b)^2 = (a - c + c - b)^2 = (a - c)^2 + (c - b)^2 + \text{some cross term}?$ What exactly is that cross term? On a similar token, I've also seen \begin{align*} \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y}) &= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_X )(Y_i - \mu_Y) - (\bar{X} - \mu_x)(\bar{Y} - \mu_Y) \end{align*} What polynomial expansion identity is at play here?","['algebra-precalculus', 'statistics']"
3285303,Roots of $(x-\lfloor x\rfloor)^2+(x-\lfloor x\rfloor)\left\lfloor{1\over x -\lfloor x\rfloor}\right\rfloor=1$,"Can you help me to find -some analytical- roots of the following function ?
I know $\sqrt2$ is a root and I think there are infinitely many roots,according to plot provided by WolframAlpha. $$
(x-\lfloor x\rfloor)^2+(x-\lfloor x\rfloor)\left\lfloor{1\over x -\lfloor x\rfloor}\right\rfloor=1
$$ I've tried Matlab and WolframAlpha for roots.Matlab gives error code ""Warning: Unable to find explicit solution. For options, see help."" But I dont trust my knowledge about Matlab. WolframAlpha gives this $x â‰ˆ 4.94605856546361519886814090Ã—10^-17$ $x â‰ˆ 0.0119030752000093205127913177$ $x â‰ˆ 0.0232432500308837633008456147$ etc... For more click here But I think these are approximations,rather than exact roots.
And if you find any,can you give me some properties about it.I assume roots have to be irrational. Thanks","['ceiling-and-floor-functions', 'roots', 'computational-mathematics', 'algebra-precalculus', 'quadratics']"
3285304,"Show that $F(\{ f \in L^{2}([0,1]): \vert \vert f \vert \vert_{2}\leq 1\})$ is relatively compact","Let $F: L^{2}([0,1])\to C([0,1]), f \mapsto F(f)$ where $(Ff)(t)=\int_{0}^{1}(t^{2}+s^{2})(f(s))^{2}ds$ Show that $F(\{ f \in L^{2}([0,1]): \vert \vert f \vert \vert_{2}\leq 1\})$ is relatively compact. My steps: let $(f_{n})_{n}$ be an arbitrary sequence in $\{ f \in L^{2}([0,1]): \vert \vert f \vert \vert_{2}\leq 1\}$ now via the diagonalization method (I have seen this for normal sequences, but not for function sequences) I want to find my subsequence $(f_{n_{k}})_{k}$ and the proposed limit $f$ . note that for any $f_{n}\in \{ f \in L^{2}([0,1]): \vert \vert f \vert \vert_{2}\leq 1\}\Rightarrow \forall t \in [0,1]:\vert Ff_{n}(t)\vert=\vert\int_{0}^{1}(t^{2}+s^{2})(f(s))^{2}ds\vert\leq \int_{0}^{1}\vert(t^{2}+s^{2})(f_{n}(s))^{2}\vert ds\leq \vert \vert t^{2}+s^{2}\vert\vert_{\infty}\vert\vert f_{n}\vert\vert_{2}<\infty$ What can I say from this? In the case of simple sequence spaces I could use Bolzano WeierstraÃŸ to show that the exists a subsequence etc. But now I am dealing with functions, and I do not know what to do","['operator-theory', 'real-analysis', 'functional-analysis', 'sequences-and-series', 'compactness']"
3285308,What kind of singularity is possessed by $z^{-1/2}$?,"I'm learning about singularities [Stein Sharkarchi Chapter 3], and this question popped up in my mind: What kind of singularity is $f(z):= z^{-\frac{1}{2}}$ at $0$ ? It doesn't seem to fall into either of these three categories: Removable singularity: It's clearly not a removable singularity as $\lim_{z \rightarrow 0} |f(z)| \rightarrow \infty$ Essential singularity: By Casorati-Weierstrass it's not essential singularity either since the image of the unit disc minus the origin is very clearly not dense (it completely misses a ball of radious $.9999$ centered at the origin) Pole : It's not a pole either since it contradicts this theorem because $z^nf(z)$ vanishes at $0$ for all positive integer $n$ : If $f$ has a pole at $0$ then for a neighbourhood of $0$ there's a positive unique  integer $n$ such that $f(z) = h(z) z^{-n}$ and $h(z)$ is holomorphic and nonvanishing in the neighbourhood So what's this singularity ? This is perplexing me. I feel this may have something to do with the nonuniqueness of $f(z)$ around $0$ but then I know nothing about branch cuts to add substance to my intuition.","['complex-analysis', 'singularity']"
3285319,Proving the identity: (A\B) âˆª (B\C) = (AâˆªB) \ (Bâˆ©C),"Trying to prove the following identity: (A\B) âˆª (B\C) = (AâˆªB) \ (Bâˆ©C) I worked algebraically on the expression on the left and reached: (A\B) âˆª (B\C) = (Aâˆ©B') âˆª (B âˆ© C') = ((Aâˆ©B') âˆª B) âˆ© ((Aâˆ©B') âˆª C') . . . = (AâˆªB) \ (Bâˆ©C) \ (C\A) I couldn't find a way to show that ""\ (C\A)"" has no influence on the whole expression, even though it is true. I also tried manipulating the other side of the equation, but with no luck. Thanks for your help!","['elementary-set-theory', 'boolean-algebra', 'discrete-mathematics']"
3285326,Integral involving $\tan(\ln(x))$,"I am trying to solve the following integral: $$I=\int\tan(\ln(x))dx$$ which I initially thought would be easy considering there are many ways to solve both: $$\int\sin(\ln(x))dx$$ $$\int\cos(\ln(x))dx$$ But I appear to be wrong. Upon substitution I can it into the following forms, although none of these appear to lead to anything promising and Wolfram Alpha seems to be showing the only solution involves the hypergeometric function. Since I have limited knowledge of this and how to arrive at this answer I was wondering if anybody had an easy way to derive this or point me in the right direction for finding a series which this can be expressed as. I have found it interesting that it can be expressed as: $$\int\tan(\ln(x))dx=-\int\frac{2}{x^{2i}+1}-1\,\,dx=\int\left[1+\frac{1}{x^i-i}-\frac{1}{x^i+i}\right]dx$$ Although I feel that this would probably be the best approach: $$\int\tan(\ln(x))dx=\int e^u\tan(u)du=e^u\tan(u)-\int e^u\sec^2(u)du$$ Any thoughts? Thanks Another thought I am having is: $$\int\tan(\ln(x))dx=\int e^u\tan(u)du=\int_0^u\sum_{n=0}^\infty\frac{(-1)^n2^{2n+2}(2^{2n+2}-1)B_{2n+2}}{(2n+2)!}e^tt^{2n+1}
$$ $$=\int_0^u\sum_{n=0}^\infty\frac{(-1)^{3n}2^{2n+2}(2^{2n+2}-1)B_{2n+2}}{(2n+2)!}e^{-t}t^{2n+1}dt
$$ $$=\sum_{n=0}^\infty\frac{(-1)^{3n}2^{2n+2}(2^{2n+2}-1)B_{2n+2}}{(2n+2)!}\gamma(2n+2,\ln(x))
$$ $$=\sum_{n=0}^\infty\sum_{k=0}^\infty\frac{(-1)^{3n}2^{2n+2}(2^{2n+2}-1)B_{2n+2}x^{k+2n+2}e^{-x}}{(2n+2)\Gamma(k+2n+3)}$$ $$=\sum_{n=0}^\infty\sum_{k=0}^\infty\sum_{r=1}^\infty\frac{2^{2n+3}(2^{2n+2}-1)x^{k+2n+2}e^{-x}}{(2\pi)^{2n}(2n+1)^r(2n+2)\Gamma(k+2n+3)}$$",['integration']
3285330,"If every polynomial in $k[x]$ has a root in $E$, is $E$ algebraically closed?","If $E/k$ is algebraic and for all $f$ in $k[X]$ , all roots of $f$ lie in $E$ , then $E$ is algebraically closed. The question is: If $E/k$ is algebraic and for all $f$ in $k[X]$ , at least one root of $f$ lies in $E$ , then is $E$ algebraically closed?","['galois-theory', 'abstract-algebra', 'extension-field']"
3285331,$A=\frac{1}{1}+\frac{1}{10}+\frac{1}{11}+\dots+\frac{1}{19}+\frac{1}{21}+\frac{1}{31}+\dots+\frac{1}{91}+\frac{1}{100}+\frac{1}{101}+\dots$,"Consider the series: $$A=\frac{1}{1}+\frac{1}{10}+\frac{1}{11}+\frac{1}{12}+\dots+\frac{1}{19}+\frac{1}{21}+\frac{1}{31}+\frac{1}{41}+\dots+\frac{1}{91}+\frac{1}{100}+\frac{1}{101}+\frac{1}{102}+\dots$$ The numerator of each term is $1$ , and the denominators are the natural numbers that contain the digit $1$ . If the denominators, instead, are the natural numbers omitting numbers containing the digit $9$ is called Kempner series, it converges to $22.92067661926415034816...$ . What is the value of $A$ ? Does $A$ have an exact form?","['summation', 'number-theory', 'harmonic-numbers', 'sequences-and-series', 'convergence-divergence']"
3285344,Integrating $\int_0^1\frac{x\ln (1+x)}{1+x^2}dx$ with restricted techniques,"How does one calculate the following integral? $$
\int_0^1\frac{x\ln (1+x)}{1+x^2}dx
$$ CONTEXT :
Our teacher asks us to  calculate the  integral
using only changes of variables , integrations by parts and the following known result: $$ \int_0^1 \frac{\ln x}{x-1}\,dx=\frac{\pi^2}{6},
$$ without using complex analysis, series, differentiation under the integral sign , double integrals or special functions. Some methods not respecting the teacher's requirement are found in answers to this question .","['integration', 'calculus', 'alternative-proof', 'definite-integrals']"
3285346,Does $\lim_{x\to 0} \frac{\sqrt{x}}{x}$ exist? A comparison with the $\lim_{x\to 0} \sqrt{x}$,"The $\lim_{x\to 0} \frac{\sqrt{x}}{x}$ can be easily evaluated  by simplification: $\lim_{x\to 0} \frac{\sqrt{x}}{x} = \lim_{x\to 0} \frac{1}{\sqrt{x}}$ . At this point, the right-hand limit can be taken: $\lim_{x\to 0+} \frac{1}{\sqrt{x}}=+\infty$ , but left-hand limit $\lim_{x\to 0-} \frac{1}{\sqrt{x}}$ can not be evaluated as the function is not defined for $x < 0$ . So my question now is: $\lim_{x\to 0} \frac{\sqrt{x}}{x} = +\infty$ or should I say it does not exist? My doubt comes from the fact that $\lim_{x\to0} \sqrt{x}=0$ , as explained in this  ( answer ).","['limits', 'calculus']"
