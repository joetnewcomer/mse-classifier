question_id,title,body,tags
3602149,A product sequence,"Evaluate $$\frac{\prod_{i=1}^n[(2i-1)^4+ 1/4]}{\prod_{i=1}^n[(2i)^4+ 1/4]}$$ First I thought I would multiply both the numerator and the denominator by the denominator itself.
Now, I am unable to evaluate the series.
I would appreciate innovative ideas to evaluate this product.",['sequences-and-series']
3602223,Is Integral is considered defined even when one method gives defined results and other undefined results,"something that I found confusing me.
Lets see for example the follow integral: $$\int_{A}^{B}e^{t\cdot x} \cdot dx=\left[\frac{e^{t\cdot x}}{t}\right]_{A}^B=\frac{e^{t\cdot B}-e^{t\cdot A}}{t}$$ From this results we may conclude that for $t=0$ , the integral is undefined: $$\frac{e^{t\cdot B}-e^{t\cdot A}}{t}=\frac{1-1}{0}=\frac{0}{0}$$ but from the other hand, if we evaluate the integral again for this case of $t=0$ , then we get a defined results: $$\int_{A}^{B}e^{t\cdot x} \cdot dx=\int_{A}^{B}e^{0\cdot x} \cdot dx=\int_{A}^{B}1\cdot dx=B-A$$ So is this integral is defined for $t=0$ or not?",['integration']
3602326,"Evaluate $\lim\limits_{x\to \infty} \frac{\int_0^x \left(\arctan t \right)^2\,dt}{\sqrt{x^2+1}}$","Evaluate $\lim\limits_{x\to \infty} \frac{\int_0^x \left(\arctan t \right)^2\,dt}{\sqrt{x^2+1}}$ My attempt was to start doing the integral by parts but at some point it just didn't work. Is there a simple way to do it ? Any help will be appreciated ! ( also, this is a highschool problem, so i would like to see some hints at that level) .","['limits', 'calculus', 'definite-integrals']"
3602439,Tree-planting problem with pagoda functions (from PROMYS),"This question has been asked before, at least twice by people who were trying to cheat on the PROMYS Europe 2020 Application, and once in a question closed because the OP showed no effort. I haven't been able to solve it, so I'm going to to ask it again.  PROMYS applications have closed, and I hope the effort shown below is enough to keep this question from being closed. The Mathematical Forest is grown in a two-dimensional plane, where
  trees can only grow on points with integer coordinates. To start with,
  there are no trees at all. The foresters plant the first tree at $(0,0)$ . Each year, they carry out tree planting according to the
  following rule. If there is a tree on the point (ùëö,ùëõ) but there are
  no trees on the points $(m+1,n)$ and $(m,n+1)$ , then they can choose
  to remove the tree on $(m,n)$ and plant new trees on the points $(m,n+1)$ and $(m+1,n)$ . For an integer $k\geq1$ , the $k$ th diagonal
  consists of all points $(m,n)$ with $m+n=k‚àí1$ . Is it possible for the
  foresters to arrange their planting so that eventually there are no
  trees on the first $2$ diagonals? What about the first $3$ diagonals? $4$ diagonals? Can you generalize? It's easy to get to a position with no trees on the first two diagonals.  (It only takes $4$ plantings.)  I can prove it's impossible to reach a position with no trees on the first $4$ diagonals, and I believe it's impossible to reach a position with no trees on the first $3$ diagonals, but I can't prove it. For the $k=4$ case, I used a pagoda function, as in a peg solitaire problem.  For $k=1,2,3,\dots$ define the potential of a tree on the $k$ th diagonal as $\frac1{2^{k-1}}$ , and the potential of the forest as the sum of the potentials of all the trees in it.  When a tree of potential $\frac1{2^{k-1}}$ is removed, it is replaced by $2$ trees of potential $\frac1{2^k}$ so the potential of the forest never changes.  Initially, the potential of the forest is $1$ . Since there are $k$ trees on diagonal $k$ , the potential of all points beyond the fourth diagonal is $$\sum_{k=5}^\infty\frac k{2^{k-1}}=\frac34<1,$$ so it is impossible that there are no trees on the first $4$ diagonals. The potential of the fourth diagonal is $\frac12$ , so this argument doesn't show that it's impossible to have no trees on the first $3$ diagonals.  I've done a lot of experimenting, though, and I believe that the statement is true.  (I even wrote a little computer game so I could experiment quickly.)  The best I've been able to do is to get down to one man on the third diagonal. The black circles are trees eligible for removal, and the gray circles are other trees.  You can see that there is a ""traffic jam"" in front of the lone tree on diagonal $3$ , and there seems to be no way to clear it. I've been trying to come up with an argument that reflects this traffic jam, but I haven't been at all successful. We know that after $n$ removals there are $n+1$ trees, and I've been trying to prove somehow that they can't all be sufficiently far from the origin to allow all trees to get past diagonal $3$ , but I haven't come close. In the diagram above, if the tree at $(1,1)$ were moved to $(0,2)$ , and the tree at $(1,2)$ were moved to $(2,0)$ , then it would be possible to remove the tree at $(0,2)$ , emptying the second diagonal.  In the fictitious position, we still have one tree on diagonal $2$ and two on diagonal $3$ . So, I think an argument along the lines I was trying cannot just be concerned with the distance from the origin; it must somehow take into account how the trees interfere with one another.  I haven't been able to do this. I'd be grateful for solutions, hints, or counterexamples. I wasn't really sure what tags to attach.  Please add any that seem appropriate.","['contest-math', 'recreational-mathematics', 'discrete-mathematics']"
3602490,Categories where possible automorphism groups are not understood.,"In many categories, such as the category of graphs or topological spaces, every group appears as an automorphism group of an object in that category. This certainly isn't true for all categories, even in cases when one might expect it; see Is every group the automorphism group of a group? for an example. Is there any category (ideally one that people care about) where it is unknown whether this property holds, or at least, a category where the collection of groups which do appear as automorphism groups is poorly understood?","['automorphism-group', 'group-theory', 'category-theory']"
3602546,Use group theory to calculate $9^{74} \pmod {13}$. [duplicate],"This question already has answers here : Mod of numbers with large exponents [modular order reduction] (3 answers) Closed 4 years ago . By Fermat's theorem (or more generally by Euler's totient function theorem), for $p$ prime, any nonzero element $a$ of $Z/pZ$ satisfies: $$a^{p-1}\equiv1 \mod p$$ Hence, in this case, we have $$9^{74}=(9^{12})^69^2$$ Applying the theorem: $$9^{12}\equiv1 \mod 13$$ So $$9^{74}\equiv9^2 \mod 13$$ And now, if I'm doing the math correctly, $$81=(13)(6)+3$$ So $$81\equiv3 \mod 13$$ Is this correct?","['group-theory', 'abstract-algebra']"
3602599,Proving $(\sin x)^{\sin x}<\cos x$ for $0<x\leq\frac{2\pi}{9}$,"Prove that $$(\sin x)^{\sin x}<\cos x$$ for $0<x\leq\frac{2\pi}{9}$ . My try was to do $\sin x\log\sin x-\log\cos x<0$ So I did $f(x)=\sin x\log\sin x-\log\cos x$ and $f'(x)=\cos x\log\sin x+\cos x+\cot x$ , but I don't know what to do now.","['proof-explanation', 'trigonometry', 'inequality']"
3602618,Construct best case example for quick sort with n = 15 [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 4 years ago . Improve this question So the question is to construct a best case example for Quick Sort with 15 elements n = 15, hopefully somebody could give me a second opinion to whether this is the best case for this Quick Sort implementation. The way the algo works for this exercise is that pivot will always be the last element. Now as you will see in the picture we have a (j). (j) will be at first position initially. If value at that position is smaller than pivot, it will move to next element.(what actually happen is that it switches with the element itself but since the element is at same position nothing happened). Now if let say the value at (j) is larger than pivot then (j) stays where it is waiting for next element that is smaller than pivot then (j) and that element will switch. Lastly, the pivot will switch position with the j element. You may wonder why we still consider for when p(begining element) == q (last element) but that is just the way this exercise is Ex:(G(1,1), G(3,3),...) in these case we still call the function but will do nothing. Hint teacher gave was: best case has to do with the least number of exchanges in a partition when comparing with the pivot M. My thinking was to construct it bottom up and make sure both side of the tree will always equal hence prevent situtation when the pivot wont go into the middle but stay at side (aka list is almost sorted and we have a tree that is skewed to one side) Thank you for helping out!","['computer-science', 'discrete-mathematics', 'algorithms']"
3602620,Reference Request: Good book on parameter estimation for stochastic processes,"I have to do some work where I need to estimate the parameters for a poisson process and a Hawkes process from data. I was looking through some of my old probability and stochastic processes textbooks, but I really could not find much on the actual parameter estimation of these process. I checked Grimmett and Stirzaker and the Sheldon Ross' Probability Models book, but they don't reference much on parameter estimation, etc. The Vere-Jones book on point processes as a bit more info, but not really fully fleshed examples. It seems a bit odd that there is not more on numerical methods and estimation of parameters for stochastic processes? Since there is so much theory on the numerical issues surrounding numerical estimation of say ordinary differential equations and partial differential equations, I assume numerical estimation would be a popular topic for stochastic processes too. There are a number of books on estimating Stochastic Differential Equations, but they don't seem to cover other stochastic processes--as far as I could see. I am curious if I am just looking in the wrong places, or if there is just a lack of materials? Seems like maximum likelihood would be a simple enough method to fit parameters for some of these models, but there could be numerical computing issues that I am not thinking of. I can certainly envision numerical computing issues cropping up in the case of continuous time stochastic processes--that need to be approximated by some discrete scheme. What about having lots of zeros, or the potential for big jumps--these things might generally throw off the optimization routine for a given model. So any good reference on parameter estimation for different types of stochastic processes would really be appreciated. Thanks.","['statistics', 'poisson-distribution', 'stochastic-processes', 'numerical-methods', 'probability']"
3602668,"Spivak Chapter 10, Problem 29 : why is this true?","The problem is as follows (verbatim) : 
Prove that it is impossible to write $x = f(x)g(x)$ where $f$ and $g$ are differentiable and $f(0)=g(0)=0$ . I rephrased the question as I realized it wasn't optimally worded : Prove that it is impossible to write $x = f(x)g(x)$ for all $x \in \mathbb R$ , where $f$ are $g$ are differentiable on $\mathbb R$ and $f(0)=g(0)=0$ . I proved this by differentiating both sides of $x = f(x)g(x)$ , which gives $1 = f'(x)g(x) + f(x)g'(x)$ ; thus when $x=0, f'(0)g(0) + f(0)g'(0) = 0 \neq 1$ . However, this proof doesn't give me much insight on why this particular exercise is true. I am really interested in seeing a more intuitive explanation, but here are some of my attempts/hypotheses : $f'(x)g(x) + f(x)g'(x)$ is constant when $f$ or $g$ is constant. However, WLOG, if $f(x) = 0$ , then we will have to divide by zero in order to get a function $g$ such that $x = f(x)g(x)$ . If we define $f(x) = \frac{x}{g(x)},$ then clearly if $g(x) = 0$ then $f$ is not even continuous at $x=0$ , so $f$ would not be differentiable on $\mathbb R$ . I am more or less looking for a graphical(?), intuitive explanation. Thank you for your help!","['calculus', 'real-analysis']"
3602699,A solution for nonlinear system of ode,"Solve the system $$x'=-x$$ $$y'=-2y+x^2$$ I see that if we hvae $x(0)=x_0,y(0)=y_0$ , then $x=x_0e^{-t}$ and $y=y_0e^{-2t}+x^2=y_0e^{-2t}+x_0^2e^{-2t}$ ? is that true? Also, is there a general way to solve any linear system $x'=x,  y'=y+x^n$ ?.",['ordinary-differential-equations']
3602747,How would you solve an equation of the form $e^{-x} - \sin(x) = 0$?,"I've been trying to do this for ages. I'm worried that it's impossible, but I have heard that it can be done by hand. As long as I can get $x$ by hand I can obviously work out its value via calculator. Please help, I am so stuck and desperately need assistance. Thanks in advance!","['algebra-precalculus', 'trigonometry']"
3602780,How to prove that every orthogonal matrix has determinant $\pm1$ using limits (Strang 5.1.8)?,"The problem of interest from Gilbert Strang's Introduction to Linear Algebra Section 5.1 is as follows. Prove that every orthogonal matrix ( $Q^TQ = I$ ) has determinant $1$ or $-1$ . (b) Use only the product rule. If $|\det(Q)| > 1$ , then $\det(Q^n) = (\det(Q))^n$ blows up. How do you know this can't happen to $Q^n$ . Anyone who has even sniffed a Strang textbook knows that the words inside are filled with ambiguity; this problem is no exception. From what I can interpret, Strang is giving the first steps to prove the desired result. Assume $|\det(Q)| \neq 1$ . If $|\det(Q)| > 1$ , then $\det(Q^n) = (\det(Q))^n$ and thus $|\det(Q^n)| \to \infty$ as $n \to \infty$ . And this contradicts... what exactly? In the solution manual (by Strang), this is the solution. $Q^n$ stays orthogonal so its determinant can't blow up as $n \to \infty$ . This sounds like circular logic to me. Since $Q$ is orthogonal, so is $Q^n$ . Since $Q^n$ is orthogonal, $|\det(Q^n)| \not\to \infty$ as $n \to \infty$ . The only way this is true is if $|\det(Q^n)| \le 1$ , which is what we are trying to prove in the first place. Is my interpretation correct? Is Strang using circular logic here or am I missing something? Also, what is Strang getting at with his hint? Thanks for the help.","['orthogonal-matrices', 'determinant', 'linear-algebra']"
3602827,The Image of Diagonal Morphism $\Delta(X)$,"I'm trying to understand the fact from Algebraic Geometry which is just assumed to be true everywhere I see it. The fact is that: Let $X$ be a scheme and $X \to S$ a morphism. Denote by $\Delta_{X/S} : X \to X \times_S X$ the diagonal morphism. Let $Z = \{y \in X \times_S X : p_1(y) \equiv p_2(y)\}$ . Where $p_1,p_2: X \times_S X\to X$ projections and if  we have $f, g : K \to X$ be morphisms of schemes, let $x \in K$ , and let $i_x : \operatorname{Spec} (\kappa(x)) \to K$ denote the associated canonical morphism. Then we say $f(x) \equiv g(x)$ if $f \circ i_x = g \circ i_x$ . Equivalently: $f(x) = g(x)$ and the maps on residue fields $\kappa(f(x)) \to \kappa(x)$ induced by $f^{\#}_x$ , $g^{\#}_x$ are equal. Show that $Z = \Delta_{X/S}(X)$ I spent a lot of time trying to understand it myself, but I think I'm missing important in my understanding of Schemes. I will appreciate any help!","['commutative-algebra', 'fibre-product', 'affine-schemes', 'algebraic-geometry', 'schemes']"
3602833,Proof that the roots of $\mathrm e^{-œÄx}=\sin œÄx$ approach integers as $x\to \infty$,"This question is inspired by @gt6989b ‚Äôs comment here . Numerical analysis suggests that the roots of the equation $\newcommand{\e}{\mathrm{e}} \e^{-œÄx} = \sin œÄx$ rapidly and closely approach integers as $x\to\infty$ . Here‚Äôs a quick list of the first nine solutions: $$\begin{array}{l}
0.18733579075230\dots \\
0.98560325090923\dots \\
2.00059331886993\dots \\
2.99997431047250\dots \\
4.00000111005168\dots \\
4.99999995203014\dots \\
6.00000000207297\dots \\
6.99999999991042\dots \\
8.00000000000387\dots \\
\end{array}$$ How can I prove (or disprove) that these values will get closer and closer to integers? Wolfie notes that the system has the alternate form $$\newcommand{\i}{\mathrm{i}} \e^{-œÄx} = \frac{\i\e^{-\i œÄx} - \i\e^{\i œÄx}}2$$","['limits', 'proof-writing', 'numerical-calculus', 'sequences-and-series']"
3602965,Is this intuition for integrating differential forms correct?,"I'm learning about differential forms and have seen that the wedge product of $k$ 1-forms $\omega_{1},\cdots,\omega_{k}$ acting on $k$ vectors $\mathbf{v}_{1},\ldots,\mathbf{v}_{k}$ is given by $$\left(\omega_{1}\wedge\cdots\wedge\omega_{k}\right)\left(\mathbf{v}_{1},\ldots,\mathbf{v}_{k}\right)=\left|\begin{array}{ccc}
\omega_{1}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{1}\left(\mathbf{v}_{k}\right)\\
\vdots &  & \vdots\\
\omega_{k}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{k}\left(\mathbf{v}_{k}\right)
\end{array}\right|.$$ This provides me with a nice mental picture that the value of the $k$ -form $\omega=\omega_{1}\wedge\cdots\wedge\omega_{k}$ acting on the $k$ vectors $\mathbf{v}_{1},\ldots,\mathbf{v}_{k}$ is given by the signed volume of the $k$ -dimensional parallelotope spanned by the column vectors of the matrix $$\left[\begin{array}{ccc}
\omega_{1}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{1}\left(\mathbf{v}_{k}\right)\\
\vdots &  & \vdots\\
\omega_{k}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{k}\left(\mathbf{v}_{k}\right)
\end{array}\right].$$ My question is, can that nice mental picture be extended to integrating differential forms? In other words, can I regard the integral of $$\intop_{M}\omega=\intop_{D}\omega\left(\frac{\partial\Phi}{\partial u^{1}},\ldots,\frac{\partial\Phi}{\partial u^{k}}\right)du^{1}\wedge\cdots\wedge du^{n}$$ as in some way the signed volume of the sum of all the little $k$ -dimensional parallelotopes spanned by the column vectors of $$\left[\begin{array}{ccc}
\omega_{1}\left(\frac{\partial\Phi}{\partial u^{1}}\right) & \cdots & \omega_{1}\left(\frac{\partial\Phi}{\partial u^{k}}\right)\\
\vdots &  & \vdots\\
\omega_{k}\left(\frac{\partial\Phi}{\partial u^{1}}\right) & \cdots & \omega_{k}\left(\frac{\partial\Phi}{\partial u^{k}}\right)
\end{array}\right].$$ Or have I got this wrong? Late in the day edit If my intuition is correct, could anyone provide a deeper explanation as to what it means for the integral to equal the sum of all the little $k$ -dimensional parallelotopes? I'm having trouble visualising what that actually means.","['integration', 'differential-forms', 'intuition']"
3602966,A suprising conjectural closed-form of $\sum _{n=1}^{\infty } \frac{1}{n^4 2^n \binom{3 n}{n}}$ and integral variations,"How to prove (any of) the following $\small \sum _{n=1}^{\infty } \frac{1}{n^4 2^n \binom{3 n}{n}}=-2 \pi  \Im(\text{Li}_3(1+i))-\frac{21 \text{Li}_4\left(\frac{1}{2}\right)}{2}-\frac{57}{8} \zeta (3) \log (2)+\frac{83 \pi ^4}{480}-\frac{23}{48}  \log ^4(2)+\frac{7}{12} \pi ^2 \log ^2(2)$ $\int_0^1 \frac{x \text{Li}_2(x) \log (1-x)}{x^2+1}dx=\frac{C^2}{2}-\frac{1}{8} \pi  C \log (2)+\frac{15 \text{Li}_4\left(\frac{1}{2}\right)}{16}-\frac{511 \pi ^4}{46080}+\frac{5 \log ^4(2)}{128}-\frac{7}{384} \pi ^2 \log ^2(2)$ $\small \int_0^1 \frac{\text{Li}_2(x) \log \left(x^2-2 x+2\right)}{x} dx=\frac{1}{2} \pi  \Im(\text{Li}_3(1+i))+\frac{5 \text{Li}_4\left(\frac{1}{2}\right)}{8}+\frac{35}{64} \zeta (3) \log (2)-\frac{577 \pi ^4}{23040}+\frac{5 \log ^4(2)}{192}-\frac{1}{96} \pi ^2 \log ^2(2)$ The first identity is an unproved conjecture of J. M. Borwein found by PSLQ, originally written in terms of multiple-polylogarithm $L_{3,1}$ . I have already established the equivalence of $3$ identities but neither of them is trivial. Any help will be appreciated. Update: Ali Shadhar had established the indeterminate integral. See here for proof of the first one using his result. The last one is direct via IBP.","['integration', 'summation', 'definite-integrals', 'harmonic-numbers', 'sequences-and-series']"
3602972,Grid of squares coloring,"Imagine a grid of size n x n of squares, where each square is colored either white or black. Black spreads as follows: At each step, all the white squares which have at least two black neighbors (where neighbors must share a side ‚Äì they can not be diagonal neighbors) become black. What is the minimum number of black squares needed at the beginning for the grid to be completely black at some point?
  (This is from a puzzles Collection by Sophia Yakoubov, January 28, 2019, found in web.mit.edu website). For $n = 3$ , I found 3 and for $n = 4$ , I found 7. I am trying to find a recursive relation but am not getting anywhere. (This is not homework or anything; just challenging myself with nice puzzles!). Any ideas? Many thanks!",['combinatorics']
3602997,Axiom to prove $ \sqrt2 $ is irrational by contradiction.,"$ \sqrt2 $ is irrational. Proof By contradiction. Assume $ \sqrt2 $ is not irrational i.e. Assume $ \sqrt2 $ is rational. ... ... ... Since $ \sqrt2 $ is rational is false , hence $ \sqrt2 $ must be irrational. Isn't this assumption $ \sqrt2 $ is rational incomplete? Shouldn't one also prove that $ \sqrt2 $ is also not an imaginary number or one of my axioms state something like there are only either rational or irrational numbers and then proceed with this proof?? By contradiction we just prove $ \sqrt2 $ is rational is false, but $ \sqrt2 $ can still be something that's either imaginary, complex or yet even not discovered.","['real-numbers', 'discrete-mathematics']"
3603067,Functional equation $ f(x) + f\left(1-\frac{1}{x}\right) = \tan^{-1}(x) $ and definite integral,"Let $f(x)$ be a function $f :\mathbb{R}\to \mathbb{R}$ such that $$ f(x) + f\left(1-\frac{1}{x}\right) = \tan^{-1}(x) $$ for all real $x$ except $0$ . Find $\int_0^1f(x)\ \mathrm dx$ . My approach till now: Put $x = \frac{1}{x}$ in the functional equation and consider the domain of integration $(0,1)$ such that $\tan^{-1}\frac{1}{x} = \cot^{-1}(x)$ and add the original functional equation and the resulting equation after the substitution to get: $$f(x) + f(1-x) = \frac{\pi}{2} - f\left(\frac{1}{x}\right) - f\left(1-\frac{1}{x}\right)$$ and integrate both sides from $0$ to $1$ . Let $I = \int_0^1f(x)\ \mathrm dx $ , then LHS of above functional equation becomes $2I$ . Now I am not able to evaluate the RHS, some $\frac{\ln(2)}{2}$ term always creeps up and doesn't gets cancelled and its not even in the answer. Please help me with this problem.","['functional-equations', 'calculus', 'definite-integrals', 'trigonometry']"
3603219,Is it always possible to find a partition of unity subordinate to a cover with the same index set?,"Let $(X,\mathcal{T})$ be a topological space. A parition of unity subordinate to an open cover $(\mathcal{O}_{i})_{i\in I}\in\mathcal{T}^{I}$ is a collection of maps $\{f_{j}:X\to [0,1]\}_{j\in J}$ such that The set of supports $\{\operatorname{supp}(f_{j})\}_{j\in J}$ is locally finite, which means that every point has a neighbourhood, which intersects only finitely many elements of $\{\operatorname{supp}(f_{j})\}_{j\in J}$ . For every $j\in J$ there is an $i\in I$ such that $\operatorname{supp}(f_{j})\subset U_{i}$ . $\forall x\in X:\sum_{j\in J}f_{j}(x)=1$ Often, we are interested in a partition of unity $\{f_{i}:X\to [0,1]\}_{i\in I}$ subordinate to a cover $(\mathcal{O}_{i})_{i\in I}\in\mathcal{T}^{I}$ with the same index set such that $\forall i\in I:\operatorname{supp}(f_{i})\subset U_{i}$ . If there exists an partition of unity subordinate to a cover, can we always choose without loss of generality that it has the same index set? I was thinking of the following proof: Proof: Let $\{f_{j}:X\to [0,1]\}_{j\in J}$ be a subordinate partition of unity subordinate to an open cover $(U_{i})_{i\in I}$ . Then there is for every $j\in J$ an $i\in I$ , such that $\operatorname{supp}(f_{j})\subset U_{i}$ . Let $\varphi:J\to I$ be the map which sends every $j\in J$ to the corresponding $i\in I$ . We define for every $i\in\varphi(J)$ the map $\widetilde{f}_{i}:X\to [0,1]$ for all $x\in X$ through \begin{align*}\widetilde{f}_{i}(x):=\sum_{j\in\varphi^{-1}(\{i\})}f_{j}(x)\end{align*} and for every $i\in I$ \ $\varphi(J)$ , $\widetilde{f}_{i}$ to be the constant zero function. Then is $\{\widetilde{f}_{i}:X\to [0,1]\}_{i\in I}$ obviously a partition of unity subordinate to an open cover $(U_{i})_{i\in I}$ with $\forall i\in I:\operatorname{supp}(\widetilde{f}_{i})\subset U_{i}$ . $\blacksquare$ But the problem is, this works only, if $\varphi^{-1}(\{i\})$ is finite for all $i\in\varphi(J)$ , or in other words, if every set $U_{i}$ of the cover contains only finitely many supports. Otherwise, the sum is not well-defined......So the question is, if this is true? Maybe this has to do something with the locally finiteness of the supports.... Thank you in advance!","['general-topology', 'differential-topology', 'differential-geometry']"
3603281,$x^{3}+ax^2+bx+c$ has all roots negative real numbers and a<3. Establish an inequality between only b and c [duplicate],"This question already has answers here : let $a,b,c \in\mathbb{R} ,a<3$ and all roots $p(x)=x^3+ax^2+bx+c=0$ be negative . then prove that $b+c\neq 4$ (2 answers) Closed 4 years ago . A cubic equation $x^{3}+ax^2+bx+c$ has all negative real roots and $a, b, c\in R$ with $a<3.$ Prove that $b+c<4.$ My attempt : Let the cubic be $f(x)$ Plotting graph we see that , $f(x\geq 0)>0$ . So we can see that a relation between $a, b, c$ can be established by putting $x=1$ , so, $1+a+b+c> 0$ . So $b+c>-4$ . Also by using Vieta's Formula we get $a, b, c > 0$ . Now I'm uncertain how to proceed, any help will be appreciated. This is a problem of a maths olympiad. Thanks.","['contest-math', 'algebra-precalculus', 'cubics', 'inequality']"
3603369,What does the second derivative of the log transform of a function tell us about the original function?,"In the current COVID19 crisis it has become more sensible to plot the mortality in log base 2 given the steep exponential growth with doubling times of 2 days. Recently, there has been a flattening of this log-linear plots in Italy and Spain. This is the second derivative of the log transform of the original function (which is bound to be logistic) is negative, but decreasing in absolute value. Yet, these changes are still not quite apparent in the initial plot: What is the mathematically precise interpretation of this change in the second derivative of the log transform of the data (we can assume a logistic curve)? Is the overlap in tendency as x increases just a product of the monotonicity of the function and its log transform? I don't have an elegant way of explaining this to myself, but simulating a logistic curve plateau-ing at $50$ cases in the course of $10$ days, makes it apparent the the binary log transform reaches a plateau earlier than the original function. Also, this point of deceleration in the log transform, corresponding to day $5,$ is the minimal negative value of the second derivative, and corresponds to the zero value of the second derivative of the original function, i.e. the middle of the straight part of the sigmoid curve. The critical value of the second derivative of the log transform (day $3$ ) seems to coincide with the initial deviation of the sigmoid (logistic) growth from a purely exponential: The plots are starting to show a similar shape with an incipient slow down in the number of deaths in Italy lagging behind the early indicator of a deceleration in the binary log of the number of cases: There are a slew of epidemiological factors (clustering, isolation measures, use of PPE, uneven testing, ICU occupancy/overload, treatment improvements, etc) that make any extrapolation from the ""back-of-the-envelop"" first plot to the actual numbers fraught with pitfalls. The area of maximal curvature in the log-linear plot in the actual curves in Italy is extremely subjective to pinpoint: notice the noise in the vector of second differences: Around March 11 the biggest second differences were noted with a large peak surrounded by two dips, which suggest an accounting problem, rather than signaling a position slightly past the brown vertical line on the first plot. Around March 25, which was some 20 days after the start of the accelerated phase of the epidemic there possibly lies a deceleration, which has already been noted in the news. But if this corresponds to the asymptotic tendency to zero in the second derivative of the log transform (first plot in blue), guessing at which point the nadir was reached in this second derivative of the log transform is anybody's guess. There is, however, a suggestion that the sigmoid curve is starting to show its exponential decrease (left half of the second plot in blue). Please note that the question is about the relationship of the derivatives of the log transform and the original logistic curve - It is not about fitting the data to a specific function , which is a fool's errand as beautifully illustrated by Constance Crozier in this plot:","['calculus', 'functions', 'transformation']"
3603441,Normalization of the generator of third cohomology of a compact Lie group,"It is proven in ""Loop groups"" by Pressley and Segal (Prop. 4.4.5, p. 49) that the left invariant 3-form $\sigma$ on a simply-connected compact Lie group $G$ whose value at the identity is given by $$ \sigma(\xi, \eta, \zeta) = \langle [\xi, \eta], \zeta \rangle $$ defines an integral cohomology class (which I interpret as the statement that its periods, i.e. integrals over $3$ -cycles, are integers) if and only if the invariant bilinear pairing $\langle -, - \rangle$ is such that $\langle h_{\alpha}, h_{\alpha} \rangle \in 2 \mathbb  Z$ for every coroot $h_{\alpha}$ . The proof relies on on the assertion that this is true for $G = \mathrm{SU}(2)$ . However I calculated that with this construction of $\sigma$ the result is $$ \int_{\mathrm{SU}(2)} \sigma = 48 \pi^2. $$ Therefore I think the value at the identity should be modified to $$ \sigma(\xi, \eta, \zeta) = \frac{1}{4 8 \pi^2} \langle [\xi , \eta], \zeta \rangle, $$ and then the argument in the book goes through. The question is where is the error - is it in Segal, Pressley or maybe my calculations are wrong? For reference I include a sketch of my calculation below. Perhaps it might be of use to someone in the future. Since I'm working with a matrix group, left-invariant Maurer-Cartan takes the form $\omega = g^{-1} dg$ . I parametrize $g = \begin{bmatrix} x & y \\ - \overline{y}  & \overline{x} \end{bmatrix}$ with $x,y$ - complex numberd satisfying $|x|^2+|y|^2=1$ . It is convenient to write $x = \mathrm{cos}(\theta) e^{i \phi}$ , $y = \mathrm{sin}(\theta) e^{i \psi}$ . Differential form $$ \sigma = \mathrm{tr} \left( \omega \wedge [ \omega \wedge \omega] \right) $$ satisfies the assumptions mentioned above. After a few lines of calculations I get that $$ \sigma = 12 \sin(2 \theta) d \theta \wedge d \phi \wedge d \psi. $$ Two factors of $2 \pi$ come from integrating $\phi$ and $\psi$ over $[0, 2 \pi]$ . Integration with respect to $\theta$ over $\left[ 0, \frac{\pi}{2} \right]$ gives $1$ . Hence the final result.","['de-rham-cohomology', 'lie-algebras', 'lie-groups', 'differential-geometry']"
3603478,Cluster point and epsilon delta question.,"Questions Let $D=\{\frac{1}{n}:n\in\mathbb N\}\subseteq\mathbb R$ . (a) Show that $0$ is a cluster point of D (b) Let $f: x \mapsto1$ where $x\in D$ . Show that $\lim_{x\to\infty} f(x) = 1$ . (c) Let $g: \frac{1}{n} \mapsto k$ where $\frac{1}{n}\in D$ and $k\in\mathbb N_0$ is the largest number such that $2^k | n$ . Show that $\lim_{x\to\infty}g(x)$ does not exist My answers (a) Theorem: Let $D\subseteq\mathbb R$ and let $x\in\mathbb R$ . $x$ is a cluster point if and only if $\exists (x_k)_{k\in\mathbb N}$ such that $x_k\in D\setminus{x}$ for all $k\in\mathbb N$ and $\lim_{k\to\infty}x_k=x$ . Let $x_n=\frac{1}{n}$ where $n\in\mathbb N$ be a sequence. We can define D in terms of $x_n$ . i.e $D=\{x_n\}$ . So $x_n\in D$ $\space\forall n\in\mathbb N$ . Proving that $0\notin D$ :
Assume $0\in D$ $\Leftrightarrow \space \exists n\in\mathbb N$ such that $\frac{1}{n}=0 \space$ $\Leftrightarrow 1=0$ $\therefore$ Contradiction $\Rightarrow 0\notin D$ $\Rightarrow D\setminus\{0\}=D$ Therefore $x_n\in D\setminus\{0\}$ $\forall \epsilon\gt 0\space$ $\space\exists N_{\epsilon}\in\mathbb N$ where $N_{\epsilon}=\frac{1}{\epsilon}$ : $\forall n\gt N_{\epsilon}\space$ $\Rightarrow |x_n-0|=|\frac{1}{n}-0|=\frac{1}{n}\lt\frac{1}{N_{\epsilon}}=\epsilon$ Hence $\lim_{n\to\infty}x_n=0$ $\Rightarrow$ By the theorem provided we have shown that $x=0$ is a cluster point. (b) Given $\epsilon\gt0$ . We can choose any $\delta$ with $0\lt |x-0|\lt\delta$ we get $|f(x)-1|=|1-1|=0\lt\epsilon$ Hence $\lim_{x\to 0}f(x)=1$ (c)
I have tried for a while now -struggling to see how to tackle this. Comments This is a nasty question which was posed to me on my Analysis I course.
Would be great if anyone could check my work, maybe even give alternative proofs for (a) and (b).
And it would be nice if someone could help me with (c) :)","['epsilon-delta', 'analysis', 'real-analysis', 'solution-verification', 'limits']"
3603497,Integral involving elliptic integral functions,Recently I came across this identity: $$\int _0^1\:\frac{K\left(x\right)}{1+x}dx=\frac{\pi ^2}{8}$$ Where: $$K\left(x\right)=\int _0^{\frac{\pi }{2}}\:\frac{1}{\sqrt{1-\left(x\sin \left(\theta \right)\right)^2}}d\theta $$ Any hints to how to prove this identity?,"['integration', 'elliptic-integrals', 'pi']"
3603526,Law of large numbers holding uniformly with respect to a distribution,"Let $X$ and $\varepsilon$ be independent random vectors, $\mathcal{X} = \text{supp}(X)$ , and $Y = f(X) + \varepsilon$ for some function $f$ .
For any $x \in \mathcal{X}$ , let $y^i = y^i(\omega)$ , $i \in \{1,\cdots,n\}$ , be independent samples of $Y \mid X = x$ defined on a measurable space $(\Omega,\mathcal{F})$ and equipped with a probability measure $\mathbb{P}_x$ .
Suppose for each $x \in \mathcal{X}$ , there exists a $\mathcal{F}$ -measurable set $S(x)$ such that $\mathbb{P}_x\{S(x)\} = 0$ and for any $\omega\in \Omega \backslash S(x)$ , $$\lim_{n \to \infty} \frac{1}{n}\sum_{i=1}^{n} g(y^i(\omega)) = \mathbb{E}[g(Y) \mid X = x]$$ for some function $g$ . Question : Can we find a measurable set $T$ such that $\mathbb{P}_x\{T\} = 0$ , $\forall x \in \mathcal{X}$ , and for any $\omega\in \Omega \backslash T$ , $$\lim_{n \to \infty} \frac{1}{n}\sum_{i=1}^{n} g(y^i(\omega)) = \mathbb{E}[g(Y) \mid X = x]? \tag{1}$$ If this is not true in general, are there mild assumptions on the functions $f$ and $g$ and/or the distribution of $\varepsilon$ under which it holds? Note: $\mathcal{X} \subset \mathbb{R}^m$ is the support of $X$ , $f: \mathcal{X} \to \mathbb{R}^d$ , and $g: \mathcal{Y} \to \mathbb{R}$ , where $\mathcal{Y}$ is the support of $Y$ . Context: This question is based on Assumption (A6) in page 11 of this paper . I am not well-versed in measure theory, so forgive me for incorrect use of notation. Thoughts : My rough interpretation is that $S(x)$ denotes the sample paths of $Y \mid X = x$ of probability zero over which the LLN-type equality does not hold. Generally, this set can depend on $x \in \mathcal{X}$ , and the question is whether there exists a set (independent of $x$ ) $T \supset S(x)$ , for a.e. $x \in \mathcal{X}$ also of zero probability for which the equality holds. Clearly, this holds when $f \equiv 0$ (i.e., $Y$ is independent of $X$ ) since the set $S$ does not depend on $x$ in this case. When $f$ is not trivially zero, it seems like there cannot be (uncountably) many values that the set $S(x)$ can take, because the conditional distributions $Y \mid X = x_1$ and $Y \mid X = x_2$ only differ by a translation when $x_1 \neq x_2$ . Plausible argument for the case when $f$ is continuous and $g$ is Lipschitz continuous: Let $\bar{\mathcal{X}} = \mathcal{X} \cap \mathbb{Q}^m$ be the intersection of the support of $X$ with $m$ -dimensional rational vectors. Then $T = \cup_{x \in \bar{\mathcal{X}}} S(x)$ satisfies (1). I think this is true because if $\omega \in S(x)$ for some $x \in \mathcal{X} \backslash \bar{\mathcal{X}}$ , then we can pick $\bar{x} \in \bar{\mathcal{X}}$ that is arbitrarily close to $x$ (since $\mathbb{Q}^m$ is dense in $\mathbb{R}^m$ ) such that $\omega \in S(\bar{x})$ .","['measure-theory', 'conditional-expectation', 'law-of-large-numbers', 'probability-theory', 'random-variables']"
3603606,Uniqueness of the Frobenius automorphism,"Let $L/K$ be a Galois extension of algebraic number fields with rings of integers $\mathcal{O}_L$ and $\mathcal{O}_K$ respectively. Let $\mathfrak{p} \subset \mathcal{O}_K$ be a prime ideal and $\mathfrak{P} \subset \mathcal{O}_L$ a prime above $\mathfrak{p}$ . It can be shown that there exists an automorphism $\varphi_{\mathfrak{P}} \in \textrm{Gal}(L/K)$ satisfying $$
\varphi_{\mathfrak{P}}(x) \equiv x^q\ (\textrm{mod}\ \mathfrak{P}) \qquad \forall x \in \mathcal{O}_L \tag{1},
$$ where $q:=\lvert \mathcal{O}_K/\mathfrak{p} \rvert$ . This is the Frobenius automorphism of $L/K$ corresponding to the prime $\mathfrak{P}$ . I want to show that the element in $\textrm{Gal}(L/K)$ satisfying $(1)$ is unique. My idea was to assume that $\sigma, \tau \in \textrm{Gal}(L/K)$ satisfy $(1)$ , then define $\upsilon:=\sigma^{-1}\circ \tau$ , so that $$
\upsilon(x) \equiv x\ (\textrm{mod}\ \mathfrak{P})\qquad \forall x \in \mathcal{O}_L. \tag{2}
$$ Or in other words: $$
\mathfrak{P} \mid \upsilon(x)-x \qquad \forall x \in \mathcal{O}_L. \tag{3}
$$ Then somehow deduce from (3) that $$
\mathfrak{P} \mid \upsilon(x)-x \qquad \forall x \in L, \tag{4}
$$ from which one would conclude that $$
\upsilon(x)-x = 0 \qquad \forall x \in L, \tag{5}
$$ and thus find that $\upsilon = \textrm{Id} \in \textrm{Gal}(L/K)$ , and hence $\sigma = \tau$ . But as I am sure you will agree, the above is more reminiscent of wishful thinking than actual mathematics. Does anyone know if there is a standard ""book proof"" of the statement, or if one might prove it along lines similar to the above? Many thanks.","['algebraic-number-theory', 'galois-theory', 'ring-theory', 'abstract-algebra', 'group-theory']"
3603614,"If $x$ and $y$ are from $[2, 100]$ show there exist $n$ so $x^{2^n}+y^{2^n}$ is composite.","If $x$ and $y$ are form $[2, 100]$ show there exist $n$ so $x^{2^n}+y^{2^n}$ is composite. This is old contest problem and I can't find solution. I tried to show that for some $n$ this sum will be divisible by 101, but didn't succeed.
Also tried some more ides, but also failure. Also we can assume that $(x,y)=1$ . Can someone help? Any hint or idea what to try?","['contest-math', 'number-theory']"
3603648,Is the space of probability measures on R sigma-compact?,"Let $P(\mathbb R)$ be the space of probability measures on $\mathbb R$ endowed with the L√©vy Prokhorov metric . I know that it is a  complete Polish space, but it is not Locally compact. I wonder whether it is sigma compact or not (my intuition says it isn't). Sadly metrizable, separable, complete and sigma compact do not imply locally compact. Any idea?","['general-topology', 'probability-theory', 'compactness', 'metric-spaces']"
3603670,"In $\triangle PQR$, if $3\sin P+4\cos Q=6$ and $4\sin Q+3\cos P=1$, then the angle $R$ is equal to","In $\triangle PQR$ , if $3\sin P+4\cos Q=6$ and $4\sin Q+3\cos P=1$ , then the angle $R$ is equal to My attempt is as follows:- Squaring both equations and adding $$9+16+24\sin(P+Q)=37$$ $$\sin(P+Q)=\dfrac{1}{2}$$ either $P+Q=\dfrac{\pi}{6}$ or $P+Q=\dfrac{5\pi}{6}$ If $P+Q=\dfrac{\pi}{6}$ , then $R=\dfrac{5\pi}{6}$ otherwise $R=\dfrac{\pi}{6}$ Let's see case $1$ : $P+Q=\dfrac{\pi}{6}$ $$3\sin P+4\cos\left(\dfrac{\pi}{6}-P\right)=6$$ $$3\sin P+4\left(\dfrac{\sqrt{3}}{2}\cos P+\dfrac{1}{2}\cdot\sin P\right)=6$$ $$3\sin P+2\sqrt{3}\cos P+2\sin P=6$$ $$5\sin P+2\sqrt{3}\cos P=6\tag{1}$$ $$4\left(\dfrac{1}{2}\cdot\cos P-\sin P\cdot\dfrac{\sqrt{3}}{2}\right)+3\cos P=1$$ $$-2\sqrt{3}\sin P+5\cos P=1\tag{2}$$ $$\cos P=\dfrac{12\sqrt{3}+5}{37}$$ $$\sin P=\dfrac{30-2\sqrt{3}}{37}$$ Using calculator I found $\cos P=0.69$ , this means $P>\dfrac{\pi}{6}$ because $\cos \dfrac{\pi}{6}=0.866$ , this mean $Q$ will be negative because $Q=\dfrac{\pi}{6}-P$ . So this cannot be the case hence $P+Q$ would be $\dfrac{5\pi}{6}$ and $R$ will be $\dfrac{\pi}{6}$ This is the correct answer also , but I want to know does there exist any better way to decide on the value of $P+Q$ . I am asking this because I had to use the calculator for finding the value of $\cos P$ .",['trigonometry']
3603673,Median Concentration implies mean concentrarion,"I want to prove that if X is such that $$P[|X-m_X|\geq t] \leq c_1 e^{-c_2t^2},$$ for $c_1, c_2$ positive constants, $t\geq 0$ , then it holds that $$P[|X-E[X]|\geq t] \leq c_3 e^{-c_4t^2},$$ with $c_3=1+2c_1$ and $c_4=c_2/4$ . There is a proof of reverse direction here .","['statistics', 'concentration-of-measure', 'median', 'means', 'probability']"
3603675,Infinite many solutions of $\varphi(2n+1)=\varphi(4n+1)$?,"Related to this question : How far apart can be solutions of $\varphi(m)=\varphi(n)$ (while avoiding multiplicativities)? Does the equation $$\varphi(2n+1)=\varphi(4n+1)$$ have infinite many solutions ? $\ \varphi(n)\ $ is the totient-function. The pari-code and the first solutions : ? for(n=1,10^7,if(eulerphi(2*n+1)==eulerphi(4*n+1),print1(n,"" "")))
656 926 3341 6386 14411 97061 99371 171746 351461 414896 654926 689981 923381 1000601 1394456 1955801 2699681 2732231 2844686 5364056 5658071 5888426 6041036 7294106 8293691 9805031 
? A larger solution is $$10^{11}+5708611$$ If this equation has infinite many solutions, this implies that we can gave arbitary large differences between two coprime numbers with the same totient value.","['number-theory', 'coprime', 'totient-function', 'elementary-number-theory']"
3603687,Almost sure convergence of average of random variables,"In my statistical inference course exercise guide, I am confronted with the following problem: Let $0<\theta<1/2$ , and define the sequence $\{X_n\}_{n\in\mathbb{N}}$ of discrete independent random variables as follows: $X_n$ takes the values $n^{\theta}$ and $-n^{\theta}$ with probabilities $P(X_n=n^{\theta})=1/2=P(X_n=-n^{\theta})$ . Show that $$\frac{1}{n}\sum_{k=1}^{n}X_k \to 0$$ almost surely. My attempt: I try to use the Borel-Cantelli lemma. If $\overline{X}_n$ denotes the average of the first $n$ variables, it would suffice to show that for every $\epsilon >0$ it holds that $$\sum_{n=1}^{\infty}P(|{\overline{X}_n}| \geq \epsilon) < \infty \tag{1}$$ A quick computation tells us that for each $n$ , we have $E[X_n] = 0$ and $\operatorname{Var}(X_n) = n^{2\theta}$ , which implies $E[\overline{X}_n]=0$ and $$\operatorname{Var}(\overline{X}_n) = \frac{1}{n^2}\sum_{k=1}^{n}\operatorname{Var}(X_k) = \frac{1}{n^2}\sum_{k=1}^{n}k^{2\theta} \tag{2}$$ If we use Chebyshev's inequality, plugging $(2)$ into $(1)$ would yield $$\sum_{n=1}^{\infty}P(|{\overline{X}_n}| \geq \epsilon) \leq \sum_{n=1}^{\infty}\frac{1}{\epsilon^2}\operatorname{Var}(\overline{X}_n) \leq \sum_{n=1}^{\infty}\frac{1}{\epsilon^2}\frac{1}{n^2}\sum_{k=1}^{n}k^{2\theta}$$ The last term of the previous inequality seems quite divergent. Any suggestions?","['borel-cantelli-lemmas', 'probability-theory', 'probability']"
3603740,Euler Class Definition (Spivak),"In the Spivak's book on Differential Geometry Euler class $\chi(\xi)$ of an oriented $k-$ plane bundle $\xi=\pi:E\to M$ is defined as $$ s^*[\omega]\in H^k(M)$$ where $s:M\to E$ is any section and $[\omega]\in H^k_c(E)$ the Thom class represented by $\omega$ closed $k$ -form with compact support on $E$ . Now for a non-zero section $s$ , if we pick $c>0$ sufficiently large, some subset of image of $M$ under the section $c\cdot s$ will lie outside of  support $\omega$ . So by definition $$\chi(\xi)=(c\cdot s)^*[\omega]=0 \in H^k(M).$$ But why is it zero? For example $\omega_{cs(p)}$ will be zero form for some $p\in M$ . Is the form then exact?","['algebraic-topology', 'differential-geometry']"
3603791,Reference request: a list of (small) finite simple groups,"I am currently in the midst of a project in which it would be useful to have a list of all (small) simple groups as a means to check calculations, not waste time, verify conjectures for small examples, etc. I found this list which enumerates all groups of order $\leq 100$ . This tells me that something like this is technically possible, and likely already exists, but I've not been able to find it. Edit: Perhaps I should have mentioned this: I do not want something like the wikipedia page which has a table of the different types of simple groups. I would like something similar to the first link , which lists all groups with order $x$ , then all groups of order $x+1$ , etc. I'm not sure how much more specificity I can add, but I'd be happy to answer any questions if I'm unclear.","['group-theory', 'simple-groups', 'reference-request']"
3603800,Kostant's connection on $\Lambda^2(M)\oplus TM$,"I'm trying to understand the equivalence Killing vector fields $\iff$ parallel sections on $\Lambda^2(M)\oplus TM$ , for a Riemannian manifold $M$ . I suppose that there exists a morphism $\phi:TM\rightarrow \Lambda^2(M)\oplus TM$ and a connection $D$ on $\Lambda^2(M)\oplus TM$ such that $\phi$ yields an isomorphism between the space of Killing vector fields and the space of parallel sections w.r.t $D$ (is it true? it can be that $\phi$ can only be defined for the Killing vector fields, not for all the vector fields...). How do I construct $\phi$ and $D$ ? I might have to use the Levi-Civita connection $\nabla$ on $M$ . Applying $\nabla$ on $X\in TM$ repeatedly I obtain $\nabla X\in T^*M\otimes TM$ and $\nabla^2 X\in \Lambda^2(M)\otimes TM$ . How can I use them to construct $\phi(X)$ ? Maybe I need to pass to local coordinates?","['connections', 'riemannian-geometry', 'differential-geometry']"
3603855,Simultaneous Diagonalizability of Multiple Commuting Matrices,"I know that for two given diagonalizable matrices $A_1$ and $A_2$ , they commute if and only if they are simultaneously diagonalizable. I was wondering if a similar condition held for multiple pairwise commuting matrices. Specifically, if we have a list of diagonalizable matrices $A_1, \cdots, A_n$ and $A_i$ commutes with $A_j$ for all $1 \leq i, j \leq n$ , then does there exist a simultaneous eigenbasis of all the $A_i$ ? That is, does there exist $S$ such that $S A_i S^{-1}$ is diagonal for all $i$ ? If this is not in general true, what kinds of non-trivial conditions are sufficient to make such a statement true?","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'linear-transformations', 'diagonalization']"
3603926,"Counting: In how many ways can you order your coffee, given the options at a coffee shop.","I came across this elementary counting problem: A coffee shop has 4 different types of coffee. You can order your coffee in a small, medium, or large cup. You can also choose whether you want to add cream, sugar, or milk (any combination is possible, for example, you can choose to add all three). In how many ways can you order your coffee? My attempt: $4*3*2^3$ . Is that correct?",['combinatorics']
3603963,The Functional-Calculus Version of the Spectral Theorem,"In the book Analysis Now by Pedersen, the Spectral Theorem is that, for a normal operator $T$ acting on a Hilbert space $H$ , there is an isometric star-isomorphism between $C(\text{sp}(T))$ and the $C^*$ -algebra that is generated by $I$ and $T$ . This star-isomorphism is called the continous functional calculus for $T$ . I am under the impression that this is the first -- or at least an early -- version of the Spectral Theorem (for the infinite-dimensional setting). First, what does this tell us, that is, why would one care about a functional calculus? Second, how does this relate to the more common multiplication-version of the the Spectral Theorem?","['spectral-theory', 'functional-analysis', 'analysis']"
3604024,Simple C*-algebras with finite representations are matrix algebras,"Let $A$ be a simple $C^*$ -algebra. I am trying to prove that $A$ admits a non-zero finite dimensional representation if and only if $A\cong M_n(\mathbb{C})$ for some $n$ . The reverse implication is trivial. For the other one, if $\varphi:A\to B(\mathbb{C}^n)$ is a non-zero finite dimensional representation of $A$ , then $\varphi$ is faithful, because $A$ is simple. Since $B(\mathbb{C}^n)\cong M_n(\mathbb{C})$ , we have that $A$ is isomorphic to a simple $*$ -subalgebra of $M_n(\mathbb{C})$ . This is as far as I can go. Any ideas on how to go on? P.S: I have seen a proof using vN algebras, but the thing is I came across this exercise in a book before the chapter on vN algebras, so I am trying to solve this without vN algebras (or irreducible representations). Also: I know the classification theorem of finite dimensional $C^*$ -algebras, but I can't use this. I want to prove this result in order to classify finite dimensional $C^*$ -algebras.","['c-star-algebras', 'abstract-algebra', 'representation-theory', 'functional-analysis']"
3604144,The structure sheaf on the disjoint union of affine schemes.,"Suppose that we consider an countable infinite sequence of rings $R_{1},R_{2},...$ . Then we can consider the disjoint union $X:=\sqcup_{i\in\mathbb{N}}\text{Spec}(R_{i})$ . Question: What does the sheaf of rings look like on $X$ ? Are we able to give a general description of the global sections on $X$ ? Intuition: My intuition would say that $\Gamma(X,\mathcal{O}_{X}) = \Pi_{i\in\mathbb{N}}\Gamma(\text{Spec}(R_{i}),\mathcal{O}_{\text{Spec}}(R_{i})) = \Pi_{i\in\mathbb{N}} R_{i}$ . But I have no clear straight argument why this should be the case.","['affine-schemes', 'algebraic-geometry', 'schemes', 'sheaf-theory']"
3604150,Unitary matrix as a product of real orthogonal and complex symmetric,Show that any unitary matrix $U$ can be written as a product of real orthogonal matrix and complex symmetric matrix. Hint: For any unitary matrix $A$ and for any $n\in \mathbb{N}$ there is unitary matrix $B$ such that $B^n=A$ . (I proved it here ) My attempt: Since $U$ is unitary then $U^TU$ is also unitary matrix then by hint one can find unitary matrix $X$ such that $X^2=U^TU$ . Then I stucked and don't know how to proceed. Would be thankful if someone can show how to solve this problem.,"['matrices', 'unitary-matrices', 'linear-algebra']"
3604214,Non-vanishing vector fields on the 2 Torus,Can you explicitly construct several non vanishing vector fields on the 2 Torus $S^1 \times S^1$ ? How can you build non zero vector fields in this particular case? Thank you in advance.,"['differential-topology', 'differential-geometry']"
3604217,"Why is it incorrect to say, $\lim_{x\rightarrow a}f(x)\notin\mathbb{C}$?","My grade $12$ calculus teacher told me I cannot write the following: $$\lim_{x\rightarrow a}f(x)\notin\mathbb{C}$$ to say that the limit does not exist. The only reasoning she gave was ""I think you should have more experience working with complex numbers before you say that."" It's been said a million times that there is no formal notation to say a limit does not exist and that it's best to just write it out or use 'D.N.E'. But I'm curious to know what is wrong with this statement mathematically. Can the limit of $f(x)$ exist and be outside $\mathbb{C}$ ? Thanks in advance.","['notation', 'limits', 'calculus', 'complex-numbers']"
3604306,Dual Space of General $L^p$ Space Which Takes Values in Banach Space,"Last week, our functional analysis course covered Riesz Representation theorem for $L^p(X,\mu),(1\leq p < \infty)$ , namely, $(L^p(X,\mu))^* = L^q(X,\mu)$ . And I was stuck with this homework problem to work out the dual space of a  more general version of $L^p$ space: Let $X$ be a Banach space and assume both $X$ and $X^*$ are known, define $L^p([0,1],X)=\{f(t):[0,1]\rightarrow X\big{|}\int_0^1 ||f(t)||^p_X\text{d}t<\infty\}$ where $||\cdot||_X $ is norm in $X$ and define similar $L^p$ norm: $||f||_p =  \big{(}\int_0^1 ||f(t)||^p_X\text{d}t\big{)}^\frac{1}{p}$ . The question is to determine what is [ $L^p([0,1],X)]^*$ ? My first guess is $[L^p([0,1],X)]^*=L^q([0,1],X^*)$ , where $\frac{1}{p}+\frac{1}{q}=1$ . To begin with, if we are given $g(s)\in L^q([0,1],X^*)$ and define $T_g\in [L^p([0,1],X)]^* $ by $$
T_g(f) = \int_0^1 g(s)(f(s)) \text{d}s
$$ Apparently, since each $g(s)$ is a linear functional of $X$ ,then $T(g)$ is a linear functional. Besides, \begin{align}
|T_g(f)|\leq\int_{0}^{1} |g(s)(f(s))| \mathrm{d} s &\leq \int_{0}^{1} ||g(s)||_{X^*}\cdot||f(s)||_X \mathrm{d} s\\ \leq (\int_{0}^{1}\|g(s)\|_{X^*}^{q} \mathrm{d} s)^{\frac{1}{q}}\cdot(\int_{0}^{1}\|f(s)\|_{X}^{p} \mathrm{d} s)^{\frac{1}{p}}
 = &||g||_{q}\cdot ||f||_p
\end{align} I use H√∂lder's inequality above. This justifies $T(g)\in $ [ $L^p([0,1],X)]^*$ and $||T_g||\leq ||g||_q$ .
However, I got stuck to preceed to verify next two things: Find $f \in L^{q}([0,1],X)$ such that $T_g(f) \geq ||g||_q$ Given $T\in \left[L^{p}([0,1], X)\right]^{*}$ , how to find $g\in L^{q}\left([0,1], X^{*}\right)$ such that $T(f)=\int_{0}^{1} g(s)(f(s)) \mathrm{d} s$ holds for any $f\in L^p([0,1],X)$ ? I try to invoke Radon- Nikodym theorem by first defining characteristic funtion $\chi_E(t) = \begin{cases}  x_0 &t\in E\\
0, & t \notin E\end{cases}$ , where $x_0$ is a unit vector in $X$ and $E \subset [0,1]$ , so we have $\chi_E \in L^{p}([0,1], X)$ . Next, we define $\nu(E) = T(\chi_E)$ , then we prove $\nu$ is indeed a signed measure and $\nu<< m$ , where $m$ denotes Lebesgue measure here. By Radon-Nikodym theorem, there exists $g:[0,1]\rightarrow \mathbb{R}$ such that $\nu(E) = \int_0^1 ||\chi_E(s)||_X\cdot g(t) \text{d}s $ but I hope to get $g:[0,1]\rightarrow X^*$ such that $\nu(E) = \int_0^1  g(s)(\chi_E(s)) \text{d}s $ One reason why the definition $T_g(f)=\int_{0}^{1} g(s)(f(s)) \mathrm{d} s$ might be reasonable is because I can let $X=\mathbb{R}$ , then $T_g(f)=\int_{0}^{1} g(s)(f(s)) \mathrm{d} s = \int_{0}^{1} g(s)\cdot f(s) \mathrm{d} s$ as the normal $L^p$ space. Sorry about the length of this question. I try to write out what I can get so far. If you have any insights, please share with me! Thanks in advance.","['banach-spaces', 'riesz-representation-theorem', 'lp-spaces', 'functional-analysis', 'dual-spaces']"
3604336,Computing the finite-dimensional marginal distributions of Brownian Bridge,"I'm working through Le Gall's Brownian Motion, Martingales, and Stochastic Calculus , and I'm struggling on an exercise. The question concerns computing the finite-dimensional marginal distributions of a Brownian bridge. In particular, let $B_{t}$ be a Brownian motion on $[0,1]$ or $\mathbb{R}^{+}$ (doesn't matter which), and for $t\in [0,1]$ define the Brownian Bridge to be $W_t = B_t - t B_1$ . I've shown that $W_t$ is a centered Gaussian process with covariance function $K(s,t) = \min\{s,t\}- st$ . I'm now asked to prove that for $0<t_1<\cdots<t_p<1$ , the law of $(W_{t_1}, \dots, W_{t_p})$ has density $$
g(w_1, \dots, w_p) = \sqrt{2\pi} \,p_{t_1}(w_1)\,p_{t_2 - t_1}(w_2 - w_1)\,\cdots\, p_{t_p - t_{p-1}}(w_p-w_{p-1})\,p_{1-t_{p}}(-w_p),
$$ where $$
p_{t}(w)= \frac{1}{\sqrt{2\pi t}}\exp(-w^2/2t).
$$ Solution Progress: Attempt 1: The density is factored into a bunch of products of Gaussian densities, where the variance of each is $t_{i}-t_{i-1}$ . This makes me want to relate the vector of Brownian Bridge terms $(W_{t_1}, \dots, W_{t_p})$ to either the vector of Brownian motion $(B_{t_1}, \dots, B_{t_p})$ or to the independent increments $(B_{t_1}-B_{0}, B_{t_2}-B_{t_1},\dots ,B_{t_p}-B_{t_{p-1}})$ . Both of these vectors have densities which are a product of individual gaussians. We note that $$
\begin{pmatrix}
W_{t_p}\\
\vdots\\
W_{t_1}
\end{pmatrix}=
\begin{pmatrix}
B_{t_p}-t_{p}B_{1}\\
\vdots\\
B_{t_1}-t_{1}B_{1}
\end{pmatrix}=
\begin{pmatrix}
-t_p&1&{}&{}&{}\\
-t_{p-1}&{}&1&{}&{}\\
\vdots&{}&{}&\ddots&{}\\
-t_1&{}&{}&{}&1
\end{pmatrix}
\begin{pmatrix}
B_{1}\\
B_{t_p}\\
\vdots\\
B_{t_1}
\end{pmatrix}
$$ I would love to use a change of variables, but the issue is that I'm required to bring in the additional $B_1$ term, and so the linear transformation above maps $p+1$ -dimensional space into $p$ dimensional space. Thus, the determinant isn't defined. I'm not sure if I'm just being stupid, or this is really a problem? Attempt 2: Another approach I've thought of is that since the density $g(w_1, \dots, w_p)$ factors into densities of differences, let's first focus on the density of $(W_1 - W_{t_p}, \dots, W_{t_2} - W_{t_1}, W_{t_1})$ . We have \begin{align*}
\begin{pmatrix}
W_{1} - W_{t_p}\\
W_{t_p}-W_{t_{p-1}}\\
\vdots\\
W_{t_2}-W_{t_1}\\
W_{t_1}
\end{pmatrix}&=
\begin{pmatrix}
(B_{1}-B_{t_p})-(1-t_p)B_{1}\\
(B_{t_p}-B_{t_{p-1}})-(t_{p}-t_{p-1})B_{1}\\
\vdots\\
(B_{t_2}-B_{t_1})-(t_2-t_1)B_{1}\\
B_{t_1} - t_{1} B_{1}
\end{pmatrix}\\
&=
\bigg\{
\begin{pmatrix}
1&{}&{}\\
{}&\ddots&{}\\
{}&{}&1
\end{pmatrix}-
\begin{pmatrix}
(1-t_p)&\cdots&(1-t_p)\\
(t_p -t_{p-1})&\cdots&(t_p - t_{p-1})\\
\vdots&{}&\vdots\\
t_{1}&\cdots&t_1
\end{pmatrix}
\bigg\}
\begin{pmatrix}
B_{1}-B_{t_p}\\
B_{t_p}-B_{t_{p-1}}\\
\vdots\\
B_{t_2}-B_{t_1}\\
B_{t_1}
\end{pmatrix}.
\end{align*} The matrix in curly braces is equal to $$
\begin{pmatrix}
1&{}&{}\\
{}&\ddots &{}\\
{}&{}&1
\end{pmatrix}
-
\begin{pmatrix}
1-t_p\\
\vdots\\
t_1
\end{pmatrix} \begin{pmatrix}1&\cdots&1\end{pmatrix}.
$$ This is a rank-p $(p+1)\times (p+1)$ matrix. And thus, change of variables is not possible. Attempt 3: Let us first consider the density of the increments $W_{t_1}, W_{t_2}-W_{t_1}, \dots, W_{t_p}-W_{t_{p-1}}, W_{1}-W_{t_p}$ , and factor it by successively conditioning $$
g(W_{t_1}, W_{t_2}-W_{t_1},\dots, W_{1}-W_{t_p})= g(W_{1}-W_{t_p}|W_{t_{p-1}}-W_{t_{p-2}},\dots, W_{t_1})\cdots g(W_{t_1}).
$$ One can compute that \begin{align*}
g(W_{t_1})&= \sqrt{2\pi} p_{t_1}(W_{t_1})p_{1-t_1}(-W_{t_1})\\
&= \frac{\sqrt{2\pi}}{\sqrt{2\pi t_1}\sqrt{2\pi (1-t_1)}}\exp\bigg( -\frac{W_{t_1}^{2}}{2t_1}\bigg) \exp\bigg(-\frac{W_{t_1}^{2}}{2(1-t_1)}\bigg)
\end{align*} This is promising, as we have the desired form for a product of distributions. The next step is computing the conditional distributions $g(W_{t_2}-W_{t_1}|W_{t_1})$ onwards.","['stochastic-processes', 'marginal-distribution', 'brownian-motion', 'probability']"
3604421,Find value of $\prod_{k=0}^{2^{1999}}\left(4\sin^2\left(\frac{k\pi}{2^{2000}}\right)-3\right)$,Find value of $$S=\prod_{k=0}^{2^{1999}}\left(4\sin^2\left(\frac{k\pi}{2^{2000}}\right)-3\right)$$ We have for $k=0$ the value as $-3$ and now for $k \ne 0$ $$S_1=\prod_{k=1}^{2^{1999}}\left(\frac{\sin\left(\frac{3k\pi}{2^{2000}}\right)}{\sin\left(\frac{k\pi}{2^{2000}}\right)}\right)$$ Letting $f(k)=\sin\left(\frac{k\pi}{2^{2000}}\right)$ we get: $$S_1=\prod_{k=1}^{2^{1999}}\frac{f(3k)}{f(k)}$$ Lets consider numerator: we have the product in Numerator with all arguments multiples of $3$ as: $$N=f(3)f(6)f(9)\cdots f(2^{1999}-2)f(2^{1999}+1)\cdots f(3.2^{1999})$$ Where as in Denominator we have the product with arguments multiples of $3$ as: $$D_0=f(3)f(6)f(9)\cdots f(2^{1999}-2) \tag{1}$$ Likewise wit arguments in denominator with reminder $1$ when divided by $3$ as: $$D_1=f(1)f(4)f(7)\cdots f(2^{1999}-1)\tag{2}$$ Likewise wit arguments in denominator with reminder $2$ when divided by $3$ as: $$D_2=f(2)f(5)f(8)\cdots f(2^{1999}) \tag{3}$$ So we have: $$S_1=\frac{N}{D_0D_1D_2}=\frac{f(2^{1999}+1)f(2^{1999}+4)\cdots f(3.2^{1999})}{D_1D_2} \tag{4}$$ Now we know that: $$f(2^{1999}-k)=f(2^{1999}+k)$$ So from backwards we can write $$D_1=f(2^{1999}+1)f(2^{1999}+4)\cdots f(2^{2000}-1)$$ Likewise from backwards we can write $$D_2=f(2^{1999})f(2^{1999}+3)\cdots f(2^{2000}-2)$$ After cancelling terms of $D_1$ from numerator in $(4)$ we get: $$S_1=\frac{f(2^{2000}+2)f(2^{2000}+5)\cdots f(3.2^{1999})}{f(2^{1999})f(2^{1999}+3)\cdots f(2^{2000}-2)}$$ I am stuck here?,"['infinite-product', 'algebra-precalculus', 'trigonometry', 'sequences-and-series']"
3604435,Solving Olympiad Functional equations: $f(xy)=f(x)f(y)$ and $f(x+z)=f(x)+f(z)$ for some $z\ne0$,"Question - Find all functions $f:\mathbb R\to\mathbb R$ such that a) $f(xy)=f(x)f(y)$ ; b) $f(x+z)=f(x)+f(z)$ , for some $z$ not equal to $0$ . My try - By taking $x=y=0$ in a) we get $f(0)=0\text{ or }1$ . I showed that case $f(0)=1$ is not possible. Then I have to show that in case $f(0)=0$ we have either $f(x)=0$ or $f(x)=x$ , which I am not able to figure out.","['functional-equations', 'functions']"
3604437,"Using the definition of sequence convergence, prove that if $\lim{y_n}=2$, then $\lim{3(y_n)^2‚àí2}=10$","Problem: Using the definition of sequence convergence, prove that if $\lim{y_n}=2$ , then $\lim{3(y_n)^2‚àí2}=10$ . Note: not allowed to use the Algebraic Limit Theorem, ONLY allowed to use the definition of sequence convergence. So I understand how to work with the epsilon proof structure when I'm just trying to show one sequence converges, but I'm confused here. $\lim{3(y_n)^2‚àí2}=10$ in my proof becomes $|{(3(y_n)^2‚àí2)-10|=|3(y_n+2)(y_n-2)|}$ .  What I am struggling with is how to go from that to the ending, $< \epsilon$ . I obviously use $\lim{y_n}=2$ so $|y_n - 2|$ < something, although I'm not quite sure what to make it less than. Can anybody help me with my proof structure here?","['limits', 'real-analysis']"
3604438,Rigid pentagons and rational solutions of $s^4+s^3+s^2+s+1=y^2$,"Gerard 't Hooft, Nobel Prize in Physics laureate, wrote three articles on what he called ""Meccano math"" ( 1 , 2 , 3 ) ‚Äì rigid constructions following rules quite similar to my earlier question on doubling the cube with unit sticks , but with the following generalisations: Sticks can be of any rational length (the formulation in 't Hooft's papers uses idealised Meccano strips of integral length, but they can be trivially scaled) Hinges can lie anywhere on a stick, not just at the ends, as long as they are at rational distances from the ends For rigid polygons, the polygon's sides can be extended One of the given constructions is a rigid pentagon with just two extra sticks. However, it does not look very nice because it requires long extensions of two sides. So I decided to make it less intrusive (in the sense of ""less occupied space outside the pentagon"") as follows. Let $r,t,s$ be the lengths of three consecutive sides of a quadrilateral, with $108^\circ=\frac{3\pi}5$ angles between them: Then it is easy to show that the fourth side length $u$ is $$\sqrt{\left((r+s)\cos\frac{2\pi}5+t\right)^2+\left((r-s)\sin\frac{2\pi}5\right)^2}$$ We want all four side lengths to be rational (but they can be negative). If $u$ is rational, so is $u^2$ , so the expression inside the square root must also be rational. Expanding it gives $$r^2+s^2+t^2-\frac{rs+rt+st}2+\frac{\sqrt5}2(rt+st-rs)$$ and for this to be rational we must have $rt+st-rs=0$ or $t=\frac{rs}{r+s}$ . Making this substitution gives $$u=\sqrt{\frac{r^4+r^3s+r^2s^2+rs^3+s^4}{r^2+2rs+s^2}}$$ Clearly we can scale any solution $(r,s,t,u)$ by any rational number, so we set $r=1$ arbitrarily: $$u=\sqrt{\frac{s^4+s^3+s^2+s+1}{s^2+2s+1}}=\frac{\sqrt{s^4+s^3+s^2+s+1}}{|s+1|}$$ Thus, up to scale, all rational solutions correspond one-to-one with solutions of $$s^4+s^3+s^2+s+1=y^2\qquad s,y\in\mathbb Q,s\not\in\{0,-1\}\tag1$$ The same equation has been posed on this site before , but only with integers, and I could not find any good reference in this answer . By Faltings's theorem there are only finitely many solutions, but have I found all of them? Is it true that $(1)$ has a solution only if $s$ or $1/s$ is in $\left\{3,\frac{808}{627},-\frac{11}8,-\frac{123}{35}\right\}$ ? References would be much appreciated. The solution with $s=-\frac{11}8$ in particular gives a much less intrusive rigid pentagon. (All black sticks below, sides of the pentagon, are of unit length.) Edit: The sequence of $s$ values is now in the OEIS! Numerators at A339325 , denominators at A339326 .","['geometric-construction', 'number-theory', 'geometry', 'diophantine-equations', 'recreational-mathematics']"
3604475,Did Archimedes squared the circle?,"What i can't understand is that  I'm reading book "" a History of Mathematics by boyer"" and it says Archimedes made possible to construct a triangle equal in area to that of a circle by help of spirals. Etc..
And then it says "" with a simple geometric  transformation you can produce a square out of it.
But, wait. isnt the squaring of circle concidered impossible all the time.
I am very confused. Plz help me understand.","['pi', 'circles', 'geometry']"
3604480,How to prove this inequality $x^2_{n}\le\frac{8}{3}$,"let sequence $\{x_{n}\}$ such $x_{1}=0,x_{2}=1$ ,and $$x_{n+1}=\left(1+\dfrac{1}{n}\right)x_{n}-x_{n-1},n\ge 2$$ show that $$x^2_{n}\le\dfrac{8}{3}$$ This problem it seem interesting,and $$x_{n+1}-x_{n}=\dfrac{1}{n}x_{n}-x_{n-1}$$ so we have $$x_{n+1}-x_{1}=\sum_{k=1}^{n}\dfrac{x_{k}}{k}-\sum_{k=1}^{n-1}x_{k}$$ where $x_{0}=-1$ It seem this problem very interesting,I guess this $\dfrac{8}{3}$ maybe is not best constant,But is stronger constant","['inequality', 'sequences-and-series']"
3604607,Can I work out the variance in batches?,"So I have a data divided into chunks, and I can only calculate the variance in each of the chunks because of software limitations. But I want to get the variance of the whole data together, not the chunks. 
I know the variance is not a linear operator. 
I would like the get kind of the average of the variance but this will have to be the same number as If I calculated the variance of the whole data together. Example:
Rolling a dice in 3 groups of 2 rolls I can calculate the variance on each of the groups, so I with this data, I want to calculate the variance of the whole set: rolling a dice 6 times.
Thank you for your help.","['statistics', 'variance', 'probability']"
3604650,On the convergence of the series $\sum \frac{(-1)^{\lfloor ne\rfloor}}{n}$,"The question is pretty simple: It the series $\sum \frac{(-1)^{\lfloor ne\rfloor}}{n}$ convergent or
  not ? As usual in this situation we let $S_n:=\sum_{k=0}^n(-1)^{\lfloor ne\rfloor}$ and apply an Abel transform to the original series. Thus the convergence of the original series is equivalent to that of $\sum \frac{S_n}{n^2}$ . We have the obvious bound $S_n = O(n)$ . However in order to conclude one might need to achieve a bound of the form $S_n=O(n^{\alpha})$ for some $\alpha <1$ . Does anyone know a proof of this fact? (Or a proof for the original quesiton).","['ceiling-and-floor-functions', 'equidistribution', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
3604661,Inequality involving the angle bisectors of a triangle,"Let $l_a,l_b,l_c$ denote the lengths of angle bisectors of a triangle with sides $a,b,c$ and semiperimeter $s$ . I am looking for the best constant $K>0$ such that $$l_a^2+l_b^2+l_c^2> K s^2.$$ I found that $K=2/3$ works, but I suspect that best constant is $K=8/9>2/3$ . Any proof or reference? BTW it is known that $l_a^2+l_b^2+l_c^2\leq s^2$ . Proof for $K=2/3$ . According to Cut-the-knot , $$m_a l_a+m_b l_b+m_c l_c\ge s^{2}$$ where $m_a,m_b,m_c$ are the medians. Therefore, by Cauchy‚ÄìSchwarz inequality, $$(m_a^2+m_b^2+m_c^2)(l_a^2+l_b^2+l_c^2)\geq (m_a l_a+m_b l_b+m_c l_c)^2\geq s^4$$ which implies $$l_a^2+l_b^2+l_c^2\geq \frac{s^4}{m_a^2+m_b^2+m_c^2}> \frac{2s^2}{3}$$ in view of $$m_a^{2}+m_b^{2}+m_c^{2}=\frac{3(a^2+b^2+c^2)}{4}< \frac{3s^2}{2}.$$ EDIT. I found a reference that $K=8/9$ is the best constant. See 11.7. at p. 218 in Recent Advances in Geometric Inequalities by Mitrinovic et al.
No proof is given.","['buffalo-way', 'geometry', 'triangles', 'geometric-inequalities', 'inequality']"
3604723,Function spaces on manifolds via category theory,"In order to define function spaces on manifolds one usually follows the same recipe and this begs for a categorial formulation. I would like to know whether there is a reference that discusses this in some detail. Here is an example of what I have in mind: Let $E$ be a function space on $\mathbb{R}^d$ , say $E=L^2(\mathbb{R}^d)$ or some Sobolev space. Then for $U\subset \mathbb{R}^d$ define $E_c(U)$ to consist of restrictions to $U$ of elements in $E$ with support compactly contained in $U$ . Then $E_c(U)$ admits a natural Frechet space structure and for the examples above any diffeo $U\cong V$ of subsets of $\mathbb{R}^d$ induces an isomorphism $E_c(U)\cong E_c(V)$ of Frechet spaces (coordinate invariance). Now if $M$ is a manifold, then one can define $E_c(U)$ whenever $U\subset M$ is a chart domain and for general $U$ via a partition of unity argument. The two properties that allowed us to make the construction above are:
1) Elements of $E$ can be restricted, we can e.g. assume that $E$ embeds into the space of distributions on $\mathbb{R}^d$ and use the natural restriction there.
2) The local spaces $E_c$ are coordinate invariant. I assume that there the construction can be formalised in the following way: For any function space $E$ with the properties 1) and 2) there exists a functor $\mathcal E_c: \mathsf{Man}\rightarrow \mathsf{LCTVS}$ from the category of smooth manifolds to the category of locally convex topological spaces such that $\mathcal{E}_c(U) \cong E_c(U)$ in a natural way when $U$ is an open subset of $\mathbb{R}^d$ .  What I am interested in is whether this in turn gives rise to a functor $E \mapsto \mathcal{E}_c$ with nice properties, e.g preserving compact embeddings, exact sequences and so on. One very concrete example that I am interested in occurs in the setting of pseudodifferential operators. On $\mathbb{R}^d$ they are easy to define and one proofs e.g. that the symbol map gives rise to a short exact sequence of Frechet spaces. The same result is true on closed manifolds and I believe that this should follow from abstract nonsense.","['category-theory', 'analysis', 'differential-geometry']"
3604774,Prove that $f(x) \to L$ and $g(x) \to M$ as $x \to x_0$ and $f(x) \leq g(x)$ implies that $L \leq M$,"Here's what I'm trying to prove: Let $f$ and $g$ be functions. Suppose that the following hold: $f(x) \leq g(x)$ $\lim_{x \to x_0} f(x) = L$ and $\lim_{x \to x_0} g(x) = M$ Then, $L \leq M$ Proof Attempt: By hypothesis, for any $\epsilon > 0$ , there exist $\delta_1,\delta_2 > 0$ such that: $0 < |x-x_0| < \delta_1 \implies |f(x) - L| < \epsilon$ $0 < |x-x_0| < \delta_2 \implies |g(x) - M| < \epsilon$ Let $\delta = \min\{\delta_1,\delta_2\}$ . Then, if we have $0 < |x-x_0| < \delta$ , we get: $L-\epsilon < f(x) \leq g(x) < M + \epsilon$ $\implies 0 < (M-L) + 2\epsilon$ Suppose that $M-L < 0$ . Let $\epsilon = \frac{L-M}{2}$ . Then, this gives us: $0 < (M-L) + (L-M) = 0$ That is an absurdity. Hence, $M-L \geq 0$ so $M \geq L$ . That proves the desired result. Does the proof above work? If it doesn't, why? How can I fix it?","['limits', 'calculus', 'solution-verification', 'real-analysis']"
3604897,Distances from Morley triangle to edges of the original triangle,"Morley's trisector theorem states that in any triangle, the three points of intersection of the adjacent angle trisectors form an equilateral triangle, as illustrated in the left-hand diagram below.  Let's call this equilateral triangle the Morley triangle and its edge length $m$ . I am interested the distances from the Morley triangle to the edges of the original triangle as illustrated in blue in the right-hand diagram. Empirically it seems that these distances lie between $\frac{\sqrt 3}{2}m$ and $m$ , depending on the angles of the original triangle. Is there simple proof?","['alternative-proof', 'euclidean-geometry', 'triangles', 'geometry']"
3604941,How do you compute this integral?,I obtain this using mathematica: $$\int_{-\pi}^\pi(2+2\cos t)^a\cos(b t)dt=\frac{2\pi\Gamma(1+2a)}{\Gamma(1+a+b)\Gamma(1+a-b)}.$$ This should hold for $\Re(a)>-1/2$ .,"['integration', 'complex-analysis', 'complex-integration']"
3604966,Wald‚Äôs identity for Brownian motion with $E[\sqrt T]<\infty$.,"It's the Exercise 3.3.35 of Karatzas and Shereve: Brownian Motion and Stochastic Calculus on page 168. Let $W=\{W_t,\mathscr{F}_t; 0\leq t<\infty\}$ be a standard, one-dimensional Brownian motion, and let $T$ be a stopping time of $\{\mathscr{F}_t\}$ with $E[\sqrt T]<\infty$ . Prove that $$E[W_T]=0, E[W_T^2]=E[T].$$ For each $t>0$ , we have $$E[W_{T\wedge t}]=0, E[W_{T\wedge t}^2]=E[T\wedge t].$$ It suffices to show that $W_{T\wedge t}$ converges to $W_T$ as $t\to\infty$ in $L^2$ and thus in $L^1$ . If $E[T]<\infty$ , this post gives a proof. But here we only have $E[\sqrt T]<\infty$ . By the Burkholder-Davis-Gundy inequality , $$E[\sup_{0\leq s\leq T}|W_s|]\leq CE[\langle W\rangle_T^{1/2}]=CE[\sqrt T]<\infty,$$ hence $W_{T\wedge t}$ converges to $W_T$ as $t\to\infty$ in $L^1$ and now the first identity follows. As for the $L^2$ convergence, I have no idea. Any help would be appreciated.","['martingales', 'stopping-times', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
3604978,What subgroup of $Sym(X)$ is generated by the elements of order $2$?,"Given a set, $X$ , let $H(X)$ denote the subgroup of $Sym(X)$ generated by the elements of order $2$ . If $X$ is finite, $Sym(X)$ is generated by transpositions, so $H(X)=Sym(X)$ . I think that $H(X)=Sym(X)$ when $X$ is uncountable, too. The argument essentially comes to down to showing that one can construct a permutation of each possible cycle type. If $X$ is countably infinite, I think $H(X)$ contains every element with the following property $(\star)$ : When $\sigma$ is expressed as the product of (possibly infinitely many) disjoint cycles, none of these cycles is co-finite. I suspect that either $H(X)=Sym(X)$ or $H(X)=\{\sigma:\sigma\text{ satisfies }\star\}$ , but I haven't found a way to determine which case it is. For example, I haven't determined whether $H(\mathbb{Z})$ contains the permutation $n\mapsto n+1$ (which does not satisfy $\star$ ). So, my questions are: Does $H(X)=Sym(X)$ for all $X$ ? And, if not, what do the exceptions look like?","['permutations', 'group-theory', 'combinatorics', 'infinite-groups']"
3605047,Surjective vector field on $\mathbb{R}^n$,"Let $V: \mathbb{R}^n \rightarrow \mathbb{R}^n$ be continuous with the property $$\frac{\langle V(x), \, x\rangle}{|x|} \, \to \infty \quad \text{as} \quad |x| \to \infty  \qquad \qquad (1)$$ where $\langle \cdot \, , \cdot \rangle$ denote the standard inner product and $| \cdot | = \sqrt{\langle \cdot \, , \cdot \rangle}$ is the Euclidian norm on $\mathbb{R}^n$ . I have to show that $V$ is surjective. My attempt: Take $z \in \mathbb{R}^n$ and define $\varphi: \mathbb{R}^n \rightarrow \mathbb{R}^n, \, \varphi(x): = V(x) - z$ . The aim is to show that $\varphi$ has a zero. So assume by contradiction that $\varphi(x)\neq 0 \, \, \, \forall \, x \in \mathbb{R}^n$ . Let $R > 0$ . We define an auxiliary function $\psi : \mathbb{R}^n \rightarrow \mathbb{R}^n, \, \psi(x): = R \cdot \frac{\varphi(x)}{|\varphi(x)|}$ . Then, $\psi$ is a continuous self-mapping $\psi: \overline{B}_R(0) \rightarrow \overline{B}_R(0)$ with $\text{im}(\psi) \subset \partial B_R(0)$ . Using Schauder's fixed point theorem, there exists $x_0 \in \overline{B}_R(0)$ s.t. $\psi(x_0) = x_0$ . In particular, $x_0 \in \partial B_R(0)$ . Now, I tried to get a contradiction with the assumption $(1)$ taking $R \to \infty$ without success. (Maybe it's not the right thing to do) Any suggestions? Thanks in advance!","['vector-fields', 'fixed-point-theorems', 'analysis', 'real-analysis', 'functions']"
3605198,"Prove $(x^a-1)(y^b-1)\geq (1-x^{-b})(1-y^{-a})$ where $x,y\geq 1$ and $a,b \geq 0$.",I am trying to see if the inequality always holds. The RHS of course is always $\leq 1$ whereas the LHS can be greater than 1. Any suggestions greatly appreciated.,"['multivariable-calculus', 'algebra-precalculus', 'analysis', 'inequality']"
3605255,"If $N$ is the least normal subgroup of $A*B$ containing $A$, then $(A*B)/N \cong B$.","If $N$ is the least normal subgroup of $A*B$ containing $A$ , then $(A*B)/N \cong B$ . My Proof: Let $f:A \to B$ be the homomorphism given by $f(a) = e_B$ . Note that $1_B:B \to B$ is also a homomorphism. Therefore, by the Universal Property of $A*B$ , there exists a unique group homomorphism $\eta:A*B \to B$ where $\eta \circ i_A = f$ and $\eta \circ i_B = 1_B$ (where each $i_X$ is the inclusion map $i_X:X \to A*B$ ). Since $1_B = \eta \circ i_B$ is surjective, so is $\eta$ . Additionally, note that $\ker(\eta) = \langle \langle A \rangle \rangle = N$ (I have no idea whether this is true or not). Therefore, by the First Isomorphism Theorem of Group Theory, there exists an isomorphism $(A * B)/\ker(\eta) \to B$ . Therefore, $(A * B)/N \cong B$ . The part of the proof I'm having trouble with is finding a suitable homomorphism $f:A \to B$ so that $\ker(\eta) = N$ . In particular, I am unsure how to show that $\ker(\eta) = N$ in any case. There is a question here asking about what the least normal subgroup is; however, it never gained any traction. Additionally, there is another question If $N$ is the normal subgroup of $A\ast B$ generated by $A$ , then $(A\ast B)/N\cong B$ , which is similar to mine. Is my proof on the right track? How do I find a suitable homomorphism $f$ and how would I prove that $\ker(\eta) = N$ ? Thanks for any help.","['group-theory', 'abstract-algebra', 'solution-verification', 'free-product']"
3605280,Is $\lim_{n\to \infty}f(x_n)=f(\lim_{n\to \infty}x_n)$ always true?,"I was studying about sequences of numbers and their limits. My book states the standard rules for algebra of limits involving sums, differences, products and quotients of convergent sequences. But the author, while solving an example problem implicitly used the fact that $$\lim_{n\to \infty}\sqrt{\frac{1}{n+1}} = \frac{1}{\sqrt{\lim_{n\to \infty}(n)+1}}=0$$ But my question is can we generalise this result to be applicable to all types of functions... I found this answer for composite functions - limit of composite function underlying principles and special cases But since the definitions of limits of number sequences and limit of a function are different, how do we formally prove the following result (this is not a composite function as such..)? $$\lim_{n\to \infty}{f(x_n)}=f(\lim_{n\to \infty}{x_n})\ \ where  \ \ n\in \mathbb N$$ Here $x_n$ is a sequence of real numbers and its range is contained in the domain of $f$ . Also, is this result applicable in all cases..if not...when can it be used.. I am specifically looking for a formal proof of the statement..in those cases where it is applicable Thanks for any answers!!","['real-analysis', 'calculus', 'functions', 'sequences-and-series', 'limits']"
3605346,"If $X$ is a totally disconnected space, then is $\beta(X)$ totally disconnected?","I know that when $X$ is a normal and totally disconnected space, the Stone-Cech compactification $\beta(X)$ is totally disconnected. But I can't find a counterexample when considering $X$ totally disconnected only.","['general-topology', 'compactification', 'examples-counterexamples', 'connectedness']"
3605368,An easy pigeonhole principle problem: Please critique my mathematical reasoning.,"Imagine a $9 \times 9$ square array of pigeonholes, with one pigeon in each pigeonhole. Suppose that all at once, all the pigeons move up, down, left, or right by one hole. (The pigeons on the edges are not allowed to move out of the array.) Show that some pigeonhole winds up with two pigeons in it. Let each side of the square be n. There are $n^2$ pigeons and pigeonholes. If the pigeons are shifted in any direction, then there will be n empty pigeonholes on the side opposite to the direction. Furthermore, now $n^2$ pigeons are trying to fit into $n^2 - n$ pigeonholes. We can invoke the pigeon hole principle as follows: Let the entire set of pigeons be $X$ and the set of pigeonholes to be populated after the shift be $Y$ .  For $X$ and $Y$ and for some integer $k$ , if $X > k Y$ , and $f X: \to Y$ , then $f(x) = \ldots = f(x {\rm till\ index}\ k+1)$ . So, $81 > 72 k$ which means $k > 1.125$ which means $k = 2$ . This means that there are at least $3$ instances with $2$ pigeons in it. Now intuitively I know there ought to be $9$ instances. Where did I go wrong? Forgive me if I have butchered the whole thing. I am new to this type of math.","['pigeonhole-principle', 'solution-verification', 'discrete-mathematics']"
3605380,Approximating reals with rationals,"I don't have any particular motivation for this question, it just popped into my head. We play the following game: you give me a real number between 0 and 1, and I have to do my best to approximate it as a rational number with a limit on the size of the denominator. More formally, you choose $x \in [0,1]$ , and I have to come up with a pair of integers $p,q \leq N$ that minimize the error: $$
E = \bigg| x - \frac{p}{q} \bigg|
$$ For a given $N$ , how should you choose $x$ to make me incur the largest possible error? I made a plot to see how all the possible fractions fall on the number line for each $N$ between 1 and 100. It has a rather interesting pattern which seems to have a fractal nature. For any $N$ , the hardest choices of $x$ seem to be at the extremes of the interval: between 0 and the smallest possible fraction larger than 0, and between 1 and the largest possible fraction smaller than $1$ .","['approximation', 'irrational-numbers', 'real-analysis', 'fractions', 'rational-numbers']"
3605417,Why is the interior of $\{(x_n)_n \in {\displaystyle \ell ^{2}}| \sum_{n=1}^{\infty}n^2|x_n|^2 < \infty\}$ empty?,Let $M=\{(x_n)_n \in {\displaystyle \ell ^{2}}| \sum_{n=1}^{\infty}n^2|x_n|^2 < \infty\}$ . How can I show that the interior of M is empty? I already showed that M is convex but I'm not sure if that's helping.,['functional-analysis']
3605430,Jordan matrix of $A$ and $A^{-1}$,"Suppose I have the Jordan normal form of a matrix $A$ . I need to find the the Jordan normal form of $A^{-1}$ . I have the following suggestion: $$J_{\lambda,n}\rightarrow J_{1/\lambda,n} $$ where $J_{\lambda,n}$ is a Jordan block of $A$ , $J_{1/\lambda,n}$ is a Jordan block of $A^{-1}$ . We can see that if $\lambda $ is an eigenvalue of $A$ then $1/\lambda$ is an eigenvalue of $A^{-1}$ because $$Av=\lambda v \Leftrightarrow   A^{-1}\lambda v=v\Rightarrow \mu=1/\lambda$$ but how can we make sure that $J_{\lambda,n}$ has the same dimension as $J_{1/\lambda,n}$ ? Thank you in advance.","['matrices', 'jordan-normal-form', 'linear-algebra', 'inverse']"
3605529,Steady state of a system of ordinary differential equations,"I have a system of four ordinary differential equation. This is a modelling problem we were also meant to criticize some of the issues with the way the problem was presented. Its meant to describe the nitrogen concentration in the available nutrients for an ecosystem. 
Where $N_c= N+P+Z+D = constant $ $$
\frac{dN}{dt} = -ulP\frac{N}{K_s + N} +aD + (1- \mu)hPZ\\ 
\frac{dP}{dt} = ulP\frac{N}{K_s + N} - hPZ - sP\\
\frac{dZ}{dt} = \mu hPZ -eZ \\
\frac{dD}{dt} = eZ +sP -aD
$$ Apart from $N,P,Z,D$ we consider all other terms constant. I note we were not given an explanation to all the other terms. We were told there were four steady solutions, two of which are relatively easy to find. I am struggling to understand how to find steady solutions. Could anybody please help with these ? Thanks not experienced with differentials. Edit: Helpful Reference for contextualization http://mpe.dimacs.rutgers.edu/2013/11/26/ocean-plankton-and-ordinary-differential-equations/","['self-learning', 'systems-of-equations', 'mathematical-modeling', 'ordinary-differential-equations']"
3605532,Student Seeking Beginning Calculus Advice [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 4 years ago . Improve this question I am a junior in high school and I am seeking advice on where I should begin learning calculus. I have just completed trigonometry as a school class, and I have to admit I enjoyed it. During the course, I consistently felt that learning trigonometry through school was too slow, and it made me want to start learning mathematics on my own. I am fascinated with math, and I want to begin learning higher-level mathematics as soon as possible. As you can probably see, I am a complete beginner when it comes to knowing about the different calculus classes. I do not know the difference between any of the different calculus classes and I am simply seeking guidance as to which one I should begin first. I would appreciate any advice you can give me. Thank you for your time. Note: This question is not limited to calculus advice. I am merely looking for guidance on the next step I should take in my mathematical career. If that means combinatorics, abstract algebra or something else that is unrelated to calculus, I completely welcome that as well. I have just been told that calculus is the most reasonable next step.","['self-learning', 'advice', 'calculus', 'linear-algebra', 'algebra-precalculus']"
3605547,Product rule for codifferential on manifolds,"Let $(M^n,g)$ be a Riemannian manifold. It is well known that the following identity holds: $$ d(\alpha \wedge \beta) = (d\alpha) \wedge \beta + (-1)^p \alpha \wedge (d \beta) $$ where $\alpha$ is a $p$ -form on $M$ and $\beta$ is a $q$ -form on $M$ . Is there a formula for the codifferential of a wedge product? That is, can we express $\delta(\alpha \wedge \beta)$ in terms of $\delta \alpha$ and $\delta \beta$ (and possibly $d \alpha$ and $d \beta$ )? Just recalling: $\delta$ is defined as being equal to $(-1)^{n(k-1)+1}\ast d \ast$ acting on $k$ -forms.","['differential-forms', 'smooth-manifolds', 'differential-geometry']"
3605617,Information Bottleneck - Proof of Algorithm,"In the Information Bottleneck (IB) paper ( https://arxiv.org/pdf/physics/0004057.pdf ). Using lagrange multipliers we need to solve $\frac{\delta F}{\delta p(\tilde{x}|x)}=0$ , where $F = I(X;\tilde{X})+\beta d(x,\tilde{x})$ . By substituting $I(X;\tilde{X})=\sum_{x,\tilde{x}}p(x,\tilde{x})log(\frac{p(\tilde{x}|x)}{p(\tilde{x})})$ and taking the derivative of $F$ , the paper writes down the solution as follows, $\frac{\delta F}{\delta p(\tilde{x}|x)}= p(x)[log(\frac{p(\tilde{x}|x)}{p(\tilde{x})})+1-\frac{1}{p(\tilde{x})}\sum_{x'}p(x')p(\tilde{x}|x')+\beta d(x,\tilde{x})+\frac{\lambda(x)}{p(x)}]$ . Question: I don't understand how it gets the term "" $-\frac{1}{p(\tilde{x})}\sum_{x'}p(x')p(\tilde{x}|x')$ ""? The rest of the terms are clear but I cannot understand only this term.",['derivatives']
3605626,Proving $\liminf_{n\to\infty} X_n \ge x_0$ a.s. for a sequence of random variables,"Assume that for a sequence of random variables $(X_n)$ one has $\lim_{x\to -\infty}\lim_{a\to 0}\lim_{n\to\infty} P[X_n \ge x_0(1-a)+a\cdot x]=1.$ Does this imply $\liminf_{n\to\infty} X_n\ge x_0$ almost surely? Edit: I've tried to prove $P[\liminf \{M_n \ge x_0\}]=1$ directly via $\sigma$ -continuity and estimates but failed. I think that $\lim_{a\to0} P[ \liminf \{X_n \ge x_0(1-a)+ax\}] = P[\bigcap_{a>0}  \liminf \{X_n \ge x_0(1-a)+ax\}] =P[\liminf \{X_n \ge x_0\}]$ and similarly for the limit of $x$ , but I don't see how to use the limit of $n$ to infinity. Is there a weaker condition for $\liminf X_n\ge x_0$ a.s. than $P[\liminf \{X_n \ge x_0\}]=1$ one could use in this case?","['limsup-and-liminf', 'probability-theory', 'sequences-and-series']"
3605684,Prove $\sum_{i=1}^{n}v_i^t \cdot v_i = I$ for orthonormal base,"Let $$
\{v_1,..,v_n\} 
$$ Be an orthonormal base in $R^n$ with the standard inner product. I need to prove that: $$
\sum_{i=1}^{n}v_i^t \cdot v_i = I
$$ Where $v_i$ is a row vector. What i tried: I tried to look at an example but still - i dont feel its getting me somewhere. Lets take $R^2$ The base will be: $$
\{v_1,v_2\}
$$ Let $v_1 = [a_1,a_2], v_2 = [b_1,b_2]$ As an orthonormal base we know that: $$
||v_1|| = ||v_2|| = 1
$$ And: $$
<v_1,v_2> = 0
$$ Therefore: $$
||v_1||^2 = a_1^2 + a_2^2 = 1, ||v_2||^2 = b_1^2 + b_2^2 = 1
$$ $$
<v_1,v_2> = a_1b_1 + a_2b_2 = 0
$$ $$
\sum_{i = 1}^{n = 2}v_i^t \cdot v_i = 
\begin{bmatrix} a_1^2&a_2a_2 \\ a_2a_1&a_2^2\end{bmatrix} + \begin{bmatrix} b_1^2&b_2b_2 \\ b_2b_1&b_2^2\end{bmatrix}
$$ But i dont see how i get here to $I_2$ ? Am i even in the right direction? what am i missing? I would prefer a hint than a full answer - as those are my homework. And thanks for the help.","['inner-products', 'linear-algebra']"
3605698,How many rounds (not matches) must there be in a fair single elimination tournament with 351 participants?,"Is it possible to give a sketch/outline of how this problem is approached and not just the answer? The way I attempted to solve this problem was by matching up the number of participants with each other for a match. So for round 1: 350/2 = 175 matches with 1 person getting a free pass. Since there are 175 matches that means there are 175 losers since they have a 1-1 correspondence, leaving 176 remaining contestants (351-175). I basically repeated the same logic from here on out.
Round 2: 176/2 = 88 matches with no people passing free.
round 3: 88/2 = 44 matches
round 4: 44/2 = 22 matches
round 5: 22/2 = 11 matches
round 6: 10/2 = 5 with 1 person getting a pass
round 7: 4/2 = 2 matches with 1 person getting a pass.
round 8: 2/2 = 1 match with no passes. This leaves the 3 people that got passes left, meaning there are an additional 2 rounds? Adding up to a total of 10 rounds? I don't think this is the right solution and it also feels pretty brute force, any help would be appreciated!","['combinatorics', 'discrete-mathematics']"
3605788,If a operator $A$ in Hilbert space is positive then $A$ is self-adjoint?,"Let $H=(H,(\cdot,\cdot))$ be a Hilbert space and $A:D(A)\subset H \longrightarrow H$ a linear operator (not necessarily bounded) such that $\overline{D(A)}=H$ and $A \geq 0$ , that is, $$(A(x),x)\geq 0,\: \forall \: x \in D(A).$$ Then $A$ is self-adjoint? I know that if $A:H \longrightarrow H$ is linear and bounded and $A\geq 0$ then $A$ is self-adjoint. I would like to know if this result is more general?","['hilbert-spaces', 'self-adjoint-operators', 'adjoint-operators', 'functional-analysis']"
3605827,What's known about $\sum_{n=1}^\infty\frac{1}{\sigma_s(n)}$?,"Let $$\sigma_s(n)=\sum_{d|n} d^s$$ $$f(s)=\sum_{n=1}^\infty\frac{1}{\sigma_s(n)}$$ (1) Is it possible to prove that $f$ converges for $s>1$ ? (2) Is there anything that can be said about an analytic continuation of $f$ ? Namely, is there a unique analytic continuation to $\mathbb{C} \setminus\{1\}$ ? Here's what's clear to me: $f$ diverges at $s=1$ . Let $\mathbb{P}$ denote the prime numbers. $$f(s)> \sum_{p\in\mathbb{P} } \frac{1}{\sigma_s(p)}=\sum_{p\in\mathbb{P}}\frac{1}{1+p^s}$$ And this last expression converges iff $P(s)$ the prime zeta function converges. So in particular $f(s)$ is divergent at $s=1$ .","['complex-analysis', 'convergence-divergence', 'zeta-functions']"
3605877,"If you draw 26 cards from 52 cards, what is the probability that you get 4 kings?",The 52 cards of a standard playing card deck are randomly distributed to two persons: 26 cards to each person. Find the probability that the first person receives all four Kings. Note: The 52 cards include four Kings. I had this question in my probability exam and my answer was $$ \frac{ {4 \choose 4} . {48 \choose 22}}{52 \choose 26} $$ However the teaching assistant's answer was $(\frac{1}{2})^4 = \frac{1}{16}$ as each card has a probability $\frac{1}{2}$ to go to either of the 2 persons Which answer is correct?,"['solution-verification', 'combinatorics', 'probability']"
3605928,How do you calculate icosahedron vertex positions in spherical coordinates?,"The Wikipedia page for regular icosahedrons says the following: The locations of the vertices of a regular icosahedron can be
described using spherical coordinates, for instance as latitude and
longitude. If two vertices are taken to be at the north and south
poles (latitude $\pm90¬∞$ ), then the other ten vertices are at latitude $\pm\arctan(\frac12)\approx\pm26.57¬∞$ . These ten vertices are at evenly spaced
longitudes ( $36¬∞$ apart), alternating between north and south latitudes. I understand the first and last parts of this. I understand having vertices at latitude $\pm90¬∞$ . I also understand putting the other vertices at longitudes $36¬∞$ apart, since there are 5 vertices on each of the pentagonal pyramids ( $360¬∞ \div 10 = 36$ ). What I don't understand, is why the latitudes are at $\pm\arctan(\frac12)\approx\pm26.57¬∞$ . Looking at an icosahedron from the side, it certainly looks like the the middle section forms a 2:1 rectangle (depending on orientation). I'm having trouble mathematically proving this, however. My question is, how did they arrive at $\pm\arctan(\frac12)\approx\pm26.57¬∞$ ? How was this derived?","['spherical-coordinates', 'geometry']"
3605973,What is wrong with my summation solution to this integral?,"Okay so I am a calculus student and found the following integration problem: $$\int f(x)f'(x) dx$$ Through integration by parts the solution is... $$\frac{f^2(x)}{2}+C$$ Pretty cool problem. Next I thought why not try $\int f(x)f''(x)dx$ ?
So I did that and through two applications of integration by parts I am left with the identity 0=0. Not helpful. I move on to $\int f(x)f'''(x)dx$ . Two applications of integration by parts proves more useful here, I get the solution $$f(x)f''(x)-\frac{[f'(x)]^2}{2}+C$$ So at this point all the by partsing is leaving me pretty lazy. I have the conjecture that given odd z in the following formula, integration by parts (however many times) will provide a nice solution and with even z trivial identities will result. I'm too lazy to go out beyond n=3 and just skipped to attempting to integrate this thing in full generality. $$\int f(x)f^{(z)}(x)dx$$ So I keep integrating by parts over and over and over and I notice a pattern... $$\int f(x)f^{(z)}(x)dx = f(x)f^{(z-1)}(x)-f'(x)f^{(z-2)}(x)+f''(x)f^{(z-3)}(x)-f'''(x)f^{(z-4)}(x)+...$$ Hmmmm. I came up with the following. $$\int f(x)f^{(z)}(x)dx = \sum_{n=0}^{\infty}[(-1)^nf^{(n)}(x)f^{(z-n-1)}(x)]$$ Upon testing the results are interesting. For z=1 and only one term you get $$f^2(x)$$ Hmmmm, close but where did the 1/2 coefficient go? My guess is that in solving that original problem at the top of my post, its one of those integration by parts problems in which the second integral is also the problem's integral so you just solve for it and that is where the 1/2 pops out. So when using this series, that second integral never comes out as integration by parts is done forever, hence no 1/2.
For z=2 the results are interesting but I don't know where to stop as I haven't actually solved z=2. Moving on to z=3 I get $$f(x)f''(x)-[f'(x)]^2$$ after two terms. Close to the solution but again missing the 1/2 coefficient, this time on the last term. So ultimately my question is what is wrong with my summation solution to the general integral? A. why can't I just add up all the terms to infinity to get my solution for any z instead of stopping and B. when I know at how many terms to stop why is the solution always off by the coefficient on the final term? I hate that this summation doesn't work even through it appears that it should. Maybe I am just dumb and making a stupid mistake.","['integration', 'calculus']"
3605991,"Prove or disprove: if $f:(0,1)\to\mathbb{R}$ is twice differentiable and $f$ and $f'$ are bounded then $f''$ is bounded.","I believe this is not true and I wonder if this is a correct counterexample:
Define $F: [0,1] \to \mathbb{R}$ by $F(0)=0$ and $F(x)=\sin (1/x)$ elsewhere. Then define $f(x)=\int_{0}^{x} F$ . Then $f$ is differentiable and bounded on $(0,1)$ and $f'(x)=\sin (1/x)$ . On the other hand, $f''(x)=-(1/x^2) \cos (1/x)$ . Is this counterexample correct and or is there any flaw in my reasoning? Is there a function $f$ not defined in terms of integrals which does not satisfy the given property?","['derivatives', 'real-analysis']"
3606010,Why is cartesian product of $A\times\varnothing=\varnothing$,"I am studying some preliminaries of set theory. I have a question why is Cartesian Product of $A\times\varnothing=\varnothing$ not the set $\{(a,\varnothing)~\mid~a\text{ belongs to }A \}$ using the definition of $A\times B=\{ (a, b)~\mid~a\text{ belongs to }A,~b\text{ belongs to }B\}$ ? Can someone please explain!",['elementary-set-theory']
3606038,Recurrence relation of Sn that depends on Sn-1,"OK, so I have run into this weird question about recurrence relations that I cannot complete by myself (first year comp. sci. student and first discrete math class, studying by myself). To help you better understand the question, I have written some examples right next to them (eg.). Here it is: A password is valid if it contains an odd number of the digit 9 (eg. 1239499786 is valid but 129789945698 is not). Lets say that $S_n$ is the number of valid passwords that have $n$ digits. I need to find a recurrence relation for $S_n$ . In other words, $S_n$ need to depend on $S_{\text{n - 1}}$ . Now I am not too good at this type of math and combinatorics are the worst for me. I have spent some time on this question, but I cannot see the answer, so please try to be a bit precise in your answers. I am sure that I will understand it if someone can provide a good explanation. Thanks, your help will be very appreciated!!! :D","['recurrence-relations', 'discrete-mathematics', 'computer-science']"
3606086,Radon transform maps a Schwartz function to a differentiable function,"This isn't supposed to be hard, but I just can't seem to be able to write this down. My Radon transform is defined as follows:
Let $f\in C_c^{\infty}(\mathbb{R}^2)$ , then $$Rf(s,\omega)=\int_{\mathbb{R}}f(s\omega+t\omega^{\perp})\,dt,\quad s\in\mathbb{R}, \omega\in S^1,$$ where $\omega^{\perp}=(-\omega_2,\omega_1)$ . I am supposed to show that if $f\in C_c^{\infty}(\mathbb{R}^2)$ then $Rf\in C^{\infty}(\mathbb{R}\times S^1)$ . I have already used Dominated convergence to show that $Rf$ is continuous and I know that the derivatives can be shown to be continuous the same way. My problem is to show that the derivatives exist. I know this is a silly question, but I am just stuck. I am trying to show the existence using difference quotients and Dominated convergence, but I don't know what should be the dominating function here. EDIT: I used Leibniz integration rule for the above mentioned problem. But a related problem is this: If $f$ is a Schwartz function then I need to show that $Rf\in C^{\infty}(\mathbb{R}\times S^1)$ . For this I have shown that $Rf$ is continuous but I don't know how to prove the existence of derivatives. Again I am trying to use difference quotients. My definition for the Schwartz function is that $f$ is a Schwartz function if $f\in C^{\infty}(\mathbb{R}^2)$ and $x^a\partial^bf\in L^{\infty}(\mathbb{R}^2)$ for all multi-indices $a$ and $b$ .","['schwartz-space', 'derivatives', 'inverse-problems']"
3606126,Intuition for $\overline{z}$ not being differentiable in the complex plane,"I am trying to get some intuition for the meaning of a complex derivative. When talking about real numbers, the function $f(x)=|x|$ is not differentiable at $x=0$ , since there is a ""sharp corner"" there, i.e., the limits from right and left are not the same, hence the function is not smooth. The math is similar when talking about complex numbers: for $f(z)=\overline{z}$ , for any $z_{0}\in\mathbb{C}$ , denoting $z-z_0=re^{i\theta}$ , we see that $\frac{\overline{z-z_{0}}}{z-z_0}=e^{-i2\theta}$ can have any value in $[-1,1]$ no matter how close to $z_0$ we approach. 
However, it is somewhat unintuitive for me that $\overline{z}$ is nowhere differentiabe in $\mathbb{C}$ . Specifically: The complex conjugate is just the number $z$ reflected across the $x$ -axis. What makes this kind of reflection impossible to differentiate, while the similar reflection $f(z)=-z$ is differentiable everywhere in the complex plane? Is there a ""sharp corner"" in some essence in the function $f(z)=\overline{z}$ , similar to the one in $f(x)=|z|$ in $\mathbb{R}$ ? Separating the function to its action on the real and imaginary parts, we see that $f(x+yi)=u(x,y)+iv(x,y)$ where $u(x,y)=x$ and $v(x,y)=-y$ . Both $u$ and $v$ feel ""smooth"", how is it that $f$ isn't? Some graphical or other intuitive explanations will be helpful. Thank you.","['complex-analysis', 'derivatives', 'intuition']"
3606145,Proving existence of a limit,"I try to prove that the folowing limit does not exist. $$\displaystyle\lim_{(x,y)\to(0,0)} \frac{x\sin (ax^2+by^2)}{\sqrt{x^2+y^2}}, a,b>0, a\neq b$$ I make the assumption that this limit exist. So, I try to write the limit $$\displaystyle\lim_{(x,y)\to(0,0)} \frac{x}{\sqrt{x^2+y^2}}$$ as a limit of the function $ \dfrac{x\sin (ax^2+by^2)}{\sqrt{x^2+y^2}}$ and another function, that the limits of those functions exist, and thus from the limits function algebra, the $\displaystyle\lim_{(x,y)\to(0,0)} \frac{x}{\sqrt{x^2+y^2}}$ exists which is a contradiction, because this limit obviously does not exist. Maybe the limit $\displaystyle\lim_{(x,y)\to (0,0)} \dfrac{\sin (ax^2+by^2)}{ax^2+by^2}=1$ can help in someway.
Any Ideas?? Thank you","['calculus', 'analysis', 'real-analysis']"
3606150,"Show that if four distinct integers are chosen between 1 and 60 inclusive, some two of them must differ by at most 19.","Let us observe a set that attempts to find 4 numbers that vary by more than 19 from each element. Such a set will be 60, 60-20=40, 60-20-20=20, 60-20-20-20=0. Since 0 is out of range we can say that such a set does not exist. Hence it is a proof by contradiction. Is it satisfactory? Is there another way to prove this directly?","['pigeonhole-principle', 'discrete-mathematics']"
3606154,Proving The existence of Set Y from non-empty Set X with an equivalence relation defined on X.,"Let $X$ be a nonempty set and let $\sim$ be an equivalence relation defined on $X$ .
Prove that there exist a set $Y$ and a function $f \colon X \to Y$ , such that for all $a, b \in X$ : $$a \sim b \iff f(a) = f(b).$$ How do I go about this?","['equivalence-relations', 'relations', 'functions', 'discrete-mathematics', 'elementary-set-theory']"
3606197,The dimension of Jacobi field,"The Jacobi field is defined as $$J^{''}(t)+R(\gamma^{'}(t),J(t))\gamma^{'}(t)=0$$ since it is a system of $2n$ order, spanned by $\{J,J^{'}\}$ , so it is dimension of $2n$ . But I don't get if we add a condition of $J(0)=0$ , then the dimension is $n$ . ( I can't see why the system is immeddiately reduced to $n$ linear independent equations which is expained by our teaching assistant ). Similarly, if we set the Jacobi field normal, that is $\langle J,\gamma ^{'}\rangle=0$ , then the dimension of normal Jacobi field is $2(n-1)$ . It seems to be a trivial consequence, but I really don' see it. Can anyone else help explain it ?","['riemannian-geometry', 'ordinary-differential-equations', 'smooth-manifolds', 'linear-algebra', 'differential-geometry']"
3606217,Is this a known method regarding expressing a prime as the sum of two squares?,"Suppose that the quadratic $x^2+bx+c$ has integer coefficients and non-zero discriminant and constant term. Then it is a simple exercise for students to prove that the number of positive integer roots of $x^2+bx+c$ added to the number of positive integer roots of $x^2-bx+c$ is either 0 or 2.
This elementary result gives an easy to understand proof of the important theorem of Fermat/Euler concerning sums of squares. Theorem : Any prime $p ‚â°1 (\text {mod }4)$ can be expressed as the sum of two squares. Proof : Let $p=4K+1$ and consider the finite number of positive integer solutions $(u,v,w)$ of $$p=(x+y+z)^2-4yz \text{ ‚ë†}$$ Any solution $(u,v,v)$ satisfies $p=u(u+4v)$ and so the only solution is $(1,K,K)$ . All other solutions occur in pairs, $(u,v,w)$ and $(u,w,v)$ , and so there is an odd number of solutions. Now rewrite ‚ë† as $z^2+2(u-v)z+(u+v)^2-p=0$ , a quadratic in $z$ . Since $p$ is prime, the discriminant $4(p-4uv)$ and constant term $(u+v)^2-p$ are both non-zero. Hence there is an even number of solutions with $u‚â†v$ and an odd number with $u=v$ , for which $p=4u^2+w^2$ . Are proofs similar to this one already known? The closest I can find is  the proof of D. Zagier https://web.archive.org/web/20120205194801/http://www.math.unh.edu/~dvf/532/Zagier .","['number-theory', 'combinatorics', 'elementary-number-theory']"
3606243,How do the various classifications of $p$-divisible groups relate?,"There are several dozen 'classification' theorems of various notions of $p$ -divisible groups in terms of crystals (where 'crystal' can seemingly mean various things), thanks to theorems of Dieudonn√©, Grothendieck, Messing, Mazur, Manin, Bertelot, Ogus, Cartier, Fontaine, A. de Jong, Breuil, Kisin, Scholze, Weinstein, and likely many others. As a newcomer I have no idea how to untangle all this mess. Could someone give me a clear overview on the following? How do all these different classification theorems relate? Do I understand correctly that they are all just different special cases of an envisaged classification of $p$ -divisible groups over an arbitrary base? What is it that motivates people? Messing showed that $p$ -divisible groups over arbitrary base schemes with $p$ nilpotent are in correspondence with certain crystals. Aren't we close to done then? I am completely OK with skipping technicalities. I just want to get an overview of what is going on.","['number-theory', 'abstract-algebra', 'big-list', 'algebraic-geometry']"
3606404,Closures of compactly supported functions for different topologies,"Let $C_c(\mathbb{R}^n)$ be the set of all compactly supported functions. $C_c(\mathbb{R}^n)$ can be equipped with at-least two topologies induced by restriction in $C(\mathbb{R}^n)$ , the topology of uniform convergence on compacts and the (finer) topology of uniform convergence. What are the closures of $C_c(\mathbb{R}^n)$ for these topologies? Notes: My intuition is that $C_c(\mathbb{R}^n)$ is dense in $C(\mathbb{R}^n)$ for the topology of uniform convergence on compacts and it is dense in $C_0(\mathbb{R}^n)$ (the set of continuous functions vanishing at infinity) for the uniform topology...","['continuity', 'general-topology', 'functional-analysis']"
3606438,Pointwise Cauchy-Riemann equations suffice?,"Another question just now reminded me of something I realized a while ago I didn't know how to do: Say $V\subset\Bbb C$ is open, $f:V\to\Bbb C$ , $f=u+iv$ , and at every point of $V$ the partials of $u$ and $v$ exist and satisfy the Cauchy-Riemann equations. How do we show that $f$ is holomorphic? I mean it seems it ""must"" follow. But note if you think this is totally trivial it's possible you're wrong; for instance it's not clear how the hypothesis implies that $f'(z)$ exists.","['complex-analysis', 'cauchy-riemann-equations']"
3606446,prove the Riemann-Lebesgue lemma: $\int^b_af(x)\cos(nx)dx\rightarrow 0$ as $n\rightarrow \infty$ for any regulated function $f$,"I would like to prove the Riemann-Lebesgue lemma, namely that $\int^b_af(x)\cos(nx)dx\rightarrow 0$ as $n\rightarrow \infty$ for any regulated function $f$ . The textbook which I'm working from says that I need to prove 3 things in the following order: For all $a \lt b$ , show that $\int^b_a\cos(nx)dx \rightarrow 0$ as $n \rightarrow \infty$ By considering separately each interval of the partition, show that $\int^b_a\phi(x)\cos(nx)dx\rightarrow 0 $ as $n \rightarrow \infty$ , where $\phi(x)$ is a step function on $[a,b]$ Extend this to all $f \in R[a,b]$ So, here's my proof: $\int^b_a\cos(nx)dx= \frac{1}{n}\sin(nb)-\frac{1}{n}\sin(na) \rightarrow 0$ by the sandwhich rule: $$-1 \leq \sin(nx) \leq 1 \Leftrightarrow \frac{-1}{n} \leq \frac{\sin(nx)}{n} \leq \frac{1}{n} \Leftrightarrow 0 \leq \frac{\sin(nx)}{n} \leq 0 \text{ as } n \rightarrow \infty \Rightarrow \frac{1}{n}\sin(nx)=0$$ $\Rightarrow \int^b_a \cos(nx)dx \rightarrow 0$ as $n \rightarrow \infty$ Let $\phi(x) \in S[a,b]$ be a step function in $[a,b]$ and let $P=\{p_0,\ldots,p_k\}$ be a compatible partition with $\phi(x)$ . Then: $$\int\phi(x)\cos(nx)dx= \frac{1}{n}\phi(x)\Bigl(\sin(nb)-\sin(na)\Bigr)+ \frac{1}{n^2}cos(nx)(p_i-p_{i-1}) \rightarrow 0 \text{ as $n \rightarrow \infty$ for $x\in [p_i,p_i-1)$}$$ using IBP: $\phi(x)=u \Rightarrow (p_i-p_{i-1})dx=du$ and then $\cos(nx)dx=dv \Rightarrow \frac{1}{n}\sin(nx)=v$ . Hence, If I apply the same to every interval, $\int^b_a\phi(x)\cos(nx)dx \rightarrow 0$ as $n \rightarrow \infty$ for each interval of the partition $P$ . Let $\phi_n \in S[a,b]$ be a sequence of step functions converging uniformly to $f$ . Then $$\lim_{n \rightarrow \infty} \int^b_a \phi_n \cos(nx)dx= \int^b_af(x)\cos(nx) \rightarrow 0$$ as $n \rightarrow \infty$ by (2) Is my proof correct? Any help is appreciated!","['solution-verification', 'real-analysis']"
3606490,Proving correctness of a braced regular heptagon from a trigonometric identity,"This is a rigid regular heptagon I found on Wikipedia during associated research for my question on rigid pentagons : The accompanying text reads The construction includes two isosceles triangles which hold the rest of [the] bars fixed. The regular heptagon's side $a$ , the shorter isosceles triangle side $e$ , and the longer isosceles triangle side $d$ satisfy $$7a^2+e^2=4d^2\tag1$$ Here $a,d,e$ are integral, or more generally rational. The Wikipedia text goes on to say that $(1)$ can be derived from the following identity: $$\sin\frac\pi7-\sin\frac{2\pi}7-\sin\frac{4\pi}7=-\frac{\sqrt7}2\tag2$$ (If $a=1$ then by solving a Pell equation (see e.g. here ) we get $d=\frac t{16}+\frac7t$ for $t\in\mathbb Q$ .) Now it is easy to prove $(2)$ by a minimal polynomial calculation. It is also easy to prove $(1)$ once you determine that the isosceles triangle's height is $\frac{\sqrt7}2a$ . But how does $(1)$ follow from $(2)$ ? If the association can be shown, I might be able to derive a rigid regular nonagon with rational sticks from the following identity. $$\sin\frac\pi9+\sin\frac{2\pi}9=\sin\frac{4\pi}9$$","['geometric-construction', 'trigonometry', 'geometry', 'recreational-mathematics']"
3606510,L√©vy's metric on $\mathbb{R}^d$,"I know that a sequence of measures on $\mathbb{R}$ converges in distribution if and only if the corresponding L√©vy's metric converges ( Relationship to weak toplogy (L√©vy metric) ). According to this article : ""The concept of the L√©vy metric can be extended to the case of distributions in $\mathbb{R}^d$ "". Let $\alpha=(1,...,1)$ ( $1$ repeated $d$ times), $\mathcal{P}$ the collection of probability measure on $\mathbb{R}^d$ and let's consider $d(F,H)=\inf(\epsilon>0;\forall x \in \mathbb{R}^d,F(x-\epsilon\alpha)-\epsilon\leq H(x) \leq F(x+\alpha\epsilon)+\epsilon),$ where $F$ and $H$ are two distribution functions on $\mathbb{R}^d.$ We can prove easily that $(d,\mathcal{P})$ is a metric space and that if $\lim_nd(F_n,F)=0$ then $F_n\Rightarrow F,$ so it remains to prove that if $F_n\Rightarrow F,$ then $\lim_nd(F_n,F)=0,$ so how can we do it?","['measure-theory', 'weak-convergence', 'metric-spaces', 'real-analysis', 'probability-theory']"
3606573,True/False: If the Wronskian of n functions vanishes at all points on the real line then these functions must be linearly dependent in R.,"I know that if a set of functions are linearly dependent, then its Wronskian = 0 at all values of t in the interval. So can you conclude that if Wronskian = 0 for all values of t in the interval, then the functions must be dependent?","['linear-algebra', 'wronskian', 'ordinary-differential-equations']"
