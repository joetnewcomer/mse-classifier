question_id,title,body,tags
2919903,Show that $e^{-t}\int_{0}^{t}\frac{e^{x}}{\sqrt{x}}dx$ is strictly decreasing for $t\geq1$,"I want to prove that $e^{-t}\int_{0}^{t}\frac{e^{x}}{\sqrt{x}}dx$ is decreasing
on $[1,\infty[$. First of all numerical experiments verify this. I am trying the first derivative test, but stuck with showing that
the sign of the derivative is negative, which is equivalent to showing that 
$$\int_{0}^{t}\frac{e^{x}}{\sqrt{x}}dx> \frac{e^{t}}{\sqrt{t}},\qquad t\geq 1$$. Any ideas?","['calculus', 'inequality', 'real-analysis']"
2919929,"Evaluating $\sum_{n=1}^{\infty} \frac{\phi(n)}{7^n + 1}$, where $\phi(n)$ is Euler's totient function","Evaluate $$\sum_{n=1}^{\infty} \frac{\phi(n)}{7^n + 1}$$
  where $\phi(n)$ is Euler's totient function . I found this problem on a Discord server I just joined. The first time I saw this sum, I was daunted. After gathering courage, I started my work on this problem. I tried various things, like using the definition
$$\phi(n) = n\left(1 - \frac{1}{p_1}\right)\cdots\left(1-\frac{1}{p_m}\right)$$ (where the $p_i$ are the prime factors of $n$) and what not, but it lead to nothing. Then I started thinking about the $7$ in the denominator; why only $7$? What is so special about $7$? What is the difference between
$$\sum_{n=1}^{\infty}\frac{\phi(n)}{6^n + 1}$$ and
$$\sum_{n=1}^{\infty}\frac{\phi(n)}{7^n + 1}$$.
To answer that question, I took the literal difference of the two sums, but the denominator blew up so I started to think again. Because of that, I defined the two sequences and their sum:
$$a_n = \frac{\phi(n)}{7^n + 1} \textrm{ and }b_n= \frac{\phi(n)}{7^n - 1}$$
$$S_1 = \sum_{n=1}^{\infty} a_n\textrm{ and }S_2 = \sum_{n=1}^{\infty} b_n$$
and took THEIR difference, which lead to $$\sum_{n=1}^{\infty}(b_n - a_n) = 2\sum_{n=1}^{\infty}\frac{a_nb_n}{\phi(n)}$$ Now I can say that I'm genuinely stuck. Can someone provide a hint as to what to do next?","['summation', 'totient-function', 'sequences-and-series']"
2919941,Rising Factorial and Stirling number of the 1st kind,"Is it true that $$(x+1)^{\bar{n}}=  \sum_{k \ge 0} \sum
_{i=0}^{n} {i \choose k}s_{n,i}\,\,x^k  \,\,\,\,?$$  where $s_{n,i}$ is the Stirling number of the first kind and the $\bar{n}$ denote rising factorial. If yes, could anyone please show me? I have been able to prove that
$$(x+1)^{\bar{n}}=  \sum_{k \ge 0} s_{n+1,k+1}\,\,x^k  \,\,\,\,$$ My goal is to try to get that $$s_{n+1,k+1} = \sum
_{i=0}^{n} {i \choose k}s_{n,i}$$ by equating (comparing) both identities","['combinatorics', 'stirling-numbers', 'discrete-mathematics']"
2919978,Directional derivative of function with two variables containing a function and its derivative.,"Given $f(x,y)=g(3x+6y)$ and suppose $g'(15)=2$, then I would like to take the directional derivative at the point $(1,2)$ and in the direction of $u=\left(\frac12,\frac{\sqrt{3}}{2}\right)$. Normally this would not be a problem but I can not see through what is going on in the function $f$. How am I supposed to interpret it?","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
2920013,Multiple integral: how to retrieve abscissa range,"We have the double integral: $$\int \int_D 2x + 3y \; dx\;dy$$ The domain in which we want to calculate this is the flat region defined by the curves: $$y = x^2 \; ; \; y=x$$ Then, through the decomposition rules we resolve the internal integral to $dy$, and to do this we find the copy ordinates of the minimum and maximum points of the domain, which are precisely $$y = x^2 \; ; \; y=x$$ While the minimum and maximum points abiscissas will be the external integral range $$\int_{0}^{1} dx \int^{x}_{x^2} 2x + 3y \; dy$$ The coordinates are found by solving to $y$ the curves  that define the domain : for the abscissas, does there exist a mathematical method, or should we simply be intuitive? Thank you in advance",['integration']
2920032,"Inclusion/exclusion, at least and exactly arrangements?","The question wants to count certain arrangements of the word ""ARRANGEMENT"": a) find exactly 2 pairs of consecutive letters? b) find at least 3 pairs of consecutive letters? I have the answer given from the tutor but it doesn't make sense to me. Let's start with the base case: $S_2 = \frac{(11-2\times2+2)!}{(2!)^{(4-2)}}\binom{4}{2}$ ：All possible combinations for 2 pairs of consecutive letters are known. $S_3 = \frac{(11-2\times3+3)!}{(2!)^{(4-3)}}{4\choose3}$ ：All possible combinations for 3 pairs of consecutive letters are known. $S_4 = (11-2\times4+4)!\binom{4}{4}=7!$ ：All possible combinations for 4 pairs of consecutive letters are known. The equation for exactly m conditions： $E_m = S_m - {m + 1\choose1}S_{m+1} + {m + 2\choose2}S_{m+2}$ . The equation for at least m conditions： $L_m = S_m - {m \choose1}S_{m+1} + {m + 1\choose2}S_{m+2}$ . Answer for (a)： $E_2 = S_2 - {3\choose1}S_3 + {4\choose3}S_4$ . Answer for (b)： $L_3 = S_3 - {3\choose1}S_4$ . For (a), I don't understand why we need to multiply $\binom{3}{1}$ with $S_3$ and $\binom{4}{3}$ with $S_4$ ? If we have ${S_3}$ that satisfies the requirement for ${S_2}$ (as three pairs would include two pairs), then wouldn't ${E_2} = S_2 - S_3$ ? For (b), wouldn't the answer just be ${S_3}$ since we it contains the combination for every triple pair? I don't understand the given formula used for ${E_m}$ and ${L_m}$ , mainly the combinatorics part because it looks to me that we already handled that combinations in the calculations of ${S_2}$ , ${S_3}$ , ${S_4}$ . Could someone please explain the formula and why the answers are as such? Thanks! EDIT: I got the question from https://www.youtube.com/watch?v=D1T3xy_vtxU&index=8&list=PLDDGPdw7e6Aj0amDsYInT_8p6xTSTGEi2 - start the video at (4.35) for the question","['combinations', 'combinatorics', 'discrete-mathematics', 'inclusion-exclusion']"
2920055,1st order non linear differential equation,"This is a first order nonlinear differential equation. Can this ODE be solved for $x(z)$?
$$
\frac{\mathrm{d}x}{\mathrm{d}z}= ax^5+bx+c
$$ I have tried using a variable substitution but it did not work: any ideas? This DE is found after solving a more complicated system of DEs; it was part of my physics research to find soliton solutions of a system of DEs. If a,b,c were known then I could use the partial fraction decomposition, but this is not the case. I was wondering if there is perhaps a physicist who has seen before such DEs. I found out that it is Chini DE : $dy/dx=f(x)y^n-g(x)y+h(x)$. For n=2 it is Ricatti and for n=3 Abel DE.
If Chini Invariant does not depend on x then it can be solved since my f,g and h functions are constant. I need to find out how? There is a book of Kamke which will be helpful. Anyone knows the name of this textbook ? Thanks guys.",['ordinary-differential-equations']
2920066,Divisibility of $10^n-1$,"Quick warm-up exercise for everyone (no spoilers for the others please) ;) A number of the form $10^n-1=\underbrace{9999...9}_{n\text{ times}},$ where $n$ is a positive integer, will never be divisible by $2$ or $5.$ Are there any other prime numbers that numbers of this form are never divisible by? Note: I appreciate all solutions and I will vote up to the answers that use a different approach than mine :) Update: If you consider this a challenge, PLEASE don't read the comments.","['number-theory', 'divisibility']"
2920068,Is $ \mathrm{Aut}(\mathrm{Gal}(\bar{\mathbb{Q}}/\mathbb{Q})) $ known?,"Following my previous question about the outer automorphism group, I would like to know if the structure of the automorphism group of the absolute Galois group of the rationals is known. Specifically, is it isomorphic to the cyclic group with two elements ?","['galois-theory', 'group-theory', 'abstract-algebra']"
2920099,How do I find the value of this series? $\frac{n^{2k}}{k!}$,"In my last exam there was a task where we had to find the value of this series: $$
\sum_{k=0}^\infty  \frac{n^{2k}}{k!}
$$ I thought about using a ratio test where I did the following: $$
\dfrac{a_{k+1} }{a_{k}} = \frac{\dfrac{n^{2*(k+1)}}{(k+1)!}}{\dfrac{n^2*k}{k!}} = \dfrac{n^{2(k+1)}k!}{(k+1)!*n^{2k}}
$$ The problem that I have now is that I don't know how to continue or if this the right approach.","['analysis', 'sequences-and-series']"
2920135,A ring such that $(a+b)^2=a^2+b^2$ and $(a+b)^3=a^3+b^3$,"Let $(A,+,\cdot)$ be a ring such that there are $a,b \in A$ which satisfy $$(a+b)^2=a^2+b^2, \quad (a+b)^3=a^3+b^3$$
  Prove that $(a+b)^n=a^n+b^n,$ for all positive integers $n.$ I have found the following solution, but I am not quite satisfied with it. From the hypothesis we get $ab+ba=0$ and $ab^2+ba^2=0.$ We will prove the identity using induction. Suppose that it is true for $1,2,...,n-1, \: n \geq 4.$ We can write $$(a+b)^n=(a+b)^{n-1}(a+b)=(a^{n-1}+b^{n-1})(a+b)=a^n+a^{n-1}b+b^{n-1}a+b^n$$
It is left to prove that $a^{n-1}b+b^{n-1}a=0.$ We can write $$a^{n-1}b+b^{n-1}a=a^{n-2}ab+b^{n-2}ba=-a^{n-2}ba-b^{n-2}ab \quad (*)$$
But $(a+b)^{n-1}=(a+b)^{n-2}(a+b)=(a^{n-2}+b^{n-2})(a+b)=a^{n-1}+b^{n-1},$ so $$a^{n-2}b+b^{n-2}a=0 \Rightarrow b^{n-2}a=-a^{n-2}b$$
Plugging this back in $(*)$ gives $$a^{n-1}b+b^{n-1}a=-a^{n-2}ba+a^{n-2}b^2=a^{n-2}(-ba+b^2)=a^{n-3}ab(-a+b)$$
But $0=ab^2+ba^2=ab^2-aba=ab(b-a),$ so $$a^{n-1}b+b^{n-1}a=a^{n-3}\cdot 0 = 0$$ and this completes the indution. Is there any other solution, maybe quicker or more beautiful?","['ring-theory', 'abstract-algebra']"
2920143,Inverse of a function that maps to R from a higher dimension.,"I have seen questions on *.stackexchange.com that pertain to finding the inverse of functions that map from $\mathbb{R}^2$ to $\mathbb{R}^2$ (for example, this , and this ). My question pertains to finding the inverse of a function like the perspective function, defined as:
$P:\mathbb{R}^{n+1}\rightarrow\mathbb{R}^n,\, P(x,\,t) = \frac{x}{t},\,
\text{dom } P = \{(x,\, t)\,\vert\,(x \in \mathbb{R}^n)\wedge(t>0)\}$. Thus, my question is: how can one find the inverse of this function? I am interested in doing so because I have recently learned that the inverse-image of a convex set under this function is also convex.","['functions', 'inverse', 'inverse-function']"
2920160,"Checking whether $X=\mathbb R$ with $d(x,y)=\min\{ \sqrt{|x-y|},|x-y|^2\}$ is a metric space","Examine whether $d$ is a metric on $X=\mathbb{R}$ where $d\left(x,y\right)=\min\{ \sqrt{|x-y|},|x-y|^2\}$ for all $x,y\in \mathbb{R}$ I think it is not.
Even though it satisfies all other properties but it doesn't satisfy triangle inequality. Take $x=2,y=1.5,z=1$
$d\left(x,z\right)=1$ $d\left(x,y\right)=0.25$ $d\left(y,z\right)=0.25$ Can someone confirm and verify.
It is correct or not.","['metric-spaces', 'real-analysis']"
2920179,Proving Rudin 1.6d (Exponentiation rule for real numbers),"I have been working through some of the early problems in Baby Rudin to prepare for a class next year, but am stuck on part (d) of question 1.6. Fix $b > 1$. (a). If $m, n, p, q$ are integers, $n > 0, q > 0,$ and $r = \frac{m}{n} = \frac{p}{q}$, prove that:
    $$(b^m)^{1/n} = (b^p)^{1/q}.$$
    Hence it makes sense to define $b^r = (b^m)^{1/n}$. (b). Prove that $b^{r+s} = b^rb^s$ if $r$ and $s$ are rational. (c). If $x$ is real, define $B(x)$ to be the set of numbers $b^t$, where $t$ is rational and $t\leq x$. Prove that:
$$b^r =  \sup B(r)$$
    when $r$ is rational. Hence it makes sense to define:
    $$b^x = \sup B(x)$$
    for every real $x$. (d). Prove that $b^{x+y} = b^xb^y$ for all real $x$ and $y$. I have thus far been able to show parts a,b,c with relatively easy concepts, but am struggling to find a solution for part d. Below is my work for parts a,b,c. Feel free to look them over for mistakes. (a). Since $\frac{m}{n} = \frac{p}{q}$, we know: $mq = np = y$. Then, by $\textbf{Theorem 1.21 of the text}$, we know that $x^{nq} = b^y$ is unique. We shall demonstrate that $(b^m)^{1/n} = (b^p)^{1/q} = b^r$:
$$((b^m)^{1/n})^{nq} = (b^m)^q = b^y$$
$$((b^p)^{1/q})^{nq} = (b^p)^n = b^y$$
Thus, $((b^m)^{1/n})^{nq} = b^y = ((b^p)^{1/q})^{nq}$, and so, $(b^m)^{1/n} = b^r = (b^p)^{1/q}$, as desired. (b). First, let $r = \frac{m}{n}, s = \frac{p}{q}$ for $m,n,p,q \in \Bbb{Z}$. Then, $b^{r+s} = b^{m/n +p/q} = (b^{mq+np})^{1/nq}.$ Since $mq, np \in \Bbb{Z}$, we can say, $(b^{mq+np})^{1/nq} = (b^{mq}b^{np})^{1/nq}$. We get: $(b^{mq}b^{np})^{1/nq} = (b^{m/n}b^{p/q}) = b^rb^s$, as desired. (c). We consider $B(r) = \{b^t \mid t \in \Bbb{Q} \ \& \ t \leq r\}$. For any $t$, $b^r = b^tb^{r-t} \geq b^t1^{r-t}$, since $b > 1$. Thus, $b^r$ is an upper bound of $B(r)$. Since $b^r \in B(r)$, we conclude that $b^r =\sup B(r)$, as desired. (d). For this part, I have considered doing $b^x = \sup B(x)$, so $B(x) = \{b^t \mid t \leq x, t \in \Bbb{Q}\}$. Then, $b^xb^y = \sup B(x)\sup B(y) \geq b^rb^s = b^{r+s} = \sup B(r+s)$, for $r \leq x, \ s\leq y, \ r,s \in \Bbb{Q}$. Thus, $\sup B(x)\sup B(y) \geq\sup B(r+s)$, and since $r+s \leq x+y$, we have $\sup B(x+y) \leq \sup B(x)\sup B(y)$, which would set $b^xb^y$ as an upper bound for $b^{x+y}$. Here I come across two issues, one in that I am not sure if this is in fact correct. Since we assumed $r,s$ were rational, I am not entirely sure if it is true that $\sup B(r+s) = \sup B(x+y)$ for $x,y \in \Bbb{R}$, as  I think would have to be the case for me to then claim that since $r+s \leq x+y$, $b^xb^y$ is an upper bound for $b^{x+y}$. Is this true, how would one prove this? My second issue is that, given the above is true, I can't figure out how one would proceed to demonstrate that $\sup B(x+y)$ is an upper bound for $b^xb^y$. Any help would be greatly appreciated!",['real-analysis']
2920189,"The matrix $I_n - v^t x$ is invertible when $\langle v, x \rangle \neq 1$","Let $v \neq 0$ be any vector in $\Bbb R^n$ and let, $U_v = \{x \in \Bbb R^n : \langle v,x \rangle \neq 1\}$ . Then: (i) Show that the matrix $I_n - v^t x$ is invertible $\forall x \in U_v$ . (ii) Compute the derivative of the map $f:U_v \to GL_n(\Bbb k)$ ( $\Bbb k = \Bbb R \text{ or } \Bbb C$ ) defined by $$f(x)={(I-v^tx)}^{-1} .$$ My attempt: (i) I have tried to do it using determinant but couldn't do it. (ii) Observed $f=f_2 \circ f_1$ , where $$f_1 : U_v \to GL_n(\Bbb R)$$ $$x \mapsto (I_n - v^t x)$$ and $$ f_2 : GL_n(\Bbb R) \to GL_n(\Bbb R)$$ $$ A \mapsto A^{-1}$$ Then derived, ${Df_1}_{(x)} (h)= -v^t h$ and ${Df_2}_{(A)}(H)= -A^{-1}HA^{-1} $ . Applied Chain Rule to obtain, $$Df_x (h)= {(I_n - v^tx)}^{-1} (v^t h){(I_n - v^tx)}^{-1}$$ I think I have done part (ii) only for $\Bbb k = \Bbb R$ . How to prove part (i) and if there is any mistake in my attempt in part $(ii)$ , then please point it out. Thanks in advance for help!","['matrices', 'frechet-derivative', 'linear-algebra']"
2920199,"$f(x) = \frac{x^2 - 1}{x-1} $ is different from $f(x) = x + 1$, in spite of the fact that rules of algebra is followed, why?","Suppose there be a function, $$ f(x) = \frac {x^2-1}{x-1} $$ For $x=1$, the function becomes un defined. But, in Algebra we know it is allowed to Cancel Denominator and numerator by the common factor and this would result in the same expression which is equivalent to the first one. But, $$\require{cancel} f(x) = \frac{(x+1)\cancel{(x-1)}}{\cancel{(x-1)}} =y$$
$$\Rightarrow y = x + 1 $$ But, here when I see that Graph of both the equation they look same however the first one is undefined for x = 1 which is not with the case of the second one. But, just canceling a common term in numerator and denominator or multiplying them, changes the whole function why? So, rules of algebra don't work? or there is a problem with my understanding?","['algebra-precalculus', 'functions']"
2920201,Looking for a 1923 paper of Issai Schur on permutation polynomials,"This question is really no more than a reference request, but here's some background for those who are interested: In Peter Muller's paper ""A Weil-Bound Free Proof of Schur's Conjecture"" (available for viewing here ), where he proves the statement that A polynomial $P$ that is bijective over infinitely many finite fields is a composition of Dickson polynomials and polynomials of the form $ax^m+b$ for some $a,b,m$, the conjecture of which is due to Issai Schur, the first theorem proven is as follows: Let $K$ be a number field, with $\mathcal{O}_K$ its ring of integers. We say that a polynomial $f\in \mathcal{O}_K[x]$ is exceptional if the following holds. For infinitely many nonzero prime ideals $\mathfrak{p}$ of $\mathcal{O}_K$, $f$ as a function on $\mathcal{O}_K/\mathfrak{p}$ permutes the elements of this field. THEOREM 1. Let $f\in \mathcal{O}_K[x]$ be an exceptional polynomial of degree $n\geq 2$. Let $t$ be a transcendental over $K$, and let $x_i (1\leq i\leq n)$ be 
  the roots of $f(X) - t$ in some algebraic closure of $K(t)$. Then $$\sum_{i=1}^n \zeta^i x_i=0$$ for $\zeta$ an $n$-th root of unity and a suitable numbering of the $x_i$. He mentions the following: Schur had this assertion on page 128 in his paper [8] from 1923 for $K=\mathbb{Q}$. Of course there was no Weil bound (or sufficiently strong substitute) available at that time. Schur used a quite complicated series of 
  arguments, involving the Lagrange inversion formula for power series and computations with multinomial coefficients. Further, Schur's method seems to work
  only for $K=\mathbb{Q}$. I've been trying to find the paper [8] mentioned here, as I want to see Schur's argument. The citation of this paper is I. Schur, Über den Zusammenhang zwischen einem Problem der Zahlentheorie und einem Satz über algebraische Funktionen, S.-B. Preuss. Akad. Wiss. Berlin (1923), 123-134. Unfortunately for me, I do not know German, so I cannot properly find or navigate any archives that might contain this journal. I can find a couple websites that have some years of this journal, but none contain records from 1923. Where might I find this paper?","['permutations', 'number-theory', 'polynomials', 'reference-request']"
2920237,Bernoulli's inequality for rational exponents,"We've proved that
$$(1+x)^n \geq 1+nx \quad \forall n \in \mathbb{N} \land x \geq -1$$
with induction, and next excercises are to prove $1$ and $2$:
$$(1+x)^p \leq 1+px \quad \forall p \in \mathbb{Q}\cap[0,1] \land x \geq -1 \tag{1}$$
$$(1+x)^p \geq 1+px \quad \forall p \in \mathbb{Q}\cap[1,\infty) \land x \geq -1 \tag{2}$$
I was told that $(1)$ will be useful in proving $(2)$, so it's suggested to prove the $(1)$ first. My work : For the first one, i was able to prove that
$$(1+x)^{1/n} \leq 1+\frac{x}{n} \quad \forall n \in \mathbb{N}_{+} \land x \geq -1$$
Like this:
$$(1+x)^{1/n} \overset{?}{\leq} 1+\frac{x}{n}$$
$$(1+x)\overset{?}{\leq}  \left(1+\frac{x}{n}\right)^n$$
$$ 1+nx \leq (1+x)^n$$
Which is true, but I could not go further. But I was able to prove $(2)$ from $(1)$: for $q \in \mathbb{Q}\cap (0,1]$, we have that
$$(1+x)^q \leq 1+qx$$
Letting $pq=1$:
$$1+x \leq \left( 1+\frac{x}{p}\right)^p$$
$$1+px \leq (1+x)^p$$
Could you give me a hint to the first one?","['inequality', 'analysis']"
2920242,MLE and method of moments estimator (example),"Let $X_1,X_2,\dots ,X_n$ be a random sample from the Gamma distribution $$ f(x,\theta)=\theta^2 x e^{-\theta x},\quad x>0$$ To find the Maximum Likelihood Estimator , we define the likelihood function as: 
$$ L(\theta;x_i)=\prod_{i=1}^nf(x_i;\theta)$$ and we demand 
$$\frac{\partial \ln[L(\theta;x_i)]}{\partial\theta}=0$$
For this example 
$$L(\theta;x_i)=\theta^{2n}\cdot \prod_{i=1}^n x_i\cdot e^{-\theta \sum_{i=1}^nx_i}$$
$$\ln[L(\theta;x_i)]=2n\ln(\theta)+n\ln\bigg[\prod_{i=1}^nx_i\bigg]-\theta \sum_{i=1}^nx_i$$
So
$$\frac{2n}{\theta}-\sum_{i=1}^n x_i=0\iff \hat{\theta}=\frac{2}{\bar{X}}$$
To find the estimator of $\theta$ using the method of moments $$\bar{X}=E(X)=\mu$$
$$E(X)=\int_0^\infty x f(x)dx=\theta^2\cdot\frac{2}{\theta^3}=\frac{2}{\theta}$$
$$\Rightarrow \tilde{\theta}=\frac{2}{\bar{X}}$$ Is there some kind of relation between the two? Why are the expressions of $\hat{\theta}$ and $\tilde{\theta}$ so similar?","['statistics', 'probability-distributions', 'maximum-likelihood']"
2920262,How to calculate the derivative of $x^x$?,"I'm trying to follow an example in my textbook. $$y=x^x$$
$$\ln (y)=\ln (x) \cdot x$$ We want to calculate the derivative with respect to x The book makes quite a leap here and states that: $$\frac{y'}{y}=\frac{1}{x}\cdot x+1\cdot \ln(x)$$ Since $y=x^x$ this means that: $$y'=x^x(1+\ln(x))$$ Is this correct? If I start from the beginning then: $$y=x^x$$
$$\ln (y)=\ln (x) \cdot x$$ Only if we want to take the derivative this expression isn't useful, we'll have to use the full expression: $$e^{\ln (y)}=e^{\ln (x) \cdot x}$$ Now, if we take the derivative of this with respect to x we find that: $$\frac {1}{y}\cdot e^{\ln (y)}=e^{\ln (x) \cdot x}\cdot (1+ln(x))$$ The left hand expression would simplify to $\frac {y'}{y}$, since $e^{\ln(y)}=y$ and the derivative of $y=y'$ so: $$\frac {y'}{y}=e^{\ln (x) \cdot x}\cdot (1+\ln(x))$$ Which can be written as: $$\frac {y'}{x^x}=x^x\cdot (1+\ln(x))$$ Which simplifies to: $$y'=x^{2x}\cdot (1+\ln(x))$$","['exponentiation', 'calculus', 'derivatives']"
2920287,Does the integrability of $ f^3 $ imply the integrability of $ f^2 $ and/or $ f $?,"We know that the integrability of $ f $ implies the integrability of $ f^2 $, but the integrability of $ f^2 $ does not imply the integrability of $ f $ (for example, the function $ f(x) = 1 $ when rational and $ -1 $ when irrational). Question : However, does the integrability of $ f^3 $ imply anything about the integrability of $ f $? And what about higher powers?","['integration', 'analysis', 'real-analysis']"
2920331,Does $\lim_{z \rightarrow 3-4i}\frac{(\overline{z}-3-4i)^4}{|z-3+4i|^4}$ exist? Justify your answer.,"I  managed to manipulate the expression by changing $$\begin{align*}
|z-3+4i|^4 &= |x + iy - 3 + 4i|^{4}\\
& = (x-3+i(y+4))^2(x-3-i(y+4))^2\\
& = (z-3+4i)^2( \overline{z}-3-4i)^2
\end{align*}$$ I'm not sure where I should go from here. I'm aware I can find two curves on which the function value differs while approaching the limit to prove it doesn't exist, but I can't seem to think of the two curves.",['limits']
2920337,A vector field is differentiable if and only if the map $X: M \to TM$ is differentiable,"Let $X$ be a vector field defined on a manifold $M$. Then $X$ is differentiable if and only if the application $\psi:M\rightarrow TM$ such that $\psi(p)=(p,X_p)$ is differentiable. I have some problems trying to prove this. Any help is welcome.","['vector-fields', 'smooth-manifolds', 'manifolds', 'differential-topology', 'differential-geometry']"
2920338,Torsion-free sheaf on $\Bbb P^2$,"Let $F$ be a coherent torsion-free sheaf on $\Bbb P^2$ and $L \subset \Bbb P^2$ be a line. Assume that there is an isomorphism $f : F_{|L} \to \mathcal O_L^r$ for some $r \in \Bbb N$. Questions : 1) Does it implies that there is an open neighborhood $U \supset L$ such that $F_{|U} \cong \mathcal O_U^r$ ? Intuitively being trivialisable is an open condition but I can't formalize it. 2) Why does it implies that $c_1(F) = 0$ ? We need a resolution by vector bundles to compute $c_1(F)$ but I don't see how it helps. Alternatively we can pick a generic section of $F$ and look at its zero locus, again I don't see why this trivialization is useful, $U$ is just slightly bigger than expected i.e it can't contains a closed curve. Bonus question : what is a good way to describe coherent torsion-free sheaves in terms of vector bundles ?","['algebraic-geometry', 'sheaf-cohomology', 'coherent-sheaves']"
2920366,$C_p = \mathbb{Z}_p \times \mathbb{Z}_p$ is a field for some prime $p$.,"Let $p$ a prime number.
$\mathbb{Z}_p \times \mathbb{Z}_p$ with sum given by $(a,b)+(c,d) = (a+c,b+d)$ and multiplication given by $(a,b)*(c,d)=(ac-bd,ad+bc)$ is a field for some prime greater than two and $C_2$ is not a field. What I did: $C_2$ is not a field, because $(1,0)$ is the neutral, and $(1,1)*(c,d) = (1,0)$ gives $c-d=1, d+c=0$, which have no solution in $\mathbb{Z}_2$, then it is not a field. But I don't know how to do for $p>2$, because all I know is check case by case, and I think it us not supposed to be that much of work. Thanks.",['abstract-algebra']
2920400,Moduli space of stable curves of genus $g$ does not admit a universal family,"I am trying to understand why the (coarse) moduli space $\overline{M}_g$ of stable curves of genus $g$ does not admit a universal family. I am following the proof in p.267 of this book . A key step is the fact that every stable curve admits a Kuranishi family. So, suppose we have a universal family $\pi:\mathcal{C}\rightarrow \overline{M}_g$ and let $[C]\in \overline{M}_g$. Let $\xi:\mathcal{X}\rightarrow (X,x_0)$ be a Kuranishi family of $C$. On the one hand there exists a neighborhood $V$ of $[C]$ in $\overline{M}_g$ and a map $f:V\rightarrow X$ such that $\pi|_V$ is the pullback of $\xi$ via $f$. On the other hand, there exists a map $h:X\rightarrow \overline{M}_g$ such that $\xi$ is the pullback of $\pi$ via $h$. By considering the composition $f\circ h$ (and restricting to a neighborhood of $x_0$) we are supposed to get a family differing from a Kuranishi family by at most  an automorphism of the central fiber. I do not understand why this is true. Anyway, this implies that $f\circ h$ is an automorphism and therefore $h$ is injective. Nevertheless, if $\gamma\in Aut(C)\setminus\{id\}$ then $\gamma$ acts non-trivially on $V$ and $h$ sends any orbit of $Aut(C)$ to the same point of $\overline{M}_g$. We reach a contradiction. In conclusion, why $f\circ h$ gives a family differing from a Kuranishi family by at most  an automorphism of the central fiber?","['algebraic-curves', 'algebraic-geometry', 'moduli-space']"
2920418,"Show that $E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)]dt $","Assume $X$, $Y$ random variables with joint distribution function $H$ and their respective marginals $F$ and $G$. I'm trying to show that:
$$E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)]dt $$ My approach : So far I know that $$ E|X-Y| = \int\int_{\mathbb{R}^2}|x-y| \text{d}H(x,y)$$ from where we can straightforwardly try to reduce the integral to $$ \int_{-\infty}^{\infty}\int_{-\infty}^{x}(x-y) \text{d}H(x,y)  + \int_{-\infty}^{\infty}\int_{x}^{\infty}(y-x) \text{d}H(x,y) $$ However, I'm not sure how to proceed from here, that is, how to think about working with the $\text{d}H(x,y)$ term and how to properly take it out. Firstly, I'm not even sure if in general case we can take the $h(s,t)$ part out, where $H(x,y) = \int_{-\infty}^{x}\int_{-\infty}^{y}h(s,t)dsdt$, since $X$ and $Y$ are not necessarily continuous? Even if we could, I can't see how to properly proceed. On the other hand, by going backwards, $$ E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)] dt = \int_{-\infty}^{\infty}\left(\int_{-\infty}^{t}dF(s) + \int_{-\infty}^{t}dG(s) - 2\int_{-\infty}^{t} \int_{-\infty}^{t} dH(s,j)\right)dt$$ It also feels like something in the likes of $$ \int_{-\infty}^{t}dF(s) = \int_{-\infty}^{\infty} \int_{-\infty}^{t}dH(s,j),$$ might hold, but again, I'm not entirely sure how to work with distribution functions when they are in the integral measure part. Any hints/ideas would be appreciated!","['statistics', 'probability-distributions', 'expected-value', 'probability-theory', 'probability']"
2920448,Maximum Entropy Distribution with Reciprocal Symmetry,"What is the maximum entropy distribution $F$ on $(0,\infty)$ with mean $1$ and $\Pr(x\le a)= \Pr(x\ge\frac{1}{a})$ for all $a$ ? After taking a derivative we find that the pdf $F'=f$ must satisfy $af(a)=\frac{1}{a}f(\frac{1}{a})$ . I tried using calculus of variations with lagrange multipliers, but the integrals look like they cannot be dealt with analytically. Alternatively I would also be happy simply having a pdf with mean $1$ and the given symmetry, which is not necessarily of maximum entropy. I looked at the F-distribution which has the symmetry but not the mean. One Ansatz that almost worked out is $f(x) = c\frac{1}{x} e^{-a(x+\frac{1}{x})}$ . But here $\int f\,\mathrm dx =2cK_0(2a) \overset{!}{=}1 $ and $\int x f \,\mathrm dx = 2 cK_1(2a) \overset{!}{=}1 $ leads to $K_0(x) = K_1(x)$ . But the only point where those two modified Bessel functions of the second kind agree is at $x=\infty$ , which leads to $f(x)=\delta(x-1)$ , i.e. a dirac impulse at $x=1$ . This is indeed a solution; albeit a useless one.","['probability-distributions', 'entropy', 'probability']"
2920555,There are $4$ numbers. First $3$ make an arithmetic progression. Last $3$ make a geometric progression.,"There are four numbers. The first three make an arithmetic progression, and the last three make a geometric progression. The sum of first and last number is $37$. The sum of middle numbers is $36$. Find the numbers. So I'm trying to solve this problem for about 2 hours now. I can't use any formulas because all I get $0=0$. I don't know all the terms in English so I'll just try to upload my notes here. Eh but it doesn't let me. At first i got that $a_1=-2d$, $d$ was $= -36$ so my numbers were $72$, $36$, $0$, $-35$. The problem is that last 3 numbers doesn't make a geometric progression.","['algebra-precalculus', 'arithmetic-progressions', 'geometric-progressions']"
2920634,Construct an order on a field $\mathbb{Q}^2$,"Let $\mathbb{Q}$ be the field of rational numbers. Let $\mathbb{Q}^2=\{(a,b):a,b\in\mathbb{Q}\}$ and define addition and multiplication as follows:
$$
(a,b)+(c,d)=(a+c,b+d)\\
(a,b)\cdot(c,d)=(ac+2bd, ad+bc)
$$
Then $(\mathbb{Q}^2, +, \cdot)$ is a field, and $(0,0)$ is its zero element while $(1,0)$ is its unit element. The inverse of $(a,b)$ is $(\frac{a}{a^2-2b^2},-\frac{b}{a^2-2b^2})$. I'm asked to construct an order on it such that it becomes an ordered field, namely invariant under addition and multiplication with a positive element. What I know is $(1,0)>(0,0)$, so $(n,0)>(0,0)$ for any natural number $n$. I don't quite know how to proceed. Is there any rules to follow to construct an order on a field? Thank you for any help!","['elementary-set-theory', 'order-theory', 'abstract-algebra']"
2920636,Ensemble average of a sum of cosine functions,"I can evaluate the following:
$$R_2 = \left\langle \sum_{i\ne j}\sum_{p\ne q} \cos(\theta_i - \theta_j + \theta_p - \theta_q)\right\rangle$$ where the $\theta$ are chosen from a uniform random distribution between 0 and $2\pi$. I just need to find how many terms result in $\theta_i - \theta_j + \theta_p - \theta_q = 0$. There are $N$ terms where $i=q$ and for each of these there are $N$ terms where $j=p$ giving $N^2$ terms. I then need to subtract off the $N$ terms which would result in $i=j$ (since they are forbidden) giving:
$$R_2 = N^2 - N$$ I'd like to extend this to evaluate:
$$R_3 = \left\langle \sum_{i\ne j}\sum_{p\ne q} \sum_{m\ne n}\cos(\theta_i - \theta_j + \theta_p - \theta_q + \theta_m - \theta_n)\right\rangle$$ and the obvious extensions thereof. Is there a better way to proceed than the kind of thinking I used above? P.S. I don't know if combinatorics is the right tag here. I used that because it seemed like it might be relevant.",['combinatorics']
2920667,Remove any number and the remaining numbers can be partitioned into two subsets of equal sum; prove all numbers are equal. [duplicate],"This question already has answers here : After removing any part the rest can be split evenly. Consequences? (3 answers) Closed 5 years ago . Supposed I have a list of $n$ real numbers, where $n$ is odd. The list is constructed such that I can remove any arbitrary number from the list, and the remaining numbers can be partitioned into two equal-sized subsets with equal sums. Prove that all numbers in the list are equal. This should be somehow related to linear algebra. A way I could think of to interpret this is that the list is essentially a $1 \times n$ row, and there exist $n$ $n \times 1$ vectors with one zero in some entry and $1$'s and $-1$'s in other entries with the entries summing to $0$, such that the product of the row and the column vector is $[0]$. In other words, the entries/$1 \times 1$ columns in the row are linearly dependent once we remove any arbitrary entry/column. I'm not sure how this is/could be related to the proof though. Thanks in advance!","['real-numbers', 'number-theory', 'linear-algebra']"
2920677,Integrate $\int_{\gamma} z^{n}$ where $\gamma$ is any circle not containing the origin.,"I want to generalize this question: Evaluate the integrals $\int_{\gamma}z^{n}dz$ for all integers $n$. I mean: the same question but with $\gamma$ any circle not containing the origin. Then if $\gamma$ has radius $r$, we can write a parameterization $z(t) = c + re^{it}$ with $c > r$. So, the integral becomes
$$\int(c+re^{it})^{n}ire^{it}dt$$
I think maybe I should use some ""trick"" taking advantage of the case of the circle centered on the origin. Can someone help me?","['integration', 'complex-analysis']"
2920709,When does $AA^T$ commute with $A^T$?,"Suppose $A \in M_n(\mathbb R)$ is a real matrix. I am wondering what conditions would guarantee $AA^T$ commute with $A^T$, i.e.,
\begin{align*}
AA^T A^T = A^T A A^T.
\end{align*}
If $A$ is normal, I think the relation holds since then $A^T$ is a polynomial in $A$. On the other hand, the commutativity is exactly $A(AA^T-A^TA) = 0$ which is columns of $(AA^T-A^TA)$ are in $ \text{ker}(A)$. Is this a property of some class of matrices?","['matrices', 'linear-algebra']"
2920805,Definition of divergence,"We see in certain places that
$$\operatorname{div} \mathbf{F}|_p = \lim_{V \to \{p\}} \iint_{\partial V} \frac{\mathbf{F} \cdot \mathbf{\hat n}}{|V|} \: dS.$$ But what is $V$? Neighborhoods of $p$? Balls around $p$? How can you take a limit that is not as one number approaches another? What is the actual rigorous definition of this limit, and furthermore, divergence? I am already familiar with the $\nabla \cdot F$ definition.","['multivariable-calculus', 'definition']"
2920812,Does this dynamical system have another conserved quantity?,"For the 3D system of ODEs: $$\begin{eqnarray}\dot{x} &=& -\beta x y  \\
\dot{y} &=& \beta x y + \hat{\beta} z y - \delta y \\
\dot{z} &=& -\hat{\beta} z y + \delta y,
\end{eqnarray}$$ the quantities $Q_1 = x+y+z$ (assume $Q_1=1$ ) and $Q_2 = (\delta/\hat{\beta}-z)(x)^{\hat{\beta}/\beta}$ are conserved quantities (i.e., $\dot{Q}_1 = \dot{Q}_2=0$ ). $Q_2$ can be found by first reducing the 3D system to 2D by using $Q_1$ (e.g. $z = 1-x-y$ ) and then computing $dy/dx$ , which can be solved analytically. My question is about the following generalization of the previous system to the following 6D system of ODEs: $$\begin{eqnarray}\dot{x}_1 &=& -\beta x_1 y_2  \\
\dot{y}_1 &=& \beta x_1 y_2 + \hat{\beta} z_1 y_2 - \delta y_1 \\
\dot{z}_1 &=& -\hat{\beta} z_1 y_2 + \delta y_1,
\end{eqnarray}$$ $$\begin{eqnarray}\dot{x}_2 &=& -\beta x_2 y_1  \\
\dot{y}_2 &=& \beta x_2 y_1 + \hat{\beta} z_2 y_1 - \delta y_2 \\
\dot{z}_2 &=& -\hat{\beta} z_2 y_1 + \delta y_2.
\end{eqnarray}$$ It is easy to see that $Q_{11} = x_1 + y_1 + z_1$ and $Q_{12} = x_2 + y_2 + z_2$ are conserved quantities for the new system. Are there any other conserved quantities in the new system? If there are, what are they? Please assume that $Q_{11} = Q_{12} = 1$ . I have played with many analogous forms to $Q_2$ without success and I would like some help from the community to help me find the other conserved quantity(ies).","['nonlinear-system', 'nonlinear-dynamics', 'ordinary-differential-equations', 'dynamical-systems']"
2920834,Domain of joint density function,"In this question we have that $G \sim \operatorname{Exp}(0.3)$ and $M \sim \operatorname{Exp}(0.6)$ where $G$ and $M$ are independent of each other. I need to find the joint density function and then find $P(G>2M)$. So far I have that the joint density function is \begin{align}
& f_{GM}(g,m)=f_G(g)f_M(m) \\[10pt]
= {} & (0.3e^{-0.3g})(0.6e^{-0.6m}) \\[10pt]
= {} & 0.18e^{-0.3g-0.6m} \text{(and $0$ otherwise??)}
\end{align} If this is correct then what is the domain of the density function? If it is $h,m>0$ then I'm not sure what the limits for each of my integrals are. I believe to find $P(G>2M)$ I need to solve a double integral like this: $$\iint 0.18e^{-0.3g-0.6m} \, dg \, dm$$ ...but I don't know how to find the limits of integration. Thanks for any input.","['statistics', 'probability-distributions', 'probability', 'density-function']"
2920850,"Show that if $(z+1)^{100} = (z-1)^{100}$, then $z$ is purely imaginary","Let $z$ be a complex number satisfying
  $$(z+1)^{100} = (z-1)^{100}$$
  Show that $z$ is purely imaginary, i.e. that $\Re(z) = 0$. Rearrange to $$\left(\frac{z+1}{z-1}\right)^{100} = 1$$ I tried using $z = x+iy$ and trying to multiply numerator and denominator by the conjugate, but I hit a roadblock. I also tried substituting $1 = -e^{i\pi}$, but that also doesn't seem to get me anywhere. How can I prove this? Any help is appreciated, thank you!","['complex-analysis', 'complex-numbers']"
2920855,Why is $ e^{-\frac{x^2}{2}+c_1} = c_1\cdot e^{-\frac{x^2}{2}} $?,"Recently I tried to solve this differential equation: $$ y'+xy = 0 $$ $$ \frac{dy}{dx} + xy = 0 $$
$$ \int \frac{dy}{y} = \int -x \,dx $$ This is my solution:
$$ y(x) = e^{-\frac{x^2}{2} + C_1} $$ According to Wolfram|Alpha this should be true but also not perfectly simplified. Wolfram's solution: $$ y(x) = C_1 \cdot e^{-\frac{x^2}{2}} $$ I don't get the last step at all.","['integration', 'algebra-precalculus', 'ordinary-differential-equations']"
2920985,How do you evaluate this trigonometric sum?,"I have strong reason$^{\dagger}$ to believe that the following equation is true: $$\sum_{m=0}^{n} \left[\left(e^{i\pi\frac{k+k'}{n}}\right)^m+\left(e^{i\pi\frac{k-k'}{n}}\right)^m+\left(e^{i\pi\frac{-k+k'}{n}}\right)^m+\left(e^{i\pi\frac{-k-k'}{n}}\right)^m\right]=2[1+\cos \left[(k+k')\pi\right]$$ Where $0<k,k'<n$ are positive integers, but with $k\neq k'$ (for simplicity we can take $k>k'$). I have already verified this for various values of  $k$, $k'$, and $n$, but I can't seem to prove it in general. Any suggestions? $^{\dagger}$I came to this formula by writing out the character orthogonality relation for different 2-dimensional representations of the dicyclic group $Q_{2n}$.","['trigonometric-series', 'group-theory', 'representation-theory', 'trigonometry']"
2921053,Alternative proof of Abel's Theorem for Uniform convergence of series of functions,"The following is the Abel's Theorem. I proved it my own way. Let $g_n(x)$ be a sequence of real-valued functions such that $g_{n+1}(x)\leq g_{n}(x),\forall \,x\in T$ and $n\in\Bbb{N}.$ If $\{g_{n}\}$ is uniformly bounded on $T$, and if $\sum f_n(x)$ converges uniformly, then $\sum f_n(x)g_n(x)$ converges uniformly on $T.$ MY TRIAL Let \begin{align}F_n(x)=\sum^{n}_{i=1} f_n(x),\forall \,x\in T,\;n\in\Bbb{N}\end{align}
Let $N>M,$ then 
\begin{align}
\left|S_N(x)-S_M(x) \right|
&=\left|\sum^{N}_{n=1} f_n(x)g_n(x)-\sum^{M}_{n=1} f_n(x)g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1} f_n(x)g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1} \left[F_n(x)-F_{n-1}(x)\right]g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1}F_n(x)g_n(x)-\sum^{N}_{n=M+1}F_{n-1}(x)g_n(x)\right|\\&=\left|
\left[F_{M+1}(x)-F_{M}(x)\right]g_{M+1}(x)+\sum^{N}_{n=M+2}\left[F_n(x)-F_{n-1}(x)\right]g_n(x)\right|\\&\leq
\left|F_{M+1}(x)-F_{M}(x)\right| \left| g_{M+1}(x)\right|+\sum^{N}_{n=M+2}\left|F_n(x)-F_{n-1}(x)\right|\left|g_n(x)\right|\end{align}
Since $g_n$ is uniformly bounded, there exists $M>0$ such that 
\begin{align} \left|g_n(x)\right|\leq M_{1},\forall \,x\in T\end{align}
Also, by uniform convergence of $\sum f_n(x)$, the sequence of partial sums is uniformly Cauchy. Let $\epsilon>0.$ Then, there exists $N_1=N(\epsilon)$ such that $\forall\,N>M\geq N_1,\;\forall\,x\in T$
\begin{align} \left|F_{N}(x)-F_{M}(x)\right|<\frac{\epsilon}{M_{1}+1}\end{align}
Hence, $\forall\,N>M\geq N_1,\;\forall\,x\in T$
\begin{align}
\left|S_N(x)-S_M(x) \right|& \leq
\left|F_{M+1}(x)-F_{M}(x)\right| M_{1}+M_{1}\sum^{N}_{n=M+2}\left|F_n(x)-F_{n-1}(x)\right|\\&< \frac{M_{1}\epsilon}{M_{1}+1}+\frac{M_{1}\epsilon}{M_{1}+1}<\epsilon\end{align}
And we are done! Please, can you help check if my proof is correct? Constructive criticisms are welcome! Thanks!","['analysis', 'real-analysis', 'uniform-convergence', 'sequences-and-series', 'convergence-divergence']"
2921113,Can you use set builder notation to imply a function with arguments?,"So I'm writing a paper (computer sciences) that involves moore neighbourhoods. If I am using set builder notation to define a set, can I use index form for example to either index elements of the set or include an argument that is a variable used in the set builder expression? Ideally I'd like to do this without having to define loads of other functions. For example let's say I want to use the following to show a moore neighbourhood around $0$:
\begin{align}\|(x_1,...,x_d)\|_\infty &= \text{max}(|x_1|,...,|x_d|) \\
M_{r}^{/0} &= \{ \mathbf{m} \in \mathbb{Z}^d : 1 \leq \|\mathbf{m}\|_\infty \leq r \} \\ \end{align}
Can I simply then use $M_{1}^{/0}$ to show a Moore neighbourhood of range 1? Or must I define some additional function of some sort? Can I then extend this idea to show that the elements of $M_{1}^{/0}$ can also be indexed? For example, it would be great if I could simlply write $\mathbf{m_{1,i}}$ where $\mathbf{m_{1,i}} \in M_{1}^{/0} $ to show that I'm accessing the $i^{\text{th}}$ element of a Moore neighbourhood with a range of 1. In effect I want to be able to show the accessing of elements of $M_{r}^{/0}$ using a function with two arguments $m(r,i)$. How do I achieve this in the most succinct way possible ideally without introducing a load of function definitions? I should also mention that my background is computer science and not maths. Also, any corrections to do with the notation I've used would be appreciated.","['elementary-set-theory', 'notation', 'computer-science']"
2921193,Deriving Polya’s Random Walk Constants,"It is a well known theorem of Pólya that a random walk in 1 or 2 dimensions has a probability of 1 of returning to the origin. However, the probability in the 3-dimensional case is given by a strange triple integral. How is this integral derived?","['calculus', 'random-walk']"
2921215,Question on Shortest Path on the Sphere,"Consider the following parameterization of the unit sphere: $$X(u,v)=(\sin v \cos u , \sin v \sin u, \cos v)$$ where $u \in (-\pi,\pi),v \in (0,\pi)$ . First of all, I am told to find the length of the curve $u=u_0, t \in [a,b]$ , where $u_0$ is a constant and $0<a<b<\pi$ (I call this curve $\alpha$ ). It is easy to see that it is given by $b-a$ . After that, I am told to show that if $(u(t),v(t)), t \in [a,b]$ is a curve on $(-\pi,\pi) \times (0,\pi)$ , then the curve on the surface $\beta (t)=X(u(t),v(t))$ which satsifies the $\alpha(a)=\beta(a)$ and $\alpha(b)=\beta(b)$ has a length $\geq b-a$ . I know there is something called ""geodesic"", but I would to like to show it explicitly without evoking any large theorem. I tried to compute the length of $X(a(t),b(t))$ , which is given by $$L=\int_a^b \sqrt{\sin ^2 (v(t)) \left(\frac{du}{dt}\right)^2+\left(\frac{dv}{dt}\right)^2}dt$$ I am stuck here. Can anyone give me some hint?","['curves', 'geodesic', 'surfaces', 'differential-geometry']"
2921240,Constructive intermediate value theorem,"I have given real numbers $x_1,x_2,y_1,y_2$ such that $x_1 > x_2$ and $y_1 < y_2$. The the claim is that there exists some $\lambda \in (0,1)$ such that $\lambda (x_1 - x_2) + (1-\lambda)(y_1-y_2) = 0$. In order to proof this, one needs ( at least in my opinion) the intermediate value theorem. But the intermediate value theorem does not hold in constructive mathematics (that is without the law of excluded middle; or constructive mathematics acts in intuitionistic logic). For a proof of this c.f. this paper. Is there any constructive way to show the above equation?","['constructive-mathematics', 'logic', 'analysis']"
2921251,"Symmetric monotonic function $f$ on $[0,1]^2$ with $\int_0^1f(x,y)dy=x$","I am searching for an almost-everywhere continuous and monotonic function $f:[0,1]^2\to[0,1]$ with the following properties: $f(x,y)=f(y,x)$ $f(0,y)=0$ and $f(1,y)=1$ (so $f(0,1)$ and $f(1,0)$ are undefined) $f(x,y)=1-f(1-x,1-y)$ therefore $f(0.5,0.5)=0.5$ $\int_0^1f(x,y)dy=x$ Here is what it should look like Are there functions having those properties? And if yes which one? If possible, I would prefer a not too complicated function. Here is a clarification: By ""monotonic function $f:[0,1]^2\to[0,1]$ "" I mean ""function for which, for any $y\in [0,1]$ , the function $f_y: [0,1]\to[0,1]$ so that $f_y(x)=f(x,y)$ is monotonic (and reciprocally by swapping $x$ and $y$ )"". Here are my attempts so far: there is a singular ""discontinuous solution"": the function which is equal to 0 when $x+y\lt1$ and to 1 when $x+y\gt1$ ; it's not really a solution since it's discontinuous, but it can be a starter if you know an invertible and monotonic function $g$ on $[0,1]$ with $g(0)=\infty$ and $g(1)=0$ , you can combine them like this: $f(x,y)=g^{-1}(g(x)g(y))$ and it already have the properties 1 and 2 to enforce the property 4 you can define instead $f(x,y)=g^{-1}(\frac{g(x)g(y)}{g(0.5)})$ to enforce the property 3 (and 4) you can define instead $f(x,y)=h^{-1}(\frac{h(g^{-1}(\frac{g(x)g(y)}{g(0.5}))+h(1-g^{-1}(\frac{g(1-x)g(1-y)}{g(0.5)}))}{2})$ with a generalised $h$ -mean, but it's starting to get ugly (the $\frac{1}{g(0.5)}$ seems to be mandatory to have the right shape but I can't explain why) if we try with $g=ln$ , we get $f(x,y)=exp(\frac{ln(x)ln(y)}{ln(0.5)})$ , but we don't have the property 3, so we need to change it to $f(x,y)=h^{-1}(\frac{h(exp(\frac{ln(x)ln(y)}{ln(0.5)}))+h(1-exp(\frac{ln(1-x)ln(1-y)}{ln(0.5)}))}{2})$ , but I can't find an $h$ that allow to have property 5: using the power means (with $h(x)=x^p$ ), at $y=0.5$ property 5 always holds, but at $y=0.25$ , I always have $\int_0^1f(0.25,y)dy\gt x$ . It seems to decrease with $p$ , but even with $p=-\infty$ (which corresponds to the minimum instead of a mean), I have $\int_0^1f(0.25,y)dy=0.276657\gt x$ idem for $g=arctanh$ : the minimum is $0.2703866$ it's slightly better with $g=x^{-1}-1$ : we get $f(x,y)=((x^{-1}-1)(y^{-1}-1)+1)^{-1}$ with which properties 1, 2, 3 and 4 already hold, but sadly not property 5: $\int_0^1f(x,y)dy=x\frac{2x-1+2(x-1)arctanh(2x-1)}{(2x-1)^2}\neq x$ Here is the background: This question follows this one : I'm trying to find a way to calculate (or approximate) $Pr(S|A B)$ given $Pr(S|A)$ and $Pr(S|B)$ (and possibly $Pr(S)$ ), and knowing that $A$ and $B$ are independent, and that if $Pr(S|A_1)\geq Pr(S|A_2)$ then $Pr(S|A_1 B)\geq Pr(S|A_2 B)$ . The last condition was not present in the initial question but seems useful to me: if the skill categories are well defined, a player that is better at a category of skills than another player should be better at any skill test from this category than the other player. EDIT: Since that question was asked and answered, I realised that the 5th property is not necessary for my problem, see my last comment .","['integration', 'recreational-mathematics', 'surfaces', 'real-analysis']"
2921300,definite integral $\int_{0}^{\frac{\pi}{4}} \frac{\sin^2x\cos^2x}{\sin^3x+\cos^3x}dx$,"$$\int_{0}^{\frac{\pi}{4}} \frac{\sin^2x\cos^2x}{\sin^3x+\cos^3x}dx$$ I tried $2$ or $3$ trigonometric transformations but it did not work. One of them is as follows 
$$\frac{\sin^2x\cos^2x}{(\sin x+\cos x)(1-\sin x\cos x)}$$ after that I am not able to figure out what to do. If I use double angle formula then 
$$\frac{\frac{\sin2x}{4}}{(\sin x+\cos x)\left(1-\frac{\sin2x}{2}\right)}$$ again i am clueless","['integration', 'calculus', 'definite-integrals']"
2921333,Proving $S= S^3$,"Let $\mathrm{A,B,C,D}$ be (not necessarily square) real matrices such that $\mathrm{A^T = BCD , B^T= CDA, C^T = DAB, D^T = ABC}$ for the matrix $\mathrm{S= ABCD}$ prove that $\mathrm{S= S^3}$ Attempt: $\mathrm{S= ABCD \implies S^T = D^TC^T B^T A^T = (ABC)(DAB)(CDA)(BCD)\\ (S^T)^T = (D^TC^TB^TA^T)^3 \implies S^3 = (S^T)}$ (using reversal law) Where have I gone wrong? Or is it that $\mathrm{S= S^T}$, how can we show that?","['matrices', 'symmetric-matrices']"
2921359,Digit sum of $3k$ given the digit sums of $k$ and $44k$,"Define $S(n)$ to be the digit sum of $n,n\in\mathbb{N_{\geqslant0}}$ . Then it is given that: $S(n)\equiv n\pmod9,\forall n\in\mathbb{N}$ $S(a+b)\leqslant S(a)+S(b),\forall a,b\in\mathbb{N}$ $S(ab)\leqslant S(a)S(b),\forall a,b\in\mathbb{N}$ Determine $S(3k)$ given that $S(k)=100$ and $S(44k)=800$ , $k\in\mathbb{N_{\geqslant0}}$ . Do not find $k$ . This is what I have gathered so far: $S(3)=3$ and $S(k)=100$ $S(3k)\leqslant S(3)\times S(k)$ $\therefore S(3k)\leqslant 300$ From here on I'm not sure how to determine the precise value of $S(k)$ . I know that a possible $k$ for $S(k)=100$ and $S(44k)=800$ is $k=\frac{10^{100}-1}{9}=11\cdots1$ , where $k$ has 100 digits and all its digits are $1$ . Then $S(\frac{10^{100}-1}{9})=300$ . But the answer should not include the value of $k$ . Any ideas how I can change the above to become an equality from an inequality?","['number-theory', 'elementary-number-theory']"
2921365,Another proof for impossibility of covering $\mathbb{R}^{n}$ with a set of varieties of cardinality less than $2^{\aleph_0}$,"Let $\mathbb{R}^{n}$ be the affine $n$-space. Let $\{V_{\alpha} \}_{\alpha \in \Gamma}$ be a set of real varieteis such that $\mathbb{R}^{n} \subseteq {\bigcup V_{\alpha}}.$ Prove that $|\Gamma| \geq 2^{\aleph_{0}}$ I know that one can take the set $A =\{(t^{a_{1}},...,t^{a_{n}}) | t \in [0,1],\hspace{0.2cm} a_{1},...,a_{n} \text{ such that they are linearly independent over} \hspace{0.2cm}\mathbb{Q}\}$ and show that every polynomial intersects with this set in finitly many points and prove the statement. But now does anyone know rather a different proof of this statement?","['elementary-set-theory', 'algebraic-geometry', 'alternative-proof']"
2921376,How to evaluate $\int_0^a\frac{x^4}{(a^2+x^2)^4}dx$?,"I have to evaluate $$\int_0^a\frac{x^4}{(a^2+x^2)^4}\,{\rm d}x$$ I tried to substitute $x=a\tan\theta$ which then simplifies to
$$\frac1{a^5}\int_0^\frac\pi4\sin^4\theta\cos^2\theta\, {\rm d}\theta$$. Now,its quite hectic to solve this. Is there any other method out?","['integration', 'calculus', 'definite-integrals']"
2921389,Confusion about embeddings of algebraic varieties,"I tried to learn a bit about embeddings of algebraic varieties into other algebraic varieties. Depending on the textbook/online notes I consider, there are the notions of closed immersion and open immersion. Some of them say that the right notion of an ""embedding"" is a closed immersion but some say that one should rather take open immersion or even just immersion by which they mean a map that can be factored into an open immersion and a closed immersion. 1) What is the correct notion of ""embedding"" for a morphism $f:X\to Y$ between (smooth) projective varieties? 2) Can you explain the difference between open and closed immersions in an example? Furthermore, whenever I read about explicit examples (e.g. projection from a point, Veronese embedding, Segre embedding,...), it is only shown that the map is injective and not a single word is said about what happens on tangent spaces. So the condition that actually turns an injective morphism into an embedding is never checked. 3) Why is that so? Under which conditions is it clear that we constructed an embedding?",['algebraic-geometry']
2921428,"Hom(G,-) functor is exact?","Given an exact sequence $0 \rightarrow A \rightarrow B \rightarrow C \rightarrow 0$ we know that the induced sequence $0 \rightarrow Hom(G,A)\rightarrow Hom(G,B)\rightarrow Hom(G,C)$ is exact. But wouldn't the last homomorphism be onto since functors preserve injectivivity and surjectivity? And thus you could extend the sequence by $Hom(G,C) \rightarrow 0$ and preserve exactness? It would follow that $Hom(G,-)$ is exact. What is my mistake?","['homological-algebra', 'group-theory', 'abstract-algebra']"
2921458,"If $n$ is such a positive integer, that $8|n^2$, then $4|n$","I'm new to the subject of discrete mathematics. This statement is either true or false and it has to be proved. I've struggled with this exercise for quite a while, and this is what I came up with: If $8|n^2$ then $n^2$ is even If $n^2$ is even then $n$ is even If $n$ is positive and $4|n$ then $n = 4k$ ($k$ - any positive integer) If $n = 4k$ then $n^2 = 16k^2$ $8|16k^2$ and $4|4k$, therefore the statement is true $n|m$ means $n$ divides $m$ Can someone verify whether I proved it or not?","['elementary-number-theory', 'divisibility', 'discrete-mathematics']"
2921484,ODE solution not unique,"Show that the solution of the initial value problem $$y'=-2\sin(x)\sqrt{y}, \quad y(0)=1, \quad y\in[0,2]$$ that are defined for all $x\in\mathbb{R}$ are not unique. I have found one such solution:
$$\dfrac{dy}{dx}=-2\sin(x)\sqrt{y}$$
$$y=(\cos(x)+C)^2$$
combining with the initial value yields:
$$y=(\cos(x))^2$$ Is it possible for me to find more? Is there a certain pattern here?",['ordinary-differential-equations']
2921486,A deck of $52$ cards is divided into four piles of $13$ cards. What is the probability that each pile has one ace?,"An ordinary deck of $52$ playing cards is randomly divided into $4$ piles of $13$ cards each. Compute the probability that each pile has exactly one ace. The answer provided is is $(39*26*13)/(51*50*49) \approx 0.105$ The above answer uses conditional probability, but I would like to know what's wrong with my reasoning: Call the four piles of partitions $1$, $2$, $3$, and $4$. For partition $1$, there are ${4 \choose 1}$ ways to choose which ace the partition will contain. Then, there are ${48\choose 12}$ ways to choose the remaining $12$ cards, as we cannot choose any other aces. For partition $2$, there are ${3\choose 1}$ ways to choose which ace the partition will contain. Then, there are ${36\choose 12}$ ways to choose the remaining $12$ cards, as there are only $36$ non-ace cards left. Following similar reasoning for partitions $3$ and $4$, we find that there are ${2\choose 1}{24 \choose 12}$ and ${1\choose 1}{12 \choose 12} = 1$ ways to form those hands. Therefore, my probability is given by $$\frac{4 \cdot {48\choose 12} + 3\cdot{36\choose 12} + 2\cdot{24\choose 12}}{{52\choose 13}{39\choose 13}{26\choose 13}} \not \approx 0.105$$ The denominator is the number of ways to choose the cards in each hand without any constraints. I am not sure what is wrong with my computation.","['probability-theory', 'probability']"
2921506,Evaluating complex integral $\int_{0}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} $ via different contour,"I got an complex integral $\int_{0}^{\pi} \frac {x \sin
> x}{1+a^2-2a(\cos x)} $ for $a \ge 1$ and my given contour is a
  rectangle such that $|Re(z)|\le \pi$ and $0 \le |Im(z)| \le h \to
 \infty$. I can rewrite the integral as $\int_{0}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} =1/2\int_{- \pi}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} $ and use the substitution: $z = e^{ix}$, $\;$ $\cos x = \frac {e^{ix}-e^{-ix}}{2} = \frac {z + \frac {1}{z}}{2}$,$\;$
$dz = ie^{ix}dx$ We then received the expression for $f(z)$ as $\frac {z(-i)}{1+a^2-a(\frac {1}{z}+z)} $ and we want to find the singularities of this function. After some algebra, we get that we have two singularities at $z = a$ $\;$ & $\;$$z = \frac {1}{a}$, which are poles of the first order. To evaluate that integral we are going to use the residue theorem: $res_a = \lim_{\to a} \frac {z(-i)}{(z-1/a)}= \frac {a(-i)}{(a-1/a)}$ $res_{1/a} = \lim_{\to 1/a} \frac {z(-i)}{(z-a)}=\frac {1/a(-i)}{(-a+1/a)}$ and then $I = 2i\pi (res_a+res_{1/a})$ But this looks like the result if we were integrating around unit circle and I don't understand how that different contour changes the result to $I = \frac {\pi}{2} \frac {Ln(a+1)}{Ln(a)}$, according to my textbook. I was thinking about plugging the residues back to $z = e^{ix}$, but I don't understand how do I get that '+1', etc. There was posted the same integral, but I am interested in that different integration contour.","['integration', 'definite-integrals', 'complex-analysis', 'contour-integration', 'residue-calculus']"
2921507,Infinite dimensional Banach lattice $L^\infty(X)$ is not order continuous,"Consider an arbitrary measure space $(X,\Sigma,\mu)$, with the only assumption being that $L^\infty(X)$ is infinite dimensional. Consider $L^\infty(X)$ as a Banach lattice with the usual ordering. As an exercise in Operator Theoretic Aspects of Ergodic Theory by Eisner et. al we are asked to show that $L^\infty(X)$  does not have an order continuous norm. By order continuous norm I mean that if $(f_n)\subset L^\infty(X)$ is a sequence such that $f_{n+1}\leq f_n$ and $\inf f_n=0$ implies $\|f_n\|\to 0$. Now it is easy to construct a specific example that is not order continuous. Take for example $X=[0,1]$, $\Sigma$ the Borel $\sigma$-algebra and $\mu=\lambda$. If we consider $(f_n)=(\mathbf{1}_{[0,1/n]})$ we see that this space cannot be order continuous. Now the way the question is asked leads me to believe that the authors are asking to find such a sequence contradicting order continuity for any arbitrary infinite dimensional $L^\infty(X)$. To do so I would like to just adjust the above example, but critically the above example relies on there being an infinite nested sequence of measurable sets such that the only set contained in all elements of the sequence has measure $0$, but all sets in the sequence have positive measure. Unfortunately I am unable to tell whether $L^\infty(X)$ being infinite dimensional places such a restriction on the measure space. So I'm basically looking for a proof of this fact, or any other consequences of the infinite dimensionality of $L^\infty(X)$that I could exploit.","['banach-spaces', 'measure-theory', 'functional-analysis', 'banach-lattices']"
2921518,Leopoldt's Conjecture and Congruence Subgroups of Prime Ideal Powers,"Let $K$ be a number field and let $\mathfrak{p} \subset \mathcal{O}_K$ be a nonzero prime ideal in its ring of integers. I read here that the following question is equivalent to (a version of) Leopoldt's conjecture: Does every finite-index subgroup $U \subset \mathcal{O}_K^\times$ contain a congruence subgroup of the form $$
\mathcal{O}_K^\times(\mathfrak{p}^m) := \{ x \in \mathcal{O}_K^\times : x \equiv 1 \text{ mod } \mathfrak{p}^m \}
$$ for some $m \in \mathbb{N}$ ? As far as I know, the Leopold conjecture for a number field $K$ and a prime number $p \in \mathbb{Z}$ states that the $p$ -adic regulator $R_p$ of $K$ vanishes. Question: Is the above problem open? If so, is it equivalent to Leopoldt's conjecture?","['number-theory', 'algebraic-number-theory']"
2921558,Solve a system of ordinary differential equations,"I have the following set of ordinary differential equations: $$
\begin{cases}
x_1'(s) &= -e^{-s} (1-x_1(s)) - x_2(s) + x_1(s) x_3(s)\\
x_2'(s) &= -x_2(s) + x_1(s)^2\\
x_3'(s) &= -x_3(s) + x_1(s),
\end{cases}
$$ with boundary condition $x_2(0)=x_3(0)=0$ . I am looking for a method to find an exact solution for this type of ODE. In particular I am interested in finding a solution for $x_1$ which satisfies $x_1(\infty) = 0$ , but it already excelent if the solution of $x_1$ is simply given in function of a general boundary condition $x_1(0) = a$ . EDIT I have found this link of methods for solving this type of problems, but my problem does not seem to fit in any of the suggested methods.","['ordinary-differential-equations', 'real-analysis']"
2921560,Is this Riemann sum formula for definite integral using of prime numbers true?,"While answering another question in MSE , I had used the following result which I thought was a trivial consequence of the prime number theorem and equidistribution.  However, I realized from the comments that many people  thought that this was not either true or counter intuitive. Hence I am posting this as a question looking for a proof or disproof. Let $p_k$ be the $k$-th prime and $f$ be a continuous function
  Riemann integrable in $(0,1)$ such that $$\lim_{n \to \infty}\frac{1}{n}\sum_{r = 1}^{n}f\Big(\frac{r}{n}\Big)
= \int_{0}^{1}f(x)dx.  $$ Then,    $$ \lim_{n \to \infty}\frac{1}{n}\sum_{r =
1}^{n}f\Big(\frac{p_r}{p_n}\Big) = \int_{0}^{1}f(x)dx. $$ My proof was based on showing that as $n \to \infty$, the ratios $p_r/p_n$ approached equidistribution in $(0,1)$ hence the integral follows as a trivial property of equidistributed sequence. Motivation : There are several identities, limits etc on prime numbers which can be easily proven using this simple formula, including all answers to all three questions on the arithmetic, geometric and harmonic means of primes mentioned in the above link.","['integration', 'definite-integrals', 'number-theory', 'real-analysis', 'prime-numbers']"
2921610,Non-constant coefficient matrix in first order linear differential equations,"I want to solve a differential equation of the following form 
$$
\frac{d}{dt}x=A(t)x\, ,
$$
where $A(t)$ does not commute at different times. This equation holds on the interval $(a,b)$. Hence, the solution cannot be written as $e^{\int_a^td\tau A(\tau)}$. I have been searching now for several hours, and I only found (source: http://www.macs.hw.ac.uk/~simonm/linalg.pdf pg. 92) the so called ""Neumann series"" 
$$
x(t)=\left(I+\int_0^{t}A(\tau)d\tau + \int_0^{t}A(\tau_1)\int_0^{\tau_1}A(\tau_2)d\tau_2 d\tau_1+...\right) x_0\, .
$$
(The series is very reminiscent of the Dyson series with the evolution operator in quantum mechanics, here $A(t)$ is not hermitian.)
Here are my doubts: In the formula the lower bound is $0$. Is this part of the formula or can it be any number? in my case $a$. Is this an infinite sum? if yes how can I stop at a certain summand to have an approximation? How does this series continue? is it similar to the time ordering in
quantum mechanics, i.e., one takes every possible commutation or is the third term just: 
$$
 \int_0^{t}A(\tau_1)\int_0^{\tau_1}A(\tau_2)\int_0^{\tau_2}A(\tau_3)d\tau_2d\tau_3 d\tau_1\, .
$$ In the link above, it says, one can check that this is the solution by taking the derivative with respect to $t$. How can one take the derivative, when it depends on the upper bound of the integral and how is the product rule for non commutative matrices? Thank you very much.","['matrix-calculus', 'noncommutative-algebra', 'ordinary-differential-equations']"
2921667,Solving the factorial equation $(n + 4)! = 90(n + 2)!$,"Solve the equation below: $(n+4)!
 = 90
(n+2)!$ I did this: $(n+4)(n+3)(n+2)!
 = 90
(n+2)!$ $n^2+7n+12+90=0$ $n^2+7n+102=0$ Is there anymore to this?","['algebra-precalculus', 'factorial']"
2921691,Prove that $(x−2y+z)^2 \geq 4xz−8y$,"Let $x,y,z$ be nonnegative real numbers such that $x+z\leq2$ Prove that, and determine when equality holds. $(x−2y+z)^2 \geq 4xz−8y$ Please correct me if my methods are incorrect or would lead nowhere. I tried expanding the LHS of the inequality getting $x^2+4y^2+z^2-4xy-4yz+2xz \geq 4xz-8y$ And got lost as to how I should manipulate the inequality to find something true through rough work. After I tried manipulating $x+z\leq2$   subtract 2 $x+z-2\leq0$ since $y\ge 0$ $x+z-2\le y$
subtract 2y and add 2 to both sides $x-2y+z\le 2-y$ And again lost sight of how I could manipulate the inequalities.","['proof-verification', 'multivariable-calculus', 'polynomials', 'sum-of-squares-method', 'inequality']"
2921693,Matrices over noncommutative rings?,"In chapter 1, section 2 of Categories for the Working Mathematician , Mac Lane says: For each commutative ring $K$, the set $\mathbf{Matr_K}$ of all rectangular matrices with entries in $K$ is a category; the objects are all positive integers $m,n,...$, and each $m\times n$ matrix $A$ is regarded as an arrow $A:n\rightarrow m$, with composition the usual matrix product. This is undoubtedly true. But why restrict the statement to commutative rings? Surely, matrices over noncommutative rings also form a category. Or am I missing something? The answer to this question suggests the noncommutative rings are just not that well studied, so perhaps Perhaps Mac Lane was going for familiarly over generality. Another question addresses the same passage in the book but does not raise the question of commutativity. To be specific about my questions Is my claim ""For each noncommutative ring $K$, the set of all rectangular matrices with entries in $K$ is a category"" true? Is the category of rectangular matrices over a commutative ring somehow nicer than that over all (commutative or otherwise) rings? EDIT: Strikeout the claim that noncommutative rings are not well studied, given the consensus in the comments that they are. In that case, why stipulate commutative rings? Were they less well studied back in the 1970s?","['matrices', 'noncommutative-algebra', 'category-theory']"
2921700,How to simplify or upperbound this summation?,"I am not a mathematician, so sorry for this trivial question. Is there a way to simplify or to upperbound the following summation: $$ \sum_{i=1}^n{\exp{\left(-\frac{i^2}{\sigma^2}\right)}}.$$ Can I use geometric series? EDIT: I have difficulty because of the power $2$, i.e if the summation would be $ \sum\limits_{i=1}^n{\exp{\left(-\frac{i}{\sigma^2}\right)}} $ then it would be easy to apply geometric series!","['geometric-series', 'sequences-and-series']"
2921750,Infinite sum of reciprocals of squares of lengths of tangents from origin to the curve $y=\sin x$,"Let tangents be drawn to the curve $y=\sin x$ from the origin. Let the points of contact of these tangents with the curve be $(x_k,y_k)$ where $x_k\gt 0; k\ge 1$ such that $x_k\in (\pi k,  (k+1)\pi)$ and $$a_k=\sqrt {x_k^2+y_k^2}$$ (Which is basically the distance between the corresponding point of contact and the origin i.e. the length of tangent from origin)  . I wanted to know the value of $$\sum_{k=1}^{\infty} \frac {1}{a_k ^2}$$ Now this question has just popped out in my brain and is not copied from any assignment or any book so I don't know whether it will finally reach a conclusion or not. I tried writing the equation of tangent to this curve from origin and then finding the points of contact but did not get a proper result which just that the $x$ coordinates of the points of contact will be the positive solutions of the equation $\tan x=x$ On searching internet for sometime about the solutions of $\tan x=x$ I got two important properties of this equation.  If $(\lambda _n)_{n\in N}$ denote the roots of this equation then $$1)\sum_n^{\infty} \lambda _n \to \infty$$ $$2)\sum_n^{\infty} \frac {1}{\lambda _n^2} =\frac {1}{10}$$ But were not of much help. I also tried writing the points in polar coordinates to see if that could be of some help but I still failed miserably. I could not think of any method so any other method would be openly welcomed. Any help would be very beneficial to solve this problem. Thanks in advance. Edit: On trying a bit more using some coordinate geometry I found that the locus of the points of contact is $$x^2-y^2=x^2y^2$$ Hence for sum we just need to find $$\sum_{k=1}^{\infty} \frac {\lambda _k ^2 +1}{\lambda _k ^2 (\lambda _k ^2 +2)}=\sum_{k=1}^{\infty} \frac {1}{\lambda _k ^2} -\sum_{k=1}^{\infty} \frac {1}{\lambda _k ^2 (\lambda _k ^2 +2)}=\frac {1}{10} -\sum_{k=1}^{\infty} \frac {1}{\lambda _k ^2 (\lambda _k ^2 +2)}=\frac {1}{10} -\sum_{k=1}^{\infty} \frac {1}{2\lambda _k ^2} +\sum_{k=1}^{\infty} \frac {1}{2(\lambda _k ^2 +2)} =\frac {1}{20}+\frac {1}{2}\sum_{k=1}^{\infty} \frac {1}{\lambda _k ^2 +2} 
 $$ Now for the second summation I did think about it to form a series but for the roots to be $\lambda _k^2 +2$ we just need to substitute $x\to \sqrt {x−2}$ in power series of $\frac {\sin x-x\cos x}{x^3}$ and then get the result but it was still a lot confusing for me. Using $x\to\sqrt {x-2}$ in the above power series and using Wolfy I have got a series. So we need ratio of coefficient of $x$ to the constant term so is the value of second summation equal to $$\frac {5\sqrt 2\sinh(\sqrt 2)−6\cosh(\sqrt 2)}{4(2\cosh(\sqrt 2)−\sqrt 2\sinh(\sqrt 2))}?$$ Is this value correct or did I do it wrong? I would also like to know if there is some other method to solve this problem","['coordinate-systems', 'calculus', 'trigonometry', 'sequences-and-series']"
2921758,Motivation/intuition behind using linear algebra behind these combinatorics problem,"What is the motivation behind using linear algebra in these three problems ? A pair $(m,n)$ is called nice if there is a directed graph with (self edge are allowed, but multiple edge are not allowed) $n$ vertices such that for every pair of vertices is connected by exactly $m$ paths of lenght $2$ . Prove $(m,n)$ is nice iff $m \leq n$ and $\sqrt{mn} \in \mathbb{Z}$ . Let $S$ be a finite subset of $[0,1]$ containing $0$ and $1$ and such that every distance that occurs betwen paris of elements occurs at least twice, except for the distance $1$ . Prove that $S$ contains only rational numbers. Prove that $n$ distnict points, not all of them lying on a line, determine atleast $n$ distnict lines ? By ""motivation"", I mean suppose you are good in linear algebra, but you don't know how to use linear algebra in combinatorics. What structure in the problem would trigger you that linear algebra is a good tool in using that ? I understand the solutions using linear algebra to all these above three problems, but I have a hard time figuring out how one could have think of them in the first place - I mean, linear transformation between vector spaces and directed graph are two completely different things, how can one see the connection between them ? As an example of what I mean, consider this problem: Let $n$ be an even integer. How many subsets of the set $\{1,2,\dots,n\}$ can you pick if they all have to have odd size but the intersection of any two of them has to have even size? For this problem, this by Fields Medallist Timothy Gowers gives a really good motivation of how one can think of using linear algebra (I'm wanting this kind of answer) If you continue experimenting in this way, you will find the same thing every time: if you have chosen fewer than $n$ sets then you can choose more, but once you get to n sets then you get stuck. But there seems to be a great deal of freedom about how you choose the sets. This contrasts with many problems in extremal combinatorics, where the best possible examples are often unique, or unique up to some obvious symmetry. (A good example of the latter: how many subsets of $\{1,2,\dots,n\}$ can you choose if none of your subsets is contained in any other? The unique best possible collection of sets is all sets of size n/2.) Are there any other circumstances where you have a collection of objects, and a condition on pairs $(x,y)$ of those objects, such that (i) whenever you have chosen objects $x_1,x_2,\dots,x_m$ with $m<n$ there are many different ways of choosing y such that the condition holds for each pair $(x_i,y)$ , and (ii) it is impossible to choose more than n of them if any two have to satisfy the condition? Yes there are: a common one is when the objects are vectors in $\mathbb{R}^n$ and the condition on a pair $(x,y)$ is that x and y should be orthogonal. Since orthogonality implies independence, we cannot choose more than n non-zero vectors that are all orthogonal to each other. Can we relate these two situations?","['algebraic-combinatorics', 'linear-algebra', 'combinatorics']"
2921801,Are Hodge numbers topological invariants for manifolds that admit a Kähler structure?,"I know that all fibers in a analytic fibration (proper, holomorpic) are homeomorphic, and if the fibers are Kählerian manifolds, then they have equal Hodge numbers. Could it happen however that a manifold admits different Kählerian structures for which the Hodge numbers differ?","['hodge-theory', 'kahler-manifolds', 'complex-geometry', 'algebraic-geometry', 'algebraic-topology']"
2921887,Second-order nonlinear ODE involving cosine of the unknown function,"Question I am interested in solving for $u : S^1 \to S^1$ given the following ODE, where $v : S^1 \to S^1$ is a given continuous function: $$u'' = -A\cos(u-v) \tag{$\dagger$}$$ Is there any hope of an analytic solution? Can anything be said about the behavior of the solution as $A$ varies? If it helps, I have $\int_{S^1} \cos[v(\theta)]\ d\theta = \int_{S^1} \sin[v(\theta)]\ d\theta = 0$ . Background I've been interested in crystalline and anisotropic mean curvature flows, along the line of the work of Novaga and Chambolle, e.g. https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.21668 My actual problem is more involved and three-dimensional, but to build intuition I've been trying to think about the following two-dimensional simplification. Consider a curve $\gamma:S^1 \to \mathbb{R}^2$ , which for simplicity we can take to be arclength-parameterized with arc length $2\pi$ . Let us write $\gamma'(\theta) = [\cos(v[\theta]), \sin(v[\theta])]$ . I want to study sections of the bundle of directors $\hat{m}(\theta) \in S^1$ along the curve: I want these directors to approximate the orientation of the curve normal, while also behaving more smoothly near regions of sharp curvature. Let $\hat{n}(\theta) = [-\sin(v[\theta]), \cos(v[\theta])]$ denote the curve normal at $\theta$ ; I would like to look at minimizers of the functional $$E(\hat m) = \int_{S^1} \left(\frac{1}{2}\left\|\hat{m}'(\theta)\right\|^2 + \frac{A}{2} \left\|\hat m(\theta) - \hat n(\theta)\right\|^2\right)\,ds$$ where the real constant $A$ controls the relative importance of smoothness vs adapting to the curve normal. Applying the calculus of variations, we have that an extremizer $\hat{m}^*(\theta) = [\cos u^*(\theta), \sin u^*(\theta)]$ of $E$ satisfies the ODE $(u^*)''(\theta) = -A\cos[u^*(\theta) - v(\theta)]$ , where $v: S^1\to S^1$ is prescribed by the choice of $\gamma$ . And we know that $\int_{S^1} \cos[v(\theta)]\ d\theta = \int_{S^1} \sin[v(\theta)]\ d\theta = 0$ , since the curve $\gamma$ is closed. Hence my question. My eventual goal is to take variations of $E(\hat{m}^*)$ with respect to $\gamma$ to flow the curve, so an analytic solution to the ODE ( $\dagger$ ) would be very helpful. Some trivial observations: $E(\hat{m}^*)$ is bounded above by on the one hand $A\pi$ , and on the other hand, $\int_{S^1} \kappa(\theta)^2\,ds$ (where $\kappa(\theta)$ is the curvature at $\theta$ ), for a constant director field, and $\hat m = \hat n$ , respectively.","['heat-equation', 'closed-form', 'ordinary-differential-equations']"
2921924,Modular Multiplicative Inverses,"I'm in a cryptography and struggling with understanding how the Euclidean Algorithm necessarily works for finding multiplicative inverses. We haven't actually covered the algorithm yet, just a way to brute force finding the inverses but I like working with an algorithm instead of just guess and checking so I learned it myself. In the equation 1/5 mod 13 I understand that this is equivalent to 5x = 1 mod 13 however when going through the algorithm I get the answer to be -5 instead of 8 which it is supposed to be. Can anyone shed some light on where I'm going wrong? Here's my work. (a) 1/5 mod 13 1/5 mod 13 ≡ 5-1 mod 13 ≡ 5x = 1 (mod 13) 13 = 2(5) + 3 5 = 1(3) + 2 3 = 1(2) + 1 GCD of 13 and 5 is 1. 1 = 3 – 2(1) = 3 – (5 – 3(1)) = 3 - 5 + 3 = 2(3) - 5 = 2(13 - 2(5)) - 5 = 2(13) – 4(5) – 5 = 2(13) -5(5) -> mod 13 on both sides 1 mod 13 = 0 – 5(5) mod 13 1 = -5(5) mod 13 x = -5","['modular-arithmetic', 'discrete-mathematics']"
2922030,Show that $f:M_f \rightarrow A_f$ is bijective when $f(x)=\frac{x-1}{x+1}$,"Problem Show that $f:M_f \rightarrow A_f$ is bijective when $f(x)=\frac{x-1}{x+1}$ Edit when $M_f \in \mathbb{R}\setminus \{-1\}$ and $A_f \subset \mathbb{R}$ Attempt to solve $f:M_f\rightarrow A_f$ is bijective when it is injective and surjective at the same time. Injection $f:M_f \rightarrow Af$ is injective when: $$ \forall (x,y) \in M_f : x \neq y \implies f(x)\neq f(y)  $$ when $p= x\neq y$ and $q=f(x)\neq f(y)$. If it is possible to show $\neg p \implies \neg q$ it means: $$ \neg p \implies \neg q \iff p \implies q $$
meaning $$ x \neq y \implies f(x) \neq f(y) \iff x = y \implies f(x)= f(y) $$ I can show: $$ \frac{x-1}{x+1}=\frac{y-1}{y+1} $$
$$ \implies  (x+1)(y+1)\frac{x-1}{x+1}=(x+1)(y+1)\frac{y-1}{y+1} $$
$$ \implies (y+1)(x-1)=(x+1)(y-1) $$
$$ \implies xy-y+x-1 = xy -x + y-1 $$
$$ \implies xy+2x = xy +2y $$
$$ \implies 2x=2y \implies x = y $$ Conclusion: $f:M_f \rightarrow A_f$ is injective since $$ x \neq y \implies f(x) \neq f(y) \iff x = y \implies f(x)= f(y) $$ is true Surjection $$ f:M_f \rightarrow A_f $$ is surjective when $$ \forall y \in A_f \exists x \in M_f : f(x)=y$$ meaning if $$ f(x)=y $$ assuming $x \neq -1$ $$ \implies \frac{x-1}{x+1}=y $$
$$ \implies x-1=y(x+1) $$
$$ \implies x-1=yx+y $$
$$ \implies x(1-y)=1+y $$
$$ \implies x = \frac{1+y}{1-y} $$ Now we get $$ f(x)=f(\frac{1+y}{1-y}) $$ $$\implies f(x)=\frac{(\frac{1+y}{1-y})-1}{(\frac{1+y}{1-y})+1}$$ For some reason odd reason i cannot get this into form $f(x)=y$. Should be simple elementary algebra but cannot see how this equals to $y$. In theory this expression should be equal to $y$ which would make $f:M_f\rightarrow Af$ surjective and then bijective since it was also injective.","['functions', 'real-analysis']"
2922060,Evaluate: $\lim\limits_{r \to \infty} \frac{\sqrt{r}}{e^{r}}\sum_{n=0}^{\infty}\frac{\Gamma{(n+3/2)}r^n}{(n!)^2}$,"Evaluate:
  $$\lim\limits_{r \to \infty} \frac{\sqrt{r}}{e^{r}}\sum_{n=0}^{\infty}\frac{\Gamma{(n+3/2)}r^n}{(n!)^2}$$ My effort: \begin{aligned}\Gamma \left({\tfrac {1}{2}}+n\right)&={(2n)! \over 4^{n}n!}{\sqrt {\pi }}
\end{aligned} Therefore,
$$ \frac{\sqrt{r}}{e^{r}}\sum_{n=0}^{\infty}\frac{\Gamma{(n+3/2)}r^n}{(n!)^2}= \frac{\sqrt{r \pi}}{4 e^{r}}\sum_{n=0}^{\infty}\frac{{(2n+2)! }}{4^{n}(n+1)! (n!)^2}r^n = \frac{\sqrt{\pi}}{4 e^{r}}\sum_{n=0}^{\infty}\frac{{(2n+2)! }}{4^{n}(n+1)! (n!)^2}{(\sqrt{r})}^{2n+1}, $$
which is very similar to:
$$\arcsin x=\sum _{n=0}^{\infty }{\frac {(2n)!}{4^{n}(n!)^{2}(2n+1)}}x^{2n+1}$$","['power-series', 'limits', 'taylor-expansion', 'sequences-and-series']"
2922129,Inverse of matrix of ones minus identity matrix,"What is the solution for $$A^{-1}(n) = (\mathbf{1}_{n} - I_{n})^{-1},$$ where $\mathbf{1}_{n}$ is the $n\times n$ matrix of ones and $I_{n}$ is the $n\times n$ identity matrix. Numerical Examples Suggest $$
A^{-1}(n) = \begin{bmatrix}
\frac{-n+2}{n-1} & \frac{1}{n-1} & \frac{1}{n-1} & ... \\
\frac{1}{n-1} & \frac{-n+2}{n-1} & \frac{1}{n-1} & ... \\
\frac{1}{n-1} & \frac{1}{n-1} & \frac{-n+2}{n-1} & ... \\
\vdots & \vdots & \vdots & \frac{-n+2}{n-1} \\
\end{bmatrix}
$$ For similar questions on determinants, see How to calculate the determinant of all-ones matrix minus the identity? Why is the determinant of the all one matrix minus the identity matrix n-1? How to calculate the determinant of all-ones matrix minus the identity? Determinant of a matrix with diagonal entries $a$ and off-diagonal entries $b$ Determinant of a specific circulant matrix, $A_n$","['matrices', 'inverse']"
2922135,Is my proof that $l^1$ is isometrically isomorphic to $c_0^*$ correct?,"This is a classic exercise of functional analysis, but I do not fully understand it after reading many answers in textbooks. So I am trying to reorganize the proof step by step in details. I am hoping that someone may review my proof very carefully and give comments or corrections. Then I will revise the proof and hopefully it could be helpful to the beginners of functional analysis. Let $c_0(\mathbb{N})$ be the space of sequences converging to $0$ .
Show that there is a well-defined, isometric isomorphism \begin{align} T: l^1(\mathbb{N}) \to \left(c_0(\mathbb{N})\right)^*,
 \qquad T(g)(f) := \sum_{n\in\mathbb{N}}f(n)g(n).  \end{align} That is,
show that $T(g)$ is a bounded linear functional $c_0(\mathbb{N}) \to
 \mathbb{C}$ with $\|T(g)\| = \|g\|$ and that any bounded linear
functional on $c_0(\mathbb{N})$ is of this form for a unique $g \in
 l^1(\mathbb{N})$ . My proof: First of all, we denote the sequences $f \in c_0(\mathbb{N})$ and $g \in l^1(\mathbb{N})$ , thus $T(g) \in c_0^*: c_0(\mathbb{N}) \to \mathbb{C}$ . By the way, can we say $T(f): l^1(\mathbb{N}) \to \mathbb{C}$ ? I think it is not well-defined. Boundedness: To show $T(g)$ is a bounded linear functional $c_0(\mathbb{N}) \to \mathbb{C}$ with $\|T(g)\| = \|g\|_{l^1}$ , we first show the boundedness. \begin{align}
|T(g)(f)| = \left|\sum_{n\in\mathbb{N}}f(n)g(n)\right| \le \sum_{n\in\mathbb{N}}|f(n)||g(n)| \le \sup_{n\in\mathbb{N}}|f(n)|\sum_{n\in\mathbb{N}}|g(n)| = \|f\|_{l^\infty}\|g\|_{l^1}
\end{align} Therefore, $T(g)$ is bounded by \begin{align}
\|T(g)\| = \sup\{|T(g)(f)|: \forall f \in c_0(\mathbb{N}), \|f\|_{l^\infty}\le 1\} \le \|g\|_{l^1}
\end{align} Linearity: To show the linearity, we define $f_1, f_2 \in c_0(\mathbb{N})$ and $a_1, a_2 \in \mathbb{C}$ . Then \begin{align}
T(g)(a_1 f_1 + a_2 f_2) 
&= \sum_{n\in\mathbb{N}} \left(a_1 f_1(n) + a_2 f_2(n)\right) g(n) \\
&= \sum_{n\in\mathbb{N}} \left(a_1 f_1(n) g(n) + a_2 f_2(n) g(n)\right) \\
&= a_1 \sum_{n\in\mathbb{N}} f_1(n) g(n) + a_2 \sum_{n\in\mathbb{N}} f_2(n) g(n) \\
&= a_1 T(g)(f_1) + a_2 T(g)(f_2) 
\end{align} implies that $T(g)$ is linear. Isometry: We already proved $T(g): c_0(\mathbb{N}) \to \mathbb{C}$ a bounded linear functional for all $g \in l^1(\mathbb{N})$ , now can we say the operator $T: l^1(\mathbb{N}) \to \left(c_0(\mathbb{N})\right)^*$ is therefore well-defined? Next we need to show that $T$ is an isometry for which $\|T(g)\| = \|g\|_{l^1}$ . Since we already have $\|T(g)\| \le \|g\|_{l^1}$ from the boundedness, if we are able to show that there exists some $f \in c_0(\mathbb{N})$ for which $\|T(g)\| \ge \|g\|_{l^1}$ , then $\|T(g)\| = \|g\|_{l^1}$ . Let $g$ be a sequence in $l^1(\mathbb{N})$ . If $g = 0$ , then $\|T(g)\| = \|g\|_{l^1}$ holds trivially. Assuming $g \ne 0$ , we define \begin{align}
f(n) := 
\begin{cases}
\frac{\overline{g(n)}}{|g(n)|} &n \le N \\
0 &n > N
\end{cases}
\end{align} which is a sequence in $c_0(\mathbb{N})$ , with $T(g)(f) := \sum_{n\in\mathbb{N}}f(n)g(n) = \sum_{n\in\mathbb{N}}|g(n)| =: \|g\|_{l^1}$ and $\|f\|_{l^\infty} = 1$ by definition. Therefore, we have \begin{align}
\|g\|_{l^1} = |T(g)(f)| \le \|T(g)\|\|f\|_{l^\infty} = \|T(g)\|
\end{align} in addition to $\|T(g)\| \le \|g\|_{l^1}$ , which implies $\|T(g)\| = \|g\|_{l^1}$ , i.e., $T$ is an isometry and thus injective (one-to-one). Surjectivity: To prove that $T: l^1(\mathbb{N}) \to \left(c_0(\mathbb{N})\right)^*$ is surjective (onto), we need to show for any bounded linear functional $\forall S \in \left(c_0(\mathbb{N})\right)^*$ there exists $T(g) = S$ that has some preimage $g \in l^1(\mathbb{N})$ . Let us build a basis $\{e_n: n = 1, 2,...\}$ of sequences for $c_0(\mathbb{N})$ , where $e_n = (\delta_n)_{n \in \mathbb{N}} \in c_0(\mathbb{N})$ . Any $f \in c_0(\mathbb{N})$ can be written coordinate-wisely by the linear combination of the sequences of the basis $f = \sum_{n\in\mathbb{N}} f(n) e_n$ . Then by the linearity of $S$ we have \begin{align}
S(f) = \sum_{n\in\mathbb{N}} f(n) S(e_n)
\end{align} If we define $g(n) := S(e_n)$ , then we find \begin{align}
S(f) = \sum_{n\in\mathbb{N}} f(n) S(e_n) = \sum_{n\in\mathbb{N}} f(n) g(n) =: T(g)(f)
\end{align} that implies $S = T(g)$ . By definition, $g(n)$ maps each sequence of basis to $T(g)(e_n)$ . In addition, we need to show this $g \in l^1(\mathbb{N})$ by $\|g\|_{l^1} \le \|S\|$ which I am not able to finish . In conclusion, we find $\exists g \in l^1(\mathbb{N})$ for $T(g)$ corresponding to $\forall S \in \left(c_0(\mathbb{N})\right)^*$ , therefore $T$ is surjective. Finally, $T$ is a well-defined isometric isomorphism. Please show me that $\|g\|_{l^1} \le \|S\|$ How to show this $g$ is unique?","['vector-space-isomorphism', 'analysis', 'linear-algebra', 'functional-analysis', 'isometry']"
2922157,Conditions for gradient dynamical systems,"In S. Smale's, “On gradient dynamical systems,” Ann. of Math. (2), vol. 74, no. 1, pp. 199–206, 1961, four conditions on a vector field $X$ on a compact manifold $M$ are given that are sufficient for the existence of a smooth function $f$ and a Riemannian metric $g$ such that $X=\text{grad}_gf$. I'm confused about the relationship of conditions (2) and (3). Let $\beta_1,...,\beta_m$ denote the zeros of $X$. Smale writes: (2) If $x\in\partial M$, $X$ is transversal to $\partial M$. Hence $X$ is not zero on $\partial M$. (3) If $x\in M$ let $\phi_t(x)$ denote the orbit of $X$ (solution curve) satisfying $\phi_0(x)=x$. Then for each $x\in M$, the limit set of $\phi_t(x)$ as $t\to\pm\infty$ is contained in the union of the $\beta_i$. Now, if I interpret the orbits to be stopped at the boundary, it seems to me that if $x\in M$ is a point close to $\partial M$, either $\lim_{t\to\infty}\phi_t(x)$  or $\lim_{t\to-\infty}\phi_t(x)$ must be in $\partial  M$ (depending on whether $X$ points in- or outwards). Therefore there has to be a $\beta_i$ on $\partial M$. However, this contradicts condition (2). Therefore it must be the case that my interpretation of the orbits is incorrect. An interpretation that works is if we impose the restriction on the limits only when the orbit can be extended to either a half-line or the entire real line. This makes sense also in view of the fact that $X$ is not assumed to be complete. Could someone clear this up for me? Is my second interpretation correct?","['gradient-flows', 'dynamical-systems', 'riemannian-geometry', 'differential-geometry']"
2922158,"If a set is closed under countable unions, is it closed under countable intersections?","I am trying to think through the intuition of DeMorgan's laws.  If I have a set $\Omega$ and a sequence of subsets ($A_n$)={$X_1$, $X_2$, ...} how can I know that given the fact $\Omega$ is closed under countable unions, $\Omega$ is closed under countable intersections, or vice-versa. Moreover - given the answer to the above, is it enough to show that $\Omega$ is closed under countable intersections OR countable unions as part of proving that $\Omega$ is a $\sigma$-algebra? Thanks in advance!","['elementary-set-theory', 'measure-theory']"
2922182,Solving $ y' -3y = x \cdot e^x $,"I'm struggling with this differential equation:  $ y' -3y = x \cdot e^x $ Step one: Solve the homogenous equation  $ y' -3y = 0 $ 
$$ y_0 = e^{3x} \cdot C $$ The approach for the particular solution $y_p$ should be $(c_1x+c_0)\cdot Ce^x$ This leads me to the following term: 
$$ y_p = Ce^x(ax+b) $$
$$ y'_p= Ce^x\cdot(ax+b)+Ce^x\cdot a $$
$$ Ce^x\cdot(ax+b)+Ce^x\cdot a - 3Ce^x(ax+b) = x\cdot e^x $$
$$ C\cdot(ax+b)+C\cdot a - 3C(ax+b) = x $$ The C is a real problem here. After taking a look in my textbook I saw that the approach for $y_p$ is: 
$$y_p = (ax + b)\cdot e^x $$ 
$$y'_p = e^x \cdot (ax +b)+e^x \cdot a $$
Plugging this into $ y' - 3y = x\cdot e^x $ and simplify gives: $$ x(-2a)+a-2b=x \Rightarrow a=-\frac{1}{2}; b=-\frac{1}{4}$$
And finally 
$$ y= e^{3x}\cdot C - \frac{1}{4}(e^x+2xe^x) $$ When I omit the C I'm able to solve this but I don't know why this is correct as the approach for $g(x)$ would be $C\cdot e^{bx}$",['ordinary-differential-equations']
2922266,Complex Line Integral of Holomorphic Function over Closed Curve is Zero,"I'm working on the following problem: Let $f$ be holomorphic on an open set $U$ which is the interior of a disk or a rectangle. Let $\gamma : [0,1] \rightarrow U$ be a $C^1$ curve satisfying $\gamma (0) = \gamma(1)$. Prove that
$$ \oint_\gamma f(z)dz = 0$$ My attempt: Now, since $U$ is either an open disk or open rectangle and $f$ is holomorphic on $U$, $\exists H$ on $U$ s.t. 
$$ \frac{\partial H}{\partial z} \equiv F$$
on U. Since $\gamma$ is a closed curve, it follows that
$$ H(\gamma (1)) - H(\gamma (0)) = 0.$$
Further, since $H$ is holomorphic on U, we also have that
\begin{align*}
H(\gamma (1)) - H(\gamma (0)) &= \oint_\gamma \frac{\partial H}{\partial z} (z) dx \\
&= \oint_\gamma f(z) dz \\
\end{align*}
Thus,
$$ \oint_\gamma f(z)dz = 0 $$ My qualm about this problem is that it seems like we are just proving the Cauchy Integral Formula, but now we're allowing $U$ to be an open rectangle. I don't seem to use this fact except in the first step, in concluding that, in either the case of $U$ being an open disk or open rectangle, $f$ being holomorphic guarantees a holomorphic antiderivative on $U$. Is this the only part of the proof where this comes into play?","['complex-analysis', 'proof-verification']"
2922279,Inverse of a specific matrix,"Let $A$ be an $(n+1)\times(n+1)$ matrix defined by $a_{ij} = (i-1)^{j-1}$ , with the convention that $0^0 = 1$ . $$A = 
\left[\begin{matrix}
0^0 & 0^1 & 0^2 & \ldots & 0^n\\
1^0 & 1^1 & 1^2 & \ldots & 1^n\\
2^0 & 2^1 & 2^2 & \ldots & 2^n\\
\vdots & \vdots & \vdots &\ddots & \vdots\\
n^0 & n^1 & n^2 & \ldots & n^n\\
\end{matrix}\right]
$$ What is a closed form of $A^{-1}$ ? I don't know how to approach this problem. Any help will be appreciated.","['matrices', 'algebra-precalculus', 'linear-algebra', 'combinatorics']"
2922293,How can we define the limit of a constant function?,"Wikipedia says: In mathematics, a limit is the value that a function(or sequence) ""approaches"" as the input (or index) ""approaches"" some value. What if the function was a constant?! A constant function will not approach anything, so, how would we define the limit of a constant function?","['limits', 'calculus']"
2922364,"Intuition of Laplacian of $f(x,y)$","I have some confusion in the physical/geometrical interpretation of the Laplacian of a function of two variables, say, $f(x,y)$ . Recently I have found a video of Khan Academy on Youtube. In this video they gave an intuition of $\nabla^2 f$ . The main theme of this video (as I've understood) is: Since the gradient gives you the slope of steepest ascent so each one of the vectors in gradient field points in the direction that you should walk, such that the graph of $f(x,y)$ is kind of a hill on top of you, it tells you the direction you should go to increase the functional value most rapidly. Now the divergence of a vector field (treating as a fluid flow) represents how much a point in the field acts like a source . So now let's think about what it might mean when we take the divergence of the gradient field of $~f$ . We can see the divergence of the gradient is very high at points that are kind of like minima, at points where everyone around them tends to be higher.But the divergence of the gradient is low at points that look more like maximum points. So this Laplacian operator is kind of like a measure of how much of a minimum point is this $(x,y)$ .You will be very positive when $f$ evaluated at that point tends to give a smaller value than $f$ evaluated at neighbors of that point. But it'll be very negative if when you evaluate $f$ at that point it tends to be bigger than its neighbors. Upto now everything is pretty much clear to me and I am so convinced with this intuition of Laplacian .
But the confusion pops up in my mind when I read the second derivative test in the Multivaiable Calculus book Vol 2 of Tom M Apostol. In the second derivative test what I understand is that only $f_{xx}$ and $f_{yy}$ is not sufficient for the conclusion about a local minima or maxima. We have to take care about the mixed partials also. But in the Khan academy's video I think $\text{div}~ \text{grad} f=f_{xx}+f_{yy}$ should determine a point as local minima or maxima at least . Now my question is: if $\nabla^2f(x,y)>0$ , can we say that $f$ has a local minima at $(x,y)$ ? Which I know from second derivative test is not enough for the conclusion whereas according to the first intuitive idea of Khan academy's video it seems pretty reasonable to me. Can anyone here please help me to figure out what's going on here or at least where am I missunderstood? Thank you.","['laplacian', 'multivariable-calculus']"
2922387,"Finding $\lim_{x \to \infty}\, {\mathrm{e}}^{x}{\left(1+\frac{1}{x}\right)}^{x-{x}^{2}}$","$$\lim_{x \to \infty}\, {\mathrm{e}}^{x}{\left(1+\frac{1}{x}\right)}^{x-{x}^{2}}$$ I don't know where to start. Can I use series expansion of $\mathrm{e}^{x}$ and $(1+\frac{1}{x})\,$ ? Or L'Hôpital's rule since it is $\frac{\infty}{\infty}$ form. I am looking for hint to get started.","['limits', 'calculus']"
2922390,Can a group have two different subgroups of index $2$?,"I know that subgroup of index $2$ is normal. I am interested in knowing that is that subgroup is unique or there exist example of subgroup which can have two subgroup of index $2$? If there is example exist , then what is condition on subgroup implies that subgroup of index $2$ is unique? Any Help will be appreciated.","['normal-subgroups', 'group-theory', 'abstract-algebra']"
2922402,Is mathematical relation between functions the same as relation between their Fourier series?,"For example I have three functions $a(x)$,$b(x)$ and $c(x)$ which are defined on $(-\pi,\pi)$
 They have a relation that $a(x)=2b(x)+c(x)$. Assume their Fourier series are $A(x)$ $B(x)$ and $C(x)$.
 Is the relation among their Fourier series same as functions relations? In other words, is $A(x)=2B(x)+C(x)$ on interval $(-\pi,\pi)$? If yes, how to prove this is true?","['fourier-series', 'functions', 'relations']"
2922411,"If $\#(S)<\#(\Bbb N)$, then prove that $S$ is finite, without using the Axiom of Choice.","If we have a set $S$ such that $\#(S)<\#(\Bbb N)$ , where $\Bbb N$ is the set of the natural numbers, how would one prove that $S$ must be finite? Here is a proof using the Axiom of Choice: Proof : From $\#(S)<\#(\mathbb{N})$ , we know that there exists an injection $f:S\to \mathbb{N}$ . On the other hand, $S$ cannot be an infinite set: If $S$ is infinite, it contains a copy of $\mathbb{N}$ by the Axiom of choice. Therefore, we have an injection $g:\mathbb{N}\to S$ . By the Schröder–Bernstein Theorem, $\#(S)=\#(\mathbb{N})$ , which is a contradiction. Can we prove the theorem without the Axiom of Choice?","['elementary-set-theory', 'axiom-of-choice', 'cardinals', 'alternative-proof']"
2922460,"For any two sets $A$ and $B$, $|A|\le |B|$ or $|B|\le |A|$","Definition: $|A|\le |B| \iff$ there exists an injection from $A$ to $B$ . Theorem: For any two sets $A$ and $B$ , $|A|\le |B|$ or $|B|\le |A|$ . My attempt: Assume $|B| \not\le |A|$ , I will prove $|A|\le |B|$ . Let $X=\{f:A'\to B \mid A'\subseteq A \text{ and } f\text{ is injective}\}$ . We define a partial order $<$ on $X$ by $$f_1<f_2 \iff f_1\subseteq f_2$$ Since $f:\emptyset\to B$ is injective, $f\in X$ . Thus $X\neq\emptyset$ . For any chain $Y$ from $X$ , let $f^\ast=\bigcup Y$ . $f^\ast$ is a mapping For $(a,b_1),(a,b_2)\in f^\ast$ , there are $f_1,f_2 \in Y$ such that $(a,b_1)\in f_1$ and $(a,b_2)\in f_2$ . Since $Y$ is a chain, we can safely assume $f_1 < f_2$ . It follows that $f_1 \subseteq f_2$ . Thus $(a,b_1),(a,b_2)\in f_2$ and consequently $b_1=b_2$ by the fact that $f_2$ is a mapping. $f^\ast$ is injective Assume $(a_1,b),(a_2,b)\in f^\ast$ . Then there exists $f_1,f_2 \in Y$ such that $(a_1,b) \in f_1$ and $(a_2,b) \in f_2$ . Since $Y$ is a chain, we can safely assume $f_1 < f_2$ . It follows that $f_1 \subseteq f_2$ . Thus $f_1(a_1)=f_2(a_1)$ and consequently $f_2(a_2)=b=f_1(a_1)=f_2(a_1)$ . Hence $f_2(a_2)=f_2(a_1)$ and consequently $a_2=a_1$ by the fact that $f_2$ is injective. It follows that $f^\ast$ is injective. To sum up, $f^\ast$ is injective and thus $f^\ast \in X$ . Furthermore, $f^\ast$ is an upper bound of chain $Y$ . Thus $X$ satisfies the requirement of Zorn's Lemma and hence has a maximal element $\bar{f}:\bar{A} \to B$ . Let $\bar{B}=\operatorname{ran}\bar{f}$ . Then $\bar{f}:\bar{A} \to \bar{B}$ is bijective. I claim that $\bar{B}\subsetneq B$ . If not, $\bar{B} = B$ . Then $\bar{f}:\bar{A} \to B$ is bijective and thus $\bar{f}^{-1}:B \to \bar{A} \subseteq A$ is bijective. This contradicts our very first assumption that $|B| \not\le |A|$ . Hence $\bar{B}\subsetneq B$ and thus $\exists b'\in B\setminus \bar{B}$ . It follows that $b'\notin \bar{B}=\operatorname{ran}\bar{f}$ . I claim that $\bar{A}=A$ . If not, $A\setminus \bar{A} \neq \emptyset$ . Thus there exits $a'\in A\setminus \bar{A}$ . It follows that $a'\notin \bar{A} = \operatorname{dom}\bar{f}$ . We define $F:\bar{A}\cup\{a'\} \to \bar{B}\cup\{b'\}$ by $F(a)=\bar{f}(a)$ for all $a\in\bar{A}$ and $F(a')=b'$ . It's clear that $F$ is   a bijection from $\bar{A}\cup\{a'\}$ to $\bar{B}\cup\{b'\}$ and that $\bar{f}\subsetneq F$ . Then $F$ is an injection from $\bar{A}\cup\{a'\}$ to $B$ and $\bar{f}\subsetneq F$ . This contradicts the maximality of $\bar{f}$ . Hence $\bar{A}=A$ . To sum up, $\bar{f}:A \to B$ is injective and thus $|A|\le |B|$ . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","['elementary-set-theory', 'proof-verification']"
2922482,"Is there a name for the inverses of the functions (i.e for the left-unique, right-total binary relations)?","The right-unique, left-total binary relations are the functions, while the  left-unique, right-total ones are their inverses. So, they are the morphisms of $\mathsf{Set}^\mathrm{op}$. Do they have a name too?","['elementary-set-theory', 'relations', 'category-theory', 'terminology']"
2922492,Sum of series $\frac{ 4}{10}+\frac{4\cdot 7}{10\cdot 20}+\frac{4\cdot 7 \cdot 10}{10\cdot 20 \cdot 30}+\cdots \cdots$,"Sum of the series $$\frac {4}{10}+\frac {4\cdot7}{10\cdot20}+ \frac {4\cdot7\cdot10}{10\cdot20\cdot30}+\cdots $$ Sum of series $\frac {4}{10}+\frac {4\cdot7}{10\cdot20}+ \frac {4\cdot7\cdot10}{10\cdot20\cdot30}+\cdots$ But i want to solve it using Beta ganmma function. My Process follows Let $$S = \frac{1}{10}\bigg[\frac{ 4}{1}+\frac{4\cdot 7}{1\cdot 2}+\frac{4\cdot 7 \cdot 10}{1\cdot 2 \cdot 3}+\cdots \cdots \bigg]$$ Let $\displaystyle a_{n} = \prod^{n}_{k=1}(3k+1)=3^n \prod^{n}_{k=1}\bigg(k+\frac{1}{3}\bigg)$ $\displaystyle   =3^n\Gamma\bigg(n+\frac{4}{3}\bigg)\cdot \frac{1}{\Gamma \bigg(\frac{4}{3}\bigg)}$ And Let $\displaystyle b_{n} = \prod^{n}_{k=1}k = \Gamma (n+1)$ So $\displaystyle S =\frac{1}{10} \sum^{\infty}_{n=1}3^n \frac{\Gamma \bigg(n+\frac{4}{3}\bigg)\cdot \Gamma \bigg(\frac{2}{3}\bigg)}{\Gamma \bigg(\frac{2}{3}\bigg)\Gamma \bigg(\frac{4}{3}\bigg)\cdot \Gamma(n+1)}$ using $\displaystyle \Gamma(x)\cdot \Gamma(1-x) = \frac{\pi}{\sin (\pi x)}$ and $\displaystyle \frac{\Gamma (a) \Gamma(b)}{\Gamma(a+b)} =B(a,b)= \int^{1}_{0}x^{a-1}(1-x)^{b-1}dx$ So $\displaystyle S = \frac{1}{10}\sum^{\infty}_{n=1}3^n\int^{1}_{0}x^{n+\frac{1}{3}}(1-x)^{-\frac{1}{3}}dx$ $\displaystyle =\frac{1}{10}\int^{1}_{0}\frac{3x}{1-3x}\cdot \bigg(\frac{x}{1-x}\bigg)^{\frac{1}{3}}dx$ Now put $\displaystyle \frac{x}{1-x} = t\Rightarrow x = \frac{t}{1+t} = 1-\frac{1}{1+t}$ So $\displaystyle S = \frac{3}{10}\int^{\infty}_{0}\frac{t^{\frac{4}{3}}}{(2t-1)(1+t)^2}dt$ Could some Help me to solve it, Thanks although it has solved Here","['gamma-function', 'beta-function', 'sequences-and-series']"
2922494,Four coins with reflip problem?,"I came across the following problem today. Flip four coins. For every head, you get $\$1$ . You may reflip one coin after the four flips. Calculate the expected returns. I know that the expected value without the extra flip is $\$2$ . However, I am unsure of how to condition on the extra flips. I am tempted to claim that having the reflip simply adds $\$\frac{1}{2}$ to each case with tails since the only thing which affects the reflip is whether there are tails or not, but my gut tells me this is wrong. I am also told the correct returns is $\$\frac{79}{32}$ and I have no idea where this comes from.","['conditional-probability', 'expected-value', 'conditional-expectation', 'probability']"
2922506,Legendre functions as solution of differential equation,"In Abramowitz/Stegun you read that $$Q_s(x) := \int_{0}^\infty  ( x  + \sqrt{x^2-1}  \cosh t )^{-s} dt, \quad x > 1, \Re(s)>0$$ is a solution to the differential equation
$$(1-x^2)y''-2xy'+s(s-1)y=0.$$ How do you prove that? I differentiated under the integral sign and wrote down $(1-x^2)y''-2xy'+s(s-1)y$ with $Q_s$ for $y$ but couldn't see how it vanishs. Do you need to use some fancy functional equations of $\cosh$ to obtain the result?","['integration', 'derivatives', 'ordinary-differential-equations']"
2922543,Union of sets with pairwise intersection having half of the elements,"Consider $k$ sets $S_1, S_2, \ldots, S_k$, of the following properties: For every $i$, $\left|S_i\right| = p$ For every pair of $i$ and $j$, $\left|S_i \cap S_j\right| = \frac{p}{2}$ Now I need to find the minimum of $\left|\bigcup S_i\right|$ in terms of $k$ and $p$. (Assume $p$ is large enough to be divisible by any small enough integers) Via trial and error I suspect the answer to be
$$\frac{\left(2^{m + 1} - 1\right)p}{2^m}$$
where $m = \lfloor\log_2 k\rfloor$, but cannot prove it. That's also why I give that assumption about $p$, so that one do not need to worry about the situation where $\frac{p}{2^m}$ is not an integer. Edition: actually, I verified that my suspected answer is wrong. For example, when $k = 5$, I managed to construct the sets using $\frac{5p}{6}$ elements. Now I am not sure what the actual answer should be. :( Correction: I think I had mistaken $p$ with another variable I used in a larger problem where this proof is required, when giving the $\frac{5p}{6}$ lower bound in the edition above. It should be $\frac{5p}{3}$. An example would be when $k = 5$ and $p = 6$ (to be divisible by both $2$ and $3$), then my $5$ sets would be
$$\left\{1, 2, 3, 4, 5, 6\right\}, \left\{1, 2, 3, 7, 8, 9\right\}, \left\{1, 4, 6, 7, 9, 10\right\}, \left\{2, 4, 5, 7, 8, 10\right\}, \left\{3, 5, 6, 8, 9, 10\right\}$$
using $10$ elements. They are obtained basically as I try to ""average"" the occurrences of each number (in this example, specifically, letting each number appear $3$ times). Maybe we can go from here, but how to prove in general that this average is reachable?","['elementary-set-theory', 'combinatorial-designs', 'combinatorics']"
2922574,Proof verification: A countable union of countable sets is countable,"I'm trying to prove that a countable union of countable sets is countable. I read this proof somewhere and re-wrote it in my own way. MY WORK Let $\{S_n\}$ be a sequence of countable sets. Define
\begin{align} S=\bigcup_{n=1}^{\infty}S_n\end{align}
It suffices to construct an injection between $S$ and $\Bbb{N}$. Define
\begin{align} \mathcal{F_n}=\{f:f:S_n\to\Bbb{N}\;\text{and}\;f\;\text{is one-one}\},\;\;\forall\, n\in \Bbb{N}\end{align}
Since $\{S_n\}$ is countable, then $\mathcal{F_n}$ is non-empty. Then, by axiom of countable choice, there exists $\{f_n\}$ such that $f_n\in\mathcal{F_n}$, i.e.
\begin{align} f_n:S_n\to \Bbb{N}\end{align}
\begin{align} x\mapsto f_n(x)\end{align}
where $\{f_n\}$ is injective. Let 
\begin{align} \phi:S\to \Bbb{N}\times\Bbb{N}\end{align}
\begin{align} x\mapsto \phi(x)=(n,f_n(x))\end{align}
Hence, $\phi$ is injective since $n$ and $\{f_n\}$ are injective. Also, there exists 
\begin{align} \alpha:\Bbb{N}\times\Bbb{N}\to\Bbb{N}\end{align}
\begin{align} (n,f_n(x))\mapsto \alpha(n,f_n(x))\end{align}
which is injective. Thus, $\alpha\circ \phi:S\to\Bbb{N}$ is injective and so, $S$ is countable. Please, can anyone show me how to define $\alpha$ explicitly? I would also love to see other proofs too! Thanks!","['elementary-set-theory', 'proof-verification']"
2922593,Why doesn't the order matter in Probability,"I got a horrible doubt in probability. Kindly help me. (in permutation and combination chapter) Now our teacher has started probability Everything was almost clear unless and until I came with the second pic. When we are doing ""10c1*15c1"" the order is already being counted in this. Then why should I multiply it with two? Or in other language if we consider that order does not matter then it should be 10*15/2 and in denominator 25C2 And if we consider order matters then 10×15 (Here 1st one green 2nd one red /or / 1st one red and second one green has already been counted___as I did in the 1st pic) And in denominator 25×24","['permutations', 'algebra-precalculus', 'combinatorics', 'probability']"
2922624,Confusion about distribution of marbles among 5 persons. Example by Kahneman and Tversky,"I came across the article Subjective Probability: A Judgment of Representativeness
  Daniel Kahneman and Amos Tversky and in particular their following example I have a lot of difficulties in understanding the question In many rounds of the game, will there be more results of type I or of type II? My difficulties are the following. IMHO the question leads to misunderstandings. There are two possible scenarios that I'm considering. 1 case: Does the order of the numbers play a role? If so, than, it should be equally likely to get the event
$$44543 \qquad \text{or} \qquad 44444$$ 2 case: Does the order of the numbers not play a role? If so, than it is way more likely, to get the event containing three $4$, one $5$ and one $3$, than to get all five $4$s. This is because the number of strings of length $5$ containing three $4$, one $5$ and one $3$ is
$$\frac{5!}{3!} = 5\cdot 4 = 20.$$ The problem is that I don't see any other scenario, but the author says The uniform distribution of marbles II (so the event that we get five $4$s) is, objectively, more probable than the nonuniform distribution I. I looked out what it meant for him the word ""objectively"" and it is intended to be as precise as a mathematical explanation should be.","['combinatorics', 'probability']"
2922630,Double integrals and interchangeable limits,Why do the answers come out to be different in these two cases where only the integrating order has been changed (The first one comes out to be 0.5 and the other one come out to be -0.5). We have learnt that the limits are interchangeable when the limits are constants. This is a little contradicting.: P.S. Sorry for the bad English.,"['multivariable-calculus', 'calculus']"
2922634,Must a sequence be well-founded?,"Must a sequence be well-founded? Is $\Bbb Z=(\ldots-1,0,1,2,\ldots)$ a sequence? Conventionally we think of $\Bbb N=(0,1,2,3,\ldots)$ as a sequence, but what about if it has no starting value? Obviously we can reorder any countable set $X$ into a well-founded sequence e.g. by an injection $f:X\to \Bbb N$ but what about in its raw form, do we call $\Bbb Z$ a sequence?","['order-theory', 'terminology', 'sequences-and-series']"
2922638,High dimensional integral of exponentials,"I am attempting to marginalize a probability density function. But I got stuck on the following integral $$
\int_{-\infty}^\infty\cdots\int_{-\infty}^\infty
\frac{\exp(\pmb x^T A\pmb z)}
{|\exp(A\pmb z )|_1^{n+|\pmb{x}|_1}}
\mathrm dz_1\cdots\mathrm dz_m
$$ where $\pmb x, \pmb z \in\mathbb R^n$ , $x_i\ge 0$ with large $n,m \in\mathbb N$ . $|\cdot|_1$ is the sum of the components e.g. $|\pmb x|_1 = \sum_{i=1}^nx_i$ . $A\in\mathbb R^{n\times n}$ is orthogonal and the first $m$ coloums are also orthogonal to $(1,\dots,1)$ . I already stripped away some constants. My goal is a fast evaluation of the integral on the remaining dimensions $z_{m+1},\dots,z_n$ . Can anybody solve this? If there is no explicit form of the integral, a good approximation would also be very helpful!","['integration', 'approximation', 'definite-integrals', 'exponential-function']"
2922659,Explanation for counter-intuitive discrete probability results,"Suppose there're two players $A$ , $B$ playing a dice game, $A$ has a normal dice whose faces are numbered 1 to 6, $B$ , on the other hand, has a (regular) icosahedron dice with faces numbered 1 to 20. Each round, $A$ rolls its dice 3 times and get the sum as his score, whereas $B$ rolls only once and get the result as his score, and the one with the greater score wins and gets 1 point. If scores are equal, then they both get 0.5 points.  Is this a fair game? A quick calculation shows that the expected scores for both players are 3.5, so it looks like it's perfectly fair. But to my surprise, when I was doing a Monte Carlo in Python, the programmed told me, out of 10^5 simulations, $A$ has only around 48.x% of the total 10^5 points, and such a 1.x% disadvantage was consistent across several tests. Now move on to a more complicated version. This time let's introduce a new player $C$ , who plays by exactly the same rule as $B$ does. Again, each round the player with the highest score wins; if two player has equal scores that are higher than the third player's, then they both get 1/2 points; and if all three have equal scores then they all get 1/3 points. Is this a fair game? I thought with a firm ""yes"" for the same reasons as previously. But the simulation results totally astounded me, much more than the previous 1.x% discrepancy: now in the 3 player game, out of 10^5 simulations, the player $A$ only gets about 27.x% of the points, whereas $B$ and $C$ both get about 36.x% - $A$ has an almost 9% disadvantage! I know to get everything clear it's best to explicitly compute the probability distribution case by case, and admittedly it's not hard in any technical sense. But, before doing that, is there any easy explanation about the discrepancies between intuition and reality as shown above? Thanks! Attached below is the code: import random
import numpy as np
import pandas as pd

def get_A_score():
    return sum(random.randint(1, 6) for i in range(3))


def get_B_score():
    return random.randint(1, 20)


if __name__ == '__main__':
    n_sim = 100000
    A_wins = 0.0
    for i in range(n_sim):
        if get_A_score() > get_B_score():
            A_wins += 1
        elif get_A_score() == get_B_score():
            A_wins += 1/2   # in case of equal numbers
    print(A_wins / n_sim)

    print()

    wins = np.array([0.0, 0.0, 0.0])
    for i in range(n_sim):
        A_score = get_A_score()
        B_score = get_B_score()
        C_score = get_B_score()
        scores = np.array([A_score, B_score, C_score])
        winner_index = np.argwhere(scores == np.amax(scores))
        n_winners = len(winner_index)
        wins[winner_index] += 1 / n_winners

    print(wins / n_sim)","['intuition', 'dice', 'discrete-mathematics', 'probability']"
2922660,Solving $x^4 -10x^3 + 26x^2 -10x +1 = 0$.,"Find the root of the  equation $$x^4 -10x^3 + 26x^2 -10x +1 = 0$$ My attempt: If $a,b,c$ and $d$ are a roots then $a+b+c+d = 10,$ $(a+b)(c+d)  + ab +cd = 26$ $(a+b)cd  +ab(c+d) = 10$ $abcd =1$ Now  i'm not able  procceed further.","['algebra-precalculus', 'polynomials']"
