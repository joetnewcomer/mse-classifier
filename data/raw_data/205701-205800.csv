question_id,title,body,tags
4094859,Geometric interpretation of symmetries of a manifold,"I have been doing some reading about Lie groups and algebras and stumble across the phrase that those theories ""measure"" the symmetries of the manifolds, like an analog of the groups that measure the symmetries of objects like a triangle, a polygon etc. I am trying to understand what that means.
I think I would understand better the above with 2 examples So lets take a 2-d manifold-a sphere. Does this mean that we have infinite symmetries? (how do we compute them mathematically meaning if someone ask how many symmetries a sphere has how do we answer that mathematically) can you give an example of a manifold that has a finite symmetry How can I think about the symmetries of a manifold? Thinking about an axes' rotation is probably wrong, so how do we think it geometrically?","['lie-algebras', 'physics', 'manifolds', 'lie-groups', 'differential-geometry']"
4094866,"Is the integral identity $\int d x \, f(x) \, \, g(f(x))' \, = \, 0$ true?","We have a positive function $f$ on a certain N-dimensional domain $E \subset  \mathbb{R}^N$ , namely $f(x)\geq 0$ for every $x\in E$ . The function is such that $f(x)=0$ on the boundary, when $x \in \partial E$ .
We also require that $$
\int_E d^Nx \, f(x)  \, = \, F >0
$$ is finite. Given a ""well behaved"" function $g: \mathbb{R} \rightarrow \mathbb{R}$ ,
how to prove that  (feel free to assume all the nice continuity properties you want for both $f$ and $g$ ) $$
\int_E d^Nx \, f(x) \, \nabla \, g(f(x)) \, = \, 0 \quad ?
$$ Attempt: probably the N-dimensional domain is a complication and it is possible to just consider the 1D case. If $g$ is the identity, by using the integration by parts we have $$
\int_E dx \, f \, \partial_x \, f \,=-\int_E dx \, (\partial_x f) \,  \, f 
$$ so in this simple case the statement is true. A similar argument holds also when $g(f) = f^a$ for some real power $a\neq -1$ such that the integrals are finite.","['integration', 'multivariable-calculus', 'calculus', 'multiple-integral']"
4094867,Understanding an intuitive explanation of the derivative of $x^x$,"This question is related to this question here Can't argue with success? Looking for ""bad math"" that ""gets away with it"" The question is about ways to get the right answer with incorrect logic/methods. One of the answers with $104$ score by Hans Engler reads like this Here's another classical freshman calculus example: Find $\frac{d}{dx} x^x$ . Alice says ""this is like $\frac{d}{dx} x^n = nx^{nâˆ’1}$ , so the answer is $xx^{xâˆ’1}=x^x$ ."" Bob says ""no, this is like $\frac{d}{dx} a^x = \log{a}â‹…a^x$ , so the answer is $\log{x}â‹…x^x$ ."" Charlie says ""if you're not sure, just add the two terms, so you'll get partial credit"". The answer $\frac{d}{dx} x^x= (1+\log x)x^x$ turns out to be correct. Joriki in the comments of this answer states that That's not wrong; that's a perfectly valid method. You get the derivative of any expression with respect to x as the sums of all the derivatives with respect to the individual instances of x while holding all other instances constant. I am having trouble making sense of his comment, this is what I think it means. Imagine that the $x$ s in $x^x$ were different. Let's call them $x_1$ and $x_2$ . Thus, our expression becomes ${x_1}^{x_2}$ . I believe his comment is saying that the rate of change of ${x_1}^{x_2} = \frac{\partial}{\partial x_1} {x_1}^{x_2} + \frac{\partial}{\partial x_2} {x_1}^{x_2}$ . Each partial derivative evaluates the change in the quantity with respect to a different $x$ and sums them up while keeping the other $x$ constant, just like the comment says. However, I am not sure why this equality is true.","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
4094921,Lecture notes or short textbooks on complex analysis,"I am looking for a good  relatively short textbook or lecture notes on graduate level complex analysis which does not ignore the rest of the mathematics (what I mean is that a lot of texbooks avoid mentioning fundamental group, differential forms, stokes theorem and so on). I intend not to learn the subject but rather refresh my memory, get my knowledge in order. I want it to contain all the classical results (Cauchy's theorems, Laurent series, maximum module principle,  Shwartz lemma and so on).","['complex-analysis', 'book-recommendation', 'reference-request']"
4094934,How to solve $x\cos(t)+y\sin(t)=1$ for $t$,"When trying to find the points, $P_1$ and $P_2$ , on a circle of radius $R$ such that the tangent line to those points passes through the point $P_0$ , it was all simple geometry until I ran into $x\cos(t)+y\sin(t)=1$ . I found other questions solving the same circle problem, but they went about it in a different way so never ran into this expression. Plugging into wolfram alpha gives $2\tan^{-1}(\frac{y+\sqrt{y^2+x^2-R^2}}{R+x})$ which works in practice here https://www.desmos.com/calculator/y8sz3kwjki , but I have no idea how it arrived at that solution. I assume there must be answers somewhere, but I couldn't find them for some reason.","['trigonometry', 'geometry']"
4094953,About Hilbert's countably infinite guests,"In Hilbert's hotel if we get each guest to his next room (guest in the room $n$ will get in room $(n + 1)$ ) then the first room will be empty. About this method Wikipedia says: ""By repeating this procedure, it is possible to make room for any finite number of new guests."" But why only finite? Why can't we add countably infinite number of new guests this way?",['elementary-set-theory']
4094963,An easy example of a non-quasiconvex subgroup,"Let $G$ be a finitely generated group, and consider the surjection $\mu:F(A)\to G$ induced by the set of generators $A$ , where $F(A)$ is the free group on $A$ . A word $w$ is said to be ( $\mu$ -)geodesic if is it of minimal length in $\mu^{-1}\mu(w)$ .
A subgroup $H<G$ is called quasi-convex if there exist a constant $k$ such that for any geodesic word $w=w_1\dots w_n$ such that $\mu(w)\in H$ , and for any $0<i<n$ , there exist a word $v_i$ of length at most $k$ such that $\mu(w_1\dots w_iv_i)\in H$ . What is the easiest example of a non-quasi-convex subgroup? Here easy may mean with an explicit presentation, easy to prove that is not quasiconvex, or with a very quick and elegant description, depending on the taste of who is answering.","['group-presentation', 'hyperbolic-groups', 'combinatorics-on-words', 'geometric-group-theory', 'group-theory']"
4095006,$\sum_{n=1}^\infty\frac{n}{(2n-1)16^n}\binom{2n}{n}^2\left(\sum_{k=n}^\infty\frac{2^k}{k\binom{2k}{k}}\right)=1-\sqrt2+\log(1+\sqrt2).$,"Prove: $$\sum_{n=1}^\infty\frac{n}{(2n-1)16^n}\binom{2n}{n}^2\left(\sum_{k=n}^\infty\frac{2^k}{k\binom{2k}{k}}\right)=1-\sqrt2+\log(1+\sqrt2).$$ I'm sorry that I don't even know how to start. I haven't met this kind of series before. I've learnt some simplier methods for calculating the value of some simplier series through complex analysis, for example using the Taylor expansion for some holomorphic functions. But it seems that these methods won't work in this problem. So I want to learn more methods or tricks to handle this kind of problems. Would you please recommend some books about this topic?","['summation-method', 'book-recommendation', 'calculus', 'binomial-coefficients', 'sequences-and-series']"
4095171,What is the integral of the floor function and any power of the floor function?,"What is the integral of the floor of x ? Furthermore, what is the integral of a power of the floor of x ? I saw in one of the answers here that: $$
\int \;\lfloor x \rfloor dx = x\lfloor x \rfloor - \frac12 \lfloor x \rfloor(\lfloor x \rfloor + 1)\;
$$ But the person did not provide a proof. I do not quite understand how they arrived at that answer. I tried Googling it, but I can't seem to find a proof. Can anyone provide one please? Additionally, can you provide how you would take the integral of a power of the floor of x , such as: $$
\int \;\lfloor x \rfloor^n dx
$$ where n is a natural number. I'd appreciate it.","['integration', 'calculus', 'ceiling-and-floor-functions']"
4095174,"Knowing that the first test was positive, what is the probability the second test will be positive?","Suppose that 5% of the employees of a certain company use illegal drugs. The company performs random drug tests that return positive results 98% of the time if the person is a drug user. However, it also has a 4% false-positive rate. The results of the test are independent from test to test for a given person. An employee at the company has a positive test. What is the probability that he uses drugs? Knowing that the first test was positive, what is the probability the second test will be positive? Suppose that the second test is also positive. What is the probability he uses drugs? My Attempt This one is straightforward.. From the problem, we know $$\mathbb{P}(positive|\;uses\;drugs)=0.98$$ $$\mathbb{P}(uses\;drugs)=0.05$$ $$\mathbb{P}(positive|doesn't\;use\;drugs)=0.04$$ $$\mathbb{P}(doesn't\;use\;drugs)=0.95$$ Then using Baye's Theorem, we have $$\mathbb{P}(Uses\;drugs)=\frac{(0.98)(0.05)}{(0.98)(0.05)+(0.04)(0.95)}=0.56$$ For this one, we are trying to find $\mathbb{P}(Second\;positive|first\;positive)$ . Since the results are independent from each other, we know that $\mathbb{P}(Second\;positive|first\;positive)=\mathbb{P}(second\;positive)$ . Would this mean that the second test being positive has the same probability as the first one? Intuitively, I would think that the probability is the same because the events are independent of each other, but I am not sure how to prove this. Edit: I think I can use the definition of conditional probability and the law of total probability to solve this problem. What I had above is wrong.
I can use the following to solve: $$\mathbb{P}(B\;|\;A)= \frac{\mathbb{P}(B\cap A)}{\mathbb{P}(A)}= \frac{\mathbb{P}(B\cap A\;|\;D)\mathbb{P}(D)+\mathbb{P}(B\cap A\;|\;D^c)\mathbb{P}(D^c)}{\mathbb{P}(A\;|\;D)\mathbb{P}(D)+\mathbb{P}(A\;|\;D^c)\mathbb{P}(D^c)}$$ For this one, I am trying to find $\mathbb{P}(Uses\;drugs|first\;positive\;\cap\;second\; positive)$ . I think I can use Baye's rule for this one again and the definition of conditional independence.","['statistics', 'conditional-probability', 'independence', 'bayes-theorem', 'probability']"
4095201,$\lim_{x \to 1} \frac{1}{x+2} = 1/3$ with $\varepsilon$-$\delta$ definition?,"I'm trying to use the $\varepsilon$ - $\delta$ definition of a limit to prove that $$
\lim_{x \to 1} \frac{1}{x+2} = 1/3.
$$ But I'm getting stuck on finding the correct $\delta$ . Here is my try: \begin{align*}
\lvert f(x) - L \rvert < \varepsilon \\
\lvert  \frac{1}{x+2} - \frac{1}{3} \rvert < \varepsilon \\
\lvert  \frac{x -1}{2 + x} \rvert < 3\varepsilon.
\end{align*} And then I'm not really sure what to do. How do you proceed from here?","['limits', 'epsilon-delta', 'real-analysis']"
4095203,Understanding mathematical terminology in Aluffi,"I'm reading the first section of Aluffi's ""Algebra: Chapter 0"" and don't fully understand this below passage concerning naive set theory. But note that while it is clear from the definitions that, for example, $$S_1 \cup S_2 \cup S_3 = (S_1 \cup S_2) \cup S_3 = S_2 \cup (S_2 \cup S_3),$$ it is not so clear in what sense the sets $$S_1 \times S_2 \times S_3, \; (S_1 \times S_2) \times S_3, \ S_1 \times (S_2 \times S_3) $$ should be `identified' (where we can define the leftmost set as the set of 'ordered triples' of elements of $S_1, S_2, S_3$ , by analogy with the definition for two sets.) In fact, again, we can really make sense of such statements only after we acquire the language of functions. However, all such statements do turn out to be true, as the reader probably expects; by virtue of this fortunate circumstances, we can be somewhat cavalier and gloss over such subtleties. My biggest confusion is the use of the word 'identified.' This is the second time the author uses this term with respect to a set. I'm also lost as to what the author means by ""all such statements turn out to be true.""","['elementary-set-theory', 'terminology']"
4095211,Doubt in the geometric interpretation of Newton's method of calculating the roots of the equation $f(x)$.,"This is a question from Rudin(trying to prove the newtons method of calculating the roots of the function) and which aks me to state the geometric intuition of : $$x_n=x_{n-1}-\frac{f(x_{n-1})}{f'(x_{n-1})}$$ I know that the the line to the tangent at the graph at the point $(x_1,f(x_1))$ has the equation $y = f(x_1)+f'(x_1)(x-x_1)$ and it crosses the graph at the point $x_2$ which is given by the above equation. Now, while looking at the equation,I found something like this: $\frac{x_1.f(x_1+h)-f(x_1)(x_1+h)}{f(x_1+h)-f(x_1)}=x_2$ which forces me to think of the exterior division formula where $m=f(x_1+h)$ and $n= f(x_1)$ and the equation assumes the form $\frac{m.x_1-n(x_1+h)}{m-n}=x_2$ .Since $x_1 \in (\alpha,b)$ and $f(\alpha)=0(f(b)>0)$ and the point $x_2$ is the exterior point , so $x_2$ is closer to $\alpha$ .Why am I getting something similar to the exterior division formula?","['analysis', 'real-analysis']"
4095213,Deforming an approximate algebra into an exact algebra,"Consider a linear subspace of matrices, $M \subset \textrm{Mat}_n(\mathbb{C})$ , which is $\epsilon$ - approximately closed under multiplication, i.e. for all $x,y \in M$ , there exists $z \in M$ such that $\lVert{xy-z}\rVert < \epsilon \lVert x \rVert \lVert y \rVert$ . Assume $M$ is closed under Hermitian adjoints.  Then you might say $M$ forms an "" $\epsilon$ -approximate"" $*$ -subalgebra of $\textrm{Mat}_n(\mathbb{C})$ .  (We might also assume $M \ni 1$ and $M$ is approximately closed under inverses.) Have approximate $*$ -subalgebras of this sort been studied? I am familiar with some notions of Ulam stability, approximate homomorphisms, and approximate representations, but the setup here appears slightly different. ( $M$ is not given as the image of some approximate homomorphism from an actual algebra.) In particular, I'm interested in the following: Is it known whether $M$ may be slightly deformed so that it becomes an exact $*$ -subalgebra?  E.g., does there exist a subspace $N \subset \textrm{Mat}_n(\mathbb{C})$ which is an exact $*$ -algebra, and which is nearby to the subspace $M$ , with distance controlled by $\epsilon$ ? If anyone's interested, I'll offer an example of a conjecture along these lines. For a von Neumann algebra $\mathcal{A}$ , call a linear subspace $M \subset \mathcal{A}$ $\epsilon$ -approximately multiplicatively closed if it is closed under $*$ , contains the identity, and satisfies the property that for all $x,y \in M$ , $\exists z \in M$ s.t. $\lVert{xy-z}\rVert < \epsilon \lVert x \rVert \lVert y \rVert$ . Also define a distance between two subspaces: for any linear subspaces $X,Y$ , let $d(X,Y)$ be the Hausdorff distance between their unit balls. Then one might conjecture: For every $\epsilon>0$ , there exists $\delta>0$ such that for any
finite-dimensional von Neumann algebra $\mathcal{A}$ , for any $\delta$ -approximately multiplicatively closed subspace $M \subset \mathcal{A}$ , there exists a von Neumann subalgebra $\mathcal{N} \subset \mathcal{A}$ such that $d(M,\mathcal{N})<\epsilon$ . The related literature I know seems to focus on maps between algebras which are approximately multiplicative, e.g. "" Approximately Multiplicative Maps Between Banach Algebras "" (Johnson, 1986).  Here, I'm wondering about linear subspaces that are approximately multiplicatively closed.  (So these are like ""approximate sub-algebras,"" rather than ""approximate homomorphisms."")","['matrices', 'von-neumann-algebras', 'operator-algebras']"
4095248,"If for any $\epsilon>0$, $ \sum_{n=1}^\infty P [|X| > n \epsilon ]< \infty $, then $E| X| < \infty $?","Suppose that given any $\epsilon>0$ , $$ \sum_{n=1}^\infty P [|X| > n
 \epsilon ]< \infty. $$ Does this imply that $$ E| X| < \infty \quad ?$$ I made the obvious attempt \begin{align*}
E| X| &= \sum_{n=1}^\infty \int 1_{\{|X| \in (\epsilon(n-1), \epsilon n)\}}|X | dP\\
&\le \sum_{n=0} ^\infty \epsilon n P\{|X| \in (\epsilon(n-1), \epsilon n)\} \\
&\le \epsilon \sum_{n=1}^\infty n P\{ |X | \ge \epsilon n \}.
\end{align*} But this does not seem to leed to the desired conclusion. Most grateful for any help provided!","['measure-theory', 'probability-theory']"
4095305,Corollary 11.46 of John Lee's introduction to smooth manifold.,"The original satatement is that Suppose that $F : M â†’ N$ is a $\textbf{local diffeomorphism}$ . Then the pullback $F^âˆ—:\mathfrak{X}^*(N)\to \mathfrak{X}^*(M)$ takes closed covector fields to closed covector fields, and exact ones to exact ones. The proof of $F^*$ sends exact one to exact one does not use the condition $F$ is a local diffeomorphism. It's used in the proof for the case of closed covector fields. And now my professor said that we can drop the local diffeomorphism condition if $M := U\subset\Bbb R^n$ and $N:=V\subset\Bbb R^m$ . I don't understand why is true in that case. Could anyone explain this?","['smooth-manifolds', 'differential-geometry']"
4095379,Are there special or interesting non-principal ultrafilters?,While non-principal ultrafilters cannot be explicitly constructed that doesn't mean that one cannot uniquely specify one of them under the assumption of their existence. Is there an example of a uniquely determined non-principal ultrafilter? Say on $\Bbb N$ . If thats not possible is it common to separate non-principal ultrafilters into different types? Or are they most often treated as an unreachable homogenous blob which provides theorems?,"['filters', 'general-topology', 'soft-question', 'set-theory']"
4095399,Complete Probability Spaces,"I am taking a course on Stochastic Analysis, and the introduction of the course covers Measure Theory\ Probability Theory. I am very new to this area of abstract maths and am trying to get to grips with the abstract approach to mathematics. I've been provided with the following definition regarding completeness of a probability space: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and let $A \subset \Omega$ (not necessarily an element of $\mathcal{F}$ ). We say that $A$ is a null set if there exists $B \in \mathcal{F}$ such that $A \subset B$ and $\mathbb{P}(B)=0$ . We denote by $\mathcal{F}^\mathbb{P}$ the family of all subsets of $\Omega$ of the form $A \cup C$ where $A \in \mathcal{F}$ and $C$ is a null set. The collection $\mathcal{F}^\mathbb{P}$ is called the completion of $\mathcal{F}$ with respect to $\mathbb{P}$ . The probability space $(\Omega, \mathcal{F}, \mathbb{P})$ is called complete if $\mathcal{F} = \mathcal{F}^\mathbb{P}$ . Firstly, I am struggling to get to grips with this definition, as it is so heavy on notation/ maths, but moreover, what is the relevance of completion of a sigma algebra or a probability space? If anyone can break down this definition into more simplistic/ plain wording, and provide some insight into the reason for dealing with so called 'completeness', that would be brilliant.","['measure-theory', 'complete-spaces', 'probability-theory', 'probability']"
4095456,Maximal ideal with given condition,"I am reading the proof by B. Banaschewski of ""Krull implies Zorn."" I am having difficulties filling in the details in one of the steps. We start with a partition $\mathfrak U$ of an arbitrary set $E$ . A subset $X$ of $E$ is called spread if $X\cap C$ has at most one element for each $C\in\mathfrak U$ . Let $\mathfrak S$ be the set of all spreads. We consider the ring $R=\mathbb Q[E]$ of polynomials with elements of $E$ as indeterminates. Set $T=\bigcup_{X\in\mathfrak S}\langle X\rangle_R$ and $U=R-T$ , where $\langle X\rangle_R$ denotes the smallest ideal in $R$ containing $X$ . One may prove that $U$ is closed under multiplication. (Since it hasn't been used elsewhere, this information may be important for the answer of my subsequent question.) Next, let $R_0=R\left[\frac 1 u\mid u\in U\right]$ , which has a maximal ideal $M$ under assumption of Krull's Theorem. Let $H=M\cap R$ . Clearly, $H$ is an ideal of $R$ which is contained in $T$ . Apparently, $H$ is maximal (with respect to inclusion) as such. More precisely, if $I\supseteq H$ is an ideal of $R$ which is contained in $T$ , then $I=H$ . I'm having difficulties to see why $H$ is maximal. My idea was to pick an ideal $I\supsetneq H$ of $R$ , and to prove that some $u\in U$ belongs to $I$ .","['ring-theory', 'abstract-algebra', 'ideals']"
4095462,Do the terms vectors/covectors in physics refer to the same thing as in math (linear algebra/differential geometry),"In math, given a vector space $V$ on $F$ , a vector is an element $v\in V$ and a covector is an element $v^*\in V^*$ where $V^*$ is defined as $V\to F$ . Moreover, in differential geometry, the term ""tangent vector"" and ""tangent covector"" have the same meaning where $V=T_xS$ is the tangent space at some point $x$ on a manifold $S$ . In particular, the gradient of a function $f$ at $x$ is a tangent vector $\nabla f(x)$ such that for all vectors $v\in V$ , the equation $v\cdot \nabla f(x)=D_xf(v)$ holds. So the total derivative $D_xf$ is a covector, and the gradient $\nabla f(x)$ is a vector. (This is also stated on the wikipedia page on the gradient ). However, in the wikipedia page on covariance and contravariance of vectors , it states that the gradient is covariant, and is therefore a cotangent vector or covector. Moreover, in that page, ""covector"" links to the page on cotangent space in differential geometry . I'm confused by this. Is the physics page on covariance and contravariance just inconsistent? Am I missing something?","['physics', 'linear-algebra', 'differential-geometry']"
4095487,Why is this integration correct? Is it a $u$-substitution?,"I need help with equation $(4)$ in the following. I'm interested why it's mathematically correct to integrate both sides with different limits . Are there some extra steps which aren't explicit stated? Here the power of a wave is derived , starting with: $$
dK= \frac{1}{2} \mu v_y^2 \, dx \tag 1
$$ where $dm = \mu \, dx$ . ""Each mass element oif the string oscillates with a velocity:"" $$
v_y=\frac{\partial y(x,t)}{\partial t}= A\omega \cos (kx-\omega t) \tag 2
$$ So $$
dK= \frac{1}{2} A^2 \omega^2 \mu \cos^2(kx-\omega t) \, dx \tag 3
$$ ""This kinetic energy can be integrated over the wavelength to find the energy associated with each wavelength of the wave"", so at $t=0:$ \begin{align}
\int_0^{K_\lambda} dK
&= \frac{1}{2} A^2 \omega^2 \mu  \int_0^\lambda \cos^2(kx) \, dx \tag 4
\\
K_\lambda
&= \frac{1}{4} A^2 \omega^2 \mu  \lambda \tag 5
\end{align} Update: I assume it's a u-substitution which isn't explicit stated. How is it done? I have $$
	\int_0^{K_\lambda} dK
	= \frac{1}{2} A^2 \omega^2 \mu  \int_0^\lambda \cos^2(kx) \, dx \tag 6
	$$ and because of $dK$ on the left side (I assume?) I want to write the LHS in terms of $K$ . For simplicity I let $B=\frac{1}{2} A^2 \omega^2 \mu$ . Change of variable: \begin{align}
K &= kx\\
\frac{1}{k} dK &= dx
\end{align} New limits: \begin{align} 
x=0: &\quad K=0 \\
x=\lambda: &\quad K=k\lambda
\end{align} Now I can write $(6)$ as: \begin{align}
\int_0^{K_\lambda} dK
= B \int_0^{k\lambda} \frac{1}{k}\cos^2(K) \, dK \tag 7
\end{align} Is this the correct solution? The differential $dK$ appear now on both sides, but the limits are still different... how to proceed?","['integration', 'physics', 'calculus', 'real-analysis']"
4095538,"During certain sequences of coin flips, why does HHHT have a greater chance than HHHH?","I was reading an article, They were comparing sequences of coin flips. They said: ""HHHT and HHHH are equal only if flipping an unbiased coin exactly four times or infinitely many times. For values in between these two extremes, probabilities will not be the same. Imagine flipping a coin, say, 20 times and checking whether either HHHH or HHHT arise at least once in that series. Given that the wait time for HHHH is longer than that for HHHT, HHHH will also be less likely to occur at all."" Can someone help me understand why the wait time for HHHH is longer than HHHT for values in between 4 and infinite flips? Naturally, I expected that either of these sequences occurring has the same probability. Since Heads and Tails, each have a 50/50 chance with an unbiased coin. What am I missing in my understanding? Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5215234/#!po=6.13208",['probability']
4095661,Non-converging integral that should be 0,"A question requires you to prove that $$\int_0^\infty f(\frac{x}{a}+\frac{a}{x})\frac{\ln{x}}{x}dx=\ln{a}\int_0^\infty f(\frac{x}{a}+\frac{a}{x})\frac{1}{x}dx...........(1)$$ I made the substitution x=at, and split the resulting logarithm $\ln{at}$ in the integral into two, and got the above left-hand integral to be $$\ln{a}\int_0^\infty f(t+\frac{1}{t})\frac{1}{t}dt+\int_0^\infty f( t+\frac{1}{t})\frac{\ln{t}}{t}dt.......... (2)$$ Now, when you substitute back the variables in the first term above, you get the valie on the right in equation 1. So the second term in integral 2 must be 0. But I can't integrate that second term, and when I ran that term on WolframAlpha, it came out as 0 for $f(x)=sin(x)$ , but it doesn't even converge for $f(x)=cot(x)$ or $log(x)$ . So I've messed up somewhere there. Can someone help me with where and how?","['integration', 'wolfram-alpha', 'definite-integrals', 'functions', 'substitution']"
4095675,Length of continued fractions,"Consider, for any pair of relatively prime positive integers $0 <j <n$ , the expansion as a continued fraction of the quotient $\frac{n}{j}$ $$
\frac{n}{j}=b_1-\frac{1}{b_2-\dfrac{1}{\cdots-\dfrac{1}{b_l}}}.
$$ Set $l_j^n:=l$ for the length of this expansion and consider the rational number $$
m(j,n)=\frac{l_j^n+l_{n-j}^n}{n}.
$$ What do we know about the set $M:={m(j,n)}$ ? By a Result of Riemenschneider (Lemma 4 in this paper ) I know that $l_j^n+l_{n-j}^n=1+ \sum_{i=1}^{l_j^n}(b_i-1)$ . In particular if $j=1$ , then $b_1=n$ , $l_1^n=1$ ,  and so $m(1,n)=1$ . It seems to me that $1$ is the maximum possible value, in other words that, for every $j, n, m (j, n) \leq 1$ holds. But I cannot prove it. In general, I would appreciate any result on $M$ . I'm interested in particular to the set $L$ of all possible limits of $m(j_k,n_k)$ for sequences $(j_k,n_k)$ where $n_k\to \infty$ . The sequence $(1,n)$ shows that $1 \in L$ .
If my computations are correct, the sequence $(n,2n-1)$ (here $l_n^{2n-1}=2, b_1=2, b_2=n$ ) shows $\frac{1}{2} \in L$ . Is it possible to determine explicitly the set $L$ ? Or at least a ""big"" subset of it?","['continued-fractions', 'combinatorics', 'combinatorial-proofs', 'prime-numbers']"
4095701,Coefficient of $x^{12}$ in $(1+x^2+x^4+x^6)^n$,"I need to find the coefficient of $x^{12}$ in the polynomial $(1+x^2+x^4+x^6)^n$ . I have reduced the polynomial to $\left(\frac{1-x^8}{1-x^2}\right)^ n$ and tried binomial expansion and Taylor series, yet it seems too complicated to be worked out by hand. What should I do?","['binomial-coefficients', 'combinatorics', 'binomial-theorem']"
4095704,"Two manifolds $X$ and $Y$ with two bijective continuous functions from $X$ to $Y$ and $Y$ to $X$, but not homeomorphic","I happen to found this question about finding two metric spaces $X$ and $Y$ such that there exists bijective continuous functions $f:X\to Y$ and $g:Y\to X$, and $X$ and $Y$ are not homeomorphic. I could not produce my own example, and I think the reason is that I am thinking of manifolds only. Suppose we have two second-countable Hausdorff metrisable manifolds $X$ and $Y$ such that there exists bijective continuous functions $f:X\to Y$ and $g:Y\to X$. Can we show that the two manifolds are homeomorphic? Or is there still a counterexample? Please note that I have taken only one course on metric space and topology, and I don't have much experience with manifolds. So please explain answers in details or post references to the details. Edit: In case of any ambiguity, I would like to state that I do not restrict attention to manifolds without boundary, i.e. the manifolds may have boundary, if such a counterexample exists.",['general-topology']
4095707,"Lawvere: Recovering Galois connections from ""globalized"" Galois connections (adjunctions)","In the section on globalized Galois connections in Lawvere's paper Adjointness in foundations , Lawvere suggests to replace Galois connections (which are, adjunctions between poset-categories) by more profound adjunctions between non-poset-categories containing more information, of which the former are ""fragments"". As an example, he mentions that the familiar Galois connection between intermediate fields of $L/K$ and subgroups of $Gal(L/K)$ , for some fixed Galois extension $L/K$ , can be ""globalized"" to an adjunction between the opposite category of the category of $k$ -algebras and the category of topological $Gal(\overline{k}/k)$ -sets. Question: In which sense can the Galois connection be considered as a ""fragment"" of the adjunction? Lawvere writes Restricting to subalgebras of $\overline{k}$ on the one hand
and to quotients of the regular representation on the other retrieves in effect the usual
Galois connection. but I don't understand this and how this ""retrieves in effect the usual
Galois connection"". Another example he mentions is that the Galois connection between ideals in $k[x_1, \dots, x_n]$ and varieties can be ""globalized"" to the adjunction between $k$ -algebras and schemes (given by ""spectrum"" and ""global section""). Here I also wonder: how can the former be recovered from the latter?","['galois-theory', 'algebraic-geometry', 'soft-question', 'category-theory']"
4095735,"Get asymptotic behaviour of the equation $y' = C e^{-(\log x)^s}$, as $x \rightarrow \infty$","I have the following differential equation $$y''+ s \frac{(\log x)^{s-1}}{x}y'=0$$ where $s>0$ . It  is very easy to see that $$y' = C_1 e^{-(\log x)^s},$$ which cannot be integrated in closed form, as far as I know. What I am interested in is finding how $y$ behaves as $x \rightarrow \infty$ , that is, it's asymptotic behaviour. A first idea would be to write the integrand as a series in $(\log x )^s$ and integrate term by term, but that doesn't really help since as $x$ is arbitrarily large, every term is larger than the previous one (in absolute terms), and so it doesn't make sense to terminate the series somewhere. How can I do that in this case? EDIT: One idea might be to make the ansatz $$y(x) = \sum_{n=0}^\infty y_n(x) s^n,$$ and solve for the $y_n(x)$ term by term. The zeroth order term is $$y_0(x) = C_1 e^{-d} x+C_2,$$ while the first order term is $$y_1(x) = C_1 d e^{-d} \int^x \log (\log u) du.$$ In general, it is easy to see that $$y_n(x) \propto \int^x[ \log (\log u)]^n du.$$ If we are able to compute the limit of the ratio $$ \lim_{x \rightarrow \infty} \frac{y_{n+1}(x)}{y_n(x)} \propto \lim_{x \rightarrow \infty}\frac{\int^x[ \log (\log u)]^{n+1} du
}{\int^x[ \log (\log u)]^n du}
$$ and show that it vanishes (I don't know what it is equal to, but it'd be lovely if it vanished ), then indeed we have the asymptotic behaviour. If it diverges, then we haven't made much progress. I think it probably diverges, given that it is easy to see that the limit is $$ \lim_{x \rightarrow \infty} \frac{y'_{n+1}(x)}{y'_n(x)} \propto \lim_{x \rightarrow \infty}\frac{[ \log (\log x)]^{n+1}
}{[ \log (\log x)]^n}=\lim_{x \rightarrow \infty} \log (\log x) = \infty.
$$ This of course assumes that the original limit is indeterminate which is likely but not known yet. NOTE: I set all integration constants for the terms $y_n(x)$ with $n \geq 1$ equal to zero, and keep them only for the zeroth term.","['integration', 'asymptotics', 'ordinary-differential-equations']"
4095739,Solving an integral equation by converting it to a differential equation [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I have to solve an integral equation given as $$ x(y)=\sin(y)+\varepsilon \int_0^\infty e^{-s} x(y+s) \mathrm{d}s$$ I know that I have to differentiate it, but I am doing hard with it. Can anyone please help me?!","['integral-equations', 'ordinary-differential-equations']"
4095872,Prove that sheaf is quasi-coherent,"Let $f :X \to Y$ be an affine morphism. Prove that the direct image sheaf $f_*\mathscr{O}_X$ is a quasi-coherent $\mathscr{O}_Y$ -module. One of the equivalent definitions of a quasi-coherent $\mathscr{O}_X$ -module $\mathscr{F}$ is that for all affine opens $V\subset U$ , the natural map $\mathscr{F}(V)\otimes_{\mathscr{O}_X(U)}\mathscr{O}_X(V)\to \mathscr{F}(V)$ is an isomorphism of $\mathscr{O}_X(V)$ -modules. My try was as follows: Let $V\subset U$ be affine opens in $Y$ . Since $f$ is an affine morphism, $f^{-1}V\subset f^{-1}U$ is an inclusion of affine opens. Now, $\mathscr{O}_X$ itself is a quasi-coherent $\mathscr{O}_X$ -module, so the natural map $$
\mathscr{O}_X(f^{-1}U)\otimes_{\mathscr{O}_X(f^{-1}U)} \mathscr{O}_X(f^{-1}V) \longrightarrow \mathscr{O}_X(f^{-1}V)
$$ is an isomorphism. This is of course just $$
f_*\mathscr{O}_X(U) \otimes_{\mathscr{O}_X(f^{-1}U)} \mathscr{O}_X(f^{-1}V) \longrightarrow f_*\mathscr{O}_X(V)
$$ What we want to show is that $$
f_*\mathscr{O}_X(U) \otimes_{\mathscr{O}_Y(U)} \mathscr{O}_Y(V) \longrightarrow f_*\mathscr{O}_X(V)
$$ is an isomorphism. I believe that there should not be much to it, but I can not see it. Perhaps that we can use the fact that $A\otimes_B B\cong A$ ? Is there any slick way to do this exercise ? Any help is appreciated","['algebraic-geometry', 'sheaf-theory']"
4095877,Representation theory and generalizing the determinant and permanent.,"Let $M$ be an arbitrary $n\times n$ complex matrix and $S_n$ be the symmetric group of order $n$ . Given $\sigma\in S_n$ , define $\sigma(M)$ to be the $n\times n$ matrix with elements $[\sigma(M)]_{ij} = M_{i\sigma(j)}$ . With this, there are two well-known matrix functions (functions that take matrices as inputs) that interplay nicely: \begin{align}
\text{perm}(\sigma(M)) &= \text{perm}(M),
\\
\det(\sigma(M)) &= \text{sgn}(\sigma)\det(M),
\end{align} where perm and $\det$ are the permanent and determinant, respectively, and $\text{sgn}(\sigma)$ is the sign of the permutation $\sigma$ . Note that these two equations have the following form: \begin{align*}
f(\sigma(M)) = \rho(\sigma) f(M)
\end{align*} where $f$ is some function of matrices and $\rho$ is a representation of the symmetric group. In the above examples, $\rho$ is the trivial representation (in the case of $f=\text{perm}$ ) or the sign representation (in the case of $f=\det$ ). My question is this: given a representation $\rho$ , can one find a matrix function $f$ such that $f(\sigma(M)) = \rho(\sigma)f(M)$ ? Subsequent questions regarding uniqueness follow naturally. Note that $f:\mathbb{C}^{n\times n}\to\mathbb{C}^d$ with $d$ the dimension of the representation. As a concrete example, suppose $\rho$ is the two-dimensional representation of $S_3$ . Is there a known function $f:\mathbb{C}^{3\times 3}\to \mathbb{C}^2$ (takes in matrices, outputs vectors) such that the aforementioned relationship holds? Thanks in advance!","['representation-theory', 'group-theory', 'linear-algebra']"
4095910,Understanding Rayleigh distribution,"I am an aerospace enthusiast. I have obtained wind speed data that's been gathered and published by NCEP/NCAR. It provides wind speed data for every $2.5^\circ$ increment in latitude and longitude for 17 altitude levels. I want to predict the upper bound of the wind speed that a given location and altitude will face with a confidence percentage of 99. Wind speed data is usually modelled as a Rayleigh distribution. How can I find this upper bound? I have tried something along these lines, please let me know if I'm going about it the right way. The probability of a wind exceeding $v_i$ for each day ( $d$ ), altitude ( $h$ ), latitude ( $\Phi$ )
and longitude ( $\lambda$ ) as $P(d, h, \phi, \lambda)_i = e^{-\frac{\pi}{4}\left(\frac{v^2}{\mu^2}\right)}$ The percent availability (i.e., the percent of the time that the wind is less than $v_i$ ) is, $\bar{P}(d,h,\phi,\lambda)_i = 1 - P(d,h,\phi,\lambda)_i \times 100%$ So the desired station keeping probability if set at 99%, we need to find $v_i$ that satisfies, $0.99 = \frac{\sum_{d=1}^{365} P(d,h,\phi,\lambda)_i}{365}$ i.e., taking the mean of the probability over 365 days. Is that right?","['statistics', 'probability', 'random-variables']"
4095969,Alternative proofs that square root is irrational function,"My work is to show alternative proof that $\sqrt x$ is irrational function. The simplest proof might be to find a ""counter-example"".  I mean, it is enough to show that $\sqrt 2=\dfrac{f(2)}{g(2)}$ is irrational. I found the argument based on this argument I said in M.SE. Suppose there exists $\alpha\in\mathbb{Q}(x)$ such that $|\alpha(x)|=\sqrt{x}$ for all $x\in\mathbb{Q}$ with $x\ge 0$ . Then in particular, we have $|\alpha(2)|=\sqrt{2}$ , contradiction, since $\alpha(2)$ can't be irrational. The argument that one of the functions $f^2(x)$ and $xg^2(x)$ has a even degree and the other has a odd degree is also valid. Now I want to know whether these two proofs that I have made are valid too. Let, $f(x)$ and $g(x)$ be polynomials, such that $$\sqrt x=\frac{f(x)}{g(x)} \Longrightarrow x=\frac{f^2(x)}{g^2(x)}$$ Then, $$\deg \left (f^2(x)-g^2(x)\right)=\deg x=1$$ $$2 \deg \left (f(x)-g(x)\right)=1$$ $$\deg \left (f(x)-g(x)\right)=\frac 12 \not\in\mathbb Z^{+}$$ Thus, we can deduce such $f(x)$ and $g(x)$ doesn't exist. By accepting $$\sqrt x=\frac{f(x)}{g(x)}$$ $$\deg f(x)=m ~~\text{and}~~ \deg g(x)=n, $$ $$m,n\in\mathbb Z^{+}âˆª\left\{0\right\}$$ Then, $$\lim_{x\to\infty}\frac{f(x)}{g(x)}=\infty \implies m-nâ‰¥1$$ Then let $xâ‰ 0$ , we have $$\frac{\sqrt x}{x}=\frac{f(x)}{xg(x)}$$ $$\frac{1}{\sqrt x}=\frac{f(x)}{xg(x)}$$ $$\lim_{x\to\infty}\frac{f(x)}{xg(x)}=0 \implies n+1-mâ‰¥1$$ Finally we have, $$\begin{cases} m-nâ‰¥1\\ n+1-mâ‰¥1 \end{cases} \implies \begin{cases} m-nâ‰¥1 \\m-nâ‰¤0\end{cases} $$ $$\implies \left\{m,n\right\}\in \emptyset.$$ Are there any points / steps I missed? Which proofs / arguments are valid and which are not? Thank you.","['proof-writing', 'solution-verification', 'polynomials', 'algebra-precalculus', 'rational-functions']"
4095988,Find f if $\int_0^1 f(x)^2dx=\int_0^1 f(x)^3dx =\int_0^1 f(x)^4dx$ [duplicate],"This question already has answers here : Solve these functional equations: $\int_0^1\!{f(x)^2\, \mathrm{dx}}= \int_0^1\!{f(x)^3\, \mathrm{dx}}= \int_0^1\!{f(x)^4\, \mathrm{dx}}$ (3 answers) Closed 3 years ago . $f:[0,1]\to \mathbb{R}$ is a continuous function such that $$\int_0^1 f(x)^2dx=\int_0^1 f(x)^3dx =\int_0^1 f(x)^4dx$$ Find all such $f$ My approach: Clearly $f=0,1$ are solutions (and only possible constant functions).
Now let $f$ to be a non constant function.
By CS inequality we have, $$\int_0^1 f(x)^2dx \times \int_0^1 f(x)^4dx \ge ( \int_0^1 f(x)^3dx )^2$$ Equality holds here.So $\int_0^t f(x)dx =k \int_0^t f(x)^2dx$ for all $t\in (0,1]$ for some $k$ .
I don't know what to do from here ðŸ˜…
Please help.","['integration', 'calculus', 'real-analysis']"
4096008,Solve trigonometric equation $2x=\sin(2x)+\pi/2$,"I would appreciate help in solving this equation: $$2x =\sin 2x + \frac{\pi}{2}$$ I am aware that instead of $2x$ in $\sin(2x)$ I could put the whole right part of the equation, and then again and again the same thing, till infinity. I know the solution exists (from photomath app). How is this type of equation called and how to find the solution? Thanks for any help!","['trigonometry', 'transcendental-equations']"
4096021,"Reference on Sobolev spaces $W^{k,p}(\Omega;\mathbb{R}^n)$","While reading about calculus of variations I stumbled upon the Sobolev spaces $W^{k,p}(\Omega;\mathbb{R}^n)$ of order $k$ weakly differentiable functions with $p$ integrable derivatives, and codomain $\mathbb{R}^n$ instead of $\mathbb{R}$ . Do you have any reference where definitions and properties about those spaces are provided?","['reference-request', 'real-analysis', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
4096051,"Artin exercise 2.5.4: Let $f:\Bbb R^+\to\Bbb C^\times$ be the map $f(x)=e^{ix}$. Prove that $f$ is a homomorphism, and determine its kernel and image.","I am trying to solve: Let $f: \mathbb{R}^{+} \to \mathbb{C}^{\times}$ be the map $f(x) = e^{ix}$ . Prove that $f$ is a homomorphism, and determine its kernel and image. Here is my attempt. Given $x,y \in \mathbb{R}$ , we have \begin{align*}
f(x+y) = e^{i(x+y)} = e^{ix + iy} = e^{ix} e^{iy} = f(x) f(y),
\end{align*} so $f$ is a homomorphism. I claim that $\mathrm{ker}(\varphi) = \{2\pi k \mid k \in \mathbb{Z}\}$ . Indeed, we have: \begin{align*}
x \in \mathrm{ker}(f) & \iff f(x) = 1 \\
& \iff e^{ix} = 1 \\
& \iff \cos(x) + i \sin x = 1 \\
& \iff \cos x = 1, \; \sin x = 0 \\
& \iff x = 2\pi k, \; k \in \mathbb{Z}
\end{align*} Finally, I claim that $\mathrm{Im}(f) = S^1 = \{z \in \mathbb{C} \mid |z| = 1\}$ . We have: \begin{align*}
z \in \mathrm{Im}(f) & \iff \exists x \in \mathbb{R}, \; f(x) = e^{ix} = z \\
& \iff |z| = 1 \\
& \iff z \in S^1 
\end{align*} How does this look?","['group-homomorphism', 'group-theory', 'solution-verification']"
4096093,Sobolev spaces with negative exponent,"For $k\in \mathbb{N}$ and $p \geq 1,$ what is the motivation behind defining the Sobolev spaces with negative exponent $W^{-k,p}$ as the dual of $W_0^{k,p}$ and not as the dual of $W^{k,p}.$","['sobolev-spaces', 'functional-analysis', 'analysis']"
4096099,Derivative of $\mbox{sgn}$,"I get a different result than the book I'm reading for the derivative of the sign function. Let's define the sign function, $x \mapsto \mbox{sgn}(x)$ , as $$ \mbox{sgn} (x) =  \begin{cases} 
      1 & x > 0 \\
     -1 & x < 0 \\
   \end{cases}$$ Let $u(x)$ be the Heaviside step and $\delta(x)$ be the Dirac delta. By definition, $u'(x) = \delta(x)$ and $\delta(-x) = \delta(x)$ . I can rewrite $\mbox{sgn}(x) = u(t) - u(-t)$ . Differentiating, we get $$\mbox{sgn}'(x) = u'(x) - u'(-x)$$ So far the book and I agree. Here is where we disagree. I then proceed to say $$\mbox{sgn}'(x) = \delta(x) - \delta(-x) = 0$$ whereas the book says $$\mbox{sgn}'(x) = \delta(x) - [-\delta(x)] = 2 \delta(t)$$ This implies that $u'(-t) = -\delta(t)$ which I don't agree with.","['step-function', 'dirac-delta', 'distribution-theory', 'calculus', 'derivatives']"
4096116,"Given the law of a diffusion $dX_t = \lambda_t(t,X_t) + \sigma dB_t$, can we find explicitly the drift?","Let $(\Omega, \mathcal F, P)$ be a probability space. Suppose that we have a stochastic process of the form $$d X_t = \lambda_t(t,X_t) + \sigma dB_t $$ where $\sigma >0$ is given and $B_t$ is a standard Brownian motion. We don't know the drift $\lambda$ but  we know that $X_t \sim_P \mathcal N (\mu_t, \sigma_t)$ where $\mu_t,\sigma_t$ are given. Can we find $\lambda_t$ ?","['stochastic-analysis', 'stochastic-processes', 'stochastic-differential-equations', 'probability-theory', 'stochastic-calculus']"
4096126,The semidirect product of $G$ with ${\rm Aut}(G)$ in the canonical way: its name and its implementation in GAP and/or Magma,Let $G$ be a finite group with automorphism group ${\rm Aut}(G)$ . Let $A_G$ denote the semidirect product of $G$ with ${\rm Aut}(G)$ in the canonical way. Question 1: Is there are name for $A_G$ in the literature? Question 2: Is there a way to obtain $A_G$ in GAP (and/or Magma) for a given finite group $G$ ?,"['gap', 'reference-request', 'definition', 'magma-cas', 'group-theory']"
4096146,Is the differential $\mathrm{d}\vec{r}$ a sensible mathematical object?,"When doing differential geometry, physicists often use $$\mathrm{d}\vec{r} = \mathrm{d}x^i\space\vec{e}_i$$ for many different things. For instance, they define the holonomic basis $\{\vec{e}^{\space\prime}_a\}$ relative to a coordinate system $\{x'^a\}$ by imposing $$\mathrm{d}\vec{r} = \mathrm{d}x'^{a}\space\vec{e}^{\space\prime}_a \implies \vec{e}^{\space\prime}_a=\frac{\partial\vec{r}}{\partial x'^a}$$ and they compute the quadratic form of the metric $\mathrm{d}s^2$ as $\mathrm{d}\vec{r}\cdot\mathrm{d}\vec{r}$ . Computing the differential of a vector field ( $\vec{r}=x^i\vec{e}_i$ , in this case) feels strange, as in differential geometry differentials are usually considered to be alternating $k$ -forms, so it would only make sense to talk about the differential of a scalar field (aka its exterior derivative). Not only that, the ""true"" definitions of holonomic bases and $\mathrm{d}s^2$ don't use this $\mathrm{d}\vec{r}$ at all. EDIT: in fact, taking the derivative of $\vec{r}$ , or any other vector field, is something we are not allowed to do in a general differentiable manifold without a connection, so we obviously wouldn't define a holonomic basis like that. A holonomic basis would basically be the basis formed by the tangent vectors $\partial/\partial x'^a$ . After thinking about it, I thought the differential of a vector field might just be $$\mathrm{d}\vec{\varphi} = (\nabla_i\varphi^j)\space\vec{e}_j\otimes\mathrm{d}x^i,$$ so maybe $\mathrm{d}\vec{r} = \mathrm{d}x^i\space\vec{e}_i$ means $\mathrm{d}\vec{r} = \mathrm{d}x^i\otimes\vec{e}_i$ ? How is $\mathrm{d}\vec{r}$ rigorously defined, otherwise?",['differential-geometry']
4096175,"What is the opposite of a ""discrete set""?","$\mathcal{N} = \{1, \ldots, p\}$ or $\{1, 2, 3, 4,\ldots\}$ are discrete sets. So what is the opposite of a discrete set? There is no such thing as a ""continuous set"". I know there is convex set, connected sets as well as path connected sets and their generalizations. Which concept would most appropriately or generally describe sets (such as $(a,b),[a,b]$ and their products, etc.) where there is no discontinuity when traveling from one point to another? i.e., what is the most general way to describe a ""connected set?""","['reference-request', 'real-analysis', 'definition', 'elementary-set-theory', 'general-topology']"
4096216,"Analogue of Cauchy Integral Formula to compute $f(a)$ in terms of $f(z)$, $z$ on $\gamma$, when $a$ is outside $\gamma$","Let $f:\Omega\to\mathbb C$ be holomorphic, where $\Omega$ is a simply connected domain. Suppose we know the values of $f$ on a simple closed curve $\gamma$ contained in $\Omega$ . The Cauchy Integral Formula tells us how to calculate $f(a)$ for $a$ inside $\gamma$ . But $f(a)$ is also uniquely determined for $a\in\Omega$ outside $\gamma$ (by the Identity Theorem). For such $a$ , is there an explicit Cauchy-like formula for $f(a)$ in terms of the values of $f$ on $\gamma$ ?",['complex-analysis']
4096220,What really is $dr$ in differential forms?,"I am reading Arnold's Mathematical Methods of Classical Mechanics , and have arrived at differential forms. At this point in the chapter, there has been no discussion of the exterior derivative. There is discussion of the differential, however. One of the problems defines a differential form $$\omega=r\;dr\wedge d\varphi$$ where $x_1=r\cos\varphi$ and $x_2=r\sin\varphi$ ; $x_1$ and $x_2$ are the standard coordinates in $\mathbb{R}^2$ . So I can take differentials \begin{align*}
dx_1\wedge dx_2
&=d(r\cos\varphi)\wedge d(r\sin\varphi)\\
&=(\cos\varphi\;dr-r\sin\varphi\;d\varphi)\wedge(\sin\varphi\;dr+r\cos\varphi\;d\varphi)\\
&=r\;dr\wedge d\varphi.
\end{align*} But looking back, I realize that I don't really understand what I did at all. First of all, when we say $x_1=r\cos\varphi$ , for example, it seems like the $x_1$ we are talking about is the one that gives the coordinates on $\mathbb{R}^2$ , which is our manifold. On the other hand, $dx_1\wedge dx_2$ is a k-form on the tangent space at a particular point of $\mathbb{R}^2$ . So this substitution really doesn't even make sense to me at all; it feels like a type error. It seems perfectly plausible to me that our manifold can have polar coordinates while each tangent space has Cartesian coordinates. Second, what even is $dr$ ? The only interpretation I have is that it is the differential of the function $r$ . Intuitively it seems like it should be the function that, if the tangent space is parameterized using polar coordinates, retrieves the coordinate $r$ . So if I were to evaluate the differential form $dr$ at the point $(0,1)$ (in $\mathbb{R}^2$ ) on the vector $(1,1)$ in the tangent space, would the result be $\sqrt{2}$ ? I really seem to have confused a bunch of stuff here, so any help would be appreciated.","['manifolds', 'differential-forms', 'differential-geometry']"
4096299,Why does Green's theorem fail for non simple curves?,"In looking at the proof of Green's theorem, it is not obvious to me why it must be a simple curve. I was thinking that perhaps it would still apply for a closed curve that crosses itself a countable number of times since then it could be broken up into the sum of countably many cases where it does apply. Does anybody have any insight on where it breaks down specifically with non-simple curves and or if it can be extended to countably many crossings?",['multivariable-calculus']
4096392,reflexivity of Bochner space,"Let $(\Omega, \mathscr F, \mu)$ be a $\sigma$ -finite measure space and $X$ be a Banach space, and assume that $X^*$ has the Radon-Nikodym property with respect to $(\Omega, \mathscr F, \mu)$ . I'm trying to prove the reflexivity of the Bochner space $L^p(\Omega;X)$ when $1< p <\infty$ . The following is my proof: Let $1/p + 1/q =1 $ and consider the map $\Phi_{p,X} : L^q(\Omega; X^*) \to L^p(\Omega; X)^*  $ defined by $$\langle f, \Phi_{p,X}g  \rangle := \int_\Omega \langle f,g\rangle \,d\mu, \quad f\in L^p(\Omega; X),\;g\in L^q(\Omega; X^*) .$$ Then by the Radon-Nikodym property, $\Phi_{p,X}$ is an isometric isomorphism. Note that, for all $f\in L^p(\Omega; X)$ and $g\in L^q(\Omega; X^*) $ we have $$ \langle f, \Phi_{p,X}g  \rangle = \int_\Omega \langle f,g\rangle \,d\mu  =  \int_\Omega \langle g,j_Xf\rangle \,d\mu  =  \langle g, \Phi_{q,X^*}(j_Xf)  \rangle, $$ where $j_X:X\to X^{**}$ is the canonical injection. Now, let $J:L^p(\Omega; X)\to L^p(\Omega; X)^{**} $ be the canonical injection.  Then for all $\Lambda \in L^p(\Omega; X)^* $ and $f\in L^p(\Omega; X) $ , we have $$ \langle \Lambda, Jf \rangle = \langle f,\Lambda \rangle  = \langle f,\Phi_{p,X}\Phi_{p,X}^{-1}\Lambda \rangle = \langle \Phi_{p,X}^{-1}\Lambda,\Phi_{q,X^*}(j_Xf) \rangle = \langle \Lambda,(\Phi_{p,X}^{-1})^*\Phi_{q,X^*}(j_Xf) \rangle, $$ where $(\Phi_{p,X}^{-1})^*$ is the adjoint operator of $\Phi_{p,X}^{-1}$ . Therefore $J$ is surjective. That is, $L^p(\Omega; X)$ is reflexive. Is the above proof correct ? Edited:
I found that reflexivity of $X$ is also needed.","['measure-theory', 'reflexive-space', 'solution-verification', 'bochner-spaces', 'radon-nikodym']"
4096419,Integral $\int_{-\infty}^{+\infty}\frac{e^{-x^2}}{e^{-x} + 1}dx$,"I would like to know how the integral \begin{equation}
\int_{-\infty}^{+\infty}\frac{e^{-x^2}}{e^{-x} + 1}dx
\end{equation} can be evaluated. Mathematica says the value is $\sqrt{\pi}/2$ . I thought I could get this using Residue theorem but I'm having trouble showing that the arc \begin{equation}
\int_{0}^\pi\frac{e^{-R^2e^{2i\theta}}}{e^{-Re^{i\theta}} + 1}iRe^{i\theta}d\theta
\end{equation} would go to zero as $R\rightarrow 0$ , mainly because $e^{-R^2e^{2i\theta}}$ is actually large when $\theta$ is around $\pi/2$ . Ultimately, I'm actually interested in a slightly more general integral which Mathematica won't evaluate at all: \begin{equation}
\int_{-\infty}^{+\infty}\frac{e^{-a(x-b)^2}}{e^{-x} + 1}dx.
\end{equation} So I'm hoping that understanding the simple case above will help me.","['integration', 'calculus']"
4096448,"Evaluating $\lim_{x\to \infty} \frac{f^{-1}(2021x)-f^{-1}(x)}{\sqrt[2021] x}$, where $f(x)=2021x^{2021}+x+1$","Let $f(x)=2021x^{2021}+x+1$ , and compute the following limit: $$\lim_{x\to \infty} \frac{f^{-1}(2021x)-f^{-1}(x)}{\sqrt[2021] x}$$ My attempt: i want to use mean value theorem to $f^{-1}(x)$ then we have: $ \frac{2020x}{((2021)^2 (Î·_y)^{2021}+1)(\sqrt[2021] x)}$ .
And $f(Î·_y)=Î·_x$ , $Î·_xâˆˆ(x,2021x) $ . We know $Î·_x$ tend to 0 as x tend to $\infty$ so from the expression of $f$ we know $Î·_y$ is also.but we  don't know  the quotient of $Î·_y$ and $x$ , so i think this way is fail. But i can't do it in other way.","['inverse-function', 'real-analysis', 'calculus', 'functions', 'limits']"
4096500,"I am confused on the last step of ""differentiability implies continuity""","I am watching this video of the proof "" differentiability implies continuity "" for functions $ f: U\subset \mathbb R \to \mathbb R $ , and I have doubts about the last step. In the proof it is concluded that $$ \lim_{t \to c } ~ (f(t) - f(c)) = 0 .$$ From here they use limit laws to rewrite the left side as a difference of limits. $$ \lim_{t \to c } f(t) - \lim_{t \to c }  f(c) = 0. $$ My question is, using the limit law is only valid provided we know apriori that $ \lim_{t \to c }f(t) $ and $ \lim_{t \to c } f(c) $ exist. It is easy to show that $ \lim_{t \to c } f(c) $ exists, since $\lim_{t \to c } f(c) = f(c)$ , but I don't see where it is given in the hypothesis that $ \lim_{t \to c }f(t) $ exists.","['continuity', 'calculus', 'derivatives']"
4096533,Stability of the equilibrium states,"I have a function defined by the following differential equation $$
\frac{\mathrm{d}\varphi}{\mathrm{d}t} = \gamma - F(\varphi)
$$ where $F(\varphi)$ is a $2\pi$ -periodic function) and the chart of the function $F(\varphi)$ is known. I need to find the equilibrium states (e.s.) and find out if they are stable. I've managed to find out what are they only in some cases (but this is not accurate). Can you help with others? ^ F(Ï†)
                1|
                 |    /\  /\
                b|   /  \/  \
                 |  /        \
                 | /          \    
__-Ï€_______-a____|/____________\____>Ï†
   \            /|0    a Ï€/2   Ï€ 
    \          / |
     \        /  |
      \  /\  /   |-b
       \/  \/    |
                 |-1 If $|\gamma| > 1$ then there are no e.s. If $|\gamma| = 1$ there are 2 (at level Â±Î³ each) e.s. in points (a,1), (Ï€-a,1). maybe they're semi-stable? If $b < |\gamma| < 1$ there are $4$ at level $\pm \gamma$ each e.s. If $|\gamma| = b$ there are $3$ at level $\pm\gamma$ each e.s.: point $(\pi/2, b)$ , $\varphi = a\gamma$ , $\gamma = \pi - a\gamma$ . If $0 < |\gamma| < b$ there are $2$ e.s. at level $\pmÂ±\gamma$ each $\varphi  = a\gamma$ (is it stable?) , $\varphi = \pi - a\gamma$ (and is this one unstable?). The form of $F(\varphi)$ is the following one: $$F(\varphi)=\begin{cases}
 & {-\dfrac{\varphi}{a}-\dfrac{\pi}{a}},  &\text{if } {\varphi \in [-\pi, -\pi + a]},\\
\\
 & \dfrac{1-b}{\dfrac{\pi }{2}-a }\varphi + \dfrac{(1-b)(\pi-a))}{\dfrac{\pi }{2}-a }-1, &\text{if } {\varphi \in [-\pi + a,-\frac{\pi }{2}}], \\ 
\\
 & \dfrac{b-1}{\dfrac{\pi }{2}-a }\varphi + \dfrac{a(1-b)}{\dfrac{\pi }{2}-a }-1, &\text{if } {\varphi \in [-\dfrac{\pi }{2}}, -a], \\
\\
 & \dfrac{\varphi}{a},  &\text{if }  {\varphi \in [- a,  a]}, \\
\\
& \dfrac{b-1}{\dfrac{\pi }{2}-a }\varphi - \dfrac{a(1-b)}{\dfrac{\pi }{2}-a }+1, &\text{if } {\varphi \in [a, \frac{\pi }{2}}], \\
\\
& \dfrac{1-b}{\dfrac{\pi }{2}-a }\varphi - \dfrac{(1-b)(\pi-a))}{\dfrac{\pi }{2}-a }+1, &\text{if } {\varphi \in [\frac{\pi }{2}}, \pi-a], \\ 
\\
 & {-\dfrac{\varphi}{a}+\dfrac{\pi}{a}},&\text{if }  {\varphi \in [\pi-a, \pi]}.
\end{cases}$$ P.S. sorry for this chart :)","['stability-in-odes', 'stability-theory', 'ordinary-differential-equations', 'dynamical-systems']"
4096535,Writing shapes as a cartesian product of other shapes.,"(I am not really sure about what tags I should give to this question, so I put every tag with 'topology' in it.) We can write a torus as a cartesian product of two circles: $T^2=S^1Ã—S^1$ And the same way, a cylinder can be thought of as a cartesian product of a line and a circle: If we denote $C^2$ as a cylinder and $L^1$ as a line, then: $C^2=L^1Ã—S^1$ So it seems like a factorization of shapes. So I want to know that $(1)$ Is there a mathematical concept like this? $(2)$ Are there prime shapes which cannot be written as a cartesian product of two shapes? (I am extremely sorry of this question lacks mathematical clarification, I am not a mathematician so I cannot really clarify more than I did in my question. But I hope that the examples I gave, clarifies enough for someone to answer my question.)","['geometric-topology', 'general-topology']"
4096545,Question on union of particular subsets of a given set,"Given positive integers $n,d,\ell$ , $d\ge2$ , $n\ge 1+(d-1)\ell$ . Let $s$ be the minimum integer possible such that the union of any $s$ subsets $A_1,\dots,A_s$ of the set $\{1,\dots,n\}$ having cardinality $d$ and with the property that for each $i$ , $A_i$ consist of elements $a_{i,1},\dots,a_{i,d}$ such that $a_{i,j+1}-a_{i,j}\ge\ell$ , for all $j=1,\dots,d-1$ , is $A_1\cup\dots\cup A_s=\{1,\dots,n\}$ . Prove that $s$ is the integer $$
s=\binom{n-(d-1)(\ell-1)-1}{d}+1.
$$ I could only prove the case $\ell=1$ . In such case $s=\binom{n-1}{d}+1$ and the subsets $A_i$ are ordinary subsets. That $s=\binom{n-1}{d}+1$ , if $\ell=1$ was proved in a previous question, I can add the link if anyone wants to see that. Maybe induction could work? Any help is appreciated.","['binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
4096591,Is $\frac {x-2}{x-2}$ defined and continuous at $x=2$,"A quick question. Is the function $\frac {x-2}{x-2}$ defined at $x=2$ ? For, when I plotted it, it was shown to be continuous. Also, if I try to prove continuity, the left limit $=1$ and right limit is also equal to $1$ , but $f(2)$ takes the $0/0$ form. How do I prove the continuity?","['limits', 'calculus', 'functions', 'continuity']"
4096596,$E[Y_n^{-1}]$ converges at the same rate as $E[Y_n]^{-1}$ where $Y_n = \bigg(n\sum_{i=1}^n X_i^2 - \bigg(\sum_{i=1}^nX_i \bigg)^2\bigg)^k$,"Let $X_1,X_2,\dots,X_n$ be i.i.d observations of a continuous random variable $X$ . Let $Y_n$ be the sample variance: $$
Y_n = \bigg(n\sum_{i=1}^n X_i^2 - \bigg(\sum_{i=1}^nX_i \bigg)^2\bigg)^k.
$$ Actually, for $k=1$ , $Y_n$ is simply the sample variance scaled by $n^2$ , i.e., we can write it as $$
Y_n = n^2 \bigg(\frac{1}{n}\sum_{i=1}^n X_i^2 - \bigg(\frac{1}{n}\sum_{i=1}^nX_i \bigg)^2\bigg).
$$ Here is a plot for the case of $k=1$ . From running computational simulations it is clear that $E[Y_n^{-1}]$ and $E[Y_n]^{-1}$ converge at the same rate as $n \to \infty$ , e.g. there exists constants $C_1$ and $C_2$ such that $$
C_1 E[Y_n]^{-1} \le E[Y_n^{-1}] \le C_2 E[Y_n]^{-1},
$$ for some constant $C$ . In fact the simulations show they both converge as $O(n^{-2k})$ . But how can we prove they have the same rate of convergence?","['statistics', 'rate-of-convergence', 'asymptotics', 'convergence-divergence', 'probability-theory']"
4096603,How do I change the order of integration for this parabolic wedge triple integral?,"The question at hand asked me to change the order of the triple integral $$\int_{-1}^{1}\int_{x^{2}}^{1}\int_{0}^{y} f(x,y,z)dz dy dx$$ to $dy dz dx$ . It seemed straight forward at first, seeing that y is bounded by $y=z$ and $y=1$ , and my region in the x-z plane would look like this: But this region seems to say that z is bound by $z=0$ and $z=1$ , and x bound by $x=-1$ and $x=1$ . But putting those as my bounds would just express a rectangular block cut in half and not the solid. I suppose my initial assumption of y being bound by $y=z$ and $y=1$ doesn't allow me to take into the account the $y=x^{2}$ also binding it. How should I approach this?","['integration', 'calculus']"
4096659,"Quadratic form, from independence to normality","Suppose we have a $k$ -dimensional random variable $x$ , and for any given idempotent matrix $A$ , $x'Ax$ and $x'(I-A)x$ are independent to each other. Is $x$ normally distributed? Far as I know, for $2$ -dimensional $x$ and idempotent and symmetric $A$ , once $Ax$ is always independent to $(I-A)x$ , $x$ must have the $2$ -dimensional normal distribution. And I think it's also true for higher dimensions. I know the fact that an idempotent matrix can always be diagonalized by an orthogonal matrix to a diagonalized matrix with eigenvalues $0,1$ . But I know little about the quadratic form. Thanks in advance.","['independence', 'normal-distribution', 'linear-algebra', 'probability-theory', 'quadratic-forms']"
4096677,Finding the units of $\mathbb{Z}\left[\frac{1+\sqrt{-19}}{2}\right]$,"I was trying to comprehend a simple exercise from my elementary number theory class. Let $\theta=\frac{1+\sqrt{-19}}{2}$ , and let $R$ be the ring $\mathbb{Z}[\theta] .$ Show that the units of $R$ are $\pm 1$ , and that 2,3, and $\theta$ are irreducible in $\mathbb{Z}[\theta]$ . The official solution:
If $z=a+b \theta$ is a unit of $\mathbb{Z}[\theta]$ then $z \bar{z}=1$ , so we have $a^{2}+a b+5 b^{2}=1$ from which we conclude $a=\pm 1$ , so the units are $\pm 1$ . If $z=a+b \theta$ is a nonunit, non-associate divisor of 2 then $z \bar{z}=2$ , but there are no solutions to $a^{2}+a b+5 b^{2}=2$ . The arguments for 3 and $\theta$ are similar. This solution is much too concise for me. Firstly, why does $z=a+b \theta$ being a unit of $\mathbb{Z}[\theta]$ imply $z \bar{z}=1$ ? At this point in time, the norm for $\mathbb{Z}[\theta]$ has not been defined, so cannot be used. I was hypothesizing that for $z_1,z_2 \in \mathbb{Z}[\theta]$ , $z_1 z_2 \in \mathbb{Z}$ implied (by comparing imaginary parts) that $z_1 = \lambda \overline{z_2}$ for some $\lambda \in \mathbb{Q}$ , but this also is not easy to prove. I even failed to brute force this, I couldn't continue the calculation. Why does $z=a+b \theta$ being a nonunit, non-associate divisor of 2 imply that $z \bar{z}=2$ ? Any partial answers (answering only one of the questions) are very welcome! I will upvote them too. If the above problem has other solutions, not necessarily following the same reasoning as the official solution, then those are also very welcome!","['number-theory', 'proof-explanation', 'euclidean-domain', 'quadratic-integer-rings', 'abstract-algebra']"
4096701,A calculus problem on the poisson equation,"Let $u(x, y)$ be a function that equals its Laplacian ( $u \equiv \Delta u$ ) on the unit disk $\mathbb{D}$ ( $x^2 + y^2 \leq 1$ ) and $u \mid_{\partial \mathbb{D}} \equiv 0$ ( $\partial \mathbb{D}$ is the circle $x^2 + y^2 = 1$ ). Please prove that $u \equiv 0$ on $\mathbb{D}$ . Note: This problem is taken from the Ph. D. qualification test of Peking University, 2019. My failed attempts: Construct a function $f$ related to $u$ such that $\Delta f = 0$ , and apply the Maximum Principle of harmonic functions. Consider the integral $F(r) = \int_0^{2\pi} u(x + r\cos\theta, y + r\sin\theta) \, d\theta$ and get $rF(r) = rF''(r) + F'(r)$ but fail to continue. Consider the Fourier transform of $u$ . This problem might be easy for the scholars who have a profound expertise in functional analysis and PDE (However, I do not). Would you please offer several hints or point out the insights behind this problem? 50 reputation will be awarded if you can prove the case where $u \in C^\infty(\mathbb{R}^2)$ . I will keep my promise like How to calculate the Fourier transform of the Kaiser-Bessel window? .","['calculus', 'partial-differential-equations', 'functional-analysis', 'real-analysis']"
4096726,Classification of $\operatorname{spin}^c$ structures,"I'm reading the notes about Seiberg-Witten invariants by Salomon (see https://people.math.ethz.ch/~salamon/PREPRINTS/witsei.pdf ). In Theorem 5.5 he gives an interesting classification of $\operatorname{spin}^c$ structures in terms of the characteristic line bundle associated to the structure. A consequence of this is that all the information about the $\operatorname{spin}^c$ structure can be recover from its characteristic line bundle iff there is no 2-torsion in the second integral cohomology group. However, in Exercise 5.9 he asks to prove that two $\operatorname{spin}^c$ structures are isomorphic iff the two characteristic line bundles are isomorphic.
This seems to be in contradiction with the previous statement about the torsion because if there is a 2-torsion element in the second cohomology group then it is possible to create non isomorphic $\operatorname{spin}^c$ structures (using the twisted $\operatorname{spin}^c$ structure associated to the torsion element) with isomorphic characteristic line bundles. What am I missing?","['gauge-theory', 'spin-geometry', 'differential-geometry']"
4096769,"$AB=BA$ from $e^{A+B} = e^A e^B$, given Hermitian matrices","Let $A$ and $B$ be Hermitian matrices. If $AB=BA$ , we know that $e^{A+B} = e^A e^B$ . In this paper , the author showed that $\text{Tr } e^{A+B} = \text{Tr } e^A e^B$ iff. $AB=BA$ . As such, $e^{A+B} = e^A e^B$ is equivalent to $\text{Tr } e^{A+B} = \text{Tr } e^A e^B$ in the context of Hermitian matrices. My question is how we can derive the commutation relation between $A$ and $B$ directly from $e^{A+B}=e^A e^B$ without bringing in the Golden-Thompson inequality (as in the paper I linked). Since the condition $e^{A+B} = e^A e^B$ has a simpler form than that involving the trace, I think there should be some way. Edit: rephrase the question","['matrices', 'trace']"
4096772,"Continuous map between topological spaces, with two local homeomorphisms is a local homeomorphism","Let $X,Y,Z$ be topological spaces. Let $f:X\rightarrow Y$ be a contionuous map. I also have two local homeomorphisms $p:X\rightarrow Z$ and $q:Y\rightarrow Z$ . Such that these functions form a commutative diagram. I need help to show that $f$ is also a local homeomorphism... I tried to show it by taking an elemet $y\in Y$ and an open neighbourhood of $y$ named $U$ such that $U$ is homeomorphic to $q(U)$ and taking the inverse image of $U$ by $f$ ..... I have no idea what to do with this...",['general-topology']
4096804,What is the partial differential symbol (bent lowercase $d$) with an $x$ at the top?,"From a government website on global warming: $PT = LT / (1 - s)$ , where the sensitivity coefficient $s = Ã°ln(LT) / Ã°ln(B)$ and $B =$ burden. I have seen this before, yet there is never an explanation as to what it means.....","['calculus', 'derivatives', 'computational-science', 'partial-differential-equations']"
4096812,Topology axioms in terms of net convergence,"I am looking for the list of axioms of ""net convergence"" in the language of nets which correspond to the axioms of a topology. (Notice that neither Wikipedia nor nlab seem  to answer this question.) Specifically: Let $X$ be a set. A net in $X$ is defined as a function $P \to X$ from a directed partial order $P$ to $X$ . Let $\to$ be a relation from nets in $X$ to elements of $X$ , thought of as net convergence. Now let us call $A \subseteq X$ closed if it is closed under net convergence: $$(x_p)_{p\in P} \to x ~ \wedge~ \forall p \in P (x_p \in A) \implies x \in A.$$ Question. What are axioms for $\to$ which guarantee that this is a topology on $X$ such that the notion of net convergence from the topology is exaclty $\to$ ? If I am not mistaken, we just need that $\to$ is compatible with subnets: A subnet of $P \to X$ is a composition $Q \to P \to X$ for some cofinal map of partial orders $Q \to P$ . We need to require that if a net converges to some element, then every subnet convergences to that element as well. Then all the axioms of a topology are satisfied: $\emptyset$ is closed since there is no net with values in $\emptyset$ (remember that directed sets are non-empty by definition). The intersection of closed subsets is closed for trivial reasons. Now if $ A,B$ are closed and a net $(x_p)_{p \in P}$ with entries in $A \cup B$ converges to some element $x \in X \setminus A$ , then it has a subnet with entries in $B$ , thus $x \in B$ . This means that we just need one axiom, which is a bit weird. What I am missing? In particular, I don't see directly how to deduce that a constant net $(x)_{p \in P}$ converges to $x$ . I would appreciate references to the literature. It seems to be a very basic question. But when I look for these kind of characterizations, the texts seem to focus on filters instead. Answer. The question is answered by Theorem 9 on p. 74 in Kelley's book General topology . Thanks Chris Custer for pointing this out.","['general-topology', 'nets', 'reference-request']"
4096846,When is an algebraic endomorphism a (Hamiltonian) symplectomorphism?,"Let $X$ be a smooth, projective complex algebraic variety. Then the analytification of $X$ is a symplectic manifold, where the symplectic form is given by the restriction of Fubini-Study. Then every endomorphism of $X$ as a complex varity gives an endomorphism of $X$ as complex manifold. Not every algebraic morphism of $X$ is a symplectomorphism. My question is if there is some ""algebraic"" property ensureing that the induced morphism is a symplectomorphism? Similarly, is there an ""algebraic"" property telling us when an endomorphism induces a Hamiltonian symplectomorphism? My hope would be that if I take a finite order automorphism, that it might satisfy these properties. Apologies for the stupid question.","['algebraic-geometry', 'symplectic-geometry', 'differential-geometry']"
4096848,A first order ordinary differential equation,"Below is a problem I did. However, it did not match the back of the book. I would like to know where I went wrong. Problem: Solve the following differential equation. $$ y' = \frac{y-x}{x} $$ Answer: \begin{align*}
\frac{dy}{dx} &= \dfrac{y}{x} - \dfrac{x}{x} =  \dfrac{y}{x} - 1 \\
y &= xv \\
\dfrac{dy}{dx} &= x \dfrac{dv}{dx} + v \\
x \dfrac{dv}{dx} + v &= v - 1 \\
x \dfrac{dv}{dx} &= - 1 \\
dv &= - \dfrac{dx}{x} \\
v &= -\ln x + c \\
\dfrac{y}{x} &= -\ln{|x|} + c \\
y &= -x \ln {|x|} + cx
\end{align*} The book's answer is: $$ y = x \ln{|\frac{k}{x}|} $$ Where did I go wrong?",['ordinary-differential-equations']
4096861,"Finding recurrence relation that contain and do not contain $122$ in the alphabet of $(0,1,2,3,4)$","Lets consider the $n-$ strings over the alphabet $\color{purple}{\{0,1,2,3,4\}}$ that $\color{blue}{a-)}$ do not contain the substring $\color{green}{122}$ such that $1334211112$ is allowed but $..44311 $$\color{red}{122}$ $344..$ is not allowed. $\color{blue}{b-)}$ contain the substring $\color{green}{122}$ I am trying to find the recurrence relation of $n$ strings that satisfies the desired conditions respectively.I found recurrence relations but i am not sure whether they are true or not . $\color{BROWN}{SOLUTION:}$ $\color{blue}{a-)}$ We know that this $n$ lenght strings will end up with either $0$ or $1$ or $2$ or $3$ or $4$ . Lets say that the  string ends  with $0$ and does not contain $122$ , so there are $a_{n-1}$ such strings. Lets say that the  string ends  with $1$ and does not contain $122$ , so there are $a_{n-1}$ such strings. Lets say that the  string ends  with $2$ and does not contain $122$ , so there are $a_{n-1}$ such strings. Lets say that the  string ends  with $3$ and does not contain $122$ , so there are $a_{n-1}$ such strings. Lets say that the  string ends  with $4$ and does not contain $122$ , so there are $a_{n-1}$ such strings. So, there are $5a_{n-1}$ such strings that do not contain $122$ , but let us think about the string which end with $2$ and do not contain $122$ . It has $a_{n-1}$ string that do not have $122$ , but this $a_{n-1}$ string might end with $12$ . Because of this, we must subtract the sequence which end up with $2$ and have a substring with lengh $n-1$ but end with $12$ . Hence , the solution is $a_n=5a_{n-1}-a_{n-3}$ $\color{blue}{b-)}$ We know that this $n$ lenght strings will end up with either $0$ or $1$ or $2$ or $3$ or $4$ . Lets say that the  string ends  with $0$ and  contains $122$ , so there are $a_{n-1}$ such strings. Lets say that the  string ends  with $1$ and  contains $122$ , so there are $a_{n-1}$ such strings. Lets say that the string ends  with $02$ and  contains $122$ , so there are $a_{n-2}$ such strings. Lets say that the  string ends  with $12$ and  contains $122$ , so there are $a_{n-2}$ such strings. Lets say that the  string ends  with $022$ and  contains $122$ , so there are $a_{n-3}$ such strings. Lets say that the  string ends  with $122$ , so there are $5^{n-3}$ such strings. Lets say that the  string ends  with $322$ and  contains $122$ , so there are $a_{n-3}$ such strings. Lets say that the  string ends  with $422$ and  contains $122$ , so there are $a_{n-3}$ such strings. Lets say that the  string ends  with $32$ and  contains $122$ , so there are $a_{n-2}$ such strings. Lets say that the string ends  with $42$ and  contains $122$ , so there are $a_{n-2}$ such strings. Lets say that the string ends  with $3$ contains $122$ , so there are $a_{n-1}$ such strings. Lets say that the  string ends  with $4$ contains $122$ , so there are $a_{n-1}$ such strings. $\therefore a_n=4a_{n-1}+4a_{n-2}+3a_{n-3}+5^{n-3}$ Is my solution correct ? Moreover , if you know another approach to this solution , can you share your knowledge with me ? What's more , do you know any book or website to find these types of exercises to improve myself ?","['book-recommendation', 'recurrence-relations', 'solution-verification', 'combinatorics', 'discrete-mathematics']"
4096869,How many quadratic functions mod 12 have exactly two roots?,"There was a challenge question in this Socratica video and [EDIT: I misunderstood the question and] boy is it giving me a headache! I thought the question was: How many $(a,b,c)$ triples in $\Bbb Z_{12}$ satisfy $|r|=2$ where $r$ is the largest subset of $\Bbb Z_{12} : \forall x \in r, a x^2 + b x + c \equiv 0\pmod {12}$ Even solving this for mod 4 has proved too challenging for me! For example, I tried to construct all the unique $(dx+e)(mx+n)$ pairs that would generate two roots, and I found to my horror that not only do some pairs have more than two roots, but some (such as $\left(3x+2\right)^2$ ) aren't even unique! Avoiding over-counting seems quite tricky... So, what am I missing? How can you cleanly generate these quadratics? Thank you ðŸ™‚","['polynomial-congruences', 'group-theory', 'modular-arithmetic', 'integral-domain']"
4096870,Differentiation to get $F'(0)$,"I have $$f(x)=\begin{cases} 
      \sin\left(\frac{1}{x}\right) &\text{ if } x\neq 0, \\
      0 & \text{ if }x=0. 
   \end{cases}$$ and define $F(x)=\int_0^x f(t) dt$ . I want to show that $F'(0)=f(0)$ . My idea is $$F'(0)=\lim_{h\to 0}\frac{F(h)-F(0)}{h}=\lim_{h\to 0}\frac{\int_0^h \sin\left(\frac{1}{x}\right) dx}{h}$$ and using a change of variables $t=\frac{1}{x}$ we have $$F'(0)=\lim_{h\to 0}\frac{\int_{\frac{1}{h}}^\infty\frac{\sin t}{t^2} dt}{h}.$$ I am not sure how to get this equal to $0$ now? Any help would be much appreciated.","['calculus', 'derivatives', 'analysis', 'real-analysis']"
4096890,General formula for the sum of $k$-products,"I try to obtain a formula for the sum $$\sum_{1\le i_1 < i_2 < \dots < i_k \le n} i_1 i_2 \dots i_k$$ with $1\le k \le n$ . The case $k=2$ is asked here . Following the hint there, I expand $(1+2+\dots+n)^2$ and using the formula for $\sum_{i=1}^{n} i^2$ I was able to get the formula. For the case $k=3$ , I expanded $(1+2+\dots+n)^3$ and by adding some terms I obtained a formula -which took a lot more time than the latter case-. However, I wonder how can I obtain a general formula?","['number-theory', 'elementary-number-theory', 'binomial-coefficients', 'symmetric-polynomials', 'discrete-mathematics']"
4096903,Combinatorial Summation,"I'm trying to solve the following question: If $s_n$ is the sum of first $n$ natural numbers, then prove that $$2(s_1s_{2n}+s_2s_{2n-1}+\dots+s_ns_{n+1})=\frac{(2n+4)!}{5!(2n-1)!}$$ This is where I've come so far: The general term of $(1-x)^{-2n}$ happens to be $t_{r+1}=\frac{(2n+r-1)!}{(2n-1)!r!}x^r$ and therefore the 6th term, i.e, $t_{5+1}=t_6=\frac{(2n+4)!}{(2n-1)!5!}x^5$ , which looks like the RHS of the question I'm trying to solve. Second, I found that $$(1-x)^{-3}=s_1+s_2x+\dots+s_nx^{n-1}+\dots$$ It's clear that the LHS must be something like, $(1-x)^{-a}(1-x)^{-b}$ . But I'm not able to find one such combination which would give me $2(s_1s_{2n}+s_2s_{2n-1}+\dots+s_ns_{n+1})$ . Help is greatly appreciated.","['summation', 'binomial-coefficients', 'combinatorics', 'generating-functions', 'binomial-theorem']"
4096962,Factoring a polynomial in $\mathbb Q[t][x]$ over an extension of $\mathbb Q[t]$,"I have found the following unit-distance embedding of the cubic symmetric graph $F_{42}A$ with $D_7$ symmetry. (Gerbracht's embedding on the MathWorld page for cubic symmetric graphs is only of $C_7$ symmetry; for embeddings of other cubic symmetric graphs see my Shibuya repository.) Let the blue vertex above have coordinates $(a,\frac12)$ , which with $D_7$ symmetry determines the rest of the graph. $a$ must satisfy the following sextic over $\mathbb Q[t]$ : $$256 a^{6} + a^{5} \left(16 t^{5} - 320 t^{3} + 304 t\right) + a^{4} \left(- 16 t^{2} - 144\right) + a^{3} \left(- 32 t^{5} + 656 t^{3} - 912 t\right) + a^{2} \left(- 4 t^{4} + 112 t^{2} - 188\right) + a \left(7 t^{5} - 136 t^{3} + 57 t\right) - t^{4} + 13 t^{2} + 14=0\tag1$$ where $t=\tan\frac\pi7$ . This suggests that there should be six algebraically related $D_7$ embeddings, but the above polynomial has only two real roots, leading to two embeddings: the one above and the one below. In the spirit of what I did at the end of this other answer , I want to see whether I can factor $(1)$ further to obtain a quadratic whose roots are the two real solutions for $a$ ( $a=0.27455\dots$ in the first picture and $a=1.24353\dots$ in the second). Normally I would use GAP's DecomPoly for this, but it only accepts polynomials over $\mathbb Q$ and not any extension of it, and certainly feeding it the degree- $36$ polynomial that $a$ satisfies over $\mathbb Q$ * would take too long. How can I find or show non-existence of a factorisation of $(1)$ over an extension of $\mathbb Q[t]$ in a reasonable amount of time? * $_{68719476736 a^{36} - 532575944704 a^{34} + 1975684956160 a^{32} - 4512936886272 a^{30} + 7013413158912 a^{28} - 8394446471168 a^{26} + 8723128909824 a^{24} - 7969139851264 a^{22} + 6247085506560 a^{20} - 4187786313728 a^{18} + 2514551767040 a^{16} - 1412168695808 a^{14} + 697307058176 a^{12} - 259585758208 a^{10} + 65704151296 a^{8} - 10689048384 a^{6} + 1029214816 a^{4} - 48560176 a^{2} + 790321}$","['gap', 'graph-theory', 'geometry', 'galois-theory', 'factoring']"
4096986,"$\int_0^\infty \log\left(1 - \frac{x}{\sinh x}\right)\,dx$ and generalisations","I'm interested in the value of $$
\theta(2) := -\frac{1}{2\pi^2}\int_0^\infty \log\left(1 - \frac{x}{\sinh x}\right)\,dx.
$$ I have some hopes this admits a closed-form solution. Expanding the logarithm yields the integral $I_n := \int_0^\infty(\frac{x}{\sinh x})^n\,dx$ , which has recently been asked about here on math.sa . More generally, I'd love to know a closed-form solution for $$\theta(\ell) := -\frac{1}{2\pi}\int_0^\infty \log\left(1 - \left\lvert \frac{\Gamma(\frac{\ell}{2}+ix)}{\Gamma(\frac{\ell}{2})}\right\rvert^2\right)\,dx$$ with $\ell\in\mathbb{N}$ . For $\ell=2$ this is the same integral as above; see below for details. The integral $\theta(\ell)$ has some relation to the eigenvalues of truncated random orthogonal matrices; see this paper , especially equationÂ (7.1). Some partial results below. For $\ell=1$ , the integral $\theta(1)$ is solvable by expanding the $\log$ and its value is $$\theta(1) = \frac{3}{16}.$$ Note that for $b\in\mathbb{R}$ , $$
\left|\Gamma\left(\tfrac{1}{2}+bi\right)\right|^2  = \frac{\pi}{\cosh \pi b}
\qquad\text{and}\qquad
\left|\Gamma\left(1+bi\right)\right|^2 = \frac{\pi b}{\sinh \pi b},
$$ or more generally for $n\in\mathbb{N}$ , $$\begin{align}
\left|\Gamma\left(1+n+bi\right)\right|^2 & = \frac{\pi b}{\sinh \pi b} \prod_{k=1}^n \left(k^2 + b^2 \right)\\
\left|\Gamma\left(\tfrac{1}{2} + n+bi\right)\right|^2 & = \frac{\pi}{\cosh \pi b} \prod_{k=1}^n \left(\left( k-\tfrac{1}{2}\right)^2 + b^2 \right)
\end{align}$$ (for a derivation, see Wikipedia ). Hence, when expanding the $\log$ the integral turns into the sum of the integral of powers of $\frac{1}{\sinh}$ and $\frac{1}{\cosh}$ times a polynomial. For instance for $\ell=2$ , one has $$2\pi^2\theta(2) = \sum_{n=1}^\infty\frac{1}{n}\int_0^\infty \Bigl(\frac{x}{\sinh x}\Bigr)^n\,dx.$$ The integral $I_n := \int_0^\infty(\frac{x}{\sinh x})^n\,dx$ has recently been asked about here on math.sa . The answers prove a recurrence relation and indicate that $I_n$ is a linear combination of $\zeta(2), \zeta(4), \ldots, \zeta(2âŒˆn/2âŒ‰)$ over $\mathbb{Q}$ , where the coefficients are the ""central factorial numbers"", see this answer . (The central factorial numbers (OEIS A008955 and A008956 ) turn out to also show up in the power series expansion of $x\mapsto(\frac{x}{\sinh x})^n$ , $x\mapsto(\arcsin x)^n$ and powers of various other trigonometric functions; see this paper for a thorough treatment.) I'd be interested to know if $\sum_{n=1}^\infty\frac{1}{n}I_n$ admits a more succinct representation. For larger values of $\ell$ , the expansion produces terms of the form $\int_0^\infty x^n(\frac{1}{\sinh x})^m \, dx$ and $\int_0^\infty x^n(\frac{1}{\cosh x})^m \, dx$ . In the question mentioned before , user Quanto has given a recurrence relation for such integrals. The polynomials in question make it likely central factorial numbers play a role in the linear combinations there too.","['integration', 'definite-integrals', 'hyperbolic-functions', 'gamma-function', 'sequences-and-series']"
4096988,Can all triangles containing integer angles (in degrees) be solved by synthetic solutions (elementary geometry)?,"I had recently asked a question about a conjecture in a triangle , and it led me to another question. In the non-equilateral triangle below, $CD, AD$ , and $BD$ concur at point $D$ . The angles $(a, b, c, d, e,$ and $f)$ in degrees are also
placed as given in the figure below. Define a solvable triangle such that:  For a triangle like the
one in the figure above, given two pairs of adjacent angles (say $a,b$ and $c,d$ ), if the
remaining two angles (say $e,f$ ) can be found by a synthetic solution using elementary geometry, it is
a solvable triangle. (Just to be clear, I have added an example at the end.) My questions are : Are all triangles containing integer angled sextuplets solvable triangles? What is the criterion for being a solvable triangle? Such a sextuplet must satisfy the Trigonometric Ceva's Theorem: $$\frac{\sin(a\cdot\frac{\pi}{180})}{\sin(b\cdot\frac{\pi}{180})}\cdot\frac{\sin(c\cdot\frac{\pi}{180})}{\sin(d\cdot\frac{\pi}{180})}\cdot\frac{\sin(e\cdot\frac{\pi}{180})}{\sin(f\cdot\frac{\pi}{180})}= 1$$ We also know that, $$a+b+c+d+e+f=180Â°$$ In the comments of their accepted answer to my previous question, @user provided a sextuplet $\frac\pi{180}\{1,30,87,2,29,31\}$ with different integers to work on -I am also sure that there more such sextuplets which consist of different integers. Here is an example problem using this sextuplet (there are more such triangles that can be formed with this sextuplet): Let $\measuredangle ACD=31Â°$ , $\measuredangle BCD=30Â°$ , $\measuredangle CAD=1Â°$ , $\measuredangle BAD=2Â°$ in $\bigtriangleup
ABC$ . Find $\color{green}{\text {$\measuredangle ABD$}}$ . Example Synthetic Solution: Since the angles are extremely small, I have reproduced the diagram by rescaling the angles (blue line segments represent the original problem and red line segments represent my constructions). Letâ€™s select a point $E$ on $AD$ such that $AE=CE$ and connect $E$ and $C$ , so $\measuredangle ECA=1Â°$ . Letâ€™s extend $BC$ and select a point $F$ on $BC$ such that $CE=CF$ , constructing the equilateral triangle $\bigtriangleup CEF$ . Angle chasing leads us to: $$\measuredangle DEC=2Â° \; \text{and} \; \measuredangle DEF=58Â°$$ Letâ€™s connect points $F$ and $D$ . Since $CD$ is the angle bisector of the equilateral triangle $\bigtriangleup CEF$ , using congruency: $$\measuredangle DFB=2Â° \; \text{and} \; \measuredangle DFE=58Â°$$ Since $\bigtriangleup AEF$ is isosceles, $\measuredangle AFE=29Â°$ . Since $\measuredangle DFB=\measuredangle BAD=2Â°$ , $AFBD$ is a cyclic quadrilateral, which allows us to conclude that: $$\color{green}{\text {$\measuredangle AFD=\measuredangle ABD=87Â°$}}$$ I think the $30Â°$ angle is the critical angle that allowed this solution. $\\$ The synthetic solution seems to be difficult when $a, b, c, d, e,$ and $f$ are all different integers . I am not very sure what the appropriate tags are for this question. Thanks in advance.","['euclidean-geometry', 'triangles', 'geometry', 'plane-geometry']"
4096995,Meaning of integral identity containing cross product with the area differential,"Edit: I just noticed that the exercise itself was asked here. However I'm not asking for a proof, but about the meaning/intuition behind the notation / exercise itself. On a Multivariable Calculus problem sheet I was asked to prove the following integral identity: Problem . Let $f$ be a smooth scalar field defined on a region $R \subseteq \mathbb{R^3}$ with a smooth boundary $\partial R$ . Show that $$\iint_{\partial R} f \mathbf{r} \wedge \text{d} \mathbf{S} = \iiint_R \mathbf{r} \wedge \nabla f \, \text{d}V$$ I did manage to solve the problem by using the fact that d $\mathbf{S}$ = $\mathbf{n}$ dS, where $\mathbf{n}$ is the outward-pointing normal to $\partial R$ at $\mathbf{r}$ and by applying the divergence theorem on a well-chosen vector field (I won't go into details in case this problem appears on a problem sheet in the future.) I have two questions about this problem: 1) Is there some sort of meaning behind taking a cross product with the area differential, or is it in this case just a shorthand notation for $\mathbf{r} \wedge \mathbf{n}$ dS? I was very confused when I first saw it, and it seems like it's not really necessary, but why would they choose this notation if it doesn't really mean anything special? 2) Is there any kind of (perhaps physical or otherwise) interpretation of this integral identity, or is it just the result of some arbitrary calculation? I can't wrap my head around what it's supposed to mean...","['divergence-theorem', 'multivariable-calculus', 'derivatives']"
4096999,"Counterexample to ""kernel determines image""","Working over a base field, there is a typical homomorphism theorem for affine algebraic groups ensuring that any two homomporphisms $G \to H_1$ , $G \to H_2$ with the same kernel in $G$ have isomorphic images. Proving this makes heavily use of the nontrivial fact that injective homomorphisms between Hopf algebras over fields are faithfully flat. Working over general base rings (which are not fields), it is easy to find non-faithfully flat injective Hopf algebra homomorphisms: For example over the base ring of integers, $\mathbb{Z}[X] \to \mathbb{Z}[X]$ sending $X$ to $nX$ for any $n \not\in \{0,1,-1\}$ is not faithfully flat. (It corresponds to the multiplication-by- $n$ -homomorphism $\mathbb{G}_a \to \mathbb{G}_a$ .) I suspect the above statement fails in this general setting, but I cound not find any counterexample so far. Question 1: Are there homomorphisms $f_1 \colon G \to H_1$ , $f_2 \colon G \to H_2$ of affine algebraic groups with the same kernel such that $\mathrm{Im}(f_1)$ is not isomorphic to $\mathrm{Im}(f_2)$ ? More specifically: Question 2: Is there an injective homomorphism $f \colon G \to H$ of affine algebraic groups such that $\mathrm{Im}(f)$ is not isomorphic to $G$ ? Edit 1 Here is an attempt to find a counterexample to question 2. My idea is to adapt known homomorphisms of algebraic groups which can be defined over general base rings but show different behavior after base extensions to fields of different characteristics. For any base ring $R$ there is the circle group $C$ defined for any $R$ -algebra $A$ by $$ C(A) = \{ (x,y) \in A^2 : x^2+y^2 = 1 \}. $$ The identity element is $(1,0)$ , and the group operations are given by $$ (x_1,y_1) \cdot (x_2,y_2) = (x_1x_2 - y_1y_2, x_1y_2+ x_2y_1), \text{ and } (x,y)^{-1} = (x,-y). $$ If $R$ has an element $i \in R$ with $i^2 = -1$ , there is a homomorphism $$ \varphi \colon C \to \mathbb{G}_m, \quad (x,y) \mapsto x+iy.$$ This morphism is quite exiting: If $2$ is invertible in $R$ then $\varphi$ is already an isomorphism. If $2$ not not invertible however, then $\varphi$ is not injective, and we can extend $R$ to a field of characteristics 2, where $\varphi$ is neither injective nor surjective (it maps onto $\mu_2$ then). This example can be found in [Waterhouse, Introduction to affine group schemes, chapter 1, exercise 11]. Since $\varphi$ has nontrivial kernel, it cannot be a counterexample to (2). So let's add an additional equation: Let $C'$ be the subgroup of the circle group given by $$ C'(A) = \{ (x,y) \in A^2 : x^2+y^2=1, 3y=0 \}. $$ Now the restriction of $\varphi$ to $C'$ has trivial kernel, but it is not surjective anymore - we have to add at least one additional equation $3t^2=3$ to $\mathbb{G}_m$ . That is, $\varphi$ induces a homomorphism of algebraic subgroups $$ \{ (x,y) : x^2+y^2=1, 3y = 0 \} \to \{ t : t \text{ invertible}, 3t^2=3 \}. $$ I think this might be a counterexample to (2) since it becomes an isomorphism after extending the base ring to any field, but I cannot see how it should be an isomorphism over (say) the Gaussian integers $R = \mathbb{Z}[i]$ . However, I also cannot see at the moment why it should be (scheme-theoretically) surjective. To restate the question in terms of Hopf algebras: There is a homomorphism $$ (\mathbb{Z}[i])[T,T^{-1}]/(3(T^2-1)) \to (\mathbb{Z}[i])[X,Y]/(X^2+Y^2-1, 3Y), \quad T \mapsto X+iY. $$ Is this morphism injective but not surjective? (Of course (2) asks for a little bit more: Is the left hand side not ismomorphic to the right hand side?) Edit 2 Unfortunately, this specific morphism is already an isomorphism which can be easily seen by condiering the localizations of $\mathbb{Z}[i]$ at all primes $\mathfrak{p}$ . For all primes with $3 \notin \mathfrak{p}$ it is quite obvious that the morphism is basically the same as the identity map $\mu_2 \to \mu_2$ , since $3$ is invertible in $\mathbb{Z}[i]_\mathfrak{p}$ . On the other hand, if $3 \in \mathfrak{p}$ then $2$ is invertible in $\mathbb{Z}[i]_\mathfrak{p}$ . In this case, $\varphi \colon C \to \mathbb{G}_m$ is an isomorphism, and it can be easily checked that its inverse maps $\{ t : t \text{ invertible }, 3t^2=3 \}$ to $C'$ . In order to get a counterexample in the way sketched above, we have to choose some other equation (instead of $3y=0$ ) which nontrivially affects the groups over the base ring $\mathbb{Z}[i]_\mathfrak{p}$ for $\mathfrak{p} = (1+i)$ .","['abstract-algebra', 'algebraic-groups', 'hopf-algebras']"
4097001,How can I solve $x\left(y^2+z\right)z_x-y\left(x^2+z\right)z_y=\left(x^2-y^2\right)z$?,"I have this right now: $$x\left(y^2+z\right)z_x-y\left(x^2+z\right)z_y=\left(x^2-y^2\right)z$$ $$\frac{dx}{x\left(y^2+z\right)}=\frac{dy}{-y\left(x^2+z\right)}=\frac{dz}{\left(x^2-y^2\right)z}$$ I get the first first integral like this: $$\frac{xdx}{x^2\left(y^2+z\right)}=\frac{ydy}{-y^2\left(x^2+z\right)}=\frac{-dz}{-\left(x^2-y^2\right)z}$$ $$\frac{d\left(\frac{1}{2}x^2\right)}{x^2y^2+x^2z}=\frac{d\left(\frac{1}{2}y^2\right)}{-y^2x^2-y^2z}=\frac{d\left(-z\right)}{-x^2z+y^2z}$$ $$\frac{d\left(\frac{1}{2}x^2+\frac{1}{2}y^2-z\right)}{0}=ds$$ $$d\left(\frac{1}{2}x^2+\frac{1}{2}y^2-z\right)=0$$ $$\frac{1}{2}x^2+\frac{1}{2}y^2-z=C$$ $$x^2+y^2-2z=C_1$$ $$\Psi _1\left(x,y,z\right)=x^2+y^2-2z$$ But I am not sure how to get the second first integral I tried using $z=\frac{1}{2}x^2+\frac{1}{2}y^2-C$ when doing: $$\frac{dx-dy}{x\left(y^2+z\right)+y\left(x^2+z\right)}=\frac{dz}{\left(x^2-y^2\right)z}$$ $$\frac{d\left(x-y\right)}{\frac{1}{2}\left(x+y\right)^3-C\left(x+y\right)}=\frac{dz}{\left(x+y\right)\left(x-y\right)z}$$ $$\frac{2d\left(x-y\right)}{\left(x+y\right)^2-2C}=\frac{dz}{\left(x-y\right)z}$$ $$\frac{2\left(x-y\right)d\left(x-y\right)}{\left(x+y\right)^2-2C}=\frac{dz}{z}$$ Let $w=\left(x-y\right)$ and $C=\frac{1}{2}x^2+\frac{1}{2}y^2-z$ , then: $$\frac{2w\:dw}{4z-w^2}=\frac{dz}{z}$$ Then we do for $v=w^2$ : $$\frac{\:dv}{4z-v}=\frac{dz}{z}$$ Which we then solve: $$\frac{\:dv}{dz}=4-\frac{v}{z}$$ Using $p=\frac{v}{z}$ we get: $$p+p'z=4-p$$ $$-\frac{1}{2}\frac{dp}{p-2}=\frac{dz}{z}$$ Integrating: $$-\frac{1}{2}ln\left|p-2\right|+C_2=ln\left|z\right|$$ $$ln\left|\frac{1}{p+2}\right|+C_2=ln\left|z^2\right|$$ $$\frac{C_2}{p+2}=z^2$$ $$C_2=z^2\left(\left(x-y\right)^2+2\right)$$ Is there an easier way to calculate the second first integral? I don't see any mistake in my calculations but still it's very very long","['ordinary-differential-equations', 'partial-differential-equations']"
4097019,Hardy's inequality with power weights,"we have that $$\hspace{20mm}\int_{0}^{\infty} \left( \frac{1}{x}\int_{0}^{x} f(t) dx \right)^{p} x^{\alpha} dx \leq \left( \frac{p}{p-\alpha-1} \right)^{p} \int_{0}^{\infty} f(x)^{p}x^{\alpha} dx     \hspace{20mm}(1)$$ for $p \geq 1$ and $\alpha<p-1$ $$\hspace{20mm}\int_{0}^{\infty} \left( \frac{1}{x}\int_{x}^{\infty} f(t) dt \right)^{p} x^{\alpha} dx \leq \left( \frac{p}{\alpha+1-p} \right)^{p} \int_{0}^{\infty} f(x)^{p}x^{\alpha} dx     \hspace{20mm}(2)$$ for $p \geq 1$ and $\alpha>p-1$ Conditions for $p \geq 1$ and $\alpha<p-1$ are essential for (1). Indeed, if I consider the functions $f_{a}(x) = \mathcal{X}_{(a,a+1)}(x)$ with $a>0$ then for $x \geq a+1$ we have $\mathcal{H}f_{a}(x) = \frac{1}{x} \int_{0}^{x} f_{a}(t)dt = \frac{1}{x}$ . let's see the two cases we have, Case $p\geq 1$ y $\alpha \geq p-1$ . $$\int_{0}^{\infty} \left[ \mathcal{H}f_{a}(x) \right]^{p}x^{\alpha} dx = \int_{0}^{\infty}  \frac{1}{x^{p}} x^{\alpha} dx  \geq \int_{a+1}^{\infty} x^{\alpha-p} dx = \left[ \frac{x^{\alpha-p+1}}{\alpha-p+1}\right]_{a+1}^{\infty} = \infty$$ Case $0<p<1$ y $\alpha<p-1$ . We have a) $$\int_{0}^{\infty} \left[ \mathcal{H}f_{a}(x) \right]^{p}x^{\alpha} dx  \geq \int_{a+1}^{\infty} x^{\alpha-p} dx = \left[ \frac{x^{\alpha-p+1}}{\alpha-p+1}\right]_{a+1}^{\infty} = \frac{(a+1)^{\alpha-p+1}}{p-\alpha-1}$$ b) $$\int_{0}^{\infty} f_{a}(x)^{p}x^{\alpha} dx = \int_{0}^{\infty} \left(  \mathcal{X}_{(a,a+1)}(x)\right)^{p}x^{\alpha} dx = \int_{a}^{a+1} x^{\alpha}dx \leq a^{\alpha}$$ so $$\frac{\int_{0}^{\infty} \left[ \mathcal{H}f_{a}(x) \right]^{p}x^{\alpha} dx }{\int_{0}^{\infty} f_{a}(x)^{p}x^{\alpha} dx } \geq \frac{\frac{(a+1)^{\alpha-p+1}}{p-\alpha-1}}{a^{\alpha}} = \frac{1}{p-\alpha-1} \frac{(a+1)^{\alpha-p+1}}{a^{\alpha}} \rightarrow \infty$$ when $a \rightarrow \infty$ Therefore it would be proven. However, for dual inequality (2) I would not know how to do it. Conditions for $p \geq 1$ and $\alpha>p-1$ are essential for (2), if I take the same function I get that for $x<a$ we have $$\frac{1}{x}\int_{x}^{\infty} f_{a}(t) dt = \frac{1}{x}  $$ let's see the thow cases we have, Case $0<p<1$ and $\alpha \geq p-1$ $$\int_{0}^{\infty} \left( \frac{1}{x} \int_{0}^{\infty} f_{a}(t)dx \right)^{p}x^{\alpha}dx \geq \int_{0}^{a} x^{\alpha-p}dx = \frac{a^{\alpha-p+1}}{\alpha-p+1} \rightarrow \infty $$ when $a \rightarrow \infty$ Case $p\geq$ and $\alpha \leq p-1$ . I don't know how I could do this step Thanks you so much.","['integration', 'inequality', 'functional-analysis', 'analysis']"
4097114,The integral: $\int_0^1(e^x)dx$ via Darboux's sums,"Need to calculate the integral: $\int_0^1(e^x)dx$ via Darboux's sums. My attempt: First, we calculate the lower summation: $$L(p,f)=\sum_{i=1}^n m_i\Delta x_i=\sum_{i=1}^n(e^{\frac{i-1}{n}}\cdot\frac{1}{n})=\frac{1}{n}\cdot e^{\frac{n(n-1)}{2n}}=\frac{1}{n}\cdot e^{\frac{n-1}{2}}$$ Second, we calculate the upper summation: $$U(p,f)=\sum_{i=1}^n M_i\Delta x_i=\sum_{i=1}^n(e^{\frac{i}{n}}\cdot\frac{1}{n})=\frac{1}{n}\cdot e^{\frac{n(n+1)}{2n}}=\frac{1}{n}\cdot e^{\frac{n+1}{2}}$$ From the result, it easy to see that both of the limits are $\infty$ . I know that there is a mistake over here, I would appreciate that, if you can enlighten me.","['integration', 'calculus', 'definite-integrals']"
4097144,What are the invariant factors of $G \times G$?,"Let a finite abelian group $G$ have invariant factors $n_1, n_2, . . . , n_k$ . What are
the invariant factors of $G \times G$ ? What I have done: I used as an example the group $G=\mathbb{Z}_3\times\mathbb{Z}_3\times\mathbb{Z}_4 $ whose invariant factors are $3$ and $12$ . Then $G\times G$ has the invariant factors $3, 3, 12$ and $12$ . Can I say that in general the invariant factors of $G\times G$ are just a combination of them? (That is, If $G$ have invariant factors $n_1, n_2, . . . , n_k$ , then the invariant factors of $G\times G$ are $n_1, n_1, n_2, n_2, . . . , n_k,n_k$ )","['direct-product', 'finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
4097212,Are there some properties of multivariate polynomials which I can use to estimate areas where they will be $=0$ or $\leq 0$?,"I am revisiting algebraic curves as level sets (equations) or as watersheds (inequations) for geometric and computer graphics purposes. Now, if I am to evaluate every multivariate polynomial for every pixel in a high resolution image, it will require lots of computations. Do there exist any theoretical results which I can use to create something of a bounding box which I will not need to perform calculations outside of? In other words, can I find a square or a circle where I can decide that outside of this there will be no values $=0$ or $\leq 0$ ? for example $$x^4+y^4 - 2^4 = 0$$ will be a shape limited by a square centered on origo with side $4$ . How can this be verified? We can represent this for example with $$\cases{x>2\\x<-2\\y>2\\y<-2}$$ We can calculate gradient $x: 4x^3, y= 4y^3$ But what then? Gradient only gives local information, doesn't it? Maybe if we consider differential equation with boundary conditions given by the bounding box..? Do there exist tools estimating range of solutions for differential equations with boundary conditions?","['geometry', 'computational-mathematics', 'algebraic-geometry', 'numerical-methods', 'soft-question']"
4097262,Cubic equation with circle intersection to form a square,"A cubic equation and circle (unit radius) has intersection at A,B,C,D. ABCD is a square. Find the angle $\theta$ . I tried: $(0,0)$ is a solution so constant term is $0$ Substituting A(x,y) and C(-x,-y) and adding them gives coefficient of $x^2$ is 0. Then the cubic becomes f(x) = $ax^3+bx$ . 3.Substituting A and B and added the two equations. I found it interesting- for n points given we can find a unique n+1 degree polynomial Also - Can complex number be used here? Please note : I am not sure whether we can find the angle(integer) without knowing the coefficients of the cubic. EDIT : From the answers 1.putting A $(cos\theta,sin\theta)$ in f(x) : $acos^3\theta + b cos\theta = sin\theta$ 2.putting B $(-sin\theta,cos\theta)$ in f'(x) : $asin^2\theta + b  = tan\theta$ [ as circle has $tan\theta$ slope at B] $1,2 $ eqn gives $3asin^2\theta = acos^2\theta$ So, $sin^2\theta = \frac{1}{4}$ But I getting the value of $\theta$ but a answer shows plot of many cubics -> because in my case $ABCD$ is a square.","['polynomials', 'geometry', 'complex-numbers', 'roots']"
4097279,Why are continuous partial derivatives up to order two (rather than one) of nonlinear autonomous (2D) systems sufficient for linear approximation?,"In Boyce and Diprima's ODE's and BVP's (10th edition page 522), it says that for the nonlinear autonomous system $$x^\prime = F(x,y)\qquad y^\prime = G(x,y) \qquad\qquad\qquad (10),$$ ""The system (10) is locally linear in the neighborhood of a critical point $(x_0,y_0)$ whenever the functions $F$ and $G$ have continuous partial derivatives up to order two. To show this , we use Taylor expansions about the point $(x_0,y_0)$ to write $F(x,y)$ and $G(x,y)$ in the form $$F(x,y)=F(x_0,y_0)+F_x(x_0,y_0)(x-x_0)+F_y(x_0,y_0)(y-y_0)+\eta_1(x,y)\\ G(x,y)=G(x_0,y_0)+G_x(x_0,y_0)(x-x_0)+G_y(x_0,y_0)(y-y_0)+\eta_2(x,y)$$ where $\eta_1(x,y)/[(x-x_0)^2+(y-y_0)^2]^{1/2}\to 0$ as $(x,y)\to(x_0,y_0)$ , and similarly for $\eta_2$ ."" Why does it say ""whenever the functions $F$ and $G$ have continuous partial derivatives up to order two"" instead of ""whenever the functions $F$ and $G$ have continuous partial derivatives up to order one""? $\eta_1(x,y)$ and $\eta_2(x,y)$ contain the nonlinear parts and the second order partial derivatives, right?  And, Taylor's Theorem says the function being k times differentiable is sufficient for an approximation by a kth degree Taylor polynomial.","['nonlinear-analysis', 'ordinary-differential-equations', 'nonlinear-system', 'nonlinear-dynamics', 'dynamical-systems']"
4097315,$\mathbf{Top}$ has no small dense subcategory,"Recall that a subcategory $\mathcal{B} \subseteq \mathcal{A}$ is called dense when $\mathcal{A} \to \mathrm{Hom}(\mathcal{B}^{\mathrm{op}},\mathbf{Set})$ , $X \mapsto \mathrm{Hom}(-,X)|_{\mathcal{B}}$ is fully faithful, or equivalently, for every $A \in \mathcal{A}$ we have the coend expression $A = \int^{B \in \mathcal{B}} \mathrm{Hom}(B,A) \otimes B$ . Since I am not able to see a small dense subcategory of $\mathbf{Top}$ , the category of topological spaces and continuous maps, I assume that there is none (in contrast to nice subcategories such as the subcategory of CW-complexes). Why does $\mathbf{Top}$ not have a small dense subcategory? Perhaps one can derive a contradiction why using ordinal numbers (equipped with the order topology)? Another path would be to use that every cocomplete category with a small dense subcategory actually satisfies a very strong adjoint functor theorem: every cocontinuous functor on it is a left adjoint. So it suffices to construct a cocontinuous functor on $\mathbf{Top}$ which is no left adjoint. Maybe we can even prove something stronger? Recall that $\mathcal{B} \subseteq \mathcal{A}$ is colimit-dense when every object $A \in \mathcal{A}$ has a diagram in $\mathcal{B}$ whose colimit in $\mathcal{A}$ is $A$ . Every dense subcategory is colimit-dense, so the following is actually stronger: Why does $\mathbf{Top}$ not have a small colimit-dense subcategory?","['general-topology', 'category-theory']"
4097364,Is every real vector bundle immersed in the tangent bundle of a Manifold?,"For me ""manifold"" = "" $C^\infty$ -manifold"" and also ""vector bundle"" = ""smooth vector bundle"" There's not much context, im learning about Vector Bundles and I wonder if every vector bundle over a manifold can be inmerse in the tangent bundle of a Manifold. Even stronger, let $E$ be a vector bundle over a manifold $M$ with fibers of dimension equal to $dim (M)$ , I would like to know if there is a diffeomorphism $f:M \rightarrow M$ whose push-out $f_* :E \rightarrow T(M)$ is a vector bundle isomorphism. If the answer to the last one is negative, are there some hypothesis over $M$ and/or $E$ to make it true? For example, I've just realised you can take many different vector bundles over $S^1$ not ishomorphic (because they make a different amount of Twists).","['vector-bundles', 'smooth-manifolds', 'differential-geometry']"
4097367,The rank of the Jacobian of an algebraic curve,"Suppose $C \subset \mathbb{A}^n$ is an algebraic curve, with $C = V(I)$ where $I = \langle f_1,...,f_r\rangle\subset \mathbb{C}[x_1,...,x_n]$ is an ideal. Let $J$ be the Jacobian matrix where $J_{i,j} = \frac{\partial f_i}{\partial x_j}$ . Why is it necessarily true that $\operatorname{Rank}(J) \leq n-1$ ? What I know: Since $C$ is an algebraic curve, I know that $I$ is generated by at least $(n-1)$ polynomials, so the maximum possible rank of $J$ is $n$ , which could potentially happen if $I$ is generated by $n$ polynomials and all of the rows of the Jacobian are linearly independent over $\mathbb{C}$ . Therefore, I imagine the goal is to show that this is actually impossible, say by contradicting the fact that $C$ is a curve. What I have tried: I know that one can change the generators of an ideal and will find that the rank of the Jacobian arising from each of these sets of generators will be the same at each point. So I hoped that one could try to find a GrÃ¶bner basis for $I$ which would only have $(n-1)$ generators, making the question trivial. However, I am not very familiar with GrÃ¶bner bases, I only know that in some sense they're ""the best you can do"" when it comes to finding generators for an ideal, so I have not been able to make much progress along this route. A second approach : As mentioned above, taking $I$ and $J_{i,j}$ as previously defined, the greatest possible rank of $J$ is $n$ , we want to show that this is in fact impossible. Suppose for the sake of contradiction that $\operatorname{rank}(J|_p) = n$ at some point $p$ , then there is some $n \times n$ submatrix of $J|_p$ which is of full rank, and is hence invertible. Therefore there is some sequence of row operations which transforms the matrix $J|_p$ into the form $$\begin{pmatrix} 
I_{n\times n}\\
0_{n \times (r-n)}
\end{pmatrix}$$ From here I am unsure how to progress, but I'll present some logic here. The row operations performed on $J$ correspond to similar operations on the generators $f_1,..,f_r$ of $I$ . Being able to bring $J$ into the above form therefore corresponds to being able to map $f_1$ to some function $g_1$ where $\frac{\partial g_1}{\partial x_1}(p) = 1$ while $\frac{\partial g_1}{\partial x_i}(p) = 0$ for $i\neq 1$ and similarly for the other functions. I would like to be able to conclude from this that my new generators give an ideal which define a zero dimensional variety, but I am unsure how to progress from this point. My first intuition is that the restriction above meant that $g_1 = x_1$ , $g_2=x_2$ and so on, but there are numerous counter examples to this claim. Is there a suitable way to proceed from one of the methods outlined here, or am I making this more complicated than it needs to be?","['algebraic-curves', 'jacobian', 'algebraic-geometry']"
4097383,Prove that $\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{F_kF_{k+1}}=\frac{1}{\phi}$.,"In this question, the OP says that $$\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{F_kF_{k+1}}=\frac{1}{\phi}$$ where $F_n$ is the $n$ th Fibonacci number, defined by $F_n=F_{n-1}+F_{n-2}$ , with $F_1=F_2=1$ . I've been trying to prove this, but I haven't had much luck. Below is the work I have done. I'll firstly write out a bunch of terms of the series. $$\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{F_kF_{k+1}}=\frac{1}{F_{1}F_{2}}-\frac{1}{F_{2}F_{3}}+\frac{1}{F_{3}F_{4}}-\frac{1}{F_{4}F_{5}}+\frac{1}{F_{5}F_{6}}-\frac{1}{F_{6}F_{7}}+\cdots$$ It therefore follows that $$\begin{align}\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{F_kF_{k+1}}&=\frac{1}{F_2}\left(\frac{1}{F_1}-\frac{1}{F_3}\right)+\frac{1}{F_4}\left(\frac{1}{F_3}-\frac{1}{F_5}\right)+\cdots\\
&=\frac{1}{F_1F_3}+\frac{1}{F_3F_5}+\cdots\\
&=\sum_{k=1}^{\infty}\frac{1}{F_{2k-1}F_{2k+1}}\tag{1}\end{align}$$ Similarly, $$\begin{align}\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{F_kF_{k+1}}&=\frac{1}{F_1F_2}-\frac{1}{F_3}\left(\frac{1}{F_2}-\frac{1}{F_4}\right)-\frac{1}{F_5}\left(\frac{1}{F_4}-\frac{1}{F_6}\right)-\cdots\\
&=1-\frac{1}{F_2F_4}-\frac{1}{F_4F_6}-\cdots\\
&=1-\sum_{k=1}^{\infty}\frac{1}{F_{2k}F_{2k+2}}\tag{2}\end{align}$$ Unfortunately I haven't had any luck in evaluating these. I did think of using Cassini's identity , which yielded the following when applied to $(1)$ and $(2)$ respectively: $$\begin{align}\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{F_kF_{k+1}}&=\sum_{k=1}^{\infty}\frac{1}{1+F_{2k}^2}\tag{3}\\
&=1-\sum_{k=1}^{\infty}\frac{1}{F_{2k+1}^2-1}\tag{4}\end{align}$$ But once more I could not see a way of evaluating these series either. Usually with summations involving Fibonacci numbers forming a telescoping series is effective, but I couldn't succeed in making this one telescope. Thank you for your help, it is really appreciated. Any possible methods will be a great help.","['summation-method', 'summation', 'fibonacci-numbers', 'telescopic-series', 'sequences-and-series']"
4097410,Finding inertia degree and ramification index over local fields,"I am working with the splitting field $L/\mathbb{Q}_2$ of the polynomial $$
h=x^4-2x^2+4\in\mathbb{Q}_2[x]
$$ and want to find the inertia degree and ramification index of $L$ . Let $w$ be the unique extension of the $p$ -adic valuation to $L$ . Using the discriminant and resolvent cubic, I found that the Galois group of $h$ is the Klein four-group $C_2\times C_2$ , and by considering the Newton polygon, it is $w(\alpha)=1/2$ for any root $\alpha$ of $h$ . This means that the ramification index $e$ is at least $2$ and thus for the inertia degree it is $f\leq 4/e=2$ . Additionally, the inertia group $I$ is nontrivial, because $L/K$ is ramified. There is a canonical isomorphism $G/I\to \mathrm{Gal}\left(\lambda/\mathbb{F}_2\right)$ and hence $$
|G|/|I|=\left|\mathrm{Gal}\left(\lambda/\mathbb{F}_2\right)\right|=\left[\lambda:\mathbb{F}_2\right]=f.
$$ I also know that $\left(|I|/|R|,2\right)=1$ for the ramification group $R\subset I$ and thus $|I|=|R|$ . Here I used that we have an injection $I/R\hookrightarrow \lambda^*$ . Furthermore, because of the injections $G_k/G_{k+1}\hookrightarrow\lambda,~k\geq 1$ the factor groups $G_k/G_{k+1}$ are abelian and have order a power of $2$ . However, with all this information I still couldn't determine whether $I=C_2\times C_2$ or $I=C_2$ . In Ramification in local fields it is suggested to look at the reduction $h\equiv x^4\mod 2$ , which doesn't help either (or I don't see how it would). This is the case for any polynomial whose Newton polygon has nonzero slope, which I encounter multiple times. Is there a way to determine the inertia group $I$ with the information I provided, or is there a different/better way? I mostly worked with Chapter 2 of Neukirch's Algebraic Number Theory. In the local fields database https://math.la.asu.edu/~jj/localfields/ we can see that for the polynomial $h$ it is $e=f=2$ . Also, for the polynomial $$
h_2=x^4+3x^2+1\in\mathbb{Q}_2[x]
$$ we have $$
h_2\equiv x^4+x^2+1 \equiv \left(x^2+x+1\right)^2 \mod 2.
$$ From how I understood the comments in Ramification in local fields , this already implies $e=f=2$ for the stem field of $h_2$ . Is this correct?
If it is correct, could you please suggest a source where I can find the involved results? Thank you very much for your help!","['galois-theory', 'number-theory', 'p-adic-number-theory', 'algebraic-number-theory']"
4097486,Fixing a proof that open path connected sets in $\mathbb{C}$ are connected.,"Let $\Omega\subset \mathbb{C}$ be open. Then if $\Omega$ is pathwise connected, then $\Omega$ is connected. Let $\Omega\subset\mathbb{C}$ be open, and suppose we can write $\Omega =\Omega_1\cup \Omega_2$ for disjoint open $\Omega_1,\Omega_2\subset\mathbb{C}$ . Let $w_0\in\Omega_1$ and $w_1\in\Omega_2$ , and let $\gamma:[0,1]\to\mathbb{C}$ be a path in $\Omega$ with $\gamma(0)=w_1$ and $\gamma(1)=w_2$ . Let \begin{equation}
t^*=\sup_{t\in [0,1]} \{t:\gamma(s)\in\Omega_1,\,0\leq s<t\}.
\end{equation} If $\gamma(t^*)\in\Omega_1$ , there is some $\varepsilon>0$ so that $D_\varepsilon(\gamma(t^*))\subset\Omega_1$ , namely, $\gamma(t^*+\varepsilon)\in\Omega_1$ , which is a contradiction. But since $\Omega_2$ is open, $\mathbb{C}\setminus\Omega_2$ is closed so it must contain its limit points, $\gamma(t^*)$ is a limit point of $\Omega_1\subset \mathbb{C}\setminus\Omega_2$ , and so $\gamma(t^*)\in \Omega_1$ , which is a contradiction. I feel uneasy with the last point of the proof, and was wondering if there was any way I could fix it. Any help/hints/feedback would be greatly appreciated.","['complex-analysis', 'general-topology']"
4097508,"Let $ G $ be a graph other than the trivial one, with exactly one vertex of degree 1. Show that $ G $ cannot be a tree.","Let $ G $ be a graph other than the trivial one, with exactly one vertex of degree 1. Show that $ G $ cannot be a tree. Proof. Since we know that every tree has $ n-1 $ edges, then the total degree of any tree must be $ 2 (n-1) $ . Then there are $ (n-1) $ vertices with degree $ \geq 2 $ while only one vertex of degree 1. Thus, adding to find the total of the vertices, we have that the total degree of the vertices is $ \geq 2 (n-1) + 1 = 2n-1 $ , which is a contradiction. Therefore $ G $ is not a tree. $ \square $ It's okay?","['graph-theory', 'trees', 'discrete-mathematics']"
4097532,Why do we define the modulus of a complex number as we do?,"For a complex number $z = a+bi$ , we say that its modulus is: $$|z|=\sqrt{a^2+b^2}$$ When we draw complex numbers in the Argand diagram, intuitively, this makes sense.
But if we used a different projection for the diagram (i.e. a different metric for distance) then it wouldn't necessarily. Of course, complex numbers can also be written as: $$z = re^{i\theta} = r(\cos\theta +i\sin\theta)$$ so an equivalent question could be, if this is what we define, why we define that: $$|e^{i\theta}| = |\cos\theta + i\sin\theta| = 1$$ for all values of $\theta$ , rather than just $\theta = n\pi$ . The answer may simply be that it is convenient to work with this definition. But is there a deeper reason? Are there any problems for which it is convenient to define things differently? And what would be the consequences if we did things differently?","['complex-numbers', 'real-analysis']"
4097544,Winning strategy of a unique game,"First let's state the game: Game: Matin and Amo met each other in a gym and decided to play a game. The gym has
long enough horizontal metal shaft and exactly one weight of each radii $1, 2,\dots, 100$ units. They
take turns alternatively, starting with Amo, picking up a weight and inserting it from either left
of right head of the shaft. After all weights have been inserted, Matin stands by the left side of
the shaft and Amo stands by its right; among them the one who can see more weights wins; if
they see equal number of weight then it is a draw. By seeing a weight we mean that no weight
with bigger radius exist between the observer and that weight. Considering that they both are
intelligent mathematicians, determine the result of this game. Here are my results: Matin has a draw strategy: If Amo starts with inserting the weight with radius 100,
Matin inserts 99 from his end, after this move Matin just needs to insert the largest weight from his
end; in this manner any weight inserted by him will be visible by him and not Amo. So Matin
will see 51 weights and Amo will see 50 weights. But if Amo start with a weight with radius
less than 100 Matin puts the weight with radius 100 at Amo's end and continues like the other
case. Playing 99 when 100 is not played yet will cause the rival to have a draw strategy: This is actually quiet easy the rival will insert 100 from not his but the other end of shaft. The rest is similar to the above when 100 is inserted. Playing 98 before 99 and 100 will cause the rival to have a draw strategy: Again the other player does the same as above it is not hard to see it works.","['game-theory', 'combinatorics', 'combinatorial-game-theory']"
4097552,Practice exercise | Trees | Graph theory,"Let $ G $ be a tree with 14 vertices of degree 1, and the degree of each nonterminal vertex is 4 or 5. Find the number of vertices of degree 4 and degree 5. My attempt, summarized, is the following: Let $ x $ be the number of vertices of degree 4, let $ y $ be the number of vertices of degree 5. Note that there are $ x + y + 14 $ vertices ( $ x + y + 13 $ edges, since $ G $ is a tree), then $ 4x + 5y + 1 (14) = 2x + 2y + 26 $ applying handshaking lemma (the sum over all vertices of the degrees is two times the number of edges). But the solution to this is $x = - \frac{3}{2} y + 6$ . I don't know if it's okay or what I'm doing wrong.","['graph-theory', 'trees', 'discrete-mathematics']"
4097557,Question about Regression,"I am solving a problem but I am having a hard time understanding the terminology. I have not been exposed to much statistics/probability before so please bear with me. I am considering a regression model $Y_i = f(x_i)+\epsilon_i$ for $i=1,2,\dots n$ . We are given that $x_i$ are independently and identically distributed in [0,1] and that $\epsilon_i$ are independently and identically distributed normal random variables with standard deviation $\sigma$ . We are of course given $\sigma$ . So the first thing I want to do is generate some random samples $\{(x_j,Y_j)\}$ , but I am unsure how to do this. I feel like I am not understanding how to generate my $x_i$ and $\epsilon_i$ , but once knowing this it should become simple I believe. I know this may be simple, but any help is much appreciated.","['regression', 'statistics']"
4097580,Integral of $\ln(dx+1)$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I want to evaluate the following integral integral of ln(dx+1) , yes the integral is inside the ln, NOT outside The inspiration came from this video integral of x^dx-1 , where the integral was divided and then multiplied by dx, so when evaluating my integral I wanted to use the same trick to get this integral . Then I took the limit as dx approaches 0 to get infinity . So finally I ended up with an integral of infinity * dx which is just equal to infinity . I know the question doesn't make any mathematical sense, so I'm just asking if the question can be solved ""symbolically""? Am I doing any mistakes in my calculation of the inegral? Is there another way to actually solve it? Many thanks,","['calculus', 'analysis', 'real-analysis']"
4097606,Understanding short exact sequences,"I'm trying to understand the presentation on short exact sequences in Benedict Gross's algebra lecture, but I'm having difficulty. This is the definition he gives (paraphrased): Given $G,H,G'$ groups, consider $$1 \to H \to G \to G' \to 1,$$ and let $g: H \to G$ and $f: G \to G'$ be homomorphisms, where $g$ is one-to-one, $f$ is onto, and $g(H) = $ the kernel of $f$ . Defining the maps in this way is fine. If $g$ is one-to-one, it is injective so it's kernel is trivial. The statement $g(H) = \mathrm{ker(f)}$ doesn't make complete sense to me. If $g$ is injective its kernel is trivial, and $g$ has to map identity to identity because it's a homomorphism, so it has to map the kernel in $g$ into the kernel in $H$ . If $g$ is injective, does not that not imply that $H$ is the trivial subgroup? Another reading of this (based on some lecture notes) states instead $\mathrm{Im}(g) = \mathrm{ker}(f)$ . Is this the correct notion? Is there an interplay between injectivity of $f$ , surjectivity of $f$ , and this fact? Finally, he concludes that by $G \cong G/H$ by the first isomorphism theorem. This would require that $H$ be a normal subgroup of $G$ (though it's possible this was embedded in the assumptions). $f: G \to G'$ is surjective by assumption, so we have $G/\mathrm{ker}(f) \cong \mathrm{im}(f)$ by the first isomorphism theorem. So this would require that $H = \mathrm{ker}(f)$ (I suppose this is where the above assumption comes into play). I'm also a little bit confused about the "" $1$ 's"": this is strange notation to me, and I'd be inclined to write $\{e\}$ . But are they different identities? Is this the identity in $H$ , $G$ , or $G'$ ? Does it not matter, since the groups are equivalent up to isomorphism anyway? I would greatly appreciate any help on parsing this concept.","['group-theory', 'exact-sequence']"
4097741,Non-existence of surjections from $L^p$ to $L^q$,"Let $1 \leq p, q \leq \infty$ and suppose there exists a continuous linear surjection $$ T : L^p[0,1] \longrightarrow L^q[0,1]. $$ Does it necessarily follow that $q \leq p?$ In the case of sequence spaces $\ell_p$ the result holds if we swap $p,q$ by Pitt's theorem, which asserts that for $q<p$ any bounded linear operator $T:\ell_p \to \ell_q$ is compact. In the $L^p$ context I suspect the notions of type/cotype may relevant, but as a non-specialist it isn't obvious to me how these can be applied. This question is mainly out of curiosity, and any references would be appreciated.","['banach-spaces', 'lp-spaces', 'functional-analysis']"
4097761,Bijection between the power set of $\mathbb R$ and $\mathbb R^{\mathbb R}$,"I want to prove that the power set of $\mathbb R$ , which can be naturally identified as $\{0,1\}^{\mathbb R}$ , is bijective to the set $\mathbb R^{\mathbb R}$ . Can the following attempt be altered to get a bijection without invoking Cantor-SchrÃ¶der-Bernstein ? Here is my attempt: Notation. For any $f:\mathbb R\to\mathbb R$ , let $\operatorname{graph}f\overset{\text{Def.}}=\{(x, f(x))\in\mathbb R^2: x\in\mathbb R\}$ . Let $g:\mathbb R\to\mathbb R^2$ be a bijection. ${}^1$ ${}^2$ ${}^3$ Now I define the operator \begin{split}B:\mathbb R^{\mathbb R}&\to\{0,1\}^{\mathbb R}, \\ f&\mapsto B(f),\end{split} where \begin{split} B(f): \mathbb R&\to\{0,1\}, \\ 
r&\mapsto
\begin{cases}
1&\text{if } g(r)\in\operatorname{graph} f\\
0&\text{if } g(r)\not\in\operatorname{graph} f
\end{cases}
\end{split} Now, $B$ is injective, because if $f_1, f_2:\mathbb R\to\mathbb R$ satisfy $B(f_1)=B(f_2)$ , then, since $g$ is a bijection, for any $(y^1, y^2)\in\mathbb R$ , we have $(y^1,y^2)\in\operatorname{graph} f_1\iff (y^1, y^2)\in\operatorname{graph} f_2$ , i.e. $f_1(y^1)=y^2\iff f_2(y^1)=y^2$ for any $(y^1,y^2)\in\mathbb R^2$ , which means that $f_1=f_2$ . However, $B$ is sadly not surjective. Since the inclusion $\{0,1\}^{\mathbb R}\to\mathbb R^{\mathbb R}$ is trivially injective, Cantor-SchrÃ¶der-Bernstein implies that the two sets are bijective.","['elementary-set-theory', 'cardinals']"
4097767,Seeking an elegant proof that these two infinite series are equal,"Recently I encountered this equality in my work: \begin{align*}
    &\bigg( 1+\frac{1}{p-1} \bigg)
    \bigg( 1+\frac{1}{p^2-1} \bigg)
    \bigg( 1+\frac{1}{p^3-1} \bigg)
    \cdots\\
    =\quad&
    1+\frac{1}{p-1}\bigg(1+\frac{1}{p-1}\bigg(1+\frac{1}{p^2-1}\bigg(1+\frac{1}{p^2-1}\bigg(1+\frac{1}{p^3-1}\bigg(1+\frac{1}{p^3-1}\bigg(1+\cdots\bigg)
\end{align*} If $p$ is a real number $\geq 2$ , it can be easily checked by showing that the ratio of L.H.S and R.H.S tends to $1$ . However, this is not the type of proof I wished for. I'm seeking for a more elegant proof, that would also work for the case in which $p$ is a complex number. For example, is there any way to find the analytical continuation of it? Also, is there any reference for this equality? I believe there are more of this kind in the literature.","['complex-analysis', 'reference-request', 'sequences-and-series']"
4097825,"Is it ""obvious"" that nested commutators generate the derived series?","The derived series of a group is constructed iteratively, taking repeated commutator subgroups. A commutator subgroup is famously not only the set of commutators but the group they generate. This raises the question of whether the second derived group is generated by commutators of commutators, as opposed to commutators of products of commutators. And so on iteratively. Now the identity $$[x, zy] = [x, y] [x, z] [[x, z], y]$$ implies that commutators of products can be expressed as products of commutators. Unless I'm mistaken, a little thought now allows one to infer that you can move all products to the outermost level of commutator brackets, and conclude that in fact the $n$ th derived group is generated by $n$ th nested commutators. But I find this argument a little messy and unsatisfying. Is there a nicer argument - and preferably an intuitive one, rather than one relying on non-obvious theorems? Thanks!","['derived-subgroup', 'group-theory']"
