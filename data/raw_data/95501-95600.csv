question_id,title,body,tags
1310843,Can we live without neighborhood basis but with open neighborhood basis?,"I am reading Lee's Introduction to Topological Manifolds, and he declares that neighborhoods always mean open neighborhoods. So, the definition of a open neighborhood basis goes: Def Let $X$ be a topological space and $p \in X$. The collection $\mathcal{B}_p$ of neighborhoods of p is called neighborhood basis for $X$ at $p$ if every neighborhood contains some $B \in \mathcal{B}_p$. This only cares about open neighborhood basis. Is this definition has any defect, I mean is there any mathematical concept that cannot be expressed as an open neighborhood basis, and needs neighborhood basis? If not, why not every mathematician follow this convention?","['manifolds', 'general-topology']"
1310856,Writing a sentence that is true in one model and false in the other,"Let $Σ=(R)$ , where $R$ is a binary relation. Write a sentence that is true in $\mathcal M_1$ but false in $\mathcal M_2$ : $$\mathcal M_1=(P(N),⊂)$$ $$\mathcal M_2=(N,<)$$ I've been trying to find this sentence for a couple of hours now and they just seem too equivalent, every sentence that i find is either good for both of them or bad for both of them, Thanks in advance !","['first-order-logic', 'logic', 'discrete-mathematics']"
1310873,Find number of solutions of this equation using generating function,"I'm given an equation $x_1 + x_2 + x_3 + x_4 + x_5 = 24$, with a restriction that all of $x_i > 1$ and 2 of them are odd, the rest are even natural numbers. I can solve this using the following reasoning: I must allocate $2 \cdot 3$ for the odd summands and $3 \cdot 2$ for even summands. Then I have to find the number of ways I can distribute the remaining 12 to the 5 unknowns.  Since these 12 must be distributed in pairs, it follows that the number of ways it can be done is ${5 + 6 - 1 \choose 5} = 210$, and the number of ways the unknowns can be arranged is $\frac{5!}{2!3!} = 10$, hence the final answer is $2100$. I know this to be correct because I also wrote some code to compute it. However, I'm required to recast this problem as a generating function, and I'm lost as to how to do that. I would probably be able to solve it, once it is given as a generating function (which is my final goal).","['generating-functions', 'discrete-mathematics']"
1310881,Homogenous equation to higher order ODE,"Hello I have a quick question in regard to general form of the solution to $$y^{(4)}-2y^{(3)}+y''=0$$ I had thought to find this solution we would consider $r^{4}-2r^{3}+r^{2}=0$ which factors as $r^2(r-1)^{2}$ that is we have $r_{1,2}=0$ and $r_{3,4}=1$ So what from what I had thought I knew, I thought this implied a solution of form $$y=c_1e^{0x}+c_2xe^{0x}+c_3e^{x}+c_4xe^{x}=c_1+c_2x+c_{3}e^{x}+c_{4}xe^{x}$$ with $c \in \mathbb{R}$ But wolfram says it is $$y(x)=e^x(c_{2}x+c_{1}-2c_{2})+c_{4}x+c_{3}$$ So where am I going wrong? Thanks all PS: I hear it is correct, and I would by wondering about solving $y^{(4)}-2y^{(3)}+y''=x$ Would I be able to use method of undetermined coefficients for this? And if so, because r=0 is a double root of the equations, would by assumed form for a particular solution need to be $x^2({A_{o}x+A_{1}})$? If I did it with this, could I get a correct answer? Im  not sure exactly",['ordinary-differential-equations']
1310890,What is $\lim_{x\to\infty}\left(\sin{\frac 1x}+\cos{\frac 1x}\right)^x$?,"$$\lim_{x\to\infty}\left(\sin{\frac 1x}+\cos{\frac 1x}\right)^x$$ It is about the $(\to1)^{(\to\infty)}$ situation. Can we find its limit using the formula $\lim_{x\to\infty}(1+\frac 1x)^x=e$? If yes, then how?","['limits', 'trigonometry']"
1310902,Translating a Euclidean proof to hyperbolic language..,"User HyperLuminal asked for help to prove the following statement: Connecting the feet of the altitudes of a given triangle, we obtain another triangle for with the altitudes of the original triangle are angle bisectors of the new triangle. User @Alexey Burdin gave nice answer. Alexey's answer is based on a fact true only in Euclidean geometry . He had a quadrangle with two opposite right angles and used the fact that this quadrangle has a special circum circle centered at the altitude point of the triangle of the OP... (Pls. see his answer.) My claim is that the OP's claim is true in the hyperbolic geometry as well. However I cannot prove this statement. My main problem is that I cannot detach myself from the Burdin solution. Help needed either to falsify my claim or to prove it.","['geometry', 'hyperbolic-geometry']"
1310922,Help with deriving an absolute strategy (very fun if anything),"My friend and I are trying to figure out a solution or even a best path to figuring out a certain win strategy to this game. This game that my friend made, calling it the number game for short, is where a person picks a number on the interval [2,100] and then the other person must search for a number which shares both a factor and a digit with the originally picked number. For example, if you start with the number 15, the number the next person chooses must have a factor of one of the following [3,5,15] and share the digit 1 or 5. Additional rules include that one is never considered a factor (as that would make everything easy) and that you may not start on a number which is prime. Whenever a number is picked, it may not be used again therefore the game is over when a player is unable to choose a different number and that player loses. We are wondering how would determine a set of bounds such that whatever number was picked to go first, you could follow to guarantee victory or if certain numbers guarantee certain loss. What we have started to do is to program a eclipse script in order to run and derive all of the paths of the game with the interval [2,20] as all of the greater intervals have total paths equalling something in the $10^{40}$ power. [2,20] we estimate to have some 7300 paths which is doable by computer. We would be happy to upload preliminary code if anyone is interested,  but so far we are still in the process of writing it. Does anyone have any idea's on how one would go about creating an absolute strategy or even to get a program to print out all of the iterations of path without requiring a supercomputer? Has anyone heard of this game before? Are there any solutions to problems like this that exist on the net (I have not found any) that may help us come to a conclusion? If you are interested, we have a link to sample game code created with eclipse. Have fun! Thank you for your help and time","['computer-science', 'prime-numbers', 'sequences-and-series', 'elementary-number-theory', 'combinatorics']"
1310936,Fourier transform of a radial function,"Consider a function $f \in L^2(\mathbb{R}^n)$ such that $f$ is radial. My question is, is the Fourier transform $\hat{f}(\xi)$ automatically radial (I can see it is even in each variable $x_i$), or we need some conditions on $f$? Thanks for your help.","['fourier-analysis', 'reference-request', 'real-analysis', 'functional-analysis']"
1310939,simple 2 sides inequality,$$2<\frac{x}{x-1}\leq 3$$ Is the only way is to multiple both sides by $(x-1)^2$? so we get $2x^2-4x+2<x^2-x $ and $x^2-x<3x^2-6x+3$ which is $-x^2+3x-2$ and $-2x^2+5x-3<0$ so the sloutions are: $1<x\leq \frac{3}{2}$ and  $1<x\leq 2$ so overall it is $1<x\leq\frac{3}{2}$,"['algebra-precalculus', 'inequality']"
1310969,The maximum of $\frac{1}{(2a+b+c)^2}+\frac{1}{(2b+c+a)^2}+\frac{1}{(2c+a+b)^2}$ [duplicate],"This question already has answers here : Let a,b,c be positive real number, proof. (2 answers) Closed 5 years ago . Let $a,b,c$ be positive reals, such that $\frac1a+\frac1b+\frac1c=a+b+c\ (\star)$, find the maximum of $\frac{1}{(2a+b+c)^2}+\frac{1}{(2b+c+a)^2}+\frac{1}{(2c+a+b)^2}$ This should be an application of Jensen's Inequality, so I have to find a concave function to maximize the sum, I thought to define; $f(\frac1x):=\frac{1}{x+a+b+c},\quad\frac{\partial^2f(x)}{\partial x^2}<0$ so $f$ is concave and then the sum above is; $f(\frac1a)+f(\frac1b)+f(\frac1c)$ using Jensen it should be less or equal to $3\cdot f(\frac{\frac{1}{a}+\frac{1}{b}+\frac{1}{c}}3)=3\frac{1}{\left(\frac3{\frac{1}{a}+\frac{1}{b}+\frac{1}{c}}+a+b+c\right)^2}\overset{(\star)}=3\frac{1}{\left(\frac3{a+b+c}+a+b+c\right)^2}$ and the denominator can be minimized with AM-GM; $\left(\frac3{a+b+c}+a+b+c\right)^2\ge\left(2\sqrt{3\frac{a+b+c}{a+b+c}}\right)^2=12$ so the result is $\frac14$, but it is wrong, where does it fail, maybe AM-GM value cannot be attained ?","['algebra-precalculus', 'inequality']"
1310999,Integral with specific method,"Evaluate $$\displaystyle \int _{ 0 }^{ \pi /2 }{ \log(\cos(x))\log(\sin(x)) \ dx }$$ Consider : $$\displaystyle F(m,n)=\int _{ 0 }^{ \pi /2 }{ \sin ^{ 2m-1 }{ x } \cos ^{ 2n-1 }{ x } dx } $$ $$\sin^{2}x = t$$ : $$ \displaystyle F(m,n) =\frac{1}{2} \int _{ 0 }^{ 1 }{ { t }^{ m-1 }{ (1-t) }^{ n-1 }dt }=\frac{\beta (m,n)}{2} $$ Where $\beta(m,n)$ is the beta function. $$\displaystyle F(m,n) = \frac { \Gamma (m)\Gamma (n) }{2 \Gamma (m+n) } $$ Hence $$\displaystyle \frac { \Gamma (m)\Gamma (n) }{ \Gamma (m+n) } = 2\int _{ 0 }^{ \pi /2 }{ \sin ^{ 2m-1 }{ x } \cos ^{ 2n-1 }{ x } dx }$$ Differentiating with respect to $m$ : $$\displaystyle \frac { \Gamma (n) }{ ({ \Gamma (m+n)) }^{ 2 } } (\Gamma '(m)\Gamma (m+n)-\Gamma (m)\Gamma '(m+n)) = 4\int _{ 0 }^{ \pi /2 }{ log(sin(x))\sin ^{ 2m-1 }{ x } \cos ^{ 2n-1 }{ x } dx } $$ $$\displaystyle \frac { \Gamma (m)\Gamma (n) }{ \Gamma (m+n) } (\psi (m)-\psi (m+n))=4\int _{ 0 }^{ \pi /2 }{ log(sin(x))\sin ^{ 2m-1 }{ x } \cos ^{ 2n-1 }{ x } dx }$$ $$\psi(x)$$ is the digamma function. Differentiate with respect to $n$ : $$\displaystyle \frac { \Gamma (m)\Gamma (n) }{ \Gamma (m+n) } (((\psi (m)-\psi (m+n))(\psi (n)-\psi (m+n))-\psi '(m+n))$$ $$\displaystyle =8\int _{ 0 }^{ \pi /2 }{ log(sin(x))log(cos(x))\sin ^{ 2m-1 }{ x } \cos ^{ 2n-1 }{ x } dx } $$ $m=n=\dfrac{1}{2}$ : $$\displaystyle \frac { { \Gamma }^{ 2 }(1/2) }{ \Gamma (1) } ({ (\psi (1/2)-\psi (1)) }^{ 2 }-\psi '(1))$$ $$\displaystyle =8\int _{ 0 }^{ \pi /2 }{ log(cos(x))log(sin(x))dx } $$ $$\displaystyle \Gamma (1/2)=\sqrt { \pi } ,\Gamma (1)=1,\psi (1/2)=-\gamma -log(4),\psi (1)=-\gamma ,\psi '(1)=\frac { { \pi }^{ 2 } }{ 6 } $$ Any other method to do this?",['calculus']
1311006,Calculation with Leray spectral sequence,"The Leray spectral sequence is a cohomological spectral sequence of the form $$H^p(Y;R^q f_*(F)) \Longrightarrow H^{p+q}(X;F)$$
for abelian sheaves $F$ on a site $X$ and morphisms of sites $f : X \to Y$. Is there an example of a concrete calculation with the Leray spectral sequence for sheaf cohomology?  So far I have ""only"" seen abstract and general arguments which use the Leray spectral sequence; my question is not about these general usages. Often the spectral sequence degenerates directly (at least, in the examples I am aware of), which is not very interesting and doesn't show the real power of spectral sequences. Actually I guess that these cases of the Leray spectral sequence may be replaced by more ""direct"" arguments. The cohomological Serre spectral sequence associated to a Serre fibration follows from the Lerre spectral sequence and in algebraic topology there are lots of calculations with the Serre spectral sequence. So I am actually asking for calculations with the Lerre spectral sequence which rather belong to sheaf theory and are not instances of the Serre spectral sequence.","['spectral-sequences', 'algebraic-geometry', 'sheaf-cohomology', 'sheaf-theory']"
1311023,Showing $ \int_0^{2 \pi } \frac{dt}{a^2 \cos^2 t + b^2 \sin^2 t} = \frac{2 \pi}{ab}$ [duplicate],"This question already has answers here : Calculate the integral $\int_{0}^{2\pi}\frac{1}{a^{2}\cos^2t+b^{2}\sin^{2}t}dt$, by deformation theorem. (2 answers) Closed 9 years ago . The question: Let $\gamma$ be a contour such that $0 \in I(\gamma),$ where $I$ is the interior of the contour. Show that $$\int_\gamma z^n \, \text{d}z = \begin{cases} 2\pi i & \text{if }  n = -1 \\ 0 & \text{otherwise} \end{cases}$$ By taking $\gamma$ as the ellipse $$\{ (x,y) : \frac{x^2}{a^2} + \frac{y^2}{b^2} = 1 \},$$
show that $$ \int_0^{2 \pi } \frac{dt}{a^2 \cos^2 t + b^2 \sin^2 t} = \frac{2 \pi}{ab}.$$ The question's answer uses the Deformation theorem and the fact that the first integral has the given value if the contour is a unit circle. However, the two contours must not overlap, so it seems like this should only be true for a contour that either always has magnitude less than one or greater than one. In Mathematica, the final integral was true for the case that $a = 1.5$ and $b=0.4$. What am I missing? Edit: The radius of the circle cancels in the integral if $n = -1$, so then it does hold irrespective of the radius.","['contour-integration', 'complex-analysis']"
1311040,The groups with symmetric subgroups lattice,"Let $G$ be a group and $\frak L (G)$ be set of all subgroups of $G$. Clearly, $\frak L (G)$ is a lattice. If we know that $\frak L (G)$ is symmetric then what can be said about the group $G$ ? Any reference and observation would be appriciated. Example: Elemantary abelian $p$ groups, the groups that all Sylow subgroups of prime orders are such examples.","['abstract-algebra', 'group-theory', 'lattice-orders']"
1311049,Prove that congruent matrices have the same rank.,Can someone prove that two similar matrices have the same rank? Thanks a lot.,['linear-algebra']
1311077,Why is the dual of a filter an ideal?,"Jech's set theory, (3rd edition) says that if $F$ is a filter on $S$ Let $I = \left\{ {S - X: X \in F}\right\}$ then $I$ is an ideal of $S$ (dual to $F$). However, let $X,Y \subset S$, $X \in I$ and $Y \subset X$. I am having a hard time showing that $Y \in I$, to fulfill the requirements of being an ideal.  Can someone please show how  $Y \in I$ ? Thanks!","['boolean-algebra', 'elementary-set-theory', 'ideals', 'filters']"
1311110,Symmetric matrix with given determinant,"The matrix
\begin{equation}
A := 
\begin{pmatrix}
x & 0 & 0 & z \\
0 & y & 0 & x \\
0 & 0 & z & y \\
y & z & x & w
\end{pmatrix}
\end{equation}
has determinant
\begin{equation}
\det A =  -x^2y^2 - x^2z^2 -y^2z^2+ xyzw,
\end{equation}
which describes the Steiner surface. However, $A$ is not symmetric, so it does not answer whether the Steiner surface is a symmetroid or not. Is it possible to find a symmetric matrix $S$ such that each nonzero entry in $S$ is a linear form in $x, y, z, w$ and $\det S = \lambda \det A$ for some $\lambda \in \mathbb{R} \setminus \{0\}$?","['linear-algebra', 'matrices']"
1311135,Non decreasing real function satisfying $f(x)=f(x+1)$ and/or $f(x)=f(x-1)$. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $f:\mathbb R\to\mathbb R$ be a non-decreasing function. For all $x\in\mathbb R$ we have $(f(x)-f(x-1))(f(x+1)-f(x))=0$. What can we say about the function? [EDITED]","['contest-math', 'functional-analysis', 'functions']"
1311147,Correspondence Theorem for Rings,"Let $I$ a proper ideal of a ring $R$. For each intermediate ideal $I\subseteq J\subseteq R$, we consider the map $$J\mapsto \pi(J):=J/I:=\{a+I:a\in J\}.$$ I want to prove that this is a bijection from the intermediate ideals to the set of ideals of $R/I$. It is easy to see that $J/I$ is an ideal of $R/I$. For injectivity, if $J/I=J'/I$ and $a\in J$, then $a+I=a'+I$ for some $a'\in J'$, so $a'-a\in I\subseteq J'$. It follows $a\in J'$. Similarly $J'\subseteq J$. What I can't do yet is to prove this is a surjective map. Let $I_0$ an ideal of $R/I$. How can I find an ideal $J$, with $I\subseteq J\subseteq R$ such that $J/I=I_0$? Thank you.","['abstract-algebra', 'group-theory']"
1311149,Why are IQ test results normally distributed?,"(I'm a nooby in probability) So why are IQ test results normally distributed? 
Or more precisely what are the hypothesizes and theorems that imply this distribution? Has it to do with the central limit theorem? (But this theorem is about the arithmetic mean of iid variables. I dont see iid variables here: I suppose it's not one person repeating the test. Is it the skills given at a person that is considered as a random variable?)","['normal-distribution', 'statistics']"
1311173,Does intrinsic mean existing regardless of some bigger space?,"How is the arc-length of a regular parametrized curve in a surface $S\subset\mathbb{R}^3$ intrinsic? Let $\bf{x}\rm(u,v)$ be a parametrization of $S$. Letting $E,F,G$ denote the coefficients of the first fundamental form, the arc length of a curve $\alpha:U\to S$ is said to be intrinsic because it can be computed with knowledge of only these coefficients as $$\int_0^t\sqrt{E(u^\prime)^2+2Fu^\prime v^\prime +G(v^\prime)^2}.$$But an ant living on the surface could not compute this value since $E,F,G$ are computed using points described by $3$-coordinates. The $3^{\text{rd}}$ coordinate does not exist to the ant. If one lived in $\mathbb{R}^2$ (or a surface which they think is $\mathbb{R}^2$), and did not know of the existence of $\mathbb{R}^3$, they would have no way to compute this value. Would they? I understand intrinsic meaning invariant under isometries, but I don't see how an intrinsic property can be computed or can exist without reference to some bigger space. To compute the Gaussian curvature at a point, you explicitly use the fact that the point is described by $3$ coordinates.","['differential-geometry', 'curves', 'surfaces', 'curvature']"
1311195,Is the derivative of a quadratic related to the second difference of that quadratic?,"Please do not judge me too harshly for my lack of knowledge, but at school we have gone over Quadratic functions recently. Now, these types of functions are not new to me, however when we viewed a table of one of these functions I found something interesting: $$
\begin{array}{c|lcr}
x & f(x) & \text{1st Diff.} & \text{2nd Diff} \\
\hline
-2 & 9 & - & - \\
-1 & 6 & -3 &- \\
0 & 5 & -1 & 2 \\
1 & 6 & 1 & 2 \\
2 & 9 & 3 & 2
\end{array}
$$
Now, as you might guess, the explicit function of this quadratic is 
$$
f(x) = x^2 + 5
$$
But what was interesting was that the 2nd difference is constantly $+2$, which would be the slope of the derivative function, since $a = 1$:
$$
f'(x) = 2(1)x
$$
We've seen a few more and every time the $a$ coefficient of the quadratic was $1/2$ that of the second difference, which only added to the connection. So, what is the relationship between the 2nd difference and the derivative of this function? I looked online but nothing had the answer that I was looking for. Thank you! Gil Keidar","['quadratics', 'derivatives']"
1311196,Computing wavenumbers for discrete Fourier transform,"I'm trying to implement a Fortran program to compute the derivative of a function using the FFT. To begin with, just to test my installation of fftpack, I computed the Fourier transform of $\mathrm{sin}(x^{2})$, followed by the inverse transform of that result, which gave me back $\mathrm{sin}(x^{2})$ as expected. So once I was satisfied that the FFT routines were working, I began trying to use it to find the derivative, via the formula $$\frac{\mathrm{d}f(x)}{\mathrm{d}x}=\mathcal{F}^{-1}[ik\hat{f}(k)],$$ where $f(x) = \mathrm{sin}(x^{2})$, for $x$ between $0$ and $2\pi$. There are $N=256$ points on the mesh, so $x_{n}=2\pi n/N.$ My simple problem is, I can't work out how to compute the values of $k$. I've tried some stuff, but it resulted in garbage. I'd really appreciate any help, thanks.","['fourier-analysis', 'numerical-methods', 'algorithms', 'derivatives']"
1311229,About the double integral.,"In my text book it says that the volume between the some region $R$ in the $xy$ plane and the surface $z=f(x,y)$ can be found by calculating $$\iint_D f(x,y)~dxdy$$ yet in the next page it uses this formula to calculate an area in the $xy$ plane not a volume under a surface why is this the case I don't see how they go from talking about volume to talking about area. It also says the volume can be calculated as follows: $$\iiint_S dxdydz $$ but I don't understand why this is the case also I thought we needed $z=f(x,y)$ to calculate the volume not $\omega=f(x,y,z)$ as surely this would be some other quantity in $4$ dimensions, not a volume? Please help me clear this up thanks.",['multivariable-calculus']
1311250,Exterior derivative = infinitesimal change in differential form?,"For simplicity I'll work in $M=\mathbf R^2$. Given $f\in C^\infty(M)=\Omega^0(M)$, its exterior derivative $df$ is a 1-form that eats a tangent vector and spits out the best linear approximation of (the change in) $f$ if we walk along the direction specified by that vector. In other words, given a point $(x,y)\in M$ and a tangent vector $(dx,dy)\in T_{(x,y)}M$, our 1-form $df=\displaystyle\frac{\partial f}{\partial x}\,dx+\frac{\partial f}{\partial y}\,dy$ eats $(x,y,dx,dy)\in TM$ and spits out a real number that's supposed to be the infinitesimal change in $f$. The part I never really wrapped my head around is the exterior derivative of higher forms. In coordinates, it's usually defined to be $d(g\,dx+h\,dy)=dg\wedge dx+dh\wedge dy$ (and analogously for higher forms). Question: Can I interpret this to be the ""infinitesimal change in $\omega=g\,dx+h\,dy$""? Thus, instead of thinking of $d:\Omega^k(M)\to\Omega^{k+1}(M)$, can I think of $d\omega$ as eating a tangent vector and spitting out the infinitesimal change in $\omega$? Paraphrased: Does $X\lrcorner\, d\omega$ represent the infinitesimal change in $\omega$ in the direction $X$? I've noted that $X\lrcorner\,d\omega$ is ""half"" of Cartan's magic formula, which is also supposed to represent the infinitesimal change in $\omega$ if we flow along $X$, and this just completely confused me. At this point, I'm not even sure I know what I mean by ""infinitesimal change in $\omega$"" anymore. Is there any hope in trying to understand things the way I'm currently trying to, or should I just abandon this altogether and just live with the axioms?",['differential-geometry']
1311274,A group of 20 students are to be arranged in two rows.,"Here is the problem: A group of $20$ students, including $3$ particular girls and $4$ particular boys, are to be lined up in two rows with $10$ students each.  In how many ways can this be done if the $3$ particular girls must be in the front row while the $4$ boys must be in the back row? Below is my solution, which is wrong according to the answer in the book. The question is where is the mistake? First, choose $7$ students to be with the girls in the first row.  There are $\binom{13}{7}$ ways to do this.  The remaining six students are with the boys.  There are $3!$ ways to arrange the girls and $4!$ ways to arrange the boys.  If you treat the groups of boys and girls as single objects, you have $8$ objects in the first row and $7$ objects in the second row.  Then the total number of ways to arrange the students as required is $$\binom{13}{7} \cdot 3! \cdot 7! \cdot 4! \cdot 8!$$",['combinatorics']
1311277,Every subring of a field is a domain. Is this reciprocal?,"I'm reading my notes on ring theory, and we proved on class that every subring of a field is a domain. Proof: Let $S \subseteq K$ be a subring of $K$, with $K$ a field. Let $x,y \in S$. If $xy=0$, then $xy=0$ in $K$ too, so $x=0$ or $y=0$ (because $K$ is a field). Automatically the question that came to my mind was: Is the reciprocal true? Can we say that every domain is a subring of a field? Thank you.","['abstract-algebra', 'field-theory', 'ring-theory']"
1311293,Show the inner product spaces are isometric,"Let $V$, $|| \bullet ||_V$ and let $W$, $|| \bullet ||_W$ be two $n$-dimensional normed linear spaces over $\mathbb R$. We know that $V,W$ are then isomorphic as vector spaces. We say that $V,W$ are isometric if there exists a linear map $T: V \to W$ such that $T$ is one to one and onto, and such that for all $v \in V$, $||T(v)||_w = ||v||_V$. a. Assume additionally that $V,W$ are $n$-dimensional inner product spaces. Show that $V,W$ are then isometric. We've done nothing in class regarding isometric stuff so I have no idea what this question is even asking of me.","['isometry', 'linear-algebra', 'linear-transformations']"
1311307,How to find the domain of a function such that it will be all positive numbers?,"I've been working on this problem for a while now and I feel like I'm not understanding it: Find all numbers a such that the domain of the function: $$f(x)= {1\over\sqrt{1+2ax-x^2}}$$ Contains all positive numbers. So far I have tried to use the quadratic formula to find where the function is negative and where the function is positive but without a set constant for ""a"" I have not been able to achieve this. If anyone could walk me through this It would be greatly appreciated.","['algebra-precalculus', 'functions']"
1311344,Unordered cartesian product?,"I have a set $\Omega=\{1;2;6\}$ and I want to define another set $A$ consisting of all triples $(a,b,c)$ with $a,b,c\in\Omega$, which contain exactly two 6's. My first attempt looked like this: $A=\{a^2\times b\vert a=\{6\},b=\{1;2\}\}$ But after looking at the cartesian product's definition, it looks like my set $A$ consists of all triples having two 6's as their first two elements instead of all triples containing two 6's. So here is my second attempt: $A=\{(a^2\times b)\cup(a\times b\times a)\cup(b\times a^2)\vert a=\{6\},b=\{1;2\}\}$ So my questions are, if my last definition of $A$ would be correct (?), if there is a way to shorten the definition of $A$ (?) and if there is something like an ""unordered cartesian product""?","['elementary-set-theory', 'cross-product']"
1311382,Exercise 1.9 in Hartshorne - is my initial attempt a good start?,"Hartshorne's Chapter 1, exercise 1.9 asks us to show that irred. components of $Z(\mathfrak a)$ have dimension $\geq n-r$ if $\mathfrak a$ is an ideal generated by $r$ elements. I think I've reduced this to a problem in commutative algebra, but I'm not sure how to tackle it. My start: for a variety $Y\subset\mathbb A^n$ we have $$\dim Y = n-\operatorname{height}I(Y),$$ thus we need to show that $\operatorname{height}I(Y)\leq r$ if $Y$ is an irred. component of $Z(\mathfrak a)$. I tried to argue by contradiction, supposing we had a chain $$\mathfrak p_0\subset\mathfrak p_1\subset\dots\subset\mathfrak p_{r+1}=I(Y),$$ but I'm not sure how to bring $\mathfrak a$ into play here as we have $I(Y)\supset\mathfrak a$, not the other way around. How would I approach this?","['algebraic-geometry', 'commutative-algebra']"
1311393,What is the precise mathematical definition of what a wavelet is and what is its relation to linear algebra?,"I was reading on wavelets and it seems that its hard to find a precise mathematical definition of what this concept is. My confusion first arose due to Gilbert Stang's linear algebra book. In particular consider the following extract: It talks about how to change a vector from one basis to another but it never rigorously defines what a wavelet is (by the way, I did understand that extract I included, just not the concept of ""wavelet""). From my understanding, some special basis are called wavelets (for some special reason). But which basis are we allowed to call wavelets? I would assume that they have something to do with linear algebra and oscillation/sinusoidal functions but I don't really see what the relation between the two is. To look for an alternative explanation I went to wikipedia and the initial paragraph starts as follows: A wavelet is a wave-like oscillation with an amplitude that begins at
  zero, increases, and then decreases back to zero. It can typically be
  visualized as a ""brief oscillation"" like one might see recorded by a
  seismograph or heart monitor. Generally, wavelets are purposefully
  crafted to have specific properties that make them useful for signal
  processing. Wavelets can be combined, using a ""reverse, shift,
  multiply and integrate"" technique called convolution, with portions of
  a known signal to extract information from the unknown signal. With that description it makes me feel that wavelets are actually functions. However, I've had difficulty understanding this precisely, specially when trying to relate it to linear algebra. I guess I am having a hard time connecting the three, wavelets, linear algebra and their relations to sinusoidal functions (if there is any relation to them).","['fourier-analysis', 'functional-analysis', 'wavelets', 'functions', 'linear-algebra']"
1311394,Why conjugate when switching order of inner product?,"There is an axiom of inner product spaces that states: $\overline{\langle x,y\rangle } = \langle y,x\rangle$ Basically (without any conceptual understanding) it seems like all you have to do when you swap the order of the arguments in an inner product space is take their conjugate. How does this make any sense? I know if we are dealing with an inner product space over $\mathbb{R}$ then the conjugate of a real number is just the real number itself so there is no change. But how does this make sense over the field $\mathbb{C}$?","['linear-algebra', 'inner-products']"
1311398,What is wrong with this integral reasoning?,"$$\int\frac{x^{2}+1}{x\sqrt{x^{4}+1}}dx$$
We start by multiplying by $1=\frac{x}{x}$.
$$\int\frac{x^{2}+1}{x^{2}\sqrt{x^{4}+1}}xdx$$
Next, we use the substitution $u=x^{2}$;$\frac{du}{2}=xdx$.
$$\frac{1}{2}\int\frac{u+1}{u\sqrt{u^{2}+1}}du=\frac{1}{2}\int\frac{1}{\sqrt{u^{2}+1}}du+\frac{1}{2}\int\frac{1}{u\sqrt{u^{2}+1}}du=$$
$$=\frac{1}{2}\ln\left(u+\sqrt{u^{2}+1}\right)+\frac{1}{2}\int\frac{1}{u\sqrt{u^{2}+1}}du$$
The problem is now reduced to computing the integral $\frac{1}{2}\int\frac{1}{u\sqrt{u^{2}+1}}du$.
$$\frac{1}{2}\int\frac{1}{u\sqrt{u^{2}+1}}du=\frac{1}{2}\int\frac{1}{u^2\sqrt{1+\frac{1}{u^{2}}}}du$$
We use substitution again $v=\frac{1}{u}$;$-dv=\frac{1}{u^{2}}du$, then we have the next integral.
$$-\frac{1}{2}\int\frac{1}{\sqrt{1+v^{2}}}dv=-\frac{1}{2}\ln\left(v+\sqrt{1+v^{2}}\right)=-\frac{1}{2}\ln\left(\frac{1}{u}+\sqrt{1+\frac{1}{u^{2}}}\right)=$$
$$=-\frac{1}{2}\ln\left(\frac{1+\sqrt{u^{2}+1}}{u}\right)$$
Finally the solution is:
$$\int\frac{x^{2}+1}{x\sqrt{x^{4}+1}}dx=\frac{1}{2}\ln\left(u+\sqrt{1+u^{2}}\right)-\frac{1}{2}\ln\left(\frac{1+\sqrt{u^{2}+1}}{u}\right)=\frac{1}{2}\ln\left(\frac{x^{4}+x^{2}\sqrt{x^{4}+1}}{1+\sqrt{x^{4}+1}}\right).$$
But the problem is, the book has the following solution:
$$\int\frac{x^{2}+1}{x\sqrt{x^{4}+1}}dx=\ln\left(\frac{x^{2}-1+\sqrt{x^{4}+1}}{x}\right)$$
which is obviously different.","['calculus', 'indefinite-integrals', 'integration']"
1311407,Combining probability of dependent events?,"Two dice are thrown simultaneously. What is the probability of getting a multiple of $2$ on one die and a multiple of $3$ on the other? According to me, the answer should be $\frac16$, as the probability of getting a multiple of $2$ is $\frac12$, and the probability of getting a multiple of $3$ is $\frac13$. So the combined probability is $\left(\frac12\right)\left(\frac13\right) = \frac16$. But the answer in the book says that the probability is $\frac{11}{36}$. What is the error in my method? How does one solve this problem properly?","['probability', 'algebra-precalculus', 'combinatorics']"
1311437,"Why is this True ? It's probability question, but really an multivariable integration question","I'm given that $X$ is a non-negative continuous random variable show that $$E(X) = \int^\infty_0 [1-F(x)]\,dx$$ $F(x)$is a cdf The solution is following $$\int^\infty_0 (1-F(x)) \, dx = \int^\infty_0 P(X > x) \, dx = \int^\infty_0 \int^\infty_x f_x(t) \, dt\,dx = \int^\infty_0 f(t) \left(\int^t_0 dx\right) \, dt$$ I don't understand why is it true for the last two equality, when the order $dx$ and $dy$ been changed. What's the theorem behind it ? (i only know basic double integration calculation)","['probability', 'multivariable-calculus']"
1311464,the determinant function is an open function?,"The determinant function $\det:M(n,\mathbb R)\rightarrow \mathbb R$ is an open mapping or a closed mapping? The determinant function $\det:M(n,\mathbb C)\rightarrow \mathbb C$ is an open mapping or a closed mapping?",['linear-algebra']
1311507,$(1+i)^6$ in polar form $re^{i\theta}$,"I used De Moivre's formula and got 
$$
  \left(\frac{\sqrt{2}}{2}\right)^6 \times 
  \cos\left(6 \times \frac{1}{4\pi}\right) + 
  i\sin\left(6 \times \frac{1}{4\pi}\right) = 
  \frac{1}{8} e^{\frac{3}{2\pi}}.
$$ But the answer is $8e^{\frac{3}{2\pi}}$, can someone explain where the $8$ is from? 
Thanks!","['complex-analysis', 'complex-numbers']"
1311549,How to prove that given set is a connected subset of the space of matrices?,"Let $M$ be the space of all $m\times n$ matrices. And $C=\{X\in M|\operatorname{rank}(X)\leq k\}$ where  $k\leq \min\{m,n\}$. Check whether the set $C$  is: Closed Connected Compact Open What are some other good properties of the set $C$,for example is it a manifold? Clearly the set $C$ is closed  if someone is interested  a good proof can be found here , hence $C$ is not open. Also as $C$ is unbounded therefore not compact. How to check whether the set $C$ is connected or not?","['general-topology', 'matrices']"
1311571,"If $A$ is normal and $A$ and $B$ commute, then $A^*$ and $B$ commute","Let $A$ is a normal matrix: $A^*\! A = A A^*\!\!$,$\,$ and $AB = BA$. Prove that $A^*\!B=BA^*\!\!$. I can prove that if $\det A\ne 0$ by multiplication $AB=BA$ by $A^*$ left and right and using some manipulation. But I have no idea what to do if $\det A = 0$.",['matrices']
1311579,Proving that the set of differentiable functions with $\left|f'(t)\right|\leq K$ is dense in the set of Lipschitz continuous functions?,"Let $M_K$be the set of all continuous functions $f$ in $C_{[a,b]}$ satisfying a Lipschitz condition, i.e., the set of all $f$ such that
$$
\left| f(t_1)-f(t_2)\right| \leq K \left| t_1-t_2\right|
$$
for all $t_1,t_2 \in [a,b]$, where $K$ is a fixed positive number. I would like to prove that $M_K$ is the closure of the set of all differentiable functions on $[a,b]$ such that $\left|f'(t)\right|\leq K$. My Try: I have proved that $M_K$ is a closed set and know that any such differentiable function is in $M_K$. Now I need to prove that for any $f\in M_K$ there exists a sequence of such differentiable functions $\{g_n\}$ such that $g_n\rightarrow f$. Any help? By $C_{[a,b]}$, I mean the set of all continuous functions on the interval $[a,b]$ with distance: $$
d(f,g) = \max_{a\leq t\leq b} \left|f(t)-g(t)\right|
$$","['analysis', 'real-analysis']"
1311616,Limits and Series in Smooth Infinitesimal Analysis,"I just learned a tiny bit about SIA. While it is interesting, that it handles derivatives so easily, I wonder: Can we still recover the concepts of limits (of sequences) and especially series, to make statements like: $\lim_{n\to \infty} (1+\frac{1}{n})^n = e$ $\sum_{k=1}^\infty \frac{1}{k} = \infty$ $e^x = \sum_{k=0}^\infty \frac{x^k}{k!}$ and so on and so forth? I didn't find anything about this.","['nonstandard-analysis', 'limits', 'constructive-mathematics', 'real-analysis', 'convergence-divergence']"
1311627,When does analytic in the operator norm imply analytic in the trace class norm?,"Consider $U$ a nice compact region in $\mathbb{C}$ with boundary $\Gamma$. Let $S_1$ b the ideal of trace class operators on a separable complex Hilbert space $H$. We will let $\|\cdot \|$ be the operator norm and $\|\cdot \|_1$ be the trace norm. Suppose $W:U\to S_1$ is complex analytic in the operator norm. Under what conditions is $W(\lambda)$ analytic in the $\| \cdot \|_1$ norm? I have proved that the following are equivalent when $W(\lambda)$ is operator analytic: $W(\lambda)$ is continuous in the operator norm for a fixed $M$, we have $\|W(\lambda)\|_1 <M$ for each $\lambda \in \Gamma$ tr $W(\lambda)B$ is analytic for each bounded operator $B$. $W(\lambda)$ is analytic in the $\|\cdot\|_1$ norm. I can provide some ideas for these proofs if that's be helpful. This leads us to Question 1 : What if we know that tr $W(\lambda)$ is analytic? Is there a nice way to compare tr $W(\lambda)$ with tr $W(\lambda)B$? I would love an inequality like 
$$ |\text{tr }AB| \leq\|B\||\text{tr }A|  $$
for $A \in S_1$ and $B$ bounded. Although it would probably be greedy to expect this in general. Also, I'm willing to impose even stronger assumptions on $W$ if necessary. One very strong constraint is to assume that $W$ has a rank bound along $\Gamma$, I.E. for a fixed $N$ we have rank $W(\lambda)<N$ for each $\lambda \in \Gamma$. This actually guarantees analyticity as 
$$\|W(\lambda)\|_1 \leq N\sup_{\lambda \in \Gamma} \|W(\lambda)\|$$ Attempting to weaken this condition, we arrive at Question 2 : What happens if $W(\lambda)$ is finite rank for each $\lambda$, but has no rank bound? I suspect that finite rank and analytic actually implies rank bounded, but I do not know. Edit 1 Here's a fun idea to that might help prove finite rank implies rank bounded. The set 
$$
S_n = \{\lambda : W(\lambda) \text{ has rank at most}n\}
$$ is closed (continuity of $W$ tells us singular values are continuous). So Baire Category theorem tells us that some $S_n$ is dense somewhere. So in some open set, $W$ is rank bounded. So can I use an analytic extension in the trace norm to do something? This looks like the proofs of the open mapping theorem and whatnot... Edit 2 Here's another fact that may be helpful. Consider a sequence of complex analytic functions $f_n:U\to \mathbb{C}$. Suppose they converge pointwise to an analytic function $f$. Then $f$ is analytic on an open dense neighborhood of $U$. This is potentially helpful because for any orthonormal basis $\phi_i$,
$$
\text{tr} W(\lambda) B = \sum_{i=1}^\infty \langle W(\lambda)B\phi_i,\phi_i\rangle
$$
And because $W(\lambda)B$ is analytic in the operator norm, so will the each inner product be analytic. I am fairly familiar with Gohberg's work on trace class operators. Unfortunately, despite all of the great theorems on bounds for singular values, knowing that tr $W(\lambda)$ is analytic gives no information about the singular values.","['operator-theory', 'functional-analysis', 'trace']"
1311628,Show that $\lim\limits_{n \to \infty} \frac{(n!)^{1/n}}{n}= \frac{1}{e}$ [duplicate],"This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 9 years ago . Show that $$\lim_{n \to \infty} \left\{\frac{(n!)^{1/n}}{n}\right\} = \frac{1}{e}$$ What I did is to let $U_n = \dfrac{(n!)^{\frac{1}{n}}}{n}$ and  $U_{n+1} = \dfrac{(n+1)!^{\frac{1}{n+1}}}{n+1}$. Then $$\frac{ U_{n+1} }{U_n } = \frac{\frac{(n+1)!^{\frac{1}{n+1}}}{n+1}}{\frac{(n!)^{\frac{1}{n}}}{n}}$$ Next I just got stuck. Am I on the right track, or am I wrong doing this type of sequence?","['limits', 'real-analysis', 'sequences-and-series', 'factorial', 'radicals']"
1311675,"Show that $\mathbb{C}[x,y]/(x^2+y^2-1)$ is a UFD. [duplicate]","This question already has answers here : Ring of trigonometric functions with real coefficients (3 answers) Closed 9 years ago . I am trying to prove that the ring $\mathbb{C}[x,y]/(x^2+y^2-1)$ is a UFD. I have an hint, that suggests to find an isomorphism between $\mathbb{C}[x,y]/(x^2+y^2-1)$ and $\mathbb{C}[e^{it},e^{-it}]$, but to be honest I don't see it. Please, could you give me a hand? I would to solve my problem completely, any kind of suggestion is fully appreciated. Update : user Daniel McLaury helped me in showing the isomorphism - so now it remains only to see that this ring is actually an UFD. Thanks in advance.
Cheers","['abstract-algebra', 'commutative-algebra', 'unique-factorization-domains', 'ring-theory']"
1311713,Checking the stability of an equilibrium point,"I have the linearization of a non-linear system about an equilibrium point as follows $$
\dot x = (-A+M)x,
$$
where $x\in\mathbb{R}^3$, $A$ is a positive definite matrix and $M$ has its eigenvalues on the imaginary axis, and only one is equal to zero. Both $A$ and $M$ have real entries. I am wondering whether this system is stable or not. Or on the other hand to find a counter-example where the system is not stable. For $M$ being a skew-symmetric matrix, then the proof becomes trivial, but in general my $M$ is not skew-symmetric.","['control-theory', 'dynamical-systems', 'ordinary-differential-equations']"
1311715,Geodesic equation for surface of sphere,"One of the standard problems of calculus of variations is showing that geodesics on the surface of the sphere are great circles. But I don't understand the equation. The equation for great circle path is derived to be: $$ a\cos(\phi-\phi_0) = \cot(\theta)$$
Where $\phi_0$ and $a$ are constants of integration, and everything else has a standard meaning of spherical geometry. This equation should describe a great circle path, so lets choose one in equatorial plane $\theta=\pi/2$, gives gives:
$$a\cos(\phi-\phi_0)=0$$ But this is no equation of the circle, this is just set of 2 points where $\phi-\phi_0=\pi/2, 3\pi/2$.","['calculus-of-variations', 'differential-geometry', 'multivariable-calculus']"
1311717,Simplify $\prod_{k=1}^5\tan\frac{k\pi}{11}$ and $\sum_{k=1}^5\tan^2\frac{k\pi}{11}$,My question is: If $\tan\frac{\pi}{11}\cdot \tan\frac{2\pi}{11}\cdot \tan\frac{3\pi}{11}\cdot \tan\frac{4\pi}{11}\cdot \tan\frac{5\pi}{11} = X$ and $\tan^2\frac{\pi}{11}+\tan^2\frac{2\pi}{11}+\tan^2\frac{3\pi}{11}+\tan^2\frac{4\pi}{11}+\tan^2\frac{5\pi}{11}=Y$ then find $5X^2-Y$. I couldn't find any way to simplify it. Please help. Thanks.,"['summation', 'products', 'trigonometry']"
1311735,How to extract solutions to a Pell's equation satisfying certain congruences?,"I'm trying to solve $y^2=3x^2+3x+1$ for integers, which transforms into $(2y)^2-3(2x+1)^2=1$. I know how to solve pell's equation, but how can we extract only (odd,even) pair from the solutions of the diophantine equation $y^2-3x^2=1$? Any help would be appreciated.","['pell-type-equations', 'number-theory', 'diophantine-equations', 'elementary-number-theory']"
1311751,Why is the solution to $y' = y^n$ always in polynomial form EXCEPT when $n = 1$?,"Could someone explain (intuition-wise) why the differential equation $$y' = y^n$$ for $n \in \mathbb{N}$ seems to always some kind of polynomial solution (or a ratio of polynomials, etc.) except when $n = 1$, in which case the solution seems to be exponential? What's so special about $n = 1$ that (if you'll pardon the term) differentiates it from e.g. $n = 2$?","['polynomials', 'ordinary-differential-equations', 'exponential-function']"
1311760,Heat equation proving smoothness,"I have a question regarding a PDE course: Let $T$ be the strongly continuous semigroup which belongs to the heat equation, thus with generator $A$ is the Laplacian. Suppose we have $g \in C^{\infty}_c(U)$, and define the sets
\begin{align*}
D(A) & = H^1_0(U) \cap H^2(U) \\
D(A^2) & = \{ x \in D(A) \mid Ax \in D(A)\} \\
& = \{x \in H^1_0(U) \cap H^2(U) \mid \Delta x \in H^1_0(U) \cap H^2(U) \} \\
D(A^k) & = \{ x \in D(A^{k-1}) \mid \Delta x \in H^1_0(U) \cap H^2(U) \}.
\end{align*} We now want to prove that
$$T(t)g \in C^{\infty}(U).$$ First I prove that $g \in D(A^k)$ for all $k$, using induction. For $k=0$ we have
$$g \in C^{\infty}_C(U) \subseteq \overline{C^{\infty}_C(U)} = H^1_0(U).$$ 
We know that $g$ and all the derivatives of $g$ are compactly supported, thus we have
$$\int_U \lvert g \rvert^2 \,\mathrm{d}x \leq \lvert U\rvert \sup_u g^2 < \infty,$$
where the last inequality follows from the fact that $U$ is bounded. For the derivatives of $g$ we have a similar proof, thus $g \in H^2(U)$, therefore $g \in D(A)$. Now suppose it is true for $k-1$, we now want to prove it for $k$. Suppose $g \in D(A^{k-1})$, then $A^{k-1}g = \Delta^{k-1}g \in C^{\infty}_C(U)$. In a similar way as above I can prove that $g \in D(A^k)$. I have also proven that from this it follows that $T(t)g \in D(A^k)$ for all $k$. Then 
$$T(t)g \in \cap_{k=1}^{\infty} D(A^k),$$
however this is where I cannot continue my proof. The last expression should be embedded in $C^{\infty}(U)$. Can someone give me a hint or a solution. If I have proven that, I can complete the rest of the proof myself, however, I am stuck on this.","['ordinary-differential-equations', 'functional-analysis', 'partial-differential-equations']"
1311784,Classify groups of order $2014$,"This is a question from an old exam. There should be $4$ groups of order $2014.$ Note $2014 = 2 · 19 · 53$. Admittedly there is an answer Can only find 2 of the 4 groups of order 2014? but I can't make much sense out of the attempt nor the answer. By Sylow's Theorem, there is a subgroup isomorphic to $\mathbb{Z}/19\mathbb{Z}×\mathbb{Z}/53\mathbb{Z}$. The hint is to 
observe that conjugation by an element of order two induces an order two
automorphism of this subgroup. I am not sure how to proceed. Should the answer depend on the factorization or should a solution be able to work for groups of any order?",['abstract-algebra']
1311819,Positivity of solution to Laplace equation,"I'm studying PDE and at the moment I'm reading L. Evans' book. The strong maximum principle states that; if $u\in C^2(U)\cup C(\bar U)$ is harmonic in $U$, where $U$ is connected and if there exists $x_0$ such that $u(x_0)=\max _\bar U u$, then $u$ is constant within $U$. A little later Evans states that if $U$ is connected and $u$ is a solution of the pde $\Delta u=0$ in $U$ and $u=g$ on $\partial U$, where $g\geq 0$. Then $u$ is positive in $U$ everywhere if $g$ is positive somewhere on $\partial U$. Why is this true? I can't see how this follows immediately from the strong maximum principle. I'm guessing it is trivial and I'm just over thinking it. Can somebody help me?","['analysis', 'partial-differential-equations']"
1311833,Proving pseudo-hyperbolic distance is distance,"The pseudo-hyperbolic distance on the unit disk is defined as:
$$\rho(z,w)=\left|\dfrac{z-w}{1-\bar wz}\right|.$$
I'd like to prove it's a distance. The real problem is, as always, the triangle inequality, because the other properties are mostly obvious. That is, I need to prove:
$$\rho(z,w)\leq\rho(z,t)+\rho(t,w),$$
for all $z,w,t\in\mathbb{D}$. I tried writing $z,t,w$ as real part plus $i$ times imaginary part, and ended up with a messy expression Wolfram can't handle. I tried polar coordinates, and the mess is even worse, and Wolfram's help is even less. I Googled first, but only found stuff about the Hyperbolic distance, and a pdf having this as an exercise, suggesting to also show that:
$$\rho(z,w)\leq\frac{\rho(z,t)+\rho(t,w)}{1+\rho(z,t)\rho(t,w)}.$$
But that didn't help. So here I am. How do I solve this?","['hyperbolic-geometry', 'complex-analysis']"
1311846,"Does $\pi$ contain infinitely many ""zeros"" in its decimal expansion?","Some number doesn't contain $""7""$ in its decimal expansion. For example Liouville's constant $$L=\sum_{n=1}^\infty\frac{1}{10^{n!}}=0.11000100....$$ contains only $0$ and $1$. It is well-known that if number is ""normal"" it contain infinite number of  $\lbrace0,1,2...9\rbrace$. 
In other words, if $\pi$ is 10-normal, then the limiting frequency of ""7"" (or any other single digit) in its decimal expansion is $\frac{1}{10}.$ It is not known that $\pi$ is normal, but can we say that $\pi$ (or $\sqrt{2}$) has infinitely many 0 or any other single digit in its decimal expansion?  If ""no"", how many zeros contains $pi$? Also it is easy to prove that  Champernowne number $0.1234567891011...$ contain infinite many ""zeros"" without know that it is 10-normal.","['number-theory', 'decimal-expansion', 'measure-theory']"
1311848,How to prove this tedious (but easy) derivative theorem,"I'm reading Fulton's algebraic curves book (page 3) and I'm having problems with (4), (5) and (6) part of this theorem. This proof seems really easy to demonstrate, but there are a lot of calculations. Is there some strategy to prove this theorem without tedious and tiresome computations. Thanks","['abstract-algebra', 'derivatives']"
1311904,Transference of properties from marginals to joint density functions,"Let $(X,Y)$ be an absolutely continuous random vector and denote by $f_{(X,Y)}(x,y)$ its joint density function and $f_X(x)$, resp. $f_Y(y)$ the marginal density functions. If $f_X$ and $f_Y$ are continuous and $X$ and $Y$ are independent then $f_{(X,Y)}(x,y)=f_X(x)f_Y(y)$ and hence $f_{(X,Y)}$ is continuous as well. So, let us assume $X$ and $Y$ are not independent. How can one obtain regularity of the joint density having only properties from the marginal densities? Is it possible? Is there any criteria? Maybe an illustrative example of a random vector with marginal continuous densities but discontinuous joint density would help. Is there a toy example of this? Thanks a lot!","['calculus', 'probability-distributions', 'real-analysis', 'analysis', 'probability']"
1311922,"If $x$ is rational, can $\log(1-x)/\log x$ be algebraic?","If $x$ is positive rational number less than $\frac{1}{2}$,  can the following logarithmic expression be equivalent to real algebraic number, say $g$? $$\frac{\log(1-x)}{\log x} = g$$","['exponential-function', 'number-theory', 'logarithms']"
1311929,Closed Form for $~\int_0^1\frac{\text{arctanh }x}{\tan\left(\frac\pi2~x\right)}~dx$,"Does $$~\displaystyle{\int}_0^1\frac{\text{arctanh }x}{\tan\left(\dfrac\pi2~x\right)}~dx~\simeq~0.4883854771179872995286585433480\ldots~$$ possess a closed form expression ? This recent post, in conjunction with my age-old interest in Gudermannian functions , have inspired me to ask this question. The reason I suspect that such a closed form might possibly exist is because the integration interval is “meaningful” for both functions used in the integrand. However, none of the various approaches that I can think of seem to be of any help. Perhaps I'm missing something ?","['calculus', 'closed-form', 'improper-integrals', 'definite-integrals', 'integration']"
1311936,$f$ has a zero of order $m\iff \frac{1}{f}$ has a pole of order m,"Question Let $f$ be holomorphic in a domain $D\subset \Bbb{C}$. Then $f$ has a zero of order $m$ in $z_0\in D \iff \frac{1}{f}\in H({D \setminus f^{-1}(0)}) \text{ has a pole of order $m$ in } z_0$. My attempt: I have proved the ""$\implies$"" direction. For the other implication, we suppose that $$\min\left\{v\in \Bbb{N} : \frac{(z-z_0)^v}{f}\text{ is bounded near }z_0\right\}=m$$ We need to find a $g\in H(D)$ with $g(z_0)\neq 0$ such that $f = (z-z_0)^m g$. I haven't been able to do this. Please tell me what I could do.",['complex-analysis']
1311940,What am I doing wrong with this derivative - Differential calculus (brush up),"today I felt like doing some maths and I thought to myself that practicing some derivatives would be neat-o. I sat myself the following question. $$\frac{d}{dx}\left(\frac{5x^4+4x^3+3x^2+2x+1}{x^3}\right)$$Here are my thought process to the problem:
$$\frac{d}{dx}\left(5x+4+\frac{3}{x}+\frac{2}{x^2}+\frac{1}{x^3}\right)$$
$$5+\frac{d}{dx}(3x^{-1}+2x^{-2}+x^{-3})$$
$$5-3x^{-2}-4x^{-3}-3x^{-4}$$
Which then if you will could be rewritten again to the perhaps more beautiful
$$5-\frac{3}{x^2}-\frac{4}{x^3}-\frac{3}{x^4}$$ Finally my question is, why is this incorrect?","['calculus', 'derivatives']"
1311973,Is there an easy way to see that $E(X^2) \geq E^2(X)$?,"I'm trying to memorize the Steiner translation theorem/König–Huygens formula.
The English name seems to be ""Algebraic formula for the variance"" $$Var(X) = E[(X-E(X))^2] = E(X^2) -E^2(X)\;\;\;[1]$$ I assume that since $Var(X) \geq 0$ , $E(X^2) \geq E^2(X)$ holds. Correct? There is a not too complicated proof for [1] on the wikipedia page linked that I understand. But it takes some time to reproduce it. However, I can perfectly remember the outcome of $E(X^2), -, E^2(X)$ just not the order. So (since the difference has to be $\geq 0$ ) is there an easy way to see which of $E(X^2)$ and $E^2(X)$ is bigger? Best shot so far from @wiskundeliefhebber: Remembering that one is at least as big as the other. Then with $P(X=1) = P(X=-1) = 0.5$ follows $E(X)=0$ and $E(X^2)=1$ Ergo $E^2(X) \leq E(X^2)$ footnote: $E^2(X)$ means $(E(X))^2$","['probability', 'linear-algebra', 'inequality']"
1311979,Negativity of a power function.,"For what values (or intervals) of 'a' it holds $2(x+1)^a$ - $x^a$ - $(x+2)^a$$<0$, where $x\in N$. I tried to do it by first derivative test but it again gives almost same type expression which is difficult to solve. By Jensen's inequality it is OK but then I am unable to show that for what values of 'a' the given function $2(x+1)^a$ - $x^a$ - $(x+2)^a$ is convex. For $a=\frac{-1}{2}$ it holds.","['calculus', 'multivariable-calculus', 'inequality']"
1312007,Difference between the largest and second largest observations from a sample of iid normal variables,"What can we say about the distribution of $s_1 - s_2$, where $s_1$ and $s_2$ are the largest and second largest draws from a sample of $N$ iid normal variables? ""Who's the world's greatest mathematician?"" doesn't seem to be as interesting a question as it was in the days of Gauss and Euler. Might this be because there are more mathaticians in the world today, or in spite of that fact? Imagine there are $N$ mathematicians in the world. Each mathematician's ability $a_i$ is drawn independently from a standard normal distribution. Let $s_1$ be the max of the $a_i$ and $s_2$ be the second largest of the $a_i$. What can we say about the distribution of $s_1 - s_2$?","['order-statistics', 'probability']"
1312008,Number of vectors whose start is different from its end,"Consider all $n$-dimensional vectors $v$ with elements from $\{0,1\}$.  We say that if there exists a $n > j \geq 1$ such that $v_{1,\dots,j} = v_{n-j+1,\dots, n}$ then the vector is ""bad"". Otherwise the vector is ""good"". For example $v^{T} = (0,1,0,0,1)$ is bad and $(0,1,1,1)$ is good. How many good vectors are there of length $n$?",['combinatorics']
1312058,"Find probability of exactly one $6$ in first ten rolls of die, given two $6$s in twenty rolls","I am trying to calculate the probability that, when rolling a fair die twenty times, I roll exactly one $6$ in the first ten rolls, given that I roll two $6$s in the twenty rolls. My thoughts Let $A = \{\text {Exactly one 6 in first ten rolls of a die} \}$ and $B = \{\text {Exactly two 6s in twenty rolls of a die} \}.$ Then I want to find 
$$P[A\mid B] = \frac{P[A \cap B]}{P[B]}.$$ By the binomial distribution formula, we get that 
$$P[B] = {20 \choose 2} \cdot \left(\frac{1}{6}\right)^2 \cdot \left(\frac{5}{6}\right)^{18}.$$ Furthermore I think that $P[A \cap B]$ is equal to the probability of rolling exactly one $6$ in ten rolls and then rolling exactly one $6$ in another set of ten rolls.  That is, $$P[A \cap B] = \left[{10 \choose 1} \cdot \left(\frac{1}{6}\right)^1 \cdot \left(\frac{5}{6}\right)^9\right]^2.$$ Am I correct in thinking this? If so, then it follows that the required probability is 
$$P[A \mid B] = \frac{\left[{10 \choose 1} \cdot \left(\frac{1}{6}\right)^1 \cdot \left(\frac{5}{6}\right)^9\right]^2}{{20 \choose 2} \cdot \left(\frac{1}{6}\right)^2 \cdot \left(\frac{5}{6}\right)^{18}},$$
which, I know, can be simplified further!","['probability', 'statistics', 'binomial-distribution']"
1312087,"Reference request, statistical inference","Good morning, I'm looking for a good reference for study on statistical inference, the main topics that will study are Tests of Hypotheses Interval estimation I recommend taking a look at Mood Casella These books are good?","['statistical-inference', 'estimation', 'hypothesis-testing', 'statistics', 'reference-request']"
1312131,"Find 3x3 real matrix A such that $A^2 \neq I$ and $A^4 = I$, where I is identity matrix.","Find $3 \times 3$ real matrix A such that $A^2 \neq I$ and $A^4 = I$, where $I$ is identity matrix. I first thought that there is no such matrix and tried to show that using determinants, but all I get is that A has to have $detA=1$ or $-1$. Next I actually found such Matrix A= $\left( \begin{matrix} 1 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & -1 & 0 \end{matrix} \right)$, but I did it through random manipulations and do not have any idea how to coherently write the answer. Any help would be appreciated. Thanks!","['linear-algebra', 'algebra-precalculus']"
1312133,What do you get with this equivalence relationship for all $\mathbb{Q}$ sequences,Consider all $\mathbb{Q}$ Cauchy sequences with this equivalence relationship $\{x_n\} \sim \{y_n\} \iff \{x_n-y_n\} \rightarrow 0$ Then you get all real numbers as an equivalence class with this relationship. Let's consider now all $\mathbb{Q}$ sequences with this equivalence relationship. We get a set which contains all real numbers and many more. What can we say about those new elements? Does that set represent some known set? Can we get some interesting topological or analytic results about it?,"['real-numbers', 'equivalence-relations', 'real-analysis', 'general-topology']"
1312140,Difficulty understanding why a set is saturated with respect to a map,"The following is the beginning of Example 7 on page 143 of Munkres' Topology . Example 7. The product of two quotient maps need not be a quotient map. Let $X = \mathbb{R}$ and let $X^*$ be the quotient space obtained from $X$ by identifying the subset $\mathbb{Z}_+$ to a point $b$; let $p : X \to X^*$ be the quotient map.
  Let $\mathbb{Q}$ be the subspace of $\mathbb{R}$ consisting of the rational numbers; let $i : \mathbb{Q} \to \mathbb{Q}$ be the idenitity map.
  We show that $$p \times i : X \times \mathbb{Q} \to X^* \times \mathbb{Q}$$ is not a quotient map. For each $n$, let $c_n = \frac{\sqrt{2}}{n}$, and consider the straight line in $\mathbb{R}^2$ with slopes $1$ and $-1$, respectively, through the point $n \times c_n$.
  Let $U_n$ consist of all points of $X \times \mathbb{Q}$ that lie above both of these lines or beneath both of them, and also between the vertical lines $x = n - \frac{1}{4}$ and $x = n + \frac{1}{4}$.
  Then $U_n$ is open in $X \times \mathbb{Q}$; it contains the set $\{ n \} \times \mathbb{Q}$ because $c_n$ is not rational. Let $U$ be the union of the sets $U_n$; then $U$ is open in $X \times \mathbb{Q}$.
  It is saturated to $p \times i$ because it contains the entire set $\mathbb{Z}_+ \times \{ q \}$ for each $q \in \mathbb{Q}$. .... I can't understand why $U$ is saturated with respect
to $p × i$. Can anyone who has studied Munkres' Topology illustrate the matter?","['quotient-spaces', 'general-topology']"
1312141,"Construct Curvilinear Coordinates from ""Tangent Basis Field""","Let say that you are on a open, simple connected subset of the Euclidian plane (2 dimensional) and you have a second order tensor field defined over it. At every point we have a second order tensor which is real, positive, and symmetric, thus it has at every point two eigenvectors which are orthogonal. So in some sense this defines at every point a tangent basis. If the tensor field is smooth, then the variation of this basis from point to point is also smooth. Let us suppose that is as smooth as we may need. My question is the following: Can I construct some curvilinear coordinates that has these eigenvectors as basis in their tangent space? If it can be done, under what other assumptions or conditions?
If it can only be done locally, then it is good enough.","['differential-geometry', 'multivariable-calculus']"
1312145,Showing $\cos (\arcsin(\cos(\theta))) = \lvert \sin (\theta) \rvert$,"Where does an absolute function should appear and why? Having the following equation: $$ \cos (\arcsin(\cos(\theta))) = \lvert \sin (\theta) \rvert $$
With $ -\frac{\pi}{2} \le \theta \le \frac{\pi}{2}$. I draw a triangle and easily found the following: Defining: $\cos(\theta) \equiv \frac{a}{\sqrt{a^2 + 1}} \\$ then $\arcsin(\cos(\theta)) = \frac{\pi}{2} - \theta$ thus $\cos (\arcsin(\cos(\theta))) = \sin(\theta)$ But why should the absolute value appear and on which phase? How does the absolute value ultimately surrounds the entire expression?",['trigonometry']
1312149,Using an inverse operator to find a particular solution to a differential equation.,"I am just learning about inverse operators in solving a differential equation, but I don't understand exactly how they work. For example, find a particular solution to $$4y''-3y'+9y=5x^2$$ using inverse operators. The above equation is equivalent to $$(4D^2-3D+9)y=5x^2$$ Now the way to solve this would be to use the inverse operator as follows: $$y_p=(4D^2-3D+9)^{-1}5x^2$$
or $$y_p=\frac {1}{4D^2-3D+9}5x^2$$ The book I am reading uses ""simple division"" and arrives at a result, but I don't quite understand how that works. What is a step-by-step method to solve the above problem?",['ordinary-differential-equations']
1312216,Solve $x\frac{dy}{dx}=y(1+\ln y-\ln x)$,"$$x\frac{dy}{dx}=y(1+\ln y-\ln x)$$
I realize that it can be rearranged to make it clear that it's a homogeneous first order differential:
$$\frac{dy}{dx}=\frac yx(1+\ln \frac yx)$$
Using the substitution $v=\frac yx$ and using the chain rule I obtain:
$$x\frac{dv}{dx}+v=v(1+\ln v)$$
$$x\frac{dv}{dx}=v\ln v$$
The differential equation then becomes:
$$\int\frac{dv}{v\ln v}=\int\frac{dx}{x}$$
Is this correct? How do integrate the integral on the left hand side?",['ordinary-differential-equations']
1312226,Prove a combinatorial identity: $ \sum_{n_1+\dots+n_m=n} \prod_{i=1}^m \frac{1}{n_i}\binom{2n_i}{n_i-1}=\frac{m}{n}\binom{2n}{n-m}$,"Prove the combinatorial identity
$$
  \sum_{n_1+\ldots+n_m=n} \;\; 
    \prod_{i=1}^m \frac{1}{n_i}\binom{2n_i}{n_i-1}=\frac{m}{n}\binom{2n}{n-m}, \enspace n_i>0,i=1,\ldots,m
$$
I ""discovered"" this equality during experiments with Maple, but I have no idea how to prove it. It may have a connection with Catalan numbers but that hasn't helped me. UPDATE Now we have brilliant proof of this equality. But may be it have purely combinatorial proof? Or proof with Catalan number's properties?","['catalan-numbers', 'binomial-coefficients', 'combinatorics']"
1312241,Flux through a paraboloid.,"Let S be the surface formed by the part of the paraboloid $z = 1- x^2-y^2$ lying above the $xy$ -plane and let $\vec F= x\hat i + y\hat j+2(1-z) \hat k$ . Calculate the flux of $\vec F$ across S, taking the upward direction as the one for which the flux is positive. Do this in two ways: a) By direct calculation of flux by $\iint_s \vec F .\hat n \;dS$ . b) By computing the flux of $\vec F$ across a simpler surface and using the divergence theorem. I am quite new to multi-variable ,so please bear with me. The problem i am having is for part a) , however i have tried part b) as follow. I know that, $\text{div}\; \vec F=0$ . Hence we can imagine a imaginary surface $x^2+y^2\leq1$ at $z=0$ with normal vector $ \hat k$ And the surface S already present. Combining them to create a closed surface through which flux will be zero as. $\iiint \text{div}\; \vec F . dV=F_1+F_2$ where, $F_1$ is considered as flux through as Paraboloid surface $S$ and $F_2$ is through the circular disc described. So $F_1=-F_2$ . Now, flux through circular disc is inward hence negative. $F_2=-\iint \vec F . \hat k \; dA$ gives $F_2=-\iint 2 . dA= -2\pi$ and $F_1=2 \pi$ . For part a), Here is what i tried, I tried to evaluate this in polar form, firstly i find normal in cartesian to paraboloid, which is given as. $\hat n = \frac{2x \hat i + 2y \hat j + \hat k}{\sqrt{1+4x^2+4y^2}}$ . Computing $\vec F . \hat n = \frac{2x^2+2y^2+2(1-z)}{\sqrt{1+4x^2+4y^2}}=\frac{4(1-z)}{\sqrt{5-4z}}$ , since all this flux is evaluated on $S$ . Now converting this to polar coordinates in 3D $<r\cos \theta \sin \phi , r \sin \theta \sin \phi , r \cos \phi>$ . and $dS=r^2 \sin \phi d\theta d\phi$ . Gives $F_1=\iint_{s}\frac{4(1-r \cos \phi)}{\sqrt{5-4r\cos \phi}}. r^2 \sin \phi d \theta d \phi $ . I tried to solve for $r$ in terms of $\phi$ giving $r=\frac{2}{\sqrt{1+3\sin^2 \phi}+\cos \phi}$ (after removing discontinuity and solving for $r$ by equation of paraboloid, taking positive root.) Add : Here's how i did this, take the equation of paraboloid we get, $r^2 \sin^2 \phi = 1- r\cos \phi$ , And solving quadratic equation in terms of $r$ . Taking the positive root. Since $r$ is independent of $\theta$ our integral becomes. $F_1= 8 \pi \int_{0}^{\pi/2}\frac{1-r \cos \phi}{\sqrt{5-4r \cos \phi}}\times r^2 \sin \phi d\phi $ . This is where i get stuck, I have no idea from here on. If this is relevant, http://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/exams/prac4b.pdf",['multivariable-calculus']
1312245,Norm of the inverse of a tridiagonal,"Let's take a tridiagonal matrix (in general not Toeplitz, nor symmetric) $$L=\begin{pmatrix}a_1 & -b_1 & & & \\ -c_1 & a_2 & -b_2 \\ & -c_2 & \ddots & \ddots\\
& & \ddots\end{pmatrix}$$ and suppose that it's an M-matrix, diagonally dominant, with $a_i,b_i,c_i>0$, $a_i\ge c_{i-1}+ b_i$, ($c_0=b_n=0$) and such that there exists at least an index $i$ with $a_i> c_{i-1}+ b_i$. I'm interested in an upper bound for the infinity norm of the inverse. I already know that if $0<\gamma\le a_i-c_{i-1}- b_i$ for all indexes, then
$$\|L^{-1}\|_{\infty}\le \gamma^{-1}$$
and, more in general, if $w\ge 0$ and $Lw\ge \gamma e$, then
$$\|L^{-1}\|_{\infty}\le \gamma^{-1}\|w\|_{\infty}$$ I also know that for the particular matrix with $a_i=2, b_i=c_i=1$, we have
$$\|L^{-1}\|_{\infty}\le \frac{(n+1)^2}{8}$$ Is there some general result of this kind?
And if the matrix is Toeplitz, there's a rule for the dependence of such a bound to $n^k$ for some $k$? Note: This Link may be useful.","['inverse', 'normed-spaces', 'linear-algebra', 'matrices']"
1312289,Space on which all real-valued continuous functions achieve maximum but not compact?,"A friend is writing a book for non-mathematicians; he has asked me some questions... One possible direction I suggested was whether a topological space (metric space can probably be assumed given what he said) for which every real-valued function achieves its maximum must be compact; and, if not, does this property have a name? He thought this probably did not work, but neither one of us has an example. There is a bookstore nearby which has copies of Counterexamples in Topology as well as Counterexamples in Analysis , and I can go browse them when I'm over jet lag.  Meanwhile, for any students confused by these topics (topology and analysis) or not seeing the motivation, counterexamples are the best way to understand the limitations of a theorem and why it was worth proving in the first place.","['examples-counterexamples', 'big-list', 'general-topology', 'compactness']"
1312304,Expected number of occurences in Poisson process that can stop under certain conditions,"We have a fisherman who catches fish according to a Poisson distribution with $\lambda = 0.6$ fish per hour. The fisherman always fishes for at least $2$ hours. If during these $2$ hours he catches at least $1$ fish, he goes back home, else, he keeps fishing until he catches his first fish and then immediately leaves (we assume that he cannot catch $2$ fish at once, as per a Poisson process). Q. What is the expected number of caught fishes? Let $X_t$ denote the Poisson (counting) process. I made two attempts. Attempt 1 $$
\begin{align*}
\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\right] &= \mathbb{P}(X_2 = 0) \times \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\mid X_2 = 0 \right] \\
&+ \mathbb{P}(X_2 > 0) \times \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\mid X_2 > 0 \right]
\end{align*}
$$ We know that if $X_2 = 0$, then the fisherman will catch only $1$ fish, and if $X_2 > 0$, then he will catch $X_2$ fish. So, we get
$$
\mathbb{P}(X_2 = 0) \times 1 + \mathbb{P}(X_2 > 0) \times \mathbb{E}\left[X_2 \right] \approx 0.3011942 + 0.8385669 = 1.139761
$$ Attempt 2 $$
\begin{align*}
\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\right] &= \mathbb{E}\left[\lim_{t \to +\infty} ((X_t - X_2) + (X_2 - X_0)\right] \\
&= \mathbb{E}\left[X_2 - X_0\right] + \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right]
\end{align*}
$$ Now, $\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right]$ is $1$ if and only if $X_2 = 0$, so $\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right] = \mathbb{P}(X_2 = 0)$. We calculate now
$$
1.2 + \mathbb{P}(X_2 = 0) \approx 1.2 + 0.3011942 = 1.501194
$$ A quick simulation suggests that attempt #2 is correct. However, I do not see why either of these attempts would be incorrect. Could anyone please shed some light?","['probability', 'poisson-distribution', 'stochastic-processes']"
1312315,Vectors that geodesically generate the same surface,"Suppose that $\langle M,g \rangle$ is a complete, simply connected Riemannian symmetric space. The surface geodesically generated by a vector $\xi$ in $T_pM$ is the set of points lying on geodesics passing through $p$ that are orthogonal to $\xi$. Suppose that $\xi$ and $\xi^\prime$ are vectors in $T_pM$ and $T_{p^\prime}M$ respectively that geodesically generate the same surface. Does it follow that the vector obtained by parallel transporting $\xi$ along the geodesic connecting $p$ and $p^\prime$ is proportional to $\xi^\prime$?","['smooth-manifolds', 'semi-riemannian-geometry', 'riemannian-geometry', 'general-relativity', 'differential-geometry']"
1312320,$\mathbb{C}$ is a one-dimensional complex vector space. What is its dimension when regarded as a vector space over $\mathbb{R}$?,"$\mathbb{C}$ is a one-dimensional complex vector space. What is its dimension when regarded as a vector space over $\mathbb{R}$? I don't understand how $\mathbb{C}$ is one-dimensional. Please help me understand that. Also, I'm pretty sure that when the field is reals we have $\dim(\mathbb{C})=2$. Since when $\alpha$ is real and $z=a+bi$ is complex we have $\alpha z=\alpha a+\alpha bi=\alpha a(1,0)+\alpha b(0,i)$. How does this look? Any solutions or help is greatly appreciated.","['linear-algebra', 'complex-numbers']"
1312367,Show that $3$ is not a prime in $\mathbb Q[\sqrt{7}]$,"Question: Show that $3$ is not a prime in $\mathbb Q [\sqrt 7] $. To show this, should I start by assuming that $3 = ab$ where $a$ and $b$ are integers in $\mathbb Q[\sqrt{7}]$ and then try to show they are not units? What should I do to show that? Or is there another better way to do this problem?","['abstract-algebra', 'number-theory', 'quadratics']"
1312387,General solution of Transport equation,"General solution of Transport equation (homogeneous): Method of Characteristics $$u_t+cu_x=0 (\star)$$ We know that if $f: \mathbb{R} \to \mathbb{R}$ is differentiable  then $u(x,t)=f(x-ct)$ is a solution of $(\star)$. We will show that each solution of $(\star)$ is of the form $u(x,t)=f(x-ct)$, where $f$ is an arbitrary differentiable function, $f: \mathbb{R} \to \mathbb{R}$. We consider the lines $\epsilon_a: x-ct=a, a \in \mathbb{R}$. We define the function $z(s)=u(x(s),t(s))$, where $x(s)=cs+a$, $t(s)=s$. Then $(x(s), t(s)) \in \epsilon_a \forall s \in \mathbb{R}$.
Let $u$ be a solution of $(\star)$ and for this $u$ I define $z(s)$ as previously. Then $z'(s)=c u_x+ u_t=0$, i.e. $z(s)=\beta \forall s \in \mathbb{R}$. $u(x(s),t(s))=z(s)=z(0)=u(a,0)=u(x(s)-ct(s),0) \forall s$ Thus $u(x,t)=u(x-ct,0)=:f(x-ct)$, where $f: \mathbb{R} \to \mathbb{R}$ is differentiable. I am looking at the following exercise: Find the general solution of the non-homogeneous  Transport equation $u_t+cu_x=g(x,t)$ where $g$ is ""smooth"" (how smooth?) and using the above find the general solution of the wave equation. Hint : We work as previously : $z'(s)=g(x(s),t(s))$. So in this case do we know that $u(x,t)=f(x-ct)$ is again a solution of the given equation? Or do we have to consider an other solution and show that all the solutions are of this form?","['wave-equation', 'ordinary-differential-equations']"
1312390,"Trigonometry in triangle, can't understand an example from my textbook","I'm stuck with this from a few hours. There is an exercise in my textbook, which is solved and it's must be used as an example, however  I can't understand it. Here's the exercises + how it's solved.
Given that:
$$
\alpha + \beta + \gamma = \pi 
$$
proof that
$$
\sin(\alpha) + \sin(\beta) + \sin(\gamma) = 4 * \cos\left(\frac{\alpha}{2}\right)\cos\left(\frac{\beta}{2}\right)\cos\left(\frac{\gamma}{2}\right)
$$ Solution from my textbook:
$$
\sin(\alpha) + \sin(\beta) + \sin(\gamma) = 2*\sin\left(\frac{\alpha+ \beta}{2}\right)*\cos\left(\frac{\alpha-\beta}{2}\right) + \sin(\pi - (\alpha + \beta))
$$
$$
= 2*\sin\left(\frac{\alpha+ \beta}{2}\right)*\cos\left(\frac{\alpha-\beta}{2}\right) + 2*\sin\left(\frac{\alpha+\beta}{2}\right)*\cos\left(\frac{\alpha+\beta}{2}\right) 
$$
$$
= 2*\sin\left(\frac{\alpha+ \beta}{2}\right)*\left(\cos\left(\frac{\alpha-\beta}{2}\right) + \cos\left(\frac{\alpha+\beta}{2}\right)\right)
$$
$$
= 4 * \sin\left(\frac{\pi -\gamma}{2}\right) * \cos\left(\frac{\alpha}{2}\right) * cos\left({\frac{\beta}{2}}\right) 
$$
$$
= 4 * \cos \left(\frac{\alpha}{2}\right) * \cos\left(\frac{\beta}{2}\right) * \cos\left(\frac{\gamma}{2}\right)
$$ The thing I can't understand is how from 
$$
\sin(\pi - (\alpha + \beta))
$$ Become $$
2*\sin\left(\frac{\alpha+\beta}{2}\right)*\cos\left(\frac{\alpha+\beta}{2}\right) 
$$ I think this is the formula for 
$$
\sin(2*\alpha)
$$","['triangles', 'trigonometry']"
1312407,Show that every subspace of $\mathbb{R}^n$ is closed [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Show that every subspace of $\mathbb{R^n}$ is closed. I'm not sure how to do this or even what closed means. I don't even have a starting point. Any hints or solutions are greatly appreciated.","['analysis', 'linear-algebra', 'real-analysis', 'general-topology']"
1312410,Proving a limit of a constant function,"Using the definition, prove that $\lim\limits_{x \to 10} 5 = 5$ Solution: when I apply the definition, i get this $0< |x - 10| < \delta \Rightarrow |5 - 5 | < \epsilon \Rightarrow 0 < \epsilon$ $0 < \epsilon \Rightarrow |x - 10| < \epsilon$ ,and $|x - 10| < \delta$ So i can take  $\delta = \epsilon$, or less Than $\forall \epsilon, \epsilon >0, \exists \delta = \epsilon; \forall x \in D_f: 0< |x - 10| < \delta \Rightarrow |5 - 5 | < \epsilon $ Is it correct?",['limits']
1312420,Translation invariant event in percolation theory in $\mathbb{Z}^d$,"At my probability theory proseminar I had a speech about the percolation theory and one of the topics I presented was the uniqueness of an infinite open cluster in Bernoulli bond percolation in $\mathbb{Z}^d$. However, I had real problems with proving that N (the number of infinite open clusters) is constant a.s. I tried using Kolmogorov's 0-1 law, but it only tells us that $\mathbb{P}_p(N \geq 1) \in \{0, 1\}$. My speech was mainly based on Grimmett's Probability on Graphs ( http://www.statslab.cam.ac.uk/~grg/books/USpgs-rev3.pdf , theorem 5.22). The proof says that $\{N = c\}$ is a translation-invariant event, therefore $\mathbb{P}(N = c) \in \{0, 1\}$ for any $c$, but I don't understand why is the sample space $\Omega$ in a product form. In fact, the codomain of a stochastic process representing the percolation model is $\{0, 1\}^{\mathbb{E}^d}$ and this is in a product form, $\textbf{not}$ the $\Omega$ itself. This makes me even more confused, since I'm a complete greenhorn in ergodic theory. I will highly appreciate any kind of explanation or reference to some more elaborate work in this context.","['probability-theory', 'ergodic-theory', 'percolation']"
1312512,Find an inner product that makes a given set of linearly independent vectors orthogonal,"I need to find an inner product such that given a set $S$ of linearly independent vectors in a Hilbert space $H$, $S$ will be orthogonal with these product. I thought Gram -Schmidt Process would help but it's not, because for the process you already have the inner product.","['hilbert-spaces', 'inner-products', 'linear-algebra', 'functional-analysis']"
1312513,Properties of polynomials that are polynomial conditions on the coefficients,"There are many occasions where we can check whether a (set of) polynomial(s) $f_i$ satisfies certain properties, simply by evaluating a fixed polynomial on the coefficients of the $f_i$. Many times, the proofs of these results are based on deep theorems from algebraic geometry and other areas, that is, they are in no way trivial. My question is for you to please: $\quad \quad$ Question 1: Provide examples like these with (possibly) their proofs. Also, I would like to know whether $\quad \quad$ Question 2: Is there a more uniform way to view, understand, or expect, these phenomena, in terms of Algebraic Geometry (or something else entirely) ? We can start the list with the following theorems: _____________________________________________________________________ A polynomial $$f=a_nx^n+a_{n-1}x^{n-1}+\cdots +a_1x+a_0$$ has multiple roots if and only if the $n^{\text{th}}$-degree Discriminant $\Delta_n$ is $0$ for the coefficients $a_i$. For instance for $f=ax^2+bx+c$, we have $\Delta_2=b^2-4ac$. Proof: The discriminant $\Delta_n$ is a polynomial on the coefficients $a_i$. This is a special case of the next part as $\Delta(f)$ is really the resultant Res$(f,f')$. _____________________________________________________________________ A set of $n$ polynomials $\{f_1,\cdots,f_n\}$, in variables $x_1,\cdots,x_n$, of given degrees $(d_1,\cdots,d_n)$ have a common root if and only if their Resultant is $0$:
$$\operatorname{Res}(f_1,\cdots,f_n)=0$$ Proof: The fact that the resultant is a polynomial of the coefficients of the $f_i$'s can be proven via elementary methods but a more enlightening path relates it to the ""Main result of Elimination Theory"" : Theorem : (Projective Extension Theorem) Given a variety $W\subset \mathbb{C}^M\times\mathbb{P}^n$ and the projection map $\pi: \mathbb{C}^M\times\mathbb{P}^n\rightarrow \mathbb{C}^M$, the image $\pi (W)$ is a variety in $\mathbb{C}^M$. Here, the idea is for $\mathbb{C}^M$ to represent the space of all sets of polynomials $\{f_i\}$ (via their coefficients) and $\mathbb{P}^n$ the values for the $x_i$ (after homogenizing maybe). Then, define $W$ as the pairs $\big( \{f_i\},{\bf x}\big)$ such that $f_i({\bf x})=0\ \forall i$. It is easy to see that $W$ is indeed a variety (its equation is just the (polynomial) evaluation of the $f_i$'s at ${\bf x}$). The theorem states that the image $\pi(W)$ (which corresponds to $f_i$'s having at least one non-trivial common root) is again a variety; that is, it is cut by a polynomial equation in $\mathbb{C}^M$, the space of polynomials, parametrised by their coefficients. _____________________________________________________________________ A polynomial $f$ on $n$ variables $x_i$ and of degree $r$ is reducible, that is can be written as a product $$f(x_1,\cdots,x_n)=g(x_1,\cdots,x_n)\cdot h(x_1,\cdots,x_n)$$ of polynomials $h$ and $g$ of smaller degree. Proof : I am not aware of any name for the resulting polynomial(s) on the coefficients of $f$. The proof uses the following corollary to the Projective extension theorem: Corollary : [Eisenbud, Cor. 14.2] The image of a projective variety under a morphism is closed; more precisely if $Y$ is a projective variety over a field $k$, and $\pi: Y\rightarrow X$ is a $k$-morphism to a projective variety $X$, then $\pi (Y)$ is a closed subset of $X$ in the Zariski topology. The idea is to consider the varieties $W_i$ that are formed by all (homogeneous) polynomials of degree $i$. Then, there is a map $W_i\times W_{n-i}\rightarrow W_n$ where we send $(f,g)$ to their product $f\cdot g$. This map is clearly a morphism (since multiplication of polynomials is a polynomial map on the coefficients). The image then, corresponds to polynomials that can be written as a product of a degree $i$ and a degree $n-i$ polynomials. The aforementioned corollary implies then that the image is closed, hence given by polynomial equations (for details see section $\S$14.1 in Eisenbud's very beautiful Commutative Algebra with a view to a kill ). _____________________________________________________________________ A system of polynomials $(f_1,\cdots,f_n)$ is algebraically dependent, that is, there exists a polynomial $h\in \mathbb{C}[z_1,\cdots,z_n]$ such  that $$h(f_1,\cdots,f_n)=0$$ Proof : The proof for this is the celebrated Jacobian criterion which states that the $f_i$ are algebraically dependent if and only if $$\operatorname{Jac}(f_1,\cdots,f_n)=0$$ where, of course, the jacobian polynomial being $0$ translates to certain polynomials on the coefficients of the $f_i$'s being $0$. See for instance $\S$3.10 in Reflection Groups and Coxeter Groups by Humphreys, or the answer here , or the mathoverflow post here . _____________________________________________________________________ A set of homogeneous polynomials $\big\{f_1({\bf x}),\cdots, f_n({\bf x})\big\}$, of given degrees $d_1,\cdots,d_n$, is a homogeneous system of parameters (h.s.o.p.) for the ring $\mathbb{C}[x_1,\cdots,x_n]$, or equivalently, the map $$\begin{alignat*}{1} \mathbb{C}^n&\rightarrow \mathbb{C}^n \\ {\bf x}:=(x_1\cdots,x_n) &\rightarrow \big(f_1({\bf x}),\cdots, f_n({\bf x})\big) \end{alignat*}$$ is a finite morphism , or equivalently, the only preimage (for the map above) of the origin is the origin, i.e. $${\bf f}^{-1}({\bf 0})={\bf 0}$$ Proof : The proof here is more difficult. First notice that being a h.s.o.p. means that the algebra $\displaystyle \mathbb{C}[x_1,\cdots,x_n]/(f_1,\cdots,f_n)$ is finite dimensional (as a vector space). Therefore, a tuple $(f_1,\cdots,f_n)$ forms a h.s.o.p. iff all but finitely many of the monomials $x_1^{a_1}\cdots x_n^{a_n}$ are in the ideal generated by the $f_i$'s. For that matter, it is enough for the ideal $(f_1,\cdots,f_n)$ to contain all the monomials of some degree $N$. Now, this can be phrased as the existence of a solution to a linear system involving the coefficients of the $f_i$'s but we need to know a suitable $N$. To the rescue comes the following characterization for regular sequences of homogeneous polynomials (notice that in our setting, a maximal regular sequence of homogeneous polynomials and a h.s.o.p. mean the same thing since $\mathbb{C}[x_1,\cdots,x_n]$ is a regular (homogeneous-)local ring): Theorem : [Stanley: Hilbert functions of graded algebras , Corol. 3.2] A tuple of homogeneous polynomials $(f_1,\cdots,f_n)$ is a regular sequence for the ring $\mathbb{C}[x_1,\cdots,x_n]$ if and only if the Hilbert series of the quotient is given by: $$\operatorname{Hilb}\big(\mathbb{C}[x_1,\cdots,x_n]/(f_1,\cdots,f_n),q \big)= \prod_{i=1}^n \frac{q^{d_i}-1}{q-1}$$ where $d_i:=\operatorname{deg}(f_i)$. Therefore, the smallest $N$ for which $(f_1,\cdots,f_n)$ must contain all monomials of degree $N$ is $$N=\sum (d_i-1)+1$$ Remark : Actually, for a tuple of (not necessarily homogeneous) polynomials, to be a regular sequence, is also a polynomial property on the coefficients but I do not have a reference for a proof of that. (?) _____________________________________________________________________","['systems-of-equations', 'algebraic-geometry', 'commutative-algebra', 'polynomials']"
1312528,"If $I$ is a maximal ideal in $R$, $(I,x)$ is a maximal ideal in $R[x]$","Click Link to Original Text Let $R$ be a commutative ring with $1$, and $I$ is an ideal of $R$.  Then, $(I) = I[x]$ is an ideal in $R[x]$.  I was able to prove, via first isomorphism, that $\frac{R[x]}{(I)}$ is isomomorphic to $\frac{R}{I}[x]$.  It follows that if $I$ is a prime ideal, then $(I)$ is a prime ideal in $R[x]$. Then the author noted that, if $I$ is maximal, it does not mean that $(I) = I[x]$ is maximal.  If my understanding is correct, it is because while $R/I$ is a field, $\frac{R}{I}[x]$ may still only be an integral domain.  Finally, the author added that $(I, x)$ is a maximal ideal in $R[x]$.  What does the notation $(I, x)$ stand for?","['abstract-algebra', 'ring-theory']"
1312568,Ring theory associates,"Can someone please give me an example of of this definition, as I am finding it hard to get my head around or even understand what an ""associate"" is. Let $R$ be a commutative ring with unity. Elements $a$ and $b$ are called associates in $R$ if $b =ua$ for some unit $u$  of $R$. My notes don't provide an example. Can someone please explain it further or even better show me an example of this definition? Much appreciated. Thank you.","['abstract-algebra', 'ring-theory']"
1312577,It is possible to demonstrate the taylor's formula (Peano) with the taylor's formula (Lagrange)?,"I wonder if it is possible demonstrate the taylor's formula in the peano form of the reminder with the taylor's formula in the lagrange formula of the reminder. In symbols:
\begin{equation}f(x)-F(x)=\frac{f(\xi)}{n!}(x-x_0)^n\implies f(x)-F(x)=o(x-x_0)^n \end{equation} with F(x) the taylor's series. I've tried different times but I have not been able to demonstrate.","['taylor-expansion', 'analysis', 'calculus', 'real-analysis']"
1312582,Blow-up of pair of intersecting lines,"I have the reducible variety $X=\mathbb{V}(x_1x_2)\subset\mathbb{A}^2$, which is a pair of lines intersecting transversely, and I would like to compute the blow-up at the origin. The Rees ring of the ideal $(x_1,x_2)\subset k[x_1,x_2]/(x_1x_2)$ is the graded ring $$R:=\frac{k[x_1,x_2]}{(x_1x_2)}\big[x_1t,\,x_2t\big],$$ where $\deg(t)=1$ and $\deg(x_1)=\deg(x_2)=0$. The blow-up of $X$ is $\mathrm{Proj}(R)$. On the affine patch $x_1t\neq 0$, the ring of functions on the blow-up is the degree $0$ piece of $R[1/(x_1t)]$, which is generated (as a $k$-algebra) by $x_1$ and $\frac{x_2}{x_1}$. The relation $x_1x_2=0$ can be written in terms these generators: $x_1x_2=x_1^2\frac{x_2}{x_1}$, so the affine patch $x_1t\neq 0$ is isomorphic to
$$
\mathrm{Spec}\;\frac{k\left[x_1,\frac{x_2}{x_1}\right]}{(x_1^2\frac{x_2}{x_1})}=\mathrm{Spec}\;\frac{k[a,b]}{(a^2b)},
$$
where I have written $a=x_1$, $b=\frac{x_2}{x_1}$. This is a problem, because the blow-up of something reduced should still be reduced and this isn't. Where did I go wrong?","['blowup', 'algebraic-geometry']"
1312613,Is it so easy to show a locally bounded function with holomorphic cross sections is holomorphic?,"Let $f: U \rightarrow \mathbb{C}$ where $U$ is open in $\mathbb{C}^n$ and suppose every coordinate cross section of $f$ is holomorphic (I hope that's not too colloquial). I've heard it's a somewhat deep theorem that this is enough to imply f is continuous, and therefore holomorphic as a function of n variables.  However when one uses Cauchy's formula (in one variable) to get a power series expansion of $f$ in a neighborhood of a point, one seems only to use that $f$ is locally bounded (so one can bound the values of f on the distinguished boundary of a polydisc). Is that correct? I.e. does {locally bounded} + {holomorphic cross sections} so easily imply holomorphic or have I made a mistake?","['analysis', 'several-complex-variables', 'complex-analysis']"
1312626,what is the maximum number of edges in a graph with self-loop?,"If we have a graph G with n nodes, what is the maximum number of edges in this graph if we allow self-loop, is it n^2 and why, please look at the graph bellow: N=4, is maximum number of edges=16 or 10 I found it is 10 ?","['graph-theory', 'discrete-mathematics']"
1312631,Trigonometric Differentiation. Height of a wave.,"The movement of the crest of a wave is modelled with the equation $h(t)=0.3\cos 3t+0.4\sin 3t$. Find the maximum height of the wave and the time at which it occurs. I have come up until here. please tell me if I did it right or wrong and how do I find the time the maximum height is at? $$h(t) = 0.3 \cos 3t + 0.4 \sin 3t $$ To find the maximum or minimum, take the first derivative 
and equate it to 0. $$\begin{align*} \frac{dh}{dt} &= -0.3*3 \sin 3 t +0.4 * 3 \cos 3t \\
\tan 3t &= 1.2/0.9 \\ 
3t &= 53.06\end{align*}$$ The maximum value is $$h(t) = 0.3 \cos(53.06) + 0.4 \sin(53.06)=0.487 $$
This is the maximum. Thanks in advance.","['derivatives', 'trigonometry']"
1312644,How to prove that the module of characteristic function is less than one,"I would like to know if my resolution is right... I want prove that $|\varphi(t)| = \vert\mathbb{E}[e^{i t X}]\vert\leq 1$ , $\forall t \in \mathbb{R}$ . $\it{proof:}$ First, note that $|\mathbb{E}[e^{i t X}]| \leq \mathbb{E}[|e^{i t X}|]$ . But, on the other side, we know that $|e^{i t X}| = |\cos(tX)+ i \sin(tX)| = 1$ . Then, $\mathbb{E}[|e^{i t X}|] = {\displaystyle\int_{\Omega}1dP} = P(\Omega) = 1$ . So, $|\varphi(t)| = \vert\mathbb{E}[e^{i t X}]\vert\leq  \mathbb{E}[|e^{i t X}|] = 1$","['characteristic-functions', 'probability']"
1312645,Expected value of area of triangle,"Here is the problem: Let $A$ be the point with coordinates $(1, 0)$ in $\mathbb R ^2$. Another point $B$ is chosen randomly over the unit circle. What is then the expected value of the area of the triangle $OAB$ ? What I do is to define a random variable $X$, which is the angle $AOB$ and assume that it is uniformly ditributed between $0$ and $\pi$. Then the random variable $Y = \frac{\sin X}{2}$ is the area of the triangle. Unfortunately I don't know how to calculate it's expected value (or even it's distribution). Can someone help me with this ? Thanks in advance!","['area', 'expectation', 'random-variables', 'triangles', 'probability']"
1312662,"How to Prove It, Exercise 6.5.9","Suppose $R$ is a relation on $A$ and $S$ is the transitive closure of $R$. If $(a, b) \in S$, then there is some positive integer $n$ such that $(a, b) \in R^n$, and therefore by the well-ordering principle, there must be a smallest such $n$. We define the distance from $a$ to $b$ to be the smallest positive integer $n$ such that $(a, b) \in R^n$, and we write $d(a, b)$ to denote this distance. (a) Suppose that $(a, b)$ and $(b, c)$ (and therefore $(a, c) \in S$ since $S$ is transitive). Prove that $d(a, b) \leq d(a, b) + d(b, c)$. (b) Suppose $(a, c) \in S$ and $0 < m < d(a, c)$. Prove that there is some $b \in A$ such that $d(a, b) = m$ and $d(b, c) = d(a, c) - m$. Here are my attempts at proving the above. Are they correct? Proof of (a): Let $d(a, b) = m$ and $d(b, c) = n$. Then $(a, b) \in R^m$ and $(b, c) \in R^n$. Therefore $(a, c) \in R^n \circ R^m = R^{n + m}.$ Let, $$
T = \{ q : (a, c) \in R^q \}.
$$ Then it follows that $m + n \in T$. Since the smallest element of $T$ is $d(a, c)$ we must have that, $$
d(a, c) \leq m + n = d(a, b) + d(b, c). \square
$$ Proof of (b): Let $n = d(a, c)$. Then $(a, c) \in R^n = R^{n - m} \circ R^m$. This means that there exists a $b \in A$ such that $(a, b) \in R^m$ and $(b, c) \in R^{n - m}$. Hence $d(a, b) \leq m$ and $d(b, c) \leq n - m$. We also have from part (a) that, $$
d(a, c) \leq d(a, b) + d(b, c).
$$ Now suppose that $d(a, b) < m$. Then we would have, $$
d(a, c) \leq d(a, b) + d(b, c) < m + n - m = n
$$ which is impossible since $d(a, c) = n$. So $d(a, b) = m$. Similarly, if we suppose that $d(b, c) < n - m$ we are led to the contradiction that $d(a, c) < n$. Hence, $d(b, c) = n - m$. So there is some $b \in A$ such that $d(a, b) = m$ and $d(b, c) = d(a, c) - m$. $\square$ I think the proof of part (a) is correct but I'm not so sure about part (b). The reason I think part (b) might not be correct is that this exercise is from the chapter on induction and I haven't used induction in the proof.","['elementary-set-theory', 'proof-verification', 'relations', 'proof-writing']"
1312663,Gradient of an absolute value [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question What is the gradient of $|\vec{x}|^2$? Is it simply $2\vec{x}$, or does the answer get expressed using absolute value notation?","['multivariable-calculus', 'derivatives']"
