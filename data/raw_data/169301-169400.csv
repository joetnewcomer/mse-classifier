question_id,title,body,tags
2976009,"Does the functor $V\mapsto V^{**}/V$ (for $\dim V=\infty$) reflect monomorphisms, epimorphisms or isomorphisms?","Let $\textbf{Vect}_\infty$ be the category of infinite dimensional vector spaces (over some fixed ground field), and consider the endofunctor $F$ of $\textbf{Vect}_\infty$ whose effect on objects is given by $F(V):=V^{**}/V$ , and whose effect on morphisms is the obvious one. (Here $V^{**}/V$ is the cokernel of the canonical monomorphism $V\to V^{**}$ .) Does $F$ reflect monomorphisms? Does it reflect epimorphisms? Does it reflect isomorphisms? (Recall the $F$ reflect monomorphisms if the condition that $F(f)$ is a monomorphism implies that $f$ is also a monomorphism. The reflections of epimorphisms and isomorphisms are defined similarly.)","['linear-algebra', 'category-theory', 'functors']"
2976010,How to solve the differential equation $(1 + t^2) \dot{y} = 2yt + t^2 + t^4$?,"I have the following differential equation that I try to solve: \begin{equation}
(1 + t^2) \dot{y} = 2yt + t^2 + t^4
\end{equation} what I do is to first put all $t$ 's on one side: \begin{equation}
\dot{y} =   \frac{2yt + t^2 + t^4}{1+t^2}
\end{equation} and then to integrate both sides \begin{equation}
\int \dot{y} dy = \int \frac{2yt + t^2 + t^4}{1+t^2} dt
\end{equation} and well now I am stuck because I don't really know how to evaluate these complex integrals. I think I should use the method by parts but whenever I try I think I am making mistake somewhere and I am not sure if my steps up till now are correct as well.","['integration', 'ordinary-differential-equations']"
2976028,Formal proof of the sequence involving double factorials $x_n = \frac{(2n)!!}{(2n-1)!!}$ is not bounded.,"I'm trying to prove the following: Let $n\in \mathbb N$ and $$ 
x_n = \frac{(2n)!!}{(2n-1)!!}
$$ Where: $$
(2n)!! = 2\cdot 4 \cdot 6 \cdot \dots \cdot 2n \\
(2n - 1)!! = 1\cdot 3 \cdot 5 \cdot \dots \cdot (2n-1)
$$ Prove $\{x_n\}$ is not bounded. Intuitively it feels like it is unbounded. Let's consider the following fraction: $$
x_n = \frac{2\cdot 4 \cdot 6 \cdot \dots \cdot (2n)}{1\cdot 3 \cdot 5 \cdot \dots \cdot (2n-1) }
$$ Now if we consequently take a number from nominator and denominator we get: $$
\frac{2}{1} > 1 \\
\frac{4}{3} > 1 \\
\frac{6}{5} > 1 \\
\dots \\
\frac{2n}{2n-1} > 1
$$ So the fraction is a product of rational numbers each of which is greater than $1$ and the product of rational numbers greater than $1$ is increasing. I've tried to formalize that by expanding $(2n)!!$ and $(2n-1)!!$ : $$
(2n)!! = (2n)(2n-2)(2n-4)\cdots(4)(2) = 2^kn!\\
(2n-1)!! = (2n-1)(2n-3)\cdots(5)(3)(1) = \\
= \frac{(2n-1)(2n-2)(2n-3)\cdots(5)(4)(3)(2)(1)}{(2n-2)(2n-4)\dots(4)(2)} = \\
\frac{(2n-1)!}{2^{n-1}(n-1)!}
$$ So using the above: $$
x_n = \frac{2^nn!2^{n-1}(n-1)!}{(2n-1)!} = \frac{2^{2n-1}n!(n-1!)}{(2n-1)!}
$$ Here is where I got stuck. How do i proceed with the proof using some constant $M$ and some number $N > n$ such that $x_N > M$ ? Should i introduce some inequality? I've seen a similar question, but the sequence there is proven to be divergent which i guess is more a calculus concept (yet very similar to (un)boundedness), and i'm in search of a precalculus solution.","['algebra-precalculus', 'factorial', 'upper-lower-bounds', 'sequences-and-series']"
2976036,Most efficient strategy for guessing outcome of (fair) dice roll?,"I'm starting to learn about information theory and I'm a bit stuck on this one. here's what I have so far: 1 possible strategy is to simply ask 'did outcome 1 occur?' if yes then we have our answer, if no we ask again 'did outcome 2 occur' etc. for a dice, the maximum number of questions with this strategy would be 5, since if for 1 - 5 the answer is no, that must mean that the outcome 6 must be positive. Based on my calculation, the average number of questions using this strategy is 2.5 (sum from 1 to 5 of $Q/6$ , where Q is number of questions and 1/6 is the probabilty of rolling any of the faces on the dice). Another strategy I thought of would be to split the probabilties – i.e. is the outcome even? if yes, we could ask 'is it greater than 3?' and then we either have the outcome (6) or we ask 'is it 4?' and from here we have a definitive answer. Likewise for the case of the first answer being no i.e. the number is odd. I struggled to calculate the average number of questions for this. My logic was we must ask at least 2 questions for the answer to be fully determined. So, we must ask 1 question and then the outcome of the second question is subject to probabilty. Hence the average number of questions is: $1+(2/6)+(3/6)=1.83333...$ Is this right? Is my logic correct? Are there any other strategies worth looking at? I'm really enjoying imformation theory and am really keen to learn more more more!","['dice', 'probability', 'information-theory']"
2976115,"Proof by induction of n-dimensional isoperimetric inequality, missing step.","I was looking for a simple proof by induction of the isoperimetric inequality, the work of Emmanuel Tsukerman gives a promising approach. There is however one line where I cannot follow the reasoning, here is an excerpt of the proof (page 4 in the link above) Theorem 1. (Classical Isoperimetric Inequality) For any body $K$ with n-dimensional volume $|K|$ and surface area $|\partial K|$ , $$\frac{|K|^{n-1}}{|\partial K|^n}\le\frac{|B^n|^{n-1}}{|\partial B^n|^n}$$ Proof. The base case of $n=1$ is straightforward, since the boundary $\partial K$ of a closed interval has volume $|\partial K|=2$ (the counting measure for two boundary points of a line segment) and so does the boundary of the ball. Assume by induction that the inequality holds for dimension $n-1$ . Let $K\subset \mathbb R^n$ and $\partial K$ its boundary. Without loss of generality, we may assume that $|K|=|B^n|$ . Define $K_t=K\cap \{x_n=t\}$ and $\partial K_t=\partial K\cap \{x_n=t\}$ . Finally, let $V(t)=|K_t|$ and $A(t)=|\partial K_t|$ . Note that because each $K_t$ is a parallel slice, $\int V(t)\mathrm dt =|K|$ . Then $$V'(t)=\int_{\partial K_t}\frac{1}{\tan\theta}$$ where $\theta$ denotes the angle formed by the $x_n$ -axis and the unit normal vector to $\partial K$ . What is the reasoning behind the following line? $$V'(t) = \int_{ \partial K_t} \frac{1}{\tan \theta} $$ where $\theta$ denotes the angle formed by the $x_n$ -axis and the unit normal vector to $\partial K$ .","['integration', 'proof-explanation', 'induction', 'real-analysis', 'trigonometry']"
2976133,Sensitivity of Lebesgue measure of level sets,"Assume we are given some constant $\alpha$ and a subset $\Omega\subset\mathbb{R}^n$ such that $\lambda(\Omega)<\infty$ , where lambda denotes the Lebesgue measure. We consider the mapping $$
\Lambda:L^1(\Omega)\to\mathbb{R}
$$ with $$
\Lambda(f)=\lambda(\{x\in\Omega: f(x)>\alpha\}).
$$ I am trying to figure out a way to control the error sensitivity of this problem. If the function values are close to $\alpha$ , then a small perturbation of the function could dramatically change the measure. Any suggestions as to what tools I could use would be greatly appreciated. Thanks","['measure-theory', 'functions', 'lebesgue-measure', 'functional-analysis']"
2976134,Minimum Value question.,"$\text{Problem:}$ If, $A+B+C=90°$ then find the minimum value of $13\tan^2(A)+9\tan^2(B)+\tan^2(C)$ . My Approach: I kind of started by using and applying the $\text{AM-GM}$ inequality repeatedly but that didn't really help me out. Then I referred to the solution given in the Book, it stated that the minimum value of the given equation will be the $t\sqrt{2}$ where $t$ is the root of the equation $2t^2-45t+234=0$ . But, I wasn't able to understand how was this expression obtained. I've a feeling that it's an extensive application of the $\text{AM-GM}$ inequality, but who knows, I may be wrong. So, I request you all to help me out.","['optimization', 'trigonometry']"
2976151,Solve $\int_0^s \left[ 1-\int_{-\infty}^{\infty} \frac{e^{-\frac{y^2}{2}}}{\sqrt{2 \pi}} \tanh\left( x-\sqrt{x}y \right)dy \right] dx$,Let $$ f(x) = 1-\int_{-\infty}^{\infty} \frac{e^{-\frac{y^2}{2}}}{\sqrt{2 \pi}} \tanh\left( x-\sqrt{x}y \right)dy. $$ I would like to understand how to get to the solution of the following integral: $$ g(s)=\frac{1}{2}\int_0^s f(x) dx = s-\int_{-\infty}^{\infty} \frac{e^{-\frac{y^2}{2}}}{\sqrt{2 \pi}} \ln\cosh\left( s-\sqrt{s}y \right)dy $$ I know that $$ \frac{d}{dx} \ln\cosh\left( x-\sqrt{x}y \right) = (1-\frac{y}{2\sqrt{x}})\tanh(x-\sqrt{x}y)$$ So far I tried the following: $$ \begin{align} g(s) &= \frac{s}{2} - \frac{1}{2}\int_{-\infty}^{\infty} \frac{e^{-\frac{y^2}{2}}}{\sqrt{2 \pi}} \int_{0}^s (1-\frac{y}{2\sqrt{x}}+\frac{y}{2\sqrt{x}}) \tanh\left( x-\sqrt{x}y \right)dx dy \\ &= \frac{s}{2} -\frac{1}{2}\int_{-\infty}^{\infty} \frac{e^{-\frac{y^2}{2}}}{\sqrt{2 \pi}} \ln\cosh\left( s-\sqrt{s}y \right)dy + \frac{1}{2}\int_{-\infty}^{\infty} \frac{ye^{-\frac{y^2}{2}}}{\sqrt{2 \pi}} \int_{0}^s \frac{\tanh\left( x-\sqrt{x}y \right)}{2\sqrt{x}} dx dy\end{align} $$ But I'm stuck there. The first part equals $1/2$ times the solution. Maybe I should use some substitution in the remaining integral?,['integration']
2976154,Probability that the triangle is acute,A triangle is formed by randomly choosing three distinct points on the circumference of a circle and joining them. What is the probability that the formed triangle is an acute triangle?,"['geometric-probability', 'geometry', 'probability']"
2976168,What is the number of different ways to seat 15 students where no two students of the same group are next to each other?,"Question: There are 15 different students: 4 students of group A, 5 students of group B and 6 students of group C. What is the number of different ways to seat these students into a row of seats where no two students of the same group are next to each other ? I tried to seat the students of group C first: $$-C-C-C-C-C-C-$$ Then I would put the students of group A and B into the spaces. I tried 2A (2 students from group A) on both ends, A on one end and B on one end, only A on one end, etc, then decide how many students of each group to put in the middle spaces. There is so many different possibilities that I thought there could be a better way. Do you have any idea? Thanks in advance. Solution Let's count the number of strings containing 4 letter A, 5 letter B and 6 letter C. To begin with, let's set up the $C$ s: $$*C-C-C-C-C-C*$$ There are $7$ gaps: $5$ obligatory $(-)$ gaps and $2$ optional $(*)$ gaps. Now we shall fill in the gaps with $A$ s first and $B$ s later. The $A$ s can't stand next to one another but have some $B$ s separate them. Consider some cases: Case 1: $ABABABA$ and $2$ spare $B$ s. Obviously this is not enough to fill in $5$ $(-)$ gaps Case 2: $ABABA$ , $A$ and $3$ spare $B$ s. Just enough to fill in $5$ $(-)$ gaps: 1 for $ABABA$ , $1$ for $A$ and remaining $3$ for $B$ s. There are ${5 \choose 1} \cdot {4 \choose 1} = 20$ strings. Case 3: $ABA$ , $ABA$ and $3$ spare $B$ s. Just enough to fill in $5$ $(-)$ gaps: $2$ for $ABA$ and $3$ remainings for $B$ s. There are ${5 \choose 2} = 10$ strings. Case 4: $ABA$ , $A$ , $A$ and $4$ spare $B$ s. We have more than enough to fill in the $(*)$ gaps now, with $3$ options: Option 1 : Fill in $2$ $(*)$ : Just enough for $7$ gaps: $1$ for $ABA$ , $2$ for $A$ s and $4$ remainings for $B$ . There are ${1 \choose 7} \cdot {2 \choose 6} = 105$ strings. Option 2 : Fill in $1$ $(*)$ , we have $3$ more sub-options: Fill it with $ABA$ . To fill the $5$ $(-)$ s: $2$ for $A$ s and $3$ remaining for $B$ s. One spare $B$ . Fill it with $A$ . To fill the $5$ $(-)$ s: $1$ for $ABA$ , $1$ for $A$ s and $3$ remaining for $B$ s. One spare $B$ . Fill it with $B$ . To fill the $5$ $(-)$ s: $1$ for $ABA$ , $2$ for $A$ s and $2$ remaining for $B$ s. One spare $B$ . Note that we have $2$ $(*)$ gaps and the spare $B$ can be put into $6$ gaps next to $A$ s. There are $2 \cdot \left[ {5 \choose 2} + {5 \choose 1} \cdot {4 \choose 1} + {5 \choose 1} \cdot {4 \choose 2}\right] \cdot {6 \choose 1} = 720$ strings. Option 3 : Fill $0$ $(*)$ gap. To fill the $5$ $(-)$ s: $1$ for $ABA$ , $2$ for $A$ s and $2$ remaining for $B$ s. Two spare $B$ s can be put into $6$ gaps next to $A$ s. There are ${5 \choose 1} \cdot {4 \choose 2} \cdot {6 \choose 2} = 450$ strings. Case 5: $A$ , $A$ , $A$ , $A$ and $5$ spare $B$ s. This should be the same: Option 1 : This one is different from last time but just like Option 2 . There are $\left[ {5 \choose 2} + {2 \choose 1} \cdot {5 \choose 3} + {5 \choose 4}\right] \cdot {8 \choose 2} = 980$ strings. Option 2 : $2 \cdot \left[ {5 \choose 3} + {5 \choose 4} \right] \cdot {8 \choose 3} = 1680$ strings. Option 3 : ${5 \choose 4} \cdot {8 \choose 4} = 350$ strings. To sum it up: The total number of desired strings is $20 + 10 + 105 + 720 + 450 + 700 + 1680 + 350 = 4315$ strings. So there should be $4315 \cdot 4! \cdot 5! \cdot 6! = 8947584000$ ways of seating these students.",['combinatorics']
2976181,What is the smallest integer greater than 1 such that $\frac12$ of it is a perfect square and $\frac15$ of it is a perfect fifth power?,"What is the smallest integer greater than 1 such that $\frac12$ of it is a perfect square and $\frac15$ of it is a perfect fifth power? I have tried multiplying every perfect square (up to 400 by two and checking if it is a perfect 5th power, but still nothing. I don't know what to do at this point.","['algebra-precalculus', 'integers', 'perfect-powers', 'diophantine-equations']"
2976205,Sum of probabilities of events vs. probability of at least one event,"$P_i$ is the probability of one event. As defined below, $a$ is the sum of all probabilities of events (that may or may not be independent), and $c$ is the overall probability that at least one event will happen. $a=\sum_{i=0}^n P_i $ $c=(1-\prod_{i=0}^n (1-P_i))$ $0\leq P_i \leq 1$ Take two events with probability of $0.5$ and $0.2$ for example: $$ a= 0.5 +0.2=0.7~, \qquad c = 1 - 0.5 \cdot 0.8=0.6$$ Is it true $\dfrac{a}{c}$ will increase as $n$ , the number of $P_i$ , increases ? It seems true to me based on sample results, but I can't think of a formal proof.","['statistics', 'inequality', 'calculus', 'algebra-precalculus', 'probability']"
2976215,Finding correlation given variance-covariance matrix,"I've been looking all over the internet and have been having trouble finding good uses of a covariance matrix to find the correlation coefficient. I know that, from a simple $2 \times2$ variance-covariance matrix, the correlation is given by $\mathrm{COR}\left(X,Y\right)=\frac{\mathrm{COV} \left(X,Y\right)}{\sqrt{Var\left(X\right)\cdot V a r\left(Y\right)}}$ . But, if a variance-covariance matrix is a $3 \times 3$ , like in this example: m                s               df
m    1.004899e-04   -4.762594e-06     -7.856965e-02
s   -4.762594e-06    7.781352e-05      4.741813e-01
df  -7.856965e-02    4.741813e-01   8278.92601173 Is it possible to compute $\mathrm{COR}\left(X,Y\right)$ ?","['statistics', 'covariance', 'variance', 'correlation', 'probability']"
2976326,Solve the ode $W^{\prime }\left( s\right) -2iH\left( s\right) W\left( s\right) -1=0$,"Consider the differential equation $W^{\prime }\left( s\right) -2iH\left( s\right) W\left( s\right) -1=0$ , $%
s\in I\subset 
\mathbb{R}
$ and consider the functions $F\left( s\right) =\int\limits_{0}^{s}\sin \left(
2\int\limits_{0}^{u}H\left( t\right) dt\right) du$ $G\left( s\right) =\int\limits_{0}^{s}\cos \left(
2\int\limits_{0}^{u}H\left( t\right) dt\right) du$ where $H:I\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ is functions real of one variable Show that the general solution to the above differential equation is given by $W\left( s\right) =\left\{ \left( F\left( s\right) -c_{1}\right) +i\left(
G\left( s\right) +c_{2}\right) \right\} \left( F^{\prime }\left( s\right)
-iG^{\prime }\left( s\right) \right) $ Can anyone help me solve this differential equation? Well I just know the ode's that I know do not have complex coefficients.","['analysis', 'riemannian-geometry', 'ordinary-differential-equations', 'differential-geometry']"
2976332,How integrating over a branch cut is made rigorous?,"This is from Ch. 7 of the book Complex Variables by J Brown and R Churchill 8th ed. In evaluation of the counter integration of $f(z)=\dfrac{z^{-a}}{z+1}$ the book first suggests the following : where $\mathbb{R^+} \cup {\{0}\}$ is the branch cut. Then it claim that integration over the branch cut is not allowed however we will make it rigorousin the exercise 8. Here it is: Well, the part (c) is where it's trying to make it 'rigorous' (part (a) and (b) are easy to understand). My questions: I can't understand part (c) about change of branches. In other words, how it integrates in other branches then sums them in another branch?! (esp. when still the legs from $\rho$ to $R$ both again relies over the branch cut $\mathbb{R^+} \cup {\{0}\}$ ). When in the text I read that it is going to become a rigorous treating, I was thinking about letting the branch cut $\mathbb{R^+} \cup {\{0}\}$ be, and limiting the legs to that branch cut (ie. limiting $\theta_1$ and $\theta_2$ to zero) like this : I tried it but I am not sure if the method is consistent with theorems.  Also I don't know if I can enter the limit $\theta_i \to 0$ inside integral. So how can I accomplish this method if it is allowed or is there any better (more acceptable) method alternative for the one presented in the exercise above? Edit: For question 2: How to prove that the following holds $$\lim_{\theta_1, \theta_2  \to 0} \int_{\rho}^{R} r^{-a} \Big( \dfrac{e^{-ai\theta_1}}{re^{\theta_1}+1} - \dfrac{e^{-2 \pi ai + ia\theta_2}}{re^{\theta_2}+1} \Big) dr = (1-e^{-2 \pi ai}) \int_{\rho}^{R} \dfrac{r^{-a}}{r+1} dr.$$ and can this be considered a rigorous-ization?","['complex-analysis', 'contour-integration', 'proof-verification', 'alternative-proof']"
2976343,"If omega limit set contains only one point, $x^*$, then $\lim_{t\to\infty}\phi(t;x_0)=x^*$","I'm trying to proof the following, and I'm looking for a verification of my proof. If it is incorrect, I'm looking for some help towards a right proof. If the omega limit set is $\omega(x_0)=\{x^*\}$ , then $\lim_{t\to\infty}\phi(t;x_0)=x^*$ Suppose $\lim_{t\to\infty}\phi(t;x_0)$ exists and equals $x'$ . Then $\omega(x_0)=\{x'\}$ , so it suffices to proof that the limit exists. Now assume for the sake of contradiction that $\lim_{t\to\infty}\phi(t;x_0)$ does not exist. Because $x^*\in\omega(x_0)$ , there exists a sequence $(t_n)_{n\in\mathbb{N}}$ such that $\lim_{n\to\infty}\phi(t_n;x_0)=x^*$ . Because $\lim_{t\to\infty}\phi(t;x_0)$ does not exist, there exists a $\delta>0$ such that there is no $T$ such that $\phi(t;x_0)\in B_{\delta}(x^*)$ for all $t\geq T$ (otherwise the limit would exist). Fix this $\delta$ . From continuity of the flow and existence of a sequence $(t_n)_{n\in\mathbb{N}}$ satisfying $\lim_{n\to\infty}t_n=\infty$ and $\lim_{n\to\infty}\phi(t_n,x_0)=x^*$ , it follows that for an arbitrary $\epsilon>\delta$ , there exists a sequence $(s_n)_{n\in\mathbb{N}}$ satisfying $\lim_{n\to\infty}s_n=\infty$ such that for all $n\in\mathbb{N}$ , $\phi(s_n;x_0)\in\overline{B_{\epsilon}(x^*)}\setminus B_{\delta}(x^*)$ , which is in particular a closed set. Now it follows from Bolzano-Weierstrass that $\left(\phi(s_n;x_0)\right)_{n\in\mathbb{N}}$ has a convergent subsequence $\left(\phi(s_{n_k};x_0)\right)_{k\in\mathbb{N}}$ , belonging to $\overline{B_{\epsilon}(x^*)}\setminus B_{\delta}(x^*)$ , because this set is closed, and thus the limit value is unequal to $x^*$ ; thus $\omega(x_0)\neq\{x^*\}$ , which gives the desired contradiction.","['proof-verification', 'ordinary-differential-equations', 'real-analysis']"
2976364,Definition of predictable process,"I am trying to understand the notion of predictable process. Let $(Ω,F_t,P)$ be a filtered measure space, satisfying the usual condition. Things starts with the predictable $\sigma$ -algebra ${\mathcal P}$ , which is generated by sets of the form $A\times (a,b]$ with $A\in{\mathcal F}_a$ and $A\times \{0\}$ with $A\in{\mathcal F}_0$ . My question: is it true that $S\in {\mathcal P}$ if and only if $S$ is progressive and $\{\omega|(\omega,t)\in S\}\in{\mathcal F}_{t−}$ for all $t$ ? In another word, is it true that $X$ is predictable if and only if $X$ is progressive and $X$ is adapted to the filtration ${\mathcal F}_{t−}$ ? The only if part is easy but I am not sure about the if part. I feel that $X$ being ${\mathcal F}_{t−}$ -measurable seems to be a more ""reasonable"" definition of ""predictable"", but maybe I am wrong.","['stochastic-processes', 'measure-theory', 'stochastic-calculus']"
2976374,Fibonnaci Sequence,"Prove that $\forall n\epsilon N$ $$F(n+2) = 1 + \sum_{i=0}^n F(i) $$ I know this is strong induction. However I am new to it and not 100% familiar with how it works. The base case is $$ F(0+2) = F(2) = 1$$ and $$1 +\sum_{i=0}^0 F(i) = 1 $$ Then the Induction Hypothesis is that you assume for arbitrary $k\epsilon N,\forall j \epsilon N, 1 \le j \le k, S(j) $ Then the inductive step is that I must prove the inductive hypothesis implies $S(k+1)$ . However I am confused on how to do that part",['discrete-mathematics']
2976421,Words Counting and Ranking,"All words which contain $2, 3, 4$ or $5$ English letters (A to Z) are listed alphabetically. In each word, the letters can be repeated, but any two adjacent letters must be distinct. So, the first word is ""AB"", and the last one is ""ZYZYZ"". What is the total number of words in the list? What is the rank of the word ""PAPER""? What is the $13554$ th word? I have answered the first part as follows; Total number of words $=26(25^1+25^2+25^3+25^4)$ $=26(25+625+15625+390625)=26(406900)=10579400$ words. Am I right for this part? How to solve the second and the third part?","['permutations', 'statistics', 'combinatorics']"
2976447,Group of matrices form a manifold or euclidean space,"There is a very interesting question How can a group of matrices form a manifold .  From the answers it looks more like group of matrices form euclidean space than a general manifold. I understand that euclidean space is a manifold, but manifold is very general and has curvature.  My question is what exactly makes a group of matrices a manifold but not simply a euclidean space. I am not a mathematician so please correct me if there is anything wrong with the question or the way I posed it.","['euclidean-geometry', 'linear-groups', 'abstract-algebra', 'manifolds', 'differential-geometry']"
2976464,Number of equations needed to define a rectangle?,"I've been wondering whether there is some sort of fundamental rule (such as n equations are needed to solve for n variables) underlying the seeming need for the definitions of different shapes. For example, to define a right angled triangle given points in a plane, we need only the right angle - its characteristic - hence we can write an equation using Pythagoras' theorem which defines it: $$AB^2 + AC^2 = BC^2$$ However, what about the definition of a rectangle? What fundamental properties does a rectangle possess? I tried the idea of right angles for each of the vertices, but it seems that you can also define a square in just 3 equations. For example: $$AC=BD$$ $$AB=CD$$ $$AB^2 + AC^2 = BC^2$$ As well as: $$AD=BC$$ $$AD^2 + BA^2 = BD^2$$ $$CD^2 + CB^2 = BD^2$$ What fundamental truth requires three properties to define a rectangle in terms of points in a plane? Is it related to solving a problem in n variables? Can this rule, if any, be extended to shapes in general in arbitrary dimensions?","['algebra-precalculus', 'geometry']"
2976481,"Proving that $S=\{ x \in (X,\| \cdot \|) : \|x\| =1 \}$ is a closed set.","Exercise : Show that the unit sphere $$S=\{x \in (X,\|\cdot \|) : \|x\| =1\}$$ of a normed space, is a closed set. Attempt : For a set to be closed, its complement must be an open set. Define the complement of $S$ to be : $$S^c = \{ x \in (X, \|\cdot \|) : \|x\| <1 \}\cup\{x\in (X,\|\cdot\|):\|x\|>1\}$$ Note : We have NOT yet been introduced to handling maps for such proofs in our functional analysis course, so it may not be the best approach for my understanding. Question : How would one proceed with proving the fact stated in the exercise?","['spheres', 'normed-spaces', 'real-analysis', 'functional-analysis', 'general-topology']"
2976508,Simple question on power series,"Suppose $\{a_n\}$ is a sequence of complex numbers such that $a_n$ is of unit length if it is not equal to $0$ .
Can we conclude that, $F(z) = \sum_{n=0}^\infty a_n z^n$ has continuous extension on an open arc of the unit circle if and only if $F(z)$ has analytic continuation across this open arc?","['complex-analysis', 'sequences-and-series']"
2976535,How to prove that $x_n = nq^n$ for $|q| < 1$ is bounded?,"This problem came up when i was solving another problem on boundedness. Consider the following problem: Let $n \in \mathbb N$ and $$
\begin{cases}
x_n = nq^n \\
|q| < 1
\end{cases}
$$ Prove $\{x_n\}$ is a bounded sequence. The problem above comes before the one I'm solving right now. I was unable to prove that $x_n$ is bounded and skipped that problem, but now I need to use it. Context of the problem: I'm working on proving that the following sum is bounded: $$
\begin{cases}
y_n = \sum_{k=1}^nkq^k\\
|q| < 1
\end{cases}
$$ I've arrived at a closed form for the sum by expanding the terms and multiplying it by $(1-q)^2$ , this is pretty easy to handle but takes a lot of space so i'm not posting it here. Here is the closed form for $y_n$ : $$
y_n = \frac{q(nq^{n+1} - q^n(n+1) + 1)}{(1-q)^2}
$$ So obviously the author of the problem expects me to first prove boundedness of $x_n$ before switching to $y_n$ because $y_n$ utilizes the prove on boundedness for $x_n$ (note the $nq^{n}$ ). My thoughts on proving boundedness for $x_n$ : For $x_n$ i have really no idea where even to start from. I've tried using Bernoulli's inequality and some tricks with binomial expansions but still couldn't handle it. So my question is: How to prove $x_n = nq^n$ is bounded. And can it be generalized for $z_n = n^pq^n$ ? For both cases $|q| < 1$ and for the second case $p\in \mathbb R$ Please note that this questions are precalculus ones, i'm not allowed to use calculus when solving it.","['algebra-precalculus', 'upper-lower-bounds', 'sequences-and-series']"
2976548,Classification of $n\times n$ real matrices up to congruence,"As we known, for matrix similarity $A= P^{-1}B P$ , we can classify equivalence class in $M_n (\mathbb{C})$ by Jordan Canonical Form . Matrix congruence , $A = P^T B P$ with $P$ invertible, is also an equivalence relation. How does one classify the equivalence classes in $M_n(\mathbb{R})$ under this relation? For symmetric real matrices, it's easy, since we can use orthogonal transformation to diagonalize it, which gives both matrix similarity and matrix congruence. Then we use a scaling matrix to make the diagonal elements to be $\pm 1$ and $0$ . Therefore, for a symmetric real matrix, we classify the matrix by the number of $\pm1$ and $0$ . What about for general real matrices?","['matrix-analysis', 'abstract-algebra', 'linear-algebra']"
2976755,Proof that every rational number is between 2 consecutive integers,"I need to prove that $\forall$ $p \in \mathbb{Q}$ , $\exists n \in \mathbb{Z}$ such that $n \leq p < n+1$ . What I have done is assume that such a $p$ does not exist. Which implies that either $p>n$ or $p<n$ , $\forall n \in \mathbb{Z}$ . This would imply that p is either a least or greatest element of $\mathbb{Z}$ which is a contradiction. Hence I can conclude that $\exists m \in \mathbb{Z}$ such that $m<p$ and that $\exists n \in \mathbb{Z}$ such that $p<n$ . Combining these 2 gives me $m<p<n$ , however I'm stuck here, how can I come to the stronger conclusion that it is between two consecutive integers?","['elementary-set-theory', 'rational-numbers', 'real-analysis']"
2976775,$L^2$ convergence of Fourier series,"Let $R_n(x)=f(x)-S_n(x)$ where $S_n(x)$ is the partial sum of Fourier series of $f(x)$ function. $\lim_{n \to \infty} <R_n(x),R_n(x)>$ $=0$ $\iff$ $\sum_{n=1}^{\infty}c_i^2 = \int_{-\pi}^{\pi}(f(x))^2dx$ (Parseval identity where $c_i$ s are Fourier coefficients) It's written that $<R_n(x),R_n(x)>$ $=$ $\sum_{n=1}^{\infty}c_i^2 \cdot\int_{-\pi}^{\pi}(f(x))^2dx$ in my notes. But I cannot identify the reason of this equality. My main problem is that I cannot see why Parseval identity satisfies $\lim_{n \to \infty} <R_n(x),R_n(x)>$ $=0$ ? Showing in real $L^2[-\pi,\pi]$ is enough for me now. It can be stupid question, I'm sorry. If someone explain it me in easiest way, I will be glad Thanks P.S. : I need a proof in the easiest way. Please do not explain with different ways. I’m only an undergraduate student now and my knowledge is really bounded unfortunately. I cannot use anything I didn’t learn in my proofs. Please illuminate me how can I show it via Parseval identity.","['fourier-analysis', 'inner-products', 'parsevals-identity', 'functional-analysis', 'fourier-series']"
2976832,Establishing Continuity of $\cos x$ based on Continuity of $\sin x$,"If we have established that $\lim_{x\to c} \sin x = \sin c$ , is it enough to argue that $\cos x$ is just a translation of $\sin x$ in order to establish that $\lim_{x\to c} \cos x = \cos c$ ?","['continuity', 'calculus', 'trigonometry']"
2976854,"Exist $f : \mathbb { R } \rightarrow \mathbb { R }$ such that $f (x)f (y) = f (x+ y) \forall x , y \in \mathbb { R }$ , but $f$ is not continuous?","Does there exist a function $f : \mathbb { R } \rightarrow \mathbb { R }$ such that $f ( x ) \cdot f ( y ) = f ( x + y )$ $\forall$ $x , y \in \mathbb { R }$ , but such that $f$ is not everywhere continuous? I have this problem for my undergraduate Real Analysis class and have not been able to make any progress whatsoever. I have talked to postdocs and PhD students and none of them have been able to help. I was thinking that it might be something like $f(x) = a^x$ if $x\in\mathbb{Q}$ and $f(x) = 0$ if $x\in\mathbb{I}$ , but then I realized that this did not work due to cases like $x=\pi$ and $y=-\pi$ . Does anyone have any input on this problem?","['continuity', 'analysis', 'real-analysis']"
2976916,Show that the following series is convergent.,"Consider the series whose general term is as follows: $$u_n=\frac{a_n}{(S_n)^\lambda}$$ with the condition $S_n = \sum_{k=1}^{n}a_k$ with constraints that $0\leq a_n\leq 1,$ $S_n$ is a divergent series and $\lambda >1.$ Show that the series is convergent. I need to find a lower bound for $S_n$ so that I can find an upper bound for $u_n.$ I tried to use the fact that $S_n$ is divergent in the following way: For $n$ large enough we can say that $S_n>N$ where $N>1$ and but this gives the bound $$u_n<\frac{1}{N^\lambda}$$ which is not helpful since we will sum up constant terms infinite times. Any hints/suggestions will be much appreciated.",['sequences-and-series']
2976924,Does the formula $\frac{1}{D + a} f = \frac{1}{a}\left(f - \frac{1}{D + a} f'\right)$ have a name?,"Using integration by parts, we can show that: $$\frac{1}{D + a} f = \frac{1}{a}\left(f - \frac{1}{D + a} f'\right)$$ where $a$ is a real number, $D$ is differentiation, and $D+a$ is the corresponding linear differential operator. This formula is very helpful for computing $\frac{1}{D+a}$ applied to a polynomial, exponential, trigonometric or hyperbolic function. For example, to solve $$y' - 5y = x^7$$ rewrite it as $$(D-5)y = x^7$$ which is equivalent to $$y \in \frac{1}{D-5} x^7$$ which an be solved relatively painlessly using the above formula, which essentially manages your integration by parts for you and allows you to just focus on the algebra. Question. Is there a name for this formula?","['power-series', 'calculus', 'differential-operators', 'ordinary-differential-equations']"
2976942,Image of a complex function contained in a line. Prove that the function is constant.,"Let $f$ be a holomorphic function on a region $G \subseteq \mathbb{C}$ , and suppose that the image $f(G)$ is contained in a line in $\mathbb{C}$ . Prove that $f$ is constant. There are various theorems in the field of complex analysis that prove a function to be constant. Liouville's Theorem proves a function is constant if it is bounded (but not necessarily dominated). The Cauchy-Riemann equations can be used to prove a function is constant if you can prove the derivatives are zero everywhere. Which theorem should be used? I'm asking for a hint, not an answer!",['complex-analysis']
2977009,"Finite-dimensionality of $H^1(X,\mathscr O_X)$ for a projective curve","A well-known result by Serre is that properness of a noetherian scheme $(X,\mathscr O_X)$ over $k$ implies finite dimensionality of $H^i(X,\mathscr O_X)$ for all $i \geq 0$ . For a projective variety it is easy to prove that $H^0(X,\mathscr O_X) = \mathscr O_X(X) = k$ . I was wondering if there's an elementary proof for finite-dimensionality of higher cohomology groups. Maybe, for the easiest case of $X$ being an smooth curve and finite-dimensionality of $H^1(X,\mathscr O_X)$ one could reduce it to computing it for $\mathbb{P}^1$ ?",['algebraic-geometry']
2977024,Kind of converse of Kolmogorov maximal inequality,"Let $S_n=\zeta_1+...+\zeta_n$ where $\zeta_i$ are independent with $E\zeta_i=0, E\zeta_i^2=\sigma_i^2<\infty, |\zeta_i|<K$ . Then, $P(\max_{1 \leq m  \leq n}|S_m| \leq x) \leq (x+K)^2/\operatorname{var}(S_n)$ . How do we show this?  The hint says that I should use the fact that $S_n^2-\sum_{m \leq n}\sigma_m^2$ is a martingale. But I am totally clueless.... Any hint would be appreciated! Thanks and regards.","['stochastic-processes', 'martingales', 'inequality', 'probability-theory', 'probability']"
2977029,How to symbolically define set of all real numbers (R) in set-builder notation?,Can we define R using set-builder notation without language semantics (purely in math symbols)? Is it valid to do the following: $\{x\in\mathbb{R}|x\}$,"['elementary-set-theory', 'notation']"
2977040,"Are there rings with uncountably many irreducible elements (prime elements, if in a PID)? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I'm playing around and trying to construct rings with different numbers of irreducible elements, hence the above question.","['elementary-set-theory', 'ring-theory']"
2977048,Concentration of $Z$ in the chemical reaction $6Z+B\rightleftharpoons 2Z+A$,"Find the differential equation for $z$ the concentration of $Z$ in the chemistry equation $$6Z+B\rightleftharpoons^{k_1}_{k_{-1}} 2Z+A$$ My idea: Let $[Z]=z,\ [A]=a,\ [B]=b$ . Then, $$\frac{dz}{dt}=-4k_1z^6b+4k_{-1}z^2a$$ Now, my question is, if the term '' $4k_{-1}z^2a$ '' is well written (the one in the left direction)? How to completely finish the exercise?","['chemistry', 'ordinary-differential-equations']"
2977051,Attempt to generalize a self-made theorem on polynomials,"This is a follow-up of this question . In that question, I brought up a theorem I had discovered: For any complex polynomial $P$ degree $n$ : $$ \sum\limits_{k=0}^{n+1}(-1)^k\binom{n+1}{k}P(a+kb) = 0\quad \forall a,b \in\mathbb{C}$$ In an attempt to generalize it to non-polynomials, I conjecture: For any function $F:\ \mathbb{R} \rightarrow \mathbb{R}$ that is smooth on $[a, b]$ : $$ \lim_{n\to\infty} \sum\limits_{k=0}^{n}(-1)^k\binom{n}{k}F\Big(a+\frac{k(b-a)}{n}\Big) = 0 $$ My rationale for this conjecture is, since any function can be approximated by a polynomial, and the theorem works for all polynomials, taking the limits of the sum of any function to infinity (treat $F$ as an infinite degree polynomial) should result in $0$ as well. My questions: If this conjecture is incorrect, can you disprove it? If possible, can you construct a correct version of this theorem (i.e., $F$ has to satisfy some other conditions)? If this is indeed correct, either a sketch or a hint of a proof is appreciated.","['limits', 'summation', 'binomial-coefficients', 'real-analysis']"
2977105,Where is $k(z)=PV(z-1)^{\frac{1}{2}}PV(z+1)^{\frac{1}{2}}$ Continuous and Differentiable,"Consider the function ( $PV$ denotes the principal value ) $$PV(z-1)^{\frac{1}{2}}PV(z+1)^{\frac{1}{2}},  \ \ \forall z\in\mathbb{C}.$$ Find where $k$ is continuous and differentiable, giving reasons. We first recall that $f(w)=w^{\frac{1}{2}}$ is not continuous when $w<0$ . Using this, we can conclude that $PV(z-1)^{\frac{1}{2}}$ is not continuous when $z<1$ and $PV(z+1)^{\frac{1}{2}}$ is not continuous when $z<-1$ . Hence, $k(z)$ is not continuous when $z<1$ . Is this sufficient to determine that $k(z)$ is not differentiable on the interval $(-\infty, 1)$ , as $k(z)$ is not continuous for $z<1$ and not differentiable at $z=1$ (by inspection)?","['complex-analysis', 'continuity', 'proof-verification', 'derivatives']"
2977195,"Inverse of sum of two marices, one being diagonal and other unitary.","$C = A+D$ , $A$ being square matrix and $D$ a full rank diagonal matrix. Is there any easy way to compute $C^{-1}$ from $A^{-1}$ and $D$ Edit 2: (important edit)
Iam interested in this question, because my matrix $A$ is huge and so is $C$ . So computing inverse of $C$ is not practical, but luckily the matrix $A$ is unitary, so $A^{-1} = A^*$ , so I easily have $A^{-1}$ , and finding ways to use it to get $C^{-1}$ .","['matrices', 'linear-algebra']"
2977213,Simplify $\sum_{l=0}^\infty \sum_{r=0}^\infty\frac{\Gamma(L+r-2q)}{\Gamma(L+r-1+2q)} \frac{\Gamma(L+r+l-1+2q)}{\Gamma(L+r+l+2)}\frac{r+1}{r+l+2}$,"This question is a continuation of this post. Let $r,l,L\geq 1$ be integers. 
Assume that $q\in [0,1]$ is a real number. The authors obtained the following equation $36$ in their paper (I express in summation forms). $$\sum_{r=1}^\infty \sum_{l=1}^\infty \frac{r}{r+l} 4(1-q)q \frac{Γ(L)}{Γ(L − 2p)} \frac{Γ(L + l − 1 − 2p)}{Γ(L + l − 2q)} \frac{Γ(L + l + r − 1 − 2q)}{ Γ(L + l + r) } = $$ $$ 1 - \frac{2q^2}{(1-2q)^2} - \frac{2\pi q(1-q)}{(1-2q)(3-4q)} \cot(2\pi q).$$ Note that the above formula are equal in the sense of asymptotically. In the midst of obtaining the above formula, I stuck at the following. Question : Is it possible to express $$\sum_{l=0}^\infty \sum_{r=0}^\infty\frac{\Gamma(L+r-2q)}{\Gamma(L+r-1+2q)} \frac{\Gamma(L+r+l-1+2q)}{\Gamma(L+r+l+2)}\frac{r+1}{r+l+2}$$ in closed form independent of summations (possibly in terms of Gamma function)? I tried to express above double summations using Appell's series .
However, I stuck at $$\frac{\Gamma(L-2q)}{\Gamma(L+2)} \sum_{l=0}^\infty \sum_{r=0}^\infty \frac{(L-1+2q)_{l+r}}{(L+2)_{l+r}} \frac{(L-2q)_r}{(L-1+2q)_r} \frac{(1)_l}{l!r!} \frac{(2)_r}{(r+l+2)}.$$ In particular, can we express $$\frac{(L-2q)_r}{(L-1+2q)_r (r+l+2)}$$ to be something which allows us to use Appell series? I also tried to evaluate the summation over $l$ , that is, $$\sum_{l=0}^\infty \frac{\Gamma(L+r-1+2q+l)}{\Gamma(L+r+2+l)(r+l+2)},$$ and I arrive at $$_3F_2(L+r-1+2q,1,r+2; L+r+2,r+3;1)\frac{\Gamma(L+r-1+2q)}{\Gamma(L+r+2)(r+2)}.$$ However, I could not find any formula to evaluate $_3F_2(L+r-1+2q,1,r+2; L+r+2,r+3;1)$ in Wolfram Alpha . Updated (2 Nov 2018): @Nikos Bagis uses the Mathematica 10 to obtain a closed form for my question. 
However, I would like to have a detailed calculations on how to obtain the answer.","['sequences-and-series', 'special-functions', 'hypergeometric-function', 'real-analysis']"
2977250,Splitting fried eggs in a fair way,"This morning I was making a breakfast for two, part of which was frying 6 eggs (sunny side up) on a round-shaped pan. When it was ready I found it quite tricky to fairly split between the two: ideally I wanted to have a single cut that will go through the center, and leave 3 yolks on each side. That made me thinking of the following: it seems that if the pan was a perfect circle and yolks were dots, there will always be a line passing through the center that will leave exactly half of the dots in each half-circle (and that would apply to any even number of dots). Questions: Is my statement in italic true, and if it is, I'd be delighted to see an elegant proof of it (does not have to come from the school math). I think this statement can be generalized as follows: we say that a connected Borel subset $A\subset\Bbb R^2$ satisfies the property E if for any even number of elements of $A$ there exists a line that splits $A$ into two sets of equal Lebesgue measure, each having an equal number of chosen elements. Does each convex set satisfy E, and if yes - are there non-convex sets with that property?","['general-topology', 'geometry']"
2977303,"If $[X, Y]=0$, then $\operatorname{Ad}_{e^{tX}}Y = Y$ for all $t\in \mathbb{R}$?","Let $G$ be a Lie group and $\mathfrak{g}$ be its Lie algebra. Let $X$ and $Y$ be commuting elements of $\mathfrak{g}$ , i.e., $[X, Y]=0$ . I want to show that $\operatorname{Ad}_{e^{tX}}Y = Y$ for all $t\in \mathbb{R}$ . I know that tangent map of $\operatorname{Ad}$ is $\operatorname{ad}$ and $\operatorname{ad}(X)Y = [X, Y]=0$ . Can this imply $\operatorname{Ad}_{e^{tX}}Y = Y$ for all $t\in \mathbb{R}$ ?
Any hints or reference are appreciated.","['lie-algebras', 'lie-groups', 'differential-geometry']"
2977317,Derivation of the tangent half angle identity,"I'm having trouble proceeding from $$\frac{\sin(\theta)}{1+\cos(\theta)}$$ to $$\tan\left(\frac{\theta}{2}\right)$$ Context: Consider the function $f$ defined for all $(x,y)$ such that $y \neq 0$ , with the rule $$f(x,y) = \frac{y}{\sqrt{x^2+y^2}+x}$$ Show that $$f(r\cos(\theta),r\sin(\theta)) = \tan\left(\frac{\theta}{2}\right)$$ So far I've done: $$f(r\cos(\theta),r\sin(\theta)) = \frac{r\sin(\theta)}{\sqrt{r^2\cos^2(\theta) + r^2\sin^2(\theta)}+r\cos(\theta)} = \frac{r\sin(\theta)}{\sqrt{r^2}+r\cos(\theta)}\\=\frac{\sin(\theta)}{1+\cos(\theta)}$$ Using $$\cos(\theta) = 2\cos^2\left(\frac{\theta}{2}\right)-1 \implies 2\cos^2\left(\frac{\theta}{2}\right)=\cos(\theta)+1$$ We get $$f(r\cos(\theta),r\sin(\theta)) = \frac{\sin(\theta)}{2\cos^2\left(\frac{\theta}{2}\right)}$$ But I can't see how to proceed from here to the required result. Thanks in advance for any help!","['multivariable-calculus', 'algebra-precalculus', 'trigonometry']"
2977339,Finding the charge density in a solid,"An object occupies the solid region in the first octant bounded by the coordinate planes and two cylinders $x^2 + y^2 = 4$ and $y^2 + z^2 = 4$ If the charge density at any point is $x$ , what's the total charge? So I know $Q = pV$ , where $p$ is charge density and $V$ is volume. I think that I need to do this in spherical coordinates, but I'm not too sure. I define $f(x, y, z) = x$ , then I have $f( \theta, \phi) = ??$ I've never used spherical coordinates before. I'm learning multivariable calc through self study, so any help would be appreciated. I think my integral will be something like this $$\int_{0}^{2\pi}\int_{0}^{\pi} f(\theta, \phi) d\theta d\phi \cdot x,$$ but I'm not sure about how to get the function. Any help is appreciated.","['integration', 'physics', 'multivariable-calculus']"
2977363,Integrating second order ODE and finding fixed points,"We know that fixed points are such points, where $x'$ = $x''$ = $0$ . Let's say we are given second order ODE $:$ $ x'' + sin(x) = C$ We can rewrite it into system of first order ODEs: $ \begin{cases} x_1' = x_2 \\ x_2' = C - sin(x_1) \end{cases} $ Now, according to this equation fixed points occur at $sin(x_1) = C$ But if we take the first integral of the system we will find that $ \frac {(x_2)^2}{2} - cos(x_1) = C \cdot  x_1 + Constant$ Now, points where $sin(x) = C$ don't satisfy the equation above (phase portrait confirms that). Yet the book claims that the fixed points are arrived from first equation. Could you help wih my confusion? Thanks","['ordinary-differential-equations', 'dynamical-systems']"
2977453,$3$-colourings of a $3×3$ table with one of $3$ colors up to symmetries,"Color each cell of a $3×3$ table with one of $3$ colors. What is the number of ways to do so if adjacent cells have different colors? Of course we consider two paintings the same (equivalent) if exist reflection or rotation which take one to another. So $$
\begin{array} {|r|r|r|}
\hline
 \color{blue}{B}& \color{yellow}{Y} &\color{red}{R}  \\
\hline
\color{red}{R}& \color{red}{R}&\color{red}{R}\\
\hline
\color{red}{R}& \color{red}{R}& \color{red}{R} \\
\hline
\end{array}
\;\;\;\;\;{\rm and} \;\;\;\;\;
\begin{array} {|r|r|r|}
\hline
  \color{red}{R}& \color{red}{R}& \color{blue}{B} \\
\hline
 \color{red}{R}& \color{red}{R}& \color{yellow}{Y} \\
\hline
\color{red}{R}& \color{red}{R}& \color{red}{R} \\
\hline
\end{array}
$$ are the same colorings. Since marked cells are ''independent'' we can color them at random but not with all 3 colors. \begin{array} {|r|r|r|}
\hline
 & X &  \\
\hline
X & &X \\
\hline
 & X&  \\
\hline
\end{array} Case 1: If all $X$ are colored with the same color, then for each unmarked cell we have 2 posibilites. So in this case we have $3\cdot 2^{5}$ possibile colorings. But clearly some of them are equivalent. What should I do? Divide this with 4? Or 16? Something else? Case 2: $Y$ is of different color then $X$ . Now we have $3$ colors for $Y$ and $2$ for $X$ . Rest of the places we can color $1^3\cdot 2^2$ so we have $6\cdot 2^{2}$ possibile colorings. But again reflections across midlle colum give us equivalent colorings so we should divide this by $2$ ? \begin{array} {|r|r|r|}
\hline
 & Y &  \\
\hline
X & &X \\
\hline
 & X&  \\
\hline
\end{array} Case 3: ... \begin{array} {|r|r|r|}
\hline
 & Y &  \\
\hline
Y & &X \\
\hline
 & X&  \\
\hline
\end{array} Is there more elegant aproach?","['graph-theory', 'combinatorics', 'coloring']"
2977461,Prove $\sum\frac{\sin{(n)}\tan{(n)}}{n^3}$ diverges/converges,"The original problem is $$\sum \frac{\sin(n)\tan(n)\ln(e-\frac{1}{n})}{n^3}$$ I know that $\sum\frac{1}{n^3}$ converges absolutely, also $\sin(n)\leq 1$ and $\ln(e-1)<\ln(e-1/n)<\ln(e)=1$ Now how to determine whether $$\sum \frac{\tan(n)}{n^3}$$ converges? (If this converged, it would assure that the original converges, because it is an upper bound and by comparison test, we are done). Otherwise, if $\sum \tan(n)/n^3$ diverged, we wish to show about the series $$\sum\frac{\sin(n)\tan(n)}{n^3}$$ whether it converges/diverges. It seems obvious that $\tan(n)$ has no limit (also, how to formally prove this?), but what about the $n^3$ doesn't it actually send it to $0$ ? I would have an argument which I am quite unsure of,... $\tan(n)$ is only "" $\pm\infty$ "" in each $(k+\frac{1}{2})\pi$ , but we can't ever reach those points, because $n$ is from $\mathbb{N}$ ?","['sequences-and-series', 'real-analysis']"
2977499,What is $\lim_{n\to\infty}\frac{2^{\log(n^2)}}{\sqrt{n^3}}$?,"I have to find out if $$2^{\log(n^2)} = \Omega (\sqrt{n^3}).$$ Now I have to find out if there exists a positive constant $c$ and a natural number $n_0$ such that $$2^{\log(n^2)} \ge c \sqrt{n^3},\quad \forall n > n_0.$$ Therefore I want to know if the limit of this function exists, because I couldn't find one. $$\lim_{n\to\infty}\frac{2^{\log(n^2)}}{\sqrt{n^3}}.$$","['limits', 'functions', 'asymptotics']"
2977502,Infinitely many $n$ such that $2^n-n$ is divisible by a prime,"I found the following question and can't make much headway with it. Show that there exist infinitely many positive integers $n$ such that $2^n \equiv n \mod p$ where $p$ is a odd prime... I started by writing the number as $n=(p-1)k+c$ which implies $$2^c \equiv c-k \mod p$$ where I used Fermat's Little theorem.
Now if $k$ is of the form $pm$ for some integer $m$ we get $n=(p-1)(p)m+c$ $$2^c \equiv c \mod p$$ and we have reduced $n$ to some smaller integer $c$ but I can't figure out how to find the smallest number $c$ which would then generate infinitely many $n$ . Any help in finding a possible approach to this would be highly appreciated.",['number-theory']
2977566,"$G$ is nilpotent iff for any maximal subgroups $M$ and $N$ of $G$, $MN=NM$.","I want to show that  finite group $G$ is nilpotent iff for every maximal subgroup of $G$ like $M$ and $N$ , $MN=NM$ . Let $G$ be nilpotent. Since every maximal subgroup of $G$ is normal in $G$ , the result is clear. But for the converse I want to show every maximal subgroup is normal in $G$ but I don't know how to show it.","['group-theory', 'finite-groups']"
2977617,Evaluate $\lim_{x\to 0}\frac{e^{(x+1)^{1/x}}-(x+1)^{e/x}}{x^2}$,"By L'Hôpital's rule, it gets $$\lim_{x\to 0}-\frac{\left(e^{(x+1)^{1/x}} (x+1)^{1/x}-e (x+1)^{e/x}\right) ((x+1) \log (x+1)-x)}{2x^3(1+x)},$$ which becomes more complicated. What could I do then?","['limits', 'real-analysis']"
2977633,$p$ and $6p+1$ both palindrome - primes. Is $(131/787)$ the only example?,"$131$ is a palindrome prime as well as $787$ , moreover $6\cdot 131+1=787$ . Are there further examples for a palindrome-prime $p$ , such that $6p+1$ is a palindrome-prime as well ? It is clear that $p$ must have an odd number od digits (since $11$ is the only palindrom-prime with an even number of digits) and the leading digit of $p$ must be $1$ , otherwise $6p+1$ has an even number of digits. So, $p$ must have the form $1\cdots 1$ and $6p+1$ must have the form $7\cdots 7$ . Upto $10^{10}$ , no further example exits.","['number-theory', 'palindrome', 'elementary-number-theory', 'prime-numbers']"
2977648,What does a having pivot in every row tell us? What about a pivot in every column?,"Given a matrix $A_1$ as part of the equation $A\vec{x}=\vec{b}$ : $$
\begin{bmatrix}
P & f & f & f\\
0 & P & f & f\\
0 & 0 & P & f
\end{bmatrix}
$$ What do we know based on the fact that there is a pivot in every row ? Given a matrix $A_2$ as part of the equation $A\vec{x}=\vec{b}$ : $$
\begin{bmatrix}
P & f & f\\
0 & P & f\\
0 & 0 & P\\
0 & 0 & 0
\end{bmatrix}
$$ What do we know based on the fact that there is a pivot in every column ? My understanding is that a pivot in every row (as in $A_1$ ) tells us that the columns of $A_1$ span $\mathbb{R}^m$ . And that a pivot in every column (as in $A_2$ ) tells us that the columns are linearly independent. Are these understandings correct? I'm sure that we know a lot about a matrix given the conditions listed above, but I'm just looking for the most obvious or helpful information.","['matrices', 'linear-algebra']"
2977675,Power Series (Cambridge Tripos 1900),"If $$a/(a+bz+cz^2)=1+p_1z+p_2z^2
+\dots$$ then $$1+p_1^2z+p_2^2z^2+\dots=\frac{a+cz}{a-cz}\frac{a^2}{
a^2-(b^2-2ac)z+c^2z^2}$$ A tricky problem from G.H.Hardy's ""A Course in Pure Mathematics"", or maybe I'm missing the obvious.Any help will be greatly appreciated.","['complex-analysis', 'sequences-and-series']"
2977701,Examples of prime-like entities on rings other than natural numbers,"For the natural numbers, primes can be viewed as the building blocks. Are there other significant examples in rings other than $\mathbb{N}$ (that do not have a one-to-one mapping with $\mathbb{N}$ ) that has something similar to primes (that are not necessarily ""numbers"")? By significant I mean the prime-like stuff plays an important (at least interesting) role in the structure of that ring. I guess the ring itself would have to be non-trivial or ""complex enough"" to have such an inner-structure.","['number-theory', 'ring-theory', 'abstract-algebra', 'prime-numbers']"
2977702,"How many integers $a,b,c$, both positive and negative, such that $P=a^b b^c c^a$ is a prime number?","How many integers $a,b,c$ , both positive and negative, such that $P=a^b b^c c^a$ is a prime number ? If $a,b,c$ are positive, then two of $a,b,c$ equal to $1$ . Assume that $b=c=1$ , then $a$ is any prime number. WLOG, if $c<0$ and $a,b>0$ , then $a$ must be even, so $a=2$ , thus $b=1$ and $c=-1$ If $a,b,c<0$ , then $P$ is smaller than $1$ , so $P$ won't be a prime. However if only one of $a,b,c$ is positive, how can we find $a,b,c$ ?",['number-theory']
2977737,Why abstractly do left and right inverses coincide when $f$ is bijective?,"I was reading Munkres Topology, one of the questions asks to show that if we have a function $f$ that has both a left and right inverse to show that $f$ is bijective and that the left and right inverse are both equal, call it $f^{-1}$ . So it's relatively easy to show that $f$ must be injective for a left inverse to exist and surjective for a right inverse to exist. Therefore, $f$ is clearly a bijection. Additional useful information is that a left inverse must be surjective and the right inverse must be injective. Now what i'm stuck on is showing that $f$ has a unique inverse and that the left and right inverses are equal to this inverse. Here is a sketch below: If $f$ is a bijection between sets $A,B$ then we can create directed graph consisting of pairs of nodes, with one node in $A$ , another node in $B$ and an arrow from $A$ to $B$ to represent $f$ . Because $f$ is a bijecton if we reverse the direction of all the arrows then we will never end up with more than one arrow pointing to a node in $A$ and every node in $B$ will have exactly one arrow leaving from it, so the function represented by this graph is well defined and has the property (call it $f^{-1}$ ) that $$f(f^{-1}) = \text{identity}_B$$ $$f^{-1}(f) = \text{identity}_A$$ Now my problem is showing the existence of this inverse function doesn't truly guarantee it is unique and therefore that the original left and right inverses must be equal to this $f^{-1}$","['elementary-set-theory', 'functions']"
2977788,"Choosing a minimal covering while avoiding ""bad"" subsets.","$\newcommand{set}[1]{\left\{#1\right\}}$ Let $S$ be a set and $\mathcal B\subseteq \mathcal P(S)$ a collection of subsets; we will call $B\in \mathcal B$ a bad subset of $S$ . We further assume all bad subsets $B$ have $|B|>1$ . Suppose $\mathcal C\subseteq \mathcal P(S)$ is a covering of $S$ ; that is, $S=
\bigcup_{C\in\mathcal C} C$ . We say a subset $T\subset S$ is good if $B\not\subset T$ for any $B\in \mathcal B$ ; that $\mathcal C$ is good if any $C\in \mathcal C$ is good; and that $\mathcal C$ is minimal good if $|\mathcal C|$ is minimal among all good coverings of $S$ . For example, if $S=\{a,b,c\}$ and $\mathcal B=\{\{a,b\},\{b,c\}\}$ , the singleton set $\{\{a\},\{b\},\{c\}\}$ is a good covering, and $\{\{a,c\},\{b\}\}$ is the unique minimal good covering. However, if $S=\{a,b,c,d\}$ and $\mathcal B=\{\{a,b\},\{c,d\}\}$ , then both $\{\{a,c\},\{b,d\}\}$ and $\{\{a,d\},\{b,c\}\}$ are minimal good coverings. Question: Given $S$ , $\mathcal B$ , is there a straightforward way to generate a minimal good covering, either directly or with an efficient algorithm? (Or put another way: how can we generate a minimal collection of sets which dominate all subsets (in the inclusion partial order) except those which are supersets of a particular collection of sets.) Naively, this requires searching $\mathcal P(S)$ , so is exponential in $|S|$ . Some observations: If there is a subset $X\subset S$ such that either $X\subseteq B$ or $X\cap B=\emptyset$ for all $B\in \mathcal B$ , then we can quotient out by $X$ (i.e. identify those elements) and solve the problem for $S'$ , where $|S'|=|S|-|X|+1$ . If we can find a maximal good set; that is, a good set $T\subset S$ such that $|T|$ is maximal with this property; then if $\mathcal C'$ is a minimal good covering of $S-T$ , $\mathcal C'\cup \{T\}$ is a good covering of $S$ . However, it may not be minimal : e.g. if $S=\set{a,b,c,d,e}$ , and $B=\set{B\subset S\mid |B|\geq 4}\cup\set{\set{a,b}}$ , then $T=\set{c,d,e}$ is maximal good, and $\mathcal C'=\set{\set{a},\set{b}}$ .
However, it is easy to see that $\set{\set{a,d,e},\set{b,c}}$ is a minimal good covering. Edit (for posterity): This problem is equivalent to finding a minimal hypergraph coloring , which, as the answer notes, includes graph coloring as a subcase.",['combinatorics']
2977815,multiplying a hypergeometric series,"We are able to calculate the value of the sum $\sum_{k=0}^\infty \frac{(a_1)_k(a_2)_k\dots(a_p)_k}{(b_1)_k(b_2)_k\dots(b_{p-1})_k}\cdot\frac{x^k}{k!}$ , which equals the generalised hypergeometric function ${}_pF_q\left[\begin{matrix} 
a_1,a_2,\dots ,a_p  \\
b_1,b_2,\dots ,b_{p-1} 
\end{matrix}\quad;x\right]$ . Is it possible to calculate (or bound) $\sum_{k=0}^\infty \frac{(a_1)_k(a_2)_k\dots(a_p)_k}{(b_1)_k(b_2)_k\dots(b_{p-1})_k}\cdot\frac{x^k}{k!}\cdot k$ ? Thank you very much for any suggestions!","['functions', 'hypergeometric-function', 'sequences-and-series']"
2977849,Gradient of distance-squared on Riemannian manifold,"Problem: Let $M$ be a Riemannian manifold. Consider the function $f: M \rightarrow \mathbb{R}$ where $f(x)=\text{dist}_M^2(p,x)$ , and $p \in M$ is fixed. Show that $\text{grad}(f)=-2\exp^{-1}_x(p)$ as vectors in $T_xM$ . (Assuming that $\exp^{-1}$ exists and is smooth etc.) My attempt at a proof: We must show that $\langle -2\exp^{-1}_x(p), \cdot \rangle_x = df(\cdot)$ as 1-forms at $x$ . Let $e_1,\dots,e_n$ be an orthonormal basis of $T_pM$ and introduce normal coordinates at $p$ : $x=(x^1,\dots,x^n) \leftrightarrow x=\exp_p(x^i e_i)$ . If $q=\exp_p(v)$ then $\text{dist}_M (p,q)=||v||_p$ and so $f(x)=||x^i e_i||^2_p=\sum (x^i)^2$ , where the second equality follows from the fact that the metric is the identity at $p$ (in these coordinates). So $df=\sum 2x^i dx^i$ . $(*)$ On the other hand, the geodesic ""from x to p"" is the same as the geodesic ""from p to x"", except that the direction is reversed. It should therefore be true that $p=\exp_x(-S_{p \rightarrow x}x^i e_i )=\exp_x(-x^i S_{p \rightarrow x} e_i)$ where $S_{p \rightarrow x}$ is the parallel transport from $p$ to $x$ . Hence $\exp^{-1}_x(p)=-\sum x^i S_{p \rightarrow x} e_i $ . Hence $\langle -2\exp^{-1}_x(p), \cdot \rangle_x=\langle 2x^i S_{p \rightarrow x}e_i, \cdot \rangle = 2x^i \langle S_{p \rightarrow x} e_i, \cdot \rangle = 2x^i dx_i$ which gives the result on comparison with $(*)$ . $\square$ My question: When writing that out, I felt like I was manipulating symbols without really understanding what they mean. For example, when I write $x^i$ I'm not sure whether I mean the coordinate function $x^i$ or its particular value at the point $x$ . I was also concerned that when I talk about parallel transport I should really have been talking about the derivative of $\exp$ . There's a lemma in Do Carmo which states $\langle (D\exp_p)_v(v),D\exp_p)_v(w)\rangle=\langle v,w \rangle$ for $v \in T_pM$ and $w \in T_v(T_pM) \simeq T_pM$ . I can see this might be useful, though I'm not sure precisely how. I would appreciate it very much if you checked to see if this proof is correct and ""expand it out"", particularly the second half) including more details to make clear what is going on.","['riemannian-geometry', 'differential-geometry']"
2977857,Primes of the form $x^2+ny^2$?,"So on the topic of sum of two squares, I wanted to see how to extend that to what primes can be expressed as $x^2+ny^2$ . I think the way to do this is to show that we can contract a binary quadratic form assuming we can find a number such that $27$ or $64$ , in this case, is a quadratic residue $\mod p$ , but I'm not sure how to continue. Is there specific set of primes that can be expressed in terms of modular relations or residual relations? How would you solve this is the case of $27, 64$ , or the general case of $n$ ?","['number-theory', 'quadratic-forms', 'elementary-number-theory', 'prime-numbers']"
2977871,"Find $\cos(\alpha+\beta)$ if $\alpha$, $\beta$ are the roots of the equation $a\cos x+b\sin x=c$ [duplicate]","This question already has answers here : Cosine of the sum of two solutions of trigonometric equation $a\cos \theta + b\sin \theta = c$ (5 answers) Closed 5 years ago . If $\alpha$ , $\beta$ are the roots of the equation $a\cos x+b\sin x=c$ , then prove that $\cos(\alpha+\beta)=\dfrac{a^2-b^2}{a^2+b^2}$ My Attempt $$
b\sin x=c-a\cos x\implies b^2(1-\cos^2x)=c^2+a^2\cos^2x-2ac\cos x\\
(a^2+b^2)\cos^2x-2ac\cos x+(c^2-b^2)=0\\
\implies\cos^2x-\frac{2ac}{a^2+b^2}\cos x+\frac{c^2-b^2}{a^2+b^2}=0
$$ $$
a\cos\alpha+b\sin\alpha=c\implies a\cos^2\alpha\cos\beta+b\sin\alpha\cos\alpha\cos\beta=c\cos\alpha\cos\beta\\
a\cos\beta+b\sin\beta=c\implies a\sin\alpha\sin\beta\cos\beta+b\sin\alpha\sin^2\beta=c\sin\alpha\sin\beta\\
c\cos(\alpha+\beta)=a\cos\beta+a\sin\alpha\cos\beta.(\sin\beta-\sin\alpha)+b\sin\alpha+b\sin\alpha\cos\beta(\cos\alpha-\cos\beta)\\
$$ I think its getting complicated to solve now. What is the simplest way to solve this kind of problems?",['trigonometry']
2977879,Summation of fractions of Gamma functions,"Recently I gave Mathematica the following input on the left hand side $$
\sum_{n=0}^{\infty}\frac{\Gamma(a+n)}{\Gamma(b+n)}=\frac{\Gamma(a)\Gamma(b-a-1)}{\Gamma(b-1)\Gamma(b-a)}.
$$ Can anyone explain to me what identities are needed to get the expression on the right hand side above?","['gamma-function', 'sequences-and-series']"
2977883,Making sense of a Lagrangian on a manifold,"Going through Villani's book on Optimal Transport, I came across the following setup: a Riemannian manifold $M$ and a Lagrangian $L : TM \times [0, 1] \to \mathbb{R}$ (So $L$ takes $(x, v, t)$ values as inputs). I'm wondering if I have the right notions of derivatives here. If $D_x L$ represents the spatial gradient, then we should have $$
D_x L(x_0, v_0, t_0)(w) = \dot\gamma(0), 
$$ where $\tilde{\gamma}(0) = x_0, \dot{\tilde{\gamma}}(0) = w$ , and $\gamma(t) = L(\gamma(t), v_0, t_0)$ . Is this correct? I'm a little more confused about the notion of $D_vL$ , where this represents the velocity gradient. I have just defined as follows: $$
D_v L(x_0, v_0, t_0)(w) = \dot\gamma(0),
$$ where $\gamma(t) = L(x_0, v_0 + tw, t_0)$ , because this seems to make sense to me. I was wondering if anyone could 1) let me know if these are correct, and (perhaps more importantly) 2) whether or not there is a better way of thinking about these objects. Much appreciation for any help.","['manifolds', 'riemannian-geometry', 'analysis']"
2977936,a torsion-free connection that preserves a complex structure,"Let $(M,I)$ be a complex manifold with a complex structure $I$ , i.e. an endomorphism $I$ of the tangent bundle such that $I^2 = -Id$ and such that the subbundle $T^{1,0}$ of eigenvectors of $I \otimes \mathbb{C}$ with eigenvalue $i$ in $TM \otimes \mathbb{C}$ is involutive. How to construct a torsion free connection $\nabla$ such that $\nabla(I)=0$ ?","['complex-geometry', 'connections', 'smooth-manifolds', 'differential-geometry']"
2977974,Prove that this class of curves has constant speed and curvature,"Let $\gamma: (a,b) \rightarrow \mathbb{R}^2$ be a smooth regular curve such that $\forall s,t \in (a,b)$ , $||\gamma(s)-\gamma(t)||$ is a non-negative real valued function which depends only on $|t-s|$ . Show that $\gamma(t)$ has speed and curvature both constant. Here is my attempt: I somehow have to use the constraint given of the function $||\gamma(t)- \gamma(s)||$ . Since this acts on $(a,b)^2$ , I want to handle a nicer funcion defined as follows: $$f(h):= ||\gamma(s+h)-\gamma(s)||^2$$ for $s\in(a,b)$ fixed. Taking the derivative with respect to $h$ , denoting with $\langle \cdot , \cdot \rangle$ the Euclidean inner product on $\mathbb{R}^2$ $f'(h)= \frac{d}{dh}\langle \gamma(s+h) - \gamma(s) , \gamma(s+h) - \gamma(s) \rangle = \frac{d}{dh} [\langle \gamma(s+h), \gamma(s+h) \rangle + \langle \gamma(s), \gamma(s) \rangle -2 \langle \gamma(s+h), \gamma(s) \rangle ] = 2[\langle \frac{d}{dh}\gamma(s+h), \gamma(s+h) \rangle - \langle \frac{d}{dh}\gamma(s+h), \gamma(s) \rangle] = 2[\langle \frac{d}{dh}\gamma(s+h), \gamma(s+h) - \gamma(s) \rangle ]$ So $f'(0)=0 \quad \forall s$ I think this is somehow useful, but I don't see how to continue from here.","['plane-curves', 'curves', 'differential-geometry']"
2977998,What are the necessary and sufficient conditions for a function to be Henstock–Kurzweil integrable?,I recently stumbled upon Lebesgue’s criterion for Riemann integrability. It didn't take very long until I found this result quite intuitive. I then began studying the Henstock–Kurzweil integral. Very quickly I realized that finding the necessary and sufficient conditions for a function to be Henstock–Kurzweil integrable would be much more difficult since functions with significantly worse discontinuities have to be treated. Has there been any research on this topic?,"['integration', 'analysis', 'real-analysis', 'calculus', 'gauge-integral']"
2978013,Showing a Geodesic Result,"Given the surface of the unit sphere with usual metric $$\large ds^2 = d\theta^2 + \sin^2(\theta)\,d\phi^2$$ I have calculated the Euler-Lagrange equations \begin{align*}\large
\ddot{\theta} - \sin\theta\cos\theta\dot{\phi}^2 &= 0\\ \large
\ddot{\phi} + 2\cot\theta\dot{\phi}\dot{\theta} &= 0
\end{align*} Giving the Christoffel symbol components as \begin{align*}\large
\Gamma^\theta_{\phi\phi} = -\sin\theta\cos\theta,\quad\Gamma^\theta_{\theta\theta} = \Gamma^\theta_{\theta\phi} &= 0\\ \large
\Gamma^\phi_{\theta\phi} = \Gamma^\phi_{\phi\theta} = \cot\theta,\quad\Gamma^\phi_{\theta\theta} = \Gamma^\phi_{\phi\phi} &= 0
\end{align*} Now there is the question to show that a line of constant $\phi$ is a geodesic. How would one go about this, given what I have done so far?","['general-relativity', 'differential-geometry']"
2978039,How to solve the differential equation $y''=\frac{y'}{y}$,"I want to solve the initial value problem: $$y''=\frac{y'}{y},\;\ y'(x=0)=1,\;\ y(x=0)=e$$ I have attempted to integrate on both sides but this results in a logarithm term on the r.h.s., which causes problems when I divide on both sides by it. I am not sure whether it is possible to isolate $y$ .","['initial-value-problems', 'calculus', 'ordinary-differential-equations']"
2978043,"There are 50 misprints in a book which has 250 pages, find the probability that page 100 has no misprints? (Use theoretically correct distribution)","My question is where this should be modelled as a binomial distribution problem or a Poisson distribution problem. Any hint/advice helps, thanks in advance!","['poisson-distribution', 'probability-distributions', 'binomial-distribution', 'probability']"
2978115,Formal proof of $f(n) = \Theta(f(n/2))$,"Is $f(n) = \Theta(f(n/2))$ ? If I take $f = 2^n$ , then whatever value I choose for the constant c, $$2^n \geq c \cdot {2^{n/2}}$$ there exists a value of n, such that $2^n$ is bigger. How can I show that there is no limit on how large $2^{n/2}$ can be, so that $2^n \neq \Theta(2^{n/2}) $ ?","['limits', 'functions', 'asymptotics']"
2978138,Non-vanishing volume form on $S^2$,"I have been given the form $\mu=x\,dy\wedge dz+y\,dz\wedge dx+z\,dx\wedge dy\in\Omega^2(S^2)$ . I am asked to prove that this form is never vanishing. That is, $\nexists p\in S^2$ such that $\mu_p=0$ . Intuitively, I would say that th eonly point where $\mu$ vanishes is $(0,0,0)$ which is not in $S^2$ , so $\mu$ is nowhere 0. However, I know there are expressions of the form $xdx+ydy+zdz$ which are 0 on $S^2$ . How could I prove that $\mu$ is nowhere vanishing?","['spheres', 'differential-forms', 'differential-geometry']"
2978156,"Multivariate Chain rule, why addition?","Lets consider the above graph. Now $\left[ \frac{\delta h}{\delta f},\,\frac{\delta h}{\delta g} \right]$ is the Jacobian. $\frac{\delta h}{\delta f}$ is the magnitude of vector along $f(x)$ and $\frac{\delta h}{\delta g}$ is the magnitude of vector along $g(x)$ . So, $$\sqrt{{{\left( \frac{\delta h}{\delta f} \right)}^{2}}+\,\,{{\left( \frac{\delta h}{\delta g} \right)}^{2}}}$$ gives the magnitude of vector of steepest change of $h( f(x), g(x))$ , which is the estimate of the change of $h$ w.r.t. $f$ and $g$ . Now if I nudge $x$ the jacobian $\left[ \frac{\delta h}{\delta f},\,\frac{\delta h}{\delta g} \right]$ will change i.e. $\frac{\delta h}{\delta f}\frac{\delta f}{\delta x}$ and $\frac{\delta h}{\delta g}\frac{\delta g}{\delta x}$ . These show how the contents of the Jacobian will change w.r.t. $x$ . Now I consider the diagram same as this one So, $$\left[ \frac{\delta h}{\delta f}\frac{\delta f}{\delta x},\,\,\frac{\delta h}{\delta g}\frac{\delta g}{\delta x} \right]$$ can be considered as new Jacobian and the estimate of change in $h$ w.r.t $x$ will be calculated just by finding root of sum of squares of the elements in the Jacobian. But the formula says $$\frac{dh}{dx}=\frac{\delta h}{\delta f}\frac{\delta f}{\delta x}+\frac{\delta h}{\delta g}\frac{\delta g}{\delta x}$$ I am trying to understand the chain rule w.r.t. estimating the change in $h$ w.r.t. $x$ . I am sure I have lots of misconception but will be glad if you point that out.","['multivariable-calculus', 'calculus', 'vectors']"
2978175,Prove $\lim_{n\to\infty}\sqrt{(n+a)(n+b)}-n=\frac{a+b}2$,"Prove $$\lim_{n\to\infty}\sqrt{(n+a)(n+b)}-n=\frac{a+b}2.$$ I have found the preceding problem in the Calculus book (Bartle & Sherbert) where I am asked to demonstrate the previous limit assuming $a>0$ , $b>0$ . I have been trying for an hour, but I cannot see how I can demonstrate it.","['limits', 'limits-without-lhopital']"
2978179,Is a Subgroup Characteristic in its Normalizer?,"Let $G$ be a finite group and $H \subseteq G$ . Is it true that $H$ is a characteristic subgroup of $N_{G}(H)$ ? Knowing that ""the something"" subgroup must be characteristic, I believe it must be true. 
Any comments would be appreciated!","['group-theory', 'abstract-algebra', 'finite-groups']"
2978216,Prove that we can't find effective bounds on the point guaranteed by the Mean Value Theorem.,"I wish to show that we cannot find effective bounds on the point that the Mean Value Theorem proves to exist. To prove this loose statement, I aimed at the slightly more specific claim: For each real number $M$ and each real number $\xi$ that lies strictly between $0$ and $1$ , construct a function $f$ such that $$f(0)=0,\; f(1)=M,\;f\text{ is continuous on }[0,1],\; f\text{ is differentiable on }(0,1),\;\text{ and }\xi\text{ is the unique point strictly between 0 and 1 such that}\;f'(\xi)=M\,.$$ For the $M\neq 0$ and $\xi\neq 1/e$ case, we can show that $$g(x)=\begin{cases}
0&\text{ if }x=0,\\
1/e&\text{ if }x=1\\
1&\text{ if }x=\infty,\\
\sqrt[1-x]{x}&\text{ otherwise}
\end{cases}$$ is strictly increasing and continuous on $[0,\infty]$ . Thus there is a unique positive $\alpha$ such that $g(\alpha)=\xi$ . In turn, we can define $f(x)=Mx^\alpha$ which will satisfy the claim. For the $M\neq 0$ and $\xi=1/e$ case, take the obvious continuous extension of $f(x)=M(x+x\ln(x))$ . For $M=0$ , we first choose $\alpha\geq 1$ and $\beta\geq 1$ such that $\frac{\alpha}{\alpha+\beta}=\xi$ . We then define $f(x)=x^\alpha(1-x)^\beta$ which will satisfy the claim. My question however is this: Can we construct such an $f$ to be a polynomial? An existential proof isn't desirable here, as I hope to use this family of polynomials as examples. It'd be useful to prove the uniqueness of $\xi$ through calculation (but possibly an appeal to monotonicity and the Intermediate Value Theorem).","['calculus', 'polynomials', 'real-analysis']"
2978220,$2n = \phi(a) + \phi(b)$,"The values of the Euler phi function $\phi(n)$ are tabulated at OEIS A $000010$ . Each of these values is even except for $\phi(1) = \phi(2) = 1$ .  However, not every even number arises in this way.  Those that don't $( 14, 26, 34, 38, ... )$ are listed at OEIS A $005277$ . A little experimentation suggests that every even number can be written as $$2n = \phi(a) + \phi(b)$$ If we invoke Goldbach's conjecture, then this can be shown as follows.  Writing $2n + 2 = p + q$ for primes $p$ and $q$ yields $2n = \phi(p) + \phi(q)$ . [For odd numbers we could rewrite this using three summands as $2n +1 = \phi(p) + \phi(q) + \phi(1)$ . ] Question:  There are many more phi values than (shifted) primes indicating that this problem might be accessible even though Goldbach currently is not.
Is it possible to give an unconditional proof that $2n = \phi(a) + \phi(b)$ always has a solution? Thanks","['number-theory', 'totient-function', 'goldbachs-conjecture']"
2978238,Categorical Interpretation of Radical Ideals,"Reading around about the Nullstellensatz theorem, I saw that we can interpret the maps $V\to I(V)$ (where $V$ is an algebraic set) and $S\to Z(S)$ (where $S$ is an ideal), as functors which are adjoint, in some sense. I didn't find, however, more then side remarks about this. So I'm having a hard time trying to understand the full picture: what are the categories here, exactly? I can see how we can define the category of algebraic affine sets, but how do we think about the ideals as a category? Do we think of it as a subcategory of the modules over $k[\bar x]$ ? Looking at this question gives a way to do it, but why is it a good way- don't we want to save some of the algebraic structure? Also, the radical ideals have some special property - the image of $I$ consists only of radical ideals. I wonder if there is a universal property for radical ideals, and whether it says something of value in the category of algebraic sets? Can it explain this special property? I don't know a lot of category theory- just some basic definitions and constructions, so I am sorry if this make no sense at all, or if I am missing something trivial. Thanks in advance to anyone who can help in clarifying any of the points above, or maybe provide some references.","['algebraic-geometry', 'soft-question', 'category-theory']"
2978351,"Is $E(Y|X)=0, a.s.$ equivalent to $E[Y\cdot f(X)]=0, \forall f\in \mathscr{B}$?","Is the statement below true? How to prove it? $$E(Y|X)=0, a.s.$$ is equivalent to $$E[Y\cdot f(X)]=0, \forall f\in \mathscr{B}$$ If $E(Y|X)=0, a.s.$ , then $E[Y\cdot f(X)]=E\{E[Y\cdot f(X)|X]\}=E[f(X)\cdot E(Y|X)]=0$ . How to prove the opposite part?","['statistics', 'measure-theory', 'conditional-expectation', 'probability-theory', 'probability']"
2978386,Use simulations in R to numerically estimate medians and modes for discrete uniform variables.,"The question I have been given is: Let X be Discrete Uniform on 1, 2, . . . , n. Please note that your answers to the questions below can depend
on whether n is even or odd. (a) Use simulations in R (the statistical programming language) to numerically estimate all medians and
all modes of X for n = 1, 2, . . . , 10. And here is the R code I have written: set.seed(1987)

rDiscUnif <- function(n,k) sample(1:k, n, replace=T) #sample randomly from disc. unif.

findModes <- function(x) {
  ux <- unique(x) #extracts unique elements of a vector
  matchx <- match(x, ux) #stores index of ux match for ea. x
  tab <- tabulate(matchx) #counts how many times each index appears 
(effectively counting the times each unique value appeared)
  ux[tab == max(tab)] #returns the mode (or modes)
}


for(i in 1:10) { #for each required value of k (n in problem statement)
  x <- rDiscUnif(1000, i) #make sample
  print(table(x)) #make a table so you can spot the mode manually as well
  plot(table(x)) #plot the table so you can see it looks uniformish
  print(paste(""for n = "", i, "" median is "", median(x)))
  z <- findModes(x)
  print(paste(""for n = "", i, "" mode(s) is/are "",  z))
} So my question is: does this satisfy the question? In particular I'm not sure if I should write a function that will find the median based on a formula (which I found in another part of the question; med=(n+1)/2 when n is odd and $x_{n/2} \leq med \leq x_{(n/2)+1}$ when n is even), or if I should use the regular median function for the ""numerical estimate"".","['statistics', 'probability-distributions', 'median', 'probability']"
2978401,Variance of $\int_0^1X(t)dt$,"Let $X(t)$ be a stationary random variable with expected value $E[X(t)] = m$ and  covariance function $r_X(\tau) = 2e^{-|\tau|}$ . I'm asked to calculate the variance of $\int_0^1X(t)dt$ , $$V[\int_0^1X(t)dt].$$ I've tried using the formula $$C[X,Y] = E[XY] - E[X]E[Y]$$ but I can't figure out $$E[\int_0^1X(t)dt\cdot\int_0^1X(t)dt].$$ How do I do it? Note; all the information given may not be necessary. The answer is supposedly $4e^{-1}.$","['stochastic-processes', 'statistics', 'variance', 'random-variables']"
2978505,Why can we multiply by breaking up the factors as sums in different ways?,"My friend and I were discussing some mathematical philosophy and how the number systems were created when we reached a question. Why can we multiply two different numbers like this? Say we had to multiply $13\times 34$ . One may break this up like $(10+3)\times (30+4)$ . Applying distributive property here will give us the answer of 442. We can also choose to multiply this as $(6+7)\times (22+12)$ . Intuitively, we can hypothesize that this should give us the same answer as $13\times 34$ . How can we prove that our answer will be equal regardless of how we break up the numbers?","['algebra-precalculus', 'arithmetic']"
2978523,Show that there is no non-constant random variable such that Chebyshev Inequality becomes an equality for all $x>0$,"I'm trying to show that there is no non-constant random variable with finite mean $\mu$ such that $$P(|X-\mu|\geq x)=\frac{\sigma^2}{x^2}$$ for all $x>0$ . I know that the equality can be achieved for a fixed $x$ with random variables with zero mean and unit variance, but I'm not sure how to tackle this problem. I noticed that if the equality were to happen, for $x<\sigma$ , then $P(|X-\mu|\geq x)=\frac{\sigma^2}{x^2}>1$ , which is a contradcition as $P$ is a probability. Is that the only source of contradiction here, or is there something deeper that must be recognized and be proven? I would appreciate more feedback on my approach or a push in the right direction for another approach!","['proof-verification', 'probability-theory', 'probability', 'real-analysis']"
2978592,How to show two inner products are the same?,"My professor told us there is a theorem which states that given a finite dimensional vector space $V$ with inner product $<|>_V$ , we can have some sort of relationship between the inner product $<|>_V$ and the standard inner product of $\mathbb R^n$ . What is this theorem? Where can I find this theorem? For example, $V$ is $\mathbb R_1[t]$ , first order polynomials of the variable $t\in \mathbb R$ , with the standard basis. Suppose we have a function from $\mathbb R_1[t] \times\mathbb R_1[t] \to \mathbb R$ defined by $$<a_0+ a_1t \mid b_0+b_2 t> = a_0b_0+a_1b_1.$$ How to show this is an inner product by showing that this function is the ""same"" as the standard inner product in $\mathbb R^2$ ?","['abstract-algebra', 'linear-algebra', 'functional-analysis']"
2978611,"value of $\int_{-\infty}^{\infty}\arcsin\frac1{\cosh x}\,dx$","I want to know the value of $$I=\int_{-\infty}^{\infty}\arcsin\frac1{\cosh x}\,dx$$ The Symbolab integral calculator says that the integral diverges, but when one graphs it obvious that it converges. So what is the value? I was thinking that I might try Feynman integration, but I can't think of the right substitution. Alert! Alert! I've found an antiderivative! From the answer provided by @user10354138, we can reach $$\int\arcsin\frac1{\cosh x}dx=i\operatorname{Li}_2(i\phi)-i\operatorname{Li}_2(-i\phi)+C$$ Where $$\phi=\tan\bigg(\frac12\arcsin\frac1{\cosh x}\bigg)$$ And $$\operatorname{Li}_2(z)=\sum_{n\geq1}\frac{z^n}{n^2}$$ is the Di-logarithm .","['integration', 'analysis']"
2978658,How to calculate the Kampé de Fériet function?,"This is a continuation of this post . The following is my original question in that post. Question : Is it possible to express $$\sum_{l=0}^\infty \sum_{r=0}^\infty\frac{\Gamma(L+r-2q)}{\Gamma(L+r-1+2q)} \frac{\Gamma(L+r+l-1+2q)}{\Gamma(L+r+l+2)}\frac{r+1}{r+l+2}$$ in closed form independent of summations (possibly in terms of Gamma function)? @G Cab managed to reduce the double summations above using Kampé de Fériet function $$ \bbox[lightyellow] {  
\eqalign{
 & S(L,q) = A\;\sum\limits_{r = 0}^\infty  {\sum\limits_{l = 0}^\infty  {{{3^{\,\overline {\,r + l\,} }
 \left( {c - d} \right)^{\,\overline {\,r + l\,} } } \over {4^{\,\overline {\,r + l\,} } c^{\,\overline {\,r + l\,} } }}{{3^{\,\overline {\,r\,} } 1^{\,\overline {\,l\,} }
 \left( {a - b} \right)^{\,\overline {\,r\,} } 1^{\,\overline {\,l\,} } 1^{\,\overline {\,r\,} } 1^{\,\overline {\,l\,} } }
 \over {2^{\,\overline {\,r\,} } 1^{\,\overline {\,l\,} } a^{\,\overline {\,r\,} } 1^{\,\overline {\,l\,} } }}{{x^{\,r} }
 \over {r!}}{{y^{\,l} } \over {l!}}} }   =   \cr 
  &  = F\left( {\matrix{   2  \cr    3  \cr    2  \cr    2  \cr 
 } \,\left| {\,\matrix{
   {3,\left( {c - d} \right)}  \cr 
   {3,\,1\;;\;\left( {a - b} \right),1\;;\;\;1,1}  \cr 
   {4,c}  \cr 
   {2,\,1\;;\;a,1}  \cr 
 } \,} \right|x,y} \right)\quad \quad \left| {\;x = y = 1} \right. \cr} 
}$$ where $r,l,L\geq 1$ are integers and $q\in [0,1]$ is a real number. The final answer should be similar to the form $$1 - \frac{2q^2}{(1-2q)^2} - \frac{2\pi q(1-q)}{(1-2q)(3-4q)} \cot(2\pi q).$$ Here comes my question for this post. Question : How to calculate the Kampé de Fériet function to get answer above? Based on @Nikos Bagis in that post, Mathematica 10 gives something involving gamma functions, cotangent and some generalized hypergeometric series . UPDATED: 08/11/18 @Nikos Bagis compuated a closed form for the double summations above. $$
F_1(L,q,x):=\sum^{\infty}_{l=0}\sum^{\infty}_{r=0}\frac{\Gamma(L+r-2q)\Gamma(L+r+l-1+2q)}{\Gamma(L+r-1+2q)\Gamma(L+r+l+2)}x^lx^r.
$$ Then $$
F_1(L,q,x)=-\frac{\Gamma(L-2q)(L-2q-1)}{4q-2}{}\frac{1}{\Gamma(L+2)} {}_2F_1(1,L-2q;L+2;x)+
$$ $$
\frac{(L+2q-2)\Gamma(L-2q)}{4q-2} \frac{1}{\Gamma(L+2)} {}_2F_1\left(1,L+2q-1;L+2;x\right)-
$$ $$
-\frac{\Gamma(L-2q)}{4q-2} \frac{1}{\Gamma(L-+)} {}_2F_1\left(2,L-2q;L+2;x\right),
$$ where $$
pF_q\left(a_1,a_2,\ldots,a_p;b_1,b_2,\ldots,b_q;z\right):=
$$ $$
\sum_{n=0}^\infty \frac{(a_1)_n (a_2)_n...(a_p)_n}{(b_1)_n (b_2)_n...(b_p)_n}\frac{x^n}{n!}$$ is the generalized hypergeometric function. Now my question is How to show that $$\sum^{\infty}_{l=0}\sum^{\infty}_{r=0}\frac{\Gamma(L+r-2q)\Gamma(L+r+l-1+2q)}{\Gamma(L+r-1+2q)\Gamma(L+r+l+2)}x^lx^r = $$ $$
F_1(L,q,x)=-\frac{\Gamma(L-2q)(L-2q-1)}{4q-2}{}\frac{1}{\Gamma(L+2)} {}_2F_1(1,L-2q;L+2;x)+
$$ $$
\frac{(L+2q-2)\Gamma(L-2q)}{4q-2} \frac{1}{\Gamma(L+2)} {}_2F_1\left(1,L+2q-1;L+2;x\right)-
$$ $$
-\frac{\Gamma(L-2q)}{4q-2} \frac{1}{\Gamma(L-+)} {}_2F_1\left(2,L-2q;L+2;x\right)
$$ and $$
F_2(L,q,x)=
$$ $$
=\frac{x\Gamma(L-2q+1)(2+L-6q-4Lq+8q^2)}{2(2q-1)(4q-3)\Gamma(L+3)}{}_2F_1\left(2,L-2q+1;L+3;x\right)-
$$ $$
-\frac{\Gamma(L-2q+1)(L+2q-2)}{2(2q-1)(4q-3)\Gamma(L+2)}{}_2F_1(1,L-2q;L+2;x)+
$$ $$
+\frac{\Gamma(L-2q+1)(L+2q-2)}{2(2q-1)(4q-3)\Gamma(L+2)}{}_2F_1(1,L+2q-1;L+2;x)-
$$ $$
-x\frac{\Gamma(L-2q+1)}{(4q-3)\Gamma(L+3)} {}_3F_2\left(2,2,L-2q+1;1,L+3;x\right).
$$ where $$
F_2(L,q,x):=\sum^{\infty}_{l=0}\sum^{\infty}_{r=0}\frac{\Gamma(L+r-2q) \Gamma(L+r+l-1+2q)}{\Gamma(L+r-1+2q) \Gamma(L+r+l+2)}rx^lx^r?
$$","['special-functions', 'gamma-function', 'discrete-mathematics', 'sequences-and-series', 'hypergeometric-function']"
2978661,Find $\lim_{x\to0} \frac{\ln(2x+1)-\ln(1-3x)}{x}$ using the definition of derivative,"Use the definition of derivative and find the following limit: $\lim_{x\to0} \dfrac{\ln(2x+1)-\ln(1-3x)}{x}$ I do not understand what this question is asking me to do. What does it mean to get the limit at 0 and how does that relate to the derivative using this example? Are not the limit and the derivative at 0 going to be different? I am really confused as to how I need to approach this question, do I take the derivative of the limit at 0? I am probably misinterpreting this question altogether, please help me clarify? Thank you.","['limits', 'definition', 'derivatives', 'real-analysis']"
2978745,Jet prolongation of a distribution on a manifold,"I'm trying to work with the first jet prolongation of a $k$ -distribution on a manifold $M$ of dimension $n$ . My intuition is to consider the Grassmann bundle $X=Gr_k(TM)\to M$ and look at the first jet space $X^{(1)}$ . But I'm stuck at how to write down a point in the jet space. From the definition, a typical point has to be of the form $j^1_\mathcal{D}(p)$ , for some germ of local section $\mathcal{D}$ of $X$ at the point $p\in M$ . Thus $\mathcal{D}$ is a locally defined $k$ -distribution around $p$ . But how do I write $j^1_\mathcal{D}(p)$ in local coordinates? Another approach could be using the $k$ -frame bundle and the take jet prolongation. But again, I cannot think about the local coordinates. Any help is appreciated.","['jet-bundles', 'grassmannian', 'differential-geometry']"
2978806,A martingale converging in distribution but not a.s. or in probability,"I am now working on R. Durrett's Probability Theory and Examples . In his book, I am asked to construct a martingale $(X_n)$ satisfying the following three conditions. (1) $P(X_n=a$ i.o. $)=1, a=-1,0,1$ (2) $\sup_n|X_n|<\infty$ (3) For some preassigned $p \in (0,1/2)$ , $P(X_n=1),P(X_n=-1)\rightarrow p, P(X_n=0) \rightarrow 1-2p$ So that this martingale converges in distribution but not a.s. or in probability. I know there already exists an answered question regarding (1)&(2), but so far I haven't found any identical question. So I guess this question is not a duplicate. I have been spending 2 days and could not come up with an example. Especially, condition (3) is hard to manage since I cannot make use of the similar trick used in the answer of Martingale oscillating between three values Any hint would be appreciated! Thanks and regards.","['sequences-and-series', 'martingales', 'convergence-divergence', 'probability-theory', 'probability']"
2978808,Combinatorics: How many persons like apples and pears and strawberries?,"Out of $32$ persons , every person likes to eat at least one of the following type of fruits: Strawberries, Apples and Pears. (Which means that there does not exist any person, who does not like to eat any type of fruit). Furthermore, we know that $20$ persons like to eat apples , $18$ persons like to eat pears and $28$ persons like to eat strawberries . (a) There are $10$ persons who like apples and pears , $16$ persons who like apples and strawberries , and $12$ persons who like pears and strawberries . How can I find out how many people like apples as well as pears as well as strawberries? To structure this a bit: $32$ persons $20 \rightarrow$ apples ( $\rightarrow$ meaning ""like"") $18 \rightarrow$ pears $28 \rightarrow $ strawberries And for (a) $10$ persons $\rightarrow$ (apples & pears) $16$ persons $\rightarrow$ (apples  & strawberries) $12$ persons $\rightarrow$ (pears & strawberries) Since we know that the total number of persons is $32$ . Can I just do the following? Because $20$ persons like apples I can just add the following numbers together: $10 \rightarrow$ ( $10$ apples & $0$ pears) + $16 \rightarrow$ ( $6$ apples & $10$ strawberries) $+ 12 \rightarrow$ ( $12$ pears & $0$ strawberries). So in total I'd get $10 + 16 + 12 = 28$ people who like apples, pears and strawberries? Is that correct? (b) Assume that you don't have the information in (a). Give the preferably  limits for the amount of persons who like to eat all kind of fruits. Since $18$ person like pears, can I just say that $18$ persons like to eat pears, apples and strawberries? (As $18$ is the minimal amount of fruits).",['elementary-set-theory']
2978909,Maximal interval of existence for $x'=\frac{xt}{\sqrt{x^2+1}}$,"I want to find the maximal interval of existence for $$x'=f(x,t)=\frac{xt}{\sqrt{x^2+1}},\ x(0)=1$$ and I want to use a theorem I found in one of my books. It is a certain statement of boundary behaviour of maximal solutions which I couldn't find in a wikipedia article to link. So just to make sure we are on the same page I will provide the theorem: Let $D\subseteq \mathbb R\times \mathbb R^n$ be a domain and $f:D\to\mathbb R^n,\ (t,x)\mapsto f(t,x)$ be continuous and locally Lipschitz with respect to $x$ . For $(\tau,\zeta)\in D$ let $\lambda:]a,b[\to\mathbb R^n$ be a solution of the IVP $$x'=f(t,x),\ x(\tau)=\zeta$$ Then $\lambda$ is a maximal solution to the IVP iff one of the conditions hold: $a=-\infty$ $a>-\infty$ and $\limsup_{t\to a}||\lambda(t)||=\infty$ $a>-\infty,\partial D=\emptyset$ and $\lim_{t\to a}\text{distance}(\partial D,(t,\lambda(t)))=0$ Replacing the $-\infty$ with $\infty$ yields the conditions for $b$ so I will not list them here. Now back to the problem: Since $f$ is continuously differentiable with respect to $x$ it is clear that $f$ is locally Lipschitz and therefore we have a unique maximal solution to the IVP with I will call $\lambda:\ ]a,b[\to\mathbb R$ . The argument for $a$ should be the same as for $b$ so I will only care about the first one. Obviously we have $\partial D=\emptyset$ so (3.) is not an option and we only need to take care of (2.). So let's assume $a>-\infty$ , then I am using $$f(t,x)\leq\text{sgn}(x)t$$ to obtain $$\limsup_{t\to a}|\lambda(t)|=\limsup_{t\to a}|\lambda(0)+\int_0^t\lambda'(s)ds|=\limsup_{t\to a}|1+\int_0^t f(s,x)ds|\leq$$ $$\leq\limsup_{t\to a}|1+\text{sgn}(x)\int_0^t sds|=|1+\text{sgn}(x)\cdot\frac{a^2}{2}|<\infty$$ so only option (1.) is left and the same goes for $b$ , so in total we have that the maximal interval of existence is $\mathbb R$ . Is my reasoning correct here? And if not, what is wrong and how do I fix it?","['initial-value-problems', 'proof-verification', 'ordinary-differential-equations']"
2978922,Calculating cohomology of sheaves,"I am trying to prove that the twisted cubic $C: (u,v)\rightarrow(u^3,u^2v,uv^2,v^3)$ has as resolution $$
0\rightarrow \mathcal O(-1)^2\rightarrow \mathcal O^3\rightarrow \mathcal I_C(2)\rightarrow0,
$$ where $\mathcal I_C$ is the ideal sheaf, using the Beilinson Theorem. For this I must calculate the cohomology $H^i(\Omega^j(j)\otimes\mathcal I_C(2))$ (actually I only need the dimension), but I do not now how compute that, any tips of methods or literature that can help me? Thanks in advance.","['algebraic-geometry', 'homology-cohomology', 'sheaf-cohomology']"
2978938,Which inequality for the fourth central moment do we need to apply here?,"Let $d\in\mathbb N$ with $d>1$ $\lambda^d$ denote the Lebesuge measure on $\mathcal B\left(\mathbb R^d\right)$ $f\in C^2(\mathbb R)$ be positive and $$\pi(x):=\prod_{i=1}^df(x_i)\;\;\;\text{for }x\in\mathbb R^d$$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space $X:\Omega\to\mathbb R^d$ with $X_\ast\operatorname P=\pi\lambda^d$ Now, let $$g(x):=\frac1{d-1}\sum_{i=2}^d\left|\frac{f'(x_i)}{f(x_i)}\right|^2\;\;\;\text{for }x\in\mathbb R^d.$$ Assume $$M:=\int\frac{|f'|^8}{f^7}\:{\rm d}\lambda^1<\infty\tag1.$$ Note that $$\operatorname E\left[g(X)\right]=\int\frac{\left|f'\right|^2}f\:{\rm d}\lambda^1=:I.\tag2$$ I want to show that $$\operatorname E\left[\left|g(X)-I\right|^4\right]\le d^{-\frac12}(d-1)^{-\frac32}3M\tag3.$$ Is there an easy estimate which yields $(3)$ ? Clearly, we can expand the left-hand side using the multinomial theorem, but then we deal with a complicated expression and annoying computations. On the other hand, by applying the Cauchy-Schwarz inequality twice, we obtain $$\operatorname E\left[\left|g(X)-I\right|^4\right]\le\frac1{d-1}\sum_{i=2}^d\operatorname E\left[\left|\left|\frac{f'(X)}{f(X)}\right|^2-I\right|^4\right],$$ but I don't know how we need to proceed from here.","['expected-value', 'inequality', 'probability-theory']"
2978997,"Completion of $C^{\infty,2}_0$ is a subset of $L^2(\mathbb{R}^n)$?","this question comes from quantum mechanics in physics. Let $C^{\infty}_0$ be the space of smooth functions with compact support. Then define $C^{\infty,2}_0 := C^{\infty}_0 \oplus C^{\infty}_0 $ . and define an inner product $(\cdot , \cdot)_0$ by $$
\begin{equation}
(f,g)_0 = \sum^n_{i=1} (D_i f_1, D_i g_1) + M^2 (f_1,g_1) + (f_2, g_2),
\end{equation}
$$ where $f,g \in C^{\infty,2}_0 $ , $f_i$ are the components of $f$ , $M^2$ is a positive constant and $(\cdot, \cdot)$ denotes the $L^2$ scalar product on $\mathbb{R}^n$ . My question is if the completion of $C^{\infty,2}_0$ with respect to the induced norm is a subset of $L^2(\mathbb{R}^n)^2$ .","['general-topology', 'normed-spaces', 'functional-analysis']"
2979034,Looking for a counter-example in Multi-variable Calculus,"I looking for a proof or a counterexample (more likely) for the following Claim: Claim. Let $\,\boldsymbol{f}:U\to\mathbb R^n$ , where $U\subset\mathbb R^m$ open, and $\boldsymbol{a}\in U$ , be a function with the property that, there exists a matrix $A\in\mathbb R^{n\times m}$ , such that for every smooth curve $\boldsymbol{\gamma}: I\to U$ , where $I$ is an open interval and $0\in I$ , with $\boldsymbol{\gamma}(0)=\boldsymbol{a}$ and $\boldsymbol{\gamma}'(0)\ne \boldsymbol{0}$ , the composition $h(t)=\boldsymbol{f}\big(\boldsymbol{\gamma}(t)\big)$ is differentiable at $t=0$ and $h'(0)=A\boldsymbol{\gamma}'(0)$ . Then $\boldsymbol{f}$ is differentiable at $\boldsymbol{x}=\boldsymbol{a}$ . So far, available are the following examples (which do not consist counterexamples of the above): A. $f(x,y)=\left\{\begin{array}{ccc}\displaystyle
\frac{xy^2}{x^2+y^6} & if & (x,y)\ne (0,0), \\
0 & if & (x,y)=(0,0).
\end{array}\right.$ For this $f$ all the directional derivatives exist, but $f$ is not even continuous at $(x,y)=(0,0)$ B. $f(x,y)=\left\{\begin{array}{ccc}\displaystyle
\frac{x^3}{x^2+y^2} & if & (x,y)\ne (0,0), \\
0 & if & (x,y)=(0,0).
\end{array}\right.$ For this $f$ , the composition $h=f\circ\boldsymbol\gamma$ is differentiable at $t=0$ and it is a function of $\boldsymbol\gamma'(0)$ , but it does not depend linearly on $\boldsymbol\gamma'(0)$ .
In particular, if $\boldsymbol\gamma'(0)=(a,b)\ne (0,0)$ , then $h'(0)=\displaystyle\frac{a^3}{a^2+b^2}$ .","['multivariable-calculus', 'calculus', 'examples-counterexamples', 'differential-geometry']"
2979067,Under what circumstances is a characteristic function Riemann integrable?,"Let $E$ be a subset of the interval $[a,b]$ .  My question is, under what circumstances is the characteristic function $1_E$ Riemannn integrable on $[a,b]$ ? Now a function is Riemann integrable if and only if its set of discontinuities is of Lebesgue measure zero.  And the set of discontinuities of $1_E$ is equal to the boundary of $E$ .  So this is equivalent to asking, under what circumstances does the boundary of a set $E$ have measure zero? $E$ having measure zero isn't a strong enough condition, because a set of measure zero could have a boundary of positive measure. So what condition does $E$ need to satisfy? And what is the Sigma algebra generated by sets with Riemann integrable characteristic functions?","['measure-theory', 'lebesgue-measure', 'riemann-integration']"
2979131,What is the Sigma Algebra generated by Jordan measurable sets?,"Unlike Lebesgue measurable sets, Jordan measurable sets do not form a Sigma algebra.  So my question is, what is the Sigma algebra $J$ generated by Jordan measurable sets? All intervals are Jordan measurable, so $J$ contains all the Borel sets.  But this answer shows that not all Jordan measurable sets are Borel sets, so the Borel Sigma algebra is a proper subset of $J$ .  And all Jordan measurable sets are Lebesgue measurable, so $J$ is a subset of the Lebesgue Sigma algebra.  But are there Lebesgue measurable sets not contained in $J$ ?","['measure-theory', 'lebesgue-measure', 'borel-sets', 'descriptive-set-theory', 'riemann-integration']"
2979209,Basis formed by hyperbolic functions,"I am currently working with separation of variables for different kinds of PDEs and one often uses here the fact that one has the sine base , i.e., $$ \left( \sin(k\pi y) \right)_{k=1}^{\infty} $$ forms a base of $L^2(0,1)$ . This also holds on discrete level, i.e., having vector $v_k \in \mathbb{R}^{n-1}$ defined entry-wise as $$ v_k = \left( \sin(\frac{k\pi}{n} j) \right)_{j=1}^{n-1} $$ then the set $\{v_k\}_{k=1}^{n-1}$ is basis of $\mathbb{R}^{n-1}$ . However, in some cases it would be much more suitable to use the hyperbolic functions - in this case the hyperbolic sine. My question is whether or not the analogue holds for hyperbolic sines as well, i.e., (A) Is the $\left( \sinh(k\pi y) \right)_{k=1}^{\infty}$ basis of some reasonable Lebesgue space on $(0,1)$ ? (B) Having vector $w_k \in \mathbb{R}^{n-1}$ defined entry-wise as $$ w_k = \left( \sinh(\frac{k\pi}{n} j) \right)_{j=1}^{n-1}, $$ is the set $\{w_k\}_{k=1}^{n-1}$ a basis of $\mathbb{R}^{n-1}$ ? Update : The computations suggest that also the vectors $w_k$ form a basis, but one that is incresingly ill-conditioned when $n$ grows. For $n=100$ , python computed that the condition number is of order $10^{130}$ . I am aware that at that point it is impossible to argue with such a result, so the question remains open. Also, I am interested only in the theoretical usage and I do not intend to use this basis (if it indeed is one in general) for computational purposes.","['change-of-basis', 'linear-algebra', 'vector-spaces', 'hyperbolic-functions']"
2979353,"Given a matrix $A(x)$, prove that $A(1)*A(2)*...*A(2017)=A(1009^2)$","I am given the matrix $A=\begin{bmatrix}1&x&0\\0&1&0\\0&0&30^x\end{bmatrix}$ and I have to prove: $A(1)*A(2)*...*A(2017)=A(1009^2)$ From previous sub-points of the problem I have proved that $A(x)*A(y)=A(x+y)$ (1) for any x,y from $R$ . Also, I have proved (with mathematical induction) that $A^k=\begin{bmatrix}1&k*x&0\\0&1&0\\0&0&30^{k*x}\end{bmatrix}$ (2), but I can't see how 
to use these to prove that $A(1)*A(2)*...*A(2017)=A(1009^2)$ . If I use (1), wouldn't $A(1)*A(2)*...*A(2017)=A(1+2+3+...+2017)$ ? Making the answer $A(2017*1009)$ ? Or am I using the proof (1) wrongly? How should I approach this problem?","['matrices', 'matrix-equations', 'proof-verification']"
