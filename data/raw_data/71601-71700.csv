question_id,title,body,tags
877256,How to show if A is denumerable and $x\in A$ then $A-\{x\}$ is denumerable,My thoughts: If $A$ is denumerable then it has a bijection with $\mathbb{N}$ So therefore $A\rightarrow \mathbb{N}$. Then x is a single object in A and A is infinite. So if a single object is removed from then $A$ is still infinite.,['elementary-set-theory']
877268,The union of all the open sets in a family of topologies,"I'm starting studying topology for the first time and my teacher just wrote this. I just don't understand the last line: Let $\{\tau_\alpha\}$ be a family of topologies on X.
  [...]
  To say that a collection of subsets of X contains all the collections $\tau_\alpha (\alpha\in A)$ is equivalent to saying that this collection contains $\bigcup_{\alpha\in A} \tau_\alpha$.
  We can see $X\in \bigcup_{\alpha\in A}\tau_\alpha$, then
  $$\bigcup_{H\in\bigcup_{\alpha\in A}\tau_\alpha} H = X$$ Why is he using the H set? Is it not $\bigcup_{\alpha\in A}\tau_\alpha = X$? Thanks!","['general-topology', 'elementary-set-theory']"
877269,Find the value of this infinitely nested radical (it appears to obtain multiple values),Find the value of $$\sqrt{1-\sqrt{\frac{17}{16}-\sqrt{1-\sqrt{\frac{17}{16}-\cdots}}}}$$ This is not as simple as it looks for one reason - there are $2$ real solutions to the equation $$x=\sqrt{1-\sqrt{\frac{17}{16}-x}}\implies\begin{cases}x_1=0.5\\x_2\approx 0.073\end{cases}$$ You can see that for yourself on Wolfram Alpha . How can we know the real value of this infinite radical?,"['radicals', 'nested-radicals', 'algebra-precalculus', 'limits']"
877282,Is there any theorem about figures of equal area and perimeter being congruent?,"I had an idea, that all geometric objects, that are different, as they're not a translation, rotation, and a reflection of one another cannot have the same area AND perimeter, as compared to ONE ANOTHER. They can't be CONGRUENT. If the shapes are similar there is no similar shapes can contradict this ""idea"", or that is what I think. I know that there was some idea on this, is there any theorem, or specific idea, which this is expressed?","['geometry', 'alternative-proof']"
877305,Limit of factorial function: $\lim\limits_{n\to\infty}\frac{n^n}{n!}.$ [duplicate],"This question already has answers here : Limit of the sequence $\{n^n/n!\}$, is this sequence bounded, convergent and eventually monotonic? (2 answers) limits of sequences exponential and factorial: $a_n=e^{5\cos((\pi/6)^n)}$ and $a_n=\frac{n!}{n^n}$ (3 answers) Closed 9 years ago . I am studying for a test and I am given this problem: $$\lim_{n\to\infty}\frac{n^n}{n!}.$$ How do I go about solving this limit? Intuitively I see how the numerator is growing much faster, but how do I express this precisely? Thanks!","['calculus', 'limits']"
877315,Class group of $\mathbb{Q}(\sqrt[4]{-2})$,"I would like to show directly that $C(K)$ is trivial, where $K = \mathbb{Q}(\sqrt[4]{-2})$. Write $\delta = \sqrt[4]{-2}$. It is pretty easy to see that $\mathcal{O}_K = \mathbb{Z}[\delta] = R$. Then $\Delta_K = 2048$, and the Minkowski bound is
$$ \frac{4!}{4^4}\left(\frac{4}{\pi}\right)^2\sqrt{2048}\approx 6.88,$$
so we need only check primes lying over $2$, $3$, $5$. Over $2$, since $\delta R = \mathfrak{B}_2$ has norm $2$, it is prime; since $\mathfrak{B}_2^4 = (2)$, this is the only prime lying over $2$, so $[\mathfrak{B}_2]$ is trivial in $C(K)$. Over $5$, since $x^4+2$ remains irreducible mod $5$, it follows that $5R = \mathfrak{B}_5$ is prime, and is the only prime lying over $5$; it too is trivial in $C(K)$. Over $3$, $x^4+2 = (x+1)(x+2)(x^2+1)$, so that $3R = \mathfrak{B}_3\mathfrak{B}'_3\mathfrak{B}''_3$, where $N(\mathfrak{B}_3) = N(\mathfrak{B}'_3) = 3$ and $N(\mathfrak{B}''_3)=9$. This is where I'm not clear on how to proceed. It doesn't seem obvious that each of these is principal. Am I going about this in a reasonable way? What other tools are available to compute such groups ""from first principles""?","['algebraic-number-theory', 'number-theory']"
877344,Proof $e^n*n!$ is an asymptote of $(n+1)^n$,I would like to prove $\lim_{n\to \infty}e^nn!-(n+1)^n=0$. All I have really done is show $(n+1)^n=\sum_{i=0}^n\frac{n!}{(n+1)^i(i!)(n-i)!}$,"['limits', 'sequences-and-series', 'combinatorics']"
877345,Composing a smooth even function and square root,"Let $f:\mathbb{R}\to\mathbb{R}$ be smooth and satisfy $f(-x)=f(x)$ for all x. Define $g:[0,\infty)\to\mathbb{R}$ by $g(x)=f(\sqrt{x})$. Is $g$ necessarily smooth at $0$? I guess the answer is positive. $f$ being an even function implies that all its derivatives of odd order vanish at $0$, hence when substituting $\sqrt{x}$ in the Taylor series of $f$ around $0$, one obtains a power series in $x$. This is obviously not a proof, as most of the smooth functions are not analytic. Showing that $f$ is differentiable is easy, and working a little harder one also shows that it is twice differentiable. It seems like it should work the same for derivatives of larger orders, and yet, I haven't found a satisfactory proof.",['calculus']
877350,Book for Undergrad Differential Geometry,"I am soon going to start learning differential geometry on my own (I'm trying to learn the math behind General Relativity before I take it next year).  I got the sense that a good, standard 1st book on the subject was do Carmo's Differential Geometry of Curves and Surfaces and so that was the book I planned on reading.  However I just read this question on mathoverflow, and both answers to it suggested that the professor NOT teach a class from a book like do Carmo's because it doesn't cover differential forms. Would you guys agree that I should find a book that introduces differential forms (and tensors?) given that I am an undergrad physics major who plans to study relativity theory?  If so, what books would you recommend?","['book-recommendation', 'reference-request', 'differential-geometry']"
877351,Can the product of $n$ factorials be $n$ factorial?,Are there any solutions to the equation $a_1!\cdot a_2!\cdots a_n!=n!$ with all variables being integers greater than or equal to $2$?,"['number-theory', 'combinatorics']"
877355,Projective varieties and irreducibility,"The ""modern""(schematic) definition of a projective variety is the following: Let $k$ be an algebraically closed field. A projective variety over $k$ is a closed subscheme of $\mathbb P^n_k=\textrm{Proj}(k[T_1,\ldots,T_n])$ (Remember the structure of $k$-scheme). By a well known proposition, every projective variety in the sense of the above definition is of the type
$$\textrm{Proj}\frac{k[T_1,\ldots,T_n]}{I}$$
where $I$ is any homogeneous ideal. Now, speaking in classical terms, Hartshorne in chapter I of his book defines a projective variety as an irreducible algebraic projective set. This means that with this definition, every projective variety corresponds to a ring of the form:
$$\frac{k[T_1,\ldots,T_n]}{I}$$
but where $I$ is a prime ideal. Finally my question: Why Hartshorne requires the irreducibility in his definition? Is it strictly necessary?","['projective-space', 'algebraic-geometry', 'projective-schemes']"
877374,What is the probability that both roots of the equation $Ax^2 + Bx + C = 0$ are real?,"Given this problem as part of prep for a test.  We've done the same problem without A being a random variable, but I am completely stumped as to how to accomplish this one with three r.v.s I know the joint is $1/288$ and that $B^2>4AC$ but cannot convert this to a happy integral. Let $A$, $B$, and $C$ be independent random variables, uniformly distributed over $[0,4], [0,8]$, and $[0,9]$ respectively. What is the probability that both roots of the equation $Ax^2 + Bx + C = 0$ are real? Thanks,",['probability']
877388,how to prove gradients vectors are the same in polar and cartesian coordinates.,"Suppose $T=T(r,\theta)=G(x,y)$ How do you prove $\nabla T(r,\theta)=\nabla G(x,y)$? I can think of some arguments in favor of this equality, but I want an actual proof or a very good intuitive argument. My arguments in favor go something like this: -Gradient vectors should be the same because if my directional derivative is taken parallel to the gradient vector then I get its maximum/minimum value and if these two gradient vectors are the same then everything will be consistent . Thanks.","['multivariable-calculus', 'vector-analysis']"
877397,Is S a group under matrix addition,"Another matrix question! Let $$S=\{A \in M_2(\mathbb{R}):f(A)=0\}\text{ and }f\left(\begin{bmatrix}a&b\\c&d \end{bmatrix}\right)=b$$ Is S a group under matrix addition. Either prove that (S,+) is a group or show that one of the group axioms fails. Group axioms: (G1) the set G is closed under the operation $*$ (G2) The operation $*$ is associative - $(a*b)*c=a*(b*c)$ (G3) There exists an element $e \in G$ such that $a*e=a=e*a$ for all $a \in G$ (G4) for each $a \in G$ there exists an element $a^{-1}$ of G such that $a*a^{-1}=e=a^{-1}*a$ Here's what I've got so far: (G1) let $A=\begin{bmatrix}a&0\\c&d\end{bmatrix}$ and $B=\begin{bmatrix}e&0\\g&h \end{bmatrix}$ where $A, B \in S$ then $A+B=\begin{bmatrix}a+e&0\\c+g&d+h \end{bmatrix}$ which is $\in S$ so it is closed. - (G1) is satisfied (G2) using $A$ and $B$ as above and $C=\begin{bmatrix}j&0\\m&n \end{bmatrix},\\ (A+B)+C = \begin{bmatrix}a+e&0\\c+g&d+h \end{bmatrix}+\begin{bmatrix}j&0\\m&n \end{bmatrix} = \begin{bmatrix}a+e+j&0\\c+g+m&d+h+n\end{bmatrix}$ and $A+(B+C)=\begin{bmatrix}a&0\\c&d\end{bmatrix}+\begin{bmatrix}e+j&0\\g+m&h+n\end{bmatrix}=\begin{bmatrix}a+e+j&0\\c+g+m&d+h+n\end{bmatrix}$ so $(A+B)+C=A+(B+C)$ - (G2) is satisfied (G3) let $e=\begin{bmatrix}0&0\\0&0\end{bmatrix}$ pretty easy to see that $A+e=A=e+A$ - (G3) satisfied (G4) let $A^{-1}=\begin{bmatrix}-a&0\\-c&-d\end{bmatrix}$ $A+A^{-1}=\begin{bmatrix}a&0\\c&d\end{bmatrix}+\begin{bmatrix}-a&0\\-c&-d\end{bmatrix}=\begin{bmatrix}0&0\\0&0\end{bmatrix}=e$ and 
$A^{-1}+A=\begin{bmatrix}-a&0\\-c&-d\end{bmatrix}+\begin{bmatrix}a&0\\c&d\end{bmatrix}=\begin{bmatrix}0&0\\0&0\end{bmatrix}=e$
(G4) satisfied So I have proved all the axioms (hopefully correctly?!) therefore we can say that (S,+) is a group. I know that's a bit of reading but I would really appreciate your confirmation that this is right / where I went wrong if it isn't. The one I'm really worried about is G1, and I know then that if this is wrong and (S,+) is not closed then I don't need to worry about the rest. And also if there is another way to do it?","['matrices', 'group-theory']"
877419,Asymptotic Behaviour Of A Bizarre Function 2,"It is well-known that
$$\frac{1}{1}-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots = \ln 2 $$ Hence
$$\frac{x}{1}-\frac{x}{2}+\frac{x}{3}-\frac{x}{4}+\cdots= x\ln 2  $$ However, consider $f(x)$, where
$$f(x)=\left\lfloor\frac{x}{1}\right\rfloor-\left\lfloor\frac{x}{2}\right\rfloor+\left\lfloor\frac{x}{3}\right\rfloor-\left\lfloor\frac{x}{4}\right\rfloor+\cdots  $$ and $\lfloor t\rfloor$ denotes the floor function. Can anyone determine and prove the asymptotic behaviour of $f(x)$? Maybe even a good error term as well or even the second term in the asymptotic expansion? I'm guessing that
$$ f(x) \sim x \ln 2$$ but cannot prove it. Edit: I believe I may have solved my own problem. The infinite sum is equal to the limit of the partial sum as the amount of terms tends to infinity. The first $n$ terms can be approximated by dropping the floor function signs at a cost of an error of $O(n)$, leaving one with
$$\frac{x}{1}-\frac{x}{2}+\frac{x}{3}-\frac{x}{4}+\cdots + (-1)^{n+1}\frac{x}{n} + O(n)$$ The alternating sum multiplied by $x$ is almost $ x \ln 2$ and the error in approximating the partial sum as the infinite sum is $O(\frac{1}{n})$, since the series is alternating. Hence, the error introduced by approximating $$ \frac{x}{1}-\frac{x}{2}+\frac{x}{3}-\frac{x}{4}+\cdots + (-1)^{n+1}\frac{x}{n}$$ as $x \ln 2$ is $O(\frac{x}{n})$ and so the nth partial sum is equal to
$$ x \ln2 + O\left(\frac{x}{n}\right) + O(n)$$ But $n$ is independent of $x$ and so we minimise the error by letting $n=\sqrt x$ giving the final result
$$f(x)= x \ln2 + O(\sqrt x) $$ I believe I have made no mistake in this solution.","['asymptotics', 'calculus', 'real-analysis']"
877422,Heaviside Unit Step Function,"Convert to heaviside function:
$$f(t) = \begin{cases}e^t ,& 0 \leq t \leq 1 \\0 ,& t > 1\end{cases}$$ My attempt:
$f(t) = U(t) e^t - U(t-1) e^t $ I think my solution is not right because at f(t=1), it doesn't give the right value. How would I go about fixing this issue. Thanks!",['functions']
877424,Polygons with equal area and perimeter but different number of sides?,"Let's say we have two polygons with different numbers of sides. They can be any sort of shape, but they have to have the same area, and perimeter. There could be such possibilities, but can someone show me with pictures? I just need visualize it. Sometimes in life you just have to know it, and sometimes we need a picture shown in our faces :).","['geometry', 'polygons', 'examples-counterexamples']"
877436,Work with algebra,$2{x}^2 + 3{y}^2 = {a}^2$ What is the maximum value of $3x+2y$ ? Not knowing calculus and how to graph a ellipse may make this harder. But is there a way to get around calculus? Please determine the answer in terms of $a$.,['algebra-precalculus']
877449,Introduction and Prerequisites to Abstract Algebra,"So I've seen similar questions asked, but none that really helped me out. I'm going to be a freshman in college next year, having already taken Multivariate Calculus and Elementary Linear Algebra. Of course these were very basic, only second-year undergraduate courses, but I am still interested in self-studying Abstract Algebra. I purchased Basic Algebra I by Jacobson, which is fairly readable so far (and I've been doing the exercises) but I am worried that I will get lost in it soon. Are there any better resources to start from, given my current mathematical standpoint? What else should I learn before digging into this topic on an introductory level, besides proof techniques and set theory? My problem is not in understanding the concepts, but rather my mathematical vocabulary is limited and I find certain definitions to be rather confusing. Basically, where should I start/what should I read in order to build my mathematical vocabulary so that I don't constantly Google while reading texts on Abstract Algebra? Maybe if someone even has a math reference to symbols and words that would be great!","['self-learning', 'book-recommendation', 'abstract-algebra']"
877455,Homotopy classes of maps from the projective plane to $S^1 \times S^3$,"I have a past qual question here: characterize the space $[(\mathbb{RP}^2,x),(S^1 \times S^3,y)]$ of homotopy classes of maps from $(\mathbb{RP}^2,x)$ to $(S^1 \times S^3,y)$, where here $x \in \mathbb{RP}^2$ and $y \in S^1 \times S^3$ are base points. In cases where we are considering homotopy classes of maps into $S^1$, I've used the relation $[X,S^1] = H^1(X;\mathbb{Z})$ when $X$ is homotopy equivalent to a CW complex. Is there a similar relation in this case? If so, does it have to do with changing coefficients? Thanks in advance for your help!","['general-topology', 'homotopy-theory', 'algebraic-topology']"
877460,"Prove ${\large\int}_0^\infty\frac{\ln x}{\sqrt{x}\ \sqrt{x+1}\ \sqrt{2x+1}}dx\stackrel?=\frac{\pi^{3/2}\,\ln2}{2^{3/2}\Gamma^2\left(\tfrac34\right)}$","I discovered the following conjecture by evaluating the integral numerically and then using some inverse symbolic calculation methods to find a possible closed form:
$$\int_0^\infty\frac{\ln x}{\sqrt{x\vphantom{1}}\ \sqrt{x+1}\ \sqrt{2x+1}}dx\stackrel{\color{#808080}?}=\frac{\pi^{3/2}\,\ln2}{2^{3/2}\,\Gamma^2\left(\tfrac34\right)}.\tag1$$
The equality holds numerically with a precision of at least $1000$ decimal digits. But so far I was not able to find a proof of it. Because the integral can be represented as a derivative of a hypergeometic function with respect to its parameter, the conjecture can be rewritten as
$$\frac{d}{da}{_2F_1}\left(a,\ \tfrac12;\ 1;\ \tfrac12\right)\Bigg|_{a=\frac12}\stackrel{\color{#808080}?}=\frac{\sqrt\pi\,\ln2}{2\,\Gamma^2\left(\tfrac34\right)}\tag2$$
or, using a series expansion of the hypergeometric function, as
$${\large\sum}_{n=0}^\infty\frac{H_{n-\frac12}\ \Gamma^2\left(n+\tfrac12\right)}{2^n\ \Gamma^2\left(n+1\right)}\stackrel{\color{#808080}?}=-\frac{3\,\pi^{3/2}\,\ln2}{2\,\Gamma^2\left(\tfrac34\right)}\tag3,$$
where $H_q$ is the generalized harmonic number , $H_q=\gamma+\psi_0\left(q+1\right).$ Could you suggest any ideas how to prove this?","['improper-integrals', 'sequences-and-series', 'calculus', 'definite-integrals', 'hypergeometric-function']"
877487,Simple counting problem,"Suppose that you have a box with $n$ balls, from the $n$ balls $k$ are white and $n-k$ are black. Now, sequentially you draw (without replacement) the $n$ balls in groups of $m$ (a natural number that divides $n$). My question is, what is the probability that in every one of the $n/m$ draws there is at least one white ball? A first naive idea that I explored is to think that we have $m$ urns and place one white ball in each urn, then count all the possible ways of drawing $n-m$ balls out of which $k-m$ are white and multiply this number by the positions in which we can place the white ball that is already in the urn within the sequence: $$
\frac{m^{n/m}{n-m\choose k-m}}{n \choose k}
$$ However the above formula is obviously overcounting some sequences.","['probability', 'combinatorics']"
877489,Can all null-homotopy be made differentiable on arbitrary metric space?,"Let $M$ be a metric, and assume that it is simply connected. For a closed curve $f$, we define it to be differentiable iff for any $x$ then $\lim\limits_{h\rightarrow 0}\frac{d(f(x),f(x+h))}{h}$ exist, where we take $f$ to be extended into a periodic function with period $1$ for the sake of having both side when taking the derivative at the boundary. The question is: Given a closed curve $f$ that is differentiable. Does there always exist a null-homotopy of $f$ such that all curves along the homotopy process is differentiable. I believe the answer to be no, but I am still unsure either way. Any helps would be welcome. Thank you.","['homotopy-theory', 'metric-spaces', 'derivatives']"
877511,How to find exponential of triangular matrix,"I'm studying for an exam and I can't find this in my notes or in the book, but it's on a past exam... Given $A = \begin{bmatrix}-1 & 1\\0 & -1\end{bmatrix}$, $e^{tA} = \begin{bmatrix}e^{-t} & te^{-t}\\0 & e^{-t}\end{bmatrix}$ True/False? The answer is true according to the answer key, but I don't see why. What theorem/concept would tell me that this is true? It's a true false question so I'm sure it should be something I can see at a glance or with very little work ...","['matrices', 'linear-algebra']"
877518,If $a_i>o$ then $(a_1a_2\cdots a_{2^n})^{1/2^n}\leq \frac{a_1+a_2+\cdots+a_{2^n}}{2^n}$,"I need help to prove this inequality, I have no idea how to proceed with the inductive step: $$a_1,a_2,\ldots,a_{2^n}>0 \Longrightarrow(a_1a_2\cdots a_{2^n})^{1/2^n}\leq \frac{a_1+a_2+\cdots+a_{2^n}}{2^n},\forall n\in\mathbb{N}$$ Any help would be appreciated.","['induction', 'discrete-mathematics']"
877526,minimal polynomial given an algebraic number,"I am trying to find the minimal polynomial for the algebraic number $1+\sqrt{2}+\sqrt{3}$.  My original thought was just let $\alpha=1+\sqrt{2}+\sqrt{3}$.  The method I use though seems very complicated.  For example, 
$$\alpha^2=(1+\sqrt{2}+\sqrt{3})^2=1+\sqrt{2}+\sqrt{3}+\sqrt{2}+2+\sqrt{2}\sqrt{3}+\sqrt{3}+\sqrt{2}\sqrt{3}+3$$
$$\alpha^2=1+\sqrt{2}+\sqrt{3}+1+\sqrt{2}+\sqrt{3}+4+2\sqrt{2}\sqrt{3}$$
$$\alpha^2=4+2\alpha+2\sqrt{2}\sqrt{3}$$
If I substitute for $\sqrt{2}=\alpha-1-\sqrt{3}$ and $\sqrt{3}=\alpha-1-\sqrt{2}$, I'm still going to end up with $\sqrt{2}$ and $\sqrt{3}$.  So I figured I'd square again.  Moving the 4 over makes the calculation easier since binomials are easier than trinomials....
$$(\alpha^2-4)^2=(2\alpha+2\sqrt{2}\sqrt{3})^2$$
$$\alpha^4-8\alpha^2+16=4\alpha^2 +8\alpha\sqrt{2}\sqrt{3}+24$$
$$\alpha^4-12a^2-8=4\alpha(2\sqrt{2}\sqrt{3})$$
From the above calculation I see that $2\sqrt{2}\sqrt{3}=\alpha^2-2\alpha-4$
$$\alpha^4-12a^2-8=4\alpha(\alpha^2-2\alpha-4)$$
$$\alpha^4-4\alpha^3-4\alpha^2+16\alpha-8=0$$
But my question is, how do I KNOW this is the minimal polynomial?  Yes, it is true now, since I constructed it so, that if $f(x)=x^4-4x^3-4x^2+16x-8$, then $f(\alpha)=0$  Do I simply attempt to factor out an $(x-\alpha)$.  In that case, $f(x)=(x-\alpha)g(x)$.  Then I show that $g(\alpha)\neq 0$?","['algebraic-number-theory', 'number-theory']"
877527,How to prove $\sum_{i=1}^k(\frac{1}{\alpha_i}\prod_{j\neq i}^k\frac{\alpha_j}{\alpha_j-\alpha_i})=\sum_{i=1}^k\frac{1}{\alpha_i}$?,"How to prove $\sum_{i=1}^k(\frac{1}{\alpha_i}\prod_{j\neq i}^k\frac{\alpha_j}{\alpha_j-\alpha_i})=\sum_{i=1}^k\frac{1}{\alpha_i}$? Where $\alpha_1, \alpha_2,\ldots, \alpha_k$  are $k$ distinct positive numbers.","['linear-algebra', 'polynomials']"
877532,Prove this result about construction of sets,"In Enderton's book on Set Theory, the following problem is given after introducing the notion of sets as an infinite hierarchy (I hope this much explanation is sufficient; if not, please mention and I'll include more): We have stated that $V_{\alpha+1} = A \cup \mathcal P (V_\alpha)$. Prove this at least for $\alpha < 3$. Here, $\mathcal P$ is the power set, and $V_\alpha$ is the infinite union $V_0 \cup V_1 \cup V_2 \cup \ldots$, and $A$ is the set of all atoms (from which we intend to construct all possible sets). A word about $V_i$ here. In the construction, $V_{i+1}$ is defined as $V_i \cup \mathcal P(V_i)$, and the first set, the set of all atoms, is $V_0$ or $A$. I don't see how this can be ""proved"" at all, let alone for $\alpha < 3$. After all, the given construction of sets is a mere representation that we dreamed up, not something we can verify. At best I can take $A=\phi$ and proceed to construct up to $V_4$, but how do I prove (verify) this?","['self-learning', 'elementary-set-theory']"
877537,Does chain rule require continuously differentiability?,"Recently I read the book Advanced Calculus written by Fitzpatrick. The Theorem 15.34 tells that  If $F:\mathbb R^n\to\mathbb R^m$ is CONTINUOUSLY differentiable (all partial derivatives exist and continuous) and $g:\mathbb R^m\to\mathbb R$ is also CONTINUOUSLY differentiable, then $\frac{\partial}{\partial x_i}(g\circ F)(x)=\sum^m_{j=1}D_jg(F(x))\frac{\partial F_j}{\partial x_i}(x)$ and $g\circ F$ is also continuously differentiable. I know that continuously differentiable (all partial derivatives exist and continuous) implies differentiable. But a function is differentiable may not indicate that its partial derivatives are continuous. I wonder that whether the chain rule can be applied if it is differentiable but do not have continuous derivatives. p.s. The proof in the book contains $\lim_{h\to0}\nabla g(x+h)=\nabla g(x)$ which needs continuity of $\nabla g$",['multivariable-calculus']
877539,"Solve for $x$, $\tan x +\sec x = 2\cos x$ ; $−∞ < x < ∞$","Solve for $x$, $\tan x +\sec x = 2\cos x$ ; $−∞ < x < ∞$ $$\tan x + \sec x = 2\cos x$$ I tried changing it all to sin and cos $$\frac{\sin x}{\cos x} + \frac{1}{\cos x} = 2\cos x$$ then I made it to one fraction $$\frac{\sin x + 1}{\cos x} = 2 \cos x$$ Then I don't know where to go from there. Please help!","['trigonometry', 'algebra-precalculus']"
877585,Find $\tan x $ if $\sin x+\cos x=\frac12$,"It is given that $0 < x < 180^\circ$ and $\sin x+\cos x=\frac12$, Find $\tan x $. I tried all identities I know but I have no idea how to proceed.  Any help would be appreciated.","['trigonometry', 'algebra-precalculus']"
877589,Solve for $x$: $\frac1e = e^{2x}$,"I tried  making it to $e^{-1} = e^{2x}$ and had the exponents equal each other $-1=2x$ and the I solved for $x$, making it $x=-1/2$, but that answer is wrong. please help I don't know why that answer is wrong.","['logarithms', 'calculus', 'algebra-precalculus']"
877591,Help with conditional expectation,"I need help finding a conditional expectation: Let $X$ be a $(0,1)$ uniform random variable i.e. $\mathbb{P}(X \in A)=\lambda((0,1)\cap A)$ where $\lambda$ is the Lebuesgue measure. 
We define the random variables $$X_n = \frac{\left\lfloor10^nX \right\rfloor}{10^n}$$ and we need to find $$\mathbb{E}(h(X_{n+1})|X_n) \text{ and }\mathbb{E}(h(X)|X_n)$$ where $h\colon [0,1]\to \mathbb{R}$ is some bounded measurable function. I noticed that $X_n$ has only $n$ decimals of $X$ hence $\sigma(X_n) \subseteq \sigma(X_{n+1})$ and that $X_n \to X$ a.s, but I don't know if this is of any help. Any hint, reference or solution will be appreciated :)!","['uniform-distribution', 'measure-theory', 'probability', 'conditional-probability']"
877594,vector spaces whose algebra of endomorphisms is generated by its idempotents,Let $V$ be a $K$-vector space whose algebra of endomorphisms is generated (as a $K$-algebra) by its idempotents. Is $V$ necessarily finite dimensional? EDIT (Jul 26 '14) A closely related question: Is there a field $K$ and a $K$-vector space whose algebra of endomorphisms of is not generated (as a $K$-algebra) by its idempotents?,['linear-algebra']
877632,Using Chain Rule and Product Rule to find derivative,"I have to find the derivative of the following function: $$f(x) = (x^3+ 4)(4x^5 + 2x − 5)^{1/2}$$ To start solving this, I've dissected the equation and realize that I must use the product and chain rule to find the derivative. The problem is I don't know how to use both at the same time. How do I do this? How can I tell when to use what first?","['calculus', 'derivatives']"
877640,Evaluating $\int_{-\infty}^\infty \frac{\sin x}{x-i} dx$,"I would like to evaluate the integral
$$\int_{-\infty}^\infty \frac{\sin x}{x-i} dx,$$
which I believe should be equal to $\frac{\pi}{e}$. However, I cannot reproduce this result by hand. My work is as follows: first, we evaluate the indefinite integral. \begin{align*}
\int \frac{\sin x}{x-i} dx &= \int \frac{\sin(u+i)}{u} du \text{ where }u=x-i \\
&= \int \frac{\sin u \cos i + \cos u \sin i}{u} du \\
&= \mathrm{Si}(u) \cos i + \mathrm{Ci}(u) \sin i \\
&= \mathrm{Si}(x-i) \cosh 1 + i\mathrm{Ci}(x-i) \sinh 1 \\
\end{align*} Then, we insert the bounds. \begin{align*}
\int_{-\infty}^\infty \frac{\sin x}{x-i} dx &= \mathrm{Si}(\infty-i) \cosh 1 + i\mathrm{Ci}(\infty-i) \sinh 1 \\
&\phantom{=}-\mathrm{Si}(-\infty-i) \cosh 1 - i\mathrm{Ci}(-\infty-i) \sinh 1 \\
&= \frac{\pi}{2}\cosh 1 + 0 +\frac{\pi}{2} \cosh 1 + \pi \sinh 1 \\
&= \pi (\cosh 1 + \sinh 1) \\
&= \pi e
\end{align*} I assume I have made some mistake in manipulating the complex sine and cosine integrals, since the result would be correct if $\mathrm{Ci}(-\infty-i)$ were evaluated to $-i \pi$. However, I cannot pinpoint the error.","['definite-integrals', 'integration']"
877645,A not free $\mathbb{Z}$-module [duplicate],This question already has an answer here : Why isn't an infinite direct product of copies of $\Bbb Z$ a free module? (1 answer) Closed 5 years ago . From this post I see that $\mathbb{Z}^{\mathbb{N}}$ is not a free abelian group. Someone can explain me why? Thanks a lot!,"['abelian-groups', 'abstract-algebra', 'modules', 'commutative-algebra', 'group-theory']"
877671,"Why ""One cannot construct more than countably many independent random variables""?","I'm reading the book ""Large Networks and Graph Limits"" by László Lovász.
On the page 18 he said the following: One cannot construct more than countably many independent random
  variables   (in a nontrivial way, neither of them   concentrated on a
  single value). But I can not understand why it is impossible, I'm asking for your help.","['probability-theory', 'random-variables', 'random-graphs']"
877681,Antiderivative of $\frac{1}{1+\sin {x} +\cos {x}}$,How do we arrive at the following integral $$\displaystyle\int\dfrac{dx}{1+\sin {x}+\cos {x}}=\log {\left(\sin {\frac{x}{2}}+\cos {\frac{x}{2}}\right)}-\log {\left(\cos {\frac{x}{2}}\right)}+C\ ?$$,"['algebra-precalculus', 'calculus', 'integration', 'indefinite-integrals', 'trigonometry']"
877696,How prove $\sum\limits_{cyc}\sqrt{PA+PB}\ge 2\sqrt{\sum\limits_{cyc}h_{a}}$,"Question: Consider a triangle $\Delta ABC$ with altitudes $h_{a}$ , $h_{b}$ and $h_{c}$ , where $AB=c$ , $BC=a$ and $AC=b$ .
Show that for any $P$ $$\sqrt{PA+PB}+\sqrt{PB+PC}+\sqrt{PA+PC}\ge 2\sqrt{h_{a}+h_{b}+h_{c}}$$ My try: the inequality is equivalent to $$(PA+PB+PC)+\sum_{cyc}\sqrt{(PA+PB)(PB+PC)}\ge 2(h_{a}+h_{b}+h_{c})$$","['geometry', 'geometric-inequalities', 'inequality']"
877711,"Evaluate $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\frac{1}{2}(x^2-xy+y^2)}dx\, dy$","I need to evaluate the following integral: $$\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\frac{1}{2}(x^2-xy+y^2)}dx\, dy$$ I thought of evaluating the iterated integral $\displaystyle\int_{-\infty}^{\infty}dx\int_{-\infty}^{\infty}e^{-\frac{1}{2}(x^2-xy+y^2)}dy$, but because of the presence of $x^2$ and $y^2$ terms, I am not being able to do that. I tried substituting $x=r\cos \theta$ and $y=r\sin \theta$ but in that case I have some confusion regarding the limits of $r$ and $\theta$. Can I get some help?","['multivariable-calculus', 'improper-integrals', 'integration', 'definite-integrals', 'real-analysis']"
877725,Retrieve the initial cubic Bézier curve subdivided in two Bézier curves,"I have a cubic Bezier curve subdivided to two cubic Bezier: Assuming that ""t_cut"" is the t value where this initial Bezier is cut: example  of function subdivision(BezierCurve initialCurve, Beziercurve b1, BezierCurveb2, float t_cut) I want to retrieve the initial Bezier curve (so, its P1 and P2 control points, because P0 and P3 are known, using this function for example: BezierCurve merge(bezier1, bezier2, t_cut )). I can fix my problem if t_cut is always 0.5 (see my first question about merging two Bezier curves: Merge two or more cubic Bézier curves for optimization ) but with other value of t_cut, I am not really satisfied by the result because I work with 10^-5m. But, If someone could help me to retrieve this value of t_cut, on where the initial curve is cut, I can use this to merge the 2 curves and get an almost perfect approximation of the original curve.
   The merge function: void BezierCurve::merge(QVector<BezierCurve> b_cContainer)
{
if(b_cContainer.empty()== false && b_cContainer.size() < 2)
{
QMessageBox::warning(0, ""Warning"", ""2 or more curves are required to be merged"");
}

auto leftCurve = b_cContainer[0];
auto rightCurve = b_cContainer[1];
auto A = leftCurve.getOrigin();
auto B = leftCurve.getC1();
auto C = leftCurve.getC2();
auto D = leftCurve.getEnd();

auto E = rightCurve.getC1();
auto F = rightCurve.getC2();
auto G = rightCurve.getEnd();

// origin and end do not changed: i-e A and G
origin = leftCurve.getOrigin();
end = rightCurve.getEnd();

auto k = (float)(norm(E-D))/(float)(norm(D-C));
c1 =(1+k)*B - k*A; //C1 is the first control point.
c2 =((1+k)*F - G)/k; // C2 is the second control.
} Thank's for help.","['geometry', 'discrete-mathematics', 'plane-curves', 'bezier-curve', 'computer-science']"
877736,Where to learn about the Chow scheme and the Hilbert-Chow morphism?,"I would like to learn something about the Chow scheme of cycles on an algebraic variety. I am not after an abstract treatment of the moduli problem in full generality, actually I would be happy with a description of it for smooth projective varieties like $\mathbb P^n$. As a start, I would like to know what these Chow schemes look like and how does one define the Hilbert-Chow morphism in this setting - i.e. not from $\textrm{Hilb}\to \textrm{Sym}$ but rather $\textrm{Hilb}\to \textrm{Chow}$. Of course, if you can provide an answer yourself rather than a reference, you are very welcome! Thanks in advance.","['algebraic-geometry', 'reference-request']"
877771,"Let $a_n$ be the $nth$ term of the sequence $1, 2, 2, 3, 3, 3, 4, 4, 4, 4, \dots$","Question: Let $a_n$ be the $nth$ term of the sequence $1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6\dots$, constructed by including the integer $k$ exactly $k$ times. Show that $a_n = \lfloor \sqrt{2n} + \dfrac{1}{2}\rfloor$. Attempt: Try to prove $k = a_n=\lfloor \sqrt{2n} + \dfrac{1}{2}\rfloor$ then $k = a_{n+k-1}=\lfloor \sqrt{2(n+k-1)} + \dfrac{1}{2}\rfloor$. The inequality of $k = a_n=\lfloor \sqrt{2n} + \dfrac{1}{2}\rfloor$, is the following, $$k \leq \sqrt{2n} + \dfrac{1}{2} < k + 1$$
$$k-\dfrac{1}{2} \leq \sqrt{2n} < k + \dfrac{1}{2}$$
$$\Big( k-\dfrac{1}{2} \Big)^2 \leq 2n < \Big(k +\dfrac{1}{2}\Big)^2$$
$$\dfrac{1}{2}\Big( k-\dfrac{1}{2} \Big)^2 \leq n < \dfrac{1}{2}\Big(k +\dfrac{1}{2}\Big)^2$$
$$\dfrac{1}{2}\Big( k-\dfrac{1}{2} \Big)^2 + k - 1 \leq n + k -1 < \dfrac{1}{2}\Big(k +\dfrac{1}{2}\Big)^2 + k - 1$$
$$\Big( k-\dfrac{1}{2} \Big)^2 + 2k - 2 \leq 2(n + k -1) < \Big(k +\dfrac{1}{2}\Big)^2 + 2k - 2$$
$$k^2 - k + \dfrac{1}{4} + 2k - 2 \leq 2(n+k - 1) < k^2 + k + \dfrac{1}{4} + 2k - 2$$
$$k^2 + k + \dfrac{1}{4} - 2 \leq 2(n+k - 1) < k^2 + 3k + \dfrac{9}{4} - \dfrac{9}{4} + \dfrac{1}{4} - 2$$
$$\Big( k+\dfrac{1}{2} \Big)^2 - 2 \leq 2(n+k - 1) < \Big( k+\dfrac{3}{2} \Big)^2 - 4$$ From here $2(n+k - 1) < \Big( k+\dfrac{3}{2} \Big)^2 - 4 \implies 2(n+k - 1) < \Big( k+\dfrac{3}{2} \Big)^2$ so I can take the square root of both sides. The problem is the left hand side, $\Big( k+\dfrac{1}{2} \Big)^2 - 2 \leq 2(n+k - 1)$ does not imply $\Big( k+\dfrac{1}{2} \Big)^2 \nleq 2(n+k - 1)$, thus we can't really get rid of the square. It is easy to see that if we have $k = a_{n+k}=\lfloor \sqrt{2(n+k)} + \dfrac{1}{2}\rfloor$, the problems we encountered are avoided, but $k \neq a_{n+k}$.",['discrete-mathematics']
877773,Is the collection $\tau_\infty = \{U:X-U$ is infinite or empty or all of $X\}$ a topology on $X$?,"Can someone please verify my proof? Is the collection $\tau_\infty = \{U:X-U$ is infinite or empty or all of $X\}$ a topology on $X$? No. Let $X = \mathbb{R}$. Clearly, $\{x\} \in \tau_\infty$ for all $x \in X$. Set $\displaystyle{B = \cup_{x \neq 0} \{x\}}$. Clearly, $X - B = \{0\}$, but $\{0\} \notin \tau_\infty$. Since $\tau_\infty$ is not closed under arbitrary unions, it does not define a topology on $X$.","['general-topology', 'proof-verification']"
877786,Cohomology Calculation,"A couple of days ago I asked this Question on calculating hypercohomology I tried a similar example for $(\mathbb{C}^*)^2$, and I have a couple of questions. Here is my calculation: We have a cochain of $ \mathbb{C}[x^{\pm 1}, y^{\pm 1} ] $-modules: $$ 0  \longrightarrow \mathbb{C}[x^{\pm 1}, y^{\pm 1} ] \longrightarrow \left< dx,dy \right> \longrightarrow \left< \ dx \wedge dy \  \right> \longrightarrow 0$$ with codifferential maps: $ d (f) = \frac{\partial f}{\partial x} \cdot dx + \frac{\partial f}{\partial y} \cdot dy  $ $d (f \cdot dx + g \cdot dy) = \left( \frac{\partial g}{\partial x} - \frac{\partial f}{\partial y} \right) \cdot ( dx \wedge dy) \\ $ and we get: $H^0_{dR} = \mathbb{C} \ \ \ \  $ , 
$ \ \ \ \ H^2_{dR} \cong \mathbb{C} \left( \frac{1}{xy} \right)\cdot ( dx \wedge dy) \cong \mathbb{C} \ \ \ $ , $ \ \ \ H^1_{dR} \cong \mathbb{C} \left(\frac{1}{x} \right)\cdot dx + \mathbb{C} \left(\frac{1}{y} \right)\cdot dx \cong \mathbb{C}^2$. My Questions: Firstly, is the above correct? Secondly, if it is correct then is there a nice way to visualize what I get for $H^1$? I understand the space looks like 4 dimensional euclidean space with two planes removed that touch at a single point? Here's a bad attempt at trying to imagine it, don't know whether it means anything. I tried to think of squashing the planes at the point so i can see it in 3d, and then use the unseen dimension to move around with one of the paths:","['sheaf-theory', 'algebraic-geometry', 'algebraic-topology', 'homology-cohomology']"
877791,"If $\{\tau_\alpha\}$ is a family of topologies on $X$, show that $\cap \tau_\alpha$ is a topology on $X$. Is $\cup \tau_\alpha$ a topology on $X$?","If $\{\tau_\alpha\}$ is a family of topologies on $X$, show that $\cap \tau_\alpha$ is a topology on $X$. Is $\cup \tau_\alpha$ a topology on $X$? For all $\alpha$, $\varnothing \in \tau_\alpha$ and $X \in \tau_\alpha$. So, $\varnothing \in \cap \{\tau_\alpha\}$ and $X \in \cap \{\tau_\alpha\}$. Now, let $\{U_\beta\}_{\beta \in J}$ be an indexed collection of subsets of $\cap \{\tau_\alpha\}$. Then, for all $\alpha$, $\{U_\beta\}_{\beta \in J} \subseteq \tau_\alpha$. This implies that for all $\alpha$, $\cup\{U_\beta\}_{\beta \in J}\in\tau_\alpha$, since $\tau_\alpha$ is a topology. But then, $\cup\{U_\beta\}_{\beta \in J}\in\cap \{\tau_\alpha\}$. Now, let $U_1, U_2, \ldots U_n$ be subsets of $\cap \{\tau_\alpha\}$. Then, for all $\alpha$, $U_i \in \tau_\alpha$. This implies that for all $\alpha$, $\cap_{i=1}^n U_i \in \tau_\alpha$, since each $\tau_\alpha$ is a topology. But then, $\cap_{i=1}^n U_i \in \cap \{\tau_\alpha\}$. Therefore, $\cap \{\tau_\alpha\}$ is a topology on $X$. However, it is not true that $\cup \{\tau_\alpha\}$ is a topology. Consider the set $X = \{a,b,c\}$ and the topologies $\tau_1 = \{\varnothing, X, \{a\}\}$ and $\tau_2 = \{\varnothing, X, \{b\}\}$. It can clearly be seen that $\tau_1 \cup \tau_2$ does not define a topology on $X$.","['general-topology', 'proof-verification']"
877802,Rank of a Matrix Sum [duplicate],"This question already has answers here : Show $\operatorname{rank}(A) + \operatorname{rank}(B) \ge \operatorname{rank}(A+B)$ [duplicate] (2 answers) Closed 8 years ago . I have $3\times3$ matrices such that $S=A+B$ . I know there is an inequality connecting rank of the matrices $A$ , $B$ and its sum $S$ . Could you write down that here? It will be a great help for me. Means equation  or inequality connecting $\operatorname{rank}(S)$ , $\operatorname{rank}(A)$ and $\operatorname{rank}(B)$ .","['matrices', 'linear-algebra', 'inequality', 'matrix-rank']"
877811,Ultrametric space of stochastic filtration,"Let $\Omega$ be an arbitrary set and $(\mathscr F_t)_{t\in \Bbb R_+}$ be a non-decresing sequence of $\sigma$-algebras on $\Omega$ such that any subset of $\Omega$ is contained is some of them, that is $\lim_{t\to\infty}\mathscr F_t = 2^\Omega$. Define
$$
  d(A,B):=\inf\{t\in \Bbb R_+: A\Delta B\in \mathscr F_t\}\qquad A,B\subseteq \Omega.
$$
where $\Delta$ is a symmetric difference of sets. One can show that $d$ is a ultra-metric: a function that satisfies $d(A,C) \leq\max(d(A,B),d(B,C))$ instead of a triangular inequality. In fact it is a pseudo ultra-metric sicen $d(A,B) = 0$ does not imply $A = B$. Was such ultra-metric studied somewhere?","['stochastic-processes', 'general-topology', 'measure-theory', 'probability-theory', 'metric-spaces']"
877816,Ordered partitions of an integer (with a twist),"I would like to know how to prove (preferably algebraically) that $P_1(2,n)=F_{2n+1}$, where $P_1(2,n)$ is what I define to be the number of ordered partitions of an integer, where the number $1$ has 2 possible colours. For example, 
\begin{align}
2
&=2\\
&={\color\red{1}}+{\color\red{1}}\\
&={\color\green{1}}+{\color\green{1}}\\
&={\color\green{1}}+{\color\red{1}}\\
&={\color\red{1}}+{\color\green{1}}\\
\end{align}
so in this case, $P_1(2,2)=5$. This is my (failed) attempt to derive a formula for $P_1(k,n)$. Consider a case where the number $n$ is expressed as a sum of $m$ natural numbers, out of which there are $j$ number of $1$s. The number of possible ways to do so is given by
$$\binom{m}{j}[x^n]x^j(x^2+x^3+...)^{m-j}$$
Now we look at how many partitions we can get from this particular case. Since there are $j$ number of $1$s, we would have to multiply by $k^j$, and since $0\le j \le m$ and $1 \le m \le n$ we have
\begin{align}
P_1(k,n)
&=\sum^{n}_{m=1}\sum^{m}_{j=0}k^j\binom{m}{j}[x^n]x^j(x^2+x^3+...)^{m-j}\\
&=\sum^{n}_{m=1}\sum^{m}_{j=0}k^j\binom{m}{j}[x^{n-2m+j}](1-x)^{-(m-j)}\\
&=\sum^{n}_{m=1}\sum^{m}_{j=0}k^j\binom{m}{j}\binom{m-j+n-2m+j-1}{n-2m+j}\\
&=\sum^{n}_{m=1}\sum^{m}_{j=0}k^j\binom{m}{j}\binom{n-m-1}{m-j-1}\\
&=2^{n-1}+\sum^{n-1}_{m=1}\sum^{m}_{j=0}k^j\binom{m}{j}\binom{n-m-1}{m-j-1}\\
\end{align}
I have tried using the ""snake-oil"" method to compute this sum, that is,
$$P_1(2,n)=2^{n-1}+[x^{n-1}]\sum_{n\ge 1}\sum^{n-1}_{m=1}\sum^{m}_{j=0}k^j\binom{m}{j}\binom{n-m-1}{m-j-1}x^{n-1}$$
but I, embarrassingly, have trouble with changing the order of summation and determining the limits of summation. This is where I am stuck, and I would like to seek your help in finding a closed form for this sum, and in particular, proving that
\begin{align}
P_1(2,n)
&=2^{n-1}+\sum^{n-1}_{m=1}\sum^{m}_{j=0}2^j\binom{m}{j}\binom{n-m-1}{m-j-1}\\
&=F_{2n+1}
\end{align}
Help will be greatly appreciated. Thank you.","['summation', 'binomial-coefficients', 'combinatorics']"
877820,$\int_\mathbb{R} \bigg( \frac{1}{h} \int_x^{x+h} |f(t)| dt\bigg) dx= ||f||_{L^1}$?,"$$\int_\mathbb{R} \bigg( \frac{1}{h} \int_x^{x+h} |f(t)| dt\bigg)  dx= ||f||_{L^1} \;\;?$$ I worked out that the equality holds for each $\chi_{[a,b]}$, therefore it holds for each piecewise constant function. By a density argument, it must hold for all functions in $L^1(\mathbb{R})$. Is this correct? If it were true, I feel like there must be an easier argument for this inequality; I just can't quite see it. Maybe using Hardy-Littlewood maximal inequality or Markov's inequality, etc. Thank you very much for the help!","['integration', 'real-analysis']"
877829,Seemingly hard integrals which are made easy via differentiation under the integral sign a.k.a Feynman Integration [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 9 years ago . Improve this question I recently discovered Differentiation under the integral sign a.k.a Feynman Integration and I read an article which says it can be substituted for contour integration. Therefore, I am assuming this technique is, indeed, very powerful. I was looking for a list of integrals which are, seemingly, hard but are made easy via this technique. Thanks a lot!","['big-list', 'calculus', 'integration']"
877840,inverse trigonometric equation $\tan^{-1}{x}+\cot^{-1}{x}=\frac{\pi}{2}$,I have problem with showing that $\displaystyle \tan^{-1}{x}+\cot^{-1}{x}=\frac{\pi}{2}$ I think there have to be used formula: $\displaystyle \tan(\alpha+\beta)=\frac{\tan{\alpha}+\tan{\beta}}{1-\tan{\alpha}\tan{\beta}} $ but I don't know how to apply it and yet I don't know whether it's true that $\displaystyle\cot^{-1}{x}=\frac{1}{\tan^{-1}{x}}$ ?,"['trigonometry', 'algebra-precalculus']"
877850,Expected area of a random triangle with fixed perimeter,"I'm trying to calculate the expected area of a random triangle with a fixed perimeter of 1. My initial plan was to create an ellipse where one point on the ellipse is moved around and the triangle that is formed with the foci as the two other vertices (which would have a fixed perimeter) would have all the varying areas. But then I realized that I wouldn't account for ALL triangles using that method. For example, an equilateral triangle with side lengths one third would not be included. Can anyone suggest how to solve this problem? Thanks.","['statistics', 'geometry', 'geometric-probability']"
877861,"In Cantor's Diagonalization Argument, why are you allowed to assume you have a bijection from naturals to rationals but not from naturals to reals?","Firstly I'm not saying that I don't believe in Cantor's diagonalization arguments, I know that there is a deficiency in my knowledge so I'm asking this question to patch those gaps in my understanding. From my understanding of Cantor's Diagonalization argument, if you apply diagonalization to a mapping from one set of numbers to another, you will always obtain a number that is not in the mapping. So this works to prove that the reals aren't countable because if you have a mapping from the naturals to the reals then you can use diagonalization to obtain a number that's not in the mapping, and this number is a real obviously, so the mapping isn't a surjection. We're not allowed to assume that the mapping from the naturals to the reals is a bijection to begin with. But when people explain why the diagonalization process doesn't produce a rational from a mapping from naturals to rationals we are allowed to assume that the mapping is a bijection to begin with? In the questions asked here: Why does Cantor's diagonal argument not work for rational numbers? The answers says: To be precise, the procedure does not let you guarantee that the
  number you obtain has a periodic decimal expansion (that is, that it
  is a rational number), and so you are unable to show that the
  ""diagonal number"" is a rational that was not in the original list. In
  fact, if your original list is given explicitly by some bijection,
  then one is able to show just as explicitly that the number you obtain
  is not a rational. Why are we allowed to assume that the original list is a bijection? Is there some way to prove that the mapping from the naturals to the rationals is a bijection that is not susceptible to diagonalization? If we can assume that the mapping from naturals to rationals is an undiagonalizable bijection why can't we do the same for the mapping from naturals to reals?",['elementary-set-theory']
877867,Is the base extension to K of an irreducible nonsingular projective variety over k irreducible?,"Suppose $X$ is an irreducible nonsingular projective variety over a field $k$ (not  necessarily algebraically closed) Let $K$ be a field extension of $k$ ( If $K/k$ is not algebraic, we can assume that the field $k$ is infinite. I don't know if this assumption is useful or not. But if necessary one can assume this). Now can we prove that the base extension $X'$= $X$  x Spec $K$ over Spec $k$ is irreducible? If $k$ is algebraically closed, then I know that this is true. Otherwise I don't know how to prove?",['algebraic-geometry']
877868,"Proof that there is a bijection, if there are injective maps in both directions",Let $A$ and $B$ be two sets. Let $f:A\to B$ be injective such that $Im(f) \subsetneq B$. Let $g:B\to A$ be injective such that $Im(g) \subsetneq A$. Obviously $A$ and $B$ are not finite sets. Can we guarantee an existence of a bijection between $A$ and $B$?,"['elementary-set-theory', 'functions']"
877876,How to integrate scalar field over quarter torus? Infinite series does not converge.,"This seems to be physics question, but the problem just concerns math. Preface If one wants to calculate the permeance $P$ of a rectangular bar: it is an easy task: $$P = \frac{\mu a b}{L} ~~~~ \rightarrow ~~~~  P\propto ab  ~~~~and~~~~  P\propto\frac{1}{L}$$ where $\mu$ is the material constant. (Permeability) Question But my geometry is a torus with just a quarter of its circular cross section and the field $V$ passes through it parallel to the circumference of the (full) cross section: How can I calculate the permeance of this geometry, when there are the same proportional relations as above? Attempted solution I divide my geometry in $N$ hollow toruses with constant wall thickness $\Delta R$ and medium length element $\Delta L$ , so the field passes an area of $\Delta A$ : A little piece of the radius $R$ is $\Delta R = \frac{d}{N}$ . Now one can calculate: $$\Delta P_{n} = \frac{\mu \Delta A_n}{\Delta L_n} $$ with $$ \Delta A_n = \pi \bigg( (R+(n+1) \Delta R)^2-(R+n \Delta R)^2\bigg) $$ (Consider the full torus circumference, not just a quarter as displayed) and $$ \Delta L_n = \frac{\pi}{2} (2n+1) \frac{\Delta R}{2} $$ (but quarter cross section!) follows: $$P = \sum^{N-1}_{n=0} \Delta P_{n} = \mu\sum^{N-1}_{n=0}  \frac{\pi(2R\Delta R+(2n+1)(\Delta R)^2)}{\frac{\pi}{2}(2n+1)(\frac{\Delta R}{2})}~~~~~~~~~~~~~~~~~~~~~~~~~$$ $$= 4\mu\sum^{N-1}_{n=0}  \frac{2r\Delta R+(2n+1)(\Delta R)^2}{(2n+1)(\Delta R)} $$ $$= 4\mu\sum^{N-1}_{n=0}  \Bigg( \frac{2R}{(2n+1)} + \Delta R \Bigg)~~~~~~~~~~ $$ $$= 4\mu \Bigg( d + 2R \sum^{N-1}_{n=0}   \frac{1}{(2n+1)} \Bigg)~~~~~~~~~~ $$ And this series does not converge for $N\rightarrow\infty$ . Which is physically seen not possible, so there must be a problem with the math. Do you see what I'm missing?","['geometry', 'convergence-divergence', 'sequences-and-series', 'integration', 'physics']"
877880,(What is the formula to find) What is the probability that the sum of the numbers on the tickets chosen is at least 7?,"Senario: Box A contains four equal-sized tickets, numbered 1, 2, 3 ,4 Box B contains three tickets of the same size, numbered 4, 5, 6 An experiment consists of selecting one ticket from the box A and then selecting one ticket from box B. My answer: sample space = {(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6),(4,4)(4,5),(4,6)} events where sum is at least 7 = (1,6),(2,5),(2,6),(3,4),(3,5),(3,6),(4,4),(4,5),(4,6)} there for probability = # of possibilities meet the constraint / # of posibilities in sample space =9/12 =3/4 Please advice if there is a formula to get the same answer?","['probability-theory', 'conditional-probability', 'probability', 'problem-solving']"
877882,Terminology on pullbacks,"I'm quite confused with the use of pullbacks, and in particular I wonder which terminology I shall use in the following examples. Let $X$ and $Y$ be arbitrary sets. Suppose that $f,g:X\to Y$ and I know that there exists $h:X\to X$ such that $f = g\circ h$.
Shall I say that $h$ is a pullback (of $f$? $g$?), or how shall I call $h$? Suppose that $R$ is a relation on $Y$ and $f:X\to  Y$ is some map. I define $S$ on $X$ by
$$
  xSx'\quad \iff \quad f(x)Rf(x').
$$
Shall I say that $S$ is a pullback of $R$ along $f$, or how shall I call $S$?","['relations', 'terminology', 'category-theory', 'elementary-set-theory']"
877892,Finitely generated ideal in Boolean ring; how do we motivate the generator?,"This problem is Exercise 11.3 in Atiyah/Macdonald Commutative Algebra. They ask to prove every finitely generated ideal in a Boolean ring is in fact a principal ideal. The question has been answered already on StackExchange: note that $(x,y) = (x+y+xy)$ and then use induction. However, is there any clear motivation for using $x+y+xy$ as the generator of this ideal? (apart from pulling it out of a hat and noticing it has nice properties)","['commutative-algebra', 'ring-theory', 'motivation', 'abstract-algebra']"
877895,Exercise 1.13 of chapter 1 of Revuz and Yor's,"This is the exercise 1.13 of chapter 1 of Revuz and Yor's. Let $B$ be the standard linear BM. Prove that $\varlimsup_{t\to\infty}(B_t/\sqrt{t})$ is a.s. $>0$ (it is in fact equal to $+\infty$ as will be seen in Chap. 2) Prove that $B$ is recurrent, namely: for any real $x$, the set $\{t: B_t=x\}$ is unbounded. Prove that the Brownian paths are a.s. nowhere locally Holder continuous of order $\alpha$ if $\alpha>\frac{1}{2}$.
  [Hint: Use the invariance properties of Proposition (1.10).] What I tried: For 1. $P(\varlimsup_{t\to\infty}B_t/\sqrt{t}>0)=1-P(\varlimsup_{t\to\infty}B_t/\sqrt{t}\leq  0)$ and fix $\varepsilon>0$ there exist large enough $t_0$ s.t. $P(\varlimsup_{t\to\infty}B_t/\sqrt{t}\leq 0)\leq P(B_{t_0}/\sqrt{t_0}<\varepsilon)$<1/2, then $P(\varlimsup_{t\to\infty}B_t/\sqrt{t}>0)>1/2$. By Hewitt-Savage zero-one law, $P(\varlimsup_{t\to\infty}B_t/\sqrt{t}>0)=1$. But I am not very familier with HS 0-1 law, is there some other method to solve this problem? (also not using law of iterated logarithm) For 2. By 1, $P(\varliminf_{t\to\infty}B_t/\sqrt{t}<0)=P(\varlimsup_{t\to\infty}(-B_t)/\sqrt{t}>0)=P(\varlimsup_{t\to\infty}B_t/\sqrt{t}>0)=1$, so $x=0$ is recurrent. But how to prove it when $x\neq0$? For 3. It is sufficient to prove $P\left(\sup_{0\leq s,t\leq 1}\frac{|B_t-B_s|}{\sqrt{|t-s|}}=+\infty\right)=1$. It can be proved by the independent increment property and scaling property of Brownian Motion.","['probability-theory', 'brownian-motion']"
877898,$\overline{\theta}$ the maximum likelihood estimator of $\theta \implies$?,I can't understand how the following statement holds without any extra conditions on the function $g$: $\overline{\lambda}$ the maximum likelihood estimator of parameter $\lambda \implies g(\overline{\lambda})$ the maximum likelihood estimator of $g(\lambda)$ Intuitively it would seem that we would need $g$ to be monotionic for this to be true. How can it be shown that this statement holds for an arbitrary function $g$?,"['statistics', 'probability']"
877907,Is this proof of the fundamental theorem of calculus correct?,"A student friend of mine recently gave me a proof of the fundamental theorem of calculus which does not correspond to any I can find in the textbooks. It starts by considering an increasing continuous function and taking the area of a thin rectangle topped with a triangle created by adding to the $x$ value (like the wikipedia entry for the theorem): $$
\begin{align}
A(x + h) & = A(x) + hA'(x)\\
hA'(x)& = A(x + h) - A(x)\\& = hf(x) + \frac12h\cdot hf'(x)
\end{align}
$$ where $A$ is the area function, $h$ is the added value, the first term on the RHS is the area of the rectangle and the second term on the RHS is the area of the triangle. The $hf'(x)$ term is the projection that forms the vertical side of the triangle. Apparently the curve can be composed of small straight lines making the triangle possible. The next step is: $$\begin{align}
    hA'(x) &= hf(x)\\
    A'(x) & = f(x)
\end{align}$$ RHS 2 is discarded because $h^2$ is negligible. Is this proof legitimate? If so why isn't it in the textbooks? It seems much simpler than the alternatives.","['calculus', 'proof-verification', 'analysis']"
877912,Explain why $\big(\int_{-\infty}^{\infty}e^{-z^2/2}dz \big)^2 = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(z^2 + u^2)/2}dzdu$,I came across the following when studying a proof related to the normal distribution: $$\left(\int_{-\infty}^{\infty}e^{-z^2/2}\ dz \right)^2 = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(z^2 + u^2)/2}\ dz\ du$$ Is this some kind of identity? It was used as a step in the proof but I would like to know how it was arrived at?,"['multivariable-calculus', 'improper-integrals', 'integration', 'statistics', 'normal-distribution']"
877922,A question about algebraically closed fields,A field $\mathbb{K}$ is said to be algebraically closed in practice if every polynomial over  $\mathbb{K}$ of positive degree less than or equal to  $10^{10}$   has zero belonging  $\mathbb{K}$. The question arises: is it possible that  an algebraically closed in practice field is not  algebraically closed? PS. The question still remains open in characteristic 0.,"['ring-theory', 'field-theory', 'abstract-algebra', 'polynomials']"
877936,Prove $\frac{\sin A}{\sec A+\tan A-1}+ \frac{\cos A}{\csc A+\cot A-1}=1$,$$\frac{\sin A}{\sec A+\tan A-1}+ \frac{\cos A}{\csc A+\cot A-1}=1$$ Prove that L.H.S.$=$R.H.S. This type of questions always creates problem when in right hand side some trigonometry function is given then it is bit easy to think how to proceed further. Can some one help me not only to solve the problem but also how to tackle this type of other problem (when R.H.S. is $1$)?,"['trigonometry', 'self-learning', 'algebra-precalculus']"
877949,Solving $xy''-(1-x)y'+y=0$,"$$xy''-(1-x)y'+y=0$$ So I know how to solve this via power series. Recently, a friend of mine was asking me how one could solve this without using series. I've got no real idea how to answer this without blinding guessing one of the solutions. Anyone have ideas on how to approach without series solution?",['ordinary-differential-equations']
877981,Duo Fresnel-like integrals $(??)$,"I really wonder how I can prove the following integrals. $$\int_0^\infty \sin ax^2\cos 2bx\, dx=\frac{1}{2}\sqrt{\frac{\pi}{2a}}\left(\cos \frac{b^2}{a}-\sin\frac{b^2}{a}\right)$$ and $$\int_0^\infty \cos ax^2\cos 2bx\, dx=\frac{1}{2}\sqrt{\frac{\pi}{2a}}\left(\cos \frac{b^2}{a}+\sin\frac{b^2}{a}\right)$$ I tried $\sin ax^2=\Im(e^{iax^2})$ and $\cos ax^2=\Re(e^{iax^2})$ then I used by parts method but I failed. Obviously tangent half-angle substitution doesn't work. I'm quite sure if we can calculate one of them, the similar technique can be used to calculate the other. Could anyone here please help me to calculate the integrals preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","['improper-integrals', 'calculus', 'integration', 'trigonometry', 'real-analysis']"
877993,Total boundness of Lipschitz densities,"In the article Almost Sure Testability of Classes of Densities by Devroye and Lugosi in 1999. They claim in Example 10 (page 9) that Lipschitz densities on [0,1] with Lipschitz constant bounded by some $C$ are a closed set and are as a class of densities totally bounded. Why is this? I cannot find a proof of it.","['statistics', 'probability-theory', 'real-analysis', 'analysis', 'probability']"
877995,Is it possible to write the curl in terms of the infinitesimal rotation tensor?,"Is it possible to write the curl in terms of the infinitesimal rotation tensor?  Basically, we can write the curl as a matrix operator $$
   curl=\begin{bmatrix} 0 & -\partial z & \partial y\\\partial z & 0 & -\partial x\\-\partial y & \partial x & 0\end{bmatrix}
$$
and we can write the infinitesimal rotation tensor as a matrix operator (modulo a 1/2 constant)
$$
   \nabla-\nabla^T = \begin{bmatrix}
        0 & -(\partial x-\partial y) & \partial z-\partial x\\
        \partial x-\partial y & 0 & -(\partial y-\partial z)\\
        -(\partial z-\partial x) & \partial y-\partial z & 0
    \end{bmatrix}.
$$
The axial vector to the infinitesimal rotation tensor is
$$
    \begin{bmatrix}
        \partial y-\partial z\\
        \partial z-\partial x\\
        \partial x-\partial y
    \end{bmatrix},
$$
which looks kind of like the curl, except that this seems kind of sloppy since we have a vector with a bunch of differential operators inside of it with no clear way on how to apply it. As such, again, is there a way to write the curl in terms of the infinitesimal rotation tensor?","['multivariable-calculus', 'ordinary-differential-equations', 'classical-mechanics', 'differential-geometry']"
878008,Alternative proof for the fact that a continuous function on a closed interval attains its boundaries.,"Let $f:[a,b]\to \mathbb{R}$  be a continuous function. We are interested in showing that $\exists  \beta \in [a,b]$, such that $f(\beta) = M$, where M is its upper boundary. I have managed to proof by myself the fact that any continuous function on a closed interval is bounded so I assume we can use this in our proof. I was playing a little with the pencil, doing some test work, and the following idea came to my mind: I defiend a new function $g:[a,b]\to \mathbb{R}$, $g(x) = \frac{1}{M-f(x)}$. $g$ is obviously continuous on $[a,b]$, and we have $g(x)>0,\forall x \in [a,b]$. Since $g$ is continouou on a closed interval, $g$ is bounded. Let $M_1$ be its upper boundary. Now we have that: $$ \frac{1}{M-f(x)} \leq M_1  $$ This actually implies that: $$f(x) \leq M - \frac{1}{M_1} < M $$ This can't be true! Because if it were true, $f$ wouldn't be bounded by $M$. So, here's what I don't get. I have arrived at a contradiction! But what have I managed to contradict? It seems to me that this contradiction arrived from the fact that $f$ was bounded. So have I proved that f can't be bounded? But this doesn't make any sense, because we know for sure that $f$ is bounded, since its continuous on a closed interval. I feel that I am very close to prove the claim. Could you please help me realise what am I doing wrong here?","['proof-verification', 'functional-analysis', 'real-analysis']"
878030,Parity of sum of Kronecker deltas in a graph,"For some fixed $n\in\mathbb N$ let $G$ be a graph on the vertex set $\{1,\dots,n\}$ with a total number of $k$ edges $e_1,\dots, e_k$. For any vertex colouring $c(i)$ of the graph, $\delta_e$ is defined to be $1$ if the vertices that are connected by the edge $e$ have the same colour, and $0$ otherwise. A colouring is given a weight of $1$ if the number of edges connecting two vertices of the same colour is even and $-1$ otherwise. If I have a total of, say, 3 colours available I am interested in the weighted sum over all possible colourings $$f(G):=3^{-n}\sum_{c(1)=1}^3\dots\sum_{c(n)=1}^3 (-1)^{k+\delta_{e_1}+\dots+\delta_{e_k}}$$ measuring the mean parity of the number of edges connecting vertices of the same colour. It is clear that for a graph without edges $f(G)=1$, and that if all edges are disjoint $f(G)=(-1/3)^{k}$. For the complete graph the result seems to be $$f(G)=\frac{3^{1-n}}{2}(1+(-3)^{n-1}).$$ Question: How $f(G)$ be described in terms of properties of the graph? Edit: See below for a table of $f(G)$ for all graphs on 3 and 4 vertices. It seems to me that for all trees the result is $(-1/3)^{k}$. It also seems more generally, that adding a new edges to a so far not connected vertex yields a division by $-3$.","['graph-theory', 'combinatorics']"
878038,"Name of this property: even + odd = odd, rational + irrational = irrational [Complementary Subgroup Test]","I'm looking for a name of a property of which I have a few examples: $(1) \quad\color{green}{\text{even number}}+\color{red}{\text{odd number}}=\color{red}{\text{odd number}}$ $(2) \quad \color{green}{\text{rational number}}+\color{red}{\text{irrational number}}=\color{red}{\text{irrational number}}$ $(3) \quad\color{green}{\text{algebraic number}}+\color{red}{\text{transcendental number}}=\color{red}{\text{transcendental number}}$ $(4) \quad\color{green}{\text{real number}}+\color{red}{\text{non-real number}}=\color{red}{\text{non-real number}}$ If I were to generalise, this, I'd say that if we partition a set $X$ into two subsets $S$ and $S^c=X\setminus S$, then the sum of a member of $S$ and a member of $S^c$ is always in either $S^c$ or $S$. My question is: ""Is there a name for this property (in these four cases) and is this property true in general?"" Also, does anyone have any more examples of this property?","['terminology', 'abstract-algebra']"
878039,"If A+tB is nilpotent for n+1 distinct values of t, then A and B are nilpotent.","Suppose $A$ and $B$ are $n\times n$ matrices over $\mathbb{R}$ such that for $n+1$ distinct $t \in \mathbb{R}$ , the matrix $A+tB$ is nilpotent. Prove that $A$ and $B$ are nilpotent. What I've tried so far: Define $f(t)=(A+tB)^n$ . Then $f(t)$ has polynomials of degree at most n as its entries. Each of these polynomials has n+1 distinct roots, and hence is the constant zero polynomial. This shows that for all $t \in \mathbb{R} \ f(t)=0$ , which in particular gives $A^n= f(0) =0$ that shows A is nilpotent. Now if none of the $t_1,...t_{n+1}$ , that make A+tB nilpotent, is zero, we can use $g(t)=(tA+B)^n$ with roots $\frac{1}{t_i}$ similarly and show that B, too, is nilpotent. But I have no idea in case one of the $t_i$ is zero. Thanks in advance.","['matrices', 'nilpotence', 'linear-algebra']"
878073,Proof of: $X$ is finite $\iff X$ is Tarski-finite,"I am self-studying Horst Herrlich, Axiom of Choice (Lecture Notes in Mathematics, Vol. 1876) . In the fourth chapter, he deals with different definitions of finite set . Here is the classical one: Definition 1. A set $X$ is called finite if there exists a bijection $n \to X$ for some $n \in \mathbb{N}$ . Otherwise it is called infinite . Here is Tarski's (1924) definition: Definition 2. A set $X$ is called Tarski-finite , provided that each non-empty subset of $\mathcal P(X)$ contains a minimal element w.r.t. the inclusion order. Otherwise it is called Tarski-infinite . The following holds: Proposition. Equivalent are: $X$ is Tarski-finite. If $\mathcal U \subseteq \mathcal P(X)$ satisfies a) $\emptyset \in \mathcal U$ , and b) $A \in \mathcal U$ and $x \in X$ imply $A \cup \{x\} \in \mathcal U$ , then $X \in \mathcal U$ . The proof of the proposition is simple. But right after that, he writes: Observe that by Proposition, the definition of finiteness as given in Definition 1 is equivalent to the one in Definition 2. No proof follows. The ""Def.1 $\implies$ Def.2"" part seems easy to me, but the converse doesn't. Would you help me with that? Please, note that we do not want to use AC (indeed, all this thing is about proving that the two definitions are equivalent even in ZF). Therefore, we can't even use that "" $X$ infinite $\implies \aleph_0 \leq |X|$ "", since the latter is not a theorem of ZF.","['elementary-set-theory', 'axiom-of-choice']"
878085,Hartshorne Example I.5.6.3,"This question is concerned with Example I.5.6.3 in Hartshorne. Let $g, h$ be elements of $k[[x,y]]$ of the form $g = y+x+g_2+g_3+\cdots, h = y-x + h_2+h_3+\cdots$ where $g_i,h_i$ are homogeneous polynomials of degree $i$. 
Hartshorne writes ""Since $g$ and $h$ begin with linearly independent linear terms, there is an automorphism of $k[[x,y]]$ that sends $g,h$ to $x,y$ respectively. This shows that $k[[x,y]]/(gh) \cong k[[x,y]]/(xy)$."" (From the context of the example, this last isomorphism is supposed to be a $k$-algebra isomorphism.) Question: Is seems to me that the automorphism described above is an automorphism of $k$-vector spaces. Why does it induce an automorphism of $k$-algebras?",['algebraic-geometry']
878103,Another Presentation of Certain Cyclic Groups,"Show that the the group with presentation $$\langle x, y\ \mid\ x^2=y^2x^2y,\ (xy^2)^2=yx^2, \ yx^{-1}y^2=x^n\rangle $$ is cyclic of order $3(n+1)$, for  $n=0 \mod 3$ or $n= 1 \mod 3$, $n\ge 0$. This presentation is related to the group presented in problem 476854 and is also related to problem 876731.","['cyclic-groups', 'finite-groups', 'group-theory', 'group-presentation']"
878115,In 30 boxes are 15 balls. Chance all balls in 10 or less boxes?,"Question1:
I found 30 boxes. In 10 boxes i found 15 balls. In 20 boxes i found 0 balls.
Afer i collected all 15 balls i put them randomly inside the boxes. How much is the chance that all balls are in only 10 boxes or less? Question2:
I found 30 boxes. In 10 boxes i found 15 balls. In 20 boxes i found 0 balls. In two of the boxes i could find 3 balls. (So in one box has to be 2 balls and in the other seven boxes have to be 1 ball.)
Afer i collected all 15 balls i put them randomly inside the boxes. How much is the chance that i find in only 2 boxes 6 balls or more? I wrote a c# programm and tried it 1 million times.
My solution was: With a chance of 12,4694% all balls are in 10 boxes or less.","['statistics', 'probability']"
878130,Polynomial $f(x)$ degree problem.,"Suppose the polynomial $f(x)$ is of degree $3$ and satisfies $f(3)=2$, $f(4)=4$, $f(5)=-3$, and $f(6)=8$. Determine the value of $f(0)$. How would I solve this problem?  It seems quite complicated...","['algebra-precalculus', 'polynomials']"
878135,Cantor diagonalization and fundamental theorem,"Can the Cantor diagonal argument be use to check countability of natural numbers?
I know how it sounds, but anyway. According to the fundamental theorem of arithmetic, any natural number can be
expressed as an unique product of primes. if we denote primes $2,3,5,\ldots$ as $P_1,P_2,P_3,\ldots$ and include $1$ as part of the
system, we will get, $$D = [1, P_1, P_2, P_3,\ldots]$$ we can write any natural number as series of $[d]$ that goes on forever, as we
can keep on appending $1$ to any product of primes forever. for example $6$ is $2 \cdot 3 \cdot 1 \cdot 1 \cdot 1 \cdot 1 \cdot 1.....$ Now, we use the Cantor diagonalization, and enumerate all possible
combinations of D. $$1 - D_{11}, D_{12}, D_{13}, D_{14}, ...$$
$$...$$
$$n - D_{n1}, D_{n2}, D_{n3}, D_{n4}, ...$$
$$...$$ Can we show that there is another number that is not in the list?
If we assume that there is a function, $\operatorname{Next}(D)$, that gives as the
next element in $[D]$. $$P_1 = \operatorname{Next}(1)$$
$$P{n+1} = \operatorname{Next}(P_n)$$ since there is always the next prime, we can construct, $$m = \operatorname{Next}(D_{11}) \cdot \operatorname{Next}(D_{22}) \cdot \operatorname{Next}(D_{33}) \cdot \operatorname{Next}(D_{44})...$$ This is analogous to adding $1$ to diagonal elements applied to real numbers. From the same diagonalization argument this number, '$m$' cannot be in the list. It
is a contradiction, and natural numbers aren't countable... Can someone point on a rigurous discussion of such a reasoning? Thanks!","['cardinals', 'elementary-set-theory']"
878167,Intuition about Taking an Integral,"My hope is to personally develop some further intuition for taking an integral (measuring the area under a curve). Consider a normal distribution and I need the area under the curve from $a$ to $b$. I know from calculus that the answer is given by: $$P(a\le X \le b)  = \int_{a}^{b} f(x)dx = \int_{a}^{b}\frac{1}{\sigma\sqrt{2\pi}}e^{−(y−\mu)^2/ 2\sigma^2} dx$$ My class instructor then draws a normal curve, indicates $a$ and $b$ on the horizontal axis (number line) and draws a line up from each point $a, b$ to the density function, connects the two crossing points and showing a square asks us, ""How do we get the area of a square?"" (Answer: base times height.) It is then shown that the area of the square underestimates the area under the curve and then to get a better approximation the squares are redrawn as two rectangles and then four rectangles and then eight rectangles and this process shows that the area of the (smaller and smaller width) rectangles approximates the area under the curve better and better. Next the instructor said that the ""$f(x)$"" part can be thought of as the height of the rectangle and the ""$dx$"" part can be thought of as the base (width) of the rectangle and that we want the base to be really small, in fact, infinitely small. The instructor then says something like, ""Taking an integral or measuring the are under a curve is like summing the areas of rectangles with infinitely small width."" My questions: Are there other intuitive explanations of what is happening when we take an integral out there and would you please provide them? How would a pure mathematician explain an integral? Would the explanations (intuitive and mathematical) be fully consistent? Multiple explanations or points of view would be appreciated.","['self-learning', 'integration', 'real-analysis', 'analysis']"
878238,Geometric meaning of a matrix decomposed into its symmetric and skew-symmetric parts,"What's the geometric meaning of a matrix decomposed into its symmetric and skew-symmetric parts?  For example, a skew-symmetric matrix on its own can be interpreted as an infinitesimal rotation.  As an another example, the polar decomposition of a matrix A=UP=QU for a unitary matrix U and symmetric positive definite matrices P and Q means that we can interpret a matrix as a stretching (the positive definite matrix) followed by a rotation (the unitary matrix) or vice versa. Basically, the decomposition of a matrix into its symmetric and skew symmetric parts $A=(1/2)(A+A^T)+(1/2)(A-A^T)$ is causing me problems because I don't know how to geometrically interpret the symmetric part (if it was positive definite it would be a stretch) nor the sum (if it was a product then one action would follow the other.) Edit 1 The answer from @user_of_math helped me figure the rest of this out. Assume that we have a matrix $B$ thats symmetric.  Then, we know that it has a spectral decomposition $B=VDV^T$.  What this says is that the action of $B$ on a vector $x$ occurs in three steps We determine how much we will project $x$ onto the columns of $V$, $V^T x$ We scale this projection by the eigenvalues of $A$, $D V^T x$ Then, we put everything back into the original coordinate axis, $V D V^T x$ In other words, a symmetric operator scales the space along the orthogonal axes defined by $V$.  When $B$ is positive definite, the elements of $D$ are positive and this is a stretch.  When $B$ is indefinite or negative definite, we can potentially flip or collapse an axis.  In any case, provides one explanation of the geometric the meaning of a symmetric operator. Now, let $C$ be a skew-symmetric operator.  Then, $exp(C)$ is orthonormal matrix, which corresponds to a rotation. At this point, we have an idea of what happens with a symmetric operator and a skew-symmetric operator, but there's a disconnect because our explanation assumed the skew-symmetric operator corresponds to something infinitesimal and the symmetric operator does not.  As such, consider an infinitesimal shift of a vector x by a symmetric operator B
$$
\lim\limits_{\alpha\rightarrow 0} (I+\alpha B)x
$$
More specifically, we want to do an infinite number of these transformations, so we have
$$
\lim\limits_{n\rightarrow\infty} \left(I+\frac{1}{n} B\right)^n x = exp(B)x
$$
Now, since $B$ is symmetric, we have the spectral decomposition, $B=VDV^T$.  Hence,
$$
exp(B)x=exp(VDV^T)x=Vexp(D)V^Tx,
$$
which is interesting because this says that $exp(B)$ is a positive definite operator.  In other words, and infinite number of shifts by a symmetric operator eventually yields a single stretch by a positive definite operator. In any case, let's look at the general situation now.  Let $B=(A+A^T)/2$ be the symmetric part of $A$ and $B=(A-A^T)/2$ be the skew-symmetric part.  Then, consider an infinite number of shifts by $A$,
$$
\lim\limits_{n\rightarrow\infty} \left(I+\frac{1}{n} A\right)^n  = exp(A) = exp(B+C) = \lim\limits_{n\rightarrow \infty}(exp(B/n)exp(C/n))^n
$$
where the last equality comes from the Lie product formula.  This says that the meaning of $exp(A)$ is an infinite, alternating application of infinitesimally small stretches, defined by $exp((A+A^T)/2)$, and rotations, defined by $exp((A-A^T)/2)$.  In other words, the geometric meaning of exp(A), when $A$ is decomposed into its symmetric and skew-symmetric components, is an alternating application of stretches and rotations defined by these symmetric and skew-symmetric components, respectively.","['geometry', 'linear-algebra', 'classical-mechanics']"
878245,Asymptotic expansion on 3 nonlinear ordinary differential equations,"The 3 nonlinear differential equations are as follows
\begin{equation}
\epsilon \frac{dc}{dt}=\alpha I   +  \ c (-K_F - K_D-K_N s-K_P(1-q)), \nonumber
\end{equation} \begin{equation}
\frac{ds}{dt}= \lambda_b P_C \ \epsilon \ c   (1-s)- \lambda_r (1-q)  \ s,  \nonumber
\end{equation}
\begin{equation}
 \frac{dq}{dt}= K_P (1-q) \frac{P_C}{P_Q} \  \ c - \gamma  \ q,  \nonumber
\end{equation}
I want to use asymptotic expansion on $c, s$ and $q$.
And values of parameters are: $K_F = 6.7 \times 10^{-2},$ $K_N = 6.03 \times 10^{-1}$ $K_P =  2.92 \times 10^{-2}$, $K_D = 4.94 \times 10^{-2}$, $\lambda_b= 0.0087$, $I=1200$ $P_C  =  3 \times 10^{11}$ $P_Q  = 2.304 \times 10^{9}$ $\gamma=2.74 $ $\lambda_{b}=0.0087 $ $\lambda_{r}= 835$ $\alpha=1.14437 \times 10^{-3}$ For initial conditions: \begin{equation}
c_0(0)= c(0) = 0.25 \nonumber
\end{equation}
\begin{equation}
s_0(0)= cs(0) = 0.02 \nonumber \nonumber
\end{equation}
\begin{equation}
q_0(0)=q(0) = 0.98 \nonumber \nonumber
\end{equation}
 and
\begin{equation}
c_i(0)= 0,    \ i>0\nonumber
\end{equation}
\begin{equation}
s_i(0)= 0, \ i>0 \nonumber \nonumber
\end{equation}
\begin{equation}
q_i(0)=0, i>0. \nonumber \nonumber
\end{equation} => i started with the expansions :
\begin{equation}
c= c_0+ \epsilon c_1 + \epsilon^2 c_2+......... \nonumber
\end{equation}
\begin{equation}
s= s_0+ \epsilon s_1 + \epsilon^2 s_2+......... \nonumber
\end{equation}
\begin{equation}
q= q_0+ \epsilon q_1 + \epsilon^2 q_2+......... \nonumber
\end{equation}
we are only interseted in up to fisrt power of $\epsilon$. 
so, we should get total 6 approximate differential equations to get answer for
$\dfrac{dc_0}{dt}, \dfrac{ds_0}{dt}, \dfrac{dq_0}{dt}, \dfrac{dc_1}{dt}, \dfrac{ds_1}{dt}$ and $\dfrac{dq_1}{dt}$ but i think $\dfrac{dc_1}{dt}$ will disappear while expanding and equating the up to first power of $\epsilon$, do i need to go further up to $\epsilon{^2}$ because $\dfrac{dc_1}{dt}$ is very important to find and we need 6 approximate differetial equations in total. what can i do? please some one help  me.","['ordinary-differential-equations', 'perturbation-theory', 'asymptotics', 'systems-of-equations', 'taylor-expansion']"
878258,"Showing that derivative of conjugate is conjugate of derivative, using chain rule","I'm trying to show that the derivative of the conjugate is the conjugate of the derivative, i.e. $$
\dfrac{\mathrm{d}[f(x)^*]}{\mathrm{d}x} = \biggl[\frac{\mathrm{d}f(x)}{\mathrm{d}x}\biggr]^*,
$$ using the chain rule. Calling the conjugate * function '\operatorname{conj}', we have by chain rule $$
\dfrac{\mathrm{d}\operatorname{conj}(f(x))}{\mathrm{d}x}
= \dfrac{\mathrm{d}\operatorname{conj}(f(x))}{\mathrm{d}[f(x)]} \cdot \dfrac{\mathrm{d}f(x)}{\mathrm{d}x}
$$ Now, $$
\dfrac{\mathrm{d}\operatorname{conj}(f(x))}{\mathrm{d}[f(x)]}
\equiv \lim \limits_{h \to 0}{\frac{\operatorname{conj}(f(x)+h)-\operatorname{conj}(f(x))}{h}}
= \lim \limits_{h \to 0}{\frac{h^*}{h}}
$$ where $h \in C$ . I wasn't sure how to evaluate that limit, but according to Wolfram Alpha , it is = 1. But that doesn't make sense, since then $$
\dfrac{\mathrm{d}\operatorname{conj}(f(x))}{\mathrm{d}x}
= 1 \cdot \dfrac{\mathrm{d}f(x)}{\mathrm{d}x}
= \dfrac{\mathrm{d}f(x)}{\mathrm{d}x},
$$ when it should be $\biggl[\dfrac{\mathrm{d}f(x)}{\mathrm{d}x}\biggr]^*$ . What am I doing wrong?","['calculus', 'complex-analysis']"
878279,Finding the zeros of trigonometric polynomials.,"I have a question about something I've struggled with for a while: Finding the zeros of trigonometric polynomials. Let me show you a problem I am solving and you guys can tell me if I got the right answer. I am to find all graphs on the following function where the tangent line is zero:
$$y = 2\sin x - 2\sin x$$ Seems easy enough, I find the derivative:
$$\frac {dy}{dx} = 2\cos x - 2\cos x$$ However when I set the expression equal to zero:
$$2\cos x - 2\cos x = 0$$
$$\cos x - \cos x = 0$$ So does this mean all points on the graph have horizontal tangents? Please let me know.","['trigonometry', 'calculus', 'algebra-precalculus']"
878325,What is a bilinear form?,"I'm a CS master student and I'm reading a paper that mentions the term ""bilinear form"". Actually the paper mentions ""bilinear regression model"". But I think in order to understand what a ""bilinear regression model"" is, I need to understand what does ""bilinear form"" mean. I checked the wiki page on ""bilinear form"" but couldn't understand. Can you please explain to me (in simpler ways) the idea behind 'bilinear form'? If you know what 'bilinear regression model' is, I would also be very thankful for an explanation as well :).","['regression', 'linear-algebra', 'bilinear-form']"
878326,Sufficient statistic,"Let $\mathbf{X}=(X_1,\ldots,X_n)$ with joint frequency function $f(\mathbf{x};\theta_1,\theta_2)$ where $\theta_1,\theta_2$ vary independently. The set $S=\{\mathbf{x}:f(\mathbf{x};\theta_1,\theta_2)>0\}$ doesn't depend on $\theta_1,\theta_2$.
Suppose $T_1$ is sufficient for $\theta_1$ when $\theta_2$ is known, and $T_2$ is sufficient for $\theta_2$ when $\theta_1$ is known. I need to show that $(T_1,T_2)$ is sufficient for $(\theta_1,\theta_2)$, if $T_1$ doesn't depend on $\theta_2$ and $T_2$ doesn't depend on $\theta_1$. So, I'm having some difficulty in interpreting the problem and expressing it with mathematical expressions. I was thinking of using the Factorization Criterion. «Suppose $T_1$ is sufficient for $\theta_1$ when $\theta_2$ is known.» This sentence I'm writing it as : With $\theta_2$ known, $f(\mathbf{x};\theta_1,\theta_2)=g_1(T_1(x),\theta_1)h_1(x)$ Similarly, for the other sentence: $f(\mathbf{x};\theta_1,\theta_2)=g_2(T_2(x),\theta_2)h_2(x)$ and so, $f(\mathbf{x};\theta_1,\theta_2)=\left(g_2(T_2(x),\theta_2)\cdot g_1(T_1(x),\theta_1)\right)^{1/2}(h_1(x)\cdot h_2(x))^{1/2 }$ However, this doesn't seem to be a correct resolution, since I don't seem to be using the information given about $S$, at least explicitly... Any help would be appreciated.","['statistics', 'estimation', 'probability']"
878341,Evaluating $\int_0^\pi\arctan\bigl(\frac{\ln\sin x}{x}\bigr)\mathrm{d}x$,"I found the following integral as a by product of another one. It has a nice closed form. $$
\int_{0}^{\pi}
\arctan\left(\ln\left(\sin x \right) \over x\right)\,{\rm d}x 
$$ Mathematica and Maple fail to give the answer. Could you find it? Hint 1: The closed form is $$
-\pi\arctan \left(2\ln 2  \over \pi\right) 
$$ Hint 2: The following integral may help $$
\int_{0}^{\pi}{x \over x^{2} + \ln^{2}\left(\alpha\sin x \right)}
\,{\rm d}x
$$ ( see this post ).","['closed-form', 'calculus', 'integration', 'definite-integrals', 'logarithms']"
878344,Evaluate $\int_0^1\frac{x^a-x^{-a}}{x-1}dx$,"I have heard that:
$$\int_0^1\frac{x^a-x^{-a}}{x-1}dx=\frac1 a-\pi\cot(\pi a)$$
when $-1<a<1$. How would I prove this? That doesn't have an elementary indefinite integral , but the definite integral is quite simple. Someone suggested I use complex analysis to prove it, but I am relatively new to the subject. (I have gotten up to contour integrals, but I'm not sure how to use them to evaluate this particular integral.) I also tried expanding it with a series, but it didn't help.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
878365,Book/Article recommendation [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question I am a first year Math major in the university, this summer I want to self study and go over some specific subjects. Firstly, can someone can give a suggestion for a detailed book/article about the construction of Real numbers? I felt like we discussed this subject briefly in my first Analysis course, and want to know more about it. Secondly, I am planning on studying Set theory , and need a good book for self study. (Undergraduate) Lastly, I need a good suggestion for Discrete math  (undergraduate) text book for self study. If by experience someone knows good books, I would be happy to hear your suggestions! 
Appreciate the feedback!","['book-recommendation', 'reference-request', 'discrete-mathematics', 'elementary-set-theory']"
878374,taylor series of $\ln(1+x)$?,Compute the taylor series of $\ln(1+x)$ I've first computed derivatives (up to  the 4th) of ln(1+x) $f^{'}(x)$ = $\frac{1}{1+x}$ $f^{''}(x) = \frac{-1}{(1+x)^2}$ $f^{'''}(x) = \frac{2}{(1+x)^3}$ $f^{''''}(x) = \frac{-6}{(1+x)^4}$ Therefore the series: $\ln(1+x) = f(a) + \frac{1}{1+a}\frac{x-a}{1!} - \frac{1}{(1+a)^2}\frac{(x-a)^2}{2!} +  \frac{2}{(1+a)^3}\frac{(x-a)^3}{3!} -  \frac{6}{(1+a)^4}\frac{(x-a)^4}{4!} + ...$ But this doesn't seem to be correct. Can anyone please explain why this doesn't work? The supposed correct answers are: $$\ln(1+x) = \int \left(\frac{1}{1+x}\right)dx$$ $$\ln(1+x) = \sum_{k=0}^{\infty} \int (-x)^k dx$$,"['derivatives', 'taylor-expansion']"
878391,How do I find a point on the surface of a sphere,"How do I find a point on a sphere knowing its radius and center point ? I have a sphere:  $$x^2+(y-1)^2+(z+3)^2=16$$
Obviously its center point is $(0,1,-3)$ and its radius is $4$.
I am asked to find the minimum and maximum distance to point $(1,1,1)$
So nearest point would be the touch point with the surface, and farthest point would be the touchpoint + distance of diameter. Can you help me solve this?","['multivariable-calculus', 'calculus']"
878406,"Prove ${\large\int}_0^\infty\left({_2F_1}\left(\frac16,\frac12;\frac13;-x\right)\right)^{12}dx\stackrel{\color{#808080}?}=\frac{80663}{153090}$","I discovered the following conjectured identity numerically (it holds with at least $1000$ digits of precision). How can I prove it?
$${\large\int}_0^\infty\left({_2F_1}\left(\frac16,\frac12;\frac13;-x\right)\right)^{12}dx\stackrel{\color{#808080}?}=\frac{80663}{153090}$$ Update: It looks like this hypergeometric function assumes algebraic values at algebraic points (it's only a guess because I have only approximations to those algebraic numbers). Looking at those values, I was able to further conjecture that the hypergeometric function for $x<0$ is actually the following elementary function: $$
{_2F_1}\left(\frac16,\frac12;\frac13;x\right)\stackrel{\color{#808080}?}=
\\
\frac1{\sqrt[4]2\sqrt3}\cdot\sqrt{\frac{\alpha}{1-x}+\frac{1}{\alpha}
\sqrt{\frac{4\left(\alpha\sqrt{2}+2\right)+x\left(\sqrt[3]{4\beta}-2\left(\alpha\sqrt{2}+4\right)\right)+2\sqrt[3]{2\beta^2}}{1-x}}}~,
$$ where $$\alpha=\sqrt{2-2x+\sqrt[3]{2\beta^2}}~,\qquad\beta=x(x-1)~.$$","['improper-integrals', 'special-functions', 'calculus', 'integration', 'hypergeometric-function']"
878409,"Are ""most"" continuous functions also differentiable?","Let $A$ be a nonempty open subset of $\mathbb{R}$. Consider a function $f : A \rightarrow \mathbb{R}$. Given that $f$ is continuous, what is the probability that it is differentiable? I suspect it is $0$.","['measure-theory', 'continuity', 'probability', 'derivatives']"
878417,Difficult Recurrence,"I am trying to solve a Sangaku problem. The blue circles have radii one. The goal is to find the total area of all the other circles (the three sequences of circles repeat ad infinitum). I have almost solved the problem. I have found the area of the red circle, and the total area of all circles touching the horizontal axis. I even have a proposed recurrence for the radius of the circles going up the center. Here is my logic: Take any circle on the vertical stack. Draw a right triangle with one vertex at its center, one at the center of the (left) blue circle, and one vertex below the blue circle's center level with the other vertex. One leg of this triangle has length one, and the hypotenuse is $1 + r$, where $r$ is the radius of the circle in question. The other leg has length one minus the sum of $r$ and the diameters of all circles below. There is just one unknown and these quantities are uniquely related by the Pythagorean theorem. So we have a recurrence. $R(n)$ denotes the radius of the $n^{th}$ circle on the vertical stack, with $n=1$ the red circle. After manipulating the expression from the Pythagorean theorem, we get
$$\begin{align*}
R(1) &= 1/4 \\
R(n) &= \dfrac{\left(1 - 2\sum_{k = 1}^{n-1} R(k)\right)^2}{4\left(1 - \sum_{k = 1}^{n-1} R(k)\right)}
\end{align*}$$ This is where I am stuck. I am looking for any sort of help in solving for a closed form of $R$. Thanks (For those interested, here is my work on the first part of the problem. If you spot a mistake here, feel free to point it out, but my main question is how to solve the above recurrence.) Revival of Sangaku Take any three circles that are $(1)$ all tangent to the horizontal axis and $(2)$ touching one another. The radius of the middle one can be given in terms of the radii of the two outer circles by
  $$\frac{1}{\sqrt{r_{mid}}} = \frac{1}{\sqrt{r_1}} + \frac{1}{\sqrt{r_2}}$$ Let's see why the relationship holds. Let $(x_{mid}, y_{mid})$ denote the center of the middle circle. Let, let $(x_1, y_1)$ and $(x_2, y_2)$ be the centers of the outer circles, with radii equal to $r_1$ and $r_2$. Draw three right triangles: $\triangle_1$ with vertices $(x_1, y_1)$, $(x_{mid}, y_{mid})$, and $(x_1, y_{mid})$, $\triangle_2$ with vertices $(x_2, y_2)$, $(x_{mid}, y_{mid})$, and $(x_2, y_{mid})$, and $\triangle_3$ with vertices $(x_1, y_1)$, $(x_2, y_2)$, and $(x_1, y_2)$. The hypotenuse of each triangle is the sum of the radii of the two circles involved. Furthermore, one leg equals the difference of the larger radius from the smaller. Thus, the length of the third leg equals twice the square root of the product of the radii involved. (Draw a picture here, use Pythagorean's Theorem) Furthermore, the sum of the lengths of the third leg of $\triangle_1$ and $\triangle_2$ equal the length of the the third leg of $\triangle_3$. Formally, $$\begin{align*}
(r_1 + r_{mid})^2 &= leg(\triangle_1)^2 + (r_1 - r_{mid})^2 \\
(r_2 + r_{mid})^2 &= leg(\triangle_2)^2 + (r_2 - r_{mid})^2 \\
(r_1 + r_2)^2 &= leg(\triangle_3)^2 + (r_1 - r_2)^2 \\
leg(\triangle_1) + leg(\triangle_2) &= leg(\triangle_3) \\
&\implies \\
\sqrt{(r_1 + r_{mid})^2 - (r_1 - r_{mid})^2} &+ \sqrt{(r_2 + r_{mid})^2 - (r_2 - r_{mid})^2} \\
&= \sqrt{(r_1 + r_2)^2 - (r_1 - r_2)^2} \\
&\implies \\
2\sqrt{r_1r_{mid}} + 2\sqrt{r_2r_{mid}} &= 2\sqrt{r_1r_2} \\
&\implies \\
\frac{1}{\sqrt{r_1}} + \frac{1}{\sqrt{r_2}} &= \frac{1}{\sqrt{r_{mid}}}
\end{align*}$$ Now let's focus on the sequence of circles descending to the left. Let $R : \{1, 2, 3, ... \} \rightarrow \mathbb{R}$ define the radius of the $n^{th}$ circle, where we start with the left circle of radius one, then move to the red circle, then left to the green circle, then to the orange, etc. $$\begin{align*}
 R(1) &= 1 \\
 \frac{1}{\sqrt{R(n)}} &= \dfrac{1}{\sqrt{R(n-1)}} + 1
 \end{align*}$$
  Notice that we can make the following substitution: 
  $$T(n) = \frac{1}{\sqrt{R(n)}}$$
  Then $T(n) = T(n-1) + 1$, with $T(1) = 1$, so $T(n) = n$. Solving for $R(n)$ gives us $$R(n) = \dfrac{1}{n^2}$$ Thus each circle has area $\pi n^{-4}$. So the total area of the nested circles touching the horizontal line is
  $$\pi\left(2^{-4} + 2\sum_{k=3}^{\infty} k^{-4}\right)$$ Now, you can use rigorous elementary methods, the Riemann zeta function, or WolframAlpha to compute
  $$\sum_{k=1}^{\infty} k^{-4} = \frac{\pi^4}{90}$$
  So, 
  $$\sum_{k=3}^{\infty} k^{-4} = \frac{\pi^4}{90} - \frac{17}{16}$$
  and so the total area of the circles touching the horizontal axis is
  $$\pi\left(\frac{\pi^4}{45} - \frac{33}{16}\right)$$","['geometry', 'sangaku', 'recurrence-relations']"
878457,Is there a way to calculate the area of this intersection of four disks without using an integral?,Is there anyway to calculate this area without using integral ?,['geometry']
878472,Show that two spaces are not homeomorphic,"Let $H=[-1,1]\times \{0\}$ and $V=\{0\}\times [-1,0)$ in the plane. Let $T=H \cup V$. Show that $T$ is not homeomorphic to the unit interval $I=[0,1]$. My idea for this problem is that , if we remove a point from the unit interval , we will be left with at most two connected components, but if we remove the origin from $T$ we will be left with $3$ connected components. Is this enough to prove that $I$ and $T$ are not homeomorphic ? How should I write my answer rigirously? Any help is appreciated, Thanks !",['general-topology']
878477,A closed form of $\sum_{k=1}^\infty\frac{(-1)^{k+1}}{k!}\Gamma^2\left(\frac{k}{2}\right)$,"I am looking for a closed form of the following series \begin{equation}
\mathcal{I}=\sum_{k=1}^\infty\frac{(-1)^{k+1}}{k!}\Gamma^2\left(\frac{k}{2}\right)
\end{equation} I have no idea how to answer this question. Wolfram Alpha gives me result: $$\mathcal{I}\approx2.7415567780803776$$ Could anyone here please help me to obtain the closed form of the series preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","['sequences-and-series', 'calculus', 'factorial', 'gamma-function', 'summation']"
878479,Can an inflection exist if there's no max/min?,"Very quick question: if a function doesn't have a maximum nor minimum, can it still have a point of inflection? I believe that these two go hand in hand and without one you can't have the other but I just want to verify.","['calculus', 'derivatives']"
