question_id,title,body,tags
476063,Ring structure of the units of order $2$ in a monogenic order?,"A wise man once told me the following: Let $f\in\mathbb{Z}[X]$ be monic and let $R=\mathbb{Z}[X]/(f)$, so
  that $(R,+,\times)$ is a ring. Let $$U=\{u\in R\mid u^2=1\}.$$ Then
   $(U,\times,\star)$ is a ring, with multiplication satisfying
  $$u\star v=w\star x\quad\Leftrightarrow\quad\ (1-u)(1-v)=(1-w)(1-x).$$ I haven't the faintest clue how $\star$ could be defined. Any ideas?","['ring-theory', 'abstract-algebra']"
476072,Continuous differentiability implies Lipschitz continuity,"Here's a statement in Zygmund's Measure and Integral on page 17: If $f$ has a continuous derivative on $[a,b]$, then (by the mean-value theorem) $f$ satisfies a Lipschitz condition on $[a,b]$. This does not seem obvious to me. How can I show it? Also, what does a continuous derivative imply? Can we conclude the function is differentiable? If so, how can I prove it?","['lipschitz-functions', 'continuity', 'derivatives', 'real-analysis']"
476076,The purpose of the $\sf ZFC$ Axiom of Infinity,"The purpose of the $\sf ZFC$ Axiom of Infinity seems to me to have no other purpose than to provide a set from which the natural numbers can be extracted. Is this correct? If so, do other $\sf ZFC$ axioms, e.g. Pairing, likewise have no other purpose than to enable this extraction process?",['elementary-set-theory']
476087,Sum of N i.i.d. random variables,"Suppose I have a random variable $X_i$ with pdf $$X_i = \begin{cases}1 & P(X_i=1)=p\\-1 & P(X_i=-1)=q\\0 & P(X_i=0)=1-p-q\end{cases}$$ What is the pdf of sum of $N$ such i.i.d. random variables, i.e. $$X = X_1+X_2+\dots+X_N$$",['probability']
476098,Compute $\sum_{j=1}^k\cos^n(j\pi/k)\sin(nj\pi/k)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Compute the series $\sum_{j=1}^k\cos^n(j\pi/k)\sin(nj\pi/k)$ Hint: the answer is in fact 0","['sequences-and-series', 'contest-math', 'trigonometry', 'analysis', 'trigonometric-series']"
476114,"Probability of n balls in n cells, one remaining empty","Counting problems have always intrigued me, and I'm working on some out of interest. The other thread on this topic had unsatisfactory answers, because they don't match the answer in my book. My question is: If $n$ balls are placed at random into $n$ cells, find the probability that exactly one cell remains empty. My book gives $\binom{n}{2} \frac{n!}{n^n}$ . But I'm not sure which answer is right?",['combinatorics']
476124,Computig the series $\sum\limits_{n=2}^\infty \ln\left(1-\frac{1}{n^2}\right)$,"So I have this problem for midterm reviews: $$\sum_{n=2}^\infty \ln\left(1-\frac{1}{n^2}\right)=\text{ ?}$$ I know that you can find the series form of a natural log, as shown here: $$\ln\left(1-\frac{1}{n^2}\right)=-\sum_{k=2}^\infty \left(\frac{1}{n^{4k}}\right)\left(\frac{1}{2k}\right) $$ But the above doesn't seem to help very much since it results in two summation notations mushed together. Is there a somewhat nontedious way to go about this? Thanks! All help appreciated.","['sequences-and-series', 'summation', 'calculus', 'real-analysis']"
476129,Kähler differentials of a hyperelliptic curve.,"Let $f:X \rightarrow \mathbb{P}^1_k$ be a hyperelliptic curve, where k is a field of characteristic not 2. $\mathbb{P}^1_k$ is the union of $U = Spec k[t]$ and $V = Spec k[s]$ where $s= 1/t$. This gives us $f^{-1}(V) \cup f^{-1}(U) = X$. On pg. 292 of Liu's book,  Liu does the following: He shows that $U' = Spec k[t,y]/(y^2-P(t)$ where $P(t)$ has no square factors, and that  $V' = Spec k[s,Z]$ where $P_1(s) = P(1/s)s^{2r}$, where $r = [(deg(P(s)+1)/2]$ and $P_1(s)$ is what we get by restricting (this is just the standard affine opens of the hyperelliptic curve. He shows that $\Omega^1_{U'/U} = k[t]/(P(t))$ and $\Omega^1_{V'/V} = k[t]/(P_1(t))$. All is clear so far, but here is my problem. He then writes: ""As $\mathbb{P}^1_k = U \cup \{s=0\}$, we have $$H^0(X,\Omega^1_{X/\mathbb{P}^1_k}) = k[t]/(P(t)) \oplus k[s]_m /P_1(s)$$ $m = sk[s]$."" Now, my question is:
Why does this hold on global sections? I thought the standard approach was just to calculate on the two affine opens and check that they coincide on intersections? Edit:
Maybe I should use the adjunction formula? But I can't see how really.",['algebraic-geometry']
476131,Does $a^6+b^6 = c^6+d^3$ have a non-trivial solution?,"It is conjectured that, $$x_1^8+x_2^8+x_3^8 = y_1^8+y_2^8+y_3^8\tag{1}$$ has no non-trivial solutions. However, if we relax it a bit, then, $$x_1^8+x_2^8+x_3^4 = y_1^8+y_2^8+y_3^4\tag{2}$$ can be shown to have an infinite number of primitive solutions such as, $$86^8+149^8+14805^4=35^8+142^8+18939^4$$ Likewise, it is conjectured that, $$x_1^6+x_2^6 = y_1^6+y_2^6\tag{3}$$ is only trivially solvable. However, $$x_1^6+x_2^3 = y_1^6+y_2^3\tag{4}$$ also has an infinite number of solutions, such as, $$5^6+167^3 = 8^6+164^3$$ Question: Can we relax $(3)$ even further? Is $$a^6+b^6 = c^6+d^3\tag{5}$$ non-trivially solvable?","['diophantine-equations', 'number-theory']"
476159,Limits of sequences of sets,"I am starting to learn about the liminf and limsup of a sequence of sets. However, I do not understand the very basics, such as why $\lim\sup A_n=\bigcap_{n\in N}\bigcup_{k>n} A_k,$ and why $\lim\sup A_n=\bigcup_{n\in N}\bigcap_{k>n}A_k.$ Can someone break these definitions down for me? Also, why is $\lim\inf\subseteq\lim\sup$?","['measure-theory', 'real-analysis']"
476167,For what real $r$ does $\sum_{n=2}^\infty\frac1{n(\ln n)^{1+ir}}$ converge and for which $r$ does the sum diverge?,"A standard convergence result is that
$\sum_{n=2}^\infty\frac1{n(\ln n)^p}$
converges for real
$p > 1$
and diverges for
$p \le 1$. How about complex $p$
with real part $1$? Specifically,
for what real $r$
does
$\sum_{n=2}^\infty\frac1{n(\ln n)^{1+ir}}$
converge and for which $r$ does the sum diverge? How about the usual series of sums
$\sum_{n=e_2}^\infty\frac1{n(\ln n)(\ln  \ln n)^{1+ir}}$
, ...,
$\sum_{n=e_k}^\infty\frac1{n(\ln n)(\ln \ln n)...(\ln ...  \ln n)^{1+ir}}$,
where $e_k$ is large enough so that
the iterated $\ln$s all are positive? I have not made any progress on this question
because of my lack of knowledge
of complex analysis. However, I guess that
the cases when
$r = \pi s$ with
$s$ rational and irrational
might have significantly different answers.","['convergence-divergence', 'sequences-and-series', 'complex-analysis']"
476179,Tensor Product of Submodules,"In Keith Conrad's text on Tensor Products , he states on Page 8 of the text that for a fixed ring $R$ and $R$ -modules $M$ , $M'$ , $N$ and $N'$ , and maps $f:M\to M'$ , $g:N\to N'$ that $\text{ker}(f)\otimes_R N$ , strictly speaking is not a submodule of $M\otimes_R N$ (and similarly for $M\otimes_R\text{ker}(g)$ ). The question that I have in mind is: Given a fixed ring $R$ and $R$ -modules $M$ , $N$ with submodules $M'$ and $N'$ respectively, with respective inclusion maps $i:M'\to M$ and $j:N'\to N$ , is it possible for (1) $M'\otimes_R N'$ to not be a submodule of $M\otimes_R N$ , and (2) $i\otimes j$ to be not injective?","['modules', 'tensor-products', 'abstract-algebra']"
476183,"Find a Möbius transformation which maps the region $|z| > 1$, $\Im z > 0$ onto the first quadrant of the complex plane.","a) Find a Möbius transformation which maps the region $|z| > 1$, $\Im z > 0$ onto the first quadrant of the complex plane. b) Find all Möbius transformations satisfying the above requirement. I know how to find Möbius transformations in general, using the cross-ratio, but in this case I don't even know how to start. Any input is appreciated! I am studying for an exam in complex analysis.",['complex-analysis']
476189,Iterative roots of sine,"Is there an analytical function $f(z)$ such that $f(f(z)) = \sin(z)$? More generally, an analytical function such that f applied $n$ times to $z$ gives $\sin(z)$? Is there a general theory for answering this question for functions besides $\sin(z)$?","['complex-analysis', 'functional-equations']"
476192,Number of possibilities of $10\times10$ matrix,"If $A$ is a $10\times10$ matrix with entries from the set $\{0, 1, 2, 3\}$ and if $AA^T$ is of the form:
  $$\begin{pmatrix}
0 & * & * & \cdots & * \\
* & 0 & * & \cdots & * \\
* & * & 0 & \cdots & * \\
\vdots & \vdots & \vdots & \cdots & \vdots \\
* & * & * & \cdots & 0
\end{pmatrix}$$ Then the number of such matrices $A$ is: A) $(4^3)^{10}$ B)$(4^2)^{10}$ C)$4^{10}$ D) $1$ Since all the diagonal elements of $AA^T$ is zero I could realize that it is a skew-symmetric matrix. But, I'm no able to understand how I can use this result for finding the possibilities of the original matrix. I would like hints rather than answers.","['matrices', 'linear-algebra']"
476195,Infinitely differentiable functions: how to prove that $e^\frac{1}{x^2-1}$ has derivative of any order?,"Let $f:\Bbb{R}\to\Bbb{R}$ be a function given by $$f(x)=\begin{cases}
\exp\left(\frac{1}{x^2-1}\right) & \text{if }\vert x\vert\lt 1\\ 
0 & \text{if }\vert x\vert\geqslant 1 
\end{cases}$$ I would like to prove that $f\in C^\infty$ , that is, $f\in C^k$ for all $k\in \mathbb{N}$ . I think that it can be done by induction on $k$ . If $\vert x\vert\gt1$ , the problem is trivial. On other points, the base case is the simplest and the only that I'm be able to do. Can someone help me? Thanks.","['induction', 'derivatives', 'real-analysis']"
476217,Closure of interior of closed set,"If $D$ is a closed set, what is the relation in general between the set $D$ and the closure of $\operatorname{Int}D$? We know that $\operatorname{Int}D\subseteq D$, so $\overline{\operatorname{Int}D}\subseteq \overline{D}$, but since $D$ is closed, we have $\overline{D}=D$, so that $\overline{\operatorname{Int}D}\subseteq D$. Now, is it true as well that $D\subseteq \overline{\operatorname{Int}D}$? I can't seem to prove it, or give an example of $D$ such that this doesn't hold.",['general-topology']
476218,Prove $X^2+Y^2-1$ is irreducible using geometrical tools.,"I'm trying to understand what is meant in this paragraph:
 of ""Conics and Cubics. A Concrete Introduction to Algebraic Curves (by Robert Byx)"": He wants to prove that the polynomial $X^2+Y^2-1$ is irreducible using geometrical  tools. I have the following doubts: What he means by Since every line has at least three points on it ? Why the fact that $X^2+Y^2-1=F(X,Y)\cdot G(X,Y)$, where F, G are lines implies that the circle $X^2+Y^2-1=0$ is made up of two lines? I would really grateful if anyone could help me.","['algebraic-geometry', 'irreducible-polynomials', 'algebraic-curves']"
476243,geometric problem solved with Pigeon Hole Principle,"The problem is: Show that among any 5 points in a equilateral triangle of unit side length, there are 2 whose distance is at most 1/2 units apart.","['pigeonhole-principle', 'combinatorics']"
476279,Showing $|\sum_{k=1}^n\frac{\sin(kx)}k|<2\sqrt{\pi}$,"For any real $x$ and positive integer $n$, is it true that: $$\left|\sum_{k=1}^n\frac{\sin(kx)}k\right|<2\sqrt{\pi}\quad ?$$ Please justify.","['inequality', 'sequences-and-series', 'trigonometry', 'summation', 'trigonometric-series']"
476281,Stone-Čech compactification of a discrete space,I would like to know: Why is the Stone-Čech compactification of a discrete space the set of ultrafilters on that space?,"['general-topology', 'filters', 'compactness']"
476289,every non-principal ultrafilter contains a cofinite filter.,"I have several questions regarding filters and ultrafilters: (a) Does every non-principal ultrafilter contain a cofinite filter? Why? (b) What is the difference between a Fréchet filter and a cofinite filter? (c) Can we say ""an ultrafilter is free iff it contains a Fréchet filter""? Why?","['general-topology', 'filters']"
476301,How to compute $I(d\omega)$? (Poincaré's Lemma),"Suppose I have an $\ell$-form in $\Bbb R^n$ $$\omega=\sum_{i_1<\cdots<i_\ell}\omega_{i_1\cdots i_\ell} dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}$$ I will say this is written in the canonical form. Having written it canonically, define $I\omega$ to be the $\ell-1$ form that sends $x\in\Bbb R^n$ to $$I\omega(x)=\sum_{i_1<\cdots<i_\ell}\sum_{\alpha=1}^\ell (-1)^{\alpha-1}\int_0^1t^{\ell-1} \omega_{i_1\cdots i_\ell}(tx)dt \; x_{i_\alpha}\,\cdot dx_{i_1}\wedge\cdots \wedge \widehat{dx_{i_\alpha}}\wedge \cdots\wedge dx_{i_\ell}$$ where the hat means the term is ommited. We can denote this by $dx_{I,\alpha}$ for brevity. By linearity, we can focus on the basic forms $$\omega=f \;\cdot  dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}\;\;;\;\;i_1<\cdots <i_\ell$$ Again, in this case we will say this is written canonically. For brevity, will denote by $dx_I$ the full, ordered wedge product $dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}$. In this case $$I\omega(x)=\sum_{\alpha=1}^\ell (-1)^{\alpha-1}\int_0^1 t^{\ell-1} f(tx) dt\; x_{i_\alpha} \cdot dx_{I,\alpha}$$ Now, when we take the derivative of this, we get two parts by the product rule. First, $$\tag 1 \sum\limits_{\alpha  = 1}^\ell (-1)^{\alpha-1} {\int_0^1 {{t^{\ell  - 1}}} f\left( {tx} \right)dt\;\cdot d{x_{{i_\alpha }}} \wedge dx_{I,\alpha}}\\  = \int_0^1 {\ell {t^{\ell  - 1}}} f\left( {tx} \right)dt \cdot dx_I$$ since we move the form $dx_{i_\alpha}$, $\alpha-1$ places, filling the gap. While on the other hand we get $$\sum\limits_{\alpha  = 1}^\ell  {{{\left( { - 1} \right)}^{\alpha  - 1}}\sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt}\, {x_{{i_\alpha }}}\;\cdot dx_j\wedge dx_{I,\alpha}} $$ Now, consider the $\ell+1$ form $$d\omega  = \sum\limits_{j = 1}^n {{D_j}f} \;\cdot d{x_j} \wedge d{x_{{i_1}}} \wedge  \cdots  \wedge d{x_{{i_\ell }}}$$ This is not written canonically, but nevertheless we would like to find $I(d\omega)$. I should be getting that this is $$I(d\omega )\left( x \right) = \sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt}  {x_j}\cdot d{x_I} - \sum\limits_{\alpha  = 1}^\ell  {{{\left( { - 1} \right)}^{\alpha  - 1}}\sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt} x_{i_\alpha }\;\cdot  d{x_j} \wedge d{x_{I,\alpha }}} $$","['differential-forms', 'differential-geometry']"
476342,The integer $c_n$ in $(1+4\sqrt[3]2-4\sqrt[3]4)^n=a_n+b_n\sqrt[3]2+c_n\sqrt[3]4$,"For non-negative integer $n$, write $$(1+4\sqrt[3]2-4\sqrt[3]4)^n=a_n+b_n\sqrt[3]2+c_n\sqrt[3]4$$ where $a_n,b_n,c_n$ are integers. For any non-negative integer $m$, prove or disprove $$2^{m+2}|c_n\iff2^m|n$$ So far I have
 $$\left[\begin{array}{c}a_n\\b_n\\c_n\end{array}\right]=\left[\begin{array}{ccc}1&-8&8\\4&1&-8\\-4&4&1\end{array}\right]\left[\begin{array}{c}a_{n-1}\\b_{n-1}\\c_{n-1}\end{array}\right].$$","['recurrence-relations', 'contest-math', 'number-theory', 'elementary-number-theory', 'linear-algebra']"
476354,Evaluating $\sum\limits_{k=1}^{\infty}\frac1{(3k+1)(3k+2)}$ [duplicate],This question already has answers here : Showing $ \sum_{n=0}^{\infty} \frac{1}{(3n+1)(3n+2)}=\frac{\pi}{3\sqrt{3}}$ (7 answers) Closed 9 years ago . What is the value of $\displaystyle\sum_{k=1}^{\infty}\frac1{(3k+1)(3k+2)}$?,['sequences-and-series']
476359,Reference request: Homomorphism sheaf is quasi-coherent,"If $X$ is a scheme and $M,N$ are $\mathcal{O}_X$-modules, then we can consider the $\mathcal{O}_X$-module $\underline{\hom}(M,N)$. I would like to have a reference for the following easy and well-known observation: If $M$ is of finite presentation and $N$ is quasi-coherent, then $\underline{\hom}(M,N)$ is quasi-coherent. (Proof: We may work locally and therefore assume that there is an exact sequence $\mathcal{O}^p \to \mathcal{O}^q \to M \to 0$. Using $\underline{\hom}(\mathcal{O}^q,N)=N^q$, we get an exact sequence $0 \to \underline{\hom}(M,N) \to N^q \to N^p$. Since quasi-coherent modules are closed under direct sums and kernels, the claim follows) I couldn't find it in the usual books (EGA, Görtz-Wedhorn, Liu, Bosch, Stacks Project). For locally noetherian schemes this is Exercise 5.1.6.(a) in Liu's book. I ask because I want to use this result in a paper and don't want to waste any time with it.","['algebraic-geometry', 'reference-request']"
476369,Trigonometric Identities for $\sin nx$ and $\cos nx $,"These are generalizations of simple trigonometric identities for $\sin 2x$ and $\cos 2x$, but in general how can we prove them? 
$$\sin nx =\sum_{k=1}^{\left\lceil\frac{n}{2}\right\rceil}(-1)^{k-1}\binom{n}{2k-1}\sin^{2k-1}x\cos^{n-2k+1}x,$$
$$\cos nx =\sum_{k=0}^{\left\lfloor\frac{n}{2}\right\rfloor}(-1)^{k}\binom{n}{2k}\sin^{2k}x\cos^{n-2k}x,$$
$$\sin nx =\sin x\left(\sum_{k=1}^{\left\lceil\frac n 2\right\rceil}(-1)^{k-1}\binom{n-k}{k-1}(2\cos x)^{n-2k+1}\right),$$
$$\cos nx =\cos x\left((2\cos x)^{n-1}+\sum_{k=1}^{\left\lfloor\frac n 2\right\rfloor}\frac n k(-1)^k\binom{n-k-1}{k-1}(2\cos x)^{n-2k-1}\right).$$","['algebra-precalculus', 'chebyshev-polynomials', 'trigonometry', 'real-analysis', 'complex-analysis']"
476375,"Solve $(a^2-1)(b^2-1)=\frac{1}4 ,a,b\in \mathbb Q$","Does the equation $(a^2-1)(b^2-1)=\dfrac{1}4$ have solutions $a,b\in \mathbb Q$? I search $0<p<1000,0<q<1000$, where $a=\dfrac{p}q$, but  no solutions exist. I wonder  is this equation solvable?","['diophantine-equations', 'number-theory']"
476383,Does There exist a continuous bijection $\mathbb{Q}\to \mathbb{Q}\times \mathbb{Q}$?,Does there exist a continuous bijection $\mathbb{Q}\to \mathbb{Q}\times \mathbb{Q}$? I am not able to find out how to proceed.,"['general-topology', 'examples-counterexamples', 'real-analysis']"
476399,How does one show that $(n-1)!\cos(n!x)$ diverges everywhere?,"In particular, how does one show divergence at points for which the fractional part of $n!x$ tends to $\frac{1}{2}$ as $n\to\infty$, such as $x=\frac{1}{2}\sum\frac{1}{(2k)!}$?
(This is an oft-cited example of a sequence of functions which are derivatives of everywhere uniformly convergent functions, but which converge nowhere.)","['sequences-and-series', 'real-analysis']"
476400,"How does the gradient of a function show greatest slope for a function $f(x,y,z)$?","$$\nabla f(x,y,z)=\frac{\partial f}{\partial x}\mathbf{i}+\frac{\partial f}{\partial y}\mathbf{j}+\frac{\partial f}{\partial z}\mathbf{k}$$ $\nabla$ is the gradient operator. $(\nabla f).\mathbf{r}$ is the rate of change of $f$ in the $\mathbf{r}$ direction. I have to prove that a scalar multiple of $\frac{\partial f}{\partial x}+\frac{\partial f}{\partial y}+\frac{\partial f}{\partial z}$ is the fastest rate of change of $f$ at any point. Let $r$ be the unit vector $(a,b,c)$. $$a^2+b^2+c^2=1$$ $(\nabla f).\mathbf{r}=a.\frac{\partial f}{\partial x}+b\frac{\partial f}{\partial y}+c\frac{\partial f}{\partial z}$ How do we know this is maximized when $a=b=c$?",['multivariable-calculus']
476401,"Residue theorem, $\int_{-\infty}^{\infty} e^{-ikx}(1-ika^2)^{-m} dk$ with integer $m$","I am trying to solve this integral $\int e^{-ikx}(1-ika^2)^{-m} dk$ using the residue theorem, but I cannot find the residue of the function.
 $$\frac{1}{(1-ika^2)^{-m}}=\sum (ika^2)^n(-1)^n \binom{-m}{n}$$ But there is not any term of the form $(1-ika^2)$ in the serie expansion. Thank you so much if someone can tell me how to proceed.","['residue-calculus', 'fourier-analysis', 'integration', 'complex-analysis']"
476412,Determinant of a $2 \times 2$ block matrix,"$\textbf{Problem}$: Let a $2n \times 2n$ matrix be given in the form $M=\left[ {\begin{array}{cc} 
             A & B \\
             C & D \\
                \end{array} } \right]$, where each block is an $n \times n$ matrix. Suppose that $A$ is invertible and that $AC=CA$. Use block multiplication to prove that $\det M= \det(AD-CB)$. Give an example to show that this formula need not hold if $AC \neq CA$ $\textbf{Proof}$: Let $A,B,C,D,X \in \textbf{M}_n(K)$ such that $A+BX$ is invertible.
For all $Y \in \textbf{M}_n(K)$, we have: $$\left[ {\begin{array}{cc}
             I_n & 0 \\
             Y & I_n \\
                \end{array} } \right] \left[ {\begin{array}{cc}
             A & B \\
             C & D \\
                \end{array} } \right] \left[ {\begin{array}{cc}
             I_n & 0 \\
             X & I_n \\
                \end{array} } \right]= \left[ {\begin{array}{cc}
             A+BX & B \\
             YA+C+(YB+D)X & YB+D \\
                \end{array} } \right].$$ Let $Y=-(C+DX)(A+BX)^{-1}$. Hence: $$YA+C+(YB+D)X=Y(A+BX)+(C+DX)=0.$$ Since $\det\left[ {\begin{array}{cc}
             I_n & 0 \\
             Y & I_n \\
                \end{array} } \right]= \det\left[ {\begin{array}{cc}
             I_n & 0 \\
             X & I_n \\
                \end{array} } \right]= (\det(I_n))^2=1$, we can conclude that: \begin{align*}
\det\left[ {\begin{array}{cc}
             A & B \\
             C & D \\
                \end{array} } \right]&=\det\left[ {\begin{array}{cc}
             A+BX & B \\
             0 & YB+D \\
                \end{array} } \right]\\
&= \det(A+BX)\det(-(C+DX)(A+BX)^{-1}B+D).
\end{align*} In particular for $X=0$, we have: \begin{align*}
\det\left[ {\begin{array}{cc}
             A & B \\
             C & D \\
                \end{array} } \right]&=\det(A)\det(-CA^{-1}B+D)=\det(-ACA^{-1}B+AD) \\
&=\det(-CAA^{-1}B+AD)=\det(AD-CB).
\end{align*} I just wanted someone to verify my proof and help me with the second part of this question. Thank you in advance","['matrices', 'block-matrices', 'solution-verification']"
476415,Benefits from using the uniform structure of compact Hausdorff spaces,"It is well known that every compact Hausdorff space admits a unique (necessarily complete) uniform structure which is compatible with the topology, and every continuous function from such a space to a uniform space is uniformly continuous. Are there situations in the general theory of compact Hausdorff spaces where it is beneficial to use the theory of uniform spaces? I can imagine, it might be helpful to prove the existence of certain points by using the convergence of arbitrary Cauchy filters/nets. One direct application I can think of is, that for compact Hausdorff spaces $X,Y$ and a dense subset $A \subseteq X$ any uniformly continuous map $f : A \to Y$ (w.r.t. to the subspace uniformity on $A$) can be uniquely extended by continuity to a map $\overline{f} : X \to Y$. By characterizing the uniformly continuous maps from $A$ in terms of the topology on $X$ one may obtain an interesting (probably well known) extension result.","['general-topology', 'compactness', 'uniform-spaces']"
476492,Value of $\sum_{n=0}^{\infty} \frac{(-1)^n}{\ln(n+2)}$,"While testing implementations of Wynn's $\epsilon$-algorithm and Levin's u-transformation I need the value of 
$$\sum_{n=0}^{\infty} \frac{(-1)^n}{\ln(n+2)} \cdot$$
The results of my algorithms are in agreement with the Pari/GP sumalt value 
of $0.92429989722293885595957$. But Wolfram Alpha gives the following approximated sum when entering sum (-1)^n/(ln(n+2)) (a direct link from Math.SE will be mangled and does not work, here is the eq.): $$\sum_{n=0}^{\infty}\dfrac{(-1)^n}{\log(2+n)}\approx1.00766524110155\ldots$$ Questions: Are the values from Pari and my algorithms correct? Is there a closed form analytical result?","['summation', 'sequences-and-series', 'convergence-acceleration']"
476508,Is the pre-image of a subgroup under a homomorphism a group?,"Let $(G, +)$ and $(H, \circ)$ be groups, $U$ a subgroup of $H$ and $\varphi: G \rightarrow H$ be a group homomorphism, i.e. 
$$\forall a, b \in G: \varphi(a+b) = \varphi(a) \circ \varphi(b)$$ Is the pre-image $\varphi^{-1}(U) = \{g \in G: \varphi(g) \in U\}$ also a group? My try $e_G \in \varphi^{-1}(U)$, because $\varphi(e_G) = e_H$ and $e_H \in U$. Let $a, b \in \varphi^{-1}(U)$. Then $\exists x, y \in U: \varphi(a) = x$ and $\varphi(b) = y$. As $U$ is a group, $x \circ y \in U$. As $\varphi$ is a group homomorphism, $\underbrace{\varphi(a)}_x \circ \underbrace{\varphi(b)}_y = \varphi(a + b) \in U \Leftrightarrow (a+b) \in \varphi^{-1}(U)$. But I still need to show: $\forall x \in \varphi^{-1}(U) \exists x^{-1} \in U: x \cdot x^{-1} = x^{-1} \cdot x = e_G$ How can I show this?","['group-theory', 'abstract-algebra']"
476514,Convergence of sum of sequences and product of sequences implies convergence sum of sqares of sequences.,"Prove or falsify: If the following limits exist:
$$\lim_{n\to\infty}(a_n+b_n)$$
$$\lim_{n\to\infty}(a_n\cdot b_n)$$
Then the following limit exists:
$$\lim_{n\to\infty}({a_n}^2+{b_n}^2)$$ Solution attempt:
$$\lim_{n\to\infty}{{a_n}^2+{b_n}^2}=\lim_{n\to\infty}{{(a_n+b_n)}^2-2a_nb_n}=\lim_{n\to\infty}{a_n+b_n}\cdot\lim_{n\to\infty}{a_n+b_n}-2\lim_{n\to\infty}{a_nb_n}$$
So it converges too?","['calculus', 'limits']"
476535,Blow up commute with base change,"Let $X$ be an irreducible Noetherian scheme and $X_{red}$ be the reduced subscheme associated to it. This induces a natural morphism from $X_{red}$ to $X$. Fix a point $p$ in $X$ (by a point we mean an irreducible zero dimensional closed subscheme of $X$, so can be non-reduced). Denote by $Bl_pX$ the blow up of $X$ along $p$ in the sense stated in Chapter II.$7$ of ""Algebraic Geometry"" by Hartshorne. Is it true that the pull-back $Bl_pX \times_X X_{red}$ is the blow up of $X_{red}$ at $p_{red}$?","['blowup', 'algebraic-geometry']"
476554,A tighter bound than Markov Inequality,"Is there any way to find a tighter bound than Markov inequality?
For example, I know that if always $X>b>0$, we can define $Y=X-b$ and have a tighter bound. Is there any similar solution that uses/applies a restriction on the random variable for example their independence or other moments?",['probability-theory']
476565,$S\subseteq T$ implies $\inf T\leq\inf S\leq\sup S\leq \sup T$,Let $S$ and $T$ be nonempty bounded subsets of $\mathbb{R}$ with $S\subseteq T$. How do I prove that $\inf T\leq\inf S\leq\sup S\leq \sup T$?,"['inequality', 'calculus']"
476568,Does a logarithmic branch point imply logarithmic behavior?,"The complex logarithm $L(z)$ is given by $$L(z)=\ln(r)+i\theta$$ where $z=re^{i\theta}$ and $\ln(x)$ is the real natural logarithm. It is well known that $L(z)$ then sends each $z$ to infinitely many values, each of which are different by an integer multiple of $2\pi i$. If we imagine going along the unit circle in the $z$-plane starting from $1$ and working anti-clockwise, the image of it under $L(z)$ will be a segment of the vertical line $i\theta$ with $\theta$ a real number. However we clearly see how $1$ has mapped to $2$ different values, and how we could continue on mapping it to infinitely many values by winding around $0$ indefinitely. We then call $0$ a Logarithmic branch point of the mapping. My question is, do there exist mappings that have logarithmic branch points that themselves have nothing to do with logarithms i.e. the logarithm does not appear explicitly somewhere in it's definition or it does not behave like a logarithm. Does a logarithmic branch point indicate logarithmic behavior?","['logarithms', 'complex-analysis']"
476582,Characteristic map of a n-cell in a CW complex,"I have a problem in understanding the purpose of the definition of a CW complex. What really would help me is to understand the following: 
Let $\sigma$ be a n-cell and $\Phi_\sigma:\mathbb D^n \to X$ be the characteristic map. Is there any relation between $\Phi_\sigma(\mathbb S^{n-1})$ and $\partial \sigma$ following directly from the Definition? I know, for example, that $\Phi_\sigma(\mathbb S^{n-1})\subset X^{n-1}$, $X^{n-1}$ being the $(n-1)$-Skeleton, but what does this tell me about the boundary of $\sigma$?","['general-topology', 'algebraic-topology', 'cw-complexes']"
476585,$AX = 0$ and $BX = 0 $ implies A and B are row equivalent,"I'm trying to prove that if the systems $AX = 0$ and $BX=0$ are equivalent, then the matrices $A$ and $B$ are row equivalent. Proving the converse was very simple, but this one seems harder. I saw a few answers to similar questions posted here before, but they were done using some higher level concepts which I am unaware  of right now (such as orthogonal subspaces etc.). I am familiar with the concepts of linear equations, ranks of matrices, and the basic idea of subspaces(only, definition, dimension, basis etc.) Any help would be appreciated.........",['linear-algebra']
476607,Historical meaning and usage of determinant,"Can anyone please explain how, why, and where determinants were developed/formalized? What was their historical usage? Why were they initially formulated and what were they used for (and later generalized for)? I'm asking because I'm trying to truly understand the meaning of the determinant. I somewhat understand that it represents the distortion of volume of a region represented by a matrix after its transformation, but I find it hard to believe that that's the historical representation for it.","['matrices', 'math-history', 'determinant']"
476640,n-simplex in an intersection of n balls,"Consider a $n$-simplex, $n \geq 2$ with vertices $x_i,i=1,...,n+1$. For each edge $(i,j)$, consider $n$-ball $B_{ij}$ such that vertices $x_i$ and $x_j$ are antipodal on this ball. Fix a point $x_0$ in the simplex. The question: is $x_0$ in at least $n$ balls? Some notes. It is impossible to make the question stronger by claiming that there is vertex $i=i(x_0)$ such that $x_0$ is in all balls $B_{ij},j \neq i$. Also, it is not true for $n+1$ balls (there are counterexamples for both cases if $n=3$). Also, $x_0$ is in ball $B_{ij}$ if and only if $\angle x_ix_0x_j \geq \pi/2$, or equivalently, vertices $x_i$ and $x_j$ are on opposite sides of the hyperplane $H_i$ that contains $x_0$ and is orthogonal to the line through $x_i$ and $x_0$ (and similarly for $H_j$). Also, this question is a stronger version of that question (Thanks to Alex Ravsky for solving it). Any help is much appreciated. Thank you.","['geometry', 'convex-analysis', 'combinatorial-geometry']"
476677,"Find 1-1 and onto mapping from {0,1}* to the integers","My idea was to essentially use ordering by the length of the string (and for strings with the same length, order them is ascending order) to map a string to a number, numbers that start with a $0$ go to a negative integer and things that start with $1$ to a positive integer. The idea is that if, say, you need to figure out what $f(01)$ is, then this is what you do. $\epsilon = 0.$$ f(0) = -1.$ $f(1) = 1.$ Now take all the 2 length strings $\,00$, $01$, $10$, $11$. $00$ gets mapped to $-2.$ $f(01) = -3.$ $f(10) = 2$ and $f(11) = 3.$ And so on. HOW TO PROVE THIS IS $1-1$ AND ONTO?",['functions']
476682,Inner Product on Division Algebras,"Here , Wikipedia gives a proof that the only finite dimensional associative division algebras over $\mathbb{R}$ are $\mathbb{R}, \mathbb{C}, \mathbb{H}$. The proof proceeds by taking such a division algebra $D$, observing that multiplication by  $d \in D$ gives an endomorphism of $D$ which can be represented by a matrix corresponding to $d$. Then, we consider $V \subset D$, the subspace of $D$ corresponding to matrices with trace $0$. At some point, an inner product of $V$ given by $\langle a, b \rangle=-ab-ba$ appears. At my current understanding (undergraduate mathematics) this inner product seems mysterious. I can prove that it works but I don't understand why that is a natural choice. Can someone give me some insight? Edit. Is there maybe a way to think about this result using Lie Theory?","['matrices', 'linear-algebra', 'abstract-algebra']"
476684,Infinum & Supremum: An Analysis on Relatedness,"$\require{color}$ Question: I need some help in proving that $\color{green}{\text{if $k\geq 0$, then $\sup (kS) = k\sup(S)$ and $\inf (kS) = k\inf (S)$}}$, and also that $\color{red}{\text{if $k<0$, then $\sup(kS)=k\inf(S)$ and $\inf(kS)=k\sup(S)$}}$. Thoughts: As far as I can tell, $S$ is a non-empty, bounded subset of $\mathbb{R}$, and $kS=\{ks:s\in S\}$, where $k\in \mathbb{R}$, so $kS\subseteq\mathbb{R}$. I suspect that we are working with the ordered set $(\mathbb{R},\leq)$, where, again, $kS\subseteq \mathbb{R}$, so if an element $\alpha\in \mathbb{R}$ is the supremum of $kS$ in $\mathbb{R}$, then $\alpha$ is an upper bound of $kS$ in $\mathbb{R}$, and $\alpha\leq \beta$ for all upper bounds $\beta$ of $kS$ in $\mathbb{R}$, and if and element $\alpha'\in\mathbb{R}$ is the infimum of $kS$ in $\mathbb{R}$, then $\alpha'$ is a lower bound of $kS$ in $\mathbb{R}$, and $\beta'\leq\alpha'$ for all lower bounds $\beta'$ of $kS$ in $\mathbb{R}$. $$\star\star\star\star\star\star\star\star\star\star$$ Here, an upper bound is an element $\gamma\in\mathbb{R}$ such that for all $\zeta\in kS$ we have $\zeta\leq\gamma$. Further, a lower bound in this case is an element $\gamma'$ such that for all $\zeta'\in kS$ we have that $\gamma'\leq \zeta'$. Comment: Please let me know if I have the foundational ideas here down, so I can begin working on this. I want to get it solid. Edit: So it turns out that this problem was pushed to the next homework set, so I get to keep working on it. So far this is what I've got: Consider the case where $k=0$. This means $kS=0S=\{0\}$, and so we have that
$$\sup(kS)=\sup\{0\}=0=0\sup(S)=k\sup(S).$$
Now consider the case where $k>0$. Note that $\sup(kS)$ is the element in $\mathbb{R}$ such that
$\hspace{0.25cm}$(a) $\sup(kS)$ is an upper bound for $kS$, and
$\hspace{0.25cm}$(b) if $\alpha$ is any upper bound for $kS$, then $\sup(kS)\leq \alpha$,
so if is sufficient to show that $k\sup(S)$ is the element in $\mathbb{R}$ such that
$\hspace{0.25cm}$(a') $k\sup(S)$ is an upper bound for $kS$, and
$\hspace{0.25cm}$(b') if $\alpha$ is any upper bound for $kS$, then $k\sup(S)\leq \alpha$,
namely that properties (a) and (b) hold for $\sup(kS)=k\sup(S)$. Thus, if $k\sup(S)$ is an upper bound for $kS$, then there is an $s\in S$ such that $\beta=ks$, where $\beta\in kS$. This would mean $s\leq \sup (S)$ because $\sup(S)$ is an upper bound for $S$, which means $\beta=ks\leq k\sup(S)$, and so $k\sup(S)$ is an upper bound for $kS$, as $\beta$ was arbitrary. Now in order to show that if $\alpha$ is any upper bound for $kS$, then $k\sup(S)\leq \alpha$, first suppose that $\alpha$ is an upper bound for $kS$. If this were the case, then $ks\leq \alpha$ for all $s\in S$, and so $s\leq\frac{\alpha}{k}$ for all $s\in S$, which therefore means that $\frac{\alpha}{k}$ is an upper bound for $S$; hence $\sup(S)\leq\frac{\alpha}{k}$. Multiplication by $k$ on both side of this inequality gives us that $k\sup(S)\leq \alpha$; quod erat demonstrandum . Similarly, to show $\inf(kS)=k\inf(S)$ there are two case to consider, namely $k=0$, and $k>0$. If $k=0$, then $kS=0S=\{0\}$, and so we have that
$$\inf(kS)=\inf\{0\}=0=0\inf(S)=k\inf(S).$$
Suppose now that $k>0$. In this case, just as above, is is sufficient to show that
$\hspace{0.25cm}$(a) $k\inf(S)$ is a lower bound for $kS$, and
$\hspace{0.25cm}$(b) if $\alpha$ is any lower bound for $kS$, then $\alpha\leq k\inf(S)$.
Thus if $k\inf(S)$ is a lower bound for $kS$, then there is an $s\in S$ such that $\beta=ks$, where $\beta\in kS$. Therefore $s\geq\inf(S)$ because $\inf(S)$ is a lower bound for $S$, and so $\beta=ks\leq k\inf(S)$, which means $k\inf(S)$ is a lower bound for $kS$ since $\beta$ was arbitrary. Now to show (b), suppose that $\alpha$ is a lower bound for $kS$. In this case we have that $ks\leq\alpha$ for all $s\in S$, and so $s\leq\frac{\alpha}{k}$ for all $s\in S$; hence $\frac{\alpha}{k} $ is a lower bound for $S$, and so we have that $\inf(S)\leq\frac{\alpha}{k}$. If we multiply by $k$ on both side of this inequality we get that $k\inf(S)\leq \alpha$; quod erat demonstrandum . Comment: $\color{green}{\text{Above}}$ is the essence of the kind of proof I'd like to exhibit for the $\color{red}{\text{second part}}$. I still haven't got the second part, so any help would be appreciated. Note: If you are from UCLA, or anywhere, please don't just copy and paste this as your answer.","['proof-writing', 'elementary-set-theory', 'real-analysis', 'order-theory']"
476689,Baby Rudin Theorem 1.20 (b) Proof,"I have a question about Rudin's proof of Theorem 1.20 (b) in his book Principles of Mathematical Analysis .  Theorem 1.20 is stated as follows: (a) If $x\in R, y\in R$, and $x>0$, then there is a positive integer $n$ such that $$nx>y.$$
  (b) If $x\in R, y\in R$, and $x<y$, then there exists a $p\in Q$ such that $x<p<y$. I understand Rudin's proof of (a).  The beginning of Rudin's proof of (b) is given below: Since $x<y$, we have $y-x>0$, and (a) furnishes a positive integer $n$ such that $$n(y-x)>1.$$  Apply (a) again, to obtain positive integers $m_1$ and $m_2$ such that $m_1>nx$, $m_2>-nx$.  Then $$-m_2<nx<m_1.$$  Hence there is an integer $m$ (with $-m_2\leq m\leq m_1$) such that $$m-1\leq nx<m.$$ I don't understand the justification for this last sentence beginning ""Hence....""  How is $m$ found, and why are $m_1$ and $m_2$ needed to find $m$?",['real-analysis']
476693,"Using Residue theorem to evaluate $ \int_0^\pi \sin^{2n}\theta\, d\theta $","can you please guide me on evaluating this integral using residue theorem and binomial theorem
$$
\int_0^\pi \sin^{2n}\theta\, d\theta
$$
for $n = 1,2,3$ Honestly, I do not even know where to start, since it has no singularity. And what is also the correct contour for this one? Thanks in advance and more power.","['integration', 'complex-analysis']"
476714,Proof that a discrete metric is indeed a metric space,"QUESTION Let X be any set and $d : X \times X \to \mathbf{R}$ be given by $$ d(x,y) = \begin{cases}
0,  & \text{if $x = y$} \\
1, & \text{if $x \neq y$}  \\
\end{cases}$$ Show that $d$ is a metric on $X$. REMARKS I'm interested in getting to understand this question. First, I assume we're discussing what is known as the Discrete Metric here. But I'm finding it a bit ""too easy"" to prove the axioms. And so I get the impression that I'm doing it wrong. For example; when looking at the axioms: $d(x,y) \ge 0$ $d(x,y) = 0 ,\text{iff}: x=y$ $d(x,y) = d(y,x)$ Both appear to be self-explanatory. The definition of the metric space does make it clear and I find myself doing nothing more than re-stating the definition of the metric to ""prove"" these points. $4.$ Triangle Inequality: $d(x,y) \le d(x,z) + d(z,y)$
This I showed by considering a number of different cases (but not all of them - should I do all possible computations of the $x=/\neq y = /\neq z$ combination? ) and find this to be true in each case. I guess all I want to know - is, is the proof of this as simple as it looks? Thanks","['general-topology', 'metric-spaces', 'real-analysis', 'analysis']"
476721,First order Differential Equation. How to bring it to standard form?,I came across this eq. in Agarwal: Ordinary and Partial diff. equations book. $$(y^2-1) + 2(x-y(1+y)^2)y'=0 $$ Is there a clever substitution to bring this to standard form?,['ordinary-differential-equations']
476731,Find the principal part of the Laurent expansion of $\frac{(z^{2}-2z-3)^{2}}{\cos(\pi z)+1}$ around $z_{0}=1$,"Problem : The function $f(z) = \frac{(z^{2}-2z-3)^{2}}{\cos(\pi z)+1}$ has an isolated singularity at $z_0=1$. a) Find the principal (singular) part of the Laurent expansion of $f$ in a punctured neighbourhood of $z_0=1$. b) In which region does the Laurent expansion converge? My thoughts : Usually I am given the region in which the Laurent expansion converges but now I have to determine that myself. Will the Laurent series still be uniquely determined? If so, I have an idea about how to proceed: to manipulate the function so that we have $z-1$ in place of $z$, find Taylor series for every $z-1$ and then just divide when you have the expansion in the top and the bottom. I am not sure if this is a good idea or not and if so I do not know how to change $cos(\pi z)$ into something I can work with. All input appreciated! I am studying for an exam in complex analysis, this is a problem from an old exam.","['laurent-series', 'complex-analysis', 'taylor-expansion']"
476735,"Elements in sigma algebra generated by sets (A,B)","I understand that the number of elements generated by sigma(A,B) is 16. But I'm not able to find all of them. I have found: $A$, $B$, $A^c$, $B^c$, $A ∩ B$, $A^c ∩ B^c$, $A^c ∪ B^c$, the empty set, the sample space, $A^c ∩ B$, $A ∩ B^c$, $A^c ∪ B$, $A ∪B^c$, $A ∪ B$. What are the last two?",['measure-theory']
476738,difference between dot product and inner product,I was wondering if a dot product is technically a term used when discussing the product of $2$ vectors is equal to $0$.  And would anyone agree that an inner product is a term used when discussing the integral of the product of $2$ functions is equal to $0$?  Or is there no difference at all between a dot product and an inner product?,"['linear-algebra', 'inner-products']"
476748,Proving $|f'(z)|\leq\frac{\text{Re}(f(z))}{\text{Re}(z)}$,"Studying for a preliminary exam, I came across the following question: Let $D = \{z \in \Bbb C : \text{Re}( z )> 0\}$ and $f : D \to D $ be a holomorphic function. Prove that $$|f'(z)|\leq\frac{\text{Re}(f(z))}{\text{Re}(z)}\quad \text{for all }z\in D.$$ I thought the best way might be to use the fact that harmonic functions satisfy the maximum modulus principle, too, along with the limit definition of the derivative, but I wasn't able to get it worked out. How should I approach this problem?",['complex-analysis']
476763,proving the Klein 4 group is abelian,"If ker $f = \{ (1), (12)(34), (14)(23), (13)(24) \}$, which is the Klein 4 group, how do I prove that it is an Abelian group? Do I just show that each element in the ker $f$ is commutative to prove this?","['finite-groups', 'group-theory', 'abstract-algebra']"
476765,Transversal and complete intersection of hypersurfaces in $\mathbb{P}^{n}$,"(a) Let $k<n$ and $F_{1},\dots,F_{k}$ be general homogeneous polynomials of degrees $d_{1},\dots,d_{k}$ in $n+1$ variables. Prove that the corresponding hypersurfaces in $\mathbb{P}^{n}$ intersect transversally at a smooth $(n-k)$-dimensional variety $X \subset \mathbb{P}^{n}$. (b)
Let $k<n$ and $V_{1},\dots,V_{k}$ be transversally intersecting hypersurfaces. Prove that $\cap_{i=1}^{k} V_{k}$ is a complete intersection.","['commutative-algebra', 'algebraic-geometry']"
476774,What axiom(s) do I need to prove that every nonempty set of natural numbers has a smallest element?,"Math people: The title is the question.  I am not a logician, and to me, it seems self-evident that any nonempty set of natural numbers has a smallest element.  I am reading an analysis book that uses the Completeness Axiom of the real numbers to prove this ""fact"" (I put ""fact"" in quotes because a logician might not accept something so obvious as a fact but might require that I assume some axiom).  To me, this really seems like overkill, and that you should be able to prove it using something much weaker. EDIT: I am not asking specifically about axioms of ZFC.  My question does not even mention ZFC.  I highly doubt that Choice is necessary here and I suspect it may not even be helpful.  I would like (i) confirmation that using the Completeness Axiom of the real numbers to prove that every nonempty set of natural numbers has a least element is massive overkill and (ii) some weaker axioms that give me the same conclusion, the weaker the better.","['logic', 'elementary-set-theory']"
476783,How to write well in analysis (calculus)?,"This is kind of a subjective question, I know; often I find myself failing exams and homeworks because of the way i write down proofs. Either I don't know how to start, or somehow the main point of the proof is lost. I've noticed that in many books there's an ""style"" but doesn't matter how much i try to mimic it, i can't seem to do it right. I'm more of an algebra person, I love it, but Analysis, well... isn't my strong suit. If you have any tips I'll appreciate it. After a while of waiting, I couldn't get the writting that I wanted to post as an example, so here it is a ""fresh"" example of an excerisize I didn't finish: If $S$ is the set of all the sequences of real numbers, for $\bar x=(x_i), \bar y=(y_i) \in S$ we define: $$d(\bar x, \bar y)= \sum_{i=0}^\infty \frac {|x_i -y_i|}{2^i(1+|x_i-y_i|)}$$ (a) Prove that $d(\bar x, \bar y)$ is a metric in $S$. (b) Let $\bar x^k=(x_i^k),\bar x=(x_i)\in S$. Prove that: 
  $$\lim_{k\to \infty} d(\bar x^k,\bar x)=0 \Leftrightarrow \lim_{k\to \infty}x^k_i=x_i \quad \forall \; i\in \mathbb N$$ So I proved (a) , and I don't feel there's much to say there. However with (b) I got in trouble very easyly. ($\Leftarrow$) We know that $x_i^k \to x_i$ if $k\to \infty$, that means that $\forall \; \varepsilon>0 \; \exists \; m\in \mathbb N$ such that $\forall k>m \;\; |x_i^k -x_i|<\varepsilon $. On the other hand, what we want to prove is $\forall \; \varepsilon>0 \; \exists \; N\in \mathbb N$ such that $\forall k>N$ $$|\sum_{i=0}^\infty \frac {|x_i^k -x_i|}{2^i(1+|x_i^k-x_i|)}|<\varepsilon$$ So what I tough is that, since we already have that $|x_i^k -x_i|<\varepsilon$ for any $\varepsilon >0$ so I did some ""reverse engineering"" , I took the absolut value that I want to prove and started to operate: 
$$\mathbf {(1)}\;\;|\sum_{i=0}^\infty \frac {|x_i^k -x_i|}{2^i(1+|x_i^k-x_i|)}| = \sum_{i=0}^\infty \frac {|x_i^k -x_i|}{2^i(1+|x_i^k-x_i|)}<\varepsilon $$
$$\Rightarrow \sum_{i=0}^ n \frac {|x_i^k -x_i|}{2^i(1+|x_i^k-x_i|)}<\varepsilon ,\;\; if\;\; n\to \infty $$
$$\Rightarrow \frac {|x_i^k -x_i|}{2^i(1+|x_i^k-x_i|)}<\varepsilon $$
$$\Rightarrow \frac {|x_i^k -x_i|}{1+|x_i^k-x_i|}<2^i \varepsilon, \;\;where\;\; 2^i\;\;is\;\;constant\;\;with\;\;respect\;\;to\;\; k$$
From here, I'm pretty much frozen. What I wanted was to get to what we already had: $|x_i^k -x_i|<\varepsilon$, but I couldn't, somehow it seems futile. In class we already saw how to do it, and it is completly different from what I tried.","['soft-question', 'proof-writing', 'real-analysis']"
476790,Find $\lim_{n\to\infty}$ of this quotient.,"Find, with proof, the value of this limit
$$\lim_{n\to\infty}\frac{\sum^n_{r=0}\binom{2n}{2r}\cdot2^r}{\sum^{n-1}_{r=0}\binom{2n}{2r+1}\cdot2^r}$$ I have tried using binomial identities but two problems occur: Only even binomial coefficients in numerator and only odd in denominator. The binomial coefficient occurs with $2^r$ and not with $2^{2r}$ which would be the binomial identity.","['summation', 'binomial-coefficients', 'contest-math', 'limits']"
476802,How do you prove that $tr(B^{T} A )$ is a inner product?,"Consider the vectorspace of all real $m \times n$ vectors and define an 
  inner product $\langle A,B\rangle = \operatorname{tr}(B^T   A)$.    ""tr"" stands for ""trace"" 
      which is the sum of the diagonal entries of a matrix. How do you prove that $\operatorname{tr}(B^T   A)$ is indeed a inner product? Kind regards","['vector-spaces', 'matrices', 'inner-products', 'trace']"
476806,Is there any way to count cycles of given size by that graph's spectrum?,"Is there any way to count cycles of given size by that graph's spectrum?
for example for $k=3$ the number of triangles in $G$ is $1/6\cdot\sum_{\lambda \in \mathrm{Spectrum}(G)} \lambda^3$ is there a way for $k>3$?","['graph-theory', 'discrete-mathematics']"
476822,"Set of infinite tuples is closed, bounded, non-compact","Let $\mathbb{R}^{\infty}$ be the set of all ""infinite-tuples"" $x=(x_1,x_2,\ldots)$ of real numbers that end in an infinite string of $0$'s. Define an inner product on $\mathbb{R}^{\infty}$ by the rule $(x,y)=\sum x_iy_i$. Let $\|x-y\|$ be the corresponding metric on $\mathbb{R}^{\infty}$. Define $e_i=(0,\ldots,0,1,0,\ldots,0,\ldots)$, where $1$ appears in the $i$th place. Let $X$ be the set of all the points $e_i$. Show that $X$ is closed, bounded, and non-compact. $X$ is bounded : Clear, since $\|e_i\|=1$ for all $i$. $X$ is closed : Suppose that $y=(y_1,y_2,\ldots)$ is a limit point of $X$, and let $y_n=y_{n+1}=\ldots=0$. Then for $i\geq n$, we have $$\|e_i-y\| = \sqrt{\sum_j ((e_i)_j-y_j)^2}\geq \sqrt{((e_i)_i-y_i)^2} = 1.$$ Let $d=\min(\|e_1-y\|,\|e_2-y\|,\ldots,\|e_{n-1}-y\|,0.5)$. If $d>0$, the ball of radius $d/2$ centered at $y$ doesn't contain any element of $X$, and so $y$ is not a limit point. So $d=0$, and $y=e_i$ for some $i$. Hence $X$ is closed. $X$ is not compact : We must show that there exists an open collection covering $\{A_{\alpha}\}$ of $X$ for which no finite subcollection covers $X$. What collection might we choose here?","['general-topology', 'metric-spaces', 'compactness']"
476830,Ring class field of $\mathbb{Q}(\sqrt{-19})$,I am looking an explicit form for the ring class field of the order $\mathbb{Z}[\sqrt{-19}]$ in the quadratic field $\mathbb{Q}(\sqrt{-19})$. Does anyone know if there is some and how it is?,"['class-field-theory', 'algebraic-number-theory', 'number-theory']"
476849,"If $f(x)$ is an integrable function, can we always find its anti-derivative using ordinary methods of integration?","Suppose that we have an integrable function $f(x)$ which is expressed in terms of elementary functions. By integrable, I mean that  we can find its anti-derivative in terms of elementary functions, and by elementary function I mean a function of one variable built from a finite number of exponentials, logarithms, polynomials, trigs, inverses of trigs and roots of other elementary function through composition and combinations of the four elementary operations ($+, -, \times, \div$). So $\sqrt{\sin(x)}$ in this definition is elementary function. Is it necessarily true that we can calculate its integral (anti-derivative) using integration by parts, partial fractions, substitutions, trigonometric & hyperbolic substitutions? Of course there are functions whose anti-derivatives we can't find in terms of elementary functions (for example, $f(x)= \frac{\sin(x)}{x}$ or $f(x)=e^x \ln(x)$), but my question is about those for which we can find their anti-derivative in terms of elementary functions. The reason behind specifying only those methods is that those methods are taught in every class in calculus when the instructor talk about methods of integration (also, another reason is that finding the derivative for any function can be calculated using the inverse of those integration methods such as the product rule or chain rule - except quotient rule!) My own guess is: Suppose that $A$ is the set of  functions $F(x)$ whose derivatives are calculated using the quotient rule on some level, and $D$ is the set of derivatives of functions of $A$ , then by definition all the functions in $D$ are integrable but there exists a function in $D$ which can't be integrated using ordinary integration methods (remember, this is just a guess!) .","['calculus', 'integration', 'analysis']"
476853,Which field is it?,"Consider the ring $R=\mathbb{Z}^\mathbb{N}$ of integer sequences with the usual componentwise operations and let $I$ be the ideal of sequences that are eventually zero. 
Questions: Is there a unique maximal ideal $\mathfrak m \supseteq I$ of $R$ ? Is $R/\mathfrak m$ isomorphic to a well-known field (like $\mathbb{R}, \mathbb{Q}_p$,...) where $\mathfrak m\supseteq I$ is any maximal ideal ?",['abstract-algebra']
476854,The order of a group presentation,"Find the order of the group $G$ which has the presentation $\langle a,b \mid a^{16}=b^6=1,bab^{-1}=a^3\rangle $ I found that $a^8b=ba^8$ hence $\langle a^8,b\rangle$ is an abelian sungroup of $G$. But I couldn't go further.","['group-theory', 'group-presentation']"
476855,Expansion of $(1-z)^{-m}$,"Expand $(1-z)^{-m}$, $m$ a positive integer, in powers of $z$. Since $\dfrac{1}{1-z}=1+z+z^2+\ldots$, we can find $$\dfrac{1}{(1-z)^2} = (1+z+z^2+\ldots)(1+z+z^2+\ldots) = 1+2z+3z^2+\ldots.$$ So, in a similar way, by using induction and multiplying by $1+z+z^2+\ldots$ at each step, we can find $$\dfrac{1}{(1-z)^n} = 1+\binom{n}{n-1}z+\binom{n+1}{n-1}z^2+\binom{n+2}{n-1}z^3+\ldots.$$ I wonder whether this is a rigorous solution to the question or not. If not, what needs to be changed?","['power-series', 'complex-analysis']"
476869,One-to-one mapping vs one-to-one correspondence,"Does the phrase ""one-to-one mapping"" mean the same thing as ""one-to-one correspondence?""  I know that the latter refers to a bijection.  Does the former refer to an injection (i.e. it is the same as simply ""one-to-one"") or does it, too, refer to a bijection?","['terminology', 'functions']"
476875,How can we determine the number of terms which we have to take in a series to get a particular accurate?,"As I remember , two days ago , there was a question ( here ) asks for calculating this limit $\displaystyle \lim \limits_{x\rightarrow \infty } \frac{x^3}{e^x}$ and the question was answered . of course this is an easy limit , we can calculate it using l'hopital rule . Now ,  if I expressed $\displaystyle e^x = 1+x+\frac{x^2}{2!} + \frac{x^3}{3!} + \ldots  = \sum\limits_{i=0}^{\infty}\frac{x^i}{i!}$ and substitute back an approximation for $e^x$. If we approximated $e^x$ for 3 terms then the limit is $\infty$ , if we approximated it for 4 terms then the limit is 6 but if we approximated for 5 terms then we get the right answer which is 0 . Now , How can we know that approximation for 5 terms will work while approximation for 4 or 3 terms would fail ? Is there any test or analytical method to determine this ? I used the geometric approach to see the reason behind that . here is the sketch for those approximations and the original function which illustrate and show why approximation for  3 and 4 terms fail . but I ask for Analytical approach as using the sketch of approximations is not rigorous and practical in general .","['taylor-expansion', 'sequences-and-series', 'calculus', 'limits']"
476881,About the use of Schwarz reflection principle in the proof of the mapping formular between the upper half plane to a given polygon,"In Chap 8 of Stein's complex analysis, he proved that all the conformal maps $f$ from the upper half plane $\mathbb{H}$ to a given polygon $P$ is of the form $c_1S(z)+c_2$, where $c_1, c_2$ are complex numbers and S(z) is the Schwarz-Christoffel integral. In the proof, he proposed that for any vertice $a_k$ of the polygon, assign a new function$h_k(z)=(f(z)-a_k)^{1/\alpha_k}$, where $\alpha_k$ is the inner angle at $a_k$, then $h_k$ maps the segment $[A_{k-1},A_{K+1}]$ to a line segment$L_k$, and then he applied the Schwarch reflection principle to see that $h_k$ is analytically continuable to a holomorphic function in the two way infinite strip $A_{k-1}<Re(z)<A_{k+1}$, and then ""since $h_k$ is injective up to $L_k$ the symmetry in the Schwarz reflection principle guarantees that $h_k$ is injective in the whole disc centered at $x$"" and later on ""finally the Schwarz reflection principle shows that $f$ is  continuable in the exterior of a disk $|z|\leq R$, for large $R$"" Can anyone help explain how the Schwarz reflection principle is used in the two quoted text? Thank you very much!","['reflection', 'complex-analysis']"
476890,The intuition behind Trig substitutions in calculus,"I'm going through the MIT open calculus course, and in one of the lectures (19-28min marks) the professor uses the trig substitution $x = \tan \theta$ to find the integral of $\frac{dx}{x^2 \sqrt{1+x^2}}$. His answer: $-\csc(\arctan  x) + c$, which he shows is equivalent to $-\frac{1+x^2}{x} + c$ by drawing a right triangle on the blackboard. I get the math behind each step of it, but I can't wrap my head around why that equivalence works.  We just used an arbitrary $x = \tan \theta$ substitution, where $\theta$ moves differently than x does, and the expression $-\frac{1+x^2}{x} + c$ by itself doesn't know anything about trigonometry.  But I type both into Excel for a bunch of different x values, and obviously they are equivalent. I guess I'm not really sure what my question is here, but I could just use some perspective.  It just seems like substituting ANY function in for x then integrating it shouldn't work, especially when crossing into polar coordinates.","['trigonometry', 'calculus']"
476899,"Linear independence of the numbers $\{1,e,e^2,e^3\}$","Does someone know a proof that $\{1,e,e^2,e^3\}$  is linearly independent over $\mathbb{Q}$? The proof should not use that $e$ is transcendental. $e:$ Euler's number. $\{1,e,e^2\}$  is linearly independent over $\mathbb{Q}$ Any hints would be appreciated.","['irrational-numbers', 'transcendental-numbers', 'reference-request', 'number-theory']"
476923,Construct a sample space $\Omega$,"Construct a sample space $\Omega$ and events $A_1,\ldots, A_n$ ($n\ge2$) such that $\operatorname{Pr}(A_i) = \frac12$ ($1 \le i \le n$), every $n-1$ of the $A_i$ are independent, but the $n$ events are not independent. Please help, I stuck for hours on this one.","['probability-theory', 'probability']"
476939,Proving the irrationality of $e^n$,"Let $n$ be a positive integer. I know the traditional proof that $e$ is irrational. How do we show that $e^n$ is irrational in some sort of similar line? I am of course assuming it is but I would be astounded if not. It occurs to me that since $e$ is transcendental, of course $e^n$ is irrational, but I don't want to use that fact. Googling gives me something for $e^2$, but I could not easily find anything for $e^3$.","['rationality-testing', 'exponential-function', 'number-theory']"
476951,A real solution to a cubic equation,"What is the easiest way to find the real solution of the equation $x^3-6x^2+6x-2=0$? I know the solution to be $x=2+2^{2/3}+2^{1/3}$ (Mathematica) but I would like to find it analytically. If possible, not by plugging the coefficients in Cardano's or similar formula.",['algebra-precalculus']
476954,How to show $\lim_{p\to \infty} x_p=1$,"Let $f$ be nonnegative, continuous, and strictly increasing on $[0,1]$. For $p >0$, let $x_p$ be the number in $(0,1)$ which satisfies $f^p(x_p) = \int^1_0 f^p(x)dx$. Find $\lim_{p\to \infty} x_p=?$ I tried letting $f(x)=x$, $x^2$, $x^n$, etc. The limit seems converging to 1. However, for any other functions, how can I show this limit is 1? Thanks a lot, -Belen","['calculus', 'real-analysis', 'limits']"
476964,"When solving a linear differential equation by factoring the operator, how does one guarantee no solutions are lost?","I think the best way to make this question clear is with an example. Lets say we want to solve the differential equation $(\Delta^2 - \lambda^4)\phi=0,$ calculations are greatly simplified if  we factor the operator as 
$(\Delta -  \lambda^2)(\Delta + \lambda^2) \phi=0.$ Since the factors commute, it is clear that we can find solutions by solving each of the equations
$$ (\Delta -  \lambda^2)\phi_1 =0\\(\Delta +  \lambda^2)\phi_2=0  $$ separately. However it is not obvious that any solution to the original problem can be given in the form $\phi = \phi_1 + \phi_2,$ which is what texts concerning vibrations of plates claim. For example the book from Leissa, Vibrating Plates, NASA. I have not found yet any reference that addresses this issue. How can one guarantee no solutions are lost by solving the equation through this method? That is, how can one guarantee there are no other solutions $\phi$ that can't be written as $\phi=\phi_1+\phi_2$? I would greatly appreciate help with this problem. Thanks in advance.","['factoring', 'linear-algebra', 'operator-theory', 'partial-differential-equations']"
476972,Theorems with the greatest impact on group theory as a whole,"In his Contemporary Abstract Algebra text, Gallian asserts that Sylow's Theorem(s) and Lagrange's Theorem are the two most important results in finite group theory.  He also provides this quote by G.A. Miller: Generally these three results are implied by the expression ""Sylow's Theorem.""  All of them are of fundamental importance.  In fact, if the theorems of group theory were arranged in order of their importance Sylow's Theorem might reasonably occupy the second place - coming next to Lagrange's Theorem in such an arrangement."" The notion of 'most important theorem' in any area of mathematics is of course highly subjective, but if we depart from this phrasing and think of theorems that are very far-reaching, widely applicable, or theorems that impacted group theory the most (surely there is a good deal of overlap), do Lagrange's and Sylow's theorems still top this list when we consider the whole of group theory?  If not, what theorem or theorems would? What theorem(s) within strictly infinite group theory would top such a list?","['soft-question', 'group-theory', 'abstract-algebra', 'big-picture']"
476983,"If $f:\mathbb{R}\to\mathbb{R}$ is infinitely differentiable, then for all $x\in[0,1]$, $f^{(m)}(x)\neq 0$ for some $m$?","This is question #2 from the Fall 2003 qualifying exam at my university. Let $f\colon\mathbb{R}\to\mathbb{R}$ be an infinitely differentiable function such that for all $x\in[0,1]$, there exists $m>0$ such that $f^{(m)}(x)\neq 0$. Prove that in fact there exists $M$ such that for all $x\in[0,1]$ there exists $0<m\leq M$ such that $f^{(m)}(x)\neq 0$. I had this idea; for each $x_i\in[0,1]$, there exists $m_i$ such that $f^{(m_i)}(x_i)\neq 0$. Since $f$ is infinitely differentiable, $f^{(m_i)}$ is continuous, so there exists $\epsilon_i$ such that $f^{(m_i)}\neq 0$ on $(x_i-\epsilon_i,x_i+\epsilon_i)$. Then
$$
[0,1]\subseteq\bigcup_{i\in I}(x_i-\epsilon_i,x_i+\epsilon_i)$$
is an open covering of $[0,1]$, so by compactness, 
$$
[0,1]\subseteq\bigcup_{i=1}^n(x_i-\epsilon_i,x_i+\epsilon_i)$$
after relabelling. Set $M=\max\{m_1,\dots,m_n\}$. For arbitrary $x\in [0,1]$, $x\in (x_j-\epsilon_j,x_j+\epsilon_j)$ for some $j$. Then $f^{(m_j)}(x)\neq 0$ on $(x_j-\epsilon_j,x_j+\epsilon_j)$, and $m_j\leq M$. Is this solution correct or can it be made better?","['real-analysis', 'solution-verification']"
476987,Surjections and equivalence relations,"(a)  Let $f: A \to B$ be a surjective function.  We define $a_1 \sim a_2$ if $f(a_1)=f(a_2)$.  Prove that $\sim$ is an equivalence relation. Reflexivity: This comes for free.  If $a_1 \sim a_1$, then $f(a_1)=f(a_1)$. Symmetry: Suppose $a \sim b$.  Then $f(a)=f(b)$.  But that is the same as saying $f(b)=f(a)$.  Thus $b \sim a$. Transitivity: Suppose $a \sim b$ and $b \sim c$. Then $f(a)=f(b)$ and $f(b)=f(c)$.  Then $f(a)=f(c)$.  Thus $a \sim c$. (b)  Suppose $A$ is a set and $\sim$ is an equivalence relation on $A$.  Find a set $B$ and a function $f\colon A \to B$ such that $f(a_1)=f(a_2)$ exactly when $a_1\sim a_2$. This one I'm not sure how to even start.  It does seem like I am trying to prove the converse to part (a), but I am not sure.","['functions', 'equivalence-relations', 'elementary-set-theory', 'abstract-algebra']"
477014,Notation of sphere in $\Bbb{R}^n$.,"In $\Bbb{R}^n$, the sphere centred at $x\in \Bbb{R}^n$ with radius $l$ is called $S^{n-1}(x,l)$ or an $(n-1)$-sphere. Why do we called it an $(n-1)$-sphere? It's certainly not defined on $\Bbb{R}^{n-1}$ instead of $\Bbb{R}^n$. Thanks in advance!",['differential-geometry']
477023,Study of Matrix Calculus,"I need to study matrix calculus such as integration, differentiation, differentiation  of functions of determinants and inverse matrices and then also other matrix based calculations such as decomposition techniques. And I need to know these operations for matrices defined in the complex domain rather than real valued. Could someone please recommend me a book or a comprehensive online resource ? Thank you","['multivariable-calculus', 'calculus', 'matrices', 'linear-algebra', 'reference-request']"
477029,Counting the number of injections and surjections,"Let $A$ be a set with $n$ elements and $B$ bet a set with $n+1$ elements. In order to be injective, for each $b \in B$ there is exactly one $a \in A$ such that $f(a)=b$. I'm under the impression that this comes out to $\frac{(n+1)!}{(n+1-n)!}=(n+1)!$.  However, I'm worried that I'm overcounting. Let $A$ be a set with $n+1$ elements and $B$ bet a set with $n$ elements. This one I'm a bit more worried about.  It seems like for each choice of $b$, there is at most $n+1$ elements to be choosen from $A$.  It seems like there are at most $(n+1)^n$ onto functions.","['functions', 'combinatorics']"
477057,On tangent spaces of Stiefel Manifolds,"I was trying to read Edelman et al.'s 1998 paper ""The Geometry of Algorithms with Orthogonality Constraints"" and since I don't have any differential geometry or much linear algebra background I am stuck at a few places. This is regarding section 2.2.1, i.e tangent and normal spaces of the Stiefel manifold. Here is the excerpt: Let $Z$ be any $n$ -by- $p$ matrix. Let $\newcommand{\sym}{\operatorname{sym}}\sym(A)$ denote $(A + A^T)/2$ and $\newcommand{\skew}{\operatorname{skew}}\skew(A)$ denote $(A - A^T)/2$ , then at $Y$ , $\pi_N(Z) = Y \sym(Y^TZ)$ defines a projection of Z onto the normal space. Similarly at $Y$ , $\pi_T(Z) = Y \skew(Y^TZ) + (I - YY^T)Z$ I tried deriving $\pi_N(Z)$ as $\newcommand{\tr}{\operatorname{tr}}\pi_N(Z) = \tr(N^TZ)$ ; $N = YS$ where $S$ is any $p$ -by- $p$ symmetric matrix but couldn't arrive at the result. But using that result I could easily derive $\pi_T(Z)$ because $Z = \pi_T(Z) + \pi_N(Z)$ Next, they go on to say that tangent directions $\Delta$ at $Y$ then have the general form: $\Delta = YA + Y_{\perp}B$ where $A$ is $p$ -by- $p$ skew symmetric, $B$ is any $(n-p)$ -by- $p$ matrix and $Y_{\perp}$ is any $n$ -by- $(n-p)$ matrix such that $YY^T + Y_{\perp}{Y_{\perp}}^T = 1$ I couldn't derive the general form of the tangents either. Can someone please help me out on this? Thanks","['vector-spaces', 'manifolds', 'differential-geometry']"
477073,Is there a name for this particular class of topological space?,"This is a simple question, but I can't figure out the name for this class of topological space. Say you start with the affine space $\mathbb{R}^n$ for finite n, and equip it with a metric. Now, say you impose the equivalence relation generated by the relation such that for any two points $p, q$, $p \sim q \iff p-q \in V$, where V is a set of linearly independent vectors and $|V| \leq n$. This gives you a new topological space which can be thought of as a topological quotient space of the original (or also thought of as an orbit space). I will notate this space $\mathbb{R}^n/V$, and note that this new space also naturally inherits a metric from the old one via the quotient metric. Example: if you start with $\mathbb{R}^2$ and do this with $|V|$ = 1, you end up with the cylinder, and if you do it with $|V|$ = 2, you end up with the flat torus. Consider the set of all spaces one can obtain in this way; by starting with some finite-dimensional $\mathbb{R}^n$ and modding by some set of vectors $V$. Is there a name for this particular class of metric space? It seems like this would be a subset of the set of ""Finsler manifolds,"" but I don't know if there's anything more specific than that. Also, if it makes this question easier to answer, you can ignore the metric and just focus on the particular set of topological spaces that are constructible in this way; does this set have a name? EDIT: as mentioned, this is the same as the set of all spaces one can generate by $\mathbb{R}^a \times T^b$. Do these spaces have any sort of canonical name? They're one way to generalize a cylinder, but not the only way.","['geometry', 'differential-geometry', 'general-topology', 'manifolds', 'differential-topology']"
477074,"If $x^2=y^2$, prove that $x=y$ or $x=-y$","I have a simple question here. I am trying to prove that, given $x^2=y^2$, $x=y$ or $x=-y$. I know exactly why this is true; it's obvious. I'm just unclear on the general format of a proof, as well as how I should specifically write this one. Any help would be appreciated. Thanks.",['algebra-precalculus']
477076,"Linear independence of the numbers $\{1,\pi,{\pi}^2\}$","Does someone know a proof that $\{1,\pi,{\pi}^2\}$ is linearly independent over $\mathbb{Q}$ ? The proof should not use that $\pi$ is transcendental. $\{1,e,e^2,e^3\}$  is linearly independent over $\mathbb{Q}$ Any hints would be appreciated.","['irrational-numbers', 'transcendental-numbers', 'reference-request', 'number-theory']"
477083,The structure of a group of order 443520,"Let $G$ be a finit group and $T$ be a normal subgroup of $G$ such that $PSL(3,4) \unlhd T \leq Aut(PSL(3,4))$ and $|T|=2|PSL(3,4)|$. If $G= T\rtimes C_{11}$, then what we can say about the structure of the group $G$? (Actually I would like $G$ has an element of order 22 and by $C_n$ I mean the cyclic group of order $n$).","['finite-groups', 'group-theory', 'symmetric-groups']"
477106,Short proof that $X^2 = X \Rightarrow X^{100} = X$,"Given that a matrix $X$ satisfies $X^2 = X$ it is clear that $X^{100}=X$ by repeated multiplication of $X$. Algebraically, we might write: $$X^{100} = (X^2)^{50}=X^{50}=(X^2)^{25}=X^{25}=X(X^2)^{12} = \dots = (X^2)^2 = X $$ But this seems like too much work for such a simple fact. Is there a short algebraic proof?",['linear-algebra']
477108,$\lfloor \sqrt n+\sqrt {n+1}+\sqrt{n+2}+\sqrt{n+3}+\sqrt{n+4}\rfloor=\lfloor\sqrt {25n+49}\rfloor$ is true?,"I found the following relational expression by using computer: For any natural number $n$, 
$$\lfloor \sqrt n+\sqrt {n+1}+\sqrt{n+2}+\sqrt{n+3}+\sqrt{n+4}\rfloor=\lfloor\sqrt {25n+49}\rfloor.$$ Note that $\lfloor x\rfloor$ is the largest integer not greater than $x$. I can neither prove this nor find any counterexample even by using computer. 
Could you show me how to prove this? Or could you get an counterexample? Update : I've just asked a related question. Generalization of $\lfloor \sqrt n+\sqrt {n+1}+\sqrt{n+2}+\sqrt{n+3}+\sqrt{n+4}\rfloor=\lfloor\sqrt {25n+49}\rfloor$","['number-theory', 'functions', 'radicals', 'ceiling-and-floor-functions', 'summation']"
477123,Converting Second Order Linear Equations to First Order Linear Equations,"$\color{green}{\text{Question}}$: How can the following $\color{blue}{\text{second-order linear equation}}$ be converted into a $\color{blue}{\text{first-order linear equation}}$? This is our second-order linear Equation :
  $${y}''-2y'+2y=e^{2t}\sin t$$ $\color{green}{\text{I think}\ldots}$ This equation contains the dependent variable and the independent variables . Equation is not complete. Equation is not homogeneous. How can I convert it to a first-order linear equation? Thank you for any hint.",['ordinary-differential-equations']
477133,How to prove this inequality for $a_{n}<5$,"Let $a_{1}=1,a_{2}=2$ and be related by the recurrence
$$a_{n+2}=\dfrac{a^2_{n+1}(1+a_{n})+(1+2a_{n})a_{n+1}-a^2_{n}}{a_{n+1}+a^2_{n}+a_{n}+1}$$ for $n\in N.$ How can I show that
$a_{n}<5,n\in N$? my idea: I think we have 
$$a_{n+2}=pa_{n+1}+qa_{n}$$ because we have
$$a_{n+2}a_{n+1}+a_{n+2}a^2_{n}+a_{n+2}a_{n}+a_{n+2}=a^2_{n+1}+a^2_{n+1}a_{n}+a_{n+1}+2a_{n}a_{n+1}-a^2_{n}\cdots (1)$$
then 
$$a_{n+1}a_{n}+a_{n+1}a^2_{n-1}+a_{n+1}a_{n-1}+a_{n+1}=a^2_{n}+a^2_{n}a_{n-1}+a_{n}+2a_{n-1}a_{n}-a^2_{n-1}\cdots (2)$$
(1)+(2)","['inequality', 'sequences-and-series']"
477174,Infinite Series $\sum\limits_{n=1}^{\infty}\frac{1}{\prod\limits_{k=1}^{m}(n+k)}$,"How to prove the following equality?
$$\sum_{n=1}^{\infty}\frac{1}{\prod\limits_{k=1}^{m}(n+k)}=\frac{1}{(m-1)m!}.$$","['closed-form', 'sequences-and-series', 'real-analysis']"
477176,Equations for double etale covers of the hyperelliptic curve $y^2 = x^5+1$,"Let $X$ be the (smooth projective model) of the hyperelliptic curve $y^2=x^5+1$ over $\mathbf C$. Can we ""easily"" write down equations for all double unramified covers of $X$? Topologically, these covers correspond to (normal) subgroups of index two in the fundamental group of $X$. So there's only a finite number of them. The function field of $X$ is $K=\mathbf C(x)[y]/(y^2-x^5-1)$. A double etale cover of $X$ corresponds to  (a certain) quadratic extension $L/K$. I guess every quadratic extension of $K$ is given by taking the root of some element $D$ in $K$, or by adjoining $(1+\sqrt{D})/2$ to $K$ for some $D$. I didn't get much further than this though.","['complex-geometry', 'covering-spaces', 'algebraic-geometry', 'algebraic-curves', 'fundamental-groups']"
477202,How to differentiate an integration?,"$$\int_{q_1}^{q_2}f_T(t)dt=0.6826\ldots(1)$$ How differentiating equation $(1)$ with respect to $q_1$ yields 
$$f_T(q_2)\frac{dq_2}{dq_1}-f_T(q_1)=0$$","['definite-integrals', 'ordinary-differential-equations', 'derivatives']"
477207,derivative of cost function for Logistic Regression,"I am going over the lectures on Machine Learning at Coursera. I am struggling with the following. How can the partial derivative of $$J(\theta)=-\frac{1}{m}\sum_{i=1}^{m}y^{i}\log(h_\theta(x^{i}))+(1-y^{i})\log(1-h_\theta(x^{i}))$$ where $h_{\theta}(x)$ is defined as follows $$h_{\theta}(x)=g(\theta^{T}x)$$ $$g(z)=\frac{1}{1+e^{-z}}$$ be $$ \frac{\partial}{\partial\theta_{j}}J(\theta) =\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{i})-y^i)x_j^i$$ In other words, how would we go about calculating the partial derivative with respect to $\theta$ of the cost function (the logs are natural logarithms): $$J(\theta)=-\frac{1}{m}\sum_{i=1}^{m}y^{i}\log(h_\theta(x^{i}))+(1-y^{i})\log(1-h_\theta(x^{i}))$$","['statistics', 'regression', 'machine-learning', 'partial-derivative']"
477211,I am having problems understanding this mark:,"I have this set defined as follows: $$A_n=\{(i,j)\in Z^2: (i,j)=1, 0\le i,j \le n\} $$ 
What does  (i,j)=1 means? Thanks in advance Now that we know it means gcd(i,j)=1, How can I calculate the size of this set?",['elementary-set-theory']
477218,Dense subset of a dual space norming?,"I'm wondering if a dense subset of the dual space is always norming. Precisely, let $E$ be a Banach space. Then for all $e\in E$ , $$\|e\|=\sup\limits_{\substack{e'\in E'\\\|e'\|=1}}|e'(e)|.$$ Now assume that $D\subset E'$ is dense. Do we have $$\|e\|=\sup\limits_{\substack{e'\in D\\\|e'\|=1}}|e'(e)|?$$ If this is not true in this generality, is it at least valid if $E$ is reflexive?",['functional-analysis']
