question_id,title,body,tags
2457628,Pre-image of a submanifold by a submersion,"Let $f: M \to N$ a submersion between two manifolds, and let $S\subset N$ a subset of N. Proof that $S$ is a  regular submanifold of $N$ if and only if $f^{-1}(S)$ is a regular submanifold of M. So far I have half of the problem. Using the transversality theorem, we see that if $S$ is a submanifold, then using that $f$ is a submersion, we see that $S$ is transverse to $f$, so the preimage of $S$ is a submanifold of M. Now, for the second part I tried to use coordinate charts and the constant rank theorem, but nothing seems to work. Any help will be appreciated.",['differential-geometry']
2457635,If there is a surjection $A\to B $ and another $B\to A$ then $A $ and $B$ are in bijection [duplicate],"This question already has answers here : Is there a Cantor-Schroder-Bernstein statement about surjective maps? (2 answers) Closed 6 years ago . I am trying to prove this (it looks true to me) : Let $A,B $ be two sets. If there is a surjection $A\to B $ and a surjection $B\to A$ then $A $ and $B $ are in bijection. I showed that is it equivalent to the following statement : If there is an injection $A\to B $ and an injection $B\to A$ then $A $ and $B $ are in bijection. But I am stuck, I don't see how to prove either.","['set-theory', 'functions']"
2457641,Sequences of Simple Functions Increasing and Decreasing,"Let $f : E \to \Bbb{R}$ be a bounded measurable function. Show that there are sequences of simple functions on $E$, $\{\varphi_n \}$ and $\{\phi_n \}$, such that one is increasing an the other is decreasing, and both of which converge uniformly to $f$ on $E$. I realize this has been asked on this website, but all of the solutions offered seemed rather complicated. So I want to present my solution which I open up to criticism (please do, especially if you think it is wrong)","['real-analysis', 'measure-theory', 'proof-verification']"
2457775,"Which of the following sequences $(f_n)$ converge uniformly on [0,1]?","as the title states, which $f_n$ converge uniformly on $[0,1]$ (i) $f_n(x)=\frac{x}{1+nx}~~~~~$
    (ii) $f_n(x)=\frac{nx}{e^{nx^2}}~~~~$
    (iii)$f_n(x)=n^{\frac{1}{2}}x(1-x)^{n}$ there are another 3 more but these are the ones ive done so far and i want to make sure my work is correct. definition of pointwise convergence is $$\forall \epsilon > 0, \wedge x\in[0,1] ~ \exists N\in\mathbb{N}. \text{s.t for } n>N \Longrightarrow |f_n(x)-f(x)|\leq \epsilon$$ then uniform convergence is $$\forall \epsilon > 0,\exists N\in \mathbb{N} \text{ s.t } \forall n>N \Longrightarrow \sup_{x\in[0,1]}|f_n(x)-f(x)| \leq \epsilon $$ so for each of the above i just need to make sure that they first converge pointwise. then see if they converge uniformly.
(now it's been a while since i last did this so i may be rusty which is why i'm looking for confirmation that i'm doing it right) first things first, for (i):
$$\lim_{n \longrightarrow \infty}f_n(x)=\lim_{n \longrightarrow \infty}\frac{x}{1+nx}=\lim_{n \longrightarrow \infty}\frac{n}{n}\frac{x/n}{1/n+x}=0 \text{ as }n  \rightarrow \infty $$ so the function converges pointwise to the zero function (yes?) so if this is uniformly convergent the limit of the sup of this function should also converge to the zero function so
$$\sup_{x\in [0,1]}|f_n(x)-f|=\sup_{x\in [0,1]}|f_n(x)|=\sup_{x\in [0,1]}|\frac{x}{1+nx}|=\frac{1}{1+n}=0 \text{ as } n\rightarrow \infty$$ so it does converge uniformly. (yes?) i use similiar reasoning on (ii) to argue that also converges uniformly and on (iii) i find
$$\lim_{n \longrightarrow \infty}f_n(x)=\lim_{n \longrightarrow \infty}n^{\frac{1}{2}}x(1-x)^{n}$$ for x = 0 or 1 we have $f_n(x)=0~\forall n$ which i believes suggests $$0 \leq f_n(x) \leq 0 $$ which suggests $$f_n(x)=0$$ and alternative arguement which i'm more confident about is the idea that $(1-x)^{n}\rightarrow 0$ faster than $x\sqrt{n} \rightarrow \infty$ which would give me the same limit of $0$ am i on the right tracks?","['real-analysis', 'convergence-divergence', 'uniform-convergence', 'limits']"
2457801,Solving $\tau(n)+\phi(n)=n$ for $n\in\mathbb{N})_{\ge 1}$.,"Let $\tau(n)$ denote the number of divisors of a positive integer $n$,
  and let $\phi(n)$ be Euler's totient function, i.e. the number of
  positive integers less than and coprime to $n$. I'd like to find all
  $n$ such
      $$ \tau(n)+\phi(n)=n.$$ The case when $n=p$ for $p\in\mathbb{P}$ is easy. We have
$\tau(n)=2$, $\phi(n)=p-1$ and the equation is equivalent to $$
   2+p-1=p+1=p,$$ which is impossible. The case of $n=p^k$, where $k\in\mathbb{N}_{\ge 2}$ is already more complicated. We have $\tau(p^k)=k+1$ and $\phi(p^k)=p^k(1-1/p)$, hence the equation is equivalent to
$$ k+1+p^k\left(1-\frac{1}{p}\right)=p^k,$$
which can be rearranged into 
$$ k=p^{k-1}-1=p^{k-1}-1^{k-1}=(p-1)(p^{k-2}+p^{k-3}+\ldots+1).$$
For example, for $k=2$ this is $2=p-1$, and $p=3$. It's easy to check that $n=3^2=9$ satisfies the conditions. For $k=3$, we have $3=p^2-1$, and $p=2$. Hence $n=2^3=8$. $k=4$ gives $4=p^3-1$, and unfortunately there's no solution. When $n=p_1\cdot p_2^k$ with $p_1,p_2$ distinct primes, we have
$\phi(p_1p_2^k)=\phi(p_1)\phi(p_2^k)$. As
$\tau(p_1p_2^{k})=2+k+1=k+3$, $\phi(p_1)=p_1-1$ and
$\phi(p_2^k)=p_2^k(1-1/p_2)$, the equation transforms into 
$$k+3+p_1-1+p_2^k\left(1-\frac{1}{p_2}\right)=p_1p_2^k,$$
which, after little bit of rearranging gives
$$ k+2+p_1+p_2^k-p_2^{k-1}=p_1p_2^k.$$
For $k=1$, this is 
$$1+2+p_1+p_2-p_2^{0}=p_1p_2, $$ or 
$$ 2+p_1+p_2=p_1p_2,$$
which does not help very much. I have no clue about the approach to the general case. I'm not even sure my current approach is useful at all . Any hints greatly appreciated.","['number-theory', 'divisor-counting-function', 'totient-function']"
2457852,Rearrange given vectors to minimize the sum of $\ell_1$ norms of pairwise sums,"Let $\mathbf{x}_1,\mathbf{x}_2,\dots,\mathbf{x}_n$ be real vectors with the following property $$\sum_{i=1}^{n}\mathbf{x}_i=0$$ I want to find a grouping strategy to achieve the minimum of $$\|\mathbf{x}_{i_1}+\mathbf{x}_{i_2}\|_1+\|\mathbf{x}_{i_3}+\mathbf{x}_{i_4}\|_1+\cdots+\|\mathbf{x}_{i_{n-1}}+\mathbf{x}_{i_n}\|_1$$ where $\|\cdot\|_1$ is the $\ell_1$ norm.","['optimization', 'discrete-optimization', 'permutations', 'linear-algebra']"
2457869,How to differentiate one function with respect to another? [closed],"Closed. This question is off-topic . It is not currently accepting answers. Closed 6 years ago . This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. This question is not about mathematics, within the scope defined in the help center . Improve this question I have two functions, u(x,y) and v(x,y), that are both intractable analytically and estimated numerically in MATLAB on a grid for x and y. How can I estimate du(x,y)/dv(x,y) at all points (x,y) on the grid? I want to plot du(x,y)/dv(x,y) against x and y.",['derivatives']
2457942,A map is differentiable if and only if its pullback preserves differentiablity,"Given $A,B$ two normed finite dimensional vector spaces and $f: U\subset A \to B$ a continuous map (where $U$ is open in $A$); show that, $f$ is differentiable ($C^{\infty}$) if and only if $f^{*}(C^\infty(B))\subseteq C^{\infty}(U)$. Here, $f^*(g)= g\circ f$. It's easy to see that if $f$ is $C^\infty$ then, $f^{*}(C^\infty(B))\subseteq C^{\infty}(U)$ because composition of differentiable maps is differentiable. However, I have no clue in the other direction.","['multivariable-calculus', 'differential-geometry', 'vector-analysis']"
2457943,Hermite polynomials approximate of a function and its derivatives,"Given a differentiable function $f\in \mathcal C^{(n)}(\mathbb R) \cap L^2(\mathbb R,e^{-x^2/2}dx)$ and its Hermite polynomial expansion $f_n=\sum_{i=0}^n a_i \psi_i$ . Is it true that $\int_{-\infty}^\infty |f^{(k)}(x)-f_n^{(k)}(x)|^2e^{-\frac{x^2}2}dx\to 0$ where $g^{(k)}$ is the $k$ 'th derivative of $g$ , as $n\to\infty$ , $\forall 0\le k\le n$ ? What is the proof? Is there a general result regarding the convergence of spanning orthogonal polynomial to the derivatives of the original function?","['approximation-theory', 'real-analysis', 'hermite-polynomials', 'orthogonal-polynomials']"
2457969,"How do I prove that if $A \neq B$, then $\{A\} \neq \{B\}$, where $A$, $B$ are sets?","This is in ZFC, and I thought it looked trivial, so I didn't give it much thought at first, but I've tried it now for some time with no progress. I'd like to keep the proof as short as possible. Would really appreciate some hints :)","['axioms', 'elementary-set-theory']"
2458018,There is a phone number with $10$ digits. What's the probability that each digit occurs exactly once?,"There is a phone number with $10$ digits. What's the probability that
  each digit occurs exactly once? This is a task of an old exam and I'm curious if my solution is correct. So we have a phone number made up of $10$ digits. Any number between $0$ and $9$ can occur as a digit. Thus in total we have $10^{10}$ combinations. But we want that each digit occurs exactly once. Since we have length $10$ with $10$ different numbers, there are $10!$ different possibilities of arranging those numbers (where each number occurs exactly once). What we need to do is $10^{10}-10!$ Thus the probability that each digit occurs exactly once in a phone number of length $10$ is $$\frac{1}{10^{10}-10!}$$ ? By the way, it took me about $15$ minutes to get to that solution and in the exam I got like $5$ minutes for one task.. :p I hope it's correct at least?",['probability']
2458021,Arc length Parameterization,If a given vector $\alpha$ is said to have unit speed such that $\Vert \alpha' \Vert$is equal to one. Does that imply that the vector is paramaterized with respect to arc length?,"['physics', 'differential-geometry']"
2458028,Integrating matrix differential equation with linearly varying anti-symmetric matrix,"I have the following 3-dimensional matrix initial value problem: $$\left\{\begin{matrix}\textbf{x}'(t) &=& (A + Bt)\:\textbf{x}(t) \\ \textbf{x}(0) &=& \textbf{x}_0\end{matrix}\right.$$ The matrices $A$ and $B$ do not depend on $t$, are anti-symmetric and have the following sparsity pattern: $$\begin{bmatrix} 0 & \times & 0 \\ \times & 0 & \times \\ 0 & \times & 0 \end{bmatrix}$$ where the crosses indicate the non-zero elements. I am wondering whether this initial value problem can be solved analytically. I am aware that both the special cases $A = 0$ and $B = 0$ can be solved analytically, with solutions $\textbf{x}(t) = e^{\frac12Bt^2}\textbf{x}_0$ and $\textbf{x}(t) = e^{At}\textbf{x}_0$, respectively. $A$ and $B$ are very likely not to commute, so the solution $\textbf{x}(t) = e^{At + \frac12Bt^2}\textbf{x}_0$ is probably false. Does anyone have an idea how to tackle this problem?","['matrices', 'ordinary-differential-equations', 'linear-algebra', 'initial-value-problems']"
2458041,Integral of $\int_C \frac{1}{z^2-z} dz$ where $C$ is a circle of radius $2$,"I wish to evaluate
$$ \int_C \frac{1}{z^2-z} dz \ \ \ \ \text{where} \ \ C=\left \{ z \in \mathbb{C}:| z |=2\right \}$$ I use the parameterisation $ \ \  \ \ \ \gamma(t)=2e^{it} \ \ : t=0\rightarrow 2\pi$ And so: $$ \int_C \frac{1}{z^2-z} dz =\int_0^{2\pi}\frac{2ie^{it}}{4e^{2it}-2e^{it}}dt=\int_0^{2\pi}\frac{ie^{-it}}{2-e^{-it}}dt=\left [\log (2-e^{-it}) \right]_0^{2\pi} =0$$ What argument can I make in terms of closed curves? I know that the integral of an analytic function on a closed curve is $0$ but how can I show that $\frac{1}{z^2-z}$ is analytic on $C$ ?",['complex-analysis']
2458055,Prove that the Sylvester equation has a unique solution when $A$ and $-B$ share no eigenvalues,"We are given the Sylvester equation $AX+XB=C$ with complex matrices. I am trying to understand the proof that if $A$ and $-B$ share no eigenvalues, then there is a unique solution $X$ for any $C$. The proof is on Wikipedia and reads like this: Suppose that $A$ and $-B$ have no common eigenvalues. Then their characteristic polynomials $f(z)$ and $g(z)$ have highest common factor $1$. Hence there exist complex polynomials $p(z)$ and $q(z)$ such that $p(z)f(z)+q(z)g(z)=1$. By the Cayley–Hamilton theorem, $f(A)=0=g(-B)$; hence $g(A)q(A)=I$. Let $X$ be any solution of $S(X)=0$; so $AX=-XB$ and repeating this one sees that $X=q(A)g(A)X=q(A)Xg(-B)=0$. Hence by the rank plus nullity theorem $S$ is invertible, so for all $C$ there exists a unique solution $X$. Firstly, I don't understand how it concludes that there exist $p(z)$ and $q(z)$ such that $p(z)f(z) + q(z)g(z)=1$. If this follows from the previous statement, I don't see how. Secondly, I don't understand how it concludes that $q(A)g(A)X=q(A)Xg(-B)$. Again, if it follows from a previous statement, it is not clear how. If anyone can explain these steps, or provide a different proof, it would be greatly appreciated.","['eigenvalues-eigenvectors', 'matrix-equations', 'sylvester-equation', 'proof-explanation', 'linear-algebra']"
2458067,Solving the integral $\int \frac{x+1}{x (x^2+1)}dx$,"I'm having trouble with the following integral:
$$\int \frac{x+1}{x (x^2+1)}dx$$
Through tedious partial fraction decomposition and term-by-term integration I got the following antiderivative:
$$-\frac{1}2 \log(x^2+1)+\log(|x|)+\arctan(x)+C$$
But the book gives the answer:
$$ \log(|x|) + \arctan(x) + C $$ I've already turned this in (it's not graded for correctness), but I want to know what the simplest way is to calculate this integral correctly.","['derivatives', 'integration', 'calculus']"
2458093,How many essentially different generating sets of cardinality $d +1$ are there in a vector space $V$ of dim $d$ over a field of prime cardinality $p$?,"Let $p$ be a prime number and let $V$ be a finite dimensional vector space over the field with $p$ elements. Let $d$ denote its dimension. For the purpose of this question let us say two subsets $A,A'$ of $V$ are equivalent if there exists an automorphism $f$ of $V$ such that $f(A)=A'$. This notion of ""equivalent"" gives an equivalence relation on the set of subsets of $V$. Question: What is the number of equivalence classes of generating subsets of $V$ of cardinality $d+1$? To be precise, maybe I should say: ""the  number of equivalence classes that contains some  generating subset of cardinality $d+1$."" Yet, note that if a class contains one  generating subsets of cardinality $d+1$ then all sets in this class  are generating subsets of cardinality $d+1$, so ultimately different interpretations should yield the same problem. I would be interested both in exact results as well as in estimates and/or pointers to relevant literature. Context: I often need to study properties of generating subsets in finite dimensional vector space over the field with $p$ elements (think of coding theory if this at first glance seems like a strange thing to study). Usually, the properties I care about are invariant under automorphisms. Thus, in my investigations I can assume ""without loss"" that the set contains a specific fixed basis. Sometimes I wonder how many cases I would need to distinguish, if I would want to go one step further, and fix one element in addition to the basis. Since so far I was always either in the case ""it is easy to figure out in my current vector space"" or ""too many to be useful"" I never investigated this seriously. Yet, I thought about it a bit and it did not seem obvious either, but maybe I just do not look at it from the right angle. Example and further comments: Let $B= \{e_1,\dots, e_d\}$ be a basis. For $g \in V \setminus B$  the set $A_g = B \cup \{g\}$ is generating of cardinality $d+1$. It is not hard to see that each of the equivalence classes we want to count contains some set of the form $A_g$. Thus their number is bounded by $|V \setminus B|$. But $A_g$ and $A_h$ can very well be equivalent for distinct $g,h$. One phenomenon are permutations. If $g=\sum_{i=1}^d a_ie_i$ and $h = \sum_{i=1}^d a_{\sigma(i)}e_i$ for some permutation $\sigma \in \mathfrak{S}_d$ then $A_g$ and $A_h$ are equivalent. But this is not all. For example, let $e_0 = \sum_{i=1}^d e_i$. Then $e_1 =e_0 -   \sum_{i=2}^d e_i$, and one thus  sees that for $f_0 =e_1 -   \sum_{i=2}^d e_i$, one has $A_{e_0}$ and  $A_{f_0}$ are equivalent.","['finite-fields', 'combinatorics', 'vector-spaces']"
2458101,Trigonometric product on quarter circle: $\prod_{k=1}^{n-1}\sin\left(\frac{\pi k}{2n}+z\right)$,"A well know trigonometric identity states that for all $z$:
$$\prod_{k=1}^{n-1}\sin\left(\frac{\pi k}{n}+z\right)=\frac{2}{2^{n}}\csc\left(z\right)\sin\left(nz\right)$$ Is there any such formula for the quantity:
$$P(n,z)=\prod_{k=1}^{n-1}\sin\left(\frac{\pi k}{2n}+z\right)$$ I'm particularly interested in lower and upper bounding the ratio
$$\frac{P^2(n,\alpha/n)}{P^2(n,\beta/n)}$$ when $n$ grows large.","['products', 'trigonometry']"
2458111,Example of a metric space where Heine-Borel theorem does not hold,"In Rudin, it says the Heine-Borel theorem holds for Euclidean metric spaces. What is an example of a metric space where Heine-Borel does not hold true?","['real-analysis', 'metric-spaces', 'compactness']"
2458136,Pulling back (affine or not) connections,"Suppose that $f:M \to N$ is a smooth map of two manifolds and $E$ is a vector bundle over $N$. Given a connecton $\nabla$ on $E$ one can pull it back to $f^*N$ (which is a bundle over $M$) and obtain a connection $f^* \nabla$. If $E=TN$ is a tangent bundle one can consider the Levi-Civita connection $\nabla$, with respect to the chosen metric $g$ on $N$. It is characterised uniquely as torsion free metric connection. Given a map $f:M \to N$ one can pullback the metric $g$ to $f^*g$. If it happens that $f^*g$ is again a metric (which is the case for example for immersions ) one can consider the Levi Civita connection on $M$ with respect to $f^*g$. I wonder how these two constructions are related, in particular Is there a way to pullback affine connections to get again affine connection (i.e. connections on tangent bundle)? Additionally I would like to know: What is the relation between Christoffels symbols for the connection and for its pullback?","['riemannian-geometry', 'differential-geometry', 'tangent-bundle', 'vector-bundles', 'connections']"
2458171,Controlling the number of nonzero components in the LASSO solution,"Let $A$ be a real $m \times n$ matrix. The Lasso optimization problem is
$$
\text{minimize} \quad \frac12 \| Ax - b \|_2^2 + \lambda \| x \|_1
$$
The optimization variable is $x \in \mathbb R^n$. The $\ell_1$-norm regularization term encourages $x$ to be sparse, so Lasso is useful for finding a sparse vector $x$ that satisfies $Ax \approx b$.  The parameter $\lambda > 0$ controls how sparse the solution to the Lasso problem is. Question: Suppose I know that I would like for the solution to the Lasso problem to have exactly $p$ nonzero entries.  Are there any techniques or tricks or heuristics for choosing a value of $\lambda$ such that the solution to the Lasso problem has exactly (or at least approximately) $p$ nonzero entries?","['statistics', 'convex-optimization', 'sparsity']"
2458253,"Is Hermitian matrix a self-adjoint operator w.r.t. just the standard inner product, or any inner product?","Given a linear map $L:V→V$ over an inner product space $(V,〈⟩)$, the adjoint of $L$, denoted by $L^*$, is a linear map $L^*:V→V$ s.t. $〈Lx,y⟩=〈x,L^* y⟩$ for any $x,y\in V$. $L$ is self adjoint if $L=L^*$ and then $〈Lx,y⟩=〈x,Ly⟩$. Just consider $V=\Bbb C^n$. I am confused by Hermtian matrix. It is easy to prove a Hermitian matrix $H$ is self-adjoint under the standard inner product $〈x,y⟩=y^*x$, by $〈Hx,y⟩=y^*Hx=(H^*y)^*x=(Hy)^*x=〈x,Hy⟩$, but I am not sure if it is actually self adjoint for any inner product. If not, it would be great if someone could help give a counterexample.","['matrices', 'linear-algebra', 'operator-theory']"
2458289,Does convergence in every $L^p$ imply convergence in $L^\infty$?,"Consider a sequence of functions $(f_n)$ on a probability space $(X,\mu)$ such that (i) $f_n \to f$ in $L^p$ for every $p\in [1,\infty)$ (ii) $f,f_1,f_2,\cdots\in L^\infty$ and they are uniformly bounded in $L^\infty$ by $\Lambda\in [0,\infty)$, i.e. 
$$\|f\|_\infty,\|f_1\|_\infty,\|f_2\|_\infty,\cdots\le \Lambda.$$ Does then $f_n\to f$ in $L^\infty$?","['real-analysis', 'lp-spaces', 'probability']"
2458301,"Does $〈Ax,y⟩=〈x,A^*y⟩$ hold for any inner product?","Consider $\Bbb C^n$. Let $A^*$ be the conjugate transpose of matrix $A$, I see in many materials $A^*$ is also called the adjoint of $A$. I am now confused by that does $〈Ax,y⟩=〈x,A^*y⟩$ hold just for the standard inner product (whose proof is simple), or any inner product? Thanks!","['matrices', 'linear-algebra']"
2458304,Student T distribution as a solution of a differential equation,"From the links between probability theory and analysis, we know that lots of pdf usually represent a solution to a differential equation, e.g. the normal distribution is the solution to the heat equation. However, what can be said about the Student T distribution? To my best knowledge, there is no PDE or ODE that admits as a solution the function $$
f(x)=\frac{\Gamma \left( \frac{\nu + 1}{2}\right)}{\sqrt{\nu \pi \sigma^2}\Gamma \left( \frac{\nu}{2}\right)} \left( 1 + \frac{(x-\mu)^2}{\nu\sigma^2} \right)^{-\frac{\nu + 1}{2}}
$$ Any toughts about this question would help me a lot! :)","['stochastic-pde', 'real-analysis', 'partial-differential-equations', 'probability', 'ordinary-differential-equations']"
2458328,A product topology where we allow countably many open sets,"Let $\{X_{\alpha}\}$ be an uncountable collection of topological spaces indexed by the set $J$. For the space $\prod_{\alpha}X_{\alpha}$, consider the topology $\tau$ generated by the basis $$\mathcal{B}=\left\{\left(\prod_{\alpha\in S}U_{\alpha}\right)\times\left(\prod_{\beta\notin S}X_{\beta}\right): U_{\alpha}\text{ open in }X_{\alpha},S\subseteq J\right\}.$$ If $S$ is arbitrary, then $\tau$ is the box topology. If $S$ is finite, then $\tau$ is the product topology. What if we allow $S$ to be countable? Has this topology been studied at all? Does it have a use somewhere?","['product-space', 'general-topology']"
2458344,Maximal ideals of $\mathbb{Z}[x]$ containing $30$ and $x^2 + 1$.,"I want to find the maximal ideals of the ring $\mathbb{Z}[x]$ containing $30$ and $x^2+1$ . Any such ideal will contain the ideal $(30, x^2+1)$ , so we are searching for maximal ideals in the ring $$\mathbb{Z}[x] / (30,x^2+1) \cong \mathbb{Z}_{30}[x] /(x^2+1) \cong \mathbb{Z}_5[x] /(x^2+1) \oplus\mathbb{Z}_3[x] /(x^2+1) \oplus \mathbb{Z}_2[x] /(x^2+1)$$ Now, we search for the ideals in the summands. Factorizing, $x^2 + 1 = (x+3)(x+2) \bmod 5$ , $x^2 + 1$ is irreducible $\bmod 3$ , and $x^2 + 1 = (x+1)^2 \bmod 2$ . From this, we see that $\mathbb{Z}_3[x] /(x^2+1)$ is a field - there are no nonzero ideals. Moreover, we get ideals corresponding to the factored components in the other summands. How do I find the maximal ideals in $\mathbb{Z}_{30}[x] /(x^2+1)$ from here? Furthermore, how do I find the generators of the corresponding ideals in $\mathbb{Z}_{30}$ ?","['abstract-algebra', 'ring-theory', 'commutative-algebra']"
2458347,A measure preserving transformation,"Let $(\Bbb{R},\mathcal{B},\mu)$ a probability space,where $\mathcal{B}$ is the Borel sigma algebra,and $d\mu=\frac{1}{\pi} \frac{1}{x^2+1}dx$ Let $T: \Bbb{R} \to \Bbb{R}$ such that $Tx=\frac{1}{2}(x-\frac{1}{x})$ for $x \neq 0.$ Prove that $T$ is $\mu-$invariant,i.e: $\mu(T^{-1}(A))=\mu(A),\forall A \in \mathcal{B}$ The strategy i'm following here is to prove that $T$ preserves the measure of all of the half open intervals $(a,b]$ where $-\infty \leq a <b \leq +\infty$ The collection  of these intervals forms a semi-algebra(or semi-ring) that generates the Borel sigma algebra,so it is enough to prove the statement for these sets.(the result will follow from a theorem we proved in class) I managed to prove that $T$ preserves the measure of bounded intervals of this form.But i have a difficulty proving it for unbounded intervals,especially for intevals of the form $(-\infty,a]$ Can someone help me to finish my proof or guide me to a different solution if it exists? Thank you in advance.","['real-analysis', 'ergodic-theory', 'measure-theory', 'transformation']"
2458397,Divergence of a series involving an operator,"Let $T$ be an operator on an infinite-dimensional Hilbert space $H$, $r$ be its spectral radius. Let $\phi$ be a positive linear functional on the algebra $B(H)$ of bounded operators on $H$ such that $\phi(I_H)=1$ and $\phi(S^*S)=0$ implies $S=0$. I wonder if
$$\sum_{n=1}^\infty\dfrac{\phi(T^n)}{nr^n}$$
diverges? Informally we can have $\phi(\log|T-rI|)$ which seems to diverge, but how should I prove it formally? Jonas provided a nice counterexmaple where the series converges. But I think it is because he constructed an operator which has $i,-i$ as its spectrum, then the series is reduced to $\sum i^n/n$ and $\sum (-i)^n/n$ which both converge. I wonder what if I assume $T$ has an eigenvalue which equals to $r$? Jonas gave another counterexmaple. Please see the answer below. I admit that my intuition is for when $\phi$ is a trace and $T$ is a matrix, then $\phi(T^n)$ will be $\sum_i \lambda_i^n$, where $\lambda_i$ are eigenvalues. Then it will diverge. But what about a general operator with a general tracial positive linear functional? This part can be found here","['functional-analysis', 'operator-algebras', 'sequences-and-series', 'operator-theory']"
2458420,Continuity topological proof,"I just want to see if I'm on the right track.  I've been struggling with this question for several days now, so I could really use help on it, as I have really given a concerted amount of time to think about it. Since, I know that f is continuous, I know that pre-images of open sets in R are open in the rectangle defined by [0,1] x [0,1].  Now, I want to prove that g(x)=max{f(x,y)) is continuous on [0,1].  The main problem, I think I'm having is I don't understand what: represents.  I want to take open sets and show that their pre-images are open in order to show that g(x) is continuous.  However, I'm not sure how to formalize this or how to construct an argument showing this.  Perhaps, using the definition of continuity using sequences would be better?  I have tried looking at similar examples but I don't find them too much.  I would be really grateful for any help.","['real-analysis', 'continuity', 'general-topology', 'metric-spaces', 'sequences-and-series']"
2458448,Group of rational numbers,The set $\mathbb{Q1}$ of all rational numbers other than 1 will form a group under the operation $a*b=a+b-ab$ If we consider another set $\mathbb{Q}$ of all rational numbers.Will the set of rational numbers $\mathbb{Q}$ form a group under the same operation? Looks like This set satisfies the properties of group under the above operation !,"['abstract-algebra', 'group-theory']"
2458510,Example 7.21 and Definition 7.22 in Baby Rudin: Why is this sequence of functions not equicontinuous?,"Here is Definition 7.19 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Let $\left\{ f_n \right\}$ be a sequence of functions defined on a set $E$. We say that $\left\{ f_n \right\}$ is pointwise bounded on $E$ if the sequence $\left\{ f_n (x) \right\}$ is bounded for every $x \in E$, that is, if there exists a finite-valued function $\phi$ defined on $E$ such that 
  $$ \left\lvert f_n(x) \right\rvert < \phi(x) \qquad ( x \in E, n = 1, 2, 3, \ldots). $$ We say that $\left\{ f_n \right\}$ is uniformly bounded on $E$ if there exists a number $M$ such that 
  $$ \left\lvert f_n(x) \right\rvert < M \qquad (x \in E, n = 1, 2, 3, \ldots). $$ Here is Example 7.21 in Baby Rudin: Let 
  $$ f_n (x) = \frac{x^2}{x^2+ (1-nx)^2} \qquad (0 \leq x \leq 1, n = 1, 2, 3, \ldots). $$
  Then $\left\lvert f_n(x) \right\rvert \leq 1$, so that $\left\{ f_n \right\}$ is uniformly bounded on $[0, 1]$. Also 
  $$ \lim_{n \to \infty} f_n(x) = 0 \qquad (0 \leq x \leq 1), $$
  but 
  $$ f_n \left( \frac{1}{n} \right) = 1 \qquad (n = 1, 2, 3, \ldots), $$
  so that no subsequence can converge uniformly on $[0, 1]$. I think I understand the assertions in this Example. Here is Definition 7.22: A family $\mathscr{F}$ of complex functions $f$ defined on a set $E$ in a metric space $X$ is said to be equicontinuous on $E$ if for every $\varepsilon > 0$ there exists a $\delta > 0$ such that 
  $$ \lvert f(x) - f(y) \rvert < \varepsilon $$
  whenever $d(x, y) < \delta$, $x \in E$, $y \in E$, and $f \in \mathscr{F}$. Here $d$ denotes the metric of $X$. Now Rudin states the following: It is clear that every member of an equicontinuous family is uniformly continuous. [This is clear to me.] The sequence of Example 7.21 is not equicontinuous. [Why? This is what is not clear to me, although I do understand that this is a sequence of uniformly continuous functions.]","['real-analysis', 'equicontinuity', 'uniform-continuity', 'sequences-and-series', 'analysis']"
2458583,Non-causal LTI system - specific case,"I am given the following signals : input signal $x_{[n]} = (\frac{1}{2})^nu_{[n]} + 2^nu_{[-n-1]}$ The signal apparetnly starts in $ n=-\infty$ and goes to $n=\infty$. system output $y_{[n]} = 6(\frac{1}{2})^nu_{[n]} - 6(\frac{3}{4})^nu_{[n]}$ The response starts at $n=0$. The question is to state the impulse response $h_{[n]}$ of such system. my question How to understand a system that ""tolerates"" infinite input from $n=-\infty$ to $n=-1$ and only then, at $n=0$ starts to respond ? For me this seems somehow flawed. analysis I have tried to calculate z-transform, to obtain $H_{(z)}$, I believe I can get rid of the same roots and zeros and thus arriving at : $H_{(z)} = \frac{Y_{(z)}}{X_{(z)}} = \frac{1-2z^{-1}}{1-(\frac{3}{4})z^{-1}}$ Which still somehow doesnt provide me with much choice for inverse z-transform.","['z-transform', 'dynamical-systems', 'discrete-mathematics']"
2458594,Two points on curve that have common tangent line,"Find the two points on the curve $y=x^4-2x^2-x$ that have a common tangent line. My solution: Suppose that these two point are $(p,f(p))$ and $(q,f(q))$ providing that $p \neq q$. Since they have a common tangent line then: $y'(p)=y'(q),$ i.e. $4p^3-4p-1=4q^3-4q-1$ and after cancellation we get: $p^2+pq+q^2=1$. Tangent lines to curve at points $(p,f(p))$ and $(q,f(q))$ are $y=y(p)+y'(p)(x-p)$ and $y=y(q)+y'(q)(x-q)$, respectively. I have tried to put $x=q$ in the first and $x=p$ in the second equations but my efforts were unsuccesfull. Can anyone explain me how to tackle that problem?",['derivatives']
2458639,What does the notation $\big(\frac{\partial p}{\partial T}\big)_V$ mean?,"In a book about thermodynamics, I came across the notation shown in the title. A more complete example would be
$$dU = \left(\frac{\partial U}{\partial T}\right)_V\; dT + \left(\frac{\partial U}{\partial V}\right)_T\; dV$$
But I have no idea what the subscript means in this notation, would love some help. I ran in to trouble with an exercise that said Assume that gases behave according to a law given by $pV = f(T)$, where $f(T)$ is a function of temperature. Show that this implies $$\left(\frac{\partial p}{\partial T}\right)_V = \frac1V\frac{df}{dT}$$","['multivariable-calculus', 'physics', 'notation']"
2458703,"$T$ self-adjoint on Hilbert space $H$, $T^n=T^{n+1}$ will $T$ be an orthogonal projection operator?","I have seen several answers and proofs here at MSE that a self-adjoint operator $T$ on a Hilbert space $H$ where $T^2=T$, implies $T$ being an orthogonal projection operator. The thought struck me; what would happen if the condition $T^2=T$ is replaced by $T^3=T^2$ or instead by $T^4=T^3$ or why not more generally by $T^n=T^{n+1}$ for some $n\in\mathbb{N}$? Would this still imply $T$ to be an orthogonal projection operator? I guess someone must have thought of this before me? In that case perhaps there is a reference in the literature for this or perhaps the proof is way simpler than I might expect?","['functional-analysis', 'operator-theory']"
2458755,Probability of a probability to happen,"I'm trying to solve this problem but I'm struggling to. A university has 300 students enrolled. You sample 30 students and see that 20 are boys and 10 are girls. If the university had 150 male students and 150 females, what would be the probability of your observation? More generally,  if there are N students enrolled in the university, B of which are boys and N − B girls, what is the probability that if you sample n (≤ N), then exactly b are boys and n − b are girls? So from the sample we know that there are (approximating) 66% boys and 33% girls. But I don't know how to estimate the probability of this observation, what am I missing?","['statistics', 'probability']"
2458761,What is the expected value of the mean of a random subset?,Lets say you have a set $A$ made up of $n$ integers. We then randomly choose $m$ distinct elements from $A$ and put them in a set $B$. How would you prove that the expected value of the mean of $B$ is equal to the mean of $A$? Namely $E\left[\dfrac{1}{m}\sum_ja_j\right] = \dfrac{1}{n}\sum_ia_i$ where $j$ represents each of the random integers in $B$ and $i$ represents the items in $A$.,"['statistics', 'probability']"
2458822,Continuous dependence of solutions to ODEs on parameters,"Let $f:V\rightarrow \mathbb{R}^n$ be locally Lipschitz ($V$ is a subset of $\mathbb{R}\times\mathbb{R}^m\times \mathbb{R}^n$). Suppose we have a function $x:[t_0,\beta[\times W\rightarrow \mathbb{R}^n$ differentiable in the first argument ($W$ is an open subset of $\mathbb{R}^m$, $\beta$ is finite) such that for every $(t,\overrightarrow{\alpha})\in [t_0,\beta[\times W$ we have: $$(t,\overrightarrow{\alpha},x(t,\overrightarrow{\alpha}))\in V$$ $$x_1(t,\overrightarrow{\alpha})=f(t,\overrightarrow{\alpha},x(t,\overrightarrow{\alpha}))$$ Here $x_1(t,\overrightarrow{\alpha})$ means partial derivative with respect to first argument. It is also given that the function $g:W\rightarrow \mathbb{R}^n$  given by $g(\overrightarrow{\alpha})=x(t_0,\overrightarrow{\alpha})$ is locally Lipschitz. Question: Does it follow that the function $x:[t_0,\beta[\times W\rightarrow\mathbb{R}^n$ is continuous ? I can only prove the conclusion if the hypotheses are strengthened to $f,g$ Lipschitz instead of just merely locally Lipschitz.I would still like to know the answer in the locally Lipschitz case. Thank you a lot.","['examples-counterexamples', 'ordinary-differential-equations']"
2458843,Trouble in proving $\int_0^\infty x^3\frac{\sin\frac{\pi x}{2}\sinh\frac{\pi x}{2}}{\cos\pi x+\cosh\pi x}(J_0(x)+I_0(x))dx=0$,"I want to prove that
$$
\int_0^\infty x^3\frac{\sin\frac{\pi  x}{2}\sinh\frac{\pi  x}{2}}{\cos\pi x+\cosh\pi x}(J_0(x)+I_0(x))dx=0,\tag{1}
$$
where $J_0(x)$ and $I_0(x)$ are Bessel function and modified Bessel function of the first kind. What I know? This
$$
\int_0^\infty x^{4n-1}\frac{\sin\frac{\pi  x}{2}\sinh\frac{\pi  x}{2}}{\cos\pi x+\cosh\pi x}dx=0,\,\,\,\,\, n\in\mathbb{N},\tag{2}
$$
and this
$$
J_0(x)+I_0(x)=\sum_{n=0}^\infty a_nx^{4n}.\tag{3}
$$
However the trouble is I don't know how to combine $(2)$ and $(3)$ rigorously to get $(1)$.
For example this is not true:
$$
\int_0^\infty x^3\cos x^2\frac{\sin\frac{\pi  x}{2}\sinh\frac{\pi  x}{2}}{\cos\pi x+\cosh\pi x}dx=0.\,\,\,\,\,(\text{wrong})\tag{4}
$$ Q: Explain rigorously why $(1)$ is true and $(4)$ is wrong. Note. I believe closed forms of $(1)$ and $(4)$ can be derived by residue theorem. However in answering this question I want to avoid explicit calculations and understand how to get from $(2)$ and $(3)$ to $(1)$ and also to understand why the same reasoning fails in case of $(4)$.","['real-analysis', 'calculus', 'complex-analysis', 'integration', 'definite-integrals']"
2458850,Tighter inequality than Cauchy - Schwarz inequality,"I just learned today that there can be a tighter result than AM-GM (Arithmetic Mean - Geometric Mean) inequality. In particular: Let $a, b > 0$ then \begin{equation}
\label{1}\tag{1}
\dfrac{a+b}{2} - \sqrt{ab} \geq \dfrac{1}{16 \max \left\lbrace a , b \right\rbrace} \left( a - b \right) ^{2} .
\end{equation} When the RHS of \eqref{1} is $0$ then we get the classical AM-GM inequality. This result is obviously better since this RHS could be greater than $0$ in general. I wonder if we can get some similar result for Cauchy - Schwarz inequality. For example, just a particular case, is there some $\mathcal{E} \geq 0$ such that \begin{equation}
\left( a + b \right) ^{2} \leq 2 \left( a^{2} + b^{2} \right) - \mathcal{E} .
\end{equation}","['algebra-precalculus', 'inequality', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality']"
2458865,A difficult integral $I=\int_0^1\sqrt{1+\sqrt{1-x^2}}\frac{dx}{1+x^2}$,"How to prove
$$I=\int_0^1\sqrt{1+\sqrt{1-x^2}}\frac{dx}{1+x^2}=\sqrt{\sqrt{2}+1}\arctan\sqrt{\sqrt{2}+1}-\frac{1}{2}\sqrt{\sqrt{2}-1}\ln(1+\sqrt{2}+\sqrt{2+2\sqrt{2}})$$ $$ I=\int_0^{\pi/4}\sqrt{1+\sqrt{1-\tan^2y}}dy=\int_0^{\pi/4}\sqrt{{cosy}+\sqrt{\cos2y}}\frac{dy}{\sqrt{cosy}} $$ put  $$x=tany$$
 But how to calculate this integral?","['integration', 'definite-integrals', 'calculus']"
2458955,"Show that $\exists m \in(k,\ell):f''(m)+f(m)=0$","Let $f$ be twice differentiable on $\Bbb R$ and $f'(x)\not=0$, $f'(k)=f(\ell)$ and $f'(\ell)=f(k)$. Show that $\exists m \in(k,\ell):f''(m)+f(m)=0$. The only thing that I was able to do is to show that $\exists n \in (k,\ell):f'(n)-f(n)=0$. I'd like a hint.","['derivatives', 'calculus']"
2458960,Understanding the Proof that Algebraic Integers are a Subring of $\Bbb{C}$,"The set $\Bbb{A}$ of all the algebraic integers is a subring of $\Bbb{C}$ Here is an excerpt from my book: Suppose $\alpha$ an $\beta$ are algebraic integers; let $\alpha$ be the root of a monic $f(x) \in \Bbb{Z}[x]$ of degree $n$, and let $\beta$ be a root of a monic $g(x) \in \Bbb{Z}[x]$ of degree $m$. Now $\Bbb{Z}[\alpha \beta]$ is an additive subgroup of $G= \langle \alpha^i \beta^j ~|~ 0 \le i < n$, ~ $0 \le j < m \rangle$. Since $G$ a finitely generated, so is its subgroup $\Bbb{Z}[\alpha \beta]$, and so $\alpha \beta$ is an algebraic integer. Similarly, $\Bbb{Z}[\alpha + \beta]$ is an additive subgroup of $\langle \alpha^i \beta^j ~|~ i+j \le n+m-1 \rangle$, and so $\alpha + \beta$ is also algebraic. I am having trouble seeing the two set inclusions, particularly because $\Bbb{Z}[\alpha] := \{g(\alpha) ~|~ g(x) \in \Bbb{Z}[x] \}$ and the degree of the polynomials in $\Bbb{Z}[x]$ is unbounded, while $G$ and the other set are built from (multivariable) polynomials of finite degree. Perhaps someone could make this more explicit. Also, what's the motivation for choosing $n+m-1$ as the upper bound for $i+j$, other than the fact that it works?","['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
2458968,How to approach this counting problem?,"Let $n ≥ 1$ be an integer. A function $f : \{1, 2, \ldots , n\} \to \{1, 2, \ldots, n\}$ is considered ""valid"", if there is at least one integer $i$ in $\{1, 2, \ldots, n\}$ for which $f(i) = i$. Determine the number of valid functions. I'm having problems understanding what this question is asking. I'm not even sure how to approach this. Could someone point me to the right direction? What technique should I be using to approach it? I guess what's confusing me the most is this line here. Since I don't understand it. A function $f : \{1, 2, \ldots, n\} \to \{1, 2, \ldots, n\}$","['permutations', 'combinatorics', 'inclusion-exclusion']"
2458969,Differential operator acting on a Vandermonde determinant - an identity,"in my endeavors I've stumbled upon the following identity:
$$
\prod_{i=1}^N \left ( 1 + \frac{\partial}{\partial a_i}\right ) \left ( 
 \Delta(a) \prod_{i=1}^N a_i \right ) = \Delta(a) \int_0^\infty dt e^{-t} \prod_{i=1}^N (t+a_i) 
$$
with Vandermonde determinant $\Delta (a) = \det \left ( a_j^{i-1} \right )_{i,j=1...N}$. I find it surprisingly hard to prove, maybe someone knows this formula or could suggest any way to derive it? I've tried to utilize Schur polynomials as the LHS is the $s_{(1_N)}$ but to no avail. EDIT: 
My attempt of a proof started from the RHS where I use the generating functional of elementary symmetric functions: $$
\prod_{i=1}^N (t + a_i ) = \sum_{n=0}^N \sigma_n (a) t^{N-n}
$$
with elementary symmetric functions defined as
$$
\sigma_n(a) = \sum_{1\leq i_1 < i_2 < ... < i_n \leq N} a_{i_1} a_{i_2} ... a_{i_n}
$$
which gives 
$$
\text{RHS} = \Delta(a) \sum_{n=0}^N (N-n)!\sigma_n(a) 
$$","['multivariable-calculus', 'random-matrices', 'linear-algebra']"
2459002,What statements are equivalent to the Axiom of Determinacy?,"We know the big statements equivalent to the axiom of choice (Zorn's Lemma, Well-Ordering Theorem, etc...). So what about the axiom of determinacy?","['descriptive-set-theory', 'general-topology', 'set-theory']"
2459037,How to demonstrate $\operatorname{tr}(AB)=0$ when $A$ is symmetric and $B$ is antisymmetric,"For a square matrix $A$ of order $n$, let $\operatorname{tr}(A)$ be the sum of the diagonal entries. $\mbox{tr}(A)=\sum_{i=1}^{n} \textrm{a}_\textrm{ii}$ Assume that $A$ is symmetric and $B$ is antisymmetric, how to demonstrate that $\operatorname{tr}(AB)=0$?","['matrices', 'symmetric-matrices', 'linear-algebra']"
2459112,Are there any other sets that are both open and closed other than $\emptyset$ and $\Bbb R$? [duplicate],"This question already has answers here : If a nonempty set of real numbers is open and closed, is it $\mathbb{R}$? Why/Why not? (10 answers) Closed 6 years ago . Is there any set $X \subseteq \Bbb R$  so that X is both open and closed, $X \neq \emptyset$, and $X \neq \Bbb R$? I know $\emptyset$ and $\Bbb R$ are two sets that are both open and closed, but are there any more sets that fit this category?","['general-topology', 'real-analysis']"
2459121,$G_{\delta}$ null dense set,"I have to construct a $G_{\delta}$ set A which is dense and has Lebesgue-measure $\lambda(A) = 0$. I have thought of taking the points $x_i \in \mathbb{Q}$ and building open balls of radius $2^{-i}\epsilon$ around them, then joining them all together in a set $U$ which has measure $\lambda(U) \le 2\epsilon$. $U$ is obviously dense and open (hence $G_{\delta}$) and the measure can get arbitrarily close to $0$, but since it is open it can never be exactly $0$. I guess that somehow my idea of taking balls around points of $\mathbb{Q}$ is probably the easiest way of doing this, however my approach is not the right one.","['general-topology', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
2459152,How to find a formula for the sum up to $n$ terms of the sum $1+11+111+11111...$ using $1+2x+3x^2+4x^3...$,I'm trying to find the formula for the sum up to $n$ terms of the sum $1+11+111+11111...$ using $1+2x+3x^2+4x^3...=\frac{1-x^n}{(1-x)^2}-\frac{nx^n}{1-x}$. It's easy to find the formula if we expressed the sum as $1+(1+10)+(1+10+100)+(1+10+100+1000)...$ however when I try to express the sum as $1+2x+3x^2+4x^3...$ I can't find a constant value for $x$. Can anyone guide me on how I can express $1+11+111+11111...$ as $1+2x+3x^2+4x^3...$.,"['summation', 'sequences-and-series']"
2459153,How does 'even though' relate to in logic?,"Lets say I have something like this: Define the propositional variable: • b : Joe has maintained a B average. • c : Joe has received below a C in a class. • h : Joe is eligible for the honors program. Translate the following sentence into logical propositions.  For
  example the statement:  ”If Joe has maintained an B average, then he
  is eligible for the honors program” would be translated as b → h . Joe has maintained a B average even though he did receive a grade
  below a C in a class. How does the 'even though' translate into logic? I think that it would be and $∧$ and so the expression would be: $$b\space∧\space c$$ but I am not certain.","['boolean-algebra', 'logic', 'discrete-mathematics']"
2459157,Dual space of $L^p$ using existence of minimisers.,"Exercise 14 from Terence Tao's notes on Hilbert spaces( https://terrytao.wordpress.com/2009/01/17/254a-notes-5-hilbert-spaces/ ) wants me to show that when $1<p<\infty$ , the dual space of $L^p(\mu)$ is $L^q(\mu)$ where $\mu$ is $\sigma-$ finite and $q$ is the dual exponent of $p$ . He wants me to do this using Exercise 11 and Proposition 1 which are as follows: Proposition 1 . (Existence of minimisers) Let $H$ be a Hilbert space, let $K$ be a non-empty closed convex subset of $H$ , and let $x$ be a point in $H$ .  Then there exists a unique $y$ in $K$ that minimises the distance $\|y-x\|$ to $x$ .  Furthermore, for any other $z$ in $K$ , we have $\hbox{Re} \langle z-y, y-x \rangle \geq 0$ . Exercise 11. Using the Hanner inequalities (Exercise 6), show that Proposition 1 also holds for the $L^p$ spaces as long as $1 < p < \infty$ .  (The specific feature of the $L^p$ spaces that is allowing this is known as uniform convexity.) Give counterexamples to show that the propsition can fail for $L^1$ and for $L^\infty$ . I tried to do something similar to the proof of the Riesz Representation theorem for the dual of a Hilbert space but have been unable to bring in $L^q$ into the picture. Specifically, let $S$ be the closed subspace of $L^p$ which is the kernel of a given linear functional $\lambda$ on $L^p$ . We choose a subspace $M$ such that $L^p$ is the direct sum of $M$ and $S$ . Now, $M$ has to be one dimensional because else we can find a non zero combination of linearly independent vectors in $M$ such that $\lambda$ assigns them the value $0$ . I have no idea if anything can be done after this. Another thing I tried was to consider the linear transformation $T:L^q\rightarrow(L^p)^*$ which maps $g$ to the linear functional $\lambda_g(f)=\int fgd\mu$ . Now, we let $S$ be the closed subspace $T(L^q)$ . Proposition 1 says that to any continuous linear functional $\lambda$ , there exists a closest functional in $S$ . Hence, I need to show that if I have a specific $\lambda_g$ as an approximation to $\lambda$ , I can always make the approximation a bit better(hence weaker than showing that $S$ is dense) by considering some $\lambda_h$ such that $h$ differs from $g$ on atleast a set of measure zero, to qualify as a different $L^q$ function. Hence, I need to somehow modify $g$ to reduce the quantity $\text{sup}\{|\lambda(f)-\int fgd\mu|:\|f\|=1\}$ , but I am unable to tackle the problem that if I modify $g$ keeping some specific $f$ in mind, another $f$ might increase the value to keep the supremum from decreasing.","['functional-analysis', 'lp-spaces', 'banach-spaces']"
2459214,Is the gradient a surface normal vector or does it point in the direction of maximum increase of f,"I'm having some trouble trying to visualize and physically understand what's happening with the gradient. 
I understand that the following is true: The gradient of f (grad(f)) points in the direction of maximum increase of f However, later on, we are told that a gradient of a surface f (grad(f)) gives us the surface normal vector (i.e pointing away). How can that be? From the first statement, I thought that the gradient must be pointing in the direction of maximum increase of f - surely the direction of maximum increase of f should be a vector pointing in some direction on f itself. How can it be pointing outward as a surface normal vector?",['multivariable-calculus']
2459232,Graph Envelope Constraint puzzles from The Witness game.,"The computer game ""The Witness"" contains various puzzles based on a finite square grid graph arranged in the usual way. A path must be found from a given point on the edge to another. Each square can contain a symbol that describes additional constraints. A 4x4 grid. . A 4x4 grid with a path. . For simplicity and to get speedily to the maths I will describe a reasonably similar but simplified version of the game. This version contains ""separating"" puzzles where only empty squares and tiles containing coloured ""dot"" symbols are used. And ""pairing"" puzzles where only empty squares and the mono-coloured ""star"" symbol is used. A 4x4 separating puzzle with a path that solves it (middle). . Various pairing puzzles. Both types of puzzle involve making envelopes between the path and the edge of the grid to enclose groups of symbols. Dots must be in seprate regions (envelopes) to dots of other colours, whereas stars must be in pairs. In separating puzzles the existence of any group of 3 adjacent squares in a puzzle that form the shape of the L shaped tromino with entirely dissimilar colours of dot symbols are unsolvable. The same is true of a two colour 2x2 square of dot symbols with diagonally opposite same colours. The same sort of check also exists for the pairing puzzle except that the shape is that of 5 square pentomino that is in a ""+"" shape. Q: Can the shapes above that indicate a puzzle is unsolvable be reduced in size, or the check otherwise be made simpler?","['puzzle', 'graph-theory', 'envelope', 'discrete-mathematics']"
2459245,Why does this theorem fail when $m(E) = \infty$?,"I'm looking for an example of when this theorem fails. Theorem: Let $E$ be a measurable set of finite measure. For each $\epsilon > 0$, there is a finite disjoint collection of open intervals $I_1,I_2,...$ for which $U = \bigcup_{k=1}^n I_k$ has $m^*(E\setminus U) + m^*(U\setminus E) < \epsilon$. I've already proved the theorem, but don't see an example of when infinity would make it fail.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2459246,Do there exist $n^2$ real coefficients such that all matrices in $\Bbb R^{n∗n}$ containing those coefficients are invertible?,"Do there exist $n^2$ real coefficients such that all matrices in $\Bbb R^{n∗n}$ containing those coefficients (for any permutations) are invertible? Can we take these coefficients to be in $[1,2]$ ?","['matrices', 'linear-algebra']"
2459321,"Is there a prime of the form $a^b+b^c+c^d$ with consecutive primes $a,b,c,d$?","Suppose $a,b,c,d$ are consecutive prime numbers with $a<b<c<d$ Can $$a^b+b^c+c^d$$ be a prime number ? On the one hand, I did not find a prime for $a\le 4723$ (maybe, someone double-checks this ?) , on the other hand, there are quartupels such that $a^b+b^c+c^d$ has no small prime factor. For example, the smallest prime factor of $$23^{29}+29^{31}+31^{37}$$ is $$1937815389893$$ having $13$ digits, the cofactor having $43$ digits, is prime as well. So, there is no easy prove that there is no such prime  either.","['number-theory', 'perfect-powers', 'prime-numbers']"
2459473,Why isn't every open set of an affine scheme quasi-compact?,"Let $X = \text{Spec }A$ be an affine scheme. We always have that $X$ is quasi-compact, although in general it is certainly not true that any open set $U \subseteq X$ is quasi-compact. I was recently trying to show that if $Z \subseteq X$ is a closed subset, then $Z$ can be covered by a finite number of affine open sets of the form $Z \cap D(f_{i})$ with $f_{i} \in A$. In the process, I seem to have ""proved"" the above claim, which I know is false. Although I am not actually able to find where my mistake is, so I am clearly not understanding something properly. Let $\mathcal{I} \subseteq A$ be the ideal defining the closed set $Z$. That is, let $Z = V(\mathcal{I})$. Without loss of generality, we can take $\mathcal{I}$ to be radical. The points of $V(\mathcal{I})$ correspond to the prime ideals of $A$ containing $\mathcal{I}$. That is, prime ideals of $A / \mathcal{I}$. Also, $A / \mathcal{I}$ is a reduced ring, and we can choose a finite number of non-unit, non-nilpotent elements which generate the unit ideal,
$$
A / \mathcal{I} = \langle \bar{g_{1}}, \bar{g_{2}}, \ldots , \bar{g_{m}}      \rangle.
$$ But any prime $\mathfrak{p} \subseteq A$ containing $\mathcal{I}$ must
  fail to contain at least one of the $g_{j}$, since otherwise it would
  be sent to the unit ideal in $A / \mathcal{I}$. So the distinguished
  open sets $\{ D(g_{j}) \}_{j}$ cover $Z$. Now let $U$ be the complement of $Z$ in $X$. Since $U$ is open, it may be covered by a collection of distinguished open sets $\{D(f_{i}) \}_{i}$. Taking the collection of all the $D(f_{i})$ and $D(g_{j})$ together then gives a cover for $X$ with the former collection contained in $U$ and the latter collection contained in $Z$. By quasi-compactness, we can choose a finite subcollection of this combined collection, and so there must be only finitely many of the $D(f_{i})$ necessary to cover $U$. Where exactly does this argument fail? The only place I can see it possibly may is the part I have highlighted above. Is it really true that $\mathfrak{p}$ being sent to the unit ideal means that it itself must not be proper?","['algebraic-geometry', 'fake-proofs', 'proof-verification', 'schemes', 'commutative-algebra']"
2459497,What are the solutions of the equation $ (\partial_1 \cdots \partial_n)f=gf $?,"Let $n$ be a positive integer and $g:\textbf{R}^n\longrightarrow \textbf{R}$ be a smooth function. Let $\partial_i$ denotes the partial derivative with respect to the the $i$th coordinate ($i\in\{1,...,n\}$). What are the functions $f:\textbf{R}^n\longrightarrow \textbf{R}$  solutions to the following partial differential equation
$$ (\partial_1 \cdots \partial_n)f=gf \quad ?$$
Or, at least, what is the dimension of the $\textbf{R}$-vector space of solutions? Many thanks!","['linear-pde', 'partial-derivative', 'ordinary-differential-equations', 'partial-differential-equations']"
2459513,Convexity and Conditional expectatuon,"Let $(\Omega, F, P)$ be our probability space. Denote $\Omega^{(n)}$ to be a partition of $\Omega$ with $n$ components/sets such that each component has equal probability measure. Denote the resulting generated sigma-field by $\sigma(\Omega^{(n)})$. Suppose $X$ is an $\mathbb{R}^d$-valued random variable and $f:\mathbb{R}^d\to\mathbb{R}$ is a convex function. Is the following true?
$$
\mathbb{E}[f(\mathbb{E}[X:\sigma(\Omega^{(n)})])] \leq \mathbb{E}[f(\mathbb{E}[X:\sigma(\Omega^{(n+1)})])] 
$$ I've done some numerical experiments and it seems to suggest the above is true. However, I can't seem to find any reference on the internet.","['probability-theory', 'conditional-expectation', 'convex-analysis']"
2459697,Prove generalized associative law [duplicate],"This question already has answers here : How does one actually show from associativity that one can drop parentheses? (6 answers) Closed 2 months ago . I want to prove the following: If $G$ is a group under the operation $\star$, $\forall a_1,...,a_n\in G$, the value of $a_1\star a_2\star ... \star a_n$ is independent of how the expression is bracketed. My attemp at the proof: We prove this with induction on $n$. Base case: $n=3$, $a_1\star (a_2\star a_3)=(a_1\star a_2)\star a_3$. This is true by the definition of a group operation. Because a group operation is a mapping $\star :G\times G\rightarrow G$, we can substitute any $a_i\star a_j$ with some $a_k\in G$. Therefore, $a_1\star a_2\star ...\star a_n\star a_{n+1}$ is equivalent to $a_1\star a_2\star ...\star a_k$, which is true by the inductive hypothesis. I want to know if: $1)$ There are any correction to be made, and $2)$ Better wording for the proof. Thank you all in advance.","['abstract-algebra', 'group-theory', 'semigroups', 'associativity', 'solution-verification']"
2459710,How would I prove the following by induction?,"Let $n_1 > 0$ be a multiple of $9$ . Suppose that we add up all the (base-10 digits) of $n_1$ ; denote this sum by $n_2$ . Then add up all the digits of $n_2$ to get $n_3$ , and all the digits of $n_3$ to get $n_4$ , and so on. This produces a sequence of numbers $n_1, n_2, n_3, \dots , n_k,\dots$ Use induction to prove that $n_k = 9$ for all large enough $k$ . When you
write up your solution, clearly state your induction hypothesis. So far, I have tried to write down the statements above in mathematical form but I am encountering a few problems. By adding up all the multiples of $9$ , wouldn't I go to infinity as there are an infinite number of multiples of $9$ . Also, how would I develop a base case and induction hypotheses when relating to sums? Any help?","['algebra-precalculus', 'induction', 'discrete-mathematics']"
2459726,Convexity of the graph of an implicit function,"Let $f(x,y)=0$ be an implicit function and suppose this defines a curve $\gamma$ on $\Bbb{R}^2$. (If it is necessary, assume $f$ is a two variable polynomial.) What are the conditions that guarantees that $\gamma$ is a simple closed curve? If it is given that the graph of this function is a simple closed curve, is there any condition that allows us to check the convexity of the region bounded by $\gamma$ ? Specifically I am looking an answer for the second question but could not find any thing related to this. For example:  Is there any systematical way to determine the convexity of the simple closed curves like $y^4+y+2x^2=1$ and $y^2+2x^2y+x^2(x^2+1)=1$ ?","['plane-curves', 'convex-analysis', 'implicit-function', 'algebraic-curves', 'differential-geometry']"
2459816,Need explanation on a binomial theorem related problem for $\sum_{k=0}^{n} \binom{n}{k}k$,So I ran into this summation $$\sum_{k=0}^{n} \binom{n}{k}k$$ So I have no idea what to do so I looked at what my professor this.  He said If we differentiate this $(1+x)^n = \sum_{k=0}^{n} \binom{n}{k}x^k$ we have $n(1+x)^{n-1} = \sum_{k=0}^{n} \binom{n}{k}kx^{k-1}$.  Plugging in $x=1$ gives $\sum_{k=0}^{n} \binom{n}{k}k = n2^{n-1}$. First of all where did he come up with $(1+x)^n$ and why did he differentiate it?  And then why did he plug in $x = 1$?  I am confused.,"['combinatorics', 'discrete-mathematics']"
2459872,Continuity of ball measure in metric spaces,"Let $(X,d)$ a metric space and $\mu$ a Borelian probability non atomic measure on $X$. Fixed $x\in X$, the following application $r\in[0,1]\mapsto\mu(B(x,r))$ is continuous? where $B(x,r)=\{y\in X:d(x,y)<r\}$. I would appreciate some counterexample or some suggestion for the proof.","['continuity', 'real-analysis', 'metric-spaces']"
2459888,Need some hint with limit with multiple variables,"The limit
$$ \lim_{(x,y)\to(0,0)} \frac{x^{1/3}y^2}{x+y^3} $$
does exist since when we set $y=0$, $x=0$, and $x=y$ (it all equals to $0$). So now we need to evaluate the limit. The L'Hospital rule does not apply with multiple variables, so I am stuck of how to approach it. I understand that I need to somehow manipulate it, but I have no idea how. Any hints?","['multivariable-calculus', 'limits']"
2459897,Moving from one Coupling to another,"Let $X,Y$ be two discrete random variables. Two joint mass distributions (couplings) with marginals $X$ and $Y$ and with entries $p_{i,j}=\mathbb{P}_1(X=i,Y=j)$ and $p_{i,j}'=\mathbb{P}_2({X=i,Y=j})$  correspond to two matrices $(p_{i,j}), (p_{i,j}').$ Is there a linear transformation that maps $(p_{i,j})\mapsto(p_{i,j}')$? If not, is there a way to move from a given coupling of $X,Y$ to any other coupling of $X,Y$? The reason I ask is because I have a coupling of $X,Y$ and I wonder if a specific coupling exists. If there are any results that allow us to go from a 
 given coupling to any other coupling, perhaps this can be used to provide the desired coupling or show that it doesn't exist.","['probability-theory', 'probability-distributions', 'linear-transformations', 'coupling', 'linear-algebra']"
2459902,How to define orientation on infinite dimensional vector space,"Let $\mathbb{V}$ be a real Banach space (if someone knows the answer for more arbitrary T.V.S. then great). Is there some concept of orientation that one could define on $\mathbb{V}$ that matches the already existing one for finite dimension? My first guess was using the non-connectivity of $\mathrm{Aut}(\mathbb{V})$ analogously to the finite dimensional case. Let $\mathrm{Aut}(\mathbb{V})$ be the group of bounded/continuous linear isomorphisms $\mathbb{V} \to \mathbb{V}$. If $\mathrm{Aut}(\mathbb{V})$ has to two connected components $C_{+}$ and $C_{-}$ such that $C_{+}$ is a subgroup and that $AB \in C_{+}$ for all $A,B \in C_{-}$, then I could take $C_{+}$ to be the ""orientation preserving"" maps and an orientation to be an orbit of the action of $C_{+}$ on the set of basis of $\mathbb{V}$. In finite dimensions this condition is easy to check because of the determinant. Is this true for any Banach space? If not, is there a better way to generalize this concept?","['banach-spaces', 'orientation', 'topological-groups', 'functional-analysis', 'topological-vector-spaces']"
2459918,Holomorphic vector bundle obtained from exceptional divisor has one section.,"I've been reading Huybrecht's Complex Geometry , and ran across this question in section 2.5: If $X$ is a compact complex manifold, and $Y$ a hypersurface, show
  that $\mathcal{O}(E)$ ( where $E = \sigma^{-1}(Y)$ is the exceptional
  divisor) has exactly one global section up to scaling. I suspect this problem is quite simple, yet I frustratingly cannot make much progress on it. There is a hint given that one could consider the case of the blow-up of a point on a Riemann surface, but in this case, since the point is a smooth divisor, $\text{Bl}_Y(X)= \hat X \cong X$. Since in addition $\mathcal{O}(E)|_E \cong \mathcal{O}(-1)$, the obvious candidate for our supposed unique section is the defining function for the divisor (as we must vanish along $E$ as $\mathcal{O}(-1)$ has no sections). Does this line of reasoning hold for higher dimensions (even if $Y$ is not smooth)? I didn't need compactness so I imagine that this is wrong. If so, can someone point me in the right direction?","['complex-geometry', 'algebraic-geometry']"
2459925,Book to learn Advanced Linear Algebra and Matrix Theory,"I am looking for a book to learn Advanced Linear Algebra and Matrix Theory in detail. Sheldon Axler :Doesn't cover matrix theory,Hoffman,Kunze:Doesn't have many exercises and examples on each of the topics Please suggest some alternatives Requisites: Theorems with proofs,easy ones left to reader,Enough examples,Good Exercises(with Hints if possible) Topics to cover : Systems of Linear equations Diagonalization of a square matrix Vector Spaces Solutions of Linear Systems: Gaussian elimination
  , Null Space and Range
  , Rank and nullity, Consistency conditions in terms of rank
  , General Solution of a linear system
  , Elementary Row and Column operations
  , Row  Reduced Form
  ,Triangular Matrix Factorization 5.Important Subspaces associsted with a matrix: Range and Null space, Rank and Nullity,Rank Nullity theorem . 6.Orthogonality: Inner product, Inner product Spaces
  , Cauchy – Schwarz inequality
  , Norm
  , Orthogonality
  , Gram – Schmidt orthonormalization
  , Orthonormal basis
  , Expansion in terms of orthonormal basis – Fourier
  series
  , Orthogonal complement. 7.Eigenvalues and Eigenvectors Hermitian Matrices:Real symmetric and Hermitian Matrices
  Properties of eigenvalues and eigenvectors. 9.General Matrices: The matrices $AA^T,A^TA$
   Rank, Nullity, Range and Null Space of $AA^T,A^TA$
  ,Singular Value Decomposition. 10.Jordan Cnonical form:
   Primary Decomposition Theorem
   Nilpotent matrices
   Canonical form for a nilpotent matrix Mostly results on MSE said to follow Matrix Analysis-Horn,Johnson but the book does not cover all the topics in great detail.It focuses on more advanced topics. Please suggest  a book accordingly as I need to prepare for my exam.","['matrices', 'reference-request', 'book-recommendation', 'soft-question', 'linear-algebra']"
2459967,Operator Exponential $e^A e^B = e^{A+B}$,"This question comes from an exam in my functional analysis class. Suppose $X$ is a Banach space, and $T \in B(X,X)$ is a bounded linear operator on $X$. For any non-negative integer $n$, let
$$S_n=\sum_{k=0}^n \frac{1}{k!} T^k$$
where $T^k$ is the composition of $T$ with itself $k$ times and $T^0=I$. We can show that for any integer $k>0$, $\Vert T^k \Vert \le \Vert T \Vert ^k$. Then we can show that $S_n \in B(X,X)$ and there is some $S \in B(X,X)$ such that $S_n \to S$. We write $S = e^T$ for this operator. Finally, We were asked to show that $e^T$ has an inverse, and that it is $e^{-T}$. My thought is to prove the following claim first: if $A,B \in B(X,X)$ and $AB = BA$, then $e^A  e^B = e^{A+B}$. If the claim is true, it follows that $e^T e^{-T}=I$. The claim can be proven provided that the product series can be computed with the Cauchy rule. $$e^Ae^B=\sum_{i=0}^{\infty}\frac{A^i}{i!}\sum_{j=0}^{\infty}\frac{B^j}{j!}=\sum_{k=0}^{\infty}\sum_{l=0}^{k}\frac{A^lB^{k-l}}{l!(k-l)!}$$
$$=\sum_{k=0}^{\infty}\frac{1}{k!}\sum_{l=0}^{k}\frac{k!}{l!(k-l)!}A^lB^{k-l}= \sum_{k=0}^{\infty}\frac{1}{k!}(A+B)^k= e^{A+B}$$ But why can the product series be summed in the Cauchy way? I know for real-number series, by Cauchy's theorem, if $\sum_{n=1}^{\infty} a_n$ and $\sum_{n=1}^{\infty} b_n$ are absolutely convergent to $A$ and $B$, respectively, then we can add $a_i b_j$ in any way, and the resulting series will converge to $AB$. Does this proposition still hold for commutable operators? (It would be greatly appreciated if ideas of proof or reference is suggested.)","['functional-analysis', 'banach-spaces', 'matrix-exponential', 'banach-algebras']"
2459968,Transformation of Expectation of Summation,"Can I perform that $$E\left[\sum_{i=1}^{n}X_i\right] = \sum_{i=1}^{n}E[X_i]$$ if $X_i$ is not i.i.d.? In other words, can I move the summation inside expectation out in any situation? Also, what about variance $Var(\sum_{i=1}^{n}X_i)$? Is it the same as expectation?","['statistics', 'probability']"
2459992,A problem in measure preserving dynamical system.,"So I have the following two problems:
Consider a measure preserving dynamical system $(X,\mathcal B, \mu, T)$, i.e. 
$\mu(A)=\mu(T^{-1}(A))$ for all $A\in\mathcal B$, $T:X\rightarrow$ measurable.
Suppose you are given $f:X\rightarrow \mathbb{R}$ measurable. (1) What can you say about $f$ if $\sum_{n=1}^{\infty}f(T^n(x))$ converges for $\mu$-almost all $x\in X$? (2) What can you say about $f$ if $\lim_{n\rightarrow\infty}f(T^n(x))$ converges for $\mu$-almost all $x\in X$? For (1) my conjecture is that $f=0$ $\mu$-a.e, but I am not really sure, I only have a sketch of a proof. We know that $\lim_{n\rightarrow\infty}f(T^n(x))=0$ $\mu$-a.e. 
By Poincare recurrence theorem, almost every $x\in\{x:f(x)>0\}$ will be recurrent, and the same applies to $x\in\{x:f(x)<0\}$. Since $\lim_{n\rightarrow\infty}f(T^n(x))=0$ $\mu$-a.e. then it must the case that $f=0$ a.e. For (2) I think that $f$ must be constant on a set of positive measure, unless $T:X\rightarrow X$ is the identity. In this case (2) would hold trivially (so we cannot say anything about $f$). So suppose that $T(x)\neq x$ for every $x\in E$ where $\mu(E)>0$. 
By contradiction, assume that $f$ is not constant on $E$. Then by Poincare recurrence theorem, almost every $x\in E$ will return to $E$ infinitely many times. Because $T$ is not the identity on $E$ then the sequence will oscillates infinitely many times. Thus $f$ has to be constant on $E$ otherwise it cannot be converging.","['dynamical-systems', 'ergodic-theory', 'measure-theory']"
2459996,"Is $\mathbb Q \subset \mathbb R$ the subspace topology, discrete?, and questions about showing discreteness","I'm looking for subspace topologies of $\mathbb R$ that are discrete. In order to show that a subspace $U$ of $\mathbb R$ is discrete, I'm trying to show that the singleton set in $U$ is open. Since arbitrary unions of open sets are open, this way I could generate all of the subsets of $U$, hence discrete. What do you think about this method? Does it sound right? It can be shown easily that each singleton set in $\mathbb Z$ is open, so $\mathbb Z$ is discrete. I have no problem with that, however I'm looking for a subspace of $\mathbb R$ other than $\mathbb Z$ that is discrete. $\mathbb Q$ came into my mind, but couldn't show that it is discrete preciously. Every rationals are surrounded by irrational numbers, can I find an open interval $I \subset \mathbb R$ such that $I \cap \mathbb Q$ is equal to a singleton set in $\mathbb Q$? What do you think about my method of showing discreteness? Can an $I$ be found? What else could be a discrete subspace of $\mathbb R$? Are my questions. Thanks.",['general-topology']
2460070,"Show that in the sequence space $l^1$, the unit ball with respect to $d_1$ is closed in the topology induced by the sup metric $d_\infty$","Let
$l^1 = \left\{ (x_i)_{i\in\mathbb{N}} \mid \sum_{i =1}^{\infty} | x_i |<\infty \right\}$, 
the space of all sequences whose associated series converge absolutely. Let $A= \{\sum_{i = 0}^{\infty} | x_i |\leq1\}$ (Note: $A$ is the unit ball with respect to $d_1$ where $d_1((x_i)_{i\in\mathbb{N}},(y_i)_{i\in\mathbb{N}}) = \sum_{n = 0}^{\infty} | x_i - y_i |$.) Let $d_\infty((x_i)_{i\in\mathbb{N}},(y_i)_{i\in\mathbb{N}}) = sup_{i\in\mathbb{N}}| x_i - y_i |$. I want to show $A$ is closed with respect to the topology induced by $d_\infty$. (I see how to show it's closed with respect to $d_1$) Suppose we have a sequence $(x^n)_{n\in\mathbb{N}}$ of members of $A$  converging to $y\in l^1$. (Each $x^n \in A$, so this is a sequence of sequences). I will try to show $lim_{n\rightarrow \infty} \sum_{i=1}^\infty|x_i^n|=\sum_{i=1}^\infty|x_i|$. Here's my attempt. For each $n$, we have:
$$|(\sum_{i=1}^\infty|x_i^n|-\sum_{i=1}^\infty|x_i|)|=\sum_{i=1}^\infty(|x_i^n|-|x_i|)|\leq\sum_{i=1}^\infty||x_i^n|-|x_i||\leq \sum_{i=1}^\infty|x^n_i -x_i|$$
$$=\sum_{i=1}^{k}|x^n_i-x_i| + \sum_{i=k +1}^\infty|x^n_i-x_i|$$ for any $k$. (We may want k to depend on n). We can make $\sum_{i=1}^{k}|x^n_i-x_i|$ small by the convergence of $(x^n)$ to $y$ with respect to $d_\infty$. And given a particular $n$, we can make $\sum_{i=k_n +1}^\infty|x^n_i-x_i|$ small by taking $k_n$ large. However, the latter is not good enough. Given $\epsilon>0$, it seems we need to find $k$ such that For All sufficiently large $n$, $\sum_{i=k_n +1}^\infty|x^n_i-x_i|<\epsilon/2$. I don't see how to do this.","['functional-analysis', 'general-topology', 'metric-spaces']"
2460091,A Square Inside A Triangle (but with a twist),"I have a right $\triangle ABC$ and I want to find the side length of one of the legs, $x$, when the square is at its max area, as shown in I am given that $AB + BC$ is $10$. Here's what I tried so far: I found ratios between the sides using similarity, but I wasn't able to get a conclusive answer, just things in terms of each other. I tried to set up equations using the Pythagorean theorem, but that just ended up with some messy variable terms and zero actual progress. The answer is $x=5$, but I want to know how I would go about approaching this kind of problem. It's like others I've seen before here and in other places, but not being given the side lengths threw me off.","['optimization', 'geometric-inequalities', 'algebra-precalculus', 'triangles', 'geometry']"
2460124,Multiplicative group modulo $2^n$,"I remember learning that the multiplicative group modulo $2^n$, namely the group $\mathbb{Z}_{2^n}^\times$of integers coprime with $2^n$ is isomorphic to $\mathbb{Z}_2\times\mathbb{Z}_{2^{n-2}}$, which is due to Gauss.
It boils down to proving that the multiplicative order of $3$ in the group is $2^{n-2}$. Can you give me a hint here?","['abstract-algebra', 'elementary-number-theory']"
2460172,Fourier transform of $L^1$ function is continuous function,"I would like to know if my proof is correct. Define Fourier transform of $f\in L^1(\mathbb{R}^n)$ as $$\widehat{f}(x)=\int_{\mathbb{R}^n}e^{-ix\cdot y}f(y)\text{d}y.$$ 
I want to show that $\widehat{f}$ is continuous. So pick any sequence $x_n\rightarrow x$. Now $g_n(y)=e^{-ix_n\cdot y}f(y)$ is measurable for all $n\in\mathbb{N}$, $g_n(y)\rightarrow e^{-ix\cdot y}f(y)=g(y)$ for all $y$ and $|e^{-ix_n\cdot y}f(y)|=|f(y)|$ where $|f(y)|$ is integrable. So by dominated convergence theorem we have $$\lim_{n\rightarrow \infty}\widehat{f}(x_n)=\lim_{n\rightarrow \infty}\int_{\mathbb{R}^n}e^{-ix_n\cdot y}f(y)\text{d}y=\lim_{n\rightarrow\infty}\int_{\mathbb{R}^n}g_n(y)\text{d}y=\int_{\mathbb{R}^n}g(y)\text{d}y=\int_{\mathbb{R}^n}e^{-ix\cdot y}f(y)\text{d}y=\widehat{f}(x).$$ Therefore $\hat{f}$ is continuous. Am I correct?","['functional-analysis', 'fourier-analysis', 'measure-theory', 'fourier-transform']"
2460174,"How many distinct triples of non-negative $\lbrace{x,y,z\mid x,y,z\in \mathbb Z\rbrace}$ satisfy $2x+y+z=16$?","Consider $$2x+y+z=16$$ how many distinct, non-negative triples of $\lbrace{x,y,z|x,y,z\in \mathbb Z\rbrace}$ are there that satisfy the equation? I assumed that in this question, the role of combinatorics play a vital role, so I thought of it in this order: if the triples did not have to be distinct, there would be $16$ options the first time a number is chosen, $16$ the second time a number is chosen, and $16$ the third time a number is chosen, hence there are $16^3$ permutations where repetition is allowed. Then, when repetition is not allowed, the first time a number is chosen there $16$ options, then there are $15$ options, and then $14$, but from here not another number is chosen, so assuming there are $16!$ permutations is senseless. Therefore the remaining $13!$ permutations need to be discounted, hence there are $\displaystyle \frac{16!}{(16-3)!}$ permutations when repetition is not allowed. So does this imply there are $3360$ possible triples? This is more or less where I encountered the flaw in my logic: When the first number is chosen, there aren't actually $15$ remaining numbers to choose from. Because say for example you choose $y$ to be $16$, then both $x$ and $z$ must be $0$, i.e. there is actually only one choice once the first number has been chosen, and one choice once the second number has been chosen. But, what if we let $x=9$? Well, this wouldn't work at all as when $x=9$, $2x=18$, which means there are no non-negative values of $y,z$ that can satisfy the equation, hence $x$ actually has its own range; $0 \leq x \leq 8$ More or less here I kind of set aside the combinatorics approach and assumed a very basic approach: listing values. Given that $x$ has the smallest range of each of the variables, I let $x$ be the independent variable and $y,z$ be the dependant variables: \begin{array}{|c|c|c|c|c|c|c|c|c|c|}
\hline x & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\\hline
  y & 0\leq y \leq 16 & 0 \leq y \leq 14 & 0 \leq y \leq 12 & 0 \leq y \leq 10 & 0 \leq y \leq 8 & 0 \leq y \leq 6 & 0 \leq y \leq 4 & 0 \leq y \leq 2 & y=0 \\\hline
  z & 0\leq z \leq 16 & 0 \leq z \leq 14 & 0 \leq z \leq 12 & 0 \leq z \leq 10 & 0 \leq z \leq 8 & 0 \leq z \leq 6 & 0 \leq z \leq 4 & 0 \leq z \leq 2 & z=0\\\hline
  T & 17 & 15 & 13 & 11 & 9 & 7 & 5 & 3 & 1\\\hline
\end{array} (Note; a prerequisite in each entry is that $y+z=16-2x$. Also; the $T$ in the bottom row signifies the total number of permutations provided all the conditions, including the prerequisite, are met) From the table, the total number of distinct, non-negative triples of $\lbrace{x,y,z|x,y,z\in\mathbb Z\rbrace}$ that satisfy the equation $2x+y+z=16$ is a mere $81$. From all of what you've just read, I have only two questions: the first of which is obviously is this answer correct, and the second of which is, arguably more obviously, how can what I've written be expressed mathematically provided it is correct? Any responses are very appreciated, thank you.","['permutations', 'combinatorics', 'linear-algebra']"
2460196,Conjecture over an integral,"So, integral question time. $$\int_0^1 \frac{1}{x} \ln\left(\frac{1+x}{1-x}\right)e^{-x}\ \text{d}x$$ I was trying to compute this integral, and at a certain point I checked with Mathematica, and it solved it in a numerical way, returning the following result: $$1.4721301560626(...)$$ I am now asking if there is a way to obtain this result in a close form. I found out that that number can be expressed as $$\frac{1}{8}\left(60 C - 4 - 21\pi +\pi^2 + 68\pi \ln(2) - 38\pi \ln(3)\right)$$ Where $C$ is the Catalan constant. But even better as $$\frac{1097113}{2341289}\pi$$ Despite those forms are not exact. Is there a way to solve that integral in order to get the result in a close form? I am not saying I strongly think there must be a close form, but it would be nice!","['numerical-methods', 'integration', 'definite-integrals', 'closed-form']"
2460232,Transpositions are not commutators,"Let $X$ be a set, potentially infinite, and $\tau$ a transposition of $X$, meaning
\begin{align*}
\tau(x)&=y \\
\tau(y)&=x \\
\tau(z)&=z \quad \text{for all} \quad z\notin\{x,y\}
\end{align*}
for some distinct $x,y\in X$ Show that there are no bijections $f,g:X \rightarrow X$ satisfying $\tau=f\circ g \circ f^{-1} \circ g^{-1}$. I stumbled on this while looking for alternative definitions of parity of (finite) permutations, I don't know how to prove it, and my claim could be false. A similar question (one I can solve) would be to show that $\tau$ is not a square but I believe the above problem requires a more sophisticated argument. My idea was that to define parity the abelianization morphism. Showing that a product of two transpositions is in the kernel is pretty standard, the above would be a step to proving the kernel is not all $S_n$. Of course this definition is rather convoluted. If you have any unusual definition for the parity of permutations of $X$, specially one that never involves ordering the elements of $X$, I would be very interested.","['permutations', 'group-theory', 'elementary-set-theory']"
2460260,Visualizing the line bundle associated to the sheaf $\mathcal{O}_{\mathbb{P}^1}(2)$,"We have that the line bundle associated to the sheaf $\mathcal{O}_{\mathbb{P}_{\mathbb{C}}^1}(1)$ is given by:
$$
\mathbb{P}_{\mathbb{C}}^2\setminus\{(0:0:1)\} \rightarrow \mathbb{P}_{\mathbb{C}}^1, (x_0:x_1:x_2)\mapsto (x_0:x_1).
$$
This corresponds the projection from $(0:0:1)$ to the projective line $\mathbb{P}_{\mathbb{C}}^1 \simeq  V(x_2)\subset \mathbb{P}_{\mathbb{C}}^2$. I was wondering If we can find such an explicit description for the line bundle associated to $\mathcal{O}_{\mathbb{P}^1_{\mathbb{C}}}(2)$. In other words, 
I would like to find a variety $L$ and a map $\pi:L\rightarrow \mathbb{P}_{\mathbb{C}}^1$ such that $(L,\pi)$ is a line bundle on $\mathbb{P}_{\mathbb{C}}^1$ and its sheaf of sections is $\mathcal{O}_{\mathbb{P}_{\mathbb{C}}^1}(2)$. Does the map $\pi$ have a geometric interpretation like before?","['vector-bundles', 'algebraic-geometry']"
2460273,Convergence of an integral involving the radical of an integer versus the convergence of $\int_2^\infty\frac{dx}{x(\log x)^2}$,"For positive integers $n\geq 2$, let $\operatorname{rad}(n)$ the radical of the integer $n$. For example $\operatorname{rad}(24)=6$. See this Wikipedia to know this definition. Question. I would like to know if it is possible to discuss the convergence of this integral $$\int_2^\infty\frac{dx}{\left(\operatorname{rad}\left(\lfloor x\rfloor\right)\right)^{\alpha}\log ^2(x)},\tag{1}$$ where $\lfloor x\rfloor$ is the floor function and $\alpha\geq 1$ a fixed real number. Thanks in advance.","['real-analysis', 'analytic-number-theory', 'asymptotics', 'improper-integrals', 'convergence-divergence']"
2460295,"Is the atlas containing only the chart (R, cube root) for a manifold (R, standard) a C^infinity? why?","Let A={(R,cube root)} be an atlas for a manifold(R, standard topology).There is only one chart and no other in the atlas. Is the atlas C^infinity compatible? and why so?","['algebraic-topology', 'general-topology', 'differential-topology', 'manifolds']"
2460304,Math biology proof by induction question,"I am stuck on this question: Consider the delay-differential equation
$\frac{d}{
dt}x(t) = x(t − 1)$,
with $x(t) = 1$ for $t \in [−1, 0]$. The solution is given by
$x(t) = \sum^{n}_{0}{\frac{[t − (k − 1)]^k}{k!}}$
for $n − 1 \leq t \leq n$,
where $n$ is a non-negative integer.
Use proof by induction (i.e., method of steps) to find the solution I have tried to use the sum of a geometric series on the series and then differentiating this and setting it equals to $x(t-1)$ also in the geometric series however when i tried to the basis case $k=1$ I ended up with $\frac{1-t^n}{t-1}=\frac{1+t^2(t-1)^n-nt^3(t-1)^{n-1}}{t^2}$ which I am unable to prove is true, can anyone see where I have gone wrong or suggest a better method of approach this? -edited so that n is the upper limit","['ordinary-differential-equations', 'biology']"
2460311,How many 6-digit numbers can be formed in which the sum if its digits is divisible by 5?,"In the decimal system of numeration the number of $6$-digit numbers in which the sum of the digits is divisible by $5$ is $$(A)\space180000 \space\space(B) \space540000\space\space (C) \space 5\times10^5\space \space (D) \space \text{none}$$ First, I noted that $a+b+c+d+e+f=5,10,15\dots50$ where $a\geq1$ and  $ b, c, d, e, f\geq0$. From this I got $9C5 + 14C5 +...... 54C5$, which is just too hectic too calculate and I don't know it will give the right answer or not. Then I observed that there are $900000$ total possible numbers and if I divide it by $5$, I will get the correct answer which is $180000$. Is it a coincidence or is there any logic to it? What would be the proper method to solve this?","['combinations', 'combinatorics']"
2460315,Computation of an étale cohomology group on the projective line,"I have the following problem: Let $U_{0}$ be a a smooth geometrically irreducible affine curve over $\mathbb{F}_{q}$, and let  $\mathcal{E}_{0}$ be a constructible étale  sheaf of $\mathbb{Q}_{\ell}$-vector spaces on $U_{0}$. By $\mathbb{F}$ we denote an algebraic closure of $\mathbb{F}_{q}$ and by $\mathbb{P}^{1}$ we denote the projective space over $\mathbb{P}^{1}$. By $U$ we denote the base change of $U_{0}$ to $\mathbb{F}$ and by $\mathcal{E}$ we denote the inverse image of $\mathcal{E}_{0}$ on $U$. Further, we denote by $j$ the inclusion of $U$ into $\mathbb{P}^{1}$ and by $i$ we denote the inclusion of its complements to $\mathbb{P}^{1}$. 
Then 
$$H^{1}_{ét}(\mathbb{P}^{1}, i_{*}i^{*}j_{*}\mathcal{E})=0.$$ This is what i don't understand. I am interested in this, because i want to deduce from the cohomology sequence of
$$   0\rightarrow j_{!}j^{*}j_{*}\mathcal{E}\rightarrow j_{*}\mathcal{E}\rightarrow i_{*}i^{*}j_{*}\mathcal{E}\rightarrow 0$$ 
that
 $$H_{c}^{1}(U,\mathcal{E})\twoheadrightarrow H_{ét}^{1}(\mathbb{P}^{1}, j_{*}\mathcal{E}).$$ 
I hope somebody can help me with this problem! Many thanks in advance","['etale-cohomology', 'algebraic-geometry']"
2460349,intuition behind discrepancy in expected number of coin tosses,"Yesterday evening I read a very interesting article on prime numbers which contained the following paragraph on coin tosses: If Alice tosses a coin until she sees a head followed by a tail, and
  Bob tosses a coin until he sees two heads in a row, then on average,
  Alice will require four tosses while Bob will require six tosses (try
  this at home!), even though head-tail and head-head have an equal
  chance of appearing after two coin tosses. I immediately tried to look into this question. Using the formula provided by André Nicolas , it can be shown that the expected number of coin tosses we need before getting $n$ consecutive heads is given by: \begin{equation}
e_n = \sum_{k=1}^n\frac{1}{2^k}(e_n+k)+\frac{n}{2^n}
\end{equation} For $n=2$, the expected number of heads($e_2$) is 6. Analytically, this makes sense once you become familiar with the above equation. Now, what I find interesting is that, as mentioned in the article, the probability of obtaining two heads is the same as the probability of obtaining a head followed by a tail: \begin{equation}
P(HH)=P(HT)=\frac{1}{4}
\end{equation} However, the expected number of coin tosses required to get the $HT$ pattern is 4 not 6. I still find this quite counter-intuitive. In fact, 
I ran a simulation using the following python code: import numpy as np

head_tail = np.zeros(10000)
two_heads = np.zeros(10000)

for i in range(10000):
    z = np.random.randint(2, size=100)

    for j in range(100):
        if z[j] == 1 and z[j+1] == 0:

            head_tail[i] = j+2

            break

    for j in range(100):

        if z[j] == 1 and z[j+1] == 1:

            two_heads[i] = j+2

            break And I noticed that their distributions behaved very differently: It's by no means intuitive to me that the behaviour of these two distributions should be very different and yet they are remarkably different. Is there an intuitive reason why this must be the case?","['real-analysis', 'probability']"
2460360,An analytical way to find range of $f(x)=\frac{x}{\lfloor x\rfloor}$,"I want to find range of this function analytically . I tried to polt it and see $$R_f=(0,2)$$ and $$f(x)=\frac{x}{\lfloor x\rfloor}$$ Can you help me ?","['ceiling-and-floor-functions', 'calculus', 'functions']"
2460383,Interior of Regular Surface.,"I have the following question, If $S\subset\mathbb{R}^3$, is a regular surface, then interior of $S$, can be empty? My approach: I have a list of ideas for this problem. The definition, that I know, for regular surface is for each point in the surface, therefore the interior cannot be empty. $A$ is a open subset of a regular surface if and only if, $A$ is a regular surface (this prop. is easy to demonstrate); So that, if $A$ is a open set, then it interior is not empty, and $\mbox{int}\{A\}\subset\mbox{int}\{S\}$. Then, interior of $S$ is not empty. I try to think in what case I have empty interior of a surface. If the interior of surface is empty, then his points are in the boundary of $S$, but the boundary of this set is a closed set, therefore I think that, I would lose the condition of regularity for the homeomorphism. On the other hand, If we consider $S$ as, the ""shell"" of the sphere, then $S$ is a regular surface, and the interior of $S$ (I have not demonstrated it) will be a empty set.","['general-topology', 'differential-geometry', 'surfaces']"
2460391,Solving the ODE: $\frac{1}{r} \frac{d}{d r} \left( r \frac{d f}{d r} \right) + \left( a - b e^{r^2} \right) f = c+ d e^{- r^2} $,"I'm trying hard to solve this: $$\frac{1}{r} \frac{d}{d r} \left( r \frac{d f}{d r} \right) + \left( a - b e^{r^2} \right) f = c+ d e^{- r^2} $$ where $r$ ranges between $0$ and $\infty$, $a$ and $b$ are positive constants, $c$ and $d$ may have either sign. Any of you is able to handle this?","['derivatives', 'laplace-transform', 'laplacian', 'stability-in-odes', 'ordinary-differential-equations']"
2460397,Prove that there exist uncountable family of subsets of $\mathbb{N}$ which is linearly (totally) ordered by relation of inclusion.,Prove that there exist uncountable family of subsets of $\mathbb{N}$ which is linearly (totally) ordered by realtion of inclusion. I do not know how to prove it. Actually I cannot concieve that such family of set can be uncountable. I would be thankful for help,['elementary-set-theory']
2460400,Domain of the closure of an unbounded operator on a Hilbert space,"Let $D$ and $F$ be two unbounded on a Hilbert space $H$ whose dense domains of definition coincide. Moreover, assume that each is a symmetric operator. As is well-known, each operator is closable, i.e. extendable to a closed operator. Will their extended domains coincide?","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'unbounded-operators']"
2460435,"how to $\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx \leq \frac e5 \ln(\pi)$?","I need to prove irreproachably that $$\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx \leq \frac e5 \ln(\pi)$$ . With an approximate calculation $\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx\approx 0.62145$ and $\frac e5 \ln(\pi)\approx 0.62233$ We can see by Laplace transform that $$\int_{0}^{+\infty}\frac{\sin x}{1+x}\,dx = \int_{0}^{+\infty}\frac{e^{-s}}{1+s^2}\,ds $$ and deduce $$\int_{0}^{+\infty}\frac{\sin x}{1+x}\,dx = \int_{0}^{+\infty}\frac{e^{-s}}{1+s^2}\,ds\leq  \sqrt{\int_{0}^{+\infty}\frac{ds}{(1+s^2)^2 } } \sqrt{\int_{0}^{+\infty} e^{-2s}  ds} = \sqrt{\frac{\pi}{8}}.$$ But $\frac e5 \ln(\pi)< \sqrt{\frac{\pi}{8}}$","['inequality', 'calculus']"
2460439,"$\int\frac{dx}{1+x}, x\geq0$ by trigonometric substitution","Consider the integral $I=\int\frac{dx}{1+x}, x\in[0,\infty)$. A standard treatment using the substitution $u=1+x$ directly gives the result $\ln(1+x)+c$. Now consider doing this with the trigonometric substitution $\sqrt{x} = \tan\theta, \theta\in[0,\pi/2)$ then $x=\tan^2\theta, dx = 2\tan\theta\sec^2\theta$. Now, following your nose with right triangle trigonometry this leads directly to the solution $I = 2\ln(1+x) + c$. Is there a mistake here or some subtlety I'm ignoring? Is there something interesting with the integration constants?","['integration', 'trigonometry']"
2460458,finding remainder by using fermat's little theorem or euler's totient,"I am trying to carry on for the following equation but I stuck with a big number that still needs to be smaller to calculate without calculator. $\ 331^{51}\mod 49$ Since the $\phi(49)=42$, I carried on the problem as follows: $=\ 331^{42}.331^{9}\mod 49$ which $331^{42}=1$, so; $=\ 331^{9}\mod 49$ Since $331/49$ remains $37$ problem becomes; $=\ 37^{9}\mod 49$ $=\ (-12)^{9}\mod 49$ $=\ (-12)^{8}.(-12)\mod 49$ Since 8 is even; $=\ (12)^{8}.(-12)\mod 49$ ... .(a bunch of conversions)... ... Finally I have found this (which is checked via wolframalpha and it is correct); $=\ (2)^{29}.(23)\mod 49$ But it is still too big to calculate manually. So I wonder maybe one of you guys have another idea? Especially, I want to know whether I can use $49$ as $7*7$ and create two different modular equations and solve them in a way? maybe with CRT maybe with another method?","['chinese-remainder-theorem', 'totient-function', 'discrete-mathematics']"
2460475,"self-adjoint operator, such that $T^2=T^3,$ is orthogonal projection.","Let $T$ be a self-adjoint operator on a Hilbert space $H$, such that $T^2=T^3.$
  Prove that $T$ is an orthogonal projection. Is that true if we had $T^4=T^3$? Thank you for the help.","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'adjoint-operators']"
2460523,Convex function with discontinuous derivative,"I am interested in this question: Find a differentiable convex function such that its derivative is not continuous. I found out that we cannot find such function if its domain is $\mathbb{R}$, since every differentiable convex function $f\colon \mathbb{R} \to \mathbb{R}$ is continuously differentiable (as proved here ). Therefore we have to look for multivariable functions, but it is not an easy work. Thank you very much.","['derivatives', 'continuity', 'convex-analysis']"
2460541,Is this a correct way to prove T is not a linear transformation?,"I have the following transformation $T:\mathbb{R}^2 \longrightarrow \mathbb{R}^3$ defined by $T\left( x, y \right) = \left( y, x, x^2 + y^2 \right).$ I know the transformation is not linear but would like to prove it, so I deviced the following ""proof."" We know every linear transformation $T$ has a unique matrix representation for the standard basis of $\mathbb{R}^2,$ which is given by $$A = \left[ \begin{array}{ccc}
T(\mathbf{e}_1) & T(\mathbf{e}_2) \\\end{array} \right],$$
and this matrix $A$ would move me back to the linear transformation by $T\left( \mathbf{x} \right) = A \mathbf{x}.$ So, I assume $T$ is a linear transformation and construct it standard matrix representation, which would be $$A = \left( \begin{array}{ccc}
0 & 1 \\
1 & 0 \\
1 & 1 \end{array} \right).$$ Now, to get my original transfomation back I would have to do $$T\left( \mathbf{x} \right) = A \mathbf{x} = \left( \begin{array}{ccc}
0 & 1 \\
1 & 0 \\
1 & 1 \end{array} \right) \cdot \left( \begin{array}{ccc}
x \\
y \end{array} \right) = \left( \begin{array}{ccc}
y \\
x \\
x+y \end{array} \right).$$ Since this transformation I got is not the original one, I conclude $T$ is not a linear transformation. My question is, the above reasoning is correct? And in general, can I apply this method to prove or disprove any transformation is a linear transformation? EDIT: Please do not sugegst alternative methods of proof; I know them well. All I need is to know if the method described works.","['proof-writing', 'linear-algebra', 'linear-transformations']"
