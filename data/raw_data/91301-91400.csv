question_id,title,body,tags
1235427,"Squeeze Theorem: $\lim_{x\to 0} \, \frac{x^2}{\sin ^2(x)}$","I'm having a hell of a time understanding how to apply the Squeeze Theorem and the corresponding theorems to solving problems like the following. $\lim_{x\to 0} \, \frac{x^2}{\sin ^2(x)}$ So I can see that this is essentially the inverse of what Rogawski refers to as Theorem 2 (2.6, if you're following along at home...) $\lim_{x\to 0} \, \frac{\sin (\theta )}{\theta }=1$ And I'm fairly comfortable with the proof of that theorem. For the purposes of the assignment, however, I am still confused, in that I am supposed to apply this theorem to evaluate. I have some hazy notion that I can just invert the function and so deduce that the limit is 1 because the squeezing inequality still expresses important relation even when I take the reciprocal of each term, but that's not exactly the same as understanding the process here...","['calculus', 'limits', 'trigonometry']"
1235462,The mysterious $\dot{H}^{-1}$ notation.,"I have encountered the $\dot{H}^{-1}$ notation in one of the SIAM Journal on Mathematical Analysis articles. It appears to be standard (or at least not uncommon) to use this one in the field, since there is no formal introduction or definition of $\dot{H}^{-1}$ in the article itself, and because of the fact that it first appears in the abstract. Authors seem to be confident using expressions like $\dot{H}^{-1}$ norm, $\dot{H}^{-1} $ distance, $\dot{H}^{-1} $ gradient flow of energy, and others. I tried my best searching for it online and checking the article references, but could not figure it out. 
Can anyone give me a hint on where to find a definition of either of $\dot{H}^{-1}$ objects mentioned above? The article is devoted to the stability analysis of a certain type of solutions of a nonlinear PDE.","['analysis', 'notation', 'ordinary-differential-equations', 'partial-differential-equations']"
1235463,Derivative with respect to the normal?,"I am trying to use greens theorem to show the following:
$$\int \int (f_{xx}+f_{yy}) \, dx \, dy=\int\frac{\partial f}{\partial n} \, ds$$
I am not completely sure how to treat the $d/dn$.  I have simplified to a point where I have
$$\int f_x \, dy-f_y \, dx=\int \int (f_{xx}+f_{yy}) \, dx \, dy$$
So I need to go from the left side of the last equation to the right side of the first equation.  Any intuition on what the derivative implies?","['greens-theorem', 'multivariable-calculus']"
1235474,The number of linearly independent solution of the homogeneous system of linear equations $AX=0$,"I came across the following multiple choice question: The number of linearly independent solution of the homogeneous system of linear equations $AX=0$, where $X$ consists of $n$ unknowns and $A$ consists of $m$ linearly independent rows is $(A)$ $m-n$ $\space$$(B)$ $m$ $\space$$(C)$ $n-m$ $\space$$(D)$ none of these I think the answer will be $(D)$ because: When $m=n$, in this case it would mean a square matrix with all linearly independent rows, which implies unique solution. When $m<n$, it would mean that the rank of the matrix is less than number of unknowns in the system, which would mean infinite solutions and these solutions must be linearly dependent (Am I going right?). When $m>n$, there will be no solution (I am not sure about this one) I think there is something wrong about my answer because I remember something like: number of linearly independent solutions = number of unknowns - rank, from my Linear Algebra class. But I am not sure how to relate to it here.. Thanks..","['matrix-equations', 'linear-algebra', 'matrices']"
1235509,A Lemma about the operator space,"The following lemma comes from the book ""C*-algebras Finite-Dimensional Approximations"" by N.P. Brown and N. Ozawa P379 Lemma 13.2.3 Let $X_{i}\in B(H_{i})$ (i=1,2) be unital operator subspaces and let $\phi: X_{1}\rightarrow X_{2}$ be a unital complete isomery. Suppose that $X_{2}$ is spanned by unitary elements in $B(H_{2})$ . Then, $\phi$ uniquely extends to a -homomorphism between the C -subalgebras $C^{*}(X_{1})$ generated by $X_{i}$ in $B(H_{i})$ . Proof By Arveson's Extension Theorem, $\phi$ extends to a complete contractive map (i.e. $||\phi||_{cb}\leq1$ ) from $B(H_{1})\rightarrow B(H_{2})$ , which we still denote by $\phi$ . Since $\phi$ is unital, it has to be a u.c.p map. Since $\phi|_{X_{1}}$ is isometric and $X_{2}$ is spanned by unitary elements, $X_{1}$ is contained in the multiplicative domain of $\phi$ . Hence, $\phi$ is a *-homomorphism on $C^{*}(X_{1})$ . In the proof of this lemma, the author first use the ""operator space"" version of Arveson's Extension Theorem to get a c.c map $\phi$ from $B(H_{1})\rightarrow B(H_{2})$ . And then comes my question : The author says ""Since $\phi$ is unital, it has to be a u.c.p."" Why? The author says ""Since $\phi|_{X_{1}}$ is isometric and $X_{2}$ is spanned by unitary elements, $X_{1}$ is contained in the multiplicative domain of $\phi$ ."" Why?","['c-star-algebras', 'operator-algebras', 'functional-analysis']"
1235547,"Is $ (A × B) ∪ (C × D) = (A ∪ C) × (B ∪ D)$ true for all sets $A, B, C$ and $D$?","Is $(A \times B) \cup (C \times D) = (A \cup C) \times (B \cup D)$ true for all sets $A, B, C$ and $ D?$ I tried to wrap my head around this, but I have absolutely no idea what is going on here. How could I possibly go about trying to prove this? Or disprove it? Any help or guidance would be appreciated.",['elementary-set-theory']
1235554,Are all smooth functions bounded?,"in my book it says that when a function f is smooth, it also means that it is bounded. I understand that a smooth function has contineous derivatives of all orders, but how can we know that the function is bounded only by knowing it is smooth?","['real-analysis', 'general-topology', 'functions']"
1235594,Kruskal Wallis - Effect size,"I analyse 4 algorithms and 3 sets of metrics for each algorithm in which I apply the non-parametric Kruskal-Wallis test for each metric to detect any differences in performance between these algorithms. I would like to know whether there is a way to calculate the effect size when applying the Kruskal-Wallis test. As mentioned in other posts in CV, a post-hoc analysis for Kruskal-Wallis should use the Dunn's test and not the Mann-Witney test for pairwise comparisons between groups (algorithms). By applying the ""inaccurate"" MW test, I can calculate the effect size, but what can I do if I apply Dunn's test? Thanks in advance for any comment/advice. PS: I posted this question to CV some time ago, but I didn't receive any reply yet. Hence, I post it in this forum too.","['probability', 'statistics', 'statistical-inference']"
1235632,Time and distance: Police and a thief with a twist.,"A thief was given a head-start of 15 hour. The velocity of the thief being 4 km/hr and the police chasing after him be 5 Km/hr. A dog is moving to and fro between the police and the thief, starting from 
 the police at a velocity of 10 Km/hr. Every time the dog touches the thief it gives him a bite which reduces the speed of the thief by 10%. When will the police catch the thief? What would be the distance covered by the dog by that time? What would be the distance covered by the dog in the forward direction? Answer Not given. How can I get the answer without writing a program?","['arithmetic', 'puzzle', 'algebra-precalculus']"
1235637,Understanding angle-preserving definition,"My book (Real and complex analysis, by Rudin) gives the following definition: Let $A(z) = \frac z{|z|}$. Then we say $f$ preserves angles at $z_0$ if $$\lim_{r \to 0}e^{-i\theta} A[f(z_0 + re^{i\theta} )- f(z_0)] \ \ \ \ (r > 0)$$ exists and it is independent of $\theta$. It then adds The requirements is that fr any two rays $L'$ and $L''$ starting at
  $z_0$, the angles which their images $f(L')$ and $f(L'')$ make at
  $f(z_0)$ is the same as that made by $L'$ and $L''$ in size as well
  orientation I am trying to understand why the definition says that. Does anyone know of a cool geometric interpretation? My thoughts $A(z)$ returns a complex number on the unit circle whose argument is the argument of $z$. So $A(z - w)$ basically is a measure of the angle between $z$ and $w$. Now in the definition I take the angle between $f(z_0 + re^{i \theta})$ and $f(z_0)$, and divide it by $e^{i \theta}$ (meaning I rotate by $-\theta$ our number). Since the original angle between $z_0$ and $z_0 + re^{i \theta}$ is $\theta$, if I want angles to be preserved, I would like the result to have an argument of $0$, right? Why is instead required the limit to exists and be independent of $\theta$? Moreover, the reason why we take the limit is because we only care about local properties of the function, right? Finally, why was it defined this way? I mean one could be naive and define it like $$\lim_{r \to 0} \arg(f(z_0 + re^{i\theta}) - f(z_0)) = \theta$$. What's the reason this isn't a good definition for our purposes?","['analysis', 'conformal-geometry', 'complex-analysis', 'complex-numbers']"
1235652,How Differential got into calculus,"I am confused what differentials are and how they become related to derivatives and integrals, as neither my textbook explains them nor my teacher. What we do to solve differential equations is to convert derivative to a ""differential form"" like this: $$\frac{dy}{dx}= 2x$$ $$dy = 2xdx$$ When we substitute to solve integrals, differentials also come up there. I'm asking: How did we get differentials, what is their physical meaning (like derivative means slope, Integration results in area under curve). I would like someone gave me a little historical aspect. When did differentials come into the scene of calculus?",['calculus']
1235687,Schauder basis for $c_0$,"So, I am trying to prove that $c_0$ has the dual space $\ell^1$ (I know this proof is out there). Except my professor told me that  a Schauder basis for $c_0$ is $(e_k)$ where $ e_k = \delta_{j,k}$ has a 1 in the $k$th place and zeros otherwise is not correct (this is what every proof out there claims). He said that I need to think about this as a matrix to develop the basis. This disagrees with everything I have found up until now. He said that I have $e_k$ depended upon $1$ variable while $\delta$ is depended upon $2$. Below I state the wording of the problem. Can anyone help me write a proper Schauder basis. Represent $\ell^1$ as the space of all real functions $x$ on $S= \{(m,n): m\geq 1, n \geq 1\}$, such that
$$
\|x\|_1 = \sum |x(m,n)| < \infty. 
$$
Let $c_0$ be the space of all real functions $\gamma$ on $S$ such that $y(m,n) \rightarrow 0$ as $m+n \rightarrow \infty$, with norm $\|y\|_\infty = \sup |y(m,n)|$. \
 Let M be the subspace of $\ell^1$ consisting of all $x \in \ell^1$ that satisfy the equations
$$
mx(m,1) = \sum_{n=2}^\infty x(m,n)      \;\;\;\;\;\;\; (m = 1, 2, 3, \ldots)
$$","['linear-algebra', 'real-analysis', 'functional-analysis', 'schauder-basis']"
1235695,The inverse Laplace transform of $ s^{3/2}-a-bs \over s^{3/2}+a+bs$,"How can I solve the inverse Laplace transform as below: $$\mathscr{L}^{-1}\left( s^{3/2}-a-bs \over s^{3/2}+a+bs \right) $$ where a and b are constants. Hint: we can consider $${ s^{3/2}-a-bs \over s^{3/2}+a+bs} = {1 \over {1+as^{-3/2}+bs^{-1/2}}}-{a \over {s^{3/2}+bs+a}}-{b \over {s^{1/2}+as^{-1}+b}}$$ I applied residue theorem to each, and at the end I got 3 integrals which I could not solve, they are given by: $${1\over \pi} \int_{0}^{\infty}\left({{ax^{-3/2}-bx^{-1/2}}\over {1+(ax^{-3/2}-bx^{-1/2})^2}}\right) \exp(-xt)\,\mathrm{d} x, $$ $${a\over \pi} \int_{0}^{\infty}\left({{x^{3/2}}\over {x^3+(a-bx)^2}}\right) \exp(-xt)\,\mathrm{d} x, $$ and
$${-b\over \pi} \int_{0}^{\infty}\left({{x^{1/2}}\over {x+(b-ax^{-1})^2}}\right) \exp(-xt)\,\mathrm{d} x. $$ Thanks!","['inverse', 'integral-transforms', 'contour-integration', 'laplace-transform', 'integration']"
1235698,Can we determine whether $f\in L^{p}$ or not ; if we know $\hat{f}$,"Let $a_{n}:=\frac{1}{n}$ for all $n\in \mathbb Z\setminus \{0\}$ and $a_{0}= c$  where $c$ is some constant. Clearly, $a_{n}\in \ell^{2}(\mathbb Z)$, that is, $\sum_{n\in \mathbb Z} |a_{n}|^{2}< \infty.$ We define the function 
$$f(t):= \sum_{n\in \mathbb Z} a_{n} e^{int}, (e^{it}\in \mathbb T, \  t\in \mathbb R)$$ By the Riesz-Fischer theorem ,  it follows that $f\in L^{2}(\mathbb T).$ We also note that $L^{p}(\mathbb T) \subset L^{2}(\mathbb T), (p>2).$ My Question : (1) Is it true that $f\in L^{p}(\mathbb T), (p>2)$? (2) If we know $\hat{f} \in \ell^{2}(\mathbb Z);$  in which situation one can expect $f\in L^{p}(\mathbb T)(p>2)$? (Of course, in general one can not expect this, for instance there exist $f\in L^{2}$ which is not in $L^{p}$)","['fourier-analysis', 'lp-spaces', 'fourier-series', 'sequences-and-series', 'analysis']"
1235724,Does set theory help understand machine learning or make new machine learning algorithms?,"When I was in a university, I didn't major in math but took some math classes. However, I dropped out of math classes pretty quick. Some person recommended that I learn some set theory because it'll help me with Machine Learning . He recommended a book named Naive Set Theory by Halmos Other people say it's not going to help much because set theory lives on a far higher abstraction level than mathematics used in machine learning do. Since I don't know math well, I can't judge who's right. Can anyone tell me how set theory is going to help me with machine learning ?","['elementary-set-theory', 'machine-learning', 'advice']"
1235735,Differential equation with integration factor,"I tried to solve this differential equation: $$ydx+(2xy-e^{-2y})dy=0$$ I found $e^{2y}$ as integration factor but when affect this on equation I don't get $M_{y}$=$N_{x}$ (they are not exact)... Note
  : Thank you  LutzL.I made a deadly mistake integration factor equals to $e^{2y}$$/y$",['ordinary-differential-equations']
1235747,Is the given binomial sum almost everywhere negative as $K\to\infty$?,"The binomial sum is as follows: $$\mathcal {L}^K(\theta)= \sum_{i=\lceil{K/2}\rceil}^K \binom{K}{i}\theta^i\left((1-\theta)^{K-i}-\frac{1}{2}(1-\theta)^{-K}(1-2\theta)^{K-i}\right)$$ which can also be written as $$\mathcal {L}^K(\theta)= B(K/2,K,1-\theta)-\frac{1}{2}B\left(K/2,K,\frac{1-2\theta}{1-\theta}\right)$$
where $B$ is the Binomial c.d.f. It can be found that as $K\to\infty$, \begin{equation}
\quad\mathcal {L}^\infty(\theta)= \begin{cases} 0, & \mbox{if } \mbox{ $\theta<\frac{1}{3}$} \\ -\frac{1}{2} & \mbox{if } \mbox{ $\frac{1}{3}<\theta<\frac{1}{2}$} \end{cases}\nonumber
\end{equation} My question is however not about it. I want to show that $\mathcal {L}^K(\theta)$ is negative if $K$ is chosen large enough, for every $\theta\in(0,0.5)$. This question is equivalent to finding that the zero crossing point $\theta_0\in(0,0.5)$ of $\mathcal {L}^K$ tends to $0$ as $K\to\infty$ and for every $\theta>\theta_0$, $\mathcal {L}^K$ is negative. Notice that $K$ is an odd number for all cases. A mathematica plot confirms that it must be the case. Here is the plot: But I dont have any idea on how to show it. Does anyone have?","['polynomials', 'calculus', 'limits', 'binomial-coefficients']"
1235755,Is there an analytic solution for this Fokker-Planck equation?,"The Fokker-Planck equation for a probability distribution $P(\theta,t)$:
\begin{align}
\frac{\partial P(\theta,t)}{\partial t}=-\frac{\partial}{\partial\theta}\Big[[\sin(k\theta)+f]P(\theta,t)-D\frac{\partial P(\theta,t)}{\partial\theta}\Big].
\end{align}
where $f$, $k$, $D$ are constants, and the initial distribution is a delta function.","['statistical-mechanics', 'ordinary-differential-equations', 'stochastic-processes']"
1235759,"Is this a valid proof? Find $\lim_{(x,y) \to (0,0)}\frac{x^2+y^2}{\sqrt{x^2+y^2+1}-1}$","I ""solved"" this limit using polar coordinates, but my question is - is this a definite proof that the limit exists? Or maybe there is some path that I missed when I transformed to polar coordinates? $\lim_{(x,y) \to (0,0)}\frac{x^2+y^2}{\sqrt{x^2+y^2+1}-1}=\lim_{r \to 0} \frac{r^2}{\sqrt{r^2+1}-1}=\lim_{r \to 0}\frac{r^2}{r\sqrt{1+\frac{1}{r^2}}-1}=\lim_{r \to 0}\frac{r}{\sqrt{1+\frac{1}{r^2}}-1}=0$ So via polar coordinates, the limit is zero. But maybe there is a path I missed and the limit via that path does not tend to zero? Please note I am not asking just on this problem. My question is a general question - does polar coordinates shift cover all possible paths? Edit - Please Read : I realize I made a mistake, The $r$ in the denominator can't be cancelled it, I was careless and missed it. Thanks for the input. I am still very much interested in knowing if polar coordinates cover all paths, which is the original point of this question. Not to solve this particular problem.","['limits-without-lhopital', 'multivariable-calculus', 'limits']"
1235767,Stochastic dominance of Binomial and Poission,"In order to investigate the size of the cluster of a given vetex in a random graph I need to use a fact about stochastic dominance that I don't know how to prove. Namely, I am looking for a proof of the fact that $\text{Binom}(n, p)$ is stochastically dominated by $\text{Poi}(\lambda)$, where $\lambda=p(n+1)$ and $p\leq\frac{1}{n+1}.$ By stochastic dominace I mean the following: $\mu$ is stochastically dominated by $\nu$ if $\mu(A)\leq\nu(A)$ for any upward closed event $A \subseteq \mathcal{P}$ (i.e. $x \in A$ and $x \leq y \implies y\in A$). Thank you for your help in advance.","['probability-theory', 'random-graphs', 'probability-distributions']"
1235802,Why not every homogeneous manifold is parallelizable?,"It is obvious that not every homogeneous manifold is parallelizable (take for example the two-sphere $S^{2}$). In contrast, every Lie group $G$ is parallelizable, as you can construct a pointwise basis of left-invariant vector fields by acting with the adjoint action of the group onto himself. My question is, what fails if one tries to carry the same construction on an homogeneous space $M = G/H$? If I am not mistaken, one has a transitive action of $G$ on $M$, which could be used to generate left-invariant vector fields. Thanks.","['lie-groups', 'differential-geometry', 'lie-algebras']"
1235846,Do join and suspension commute?,"Do join and suspension of topological spaces always commute, i.e. is it true that $\sum(A\star B)=A\star(\sum B)$? I suppose that it is not true in general (but, for example, everything works in the case of two spheres), but perhaps there is an epimorphism from one space to another?","['algebraic-topology', 'general-topology']"
1235849,Evaluating: $I_1 = \int\sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) dx$,"$$I_1 =\int \sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) dx= ?$$ I tried substitution: $\sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) = \Xi$, but then I'm not able to do anything after the resulting integral. Could someone help? There must be a simple way to solve this...","['trigonometry', 'calculus', 'indefinite-integrals', 'integration']"
1235864,Chess Probability 8 rooks,"You have 8 rooks. What is the probability of placing all 8 rooks on an 8 by 8 chess board with out one being able to hit each other? But there's a catch of course..one of the spaces is unavailable to be used. That being said, there could potentially be 2 rooks in a certain row or column. The unavailable space is 7 columns over and 7 rows down. Without the catch it would be $\frac{8!}{64\choose 8}$ I came up with.. $\frac{8\cdot{7\choose 2}6\cdot6\cdot5\cdot4\cdot3\cdot2}{63 \choose 8}$ 
but I don't think I'm correct. 
Any advice/ideas?",['probability']
1235875,Solve $(x+1)^n-x^n=p^m$ in positive integers,"Solve in positive integers: $$(x+1)^n-x^n=p^m$$ $p$ is prime, $n\ge 2$. Seemingly Zsigmondy's Theorem and LTE won't work here. Though you can tell (as suggested by user barto), using Zsigmondy, that $n=q$ is prime and $p\equiv 1\pmod q$ (since $\text{ord}_p (1+x^{-1})=q\mid p-1$ by FLT). This is just a problem I've thought of (because I was solving diophantine equations of the form $x^n-y^n=p^m$ and the case $(x+1)^n-x^n=p^m$ is the only one that doesn't let me use Zsigmondy's Theorem directly to finish the problem) and I'm interested to hear a solution. Zsigmondy's Theorem tells us that $x^n-y^n$ (if $(x,y)=1, x>y+1, (x,y,n)\neq (2,1,6), \lnot(n=2\wedge (x+y=2^l, l\in\mathbb N))$) has at least $d(n)$ different prime divisors ($d(n)$ -- number of $n$ divisors), which is impossible ($d(n)\ge 2$). If $n=2\wedge (x+y=2^l, l\in\mathbb N)$, then we're left with $x-y=2^{m-l}$, which has infinitely many solutions, fully characterized by $(x,y)=(2^{m-l-1}+2^{l-1},2^{l-1}-2^{m-l-1})$. If $(x,y)\neq 1$ or $x=y+1$, we're left with having to know how to solve diophantine equations of the form $(x+1)^n-x^n=p^m$.","['number-theory', 'diophantine-equations']"
1235876,"How many pairs of polynomials $(U,V)\in \Bbb Z[x]^2$ such that $P=U^2+V^2$ for a given polynomial with integer coefficients?","This question is no more than curiosity question. For integers we know that a positive integer $n$ is a sum of two squares if and only if for any prime $p$ such that $p\equiv 3 \mod 4$ we have $v_p(n)$ is even, and we know also that the number of possible representations $n=x^2+y^2$ is $r_2(n)=4(d_{4,1}(n)-d_{4,3}(n))$. My question asks for similar results for other rings $\Bbb Z[x]$ for example Given a polynomial $P\in \Bbb Z[x]$ how many pairs of polynomials $(U,V)\in \Bbb Z[x]^2$ such that $P=U^2+V^2$ This can be interpreted in $\Bbb Z[i][x]$ as a factorization of $P$ but the problem is how many divisors $P$ in $\Bbb Z[i][x]$ may have, for example:
$x^2+1=(x+i)(x-i)=(x^2+1)1 $","['abstract-algebra', 'polynomials', 'number-theory']"
1235877,Does $\operatorname{div}\left(\nabla G +xG\right)=0\Longleftrightarrow \nabla G +xG=0$?,"Let $G$ be a smooth function defined on $\textbf{R}^d$. What are the assumptions I should use to assume that
$$\operatorname{div}\left(\nabla G(x) +xG(x)\right)=0 \quad (\forall x\in \textbf{R}^d)$$
implies that $G$ is a Gaussian? (Several answers are possible I guess...) Many thanks !","['partial-differential-equations', 'entropy', 'gaussian-integral', 'integration']"
1235891,What derivative should be taken for relative maxima and absolute maxima (or minima)?,I get confused on what derivative should be taken for defining relative maxima and absolute maxima because some sources said to use first derivative while the others said to use second derivative. Also is relative maxima same as local maxima? I really need detail with prove or example about them.,"['graphing-functions', 'derivatives']"
1235895,Proving vector Identities (Using the Permutation Tensor and Kroenecker Delta),Prove the following vector identities by using permutation tensor and kroenecker delta. $$(\vec{A} \times \vec{B}) \times (\vec{C} \times \vec{D}) = (\vec{A} \cdot (\vec{B} \times \vec{D})) \cdot \vec{C} - (\vec{A} \cdot (\vec{B} \times \vec{C})) \cdot \vec{D}$$ I started by assuming $\vec{F}=\vec{A} \times \vec{B} = \varepsilon_{ijk} A_j B_j$ and $\vec{E}=\vec{C} \times \vec{D} = \varepsilon_{mnp} A_n B_p$ Then $\vec{G} = \vec{F} \times \vec{E} = \varepsilon_{qim} F_i E_m = \varepsilon_{qim} \varepsilon_{ijk} \varepsilon_{mnp}A_j B_k C_n D_p$ After this I have dont know what else to do. Could be please give me some tipps. Thanks.,"['vector-analysis', 'multivariable-calculus', 'tensors']"
1235898,Prove the order of the group homomorphism of an element divides the order of the element.,"Let $\phi : G \rightarrow H$ be a group homomorphism. Prove $\forall g \in G$, the order of $\phi(g)$ divides $g$. I've gotten to the point where I've shown that if, $ord(\phi(g)) < ord(g)$
then $ord(\phi(g))$ divides $ord(g)$. But what I've done to just show this seems unnecessarily complicated.","['group-homomorphism', 'number-theory', 'abstract-algebra', 'group-theory', 'divisibility']"
1235957,Limit of a function of 3 variables,"I need help to evaluate the following limit please, I used to use polar coordinates in most 2 variable functions but here I am stuck. $\lim_{(x,y,z)\to(0,0,0)}$$\frac{xy+yz^2+xz^2}{x^2+y^2+z^2}$",['limits']
1235970,"Dice roll probability, at least 9 total?","If I have two dice with $6$ sides each, what is the probability of me rolling atleast $9$ total? I think I'm correct when thinking that the probability of rolling a $9$ is $\frac{4}{36}$, that is $11.1...\%$, but how do I go from here to calculate the ""at least"" part?","['dice', 'probability']"
1235977,How to construct a line with a given equal distance from 3 Points in 3 Dimensions?,"Important: I'm now convinced that 4 points are needes in order to reduce the solutions to a finite number. (Which is necessary because I need ALL solutions) In a computer science context I need to solve a geometrical problem which states: Given three points in three-dimensional space, find a line $L$ (in any form, e.g. specify two points which lie on the line) so that the distance between each of the points and $L$ are equal to a given distance $d$, if possible. By distance between a point $P$ and a line $L$, the euclidean distance between $P$ and the foot of the perpendicular on $L$ that passes through $P$ is meant. In two dimensions (given two points) this is rather simple as it involves only a few trigonometric functions, altough I really struggle with it in three dimensions. The reason surely is that I'm not from a math background and don't know too much about linear algebra (which I believe is involved here). It would be ideal if there is a solution for $N$ dimensions (I think that $N$ Points are needed then), altough I would be very happy if someone could give at least some hints about the three dimensional problem (maybe some sort of heuristic that i didn't thought of could also work). :) EDIT: Clarification The distance between the points and the line is a given constant . Example: 
Given three Points and a distance $d=3$, I want to find the line which has a distance of $d$ (in this case $3$) to every given point, if possible (of course there are many cases where such a line does not exist). And I am aware of the fact that this line is not unique (several, or in case of colinearity of the three points, infinitely many lines exist) EDIT: Clarification II It seems that my wording causes much confusion about exactly WHAT properties the line should have. A picture showing the two-dimensional case follows: In this case the Points $P_1$ and $P_2$ are given and the task was to find the line $g$ such that every given Point has the same shortest distance $r_B$ (which is preset) to $g$. (In this context the line was specified by a point $C$ and the angle $\alpha$, altough I'm happy with any kind of parameterization). Now I have given 3 three-dimensional points and want to find a line with the described properties and I do not have any idea how to do this. EDIT III: I should also have mentioned that I should be able to find all solutions (I am 99% convinced that there is only a finite number of solutions for ordinary cases)","['euclidean-geometry', 'geometry', 'linear-algebra', 'trigonometry']"
1235983,"Distribution of $\| W_t \|^2_{L^2([0,T])}$","Motivation: consider the SDE $$dX_t = b(X_t) dt + \sqrt{\varepsilon} dW_t. \tag1$$ Consider the action, defined by $$S(\phi)=\int_0^T |\phi'(t)-b(\phi(t))|^2 dt$$ if $\phi \in H^1([0,T])$ and $+\infty$ otherwise. If $\phi$ is a sample path of $(1)$, then we can rearrange to see that $S(\phi)=\varepsilon \| W_t \|^2_{L^2([0,T])}$, where $W_t$ is the particular Brownian motion which drives $\phi$. I think this implies that the probability density of the paths is $\phi \mapsto f_\varepsilon(S(\phi))$ where $f_\varepsilon$ is the probability density for $\varepsilon \| W_t \|^2_{L^2([0,T])}$. So I get the question: what are the properties of the distribution of $\| W_t \|^2_{L^2([0,T])}$? The one thing that I think I have correctly derived is: $$\mathbb{E} \left ( \| W_t \|^2_{L^2([0,T])} \right ) = \mathbb{E} \left ( \int_0^T W_t^2 dt \right )= \int_0^T \mathbb{E} \left ( W_t^2 \right ) dt = \int_0^T t dt = T^2/2.$$ Any information about the distribution of this quantity, for instance how to compute its variance, would be appreciated. Edit: Nate Eldredge has pointed out that my motivation, while intuitive, does not really work when treated formally as written, because $S(\phi)=+\infty$ with probability $1$. So I would also be interested in some description, formal or informal, of the extent to which $S$ and the distribution of paths of (1) are connected.","['probability-theory', 'stochastic-processes']"
1235985,Almost sure convergence of a sequence of Gaussians with vanishing variance,"Let $(X_n)_{n\geq 1} $ a sequence of independent random variables. We assume that $X_n \sim \mathcal{N}(0,\sigma_n^2)$ and that $(\sigma_n)_{n\geq 1}$ is a vanishing sequence of positive numbers. Let $\delta_0$ be the Dirac law with mass at $0$. Using Lévy's continuity theorem, it is easy to see that $(X_n)_{n\geq 1} $ weakly converges to $\delta_0$. My question is : does $(X_n)_{n\geq 1} $ almost surely converges to $0$ ? A natural way to prove the (potential) almost sure convergence would be to use the Borel-Cantelli lemma. It tells us that, if $\sum_{n\geq 1}\mathbb{P}(|X_n|\geq\varepsilon)<\infty$ for all $\varepsilon >0$, then $X_n \overset{a.s}{\longrightarrow} 0$. Using a variant of Chebyshev's inequality, we can see that, for all integer $p\geq 2$, $$\mathbb{P}(|X_n|\geq\varepsilon )\leq\frac{\mathbb E |X_n|^p}{\varepsilon^p}=\frac{\mu_p}{\varepsilon^p}\sigma_n^p$$where $\mu_p$ is the $p$-th moment of the standard Gaussian. which leads to $$\sum_{n\geq 1}\sigma_n^p<\infty \;  \text{for some} \;p \Rightarrow (X_n \overset{a.s}{\longrightarrow} 0). $$ Is is possible to obtain a more general result? Or to find a necessary and sufficient condition on the speed of convergence of $(\sigma_n)_{n\geq 1}$ for $(X_n \overset{a.s}{\longrightarrow} 0)$ to be true?","['probability-theory', 'normal-distribution', 'almost-everywhere', 'random-variables', 'convergence-divergence']"
1236000,Solve differential equation $f'(z) = e^{-2} (f(z/e))^2$,"I'm curious if there's a simple closed solution to the following DE and, if so, what it is. $$\begin{align}
f'(z) &= e^{-2} (f(z/e))^2 \\
f(0) &= 1.
\end{align}$$","['ordinary-differential-equations', 'functional-equations']"
1236022,"How many ways to order vectors in $\{0,1\}^n$?","How many different rankings can be produced for the vectors in $\{0,1\}^n$ that also respect the usual $\geqq$ ordering of vectors (defined below)? I want to produce a complete ordering where, for $x\neq y$, if $x_i \geq y_i$ for all $i=1,\dots,n$ then $x$ is greater than $y$ according to that new vector ordering. This leaves some freedom in the ordering where I could have $(1,0,0) > (0,1,1)$ as a possibility. $(1,0,0) < (0,1,1)$ is also allowed. Example: For $n=2$, there are two rankings. $(1,1) \geq (0,1) \geq (1,0) \geq (0,0)$ and $(1,1) \geq' (1,0) \geq' (0,1) \geq' (0,0)$.","['order-theory', 'combinatorics']"
1236038,$f$ is holomorphic iff $df$ is $\Bbb C$-linear,"Let $\Omega\subseteq\Bbb C^n$ open connected, $f:\Omega\to\Bbb C$ differentiable in the real sense. We know that $f$ is holomorphic iff $\partial_{\bar z_j}f=0\;\;\forall j=1,\dots,n$ . We know also that $df=\partial_zfdz+\partial_{\bar z}f d\bar z=:\partial f+\bar{\partial}f$. How can I prove from this that $f$ is holomorphic iff $df$, which is in general $\Bbb R$-linear, is now $\Bbb C$-linear? We know by definition that such an $f$ is differentiable in the complex sense in $w\in\Omega$ iff $\;\exists\; T:\Bbb C^n\to\Bbb C$ $\Bbb C$-linear such that
$$
\lim_{z\to w,z\in\Omega}\frac{f(z)-f(w)-T(z-w)}{||z-w||_{\Bbb C^n}}=0
$$
and being $T=df$ we can conclude. But I would like to prove it directly, using that $df=\partial f+\bar{\partial}f$, showing that $df$ is $\Bbb C$-linear iff $\bar{\partial}f=0$. Even because trying in different ways it seems that $df$ be always $\Bbb C$-linear, and this is wrong, so showing what I've asked I'd shed some lights on this. Can somebody give me some hints? Many thanks!","['several-complex-variables', 'complex-analysis']"
1236054,How to determine $\lim_{h \to 0}\frac{g(h+1)-g(1)}{h}$,"It is given that $g(x) = x^{20}$ Determine $$\lim_{h \to 0} \frac{g(h+1)-g(1)}{h}$$ Can someone give me a hint please? I worked it out to be so far as:
$$\lim_{h \to 0} \frac{(1+h)^{20}-1}{h}$$ The exponent of power $20$ is quite problematic. Any hints? Note : I have to do it using first principles.","['calculus', 'derivatives']"
1236069,Problems with a proof involving graphs and groups,"I'm studying an article that is the main literature when it comes to non-commuting graph : this article . Originally, a non-commuting graph of a group (denoted by $\Gamma_G$)  is a graph whose vertices are the elements of the group and they're joined by a edge if $[x,y]$ is not trivial, that is, if they don't commute like elements of the group. The article that I'm studying they made a little change: they consider the vertices the elements of $G$ that are not in the center, that is, $G-Z(G)$. My problem is the proof of Preposition 2.4. Let $G$ a non-abelian group and let $S$ a cut set of $\Gamma_G$.  If $x$ and $y$ two vertices of $\Gamma_G$\ $S$ belong to distinct connected components, then $S$ is a union of double cosets of $C_G(x)\cap C_G(y)$. In particular, if $G$ is finite, then $\kappa(\Gamma_G)=t\mid Z(G)\mid$, where $t>1$ is an integer. Proof: Let $H=C_G(x)\cap C_G(y)$ and $a\in G$ such that $HaH\cap S\neq\emptyset$. Then $HaH\subseteq S$, for if there exist elements $h_1, h_2\in H$ such that $h_1ah_2\notin S$, then $\{x,h_1ah_2\}$ and $\{y,h_1ah_2\}$ are edges of $\Gamma_G$, a contradiction. And continues... Well, I got the contradiction, but why if $h_1ah_2\notin S$, then $\{x,h_1ah_2\}$ and $\{y,h_1ah_2\}$ are edges? I could see why necessarily $[x,h_1ah_2]$ and $[y,h_1ah_2]$ are not trivial in this case. Thank you!","['graph-theory', 'group-theory']"
1236073,Prove that $\int_0^1 \frac{dx}{f^2(x)+1} \le \frac{ \pi}{4}$,"Let $f:[0,1] \to \mathbb{R}$ be a differentiable function, for which $f'(x) \ge 1 , \forall x\in [0,1]$, and $f(1)=1$. Prove that: $$\int_0^1 \frac{dx}{f^2(x)+1} \le \frac{ \pi}{4}$$ From the hyphotesis, we deduce that $f(0) \le 0$. This doesn't help very much, because if we write $$\int_0^1 \frac{dx}{f^2(x)+1} \le \int_0^1 \frac{f'(x)}{f^2(x)+1} dx =\arctan(f(x))|_0^1=\frac{ \pi }{4}-\arctan(f(0)) \ge \frac{ \pi }{4}$$ Another attempt is: We notice that $ \frac{ \pi }{4} = \int_0^1 \frac{dx}{x^2+1}$, so we only need to prove that $\int_0^1 \frac{dx}{f^2(x)+1} \le \int_0^1 \frac{dx}{x^2+1}$. This can be written as:
$$ 0 \le \int_0^1 \frac{(f(x)-x)(f(x)+x)}{(x^2+1)(f^2(x)+1)} dx $$
whichi, I think, isn't very easy to prove. Also, I tried to use that the function $x \to f(x)-x$ is increasing (in fact, I used it when I proved that $f(0) \le 0$), but nothing.",['real-analysis']
1236083,$f(x)$ is convex $\Leftrightarrow f'$ is monotonically increasing,"How can I prove that $f(x)$ is convex on an interval if and only if $f'(x)$ is monotonically increasing ? • Let $\lambda \in (0,1)$ and $x,y \in I$. $f(x)$ is convex on an interval, if the statement  $f((1-\lambda)x + \lambda y) \leq (1-\lambda)f(x) + \lambda f(y) $ is true for all $x,y$. • $f'(x)$ is monotonically increasing on an interval $I$, if $0 \leq \frac{d f'(x)}{dx}$ is true for all $x \in I$. I don't have a problem understand this, with a graph it's quite easy to understand. But I can't manage to prove it formally, can someone give me a hint? Note that I do have seen this question , but since I can't use inequality proven previously it doesn't help me.","['analysis', 'real-analysis']"
1236092,Probability of cartesian product of events,"Suppose we have $n$ experiments performed independently. Every $j$ -th experiment has a probability space $(\Omega_j, F_j, P_j)$ associated to it. The outcome of $n$ experiments is a sequence $(w_1, \ldots, w_n$ ) - $w_j$ is the outcome of $j$ -th experiment. Then our sample space (we conduct $n$ experiments) is $\Omega = \Omega_1 \times \Omega_2 \times \cdots \times \Omega_n$ . $$F=F_1\otimes \cdots \otimes F_n \tag{1}.$$ Then probability $P$ should satisfy the property that $P(A) = P_j(A_j)$ where $A_j \in F_j$ , i.e. \begin{align}
P(A_1 \times A_2 \times \cdots \times A_n) &= P(A_1 \times \Omega_2 \times \cdots \times \Omega_n) \times \cdots \times P(\Omega_1 \times \cdots \times A_n) \\
&= {} P_1(A_1) \cdot P_2(A_2)\cdot \cdots \cdot P_n(A_n).
\tag{2}
\end{align} There exists only one $P$ , namely $$P=P_1\otimes P_2\otimes P_3 \otimes \cdots \otimes P_n. \tag{3}$$ Questions It makes sense to me that if we have several experiments with respective sample spaces, then conducting them all gives a sample space that is their Cartesian product. Could you explain what does it all mean? $1.$ What does $(1)$ mean and why is it true? $2.$ I understand the first term - the probability of Cartesian product of events. Why is it equal to the right side and how we obtain the second and third term in this equality (by term I mean the part after the 1st and 2nd '=' sign). For example, after 1st equality sign there is a Cartesian product of probabilities. How can we have Cartesian product of numbers? Isn't it a mistake? Anyway, this equality follows from the above statement 'Then probability $P$ should satisfy the property that $P(A) = P_j(A_j)$ , but I'm not sure what's the connection. $3.$ Again, what does it mean and why is that?",['probability']
1236137,immersion of punctured torus in plane,"Let $S^1 \times S^1$ be the $2$-torus.  If a point $a=(p,q)$ of the torus is removed, i.e., it is punctured at one point then how can I show that it can be immersed in the plane, i.e., in $\Bbb{R}^2$? I have the idea of decomposing the punctured torus into two intersecting cylinders and then immersing each of them to $\Bbb{R}^2$, but the problem is by this way even if we make that the intersecting region mapped to same region, we cannot define an immersion on the whole the two immersions may not agree pointwise on the intersection.  I have got stuck here. Thanks in advance for any kind of help.","['differential-topology', 'differential-geometry']"
1236147,Logarithm multivariable limit $\frac{\ln(1+x^3+y^3)}{\sqrt{x^2+y^2}}$,"Find multivariable limit $$\lim_{\left( x,y \right) \rightarrow (0,0)}\frac{\ln(1+x^3+y^3)}{\sqrt{x^2+y^2}}$$
I was trying to find and inequality i've found out that:
$$\frac{\ln(1+x^3+y^3)}{\sqrt{x^2+y^2}} \le \frac{\sqrt{x^2+y^2} \ln(1+x^3+y^3)}{2xy} $$
and after that i am stuck. From iterated limits i've calculated before i knwo that the limit exists for certain. I have also another idea to do that precisely to $y=x$ and $y=-x$ but i do not know whether this is working properly.","['limits', 'logarithms', 'functions', 'multivariable-calculus', 'inequality']"
1236177,Product of schemes and ideal sheaves,"Let $X \subset \mathbb{P}^n$ and $Y \subset \mathbb{P}^m$ be projective schemes over $\mathbb{C}$. Then, 1) Is the structure sheaf of $X \times_{\mathbb{C}} Y$ isomorphic to $\mathcal{O}_X \otimes_{\mathbb{C}} \mathcal{O}_Y$? 2) Is the ideal sheaf of $X \times_{\mathbb{C}} Y$ in $\mathbb{P}^n \times \mathbb{P}^m$
isomorphic to $\mathcal{I}_{X|\mathbb{P}^n} \otimes_{\mathbb{C}} \mathcal{I}_{Y|\mathbb{P}^m}$?","['algebraic-geometry', 'schemes']"
1236206,Proving the Derivative of cosine and sine functions,"In the proof of the derivatives of cosine and sine functions, we used the facts that: $$\lim\limits_{\Delta x \to 0} \frac{\cos \Delta x - 1}{\Delta x} = 0$$ and $$\lim\limits_{\Delta x \to 0} \frac{\sin \Delta x}{\Delta x} = 1.$$ I saw the proof of these two facts but it's said that $x$ here must be in radians, so why it must be measured in radians?","['derivatives', 'calculus', 'trigonometry']"
1236230,"If $A$ is a square matrix and $A^2 = 0$ then $A=0$. Is this true? If not, provide a counter-example.","This is a proof question and I am not sure how to prove it. It is obviously true if you start with $A = 0$ and square it. I was thinking: If $ A^2 = 0 $ then
$ A A = 0 $ $ A A A^{-1} = 0 A^{-1}$ $I\,A = 0 $ but the zero matrix is not invertible and that it was not among the given conditions. Where's a good place to start?","['examples-counterexamples', 'linear-algebra', 'nilpotence', 'matrices']"
1236246,Given $\mathbb{E}[X|Y] = Y$ a.s. and $\mathbb{E}[Y|X] = X$ a.s. show $X = Y$ a.s.,"Given $X,Y \in L^2(\Omega,\mathscr{F},\Bbb{P})$ such that $\mathbb{E}[X|Y] = Y$ a.s. $\mathbb{E}[Y|X] = X$ a.s. show that $\Bbb{P}(X = Y ) = 1.$ $Attempt: $ I can see that $\mathbb{E}[X|Y] = Y$ means $$ \int_{\{Y\in{A}\}}X \, d\Bbb{P} = \int_{\{Y\in{A}\}}Y \, d\Bbb{P} $$ for any
$A \subset{\Bbb{R}} $ Borel, so $$ \int_{\{Y\in{A}\}}X - Y \, d\Bbb{P} = 0 $$ over any such sets. Similarly for sets of the form $\{X \in A \}$. Now if I could show that $ \int_U X - Y \, d\Bbb{P} = 0$ for any set $U \subset \Omega$ of the form $\{X \lt a, Y \lt b\}$ for $a,b \in \Bbb{R}$ then I'd be done, because sets of that form are a $\pi$-system that generates $\sigma(X,Y)$, so I'd have (by a lemma) that the integral of $X-Y$ vanishes on all $\sigma(X,Y)$ sets - so of course, it would be zero. But I can't work out how to do that. I'm given the hint that 
$$ \int_{ \{ X \gt c, Y \le c \} } X - Y \, d\Bbb{P} + \int_{ \{ X \le c, Y \le c \} } X - Y \, d\Bbb{P} = 0 \; \text{for all} \; c $$ because that's the integral over $\{Y\le c\}$, a set of the above form. With the condition that $X$ and $Y$ are integrable, this is exercise 9.2 in Williams' ""Probability with Martingales"". Driving me up the wall to get so stuck on what seems such a simple exercise!","['probability-theory', 'conditional-expectation']"
1236269,Looking for info on power set functor,"I was reading here about the various functors which take a set $S$ to its power set. In particular, there is the normal contravariant one, and two covariant ones, which the article calls $\exists$ and $\forall$. I'd like a little more information on these functors and their properties. In particular, I'm interested in how these might play in to proofs in point-set topology...for instance the relation between the fact that $\forall$ plays nice with intersections and the fact that the regular forward image plays nice with intersections as long as at most one of the sets fails to be saturated. I think these might provide a simple way to look at the rules we need to remember when we manipulate sets in point-set topology. (I previously wrote a poor version of this question here , and this is a new version.)","['elementary-set-theory', 'general-topology', 'category-theory']"
1236299,Can $\oint_{|z|=2}z^3 \bar {z} e^\frac{1}{(z-1)} dz$ be solved?,How we can calculate the result of following Integral? $$\oint_{|z|=2}z^3 \bar {z} e^\frac{1}{z-1} \mathrm{d}z$$,"['contour-integration', 'calculus', 'definite-integrals', 'integration']"
1236302,"How to show that $f : \mathbb{R}^n → \mathbb{R}^n$, $f(x) = \frac{h(\Vert x \Vert)}{\Vert x \Vert} x$, is a diffeomorphism onto the open unit ball?","Could anyone help me with the following problem? The problem Fix $\varepsilon \in (0, 1)$ and choose a smooth function $h$ on $[0,\infty)$ such that $h'(t) > 0$ for all $t ≥ 0$, $h(t) = t$ for $t \in [0, \varepsilon]$, $h(t) = 1 − \frac{1}{\ln t}$ for all $t$ large enough. (You don’t have to explain why such a function exists.) Consider the map $f : \mathbb{R}^n \rightarrow \mathbb{R}^n$, $f(a) = \frac{h(\lVert a \rVert)}{\lVert a \rVert} a$, where $\lVert a \rVert = \sqrt{ (a^1)^2 + \cdots + (a^n)^2}$ is the usual Euclidean norm. Show that $f$ is a diffeomorphism of $\mathbb{R}^n$ onto the open unit ball $B \subset \mathbb{R}^n$. What I have so far (see edit below) In order to show that $f$ is a diffeomorphism it is enough to show that $f \in C^{\infty}$, the Jacobian is nowhere zero, $f$ is a bijection. I've shown that $f$ is a bijection onto $B$. I've also shown that $f = id$, the identity function, on $\overline{B_{\varepsilon}(0)}$ (i.e. the closed ball with radius $\varepsilon$ centered at the origin). But what about outside of $\overline{B_{\varepsilon}(0)}$? There we don't know that much about $h$, and so finding the Jacobian is not so easy. Should I look at the following partial derivatives in order to figure out the Jacobian?
$$\frac{\partial f^i}{\partial x^j} = \frac{\partial \frac{h(\lVert x \rVert)}{\lVert x \rVert} x^i}{\partial x^j}$$ Any help is greatly appreciated! Edit: We have that $h^{-1}$ is differentiable (even smooth since $h$ is smooth) and its derivative by the Inverse Function Theorem. We also have that $\Vert f(x) \Vert = h(\Vert x \Vert )$, and $\frac{f(x)}{\Vert f(x)\Vert } = \frac{x}{\Vert x\Vert }$. So $f$ is a bijection, with $f^{-1}(x) = h^{-1}(\Vert x\Vert )\frac{x}{\Vert x\Vert }$. Now, I was just wondering, since we have that $f$ is a bijection, $f \in C^{\infty}$ (since it is a composition of $C^{\infty}$-functions), and $f^{-1} \in C^{\infty}$ (since it also is a composition of $C^{\infty}$-functions), does it not follow that $f$ is a diffeomorphism?","['smooth-manifolds', 'differential-geometry', 'manifolds']"
1236308,Logic behind the combo of cards in a hand that contain only clubs,"In looking at a stats problem where you want all combos of a 5-card hand that contain at least one club, the approach I have is to find the combos of 5-card hands that do not contain clubs, and then subtract it from the total number of 5-card hand combos, so this would be the following: $$\left(\begin{array}{c} 52 \\ 5 \end{array}\right) - \left(\begin{array}{c} 39 \\ 5 \end{array}\right)$$ I am pretty sure the above approach is correct. What I'm curious about is why the logic does not flow to the multiplication rule? Is it not that if we know all 5-card combinations of Hearts, Diamonds, and Spades, then we can multiply these together to get all possible 5-card combinations of these suits? By that logic, the following should be the same as the above, but its not. $$\left(\begin{array}{c} 52 \\ 5 \end{array}\right)-\left(\begin{array}{c} 13 \\ 5 \end{array}\right)\cdot \left(\begin{array}{c} 13 \\ 5 \end{array}\right)\cdot \left(\begin{array}{c} 13 \\ 5 \end{array}\right)$$ Perhaps I'm not seeing something obvious. Can anyone shed any light?","['combinations', 'probability', 'statistics']"
1236319,Matrix multiplication memorisation,"So I'm writing an exam about matrices in a few weeks time, and I'd like to know if anybody has any tips about multiplying matrices.","['self-learning', 'learning', 'matrices']"
1236339,How to prove $E[e^{e^y}]=\infty$? y is a normal random variable,"The question is, given $Y\sim N(\mu,\sigma^2)$, how to prove$E[e^{e^Y}]=\infty$? I tried to look Y as some kind of Ito's process and apply Ito's formula to it but it doesn't make sense. Next I tried to use variable change $u=e^y$ and I still can't prove it. Is there anyway to do that?","['normal-distribution', 'probability', 'statistics', 'stochastic-processes']"
1236356,"$f$ convex and concave, then $f=ax+b$","Let $f$ be a real function defined on some interval $I$. Assuming that $f$ both convex and concave on $I$, i.e, for any $x,y\in I$ one has
$$f(\lambda x+(1-\lambda)y)=\lambda f(x)+(1-\lambda)f(y),\, \, \lambda\in (0,1) .$$ I would like to show that $f$ is of the form 
$f=ax+b$ for some $a,b$. I was able to prove it when $f$ is differentiable, using the relation 
$$f'(x)=f'(y).$$ Anyway, I was not able to provide a general proof (without assuming that $f$ is differentiable, and without assuming that $0\in I$). Any answer will be will be appreciated. Edit: It is little bit different from tte other question How to prove convex+concave=affine? . Here $f$ is defined on some interval, so $o$ not necessary in the domain. Please remove the duplicate message if this possible","['analysis', 'real-analysis']"
1236388,"Volume of a parallelepiped, given 8 vertices","Given the eight vertices $(0,0,0)$, $(3,0,0)$, $(0,5,1)$, $(3,5,1)$, $(2,0,5)$, $(5,0,5)$, $(2,5,6)$, and $(5,5,6)$, find the volume of the parallelepiped. I'm having trouble finding the 1 vertex and 3 vectors needed to find the volume. The closest four vertexes I found so far are $(0,0,0), (3,0,0), (0,5,1), (3,5,1)$...is using those four vertexes correct? Any starting hints to point me in the right direction?","['calculus', 'matrices', 'algebra-precalculus', 'geometry', 'trigonometry']"
1236399,In a 30-60 right triangle the side opposite the 30 degree angle is half the length of the hypotenuse. Why? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question In a 30-60 right triangle the side opposite the 30 degree angle is half the length of the hypotenuse. A statement from the trigonometry section of Simmons' Precalculus in a nutshell . Please explain.","['geometry', 'triangles', 'trigonometry']"
1236404,Integrating with respect to a linear combination of two signed measures,"Let $(X, d)$ be a metric space and $\mathcal{B}(X)$ the Borel $\sigma$-algebra of X. Let $\mu, \nu$ be two real-valued signed measures defined on $(X, \mathcal{B}(X))$ and $f : X \to \mathbb{R}$ Borel measurable, $\alpha, \beta \in \mathbb{R}$. Can anyone explain to me if the following takes place
$$\int f(x) d(\alpha \mu + \beta \nu)(x) = \alpha \int f(x) d\mu(x) + \beta \int f(x) d\nu(x)?$$ Thank you!","['lebesgue-integral', 'measure-theory']"
1236413,Globally Lipschitz implies solutions exist for all time,I understand when you have a locally lipschitz functiion $f$ for the IVP you are guaranteed the existence and uniqueness of a solution. However this solution may not exist for all time. Why is it that with a globally lipschitz function solutions do exist for all time?,['ordinary-differential-equations']
1236415,is every totally geodesic submanifold the set of fixed points of some isometries?,"It is well known that the set of fixed points of an isometry $\phi:(M,g)\rightarrow (M,g)$ is a totally geodesic embedded submanifold. (e.g here ). I ask whether the converse is true, i.e is every totally geodesic embedded submanifold $N \subset M$ can be realized as the set of fixed points of some isometries? One trivial obstruction is that $N$ should be closed. (Since the $Id,\phi $ are continuous and the diagonal in $M \times M$ is closed, the set of fixed points is always closed in $M$). So, if we assume $M$ is connected, then of course we have to omit from our discussions open submanifolds (which I think are all totally geodesic but cannot be closed, hence cannot be a fixed-points-set). Update: The answer is negative. A brief summary of the idea: take a small enough compact geodesic segement. Any isometry which fixes it, must ""fix some more"" of the whole geodesic the segment is a part of. Now I wonder if every such submanifold must be the fixed point of some diffeomorphism(s)? (not necessarily an isometry).","['isometry', 'riemannian-geometry', 'group-actions', 'differential-geometry', 'geodesic']"
1236426,Initial and final topologies,"Suppose that $X_i$ are topological spaces, and $X_i \xrightarrow{f_i} Y$ are a family of maps into the set $Y$. The final topology on $Y$ is defined to be the finest topology on $Y$ such that each $f_i$ is continuous. I have also heard it described as ""the topology on $Y$ consisting of the images of saturated open sets in $X_i$"", but it seems this requires that every $y\in Y$ is in the image of some $X_i$. It also makes sense that we would mostly be interested in the final topology when $Y = \cup_i f_i(X_i)$; otherwise we just have this chunk of $Y$ hanging around with the discrete topology on it. Dually, suppose we have $X \xrightarrow{g_i} Y_i$ and we want to give $X$ the initial topology. Now is there some reason why $g_i$ should separate points? (I think this would be the dual requirement to $Y$ being the image.) Maybe if it does not, then points not separated are topologically indistinguishable? Would we ever care about the initial topology with respect to a single map which was not injective? The separating points reminds me of the characterization of initial topologies as separating points from closed sets","['elementary-set-theory', 'general-topology']"
1236465,Euclidean distance and dot product,"I've been reading that the Euclidean distance between two points, and the dot product of the two points, are related. Specifically, the Euclidean distance is equal to the square root of the dot product. But this doesn't work for me in practice. For example, let's say the points are $(3, 5)$ and $(6, 9)$ . The Euclidean distance is $\sqrt{(3 - 6)^2 + (5 - 9)^2}$ , which is equal to $\sqrt{9 + 16}$ , or $5$ . However, the dot product is $(3 * 6 + 5 * 9)$ , which is $63$ , and the square root of this is not $5$ . What am I getting wrong?","['vectors', 'linear-algebra']"
1236472,Cauchy–Riemann equation on differntiability,"I have found that: $U_x = -\exp(y)\sin(x) $ $U_y = \exp(y)\cos(x) $ $V_x = \exp(y)\cos(x) $ $V_y = \exp(y)\sin(x) $ I need to show that $U_x=V_y$ and $U_y=-V_x$, however these aren't satisfied? does that mean $f$ is not differentiable?",['derivatives']
1236489,"Generating the Borel $\sigma$-algebra on $C([0,1])$","We put $S=C([0,1])$ (the collection of continuous real functions on $[0,1]$), equipped with the metric $d(f,g)=\sup_{x\in[0,1]}|f(x)-g(x)|$, and let $\mathcal{B}(S)$ be the Borel $\sigma$-algebra on $S$. I'd appreciate some quidance on proving that $\mathcal{B}(S)$ is generated by the collection of sets of the form
$$
\{f: (f(t_1),\ldots, f(t_n)\in B_1\times\cdots \times B_n\},
$$
where $B_j\in \mathbb{B}(\mathcal(R))$, $n<\infty$ and $0\le t_1<t_2<
\cdots t_n\le 1$. I know that $S$ is complete and separable, but need some help on how to proceed.","['probability-theory', 'stochastic-processes', 'measure-theory']"
1236513,"Probability - something with a small chance of occurring, but is repeated multiple times.","For example, if you have a $1.5\%$ chance of obtaining admission to any school and you apply to $15$ schools what is the chance that you'll get into a least $1$ school? Is this as simple as $1.5\%$ $×$ $15 $= $22.5\%$ chance of getting into one school? Phrased another way: if an event has a $1.5\%$ chance of occurring every time it is performed, and you perform it $15$ times what is the probability that the event occurs at least once?","['probability', 'statistics']"
1236550,How do we integrate $(e^x + 2x)^2$?,"I need to integrate $$\int(e^x+2x)^2dx.$$ I tried breaking it into $$\int(e^x+2x)(e^x+2x)dx$$ and then integrating by parts, but got stuck at 
$$
\int (e^x + 2x)^2\,dx = 
(e^x+2x)(e^x+x^2)-\int(e^x+2x)(e^x+x^2)dx
$$","['calculus', 'indefinite-integrals', 'integration']"
1236570,Solve congruence using fermat's theorem [duplicate],"This question already has answers here : Prove congruence using fermat's thm (5 answers) Closed 9 years ago . Hi I am given this problem and I am supposed to use fermat's theorem.
Here is it is:
Prove that
$$24^{31} \equiv 23^{32} \pmod{19}$$ We are supposed to solve it by setting up the congruence like this: $$24^{31} \equiv x \pmod{19}$$ $$23^{32} \equiv x \pmod{19}$$ I am just confused how to break it down. 
I was hoping someone can guide me through this question","['congruences', 'discrete-mathematics']"
1236571,Automorphism group of direct product of groups,"I was working on a problem in group theory, which asks about the automorphism group of a direct product of groups. Okay, so I know that if $G,H$ are two groups whose orders are relatively prime, then $\operatorname{Aut}(G\times H)\cong\operatorname{Aut}(G)\times \operatorname{Aut}(H)$. I also know that if $G,H$ are abelian and simple and isomorphic, then $\operatorname{Aut}(G\times H)\cong \operatorname{GL}_2(\mathbf{Z}_p)$ where $p$ is the order of $G$. What I don't know is the following: what if $G,H$ are simple, yet not abelian? Let us for now focus on a more restricted case where $G\cong H$, in particular, $G=H$. What can we say about the group $\operatorname{Aut}(G\times H)$? (I heard something about this group being related to what is called ""wreath product"", which I do not know...) Thanks bunch in advance!","['abstract-algebra', 'automorphism-group', 'group-theory', 'direct-product']"
1236587,Finite summation of the inverse of prime numbers. Show that $\sum\limits_{p \leqslant x}1/p = \frac{\pi(x)}{x} + \int_2^x \frac{\pi(u)}{u^2} du.$,"Show that $$\displaystyle\sum\limits_{p \leqslant x}1/p = \dfrac{\pi(x)}{x} + \int_2^x \dfrac{\pi(u)}{u^2} du.$$ In the equation above, $\pi(x)$ denotes the prime counting function. To get started, how do we deal with the integral $\displaystyle\int_2^x \dfrac{\pi(u)}{u^2} du$ on the right hand side? Not really sure what to with it because of $\pi(u)$ in the numerator. In my number theory class we were given the Riemann Zeta Function: $$\zeta(s) = \displaystyle\sum\limits_{n=1}^\infty \dfrac{1}{n^s}: s \in \mathbb{C}, \operatorname{Re}(s) > 1.$$ We proved $\zeta(s) = \displaystyle\prod\limits_{p \text{ prime}} \left(1-\dfrac{1}{p^s} \right)^{-1}$ and that $\displaystyle\sum\limits_{p \leqslant y}^\infty \dfrac{1}{p} > \log(\log y) - 1,$ $y \in \mathbb{Z}^{>0},$ but not much more than that (that I can think would be useful). Some hints or pointers in the right direction appreciated.","['prime-numbers', 'number-theory', 'analytic-number-theory']"
1236603,Entire functions of order 0,"Sorry, this may be a stupid question, but I am just beginning to learn about this and cannot find the answer anywhere I have looked so far. Clearly if we have any polynomial $P(z)$, then it is easy to show that the order is $0$. Clearly though not all entire functions that grow at roughly this rate are polynomials as I believe $\sin (z)$ is of order $1$, which would make $f(z) = \frac {\sin (z)}{e^z}$ an entire function of order $0$. It is obvious that $f$ still has infinitely many $0$'s and is thus not a polynomial. I was wondering what the characterization of all entire functions of $0$-order look like. I would assume it will just be all functions with $0$'s that are ""nicely"" spaced. But I do not know how to make this precise exactly as I know very little about this subject material. If anyone wants to aid me in my studies it would be greatly appreciated. Thanks. EDIT: My friend pointed out that $\frac {\sin z}{e^z}=e^{-z} \sin z$, which grows at least as fast as $\sin z$ for large negative real values of $z$. So I'm confused... are there non-polynomial entire functions of order $0$ or not? And how can we see this.","['roots', 'analyticity', 'complex-analysis']"
1236618,Product of two infinite sequences,"Let $p_i$ be reals in (0,1) such that $\sum_1^{\infty} p_i=\infty$ and $\sum_1^{\infty} (1-p_i)=\infty$. Prove that $\sum_1^{\infty} p_i(1-p_i)=\infty$. I know a probabilistic proof (follows from Kolmogorov 0-1 Law on infinite seq of independent Bernoulli random variables) but I am unable to show it by usual real analysis trick. Any kind of help/hint is highly appreciated. And this has just come to my mind out of the curiosity. Edit: $\lim p_n$ exists.","['probability-theory', 'sequences-and-series', 'real-analysis']"
1236692,How would multiplying money work?,This is a very silly question since nobody will actually do this because it makes very little sense in the real world but I just want to know how would it actually work if possible. For example let us take an amount of 2 dollars and 2 cents and multiply that buy 2 dollars and 2 cents. Would the result be 4 dollars and 4 cents? The only way to make sense out of this for me is to treat them as vectors and multiply components.,"['unit-of-measure', 'algebra-precalculus']"
1236758,Spaces in which the closure of every countable subset does not include an uncountable closed discrete subset,"What classes of spaces $X$ have the property that that for every countable subset $C \subset X$, $\overline{C}$ does not have an uncountable closed discrete subset? I know every space with countable extent, such as compact spaces, Lindelöf spaces and so on, shall satisfy this property.  Are there other examples with this property?",['general-topology']
1236801,Why aren't these negative numbers solutions for radical equations?,"I was working on radical equations and I came across a few problems where I got answers that worked when I checked, but were not listed as solutions. My teacher's only explanation was, ""just because."" Here is one problem where the only solution is $1$. $x=\sqrt{2-x}$ How I solved it $x^{2}=2-x$ $x^{2}+x-2=0$ $(x+2)(x-1)=0$ $x= \{-2, 1\}$ Then plugging both numbers back in, I get $1 = \sqrt{2-1}$ $1 = \sqrt{1}$ $1 = 1$ and $-2 = \sqrt{2--2}$ $-2 = \sqrt{4}$ The square root of $4$ can be both $-2$ because $-2 \times -2 = 4$ and $2$. $1$ is the only solution listed and my teacher says that it's right. What is the explanation for this? Why isn't $-2$ a solution for the problem?","['radicals', 'algebra-precalculus']"
1236802,Possibilities of license plates with special rules,"I have looked all over the web for some additional information on this matter with no results. Let's say a new form of license plate have 4 letters followed by 3 digits and all sequences are possible. My understanding is since there are 52 letters (lower case and upper case) and 10 digits then the possibilities are $52^4 \cdot 10^3 = 7311616000$ possibilities for the entire license plate with no specific rules. The issue I am running into now is when certain rules are applied: 1) The license plate must have exactly two T's and end in one 5. The solution stated in the book is 375,000. I have tried $52^2 \cdot 1 \cdot 1 \cdot 10^2 \cdot 1$ , but it is not equal to 375,000. 2) This is another question but requires at least one ""T"" and the digit ""4"" someplace in them. The solution in the book states it is 17,981,121. The second question came to a halt as well as I used the same method in question 1. Is there something I am doing incorrectly because the answer is not meeting with the solution.","['discrete-mathematics', 'combinatorics', 'permutations']"
1236805,Expected values of a dice game with a 30-sided die and a 20-sided die.,"Two people, $A$ and $B$, have a $30$-sided and $20$-sided die, respectively. Each rolls their die, and the person with the highest roll wins. ($B$ also wins in the event of a tie.) The loser pays the winner the value on the winner's die. Question: What is expected value for player $A$? How does the expected value of the game for player $A$ change when player $B$ can re-roll? How much is it worth for player $A$ to get a re-roll in this scenario, where player $B$ can have the re-roll? If you remove player $A$ re-roll. How many re-rolls does player $B$ need in order for him to be a favorite in the game? I took the average score for player $A$ to be $15.5$ and for player $B$ to be $10.5$. I am assuming this to be expected return for player $A$ so $15.5 - 10.5 = 5$. We also need to take into account when $X = Y$ when $A$ loses to $B$ on draw so $5 - (7/20) = 4.65$. What I do not understand is how to factor in for when player $B$ can re-roll. I understand that $B$ would re-roll if he gets a value $< 10.5$ which happens $\frac 12$ of the time. Nor can I seem to grasp how to set up the  follow-up questions.","['probability-theory', 'probability', 'discrete-mathematics']"
1236862,Prove $a^3\mid b^2 \Rightarrow a\mid b$,"I think it's true, because I can't see counterexamples. Here's a proof that I am not sure of: Let $p_1,p_2,\ldots, p_n$ be the prime factors of $a$ or $b$ 
\begin{eqnarray}
a&=& p_1^{\alpha_1}\cdots p_n^{\alpha_n} \\
b&=& p_1^{\beta_1}\cdots p_n^{\beta_n} \\
a^3\mid b^2 &&\Rightarrow \frac{b^2}{a^3} \in \mathbb{Z} \\ 
&&\Rightarrow 2 \beta_i - 3\alpha_i \geq 0 \\
&&\Rightarrow 2 \beta_i \geq 3\alpha_i \text{ and } \beta_i \geq 0 \\
&&\Rightarrow 3 \beta_i \geq 3\alpha_i \\
&&\Rightarrow \beta_i \geq \alpha_i \\
&&\Rightarrow \beta_i - \alpha_i \geq 0 \\
&&\Rightarrow \frac{b}{a} \in \mathbb{Z}\\
&&\Rightarrow a\mid b
\end{eqnarray}
Is this proof correct ?","['number-theory', 'prime-factorization', 'divisibility']"
1236904,Intuitive explanation of requirement for achieving the Cramer Rao Lower Bound,"this question relates to the requirement for achieving CRLB. I know that for a random sample $Y_1, \ldots, Y_n$, an estimator $U$ of $g(\theta)$ is MVUE (i.e. it is unbiased and also $\operatorname{Var}(U) = \frac{[\frac{\delta}{\delta\theta}g(\theta)]^2}{I_Y{(\theta})}$), then it also achieves its CRLB. However if the logic flows the other way, that is to say, for the unbiased estimator $U$, $U$ achieves its CRLB iff $s(\theta;y) = b(\theta)(h(y) - g(\theta))$. My question: Can someone please explain, intuitively, this requirement $s(\theta;y) = b(\theta)(h(y) - g(\theta))$ please? Many thanks","['statistics', 'statistical-inference', 'parameter-estimation']"
1236942,Determine the possible grouping,"Consider I have a set of $3$ object $1,2 $ and $ 3.$ What is the possible grouping? I'll have either $\{(1,2,3)\}$  or $\{(1),(2),(3)\}$ or $\{(1,2),(3)\}$ or $\{1,(2,3)\}$ or $\{(2,(1,3)\}.$ So, I'll have $5$ possible grouping. In the same manner for $4$ objects, I'll have $14$ possible grouping.
So, What about $n$ numbers and how could I formulate it?",['discrete-mathematics']
1236958,The expected area of a triangle formed by three points randomly chosen from the unit square,"""Three points are chosen uniformly and at random from a unit square. What is the expected value of the area of the resulting triangle?"" I need to do a research about that problem and i found this suggested solution: here . Now, I understand almost everything except anecdote (2) when he computes the expected value of $b$ and $v$.  I can't understand how he reaches those calculations. If someone can explain to me this that would be great. Thanks.",['probability']
1236989,"$\operatorname{Cov} \, (A,B)\geq 0$ and $\operatorname{Cov}(B,C)\geq 0\Rightarrow \operatorname{Cov}(A,C)\geq 0$?","Let's say we have three random variables $A$, $B$ and $C$.
I know that $\DeclareMathOperator{cov}{Cov} \cov(A,B)\geq 0$ and $\cov(B,C)\geq 0$ . Then is it true that $\cov(A,C)\geq 0$?","['covariance', 'probability']"
1236998,Differentiability of an absolute function.,"Check the differentiability of $f(x)=x|x|$, $x$ is in $\mathbb{R}$.
I know that it is differentiable when $x>0$ and $x<0$. I am not sure about the case when $x=0$. I found that as $$\lim \limits_{h\to 0}\frac{f(x+h)-f(x)}{h}$$ exists and equal to $0$. But still something seems wrong. Is function differentiable at $0$? Thank you.","['absolute-value', 'derivatives']"
1237009,Existence of a differentiable function given a unit gradient field,"I'm trying to prove that ""Given a unit vector field $V$, it can always be uniquely determined a differentiable function $f$ that satisfies $\nabla f = V$."" To provide you more information, the unit vector field $V$ is actually determined from $V=\frac{\nabla \phi}{\| \nabla \phi \|}$, where $\phi$ is a level-set function. That is, I want to prove the existence and uniqueness of a function $f$ satisfying $\nabla f = \frac{\nabla \phi}{\| \nabla \phi \|}$. Can any of you give me a proof or at least some advice?
Any kind of help will be greatly appreciated. Thank you all in advance. :)","['calculus', 'poissons-equation', 'differential-geometry', 'analysis', 'vector-fields']"
1237023,"Laplace's equation in Polar coordinate, an example?","Consider Laplace's equation in polar coordinates $$ \frac {1}{r} \frac {\partial} {\partial r}  (r \frac {\partial U} {\partial r}) +  \frac {1} {r^2}  \frac {\partial^2 U} {\partial \theta^2} = 0$$ with $U(r,\theta)$ as the solution, subject to the boundary conditions: $$U(a,\theta)=\begin{cases}
2\theta && 0 < \theta <\pi\\
0 &&\pi< \theta < 2\pi\\
\end{cases}$$ How can we calculate $\,U(0, \theta)$ ?","['polar-coordinates', 'ordinary-differential-equations']"
1237039,Show that $\limsup_{x \to \infty} \frac{\pi(x)}{x/ \log x} \geqslant 1. $,"Show that $$\displaystyle\limsup_{x \to \infty} \dfrac{\pi(x)}{x/ \log x} \geqslant 1. $$ I've seen $\displaystyle\lim_{x \to \infty}$ operator, but I haven't seen $\displaystyle\limsup_{x \to \infty}$ or $\displaystyle\liminf_{x \to \infty}$ before. What do they mean exactly? Based on the image from wikipedia: It seems that we need $\displaystyle\limsup_{x \to \infty}$ and $\displaystyle\liminf_{x \to \infty}$ when a sequence is not strictly increasing or decreasing, but jumping between values. I've not taken analysis, so these terms are not so familiar to me. $\textbf{Edit:}$ These concepts make sense to me now. The following was proved in my notes: For every real number $y \geqslant 2,$ $$\displaystyle\sum\limits_{p \leqslant y} \dfrac{1}{p} > \log(\log y) - 1.$$ This is supposed to be useful in application in this problem, but I am not sure how exactly. The prime number theorem states that $$\displaystyle\lim_{x \to \infty} \dfrac{\pi(x)}{x/ \log x} = 1,$$ but we didn't prove it in my textbook or notes, so I'd like to refrain from using it if necessary.","['prime-numbers', 'number-theory', 'analytic-number-theory']"
1237069,Caden has 4/3 kg of sand which fills 2/3 ​​ of his bucket. How many buckets will 1kg sand fill?,"I have already finished Calculus II but I go back and practice the basics on Khan Academy. This problem confuses me conceptually every time. I know what the answer is, but I am having a hard time rationalizing the steps. What are the mental steps you take solving this problem? Thanks in advance and please have mercy on me. I am doing this for my own entertainment not for a grade!",['algebra-precalculus']
1237074,Prove that any group of 14 people must contain either 5 mutual friends or 3 mutual strangers.,"So I think I have the answer to this problem, but there's something about it that's bothering me: Suppose we choose a fixed point with $13$ edges coming out of it. There must be at least $a)$ $9$ red edges (friends) OR $b)$ $5$ blue edges (strangers) because $8 + 4 < 13$. In case $b)$, among the $5$ edges if any are blue then we have blue triangle with our fixed point, and so we are done. Otherwise, they are all red and we have a red-pentagon, also as desired. In case $a)$, among $9$ people there are $3$ mutual strangers or $4$ mutual friends. If the former, we are done. If the latter, since the $4$ friends are red edges to our fixed point then we have $5$ mutual friends including our fixed point, again as desired. Namely, for case $a)$, do I need to include the case if among $9$ people there are $4$ mutual STRANGERS or $3$ mutual FRIENDS? If so, how? If not, well why not? This has been bothering me for quite some time and I would appreciate an answer! Thanks!","['ramsey-theory', 'discrete-mathematics']"
1237097,Difference : subsequences and substrings,What are the differences between subsequences and substrings?,['combinatorics']
1237159,Understanding the definition of nowhere dense sets in Abbott's Understanding Analysis,"First of all, I am sorry for asking a question about understanding a definition in a book named Understanding Analysis. But it is my first time to encounter basic topology, so I hope you can excuse me.  I have searched previous questions like this and this . I have looked to the wiki page. Still I am having a hard time to understand the following definition: A set $E$ is nowhere dense if $\overline E$ (the closure of $E$ )
  contains no nonempty open intervals. I am not familiar with other concepts of topology which are not available in the Abbott's Understanding Analysis like balls or interior. I know a set $A$ is dense in $B$ if and only if $\overline A = B$ . For example, $\mathbb Q$ is dense in $\mathbb R$ , because its limit points are all real numbers and its closure gives $\mathbb R$ . Similarly, $\mathbb Z$ is not dense in $\mathbb R$ because it doesn't have limit points and hence its closure is itself. According to my knowledge of denseness, could you help me to understand the above definition with an example?","['real-analysis', 'general-topology']"
1237171,Proving the limit of a nested sequence,"I have trouble proving the next sequence limit: $\displaystyle\lim_{n\rightarrow\infty}(x_{n}-\sqrt{n})=\frac{1}{2}$ where $x_{n}=\sqrt{n+\sqrt{n-1 ...\sqrt{2+\sqrt{1}}}}.$ I've had a lot of problems; my try is multiplying by the conjugate but the resulting expression continues with $x_{n-1}.$ Also I tried to bound the expression and apply limit in each side which it was failed. By other hand, I thought that I can operate with the expression $x_{n}=\sqrt{n+x_{n-1}}$ and try to get a quadratic equation; solve it and work with a new expression but its usless. I thank any help to prove this limit.","['sequences-and-series', 'nested-radicals', 'calculus', 'limits']"
1237174,Is the following statement true on $L^0$ spaces?,"Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $X,Y\in L^0(\Omega;\mathbb{R})$ two random variables taking values in $\mathbb{R}$. Is it true that:
$$\int_{A} f(X(\omega)) P(d\omega) = \int_{A} f(Y(\omega)) dP(\omega)$$
for all $A\in \mathcal{F}$ and all Lipschitz continuous functions $f:\mathbb{R}\rightarrow \mathbb{R}$ then
$$X=Y, \quad P-a.s.?$$
In other notation this is like saying:
$$E[f(X)] = E[f(Y)] \quad \forall f\in Lip(\mathbb{R}) \Rightarrow X=Y,\quad P-a.s.$$ Could we also relax it to all $f$ continuous and bounded (not necessarily Lipschitz)? Thank you for the help :)","['probability', 'real-analysis', 'functional-analysis', 'measure-theory']"
1237227,Choosing 10 balls out of a box of 90 balls,"A box contains $ 30$ red balls, $30$ white balls and $30$ blue balls. If $10$ balls are selected at random without replacement, what is the probability that at least one color will be missing from the selection? The answer is: Solution : Let $A_1, A_2$ and $A_3$ be the events that there is no red, no white and no blue balls, respectively. Then by the inclusion-exclusion principle, $P(A_1\cup A_2\cup A_3) = \sum_{i}P(A_i)-\sum_{i<j}P(A_i\cap A_j)+ P(A_1\cap A_2\cap A_3)$. Clearly, $P(A_1\cap A_2\cap A_3)=0$ and $P(A_i\cap A_j)={\binom{30}{10}\over{\binom{90}{10}}}$ for $i\ne j$. Finally, $P(A_i)= {{\sum\limits_{k=1}^{10}\binom{30}{k}\binom{30}{10-k}}\over{\binom{90}{10}}}={{\sum\limits_{k=0}^{10}\binom{30}{k}\binom{30}{10-k}-\binom{30}{10}}\over{\binom{90}{10}}}={{\binom{60}{10}-\binom{30}{10}}\over{\binom{90}{10}}}$ Why isn't it just $\binom{60}{10}\over\binom{90}{10}$?",['probability']
1237239,What is the derivative of max and min functions? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question If I define a function: $f(x) = \max[g(x),h(x)]$ What is $f'(x)$?",['derivatives']
1237301,How do I show that the following map establishes a bijection between $\mathbb Q$ and $\mathbb Z \times \mathbb{Z}_{>0}$,"Define $$f:\mathbb Z \times \mathbb{Z}_{>0} \to \mathbb{Q}$$ by $$f(p, q) = \frac{p}{q} $$ Edit: Is there an explicit map then that is a bijection?",['elementary-set-theory']
1237306,Lipschitz condition not satisfied,"To show there is no contradiction to existence and uniqueness $\displaystyle\frac{|f(x,u)-f(x,v)|}{|u-v|}= \displaystyle\frac{|x||u^{1/2}-v^{1/2}|}{|u-v|}=\frac{|x|}{u^{1/2}+v^{1/2}}$ I understand that for small $u$ and $v$ the above expression is unbounded. However, what is this actually saying? i.e does this imply $y$ is not lipschitz at $y=0$? If so why is this?","['multivariable-calculus', 'ordinary-differential-equations']"
1237309,Find multivariable limit $\frac{x^2y}{x^2+y^3}$,"Find multivariable limit of: $$\lim_{ \left( x,y\right) \rightarrow \left(0,0 \right)}\frac{x^2y}{x^2+y^3}$$
How to find that limit? I was trying to do the following, but i am not able to find a proper inequality:
$$| \frac{x^2y}{x^2+y^3} | = |y-\frac{y^4}{x^2+y^3}| \le$$","['multivariable-calculus', 'limits', 'inequality']"
1237327,Solutions cannot cross,"I understand for for the initial value problem: $\frac{dx}{dt}=f(x) \quad$  $x_0=x(0)$ If I have two solutions $x_1(t),x_2(t)$ defined on the same interval with the same initial condition satisfying the above initial value problem then $x_1(t)=x_2(t)$.
However, why if I have two solutions, with different initial conditions are they unable to cross one another? i.e $x_1(t)\neq x_2(t)$",['ordinary-differential-equations']
1237329,show that $f(x)=-3x+4$ is bijective,Determine whether each of these functions is a bijection from $\mathbb{R}$ to $\mathbb{R}$ a) $f(x)=-3x+4$ So I know that a function is bijective if it is both injective (one-to-one) and surjective (onto). A function is one-to-one if  every $x$ has a unique $y$. And it is onto if for every $y$ there is an $x$ such that $f(a)=b$. But I don't know how write it down and show that $f(x)=-3x+4$ is bijective,['functions']
1237361,To be a scalar matrix or not to be?,"What follows is a pretty (but not so easy) exercise. Is fun off-topic? Let $A, B \in M_2(\mathbb{C})$. Show that for every $m, n \in \mathbb{N}$ $$((AB)^m-(BA)^m)((AB)^n-(BA)^n)$$ is a scalar matrix (that is, of the form $\lambda I_2$).","['linear-algebra', 'matrices']"
