question_id,title,body,tags
4032353,Understanding basic concept of prime numbers,"My textbook provides a theorem but I cannot understand the structure of the sentence being used. Could someone please help me understand the meaning of this theorem? A natural number $n>1$ is prime if and only if for all primes $p\leq \sqrt{n}$ , $p$ does not divide $n$ . ""for all primes $p\leq \sqrt{n}$ , $p$ does not divide $n$ "". This is the part I don't understand. The premise is that $p$ is less than the square root of $n$ then the conclusion is that $p$ does not divide $n$ . So for $p$ to divide $n$ it must be greater than the square root of $n$ ? I'm really confused as to what information and meaning I'm supposed to see in this theorem.",['discrete-mathematics']
4032385,Why is $\sin(\tanh x) + \sinh(\tanh x)$ almost exactly $2\tanh x$?,"I was trying to come up with some approximations for the solution to the differential equation $y'' + \operatorname{sgn}(y') + y = 0$ and noticed while I was messing around that $\sin(\tanh x) + \sinh(\tanh x)$ is almost exactly $2\tanh x$ . Looking at the series expansions for $\sinh$ and $\sin$ it's not immediately obvious why this would be the case. It makes sense that high-order terms should converge to a constant value for large $x$ , and that near $x=0$ they should be approximately zero. This seems to imply that for some intermediate values of $x$ around something like $x=0.5$ there should be disagreement, but this seems like a remarkably good fit for every value of $x$ . Why might this be?","['hyperbolic-functions', 'calculus', 'taylor-expansion', 'limits', 'trigonometry']"
4032394,Does incompressible in the smooth sense imply incompressible in the measure theoretic sense?,A smooth map $T$ is called incompressible if it has zero divergence and a measurable map $T$ is incompressible if $T^{-1}(B) \subset B$ implies $\mu(T^{-1}(B))=\mu(B)$ where $\mu$ is some probability measure.  Are these two versions of incompressibility equivalent in $R^n$ ?,"['measure-theory', 'volume', 'riemannian-geometry', 'real-analysis', 'differential-geometry']"
4032417,Theorem. (Lindenbaum),"I have found the following Lindenbaum theorem ( here , page7) It states that: Suppose $X$ , $Y$ are linear orders . If $X$ is isomorphic to
an initial segment of $Y$ (with $f$ ) , and $Y$ is isomorphic to a final segment of $X$ (with $g$ ), then X $\simeq$ Y. I can't seem to prove it. I have the bijection in the constructed out of $f$ , $g$ as in the classical proof of the Schroeder-Bernstein theorem, but I can't show that it's order embedding . Any tips ? Edit: In the article it's written "" the hypotheses(f, g are isomorphisms) guarantee that this bijection is order-preserving"" But how does it guarantee it ?","['elementary-set-theory', 'order-theory', 'set-theory']"
4032477,"$A_1 \times ... \times A_n$ is countable if $A_1, ..., A_n$ are countable [duplicate]","This question already has answers here : The cartesian product of a finite amount of countable sets is countable. (2 answers) The Cartesian product of a finite number of countable sets is countable [duplicate] (3 answers) Finite Cartesian Product of Countable sets is countable? (1 answer) Is the cartesian product of a finite amount of countable sets, countable? (1 answer) Closed 3 years ago . Suppose that $A_1, ..., A_n$ are countable sets. Show that the cartesian product $A := A_1 \times ... \times A_n$ is countable. My attempt: Sets are said to be countable if they are finite or if they have the same cardinality as some subset of $\mathbb{N}$ (i.e. we can find some bijection $f: A \rightarrow S$ or $f: S \rightarrow A$ where $S \subset \mathbb{N}$ ). Assume that $A_1, ..., A_n$ are countable sets. Then, there exists bijections $fi: \mathbb{N} \rightarrow A_i$ for $i = 1, ..., n$ . Define $g: \mathbb{N} \rightarrow A$ as follows My issue arises here in finding such a bijective function without it being too complicated. How would I go about finding one? I am also open to any suggestions. Any assistance is welcomed.","['elementary-set-theory', 'induction']"
4032502,"In Fisher’s discriminant for multiple classes, How do you manage when $(Sw)$ is singular matrix (so you cant get $(Sw)^{-1}$)?","I am trying to use Fisher’s discriminant for multiple classes to reduce the Dimension of the MNIST data set, similar to this post: https://towardsdatascience.com/an-illustrative-introduction-to-fishers-linear-discriminant-9484efee15ac But in my Implementation in Python, when I compute $Sw$ it is a singular matrix so I can not get $(Sw)^{-1}$ to obtain the eigenvectors from $(Sw)^{-1}Sb$ . Am I doing something wrong or what can I do to solve this problem? I am following the steps given in Pattern Recognition and Machine Learning By Bishop. Thanks.","['statistics', 'discriminant', 'machine-learning', 'pattern-recognition', 'probability']"
4032504,Formal proof for the limit of $\frac{\tanh(x)-1}{e^{-2x}}$ as $x \rightarrow \infty$,"Formal proof for the limit of $\frac{\tanh(x)-1}{e^{-2x}}$ as $x \rightarrow \infty$ . So far Keep in mind I have to use the definition for a limit. I.e for this would be a proof for the limit at $\infty$ with a finite value (I have checked this to be $-2$ ). I would have to use the definition that states $\lim_{x \ \to \  \infty} f(x) = L \Leftrightarrow 
  \forall \ \epsilon>0\; (\exists \ \delta : (\;x>\delta\implies |f(x) - L|\leq\epsilon)).
$ i.e I start off by by finding that $$\left | \frac{\tanh{x}-1}{e^{-2x}}-(-2) \right | \iff \left | \frac{2}{1+e^{2x}} \right |$$ Or just $\frac{2}{1+e^{2x}}$ since we will assume $\epsilon >0$ . Now I would have to to start my proof and this is where I struggle. I know that
""for alle $\epsilon>0$ let $\delta=\frac{2}{1+e^{2\epsilon}}>0$ and $x>\delta>0$ ....."" *Remark: I know we use $N,M,K$ and not $\delta$ normally.","['epsilon-delta', 'limits-without-lhopital', 'analysis', 'real-analysis', 'limits']"
4032561,"Prove that $2^{n}>1+n\sqrt{2^{\left(n-1\right)}}, \ \ \forall n>2$.","this is a question from the concept of $AM\ge GM\ge HM$ , how do i know which number to select for applying the inequality, please help!","['algebra-precalculus', 'a.m.-g.m.-inequality', 'inequality']"
4032593,Show that the cardinality of $P(\mathbb{N})$ is $2^{\aleph_o}$,"Show that the cardinality of $P(\mathbb{N})$ - the power set of $\mathbb{N}$ - is $2^{\aleph_o}$ . Hint: Show that $P(\mathbb{N})$ has the same cardinality as the set $N = \{f: \mathbb{N} \rightarrow A| f$ is a function $\}$ , where $A = \{0, 1\}$ . My attempt: Using an inductive argument with the statement that if $|X|=n$ , then, $|P(X)| = 2^n$ for all $n\geq 0$ , we have Base: If $n = 0$ , $X = \emptyset$ . But the empty set is the only subset of itself, so $|P(X)| = 2^0$ . Inductive: Suppose for $m \geq 0$ , if $|X| = m$ , then $|P(X)| = 2^m$ . If $|X| = m + 1$ , pick some $x \in X$ and let $Y = X - \{x\}$ . By assumption, $|P(Y)| = 2^m$ . There are two subsets of $X$ : subsets with $x$ and subsets without $x$ . For each subset, there are $2^m$ elements so $|P(X)| = 2P(Y) = 2^m + 2^m = 2^{m+1}$ . We have shown that the power set of a set $X$ has $2^{|X|}$ elements. Let $X = \mathbb{N}$ , then, as $|\mathbb{N}| = \aleph_o$ , it follows that $|P(\mathbb{N})| = 2^{\aleph_o}$ . QED. Is this proof correct? If so, what would a proof that uses the hint look like? Any insight is much appreciated.","['elementary-set-theory', 'cardinals', 'solution-verification']"
4032621,"What is meant by ""a curve $r(t)$ of constant length $|r(t)|$""?","I am working on an assignment for Calculus III. This particular one has to do with some vector calculus, but I am caught on some wording by my professor and he is not holding office hours at the moment. In a few questions he asks us to show certain properties of ""a curve $r(t)$ with constant length $|r(t)|$ ."" I have been operating under the assumption that this means any curve with a scalar as its length, such as $\langle 0,0,t\rangle$ over $0\le t\le 1$ , but am now questioning that assumption, as he asks us to show a property is true ""for all of $t$ ."" Does anyone have any ideas what he means here? I have been working these by creating examples with small bounds such as the one above for simple integration for the lengths.","['multivariable-calculus', 'vectors']"
4032641,"Given two natural numbers $m, n$ so that $m> n.$ Prove that there exist any real numbers $x$ so that $2\sin nx\cos mx\geq 1$","Given two natural numbers $m, n$ so that $m> n.$ Prove that there exist any real numbers $x$ so that (unsolved in a case..) $$2\sin nx\cos mx\geq 1$$ Source: StackMath/@RiverLi_ Prove: $(\forall m, n\in\Bbb N_{>0})(\exists x\in\Bbb R)$ s. t. $2\sin n x \cos m x \ge 1$ . I couldn't find a concrete value of $x,$ but I succeeded at proving the problem by using Intermediate value theorem (My friend has taught me a solving plan..). Let $x$ on the interval $I= \left [ -\frac{5}{6}\pi, \frac{\pi}{6} \right ],$ we call $f\left ( x \right ):=\frac{1}{2\sin x}, g\left ( x \right ):=\cos\alpha x, \alpha:=\frac{m}{n}> 1,$ I devide my problem into 2 cases as followings When $1< \alpha< \frac{6}{5},$ we have $f, g$ continuous both and $f\left ( -\frac{3}{4}\pi \right )\geq g\left ( -\frac{3}{4}\pi \right ),$ by Intermediate value theorem $\exists x\in I$ so that $f\left ( x \right )= g\left ( x \right )$ When $\alpha\geq\frac{6}{5},$ we have $f, g$ continuous and $\exists x\in I$ so $g\left ( x \right )= -1\Rightarrow\exists x\in I$ so that $f\left ( x \right )= g\left ( x \right )$ Conclusion . $$\forall\alpha= \frac{m}{n}> 1, \exists x\in I: f\left ( x \right )= g\left ( x \right )\Leftrightarrow\forall m, n, \exists x\in I: 2\sin x\cos\alpha x= 1$$ $$\Rightarrow\forall m, n, \exists x\in \mathbb{R}: 2\sin nx\cos mx\geq 1$$ I'm waiting for @RiverLi's complete solution and want to see such a value of $x$ for my proof, thanks","['real-analysis', 'continuity', 'calculus', 'trigonometry', 'substitution']"
4032670,What does it mean to equip a subset with the subspace topology?,"This goes for equipping any set with any topology. Suppose that I want to equip a subset $A \subseteq X$ where $X$ is a topological space, with the subspace topology. I know that by definition of the subspace topology that $\tau_A = \{U \cap A | U \in \tau\}$ . But what does this do to $A$ ?",['general-topology']
4032710,Proof without using truth tables,"I need some further explanation, as I feel I am just missing some critical piece of information. I have shown my work thus far (I excluded the truth tables as they take up so much space but included the pertinent values). Can someone shed some light on what I'm overlooking here? Which of the following formulas are equivalent? Without showing truth tables, explain why which of the following five statements are equivalent. Hint – analyze the possible values of P, Q, and R that make each of the statements false. a. P → (Q → R). b. Q → (P → R). c. (P → Q) ∧ (P → R). d. (P ∧ Q) → R. e. P → (Q ∧ R). My work: So using truth tables I was able to determine that a,b,d are all equivalent to each other AND c and e are equivalent to each other.
A, B, D are all false ONLY when p and q are true and r is false, as that is the  only time that the conditional statement becomes true implies false.
C and E are false for several instances, when p=T q=T r=F; p=T q=F r=T; p=T q=F r=F. What has me stumped is how to write a proof from that information. I have tried using the logical equivalence identities, but am unable to  come up with the correct answer, so I feel like that is not the proper way to do it. So I'm wondering, is there somethin I'm missing? Is this supposed to be a proof by implication, or and indirect proof, and if so, how am I supposed to start that? I understand that these are conditional statements, but again, I feel as if I am missing something.","['formal-proofs', 'logic', 'problem-solving', 'discrete-mathematics']"
4032890,Winding number of a curve (not complex analysis),"I am asked to calculate the winding number of an ellipse (it's clearly 1 but I need to calculate it) I tried two different aproaches but none seems to work. I would like to know why none of them work (I believe it is because these formulas only work if I have a curve parametrized by arc lenght). Approach 1: A valid parametrization : $\gamma=(a\cos t,b\sin t)$ , with $t \in [0,2\pi], \, a,b \in \mathbb{R}$ $\dot{\gamma}(t)=(-a\sin t,b\cos t)$ , with $t \in [0,2\pi], \, a,b \in \mathbb{R}$ $\ddot{\gamma}(t)=(-a\cos t,-b\sin t)$ , with $t \in [0,2\pi], \, a,b \in \mathbb{R}$ $\det(\dot{\gamma}(t)|\ddot{\gamma}(t)) = \renewcommand\arraystretch{1.2}\begin{vmatrix}
-a\sin t & -a\cos t \\ b\cos t & -b\sin t \end{vmatrix}=ab \sin^2 t+ab \cos^2 t=ab$ $||\dot{\gamma}(t)||^3=(\displaystyle\sqrt{(-a\sin t)^2+(b\cos t)^2})^3=(\displaystyle\sqrt{a^2\sin^2 t+b^2\cos^2 t})^3=a^3b^3$ $\kappa(t)=\displaystyle\frac{ab}{a^3b^3}=\displaystyle\frac{1}{a^2b^2}$ $\mathcal{K}_\gamma = \displaystyle\int_{0}^{2\pi} \displaystyle\frac{1}{a^2b^2} \ dt= \displaystyle\frac{2\pi}{a^2b^2}$ , $\mathcal{K}_\gamma$ is the total curvature of the curve. $i_\gamma=\displaystyle\frac{\displaystyle\frac{2\pi}{a^2b^2}}{2\pi}=\displaystyle\frac{1}{a^2b^2}$ ...which is not necessarily 1. Approach 2: Winding # = $\displaystyle\frac{1}{2\pi}\displaystyle\int_{\gamma}\displaystyle\frac{-y}{x^2+y^2}\>dx+\displaystyle\frac{x}{x^2+y^2}\>dy$ That gives us $\displaystyle\frac{1}{2\pi}\displaystyle\int_{0}^{2\pi}\left( \displaystyle\frac{-b\sin t}{a^2\cos^2 t+b^2\sin^2 t}(-a\sin t)+\displaystyle\frac{a\cos t}{a^2\cos^2 t+b^2\sin^2 t}(b\cos t) \right)\>dt$ $\displaystyle\frac{1}{2\pi}\displaystyle\int_{0}^{2\pi}\left( \displaystyle\frac{ab}{a^2\cos^2 t+b^2\sin^2 t }\right)\>dt$ , which I computed and cannot be calculated. Clearly the second approach is valid if we are dealing with a circumference of radius 1. We can generalize for the elipsee using Green's Theorem. I would also like if someone could show me this way as well. Thank you","['differential', 'multivariable-calculus', 'geometry', 'differential-geometry']"
4032954,"What does $\sum_{n=0}^\infty z^{n(n+1)/2}$, $|z|<1$ converge to?","Does anyone know what the series $$
S(z) = \sum_{n=0}^{\infty} z^\frac{n(n+1)}{2}
$$ converges to for $|z|<1$ ? This came up in an application where $z$ is a probability and $S(z)$ an expected value. The exponent comes from the fact that $\sum_{k=0}^nk=\frac{n(n+1)}{2}$ . I think $S(z)$ should definitely converge because the coefficients are nonnegative and form a subsequence of the well-known $\sum_{n=0}^\infty z^n=\frac{1}{1-z}$ . Is there a closed-form representation of $S(z)$ ?","['power-series', 'theta-functions', 'sequences-and-series']"
4033005,"For a tree T, the tree of increasing sequences of elements of T does not embed in T","For a tree T, let σT be the set of all increasing sequences in T of elements of T, ordered by initial segment (s<t of s is an initial segment of t). Why isn't σT embeddable in T ? In the sense there is no f from σT to T such that s<t --> f(s)<f(t) ? I saw in a paper of Todorcevic that it is because such an embedding implies a one-to-one function between T and Ord, but I don't see where is the contradiction..","['elementary-set-theory', 'trees', 'order-theory', 'set-theory']"
4033081,Finding the function for a curve given its length and the length of its velocity?,"I am working on an assignment and am trying to find a function for $\vec{r}(t)$ with constant length $x$ , whose velocity function also has a constant length $y$ . I'm not sure where to begin with this. I know that, say, $\langle \cos(t),\sin(t),0\rangle$ has a constant length of 1, but its velocity curve also has a constant length of 1. How can I scale the velocity without scaling the original function? Thanks!","['multivariable-calculus', 'vectors']"
4033099,Existance of multivariable limit,"We are asked to find whether the limit $$
\lim_{(x,y)\to(0,0)}\frac{x^3y^3}{x^8+y^4}
$$ exists. I tried to find through the epsilon-delta definition but wasn't able to apply it successfully. So I tried to come up with a convergent sequence $(x_n)$ such that it converges to $(0,0)$ but $f(x_n)$ does not converge to a single point, thus establishing non-existence of the limit. But I wasn't able to come up with any such sequence.
When I checked on Wolfram-Alpha it showed the limit to be non existent. Can someone provide a proof of this or give example of a sequence $(x_n)$ converging to $(0,0)$ such that such that $f(x_n)$ does not converge ?",['multivariable-calculus']
4033151,$f:\mathbb{R} \mapsto \mathbb{R}$ convex and increasing. Show there is $a \in \mathbb{R}$ such that $\lim\limits_{x\to -\infty}\frac{f(x)}{x}=a$,"Let $f:\mathbb{R} \to \mathbb{R}$ be a convex and increasing function such that $\lim\limits_{x\to -\infty}f(x)\to-\infty$ Show that there is an $a \in \mathbb{R}$ such that $\lim\limits_{x\to -\infty}\frac{f(x)}{x}=a$ . First of all, i can't really find an example respecting the hypothesis. Is there a convex function which is increasing with $\lim\limits_{x\to -\infty}f(x)=-\infty$ ? If $f$ was supposed concave, it appears true to me. Then, if the statement holds, I don't really see how to prove it. I tried to apply the following property of convex function on the interval $x<a<b$ : $$\frac{f(a)-f(x)}{a-x}\le\frac{f(b)-f(x)}{b-x}\le\frac{f(b)-f(a)}{b-a}.$$ But, even if i suceed to ""sandwich"" ${f(x) \over x}$ , i don't really see how it could help.. Thank you in advance for help.","['limits', 'functions', 'convex-analysis', 'real-analysis']"
4033155,Redundancy in the description of transfinite induction,"I am wondering if there is redundancy in the description of transfinite induction: Let $A \subseteq \lambda$ , where $\lambda$ is an ordinal. If (1) $\boldsymbol{0} \in A$ ; (2) for all ordinals $\beta$ , if $\beta \subseteq A$ , then $\beta \in A$ ; then $A = \lambda$ . I am wondering if (1) is redundant. With only (2), as $\boldsymbol{0} = \emptyset \subseteq A$ is trivially true, we have $\boldsymbol{0} \in A$ . Thus, (1) is included in (2). Why do we still need (1)?",['elementary-set-theory']
4033182,Non-atomic measure on $\mathbb{Z}\cup\{\pm\infty\}$?,"I have a rather naive question? Is there a non-atomic measure on $\bar{Z}:=\mathbb{Z}\cup\{\pm\infty\}$ ? For example, the counting measure is atomic.",['measure-theory']
4033191,"If $f_x(x,y)>0$, $f_{xx}(x,y)<0$, $f_y(x,y)>0$, $f_{yy}(x,y)<0$ can $f_{xy} $ change sign?","That is, suppose we have a continuous and (at least) twice differentiable function $f(x,y)$ which is increasing but concave in each of its individual arguments $^*$ , Note that these derivatives are all assumed to be non-zero the domain of $f$ is $[0,C]$ with $C>0$ (if changing the domain matters please feel free to let me know. I'm interested) Is it possible for the cross partial derivative to change signs (? (i.e. $\frac{\partial f}{\partial x \partial y} >0$ at some point but $<0$ at another point) If it is possible, what if we look along a line (i.e. fix an $x$ or $y$ value and look along the line from that point) (just answering the bold question is an acceptable answer) If it is possible, can someone provide an example function? If not, I am looking for a proof (or hints for a proof, or some intuition) *By increasing but concave in each argument I mean $\frac{\partial f}{\partial x} >0$ and $\frac{\partial^2 f}{\partial x^2}<0$ , and similar for $y$ Edit: I made question more slightly general. I apologize if someone was already typing an answer. (It is more general because if this edited question is true, then so is the original)","['examples-counterexamples', 'multivariable-calculus', 'functions', 'partial-derivative', 'derivatives']"
4033199,"Show there exists differentiable $g : (0, \infty) \to \mathbb{R}$ s.t $f(\vec{x}) = g(||\vec{x}||)$ for $f : \mathbb{R}^3 \to \mathbb{R}$","Let $f : \mathbb{R}^3 \setminus \left \{0 \right \} \to \mathbb{R}$ be a differentiable function s.t $\nabla f \neq 0$ and: $y \frac{\partial f}{\partial x} -  x \frac{\partial f}{\partial y} =0 \\
z \frac{\partial f}{\partial y} -  y \frac{\partial f}{\partial z} =0$ Show there is a differentiable $g : (0, \infty) \to \mathbb{R}$ s.t $f(x,y,z) = g(||(x,y,z)||)$ I tried using spherical coordinates to show that the gradient is only determined by $r$ which I think should help, but I had some trouble with the algebra, help appreciated.",['multivariable-calculus']
4033228,Integration with trig substitution,"Trying to evaluate this using trig substitution: $$\int \frac {1}{49x^2 + 25}\mathrm{d}x $$ Here's how I'm going about it, using $x = 5/7(\tan\theta)$ $$\int \frac {1}{49\left(x^2 + \frac{25}{49}\right)}\mathrm{d}x $$ $$=\int \frac {1}{49\left(\frac{25}{49}\tan^2\theta + \frac{25}{49}\right)} \mathrm{d}\theta$$ $$=\int \frac {1}{(25\tan^2\theta + 25)} $$ $$=\int \frac {1}{25(\tan^2\theta + 1)}\mathrm{d}\theta $$ $$=\int \frac {1}{25\sec^2\theta}\mathrm{d}\theta $$ $$=\int \frac {\cos^2\theta}{25}\mathrm{d}\theta $$ $$=\frac{1}{50}(\theta + \sin\theta + \cos\theta) $$ To generalize for $x$ , $\theta = \arctan(7x/5)$ $$\frac{1}{50}\left(\arctan\left(\frac{7x}{5}\right) + \sin\left(\arctan\left(\frac{7x}{5}\right)\right) + \cos\left(\arctan\left(\frac{7x}{5}\right)\right)\right) $$ $$\frac{1}{50} \left(\frac{7x}{5\left(\frac{49x^2}{25}+1\right)} + \arctan\left(\frac{7x}{5}\right)\right)$$ But taking the derivative of this gets me: $$ \frac{35}{(49x^2 +25)^2}$$ Where is my mistake?","['integration', 'analysis', 'real-analysis', 'calculus', 'indefinite-integrals']"
4033286,"Suppose $X_{1},...\sim U[0, 1]$. Let us define $X(n)$ = $\max_{1≤i≤n} X_i$ . Prove that $X(n)$ converges in probability to $1$.","Suppose $X_{1},...\sim U[0, 1]$ . Let us define $X(n)$ = $\max_{1≤i≤n} X_i$ . Prove that $X(n)$ converges in probability to $1$ .
Is this solution enough?... I cannot understand the solution provided in the below mentioned link: https://www.stat.cmu.edu/~larry/=stat705/Lecture4.pdf","['statistics', 'probability-theory', 'probability-distributions', 'problem-solving', 'probability']"
4033310,Alternative Methods for Trigonometry Proofs (Varying Angles),"Consider all the ways to prove $\sin(2x)=2\sin(x)\cos(x)$ . There are many! I personally would use Euler's formula involving complex numbers due to it being extremely simple and straightforward. We know $\sin(x)=\frac{e^{ix}-e^{-ix}}{2i}$ and $\cos(x)=\frac{e^{ix}+e^{-ix}}{2}$ . The LH and RH sides become $\frac{e^{i2x}-e^{-i2x}}{2i}=2(\frac{e^{ix}-e^{-ix}}{2i})(\frac{e^{ix}+e^{-ix}}{2})$ . And now this proof can be done with some basic algebra! At the same time, I have always been bothered by rewriting $\sin(x)$ and $\cos(x)$ this way. To rewrite everything in terms of $e$ feels like an utter avoidance to use the words ""sine"" and ""cosine."" It also seems like an avoidance to represent such formulas along the unit circle to prove them. The proofs involving the sum and difference formulas that use the unit circle have always appeared so clean to me. This got me thinking... is there a dependable way to prove results like these using the unit circle? Or is there a way to rewrite everything in terms of sine and cosine another way? I have been curious about this for a long time, and I would be curious as to what other dependable ways are used to prove trigonometric results such as these without $i$ and infinite sequences. What do other people do?","['trigonometry', 'soft-question', 'geometry', 'complex-numbers']"
4033383,What is the name of the function $1/\Gamma(z) \int_0^\infty \frac{x^{z -1}}{e^w-1}dw$?,"I recently saw on the internet, and was curious what the name of the ""pineapple"" function was? $$1/\Gamma(z) \int_0^\infty \frac{\color{red}{x}^{z-1}}{e^w-1}dw$$ I recognize the ""mango"" function as $\Gamma(z)$ the gamma function.  Also, does anyone know what theorem this refers to?","['complex-analysis', 'gamma-function']"
4033395,Cluedo probabilities as information progresses,"I am trying to calculate the probability that each card is inside the envelope as the information revealed progresses during the game. The deck is composed of 21 cards, which are divided into three different classes ('Suspects', 'Weapons' and 'Rooms'). The first two classes contain 6 cards each, while the third one contains 9 cards. Then one card is removed for each class and placed in an enevelope, so that the deck now contains 18 cards in total. After shuffling, these 18 cards are dealt among 6 players (I am insterested in this case only), so that each player holds 3 cards (not necessarily one for each class). Let's assume I am one of the 6 players. At this point, the probability that any of the cards belonging to the class 'Rooms' has been removed from the deck and placed in the envelope is 1/9, while for the other two classes is 1/6. Conversely the probabilities that these kind of cards are in the hands of the players are respectively 8/9 and 5/6. Then let's assume that I become aware of the three cards that I have been dealt with. At this point I want to answer these two kinds of questions: What is, for example, the probability that the card 'Kitchen' (which belongs to the 'Rooms' class) is in the enevelope conditioned to the fact that it is not among my three cards? What is, for example, the probability that the card 'Kitchen' is in the envelope conditioned to the fact that it is not among my cards but 'Living Room' (another card from the class 'Rooms') is? I know that we are dealing with conditional probabilities, but I cannot figure out how to calculate them, as the initial probability of the card 'Kitchen' to be removed from the deck and placed in the envelope is 1/9, which is different from the probability that this card will end in the hands of each player (which if I am not wrong should be 4/27).","['conditional-probability', 'probability-theory', 'probability']"
4033449,"Let $a,b,c$ be positive integers such that $a^3+b^3=2^c.$ Show that $a=b$.","Let $a,b,c$ be positive integers such that $$a^3+b^3=2^c.$$ Show that $a=b$ . I have that $$a^3+b^3=(a+b)(a^2-ab+b^2)=2^c =2^x\cdot2^y$$ now it can only be that $a$ and $b$ are both odd or even since they sum to an even number. Thus if $a$ and $b$ are both odd I have that $a^2$ is odd, $ab$ is odd and $b^2$ is odd. This would imply that $a^2-ab+b^2 = 2^y =1$ which in turn implies that $a^3+b^3 = a+b \implies a=b.$ The problem I have is that if I would have considered that both $a$ and $b$ are even I would have gotten that $a=2t, b=2k$ from where $$8t^3+8k^3=2^c \implies t^3+k^3=2^{c-3}$$ but I couldn't deduce anything from here why cannot $a$ and $b$ be even?","['elementary-number-theory', 'algebra-precalculus']"
4033497,"Prove $\int_0^1 f(g(x)) \, dx \leq \int_0^1 f(x)\,dx + \int_0^1 g(x)\,dx$","$f$ and $g$ are continuous functions on $[0, 1]$ . $f$ doesn't decrease on this segment. Values of both $f$ and $g$ are in range $[0, 1]$ . Prove following inequality $$\int_0^1 f(g(x)) \, dx \leq \int_0^1 f(x)\, dx + \int_0^1g(x) \,dx$$ I couldn't think of any great idea to show that this inequality is actually satisfied by all functions with mentioned properties. Thank you for your hints and help in advance!","['integration', 'calculus', 'definite-integrals']"
4033521,"Uniqueness of geodesics between two points on surface, given metric","For concreteness, let us consider the surface described in this question: it is the graph of $$
z=\sin(x)+\sin(y)
$$ The metric on the surface is $$
g=\left( \matrix{1+\cos^2(x) & \cos(x) \cos(y) \\ \cos(x) \cos(y) & 1+\cos^2(y)} \right)
$$ I am more physicist than mathematician. I'm familar with GR, but not differential geometry. I'm quite happy finding the Christoffel symbols, curvature tensor, etc. I am aware of a theorem that guarantees unique geodesics at a point and in a given direction , (modulo certain niceties) but I'm interested in uniqueness between two points. In this answer, it seems that there exists a length minimizing geodesic, but not necessarily that it is unique. This answer mentions the Cartan-Hadamard theorem. It seems for a surface, 'sectional curvature'=scalar curvature. For the surface in question $$
R=\frac{8 \sin(x) \sin(y)}{(4+\cos(2x)+\cos(2y))^2}
$$ Which oscillates between positive and negative over the surface. Can we apply the theorem to a region of the surface where $R<0$ , and say that for two points within that region, there is a unique length minimizing geodesic? Is there any way to tell if geodesics connecting two given points on  surface are unique? Can this be phrased in terms of: ""requirements for the metric such that there are unique geodesics""? Specifically, I'm asking about 'nice' surfaces like the one here: it doesn't have points removed, and it's smooth (you will undoubtedly shake your head and tell me the correct term to use).","['metric-spaces', 'riemannian-geometry', 'differential-geometry']"
4033554,First Order Differential Equation Problem - Calorie intake,"UPDATE :  Thanks to Matthew for pointing out what to do next, this problem has been solved. Thanks everyone for your time and effort. I've been stuck on this DE problem for a few days now and was wondering if someone can point me in the right direction.  I know the solution is $101$ days. The daily calorie intake is taken to be a fixed quantity $C$ and is modelled by the DE. $$\frac{dt}{dm} = \frac{1}{a(C-bm)}$$ where $a$ and $b$ are both constants. A man is $90$ kg.  If he were to take no calories for $14$ days, his mass would reduce by $20$ %.  How long will it take him to reduce his mas by the same amount if he took $3/4$ of the calories required to keep his mass constant at $90$ kg? I'm missing something simple, but just can't figure it out. Thanks in advanced. So far I have the general solution to the DE as: $$\int dt = \int\frac{1}{a(C-bm)} dm$$ $$t + K = - \frac{1}{ab} ln|C-bm| $$ $$-tab - Kab = ln|C-bm| $$ $$|C-bm| = e^{-tab} e^{-Kab}$$ $$C-bm = Ae^{-tab}$$ where $$A=\pm e^{-Kab}$$ and $K$ is an arbitrary constant. Now, when $t=0$ $m=90$ kg, so $A=C-90b$ , therefore we now have $$C-bm = (C-90b)e^{-tab}$$ Transposing $$ bm= \frac{C-(C-90b)e^{-tab}}{b}$$ $$ m(t) = \frac{C+(90b-C)e^{-tab}}{b}$$ Next, $t=14$ , $m=72$ ( $20$ % reduction of $90$ ), $C=0$ $$72b = 90be^{-14ab}$$ $$\frac{72}{90} = e^{-14ab}$$ $$e^{14ab} = \frac{90}{72}$$ Thus $$ab=\frac{\ln\frac{90}{72}}{14}$$ $$ab=\frac{1}{14}\ln\Big(\frac{5}{4}\Big)$$ $$ab=0.0159$$ So substituting $ab$ back into the equation $$ m(t) = \frac{C+(90b-C)e^{-t0.0159}}{b}$$ So I have 3 unknows $C$ , $b$ and $t$ . I can seem to extract the required information to solve for $t$ . The next part is where I get stuck.  I don't know how to implement the $3/4$ of the calories required in my formula.","['calculus', 'ordinary-differential-equations']"
4033591,Set Inequality Proof Check,"Looking at a problem on an intro. analysis practice exam:
Prove that $$ U\setminus(A\setminus B)\ \;=\; (U\setminus A)\setminus B $$ I don't think this is true, here is the counterexample that I cooked up: $$ U\;=\;\{1,2,3,\dots, 9, 10\}$$ $$ A\;=\;\{2,4,6,8\} $$ $$ B\;=\; \{2,4,5,7\} $$ Considering $u=2$ , we have $u\in \{1,2,3,4,5,7,9,10\}=U\setminus(A\setminus B)$ , yet $u\notin \{1,3,9,10\}=(U\setminus A)\setminus B$ . Just looking for a quick verification, seeing as the awkward scenario here is an undergraduate is claiming that a tenured professor is incorrect (maybe he did it on purpose?).","['elementary-set-theory', 'solution-verification', 'real-analysis']"
4033607,Is there a closed form for the distribution of $T = \sum_{k=0}^\infty 2^{-k} X_k$?,Let $$T = \sum_{k=0}^\infty 2^{-k} X_k$$ Where each $X_k \sim \text{Exp}(1)$ is i.i.d. as an exponential random variable with $\lambda = 1$ . Is there a closed form for the pdf or cdf of $T$ ?,"['statistics', 'probability-distributions', 'probability-theory']"
4033621,Covering a square with crosses,"I am trying to find the smallest number of ""crosses"" needed to cover an n by n square with overlap. A ""cross"" is basically the ""X"" pentomino, the following figure: The problem is to place the smallest number of crosses so that each cell is covered at least once. The crosses are placed by picking the point for their center. They may overlap with each other and they do not have to fit entirely on the board - for example, you can place a cross at the cell $(0,0)$ . Which would produce the following: I would like to know whether there exists a polynomial-time algorithm for finding an optimal solution (finding the positions of the crosses). Clearly there are some patterns that achieve a good covering, but I would like to have a proof or decent argument why such a covering is the best possible. I have checked $n = 1,2,3,4,5,6,7$ . The minimal number of crosses are: $1,2,3,4,7,10,12$ Here are some examples of how such coverings might be achieved (green cells are the centers of the crosses):","['computational-complexity', 'geometry', 'tiling', 'algorithms']"
4033673,4 Color Theorem - What am I not seeing??,"Let me say first that I am in no way a mathematician. Just slightly interested in mathematics. I think I may have found an exception to the 4 color theorem.
I don't claim to be smarter than those who proved the theorem, and I'll assume I'm wrong.
What am I missing here?
(forgive my quickly drawn graph!) (I created this account just to ask this question, so the website made me embed the image instead of just adding it straight to the question.) I may be missing some fundamental rule in setting up my problem. But I think my map fits the desired intent of the ""map"" motif of the theorems original question.","['coloring', 'geometry']"
4033674,Kulkarni-Nomizu identity,"I am trying to prove the identity $\newcommand\KN{\bigcirc
\kern-2.5ex\wedge \;}$ $$
g(T,h \KN\, g)=4g({\rm tr}_g T,h)
$$ where $h$ is a symmetric tensor of type $(0,2)$ , $T$ is an algebraic curvature tensor and $g$ is a metric for a vector space $V$ . Here, $h \KN\, g$ denotes the Kulkarni-Nomizu product between $h$ and $g$ . In my attempt, I wrote in coordinates the left part of the equality: $$
T_{ijkl}(h_{mp}g_{no}+h_{no}g_{mp}-h_{mo}g_{np}-h_{np}g_{mo})g^{im}g^{jk}g^{ko}g^{lp}
$$ using the formula for the inner product of covariant tensors, but I don't get anywhere. Any help?","['curvature', 'tensors', 'riemannian-geometry', 'differential-geometry']"
4033690,Lie transported commutator ?= commutator of Lie-transported vectors [Schutz],"I am working through Schutz's Geometrical methods in mathematical physics. Stuck in 3.8, on Forbenius' theorem. My question is about the very last step. Let there be an $n$ -dimensional manifold $M$ and an open set $U \subset M$ . Let there be an $m-1$ dimensional sub-manifold $S'$ and a set of vector fields $\mathbf{Y}_{(a)},\,a=1...m-1$ which form coordinate basis on $S'$ ( $m\le n$ ). Here we only consider $S'$ inside $U$ . Next there is a vector field $\mathbf{V}$ such that: $$
\left[\mathbf{V},\,\mathbf{Y}_{(a)}\right]=0\,\forall a
$$ The aim of the author is to build a set of vector fields $\mathbf{Z}_{(a)}$ that would commute with each other and with $\mathbf{V}$ . $\mathbf{Z}_{(a)}$ are defined to equal to corresponding $\mathbf{Y}_{(a)}$ on $S'$ , and to be Lie-transported along $\mathbf{V}$ in all other points outside $S'$ . Also, by definition $\left[\mathbf{V},\,\mathbf{Z}_{(a)}\right]=0$ . I can follow author up to and including proving that: $$
\mathcal{L}_\mathbf{V}\left[\mathbf{Z}_{(a)},\,\mathbf{Z}_{(b)}\right]=0
$$ But then the author concludes that $\left[\mathbf{Z}_{(a)},\,\mathbf{Z}_{(b)}\right]=0$ everywhere. Not sure about this step. It is certainly true on $S'$ , where $\left[\mathbf{Z}_{(a)},\,\mathbf{Z}_{(b)}\right]=\left[\mathbf{Y}_{(a)},\,\mathbf{Y}_{(b)}\right]=0$ and one can see that Lie-transport of that vector ( $\left[\mathbf{Y}_{(a)},\,\mathbf{Y}_{(b)}\right]$ ) along $\mathbf{V}$ will keep it at zero. I am not sure that this implies that commutator of two Lie transported vectors will also be zero: $\left[\mathbf{Z}_{(a)},\,\mathbf{Z}_{(b)}\right]\overset{?}{=}0$","['lie-algebras', 'lie-derivative', 'smooth-manifolds', 'manifolds', 'differential-geometry']"
4033702,Linear Algebra Done Right: Notation 1.23,"I recently started reading Linear Algebra Done Right by Axler, and I find it great up until Notation 1.23, where the first bullet point states: If $S$ is a set then $F^S$ denotes the set of functions from $S$ to $F$ I would really like to know what this means; in other words, does this mean that for all $f \in S$ , then $f \in F$ , but the only difference is that $F$ is a vector field?","['notation', 'linear-algebra', 'vector-spaces']"
4033741,"Complementary book for Conway's book ""A Course in Functional Analysis""","I am first year graduate student and I have taken Functional Analysis course this semester. The main book of teaching is Conway's book ""A Course in Functional Analysis"" but the lecturer is notorious for giving exams from questions that are not exercises of the book he's teaching. So I need an accompanying book for functional analysis with lots of cool problems that covers same materials of Conway's book and is on graduate level. Any suggestions would be much appreciated.","['book-recommendation', 'functional-analysis']"
4033743,Solve trigonometric equation $\cos \sqrt{\frac{\pi^2-x^2}3} + 2\cos \frac{\pi -x}3=0$,"I don't seem to have a credible way to solve the trigonometric equation below $$\cos \sqrt{\frac{\pi^2-x^2}3} + 2\cos \frac{\pi -x}3=0$$ I was able to guess quickly that $-\pi$ is a root, and, after staring at it long enough, was able to see that $-\frac\pi2$ is another one. I graphed  the function and verified that these two are the only roots. However, I have not been able to solve it algebraically. One thing I have tried is to convert it into a system of equations $$3y^2=\pi^2 - x^2$$ $$\cos y +2\cos\frac{\pi-x}3=0$$ and hoped to explore the symmetry, as seen the plot Edit: Note that the plot reveals that one root is at an extreme, where the two curves are tangential to each other. This indicates that the root may be solved via calculus, albeit not algebraically. One easier example of such soluble equation is $\pi\cos x=\sqrt{\pi^2 -x^2}$ which has a single root at its extreme. The complication in the posted equation is that it has two roots.","['algebra-precalculus', 'trigonometry']"
4033761,Help finding Eigenvectors,"The matrix is \begin{equation*}
A = 
\begin{pmatrix}
1 & 0 & 0 \\
2 & 1 & -2 \\
3 & 2 & 1
\end{pmatrix}
\end{equation*} I got the eigenvalues $\lambda_1 = 1, \lambda_2 = 1 + 2i$ , and $\lambda_3 = 1-2i$ . I am only concerned with the complex valued eigenvectors. For $\lambda_2$ , I got the eigenvector \begin{equation*} v_2=
\begin{pmatrix}
0 \\
i \\
1
\end{pmatrix}\end{equation*} and for $\lambda_3$ , I got the eigenvector \begin{equation*}v_3=
\begin{pmatrix}
0 \\
-i \\
1
\end{pmatrix}\end{equation*} In the back of the book, it is saying the eigenvectors for $\lambda_2$ and $\lambda_3$ are \begin{equation*} v_2=
\begin{pmatrix}
0 \\
1 \\
-i
\end{pmatrix}\end{equation*} and \begin{equation*}v_3=
\begin{pmatrix}
0 \\
1 \\
i
\end{pmatrix}\end{equation*} When I checked on Wolfram Alpha, it is saying that my answers are correct. Did I do something wrong or is the back of my book wrong?","['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'generalized-eigenvector']"
4033791,Find $\lim_{n\to\infty}2^nx_n$,"Find $\lim_{n\to\infty}2^nx_n$ where $$x_{n+1}=\frac{x_n}{1+\sqrt{x_n^2+1}},\forall n\in \mathbb{N}$$ given $x_1=\sqrt{3}$ I tried finding the first few terms which go as follows: $$\sqrt3,\frac{1}{\sqrt3},\frac{1}{2+\sqrt3},\cdots$$ This doesnt seem to follow a definite pattern, and Im not sure how to proceed. Any hint is appreciated!","['limits', 'recurrence-relations']"
4033807,Equivalent sets proof,"Let $A$ be a set. Show that $\cal P(A)$ - the power set of $A$ - is equivalent (same cardinal) to ${\{0, 1\}}^A$ - the set of all functions from $A$ to $\{0, 1\}$ . Suppose $A$ was $\mathbb{N}$ ; would this hold? How about if $A$ was $\mathbb{N}^\mathbb{N}$ (the set of sequences with values in $\mathbb{N}$ )? My friend gave me the following proof: It suffices to construct a bijective function. Suppose that $f: A \rightarrow \{0, 1\}$ , and let $A_f$ be the set of elements such that $a\in  A_f \iff f(a)=1$ . Define the map $h(f) =A_f$ then we proceed to show injectivity and surjectivity: Injectivity: Suppose that for functions $f, g$ , we have $f\ne g$ . Then there is an $x\in A$ so $f(x)=1$ and $g(x)=0$ or vice versa. Then $A_f\ne A_g$ . By the contrapositive argument, $h$ is injective. Surjectivity: Let $X\in{\cal P}(A)$ and then define a function $f$ as follows: $$f(x)=\cases{1, if x\in B\cr 0, if x \notin B }$$ Then $X = h(f)$ and $h$ is surjective. We have a bijection $h:{\{0, 1\}}^A \rightarrow {\cal P}(A)$ so, we may conclude that the two sets are equivalent. Is this proof correct? Is there a more formal or more detailed way to express it? In addition, does this proof carry forward to $\mathbb{N}$ and $\mathbb{N}^\mathbb{N}$ defined in the problem above? Any assistance much appreciated.","['elementary-set-theory', 'proof-writing', 'functions', 'solution-verification']"
4033821,$1+i$ is a prime element of ring of Gaussian integers.,"I want to prove that $1+i$ is a prime element of ring of Gaussian integers $Z[i]$ . I started off with saying that if $1+i$ is prime then $1+i|(a+bi)(c+di)$ implies $1+i|a+bi$ or $1+i|c+di$ for $a+bi,c+di$ in $Z[i]$ .
Taking conjugate, we get $1-i|(a-bi)(c-di)$ Next we get, $2|(a^2+b^2)(c^2+d^2)$ Since $2$ is a prime in $Z$ hence $2|(a^2+b^2)$ or $2|(c^2+d^2)$ . After this I am stuck. I do not know how to get $1+i|a+bi$ or $1+i|c+di$ from here. Please suggest.","['abstract-algebra', 'gaussian-integers', 'prime-numbers']"
4033909,Real numbers satisfing a trigonometric property,One of my students sent me the problem below and I am looking for solution. I tried simply to expand using complex numbers ( $Re(\sum e^{i(A-B)}$ ) but to no avail. Does any body have idea how to proceeed? If $$\cos (A-B)+\cos (B-C)+\cos (C-A)=-\frac32$$ find the value of $$\cos A+\cos B+\cos C$$,"['algebra-precalculus', 'trigonometry']"
4033921,Convergence of integral and summation for Time taken for complete revolution around vertical circle,"I want to find Time taken to complete Vertical circular motion by Particle of mass $m$ So I proceed as follows Applying work energy theorem $$-mgR(1-\cos(\theta)=\frac12 mv^2-\frac12 mu^2$$ $$\implies v^2=u^2-2gR(1-\cos\theta)$$ $$\implies \omega=\frac{\sqrt{u^2-2gR(1-\cos\theta)}}{R}$$ $$\implies \frac {d\theta}{dt}=\frac{\sqrt{u^2-2gR(1-\cos\theta)}}{R}$$ $$\implies \frac {d\theta}{\sqrt{u^2-2gR(1-\cos\theta)}}=\frac{dt}{R}$$ Let T be the time taken for complete revolution Now, Integrating both sides $$\int_{0}^{2\pi}\frac {d\theta}{\sqrt{u^2-2gR(1-\cos\theta)}}=\int_{0}^{T}\frac{dt}{R}$$ $$\implies T=2R\int_{0}^{\pi}\frac{d\theta}{\sqrt{u^2-4gR\sin^2\theta}}$$ $$\implies T=\frac{2R}{u}\int_{0}^{\pi}\frac{d\theta}{\sqrt{1-\frac{4gR}{u^2}\sin^2\theta}}$$ On evaluating this elliptic integral we get, $$T=\sum_{n=0}^{\infty} \left(\frac{2}{u}\right)^{2n+1}\left(\frac{(2n-1)!!}{2^n n!}\right)^2 (gR)^n$$ Here $T$ denotes Time taken for complete revolution. Block will complete full circle only if $u\geq \sqrt{5gR}$ . So my question is $T$ will be Real only when $u\geq \sqrt{5gR}$ so This condition should exist in integral as well as summation for $T$ but I'm not able to see it. Also Wolfram alpha evaluates integral only if $u\geq \sqrt{5gR}$","['integration', 'summation', 'definite-integrals', 'classical-mechanics', 'convergence-divergence']"
4033951,A limit which exists in polar coordinates but not in Cartesian coordinates?,"Let's have look at the function $$ f(x,y) \begin{cases}
\frac{y(x^2+y^2)}{y^2+(x^2+y^2)^2} & (x,y)\neq(0,0)
\\0 & (x,y)=(0,0)\end{cases}.$$ Switching to polar coordinates gives $$ f(r,\theta)=\begin{cases}
\frac{r^3 \sin \theta}{r^2\sin^2\theta+r^4} & r\neq0
\\0 & r=0\end{cases}.$$ We'd like to investigate the existence of a limit for $f$ at the origin.
In Cartesian coordinates ( $f(x,y)$ ) one can immeidately see that the limit doesn't exist because for example on the path $y=0$ we have $\lim_{x\rightarrow 0,y=0} f(x,y)=0$ and on the path $y=x^2$ we have $\lim_{x\rightarrow 0,y=x^2} f(x,y)=\frac{1}{2}$ . However, in polar coordinates we have $$ f(r,\theta)=\begin{cases}
\frac{r \sin \theta}{\sin^2\theta+r^2} & r\neq0
\\0 & r=0\end{cases} $$ so that $$ \lim_{r\rightarrow 0}f(r,\theta) = \begin{cases}
0 & \sin\theta = 0\\
0 & \sin\theta \neq 0
\end{cases}$$ so the limit exists and is zero regardless of $\theta$ . Why does it look the limit doesn't exist in Cartesian coordinates but exists in polar coordinates? Edit: Thanks to the insightful comments on this page and other similar questions in the site, the unboundedness of the expression with $\sin^2 \theta$ is the key to the failure of the limit existence. $\sin\theta$ can get arbitrarily small, making the whole expression arbitrarily large, effectively counteracting $r\rightarrow 0$ .","['multivariable-calculus', 'limits', 'calculus', 'limits-without-lhopital']"
4033975,Long division with integers,"Consider the long division of 237 with divisor a natural number $K$ . If the quotient is $Q$ and the remainder is $R$ , find all possible values of $K$ , such that $K, Q, R$ , not necessarily in this order, form a Geometric Progression (GP). I have found 15, 78 and 236 but can't think of an analytical approach.
We have $237 = K*Q + R$ and $1 \leq K \leq 237$ Also $1 \leq Q \leq 237$ and $1 \leq R \leq 118$ where $118$ is the integer part of $\frac {237}{2}$ . Therefore $119 \leq K*Q \leq 237$ In order for $K, Q, R$ to be in GP, any of 2 of $\frac {K}{Q}$ , $\frac {K}{R}$ , $\frac {Q}{R}$ or $\frac {Q}{K}$ , $\frac {R}{K}$ , $\frac {R}{K}$ must be equal. Clearly the condition is met if any 2 of $K, Q, R$ are equal. Can you please provide a full solution?",['number-theory']
4033995,Set notation with subscript and superscript,"In the ""The Hundred-Page Machine Learning Book"", the author uses the following notation to describe the set of all labeled feature vectors. $$\{(x_i,y_i)\}_{i=1}^N$$ What I understand: $\{\ldots\}$ denotes a set $x_i$ and $y_i$ are the feature vector and its label $i$ starts at $1$ and runs up to $N$ What I do not understand: Is this a common set notation? I did not find anything like this","['elementary-set-theory', 'notation']"
4033996,Developing Kepler's first law from the two-body problem,I'm supposed to develop Kepler's first law from the two-body problem. I've the information that I'd get a differential equation which can't be solved by elementary function but however the orbitals can be found out from equation. I've been doing a lot research but I still am a bit confused what is the starting point and what is the differential equation I'm supposed to end up with. I would be very pleased if someone could help me.,"['celestial-mechanics', 'proof-writing', 'ordinary-differential-equations']"
4034012,Does convexity of $f(x)$ imply convexity of $f(e^x)$?,"Let $0<\epsilon<1$ , and let $f:[1-\epsilon,1] \to \mathbb{R}$ be a strictly decreasing, continuous, and strictly convex function. Suppose that $f_-'(1)=0$ . Define $g:[\log(1-\epsilon),0] \to \mathbb{R}$ by setting $g(x)=f(e^x)$ . Is $g$ convex on some half-neighbourhood of $0$ ? I specifically don't want to assume stronger differentiability assumptions . The differentiability assumptions do matter here: If we assume $f,g \in C^2$ and $f''(1)>0$ , then $g''(0)=f''(1)>0$ and $g$ is convex. If we remove the assumption $f_-'(1)=0$ , $g$ might be non-convex. Take $f(x)=1-x$ . Then $g(x)=1-e^x$ , so $g''(x)=-e^x<0$ .","['examples-counterexamples', 'real-analysis', 'calculus', 'derivatives', 'convex-analysis']"
4034018,Do the position and velocity vectors live in the same space?,"This is a question I've been thinking about for a while. Position vectors are supposed be represented by an arrow from the origin that traces out a path, while one does not need to think of the velocity vector as having any sort of starting point because as long as the length and direction and the same, they represent the same velocity. From a pure math perspective, a vector space is just an object with a dozen or so properties with closure being one of them. But it makes no sense to add a position and a velocity vector right? So that means they do not belong to the same vector space. But at the same time, it is possible to take the dot or cross products of a position and velocity vector. So how do you explain that? Also when we learn multivariable calculus, why do we need the position vector to originate from the origin? $\Bbb R^3$ or $\Bbb R^2$ satisfies all the properties of a vector space without needing to conjure up any sort arrow.","['multivariable-calculus', 'linear-algebra', 'vector-spaces', 'differential-geometry']"
4034214,Order and degree of a differential equation,"Here is a question in my book Find the order and degree of the differential equation $$y=1+\frac{dy}{dx}+\frac{1}{2!}{\left(\frac{dy}{dx}\right)}^2+\frac{1}{3!}{\left(\frac{dy}{dx}\right)}^3+\cdots$$ At first sight we can conclude that the order is $1$ and the degree is undefined as  as the power of $\frac{dy}{dx}$ continues to increase and has no limit.However  my book gives the following solution Rewrite the DE as $$y=\exp\left({\frac{dy}{dx}}\right)$$ $$\implies \frac{dy}{dx}=\ln y$$ whose order and degree is 1 . Now ,I completely agree with this solution however I find it rather counterintuitive to my first line of thought .If the book is correct how can it be justified to prove my intuition was wrong?","['intuition', 'ordinary-differential-equations']"
4034221,The natural sequence {$a_n$} is given. Need to prove that from some point all values of $a_n$ will be the same.,"Natural number $a_0$ is given. The natural sequence $\{a_n\}$ is given so that $a_n$ is the smallest possible number that satisfies this: $$\sqrt[n]{a_0\times a_1\times a_2 \times\cdots\times a_n} = \text{natural number}.$$ Prove that after some point all the values of $a_n$ will be the same. I've done this: Variable $a_1$ will be $1$ because $a_0\times a_1 \in \mathbb{N}$ .
If $a_0$ is a prime  then $a_0\times a_1\times a_2 = x^2$ , that means $a_2 = a_0$ , and in the same way $a_3 = a_0,\;\cdots,\; a_n=a_0$ . That means for prime $a_0$ 's it's true. Then I tried a non-prime example for $a_0$ . It was $a_0 = 2^3\times 3$ .
And it really gave me that from some point $a_n$ -s are the same.
I don't know how to prove this for $a_0 = p_1^{b_1}\times p_2^{b_2}\times\cdots\times p_k^{b_k}$ .","['number-theory', 'sequences-and-series']"
4034229,Number of attempts to fully color a disk coloring half of it at a time [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Mark precisely one half of the disk by a line that goes through its center. The angle of the line has a uniform distribution, meaning there is no preferable direction. You color one half of the disk and keep on with the same coloring scheme. What is the average number of attempts that you need to color the entire disk?","['expected-value', 'probability']"
4034237,What is regularity of solution of Dirichlet problem with Dirac distribution as boundary data?,"I was thinking if we have Dirac distribution as boundary condition, then what will be regularity of solution. Problem is following, $$
\left\{\begin{matrix}
\nabla_x(\gamma(x)\nabla_x u(x,y))=0 & in~\Omega\\ 
u(x,y)=\delta_y(x) & on ~\partial \Omega 
\end{matrix}\right.
$$ where $x,y\in \mathbb R^n , \gamma(x)>c>0 $ . $\Omega$ is with smooth boundary. Any help or  reference is greatly appreciated.","['regularity-theory-of-pdes', 'distribution-theory', 'functional-analysis', 'partial-differential-equations']"
4034271,"Show that the statistic $T(x_1,...,x_n)=\sum_{i=1}^nx_i^2$ is complete.","Let $X_1,...,X_n$ be iid random sample form $N(\theta,c\theta)$ , where $c$ is a known constant.
Show that the statistic $T(x_1,...,x_n)=\sum_{i=1}^nx_i^2$ is complete. In other words I have to show that if $$E[g(T)]=0\quad \Longrightarrow \quad g(T)=0 \quad \forall t$$ I'm kind of stuck with the distribution of $T$ because $x_i^2$ isn´t a gaussian distribution. Any suggestions on how to approach this problem would be great!","['statistical-inference', 'statistics', 'probability']"
4034286,Show $ \begin{bmatrix} A & BC(A+BC) \\ I_n & 0 \end{bmatrix} $ and $\begin{bmatrix} A+BC & 0 \\ 0 & -CB \end{bmatrix}$ have same nonzero eigenvalues,"Let $A\in\mathbb{R}^{n\times n}$ , $B\in\mathbb{R}^{n\times m}$ , and $C\in\mathbb{R}^{m\times n}$ .  Define \begin{equation}
D_1=\begin{bmatrix}
A & BC(A+BC) \\
 I_n & 0
\end{bmatrix},\qquad D_2=\begin{bmatrix} A+BC & 0 \\ 0 & -CB \end{bmatrix}
\end{equation} Show that $D_1$ and $D_2$ have the same nonzero eigenvalues. My attemp: If we check the claim numerically, we see that the nonzero eigenvalues of $D_1$ and $D_2$ are the same. Probably, there is a factorization of $D_1$ , for example $D_1=EF$ such that $D_2=FE$ .","['matrices', 'linear-algebra']"
4034300,Does the order of the Fibonacci sequence's initial values matter?,"I am reading about generating functions in this reputable engineering textbook and the author uses the Fibonacci sequence as an example: The Fibonacci sequence is defined by the initial conditions $a_0=0$ , $a_{-1}=1$ , and the recursion relation $a_n=a_{n-1}+a_{n-2}$ for $n>0$ . Using this definition, I am able to work through the author's example to get the correct generating function: $$G(x)=\frac{1}{1-x-x^2}$$ However, everywhere I read online states the initial conditions of the Fibonacci sequence as (0,1) and not (1,0). So I tried that instead, but I get a different result: $$G(x)=\frac{1+x}{1-x-x^2}$$ This generating function seems to produce the Fibonacci sequence, but starting from the second number instead of the first $(1,2,3,5,8,13,...)$ . Where did I go wrong? I would have thought that the sequence should be identical in both cases. Many thanks for any help! My calculations: The author starts with a general expression for a generating function for a sequence $\{a_n\}$ : $$G(x)=\sum_{n=0}^{\infty}a_nx^n$$ He then looks at the special case where $\{a_n\}$ is a linear recurrence of range $r$ : $$a_n=\sum_{i=1}^rc_ia_{n-i}$$ and proves that this leads to: $$G(x)=\frac{g(x)}{f(x)}=\frac{\sum_{i=1}^rc_ix^i\left(a_{-i}x^{-i}+\cdots+a_{-1}x^{-1}\right)}{1-\sum_{i=1}^rc_ix^i}$$ So, for the Fibonacci sequence, I guess we have $r=2$ and $c_1=c_2=1$ . So we get: $$g(x)=a_{-1}+a_{-2}+a_{-1}x$$ Now I'm a bit confused because the subscripts don't seem to match up. In all the author's discussion, the ""initial conditions"" have strictly negative subscripts ( $a_{-i}$ for $i=1,2,\dots,r$ ). But just for the Fibonacci example, we have initial conditions $a_0=0$ and $a_{-1}=1$ . So I assume these are just off by 1. Therefore, substituting $a_{-1}=0$ and $a_{-2}=1$ gives the author's result above and using $a_{-2}=0$ and $a_{-1}=1$ gives my result above.","['generating-functions', 'fibonacci-numbers', 'sequences-and-series']"
4034318,Calculating the limit $\lim\limits_{\theta \to 0} \frac{\sin \theta}{\tan \theta}$,"I'm calculating this limit and would kindly appreciate feedback on my solution $\lim\limits_{\theta \to 0}\dfrac{\sin \theta}{\tan \theta}$ What I've tried: given that $\tan \theta = \dfrac{\sin \theta}{\cos \theta}\;,$ then I rearrange the equation like so: $$\frac{\sin \theta}{\tan \theta} = \frac{\sin \theta \cos \theta }{\sin \theta} = \cos \theta$$ As $\theta$ approaches $0$ , then is it true that $\dfrac{\sin \theta}{\tan \theta}=\cos\theta\to1\;?$",['limits']
4034319,Can you expand induction proofs to the real numbers?,"Everyone knows the principle of induction, where you first prove a base case for some $n_0\in \mathbb{N}$ , and than show that by assuming the case for an $n \in \mathbb{N}$ the $n+1$ case follows. This is true because of the application of some sort of domino principle.
However, you could also try to combine this principle with an epsilon proof.
For any statement $S_x$ , show that $S_{x_{0}}$ holds and than show that from $S_x$ , $S_{x+\epsilon}$ follows, for $|\epsilon |>0$ , where $\epsilon,x_0,x \in \mathbb{R}$ .
If I am not mistaken this should at least work for proving statements for all rational numbers, please correct me if I am wrong(I am still new to this). But does this also work for proofs of real numbers and if not, is there some sort of ""induction for the reals""? I hope that I could make my question clear enough. I am quite sorry for any sort of mistakes and hope nonetheless, that you could help/correct me.","['real-numbers', 'induction', 'rational-numbers', 'real-analysis']"
4034344,A Basic Limit From Exponentials,"Reading the proof of exponential derivatives I understand this: To show that $(2^x)'=\ln 2 \cdot 2^x$ in the proof is used the limit: $$\lim_{x \to 0} \frac{2^x-1}{x}$$ My question is: ¿How do I prove that this limit exist? I don't care about its value. If I were going to prove that this limit is equal to $\ln 2$ , I would need the number $e$ , and again, this number is defined as the number $a$ such that: $$\lim_{x \to 0} \frac{a^x-1}{x} = 1$$ In another words if I know that for some constant value $a$ the limit: $$\lim_{x \to 0} \frac{a^x-1}{x} $$ exists, let's say it's a number $L$ then I could find all the limits like these in function of $L$ ,
But what makes obvious that this limit exist?","['limits', 'derivatives', 'exponentiation']"
4034360,calculate the limit $\lim\limits_{\theta \to 0} \frac{1 - \cos \theta}{\theta \sin \theta}$,"I'm working on finding the limit for this equation, and would kindly welcome your support to my solution: $$\lim_{\theta \to 0} \frac{1 - \cos \theta}{\theta \sin \theta}$$ These are my steps in hopefully deriving the correct result: $$\frac{1-\cos \theta}{\theta \sin \theta} = \frac{1-\cos^2\theta}{\theta(1+\cos\theta)\sin\theta}=\frac{1-\cos^2\theta}{\theta(1+\cos\theta)\sin \theta}=\frac{\sin\theta}{\theta}\cdot\frac{1}{1+\cos\theta}$$ Given that as $\theta$ approaches $0$ then $\dfrac{\sin\theta}{\theta}$ $\approx$ $0$ and $\cos\theta \approx 1$ . I thought the answer would be $0$ given $\sin{\theta}$ tends to $0$ but the answer is $\frac{1}{2}$ . Can someone kindly explain and show this to me? Maybe I went wrong in my reasoning or calculation? EDIT: Given that: $\cos \theta < \frac{\theta}{\sin \theta} < \frac{1}{cos \theta} = \sec \theta$ because $\frac{\theta}{\sin \theta}$ is between two variables approaching 1, then it must also approach 1. hence, $\frac{\sin \theta}{\theta}$ approaches 1. So the answer is $\frac{1}{2}$",['limits']
4034381,How can we simplify this integral? $\int{x\frac{f(x)}{\int f(x) dx} dx}$,"In a machine learning lecture, we encountered the following integral that we needed to solve to calculate the mean of some random variable $x$ : \begin{equation*}
  \int{x\frac{f(x)}{\int f(x) dx} dx}
\end{equation*} Without really explaining, the professor just simplified it to this: \begin{equation*}
  \frac{\int x f(x) dx}{\int f(x) dx}
\end{equation*} I'm not sure how that works. Since the integration is without limits, then the result is a function not a constant, right? It can't be factored out as if it were a constant. Am I missing something? Does integrating on the same variable twice have any special properties that are relevant here? I'm sorry if the question is lacking in details, if there's anything I can edit to make it clearer, please let me know. Edit: The problem is solved. The simplification is because the denominator is a definite integral and I didn't understand that at first. Since the result of a definite is just a constant, it can be factored outside the integral.","['integration', 'calculus']"
4034382,Proving that $f$ verifies $f(1-x)=-f(x)$,"I'm trying to show an identity verified by a function. I have this function which is defined for all real numbers as $ f(x) = \sum_{k=0}^{p-1} \frac{(x+k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!}$ I would like to show that $f(1-x) = -f(x)$ . First thing that tried: $
\begin{align*} 
f(1-x)
&= \sum_{k=0}^{p-1} \frac{(1-x+k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!} \\
&= \sum_{k=0}^{p-1} \frac{(-1)^{2m-1}(x-1-k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!} 
\quad \text{factoring the numerator by }(-1)^{2m-1}\\
&= -\sum_{k=0}^{p-1} \frac{(x-1-k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!}
\quad \text{reducing }(-1)^{2m-1}=-1\\
&= -\sum_{i=-p}^{-1} \frac{(x+i)^{2m-1}}{(-1)^{p-i-1} (p+i)!(p-i-1)!}
\quad \text{doing a change of variable } i = -k-1 \\
\end{align*}
$ I'm kind of stuck at this point and I don't see how to move forward with it. I think I'm not going to the optimal direction to prove that relation. Second thing that I am investigating: Since $f(x)$ is a polynomial of degree $2m-1$ , I could write it as a finite power series centered at $0$ . So with Taylor's theorem I would have $f(x) = \sum_{i=0}^{2m-1}  \frac{f^{(i)}(0) }{i!} x^{i}$ . and $
\begin{align*} 
f(1-x) 
&= \sum_{i=0}^{2m-1}  \frac{ f^{(i)}(0) }{i!} (1-x)^{i} \\
&= \sum_{i=0}^{2m-1}  \frac{ f^{(i)}(0) }{i!} \Bigg( \sum_{j=0}^{i} \binom{i}{j} (-x)^{j} \Bigg)
\quad \text{binomial expansion applied to } (1-x)^{i} \\
&= \sum_{j=0}^{2m-1}  \Bigg((-1)^{j}\sum_{i=j}^{2m-1} \binom{i}{j} \frac{ f^{(i)}(0) }{i!} \Bigg) x^{j}
\quad \text{changing the summation order} \sum_{i=0}^{2m-1}\sum_{j=0}^{i} \text{ to }   \sum_{j=0}^{2m-1}\sum_{i=j}^{2m-1}  \\
\end{align*}
$ So showing that $f(1-x) = -f(x)$ is equivalent to showing that $(-1)^{j}\sum_{i=j}^{2m-1} \binom{i}{j} \frac{ f^{(i)}(0) }{i!} = - \frac{f^{(j)}(0) }{j!} $ .
I think this is the more elegant way to go but I don't know if it is going to make things worse. Any feedback ? EDIT : clarification of the parameters m and p :
I forgot to mention hypothesis on the parameters $m$ and $p$ . So we consider that $ 1 \leq m < p$","['calculus', 'functions', 'real-analysis']"
4034394,"Prove that there exist integers $k, l \in \mathbb{N}$ such that $\mathrm{ord}(x^ky^l) = \mathrm{lcm}(\mathrm{ord}(x), \mathrm{ord}(y))$ [duplicate]","This question already has answers here : Order of elements is lcm-closed in abelian groups (6 answers) Closed 3 years ago . Let $x, y \in G$ , where $G$ is a group, $\operatorname{ord}(x), \operatorname{ord}(y) \in \mathbb{N} < \infty$ , and $xy=yx$ (seems like it's very important). I want to prove that there exist integers $k, l \in \mathbb{N}$ such that $\operatorname{ord}(x^ky^l) = \operatorname{lcm}(\operatorname{ord}(x), \operatorname{ord}(y))$ . I know these two facts: If $\operatorname{gcd}(\operatorname{ord}(x), \operatorname{ord}(y)) = 1 \Rightarrow \operatorname{ord}(xy) = \operatorname{ord}(x)\operatorname{ord}(y)$ . For $g \in G$ and $n \in \mathbb{N}$ , $\operatorname{ord}(g^n) = \frac{\operatorname{ord}(g)}{\operatorname{gcd}(\operatorname{ord}(g), n)}$ . Looks like these two facts can help me, but I have no idea how. And why is $xy=yx$ so important? I tried to consider infinite non-abelian groups (For example $2\times2$ matrices), but I couldn't find any counterexamples. Maybe you can help me.","['group-theory', 'abstract-algebra']"
4034412,Vector $x$ Solves Least Squares Problem $\iff$ $b - Ax \in \text{Null}(A^*)$,"I am preparing for a graduate exam in Numerical Linear Algebra and I have to solve the following question (without calculus, and without any other theorems about Least Squares): Let $A \in \mathbb{C}^{m \times n}$ with $n < m$ (not necessarily of full rank). For any $x \in \mathbb{C}^n$ let $r(x) = b - Ax$ . Show that $x$ solves the least squares problem $\min_{x \in \mathbb{R}^n}||b - Ax||_2$ if and only if $r(x) \in \text{Null}(A^*).$ Below, I wrote down my attempt. Not only is it incomplete (it purports to prove just one direction of the equivalence), but later I realized that it contains a major flaw. I would immensely appreciate your help  in either fixing this solution, or finding a new one. I have very little time on the exam, so as a bonus, I would be very thankful if you could tell me if you see bad habits in my mathematical writing which make the solution too long. P.S. I have an inkling that a correct solution might involve a QR decomposition, but I'm not sure. Flawed Solution: Lemma: The equation $A^*Ap = A^*b$ has a solution. Proof: We are trying to show that $A^*b \in \text{Col}(A^*A) = \text{Null}(A^*A)^{\perp}$ . Take any $y \in \text{Null}(A^*A).$ We will show that $A^*b \perp y$ . But first, we will show $Ay = 0$ . Indeed, $$y \in \text{Null}(A^*A) \implies A^*Ay = 0 \implies y^*A^*Ay = 0 \implies ||Ay|| = 0 \implies Ay = 0.$$ Now, we show perpendicularity. We have $$(A^*b)^*y = b^*(Ay) = b^*0 = 0.$$ So $A^*b \in \text{Col}(A^*A)$ . Q.E.D. We proceed to the main proof. Let $p$ be a solution of $A^*Ap = A^*b$ . Then $A^*b - A^*Ap = 0$ . We claim $r(p) \perp \text{Col(A)}.$ Indeed, for any $Az \in \text{Col}(A)$ , we have $$(Az)^*(b - Ap) = z^*(A^*b - A^*Ap ) = 0.$$ Now, by the Pythagorean Theorem, $$||b - Ay||^2 = ||b - Ap + Ap - Ay||^2 = ||b - Ap||^2 + ||Ap - Ay||^2 \ge ||b - Ap||^2$$ with equality $\iff Ay = Ap$ . $\color{red}{\text{The flaw is here. I need to bound the function } ||b - Ax||}$ $\color{red}{\text{ by a constant, not by a function of p.}}$ Now suppose $x$ is a vector that solves the L.S. problem. Then $Ax = Ay$ , so $r(x) = b - Ax = b - Ap = r(p)$ and $r(p) \in \text{Null}(A^*)$ because $A^*Ap = A^*b \implies A^*(b - Ap) = 0$ . Now for the converse, suppose that $A^*Ax = A^*b$ . I don't yet know how to show that $Ax = Ap$ .","['matrices', 'abstract-algebra', 'linear-algebra', 'numerical-linear-algebra', 'numerical-methods']"
4034437,Poisson distribution problem including cdf,"The Question The number of cracks in a section of highway that is significant
enough to require repair is assumed to follow a Poisson distribution. (a) Let $Y$ be the number of cracks in $4$ km, sketch the (CDF) Cumulative
Distribution Function and graph up to $𝑦 = 4.5$ . (b) If we should order the material to fix the cracks beforehand, how
many packages of the material (One package for one crack) shall we
order to ensure that all the cracks in $4$ km can be fixed with at least $95\%$ chance? My Understanding For part (a), I tried to compute the probabilities of $Y=0, 1, 2, 3, 4, 5$ respectively, by using the formula of $Pr(X=k)=\frac{e^{-𝜇}\mu^k}{k!}$ however, when I tried to sum these probabilities together , $F(Y)$ turns out to exceed $1$ , where probability should not $\gt 1$ , what's wrong with that? What is the appropriate way to find the probabilities and thus I can graph up to $y=4.5$ ? For part (b), for my understanding, this Poisson distribution has infinite number of cracks, so I am quite doubt that how to ensure that all the cracks in $4$ km can be fixed with at least $95\%$ chance?","['statistics', 'probability-distributions', 'probability']"
4034443,computing the limit $\lim_{\theta \to \frac{\pi}{2}} (\sec \theta - \tan \theta)$,I'm trying to compute the following limit and would greatly appreciate your heartening feedback on my solution. The limit: $\lim_{\theta \to \frac{\pi}{2}} (\sec \theta - \tan \theta)$ My steps in deriving the solution: Preliminary identities: $\sec \theta = \frac{1}{\cos \theta}$ $\tan \theta = \frac{\sin \theta}{\cos \theta}$ $\frac{1}{\cos \theta}-\frac{\sin\theta}{\cos\theta} = \frac{1-\sin\theta}{\cos\theta} = \frac{1-\sin^2\theta}{(1+\sin\theta)\cos\theta} = \frac{\cos^2\theta}{\cos\theta}\cdot \frac{1}{1+\sin\theta} = \frac{\cos\theta}{1+\sin\theta} = \frac{0}{1+1}$ When $\theta \to \frac{\pi}{2}$ then $\cos(\frac{\pi}{2}) = 0$ and $\sin(\frac{\pi}{2}) = 1$ The answer being: $\lim_{\theta \to \frac{\pi}{2}} (\sec \theta - \tan \theta) = 0$,"['limits', 'limits-without-lhopital']"
4034449,Prove that if $f:M\rightarrow\Bbb R$ is a scalar function over a 1-manifold M without boundary then $\int_M df=0$,"Well James Munkres in the text Analysis on Manifolds prove the general Stoke's theorem for $k$ -form when $k>1$ and then he proves it for $k=1$ only when the bounary of the Manifold is not empty and he leaves as exercise to show that if $f$ is a scalar function defined over a compact $1$ -manifold $M$ then $$
\int_M df=0
$$ So let's start to try to prove it and precisely we will do to scalar function whose support is covered by a single coordinate chart becasue as Munkres showed in the general proof this is sufficent. Indeed if $\Phi:\{\phi_i:i=1,...,l\}$ is a partition of unity dominated by the coordinate patches of $M$ then the support of the forn $\phi_i\omega$ is contained in a single coordinate patch for each $i=1,..,l$ and thus $$
\int_Md\omega=\int_M0+\int_Md\omega=\int_M0\curlywedge\omega+\int_M\Biggl(\sum_{i=1}^l\phi_i\Biggl)\curlywedge d\omega=
\\
\int_Md1\curlywedge\omega+\int_M\Biggl(\sum_{i=1}^l\phi_i\curlywedge d\omega\Bigg)=
\\
\int_Md\Biggl(\sum_{i=1}^l\phi_i\Biggl)\curlywedge\omega+\sum_{i=1}^l\Biggl(\int_M\phi_i\curlywedge d\omega\Biggl)=
\\
\sum_{i=1}^l\Biggl(\int_Md\phi_i\curlywedge\omega\Biggl)+\sum_{i=1}^l\Biggl(\int_M(-1)^0\phi_i\curlywedge d\omega\Biggl)=\sum_{i=1}^l\Biggl(\int_Md\phi_i\curlywedge\omega+\int_M(-1)^0\phi_i\curlywedge d\omega\Biggl)
\\
\sum_{i=1}^l\Biggl(\int_Md\phi_i\curlywedge\omega+(-1)^0\phi_i\curlywedge d\omega\Biggl)=\sum_{i=1}^l\int_Md(\phi_i\omega)=0
$$ Well if $M$ is a compact $1$ -manifold without boundary it is possible to prove that for any $p\in M$ there exist a coordinate patch $\alpha$ defined in the unitary positive interval $(0,1)$ and thus if $f:M\rightarrow\Bbb R$ is a scalar function defined over M whose support $S_f$ is covered by a single coordinate patch then $$
\int_Mdf:=\int_{(0,1)}\alpha^*(df)=\int_{(0,1)}d(\alpha^*f)=\int_{(0,1)}d(\alpha\circ f)
$$ So Unfortunately I do not able to prove that $$
\int_{(0,1)}d(\alpha\circ f)=0
$$ and thus I ask to do it. So could someone help me, please?","['multivariable-calculus', 'calculus', 'stokes-theorem', 'compact-manifolds', 'differential-geometry']"
4034617,Cyclotomic units modulo $p$-th powers in the cyclotomic tower,"Let $E$ be the unit group of the cyclotomic field $L_n=\mathbb{Q}(\zeta_{p^n})$ where $\zeta_{p^n}$ is a primitive $p^n$ -th root of unity. Let $G=Gal(L_n/\mathbb{Q})$ and let $\Delta=Gal(L_1/\mathbb{Q})$ . If we let $\omega: (\mathbb{Z}/p\mathbb{Z})^{\times} \to \mu_{p-1}\in \mathbb{Z}_p$ be the Teichmuller character (which we may also regard as a character to $\mathbb{Z}/p^n\mathbb{Z}$ by reducing modulo $p^n$ ), then we may embed $\Delta$ into $G$ by sending $\sigma_a \mapsto \sigma_{\omega(a)}$ . In this way, $E$ is a $\Delta$ -module and $E/E^p$ is a $\mathbb{Z}/p\mathbb{Z}[\Delta]$ -module. Define the usual idempotents for $i=0,\dots,p-2$ \begin{align*}
\theta_i=-\sum_{a=1}^{p-1}a^i\sigma_{\omega(a)}^{-1}
\end{align*} and decompose $E/E^p$ as a direct sum of its eigenspaces in the usual way. Now if we further suppose that $p$ is regular, then $p$ does not divide the index of the cyclotomic units in the full unit group so we may take cyclotomic units as generators for each of the subspaces. It is shown in Washington's book that when $n=1$ , $\theta_i(E/E^p)=0$ for odd $i \neq 1$ , $\theta_1(E/E^p)=\langle \zeta_p \rangle$ , $\theta_0(E/E^p)=0$ and $\theta_i(E/E^p)\cong \mathbb{Z}/p\mathbb{Z}$ for even $i\neq 0$ . In addition, if $g$ is a primitive root modulo $p$ , we have that \begin{align*}
E_i=\prod_{a=1}^{p-1}\Big(\zeta^{(1-g)/2}\frac{1-\zeta^g}{1-\zeta}\Big)^{a^i\sigma_a^{-1}}
\end{align*} are generators for $\theta_i(E/E^p)$ and even $i$ .
When $n>1$ , things are not so simple.
The odd components are the same since every unit in $L_n$ is a product of a root of unity and a real unit and the odd components of real units vanish.
What I am having trouble with is determining the even components. For the $n=1$ case, there was a simple, perhaps naive, guess that turned out to be true: If $E_{+}$ is the group of real units, then $E_{+}/E_{+}^p\cong (\mathbb{Z}/p\mathbb{Z})^{(p-3)/2}$ by the Dirichlet unit theorem, the $0$ -th component vanishes since $\theta_0$ is just the inverse of the norm, so the obvious guess is that the remaining $(p-3)/2$ even eigenspaces  are all cyclic of order $p$ . For $n>1$ , the $0$ -th component doesn't necessarily vanish since it isn't a norm to $\mathbb{Q}$ but a norm to the subfield of degree $p^{n-1}$ over $\mathbb{Q}$ . Also, $E_{+}/E_{+}^p \cong (\mathbb{Z}/p\mathbb{Z})^{p^{n-1}(p-1)/2-1}$ so unless I'm completely overlooking something it doesn't seem obvious how the sizes of the components should be distributed. What I do have is a set of generators for $E_{+}/E_{+}^p$ : If $g$ is a primitive root modulo $p^n$ then \begin{align*}
\zeta_{p^n}^{(1-g)/2}\frac{1-\zeta_{p^n}^g}{1-\zeta_{p^n}}
\end{align*} generates the  real cyclotomic units modulo $\{\pm 1\}$ over $\mathbb{Z}[G]$ so hitting all Galois conjugates of these elements with the idempotents $\theta_i$ will give us a set of generators for the components but it will be redundant. Has anyone come across an analysis of this decomposition or something relevant?","['number-theory', 'cyclotomic-fields']"
4034628,Mathematical constants and approximations of irrational numbers,"I found two examples where various constants have some surprising properties, related to the approximations of real numbers (you can convince yourself with Wolfram Alpha): The real number $\pi^{\pi^{1/\pi}}\approx5.19644$ has the same first $\lfloor \pi \rfloor$ decimals as the number $3\sqrt{\lfloor \pi\rfloor}\approx5.19615$ . If we replace $\pi$ with $e$ in the above phrase, we get the same result: $e^{e^{1/e}}\approx4.24044$ , $3\sqrt{\lfloor 
 e\rfloor}\approx4.24264$ . The Euler-Mascheroni constant, $\gamma\approx0.57721$ , has the same first $3$ decimals as $\frac{1}{\sqrt3}\approx0.57735$ . It is very unlikely that these examples do have a strong mathematical explanation, therefore they might be pure coincidence. For the first one, it seems obvious that if I change the $100^{th}$ decimal of $\pi$ , for example, the result still holds. Also, over a ,,small'' neighbourhood of $\pi$ or $e$ , the result is verified. Do you know other similar examples, where mathematical constants ""almost"" satisfy a short equation or appear in an unexpected way (I mean, not related to their usual definitions and applications)? You are more than welcome to post an answer, your effort will be appreciated! P.S. This question is mainly recreational and is the result of my pure imagination.","['real-numbers', 'recreational-mathematics', 'floating-point', 'real-analysis']"
4034629,How to express a formula that iterates over itself n number of times?,"I'm not very good at math so I might use the wrong words when searching for an answer (i even don't know what tags to apply). I have an expression in a loop and the only way I can explain it is something like this. x = h
Loop n times
  x = k*x
end loop
Result = x h is the initial value of x . For each loop x = k*x n is the number of loops
After n loops x now hold the result. How do I express this mathematically?","['notation', 'functions', 'sequence-of-function']"
4034650,How to show the sequence $\left\{6(-\frac{5}{6})^n\right\} _{n=1}^\infty$ converges to $0$?,"Some quick notes about what I have studied so far about sequences (Note: this is an edit after I accepted the answer and realized my lack of understanding for this simple sequence): Here I am working with sequences of Real numbers, therefore, for that sequence, I defined a function $a$ , such that $$a: \mathbb{N}\to \mathbb{R}$$ $$a:n  \mapsto a(n) = a_n$$ The sequence is denoted as $\{a_n\}_{n\in\mathbb{N}}$ , such that $\mathbb{N} = \{1, 2, 3, ...\}$ . Given sequence $\left\{6(-\frac{5}{6})^n\right\} _{n=1}^\infty$ Once a sequence $\{a_n\}_{n\in\mathbb{N}}$ is convergent for $L\in\mathbb{R}$ when $n\to\infty$ , therefore $$\lim _{n\to\infty} a_n = L$$ this is for only if for a given $\epsilon > 0$ , so we can find a $N_0 \in \mathbb{N}$ such that $\forall n > N_0$ we have $|a_n - L| < \epsilon $ .
Basically, a sequence is convergent if it tends to a Real number. On the other hand, it is divergent if it does not converge to a Real number. This is the reason why I tried to find the limit but I ended up not being able to solve it. I know that for the sequence $a_n$ , such that $a_n = 6\left(-\dfrac{5}{6}\right)^n$ we have. $$a_n = 6\left(-\dfrac{5}{6}\right)^n = 6 \cdot\dfrac{(-5)^n}{6^n} = 6^{1-n}\cdot(-5)^n$$ According to Wolfram Alpha, $\lim _{n\to \infty }(6^{1-n}(-5)^n) = 0$ and thus the sequence converges to $0$ . But I couldn't solve the limit. Wolfram solves it using exponential but it wasn't a straightforward solution for me. How can I solve $\lim _{n\to \infty }(6^{1-n}(-5)^n)$ in a simpler and good way? This might be a  consequence of the first question, but how can I show that the sequence is convergent? What would be another approach?","['calculus', 'sequences-and-series']"
4034667,A different way to calculate $\int_0^\infty \tfrac{1}{1+x^n} dx$.,"Most of you might have stumbled upon this integral, when studying complex analysis, namely via contour integration, but today I asked myself if there is a different way to calculate it. I'm almost sure that I'm not the first one to come up with this technique, but I wanted to share it with you and would like to know if anyone of you knows another approach. EDIT I made a mistake regarding the format of this post, so I posted my own approach as an answer now.","['integration', 'solution-verification', 'gamma-function']"
4034673,Why $E|X-Y|^2 = 0$ implies $P(X=Y) = 1$,"Why does $$\mathbb{E}|X(t)-Y(t)|^2 = 0$$ imply $$\mathbb{P}(X(t)=Y(t))=1$$ for all $t$ . Idea: By Markov we get $\mathbb{P}(|X-Y|^2 \geq a)=0$ , respectively $\mathbb{P}(|X-Y|^2 < a)=1$ with $a$ any real number.
I believe this is a first step, but what is the following step and how is it written mathematically correct?","['expected-value', 'probability-theory', 'probability', 'random-variables']"
4034675,Derivative of trace involving Hadamard product,"Let us assume that $A, S\in\mathbb{R}^{n\times n}$ , $U\in\mathbb{R}^{n\times k}$ , and $V\in\mathbb{R}^{n\times k}$ . I am trying to differentiate the following expression: $$\Phi(U,V)=\mathrm{trace}\left((S\circ A)(S^T\circ(VU^T))\right),$$ with respect to $U$ and $V$ , respectively, i.e.: $$\frac{\partial \Phi}{\partial U}\quad and\quad \frac{\partial \Phi}{\partial V}.$$ in which $\mathrm{trace}(\cdot)$ is the trace of a matrix, and $\circ$ is the Hadamard product. I appreciate any help.","['scalar-fields', 'hadamard-product', 'matrices', 'matrix-calculus', 'derivatives']"
4034688,Is it true that the domain of this function is finite?,"(This is a subproblem that came up as I was proving that $\{e: \phi_e(x) \text{ has infinite domain}\}$ is $\Pi_2$ -complete.) Let $A$ be a set of natural numbers and suppose $$n\in A\iff \forall y_1\exists y_2 T(n,y_1,y_2)$$ (where $T$ is a (computable) relation). Consider this  partial function on pairs of natural numbers: $$(n,x) \mapsto 1\text{ if }\forall y_1\leq x\exists y_2 T(n,y_1,y_2)\\(n,x)\text{ is undefined otherwise} $$ If $n\in A$ , then the above function as a function of $x$ is total. Is it true that if $n\notin A$ , then this function (again as a function of $x$ ) has finite domain? I think so, and I think this is a trivial result but I can't wrap my head around proving it in a formal way. Here's what I think informally: if $n\notin A$ , then the first condition in the definition may be true for small $x$ , but starting from some $x_0$ , that wouldn't be true. Is this indeed the case? I can't connect this with the negation of $x\in A$ i.e. with $\exists y_1\forall y_2 \neg  T(n,y_2,y_3) $ . Edit: I modified the original function. Does the new function has a finite domain as a function of $x$ when $x\notin A$ ? If not, I was wondering if there's a way to modify this function further so that (1) it remains computable, (2) if $n\in A$ , the domain is still infinite, (3) if $n\notin A$ , the domain is finite?","['predicate-logic', 'quantifiers', 'logic', 'functions', 'computability']"
4034693,How to show that this $2n \times n^2$ matrix has rank $2n-1$?,"The matrix is fairly messy to present, but quite easy to understand. When $n=3$ , the matrix is \begin{bmatrix}
1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0\\
0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 & 0\\
0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1\\
1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1
\end{bmatrix} So, basically, it splits into two parts: the upper part (from row $1$ to row $n$ ) has $n$ identity matrices $I_n$ . the lower part is $O_n^1, \ldots, O_n^n$ , where each $O_n^i$ is an $n \times n$ matrix whose $i$ -th row is all one whereas the other entries are zero. By some examples and intuition, I am aware that the rank of such a matrix is $2n-1$ , but how should I rigorously prove it?","['matrices', 'matrix-rank', 'linear-algebra']"
4034784,What exactly is sheafification?,"I have recently learned about the very BASICS of sheaves, but I was wondering is there an easier definition for sheafification? I could not find anywhere an easier definition for sheafification. I kind of compare it to local rings, where in local rings, you collect the local data at a point for a variety or an algebraic set where some function is defined on that regular set. Am I heading in the right direction? If not, what is the rigorous definition of sheafification and what is some intuition one could use to understand it? I would much more appreciate the intuition and a clear definition, rather than rigour.","['local-rings', 'algebraic-geometry', 'sheaf-theory']"
4034812,Billy and Bob start with two rectangular grid which can be modeled as a chocolate,"Billy and Bob start with two rectangular grid which can be modeled as
a chocolate. They take turns cutting and eating the chocolate: on
their turn, they can cut the chocolate along an edge parallel to the
sides (thus resulting in three rectangles) and consume one of the
three pieces, so that his partner has two chocolates, and therefore
can make an analogous move. A player loses if they cannot make a cut.
Assuming optimal play, who wins if: (a) the starting rectangles are $1\times 2020$ and $2\times 4040$ , (b) the starting rectangles are $100\times100$ and $100\times 500$ , and (c) generalize. My friend and I tested the first case (a) extensively, and ended up with somewhat of a mirroring thing if there are two $1\times n$ rectangles resultant. However, if $n$ is even one player could theoretically cut the $1\times n$ into two $1\times\frac n2$ rectangles, and discord the other $1\times n$ . I don't know how to continue.","['recreational-mathematics', 'puzzle', 'combinatorics', 'combinatorial-game-theory']"
4034814,"Solve Limit Tend To $\pi$, From Length Of Circle","Computing the length of a semicircle of radius 1. It's divided in $2^x$ equal arcs, I find the following formula for the total length of the chords created: $$L=2^{x+1} \sin \left( \frac{45}{2^{x-1}} \right)$$ When $x \to \infty$ we see, geometrically, that this expression tends to be  the length of the circle: $$2^{x+1} \sin \left( \frac{45}{2^{x-1}} \right)$$ My goal is to define $\pi$ as the value of that expression when $x \to \infty$ (the limit). But how can I rigorously prove that this limit exists and that the expression tends to be the length of the circle? In other words, how can I write rigorously the geometric ideas? Note: The number $\frac{45}{2^{x-1}}$ is in degrees.","['limits', 'pi', 'geometry']"
4034850,Algebraic argument for why any $A_5$ in $S_6$ can be extended to an $S_5$ in $S_6$,"It is well known that $S_5$ is a subgroup of $S_6$ in a way that acts transitively on $6$ points, a surprising fact related to the outer automorphism of $S_6$ . One can see this using the icosahedron: its rotational symmetry group is isomorphic to $A_5$ , and acts transitively on the $6$ axes of the icosahedron that go through opposite vertices. One can show that this exotic $A_5$ in $S_6$ extends to an $S_5$ in $S_6$ (see this excellent page by John Baez), using some geometric observations. Is there a purely algebraic way to see that any $A_5$ including into $S_6$ extends to an inclusion of $S_5$ in $S_6$ , that avoids working directly with the icosahedron? If such an argument were slick enough, I might prefer it to the way Baez gives (not that I don't love the icosahedron!)","['symmetric-groups', 'group-theory', 'platonic-solids']"
4034867,F-distributions and chi-square distributions: Can someone help explain the answer to this problem?,"Let $X_1, X_2, X_3, X_4$ be independent $\mathscr{N}(\mu,
 \sigma^2)$ random variables. Find the distribution of the ratio $$R=\frac{(X_1-X_2)^2}{(X_3-X_4)^2}.$$ Note that $X_1-X_2$ and $X_3-X_4$ are independent $\mathscr{N}(0,
 \sigma^2)$ random variables. Thus $W_1=(X_1-X_2)^2/(2\sigma^2)$ and $W_2=(X_3-X_4)^2/(2\sigma^2)$ are independent $\mathcal{x}^2(1)$ random variables. Since $R$ equals $W_1/W_2$ , we conclude $R\sim
 F(1,1).$ I understand that an $F$ distribution is the ratio of two chi-squares with their respective degrees of freedom.  But for this one, why is the square of a non-standard normal distribution a chi-square?  Why is it only one degree of freedom?  Moreover, where does the $2\sigma^2$ come from on the denominators for $W_1$ and $W_2$ ?","['statistics', 'probability-distributions']"
4034939,"What is is it meant by ""analytically derive the expected value of an estimator?"" in statistics?","Good evening, everyone. I am new to statistics, so I wanted to see if I could get guidance with this problem: Consider a variable Y which follows a distribution with mean µ and variance σ2 in the population.
Suppose we take a random sample of Y of size n, and propose to estimate the mean of Y from this
dataset using two potential new estimators, the Addition Estimator and the First-ten Estimator, which
are defined as follows: The Addition Estimator: Take the sample mean, and add on $\frac{20}{n}$ The First-ten Estimator: Select only the first ten observations in the sample, and take the sample
mean of these observations For the sake of simplicity, we will assume that we always take samples containing more than ten obser-
vations. Remember that the sample mean can be calculated in the following manner: $µ = ∑_n \frac{Yn}{n} $ Analytically derive the expected value of both estimators. Based on these results, is each estimator
biased or unbiased? Using your knowledge of limits, intuitively explain what you think will happen
to the bias (that is, the degree to which E[θ] deviates from θ) as n approaches infinity I am not understanding what it means to ""analitically derive de expected value"" if someone could explain me what it means and how to do it, I would be very thankful. Thank you again!",['statistics']
4034947,"Help-me, please! Solve $\oint_{c} xy ds$ where $C$ is the intersection of the surfaces $x^2+y^2=4$ and $ y+z=8 $","Solve $\oint_{c} xy ds$ where $C$ is the intersection of the surfaces $x^2+y^2=4$ and $ y+z=8 $ Hi. I tried to resolve the issue below using the definition of line integral, but I couldn’t solve it. Could someone appreciate my resolution and help me finish it? Below follows what I did: $$\oint_{c} xy ds = {\int }_{C}f\left(x,y,z\right)ds= \int_{a}^{b}f\left(\text{r}\left(t\right)\right)\sqrt{{\left({x}^{\prime }\left(t\right)\right)}^{2}+{\left({y}^{\prime }\left(t\right)\right)}^{2}+{\left({z}^{\prime }\left(t\right)\right)}^{2}}dt.$$ \begin{align*}
		x&=2\cos t \\
		y&=2\sin t \\
		z&=8-2\sin t
	\end{align*} \begin{align*}
f\left(\text{r}\left(t\right)\right)&=\langle 2\cos t, 2\sin t, 8-2\sin t \rangle \\
ds = \left\Vert\left(\text{r}\left(t\right)\right)^{\prime} \right\Vert&= \sqrt{{\left({x}^{\prime }\left(t\right)\right)}^{2}+{\left({y}^{\prime }\left(t\right)\right)}^{2}+{\left({z}^{\prime }\left(t\right)\right)}^{2}}dt
\end{align*} Thus, \begin{align*}
\oint_{c} xy ds ={\int }_{C}f\left(x,y,z\right)ds&={\int_{0}^{2\pi}}(4\cos t\sin t)\sqrt{{\left({-2\sin t}\right)}^{2}+{\left({2\cos t}\right)}^{2}+{\left({-2\cos t}\right)}^{2}} dt \\
	 &={\int_0^{2\pi}} 8\cos \left(t\right)\sin \left(t\right)\sqrt{-\sin ^2\left(t\right)+2} dt \\
	 &= -\left[\frac{8}{3}\left(1+\cos ^2\left(t \right)\right)^{\frac{3}{2}}\right]_{_{0}}^{^{2\pi}} \\
	 &=0.
\end{align*} Thanks!","['multivariable-calculus', 'calculus', 'differential-geometry']"
4034948,Computing the value of $\zeta(6)$ and $\zeta(8)$,"I know the closed form formula for calculating the values of Zeta function at even integers. I was able to derive it from the coefficients of the power series of $-\dfrac{\pi x}{2}\cot(\pi x)$ . Now, I am looking at the way with which Euler was able to derive the values of $\zeta(2n)$ . I have seen this "" trick "" in Brilliant: So I have: $$\dfrac{\sin(x)}{x}=1-\dfrac{x^2}{3!}+\dfrac{x^4}{5!}-\dfrac{x^6}{7!}+\dfrac{x^8}{9!}...\tag{1}$$ $$\dfrac{\sin(x)}{x}=\left(1-\dfrac{x^2}{\pi^2}\right)\left(1-\dfrac{x^2}{4\pi^2}\right)\left(1-\dfrac{x^2}{9\pi^2}\right)\left(1-\dfrac{x^2}{16\pi^2}\right)...\tag{2}$$ $$\dfrac{\sin(ix)}{ix}=1-\dfrac{(ix)^2}{3!}+\dfrac{(ix)^4}{5!}-\dfrac{(ix)^6}{7!}...\tag{3}$$ $$\dfrac{\sin(ix)}{ix}=1+\dfrac{x^2}{3!}+\dfrac{x^4}{5!}+\dfrac{x^6}{7!}...\tag{4}$$ $$\dfrac{\sin(ix)}{ix}=\left(1-\dfrac{(ix)^2}{\pi^2}\right)\left(1-\dfrac{(ix)^2}{4\pi^2}\right)\left(1-\dfrac{(ix)^2}{9\pi^2}\right)\left(1-\dfrac{(ix)^2}{16\pi^2}\right)...\tag{5}$$ $$\dfrac{\sin(ix)}{ix}=\left(1+\dfrac{x^2}{\pi^2}\right)\left(1+\dfrac{x^2}{4\pi^2}\right)\left(1+\dfrac{x^2}{9\pi^2}\right)\left(1+\dfrac{x^2}{16\pi^2}\right)...\tag{6}$$ Multiply $(6)$ and $(2)$ , I have: $$\dfrac{\sin(x)\sin(ix)}{ix^2}=1+\left(\dfrac{x^2}{3!}-\dfrac{x^2}{3!}\right)+\left(\dfrac{x^4}{5!}+\dfrac{x^4}{5!}-\dfrac{x^4}{(3!)^2}\right)+...\tag{7}$$ $$\dfrac{\sin(x)\sin(ix)}{ix^2}=\left(1+\dfrac{x^2}{\pi^2}\right)\left(1-\dfrac{x^2}{\pi^2}\right)\left(1+\dfrac{x^2}{4\pi^2}\right)\left(1-\dfrac{x^2}{4\pi^2}\right)\left(1+\dfrac{x^2}{9\pi^2}\right)\left(1-\dfrac{x^2}{9\pi^2}\right)...\tag{8}$$ $$\dfrac{\sin(x)\sin(ix)}{ix^2}=\left(1-\dfrac{x^4}{\pi^4}\right)\left(1-\dfrac{x^4}{16\pi^4}\right)\left(1-\dfrac{x^4}{81\pi^4}\right)...\tag{9}$$ Comparing the coeffcients of $x^4$ in the infinite Maclaurin series and the infinite product, we will arrive at $\zeta(4)=\dfrac{\pi^4}{90}$ . Now that I wish to continue this process to see if I can get $\zeta(6)$ , $\zeta(8)$ , $\zeta(10)$ , I don't know how to continue. The trick above works fine for $\zeta(4)$ , but what about higher $\zeta(2n)$ . I look around and find this interesting post of user17762 : In his answer, he wrote the function on the LHS as $\dfrac{i\sin(z)\sin(\dfrac{z}{i})}{z^2}$ . A little bit of manipulation shows that it is exactly like $\dfrac{\sin(x)\sin(ix)}{ix^2}$ or $\dfrac{\sin(x)\sinh(x)}{x^2}$ I have tried to multiply again $\dfrac{\sin(x)\sinh(x)\sin(x/i^2)}{x^2(\frac{x}{i^2})}=\dfrac{\sin^2(x)\sinh(x)}{x^3}$ , using the hint found in the answer of the member above. Then I use Wolfram to check the series expansion of this function but the third term of $x^6$ is $\dfrac{5}{3024}$ . I thought that I should a find a function where its coefficient of $x^6$ should be $\dfrac{1}{945}$ . I am not sure if my reasoning is problematic. Is there an algorithm to find the function on the LHS?","['riemann-zeta', 'sequences-and-series', 'analysis', 'real-analysis']"
4034979,Cardinals of $\mathbb{N}$ and $2^\mathbb{N}$ proof,"Show that $\mathbb{N}^{\mathbb{N}}$ is equivalent to $2^\mathbb{N}$ , where $2^\mathbb{N} = \{f:\mathbb{N} \rightarrow \{0, 1\}\}$ . My attempt: It suffices to show that the two sets have the same cardinal. We know that $|\mathbb{N}| = \aleph_0$ . So, $2^{\aleph_0}\leq \aleph_0^{\aleph_0}\leq (2^{\aleph_0})^{\aleph_0} =2^{\aleph_0\cdot\aleph_0} = 2^{\aleph_0^2} = 2^{\aleph_0}$ What theorem does this proof follow from? Also, is there a way to do this proof by constructing a bijective function? If yes what would such a proof look like? Any insight much appreciated.","['elementary-set-theory', 'cardinals', 'proof-writing']"
4035032,A question about the derivative of trace involving Hadamard product,"Assume that $X\in\mathbb{R}^{n\times n}\geq 0$ , $Y\in\mathbb{R}^{n\times k}\geq 0$ and $Z\in\mathbb{R}^{k\times n}\geq 0$ . Let us define the function $f(Y,Z)$ as follows: $$f(Y,Z)=\Vert X-YZ\Vert_W^2:=\mathrm{trace}\left((X-YZ)^T(W\circ(X-YZ))\right),$$ where $\circ$ is the Hadamard product and $W\in\mathbb{R}^{n\times n}\geq 0$ is symmetric. It can be seen that \begin{align*}
f(Y,Z)&=\mathrm{trace}\left((X^T-Z^TY^T)(W\circ(X-YZ))\right)\\
&=\mathrm{trace}(X^T(W\circ X))-\mathrm{trace}(X^T(W\circ (YZ)))-\mathrm{trace}(Z^TY^T(W\circ X))
+\mathrm{trace}(Z^TY^T(W\circ (YZ))).
\end{align*} Now, according to the fact that $\mathrm{trace}(AB)=\mathrm{trace}(BA)$ , and $\mathrm{trace}(A^T(B\circ C)=trace((A\circ B)^TC)$ , it follows that $$f(Y,Z)=\mathrm{trace}(X^T(W\circ X))-2\mathrm{trace}(Z^TY^T(W\circ X))
+\mathrm{trace}(Z^TY^T(W\circ (YZ))).$$ I have a question about the derivative of $f$ with respect to $Y$ or $Z$ . To this end, we have $$\frac{\partial \mathrm{trace}(Z^TY^T(W\circ X))}{\partial Y}=(W\circ X)Z^T,\quad and\quad \frac{\partial \mathrm{trace}(Z^TY^T(W\circ X))}{\partial Z}=Y^T(W\circ X).$$ What can it be said about the following items? $$\frac{\partial \mathrm{trace}(Z^TY^T(W\circ (YZ)))}{\partial Y},\quad and\quad\frac{\partial \mathrm{trace}(Z^TY^T(W\circ (YZ)))}{\partial Z}.$$ I would be appreciate if someone can help me.","['matrices', 'hadamard-product', 'derivatives']"
4035080,Locally finite vs. Borel measures on $\sigma$-compact Polish spaces,"Let $E$ be a Polish space, and let $\mu$ be a measure on $E$ . Define the following properties: $E$ is $\sigma$ - compact if $E$ is the countable union of compact sets. $E$ is locally compact if every $x \in E$ has an open neighborhood $U$ whose closure is compact. $\mu$ is locally finite if for every $x \in E$ , there is an open set $U \subset E$ containing $x$ with $\mu(U) < \infty$ . $\mu$ is a Borel measure if for every compact $K \subset E$ , we have $\mu(K) < \infty$ . Clearly a locally finite measure is Borel. And if $E$ is locally compact (not even necessarily separable or complete), Borel measures are necessarily locally finite. But are there more general conditions for which Borel measures are locally finite? Question: If $E$ is a $\sigma$ -compact Polish space and $\mu$ is a Borel measure, is $\mu$ locally finite? I can’t think of a counter example to this, but I’m having trouble proving it. My original strategy was to prove that a $\sigma$ -compact Polish space is locally compact. However, as the comments demonstrate, $\sigma$ -compact Polish spaces are not necessarily locally compact, so that strategy doesn’t work. A counter example is the subset $X \subset \ell^2$ given by the union of the lines $X_k = \{\lambda e_k : \lambda \in \mathbb R\}$ , where $\{e_k\}_{k \geq 1}$ is the standard orthonormal basis of $\ell^2$ . Then $X$ is $\sigma$ -compact, but not locally compact (at the origin specifically). But I’m not sure of a measure $\mu$ on this space that is Borel, but not locally finite; the problem is there are compact subsets of $X$ containing $0$ and intersecting infinitely many of the $X_k$ . Can anyone think of a counter example?","['polish-spaces', 'general-topology', 'measure-theory', 'real-analysis']"
4035109,Contractive Fixed Point Theorm for Vector Value Functions,"Consider the following question: I tried to look on the function $g(x)=f(x)+[x_1,x_2]$ , so if I could prove that $g(x)\in S$ for $x\in S$ , then by the contractive fixed point theorm there exists some vector $a$ such that $g(a)=a$ and therefore $f(a)=0$ .
I prove it in the following ways: I tried to prove that $||g(x)||<=1$ for $||x||<=1$ but I couldn't do it, the calculations got too complex. I tried to prove that $|g(b)-g(a)|<=K|(b-a)|$ for $a,b\in S$ and $0<K<1$ but I couldn't find any such $K$ . I tried to use the mean value theorm - since for every $a,b \in S$ there exists some vector $c\in S$ such that $g(b)-g(a)=(\nabla g)(c)(b-a)$ then if I can prove that $||(\nabla g)(c)||<1$ for $c\in S$ then I can find a $K$ for section 2. Am I going in the right direction? Can I get any hints?","['fixed-points', 'functions', 'vectors', 'fixed-point-theorems']"
4035183,How do we solve $y''=e^{2y}$?,"I tried to make the substitution $v=y'(x)$ , which would ( hopefully ) make this into a separable ODE as per the following. $$y''=e^{2y}$$ by the chain rule, we have $v'=v'(y(x)) \cdot y'(x)=\frac{dv}{dy}\frac{dy}{dx}$ . If we make the substitution, then $$\frac{dv}{dy}\frac{dy}{dx}=e^{2y}$$ So we could cancel the differential terms $dy$ ? I wonder if we can really do so, and also a better substitution might be just $v=y(x)$ . Am I on the right track here?",['ordinary-differential-equations']
4035376,"Categorize circle on a plane with ""left"" and ""right"" relative to a line.","CONTEXT: I'm doing a simulation in Object Oriented Programming. I have a bunch of circles with properties: Location = Vector with x and y coordinate Angle = Vector détermining ""where"" the circle is looking at DetectionRadius = A bigger circle, we want to interact only with others circle located within that circle. So i have my central circle and secondary circle all around the plane. I have access to all circle properties in an array. My question is: PROBLEM: How can i determine wich circle is on the left side of my central circle, and wich are on the right side ? Here is an image to understand better what i mean: Image1 (Principal circle is in the center, black line is the angle vector (we can extend it to a line if needed), blue circle is the detection radius and other green circle are secondary circles) I already know wich secondary circle are in the principal circle's detection radius. I just need to know wich are on the left, wich are on the right. Thank you !","['trigonometry', 'linear-algebra', 'geometry', 'circles']"
4035416,Prove $\frac1{\sin A}+\frac1{\sin B}+\frac1{\sin C}-\frac12(\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}) \ge \sqrt{3}$,Let $ABC$ be a triangle. Prove that: $$\frac{1}{\sin A}+\frac{1}{\sin B}+\frac{1}{\sin C}-\frac{1}{2}\left(\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}\right) \ge \sqrt{3} $$ My attempt: $$P=\frac{1}{\sin A}+\frac{1}{\sin B}+\frac{1}{\sin C}-\frac{1}{2}\left(\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}\right) = \frac{1}{2}\left(\cot\frac{A}{2}+\cot\frac{B}{2}+\cot\frac{C}{2}\right)$$ $$\alpha = \cot\frac{A}{2}+\cot\frac{B}{2}+\cot\frac{C}{2}=\cot\frac{A}{2}\cdot\cot\frac{B}{2}\cdot\cot\frac{C}{2}$$ $$\Leftrightarrow \alpha \ge3.\sqrt[3]{\alpha} \Leftrightarrow \alpha^2\ge27\Leftrightarrow \alpha\ge3\sqrt{3}$$ $$\Rightarrow P=\frac{1}{2}\alpha\ge\frac{3\sqrt{3}}{2}$$ Hmm where I was wrong ?,"['trigonometry', 'a.m.-g.m.-inequality', 'inequality']"
4035441,Measure theory book suggestion for a foundation to Probability theory,"I would like your comment (or another suggestions) on the 2 measure theory books for self-study: Introduction to measure theory by Terence Tao Measures, Integrals and Martingales by René L. Schilling My goal is to have only necessary foundations (because I don't want to go too deep in the measure theory) to understand the rigorous foundation of probability (to the point of Brownian motion and Ito's calculus) and furthermore, the theoretical foundation of statistics ( $i.e$ to understand the rigorous logic behind Maximum Likelihood Estimator or hypothesis testing, monte-carlo simulation). Which measure theory book of these 2 books above will serve better for my purpose ? Could you suggest me a book (good for self-study) on Probability/statistics which serve my purposes above ? Thank you very much!","['measure-theory', 'probability-theory', 'statistics', 'stochastic-calculus']"
4035459,"difference between the metric tensor, dot product and metric","From my understanding the metric tensor is a function/tensor field that specifies a tensor at each point on a manifold, the tensor is used to define the inner product for the tangent space (in this sense the inner product can also be referred to as the dot product) and then from there we can naturally induce a norm and subsequently a metric for said tangent space at any given point on a manifold forming a metric vector space. Is this correct?","['metric-spaces', 'differential-geometry']"
4035460,Monotone class theorem to show the property for nonnegative measurable functions,"The Monotone Class theorem: Suppose $\mathcal{A}_0$ is an algebra, $\mathcal{A}$ is the smallest σ-algebra containing $\mathcal{A}_0$ , and $\mathcal{M}$ is the smallest monotone class containing $\mathcal{A}_0$ . Then $\mathcal{M}=\mathcal{A}$ . Suppose we want to prove a property $P$ for all nonnegative $\mathcal{S}$ -measurable functions $Z$ . Can we prove the property holds for simple functions or bounded continuous functions and use Monotone Class Theorem to extend the result to all nonnegative measurable functions? I know the technique holds for bounded functions, and I wonder if we may extend it to the unbounded cases? A similar discussion appears in Monotone class theorem for unbounded functions but they are talking about general measurable functions instead of nonnegative ones.","['stochastic-processes', 'measure-theory', 'random-variables']"
4035486,Proving that $f$ verifies $f(1−x) + f(x) = 1$,"I have a function which is defined for $x \in (0,1)$ and for $p>1$ with the expression \begin{align*} 
f(x) = \sum_{k=0}^{p-1} \frac{(-1)^{p+k}}{(p-1-k)!(p+k)!}\left(\prod_{i=k-p+1, i\neq0}^{k+p} (x+k-i)\right) 
\end{align*} I would like to show that $f(1-x) + f(x) = 1$ . What I have done so far With a little bit of algebra I have \begin{align*} 
f(x) 
&= \frac{1}{(2p-1)!}\sum_{k=0}^{p-1} (-1)^{p+k} \binom{2p-1}{p+k} \left(\prod_{i=k-p+1, i\neq0}^{k+p} (x+k-i)\right)
&& \text{using }\binom{n}{m} = \frac{n!}{m!(n-m)!}
\\
&= \frac{1}{(2p-1)!}\sum_{k=0}^{p-1} (-1)^{p+k} \binom{2p-1}{p+k} \left(\prod_{j=1-p, j\neq-k}^{p} (x-j)\right) 
&& \text{using the change of indices j=i-k} 
\\
&= \frac{1}{(2p-1)!}\sum_{k=0}^{p-1} (-1)^{p+k} \binom{2p-1}{p+k} \left(\prod_{j=1-p}^{p} (x-j)\right) \frac{1}{x+k}
&& \text{completing the product} 
\\
&= \frac{1}{(2p-1)!} \left(\prod_{j=1-p}^{p} (x-j)\right) \left(\sum_{k=0}^{p-1}\frac{(-1)^{p+k}}{x+k}\binom{2p-1}{p+k}\right)
&& \text{factoring the product from the sum} 
\end{align*} Then I introduce the functions \begin{align*} 
F(x) &= (2p-1)! f(x)  = G(x) H(x)\\
G(x) &= \prod_{j=1-p}^{p} (x-j) \\
H(x) &= \sum_{k=0}^{p-1}\frac{(-1)^{p+k}}{x+k}\binom{2p-1}{p+k}
\end{align*} So the initial question reduces to proving that $F(1-x) + F(x) = (2p-1)!$ Next, playing with the indices of the product I have been able to show that $G(1-x) = G(x)$ . So that now I only need to show $G(x) \left( H(1-x) + H(x)\right) = (2p-1)!$ EDIT: I have just been able to simplify $H(1-x) + H(x)$ as follows : \begin{align*} 
H(x) 
&=\sum_{k=0}^{p-1}\frac{(-1)^{p+k}}{x+k}\binom{2p-1}{p+k} 
\\
&=\sum_{s=p}^{2p-1}\frac{(-1)^{s}}{x-p+s}\binom{2p-1}{s}
&& \text{using a change of index } s=p+k 
\end{align*} And \begin{align*} 
H(1-x) 
&=\sum_{k=0}^{p-1}\frac{(-1)^{p+k}}{1-x+k}\binom{2p-1}{p+k} 
\\
&=\sum_{k=0}^{p-1}\frac{(-1)^{p+k}}{1-x+k}\binom{2p-1}{p-1-k}
&& \text{using } \binom{2p-1}{p+k} = \binom{2p-1}{p-1-k} 
\\
&=\sum_{s=0}^{p-1}\frac{(-1)^{s}}{x-p+s}\binom{2p-1}{s}
&& \text{using a change of index } s=p-1-k 
\end{align*} So finally \begin{align*} 
H(1-x) + H(x) 
&=\sum_{s=0}^{2p-1}\frac{(-1)^{s}}{x-p+s}\binom{2p-1}{s}
\end{align*} EDIT2: I have just made the same work on $G(x)$ as follows \begin{align*} 
G(x) 
&=\prod_{j=1-p}^{p} (x-j) \\
&=\prod_{s=0}^{2p-1} (x-p+s)
&& \text{using a change of index } s=p-i 
\end{align*} Now I think the constant $(2p-1)!$ in the relation $F(1-x)+F(x)=(2p-1)!$ comes from the binomial factor in $H(1-x) + H(x)$ but I don't see how to prove that... Any lead ?","['products', 'calculus', 'functions', 'sequences-and-series']"
4035495,"Is it correct to have understanding of logic with the use of set theory, to make learning it easier?","My teacher taught us mathematical logic by relating it to set theory (not entirely).
He asked us to relate the propositional variable p to a set P, and similarly q to a set Q.
The intuitive relations were- $$
p ∧ q\equiv P \cap Q ,
p ∨ q\equiv P \cup Q,
p\rightarrow q\equiv \overline{P}∪Q
$$ He says that we can relate the value of a propositional variable to a set like- If p has a truth value of False then take it as an empty set and if it has a truth value of True then take it as the universal set S or U. This literally helps in simplifying long mathematical statements easily by converting them to sets and then to converting them again to propositional variables. ( rather than writing long and hard truth tables) Is this an easy way to learn logic or is it because it just simplifies thing fast? I want to know if this approach for simplifying things out is sound, or will i run into some roadblocks later. Any suggestions and comments are welcome if they make this intuitive understanding more concrete. Just a heads-up I'm just a high-school student.","['elementary-set-theory', 'logic']"
