question_id,title,body,tags
100820,Multiplying Infinite Cardinals (by Zero Specifically),"On the Wikipedia page on Cardinal Numbers, Cardinal Arithmetic including multiplication is defined. For finite cardinals there is multiplication by zero, but for infinite cardinals only defines multiplication for nonzero cardinals. Is multiplication of an infinite cardinal by zero undefined? If so, why is it? Also does $\kappa\cdot\mu= \max\{\kappa,\mu\}$ simply means that the multiplication of the two is simply the cardinality of the higher cardinal? Why is this?","['cardinals', 'elementary-set-theory']"
100848,Is $f$ non-decreasing a.e. if its primitive is convex?,"The subsequent statement can be regarded as a follow-up to If $\int_0^x f \ dm$ is zero everywhere then $f$ is zero almost everywhere Is $f$ non-negative a.e. if its primitive is non-decreasing? Let $f:[a,b]\to\mathbb{R}$ be Lebesgue integrable.
  Furthemore, let
  $$
g:[a,b]\ni x\mapsto\int_a^x f(t)\,\mathrm{d}t\in\mathbb{R}
$$
  be convex. Then $f$ is non-decreasing almost everywhere. Let $a\le x_0<x_1<x_2\le b$. Since $f$ is convex, we have
$$
\frac{g(x_2)-g(x_1)}{x_2-x_1}-\frac{g(x_1)-g(x_0)}{x_1-x_0}\ge 0\text{.}
$$
This can be reduced to
$$
\int_{x_1}^{x_2} \frac{f(t)}{x_2-x_1}\,\mathrm{d}t
\ge\int_{x_0}^{x_1} \frac{f(t)}{x_1-x_0}\,\mathrm{d}t\text{.}
$$
The last formula roughly shows that the 'average' $f$ on $[x_0,x_1]$ does not exceed the 'average' of $f$ on $[x_1,x_2]$. Do you know a rigorous argument showing that $f$ is non-decreasing a.e.?","['measure-theory', 'integration', 'real-analysis']"
100860,Finitely-generated $k$-algebras and their relationship with affine coordinate rings,"Let $k$ be an algebraically closed field, $A = k[x_1, ... , x_n]$ . For $Y \subseteq \mathbb A^n$ , define $I(Y) = \{f \in A| f(P) = 0 \ \forall P \in Y\}$ Hartshorne's Algebraic Geometry, p. 4-5 , says the following: If $Y \subseteq \mathbb A^n$ is an affine algebraic set, we define the affine coordinate ring $A(Y)$ of $Y$ to be $A/I(Y)$ ... ... $A(Y)$ is a finitely generated $k$ -algebra. Conversely, any finitely generated $k$ -algebra $B$ which is a domain is the affine coordinate ring of some affine variety. Indeed, write $B$ as the quotient of a polynomial ring $A = k[x_1, ... , x_n]$ by an ideal $\mathfrak{a}$ , and let $Y = Z(\mathfrak{a})$ . As might be obvious from my recent posts, I'm trying to learn Algebraic Geometry with (currently) less-than-desired knowledge of commutative algebra. I'm picking up the relevant bits as I go (as much as I feel I need to). I have a few questions about the above passage: I've just learned the definition of a $k$ -algebra. Am I safe to think of a $k$ -algebra as a ring $R$ which is also a $k$ -module? If I knew that $A$ was a finitely generated $k$ -algebra, say $A = \sum_{i=1}^d A f_i$ , then I think $A(Y)$ would be generated by $f_1 + I(Y), .... , f_d + I(Y)$ . But why/is $A$ finitely generated? Some googling has shown me that if $A$ is a Noetherian module then it is finitely generated (as a $k$ -module). Is this equivalent to being finitely generated as a $k$ -algebra? If so, how would I show that it's a Noetherian module? Why can any finitely-generated $k$ -algebra which is a domain be expressed as the quotient of a polynomial ring and an ideal? Thank you.","['commutative-algebra', 'algebraic-geometry']"
100863,Probability and combinatorics on tetahedron faces.,"Let it be a tetrahedron with the numbers $1$,$2$,$3$ and $4$ on its faces.The tetrahedron is launch $3$ times. Each time, the number that stays face down is registered. $1$)In total how many possible ways there are to registered the $3$ launches? As there are $4$ numbers to $3$ launches(positions), the order matters and each number can repeats itself. I used a permutation with replacement: $4^3=64$ $2$)How many possible ways there are to the number $1$ never face down? In this case I reduced the sample set to $\{2,3,4 \}$, and made the same as before. But this time there are $3$ numbers to $3$ launchs: $3^3=27$ $3$)How many possible ways there are to the number $1$ appears only $1$ time face down? There are $3$ ways for number $1$ can be put on the $3$ launches. For the $2$ left there is $\{2,3,4 \}$.So I made a permutation with replacement: $3 \cdot 3^2=27$ $4$)How many possible ways there are to the number $1$ appears exactly $2$ times face down? First I made a combination: $C(3,2)$ to find the number of ways that the pair of $1$'s can be put in the $3$ launchs.Then I multiplied by $3$, that is $ \{2,3,4 \}$ : $C(3,2) \cdot 3=9$. Is this correct?
Thank you very much, you(plural)have been very helpful.","['probability', 'combinatorics']"
100871,Equality with Euler–Mascheroni constant,"While trying to prove $\int_0^{\infty } \frac{\log (x)}{e^x+1} \, dx = -\frac{1}{2} \log ^2(2)$ How to show? in an alternative way, I came to this solution: $$\sum_{k=0}^{+\infty}(-1)^{k+1}\frac{\log (k+1)+\gamma }{(k+1)}.$$ As both solutions have to be the same, the following equality should be valid: $$\sum_{k=0}^{+\infty}(-1)^{k+1}\frac{\log (k+1)+\gamma }{(k+1)}=- \frac{1}{2}{{\log }^2(2)}. $$ Can anyone give me some advice on how to prove this equality. p.s. You can be sure that the equality is correct, as I checked it numerically.","['euler-mascheroni-constant', 'power-series', 'calculus']"
100872,"If two Gaussian random variables are uncorrelated, they are statistically independent","I read in a textbook that when two gaussian variables are uncorrelated, then they are statistically independent? How can I prove that?","['statistics', 'correlation', 'probability-distributions']"
100876,Density of black cells in rule 110,"Is there a way to compute the limit of the ratio (number of black cells)/(number of white cells), in the rule 110 or rule 30 automaton? With initial state = 1 black cell. Simulation of first 120000 rows shows a quite stable total density of 0.592..., and row-density 0.592... Here is average density of some consecutive columns of height some thousands:
How to explain the apparent periodicity?
These are quite clearly converging, how to calculate the exact values? (0.62499..==5/8 ??) 0.6249983636387438, 0.5937438636452892, 0.5312544999934545, 0.5937569545353388, 0.624991818193719, 0.6249983636387438, 0.5937569545353388, 0.5312414091034049, 0.5937438636452892, 0.6250049090837686, 0.6249983636387438, 0.5937504090903141, 0.5312479545484298, 0.5937373182002644, 0.624991818193719, 0.6250049090837686, 0.5937569545353388, 0.5312479545484298, 0.5937438636452892, 0.6250049090837686, 0.6250114545287934, 0.5937504090903141, 0.5312479545484298, 0.5937504090903141, 0.6249983636387438, 0.6250114545287934, 0.5937504090903141, 0.5312414091034049, 0.5937634999803637, 0.6250114545287934, 0.6249983636387438, 0.5937438636452892","['recreational-mathematics', 'automata', 'algorithms', 'combinatorics']"
100883,Has the notion of having a complex amount of dimensions ever been described? And what about negative dimensionality?,"The notion of having a number $a \in \mathbb{R}_{\geq 0} $ associated to any metric space is described by the definition of a "" Hausdorff Dimension "". I was wondering if work has been done on spaces which (seem to) have a complex amount dimensions associated with it? Does this concept exist? If so, when is it useful, if at all? Inspired by the comments, I am also interested as to whether the concept of negative dimensionality has been explored already. Thanks in advance.","['dimension-theory-analysis', 'measure-theory', 'geometric-measure-theory']"
100884,Local diffeomorphism from $\mathbb R^2$ onto $S^2$,Is there any local diffeomorphism from $\mathbb R^2$ onto $S^2$?,['differential-geometry']
100900,Diagonalization of Riemannian Metric and the Laplace Beltrami Operator,"Consider the local representation of the Laplace Beltrami operator on a Riemannian n - dimensional manifold $(M,g)$:
\begin{equation}
\triangle_g = \frac{1}{\sqrt{\text{det}(g)}} \sum^n_{i,j = 1} \frac{\partial}{\partial x^i} g^{ij} \sqrt{\text{det}(g)}\frac{\partial}{\partial x^j} 
\end{equation} Some time ago I read in some textbook that one can, locally at any point $p \in M$, choose a small enough neigborhood $U \subset M$ so that by a linear transformation of the coordinates the matrix representation of $g$ in $U$ is $g_{ij} = \delta_{ij}$. But wouldn't this imply that the above expression always simplifies to the expression
\begin{equation}
 \triangle_g = \sum^n_{i = 1} \frac{\partial^2}{\partial (x^i)^2} \quad ?
\end{equation} Alternatively I would think that even though the metric evaluates to the Kronecker delta that doesn't mean that its derivatives are zero. So do we actually then have \begin{equation}
\triangle_g =  \sum^n_{j = 1} \frac{\partial^2}{\partial (x^j)^2} + \sum_{j = 1}^n ( \frac{\partial}{\partial x^j} \sqrt{\text{det}(g)} + \sum_{i = 1}^n \frac{\partial}{\partial x^i} g^{ij})\frac{\partial}{\partial x^j} 
\end{equation} I am sure at least one my impression is false, if anybody could help pointing out what I got wrong, or refer to a reference where I could read about diagonalization of metrics that would be so helpful, many thanks !",['differential-geometry']
100906,Hartshorne Exercise 1.1 (a),"(see bottom for apology) Let $Y$ be the plane curve $y = x^2$ (i.e., $Y$ is the zero set of the polynomial $f = y - x^2$). Show that $A(Y)$ is isomorphic to a polynomial ring in one variable over $K$. In case the notation is non-standard, let $A = k[x_1, ... , x_n]$. Then $A(Y) = A / I(Y)$ is the affine coordinate ring of an algebraic subset $Y \subseteq \mathbb A^n$, where $I(Y) = \{ f \in A | f(P) = 0 \ \forall P \in Y\}$. My initial thoughts : I can use the information in the question to help me; I know in advance that $A(Y)$ is going to be generated by one of its elements (as a $k$-algebra). I'd like to see what the elements of $A(Y)$ look like, as this will help me to find a generator. My attempt : I'm quotienting out by $I(Y) = I(Z(\mathfrak{a})) = \sqrt{\mathfrak{a}}$ (Hilbert's Nullstellensatz), where $\mathfrak{a}$ is the ideal generated by $f$. It'd be nice if $\mathfrak{a}$ was a radical ideal. Suppose $g \in \sqrt{\mathfrak{a}}$. Then $g^r \in \mathfrak{a}$ for some positive integer $r$, i.e. $g(x,y)^r = h(x,y)(y-x^2)$
 for some $h(x,y) \in A$. Since $(y-x^2)$ is irreducible in $A$ and it divides $g(x,y)^r$, it must divide $g(x,y)$, and so $g(x,y) \in \mathfrak{a}$. So I have that $I(Y) = \mathfrak{a}$. [if this method is correct, it can be generalised to show that an ideal of $A$ generated by an irreducible is radical] So elements of $A(Y)$ are of the form $p(x,y) + \langle y-x^2 \rangle$. Notice that $(x + \langle y-x^2\rangle)^2 = x^2 + \langle y-x^2 \rangle = x^2 + y - x^2 + \langle y - x^2 \rangle = y + \langle y - x^2 \rangle$. Thus $x + \langle y - x^2 \rangle$ is a generator of $A(Y)$. Let $\phi : A(Y) \to k[z]$ be the $k$-linear map specified by sending $x + \langle y - x^2 \rangle $ to $z$. This is an isomorphism of $k$-algebras. I promise I won't ask about every exercise in this book; I just want to make sure I'm approaching the topic in the right way. Obviously what appears above isn't how I'd structure a proper solution - I included my thought processes where possible in the hope that someone might tell me I'm thinking about this in the right/wrong way. Thanks a lot.","['commutative-algebra', 'algebraic-geometry']"
100918,A characterization of finite purely inseparable extensions of fields,"Let $K/k$ be a finite extension of fields. Let $A=K \otimes_k K$. An exercise:
Show that $K/k$ is purely inseparable $\Leftrightarrow A/J(A) \cong k$, where $J(A)$ is the Jacobson radical of $A$. It doesn't seem right to me. I can show that $A/J(A)$ is a product of copies of fields, each containing $K$. So that must mean that $A/J(A) \cong k$ implies $k=K$, making the $\Leftarrow$ direction trivial and $\Rightarrow$ direction wrong. Am I correct? Maybe $A/J(A) \cong K$ instead of $A/A(J) \cong k$ would make it correct?","['tensor-products', 'abstract-algebra', 'field-theory']"
100933,How to prove that the converse of Lagrange's theorem is not true?,"I consider the Lagrange theorem.
Let $G$ be a finite group and let $H \subseteq G$ be a subgroup, then the order of $H$  divides the order of $G$.
I am interesting with the proof of this theorem. The proof is as follows Let $C= \{a_1 H, a_2 H,\ldots,a_t H\}$ be a collection of all distinct left cosets of $H$ in $G$, where $t$ is a positive integer.
Since $C$ is a partition of $G$ ,we have
$|G|=|a_1 H|+|a_2 H|+\ldots+|a_t H|=|H|+|H|+….+|H|=t|H|$, hence the theorem is proved! Now  how can I prove that the converse of this theorem is not true? Is the converse not true generally ? Here is the way I try, from $|G|=|a_1 H|+|a_2 H|+\ldots+|a_t H| = |H|+|H|+\ldots+|H|=t |H|$. If I try to write $|H|/|G|=1/t$, I see that $1/t$ is not an integer, so that the converse of Lagrange theorem is not true. Does this satisfy for the proof “converse of Lagrange's theorem is not true”? Please I beg your more help for this case, thanks","['group-theory', 'abstract-algebra']"
100945,Limit of a function satisfying an inequality,"If $f(x)+f(y)\leq f(x+y)$ and $f:\mathbb{R}\to\mathbb{R}$, then can we find $\lim_{x\to 0} \frac {f(x)}{x}$? I am not sure whether the question is correct.Thank you.(I tried this idea: $f(x)=f(x+y-y)\ge f(x+y)+f(-y)\ge f(x)+f(y)+f(-y)\implies f(y)\leq -f(-y)$ but after that I seem to be hitting a roadblock. Thank you in advance.","['inequality', 'calculus', 'functional-inequalities', 'functional-equations', 'limits']"
100948,Prove that there only two groups of order 4 up to isomorphism,"Can the following statement be proved? There are only two different groups of order $4$ up to isomorphism. I have seen somewhere that there are only two groups up to isomorphism of order $4$ -cyclic of order $4$ and the Klein- $4$ group. All other groups with $4$ elements are isomorphic to one of these. Really I don't have any idea on attempting this problem, so I please need your help. Thanks all!","['group-isomorphism', 'finite-groups', 'group-theory', 'abstract-algebra']"
100954,Issue with Proof by Contradiction,"So we were asked to solve a question in class about proof by contradiction... Q) Suppose integers $1,2,3,\dots,10$ are placed randomly in a circular wheel. Show that the sum of any three consecutive integers is at least $15$. Logical Answer: NO, because $1+2+3 = 6 < 15$. Textbook Answer: PROVED. How?.... Let $A_r$ be the number positioned in the wheel at $r$-th position.
Equation Set 1: $$\begin{align*}
&A_1+A_2+A_3 \ge 15\\
&A_2+A_3+A_4 \ge 15\\
&A_3+A_4+A_5 \ge 15\\
&\qquad\qquad\qquad\vdots\\
&A_{10}+A_1+A_2 \ge 15
\end{align*}$$ So, continuing proof by contradiction, lets assume Equation Set 1 is NOT true. Which implies-- Equation Set 2- $$\begin{align*}
&A_1+A_2+A_3 < 15\\
&A_2+A_3+A_4 < 15\\
&A_3+A_4+A_5 < 15\\
&\qquad\qquad\qquad\vdots\\
&A_{10}+A_1+A_2 < 15
\end{align*}$$ Now, adding all equations in Equation Set 2 we get $$3(A_1+\cdots+A_{10}) < 15\cdot10$$ $$\frac{3n(n+1)}2 < 150\;,$$ where $n=10$ (cuz sum of $n$ integers is $n(n+1)/2$) $$3\cdot55 < 150$$ $$165 < 150$$ Which is FALSE and is a contradiction to what we assumed (Equation set 2).
Therefore our assumption is wrong and Equation Set 1 holds TRUE. Which means sum of $3$ nos should be at least $15$. BUT logically thinking, a simple example of $1+2+3$ does not satisfy. What is the problem? Please Help!",['discrete-mathematics']
100955,Finding general harmonic polynomial of form $ax^3+bx^2y+cxy^2+dy^3$.,"I'm trying to find the most general harmonic polynomial of form $ax^3+bx^2y+cxy^2+dy^3$. I write this polynomial as $u(x,y)$. I calculate
$$
\frac{\partial^2 u}{\partial x^2}=6ax+2by,\qquad \frac{\partial^2 u}{\partial y^2}=2cx+6dy
$$
and conclude $3a+c=0=b+3d$. Does this just mean the most general harmonic polynomial has form $ax^3-3dx^2y-3axy^2+dy^3$ with the above condition on the coefficients? ""Most general"" is what my book states, and I'm not quite sure what it means. Also, I want to find the conjugate harmonic function, say $v$. I set $\frac{\partial v}{\partial y}=\frac{\partial u}{\partial x}$ and $\frac{\partial v}{\partial x}=-\frac{\partial u}{\partial y}$ and find
$$
v=dx^3+3ax^2y+bxy^2-ay^3+K
$$
for some constant $K$. By integrating $\frac{\partial v}{\partial x}$, finding $v$ as some polynomial in $x$ and $y$ plus some function in $y$, and then differentiating with respect to $y$ to determine that function in $y$ up to a constant. Is this the right approach? Finally, the question asks for the corresponding analytic function. Is that just $u(x,y)+iv(x,y)$? Or something else? Thanks for taking the time to read this.","['functions', 'complex-analysis']"
100956,Is the number of index d subgroups in the free group of rank 2 bounded by a polynomial?,"For $d=1$, let $M_1 = 1$. For $d>1$, define $M_d$ recursively by $$M_d = d(d!) - \sum_{i=1}^{d-1} (d-i)! M_i.$$ Is $M_d$ bounded by a polynomial (of some high degree) in $d$? Note that $M_d$ is the number of subgroups of index $d$ in the free group of rank $2$.","['group-theory', 'abstract-algebra']"
100978,How many connected components does $\mathrm{GL}_n(\mathbb R)$ have?,"I've noticed that $\mathrm{GL}_n(\mathbb R)$ is not a connected space, because if it were $\det(\mathrm{GL}_n(\mathbb R))$ (where $\det$ is the function ascribing to each $n\times n$ matrix its determinant) would be a connected space too, since $\det$ is a continuous function. But $\det(\mathrm{GL}_n(\mathbb R))=\mathbb R\setminus\{0\},$ so not connected. I started thinking if I could prove that $\det^{-1}((-\infty,0))$ and $\det^{-1}((0,\infty))$ are connected. But I don't know how to prove that. I'm reading my notes from the topology course I took last year and I see nothing about proving connectedness...","['general-topology', 'matrices', 'lie-groups']"
100981,On the Use of the Topology on Tangent Bundles,"On learning about how to define smooth vector fields on a manifold $M$, I learned that one should first define a tangent bundle , $T(M)$,  as $\cup T_p(M)$ together with a topology(smooth structure). And then, a smooth vector field $X$ would be a smooth map from $M \rightarrow T(M)$ s.t. $\pi \circ X=id_M$ However, it is obvious that the use of the auxilary manifold $T(M)$ should not be confined to merely offering a good def. of ""smooth"" vector fields. Well, at least you would not be using the global topology of $T(M)$. (Since the checking of ""smoothness"" is done locally) I am inclined to believe that the global topology of $T(M)$ may play a more important role in determining the properties of vectorfields on $M$. So here are my two questions: Can you give an example where the global topology of $T(M)$ is used to control certain properties(possibly about vec. fields) on $M$? If the global topology on $T(M)$ is indeed important, how do we set about determining it?  I have only seen trivial examples where for $M=S^1 or \mathbb{R}^n$, $T(M)=M\times \mathbb{R}^n$. But surely, there are examples where $T(M)\neq M\times \mathbb{R}^n$. And how do we determine the topology in that case?","['differential-topology', 'manifolds', 'differential-geometry']"
100986,What is the limit of the quotient of Stieltjes Constants? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What is the limit : $\displaystyle\lim_{n\to \infty }\frac{\gamma_{n-1} }{\gamma_{n}} $ Here $\gamma_{n} $ is the $n$-th Stieltjes Constant .","['functions', 'limits']"
100991,Existence of total derivative of a function,"Given the function  $ f(x,y) = \sqrt[3]{y}\cdot \arctan(x)$ discuss the existence and continuity of it's partial derivatives and existence of it's total derivative. Since the partial derivative $ \frac{\partial f}{\partial y} = \frac{\arctan(x)}{3\sqrt[3]{y^2}}$ has discontinuity at $y=0$, I tried to compute the partial  derivative at $(x,0)$ using the limit, which gives: $$ \lim_{t\to0} \frac{f(x,t) - f(x,0)}{t} = \lim_{t\to 0} \frac{\sqrt[3]{t}}{t}\arctan(x) = +\infty.$$ Does this mean that the partial derivative doesn't exist at $(x,0)$? So there's no total derivative at $(x,0)$ and it can be said that the function is not differentiable at $\mathbb{R}^2$ ?","['multivariable-calculus', 'derivatives']"
100998,Partial derivative confusion.,"I don't understand partial derivatives. Here's an example that nails down my confusion: Suppose we have some variables $x$, $p$, and $q$ with $p=x^2$ and $q=e^x$. Then $$\frac{\partial q}{\partial p} = \frac{\partial}{\partial p}e^{\left(p^{1/2}\right)}=\frac{e^{\left(p^{1/2}\right)}}{2p^{1/2}}$$ So far so good. Now suppose we have variables $p$, $q$ and $a$ with $a=pq$. Then $$\frac{\partial q}{\partial p}=\frac{\partial}{\partial p}\frac{a}{p}=-\frac{a}{p^2}$$(where $a$ is being held constant) What happens when we have both of these at once? i.e. $p=x^2$, $q=e^x$ and $a=pq$. What's $\frac{\partial q}{\partial p}$? Does it depend on what we hold constant? Does holding $x$ constant even make sense?","['multivariable-calculus', 'derivatives']"
101000,"Is there a one-one onto continuous function $f:[0,1]\rightarrow[0,1]^2$?","Is there a one-one onto continuous function $f:[0,1]\rightarrow[0,1]^2$? I was trying to prove that there is no such function, but failed. Any suggestions?","['functions', 'real-analysis']"
101001,On the set of integer solutions of $x^2+y^2-z^2=-1$.,"Let 
$$
\mathcal R=\{x=(x_1,x_2,x_3)\in\mathbb Z^3:x_1^2+x_2^2-x_3^2=-1\}.
$$
The group $\Gamma= M_3(\mathbb Z)\cap O(2,1)$ acts on $\mathcal R$ by left multiplication. 
It's known that there is only one $\Gamma$-orbits in $\mathcal R$, i.e. $\Gamma \cdot e_3=\mathcal R$ where $e_3=(0,0,1)$. Could anybody give me a proof of this fact? Thanks.-. [ Comments: (i) $O(2,1)$ is the subgroup in $GL_3(\mathbb R)$ which preserves the form $x_1^2+x_2^2-x_3^2$, that is
$$
O(2,1)=\{g\in GL_3(\mathbb R): g^t I_{2,1} g=I_{2,1}\}\qquad\textrm{where}\quad
I_{2,1}=
\begin{pmatrix}1&&\\&1&\\&&-1\end{pmatrix}.
$$ (ii) $g(\mathcal R)\subset \mathcal R$ for any $g\in \Gamma$ because $g$ has integer coefficients and we can write
$$
x_1^2+x_2^2-x_3^2=x^tI_{2,1}x,
$$
then
$$
(gx)^t I_{2,1} (gx)= x^t (g^tI_{2,1}g)x=x^tI_{2,1}x=-1.
$$]","['quadratic-forms', 'number-theory']"
101004,The Axiom of Choice and the Cartesian Product.,"I understand that the axiom of choice, given the axioms of ZF set theory, is equivalent to the statement that ""the Cartesian product of any family of nonempty sets is nonempty."" I've been unable to find this proof. Could someone sketch it for me? Or provide me with a source at least?","['elementary-set-theory', 'axiom-of-choice']"
101023,Convex Conjugate of Absolute Norm,"Let $f:\mathbb{R}\rightarrow[-\infty,\infty]$ be a continuous function.
The convex conjugate of $f$ is: $$f^*(p) := \sup_{x\in\mathbb{R}}\{px-f(x)\}~.$$ Furthermore, let us define the subderivative $\partial f(a)$ of $f$ at $a$: $$\partial f(a) :=  \{y\in[-\infty,\infty]: f(x)-f(a)\ge y(x-a)\}~.$$ I found out that for $f(x)=|x|$: $$ f^*(p) = 
\begin{cases}
0 & \text{for } |p|\le 1\\
\infty &\text{else}.\end{cases}
 $$ How can we show that?","['convex-analysis', 'convex-optimization', 'analysis']"
101025,example for non-abelian group,"We defined a group as a set $G$ with an operation $\circ$ with 1) $\forall x,y,z, \in G: x \circ ( y \circ z) = (x \circ y) \circ z$ 2) $\exists e\in G: \forall x\in G : x \circ e = e \circ x = x$ 3) $\forall x \in G\;\;\;\exists x^{-1} \in G: x \circ x^{-1} = x^{-1} \circ x = e$ Now I'm wondering what group fullfilling these axioms isn't abelian, because in 2) and 3) there's already some kind of commutativity.","['group-theory', 'abelian-groups']"
101038,What does this notion of scheme morphism mean?,"I apologize for the naivety of this question but I am a beginner in algebraic geometry. Moreover, I realized that the initial question (quoted at the end) was not formulated very clearly. Hopefully, I can do better now involving the things learned from  Zhen Lin's comments. One sometimes sees morphism of affine or projective schemes over a base field defined by some kind of coordinate notation, e.g. \begin{equation}
f:\mathbb{A^2}\to \mathbb{A^3}, (a,b)\mapsto (a^2+b,b^2-2,4)\hspace{20pt} (*)
\end{equation} but formally a morphism of schemes is a priori a pair consisting of a map $f:\mathbb{A^2}\to \mathbb{A^3}$ of topological spaces and a morphism $f^\sharp:\mathcal{O_{\mathbb{A^3}}}\to f_*\mathcal{O_{\mathbb{A^2}}}$ of structure sheaves. As Zhen Lin explains in the comments, the map of topological spaces $f$ is determined by what is does on the maximal ideals of $\mathbb{A}^2$ . If the base field is algebraically closed, these maximal ideals are of the form $(x_1-a,x_2-b)$ by the Hilbert nullstellensatz. Hence, in this case it suffices to specify an image for the pairs $(a,b)$ to get the topological morphism. I have (still) two problems with this notion. Firstly , why exactly does such an assignment $(a,b)\mapsto (f_1(a,b),f_2(a,b),f_3(a,b))$ lead to a morphism of schemes and not only of topological spaces? I guess, the thing is that the $f_i$ are given by polynomials and not by arbitrary functions $k^2\to k$ . Let me please look at a concrete example to see how this works. Consider $f:Spec~k[x]\to Spec~k[y]$ and the assignment $a\mapsto a^2-1$ . To construct a map of the structure sheaves, I have to build a $k$ -algebra map $\tilde f:k[y]\to k[x]$ such that the pre-image of the ideal $(x-a)$ is the ideal $(y-(a^2-1))$ . Is it correct to set $y\mapsto a^2-a-1$ and is it obvious that one finds such a $k$ -algebra morphism for the ''higher dimensional'' analogues like $\bar f:k[y_1,y_2,y_3]\to k[x_1,x_2]$ ? Secondly , when the base field is not algebraically closed, why does it suffice to specify an image only for the pairs $(a,b)$ , too? Maybe, this is because for the special case of the ring $k[x_1,x_2]$ , the maximal ideals are still precisely $(x_1-a,x_2-b)$ , is this true? This was the initial question to which  Zhen Lin's comments refer to. What is the very formal legitimation of defining a morphism $f:X\to Y$ of affine or projective schemes by a kind of coordinate notion (explained below)
instead of applying the spectrum functor to a ring morphism (in the
other direction) or instead of working with the prime ideals?",['algebraic-geometry']
101045,What can we learn about a group by studying its monoid of subsets?,"If $G$ is a group, then $M(G)=2^G$ is has a monoid structure when we define $AB$ to be $\{ab|a\in A,b\in B\}$ and $1_{M(G)}=\{1\}$. How much of the structure of $G$ can be recovered by studying the structure of $M(G)?$ Is there any known example of a sensibly large class $\mathscr{C}$ of groups, for which the following implication holds? For any $G,H\in \mathscr C,$ if $M(G)\cong M(H),$ then $G\cong H.$ Could you please give me any references concerning the monoid of subsets of a group? Edit: I'll write here what I came up with after I asked the quesiton. Please comment on it as well. I've found a funny structure that I think is isomorphic to $M(G).$ Let $B=(\{0,1\},∨,∧).$ It's a semiring in which infinite sums (and products, actually) are well-defined. If I'm not mistaken, we can define the ""group semiring"" $B[G]_\infty$ just like we define group rings, but without the restriction of finite supports. It looks like the multiplicative structure of $B[G]_\infty$ is isomorphic to $M(G).$ The additive structure of $B[G]_\infty$ seems to be isomorphic to $(M(G),\cup).$ If we do keep the restriction of finite supports and define $B[G]$ as we would a group ring, I believe it's equivalent to changing $2^G$ to the family of all finite subsets of $G$ in the definition of $M(G).$ I haven't written the proofs of these things down, but I will if anyone thinks it's a good idea. Edit: I don't know how close I am, but for what it's worth. OK, so $M(G)$ has a structure of an additively idempotent semiring. Indeed, let's take $(M(G),\cup,\cdot,\emptyset,\{1\}).$ The additive structure is obviously that of a commutative idempotent monoid. The multiplicative structure is that of a monoid. The distributive laws hold because: $
\begin{eqnarray}
\left(\forall A,B,C\in M(G)\right) \;\;\; A(B\cup C) &=& \{ax\,|\,a\in A\wedge x\in B\cup C\}=\{ax\,|\, a\in A\wedge (x\in B\vee x\in C)\}\\ &=& \{ax \,|\,(a\in A\wedge x\in B)\vee (a\in A\wedge x\in C)\} \\ &=& \{ax\,|\,a\in A \wedge x\in B\}\cup\{ax\,|\,a\in A \wedge x\in C\}\\ &=& AB\cup AC,
\end{eqnarray}
$ and analogously $\left(\forall A,B,C\in M(G)\right) \;\;\; (B\cup C)A=BA\cup CA.$ Now, in this semiring there is the subset $G'=\left\{\{g\}\,|\,g\in G\right\}.$ The multiplicative structure of this subset is isomorphic to $G.$ Suppose we have the semiring $(M,+,\cdot,0,1)$ and we know that $M\cong M(G)$ for some group $G.$ (The isomorphism is between semirings, not monoids.) Then finding out the structure of $G$ is equivalent to recognizing $G'$ inside $M.$ But this is possible when we have the additive structure. $G'$ is the set of all elements $g$ such that the equation $g+x=g$ has exactly one solution, that is $0.$ This, if I'm not mistaken means that the semiring structure of $M(G)$ gives the structure of $G$ unanmbiguously. So perhaps, having the monoid $M(G),$ we could try proving that there is a unique additive operation that makes this monoid into an (additively idempotent) semiring? Edit: This is to announce that I have asked a follow-up question on MO. It is whether the class of inverse semigroups is globally determined (as defined in my answer below). Inverse semigroups can be seen as generalized groups and I'd like to know if they retain this particular property of groups.","['reference-request', 'soft-question', 'monoid', 'semigroups', 'group-theory']"
101049,"Compute: $\int_{0}^{1}\frac{x^4+1}{x^6+1}\, dx$","I'm trying to compute: $$\int_{0}^{1}\dfrac{x^4+1}{x^6+1}\,dx.$$ I tried to change $x^{4}$ into $t^{2}$ or $t$ , but it didn't work for me. Any suggestions? Thanks!","['definite-integrals', 'calculus', 'integration']"
101053,"Why is it that when proving trig identities, one must work both sides independently?","Suppose that you have to prove the trig identity: $$\frac{\sin\theta - \sin^3\theta}{\cos^2\theta}=\sin\theta$$ I have always been told that I should manipulate the left and right sides of the equation separately, until I have transformed them each into something identical. So I would do: $$\frac{\sin\theta - \sin^3\theta}{\cos^2\theta}$$
$$=\frac{\sin\theta(1 - \sin^2\theta)}{\cos^2\theta}$$
$$=\frac{\sin\theta(\cos^2\theta)}{\cos^2\theta}$$
$$=\sin\theta$$ And then, since the left side equals the right side, I have proved the identity. My problem is: why can't I manipulate the entire equation? In this situation it probably won't make things any easier, but for certain identities, I can see ways to ""prove"" the identity by manipulating the entire equation, but cannot prove it by keeping both sides isolated. I understand, of course, that I can't simply assume the identity is true. If I assume a false statement, and then derive from it a true statement, I still haven't proved the original statement. However , why can't I do this: $$\frac{\sin\theta - \sin^3\theta}{\cos^2\theta}\not=\sin\theta$$
$$\sin\theta - \sin^3\theta\not=(\sin\theta)(\cos^2\theta)$$
$$\sin\theta(1 - \sin^2\theta)\not=(\sin\theta)(\cos^2\theta)$$
$$(\sin\theta)(\cos^2\theta)\not=(\sin\theta)(\cos^2\theta)$$ Since the last statement is obviously false, is this not a proof by contradiction that the first statement is false, and thus the identity is true? Or, why can't I take the identity equation, manipulate it, arrive at $(\sin\theta)(\cos^2\theta)=(\sin\theta)(\cos^2\theta)$, and then work backwards to arrive at the trig identity. Now, I start with a statement which is obviously true, and derive another statement (the identity) which must also be true - isn't that correct? Another argument that I have heard for keeping the two sides isolated is that manipulating an equation allows you to do things that are not always valid in every case. But the same is true when manipulating just one side of the equation. In my first proof, the step $$\frac{\sin\theta(\cos^2\theta)}{\cos^2\theta}$$
$$=\sin\theta$$ is not valid when theta is $\pi/2$, for example, because then it constitutes division by zero.","['trigonometry', 'learning', 'proof-writing']"
101062,Is the product of two Gaussian random variables also a Gaussian?,"Say I have $X \sim \mathcal N(a, b)$ and $Y\sim \mathcal N(c, d)$.  Is $XY$ also normally distributed? Is the answer any different if we know that $X$ and $Y$ are independent?","['probability-theory', 'normal-distribution', 'probability', 'random-variables']"
101066,Number of permutations with a single fixed point,I know that the number of permutations with no fixed points over a set with $n$ elements approaches $\frac{n!}e$ as $n$ grows. I'm interested in finding a limit (if one exists) for the number of permutations with a single fixed point. Thank you.,"['derangements', 'permutations', 'discrete-mathematics', 'combinatorics']"
101074,Switching the order of integraton,"I'm trying to figure out how to switch the order of integration for this problem.  I'm given the region (I don't know how to use latex, maybe someone can clean this up for me?) $z$ from $0$ to $x+y$ $y$ from $0$ to $1-x$ $x$ from $0$ to $1$ That was for the integral $dz\;dy\;dx$ and I have to change it to $dy\;dx\;dz$.  I think maybe I drew out the region wrong and that's why I can't figure this out.  The one I drew looks like a right triangle.  In the first octant The $x$ axis from 0 to 1 and the hypotenuse of the triangle is the line $1-x$ then it goes out in $y$ from 0 to 1 (I can upload the picture if it helps).  I don't think I'm taking the $x+y$ part into account anywhere?  The new integral I came up with is $y$ from $0$ to $1$ $x$ from $0$ to $1-y$ $z$ from $0$ to $1$","['multivariable-calculus', 'calculus']"
101080,Is the projective closure of a smooth variety still smooth?,"Let $X$ be a closed subscheme of $\mathbb{A^n}$ (over a basefield) defined by an ideal $I$ and consider the immersion $\mathbb{A^n}\to \mathbb{P^n}$, $(x_1,\ldots, x_n)\mapsto [x_1,\ldots,x_n,1]$. One may consider the projective variety $\bar X$ in $\mathbb{P^n}$ given by the homogenized ideal $\bar I$. This ideal consists of the homogenized elements of $I$, so for example if $f=x_1^2+x_2+1$ is in $I$ then $\bar f=x_1^2+x_2x_{n+1}+x_{n+1}^2$ is in $\bar I$. Then $\bar X$ is the projective closure of the image of $X$ under $\mathbb{A^n}\to \mathbb{P^n}$, right? I wonder if smoothness is inherited. If $X$ is a smooth affine scheme over the base field, is $\bar X$ smooth, too?",['algebraic-geometry']
101086,$\lim_{n\to \infty}f(nx)=0$ implies $\lim_{x\to \infty}f(x)=0$ [duplicate],"This question already has an answer here : A classical problem about limit of continuous function at infinity and its connection with Baire Category Theorem (1 answer) Closed 8 years ago . Can anyone help me with this problem? Let $f:[0,\infty)\longrightarrow \mathbb R$ be a continuous function such that for each $x>0$, we have $\lim_{n\to \infty}f(nx)=0$. Then prove that $\lim_{x\to \infty}f(x)=0$. Our teacher told first to prove Baire's theorem, and then show that this is a consequence of that theorem. I proved Baire's theorem, and I spend a few hours thinking on how Baire's theorem is related to this problem, but I couldn't find anything. I'd really appreciate your help.","['baire-category', 'real-analysis', 'limits']"
101098,How to obtain the standard basis for $\mathbb{R}^2$ using differential geometry?,"I apologize in advance because I don't know how to enter code to format equations, and I apologize for how elementary this question is. I am trying to teach myself some differential geometry, and it is helpful to apply it to a simple case, but that is where I am running into a wall. Consider $M=\mathbb{R}^2$ as our manifold of interest. I believe that the tangent space is also $\mathbb{R}^2$. From linear algebra, we know that a basis set for $\mathbb{R}^2$ is $$\left\{\left[\matrix{1\\0}\right], \left[\matrix{0\\ 1}\right] \right\}\;.$$ Now, from differential geometry, we are told that basis vectors are $\frac{d}{dx}$ and $\frac{d}{dy}$ where the derivatives are partial deravatives. So my question is how does one obtain a two-component basis vector of linear algebra from a simple partial derivative? EDIT: Thanks to everyone for the replies. They have been very helpful, but thinking as a physicist, I would like to see how the methods of differential geometry could be used to derivive the standard basis of linear algebra. It seems that there must be more to it than saying that there is an isomorphism between the space of derivatives at a point and R^n which sets up a natural correspondence between the basis vectors. I may be completely off-the-wall wrong, but somehow I think that the answer involves partial derivatives of a local orthognal coordinate system at point p.",['differential-geometry']
101111,"Transition, marginal probability measures and probability measure on product space","Let $(\Omega_i, \mathcal{F}_i), i=1,2$ be measurable spaces. Their product measurable space is $(\Omega, \mathcal{F})$. Let $\mu_1$ be a probability measure on $(\Omega_1, \mathcal{F}_1)$, and let $(\mu_{ω_1})_{ω_1∈\Omega_1}$ be a transition probability from $\Omega_1$ to
$\Omega_2$. Then there exists a probability measure $\mu$ , deﬁned by
$$\mu(A)= \int_{\Omega_1} \mu_{ω_1}(A_{ω_1})\mu_1(dω_1), \quad \forall A \in \mathcal{F}$$
where $A_{ω_1}:= \{\omega_2 \in \Omega_2: (\omega_1, \omega_2) \in A\}$. My questions are: Conversely, given any probability measure $\mu$ on $(\Omega,
    \mathcal{F})$, do there exist a probability measure $\mu_1$ on
$(\Omega_1, \mathcal{F}_1)$, and  a transition probability
$(\mu_{ω_1})_{ω_1∈\Omega_1}$ from $\Omega_1$ to $\Omega_2$, such
that $$\mu(A)= \int_{\Omega_1} \mu_{ω_1}(A_{ω_1})\mu_1(dω_1), \quad
    \forall A \in \mathcal{F} ?$$ Can they be explicitly or implicitly determined? Are such probability measure $\mu_1$, and  transition probability
$(\mu_{ω_1})_{ω_1∈\Omega_1}$ unique? What if considering general measures instead of probability
measures? Are the answers yes only up to scaling of measures? Thanks and regards!","['probability-theory', 'measure-theory']"
101128,An inequality with radicals,"If $s_{1}\ge t_{1}\ge t_{2}\ge s_{2}\ge0$, does one always have $(s_{1}-t_{1}+s_{2}+t_{2})^{1/2}\ge\sqrt{s_{1}}-\sqrt{t_{1}}+\sqrt{t_{2}}-\sqrt{s_{2}}$?
Thanks a lot!","['inequality', 'calculus', 'algebra-precalculus', 'analysis']"
101132,How to turn this sum to a product?,"I arrived at this sum or trigonometric functions that I need to turn into a product in order to continue the exercise. How do I do that? $$\sin{x}\cos{(x+y)} -\cos{x}\sin{(x+y)}$$ I know of the identities of $\cos{(a \pm b)}$ and $\sin{(a \pm b)}$, but I can't figure the solution out.",['trigonometry']
101138,Complexity class of comparison of power towers,"Consider the following decision problem: given two lists of positive integers $a_1, a_2, \dots, a_n$ and $b_1, b_2, \dots, b_m$ the task is to decide if $a_1^{a_2^{\cdot^{\cdot^{\cdot^{a_n}}}}} < b_1^{b_2^{\cdot^{\cdot^{\cdot^{b_m}}}}}$. Is this problem in the class $P$ ? If yes, then what is the algorithm solving it in polynomial time? Otherwise, what is the fastest algorithm that can solve it? Update: I mean polynomial type with respect to the size of the input, i.e. total number of digits in all $a_i, b_i$. $p^{q^{r^s}}=p^{(q^{(r^s)})}$, not $((p^q)^r)^s$.","['number-theory', 'algorithms', 'computational-complexity', 'exponentiation', 'power-towers']"
101150,Structure sheaf of a fiber,"Let $\phi: Y\to X$ be an affine (finite & dominant) morphism of (smooth) $\Bbbk$-varieties. Let $Y_P$ be the scheme-theoretic fiber of $P\in X$, i.e. $Y_P=Y\times_X\mathrm{Spec}(\Bbbk(P))$. I was told that $Y_P=\mathrm{Spec}((\phi_\ast\mathcal{O}_Y)_P)$, but I do not see how to prove it. (I assume that the conditions in brackets can be omitted, but you may assume them if necessary) Clearly, we can do this locally and assume $Y=\mathrm{Spec}(B)$ as well as $X=\mathrm{Spec}(A)$. Now, I would have said that $Y_P=\mathrm{Spec}(B\otimes_A\Bbbk(P))$ but $(\phi_\ast\mathcal{O}_Y)_P=B\otimes_A A_P$, which is why I am confused.","['commutative-algebra', 'algebraic-geometry']"
101157,A commutative ring is a field iff the only ideals are $(0)$ and $(1)$,Let $R$ be a commutative ring with identity. Show that $R$ is a field if and only if the only ideals of $R$ are $R$ itself and the zero ideal $(0)$. I can't figure out where to start other that I need to prove some biconditional statement. Any help?,"['commutative-algebra', 'ring-theory', 'abstract-algebra']"
101174,Use Pearson's correlation coefficient on a matrix,"I have a problem to interpret the following formula which is said to be the Pearson's correlation coefficient: $$r = \frac{N \left(\sum XY\right) - \left(\sum X\right) \left(\sum Y\right)}{\sqrt{\left[N \left(\sum X^2\right) - \left(\sum X\right)^2\right] \left[N \left(\sum Y^2\right) - \left(\sum Y\right)^2\right]}}$$ It is from Mining a Web Citation Database for author co-citation analysis (p.7). I have problems with its interpretation, since the authors says $X$ and $Y$ are vectors with length $N + 1$ and the product of two column vectors is not defined, at least not normally, isn't it? I have found a similiar notation of this formular on this Wikipedia article . Here, the formula does not take vectors as arguments, but a series of $n$ measurements with $x_i$ and $y_i$, where $i = 1,2,\dots,n$. I have problems to combine both formulas and understand what my calculations should look like when applying it. Maybe an example would help: Let's take this two vectors: $$X = (0,0.5,0,0)$$ $$Y = (0.5,0,0,0)$$ with $N = 3$ which would be from this matrix: $$\begin{pmatrix}
0 & 0.5 & 0 & 0\\
0.5 & 0 & 0 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 0 & 0\\
\end{pmatrix}$$","['statistics', 'correlation', 'linear-algebra']"
101200,Sparseness of a Vector,The sparseness of a vector is defined a follows: $$\psi(\textbf{x}) = \frac{\sqrt{n}-\frac{\left(\sum_{i} x_i \right)}{\sqrt{\sum_{i} x_{i}^{2}}}}{\sqrt{n}-1}$$ So $\psi(\textbf{x}) =0 $ if $\sqrt{n} = \frac{\left(\sum_{i}x_i \right)}{\sqrt{\sum_{i} x_{i}^{2}}}$ or if $$\sqrt{n} \sqrt{\sum_{i} x_{i}^{2}} = \sum_{i} x_i$$ How does imply that all the $x_i$ are equal? Cauchy-Schwarz? Likewise $\psi(\textbf{x}) = 1$ iff $\textbf{x}$ contains a single non-zero element. How does this follow? We know that $$\sqrt{n}-\frac{\left(\sum_{i} x_i \right)}{\sqrt{\sum_{i} x_{i}^{2}}} = \sqrt{n}-1$$,['linear-algebra']
101208,How does one prove that the spectral norm is less than or equal to the Frobenius norm?,"How does one prove that the spectral norm is less than or equal to the Frobenius norm? The given definition for the spectral norm of $A$ is the square root of the largest eigenvalue of $A*A$. I don't know how to use that. Is there another definition I could use? We also have $\displaystyle{\max\frac{\|Ax\|_p}{\|x\|_p}}$, but if $p=2$ it's the Frobenius norm, right?","['matrices', 'normed-spaces', 'spectral-norm', 'matrix-norms']"
101217,Why are linear functions the natural analogue of exponential functions in a tropical semiring?,"I was reading a blog post on the Fourier transform and the Legendre transform as being the same thing over different semirings , in which the author says It's not obvious how to interpret the exponential function in
  (R',min,+) but it turns out that the natural choice is to consider the
  ordinary linear functions (in the conventional sense) to be the
  correct analogue. So why are ordinary linear functions a natural analogue for the exponential function in a tropical semiring? (Note: an intuitive answer is fine. I don't know any tropical geometry and only basic algebraic geometry, so not necessarily looking for a very technical response, though that would be awesome as well.","['algebraic-geometry', 'fourier-analysis', 'physics', 'tropical-geometry']"
101222,How to use Hardy and Wright's text and what corresponding exercises/problem books  can I do?,"I have just started out with Hardy and Wright's An Introduction to the Theory of Numbers today. I find the lack of exercises in the book as a departure from the style of the textbooks we are so accustomed to read. So, I was wondering if there is an optimal way to read the book or to extract the most of it (I am not reading for an exam, I reading that book for its sake). I believe the book contains more material than is covered in Olympiad mathematics. Coming from the Olympiad culture, it is but natural for me to request to be pointed to some source of rather tough problems based on GH Hardy's book. Your help is really appreciated.","['reference-request', 'soft-question', 'number-theory']"
101235,Interpreting the scalar curvature in a semi-Riemannian manifold,"Background: Let $M$ be a smooth Riemannian manifold of dimension $n$ and scalar curvature $R$ (with respect to the Levi-Civita connection).  Let $m \in M$ and let $B$ be the geodesic ball of radius $r$ centered at $m$ .  That is, $B = \{ Exp_m(v)\ |\ \ v\in T_mM,\ ||v||< r\ \} $ Then for small $r$ , the volume of $B$ is: \begin{equation}
Vol(B) = (constant)\ r^n\ \left[1 - \frac{R}{6(n+2)}r^2 + O(r^4)\ \right]
\end{equation} where the constant depends only on $n$ , and $R$ is evaluated at $m$ .  So $R$ basically tells us the difference between the volume of a small ball in $M$ and the volume of a small ball in Euclidean $\mathbb{R}^n$ (to leading order in the radius $r$ ). Questions: 1) Is there any generalization of this to the case of a semi-Riemannian manifold? 2) If not, is there an analogous result for the case of a Lorentzian manifold (that is, a semi-Riemannian manifold whose metric signature has $n-1$ pluses and one minus)? 3) If not, is there some other result that gives a nice way to interpret the scalar curvature $R$ in a semi-Riemannian (or Lorenztian) manifold? Comment: The problem I see is this: to define a geodesic ball, we want to start with a ball ""of radius $r$ "" in $T_mM$ .  But the metric is indefinite, so there is no norm.  I looked in Barrett O'Niell's book ""Semi-Riemannian Geometry"" but did not find the answer there. Thanks in advance for your help!","['general-relativity', 'riemannian-geometry', 'semi-riemannian-geometry', 'differential-geometry']"
101236,Question about substitution,"[ Note :] The error described here has been corrected in the meantime in response to this question. When checking wikipedia on substition they say that $\int f(g(t))g'(t) dt = \int f(x)dx$ with x = g(t). Which is true. However, when checking example 1 on the page ( http://en.wikipedia.org/wiki/Integration_by_substitution ) They say that when evaluating $\int x\cos(x^2 +1) dx$ in example one, they use the substition $u=x^2 + 1$ and say that they use the rule mentioned above from right to left, however this isn't the case right? Aren't they using that rule from left to right?",['calculus']
101242,Why is a linear equation with three variables a plane?,"In linear algebra, why is the graph of a three variable equation of the form $ax+by+cz+d=0$ a plane? With two variables, it is easy to convince oneself that the graph is a line (using similar triangles, for example). However with three variables, this same technique does not seem to work: setting one of the variables to be a constant yields a line in 3-D space (I think), and one could repeat this process for each constant value of that variable, but in the end there seems not to be an easy way to check that all these lines are coplanar. I don't remember seeing why this is in a book, and Khan Academy's video , for example, simply states that this is the case.",['linear-algebra']
101262,Projective varieties - basics,"I am taking an introductive course in (real) algebraic geometry and I got stuck at some basic exercises. They regard affine and (real) projective varieties, as follows: Prove that the punctured projective space, $\mathbb{P}^n - \{x\}$ is neither projective, nor quasi-affine, when $n \geq 2$. Prove that $\mathbb{P}^1 \times \mathbb{P}^1$ and $\mathbb{P}^2$ are birationally equivalent, but not isomorphic. Now, to clarify some things. We study more or less based on I. R. Shafarevich - Basic Algebraic Geometry (or something like that). Our definitions of the notions involved are: X is quasi-affine if it is a Zariski open set in an affine variety $\mathbb{P}^n$ is supposed to mean $\mathbb{P}^n(k)$, for an algebraically closed field $k$ and is the space of ""directions"" in $\mathbb{A}^{n+1}-\{0\}$. Specifically, $\mathbb{P}^n=\mathbb{A}^n/\sim$, where $x\sim y \Leftrightarrow \exists \lambda \in k, \ s.t. x=\lambda\cdot y$. birational equivalence means that there exist rational functions from either to the other, whose composite is the identity (either way), but that these need not be defined everywhere isomorphism is usually treated in terms of isomorphic fields under the isomorphism induced by the initial morphism. Note that the course is absolutely basic, without (co)homology, schemes, sheaves etc. Just the basics that I listed, along with Krull dimension. Thank you.",['algebraic-geometry']
101269,Continuity of $\delta$ in the definition of continuity,"When I was in the shower this morning a question went through my head about continuity of a function at a point. The simplest formulation of this question is: Let $f : \mathbb{R} \to \mathbb{R}$ be an unbounded continuous function with $f(0) = 0$. Define $\delta_f : (0, \infty) \to (0, \infty)$ by
  $$\delta_f(\varepsilon) = \sup \{ \delta > 0\, :\, |x|< \delta \Rightarrow |f(x)| < \varepsilon \}$$
  Under what conditions is $\delta_f$ a continuous function of $\varepsilon$? The answer to this probably involves monotonicity; for example, it seems that $\delta_f$ is continuous whenever $f$ is strictly monotone. I'd like to find (if possible) the weakest condition on $f$ to make $\delta_f$ continuous. My hunch is that the answer is that $\delta_f$ is continuous if and only if $|f| : \mathbb{R} \to [0,\infty)$ is strictly monotone, but I await counterexamples with open arms. More generally, the question can be formulated as follows: Let $f : V \to W$ be a continuous unbounded function between normed spaces with $f(0_V) = 0_W$. Define $\delta_f : (0, \infty) \to (0, \infty)$ by
  $$\delta_f(\varepsilon) = \sup \{ \delta > 0 \, :\, \lVert x \rVert < \delta \Rightarrow \lVert f(x) \rVert < \varepsilon \}$$
  Under what conditions is $\delta_f$ a continuous function of $\varepsilon$? My ultimate goal  is to prove that $\delta_f$ is continuous if and only if $\lVert f \rVert : V \to [0, \infty)$ is strictly monotone, or to find a counterexample.",['real-analysis']
101275,Roots of minimal and characteristic polynomials,"Why is it that for matrix $A \in M_n(\mathbb{C})$ the characteristic polynomial $\chi_A(t)$ and the minimal polynomial $\mu_A(t)$ have the same roots? Since $\chi_A(t) = \mu_A(t) \cdot p(t)$ it should be easy to follow, that $\chi_A(t)$ has roots where $\mu_A(t)$ has roots. But why can't $\chi_A(t)$ have roots where $\mu_A(t)$ hasn't?","['roots', 'characteristic-polynomial', 'polynomials', 'matrices', 'minimal-polynomials']"
101322,Equivalence of two definitions of ramification index,"Let $\phi:Y\to X$ be a morphism of $\Bbbk$-varieties. In Görtz and Wedhorn's Algebraic Geometry 1 , the ramification index is defined by $$e_Q(Y) := \mathrm{length}_{\mathcal{O}_{Y,Q}}\left(\mathcal{O}_{Y,Q}\right)$$ and then $e_{Q/P} := e_Q(Y_P)$ where $Y_P$ is the scheme-theoretic fiber of $P\in X$ under $\phi$, i.e. $Y_P=Y\times_X\mathrm{Spec}(\Bbbk(P))$. For points of codimension one and assuming that $X$ and $Y$ are smooth, I know a different definition: Namely, let $f$ be a uniformizing parameter at $P$, i.e. $\mathfrak{m}_P=(f)$ is the unique maximal ideal of $\mathcal{O}_{X,P}$. Let $v_Q:\Bbbk(Y)\to\mathbb{Z}$ be the valuation corresponding to $\mathcal{O}_{Y,Q}$. Then, $$e_{Q/P} = v_Q(\phi^\sharp_Q(f))$$ where $\phi^\sharp_Q: \mathcal{O}_{X,P} \to \mathcal{O}_{Y,Q}$ is the induced map. I would like to know why these two definitions coincide (in codimension one). I frankly don't even have an idea where to start.",['algebraic-geometry']
101346,Partial derivative of an implicit function,"I am trying to solve this question (sorry if the translation is a bit vague): $Z(x,y)$ is an implicit function of $x$ and $y$ given in the form of $$x^3z^2+\frac{2}{9}y^2\sin(z) = xyz$$ in the neighborhood of $x=2, y=\pi, z=\frac{\pi}{6}$. Find $Z_x$ and $Z_y$ at $(x,y) = (2,\pi)$ I know how to partially/totally differentiate, and I know how to find the derivative of a single-variable implicit function. How do I combine it to solve this?
I have the solution in front of me but I can't understand it. Thanks!","['multivariable-calculus', 'implicit-differentiation']"
101348,Show that every ideal of the ring $\mathbb Z$ is principal,Let $\mathbb Z$ be the ring of integers. The question asks to show  that every ideal of $\mathbb Z$ is principal. I beg someone to help me because it is a new concept to me.,"['principal-ideal-domains', 'ring-theory', 'ideals', 'abstract-algebra']"
101357,Is there a sufficient statistic for shifted exponential distribution?,"Suppose we have $X_1, \ldots, X_n$ i.i.d, $X_i \sim \text{Exp}(1, \mu)$ (pdf is $f_\mu(x) = e^{-(x-\mu)}$ for $x \geq \mu$ and $0$ for $x < \mu$ ). Is there any one dimensional (i.e. $T: \mathbb{R}^n \to \mathbb{R}$ ) sufficient statistic for parameter $\mu$ ? Obvious two dimensional sufficient statistic is $T(x_1, \ldots, x_n) = \left( \sum x_i, \min x_i \right)$ , but I have a hard time finding one dimensional statistic.","['statistics', 'probability']"
101367,probability 2 coins in last box,"We have initially $2n$ boxes and each of them contains initially 1 coin. In each round, we select randomly 2 boxes, if both of the two boxes contain the same number of coins, for example $x$, replace them by 1 box with $x+1$ coins, otherwise, remove the one with the most coins. After $2n-1$ rounds, only 1 box is left, the probability that the box has 2 coins is $p(2n)$ What is $\lim_{n \to \infty}p(2n)$ ? The answer is $\frac{\sqrt{2}}{2}$. I found this question on another forum and it fascinated me, but I don't know how to prove the answer.","['probability', 'combinatorics']"
101371,Finding how many terms of the harmonic series must be summed to exceed x?,"The harmonic series is the sum 1 + 1 / 2 + 1 / 3 + 1 / 4 + 1 / 5 + 1 / 6 + ... + 1 / n + ... It is known that this sum diverges , meaning (informally) that the sum is infinite and (more formally) that for any real number x, there there is some number n such t that the sum of the first n terms of the harmonic series is greater than x.  For example, given x = 3, we have that 1 + 1 / 2 + 1 / 3 + ... + 1 / 11 = 83711 / 27720 ≈ 3.02 So eleven terms must be summed together to exceed 3. Consider the following question Given an integer x, find the smallest value of n such that the sum of the first n terms of the harmonic series exceeds x. Clearly we can compute this by just adding in more and more terms of the harmonic series, but this seems like it could be painfully slow.  The best bound I'm aware of on the number of terms necessary is 2 O(n) , which uses the fact that 1 + 1 / 2 + 1 / 3 + 1 / 4 + 1 / 5 + 1 / 6 + 1 / 7 + 1 / 8 + ... is greater than 1 + ( 1 / 2 ) + ( 1 / 4 + 1 / 4 ) + ( 1 / 8 + 1 / 8 + 1 / 8 + 1 / 8 ) + ... which is in turn 1 + 1 / 2 + 1 / 2 + 1 / 2 + ... where each new 1 / 2 takes twice as many terms as the previous to accrue.  This means that the brute-force solution is likely to be completely infeasible for any reasonably large choice of x. Is there way to calculate the harmonic series which requires less operations than the brute-force solution?",['sequences-and-series']
101376,How did Hermite calculate $e^{\pi\sqrt{163}}$ in 1859?,"Pretend you are in 1859. What is a fast, efficient, and accurate way to numerically evaluate constants like that to, say, 20 decimal places, using ONLY pen and paper?","['math-history', 'real-analysis']"
101393,How to normalize this circle equation?,I am given a circle described by the equation below. Is there any way I can bring it to the form $(x-a)^2 + (y-b)^2 = c^2$ to have it be normal? My intent is to translate it to polar coordinates and I think I'd get much nicer results if I could normalize the equation. $$(x^2 + y^2)^2 = 9(x^2 - y^2)$$,"['algebra-precalculus', 'circles']"
101404,What is known about totally positive matrices?,"A totally positive matrix is one whose minors are all positive. This is a simple elementary concept but most of the development on the subject is far from elementary. I am having a hard time understanding most papers on the subject because of the complicated language. I would like to know, in simple terms, what is known about real totally positive matrices. What are necessary and sufficient conditions for a matrix to be totally positive? What is the simplest known algorithm to verify total positivity? Thanks in advance.",['matrices']
101406,"Is a field perfect iff the primitive element theorem holds for all extensions, and what about function fields","Let $L/K$ be a finite separable extension of fields. Then we have the primitive element theorem , i.e., there exists an $x$ in $L$ such that $L=K(x)$. In particular, the primitive element theorem holds for all finite extensions of a perfect field. Question 1. Is a field $K$ perfect if and only if the primitive element theorem holds for all finite extensions of $K$? Question 2. Suppose that $K$ is a field extension of $\mathbf{F}_p$ of transcendence degree 1, i.e., a function field over a finite field. Does the primitive element theorem hold for any finite extension of $K$? In Question 2, I am actually only interested in the case $K=\mathbf{F}_q(t)$.","['finite-fields', 'function-fields', 'abstract-algebra', 'field-theory']"
101410,L-function at s=5 with D=-4?,"I want to know the value of $L(5,-4)$. Recall that
$$
L(s,D)=\sum_{n=1}^\infty \left(\frac{D}{n}\right) n^{-s}.
$$
I would like a reference with computations of $L(5,D)$, or more generally, of $L(s,D)$ with $s$ and odd natural number.","['l-functions', 'reference-request', 'number-theory']"
101418,What is this function called (looks like a variant of the exponential function),"We set (as usual) $\displaystyle{x \choose k} := \frac{x \cdot (x-1) \cdots (x-k+1)}{k!}$ for $x\in \mathbb{C}$. Now we can define a function $\displaystyle f(x) := \sum\limits_{k=0}^\infty {x \choose k}$. Does anybody know how this function is called (I need its name, so that I can get more information about it)? I believe, it should be well-known, but I don't know its name. Note that if we defined $\displaystyle{x \choose k} := \frac{x^k}{k!}$ instead, we would simply get the $\exp$ function - so my function is probably be related to it.",['functions']
101423,Quickest route to the structure theorem for finitely generated modules over a PID,"This is the theorem the title refers to. In his Basic Algebra I , Jacobson proves it by means of a Lemma: Lemma Let $D$ be a PID and $K$ be a submodule of $D^{(n)}$ (the free module of rank $n$). Then $K$ is finitely generated; $K$ is free of rank $\le n$. Question What is the relevance of conclusion 2. to the subsequent proof? I guess it is not needed. Indeed, Jacobson's proof goes as follows. Take a finitely generated module $M$ over the PID $D$ and a generating homomorphism $ \eta\colon D^{(n)} \to M$. Then the kernel $K$ of $\eta$ is finitely generated and we have a relations matrix $A$, whose rows are a set of generators for $K$. We then apply the machinery of Smith normal form to $A$. It seems to me that we made no use of 2. This point guarantees that we can take $A$ of full rank, but that is something we don't need. Am I wrong? Thank you.","['modules', 'abstract-algebra']"
101441,Epsilon delta proof of a limit problems,"I am attempting to decipher the word of Stewart but I can't really understand any of the epsilon delta stuff. I watched several videos online and I have a better understanding but I still don't quite get how to do the math as no one really describes that part. As far as I understand I need to find the distance between x and delta that is less than delta and greater than zero that will coorespond to an epsilon (y). So I have the problem
$$
\lim_{x \to 1}\frac{2+4x}{3}=2
$$
so I do some algebra magic and I get $x=1$ but from there I am not sure what to do.","['calculus', 'proof-writing', 'limits']"
101453,Equivariant differential forms.,"I have some question about the equivariant differential forms on a smooth manifold: \
The equivariant differential forms over some smooth manifold $M$, on which the compact Lie group $G$ acts, are defined to be 
$$
\Omega_{G}^q(M)= \oplus_{2i+j=q} (S^{i}(\mathfrak g^*) \otimes \Omega^j(M))^G,
$$
where $\mathfrak g^*$ denotes the dual of the Lie algebra $\mathfrak g$ of $G$. Then many authors say that these forms can be considered as polynomial functions on the Lie algebra $\mathfrak g$ of $G$, but I am not sure how this is to be done. For example if we consider the element $(x_1 \otimes... \otimes x_i) \otimes \omega$ where $x_1,..., x_i$ are elements of $\mathfrak g^*$ and $\omega$ is a differential form, what is the evaluation of this element on some $a \in \mathfrak g$ in the Lie algebra of $G$.",['differential-geometry']
101463,Interpretation of {Infinitely Often} = {Almost Always},"I am trying to better understand what it means for a sequence $A_n$ of subsets of a set $S$ to be such that
$\bigcap^\infty_{n = 1} \bigcup^\infty_{m = n} A_n = \limsup A_n = \liminf A_n = \bigcup^\infty_{n = 1} \bigcap^\infty_{m = n} A_n$ I find the interpretation infinitely often and eventually always as in \begin{equation}
\bigcap^\infty_{n = 1} \bigcup^\infty_{m = n} A_n = \limsup A_n = \{ w \,  \colon w \in A_n \quad \text{infinitely often} \}
\end{equation}
and
\begin{equation} \bigcup^\infty_{n = 1} \bigcap^\infty_{m = n} A_n = \liminf A_n = \{ w \, \colon w \in A_n \quad\text{eventually always} \}
\end{equation} very helpful and I am looking for an analogous interpretation what it means for the two to be equal.","['limsup-and-liminf', 'elementary-set-theory', 'limits']"
101468,What does it mean to divide by the standard deviation?,"I'm trying to ""variance-normalize"" an image. In order to do so, I subtract the mean from the pixel value (to have a $0$ mean), and divide by the standard deviation (to have a unit variance) right? But I've also seen division by the standard deviation, since it's obviously not the same, what does it do? I'm also a bit confused about the values I get after normalization: some values still more than $1.0$ or less than $-1.0$. I thought a unit variance means a variance from $-1.0$ to $1.0$.","['statistics', 'standard-deviation', 'image-processing']"
101480,Are there other kinds of bump functions than $e^\frac1{x^2-1}$?,"I've only seen the bump function $e^\frac1{x^2-1}$ so far.  Where could I find examples of functions $C^∞$ on $\mathbb{R}$ that are zero everywhere except on $(-1,1)$? Are there others that do not involve the exponential function?  Are there any with a closed form integral?  Is there a preferred function?","['multivariable-calculus', 'smooth-functions', 'big-list']"
101481,Calculating maximum-likelihood estimation of the exponential distribution and proving its consistency,"The probability density function of the exponential distribution is defined as $$
f(x;\lambda)=\begin{cases}
\lambda e^{-\lambda x} &\text{if } x \geq 0 \\
0 & \text{if } x<0
\end{cases}
$$ Its likelihood function is $$
\mathcal{L}(\lambda,x_1,\dots,x_n)=\prod_{i=1}^n f(x_i,\lambda)=\prod_{i=1}^n \lambda e^{-\lambda x}=\lambda^ne^{-\lambda\sum_{i=1}^nx_i}
$$ To calculate the maximum likelihood estimator I solved the equation $$
\frac{d\ln\left(\mathcal{L}(\lambda,x_1,\dots,x_n)\right)}{d\lambda}\overset{!}{=}0
$$ for $\lambda$. $$
\begin{align}
\frac{d\ln\left(\mathcal{L}(\lambda,x_1,\dots,x_n)\right)}{d\lambda}
&= \frac{d\ln\left(\lambda^ne^{-\lambda\sum_{i=1}^nx_i}\right)}{d\lambda} \\
&= \frac{d\ln\left(n\ln(\lambda)-\lambda\sum_{i=1}^n x_i\right)}{d\lambda} \\
&= \frac{n}{\lambda}-\sum_{i=1}^n x_i
\end{align}
$$ Finally we get $$\lambda = \frac{n}{\sum\limits_{i=1}^n x_i}$$ I hope this is correct this far. Where I am more uncertain is the proof for consistency. I understand that to be consistent is in this case equivalent to to converge in probability to $\lambda$ . So I have a hinch, that something like $$
\lim_{n\to\infty}\mathbb{P}\left(\mathcal{L}(\lambda,x_1,\dots,x_n)-\lambda\right)=0
$$ will lead me to a solution. Am I correct this far? If yes, how can I solve this? A hint would be great. Update: Using hints by users @Did and @cardinal I will try to show the consistency by proving that $\frac{1}{\Lambda_n}\to\frac{1}{\lambda}$ for $n\to\infty$ where $$
\Lambda_n=\frac{n}{\sum\limits_{k=1}^nX_k}
$$ Since $E(X_1)=\int\limits_0^\infty\lambda xe^{-\lambda x}dx=\frac{1}{\lambda}$ and the random variables $X_i$ for $i\ge1$ are independent the strong law of large numbers implies that $$
P\left(\limsup_{n\to\infty}\left|\frac{1}{\Lambda_n}-\frac{1}{\lambda}\right|=0\right)=P\left(\limsup_{n\to\infty}\left|\frac1n\sum_{k=1}^nX_k-\frac{1}{\lambda}\right|=0\right)=1
$$ is true which implies convergence almost everywhere. This implies convergence in probability of $\Lambda_n$ to $\lambda$, which is equivalent to consistency. Is this proof correct?","['probability-theory', 'probability-distributions', 'probability']"
101487,Why are groups more important than semigroups?,"This is an open-ended question, as is probably obvious from the title. I understand that it may not be appreciated and I will try not to ask too many such questions. But this one has been bothering me for quite some time and I'm not entirely certain that it's completely worthless, which is why I've decided to ask it here. Why are groups so immensely more important in mathematics and its applications than semigroups are? I know little of group theory, mathematics and its applications, so I cannot understand how much more important they are. But I know they are because I see how many more people are interested in groups than in semigroups. I wouldn't ask this question if this fact didn't seem a little strange to me. I know that groups are associated with symmetries, or with automorphisms of structures. Cayley's Theorem tells me that every group can be seen as a set (closed with respect to taking compositions and inverses) of automorphisms of a structure with no constants, functions or relations, i.e. a plain set. I know that the automorphisms of a vector space, a module or a group form a group. Obviously, automorphisms are important. Then we have inverse semigroups. These are less popular but this I can understand. They are associated with partial symmetries, by the Wagner-Preston Theorem. Partial functions do seem much less used than functions. But then come semigroups. Just like in the two previous cases, there is an ""embedding theorem"", which says that every semigroup can be embedded in a semigroup of maps from a certain set into itself. And, analogously to the case of groups, the endomorphisms of a vector space, a module or a group form a semigroup. This seems to say that semigroups are to endomorphisms what groups are to automorphisms. The ""conclusion"" would be that $\frac{\mbox{the importance of semigroups}}{\mbox{the importance of endomorphisms}}=\frac{\mbox{the importance of groups}}{\mbox{the importance of automorphisms}}$ Assuming that endomorphisms are about as important as automorphisms, we get that semigroups are about as important as groups. My feeling is that the assumption is correct. I understand that I must be oversimplifying something at some point. But what am I oversimplifying and where? I realize that this is possibly a very dumb question, but my confusion is genuine. Edit: I have realized, after reading your answers and comments, that I made the mistake of using a very vague term without even attempting to define it. The problem seems to be what importance is. Is it popularity or usefulness, or being used a lot, or interesting or being interesting, or something else, or a mixture of many traits? I'm not going to force my understanding of the word now. But if someone still wants to answer this question, perhaps it would be good idea if the answer contained an attempt at clearing this up. (Or maybe not. I'm not sure!) Edit: A question similar to mine is dealt with here .","['big-picture', 'abstract-algebra', 'soft-question', 'semigroups', 'group-theory']"
101505,"Probability - Couples randomly sitting at a table, calculate the probability that they are together","I'm currently practicing for my first actuarial exam and came across this problem.  The posted solution doesn't make sense to me, and even if I'm right I don't know the correct way to do it. The problem: 13 married couples are seated randomly at a round table.  Calculate E(X), where X is the number of husbands sitting next to their wives. The given solution: Consider an individual couple.  The probability that that couple is seated together is $\frac 2 {25}$, so E(X) = $13(\frac 2 {25})$ = $\frac {26} {25}$ Me: What?  These aren't independent events!  I'm going to brute force a smaller version of this problem... So I decided to tackle the problem for 2 couples instead of 13.  This gives us 24 permutations, 17 of which have both couples sitting together (X=2) and the rest of which have none (X=0).  Therefore E(X) = $\frac {34} {24}$ Using the solution from above, $2 (\frac 2 3) = \frac 4 3$. To repeat my actual question: I'm pretty sure the given solution is wrong but I don't know what right is, so I'm looking for either an explanation for the flaw in my reasoning or the correct answer. EDIT: OK, I rechecked my work and found my error.  There are actually 16 permutations making the answer for N=2 $\frac {32} {24} = \frac 4 3$.  I'll be off to bed now.",['probability']
101507,limit superior of a sequence proof,"Let $(x_{n})\in\mathbb{R}^{+}$ be bounded and let $x_{0}=\lim\sup_{n\rightarrow\infty}x_{n}$. $\forall\epsilon>0$, prove that there are infinitely many elements less than $x_{0}+\epsilon$ and finitely many terms greater than $x_{0}+\epsilon$. My attempt:
By definition of limit superior, $\forall\epsilon>0$, $\exists N_{\epsilon}\in\mathbb{N}$  s.t. $\forall n>N_{\epsilon}$, $x_{n}<r+\epsilon$ . Since $\{x_{n}\}$ is a bounded sequence, there are only $N_{\epsilon}$  values of $\{x_{n}\}$  s.t. $x_{n}>r+\epsilon$.  However, since for all $n>N_{\epsilon}$,  $x_{n}<r+\epsilon$,  there are infinitely such $x_{n}<r+\epsilon$. I think my proof is probably incomplete/too informal. What do you think?","['limsup-and-liminf', 'sequences-and-series', 'proof-writing', 'limits']"
101512,"Proving: ""The trace of an idempotent matrix equals the rank of the matrix""","How could we prove that the ""The trace of an idempotent matrix equals the rank of the matrix""? This is another property that is used in my module without any proof, could anybody tell me how to prove this one?","['trace', 'matrix-rank', 'matrices', 'linear-algebra', 'idempotents']"
101517,Simple Partial Fractions Question,"For practice, I am integrating, $$\int \frac{x}{3x^2 + 8x -3}dx$$ So, I can then factor it as, $$\int \frac{x}{(3x-1)(x+3)}dx$$ By partial fractions, I decompose $$\frac{x}{(3x-1)(x+3)}= \frac{A}{3x-1} + \frac{B}{x+3}$$ For finding $A$, I multiply both sides by $3x-1$, which gives $$\frac{x(3x-1)}{(3x-1)(x+3)} = \frac{A(3x-1)}{3x-1} + \frac{B(3x-1)}{x+3}$$ So, we have that $$\frac{x}{(x+3)} = A + \frac{B(3x-1)}{x+3}$$ Letting $3x-1=0$, we have that $x=\frac{1}{3}$, so then $$\frac{\frac{1}{3}}{(\frac{1}{3}+3)} = A$$ Thus, we have that $A=\frac{1}{10}$. For determining $B$, we then multiply both sides by $x+3$ and receive, as a similar process to the previous, $$\frac{x(x+3)}{(3x-1)(x+3)} = \frac{A(x+3)}{3x-1} + \frac{B(x+3)}{x+3}$$ Then, $$\frac{x}{3x-1} = \frac{A(x+3)}{3x-1} + B$$ So, if we let $x+3=0$, we then have that $x=-3$ and so, $$\frac{-3}{3(-3)-1}=B$$ So, we then have that $B=\frac{3}{10}$. Thus, our original integral can then be written as, $$\int \frac{x}{(3x-1)(x+3)}dx = \int \frac{1}{10(3x-1)} + \frac{3}{10(x+3)} dx$$ We can, by splitting up the integral find, $$\int \frac{x}{(3x-1)(x+3)}dx = \frac{1}{10} \int \frac{1}{3x-1} dx + \frac{3}{10} \int \frac{1}{x+3} dx$$ Thus, we conclude that, $$\int \frac{x}{3x^2 + 8x -3}dx = \frac{\ln|3x-1|}{30} + \frac{3 \ln|x+3|}{10} + C$$ Wolframalpha shows that, the answer is: $$\frac{1}{30}(\ln(1-3x)+ 9 \ln(3+x)) +C$$ What am I doing wrong, did I miss a negative sign somewhere?",['calculus']
101527,Transversal of a family of sets,"What I want to prove is: Let $U=(A_1\ldots,A_n)$ be a family of sets and let $P\subseteq A_1\cup \cdots \cup A_n$. Then $U$ has a transversal which includes the set $P$ if and only if (i) $U$ has a transversal (ii)$|P\setminus (\cup_{i\in I}A_i)|\le n-|I|$ for any $I\subseteq \{1,\ldots,n\}$. A transversal of $U$ is a set $X$ with $|X|=n$ which can have its elements arranged in a certain order, $X=\{a_1,\ldots,a_n\}$ say,so that $a_1\in A_1,\ldots,a_n\in A_n$; in other words then $n$ distinct elements of $X$ 'represent' the $$ sets. I think $\Rightarrow$ direction is quite easy to prove but the converse, I don't know how to start the proof. Does anyone has any idea to prove this statement?",['combinatorics']
101528,Derivative of Rayleigh quotient,"I'm going over the proof of the spectral theorem for compact symmetric operators in Hilbert space in Lax. Let $A$ be a compact symmetric operator on a Hilbert space to itself. Define the Rayleigh quotient to be $$R_A(x) = \frac{(Ax, x)}{\|x\|^2}$$ Let $z$ be vector that maximizes the quadratic form $(Ax, x)$ over the unit ball. Let $w$ be arbitrary. Now the text claims that $R(z + tw)$ is differentiable, and since it achieves its maximum at $t=0$, it's $t$-derivative is zero, and we have $$\frac{(Aw, z) + (Az, w)}{\|z\|^2} - (Az, z) \frac{(w, z) + (z, w)}{\|z\|^4} = 0$$ I don't see why the given function is differentiable, nor the computation of its derivative.",['functional-analysis']
101530,Showing $A_4$ is not simple.,"This is meant to be a counter example to $A_4$ being simple, since $\{ (1),(12)(34),(13)(24),(14)(23)\}$ is normal. But, how can you check it's normal, is there a quick way or do you need to calculate all of $A_4$?",['group-theory']
101532,Convergence/divergence of a couple of infinite series,"I have to figure out if the following series converge or diverge: (1) $\sum_{n=1}^{\infty}\frac{(-i)^{n+1}}{n^{2}+1}$. This has the $N$-th partial sum $s_N=\sum^{N}\frac{(-i)^{N+1}}{N^{2}+1}$. My attempt: To show whether or not the series converges, I need to show whether {$S_{N}$} is Cauchy. So I have to see that $\forall\epsilon>0$ $\exists N_{\epsilon}$ s.t. for all $n,m>N_{\epsilon}$, $|\sum_{k=m+1}^{n}\frac{(-i)^{n+1}}{n^{2}+1}|<\epsilon$. Where do I go from here? (2) $\sum_{n=1}^{\infty}e^{in\theta}/n$ for $0<\theta<2\pi$, $\theta$ fixed. Not sure how to approach this.","['convergence-divergence', 'sequences-and-series']"
101537,Irreducible elements in  $\mathbb{Z}[\sqrt{-2}]$ and is it a Euclidean domain?,"First of all I am new to this topic, algebraic number theory, so I only know a decent (not great) amount of abstract algebra. The question I have is that, given the imaginary quadratic field $\mathbb{Z}[\sqrt{-2}]$, I want to find; (1) all irreducible elements of it, (2) show that it is a Euclidean domain, and (3) show that for an odd prime number $p,\; \exists \;x,y\; \in \mathbb{Z}$ s.t. $p = x^2+2y^2$ iff $p=1,3(\textrm{mod}\; 8)$. I have been reading and have books but there are some things I am not getting. (a) My attempt at finding the units (I read that there are only ${}^{\pm}1$ for this integral domain (ID)); A unit is an element with an inverse, so for an element $p_1 \in \mathbb{Z}[\sqrt{-2}]$, there is another element $p_1'$ s.t. $p_1\,p_1' = p_1'\,p_1 = 1$ (it is integral domain, not just domain). Let $p_1 := a+b\sqrt{-2}$ and $p_1':=x+y\sqrt{-2}$ and so $p_1\,p_1' = 1$ becomes $(a+b\sqrt{-2})(x+y\sqrt{-2}) = 1  = 1+0\sqrt{-2}$ and into the two equations, $1=ax-2by$ and $0=ay+bx$. Solving these leads to $x=\frac{a}{a^2+2b^2}$, $y=\frac{-b}{a^2+2b^2}$ and $p_1'=\frac{a}{a^2+2b^2} + \left( \frac{-b}{a^2+2b^2} \right)\sqrt{-2}$, which can only belong to $\mathbb{Z}$ if $b=0,\;a={}^{\pm}1$. Is there a better way of determing the units of an ID ? I read that the units, $\epsilon$, of a quadratic ID of the general form $R[\sqrt{d}]$, where $d$ was square-free, were determined by $Norm(\epsilon) = {}^{\pm}1$ Is this general ? Is this for any $d$ that is square-free (though I see little difference between $d=d$ and $d=z*d$, as $z\in \mathbb{Z}$) ? (1) I know, procedurally, how to do this for a given element, but I do not know of a better way to do it in general. Here is my attempt: I read that: An element $p$ of an ID is irreducible in R if it satisfies: (i) $p \neq 0$ and $p$ is not a unit, (ii) if $p=ab$ in R, then $a$ or $b$ is a unit in R. (maybe because I know the units in this ID I can say that all other non-zero elements are irreducible ? ) So if $p = ab$, with $a = m+n\sqrt{-2}$, then using the as-of-yet-unproved-homomorphism-norm-map, $N(ab) = N(a)\,N(b)$, $N(p=x+y\sqrt{-2}) = x^2+2y^2 = N(a)\,N(b) = (m^2+2n^2)\,N(b)$. Now if I had a specific element, to determine if it was irreducible, I could then determine what values of $N(a)$ and $N(b)$ were valid so that their product equaled $N(p) = N(x+y\sqrt{-2})$, which this latter term would be an integer ($N: \mathbb{Z}[\sqrt{-2}] \mapsto \mathbb{Z}$). The latter two questions I haven't got far with either but am wanting to get this initial question(s) understood first. Thanks all for your time reading my rather lengthy question!","['ring-theory', 'number-theory']"
101548,generalized ordering of positive semi-definite matrix by eigenvalues,"I know positive semi-definite matrices are generalizations of non-negative numbers.
So ""ordering"" of the two systems should be pretty much like each other.
How to prove the following theorem? For two symmetric $X$ and $Y$, if $X \geq Y$, then $\lambda_i(X) \geq \lambda_i(Y)$, for every $i$. $\lambda_i(\cdot)$ denotes the $i$-th largest eigenvalue. And what about the converse statement? Is it true? Thanks a lot.",['matrices']
101550,Pythagorean triplets,"Respected Mathematicians, For Pythagorean triplets $(a,b,c)$, if $c$ is odd then any one of  $a$ and $b$ is odd. Here $(a, b, c)$ is a Pythagorean triplet with $c^2 = a^2 + b^2$. Now, I will consider $c = b + \Omega$. The reason for considering $c = b + \Omega$ is, $c$ is a hypotenuse side of right triangle and it is obviously larger than the other side $b$. Now, 
$$a^2 + b^2 = (b + \Omega)^2 = b^2 + 2b \Omega +  \Omega ^2\qquad\qquad(1)$$ which is same as 
$$b = [a^2 -  \Omega ^2] \div 2\Omega.$$ 
Which implies that $\Omega$ divides $a^2$ for $a^2- \Omega ^2) \gt 0$ or $(a - \Omega) (a + \Omega) \gt 0$, which implies that 
$$a \gt \Omega\qquad\qquad(2).$$ Now, I will consider $a = 2^m$; then $\Omega$ is also even. Otherwise, if $a = 2^m + 1$ then obviously $\Omega$ is odd. Now, I will consider both $a$ and $\Omega$ is an even numbers such that, $a = 2^m$ and $\Omega = 2^r$ for some $m$ and $r$. By (2), we have $m \gt r$ and by (1), we have
$$(2^m)^2 = 2^r (2b + 2^r)$$
or 
$$b = \frac{2^r}{2}((4^m \div 4^r) - 1))\qquad\qquad(3)$$ As I said earlier, $a$ and $\Omega$ is an even, then $b$ should be an odd number. i.e., $r  = 1$ Therefore, the required triplets for even numbers in powers of $2$ are 
$(2^m, (4^m \div 4) - 1, (4^m \div 4 ) + 1))$ Now my question is, how one can generalize the same for following? Case 1: if we take odd numbers for powers of some prime Case 2: if we take even numbers with prime powers. Thanking you,","['elementary-number-theory', 'pythagorean-triples', 'number-theory']"
101556,Period of a product of $\sin$ and $\cos$,"I want to find the period of $\sin(t) \cos(\pi t)$. I started off by transforming that into
$\frac{1}{2}\left [ \sin((\pi +1)t) - \sin((\pi - 1)t\right ]$, but then I get stuck.  How do I find the least common multiple of $\pi + 1$ and $\pi - 1$? Is that what I need to do to find the period of the whole thing?","['trigonometry', 'signal-processing']"
101560,"Computing $\lim_{(x,y)\to (0,0)}\frac{x+y}{\sqrt{x^2+y^2}}$","What is the result of  $\lim_{(x,y)\to (0,0)}\frac{x+y}{\sqrt{x^2+y^2}}$ . I tried to do couple of algebraic manipulations, but I didn't reach to any conclusion. Thanks a lot.","['multivariable-calculus', 'calculus', 'limits']"
101566,"Using Euler's Totient Function, how do I find all values n such that $\phi(n)=12$? [duplicate]",This question already has answers here : How to solve the equation $\phi(n) = k$? (4 answers) Closed 3 years ago . How do I generalize the equation to be able to plug in any result for $\phi(n)=12$ and find any possible integer that works?,"['totient-function', 'elementary-number-theory', 'discrete-mathematics']"
101570,How do you split a long exact sequence into short exact sequences?,"How does one split up a long exact sequence into short exact sequences? Say you have some longs exact sequences of modules
$$
0\longrightarrow M_1\stackrel{\phi_1}{\longrightarrow}M_2\stackrel{\phi_2}{\longrightarrow}M_3\stackrel{\phi_3}{\longrightarrow}M_4\stackrel{\phi_4}{\longrightarrow}\cdots
$$
I've read it's possible to split this into short exact sequences. What exactly does that mean? Would it be written as short exact sequences, one appended to another like
$$
0\longrightarrow N_1\longrightarrow M_1\longrightarrow N'_1\longrightarrow 0\longrightarrow N_2\longrightarrow M_2\longrightarrow N'_2\longrightarrow 0 \longrightarrow\cdots?
$$
If so, how does this work? Merci.",['abstract-algebra']
101580,"Using $\epsilon$-$\delta$ approach to prove that $\lim_{(x,y,z)\rightarrow (0,0,0)}\frac {y^3-1000xy^2+z^5}{x^2+y^2+z^4}=0$?","As the title indicates, Using $\epsilon$-$\delta$ approach to prove that $$\lim_{(x,y,z)\rightarrow (0,0,0)}\frac {y^3-1000xy^2+z^5}{x^2+y^2+z^4}=0$$?","['multivariable-calculus', 'calculus', 'limits']"
101586,"Let $f(x)=x^2+2x$ and $g(x)=x^3$, finding the roots of $f\circ g(x)=g\circ f(x)$","Let $f(x)=x^2+2x$ and $g(x)=x^3$, how many different roots does $f\circ g(x)=g\circ f(x)$ have? I solved it and found $x=-1$ but it says it has two different roots, could someone clarify?","['algebra-precalculus', 'roots', 'functions']"
101590,What is zero power of a non-square matrix?,I'm told that zero power of square matrix is an identity matrix of appropriate size. How it is with a non-square matrix?,"['matrices', 'linear-algebra']"
101624,Is the infinite sum of $2 ^{-n}$ convergent? Why?,"As a follow-up to a previous question , I'd like to know if $$\sum_{n=1}^\infty\frac{1}{2 ^ n}$$ is convergent? If yes, then what does it converge to? Just as a sidenote - the whole issue started with reading about Zeno's Turtle Paradox which made me curious about the underlying mathematics.","['sequences-and-series', 'real-analysis']"
101636,Jacobi's criterion for projective schemes?,"When can we apply the Jacobi's criterion for the projective variety $V(f_{1}, \ldots, f_{r}) \subset \mathbb{P}^{n}$ in order to find the singularities of the scheme $\mathrm{Proj} \left( k[x_{1}, \ldots, x_{n+1}] / (f_{1}, \ldots, f_{r}) \right)$? In Hartshorne's book Algebraic Geometry, Proposition II.2.6, we have a fully faithful functor from the category of varieties over $k$ to the category of schemes over $k$, but it seems to provide information only for the closed points of the scheme. Thank you.",['algebraic-geometry']
101639,Notation for a canonical quotient of an abelian variety in positive characteristic,"This may be a somewhat silly question, but there it goes. Let $k$ be an algebraically closed field of characteristic $p>0$ and let $A=A_{/k}$ be an ordinary abelian variety of dimension $g\geq1$. One knows that the $p$-torsion of $A$ is a product: 
$$A[p]=\hat A[p]\times T_p(A)\otimes(\Bbb Z_p/p\Bbb Z_p).$$ 
Here $\hat A[p]$ is the maximal connected subgroup,
$T_p(A)\otimes(\Bbb Z_p/p\Bbb Z_p)$ is etale, both factors are subgroups of rank $p^g$ and they're Cartier dual of each other. The completely inseparable isogeny obtained by quotient by $\hat A[p]$ is the relative Frobenius $F_k:A\rightarrow A^{(p)}$ where $A^{(p)}$ is the abelian variety obtained by twisting the $k$-structure of $A$ by the geometric Frobenius i.e. the automorphism $x\mapsto x^{1/p}$ of $k$. The isogeny $A\rightarrow A^\prime$ obtained by quotient by 
$C=T_p(A)\otimes(\Bbb Z_p/p\Bbb Z_p)$ is etale and after an identification $A\simeq(A^\prime)^{(p)}$ is the Verschiebung $V_k:(A^\prime)^{(p)}\rightarrow A^\prime$ associated with $A^\prime$. Is there a standard notation for the abelian variety that I denoted $A^\prime$? I have checked a few textbooks and lecture notes about abelian varieties and/or group schemes, but I seemed not to be able to find any.","['notation', 'algebraic-geometry', 'algebraic-groups', 'abelian-varieties']"
101654,Lower bound for $\phi(n)$: Is $n/5 < \phi (n) < n$ for all $n > 1$?,"Is it true that : $\frac {n}{5} < \phi (n) < n$ for all $n > 1$ where $\phi (n)$ is Euler's totient function . Since $\phi(n)$ has maximum value when $n$ is a prime it follows that maximum value of $\phi(n)$ in term of $n$ is $n-1$ , therefore $\phi(n)< n$ for all $n$ . What is the best lower bound for $\phi(n)$ ?","['totient-function', 'analytic-number-theory', 'inequality', 'number-theory']"
101664,Can all first order ODEs be made exact?,"Elementary differential equations classes usually cover exact differential equations . These are equations of the form: $$M(x,y)+N(x,y)y'=0 \qquad \mathrm{such\;that} \qquad \frac{\partial M}{\partial y} = \frac{\partial N}{\partial x}$$ We know that in many cases if one cooks up the right integrating factor $I(x,y)$ , we can multiply through the equation and get a new equation $I(x,y)M(x,y)+I(x,y)N(x,y)y'=0$ which is exact (i.e. $\frac{\partial (IM)}{\partial y} = \frac{\partial (IN)}{\partial x}$ ) and has the same solutions. Also, we know that finding $I$ (in general) is quite hopeless since this boils down to solving the first order partial differential equation: $\frac{\partial (IM)}{\partial y} = \frac{\partial (IN)}{\partial x}$ for $I$ . To find $I$ one usually makes some simplifying assumption (like $I(x,y)$ is a monomial or $I$ does not depend on $x$ or $y$ ). In such cases finding $I$ reduces to algebra or solving an easier first order ODE. Of course, $I=0$ , always makes the equation exact (but this introduces solutions which are not solutions to the original equation). Also, it's not too hard to come up with examples which have no integrating factors which are monomials or functions of $x$ or $y$ alone (the special assumptions don't always pan out). My question: Is it true (under some assumptions -- like $M$ and $N$ are analytic or something) that there always exists some $I$ such that $IM+INy'=0$ is exact (and has the same set of solutions)? If so, could you provide a reference or two? Preferably something better than ""look at DeRham cohomology...blah blah...foliations."" A fairly elementary reference accessible to someone without extensive differential topology background would be nice (if it exists). If this is not true, are there reasonable assumptions one can make so that it is true? I'm no DEs expert (I've taught a few introductory courses but this is outside my realm of expertise). By brother brought up this question a few weeks ago and it's been bothering me. He says he's seen the answer ""Yes"" claimed in some text (but that text was written for engineers so who knows whether the author meant ""integrating factors always exist"" or ""integrating factors exist for the equations we care about""). Thanks in advance! Edit: Thanks to Julian for his answer. Here's a more detailed version of what he posted... Given a differential equation, $M(x,y)+N(x,y)y'=0$ . Let's assume $M$ and $N$ have continuous first partials. In addition assume $M(x,y)$ and $N(x,y) \not=0$ [If $N(x,y)=0$ , this is not a DE. If $M(x,y)=0$ we just have trivial constant solutions]. Then the equation is equivalent to $y'=-M(x,y)/N(x,y)$ . Call on the fundamental existence/uniqueness theorem and get a solution $F(x,y,C)=0$ . If $F_y=0$ , then $y$ does not appear in $F$ (which is absurd) so $F_y \not=0$ . Fix a constant $C$ , by the chain rule, since $F(x,y,C)=0$ we have $F_x(x,y,C)+F_y(x,y,C)y'=0$ . Therefore, $y' = -F_x/F_y$ (recall $F_y \not=0$ ). But $y'=-M/N$ . Therefore, $-F_x/F_y=-M/N$ and so $F_x/M = F_y/N$ (recall $M$ and $N$ are non-zero). Let $I(x,y) = F_x(x,y)/M(x,y) = F_y(x,y)/N(x,y)$ (this is our integrating factor). Then $I(x,y)M(x,y) + I(x,y)N(x,y)y' = 0$ which is $\frac{F_x}{M}M+\frac{F_y}{N}Ny'=0$ and so $F_x(x,y)+F_y(x,y)y'=0$ (which is an exact equation). Therefore, we can (in theory) always find (except in a trivial case) an integrating factor to make a non-exact first order ODE into an exact one. Also, note: I have not been precise about where things are non-zero, but we don't really need these functions and partials to be non-zero everywhere just in the regions we care about.","['ordinary-differential-equations', 'reference-request']"
101667,Complex differentiation,Is differentiation in the complex plane the same as that in the reals? In particular do the normal differentiation rules apply in the complex case such that I can just treat a complex map as a real map? Thanks.,['complex-analysis']
101673,Flaw in expected value solving logic (Project Euler 323),"The problem statement for Project Euler #323 is as follows: Let $y_0, y_1, y_2, ...$ be a sequence of random unsigned 32 bit integers (i.e. $0 \leq y_i < 2^{32}$ , every value equally likely). For the sequence $x_i$ the following recursion is given: $x_0 = 0$ and $x_i = x_{i-1} | y_{i-1}$ , for $i > 0$ . ( | is the bitwise-OR operator) It can be seen that eventually there will be an index N such that $x_i = 2^{32} -1$ (a bit-pattern of all ones) for all $i \geq  N$ . Find the expected value of N.  Give your answer rounded to 10 digits after the decimal point. I'm not interested in the actual solution to the problem, but I wish to understand where my attempts have gone wrong. My attempt to the problem thus far has been as follows: For any $y_i$ , the chance of any bit being a 1 is $\frac{1}{2}$ as all values are equally likely. In other words, the chance that a bit will ""flip"" from a 0 to a 1 on the next turn is $\frac{1}{2}$ . Thus the expected number of 1s in $x_1$ is $32 \div 2 = 16$ Following this logic, the expected number of 1s in $x_2$ is 24, as half of the sixteen zeroes would flip. Then the expected number of 1s in $x_3$ is 28, for $x_4$ it's 30 and for $x_5$ it's 31. The expected value for the last bit is equivalent to flipping a coin until we hit a head (1), which would be $\sum_{1}^{\infty} \frac{n}{2^n} = 2$ . Therefore the expected value of N is 5 + 2 = 7. However, apart from the fact that the answer is completely wrong, something makes me think that expected values just don't work that way. Can someone please clarify where I've made a mistake? Disclaimer: Although I try to refrain from posting questions related to Project Euler on Math StackExchange, I believe that the answer to my problem would make it no easier for anyone else to solve the problem, and might in fact help others understand where they went wrong.","['project-euler', 'probability']"
