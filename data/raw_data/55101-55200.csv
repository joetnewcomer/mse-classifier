question_id,title,body,tags
593542,Commutator subgroup of a dihedral group.,"I have a few questions concerning an example of the commutator subgroups in the dihedral group. This example is found on pg.171 of Abstract Algebra by Dummit and Foote. Let $D_{2n}=\langle r,s |r^n=s^2=1, s^{-1}rs=r^{-1}\rangle$. Since $[r,s]=r^{-2}$ we have that $\langle r^{-2} \rangle = \langle r^2 \rangle \le D'_{2n}$. Furthermore, $\langle r^2\rangle \trianglelefteq D_{2n}$ and the images of $r$ and $s$ in $D_{2n} / \langle r^2 \rangle$ generate this quotient. What exactly is meant by the image of $r$ and $s$? They (is this referring to $r$ and $s$?) are commuting elements of order $\le 2$ (I know $s$ is of order $2$ but $r$ is of order $n$??) so the quotient is abelian and $D'_{2n} \le \langle r^2 \rangle$. (I thought the quotient was abelian due to the already established properties of $\langle r^2 \rangle$ i.e it is normal and a subgroup of the commutator subgroup.)","['dihedral-groups', 'group-theory', 'abstract-algebra', 'derived-subgroup']"
593550,Expressing a positive integer as a sum of positive integers,"I am trying to find a way for the positive integers written as the sum of other positive integers.( expressed in terms of some functions) I searched a bit and I came across with Partitions But in my case the order matters. What I mean is for example if we write for 4, 
there would be 7 ways to express 4 as; 1 + 3

         2 + 2

         3 + 1

         1 + 1 + 2

         1 + 2 + 1 

         2 + 1 + 1

         1 + 1 + 1 + 1 Can anyone guide me in approaching to the solution of my problem? Thanks in advance.","['discrete-mathematics', 'number-theory', 'combinatorics']"
593551,Differentiating the Spherical Mean w.r.t its radius,"this question regards differentiating the spherical mean with respect to its radius. This is my attempt so far: Start with the equivalent form of the spherical mean so that we can pass the partial derivative into the integrand: $$S(v,x,r) = {1 \over d \omega_d} \int_{|\xi|=1)} v(x+r\xi)do(\xi)$$ Then take partial derivative with respect to r: $${\partial \over \partial r}S(v,x,r) = {1 \over d \omega_d} \int_{|\xi|=1} {\partial \over \partial r} v(x+r\xi)do(\xi)$$ What I understand so far is that this turns into the LHS of the equality below, because of the multivariable chain rule, but I don't know how to go from the LHS to the RHS: $${1 \over d \omega_d} \int_{|\xi|=1} \sum_{i=1}^{d} {\partial \over \partial x^i} v(x+r\xi)\xi^ido(\xi)=S(v,x,r) = {1 \over d \omega_d r^{d-1}} \int_{\partial B(x, r)} {\partial \over \partial \nu} v(y)do(y)$$ I tried to write the integrand of RHS using the definition of divergence, and get it to look like: $$\int_{\partial B(x, r)} {\partial \over \partial \nu} v(y)do(y)=\int_{\partial B(x, r)} v(y) 
\cdot \nu do(y)$$ But I am not understanding what would happen to $\xi ^i$, and how/when to make the substitution back to the original form of the spherical mean, over $B(x,r)$. Any input/hints are appreciated.",['multivariable-calculus']
593568,Multiple root of a polynomial is also a root of the derivative,"Suppose $a\in\Bbb R$ is a root of $f(x)$ in $\Bbb R[x]$. Show that $a$ is a multiple root of $f(x)$ if and only if $f'(a) = 0$, if and only if the graph of $y = f(x)$ is tangent to the $x$-axis at $x=a$. So for a I know that if $f'(a) = 0$, then $f(a)$ is a local extremum so $a$ is a root but I do not see why a would be a multiple root.","['calculus', 'roots', 'derivatives', 'polynomials']"
593572,"If $3^n+81$ is a perfect square, then positive integer value $n$ is","If $3^n+81$ is a perfect square, Then calculation of  a positive integer value of $n$. $\bf{My\; Try}::$ When $n≤4,$ then easy to know that $3^n+81$ is not a perfect square. Now let $n=k+4(k∈Z^{+}),$ then $3^{n}+81=81(3^{k}+1).$ So $3^{n}+81$ is a perfect square, and $81$ is square, there must be a positive integer $x$, such that $3^{k}+1=x^2⇒3^k=(x−1)⋅(x+1)$ Means $(x+1)$ and $(x-1)$ must be a power of $3$ form Now I did not understand how can i solve after that Help Required Thanks.",['algebra-precalculus']
593592,Pigeonhole Principle: birthdays on same day of week,"How many people must be in a room so that at least 10 have a birthday on a Friday? edit: Assume that no two people share the same birthday I'm somewhat confused and see two different ways to solve the problem. First, since all birthdays fall on one of seven days, if there are 64 people in the room one would at least one day of the week to hold 10 people. This is a similar problem: picking certain number of days . However, there are 366 possible birthdays and only 52 or 53 of those are Fridays, giving $\displaystyle366 - 52= 314$ days of the year that are not Friday. So to be absolutely certain there are 10 people with Friday birthdays, would one need $314+10=324$ people?","['pigeonhole-principle', 'discrete-mathematics', 'combinatorics']"
593594,Confusion in proof that primes $p = 4k + 1$ are uniquely the sums of two squares,"I'm reading a proof in my number theory textbook that all primes of the form $p = 4k+1$ are uniquely the sum of two squares. I'm stuck right at the beginning of the proof, where they say: To establish the assertion, suppose that
$$
p = a^2 + b^2 = c^2 + d^2
$$
where $a,b,c,d$ are all positive integers. Then
$$
a^2 d^2 - b^2 c^2 = p(d^2 - b^2).
$$ Perhaps I'm just missing something obvious, but I can't figure out how they managed to conclude that $a^2 d^2 - b^2 c^2 = p(d^2 - b^2).$ Please advise.","['prime-numbers', 'elementary-number-theory', 'number-theory']"
593598,similar matrices over $\mathbb{Z}$,"Let $A,B$ be $2\times 2$ matrices over $\mathbb{Z}$. Suppose $x^2+x+1$ is the characteristic polynomial for both $A,B$. Determine whether $A,B$ are similar to each other over $\mathbb{Z}$. How to solve?","['number-theory', 'ring-theory', 'matrices', 'linear-algebra', 'modules']"
593607,"How prove this integral limit is exsit $\lim_{\varepsilon\to 0^{+} }f(x,y)dxdy$","Question: This problem  is the 2013 Beijing university mathematics examination the last question,and I consider sometimes,and I can't, let  $D$ is with smooth boundary bounded region in plane,and the function 
$f(x,y)$  is Continuous differentiable on $\overline{D}$,and $\forall P_{0}=(x_{0},y_{0})\in D$, show that this limit $$A=\lim_{\varepsilon\to 0^{+}}\int\int_{D/B_{\varepsilon}(P_{0})}\dfrac{\dfrac{\partial f}{\partial y}(x,y)(y-y_{0})+\dfrac{\partial f}{\partial x}(x,y)(x-x_{0})}{(x-x_{0})^2+(y-y_{0})^2}dxdy$$
  is exsit,where $B_{\varepsilon}(P_{0})=\{(x,y)|(x-x_{0})^2+(y-y_{0})^2\le\varepsilon^2,,x_{0},y_{0}\in D\}$ (2):show that
  $$f(x_{0},y_{0})=\dfrac{1}{2\pi}\left(\int_{\partial D}\dfrac{f(x,y)}{(x-x_{0})^2+(y-y_{0})^2}((x-x_{0})dy-(y-y_{0})dx)-A\right)$$ First,I want use this Taylor lemma:
$$f(x,y)=f(x_{0},y_{0})+f'_{x}(x_{0},y_{0})(x-x_{0})+f'_{y}(x_{0},y_{0})(y-y_{0})+\cdots $$ But I can't any work .Thank you for you help!","['calculus', 'analysis']"
593611,Trying to Understand Lefschetz Pencils,"I'm reading on Lefschetz pencils, and I'm trying to understand the following condition ii) better, although I would appreciate insights on condition i), and in general. A Lefschetz pencil on a $4$-manifold  $X$ is a pair $(B, \pi)$, where
  $B$ is a finite, discrete subset of $X$ , and a map $\pi$: $(X-B)
> \rightarrow \mathbb CP^1 $  so that: i) Each point $b$ in $B$ has an orientation-preserving local
  coordinate map to $(\mathbb C^2,0)$ in which $\pi$ corresponds to the
  projectivization map (i.e., every line thru $0^{2n}$ becomes an
  equivalence class $[t_0:t_1]; t_0,t_1$ not both $0$, partitioning
  $\mathbb C^2 -0)$ , and ii) Every critical point of $\pi$ has an
  orientation-preserving chart in which $\pi(z_1,z_2)=z_1^2+z_2^2 $, for
  some holomorphic local chart in $\mathbb CP^1$. A few questions I hope someone can help me with: (1) There is no mention , AFAIK, of any smoothness condition for $\pi$. Is this mention of critical point related to something else, or do we assume $\pi$ is smooth, or at least differentiable, so that critical points are those where $d\pi$ does not have full rank? (2) What is the relevance of having a chart in which $\pi(z_1,z_2)$ equals $z_1^2+ z_2^2 $? I'm aware that these pencils extend, after blowing up each point of the finite, discrete point-set $B$ , into a full-blown (ha-ha) Lefschetz fibration. 
The blow up consists, AFAIK, of  defining a tangent space at a ""problem point"" where this tangent space is not defined, somehow patching all possible directions at a point by attaching a $\mathbb CP^n$ containing all directions. But I don't fully get the importance or relevance of these two conditions in ii). Any ideas or references? EDIT - My Background: I'm trying to include the little I understand about the algebraic-geometric perspective. please feel free to correct and comment, since my understanding from this perspective is pretty limited: 1) We start with a complex surface M (meaning Real 4-manifold). 2) We consider a codimension-2 , generic linear subspace $L \subset \mathbb CP^n$. Let $B:= L\cap M $ .By a dimension count (and ""genericity""), $|B|=n < \infty$ 3) We consider two generic codimension-1 subspaces $S^1, S^2$, generic other than they contain the linear subspace $L$. We have that $S_1,S_2$ can be represented as $V(p_0)$, $V(p_1)$ respectfully , i.e., as algebraic varieties, i.e., as the zero sets of two polynomials $p_0,p_1$ (not sure why this is possible, i.e., what guarantees we can do this.) 4) We consider the varieties associated to/ generated-by the above subspaces and respective  polynomials , variety which is generated by any two points $[r_0:r_1], [s_0:s_1]$ in $\mathbb CP^1$ , i.e., the sets $V(r_0p_0+r_1p_1 )$ and $V(s_0p_0+s_1p_1)$. We show this two varieties intersect $S$ precisely at $B$, as in #2). This intersection is independent of the choice of points $[s_0,s_1], [r_0,r_1]$ used, i.e., for any two points in $\mathbb CP^1 $ used, the associated varieties will intersect in $B$. As you see, my understanding from this perspective is minimal, but I would love to understand it better. Thank You.","['differential-topology', 'algebraic-geometry', 'algebraic-topology', 'differential-geometry']"
593612,Finding the other trig. functions with given values,"If $\sec\theta = \frac{5}{2}$ and $\csc\theta < 0$, find the other five trig. functions The ""$\csc < 0$"" is confusing me. How do I know which quadrant that is in? What if it was ""$\cot < 0$""?","['trigonometry', 'functions']"
593616,Which conformal maps UHP$\to$UHP extend continuously to the closure?,"Does every conformal map of the upper half-plane $\{\text{Im }z >0\}$onto itself extend continuously to a map from its closure $\{\text{Im }z \geq 0\}$ to itself? If not, which ones do? In this answer (written by a student, so there may be mistakes), some claims are made which I'm trying to prove. First: Any map $\varphi$ which has such an extension $\tilde{\varphi}$ is such that $\tilde{\varphi}(\mathbb{R})=\mathbb{R}$ . Why? Certainly I see that $\tilde{\varphi}(\mathbb{R}) \supseteq \mathbb{R}$, but I don't see why they must be equal. Second: In this case $\tilde{\varphi}(\mathbb{R})=\mathbb{R} \Longrightarrow \tilde{\varphi}$ is an FLT . In trying to show this, I've considered pre- and post-composing $\tilde{\varphi}$ with a map taking the UHP to the disk. Then the composition is analytic, takes the disk to the disk and preserves $S^1$. If I knew it were bijective, I could show that it is of the form $$e^{i\theta}\frac{z-a}{1-\bar{a}z},$$ but not knowing that it is bijective, I'm unsure of what to do.","['conformal-geometry', 'complex-analysis']"
593625,Inverse of diagonalizable matrix is diagonalizable,"Let $A \in M_n(\mathbb C)$ be invertible. Prove that $A$ is diagonalizable if and only if $A^{-1}$ is diagonalizable. This is what I have for one direction of the proof:
Suppose $A$ is diagonalizable. 
Then there exists a diagonal matrix $D \in M_n(\mathbb C)$ and an invertible matrix $S \in M_n(\mathbb C)$ such that $A=SDS^{-1}$. 
So $$A=SDS^{-1}$$
$$A^{-1}A=A^{-1}SDS^{-1}$$
$$I_n=A^{-1}SDS^{-1}$$
$$S=A^{-1}SD$$
$$*SD^{-1}=A^{-1}S*$$
$$SD^{-1}S^{-1}=A^{-1}$$ In my deduction above, I assumed that $D$ is invertible. I know this is the case. $D$ is the diagonal matrix with entries that are just the eigenvalues of $A$. Since $A$ is invertible, $\lambda \neq 0$, so $det(D) \neq 0$ and therefore $D$ is invertible. But how can I show that the entries of $D$ are just the eigenvalues of $A$? I already proved that for an invertible matrix $A$, $\lambda$ is an eigenvalue of $A$ if and only if $1/ \lambda$ is an eigenvalue of $A^{-1}$. Can I use this to somehow prove that the entries in $D$ are the eigenvalues of $A$?","['matrices', 'linear-algebra', 'inverse', 'eigenvalues-eigenvectors']"
593645,Show that $\frac1{\sqrt{(n+\frac12) \pi}} \le\frac{1\cdot 3\cdot 5 ... (2n-1)}{2\cdot 4\cdot 6 ... (2n)} \le \frac1{\sqrt{n \pi}} $,"Show that,
if $n$ is a positive integer,
$$\frac1{\sqrt{(n+\frac12) \pi}}
\le\frac{1\cdot 3\cdot 5 ... (2n-1)}{2\cdot 4\cdot 6 ... (2n)}
\le \frac1{\sqrt{n \pi}} .
$$ This result is in a current issue
of a MAA magazine,
and I thought it would be interesting to see
how many proofs could be found. I know it may be a duplicate,
but none were suggested when I entered it.","['gamma-function', 'inequality', 'combinatorics']"
593669,How to minimize $|z_1 - z_2|^2 + |z_1 - z_4|^2 + |z_2 - z_3|^2 + |z_3 - z_4|^2$?,"If $z_1,z_2,z_3,z_4 \in \mathbb{C}$ satisfy $z_1 + z_2 + z_3 + z_4  =
 0$ and $|z_1|^2 + |z_2|^2 + |z_3|^2 + |z_4|^2 = 1$, then the least value of $|z_1 - z_2|^2 + |z_1 - z_4|^2 + |z_2 - z_3|^2 + |z_3 -
 z_4|^2$ is $2$. I solved this by taking two of the values to be $\frac{1}{2}$ and other two as $-\frac{1}{2}$. But I couldn't prove this in an efficient manner.","['recreational-mathematics', 'complex-analysis', 'combinatorics']"
593670,Proving number of digits d to represent integer n in base B?,"I am interested in learning about proofs for discrete mathematics. One recurring fact I find in the literature is that the number of digits $d$ required to represent integer $N$ in base $B$ is  $\log_B{n}$ I am unhappy with this on two fronts. The first is that no source I have come across actually proves this claim. The second, I do not think the claim is true, and I am trying to prove this in a few ways but am finding slightly different results. If we have a $d$ digit string in base $B$, this is an element of the set $\{0,1,\dots,B-1\}^{d}$ which has $B^d$ elements. This means we can represent exactly $0,1,\dots,B^{d}-1$ using $d$ digits; solving for $N$ gives $d=\lceil \log_B{(N+1)}\rceil$. An alternative way to see this is that the largest integer we can represent is $\sum_{i=0}^{d-1}(B-1)*B^i$, which is also $B^d-1$ and gives the same result. Why then, do sources describe this as $\log_B(n)$? An alternative representation that is equally confusing is $\lfloor\log_BN\rfloor+1$; this requires a proof that $$\lfloor\log_BN\rfloor+1 = \lceil \log_B{(N+1)}\rceil$$ which I cannot seem to resolve; unless I am on the wrong track entirely.","['discrete-mathematics', 'logarithms', 'elementary-number-theory', 'number-systems', 'decimal-expansion']"
593701,"If $f\in L^1(\mathbb{R})$ is such that $\int_{\mathbb{R}}f\phi=0$ for all continuous compactly supported $\phi$, then $f\equiv 0$.","I am wondering about a proof of the fact that If $f\in L^1(\mathbb{R})$ is such that $\int_{\mathbb{R}}f\phi=0$ for all continuous compactly supported $\phi$, then $f\equiv 0$. I am familiar with the proof given here http://www.academia.edu/740170/An_Introduction_to_Weak_Derivatives on page 4, but I am wondering if there is another proof using density. Basically something like take a sequence of $\phi_n\in C_c({\mathbb{R}}$) such that $\phi_n\to f$ in $L^1$, then $\displaystyle0=\int_\mathbb{R} f\phi_n\to\int_{\mathbb{R}}f^2$, hence $f=0$ a.e. But I need to justify this last limit. If $f$ is bounded it is fine, since $\displaystyle|\int_\mathbb{R} f\phi_n-f^2|\le\int_\mathbb{R} |f||\phi_n-f|\le\|f\|_{\infty}\int_\mathbb{R}|\phi_n-f|\to 0$. I am having trouble doing it without the assumption that $f$ is bounded though.","['measure-theory', 'distribution-theory']"
593715,Convergence in mean,"This is a very basic question, however, I can't find a definitive answer for it. Let $(X_n)$ be a sequence of random variables.  Suppose that the limit of expectation of this sequence $\lim_{n\rightarrow\infty}\mathbb{E}[X_n]=\mu$.  Does that imply that $(X_n)$ converges to $\mu$ in mean, i.e., that $\lim_{n\rightarrow\infty}\mathbb{E}[|X_n-\mu|]=0$? Intuitively it seems so (by the identity of indiscernibles), but I've learned to be careful with absolute values of random variables, so hence the question to the community...","['probability-theory', 'convergence-divergence']"
593737,Some Scaling Estimate for Heat Kernel,"NOTE. I have rewritten the question to summarize my current progress on this question.  The bounty is for completing what I have done so far, or by offering a more elegant solution probably based on some clever scaling/translation argument.  I have also slightly (I hope) clarified the wording in (b). Let $$G(x,t)=\frac{1}{(4\pi t)^{\frac{d}{2}}}e^{-\frac{|x|^{2}}{4t}}.$$ be the usual heat kernel. (a) Given $\alpha>0$ find constants $\beta$ and $C$ so that
$$G(x+y,t)\leq CG(x,\beta t)$$
holds for every $x\in\mathbb{R}^{d}$, $t>0$ and $|y|\leq\alpha\sqrt{t}.$} (b) Deduce that for $f\in L^{1}$, $\lambda>0$, and $u(x,t)=(G(t,\cdot)*f)(x)$, that
$$\mu\left(\left\{y:\text{s.t.}\;\exists t>0\;\text{whereby the estimate}|u(x,t)|\geq\lambda\;\text{holds whenever}\;x\in B(y,\alpha\sqrt{t})\right\}\right)\leq\frac{||f||_{L^{1}}}{\lambda}.$$ Let us for now assume $d=1$ so
$$G(x,t)=(4\pi t)^{-1/2}\exp\left(\frac{-x^{2}}{4t}\right).$$ After fixing $x\in\mathbb{R}$, $t>0$, $\alpha>0,$ and restricting $|y|\leq\alpha\sqrt{t},$ we are tasked to prove the estimate
$$(4\pi t)^{-1/2}\exp\left(\frac{-|x+y|^{2}}{4t}\right)\leq C(4\pi\beta t)^{-1/2}\exp\left(\frac{-|x|^{2}}{4\beta t}\right),$$
for constants $\beta=\beta(\alpha)>0$ and $C=C(\alpha)>0.$  Cancelling the factor $(4\pi t)^{-1/2}$ from both sides reduces the estimate to
$$\exp\left(\frac{-|x+y|^{2}}{4t}\right)\leq C\beta^{-1/2}\exp\left(\frac{-|x|^{2}}{4\beta t}\right).$$
Since we can multiply $C$ by $\beta^{1/2}$, we can absorb the factor $\beta^{-1/2}$ into $C$.  The estimate then further reduces to
$$\exp\left(\frac{-|x+y|^{2}}{4t}\right)\leq C\exp\left(\frac{-|x|^{2}}{4\beta t}\right).$$
Since $1/(4t)$ appears in both exponentials in a symmetric way, we can also ``cancel'' them to finally get
$$\exp\left(-|x+y|^{2}\right) \leq C\exp\left(-|x|^{2}/\beta\right).$$
Let us maximize the left hand side subject to the constraint $|y|\leq\alpha\sqrt{t}$, for clearly the validity of the resulting estimate will imply the present one.  The left hand side is maximized when $y=-x$, and this is valid if $|x|\leq\alpha\sqrt{t}$.  However, if $|x|>\alpha\sqrt{t}$, then $y=-\text{sgn}(x)\alpha\sqrt{t}$ is the best that can be done.   Thus we get the system of inequalities
$$\left\{\begin{array}{ll}
1\leq C\exp\left(-|x|^{2}/\beta\right)&\text{if}\;|x|\leq\alpha\sqrt{t},\\
\exp\left(-|x-\text{sgn}(x)\alpha\sqrt{t}|\right)\leq C\exp\left(-|x|^{2}/\beta\right)&\text{if}\;|x|>\alpha\sqrt{t}.\end{array}\right.$$ At this point I get the sense that I am going in the wrong direction, especially since we need to solve for $\beta$ and $C$ independently of $x$ and $t$.  Perhaps I should have kept the $1/(4t)$ factor in the exponentials.  Even when I did this separately, I still ended up with a similar set of inequalities with know obvious way to get rid $x$ and $t$ in them. Any help extending this argument, or providing a more elegant alternative would be highly welcomed. As for (b), the wording and all of the parameters involved still confuses me.  However, I can at least start by writing out $u(x,t)$ as
$$u(x,t)=\int_{-\infty}^{\infty}(4\pi t)^{-1/2}\exp\left(\frac{-|x-y|^{2}}{4t}\right)f(y)\;dy.$$
The appearance of the $|x-y|$ in the convolution already suggests (a) will be helpful.  Since $G(x,t)\in L^{1}$ for every $t>0$ and $f\in L^{1}$ by assumption, we see $u\in L^{1}$ for every $t>0$.  Thus $f$ satisfies the weak-type estimate (special case of Chebyshev inequality)
$$\mu\left(\{x:|u(x,t)|>\lambda\}\right)\leq\frac{||f||_{1}}{\lambda}.$$
The key then seems to be relating the above set with the one in (b).","['ordinary-differential-equations', 'partial-differential-equations', 'real-analysis', 'analysis']"
593746,Does ergodicity imply stationarity?,"In general, if a random process is ergodic, does it imply that it is also stationary in any sense?","['probability-theory', 'probability']"
593753,Is a diagonal matrix diagonalizable?,"A matrix $A$ is a diagonalizable if there exists a diagonal matrix $D$ such that $A$ is similar to $D$. If $A$ is a diagonal matrix, though, is it diagonalizable? If so, it would seem $D$ would just be $A$. I suppose my real question is if it is even proper to ask if a diagonal matrix is diagonalizable. (I am writing a proof, and I want to be as correct as possible.)",['linear-algebra']
593774,Corestriction map in lie algebra cohomology,"Given a lie algebra $\mathfrak{g}$ over a field $k$, we can define the cohomology groups of $\mathfrak{g}$ as follows: $$H^n(\mathfrak{g},k):=\mathrm{Ext}_{U(\mathfrak{g})}^n(k,k)$$ where $U(\mathfrak{g})$ is the universal enveloping algebra of $\mathfrak{g}$, and $k$ is the trivial $U(\mathfrak{g})$-module.  There is a cup product on $H^*(\mathfrak{g})=\oplus H^n(\mathfrak{g},k)$ which gives it the structure of a graded commutative ring.  By functoriality, a map of lie algebras $\mathfrak{h}\hookrightarrow\mathfrak{g}$ induces a ring map on cohomology $H^*(\mathfrak{g})\to H^*(\mathfrak{h})$, which we call the restriction map. For a group $G$, we may replace $U(\mathfrak{g})$ with $kG$, the group algebra, to obtain group cohomology, and again, a map of groups $H\hookrightarrow G$ induces a ring map on cohomology $H^*(G)\to H^*(H)$.  However, in the case that $(G:H)<\infty$, we also obtain a corestriction map $H^*(H)\to H^*(G)$.  Corestriction is the composition $$H^n(H,k)\to H^n(G,kG\otimes_{kH}k)\to H^n(G,k)$$ where the first map is from Shapiro's lemma (this is where we use the finite index condition, so that the induced and coinduced modules are isomorphic), and the second map is induced by the $kG$-module map $g\otimes a\mapsto ga=a$. I've heard that there is no corestriction map in the lie algebra setting.  Is this true?  If so, what is the obstruction in trying to define such a map?","['lie-algebras', 'homology-cohomology', 'abstract-algebra', 'group-cohomology', 'lie-algebra-cohomology']"
593780,What is a good example to show high school students why a proof for induction is a reasonable kind of proof?,"I teach average-level high school students who have not had much beyond Algebra 1. I want to show them why induction makes sense. I want the sort of problem where it is intuitive that a statement is true for n=3 provided it is true for n=2, etc. All the ones in the textbooks I find involve proving conjectures that I feel one would not discover by looking at n=1, then n=2, then n=3, etc, or they are too hard/abstract for my students, or it is not immediately clear why one would think to do an inductive proof on them (e.g. the typical summation problems). I'm thinking about say, you are reading a textbook, and it says something like ""and clearly that follows by induction""....so, the kind of theorem that naturally makes you think of an inductive proof. I found one that I like, which is the following: Proving that $n!\geq 2^n$ for $n\geq 4$. I like this one because we can see it is true for 4, that is, we know that $$4\cdot3\cdot 2\cdot 1\geq 2\cdot 2\cdot 2 \cdot 2$$ and so then because $5\geq 2$, it follows from a preservation property of inequalities that 
$$5\cdot 4\cdot 3\cdot 2\cdot 1\geq 2\cdot 2\cdot 2\cdot 2\cdot 2$$ With this sort of example, the students can see why a proof by induction makes sense: we just keep using previous knowledge. We look at the case for $n=4$ and see it works, and then almost immediately from that we see that it works for $n=5$, etc. The problem with this example is that is starts at $n=4$. I want something that starts at $n=1$ as the first induction example I give them, and I don't just want to do $$(n+4)!\geq 2^{n+4},$$ because I think that would confuse them more. Any ideas? I have been to this question: Examples of mathematical induction but it did not help, as I needed a much simpler example for my students.","['induction', 'education', 'algebra-precalculus']"
593794,Minors of a positive definite matrix are positive definite,"All main minors of a positive definite matrix are positive definite as
  well and therefore $A$ is  strictly invertible. All I know about positive-definiteness is that for the symmetric matrix $A$ the following inequality holds: $$x^TAx>0, \forall x(\neq 0) \in \mathbb R^3$$ Could you please give me some hints as to how can I prove the above theorem, specially its second part, what does  positive-definiteness have to do with being invertible?","['matrices', 'linear-algebra']"
593818,Find $x$ for $\left(\frac1{1\times101} + \frac1{2\times102} + \dots +\frac1{10\times110}\right)x = \frac1{1\times11} + \frac1{2\times12}...$,"$$\left(\frac1{1\times101} + \frac1{2\times102} + \dots +\frac1{10\times110}\right)x = \frac1{1\times11} + \frac1{2\times12} + \dots +\frac1{100\times110}$$ Find x My younger sister in grade 5 had this question in a test. But I, a college student, still can't solve this. What a shame :<",['algebra-precalculus']
593821,prove the existence of a measure $\mu$,"Suppose $X$ and $Y$ are compact metric spaces and $F : X \rightarrow Y$ is a continuous map from $X$ onto $Y$. If $\nu$ is a finite measure on the Borel sets of $Y$, prove that there exists a measure $\mu$ on the Borel sets of $X$ such that $$
\int_{Y} f d\nu = \int_{X}f \circ F d \mu
$$
for all $f$ that are continuous on $Y$. This is pretty hard to show the existstence of $\mu$ for me (Even for my TA). Currently I am in the chapter of Riesz Representation. Can anybody give me some hints?","['measure-theory', 'functional-analysis', 'real-analysis']"
593824,$\int_0^\pi\int_0^\infty e^{-xy}\sin kx~dy~dx=$ ?,"$$\int_0^\pi\int_0^\infty e^{-xy}\sin kx~dy~dx=~?$$
My computation is $$\int_0^\infty e^{-xy}\sin kx~dx=\frac{1}{k+y^2}$$ so $$\int_0^\pi\frac{1}{k+y^2}dy=\frac{\sqrt{k}}{k}\arctan\pi$$ $$\int_0^\pi\int_0^\infty e^{-xy}\sin kx~dy~dx=\frac{\sqrt{k}}{k}\arctan\pi$$ Is my result wrong?","['definite-integrals', 'multivariable-calculus', 'improper-integrals', 'integration']"
593835,An exercise in Silverman,"This is self-learning, not homework. Problem: Let $A, B \in \bar{\mathbb{K}}$. Characterize the values of $A, B$ for which each of the following varieties is singular. In particular, as $(A,B)$ ranges over $\mathbb{A}^2$, the ""singular values"" lie on a one-dimensional subset of $\mathbb{A}^2$, so ""most"" values of $(A,B)$ give a non-singular variety. ($\mathbb{K}$ is a field, $\mathbb{A}^2$ is affine 2-space, etc.) $(a) V: Y^2Z + AXYZ + BYZ^2 = X^3$.
$(b) V: Y^2Z = X^3 + AXZ^2 + BZ^3$ (char $\mathbb{K} \neq 2$). My attempt: We need to find $(A,B)$ so that the polies defining these varieties have derivatives (with respect to each variable) which have roots in $\mathbb{K}$, i.e. we need to solve the systems of equations $(a) 2YZ + AXZ + BZ^2 = Y^2 + AXY + 2BYZ = 3 X^2 - AYZ = 0$
$(b) 2YZ = 3X^2 + AZ^2 = 2AXZ + 3BZ^2 - Y^2 = 0$ for $A$ and $B$. Silverman gives the solutions $(a) B(A^3 - 27B) = 0$ and $(b) 4A^3 + 27B^2 = 0$. This is probably just embarrassingly basic highschool algebra but I'm not seeing it.",['algebraic-geometry']
593840,Why do odd dimensions and even dimensions behave differently?,"It is well known that odd and even dimensions work differently. Waves propagation in odd dimensions is unlike propagation in even dimensions. A parity operator is a rotation in even dimensions, but cannot be represented as a rotation in odd dimensions. Even dimensional spheres do not admit continuous nonvanishing vector fields , but odd dimensional spheres do. Is there some unifying reason for these differences? Why is dimensional parity so important? (If you know of any more interesting differences, please leave a comment and I will add them to the list.)","['quantum-mechanics', 'partial-differential-equations', 'differential-geometry']"
593857,Counterexample for the Open Mapping Theorem,"I would like to ask a counterexample for the open mapping theorem: Find a discontinuous linear mapping $T:X \to Y$ such that $T(X)=Y$ and $X,\;Y$ are Banach but $T$ is not open. Could you help me with this problem?
Thanks!","['examples-counterexamples', 'functional-analysis']"
593863,"Haar measure, convolution and involutions","I have some problems to follow the proof of the anti commutativity property of the convolution and involution operations defined using a Haar measure as presented in Pedersen's book Analysis Now , chapter 6 section 6, theorem 6.6.21.
To explain the problem I need to recall the definition he makes: Given $G$ locally compact Hausdorff group, let $C_c(G)$ be the family of continuous functions from $G$ to $\mathbb{C}$ with compact support. A Radon integral
$\int: C_c(G)\to\mathbb{C}$ defines an Haar measure if it is a linear continuous map which maps positive functions on positive real numbers and is left invariant
(i.e$\int f_y=\int f$ for all $y\in G$ where $f_y(x)=f(y^{-1}\cdot x)$). The modulus function $\Delta :G\to\mathbb{R}$ is the unique group homomorphism defined by the request that
$\Delta(x)\int f(yx)d y=\int f(y)dy$ for all $x\in G$ and $f\in C_c(G)$. The convolution of $f$ and $g$ is defined by: $f\times g(x)=\int f(y)g_y(x)dy$. The involution is defined by: $f^*(x)=\overline{f(x^{-1})}\cdot \Delta(x^{-1})$. Theorem 6.6.21 states (among other identities which are less problematic to me): $(g^*\times f^*)=(f\times g)^*$. The proof of this identity is as follows: $(g^*\times f^*)(x)=$ $=\int g^*(y)f^*(y^{-1}x)dy=$ $=\int \overline{f(x^{-1}y)}\Delta(x^{-1}y)\overline{g(y^{-1})}\Delta(y^{-1})dy=$ $=\int \overline{f(x^{-1}y)}\overline{g(y^{-1})}dy\Delta(x^{-1})=$ $=\int \overline{f(y)}\overline{g(y^{-1}x^{-1})}dy\Delta(x^{-1})=$ $=\overline{\int f(y)g(y^{-1}x^{-1})dy}\Delta(x^{-1})=$ $=(f\times g)^*(x)$. I can't really understand how is it justified the passage from (4) to (5).
Can someone help me? Thanks.","['convolution', 'topological-groups', 'measure-theory', 'functional-analysis', 'locally-compact-groups']"
593875,Relative spectrum of a quasi-coherent algebra.,"I'm working out the notion of spectrum of a quasi-coherent algebra over a scheme. $\require{AMScd}$
Let $(X,\mathcal O_X)$ be a scheme and $\mathcal A$ a quasi-coherent $\mathcal O_X$-algebra, i.e. a sheaf of ring $\mathcal A$ together with a morphism $\mathcal O_X \to \mathcal A$ making it a quasi-coherent $\mathcal O_X$-module. Then from the previous morphism, for every affine open subset $U$ of $X$, we have
$$ \mathrm{Spec}\,(\mathcal A(U)) \to U.$$
Taking another affine open subset $V$ of $X$ such that $V \subseteq U$, the diagram
$$\begin{CD}
  @. V \\
 @. @VVV \\
\mathrm{Spec}\,(\mathcal A(U)) @>>> U
\end{CD}$$
admit the limit $\mathrm{Spec}\,(\mathcal A(U)) \times_U V \simeq \mathrm{Spec}\,(\mathcal A (U) \otimes_{\mathcal O_X (U)} \mathcal O_X(V)) = \mathrm{Spec}\,(\mathcal A(V))$, the last equality because of the quasi-coherence of $\mathcal A$. So the arrow $\mathrm{Spec}\,(\mathcal A(V)) \to \mathrm{Spec}\,(\mathcal A(U))$ is an open immersion and we can define the relative spectrum as the glueing
$$ \mathrm{Spec}\,\mathcal A := \mathrm{colim}_{\mathcal I}\,\mathrm{Spec}\,(\mathcal A(-))$$
where $\mathcal I$ is the opposite category of affine open subset of $X$. Then , it is said in my notes that for all affine open subset $U$ of $X$, one have
$$ \boxed{\mathrm{Spec}\,(\mathcal A(U)) = \mathrm{Spec}\,\mathcal A \times_X U,}$$
which I can't see.
Obviously, the map $\mathrm{Spec}\,\mathcal A \to X$ being defined by the universal property of colimits on the maps $\mathrm{Spec}\,(\mathcal A(U)) \to U \to X$, we have a commutative square
$$\begin{CD}
\mathrm{Spec}\,(\mathcal A(U)) @>>> U \\
@VVV @VVV \\
\mathrm{Spec}\,\mathcal A @>>> X.
\end{CD}$$
However, I don't see why it is cartesian...","['quasicoherent-sheaves', 'algebraic-geometry', 'schemes']"
593894,How to prove this matrix inequality $\det(A+B)\ge 2^n\sqrt{\det(A)\det(B)}$,"Question: Let $A_{n\times n}$ and $B_{n\times n}$ be positive Hermitian matrices. Show that $$\det(A+B)\ge 2^n\sqrt{\det(A)\det(B)}.$$ I know that $$\det(A+B)\ge \det(A)+\det(B)$$ But my problem is that I can't,(maybe this is an old reslut,and also I can't find it), Thank you very much!","['matrices', 'linear-algebra', 'inequality']"
593900,characterization of the operation on a finite or infinite group.,"Suppose $G$ is a group which is a group again with another operation $*$. For each $a,b\in G$ with $a\ne b$ we have:
$$ab=a*b$$
Can always the condition $a\ne b$ be dropped?",['group-theory']
593950,What are the length of the longest element in a Coexter group for every type?,What are the length of the longest element in a Coxeter group for every type? Thank you very much.,"['lie-groups', 'group-theory']"
593996,How to prove $\sum_{n=0}^{\infty} \frac{n^2}{2^n} = 6$?,"I'd like to find out why \begin{align}
\sum_{n=0}^{\infty} \frac{n^2}{2^n} = 6
\end{align} I tried to rewrite it into a geometric series \begin{align}
\sum_{n=0}^{\infty} \frac{n^2}{2^n} = \sum_{n=0}^{\infty} \Big(\frac{1}{2}\Big)^nn^2
\end{align} But I don't know what to do with the $n^2$.","['sequences-and-series', 'calculus', 'real-analysis', 'analysis']"
594004,How to find other solutions to this vectorproblem?,"Suppose I have a vector field $\mathbf{A}(x,y,z)$, of which I know: $$ \mathbf{A}(x,y,0)=(1+\alpha x)\hat{z}$$
Thus, I know the value of $\mathbf{A}$ in the $xy$-plane. Say, within $|x|,|y|\leq\frac{1}{2}$. Furthermore, I have the following requirements for $\mathbf{A}$. $$\nabla\cdot\mathbf{A}=0, \\ \nabla\times\mathbf{A}=0,$$
which have to be satisfied in $|x|,|y|,|z|\leq{\frac{1}{2}}$. I want to find the vector field $\mathbf{A}$ that satisfy all of the above conditions, at least for the given boundaries, but for larger (infinite?), domains as possible. I did find the following solution, but, with some rather crude assumptions, so I wonder if there are any other approaches to solve the problem. Assumption 1: There is no $y$-dependency. Assumption 2: $\displaystyle\frac{d\mathbf{A}_x}{dx}=0$. Under these assumptions, one can easily obtain from the curl-requirement, that $$\mathbf{A}=\alpha z\hat{x}+(1+\alpha x)\hat{z}$$ But, is this the only one? I am especially interested in other solutions which do no show $y$-dependency, and, even more interested if there is a solution $\displaystyle\lim_{z\to\infty}\mathbf{A}_x<\infty$. A proof that the solution that I obtained straightforwardly is the only one obviously also counts as an answer.","['multivariable-calculus', 'ordinary-differential-equations']"
594025,How to prove The following sentences?,"let $\{f,f_{n}:n\ge 1\}$ be $\mathbb R$-valued measurable function on $(\Omega,\mathcal A,\mu)$ (a) Assume that $f_{n}\uparrow f$ and that there exist an $(\mathcal A,\mathcal B_{\mathbb R})$ measurable function such that $\int h d\mu< \infty  $   and $f_{n}\ge h\quad  \forall n$. Then Show that $\int f_{n} d\mu\uparrow \int f d\mu$. (b) show by counter example that the above hypothesis cannot be dropped. thanks for help","['measure-theory', 'integration', 'real-analysis']"
594079,Software for generating Cayley graphs of $\mathbb Z_n$?,"Does it exist any program (for linux) which can generate a nice Cayley graph of any $\mathbb Z_n$? (If it's possible to create such a graph at all, that is.) (where perhaps $n ≤ 100$ or something like that)","['cayley-graphs', 'graph-theory', 'soft-question', 'math-software', 'group-theory']"
594081,Existence of a subgroup with order 3 in a group with order 6,Let $G$ be a group of order 6. Why does $G$ has a subgroup of order 3 even if $G$ isn't cyclic? I've tried using to use negation and assume all elements in $G$ have an order of 2 or 1 but I can't contradict with that (without sylow or cauchy theorem.),"['finite-groups', 'group-theory', 'abstract-algebra']"
594099,"What does ""$f(x,y)$ is strictly increasing in each argument"" imply?","Say we have a function $f(x,y)$. below are what we know about $f(x,y)$ strictly increasing in each argument . $x$ and $y$ are natural numbers only, i.e., $0, 1, 2, ...$ Now we have a fixed number $z$ which is also a natural number and we want to find out all values of $x$ and $y$ which satisfy $f(x,y)=z$. My question: Is $x \leq z,$ $y \leq z$ implied from the above two conditions? and Why? Is $f(x,y) \geq x + y$ implied also? and Why?","['calculus', 'algebra-precalculus', 'functions']"
594108,"If $(A-2I)^3(A+2I)^2=0$, then what are the possible Jordan canonical forms of $A$?","Here is the exercise: Let $A$ be a $5\times5$ complex matrix such that $(A-2)^3(A+2)^2=0$, where we define $A-\mu:=A-\mu I$ for scalar $\mu$. Assume that $\lambda=2$ is an eigenvalue of $A$ and its geometric multiplicity is at least $2$. What are the possibilities for the Jordan canonical form (JCF)? What I know so far from the assumption is that the minimal polynomial of $A$ is of the form $f(x)=(x-2)^i(x+2)^j$ where $1\leq i\leq 3$ and $0\leq j\leq 2$. The number of blocks in the Jordan segment $J(2)$ is at least $2$. One can write the possible minimal polynomial one by one, which gives the information of the size of the largest block in each Jordan segment, and use the possible geometric multiplicity of $\lambda=2$ to find JCF. Here are my questions: Is there an alternative approach? Can we use the characteristic polynomial of $A$ here?","['jordan-normal-form', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
594135,"Prove $a^\alpha b^{1-\alpha} \le \alpha a + (1 - \alpha)b, \; a,b > 0,\; 0 < \alpha < 1$","I have no idea how to do this. Any help would be appreciated. The chapter I'm on is about differentiation and the mean value theorem. Prove $a^\alpha b^{1-\alpha} \le \alpha a + (1 - \alpha)b, \; a,b > 0,\; 0 < \alpha < 1$","['inequality', 'real-analysis', 'analysis']"
594137,Elementary set theory - show a function is surjective,"A question from my homework im currently trying to solve and can use a push in the right direction. Definition : let $F(X)$ be the set of all functions from $X$ to $\mathbb R$ Let $\phi: A \to B$  a function from set $A$ to set $B$, and let $\psi:F(B) \to F(A)$ be a function from $F(B)$ to $F(A)$ defined by: for all $f \in F(B)$, $\psi(f)=f \circ \phi$ Show that: 1) if $\phi$ is injective, then $\psi$ is surjective. Meaning for all $f_A \in F(A)$ there is an $f_B \in F(B)$ such that $\psi(f_B)=f_A$","['elementary-set-theory', 'functions']"
594154,$\lim_{h\rightarrow 0} \dfrac {e^{f(z+h)}-e^{f(z)}}{f(z+h)- f(z)}$,"given that $V$ is an open subset of $\mathbb{C}$ and $z \in V$, calculate $\lim_{h\rightarrow 0} \dfrac  {e^{f(z+h)}-e^{f(z)}}{f(z+h)- f(z)}$, if $f$ is known to be a continuous complex function in $V$. I know that the result is supposed to be  $e^{f(z)}$, but I can't figure out the details in a rigorous way. Any help appreciated and many thanks in advance.",['complex-analysis']
594167,"If $\lim_{h\to 0} \frac{f(x_0 + h) - f(x_0 - h)}{2h} = f'(x_0)$ exists, is f differentiable at $x_0$?","I'm not too sure where to start. Any help will be appreciated. If $\lim_{h\to 0} \frac{f(x_0 + h) - f(x_0 - h)}{2h} = f'(x_0)$ exists, is f differentiable at $x_0$?","['derivatives', 'real-analysis', 'analysis']"
594173,"Weak solution $u(x,t)$ of heat equation converges as $t \in \infty$","Where can I find a proof that the weak solution $u \in L^2(0,T;H^1) \cap H^1(0,T;H^{-1})$ of the heat equation
$$u_t -\Delta u = f$$
converges as $t \to \infty$ to the solution of the elliptic PDE
$$-\Delta u = f$$
?? Any references greatly appreciated.","['sobolev-spaces', 'heat-equation', 'functional-analysis', 'partial-differential-equations']"
594181,Notation for unordered product of sets,"Frequently, when referring to the edges of an undirected graph $G=(V,E)$, I want to write that $E \subset V \times V$, which isn't correct since the Cartesian product is ordered and the edges are not. This motivates my question: is there a common notation for a product of sets $A$ and $B$ defined by $\{ \{a,b\} ~|~ a \in A ,~ b \in B \}$?","['notation', 'elementary-set-theory']"
594222,"Give an example of a uniformly continuous function $f$ on $[0, 1]$ that is differentiable on $(0, 1)$ but for which $f'$ is not bounded on $(0, 1)$","Any help would be appreciated! Would $f(x) = \sqrt(x)$ work? Give an example of a uniformly continuous function $f$ on $[0, 1]$ that is differentiable on $(0, 1)$ but for which $f'$ is not bounded on $(0, 1)$","['continuity', 'real-analysis', 'analysis']"
594228,Proof that $n^3-n$ is a multiple of $3$. [duplicate],"This question already has answers here : Using induction prove $n^3-n$ is divisible by 3 whenever n is a positive number. (6 answers) Closed 10 years ago . I'm struggling with this problem of proof by induction: For any natural number $n$, prove that $n^3-n$ is a multiple of $3$. I assumed that $k^3-k=3r$ I want to show that $(k+1)^3-(K+1)=3r$ The final statement is $K^3 +3K^2+2K$ Am I missing something ?","['arithmetic', 'algebra-precalculus', 'divisibility', 'induction']"
594270,Lie-brackets and solution space of PDE,"I have a linear, first-order homogeneous PDE system with polynomial coefficients $$L_j\, f =0,\text{ for } j=1,..,J\quad \text{ where } L_j \text{ is a first order, diff. operator with polynomial coeff.}$$ so any constant function always solves it. I want to find whether in a neighborhood of a point p , all solutions are constant or not. We compute the Lie-brackets, $L_{ij}=[L_i,L_j]$, and since $L_{ij}\,f =0$ provided $f$ is a solution of the original system, I can think of $L_{ij}$ as a vector field in the tangent bundle of $f$. If we get the minimal module of linear operators that contains the $L_i$ and is ""closed"" under Lie-bracket, evaluate them at p , and the compute the dimension of the corresponding vector space (which is a subspace of the tangent space of a solution at p ) we have that: All solutions are constant at p if and only if the space described above has maximal dimension. Is this true? I think this statement is correct, if not please let me know.","['algebraic-geometry', 'lie-algebras', 'partial-differential-equations']"
594300,Why is $x\log(x)$ convex?,"Why is $x\log(x)$ convex? According to the definition it must hold: $(tx+(1-t)y)\log(tx+(1-t)y)\le tx\log(x)+(1-t)y\log(y)$ for all positive $x,y$ and $t\in[0,1]$ edit: It is allowed to derive, but i have to prove using the definition.","['logarithms', 'inequality', 'real-analysis']"
594328,How to prove or disprove statements about sets,"Prove or disprove: The set: $\{ \emptyset\}^{\Bbb N}$ has only one element. The set $\emptyset^{\Bbb N}$ is empty. I'm pretty sure both are true, for 1. all the natural numbers go to the empty set and that is the only element. Where as 2. all the natural numbers go to nothing so that's why it's empty. (Same as $ {\Bbb N}^{\emptyset} $ nothing goes to something is nothing (I think)). The problem is I have no idea how to show this so advice would be appreciated. Edit:
My defintion of a function is: $f:B\to A$ if $(a_1,b),(a_2,b)\in f \ \Rightarrow \ a_1=a_2$ So for 2. I can simply say that: $(1,\emptyset),(2,\emptyset)\in f \Rightarrow a_1\neq a_2$ ?",['elementary-set-theory']
594350,Integrating $\int_0^\infty \frac{1-\cos x }{x^2}dx$ via contour integral.,"In Stein's Complex Analysis notes, the following exampleis given. They then proceed to calculate the integral over the small semicircle. My question is, why is it necessary to dodge the origin? Afterall, the singularity at $z=0$ is removable?",['complex-analysis']
594367,Relation between Algebraic multiplicities and rank of a matrix,"A is  a 6x6 matrix , 
 $rank(A-3I) = 4$, the minimal polynomial of A is $(x-1)^2(x-3)^2$ I need to write the Jordan matrix options for A. How can I use the given information about the rank, what does it tell me about the eigenvalue 3 and his algebraic multiplicity in the characteristic polynomial? Can someone give me an elaborated explanation how it is connected? thank you","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'polynomials']"
594369,What is the ideal of leading terms?,"Fix a monomial ordering on the polynomial ring $\Bbb{k}[x_1, \dots, x_n] = R$ over a field.  What exactly is $LT(I)$ for an ideal $I$ of $R$?  How is it defined and does it form an ideal?","['commutative-algebra', 'groebner-generators', 'abstract-algebra', 'polynomials']"
594404,Prove $ \mathrm{E}\left[\max_{1≤i≤\infty}|S_i|\right]≤2\sqrt{b} $?,"Suppose $X_1, X_2,\ldots$, are independent r.v.s. with mean $0$ such that: $$ \sum_{n=1}^{\infty}\mathrm{var}(X_i)=b<\infty $$ How can one prove that: $$ \mathrm{E}\left[\max_{1≤i≤\infty}|S_i|\right]≤2\sqrt{b} $$ Borel-Cantelli might be useful right?",['probability-theory']
594407,How many four digit numbers are there?,"Assume that 0 can't be a first digit. I got 9,000. Is that right? Follow up question: How many of those four digit numbers have no repeated digits?","['discrete-mathematics', 'combinatorics']"
594409,Problem in Gauge theory,"[...] one does not yet have a mathematically complete example of a
  quantum gauge theory in four-dimensional space-time, nor even a
  precise definition of quantum gauge theory in four dimensions. Will
  this change in the 21st century? We hope so!  ” —From the Clay Institute's official problem description by Arthur
  Jaffe and Edward Witten. Can you interprete this mathematically to me? I mean why  can't we represent or define precisely "" quantum gauge theory in four-dimensional space-time ""","['gauge-theory', 'abstract-algebra']"
594431,How to approximate $n \int_{0}^{1} [1 - x^m ]^n x^m dx $ near infinity?,"I have a hypothesis that if:
$$ 
I_{n,m} := n \int_{0}^{1} [1 - x^m ]^n x^m dx
$$ where $m,n \in \mathbb{N}$ then 
$$
\lim_{n \rightarrow \infty} \frac{I_{n,m}}{n^{-\frac{1}{m} } } = c_m
$$ But I have no idea how to prove it. For $m = 1$ I can evaluate the integral using integration by parts: $$
\int_{0}^{1} (1 - x)^nx dx = 
\left [- \frac{( 1-x )^{n+1} }{n+1} x \right ]_0^1 - \int_{0}^{1}  -\frac{( 1-x )^{n+1} }{n+1} dx= 
0 + \frac{1}{n+1}  \int_{0}^{1} {(1 - x)}^{n+1} dx =
 \frac{1}{n+1} \left [ -\frac{( 1-x )^{n+2} }{n+2}  \right ]_0^1  =
  \frac{1}{(n+1)(n+2)}
$$ therefore: $$
I_{n,1} = \frac{n}{(n+1)(n+2)}
$$ and this can be approximated by $\frac{1}{n}$ as the hypothesis suggests. But if I try integrating by parts for general $m$ I just transform the integral to an expression containng: $$
\int_{0}^{1} [1 - x^m ]^n  dx
$$ which I do not know how to solve. I really do not know if my hypothesis is true. I would just like to know how does $I_{n,m}$ behave for large values of $n$.","['definite-integrals', 'approximation', 'integration', 'limits']"
594440,Evaluating $\lim_{x \to 0^+} (e^x-1)^{\frac{(\tan{x})^2}{\sqrt[3]{x^2}}}$,"I cannot figure this limit out. $$\lim_{x \to 0^+} (e^x-1)^{\frac{(\tan{x})^2}{\sqrt[3]{x^2}}}$$ I've used the e to the ln trick and multiplied by 1 ($\frac{x^2}{x^2}$) and arrived at $$\lim_{x \to 0^+} \exp({x^{4/3}} \ln ({e^x-1})) $$ However I failed at getting further. I tried adding and subtracting $\ln x$ but that got me nowhere. I cannot use l'Hospital or Taylor series (only the ""known"" limits for $\sin$, $\cos$, $e^x$, $\ln$ such as $\lim_{x \to 0}\frac{sinx}{x}=1$ which are really only Taylor series). Thanks for help!","['calculus', 'real-analysis', 'limits']"
594443,Besicovitch Covering Lemma,"We just finished our unit on covering lemma's in my analysis class and my professor proved both the Vitali and Besicovitch covering lemma's (for finite and infinite coverings) using balls. He mentioned that it was possible to use cubes in place of balls and the proof of how to do this with Vitali seemed pretty easy. I was wondering if anyone had access to a proof of the Besicovitch covering lemma that uses cubes instead of balls and tackles the infinite case. In other words, Given a set $E\subset\mathbb{R}^n$ and a possibly infinite family of cubes $\{Q_{x_i}\}_{{x_i}\in E}$ such that $E\subset \bigcup_{{x_i}\in E}Q_{x_i}$ with $sup_{xi}\rho(Q_{xi})<+\infty$ where $Q=(x,\rho)$ is the cube with center x and side length $\rho$, show that there exists a sub-family of cubes $\{Q_{x_i}\}_{{x_i}\in I}$ such that $E\subset\bigcup_{x_i\in I}Q_{x_i}$ and each point in E lies in at most a finite number of cubes in the sub-family. I have seen a couple of proofs but they all require that E be bounded. Are there any out there for a general E?","['general-topology', 'measure-theory', 'real-analysis']"
594456,Is the Support Vector Classifier in some sense optimal?,"My question is, is the original hard-margin support vector classifier optimal in some sense? If you have an answer that refers to the soft-margin SVC instead, I'd also be interested. I know that the SVC has advantages: – it does not depend on specific distributional assumptions – it deals gracefully and without special tricks with the $p > n$ situation – it produces a solution which is sparse w.r.t. the training data – it integrates naturally with the ""kernel trick"". I know that the SVC performs well in many practical problems. I know that it is possible to derive diverse upper bounds on the generalization error of the SVC. I know that the SVC is based on an optimization process: finding the separating hyperplane with the largest margin. … but I'm unclear about the statistical motivation of the margin maximization approach itself. Of course it makes intuitive sense: First make sure that all training data points are correctly classified (separating hyperplane), then choose the hyperplane that least invites any ambiguity as to how the training data should be classified. But is this more than a plausible heuristic? Is there e.g. a theorem that shows that maximizing the margin leads to the smallest generalization error under some set of assumptions? Hastie et al. write in The Elements of Statistical Learning : Not only does this provide a unique solution to the separating
  hyperplane problem, but by maximizing the margin between the two
  classes on the training data, this leads to better classification
  performance on test data. … The intuition is that a large margin on the training data will lead to
  good separation on the test data. This suggests the ""plausible heuristic"" interpretation. They further write: Vapnik’s structural risk minimization (SRM) approach fits a nested
  sequence of models of increasing VC dimensions $h_1 < h_2 < \cdots$ ,
  and then chooses the model with the smallest value of the upper bound.
  … An example in which the structural risk minimization program can be
  successfully carried out is the support vector classifier … This sounds like that what makes the SVC special is that it can be analyzed by the SRM approach – but not necessarily that it is SRM-optimal, because alternatives cannot be analyzed. Can anyone shed light on this?","['statistics', 'optimization', 'machine-learning']"
594507,Examples of Dedekind rings with infinite class number,"I am looking for explicit examples of Dedekind rings with infinite class number. In most books on algebraic number theory there is a standard example (before or after proving that the class number is finite for the ring of integers in a number field), namely
$$
\mathbb{C}[x,y]/(y^2-x^3-ax-b),
$$
for affine elliptic curves $y^2=x^3+ax+b$, i.e., with $-4a^3-27b^2\neq 0$. Are there other explicit examples, possibly even with a nice proof that the class number is infinite ?","['ring-theory', 'algebraic-number-theory', 'number-theory']"
594529,Is zero vector potential for Helmholtz decomposition of curl and divergence free vector fields necessary?,"Helmholtz's theorem tells us that a sufficiently smooth vector field $\mathbf{A}$ can be decomposed into curl and gradient free parts as the gradient of a scalar potential plus the curl of a vector potential  $$ \mathbf{A} = \nabla \phi + \nabla \times \mathbf{B}$$ Given the constraint that the vector field must be divergence and curl free  $$ \nabla \cdot \mathbf{A} = 0$$  $$ \nabla \times \mathbf{A} = 0$$ this leads to $$\nabla^2 \phi = 0 $$ $$\nabla \times (\nabla \times \mathbf{B}) = 0$$  In application, such as potential flow theroy, it is often taken as a given that $\mathbf{B}=\mathbf{0}$ and $\mathbf{A} = \nabla \phi$.  I can see no reason that this is absolutely required.  Other than simplification, is there a justification for $\mathbf{B}=\mathbf{0}$?  For potential flow theory the choice leads to useful solutions, but is it ignoring a subset of possible solutions? Edit : There are certainly solutions that have non-zero $\mathbf{B}$ that satify the divergence free and curl free constraints.  For instance $$\phi = 0$$ $$\mathbf{B}=\alpha y \hat{i}+\beta x\hat{j}$$  which gives $$\mathbf{A} = \beta-\alpha$$ for constants $\alpha$ and $\beta$.  Any constant vector field satisfies the divergence and curl free constraint.  My intuition is that while $\mathbf{B}=0$ is not necessary, it simply does not add any new unique solution that can't be found by simply satisfying the constraints with $\phi$.","['multivariable-calculus', 'partial-differential-equations']"
594532,"In algebraic geometry, why do we use $\mathbb C$ instead of the algebraic closure of $\mathbb Q$?","In algebraic geometry, why do we use $\mathbb C$ instead of the algebraic closure of $\mathbb Q$? What properties of algebraic varieties use the topological completeness of our field? I'd be interested in hearing either general perspectives or specific results that might fail for $\bar{\mathbb Q}$.","['algebraic-geometry', 'soft-question']"
594546,Korean Math Olympiad 2005 (trapezoid & tangent circles),"In a trapezoid $ABCD$ with $AD||BC$, $O_1$, $O_2$, $O_3$, $O_4$ denote the circles with diameters AB, BC, CD, DA, respectively. Show that there exists a circle with center inside the trapezoid which is tangent to all the four circles O1, O2, O3, O4 if and only if ABCD is a parallelogram. I tried the following: let $AB = CD = 2r_1$, $BC = 2r_2$, $AD = 2r_3$, the circle tangent to $O_1, O_2, O_3, O_4$ has radius $r$, then we can solve: $r=\frac{\sqrt{4r_1^2-(r_2-r_3)^2}-r_2-r_3}{2}$ If $O$ is externally tangent to $O_1$ and $O_3$, then $(r+r_1)^2=OP^2+O_1P^2$. If $O$ is internally tangent to $O_1$ and $O_3$, then $(r_1-r)^2=OP^2+O_1P^2$. Just need to prove that these equations do not hold as long as $r_2 \not= r_3$. But I ran into equations that seems unsolvable.
Is this the correct direction or there are better ways to prove?","['geometry', 'contest-math']"
594576,Write the negation of the following statement (in words):,"""For any field $F$, and any $a\in F$, if $a^3 = 1$ then $a = 1$."" Is this statement TRUE OR FALSE? Is the negation TRUE OR FALSE? Attempt: There is a field $F$ and there is an $a \in F$ such that if $a^3 ≠ 1$ then $a ≠ 1$.","['logic', 'quantifiers', 'discrete-mathematics']"
594581,Approximating $1/z$ by polynomials,"Let $C=\{\mathrm e^{\mathrm it}, 0\le t\le 3\pi/2\}$ and $f(z)=1/z$. By Runge's theorem, there is a sequence of polynomials $p_n(z)$ such that $$\lim_n p_n(z)=f(z)$$ uniformly on $C$. 
Does anyone know such a sequence?","['approximation', 'complex-analysis']"
594624,Ring of rational functions for reducible variety,"Let $X$ be some affine algebraic variety over $\mathbb{k}$ (i.e. some closed subset in $\mathbb{A}_\mathbb{k}^n$). First suppose $X$ to be irreducible. Then the algebra $\mathbb{k}[X]$ is a domain and we can consider the field of rational functions $\mathrm{Quot}_{\mathbb{k}[X]}=\mathbb{k}(X)$. Could you explain me how to build an analogue of this field in the case when $X$ is not necessarily irreducible? Then $\mathbb{k}[X]$ must not be a domain and we are to build some kind of localization? Also, what is the destination of rational functions? Why we cannot be satisfied with only regular maps and regular functions?","['algebraic-geometry', 'definition']"
594641,Computing $\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x$ with residue calculus,"This refers back to $\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x = \frac\pi2$ already posted. How do I arrive at $\frac\pi2$ using the residue theorem ? I'm at the following point: $$\int \frac{e^{iz}}{z} - \int \frac{e^{iz}}{z},$$ and I would appreciate any help.","['residue-calculus', 'improper-integrals', 'integration', 'definite-integrals', 'complex-analysis']"
594661,"True/False: $\mathop {\lim }\limits_{n \to \infty } {{{a_n}} \over {{b_n}}} = 1$ implies $\sum {{a_n},\sum {{b_n}} } $ converge or diverge together.","$$\mathop {\lim }\limits_{n \to \infty } {{{a_n}} \over {{b_n}}} = 1$$
Prove the statement implies $\sum {{a_n},\sum {{b_n}} } $ converge or diverge together. My guess the statement is true. if $\sum{{a_n}}$ diverges, then $\mathop {\lim }\limits_{n \to \infty } {a_n} \ne 0$ So, 
$$\eqalign{
  & \mathop {\lim }\limits_{n \to \infty } {a_n} = L \ne 0  \cr 
  & {{\mathop {\lim }\limits_{n \to \infty } {a_n}} \over {\mathop {\lim }\limits_{n \to \infty } {b_n}}} = 1 \Rightarrow {L \over {\mathop {\lim }\limits_{n \to \infty } {b_n}}} = 1 \Rightarrow L = \mathop {\lim }\limits_{n \to \infty } {b_n} \ne 0 \cr} $$ therefore, 
$\sum {b_n}$ also diverges. What I was not managed to do is proving that the two series converges together. Or maybe the statement is not always true?","['sequences-and-series', 'calculus', 'limits']"
594663,Show $\left|\int_\alpha^\beta F(t) dt\right| \le \int_\alpha^\beta |F(t)| dt$,"Let $F: [\alpha,\beta] \to \mathbb C$ be a continuous function, $F(t) = u(t)+iv(t)$. Define the integral of $F$ over $[\alpha,\beta]$ to be 
  \begin{align*}
\int_\alpha^\beta F(t) dt = \int_\alpha^\beta u(t) dt + i \int_\alpha^\beta v(t) dt.
\end{align*} I was trying to prove the following: Is $F$ continuous on $[\alpha,\beta]$, then
  \begin{align*}
\left|\int_\alpha^\beta F(t) dt\right| \le \int_\alpha^\beta |F(t)| dt.
\end{align*} My (incomplete) solution:
\begin{align*}
\left|\int_\alpha^\beta F(t) dt\right| &= \left|\int_\alpha^\beta u(t)dt + i \int_\alpha^\beta v(t)dt\right|
\le \left|\int_\alpha^\beta u(t)dt\right| + \left|\int_\alpha^\beta v(t)dt\right| \\
&\le \int_\alpha^\beta |u(t)|dt + \int_\alpha^\beta |v(t)|dt
= \int_\alpha^\beta |u(t)| + |v(t)|dt.
\end{align*} The problem: My estimation is already too far. How can I correct this?","['integration', 'complex-analysis']"
594688,"Conformal mapping of disk, surjective, not injective","Is there an example of a conformal mapping of the disk onto itself which is not injective? If not, how may we prove there does not exist such a map? This came up in the answer to this question.","['conformal-geometry', 'complex-analysis']"
594708,"Fermat-quotient of ""order"" 3: I found $68^{112} \equiv 1 \pmod {113^3}$ - are there bigger examples known?","I'm rereading an older text on fermat-quotients (see wikipedia ) from which I have now the Question for
$$ b^{p-1} \equiv 1 \pmod{ p^m} \qquad \text{ with $p \in \mathbb P $, $1 \lt b \lt p$ and $m \gt 2$} $$ 
(This is a generalization of the question for Wieferich primes). Note that I ask here for examples, where the bases $b$ are smaller than the prime $p$, so a very well known weaker case $3^{10} \equiv 1 \pmod {11^2 } $ were an example, but only if the exponent at $11$ where one more; however frequent and well known cases like $18^6 \equiv 1 \pmod {7^3} $ were not because the base is bigger than the prime. The only example that I've found so far is
$$ 68^{112} \equiv 1 \pmod {113^3 } $$
but I've scanned only the first 2000 primes $p \in (3 \ldots 17389)$ and my primitive brute force algorithm has more than quadratic time-characteristic, so checking 10 000 or 100 000 primes were no fun - the quadratic regression prognoses 1 hour for testing 10 000 primes and 101 hours for testing 100 000 primes... I'm aware of a couple of webpages containing lists of fermat quotients up to much higher primes, but either there is no explicite mention of the cases of $b \lt p$ and quotient $m \gt 2$ or I've been too dense when scanning through the listings ( Richard Fischer , Wilfrid Keller , Michael Mossinghoff ) For reference: my Pari/GP-code is for(j=2,2000,p=prime(j);p3=p^3;
    for(k=2,p-1,
        r = lift(Mod(k,p3)^(p-1));
        if(r==1,print(p,"" "",k,"" "",r)));
    ); P.s. I've no real good idea for tagging of this question; I just tried the most similar...","['prime-numbers', 'numerical-methods', 'reference-request', 'number-theory']"
594722,Prove that $e^{-A} = (e^{A})^{-1}$,"Let $A, B \in R^{n \times n}$. Prove that $e^{-A} = (e^{A})^{-1}$. ($R$ is the real numbers) I've tried messing around with both sides, evaluated as sums. I just can't get the two to match up. Any ideas?","['matrices', 'exponential-function']"
594725,"Strictly increasing, absolutely continuous function with vanishing derivative","The following problem comes from Folland's Real Analysis: $A\subset [0,1]$ is a Borel set which has the property that $0<m(A\cap I)<m(I)$ for every interval $I\subset [0,1]$. We define the functions $F(x)=m([0,x]\cap A)$ $G(x)=m([0,x]\cap A)-m([0,x] -A)$ Its fairly straightforward to show $F$ is strictly increasing and absolutely continuous $G$ is absolutely continuous We wish to show that $F'=0$ on some set of positive measure $G$ is not monotone on any interval Any thoughts?",['measure-theory']
594782,2 is a primitive root mod $3^h$ for any positive integer $h$,It's easy to verify that 2 is a primitive root mod $3^2$. But then why does it follow that 2 is a primitive root mod $3^h$ for any positive integer $h$? This was used in the solution of 2009 Putnam B6 http://math.hawaii.edu/home/pdf/putnam/Putnam_2009.pdf I saw this Primitive roots of odd primes but unfortunately I don't have access to the book.,"['contest-math', 'number-theory', 'primitive-roots', 'elementary-number-theory', 'group-theory']"
594809,Embedding of continuous functions into differentiable functions,"This question refers to a solution printed in the current (December 2013, 120 (10)) issue of The American Mathematical Monthly , p. 944.  There, the authors intend to show that any ring homomorphism from the set $C$ of continuous functions R $\to$ R to the set of differentiable functions R $\to$ R cannot be an injection.  (Note we are talking of only an algebraïc homomorphism.  That is, we have no topology on the function spaces.) I follow the solution through ""the image of [such a homomorphism] $\phi$ consists only of constant functions.""  What I don't get is the following (and terminal) sentence, ""In particular, $\phi$ is not injective.""  This does not follow from cardinality considerations, as $C$ has the same cardinality as R .  Could someone please elucidate?","['ring-theory', 'real-analysis']"
594826,Unknown number of colours Bernoulli Urn,"Okay, so, in the traditional Bernoulli Urn problem, we have an urn with a number N, possibly infinite, of coloured balls, and there are k possible colours. That one I grok. However, what if I don't actually know what k is? That is, what if I have an urn with N balls and an unknown but finite and strictly positive number of possible colours? The main question is, in fact, what my priors should be. What's the prior that there is exactly one colour? Exactly two? At least two? How do I update on the relative frequencies of each colour? Is this problem even solvable? My first lines of thinking are to have a vector of parameters $\vec \theta \in \mathbb R^\infty$ such that the first parameter is the number of colours in the urn (let's call it $\alpha$ ) and the remaining are the relative frequencies of each colour. If $P(A=n\mid\vec\theta)$ is the probability that the colour of the next draw will be $n$ given the knowledge contained by $\vec\theta$ , we'd have: $\vec\theta = (\alpha, p_1, p_2, p_3, \ldots)$ $\alpha \in \mathbb N^*$ $\left(\sum\limits_{n=1}^\infty P(\alpha = n) \right)= 1$ $\left(\sum\limits_{n=1}^\infty p_n\right) = 1$ $\forall n > \alpha : p_n = 0$ $\forall n \in \mathbb N^* : P(A=n\mid\vec\theta) = p_n$ However, this is just wild speculation on my part. I'm mostly curious about whether this is even in principle solvable. What I'd want to know is a way to compute both the prior and posterior distributions of $P(\vec\theta)$ or, in other words, the pdfs $P(\alpha)$ , $P(p_1)$ , $P(p_2)$ , etc. How to start with them and how to update on them.","['probability-theory', 'probability-distributions', 'probability']"
594841,Polycyclic groups are finitely generated,"The definition of a group $G$ being polycyclic that I'm currently learning is:
G has a normal series : $e = G_n \triangleleft G_{n-1} \triangleleft ... \triangleleft G_1 \triangleleft G_0 = G$ such that each factor $G_i / G_{i+1}$, $1 \le i \le n-1$ is cyclic. I'm currently doing a problem that asks me to give an example of an abelian group $G$ which is not polycyclic. I know that polycyclic groups are finitely generated so any abelian group that is not finitely generated, e.g. $\mathbb{R}$, works. Although the intuition really goes fine, since the normal series is finite and every factor is cyclic thus can be generated by one element. But I don't really know how to prove the statement that polycyclic groups are finitely generated. Any idea is appreciated.","['finitely-generated', 'group-theory', 'abstract-algebra']"
594863,Classification problem: admissible rule is a Bayes rule for some prior $\pi$,"I have a classification problem where I want to place an observation $X$ into a population described by a pdf equal to either $f_1$ or $f_2$. Given $P_{f_i}(\frac{f_1(X)}{f_2(X)}=j)=0$ for all $j\in [0,\infty]$, $i\in\{1,2\}$, I want to show that any admissible classification rule is a Bayes classification rule for some prior $\pi$. Any help doing this would be very much appreciated.","['statistics', 'statistical-inference', 'decision-theory']"
594887,Notation for Subspaces,"Is there a proper notation for denoting subspaces? For example, if $U$ is a subspace of some vector space $V$. I would usually just write ""the subspace $U \subseteq V$"" but I'm wondering is there is a proper, more compact, notation.","['notation', 'linear-algebra']"
594891,Need clarity with the maximum modulus principle of analytic functions,"I was reading on the maximum modulus principle and I stumbled upon a Theorem: If a function $f$ is analytic and not constant in a given domain $D$, then $|f(z)|$ has no maximum value in $D$. That is, there is no point $z_0$ in the domain such that $|f(z)|\leq |f(z_0)|$ for all points $z$ in it. However, the author also says this: If a function $f$ that is analytic at each point in the interior of a closed bounded region $R$ is also continuous throughout $R$, then the modulus $|f(z)|$ has a maximum value somewhere in $R$. That is, there exists a nonnegative constant $M$ such that $|f(z)|\leq M$ for all points $z$ in $R$, and equality holds for at least one such point. Question : I seem to have trouble wrapping my head around both statements being true. The theorem just means that $|f(z)|$ is a constant in the domain $D$. The author's note, which is practically the same conditions (unless I'm not seeing something), basically contradicts the theorem and says that there is a max. Can someone help clarify?",['complex-analysis']
594908,Computing the derivative of square root of a matrix,"maybe this is an idiot question, however I could not figure out how to solve it. Let $X =M_n(\mathbb{R})$ be the space of $n \times n$ matrix over the reals, then there exists two open neighborhoods of the identity, $U$ and $V$, such that the function $\phi: V \longrightarrow U$, $\phi(A) = \sqrt{A}$ is well defined and is differentiable at the identity $I$.Furthermore,  what's $d\phi(I)(T)$ ? I was thinking in inverting the matrix $A = I - B$ by the usual $\sum_i B^{i}$ and then, somehow, find the unique square root. Thanks in advance.","['multivariable-calculus', 'matrix-calculus']"
594909,Sum of Gaussian Variables may not Gaussian,"I am currently trying to understand the following three points which we discussed in lectures recently: We say that $X=(X_1,\ldots,X_d)$ is $d$-dimensional multivariate Gaussian distributed if $X\sim N(\mu,Q)$ for some $\mu\in\mathbb R^d$, $Q=(q_{ij})\in\mathbb R^{d\times d}$, that is, $X_i\sim N(\mu_i, q_{ii})$ and $\text{cov}(X_i,X_j)=q_{ij}$. There holds: $X=(X_1,\ldots,X_d)$ is $p$-dimensional multi-variate Gaussian distributed if and only if any linear combination of $X_1,\ldots,X_d$ is Gaussian. If $X,Y$ are Gaussian variables, then $X+Y$ is not be Gaussian (in general). This only holds true if $X,Y$ are indepenent. I get the feeling that the ""multivariate Gaussian"" definition in point (1) is somewhat wrong (or incomplete), because otherwise (2) and (3) would contradict each other. But (2) seems correct (as I have found it in many other lecture notes online) and (3) seems correct as well (because of Simon Nickerson's comment in Proof that the sum of two Gaussian variables is another Gaussian ). I know there are other definitions for ""multivariate Gaussian"", which do not contradict (2) and (3), but I am basically wondering whether there is any way of fixing the definition I have got, or is it just plain wrong?","['multivariable-calculus', 'normal-distribution']"
594915,"Cardinality of $A=\{f: \mathbb R \to \mathbb R , f \text{ is continuous and} f(\mathbb Q) \subset \mathbb Q\}$","Find the cardinality of the set $A=\{f: \mathbb R \to \mathbb R , f \text{ is continuous  and} f(\mathbb Q) \subset \mathbb Q\}$. My attempt at a solution: First I've noticed that $A \subset B=\{f:\mathbb R \to \mathbb R, f \space \text{is continuous}\}$. Since a continuous functions is determined by which values it takes at all the rational points of the domain, it's easy to see that $|B|=c^{\aleph_0}=c$. Now, I am trying to find a subset $C$ of $A$ such that $|C|=c$ but I am having a hard time finding this subset. Could anyone give me suggestions/hints to find this subset?",['elementary-set-theory']
594922,Sum of squares at integer points for $L^2$ function,"Let $f\in L^2(\mathbb{R})$ be a continuous function such that $f(x)\rightarrow 0$ as $x\rightarrow\pm\infty$. Is it true that $\sum_{n=1}^\infty |f(n)|^2$ is finite? If the continuity and going to zero conditions are dropped, the statement is not true, because $f(n)$ could have very high values only at the integer points.","['sequences-and-series', 'continuity', 'real-analysis']"
594956,Rotations and reflections in ${\bf R}^3$.,"By a rotation in ${\bf R}^3$ I mean an orthogonal linear transformation $f:{\bf R}^3\to {\bf R}^3$ represented by a matrix $A$ (i.e. $fx=Ax$) with $\det A=1$. By a reflection (through $S$) I mean an orthogonal  linear transformation such that for some subspace $S$, $f\mid S={\rm id}$ and $f\mid S^{\perp}=-{\rm id}$. I am currently stuck in two tasks: $(1)$ Let $\mathscr L_1=\langle(1,1,0)\rangle+(2,0,1)$ and $\mathscr L_2=\langle (2,1,3)\rangle+(1,0,4)$. I have to find a rotation such that $f(\mathscr L_1)=\mathscr L_2$. Now, the distance of both lines to the origin is $\sqrt 3$. The first line accomplishes this with $(1,-1,1)$, while the second line accomplishes this with $(-1,-1,1)$. I tried various times to define a rotation, but I failed. In particular, I know I should map $(1,-1,1)$ to $(-1,-1,1)$. $(2)$ Let $\Pi_1=\{(x_1,x_2,x_3):x_1-x_2+2x_3=k\}$ and $\Pi_2=\langle (1,0,1),(0,1,2)\rangle+(1,-1,1)$. I have to find $k$ such that there exists a reflection that maps $\Pi_1$ to $\Pi_2$ and find $f(\Pi_2)$. Now, the distance to $\Pi_1$ to the origin is $|k|/\sqrt 6$ and that of $\Pi_2$ is $3/\sqrt 6$ which gives me $k=3,-3$. I don't really know how to continue now.","['linear-algebra', 'inner-products', 'geometric-transformation', 'euclidean-geometry']"
594960,Expected value of a negative binomial that has finite $n: n \lt \infty$?,"Cards from an ordinary deck are turned face up one at a time. Compute
  the expected number of cards that need to be turned face up in order
  to obtain (a) 2 aces; (c) all 13 hearts. This is a homework problem straight from a chapter on Expectation from a probability textbook. The textbook has a section on finding the expected value of a negative binomial random variable, and says  $E[X] = E[X_1]+ E[X_2[ \dots + E[X_r] = \frac{r}{p}$. (The textbook defines the negative binomial distribution as the probability that $n$ trials are required until $r$ successes occur. It is assumed that $r$ is constant and $n$, the value of the negative binomial random variable, is unbounded i.e. may go to $\infty$. 
$$P(X = n) = \binom{n-1}{r-1}p^r (1-p)^{n-r}\ \ \ \ \text{for}\ r \le n \lt \infty$$ The problem (a) here seems to want the expectation of a negative binomial random variable, however, the above equation for $E[X]$ assumes that $r \le n \lt \infty$, but in the case of this problem, only up to $50$ cards may actually be selected such that $2$ are aces (there are $48$ non-aces, so the next $49$th, $50$th cards must be aces). In other words, for this problem $2 \le n \le 50$. So instead of following the textbook's equation for $E[X]$, I tried to find $E[X]$ for (a), given $r = 2, p = \frac{4}{52}$ as $$E[X] =  \sum_{n=2}^{50} n \binom{n-1}{2-1} \left(\frac{4}{52}\right)^2\left(\frac{48}{52}\right)^{n-2} \approx 19.8134 $$ If I follow the textbook, I get $E[X] = \frac{r}{p} = 2 \left(\frac{48}{52}\right)^{-1} = 26$. Are either of these answers correct? And is problem (c) essentially the same as solving (a)?",['probability-theory']
594967,Card game probability,"Suppose the following solitaire with a standard deck. I turn four cards visible on the board and on each turn, I remove those suits that appears more than once in the board. Then I fill the board such that it has four cards and repeat removing. I win the game if I can remove all 52 cards from the board and lose otherwise, i.e. when all cards are from different suit. What is the probability to win this game? I guess we need some kind of generating polynomial but I'm not sure how to solve that kind of problems.","['generating-functions', 'card-games', 'recreational-mathematics', 'probability', 'combinatorics']"
594996,Differentiating $ y = e^x \sqrt{x} $,"I need to take the derivative of: $$ y = e^x \sqrt{x} $$ I tried completing this question, and my result was: $$\frac{e^x (2x+1)}{2\sqrt{x}}$$ Let $u = e^x$ and $v = x^{1/2}$, I followed through the rule and got my answer, problem is it's wrong.. Can someone please complete this question and show me how it's done? Thanks in advance. The answer should be in the form: $$ \frac{dy}{dx} = \frac{\square}{\square} + \square $$","['calculus', 'derivatives']"
595010,"Prove that $\lim_{(x,y)\to(0,0)} \frac{x^3y}{x^6+y^2} = 0$","Prove that $$\lim_{(x,y)\to(0,0)} \frac{x^3y}{x^6+y^2} = 0.$$ The only why I can think about is using the Sandwich theorem . Because $\lim_{(x,y)\to(0,0)} \frac{x^3y}{x^6+y^2} = 0$, then I just need to find $h(x,y)$ such that $\lim_{(x,y)\to(0,0)} h(x,y) = 0$ such that: $$0 \le \frac{x^3y}{x^6+y^2} \le h(x).$$ How can I find $h(x)$? EDIT: So what is wrong with my wolframalpha query ? why is it says the limit is zero?","['multivariable-calculus', 'calculus', 'limits']"
595014,Can this limit be solved algebraically?,"I know it's pretty straight forward with L'Hopital's rule, but I was trying to solve algebraically to no avail. $$ \lim_{x\to 2} \frac{x^2+2x - 8}{\sqrt{x^2 + 5} - (x+1)}$$ The limit is $-18$, as discerned using L'Hopital's... Can we solve algebraically?","['calculus', 'limits']"
595038,calculation of $\int\frac{1}{\sin^3 x+\cos^3 x}dx$ and $\int\frac{1}{\sin^5 x+\cos^5x}dx$,"Solve the following indefinite integrals: $$
\begin{align}
&(1)\;\;\int\frac{1}{\sin^3 x+\cos^3 x}dx\\
&(2)\;\;\int\frac{1}{\sin^5 x+\cos^5 x}dx
\end{align}
$$ My Attempt for $(1)$: $$
\begin{align}
I &= \int\frac{1}{\sin^3 x+\cos ^3 x}\;dx\\
&= \int\frac{1}{\left(\sin x+\cos x\right)\left(\sin^2 x+\cos ^2 x-\sin x \cos x\right)}\;dx\\
&= \int\frac{1}{\left(\sin x+\cos x\right)\left(1-\sin x\cos x\right)}\;dx\\
&= \frac{1}{3}\int \left(\frac{2}{\left(\sin x+\cos x\right)}+\frac{\left(\sin x+\cos x \right)}{\left(1-\sin x\cos x\right)}\right)\;dx\\
&= \frac{2}{3}\int\frac{1}{\sin x+\cos x}\;dx + \frac{1}{3}\int\frac{\sin x+\cos x}{1-\sin x\cos x}\;dx
\end{align}
$$ Using the identities $$
\sin x = \frac{2\tan \frac{x}{2}}{1+\tan ^2 \frac{x}{2}},\;\cos x = \frac{1-\tan ^2 \frac{x}{2}}{1+\tan^2 \frac{x}{2}}
$$ we can transform the integral to $$I = \frac{1}{3}\int\frac{\left(\tan \frac{x}{2}\right)^{'}}{1-\tan^2 \frac{x}{2}+2\tan \frac{x}{2}}\;dx+\frac{2}{3}\int\frac{\left(\sin x- \cos x\right)^{'}}{1+(\sin x-\cos x)^2}\;dx
$$ The integral is easy to calculate from here. My Attempt for $(2)$: $$
\begin{align}
J &= \int\frac{1}{\sin^5 x+\cos ^5 x}\;dx\\
&= \int\frac{1}{\left(\sin x+\cos x\right)\left(\sin^4 x -\sin^3 x\cos x+\sin^2 x\cos^2 x-\sin x\cos^3 x+\cos^4 x\right)}\;dx\\
&= \int\frac{1}{(\sin x+\cos x)(1-2\sin^2 x\cos^2 x-\sin x\cos x+\sin^2 x\cos^2 x)}\;dx\\
&= \int\frac{1}{\left(\sin x+\cos x\right)\left(1-\sin x\cos x-\left(\sin x\cos x\right)^2\right)}\;dx
\end{align}
$$ How can I solve $(2)$ from this point?","['calculus', 'integration', 'indefinite-integrals']"
595050,Lower Limit Topology?,"Show $(0,1)$ is open but not closed in the Lower Limit Topology. I know that $[a,b)$ is open and closed in the lower limit topology, but I am not sure how to prove this one. Thanks for any help.",['general-topology']
595054,"$\dim_k H^1(X, \Omega_X)$, $X \subset \mathbb{P}^3$ a projective surface","Is it possible to calculate $\dim_k H^1(X, \Omega_X)$, for $X \subseteq \mathbb{P}_\mathbb{C}^3$ a smooth projective surface of degree $d$, without using Chern classes? I've been trying to do this by playing around with the long exact sequences in cohomology associated to the Euler sequence and the conormal sequence
$$0 \to \mathcal{O}_X(-d) \to i^\ast\Omega_{\mathbb{P}^3} \to \Omega_X \to 0$$
 for $i: X \hookrightarrow \mathbb{P}^3$.  I don't really understand Chern classes very well.  Mainly I guess I want to know whether I need them to solve this problem. (This is homework: I was assigned to calculate the Hodge diamond of a complex projective surface, and I have the other Hodge numbers.)","['algebraic-geometry', 'hodge-theory']"
595069,How to prove that the series $\sum_{n=1}^\infty \frac{(-1)^n}n$ converges,"I know by definition that a series $$\sum_{n=1}^\infty a_n$$ converges when the sequence of partial sums $S_N=a_1 + a_2 + .. + a_N$ converges to $S$, so $\lim_{N\rightarrow \infty} S_N=S$. So in particular, I'm given the series $$\sum_{n=1}^\infty \frac{(-1)^n}{n},$$ which converges to $\ln 2$. I'm kinda stuck on how to get started. So far I have, $\forall \epsilon >0$, $\exists N>0$ s.t. if $n>N$ then $|a_n-0|<\epsilon$.
Is this ok so far? How do I go from here?","['sequences-and-series', 'real-analysis', 'analysis']"
595082,Cardinality of this set: $A=\{f: \mathbb{R} \rightarrow \mathbb{R} \text{ continuous} : f(\mathbb{Q})\subseteq\mathbb{Q}\}$,"How can I show that the cardinality of this set: $A=\{f: \mathbb{R} \rightarrow \mathbb{R} \text{  continuous} : f(\mathbb{Q})\subseteq\mathbb{Q}\}$ is $2^{\aleph_{0}}$? I know that $A\subseteq \{f: \mathbb{R} \rightarrow \mathbb{R} \text{  continuous} \}$ so #$(A)\leq2^{\aleph_{0}}.$ But I don't know how to show the other inequality. Thanks a lot for your help! I know there is a post with the same question, but I don't understand the answer :( Cardinality of $A=\{f: \mathbb R \to \mathbb R , f \text{ is continuous and} f(\mathbb Q) \subset \mathbb Q\}$",['elementary-set-theory']
595149,Prove that either $(2^{10500} + 15)$ or $(2^{10500} + 16)$ is not a perfect square. [duplicate],"This question already has answers here : How to prove that either $2^{500} + 15$ or $2^{500} + 16$ isn't a perfect square? (10 answers) Closed 10 years ago . Prove that either $(2^{10500} + 15)$ or $(2^{10500} + 16)$ is not a perfect
square. how should I solve this problem? what is the idea for solving this kind of problems? Thank you so much",['discrete-mathematics']
