question_id,title,body,tags
2274501,How to go from Lie Algebra representation to group representation?,"On wikipedia, they say about $SU(2)$ group : ""Since the group SU(2) is simply connected, every representation of its Lie algebra can be integrated to a group representation"". They give a reference to a book but I don't find the corresponding theorem inside. I would like to basically understand the connection between representations of Lie algebras and Lie groups. I am a huge beginner in representation theory, lie group and lie algebra, I basically know the definitions. So I would like a really simple answer (I'm actually doing physics and I need to basically understand the connection between Lie group and Lie algebra representation).","['representation-theory', 'group-theory', 'lie-groups']"
2274556,How to prove there are no solutions for $5^{3+a} = 11^{2+b} + 4$ except $a=b=0$?,"Working out some similar questions with my systematic approach as done for instance in this older question (and in some other questions) I could not yet find the equivalent proof of nonexistence of a solution in $a,b \gt 0$ 
$$ 5^{3+a} = 11^{2+b} + 4 \tag 1$$ 
which I usually rewrite as
$$ {5^a -1 \over 11^2} = {11^b - 1\over 5^3 } \tag 2$$ Possibly there is a simpler method than mine by some cleverer modular considerations. Well, I didn't check whether we can deduce from the fact that $4=2^2$ being a square number there is only a finite (already known) list of possible solutions for $x^a-y^b = z^2$ for $a,b>2$ which would solve this immediately. However, I'd prefer the other way: I'd like to see a proof using modularity to understand, why or where my own method fails or why it might need only more/excessive effort.","['number-theory', 'diophantine-equations']"
2274577,Find the sum of the infinite series $\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\frac{1\cdot3\cdot5}{1\cdot2\cdot3\cdot4\cdot5\cdot6}+...$ [duplicate],"This question already has answers here : Sum of the series:$\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\cdots$ (2 answers) Closed 3 years ago . Find the sum of the series $\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\frac{1\cdot3\cdot5}{1\cdot2\cdot3\cdot4\cdot5\cdot6}+...$.
This type of questions generally require a trick or something and i am not able to figure that out. My guess is that it has something to do with exponential series or binomial series. Any help?",['sequences-and-series']
2274634,Why does Milnor need to move to the Riemann sphere to prove the fundamental theorem of algebra?,"On pages 8 and 9 of Topology from the differentiable viewpoint , Milnor proves the fundamental theorem of algebra. He does so by first turning our polynomial $P:\mathbb{C} \rightarrow \mathbb{C}$ into a function $f:\hat{\mathbb{C}} \rightarrow \hat{\mathbb{C}}$ on the Riemann sphere. But, I don't see why moving to $\hat{\mathbb{C}}$ is necessary. Here's the argument: Next observe that $f$ has only a finite number of critical points; for $P$
  fails to be a local diffeomorphism only at the zeros of the derivative
  polynomial $P$ and there are only finitely many
  zeros since $P'$ is not identically zero. The set of regular values of $f$, being a sphere with finitely many points removed, is therefore connected. Hence the locally constant function $\#f^{-1}(y)$ must actually be constant
  on this set. Since $\#f^{-1}(y)$ can't be zero everywhere, we conclude that
  it is zero nowhere. Thus $f$ is an onto mapping, and the polynomial $P$
  must have a zero. I don't see why we can't just apply this argument to $P$ directly. After all, a plane with finitely many points removed is still connected; this property isn't unique to the sphere. Question. If we try to replace $f$ with $P$ in Milnor's proof, what goes wrong?","['complex-analysis', 'general-topology', 'complex-numbers', 'differential-topology']"
2274656,"What is wrong with this ""proof""? $1$ is always an eigenvalue for $I + A$ ($A$ is nilpotent)?","Consider the nilpotent matrix $A$ ($A^k = 0$ for some positive $k$).
  It is well known that the only eigenvalue of $A$ is $0$. Then suppose $\lambda$ is any eigenvalue of $I + A$ such that 
  $(I + A) \mathbf{v} = \lambda \mathbf{v}$ where ($\mathbf{v} \neq \mathbf{0}$). Then $I \mathbf{v} + A \mathbf{v} = \lambda \mathbf{v} \implies 
 \mathbf{v} + A \mathbf{v} = \lambda \mathbf{v} \implies A \mathbf{v} =
(\lambda - 1) \mathbf{v}$ We know that $\lambda - 1 = 0$ because the only eigenvalue of a
  nilpotent matrix is $0$. Therefore $\lambda = 1$ This ""proof"" seems to indicate that $1$ is always an eigenvalue for the sum of the identity matrix with any nilpotent matrix, but I believe I have a counterexample that disproves this. I believe my error was in assuming that $I + A$ has eigenvalues -- but I do not know how I could prove/disprove this. If someone could help me see where I've gone wrong I would greatly appreciate it!","['matrices', 'eigenvalues-eigenvectors', 'fake-proofs', 'linear-algebra']"
2274693,Number Theory: Find all functions that $f(n)! = f(n!)$ and $m-n | f(n)-f(m)$,"Find all functions like $f$ which take positive integers as argument,
  that $f(n)! = f(n!)$ and for each natural numbers $m,n$ $m-n |
> f(n)-f(m)$ Any hints how can i find functions that satisfy given condition?","['number-theory', 'elementary-number-theory']"
2274735,Find likelihood function and MLE for hypothesis,"I'm currently reading about statistics and I'm trying to understand likelihood function and MLE (maximum likelihood estimation). I have come across an exercise which is basically like this: I'm given four numbers including $x_1, x_2, x_3$ and $n$, where $n$ is the total number of trials. The numbers for $x_1, x_2$ and $x_3$ are all different. Then I'm given a model $M_0$ which states that $(X_1, X_2, X_3)$ is distributed as the multinomial distribution with parameters $n$ and $(\pi_1, \pi_2, \pi_3)$ where $(\pi_1, \pi_2, \pi_3) \in \Pi^3$. Finally, I have to consider the hypothesis $H_1: (\pi_1, \pi_2, \pi_3) = (1 - 2p, p, p)$, $p \in (0, 0.5)$ My task is then to show that the likelihood function for the hypothesis $H_1$ is given by: $$
L(p) ={{n} \choose {x_1,x_2,x_3}}\cdot (1 - 2p)^{x_1}\cdot p^{x_2+x_3}
$$ and show that the maximum likelihood estimation for p is given by $$
\hat{p} = \frac{x_2 +x_3}{2n}.
$$ I have been reading and watching a lot of videos about the likelihood function and MLE in order to try to understand it, but I don't even know where to begin in this case. Also, I'm a bit confused whether $p \in (0, 0.5)$ means that $p$ is either $0$ or $0.5$ since the brackets used aren't the normal set brackets { and }. Can someone point me in the right direction?","['maximum-likelihood', 'statistics', 'probability', 'mathematical-modeling', 'descriptive-statistics']"
2274743,Homeomorphism between homeomorphic spaces [duplicate],"This question already has answers here : Are continuous self-bijections of connected spaces homeomorphisms? (4 answers) Closed 7 years ago . I have a practice exam problem that asks to prove or disprove the following statement. Every continuous bijection between homeomorphic spaces is a homeomorphism. Now based on everything I know about topology, I feel like I have several ways to show that this is indeed false. But then I started second guessing myself based on the wording of the question. It's kind of hard for me to interpret what this question is really asking. So we already know that we have homeomorphic spaces $(X,\tau_1), (X,\tau_2)$. But are they really homeomorphic if $\tau_1\neq \tau_2$? I guess what I'm really confused about is what is meant by homeomorphic spaces precisely. Because I know that a continuous bijection is a homeomorphism if and only if it is open (closed), which is equivalent to saying that a continuous bijection is a homeomorphism if and only if $\tau_1=\tau_2$. But if they had to be equal in order for the spaces to even be homeomorphic to begin with, then can't we argue that any continuous bijection between the spaces has to be a homeomorphism?",['general-topology']
2274760,Weird functional equation $(e^x-1)f(2x)=\left(e^{2x}-1\right)f(x)$,"I had a rehearsal test today and got this question in the test that completely stumped me. Let $f: \mathbb{R} \to \mathbb{R}$ be a non constant continuous function such that $$(e^x-1)f(2x)=\left(e^{2x}-1\right)f(x)$$ If $f'(0)=1$ , then what are $f(x)$ and $f(2x)$ ? My try: I just differentiated both sides with respect to $x$ and made use of $f'(0)=1$ , but that got me nowhere. Please help me someone. Thanks in advance.","['exponential-function', 'functions', 'functional-equations']"
2274805,Prove $T:X\to X$ is bounded,"Let $X$ be a Banach space and $T:X\to X$ be linear operator. Let $A$ be s subset of $X^*$ which separates the points in $X$. Suppose $f\circ T$ is bounded $\forall f\in A$, show that $T:X\to X$ is bounded. I think it is kind of using Uniform Boundedness theorem, but I have no idea how to do it. Could you please give me some hints please? Thank you.","['functional-analysis', 'banach-spaces']"
2274812,"$S\subset\mathbb{R}^3$ compact, orientable, not a sphere $\Rightarrow K$ has positive and negative values","Let $S$ be a compact, orientable surface embedded in $\mathbb{R}^3$, not diffeomorhic to $\mathbb{S}^2$. Prove that its Gauss curvature attains positive and negative values (consequently, it eventually vanishes). Since $S$ is not a sphere, the only possible values for $\chi(S)$ are $0,-2,-4,-6,...$, so by the Gauss Bonnet theorem, $\int\int_S Kd\sigma=2\pi\chi(S)\leq 0$, which means $K$ cannot be always positive. I'm trying to prove that $K$ also cannot be always negative, but I'm having trouble with it. Intuitively, the fact that $S$ is compact should be enough to guarantee that, but I have no idea how to implement the idea.","['curvature', 'smooth-manifolds', 'differential-geometry', 'surfaces']"
2274827,How to recover the coefficients of a formal noncommutative power series from a twist?,"This is a very half-baked question relating to something in my PhD research. I am trying to apply these ideas to a different situation, but this is a starter case that I am trying to think about. Therefore I'd like to try to set things up quite generally, although I think this is still incredibly vague. Apologies in advance! Let's suppose I have some commutative $\mathbb{Q}$-algebra $A$ (think: subring of the complex numbers) and let $B = A[\alpha, \alpha^{-1}]$ for some element $\alpha$ (thought of as a complex number not in $A$). Let $A\langle\langle x_0, x_1\rangle\rangle$ denote the ring of formal power series in noncommuting variables $x_0, x_1$ with coefficients in $A$. That is, let $X$ be the free monoid on $\left\{ x_0, x_1\right\}$. Then an element of $A\langle\langle x_0, x_1\rangle\rangle$ is a formal series
$$S = \sum_{w \in X}S_w w, \quad S_w\in A.$$ The ring $A\langle\langle x_0, x_1\rangle\rangle$ is a Hopf algebra with the coproduct for which $x_0$ and $x_1$ are primitive. Let $\text{GrL}(A\langle\langle x_0, x_1\rangle\rangle)$ denote the set of grouplike elements of this Hopf algebra. I am interested in the following map: set $\alpha = 2\pi i$, and let $f: \text{GrL}(A\langle\langle x_0, x_1\rangle\rangle)\to \text{GrL}(B\langle\langle x_0, x_1\rangle\rangle)$ be the conjugation map $$S\mapsto S \exp(2 \pi i x_1) S^{-1}=S(1+2\pi i x_1 + \frac{(2\pi i)^2}{2}x_1 x_1 + \dots)S^{-1}.$$ Question : I have heard that it is possible to recover the (space of) coefficients $S_w$ of $S$ from the ""twisted series"" $f(S)$. How can one go about doing this? Is it a direct computation or is there an abstract way to see it? I have heard that this is discussed in Deligne-Goncharov's paper Groupes fondamentaux motiviques de Tate mixte but unfortunately my French isn't very good and the exposition seems fairly complicated. The motivation for this comes from what happens to the Drinfeld associator $S = \Phi(x_0, x_1)$ under monodromy around the punctured point $1\in\mathbb{P}^1\backslash\left\{0,1,\infty\right\}$. More abstractly (and unfortunately much less certainly in my mind), let $_{0}\Pi_{1}$ denote the (de Rham) torsor of paths from the tangential basepoint $\vec{1}_0$ at $0$ to the tangential basepoint $-\vec{1}_1$ at $1$. I believe that we have $_{0}\Pi_{1}\cong \text{Spec}(\mathbb{Q}\langle x_0, x_1\rangle)$, the spectrum of the shuffle algebra. (I am actually unsure on whether this is correct because $_{0}\Pi_{1}$ is a torsor under the de Rham fundamental group - which is also this same scheme - but it is only isomorphic after picking a point. Perhaps this isomorphism above is not natural?) Set $_{0}\Pi_0$ (resp. $_1\Pi_1$) to be the de Rham fundamental group at the tangential basepoint $\vec{1}_0$ (resp. $-\vec{1}_1$). Then for $K$ a $\mathbb{Q}$-algebra, the $K$-points of each of these schemes $_a\Pi_b$ should be $$_a\Pi_b (K) \cong \text{GrL}(K\langle\langle x_0, x_1\rangle\rangle),$$ although these isomorphisms may be different in each case. The Drinfeld associator lives in $_0\Pi_1 (\mathbb{R})\hookrightarrow _0\Pi_1 (\mathbb{C})$, and can be thought of as the ""straight line path"" $\text{dch}$ from $\vec{1}_0$ to $-\vec{1}_1$. Then by picking the element $\exp(2\pi i x_1)\in _1\Pi_1 (\mathbb{C})$ (thought of as a small loop around the puncture at $1$) we first go along $\text{dch}$, then go around the loop around $1$, and then go along the reverse path $\text{dch}^{-1}$. This results in a map $$_0\Pi_1 (\mathbb{C}) \to  _{0}\Pi_0 (\mathbb{C}), \quad S\mapsto S \exp(2\pi i x_1) S^{-1}.$$ The idea is that one should be able to recover the original ""path"" from $\vec{1}_0$ to $-\vec{1}_1$ from this new ""loop"". I am trying to understand this case before moving onto a much more complicated twisting map arising from the case of a punctured elliptic curve.","['abstract-algebra', 'hopf-algebras', 'power-series', 'algebraic-geometry']"
2274845,Moment generating function and martingales,"Let $(X_n)_{n\geq1}$ be a sequence of i.i.d. random variables such that the moment generating function $M_{X_1}(t)<\infty$ for all $t$ . Let $S_n=\sum_{i=1}^n X_i$ and $\displaystyle{M_n=\frac{e^{tS_n}}{M_{X_1}(t)^n}, n = 1,2,\dots}$ Show that $(M_n)$ is a martingale w.r.t. $(F_n=\sigma\{X_m:m\leq n\})$ . How to show $E[M_{n+1}|F_n]=M_n$ ? If I want to show $M_n$ is integrable, then I have to show $E[M_n]<\infty$ . It is easy to show the numerator of $M_n$ is integrable, but how to show $M_n$ is integrable?",['probability-theory']
2274876,"What is the meaning of the phrase ""Up to isomorphism "" in Abstract Algebra?","What is the meaning of the phrase ""Up to isomorphism "" in Abstract Algebra in context of- GROUPS RINGS FIELDS","['finite-fields', 'abstract-algebra', 'ring-theory', 'group-theory']"
2274890,How to prove this formula for the Legendre symbol for a finite field,"Let $\mathbb{F}_q$ be a finite field with $q$ odd, let $x\in\mathbb{F}_q$ and define the Legendre symbol for $\mathbb{F}_q$ as
\begin{equation} \left(\frac{x}{\mathbb{F}_q} \right) = \begin{cases}
	\phantom{-}1 & \text{if $t^2=x$ has a solution $t\in\mathbb{F}_q^*$}\;,\\
	-1 & \text{if $t^2=x$ has no solution $t\in\mathbb{F}_q$}\;,\\
	\phantom{-}0 & \text{if } x=0\;.
	\end{cases} \end{equation} How do I see that
$$ \left( \frac{x}{\mathbb{F}_q} \right) = x^{(q-1)/2} $$
as elements of $\mathbb{F}_q$?
This is left as an exercise in ""Elliptic Curves - Number Theory and Cryptography"" by Washington but I need it in a proof and I can't seem to figure it out. Any help is greatly appreciated.","['number-theory', 'finite-fields', 'legendre-symbol']"
2274900,different definitions for $C^\infty(p)$,"I've seen in some books and notes that in order to define the tangent vector $v:C^\infty(p)\to\mathbb R$, the author defines $C^\infty(p)$ as the set of all real valued functions $f:M\to\mathbb R$ such that does there exist an open set $U\subseteq M$ containing $p$ and $f|_U$ is smooth and then defines a tangent vector as a map $v:C^\infty(p)\to\mathbb R$ such that for all $f,g\in C^\infty(p)$ and $a,b\in\mathbb R$, $$v(af+bg)=av(f)+bv(g)\\
v(fg)=f(p)v(g)+v(f)g(p).$$ So why we really need to insert smooth functions which are agree on some smaller open set containing $p$ in an equivalence class and define $C^\infty(p)$ as the set of these equivalence classes? And then define a tangent vector as the map $v:C^\infty(p)\to\mathbb R$ such that for all $[f],[g]\in C^\infty(p)$and $a,b\in\mathbb R$, $$v[af+bg]=av[f]+bv[g]\\
v[fg]=f(p)v[g]+v[f]g(p)?$$ What are differences between first and second $C^\infty(p)$? Is the first definition a standard definition?","['smooth-manifolds', 'riemannian-geometry', 'differential-geometry', 'differential-topology']"
2274907,How many axis of symmetry of the cube are there?,"In my final mathematics test, I have a bonus question: How many axis of symmetry of the cube are there? The teacher gives me the definition: Definition: If we rotate a 3-dimension object around the line d for 180 degrees and it result in an exactly same shape in an exactly same position, line d is a axis of symmetry of that object. I have found 9 axis of symmetry, 3 of which pass through the centers of 2 opposite faces, the other 6 pass through the midpoints of the 2 opposite edges. But my teacher told that 9 is wrong and said that the correct answer is not what we're going to expect. So, what is the correct answer? And how can we prove it?","['rubiks-cube', 'geometry']"
2274929,Calculate the limit of $\left(\frac{f(x)}{x}\right)^{1/x}$,"Let $f(x),f:R\to R$ be a non-constant continuous function such that 
$$\left(e^x-1\right)f(2x)=\left(e^{2x}-1\right)f(x)\,.$$If $f'(0)=1$, then $$\lim_{x\to \infty}\left(\frac{f(x)}{x}\right)^{1/x}$$ My approach : Well I just dont get the idea of how to start, I separated the $f(x)$ terms and tried to solve but got nowhere. Any help will be appreciated, thanks.","['exponential-function', 'limits']"
2274932,"Pearson Correlation Coefficient for samples $X,Y$ equals $1$ iff there is $a>0, b\in \mathbb{R}$ with $x_i = ay_i + b$ for every $i=1,\dots,n$.","Let $X = (x_1,\dots,x_n)$ and $Y = (y_1,\dots,y_n)$ be outcome values.
We have defined the variances $s^2_X = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$, $s^2_Y = \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar{y})^2$, the covariance $s_{XY} = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})$ and the correlation coefficient $r_{XY} = \dfrac{s_{XY}}{s_X s_Y}$. The if-direction was rather easy to show but I have trouble with the other direction. I do not know how to find $a>0, b \in \mathbb{R}$ or how to use my precondition $r_{XY}=1$ or how to show the equality for every sample unit. Could anyone help me with this problem? Thank you.","['descriptive-statistics', 'statistics', 'correlation', 'discrete-mathematics']"
2274972,An integral formula for the reciprocal gamma function,"I'm looking to compute an exact integral formula for the reciprocal of the double factorial function, $(2n-1)!!$, or just as easily for the reciprocal gamma function, $\Gamma\left(n+\frac{1}{2}\right)$. I found the post located here and that formula works well for me when, for example, I take $c := 1$. However, there is another known formula that I'm looking to replicate, or at least find a suitable analog to. Namely, that for integers $n \geq 0$ we have that (this formula is found in the appendices of the Concrete Mathematics book, for example): 
\begin{align*}
\frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-n\imath t} e^{e^{\imath t}} dt & = \frac{1}{n!}. 
\end{align*} 
I have had a look around google and found page 3 of this article and the Hankel loop contour described here , though I am still struggling to find the analog to this formula for the double factorial function case. I believe that the integral formula above is derived from the contour integral for the reciprocal gamma function, but when I perform a change of variable in the loop contour formula and plugin $z \mapsto n + \frac{1}{2}$, Mathematica computes the following result when $n = 3$ (the expected result is acceptably $\frac{8}{105}$, or ideally $\frac{1}{105}$): 
\begin{align*}
\frac{1}{4\sqrt{\pi}} \int_{-\pi}^{\pi} e^{-(n_3+\frac{1}{2})\imath t} e^{e^{\imath t}} dt & = -\frac{1}{21 e \sqrt{\pi}} + \frac{8}{105} \operatorname{erf}(1). 
\end{align*} 
The result is obviously close to the intended formula, so I'm thinking that perhaps it's an issue with the bounds on the integral. I would like to keep the bounds of integration finite as in the factorial function formula if possible. Does anyone have any thoughts, advice, or solutions for this problem?","['complex-analysis', 'factorial', 'contour-integration', 'calculus']"
2275022,Solve this trigonometric inequality,"The values of $\lambda$ for which the equation $2\sin (x)-\sqrt \lambda \cos(x)=\sqrt2+\sqrt{2-\lambda}$ has solutions. MY APPROOACH: Now I know that max value of LHS of above expression can be $\sqrt{4+\lambda}$ and min value can be $\sqrt{4-\lambda}$. So $\sqrt2+\sqrt{2-\lambda}\in [\sqrt{4-\lambda},\sqrt{4+\lambda}]$. So I get $\lambda \ge \frac{1}{2}$. Now how do I find the max value because I am unable to get a conclusion from $\sqrt{4+\lambda}\ge \sqrt2+\sqrt{2-\lambda}$","['inequality', 'trigonometry']"
2275045,"Limits of sequences from given conditions and relations between the general terms $a_n, b_n, c_n$.","Let $a_n, b_n, c_n$ be sequences such that 
  $$a_n+b_n+c_n=2n+1,$$ 
  $$a_nb_n +b_nc_n +a_nc_n=2n-1,$$ 
  $${a_n}{b_n}{c_n} =-1.$$ 
  It is also given that $a_n \gt b_n \gt c_n $. Then what is the value of the following? a) $\lim_{{n}\rightarrow {\infty}}\frac{a_n}{n} $. b) $\lim_{n\rightarrow{-\infty}}\frac{a_n}{n}$. I took $b_n+c_n=2n+1-a_n$ and $b_nc_n=\frac{-1}{a_n}$. Now the second condition which can be written as $(c_n+b_n)a_n + b_nc_n=2n-1$ now changes to $(2n+1-a_n)a_n - \frac{1}{a_n}=2n-1$. I have absolutely no idea on what to do next. I tried reducing $a_n$ into something in terms of $n$, but I have gotten nowhere. How can this question be solved?","['sequences-and-series', 'limits']"
2275047,Problem with limit and increasing function,"Let $f:(0,\infty) \to (0,\infty)$ be an increasing function such that $$\lim_{x \to \infty}f(x)=\infty \text { and } \lim_{x \to \infty} \frac {f(x+f(x))}{f(x)}=1.$$ Show that $$\lim_{x \to \infty} \frac {f(x)}{x}=0 \text { and } \lim_{x \to \infty} \frac {f(x+af(x))}{f(x)}=1,$$ for every $a \gt 0$.",['limits']
2275089,Proof that $ \int_0^\infty \frac{(f'(x))^2}{f(x)^{1980}} dx < \infty$,"Suppose that $f(x), f'(x), f''(x)$ are continuous on $(0,+\infty)$ and $f(x) \geq \alpha > 0,$ and the improper integral $\displaystyle \int_{0}^{\infty} |f''(x)| dx$ exists. Proof that $$\displaystyle \int_0^\infty \dfrac{(f'(x))^2}{f(x)^{1980}} dx < \infty$$
My attempt is to use $\displaystyle \int \frac{f'(x)}{f(x)^{990}} dx = \frac{-1}{989 f(x)^{989}} $ but I got stuck. How can I use the continuity of $f , f', f''$","['improper-integrals', 'integration', 'calculus']"
2275132,Star Wars Knights of the Old Republic Math Puzzle,"This question confuses me on how to reach a solution for it. In the game, a robot poses this question: Droid K-X12d: Puzzle - Battle Droid: Scanning memory nodes... 4 * 14 * 11-14 * 31-14 * 13-21-14 * ...?... * ...?... Error: Descriptive number progression corrupted. 
To re-calibrate, determine the correct progression by describing the previous entry. We're given a few answers to choose from but I actually want to know how this question is mathematically solved. The answers are in a format such as 12-34-56-78 * 12-34-56-78 I know the answer which I'll leave in spoiler tags in case you want to work the solution before looking at the answer. 31-13-12-14 * 23-41-12-14","['puzzle', 'discrete-mathematics']"
2275146,Smallest subgroup of $S_4$ containing a set of permutations.,"So the question asks to find the order of the smallest subgroup of $S_4$ (call this subgroup $G$) which contains the following set of permutations:
$$\{ (12)(34),(14)(32),(24),(31) \}$$ I know that since the order of $S_4$ is 24, the order of $G$ must divide 24. I also have that the identity element is included in $G$ so the order of $G$ must be at least $5$ which limits the possible orders to: $6$, $8$, $12$, and $24$. In a similar question I had that all the permutations were even so could use that it was in $A_4$ but that won't work here. Any tips or tricks I can use to solve this would be appreciated.","['abstract-algebra', 'group-theory', 'symmetric-groups']"
2275151,4th order tensors double dot product and inverse computation,"I am currently working on a subject that involves a lot of 4th order tensors computations including double dot product and inverse of fourth order tensors. First the definitions so that we are on the same page. What I call the double dot product is : $$ (A:B)_{ijkl} = A_{ijmn}B_{mnkl} $$ and for the double dot product between a fourth order tensor and a second order tensor : $$ (A:s)_{ij} = A_{ijkl}s_{kl}$$ Using the convention of sommation over repeating indices. What I call the identity of the fourth order tensors is the only tensor such that : $$ A:I = I:A = A $$ it is defined by $ I = \delta_{ik}\delta_{jl} e_{i} \otimes e_{j} \otimes e_{k} \otimes e_{l} $ . What I call the inverse of a fourth order tensor is the inverse with respect to the double dot product, that is, the inverse of $A$ is the only tensor $B$ such that $AB = BA = I$ . The double dot product is easy to compute if you don't think about the efficiency of the code, just create an array and loop over the four indices. Computing the inverse is something else. Every tensor I use has the minor symmetries $A_{ijkl} = A_{jikl} = A_{ijlk}$ so I thought I would use the Mandel representation for second order and fourth order tensors mentioned on Wikipedia. The fourth order tensor can be put into a $6 \times6$ matrix with the following components : $$ [C] =
\begin{bmatrix}
    C_{1111}  & C_{1122} & C_{1133} & \sqrt{2}C_{1123} & \sqrt{2}C_{1131} & \sqrt{2}C_{1112}\\
    C_{2211} & C_{2222} & C_{2233} & \sqrt{2}C_{2223} & \sqrt{2}C_{2231} & \sqrt{2}C_{2212}\\
    C_{3311} & C_{3322} & C_{3333} & \sqrt{2}C_{3323} & \sqrt{2}C_{3331} & \sqrt{2}C_{3312}\\
    \sqrt{2}C_{2311} & \sqrt{2}C_{2322} & \sqrt{2}C_{2333} & 2C_{2323} & 2C_{2331} & 2C_{2312}\\
    \sqrt{2}C_{3111} & \sqrt{2}C_{3122} & \sqrt{2}C_{3133} & 2C_{3123} & 2C_{3131} & 2C_{3112}\\
    \sqrt{2}C_{1211} & \sqrt{2}C_{1222} & \sqrt{2}C_{1233} & 2C_{1223} &2C_{1231} & 2C_{1212}
\end{bmatrix}
$$ $C$ is a fourth order tensor with minor symmetries and $[C]$ is its Mandel representation. The reason why Mandel's representation exists according to different sources is such that the matrix-matrix and matrix-vector usual products coincide with the fourth order tensors double dot product and the inverse in each respective space (fourth order tensors and $6\times 6$ matrices) coincides as well, that is $$
[A:B] = [A] \cdot [B] \qquad \qquad (1)
$$ and $$
[A^{-1}] = [A]^{-1} \qquad \qquad (2)
$$ where $ \cdot $ is the usual matrix-matrix product. But it doesn't work or at least there must be something I don't understand. If I put the identity 4th order tensor defined above into Mandel's notation, I get the following matrix : $$ [I] =
\begin{bmatrix}
    1&0&0&0&0&0\\
    0&1&0&0&0&0\\
    0&0&1&0&0&0\\
    0&0&0&2&0&0\\
    0&0&0&0&2&0\\
    0&0&0&0&0&2
\end{bmatrix}
$$ which is obviously different from the identity of $6 \times 6$ matrices so if I compute $[C] \cdot [I]$ using the usual matrix-matrix product I won't get the same $[C]$ .
I also wrote a little script to check relations (1) and (2) but wasn't able to find this result with random $4^{th}$ order tensors possessing minor symmetries. What am I missing here ? Thanks a lot for your help and the discussions to come :)","['tensor-products', 'matrices', 'abstract-algebra', 'tensors', 'linear-algebra']"
2275164,Truncated taylor series inequality,"I came across the following fact in a paper and am having trouble understanding why it is true: Consider the error made when truncating the expansion for $e^a$ at the $K$th term. By choosing $K = O(\frac{\log N}{\log \log N})$, we can upper bound the error by $1/N$, in other words
$$\sum_{j={K+1}}^\infty \frac{a^j}{j!} \leq \frac{1}{N}.$$ Here, the $O$ is ""big-O"" notation. I'm thinking a Stirling approximation probably has to be used in the denominator but still can't reproduce this result. Maybe this is some well-known result that I'm not aware of?","['real-analysis', 'taylor-expansion', 'asymptotics', 'calculus']"
2275167,Why is the stereographic projection a map from $S^2\to\mathbb{R}^2$?,"How can I understand that the stereographic projection $$X=\cot\left(\frac{\theta}{2}\right)\cos\phi,\hspace{0.5cm}Y=\cot\left(\frac{\theta}{2}\right)\sin\phi\tag{1}$$ is a map from the surface of a unit sphere to a plane? For (1) to be map from $S^2\to \mathbb{R}^2$, shouldn't $X,Y$ vary from $-\infty$ to $+\infty$ for the allowed ranges of $\theta,\phi$? Does it suffice to see that $X,Y$ are real? I think it's not because $\theta,\phi$ themselves were real. Then why is this a map from $S^2\to \mathbb{R}^2$ and not from $S^2\to \mathcal{M}$ where $\mathcal{M}$ is some other 2-dimensional manifold?","['riemannian-geometry', 'stereographic-projections', 'manifolds', 'differential-geometry', 'open-map']"
2275239,Matrices and Divisibility,"Let $p$ be an odd prime number and $T_p$ be the following set of $2$ x $2$ matrices
$$T_p=\{A=\left(\begin{array}{cc} a & b\\ c & a \end{array}\right); a,b,c \in\{0,1,2,3...,p-1\}\}$$ Q.1) The no. of $A$ in $T_p$ such that $det(A)$ is not divisible by p. (A) $2p^2$ (B) $p^3-5p$ (C) $p^3-3p$ (D) $p^3 - p^2$ Q.2) The no. of $A$ in $T_p$ such that the trace of $A$ is not divisible by $p$ but $det(A)$ is divisible by $p$ (A) $(p-1)(p^2-p+1)$ (B) $p^3-(p-1)^2$ (C) $(p-1)^2$ (D) $(p-1)(p^2-2)$ Q.3) The no. of $A$ in $T_p$ such that $A$ is either symmetric or skew-symmetric or both and $det(A)$ is divisible by $p$ (A) $(p-1)^2$ (B) $2(p-1)$ (C) $(p-1)^2 +1$ (D) $2p-1$ I wa able to solve Q.3 only. Approach:- Considering the values of $a,b,c,$ $A$ can never be skew-symmetric. Now $det(A) = a^2-bc$ For symmetric matrix, $b=c$ So, $det(A)=a^2-b^2=(a+b)(a-b)$ Case $I$ : $a=b$ There are $p$ ways of selecting $a$ or $b$ (Select any no. in $\{1,2,3...,p-1\}$ Case $II$ : $a \neq b$ $a+b$ must be a multiple of $p$ since $a-b$ will always given a no. less than $p$ according to the given set of $a,b,c$ and also $p$ is a prime no. So there are $p-1$ ways to select $a$ and $b$. Possible ordered pairs of $(a,b)$ $(1,p-1), (2,p-2),...(p-1,1)$ Total ways: $2p-1$ Need help for Q.1 and Q.2","['matrices', 'determinant']"
2275266,"If $G$ is a finite cyclic group acting faithfully on $\mathbb{P}^1_\mathbb{C}$, must it have exactly two fixed points?","If $G$ is a finite (nontrivial) cyclic group acting faithfully on $\mathbb{P}^1_\mathbb{C}$ by holomorphic automorphisms, must it have exactly two fixed points? I believe this should follow from the Hurwitz formula, but it's possible I've made a mistake. Is this well known? Are there other proofs of this which don't use the Hurwitz formula?",['algebraic-geometry']
2275333,Complex integration of $\log(z)$ over a closed counter-clockwise curve containing the origin only once,"What's the integral of $\log(z)$ in $C$, where $C$ is a closed curve enclosing the origin only once (counter-clockwise)? I tried to use the circle with radius $r$, $\{z=re^{\theta i} : \theta \in (0,2\pi) \}$, but then I obtain the result $2 \pi r i$, and I think that the result should not depend on the radius.","['complex-analysis', 'contour-integration', 'complex-integration']"
2275344,Proving that $a_n=\frac{n^2+2n+6}{n^3-3}\to 0$ as $n\to\infty$,"$$a_n=\frac{n^2+2n+6}{n^3-3}$$ So I want to show that ""$a_n\to a\iff\forall \epsilon>0,\quad\exists N\in\mathbb{N}:n\geq N\implies |a_n-a|<\epsilon$"" Then my rough working: $|a_n-0| =\left|\frac{n^2+2n+6}{n^3-3}\right|<\epsilon$ Estimate $\frac{n^2+2n+6}{n^3-3}<\frac{b_n}{c_n}$ Require $b_n>n^2+2n+6$, so choose $b_n=2n^2>n^2+2n+6$ for $n\geq 4$ Require $c_n<n^3-3$, so choose $c_n=\frac{n^3}{2}<n^3-3$ for $n\geq 2$ Then let $N=\frac{2n^3}{n^3/2}=\frac{4}{n}$ So now the proof: $$\text{Fix}\quad \epsilon>0.\quad\text{Pick}\quad N:N>\frac{4}{n}\quad\text{and}\quad N\geq 4$$ $$\implies \forall n\geq N,\quad |a_n-0|=\left|\frac{n^2+2n+6}{n^3-3}\right|<\frac{4}{n}\leq\frac{4}{N}\leq\epsilon$$ Is this correct? Is it completely rigorous? I've just started doing analysis on my own, so please point out if anything is wrong/not conventional so that I can get into good habits at the start. Thanks for any help.",['sequences-and-series']
2275362,Let $T$ be a surjective linear map such that $ \|Tx\| \geq \frac{1}{2017} \|x\|$ for all $x \in X$. Show that $T$ is bounded.,"Problem: Let $T$ be a surjective linear map from a Banach space $X$ onto a Banach space $Y$ such that $$ \|Tx\| \geq \frac{1}{2017} \|x\|$$ for all $x \in X$. Show that $T$ is bounded. I thought of proving by contradiction: saying that if $T$ is not bounded then $T$ is not continuous (since we know that $T$ is bounded is equivalent to $T$ is continuous), but it get me to nowhere. Could anyone give me a tip or a solution for this problem? Thanks","['functional-analysis', 'real-analysis']"
2275384,Proving a set is positive invariant for a dynamical system,"I have the following dynamical system: $$
\begin{align}
\dot{x}&=-x-2y^2, \\
\dot{y}&=-x^2y-y^3.
\end{align}
$$
My task is to show that, for the dynamical system, the set $$S=\left\{ (x,y) \in \mathbb{R}^2:x \leq0 \right\}$$ is positive invariant. My first thought is to use a Liapunov function defined by $$L:S \to \mathbb{R}, \: \: L(x,y)=-x,$$ which is positive definite. However, calculating $\dot{L}$ gives $$\dot{L}=L_x\dot{x}+L_y\dot{y}=-\left(-x-2y^2\right)=x+2y^2,$$ from which I cannot seem to deduce anything. Any help would be great!","['set-invariance', 'ordinary-differential-equations', 'dynamical-systems']"
2275408,Orthogonal differentiable family of curves,"This problem is out of section 4-4 in M. do Carmos' Differential Geometry of Curves and Surfaces : We say that a set of regular curves on a surface $S$ is a differentiable family of curves on $S$ if the tangent lines to the curves of the set make up a differentiable field of directions. Assume that a surface $S$ admits two differentiable orthogonal families of geodesics. Prove that the Gaussian curvature of $S$ is zero. As a tip, he says: Parametrize a neighborhood of $p\in S$ in such a way that the two families of
  geodesics are coordinate curves (Corollary 1, Sec. 3-4). Show that this implies
  that $F = 0, E_v = 0 = G_u$. Make a change of parameters to obtain that $\bar{F} = 0, \bar{E} = \bar{G} = 1$. I know that for every $p\in S$ we can find a neighbourhood $U\subset S$ of $p$ and a parametrization $X:I\times J\to U$ such that the coordinate curves $\alpha_{v_0}(u)=X(u,v_0)$ belong to one family and $\beta_{u_0}(v)=X(u_0, v)$ belong to the other. That way, $$F=<X_u,X_v>(u_0,v_0)=<\alpha'_{v_0}(u_0), \beta'_{u_0}(v_0)>=0$$ I also know that if I can prove that $E_v=G_u=0$, then I can use the formula for orthogonal parametrizations: $$K=-\frac{1}{2\sqrt{EG}}\left\{\left(\frac{G_u}{\sqrt{EG}}\right)_u+\left(\frac{E_v}{\sqrt{EG}}\right)_v\right\}$$ to prove that $K=0$, but I don't know how to prove that. Besides, I don't see the need of changing parameters to get $\bar{E}=\bar{G}=1$. Any hints?","['curves', 'curvature', 'differential-geometry', 'surfaces']"
2275438,Is there a partition of an open square into closed segments (not reduced to a point)?,"Let $C$ be an open square (for example $]0, 1[ \times ]0, 1[$)of the plane $\mathbf R^2$.
Is there a partition of $C$ into closed segments (not reduced to a point) ?","['general-topology', 'integer-partitions']"
2275465,PDF of uniform distribution over the hypersphere and the hyperball,"There are some good questions and answers about picking random multivariate points over the surface of the hypersphere and the volume of the hyperball, just like this and this . However none of the answers provide probability density function (PDF) for these distributions. The related Wolfram Mathworld articles ( this and this ) also lack the PDFs. The missing PDFs should be in the form $P(x; x_0, r)$. where the parameters are $x_0$ is the location (center) of the hypersphere/hyperball $r$ is the radius of the hypersphere/hyperball More specifically, the methods in question are the following: Picking a random multivariate over the hypersphere: If $X = (X_1, \ldots, X_n)$ are independent (iid) standard normal variates, then $x_0 + r \frac{X}{||X||_2}$ is uniformly distributed over the surface of the n-sphere (in the geometer's sense) with location $x_0$ and radius $r$. Picking a random multivariate over the hyperball: If $X = (X_1, \ldots, X_n)$ are independent (iid) standard normal variates, and $Y$ is a standard exponential ($\lambda = 1$) variate, then $x_0 + r \frac{X}{\sqrt{Y + ||X||_2^2}}$ is uniformly distributed over the volume of the n-ball with location $x_0$ and radius $r$. Alternatively, using a variate $U$ uniformly distributed over $[0,1]$, the expression $x_0 + r U^{1/n} \frac{X}{||X||_2}$ is also uniformly distributed over the hyperball.","['probability-theory', 'probability-distributions', 'statistics', 'geometry']"
2275475,Direct sum of injective modules is injective.,"By the Bass-Papp Theorem, for a unital ring $R$, any direct sum of injective left $R$-modules is injective if and only if $R$ is left Noetherian.  I would like to restrict my consideration to an arbitrary abelian subcategory $\mathcal{C}$ of the category $R\text{-mod}$ of unitary left $R$-modules. We say that an abelian subcategory $\mathcal{C}$ of $R\text{-mod}$ is injectively closed if it satisfies the property that, for an arbitrary family $\left(I_\alpha\right)_{\alpha\in A}$ of injective objects in $\mathcal{C}$ such that $I:=\bigoplus\limits_{\alpha \in A}\,I_\alpha$ is an object in $\mathcal{C}$, $I$ is an injective object in $\mathcal{C}$.  Is it true that if $R$ is left Noetherian, then any abelian subcategory of $R\text{-mod}$ is injectively closed?  If not, can you please provide a counterexample?  Is there a sufficient condition for $\mathcal{C}$ to be injectively closed?  References are greatly appreciated. For a nontrivial example, let $\mathfrak{g}$ be a finite-dimensional semisimple Lie algebra over an algebraically closed field of characteristic $0$ with a triangular decomposition $$\mathfrak{g}=\mathfrak{n}^-\oplus \mathfrak{h}\oplus \mathfrak{n}^+\,.$$
Denote by $\bar{\mathcal{O}}$ the full subcategory of the category of $\mathfrak{U}(\mathfrak{g})$-modules (where $\mathfrak{U}(\mathfrak{g})$ is the enveloping algebra of $\mathfrak{g}$) consisting of $\mathfrak{U}(\mathfrak{g})$-modules $M$ with the following properties: $M$ is a weight module with respect to the Cartan subalgebra $\mathfrak{h}$, each weight space of $M$ is finite dimensional, and $M$ is locally $\mathfrak{n}^+$-finite (that is, $\mathfrak{U}\left(\mathfrak{n}^+\right)\cdot v$ is a finite-dimensional vector subspace of $M$ for any $v\in M$). Then, $\bar{\mathcal{O}}$ is injectively closed.  (In this example, note that $\mathfrak{U}(\mathfrak{g})$ is both left and right Noetherian.) P.S.: The Bass-Papp Theorem can be found, for example, in Theorem 3.39 on Page 123 of An Introduction to Homological Algebra by Joseph Rotman.","['abstract-algebra', 'representation-theory', 'category-theory', 'abelian-categories', 'lie-algebras']"
2275486,Differential Equations: Finding the increasing/decreasing values of autonomous diff eq.,"The question gives the differential equation: $${dP\over dt} = 0.4P\left(1-{P\over 230}\right)$$ The textbook question is, "" For what values of $P$ is the population (b) increasing and (c) decreasing. "" I understand that we must first find the values of $P$ the population is in equilibrium which are $P = 0$ and $P = 230$, but I'm generally confused on how the bounds for the values of $P$ when they are increasing, as the solution states that ""if the population is increasing if $\frac{dP}{dt} > 0$ and decreasing if $\frac{dP}{dt} < 0$. Where do the values of equilibrium play into finding this increase/decrease thing and how do I solve that question?",['ordinary-differential-equations']
2275508,showing $ 1-\frac{3}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{3}{6}+\frac{1}{7}+\frac{1}{8}+\cdots=0 $,"How to show that the following infinite series
$$
1-\frac{3}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{3}{6}+\frac{1}{7}+\frac{1}{8}+\cdots=0?
$$
The above series is of the form $\sum_{n \ge 1} \frac{f(n)}{n}$, where $f$ is a periodic arithmetical function of period $4$, with the values $f(1)=f(3)=f(4)=1$ and $f(2)=-3$. Since $\sum_{1 \le i \le 4} f(i)=0$, it is assured that this series is convergent.","['number-theory', 'analytic-number-theory', 'sequences-and-series', 'elementary-number-theory']"
2275558,Evaluate $ \prod_{n=1}^{80}n^{k-n} \pmod{83}$,"Evaluate $\displaystyle \prod_{n=1}^{80}n^{80-n} \pmod{83}$. Attempt: The product is \begin{align*}\prod_{n=1}^{80}n^{80-n} &= 1^{79} \cdot 2^{78} \cdot 3^{77} \cdots 79^1 \cdot 80^0\\&\equiv -2^{78} \cdot 3^{77} \cdot 4^{77} \cdots 41^{77}\\&\equiv -2 \cdot (1 \cdot 2 \cdots 41)^{77} \\&\equiv -2(1 \cdot 2 \cdots 41)^{77}\pmod{83}\end{align*} Note that $$1^2 \cdot 2^2 \cdot 3^2 \cdots \left(\dfrac{p-1}{2}\right)^2 \equiv (-1)^{\frac{p+1}{2}} \pmod{p}$$ for a prime $p$. Thus for $83$ we find $$(1 \cdot 2 \cdot 3 \cdots 41)^2 \equiv (-1)^{\frac{83+1}{2}} \equiv (-1)^{42} \equiv 1 \pmod{83}.$$ But if $x^2 \equiv 1 \pmod{p}$, then $x \equiv \pm 1 \pmod{p}$. How do we eliminate the case that  $1 \cdot 2 \cdots 41 \equiv -1 \pmod{83}$?",['number-theory']
2275560,Do springs and projectiles under gravity exist in the same family?,"Background A 1D vertical spring subject to gravity satisfies Hook's Law: $m x''(t) = -kx(t) + g$ where $m$ is the mass at the end of the spring, $x(t)$ is the position of the mass at time $t$, $x''(t)$ is its acceleration, $k$ is the stiffness coefficient, and $g$ is the gravitational force. Solving this ODE (I used maple, shame on me), I get: $x \left( t \right) =\sin(\frac{\sqrt{k}t}{\sqrt {m}})c_1+\cos(\frac{\sqrt {k}t}{\sqrt {m}})c_2 + {\frac {g}{k}},$ where $c_1$ and $c_2$ are integration constants. If my mass were detached from the spring, then this amounts to setting $k=0$ and the mass falls according to: $mx''(t) = g$ and solving this produces– as expected –a quadratically increasing displacement: $x(t) = \frac{g}{2m}t^2 + c_3 t + c_4$ where $c_3$ and $c_4$ are integration constants. With initial conditions: We can simplify this problem further by assuming homogenous initial conditions in both cases: $x(0) = x'(0) = 0$. For the spring solution we get: $x(t) = -\frac{g}{k}cos(\frac{\sqrt{k}}{\sqrt{m}}t) + \frac{g}{k}$ and for the falling object we get: $x(t) = \frac{g}{2m}t^2$. Question Because of the divide by $k$ I cannot simply consider $k=0$ to get from the spring solution to the falling object solution. Naively taking the limit seems to produce $x(t) = \infty$. Is there a correct way to take the limit or to solve the ODE so that I get a solution that transitions from the oscillatory spring into the falling object as $k\rightarrow 0$? Note: the conversation in the comments here mention similar behavior but without a solution to the specific question. Bonus points for convincing maple to do this since my actual problem is a more complicated of this simple scenario.","['limits', 'physics', 'maple', 'ordinary-differential-equations', 'projectile-motion']"
2275591,Show the exponential map $\mathfrak{u}(n) \to U(n)$ is surjective,"I know this or similar questions have been asked numerous times. But the answers seem quite advanced. This problem is an exercise in a set of notes in a course where the main text is Stillwell's ""Naive Lie Theory,"" so I would appreciate help with a solution at that level. Show the exponential map $\mathfrak{u}(n)\rightarrow U(n)$ is surjective where $\mathfrak{u}(n)$ is the tangent space at the identity (in the next section to be referred to as the Lie algebra) of $U(n)$, the space of unitary matrices. Earlier it was proved that this tangent space for $U(n)$ is the set of matrices $\lbrace X\in M_n(\mathbb{C}):X+X^{*}=0\rbrace$ There is a hint that if $A$ is a unitary matrix, then there is a unitary matrix $U$ and a diagonal matrix $D$ such that $A=UDU^{*}$. So far, I would say if $A\in \mathfrak{u}(n)$ then $e^A=e^{UDU^{*}}\in U(n)$. And $e^{UDU^{*}}=Ue^{D}U^{*}$. Thanks","['matrices', 'unitary-matrices', 'linear-algebra', 'lie-algebras', 'lie-groups']"
2275616,Probability of a number rolled of a 20 sided dice being greater than the sum of the numbers rolled on 3 six sided die.,"Bob rolls $3$ six-sided die and sums the numbers facing up. Bill rolls a single $20$ sided dice and records the number. What is the probability that Bob's number is greater than Bill's number. I started the problem trying to come up with an equation, but that didn't work, so I resorted to creating $6$ six by six tables with all of the possible sums for Bob's die. Then, I counted the number of each number and created a chart and calculated the probability of each of those numbers occurring. Then, I multiplied the probability of each number occurring by the probability that Bill's number is greater than that number. Finally, I added them all up. Obviously, this was very tedious and time-consuming. Is there a more elegant/less tedious way to do this problem. PS: Is there away to do a $n$ die vs $m$ dice problem without listing them all out? Is there a general formula? Up until now, that's what I've been doing.","['combinatorics', 'probability', 'dice']"
2275638,Isometries of $\mathbb{S}^2$,"Definition : let $S,S'\subset\mathbb{R}^3$ be surfaces and a diferentiable function $f:S\to S'$ . $f$ is said to be an isometry if for every $p\in S$ we have $\langle df_p(v), df_p(w)\rangle = \langle v,w\rangle$ whenever $v, w\in T_pS$ I'm trying to prove that if $f:\mathbb{S}^2\to\mathbb{S}^2$ is an isometry, then $f$ is an orthogonal linear transformation. What I've done so far was to prove that $df_p$ is an orthogonal linear transformation for every $p\in S$ . But I really don't know how to conclude that $f$ it self is an orthogonal transformation. What is the trick?","['isometry', 'orthogonal-matrices', 'smooth-manifolds', 'differential-geometry']"
2275642,"If $f(y\mid\theta)\sim N(\theta, 1)$, how to find the asymptotic distribution $f\left(y\mid\hat{\theta}_n^{MLE}\right)$?","If I have that $f(y\mid\theta)$ has a $N(\theta, 1)$ distribution, and $\widehat{\theta}_n^{MLE} \to \theta^{\star}$ in probability, where $Y_1, \ldots, Y_n \sim N(\theta^{\star},1)$ , how can I find the asymptotic distribution of $p\left(y\mid\widehat{\theta}_n^{MLE}\right)$ ? I know that we should have $N\left(\widehat{\theta}_n^{MLE},1\right)$ converging to $N\left(\theta^{\star},1\right)$ but am not sure how to show this. Does anyone have any ideas?","['normal-distribution', 'probability-theory', 'asymptotics', 'probability-distributions', 'statistics']"
2275645,Broken stick game,"Two players Alice and Bob play the following game consisting of $n-1$ turns. Initially the segment $[0,1]$ is given. Alice and Bob then alternate breaking one segment into two pieces. After all turns have passed, there are $n$ pieces. What is the maximum number of triangles Alice can guarantee forming? If you cannot see the answer for the total can you at least give the answer for the case $n=4$ or higher because I'm lost. Anything would help. Thanks.","['combinatorial-game-theory', 'combinatorics', 'contest-math', 'discrete-mathematics']"
2275659,How do you prove the statement: $A^c=(A\cup B)^c\cup (B \setminus A)$,"I've been stuck on this question for a while and the problem is basically I just don't know how to prove it, I tried converting it to $\vee$ and $\wedge$ symbols then I did some research and found mathematically it doesn't make sense to compare them, so I'm currently stuck on how to prove such a statement. Question Determine whether the following statement is true or false, if true prove it, if false, provide a counterexample. $A^c=(A\cup B)^c\cup (B \setminus A)$ Working $A^c=$ ~$A$, $(A \cup B)^c=($~$A$ $\wedge$ ~$B$), $(B\setminus A)=$ ~$A$ $\implies A^c=(A\cup B)^c\cup (B \setminus A)=$~$A =($~$A$ $\wedge$ ~$B)$ $\wedge$ ~$A$ $\rightarrow$ I then went on to show this was equal to ~$A$ $\wedge $ ~$B$ which doesn't show anything additionally it's mathematically incorrect from what I found. Note I tried finding a counterexample and couldn't find one, so I'm assuming it is true, and as I said that's where I'm stuck, I don't know how to prove it. ANY help would GREATLY be appreciated, thanks! :)","['logic', 'elementary-set-theory']"
2275663,When are integral operators trace class?,"Define an integral operator $T$ on $L^2([0,1])$ by $$Tf(x) = \int_0^1 K(x, y) f(y) \, dy. $$ Such an operator is Hilbert-Schmidt when $K$ is in $L^2([0,1]\times [0,1])$. I heard that if $K$ is smooth, then $T$ is in fact trace-class. Why is this? When is such an operator trace-class?","['functional-analysis', 'integral-transforms', 'real-analysis', 'operator-theory']"
2275671,Surface Area vs. Volume of Solid of Revolution,"Surface Area and Volume of Solid of Revolution: Why does $\int 2 \times \pi y \, dx$ not work for surface area, but $\int \pi \times y^2 \, dx$ works for volume? I know that for surface area, it’s because the function is slanted so it couldn’t be written as Riemann sum but also for volume, it can be written as Riemann sum while the function is also slanted.","['calculus', 'solid-of-revolution', 'integration', 'geometry', 'ordinary-differential-equations']"
2275679,Show monotonicity,"Originally, I want to show that
$$
\frac{\sqrt{a \cdot b + \frac{b}{a}x^2}\arctan \left(\frac{c}{\sqrt{a \cdot b + \frac{b}{a}x^2}}\right)}{\sqrt{a \cdot b}\arctan \left(\frac{c}{\sqrt{a \cdot b}}\right)} \geq 1 \  \ \text{for} \ \  x, a,b,c > 0 \ .
$$ 
To do so, I figured it is sufficient to show that
$$
f(x) = \sqrt{a \cdot b + \frac{b}{a}x^2}\arctan \left(\frac{c}{\sqrt{a \cdot b + \frac{b}{a}x^2}}\right)
$$ is monotonically increasing for $x > 0$. 
Of course, I took the derivative $f'(x)$ and proceeded with the demand 
$$
\frac{\frac{b}{a}x}{\sqrt{a \cdot b + \frac{b}{a}x^2}} \arctan \left(\frac{c}{\sqrt{a \cdot b + \frac{b}{a}x^2}}\right) - \frac{c \frac{b}{a} x}{a \cdot b + \frac{b}{a} x^2 + c^2} > 0 \ .
$$
In the end, I got stuck with
$$
\arctan \left(\frac{c}{\sqrt{a \cdot b + \frac{b}{a}x^2}}\right) > \frac{c \sqrt{a \cdot b + \frac{b}{a}x^2}}{a \cdot b + \frac{b}{a} x^2 + c^2} \ .
$$ Inserting values for a,b, and c seems to work perfectly, but I can't manage to analytically solve the inequation.
Does anyone have an idea of how to approach this problem? Edit:
I came across the Shafer-Fink inequality stating
$$
\frac{3y}{1+2\sqrt{1 + y^2}} < \arctan y < \frac{\pi y}{1 + 2\sqrt{1 + y^2}} \ .
$$
Can I substitute 
$$
y = \frac{c}{\sqrt{a \cdot b + \frac{b}{a}x^2}}
$$
and therefore receive 
$$
\arctan (y) > \frac{3y}{1+2\sqrt{1 + y^2}} > \frac{y}{1 + y^2} ?
$$
Is that a proper way?","['inequality', 'monotone-functions', 'analysis']"
2275710,Sum involving $\gcd$,"I was asked to evaluate the sum $\sum_{k = 1}^n \frac{n}{\gcd(n,k)}$ in terms of the prime factorization of $n$. I know that there are $\phi(n)$ integers $k < n$ such that $\gcd(n,k) = 1$ so I tried writting $\sum_{k = 1}^n \frac{n}{\gcd(n,k)} = \phi(n)n + 1 + S$ where $S$ is the contribution from the terms where $k < n$ and $\gcd(n,k) > 1$. I've also tried evaluating $\sum_{k = 1}^n \frac{\text{lcm}(n,k)}{k}$ but to no avail. I would preferably like a hint as opposed to a full solution. Any help is appreciated.","['number-theory', 'summation', 'elementary-number-theory']"
2275711,Find the Riemann integral of the following function.,"Define $f$ on $[0,1]$ by $$f(x)=\begin{cases}x^2  ~~\text{if $x$ is rational}\\ x^3  ~~\text{if $x$ is irrational}\end{cases}$$ Then $f$ is not Riemann integrable on $[0,1]$ $f$ is Riemann integrable and $\int_{0}^{1}f(x)dx=\frac{1}{4}$ $f$ is Riemann integrable and $\int_{0}^{1}f(x)dx=\frac{1}{3}$ $\frac{1}{4}=\underline\int_{0}^{1}f(x)dx< \overline\int_{0}^{1}f(x)dx=\frac{1}{3}.$ I have not solved this kind of problems before in Riemann integration. So I have no idea how to approach. Few thoughts that came to my mind are like- if somehow I prove that the function is not continuous then option 1 is true. For checking the upper sum and lower sum, I have to partition the interval and calculate. But I am confused about, if the intervals end with rational points, then how to take care of the irrational part of the function? Please, any kind of help in solving and understanding this problem will be greatly helpful. Thanks","['real-analysis', 'functions', 'riemann-integration']"
2275730,Integrals of the form $\int_0^{+\infty} \sin g(x) \ dx$,"I'm interested in the convergence of integrals of the form $$\int_0^{+\infty} \sin g(x) \ dx$$ where $g$ is nonnegative, increasing and growing without bound as $x \to +\infty$ (hence $\sin g(x)$ oscillates as $x \to +\infty$). For example, it's known that $$\int_0^{+\infty} \sin x^p \ dx$$ converges for $p>1$. Similarly, $\int_0^{+\infty} \sin(\exp x) \ dx$ converges. Here are three questions (they are related enough that I didn't think it was worth making three separate questions). Consider functions $g:[0, +\infty) \to [0, +\infty)$ which are continuous, strictly increasing and unbounded. $(i)$ Suppose we add the additional hypothesis that $g$ is strictly convex. Does $\int_0^{+\infty} \sin g(x) \ dx$ converge? $(ii)$ Can we characterize those $g$'s for which $\int_0^{+\infty} \sin g(x) \ dx$ converges? $(iii)$ Is there a $g$ such that $\int_0^{+\infty} \sin g(x) \ dx$ converges absolutely?","['real-analysis', 'integration', 'calculus']"
2275809,Calculate minimal polynomial of a matrix,"\begin{bmatrix}0&1&0&1\\1&0&1&0\\0&1&0&1\\1&0&1&0\end{bmatrix}
I have calculated characteristic polynomial as $x^2(x^2-4)$ but I don't know what is minimal polynomial please solve","['matrices', 'linear-algebra', 'minimal-polynomials']"
2275830,Prove that $\lim\limits_{k\to\infty}\left(\frac1k\sum\limits_{n=1}^k\left\lfloor\frac kn\right\rfloor-\ln k\right)=2\gamma-1$,"Prove that $$\lim\limits_{k\to\infty}\left(\frac1k\sum\limits_{n=1}^k\left\lfloor\frac kn\right\rfloor-\ln k\right)=2\gamma-1$$ I have approximated this limit with python: import math

len = 10000000000

ans = 0.0
x = 1
while (x<len):
    ans += len/x
    x = x + 1

ans = ans/len - math.log(len)

print ans



# this is the value i got for len = 10 billion:   0.154433 If anyone knows anything about this limit I would be extremely interested to hear about it. I came up with it when thinking about the Euler -
 Mascheroni Constant which is defined similarly. The main difference here is the I have in a sense rounded the harmonics down to a values that form discrete intervals of [0,1]. It appears that this limit is one less than twice the Euler - Mascheroni Constant or at least very close according to the program I wrote. If anyone could prove this or suggest any ways I might attempt to do so that would be great. Stated more clearly where L is the limit and γ is the Euler - Mascheroni Constant: L = 2γ-1","['limits', 'euler-mascheroni-constant', 'harmonic-numbers', 'sequences-and-series', 'ceiling-and-floor-functions']"
2275836,Differential equation involving functions and value of function at two points are given.,"The equation is $$2 (f(x))^2 - \frac{d^2f(x)}{dx^2}f(x) + \left(\frac{df(x)}{dx}\right)^2=0   $$ It is also given that $f(0)=f(1)=1$. I tried to solve by substituting $y$ in place of $f(x)$:
$$2y^2-y''y+(y')^2=0$$ 
 but I could not reduce it to any form that I could solve. Is there some special way to solve it?","['ordinary-differential-equations', 'calculus', 'functions']"
2275879,Proving that sequences with the pattern aaaaaaa don't include a perfect square,"I need help with the following problem: Which of the following sequences doesn't have perfect square: A) $11, 111, 1111, \dots$ B) $33, 333, 3333, \dots$ C) $44, 444, 4444, \dots$ D) $77, 777, 7777, \dots$ I proved that the first sequence cannot contain a perfect square, but it seems that none of them contains a perfect square. Is it possible to  write a proof for a general pattern $aaaaaaaaa$?","['sequences-and-series', 'elementary-number-theory']"
2275919,Do there exist another $\mathbb{R}$?,"Can we find a set other the $\mathbb{R}$ satisfying all the field axioms, order properties and completeness axiom? By another set I mean, it differs from $\mathbb{R}$ may be in terms of topology, cardinality, etc,. Edit I am just curious to see some structure which evidently differ from $\mathbb{R}$, yeah topologically we can find, but topological difference doesn't quit a apparent difference in some sense for me. Yeah I understand my question is vague... but I think I let the reader to get the point.","['general-topology', 'real-numbers', 'large-cardinals']"
2275927,Is $f(x)=x+\sin(x)$ a one to one or many to one function?,"If we differentiate the function, we get $$f'(x)=1+\cos(x)$$ Hence, $f'(x)$ varies from $0$ to $2$. So, I think it is a one to one function because the function is never decreasing, and the function never becomes consecutively constant for more than one point. But how do I prove that $f(x)$ is never strictly $0$ in an interval?",['functions']
2275950,How may we show that $\int_{0}^{\pi/2}e^{-{\pi\over 2}\tan t}\mathrm dt=C_i\left({\pi\over 2}\right)?$,Proposed: $$\int_{0}^{\pi/2}e^{-{\pi\over 2}\tan t}\mathrm dt=C_i\left({\pi\over 2}\right)\tag1$$ Where $C_i$ is Cosine Integral $$C_i(x)=-\int_{x}^{\infty}{\cos t\over t}\mathrm dt\tag2$$ My try: Recall (I doubt it would be any useful) $$e^{\tan t}=1+t+{t^2\over 2}+{t^3\over 2}+{3t^3\over 8}+\cdots\tag3$$ $u={\pi\over 2}\tan t\implies {\pi\over 2}\sec ^2 t$ then $(1)$ becomes $$2\pi\int_{0}^{\infty}e^{-u}\cdot{\mathrm du\over 4u^2+\pi^2}\tag4$$ Recall $$\int{\mathrm du\over u^2+a^2}={1\over a}\tan^{-1}{u\over a}\tag5$$ probably $(4)$ we may apply integration by parts? How does one prove $(1)$?,"['integration', 'definite-integrals', 'calculus']"
2276025,Construct right triangle given the sum of legs and the hypotenuse.,"I actually  made one however with the help of an ellipse. Can the construction be done without using the concept of ellipse? I want another solution since this chapter problem in a book has not yet introduced the concept of ellipse so there maybe a solution. To anyone asking how I did it with an ellipse here's how: construct a circle with center and end point on mid point and end point of the hypotenuse, respectively. This should act as the median to the hypotenuse as it is half of the hypotenuse (theorem), and the circle act as the locus of the third vertex.  Now construct ellipse whose constant lenght is the sum of the base pivoted at the end points of the hypotenuse. The intersection of the circle and ellipse is the vertex that satisfy the condition. The angle between leg should be right by Thales theorem. So there you go, that is my construction.","['geometric-construction', 'geometry']"
2276065,"Standard hyperbolic solution to 2nd order ODE, equivalent forms.","Consider the following 2nd order ODE:
$$\frac{d^2u}{dx^2}-\gamma^2u=0.$$
This equation has solutions of the form $$u(x)=Ae^{\gamma x}+Be^{-\gamma x},$$
or equivalently $$u(x)=(A+B)\cosh{\gamma x}+(A-B)\sinh{\gamma x}\equiv C_1\cosh{\gamma x}+C_2\sinh{\gamma x}.$$
I would like to demonstrate, that both are equivalent to $$u(x)=D\cosh{(\gamma x +x_0)}.$$ How do you go about doing this (if it is indeed possible)? I tried to do it the same way you do it for regular trig functions but cosh is undefined for values less than 1.","['trigonometry', 'ordinary-differential-equations']"
2276072,"Prove the following: $f:X \to Y$ is 1-1 if and only if it has a left inverse: that is, a function $g:Y \to X$ such that $g \circ f = 1_X$","$f:X \to Y$ is 1-1 if and only if it has a left inverse: that is, a function $g:Y \to X$ such that $g \circ f = 1_X$. I have been trying to solve this question with injection function but I still can't solve it. Can anyone show me how to do it?","['elementary-set-theory', 'functions']"
2276088,How to find period of a real function $f$ given the functional equation $\sqrt{3}f(x) = f(x-1) + f (x+1) $?,If a periodic function satisfies the equation $\sqrt{3}f(x) = f(x-1) + f (x+1) $ for all real $x$  then prove that fundamental period of the function is $12$. Here fundamental period means the smallest positive real for which function repeats its value for all $x$. I tried replacing $x$ by $x \pm 1$ then try to find $f(x)$ in terms of other but always end up with it in terms of sum of other two arguments in the function eg $f(x-2)$ + $f (x+2)$  etc. Please provide a general method and also especially do give the thought process or reasoning for all the steps ie why you are doing these particular steps or what led you to thinking that doing these steps would give you the period of f.,"['functions', 'functional-equations']"
2276096,"Let $M$ be a smooth manifold and let $N$ be a manifold with boundary. If $dF_{p}$ is an isomorphism, then $F\left(p\right)\in\mbox{int}M $.","Let $M$ be a smooth manifold and let $N$ be a manifold with boundary, both with the same dimension $n$. If $dF_{p}$ is an isomorphism, then $F\left(p\right)\in\mbox{int}N  $. I am trying to prove this theorem to prove a result about smooth embeddings.  Here is how I am thinking the problem could be solved. Assume thet $F(p)$ is a boundary point of $N$. Then there exists a chart $(V,\psi)$ at $F(p)$ such that $\psi(V) $ is an open subset of the upper half space $\mathbb{H}^{n}$. I guess we have to use some fact about $M$ having no boundary and the the fact that $dF_p$ is an isomorphism to show that there is a contradiction, but I cannot figure that out.","['inverse-function-theorem', 'smooth-manifolds', 'differential-geometry', 'manifolds-with-boundary']"
2276111,"If $A_i$ are subsets of a metric space and $B_n=\cup^{n}_{i=1}A_i$, prove that $\bar{B_n}=\cup^{n}_{i=1}\bar{A_i}$ for $n=1,2,3,...$","For my course in real analysis I'm working on the problem: Let $A_1,A_2,A_3,...$ be subsets of a metric space and $B_n=\cup^{n}_{i=1}A_i$, prove that $$\overline{B_n}=\cup^{n}_{i=1}\overline{A_i},\quad n=1,2,3,...$$ My attempt: (1) Let $x\in\overline{A_i}$ a limit point of $A_i$, then for any neighbourhood $N$ of $x$, $A_i\cap N\neq \emptyset$ so $N\cap B_n$ is not empty. Therefore $x\in B_n'$ and $x\in \overline{B}_n$. (2) Let $x\in B_n'$, then for any neighbourhood $N$ of $x$, $N\cap(A_1\cup ... \cup A_n)\neq\emptyset$. So for any neighbourhood, $N\cap A_i\neq\emptyset$ for some $A_i$. Therefore $x$ is a limit point of this $A_i$. Now I talked about the proof with one of the teachers why said that the second argument was invalid; but I didn't manage to understand why that would be the case. So I'm hoping someone here can explain the error better.","['general-topology', 'real-analysis', 'proof-verification']"
2276112,Which solutions to use for the following hypergeometric equation?,"I am currently trying to understand the solution to a hypergeometric equation given in a paper on scalar fields and rotating black holes by S. Detweiler ( https://journals.aps.org/prd/abstract/10.1103/PhysRevD.22.2323 ). The equation I have trouble with is (17): $$z(z+1)\frac{d}{dz}[z(z+1)\frac{dR}{dz}]+[P^2-l(l+1)z(z+1)]R=0$$ When I try to solve it in mathematica I get associated Legendre polynomials: $$R(z) = C[1]LegendreP[l, 2 I P, 1 + 2 z] + C[2] LegendreQ[l, 2 I P, 1 + 2 z]$$ I know these can be written in terms of hypergeometric functions but they don't seem to match up when I try. In the paper, the author provides a solution of the following form: $$R(z)=(\frac{z}{z+1})^{iP}G(-l,l+1;1-2iP;z+1)$$ where G is any solution to the hypergeometric equation. From here he uses two independent hypergeometric functions $U_3$ and $U_4$ (which are in turn linear combinations of two other solutions $U_1$ and $U_5$): $$U_3 = (-z)^lF(-l,-l-2iP;-2l;-z^{-1})$$
$$U_4 = (-z)^{-l-1}F(l+1,l+1-2iP;2l+1;-z^{-1})$$ I am unsure how, given his solution in terms of G, the author knew which independent hypergeometric functions to use in the following steps to give the correct solution. Thank you in advance for any advice you can give me! EDIT: As I was unable to find them in the paper, I have calculated what I think are the correct boundary conditions. The requirement is that at the horizon, $r \rightarrow r_+$, there is only an ingoing wave solution. It is useful to know that in the above equations: $$ P = (am - 2Mr_+ \omega)/(r_+ - r_{-}) $$ $$ z = (r-r_+)/(r_+ - r_-)$$ then the boundary condition at $r \rightarrow r_+$ is $$R \sim (r-r_+)^{-i\alpha}$$
where $$ \alpha = \frac{Mr_+\omega-ma/2}{\sqrt{M^2-a^2}} $$","['special-functions', 'hypergeometric-function', 'ordinary-differential-equations', 'mathematical-physics']"
2276134,"What F-test is performed by $\texttt{lm()}$ function in R, at the end of the output?","I was wondering what is the F test (in general) that is done by the function $\texttt{lm()}$ in R. I mean you can  do different F tests, which one does it chose and how? For instance in a linear regression setting, I can fit a certain model with $\texttt{lm()}$ , but (before running the code) how do we know against which model it will be compared to? For instance look at this: For instance my model here is of the form $$Y_i= \beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\beta_3x_{i1}^2+\beta_4x_{i2}^2+\beta_5x_{i1}x_{i2}+\epsilon_i$$ but, before running this code, what F-test could I have expected to get out of $\texttt{lm()}$? And what test (here) has actually been performed?","['regression', 'statistics', 'hypothesis-testing']"
2276168,Let f be continuously differentiable on R. Let $f_n(x) = n\left(f\left(x + \frac1n\right) - f(x)\right)$.,"Let $f$ be continuously differentiable on $\mathbb R$. Let $f_n(x) = n\left(f\left(x + \frac1n\right) - f(x)\right)$. 
Then show that $f_n$ converges on $\mathbb R$, but not necessarily uniformly $f_n$ converges to the derivative of $f$ uniformly on $[0, 1]$. I could show that $f_n$ converges to derivative of $f$. But could not show the rest. Thanks","['sequences-and-series', 'uniform-convergence']"
2276178,Example of a sequence of closed and connected sets whose intersection is disconnected [duplicate],"This question already has answers here : Looking for a counter example for non-connected intersection of descending chain of closed connected sets (3 answers) Closed 4 years ago . How can I find an example of subsets which satisfies; for every $i \in \mathbb{N}$ $c_1 \supset c_2 \supset c_3 \supset \cdots \supset c_n$ which are closed and connected subsets of $\mathbb{R^k}$ then $\bigcap_{i=1}^\infty c_i$ is not connected. until now I have $c_n=\{[n,\infty) , n \in \mathbb{N}\}$ $\Rightarrow$ $\bigcap_{i=1}^\infty c_i=\varnothing$ which is I couldn't decide whether if it is connected or not connected. $d_n=\{ ( [-\frac{1}{n},\frac{1}{n}] \times \{0\}) \cup (\{0\}\times ([-1,1]\setminus \{0\})), n\in \mathbb{N}\}$ $\Rightarrow$  $\bigcap_{i=1}^\infty d_i= \{0\} \times [-1,1]$  which is connected. (here I want to seperate the vertical one from the point $(0,0)$ for not path connected implies not connected. If i rearrange  the $ [-1,1] \times \{0\}$ element -for not path connecting result-  as $(-1,1) \times \{0\}$ the set will be not closed but intersection is not connected.) Thanks in advance for your guidances :)","['general-topology', 'examples-counterexamples', 'connectedness']"
2276228,How many manifolds are there?,"I think there are three questions here, an answer to any would be interesting: How many compact manifolds are there? How many (not necessarily compact) manifolds are there? How many compact/not-compact manifolds of dimension $n$ are there? I know there exist uncountably many smooth structures on $\Bbb R^4$, so there are up to diffeomorphism uncountably many smooth manifolds. I also know there are only countably many compact $2$d manifolds. Here I would view to manifolds as being the same if there is a homeomorphism between them, but I would restrict to smooth manifolds and not to topological manifolds. These definitions are basically arbitrary, so I don't really mind if you take a different view.","['manifolds', 'general-topology', 'differential-geometry', 'differential-topology']"
2276274,Lift of symplectic form to the cotangent bundle,"Consider a symplectic manifold $(M,\omega)$ on which a Hamiltonian group action $G\curvearrowright M$ is defined. Then we have the usual canonical induced action of $G$ on $X:=T^*M$, that also preserves the fibration $\pi:X\to M$. My question is: Is there any symplectic form on $X:=T^*M$ that coincides with $\omega$ on the zero-section of $X$, that is also preserved by the induced action $G\curvearrowright X$ ? I realize that the question may seem too broad or vague, but I would very much appreciate any reference to articles or books addressing the question. Feel free to assume additional regularity on the manifold, like compactness or being Kähler.","['reference-request', 'group-actions', 'symplectic-geometry', 'kahler-manifolds', 'differential-geometry']"
2276282,Prove that for any $\epsilon >0$ there exists a measurable set $E$ such that $m(E)<\infty$ and $\int_E f>(\int f)-\epsilon$.,Let $f$ be a non-negative measurable function on $\mathbb{R}$ such that $\int f<\infty$. It is required to prove that for any $\epsilon >0$ there exists a measurable set $E$ such that $m(E)<\infty$ and $\int_E f>(\int f)-\epsilon$. The following is my attempt. Let $\epsilon >0$. Then there exists a simple function $\phi$ with $0\leq\phi\leq f$ such that $(\int f)-\epsilon<\int\phi$. Say $\sum_{k=1}^N a_k\ \chi_{E_k}$ is the canonical representation of $\phi$. Then $\int \phi=\sum_{k=1}^N a_k\ m(E_k)\leq\int f<\infty$. Define $E=\bigcup_{k=1}^N E_k$. Then $E$ is measurable and $m(E)<\infty$ and $\int \phi=\int_E\phi\leq\int_E f$. Hence the result. Is this proof correct? Someone please help. Thanks.,"['self-learning', 'lebesgue-integral', 'measure-theory', 'proof-verification']"
2276285,Application of Cauchy-Davenport,"Let $ p $ be a prime number and $ A \subset \mathbb{Z}/p\mathbb{Z} $. Suppose $ 0 \notin A $ and for $ a \in A $ define $ d(a)= \min\{k|-a \in \underbrace{A+A+ \dots +A}_\text{k  times} \} $. I want to show that $$ \sum_{a \in A}d(a) \leq p-1 $$ Using a simple generalization of the Cauchy-Davenport inequality, one has that $$ |\underbrace{A'+A'+ \dots +A'}_\text{k  times}| \geq \min\{p,k|A|+1\} $$where $ A'=A \cup \{0\} $ but I haven't figured out how to use this to prove the statement. As a side question, if $ 0 $ would belong to $ A $, then I guess $ d(0)=1 $ or is it $ 0 $ as this maybe is the definition of adding $ A $ $ 0$ times if that makes any sense? Otherwise, I don't see why in the original statement we can take $ 0 \notin A $. I would appreciate any help concerning the main question. Thank you!","['finite-fields', 'additive-combinatorics', 'number-theory', 'abelian-groups', 'combinatorics']"
2276367,"""Universal"" differential identities","I now asked this at MO . Let $f:\mathbb{R}^d \to \mathbb{R}$ be smooth. The mixed derivatives commute: $f_{xy}=f_{yx}$. This  identity is "" universal "" in the sense that it holds for any smooth map. Question: Are there any universal identities which are not consequences of the commutation of the mixed derivatives? More explicitly, let $D_i$ be the differential operator which takes the partial derivative with respect to $x_i$. The symmetry can be written as an algebraic statement $$    D_i \circ D_j = D_j \circ D_i \tag{1}.$$ (When we choose the domain for these operators to be the space of smooth maps $\mathbb{R}^d \to \mathbb{R}^d$, so we can compose operators). Consider the subset $A$ of differential operators (which map $C^{\infty}(\mathbb{R}^d) \to C^{\infty}(\mathbb{R}^d)$) that is ""generated"" by the $D_i$ via addition, composition and multiplication*. Note that this algebraic structure $A$ has $3$ binary operations. (I am not sure if there is a term for such an ""algebraic creature"", $A$ is a ring w.r.t both operations $(+,\cdot)$ and $(+,\circ)$, but this two operations have relations, namely $$(f \cdot g) \circ h = (f \circ h) \cdot (g \circ h),$$ they ""commute"". Does such a structure have a name? ""Concrete Question:"": Are there relations in $A$ which are not consequences of the fundamental relation $(1)$?. *By multiplication (as opposed to composition ) of operators I mean the following: $$D_x \times D_y(f)=f_x \cdot f_y \, , \,  D_x∘D_y(f)=f_{xy} \, , \, (D_x \circ D_x) \times D_y(f)=f_{xx}f_y$$ etc. (Here $f$ is a scalar function, to extend the operations to $\mathbb{R}^d$-valued maps, jut act on each component separately.  I am also allowing for the $i$-th component of output to depend on partial derivatives of all components of $f:\mathbb{R}^d \to \mathbb{R}^d$). The multiplication is needed in order to talk about relations of the form of $f_x f_y=f_yf_x$ (trivially true) or $f_{xx}=f_yf_{xy}$ (clearly not universal). 
(Without multiplication, there are no additional relations as observed in this answer ). In particular, I am interested to know whether the ""Cofactor Lemma"" (divergence-free rows, see below) is a ""consequence"" of the commutation of mixed derivatives (for dimension $d>2$ this involves multiplication, as well as addition and composition). The Cofactor Lemma: Let $f:\mathbb{R}^d \to \mathbb{R}^d$ be smooth. Then the Cofactor of $df$ has divergence-free rows : $$\sum_{j=1}^n \frac{\partial(Cof(Du))_{kj}}{\partial x_j} = 0, k=1,...,d.$$ In dimension $d=2$, it reduces to relation $(1)$: Given $A= \begin{pmatrix} a & b \\\ c & d \end{pmatrix}$,
$\operatorname{Cof}A= \begin{pmatrix} d & -c \\\ -b & a \end{pmatrix}$, so $$ df= \begin{pmatrix} (f_1)_x & (f_1)_y \\\ (f_2)_x & (f_2)_y \end{pmatrix},
\operatorname{Cof}df= \begin{pmatrix} (f_2)_y & -(f_2)_x \\\ -(f_1)_y & (f_1)_x \end{pmatrix} .$$ We see that $\operatorname{div} (\operatorname{Cof}df)=0$ is equivalent to $(f_1)_{xy}=(f_1)_{yx},(f_2)_{xy}=(f_2)_{yx}$. As stated above, for dimension $d>2$ we need multiplication to even phrase the question properly.","['congruence-relations', 'abstract-algebra', 'differential-operators', 'universal-property']"
2276370,An algebraic way to prove some identity,"I found the following fact accidentially. Fact :  Let $d, n \in \mathbb{N}$ and $n \geq d+2$. Suppose $\lambda_1, \ldots , \lambda_n$ are distinct complex numbers. Then the following holds;
$$ \sum_{k=1}^n \left[ \prod_{j=1 \\ j \neq k}^n \frac{1}{\lambda_k - \lambda_j} \right] \lambda_k^d = 0.$$ I was able to prove this via complex analysis. In fact consider the left side as a rational function of $\lambda_n \in \mathbb{C}$ and call it $f$. $f$ has sigularities at $\lambda_1, \ldots, \lambda_{n-1}$. However calculating the residue of $f$ at $\lambda_k$, we get
$$ \mbox{Res}(f, \lambda_k) = - \left[ \prod_{j=1 \\ j\neq k}^{n-1} \frac{1}{\lambda_k - \lambda_j} \right] \lambda_k^d + \left[ \prod_{j=1 \\ j\neq k}^{n-1} \frac{1}{\lambda_k - \lambda_j} \right] \lambda_k^d = 0$$
hence we see that those singularities are actually removable. Thus $f$ is entire. And since $n\geq d+2$, $f(\lambda_n) \to 0$ when $\lambda_n \to \infty$. By Liouville's theorem $f = 0$, as claimed. 
So my question is whether we can prove this identity in a purely algebraic way. I want to know this because, if there is a way, probably this identity can be extended to other fields than $\mathbb{C}$.","['algebra-precalculus', 'complex-analysis']"
2276374,Strang's proof of SVD and intuition behind matrices $U$ and $V$,"In lecture 29 of MIT 18.06, Professor Gilbert Strang ""proves"" the singular value decomposition (SVD) by assuming that we can write $A = U\Sigma V^T$ and then deriving what $U$, $\Sigma$, and $V$ must be based on the eigendecomposition of
$$ AA^T = U\Sigma ^2 U^T$$
and
$$ A^TA = V\Sigma ^2 V^T$$ My intuition tells me there's something wrong with first assuming that we can write $A$ in this form. As in, we are finding $U$, $\Sigma$ and $V$ for those matrices that have this form, but what if some matrices couldn't be written in this form in the first place? Also, is there some intuition to be found about $U$ and $V$ by only thinking about them as eigenvectors of $AA^T$ and $A^TA$? In the sense that we should be able to know why $V$ will have its properties (be mapped orthogonally by $A$) by just looking at it as an eigenvector of $A^TA$ (which somehow implicitly ""encodes"" the basis $U$). Not sure if this intuition makes sense either.","['matrices', 'svd', 'linear-algebra']"
2276401,$O_P(1) o_P(1) = o_P(1)$,"There is something written in the book ""Mathematische statistiek"" from van der Vaart which I don't see: ""it is short for: if $X_n$ is bounded in probability and $Y_n \rightarrow^P 0$ then $X_nY_n\rightarrow^P 0$. If $X_n$ would also converge in distribution, this would be Slutsky's lemma (with $c=0$). But by Prohorov's theorem $X_n$ converges in distribution 'along subsequences' if it is bounded in probability, so that this rule can still be deduced by arguing 'along subsequences'."" Now some subsequence $X_{n_j}$ converges in distribution and $Y_{n_j}$ converges in probability to $0$, so $X_{n_j}Y_{n_j}$ converges in distrubition to $0$ (Slutsky). I think we cannot conclude that also $X_nY_n$ converges to $0$ in distribution. But van der Vaart thinks differently. Can anyone say what he probably thinks?","['weak-convergence', 'statistics', 'probability']"
2276402,Limit of sequence in which each term is defined by the average of preceding two terms,"We have a sequence of numbers $x_n$ determined by the equality $$x_n = \frac{x_{n-1} + x_{n-2}}{2}$$ The first and zeroth term are $x_1$ and $x_0$.The following limit must be expressed in terms of $x_0$ and $x_1$
$$\lim_{n\rightarrow\infty} x_n $$ The options are: A)$\frac{x_0 + 2x_1}{3}$
B)$\frac{2x_0 + 2x_1}{3}$ C)$\frac{2x_0 + 3x_1}{3}$
D)$\frac{2x_0 - 3x_1}{3}$ Since it was a multiple choice exam I plugged $x_0=1$ and $x_1=1$. Which means that all terms of this sequence is $1$,i.e, $$x_n=1, n\in \mathbb{N} $$ From this I concluded that option A was correct.I could not find any way to solve this one hence I resorted to this trick. What is the actual method to find the sequence's limit?","['recurrence-relations', 'sequences-and-series', 'calculus', 'limits']"
2276411,Question about the relation between Expectation and Covariance,"I have a question regarding the relationship between the Expectation $E(X)$ and Covariance $Cov(X, Y)$. For reference, Wolfram MathWorld defines Expectation for a single discrete random variable as: $$E(f(X)) = \sum_{x}f(x)P(x)\qquad\qquad\qquad \cdots\qquad(i)$$ and Covariance of two discrete random variables as: $$Cov(X, Y) = E(XY) - E(X)E(Y)\qquad \cdots\qquad(ii)$$ But it also states the Covariance explicitly as: $$Cov(X, Y) = \sum_{i=0}^N\frac{(x_i - x_a)(y_i - y_a)}{N}\qquad \cdots\qquad(iii)$$ How do you get (iii) from (i) and (ii)? What happened to the P(x) and P(y)?","['statistics', 'probability', 'expectation', 'covariance']"
2276413,Derivative of the conjugate of a function,"In short, is the derivative of the conjugate of a function, the conjugate of the derivative of that function? We assume that the function is complex-valued. I think this property is true when the derivation variable is real, but my question is: if this is the case, can't we always do a change of variable so that we change from a real variable to a complex one? It's a bit confusing to me.",['complex-analysis']
2276416,A holomorphic function with poles at all $(2n)!$,"During a discussion, I was asking to find a function $f$ which is holomorphic on $$\mathbb{C}\setminus \{(2n)! : n \in \mathbb{N}\}.$$ Naturally, I wanted to set $$f(z) = \prod_{n=0}^{+\infty} \frac{1}{z-(2n)!}$$ but this product does not converge. (Remember that $\prod_n z_n$ is convergent if and only if $\sum_n |z_n-1|$ is convergent.) So finally, I set $$f(z) = \prod_{n=0}^{+\infty} \frac{(2n)!}{(2n)!-z}$$ which is holomorphic on the required domain. First, I'd like to know if someone has a better idea to find a holomorphic function on $\mathbb{C}\setminus \{(2n)! : n \in \mathbb{N}\}.$ (If possible with ""usual"" functions). I would also like to know if one can get interesting informations about the function $f$ I sat. For example, can we obtain its Taylor expansion on $D(0,1)$ ?","['complex-analysis', 'holomorphic-functions', 'taylor-expansion', 'complex-numbers']"
2276449,Are there infinitely many primes that avoid any particular finite string of digits?,"I just learned of this paper showing that for any particular decimal digit $d$, there are infinitely many prime numbers whose decimal numerals do not contain $d$. Is anything known about the obvious generalization, i.e., that for any particular finite string of decimal digits, there are there infinitely many prime numbers whose decimal numerals do not contain that string? Or, of course, similar results for other bases?","['number-theory', 'reference-request', 'prime-numbers']"
2276463,Lexicography Rule with a Tie - an example,"Using the Lexicography rule makes sure that the algorithm terminates. This example below is a classical example where there is a tie in the leaving variables which I am uncertain which variable should leave the basis. $$(P_1) \text{ }\text{max}\left \{ 3+x_1+2x_2+3x_3 \mid \begin{matrix}2x_1-x_2+2x_3 \leq 8\\-x_1+3x_2+3x_3 \leq 12\\ -x_1-x_2+5x_3 \geq -4\\ x_1,x_2,x_3 \geq 0
\end{matrix} \right \}$$ I firstly formed these inequations to equations: $2x_1-x_2+2x_3 +u_1 = 8$ $-x_1+3x_2+3x_3 +u_2 = 12$ $x_1+x_2-5x_3+u_3 = 4$ $x_1,x_2,x_3 \geq 0$ Now I started to make the simplex table: x1  |  x2 |  x3 |  u1  |  u2 | u3  |
_____|_____|_____|______|_____|_____|___
 2   | -1  |  2  |  1   |  0  |  0  |  8
-1   |  3  |  3  |  0   |  1  |  0  | 12
 1   |  1  | -5  |  0   |  0  |  1  |  4
_____|_____|_____|______|_____|_____|___
 1   |  2  |  3  |  0   |  0  |  0  |  0 We pick $x_3$ as the entering variable since it has the largest reduce cost. Now deciding which variable should leave the basis, we have row 1 $ (u_1): \frac{8}{2}=4$ and row 2 $ (u_2): \frac{12}{3}=4$ . There's a tie. What should I do?","['inequality', 'optimization', 'linear-programming', 'simplex', 'discrete-mathematics']"
2276470,Recursive sequence modulo 4,"For all odd positive integers $k$, I define a recursive sequence by
$$
d_k=2+ {k\choose 1}d_{k-2} + {k\choose 2}d_{k-4} + \dots +{k\choose \frac{k-1}{2}}d_1\\
d_1=2
$$ I want to study this sequence modulo $4$. By induction, it is easy to see that $d_k$ is either $0$ or $2$. Computing this sequence I get 
$$
2,0,2,2,0,2,2,0,2,2,0,2,2,0,2\dots (\mod 4)
$$
which made me think that
$$
d_k\equiv 0 (\mod 4)\text{  if and only if  } k\equiv 0 (\mod 3)
$$ Do you have an idea how to prove that? I tried to prove but I don't find any nice behavior on the binomial coefficients that helps me.","['number-theory', 'binomial-coefficients', 'arithmetic']"
2276507,Action of Weyl group on the dual Cartan subalgebra in bad characteristic,"I am interested in an analogue of Proposition 14.31 in Fulton and Harris' book 'Representation Theory: A First Course' for positive characteristic. Let $G$ be a semisimple algebraic group of adjoint type defined over an algebraically closed field $K$ of characteristic 2, and $\mathfrak{g} = Lie(G)$. Suppose that $\mathfrak{g}$ is a Lie algebra of classical type $B, C$ or $D$. Let $T$ a maximal torus of $G$, and $W = N(T)/T$ the Weyl group of $T$. Set $\mathfrak{h} = Lie(T)$, a Cartan subalgebra of $\mathfrak{g}$, and let $\mathfrak{h}^*$ denote the dual vector space of $\mathfrak{h}$. Since I am working in bad characteristic, I don't have a $G$-equivariant isomorphism $\mathfrak{h} \to \mathfrak{h}^*$. Now Fulton and Harris state that, in characteristic 0, the Weyl group $W$ acts irreducibly on $\mathfrak{h}^*$. Their proof requires that $\mathfrak{g}$ is a simple Lie algebra, which is not true in general over fields of characteristic 2, and that such a $G$-equivariant isomorphism $\mathfrak{h} \to \mathfrak{h}^*$ exists. It's easy enough to see that their proof works for fields of positive characteristic $p > 2$, since in this case the characteristic of $K$ is very good for $G$ and one can just apply the given proof in this situation. Is it true that, when the characteristic of $K$ is 2, $W$ has an irreducible action on $\mathfrak{h}^*$, or does this property fail? Any reference or counterexample would be appreciated.","['representation-theory', 'algebraic-groups', 'group-theory', 'lie-algebras']"
2276509,Trivial AP Statistics Problem 2012: Confidence Intervals of a survey,"I assume that this problem is trivial but I am not sure what to do:
In a survey of 900 people in the US a journalist says that 60% of people support a new law. If the margin of error is 2.7% for the percentage, what is the level of confidence?","['statistics', 'confidence-interval']"
2276573,List of trig identities with proofs [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I want a list of trig identities with available proofs, not just observations. And they cannot be proven by other trig identities without proofs themselves! For example, we know that: $$\tan x = \frac{\sin x}{\cos x}$$ Well, if we use Soh Cah Toa, then we know that : $$\tan x = \frac{O}{A}, \cos x = \frac{A}{H}, \sin x = \frac{O}{H}$$ $$\tan x = \frac{\sin x}{\cos x} = \frac{\frac{O}{H}}{\frac{A}{H}}=\frac{O}{A} = \tan x$$ This proof is a proof without other trig identities. Are there any other identities with proof like this? I want either the proof itself in this article or the link that it is available to show the proof. Optional: You can also make a list of identities without a proof.",['trigonometry']
2276625,"Affine Maps, Matricies, Invertibility, and Equivalence Relations","A mapping $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ is affine if there is an invertible $n$ x $n$ matrix $M$ and a vector $s \in \mathbb{R}$ such that $f(x)=Mx+s$ for every $x \in \mathbb{R}^n$. Show that every affine map $f(x) = Mx+s$ is invertible and its inverse is also affine? Show that the composition of affine maps $\mathbb{R}^n \rightarrow \mathbb{R}^n$ is affine. For two subsets, $S$, $T$ of $\mathbb{R}^n$, write $S \sim T$ if there exists an affine map $f$ such that $f(S) =T$. We then say that $S,T$ are affine-related . Prove that $\sim$ is an equivalence relation on the set of subsets of $\mathbb{R}^n$.","['linear-programming', 'equivalence-relations', 'linear-algebra', 'linear-transformations']"
2276686,Value of expression involving coefficients of an equation and its complex roots.,"It is given that $\cos\alpha + i \sin\alpha$ is the solution of the equation $$x^n + P_1x^{n-1}+ \cdots +P_n=0$$ where all the coefficients are real. Then what is the value of $$P_1\sin\alpha+P_2\sin2\alpha+ \cdots + P_n \sin n\alpha$$ By substituting $n=1$ and $P_n$ an arbitrary real value, it is easily seen that $\alpha=n\pi$ and hence the value is $0$. But how can this be proved for any values of $n$ and the other co-efficients in the equation?","['algebra-precalculus', 'complex-numbers']"
2276701,"Collection of sets, where each pair of sets has at most one element in common","Let $S_1,\dots,S_m \subseteq \{1,2,\dots,n\}$ be a collection of sets, each of size $k$.  I'll say that they are almost-disjoint if, for every $i,j$ with $i\ne j$, we have $|S_i \cap S_j| \le 1$, i.e., each pair of sets has at most one element in common. Is there an asymptotic upper-bound on the largest possible value of $m$, as a function of $n,k$, for any almost-disjoint collection of sets? In particular, suppose $k=n^c$, for some $0 \le c \le 1$.  Can I upper-bound $m$ as $m=O(n^{f(c)})$, for some function $f$?  What's the best upper bound known? If I replace ""almost-disjoint"" with ""disjoint"", the problem becomes an easy application of the pigeonhole principle; we find $m = O(n^{1-c})$.  However, I don't know how to deal with the generalization to almost-disjoint collections.  Is there some generalization of the pigeonhole principle that is applicable here?  This question arose in the analysis of an algorithm I was thinking about.  I wondered if it might be related to some kind of combinatorial design but I couldn't match it to any existing concept I know of. We can use the projective plane over a finite field to construct an almost-disjoint collection of sets with $k=\Theta(n^{1/2})$ and $m=\Theta(n)$.  That gives a lower bound.  I'm hoping to get an upper bound on $m$ that is better than $m = O(n)$, so this implies I need to restrict attention to the case $c>1/2$.","['combinatorial-designs', 'combinatorics', 'pigeonhole-principle', 'discrete-mathematics']"
2276721,$\int \frac{x^4-1}{x^2\sqrt{x^4+x^2+1}}dx$,"$$\int \frac{x^4-1}{x^2\sqrt{x^4+x^2+1}}\,dx$$ My attempt, I changed it to $\int \frac{x^2}{\sqrt{x^4+x^2+1}} \, dx-\int \frac 1 {x^2\sqrt{x^4+x^2+1}} \, dx$, but I stuck here. Any method to solve this integral? Thanks in advance.","['integration', 'calculus']"
2276723,Property of Vectors of an n-gon,"Let ${P_1,..., P_n}$ be the vertices of a regular n-gon in the plane, and $O$ it's center; show without computation or coordinates that ${\overrightarrow {OP_1} + \overrightarrow {OP_2} + ... + \overrightarrow {OP_n}} = 0$ a) if n is even b) if n is odd My attempt at solving this problem makes use of the fact that if we have any closed polygon in the plane which does not cross itself with vertices ${P_1,..., P_n}$, the following holds true: ${\overrightarrow {P_1P_2} + \overrightarrow {P_2P_3} + ... + \overrightarrow {P_nP_1}} = 0$. Say we constructed vectors ${\overrightarrow {A_1}, \overrightarrow {A_2},... \overrightarrow {A_n}}$ where $\overrightarrow {A_1}$ is a vector with the same magnitude as $\overrightarrow {P_1P_2}$ rotated $\theta°$ counter-clockwise to it in the plane, $\overrightarrow {A_2}$ is a similar vector for $\overrightarrow {P_2P_3}$ etc, then we can say that ${\overrightarrow {A_1} + \overrightarrow {A_2} + ... + \overrightarrow {A_n}} = 0$. If we arbitrarily scaled the magnitudes of all the vectors ${\overrightarrow {A_1}, \overrightarrow {A_2},... \overrightarrow {A_n}}$ then the fact above still holds. If we rotated these vectors all by the same angle in the same direction then the fact above still holds. Using this logic, I think we can conclude that ${\overrightarrow {OP_1} + \overrightarrow {OP_2} + ... + \overrightarrow {OP_n}} = 0$ as the vectors formed by joining $O$ to ${P_1,..., P_n}$ all have the same magnitude and the heads of these vectors are touching the vectors ${\overrightarrow {P_1P_2},  \overrightarrow {P_2P_3}, ..., \overrightarrow {P_nP_1}} = 0$., ie they are scaled down by some factor and rotated by some angle $\theta$ which is dependent on the number of sides of the regular n-gon $n$. I now do not know if this logic is sound and it doesn't explain why the question is asking for the case when $n$ is a) even and b) odd.","['vectors', 'geometry']"
2276728,Alternating group $A_5$ has subgroup of order $6$ (group theory),"In my lectures, I've read that $A_5$ $($the alternating group of even length cycles in $S_5$$)$, has a subgroup of order $6$, and the example is: the group generated by $\langle (12) (34), (123)\rangle$. I don't even understand what group we are generating? Wasn't a cyclic group only generated by one element? Why would this group be of order $6$?","['cyclic-decomposition', 'group-theory', 'cyclic-groups']"
2276746,"Given that $x+\frac{1}{x}=\sqrt{3}$, find $x^{18}+x^{24}$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Given that $x+\frac{1}{x}=\sqrt{3}$, find $x^{18}+x^{24}$ Hints are appreciated. Thanks in advance.",['algebra-precalculus']
2276749,$a+b\sqrt{-3}$ and $a-b\sqrt{-3}$ are coprime in $\mathbb{Z}+ \omega \mathbb{Z}$,"I want to prove that $a+b\sqrt{-3}$ and $a-b\sqrt{-3}$ are coprime in $\mathbb{Z}+ \omega \mathbb{Z}$ with $\omega$ a primitive third root of unity and $\gcd(a,b)=1$. Approach: Assume they are not, let $s$ be an irreducible factor of $a+b\sqrt{-3}$ and $a-b\sqrt{-3}$, then $s|2b\sqrt{-3}$. Then $N(s)|6b^2$ and $N(s)|(a^2+3b^2)$.... Can someone help me how to approach a contradiction from this? Thanks in advance!!","['number-theory', 'algebraic-number-theory']"
2276757,Branches in complex analysis,"I still don't get how to work with branches. I understand that it is a way to define continous multivalued functions, but how to apply it to an specific problem I still don't know how to do it. Here is an exercise from Gamelin's Complex analysis (p53): Consider the branch of $f(z)=\sqrt{z(1-z)}$ on $\mathbb{C}-[0,1]$ that has positive imaginary part at $z=2$. What is $f'(z)$? Be sure to specify the branch of the expression for $f'(z)$? I have several questions: Regarding the function $f(z)=\sqrt{z(1-z)}$. I know that this function have ""two special points"", at $z=0$ and $z=1$, meaning that if I make a turn around one of these points, I get an extra phase. Question: why I mus exclude $[0,1]$, and not just the points $0$ and $1$? There is no problem in getting the derivative (it's just routine calculus), but what does it mean ""... that has positive imaginary part at $z=2$""? Finally, how do I get the branch expression for $f'(z)$ and why to choose that branch?",['complex-analysis']
2276758,Computing expected value of a local function under global constraints,"I have a distribution on $\mathbb{Z}^n$: $$p_X(x;a)=\begin{cases} C \prod\limits_{i=1}^n a^{|x_i|} & \sum\limits_{i=1}^n i x_i = 0 \text{ and } \sum\limits_{i=1}^n x_i=0\\ 0 & \text{otherwise} \end{cases}$$ where $a \in (0,1)$ is a parameter and $C$ is a normalization constant. I am looking to compute the expected value of a certain bounded function $f$ depending on $(X_1,X_2)$ only; beyond that I don't think the identity of $f$ is relevant. I actually just want to compute $\lim_{n \to \infty} E[f(X)]$, so estimation is OK provided it becomes exact as $n \to \infty$. It is clear that without the constraints, the $X_i$ would be independent and identically distributed. My intuition suggests that the sum constraints become ""delocalized"" as $n \to \infty$, so that the joint distribution of any fixed subset of the $X_i$ should not ""see"" them. Thus I expect to see $P(X_1=x_1,X_2=x_2) \approx C a^{|x_1|} a^{|x_2|}$ (for a new $C$ of course).  In this case the expectation is straightforward to calculate for the particular $f$ I have in mind. However, I am not quite certain of how to justify this approximation. I am aware of this paper: https://projecteuclid.org/download/pdf_1/euclid.cmp/1104178139 In section 2 of this paper, the authors consider a very similar problem, but instead it has $\sum\limits_{i=1}^n i x_i = V$ where $V$ is proportional to $n^2$. As best I can tell this form of the constraint is essentially ""baked into"" their technique, but I may be missing some way to adapt it. Any suggestions would be very helpful. I notice now that this little $2 \times n$ linear system can be explicitly solved; you have $x_1=\sum_{i=3}^n (i-2) x_i$ and $x_2=-\sum_{i=3}^n (i-1) x_i$, with the other $x_i$ being free variables. Thus the expected value with the constraints looks like $$C \sum_{(x_3,\dots,x_n) \in \mathbb{Z}^{n-2}} \left ( \prod_{j=3}^n a^{|x_j|} \right ) f \left ( \sum_{i=3}^n (i-2) x_i,-\sum_{i=3}^n (i-1) x_i \right ) a^{\left | \sum_{i=3}^n (i-2) x_i \right |} a^{\left | \sum_{i=3}^n (i-1) x_i \right |}.$$ Thus my approach to the problem seems to boil down to showing that $g(y,z)=\sum_{x \in S_n(y,z)} \prod_{i=1}^{n-2} a^{|x_i|}$ where $S_n(y,z)=\left \{ x \in \mathbb{Z}^{n-2} : \sum_{i=1}^{n-2} i x_i = y,\sum_{i=1}^{n-2} x_i=z \right \}$, is in some sense ""asymptotically constant""...perhaps this approach is oversimplified, then?","['probability-theory', 'statistical-mechanics']"
