question_id,title,body,tags
4828234,Evaluating $\int \frac{dx}{\sin x \sqrt{k^2+\sin^2 x}}$,"Let $k$ and $x$ be real numbers. Let: $$I= \int \frac{dx}{\sin x \sqrt{k^2+\sin^2 x}}$$ Let $u=\sin x$ , then $du=\sqrt{1-u^2}dx$ . Then $$I= \int \frac{du}{u\sqrt{k^2+u^2}\sqrt{1-u^2}}$$ To go further any recommendations? Not sure if $u=k\tan y$ may help.","['integration', 'indefinite-integrals', 'calculus', 'trigonometric-integrals']"
4828244,Is the irreducible $ SU(3) $ subgroup of $ SU(6) $ maximal?,"Is the 6 dimensional $ (2,0) $ irrep of $ SU(3) $ maximal in $ SU(6) $ ? For those of you who are interested in context, I started wondering this the other day when I tried to write down the maximal subgroups of $ SU(6) $ . My guess so far is that the full list of maximal (proper closed) subgroups of $ SU(6) $ is: Type I (normalizer of maximal connected subgroup) \begin{align*}
& U(5) \cong S(U(5) \times U(1)) \\
& S(U(4) \times U(2)) \\
& S(U(3) \times U(3))\rtimes S_2 \\
& 6 \circ_2 Sp(3)  \\
& 6 \circ_2 SO(6)  \\
& 6 \circ_3 SU(3)_{irr}
\end{align*} Type II (finite maximal closed subgroup, for the last 2 groups GAP subscripts are used to label the center and the outer automorphisms when multiple groups of this structure description exist) \begin{align*}
& 6.A_7
 \\
&6.PSL(3,4).2_1
 \\
&6_1.PSU(4,3).2_2
\end{align*} Type III (normalizer of a subgroup which is connected but not maximal connected) \begin{align*}
& N(T^6)=S(U(1) \times U(1) \times U(1) \times U(1) \times U(1) \times U(1)) \rtimes S_6\\
&S( U(2) \times U(2) \times U(2) ) \rtimes S_3\\
\end{align*} Note on notation. $ \rtimes $ means split extension (semidirect product). $ \cdot $ means nonsplit extension. $ \circ $ denotes central product, in most cases here we have $ 6 \circ_2 H $ , which is just the group generated by $ H $ and $ \zeta_6I $ but that group is not a direct product since already $ -I \in H $ , we get a central product essentially with three $ H $ components. Similar idea for $ 6 \circ_3 SU(3)_{irr} $ having two components. Here $ N $ denotes normalizer. Recall that a positive dimensional (type I and type III above) maximal subgroup of a simple Lie group equals the full normalizer of its identity component. https://arxiv.org/pdf/math/0605784.pdf classifies all maximal closed subgroups of $ SU(n) $ whose identity component is not simple (here trivial counts as simple). According to table 5 the maximal closed subgroups of $ SU(4) $ of this type are: The normalizer of the maximal torus (row 4 table 5, $ \ell=6, p=1 $ ) $$
 N(T)=S(U(1) \times U(1) \times U(1) \times U(1)) \rtimes S_6
$$ and (row 4 of table 5, $ \ell=3, p=2 $ ) $$
S( U(2) \times U(2) \times U(2) ) \rtimes S_3
$$ As well as (row 1 table 5, $ p=5,q=1 $ ) $$
S(U(5) \times U(1) )\cong U(5) 
$$ and (row 1 table 5, $ p=4,q=2 $ ) $$
S(U(4) \times U(2) ) 
$$ and the normalizer of $ S(U(3) \times U(3))= \{\begin{bmatrix} A & 0 \\ 0 & B \end{bmatrix}:A,B\in U(3),det(A)det(B)=1 \} $ which is a split extension (row 1 table 5 $ p=q=3 $ ) $$
< S(U(3) \times U(3)),SWAP_{\oplus}> \cong S(U(3) \times U(3)) \rtimes S_2
$$ where the normalizing matrix $ SWAP_{\oplus}=\begin{bmatrix}  0 & 0 & 0 & 0 & 0 & 1\\ 0 & 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 & 0 &  0 \\ 0 & 0 & 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 & 0 \\ 1 & 0 & 0 & 0 & 0 & 0 \end{bmatrix} $ swaps the two blocks in the direct sum. Next, we consider maximal closed subgroups with nontrivial simple connected component. By dimension, such a subgroup would be isogeneous to $ SU(2),SU(3),Sp(2), G_2, SU(4), SO(7), Sp(3), SU(5), SO(8) $ of dimensions $ 3,8,10,14,21,21,24,28 $ respectively. Of these the only one with 6d irreps are: 6d irrep of $ SU(2) $ , the $ (2,0) $ 6d  irrep of $ SU(3) $ , fundamental irrep of $ Sp(3) $ , Of these only $$
6 \circ_2 Sp(2)=<\zeta_6 I,Sp(3)>
$$ is maximal subgroup of $ SU(6) $ . Even dimensional irreps of $ SU(2) $ are always symplectic so all $ SU(2) $ subgroups of $ SU(6) $ are contained in a conjugate of $ Sp(3) $ . See Understanding the 4 dimensional irrep of $ SU_2 $ Finally we consider subgroups with trivial connected component. These are finite since $ SU(6) $ is compact. To be maximal they must at least be primitive. For example there is a very large $ 6 \circ_2 2.J_2 $ subgroup of $ SU(6) $ but it is not maximal because it is not even Lie primitive: it is contained in $ 6 \circ_2 Sp(3) $ . Also there is an $ A_7 $ subgroup that is not Lie primitive, it is contained in $ SO(6) $ since it is the standard $ A_{n+1} $ subgroup of $ SO(n) $ arising from the deleted permutation representation. Even Lie primitive subgroups may not be maximal if they are contained in another larger Lie primitive finite subgroup. For example there is a subgroup $ 3.A_7 \subset 6.PSU(4,3) \subset SU(6)  $ which is Lie primitive but not maximal. A maximal finite subgroup which is irreducible in the adjoint representation is always a maximal closed subgroup. This includes the following subgroups
The central product $$
6.A_7
$$ of order $ 6(2,520)=15,120 $ (maximal closed since it is maximal finite and a 2-design) $$
6.PSL(3,4).2_1
$$ of order $ 6(20,160)2 $ (maximal closed since it is maximal finite and a 3-design). $$
6_1.PSU(4,3).2_2
$$ of order $ 6(3,265,920)2 $ (maximal closed since it is maximal finite and a 3-design). For references on designs and maximality see Finite maximal closed subgroups of Lie groups This is consistent with the fact
that a maximal $ 2 $ -design group is maximal closed ( all $ 3 $ designs are $ 2 $ designs).","['maximal-subgroup', 'representation-theory', 'finite-groups', 'group-theory', 'lie-groups']"
4828251,Can the set of sequences such that $\frac{b_n}{a_n}$ is unbounded be specified by a countable base of sequences $\{f_n\}$,"Introduction : Let $A$ be the set of non-negative sequences $\{a_n\}$ such that $\sum_{n\geq 1} a_n=1$ . Suppose we have a positive sequence $\{a_n\}\in A$ . Consider the set $B\subseteq A$ of sequences $\{ b_n \}$ such that $\sum_{n\geq 1} b_n=1$ and $\left\{\frac{b_n}{a_n}\right\}$ is unbounded. Observe that both $B$ and $A\setminus B$ are convex. For any $\{b_n\}\in B$ there exists a sequence $\{f_n\}$ such that $\sum_{n\geq 1} a_n f_n<\infty$ and $\sum_{n\geq 1} b_n f_n=\infty$ . Indeed if we let $n_k$ be such that $k\leq \frac{b_{n_k}}{a_{n_k}}$ and we let $f_{n_k}=\frac{1}{a_{n_k} k^2}$ and $f_n=0$ otherwise, then \begin{align*}
\sum_{n\geq 1} a_n f_n &= \sum_{k\geq 1} a_{n_k} f_{n_k}=\sum_{k\geq 1} \frac{1}{k^2}<\infty\\
\sum_{n\geq 1} b_n f_n &= \sum_{k\geq 1} b_{n_k} f_{n_k}=\sum_{k\geq 1} \frac{1}{k^2}\cdot\frac{b_{n_k}}{a_{n_k}}\geq \sum_{k\geq 1} \frac{1}{k}=\infty
\end{align*} It is also clear that if $\{ b_n\}\in A\setminus B$ then there is $x>0$ such that $\left\{  \frac{b_n}{a_n}\right\}$ is bounded by $x$ , and so $\sum_{n\geq 1} b_n f_n\leq x\sum_{n\geq 1} a_n f_n$ and so if $\sum_{n\geq 1} a_n f_n<\infty$ then $\sum_{n\geq 1} b_n f_n<\infty$ . All this means that we can write \begin{align*}
B &= \left\{ \{b_n\} \in A : \exists \{f_n\}, \sum_{n\geq 1} a_n f_n < \infty = \sum_{n\geq 1} b_n f_n \right\}\\
&=\bigcup_{\{ f_n \}\in F} B_{\{f_n\}}
\end{align*} with $F=\left\{\{f_n\} : \sum_{n\geq 1} a_n f_n < \infty \right\}$ and $B_{\{f_n\}}=\left\{ \{b_n\} \in A : \sum_{n\geq 1} b_n f_n=\infty \right\}$ . Problem : My question is the following : Is there a countable subset $G\subset F$ such that $B=\bigcup_{\{f_n\}\in G} B_{\{f_n\}}$ ? Attempt : In case of a negative result, it might be possible to construct a ""Cantor's diagonal"" like argument by assuming that such a countable set doesn't exists. I have being trying to characterize the inclusion $B_{\{ f_n\}} \subseteq B_{\{ g_n \}}$ by giving an appropriate comparison test on $\{ f_n \}$ and $\{ g_n \}$ without success. Any idea would be very much appreciated.","['measure-theory', 'real-analysis', 'sequences-and-series', 'convergence-divergence', 'convex-analysis']"
4828255,A troubling differential equation: $(xy+2y+x+2)y'=e^{-y}(x+3)$,"Of course, I found this to be sort of troubling, you might not. So this is a differential equation that I came up with about 3 days ago that has taken me quite a while to solve (for some reason): $$(xy+2y+x+2)y'=e^{-y}(x+3)$$ which although I did solve it, I really am not sure if I made any incorrect assumptions while solving it or if my solution is incorrect. Here is my solving process: Right away I noticed that I could factor the $xy+2y+x+2$ as $(x+2)(y+1)$ , and dividing both sides by $x+2$ gets $$(y+1)y'=(e^{-y})\dfrac{x+3}{x+2}$$ and then I can multiply both sides by $e^y$ gets $$(y+1)y'e^y=\dfrac{x+3}{x+2}$$ which we can rewrite as $$(y+1)e^ydy=\dfrac{x+3}{x+2}dx$$ and this is where I feel like I might have made a mistake somewhere. I know the integral on the right hand is $x+\ln|x+2|+c_0$ , but the left hand side is a bit weird. I know I can write the left hand side as $$\int(y+1)e^ydy=\int ye^y+e^ydy=\int ye^ydy+e^y+c$$ but I was unsure on how to evalute $\int ye^ydy$ . I decided to use IBP (integration by parts) and got that the integral on the left hand side was equal to $\int(y+1)e^ydy=ye^y+c_1$ which now we can subtract $c_1$ from both sides and then take Lambert's $W$ function to find that $$y(x)=W(x+\ln|x+2|+b),b=c_0-c_1$$ but my question is Is my solution correct, or did I make any incorrect assumptions/get the wrong solution?","['calculus', 'solution-verification', 'ordinary-differential-equations', 'recreational-mathematics']"
4828257,How to calculate 2 unknown angles of a equilateral non-equiangular pentagon given 3 known angles? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 months ago . Improve this question I'm trying to figure out how to calculate 2 unknown angles of a equilateral non-equiangular pentagon given 3 known angles. My intuition tells me there should only be one solution for the resulting 2 angles but I do not know how to work it out. I've added this illustration of the problem. Here is another variation of the problem with 2 known angles. And here is another variation of the problem given 2 angles. The 2 angle problems will have two solutions if the pentagon can go concave, but if we restrict it to a convex equalateral pentagon there should just be one solution. Right?",['geometry']
4828282,Disjoints subsets of a multilabeled set,"We are given a set of elements $U$ and $n$ binary functions, i.e. $f_i: U \to \{0,1\}$ . Moreover, each function maps exactly $k$ elements of $U$ to 1. The task is to create a collection of $n$ disjoint sets $S_i$ satisfying the following property: $$ \forall S_i\ \forall j \ne i\ \exists e \in S_i: f_j(e) = 1$$ The question is what is the minimum $k$ so that the above construction is possible. My work so far: let $g(n)$ denote the minimum $k$ . Clearly, $g(n) \ge n-1$ . However, if $g(n) = n-1$ but every $f_i$ maps the same subset of $U$ to 1 the construction is not possible. Thus $g(n) \ge n$ . I also have an upper bound, $g(n) \le (n-1)^2$ . Consider the following algorithm: in round $i$ , if $S_j$ does not include an element $f_i$ maps to 1 we add one such element to $S_j$ . Before round $n$ begins, we have $$\left\lvert\bigcup_i S_i\right\rvert = (n-1)\cdot (n-2) + (n-1) = (n-1)^2$$ thus if $g(n) \ge (n-1)^2$ the assignment is possible. Observations $g(2) = 2$ and $g(3) = 3$ . I can provide proofs if needed. Also it gets annoyingly more complex to compute $g(4)$ . For every $e \in U$ we can see the vector $f_1(e), \dots, f_n(e)$ as a $n$ -bit binary label, hence my title We can reduce $U$ to $U'$ such that $U'$ contains only elements that at least one function maps to 1 My intuition is that there is some connection between my problem and some (multi)graph edge coloring problem or bipartite coloring but I am not sure exactly what I am looking for. Any ideas? Edit:
I found a different formulation and think it may be helpful to include it. Assume for now that we strengthen the needed property to $$ \forall S_i\ \forall j\ \exists e \in S_i: f_j(e) = 1$$ Consider the universe of elements $U = \{1,\dots,n\}$ and a collection of $m$ subsets of $U$ such that each $i \in U$ appears at  exactly $k$ of the $m$ sets. What is the least $k$ so that we can create $n$ non overlapping set covers of $U$ , i.e. no two set covers share a subset. To return to my original question let me define the ""almost set cover"" $C_i$ as the set cover of $U\setminus i$ . Then the question is what is the least $k$ so that we can create all the almost set covers without overlap. (Edit 3: based on the set cover formulation I also asked the question here ) Edit 2:
A refinement of the upper bound is achievable via the pigeonhole principle. Before round $n$ begins, there  are $n-1$ nests of size $n-2$ and 1 nest of size $n-1$ . Thus if $g(n) \ge (n-2)^2 + n-1 + 1 = n^2 - 3n + 4$ the construction is once again possible.
Also, this hints at a way to improve the upper bound a bit more: for instance if $g(n) = n^2 - 3n + 3$ we can only fail by one element in the last round. That can only occur when there are two elements $e, e'$ assigned in $S_i$ and $S_n$ respectively at round $t$ such that $f_t(e) = f_t(e') = 1$ and $f_n(e) =0, f_n(e')=1$ . Then we can simply swap them and we lowered the bound by 1.","['graph-theory', 'combinatorics', 'extremal-combinatorics', 'coloring']"
4828298,Connectedness of a certain space with closed retracts but non-unique sequential limits,"M W cleverly answered my question at https://mathoverflow.net/questions/454997/ asking for a space without unique sequential limits, but with closed retracts, using this example: Let $X=[0,\infty)\cup \{\infty_1,\infty_2\}.$ The topology on $[0,\infty)$ is the usual Euclidean topology, a neighborhood base of $\infty_1$ is given by sets of the form $\{\infty_1\}\cup (a,\infty)\backslash 2\mathbb N$ , and a base for $\infty_2$ by sets of the form $\{\infty_2\}\cup (a,\infty)\backslash (2\mathbb N +1)$ . I'm making a contribution to pi-Base to give a result for this search , and would like to include properties on its connectedness. For example, it is certainly connected: Consider a clopen subset $C$ of the space containing $\infty_1$ . Note $\infty_2$ is in the closure of any neighborhood of $\infty_1$ , so $\infty_2\in C$ . Then, any proper open neighborhood of both $\infty_1$ and $\infty_2$ is of the form $(a,\infty)\cup\{\infty_1,\infty_2\}$ ; but this is not closed, so we conclude $C=X$ . But what about path connected? Strongly connected? Biconnected?","['general-topology', 'connectedness']"
4828323,Show that no arbitrage implies the extension property in $L^p$,"Let $(\Omega,\mathcal F,P)$ be a probability space, and let $X:=L^p$ denote the normed space of (equivalence classes) of $p$ -integrable real random variables on $(\Omega,\mathcal F,P)$ , where $1\leq p<\infty$ . Definition. Let $M$ be a subspace of $L^p$ and $\pi:M\to \mathbb R$ be a linear functional on $M$ . We say that $(M,\pi)$ has the extension property if there exists a strictly positive continuous linear functional $\psi:X\to \mathbb R$ such that $\psi|_M=\pi$ . Strictly positive means $\psi(x)>0$ if $x\in L_+^p\setminus\{0\}$ , where $L_+^p=\{x\in L^p : x\geq 0\}$ . Let $M_0=\{m\in M: \pi(m)=0\}$ and let $C=M_0-L_+^p$ . Suppose the no arbitrage condition $$\bar{C}\cap L_+^p=\{0\}$$ holds, where $\bar{C}$ denotes the closure of $C$ . It follows from the Kreps-Yan theorem that there exists a strictly positive continuous linear functional $g:X\to \mathbb R$ such that $g|_C\leq 0$ . How can I use this to show that $(M,\pi)$ has the extension property? This claim is made right after Theorem 1.4 here . Thanks a lot for your help. Edit: The condition $g|_C\leq 0$ implies that the null space of $\pi$ is a subspace of the null space of $g|_M$ . Using this result we get that $g|_M=\lambda \pi$ for some $\lambda\in\mathbb R$ . If $\lambda>0$ then $\psi=\frac{1}{\lambda}g$ gives the desired extension. But how to deal with the case $\lambda\leq0$ ?","['lp-spaces', 'finance', 'functional-analysis', 'hahn-banach-theorem']"
4828351,A result in multivariable statistics,"I'm having problems proving the following result: $$\sum ^{n}_{i=1}(\underline{X_{i}} - \underline{\mu})(\underline{X_{i}} - \underline{\mu})^{T} = \sum^{n}_{i=1}(\underline{X_{i}}-\overline{\underline{X}})(\underline{X_{i}}-\overline{\underline{X}})^{T}+n(\overline{\underline{X}}-\underline{\mu})(\overline{\underline{X}}-\underline{\mu})^{T}$$ Where $\underline{X_{i}}$ is the notation for a vector.
This is what I tried to do: $$\sum^{n}_{i=1}\left[(\underline{X_{i}})-\overline{\underline{X}})(\underline{X_{i}}-\overline{\underline{X}})^{T} + (\underline{X_{i}}-\overline{\underline{X}})(\overline{\underline{X}}-\underline{\mu})^{T}+(\overline{\underline{X}}-\underline{\mu})(\underline{X_{i}}-\overline{\underline{X}})^{T}+(\overline{\underline{X}}-\underline{\mu})(\overline{\underline{X}}-\underline{\mu})^{T}\right]$$ $$\sum^{n}_{i=1}\left[(\underline{X_{i}}-\overline{\underline{X}})(\underline{X_{i}}-\overline{\underline{X}})^{T} + (\underline{X_{i}}-\overline{\underline{X}})(\overline{\underline{X}}-\underline{\mu})^{T}+(\overline{\underline{X}}-\underline{\mu})(\underline{X_{i}}-\overline{\underline{X}})^{T}\right]+n(\overline{\underline{X}}-\underline{\mu})(\overline{\underline{X}}-\underline{\mu})^{T}$$ But I don't understand why $(\underline{X_{i}}-\overline{\underline{X}})(\overline{\underline{X}}-\underline{\mu})^{T}$ apparently equals 0.
Any help would be appreciated thank you!","['multivariable-calculus', 'statistics', 'linear-algebra']"
4828392,Recursion that never halts,"Let $a$ and $b$ be (not necessarily proper) subsets of $\mathbb{Z}$ . Let the operator $\oplus$ be defined recursively as follows: $$a \oplus ∅ = a$$ $$a \oplus b = (a△b) \oplus (a \cap b)^*$$ Being $a△b$ the symmetric difference between $a$ and $b$ , and $a^* ≔ \{z∈Z:z-1 \in a\}$ . Think of $a$ and $b$ as bit strings, where each element identifies a position, e.g. $\{2,0,-1\}$ represents ${101.1}_2={5.5}_{10}$ . Then the operator $\oplus$ is the addition with $(a \cap b)^*$ being the carried bits shifted 1 bit to the left. If both $a$ and $b$ have a maximum element, then I think I can show that for any such $a$ and $b$ the recursion will eventually halt, and the result will also have a maximum element. But what happens if $a$ has no maximum element, e.g. when $a= \mathbb{N}$ ? Let $b=\{0\}$ . Carrying out the first steps of the recursion yields: $$\mathbb{N} \oplus \{0\}=(\mathbb{N} \setminus \{0\})\oplus \{0\}^*=(\mathbb{N} \setminus \{0\})\oplus\{1\}$$ $$=(\mathbb{N}\setminus\{0,1\}) \oplus \{1\}^*=(\mathbb{N}\setminus\{0,1\}) \oplus \{2\}$$ $$=(\mathbb{N}\setminus\{0,1,2\}) \oplus \{2\}^*=(\mathbb{N}\setminus\{0,1,2\}) \oplus \{3\}$$ Intuitionally, I would expect that after an infinite number of steps (¿after ω steps?), we would only be left with the empty set as we keep on removing elements from N. Is there any way to argue that indeed $\mathbb{N} \oplus \{0\}=\emptyset$ ? Is there any “framework” in which $\mathbb{N} \oplus \{0\}=\emptyset$ ? Is the operator $\oplus$ even well defined?","['elementary-set-theory', 'arithmetic']"
4828441,How many numbers in the interior of Pascal's triangle are Mersenne numbers?,"Consider the interior of Pascal's triangle, i.e. the triangle without numbers of the form $\binom{n}{0},\binom{n}{1},\binom{n}{n-1},\binom{n}{n}$ . How many numbers in the interior of Pascal's triangle are Mersenne numbers , that is, numbers of the form $2^n-1$ where $n\in\mathbb{Z^+}$ ? I have found four such numbers: $\color{red}{\binom{6}{2}}=\color{red}{\binom{6}{4}}=15=2^4-1$ and $\color{red}{\binom{91}{2}}=\color{red}{\binom{91}{89}}=4095=2^{12}-1$ . I searched, within the interior of Pascal's number, the smallest $10000$ numbers without repeats , the first $141$ rows , and $\binom{n}{2}$ up to $n=100000$ . Possibly related: There are no numbers of the form $2^n$ is the interior of Pascal's triangle ( proof ). Context: I have been investigating Pascal's triangle, looking for new results . I thought of Mersenne primes , so this question naturally arose.","['number-theory', 'elementary-number-theory', 'integers', 'mersenne-numbers', 'binomial-coefficients']"
4828451,An Interesting Type of Infinite Permutation Group,"Let $f:\mathbb{N}\rightarrow\mathbb{N}$ be nondecreasing such that $f(n+1)-f(n)$ is bounded. Let $S_\mathbb{N}$ be the bijections from $\mathbb{N}$ to $\mathbb{N},$ i.e. the symmetric group of $\mathbb{N}.$ Let $$G_f=\{\phi\in S_\mathbb{N}|\exists m\in\mathbb{N}:-mf(\phi_n)\leq\phi_n-n\leq mf(n)\text{ eventually always}\}.$$ In simpler terms, these are the permutations $\phi$ such that $\phi_n$ and $\phi^{-1}_n$ stray away from $n$ at a rate of $O(f(n))$ (it turns out that this is an exact characterization after some proof). I was able to prove that $G_f$ is always a permutation group in $S_\mathbb{N}$ and there are uncountably many distinct $G_f.$ Has anyone seen these groups in the literature of the infinite symmetric group? They seem to be very useful in computing rearrangements of conditionally convergent sums, but I haven't been able to find them anywhere. Note: If we replace the $f(n+1)-f(n)$ is bounded assumption with $f(n)=O(n)$ and $n=O(f(n)),$ then we still have that $G_f$ is a group.","['permutations', 'reference-request', 'combinatorics', 'symmetric-groups', 'group-theory']"
4828460,"""Most"" irreducible representations of ""most"" finite groups are one-dimensional","Looking through the character tables of the groups on this list, it seems like most irreducible representations of most groups on the list will be one-dimensional. I'm looking for a reference request: is there a result formalizing this observation?","['representation-theory', 'group-theory', 'finite-groups', 'reference-request']"
4828566,Detemining the eigenvalues $F: \ M_{nxn}(\mathbb{R}) \to M_{nxn}(\mathbb{R}) : X \mapsto AX-XB^T$ if we know the eigenvalues of $A$ and $B$.,"I'm starting to look at some linear algebra again, and it's been a long time since I have worked with eigenvalues. That being said, I found this exercise: Take $A,B \in M_{nxn}(\mathbb{R})$ and $\lambda_1,....,\lambda_n \in \mathbb{R}$ , $v_1,...,v_n \in \mathbb{R}^n$ , $\mu_1,....,\mu_n \in \mathbb{R}$ , $w_1,...,w_n \in \mathbb{R}^n$ be respectively the eigenvalues and associated eigenvectors of $A$ and $B$ . Now consider the linear map $F:  M_{nxn}(\mathbb{R})\rightarrow  M_{nxn}(\mathbb{R})$ defined by $F: X \rightarrow AX-XB^T$ . Show that the eigenvalues of $F$ are the $\lambda_i-\mu_j$ for $i,j=1,...n$ . Now it's easy to show that the $\lambda_i-\mu_j$ are indeed eigenvalues but in the correction they say that since $F$ cannot have more than $n^2$ eigenvalues we have shown that they are no others eigenvalues. But I must be missing some properties of eigenvalues since nothing tells us that all $\lambda_i-\mu_j$ are different and if two are the same we might be missing one since we haven't compute the characteristic polynomials, and we don't know the multiplicity of the eigenvalues. So I'm wondering if the correction is indeed missing a part and if yes, is there an easier way to solve the exercise than computing the characteristic polynomial of $F$ ? Edit: If eigenvalues are all different, it works, but what about if they are not ?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
4828596,"In Pascal's triangle without the $1$s, what is the sum of squares of reciprocals?","Consider Pascal's triangle without the $1$ s. Let $S$ be the sum of squares of reciprocals. $$S=\frac{1}{2^2}+\frac{1}{3^2}+\frac{1}{3^2}+\frac{1}{4^2}+\frac{1}{6^2}+\frac{1}{4^2}+\frac{1}{5^2}+\cdots$$ Does $S$ have a closed form? Wolfram does not evaluate $S$ . Significance of $S$ $S$ is a single non-trivial number representing all of Pascal's triangle without the $1$ s. (The sum of unsquared reciprocals diverges because the harmonic series diverges.) Why I suspect $S$ has a closed form I suspect $S$ has a closed form, because many other infinite sums of reciprocals in Pascal's triangle have closed forms. Examples: $\sum\limits_{k=1}^\infty\binom{k+2}{k}^{-2}=\frac43\pi^2-13$ ( source ) $\sum\limits_{k=1}^\infty\binom{k+3}{k}^{-2}=9\pi^2-\frac{355}{4}$ ( source ) $\sum\limits_{k=0}^\infty\binom{2k}{k}^{-1}=\frac43+\frac{2\pi\sqrt3}{27}$ ( source ). In Pascal's triangle without the outer two layers, the sum of (unsquared) reciprocals is $3/2$ , as I show below. Showing that $1<S<2$ Consider the color-coded Pascal's triangle below. (The green and orange numbers extend below the diagram infinitely). Let $T$ be the sum of reciprocals of the blue and green numbers. I found that $f(n)=\sum\limits_{k=2}^\infty\binom{n+k}{k}^{-1}=\frac{2}{n^2-1}$ for $n>1$ ( source ). Then $T=\sum\limits_{n=2}^\infty f(n)=\sum\limits_{n=2}^\infty \frac{2}{n^2-1}=\frac32$ by telescoping. So the sum of reciprocals of the green numbers is $\frac32-\left(\frac16+\frac{2}{10}+\frac{2}{15}+\frac{1}{20}+\frac{2}{21}+\frac{2}{35}\right)=\frac{67}{84}$ . So the sum of squares of reciprocals of the green numbers is between $0$ and $\left(\frac{67}{84}\right)^2\approx 0.6361961451$ . Using the fact that $\sum\limits_{k=2}^\infty\frac{1}{k^2}=\frac{\pi^2}{6}-1$ , the sum of squares of reciprocals of the orange and blue numbers is $2\left(\frac{\pi^2}{6}-1\right)-\left(\frac12\right)^2+\left(\frac{1}{6^2}+\frac{2}{10^2}+\frac{2}{15^2}+\frac{1}{20^2}+\frac{2}{21^2}+\frac{2}{35^2}\right)\approx 1.105202601$ . Therefore $1<S<2$ . Edit In the comments, @Tyma Gaidash shows that $S=\frac23-\frac{2\pi}{9\sqrt3}+\int_0^1\frac{t(t^2-3t+1)\ln(t(1-t))}{(t^2-t+1)^3}dt\approx 1.1146$ . I have asked about a closed form for the integral here .","['number-theory', 'elementary-number-theory', 'binomial-coefficients', 'closed-form', 'sequences-and-series']"
4828603,What is the digit in the hundreds place of $5^{2017}$,"What is the digit in the hundreds place of $5^{2017}$ ? Since $5^3 = 125$ , powers with odd exponent of $5$ , from the third onward, will end with the digits $125$ , while those with even exponents will end with $625$ . We can conclude that the digit of the hundreds of $5^{2017}$ is $1$ . Is it correct or are there possible other solutions than mine?",['algebra-precalculus']
4828652,Evaluating $\int_0^{\frac{1}{2}} \frac{1}{x} \cdot \ln(1+x) \cdot \ln(\frac{1}{x} -1)dx$,"I was trying to evaluate the definite integral $$\int_0^{\frac{1}{2}} \frac{1}{x} \cdot \ln(1+x) \cdot \ln\left(\frac{1}{x} -1\right)\,\mathrm{d}x.$$ On WolframAlpha, I found out that this converges to 0.651114. This seems to be pretty close (and possibly equal) to $\frac{13}{24}\cdot\zeta(3)$ , where $\zeta(3)$ is the value of the Riemann Zeta function $\zeta(n)$ at $\ n = 3$ . Is this true? How can we prove that they are equal? I tried substituting $\ x = e^{-t}$ and the integral became $$\ I = \int_0^{\ln2}\ln(1+e^{-t}) \cdot \ln\left(\frac{e^{-t}}{1-e^{-t}}\right)\,\mathrm{d}t.$$ How do I proceed further? Any help is appreciated. Thanks for reading.","['integration', 'calculus', 'definite-integrals']"
4828670,Gauge integral on infinite-dimensional Banach space and differentiability,"Call $f:I\to F$ gauge integrable where $I = [a, b]$ is a compact interval and $F$ is a Banach space, if the usual definition holds like if $F = \mathbb{R}$ , just replace absolute value by norm. How can one prove the following? Theorem 1. If $f:I\to F$ is gauge integrable, $I = [a, b]$ then its indefinite integral $F(x) := \int_a^x f$ is differentiable a.e. Above theorem might not be true, it should be true when $F$ is finite-dimensional. Lemma 1 (Saks-Henstock). Let $f:I\to F$ be gauge integrable, $\varepsilon > 0$ and $\delta$ be a gauge such that for all $\delta$ -fine paritions $\mathcal{P}$ $$\left\|\int_I f - S(f, \mathcal{P})\right\|\leq \varepsilon.$$ If $\mathcal{Q} = \{(I_i, t_i)\}$ is a $\delta$ -fine subpartition of $I$ , then $$\left\| \sum_i \int_{I_i} f - S(f, \mathcal{Q})\right\| \leq \varepsilon.$$ Above lemma is fine as it is for any Banach space $F$ . Here $S(f, \mathcal{P})$ is the Riemann sum of $f$ with respect to (sub)partion $\mathcal{P}$ . Lemma 2. If $f, \varepsilon$ and $\delta$ are like above, $F = \mathbb{R}$ then $$\sum_i \left\|\int_{I_i} f - f(t_i)\ell(I_i)\right\| \leq 2\varepsilon.$$ Here $\ell(J)$ is length of $J$ , and for $F = \mathbb{C}$ lemma 2 holds with $2$ replaced by $4$ . The proof of theorem 1 for $F = \mathbb{R}$ uses Vitali's covering lemma and lemma 2, but as this seems to be unavailable when $F$ is an infinite-dimensional Banach space, how can I prove theorem 1 in this case, and is it even true?","['integration', 'banach-spaces', 'indefinite-integrals', 'gauge-integral', 'derivatives']"
4828858,Number of permutations in the symmetric group $S_n$ composed of $k$ disjoint $m$-cycles,"Find the total number of permutations in the symmetric group $S_n$ that are composed of $k$ disjoint $m$ -cycles, for valid $m$ and k. I  encountered a simpler version of this question in class for $m=k=2$ . They way I solved the $m=k=2$ version is: First chose $4$ numbers out of $n$ , which can be done in $\binom{n}{4}$ ways, now for each of these selections we can make a few of the permutations included in the set, since the permutations we are counting are of the form: $(ab)(cd)$ . Now of the four different numbers you can form $\binom{4}{2}$ couples but since disjoint cycles commute in $S_n$ we divide by $2$ , which gives the result: $$\frac{{\binom{n}{4} \cdot \binom{4}{2}}}{2}$$ I had a homework task to create a generalisation of any of the problems we had encountered in class, solve it(by help if necessary) and then present it in class, of which I created this generalization which is the given problem. I've tried the exact same way for the generalization but there are some things I've used here that aren't valid for the generalization one of which is that $(ij)=(ji)$ , and I'm stuck on how to generalize the solution. Any help is appreciated on how to tackle the generalization or suggest any different routes I could take to generalize it for example removing some restrictions and any suggestion on how to tackle it.","['permutation-cycles', 'abstract-algebra', 'combinatorics', 'symmetric-groups', 'group-theory']"
4828874,When does a ring split into local rings?,"In algebra , an artinian ring R is a zero dimensional noetherian ring. With this definition the spectrum X of R equal to maximal spectrum equal to the set of minimal prime ideals which is finite, so the Zariski topology is the discrete topology. If we combine this remark with the fact that idempotent of R are in bijection with clopen (open and closed) set of X, we get a proof that Artinian ring is product of local Artinian ring. I'm interested in some criterion exemple when a ring a product of local ring ,so i try to express this result in language of scheme. Precisely in artinian affine scheme(and i think more generally when the topology is finite discrete), we can glue germs over closed point to get a global section. Do you know another proof of this result or some other condition for this to be true . This look to me like some sheaf or homological problem And thanks.","['algebraic-geometry', 'commutative-algebra']"
4828899,Is there a name for the class of functions that don't depend on argument order?,"To provide examples of such functions: $$f(x_1,x_2,...,x_n)=\sum_{i=1}^n x_i$$ $$f(x,y)=f(y,x)=x^y+y^x$$ In contrast, here are examples of functions that do depend on the argument order: $$f(x_1,x_2,...,x_n)=\sum_{i=1}^n (-1)^i x_i$$ $$f(x,y)=x^y+y$$ Is there a name for the former class of functions? P.S. Commutativity is defined for operations, not sure if that's a correct term for multivariate functions over more than 2 arguments.","['functions', 'terminology']"
4828901,Stochastic integral of continuous integrand with bounded variation,"Let me consider the $0=t_{0}<t_{1}<\ldots<t_{n}=T$ partition of the time interval $\left[0,T\right]$ . I know that under very general assumptions, if $X$ is a continuous deterministic function, then $$\sum_{i}X\left(s_{i}\right)\left[Y\left(t_{i}\right)-Y\left(t_{i-1}\right)\right]\overset{p}{\rightarrow}\int_{0}^{T}X\left(t\right)dY\left(t\right),$$ where $s_{i}\in\left[t_{i-1},t_{i}\right]$ . So it is not necessary to choose $s_{i}=t_{i-1}$ (the beginning of the time interval $\left[t_{i-1},t_{i}\right]$ ) in the integral approximating sum, as the Itô integral construction would suggest. (See my previous question: Convergence of approximating integral sum in case of stochastic integrals ). I know that the convergence above is guaranteed if $s_{i}=t_{i-1}$ (, even in the case when $X$ is continuous, but NOT necessary has bounded variation). Can the convergence above somehow be expanded to continuous integrand with bounded variation? Other words, does it matter where to choose $s_{i}$ in the integral approximating sum in order to reach any kind of convergence when the $X$ integrand is continuous (stochastic) process with bounded variation? I think choosing $s_i$ does matter (so we can't choose it arbitrarily), but do we know any (counter) example?","['stochastic-integrals', 'stochastic-analysis', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
4828950,Proving that mixed partial derivatives can be taken in any order for for smooth functions on smooth manifolds,"The following is a description of the partial derivative on smooth manifolds from John Lee's Introduction to Smooth Manifolds. Suppose $M$ is a smooth manifold and let $(U,\phi)$ be a smooth coordinate chart on $M$ . Then $\phi$ is a diffeomorphism from $U$ to an open subset $\hat{U}\subset \mathbb{R}^n$ . So $d\phi_p : T_p M \to T_{\phi(p)} \mathbb{R}^n$ is an isomorphism. Let the standard coordinate frame be $\partial/\partial x^1 |_{\phi(p)},\dots \partial / \partial x^n|_{\phi(p)}$ for $T_{\phi(p)} \mathbb{R}^n$ . Then we use the notation $\partial/ \partial x^i|_p$ as the preimages of these vectors under the isomorphism $d\phi_p$ that form a basis for $T_p M$ characterized by either of the following expressions: $$\frac{\partial}{\partial x^i}|_p = (d\phi_p)^{-1}(\frac{\partial}{\partial x^i}|_{\phi(p)}) = d(\phi^{-1})_{\phi(p)}(\frac{\partial}{\partial x^i}|_{\phi(p)}).$$ Unwinding the definitions, we see that $\partial/ \partial x^i|_p$ acts on a function $f\in C^\infty(U)$ by $$\frac{\partial}{\partial x^i}|_p f = \frac{\partial}{\partial x^i}|_{\phi(p)} (f\circ \phi^{-1}) = \frac{\partial \hat{f}}{\partial x^i}(\hat{p}),$$ where $\hat{f}=f\circ \phi^{-1}$ is the coordinate representation of $f$ , and $\hat{p}=(p^1, \dots, p^n)= \phi(p)$ is the coordinate representation of $p$ .  In other words, $\partial / \partial x^i|_p$ is just the derivation that takes the $i$ th partial derivative of the coordinate representation of $f$ at the coordinate representation of $p$ . In the special case of standard coordinates on $\mathbb{R}^n$ , the vectors $\partial/ \partial x^i|_p$ are literally the partial derivative operators. Now, for the general smooth manifold $M$ how do we guarantee that that mixed partial derivatives of a smooth function can be taken in any order, i.e. $\frac{\partial^2 f}{\partial x^i \partial x^j}=\frac{\partial^2 f}{\partial x^j \partial x^i}$ ? I think this follows from the fact that this is true for smooth functions on the Euclidean space, but how do we compute the second order derivative for smooth functions on manifolds as in the single derivative case above? I cannot figure out how to define $\frac{\partial}{\partial x^i}|_p \frac{\partial f}{\partial x^i}= \frac{\partial}{\partial x^j}|_p \frac{\partial \hat{f}}{\partial x^j}(\hat{p})$ using the definition above. Can we put the second order derivative of $f\in C^\infty(M)$ in terms of second order derivative of the coordinate representation of $f$ in $C^\infty(\mathbb{R}^n)$ so we can use the result in $\mathbb{R}^n$ to conclude the result? Or do we rely on a different result to conclude that mixed partial derivatives can take any order? I would greatly appreciate some help as I have been puzzled about the precise form of mixture of partial derivatives for smooth manifolds and why the order does not matter as for smooth functions on $\mathbb{R}^n$ .","['smooth-manifolds', 'multivariable-calculus', 'partial-derivative', 'manifolds', 'differential-geometry']"
4828954,Closed form for $\int_0^1\frac{(x^3-3x^2+x)\log(x-x^2)}{(x^2-x+1)^3}\mathrm dx$,"I am looking for a closed form for $$I=\int_0^1\frac{(x^3-3x^2+x)\log(x-x^2)}{(x^2-x+1)^3}\mathrm dx\approx 0.851035604949$$ Wolfram does not evaluate $I$ . I suspect $I$ has a closed form, because if $I$ has a closed form then the answer to my question In Pascal's triangle without the $1$ s, what is the sum of squares of reciprocals? has a closed form. In that question, I give reasons for why I suspect a closed form answer. But of course I could be wrong. My attempt Here is the graph of $y=\frac{(x^3-3x^2+x)\log(x-x^2)}{(x^2-x+1)^3}$ . I thought about translating the function to an odd function in order to take advantage of rotational symmetry, but the curve clearly does not have rotational symmetry. I tried substitution and Maclaurin series, but got nowhere.","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'closed-form']"
4829011,Coprime Scoreboard and Probability,"In a more Intuitional Description: My friends and I were working on a problem of a scoreboard problem. It's a scoreboard that automatically ""simplifies"" itself (we tend to read $7:2$ as ""7 to 2"", which makes people think of fractions). Simplified fractions and the original ones are the same, so we want to know what will happen if the scoreboard does the same thing. Hence, if the current score is $19:15$ and the left team wins a point, it becomes $4:3$ (divided by $5$ on both sides), and if the right-hand side gets a point it goes to $1:1$ (divided by $4$ on both sides). We consider both sides to have an equal chance of winning a point. Notice, the order of the points matters, if we switch the scoring order from the case above, $19:15$ will firstly become $19:16$ , and then $5:4$ (divided by $4$ ). The following gives the problem written in a formalized language. In Formalized Language: In an experiment, we let the $0\,$ th state be $(0,0)$ . For $k\,$ th state $(a,b)$ , $(k+1)\,$ th state has equal probabilities, $50\%$ each, to become $$\left(\frac{a+1}{\gcd(a+1,b)},\frac{b}{\gcd(a+1,b)}\right)$$ or $$\left(\frac{a}{\gcd(a,b+1)},\frac{b+1}{\gcd(a,b+1)}\right)$$ where we define $\gcd(0,a)=\gcd(a,0)=a$ for all $a\in\mathbb{N}$ . We use $f_n(a,b)$ to denote the probability that the $n\,$ th state is $(a,b)$ , and define $f(a,b)$ by $$f(a,b)=\lim_{n\to\infty}f_n(a,b).$$ Based on the definitions above, we want to know If $\lim_{n\to\infty}f_n(a,b)$ exists. For all $p$ and $q$ satisifying $\gcd\left(p,q\right)=1$ , $f\left(p,q\right)=0$ only when $p\cdot q=0$ . The value of $f\left(1,1\right)$ . The value of $f\left(p,q\right)$ for all $\gcd\left(p,q\right)=1$ , in terms of $p$ and $q$ . Our Current Process: Trivially, $$f\left(0,0\right)=f\left(0,1\right)=f\left(1,0\right)=0.$$ And numerically, $$f_{10}\left(1,1\right)=0.2128906250,$$ $$f_{20}\left(1,1\right)=0.1955623627,$$ $$f_{30}\left(1,1\right)=0.1951741818,$$ $$f_{40}\left(1,1\right)=0.1951625187,$$ $$f_{50}\left(1,1\right)=0.1951622049,$$ $$f_{60}\left(1,1\right)=0.1951621955\cdots$$ which does not seem to converge to $0$ .","['number-theory', 'markov-process', 'probability-theory', 'martingales']"
4829017,How to understand all characteristic classes as generators of classifying space cohomologies,"Context: I'm somewhere in the middle of my study of differential geometry and starting to learn about characteristic classes. I like to have a general intuitive understanding of a concept before diving into details, and I've been struggling to assemble that understanding for characteristic classes. Getting an answer to the following couple of questions would be a huge help. To set the stage, let's restrict to the smooth category and define characteristic classes as natural transformations between the (contravariant) functor $A$ from the category of smooth manifolds $\mathrm{Man}^\infty$ to $\mathrm{Set}$ which maps a manifold $M$ to its associated set of isomorphism classes of vector bundles with base $M$ (and mapping morphisms to pullbacks), and a cohomology functor $B$ from $\mathrm{Man}^\infty$ to $\mathrm{Set}$ which maps a manifold to its set of cohomology groups. We can develop an alternative characterization as follows. Exploiting a bijection between isomorphisms classes of real $n$ -vector bundles and isomorphism classes of $GL_n(\mathbb{R})$ -principal bundles, one can construct the classifying space $BO(n)$ and show that all real bundles over $M$ are pullbacks of the universal bundle $\gamma_n$ over this space. This is useful because it means that $BO(n)$ represents the functor $A$ , so by the Yoneda lemma, we can think about characteristic classes for $n$ -vector bundles as choices of elements in the cohomology of $BO(n)$ . A similar result holds for complex vector bundles if we replace $BO(n)$ with $BU(n)$ . These ideas are all nicely summarized, for example, in this REU paper . This can in turn be made more tangible by computing some cohomology rings for these classifying spaces. For example, $H^*(BO(n), \mathbb{Z}_2) \cong \mathbb{Z}_2[x_1, \dots, x_n]$ $H^*(BU(n), \mathbb{Z}) \cong \mathbb{Z}[y_1, \dots, y_n]$ and you can pick out canonical manifestations of these isomorphisms. Putting together all of the pieces, characteristic classes for real vector bundles with coefficients in $\mathbb{Z}_2$ are generated by the $x_i$ (the Stiefel-Whitney classes), while for complex vector bundles with coefficients in $\mathbb{Z}$ they are generated by the $y_i$ (the Chern classes). Now, there are only so many characteristic classes discussed in the literature: Stiefel-Whitney, Chern, Thom, Euler, Pontryagin, Todd. My questions are as follows: Is there a concise way to see how Thom, Euler, Pontryagin, and Todd classes fit in this framework of looking at the generators of $H^*(BG,R)$ for $G = O(n), U(n)$ and some choice of ring $R$ ? How come the list of characteristic classes stops there, given the number of rings one can consider? That is, why does it suffice to look at some subset of all of the possible rings, and why do we choose the ones we do?","['classifying-spaces', 'complex-geometry', 'homology-cohomology', 'characteristic-classes', 'differential-geometry']"
4829030,"To what extent does the ""Cauchy-Schwarz inequality"" hold for a normed vector space not inner product space?","It is known to all that for inner product space $H$ , Cauchy-Schwarz inequality hold: $| \langle x,y \rangle | \leq \| x \| \cdot \| y \| \ \forall x,y\in H$ , and for a normed space $X$ without inner product structure, we have two similar ""Cauchy inequality"":1. real case (use some algebraic substitution); 2. complex case My question is that for a normed space but not inner product space $X$ , noting that $$f(x,y)=\sum_{k=1}^{n} a_k(\|x+b_k y\|^2-\|x\|^2-\|b_k y\|^2) \ (a_k,b_k\ne 0,k=1,2,···,n )$$ which satisfy that $$\sum_{k=1}^{n}a_k\overline{b_k}=1; \ \sum_{k=1}^{n}a_kb_k=0 $$ in complex case,or $$\sum_{k=1}^{n}a_kb_k=\frac{1}{2}$$ in real case, (In summary, for an inner product space there is $f(x,y)=\langle x,y \rangle$ ) then in addition to the two examples mentioned above, what conditions are satisfied by sequence $\{a_k\},\{b_k\},\{c_k\}$ that enable inequality $|f(x,y)|\le\|x\|\|y\| \ \forall x,y\in X$ to hold? ----2023.12.17 Okay, I admit that I asked the question in order to find the condition that makes the normed space $X$ isometric isomorphic to the inner product space, here's the link to the question I asked on MathOverFlow . Thank if you can give me any help. ----2024.02.02 I'm now focus on a particular case about this problem: $$f(x,y)=\frac{1}{2}\sum_{k=1}^{n}a_{k}(\|x+b_{k}y\|^2-\|x-b_{k}y\|^2)$$ where $\sum_{k=1}^{n}a_{k}b_{k}=\frac{1}{2}$ , is $|f(x,y)|\le \|x\| \|y\|$ hold? Anyone who can give a proof of this case might be instructive. ----2024.02.28","['inequality', 'normed-spaces', 'cauchy-schwarz-inequality', 'functional-analysis']"
4829042,Which is correct Euler path or Euler trail?,"Since path cannot have repeated vertices, the definition for A graph which exactly two vertices have odd degree, and all of its vertices with nonzero degree belong to a single connected component seems to must refer to Euler trail. Is Euler path sth else and if it is? (I think it can just be a path graph.) Another question is, An undirected graph has an Eulerian trail if and only if exactly zero or two vertices have odd degree, and all of its vertices with nonzero degree belong to a single connected component this is from Wikipedia, How can a graph with zero  odd-degree vertices has an Eulerian trail?","['graph-theory', 'discrete-mathematics', 'eulerian-path']"
4829164,Estimate the subgroup order of group of units in finite algebra in GAP,"Let $G$ be a finite group $p$ -group and $FG$ be a modular group algebra of $G$ .
Is there any way to estimate the order of subgroup generated by two or more elements of $U(FG)$ , where $U(FG)$ is the group of units of $FG$ ? For small groups it extremely easy.
The larger group and field, the more difficult this exercise is. Example. Easy. gap> G := QuaternionGroup(8);;
gap> F := GF(2);;
gap> FG := GroupRing(F, G);;
gap> UFG := Units(FG);;
gap> Order(Subgroup(UFG, [Random(UFG), Random(UFG)]));
32
gap> Order(Subgroup(UFG, [Random(UFG), Random(UFG)]));
8 A little bit more difficult. gap> G := OneSmallGroup(2^9);;
gap> F := GF(2);;
gap> FG := GroupRing(F, G);;
gap> FG_Teta := Embedding(G, FG);;
gap> Group([Random(G)^FG_Teta + Random(G)^FG_Teta + Random(G)^FG_Teta, Random(G)^FG_Teta]);; 
gap> Order(Group([Random(G)^FG_Teta + Random(G)^FG_Teta + Random(G)^FG_Teta, Random(G)^FG_Teta]));;
gap> Order(Group([Random(G)^FG_Teta + Random(G)^FG_Teta + Random(G)^FG_Teta, Random(G)^FG_Teta])); 
16384
gap> Order(Group([Random(G)^FG_Teta + Random(G)^FG_Teta + Random(G)^FG_Teta, Random(G)^FG_Teta]));
32768
gap> Order(Group([Random(G)^FG_Teta + Random(G)^FG_Teta + Random(G)^FG_Teta, Random(G)^FG_Teta]));
2048 My main goal is to bypass the step of calculating the exact order of a subgroup and replace it with a logical condition, in which I will determine whether the order of the subgroup is not less than.","['gap', 'group-theory']"
4829229,"If $m > n > 2$, then $m! - n!$ is never a perfect square?","This is a ""pupil-level"" problem from a Chinese software Xiaohongshu (Chinese version Twitter/Reddit/Quora/Insta). Unfortunately, its ""official"" solution is wrong: The solution states that $m! - n!$ contains a prime factor larger than $m$ , however $37! - 35! = 35! \times (36 \times 37 - 1) = 35! \times 11^3$ . I found this problem extremely hard for me. I can only prove partial results: (1)If $m \geq 2n > 4$ , then $m! - n!$ is never a square. Proof: Let $p$ be the largest prime $\leq n$ . According to the Bertrand's postulate , $p > \frac{n}{2}$ . Therefore, $v_p(n!) = 1$ . Since $m \geq 2n \geq 2p$ , $v_p(m!) \geq 2$ , therefore $v_p(m!-n!) = 1$ , hence $m! - n!$ is not a perfect square. (2)If $m = n+1$ , then $m! - n!$ is never a perfect square. Proof: $m! - n! = n \times n! = n^2 \times (n-1)!$ . However, $(n-1)!$ is never a perfect square when $n \geq 2$ (see here if you are confused). Therefore $(n+1)! - n!$ is not a perfect square for $n \geq 2$ . (3) If $popcount(\lfloor \frac{n}{2} \rfloor)$ is odd, then $m! - n!$ is never a perfect square. Proof: The case $m = n+1$ has been discussed in (2). For $m > n+1$ , by Legendre's formula , $v_2(m) = \sum\limits_{i=1}^\infty \lfloor \frac{m}{2^i} \rfloor > v_2(n)$ , however $v_2(n)$ is an odd number, therefore $v_2(m! - n!)$ is also odd. We note that the parity of $v_2(n)$ equals $popcount(\lfloor \frac{n}{2} \rfloor)$ , where popcount means the number of $1$ in a number's binary representation. For example, $popcount(7) = popcount(111_2) = 3$ and $popcount(6) = popcount(110_2) = 2$ . This problem, on the one hand, seems easy. Intuition and Python experiments show the $m! - n!$ are never perfect squares, as it is ""somehow difficult"" to make $v_p(m! - n!)$ even for every $p$ . On the other hand, it is also difficult. When $m > n+1$ , it might require analysis on the expression $\Pi_{i=n+1}^m i - 1$ , while the term "" $-1$ "" is quite annoying. I am curious whether it is possible to introduce some analytic or algebraic tools?",['number-theory']
4829307,Orbits of points in compact metric space when there exists a point that is fixed by all isometries,"Let $(X,d)$ be a compact metric space and Iso $(X,d)$ be a set of all isometries $f : X \rightarrow X$ . For $x \in X$ orbit of $x$ is defined as: $$\operatorname{Orb}(x) := \{f(x) : f \in \operatorname{Iso}(X,d)\}.$$ Suppose $\operatorname{Iso}(X,d)$ is infinite and suppose there is a point $x_0 \in X$ such that $f(x_0) = x_0$ , for every $f \in \operatorname{Iso}(X,d)$ . Let $x$ be a point in $X$ and define $r_x := d(x_0, x)$ . Let $y \in \operatorname{Orb}(x)$ and $f \in \operatorname{Iso}(X,d)$ such that $f(x) = y$ , we have $$r_x = d(x, x_0) = d(f(x), f(x_0)) = d(y, x_0).$$ It follows that $\operatorname{Orb}(x) \subseteq S(x_0, r_x)$ , for every $x \in X$ , where $S(x, r) := \{y \in X : d(x, y) = r\}$ . Is it maybe true that $\operatorname{Orb}(x) = S(x_0, r_x)$ , for all $x \in X$ , under these assumptions?","['general-topology', 'isometry', 'metric-spaces']"
4829367,"Integral: $I = \int_0^{\frac{\pi}{4}} \frac{\ln^3(\cos x) + \ln^2(\cos x)\tan x - \ln(\cos x)\cot^2 x}{\sin^3 x}\,dx$","I need some help in evaluating $I$ , which is the integral: $$I = \int_0^{\frac{\pi}{4}} \frac{\ln^3(\cos x) + \ln^2(\cos x)\tan x - \ln(\cos x)\cot^2 x}{\sin^3 x}\,dx$$ Clarifications: For better readability, the expression $\ln^3(\cos x)$ represents $(\ln(\cos x))^3$ . The term $\ln^2(\cos x)\tan x$ denotes $(\ln(\cos x))^2 \times \tan x$ . If any other interpretations are possible, please advise. First Steps: \begin{align*}
I &= \int_0^{\frac{\pi}{4}} \frac{\ln^3(\cos x) + \ln^2(\cos x)\tan x - \ln(\cos x)\cot^2 x}{\sin^3 x} \, dx \\
&= \int_0^{\frac{\pi}{4}} \frac{\ln^3(\cos x) + \ln^2(\cos x)\tan x - \ln(\cos x)\frac{\cos^2 x}{\sin^2 x}}{\sin^3 x} \, dx \\
&= \int_0^{\frac{\pi}{4}} \frac{\ln^3(\cos x) + \ln^2(\cos x)\tan x - \ln(\cos x)\csc^2 x}{\sin x} \, dx
\end{align*} $$ = \int_0^{\frac{\pi}{4}} \frac{\ln^3(\cos x) + \ln^2(\cos x)\tan x - \ln(\cos x)\cot(x)\csc(x)}{\sin x} \, dx$$","['integration', 'calculus', 'definite-integrals', 'trigonometry']"
4829388,Find vectors $ \bf x $ and $ \bf y $ of binaries that maximize $ \bf xCy $.,"Given a matrix of integers, $ \bf C $ , find row vector $ \bf x $ of binaries and column vector $ \bf y $ of binaries that maximize the product $ \bf xCy $ . Is there an efficient algorithm to either find a solution or approximate solution? I've been researching (Integer) Linear Programming and can't seem to find an algorithm for this particular variant. Here's an example. You're given matrix $$ \textbf{C} = \begin{bmatrix}
-2 & 4 & -4\\
8 & 4 & -7\\
-5&3&1\\
2&2&2
\end{bmatrix} $$ . The solution of binary row/column vectors is: $$ 
\textbf{x} = \begin{bmatrix} 1 & 1 & 0 & 1 \end{bmatrix},
\textbf{y} = \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} 
$$ where $ \textbf{xCy} = 18$","['linear-programming', 'matrices', 'linear-algebra', 'discrete-optimization', 'optimization']"
4829443,Binomial distribution where successes increases the number of trials,"I'm trying to calculate the probability of $k$ successes when the number of trials ( $n$ ) increases by $6$ each time a success occurs (starting at $20$ ): $$ P(X=k) = \ ? \qquad\text{where}\qquad p=.05, \quad n=20. $$ I can't just punch in $n=20+6k$ because that includes impossible scenarios like $X>0$ with no successes in the first $20$ trials. The run ends one you've reached the $(n+6k-k)$ th loss. Edit: Apologies for the lack of clarity. Hopefully these steps will help Begin run Perform $20$ trials Perform check to determine # of successes Perform $6$ additional trials for each success ( $2$ successes = $12 $ add'l trials, totaling $32$ trials) Perform check to determine  # of successes since previous check Perform $6$ additional trials for each success since previous check Repeat steps $5$ and $6$ until # of successes since previous check is $0$ End run See below for an attempted solution and tell me why it's wrong $$\frac{20}{20 + 6k} \binom{20 + 6k}{k} \frac{19^{20+5k}}{20^{20+6k}}$$","['binomial-distribution', 'probability']"
4829460,How to find the derivative of a piecewise function?,"How to find the derivative of $\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))}$ . That is find $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))})$ . Now we clearly know that $\operatorname{sgn}(x)$ is a piecewise function.
We know that $\operatorname{sgn}(x)=\frac{|x|}{x}$ when $x\neq0$ and $0$ when $x=0$ . Therefore when $x>0$ then the value of $\frac{|x|}{x}$ is $1$ . When $x<0$ then the value of $\frac{|x|}{x}$ is $-1$ . Now let's take cases. Case-1): When $\operatorname{sgn}(x)=1$ , then $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+7+3x})=\frac{1}{2\sqrt{x^{2}+3x+7}}(2x+3)$ . Case-2): When $\operatorname{sgn}(x)=0$ , then $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{4})=0$ . Case-3): When $\operatorname{sgn}(x)=-1$ , then $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+3x+1})=\frac{1}{2\sqrt{x^{2}+3x+1}}(2x+3)$ . So, we can clearly see that $3$ different results are occuring for $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))}$ . But I want to know that is my process correct? Are $3$ different results possible? Please do let me know.","['calculus', 'derivatives-of-piecewise-functions', 'derivatives']"
4829501,Folland Theorem 3.20,"I'm new to this forum. I don't have a formal education in mathematics and I'm trying to learn real analysis from Folland by myself. I'm not sure if I've understood the proof of theorem 3.20 correctly and your input would be appreciated. Definition: $L_f = \{x: \lim_{r \rightarrow 0} \frac{1}{m(B(r,x))} \int_{B(r,x)} |f(y) - f(x)| dy = 0\}$ . Here is an image of the theorem and its proof. Theorem 3.20 The way I understand this proof is that $E^c \subset L_f$ and $E$ contains points belonging to both $L_f$ and $L_f^c$ . But, since $m(E) = 0$ and $L_f^c \subset E$ , $m(L_f^c) = 0$ . Is this correct or am I missing something? All help is greatly appreciated. Thank you!","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4829532,Limit involving a recursively-defined sequence,"$$A_{n+1}=A_n+\frac{1}{\sum_{i=1}^n A_i}$$ with $$A_1=1$$ Find out the value of $$\lim_{n→∞}A_n/\sqrt{\log(n)}$$ I used Stolz Theorem, but it seems to be useless.","['calculus', 'analysis', 'sequences-and-series']"
4829578,Sum of distance between integer numbers,"Let $p$ is a positive integer, and let $A_1,\ldots,A_p$ be a partition of $\{1,\ldots,n\}$ . My conjecture is that \begin{equation}
\displaystyle\sum_{i=1}^p\left( \frac{\displaystyle\sum_{a_i,a_j \in A_p}|a_i-a_j|}{|A_p|} \right)\leq \frac{\displaystyle\sum_{1\leq i,j \leq n}|i-j|}{n}=\frac{(n-1)(n+1)}{3}
\tag{1}
\end{equation} I have checked that this is true for $n=4,5,6$ . I have tried to prove this conjecture by induction, but I did not succeed yet. I think also about the weighted network. The sum $\displaystyle\sum_{a_i,a_j \in A_p}|a_i-a_j|$ is the sum of the inverse of closeness of all points in network represented by $A_p$ . But once again, I did not find any good references. Another way I have thought about the proof is as follows. Let $A,B$ be two disjoint sets of positive integers. The conjecture above is true if we can prove that \begin{equation}
\frac{\displaystyle\sum_{a_i,a_j \in A}|a_i-a_j|}{|A|}+\frac{\displaystyle\sum_{b_i,b_j \in B}|b_i-b_j|}{|B|}\leq \frac{\displaystyle\sum_{x_i,x_j \in A\cup B}|x_i-x_j|}{|A|+|B|}
\tag{2}
\end{equation} I am trying to prove inequality (2) by proving that if we move one element from set $B$ to set $A$ , then it will increase the sum in LHS of (2) provided that $|A|\geq |B|$ . I am still working on it. If you have any ideas, comments, or even counter examples, please do not hesitate to write them here. Thank you very much. Update: The inequality in (2) seems wrong. I have done a simulation for the case $n=10$ . The values of those partitions are not monotone; however, they're all smaller than $\frac{(n-1)(n+1)}{3}$ .","['inequality', 'network', 'discrete-mathematics', 'real-analysis']"
4829583,Minimal area of hexagon with each side 1 unit away from a point,"I need to find the minimal area of a convex hexagon with all of its sides 1 unit away from a point. Here's what I've done so far. I think this is equivalent to asking for the minimal area of a hexagon circumscribed around a circle with radius 1, since then all of its sides will be 1 unit away from the center of the circle. Intuitively, it looks like a regular hexagon would minimize the area, and playing around in GeoGebra seems to support this. However, I'm having trouble proving this result formally. I've tried two things so far: One, starting with a regular hexagon and moving one of the points of tangency along the circle. If we overlap the regular hexagon with this new hexagon, there is a triangle of added area and a triangle of lost area. I've tried to show that the lost area is greater than the gained area, but I haven't been able to find a way to get the area of either triangle. Second, I split the hexagon into 12 triangles. In a regular hexagon, each triangle would have an area of $\frac{\tan 30 ^{\circ}}{2} = \frac{\sqrt{3}}{6}$ . I tried to show that if we change the central angle, the area will decrease, but this gave me the opposite of what I wanted - if the angle is $45^{\circ}$ , for example, the area of the triangle would be $\frac{1}{2}$ , which is greater than the previous result. I'm a high school student and haven't taken calculus yet, so please try to give a proof using only trigonometry or other elementary methods, if that is possible. However, if there is a more elegant proof using more advanced concepts, please point me to any relevant resources.","['geometry', 'maxima-minima', 'plane-geometry', 'optimization', 'trigonometry']"
4829640,Evaluation of $\int_0^1\frac{\ln ^2\left( 1-x \right) \text{Li}_2\left( \dfrac{1+x}{2} \right)}{x}\text{d}x$,"​show that \begin{align*} \int_0^1\frac{\ln ^2\left( 1-x \right) \text{Li}_2\left( \dfrac{1+x}{2} \right)}{x}\text{d}x&=\text{2Li}_5\left( \frac{1}{2} \right) +\text{2}\ln\text{2Li}_4\left( \frac{1}{2} \right) +\frac{81}{32}\zeta \left( 5 \right)\\ & -\frac{\ln ^22}{8}\zeta \left( 3 \right)+\frac{5\pi ^2}{16}\zeta \left( 3 \right) -\frac{\pi ^2\ln ^32}{18}-\frac{\pi ^4\ln 2}{15}\\ &+\frac{\ln ^52}{15} \end{align*} $$I = \int_0^1 \frac{\ln^2(1-x) \text{Li}_2\left(\frac{1+x}{2}\right)}{x} \, dx = -\int_0^1 \frac{\ln^2(1-x)}{x} \int_0^{\frac{1+x}{2}} \frac{\ln(1-y)}{y} \, dy \, dx$$ Swapping the order of integration, we get: \begin{align*}
I = &-\int_0^{\frac{1}{2}} \frac{\ln(1-y)}{y} \int_0^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\
&- \int_{\frac{1}{2}}^1 \frac{\ln(1-y)}{y} \int_{2y-1}^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\
= &-\int_0^{\frac{1}{2}} \frac{\ln(1-y)}{y} \int_0^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\
&- 2\int_{\frac{1}{2}}^1 \frac{\ln(1-y) \text{Li}_3(2-2y)}{y} \, dy \\
&+ 2\int_{\frac{1}{2}}^1 \frac{\ln(1-y) \text{Li}_2(2-2y) \ln(2-2y)}{y} \, dy \\
&+ \int_{\frac{1}{2}}^1 \frac{\ln(1-y) \ln(2y-1) \ln^2(2-2y)}{y} \, dy
\end{align*}","['integration', 'improper-integrals', 'definite-integrals', 'logarithms', 'calculus']"
4829652,Solve the maximum of a trigonometric function without differentiation,"The problem is,
when $f(x) \stackrel{\mathrm{def}}{=} \frac{\sin(x)\cos(x)}{(1+\sin(x))^2} 
$ for $(x \in [0,\frac π2])$ , what is the maximum of $f(x)$ ？ Of course, we solve this problem with differentiation.
Specifically, to solve $f’(x)=0$ .
The answer is $sqrt(3)/9$ when $x=π/6$ I am also searching for a solution using inequalities(e.g. AM-GM, Cauchy-Schwarz). However, I can't having precisely applying inequalities.
This is Because, I think, $f(x)$ is not symmetric . Would you mind to tell me how to solve this problem using inequality?","['maxima-minima', 'inequality', 'trigonometry']"
4829747,Olympiad Geometry Problem about Pentagon Inscribed in Circle,"Someone gave me this question, and I seriously have no clue how to answer it. I've tried considering the centre, drawing diagrams, and searching up all the theorems in the internet but I can't find a way to solve it. Any help would be greatly appreciated. There is a pentagon $ABCDE$ inscribed in a circle, with $AB = 2, BC = 5, CD = 2, DE = 5$ and $AD = 8$ . What is the length of the line segment $BE$ ? It feels like there isn't enough information. I don't  even think we can find or use the radius of the circle. There must be a trick somewhere, right?","['contest-math', 'geometry', 'polygons']"
4829768,Show that $\liminf \frac{\vert S_n\vert}{\sqrt{n}} = 0$.,"Let $X_1, X_2, \dots$ be i.i.d random variables with $\mathbb{E}(X_i) = 0$ and $0 < \operatorname{Var}(X_i) < \infty$ , then by the Central Limit Theorem and Kolmogorov’s 0-1 Law we can conclude that $$\limsup_{n\rightarrow\infty} \frac{S_n}{\sqrt{n}} = \infty, \ a.s.$$ Now my question is that can we establish that $$\liminf_{n\rightarrow\infty} \frac{\vert S_n\vert}{\sqrt{n}} = 0, \ a.s.$$ It seems that the approach to the problem above fails here. I also tried to use the law of iterated logarithm to solve it, but only ended up with failure. Any help will be greatly appreciated.","['probability-limit-theorems', 'probability-theory', 'probability']"
4829781,Finding a scalar potential given its set of stationary points,"Given a set of points in $\mathbb{R}^3$ $$x^\star(t), y^\star(t), z^\star(t)\text{,}\quad 0\le t\le 1$$ I am looking for a scalar potential $V(x, y): \mathbb{R^2} \rightarrow \mathbb{R}$ , whose partial derivatives satisfy the following conditions, \begin{align*}
\dfrac{\partial V}{\partial x}(x^\star(t),y^\star(t)) &= 0\\
\dfrac{\partial V}{\partial y}(x^\star(t),y^\star(t))&=z^\star(t)\text{,}\\
\forall 0\le t\le 1\text{.}
\end{align*} Any idea on how to find $V$ ? Less confusing formulation Given a curve $x^\star, y(x^\star)$ in $\mathbb{R}^2$ , I am looking for a scalar potential $V(x, y)$ having a specific gradient along that curve, i.e. \begin{align*}
\dfrac{\partial V}{\partial x}(x^\star,y(x^\star)) &= 0\\
\dfrac{\partial V}{\partial y}(x^\star,y(x^\star))&=z(x^\star)\text{,}\\
\end{align*} where $z: \mathbb{R} \rightarrow \mathbb{R}$ is a given function. Context This problem arises when one tries to derive the potential elastic energy of an elastic structure with two degrees of freedom $x$ and $y$ given its equilibrium path. The equilibrium path is the set of all the static equilibrium states the structure can be in when a force acts on it. This path can be represented by a curve in a three-dimension space: two dimensions for the degrees of freedom ( $x$ and $y$ ), and a third dimension for the force $z$ acting on one of the degree of freedom ( $y$ in this case). Each triplet of points $(x^\star(t), y^\star(t), z^\star(t))$ corresponds to a static configuration of the structure. When on tries to find the equilibrium path of an elastic structure whose elastic energy is given by $V(x, y)$ , the classic approach consists of forming the total potential energy $\Pi$ defined as $$\Pi = V(x, y) - zy\text{,}$$ where $z$ represents the external force acting on the degree of freedom $y$ . We consider the case where no external force acts on the degree of freedom $x$ . The static equilibrium states ( $x^\star$ , $y^\star$ , $z^\star$ ) are the stationary points of the potential $\Pi$ (w.r.t the variables $x$ and $y$ ), which leads to the following set of equations \begin{equation*}
0=\dfrac{\partial V}{\partial x}(x^\star, y^\star),\quad
0=\dfrac{\partial V}{\partial y}(x^\star, y^\star) - z^\star\text{.}
\end{equation*}","['lagrange-multiplier', 'multivariable-calculus', 'calculus', 'multiple-integral', 'indefinite-integrals']"
4829818,Prove That $m\geq\frac{5}{6}(n-5)$,"Question: A city has $n$ bus lines. Every bus stop is on at most $3$ bus lines and every bus line has at least $2$ bus stops. Besides, for any $2$ lines $l_1$ and $l_2$ , there exists a line $l_3$ such that $l_1$ and $l_3$ share a bus stop, and $l_3$ and $l_2$ share a bus stop. Let $m$ be the total number of bus stops. Prove that $m\geq\frac{5}{6}(n-5)$ . This problem is from a book on Math Olympiads that I am currently studying. No solutions were provided, but a hint was given: ""Consider lines that only has $2$ bus stops"". From this I was able to develop some ideas. They are as follows. If every bus line has at least $3$ bus stops, consider pairs $(A, l)$ where $A$ is a bus stop on line $l$ . Let $k$ be the number of such pairs. Since every bus stop is on at most $3$ bus lines, we know that $3m\geq k$ . Since we assumed that every line has at least $3$ bus stops, we know that $k\geq3n$ . Hence, $3m\geq k\geq3n\implies m\geq n\geq\frac{5}{6}(n-5)$ . Hence, suppose that there exists a line $l$ with only $2$ bus stops. Let these $2$ bus stops be called $A$ and $B$ . Call all lines that pass through $A$ and/or $B$ ""type-1 lines"". Since each bus stop is on at most $3$ bus lines, there are at most $5$ ""type-1 lines"". Call all other lines ""type-2 lines"". From the third condition, every ""type-2 line"" must share a stop with a ""type-1 line"". I stopped here. I could not figure out anything from this last statement. Any help on this question will be appreciated!","['contest-math', 'combinatorics']"
4829822,How is the Haar integral related to the Haar measure?,"Here, $\mathcal{C}(G, \mathbb{R})$ denotes the continuous functions from a topological group $G$ to $\mathbb{R}$ . I'm taking a course on the representation theory of groups and have moved onto a section about topological groups, and we have defined the Haar integral as a linear map $$\smallint_G: \mathcal{C}(G, \mathbb{R}) \to \mathbb{R}$$ with the properties $\int_G \mathbf{1}_G = 1$ (so $\int_G$ is normalised so that the total value is $1$ ) $\int_G f(xg) dg = \int_G f(g)dg = \int_G f(gx) dg$ for all $x \in G$ (so $\int_G$ is translation-invariant) We write $\int_G f(g)dg = \int_G f$ and $\int_G f(xg) dg$ means apply $\int_G$ to $g \mapsto f(xg) \in \mathcal{C}(G, \mathbb{R})$ . $\int_G f \geq 0$ if $f(g) \geq 0$ for all $g \in G$ (positivity) I've only self-studied measure theory, and am wondering how these properties of the Haar integral relate to the Haar measure. For example, I know the Haar measure is translation invariant, like the Haar integral, but (how do) the other properties of the Haar integral correspond with other properties of the Haar measure?","['measure-theory', 'representation-theory', 'topological-groups']"
4829831,Evaluate $\int_{2}^{\frac{2}{3}}\int_y^{2-2y}(x+2y)e^{y-x}dxdy$,"Evaluate $$\int_{2}^{\frac{2}{3}}\int_y^{2-2y}(x+2y)e^{y-x}dxdy$$ My try: I actually started using the transformation $$u=x+2y, v=y-x$$ But I am really not sure, how to frame the limits for $u$ and $v$ . Any HINT please?","['integration', 'multivariable-calculus', 'calculus']"
4829959,evaluate $\lim_{n\to\infty}\frac{\sum_{i=0}^{n+3}\frac{1}{i+1}}{\sum_{i=0}^{n+7}\frac{1}{2i+1}}$,How do I evaluate this limit? $$\lim_{n\to\infty}\frac{\sum_{i=0}^{n+3}\frac{1}{i+1}}{\sum_{i=0}^{n+7}\frac{1}{2i+1}}$$ We know that $$\sum_{i=1}^{n}\frac{1}{i}\approx\ln(n)+\gamma$$ where the value of $\gamma$ is $0.577$ Similarly we can also say that $$\sum_{i=0}^{n}\frac{1}{i+1}=\ln(n+1)+\gamma$$ Therefore we can again say that $$\sum_{i=0}^{n+3}\frac{1}{i+1}=\ln(n+4)+\gamma$$ Again we can say that $$\sum_{i=0}^{n+7}\frac{1}{2i+1}=1+\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+...+\frac{1}{2n+15}$$ But after this step I can't find the exact value of the limit. Wolfram Alpha is giving the result as $2$ .,"['summation', 'sequences-and-series']"
4829973,"How to compute this ""differential sequence"" of functions?","Given a real function $f$ , define the following sequences of functions: $f_0(x) = f(x)$ ; $f_{i+1}'(x) = [f_i(x+1)-f_i(x-1)]/2$ . Some simple examples are: If $f(x)=x$ , then $f_i(x)=x$ for all $i\geq 0$ (up to an additive constant; note that adding a constant to $f_i$ does not affect $f_{i+1}$ ). Similarly, if $f(x)=x^2$ , then $f_i(x)=x^2$ for all $i\geq 0$ . The ""pattern"" breaks at 3: if $f(x)=x^3$ , then $f_i(x) = x^3 + i\cdot x$ . But for some functions, computing $f_i$ is much harder. I am particualrly interested in $f(x)=1/x$ . I get $f_1(x) = (\ln(x+1)-\ln(x-1))/2$ , but from this point on, the sequence becomes much harder to compute. QUESTIONS: Is there a simple algorithm to compute $f_i(x)$ for a general $f$ ? If not, is there a simple expression for $f_i(x)$ for the case when $f(x)=1/x$ , or at least an expression that approximates $f_i(x)$ ? Does this sequence I made up have a known name?","['ordinary-differential-equations', 'real-analysis', 'functional-analysis', 'delay-differential-equations', 'derivatives']"
4829999,A relatively compact family of probability measures that is not tight,"We know, thanks to Prokhorov's theorem, that a family of probability measures $\mathcal{H}$ in a metric space $X$ is tight if, and only if, it's relatively compact whenever $X$ is polish. The implication known as Prokhorov's direct half which states that the tightness of $\mathcal{H}$ implies the relative compactness of $\mathcal{H}$ does not require the metric space $X$ to be polish. This hypothesis is only required for the inverse half, that is: A family of probability measures $\mathcal{H}$ on a polish space is tight whenever it is relatively compact. Is there an example of a family of probability measures on a (not polish) metric space that is relatively compact but fails to be tight?","['probability-theory', 'weak-convergence']"
4830060,If G is discrete and amenable then $C^*(G)$ has the CPAP,"I have a question about the proof of Propostion 4.1 of the paper ""On Nuclear C*-algebras"" by Christopher Lance, it reads Proposition 4.1. If G is an amenable discrete group then $C^*(G)$ has the CPAP. The definition of CPAP is in the paper: Definition 3.5 . A $C^* $ -algebra $A$ has the completely positive approximation property (CPAP) if the identity mapping on $A^* $ can be approximated in the topology of simple weak*-convergence by completely positive mappings of norm one and finite rank. Lets assume that $G$ is countable and call the operators $T_n$ . My first question is regarding this definition: Question 1 By simple weak*-convergence is meant that for every $f \in A^* $ , $T_nf \rightarrow f$ in the norm of $A^* $ , or that for every $f \in A^* $ and $a \in A$ , $(T_nf)(a) \rightarrow f(a)$ ? Regarding the proof, we start by using the existence of a sequence $\sigma_n$ of functions of positive type on $G$ with finite support such that $\sigma_n \rightarrow$ $1$ pointwise ( 1 is the function that is identically 1). Then it is said we can view each $\sigma_n$ as a state on $C^*(G)$ . Question 2 Is the way that $\sigma_n$ is viewed as a state by defining $$
\sigma_n: C^*(G) \rightarrow \mathbb C \, \space u_g \rightarrow \sigma_n(g)?
$$ After that, for every $\sigma \in E(C^* (G) ) $ (the set of states in $C^* (G)$ ) they consider a map $$
T_\sigma: E(C^* (G) ) \rightarrow E(C^* (G) )  
$$ $$
\rho \rightarrow \rho\sigma
$$ which is then extended to an operator in $B(C^* (G)^* )$ . We can thus consider the family $T_{\sigma_n}$ and they prove that it is completely positive, has norm one and state that it is easy to show that they are of finite rank and tend to $1$ in the topology of weak*-convergence. Question 3 I think there is a typo and when they say ""tend to $1$ "", they mean ""tend to the identity on $C^* (G)^* $ "". Is it true that they made a typo? Question 4 This is the most important one, they claim that it is easy to show that $T_{\sigma_n}$ converge to the identity on $C^* (G)^* $ in the simple weak* topology but I am not being able to prove this. Sorry for the long post and thank you in advance!","['c-star-algebras', 'operator-algebras', 'proof-explanation', 'completely-positive-maps', 'functional-analysis']"
4830064,Numerically computing eigenvalues -- what is it useful for?,"Cross-posted on Scientific Computing Stack Exchange Are there real-world applications that call specifically for eigenvalues rather than singular values? Top eigenvalue is useful to establish convergence , but what about the rest? I often see eigendecomposition used as ""poor-man's SVD""
For instance it's used in Matlab's Lyapunov solver, but that could be reformulated in terms of SVD with greater cost ( $22n^3$ instead of $9n^3$ , Higham's big six ), while gaining numerical stability. Similarly, PCA can be done using SVD. Picture below: two linear transformations below have the same eigenvalues: Notebook","['applications', 'linear-algebra', 'numerical-linear-algebra', 'numerical-methods', 'soft-question']"
4830100,Finding kernel and image of a linear transformation (polynomial),"I have the following linear transformation: $D : V(\mathbb{R})\rightarrow V(\mathbb{R}) $ defined by: $$ D:p(x)=ax^3 +bx^2 + cx + d \mapsto Dp(x) = 3ax^2 + 2bx + c$$ And I want to find the kernel and the image of the transformation. Regarding the kernel, I have done the following $$\operatorname{ker}(D) =  \{ Dp(x) = 0 \mid x \in V\} $$ $$ p(x)=ax^3 +bx^2 + cx + d = Dp(x) = 3ax^2 + 2bx + c = 0 $$ Which can be solved through the quadratic formula. Is the answer then: $$\operatorname{ker}(D) = \left\{\frac{-b\pm\sqrt{b^2-3ac}}{3a} \right\}$$ And what about the image? I know that $\operatorname{Im}(D) = \{ Dp(x) \mid x \in V \}$ , but how can I show it?","['linear-algebra', 'linear-transformations']"
4830117,Sum of alternating series without alternating sequence.,"I'm not sure if I stated the problem correctly in the title, since my English is not very good, especially in mathematical terms. Given the following number series: $$\sum\limits_{n=1}^\infty \frac{(-1)^{\lfloor \sqrt{n}\rfloor}}{\sqrt{n}}$$ where the floor function $\lfloor t\rfloor$ - is operation of removing an integer part of a number, so $\lfloor\sqrt1\rfloor = 1$ , $\lfloor\sqrt3\rfloor = 1$ , $\lfloor\sqrt{10}\rfloor = 3$ . How to check the convergence of a given series?","['convergence-divergence', 'sequences-and-series']"
4830219,Convergence from spectrum of the Choi matrix?,"Suppose I have a linear operation of the form $T(C)=\frac{1}{m}\sum_i^m A_i C A_i$ for a set of $m$ symmetric $d \times d$ matrices $A_i$ . I construct Choi matrix below with $e_i$ referring to standard basis $$
M=\left(\begin{array}{cccc}
T(e_1 e_1^T) & T(e_1 e_2^T )& \ldots& T(e_1 e_d^T)\\
\ldots & \ldots & \ldots&\ldots\\
T(e_d e_1^T) & T(e_d e_2^T) & \ldots & T(e_d e_d^T)
\end{array}
\right)
$$ Is it possible to tell if $T$ is contractive or convergent by looking at eigenvalues of $M$ ? Note that entries of $M$ are rearrangement of entries of $T$ viewed as linear matrix acting on $\operatorname{vec}C$ ( Choi-Jamiołkowski isomorphism ) $$
T=\left(\begin{array}{c}
\operatorname{vec}T(e_1 e_1^T)^T\\
\operatorname{vec}T(e_2 e_1^T)^T\\
\ldots \\
\operatorname{vec}T(e_d e_1^T)^T\\
\operatorname{vec}T(e_1 e_2^T)^T\\
\ldots \\
\operatorname{vec}T(e_d e_d^T)^T\\
\end{array}
\right)
$$ In my application, most eigenvalues of $M$ appear zero, while most eigenvalues of $T$ not-zero, so it seems that $M$ spectrum is easier to analyze. Example: $$A=\left(
\begin{array}{cc}
 0 & 0 \\
 0 & 1 \\
\end{array}
\right),\left(
\begin{array}{cc}
 0 & -1 \\
 -1 & 0 \\
\end{array}
\right)
$$ $$M=\left(
\begin{array}{cccc}
 0 & 0 & 0 & 0 \\
 0 & \frac{1}{2} & \frac{1}{2} & 0 \\
 0 & \frac{1}{2} & \frac{1}{2} & 0 \\
 0 & 0 & 0 & \frac{1}{2} \\
\end{array}
\right)$$ $$T=\left(
\begin{array}{cccc}
 0 & 0 & 0 & \frac{1}{2} \\
 0 & 0 & \frac{1}{2} & 0 \\
 0 & \frac{1}{2} & 0 & 0 \\
 \frac{1}{2} & 0 & 0 & \frac{1}{2} \\
\end{array}
\right)$$ Eigenvalues of $M$ are ${1, 1/2, 0, 0}$ , while eigenvalues of $T$ are $\left\{\frac{1}{4} \left(\sqrt{5}+1\right),-\frac{1}{2},\frac{1}{2},\frac{1}{4} \left(1-\sqrt{5}\right)\right\}$ Notebook","['quantum-mechanics', 'operator-theory', 'linear-algebra', 'positive-definite']"
4830236,Something's not right about my understanding about identity matrices.,"I tried the following problem. Let $A = \begin{bmatrix} \alpha & 0 \\ 0 & \beta \end{bmatrix}$ and $B = \begin{bmatrix} 0 & \gamma \\ \delta & 0 \end{bmatrix}$ . There are 2 statements: $AB - BA$ is always an invertible matrix, and $AB - BA$ is never an identity matrix. Now I'm being asked to find out whether these statements are true or false. I'm not too familiar with $\LaTeX$ and I don't have enough rep to upload images, I had to put my problem as a linked image: On calculation: I first got the product of the two matrices as: $AB = \begin{bmatrix} 0 & \alpha\gamma \\ \beta\delta & 0 \end{bmatrix}$ $BA = \begin{bmatrix} 0 & \beta\gamma \\ \alpha\delta & 0 \end{bmatrix}$ $AB - BA = \begin{bmatrix} 0 & (\alpha-\beta)\gamma \\ (\beta-\alpha)\delta & 0 \end{bmatrix}$ From the above I got that $AB-BA$ cannot be an identity matrix since the main diagonal elements are all zero. So statement 2 is correct, I believe. And I also felt Statement 1 too was correct, since $|AB-BA|=\gamma\delta(\alpha-\beta)^2$ . (Ouchie, it was quite careless of me!) But the answer tells me a different story. I deduced that there are two possibilities: either the answer given is incorrect, or I have made an error somewhere and I am not able to identify.","['matrices', 'solution-verification', 'determinant', 'question-verification']"
4830281,$\phi(t)=\sqrt{1-t^2} \ $ if $|t|<1$ and $\phi(t)=0$ if $|t| \geq 1.$ Prove that $\phi(t)$ is not a characteristic function,"$\phi(t)=\sqrt{1-t^2} \ $ if $|t|<1$ and $\phi(t)=0$ if $|t| \geq 1.$ Prove that $\phi(t)$ is not a characteristic function. $\phi(t)$ checks obvious signs of a characteristic function ( $\phi(0)=1, \ |\phi(t)| \leq 1$ ). $\phi(t)$ is an even real-valued function, so if it is a characteristic function, then its corresponding random variable $X$ has a distribution that is symmetric about zero. Assuming $E|X|^k$ exists, we should have $\phi^k(0) = i^k E X^k.$ $\phi'(0) = \frac{-2t}{2\sqrt{1-t^2}} |_{t=0}=0$ (since $X$ is assumed to be symmetric, odd moments of $X$ would be $0$ , so it's correct). $\phi''(0) = \frac{-\phi(t) + \phi ' (t)(t)}{\phi^2(t)} |_{t=0} =  \frac{-1+0}{1} = i^2 EX^2 = -EX^2 \Longrightarrow EX^2 = 1$ . $\phi'''(0)$ is also $0$ , and I can't calculate further. Wolfram says $\phi''''(0)=3$ ; I see no use for it. Finding pdf from the ""characteristic function"" (Wolfram calculated the integral): $p(x)=\frac{1}{2\pi} \int_{t=-1}^{t=1} \cos(tx) \sqrt{1-t^2} dt = \frac{\pi J_1(x)}{x},$ where $J_1(x)$ is ""Bessel function of the first kind"" (we haven't studied it). Could someone please help me see how $\phi(t)$ is not a characteristic function?","['characteristic-functions', 'probability-theory', 'density-function']"
4830300,How to prove this general form of the BBP formula?,"Question How to prove the general form of the BBP(Bailey–Borwein–Plouffe) formula? Prove this formula is always true, or find a counterexample $k$ that makes the formula invalid: $$
π≟\sum_{n=0}^∞ \frac{1}{2^{4kn+4k+4 n+3}}\sum_{m=0}^{8k+8}\frac{ (1-i)^{m+1}+(1+i)^{m+1}-2^{m/2}\left((-1)^m+1\right)}{8kn+8k+8n-m+8},∀ k∈\mathbb{N}
$$ Background I discovered this formula while solving this problem: Find pattern for BBP-type π formulas for order 28? When $k = 0$ , the original BBP formula is given, in which the coefficients are not simplified, and the rules are not obvious after simplification. $$
π=\underset{n=0}{\overset{\infty }{\sum }}4^{-2 n-1} \left(\frac{16}{8 n+1}-\frac{8}{8 n+4}-\frac{4}{8 n+5}-\frac{4}{8 n+6}\right)
$$ When $k = 1$ , the following formula is given: $$
π=\underset{n=0}{\overset{\infty }{\sum }}4^{-4 n-3} \left(\frac{256}{16 n+1}-\frac{128}{16 n+4}-\frac{64}{16 n+5}-\frac{64}{16 n+6}+\frac{16}{16 n+9}-\frac{8}{16 n+12}-\frac{4}{16 n+13}-\frac{4}{16 n+14}\right)
$$ When $k = 2$ , the following formula is given: $$
π=\underset{n=0}{\overset{\infty }{\sum }}4^{-6 n-5} \left(\frac{4096}{24 n+1}-\frac{2048}{24 n+4}-\frac{1024}{24 n+5}-\frac{1024}{24 n+6}+\frac{256}{24 n+9}-\frac{128}{24 n+12}-\frac{64}{24 n+13}-\frac{64}{24 n+14}+\frac{16}{24 n+17}-\frac{8}{24 n+20}-\frac{4}{24 n+21}-\frac{4}{24 n+22}\right)
$$ Numerical verification of higher order can also be passed. A quick numerical verification can be done with the following Mathematica code. ExtendBBP[k_] := Inactive[Sum][2^(-3 - 4k - 4n - 4k * n)*Sum[
    ((1-I)^(m+1)+(1+I)^(m+1)-2^(m/2)(1+(-1)^m))/
    (8 + 8k - m + 8n + 8k * n),
    {m, 0, 8 + 8k}], 
    {n, 0, Infinity}
]; 
N[Activate[ExtendBBP[0] - Pi], 200]
N[Activate[ExtendBBP[1] - Pi], 200]
N[Activate[ExtendBBP[2] - Pi], 200]","['pi', 'sequences-and-series']"
4830431,"Prove $\,\lim\limits_{n\to\infty} \sqrt{\frac{4n+1}{n}}=2$","As shown in the title, I'm asked to prove $\lim\limits_{n\to\infty} \sqrt{\dfrac{4n+1}{n}}=2$ using the $\epsilon,N$ definition only. My solution was completely different from the solution they posted so I want to know if I did something wrong. Let $\epsilon>0$ , we have to find $N$ s.t $\forall n>N$ . $\left|\sqrt{\dfrac{4n+1}{n}}-2\right|<\epsilon$ . Since $n$ is iterating over naturals, we can say that $\sqrt{\dfrac{4n+1}{n}}-2$ is always positive by plugging in the minimum of $\mathbb{N}$ . I continued by multiplying by $\left(\sqrt{\dfrac{4n+1}{n}}+2\right)$ .\ $\dfrac{\left(\sqrt{\dfrac{4n+1}{n}}-2\right)\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}{\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}= \dfrac{\dfrac{4n+1}{n}-4}{\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}\stackrel{(*)}{<}\dfrac{1}{n}$ while (*) was using the previous conclusion that the denominator is always positive and greater than $1$ . Now I can say that we can take $N=\dfrac{1}{\epsilon}+10$ and this satisfies the desired.","['limits', 'calculus', 'epsilon-delta', 'sequences-and-series']"
4830505,"Roll a dice infinitely many times, what is the probability of getting a 5 before a 6","My proof: For all possible events, based on the order of appearance between 5 and 6.l, they can be categorised into 2 groups. $A:$ event with 5 appear before 6 $A^{c}:$ event with 6 appear before 5 And the union of $A$ and $A^{c}$ should be all possible events. So $P(A) + P(A^{c}) = 1$ The last step: by symmetry, number of events that have 5 before 6 is the same as that for 6 before 5. So $P(A) = P(A^{c}) = 0.5$ However, this last step I am not sure  how to write out a formal proof to support my intuition for the symmetry. I think I need to evaluate the cardinality $A$ and $A^{c}$ but not sure how to. So I need help here.","['dice', 'probability-theory', 'probability']"
4830550,A curious property of the fractional part,"I've found a curious property of the fractional part. Namely, let be given a number $n$ . Then among the numbers $
n/1, n/2, n/3, .... n/n,
$ the proportion of elements whose fractional part is $\geq 1/2$ tends to $2.588\ldots$ as $n$ tends to $\infty$ .
Here is the Python code that helped me to discover this fact, by giving various values to $n$ . n = 7379491
count = 0
for i in range(1, n):
    if n/i - n//i >= 0.5:
        count += 1

print(""{}, {}"".format(n, n/count)) Is it something known? what is the rationale behind this?","['number-theory', 'fractional-part']"
4830616,Fascinating property of the Dirichlet Beta function,"I was originally investigating the definite integral $$\ I = \int_0^{\frac{\pi}{4}} \cos(\ln(\tan x))dx$$ After substituting $\ln(\tan x) = u$ and changing the upper and lower bounds, the integral simplified into $$\ I =  \int_0^{\infty} \frac{\cos u \cdot e^u}{1+e^{2u}}du$$ Which is nothing else but $$\ I = \frac{1}{2} \cdot \int_0^{\infty} \frac{\cos u}{\cosh u} du$$ Now, I considered the Maclaurin series of $\cos x$ : $$ \cos x = \sum_{n=0}^{\infty}(-1)^n \cdot \frac{x^{2n}}{(2n)!}$$ Then, I substituted this summation inside the integral: \begin{align}
 I 
&=  \int_0^{\infty} \frac{e^u}{1+e^{2u}} \cdot \sum_{n=0}^{\infty}(-1)^n \cdot \frac{u^{2n}}{(2n)!} du \\
&= \int_0^{\infty} \frac{e^u}{1+e^{2u}}du - \frac{1}{2!}\cdot \int_0^{\infty} \frac{u^2e^u}{1+e^{2u}}du + \frac{1}{4!} \cdot \int_0^{\infty} \frac{u^4e^u}{1+e^{2u}}du +\ldots 
\end{align} Rearranging the terms, we get: $$ I  = \sum_{n=0}^{\infty}\frac{(-1)^n}{(2n)!} \cdot \int_0^{\infty} \frac{u^{2n}e^u}{1+e^{2u}} du $$ As seen here and substituting $\ 2n$ instead of $\ n$ , we get: $$\int_0^{\infty} \frac{u^{2n}e^u}{1+e^{2u}} du = \Gamma(2n+1)\beta(2n+1) = (2n)!\beta(2n+1)$$ Substituting this equality into our original integral, note that the $(2n)!$ terms cancel and we obtain $$\ I = \sum_{n=0}^{\infty}(-1)^n\beta(2n+1)$$ Meanwhile, from the comments in the answer of the same question , setting $\ t =1$ , we have: $$\ I = \frac{1}{2}\int_0^{\infty} \frac{\cos u}{\cosh u} du = \frac{\pi}{4}\cdot \operatorname{sech}(\frac{\pi}{2})$$ Then, is it valid to assert the below equality? $$\sum_{n=0}^{\infty}(-1)^n\beta(2n+1) = \frac{\pi}{4} \cdot \operatorname{sech}(\frac{\pi}{2})$$ Which seems to be true, as per WolframAlpha at least. Can we derive it via any other method? The sum on the LHS feels like a daunting one, but it turns out to be equal to this rather simplified expression on the right. Also - as pointed out in the comments, the limit as k approaches ${\infty}$ of $\beta(2k+1)$ should be $\ 1$ . Given that this is true, how do we explain the fact that this sum converges? Thank you for reading. Any suggestions are appreciated.","['integration', 'definite-integrals', 'special-functions', 'calculus', 'sequences-and-series']"
4830618,How do I take $\dfrac d{dx}W(x+\ln|x+2|+c)$?,"So 4 days ago, I asked this question on how to solve the differential equation $$(xy+2y+x+2)y'=e^{-y}(x+3)$$ which I was able to solve, with the solution being $$W(x+\ln|x+2|+b),b=c_0-c_1$$ where $W(z)$ is Lambert's $W$ function, however I don't know how to verify this answer. Sure, as @Moo mentioned, all I have to do is plug in $W(x+\ln|x+2|+b)$ into the original equation, but that involves taking $\frac d{dx}W(x+\ln|x+2|+b)$ , which I don't know how to do. So my question is: How do I go about taking $\frac d{dx}W(x+\ln|x+2|+b)$ , where $W(z)$ is Lambert's $W$ function, also known as the product log function?","['calculus', 'derivatives']"
4830633,Second order nonlinear ODE with a squared first derivative,"In the context of an HJB equation for a control problem that I'm trying to solve, I have encountered the following ODE $$
 4 \gamma  \zeta ^2 \beta  g(x) = \zeta ^2 \left(2 \gamma  \sigma ^2 x^2 g''(x)+1\right)-2 \zeta  g'(x) \left(\rho +2 \gamma  \zeta  x \left(\mu -\rho -\sigma ^2\right)\right)+\rho ^2 g'(x)^2\ .
$$ where Greek letters are constants. Setting each of these equal to unity simplifies the above to $$
 4 g(x)=2 x^2 g''(x)+g'(x)^2+2 (2 x-1) g'(x)+1\ ,
$$ This latter ODE in fact admits the non-trivial solution $g(x) = x - 2 x^2$ . Is there any way to apply this knowledge to full problem?","['ordinary-differential-equations', 'reference-request']"
4830638,Is strict positivity preserved by weak convergence?,If $\{u_n:\Omega\to \mathbb{R}\}$ is a continuous function sequence such that $u_n>0$ for all $n\in \mathbb{N}$ and suppose that $u_n$ converges weak to $u \in L^2(\Omega)$ . Can I obtain $u>0$ ?,"['measure-theory', 'functional-analysis', 'weak-convergence']"
4830644,"What do physicists mean when they say something is ""not a vector""?","It's common for physicists to say that not every 3-tuple of real numbers is a vector: “Well, isn’t torque just a vector?” It does turn out to be a vector, but we do not know that right away without making an analysis.... because force is a vector it transforms into the new system in the same way as do $x$ , $y$ , and $z$ , since a thing is a vector if and only if the various components transform in the same way as $x$ , $y$ , and $z$ . Richard Feynman You might be inclined to say that a vector is anything that has three components that combine properly under addition. Well, how about this: We have a barrel of fruit that contains $N_x$ pears, $N_y$ apples, and $N_z$ bananas. Is $N = N_x\hat{x} + N_y\hat{y} + N_z\hat{z}$ a vector? It has three components, and when you add another barrel with $M_x$ pears, $M_y$ apples, and $M_z$ bananas the result is $(N_x + M_x)$ pears, $(N_y + M_y)$ apples, $(N_z + M_z)$ bananas. So it does add like a vector. Yet it’s obviously not a vector, in the physicist’s sense of the word, because it doesn’t really have a direction. What exactly is wrong with it? David J. Griffiths, Introduction to Electricity and Magnetism, 1.15 Interestingly, Griffiths' example of apples and bananas not being a vector is almost identical to Strang's example of what a vector is: ""You can't add apples and oranges."" In a strange way, this is the reason for vectors.
We have two separate numbers $V_I$ and $V_2$ . That pair produces a two-dimensional vector $v$ . Gilbert Strang, Introduction to Linear Algebra, 1.1 What do physicists mean then when they say a certain $(x,y,z)$ isn't a vector? Certainly any element of $\mathbb R^3$ is a vector. The sources talk about being the same under coordinate transforms: but of course any transform of $(x,y,z)$ yields a particular $(x', y', z')$ value.  What does it mean for a 3-tuple to be invariant under transform? Is there a way of expressing the physicists' statement clearly and precisely? How can I test if a certain tuple (or function) ""is"" a vector? Can this statement be put into mathematical language: $f: \mathbb R^3 \to \mathbb R^3$ is a physicists' vector if...","['physics', 'linear-algebra', 'vectors', 'applications']"
4830647,Can one find commuting homotopies of maps?,"Say $X$ is a topological space, and $f_0, f_1, g: X \to X$ are continuous self-maps. Let's assume that both $f_0$ and $f_1$ commute with $g$ , i.e. $$f_i \circ g = g \circ f_i \quad \text{for} \quad i=1,2.$$ Assume furthermore that $f_0$ is homotopic to $f_1$ . Is there any hope that there exists a homotopy $f_t:[0,1] \times X \to X$ which commutes with $g$ , i.e. $$f_t \circ g = g \circ f_t \quad \forall t \in [0,1]?$$","['general-topology', 'homotopy-theory', 'algebraic-topology']"
4830650,How are combinatorial classes and combinatorial species related?,"I am reading through Analytic Combinatorics by Flajolet and Sedgewick and I feel pretty confident with my understanding of classes and how they relate to EGFs. However recently I encountered the concept of combinatorial species, and it seems like both concepts essentially do the same thing in relation to EGFs. I'm wondering what is the relation between combinatorial species and combinatorial classes? For example I would like to know if there is some big difference I'm missing, if there is some advantage to using one over the other, or if one is more general than the other. If both concepts are analogous, then are they just different ways to formalize the same thing, or is there some historical reason why they were both developed? Thank you for helping my understanding. Edit: By classes I mean labelled classes. Sorry for the unclear wording.","['analytic-combinatorics', 'combinatorics', 'combinatorial-species']"
4830676,Definition of weak convergence,"Weak convergence came up in my PDE class and I'm trying to understand it even though I lack background in topology and functional analysis. Please check if my understanding is correct. Definition : Let $X$ be a real Banach space with norm $\left\lVert . \right\lVert_{X}.$ A sequence $(x_n)_{n \in \mathbb{N}}$ converges weakly to $x \in X,$ if for all continuous linear functionals $f: X \rightarrow \mathbb{R}, f(x_n) \rightarrow f(x).$ Question: Why is this equivalent to convergence in the weak topology? $\bullet$ Weak topology: The coarsest topology so that all continuous linear functionals on $X$ are still continuous. Note that we started with some topology on $X$ with respect to which we identify the linear continuous functionals. In a Banach space, we start with the norm-induced topology (Please confirm if my understanding is correct, this is not explicitly stated in my course but I guess it is obvious) . $\bullet$ Convergence wrt a topology $\mathcal T$ on $X$ : $(x_n)_{n \in \mathbb{N}} \subset X$ converges to $x \in X,$ if for every open set $\mathcal O \in \mathcal T,$ such that $x \in \mathcal O,$ there is $N \in \mathbb{N},$ so that $x_n \in \mathcal O$ $ \forall n \geq N.$ Is my intuition below correct? The weak topology consists of sets $(\phi_{1})^{-1}(A_1), ..., (\phi_{n})^{-1}(A_n),$ where $\phi_{k}$ is a linear continuous functional and $A_k$ an open set in $\mathbb{R}.$ ( see link at the end of my post ) If $x_n$ converges to $x$ wrt to the weak topology, then for each set of the above form, if $x \in (\phi_{1})^{-1}(A_1), ..., (\phi_{n})^{-1}(A_n),$ $x_n \in (\phi_{1})^{-1}(A_1), ..., (\phi_{n})^{-1}(A_n) \forall n \geq N$ for some $N \in \mathbb{N}.$ Using the definition of preimage, it means that $ \phi_{j}(x) \in A_j $ for some $j \in [n]$ implies that $\phi_{j}(x_n) \in A_j \forall n$ large enough. And we would have to do this for every single continuous linear functional. That's why the convergence wrt to the weak topology amounts to the definition I started with. Is this intuition correct? Some intuition about weak topology - Was useful for understanding the weak topology.","['banach-spaces', 'weak-convergence', 'weak-topology', 'dual-spaces', 'general-topology']"
4830688,"With some conditions on $f$, resolve the claim $|f(x)-f(y)|\le|x-y|$ for all $x,y\in[0,1]$.","Here's the problem . . . Prove or disprove: $\;$ If $f:[0,1]\to\mathbb{R}$ is a twice differentiable function such that $f(0)=f(1)=0$ . $|f''(x)|\le 2$ for all $x\in[0,1]$ . then $|f(x)-f(y)|\le|x-y|$ for all $x,y\in[0,1]$ . Some context . . . This problem was posted yesterdayby @Alex (user 1258161) https://math.stackexchange.com/questions/4829557/ but was closed for lack of context, and then deleted by the post author. I found the problem interesting so I tried it just for fun. Considering the possibility that the claim might be false, I first tried to construct a counterexample. Not finding one, I tried to prove the claim, but so far without success. Perhaps I'm missing something simple, a commonly used approach or a standard trick. In any case, as shown below, I made some progress, and perhaps my partial results could be of some use in the quest for a complete solution. Attempting to prove the claim, here's what I tried . . . Assume the hypothesis and suppose $|f(u)-f(v)| > |u-v|$ for some $u,v\in[0,1]$ . Our goal is to derive a contradiction. We can assume $u < v$ , else replace $f(x)$ by $f(1-x)$ . $f(u) > f(v)$ , else replace $f(x)$ by $-f(x)$ . Thus we have $f(u)-f(v) > v-u$ . By the MVT, there exists $a\in(u,v)$ such that $f(u)-f(v)=f'(a)(u-v)$ , hence $f'(a) < -1$ . By the MVT, for arbitrary $x\in[0,1]{\setminus}\{a\}$ , there exists $b$ with $\min(x,a) <  b < \max(x,a)$ such that $f'(x)-f'(a)=f''(b)(x-a)$ , so $f'(x) < 1$ . Thus we have $f'(x) < 1$ for all $x\in[0,1]$ . Then by the MVT Since $f(0)=0$ , it follows that $f(x) < x$ for all $x\in(0,1]$ . Since $f(1)=0$ , it follows that $f(x) > x-1$ for all $x\in[0,1)$ . By Rolle's Theorem, there exists $c\in(0,1)$ such that $f'(c)=0$ . By the MVT, for arbitrary $x\in[0,1]{\setminus}\{c\}$ , there exists $d$ with $\min(x,c) < d < \max(x,c)$ such that $f'(x)-f'(c)=f''(d)(x-c)$ , so $f'(x) > -2$ . Thus we have $f'(x) > -2$ for all $x\in[0,1]$ . Then by the MVT Since $f(0)=0$ , it follows that $f(x) > -2x$ for all $x\in(0,1]$ . Since $f(1)=0$ , it follows that $f(x) < 2-2x$ for all $x\in[0,1)$ . Then we have $f(x) < \min(x,2-2x)$ for all $x\in(0,1)$ , hence $f(x) < 2/3$ for all $x\in[0,1]$ . $f(x) > \max(-2x,x-1)$ for all $x\in(0,1)$ , hence $f(x) > -2/3$ for all $x\in[0,1]$ . That's my progress so far. How to resolve the problem?","['mean-value-theorem', 'calculus', 'real-analysis']"
4830695,Determine sets elements from their union and intersection using only math reasoning if possible,"We have $E=\{a,b,c,d,e\}$ and $A,B$ & $C$ are subsets of $E$ such that: $$A\cup B = \{b,c,d,e\}$$ $$A\cap B = \{b,d\}$$ $$A\cup C = \{a,b,c,d\}$$ $$A\cap C = \{b,c\}$$ How to determine the sets $A, B$ and $C$ . Please, using only math and i mean by that not using logic, it's hard to explain what i mean by that. I determined them but without using any math i just knew that $A = \{b,c,d\}$ and $B=\{b,d,e\}$ and $C=\{b,c,a\}$ I wanna know is there any mathematical proof to determine them like using set theory laws...",['elementary-set-theory']
4830769,Does $\int_{1}^{2}\ln\left(x+\ln\left(x^2+\ln\left(x^3+\ln\left(\dots\right)\right)\right)\right)dx=1$?,"I was messing around with the infinitely nested logarithm $f(x)=\ln\left(x+\ln\left(x^2+\ln\left(x^3+\ln\left(\dots\right)\right)\right)\right)$ on Desmos when I decided to take the integral from $x = 1$ to $x = 2$ . Here's what I got where $n$ represents the number of times the logarithm is nested. For example, for $n=1$ , it is $f_1(x)=\ln\left(x\right)$ and for $n=2$ , it is $f_2(x)=\ln\left(x+\ln\left(x^2\right)\right)$ . $$\begin{array}{c|c} 
 \text{n} & \int_{1}^{2}{f_n(x)}dx \\ \hline
 1 & 0.38629436112 \\ \hline
 2 & 0.769701324476 \\ \hline
 3 & 0.923253197047 \\ \hline
 4 & 0.968765188969 \\ \hline
 5 & 0.982950647903 \\ \hline
 10 & 0.992710069039 \\
\end{array}$$ $\therefore\text{I conjecture that it converges to $1$}$ Can someone help me analytically prove or refute my conjecture? I lack the skills to do it. P.S. I could not figure out a closed form for the infinitely nested logarithm but I assume finding one would make this a lot easier to prove.","['integration', 'conjectures', 'definite-integrals', 'logarithms', 'convergence-divergence']"
4830791,Did I set up the equation for the Mittag-Leffler theorem correctly?,"From the wiki page , it looks like a meromorphic the function is written as $$f(z) = \sum_{a\in E}p_a(z)$$ where $p_a(z)$ is the principal part (a Laurent series), $a$ is the place where a singularity occurs and I is the points belonging to some open set where the singularities occur. It looks like in the theorem, it also defines $p_a(z) = \sum_{n=1}^{N_a}\frac{c_{a,n}}{(z-a)^n}$ So let's say I have one of the examples on the page $\cot(z)$ , we would have a singularity at the points $z=0$ and $z=n\pi$ and this would occur for all integers $-\infty \le n \le \infty$ , so if I were to write this out, I would get: $$f(z) = \cot(z) = \frac{\cos(z)}{\sin(z)} = \lim_{N\rightarrow\infty} \sum_{n=-N}^N \Big( \sum_{n=1}^{N_a}\frac{c_{n\pi,n}}{(z-n\pi)^n}\Big)$$ I'm assuming that after finding $p_a(z)$ from finding the Laurent series (however that's done, I've never done one myself), the sum ends up becoming: $$f(z) = \lim_{N\rightarrow \infty} \sum_{n=-N}^N \frac{1}{z-n\pi}$$ . Is that correct? Note: Something unusual I noticed in the example for $\cot(z)$ is that despite $\frac{1}{z-n\pi}$ not being even (nor odd), it appears that the infinite sum was simplified by being split and doubled i.e.: $$\sum_{-N}^N a_n = a_0 + 2\sum_{n=1}^N a_n$$ .","['complex-analysis', 'mittag-leffler-function']"
4830928,"Take a random walk on a Christmas tree, starting at the top. What is the probability of returning to the top?","Consider a ""Christmas tree lattice"" composed of equilateral triangles, as shown. The lattice extends down infinitely. Start at the top vertex and take a random walk. At each step, move to a randomly chosen neighboring vertex, each with equal probability. Re-visiting vertices is allowed. What is the probability of returning to the top? Context I was reading about Polya's random walk constants , and with all the Christmas trees appearing these days, this question naturally arose. My thoughts Let $p(k)$ be the probability of returning to the top for the first time on the $k$ th step, and let $P(n)=\sum\limits_{k=2}^n p(k)$ . We are looking for $P(\infty)$ . According to my calculations, based on counting paths: $p(2)=\frac14$ $p(3)=\frac{1}{4^2}=\frac{1}{16}$ $p(4)=\frac{2}{4^3}+\frac{1}{4^2\cdot3}=\frac{5}{96}$ $p(5)=\frac{3}{4^4}+\frac{4}{4^3\cdot 3}=\frac{25}{768}$ $p(6)=\frac{6}{4^5}+\frac{21}{4^4 6}+\frac{12}{4^3 6^2}+\frac{4}{4^2 6^3}=\frac{179}{6912}$ Calculating gets progressively harder. $P(6)=\frac14+\frac{1}{16}+\frac{5}{96}+\frac{25}{768}+\frac{179}{6912}=\approx 0.423032$ . I guess $P(\infty)<1$ , because whenever the path touches the boundary of the tree, the probability of going down is double the probability of going up. If we have a triangular lattice (instead of a Christmas tree), the probability of returning to the origin is presumably $1$ . Edit In the comments, @user has provided values of $P(n)$ for $n=5,6,50,100, 150, 200, 250,300$ . (I got the same results for $n=5,6$ .) Here is a graph of $P(n)$ against $n$ , for $n=2,6,50,100,150,200,250,300$ .","['random-walk', 'graph-theory', 'sequences-and-series', 'limits', 'probability']"
4830937,Jacobian computes the Zariski cotangent space at a rational point,"In Vakil's Foundations of Algebraic Geometry ( July 31, 2023 version ), he has the following Exercise (13.1.I): Suppose $X$ is a finite type $k$ -scheme. Then
locally it is of the form $\operatorname{Spec} k[x_1, \dots , x_n]/(f_1, \dots , f_r)$ . Show that the Zariski cotangent space at a $k$ -valued point (a closed point with residue field $k$ ) is given by the
cokernel of the “Jacobian map” $k^r\to k^n$ given by the Jacobian matrix $$J=\begin{pmatrix}\frac{\partial f_1}{\partial x_1}(p) & \cdots & \frac{\partial f_r}{\partial x_1}(p)\\ \vdots & \ddots & \vdots\\ \frac{\partial f_1}{\partial x_n}(p) & \cdots & \frac{\partial f_r}{\partial x_n}(p)\end{pmatrix}$$ and I'm completely stumped trying to solve it. Per a hint Vakil gives, I'm only considering the case where $p$ is the origin (and then want to do a change of coordinates for any $p$ not the origin) but even in this case I can only prove the statement for $r = 0$ , where its trivial. This answer details a way to do something similar (which would immediately give me the answer here), but I cannot follow the proof outline given.",['algebraic-geometry']
4831000,"The pushforward of a locally free sheaf along $\Bbb P^1\to\Bbb P^1$, $t\mapsto t^2$ is locally free","Let $X,Y$ be $\mathbb{P}^{1}_{\mathbb{C}}$ , and $f:X\to Y$ is a morphism given by $$
(x_0:x_1)\mapsto(y_0:y_1)=(x_0^2:x_1^2).
$$ I want to prove that (1) $f_*\mathscr{O}_X$ is locally free sheaf of rank two; (2) $i:\mathscr{O}_Y\to f_{*}\mathscr{O}_X$ is injective; (3)The cokernel of $i$ isomorphic to the twisting sheaf $\mathscr{O}_Y(-1)$ . Where $\mathscr{O}_Y(-1)$ is a sheafification of $\mathscr{O}^{'}_Y(-1)$ , and $\mathscr{O}^{'}_Y(-1)$ is a presheaf on $Y$ by $$
\mathscr{O}^{'}_Y(-1)(U) = \{\frac{f}{g}\mid g(P)\neq 0,\forall P \in U\subset Y\}.  
$$ $f,g$ are homogeneous polyhomials with degree $f =$ degree $g -1$ . I know that the pushforward of locally free sheaf doesn't need to be locally free, but in this special case, this holds true.But I don't know how to prove it. About (2),I thought of considering the kernel of $i$ ,but I don't know how to describe the morphism $i$ . Please give me some hints.","['pushforward', 'algebraic-geometry', 'sheaf-theory']"
4831059,"Necessary and sufficient conditions for a Boolean function $f$ in $n$ variables to satisfy $f(x_1,x_2,...,x_n)=f(x_n,...,x_2,x_1)$? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 months ago . Improve this question What are necessary and sufficient conditions for a Boolean function $f$ in $n$ variables to satisfy $$f(x_1,x_2,...,x_n)=f(x_n,...,x_2,x_1)?$$ Functions like this may be useful in cryptographic algorithms, so I need a way to search for them.","['functions', 'boolean-algebra', 'abstract-algebra', 'logic']"
4831061,Kernel of an operator defined by a power series,"Let $K = K(x,y) \in L^{2}(\mathbb{R}^{d}\times \mathbb{R}^{d})$ . This function defines an integral operator on $L^{2}(\mathbb{R}^{d})$ , which I denote by $K$ , as follows: $$(Kf)(x) = \int_{\mathbb{R}^{d}}K(x,y)f(y)dy$$ This operator $K$ is proven to be a Hilbert-Schmidt operator, with Hilbert-Schmidt norm $\|K\|_{\mathcal{J}_{2}}$ . Analogously, the complex conjugate $\overline{K} = \overline{K(x,y)}$ induces an operator $\overline{K}$ on $L^{2}(\mathbb{R}^{d})$ . Next, consider the operators $A_{K}$ and $B_{K}$ defined by its power series: $$A_{K} = \sum_{n=0}^{\infty}\frac{(K\overline{K})^{n}K}{(2n+1)!} \quad \mbox{and} \quad B_{K} = \sum_{n=1}^{\infty}\frac{(K\overline{K})^{n}}{(2n)!}$$ These two series converge in the Hilbert-Schmidt norm, so these operators are well-defined as Hilbert-Schmidt operators. Hence, both $A_{K}$ and $B_{K}$ can be written as integral operators, with integral kernels $A_{K}(x,y)$ and $B_{K}(x,y)$ , that is: $$(A_{K}f)(x) = \int_{\mathbb{R}^{d}}A_{K}(x,y)f(y)dy \quad \mbox{and} \quad (B_{K}f)(x) = \int_{\mathbb{R}^{d}}B_{K}(x,y)f(y)dy $$ Questions: Suppose that $K$ (and, consequently, $\overline{K}$ ) is symmetric in the sense that $K(x,y) = K(y,x)$ for every $x,y \in \mathbb{R}^{d}$ . Is it true that $A_{K}(x,y) = A_{K}(y,x)$ and $B_{K}(x,y) = B_{K}(y,x)$ as well? What about the product $KA_{K}$ and $KB_{K}$ ? Do they satisfy $(KA_{K})(x,y) = (KA_{K})(y,x)$ and $(KB_{K})(x,y) = (KB_{K})(y,x)$ ? Note: the notation $K\bar{K}$ means composite maps: $$((K\bar{K})f)(x) = \int_{\mathbb{R}^{d}}dy K(x,y) \int_{\mathbb{R}^{d}}dz \overline{K(y,z)}f(z)$$","['operator-theory', 'functional-analysis', 'analysis']"
4831139,Residue of the function: $\sin(\frac{1}{z^2+1})$ at $z = i$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 6 months ago . Improve this question Residue of $$\sin(\frac{1}{z^2+1})$$ at $z = i$ . I've tried to find its Laurent series, but it's seemed too complicated, so i don't know what to do..","['complex-analysis', 'residue-calculus']"
4831173,A Non-Metrizable subspace of a compact,"Let $K$ be a Hausdorff compact space in which every closed set is $G_{\delta}$ . Suppose that $X$ is a non-metrizable subspace of $K$ . Prove that $X$ cannot be written as $X=\bigcup_{n=1}^{\infty}X_{n}$ where each $X_{n}$ is a metrizable subspace of $X$ . My attempt: It is clear that $K$ is a normal space. Furthermore, $K$ is perfectly normal. It is useful to notice that the property of being perfectly normal is hereditary. Assume the contrary, i.e., let $X=\bigcup_{n=1}^{\infty}X_{n}$ , where each $X_{n}$ is metrizable. By Bing-Nagata-Smirnov theorem, each $X_{n}$ has a countably locally finite basis. Then $X$ has a countably locally finite basis (is it true?). As noted above, the space $X$ is perfectly normal. Therefore, $X$ is regular. Consequently, $X$ is a regular space with a countably locally finite basis. Hence, $X$ is metrizable in virtue of Bing-Nagata-Smirnov theorem. This is a contradiction. Firstly, is my proof correct? Secondly, I would like to find a proof which does not involve the metrization theorem of Bing, Nagata, Smirnov.",['general-topology']
4831230,Check my work: Find almost sure limit of product of uniform distributions,"Suppose $\{\xi_n\}$ are i.i.d uniform random variables on $[0,1]$ , and $$\eta_n = 2^n\Pi_{i=1}^n\xi_i$$ then: Show that $\{\eta_n\}$ is a martingale, Find the almost sure limit of $\{\eta_n\}$ Determine if $\{\eta_n\}$ is uniformly integrable. I have no problem with the first part, I also know that $-\log\xi_i$ follows exponential distribution with parameter $1$ , so $$\log(2^n\eta_n^{-1})\sim \text{Gamma}(n,1)$$ and consequently the pdf is given by $$f_{\eta_n}(t)=\frac{(-\log(t)+n\log 2)^{n-1}}{(n-1)!2^{-n}}$$ using Stirling's formula, for every fixed $t$ there is \begin{align}
f_{\eta_n}(t)&=\frac{(-\log(t)+n\log 2)^{n-1}}{(n-1)!2^{-n}}\\
&=\frac{(n\log 2)^{n-1}(1-\frac{\log t/\log 2}{n})^{n-1}}{(n-1)!2^{-n}}\\
&\approx e^{\log t/\log 2}\sqrt{2\pi n}^{-1}(2^{-1}\cdot e\cdot \log 2)^{n-1}\left(\frac{n}{n-1}\right)^{n-1}\\
&\approx \sqrt{2\pi n}^{-1}e^{\log t/\log 2+1}(0.94)^{n-1}
\end{align} which goes to zero as $n$ goes to $\infty$ . So what is the almost sure limit? Is the martingale uniformly integrable?","['uniform-distribution', 'uniform-integrability', 'solution-verification', 'martingales', 'probability-theory']"
4831249,weakened $L^p$ interpolation using the Fourier transform?,"It is easy to see that $$f\in L^\infty(\mathbb R^d), \ f\in L^1(\mathbb R^d) \implies f\in L^p(\mathbb R^d) \ \text{for all}\  p\in[1,\infty] \label{1}\tag{A}$$ Indeed, $ \int|f|^p \le \|f\|_{L^\infty}^{p-1}\|f\|_{L^1}. $ Let $\hat f$ denotes the Fourier transform. Another well-known easy result is $$ \|\hat f\|_{L^\infty} \le \|f\|_{L^1}.$$ It seems natural then to ask if the following generalisation of \eqref{1} could hold? $$f\in L^\infty(\mathbb R^d), \ \hat f\in L^\infty(\mathbb R^d) \implies f\in L^p(\mathbb R^d) \ \text{for some}\  p\in(1,\infty] \label{2}\tag{B}$$ I know that \eqref{2} for $p=1$ is false in general by taking $d=1,f(x)=\frac{\sin x}x\notin L^1$ since $f\in L^p$ for all $p>1$ and $\hat f = C \mathbf 1_{[-1,1]} \in L^\infty$ . Could it be true for any other values of $p$ ? Dare I hope for all $p\in(1,\infty]$ ?","['fourier-analysis', 'harmonic-analysis', 'real-analysis', 'lp-spaces', 'integral-inequality']"
4831269,Closed form for $\int_0^1\left(\frac1x-1\right)^x\mathrm dx$?,"Is there a closed form for $I=\int_0^1\left(\frac1x-1\right)^x\mathrm dx\approx 0.838104577482$ ? That is, can $I$ be expressed in terms of known functions (elementary or otherwise) or established constants? I know this is not is not a strict definition of ""closed form""; I'm just trying to see what can be said about this integral. Wolfram does not give a closed form. Here is the graph of $y=\left(\frac1x-1\right)^x$ . (It is close to the cubic curve $y=4x^3-8x^2+3x+1$ for $0<x<1$ .) Context I'm interested in Pascal's triangle, in particular, numbers that represent the entire triangle . I found that if we take the $n$ th root of each number in Pascal's triangle, where $n$ is each number's row number, then the mean value of the resulting numbers for the entire triangle is $2\int_0^1\left(\frac1x-1\right)^x\mathrm dx\approx 1.67620915496$ . I'm wondering if this value has a closed form. Related fun fact: If we take the log of the $n$ th root of each number in Pascal's triangle, where $n$ is each number's row number, then the mean value of the resulting numbers for the entire triangle is $\dfrac12$ and  the variance is $\dfrac{21-2\pi^2}{36}$ . Related integrals $\int_0^1 \frac{1}{x^x}\mathrm dx\approx 1.2913$ (which equals $\sum\limits_{n=1}^\infty \frac{1}{n^n}$ ) does not have a closed form. $\int_0^\infty \frac{1}{x^x}\mathrm dx\approx 1.9955$ does not have a closed form (but it can be shown to be less than $2$ ).","['integration', 'definite-integrals', 'calculus', 'binomial-coefficients', 'closed-form']"
4831274,Is there any sequence of closed shapes whose limit tends to the unit circle while the limit of the perimeter goes to infinity?,"I know there is a simple method that generates a sequence of closed shapes whose limit is the unit circle but the limit of the perimeter is not $2\pi$ , but in all of the cases that I know , the perimeter limit is finite. How we can generate a sequence of shapes whose limit tends to unit circle but the limit of the perimeter is infinity?","['limits', 'geometry', 'fractals']"
4831285,For which $\{a_k\}_{k=1}^\infty$ does $\sum_{k=1}^\infty \frac{1}{a_k} f(x+a_k)$ converge absolutely for almost every $x\in \Bbb R$?,"Question: Let $f\in L^1(\Bbb R)$ . For which increasing sequences $\{a_k\}_{k=1}^\infty$ of positive real numbers does $$\sum_{k=1}^\infty \frac{1}{a_k} f(x+a_k)$$ converge absolutely for almost every $x\in \Bbb R$ ? I believe this might be true for many such sequences, with possible restrictions on how fast $a_k$ grows to infinity. I have sketched the proof for $a_k = \sqrt{k}$ below, which I shall try to generalize. The key step seems to involve the ""inverse"" sequence. Let $a_k = \phi(k)$ for $k\in \Bbb N$ , where $\phi:[1,\infty) \to [1,\infty)$ is a strictly increasing surjective function. Then, $\phi^{-1}: [1,\infty) \to [1,\infty)$ exists. I refer to $b_k = \phi^{-1}(k)$ as the ""inverse"" sequence of $a_k.$ Toy Case: One can do the following if $a_k = \sqrt k$ . It is enough to show that the series converges a.e. on $[n,n+1]$ , for all $n\in \Bbb Z$ . WLOG, let $n=0$ . Now, it is enough to show $$\int_0^1 \sum_k \frac{1}{\sqrt k} |f(x+\sqrt k)|\,dx < \infty$$ as $\int_0^1 |g| < \infty \implies g$ is finite a.e. on $[0,1]$ . Using the Monotone Convergence Theorem, it is enough to show $$ \sum_k \frac{1}{\sqrt k} \int_0^1|f(x+\sqrt k)|\,dx < \infty.$$ For fixed $m \in \Bbb N$ and $m^2 \le k < (m+1)^2$ , $$\frac{1}{\sqrt k} \int_0^1|f(x+\sqrt k)|\,dx \le \frac{1}{m} \sup_{y\in [m, m+1)} \int_0^1 |f(x+y)|\, dx \le \frac1m \int_m^{m+2} |f(x)|\, dx$$ so that $$
\begin{align*}
\sum_k \frac{1}{\sqrt k} \int_0^1|f(x+\sqrt k)|\,dx &\le \sum_{m=1}^\infty \sum_{k=m^2}^{(m+1)^2-1} \frac1m \int_m^{m+2} |f(x)|\, dx\\
&= 2 \sum_{m=1}^\infty \int_m^{m+2} |f(x)|\, dx + \sum_{m=1}^\infty \frac 1 m \int_m^{m+2} |f(x)|\, dx\\
&\le 3 \sum_{m=1}^\infty \int_m^{m+2} |f(x)|\, dx\\ &\le 6\|f\|_1 < \infty.
\end{align*}$$ Generalization: I propose the following hypotheses on $\{a_k\}_{k=1}^\infty$ . Let $\phi:[1,\infty) \to [1,\infty)$ be a strictly increasing surjective function, and $a_k := \phi(k)$ for all $k\in \Bbb N$ . Let $\{b_k\}$ be the inverse sequence of $a_k$ , defined using $\phi^{-1}:[1,\infty) \to [1,\infty)$ . Lastly, assume there exists $\beta > 0$ such that $b_{k+1} - b_k \le \beta k$ for all $k\in \mathbb N$ . Once again, it is enough to show that the series converges a.e. on $[n,n+1]$ , for all $n\in \Bbb Z$ . WLOG, let $n=0$ . Now, it is enough to show $$\int_0^1 \sum_k \frac{|f(x+a_k)|}{a_k} \,dx < \infty$$ as $\int_0^1 |g| < \infty \implies g$ is finite a.e. on $[0,1]$ . Using the Monotone Convergence Theorem, it is enough to show $$ \sum_k \frac{1}{a_k} \int_0^1|f(x+a_k)|\,dx < \infty.$$ For fixed $m \in \Bbb N$ and $b_m \le k < b_{m+1}$ , we have $m = \phi(b_m) \le a_k < \phi(b_{m+1}) = m +1$ . $$\frac{1}{a_k} \int_0^1|f(x+a_k)|\,dx \le \frac{1}{m} \sup_{y\in [m, m+1)} \int_0^1 |f(x+y)|\, dx \le \frac1m \int_m^{m+2} |f(x)|\, dx$$ so that $$\sum_k \frac{1}{a_k} \int_0^1|f(x+a_k)|\,dx \le \sum_{m=1}^\infty \sum_{k=b_m}^{b_{m+1}-1} \frac1m \int_m^{m+2} |f(x)|\, dx = \sum_{m=1}^\infty \frac{b_{m+1}-b_m}{m} \int_m^{m+2} |f(x)|\, dx .$$ As $b_{m+1} - b_m \le \beta m$ for each $m\ge 1$ , we have $$\sum_k \frac{1}{a_k} \int_0^1|f(x+a_k)|\,dx \le \beta \sum_{m=1}^\infty\int_m^{m+2} |f(x)|\, dx \le 2\beta \|f\|_1 < \infty.$$ Other Thoughts: In an ideal world, I'd like to know necessary and sufficient conditions on $\{a_k\}_{k=1}^\infty$ so that $\sum_{k=1}^\infty \frac{1}{a_k} f(x+a_k)$ converges absolutely for almost every $x\in \Bbb R$ . For sequences growing slower than $\sqrt k$ , e.g. $a_k = k^{1/3}$ , the ""inverse"" sequences grow faster. In this case, $b_k = k^3$ , and there is no constant $\beta > 0$ such that $b_{k+1} - b_k \le \beta k$ for all $k \in \Bbb N$ . As a result, I'd expect the series $$\sum_{k=1}^\infty \frac{1}{k^{1/3}} f(x+k^{1/3})$$ to not converge absolutely on a set of positive measure. I do not know if this is true. Thank you!","['absolute-convergence', 'lp-spaces', 'analysis', 'real-analysis']"
4831301,Trigonometric proof of the equivalence $ \arctan [\frac {1} {2}] - \arccos [{\frac {1+3 \sqrt{3}}{2 \sqrt{10}}}] = \frac {\pi} {12} $,"Solving this problem Two identical circles passing through each other's centres. Three parallel lines and two diagonal lines drawn as below. What is the value of the marked angle? I found that the request angle is $ \arccos [{\frac {1+3 \sqrt{3}}{2 \sqrt{10}}}] $ , but this can be even written as $ \arctan [\frac {1} {2}] - \frac {\pi} {12} $ (you can see they are numerically equivalent). How that equivalence can be proved with trigonometry?","['equivalence-relations', 'trigonometry']"
4831335,4-digit password that have exactly 2 digits in common with a given password.,"Question: A system generates a 4 unique digits password. Extracting 2 passwords created independently and randomly, what is the probability that they have exactly 2 digits in common? My attempt: There are $\frac{10!}{(10-4)!} = 5040 $ different passwords in the sample space. If we take one them, say $2647$ ,  there are ${4 \choose 2} = 6$ cases of coincidence: $\{2,6\},\{2,4\},\{2,7\},\{6,4\},\{6,7\},\{4,7\}$ . So, if we consider the first case, there are 30 passwords that have a 2 and a 6 and also don't have a 4 and a 7. If we shuffle the digits, we still get valid passwords, so in the first case there are $30 \times 4! = 720$ passwords. The reasoning for the other cases is identical, so we must have $720 \times 6$ passwords in total that match the given password in exatcly 2 digits. So the probability asked is $\frac{720 \times 6}{5040} = \frac{6}{7}$ the supposed answer is $\frac{3}{7}$ What did I miss? Thanks in advance.","['combinatorics', 'probability']"
4831340,$\int\limits_0^1{\frac{{E\left( {\sqrt{\frac{t}{{1+t}}}}\right)-K\left({\sqrt{\frac{t}{{1+t}}}}\right)}}{{t\sqrt {1+t} }}}\ln \left( {1 - t}\right)dt$,"I found this integral from a Facebook page : Find a closed form for this integral $$\int\limits_0^1{\frac{{E\left( {\sqrt{\frac{t}{{1+t}}}}\right)-K\left({\sqrt{\frac{t}{{1+t}}}}\right)}}{{t\sqrt {1+t} }}}\ln \left( {1 - t}\right)dt$$ $${\text{Where}}:K\left( k \right),{\text{ }}E\left( k \right){\text{ are in order the complete elliptic integral of the first and second kind}}{\text{.}}$$ $${\text{And}}:K\left( k \right) = \int\limits_0^1 {\frac{1}{{\sqrt {\left( {1 - {x^2}} \right)\left( {1 - {k^2}{x^2}} \right)} }}dx} ,E\left( k \right) = \int\limits_0^1 {\frac{{\sqrt {1 - {k^2}{x^2}} }}{{\sqrt {1 - {x^2}} }}dx} $$ I really don't know how to express a relation between $E(k)$ and $K(k)$ to reduce the problem. I think this is an intriguing integral, but I can't evaluate it yet. May you guys please help me with this? Thank you very much.","['integration', 'calculus', 'elliptic-integrals']"
4831369,Perfect Square from Geometric Progression,"This question is from QuantGuide(namely Geometrical Progression): Write out a series of whole numbers in geometrical progression with at least 3 terms, starting from
1, so that the numbers add up to a square. The common ratio must be strictly larger than 1. Give the answer in the form of the smallest square number in which a progression can be written. My Approach: I have arrived at this position \begin{equation}
1+r+r^2+r^3+...+r^{n-1} = b^2
\end{equation} where r,n,b are some integers and $r>1$ . But I can't proceed further. Hints would be appreciated.","['number-theory', 'geometric-progressions']"
4831446,"Let $A+B+C=\pi$ and $\sin^2(A)+\sin^2(B)-\sin^2(C)=p$, then find range of $p$","Let $A+B+C=\pi$ and $\sin^2(A)+\sin^2(B)-\sin^2(C)=p$ , then find range of $p$ Approach: After simplifying above expression I obatained $p=2\sin A \sin B \cos C$ . As I can see maximum value of above expression is $2$ with guess of $A=\dfrac{\pi}{2}, B=\dfrac{\pi}{2}, C=0$ . But I am not able to find its minimum value. Also is there proper method to solve this problem other than gueesing.","['optimization', 'trigonometry', 'maxima-minima']"
4831482,"Distribution of the fractional parts of $n/1, n/2,\ldots, n/n$ as $n$ tends to infinity","Motivation: I felt excited by the answer of X-Rui in this thread . So, I tried to generalize his answer. I tried to obtain the distribution in $[0,1]$ of the fractional parts of the numbers $n/1, n/2, .... n/n$ as $n$ tends to $\infty$ . There may be many applications like computing the limit of ${1\over n}(\sum_k [an/k] - \sum_k n/k)$ as $n$ tends to $\infty$ . My overall question is: do you think the following informal argument makes sense? (of course, there should be much more work to make it a formal proof). Fix an integer $n>1$ , which is in fact assumed to be large.
Let $\alpha$ be another positive large number. Building upon the argument of X-Rui, we have for ${\alpha\over \alpha+1} n < k \leq n$ , there holds $1\leq {n\over k} < 1 + {1\over \alpha}$ for ${\alpha\over \alpha+2}n < k \leq {\alpha\over \alpha+1}n$ , there holds $1+{1\over \alpha}\leq {n\over k} < 1 + {2\over \alpha}$ . for ${\alpha\over \alpha+3}n < k \leq {\alpha\over \alpha+2}n$ , there holds $1+{2\over \alpha}\leq {n\over k} < 1 + {3\over \alpha}$ . . . . for ${\alpha\over 2\alpha}n < k \leq {\alpha\over 2\alpha-1}$ there holds $2 - {1\over \alpha} \leq {n\over k} < 2$ for ${\alpha\over 2\alpha+1} n < k \leq {\alpha \over 2\alpha}$ , there holds $2\leq {n\over k} < 2 + {1\over \alpha}$ and so on. Hence, if $q$ is a number between $1$ and $\alpha-1$ , the fractional part of $n/k$ will lie between ${q-1\over \alpha}$ and ${q\over \alpha}$ whenever ${n\alpha \over m\alpha + q} < k \leq {n\alpha\over m\alpha+q-1}$ , with $m = 1, 2,3,...$ . So, as $n$ becomes very large, the proportion of these fractional parts among the fractional parts of $n/1,n/2,... n/n$ will tend to $$ S = \alpha \sum_{m=1}^\infty {1\over m\alpha+q-1} - {1\over m\alpha + q}
= \sum_m {1\over m + {q\over \alpha}-{1\over \alpha}} - {1\over m + {q\over \alpha}}.$$ Since $\alpha$ has been assumed to be large, we can use the formula ${1\over x-\varepsilon}-{1\over x} \approx {\varepsilon\over x^2}$ to get $$ S \approx \sum_m \bigg({1\over m+{q\over \alpha}}\bigg)^2 {1\over \alpha}.$$ Now, in order to have a continuous distribution, we replace ${q\over \alpha}$ by $x$ , and $1\over \alpha$ by $dx$ , to obtain $$d\phi = \sum_m {1\over (x+m)^2} dx, $$ where $\phi$ is the cumulative function of the desired distribution. In other words, the density of this distribution is $$\varphi(x) = \sum_m {1\over (m+x)^2}.$$ My secondary question is: does the above sum have a known analytic form? Note: the above function is indeed a distribution density (actually it is the folded distribution of the ditribution $1/(1+x)^2$ in $[0, \infty)$ ): to see that, we have only to check that $\int_0^1 \varphi(x) dx = 1$ :
We have $$S_m = \int_0^1 {1\over (m+x)^2} = {1\over m} - {1\over m+1} = {1\over m(m+1)}.$$ Hence $\sum_{m\geq 1} S_m < \infty$ and $\int_0^1\varphi(x)dx = \sum_m S_m$ . Now $$\sum_{m=1}^N S_m = \sum_{m=1}^N {1\over m} - {1\over m+1} = 1 - {1\over N+1} \longrightarrow 1, \quad {\rm as}\ N\to \infty.$$","['number-theory', 'fractional-part']"
4831570,Solving trigonometric integral using contour integration [duplicate],"This question already has answers here : How to evaluate the integral $\int_{0}^{\infty}\frac{\cos {(ax)}-\cos{(b x)}}{x^2 }dx$? (5 answers) Closed 6 months ago . How to solve this integral using contour integration: $$\int_{-\infty}^{\infty} \frac{\cos px - \cos qx}{x^2} dx \stackrel{?}{=} \pi (q-p)$$ Here is what I have tried:
I don't know if I can use Residue theorem, as it has a pole of second order on the real axis, which is not simple. So I am stuck.","['complex-analysis', 'calculus', 'contour-integration', 'trigonometric-integrals', 'residue-calculus']"
4831573,Distinguishable subsets of the 52-card blackjack deck,"I need to find, for $n = 0, 1, . . . , 52$ , the number of distinguishable subsets of size n.
Blackjack deck has $4$ cards for each value from $1$ to $9$ and $16$ cards of value $10$ , color doesn't matter. I know that the total number of combinations is $5^9*17$ , but when I'm trying to find subsets they don't reach that, there's always more or less.
Until $n=5$ it's trivial. Then, until $n=16$ I'm calculating number of combinations of max $4$ cards of each value and adding combinations with more than $4$ $10$ s, e.g. for $n=8$ I have $22110$ combinations of max $4$ cards of each value $+ 220$ combinations for 10,10,10,10,10,x,x,x, which gives $22330$ . Then, for $n = (17,...,26)$ I'm using similar strategy. E.g. for $n=18$ I have $780175$ combinations with max $4$ cards of each value $+ 264220$ combinations for 10,10,10,10,10,x,x,x,x,x,x,x,x,x,x,x,x,x (where in place of x I can still put only $4$ $10$ s) $+22110$ combinations for 10,10,10,10,10,10,10,10,10,10,x,x,x,x,x,x,x,x $+210$ combinations for 10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,x,x,x (where in place of x I can put only $1$ $10$ ) $=1066715$ . I did it also with the same strategy, but when adding assuming there's no limit for $10$ s, then subtracting combinations with more than $16$ $10$ s - I got the same result $(780175+286550-10=1066715)$ . For bigger $n$ s I used recursive logic - e.g. for $n=50$ I can only choose $2$ cards, so it's $55$ again, as for $n=2$ , so it goes. With this method I'm missing 1287 counts. What am I doing wrong?","['extremal-combinatorics', 'combinations', 'combinatorics', 'card-games']"
4831578,Compute $\lim\limits_{x \to +\infty}{e^{x^2\sin{\frac{1}{x}}}-e^x}$,"As the title suggests, I am trying to compute the limit $$\mathcal{L}=\lim_{x \to +\infty}{e^{x^2\sin{\frac{1}{x}}}-e^x}$$ and I am stuck. I have defined the function $f(x)=e^{x^2\sin{\frac{1}{x}}}-e^x$ and I have already proven that it is negative on $(0, +\infty)$ as $$e^{x^2\sin{\frac{1}{x}}} < e^{x^2 \frac{1}{x}} = e^x \Rightarrow f(x) < 0$$ as $\sin{x} < x, \ \forall \ x >0$ . Also, the graph suggests that the function is decreasing on $[1, +\infty)$ which would mean that the aforementioned limit is $-\infty$ , which is in accordance with Wolfram Alpha's results. However, I can't get any further. I have also tried finding the sign of the derivative on that interval, but to no avail. Thanks in advance!","['limits', 'calculus']"
4831584,Abelian extension over imaginary quadratic field,"Notation:
For a finite abelian extension $F / K$ , let $\mathfrak{f}_{F / K} \subset \mathcal{O}_K$ denotes its conductor such that $F$ is contained in the ray class field $K(\mathfrak{f})$ . In particular, the set of primes dividing $\mathfrak{f}_{F / K}$ consists precisely of those prime ideals which ramify in $F / K$ . Whenever $\chi: \mathbf{A}_L^{\times} \rightarrow \mathbf{C}^{\times}$ is a Hecke character of some number field $L$ , we let $\mathfrak{f}_\chi$ denote its conductor, i.e. the smallest ideal such that $\chi$ is trivial on $U_f\left(\mathfrak{f}_\chi\right)$ . Let $K$ be an imaginary quadratic field and $F / K$ a finite abelian extension. Let $E / F$ be an elliptic curve with complex multiplication by $\mathcal{O}_K$ . Let $F\left(E_{\text {tors }}\right)$ denote the field extension of $F$ generated by all the torsion points of $E$ . Let $\psi: \mathbf{A}_F^{\times} \rightarrow \mathbf{C}^{\times}$ be the Hecke character associated to $E / F$ . Let $N_{F / K}: \mathbf{A}_F^{\times} \rightarrow \mathbf{A}_K^{\times}$ denote the idele norm. Assume that there exists a Hecke character $\varphi: \mathbf{A}_K^{\times} \rightarrow \mathbf{C}^{\times}$ such that $$\psi=\varphi \circ N_{F / K}$$ Show that $F\left(E_{\text {tors }}\right)$ is an abelian extension over $K$ . Hint: It is equivalent to show that the $G_K$ -module $\operatorname{Ind}_{G_F}^{G_K}\left(E_{\mathrm{tors}}\right)$ is abelian. Note that the Artin map $$\left[-, K^{\mathrm{ab}} / K\right]: \mathbf{A}_K^{\times} \rightarrow \operatorname{Gal}\left(K^{\mathrm{ab}} / K\right)$$ factors through the finite ideles. We may use that the kernel of $\left[-, K^{\mathrm{ab}} / K\right]$ : $\mathbf{A}_{K, f}^{\times} \rightarrow \operatorname{Gal}\left(K^{\mathrm{ab}} / K\right)$ is the topological closure of $K^{\times}$ in $\mathbf{A}_{K, f}^{\times}$ . I would really appreciate any help with this exercise with which I am stuck.","['number-theory', 'hecke-characters', 'complex-multiplication', 'elliptic-curves']"
4831614,Function to count trailing zeroes,"Recently a friend of mine suggested a question, which was to find the number of trailing zeroes in $(100!)$ . While that should be easy enough to tackle, as I have seen a lot of questions on MSE that deal with exactly this type of problem, I would like to solve a more general problem: Define a function $f(n)$ using common mathematical operators and other notation that counts the number of trailing zeroes in a given positive integer $n$ Now I have got something in mind, which is: $$f(x)=\sum_{i=1}^{\lfloor log_{10}x\rfloor} \left(1-|sgn(x\mod(10^i)|\right)$$ Where $sgn()$ is the signum function . The function is based on the concept of checking if the number is divisible by successive powers of $10$ . Here’s a Desmos link for the function. While this does seem to work, I would like a more compact function that I can actually work with, while this is something like rewriting a computer algorithm, only using mathematical notation. All ideas are welcome. Thanks in advance. EDIT:
As proposed in a comment by @RobertIsrael, another definition for the function is: $$\min(v_{2}(n), v_{5}(n))$$ with reference to the $p$ -adic valuation of $n$ .","['elementary-number-theory', 'functions', 'natural-numbers', 'algorithms']"
4831627,Zariski tangent space to a moduli space,"I’m reading the paper 13/2 Ways of Counting Curves by Pandharipande and Thomas. I’m very confused with the following statement on page 8 $\S$ Deformation theory. We return now to the deformation theory for embedded curves briefly discussed in Section $\frac{1}{2}$ . The deformation theory for arbitrary stable maps is very similar. Let $C \subset X$ be a nonsingular embedded curve with normal bundle $\nu_C$ . The Zariski tangent space to the moduli space $\overline{\mathcal{M}}_g(X,\beta)$ at the point $[C \to X]$ is given by $H^0(C, \nu_C)$ . Locally, we can lift a section of $\nu_C$ to a section of $T_X |_C$ and deform $C$ along the lift to first order. Since globally $\nu_C$ is not usually a summand of $T_X|_C$ but only a quotient, the lifts will differ over overlaps by vector fields along $C$ . The deformed curve will have a complex structure whose transition functions differ by these vector fields. In other words, from $$0 \to T_C \to T_X |_C \to \nu_C \to 0$$ we obtain the sequence $$(1.1) \quad 0 \to H^0(C, T_C) \to H^0(C, T_X |_C) \to H^0(C, \nu_C) \to H^1(C, T_C)$$ How do I understand the Zariski tangent space? Many thanks!","['algebraic-geometry', 'moduli-space']"
4831630,"Showing $\lim_{n \to \infty}\;( (2n+1)! )^{1/n}\,\sin\left(\frac {1}{n^2-n}\right) = \frac{4}{e^2}$",$ \displaystyle \lim_{n \to \infty}( (2n+1)! )^{1/n} \sin(\frac {1}{n^2-n})  $ = $\frac{4}{e^2}$ the factorial part tends to $ \infty$ while the sin part to $0$ considering that sin is continous : $ \lim_{n\to\infty}  \sin(\frac {1}{n^2-n})=0$ because the denominator tends to infinity ( the $n^2$ grows asimptotically faster than $n$ ) while using the quotion theorem we can find $ a_n:= (( 2n+1)!)^{1/n}$ let $ \lambda = \frac{a_{n+1}}{a_n}= \frac{(( 2n+3)!)^{1/(n+1)}}{(( 2n+1)!)^{1/n}} > \frac{(( 2n+3)!)^{1/(n+1)}}{(( 2n+1)!)^{1/n+1}} = ( ( (2n+3)(2n+2 ) ) ^{1/n+1} = (4n^2 +10n +6)^{n+1}=(1+(4n^2 +10n +5 ))^{  \frac{1}{4n^2 +10n +5}   (4n +10 +5/n)} = e^\infty = \infty$ therefore $ \lambda \rightarrow \infty>0 \implies a_n \rightarrow \infty$ now i know that  the limit is of the form $ \infty 0$,"['limits', 'limits-without-lhopital', 'real-analysis']"
4831637,$\beta$-mixing in Asmptotically Stochasitic (Random) Process,"This issue involves a very important concept, which is the $\beta$ -mixing nature of stochastic processes . All the stochastic processes we discuss are time-positive and discrete. To strictly adhere to this concept, we first introduce it: ( $\beta$ -mixing) Firstly, this concept is limited to markov process $\left\{ Z_t \right\} _{t\geqslant 1}$ . We assume that markov processes have a unique stationary distribution $\nu$ . When $\left\{ Z_t \right\} _{t\geqslant 1}$ has exponential ergodicity , there exists $\beta$ -mixing coefficients $\beta(t)$ , i.e. $$
\beta \left( t \right) =\mathop {\mathrm{sup}} \limits_{k\geqslant 1}\mathbb{E} \left[ \mathop {\mathrm{sup}} \limits_{\mathcal{B} \in \mathcal{F} _{k+t:\infty}}\left| \mathbb{P} \left( \mathcal{B} |\mathcal{F} _{1:k} \right) -\mathbb{P} \left( \mathcal{B} \right) \right| \right] ,
$$ where $\mathcal{F} _{n:m}=\sigma \left( \left\{ Z_n,\cdots ,Z_m \right\} \right) $ , and $\beta \left( t \right) \leqslant C\exp \left( -bt \right) $ w.r.t. constants $C$ and $b$ .
See the following reference for more detail: Meitz, Mika, and Pentti Saikkonen. ""Subgeometric ergodicity and β-mixing."" Journal of Applied Probability 58.3 (2021): 594-608, Page 594. We usually call this markov process is $\beta$ -mixing. Now we will divide the problem into two levels: ( Q1 , Simple Baseline) Suppose there exists a general process $\left\{ X_t \right\} _{t\geqslant 1}$ with $\left| X_t \right|<\infty $ and $\mathbb{E} \left| X_t \right|<\infty $ , $\mathbb{E} \left| X_t \right|^2<\infty $ . Now truncate the process with constant time $N<\infty$ . Construct a new process $\left\{ Z_t \right\} _{t\geqslant 1}$ where $Z_t=X_t$ a.s. when $t\leqslant N$ , and $\left\{ Z_{N+t} \right\} _{t\geqslant 1}$ is a $\beta$ -mixing markov process . Denote $\mathcal{F} _{n:m}=\sigma \left( \left\{ Z_n,\cdots ,Z_m \right\} \right) $ . Question: Suppose $\mathcal{F} _{N+1:\infty}$ is independent of $\mathcal{F} _{1:N}$ , can we also claim that $\left\{ Z_t \right\} _{t\geqslant 1}$ (note it is not markovian ) is $\beta$ -mixing? ( Corollary of Q1 ) Suppose exists non-trivial constant $T\leqslant N<\infty $ satisfying $\frac{N}{T}=k\in \mathbb{N} _+$ . We can ""cut"" $\left\{ Z_t \right\} _{t\geqslant 1}$ into $$
\underbrace{Z_1,\cdots ,Z_T}_{H_1}, \underbrace{Z_{T+1},\cdots ,Z_{2T}}_{H_2}, \cdots , \underbrace{Z_{\left( k-1 \right) T+1},\cdots ,Z_{kT}}_{H_k}, \cdots  
$$ So $H_1$ means the $i$ -th block in $\left\{ Z_t \right\} _{t\geqslant 1}$ . We only sliced the process in Q1, so the conclusion of Q1 remains unchanged. ( Q2 , Infinite Case) Now let $N = \infty$ and $T < \infty$ . According to ""cut"" method above, suppose $H_i$ satisfies the following properties: The initial state of $H_i$ is $Z_{\left( i-1 \right) T+1}$ . It is i.i.d. with $Z_{\left( i-1 \right) T}$ , the ternimal state of $H_{i-1}$ . Denote $Z_{\left( i-1 \right) T+1}, Z_{\left( i-1 \right) T}\sim \mu _i$ . Moreover, $\mathcal{F} _{\left( i-1 \right) T+1: iT}=\sigma \left(  H_i \right) $ is independent of $\mathcal{F} _{1:\left( i-1 \right) T}=\sigma \left( \left\{ H_1,\cdots ,H_{i-1} \right\} \right) $ . Process in $H_i$ must be a truncation of a $\beta$ -mixing markov process, i.e. $\left\{ Z_{\left( i-1 \right) T+t} \right\} _{t\geqslant 1}$ is a $\beta$ -mixing markov process with stationary distribution $\nu _i$ . Hint: So you cannot use any general Asymptotic Properties directly for markov process. There exists limit distribution $\nu $ s.t. $D_{\mathrm{TV}}\left( \nu _i, \nu \right) \rightarrow 0$ , and $D_{\mathrm{TV}}\left( \nu _{i-1}, \nu _i \right) \rightarrow 0$ as $i \rightarrow \infty$ . Also, suppose $D_{\mathrm{TV}}\left( \mu _i, \nu _{i-1} \right) \rightarrow 0$ . The divergence $D_{\mathrm{TV}}$ means total variation distance. Hint: This condition is almost the most important, as it implies the relationship between random processes under different blocks. Although the partitioning of each process is independent, we suggest that over time, $H_i$ progresses towards a strictly stationary process , and the initial distribution of the next block is very close to the stationary distribution of the previous block. Question: Can we claim that $\left\{ Z_t \right\} _{t\geqslant 1}$ (note it is not markovian) is $\beta$ -mixing? Why? Additional Question: If the answer is not, Can we achieve our final goal by fixing the proposition 4 above? I.e. convergence in probability or a.s. or ...","['stationary-processes', 'markov-chains', 'markov-process', 'probability-theory', 'probability']"
4831651,"Evaluating $\lim_{n \to \infty} \frac{1}{n}\sum_{t = 1}^{n}e^{-k\cos^2(\omega t)}$, where $k>0$ and $0<\omega<\pi$","Need to evalute a closed form expression of the following limit: $$\lim_{n \to \infty} \frac{1}{n}\sum_{t = 1}^{n}e^{-k\cos^2(\omega t)}$$ where $k>0$ and $0<\omega<\pi$ . Empirically, I have observed that the limit exists and it does not depend on $\omega$ , it depends only on $k$ . Also, the value of the limit decreases as $k$ increases, which means the limit is a decreasing function in $k$ . I need to prove that the limit is independent of $\omega$ and is a decreasing function in $k$ .  Please help me in finding the limit.","['computational-mathematics', 'statistics', 'real-analysis']"
