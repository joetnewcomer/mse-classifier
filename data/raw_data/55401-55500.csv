question_id,title,body,tags
598274,Hom-functor preserves pullbacks,"I am trying to prove that the hom-functor $\mathrm{Hom}(A,-)$ preserves pullbacks.
I stuck at showing uniqueness. Could you please give me some hints?","['category-theory', 'abstract-algebra']"
598285,Degree 3 Galois extension of $\mathbb{Q}$ which is not radical,"I have the following question. I have the following result in Dummit and Foote, Abstract Algebra (Theorem 39 p. 628) that says that over a field of characteristic $0$ a polynomial $f(x)$ is soluble by radicals if and only if its Galois group is a soluble group. But I also have a result in one of my exams that says that a Galois extension of degree 3 over $\mathbb{Q}$ is not a radical extension. How is it that the two statements aren't contradicting one another? Since I thought that if the Galois group was of size 3 then its cyclic, so soluble, so if $G$ is the Galois group of some irreducible cubic then wouldn't the theorem say that it is soluble by radicals? Or is there a difference between a polynomial being soluble by radicals and its splitting field being a radical extension? Thank you","['galois-theory', 'abstract-algebra', 'field-theory']"
598295,Is there a proof of the irrationality of $\sqrt{2}$ that involves modular arithmetic?,"I was reading Ian Stewart's Concepts of Modern Mathematics . Using congruences, It's possible to explain why all perfect squares end in $0,1,4,5,6,9$ but not in $2,3,7,8$. With this I had the idea of exploring the congruences for both sides of $n^2=2m^2$ in Mathematica: Table[Mod[n^2, 9], {n, 0, 20}] Table[Mod[2 m^2, 9], {n, 0, 20}] And had the results: {0, 1, 4, 0, 7, 7, 0, 4, 1, 0, 1, 4, 0, 7, 7, 0, 4, 1, 0, 1, 4} {0, 2, 8, 0, 5, 5, 0, 8, 2, 0, 2, 8, 0, 5, 5, 0, 8, 2, 0, 2, 8} But I'm still not sure if the outputs really show what I'm looking for, I have also tried $mod \;10$. The idea is still pretty loose in my mind, I'm stuck on deciding if this proves something or what directions I could take in this enterprise.","['abstract-algebra', 'real-analysis', 'alternative-proof']"
598302,"Show that $(1,x,x^2),(1,y,y^2),(1,z,z^2)$ form a basis of $\mathbb{R}^3$ iff $x\neq y, x \neq z, y \neq z$","I'm having some trouble with this one because I always get negated statements. If I try to prove both direction directly I get that three elements are all not equal to each other and the three vectors form a basis, or if I proof by contrapositive I get the statement that the vectors do not from a basis and therefore do not span $\mathbb{R}^3$ and are not linearly independent. Either way I end up with negated statements, which I find hard to use in proofs. What I have come up with thus far: $=>$ Proof by contraposition: Suppose $(1,x,x^2),(1,y,y^2),(1,z,z^2)$ form a basis of $\mathbb{R}^3$ and assume that $x=y \vee x=z \vee y=z$. 
In each case it follows that at least two of the three vectors are equal and thus all three vectors are not linearly independent, therefore $(1,x,x^2),(1,y,y^2),(1,z,z^2)$ cannot be a basis of $\mathbb{R}^3$. $<=$ Proof by contraposition: Suppose $(1,x,x^2),(1,y,y^2),(1,z,z^2)$ are not a basis of $\mathbb{R}^3$, then the vectors are not linearly independent or do not span $\mathbb{R}^3$. Case 1: One of the vectors is in the span of the other two. Then it follows that there is a linear combination of the following form : $1x + 0y = z$, where x is the vector $(1,x,x^2)$ and y and z the corresponding other two vectors. Then it follows that $(1,x,x^2) = (1,z,z^2)$ and therefore $x=z$ with $x,z \in \mathbb{R}$. The same result would hold in the other cases. Case 2: No idea. Honestly I don't really feel as if those proofs are correct. For the second direction in case 1, I'm not sure whether the fact that the vectors are not linearly independent, implies the fact that there is a linear combination of the form $1x + 0y = z$. Can anybody tell me what I have done wrong thus far and give some hints to help me prove this?",['linear-algebra']
598323,Connection between sequences and filters in first countable spaces,"It is generally known that the concept of sequences does not yield a satisfactory theory of convergence in arbitrary topological spaces. Instead one considers more general objects such as filters. However, many theorems about filters also become true for sequences when one restricts the attention to first countable spaces. Here are some examples: $x \in X$ belongs to the closure of $A \subseteq X$ iff there is a filter on $A$ which converges to $x$. $f : X \to Y$ is continuous at $x$ iff $f(\Phi)$ converges to $f(x)$ whenever $\Phi$ converges to $x$. $X$ is Hausdorff iff every filter converges to at most one point. $X$ is countably compact iff every filter with countable basis has an accumulation point. Is there any connection between sequences and filters in first countable spaces that explains their interchangeability in theorems like above?","['general-topology', 'filters']"
598330,Compact hypersurface of $\mathbb{R}^{n+1}$ with positive curvature is diffeomorphic to $S^n$.,"I have a compact hypersurface $M$ of $\mathbb{R}^{n+1}$ with positive curvature. I need to show that it is diffeomorphic to $S^n$. The hint is to consider the shape operator $A_{\nu_p} x$, where $\nu$ is a smooth unit normal vector field regarded as a map $\nu: M \rightarrow S^n$, and then show that it is a covering map. Unfortunately, I don't think the hint really made the approach any clearer. Can anyone help to shed some light on this exercise for me?","['riemannian-geometry', 'differential-geometry']"
598331,What is the dimension of this Grassmannian?,Why is  $2\times 3$ the dimension of $Gr_2(\mathbb{R}^5)$? and can one use the dimensions of Lie groups to derive this dimension? Note: $Gr_2(\mathbb{R}^5)$ denotes the Grassmannian of all $2$-dimensional subspaces of $\mathbb{R}^5$.,"['differential-geometry', 'algebraic-geometry', 'matrices', 'linear-algebra', 'lie-groups']"
598392,What is the relation between dual spaces and inner product?,"What is the relation (if any) between dual spaces and inner product? As far as I understand the dual space of a vector space is the set of all linear mappings from the vector set to the field over which the space is defined. But the definition of the inner product is a bilinear mapping of two vectors to a scalar. It sounds to me like if we had defined the same thing twice, in two different ways, is that so? If the answer is yes, and given that every space has a dual space, does that mean that every vector space is automatically an inner product space? Moreover, if the polarization identity can be used to define a norm from an inner product, are all vector spaces inner normed spaces? I am sure I'm misunderstanding some definition, but I'm totally lost here. Any help?","['vector-spaces', 'inner-products', 'duality-theorems', 'linear-algebra', 'functional-analysis']"
598413,$F(xy) = F(x)+F(y)$ Proof,"Suppose $F$ is differentiable $\forall x>0$ and $F(xy) = F(x)+F(y)$ , $ \forall x,y>0$ .
Prove that if $F$ is not the zero function, then $\exists$ $  a>0$ such that: $F(x)=\log_a(x)$ , $\forall x>0$ .
I seem to be doing fine except on getting the base $a$ for the log. So far I have that $F'(x)=\frac{F'(1)}{x}$ . I know from calculus that $\int\frac{1}{t}dt=\ln(t)$ . How can I get the base to be $F'(1)$ instead of $e$ ?","['derivatives', 'real-analysis', 'functional-equations']"
598457,How to solve $(2x^2+y)\partial x+(xy^2-x)\partial y=0$,"How can we solve this kinda eq.?
$$(2x^2+y)\partial x+(xy^2-x)\partial y=0$$ first I check  if it is entire. (which is not because $M(x,y)=2x^2+y\quad and \quad N(x,y)=xy^2-x\quad thus \quad M_y=1\neq y^2-1=N_x$)
I tried to find integral factor.( which I couldn't because $\frac{M_y-N_x}{N}$ doesnt respect to x and $\frac{M_y-N_x}{M}$ doesn't respect to y)
how do we approach? (I may wrote  math. expressions wrong)",['ordinary-differential-equations']
598467,Help with I.V.P,"is the I.V.P: $$\begin{cases}
\dfrac{dy}{dx}=\sin(e^{y})\\[8pt]
y(0)=a
\end{cases}
\text{ where } a\in \mathbb{R}$$ a) Prove that the equation has unique solution $y(x,a)$ and the maximum range is $\langle- \infty, \infty\rangle$ b) Prove: $|y(x,a)-a |\le x$ I have tried to solve the equation $$\int \frac{dy}{\sin(e^{y})}=\int dx$$ for starters but no solution. any idea how to start?",['ordinary-differential-equations']
598468,CounterExamples for Hilbert Nullstellensatz,"It is easy to prove that for any two algebraic sets $X_1, X_2$ in $\mathbb{A}^n$ we have that
$$I(X_1\cap X_2) = \sqrt{I(X_1)+I(X_2)}$$
Find an example that the radical is neccessary, i.e., an example on algebraic sets $X_1, X_2$ that $I(X_1\cap X_2) \ne I(X_1)+I(X_2)$. Can you see geometrically what it means if we have inequality here? Many thanks in advance.",['algebraic-geometry']
598497,Why is $\lim\limits_{n \to \infty} \frac{1}{n} \sqrt[n] {n^n}=1$ where $\lim\limits_{n \to \infty} \sqrt[n] {n!}=\infty$?,"Why is $\lim\limits_{n \to \infty}\frac{1}{n} \sqrt[n] {n^n}=1$ where $\lim\limits_{n \to \infty} \sqrt[n] {n!}=\infty$ ? We all know that $n^n > n! \ : \forall n$ so how come the factorial ""beats"" the exponent when it's nth rooted and going to infinity ? The factorial is behaving as if it's bigger than $n^n$.","['calculus', 'limits']"
598517,"If $U$ is connected, any two sections $U \to \mathfrak S$ either coincide or have disjoint images (Is my proof correct?)","I tried proving the following statement by Ahlfors, page 287: If $U$ is connected and $\varphi,\psi: U \to \Gamma(U,\mathfrak S)$, then either $\varphi$ and $\psi$ are identical, or the images $\varphi(U)$ and $\psi(U)$ are disjoint. Indeed, the sets with $\varphi - \psi = 0$ and $\varphi- \psi \neq 0$ are both open. Here $\mathfrak S$ is the sheaf of germs of analytic functions over some open set $D \subseteq \mathbb C$, and $\Gamma(U,\mathfrak S)$ is the set of all sections from an open set $U \subseteq D$. Mainly, what I tried is expanding on the openness of the sets $$A=\{ \zeta \in U: \varphi(\zeta)-\psi(\zeta)=\mathbf{0}_\zeta \} \\
B=\{ \zeta \in U: \varphi(\zeta)-\psi(\zeta) \neq \mathbf{0}_\zeta \} $$ $A$ can be viewed as the inverse image $$(\varphi-\psi)^{-1}[\omega(U)] $$ where $\omega:\zeta \mapsto \mathbf{0}_\zeta$ is the zero section . Since it is an open map, and $\varphi-\psi$ is continuous it follows that $A$ is open. However, proving that $B$ is open turned out to be more problematic for me. I couldn't do it using representation as an inverse image, so I tried the more direct approach: Let $\zeta_0 \in B$ and suppose that in every arbitrarily small disk $\Delta(\zeta_0,r)$ there exists a point $\zeta_r$ such that $(\varphi-\psi)(\zeta_r)=\mathbf{0}_{\zeta_r} \equiv \omega(\zeta_r)$. Thus we may extract a sequence $\{\zeta_n \}_{n=1}^\infty$ which tends to $\zeta_0$, such that for all $n$, $(\varphi-\psi)(\zeta_n)=\omega(\zeta_n)$. Since both $\varphi-\psi$ and $\omega$ are continuous, they are sequentially continuous, and taking the limit as $n \to \infty$ yields the contradiction $\varphi(z_0)-\psi(\zeta_0)=\mathbf{0}_{\zeta_0}$. It follows that $B$ is open as well. Lastly, $U=A \coprod B$, and from connectedness either $U=A$ or $U=B$. In the former $\varphi,\psi$ coincide, and in the latter they have disjoint images (this is because if they share a value, they must share it at the same point). Is this all correct? If not, please help me correct it. Thanks!","['sheaf-theory', 'complex-analysis']"
598530,Pictures of One-point compactification,"Are these the pictures of the following one-point compactification of the following surfaces: Two dimensional sphere with three points removed The disjoint union of two copies of $S^{1} \times \mathbb{R}$ Disjoint union of $\mathbb{R}^{2}$ and $\mathbb{R}^{1}$ Disjoint union of the real line together with an open cylinder, I am not sure about the second one (Should it be two cones joined at a point called $\infty$)and the 4th one shoud be a cone and a circle with the circle?","['general-topology', 'compactness']"
598534,"If $n\in\Bbb N$, then gcd($8n+1, 7n+1)$ =","If  $n\in\Bbb N$, then gcd($8n+1, 7n+1)$ = How to do these type of questions?",['discrete-mathematics']
598564,The problem of the drunkard in a valley.,"We consider a Markov chain on a subset of positive integers $S =$ {$0, 1, 2, 3, .......N$}, with transition probabilities defined as follows: The chain jumps only one unit to the left or right. $p(i, j) = 0$ if  $|i - j|>1$ $p(i, i + 1) = (N - i) /N$ , for $i$ in {$1, 2, 3, ....., N-1$}. $p(i, i - 1) = i/N$ , for $i$ in {$1, 2, 3, ....., N-1$}. We assume that we have absorbing barriers at $0$ and $N$, so we have $p(0, 0) = p(N, N) = 1$. What is the expected time it takes for the chain to be absorbed at $0$ or $N$, starting at $i$ in {$0, 1, 2, 3, .......N$}? If $T_i$ is the time it takes for the chain to be absorbed at $0$ or $N$, when starting at $i$, what is $E(T_i)$? This Markov chain can be seen as a particular case of a birth and death chain, or as a one dimensional random walk with 2 absorbing barriers and probabilities varying from place to place. I would call this the problem of the drunken man in a valley. The closer he gets to the absorbing barriers (the top of the hill), less likely it is that he will continue towards them. Then what is the expected time of the drunkard to reach the top of the hills surrounding him? Main question. Is the expected time to absorption polynomial or exponential (in $N$)? Note that this problem is related to a class of problems of practical interest.","['markov-chains', 'random-walk', 'probability']"
598608,"What is the maximum entropy distribution for a continuous random variable on $[0,\infty)$ with given mean and variance?","I know that for a given logmean and logstdev its the lognormal, but what about where we directly specify the mean and variance? The above seems to depend on the log-transformation to the maxent for unbounded continuous RV with given mean and variance (i.e, Normal).","['statistics', 'probability', 'entropy']"
598618,A curious problem about Lebesgue measure.,"The Problem: Let $(B(x_{m},0.5))_{m}$ be a sequence of disjoint open discs in $\mathbb{R}^{2}$ centered in $x_{m}$ and with radius 0.5. Let $\psi(n)$ be the number of these discs contained in the open disc $B(0,n)$ (that is, the disc centered in (0,0) and with radius $n$). Prove that if $\lim \inf \frac{\psi(n)}{n^{2}} = k > 0$, then there exists a ray starting from (0,0) that crosses an infinite number of the discs $(B(x_{m},0.5))_{m}$. My Thoughts: I find this problem particularly curious. There are several hints below the problem: Use that if $A \subset \mathbb{R}^{2}$ is Lebesgue-measurable and $k \geq 0$ then $kA= \{ kx:x \in A \} $ is Lebesgue-measurable too and $\lambda(kA)=k^{2}\lambda(A)$. Use that $\mu( \cup _{n} A_{n}) < +\infty$ implies $\mu( \lim \sup A_{n}) \geq \lim \inf _{n} \mu (A_{n})$ for any measure $\mu$. I have thought about calling $R_{\alpha}$ to the ray with angle $\alpha$ and $A_{n} = \{ \alpha : R_{\alpha}$ crosses $B(x_{n},0.5) \}$. Then it would be enough to prove that $\lim \sup A_{n} \neq \emptyset$. Using the second hint, it is enought to prove that $\lim \inf \mu(A_{n}) >0$ for certain measure $\mu$. It would be done if I could find a measure such that $\mu(A_{n})=\frac{\psi(n)}{n^{2}}$. I feel it is almost done but I'm stuck for nearly a week. Thanks in advance!","['measure-theory', 'lebesgue-measure', 'geometric-measure-theory', 'analysis']"
598649,Random sample from discrete distribution. Find an unbiased estimator.,"$X$ is a discrete random variable with parameter $a > 0$ whose pmf is defined as:
$$
f_X(x) = \begin{cases}0.2, &x = a\\0.3, &x = 6a\\0.5, &x = 10a\end{cases}
$$
Say we have a random sample of length $n$ of $n$ independent, identically distributed random variables with the distribution of $X$. I need to find an unbiased estimator ($\operatorname{E}[\,\hat{\theta}\,] = \theta$) for $a$. We know that $\operatorname{E}[X] = 7a$, and we could say $\operatorname{E}[\frac{1}{7}\cdot\overline{X}] = a$. So, is $\frac{1}{7}\cdot\overline{X}$ an unbiased estimator for $a$?","['probability-theory', 'probability-distributions', 'probability']"
598666,Infinite Probability,"A has 2 dollars and B has 3 dollars. They toss a coin. If it is heads A gives 1 dollar to B, B gives 1 dollar to A otherwise. P(Heads) = 1/3 What is the probability of B's winning? I tried too much but I could not solve this.
I found P(B) = {HH, HTTT, THTT, ...} but I couldnt find a pattern for this. Thanks in advance.",['probability']
598686,Is there an invertible matrix that transposes?,"Quick question: I was asked if there exists an invertible matrix $P$ over the complex numbers such that for any matrix $A$: $PAP^{-1} = A^{T}$ I don't know how to prove it, but I don't think this is true. I know every matrix is similair to its transpose, but it can't be the same matrix $P$ for all matrices...So my gut feeling tells me no, but how do I show it?","['matrices', 'linear-algebra']"
598689,"If $a$ and $b $ are two integers, and $a \mid b$, then gcd$(a^2,b^2)$ =","If $a$ and $b $ are two integers, and $a \mid b$, then gcd$(a^2,b^2)$ = I think the answer is $a^2$. Is it correct?",['discrete-mathematics']
598692,Distribution of the sum of absolutes values of T-distributed random variables,"Where $X$ is a r.v. following a symmetric $T$ distribution with $0 $ mean and tail parameter $\alpha$ . I am looking for the distribution of the $n$ -summed independent variables $ \sum_{1 \leq i \leq n}|x_i|$ . $Y=|X|$ has for PDF $\frac{2 \left(\frac{\alpha }{\alpha +y^2}\right)^{\frac{\alpha +1}{2}}}{\sqrt{\alpha } B\left(\frac{\alpha }{2},\frac{1}{2}\right)}$ , $y \geq 0 $ . I managed to get the characteristic function $C(t)$ but could not invert the convolution, that is, $C(t)^n$ .
Thank you for the help.","['convolution', 'independence', 'probability-theory', 'probability-distributions', 'characteristic-functions']"
598704,Sum of squares of cotangents (Check properly of expression),"I found exercise in ""Introduction to algebra"" Part I (A.I. Kostrikin) Check expression
  $\sum_{k=1}^n\cot^2\frac{k\pi}{2n+1}=\frac{n(2n-1)}{3}$ for
  $n=1,2,3,4,5$. For $n=1,2$ it is simple. $\cot\frac{\pi}{3}=\frac{1}{\sqrt{3}}$, so $\left(\frac{1}{\sqrt{3}}\right)^2=\frac{1}{3}=\frac{1(2-1)}{3}$. $\cot\frac{\pi}{5}=\sqrt{1+\frac{2}{\sqrt{5}}}$ and $\cot\frac{2\pi}{5}=\sqrt{1-\frac{2}{\sqrt{5}}}$, so $\left(\sqrt{1+\frac{2}{\sqrt{5}}}\right)^2+\left(\sqrt{1-\frac{2}{\sqrt{5}}}\right)^2=2=\frac{2\cdot3}{3}$. But for bigger values i have a lot of problems. This is begin of book and I feel that should be simple way to resolve that. I found proof for one case here (Proof for $n=3$) , but this is much more complicated than cases $n=1,2$. Is there any basic way to resolve that exercise? Without Chebyshev polynomials or Teoplitz matrixes?","['trigonometry', 'induction', 'alternative-proof']"
598709,Intersection of class number one fields,Let $F$ and $K$ be two number fields with class number one. How can one prove that the class number of $F \cap K$ is also equal to one. I have been trying to prove something like the intersection of the hilbert class fields is the hilbert class field of the intersection but I haven't been able to do so nor  have I any kind of indication that it should be true. Can we say something in general about the class number of the intersection of two fields ? Or about the Hilbert class field of the intersection of two fields ? Anyway i'm guessing this assertion must have a way more elementary answer.,"['class-field-theory', 'algebraic-number-theory', 'number-theory']"
598711,Eigenvalues of a Permutation?,"I'm stuck on the following problem for my Linear Algebra class: Let $\pi:\{1, \ldots, n \} \rightarrow \{1, \ldots, n\}$ be a bijective map (permutation). Let $f_{\pi}:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be defined by $f_{\pi}(x_1, \ldots, x_n) := (x_{\pi(1)},\ldots,x_{\pi(n)})$. Determine the set of eigenvalues of $f_{\pi}$. I know that in general for a square matrix $A$, the set of real eigenvalues of $A$ is given by $\{\lambda \in \mathbb{R}\mid \det(A- \lambda I) = 0\}.$ I've figured out that the matrix representation of $f_{\pi}$ with respect to the standard ordered basis will have rows that contain all $0$s except for a $1$ in one column; this column will be different for each row. However, I can't figure out how to get the eigenvalues from there. Please advise.","['linear-algebra', 'eigenvalues-eigenvectors']"
598732,Heisenberg Bound,"Question Verify $x(t) = e^{i\omega t}e^{-(t-\tau)^2}$ exactly satisfies the Heisenberg bound of $\sigma_t(x)\sigma_{\omega}(x)$. Attempt: I know $\sigma_t(x) = \int_{\mathcal{R}} (t-\mu_t(x))^2\rho_x(t)dt$ where $\rho_x(t) = \frac{|x(t)|^2}{||x||^2}$ and $\mu_t(x) = \int_{\mathcal{R}} t\rho_x(t)dt$ $||x||^2 = <x. x^*> = \int e^{-2(t-\tau)^2}dt$ (I didn't include the derivation for this) I'm also guessing I have to take the Fourier transform at some point to find $\sigma_{\omega}(x)$ I realize that it sort of has the form of a Gaussian which is when the inequality is sharp.  I also know that the inequality is $\sigma_t(x)\sigma_{\omega}(x) \geq \frac{1}{4}$ Other thoughts: I saw a similar question on the physics forum but not sure how to actually calculate/prove it.  I figure that if i find the variance with respect to time, take the Fourier transform o find $\hat{x}(\omega)$ and find the variance with respect to $\omega$, then their product should equal $\frac{1}{4}$.","['fourier-analysis', 'complex-analysis', 'analysis']"
598750,Finding the rotation matrix in n-dimensions,"Suppose that we know two real vectors with n components, which are linked by some arbitrary transformation/scaling/rotation/shearing... Now, I think that it is possible to know which is the scaling matrix and the rotation matrix. For example, the scaling matrix would be a diagonal matrix with n entries representing the n scaling factors. On the other side, I can normalize the two vectors and then compute the rotation matrix between the two, isn't it? 1) How can I retrieve the rotation matrix? (if it is possible, obviously) 2) I need such matrix in order to use it in a computational mechanics context. Then, how would you find it in an operative way? I have been reading somewhere that in multiple dimensions we can apply rotations that are combination of rotations in n-2 hyperplanes. Is this a convenient way to compute such matrix? Thank you very much!! EDIT: Let us put this way, in order to understand better what I should do... Vector $x= [ 2, 4, 5, 3, 6 ]^T$ and vector $y= [ 6, 2, 0, 1, 7 ]^T$. I would like to find the rotation matrix that aligns vector x to vector y. First of all, I understood that one need to find the base of the orthogonal complement to the two vectors, i.e. find the hyperplane containing such two vectors. Consequently, one first compute the null space: Reducing rows:
$$A=
\left[
\begin{array}{ccccc}
 1 & 0 & -1/2 & -1/10 & 4/5 \\
 0 & 1 & 3/2 & 4/5 & 11/10 \\
\end{array}
\right]
$$ Vectors of orthogonal space (linked to $x_3, x_4, x_5$)
$$v_1^{\perp}=
\left[
\begin{array}{c}
 1/2 \\ -3/2 \\ 1 \\ 0 \\ 0 \\
\end{array}
\right],
v_2^{\perp}=
\left[
\begin{array}{c}
 1/10 \\ -4/5 \\ 0 \\ 1 \\ 0 \\
\end{array}
\right],
v_3^{\perp}=
\left[
\begin{array}{c}
 -4/5 \\ -11/10 \\ 0 \\ 0 \\ 1 \\
\end{array}
\right]
$$ Then one can do Gram-Schmidt over the two groups of vectors, the one representing the plane containing the two initial vectors and the one representing the orthogonal subspace. The resulting matrix presents in the column vectors the basis of the space: $$E=
\left[
\begin{array}{ccccc}
    0.7255 &  -0.0117 &   0.2673  & -0.0716 &  -0.6301 \\
         0 &   0.4429 &  -0.8018  & -0.2409 &  -0.3209 \\
   -0.3627 &   0.6701 &   0.5345  & -0.3255 &  -0.1663 \\
   -0.0725 &   0.3555 &        0  &  0.9115 &  -0.1937 \\
    0.5804 &   0.4778 &        0  &       0 &   0.6594 \\
\end{array}
\right]
$$ The last matrix is correct and represent a base because obviously the scalar product between two columns i,j is equal to the Kronecker delta $\delta_{i,j}$. Now, I have information about almost everything, I can compute the angle between the two vectors saying that $$
\cos(\theta)=\frac{x \cdot y}{\left|| x \right|| \: \left|| y \right||}
$$ but now how do I construct the rotation matrix?","['linear-algebra', 'rotations']"
598765,Why are Noetherian Rings important?,"I know they are important in abstract algebra, but why do people study them? Why are they so important to study? Do they make certain things easier to understand?","['ring-theory', 'abstract-algebra', 'noetherian']"
598774,"What functions $f: A \to B$ and $g: B \to A$, satisfy a restriction such that $f$ is not invertible but $f \circ g=id_B$?","I am caught up on the notation of $id_B$. I'm thinking that $f=x^2$, or something along those lines, but not so sure as to what $g$ may be.","['relations', 'discrete-mathematics', 'functions']"
598796,Creating a question that use the $\epsilon$-$\delta$ definition to prove that $f$ is a continuous function,Let $f:\Bbb R\backslash \{1 \} \to \Bbb R$ be defined by $f(x)= \frac{1}{(1-x)}$. Use the $\epsilon$-$\delta$ definition to prove that $f$ is a continuous function. I do not need answers for it. I want your help to twist the questions a little bit with the goal to get another set of questions with more difficulty or similar difficulty and requires different tricks to solve the questions. Please provide the answers and explanation too.,['real-analysis']
598805,Weierstrass product form,"How to show the Weierstrass product form of the entire function $f(z)= \sinh z$ This question seem so interesting. I would like to write my some ideas, but I dont want to direct incorrectly. Please help me to learn correctly and explicitly. I asked to question in fact in order to learn the topic precisely.","['calculus', 'complex-analysis', 'analysis']"
598808,"If you roll a fair six sided die twice, what's the probability that you get the same number both times? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question So I know that rolling a fair six-sided die twice would mean the total possible outcomes would be 36, and rolling the same number twice would be 2/36 or 1/18, but I feel like that's wrong. What am I doing that isn't right?","['dice', 'probability']"
598838,"If I roll two fair dice, the probability that I would get at least one 6 would be....","$11$ out of $36$ ? I got this by writing down the number of possible outcomes ( $36$ ) and then counting how many of the pairs had a $6$ in them: $(1,6)$ , $(2,6)$ , $(3,6)$ , $(4,6)$ , $(5,6)$ , $(6,6)$ , $(6,5)$ , $(6,4)$ , $(6,3)$ , $(6,2)$ , $(6,1)$ . Is this correct?","['statistics', 'dice', 'probability']"
598858,About cutting Almonds,"Every year, during Christmas baking, I chop almonds, which causes me to puzzle over the same question, and I don't quite know how to approach it. I start out with N almonds. Let's assume they are all the same size, so if I drew a histogram of number over size, I'd get a single spike. Now I start cutting. The first cut bisects some randomly selected almonds, at a random angle. The second and subsequent cuts may also bisect some of the pieces that result from a previous cut. Some rather irregular shapes result. The experimental experience is that after some time, there are still surprisingly many large pieces, while some of the smaller pieces have become small enough to be hard to distinguish with the eye. So my histogram has ""smeared out"". There are different ways to draw this histogram. I'm thinking volume of a particle may be best on the x-axis, and number (or perhaps number times volume) on the y-axis. The question: how does this histogram evolve over time? It starts as a single spike, and then what? Does it have inflection points? If I want no more than M particles to be smaller than a certain minimum size, after how many cuts should I stop cutting? P.S. I realize this post has a high likelihood of being marked as off-topic. Almonds? What was he thinking? But methinks it's an interesting problem to think of, and applicable by many people at this time of year who want their baking to work out just right. One year later: I cut some more almonds, and I'm just as puzzled! This year I've been pondering the shapes the pieces end up having. It appears that without having a good idea of the shapes, the original question may not be answerable. Perhaps they pieces can be approximated as being round, in which case it would be straightforward to determine the size distribution of the resulting pieces after the piece is cut.","['statistics', 'geometry', 'probability']"
598880,Calculating a basis of vector space $U \cap V$,"So I have two vector spaces: $ U := \langle(1,2,1,2), (1,2,3,3), (1,2,2,3)\rangle $ and $ V := \langle(2,0,2,1), (3,2,3,2), (0,4,0,1)\rangle $ I was able to calculate the base of both $U$ and $V$: $ B_U = \langle(1,2,1,2), (1,2,3,3), (1,2,2,3)\rangle $ since the vectors linearly independent. $ B_V = \langle(2,0,2,1), (3,2,3,2))\rangle $ since you can write
$(0,4,0,1)$ as $2*(3,2,3,2) - 3*(2,0,2,1)$. However, I have no clue for to do it for $U \cap V$. Could you please point out how to go about doing that and/or giving me an example?
Thanks in advance.","['vector-spaces', 'matrices', 'linear-algebra']"
598892,"If $X$ is not compact, does this mean that Cone($X$) is not compact?","I know that for $X$ a topological space, that if $X$ is compact then so is Cone($X$). Is the following identity also true:
If $X$ is non-compact then Cone($X$) is not compact, if not can somebody give a counterexample. Thanks in advance.",['general-topology']
598893,Prove there is a sequence of increasing positive integers $n_i$ s.t. the limit of $\lim_{{n_i} \to \infty} \sin(n_i)$ exists,Here is my question: Prove there is a sequence of increasing positive integers $n_i$ such that the limit of $\sin(n_i)$ exists as $i \to \infty $. The problem with this question is... I don't know how to start it! Doesn't the sine function fluctuate between -1 and 1? How would a limit exist if it keeps going back and forth? Thank you for any help you give me! :),"['sequences-and-series', 'real-analysis', 'limits']"
598913,Prove that a countable subset of $\mathbb{R}$ has Lebesgue outer measure zero,"Prove that a countable subset of $\mathbb{R}$ has Lebesgue outer measure zero. I believe I am on the right track but can use some help with this one. Here is my proof thus far: Let $a \in \mathbb{R}$. Then, $\{a\} \subset [a-\epsilon, a+\epsilon]$ holds $\forall \epsilon>0$ and so $\lambda^*(\{a\}) \le \lambda^*([a-\epsilon, a+\epsilon])=2\epsilon \; \forall \epsilon >0$. Therefore, $\lambda^*(\{a\})=0$ holds $\forall a \in \mathbb{R}$. If $A = \{ a_1, a_2,... \} = \bigcup_{n=1}^{\infty} \{a_n\}$ is a countable set, then note that $\lambda^*(A) \le \sum_{n=1}^{\infty} \lambda^*(\{a_n\})=0$ so that $\lambda^*(A)=0$. Is this along the right lines?","['lebesgue-measure', 'real-analysis']"
598928,Limit of $\lim\limits_{n \rightarrow \infty}(\sqrt{x^8+4}-x^4)$,"I have to determine the following: $\lim\limits_{n \rightarrow \infty}(\sqrt{x^8+4}-x^4)$ $\lim\limits_{n \rightarrow \infty}(\sqrt{x^8+4}-x^4)=\lim\limits_{x \rightarrow \infty}(\sqrt{x^8(1+\frac{4}{x^8})}-x^4 = \lim\limits_{x \rightarrow \infty}(x^4\sqrt{1+\frac{4}{x^8}}-x^4 = \lim\limits_{x \rightarrow \infty}(x^4(\sqrt{1+\frac{4}{x^8}}-1)= \infty$ Could somebody please check, if my solution is correct?","['radicals', 'real-analysis', 'limits']"
598933,How would I express this as a linear combination?,I want to express 1 as a linear combination of 51781 and 4655. I have a lot of other problems that consist of finding a linear combination but I just need to know do one so then I will be able to do them all. What steps do I need to take to understand how to solve this? Would this be my answer? 51781 = 11*4655+576 4655 = 8*576+47 576 = 12*47+12 47 = 3*12+11 12 = 1*11+1 11= 1*11+0,['discrete-mathematics']
598934,Projection into a subspace?,"Let $S$ be a nonzero subspace with orthogonal basis $(v_1, \ldots, v_k)$ . Then the projection of $u$ onto $S$ is given by: $$\operatorname{proj}_S u = \frac {v_1 \dot{} u}{\operatorname{norm} (v_1)^2}v_1 + \cdots + \frac {v_k \dot{} u}{\operatorname{norm}(v_k)^2}v_k$$ Why does the basis have to be orthogonal? Doesn't the same formula allow you to ""extract"" the components even if the basis isn't orthogonal?","['vector-spaces', 'matrices', 'linear-algebra']"
598954,Does local flow of left-invariant vector field commute with the left-translation operator?,"Let $G$ be a Lie group and $X$ a left-invariant vector field over $G$ (i.e. $\forall g,p\in G: (D_p l_g)(X_p) = X_{gp}$ whereby $l_g$ is the map $G\rightarrow G:p\mapsto gp$). Let $\phi_t$ be the local flow of $X$. Is it true, that $\phi_t$ and $l_g$ commute for every $t\in \mathbb R$ and $g\in G$? (Reason for my question: I want to solve an exercise. I have found a solution if the above statement is true. So I wonder whether from $\forall g\in G: (D_p l_g)(X_p) = X_{gp}$ follows $l_g\circ\phi_t=\phi_t\circ l_g$).","['lie-groups', 'differential-geometry', 'vector-fields']"
598978,What ideal is this?,"Let $k$ be a field and $R = k[X]$ all polys over $k$ in $X$.  Choose $p \in R$ and define $I_p = \{ f \in R : f\circ p(X) \in I \}$, where $I$ is some ideal in $R$. Then $I_p$ is an additive subgroup as $f, g \in I_p \implies (f - g)(p) = f(p) - g(p) \in I$.  And it absorbs $R$: let $h \in R, \ f \in I_p$, then $(hf)\circ p = (h\circ p) (f\circ p) \in I \implies hf \in I_p$.   What is the name of this ideal? Let's see if it generalizes to $R = k[x_1, \dots, x_n]$. Let $I \subset R$ be an ideal and $p = \{p_1, \dots, p_n\}$ a collection of polynomials in $R$. Then define $I_p = \{ f \in R : f(p_1(x), \dots, p_n(x)) \in I \}$. Let $f, g \in I_p$.  Then $(f - g)(p_1, \dots, p_n) = \dots  \in I \implies f - g \in I_p \implies I_p$ is an additive subgroup of $R$.  Let's see if it absorbs $R$.  Let $h \in R$.  Then $(hf)(p_1(x), \dots, p_n(x)) = h(p_1(x),\dots, p_n(x))f(p_1(x),\dots, p_n(x))$, the right factor being in $I$ so the whole thing being in $I \implies hf \in I_p$.  So it generalizes nicely to multivariate polynomials. Some examples. Ex 1. Let $I = (g), \ p(x) = x$, then clearly $I_p = I$ since $I_p = \{ f \in R : f(x) \in I\} = I$.  This shows that the ideal is not always trivial.","['algebraic-geometry', 'abstract-algebra', 'polynomials', 'commutative-algebra', 'ideals']"
598995,Show $(1+\frac{1}{3}-\frac{1}{5}-\frac{1}{7}+\frac{1}{9}+\frac{1}{11}-\cdots)^2 = 1+\frac{1}{9}+\frac{1}{25}+\frac{1}{49} + \cdots$,"Last month I was calculating $\displaystyle \int_0^\infty \frac{1}{1+x^4}\, dx$ when I stumbled on the surprising identity: $$\sum_{n=0}^\infty (-1)^n\left(\frac{1}{4n+1} +\frac{1}{4n+3}\right) = \frac{\pi}{\sqrt8}$$ and I knew $$\sum_{n=0}^\infty \frac{1}{(2n+1)^2} = \frac{\pi^2}{8}$$ So if I could find a proof that $$\left(\sum_{n=0}^\infty (-1)^n\left(\frac{1}{4n+1} +\frac{1}{4n+3}\right)\right)^2 = \sum_{n=0}^\infty \frac{1}{(2n+1)^2}$$ then this could be a new proof that $\zeta(2)=\frac{\pi^2}{6}$. I've thought over this for almost a month and I'm no closer on showing this identity. Note: Article on the multiplication of conditionally convergent series: http://www.jstor.org/stable/2369519","['sequences-and-series', 'real-analysis', 'number-theory']"
599043,What is the best way to supplement a complex variables class to make it more complete for a math major?,"For the upcoming semester I plan on a taking a “complex variables” course that many people, including myself, would not consider a true complex analysis class. I know that the course will likely use a text similar those by Saff & Snider or Brown & Churchill because it is more of a survey class meant to give the basics for leading into to true complex analysis classes and giving the appropriate tools for physicists and engineers. As someone interested in theoretical mathematics, I naturally want to expand my knowledge beyond what is taught, see a more rigorous presentation of the material, have applications leaning more toward number theory than physics, and see topological constructions in action. I know that Ahlfors’ Complex Analysis is the a very common text instructors and students turn to for what I am looking for, but it is very expensive ($200 USD + for a ~300 page text), and I have heard people describe it as “difficult” for independent study unless you really know what you’re doing beforehand. Is there a better text for me to follow? I see that MIT has its 18.112 course (Functions of a Complex Variable), an undergraduate level course based on Ahlfors , listed on OCW, so I would have something to follow and test myself on, but I would prefer to not use Ahlfors. I have seen recommendations to other people to use Visual Complex Analysis for self-study, but this book is still more directed at undergraduate physics students and the like. What are the best alternatives to a text like Ahlfors? Which are the best suited for independent study for someone working alongside a less mathematically rigorous course? Which are the more comprehensive? Are there any that follow naturally from where books like that by Brown & Church leave off? Which are the most comprehensive, and are there any that lead into analytic number theory or give a taste of complex analysis in several variables?","['analytic-number-theory', 'complex-analysis']"
599071,Expanding brackets of the form $(a+b)^n$,"If we have the equation $
(a+b)^n = (a+b)\times(a+b)\times(a+b)\times \ldots \times (a+b)
$ expanding the right hand side of the above, is the sum of terms in the form $a^n$, $a^{n-1}b$,$a^{n-2}b^2$, $\ldots$, $b^n$. That is $a^{n-1}b^k$ for $k=0,1,\ldots,n$ Now, my textbook states the following Each term of the form $a^{n-k}b^k$ arises by choosing the variable $b$
  from $k$ of the pairs of brackets on the right hand side of the
  equation and the variable $a$ from the remaining $n-k$ pairs of
  brackets. My question is now, why? There is no proof given for this, and I am struggling to understand why the above holds.For a very simple expansion, where $k=1$ and $n=2$, we have 2 terms of the form $ab$, here its pretty easy to see from $
(a+b)(a+b) = a(a+b) + b(a+b) = a^2 + b^2 + 2ab
$ why the statement in the book holds for this case. But, for bigger ones, such as $(a+b)^3$ i can't see it. I can see that there is 3 ways of choosing one $b$ and two $a$, for the term $a^2b$ when looking at $(a+b)(a+b)(a+b)$, but I cant relate it to the expansion of them, if that makes sense?","['binomial-theorem', 'combinatorics']"
599100,Liapunov function for a system of quadratic ODEs,"I have been trying to find a Liapunov function which would give me information about the stability of the following system of differential equations, however, I am not able to come up with any. The problem is an exercise from the book 'Differential Equations and Dynamical Systems' by Lawrence Perko (Third Edition), Chapter Two, Problem Set $9$, Question $5(c)$, so I guess, there does exist a Liapunov function for the same: \begin{align}
\frac{\mathrm{d}x_1}{\mathrm{d}t} &= -4x_2 + x_1^2 \\
\frac{\mathrm{d}x_2}{\mathrm{d}t} &= 4x_1 + x_2^2
\end{align}","['lyapunov-functions', 'ordinary-differential-equations']"
599103,Special Gram's inequality,"For $1 \le s < k$ and $v_1$, $v_2,\dots,v_k$ vectors in $\mathbb{R}^n$, show that
$$\det G(v_1, v_2,\dots,v_k) \le \det G(v_1,v_2,\dots,v_s)\det G(v_{s+1}, v_{s+2},\dots,v_k).$$
Here, $G(v_1, v_2,\dots,v_k)$ is a Gram matrix of vectors $v_1, v_2,\dots,v_k$ with the standard inner product. This is my homework problem, but I have no idea how to approach it. I found that this is one of the Gram's inequalities, but I can't figure out how it could be derived either from this:
$$\det G(v_1, v_2,\dots,v_k) \ge 0,$$
or Hadamard's inequality:
$$\det G(v_1, v_2,\dots,v_k) \le \prod_{i=1}^{k}\|x_i\|^2.$$
So any help would be much appreciated.","['matrices', 'linear-algebra', 'determinant']"
599108,Find the numbers satisfying $x+y=19$ and $x^3+y^3=2071$,"The sum of the cubes of two numbers is $2071$, while the sum of the two
numbers themselves is $19$. Find the two numbers. I've been working hard to solve this problem and I need someone to tell me how to solve it, it perplexes me. I know the answer is $7$ and $12$ and it might have something to do with $$a^3 + b^3 = (a + b)(a^2 – ab + b^2)$$  but how do they get to that answer? Any help will be appreciated thank you. I followed this Yahoo question up to where it said solve it then I searched like $4$ hours looking for a way to solve it, so I'm hoping someone can help me out.",['algebra-precalculus']
599109,"Calculate $\int_\Gamma \frac{f'(z)z}{f(z)}\, \operatorname dz$","Calculate usign the formula for zeros and poles, for a meromorphic function $f$ the following:
 $$\int_\Gamma \frac{f'(z)z}{f(z)}\, \operatorname dz$$ Where $\Gamma$ is simple and closed. I tried writting $ \dfrac{f'(z)z}{f(z)}=\dfrac{g'(z)}{g(z)}$ for some meromorphic function (and then use the formula for zeros and poles for $g$) $g$ but I can't find $g$. I don't know if this idea is good for reducing this integral.","['laurent-series', 'complex-analysis']"
599110,Prove that every hyperplane is a null space of a linear functional [duplicate],"This question already has an answer here : How do I prove that a subspace of a vector space $X$ is the null space of some linear functional on $X$? (1 answer) Closed 8 years ago . How can we prove that every hyperplane (a subspace of dimension $n-1$) is a null space of a linear functional? I don't know how to prove this. 
I tried a lot, but something is missing.",['linear-algebra']
599111,"Show that for $\forall a\in\mathbb{H}, \ \exists b \in\mathbb{H}: ab =ba = 1$.","Show that  $\forall a\in\mathbb{H}, \ \exists b \in\mathbb{H}: ab =ba = 1.$ I am pretty sure I can easily google the multiplicative inverse in $\mathbb{H}$, but can you give me a hint on how to determine the inverse von an arbitrary $a \in\mathbb{h}$ myself? This task comes directly after showing that the conjugation is a ring antihomomorphism. ($a\ \bar+ \ b\ = \bar a+\bar b, a\ \bar  *\ b = \bar b*\bar a$ and $ 1 = \bar1$)","['quaternions', 'abstract-algebra']"
599121,Why can't you divide matrices?,"I was just wondering that because one can multiply and add and subtract matrices, why can't    one divide them?","['matrices', 'linear-algebra', 'abstract-algebra']"
599122,Equivalence Classes of a Relation Given as a Set of Ordered Pairs,"Question: The relation R is an equivalence relation on the set A. Find the distinct equivalence classes of R. A = {a, b, c, d}
R = {(a, a), (b, b), (b, d), (c, c), (d, b), (d, d)} My work: 
So when you draw the directed graph you get a loop from a to a, b to b, c to c and d to d
There are arrows from b to d and from d to b. Now this is where I get confused (this solution is from the book): [a] = {x∈A | x R a} = {a} <- this one makes sense as a is a loop [b] = {x∈A | x R b} = {b,d} <- why is {b,b} not included? [c] = {x∈A | x R c} = {c} <- this one makes sense as c is a loop [d] = {x∈A | x R d} = {b,d} <- again why is d,d not included Answer: My book says the equivalence classes are {a}{b,d}{c} I'm not really sure how to go about solving this problem. I would really appreciate any help on what to do.","['relations', 'equivalence-relations', 'functions']"
599126,Continuous bounded function $f:\mathbb{R}\rightarrow \mathbb{R}$,"Question is to check which of the following holds (only one option is correct) for a continuous bounded function  $f:\mathbb{R}\rightarrow \mathbb{R}$. $f$ has to be uniformly continuous. there exists a $x\in \mathbb{R}$ such that $f(x)=x$. $f$ can not be increasing. $\lim_{x\rightarrow \infty}f(x)$ exists. What all i have done is : $f(x)=\sin(x^3)$ is a continuous function which is bounded by $1$ which is not uniformly continuous. suppose $f$ is bounded by $M>0$ then restrict $f: [-M,M]\rightarrow [-M,M]$ this function is bounded ad continuous so has fixed point. I could not say much about the third option ""$f$ can not be increasing"". I think this is also true as for an increasing function $f$ can not be bounded but i am not sure. I also believe that $\lim_{x\rightarrow \infty}f(x)$ exists as $f$ is bounded it should have limit at infinity.But then I feel the function can be so fluctuating so limit need not exists. I am not so sure. So, I am sure second option is correct and fourth option may probably wrong but i am not so sure about third option. Please help me to clear this. Thank You. :)",['real-analysis']
599133,"Let G be a group of order $n$, where $n$ is a positive integer relatively prime to $\varphi(n)$. Show that G is cyclic.","Let G be a group of order $n$, where $n$ is a positive integer relatively prime to $\varphi(n)$. Show that G is cyclic. You may only assume the Feit-Thompson theorem here and prove in the following way: (1) $n$ is a product of odd prime numbers and squarefree. (2) Then $G$ is solvable. Show that it has a cyclic quotient of prime order, that is there is a an epimorphism $G\to H$with $H$ cyclic of prime order. Let $N$ be the kernel. (Hint: using composition series) (3)Show that $G\cong N \times H$ and then prove $G$ is abelian. (4)Show that $G$ is cyclic. I have proved (1) but get stuck at step 2. Is there any help? Thanks.","['cyclic-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
599172,"Structures with addition, multiplication and exponentiation.","The set $\mathbb{N}$ can be viewed as a mathematical structure with operations off addition, multiplication and exponentiation. Observe that: It forms an Abelian monoid under both addition and multiplication. Multiplication distributes over addition. $1^x = x^{0} = 1$ $x^{a+b}=x^{a}x^{b}$ $x^{ab} = (x^a)^b$ Furthermore, the set $[0,\infty)$ can also be viewed in this way. Are there other interesting examples of this sort of thing? I am especially looking for examples lacking a natural total order. Remark . A few more examples occur to me. However, they're both naturally ordered. Firstly, for every strong limit cardinal $\kappa$, I think that the set $\{\nu < \kappa\}$ is an example of such a structure. Secondly, if we drop the requirements that addition and multiplication be commutative, and require distributivity only on the left, as in $$x(a+b)=xa+xb,$$ then every non-trivial ordinal that is closed under exponentiation is an example of such a structure.","['examples-counterexamples', 'abstract-algebra']"
599204,"Stolz-Cesaro Theorem, 0/0 Case","How to prove the $0/0$ case of Stolz-Cesaro Theorem? In other words: Given that
$$\lim_{n \to \infty} a_n = \lim_{n \to \infty} b_n = 0$$
with $(b_n)_{n=1}^{\infty}$ strictly monotone, and that $$\lim_{n \to \infty} \frac{a_{n+1} - a_{n}}{b_{n+1} - b_{n}} = L$$ prove that $\lim_{n \to \infty} \frac{a_n}{b_n} = L$.","['calculus', 'real-analysis', 'limits']"
599206,What does the notation $P[X\in dx]$ mean?,"I am studying probability, specifically regular conditional distributions, and came across the notation $P[X\in dx]$. What does this mean? Here, $X$ is a random variable and $P$ is a probability measure. I am also curious about $$\frac{P[Y\in dy\ |\ X=x]}{dy}.$$","['notation', 'probability']"
599213,"The collection of all charges on $(X, \mathcal{X})$ is a Banach space.","The collection of all charges on $(X, \mathcal{X})$ is a Banach space under
  the vector operations $(c\mu)(E) = c\mu(E)$, $(\lambda + \mu)(E) = \lambda(E) + \mu(E)$
  and the norm $\|\mu\| = |\mu|(X)$. I took a Cauchy sequence $(\mu_n)$ and I defined $\mu(E)=\lim_{n\to \infty}\mu_n(E)$, I had proved that $\lim_{n\to \infty}\mu_n(E)$ exists, and that $\mu$ is a charge, but I can't proof that $$\|\mu-\mu_n\|=|\mu-\mu_n|(X)\to 0.$$ I know that this question is similar to "" Space of Complex Measures is Banach (proof?) "" but I don't understand why $$\lVert\mu-\mu_m\rVert
\leq \liminf_{n\to\infty}\lVert\mu_n-\mu_m\rVert
\xrightarrow{m\to\infty}0.$$",['measure-theory']
599217,"prove that one of the digits $1,2,\dots,9$ occurs infinitely often in the decimal expansion of $\pi$","prove that one of the digits $1,2,\ldots,9$ occurs infinitely often in the decimal expansion of $\pi$. you may use without proof the fact that $\pi$ is irrational. It is recommended using proof by contradiction. My attempt: Supppose that $1$ does not occur infinitely in the decimal expansion of $\pi$ and that it only occurs once. Since  the starting decimals of $\pi$ is $3.14$ then $1$ has already occurred but since $\pi$ is irrational, the decimal expansion is infinitely long it means that $1$ has to occur in $\pi$ infinitely. By contradiction $1$ must occur infinitely long in the decimal expansion of $\pi.$ Note: I realised my attempt is foiled since one argument to my attempt could be; what if $1$ never occurs again, but $2$ occurs infinitely often? Question: How do you proof what I am trying to proof by contradiction?",['discrete-mathematics']
599221,Distance from point in circle to edge of circle,"The situation is as follows: I have a circle with a diameter of $20$ and a center at $(0,0)$.
A point $P$ inside that circle is at $(2,0)$. How do I calculate the distance from $P$ to the edge of the circle for a given angle $\theta$?",['geometry']
599226,"$\int_{S^{n-1}}\operatorname e^{ix\cdot \omega}\, \operatorname d\omega$","Given $x \in \mathbb R^n$, there exists a simpler expresion for the integral?
$$\int_{S^{n-1}}\operatorname e^{ix\cdot \omega}\, \operatorname d\omega$$
where $S^{n-1}$ is the sphere of $\mathbb R^n$.I know that only depends on |x| but nothing else.","['spherical-harmonics', 'calculus']"
599227,How many ways are there of rearranging the letters MATH such that each letter is replaced by a different one?,"How many ways are there of rearranging the letters MATH such that each letter is replaced by a different one? In other words, no letters can be in the same place. So it starts as MATH. It could be THAM or AMHT. But it could not be MAHT because M and A are still in their initial positions. I know that for any combination we would get 4!, but I'm not sure where to go from there.",['discrete-mathematics']
599241,Do silly-rings exist?,"A ring can be defined as a near-ring satisfying two-sided distributivity, whose underlying additive group is Abelian. Negating this second stipulation, we obtain the following definition. A silly-ring is a near-ring satisfying two-sided distributivity, whose underlying additive group is non -Abelian. Do silly-rings exist?","['ring-theory', 'examples-counterexamples', 'abstract-algebra']"
599243,Writing a linear function?? Precalculus,I am suppose write a linear function for $h(x)$ and I am given $h(6) = -3$ and $h(2) = 7$ Iam not asking u to do the problem for me just a link or a little help thanks,['algebra-precalculus']
599251,"Check Points are line, triangle, circle or rectangle","How to determine geometric properties of four distinct points in a plane (x1,y1), (x2,y2), (x3,y3), (x4,y4) represented in the 2-D Cartesian coordinate system, whether these four points are on a line, a circle, a rectangle, a triangle. To check points are on a line, we can check if two lines forming are colliniar or not.. (y1 - y2) * (x1 - x3) -  (y1 - y3) * (x1 - x2) = 0
(y2 - y3) * (x2 - x4) -  (y2 - y4) * (x2 - x3) = 0 How about circle, rectangle and triangle?","['geometry', 'fixed-point-theorems', 'coordinate-systems']"
599265,What is the definition of the domain of composite partial functions?,"In calculus books they define the domain(natural domain) of $f+g$ as $Dom(F)\bigcap Dom(g)$. And they define the domain of $fog$ as the set of all real numbers $x$ such that $x$ is in the domain of the function $g$ and $g(x)$ is in the domain of the function $f$. Is it how they define the domain of $f+g$ or $fog$ as partial functions in very formal mathematics?Can you suggest any books I can see the formal definitions of domain , source and compositions of partial functions in details?","['foundations', 'calculus', 'elementary-set-theory']"
599275,Convergence in Distribution which places mass of 1/2 at -1 and +1,"Let $\{X_{n}\}$ be i.i.d. with $P(X_{n}=1)=P(X_{n}=-1)=1/2$ and let $Y_{n}=\sum_{k=1}^{n}{\frac{1}{2^{k}}X_{k}}$. Then how do we show that $Y_{n}\rightarrow{U(-1,1)}$ in distribution. As a solution I tried the following I could not get it ultimately. I used convergence in distribution if and only if convergence in characteristic function. The characteristic function of $Y\sim{U(-1,1)}$ is $\phi_{Y}(t)=\frac{sin(t)}{t}$ and I found  $\phi_{Y_{n}}(t)=\prod_{k=1}^{n}{cos(\frac{t}{2^{k}})}$. But then I don't see that  $\phi_{Y_{n}}(t)\rightarrow{\phi_{Y}(t)}$ as $n\rightarrow{\infty}$ for all $t$.","['statistics', 'probability']"
599292,"Schur functors as spaces of ""flag tensors""?","Consider the following construction: for a vector space $V$, define $W \subseteq \bigwedge^2 V \otimes V$ by $W = \langle\ \alpha \otimes v : v \in \text{Span}(\alpha) \ \rangle$, that is, $W$ is spanned by ""flag tensors"", as in a 2-plane containing a line. Of course, we can make similar constructions for arbitrary shapes of flags. How is $W$ related to the Schur functor $\mathbb{S}^{2,1}(V)$? (Edit: I have answered this particular instance of the question. See below.) Note that the generators of $W$ satisfy the same ""exchange relations"" used to define the Schur functor (e.g. in Fulton's Young Tableaux ): for example, if $\alpha = x \wedge y$, and $v = ax + by$, then by playing around with the tensors one can show $x \wedge y \otimes v = v \wedge y \otimes x + x \wedge v \otimes y$, which is the defining relation used to construct $\mathbb{S}^{2,1}(V)$ as a quotient of $\bigwedge^2 V \otimes V$ (by modding out by it). This works for all the other exchange relations for other shapes of flag as well. The quotient picture is nice to analyze (e.g. finding a basis takes some relatively straightforward combinatorics), and is very natural for algebraic geometry, since it corresponds to the surjection $H^0(\mathbb{P}(\bigwedge^2 V) \times \mathbb{P}(V),\mathcal{O}(1,1)) \to H^0(Fl^{2,1}(V),\mathcal{O}_{Fl^{2,1}(V)}(1,1)),$ coming from the Plücker embedding of the (2,1)-flag variety. (It's a general fact that the Schur functors give the multigraded components of the flag variety's Plücker coordinate ring in this way.) On the other hand, the setup above with ""flag tensors"" is appealingly simple and I'd like to understand it. For example, the definition of $W$ is clearly functorial and a $GL$-subrepresentation (the condition $v \in \text{Span}(\alpha)$ is $GL$-invariant). Is it actually (or almost) the same space? Is it simply dual to the quotient picture somehow? (Perhaps my $W$ is just $\mathbb{S}^\lambda(V^*)$ or something.) Or is it entirely different? I got confused when I tried to work this out, particularly since (a) there are other ways of constructing Schur functors as subspaces rather than quotients, (b) I'm not sure how to define $W$ for a partition $\lambda$ with repeated column lengths. For instance, $\lambda = (2,2,2,1)$ should come from $Sym^3(\bigwedge^2V) \otimes V$. Should the corresponding ""flag tensors"" be of the form $\alpha_1 \alpha_2 \alpha_3 \otimes v$, where $v \in \text{Span}(\alpha_i)$ for each $i$? Thanks! Edit: A quick way to see that the $W$ given initially is isomorphic to $\mathbb{S}^{2,1}(V)$ is to use the Pieri rule, which in this case says that $\bigwedge^2V \otimes V \cong \mathbb{S}^{2,1}(V) \oplus \bigwedge^3 V$. And the definition guaranteed that $W = \ker\left( \bigwedge^2V \otimes V \to \bigwedge^3 V\right).$","['schubert-calculus', 'algebraic-geometry', 'representation-theory', 'combinatorics']"
599304,Continuity correction: Change P(2 ≤ x < 9) to continuous?,Convert discrete probability into continuous probability using continuous correction: attempt: Discrete: P(2 ≤ x < 9) therefore continuous should be Continuous: P(1.5 < X < 8.5) Is this right? or should it be P (1.5 < x < 9)?,"['statistics', 'data-analysis']"
599307,A clear reference on regular conditional distributions?,"I've been trying to learn about regular conditional distributions from Klenke's book on probability theory, but I'm incredibly confused. I looked at Durrett's book, but his chapter on regular conditional distributions is short and lacks examples. Does anyone know of another reference that is gentle and gives many examples? It would be great if it also included a treatment of the Borel-Kolmogorov paradox, but perhaps that is too much to ask. I am not familiar with the probability literature, so perhaps this is an easy question and another standard textbook gives a good treatment. If so, I welcome that as an answer!","['probability-theory', 'reference-request']"
599309,Proving completeness and compactness of a sequence of metric spaces.,"The problem statement Let $(X_n,d_n)_{n \in \mathbb N}$ be a sequence of metric spaces. Consider the product space $X=\prod_{n \in \mathbb N} X_n$ with the distance $d((x_n),(y_n))=\sum_{n \in \mathbb N} \dfrac{d_n(x_n,y_n)}{n^2[1+d_n(x_n,y_n)]}$ $a)$ Prove that $(X,d)$ is complete if and only if each $(X_n,d_n)$ is complete. $b)$ Prove that $(X,d)$ is compact if and only if each $(X_n,d_n)$ is compact. My attempt at a solution: For $a)$, after Willie's answer I could do the following: $\implies$ Let $n$ fixed, call it $n=n_0$ and let $\{y^{j}\}_{j \in \mathbb N}$ be a Cauchy sequence in $(X_{n_0},d_{n_0})$. I fix an arbitrary $x_i \in (X_i,d_i)$ for $i \neq n_0$ and now I consider the sequence $\{\vec{x}^{j}\}_{j \in \mathbb N}$ defined as $\vec{x}^{(j)} = (x_1, x_2, \ldots, x_{n_0-1}, y^{(j)}, x_{n_0+1} , \ldots) \in X$. Lets prove $\{\vec{x}^{j}\}_{j \in \mathbb N}$ is a Cauchy sequence: let $\epsilon>0$, by hypothesis, there is $N \in \mathbb n$ : $\space \forall \space m,n \geq N$, $d_{n_0}(y^n,y^m)< \epsilon$. For $k \neq n_0$, $d_k(x_{k}^m,x_{k}^n)=d_k(x_k,x_k)=0$. Then, $d(\vec{x}^{m},\vec{x}^{n})=\sum_{k \in \mathbb N} \dfrac{d_k(x_{k}^m,x_{k}^n)}{k^2[1+d_k(x_{k}^m,x_{k}^n)]}=\dfrac {d_{n_0}(x_{n_o}^m,x_{n_0}^n)}{{n_0}^2[1+d_{n_0}(x_{n_o}^m,x_{n_0}^n)]}\leq d_{n_0}(y^m,y^n)<\epsilon \space \forall n,m \geq N$. This proves $\{\vec{x}^{j}\}_{j \in \mathbb N}$ is a Cauchy sequence in $X$. which means $\vec{x}^{j} \to  \vec{a}^{\infty}$, $\vec{a}^{\infty}=(a_1,a_2,...,,a_{n_0-1},a_{n_0},a_{n_0+1},...)$. Lets prove that $y^j \to a_{n_0}$ in $(X_{n_0},d_{n_0})$. Given $0<\epsilon<1$, there is $N \in \mathbb N$ : $\space \forall \space n\geq N$, $d(\vec{x}^n,\vec{a}^{\infty})<\dfrac{\epsilon}{n_{0}^2}$. So, $\dfrac{d_{n_0}(y^j,a_{n_0})}{n_{0}^2[1+d_{n_0}(y^j,a_{n_0})]}\leq \sum_{k \in \mathbb N} \dfrac{d_k(x_{k}^n,a_k)}{k^2[1+d_k(x_{k}^n,a_k)]}=d(\vec{x}^n,\vec{a})< \dfrac{\epsilon}{n_{0}^2}$ for $n \geq N$. From here, it follows that $d_{n_0}(y^j,a_{n_0})<\dfrac{\epsilon}{1-\epsilon}<\epsilon$ for all $n\geq N$. We've proved that $\{y^{j}\}_{j \in \mathbb N}$ is a convergent sequence in $(X_{n_0},d_{n_0})$, since the Cauchy sequence  and $n=n_0$ were arbitrary, one can conclude that for every $n \in \mathbb N$, $(X_n,d_n)$ is complete. Now it remains to prove the other implication (I had problems with this one): Let $\{\vec{x}^n\}_{n \in \mathbb N}$ be a Cauchy sequence in $(X,d)$. For a fixed $n=n_0$, lets prove that $\{x_{n_0}^{n}\}_{n \in \mathbb N}$ is a Cauchy sequence in $(X_{n_0},d_{n_0})$. Let $0<\epsilon<1$, by hypothesis, there is $N \in \mathbb N: n,m\geq N \implies d(\vec{x}^n,\vec{x}^m)<\dfrac{\epsilon}{{n_0}^2}$. But then, $\dfrac{d_{n_0}(x_{n_0}^n,x_{n_0}^m)}{n_{0}^2[1+d_{n_0}((x_{n_0}^n,x_{n_0}^m)]}\leq \sum_{k \in \mathbb N} \dfrac{d_k(x_{k}^n,x_{k}^m)}{k^2[1+d_k((x_{k}^n,x_{k}^m)]}=d(\vec{x}^n,\vec{x}^m)<\dfrac{\epsilon}{{n_0}^2}$. We have that $d_{n_0}(x_{n_0}^n,x_{n_0}^m)<\dfrac{\epsilon}{1-\epsilon}<\epsilon$. So the sequence $\{x_{n_0}^n\}_{n \in \mathbb N}$ in $(X_{n_0},d_{n_0})$, which means there is $y^{n_0}=\lim_{n \to \infty} x_{n_0}^n$. If we call $\vec{y}^{\infty}=(y_1,y_2,...,y_n,...)$, lets show that $\vec{y}^{\infty}=\lim_{n \to \infty}\vec{x}^n$. Here I got stuck, given $\epsilon>0$, I don't know which $N$ to choose such that for $n\geq N$, $d(\vec{x}^n,\vec{y}^{\infty})<\epsilon$, for every term of the sequence $\{\vec{x}^n\}_{n \in \mathbb N}$, I will have a different $N_k$ that will depende on the sequence of the space $(X_k,d_k)$. A secondt attempt for this last part: Note that $0\leq d(\vec{x}^n,\vec{y}^{\infty})=\sum_{k \in \mathbb N} \dfrac{d_k(x_{k}^n,y_k)}{k^2[1+d_k(x_{k}^n,y_k)]}\leq \sum_{k \in \mathbb N} \dfrac{1}{k^2}$. Then, $\sum_{k \in \mathbb N} \dfrac{d_k(x_{k}^n,y_k)}{k^2[1+d_k(x_{k}^n,y_k)]}$ is convergent, which means that given $\epsilon>0$, there is $N \in \mathbb N$: $\sum_{N+1}^{\infty}  \dfrac{d_k(x_{k}^n,y_k)}{k^2[1+d_k(x_{k}^n,y_k)]}<\dfrac{\epsilon}{2}$. For a fixed $k$, $\{x_{k}^n\}_{n \in \mathbb N}$ converges to $y_k$ in $(X_k,d_k)$, so there is $n_k : \space \forall \space n_k\geq n$, $d_k(x_{k}^n,y_k)<\dfrac{\epsilon}{2N}$. Consider $M=\max\{n_1,n_2,...,n_N\}$,then $\sum_{k=1}^N \dfrac{d_k(x_{k}^n,y_k)}{k^2[1+d_k(x_{k}^n,y_k)]}\leq \sum_{k=1}^N d_k(x_{k}^n,y_k)<N\dfrac{\epsilon}{2N}=\dfrac{\epsilon}{2}$. So we have that for $n\geq M$, $d(\vec{x}^n,\vec{y}^{\infty})=\sum_{k=1}^N \dfrac{d_k(x_{k}^n,y_k)}{k^2[1+d_k(x_{k}^n,y_k)]}+\sum_{k=N+1}^{\infty} \dfrac{d_k(x_{k}^n,y_k)}{k^2[1+d_k(x_{k}^n,y_k)]}<\dfrac{\epsilon}{2}+\dfrac{\epsilon}{2}=\epsilon$ This proves that $\vec{x}^n \to \vec{y}^{\infty}$; since the sequence $\{\vec{x}^n\}_{n \in \mathbb N}$ was an arbitrary Cauchy sequence in $(X,d)$, then  $(X,d)$ is complete. Sorry if my notation is confusing, I did the best I could but with so many sequences and indexes I easily get lost.","['metric-spaces', 'compactness', 'analysis']"
599315,"The number of nuts in a package of ""Premium Cashews"" is normally distributed with a mean of 433 and a standard deviation of 6 nuts.","The number of nuts in a package of ""Premium Cashews"" is normally distributed with a mean of 433 and a standard deviation of 6 nuts. Packages with fewer than 420 nuts or more than 445 nuts will be rejected by quality control. a) what is the probability that a package selected at random has at most 430 nuts? Attempt : (430.5 - 433) / 6 = -0.42 using area under normal distribution curve. -0.42 = 0.3372 therefore there is a 33.72% chance? Am i right? Thanks in advance!","['statistics', 'data-analysis', 'random-variables']"
599376,Complex Analysis: Log Function,"I want to approach this problem with maximum understanding of everything that is going on. I have the function $F(z)=\log(z^2+4)$, and I want to give a region in which it is analytic. I guess I shouldn't call it a function until I give the region since it's multivalued. $(1)$ I first start by solving $z^2+4=0 \Rightarrow z^2=-4$. (why do we do this)? $(2)$ Then, I define $z=re^{i\theta} \Rightarrow r^2e^{2\theta i}=-4$ $(3)$ Thus, $r=2$ and $\theta=\frac{\pi + 2\pi k}{2}$ for $k=0,1$. $(4)$ Next, I draw the rays eminating from the $0's$ of the function (green). $(5)$ These are the two rays describing 2 complex numbers such that when I double their angle and add $4$ I end up on the negative x-axis. $(6)$ Now I choose my region of validity. I take my branch cut to be principle branch of log, which seems intuitive. However, can I also choose to make $f$ analytic on $\mathbb{C}$ \ {$z=re^{i\theta}: r>2, \theta=\frac{pi}{2},\frac{3\pi}{2}$}?","['logarithms', 'analyticity', 'complex-analysis']"
599377,Factoring question from March $2013$ AMATYC exam,"For how many pairs of positive integers $(n, \space m)$ with $n, \space m < 100$ are both of the polynomials $x^2 + mx + n$ and $x^2 + mx - n$ factorable over the integers? I have found four solutions:
$$x^2 + 10x + 24$$
$$x^2 + 20x + 96$$
$$x^2 + 13x + 30$$
$$x^2 + 17x + 60$$ but I found these by trial and error. I do not see how to systematically answer this question.
Any help?",['algebra-precalculus']
599391,Where is $k$ algebraically closed used?,"Suppose $k$ is algebraically closed, $A$, $B$ are $k$-algebras and $A$ is an affine $k$-algebra. It is known that then $A\otimes_k B$ is a domain if $A$ and $B$ are domains. This can be found in Milne's Algebraic Geometry notes as Proposition 4.15(b). I do not see where the assumption $k$ algebraically closed is used. He gives an example that the above is not true if $k$ is not algebraically closed. But i dont see where this assumption is being used in the proof. I think that for an affine $k$-algebra the Jacobson radical is the nilradical, so here we do not need $k$ to be algebraically closed.","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
599458,Proof of Proposition IV.3. 8 in Hartshorne,"Hartshorne book Proposition (IV.3. 8) is that Let $X$ be a curve in $\mathbb{P}^3$, which is not contained in any plane.
   where, curve means a complete, nonsingular curve over algebraically closed field $k$.
  Suppose either (a) every secant of $X$ is a multisecant. or (b) for any two points $P,Q$ in $X$, the tangent lines $L_P.L_Q$ are coplanar. Then  there is a point $A$ in $\mathbb{P}^3$, which lies on every tangent line of $X$. In proof,  fix a point $R$ in $X$, consider the projection from $R$ , $\phi:X-R \rightarrow \mathbb{P}^2$. My question is that (1) If $\phi$ is inseparable, why the tangent line $L_P$ at $X$ passes through $R$ for any point $P$ in $X$? (2) If $\phi$ is separable, does there exist point $T$ is a nonsingular point of $\phi(X)$ over which $\phi$ is not ramified?",['algebraic-geometry']
599459,$\mathrm{card} ( \mathbb{Q})=\mathrm{card}( \mathbb{Q^c})$: Overcoming Wrong Intuition,"This is a widespread intuitive argument, asserting that $\mathrm{card} ( \mathbb{Q})=\mathrm{card}( \mathbb{Q^c})$: Between any two rational numbers there's an irrational one and vice versa. So $\mathrm{card} ( \mathbb{Q})=\mathrm{card}( \mathbb{Q^c})$. How can one convince the learner that this argument is invalid?","['education', 'cardinals', 'elementary-set-theory', 'fake-proofs']"
599460,prove that the closure of the intersection of A and B is the subset of the intersection of the closure of A and the closure of B.,"prove that the closure of the intersection of A and B is the subset of the intersection of the closure of A and the closure of B. my proof: let x be in cl(A intersects B), then x is in the intersection of A and B and x is in the set of the limit of the intersection of A and B.
case i: x is in cl(A intersects B), then x is in A and x is in B, then x is in the closure of A and x is in the closure of B. Therefore, x is in the intersection of the closure of A and the closure of B. For the second part, I'm not sure how to do it. Please help! Thank you. I'm using the Topology without tears book. (3.2 #2) It's online.",['general-topology']
599480,"Unit, co-unit of adjunction",Let us assume the following: (I) $F:Set\rightarrow Group$ is the free group functor and $f:Group\rightarrow Set$ is the natural forgetful functor. (ii) $F:Group\rightarrow Ab$ is the abelianization and $G:Ab\rightarrow Group$ is the forgetful functor. Could someone kindly explicitly compute the unit and co-unit of the adjunction in the above two cases please?,"['category-theory', 'abstract-algebra', 'adjoint-functors']"
599487,Why is 11 times the 7th term of a fibonacci series equal to the sum of 10 terms?,"Why is 11 times the 7th term of a fibonacci series equal to the sum of 10 terms? I was watching scam-school on youtube the other day and this number trick just astonished me. Can someone please explain why this works? After a lot of searching, I've been stumbling onto slightly complicated mathematical explanations. An explanation of a simpler nature, one that a child can understand, would be much appreciated. Also, Can you extend this to find the sum of n terms of a fibonacci type sequence?","['fibonacci-numbers', 'sequences-and-series', 'recreational-mathematics']"
599488,Why gradient vector is perpendicular to the plane,"I know what gradient vector or $\nabla F$ is and I know how to prove that it is orthogonal to the surface (using calculation - not intuitive). In a particular case, in which we have a three variable function, I want to know why the gradient vector is perpendicular as mentioned. I mean, not in theoretical terms, but intuitive.",['multivariable-calculus']
599507,Numbers permutation,Given $n$ numbers and $k$ positions I want the total number of permutations of these n numbers on these $k$ positions if repetition is allowed and if the following two arrangements are considered similar : 1 Two arrangements $(A$ and  $B)$ are similar if $B$ is a cyclic shift of $A$. Example : ${2 3 1}$ is cyclic shift of ${1 2 3}$ 2 Two arrangements $(A$ and $B)$ are similar if $B$ is a reversed cyclic shift of $A$. Example : ${3 2 1 5 4}$ is reversed cyclic shift of ${1 2 3 4 5}$.,"['permutations', 'number-theory', 'logic', 'elementary-number-theory', 'algorithms']"
599532,N-dimensional Hypercubes coloring,"How many ways 3-cube vertices can be coloring using 10 color, vertices which have relation is not able to have same color. I would also appreciate anyone who show the solution for finding total ways problems in order to color the graphs with more color than chromatic number.","['graph-theory', 'coloring', 'discrete-mathematics']"
599573,An isometrie $\varphi: S_1\to S_2$ which cannot be extended into distance-preserving map,I'm searching for an example isometrie $\varphi: S_1\to S_2$($S_i$ are regular surfaces) which cannot be extended into distance-preserving maps $F: \Bbb R^3 \to \Bbb R^3$. A reference or hint will help too. \color{gray}{No need the proof of isometrie or disability for extending.},"['examples-counterexamples', 'reference-request', 'differential-geometry']"
599589,Existence of a map $f: \mathbb{Z}\rightarrow \mathbb{Q}$,"Question is to check which option holds true : There exist a map $f: \mathbb{Z}\rightarrow \mathbb{Q}$ such that is bijective and increasing is onto and decreasing is bijective and satifies $f(n)\geq 0$ if $n\leq 0$ has uncountable image. First of all any subset of $\mathbb{Q}$ is countable so there is no point in looking for last option. Now, As both $\mathbb{Z}$ and $\mathbb{Q}$ are countable, there could be a possible bijective function.. Now, the first problem is i could not think of a bijection (I am very sure this exist) and second problem is even if i find some function will that old first or third possibilities. Please just do not give an answer but please give some hint and give some time to think about. Thank you :)",['real-analysis']
599601,Properties of a continuous map $f : \mathbb{R}^2\rightarrow \mathbb{R}$ with only finitely many zeroes,"Let  $f : \mathbb{R}^2\rightarrow \mathbb{R}$ be a continuous map such that $f(x)=0$ only for finitely many values of $x$. Which of the following is true? Either $f(x)\leq 0$ for all $x$ or $f(x)\geq 0$ for all $x$. the map $f$ is onto. the map $f$ is one one. None of the above. What I have done so far is : I would take polynomial in two variables.. This need not be like $f(x)\geq 0$ for all $x$ or $f(x)\geq 0$ for all $x$.So,first option is eliminated. The map is not one one assuming that $f$ has more than one zero. So, third option is wrong. I could not think of an example in which it is not onto.. Only examples i am getting in my mind are polynomials and they are onto.. So, I am having trouble with surjectiveness of the function. Please help me to clear this. Thank you..","['general-topology', 'continuity', 'real-analysis']"
599644,How find this matrix $A=(\sqrt{i^2+j^2})$ eigenvalue,"let the matrix 
$$A=(a_{ij})_{n\times n}$$
where
$$a_{ij}=\sqrt{i^2+j^2}$$ Question: Find the difference $sign{(A)}$ can see this define: http://en.wikipedia.org/wiki/Sylvester's_law_of_inertia My try:
consider the 
$$|\lambda I-A|=\begin{vmatrix}
\lambda-\sqrt{2}&-\sqrt{3}&\cdots&-\sqrt{1^2+n^2}\\
-\sqrt{3}&\lambda-\sqrt{8}&\cdots&-\sqrt{n^2+2^2}\\
\cdots&\cdots&\cdots\cdots\\
-\sqrt{n^2+1}&-\sqrt{n^2+2}&\cdots&\lambda-\sqrt{n^2+n^2}
\end{vmatrix}$$
and I found this determinant is not easy, maybe we can consider this characteristic polynomial.and this problem is from china hard linear algebra book problem 
Thank you","['matrices', 'quadratic-forms', 'linear-algebra']"
599648,Homotopy versus path-homotopy on punctured surface,"I have some problems with homotopies. The situation is this: Let $X$ be a surface, which is homeomorphic to a 2-Sphere with a finite number (at least 3) of points removed (equivalently, an open Annulus with a finitely many punctures). $f: X \rightarrow X$ is a homeomorphism, which is isotopic to the identity. Now, let's say we have two isotopies $\tilde{f},\tilde{g}: [0,1]\times X \rightarrow X$ of $f$ to the identity, with
$$
\tilde{f}(0,x) = \tilde{g}(0,x) = x \quad \forall x \in X,\\
\tilde{f}(1,x) = \tilde{g}(1,x) = f(x) \quad \forall x \in X.
$$ Let $x$ be a point in $X$. We can now look at two paths $\alpha, \beta : [0,1] \rightarrow X$, definded by
$$
\alpha(t) = \tilde{f}(t,x),\\
\beta(t) = \tilde{g}(t,x).
$$ The two paths have the same start- and endpoints, namely $x$ and $f(x)$. It seems to be a well-known fact (I read about it in ""Farb, Margalit - A primer on mapping class groups (p.43)""), that on this surface, the maps $\tilde{f}$ and $\tilde{g}$ are homotopic. Thus, there exists a continuous map $h:[0,1]\times [0,1] \times X \rightarrow X$, with
$$
h(0,t,x) = \tilde{f}(t,x),\\
h(1,t,x) = \tilde{g}(t,x), \quad \forall t \in [0,1], \forall x \in X.
$$ It is clear now, that $h$ gives us a free homotopy of the two paths $\alpha$ and $\beta$, by sending $(s,t) \mapsto h(s,t,x)$ but I don't see a reason, why $\alpha$ and $\beta$ should be homotopic in the usual sense of a homotopy between paths (i.e. fixing the endpoints). My problem is, that this is exactly what is claimed to be true in a paper by John Franks (page 4). Also, on the open annulus $A = (0,1) \times \mathbb{R}/ \mathbb{Z}$, this is clearly not true: Let $f$ be the identity on $A$. Then, there are two isotopies $\tilde{f}$  and $\tilde{g}$ of $f$ to itself:
$$
\tilde{f}(t,[x]) = [x + t],\\
\tilde{g}(t,[x]) = [x],
$$
where $[x]$ is an equivalence class in $\mathbb{R}/ \mathbb{Z}$. Now, $\alpha$ is a loop that winds around the hole in the center and $\beta$ is the constant loop. These two are clearly not homotopic in the sense of a path-homotopy, so the argument has to stem somehow from the number of punctures... I'm confused. Any help is much appreciated!","['surfaces', 'homotopy-theory', 'algebraic-topology', 'differential-geometry']"
599655,sum of polynoms of given property,"I have $P(x)$ a polynomial with degree $n$ ,$P(x) \ge 0$ for all $x \in$ real. I have to prove that: $f(x)=P(x)+P'(x)+P""(x)+......+P^{n}(x) \ge 0$ for all $x$. I tried different methods to solve it but I got stuck.Any suggestion or advice is welcomed.","['derivatives', 'polynomials']"
599675,Why there are $11$ non-isomorphic graphs of order $4$?,"I'm new to graph theory and I don't plan to become a serious student of graph theory either. My book suggests that there are $11$ non-isomorphic graphs of order $4$, but I can't see why. I know that the most naive approach is that I can use brute force and draw four vertices and then try to connect two vertices by an edge in such a way that I don't get isomorphic graphs in each step. But then the question is, how should I know I have counted all possibilities at the end? And when the size of the graph becomes larger, how should I know I'm not counting two isomorphic structures more than once? To be more precise, I have 5 questions about determining the number of non-isomorphic graphs with $n$ vertices: Is there an algorithmic approach for creating all non-isomorphic graphs of a certain order $n$? Does it have anything to do with graphic sequences and Havel-Hakimi algorithm or something? Is it possible to count the number of non-isomorphic graphs with $n$ vertices without actually knowing them or it's still an open problem? Is it possible to partially solve this by using group theory? How can I see that there are $11$ non-isomorphic graphs with $4$ vertices without brute force?","['graph-theory', 'algebraic-graph-theory', 'graph-isomorphism', 'combinatorics']"
599690,Hensel's lemma and roots of a polynomial mod n,"Use Hensel's lemma to find all roots of the polynomial $f(x) = x^3 + 4x + 79$ in $\mathbb Z/(125)$ . Hint: $2$ is the unique root of $f(x)$ in $\mathbb Z/(5)$ . I missed the last class of number theory which was about Hensel's lemma.. and as a result I don't know how to do this one. woudl love some help. googling Hensel's lemma hasn't been very helpful, the stuff I'm finding is a bit too verbose for me.",['number-theory']
599697,Distribuation Max - Min of Brownian motion,"I'm looking for the distribuation of $M_X(t) - m_X(t)$ of the brownian motion and not the joint distribuation.
where $m_X(t) = \min\limits_{0\leq s\leq t}X(s)$ and  $M_X(t) = \max\limits_{0\leq s\leq t}X(s)$.
Any help would be greatly appreciated.","['stochastic-processes', 'probability', 'brownian-motion']"
599698,Solve the differential equation: $\dot{x}(t)^2+x(t)=\sin(x)^2$,"I am unable to solve this nonlinear differential equation:
$$\dot{x}(t)^2+x(t)=\sin(x)^2$$
I tried with Maple without success.
Is it possible to solve it without the use of numerical methods? Thanks.",['ordinary-differential-equations']
599706,Why isn't there a fixed procedure to find the integral of a function? [duplicate],"This question already has answers here : Why is integration so much harder than differentiation? (6 answers) Closed 10 years ago . Since the integration of a function is the opposite of a the derivative of a function, and there are clear steps to follow when we want to find the derivative of a function, I thought there would be clear steps to follow too when we want to find the integral of a function. What is it about finding the integration of a function that makes it impossible to come up with a guaranteed method to find it? Edit:
I am only considering elementary functions.","['calculus', 'integration', 'soft-question']"
599747,How to prove that $\sum_{n=1}^{\infty}\frac{a_{n}}{1+a_{n}}$ converges absolutely,"If $\sum_{n=1}^{\infty}a_{n}$ converges absolutely, show that
$$\sum_{n=1}^{\infty}\dfrac{a_{n}}{1+a_{n}}$$ converges absolutely. My try: since $\sum_{n=1}^{\infty}a_{n}$ converges absolutely, then
$$\sum_{n=1}^{\infty}|a_{n}|$$ converges, then there exsit $M>0$, such
$$\sum_{n=1}^{N}|a_{n}|<M$$ then, how to prove than
$$\sum_{n=1}^{N}\dfrac{|a_{n}|}{|1+a_{n}|}<cM?$$
where $c$ is a constant?","['sequences-and-series', 'analysis']"
599769,Independent Events- Indicator Functions,I can't seem to prove that two events are independent iff their indicator functions are independent discrete random variables. I was hoping to see a proof of this as I cant seem to find a proof in any of my notes nor online. Thanks,['probability']
