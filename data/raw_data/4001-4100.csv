question_id,title,body,tags
29005,Minimal Polynomial of $i + \sqrt{2}$ in $\mathbb{Q}$,"I am trying to find Minimal Polynomial of $i + \sqrt{2}$ in $\mathbb{Q}$.   I was able to determine the minimal polynomial is fourth degree with roots at  $i-\sqrt{2}$, $i+\sqrt{2}$,$-i-\sqrt{2}$,$-i+\sqrt{2}$.   However I got this answer by guessing at what the roots should be.   Is there a general technique for this type of problem.","['minimal-polynomials', 'abstract-algebra', 'field-theory']"
29010,Combinatorics question: Show divisibility,"Let $a\geq2$, $b\geq2$ be two prime numbers and k be a natural number with $k\leq min(a,b)$. How can one show that $z := \binom{a+b}{k} - \binom{a}{k} - \binom{b}{k}$ is divisible by the product $ab$?","['prime-numbers', 'binomial-coefficients', 'combinatorics']"
29023,Values of $\sum_{n=0}^\infty x^n$ and $\sum_{n=0}^N x^n$,"Why does the following hold: \begin{equation*}
\displaystyle \sum\limits_{n=0}^{\infty} 0.7^n=\frac{1}{1-0.7} = 10/3\quad ?
\end{equation*} Can we generalize the above to $\displaystyle \sum_{n=0}^{\infty} x^n = \frac{1}{1-x}$ ? Are there some values of $x$ for which the above formula is invalid? What about if we take only a finite number of terms? Is there a simpler formula? $\displaystyle \sum_{n=0}^{N} x^n$ Is there a name for such a sequence? This is being repurposed in an effort to cut down on duplicates, see here: Coping with abstract duplicate questions. and here: List of abstract duplicates .","['sequences-and-series', 'algebra-precalculus', 'geometric-progressions', 'faq', 'summation']"
29037,Third point of a triangle from only two points and all three edge lengths,"I want a triangle composed of points A, B and C in Cartesian 3D space. I currently know the positions of points A and B, but I need point C. I have the line segment AB, and thus its magnitude. I have only the magnitudes of line segments AC and BC. From this data, how do I derive point C? Please explain your logic. Thank you for your help.",['geometry']
29048,What are the 2125922464947725402112000 symmetries of a Rubik's Cube?,"In a recent talk , Marcus du Sautoy says there are 2125922464947725402112000 (2.1*10^24) symmetries of a Rubik's cube, but doesn't explicitly identify what qualifies as a symmetry. What counts as a symmetry of the Rubik's cube?  Is it a thing like, ""turn the top face once clockwise, then once counterclockwise""? How are these symmetries counted?","['rubiks-cube', 'recreational-mathematics', 'group-theory']"
29050,Is there a geometric interpretation of the exponential function of real numbers?,"I can visualize the exponential function with the graph $y = e^x$, but I can do that for almost any function. In addition to its graph, the function $f(x) = x^n$ can be visualized as the volume of a box with sides of length $x$ in n-dimensional space, and the trigonometric functions can be interpreted as side lengths of certain right triangles. Is there a similar geometric interpretation of the exponential function?","['geometry', 'visualization', 'real-analysis']"
29066,$\operatorname{tr}(AABABB) = \operatorname{tr}(AABBAB)$ for $2×2$ matrices,"Similar to a previous question here , I wonder if cyclic permutations are the only relations amongst traces of (non-commutative) monomials.  Since the evaluations $\operatorname{tr}:k\langle x,y,\dots \rangle \to k$ take an infinite dimensional vector space to a one-dimensional vector space there must be quite a few relations, but I wonder if any of them are on binomials other than the cyclic permutations. At any rate, for small dimensions, we probably get some extra relations. It appears that $\operatorname{tr}(AABABB−AABBAB) = 0$ for all $2×2$ matrices.  Is this true?  How does one prove it?","['trace', 'matrices', 'linear-algebra']"
29072,How is the column space of a matrix A orthogonal to its nullspace?,How do you show that the column space of a matrix A is orthogonal to its nullspace?,['matrices']
29080,An expression that vanishes over every field,"In this question , Jack Schmidt asks to prove a certain identity for $2\times 2$ matrices A and B. In fact he asks to show that tr(AABABB−AABBAB) = 0. In an answer by user7406, he shows that 3 times this expression must be 0, solving the problem at least when the characteristic of the ground field isn't 3.
In a comment by Mariano Suárez-Alvarez he tells us a computercalculation show that it is in fact identically zero. This made me wonder whether or not this is a surprise. I think the proper way to state the problem is as follows: Let $\varphi \colon \mathbb Z\langle x_1,\dots x_n\rangle\to \mathbb Q [x_1,\dots,x_n]$ be the morphism from the free non-commutative ring over these variables to the polynomialring. Let $\Phi \colon \mathbb Z\langle x_1,\dots,x_n\rangle \to k[x_1,\dots,x_n]$ be the corresponding morphism by sending every element to 'itself' the ususal way. Here are my questions: Is it true that if $\varphi(x)=0$ then $\Phi(x) = 0$? My guess is it is because one can construct $\psi$ such that $\Phi = \psi\circ \varphi$. Does this indeed settle the original problem for characteristic 3 from the solution by user7406, thereby bypassing von Neumann or am I really missing something? [I first asked this question in a comment to the post by user7406, but I deleted that because I didn't want to hijack the other question.]",['abstract-algebra']
29089,How to show the uniqueness of splitting fields?,"When one defines the splitting field for an arbitrary collection of polynomials, how does one show the uniqueness of such a splitting field? (I'm guessing it is still unique.) The induction argument used for the case of a single polynomial obviously doesn't work. I'm not so keen on using transfinite induction, either. I thought of direct limit approach but since the isomorphism between splitting fields of a single polynomial is not canonical, it doesn't seem to work either.","['splitting-field', 'abstract-algebra', 'field-theory']"
29090,Conditional Expectation,"I'm having trouble establishing this identity below. Suppose $Y$ and $Z$ are random variables on $(\Omega,F,P)$ and $Y \in L^1$. Suppose $Z$ is bounded and let $G \subset F$ be a sub-$\sigma$-field. Show that $$\mathbb{E}(\mathbb{E}(Y|G)Z)=\mathbb{E}(\mathbb{E}(Z|G)Y).$$ Is there a way I can attack it using the Cauchy-Schwarz inequality: $$\mathbb{E}(XY|G)^2 \leq \mathbb{E}(X^2|G)\mathbb{E}(Y^2|G)?$$ 
    Any help would be appreciated.","['probability-theory', 'probability']"
29097,how to solve this nonlinear partial differential equation?,"How to solve this nonlinear partial differential equation?
$$\displaystyle\frac{\partial^2}{\partial x^2} f(x,t) +b \frac{\partial^2}{\partial x^2} f(x,t) \cdot \frac{\partial^2}{\partial t^2} f(x,t) + a = 0,$$
where $a,b$ are constant.",['ordinary-differential-equations']
29100,small o(1) notation,"It's probably a vey silly question, but I'm confused. Does o(1) simply mean $\lim_{n \to \infty} \frac{f(n)}{\epsilon}=0$ for some $n>N$?","['limits', 'analysis']"
29107,After Whitney embedding,Let $M$ be a $d$-dimensional compact manifold and $f:M\to M$ be a diffeomorphism on $M$. Whitney embedding theorem says that we can embed $M$ into $\mathbb{R}^{2d+1}$. Let $T$ be a tubular neighborhood of $M$ with respect to the embedding. In some papers they say that there exists a diffeomorphism $F:T\to F(T)\Subset T$ with $F|_M=f$. Is there a theorem about this? Any reference will be great!,"['manifolds', 'differential-geometry']"
29108,How to prove the following inequalities?,"Thanks for your time. I am interested in various ways/techniques/tricks/methods (induction, convexity, concavity, maximum, minimum, geometry, trigonometry, ...) for proving the  inequalities and their generalizations (1) $\sqrt{1-x_1^2 -y_1^2}  + \sqrt{1-x_2^2 -y_2^2} + \sqrt{1-x_3^2 -y_3^2}  \le 3\,\sqrt{1-\left(\frac{x_1+x_2+x_3}{3}\right)^2 - \left(\frac{y_1+y_2+y_3}{3}\right)^2} $ I think for $0 \le x_1,y_1,z_1 \le 1$ (2) $\sqrt{x_1^2 + y_1^2} + \sqrt{x_2^2 + y_2^2} + \sqrt{x_3^2 + y_3^2} \ge 3 \sqrt{\left(\frac{x_1+x_2+x_3}{3}\right)^2 + \left(\frac{y_1+y_2+y_3}{3}\right)^2}$ for all $x_1,y_1,z_1$","['geometry', 'inequality', 'calculus', 'trigonometry', 'soft-question']"
29125,What is a Structured Polyhedron?,"In my work on lattice point enumeration of polytopes, I stumbled upon the following sequence:
\begin{eqnarray}
1, 120, 579, 1600, 3405, 6216, 10255, 15744, 22905, 31960, 43131, ...
\end{eqnarray}
which counts the Structured great rhombicosidodecahedral numbers (A100145) by the formula 
\begin{eqnarray}
a(n)=\tfrac{1}{6} (222 n^3-312 n^2+96 n).
\end{eqnarray}
Such numbers fall into the category of figurate numbers , which count the number of points in a sequence of similar discrete geometric shapes. For example, the triangular and square numbers bear their names because they count the dots arranged in a sequence of triangular $(1,3,6,10,...)$ and square $(1,4,9,16,...)$ configurations. One generalizes these to higher dimensional regular polyhedral numbers like tetrahedral (A000292) or dodecahedral (A006566) numbers, for instance. These numbers are always enumerated by $\mathbb{Q}$-polynomials of degree $n$, where $n$ is the dimension of the polyhedron. For the sequence above, the author gives the following description: Structured polyhedral numbers are a type of figurate polyhedral numbers. Structurate polyhedra differ from regular figurate polyhedra by having appropriate figurate polygonal faces at any iteration, i.e. a regular truncated octahedron, n=2, would have 7 points on its hexagonal faces, whereas a structured truncated octahedron, n=2, would have 6 points - just as a hexagon, n=2, would have. Like regular figurate polygons, structured polyhedra seem to originate at a vertex and since many polyhedra have different vertices (a pentagonal diamond has 2 ""polar"" vertices with 5 adjacent vertices and 5 ""equatorial"" vertices with 4 adjacent vertices), these polyhedra have multiple structured number sequences, dependent on the ""vertex structures"" which are each equal to the one vertex itself plus its adjacent vertices. For polystructurate polyhedra the notation, structured polyhedra (vertex structure x) is used to differentiate between alternate vertices, where VS stands for vertex structure. At first read, this doesn't make any sense. I thought the regular truncated octahedron had 6 vertices at each hexagonal face, not 7 as the author claims. (I know that this sequence isn't bogus because I can generate it in a completely different context, that of computing the cohomology and geometric genera in a singularity theory problem.) Can anyone make sense of this and help me understand the difference between regular and structured polyhedra? Update (4-1-11): I emailed the author of the entry on OEIS and never heard back from him. I think the responsibility now lies with us to figure this out.","['geometry', 'combinatorics', 'number-theory']"
29128,Why determinant of a 2 by 2 matrix is the area of a parallelogram?,"Let $A=\begin{bmatrix}a & b\\ c & d\end{bmatrix}$. How could we show that $ad-bc$ is the area of a parallelogram with vertices $(0, 0),\ (a, b),\ (c, d),\ (a+b, c+d)$? Are the areas of the following parallelograms the same? $(1)$ parallelogram with vertices $(0, 0),\ (a, b),\ (c, d),\ (a+c, b+d)$. $(2)$ parallelogram with vertices $(0, 0),\ (a, c),\ (b, d),\ (a+b, c+d)$. $(3)$ parallelogram with vertices $(0, 0),\ (a, b),\ (c, d),\ (a+d, b+c)$. $(4)$ parallelogram with vertices $(0, 0),\ (a, c),\ (b, d),\ (a+d, b+c)$. Thank you very much.","['matrices', 'linear-algebra', 'area', 'determinant']"
29133,Why is $\tan$ so different from $\sin$ & $\cos$?,"I'm just curious, considering how similar the graphs of the sine & cosine functions are in shape, why is the shape of the tangent's graph so different, despite being used in very similar types of problem? Thanks!",['trigonometry']
29140,Adjoint of a linear transformation in an infinite dimension inner product space,"We learned that if $V$ is a finite inner product space then for every linear transformation $T:V\to V$, there exists a unique linear transformation $T^*:V\to V$ such that $\forall u, v \in V: (Tv, u)=(v, T^*u)$. The construction of $T^*$ used the fact that $V$ is finite and therefore has an orthonormal basis, which is not the case had it been infinite. Are there infinite dimension inner product spaces such that not all linear transformations have an adjoint? Or is it somehow possible to extend this definition to infinite spaces as well?",['linear-algebra']
29157,How do I convert the distance between two lat/long points into feet/meters?,"I've been reading around the net and everything I find is really confusing. I just need a formula that will get me 95% there. I have a tool that outputs the distance between two lat/long points. Point 1: 32.773178, -79.920094
Point 2: 32.781666666666666, -79.916666666666671
Distance: 0.0091526545913161624 I would like a fairly simple formula for converting the distance to feet and meters. Thanks!","['geometry', 'transformation', 'mathematica']"
29158,How to prove that $f(A)$ is invertible iff $f$ is relatively prime with the minimal polynomial of $A$?,"Let $A$ be a matrix from $\mathbb{M}_{n \times n}(F)$ and $f(x) \in F[x]$. How does one prove the following: $f(A)$ is invertible iff $\gcd(Ma,f)=1$ where $Ma$ is the minimal polynomial of $A$. Thanks.",['linear-algebra']
29160,What am I misunderstanding with this simple Trigonometry question?,Simplify: $\sin^4x + \sin^2x \cdot \cos^2x$ The textbook states the answer as $\sin^2x$ and I understand the reasoning: Take a factor of $\sin^2x$ out and you are left with $\sin^2x \cdot 1$ However I can't work out why my method is wrong (it produces the answer of 1): Divide everything by $\sin^2x$ $(\sin^4x  / \sin^2x)+ (\sin^2x  \cdot \cos^2x )/ \sin^2x$ Which cancels down to: $\sin^2x + \cos^2x$ Which equals $1$. I managed to get both results when using WolframAlpha to check my working! What am I misunderstanding? Thanks!,['trigonometry']
29163,Integral $\int{\sqrt{25 - x^2}dx}$,"I'm trying to find $\int{\sqrt{25 - x^2} dx}$ Now I know that $\int{\frac{dx}{\sqrt{25 - x^2}}}$ would have been $\arcsin{\frac{x}{5}} + C$, but this integral I'm asking about has the rooted term in the numerator. What are some techniques to evaluate this indefinite integral?","['calculus', 'integration']"
29164,Determine if a function is increasing/decreasing at a particular point,"I'm getting better at using trig functions, but this problem has me up against a wall. As I understand it, to find if a function is increasing or decreasing over a given interval, select a number inside that interval and if the result is greater or less than zero, the interval is increasing and decreasing, respectively. Given $f(x)=5x+10 \sin x$ on the interval $(0, 2\pi)$, find the open intervals where the function is increasing or decreasing. The given intervals are $(0, \frac{2\pi}{3}), (\frac{2\pi}{3}, \frac{4\pi}{3}), (\frac{4\pi}{3}, 2\pi).$ On the first interval, I selected $\frac{\pi}{2}$ as the test for x.  Thus $$f(x)= 5x+10 \sin x \Rightarrow 5(\frac{\pi}{2}) + 10 \sin(\frac{\pi}{2})\Rightarrow \frac{5\pi}{2}+10$$ $\frac{5\pi}{2}+10 > 0$, so the function should be increasing at that point The second interval test variable was $\pi$, and thus $5(\pi)+10 \sin(\pi)= 5\pi > 0$ So the interval of $(\frac{2\pi}{3}, \frac{4\pi}{3})$ should be increasing. The third interval test variable was $\frac{3\pi}{2}$, and $5(\frac{3\pi}{2})+10 \sin(\frac{3\pi}{2})= \frac{15\pi}{2}-10 > 0$, so that interval is increasing as well. However, the WebAssign site didn't accept those answers.  What is missing with my logic and work?","['calculus', 'functions']"
29175,Why is the rank of the Picard group of a K3 surface bounded above by 22?,"I understand that, over $\mathbb{C}$, the rank of the Picard group of a K3 surface $X$ is bounded above by $20$ because we can use the exponential sheaf sequence:
$0 \to 2\pi i \mathbb{Z} \to \mathcal{O}_X \to \mathcal{O}_X^\times \to 0$,
and because $H^1(X,\mathcal{O}_X)$ is trivial this gives an injective homomorphism $H^1(X,\mathcal{O}_X^\times) \to H^2(X,\mathbb{Z})$, and $H^2(X,\mathbb{Z})$ has rank $22$. Then, by the Lefschetz Theorem on $(1,1)$-classes, this actually embeds into $H^{1,1}(X)$, which has rank $20$ (all of these follow straight away from the definition of a K3 surface). I know that over finite fields for instance we don't have such arguments, and the rank can be $22$. Question: What's the proper way of stating this argument in good generality, i.e. without assuming anything about the basefield. Presumably this would involve talking about algebraic cycles. Also, why can't the rank be $21$?","['algebraic-geometry', 'k3-surfaces']"
29181,How to find closed form for a partial infinite product?,"I ran across this infinite product: $$\lim_{n\to\infty}\prod_{k=2}^n\left(1-\frac1{\binom{k+1}{2}}\right)$$ I easily found that it converges to 1/3. Using my calculator, I found that $$1-\frac1{\binom{k+1}{2}}=\frac{(k-1)(k+2)}{k(k+1)}$$ Then, here is my question $$\prod_{k=2}^n\frac{(k-1)(k+2)}{k(k+1)}=\frac{n+2}{3n}$$ This is what my calculator gave me. How did it arrive at this? That is, how could I do this by hand if I wanted to? I tried writing out some terms and even the (n+1)st term, made cancellations, but it did not work out. I feel rather obtuse. How does one find a closed form for a partial infinite product like this? $$\frac23\cdot \frac56\cdot \frac9{10}\cdot\cdot\cdot \frac{(n-1)(n+2)}{n(n+1)}\cdot \frac{n(n+3)}{(n+1)(n+2)}$$ Making the cancellations leaves $\frac{(n-1)(n+3)}{(n+1)^2}$, not $\frac{n+2}{3n}=\frac2{3n}+\frac13$. This is why it converges to 1/3. It is easy to see the limit. That is not my concern. It is how does one arrive at the closed form of $\frac{n+2}{3n}$ for this 'finite' product? I am overlooking something obvious. I just know it. Thank you",['sequences-and-series']
29186,Uniform convergence problem,"I encountered this problem while studying for an analysis exam. Here is a related question I asked some days ago. The problem is as follows: Suppose $a_n$ is a decreasing sequence of positive real numbers and that$$\sum_{n = 0}^{\infty}{a_n \sin{(nx)}}$$ converges uniformly on $\mathbb{R}$, show that $$\lim_{n \to \infty}{(n a_n)} = 0.$$
Any tip or solution is welcome, and also avoid using Fourier series, because they haven't been introduced in the book so it can be solved without using them.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
29192,Closed form for a sum involving binomial coefficients: $\sum\limits_{s=0}^{k} \binom{n}{s} \binom{s}{k-s}$,"Let $n,k$ be positive integers. Is there a closed form of the sum $$\sum_{s=0}^{k} \binom{n}{s} \binom{s}{k-s}\text{?}$$ By that I mean a representation which is free of sums and hypergeometric functions or alike. Combinatoric interpretation: This is the number of possibilities to distribute $k$ balls in $n$ urns, where each urn has at most $2$ balls.","['summation', 'balls-in-bins', 'binomial-coefficients', 'combinatorics']"
29219,Find the spectrum of the linear operator $T: \ell^2 \to \ell^2$ defined by $Tx=(\theta x_{n-1} +(1-\theta)x_{n+1})_{n\in \mathbb{Z}}$,"Let $\ell^2 =\ell^2(\mathbb{Z})$. Choose $\theta \in ]0,1[$ and set: $$Tx=(\theta x_{n-1} +(1-\theta)x_{n+1})_{n\in \mathbb{Z}}$$ for each $x=(x_n)_{n\in \mathbb{Z}}\in \ell^2$ (thus $T$ is a convex combination of the right and left shift operators ). It is easy to prove that, for every $\theta$, $T$ is a bounded linear operator of $\ell^2$ into itself, that $\lVert T\rVert =1$ and that $T$ is selfadjoint iff $\theta =\ frac{1}{2}$.
Moreover $T$ is not compact: in fact, if $e^m:=(\delta_n^m)$ (so $e^m$ is a vector of the canonical base of $\ell^2$), one has: $$|Te^m -Te^p|^2=\begin{cases} 0 &\text{, if } p=m \\ \theta^2 +(1-\theta)^2+1 &\text{, if } m=p+2 \text{ or } p=m+2 \\ 2\theta^2+2(1-\theta)^2 &\text{, otherwise} \end{cases} \; ,$$ thus $|Te^m-Te^p|^2> \theta^2+(1-\theta)^2>0$ for $m\neq p$; therefore the sequence $\{ Te^m\}_{m\in \mathbb{N}}$ does not contain any Cauchy's subsequence. The problem is: I am not able to find the spectrum of $T$. About the eigenvalues, the only thing I know for sure is that $1$ is not in the point spectrum of $T$ for any value of $\theta$: in fact if $1$ were in the point spectrum $\sigma_P(T)$, then the eigenvectors would satisfy the linear recurrence: $$x_n=\theta x_{n-1}+(1-\theta) x_{n+1} \; ,$$ hence they have to be sequences of the type: $$x_n=A \left( \frac{\theta}{1-\theta}\right)^n +B$$ ($A,B$ suitable constants); but a sequence like this doesn't belong to $\ell^2$ except in the trivial case $A=B=0$, which however doesn't give a valid eigenvector. Therefore $1\notin \sigma_P(T)$. But now, what about other eigenvalues? And what about the residue and continuous spectra of $T$? Any hint is welcome.","['operator-theory', 'spectral-theory', 'functional-analysis']"
29220,"Chebyshev's inequality, variance and mean","I am trying to implement a solution (working code) for the 4.1 paragraph in this paper . The problem: We have words with lengths for instance: 
$l_1$ = 1, $l_2$ = 2, $l_3$ = 3, $l_4$ = 8 and $l_5$ = 7. These words will be part of the white-list. We calculate the sample mean and the variance of the lengths of these words. $\mu = \frac{1}{N}\sum_{i = 1}^N X_i$ So, $\mu = 4.2$ in our case. Next step is to calculate the variance. $\sigma^2 = \frac{1}{N}\sum_{i = 1}^N (X_i - \mu)^2$ So, $\sigma^2 = 7.76$ After all calculations are done we get another list of words and the goal of the algorithm is to assess the anomaly of a string with length l , by calculating the ''distance'' of the length l from the mean $\mu$ of value l of the length distribution. This distance is expressed with the help of the Chebyshev inequality. $p(\mid x-\mu \mid > t) < \frac{\mu^2}{t^2}$ When l is far away from $\mu$, considering the variance of the length distribution, then the probability of any (legitimate) string x having a greater length than l should be small. 
Thus, to obtain a quantitative measure of the distance between a string of length l and the mean $\mu$ of the length distribution, we substitute t with the difference between $\mu$ and l . $p(\mid x-\mu \mid > \mid l-\mu \mid) < p(l)=\frac{\sigma^2}{(l-\mu)^2}$ Having the information above, if I run it with the next numbers: 1, 5, 10. I get these probabilities: p(1) =0.757 p(5) =12.125 p(10) =0.230 Which I don't understand why some probabilities I get are bigger than 1, they are not supposed to be bigger than 1. I am trying to understand if the formulas described above are correct or maybe I am using them wrong. Thank you.","['statistics', 'calculus']"
29222,Finding maxima and minima of a function,"A couple problems are giving me trouble in finding the relative maxima/minima of the function.  I think the problem stems from me possibly not finding all of the critical numbers of the function, but I don't see what I missed. Given $f(x)= 5x + 10 \sin x$, I calculated the derivative as $5 + 10 \cos x$, and found the first critical number by this work: $$5+ 10 \cos x=0$$
$$\frac{5}{5}+10 \cos x= 0-5 \Rightarrow 10 \cos x= -5$$
$$\frac{10 \cos x}{10}= \frac{-5}{10}\Rightarrow \cos x= -\frac{1}{2}$$
$$x= \arccos(-\frac{1}{2}) = \text{First critical number is }\frac{2\pi}{3}$$ That gave me the maxima of the formula, since $$f(\frac{2\pi}{3})= 5(\frac{2\pi}{3})+10 \sin(\frac{2\pi}{3})= \frac{10\pi}{3}+5\sqrt3$$ However, I need the other critical number to calculate the minima.  Should I look for the value of $\arccos(\frac{1}{2})$?",['calculus']
29229,The real part treated like an angle in complex vector spaces,"In my current lecture I regularly encounter usage of the real part of, say, a scalar product of two vectors similar to angles in classical geometry. For example in Hilbert space theory: Let $H$ be a Hilbert space, $C \subset H$ be convex and closed. For $x_0 \in H$, $x \in C$ is the best approximation of $x_0$ by $C$, iff
$\forall y \in C : Re \langle x - x_0, y - x_0 \rangle \leq 0$ As much as it is intuitive (and the proof itself is no problem), I do not know how to interpret this. So the question (not necessarily connected to the above example theorem) is Is there any useful interpretation to the real part of a scalar product in complex vector spaces? if there is none, in best case the real part is just used for convinience, and the author of my book wants to grasp a more general concept. - in worst case, not such interpretation exists.","['vector-spaces', 'complex-numbers', 'functional-analysis']"
29231,"Arbitrary intersection of closed, connected subsets of a compact space connected?","Let $(B_i)_{i\in I}$ be an indexed family of closed, connected sets in a compact space X. Suppose $I$ is ordered, sucht that $i < j \implies B_i \supset B_j$. Is $B = \bigcap_i B_i$ necessarily connected? I can prove it, if I assume $X$ to be Hausdorff as well: If $B$ is not connected, then there are two disjoint, closed, nonempty sets $C$, $D$ in $B$, such that $C \cup D = B$. Now these sets are also closed in $X$, hence by normality there exist open disjoint neighborhoods $U$, $V$ of $C$ and $D$, respectively. Then for all $i$: $B_i \cap U^c \cap V^c \ne \emptyset$, since $B$ is contained in $B_i$ and $B_i$ is connected. Thus we must also have $$ B \cap U^c \cap V^c = \bigcap_i B_i \cap U^c \cap V^c \ne \emptyset $$ by compactness and the fact that the $B_i$ satisfy the finite intersection property. This is a contradiction to the choice of $U$ and $V$. I can neither see a counterexample for the general case, nor a proof. Any hints would be greatly appreciated! Thanks, S. L.",['general-topology']
29233,Intuitive meaning of Limit Supremum?,"I am trying to understand the difference between the following two equations: $$\bar{P} = \limsup_{t \to \infty}\frac{1}{t} \sum_{\tau = 0}^{t-1}E\{P[\tau]\} < \infty$$
and 
$$\bar{P} = \lim_{t \to \infty}\frac{1}{t} \sum_{\tau = 0}^{t-1}E\{P[\tau]\} < \infty$$ where $\bar{P}$ denotes the average value of P and E stands for expectation. I have previously come across equations like the second one but I am not able to understand when to use equations of the first type. I have read the definition on Wikipedia's Supremum page but I am failing to understand the intuitive meaning of when to use what. The wiki defines it as: A set A of real numbers (shown as blue
  balls), a set of upper bounds of A
  (red balls), and the smallest such
  upper bound, that is, the supremum of
  A (shown as a red diamond). What does a set of upper bounds actually mean? I thought upper bound means the uppermost value but I guess my understanding is flawed. Can someone please tell me the difference between the two and give me some easy to understand example to understand the difference between a normal limit and supremum limit?","['examples-counterexamples', 'limsup-and-liminf', 'reference-request', 'real-analysis', 'limits']"
29234,Tall fraction puzzle,"I was given this problem 30 years ago by a coworker, posted it 15 years ago to rec.puzzles, and got a solution from Barry Wolk, but have never seen it again.  Consider the series: $$1, \frac{1}{2},\frac{\displaystyle\frac{1}{2}}{\displaystyle\frac{3}{4}},\frac{\displaystyle\frac{\displaystyle\frac{1}{2}}{\displaystyle\frac{3}{4}}}{\displaystyle\frac{\displaystyle\frac{5}{6}}{\displaystyle\frac{7}{8}}},\cdots$$ Each fraction keeps its large bars while being put atop a similar structure. This can also be represented as $$\frac{1\cdot 4 \cdot 6 \cdot 7 \cdot\cdots}{2 \cdot 3 \cdot 5 \cdot 8 \cdot\cdots}$$ terminating at $2^n$ for some $n$, where it is much closer to the limit than elsewhere. The challenge: Find the limit, not too hard by experiment In the last expression, find a simple, nonrecursive, expression to say whether $n$ is in the numerator or denominator Prove the limit is correct-this is the hard one.","['puzzle', 'sequences-and-series']"
29236,component and dimension in Gaussian mixture model,"What is the relation between a dimension and a component in a Gaussian Mixture Model? And what is the meaning of dimension and component? Thank you. Please correct me if I'm wrong: my understanding is the observed data have many dimensions. Each dimension represents a feature/aspect of the collected data and has its own Gaussian distribution. I don't know where ""component"" fits into this picture and what it means.","['statistics', 'probability-distributions', 'terminology']"
29242,Probability that a quadratic polynomial with random coefficients has real roots,"The following is a homework question for which I am asking guidance. Let $A$, $B$, $C$ be independent random variables uniformly distributed between $(0,1)$. What is the probability that the polynomial $Ax^2 + Bx + C$ has real roots? That means I need $P(B^2 -4AC \geq 0$). I've tried calling $X=B^2 -4AC$ and finding $1-F_X(0)$, where $F$ is the cumulative distribution function. I have two problems with this approach. First, I'm having trouble determining the product of two uniform random variables. We haven't been taught anything like this in class, and couldn't find anything like it on Sheldon Ross' Introduction to Probability Models. Second, this strategy just seems wrong , because it involves so many steps and subjects we haven't seen in class. Even if I calculate the product of $A$ and $C$, I'll still have to square $B$, multiply $AC$ by four and then subtract those results. It's too much for a homework question. I'm hoping there might be an easier way.","['quadratics', 'probability', 'polynomials']"
29255,Why are the empty set and the set of all real numbers both open and closed?,sorry! am not clear with these questions why an empty set is open as well as closed? why the set of all real numbers is open as well as closed?,"['general-topology', 'real-numbers']"
29262,"Closed forms of sums $f(a)+f(a+d)+\cdots+f(a+nd)$ with $f$ sine, cosine or tangent","is/are there a closed form for $\sin{(a)}+\sin{(a+d)}+\cdots+\sin{(a+n\,d)}$ $\cos{(a)}+\cos{(a+d)}+\cdots+\cos{(a+n\,d)}$ $\tan{(a)}+\tan{(a+d)}+\cdots+\tan{(a+n\,d)}$ $\sin{(a)}+\sin{(a^2)}+\cdots+\sin{(a^n)}$ $\sin{(\frac{1}{a})}+\sin{(\frac{1}{a+d})}+\cdots+\sin{(\frac{1}{a+n\,d})}$","['sequences-and-series', 'closed-form', 'trigonometry', 'calculus']"
29264,Torsion in free products of groups,"While reading a paper about the modular group $\Gamma = PSL_{2}(\mathbb{Z})$, I read that  $PSL_{2}(\mathbb{Z}) \cong C_{2} * C_{3}$ and consequently, all the torsion elements in $\Gamma$ are of order 2 or 3. While I understand the isomorphism, I don't know how to prove the second statement. More in general, is it true that if $G \cong C_{n_{1}} * \ldots * C_{n_{k}}$, then all torsion elements in $G$ have order $n_{1}, \ldots, n_{k}$ ?",['group-theory']
29276,Why do 4 circles cover the surface of a sphere?,Is there a geometric explanation for why a sphere has surface area $4 \pi r^2$ ? Ie equal to 4 times its cross-section (a circle of radius r).,"['geometry', 'intuition']"
29279,"Why is the orthogonal group $\operatorname{O}(2n,\mathbb R)$ not the direct product of $\operatorname{SO}(2n, \mathbb R)$ and $\mathbb Z_2$?","We know that when $n$ is odd, $\operatorname{O}_n(\mathbb R) \simeq \operatorname{SO}_n (\mathbb R) \times \mathbb Z_2$. However, this seems not true when $n$ is even . But I have no idea how to prove something is not a direct product. I have tried to verify some basic properties of direct product. For example, $\operatorname{SO}_n(\mathbb R)$ is a normal subgroup of $\operatorname{O}_n(\mathbb R)$, whenever $n$ is odd or even. But they are not helpful. So, is this statement true and how to prove it? Thank you!","['orthogonal-matrices', 'linear-algebra', 'group-theory', 'abstract-algebra']"
29297,Solvable group of order $pqr^2$,"$|G|=pqr^2$ where $3\leq p<q<r$ prime.  Show that if $r>\frac{1}{2}(pq-1)$ then $G$ is solvable. I took $H\leq G$ $r$-sylow subgroup of $G$, there is a theorem claiming that there exists a homomorphism from $G$ to $S_{pq}$ ($pq$ is the index of $H$). If the homomorphism is injective then $G$ is a subgroup of $S_{pq}$, that means $pqr^2|(pq)!$ so $r^2|(pq-1)!$ but we know $r^2>2r>pq-1$ from what follows that the homomorphism can't be injective, that means there is a non trivial kernel which is a maximal subgroup of $H$ and a normal subgroup of $G$, it can be of order $r$ or $r^2$, lets name it K. If $|K|=r^2$ then the sequence $\{e\}\triangleleft K\triangleleft G$ has a factor of order $r^2$ which is abelian as a square of a prime and a factor of order $pq$. The other option is $|K|=r$, then the factors are of order: $r$ and $pqr$. I am a bit stuck from here.","['group-theory', 'abstract-algebra']"
29299,Characteristic function of the normal distribution,"The standard normal distribution
$$f(x) = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}},$$
has the characteristic function
$$\int_{-\infty}^\infty f(x) e^{itx} dx = e^{-\frac{t^2}{2}}$$
and this can be proved by obtaining the moments. However, is there a more direct method of proving that the standard normal has the stated characteristic function?  I got stuck on trying to show that $$\int_{-\infty}^\infty e^{-\frac{1}{2}(x-it)^2} dx= \sqrt{2\pi}.$$","['statistics', 'normal-distribution', 'improper-integrals', 'fourier-analysis']"
29312,de Rham cohomology generators of 2-torus,"How I can compute explicitly a set of differential forms generating the de Rham cohomology of a 2-torus of revolution in $\mathbb{R}^3$ ?
A 2-torus is embedded in $\mathbb{R}^3$ by
$\psi(u,v):=\left(x(u,v),y(u,v),z(u,n)\right),$ where 
$x(u, v) =  (R + r \cos{v}) \cos{u},y(u, v) =  (R + r \cos{v}) \sin{u} , z(u, v) =  r \sin{v}$ and $ u,v\in [0,\pi).$","['algebraic-topology', 'differential-geometry']"
29338,Sum of cosines of primes,"Let $p_n$ be the nth prime number, $p_1=2,p_2=3,p_3=5,\ldots$ How to prove this series converges/diverges? $$\sum_{n=1}^\infty \cos{p_n}$$","['prime-numbers', 'convergence-divergence', 'sequences-and-series']"
29354,what are the uses of this identity,"Consider this wonderful ( think it is) identity 
$$\begin{align*}
&a+b(1+a) + c(1+a)(1+b) + d(1+a)(1+b)(1+c)
+\cdots+l(1+a)(1+b)\cdots(1+k)\\ 
&\qquad= 
 (1+a)(1+b)(1+c)\cdots(1+l)-1
\end{align*}
$$ I believe there must be some beautiful applications, for example deriving some other identities, of it. Can someone please explore these possibilities?","['algebra-precalculus', 'soft-question']"
29362,Showing that matrix is invertible using eigenvalues,Let $A$ be matrix from the  vector space of square $N \times N$ matrices. With the inital information: $A^2-4A=4I$. How does one show that $A+I$ is invertible? (I need please a solution that involves eigenvalues) Thank you,['linear-algebra']
29371,How to prove that eigenvectors from different eigenvalues are linearly independent [duplicate],"This question already has answers here : Finite sum of eigenspaces (with distinct eigenvalues) is a direct sum (3 answers) Closed 2 years ago . How can I prove that if I have $n$ eigenvectors from different eigenvalues, they are all linearly independent?","['linear-algebra', 'eigenvalues-eigenvectors']"
29377,"The value of improper integral $x\exp(-\lambda x^2)\, dx$","The integral in question is $\int_{-\infty}^{+\infty} x {e}^{-\lambda x^2}dx$ where $x$ and $\lambda$ both are real numbers. My solution: $\int_{-\infty}^{+\infty} x {e}^{-\lambda x^2}dx = \int_{-\infty}^{0} x {e}^{-\lambda x^2}dx +\int_{0}^{+\infty} x {e}^{-\lambda x^2}dx =$ $\lim_{a\rightarrow -\infty}\int_{a}^{0} x {e}^{-\lambda x^2}dx +\lim_{b\rightarrow +\infty}\int_{0}^{b} x {e}^{-\lambda x^2}dx = \begin{vmatrix}
u = -\lambda x^2\\ 
du = -\lambda 2xdx\\ 
\begin{matrix}
x & 0 & a & b\\ 
u & 0 & -\lambda a^2 & -\lambda b^2
\end{matrix}
\end{vmatrix} =$ $-\frac{1}{2\lambda}\left( \lim_{a\rightarrow -\infty}\int_{-\lambda a^2}^{0} {e}^{u}du +\lim_{b\rightarrow +\infty}\int_{0}^{-\lambda b^2} {e}^{u}du \right) =$ $-\frac{1}{2\lambda}\left( \lim_{a\rightarrow -\infty}\left(1 - {e}^{-\lambda a^2} \right) +\lim_{b\rightarrow +\infty}\left({e}^{-\lambda b^2} - 1 \right) \right) = 
-\frac{1}{2\lambda}\left( \left(1 - 0 \right) +\left(0 - 1 \right) \right) = 0$ 1) Is this solution correct? 2) Suppose that real function of real argument $f\left(x\right)$ is odd and both limits of $f\left(x\right)$ as $x$ approaches $\pm\infty$ are finite values. Is it enough to say that $\int_{-\infty}^{+\infty}f\left(x\right)dx$ is equal to 0?","['improper-integrals', 'integration']"
29382,the expectation of a chocolate bar,"So my buddy claims that if I split a chocolate bar at random into two pieces, then the expected size of the larger piece is $\frac{3}{4}$ of the bar. I can't figure out how he came up with this value... Can someone explain this? If you can, can you provide some kind of a proof? p.s. it would be helpful to think of this chocolate bar as a 1D array :) UPDATE Imagine the candy bar is a world-famous chocolate bar, the ones that are broken into chunks. However, this special chocolate bar has n chunks. If we broke the chocolate bar randomly along these chunks, what would the expected size of the larger chunk be? My buddy claims it to be $\leq{\frac{3}{4}}$.",['probability']
29392,Does such a function exist? What is a good example?,"Does there exist a function $f$ such that it is continuous a.e. on a measurable subset 
$E$ $\subseteq$ $R$ (the set of real numbers), Lebesgue integrable, but not Riemann integrable? I was thinking maybe the Dirichlet function, because it is Lebesgue integrable but not Riemann integrable, but it is nowhere continuous! Any ideas?","['measure-theory', 'real-analysis']"
29400,fractional linear maps,what is the fractional linear map maps the circles $|z-5|=3$ and $|z+5|=3$ to concentric circles? What is the general method to find such maps? What is the image of $|z+2|=2$ under the map: $z \to 1/\bar{z}$? Thank you very much.,['complex-analysis']
29411,Explicit computation of a Galois group,"Let $E$ be the splitting field of $x^6-2$ over $\mathbb{Q}$. Show that $Gal(E/\mathbb{Q})\cong D_6$, the dihedral group of the regular hexagon. I've shown that $E=\mathbb{Q}(\zeta_6, \sqrt[6]{2})$, where $\zeta_6$ is a (fixed) primitive sixth root of unity, and thus that $[E:\mathbb{Q}]=12$. I'm getting a little mixed up working out the automorphisms, though. I know the Galois group is determined by the action on the generators $\zeta_6$ and $\sqrt[n]{2}$. So then the possibilities appear to be: \begin{align*}\sqrt[6]{2}&\mapsto\zeta_6^n\sqrt[6]{2}\;\;\;\mbox{ for } n=0,1,\ldots ,5 \\ \zeta_6&\mapsto \zeta_6^j\;\;\;\;\;\;\;\;\mbox{ for } j=1,5\,.\end{align*} Does this make sense? Something doesn't quite feel right, but I'm not sure where the issue might be. I know that in some sense the generators are ""independent"", because I definitely can't get one generator from the other. (For example, it'd be different if we had fourth roots of unity because we could get $\sqrt{2}$ from both generators.) Any help is appreciated","['galois-theory', 'abstract-algebra']"
29413,How to solve this equation?,"The following is an error correcting equation for a sidereal astrophotography tracking mount I'm building and $t$ represents the amount of time before the tracking is off by a quarter of a stepper motor step.  I need to solve for $t$, but I've having trouble solving this. I can plot it with a value of $n$ and find an ok approximation, but the problem is that I need it for several values of $n$. Any good ways?  $n$ is the integer number of corrections applied thus far.  If it can't be solved in a general sense, what's a good way to generate approximate solutions for a few hundred values of $n$, starting at 0? $$-0.25=\frac{\sqrt{2\cdot 150^2-2\cdot 150^2\cdot \cos(t\cdot 0.000072733)} - (t\cdot 0.0109170306+(n\cdot -0.25\cdot 0.005))}{0.005}$$","['trigonometry', 'algebra-precalculus']"
29420,How does one get the formula for this bijection from $\mathbb{N}\times\mathbb{N}$ onto $\mathbb{N}$?,"When showing that $\mathbb{N}\times\mathbb{N}$ is in bijection with $\mathbb{N}$, it seems standard to give a proof by picture that shows a way to systematically weave through all the points in $\mathbb{N}\times\mathbb{N}$ and label each one as you go. I know there is a polynomial expression for this method, given by $$
J(m,n)=[1+2+\cdots+(m+n)]+m=\frac{1}{2}[(m+n)^2+3m+n]
$$
where $m$ is the usual $x$-coordinate and $n$ the usual $y$-coordinate. But how does one ""see"" how this formula is arrived at? I know how to manipulate the middle expression to arrive at the rightmost expression, but how does the middle expression relate to the weaving pattern through $\mathbb{N}\times\mathbb{N}$? Thank you.",['elementary-set-theory']
29421,Analytic functions with nonessential singularity at infinity must be a polynomial,"This is an exercise from Alhfors Complex Analysis book- to show that an analytic function with a nonessential singularity at infinity must be a polynomial.
It seems like it should probably be pretty straight forward, but I must be missing something.
If it has a removable singularity at infinity then it extends to an analytic function on the Riemann sphere, and so must be constant by Liouville's theorem.
What if there is a pole at infinity though?
This was homework some time ago, and  I never finished it :/ but have been thinking about it again recently.
Thanks :)",['complex-analysis']
29430,Morphism of Exterior Algebras,"Let $k$ be a field, let $V$ and $W$ be $k$-vector spaces of dimensions $n$ and $m$ respectively, and let $f:V\to W$ be a $k$-linear transformation. Let $\Lambda(V)$ and $\Lambda(W)$ denote the exterior algebras of $V$ and $W$ respectively. So we have
$$\Lambda(V) = \Lambda^0(V)\oplus\Lambda^1(V)\oplus\cdots\oplus\Lambda^n(V)$$
and
$$\Lambda(W) = \Lambda^0(W)\oplus\Lambda^1(W)\oplus\cdots\oplus\Lambda^m(W).$$ The wikipedia page on exterior algebras states that there is a unique function $\Lambda(f):\Lambda(V)\to\Lambda(W)$ such that $\Lambda(f)|_{\Lambda^1(V)}:\Lambda^1(V)\to\Lambda^1(W)$ is defined by $\Lambda(f)(v)=f(v)$. In fact, $\Lambda(f)$ preserves grading (i.e. it can be written as a sum of maps $\Lambda^k(f):=\Lambda(f)|_{\Lambda^k(V)}:\Lambda^k(V)\to\Lambda^k(W)$). If $1\leq k \leq n$, then $\Lambda(f)$ is given by
$$\Lambda^k(f)(v_1\wedge\cdots\wedge v_k) = f(v_1)\wedge\cdots\wedge f(v_k).$$ I do not understand how this function acts on $\Lambda^0(V)=k$. I know that we have a map
$$\Lambda^0(f):\Lambda^0(V)\to\Lambda^0(W)$$ which is really the same as
$$\Lambda^0(f):k\to k.$$ My question has two parts: what is $\Lambda^0(f)$ and how is it determined from the universal mapping property for exterior algebras?","['exterior-algebra', 'linear-algebra', 'abstract-algebra']"
29432,Product of two power series,Say if I define a power series over some arbitrary field $F$ as $$a = \sum^{ \infty }_{i = 0} a_{i} X^{i} $$ Then can I say: $$ab = \sum^{ \infty }_{i = 0} \sum^{ \infty }_{j = 0} a_{i} b_{j} X^{i + j} $$,"['power-series', 'convergence-divergence', 'abstract-algebra']"
29442,Expected tail and head length of $\rho$ for a finite random function,"Let $F: D \rightarrow D$ be a random function on finite domain $D$ of size $n$.  It is well-known that, from any $x \in D$, iterating $F$ on $x$ traces out a sequence of values $x, F(x), F(F(x)), \ldots$ that must eventually repeat (since $D$ is finite) and resembles a Greek ""$\rho$"".  The expected number of total elements in this $\rho$ is $\sqrt{n\pi/2}$ with half being on the tail and half on the head.  I've seen this stated in several places, but cannot find a proof. Illustration: In order to clarify what I'm asking (since the comments make it clear that this might be useful), fix an integer $n$.  Uniformly sample $a_0 \in [1,n]$ and make a vertex with label $a_0$.  Do this again, obtaining a vertex labeled $a_1$ and make a directed edge from $a_0$ to $a_1$ (this does not preclude $a_0 = a_1$).  The pigeon-hole principle tells us that eventually we will create a cycle in this digraph; we terminate the process when this occurs. Clearly the graph will look like the letter $\rho$: the ""tail"" is the part of the graph before we enter the cycle (the tail might have length zero, of course), and the ""head"" is the is part of the graph comprising the cycle. My question is this: what is the expected length of the tail and head, in terms of $n$.  Asymptotically, the answer is known to be $\sqrt{n\pi/8}$, but I cannot find a derivation.","['random-functions', 'probability']"
29443,The relationship between mean and variance in the context of system energy and the partition function,I'm looking at a specific derivation on wikipedia relevant to statistical mechanics and I don't understand a step. $$ Z = \sum_s{e^{-\beta E_s}} $$ $Z$ (the partition function) encodes information about a physical system. $E_s$ is the energy of a particular system state. $Z$ is found by summing over all possible system states. The expected value of $E$ is found to be: $$ \langle E \rangle = -\frac{\partial \ln Z}{\partial \beta} $$ Why is the variance of $E$ simply defined as: $$ \langle(E - \langle E\rangle)^2\rangle = \frac{\partial^2 \ln Z}{\partial \beta^2} $$ just a partial derivative of the mean. What about this problem links the variance and mean in this way?,"['statistics', 'calculus', 'physics']"
29450,Self-Contained Proof that $\sum\limits_{n=1}^{\infty} \frac1{n^p}$ Converges for $p > 1$,"To prove the convergence of the p-series $$\sum_{n=1}^{\infty} \frac1{n^p}$$ for $p > 1$, one typically appeals to either the Integral Test or the Cauchy Condensation Test. I am wondering if there is a self-contained proof that this series converges which does not rely on either test. I suspect that any proof would have to use the ideas behind one of these two tests.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
29471,Number of periodic integer functions with a certain property,"How many (equivalence classes of) periodic functions $f : \mathbb{Z} \rightarrow \mathbb{Z}$, of period $N$, satisfy
$$\sum_{i \le n \le j} f(n) \in \{-1,0,1\}$$
for all pairs of integers $(i,j)$? I consider two functions equivalent if they are related by a simple shift, hence ""(equivalence classes of)"". I wrote a computer program to count these functions for small values of $N$, and it spit out the first dozen terms of http://oeis.org/A008965 . However, I can't see any simple relationship between the things being counted there (necklaces of beads grouped into sets), and the things I'm counting (periodic functions with a certain property). So what I'm really asking is why the numbers of functions are the same as the numbers of necklaces, or in other words how to map one problem onto the other. As an example, here are the 13 functions for $N=6$: [1, 0, 0, 0, 0, -1], [0, 1, 0, 0, 0, -1], [1, -1, 1, 0, 0, -1], [0, 0, 1, 0, 0, -1], [1, 0, -1, 1, 0, -1], [0, 1, -1, 1, 0, -1], [1, -1, 0, 1, 0, -1], [0, 0, 0, 1, 0, -1], [1, -1, 1, -1, 1, -1], [0, 0, 1, -1, 1, -1], [0, 1, -1, 0, 1, -1], [0, 0, 0, 0, 1, -1], [0, 0, 0, 0, 0, 0] and here are the 13 necklaces with 6 total beads: (2, 3, 1), (2, 1, 1, 1, 1), (2, 2, 2), (2, 4), (3, 3), (4, 1, 1), (1, 1, 1, 1, 1, 1), (3, 1, 1, 1), (2, 2, 1, 1), (1, 5), (2, 1, 3), (6), (2, 1, 2, 1) There are 13 of either, but I don't see how to put them in a natural 1-to-1 correspondence. And I'd be very surprised if it were just a coincidence, because the sequence matches up to 351, at which point my rather brute-force program started taking way too long.",['combinatorics']
29475,Conformality of Inversion Map,"I am trying to show that elements of the general Möbius group generated by an affine transformation $f(z) = az+b$, the inversion map $f(z)=\frac{1}{z}$ and complex conjugation $f(z)=\overline{z}$, where $a,b \in \mathbb{C}$, are conformal maps. So if I have a curve lying in the $x$-$y$ plane, then its image in the $u$-$v$ plane is another curve, and I want to show that the angles between the curves are preserved under the three transformations above. Because we speak of angles between curves, the problem reduces to proving that the angle between their tangents is preserved and hence to the simplest problem f showing that angles between straight lines are preserved under these maps. Now let $X_1$ and $X_2$ be straight lines. Then under an affine transformation and complex conjugation it is not hard to show that the angle between $X_1$ and $X_2$, let's call it $angle(X_1 , X_2)$ is preserved (Under complex conjugation the sign of the angle is reversed however). Now the inversion map is a bit more tricky. If my two lines in $x-y$ space pass through the $y$-axis at 1, viz. that $X_k$ has equation $\beta_k z + \overline{\beta_k z} + 1 = 0$ where $ k \in {0,1}$, then under inversion these straight lines get mapped to circles through the origin, and hence it is plain that the angles between the tangents of the circles at $(0,0)$ is preserved. However, what if my lines $X_1$ and $X_2$ are such that under inversion $X_1$ maps to a line while $X_2$ maps to a circle? This is where I am getting stuck. On the other hand, if I try to prove the conformality of the inversion map by saying that my $x$ and $y$ coordinate curves in $x-y$ space get mapped to $\frac{x}{x^2 + y^2}$ and $\frac{-y}{x^2 + y^2}$ in $u-v$ space, and then write vector equations of lines and compute partial derivates, the maths becomes ugly and the method is certainly not elegant. Anyone got any ideas? (Maybe involving Cauchy - Riemann Equations!!)","['inversive-geometry', 'complex-analysis']"
29477,Good book for self-learning sequence and series,I would be very happy if it covers sequence and series from very basics to advanced. Thanks.:),"['book-recommendation', 'sequences-and-series', 'reference-request']"
29482,Frobenius morphism and global sections of direct image of structure sheaf,"Let $X$ be a proper scheme defined over an algebraically closed field of characteristic $p > 0$. Let $F : X\rightarrow X$ be the absolute Frobenius morphism. What is the dimension of $H^0(X, F_*\mathcal{O}_X)$?",['algebraic-geometry']
29491,"Will moving differentiation from inside, to outside an integral, change the result?","I'm interested in the potential of such a technique.  I got the idea from Moron's answer to this question , which uses the technique of differentiation under the integral. Now, I'd like to consider this integral: $$\int_{-\pi}^\pi \cos{(y(1-e^{i\cdot n \cdot t}))}\mathrm dt$$ I'd like to differentiate with respect to y.  This will give the integral: $$\int_{-\pi}^\pi -(1-e^{i\cdot n \cdot t})(\sin{(y(1-e^{i\cdot n \cdot t}))}\mathrm dt$$ ...If I'm correct.  Anyways, I'm interested in obtaining the results to this second integral, using this technique.  So I'm wondering if solving the first integral can help give results for the second integral.  I'm thinking of setting $y=1$ in the second integral.  This should eliminate $y$ from the result, and give me the integral involving $x$. The trouble is, I'm not sure I can use the technique of differentiation under the integral.  I want to know how I can apply this technique to the integrals above.  Any pointers are appreciated. For instance, for what values of $y$ is this valid?","['leibniz-integral-rule', 'calculus', 'integration']"
29498,Nonlinear function continuous but not bounded,"I would like an example of a map $f:H\rightarrow R$, where $H$ is a (infinite dimensional) Hilbert space, and $R$ is the real numbers, such that $f$ is continuous, but $f$ is not bounded on the close unit ball $\{ x\in H : \|x\| \leq 1\}$. Actually, $H$ could be replaced by any Banach space (but not just a normed space-- that's too easy).  My motivation is that if $f$ is linear, this is impossible; but I have next to no intuition about non-linear functions. Edit: Here's an example for $c_0$ which is even differentiable (disclaimer: I found it here: http://www.ms.uky.edu/~larry/paper.dir/korea.ps ).  Define $f:c_0\rightarrow F$ (where F is your field, real or complex) by $$ f(x) = \sum_{n=1}^\infty x_n^n \qquad (x=(x_n)). $$  You can estimate the sum by a geometric progression, so it does converge.  A bit of checking shows that f is Frechet differentible (so certainly continuous).  But $f(1,1,\cdots,1,0,\cdots)=n$ (if there are $n$ ones) so $f$ is not bounded on the closed unit ball.  What I don't immediately see is how to adapt this to $\ell^2$, say.",['functional-analysis']
29506,What is the statistically natural way to center the logit-scale around a given value?,"I would like to find out the formula for CandidateAbility used in the European PISA-test, which tests 9th grade pupil's abilities. Unfortunately the agency which publishes the results does not provide many mathematical facts. They say they use a logit-function to determine pupils' abilities in terms of percentage of correctly solved problems from a fixed problem set and the average problem difficulty for that set (never mind the definition of that). Googling for ""logit"" revealed the following formula: $$\mathrm{CandidateAbility} = \log \left( \frac{x}{1-x} \right) + \mathrm{AverageDifficulty}$$ where $x$ denotes the fraction of correctly solved problems. Assuming $\mathrm{AverageDifficulty}=0$ for now, this is centered around 0.5, i.e. a pupil solving half of the problems gets assigned ability zero. However, the PISA-agency says that they center the scale around 0.625, i.e. a pupil solving 62.5 percent of the problems gets assigned 0. Now I can imagine many ways of modifying the above formula to achieve this. The first that come to my mind are: $$\mathrm{CandidateAbility} = \log \left( \frac{x}{1-x} \right) + \mathrm{AverageDifficulty} - \log \left( \frac{0.625}{1-0.625} \right),$$
just shifting the outcome of the formula, and $$\mathrm{CandidateAbility} = \log \left( \frac{x-c}{1-(x-c)} \right) + \mathrm{AverageDifficulty}$$ where c=0.625-0.5 (the difference between the new and the old center), modifying the input into the log-term. My question is: Is there any modification of the formula, either one of the above or something entirely different, which is most natural from a statistician's point of view? Any suggestion would be welcome and could be used to counter-check against the data that is provided by the PISA-agency. Thanks!",['statistics']
29515,Why is every discrete subgroup of a Hausdorff group closed?,"I have just begun to learn about topological group recently and is still not familiar with combining topology and group theory together. I have read a useful property of discrete group on the wikipedia : every discrete subgroup of a Hausdorff group is closed But I have no idea how to prove it. I find that it cannot be proved only
considering the topological structure, since $\left\{\frac{1}{n}: n=1,2,3,...\right\}$
is a discrete subspace of $\Bbb R$, which is not closed. I don't know how to use the group structure here. Can you please help?  Thanks.","['general-topology', 'topological-groups', 'algebraic-topology']"
29536,Are there any Hessian matrices that are asymmetric on a large set?,"Are there any functions, $f:U\subset \mathbb{R}^n \to \mathbb{R}$, with Hessian matrix which is asymmetric on a large set (say with positive measure)? I'm familiar with examples of functions with mixed partials not equal at a point, and I also know that if $f$ is lucky enough to have a weak second derivative $D^2f$, then $D^2 f$ is symmetric almost everywhere.","['hessian-matrix', 'multivariable-calculus', 'real-analysis']"
29551,How to compute a linear fractional transformation that maps a circle to a given circle?,"How to compute a linear fractional  transformation that maps a circle to a given circle? For example, let $C_1$ be the circle $|z+(2+i)|=1$ and $C_2$ be the circle $|z-5|=7$. How to find a linear fractional transformation that maps $C_1$ to $C_2$? Thank you very much.",['complex-analysis']
29561,"Geometric interpretation of $\frac {\partial^2} {\partial x \partial y} f(x,y)$","Is there any geometric interpretation for the following second partial derivative? $$f_{xy} = \frac {\partial^2 f} {\partial x \partial y}$$ In particular, I'm trying to understand the determinant from second partial derivative test for determining whether a critical point is a minima/maxima/saddle points: $$D(a, b) = f_{xx}(a,b) f_{yy}(a,b) - f_{xy}(a,b)^2$$ I have no trouble understanding $f_{xx}(x,y)$ and $f_{yy}(x,y)$ as the of measure of concavity/convexity of $f$ in the direction of $x$ and $y$ axis. But what does $f_{xy}(x,y)$ mean?","['multivariable-calculus', 'geometric-interpretation', 'hessian-matrix', 'partial-derivative', 'scalar-fields']"
29581,Stochastics problem: give an example,"Give an example on $\Omega = \{a, b, c\}$ in which $E(E(X|F_{1})|F_{2}) \neq E(E(X|F_{2})|F_{1})$ -- Obviously X is a random variable and $F_{1}$ and $F_{2}$ are sigma-algebras... but I'm not even sure how to get started on the actual example. Any help is appreciated. Thanks.","['stochastic-processes', 'measure-theory']"
29586,The inclusion map from a manifold to a product manifold is $C^{\infty}$,"Let $i_{q0} : M\rightarrow M\times N$, $i_{q0}(p) = (p, q0)$ be a mapping between smooth manifolds.  I need some hints to show that it is $C^{\infty}$. I have so far... Let $(U,\phi)$ and $(V,\psi)$ be charts about $p$ and $i_{q0}$, and let $r^{i}$ be the $ith$ coordinate function on Euclidean space.  Then we need to show that 
$\frac{\partial (r^{i}\circ \psi \circ i_{q0} \circ \phi^{-1})}{\partial r^{j}}$ exists and is continuous at $\phi(p)$ and that we can keep taking partial derivatives.","['manifolds', 'differential-geometry']"
29599,Is the set of all finite sequences of letters of Latin alphabet countable/uncountable? How to prove either?,"Today in Coding/Cryptography class, we were talking about basic definitions, and the professor mentioned that for a set $A=\left \{ \left. a, b, \dots, z \right \} \right.$ (the alphabet) we can define a set $A^{*}=\left \{ \left. a, ksdjf, blocks, coffee, maskdj, \dots, asdlkajsdksjfs \right \} \right.$ (words) as a set that consists of all finite sequences of the elements/letters from our $A$/alphabet. My question is, is this set $A^{*}$ countably or uncountably infinite? Does it matter how many letters there are in your alphabet? If it was, say, $A=\left \{ \left. a \right \} \right.$, then the words in $A^{*}$ would be of form $a, aa, aaa, \dots$ which, I think, would allow a bijection $\mathbb{N} \to A^{*}$ where an integer would signify the number of a's in a word. Can something analogous be done with an alphabet that consists of 26 letters (Latin alphabet), or can countability/uncountability be proved otherwise? And as mentioned before, I am wondering if the number of elements in the alphabet matters, or if all it does is change the formula for a bijection. P.S. Now that I think of it, maybe we could biject from $\underset{n}{\underbrace{\mathbb{N}\times\mathbb{N}\times\mathbb{N}\times\dots\times\mathbb{N}}}$ to some set of words $A^{*}$ whose alphabet $A$ has $n$ elements? Thanks!","['coding-theory', 'elementary-set-theory', 'cryptography']"
29600,Proof of the classical div-curl-lemma,"let $1 = \frac{1}{p} + \frac{1}{q}$ as usual. Let $f \in L^p, g \in L^q$ be vector fields from $\mathbb R^n$ to itself. Assume $div f = 0$ and there exists a function $G$ s.t. $\nabla G = g$. Then $f \cdot g \in \mathcal H^1$ is a Hardy space function. Do you know where I can find a proof of this conclusion? I am aware of a paper by Coifman et al. ""Compensated compactness and Hardy spaces"", but I am not granted access to this journal. Hence I am looking for an alternative resource.","['harmonic-analysis', 'reference-request', 'analysis']"
29609,Convergence in measure,There is a proposition that states the following: Assume $E$ has finite measure. Let {$f_n$} be a sequence of measurable functions that converges pointwise a.e. on $E$ to $f$ and $f$ is finite a.e. on $E$. Then {$f_n$} converges in measure to $f$ on $E$. How do you show that this fails if $E$ has infinite measure?,"['measure-theory', 'real-analysis']"
29615,"if a complex function $f$ is real-differentiable, then $f$ or $\overline{f}$ are complex-differentiable",This is an exercise from Remmert's Theory of Complex functions. Let $D\subset \mathbb{C}$ be a domain and $f:D\rightarrow \mathbb{C}$ a real-differentiable function. Assume that the following limit exists: $ \mathrm{lim}_{h\rightarrow 0} \left|  \frac{f(c+h) - f(c)}{h}   \right|.$ Show that either $f$ or $\overline{f}$ is complex-differentiable. I've tried showing that $\frac{\partial f}{\partial \overline{z}} = 0$ or $\frac{\partial \overline{f}}{\partial z} = 0$ by using the fact that there exist continuous functions $g$ and $h$ such that in $D$ one can write $f(z) = f(c) + (z-c)g(z) + (\overline{z} - \overline{c})h(z)$ and that $g(c)= f_{z}(c)$ and $h(c) = f_{\overline{z}}$ and then plugging this into the limit above. Does this approach works and I just can´t see how to do it? Can someone give a hint or a guideline solution to this?,['complex-analysis']
29616,Inverse Limit of Sheaves,"It is well-known that if you have an inverse system of abelian groups $(A_n)$ (this works in several other nice categories) in which all the maps are surjective (or at least satisfy the Mittag-Leffler Condition), and if you have a short exact sequence of inverse systems $0\to (A_n)\to (B_n)\to (C_n)\to 0$, then taking the limit is exact and you get another short exact sequence $0\to \lim A_n \to \lim B_n \to \lim C_n \to 0$. Hartshorne warns that this is not the case with abelian sheaves on a space. In particular, you can have all the maps of $(\mathcal{F}_n)$ surjective, and a short exact sequence $0\to (\mathcal{F}_n)\to (\mathcal{G}_n)\to (\mathcal{J}_n)\to 0$ but you only get left exactness $0\to \lim \mathcal{F}_n\to \lim \mathcal{G}_n\to \lim \mathcal{J}_n$ I.e. you get that $\lim^1(\mathcal{F}_n)\neq 0$ despite satisfying surjectivity of maps. Is there a canonical example of this happening? My first guess was that this had to be related to the fact that you can have a surjective map of sheaves $\mathcal{F}\to \mathcal{G}$, yet still have an open set for which $\mathcal{F}(U)\to \mathcal{G}(U)$ is not surjective. The canonical example of when this happens is to use the exponential map on the sheaf of holomorphic functions on $\mathbb{C}^\times$, but it is very non-obvious to me how to turn this into an example of the above.","['sheaf-theory', 'algebraic-geometry']"
29632,Circle preserving homeomorphisms in the closure of $\mathbb{C}$ and Möbius Transformations,"I am presently a learner of Hyperbolic Geometry and am using J. W. Anderson's book $Hyperbolic$ $Geometry$.  Now the author presents a sketch proof of why every circle preserving homeomorphism in $\overline{\mathbb{C}}$ is an element of the general Möbius group, which is what I am struggling to understand. First, a brief outline. Let $f$ be an element of the set of all circle preserving homeomorphisms which we denote Homeo$^{C}(\overline{\mathbb{C}})$ and let $p$ be a Möbius transormations that maps the triples $(f(0),f(1),f(\infty))$ to $(0,1,\infty)$ Then we see that $p\circ f(0) = 0, p\circ f(1) = 1$ and $p \circ f(\infty)=\infty$, and  since $p \circ f(\mathbb{R}) = \mathbb{R}$, either such a composition maps the upper half of the complex plane, $\mathbb{H}$ to itself or the lower half of the complex plane. If $p \circ f(\mathbb{H}) = \mathbb{H}$, we take $ m =p$, while if $m \circ (\mathbb{H})$ goes to the lower half, we just take $m = W \circ p$, where $W(z) = \overline{z}$ Now here is the thing I don't understand: Let $A$ be an euclidean circle in $\mathbb{C}$ with euclidean centre $\frac{1}{2}$ and radius $\frac{1}{2}$. Let $V(0), V(1)$ be the vertical lines through the points $x=0$ and $x=1$. Can anybody explain why as $V(0)$ and $V(1)$ are vertical tangents to the circle, then these lines under the map $m \circ f(z)$, namely  $m \circ f\Big(V(0)\Big)$ and  $m \circ f\Big(V(1)\Big)$ are again vertical tangents to the circle $m \circ f(A)$ at $m \circ f(0) = 0$ and $m \circ f(1) = 1$? I am trying to conclude from here that $m \circ f = Id_z$ , the identity transformation. Thanks, Ben","['hyperbolic-geometry', 'complex-analysis']"
29634,Convergence of functions in $L^p$,"Let $\{f_k\} \subset L^2(\Omega)$, where $\Omega \subset \mathbb{R}^n$ is a bounded domain  and suppose that $f_k \to f$ in $L^2(\Omega)$. Now if $a \geq 1$ is some constant, is it possible to say that $|f_k|^a \to |f|^a$ in $L^p$ for some $p$ (depending on $a$ and also possibly depending on $n$)? Showing the statement is true would probably require a smart way of bounding $\left| |f_k|^a - |f|^a \right|$ by a term including the factor $|f_k - f|^2$. However, I don't really know what to do with the fact that $a$ doesn't have to be an integer...","['lebesgue-integral', 'convergence-divergence', 'lp-spaces', 'real-analysis']"
29649,Why is $\arctan(x)=x-x^3/3+x^5/5-x^7/7+\dots$?,"Why is $\arctan(x)=x-x^3/3+x^5/5-x^7/7+\dots$? Can someone point me to a proof, or explain if it's a simple answer? What I'm looking for is the point where it becomes understood that trigonometric functions and pi can be expressed as series.  A lot of the information I find when looking for that seems to point back to arctan.","['trigonometry', 'sequences-and-series']"
29670,How do I know the limit of this infinite sequence,"I have $a_k=\frac1{(k+1)^\alpha}$ and $c_k=\frac1{(k+1)^\lambda}$, where $0<\alpha<1$ and $0<\lambda<1$, and we have a infinite sequence $x_k$ with the following evolution equation.
$$
x_{k+1}=\left(1-a_{k+1}\right)x_{k}+a_{k+1}c_{k+1}^{2}
$$
I have proven that $x_k$ is bounded and obviously positive. How can I know its limit?",['sequences-and-series']
29672,Why does the Gram-Schmidt procedure divide by 0 on a linearly dependent lists of vectors?,"Let $v_1, \dots, v_m$ be a linearly dependent list of vectors. If $v_1 \ne 0$, then there is some $v_j$ in the span of $v_1, \dots, v_{j-1}$ If we let j be the smallest integer with this property, and apply the gram-schmidt procedure to produce an orthonormal list $(e_1, \dots, e_{j-1})$ then $v_j$ is in the span of $(e_1, \dots, e_{j-1})$ and $$v_j = \langle v_j, e_1\rangle e_1+ \dots + \langle v_j, e_{j-1}\rangle e_{j-1}$$ Why does this guarantee that length of $v_j$=0? I'm missing something about linear dependence that should probably be obvious sorry :\","['linear-algebra', 'inner-products']"
29685,Summing Matrix Series,"I need to sum the series $$I + A + A^2 + \ldots$$ for the matrix $$A = \left(\begin{array}{rr}
0 & \epsilon \\
-\epsilon & 0
\end{array}\right)$$ and $\epsilon$ small. The goal is to invert the matrix $I - A$. The text says to use a geometric series but I had a hard time finding it. I'm studying on my own so I can't ask my teacher. The way I did it follows. I know it isn't quite rigorous (I assume the series in question converge) so I'd like to see how I'm supposed to do it. We see that $$\left(\begin{array}{rr}
0 & \epsilon \\
-\epsilon & 0
\end{array}\right)
\left(\begin{array}{rr}
a_{00} & a_{01} \\
a_{10} & a_{11}
\end{array}\right) = 
\left(\begin{array}{rr}
\epsilon a_{10} & \epsilon a_{11} \\
-\epsilon a_{00} & \epsilon a_{01}
\end{array}\right)$$ so if we let $a(i, j, k)$ be entry $a_{ij}$ in the $k$'th power of $A$ then we see that $$
a(0, 0, k) = \epsilon a(1, 0, k-1)
$$ $$
a(1, 0, k) = -\epsilon a(0, 0, k-1)
$$ Then, letting $\alpha$'s denote the entries in the sum without $I$ added in, we see that $$
\begin{eqnarray*}
\alpha_{00} &=& \sum_{k=0}^{\infty}a(0, 0, k) \\
&=& \sum_{k=0}^{\infty}a(0, 0, 2k + 1) \\
&=& \epsilon\sum_{k=0}^{\infty}a(1, 0, 2k) \\
&=& \epsilon\alpha_{10}
\end{eqnarray*}

$$ and $$
\begin{eqnarray*}
\alpha_{10} &=& \sum_{k=0}^{\infty}a(1,0,k) \\
&=& \sum_{k=0}^{\infty}a(1,0,2k) \\
&=& -\epsilon + \sum_{k=1}^{\infty}a(1,0,2k) \\
&=& -\epsilon - \epsilon\sum_{k=1}^{\infty}a(0,0,2k-1) \\
&=& -\epsilon\left(1 + \sum_{k=0}^{\infty}a(0,0,2k+1) \right) \\
&=& -\epsilon\left(1 + \alpha_{00}\right)
\end{eqnarray*}
$$ so $\alpha_{00} = \epsilon\alpha_{10}$ and $\alpha_{10} = -\epsilon(1 + \alpha_{00})$ which we can solve for the $\alpha$'s. It's pretty much the same for the other two. I feel like there has got to be a better way to do this.","['matrices', 'power-series']"
29698,Largest eigenvalue of a real symmetric matrix,"If $\lambda$ is the largest eigenvalue of a real symmetric $n \times n$ matrix $H$, how can I show that: $$\forall v \in \mathbb{R^n}, ||v||=1 \implies v^tHv\leq \lambda$$ Thank you.",['linear-algebra']
29704,Why are translation invariant operators on $L^2$ multiplier operators,"For $m \in L^\infty$, we can define the multiplier operator $T_m \in L(L^2,L^2)$ implicitly by $\mathcal F (T_m f)(\xi) = m(\xi) \cdot (\mathcal F T_m)(\xi)$ where $\mathcal F$ is the Fourier transform. It is obvious from the defintion that $T_m$ commutes with translations. How can you show the converse, i.e. every translation invariant $T \in L(L^2,L^2)$ is induced by a multiplier $m_T$? I have no idea how this might work.","['harmonic-analysis', 'fourier-analysis', 'functional-analysis']"
29722,Is a completion of an algebraically closed field with respect to a norm also algebraically closed?,"Assume we have an algebraically closed field $F$ with a norm (where $F$ is considered as a vector space over itself), so that $F$ is not complete as a normed space. Let $\overline F$ be its completion with respect to the norm. Is $\overline F$ necessarily algebraically closed? Thanks.","['normed-spaces', 'banach-spaces', 'abstract-algebra', 'field-theory']"
29730,Why is the real projective space $P^n$ equal to both unit sphere $S^n$ and unit ball $B^n$ with identified antipodal points?,I saw this in Basic Topology by M.A.Armstrong. It gives three descriptions of real n-dimensional  projective space $P^n$. Two of them are: (a) Begin with the unit sphere $S^n$ in $E^{n+1}$ and identify its antipodal points. (c) Begin with the unit ball $B^n$ and identify antipodal points of its boundary sphere. I find it hard to imagine why these two descriptions lead to the same space. Can you please help? Thank you.,"['general-topology', 'projective-space', 'projective-geometry']"
29732,"In what way is the Peano curve not one-to-one with $[0,1]^2$?","In discussion about the question Is there a way to represent the interior of a circle with a curve? , it was mentioned that such a curve cannot be one-to-one (because $[0,1]$ is not homeomorphic to $[0,1]^2$). I'm curious about in what way the Peano curve is not one-to-one. The construction of the Peano curve is a recursive refinement of a particular path that discretely looks one-to-one, in that it touches every coordinate point at a given scale in a bijection. In the limit there's no bijection, but at every step there is a bijection between the curve so far and the coordinates of points within $[0,1]^2$ truncated to so many binary digits. In a surjection that is not an injection, there must be some overlap (some $x,y$ where $x\neq y$ but $f(x)=f(y)$. What I'm getting at is...where is the overlap? I'm guessing it's not just at one point - is it at all points? how much overlap? What is the nature of the overlap (for a given point on $[0,1]^2$, which points in $[0,1]$ map to it? (for discussion's sake, use the definition of the Hilbert-Peano curve ) Edit: A small bit of clarification: given a point $(j,k)$, is their overlap, and if so, how much (what is the cardinality of the inverse image at that point)? How about just for a particular point like $(1/2, 1/2)$?","['general-topology', 'analysis']"
29758,Entire one-to-one functions are linear,Can we prove that every entire one-to-one function is linear?,['complex-analysis']
29766,Measure theory question,"Let $f\geq 0$ be a measurable function which is finite almost everywhere. For each $k\in\mathbb{Z}$, define, $E_k=\lbrace x|f(x)>2^k\rbrace, F_k=\lbrace x|2^k\leq f(x)<2^{k+1}\rbrace$. Is it true that $\sum_{k=-\infty}^{\infty}2^km(E_k)<\infty$ if and only if $\sum_{k=-\infty}^{\infty}2^km(F_k)<\infty$?",['measure-theory']
29767,Different norms on a product space $X \times Y$,"It is well known how to define standard product topology on a product space $\prod_{i \in I} X_i$. Assume now that $(X,\lVert \, \cdot \, \rVert_{X})$ and $(Y,\lVert \, \cdot \, \rVert_{Y})$ are normed spaces and that the space $X \times Y$ is also equipped with a norm $\lVert \, \cdot \, \rVert_{X \times Y}$. Is it true that all norms on $X \times Y$ are equivalent? It is quite easy to prove this if $\lVert \, \cdot \, \rVert_{X \times Y}$ is one of the p -norms, i.e. $\lVert (x,y) \rVert_p = (\lVert x \rVert_X^p + \lVert y \rVert_Y^p)^{1/p}$. All such norms are equivalent. We only need to know that all norms on a finite dimensional space are equivalent (in this case we use it for $\mathbb{R}^2$). How it is general case?","['normed-spaces', 'functional-analysis']"
29777,Closed form for the sequence defined by $a_0=1$ and $a_{n+1} = a_n + a_n^{-1}$,"Today, we had a math class, where we had to show, that $a_{100} > 14$ for $$a_0 = 1;\qquad a_{n+1} = a_n + a_n^{-1}$$ Apart from this task, I asked myself: Is there a closed form for this sequence? Since I didn't find an answer by myself, can somebody tell me, whether such a closed form exists, and if yes what it is?","['closed-form', 'recurrence-relations', 'sequences-and-series']"
29792,What does matrix multiplication have to do with scalar multiplication?,Why are matrix and scalar multiplication denoted the same way and treated as the same operation in standard mathematical notation?  This is always a source of confusion for me because they have completely different properties (specifically commutativity).  Multiplying a 1x1 matrix by an NxN matrix isn't even generally equivalent to multiplying an NxN matrix by a scalar.  (The former is not even always defined.)  Wouldn't it be clearer to consider these to be completely unrelated operations and use completely different notation to represent them?,"['notation', 'math-history', 'matrices', 'linear-algebra', 'faq']"
29794,What is the asymptotic behavior of A103213 in OEIS? [duplicate],This question already has answers here : Sum with binomial coefficients: $\sum_{k=1}^m  \frac{1}{k}{m \choose k} $ (7 answers) Closed 4 years ago . It's probably not at all hard—but at least right now it's not obvious to me—how to determine the asymptotic behavior of $\sum_{k=1}^n \binom{n}{k} \frac{1}{k}$ ( link to OEIS ).,['sequences-and-series']
29797,Direct proof that the wedge product preserves integral cohomology classes?,"Let $H^k(M,\mathbb R)$ be the De Rham cohomology of a manifold $M$. There is a canonical map $H^k(M;\mathbb Z) \to H^k(M;\mathbb R)$ from the integral cohomology to the cohomology with coefficients in $\mathbb R$, which is isomorphic to the De Rham cohomology. As a previous question already revealed, the images of this map are precisely the classes of differential $k$-forms $[\omega]$ that yield integers when integrated over a $k$-cycle $\sigma$, $$ \int_{\sigma} \omega \in \mathbb{Z}  \quad\text{ whenever } d\sigma = 0$$ Let us call them ""integral forms"". Motivated by the cup product on cohomology, my question/request is the following: Give a direct proof that the wedge product $[\omega\wedge\eta]\in H^{k+l}(M,\mathbb R)$ of two integral forms $\omega\in \Omega^k(M)$ and $\eta\in \Omega^l(M)$ is again an integral form. This should be true because the cup product is mapped to the wedge product, but the point of the exercise is to prove this statement directly, without constructing the singular cohomology $H^k(M,\mathbb Z)$ or homology first. Maybe I also have to make sure that the condition of being an integral form is something that can be ""checked effectively"" without singular homology; this might be subject to a new question.","['homology-cohomology', 'differential-forms', 'algebraic-topology', 'differential-geometry']"
29810,A torsion-free quotient?,"Let $G$ be a group and $T$ the set of elements of finite order in $G$. If $T$ is a subgroup of $G$, then $G/T$ is a torsion-free group. Suppose $G$ is a compact Hausdorff topological group. Is it true that $G/cl(T)$ is torsion-free? (where $cl(T)$ is the topological closure of $T$ in $G$).","['general-topology', 'group-theory']"
29814,Prove that the given set is bounded above in $\mathbb{Q}$ but does not have a Supremum in $\mathbb{Q}$,"Let $S=\{r\in \mathbb{Q}\mid r\leq\sqrt{3}\}$ . Now prove that $S$ is bounded above in $\mathbb{Q}$ but it does not have a supremum in $\mathbb{Q}$ . The following is the proof I came up with, but I do not feel confident with it. Please let me know what is incorrect or could be written better. Proof. Let $m=\sqrt{3}$ . Then their exists an $m$ that belongs to the set of real numbers $\mathbb{R}$ such that $r\leq m$ for all $r$ that belong to the set $S$ .
Hence, $S$ is bounded above in $\mathbb{Q}$ . Now, suppose that there exists a smaller upper bound in $S$ , $t$ .
Then $t<\sqrt{3}$ , and as $t$ is an upper bound of $s$ , $t\geq s$ for all $s\in S$ . Therefore, $s\leq t<\sqrt{3}$ , and $s\leq \sqrt{3}\leq t$ , which implies $\sqrt{3}\leq t\leq \sqrt{3}$ , which is impossible. Therefore, $S$ does not have a supremum in $\mathbb{Q}$ . Edit (added by Arturo Magidin, taken from comment made by OP) 2nd Attempt: Proof Let $m=\sqrt{3}$ . Then $m\geq r$ for all $r$ that belong to $S$ . Hence, $S$ is bounded above by $m$ in $\mathbb{R}$ . Therefore, $S$ is bounded above in $\mathbb{Q}$ . Now, suppose $m=\sup(S)$ in $\mathbb{R}$ . Let $t$ be an upper bound in $\mathbb{Q}$ and $t\leq m$ . Hence, there exists $t$ that belongs to $\mathbb{Q}$ such that $m>t\geq r$ for every $r$ that belongs to $S$ . Then there would exist an $r$ that belongs to $S$ such that $r>t$ . Which contradicts $t\geq r$ . Therefore, $S$ doesn't have a supremum in $\mathbb{Q}$ . 3rd Attempt: Proof Since for every $r \in S$ $r<3$ and $3 \in \mathbb{Q}$ , we know $S$ is bounded above in $Q$ . To prove it doesn't have a supremum in $\mathbb{Q}$ , I will use contradiction. Suppose m were the supremum of $S$ in $\mathbb{Q}$ , then m does not equal $\sqrt{3}$ , and $m\in \mathbb{Q}$ . If $m\lt \sqrt{3}$ , by Archmedian's Property, their exists $t$ that belongs to $\mathbb{Q}$ such that $m\lt t\lt \sqrt{3}$ . This is a contradiction, because $m$ isn't an upper bound. If $m\gt\sqrt{3}$ , by Archmedian's Property, their exists $u$ that belongs to $\mathbb{Q}$ such that $\sqrt{3}\lt u\lt m$ This is also a contradiction. Hence, $S$ does not have a supremum in $\mathbb{Q}$",['real-analysis']
