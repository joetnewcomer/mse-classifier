question_id,title,body,tags
164804,Show $f$ is constant if $|f(x)-f(y)|\leq (x-y)^2$.,"Problem : Let $f$ be defined for all real $x$, and suppose that $$|f(x)-f(y)|\le (x-y)^2$$ for all real $x$ and $y$. Prove $f$ is constant. Source : W. Rudin, Principles of Mathematical Analysis , Chapter 5, exercise 1.","['continuity', 'real-analysis']"
164806,Are $|X|$ and $\operatorname{sgn}(X)$ independent?,"Let $X$ be a real valued random variable. Let $\operatorname{sgn}(x)$ be $1$ when $x>0$, $-1$ when $x<0$ and $0$ when $x=0$. Why  are $|X|$ and $\operatorname{sgn}(X)$ independent, when the density function of $X$ is symmetric with respect to $0$? Are $|X|$ and $\operatorname{sgn}(X)$ independent, when the density function of $X$ is not necessarily symmetric with respect to $0$? Thanks!",['probability']
164811,Explanation for why $1\neq 0$ is explicitly mentioned in Chapter 1 of Spivak's Calculus for properties of numbers.,"During the first few pages of Spivak's Calculus (Third edition) in chapter 1 it mentions six properties about numbers. (P1) If $a,b,c$ are any numbers, then $a+(b+c)=(a+b)+c$ (P2) If $a$ is any number then $a+0=0+a=a$ (P3) For every number $a$, there is a number $-a$ such that $a+(-a)=(-a)+a=0$ (P4) If $a$ and $b$ are any numbers, then $a+b=b+a$ (P5) If $a,b$ and $c$ are any numbers, then $a\cdot(b\cdot c)=(a\cdot b)\cdot c$ (P6) If $a$ is any number, then $a\cdot 1=1\cdot a=a$ Then it further states that $1\neq 0$. In the book it says that it was an important fact to list because there is no way that it could be proven on the basis of the $6$ properties listed above - these properties would all hold if there were only one number, namely $0$. Questions: 1) How does one rigorously prove that $1\neq0$ cannot be proven from the $6$ properties listed? 2) It says that ""these properties would all hold if there were only one number, namely $0$."" Is a reason as to why this is explicitly mentioned is to avoid this trivial case where we only have the number $0$? Is there another deeper reason as to why this sentence was mentioned in relation to $1\neq 0$? NB: Can someone please check if the tags are appropriate and edit if necessary? Thanks.",['abstract-algebra']
164847,congruent to mod p $1^{p-2}+2^{p-2}+\cdots+\left(\frac{p-1}{2}\right)^{p-2}\equiv\frac{2-2^p}{p}\pmod p.$,Let $p$ be an odd prime.How to prove that $$1^{p-2}+2^{p-2}+\cdots+\left(\frac{p-1}{2}\right)^{p-2}\equiv\frac{2-2^p}{p}\pmod p.$$,['number-theory']
164864,Existence of Consecutive Quadratic residues,"For any prime $p\gt 5$,prove that there are consecutive quadratic residues of $p$ and consecutive non-residues as well(excluding $0$).I know that there are equal number of quadratic residues and non-residues(if we exclude $0$), so if there are two consecutive quadratic residues, then certainly there are two consecutive non-residues,therefore, effectively i am seeking proof only for existence of consecutive quadratic residues. Thanks in advance.",['number-theory']
164865,Cech cohomology of $\mathbb A^2_k\setminus\{0\}$,"I'm trying to prove, via the Cech cohomology, that $S=\mathbb A^2_k\setminus\{0\}$ with the induced Zariski topology is not an affine variety. Consider the structure sheaf $\mathcal O_{\mathbb A^2_k}\big|_S:=\mathcal O_S$ (which is quasi coherent), i must show that $\exists n$ such that $\check H^n(S,\mathcal O_S)\neq 0$. It is enough to prove that $\check H^n(\mathcal U,\mathcal O_S)\neq0$ for a certain affine cover of $S$ (and a certain $n$); so let's choose $\mathcal U=\{D(X), D(Y)\}$ where $D(X)=\{(x,y)\in S\,:\, x\neq 0\}$ and $D(Y)=\{(x,y)\in S\,:\, y\neq 0\}$. Clearly for $n\ge 2$ we have that $\check H^n(S,\mathcal O_S)=0$, so i must show that $\check H^1(\mathcal U,\mathcal O_S)\neq0$. The Cech complex is:
$$\mathcal O_S(D(X))\times\mathcal O_S(D(Y))=\Gamma(S)_X\times\Gamma(S)_Y\longrightarrow \mathcal O_S(D(X)\cap D(Y))=\Gamma(S)_{XY}\longrightarrow 0\cdots$$ with the homomorphism: $d^0: (f,g)\mapsto g|_{{D(X)\cap D(Y)}}-f|_{{D(X)\cap D(Y)}}$. To complete the proof i should conclude that $d^0$ is not surjective, but why is this true? thanks","['homology-cohomology', 'sheaf-theory', 'algebraic-geometry']"
164874,$|2^x-3^y|=1$ has only three natural pairs as solutions,"Consider the equation $$|2^x-3^y|=1$$ in the unknowns $x \in \mathbb{N}$ and $y \in \mathbb{N}$. Is it possible to prove that the only solutions are $(1,1)$, $(2,1)$ and $(3,2)$?","['diophantine-equations', 'number-theory']"
164878,Is locally free sheaf of finite rank coherent?,"Let $\mathcal{F}$ be a locally free sheaf of finite rank of scheme $X$, is $\mathcal{F}$ coherent? By the definition of locally free sheaf, there exists an open cover {$U_i$} of $X$ such that $\mathcal{F}|_{U_i}$ is isomorphic to the sheaf $\widetilde{\mathcal{O}(U_i)^n}$. But we don't know each $U_i$ affine or not! So, it that true or not? How about $X$ being locally noetherian? It $X$ is, we can find $V_{ij} \subset U_i$ s.t. $V_{ji} = Spec(A_{ji})$. And $\mathcal{F}|_{V_{ij}} = \mathcal{F}|_{U_i}|_{V_{ij}}$...? For example, $X(\Delta)$ is a toric varity with $\Delta$ consists of strongly convex polyhedral cones. Thank you very much!!","['algebraic-geometry', 'toric-geometry']"
164889,Why do the endpoints of the Maclaurin series for arcsin converge?,"The series $$\sum_{n=0}^\infty {{-\frac {1} 2} \choose n} \frac{(-1)^n}{2n+1}$$ is an endpoint for the Maclaurin series for arcsin(x). (The other endpoint is just the negative of this one.) I played around with this a bit and turned it into three (potentially useful) forms : $\sum_{n=0}^\infty \frac12\frac34\frac56\cdots\frac{2n-1}{2n} \frac{1}{2n+1}$ $\sum_{n=0}^\infty \left( 1-\frac 1 2 \right) \left( 1-\frac 1 4 \right)\cdots \left( 1-\frac 1 {2n} \right)\frac{1}{2n-1}$ $\sum_{n=0}^\infty \dfrac{(2n)!}{2^{2n}(n!)^2}\dfrac{1}{2n+1}$, but I'm not sure where one could go from here.","['calculus', 'taylor-expansion']"
164893,How to derive the equation for a bézier curve,"So, I remember a while back there was a maths competition and we were given a curve that we needed to write an equation for. I just skipped the question since I didn't even know where to begin. I remember it was one among the last few questions of the paper and it was worth a lot of points. I don't really remember what the curve looked like; it was something spirally, but I can't recall it to save my life right now. So, I drew this curve in Inkscape (it's a Bézier curve. Or a few of them linked together, according to Wikipedia. If it's required I will post the whole path). And I would like to write the equation for it (with someone's help, obviously). I was always a bit bad with curves, graphs and lines, but I want to understand them better. So, I was hoping someone could explain the process of deriving the equation for a curve. P.S: I'd like it if you could use another curve (it can be something simpler, but try avoiding something overly complicated) so I can crack this one on my own, but if you feel like using this curve as an example I won't mind. EDIT So  have been browsing the internet, read a few Wikipedia entries about Bazier curves, and I understand how they're drawn (mostly the GIFs helped, haha), but I am still stumped when it comes to mathematically representing a Bézier curve. Also, I will add this image, which is the path and its control points (at the end of the blue lines; I didn't paint them in): And also, the contents of the .tex file for the shape. %LaTeX with PSTricks extensions
%%Creator: 0.48.2
%%Please note this file requires PSTricks extensions
\psset{xunit=.5pt,yunit=.5pt,runit=.5pt}
\begin{pspicture}(451.46875,34.25392151)
	{
	\newrgbcolor{curcolor}{1 0 0}
	\pscustom[linewidth=3,linecolor=curcolor]
	{
	\newpath
	\moveto(450.48448,1.10834551)
	\curveto(404.89404,41.45133951)(333.34998,42.21654151)(281.90128,9.03018551)
	\curveto(258.09407,-6.32636849)(228.42388,9.91159551)(202.75741,15.38398551)
	\curveto(145.68728,27.55199551)(85.852286,40.32786151)(28.08402514,26.23698551)
	\curveto(18.5710181,23.91656551)(9.403556,20.24334551)(0.681686,15.78116551)
	}
	}
	\end{pspicture} Thanks!","['graphing-functions', 'bezier-curve', 'derivatives']"
164899,Generalized Laplacian operator?,"Suppose a surface $S$ is endowed with a metric given by the matrix $$M=\begin{pmatrix} E&F\\F&G\end{pmatrix}$$ And $f,g$ are scalar functions defined on the surface. What then is the (geometric) significance of the scalar function given by ${1\over \sqrt{\det(M)}}{\partial \over \partial x_i}\left(f\sqrt{\det(M)} (M^{-1})_{ij} {\partial \over \partial x_j} g\right)$? I have been told that if we set $f=1$, we get an operator equivalent to the Laplacian acting on the function $g$. Why does the Laplacian become this form? Is there an intuitive geometric explanation of what is going on? Thank you.","['geometry', 'differential-geometry']"
164902,cardinality: The cardinality of the set of all relations over the natural numbers.,"I have to find the cardinality of the set of all relations over the natural numbers, without any limitations. It seems to be א , but I can't find a function/other way to prove it. help anyone? thanxs.","['cardinals', 'elementary-set-theory']"
164946,Characterization of real functions which have limit at each point,"The following problem is Exercise 7.K from the book van Rooij-Schikhof: A Second Course on Real Functions and it is very close to a question which was recently discussed in chat . So I thought that sharing this interesting problem with other MSE users could be useful. Here's the problem: Let $L$ be the set of all functions $f\colon [0,1]\to\mathbb R$ that have the property that $\lim\limits_{x\to a} f(x)$ exists for all $a \in [0, 1]$.
  Show that: (i) $L$ is a vector space. Each $f \in L$ is bounded. (ii) For each $f \in L$, define $f^c(x): = \lim\limits_{y\to x} f(y)$ ($x \in [0, 1]$). $f^c$ is continuous. (iii) '$f^c =0$' is equivalent to 'there exist $x_1, x_2, \dots$ in $[0,1]$ and $a_1, a_2,\dots$ in $U$ with
  $\lim\limits_{n\to\infty} a_n = 0$, such that $f(x_n) = a_n$ for every $n$, and $f=0$ elsewhere'. (iv) Describe the general form of an element of $L$. Show that every $f\in L$ is Riemann integrable. The original question in the chat was about functions $\mathbb R\to\mathbb R$, but it does not change much in the parts (iii) and (iv).",['real-analysis']
164959,Is there any famous number theory conjecture proven impossible to be find out the truth or false?,Is there any famous number theory conjecture proven undecidable? Is there any history about it? i would like to know any number theory conjecture by the types of undecidable.,['number-theory']
164960,Taking stalk of a product of sheaves,"Let $(\mathscr{F}_\alpha)_\alpha$ be a family of sheaves on $X$, and $\prod_\alpha\mathscr{F}_\alpha$ the product sheaf. If $x\in X$, is it true that
$$\left(\prod_\alpha\mathscr{F}_\alpha\right)_x\simeq\prod_\alpha(\mathscr{F}_\alpha)_x \ ?$$
I think $(\oplus_\alpha\mathscr{F}_\alpha)_x\simeq\oplus_\alpha(\mathscr{F}_\alpha)_x$ may be true, but not the product sheaf.","['sheaf-theory', 'algebraic-geometry']"
164963,Elements of finite order in $SL_2(\mathbb{Z})$,"Assume $A \in SL_2(\mathbb{Z})$ has finite order, and let $N_0 \in \mathbb{N}$ be the smallest natural number such that $A^{N_0} = I$. I want to show that the only possible values of $N_0$ are $1,2,3,4$ or $6$.  I have a proof, but I worry it is incomplete, so my (two part) question is:
$$
\text{Is the following proof correct? If not, where does the proof break down?}
$$$$
\text{Does there exist a proof using only first principles?  }
$$
Basically, my proof follows from Corollary 2.4 here , which says ""Any homomorphism $SL_2(\mathbb{Z}) \to \mathbb{C}^\times$ has image in the 12th roots of unity"" and Lagrange's theorem.  Namely, let $N_0$ be as above, and let $\phi: SL_2(\mathbb{Z}) \to \mathbb{C}^\times$ be a homomorphism.  Then, since $\phi(I) = 1$, 
$$
\phi(I)=\phi(A^{N_0}) = \phi(A)^{N_0} = 1.
$$
By Lagrange's theorem, and Corollary 2.4, $N_0 | 12$, so $N_0=1,2,3,4$ or $6$. 
\qed My trouble is that although $N_0$ is the order of $A$ in $SL_2(\mathbb{Z})$, it does \emph{not} need to be the order of $\phi(A)$ in the 12th roots of unity, in general, but I think I used this implicitly when I used Lagrange's theorem. If $\phi(A)^{N_0} = 1$ then all we can conclude is that the order of $\phi(A)$ divides $N_0$, not that it equals $N_0$. If we were still in $SL_2(\mathbb{Z})$, then this implies it does equal $N_0$ by assumption of minimality, but like I said, I don't see why this needs to hold in $\mathbb{C}^\times$. For exmaple, what's stopping $N_0 = 8$ while $\phi(A)$ has order 4 in the 12th roots of unity?  This doesn't seem to yield an immediate contradiction. Whether or not this proof is correct, I'd like to see how (if) my troubles can be resolved, and if a proof in this way can work.  I would also like to know if there is a proof using only the definition of $SL_2(\mathbb{Z})$, and perhaps some ingenuity, since I wouldn't consider Corollary 2.4 a standard fact (to, say, a beginning graduate student).","['matrices', 'group-theory', 'abstract-algebra']"
164964,Description of flipping tableau for inversions in reduced decompositions of permutations,"Short version: Is there a graphical description of the possible orders in which inversions can appear in a reduced decomposition of a permutation? Something akin to the definition of standard Young tableaux. Inversions of longest permutation version A permutation of degree $n$ is a bijection on $\{1,2,\cdots,n\}$.  An inversion of a permutation $\pi$ of degree $n$ is a pair $(i,j)$ such that $1 \leq i < j \leq n$ but $\pi(i) > \pi(j)$.  A reduced decomposition of a permutation $\pi$ of degree $n$ is an expression $\pi = g_1 \cdots g_m$ so that (1) each $g_k = (i,i+1)$ is an adjacent transposition for some $i$, (2) $m$ is the number of inversions of $\pi$. The longest element $\pi_0$ of degree $n$ is the permutation in which every pair is an inversion; $\pi_0 = (1,n)(2,n-1)\cdots$ is the ""reversal"". In a reduced decomposition, the set of inversions of $g_1 \cdots g_{k+1}$ has precisely one more element $u_k = \{i,j\}$ than the set of inversions of $g_1 \cdots g_k$. The flipping tabelau of the decomposition is the tableau whose $j,i$ entry is $k$ where $u_k=\{i,j\}$ with $i<j$. How does one describe all those possible flipping tableaux? In particular, it should be easy to tell if a tableaux is in fact flipping without exhaustively constructing the flipping tableaux of all reduced decompositions of the longest permutation and checking if it appears in the list. Example: If $n=3$, then $\pi_0 = [3,2,1] = (1,3)(2)$ takes $1$ to $3$ and back, leaving $2$ alone.  Its inversions are $\{ \{1,2\}, \{1,3\}, \{2,3\} \}$. A reduced decomposition is $\pi_0  = (1,2)(2,3)(1,2)$ and the prefix subwords are: $[1,2,3] = ()$ has no inversions $[2,1,3] = (1,2)$ has only one inversion: $\{\{1,2\}\}$ $[2,3,1] = (1,2)(2,3)$ has two inversions: $\{\{1,2\}, \{1,3\}\}$ $[3,2,1] = (1,2)(2,3)(1,2)$ has three inversions: $\{\{1,2\},\{1,3\},\{2,3\}\}$ The sequence $u_k$ is thus $\{1,2\}, \{1,3\}, \{2,3\}$, and so the flipping tableau is:
$$\begin{array}{ccc}
. & . & . \\
3 & . & . \\
2 & 1 & . \\
\end{array}$$ where empty boxes are listed as ""."" More Examples: By switching $(1,2)(2,3)(1,2)$ with $(2,3)(1,2)(2,3)$ we get the other possible flipping tableau for $n=3$: $$\begin{array}{ccc|ccc}
.&.&.&.&.&.\\
1&.&.&3&.&.\\
2&3&.&2&1&.\\
\end{array}$$ For $n=4$ there are 16 possible flipping tableaux: $$\small\begin{array}{cccc|cccc|cccc|cccc}
.&.&.&.&.&.&.&.&.&.&.&.&.&.&.&.\\
1&.&.&.&1&.&.&.&1&.&.&.&1&.&.&.\\
2&3&.&.&2&4&.&.&2&6&.&.&5&6&.&.\\
4&5&6&.&3&5&6&.&3&5&4&.&3&4&2&.\\ \hline
.&.&.&.&.&.&.&.&.&.&.&.&.&.&.&.\\
1&.&.&.&3&.&.&.&6&.&.&.&5&.&.&.\\
4&6&.&.&2&1&.&.&2&1&.&.&2&1&.&.\\
3&5&2&.&4&5&6&.&4&3&5&.&4&3&6&.\\ \hline
.&.&.&.&.&.&.&.&.&.&.&.&.&.&.&.\\
6&.&.&.&5&.&.&.&6&.&.&.&2&.&.&.\\
3&1&.&.&3&1&.&.&5&1&.&.&5&6&.&.\\
4&2&5&.&4&2&6&.&4&2&3&.&3&4&1&.\\ \hline
.&.&.&.&.&.&.&.&.&.&.&.&.&.&.&.\\
2&.&.&.&4&.&.&.&6&.&.&.&6&.&.&.\\
4&6&.&.&5&6&.&.&5&4&.&.&5&3&.&.\\
3&5&1&.&3&2&1&.&3&2&1&.&4&2&1&.\\
\end{array}$$ There are 768 possibilities for $n=5$, and 292864 possibilities for $n=6$.  This is OEIS:A005118 in general, but I don't see how my flipping tableaux are standard Young tableaux (rows are not monotonic, columns are not monotonic). Stanley also describes a similar set of tableaux, the balanced tableaux, which are put in bijection with reduced decompositions in Edelman–Greene (1987) .  However, I still don't see the connection with my flipping tableaux.","['coxeter-groups', 'group-theory', 'combinatorics']"
164974,"Open sets, topology","I don't understand why in the definition of a topology, you require the union of an ""arbitrary"" collection of open subsets to be open and the intersection of a ""finite"" number of open subsets to be open. That is, I don't get why one of them is arbitrary and the other is finite. Thanks!!",['general-topology']
164987,"Find $(x, a, b, c)$ if $x! = a! + b! + c!$","Find $(x, a, b, c)$ if $$x! = a! + b! + c!$$ I want to know if there are more solutions to this apart from $(x, a, b, c) = (3, 2, 2, 2)$.",['number-theory']
165013,Which number was removed from the first $n$ naturals?,"A number is removed from the set of integers from $1$ to $n$. Now, the average of remaining numbers turns out to be $40.75$. Which integer was removed? By some brute force, I got $61$. I want to know if there's any analytic approach?","['elementary-number-theory', 'means', 'summation', 'algebra-precalculus']"
165026,Limit of $\prod_{i=1}^n (1-1/2^i)$,"I am trying to find the limit of the sequence $$s_n:=\displaystyle \prod_{i=1}^n \left(1-\frac{1}{2^i} \right)$$ The sequence is decreasing and bounded below by $0$. I guess that the limit is $0$, is there any way to show this ? Or, is there any argument which shows that the limit is not zero ?",['sequences-and-series']
165038,"Finding $3$ distinct prime numbers $a| (bc+b+c)$, $b|(ac+a+c)$, $c|(ab+a+b)$","How to find $3$ prime numbers $a,b$ and $c$ such that:
$$a| (bc+b+c)$$
$$b|(ac+a+c)$$
$$c|(ab+a+b)$$",['number-theory']
165047,Evaluation of $\sum_{n=1}^\infty \frac{1}{\Gamma (n+s)}$,"I want to try and evaluate this interesting sum: $$\sum_{n=1}^\infty \frac{1}{\Gamma (n+s)}$$ where $0 \le s < 1$ WolframAlpha evaluates this sum to be $$\sum_{n=1}^\infty \frac{1}{\Gamma (n+s)} = e\left(1-\frac{\Gamma(s, 1)}{\Gamma(s)}\right)$$ Some notable cases of this sum would be when $s=0$ (producing the Taylor's series for $e$) and when $s=\frac{1}{2}$: $$\sum_{n=1}^\infty \frac{1}{\Gamma (n+\frac{1}{2})} = e \operatorname {erf}(1)$$ I would be very interested to know the steps of how one would evaluate this interesting sum.","['special-functions', 'sequences-and-series', 'gamma-function', 'mittag-leffler-function', 'error-function']"
165050,Exponentiating cubic functions (and so on),"The exponential distribution follows from exponentiating a linear function, while the normal distribution follows from exponentiating a quadratic function. Do the distributions that follow from exponentiating functions of 3rd or higher degree have names or uses?","['statistics', 'probability-distributions']"
165059,Find the sum of this series :$ \frac{1}{{1!2009!}} + \frac{1}{{3!2007!}} +  \cdots  + \frac{1}{{1!2009!}}$,"Find the sum of this series : $$\sum\limits_{\scriptstyle 1 \leqslant x \leqslant 2009  \atop 
  {\scriptstyle x+y=2010 \atop 
  \scriptstyle {\text{  }}x,y{\text{ odd}} }}  {\frac{1}{{x!y!}}}  = \frac{1}{{1!2009!}} + \frac{1}{{3!2007!}} +  \cdots  + \frac{1}{{1!2009!}}$$ I tried converting it into binomial coefficients and I'm getting sort of $\dfrac{2^{2009}}{2009!}$ Please help me.","['sequences-and-series', 'binomial-coefficients']"
165074,"A weak converse of $AB=BA\implies e^Ae^B=e^Be^A$ from ""Topics in Matrix Analysis"" for matrices of algebraic numbers.","It is a well known fact that if $A,B\in M_{n\times n}(\mathbb C)$ and $AB=BA$, then $e^Ae^B=e^Be^A.$ The converse does not hold. Horn and Johnson give the following example in their Topics in Matrix Analysis (page 435). Let $$A=\begin{pmatrix}0&0\\0&2\pi i\end{pmatrix},\qquad B=\begin{pmatrix}0&1\\0&2\pi i\end{pmatrix}.$$ Then $$AB=\begin{pmatrix}0&0\\0&-4\pi^2\end{pmatrix}\neq\begin{pmatrix}0&2\pi i\\0&-4\pi^2\end{pmatrix}=BA.$$ We have $$e^A=\sum_{k=0}^{\infty}\frac 1{k!}\begin{pmatrix}0&0\\0&2\pi i\end{pmatrix}^k=\sum_{k=0}^{\infty}\frac 1{k!}\begin{pmatrix}0^k&0\\0&(2\pi i)^k\end{pmatrix}=\begin{pmatrix}e^0&0\\0&e^{2\pi i}\end{pmatrix}=\begin{pmatrix}1&0\\0&1\end{pmatrix}.$$ For $S=\begin{pmatrix}1&-\frac i{2\pi}\\0&1 \end{pmatrix},$ we have $$e^B=e^{SAS^{-1}}=Se^AS^{-1}=S\begin{pmatrix}1&0\\0&1\end{pmatrix}S^{-1}=\begin{pmatrix}1&0\\0&1\end{pmatrix}.$$ Therefore, $A,B$ are such non-commuting matrices that $e^Ae^B=\begin{pmatrix}1&0\\0&1\end{pmatrix}=e^Be^A.$ It is clear that $\pi$ is important in this particular example. In fact, the authors say what follows. It is known that if all entries of $A,B\in M_n$ are algebraic numbers and $n\geq 2,$ then $e^A\cdot e^B=e^B\cdot e^A$ if and only if $AB=BA.$ No proof is given. How does one go about proving that?","['noncommutative-algebra', 'matrices', 'algebraic-number-theory', 'analysis', 'exponentiation']"
165081,Numerical range of an operator on Hilbert spaces.,"If $H$ is a Hilbert space and $T$ is in $\mathcal{L}(H)$, the numerical range of $T$ is defined by
$$W(T) := \left\{(Tx; x) \mid x \in H,\ \|x\| = 1 \right\}.$$
We have to prove that The point and residual spectrum are subsets of $W(T)$. The continuous spectrum is a subset of closure of $W(T)$. Please help me out, Thank you.","['hilbert-spaces', 'functional-analysis']"
165097,Does the specification of a general sequence require the Axiom of Choice?,"Many results in elementary analysis require some form of the Axiom of Choice (often weaker forms, such as countable or dependent). My question is a bit more specific, regarding sequences. For example, consider a standard proof of the boundedness theorem which states that a function continuous on a closed interval $I$ is bounded on that interval. In the first step of the proof, one specifies a sequence as follows: Suppose for contradiction that $f$ is unbounded. Then for every $n\in\mathbb{N}$ there exists $x_n$ such that $f(x_n) > n$. This specifies a sequence $(x_n)$. I'm not sure if the above example requires choice. To me, it certainly feels like it does. More specifically, I think that we are specifying a sequence of sets $$A(n) = \left\{x\in I\mid f(x) > n\right\}$$ and claiming the existence of a choice function $g$ such that $g(n) \in A(n)$ so that this example specifically requires the axiom of countable choice. Please clarify whether my reasoning is correct. More specifically, does the construction of any general sequence (such as one defined as above, or perhaps recursively) then require some form of choice? Thanks for any help.","['set-theory', 'axiom-of-choice', 'real-analysis', 'analysis']"
165105,Non-$C^{*}$ Banach algebras?,"It suddenly occurred to me almost every Banach algebra I know is actually a $C^{*}$ algebra. Several kinds of function algebras are definitely $C^{*}$ algebras. So is the matrix algebra. Although one gets a non-$C^*$ algebra by focusing on the upper triangular matrices, the norm still satisfies the $C^*$ identity. The algebra of operators on a general banach space is not $C^*$, but at least for me this is a too abstract class that do not provide much intuition. Thus I wonder whether someone has some good examples of banach algebras that fail the $C^*$ identity but are on the other hand elementary enough to provide intuition and direct computation, like the function algebras. Thanks!","['operator-algebras', 'banach-algebras', 'functional-analysis']"
165116,Odd-dimensional complex skew-symmetric matrix has eigenvalue $0$,"There is the standard proof using $$\det(A)=\det( A^{T} ) = \det(-A)=(-1)^n \det(A)$$ 
I would like a proof that avoids this. Specifically, there is the proof that for $A$ a $\bf{real} $ matrix, the transpose is the same as the adjoint, which gives (using the complex inner product) $\lambda \|x\|^2 =\langle  Ax, x \rangle= \langle  x, -Ax \rangle=-\overline{\lambda } \|x\|^{2}$, so any eigenvalue is purely imaginary. Then we conclude that, since any odd-dimensional real matrix has a real eigenvalue, that eigenvalue must be zero.  This argument doesn't work for a general complex skew-symmetric matrix.  Is there something I'm missing, is there a way to modify this argument to get that zero is an eigenvalue for the complex case?  Also, can somebody please give a geometric reason why odd-dimensional skew-symmetric matrices have zero determinant (equiv., a zero eigenvalue)? Thanks!","['linear-algebra', 'eigenvalues-eigenvectors']"
165118,How does partial fraction decomposition avoid division by zero?,"This may be an incredibly stupid question, but why does partial fraction decomposition avoid division by zero?  Let me give an example: $$\frac{3x+2}{x(x+1)}=\frac{A}{x}+\frac{B}{x+1}$$ Multiplying both sides by $x(x+1)$ we have: $$3x+2=A(x+1)+Bx$$ when $x \neq -1$ and $x \neq 0$. What is traditionally done here is $x$ is set to $-1$ and $0$ to reveal:
$$-3+2=-B \implies 1=B$$
and 
$$2=A$$ so we find that $$\frac{3x+2}{x(x+1)}=\frac{2}{x}+\frac{1}{x+1}$$ Why can $x$ be set equal to the roots of the denominator (in this case, $0$ and $-1$) without creating a division by zero problem?","['calculus', 'algebra-precalculus', 'rational-functions', 'partial-fractions', 'polynomials']"
165136,Prove tensor product of two multilinear forms is commutative only if one of them is zero,Prove $L \otimes M = M \otimes L$ only if either $L=0$ or $M=0$ I saw this statement on Linear Algebra (2ed) written by Hoffman and Kunze. I can't figure out how to prove it. The multilinear forms $L$ (and $M$) are from $V^r$ (and $V^s$) into $K$ where $K$ is a commutative ring with identity and $V$ is a $K$-module. I think it is reasonable to exclude $L=M$. Thanks. Added by the crowd. Here's the relevant excerpt.,"['tensor-products', 'linear-algebra', 'abstract-algebra']"
165137,Antiderivative of $x \mapsto \operatorname{tr}\{(\mathbf{A}x+\mathbf{B})^{-1}\mathbf{C}\}$,"I am wondering how to integrate the function $$x \mapsto \operatorname{tr}\bigl\{(\mathbf{A}x+\mathbf{B})^{-1}\mathbf{C}\bigr\}$$ In my case, the matrices $\mathbf{A}$, $\mathbf{B}$, $\mathbf{C}$ are (strictly) positive definite. If $\mathbf{C} = \mathbf{A}$ it is easy to see that $$\ln\det(\mathbf{A}x+\mathbf{B})$$ is an antiderivative. But what if $\mathbf{C} \neq \mathbf{A}$? Thanks, jens","['matrices', 'improper-integrals', 'calculus', 'integration']"
165154,"a) Prove that $f$ has a removable singularity if $f'$ does; b) Evaluate $\int_0^\infty\frac{\log x}{(1+x)^3}\,dx$","a) Let $\,f\,$ be an analytic function in the punctured disk $\,\{z\;\;;\;\;0<|z-a|<r\,\,,\,r\in\mathbb R^+\}\,$ . Prove that if the limit $\displaystyle{\lim_{z\to a}f'(z)}\,$ exists finitely, then $\,a\,$ is a removable singularity of $\,f\,$ My solution and doubt: If we develop $\,f\,$ is a Laurent series around $\,a\,$ we get
$$f(z)=\frac{a_{-k}}{(z-a)^k}+\frac{a_{-k+1}}{(z-a)^{k-1}}+\ldots +\frac{a_{-1}}{z-a}+a_0+a_1(z-a)+\ldots \Longrightarrow$$
$$\Longrightarrow f'(z)=-\frac{ka_{-k}}{(z-a)^{k+1}}-\ldots -\frac{a_{-1}}{(z-a)^2}+a_1+...$$
and since $\,\displaystyle{\lim_{z\to a}f'(z)}\,$ exists finitely then it must be that
$$a_{-k}=a_{-k+1}=...=a_{-1}=0$$
getting that the above series for $\,f\,$ is, in fact, a Taylor one and thus $\,f\,$ has a removable singularity at $\,a\,$ . My doubt: is there any other ""more obvious"" or more elementary way to solve the above without having to resource to term-term differentiating that Laurent series? b) Evaluate, using some complex contour, the integral 
$$\int_0^\infty\frac{\log x}{(1+x)^3}\,dx$$ First doubt: it is given in this exercise the hint(?) to use the function
$$\frac{\log^2z}{(1+z)^3}$$Please do note the square in the logarithm! Now, is this some typo or perhaps it really helps to do it this way? After checking with WA, the original real integral equals $\,-1/2\,$ and, in fact, it is doable without need to use complex functions, and though the result is rather ugly it nevertheless is an elementary function (rational with logarithms, no hypergeometric or Li or stuff). The real integral with the logarithm squared gives the beautiful result of $\,\pi^2/6\,$ but, again, I'm not sure whether ""the hint"" is a typo. Second doubt: In either case (logarithm squared or not), what would be the best contour to choose? I though using one quarter of the circle $\,\{z\;\;;\;\;|z|=R>1\}\,$ minus one quarter of the circle $\,\{z\;\;;\;\;|z|=\epsilon\,\,,0<\epsilon<<R\}\,$,  in the first quadrant both, because $(i)\,$ to get the correct limits on the $\,x\,$-axis when passing to the limits $\,R\to\infty\,\,,\,\epsilon\to 0\,$ $(ii)\,$ To avoid the singularity $\,z=0\,$ of the logarithm (not to mention going around it and changing logarithmic branch and horrible things like this!). Well, I'm pretty stuck here with the evaluations on the different segments of the path, besides being baffled by ""the hint"",  and I definitely need some help here. As before: these exercises are supposed to be for a first course in complex variable and, thus, I think they should be more or less ""elementary"", though this integral looks really evil. For the time you've taken already to read this long post I already thank you, and any help, hint or ideas will be very much appreciated.",['complex-analysis']
165164,Functions between topological spaces being continuous at a point?,"Given metric spaces $B$ and $P$, a function $q: B \to P$ is continuous at $c \in B$ if for every $\epsilon > 0$, there exists $\delta > 0$ such that $$d_B(x, c) < \delta \implies d_P(q(x), q(c)) < \epsilon$$ But if $B$ and $P$ happen to be topological spaces, $q$ is continuous if the preimage of every open subset of $P$ is open in $B$.  So in this case, what would it mean for $q$ to be continuous at $c \in B$?","['general-topology', 'analysis']"
165169,Using Khinchin's inequality,"At the end of page 5 of the Tao's lectures notes , he sets $\psi$ a Schwartz function supported on the unit cube $[0,1]^n$ and choose $f(x)=\sum_{k=1}^N\epsilon_k\psi(x-ke_1)$, where $e_1$ is one of the basis vectors of $\mathbb{R}^n$, $N$ is a large integer and $\epsilon_k$ are a collection of independent identically distributed signs $\epsilon_k=\pm1$. We have $\|f\|_p\sim N^{1/p}$ (here $A\sim B\Leftrightarrow A\lesssim B$ and $B\lesssim A$, where $A\lesssim B$ means that there is C such that $A\leq C.B$.) Using the Khinchin inequality: If $f_1,\ldots,f_N$ are a collection of functions and $\epsilon_k$ are randomized signs, then for any $1<p<\infty$ we have $$E(\|\sum_{k=1}^N\epsilon_kf_k\|_p^p)\sim \|(\sum_{k=1}^N|f_k|^2 )^{1/2}\|_p^p,$$
where the constants in the $\sim$  symbol are independent of $N$ and $f_k$ and $E$ denotes the expectation, we see that $$E(\|\hat{f}\|_q^q)\sim \|(\sum_{k=1}^N|\hat{\psi}(\xi)e^{2\pi ik\xi_1}|^2)^{1/2}\|_q^q\sim N^{q/2}.$$ I don't understand the following statement: there must exist some choice of signs for which $\|\hat{f}\|_q\gtrsim N^{1/2}$. Help me, please?","['fourier-analysis', 'probability', 'analysis']"
165171,Set of convergence is measurable. [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: pointwise convergence in $\sigma$-algebra Problem: Prove that the set of points at which a sequence of measurable real functions converges is a measurable set. (I believe the problem means functions from the reals to the reals.) Source: W. Rudin, Real and Complex Analysis , Chapter 1, exercise 5. I have posted a proposed solution in the answers.",['measure-theory']
165176,"Hensel lifting square roots $\!\bmod p\,$ to $\!\bmod p^2$","I've been working on this problem for a while, but hit a dead end. Here's the problem: Suppose $p$ is an odd prime. Also let $b^2 \equiv a \pmod p$ and $p$ does not divide $a$. Prove there exists some $k \in \mathbb{Z}$ such that $(b+kp)^2 \equiv a \pmod {p^2}$. Here's what I've tried so far: $$(b+kp)^2 \equiv b^2 + 2bkp + k^2p^2 \equiv a \pmod {p^2}$$ Here, I need to find such $k$ that satisfy this congruence. Equivalently, I need to find such $k$ so that $p^2$ divides $(b^2-a) + 2bkp + p^2k^2$ or equivalently show that $p^2$ divides $(b^2-a) + 2bkp$ for some $k \in \mathbb{Z}$. So far, since $p$ divides $(b^2-a)$, then by definition, there exists some $x \in \mathbb{Z}$ such that $b^2-a = px$. I got stuck here, and I've tried some examples, but I haven't seen any pattern that pertains to this problem. Any insight would be helpful.","['faq', 'hensels-lemma', 'elementary-number-theory', 'number-theory']"
165184,Burnside's Lemma,"I've been trying to understand what Burnside's Lemma is, and how to apply it, but the wiki page is confusing me. The problem I am trying to solve is: You have 4 red, 4 white, and 4 blue identical dinner plates. In how
  many different ways can you set a square table with one plate on each
  side if two settings are different only if you cannot rotate the table
  to make the settings match? Could someone explain how to use it for this problem, and if its not too complicated, try to explain to me what exactly it is doing in general?","['puzzle', 'combinatorics']"
165194,Why is the absence of zero divisors not sufficient for a field of fractions to exist?,"I've recently begun to read Skew Fields: The General Theory of Division Rings by Paul Cohn. On page 9 he writes, Let us now pass to the non-commutative case. The absence of zero-divisors is still necessary for a field of fractions to exist, but not sufficient. The first counter-example was found by Malcev [37], who writes down a semigroup whose semigroup ring over $\mathbb{Z}$ is an integral domain but cannot be embedded in a field. Malcev expressed his example as a cancellation semigroup not embeddable in a group, and it promped him to ask for a ring $R$ whose set $R^\times$ of nonzero elements can be embedded in a group, but which cannot itself be embedded in a field. The cited paper [37] is On the immersion of an algebraic ring in a skew field , Math. Ann 113 (1937), 686-91. (EDIT by M.S: doi: 10.1007/BF01571659 , GDZ .) I've had no luck finding this freely available online, nor at the library. Does anyone have reference to this paper, or at least the part where Malcev demonstrates these two parts of his counter-example? I would greatly appreciate seeing it. Thanks.","['ring-theory', 'reference-request', 'abstract-algebra']"
165195,Solving ODE and finding maxima,"Consider the initial value problem $y' + 5y = 5t, y(0) = y_0$.  Find
  the value of $y_0$ for which the solution touches, but does not cross,
  the $t$-axis. This is linear first order DE, so I found integrating factor=$e^{(2/3)t}$ 
Solving ODE I got, $y=\frac{21}{8}-\frac{3}{4}t+Ce^{(-2/3)t}$
Using, $y(0)=y_0$, we get $C=y_0-\frac{21}{8}$.
Now, if we take first derivative of the solution function $y$ to find the point where it has zero slope, we end up with two unknown in the equation, $y_0$ and $t$.
$y'=\frac{-3}{4}+\frac{-2}{3}(y_0-\frac{21}{8})e^{-(2/3)t}=0.$",['ordinary-differential-equations']
165215,Prove that $\frac{1}{\sin^2 z } = \sum\limits_{n= -\infty} ^ {+\infty} \frac{1}{(z-\pi n)^2} $,"I have the following problem: Find the constants $c_n$ so that 
$$ \frac{1}{\sin^2 z } = \sum_{n= -\infty} ^ {+\infty} \frac{c_n}{(z-\pi n)^2} $$
and the series converges uniformly on every bounded set after dropping finitely many terms. Justify all your claims.
Hint: Use Liouville's theorem to prove the equality. Let $c_n = 1 $ for all $n$. Let $\displaystyle f(z) := \frac{1}{\sin^2 z}$ and $\displaystyle g(z) := \sum_{n= -\infty} ^ {+\infty} \frac{1}{(z-\pi n)^2} $. Begin by showing that $h$ is an analytic function which converges uniformly on compact subsets of $\mathbb{C} \backslash \mathbb{Z}$. Suppose $K$ is a compact set which contains no integers. Define 
$$ \delta_n = \inf_{z \in K} |\pi-z/n| =\frac{1}{n} \inf_{z \in K} |\pi n-z|, $$
where the infimum exists because $K$ is compact. Also, compactness implies boundedness. Thus as $n \to \pm \infty$, we have $\delta_n \to \pi$. Therefore, for sufficiently large $n$, we have $\delta_n > 2$, and 
$$ \frac{1}{|z \pm n | ^2} \leq \frac{1}{\delta_n ^2 n^2} < \frac{1}{4n^2}. $$
By the Weierstrass M-test, $g$ converges absolutely uniformly on $K$. Since each term is analytic on $K$, we conclude that the series converges to an analytic function on $\mathbb{C} \backslash \mathbb{Z}$. Clearly the only poles of $g(z)$ are at $\pi n$ for each integer $n$, with corresponding principal part $\frac{1}{(z-\pi n)^2}$. For each integer $n$, we have $\sin^2 (\pi n) = \frac{d}{dz} \sin^2(\pi n) = 0$ and $\frac{d^2}{dz^z} \sin^2 (\pi n) \neq 0$, so $f(z) = 1/ \sin^2 (z)$ also has a pole of order two at each integer multiple of $\pi$, and no other poles. Furthermore, the principal part of $f(z)$ is, using the Laurent formulas and contour integration, equal to $\displaystyle \frac{1}{(z-n\pi)^2}$. Thus $h(z) := f(z)-g(z)$ has removable singularities at the points $n\pi$. Note that both $f$ and $g$ are periodic with period $\pi$. That is, 
$$ f(z) = f(z +\pi) \quad \text{ and } \quad g(z) = g(z+\pi) \quad \text{ for all } z \in \mathbb{C}\backslash\mathbb{Z}. $$
Thus, since $h$ is bounded on the square $\{ z: |\operatorname{Re} z| < \pi, |\operatorname{Im} z |< \pi \}$ and periodic, we may conclude that $h$ is bounded on the set $\{ z: |\operatorname{Im} z |< \pi \}$. To show boundedness on the entire plane, we show that it holds on the vertical strip (with center removed) 
$$ S = \{ z: 0 \leq \operatorname{Re} z \leq \pi, | \operatorname{Im} z | \geq \pi \}. $$ 
For $z$ in $S$,
\begin{align*} 
\sum_{n= -\infty} ^ {+ \infty} |z-\pi n | ^{-2} 
&= \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(x-\pi n)^2 + y^2}  
&\leq \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(\pi (n-1))^2 +y^2}  
\end{align*}
\begin{align*}
& = \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(\pi n)^2 +y^2}  
&< 2\sum_{n=0} ^ {+ \infty} \frac{1}{(\pi n)^2 +y^2}  
&\leq 2\sum_{n=0} ^ {+ \infty} \frac{1}{(\pi n)^2 +\pi ^2}. 
\end{align*} 
Thus $g$ is bounded on the set. It is easy to show that $f$ is also bounded on $S$. Thus the difference $f-g$ is also bounded. By the periodicity of $h$, the function is bounded on the entire plane, and is constant by Liouville's theorem. I'm wondering if my reasoning so far is valid; and if so, how to show that the relevant constant is in fact zero. Thanks.",['complex-analysis']
165226,Example of an infinite sequence of irrational numbers converging to a rational number?,"Are there any nice examples of infinite sequences of irrational numbers converging to rational numbers? One idea I had was the sequence: $ 0.1001000010000001\cdots,0.1101000110000001\cdots,\cdots,0.1111000110000001\cdots,$ etc. Where the first term in the sequence has ones in the place $i^2$ positions to the right of the decimal point. $(i=1,2,3,\dots)$ For the second term, we keep all the ones from the first term and add one in place of the first zero after the decimal point. We then add ones $i^3$ places after the decimal point. (The logical sum 1+1=1, i.e a number $i^2=j^3$ spaces after the decimal place has the value 1). It is clear that this will converge to $1/9$, and I don't think the decimal expansion repeats at all.",['sequences-and-series']
165260,A lemma about extension of function,"Definition Suppose that $f(M)$ is a $\mathcal C^n$-function whose domain is $\mathcal X$. If $f^*(M)$ is a $\mathcal C^n$-function whose domain is $\mathcal X^*$, and $f(M)=f^*(M)$ whenever $M\in\mathcal X\cap\mathcal X^*$, we call that $f^*$ is an ($\mathcal C^n$-)extension of $f$, and $f$ is ($\mathcal C^n$-)extended into $\mathcal X^*$. Lemma Given that $f(x,y)$ is $\mathcal C^n$ ($n\ge1$) function on some bounded open set $\mathcal M\subset\Bbb R^2$, whose boundary is $\mathcal L$, and for each point on $\mathcal L$, there's a neighborhood into which $f$ could be $\mathcal C^n$-extended. We conclude that $f$ could be extended into $\Bbb R^2$. Source Григорий Михайлович Фихтенгольц I found that the proof on the book was so complicated for me to understand, so I'm looking for some explanation, as intuitive as possible. Can anyone help me? Thanks a lot!","['multivariable-calculus', 'calculus', 'real-analysis']"
165261,Deriving the Formula for Average Speed (Same distance).,"Let me start of by specifying the question: A and B are two towns. Kim covers the distance from A to B on a scooter at 17Km/hr and returns to A on a bicycle at 8km/hr.What is his average speed during the whole journey. I solved this problem by using the formula (since the distances are same): $$ \text{Average Speed (Same distance)} = \frac{2xy}{x+y} = \frac{2\times17\times8}{17+8} =10.88 \text{Km/hr}$$ Now I actually have two questions: Q1- I know that $$ Velocity_{Average}=  \frac{\Delta S }{\Delta T} $$
Now here does $$\Delta S$$ represent $$ \frac{S_2+S_1 }{2} \,\text{or}\, S_2-S_1 ?$$ Where S2 is the distance covered from point A to point B and S1 is the distance covered from point B to point A Q2. How did they derive the equation:
$$ Velocity_{Average(SameDistance)} = \frac{2xy}{x+y} $$ Could anyone derive it by using 
$$ Velocity_{Average}=  \frac{\Delta S }{\Delta T} $$",['algebra-precalculus']
165262,Going in the direction of the gradient,"First, a motivating example. Suppose $f(x)$ is convex, differentiable, with a single minimum $x^*$. Then the differential equation $$\dot{x}(t) = -\nabla f(x(t))$$ drives $x(t)$ to $x^*$. Now my question is about a generalization of this. Let $f(x), g(x)$ be two smooth convex functions and let ${\cal G}$ be the set of minima of $g(x)$, which we assume to be nonempty. Consider the differential equation 
$$ \dot{x}(t) = - \frac{1}{t} \nabla f(x(t)) - \nabla g(x(t))$$ Is it true that this equation drives $x(t)$ to the minimum of $f(x)$ on ${\cal G}$? If not, would it be true if we replaced $1/t$ by a different function, say one which perhaps decays slower or faster? This statement seems to be true in a few simple examples I tried. For example, taking $g(x)=(x_1+x_2-2)^2$ and $f(x)=x_1^2+x_2^2$ and solving the resulting equation numerically, I do get that solutions seem to approach $(1,1)$. Update: I asked this question on MO and received a solution. Unfortunately, the solution was given at a level of mathematical maturity that exceeds my own and I am unable to fill in the details of the arguments. Asking the answerer a followup question has not really clarified matters. I am hoping that someone here on could fill in the details.","['optimization', 'convex-analysis', 'ordinary-differential-equations', 'convex-optimization']"
165295,Finding area of triangle,"if the sides of the triangle are given by 20 cm, 30 cm, and 60 cm find the area of the triangle. I tried a long time. 
Apparently, Heron's formula does not seem to work $\sqrt{s(s-a)(s-b)(s-c)}$ where $s = (a+b+c)/2$ In the above problem $s=55$ and thus we end up with a negative number inside square root. I am not sure if there is any other formula to be applied to this problem .","['geometry', 'triangles']"
165299,Failure of uniqueness for linear ODE,"Let's say we have a linear ODE  with polynomial coefficients $p_j(x)$:
$$
p_n(x) y^{(n)}(x)+\dots+p_1(x)y'(x)+p_0(x)y=0
$$
and let's say $x_0$ is a root of $p_n(x)$. What can be said about uniqueness of the IVP for this ODE at $x_0$? In particular, if I succeeded to prove that an analytic solution $y_0(x)$ satisfies $y_0(x_0)=y'(x_0)=\dots=y^{(n-1)}(x_0)=0$, does it necessarily follow that $y_0(x)\equiv 0$?",['ordinary-differential-equations']
165306,Problem book on differential forms wanted,"I want to get used to differential forms. Thus I would like to solve a bunch of problems, especially on integration of differential forms. So I need a collection of problems with answers/solutions, starting from really elementary ones. No theorem proving, just straightforward calculations.","['differential-forms', 'reference-request', 'differential-geometry']"
165318,"Separatedness of a composition, where one morphism is surjective and universally closed.","I'm stuck with the following problem:
Let $f:X \rightarrow Y$ and $g:Y \rightarrow Z$ be scheme morphisms such that f is surjective and universally closed and such that $g \circ f$ is separated. The claim is then that g is also separated. I've been trying to use the fact that f is (as any surjective morphism) universally surjective, and somehow deduce that the diagonal $\Delta(Y)$ is closed in $Y \times_Z Y$ but I haven't gotten that far. I would love some hints on how to do this. Full answers are OK, but I would prefer to have hints!
Thank you!",['algebraic-geometry']
165341,Any  group of order four is either cyclic or isomorphic to $V$,"I will try and show that if our group $G$ is not cyclic then it is isomorphic to Klein's four-group $V$ . So suppose $G$ is not cyclic. Then its elements, excluding $e$, are of order $3$ or $2$. Supposing there is an element of order $3$ gives three distinct elements $g, g^2, g^3$. By hypothesis there exists  $h \in G$ such that $h$ is distinct from these three elements. So we can make $gh$ which must be equal to one of the elements previously mentioned. Setting this equal to the various elements: \begin{align}
&gh=g \Rightarrow h=e && gh=g^2 \Rightarrow h=g & \\
&gh=h \Rightarrow g=e, && gh=g^3 \Rightarrow h=g^2 &
\end{align}
Each of which is a contradiction.
Therefore all the elements are of order two and we can get an isomorphism between $G$ and $H \times H$ where $ H$ is cyclic of order two. But this direct product is isomorphic to Klein's four-group so $G$ is isomorphic to $V$. Is this correct? Also it is just given in the book that $V$ is isomorphic to this product; how do I show this without checking that $f(gh)=f(g)f(h)$ for all combinations?","['finite-groups', 'group-theory']"
165370,Moment Generating Function for Sum of Independent Random Variables,"I'm taking a graduate course in probability and statistics using Larsen and Marx, 4th edition and looking specifically at estimation methods this week.  I ran into a homework problem that is related to moment generating functions and I can't quite connect the dots on how they arrived at the solution. If you have three independent random variables $$Y_{1}, Y_{2}, Y_{3}$$ and you would like to determine the moment-generating function of $$W = Y_{1} + Y_{2} + Y_{3}$$ knowing that each of the three independent random variables have the same pdf $$f_{y} = \lambda y e^{-\lambda y}, y \geq 0$$ The easy part of the this problem is applying the theorem that says for $$W = W_{1} + W_{2} + W_{3}$$ the moment generating function of the sum is: $$M_{W}(t) = M_{W_{1}}(t)* M_{W_{2}}(t)* M_{W_{3}}(t)$$ Where I run into trouble is getting the individual moment generating functions for the Y's.   The problem directs you to apply yet another theorem where you would let, for example, another random variable V equal to $$aY_{1}+b$$ and it follows that $$M_{V}(t) = e^{bt}M_{W}(at)$$ The solution states that if you allow $$V = (1/\lambda)*W$$ then the pdf of V then becomes $$f_{V}(y) = ye^{-y}, y \geq 0$$ and subsequently, you can get the moment generating function using a simple integration by parts but I can't quite follow the application of the theorem used to get to the pdf of V. Any insight?  Likely a fundamental property I missed along the way...",['probability-theory']
165387,Family of distributions preserved under summing or product of their random variables,"I wonder what families of distributions can satisfy that the sum of their any
two random variables still have a distribution in the same family? what families of distributions can satisfy that the product of their
any two random variables still have a distribution in the same
family? My questions arose when I read this reply The sum of normal (Cauchy, Levy) random variables is normal (Cauchy,
  Levy). The sum of gamma random variables is gamma if the distributions have a common scale parameter. The product of log-normal random variables is log-normal. I know it is not true that the sum of two normal distributed random variables is still normally distributed. For example, if $X$ is normally distributed, define $Y$ to be $X$ if $|X| > c$ and $Y = −X$ if $|X| < c$, where $c > 0$. Then $X+Y$ is not normally distributed. I am not sure how to verify if the other claims are right or not. What can be say about a family of distribution that satisfies the above requirements? Thanks and regards!",['probability']
165402,Solving $y'' - \frac{1}{x} y' + (1+\frac{\cot x}{x}) y = 0$ by rank reduction,"With the substitution $$y(x) = \sin x \int u(x) \, dx\tag{*}$$ I managed to get to$$u'(x) = \left(\frac{1}{x}-2\cot x\right)u(x)$$ Solving which gave me $$u(x) = C_1 \frac{x}{\sin^2 x}$$
Inserting that back into $(*)$ $$y(x) = (\sin x) C_1\int \frac{x}{\sin^2 x} \, dx = (\sin x) C_1 \left(\log(\sin x) - \frac{x}{\cot x} + C_2\right)$$ Which doesn't seem to be the correct solution(s). I don't know where I went wrong though.","['ordinary-differential-equations', 'analysis']"
165404,Finding Limits of Trig Functions: $\lim_{\theta \rightarrow 0}\frac {\sin^2\theta}{\theta}$,"I am asked find the following limit $$\lim_{\theta \rightarrow 0}\frac {\sin^2\theta}{\theta}$$ I recognize that $$\lim_{\theta \rightarrow 0}\frac{\sin\theta}{\theta}=1$$ But because I have $sin^2\theta$ in the numerator, I am left with... $$\lim_{\theta \rightarrow 0}1(\sin\theta)$$ When I think about what this implies, I reason that the ratio of the opposite side over hypotenuse of the angle $\theta$ must approach approach zero, but for this to happen the opposite side would have a value of zero, which means the triangle formed would have no x component. $$\lim_{\theta \rightarrow 0}1(\sin\theta)=0$$ Is my reasoning correct? Am I thinking about this question in a constructive manner?","['trigonometry', 'calculus', 'limits']"
165407,Name Drawing Puzzle,"There is a party with 20 people, and everyone writes their name down
  on a piece of paper and puts it into a bag. The bag is mixed up, and
  each person draws one piece of paper. If you draw the name of someone
  else, you are considered to be in his ""group"". What is the expected
  number of groups after everyone draws? So basically if we have a loop where each person draws someone else's name, and the last person draws the first person in that list's name, we have a group. Not quite sure how to approach this problem. Thanks for any help.","['puzzle', 'probability', 'harmonic-numbers']"
165421,Lexicographical order - posets vs preorders,"I found the following definition for lexicographical ordering on Wikipedia (and similar definitions in other places): Given two partially ordered sets $A$ and $B$, the lexicographical order on the Cartesian product $A \times B$ is defined as $(a,b) \le (a',b')$ if and only if $a < a'$ or ($a = a'$ and $b \le b'$). The result is a partial order. If $A$ and $B$ are totally ordered, then the result is a total order as well. Does this definition work equally well if $A$ and $B$ are preorders, rather than posets? In other words, does the anti-symmetric property of the ordering relations on A and B make any difference here?","['relations', 'elementary-set-theory', 'order-theory']"
165422,Largest number that divides $n^2(n^2 - 1)(n^2 - n - 2)$ for all $n$,Obtain the greatest natural that divides $n^2(n^2 - 1)(n^2 - n - 2)$ for all natural numbers $n$. What should be the approach in these type of questions? Should I equate with prime factorization $2^a 3^b 5^c \cdots$ etc?,"['algebra-precalculus', 'number-theory']"
165428,$\{f_n\}$ continuous such that $\inf f_n$ and $\sup f_n$ are not continuous,"Find a sequence of continuous functions on $[0,1]$, $\{f_n\}$, such that $f(x):=\sup\{f_n(x):n\geq 1\}$ and $g(x):=\inf\{f_n(x):n\geq 1\}$ are both not continuous. I kept finding examples where one was discontinuous but the other was continuous like $f_n(x)=|x|^\frac{1}{n}$ and $f_n(x)=x^n$",['real-analysis']
165432,"Let $Y$ be an ordered set in the order topology with $f,g:X\rightarrow Y$ continuous, show that $\{x:f(x)\leq g(x)\}$ is closed in $X$","Let $Y$ be an ordered set in the order topology with $f,g:X\rightarrow Y$ continuous.  Show that the set $A = \{x:f(x)\leq g(x)\}$ is closed in $X$. I am completely stumped on this problem.  As far as I can tell I've either got the task of proving $A$ gathers its limit points, or showing that there is a closed set $V \subset Y$ such that $f^{-1}(V)$ or $g^{-1}(V)$ is equal to A, which would prove $A$ closed since both $f$ and $g$ are continuous. The latter strategy seems like the more likely to succeed.  Unfortunately I can't find any way of constructing this set $V$.  The fact that I don't know if $f$ or $g$ are injective means I keep running into the problem of having $f^{-1}(V)$ or $g^{-1}(V)$ give me extra points not in $A$.  And even if I were able to construct $V$ this wouldn't guarantee it was closed. I suspect I may need to use the continuity of both $f$ and $g$ together in some way but I can't see how.  Can anyone give me some guidance on this problem? Thanks.","['general-topology', 'order-topology']"
165434,How to prove if a function is bijective?,"I am having problems being able to formally demonstrate when a function is bijective (and therefore, surjective and injective). Here's an example: How do I prove that $g(x)$ is bijective? \begin{align}
f &: \mathbb R \to\mathbb R \\
g &: \mathbb R \to\mathbb R \\
g(x) &= 2f(x) + 3
\end{align} However, I fear I don't really know how to do such. I realize that the above example implies a composition (which makes things slighty harder?). In any case, I don't understand how to prove such (be it a composition or not). For injective, I believe I need to prove that different elements of the codomain have different preimages in the domain . Alright, but, well, how? As for surjective, I think I have to prove that all the elements of the codomain have one, and only one preimage in the domain , right? I don't know how to prove that either! EDIT f is a bijection. Sorry I forgot to say that.",['functions']
165443,Finding horizontal tangents for trig function,"I am asked to find the points on the curve at white the tangent is horizontal, for the function: $$y=\frac{\cos x}{2+\sin x}$$ To find the points at which the tangent is horizontal, I need to know what values will result in the derivative of the function equaling zero, so I differentiate using quotient rule: $$y'=\frac{(-2\sin x-\sin^2 x)-\cos^2 x}{(2+\sin x)^2}$$ The algebra in simplifying the derivative from here is what is holding be back. Also, have I differentiated this correctly?","['trigonometry', 'calculus']"
165472,Poincaré Lemma Contractible Hypothesis,"Poincaré's Lemma is often stated as saying that a closed differential form on a star-shaped domain is exact. More generally, it is true that a closed differential form on a contractible domain is exact. What I am wondering is if there is an easy example of a closed differential form on a simply connected domain which is not exact.","['differential-topology', 'differential-forms', 'differential-geometry']"
165496,Actually calculating an Intersection of Variety and Divisor,"This has been bugging me for a while now. Say I have a projective variety given by some polynomial $P$ and the canonical divisor of the projective space. How can I concretly calculate the Intersection of the two? And by concretly I mean, actually get a result that is not purely abstract? (Like actual Intersection points, degree, etc...)","['intersection-theory', 'algebraic-geometry']"
165503,Is the zero map (between two arbitrary rings) a ring homomorphism?,"I was looking at the definition under Wikipedia , which states that for arbitrary rings $R,S$, a ring homomorphism $f:R\to S$ must satisfy $f(1)=1.$ Here, I assume they mean $1$ as the multiplicative identity. Certainly then, this implies the zero map is not a ring homomorphism? This seems somehow intuitionally false; that is, we would want the zero map to be a ring homomorphism, as it is a group homomorphism between groups, a continuous function between reals, a smooth function between manifolds, etc. Could someone help explain why the zero map in the category of rings seems to be an exception to this pattern?","['ring-theory', 'abstract-algebra']"
165513,When will these two trains meet each other,"I cant seem to solve this problem. A train leaves point A at 5 am and reaches point B at 9 am. Another train leaves point B at 7 am and reaches point A at 10:30 am.When will the two trains meet ? Ans 56 min Here is where i get stuck.
I know that when the two trains meets the sum of their distances travelled will be equal to the total sum , here is what I know so far Time traveled from A to B by Train 1 = 4 hours Time traveled from B to A by Train 2 = 7/2 hours Now if S=Total distance from A To B and t is the time they meet each other then $$\text{Distance}_{\text{Total}}= S =\frac{St}{4} + \frac{2St}{7} $$ Now is there any way i could get the value of S so that i could use it here. ??",['algebra-precalculus']
165515,How to find $ \lim\limits_{ x\to 100 } \frac { 10-\sqrt { x } }{ x-100 }$,Find $ \lim\limits_{ x\to 100 } \dfrac { 10-\sqrt { x } }{ x-100 }$ (without using a calculator and other machines...?),"['calculus', 'limits']"
165521,There is some intuitive idea of Pascal's 's theorem in Projective Geometry?,"In projective geometry, Pascal's theorem (formulated by Blaise Pascal when he was 16 years old) determines that a hexagon inscribed in a conic, the lines that contain the opposite sides intersect in collinear points, ie if the six vertices a hexagon are located on a circle and three pairs of opposite sides intersect three intersection points are colinear.
It is a generalization of the theorem of Pappus . No doubt a theorem fantastic! Mainly, as well as aesthetic appeal, by Fanto is not clear (at least as far as I know). And it is this that motivates my questions. 1) There is some intuitive way to see Pascal's theorem? What I mean is something in the same spirit of Java Aplet on the Sum of Outer Angles of a Polygon Theorem. 2) Pascal conceived his theorem as a generalization of Pappus theorem? The proof of Pascal gives some clue as to how he got the idea theorem?","['algebraic-geometry', 'math-history', 'projective-geometry']"
165523,A space that has a countably locally finite basis but not second countable,"[Munkres, Ch40, p252] Find a nondiscrete space that has a countably locally finite basis but does not have a countable basis. I solved this problem. My solution is $X=\mathbb{R} \cup \{0'\}$ with topology given by basis $\mathfrak{B}$ consisting of all the nonzero points and {0,0'}. This is almost discrete, except for zero points. This basis $\mathfrak{B}$ is locally finite, so countably locally finite. And this space has no countable basis, since all the nonzero points(which are uncountable) should be in the basis. But I think that this space can be regarded discrete by passing to the quotient space. Is there any more truly nondiscrete example?",['general-topology']
165535,proof of Zassenhaus formula for exponentials of linear operators,"The Zassenhaus formula is $$e^{t(X+Y)}= e^{tX}~  e^{tY} ~e^{-\frac{t^2}{2} [X,Y]} ~
e^{\frac{t^3}{6}(2[Y,[X,Y]]+ [X,[X,Y]] )} ~
e^{\frac{-t^4}{24}([[[X,Y],X],X] + 3[[[X,Y],X],Y] + 3[[[X,Y],Y],Y]) } \cdots$$ from this Wikipedia page . $X$ and $Y$ are linear operators, and $[X,Y]$ is their commutator. I mostly want to prove it for the case where the commutator of $X$ and $Y$ is a constant, or simply the general proof. What I'm looking for is either a reference to a place where it's proven or at
least some shove in the right direction. So far I've tried to just expand the exponential to see if I see anything
but have no ideas so far.","['noncommutative-algebra', 'linear-algebra']"
165542,"If $f\in C^1, L^1$, does $\lim_{x\rightarrow \infty} f(x)=0$?","Problem: Prove or provide a counterexample: Let $m$ be the Lebesgue measure on $\mathbb{R}$. Suppose $f\in L^1(\mathbb{R}, m)$ is of class $C^1$, and that $f'\in L^1 (\mathbb{R}, m)$. Then $\lim_{x\rightarrow \infty} f(x) =0$. Thoughts: Take the standard Gaussian function that integrates to 1. By changing the ""variance"" (using $e^{-x^2/c}$ for some $c$) we can vary the total integral while keeping the maximal value as 1. Translating these across the real line so that we have functions centered on each positive integer $n$ with total integral $\frac{1}{n^2}$ (and adding them together and using the monotone convergence theorem), we get a $C^\infty$ function in $L^1$. My scratchwork indicates the derivative is also in $L^1$, so this seems to provide a counterexample. However, upon further review, my scratch work is incorrect...",['measure-theory']
165547,Count the number of solutions of the inequality $x + y + z \leq N$ [duplicate],"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . Problem Given $A, B, C $ and $N$. How many integer solutions are there of the following inequality:
  $$x + y + z \leq N$$
  where $0 \leq x \leq A, 0 \leq y \leq B, 0 \leq z \leq C$? When $A + B + C \leq N$, the solution is obvious $(A + 1) \cdot (B + 1) \cdot (C + 1)$ The general formula for the number of solutions of the form $x + y + z = N$, for $x, y , z \geq 0$ is $\dbinom{N + r -1}{r - 1}$. Unfortunately, I couldn't find a way to bring this idea into place. Any suggestion?","['inequality', 'combinatorics']"
165564,Approximating Coins Flips Problem,"Approximate the probability of getting 500 heads out of a 1000 coin
  flip of unbiased coins to be within 5% of its true value (without the use of a calculator). I know that an exact probability is $$\binom{1000}{500}(.5)^{1000} = .02522...$$ I am unsure how one could simplify this problem through estimation to get an approximate answer however. Thanks for any help.","['approximation', 'puzzle', 'probability']"
165565,Square units of area in a circle,"I'm studying for the GRE and came across the practice question quoted below. I'm having a hard time understanding the meaning of the words they're using. Could someone help me parse their language? ""The number of square units in the area of a circle '$X$' is equal to $16$ times the number of units in its circumference. What are the diameters of circles that could fit completely inside circle $X$?"" For reference, the answer is $64$, and the ""explanation"" is based on $\pi r^2 = 16(2\pi r).$ Thanks!",['geometry']
165609,Name for matrices with orthogonal (not necessarily orthonormal) rows,"Is there a name for a matrix whose rows (or columns) are non-zero orthogonal vectors ? It seems to me that ""orthogonal matrix"" would be a good name, but this is already taken -- it refers to a matrix whose rows (or columns) form an orthonormal set of vectors.","['matrices', 'linear-algebra', 'orthogonality', 'terminology']"
165626,Defining additions in the ring of integers,Is it possible to describe all possible ways in which one can define additions in the set of integers to give it a structure of ring when the multiplication is same as the usual multiplication ? If the addition is same as the usual addition then one can easily describe all possible multiplications. What can we say when multiplication is usual ?,"['elementary-set-theory', 'abstract-algebra']"
165629,Proof that convex open sets in $\mathbb{R}^n$ are homeomorphic?,"This is an exercise from Kelley's book. Could someone help to show me a proof? It seems very natural, and it is easy to prove by utilizing the arctan function in $\mathbb{R}^1$. 
Thanks a lot.",['general-topology']
165652,Is this vector derivative correct?,"I want to comprehend the derivative of the cost function in linear regression involving Ridge regularization, the equation is: $$L^{\text{Ridge}}(\beta) = \sum_{i=1}^n (y_i - \phi(x_i)^T\beta)^2 + \lambda \sum_{j=1}^k \beta_j^2$$ Where the sum of squares can be rewritten as: $$L^{}(\beta) = ||y-X\beta||^2 + \lambda \sum_{j=1}^k \beta_j^2$$ For finding the optimum its derivative is set to zero, which leads to this solution: $$\beta^{\text{Ridge}} = (X^TX + \lambda I)^{-1} X^T y$$ Now I would like to understand this and try to derive it myself, heres what I got: Since $||x||^2 = x^Tx$ and  $\frac{\partial}{\partial x} [x^Tx] = 2x^T$ this can be applied by using the chain rule: \begin{align*}
\frac{\partial}{\partial \beta} L^{\text{Ridge}}(\beta) = 0^T  &= -2(y - X \beta)^TX + 2 \lambda I\\
0 &= -2(y - X \beta) X^T + 2 \lambda I\\
0  &= -2X^Ty + 2X^TX\beta + 2 \lambda I\\
0  &= -X^Ty + X^TX\beta + 2 \lambda I\\
  &= X^TX\beta + 2 \lambda I\\
(X^TX + \lambda I)^{-1} X^Ty &= \beta
\end{align*} Where I strugle is the next-to-last equation, I multiply it with $(X^TX + \lambda I)^{-1}$ and I don't think that leads to a correct equation. What have I done wrong?","['matrices', 'vector-analysis', 'derivatives']"
165656,Set Operations with Empty sets,"I have a question regarding performing set operations on empty sets. For example let A = ∅, Let B = {A, ∅}, Let C = {A, B}. Would B = {∅, ∅} and C = {∅, {∅,∅}}? or would B = {∅} and C = {∅, {∅}} since {∅, ∅} reduces to {∅}? Now if I wanted to do $A \cup C$ would the answer be $∅ \cup C$ -> C = {∅, {∅}}? Now what if I wanted to do D = C - B, would the result be {{∅}}? One last question. If P = {∅}, Q = {P}, R = {∅,P}, S = {∅, P, Q, R}; What would X = {$ x : (x ∈ R) \wedge ( x ⊆ S)$}? My thoughts are that Q = {{∅}}, R = {∅, {{∅}}} and S = { ∅, {∅}, {{∅}}, {∅, {{∅}}} } x ∈ R would mean x = ∅ and x = {{∅}} x ⊆ S would mean x is a set containing any combination of ∅, {∅},
{{∅}}, {∅, {{∅}}} as members Therefore X = {{{∅}}} as {{∅}} is the only member that fits both those conditions? I've tried looking at some lectures online on set theory but I want to make sure my understanding is correct so far. On a more general note, I am also wondering if lets say D = {1, 2} and E = {D, 5}. Would E = {1,2,5} or E = {{1,2},5}? Thanks",['elementary-set-theory']
165657,Show $\lim_{N\to \infty}\sum_{k=1}^{N}\frac{1}{k+N}=\ln(2)$,"I have some difficulty to prove the following limit:
$$\lim_{N\to \infty}\sum_{k=1}^{N}\frac{1}{k+N}=\ln(2)$$
Can someone help me? Thanks.","['sequences-and-series', 'limits']"
165671,"Convergence of the sequence $\sqrt{1+2\sqrt{1}},\sqrt{1+2\sqrt{1+3\sqrt{1}}},\sqrt{1+2\sqrt{1+3\sqrt{1+4\sqrt{1}}}},\cdots$ [duplicate]","This question already has answers here : Evaluating the nested radical $ \sqrt{1 + 2 \sqrt{1 + 3 \sqrt{1 + \cdots}}} $. [closed] (3 answers) Closed 4 years ago . I recently came across this problem Q1 Show that $\lim\limits_{n \rightarrow \infty} \underbrace{{\sqrt{1+2\sqrt{1+3\sqrt{1+4\sqrt{1+\cdots+n\sqrt{1}}}}}}}_{n \textrm{ times  }} = 3$ After trying it I looked at the solution from that book which was very ingenious but it was incomplete because it assumed that the limit already exists. So my question is Q2 Prove that the sequence$$\sqrt{1+2\sqrt{1}},\sqrt{1+2\sqrt{1+3\sqrt{1}}},\sqrt{1+2\sqrt{1+3\sqrt{1+4\sqrt{1}}}},\cdots,\sqrt{1+2\sqrt{1+3\sqrt{1+4\sqrt{1+\cdots+n\sqrt{1}}}}}$$ converges. Though I only need solution for Q2 , if you happen to know any complete solution for Q1 it would be a great help . If the solution from that book is required I can post it but it is not complete as I mentioned. Edit : I see that a similar question was asked before on this site but it was not proved that limit should exist.","['nested-radicals', 'sequences-and-series', 'limits']"
165679,Lowest surface-to-volume ratio for an uncovered vessel,"It is well known that a sphere has the lowest surface to volume ratio. However, a related question is: What is the shape that gives the lowest surface to volume ratio if you do not include the top in the surface. That is, what is the maximal volume of an uncovered vessel of a fixed surface area? To be more specific with the definition of top or cover -- I regard this as a continuous manifold which allow holes. The holes do not contribute to the surface , but the volume I consider is only the one up to ( up defined by the direction of gravity) the first hole. The answer thus depends on the direction of the vessel. An upside-down water glass would have an infinite ratio. For example, a cylinder whose height is equal to its radius and a missing top basis, has a volume $\pi R^2 h = \pi R^3$ and a surface (without cover) of $\pi R^2 + 2\pi R h = 3 \pi R^2$. If we fix the volume to unity, the surface in this case is $3 \sqrt[3]{\pi}$. In comparison, a half sphere of unity volume has a smaller surface, i.e. $\sqrt[3]{18\pi}$ . However, it's clear this is not the best shape -- a sphere cut just a little higher the equator beats the half sphere. So, what is the shape that gives the lowest surface to volume ratio if you do not include the top in the surface? Thanks!",['geometry']
165684,"While proving that every vector space has a basis, why are only finite linear combinations used in the proof?","Statement : Every vector space has a basis Standard Proof :It is observed that a maximal linearly independent set is a basis.
  Let $\mathscr{Y}$ be a chain of linearly independent subsets of a vector space $\mathscr{V}$. The union of such a set can serve as an upper bound for it.To apply Zorn's lemma,we have to check whether the union is linearly independent? Well, if $t_1,\dots,t_n$ belong to the union, then each $t_i$ belongs to some linearly independent set $L_i\in \mathscr{Y}$. Because $\mathscr{Y}$ is a chain, one of these sets $L_i$ contains all the others. If that is $L_j$, then the linear independence of $L_j$ implies that no non-trivial linear combination of $t_1,\dots,t_n$ can be zero, which proves that the union of the sets in $\mathscr{Y}$ is linearly independent. Therefore, by Zorn’s lemma, there is a maximal linearly independent set and hence a basis. My question : Why are we using only finite linear combinations to show that the union is linearly independent. Surely, if the union is infinite,then there do exist many infinite linear combinations of elements of the union, which cannot be proven to be linearly independent by the same reasoning. I suspect, that perhaps we are not concerned with infinite linear combinations due to issues of convergence, but I'm not sure. Clear answers will be appreciated.","['vector-spaces', 'linear-algebra']"
165696,Your favourite application of the Baire Category Theorem,"I think I remember reading somewhere that the Baire Category Theorem is supposedly quite powerful. Whether that is true or not, it's my favourite theorem (so far) and I'd love to see some applications that confirm its neatness and/or power. Here's the theorem (with proof) and two applications: (Baire) A non-empty complete metric space $X$ is not a countable union of nowhere dense sets. Proof: Let $X = \bigcup U_i$ where $\mathring{\overline{U_i}} = \varnothing$. We construct a Cauchy sequence as follows: Let $x_1$ be any point in $(\overline{U_1})^c$. We can find such a point because $(\overline{U_1})^c \subset X$ and $X$ contains at least one non-empty open set (if nothing else, itself) but $\mathring{\overline{U_1}} = \varnothing$ which is the same as saying that $\overline{U_1}$ does not contain any open sets hence the open set contained in $X$ is contained in $\overline{U_1}^c$. Hence we can pick $x_1$ and $\varepsilon_1 > 0$ such that $B(x_1, \varepsilon_1) \subset (\overline{U_1})^c \subset U_1^c$. Next we make a similar observation about $U_2$ so that we can find $x_2$ and $\varepsilon_2 > 0$ such that $B(x_2, \varepsilon_2) \subset \overline{U_2}^c \cap B(x_1, \frac{\varepsilon_1}{2})$. We repeat this process to get a sequence of balls such that $B_{k+1} \subset B_k$ and a sequence $(x_k)$ that is Cauchy. By completeness of $X$, $\lim x_k =: x$ is in $X$. But $x$ is in $B_k$ for every $k$ hence not in any of the $U_i$ and hence not in $\bigcup U_i = X$. Contradiction. $\Box$ Here is one application (taken from here ): Claim: $[0,1]$ contains uncountably many elements. Proof: Assume that it contains countably many. Then $[0,1] = \bigcup_{x \in (0,1)} \{x\}$ and since $\{x\}$ are nowhere dense sets, $X$ is a countable union of nowhere dense sets. But $[0,1]$ is complete, so we have a contradiction. Hence $X$ has to be uncountable. And here is another one (taken from here ): Claim: The linear space of all polynomials in one variable is not a Banach space in any norm. Proof: ""The subspace of polynomials of degree $\leq n$ is closed in any norm because it is finite-dimensional. Hence the space of all polynomials can be written as countable union of closed nowhere dense sets. If there were a complete norm this would contradict the Baire Category Theorem.""","['general-topology', 'baire-category', 'functional-analysis', 'big-list']"
165698,On the Diophantine equation $a^2+b^2 = c^2+k$,"Given the Diophantine equation, $$a^2+b^2=c^2+k$$ where k is a constant integer.  Let $0 < a \le b$, and $\Delta_k(N)$ be the number of primitive solutions with $0 < c < N$ for some bound N . For example, for k = 0 and $N = 10^5 $, there are exactly 15919 primitive Pythagorean triples, hence $\Delta_0(10^5) = 15919$. ""Conjecture : $$\lim_{N\to\infty}\frac{\Delta_k(N)}{N} = \text{constant}$$ where the constant, for negative k, involves $\frac{1}{\sqrt{-k}}$."" In the table below, the first column gives selected k , subsequent columns give (rounded to 5 decimal places) the ratio $\frac{\Delta_k(N)}{N}$ up to $N = 10^7$, its conjectured limit L as $N \to \infty$, and error difference of L and ratio at $N = 10^7$. $$\begin{array}{ccccc}
k&10^5&10^6&10^7&\infty&\text{Error diff}\\
0&0.15919&0.15914&0.15916& \to 0.15915 \;=\; \frac{1}{2\pi}&0.00001\\ 
-1&0.12517&0.12497&0.12499& \to 0.12500 \;=\; \frac{1}{8}&0.00001\\
-2&0.17697&0.17679&0.17680& \to 0.17677 = \frac{1}{4\sqrt{2}}&0.00003\\
-3&0.28871&0.28868&0.28864& \to 0.28867 = \frac{1}{2\sqrt{3}}&0.00003\\
-5&0.22354&0.22367&0.22357& \to 0.22360 = \frac{1}{2\sqrt{5}}&0.00003\\
-7&0.37772&0.37780&0.37799& \to 0.37796 = \frac{1}{\sqrt{7}}&0.00003\\ 
\end{array}$$ Lehmer (1900) proved the case k = 0. Question: Can you prove the conjectured limits are valid/invalid? Similar simple limits can be found for other negative k , but not for positive k . Code by Daniel Lichtblau of Wolfram Research to find the number of solutions $\le N$ can be found here , though $N = 10^7$ already takes more than an hour, and beyond that takes MUCH more. Do you know of a faster code?","['limits', 'diophantine-equations', 'number-theory']"
165709,Questions concerning a proof that $\mathcal{D}$ is dense in $\mathcal{S}$.,"I am currently working through this lecture notes and on page 164, there it is said The space of $\mathcal{D}(\mathbb{R}^n)$ of smooth complex-valued functions with compact support is contained in the Schwartz space $\mathcal{S}(\mathbb{R}^n)$. If $f_k \to f$ in $\mathcal{D}$, then $f_k \to f$ in $\mathcal{S}$, so $\mathcal{D}$ is continuously embedded in $\mathcal{S}$. Furthermore, if $f\in \mathcal{S}$, and $\eta \in C_c^{\infty}(\mathbb{R}^n)$ is a cutoff function with $\eta_k(x) = \eta(x/k)$, then $\eta_k f \to f$ in $\mathcal{S}$ as $k \to \infty$, so $\mathcal{D}$ is dense in $\mathcal{S}$. I don't understand the arguments in this paragraph, for a subset $\mathcal D$ of $\mathcal S$ to be dense in $\mathcal S$ for every element $s$ of $\mathcal S$ I need to find a sequence in $\mathcal D$ which converges to $s$, but there just stands that $\eta_k f \to f$ in $\mathcal{S}$, but what i need is a sequence in $\mathcal{D}$ not in $\mathcal{S}$, so why does it follow from this that $\mathcal{D}$ is dense in $\mathcal{S}$?","['distribution-theory', 'partial-differential-equations', 'analysis']"
165712,For which categories we can solve $\text{Aut}(X) \cong G$ for every group $G$?,"It is usually said that groups can (or should) be thought of as ""symmetries of things"". The reason is that the ""things"" which we study in mathematics usually form a category and for every object $X$ of a (locally small) category $\mathcal{C}$, the set of automorphisms (symmetries) of $X$, denoted by $\text{Aut}_{\mathcal{C}}(X)$, forms a group. My question is: Which categories that occur naturally in mathematics admit all kinds of symmetries? More precisely, for which categories we can solve the equation (of course up to isomorphism) $$\text{Aut}_{\mathcal{C}}(X) = G$$ for every group $G$? I will write what I could find myself about this, which also hopefully illustrates what kind of answers that would interest me: Negative for $\mathsf{Set}$: Infinite sets have infinite symmetry groups and for finite sets we get $S_n$'s. So if we let $G$ to be any finite group which is not isomorphic to some $S_n$, the equation has no solution. Negative for $\mathsf{Grp}$: No group can have its automorphism group a cyclic group of odd order. Positive for $\mathsf{Grph}$ (category of graphs): Frucht's theorem settles this for finite groups. Also according to the wikipedia page, the general situation was solved independently by de Groot and Sabidussi. An obvious necessary condition is that $\mathcal{C}$ should be a large category. This paper shows that the equation can be solved if $\mathcal{C}$ is the category of Riemann surfaces with holomorphic mappings and $G$ is countable. If we take $\mathcal{C}$ to be the category of fields with zero characteristic, I guess the equation relates to the inverse Galois problem. Edit: This may be much easier than the inverse Galois problem, as Martin Brandenburg commented.","['big-list', 'category-theory', 'group-theory']"
165730,Calculating the norm of an element in a field extension.,"Given a number field $\mathbb{Q}[\beta]$, where the minimal polynomial of $\beta$ in $\mathbb[Z][x]$ has degree $n$, I would like to calculate the norm of the general element $$a_0+a_1\beta+\cdots+a_{n-1}\beta^{n-1}.$$ In particular, here is my attempt when $\alpha=2^\frac{1}{3}$: Let $K=Q[2^\frac{1}{3}]$.  Using the definition of the norm , it is the determinant of the linear transformation.  Consider $\alpha =a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c$ acting by multiplication on the element $d+2^{\frac{1}{3}}e+2^{\frac{2}{3}}f$.  Since $$\left(a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c\right)\left(d+2^{\frac{1}{3}}e+2^{\frac{2}{3}}f\right)=ad+2bf+2ce+2^{\frac{1}{3}}\left(ae+bd+2cf\right)+2^{\frac{2}{3}}\left(af+dc+be\right) $$ in the basis $[1,2^{\frac{1}{3}},2^{\frac{2}{3}}$ we may view multiplication by $\alpha$ as a linear transform $$\alpha\left[\begin{array}{c}
d\\
e\\
f
\end{array}\right]=\left[\begin{array}{c}
ad+2bf+2ce\\
ae+bd+2cf\\
af+dc+be
\end{array}\right].$$  Using the above, we see that $$\alpha=\left[\begin{array}{ccc}
a & 2c & 2b\\
b & a & 2c\\
c & b & a
\end{array}\right] $$ in this basis.  Taking the determinant we find $$\det \left[\begin{array}{ccc}
a & 2c & 2b\\
b & a & 2c\\
c & b & a
\end{array}\right] =a\left(a^{2}-2bc\right)-2c\left(ba-2c^{2}\right)+2b(b^{2}-ac) $$ $$=a^{3}+2b^{3}+4c^{3}-6abc. $$ This means we have shown that $N_K(\alpha)=a^{3}+2b^{3}+4c^{3}-6abc$ for $\alpha=a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c$ Questions: (1) Was the above calculation correct?  Can we conclude that the norm of a general element in that space is $a^{3}+2b^{3}+4c^{3}-6abc$? (2) Is there a better way to do this computation?  What about if the extension is Galois?","['galois-theory', 'normed-spaces', 'abstract-algebra', 'field-theory']"
165739,How to prove $I + t X$ is invertible for small enough $ | t | ?$,"Let $X \in \text{GL}_n(\mathbb{R})$ be an arbitrary real $n\times n$ matrix. How can we prove rigorously: 
$$ \underset{b>0} {\exists} : \underset{|t|\le b} {\forall} : \det (I + t X) \neq 0 $$
If necessary, we could also assume that $t \ge 0.$","['matrices', 'linear-algebra', 'determinant']"
165746,Existence of a semi-martingale that matches given densities,"Let $\{p_t\}_{t \geq 0}$ be a family of densities. Is there any result concerning the existence of a semi-martingale $\{X_t\}_{t \geq 0}$ such that for all $t\geq 0$, the density of $X_t$ is $p_t$ ?","['probability-theory', 'stochastic-processes', 'probability-distributions']"
165758,Regular functions on $\mathbb P_k^n$,"Let be $k$ an algebraically closed field and let's consider a projective algebraic set $V\subseteq\mathbb P^n_k$ with the induced Zariski topology. If $U\subseteq V$ is open, likewise the affine  case, regular functions on $U$ are those functions that can be written locally as $\frac{f}{g}$ where $f,g\in \Gamma[V]_h$ are represented by homogeneous polynomials of the same degree. If $V$ is an affine  algebraic set  one can show that $\mathcal O_V(D(f))=\Gamma[V]_f$ for all $f\in \Gamma[V]$. In the projective case with the sheaf of regular functions definited above, can be shown that $$\mathcal O_V(D(f))=\Gamma[V]_{(f)}$$ where $\Gamma[V]_{(f)}:=\{\frac{g}{f^n}\,:\, g,f\;\textrm{are homogeneous and}\; deg(g)=deg(f^n)\}$. This formula is true if $deg(f)>0$ because, for example, if $f=1$ then we would have $\mathcal O_V(D(1))=k$ so the global regular functions would be only costant functions on $V$. This is wrong because if $V$ is not connected we have other regular functions, precisely functions that are costant on every connected component of $V$. So my question is: when one proves the relation $\mathcal O_V(D(f))=\Gamma[V]_{(f)}$, what is that goes wrong in the case $deg(f)=0$?",['algebraic-geometry']
165762,Automorphism group of dyadic rationals,I googled for this information but couldn't find anything... What is the automorphism group of the additive group of the dyadic rationals $\mathbb{Z}[\frac{1}{2}]$ ?,['group-theory']
165764,Lower semicontinuous function as the limit of an increasing sequence of continuous functions,"Let $ f:\mathbb{R}^m \rightarrow (-\infty,\infty] $ be lower semicontinuous and bounded from below. Set $f_k(x) = \inf\{f(y)+k d( x,y ): y\in \mathbb{R}^m\} $ , where $d(x,y)$ is a metric. It is easy to see that each $f_k$ is continuous and $f_1  \leq f_2\leq ...\leq f \\$. However, I don't know how to prove that $ \lim_{k \rightarrow \infty}f_k(x) = f(x) $ for every $x\in\mathbb{R}^m $.","['semicontinuous-functions', 'real-analysis']"
165768,A sequence of polynomials that converges to $0$ pointwise except at $z=0$,"This is an exercise from John Conway's book on complex analysis: Investigate if there exists a sequence of polynomials $(P_n)$ that fulfills the conditions $P_{n}(0)=1$ for all natural numbers $n$ and $\lim_{n\rightarrow\infty}P_n(z)=0$ for all $z\neq0$ Polynomials obey the maximum principle, but I don't see how to apply it if all we know is point-wise convergence. (Uniform convergence would imply $|P_n|<\epsilon$ on the unit circle for large $n$, contradicting $P_n(0)=1$.)","['complex-analysis', 'polynomials']"
165787,Determinant of a real skew-symmetric matrix is square of an integer,"Let $A$ be a real skew-symmetric matrix with integer entries. Show that $\operatorname{det}{A}$ is square of an integer. Here is my idea: If $A$ is skew-symmetric matrix of odd order, then $\operatorname{det}{A}$ is zero. So, take $A$ to be of even order and non-singular. Since all the eigenvalues of $A$ are of the form $ia$ and its conjugate (where $a$ is real number), we see that $\operatorname{det}{A}$ is square of a real number. But I am not getting how to show it is square of an integer.","['bilinear-form', 'matrices', 'linear-algebra', 'skew-symmetric-matrices', 'determinant']"
165797,Is it possible to combine two integers in such a way that you can always take them apart later?,"Given two integers $n$ and $m$ (assuming for both $0 < n < 1000000$) is there some function $f$ so that if I know $f(n, m) = x$ I can determine $n$ and $m$, given $x$? Order is important, so $f(n, m) \not= f(m,n)$ (unless $n=m$).",['functions']
165816,Computing determinant of a specific matrix. [duplicate],"This question already has answers here : Determinant of a matrix with diagonal entries $a$ and off-diagonal entries $b$ [duplicate] (9 answers) Closed 7 years ago . How to calculate the determinant of
$$ A=(a_{i,j})_{n \times n}=\left(
\begin{array}{ccccc}
a&b&b& \cdots & b\\
b& a& b& \cdots& b\\
\vdots& \vdots& \vdots& \ddots&\cdots\\
b&b&b & \cdots&a
\end{array}
\right)? $$","['matrices', 'determinant']"
165819,How to tile a sphere with points at an even density?,"I'm writing a bit of code to plot twitter usage across the globe. To do this, I'm searching for users within n km of a certain longitude/latitude (a circular area), at many different lat/lon coordinates. The fact that this is lat/lon coordinates is irrelevant, since this portion is done in cartesian coordinates. I need to tile the earth (a sphere in this model) with m points, which will serve as the centre of a search radius. The location of each point (x y z) is subject to the constraint that it cannot be within m km of any other point (x' y' z'), so that the search radii do not overlap. Any thoughts? It seems like the kind of problem that has a perfect solution.","['geometry', 'tiling']"
165825,"If $\int_0^1 f(x)x^n \ dx=0$ for every $n$, then $f=0$. [duplicate]","This question already has answers here : Closed 11 years ago . Possible Duplicates: Nonzero $f \in C([0, 1])$ for which $\int_0^1 f(x)x^n dx = 0$ for all $n$ Slight generalization of an exercise in (blue) Rudin What can we say about $f$ if $\int_0^1 f(x)p(x)dx=0$ for all polynomials $p$ ? I found a nice problem I would like to share. Problem: If $f$ is continuous on $[0,1]$ , and if $$\int_0^1 f(x)x^n \ dx =0$$ for every non-negative integer $n$ , prove that $f(x)=0$ on $[0,1]$ . Source: W. Rudin, Principles of Mathematical Analysis , Chapter 7, Exercise 20. I have posted a proposed solution in the answers.",['real-analysis']
165831,Conditional probability,"A girl goes to school by bus every day. If it doesn't rain, probability that she will be late for bus is 1/5. If it rains probability that she will be late is 2/3. Probability that it is raining is 1/4. Girl forgot to pick up a bus. Define the probability that it was raining. In this task I have done following using my logic, but I am not sure is it correct:
P(late for bus and rained that day) = P(rains)/P(late for school and is raining )= 1/4/2/3 = 3/8. I am not sure if it is correct, so I plead for your help.","['statistics', 'probability']"
