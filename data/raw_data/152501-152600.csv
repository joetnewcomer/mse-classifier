question_id,title,body,tags
2557554,Understanding a Taylor expansion in probability,"I initially posted this on stats.stackexchange but received no feedback. Maybe this is better suited for math.stackexchange since the question is mainly about Taylor expansion with random variables. I'm trying to understand the proof of an expression for the asymptotic bias in local polynomial regression of degree $p\ge0$. Specifically, I'm distraught with equation $(3.59)$ on page 102 of this book . This is part of the proof of Theorem 3.1 on page 62 . (You can read the full passages by clicking on the snippets I have linked to.) Here's the setup.
Let $(X_1, Y_1),\ldots,(X_n,Y_n)$ be iid taking values in $\mathbb R^2,$ let $X_1$ have density $f.$ Let $m(x)=E(Y|X=x)$ and let $K$ be a symmetric kernel with bounded support, let $K_h(t) = K(t/h)/h,$ where $h$ is the bandwidth. Write
$$\mathbf X=((X_i-x_0)^j)_{i=1,\ldots,n \atop j=0,\ldots,p}, \mathbf W = \operatorname{diag}(K_h(X_1-x_0),\ldots,K_h(X_n-x_0)),\\
\mathbf y=(Y_1\ldots,Y_n)^T, \mathbf m=(m(X_1),\ldots,m(X_n))^T.$$ Then the conditional bias of the local polynomial estimator $\hat\beta=(\mathbf X^T \mathbf W \mathbf X)^{-1}\mathbf X^T \mathbf W \mathbf y$ is
$$\operatorname{Bias}(\hat\beta|(X_1,\ldots,X_n))=(\mathbf X^T \mathbf W \mathbf X)^{-1}\mathbf X^T \mathbf W \mathbf r =: S_n^{-1}\mathbf X^T \mathbf W \mathbf r,$$
where $\mathbf r = \mathbf m-\mathbf X \beta,\, \beta=(m(x_0),\ldots,m^{(p)}(x_0)/{p!})^T.$ Assume that $m^{(p+1)}(\cdot)$ is continuous in a neighborhood of $x_0.$
Fan writes on page 102: By using the Taylor expansion the conditional bias $S_n^{-1}\mathbf X^T \mathbf W \mathbf r$ of $\hat\beta$ can be written as
  $$S_n^{-1}\mathbf X^T \mathbf W \Bigl[\beta_{p+1}(X_i-x_0)^{p+1}+o_P\left\{(X_i-x_0)^{p+1}\right\}\Bigr]_{1\le i\le n}$$ I don't understand what is meant by $o_P\left\{(X_i-x_0)^{p+1}\right\}$ in this context. I know that the usual definition is that it's a term which converges in probability to zero even after dividing by $(X_i-x_0)^{p+1}.$ But what converges in probability here? Is it meant that this holds as $n\to\infty$? I tried writing everything out using Lagrange remainder, but as as @TedShifrin pointed out, the Lagrange remainder term should have an exponent of p+2, not p+1. But $m$ is only $p+1$ times differentiable. So maybe the Lagrange-remainder is not as helpful here as I thought. Peano-remainder yields 
$$
\begin{align}
\mathbf r &= \mathbf m-\mathbf X \beta \\
&= \Biggl[\sum_{l=0}^{p+1} \frac{m^{(l)}(x_0)}{l!} (X_i-x_0)^{l} + (X_i-x_0)^{p+1}g_i(X_i-x_0)\\
&\quad\quad- \sum_{l=0}^{p} \frac{m^{(l)}(x_0)}{l!} (X_i-x_0)^{l}\Biggr]_{1\le i\le n}\\ 
&= \left[\frac{m^{(p+1)}(x_0)}{(p+1)!} (X_i-x_0)^{p+1} + (X_i-x_0)^{p+1}g_i(X_i-x_0)\right]_{1\le i\le n} 
\end{align}
$$
For a function $g_i$ with $g_i(t)\to 0$ as $t\to0.$ If the $X_i$ were not random we would write $(X_i-x_0)^{p+1}g_i(X_i-x_0)=o((X_i-x_0)^{p+1})$ as $X_i-x_0\to0.$ But since the $X_i$ are random, in what sense is $$(X_i-x_0)^{p+1}g_i(X_i-x_0)=o_P((X_i-x_0)^{p+1})?$$","['taylor-expansion', 'probability-theory', 'asymptotics', 'statistics', 'random-variables']"
2557564,Does specifying the lengths of the sides of a polygon completely fix its shape (area and angles)?,"Mine is a very generic question. I believe the answer is yes for a triangle. I don't have a formal proof, just an image in my head. Is it also true for a higher $n$-gon? Does anyone know of a theorem? EDIT (following comments):
The answer is NO for $n>3$. This is because the lengths of the sides of an $n$-gon do no specify its angles, for $n>3$. E.g., consider the square and the rhombus having the same sides. FOLLOW-UP question: 
Why is it this so? What is special about $n=3$, that changes for higher $n$. General guess to an answer:
I am a physicist, so let me use a physicist's argument. The shape of an $n$-gon is specified by its $n$ sides and $n$ angles. That's $2n$ parameters. Somehow, for $n=3$, there are sufficient constraints such that all 3 angles are determined by the 3 sides. For higher $n$, that is not the case, so that we are left with extra parameters, and can get a range of shapes. But why is this so? Someone please fill in the blanks.",['geometry']
2557600,Prove $\tan(\frac{\alpha}{2})\tan(\frac{\beta}{2})=\frac{1}{5}$,"Given $2\sin(\alpha)+2\sin(\beta)=3\sin(\alpha+\beta)$, prove that $\tan(\frac{\alpha}{2})\tan(\frac{\beta}{2})=\frac{1}{5}$
Also we know that all the expressions are different from zero and defined. Including the expressions we received during the solution. Tried to play with it, didn't seem to work for me.",['trigonometry']
2557624,Dimension of most fibers of $X^m \to Y^n$ of irreducible $k$ varieties are pure dimension $m-n$.,"I am reading Ravi Vakil's notes on algebraic geometry and in Theorem 11.4.1 he claims: ""Suppose $\pi: X \to Y$ is a (necessarily finite type) morphism of irreducible $k$-varieties with $dim X = m,$ and $ dim Y = n$. Then there exists a nonempty open subset $U \subset Y$ such that for all $q \in U,$ the fiber over $q$ has pure dimension $m-n$."" He quickly reduces to the affine case $\pi: Spec(A) \to Spec(B)$ with $\pi$ dominant and claims that it suffices to show there is a distinguished open subset $U \subset Spec(B)$ for which the restriction factors through $\pi^{-1}(U) \to \mathbb{A}^{m-n}_U \to U$ where $\mathbb{A}^{m-n}_U := \mathbb{A}_k^{m-n} \times U$ and $\psi: \pi^{-1}(U) \to \mathbb{A}^{m-n}_U$ is a finite surjection. In particular, he argues that using the fact that codimension is the difference of dimension for varieties and the fact that for any morphism with $\pi(p) = q, codim_Xp \leq codim_Yq + codim_{\pi^{-1}(q)}p$, we can argue that any component of the fiber over a point of $U$ has dimension at least $m-n$. While I agree we can show this for some component, what precisely is stopping a situation like $\mathbb{A}^2_k \coprod \mathbb{A}^1_k \to \mathbb{A}^2_k$ from happening? I looked in other books but none seemed to specifically address the pure dimension part of this statement.","['algebraic-geometry', 'commutative-algebra']"
2557646,The Sequence of Eigenfunctions Of a Self-adjoint Operator is Complete,"I saw this theorem somewhere and I have problem finding proof for the third part. Is it even true? If yes I'd be glad if someone could suggest me a book for reference or give me some hints for proving it myself:
Consider the eigenvalue problem: $$\mathbf Ty_n=\lambda_nw(x)y_n(x),n=0,1,...,x\in\Omega.$$
Where $\mathbf T$ is linear and dense in $L^2([a,b]).$ If $\mathbf T$ is a self-adjoint operator then: 1. All the eigenvalues $\lambda_n$ are real. 2. Any two eigenfunctions of $\mathbf T$ belonging to different eigenvalues are orthogonal to each other. 3.The set of eigenfunctions is complete(dense) in the corresponding space.","['functional-analysis', 'eigenvalues-eigenvectors', 'operator-theory']"
2557703,Representation of Metric in Normal Coordinates,"I'm trying to show that for coordinates $x:U \to \mathbb{R}^n$ centered at $p \in (M,g)$, the property $g_{ij}(0)x^j = g_{ij}(x)x^j$ characterizes normal coordinates - i.e. straight lines through the origin are geodesics. However, I don't know what $g_{ij}(0)x^j$ even means - is it just the matrix of coefficients of $g$ multiplied by some vector? Does it have any geometric meaning? $g$ is a map from $TM$ so it's weird that it's being applied to a point in the image of $M$ in $\mathbb{R}^n$. I get that $T_pM$ is diffeomorphic to some neighborhood of $p$, but I'm struggling to see the context for this property (it was shown in class and I wasn't in class). If the proof is just symbol manipulation - something like taking the derivative of $g_{ij}(c(t))c^j(t)$ where $c(t)$ is a parametrized line in the direction of some vector $c$, then that's fine, I'm just wondering if there's more geometric context in the property/condition.","['riemannian-geometry', 'differential-geometry']"
2557735,Operating with Exponential Generating Function,"I am having troubles understanding how to operate with generating functions to obtain a final formula. I have been looking to the answer to this question: Exponential generating function and number of balls . $$\color{red}{\left(\frac{x^2}{2!}+\frac{x^4}{4!}\right)}\color{green}{\frac12\left(e^x+e^{-x}\right)}\color{blue}{e^x}.$$
  This expands to
  $$\frac12\cdot\frac{x^2}{2!} + \frac12\cdot\frac{x^4}{4!} + \sum_{n=2}^\infty \frac1{16}2^nn(n-1)\frac{x^n}{n!} + \sum_{n=4}^\infty\frac1{768}2^nn(n-1)(n-2)(n-3)\frac{x^n}{n!}. $$
  Simplification yields
  $$\frac{x^2}{2!}+3\frac{x^3}{3!}+13\frac{x^4}{4!} + \sum_{n=5}^\infty \frac1{768} 2^nn(n-1)(n^2-5n+54)\frac{x^n}{n!}. $$ What are the steps to obtain this and the simplification? I can't see how to get from one to another
I have tried a different approach, since
$$ e^x + e^{-x} =
\sum_{n=0}^\infty {2x^{2n}\over (2n)!}; \; e^x =
\sum_{n=0}^\infty {x^{n}\over n!}, $$
Multiplying everything, I obtain:
$$
 \frac{1}{2}\frac{x^2}{2!}\left(\sum_{n=0}^\infty\frac{2x^{2n}}{(2n)!}\right)\cdot \left(\sum_{n=0}^\infty \frac{x^n}{n!}\right) + \frac{1}{2}\frac{x^4}{4!}\left(\sum_{n=0}^\infty\frac{2x^{2n}}{(2n)!}\right)\cdot \left(\sum_{n=0}^\infty \frac{x^n}{n!}\right)
$$ Removing the 2 of the numerator of the fractions and simplifying $x^{2n}/2n!$ for $x^{n}/n!$;  and if I understand multiplication correctly, I should have:
$$
\sum_{k=0}^{n}\binom{n}{k}\frac{x^n}{n!}
$$
as a result of both the multiplications, but doesn't look like any form of the right answer. PS: Decided to make another question instead of commenting the answer because it is 2 years old already.","['generating-functions', 'combinatorics', 'discrete-mathematics']"
2557768,Torsion and Torsion-Free Quotient Group,"The book by Fraleigh says that if $G$ is a torsion group, then so is $G/H$ for every normal subgroup $H$ in $G$ . It also says if $T$ is the torsion normal subgroup of an abelian group $G$ , then then $G/T$ is torsion-free. I cannot reconcile both these facts: $G$ torsion implies $G/H$ torsion $H$ torsion implies $G/H$ torsion-free ( $G$ abelian) If $G$ is torsion, then shouldn't $H$ be torsion too? and that means there is a contradiction, I am hopeless Proof 1) Because $G$ is a torsion group, we know that $x^m = e$ in $G$ for some positive integer $m$ . Computing $(xH)^m$ in $G/H$ using the representative $x$ , we have $(xH)^m = x^mH = eH = H$ , so $xH$ is of finite order. Because $xH$ can be any element of $G/H$ , we see that $G/H$ is a torsion group. Proof 2) Suppose that $xT$ is of finite order in $G/T$ ; in particular, suppose that $(xT )^m = T$ . Then $x^m \in T$ . Because $T$ is a torsion group, we must have $(x^m)^r = x^{mr} = e$ in $G$ for some positive integer $r$ . Thus $x$ is of finite order in $G$ , so that $x \in T$ . This means that $xT = T$ . Thus the only element of finite order in $G/T$ is the identity $T$ , so $G/T$ is a torsion-free group. It is probably very obvious, and I apologize if it is, I just cannot wrap my head around it with exams coming up.","['abstract-algebra', 'group-theory']"
2557780,"Does a metric-like space generate a topology if open balls are defined as $B_\sigma(X,\varepsilon)=\{y\in X; |\sigma(x,y)-\sigma(x,x)|<\varepsilon\}$?","The following is a quote from the paper A. Amini-Harand: Metric-like spaces, partial metric spaces and fixed points, DOI: 10.1186/1687-1812-2012-204 Definition 2.1. A mapping $\sigma\colon X\times X\to\mathbb R^+$, where $X$ is a non-empty set, is said to be metric like on $X$ if for any $x$, $y$, $z$ the following condition hold true: $\sigma(x,y)=0$ $\Rightarrow$ $x=y$ $\sigma(x,y)=\sigma(y,x)$ $\sigma(x,z)\le \sigma(x,y)+\sigma(y,z)$ The pair $(X,\sigma)$ is then called a metric-like space. Then a metric-like on $X$ satisfies all of the conditions of a metric except that $\sigma(x,x)$ may be positive for $x\in X$. Each metric-like $\sigma$ on $X$ generates a topology $\tau_\sigma$ on $X$ whose base is the family of open $\sigma$-balls
  $$B_\sigma(x,\varepsilon)=\{y\in X; |\sigma(x,y)-\sigma(x,x)|<\varepsilon\} \qquad\text{for all $x\in X$ and $\varepsilon>0$.}$$ Then a sequence $\{x_n\}$ in a metric-like space converges to a point $x\in X$ if and only if $\lim_{n\to\infty} \sigma(x_n,x)=\sigma(x,x)$. Question 1. Are the above claims correct? If yes how can we show that $\{B(x,\varepsilon); x\in X, \varepsilon>0\}$ is indeed a base of topology? Side remark: I have also found the same condition under the name metametric in the Wikipedia article on metric ( current revision ). The reference given there is: Väisälä, Jussi (2005), "" Gromov hyperbolic spaces "", Expositiones
Mathematicae, 23 (3): 187–231, doi: 10.1016/j.exmath.2005.01.010 . However, the topology in this paper is defined differently. (For example, a point $x$ is isolated whenever $\sigma(x,x)>0$.) I have experimented a bit with some finite spaces. I suppose I might have missed something, but this seems to be a counterexample to the claim that this is a base. Example. Let $X=\{a,b,c\}$ and we define $\sigma(x,y)$ as follows:
$$
\begin{array}{c|ccc}
    & a & b & c \\\hline
  a & 1 & 1 & 2 \\
  b & 1 & 2 & 2 \\
  c & 2 & 2 & 3 
\end{array}
$$
This $\sigma$ is obviously symmetric. The implication $\sigma(x,y)=0$ $\Rightarrow$ $x=y$ is vacuously true. So it remains to check triangle inequality
$$\sigma(x,z)\le \sigma(x,y)+\sigma(y,z).$$
For any choice of $x$, $y$, $z$ we have $\sigma(x,y)+\sigma(y,z)\ge1+1=2$. So the only remaining possibility to check is $x=z=c$. To see that this is true it suffices to notice that
$$\sigma(c,c)\le2\sigma(c,x)=\sigma(c,x)+\sigma(x,c)$$
for any choice of $x$. (We get either $3\le2\cdot2$ or $3\le2\cdot3$.) As far as I can tell, the balls defined above do not give a base. We have $B_1=B(a,1/2)=\{a,b\}$ and $B_2=B(b,1/2)=\{b,c\}$. But the intersection $B_1\cap B_2=\{b\}$ does not contain any open ball $B(x,\varepsilon)$. Question 2. Is my counterexample wrong? Where did I make a mistake? DISCLAIMER: This is a modification of a question was originally asked on MathOverflow: Base of topology for metric-like space . From the reopen review it seems that it is unlikely to get reopened. And based on the OP comments, they seem reluctant to post it on another site. To me the question does not seem immediately trivial. (In fact, I think that I have a counterexample, but I might have easily missed something.) And judging by the comments on MO at least one another user shown interest in it. So I decided to post it here. EDIT: Only after posting this I have noticed these two older posts: metric-like spaces and Metric-like space . However, I see only one deleted answer there. As far as I can tell, the deleted answer uses different definition of open ball from the one given above. (It uses open ball defined in the same way as for metric spaces.)","['general-topology', 'metric-spaces']"
2557802,"Let $(\mathbb{N},\tau)$ be a topological space, where $\tau=\{\emptyset, \mathbb{N}, \{0\},\{0,1\},\{0,1,2\},\dots\}$","I'm stuck here: Let $(\mathbb{N},\tau)$ be a topological space, where $$\tau=\{\emptyset, \mathbb{N}, \{0\},\{0,1\},\{0,1,2\},\dots\}$$ a) Prove that is not compact. b) Prove that every continuous function $f: (\mathbb{N},\tau) \to \mathbb{R}$ is constant and hence bounded. Part a) is easy: obviously $\tau$ without $\mathbb{N}$ and $\emptyset$ is a cover for $(\mathbb{N},\tau)$ . Suppose that there's a finite subcovering for $\mathbb{N}$ . Then we take the biggest set to see that the next element is not in this subcover and that it doesn't cover $\mathbb{N}$ , so it's not compact. Part b) is what I cannot see. How can I show that every continuous real valued set with domain that topological space is always constant? Thanks for your time.",['general-topology']
2557824,Why do we assume that the solutions to the differential equation y''=-ky are sines and cosines?,"Why do we assume that the solutions to the second order differential equation of the form $$y''=-ky$$ are sines and cosines? Just by inspection it seems pretty obvious that this is the case given that the only difference between $y$ and its second derivative is a negative constant. However, is there a formal way to show that sines and cosines are well-suited solutions to the differential equation?","['ordinary-differential-equations', 'calculus']"
2557856,Growth rate of the nth natural number not constructable with n steps of addition and multiplication,"While messing around with the idea of ordinal collapsing functions, I stumbled upon an interesting simple function: $$C(0)=\{0,1\}\\C(n+1)=C(n)\cup\{\gamma+\delta:\gamma,\delta\in C(n)\}\\\psi(n)=\min\{k\notin C(n),k>0\}$$ The explanation is simple. We start with $\{0,1\}$ and repeatedly add it's elements to themselves: $C(1)=\{0,1,2\}\\
C(2)=\{0,1,2,3,4\}\\
C(3)=\{0,1,2,3,4,5,6,7,8\}\\\vdots\\C(n)=[0,2^n]$ And $\psi(n)$ is defined as the smallest integer not within $C(n)$, which is $2^n+1$. I then extended my function. Imagine all the same definition, except that we now have $$C(n+1)=C(n)\cup\{\gamma+\delta,\color{red}{\gamma\cdot\delta}:\gamma,\delta\in C(n)\}$$ This simple change gives us something a bit more complicated. The first few sets are $C(1)=\{0,1,2\}\\
C(2)=\{0,1,2,3,4\}\\
C(3)=\{0,1,2,3,4,5,6,7,8,9,12,16\}\\
C(4)=\small\left\{\begin{align}0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30,\\ 32, 35, 36, 40, 42, 45, 48, 49, 54, 56, 60, 63, 64, 72, 80, 81, 84, 96, 108, 112, 128, 144, 192, 256\end{align}\right\}\\
C(5)=\{0,\dots,177,179,\dots\}\\
\vdots$ If $\psi(n)$ is the smallest natural number not found in $C(n)$, asymptotically, how fast does $\psi$ grow? The first few values of $\psi$ are $$2,3,5,10,26,178,\dots$$ Here's a program that outputs $\psi$ and here's a program that outputs $C$ . I'm looking for better bounds and/or asymptotic formulas in the form of $$\psi(n)\approx x^{y^n}$$","['recursion', 'asymptotics', 'upper-lower-bounds', 'discrete-mathematics']"
2557857,"A projectile is fired up from the surface of the earth with initial velocity $(u_0, v_0)$","A projectile is fired up from the surface of the earth
with initial velocity $(u_0, v_0)$. Under the influence of constant vertical acceleration − g the projectile
reaches height $h_{max}$ and then falls back to earth. Neglecting air resistance, show that the
fraction of time during its trajectory that the projectile spends above height $h_1$ is $|v_1|/v_0$, where
$(u_1, v_1)$ is the projectile’s velocity vector at height $h_1$. Assume that $0 ≤ h_1 ≤ h_{max}$ I am having trouble solving this because I can't figure out the time the projectile is in the air without a function being given. Or would I not even need that to determine the time it is above $h_1$? Thanks for the help!",['multivariable-calculus']
2557962,Can we find the limit $\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\frac{\left(-1\right)^nx^2}{n^2+x^2}$ without evaluating the sum?,"How to find the limit   $\displaystyle\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\frac{\left(-1\right)^{n}x^{2}}{n^{2}+x^{2}}$   if we don't evaluate the sum? I know the sum is actually an elementary function which we can find it using Fourier series or other methods, but I'm just curious about if there exists some alternative ways to find this limit. I tried to write it as this form: $$\displaystyle\lim_{x\rightarrow\infty}x\sum_{n=1}^{\infty}\left(\frac{x}{\left(2n\right)^{2}+x^{2}}-\frac{x}{\left(2n-1\right)^{2}+x^{2}}\right).$$ As we know, $\displaystyle\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\frac{x}{\left(2n\right)^{2}+x^{2}}$ and $\displaystyle\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\frac{x}{\left(2n-1\right)^{2}+x^{2}}$ must get a same value (we don't need to care about what the exact value is) , so this is in the form $``0\cdot\infty""$, which cannot be evaluated directly. This is where I get stucked. After days of thinking, I'm getting closer to the answer.
We can use easy algebra to get that $$\left |\frac{2x^2}{\left(2n\right)^2+x^2}-\frac{x^2}{\left(2n-1\right)^2+x^2}-\frac{x^2}{\left(2n+1\right)^2+x^2}\right |\leq\frac{1}{n^2}\quad\forall n\in\mathbb{Z^+},x\in\mathbb{R}$$ Hence the series below converges uniformly on $\mathbb{R}$:$$\displaystyle\sum_{n=1}^{\infty}\left(\frac{2x^2}{\left(2n\right)^2+x^2}-\frac{x^2}{\left(2n-1\right)^2+x^2}-\frac{x^2}{\left(2n+1\right)^2+x^2}\right)$$ Changing the order of sum and limit, we can get:$$\displaystyle\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\left(\frac{2x^2}{\left(2n\right)^2+x^2}-\frac{x^2}{\left(2n-1\right)^2+x^2}-\frac{x^2}{\left(2n+1\right)^2+x^2}\right)=0$$ which is$$\displaystyle\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\left(\frac{x^2}{\left(2n\right)^{2}+x^{2}}-\frac{x^2}{\left(2n-1\right)^{2}+x^{2}}\right)=\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\left(\frac{x^2}{\left(2n+1\right)^{2}+x^{2}}-\frac{x^2}{\left(2n\right)^{2}+x^{2}}\right)$$ and we also know $$\displaystyle\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\left(\frac{x^2}{\left(2n\right)^{2}+x^{2}}-\frac{x^2}{\left(2n-1\right)^{2}+x^{2}}\right)=\lim_{x\rightarrow\infty}\left(-\frac{x^2}{1+x^2}-\sum_{n=1}^{\infty}\left(\frac{x^2}{\left(2n+1\right)^{2}+x^{2}}-\frac{x^2}{\left(2n\right)^{2}+x^{2}}\right)\right)$$
If the limit exists, there must be an equation for the limit $L=-1-L$ which solves $L=-1/2$. So everything needed is to prove that the limit exists. This would require a bit of analysis.
I’m going to prove it via Cauchy’s rule ($\displaystyle\lim_{x\rightarrow+\infty}f\left(x\right)\ exists\Leftrightarrow\forall\epsilon>0\exists X>0 \forall x_1,x_2>X, \left|f(x_1)-f(x_2)\right|<\epsilon$).","['sequences-and-series', 'analysis', 'limits']"
2558007,Where can I read the full proof of the Banach-Mazur theorem?,"The theorem is: every Banach separable space can be embedded in $C[0,1]$ linear and isometrically. I actually found two books which contain the theorem and its proof: -S. Banach, A Course of Functional Analysis [in Ukrainian], Kiev, 1948. -L. A. Lyusternik and V. I. Sobolev, A Concise Course of Functional Analysis [in Russian], Nauka, Moscow, 1982. But I can't read ukrainian nor russian. Does anyone know a book in english with this proof? The functional analysis books I have read so far don't contain it. Thank you.","['general-topology', 'reference-request', 'real-analysis', 'functional-analysis']"
2558046,"If $X_n$ converge to a negative number in probability, then $\lim P(X_n > 0) = 0$?","Let $X_n$ be a sequence of random variables. Let $a$ be a negative real number. If $X_n\overset{p}\to a$, is it true that $\lim_{n\to\infty} P(X_n > 0) = 0$? I think I came up with a proof but it's a little bit long (and in fact, not sure about ""exchanging limit and sum"" the last step). Wlog, assume $a=-1$. Since $X_n\overset{p}\to -1$, then for any $\epsilon >0$, $\lim P(X_n > \epsilon - 1) = 0$. Let $\epsilon = 1 + \frac{1}{k}$, we have $\lim_n P(X_n > \frac{1}{k}) = 0$ for any $k$. For any fixed $n$, $P(X_n > 0) = P(\cup_{k=1}^\infty X_n > \frac{1}{k})$ by continuity of probability. Then we have $P(X_n > 0) = \sum_{k=1}^\infty P(X_n > \frac{1}{k})$. So $\lim P(X_n >0) = \lim_n \sum_{k=1}^\infty P(X_n > \frac{1}{k})=\sum_{k=1}^\infty \lim_n P(X_n > \frac{1}{k}) = \sum_k 0 = 0$","['probability-theory', 'probability', 'measure-theory']"
2558048,What is the probability of a four occurring in 300 dice rolls?,"If I rolled a die 300 times and recorded each outcome, what is the chance of rolling at least one four? I know that the answer will be very close to $1$, but I don't know if there is a formula for finding that exact value. If I did this with two dice, then $P(4)=\frac{11}{36}$, which I only know how to work out if I draw a two-way table. Any help is appreciated, thanks!","['probability', 'dice']"
2558071,Prove that two sequences converge or are Cauchy,"I have the two following implications to prove. The first is this: Assume that $\forall k\in \mathbb{N}, \{f_n(k)\}_{n=1}^\infty \subset \mathbb{R}$ converges in $\mathbb{R}$. Then prove that $\{f_n\}_{n=1}^\infty \subset \mathbb{R}^\mathbb{N}$ is convergent in the metric space $(\mathbb{R}^\mathbb{N}, d)$. I have already proven that d is a metric; it is defined by:
$$ d(f,g)= \sum_{k=1}^\infty 2^{-k} \min\{1, |f(k)-g(k)| \} .$$ For this implication, I have the following so far:
Assume that $\forall k\in \mathbb{N}, \{f_n(k)\}_{n=1}^\infty \subset \mathbb{R}$ converges in $\mathbb{R}$ to some point $p\in \mathbb{R}$. Then, for all $\epsilon>0$, there exists some integer $N$ such that $n\geq N\rightarrow d(f_n(k), p)=|f_n(k)-p|< \epsilon$. Note that $|f_n(k)-p|\leq \min\{1,|f_n(k)-p|\}$ and $0<2^{k}<1$ for all $1\leq k< \infty$, so then for the same set of $k$ values we have that $2^{-k} \min\{1,|f_n(k)-p|\}< |f_n(k)-p|<\epsilon$. From here, I wanted to add all the $2^{-k} \min\{1,|f_n(k)-p|\}$ was less that $\epsilon  \,\times $ the number of $k$'s, but there are infinite $k$ values so that wouldn't really work. Also, I realized that I assumed all the sequences for the different $k$ values converge to the same point, which I don't think is guaranteed. Would anyone be able to point me in the right direction or validate if anything I've shown is very useful? For the second implication, I need to show that given that $\{f_n\}_{n=1}^\infty \subset \mathbb{R}^\mathbb{N}$ converges in the metric space $(\mathbb{R}^\mathbb{N}, d)$, show that $\forall k\in \mathbb{N}, \{f_n(k)\}_{n=1}^\infty \subset \mathbb{R}$ is a Cauchy sequence in $\mathbb{R}$. I believe this will be similar to the first implication I need to prove, but I'm not too sure on how to start.","['real-analysis', 'cauchy-sequences', 'functional-analysis', 'sequences-and-series', 'analysis']"
2558139,Prove that the zero square matrices are the only matrices that are both symmetric and skew-symmetric.,"Prove that the zero square matrices are the only matrices that are both symmetric and skew-symmetric. My Proof I will restate the proposition in a way that makes the proof easier to formulate: There exists a unique matrix $A = 0_{n \times n}$, such that it is both symmetric and skew-symmetric. We first prove that the object exists. $A = 0_{n \times n} = [a_{ij}]_{n \times n} = 0 \ \forall i,j$ $\implies -A = -[a_{ij}]_{n \times n}$ By the properties of scalar multiplication of matrices. $\implies (-A)^T = -(A)^T = -[a_{ji}]_{n \times n}$ By the properties and definition of matrix transposition. $= -0 \ \forall j,i$ By the definition of the zero matrix. $= 0 = A$ and $A^T = [a_{ji}]_{n \times n} = 0 \ \forall j,i$ By the definition of the zero matrix. $= A$ $Q.E.D.$ We must now prove that $A$ is unique. $A = A^T = (-A)^T$ Let $B = B^T = (-B)^T$ We want to prove that $A = B$. We now have $A = (-A)^T, A = A^T, B = (-B)^T, B = B^T$ Adding $A = (-A)^T, A = A^T$ and $B = (-B)^T, B = B^T$, we get $2A = A^T + (-A)^T$ and $2B = B^T + (-B)^T$ $\implies A = \dfrac{1}{2}(A^T) + \dfrac{1}{2}(-A)^T$ and $B = \dfrac{1}{2}(B^T) + \dfrac{1}{2}(-A)^T$ $A - B = \dfrac{1}{2}(A^T) + \dfrac{1}{2}(-A^T) - \dfrac{1}{2}(B^T) - \dfrac{1}{2}(-B^T)$ $= \dfrac{1}{2}(A^T) - \dfrac{1}{2}(A^T) - \dfrac{1}{2}(B^T) + \dfrac{1}{2}(B^T)$ Using the hypothesis. $= 0$ $\implies A = B$ $Q.E.D.$ I would greatly appreciate it if people could please take the time to review my proof for correctness and provide feedback.","['matrices', 'symmetric-matrices', 'linear-algebra', 'proof-verification']"
2558142,Number of way to split $n$ people into nonempty committees with at least 1 chairperson,"I need to find an exponential generating function for the number of way to split $n$ people into nonempty committees with at least 1 chairperson. I am struggling greatly with EGFs... Anyways if we removed the requirement of needing one chair person I can see that the EGF could just be defined as $G(x) = \sum_{0}^{\infty}S(n,k) \frac{x^n}{n!}$ which has a well known closed form (S(n,k) here are the stirling numbers of the first kind. I am unsure how to incorporate the requirement of a chairperson. I see for any committee with $k$ people there are $k$ possibilities for chairperson, but what would we do? Multiply it into the EGF?","['permutations', 'combinatorics', 'generating-functions']"
2558174,If $A$ countable then $\Bbb{R}^2\setminus A$ is path connected [duplicate],"This question already has answers here : Arcwise connected part of $\mathbb R^2$ (4 answers) Closed 5 years ago . Let $A\subset\Bbb{R}^2$ be countable. I need to prove that
  $\Bbb{R}^2\setminus A$ is path connected. I know that through each of $\Bbb{R}^2\setminus A$, there pare uncountably many straight lines, and as there are only countably many points in $A$, uncountably many of these lines will not contain any point of $A$. But why do I construct a path between any two points. Also can this result be generalised, so that: If $X$ is uncountable and $A$ is a countable subset of $X^2$, then
  should $X^2\setminus A$ be path connected.? (where $X$ and $X^2$ are
  path connected of course)","['general-topology', 'path-connected']"
2558179,Geometric interpretation of $|\frac{z+i} {z-i}| =2$,"Consider the equation $$\left|\frac{z+i} {z-i}\right| =2$$ Solving it yields a circle, but I wonder if the equation itself has a geometric interpretation.",['geometry']
2558199,Showing that all solutions to the ODE $x''=4x^3$ cease to exist after a finite time,"I am given the ""Newton equation"" $$x''(t)=4x^3(t)$$
The first part asks for finding a ""conservation of energy"" law. I'll spare the details: the conclusion is that every solution has a constant $C$ such that $\frac{y^2}{2}-x^4=C$ where $y(t)=x'(t)$. (That follows from writing the ODE as a system of two ODEs: $x'=y$ and $y'=4x^3$ which is exact). The second part asks to show that except the trivial solution $x\equiv0$, all solutions cease to exist (and therefore tend to infinity) after a finite time. Now, this is something that can't be inferred by knowing the relation between $x$ and $y$ because it relies on their dependence on $t$, so I suspect I don't have the means to solve it. I'd like to hear what is the technique for these questions so I can do the rest of the problems in my homework that contain similar questions (like, which solutions are bounded). Thanks!",['ordinary-differential-equations']
2558236,Does $f^{-1}(B^\circ)\subset (f^{-1}(B))^\circ$ imply continuity?,"Let $(X,\tau),(Y,\eta)$ be topological spaces and  $f:X\to Y$ a function. Prove that  $f$ is continuous if and only if $f^{-1}(B^\circ)\subset (f^{-1}(B))^\circ,\forall B\subset Y$ $\implies$ Let $B\subset Y.$ As $f$ is continuous, $f^{-1}(B^\circ)=(f^{-1}(B^\circ))^\circ\subset (f^{-1}(B))^\circ$ $\Longleftarrow$ What can I do to prove this side? Is the implication $\implies$ correct?","['continuity', 'general-topology', 'elementary-set-theory']"
2558251,"Spectrum of the operator $(Ax)(t) = x(0) + t x(1)$ for $A: C[0,1] \to C[0,1]$.","I have a question: How can we find the spectrum and resolvent of the operator $A: C[0,1] \to C[0,1]$ which defines as  $(Ax)(t) = x(0) + t x(1)$? $\textbf{Some definitions and facts:}$ The resolvent set of $A$ is: $$\rho(A) = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is invertible} \} = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is bijective} \} $$
And the spectrum of $A$ is: $$\sigma(A) = \mathbb{C}\ \rho(A) = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is not invertible} \} = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is not bijective} \} $$. And we know that $A$ is a positive and a compact operator. If needed I will prove it. Can you please give me the idea on how to find its spectrum? Thanks!","['functional-analysis', 'real-analysis', 'operator-theory']"
2558271,Subset of Banach space is bounded,"I am currently having problems understanding the following problem: Let X be a Banach space and M be a subset of X such that 
$$\forall l \in X' \exists c \gt 0: \sup_{m\in M}l(m) \le c$$
Show that M is bounded. (X' is the dual space of X) My approach would have simply been to assume M is not bounded. Then, we can find a sequence $(x_n)\subseteq M$ with $\Vert x_n\Vert \ge n$. Now, let $l:X\to \mathbb{R}, l(x)=\Vert x\Vert$. Then, $l(x_n)\ge n$. Thus, $\sup_{m\in M}l(m) = \infty$. But this solution seems to be too easy. Also, I did not even use the fact that X is a Banach space. Where did I make a mistake? How should I approach this problem correctly?","['functional-analysis', 'banach-spaces', 'dual-spaces']"
2558297,Maximizing the trace in an elegant way,"Suppose $\Lambda = {\rm diag}(\lambda_1,\cdots,\lambda_n)$, $\Sigma = {\rm diag}(\sigma_1,\cdots,\sigma_n)$, and we have $\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_n \geq 0$ and $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_n \geq 0$. I want to prove that
$${\rm max}[ {\rm Tr}(O^{\rm T}\Lambda O \Sigma)] = \sum_{i=1}^n \lambda_i \sigma_i,$$
where $OO^{\rm T} = I$. One approach is to maximize the function
$$f(o_{ij}) = \sum_{i,j} \lambda_i (o_{ij})^2 \sigma_j$$
under the constraint $\sum_{k} o_{ik}o_{jk} = \delta_{ij}$ by Lagrange multiplier method. I can prove the statement in this way but the whole proof is lengthy and lack of the flavor of linear algebra. Since the statement ""must be true"" intuitively, I want to know if there is an elegant way to prove it. A possible way may be mathematical induction but I failed to make it. Any help is appreciated.","['matrices', 'trace', 'linear-algebra', 'optimization']"
2558300,Counting homomorphisms between $\Bbb Z$ and $\Bbb Z_n$ and also between $\Bbb Z_n$ and $\Bbb Q$,"Recently, I have tried to find out how many group homomorphisms exist from $\Bbb Z$ to  $\Bbb Z_n$ . My argument goes like this: (in the following, $\tau$ and $\phi$ denote the well-known number theoretic functions) Let, $\psi$ be such a homomorphism. Since $\Bbb Z$ is cyclic, hence $\psi{(\Bbb Z)}$ must be a cyclic subgroup of $\Bbb Z_n$ with the generator $\psi{(1)}$ . Using properties of Cyclic groups, we obtain that $| \psi{(\Bbb Z)}|$ can be any positive integer m such that $ m | n$ , hence there are in total $\tau (n)$ number of possibilities for  $| \psi{(\Bbb Z)}|$ and hence for $ o(\psi(1))$. Let S denote the set of all positive integer divisors of n, i.e. $$ S = \{d \in {\Bbb Z}^+ : d | n \}$$ , then |S| =  $\tau(n)$ . Again, since $\psi{(\Bbb Z)}$ is cyclic it follows that for each $d \in S$, we have $\phi(d)$ number of possible distinct images. Since for each such image (for each divisor) it defines a homomorphism, the required number of homomorphisms are :
$$\sum_{d|n} \phi(d) = n$$
and among these n homomorphisms , there are precisely $\phi(n)$ number of epimorphisms. Conversely, from $\Bbb Z_n$ to $\Bbb Z$ I get that there exists only one homomorphism namely the 0 homomorphism. Are my claims and arguments correct? If there is any mistake, please help me by correcting it. I was also trying to find out how many homomorphisms exist from $\Bbb Z_n$ to $\Bbb Q$ i.e. precisely as group homomorphism and as ring homomorphism. Also, conversely, how many homomorphisms exist from $\Bbb Q$ to $\Bbb Z_n$ again as group homomorphism and ring homomorphism seperately and also how many out of these are epimorphisms (in each case). Thanks in advance for helping.","['ring-homomorphism', 'abstract-algebra', 'group-homomorphism', 'ring-theory', 'group-theory']"
2558312,On determinants and common divisors,"Let $n\in\mathbb N$ and let $a_1,\ldots,a_n$ be natural numbers smaller than $10^n$ . Write each $a_k$ in base $10$ and add $0$ 's to the left of each decimal expansion, if needed, so that each $a_k$ is written with $n$ digits. Consider the matrix such that the entries of the $k$ th row are the digits of $a_k$ (written in the same order). Let $d\in\mathbb N$ be such that $d$ divides each $a_k$ . Prove that $d\mid\det A$ . For instance, suppose that $n=4$ and that your numbers are $3876$ , $2784$ , $684$ , and $8388$ , each of which is a multiple of $12$ . Then $$A=\begin{bmatrix}3 & 8 & 7 & 6 \\  2 & 7 & 8 & 4 \\ 0 & 6 & 8 & 4 \\
 8 & 3 & 8 & 8\end{bmatrix}$$ and $\det A=-360$ , which is, in fact, a multiple of $12$ . I learned about this problem yesterday. I found it quite cute and I decided to share it with all of you. Note: I know how to prove it.","['decimal-expansion', 'divisibility', 'matrices', 'determinant', 'puzzle']"
2558315,Additive and multiplicative function.,"We have $f:\mathbb{R} \to \mathbb{R}$ and we know that $f$ is both additive: $f(x+y)=f(x)+f(y)$ and multiplicative: $f(xy)=f(x)f(y)$ and I found out that this means that $f(x)=0$ for any $x$ or $f(x)=x$ for any $x$ but I don't know how to prove it. Can you help me? I know that if $f$ is continuous or monotone we can show what we want only from the first relation, is this somehow related to the second relation?","['real-analysis', 'calculus', 'functions']"
2558374,Connection between minimal polynomial of $\cos(2\pi/k)$ and Euler's totient function,"Background I'm a recreational mathematician whose formal math education is only to pre-university level. I'm very much a self-learner and I particularly like (elementary) number theory. I was investigating a problem originally asked on Twitter, which was For each $k$, is there always an $N$ for which the integers less than and coprime to $N$ sum to $kN$? $(k,N\in\mathbb{N})$ The answer to this is no, and it turns out that if Euler's totient function , $\phi(n)$, never has value $2k$, then there is no such $N$ for $k$. The missing values for $k$ are given in http://oeis.org/A079695 . In the comments to sequence A079695 it's stated that "" Because the degree of the minimal polynomial of $\cos(2\pi/k)$ is $\phi(k)/2$ , the degree can never be a number in this sequence. "" I'm familiar with cosine and totient, of course, but not familiar with minimal polynomials. I did a little research on minimal polynomials, but I don't at all understand why a trigonometric function should have any connection to a function, $\phi(n)$, that is essentially about divisibility of positive integers. So... Question Is there a straightforward way to explain why these two functions (cosine and totient) are connected via minimal polynomials?","['minimal-polynomials', 'trigonometry', 'totient-function', 'elementary-number-theory']"
2558398,Sequence in uncountable set,"Given an uncountable subset $A$ of $(0,1)$, does there always exist $a,r>0$ such that $a+r,a+r^2,a+r^3,\dots$ are all in $A$? For example, if $A$ contains an interval, it is easy to find such $a,r$. To try to show this, we can assume that no such $a,r$ exist (meaning that for any $a,r$, there exists $k$ with $a+r^k\not\in A$) and show that the set must be countable.",['real-analysis']
2558403,What does $f(5x)$ mean when I differentiate?,"if 
$$f(5x)=x^2 + x$$ $$f '(2) = ?$$ Answer is 9/25 But I do not know how it came How i can factor or simplify $$f(5x)$$ but i want understand what f(5x) mean?","['derivatives', 'calculus']"
2558474,Compute; $\lim_{x\to\infty}\frac{(1-y^{x-1}\frac{x-1}{2})xy^{x-1}}{1-xy^{x-1}}$ with $0 \leq y <1$.,"Prove that $$\lim_{x\to\infty}\frac{(1-y^{x-2}\frac{x-1}{2})xy^{x-1}}{1-xy^{x-1}}=1$$ where $x \in \mathbb{N}$ ($x \neq 0$) and $0 \leq y <1$. I have managed to to multiply by $\frac{2}{2}$ to get
$$\lim_{x\to\infty}\frac{[2-y^{x-1}(x-1)]xy^{x-1}}{2-2xy^{x-1}}$$
And then, through expanding and rearranging :
$$\lim_{x\to\infty}\frac{(2-2xy^{x-1})xy^{x-1}+x^{2}y^{2x-2}+xy^{2x-2}}{2-2xy^{x-1}}$$
Which obviously results in :
$$\lim_{x\to\infty}\bigg(\frac{xy^{x-1}}{2-2xy^{x-1}}+\frac{x^{2}y^{2x-2}+xy^{2x-2}}{2-2xy^{x-1}}\bigg)$$ However I don’t know how to go on from here.","['real-analysis', 'limits', 'calculus', 'multivariable-calculus', 'analysis']"
2558475,Find the probability that no kid will have his own pair of shoes,"In the morning, $n$ children come to the kindergarten and leave their shoes in the locker room. Leaving the kindergarten one by one, each child takes one left and one right shoe, accidentally equiprobably choosing them from among the remaining ones. Find the likelihood that none of the children will leave in their own pair of shoes. My thoughts: I assume that decisions are independent based on accidentally equiprobably choosing them from among the remaining ones part. Let $I_l$ and $I_r$ be indicator r.v. for choosing his/her left shoe. Let $A$ be the probability that none of the children will leave in their own pair of shoes $$P(I_l=1)=\frac1n; P(I_r=1)=\frac1n$$ Leaving without his/her pair of shoes can occur in several ways: $1$) Choose his/her left shoe and other (not his/her) right shoe
$$P(I_l=1)P(I_r=0)=\left(\frac1n\right)^n\left(1-\frac1n\right)^n$$ $2$) Choose his/her right shoe and other (not his/her) left shoe
$$P(I_r=1)P(I_l=0)=\left(\frac1n\right)^n\left(1-\frac1n\right)^n$$ $3$) Nobody chose his/her pair of shoes
$$P(I_l=0)P(I_r=0)=\left(1-\frac1n\right)^n\left(1-\frac1n\right)^n$$ Therefore, $$P(A)=2\left(\frac1n\right)^n\left(1-\frac1n\right)^n+\left(1-\frac1n\right)^{2n}$$ Here I assume that kids can distinguish between right and left shoes. If they can not: probability of choosing left shoe out of $2n$ shoes: $$P(\text{left})=\frac{n}{\binom{2n}{2}}$$ by symmetry the same for $P(\text{right})$ $1$) Chose two left shoes included his/her:
$$(P(\text{left})P(\text{left}))^n=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$
Power $n$, because there are $n$ people who make this decisions $2$) Chose two right shoes included his/her:
$$(P(\text{right})P(\text{right}))^n=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ $3$) Choose one left included his/her and one right excluded his/her own:
$$P(\text{left})P(\text{right})=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ $4$) Choose one right inlcuded his her and one left excluded his/her own
$$P(\text{right})P(\text{left})=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$","['combinatorics', 'probability']"
2558487,how to find out a matrix for a given minimal polynomial,"I know how to find out the the minimal polynomial for a given matrix.
But I am stuck to do the reverse process. For example how to find out a
 $3\times3$ matrix, whose minimal polynomial is $x^2$.",['linear-algebra']
2558494,Solve $f'=f$ using fourier transform.,"I'm trying to solve $f'=f$ using fourier transform. I know that $$\hat f'(\alpha )=2i\pi \alpha  \hat f(\alpha )$$
therefore
$$f'=f\iff 2i\pi \alpha \hat f(\alpha )=\hat f(\alpha )\iff \hat f(\alpha )=0\iff f(x)=0,$$ what wrong ? Because the solution should be $f(x)=e^{x}$.","['ordinary-differential-equations', 'fourier-transform']"
2558545,Does $\lim_{n\rightarrow \infty} \left(r+\frac{1}{n^2}\right)\uparrow \uparrow n=e$ hold?,"Does $$\lim_{n\rightarrow \infty}\left (r+\frac{1}{n^2}\right)\uparrow \uparrow n=e$$ hold ? $r$ is the number $e^{e^{-1}}$ , the largest real number for which the infinite power tower $r\uparrow r\uparrow r\uparrow \cdots$ converges. So we have a power tower of $n$ numbers having the value $e^{e^{-1}}+\frac{1}{n^2}$. Numerical examples I calculated with PARI/GP indicate that the error is about $\frac{3.614}{n}$.","['complex-dynamics', 'tetration', 'calculus', 'limits']"
2558551,$A_n$ is generated by $3$-cycles for $n>2$,"I am reading about alternating groups and I have seen this theorem : For $n> 2$,  $A_n$ is generated by $3$-cycles. I am confused about it. Now if we have a group that generated by an element we would have that element multiplied by itself (or whatever binary operations) until we back to the identity.
But in this case the proof of the theorem takes an arbitrary element of the group and write it as decomposition of $3$-cycles .
In a theorem proving that $A_n$ is simple they tried to find a $3$-cycle in a subgroup that assumed to be normal in $A_n$ and once they found it they conclude that the subgroup is equal to $A_n$ hence $A_n$ is simple. So is it right that any subgroup $H$ of $A_n$ that include a $3$-cycle is trivial i.e $H=A_n$?","['abstract-algebra', 'group-theory']"
2558553,What is the difference between Procrustes analysis and the Linear Transformation in terms of Shape Analysis?,"Let's say you have two objects, each described by some 2D corresponding points. 
In order to compare these two shapes, you can multiple algorithms: Procrustes analysis Search the Linear / Affine transformation (with least-squares) Other ... My question is; what's the difference between the first two? For me, it seems like Procrustes is the same as finding the Linear/Affine transformation, only divided in 3 steps (translation, rotation and than scaling). And they both try to minimize square distance","['affine-geometry', 'statistics', 'linear-transformations', 'geometry', 'linear-algebra']"
2558565,Simplify expression $\frac{2\cos(x)+1}{4\cos(x/2+π/6)}$,How to simplify the following expression: $$\frac{2\cos(x)+1}{4\cos\left(\frac x2+\fracπ6\right)}$$ I got to: $ \dfrac{2\cos(x)+1}{4\cos\left(\dfrac x2\right)\cdot \dfrac{\sqrt3}2-\sin(x) \cdot \frac 12}$,['trigonometry']
2558598,"For $f$ in dual space, there exists $x$ with norm 1 and $f(x)=\|f\|$ if space is reflexive (and nontrivial)","Let $X\ne\{0\}$ be a reflexive space and let $f\in X^*$, where $X^*$ is the dual of $X$. I want to know: in general, does there exist an $x\in X$ with $\|x\|=1$, and $f(x)=\|f\|$, where $\|f\|$ is defined as $\sup\{|f(x)|:x\in X,\|x\|=1\}$? I know this is true for $\mathbb{R}^n$ with the norm from the standard inner product, but I'm wondering if it is true in general.","['functional-analysis', 'normed-spaces', 'reflexive-space', 'dual-spaces']"
2558601,Prove that $\sum_{n=0}^N\binom{2N-n}N2^n(n+1)=(1+2N)\binom{2N}N$,"I used WolframAlpha to calculate a sum but it didn't show me the way :( Anybody has a hint or a solution for proving this sum?
$$\sum_{n=0}^N\binom{2N-n}N2^n(n+1)=(1+2N)\binom{2N}N$$","['combinatorics', 'summation']"
2558614,Let $f(x)=x^3-x^2-x+a$ only have a real negative root then what is range of $a$,Let $f(x)=x^3-x^2-x+a$  only have a real negative root then what is range of $a$ I got it : $$g(x)=x^3-x^2-x  \ \ \ h(x)=-a$$ Now we have : so must $-a<-1 \to a>1$ But I want to be algebraic please help me !,['algebra-precalculus']
2558619,Computing integral involving Dirac Delta Function,"Compute
$$
\int_{-\infty}^{\infty} t^2 \delta(\sin(t)) e^{-|t|} \mathrm dt
$$
In closed form, where $\delta(t)$ is the Dirac Delta function . My attempt: $$
\int_{-\infty}^{\infty} t^2 \delta(\sin(t)) e^{-|t|} \mathrm dt = \int_{-\infty}^{\infty} \delta(\sin(t))t^2 e^{-|t|}\mathrm dt
$$ Then noting that $\sin(t)$ is zero whenever $t=n\pi$. By formula (2) and (7) in the above link, \begin{align}
\int_{-\infty}^{\infty} \delta(\sin(t))t^2 e^{-|t|} \mathrm dt& = \sum_{n=-\infty}^{\infty} \frac{(n\pi)^2e^{-|n\pi|}}{|\cos(n\pi)|}
\\&
=2\pi^2\sum_{n=0}^{\infty} \frac{(n)^2e^{-n\pi}}{1}
\end{align} However , I am stuck here, i do not know how to procede, Wolfram Alpha tells me that this sum doesn't converge so how can i compute it in closed form? I can only assume I have gone about this the wrong way or made a mistake. Any help would be great.","['fourier-analysis', 'calculus', 'integration', 'dirac-delta', 'sequences-and-series']"
2558635,Hyperplane doesn't contain component of a scheme,Suppose that $I$ is ideal sheaf of $\mathcal{O}_\Bbb{P^r}$. Let $X$ be a scheme defined by $I$. Is it true that we can find hyperplane $H$ such that it doesn't contain any components of $X$?,['algebraic-geometry']
2558679,Probability to get a particular string.,"We are generating a strings of length $n$ . The string consists of $n_1$ $1`s$ and $n_2$ $2`s$ . Where $n_1+n_2=n $ . All permutations of the string are equally likely. What is the probability of the event $A({m}_{11},{m}_{12},{m}_{21},{m}_{22} ) = \{{v}_{11} = {m}_{11},{v}_{12} = {m}_{12},{v}_{21} = {m}_{21},{v}_{22} = {m}_{22}\}$ ? What will be the probability space in the case? How can I build it? ${v}_{ij}$ - denotes the number of occurrences in the string when the j goes immediately after i. For example, if we have the following string $122212212121$ , then ${v}_{11} = 0, {v}_{12} = 4, {v}_{21} = 4, {v}_{22} = 3$ . I can not get how to build the probability space in the case. I tried to compute the probability of $A$ by noting that there are $2^n$ strings we can get. Then I thought about using Markov chain to compute the number of strings which would be inappropriate for the event $A$ and subtracting them from $2^n$ and dividing the result by $2^n$ due to the classic definition of the probability. I would like to get a better way to compute the probability of the event $A$ if it is possible and to get the idea behind building the probability space.","['probability-theory', 'probability']"
2558753,Characterization of continuous functionals on Fréchet spaces in terms of a seminorm,"I've recently encountered Fréchet spaces for the first time, and I was wondering if it remains true that a functional $T \rightarrow \mathbb{R}$ with $S$ a Fréchet space, is continuous if for all $\phi \in S$  we have $$|T\phi| \leq c\|\phi\|_S$$ where $\|\cdot\|_S$ denotes a semi-norm on the $S$ space. The reason I'm asking is that I have only ever seen the above result formulated for Banach spaces, and I was curious if it extends naturally?","['functional-analysis', 'topological-vector-spaces']"
2558790,"Radon-Nikodym Theorem for (positive) measures, chain rule","Let us take some time to recall the Radon-Nikodym Theorem for (positive) measures: If $\nu$ and $\mu$ are $\sigma$-finite measures on $(X, \mathcal{M})$ then $\nu = \nu_a + \nu_s$ with $\nu_a \ll \mu$ and $\nu_s \perp \mu$, and the decomposition is unique. Moreover, $d\nu_a = f\,d\mu$ for a nonnegative measurable function $f$ (note: $d\nu_a = f\,d\mu$ means that for every measurable $E$, $\int_E d\nu_a = \int_E f\,d\mu$). If $\nu \ll \mu$ then $\nu_s = 0$ and the function $f$ is called the Radon-Nikodym derivative and is denoted ${{d\nu}\over{d\mu}}$. Say that $\mu$, $\nu$ and $\sigma$ are finite measures on $(X, \mathcal{M})$ and suppose that $\mu \ll\nu$ and $\nu \ll \lambda$. How do I see that $\mu \ll \lambda$ and$${{d\mu}\over{d\lambda}} = {{d\mu}\over{d\nu}}{{d\nu}\over{d\lambda}}$$for $\lambda$ almost every point?","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
2558804,Intersection of two x powers,"Many months ago in class I came up with the problem: $$x^{(x+1)} = (x+1)^x$$
Using the solve function on my calculator I have found that the answer is around 2.29... This is backed up by the graph. However I was determined to find the inverse function where: $$x = f(y) $$ or find the answer algebraically $$ x = _-$$ Being a lowly first year A-level student this has been pretty much impossible. So far doing some simple rearranging the equation looks like: $$ x^{\frac 1 x} - \frac 1 x - 1=0$$I've tried many methods and had a good look online. So far I have just about been able to solve the equation $x^{\frac 1 x} = y$ by finding the inverse of $x^x$ graphically so $$ x^x = y $$ $$ x = P(y)$$
 where P is the inverse function of $x^x$, then doing $$x^{\frac 1 x} = y$$ $$e^{ln(x^{\frac 1 x})}=y$$ $$\frac1 x (ln(x))=ln(y)$$ $$xln(x)=\frac 1 {ln(y)}$$ $$x^x = e^{\frac1 {ln(y)}}$$ $$x=P\biggl(e^{\frac1 {ln(y)}}\biggr)$$I don't know how to fit this in to my original equation to have just x on one side and no x's on the other side ... I do not want to use any guesswork methods or methods where you work your way to the answer slowly. I have tried using methods where you go one step up above powers so $x^x$ becomes something like $x@2$ where @ is used like + or X then trying to find the inverse of this like - is to + and / is to X  and $\sqrt x$ is to $x^2$, to help you bridge the barrier between the $x^x$ and the $\frac 1 x$ but I couldn't find any way of doing this. Thank you for the help.",['algebra-precalculus']
2558811,How can the Central Limit Theorem apply to Finite Populations?,"In my statistics for beginners course we've just been introduced to the CLT, where it's been stated that a distribution of sample means tends to the normal dist. as your sample size $n$ increases to infinity. But what if your population is finite (i.e. of size $N$), so that your max sample size can only be of size $N \ll \infty$? Will such a distribution (which must be that of nearly all practical statistical surveys)not follow the CLT? My best attempt at thoughts on this so far go like this: If I were to take a random sample from my population of size N, each sample though containing just a single member of the pop, calculate and plot the 'mean' of each sample (which would just equal the single value) until I've sampled and plotted every member and done so for each only once, I would eventually of course replicate exactly the population distribution. Suppose then I repeat the experiment, increasing my sample size each repetition, until my sample is of size $N$. I take a single sample, plot its mean, then by definition this is the same as the population mean $\mu$. So here, as my sample size has increased, my distribution of sample means hasn't tended to the Normal - with an ever thinner distribution with flatter tails and a taller peak - but more like a hyper-idealised version of the Normal - a single value at the population mean. Clearly then, for finite populations - if I've understood the idea behind the CLT correctly, which is a big if -the CLT does not apply, rather in these practical cases, their sample mean distribution approaches something approximately Normal? Is it the case then that the CLT is more a theoretical concept, that applies to infinitely large populations, from which samples sizes can tend to infinity? Further to this, I've read for the CLT to apply, the random variables of your population have to be I.I.D - if I'm using SRS without replacement for a finite population, does that mean the variables aren't I.I.D anymore, and thus the CLT would also not apply because of this? If the population were infinite though and I used SRSWOR, would the r.v.'s then be I.I.D, thus meaning the CLT would apply? I appreciate all your insight on this; I'm very new to statistics, so I apologise if a lot of this is pretty basic and if my thoughts were way off. Thanks for any help you can lend, really appreciate it.","['descriptive-statistics', 'statistics']"
2558856,"Prove that the eigenvectors of $(A - pI)^{-1}$ are the same as the eigenvectors of $A$ for real, symmetric $A$","From the book ""Numerical Linear Algebra"" p. 206: $A$ is a real, symmetric matrix. For any $p\in R$ that is not an eigenvalue of $A$, the eigenvectors of
  $(A - pI)^{-1}$ are the same as the eigenvectors of $A$, and the
  corresponding eigenvalues  are$ \{(q_j - p)^{-1}\}$, where $\{q_j\}$
  are the eigenvalues of $A$ How is this result derived?","['eigenvalues-eigenvectors', 'numerical-linear-algebra', 'linear-algebra']"
2558914,What is the coefficient of $x^{9}$ in the expansion of $(1+x)^{12}(1+x)^{4}$?,"Answer in the textbook: $\sum_{k=0}^{4} \binom{12}{9-k}\binom{4}{k}$ Can I just multiply the two terms together to get $(1+x)^{16}$ then apply the binomial coefficient theorem? I don't know how they got the sum at the end, I was only taught how to find the coefficient of a term in one binomial expansion using the binomial coefficient theorem...","['combinatorics', 'binomial-coefficients']"
2558941,polynomials converging point wise to $f$ on $\mathbb{R}$,Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be continuous. Would there exist a sequence of polynomials converging point wise to $f$ on $\mathbb{R}$? I know that it is true on a compact set in $\mathbb{R}$.,"['real-analysis', 'measure-theory', 'weierstrass-approximation']"
2558969,"Is $\{(x,y)\mid f(x)>y\}$ connected if $X$ is connected? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Suppose $X$ is a connected space, and $f:X\rightarrow \mathbb{R}$ a continuous real valued function. Is it true that $\{(x,y)\in X\times\mathbb{R}\mid f(x)>y\}$ is connected?","['general-topology', 'connectedness']"
2559008,Multiplication operation of End(X) with strong topology not continuous,"Let $(X, ||\ ||)$ be a normed space. $dim X = \infty$. $L(X)$ is a space of continuous (which is equialent to bounded in a normed space) linear operators with strong topology. Strong topology is defined by zero neighborhoods: $U(x, W) = \{A \in L(X) | Ax \in W\}$, where $x \in X, 0 \in W \in T_X, T_X$ is topology on $X$, and these neighborhoods finite intersections. Convergence $A_n \rightarrow A (A_n, A \in L(X))$ is equialent to convergence $A_n x \rightarrow Ax$ over $X$, $\forall x \in X$. Show that multiplication operation of End(X) (сomposition of operators) isn't continuous.","['functional-analysis', 'normed-spaces', 'operator-theory']"
2559019,Prime/Maximal Ideals in $\mathbb{Z}[\sqrt d]$,"Let $d \in \mathbb{Z}$ be a square free integer.  $R=\mathbb{Z}[\sqrt d]$ =$\{a+b\sqrt d | a,b \in \mathbb{Z} \}$. Overall, I'm trying to show that every prime ideal $P \subset R$ is a maximal ideal. So far I showed that $I \subset R$ is finitely generated.  $I=\{(x,s+y \sqrt d)\}$ And now I'm trying to show that R/P, for some prime ideal is a finite ring with no zero divisors.  From there it would follow that R/P is a field and any prime ideal is maximal. I know R could also be written as $R= \mathbb{Z}[x]/(x^2-d)$.  How could I show that R/P is a quotient of $\mathbb{Z}/n\mathbb{Z}[x]/(x^2-d)$?","['abstract-algebra', 'ring-theory', 'maximal-and-prime-ideals', 'ideals']"
2559049,Ways to arrive at the existence of irrational numbers,"I know about a way Greeks arrived at the existence of irrational numbers by showing that sometimes two line segments can be incommensurable. And about a simple way by which it can be shown that some numbers are irrational, for example, as is usually shown that $\sqrt2$ is irrational. Also, it can be shown that some numbers are transcendental and because all rationals are algebraic that shows that there are some non-rational, that is, irrational numbers. And also there is a way that shows that all rational numbers have periodic expansion in every base and since there are non-periodic expansions that also shows the existence of irrationals. And there is countability/uncountability way. Are there some other ways?","['irrational-numbers', 'alternative-proof', 'analysis']"
2559085,What does a semicolon denote in the context of probability and statistics?,"I sometimes see the notation $;$ being used in a statistical context For example, let $f_X(x)$ be the probability density function associated with random variable $X$, then sometimes I see things like $f_X(x| y; \theta)$, where $\theta$ is a set of the mean and the covariance associated with the distribution. What does these $;$ mean? Any reference helps.","['notation', 'statistical-inference', 'probability-distributions', 'statistics', 'probability']"
2559130,State space model with constant offset for harmonic balance,"Given a linear state space model as $$
\begin{split}
\dot{x}_1 &= -50\,x_1 + 5\,x_2 - 0.15\,u + 250 \\
\dot{x}_2 &= 5 - x_1 \\
y &=0.2\,x_1 - 1 \,.
\end{split}
$$ I now would like to analyse this model with harmonic balance given a symetric  nonlinear curve $$
u = f(e)
$$ with $e = w - y$ and $w = 0$, as usual with harmonic balance, so $$
u = f(-y) = -f(y)\,.
$$ My problem here are the constant terms in the state equations and the output equation. How can I deal with those? The $f(\cdot)$ curve is point symmetric to the origin, so I cannot just omit the $-1$ in the output equation, otherwise the symmetry required for application of harmonic balance is not given anymore at the equilibrium $x_1 = 5$.","['control-theory', 'ordinary-differential-equations', 'dynamical-systems', 'nonlinear-system']"
2559138,Evaluate the limit $\lim_{x\to \infty} x(16x^4 + x^2+1)^{1/4}-2x^2$,"Can someone please check my conclusion to the evaluation of the following limit?
$$\lim_{x\to \infty} x(16x^4 + x^2+1)^{1/4}-2x^2$$ I got that the limit is equal to infinity. If limit is equal to infinity does this mean that limit does not exist?","['limits-without-lhopital', 'calculus', 'limits']"
2559158,"Compact embedding in $L^2((0,\infty),rdr)$","Let $H$ be the closure of $C^{\infty}_0(0,\infty)$ with respect to the inner product
$$(f,g)=\int_0^{\infty}\left(f'(r)g'(r)+h(r)f(r)g(r)\right)rdr,$$
and induced norm $||f||_H^2=(f,f)$, and where $h(r)=1/r^2+\lambda$ with $\lambda>0$. Is this space compactly embedded in $L^2((0,\infty),rdr)$? Here is what I am able to show: $H$ is continuously embedded in $L^2((0,\infty),rdr)$ and in $W^{1,2}((0,\infty),rdr)$, i.e., 
\begin{align}
\int_0^{\infty}f^2(r)rdr\leq\int_0^{\infty}\left(f_r^2(r)+f^2(r)\right)rdr\leq \max\left\{1,\dfrac{1}{\lambda}\right\}||f||_H^2.
\end{align} $H$ is embedded in $W_{loc}^{1,2}(0,\infty)$. So $f$ is continuous on $(0,\infty)$. Every $f\in H$ satisfies $f(0)=0$ and $f(\infty)=0$. Using $f(0)=0$, we have that $H$ is embedded in $L^{\infty}[0,\infty)$.","['functional-analysis', 'sobolev-spaces', 'partial-differential-equations']"
2559192,Finding a basis for an eigenspace? Where do the additional vectors come from?,"I want to diagonalize the following matrix: $$A =\begin{bmatrix}
    1&0&0&0 \\
    0&0&1&0 \\
    0&1&0&0\\
    0&0&0&1
\end{bmatrix}$$ And I get the following characteristic equation: $(\lambda - 1)^3(\lambda +1)$ and therefore $\lambda=1,-1$ Firstly get the basis vectors for $\lambda = 1$
$$(A - \lambda_2 I_4) =  \begin{bmatrix}
    0&0&0&0 \\
    0&-1&1&0 \\
    0&1&-1&0\\
    0&0&0&0
\end{bmatrix} \rightarrow \text{row reduce} \rightarrow \begin{bmatrix}
    0&1&-1&0 \\
    0&0&0&0 \\
    0&0&0&0\\
    0&0&0&0
\end{bmatrix}$$ So I have $x_2 = x_3$ wich yields the vector:
$$v_1 = \begin{bmatrix}
    0 \\
    1 \\
    1\\
    0
\end{bmatrix}$$ However there should be $3$ basis vectors total for $\lambda = 1$ according to the characteristic equation. The answer key gives vectors: $$\begin{bmatrix}
    1 \\
    0 \\
    0\\
    0
\end{bmatrix} , \begin{bmatrix}
    0 \\
    0 \\
    0\\
    1
\end{bmatrix}$$
to be the other basis vectors for $\lambda = 1$, but where do these vectors come from in regards to my reduced matrix? I understand there ought to be 2 additional vectors to the one that I found but why are they the vectors given?","['eigenvalues-eigenvectors', 'matrices', 'matrix-decomposition', 'diagonalization', 'linear-algebra']"
2559211,"If $(x_n)$ converges to a non-invertible element, then $\lim \| x_n^{-1} \| = \infty .$","Let $(x_n)$ be a sequence of invertible elements in a Banach algebra $A$ with identity $e$ converging to a non-invertible element $x.$ Prove that $\lim \| x_n^{-1} \| = \infty .$ My attempt: I tried proving it by contradiction. If $\lim \| x_n^{-1} \| \neq \infty,$ then we may assume that there exists $C>0$ such that $\|x_n^{-1}\|\leq C$ for all $n \in \mathbb N.$ Then I tried to get a contradiction to the fact that $x$ is not invertible by showing $\|e-x\|<1,$ but I couldn't show this. Am I on the right track? Any hints are appreciated.","['functional-analysis', 'banach-algebras']"
2559248,triangulating a sphere,"Can there be a triangulation of the sphere with $3$ triangles? We can start with the sphere and three vertices fixed. This divides the sphere into two triangles, which is illegal as the triangles would share more than two sides. Then if we add another vertex, we get four triangles, which is possible. Is there no way of obtaining three?","['geometric-topology', 'general-topology']"
2559281,Motion of a falling object with air resistance,"I was wondering how you would model the velocity of a falling object, taking into account air resistance. Bear in mind I have only studied basic calculus, and have no experience with differential equations. Considering a general solution for mass $m$ and drag $kv^2$, where $k=\frac{1}{2} \rho AC_D$. Let's say that when $t=0$, $v=0$. Using Newton's Second Law: $mg - kv^2 = ma$, hence $a = g - \frac{k}{m} v^2$. From here, I tried to integrate with respect to $t$, which gave $v = gt-\frac{kt}{m}v^2$. This, when solved for v, seems to model the velocity correctly, but I have been led to believe that solutions to differential equations of this kind will involve $e^x$ in some way. Is my solution correct, or have I integrated incorrectly? How do we go from here to a function for v in terms of t?","['classical-mechanics', 'ordinary-differential-equations', 'mathematical-modeling']"
2559296,How to interpret 2 variables separated by a comma in chained inequalities,"What does $0\le x,y\le1$ mean? See the red circled part in the image below for an example. I first thought it meant: $x\ge0$ and $y\le1$ Then I thought it meant: $0\le x\le y \le 1 $ But, based on the green part, I believe it means: $x$ and $y$ are in $[0,1]$ Is this notation unambiguous? In probability, the comma means $\bigcap$, so, to me, these are ""separate"" statements, as in (1) and not (3).","['algebra-precalculus', 'inequality', 'notation']"
2559302,Attaching $2$-dimensional cell to $D^2$ gives the space $S^2/(x\sim -x)$,"I am studying Algebraic Topology, and right now I am going through cell-attachment, which I have a pretty hard time to grasp. An ""example"" they give in the book is: Example: Define $X$ to be the space obtained from $S^2$ by identifying antipodal points on the equator, then it is easy to see that $X$ can be obtained by attaching a $2$-dimensional cell to $D^2$. I suppose this should be easy, but it isn't for me, so I would be really happy if someone could help me through this example and how to define the map. Since I don't even know where (and how) to start.","['algebraic-topology', 'general-topology', 'cw-complexes']"
2559339,Existence of the vector that decomposes the trace of diagonal and symmetric matrix,"Question: Suppose that $\Lambda$ is an $N × N$ real-valued diagonal
  matrix and $Q$ is real symmetric. Suppose that $tr\ \Lambda \neq 0$
  and $tr\ Q \neq 0$. Prove there is a vector $v \in \mathbb{R}^N$ such
  that $$v^T\Lambda v = tr\ \Lambda, v^TQv = tr\ Q $$ My thought: Decompose the $\Lambda$ as $\Lambda = U^T\Lambda U, \ \forall\ U^TU = I $ and $Q = U^T\Lambda_1 U$. So $$v^T\Lambda v = (Uv)^T\Lambda (Uv)= tr\ \Lambda$$ and $$v^TQ v = (Uv)^T\Lambda_1 (Uv) = tr \ Q = tr\ \Lambda_1$$ 
Intutively,the structure is same so they could preserve the same property. But how could I prove the $v$ in two formulas is the same one? Could anyone help me out? Thank in advance!","['matrices', 'matrix-decomposition', 'trace', 'linear-algebra']"
2559357,Wrong application of L'Hôpital's rule?,"I was trying to find the right oblique asymptote of the following function:
$$ g(x)= \frac{x^2+(x+2)\cosh(x)}{\sinh(x)}=\frac{x^2}{\sinh(x)}+(x+2)\coth (x)$$
Now since $\frac{x^2}{\sinh(x)}\to 0$ and $\coth(x)\to 1$ as $x\to \infty$, it is easy to see that this asymptote is $y=x+2$. However, when I try to find this asymptote using L'Hôpitals rule, I get a different result: 
$$\begin{align}
\lim_{x\to \infty}g(x) & =\lim_{x\to \infty} \frac{x^2+(x+2)\cosh(x)}{\sinh(x)} \\
& \stackrel{LH}{=}\lim_{x\to \infty}\frac{2x+\cosh(x)+(x+2)\sinh (x)}{\cosh(x)} \\
& =\lim_{x\to \infty} \frac{2x}{\cosh(x)}+1+(x+2)\tanh(x) \\
& =\lim_{x\to \infty} x+3
\end{align}$$
since $\frac{2x}{\cosh(x)}\to 0$ and $\tanh(x)\to 1$ as $x\to \infty$. This suggests that the asymptote is $y=x+3$ instead of $y=x+2$. A quick look at the function using WolframAlpha shows that $y=x+2$ is indeed the correct asymptote, so I highly suspect that I somehow applied L'Hôpitals rule in a wrong way. I have however no clue as to what I did wrong. Could anyone enlighten me?","['real-analysis', 'asymptotics', 'calculus', 'limits']"
2559375,Proving $\lim_{x\to a}f(x)$ and $\lim_{h\to 0}f(a+h)$ are equivalent using $\epsilon$-$\delta$ argument,"In Spivak's Calculus , he asks for a proof that $\lim_{x\to a}f(x)=\lim_{h\to 0}f(a+h)$ . He first shows that the existence of $\lim_{x\to a}f(x)$ implies the existence and equivalence of $\lim_{h\to0}f(a+h)$ , and then he says the argument for the other direction is ""similar,"" but I am having a hard time replicating it (I may be getting unnecessarily bogged down in notational issues). His proof of the first direction is essentially as follows: (Spivak forward direction): Let $\ell=\lim_{x\to a}f(x)$ and define $g(h)=f(a+h)$ . Then for every $\epsilon>0$ there is a $\delta>0$ such that, for all $x$ , if $0<|x-a|<\delta$ , then $|f(x)-\ell|<\epsilon$ . Now, if $0<|h|<\delta$ , then $0<|(a+h)-a|<\delta$ , so $|f(a+h)-\ell|<\epsilon$ , which we can write as $|g(h)-\ell|<\epsilon$ . Thus, $\lim_{h\to0}g(h)=\ell$ , which can also be written $\lim_{h\to 0}f(a+h)=\ell$ . The same sort of argument shows that if $\lim_{h\to 0}f(a+h)=m$ , then $\lim_{x\to a}f(x)=m$ . So either limit exists if the other does, and in this case they are equal. My attempt at other direction: Let $m=\lim_{h\to 0}f(a+h)$ . Then for every $\epsilon>0$ there is a $\delta>0$ for all $h$ such that if $0<|h|<\delta$ then $|f(a+h)-m|<\epsilon$ . Now, if $0<|x-a|<\delta$ , then $|f(a+(x-a))-m|=|f(x)-m|<\epsilon$ . Thus, $\lim_{x\to a}f(x)=m$ . What am I missing here? Is my proof okay? Why does Spivak use the function $g$ in the previous direction? Is it really necessary? What would such a $g$ be in the other direction?","['epsilon-delta', 'real-analysis', 'calculus', 'limits']"
2559407,Are all $n-1$ edge colorings of $K_n$ isomorphic?,Baranyai's theorem tells us that a $K_n$ can be colored with $n-1$ colors whenever $n$ is even; the handshaking lemma makes it easy to show that is not possible when $n$ is odd. It's not hard to verify that for $n=4$ or $n=6$ this coloring is unique up to isomorphism (where we're allowed to reorder vertices and relabel colors). Is this always true? Are there larger even $n$ where are are multiple distinct colorings?,"['combinatorics', 'graph-theory', 'coloring', 'graph-isomorphism']"
2559498,The area of a right spherical triangle,"Is there a compact formula for the area (excess angle – assuming a unit sphere)  of a right spherical triangle given its side lengths $a$ and $b$? As explained in an answer to an earlier question about the area of a generic spherical triangle, the excess angle $E$ is given by
$$\tan\frac E4=\sqrt{\tan\frac{a+b+c}4\tan\frac{-a+b+c}4\tan\frac{a-b+c}4\tan\frac{a+b-c}4}$$
However, I do not have $c$. Of course, I can use Napier's rules for right spherical triangles to find $c$. I thought about using integration in spherical coordinates (assuming B is the north pole and equating $a$ and $c$ with polar and azimuthal angles respectively). That approach, however, requires knowing the exact representation of the great circle that connects $A$ to $B$ in the coordinate chart.","['trigonometry', 'spherical-geometry', 'geometry', 'spherical-trigonometry', 'area']"
2559505,Sum of uniform and exponential random variables,"$$U \sim \operatorname{unif}(0,1);X \sim \operatorname{expo}(1) .$$
$U,X$ indep. Find the PDF of $U+X$. Here's my answer, but I find this answer implausible, not sure where I went wrong. \begin{align}
F_Y(y) & =P(U+X \leq y) \\
&= \int_{-\infty}^{\infty} P(U+X < y \mid X=x)f_X(x)\,dx \\
&= \int_{-\infty}^{\infty} P(U < y - X\mid X=x)f_X(x)\,dx \\
&= \int_{-\infty}^{\infty} P(U < y - x\mid X=x)f_X(x)\,dx \\
&= \int_{-\infty}^{\infty} P(U < y - x)f_X(x)\,dx \\
&= \int_{-\infty}^{\infty} F_U(y-x)f_X(x)\,dx \\
&= \int_{-\infty}^{\infty} (y-x)f_X(x)\,dx \\
&= \operatorname E_X[y-X] \\ 
&= y - \operatorname E_X[X] \\
&= y - 1/\lambda \\
&= y - 1/1 \\
&= y - 1
\end{align} $$
f_Y(y) = \frac d {dy} F_Y(y) = 1
$$","['statistics', 'integration', 'probability']"
2559519,Pigeonhole Principle: How many three-digit bit strings must we choose to be sure two of them agree on at least one digit?,"Textbook answer: 4 I don't see how the answer is 4, though. Because choose any two bit strings, say 000 and 111 or 010 and 101, then wouldn't any other bit string agree on one digit of any two of those bit strings that do not agree on none of the digits? So shouldn't the answer be 3? Or am I missing a special case?","['combinatorics', 'pigeonhole-principle']"
2559523,Obtaining Determinant without Expanding,"The question is #653 from Golan's Linear Algebra Every Graduate Student Should Know and while it doesn't explicitly say not to just expand and factor it, I think that's the spirit of the question. $$
\begin{vmatrix}
-2a & a+b & a+c\\ 
a+b & -2b & b+c \\ 
c+a & c+b & -2c \\
\end{vmatrix}
$$ Since the answer is
$$
4(a+b)(b+c)(a+c)
$$ I am inclined to think it has something to do with wisely dividing out (a+b), etc. from particular rows or some other linear combination tricks but I can't seem to quite figure it out. Any ideas?","['matrices', 'linear-algebra', 'determinant']"
2559542,"Rewrite $\int_{0}^{1}\int_{-\sqrt{y-y^2}}^{0}(x^2+y^2)\,\text{d}x \, \text{d}y$ in polar","Rewrite $$\int_0^1 \int_{-\sqrt{y-y^2}}^{0}(x^2+y^2)\,\text{d}x \, \text{d}y$$ in polar. We see that $-\sqrt{y-y^2}\leq x\leq 0$. If $x=-\sqrt{y-y^2}$, then $x^2=y-y^2\to x^2+y^2-y=0\to \color{red}{x^2+(y-\dfrac{1}{2})^2=\dfrac{1}{4}}$ Clearly $0\leq\theta\leq\pi$. Also, $x^2+y^2=y\to r^2\sin^2(\theta)+ r^2\cos^2(\theta)=r\sin(\theta)\to r^2=r\sin(\theta)\to\color{red}{r=\sin(\theta)}$ Therefore, $0\leq r \leq \sin(\theta)$ Thus the new integral is $$\int^\pi_0 \int^{\sin(\theta)}_0 r^2 r \, \mathrm{d}r \, \mathrm{d}\theta=\frac{3\pi}{32}$$ But wolfram alpha says the original integral in cartesian coordinates evaluates to $\dfrac{3\pi}{64}$?","['polar-coordinates', 'calculus', 'multivariable-calculus', 'integration', 'definite-integrals']"
2559591,How to show that Bernstein set is not Lebesgue measurable?,"A Bernstein set is a subset of the real line that meets every uncountable closed subset of the real line but that contains none of them. (They can be easily generalized to $\mathbb R^n$, but for the sake of simplicity we might stick with $\mathbb R$.) See also this post for some more details: What's application of Bernstein Set? (A proof of existence of Bernstein sets is given there - it is based on transfinite induction and well-ordering theorem. Also various properties of Bernstein sets are mentioned there, including the fact that existence of Bernstein sets cannot be shown in ZF.) My questions are: How can we show that a Bernstein set is not Lebesgue measurable? Can these proofs be generalized to other measures? By the latter I mean whether something like this can be said about some of the proofs: ""We have shown that Bernstein set is not Lebesgue measurable. But the same proof works for any translation-invariant measure such that all closed sets are measurable and bounded sets have finite measure."" (This is just a hypothetical example to make a bit clearer what I mean by the second question.) When I was thinking about this problem, I thought that one way to go would be using regularity of Lebesgue measure . Let $B$ be a Bernstein set. If $C\subseteq B$ is compact, then it has to be countable and thus $\mu(C)=0$. Similarly, if $B\subseteq U$ then $B$ does not intersect the closed set $\mathbb R\setminus U$, hence $U$ is complement of countable set and $\mu(U)=\infty$. So from regularity of Lebesgue measure we get that $B$ is not measurable. I have considered also posting my attempt sketched in the previous paragraph as an answer. But I decided not to do so - maybe somebody who knows more about this will be able to expand on this or add some other related results and useful observations.","['real-analysis', 'lebesgue-measure', 'descriptive-set-theory', 'measure-theory', 'general-topology']"
2559597,Why is the intermediate value theorem so important?,I would like to know why the intermediate value theorem is so important. So my questions are: Which important theorems do we prove using the intermediate value theorem? Are there direct applications of the intermediate value theorem outside mathematics? Does the intermediate value theorem have a historically importance?,['calculus']
2559623,Calculate $\lim_{n \to +\infty} \int_{0}^{+\infty} \frac{n \sin(\frac{x}{n})}{1 + x^2} dx$,The question is as follows: Calculate $\lim_{n \to +\infty} \int_{0}^{+\infty} \frac{n \sin(\frac{x}{n})}{1 + x^2} dx$. $\textbf{Some ideas:}$ We can use the fact that $\sin(\frac{x}{n}) \simeq \frac{x}{n} $.But then we find that $\lim_{n \to +\infty} \int_{0}^{+\infty} \frac{n \sin(\frac{x}{n})}{1 + x^2} dx \simeq \lim_{n \to +\infty} \int_{0}^{+\infty} \frac{n  \times \frac{x}{n}}{1 + x^2} = \lim_{n \to +\infty} \int_{0}^{n} \frac{ x }{1 + x^2} dx $ $ \hspace{9.1cm} = \lim_{n \to +\infty} \frac{1}{2}\int_{0}^{n} \frac{ 2x }{1 + x^2} dx   $ $ \hspace{9.1cm} \text{take } x^2=y$ $ \hspace{9.1cm} = \lim_{n \to +\infty} \frac{1}{2}\int \frac{ dy }{1 + y} $ $ \hspace{9.1cm} = \lim_{n \to +\infty} \frac{\ln(y)}{2} $ $\hspace{9.1cm} = \lim_{n \to +\infty} \frac{\ln(x^2)}{2} \mid_{0}^{n}$ $\hspace{9.1cm} = \lim_{n \to +\infty} \frac{\ln(n^2)}{2} = +\infty$ But someone said me that the final result should be $\frac{\pi}{2}$? Can you please let me know where is my mistake? Thanks!,"['improper-integrals', 'real-analysis', 'integration', 'limits']"
2559624,Is this identity about the Ricci curvature true?,"$\newcommand{\tr}{\operatorname{tr}}$
$\newcommand{\M}{\mathcal{M}}$
$\newcommand{\Ric}{\operatorname{Ric}} $
$\newcommand{\div}{\operatorname{div}} $ Let $\M$ be a Riemannian manifold, $\nabla^{T\M}$ is its Levi-Civita connection. Given $X \in \Gamma(T\M)$, we consider $\nabla^{T\M} X$ as a linear map (vector bundle morphism) $T\M \to T\M$. Is it true that for all $X,Y \in \Gamma(T\M)$
$$\Ric(Y,X)=\tr (\nabla^{T\M}Y) \cdot \tr(\nabla^{T\M}X)  -\tr ( \nabla^{T\M}Y \circ \nabla^{T\M}X), \tag{1}$$ where $\Ric$ is the Ricci curvature of $\M$. Motivation: I somehow derived (in a very cumbersome way) the equality
$$\int_{\M} \Ric(Y,X)= \int_{\M} \tr (\nabla^{T\M}Y) \cdot \tr(\nabla^{T\M}X)  -\tr ( \nabla^{T\M}Y \circ \nabla^{T\M}X) , \tag{2}$$ (I assume $\M$ is closed and oriented; the integration is w.r.t the Riemannian volume form of $\M$). Edit: As observed by levap , equality $(1)$ is false. Here is a proof of equality $(2)$, based on a few lemmas in my answer : First note that $\tr (\nabla^{T\M}Y)=\div Y,\tr (\nabla^{T\M}X)=\div X$, so equality $(2)$ is nothing but $$\int_{\M} \Ric(Y,X)= \int_{\M} \div Y\cdot\div X  -\tr ( \nabla^{T\M}Y \circ \nabla^{T\M}X) . \tag{3}$$ We now turn to analyse both summands of the RHS, up to divergence terms: (since the integral of a divergence is zero, this does not matter for the integral): The first observation (by Anthony Carapetis) is that
$$ (\mathrm{tr}_{13} \nabla^2 Y)(X) = \mathrm{div}(\nabla_X Y) - \mathrm{tr}(\nabla Y \circ \nabla X). \tag{4}$$ (For a proof, see lemma 2 in my answer ). For the other term, we use the identity $\div(fX)=f\div X+\tr(df \otimes X)$, for $f=\div Y$: $$\div(\div Y X)=\div Y\div X+\tr\big(d\div Y \otimes X\big). \tag{5}$$ Combining equations $(4),(5)$ we obtain that equality $(3)$ is equivalent to $$\int_{\M} \Ric(Y,X)= \int_{\M} -\tr\big(d\div Y \otimes X\big)  +(\mathrm{tr}_{13} \nabla^2 Y)(X). \tag{6}$$ Now, we use 
$$ \tr\big(d\div Y \otimes X\big) = (\tr_{23} \nabla^2 Y)(X), \tag{7}$$
(See lemma 3 in my answer ) which implies $(6)$ is equivalent to $$\int_{\M} \Ric(Y,X)= \int_{\M} (\mathrm{tr}_{13} \nabla^2 Y-\tr_{23} \nabla^2 Y)(X). \tag{8}$$ But, lemma 1 in my answer implies that now the integrands are equal: $$ \Ric(Y,X)=  (\mathrm{tr}_{13} \nabla^2 Y-\tr_{23} \nabla^2 Y)(X).$$ To summarize, we showed the original integrands are the same up to divergence terms so their integrals are equal.","['riemannian-geometry', 'reference-request', 'curvature', 'trace', 'differential-geometry']"
2559639,"Why is $(a,b)$ open on the lower limit topology of $\mathbb{R}$?","In the book of General Topology by Munkres, on page 104, it is given that However, as far as I know, the lower limit topology $\tau_l$ corresponds to the intervals of the form $[a,b)$ where $a < b$ . So how can $(a,b)$ be open in this topology?",['general-topology']
2559650,"Describe the set of all elements $x,y \in H$, such that $\|x+y\|=\|x\|+\|y\|$.","The question is as follows: Let $H$ be a Hilbert space. Describe the set of all elements $x,y \in H$, such that $\|x+y\|=\|x\|+\|y\|$. $\textbf{An idea:}$ The set of all such elements will be in a unit sphere that contains a line segment $[x,y]$ where $x,y \in H$ and $x \neq y.$ Such elements are linearly independent, because suppose they are dependent and say $y = \beta x$ for some $\beta \in \mathbb{C}$. Then we have $1 = \|ax + (1-a)\beta x \| = \|a + (1-a)\beta\|$. Then for $a = 0$ we get $|\beta|=1$ and for $a = \frac{1}{2}$ we get $|1+\beta|=2$ which implies that $\beta = 1$ and so $x=y$, which is contradiction. Can you please let me know if I am wrong? And if I am wrong? Can you please let me know what is the correct answer? Thanks!","['functional-analysis', 'real-analysis', 'hilbert-spaces']"
2559673,A question about dominated convergence theorem,"I have this question and I don't know how to proceed: Suppose that $(f_n)$ is a sequence of measurable functions on $[0,1]$ such that $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, =0$ 
  and that there is an integrable function $g$ on [0,1] such that $|f_n|^2\leq g$ for all $n$. Show that $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|^2\, =0$. I think that I must show $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, = \displaystyle  \int_0^1 \lim_{n \to \infty}|f_n|$ , in other words I must show that we can take limit inside the integral.  What does $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, =0$ mean? Can you help me for this question? Thanks.","['real-analysis', 'measure-theory']"
2559675,Proving the max/min of two finite signed measures,"Let $\mu_1$ and $\mu_2$ be finite signed measures on the measurable space $(X, \mathcal A)$. Define signed measures $\mu_1 \vee \mu_2$ and $\mu_1 \wedge \mu_2$ on $(X, \mathcal A)$ by $\mu_1 \vee \mu_2 = \mu_1 + (\mu_2 - \mu_1)^+$ and $\mu_1 \wedge \mu_2 = \mu_1 - (\mu_1 - \mu_2)^+$. (a) Show that $\mu_1 \vee \mu_2$ is the smallest of those finite signed measures $\nu$ that satisfy $\nu(A) \geq \mu_1(A)$ and $\nu(A) \geq \mu_2(A)$ for all $A \in \mathcal A$. (b) Find and prove an analogous characterization of $\mu_1 \wedge \mu_2$. When it comes to doing (a), I let $(P,N)$ be the Hahn decomposition of $X$ with respect to $\mu_2 - \mu_1$. Then $(\mu_1 \vee \mu_2)(A) = \mu_1 (A \cap N) + \mu_2 (A \cap P)$. I have no idea where to go from this point.","['real-analysis', 'measure-theory', 'elementary-set-theory']"
2559702,Do all continuous functions have antiderivatives?,"If not all continuous functions are differentiable, so how is it that all continuous functions have anti-derivatives?","['derivatives', 'integration', 'continuity', 'calculus']"
2559707,How to show that the integral $\frac{1}{2\pi i} \int_{\gamma} \frac{dz}{z - a}$ is integer-valued when the curve $\gamma$ is not piecewise smooth?,"In Conway's Functions of One Complex Variable , there is a proposition which is as follows: 5.1 Proposition. If $\gamma\colon [0,1] \to \mathbb{C}$ is a closed rectifiable curve and $a \notin \{\gamma\}$ then 
  $$\frac{1}{2\pi i} \int_{\gamma}\frac{dz}{z - a}$$
  is an integer. Proof. This is only proved under the hypothesis that $\gamma$ is differentiable. For those unfamiliar with Conway's book, $\{\gamma\}$ is his notation for the image set of the curve $\gamma$ and differentiable (when referring to curves) means $\gamma'$ exists and is continuous. I know the latter as smooth. The proposition is meant to motivate his definition of the winding number. From Conway's proof, it's trivial to generalize to closed piecewise smooth curves. This leads me to my first question: how can one prove the proposition in its full generality for closed rectifiable curves? In general, the integral is a Riemann-Stieltjes integral
$$\frac{1}{2\pi i} \int_{0}^{1}\frac{1}{\gamma(t) - a}\,d\gamma(t)$$
whose existence follows from the fact that $1/(\gamma(t) - a)$ is continuous and $\gamma(t)$ is of bounded variation. Seeing as how the winding number about $a$ can be defined using a continuous choice of argument for all closed curves not passing through $a$, my second question is: if the hypothesis is relaxed to include all closed curves, does the integral necessarily exist and is it still integer-valued?","['complex-analysis', 'winding-number', 'integration']"
2559712,How to show that it is an invariant set?,"I have this system of differential equations: $$\frac {dx}{dt} = x\left(1-\frac x5\right)- \frac 25xy $$ $$\frac {dy}{dt} = y\left(1-\frac y5\right)- \frac 35xy $$ I have found the equilibria for the system. 
Now, I have to show that that $$ L = \{(x,y) \in \mathbb R^2: y = 2x, x \gt 0\} $$ I have no idea how to show that this is an invariant set. Could someone give me a hint on how to start the the proof?","['ordinary-differential-equations', 'dynamical-systems', 'systems-of-equations']"
2559724,Proof of multivariable chain rule,"I'm working with a proof of the multivariable chain rule $\displaystyle{\frac{d}{dt}g(t)=\frac{df}{dx_1}\frac{dx_1}{dt}+\frac{df}{dx_2}\frac{dx_2}{dt}}$ for $g(t)=f(x_1(t),x_2(t))$ , but I have a hard time understanding two important steps of this proof. The proof includes the function $\displaystyle{\Delta_i(h)=x_i(t+h)-x_i(t)}$ for $\displaystyle{i=1,2, \bar{\Delta}=(\Delta_1(h),\Delta_2(h)) \Rightarrow \lim_{h\rightarrow0}\frac{\Delta_i}{h}=x^{'}_i}$ . It says that $\frac{g(t+h)-g(t)}{h}=\frac{f(\bar{x}(t+h))-f(\bar{x}(t))}{h}=\frac{f(\bar{x}(t)-\bar{\Delta(h))}-f(\bar{x}(t))}{h}$ which I understand, but the next step is the to state that $f$ is differentiable and then let the previous equation be equal to $=f^{'}_1(\bar{x}(t))\cdot\Delta_1(h)+f^{'}_2(\bar{x}(t))\cdot\Delta_2(h)+o(\vert\vert\bar{\Delta}\vert\vert)$ and this step I do not understand. I think there might be missing some limit-notation? But even with the limit notation I'm still not sure as to how it becomes a partial derivative multiplied with $\Delta_i$ . Afterwards they let $h\rightarrow0$ to get $=f^{'}_1(\bar{x}(t))\cdot x_1^{'}(t)+f^{'}_2(\bar{x}(t))\cdot x_2^{'}(t)$ Again I am very confused as to possibly missing limit notations. Does anyone know this version of the proof of the chain rule (besides these two steps, I find it the easiest version to understand), or understand these steps? Here are pictures of the notes: Theorem: Multivariable chain rule Proof of theorem","['multivariable-calculus', 'chain-rule']"
2559729,derivative of limited summation,what's the simple way to find $$\frac{d}{dx}$$ of limited summation ? $$\frac{d}{dx}\sum_{n=1}^{13}\left({x^n}\right)$$ Is there a general formula for this? what's the sum when x=1,"['derivatives', 'summation']"
2559736,How to prove $\sum_{m=1}^\infty \sum_{n=1}^\infty \frac{1}{m^2+n^2}=+\infty$,"How to prove $$\sum_{m=1}^\infty \sum_{n=1}^\infty \frac{1}{m^2+n^2}=+\infty.$$ I try to do like $$\sum_{m=1}^\infty \sum_{n=1}^\infty \frac{1}{m^2+n^2}=\sum_{N=1}^\infty \sum_{n+m=N}^\infty  \frac{1}{m^2+n^2}=\sum_{N=1}^\infty \sum_{m=1}^{N-1}  \frac{1}{m^2+(N-m)^2}$$
 $$\frac{1}{m^2+(N-m)^2}\leq \frac{2}{N^2}$$
but it doesn't work.","['real-analysis', 'sequences-and-series']"
2559756,$f(x) = \sum_{k=1}^{+\infty} (1 - \frac{1}{k}) x_k$ is bounded for $x=(x_k) \in \ell_1$ and find its norm.,"The question is as follows: Prove that the functional $f(x) = \sum_{k=1}^{+\infty} (1 - \frac{1}{k}) x_k$ is linear bounded for $x=(x_1, x_2, \ldots) \in \ell_1$ and find its norm. $\textbf{Some effort:}$ First we note that $f:\ell_1 \to \mathbb{R}$. So we can use  Cauchy-Schwarz inequality and so we have \begin{align}
|f(x)| &= \left|\sum_{k=1}^{+\infty} \left(1 - \frac{1}{k}\right) x_k\right|\\
&\le \sum_{k=1}^{+\infty} \left|\left(1 - \frac{1}{k}\right)x_k\right|\\
&\le \sum_{k=1}^{+\infty} \left|1 - \frac{1}{k}\right| |x_k|\\
&\le \left\|\sum_{k=1}^{+\infty} \left(1 - \frac{1}{k}\right)\right\|_{\infty} \|x\|_1\\
&= \sup_{n \in \mathbb{N}} \left\|\sum_{k=1}^{n} \left(1 - \frac{1}{k}\right)\right\|_{\infty}\|x\|_1
\end{align} So $f$ is bounded and $\|f\| \leq \sup_{n\in\mathbb{N}} \left| \sum_{k=1}^{n} \left(1 - \frac{1}{k}\right)\right| $ Please let me know if my calculation is not correct? And please let me know that how can I find its norm? Thanks!","['functional-analysis', 'real-analysis', 'lp-spaces']"
2559759,Find $f(4)$ where $f$ is a polynomial such that $f'(x)+f(x)=x$,"$f(x)$ is polynomial function and
  $$f'(x)+f(x)=x,$$ 
  then what is the value of $f(4)=$? The Answer is $f(4)=3$
   , but I don't know how?","['derivatives', 'ordinary-differential-equations', 'calculus']"
2559785,Geometric interpretation for median formula $m_c = \sqrt{\frac{2(a^2 + b^2)- c^2}{4}}$ for $a + b < c$?,"For a triangular with side lengths $a, b, c$, the length of the median of $c$ is $m_c = \sqrt{\frac{2(a^2 + b^2) - c^2}{4}}$. If $a + b < c$, the configuration is obviously not a triangle anymore. 
However, there are values for $a, b, c$ with $a + b < c$ (e.g. $a = 7, b = 2, c = 10$) where the root is still positive. Is there any geometric interpretation for that?","['euclidean-geometry', 'geometry']"
2559801,"Limit points of the set $\{\frac{1}{2m} - \frac{1}{2n}\mid n, m \in \mathbb{N}\}$","Let S := $\{\frac{1}{2m} - \frac{1}{2n}\mid n, m \in \mathbb{N}\}$ Then, the limit points will be: $\lim\limits_{n \to \infty} S = \frac{1}{2m}$ $\lim\limits_{m\to \infty} S = \frac{-1}{2n}$. $\lim\limits_{m, n \to \infty} S = 0$. Thus, the limit points of S will be, at least, the following: $ C := \{\frac{1}{2m}, \frac{-1}{2n}, 0\} \subset S'$ Yet, I am not sure that I can to prove that there are no other limit points, that is, that $S' \subset C$. Here's what I've got: Let $x \notin C$ be a limit point of S $\Rightarrow x = \frac{1}{2m} - \frac{1}{2n} \text{ for some } n, m \in \mathbb{N}$. Let $\epsilon = \frac{\sqrt{2}}{2} * (\frac{1}{2m} - \frac{1}{2(m + 1)}) \Rightarrow \nexists s \in S : s \in B(x, \epsilon) \Rightarrow s \notin S'. $ Though I am not sure that the procedure was correct. Any help will be appreciated. Thank you beforehand.","['sequences-and-series', 'calculus']"
2559810,Determine number of trials in Monte Carlo simulation,"Assume we estimate $P(C) = P(A+B)$, where $P(B|\overline{A})$ is given, using Monte Carlo simulation in two different ways: $P(C)$ is equals to number of event $C$ occurences in $n$ independent experiments At first we estimate frequency $\frac{m}{n}$ of event $A$ occurence in $n$ independent experiments and then we compute $P(C)$ as $$P(C) \approx P_n(C)=\frac{m}{n} + (1-\frac{m}{n})P(B|\overline{A})$$ If $P(B|\overline{A}) = 0.3$ and $P(A) = 0.4$, how to determine (for both ways) the minimal number of trials, that is sufficient to get absolute error of $P(C)$ estimation less than $0.01$ with probability $\geq 0.95$? Thank you for any help!","['probability-limit-theorems', 'probability-theory', 'statistics', 'probability', 'monte-carlo']"
2559814,"Is the proof I am using, sufficient/ correct for the system of equation?","I want to ask MSE to confirm the correctness of the alternate solution and its mistake. I know possible solution: https://math.stackexchange.com/a/2557094/456510 If $x,y,z\in {\mathbb R}$, Solve the system equation: $$
\left\lbrace\begin{array}{ccccccl}
    x^4 & + & y^2 & + & 4         & = & 5yz
\\[1mm]
y^{4} & + & z^{2} & + & 4 & = &5zx
\\[1mm]
z^{4} & + & x^{2} & + & 4 & = & 5xy
\end{array}\right.
$$ I wrote a solution myself (after more work). My attempts / solution: It is obvious that, if $x>0,y>0,z>0$ are solutions, $x<0,y<0,z<0$ are also solutions and it is obvious $x≠0,y≠0,z≠0$. If the equations have a solution, then $ x = y = z $ should be. Proof: I will accept $x,y,z\in {\mathbb R^+}$ a-1) Let $x≥z>y$ We can write : $z^4>y^4 \\ x^2≥z^2 \\ z^4+x^2+4>y^4+z^2+4 \\ 5xy > 5zx \\ y>z$ We get the contradiction : $y>z$ Because, it must be $z>y$ a-2) Let $x>z≥y$ We can write: $z^4≥y^4 \\ x^2>z^2 \\ z^4+x^2+4>y^4+z^2+4 \\ 5xy > 5zx \\ y>z$ We get the same contradiction : $y>z$ Because, it must be $z≥y$ b) $y≥x>z$ We can write: $x^4>z^4 \\ y^2≥x^2 \\ x^4+y^2+4>z^4+x^2+4 \\ 5yz > 5xy \\ z>x$ But, this is contradiction, because it must be $z<x$. We get the same contradiction for : $y>x≥z$ c) $y>z≥x$ We can write: $y^4>z^4 \\ z^2≥x^2 \\ y^4+z^2+4>z^4+x^2+4 \\ 5zx > 5xy \\ z>y$ But, this is contradiction, because it must be $z<y$. We get the same contradiction for : $y≥z>x$ d) $z>x≥y$ We can write: $z^4>x^4 \\ x^2≥y^2 \\ z^4+x^2+4>x^4+y^2+4 \\ 5xy > 5yz \\ x>z$ But, this is contradiction, because it must be $z>x$. We get the same contradiction for : $z≥x>y$ e) $z≥y>x$ We can write: $y^4>x^4 \\ z^2≥y^2 \\ y^4+z^2+4>x^4+y^2+4 \\ 5zx > 5yz \\ x>y$ But, this is contradiction, because it must be $x<y$. We get the same contradiction for : $z>y≥x$ f) $x>y≥z$ We can write: $x^4>y^4 \\ y^2≥z^2 \\ x^4+y^2+4>y^4+z^2+4 \\ 5yz > 5zx \\ y>x$ But, this is contradiction, because it must be $x>y$. We get the same contradiction for : $x≥y>z$ Then, solution must be $x=y=z$ (if there is a solution). The proof is completed. Finally, $$x^4+x^2+4-5x^2=0 \Rightarrow x^4-4x^2+4=0 \Rightarrow (x^2-2)^2=0 \Rightarrow x=±\sqrt2\Rightarrow x=y=z=±\sqrt2 .$$ Is my proof/ solution correct? Thanks.","['systems-of-equations', 'proof-verification', 'algebra-precalculus', 'proof-writing', 'contest-math']"
2559827,Normalized integrals over shrinking tubular neighbourhoods converge to an integral on the limit submanifold,"$\renewcommand{\S}{\mathcal{S}}$
$\newcommand{\M}{{\mathcal{M}}}$
$\newcommand{\TM}{{T\mathcal{M}}}$
$\newcommand{\TS}{{T\mathcal{S}}}$
$\newcommand{\NS}{{\mathcal{NS}}}$
$\newcommand{\N}{\mathcal{N}}$
$\newcommand{\g}{\mathcal{g}}$
$\newcommand{\Volg}{\text{Vol}_\g}$
$\newcommand{\Vol}{\text{Vol}}$
$\newcommand{\VolgS}{\text{Vol}_{\g|_\S}}$ Let $(\M,\g)$ be a smooth $d$-dimensional Riemannian manifold, and let $\S\subset\M$ be a smooth compact $k$-dimensional oriented submanifold. Let $\NS$ be the normal bundle of $\S$ in $\M$. For a sufficiently small $h>0$, define
$\S_h := \{ \exp_p(v) : p\in \S, v\in \NS, |v|\le h \}.$ Let $f:\M \to \mathbb{R}$ be a continuous function. I am trying to prove the following: $$ \lim_{h \to 0} \frac{\int_{\S_h} f}{\Volg(\S_h)}=\frac{\int_{\S} f}{\VolgS(\S)},$$ where the integrals are w.r.t the Riemannian volume forms on $\S_h$,$S$ defined by $\g,\g|_{\S}$ respectively. 
(Recall $\S$ is oriented). Edit: Let's start with the case of a $k$-cube embedded in $\mathbb{R}^d$ in the standard way. The general case should follow by an approximation argument, since ""locally, everything is Euclidean"". Here is a proof for the Euclidean case: Let's use Fubini theorem:
Suppose $\S \subseteq \mathbb{R}^k \times \{\bar 0^{d-k}\} \subseteq \mathbb{R}^d$, where $S$ is a product of $k$ intervals. Then $\S_h=S \times [-h,h]^{d-k}$. Let $\epsilon >0$, and let $(x,y)\in S\times [-h,h]^{d-k}$. $$\frac{\int_{\S_h} f}{\Vol(\S_h)}= \frac{\int_{[-h,-h]^{d-k}}\big(\int_{S} f(x,y) dx\big)dy }{(2h)^{d-k}\Vol(S)} =\frac{\int_{[-h,-h]^{d-k}} g(y) dy }{\Vol([-h,-h]^{d-k})} ,$$ where $g:[-h,-h]^{d-k} \to \mathbb{R}$ is defined by
$$ g(y)=\frac{\int_{x \in S} f(x,y)dx}{\Vol(S)}.$$ Since the domain is compact, $f$ is uniformly continuous, so $g$ is continuous. This implies $$ \lim_{h \to 0} \frac{\int_{[-h,-h]^{d-k}} g(y) dy }{\Vol([-h,-h]^{d-k})}  =g(\bar 0)=\frac{\int_{x \in S} f(x,0)dx}{\Vol(S)}=\frac{\int_{\S} f}{\Volg(\S)}.$$","['riemannian-geometry', 'limits', 'smooth-manifolds', 'integration', 'differential-geometry']"
2559839,$f(x) = \sum_{k=1}^{+\infty} 2^{-k+1} x_k$ is linear bounded for $x=(x_k) \in c_0$ and find its norm.,"The question is as follows: Prove that the functional $f(x) = \sum_{k=1}^{+\infty} 2^{-k+1} x_k$ is linear bounded for $x=(x_1, x_2, \ldots) \in c_0$ and find its norm. $\textbf{Some effort:}$ First we note that $f:c_0 \to \mathbb{R}$. For to show that it is bounded, we have 
\begin{align}
|f(x)| &= \left|\sum_{k=1}^{+\infty} 2^{-k+1} x_k  \right|\\
&\le \sum_{k=1}^{+\infty} \left| 2^{-k+1} x_k  \right|\\&\le \sum_{k=1}^{+\infty} \left| 2^{-k+1}\right|\left| x_k  \right|\\&\le \left\|\sum_{k=1}^{+\infty}2^{-k+1} \right\|_{1} \left\|  x_k \right\|_{\infty}\\& = 2 \sum_{k=1}^{+\infty} 2^{-k} \left\|  x_k \right\|_{\infty}\\& = 2 \left\|  x_k \right\|_{\infty}
\end{align}
 So $f$ is bounded and $\|f\| \leq 2 $. for to show that its norm is equal to 2, we have to show that $\|f\| \geq 2$. For to show this we have to find a sequence $x=(x_k) \in c_0$ such that by substituting it in $f(x)$ instead of $x$ and also by finding its norm $\|x\|_{\infty} = \sup_{k\in\mathbb{N}}\{|x_k|\}$ and by using $|fx|\leq \|f\|_1 \|x_k\|_{\infty}$, i.e. by moving $\|x_k\|_{\infty}$ from right side to the left side of the inequality, to find 2 out of this process. But I couldn't find such sequence. Can someone please help me to find its norm? And also please let me know if my calculation for boundedness is not correct? Thanks!","['functional-analysis', 'real-analysis', 'lp-spaces']"
2559845,Find all integer solutions to the equation based on the following conditions.,"$x_1+x_2+x_3+x_4=4$. where $x_2,x_3 >0$ and $x_1,x_4 \ge 0$ I just know that the ans is $\binom{4-1+4}{4}$ if all the variables are just non negetive, but here 2 of them are non zero. How to do this?","['combinations', 'combinatorics', 'discrete-mathematics']"
