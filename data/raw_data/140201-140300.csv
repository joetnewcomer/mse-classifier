question_id,title,body,tags
2258389,How can a mug and a torus be equivalent if the mug is chiral?,"I don't know much about topology, but the other day I was thinking about the (classic?) coffee cup - donut topological equivalence. I realised that a cylinder with one open end and a handle on the side (a mug) is a chiral object in 3D space, whereas a torus/donut is achiral (""meso"", as indicated by the internal planes of symmetry present in a torus). EDIT: I just realized the mug may not in fact be chiral, due to an internal plane of symmetry (vertical, through the handle). But I will leave the post as some of the questions are still relevant, and I'm still interested in the arbitrary example of how topology handles a chiral object being transformed into an achiral object. As an outsider, my impression is that topology is roughly ""the qualitative mathematics of shapes""; is this accurate at all? I would expect such a field would be quite concerned with phenomena like chirality, the lack of superposability of two mirror-images of a 3D object . From another perspective, chirality is the reason we have a ""right hand rule"" convention, or the very reason we can distinguish between a right- and left-handed coordinate system. To me chirality seems to be an emergent property, an asymmetry that arises when the object/space is sufficiently complex. So when a chiral object and achiral object are claimed to be topologically equivalent, is there some unsung caveat about chirality? Perhaps topologists truly do not care about chirality, as it does not stop their infinitely malleable material from transforming between the two shapes. If so, then my question is what is the significance of chirality in topology? And if I may, these questions built off this train of thought: If a 3D object that is chiral in 3D space is viewed in a four-dimensional space, would it be considered achiral (""meso"")? (Analogous to a 2D object being considered achiral in 3D space, if I am not mistaken.) Is there any usefulness to defining chirality of 2D objects in 2D space? Is there any generalized notion of chirality for an $n$-dimensional space, some ""$n$-chirality""?","['geometric-topology', 'general-topology']"
2258401,"$K(x,y)$ continuous on $S=[0,1]\times[0,1]$ and $\phi \in C([0,1])$, define $T\phi$ on $[0,1]$ by $T\phi(x)=\int_0^xK(x,y)\phi(y)dy,~~x\in[0,1].$","Let $K(x,y)$ be continuous on $S=[0,1]\times[0,1]$ and $\phi \in C([0,1])$, define $T\phi$ on $[0,1]$ by 
$$T\phi(x)=\int_0^xK(x,y)\phi(y)dy,~~x\in[0,1].$$ (a) Show that $T\phi \in C([0,1])$ (b) Show that $T$ is continuous. (C) If $\{\phi_n\}_{n=1}^\infty$ is a bounded sequence in $C([0,1]),$ show that the sequence $\{T\phi_n\}_{n=1}^\infty$ has a convergent subsequence. My attempt: (a) By assumption, we have that $K(x,y)$ is uniformly continuous. So,  $\exists~\delta>0$ s.t. $|K(x,y)-K(x',y')|<\frac{\epsilon}{1+\|\phi\|}$ whenever $\sqrt{(x-x')^2+(y-y')^2}<0$. $|\int_0^xK(x,y)\phi(y)~dy-\int_0^z K(z,y)\phi(y)~dy| \\ \leq |\int_0^z K(x,y)\phi(y)~dy-\int_0^z K(z,y)\phi(y)~dy +\int_z^x K(x,y)\phi(y)~dy| \\ \leq |\int_0^z (K(x,y)-K(z,y))\phi(y)~dy~| + |\int_z^xK(x,y)\phi(y)~dy| \\ 
 \leq \|\phi\|\frac{\epsilon}{1+\|\phi\|}+|\int_z^xK(x,y)\phi(y)~dy|$ How to estimate this term $|\int_z^xK(x,y)\phi(y)~dy|$ ? (b) $|\int_0^x K(x,y)\phi(y)~dy|\leq \int_0^1 |K(x,y)\phi(y)|~dy \\ \Rightarrow \|T\phi\|=\displaystyle\sup_{x\in[0,1]}|\int_0^x K(x,y)\phi(y)~dy|\leq \|K\|\cdot\|\phi\|=C\|\phi\|~~~(C=\|K\|)$ So, $\|T\phi_1-T\phi_2\|=\|T(\phi_1-\phi_2)\| \leq C\|\phi_1-\phi_2\|$ for $\phi_1,\phi_2 \in C([0,1])$. So, $T$ is continuous. (c) I have no idea about this problem. Maybe I should show that  $\{T\phi_n\}_{n=1}^\infty$ is equicontinuous. I know the theorem that if  $\{T\phi_n\}_{n=1}^\infty$ is pointwise bounded and equicontinuous on $K$, then  $\{T\phi_n\}_{n=1}^\infty$ contains a uniformly convergent subsequece.","['functional-analysis', 'real-analysis', 'analysis']"
2258420,Find generators of the ideal of an algebraic set,"The following exercise comes from Fulton's Algebraic Curves: Let $k$ be an infinite field and $V = \{(t,t^2,t^3) \, ; \, t \in k \} \subset \mathbb{A}^3(k)$. Show that $V$ is algebraic and compute $I(V)$ by giving a finite set of generators. Now, showing $V$ is algebraic is easy by noting that $V = V(X^2-Y, X^3-Z)$, but I can't find a way to describe $I(V)$ explicitly. Obviously $(X^2-Y)(X^3-Z) \in V$, but how can I find the actual generators of this ideal?","['algebraic-curves', 'algebraic-geometry']"
2258459,Help needed with modulus addition and multiplication proof,"We have recently started working with modular arithmetic in my discrete mathematics course, and I found two problems in my textbook that I am having trouble with. What are these kinds of proofs called, and what is the usual approach that is undertaken? Lastly, how would you suggest tackling these proofs in particular? Thank you so much in advance! 1.(a mod m) + (b mod m) ≡ (a + b mod m) 2.(a mod m)(b mod m) ≡ (ab mod m)","['proof-writing', 'discrete-mathematics']"
2258486,"What is a ""standard representation"" of a symmetric group?","Would someone please explain what a standard representation is? Not all groups seem to have a standard representation, and those I have seen are related to the symmetric group. However, I can't seem to find a clear explanation.","['representation-theory', 'abstract-algebra', 'group-theory']"
2258535,Find the coefficient of $x^2y^2z^4$ in the expansion of $(x-2y+z)^8$.,"I need help solving this question​. How do I start? Attempt at solution *The term that contains $x^2y^2z^4$ is ${8 \choose 4} (-2y)^2(z)$ ?
*","['binomial-coefficients', 'discrete-mathematics']"
2258564,$f(f(f(x))) = x$. Prove or disprove that f is the identity function [duplicate],"This question already has answers here : If $ f(f(f(x)))=x$, does$ f(x)=x$ necessarily follow? [duplicate] (4 answers) Closed 7 years ago . Let $f$ be a continuous function on $\mathbb R$ satisfying the relation
$$f(f(f(x))) = x\ \text{for all}\ x \in \mathbb R$$
Prove or disprove that $f$ is the identity function. I tried taking the derivative. From the derivative, I'm not sure about it, but I concluded it had to be of degree 1 if it is a polynomial since if it'd have been of degree 2 or higher.. there needed to be terms of $x$ in the derivative.. which are not there.",['functions']
2258604,characters of finite groups which vanish except identity,"Let $G$ be a finite group. The regular $\chi_{reg}$ of $G$ is the character corresponding to representation of $G$ on $\mathbb{C}[G]$ with action by (left) multiplication to basis elements of $G$. It is well known that $\chi_{reg}$ is zero at all $g\in G$ except $g=1$. Also the degree of this character (i.e. value at $1$) is $|G|$. There is an exercise in Isaacs' character theory about similar kind of character: Fact: Let $G$ be a finite group and $\chi$ a character of $G$ such that $\chi$ vanishes on $G-\{1\}$. Then $|G|$ divides degree of character. Question: In the above fact, can we also say that $\chi$ contains $\chi_{reg}$ as a component? (i.e., is $\chi$ equal to sum of $\chi_{reg}$ and some other character of $G$? Note: In above discussion, character of  $G$ means character of a complex (possibly reducible) representation of $G$, and not virtual character , or class function etc.","['finite-groups', 'representation-theory', 'group-theory', 'characters']"
2258677,Finding eigenvalues shortcut,"I am being asked to find the eigenvalues for this matrix. It mentions that some tricks can be used instead of having to use $det(A-\lambda I)$. I understand how to do it that way, but what is a shortcut I can use for this matrix? Thanks. Solution is $(\lambda -2)^2 \lambda ^ 2$ $\lambda = 0$ and $\lambda = 2.$ $$
        \begin{bmatrix}
        1 & 0 & 1 & 0\\
        0 & 1 & 0 & 1\\
        1 & 0 & 1 & 0\\
        0 & 1 & 0 & 1\\
        \end{bmatrix}
$$",['linear-algebra']
2258697,"Given that $\frac{1}{a}+\frac{1}{b}+\frac{1}{c}=\frac{1}{5}$ and $abc = 5$, solve for $a^3 + b^3 + c^3$","I recently encountered this question and have been stuck for a while. Any help would be appreciated! Q: Given that 
$$\frac{1}{a} + \frac{1}{b} + \frac{1}{c} = \frac{1}{5} \tag{1} \label{eq:1}$$
$$abc = 5 \tag{2} \label{eq:2}$$
Find $a^3 + b^3 + c^3$. It wasn't specified in the question but I think it can be assumed that $a, b, c$ are real numbers. My approach:
$$ ab + ac + bc = \frac{1}{5} abc = 1 $$
$$ a^3 + b^3 + c^3 = (a+b+c)^3 - 3[(a + b + c)(ab + ac + bc) - abc] $$
$$ a^3 + b^3 + c^3 = (a+b+c)^3 - 3(a+b+c) + 15 $$
From there, I'm not sure how to go about solving for $a + b + c$.
Something else I tried was letting $x = \frac{1}{a}, y = \frac{1}{b}, z = \frac{1}{c}$, so we get $$ xyz = x + y + z = \frac{1}{5} $$Similarly, I'm not sure how to continue from there.","['algebra-precalculus', 'contest-math', 'systems-of-equations']"
2258724,Brachistichrone problem with friction,"In this Mathworld article for the Brachistichrone problem, it is said that the following: $$\left(1+(y')^2\right)(1+\mu y')+2(y-\mu x)y''=0$$ Implies that: $$\frac{1+(y')^2}{(1+\mu y')^2}=\frac{C}{y-\mu x}$$ I'm not sure how they arrived at this step -- how could a second-order differential equation even be reduced to a first-order one? I thought maybe they had a reason to assume constant curvature, but constant curvature would actually mean: $$\frac{1+(y')^2}{(1+\mu y')^2}=\frac{C}{(y-\mu x)^2}$$ (which doesn't make sense, anyway, because setting $\mu=0$ does not return the differential equation for the standard, frictionless brachistichrone)",['ordinary-differential-equations']
2258739,"Differentiability of $x^2\log(x^4+y^2)$ at $(0,0)$","Based on this question , I have the function
$$
f(x,y)=\begin{cases}
x^2\log(x^4+y^2), & (x,y)\in\mathbb{R}^2\setminus\{(0,0)\},\\
0,                & (x,y)=(0,0).
\end{cases}
$$
I would like to study its continuity and differentiability at $(0,0).$ Continuity For the continuity, I see that I can rewrite the expression $x^2\log(x^4+y^2)$ as
$$
\sqrt\frac{x^4}{x^4+y^2}\cdot\sqrt{x^4+y^2}\log(x^4+y^2),
$$
and given that: $\sqrt\frac{x^4}{x^4+y^2}$ is bounded:
$$
0\leq\sqrt\frac{x^4}{x^4+y^2}\leq1;
$$ for $\sqrt{x^4+y^2}\log(x^4+y^2)$ I can use the known limit
$$
\lim_{t\to0}t^\alpha\log t=0,\qquad\forall\alpha>0;
$$ I conclude that 
$$
\lim_{(x,y)\to(0,0)}f(x,y)=0,
$$
so the function is continuous in $(0,0).$ Existence and continuity of derivative with respect to $x$ Something similar can be done for the derivative with respect to $x$ in $(0,0),$ in fact
$$
f'_x(0,0)=\lim_{(x,y)\to(0,0)}\frac{x^2\log(x^4+y^2)-0}{x-0}=\lim_{(x,y)\to(0,0)}x\log(x^4+y^2)
$$
and the expression $x\log(x^4+y^2)$ could be written as
$$
\operatorname{sign}x\cdot\sqrt[4]\frac{x^4}{x^4+y^2}\cdot\sqrt[4]{x^4+y^2}\log(x^4+y^2),
$$
whose limit, as before, is $0.$ As for the limit of the derivative function with respect to $x$, it is
$$
\lim_{(x,y)\to(0,0)}f'_x(x,y)=\lim_{(x,y)\to(0,0)}\left(2x\log(x^4+y^2)+\frac{4x^5}{x^4+y^2}\right)
$$
and the first term of the sum is as before, while the second can be written as the product of $4x$, that goes to $0$, by a bounded ratio, so the limit is $0$ and I can conclude that $f'_x(x,y)$ is continuous at $(0,0).$ Existence and continuity of derivative with respect to $y$ For the derivative with respect to $y$ the things are different, I have
$$
f'_y(0,0)=\lim_{(x,y)\to(0,0)}\frac{x^2\log(x^4+y^2)-0}{y-0}=\lim_{(x,y)\to(0,0)}\frac{x^2}{y}\log(x^4+y^2)
$$
that I am not able to rewrite in a form that is simpler to manage. Moreover, if I make the limit along the curves $y=x^2$ and $y=-x^2$ I get
$$
\lim_{x\to0}\frac{x^2}{x^2}\log(2x^4)=-\infty\\
\lim_{x\to0}\frac{x^2}{-x^2}\log(2x^4)=+\infty
$$
so the derivative with respect to $y$ does not exist in $(0,0),$ and the function cannot be differentiable in $(0,0).$ The question Given all that, my question is: this question is wrong saying $f$ is differentiable, or I am making some mistake? Also the graphics of $f$ seems rather smooth around $(0,0)$:","['multivariable-calculus', 'real-analysis', 'derivatives']"
2258751,Resolving singularities in elliptically fibered fourfolds,"Consider a Calabi-Yau fourfold given as an elliptic fibration $\pi : X_4 \to B_3$ over a complex threefold. The discriminant locus $\{\Delta=0\}$ describes the locus in $B_3$ over which the elliptic curve degenerates. We can (usually, though perhaps not always) tune the fibration such that an $E_8$ singularity appears as a component of the discriminant locus. Generically this locus will have non-zero intersection with the rest of the discriminant locus, and at this locus (which is complex codimension two in $B_3$) the singularity will be worse than $E_8$. I have heard on the one hand that such a singularity cannot be resolved with a crepant resolution (one which preserves the Calabi-Yau condition), and on the other hand that because of this we need to resolve these singularities. My question is then: What is the appropriate way to resolve such a space to get a smooth Calabi-Yau fourfold? How does this differ from the case of resolving a less serious singularity? In lieu of an answer, a useful reference would also be very appreciated.","['manifolds', 'singularity-theory', 'algebraic-geometry', 'fibration']"
2258800,How to solve Diophantine equations of the form $Axy + Bx + Cy + D = N$?,"Is there a general solution to solve a Diophantine equation of the form $Axy + Bx + Cy + D = N$? With $A,B,C,D,N,x,y$ positive integers.","['number-theory', 'factoring', 'integers', 'discrete-mathematics']"
2258818,The number of solutions to $\cos^2{x}=\cos{2x}.$,"How can one quickly find out the number of solutions to $$\cos^2{x}=\cos{2x}, \ \ \ 0 \leq x \leq 2\pi \ ? $$ I rewrote the equation as $$\cos2x=\cos^2{x}-\sin^2{x} \Longleftrightarrow -\sin^2{x} = 0 \Longleftrightarrow \sin{x}=0.$$ So, the equation $\sin{x}=0$ has roots on $0, \pi$ and $2\pi$. So the answer should be 3. Is this an acceptable and all correct reasoning or can I improve on any detail? Is the answer correct?",['trigonometry']
2258833,Simplifying expression $\sqrt{6+2\sqrt{5}} - \sqrt{6-2\sqrt{5}}.$,I'm stuck. Squaring it will change it's value. Is there any general method of simplifying expressions of the form $$\sqrt{a+b}-\sqrt{a-b} = c \ \ ?$$,['algebra-precalculus']
2258850,diffrentiation wrt to z bar operator,"I want to find $\partial_{\overline{z}}(\frac{z}{z-w})$ .I am getting two different answers. First I tried to do the product rule taking one of the function as $z$ and other as $z-w$ .The answer I got was $z\delta(z-w)$. Then I tried to rewrite the function as $ 1 + \frac{w}{z-w}$ and then did the diffrentiation .The answer I got was $w\delta(z-w)$. In both the cases I used the fact $\partial_{\overline{z}}(\frac{1}{z-w})=\delta(z-w)$.
Am I doing something wrong?Please help me",['complex-analysis']
2258870,An almost Fresnel integral,"$\def\d{\mathrm{d}}$So I tried doing the following integral: $$I=\int_0^{+\infty}\sin(2^x)\,\d x,$$ which is quite similar to the famous Fresnel integral .  First, I rewrote $\sin$ using its complex exponential definition, then I let $u=2^x$: $$I=\int_0^{+\infty}\frac{e^{i2^x}-e^{-i2^x}}{2i}\,\d x = \frac1{2i\ln(2)} \int_1^{+\infty} \frac{e^{iu}-e^{-iu}}u \,\d u.$$ (so close to letting me use Frullani's integral $\ddot\frown$) But where do I go from here?  It looks very close to a place where I could use the exponential integral or something like that, but not quite...","['improper-integrals', 'integration']"
2258877,Where does the notion of first countability is used? How does $f(\bar{A}) \subset \overline{f(A)}$ happened?,"Let $f:X\rightarrow Y.$If $f $ is continuous,then for every convergent sequence $x_n\rightarrow x$ in $X$,the sequence $f(x_n)$ converges to $f(x)$.The converse holds if $X$ is first countabe. I was  getting  problem in proving the converse part but Convergence of $f(x_n)$ implies convergence of $x_n$ (From  Daniel Fischer's 2nd comment) cleared
my query upto very very extent.Now i wanted to know where does the  notion of first countability is used in proving its converse? This is the proof given in Munkres To prove the converse,assume that the convergent sequence condition is satisfied.Let A be as subset of $X$;We show  that $f(\bar{A}) \subset \overline{f(A)}$.If $x\in \bar{A},$there is a sequence converging to $x$.By assumption,the sequence $f(x_n)\rightarrow f(x) $.Since $f(x_n)\in f(A) \implies f(x)\in \overline{f(A)}$.Hence $f(\bar{A}) \subset \overline{f(A)}$. How does $f(\bar{A}) \subset \overline{f(A)}$ happened? My trial: Let $x\in \bar{A} $ then $f(x)\in f(\bar{A})-----------------(1)$ . Now we'll show that $f(x)\in \overline{f(A)} $. Since $x\in \bar{A}$
  so there exists a sequence,$<x_n>$ in $A$ such that $<x_n>\rightarrow
 x$ and by assumption we have $f(x_n)\rightarrow f(x)$ then  $f(x)\in
  \overline{f(A)}---------------------------(2)$ From (1) and (2) we have  $f(\bar{A}) \subset \overline{f(A)}$. Is it correct?","['continuity', 'general-topology', 'sequences-and-series', 'proof-verification']"
2258887,Difference of asymptotes at infinity,"Let $f(x)$ and $g(x)$ be two functions such that $$\lim_{x\to\infty}\frac{f(x)}{g(x)}=1$$ Does it imply: $\lim_{x\to\infty}\frac{g(x)}{f(x)}=1$ $\lim_{x\to\infty}\left(f(x)-g(x)\right)=0$ To me it seems like both are true, but the second is obviously false: $$\lim_{x\to\infty}\left(\sqrt{x+\sqrt{x}}-\sqrt{x}\right)=1/2$$ but why? If both functions are basically the same far enough in the number line why does the limit not approach $0$. I don't know how to give a rigorous answer (rather than examples) Are the answers different in these two cases? $\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=\infty$ $f(x)$ and $g(x)$ are bounded Thanks","['asymptotics', 'functions', 'limits']"
2258968,Why is the inverse image functor on sheaves defined the way it is?,"I have recently become comfortable with the definition of the inverse image sheaf in algebraic geometry. In particular, given ringed spaces $(X, \mathcal{O}_{X})$ and $(Y, \mathcal{O}_{Y})$ and a morhpism $f: (X, \mathcal{O}_{X}) \longrightarrow (Y, \mathcal{O}_{Y})$, then we can use the sheaf structure on $Y$ to define one on $X$. In particular, for $U \subseteq X$ open, we define the presheaf to be
$$U \mapsto\varinjlim  G(V)$$
where the colimit is taken over $V \subset Y$ such that $f(U) \subseteq V$. Intuitively, I interpret this as ""approximating"" $f(U)$ by smaller and smaller open sets, and the universal property of the colimit says that we want the smallest open set such that it's not smaller than $f(U)$. The drawback of this is that you need to sheafify the result, since sheafification is not preserved by colimits. My question is, why not do the opposite? Why not take a limit (instead of a colimit) over $V \subset Y$ such that $V \subset f(U)$. That way you wouldn't need to sheafify since, by abstract nonsense, limits preserve sheafification. Is there a reason it is defined the first way rather than the second? Have I fundamentally misunderstood something important? I ask because I noticed the way you can use a limit to recover a sheaf structure on a space once you have it defined on a base of open sets. I tagged this as a soft question too since I am not sure it has a definite answer. Thanks","['sheaf-theory', 'soft-question', 'algebraic-geometry']"
2258970,Finding a probability density function for $Y=X^2$,"Question: Let $X$ have an exponential distribution with parameter $λ$. Let $Y = X^2$. Compute $f_Y(t)$. My answer: I know that $f_X(x)=\lambda e^{-\lambda x}$ for $x \geq 0$. I found that $F_Y(t)=P(Y \leq t)=P(X^2 \leq t)=P(X \leq \sqrt{t})$ so that $f_X(x)= F'_X(\sqrt{t})= f_X(\sqrt{t})\frac{d}{dy}(\sqrt{t})=f_X(\sqrt{t}) \frac{1}{2\sqrt{t}}$. Now, $f_X(\sqrt{t})= \lambda e^{-\lambda \sqrt{t}}$. Thus, $f_Y(t)= \frac{ \lambda}{2\sqrt{t}}e^{-\lambda\sqrt{t}}$ for $t \geq 0$. I am unsure if what I have done is correct or if there is an easier way to tackle such questions.","['probability', 'functions', 'density-function']"
2258984,"What's wrong with my ""proof"" that the Lebesgue measure of $[0,1]$ is $0$? [duplicate]","This question already has answers here : What is wrong in this proof: That $\mathbb{R}$ has measure zero (5 answers) Closed 7 years ago . Proposition. $\lambda [0,1] = 0$ Proof. Let $\varepsilon>0$ be arbitrary. We will prove that $\lambda[0,1] <\varepsilon$. Let $q : \mathbb{N} \rightarrow \mathbb{R}$ denote an injection with image equal to $\mathbb{Q} \cap [0,1]$. Let $p : \mathbb{N} \rightarrow \mathbb{R}_{>0}$ denote a sequence with $\sum_{i \in \mathbb{N}} p_i < \varepsilon$. Then $$\lambda [0,1] = \lambda \bigcup_{i \in \mathbb{N}} (q_i+[-p_i/2,p_i/2]) \leq \sum_{i \in \mathbb{N}} \lambda (q_i+[-p_i/2,p_i/2]) = \sum_{i\in \mathbb{N}} p_i < \varepsilon$$ So $\lambda[0,1] < \varepsilon$. Since this is true for all $\varepsilon>0$, we deduce that $$\lambda [0,1] = 0.$$ Question. What gives?","['fake-proofs', 'lebesgue-measure', 'measure-theory']"
2259011,Group-theoretic proof that $n$ does not divide $2^n-1$. [duplicate],"This question already has answers here : For $n \geq 2$, show that $n \nmid 2^{n}-1$ (4 answers) Closed 7 years ago . I know a elementary way to prove that for $n>1$, $n$ never divides $2^n-1$: Suppose that $n$ does divide $2^n - 1$. Then $n$ must be odd. Let $p$ be the smallest prime dividing $n$. Then $2^{p-1}\equiv1 \pmod p$. Let $m$ be the smallest divisor of $p - 1$ such that $2^m \equiv1 \pmod p$. Since $m$ is smaller than $p$ it must be coprime to $n$, so $n = qm + r$ with $0 < r < m$. Hence $2^r \equiv 1 \pmod p$. Contradiction. One can find this solution here (it's from an old Putnam exam). But I heard that there is a nice way to prove the claim utilizing group theory and Lagrange theorem. Could somebody provide such a proof?","['number-theory', 'alternative-proof', 'group-theory', 'divisibility']"
2259027,Finding the probability density function of $X+Y$,"Question: Let $X$ and $Y$ be two independent and identically distributed exponential random variables with parameter $\lambda>0$. Compute the probability density function of $X+Y$. My Answer: I have found the joint probability density function of $X$ and $Y$ to be $f_{X,Y}(x,y)=\lambda^2e^{-\lambda x - \lambda y}$. I then let $Z=X+Y$ and calculated $F_Z(z)=\lambda^2e^{-\lambda z}$. I know I need to integrate $F_Z(z)$ to calculate the density function but am unsure on what the limits should be or if I found $F_Z(z)$ correctly. I was also wondering if there is a quicker way to tackle such questions or if this method is okay.","['probability', 'functions', 'density-function']"
2259068,Is it possible to compute Right Triangle's Legs starting from another Right Triangle with the same Hypotenuse?,"In an application of the Manhattan Distance trough the haversine formula, I was stuck in a problem that doesn't allow me to compute the right distance among two points in a space. Despite the scope, it could be useful to many other applications, so I'm trying to find a ""good enough"" solution of this tedious problem. Take a look at this simple picture to easily understand the problem: right triangles with same hypotenuse There are two right triangles, one red and one blue, which have the same hypotenuse but different legs and legs ratios.
The two legs of the red triangle are known, so it is easy to compute both hypotenuse and angles gamma and beta , but what is important for me is the computation of c and d which are the legs of the blue triangle. There doesn't exist a same ratio among the red legs and the blue ones (such as 16:9 in TV monitors), so it is probably impossible to solve this problem, but maybe I'm wrong. I spent some time trying to compute alpha and now I think that this is impossible, I know that putting alpha equal to 45° I will be able to compute c = d but this is not the solution that I want, as you can see the blue legs are different each other. If you have any idea concerning this problem please let me know your POV, I will appreciate because I was not able to find any suggestion. THANK YOU","['trigonometry', 'triangles']"
2259070,Prove that a weak continuous curve in a separable Banach space is a Borel function.,"I need some help to approach the following exercise. Let $B$ be a separable Banach space and let $\gamma : [0,1] \rightarrow B$ be a continuous curve with respect to the weak topology of $B$. Prove that $\gamma$ is a Borel function with respect to the Borel sets of the strong topology of $B$. Is this still true if $B$ is not separable?","['functional-analysis', 'weak-convergence', 'general-topology', 'topological-vector-spaces', 'analysis']"
2259116,"Show that $f(x,y)=\frac{x^3}{x^2+y^2}$ is differentiable and that directional derivatives are linear combinations of partial derivatives","Consider $f\colon\mathbb R^2\to\mathbb R$ with $f(0,0)=0$:
$$
f(x,y)=\frac{x^3}{x^2+y^2}.
$$
I need to show if $f$ is differentiable at $\vec 0$. One way of showing it, is noting that $f$ is homogeneous of degree 1. I have two questions about other approaches: 1) I would also like to show differentiability using the definition. I first calculated $D_1f(\vec0)=1$ and $D_2f(\vec 0)=0$. So I would need to show that for $\vec x=(x,y)\to (0,0)$, it holds that
$$
f(\vec x)-f(\vec 0)-x=o(\Vert\vec x\Vert).
$$
So basically I need
$$
\lim_{(x,y)\to(0,0)}\frac{y^2}{(x^2+y^2)\sqrt{x^2+y^2}}=0.
$$
I don't know how to show this limit. I can't bound stuff like $x^2+y^2\leq y^2$, because that doesn't help me anywhere. Any tips? edit I made an error, it should have been: $$
\lim_{(x,y)\to(0,0)}\frac{xy^2}{(x^2+y^2)\sqrt{x^2+y^2}},
$$
for which it is easy to show that this limit equals 0! So only my second question is still relevant (see below) 2) I also wanted to check if for $\vec u=(u_1,u_2)$, $D_{\vec u}f(\vec 0)$ is a linear combination of the partial derivatives. However, this doesn't seem to be true, for we have
$$
D_{\vec u}f(\vec 0)=\lim_{t\to 0}\frac{t^3u_1^3}{t^3(u_1^2+u_2^2)}=\frac{u_1^3}{u_1^2+u_2^3}\neq u_1D_1f(\vec 0)=u_1.
$$
So did something go wrong calculating the directional derivatives?
$$
D_1f(\vec 0)=\lim_{t\to0}\frac{t^3}{t^3}=1
$$
and
$$
D_2f(\vec 0)=\lim_{t\to0}\frac{0}{t}=0.
$$
So how does the directional derivative not equal the linear combination of the partial derivatives, while $f$ is differentiable?","['multivariable-calculus', 'partial-derivative', 'derivatives']"
2259152,"If $e^f$ is holomorphic, then so is $f$?","Let $f$ be defined on some open set. Is it true that if $e^f$ is holomorphic, then so is $f$? I believe this is true. But I do not know how to prove it. Please help.",['complex-analysis']
2259157,Which is greater $x_1$ or $x_2$?,$$x_1=\arccos\left(\frac{3}{5}\right)+\arccos\left(\frac{2\sqrt{2}}{3}\right)$$ $$x_2=\arcsin\left(\frac{3}{5}\right)+\arcsin\left(\frac{2\sqrt{2}}{3}\right)$$ We have to find which is greater among $x_1$ and $x_2$ If we add both we get $$x_1+x_2=\pi$$ If we use formulas we get $$x_1=\arccos\left(\frac{6\sqrt{2}-4}{15}\right)$$ and $$x_2=\arcsin\left(\frac{3+8\sqrt{2}}{15}\right)$$ but how to compare now?,"['algebra-precalculus', 'functions']"
2259159,Is every submodule of cyclic module over PID cyclic?,"I needed to check if any subgroup of cyclic abelian group is cyclic and successfully proved that ""yes"" using the fact that $\mathbb{Z}$ is Euclidian domain. It's easy to give an example that it doesn't hold for modules over arbitrary ring, but I am pretty sure that it does for PID. How can I prove it?","['abstract-algebra', 'modules']"
2259240,$S=T\circ T + T+\mathrm{Id}_V$ and there is a $T$-invariant subspace $U\subseteq V$ with $ \dim (U) = 2$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $V$ be a vector space with $\dim V < \infty$. Let $T, S:V\rightarrow V$ be linear operators, $S=T\circ T + T+\mathrm{Id}_V$ and $\dim\mathrm{Im}(S) < \dim (V)$. How to prove that there exists a $T$-invariant subspace, $U \subseteq V$, such that $\dim(U) = 2$ ?","['matrices', 'abstract-algebra', 'linear-algebra', 'vector-spaces']"
2259243,Solving Recurrence Relation with substitution,"How to solve T(n) = T(n-2) + n using iterative substitution Base case:
T(0) = 1
T(1) = 1

Solve:
T(n) = T(n-2) + n Currently I have: T(n) = T(n-2) + n
     = T(n-4) + n - 2 + n = T(n-4) + 2n - 2
     = T(n-6) + n - 4 + n - 2 + n = T(n-6) + 3n - 6
     = T(n-8) + n - 6 + n - 4 + n -2 + n = T(n-8) + 4n - 12
     = T(n-10) + n - 8 + n - 6 + n - 4 + n - 2 + n = T(n-10) + 5n - 20 The pattern I see is: $$\ T(n-2 \sum_{i=1}^k i) + n \sum_{i=0}^k i - \sum_{i=0}^{k-1} i(i+1) $$ but this may be wrong because I am completely stuck after this","['substitution', 'recurrence-relations', 'computer-science', 'discrete-mathematics']"
2259361,Is $n\log(n)+m\log(m)=O(n\log(m)+m\log(n))$? And what about $n\log(m)+m\log(n)=O(n\log(n)+m\log(m))$?,"I am trying to decide if each of these two statements are true or false: $n\log(n)+m\log(m)=O(n\log(m)+m\log(n))$ $n\log(m)+m\log(n)=O(n\log(n)+m\log(m))$ I've tried using some properties of logarithms so as to take these two statements to these inequalities: For the first one, the statement is true if and only if there exist $c$ and $(n_0,m_0)$ such that for all $(n,m)>(n_0,m_0)$ (which means $n>n_0$ and $m>m_0$) $$n^n* m^m \leq c(m^n* n^m)$$ $${n}^{n-m}\leq cm^{n-m} $$ If I take $m=m_0+1$ and $n=(n_0+1)(m_0+1)c$ then $(n,m)>(n_0,m_0)$ but $$n^{n-m} > cm^{n-m}$$ From here it follows that the first statement is false. As for the second one, the statement is true if and only if there exist $c, (n_0,m_0)$ such that for all $(n,m)>(n_0,m_0)$ $$m^n*n^m \leq c(n^n*m^m)$$ $$n^{m-n} \leq cm^{m-n}$$ I got stuck at this part, I would appreciate some help to prove or disprove the second statement and also to know if I've done the first part correctly. Thanks in advance.","['asymptotics', 'limits']"
2259380,Under what conditions does something count as a proof?,"I'm new to discrete math, and I am struggling with the concept of proof. I asked for a precise definition, but the professor remarked there was no such precise definition. For example, a homework question asks me to show that, if σ: A→B is an isomorphism for two structures A and B, then σ inverse is an isomorphism. Now, this seems to me to fall directly out of the definition: an isomorphism is a bijection that is closed under operations in (on?) the structure, and that has an inverse. Since σ is a bijection, σ inverse will be a bijection, and so uniquely determined. Since σ is an isomorphism, σ inverse must be an isomorphism. I am sure this does not constitute a proof, but I am unsure why. In general, I want to know in virtue of what one sequence of observations could be called a proof but not another, and why something that is obvious may yet need to be proven.","['proof-writing', 'discrete-mathematics']"
2259412,Infinitely many primes divide some $\sum_{k=1}^n k!$,"For a positive integer $n$ define $$a_n=\sum_{k=1}^n k!.$$ Prove that the set of primes that divide some $a_n$ is infinite. Some progress I guess. Let $S$ be the set of primes dividing some $a_n$, and suppose for contradiction that $S$ is finite. There must exist a prime $p\in S$ and an $N>p$ such that $p\mid a_N$: then $p\mid a_k$ for all $k\geq N$. Let $v_p(n)$ denote the $p$-adic valuation of $n$. If there is an $n$ such that $v_p(a_{n-1})\neq v_p(n!)$ for all primes $p\in S$, then it follows that $v_p(a_k)=\min\{v_p(a_{n-1}),v_p(n!)\}$ for all $k\geq n$, so $a_n$ is bounded, contradiction. Else, there exist primes $p_1,\dots,p_k\in S$ such that $v_{p_i}(a_{n-1})=v_{p_i}(n!)$ for all $n$. But from here, I'm stuck.","['number-theory', 'prime-numbers']"
2259413,"Convergence in $L^2(1,\infty)$ – counterexample","Consider the (complex) Hilbert space $L^2(1,\infty)$ and a real function $g(x)=x^2$ defined on the interval $(1,\infty)$. Does there exist a sequence of functions $f_n \in L^2(1,\infty)$ and a function $f \in L^2(1,\infty)$ satisfying all the following conditions? $f_n \cdot g \in L^2(1,\infty)$ for every $n \in \mathbb{N}$ $f \cdot g \in L^2(1,\infty)$ $f_n \rightarrow f$ in the norm of $L^2(1,\infty)$ $f_n \cdot g \rightarrow f \cdot g$ in the norm of $L^2(1,\infty)$ $\int_1^{\infty}f_n(t) \mathrm{d}t=0$ for every $n \in \mathbb{N}$ $\int_1^{\infty}f(t) \mathrm{d}t \neq 0$ This question was inspired by my recent thread ( Adjoint of an operator on $L^2$ ), where I was shown that this should be possible. However, I'd like to see a straightforward (and perferably constructive) argument. I've been thinking about this for more than hour now with no success. Thanks for any help.","['real-analysis', 'hilbert-spaces', 'functional-analysis', 'lebesgue-integral', 'analysis']"
2259479,"Show that $\int_a^b |f(x)|^2 \,\mathrm dx \le \frac{(b-a)^2}{\pi^2}\int_a^b |f'(x)|^2 \,\mathrm dx$","$\def\d{\mathrm{d}}$Show that if $f \in C^1[a,b]$ and $f(a)=f(b)=0$, then $$\int_a^b |f(x)|^2 \,\d x \le \frac{(b-a)^2}{\pi^2}\int_a^b |f'(x)|^2 \,\d x.$$ By a change of variable, it suffices to assume that $a=0$ and $b=\dfrac{1}{2}$. Extend $f$ to $\left[-\dfrac{1}{2},\dfrac{1}{2}\right]$ by setting $f(-x)=-f(x)$, then extend $f$ to be periodic on $\mathbb{R}$, $f$ thus extended is in $C^1(\mathbb{T})$. $$\hat{f}(k)=\int_{-\frac{1}{2}}^{\frac{1}{2}}f(x)e^{-2ik\pi x} \,\d x=\frac{1}{ik\pi}\int_0^{\frac{1}{2}}f'(x)e^{-2i\pi kx} \,\d x=\frac{1}{2i\pi k}\hat{f'}(k).$$ Now $$\sum_{k\in \mathbb{Z}}|\hat{f}(k)|^2=\sum_{k\in \mathbb{Z}}\frac{1}{4\pi^2k^2}|\hat{f'}(k)|^2\le \frac{1}{4\pi^2}\sum_{k \in \mathbb{Z}}|\hat{f'}(k)|^2.$$ This gives us that $$\int_{0}^{\frac{1}{2}}|f(x)|^2 \,\d x \le \frac{1}{4\pi^2}\int_0^{\frac{1}{2}}|f'(x)|^2 \,\d x.$$ For the general case define $g:\left[0,\dfrac{1}{2}\right] \to \mathbb{R}$ by $g(x)=f(2(b-a)x+a)$. Then by the above we have $$\int_0^{\frac{1}{2}}|g(x)|^2\,\d x \le \frac{1}{4\pi^2}\int_0^{\frac{1}{2}}|g'(x)|^2\,\d x,$$ which gives that $$\int_{0}^{\frac{1}{2}}|f(2(b-a)x+a)|^2\,\d x \le \frac{1}{4\pi^2}\int_0^{\frac{1}{2}}|f'(2(b-a)x+a)|^24(b-a)^2\,\d x.$$ Let $u=2(b-a)x+a$. Then $\d u=2(b-a)\,\d x$ and the integral changes to $$\int_{a}^b|f(u)|^2\,\d u \le \frac{(b-a)^2}{\pi^2}\int_a^b|f'(u)|^2\,\d u.$$","['real-analysis', 'fourier-series', 'fourier-analysis', 'analysis']"
2259501,"Marbles into bins, where bins must have *at least* a certain number of marbles","Say we have $2n$ indistinguishable marbles to be distributed into $n \geq 3$ labeled bins.  How many arrangements are there such that 2 bins have at least 2 marbles each, and the remaining bins have at least $1$ marble each? I originally attempted to solve this problem by assigning all bins to have 1 marble each, then choosing 2 of the $n$ bins to get a second marble.  I then attempted to distribute the remaining marbles using multichoose/stars and bars, but I realized this could lead to over-counting of scenarios. What might be a better approach to solving this problem?  Thank you!","['combinatorics', 'discrete-mathematics']"
2259517,Evaluate limit of sums,"Evaluate $$\lim_{n \to \infty} \sum_{k=1}^n \frac{1}{n + \sqrt{k^2+n}}$$ I saw this as a Riemann Sum and tried to rewrite as
$$\lim_{n \to \infty} \frac{1}{n} \sum_{k=1}^n \frac{1}{1 + \sqrt{(\frac{k}{n})^2 + \frac{1}{n}}}$$ but I can't say this is equal to $$\int_0^1 \frac{1}{1 + \sqrt{x^2 + 1}}$$ because there would be a too big error. The answer should be $\ln 2$.","['riemann-sum', 'sequences-and-series', 'limits']"
2259591,Prove that $xy=yx$,"Let $(G,\cdot)$ be a group and $f,g:G\rightarrow G,f(x)=x^6,g(x)=x^{10}$ are homomorphisms, where $f$ is injective. Prove that $xy=yx$ . We know that $(xy)^{10}=x^{10}y^{10},(xy)^{6}=x^{6}y^{6},(xy)^{9}=y^{9}x^{9},(xy)^{5}=y^{5}x^{5},x^{9}y^{10}=y^{10}x^{9}$ and $x^{5}y^{6}=y^{6}x^{5}$ , but I couldn't use these results in a productive way.","['abstract-algebra', 'group-theory']"
2259596,Why does the partial of $f: \Delta \to \mathbb{R}^2$ fail to exist?,"Given $f: \Delta = \{x = (x_1,x_2)| x_1+x_2 = 1, x_1 \geq 0, x_2 \geq 0\} \to \mathbb{R}^2$ Claim: $\dfrac{\partial f_i}{ \partial x_j}$ doesn't exist. This statement is true. Can anyone please provide a way to justify this statement? I have a feeling that this is due to compactness of the domain of $f$, which comes into conflict with the formal definition of the partial derivative. But I do not know if we could extend the definition of partial derivative for $f$ defined on compact sets. Further, I can produce large amount of examples that seems to contradict the claim: Example: Consider $f(x_1,x_2) = \begin{bmatrix} x_1 \\ 2 x_2 \end{bmatrix} = \begin{bmatrix} f_1 \\ f_2 \end{bmatrix}$, then clearly $\dfrac{\partial f_1}{\partial x_1} = 1, \dfrac{\partial f_1}{\partial x_2} = 0$, ditto the other partials. Can anyone please assist!","['derivatives', 'real-analysis', 'multivariable-calculus', 'jacobian', 'definition']"
2259604,An exercise on Central Limit Theorem and Law of Large Numbers,"Let $X_1,X_2,\dotsc$ be independent random variables with the common density $\frac{1}{2}e^{-|x|}$, where $-\infty < x < \infty$.
  Show that $(n^{0.5}\sum_{i=1}^n X_i)/\sum_{i=1}^n X_i^2$ converges to $Z$ in distribution, where $Z$ is a Normal random variable with mean $0$ and variance $1/2$. (Hint: Use Slusky's theorem.) My idea is to show that $n^{0.5}\sum_{i=1}^n X_i$ converges to some normal r.v. in distribution while $\sum_{i=1}^n X_i^2$ converges to some constant number in probability so the whole thing would converge to a normal r.v.. But I have no idea how to show it and I'm not sure if I'm on the right track. Could anyone explain how to do this? Thanks in advance!","['probability-theory', 'probability']"
2259624,"How to explain this relation between surface area and 1st derivative of volume(circle, sphere, square and cube)?","I have recently realized that the first derivative of the area of a circle $A = \pi r^2$ is the circumference (perimeter) $C = 2 \pi r$ and the first derivative of the volume of a sphere $V = 4 \pi r^3 / 3$ is the surface area of a sphere $SA = 4 \pi r^2$. (So basically 3D to 2D, 2D to 1D). Then I tried with cube and square and found out that the first derivative of the area of a square $A = a^2$ is half the perimeter of a square, and the first derivative of the volume of a cube $V = a^3$ is half the surface area of a cube. Is there any mathematical explantion to this?","['calculus', 'geometry']"
2259640,Cramer-Rao Casella Berger 7.38 for exponential family,"The question states  ''let $X_{1}, \dots, X_{n}$ be random sample from $f(x \mid \theta) = \theta\cdot x^{\theta-1}$ for $0 < x< 1 ; \theta > 0$ . Is there a function of $\theta, g(\theta)$ for which there exists an unbiased estimator of $\theta$ whose variance $\textbf{attains}$ the Cramèr-Rao lower bound ? if so find it!"". so we have an exponential family, and we can interchange differentiation and integration, so the fisher information term, denominator of the Cramér-Rao lower bound, I calculated as $E \left(\dfrac{\partial}{\partial \theta}[\ln(\theta \cdot x^{\theta-1})] \right)^{2} = -n E \left(\dfrac{\partial^{2}}{\partial \theta^{2}}(\ln(\theta x^{\theta-1}\right) \implies \dfrac{\theta^{2}}{n}$ taking $\dfrac{1}{I(\theta)}$ Now just taking a stab the statistic I've used is $W(X)= \overline{X}$ which I calculate to be UBE since $E[X] = \dfrac{\theta}{\theta + 1}$ and thus E $[\overline{X}] = \frac{\theta}{\theta + 1}$ from my calculations (hopefully right). similarly, if I calculate the variance I get $\dfrac{\theta}{(\theta + 1)^{2}(\theta + 2)} \geq \dfrac{\theta^{2}}{n}$ satisfies the lower bound. If I examine the MLE I find: $\dfrac{n}{\theta} + \sum_{i}\ln(x_{i}) = 0 \implies \hat{\theta_{MLE}} = \dfrac{-n}{\sum \ln(x_{i})}$ . the attainment theory states \begin{equation}
\begin{split}
\frac{n}{\theta} + \sum_{i}\ln(x_{i}) &= a(\theta)[W(\vec{x})-\tau(\theta)]\\
 &= n [\frac{ \sum \ln(x_{i})}{n} - \dfrac{-1}{\theta}]
\end{split}
\end{equation} where if W(x) satisfies the above, then it is the best estimate for $\tau$ . We need to use Rao-Blackwell theorem for W in the above equation to show that $\dfrac{1}{\hat{\theta_{MLE}}}$ is the best. Consider Y = \log(X) now applying the transformation with the Jacobian we have \begin{equation}
\begin{split}
f_{X}(e^{y}) = \theta e^{y(\theta-1)}\cdot e^{y} = \theta e^{y\theta} = f_{Y}(y)
\end{split}
\end{equation} where E[Y] = $\frac{1}{\theta}$ (Which I think is an unbiased estimator ?) Using the Rao-Blackwell theorem, let $\theta^{\star} = E[Y_{i} \mid \sum y_{i} = t]$ where since $f_{Y}(y)$ is an exponential family then $\sum y_{i}$ can be shown to be sufficient statistic. then \begin{equation}
\begin{split}
 E[\theta^{\star}] &= E \left[ E[Y_{i} \mid \sum y_{i} = t] \right] \\
 &= E\left[ \theta^{\star} \right] \\
 &= \frac{1}{\theta^{\star}}
\end{split}
\end{equation} which really fits into the attainment equation written above! so my guess is to let $W(\vec{x}) = \dfrac{1}{\theta_{\text{MLE}}^{\star}}$ be the best UBE (?)","['statistics', 'estimation', 'variance', 'upper-lower-bounds']"
2259642,Decomposing symmetric tensor field into sum of metric and tensor product,"Consider a symmetric tensor field $K_{ij}$ on a 2-dimensional Riemannian manifold with metric $g_{ij}$. How does one show that there exists a (smooth) function $f$ and one-form $\phi$ such that $$K_{ij}=fg_{ij}+\phi_i\phi_j?$$
I tried raising the $j$ index (so the metric becomes the identity) and solving the equation directly, but couldn't get the algebra to work out, and it would almost certainly involve division somewhere so smoothness gets dicey.","['differential-geometry', 'riemannian-geometry', 'linear-algebra']"
2259676,Verifying the identity $\frac{1}{\cos x} - \cos x = \sin x \tan x$,$\frac{1}{\cos x} - \cos x = \sin x  * \tan x$ I have tried a few things and nothing works Left Side $\frac{1}{\cos x} - \cos x$ $1 - (\cos x)^2$ $1 - 1 + \frac{\cos 2x}{2}$ $ \frac{\cos 2x}{2}$ $ \frac{\cos x}{2} \times \frac{\cos}{2}$ ... And I am out in left field!,['trigonometry']
2259700,Residue Theorem: Evaluate the integral $\int_\pi^{3\pi} \frac {dx}{5\cos x+13}$,Evaluate the integral using the Residue Theorem. $$\int_\pi^{3\pi} \frac {dx}{5\cos x+13}$$ Residue Theorem makes my head hurt. I have a lot of trouble with Laurent series in the first place. Any help would be greatly appreciated!,"['residue-calculus', 'complex-integration', 'laurent-series', 'complex-analysis', 'contour-integration']"
2259709,"Is $1 = [1] = [[1]] = [[[ 1 ]]], \ldots$?","Is the following true? Where [a] is a 1x1 matrix containing the object a. $$
\begin{bmatrix}
2
\end{bmatrix}
=\\
\begin{bmatrix}
\begin{bmatrix}
2
\end{bmatrix}
\end{bmatrix}
=\\
\begin{bmatrix}
\begin{bmatrix}
\begin{bmatrix}
2
\end{bmatrix}
\end{bmatrix}
\end{bmatrix}\\
\vdots
$$ I am curious because I am writing a function for adding matrices, but there is no rule forbidding elements of matrices to be matrices; so I want to know if $$
\begin{bmatrix}
\begin{bmatrix}
\begin{bmatrix}
2
\end{bmatrix}
\end{bmatrix}
\end{bmatrix} 
+
\begin{bmatrix}
\begin{bmatrix}
2
\end{bmatrix}
\end{bmatrix}
= 4
$$ after canonicalization or not. I also want to know if this holds for direct sum: $$
\begin{bmatrix}
\begin{bmatrix}
\begin{bmatrix}
2\\
4
\end{bmatrix}
\end{bmatrix}
\end{bmatrix} 
+
\begin{bmatrix}
\begin{bmatrix}
2\\
4
\end{bmatrix}
\end{bmatrix}
= 
\begin{bmatrix}
4\\
8
\end{bmatrix}
$$ I am aware that this messes up the convenient ""indexing"" property, as A[0] will no longer make sense; but matrices don't require to support this property anyway, we just have it for free for implementing them as arrays, so it's a nonissue. I am curious if there is any particular harm to the algebra if 1 = [1] = [[1]] = [[[1]]] that makes it unusable, or if it just causes minor nuisance? Breakages so far/severity: Indexing of a matrix(minor) [3] at 0 is 3, but 3 at 0 is undefined(since indexing is not defined for scalars), and it is not clear whether [[3; 4]] at 0 is [3; 4] which is what it would be in current algebra, whereas it would be 3 in proposed algebra. This is not very severe since matrices are not really arrays, but bilinear maps, so indexing them is fairly naive to begin with. This property won't work unless the given matrix is canonicalized before being indexed. Multiplication of matrix by scalar(minor/real damage) . There are some concerns over whether or not multiplication by scalar is invalid, but my previous argument is invalid. so I removed it.",['linear-algebra']
2259777,Counting Balanced Sequences,"Let's call a sequence with $n$ occurrences of $L$ and $n$ occurrences of $R$ a balanced sequence if on counting from left to right the number of $L$'s is always greater than or equal to the number of $R$'s. How many such balanced sequences are there? The answer given in my textbook is 
$$ {{2n}\choose{n}}  \cdot \frac{1}{n+1}$$ I could devise no counting arguments for this. EDIT :
The number of balanced and unbalanced sequences is 
$$ {{2n}\choose{n}}$$ For finding the unbalanced sequences,I've taken hint that interchanging $R$ and $L$ from the place where the number of occurrences of $R$ exceeds the number of occurrences of $L$.
This gives the number of such sequences to be$$ {{2n}\choose{n+1}}  $$ I infer that this interchanging produces a bijection between unbalanced sequences with $n$ occurrences of $L$ and $n$ occurrences of $R$ and $n-1$ occurrences of $L$ and $n+1$ occurrences of $R$. But I am not sure if my reason for this bijection is correct.After the interchange the number of occurrences of $R$ is always greater than that of $L$.So all the sequences will be unbalanced.But how could I prove that this will contain exactly the same number of unbalanced sequences as the original sequence?","['combinatorics', 'catalan-numbers']"
2259801,What regularity conditions on partial derivatives are equivalent to differentiability?,"This question is intended to kind of rekindle this old question , which was apparently very hard didn't receive a satisfactory answer. I'm aware that the hope of a definite answer is quite slim, but I'm still very curious to know: Suppose $f:U\to \Bbb R$ is a function, $U$ is an open subset of $\Bbb R^n$, and $x_0\in U$, and the partial derivatives $\partial_i|_{x_0}f,\,i=1,\cdots,n$ exist. Then what regularity conditions on $\partial_i|_{x_0}f,\,i=1,\cdots,n$ are a sufficient and necessary condition for $f$ to be differentiable at $x_0$? The mere existence of $\partial_i|_{x_0}f$ is far from enough. The continuity of all of them is over-sufficient. The weakest sufficient condition AFAIK is this one , i.e. the continuity of all but one of them, which is nevertheless still over-sufficient. Given that we can easily construct a function differentiable at $x_0$ yet has all its partial derivatives discontinuous at $x_0$, like $$f(x,y)=\begin{cases}(x^2+y^2)\sin\left(\dfrac{1}{\sqrt{x^2+y^2}}\right) & \text{ if $(x,y) \ne (0,0)$}\\0 &  \text{ if $(x,y) = (0,0)$}.\end{cases}$$ this problem I believe is intrinsically hard. Has any research been done that can shed some light on this complicated problem?","['multivariable-calculus', 'real-analysis', 'calculus', 'derivatives']"
2259840,Radius of circle tangent to the semi-circles in an arbelos,"Points $P$, $Q$, and $R$ lie on the same line. Three semi-circles with the diameters $PQ$, $QR$, and $PR$ are drawn on the same side of the line segment $PR$. (That is, suppose we have an arbelos .) The centers of the semi-circles are $A$, $B$, and $O$, respectively. A circle with center $C$ touches all three semi-circles. Show that the radius of this circle is 
  $$c = \frac{ab(a+b)}{a^2+ab+b^2}$$
  where $a :=|AQ|$ and $b :=|BQ|$ are the radii of the smaller two semi-circles. I know that since this is a trigonometry question, I have to construct a triangle somewhere. However, I am unsure as to whether I should construct the triangle between points ACQ or points ACB.","['circles', 'trigonometry', 'triangles', 'geometry']"
2259855,Bride and groom for photo,"In how many ways can a photographer at a wedding arrange seven people in arow, including the bride and the groom, if the bride must be next to the groom? Here is my attempt at solving this problem. Since there are 7 people and 2 of the seven are the bride and groom. The bride and groom must be next to each other. So we can consider them as one person. This leaves 6 people left. The bride and groom can be arranged 2 different ways. The six people can be arranged 6! Different ways. So in total 2*6!.","['combinatorics', 'discrete-mathematics']"
2259862,On understanding nullary relations and the definition of $\mathfrak A \models P$ for a structure $\mathfrak A$ and 0-ary predicate $P$,"I had just asked a similar question, but realized a few things. I am now looking to see if my understanding of how to define $\mathfrak A \models P$ where $P$ is a predicate of 0-ary (i.e., a propositional symbol) and $\mathfrak A$ is a structure, is correct. Somewhat informally, an $\mathcal{L}-structure$ for a language $\mathcal{L}$ is a pair ( $D, I$ ) where $D$ is our domain of objects and $I$ maps to each constant symbol an object of $D$ to each n-ary function symbol, a function from $D^n$ to $D$ to each n-ary predicate symbol $P$ , a relation $I(P) \subseteq D$ A text would then typically talk of denotation and how to ""get a hold"" of what each term denotes, then talk of variable assignments, and then finally define logical consequence:' $\models$ '. Since my question doesn't pertain to variable assignments, for succinctness I won't consider it. So then for defining when a formula $\varphi$ is a logical consequence of a structure $\mathfrak A$ (written as: $\mathfrak A \models \varphi$ ), I've seen texts start out with something like: Given that $t_1 , ... , t_n$ are terms and tha $P$ is a predicate symbol of arity $n$ : $\mathfrak A$ $\models $ P( $t_1$ ,..., $t_n$ ) iff ( $d_1$ ,..., $d_n$ ) $\in$ $I(P)$ , where $d_i$ = || $t_i$ || where || $t_i$ || is the notation used for the denotation of term $t_i$ . So when P is of arity 0, the right hand condition becomes: $ () \in I(P)$ , correct? And according to this post , the empty tuple is equal to the empty set. That is, $( ) = \emptyset$ ,which would make sense when thinking about it. It's helpful to note that there is a quote from Bruno Poizat's book on mathematical logic (that I won't copy and paste here to try to minimize the clutter) which deals with this topic and which was put as an answer in this thread about the same thing, but I didn't find it as elucidating as I would have hoped. So my question is if my following understanding of the situation is accurate. For a structure $\mathfrak A$ and a 0-ary predicate $P$ we have that: $\mathfrak A$ $\models P$ iff $\emptyset \in I(P)$ And the line of reasoning as to why we associate 'true' with the relation (the set) $\{ \emptyset \}$ and 'false' with $\emptyset$ is as follows An n-ary predicate symbol under an interpretation is mapped to a subset of $D^n$ We are dealing with 0-ary predicate symbols, so they should be mapped to $D^0$ $D^0 = \{ \emptyset \}$ There are two sets which are subsets of $\{ \emptyset \}$ : either $\{ \emptyset \}$ itself or $\{\} = \emptyset$ Thus, there are two possible relations which the predicate symbol can be mapped to, those being either of the two aforementioned sets. If my understanding is correct, then a 0-ary predicate $P$ is a logical consequence iff $\emptyset \in I(P)$ . Depending on our interpretation, $I(P)$ will be either the set $\{ \emptyset \}$ or the set $\emptyset$ . If under our interpretation, $P$ is mapped to the set $\emptyset$ , then $\mathfrak A$ $\models P$ does not hold as $\emptyset \notin \emptyset$ . Hence why we associate false with $\emptyset$ . If under our interpretation, $P$ is mapped to the set $\{\emptyset \}$ , then $\mathfrak A$ $\models$ $P$ holds. Hence why we associate true with $\{ \emptyset \}$ . So we can say $\mathfrak A$ $\models$ $P$ holds for any 0-ary predicate $P$ iff $P$ is mapped to $\{\emptyset \}$ in our interpretation. Thank you for taking the time to read this. edit: the very last slide here very briefly discusses nullary relations and they seem to be in line with my understanding. But as one of the comments noted, perhaps it is odd/wrong to consider the empty tuple as the empty set here.
So what exactly is a nullary-relation in our context?","['model-theory', 'logic', 'elementary-set-theory']"
2259864,The number of algebraic integer within the unit disk,"Let $K$ be a number field (I am mostly interested in the case $K=\Bbb Q(\zeta_n)$ is a cyclotomic field). Let $\alpha$ be an algebraic integer in $K$. I would like to know whether there are only finitely many such $\alpha$ whose absolute value is less than 1. If so, is there any explicit bound? How about if we restrict to real algebraic integers with absolute value less than 1? For 2, if $K=\mathbb{Q}(\zeta_n)$, where $\zeta_n$ is a primitive $n^{th}$ root of unity, then is there a bound in terms of $n$?","['number-theory', 'algebraic-number-theory', 'field-theory', 'cyclotomic-fields']"
2259879,Asymptotic Riemann Roch,"I am reading Ravi Vakil's Foundation of Algebraic Geometry 20.1.I. I want to show this: Suppose $X$ is projective (over an infinite field), $\mathfrak{F}$ is a coherent sheaf on $X$ with support of dimension $= n$, and $\mathfrak{L}$ is a line bundle on $X$. Show that $\chi(\mathfrak{L}^{\otimes m}\otimes \mathfrak{F})$ is a polynomial with degree at most $n$, and the coefficient of $m^n$ is $(\mathfrak{L}^n\cdot \mathfrak{F})$ Hint: Expanding $(\mathfrak{L}^{n+1}\cdot (\mathfrak{L}^{\otimes i}\otimes \mathfrak{F}))=0$ to get a  recursion for $\chi (\mathfrak{L}^m \otimes \mathfrak{F})$. For the case that $\mathfrak{L}$ is very ample, I can obtain the result by induction on $n$ as follows: The case $n=1$ follows from Riemman Roch for nonreduced curves (Exercise 18.4 S). And if $n>1$, then I can find a global section $s$ of $\mathfrak{L}$, such that $s$ does not passes through the assocaited points of $\mathfrak{F}$.
By the short exact sequence
$$0\to \mathfrak{L}^{\vee}\otimes \mathfrak{F}\xrightarrow{\times s}\mathfrak{F}\to \mathfrak{G}\to 0$$ where $\mathfrak{G}$ has support with dimension $n-1$. I can obtain the result from the fact that Euler characteristic is additive. What I want to know is how to do the general case, I know that every line bundle on $X$ can be expressed as the difference of two very ample line bundles, but I don't know how to obtain the result from this. I also don't know how to use the hint, from the hint, I can obtain
$$\chi(\mathfrak{L}^{\otimes m}\otimes \frak{F})=\sum_{i=1}^{n+1}(-1)^{j+1}\chi(\frak{L}^{\otimes (m-i)}\otimes \frak{F})$$
but I don't know why this formula is useful. Any help or hints are appreciated, thank you.","['sheaf-cohomology', 'line-bundles', 'intersection-theory', 'algebraic-geometry']"
2259920,Polar coordinates unit vectors proof [duplicate],"This question already has answers here : relationship of polar unit vectors to rectangular (5 answers) Closed 1 year ago . Prove that the unit vectors in polar coordinates are related to those in rectangular coordinates by
\begin{align*}
\hat{r}&=\hat{x}\cos\phi+\hat{y}\sin\phi\\
\hat{\phi}&=-\hat{x}\sin\phi+\hat{y}\cos\phi.
\end{align*}
What are $\hat{x}$ and $\hat{y}$ in terms of $\hat{r}$ and $\hat{\phi}$?","['multivariable-calculus', 'polar-coordinates']"
2259926,Etale fundamental groups of the projective line and the affine line,"Theorem 1 Let $X$ be a normal integral scheme, $K$ its function field, $\bar{K}$
  an algebraic closure of $K$, and $M$ the composite of all finite
  separable field extensions $L$ of $K$ with $L\subset K$ for which $X$
  is unramified in $L$. Then the fundamental group $\pi(X)$ is
  isomorphic to the Galois group $\operatorname{Gal}(M/K)$. In the above paragraphs Theorem 1 at the beginning of this post is being used to compute the etale fundamental groups of $\mathbb P_{K}^1$ and $\mathbb A_{K}^1$. I've difficulty in understanding the difference between the two cases. In particular, I'm particular I've difficulty in understanding how to figure out if  a finite extension of $F$ of $k(t)$ is unramified over
$\mathbb P_{K}^1$ or $\mathbb A_{K}^1$? And in case  $\mathbb A_{K}^1$ are we looking only at valuations $v_f$ (and not $v_{\infty}$) and checking if $F$ is unramified at all these valuations? In case of  $\mathbb P_{K}^1$ are we looking at all the valuations $v_f$ and $v_{\infty}$ and checking if $F$ is unramified at all these valuations? Is that the difference? Why is checking at $v_{\infty}$ and $v_f$ enough in this case?","['etale-cohomology', 'algebraic-geometry', 'commutative-algebra']"
2259946,"If $g$ is commutator then so is $g^m$ for $(m,o(g))=1$","There are certain theorems in finite group theory whose proofs involve character theory and for which there are still no character-free proofs. Among such is Frobenius theorem on transitive permutation groups. (Another was Burnside's $pq$ theorem; but there is now group theoretic proof. I am considering one such theorem, whose proof is based on following theorem. Theorem 1. An element $g\in G$ is a commutator if and only if $\sum_{\chi\in{\rm Irr}(G)} \frac{\chi(g)}{\chi(1)}\neq 0.$ So if $m$ is an integer relatively prime to $o(g)=n$ , then consider the Galois automorphism $\sigma$ , which, on $n$ -th roots of unity acts by $\zeta_n\mapsto \zeta_n^m$ . Then $(\chi(g))^{\sigma}=\chi(g^m)$ . Thus, if $g$ is a commutator, then applying $\sigma$ to inequality in theorem we get that $g^m$ is also a commutator. Thus, Theorem 2. If $g\in G$ is a commutator then so is $g^m$ for $(m,o(g))=1$ . The Theorem 2 is purely group theoretic; but proof involves character theory arguments. Question is now simple: Q. Is there character-free proof for Theorem 2? (I do not know whether this question has been considered before by anyone.)","['finite-groups', 'representation-theory', 'group-theory', 'characters']"
2259968,Show an integration equality without using $\int\frac{\mathrm dx}{x}=\ln|x|+c$,Show that $$\int_{1}^{t_1t_2}\frac{\mathrm{d} x}{x}=\int_1^{t_1}\frac{\mathrm{d} x}{x}+\int_1^{t_2}\frac{\mathrm{d} x}{x}$$ without using $$\int\frac{\mathrm{d} x}{x}=\ln|x|+c.$$,['calculus']
2259989,"Interesting math question motivated by physics -- if $\int_0^1f(x)\,dx=1$ and f(0)=f(1)=0 then find $\min f'(x)$","I saw a question in a physics textbook which was: A particle starts from rest at $t=0$ , $x=0$ , and comes again at rest on $x=1$ , $t=1$ . Let the instantaneous acceleration be $a$ . Then: (a) $a$ cannot be positive for all $t\in[0,1]$ . (b) $|a|$ cannot exceed 2 at any point. (c) $|a|$ must be $\geq 4$ at some point (d) $a$ must change sign but no other assertion can be made. The anwer was (a,c) which is easy to see intuitively but how to attack this problem rigorously? Translated into math the problem becomes $$\text{If }\int_0^1 f(x) \, dx = 1,\text{ and }f(0)=f(1)=0\text{ then find } \min f'(x).$$ Assuming $f(x)$ is continuous. At first I thought lets use some integral inequalities like Cauchy-Schwarz or something but then I realised it wont work. After that I thought that this is somewhat similar to calculus of variations but not quite. I have no idea how to approach this rigorously but I want to see how its done because this is like a ""simple problem"" but still I have no clue how to approach this. ... Its probably indicating some sort of gap in my knowledge or technique. So .. Please help!","['derivatives', 'inequality', 'calculus', 'proof-writing', 'definite-integrals']"
2259992,Why the graph of $f(x)=ax+b$ is a straight line?,I am going to teach 10th grade students for the first time and while preparing my lecture i was just curious to know about this so as i can explain it to my students Thanks,['algebra-precalculus']
2260024,Show this matrix is invertible,"Consider the matrix
\begin{equation}
S_n = 
		\begin{bmatrix}
			\frac{1}{2!} & \frac{1}{3!} & \cdots & \frac{1}{(n+1)!} \\
			\frac{1}{3!} & \frac{1}{4!} & \cdots & \frac{1}{(n+2)!} \\
			\vdots & \vdots & \ddots & \vdots \\
			\frac{1}{(n+1)!} & \frac{1}{(n+2)!} & \cdots & \frac{1}{2n!} \\
		\end{bmatrix}.
\end{equation} I am interested to know if $S_n$ is invertible for all $n$. I do not need the inverse explicitly, knowing it exists is sufficient (ie. non-zero determinant for all $n$ is enough). If this matrix has a special name, I would appreciate if someone could bring it to my attention.","['matrices', 'linear-algebra']"
2260030,"For Brownian Motion definition, is pairwise independence of intervals sufficient?","Suppose that $B_t : t \geq 0$ is a stochastic process with: 1) $B(0) = 0$ 2) For $0 \leq t_0 < t_1 \leq t_2 < t_3$, $B(t_1) - B(t_0)$ and $B(t_3) - B(t_2)$ are independent. 3) $B(t + h) - B(t) \sim N(0,h)$, for all $t \geq 0$ and $h > 0$ 4) a.s. $t \to B(t)$ is continuous. Is $B(t)$ necessarily a Brownian motion? If not, what is a counter example? Note that the difference is that for $2)$, the usual definition requires independence among the adjacent differences for any finite set of times. I am aware that pairwise independent normal do not have to be normal, so I guess that could figure in here. However, I feel that there might be enough leftover structure to force the stronger independence statement. Also, I saw the same definition here: http://wwwf.imperial.ac.uk/~mdavis/course_material/sp1/BROWNIAN_MOTION.PDF","['probability-theory', 'brownian-motion']"
2260039,Identify covariance-like formula,"This might be a weird question, but in the process of some computation I obtained the following formula: $$\text{E}[X^2]\text{E}[Y^2] - \text{E}[XY]^2$$ It kind of looks like a ""quadratic"" covariance, but I don't know what it actually means. Is there a mathematical meaning to this quantity? Specifically, what kind of relationship between $X$ and $Y$ would ensure the above quantity is non-zero? UPDATE: Seems this is equal to $\text{Var}(XY) - \text{Cov}(X^2, Y^2)$. Is there a clearer meaning to this anyway?","['statistics', 'probability']"
2260042,"Calculate $ E(X) $ where $f(x,y) = \frac{1}{y}e^{-(y+\frac{x}{y})}$","I am trying to solve the following probability problem: Please calculate $ E(X) $ where the joint density function of x and y is: $$f(x,y) =
 \frac{1}{y}e^{-(y+\frac{x}{y})} \text{ for } x,y > 0$$ It is well known that the expected value of a continuous random variable is: $$
E(X) = \int_{-\infty}^\infty{xf_X(x)dx}
$$ That means that we have to find $f_X(x)$ first by doing: $$
f_X(x)=\int_{0}^\infty{\frac{1}{y}e^{-(y+\frac{x}{y})}}dy
$$ Note: The zero lower bound is due to the given inequality $ y > 0$. However, this integral turned out to be a handful (I tried substitution and integration by parts to no avail). Then, I tried this on WolframAlpha instead. However, it gave me an answer which I did not understand ( link ). Am I even supposed to integrate this integral in the first place? I do not know much about the bessel function, which was present in the answer given by WolframAlpha. Furthermore, I am only undergoing an introductory probability course so it is not possible for the integral to be so complex (I was not taught bessel function anyway). Could someone please advise me on how I could calculate the value of $E(X)$?","['probability-theory', 'expectation', 'random-variables']"
2260044,Definition of separable algebras over a field,"Let $k$ be a field, and $A$ a commutative $k$-algebra. I noticed two definitions of what it means for $A$ to be separable over $k$: Definition 1 [Matsumura, Commutative Algebra, 1980, (27.D) + (27.G)]: $A$ is separable over $k$ if for all field extensions $L$ of $k$, $A \otimes_k L$ is reduced. Definition 2 [ https://ncatlab.org/nlab/show/separable+algebra ]: $A$ is separable over $k$ if for all field extensions $L$ of $k$, $A \otimes_k L$ has zero Jacobson radical. Note that Definition 2 $\Rightarrow$ Definition 1 since the nilradical of a ring is contained in the Jacobson radical, but I don't see why Definition 1 $\Rightarrow$ Definition 2, unless some restrictions are imposed on $A$ (for e.g. if $A$ is of finite type over $k$, or if $A$ is generated as a $k$-algebra by a set $\{x_i\}_{i \in I}$  such that the cardinality of $I$ is less than the cardinality of $k$ [Stacks, Tag 00FU]). Question: Are the two definitions equivalent? If not, is one definition better than the other for commutative rings ?","['definition', 'abstract-algebra', 'field-theory', 'commutative-algebra']"
2260087,How can i solve this question with Geometric distribution or random variables?,"I tried have tried using a 'Geometric distribution', but it hasn't worked. John and Ron play basketball 10 times. The probability that John wins in single round = $0.4$. The probability that Ron wins in single round = $0.3$. The probability that there is equality between them in a single round = $0.3$. The ""Winner"" is defined to be the first to win a single round. The rotations are different and independent. What is the probability that John is the Winner?","['probability-theory', 'probability', 'random-variables', 'probability-distributions']"
2260154,Determining the number of solutions using Generating functions,"I have the equation $u_1 + u_2 + ... + u_5 = 24$ with the restrictions $1 \le u_i \le 7, i = 1,...5$ I've managed to work up to the point of finding the coefficient of $x^{24}$ in $(X+X^2+...X^7)^5 = X^5(1+X+...X^6)^5$ I know my final answer will need to be in binomial form similar to this $\binom{10}{5}$ However I am unsure where to go, or if this is even correct. Any help would be greatly appreciated.","['generating-functions', 'combinatorics', 'discrete-mathematics']"
2260163,Why are random walks in dimensions 3 or higher transient?,I watched this PBS video a while ago (relevant part here ) and have been trying to get my head around the idea of transient walks. The video says that a recurrent random walk is one that is guaranteed to return to it's starting position - all 1D and 2D walks - and a walk is transient if there is a positive probability that it never returns - 3D or higher. I've tried to have a think about this and looked some stuff up but I haven't had any breakthroughs. What confuses me is this: A random walk in 3 dimensions can be split up into 3 independent random 1D walks. If each of these walks is guaranteed to return to the starting position infinitely many times we can say that there is a finite positive probability that they will return to the starting point on a given 'turn'. The product of the three finite probabilities is finite so isn't there a finite chance that any random walk in three dimensions will return to the start on any given 'turn' and hence they are guaranteed to return at some point? I imagine I am just making incorrect assumptions about the nature of these infinite systems as is too easy to do but I'd like to know exactly where my intuition is wrong.,"['random-walk', 'probability']"
2260180,calculate number of ways to achive opposite Vertex,"Hi I have a problem with following task:
We have regular octagon. We start from one vertex want to move to the opossite one. We can only move to an vertex thats next to us( we may go right or left for each) now my task is to calculate the ways to get from starting vertex to opposite one doing exactly $n$ moves and opposite vertex is achived only at the end. 
Will be glad for hint and or sugestions as I am stuck with this one for a long time.","['combinatorics', 'discrete-mathematics']"
2260187,Find all functions $F(x)$ satisfying $F(x)=f(x)^2+f'(x)^2$,"Find all functions $F(x)$ satisfying $F(x)=f(x)^2+f'(x)^2$ such that $F(0)=9$ and $|f(x)| \le 2$ and $f(x)$ is thrice differentiable function One possibility i could get is $f(x)=3sinx$ and $f'(x)=3cosx$ which satisfies $|f(x)| \le 2$ so $F(x)=9$ any other functions possible? With given information above which of the following is/are True EDIT: A) there is at least one point in each of intervals  $(-2 \: \: 0)$ and $(0 \:\: 2)$ such that $|f'(x)| \le 2$ B)  there is at least one point in each of intervals  $(-2 \:\: 0)$ and $(0 \:\: 2)$ such that $F(x) \le 8$ C)there is no point of Local maxima in $(-2\: \: 2)$ for $F(x)$ D)For some $c \in (-2 \:\: 2)$ $F(c) \ge 9$, $F'(c)=0$ and $F''(c) \le0$","['algebra-precalculus', 'functions']"
2260189,Why if an integrable increasing process is continuous then its natural?,"I have been self-studying the book on Stochastic Differential Equations and Diffusion Processes by Watanabe and Ikeda. Here is something I dont really follow An increasing integrable process $A_t$(A is adapted to $\mathcal{F}_t$, integrable for all $t$ with right continuous increasing paths) is natural if $E\int_0^t m_s dA_s = E\int_0^t m_{s-} dA_s$ for every bounded martingale(we always use the right continuous modification of this bounded martingale which always exists as a consequence of the Doob's Upcrossing inequality) Claim:If an integrable increasing process $A$ is continuous then its natural Proof(In book)):Since $M$ is right continuous the integral $\int_0^t \mathbb{1}_{[M_s \neq M_{s-}]} dA_s$=0.a.s This implies that $\int_0^t M_sdA_s=\int_0^t M_{s-}dA_s$ My Attempt
So $\int_0^t \mathbb{1}_{[M_s \neq M_{s-}]} dA_s$=0 is true because if we think of this integral as a lebesgue stieltjes integral then since for every $\omega$, $t \mapsto A_t(\omega)$ induces a unique measure and since the set $\{s\in(0,t):M_s(\omega) \neq M_{s-}(\omega)\}$ has lebesgue measure $0$, we have that $\int_0^t \mathbb{1}_{[M_s(\omega) \neq M_{s-}(\omega)]} dA_s(\omega)=0$.(It has lebegue measure zero because a right continuous function has atmost countably many discontinuities). Is this reasoning correct or am I wrong? I would be grateful if you could help me out here","['stochastic-processes', 'probability-theory', 'martingales', 'stochastic-analysis']"
2260267,Flow of vector field,"For my PDE class I have to find the flow of the following vector field $$\mathbf{F}: \mathbb{R}^2-\{0\} \to \mathbb{R}^2, \mathbf{F}(x_1,x_2) = \frac{1}{r}(-x_2, x_1)$$
where $$r = \frac{1}{\sqrt{x_1^2 + x_2^2}}$$ I know that I can find the flow of this vector field by setting $$\mathbf{\dot{x}}(t) = \mathbf{F}(\mathbf{x}(t)) $$ which yields the equations $$ \dot{x_1} = \frac{1}{r} (-x_2) $$ and $$ \dot{x_2} = \frac{1}{r} x_1 $$ or in matrix notation 
$$ \dot{\begin{pmatrix} x_1 \\ x_2 \end{pmatrix}} = \begin{pmatrix} 0 & -\frac{1}{r} \\ \frac{1}{r} & 0 \end{pmatrix}\begin{pmatrix} x_1 \\ x_2 \end{pmatrix} $$ Normally, I would solve this quite easily with an exponential ansatz. But here, $r$ itself depends on $x$ and $y$ which makes the matrix nonlinear. Thus I have no idea how to approach this?","['ordinary-differential-equations', 'vector-analysis']"
2260300,Log of a sum with three terms,"From other posts on here I learned that the following is true: $$
\log(a + b) = \log\left(a \cdot \left(1 +  \frac{b}{a}\right)\right) = \log(a) + \log\left(1 +  \frac{b}{a}\right)
$$ What about $\log(a + b + c)$?","['algebra-precalculus', 'calculus']"
2260302,Am I supposed to use generating functions or combinatorics or something for this question?,"If there are 201 seats in the Parliamentary chamber, how many different ways are there for the numbers
of seats to be allocated amongst three political parties, subject to no one party having an overall
majority? I could figure it out manually. 201/3 = 67 per party. Thats one way. Then divide 67/2 (because you can move 2 from one party at a time to ensure the other 2 are equal) = 33.5 but use lower bound as a person cannot be split in half. That makes it 100+100+1 = 201. So now thats 33 ways. But party that gives up 2 each time can change. i.e. Party A gives up 2 members to B&C until 1 remain. Then party B gives up... then C. So would it be 1+(33*3) = 100 ways? Is there a cleaner way to do this, say using generating funtions or combinatorics of some sort? If not I dont know why the would ask this question. Any help appreciated.","['generating-functions', 'combinatorics', 'discrete-mathematics']"
2260309,Inverse of special type of symmetric block matrix,"$W = \begin{pmatrix}A & B &B &\cdots&B\\
B& A & B &\cdots &B\\
\vdots & \vdots & \vdots & \ddots &\vdots &\\
B& B & B &\cdots &A \end{pmatrix} $
where $A$ and $B$ are symmetric matrices of appropriate order. In fact $B = aJ$, where $J$ is the matrix of all ones. Is there any compact form of $W^{-1}$ ?. Thanks",['matrices']
2260337,"In the space of bounded sequences which converge to $0$ there is one such sequence with a minimum distance to $(1,1,1,...)$","In $\ell^{\infty}$, there is exactly one sequence in $c_0$ that has the minimum distance to $(1,1,1,...)$. I believe this statement is actually false. However, I am having trouble formulating two such sequences with minimal distance to disprove the statement. Could anyone provide a counter-example? Or is this statement actually true?",['functional-analysis']
2260353,Necessity of closedness in going from precompactness in chart to precompactness in the manifold,"I have a doubt about the last part of the proof of Lemma 1.10 in Introduction to smooth manifolds by John Lee, so I will put just the last part of the proof. Lemma 1.10 Every topological manifold has a countable basis of precompact coordinate balls. ""[...] If $V \subset U_i$ is one of these balls (a coordinate ball that is precompact in $U_i$ ), then the closure of $V$ in $U_i$ is compact, and because $M$ is Hausdorff, it is closed in $M$ . It follows that the closure of $V$ in $M$ is the same as its closure in $U_i$ , so $V$ is precompact in $M$ as well."" $\square$ I know that we need to prove that $\overline{V}$ is compact in $M$ , but by the Lemma  26.1 of Munkres's book Topology , it is clear that if $\overline{V}$ is compact in $U_i$ , then $\overline{V}$ is compact in $M$ , isn't it? Why show that $\overline{V}$ is closed in $M$ ensure that $\overline{V}$ is compact in $M$ ? Thanks in advance! Lemma 26.1 (Munkres) Let $Y$ be a subspace of $X$ , then $Y$ is compact if and only if every covering $Y$ by sets open in $X$ contains a finite subcollection covering $Y$ .","['manifolds', 'general-topology', 'compactness']"
2260413,Finding a sum of $1+\frac{1}{4\cdot2^{4}}+\frac{1}{7\cdot2^{7}}+\frac{1}{10\cdot2^{10}}+\cdots$,"I need someone to find a mistake in my soliution or maybe to solf it much more easily... I have got a sum $$1+\frac{1}{4\cdot2^{4}}+\frac{1}{7\cdot2^{7}}+\frac{1}{10\cdot2^{10}}+\cdots$$ and need to evaluate it. So here's my soliution:
$$S(x)=1+\frac{x^{4}}{4\cdot2^{4}}+\frac{x^{7}}{7\cdot2^{7}}+\frac{x^{10}}{10\cdot2^{10}}+\cdots=1+\sum_{n=1}^\infty \frac{x^{3n+1}}{(3n+1)\cdot2^{3n+1}}=1+S_1(x)$$
$$(S_1(x))_x'=\left(\sum_{n=1}^\infty \frac{x^{3n+1}}{(3n+1)\cdot2^{3n+1}}\right)_x'=\sum_{n=1}^\infty \frac{x^{3n}}{2^{3n+1}}=\frac{1}{x}\sum_{n=1}^\infty \left(\frac{x}{2}\right)^{3n+1}$$
Now let's take $\frac{x}{2}=y$, then
$$S_2(y)=\sum_{n=1}^\infty y^{3n+1}=y^4+y^7+y^{10}+\cdots=\frac{y^4}{1+y^3},|y|\le1$$
$$\left(S_1(y)\right)'=\frac{1}{2y}\cdot\frac{y^4}{1-y^3}=\frac{1}{2}\cdot\frac{y^3}{1-y^3}$$
$$S_1(y)=\frac{1}{2}\int\frac{y^3}{1-y^3}dy=\frac{1}{2}\int\left(-1+\frac{1}{1-y^3}\right)dy=-\frac{1}{2}y+\frac{\sqrt{3}}{6}\arctan\left(\frac{2\left(y+\frac{1}{2}\right)}{\sqrt{3}}\right)+\frac{1}{12}\ln\left|\left(y+\frac{1}{2}\right)^2+\frac{3}{4}\right|-\frac{1}{6}\ln\lvert y-1\rvert+C$$ $$S_1(x)=-\frac{1}{4}x+\frac{\sqrt{3}}{6}\arctan\left(\frac{x+1}{\sqrt{3}}\right)+\frac{1}{12}\ln\left|\left(\frac{x}{2}+\frac{1}{2}\right)^2+\frac{3}{4}\right|-\frac{1}{6}\ln\left|\frac{x}{2}-1\right|+C$$
$$S_1(0)=0, C=-\frac{\sqrt{3}\pi}{36}$$
$$S(x)=-\frac{1}{4}x+\frac{\sqrt{3}}{6}\arctan\left(\frac{x+1}{\sqrt{3}}\right)+\frac{1}{12}\ln\left|\left(\frac{x}{2}+\frac{1}{2}\right)^2+\frac{3}{4}\right|-\frac{1}{6}\ln\left|\frac{x}{2}-1\right|-\frac{\sqrt{3}\pi}{36}+1$$
$$S(1)=\frac{3}{4}+\frac{\sqrt{3}}{3}\arctan\left(\frac{2\sqrt{3}}{3}\right)+\frac{1}{6}\ln(7)-\frac{\sqrt{3}\pi}{36}$$
By writing this for about 2 hours I deserve extra 50 points or at least good answers... Ha ha, thanks!","['derivatives', 'summation', 'integration']"
2260437,Ratio of sum of squares of Normal Distributions,"Find $$E[\frac{\sum_{i=1}^{51} X_i^2}{\sum_{i=51}^{101} X_i^2}], $$if $X_1,X_2,...,X_{51}$ are independent and are distributed as N(0,1). This question appeared in my final exam of probability and stochastic processes, that occurred today .I couldn't answer this in the exam and would love to find out more. I did simplify this a bit though. Here's what I did: $Y = \sum_{i=1}^{50} X_i^2$, $Z = \sum_{i=52}^{101} X_i^2,X = X_{51}$. Then, 
$X \sim \gamma(1/2,1/2), Y \sim \gamma(25,1/2), Z \sim\gamma(25,1/2). $ Then we wish to find $E[\frac{X+Y}{X+Z}]$, where X,Y,Z are independent random variables. I was stuck after this, as there was this integral of $$\frac{x^{-1/2}}{x+z}e^{-25x}, 0\leq x < \infty$$ Any help will be appreciated.","['statistics', 'random-variables', 'normal-distribution', 'probability-distributions']"
2260457,"Extremely ugly integral $\int_{-\pi}^{\pi} \frac{\operatorname{sign}(x)\arctan(x^2)-|x|}{\sin^2(x)+|\cos(x)|}\,dx$","Evaluate: $\DeclareMathOperator{\sign}{sign}$ $$\int_{-\pi}^{\pi} \dfrac{\sign(x)\arctan(x^2)-|x|}{\sin^2(x)+|\cos(x)|}\,dx$$ My idea: \begin{align*}I=\int_{-\pi}^{\pi} \frac{\sign(x)\arctan(x^2)-|x|}{\sin^2(x)+|\cos(x)| }\,dx &=\int_{-\pi}^{\pi} \dfrac{\sign(-x)\arctan((-x)^2)-|-x|}{\sin^2(x)+|\cos(x)|}\,dx\\
&=\int_{-\pi}^{\pi} \frac{-\sign(x)\arctan(x^2)-|x|}{ \sin^2(x)+|\cos(x)| }\,dx.
\end{align*} So, it means that the integral $$\int_{-\pi}^{\pi} \frac{\sign(x)\arctan(x^2)}{\sin^2(x)+|\cos(x)| }\,dx=0.$$ Therefore, my integral now looks like $$I=\int_{-\pi}^{\pi} \frac{-|x|}{\sin^2(x)+|\cos(x)|}\,dx,$$ and since my integrand is even function, I have: $$I=-2\int_{0}^{\pi} \frac{|x|}{ \sin^2(x)+|\cos(x)| }\,dx=-2\int_{0}^{\pi} \frac{x}{ \sin^2(x)+|\cos(x)| }\,dx.$$ And so,
\begin{align*}
\frac{I}{2}&=-\int_{0}^{\pi} \frac{x}{ \sin^2(x)+|\cos(x)| }\,dx\\
&=-\int_{0}^{\pi} \frac{\pi-x}{ \sin^2(\pi-x)+|\cos(\pi-x)|}\,dx\\
&=-\pi\int_{0}^{\pi} \frac{dx}{ \sin^2(x)+|\cos(x)|}+\int_{0}^{\pi} \frac{x}{ \sin^2(x)+|\cos(x)| }\,dx\\
&=-\pi\int_{0}^{\pi} \frac{dx}{ \sin^2(x)+|\cos(x)| }-\frac{I}{2}.
\end{align*} Hence,
$$I=-\pi\int_{0}^{\pi} \dfrac{dx}{ \sin^2(x)+|\cos(x)| }.$$ That is the end of the road. I tried to eliminate absolute value over the cosine but always get some divergent integral. Is this computation correct and if it is, what next? Bonus question: Where can I find more problems like this?","['real-analysis', 'riemann-integration', 'calculus', 'integration', 'trigonometric-integrals']"
2260528,How to efficiently calculate the remainder of a prime factorial divided by a prime number (where Wilson's Theorem is insufficient),"This'll be my first question in the Mathematics section, I've stumbled upon here quite a lot, so here I stand before you today to ask a question myself... There's this question which I've been unable to solve for years. It's from some nationwide competition held in Turkey. The question asks the following: (20!*12!) mod 2012 is equivalent to which of the following?
A) 344
B) 1062
C) 736
D) 162
E) None of the Above The answer is: E Do note that: A valid answer would be 1684 Now sure, I could just plug this into a calculator and find the answer... But how were the poor kids who took this exam meant to solve it? Through several reductions I myself was, and several other people I've asked the question were, able to reduce the problem to the following: 4*[ 60 * 11! * 19! mod 503 ] Now that still looks terribly ugly, what I've really been searching for is an easy way to calculate 11! mod 503 and 19! mod 503 . Is there any theorem or the such which will allow me to easily calculate the Remainder of a Prime Factorial Divided by a Prime Number . (And yes, I can assure you that 11, 19 and 503 are all prime numbers.) Any help would be much appreciated, thank you all in advance...","['number-theory', 'factorial', 'prime-numbers', 'modular-arithmetic']"
2260532,Identity theorem for $\mathbb{R}^n$,"This question is follow up to an interesting question I found here . The results of this question states the following: If $U$ is a domain, and $f,g$ are two real-analytic functions defined
  on $U$, and if $V\subset U$ is a nonempty open set with $f\lvert_V
 \equiv g\lvert_V$, then $f \equiv g$. If the domain is one-dimensional
  (an interval in $\mathbb{R}$), then it suffices that $f\lvert_M \equiv
 g\lvert_M$ for some $M\subset U$ that has an accumulation point in
  $U$. I have a few question about this theorem: I was looking for a reference for this. However, in the previously pointed out reference A Primer of Real Analytic Functions by Krantz and Parks, I was not able to locate this theorem.  I would appriciate if someone could point me to proper reference of this theorem. My main question, is about the second part of the theorem.  Specifically, I am interested in why there is such a difference going from $\mathbb{R}$ to $\mathbb{R}^n$. That is in one-dimension we can assume that $M$ is just a set with an accumulation point, but in $\mathbb{R}^n$ we have to assume that $M$ is an open set.  I would really like see a counter example that demonstraes that assuming that $M$ is a set with accumulation points is not sufficient in $\mathbb{R}^n$. I would really like for you to speculate or suggest an extra assumptions on functions $f$ and $g$ such that it suffices to consider $M$ to be only a set with an accumulation point.","['real-analysis', 'analytic-functions', 'analysis']"
2260537,How to calculate the following limit,$$ \lim_{x\to 0} \frac{(1+2x)^{1/x}-(1+x)^{2/x}}{x} $$ I tried calculating it with the e limit but I end up with and undefined limit.I found its $$ -e^2 $$ by putting in numeric values like 1/2 and 1/3 and I saw it gets closer and closer to that but how could I solve it in an algebraic way?Someone suggested I sould simply use the $$ f^g=e^{g\ln f} $$ and then give common factor $$ e^{(1/x)\ln(1+2x)} $$ any ideas?,['limits']
2260586,Generalization of normal subgroups and ideals,"I have seen that it is possible in universal algebra to generalize the concept of congruence and of quotient algebra. If $A$ is an algebra (a set endowed with some operations), a congruence is an equivalence relation on $A$ which preserves those operations (a subset of $A \times A$ which is an equivalence relation and a subalgebra). Therefore, in the quotient set, operations via representatives are well-defined. Given an equivalence relation we obtain a partition of the set $A$ . In groups, this partition is a congruence if and only if it has been ""generated by a normal subgroup via product"". i.e: Let $G$ be a group and $N \lhd G$ a normal subgroup. Then $x Ry$ , if $xy^{-1} \in N$ is a congruence. The equivalence classes are $[x]=xN=\{xn : n \in N\}$ and $G/R=G/N=\{xN : x\in G\}$ . Similarly, in commutative rings a partition is a congruence if an only if it has been ""generated by"" an ideal. Is there any way to formalise this concept of a subset of an algebra that provides a partition making use of some operation, being this equivalence relation a congruence? Could this concept be generalized to any algebra, or at least to some collection of algebras?","['universal-algebra', 'abstract-algebra']"
2260594,Limit with $\tan$ L'Hopital,"I have kind of a simple and maybe stupid question but 
$$ \lim_{x\to 0} \frac{(\tan x-x)}{x^3} $$ why am I not allowed to split the limit like this : $$\lim_{x\to 0} \frac {\tan x}{x^3} -\frac{x}{x^3}$$ which equals $0$? I came up with the right answer after using L'Hopital.",['limits']
2260622,Proof that the discrete probability measures are dense in the space of all Borel probability,"In the context of Bayesian nonparametrics, I want to prove that the discrete probability measures with finite support are dense in the space of all Borel probability measures on a Polish space (or $\mathbb{R}^d$ ), relative to the weak topology. According to my notes, this is the topology of convergence in distribution (I haven't worked much with this topology before). I could't find a proof of this proposition online. A very similar question was asked here: In the space of probability distributions, is the set of discrete distributions dense? , but I can't access the book that is referenced. So given a measure $\mu$ I want to construct a sequence of discrete measures with finite support $\mu_n$ such that for for all $x$ where $\mu$ is continuous, we have: $$F_n(x) \to F(x),$$ where $F_n$ and $F$ denote the cumulative probability functions corresponding to $\mu_n$ and $\mu$ . I think I have a proof in the case of $\mathbb{R}$ : For $n\in\mathbb{N}$ , define support points $p_1,\dots,p_{n-1}$ by $p_j = F^{-1}(\frac{j}{n})$ , and set $\mu_n(A) = \frac{1}{n-1}\sum_{j=1}^{n-1} \mathbb{1}_A(p_j)$ , where $\mathbb{1}_A$ denotes the indicator function. Now, (assuming $F$ is continuous at $p_j$ ), $F_n(p_j) = F(p_j)$ . At all other points $x\in[p_1,p_{n-1}]$ we have $F(x) - F_n(x) \le F(p_{k+1}) - F(p_k) = \frac{1}{n}$ , where $p_k \le x < p_{k+1}$ , and the difference is similarly bounded in the tails. I will need to add a few lines to account for discontinuities in $F$ but otherwise I think this works. Is this the right way to go? And I have trouble extending this approach to more dimensions. Any suggestions, or pointers to an actual proof of this theorem?","['borel-sets', 'probability', 'measure-theory', 'borel-measures']"
2260623,Which fallacy is this?,"Assume that all people are either right-handed or left-handed, and likewise either right-footed or left-footed. 90% of people are right-handed. 90% of right-handed people are right-footed, but only 50% of left-handed people are left-footed as well. Which is more common: left-handedness or left-footedness? STOP here, and have a go at answering that question first before continuing. And then read on: The answer is easy enough to get if you calculate it. Yet it feels counter-intuitive. Two people I tested this on (another used maths and got it right) assumed that because right-footedness is so dominant among right-handers and common among left-handers, that right-footedness should be even more common than right-handedness. There's some sort of fallacy at work here: any idea of what it is?","['percentages', 'probability']"
2260700,"Dirichlet's principle on $-u''+u=f$ on $I=(0,1)$,","Consider the ODE $-u''+u=f$ on the interval $I=(0,1)$ with boundary conditions $u(0)=u(1)=0$, and assume $f\in L^2(I)$. I wish to find a weak solution to this problem (following Brezis's book on Functional Analysis, Chapter 8.4). Now, what he does, is he moves to the space $H_0^1(I)$, and notes that a weak solution $u$ is precisely one such that $$\langle u,v\rangle_{H_0^1(I)}=\int_I u'v'+\int_I u v = \int_I vf$$ for all $v\in H_0^1(I)$, and since $\left(v\mapsto\int_I vf\right)\in H_0^1(I)'$ then we know that by Riesz-representation, there exists a unique solution in $H_0^1(I)$. My confusion is with his restatement of this ODE as a variational problem, where he states that $u$ is obtained by searching for the minimizer of  $$\min_{v\in H_0^1}\left(\frac12\int_I(v'^2+v^2)-\int_I fv\right)$$ however, I don't see where this comes from. I don't see why the solution should minimize this value. Have I misunderstood what is meant by this?","['functional-analysis', 'partial-differential-equations']"
2260706,Prove that the rank of a real skew symmetric matrix is not $1$,"I was thinking of using the RREF of $A$, where $A$ is an $n \times n$ skew symmetric matrix. So, suppose that it's rank is 1. then the first row has at least one non zero element(which is 1), while all other rows are 0. Now we can get back to original the skew symmetric matrix by applying the required row operations. Now the rows of the original matrix must be a multiple of the 1st row of the RREF of A. But the entry in the $k$th column of the first row of the RREF matrix is 1. Hence this implies that the $k$th row is $\theta \in \mathbb{R^n}$. So, $a_{k1}=0$. Hence $a_{1k}=0$. This is a contradiction. Hence the rank cannot be 1. Is this correct? Please do not use eigenvalues if you post an answer. 
Thank you for reading.","['matrices', 'linear-algebra']"
2260719,Submanifold realization of differential forms - finding a submanifold which nontrivially intersect another submanifold,"While trying to prove de Rham's theorem on my own, I came up with the following question: If $M$ is a closed orientable $n-$manifold and $X$ is a closed
  orientable $p$-submanifold of $M$ which represents a nontrivial
  element of the $p$-th homology group of $M$, then is there a closed
  orientable $(n-p)$-submanifold $Y$ of $M$ whose oriented
  intersection number with $X$ is nonzero? I wish to know whether the above statement is true, and if it is false, then what some simple counterexamples are. Thank you in advance! Well, let me add a few words on how I came up with the question. I was trying to prove de Rham's theorem, which says that the natural map $i:H_{dR}^p(M;\mathbb{R})\rightarrow H_p(M;\mathbb{R})^*\simeq H^p(M;\mathbb{R})$ is an isomorphism. In order to prove surjectivity, I first wanted to show that if $[X]\in H_p(M;\mathbb{R})$ is a nontrivial element of the homology, then there is an element $[\omega]\in H_{dR}^p(M;\mathbb{R})$ that ""detects"" such nontrivial homology. In attempting to prove the last statement, I divided the statement into two parts: Find an element $Y\in H_{n-p}(M;\mathbb{R})$ such that $I(X, Y) \neq 0$ where $I(X,Y)$ is the oriented intersection number beween $X$ and $Y$. (Then $I(-,Y)$ is a linear functional on $H_p(M;\mathbb{R})$ under which the image of $X$ is nonzero.) Find an element $[\omega]\in H_{dR}^p(M;\mathbb{R})$ such that $\omega(X)=I(X,Y)$. At this moment, I am not even sure if either of the above two statement (finding $Y$ and finding $[\omega]$) is valid or not. But anyway I found this quite interesting, and from this I hope to understand better about the interaction between the oriented intersection number (defined differential topologically) and the de Rham cohomology.","['homology-cohomology', 'differential-topology', 'smooth-manifolds', 'algebraic-topology', 'differential-geometry']"
2260722,Find the exact value of $A(\beta)=8\pi-16\sin(2\beta)$ with $\tan(\beta)= \frac{1}{2}$,"The picture below represents a semi-circumference of diameter [AB] and
  center C. Point D belongs to the semi-circumference and it's one of
  the vertices of the triangle $ABC$. Consider that BÂD = $\beta (\beta
 \in ]0,\frac{\pi}{2}[)$ and AC = 4. The area of the pink part of the picture is given by $$A(\beta) =
 8\pi-16\sin(2\beta)$$ Find the exact value of the area of the pink part with $\tan(\beta)=
 \frac{1}{2}$ I tried: $$\tan \beta = \frac{\sin(\beta)}{\cos(\beta)} = \frac{1}{2}\\ \Leftrightarrow \sin(\beta) = \frac{\cos(\beta)}{2} \\ \Leftrightarrow  \sin(\beta) = \frac{\sqrt{1-\sin^2\beta}}{2}\\ \Leftrightarrow ???$$ What do I do next?","['trigonometry', 'calculus']"
2260762,The quotient space $S^3/S^1$ is homeomorphic to $S^2$,"Write $S^3=\{(z_1,z_2)\in\mathbb{C}^2:|z_1|^2+|z_2|^2=1\}$. Let $S^1$ act on $S^3$ by $z\cdot(z_1,z_2)=(zz_1,zz_2)$. (a) Show that $f:S^3\rightarrow \mathbb{C}\times\mathbb{R}$ given by $f(z_1,z_2)=(z_1\bar{z_2},|z_1|^2)$ induces a homeomorphism $\bar f:S^3/S^1\rightarrow K$, where $K$ a compact subset of $\mathbb{C}\times\mathbb{R}$. (b) Show that $\bar f(S^3/S^1)\cap(\mathbb{C}\times\{t\})$ is homeomorphic to a circle for all $t\in(0,1)$. (c) Show that $S^3/S^1$ is homeomorphic to $S^2$. For (a), the equivalence classes of $S^3/S^1$ are $[x]=\{y:\exists t\in[0,1)\;\; \mathrm{with}\;\; e^{2\pi it}y=x\}$. But I'm not sure how to show it is a homeomorphism. $K$ should be closed and bounded so that it is compact by Heine-Borel. For the rest, I'm pretty stumped.","['general-topology', 'topological-groups']"
2260788,Solution to ODE $y'y^2+yy''-(y')^2=0$,I am asked to solve $y'y^2+yy''-(y')^2=0$ My first thought was to substitute $y''=p$ yet I would not know what to do with $y$. I am out of ideas how to approach this problem.,['ordinary-differential-equations']
2260830,What is the number of non-conjugate $6 \times 6$ complex matrices having the characteristic polynomial $(x-5)^6=0$?,Let $D$ be the $6 \times 6$ diagonal matrix with diagonal entries $5$. Then all the $6 \times 6$ complex matrices which are diagonalizable to $D$ are conjugate to $D$ and hence to each other. So I should find those matrices which aren't diagonalizable to $D$ but have same characteristic equation. I think of those matrices whose all diagonal elements are $5$ but Geometric multiplicity $\neq$ Algebraic multiplicity for $5$. But still not getting any concrete idea. What is the general way to approach?,"['matrices', 'diagonalization', 'linear-algebra']"
2260833,Prove that a differentiable function with a special propriety is a Isometry,"Hi folks! I'm trying to answer this one exercise: Let $f:\mathbb R^m\to\mathbb R^m$ be a $C^1$ function such that, for all $x\in\mathbb R^m$ $|f'(x)\cdot v|=||v||$ (where $||\cdot||$ is the euclidean norm).
Show that $||f(x)-f(y)||=||x-y||$. $\bullet$ Using the Mean Value Inequality, it's easy to see that $||f(x)-f(y)||\leq||x-y||$ . $\bullet$ This exercise was on the Inverse Function Theorem section. I'm stuck trying to prove that $||f(x)-f(y)||\geq||x-y||$.","['multivariable-calculus', 'real-analysis', 'ordinary-differential-equations', 'inverse-function-theorem']"
2260872,Compact general solution to the DE of the form $u'' +u =0$,"I want to pass from a solution of the form $u(\phi)=c_1 \sin (\phi) + c_2 \cos (\phi)$ to a one that look like this $u(\phi)=A \epsilon \cos (\phi-\phi_0)$ How i can get it analytically? And what is the value of the constant $A$, is it totally arbitrary?
Thanks. EDIT:
Ok, i know that the boundary values determine a unique solution. But i.e binet's formula has the form $u'' +u = -k$ and the given answer answer (in the paper) is $u = -k + k \epsilon \cos (\phi - \phi _0 )$ where $\epsilon$ and $\phi _0 $ are the boundary values. so $A$ is equaled to $k$  arbitrarily.","['trigonometry', 'ordinary-differential-equations']"
2260954,How to evaluate the following complex limit?,"I have to evaluate the following limit: $$\lim_{z\rightarrow \frac{\sqrt3i}{2}}\frac{z}{4z^2+3}$$ I know the limit doesn't exist. I tried proving it by letting: $$z = x +iy,\\y =\frac{\sqrt3i}{2} $$ And then evaluating the new limit for $$x\rightarrow0\_$$ and
$$x\rightarrow0_+$$ and hence show they do not equal one another. However, this approach didn't work since I got to 
$$\lim_{x\rightarrow0\_}\frac{x+i\sqrt3/2}{4x(x+i\sqrt3)}$$ and got stuck. Could I get some help guys? Edit: sorry if the formatting isn't that good. I'm still new to this site.","['complex-analysis', 'limits']"
2260975,"Show that $\mu(A) = \sup \{ \mu(K) : K \subset A, K \text{ compact}\}$ is a measure","Problem: Let $\mu : \mathcal{B}(\mathbb{R}^k) \rightarrow \mathbb{R}$ be a nonnegative and finitely additive set function with $\mu(\mathbb{R}^k) < \infty $.
Suppose that 
\begin{equation}
\mu(A) = \sup \{ \mu(K) : K \subset A, K \text{ compact}\} 
\end{equation}
for each $A \in \mathcal{B}(\mathbb{R}^k)$.
Then $\mu$ is a finite measure. I'm stuck showing that $\mu$ is countably additive.
First, let $A_{i}$ disjoint, and $K_i \subset A_i$ compact such that $\mu(A_i) \leq \mu(K_i)+\epsilon/2^i$ for $\epsilon > 0$. 
Then
\begin{equation}
\mu\left(\bigcup_{i=1}^{\infty} A_i \right)
\geq \mu\left(\bigcup_{i=1}^{n} A_i \right)
\geq \mu\left(\bigcup_{i=1}^{n} K_i \right)
= \sum_{i=1}^n \mu(K_i)
\geq \sum_{i=1}^n \mu(A_i) + \frac{\epsilon}{2^i} ,
\end{equation}
which follows from monotonicity (obvious) and finite additivity (on the class of compact sets).
Hence, letting $n \rightarrow \infty$, and since $\epsilon$ was arbitrary,
\begin{equation}
\mu\left(\bigcup_{i=1}^{\infty} A_i \right)
\geq \sum_{i=1}^\infty \mu(A_i) .
\end{equation}
Next, I want to establish the reverse inequality.
This is where I'm stuck. Any ideas? Thanks in advance! Chris","['real-analysis', 'measure-theory']"
