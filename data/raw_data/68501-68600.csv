question_id,title,body,tags
823770,"How to arrange $e^3,3^e,e^{\pi},\pi^e,3^{\pi},\pi^3$ in the increasing order?","For these six numbers, $e^3,3^e,e^{\pi},\pi^e,3^{\pi},\pi^3$, how to arrange them in the increasing order? This problem is taken from the today test: National Higher Education Entrance Examination. I think we can consider
$$f(x)=\dfrac{\ln{x}}{x}$$ or perhaps other methods, so I am looking forward to seeing other methods to solve this problem. Thank you.","['inequality', 'algebra-precalculus', 'real-analysis']"
823773,Ramanujan's formula for $\sum_{n = 0}^{\infty}p(7n + 5)q^{n}$,"Analyzing the function $$f(-q) = (1 - q)(1 - q^{2})(1 - q^{3})\cdots$$ by replacing $q$ with $q^{1/5}$, Ramanujan is able to calculate the sum $$\sum_{n = 0}^{\infty}p(n)q^{n/5} = \frac{1}{f(-q^{1/5})}$$ where $p(n)$ is the number of partitions of $n$. Further, on equating coefficients of $q^{4/5}$ on both sides, he gets the beautiful result $$\sum_{n = 0}^{\infty}p(5n + 4)q^{n} = 5\frac{\{(1 - q^{5})(1 - q^{10})(1 - q^{15})\cdots\}^{5}}{\{(1 - q)(1 - q^{2})(1 - q^{3})\cdots\}^{6}}$$ which can be used to show $$\begin{aligned}p(5n + 4) &\equiv 0\pmod{5}\\p(25n + 24) &\equiv 0\pmod{25}\end{aligned}$$ (this is shown in detail in my blog post ). Next Ramanujan mentions that the same technique can be applied by analyzing $$\sum_{n = 0}^{\infty}p(n)q^{n/7} = \frac{1}{f(-q^{1/7})}$$ and equating the coefficient of $q^{5/7},$ to get another beautiful identity $$\sum_{n = 0}^{\infty}p(7n + 5)q^{n} = 7\frac{\{(1 - q^{7})(1 - q^{14})(1 - q^{21})\cdots\}^{3}}{\{(1 - q)(1 - q^{2})(1 - q^{3})\cdots\}^{4}} + 49q\frac{\{(1 - q^{7})(1 - q^{14})(1 - q^{21})\cdots\}^{7}}{\{(1 - q)(1 - q^{2})(1 - q^{3})\cdots\}^{8}}$$ This can be used to prove the congruences $$\begin{aligned}p(7n + 5) &\equiv 0\pmod{7}\\p(49n + 47) &\equiv 0\pmod{49}\end{aligned}$$ Unfortunately, in his characteristic style, Ramanujan omits the proof for the case of $f(-q^{1/7})$. I tried to use the approach mentioned by Ramanujan for $f(-q^{1/7})$ and was led to rather cumbersome expressions (multiplying three almost similar polynomials of 6 degrees each with symbolic coefficients). Needless to say, none of the online symbolic packages like wolfram alpha or sympy handle such complex symbolic manipulation. I guess that Ramanujan must have somehow simplified these calculations and thereby obtained a very simple-looking result. Does anyone have any references for a simpler approach to establishing the identity concerning $\sum p(7n + 5)q^{n}$? Update : To add more details, we use Euler's pentagonal formula $$f(-q^{1/7}) = \sum_{n = -\infty}^{\infty}(-1)^{n}(q^{1/7})^{n(3n + 1)/2}$$ The numbers $n(3n + 1)/2$ fall into one of the following four classes modulo $7$ as $n$ takes integer values: $$\begin{aligned}n(3n + 1)/2\,\,&\equiv 0\pmod{7}\text{ if } n &\equiv 0, 2\pmod{7}\\
&\equiv 1\pmod{7}\text{ if } n &\equiv 3, 6\pmod{7}\\
&\equiv 2\pmod{7}\text{ if } n &\equiv 1\pmod{7}\\
&\equiv 5\pmod{7}\text{ if } n &\equiv 4, 5\pmod{7}\end{aligned}$$ and hence, if we put $r = q^{1/7}$, then we see that  $$P = f(-r) = A_{0} + A_{1}r + A_{2}r^{2} + A_{3}r^{5}$$ where $A_{i}$ are power series in $q$ and do not involve any fractional powers of $q$. Further, if we replace $r = q^{1/7}$ by $r\zeta^{i}$ for $i = 1, 2, \ldots, 6$, where $\zeta$ is a primitive $7^{\text{th}}$ root of unity, then the product $Q = \prod_{i = 0}^{6}f(-r\zeta^{i})$ can be expressed without any fractional powers of $q$. In fact it is easy to show that $$Q = \prod_{i = 0}^{6}f(-r\zeta^{i}) = \frac{f^{8}(-q)}{f(-q^{7})}$$ The idea is then to find $Q/P = \prod_{i = 1}^{6}f(-r\zeta^{i})$, and we try to find the coefficient of $r^{5}$ in $Q/P$. Suppose that the coefficient is $R$. Then we have $$\sum_{n = 0}^{\infty}p(n)q^{n/7} = 1/P = (1/Q)(Q/P)$$ and hence $$\sum_{n = 0}^{\infty}p(7n + 5)q^{n} = R/Q$$ Further Update : I recently found a paper by Oddmund Kolberg titled ""Some Identities Involving the Partition Function"" which provides an elementary proof of Ramanujan's identity for $p(7n + 5)$. The same proof has been presented in my blog post .",['sequences-and-series']
823787,Convegence of regularized sequence in $L^2$,"Let $(\rho_n)_{n \geq 0}$ be a standard regularizing sequence on $\mathbb R$. Let $P$ be a probability measure on $\mathbb R$ such that the sequence $(P*\rho_n)_{n \geq 0}$ is bounded in $L^2$. Then, does the probability measure $P$ admit a density in $ L^2$? i.e., is there a $p \in L^2(\mathbb R)$ satisfying
\begin{align}
P(dx) = p (x) dx?
\end{align}
My understanding is that, due to the boundedness in $L^2$, the sequence $(P*\rho_n)_{n \geq 0}$ contains a subsequence, which converges weakly to a limit in $L^2$. But, how do we know that the density $p$ is the limit?","['probability-theory', 'weak-convergence', 'probability-distributions', 'functional-analysis']"
823790,Bound of direct sum of operators,"Let $X$ be a Banach space and $U,V$ complementary subspaces. Let $A: U \to U, B: V \to V$ be continuous and let $T(x) = (A \oplus B)(u \oplus v)= A(u) \oplus B(v)$. Does it hold that $\|T\| \le \|A \| + \|B\|$?",['functional-analysis']
823816,Is $ \sum\limits_{n=1}^\infty \frac{|\sin n|^n}n$ convergent？,"Is the series $$ \sum_{n=1}^\infty \frac{|\sin n|^n}n\tag{1}$$ convergent？ If one want to use Abel's test, is $$ \sum_{n=1}^\infty |\sin n|^n\tag{2}$$ convergent？ Thank you very much","['sequences-and-series', 'calculus', 'convergence-divergence', 'trigonometry', 'real-analysis']"
823817,Monodromy representation of Airy equation,"Let $K=\Bbb{C}(z)$ with the usual derivation and consider the Airy dierential equation
$y^{(2)}-zy$=0. How to determine the monodromy representration? Airy equation is not Fuchsian diferential equation. i am new to monodromy. I have recently started learning monodromy representation of a differential equation from the book 'Algebraic groups and differential galois theory' by Crespo and Hajto. The monodromy representation is in Chapter 7. It will be very helpful someone determines the monodromy representation of the airy equation and describe the steps a little bit so that i can understand it. Can someone explain to me the concept of monodromy representation of a differential equation by analytic continuation of solutions?","['ordinary-differential-equations', 'differential-geometry', 'covering-spaces', 'algebraic-topology', 'complex-analysis']"
823819,If $\alpha = \frac{2\pi}{7}$ then the find the value of $\tan\alpha .\tan2\alpha +\tan2\alpha \tan4\alpha +\tan4\alpha \tan\alpha.$,If $\alpha = \frac{2\pi}{7}$ then the find the value of $\tan\alpha .\tan2\alpha +\tan2\alpha \tan4\alpha +\tan4\alpha \tan\alpha$ My 1st  approach : $\tan(\alpha +2\alpha +4\alpha) = \frac{\tan\alpha +\tan2\alpha +\tan4\alpha -\tan\alpha \tan2\alpha -\tan2\alpha \tan4\alpha -\tan4\alpha \tan\alpha}{1-(\tan\alpha \tan2\alpha +\tan2\alpha \tan4\alpha +\tan\alpha \tan4\alpha)} $ $\Rightarrow 0 = \frac{\tan\alpha +\tan2\alpha +\tan4\alpha -\tan\alpha \tan2\alpha -\tan2\alpha \tan4\alpha -\tan4\alpha \tan\alpha}{1-(\tan\alpha \tan2\alpha +\tan2\alpha \tan4\alpha +\tan\alpha \tan4\alpha)} $ which doesn't give me any solution. My IInd approach : U\sing Euler substitution : \since $\cos\theta +i\sin\theta = e^{i\theta} $.....(i) and $\cos\theta -i\sin\theta =e^{-i\sin\theta}$....(ii) Adding (i) and (ii) we get $\cos\theta =\frac{e^{i\theta} +e^{-i\theta}}{2}$  and subtracting (i) and (ii) we get $\sin\theta =\frac{e^{i\theta} -e^{-i\theta}}{2}$ By u\sing this we can write : $$\tan\alpha .\tan2\alpha +\tan2\alpha \tan4\alpha +\tan4\alpha \tan\alpha$$ as $$\frac{1}{4}\left[ (e^{\frac{i2\pi}{7}} -e^{\frac{-i2\pi}{7}}) (e^{\frac{i4\pi}{7}} -e^{\frac{-i4\pi}{7}}) + (e^{\frac{i4\pi}{7}} -e^{\frac{-i4\pi}{7}})(e^{\frac{i8\pi}{7}} -e^{\frac{-i8\pi}{7}}) + (e^{\frac{i8\pi}{7}} -e^{\frac{-i8\pi}{7}}) (e^{\frac{i\pi}{7}} -e^{\frac{-i\pi}{7}})\right]$$ $$\large= e^{i\frac{6\pi}{7}}-e^{\frac{i2\pi}{7}}-e^{\frac{-i2\pi}{7}} +e^{\frac{-i6\pi}{7}} +e^{\frac{i3\pi}{7}}-e^{\frac{-i5\pi}{7}}-e^{\frac{i5\pi}{7}} +e^{\frac{-3\pi}{7}} +e^0 -e^{\frac{i2\pi}{7}} -e^{\frac{-i2\pi}{7}}+e^0$$ Can anybody please suggest whether this is my correct approach or not. please guide further... Thanks.,"['trigonometry', 'algebra-precalculus']"
823822,Prove that $\int_{0}^{2\pi}\ln \left(\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}\right)dx = 0$,"Prove that $$
I=\int_{0}^{2\pi}\ln \left(\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}\right)\;dx = 0
$$ My Attempt: $$
\begin{align}
I &= \int_{0}^{2\pi}\ln(1+\sin x)^{1+\cos x}\;dx-\int_{0}^{2\pi}\ln(1+\cos x)\;dx\\
&=\int_{0}^{2\pi}(1+\cos x)\cdot \ln(1+\sin x)\;dx-\int_{0}^{2\pi}\ln(1+\cos x)\;dx\\
&= \int_{0}^{2\pi}(1+\cos x)\cdot \ln(1+\sin x)\;dx - 2\int_{0}^{\pi}\ln(1+\cos x)\;dx
\end{align}
$$ How can I complete the solution from this point?","['definite-integrals', 'calculus', 'integration']"
823835,"Let $G$ be a group and $a,b,c \in G$. Given that $abc$ and $cba$ are conjugated, prove that $G$ is abelian.","Let $G$ be a group and $a,b,c \in G$. Given that $abc$ and $cba$ are conjugated, prove that $G$ is abelian. In other words, if for any $a,b,c \in G$ there is a $g \in G$ so that $a b c = g c b a g^{-1}$, prove $G$ is abelian.","['group-theory', 'abstract-algebra', 'abelian-groups']"
823858,$ a \cos A + b \cos B + c \cos C = \dfrac{a+b+c}2 $ $\implies$ the triangle is equilateral?,"If in a triangle $ a \cos A + b \cos B + c \cos C = \dfrac{a+b+c}2 $ , then is the triangle equilateral ?",['trigonometry']
823875,"Subgroups of $(\mathbb Z_n,+)$","The problem is to define all subgroups of $(\mathbb Z_n,+), n \in \mathbb N$. My guess is if n is prime number, then there is only trivial subgroups. If n is not prime, then I can factorize it, and every prime divisor will generate it's own subgroup in $(\mathbb Z_n,+)$. That means that $(\mathbb Z_n,+) \cong (\mathbb Z_h,+) \times (\mathbb Z_k,+) \times \dots$ , $h,k \in \mathbb N$ are the prime factors of $n$.
The problem is that I don't know how to prove it. It's pretty easy to show that, for example, in $(\mathbb Z_6,+)$ $ [2]_6$ and $[3]_6$ generate their own subgroups and $[1]_6$ generate entire $(\mathbb Z_6,+)$, but I don't know how to show that $[5]_6$ do the same, except by showing it all: $[5]^2_6 = [4]_6$ and so on.","['finite-groups', 'group-theory', 'abstract-algebra']"
823910,Rank of the differential,"Let $f:\mathbb R^n \to \mathbb R^n$ such that $f$ maps roots of a polynomial to its coefficients. Meaning: if $(x-x_1)(x-x_2)...(x-x_n)=x^n+a_1x^{n-1}+a_2x^{n-2}+...+a_n$ then $f\begin{pmatrix} x_1 \\x_2\\x_3\\ \vdots \\x_n \end{pmatrix} =\begin{pmatrix} a_1\\a_2\\a_3 \\ \vdots \\a_n \end{pmatrix}$ Show that the rank of the differential of $f$ is equal to the number of different roots.
$rank(Df)=cardinal\{x_1,...x_n\}$","['multivariable-calculus', 'matrix-rank', 'calculus', 'linear-algebra', 'derivatives']"
823913,how big is the smallest inaccessible cardinal?,"I know a cardinal is inaccessible if it is uncountable,regular,strong limit.And we cannot prove its existence in ZFC.but by axiom of choice,every infinite cardinal is an aleph.so can you write the smallest inaccessible cardinal in terms of aleph?","['large-cardinals', 'elementary-set-theory']"
823923,Compute $\int_0^1 \frac{\arcsin(x)}{x}dx$,"$$\int_0^1 \frac{\arcsin(x)}{x}dx$$ This is a proposed for a Calculus II exam, and I have absolutely no idea how to solve it. Tried using Frullani or Lobachevsky integrals, or beta and gamma functions, but I can't even find a way to start it. Wolfram Alpha gives a kilometric solution, but I know that cannot be the only answer. Any help appreciated!","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'trigonometry']"
823957,Why is the algebraic closure of a finite field countable?,"An algebraic closure of a field K is an algebraic extension of K that is algebraically closed. It is one of many closures in mathematics.
But why is it a countable set?","['finite-fields', 'elementary-set-theory', 'field-theory']"
823958,Weak convergence of continuous functions,"Let $X$ be an LCH space and $C_0(X)$ the set of continuous vanishing functions on $X$. If $C_0(X)$ is given the structure of a Banach space with the sup-norm, then its weak topology is given by the set of Radon measures $M(X)$ of finite total variation. One has $f_\alpha \to f$ if and only if $\int f_\alpha ~d\mu \to \int f~d\mu$ for all $\mu \in M(X)$. My question: Is there a characterization for weak convergence in $C_0(X)$? Weak convergence is at least as strong as pointwise convergence (because of the Dirac measures). I have an example showing that it is not the same as pointwise convergence in general.","['measure-theory', 'functional-analysis']"
823963,Prove that this space is not Banach,"Let $\Omega\subset\mathbb{R}^n$ be an open, bounded set with boundary $\partial\Omega$ of class $C^1$.
$$\mathcal{A}:=\{u\in C^2(\bar\Omega):u=0\text{ on }\partial\Omega \}$$
endowed with the scalar product
$$(u,v)_{\mathcal{A}}:=\int_{\Omega}(\nabla u,\nabla v)_{\mathbb{R}^n}\,dx.$$
I have to prove that $\mathcal{A}$ equipped with the induced norm is a normed space, but it is not a Banach space. I can't find a proper counterexample. Any help?","['hilbert-spaces', 'functional-analysis', 'banach-spaces', 'analysis']"
823966,Smallest integer $k$ so that no Sudoku grid has exactly $k$ solutions,"Inspired by this question ,
consider hints on a Sudoku board. A regular puzzle has a unique solution.
It is clear that there are puzzles with 2 or 3 solutions, and therefore, I guess, puzzles with say 4, and 6 solutions. Now, what is the smallest integer $k$ such that there is no set of Sudoku clues resulting in exactly $k$ solutions?","['puzzle', 'combinatorics']"
823968,Definition of a principal ultrafilter,"I just started trying to read through Lectures on the Hyperreals: An Introduction to Nonstandard Analysis, by Robert Goldblatt. I'm near the beginning in the section on filters.  He's defined an ultrafilter as follows: Consider a non-empty set $I$ and it's Power Set $\mathcal P(I)$.  An ultrafilter $\mathcal F$ on $I$. contains all supersets of its elements as well as all finite intersections.  Also $A\in$ $\mathcal F$ iff $A^c\notin\mathcal F$.  Where $A^c = I-A$ and $A\in \mathcal P(I)$. He then goes on to give some examples of filters, including 2 that are examples of ""principal ultrafilters"", however he doesn't actually define principal ultrafilters. The first example would be $\mathcal F^i=\{A\subseteq I:i \in A \}$. The second example is similar, but for a set, rather than a single element.  $\mathcal F^\mathcal H=\{A\subseteq I:A \supseteq B \}$ and $B\ \in \mathcal P(I)$. I'm unsure of the actual definition of a principal ultrafilter.  It appears that it's a filter generated by an object (via supersets), where that object is either an element of the universe or an element of the power set of the universe.  Along with satisfying the requirements of being an ultrafilter.  Is that correct?","['filters', 'elementary-set-theory', 'definition']"
823979,Is this integral with sine and cosine such a challenge?,"...or maybe I just don't know some specific trick with trigonometric functions? Well, anyway, here it is: 
$$\int{\sin^6{x}\cos^4{x}\, dx}$$ I'm bored with it, because I get 9 integrals out of 1 and the whole thing frustrates me as hell. 
So, is there a simpler way of integrating this or should I just make up my mind to it and integrate and integrate and integrate and integrate...untill the end comes? By the way, here's the answer:
$$ \frac{3 x}{256}-\frac{1}{512} \sin (2 x)-\frac{1}{256} \sin (4 x)+\frac{\sin (6 x)}{1024}+\frac{\sin (8 x)}{2048}-\frac{\sin (10 x)}{5120}$$","['trigonometry', 'integration']"
824000,Does $f(f(x)) = x \Rightarrow f$ is bijective apply?,"As far as I remember a reverse function for some function $f$ exists iff an inverse function exists. Can I therefore follow from $f(f(x)) = x$ ($f$ is its own inverse function) for some function $f$ that it is bijective without proving it is injective and surjective? Example: $f : \mathbb{R} \rightarrow \mathbb{R},\ f(x) = 5 - x$",['functions']
824027,Non-brute-force proof of parabola tangent property,"I'm working through a classic Calculus book (Morris Kline), and one of the problems is: Prove that the foot of the perpendicular from the focus to any tangent
  of a parabola lies on the tangent to the vertex. Basically, it's saying that if the parabola $y=x^2$ has a tangent line T at point $P$, and we draw a line $L$ perpendicular to $T$ that goes through the focus $F$, then $T$ meets $L$ at a point where $y=0$. I managed to prove this by: Calculating the equation of $T$ (based on slope of $y'$ and point $P$) Calculating the equation of $L$ (based on slope of $\frac{-1}{y'}$ and point $F$) Putting $y=0$ in both equations and solving for $x$ Observe that they both have the same $x$ at $y=0$ and therefore they meet on the $x$ axis. HOWEVER, this seems like a very brute-force approach.  It's almost like I cheated or I simulated it on the computer with $1000$ points and determined that it is so.  I don't really understand WHY these $2$ lines must meet in this manner. Is there any sort of geometric or intuitive proof?","['geometry', 'calculus']"
824047,Recommend books for learning math from elementary school?,"I've learned math long time ago, but I hardly remember anything.
I really want to relearn by reading  good books, from the ground up.
Workbooks didn't really help. Other posts recommend different books. So a list of best books feels helpful from Pre-algebra to calculus and beyond. Would you be so kind to add which others you recommend. English is not my native language; please excuse typing errors. Children The Number Devil: A Mathematical Adventure by Hans Magnus Enzensberger Alice in Puzzle-Land by Raymond M. Smullyan The Phantom Tollbooth by Norton Juster ... Beginner What Is Mathematics? An Elementary Approach to Ideas and Methods by Richard Courant Mathematics: Its Content, Methods and Meaning (Dover Books on Mathematics) by A. D. Aleksandrov Mathematics: A very short introduction by Timothy Gowers ... Basic Math Basic Mathematics by Serge Lang 1998  (high school or college students.) ... Pre-Algebra Pre-Algebra DeMYSTiFieD by Allan Bluman ... Algebra Algebra by Israel M. Gelfand 2013 A book of Abstract Algebra by Charles Pinter? ... Algebra II ... Trigonometry Trigonometry by I.M. Gelfand 2013 ... Pre-Calculus ... Calculus Calculus by Michael Spivak ... Problem Solving https://en.wikipedia.org/wiki/Yakov_Perelman#Books How to Solve it by Polya's Techniques in Problem Solving by Steven George Krantz The Art and Craft of Problem Solving by Paul Zeitz How to Prove It: A Structured Approach by Daniel J. Velleman 2006 Problem-Solving Strategies (Problem Books in Mathematics) by Arthur Engel Number Theory (Dover Books on Mathematics) by George E. Andrews Some of the books in the Art of Problem Solving series at www.ArtofProblemSolving.com","['arithmetic', 'calculus', 'soft-question']"
824062,Inner automorphisms form a normal subgroup of $\operatorname{Aut}(G)$,"For an arbitrary group $(G,\cdot)$ let $\operatorname{Aut}(G) = \{f: G \to G \mid f \text{ is an isomorphism}\}$ be the set of all automorphisms of the group $G$. We assume that $(\operatorname{Aut}(G),\circ)$ where $\circ$ is composition of mappings is a group. 1) Prove that for arbitrary $a \in G$ there is an automorphism $p_a: G \to G;\quad p_a(x) = a^{-1}xa$. 2) Prove, that $\operatorname{Inn}(G) = \{p_a \mid a \in G\}$ is a normal subgroup of $(\operatorname{Aut}(G),\circ)$.","['group-theory', 'abstract-algebra', 'normal-subgroups']"
824122,Almost sure convergence of a sequence of random variables,"Once again I've encountered a problem, which might not be difficult: I'm given a sequence of random variables $ (X_n) $, each with density function $g_n(x) = nx^{n-1} \textbf{1}_{(0,1]} $. I am to prove that this sequence converges almost surely. So to begin with, I think I am able to find the limit and prove convergence by probability. We have: $\mathbb{E} X_n = \int\limits_{0}^1 nx^n dx = \frac{n}{n+1} $ Applying Chebyshev inequality: $ \lim\limits_{n \rightarrow \infty}\mathbb{P}(1-X_n < \epsilon) = \lim\limits_{n \rightarrow \infty} (1 - \mathbb{P}(1- X_n \geq \epsilon)) \geq \lim\limits_{n \rightarrow \infty}(1- \frac{\mathbb{E}(1-X_n)}{\epsilon}) = \lim\limits_{n \rightarrow \infty} (1- \frac{1}{\epsilon}(1-\frac{n}{n+1})) = 1$ Thus, $ X_n \rightarrow 1 $ by probability. And there goes my question: how do I prove almost sure convergence? I've been trying to use the definition, but it doesn't seem to help. Thanks in advance","['probability-theory', 'convergence-divergence', 'probability', 'random-variables']"
824123,What is an embedding degree of elliptic curve?,"I am dealing with MOV algorithm to transform ECDLP to DLP in $GF(p^k)$, but at the first step I have to determine embedding degree k. I have read the definitions of embedding degree, but still I am not sure, how to compute it and what exactly it states for. As far as I understand embedding degree is not equal to the degree of the curve. I would be grateful, if somebody could clarify, what the embedding degree stands for, and how to calculate.","['elliptic-curves', 'abstract-algebra', 'cryptography']"
824127,Linear map from zero vector to zero vector.,"I am reading an introduction on linear maps in my text book on linear algebra. The following statements are made: Suppose $G_1 (\vec{u}) = (x_1 + 2x_2 + 3x_3 + 1, 4x_1, 9x_3)$ Then we can use the following property of linear maps. Let $\lambda = 0$ and $\vec{u} = \vec{0}$ $$G(\lambda\vec{u}) = \lambda G(\vec{u})$$ And specifically: $$G(\vec{0}) = 0 \cdot G(\vec{0}) = \vec{0}$$ This means that a linear map maps the zero vector to the zero vector. It also means that $G_1$ cannot be a linear map, this is because $G_1(0,0,0) = (1,0,0) \neq (0,0,0)$. The constant term $1$ is breaking the linearity. My analysis I don't understands the above statements completely. For example this statement: $G(\vec{0}) = 0 \cdot G(\vec{0}) = 0$ should be true for any function $G(\vec{u})$, since whatever result of the  map $G(\vec{u})$ will be it will be multiplied by $0$ and result in $\vec{0}$. In the case above it would be $0 \cdot (1,0,0) = \vec{0}$. This would map the zero vector to the zero vector and hence be a correct linear map? Can anyone please explain this to me?",['linear-algebra']
824160,Is a Variety a manifold?,"Is it true that every smooth variety (over $\mathbb{R}$ or $\mathbb{C}$ ) is a (real or complex) manifold? I have tried to show this using the implicit function theorem but I am not getting anywhere. I think I  understand it if I have a complete intersection variety, If $X=V(f_{1},...,f_{m})\subset\mathbb{A}^{n+m}$ and $dimX=n$ then we have a function, 
$f:\mathbb{R}^{n+m}\to\mathbb{R}^{m}$, and the implicit function theorem gives a local function $g:\mathbb{R}^{n}\to\mathbb{R}^{m}$ such that $f(x,g(x))=0$. Thus, $X$ is the graph of $y=g(x)$. The problem is that this uses the fact that $n+m$ is the dimension of the ambient space.","['complex-manifolds', 'algebraic-geometry', 'smooth-manifolds', 'manifolds']"
824175,How to explain the perpendicularity of two lines to a High School student?,"Today I was teaching my friend from High School about linear functions. One of the exercises we had to do was finding equations of perpendicular and parallel lines. Explaining parallel equations was quite easy, if we have the equation $y = ax + b$ it's not hard to show with a couple of examples that changing the parameter $b$ only ""moves"" the line up or down but doesn't change the angle, thus lines $k$ and $\ell$ are parallel iff $a_k = a_{\ell}$. However, I couldn't find a clear way to explain why those lines are perpendicular iff $a_k \times a_{\ell}= -1$. Of course, it's obvious if we use the fact that $a = \tan (\alpha)$ with $\alpha$ being the angle at which line intersects the X axis and that $\tan (\alpha) = - \cot (\frac{\pi}{2} + \alpha)$. But this forces us to introduce trigonometry and rises oh so many questions about the origin of the equation above. Does anyone know a good, simple explanation that's easy to remember?","['graphing-functions', 'education', 'functions']"
824212,Show that $f(x) = x\sin(1/x)$ is Differentiable everywhere where $x\ne0$.,"I have to show that  $f(x)= x\sin(1/x)$ is continuous everywhere differentiable everywhere where $x\ne 0$. I can show the continuous property, and how it is not differentiable when $x=0$, but how would I go to prove that it is differentiable for all $x$, such that $x\ne 0$. Trying to put it into the definition of the derivative and simplifying does not work (I could not get a proper answer.) Any hints on how to proceed would be greatly appreciated.","['calculus', 'derivatives']"
824247,How can I choose the best algorithm to integrate ODEs numerically?,"I have studied in a course several algorithms to integrate ODEs numerical: Runge-Kutta, Predictor-Corrector methods, Taylor... However the teacher failed to show which is the best for every particular situation. The only thing I know is that implicit methods are appropriate for stiff systems. But how do they compare Runge-Kutta (of any order) with predictor-corrector methods or with Taylor method? Which is best for each situation? Heuristic answers based on experience may be good enough!","['ordinary-differential-equations', 'soft-question', 'numerical-methods']"
824248,k-Nearest nodes: Average distance between connected nodes when search radius is non-integer,"Say I have an infinitely large grid where the probability any given square contains a 
node is $p$. Each node makes a connection with its $k$ nearest neighbours. How do I calculate the average distance between each connected node pair on the grid, in terms of Manhattan distance? I have managed to do it for $k=4$ and $p=0.1$ by deriving the following formula: At a distance of $d$ from any given cell, there are $4d$ cells (recall manhattan distance: there are 4 nodes at a distance of 1 apart, 8 nodes at a distance of 2 apart, 12 at a distance of 3 apart...). Since $k=4$, we expect to find the 4 nearest nodes within $4/0.1 = 40$ cells. We cover 40 cells when our search radius $r$ is 4, since 4+8+12+16 = 40. Hence the expected avg. distance between connected pairs is (4/40 * 1) + (8/40 * 2) + (12/40 * 3) + (16/40 * 4) which is 3 . This is the same as: Avg distance between connected pairs $= \sum\limits_{d=1}^r \frac{4d^{2}}{n}$ My problem is, what about when the search radius $r$ is not an integer? The formula no longer works. Note that you can solve for $r$ using: $\frac{k}{p} = 2r(r+1)$ when $k=4, p=0.1$ then $r=4$. But usually it will be a non-integer.","['discrete-mathematics', 'probability', 'expectation']"
824254,Properties and representations of the the rescaled complementary error function $\mathrm{erfcx}{z}$,"Consider the rescaled complementary error function: $$
\mathrm{erfcx}(z) = {e^{z^2}} \left( {1-\mathrm{erf}(z)} \right)
$$ $z \in \Bbb{C}$ which also has the following integral representation:
$$
\mathrm{erfcx}(z) = -{\frac{i}{\sqrt{\pi}}}\int {\frac{e^{-t^2}}{t-iz} dt}
$$ What is the correct decomposition into real and imaginary parts? Are they related to other known functions? What are the symmetries of this function? Estimate $\mathrm{erfcx}(z) - \mathrm{erfcx}(z^*)$ ($z^*$ denoting complex conjugation) Does $\mathrm{erfcx}(z) - \mathrm{erfcx}(z^*)$ have any notable properties? What are its stationary points (e.g. along lines parallel to the real axis)? Can anyone suggest possible routes for graphing the real and imaginary parts of this function? Motivation The complementary error function appears in the solution of a transport problem that I am trying to solve - I have exposed it to some detail here .
I hope that the study of this function will enable the suitability of my solution for the required application. Here are my attempts to solve these questions - I believe I have made some progress, but they are incomplete. 1. It is worth noting that $\mathrm{erfcx}(z)=w(iz)$ where $w(z)$ is the Faddeeva function. Therefore, the properties of $\mathrm{erfcx}(z)$ should follow trivially from that relation (as they are given, for example in Abramowitz & Stegun ). However, I do find in the literature the restriction of many of the properties to the upper half of the imaginary plane, but as I would like to see if such restrictions can be avoided I shall state the more salient ones explicitly. Let $z = \alpha + i \beta$; $\alpha , \beta \in \Bbb{R}$. Then $$
\mathrm{erfcx}(z) = u(\alpha,\beta)+ i\ v(\alpha,\beta)=
$$
$$
e^{\alpha^2 -\beta^2} 
\left[ 
\cos{(2\alpha\beta)}(1 - \Re[\mathrm{erf}z]) + \sin{(2\alpha\beta)}\Im[\mathrm{erf}z]
\right]
-i\ e^{\alpha^2 -\beta^2}
\left[
\cos{(2\alpha\beta)}\Im[\mathrm{erf}z] + \sin{(2\alpha\beta)}(1 - \Re[\mathrm{erf}z])
\right]
$$ which (taking $\Re[\mathrm{erf}z]$ to be odd wrt $\alpha$ and even wrt $\beta$ and conversely $\Im[\mathrm{erf}z]$ even wrt $\alpha$ and odd wrt $\beta$ - if I am not terribly mistaken) implies $u(\alpha,\beta)=u(\alpha,-\beta)$ and $v(\alpha,\beta)=-v(\alpha,-\beta)$. As the Faddeeva function $w(z)$ is decomposed to (real and imaginary) Voigt functions $$
w(p + iq) = U(p,q)+i\ V(p,q)
$$ one is tempted to write $u(\alpha,\beta)=U(-\beta, \alpha)$ and $v(\alpha,\beta)=V(-\beta, \alpha)$ But does this relation hold $\forall \alpha , \beta \in \Bbb{R}$? Moreover, are there calculation methods $v$ and $u$ and relations to other commonly used special functions? With appropriate scaling, for $\alpha>0$ $U$ is related to the Voigt profile; for $\alpha=0$, $V$ is related to Dawson's integral $\sqrt{\pi/4}{e^{-x^2}\mathrm{erfi}(x)}$. But can a more generalised representation be found, valid for all $z$? 2. $u$ has even parity wrt $\beta$ and $v$ is odd wrt $\beta$. The symmetries of $w(z)$ would be expected to hold for $\mathrm{erfcx}(z)$ as well. 3. $$
\mathrm{erfcx}(z) - \mathrm{erfcx}(z^*) = 2 i \ v = -2i\ e^{\alpha^2 -\beta^2}
\left(
\cos{(2\alpha\beta}\Im[\mathrm{erf}z]
 + \sin{2\alpha\beta}(1- \Re[\mathrm{erf}z]) 
\right)
$$ showing that this difference is purely imaginary. But a way to calculate this wouldbe useful. 4. I have not yet looked into this problem in any particular detail; the ODE representation of $w$ and the associated recurrence relations will probably be of use here. 5. I have found a number of C libraries for complex error functions (e.g. here , which includes a short bibliography for the calculation). I am in the process of implementing them; but if there are other quidirty hacks for estimating the imaginary and real parts of $\mathrm{erfcx}(z)$ I would be very glad to hear about them. Addendum As the expressions I obtain for $\Re[\mathrm{erf}(\alpha + i \beta)]$ and $\Im[\mathrm{erf}(\alpha + i \beta)]$ are long-winded (and often encountered in the relevant literature) I shall append them here. ( a ) Migrating along the real axis to $z=\alpha$ and then up to $z=\alpha + i\beta$
$$
\mathrm{erf}(\alpha + i \beta) =
\sqrt{\frac{4}{\pi}}\int _{0}^{\alpha}{e^{-t^2} dt} + i
\sqrt{\frac{4}{\pi}}\int _{0}^{\beta}{e^{-(\alpha+ i \ t)^2} dt} =
$$
$$
\mathrm{erf}(\alpha) +
\sqrt{\frac{4}{\pi}} e^{-\alpha^2} \int _{0}^{\beta}{e^{t^2} \sin{(2\alpha t)} dt} +
i \sqrt{\frac{4}{\pi}} e^{-\alpha^2} \int _{0}^{\beta}{e^{t^2} \cos{(2\alpha t)} dt}
$$
( b ) Migrating along the imaginary axis to $z=i\beta$ and then parallel to the real axis to $z=\alpha + i\beta$
$$
\mathrm{erf}(\alpha + i \beta) =
i\sqrt{\frac{4}{\pi}}\int _{0}^{\beta}{e^{t^2} dt} + 
\sqrt{\frac{4}{\pi}}\int _{0}^{\alpha}{e^{-(t + i \beta)^2} dt} =
$$
$$
\sqrt{\frac{4}{\pi}} e^{\beta^2} \int _{0}^{\alpha}{e^{-t^2} \cos{2 \beta t} dt} + 
i\sqrt{\frac{4}{\pi}} e^{\beta^2} \int _{0}^{\alpha}{e^{-t^2} \sin{2 \beta t} dt} + 
i\ \mathrm{erfi}(\beta)
$$ I find the occurrence of definite integrals of the form$ \int _{0}^{\kappa}{e^{\pm t^2} \cos{2 \lambda t} dt}$ and $ \int _{0}^{\kappa}{e^{\pm t^2} \sin{2 \lambda t} dt}$ quite suggestive, esp. when seen e.g. in conjunction with an integral representation of Dawson’s function: $$
D_{+} (\chi)= \int_{0}^{\infty}{e^{-t^2} \sin{2 \chi t} dt}
$$ Is the presence of such formulae, which resemble the sine and cosine transforms of the Gaussian coincindental? If not, can it be somehow exploited? (Apologies for the long question – but at least I will not be accused of not being thorough.)","['special-functions', 'integration', 'graphing-functions', 'complex-analysis', 'error-function']"
824267,Double roots of polynomials,"If $f\in R[x]$ is a real univariate polynomial of degree $2d$ then $f$ can have at most $d$ double roots. What about generalizations to multivariate polynomials? Suppose that for $f\in R[x_1,\ldots,x_n]$ of degree $d$ the set $S:=\{\xi\in R^n : f(\xi)=0  \frac{\partial f}{\partial x_i}(\xi)=0,  i\in\{1,\ldots,n\}\}$ is finite. What is a bound on $|S|$?","['algebraic-geometry', 'real-analysis', 'real-algebraic-geometry']"
824304,Help needed in solving a system of DE,"The system of DE is:
$$\frac{dI}{db}=-\frac{b}{c}\frac{dJ}{db}-\frac{2ab+1}{2c}J$$
$$\frac{dJ}{db}=\frac{b}{c}\frac{dI}{db}-\frac{2ab-1}{2c}I$$ Assume that $a$ and $c$ are constants and both $I$ and $J$ tends to zero as $b$ tends to $\infty$. To be honest, I have never solved a system of DE before. I usually use W|A if I am in a situation like this but in this case, even W|A fails. I am not sure if it is even possible to solve the above system. Any help is appreciated. Many thanks!","['ordinary-differential-equations', 'calculus', 'integration']"
825316,Linear algebra notation involving $\preceq$,"I am trying to read a paper which involves some linear algebra. I would appreciate if anyone could clarify what the below statements exactly mean. 1-) $0 \preceq B^TB \preceq A^TA$ where $A \in \mathbb{R}^{n \times m}$ and $B \in \mathbb{R}^{l \times m}$ are matrices. 2-) $\langle A_i,x \rangle^2$ where $A_i$ and $x$ are vectors","['notation', 'linear-algebra']"
825320,What is the relationship between the area of a triangle and an area of a segment of a circle?,"I had a very smart physics teacher in the past remind us of the area of a segment of circle through this 'derivation': ""well, if you put two of those together doesn't it kind of look like a rectangle? what's the area of a rectangle? now divide that in half."" It is greatly bothering me that this explanation works and assume there's some relationship I don't see please help!","['geometry', 'trigonometry']"
825336,Determine the Cumulative Distributive Distribution(CDF) of a truncated value?,It is the last part(part h) that I am having problems with. I know you use integration and then split it into 2 parts. But how exactly do you do it ? A detailed answer would be very helpful ! Please help !,"['statistics', 'probability-distributions', 'probability']"
825375,Quesrion about a complex integral: I am struggling with $\int _0^1 {\ln x\over{1-x^2}}dx=-{\pi^{2}\over 8}$,"How do I prove $$\int _0^1 {\ln x\over{1-x^2}}=-{\pi^{2}\over 8}$$ My solution:
If we can prove $\int _0^1 {\ln x\over{1-x^2}}= \lim_{n\to \infty} \int _0^1\ln(x)(1+x^2+x^4+......+x^{2n})$ ,then I think we can prove the equality above. because the right hand = $\lim_{n\to \infty} $$(-1-{1\over{3^2}}-{1\over 5^2}......-{1\over{2n+1}^2})={-\pi^{2}\over 8}$ . Can someone help me prove why $\int _0^1 {\ln x\over{1-x^2}}= \lim_{n\to \infty} \int _0^1\ln(x)(1+x^2+x^4+......+x^{2n})$ ? I don't know how to prove it? Or, can someone use other methods to solve the equality above?","['improper-integrals', 'sequences-and-series', 'integration', 'real-analysis', 'analysis']"
825404,-ln(0.1) equalling to ln(10)?,I am having quite a headache wrapping my head around this solution. I do not understand the first line where they get lambda = ln(10) from statement to the left. Somebody please explain this to me. Ignore the problem itself please.,"['statistics', 'logarithms', 'algebra-precalculus']"
825414,Simplify function with polynomial via least-squares,"I want to ""adjust"" (simplify) $f(x)$, a function, by $g(x)$, a polynomial, via least-squares. I want to write code for that. Apperently my code is issuing wrong results, so I was wondering if my mistake lies on the math I had to do in order to simplify the problem into something ""codeable"" or on the code itself. My ""simplification"" was as follows: $r^2 = \int_{x_0}^{x_n}(f(x)-g(x))^2dx$ must be as low as possible, i.e. $$\nabla \int_{x_0}^{x_n}(f(x)-g(x))^2dx = 0$$ $g(x)$ being a polynomial of degree $n$ then there's a linear system of $n$ partials to be solved, such as $$\begin{cases}\int_{x_0}^{x_n}\frac{\partial r^2}{\partial c_i}(f(x)-\sum\limits_{j=0}^{n}c_jx^j)^2dx=0\end{cases}$$ $c_j$ the $j$th coefficient of the polynomial we need to determine, with the partial derivative in respect of $c_i$, $i$ being the system's $i$th equation (the $i$th partial). Solving the partial of $r^2$ (chain rule) gives $\int_{x_0}^{x_n}2r\frac{\partial r}{\partial c_i}rdx=0$. Taking the $2$ out of the integral, solving the partial of $r$ and replacing $r$ gives out $$\int_{x_0}^{x_n}(f(x)-\sum\limits_{j=0}^{n}c_j x^j)(-x^i)dx=0$$ Since $x^i$ is the only term of $r$ with $c_i$ (and it's $-g(x)$). Taking the $-1$ out of the integral, expanding and adjusting the equation such that $c_j$ gets out of the integral $$\int_{x_0}^{x_n}x^if(x)dx-\sum\limits_{j=0}^{n}c_j\int_{x_0}^{x_n}x^jx^idx=0$$ Alternatively (so it's easier to write code) $$\begin{cases}\int_{x_0}^{x_n}x^if(x)dx=\sum\limits_{j=i}^{n+i}c_{j-i}\int_{x_0}^{x_n}x^jdx\end{cases}$$ I tested it with the following case: $$f(x) = sin(2 \pi x) + cos(3 \pi x) \\ [x_0, x_n] = [-1, 1] \\ n (degree) = 5$$ Using the discrete least-squares approach, with $h=10^{-6}$, that is, 2000000 points, I got $$g(x) = 14.52221837x^5 - 3.90881979x^4 - 17.86276751x^3 + 3.09711194x^2 +   4.01638587x - 0.25060696$$ Which looks good. Using the continuous approach described above I got $$g(x) = -0.57270982x^5 - 3.90880894x^4 + 2.17959533x^3 + 3.0971047x^2 - 0.74400025x - 0.25060645$$ Which seems off. So... are there any issues with the math?","['calculus', 'least-squares', 'statistics', 'approximation', 'numerical-methods']"
825418,Flux through a vector field of a sphere (not centered at origin)?,"If $$F = \langle xy,yx,-(x+y)z \rangle$$ find $$\int F \cdot \hat n \, dS$$ where $S$ is a sphere of radius $2$ centered at $\langle 0,1,0 \rangle$? I don't need a numerical solution to the problem because I know how to do it...for a sphere that is centered at the origin. How do I take into account the fact that the sphere is centered at $\langle 0,1,0 \rangle$? I am going to be using spherical coordinates, so can I simply add a '$-1$' onto the $y$ term of the parametrization? Or is this completely the wrong idea?","['multivariable-calculus', 'calculus']"
825437,Combinatorial identity [duplicate],"This question already has answers here : Weird $3^n$ in an identity to be combinatorially proved (3 answers) Closed 10 years ago . Find a formula for:
$$
\binom n0 + 2\binom n1 + 4\binom n2 + 8\binom n3 + \cdots + 2^{n-1}\binom n{n-1} + 2^n\binom nn
$$
using a counting argument. I just used the binomial t. to show it's $3^n$ but I can't find a combinatorial way. Any help?",['combinatorics']
825455,Probability that a sample comes from one of two distributions,"Let's say I have two normal distributions with means $\mu_1$, $\mu_2$ and standard deviations $\sigma_1$, $\sigma_2$ (which I know). I am handed a random variate from one of the distributions (I don't know which). What is the likelihood that my variate belongs to distribution 1 and not distribution 2? UPDATE: a concrete example. Machine one generates normally-distributed variates with mean 1053 and standard deviation 59. Machine two generates normally-distributed variates with mean 1187 and standard deviation 73. One of them is picked at random, the handle is turned (unseen by me) and the number 1162.4 comes out. What is the likelihood that number was generated by machine 1 as opposed to machine 2?","['statistics', 'estimation']"
825468,Intuition behind the definition of a derivative by Lang,"In Serge Lang's Introduction to Differentiable Manifolds he says that a function $f:U\to F$ is differentiable at a point $x_0\in U$ if there exists a linear map $\lambda$ of $E$ into $F$ such that, if we let $$f(x_0+y)=f(x_0)+\lambda y+\varphi(y)$$ for small $y$, then $\varphi$ is tangent to $0$. Tangent to $0$ is defined as follows: A real valued function of a real variable, defined on some neighborhood of $0$ is said to be $o(t)$ if $$\lim_{t\to 0}o(t)/t=0.$$ Let $E,F$ be two vector spaces, and $\varphi$ a mapping of a neighborhood of $0$ in $E$ into $F$. We say that $\varphi$ is tangent to $0$ if, given a neighborhood $W$ of $0$ in $F$, there exists a neighborhood $V$ of $0$ in $E$ such that $$\varphi(tV)\subset o(t)W$$ What is the intuition behind defining it in this manner?","['differential-topology', 'derivatives']"
825469,"What is the ""proof"" for this vector calculus theorem besides intuition?","I'm reading Div, Grad, Curl, and All That , and one of the exercises reads as follows: Instead of using arrows to represent vector functions, we sometimes use families of curves called field lines . A curve $y = y(x)$ is a field line of the vector function $\mathbf{F}(x, y)$ if at each point $(x_0, y_0)$ on the curve, $\mathbf{F}(x_0, y_0)$ is tangent to the curve. Show that the field lines $y = y(x)$ of a vector function $$\mathbf{F}(x, y) = \mathbf{i}F_x(x, y) + \mathbf{j}F_y(x, y)$$ are solutions of the differential equation $$\frac{dy}{dx} = \frac{F_y(x, y)}{F_x(x, y)}.$$ (pp. 9–10) I understand the concepts here (or I think I do), and I understand that this proof makes sense. However, I don't really know how to go about proving it. It seems to me that the statement is self-evident: it's given that the vector function is tangent to the curve, so of course the slopes will be the same, by definition. Am I missing something here? How should I approach this? No solution is provided in the book (for any of the open-ended problems).","['multivariable-calculus', 'calculus', 'vectors']"
825470,Synthetic division of polynomials by factor of the form $(ax+b)$,"Find the quotient and remainder when $6x^4-11x^3+5x^2-7x+9$ is divided by $(2x-3)$. I expressed the divisor $(2x-3)$ as $2(x-\frac{3}{2})$ and conducted synthetic division by $\frac{3}{2}$ and obtained the coefficients of the quotients as $6, -2, 2$ and $-4$ and the remainder as $3$. Then I divided the quotients by $2$. Why should I do this? and why should I not divide the remainder by $2$?","['algebra-precalculus', 'polynomials']"
825473,Motivation and Derivation of the Riccati Equation Transformation,Given a Riccati Equation which is differential equation of the form: $$ \frac{dy}{dx} = a_0 (x) + a_1 (x)y + a_2 (x)y^2  $$ It is well known that the transformation: $$ y = -\frac{1}{a_2(x)} \frac{\frac{du}{dx}}{u} $$ Can be substituted into this equation to transform it into a second order linear differential equation (which after simplifying the algebra is) $$ a_0(x)a_2(x) u - (a_1(x)a_2(x) + 1) \frac{du}{dx} + a_2(x)\frac{d^2u}{du^2} = 0 $$ My question is: How does one derive this transformation from scratch. Since although it is easy to prove that the transformation works it does not reveal how it was found.,"['ordinary-differential-equations', 'calculus', 'analysis', 'derivatives', 'problem-solving']"
825476,$AB-BA$ is nilpotent matrix,"Let $A$ and $B$ be $n\times n$ nilpotent matrices. Show that $AB-BA$ is a nilpotent matrix if and only if $A$ and $B$ share the same eigenvector $\alpha$ . I tried if $A$ and $B$ share the same eigenvector $\alpha$ , then due to $A\alpha=0=B\alpha$ we have $(AB-BA)\alpha=0$ . Then I don't know how to continue ... :(","['matrices', 'linear-algebra']"
825498,If $\lim_{x\to \infty} f(x) + f'(x) = L$... [duplicate],"This question already has answers here : If $\lim_{x\to\infty}(f(x)+f'(x))=L$ show that $\lim_{x\to\infty} f(x) = L$ and $\lim_{x\to\infty} f'(x) = 0$ [duplicate] (2 answers) Closed 10 years ago . How can I prove $\lim_{x\to \infty} f(x) = L$ ? I tried to prove by L'Hospital's Rule, but I only proved when the limit exists... How can I prove when I am not provided that the limit exists?","['real-analysis', 'limits']"
825509,Group of Points on an Ellipse,"I did some tooling around to find an abelian group operation for the set of points on the ellipse $\left(\frac{x}{a}\right)^2+\left(\frac{y}{b}\right)^2=1$, given by $(p,q)*(r,s)=\frac{1}{a}(pr-\frac{a^2}{b^2}qs,ps+qr)$. I checked associativity, the identity is $(a,0)$, and the inverse of $(p,q)$ is $(p,-q)$. What are some properties of this group worth exploring -- some good problems for someone with basic algebra experience?","['geometry', 'conic-sections', 'group-theory']"
825515,How does a row of zeros make a free variable in linear systems of equations?,"I don't understand how a row of zeros gives a free variable when solving systems of linear equations. Here's an example matrix and let us say that we're trying to solve Ax=0 : $$\left[
        \begin{matrix}
        2 & -3 & 0 \\
        3 & 5 & 0 \\
        0 & 1 & 0 \\
        \end{matrix}
\right]$$ This makes sense to me - you have a COLUMN of numbers corresponding to the number of times the variable $x_3$ is used for each equation and since they are all zeros, $x_3$ could have been any real number because we never get to manipulate our equations to determine a value for it. Hence, it is a free variable as it is not subject to the constraints of the equations. $$\left[
        \begin{matrix}
        2 & -3 & 5 \\
        0 & 5 & 1 \\
        0 & 0 & 0 \\
        \end{matrix}
\right]$$ Now for this second example, $x_3$ would still be a free variable. Why is this so? $x_3$ is being used in the other two equations where you could certainly come up with a finite set of answers for this variable rather than saying ""It could've been anything!"" right? Also is it entirely arbitrary that $x_3$ is the free variable or could it be decided that $x_1$ or $x_2$ is free instead? Could someone explain to me in a more layman or simplified form on why a row of zeros magically makes a free variable?
Please help me :(","['matrices', 'linear-algebra', 'systems-of-equations']"
825554,"Generalization of $|HK|=\frac{|H||K|}{|H∩K| }$, where $H,K$ are finite subgroups","I know (and proved) the theorem 
$$
|HK| = \frac{|H| |K|}{|H \cap K|}, \text{where $H,K$ are finite subgroups of $G$}.
$$ NOW I'm wondering about a generalization of this statement. In my 1st attempt:  if $H, I, K$ are finite subgroups of $G$, then
$$
|HIK| = \frac{|H||I||K|}{|H \cap I \cap K|}
$$
BUT this is false for $G=$Klein 4 group, $H = \{e, a\}$, $I = \{e,b\}$, $K = \{e,c\}$ and 2nd attempt, 3rd, ... are not true... Is this generalization NOT worth wondering about? Please give me some advice. Thank you for your attention to this matter.","['finite-groups', 'group-theory', 'abstract-algebra']"
825580,the automorphism group of a finitely generated group,"Let $G$ a finitely generated group, $\mathrm{Aut}(G)$ is its automorphism group, then it is necessary that $\mathrm{Aut}(G)$ is a finitely generated group? Thanks in advance.","['finitely-generated', 'group-theory', 'abstract-algebra']"
825586,"$\int_0^1f(x)dx=1, \int_0^1xf(x)dx=\frac16$ minimum value of $\int_0^1f^2(x) dx$?","Let $f(x)\geq0$ be a Riemann integrable function, and $$\int_0^1f(x)\,\mathrm dx=1, \int_0^1xf(x)\,\mathrm dx=\frac16.$$ Find the minimum value of  $\int_0^1f^2(x)\,\mathrm dx$ Cauchy-Schwarz inequality?  en, I'm  in trouble for $f(x)\geq0$ Thank you","['calculus', 'integration', 'limsup-and-liminf']"
825610,How can an improper integral have multiple values?,"Integrals like this are said to dependend on the contour of integration: $$\int^{\infty}_{-\infty}\frac{x\sin x}{x^2-\sigma^2}dx=\pi e^{i\sigma}\space \mathrm{or}\quad \pi \cos\sigma $$ How is it possible that an improper integral has multiple values? Is this similar to the case where the improper integral doesn't exist and we have to use the Cauchy principal value (because the integral would depend on the limit)? Does the problem remain if we don't use contours at all? I've encountered this type of integrals in Quantum Field Theory and in Arkfen's Mathematical methods , so I don't if this is one of the cases were physicists are being sloppy. Since my complex calculus followed Churchill, I never saw how to deal with this problem. To give some more context, in QFT, we have the propagator (related to Green's functions ): $$D(r)=\int dp^0 d^3p \frac{e^{-ip_0r^0+i\vec{p}\vec{r}}}{p_0^2-p^2-m^2}$$","['quantum-field-theory', 'complex-integration', 'improper-integrals', 'complex-analysis']"
825612,How far is it possible to develop cardinals without ordinals?,"I'm wondering which of the usual facts about cardinals in ZFC can be established without using ordinal arithmetic at all. After all the definitions of a cardinal (as a class of equivalence), and also of limit/successor/regular/singular cardinals etc. do not involve order types. Is it possible to develop ""just"" cardinals, without working with ordinals? Is there an analogue of transfinite recursion that ""just"" uses cardinals? Does there exist a treatment of cardinals written up along these lines?","['cardinals', 'elementary-set-theory']"
825649,How to calculate historical data knowing only yearly percentage increase and data for year 2015?,"How do I calculate historical yearly market worth knowing only its yearly growth rate and its martket worth for year 2015? Example: According to MarketLine, the global home improvement market is
  expected to grow at 2.5% yearly rate between 2010-2015 and is
  predicted to be worth almost $678 billion by 2015 I need to find X for each year since 2010 until 2014. I have yearly 2.5% percentage increase and 678,000,000,000 for year 2015. How do I calculate historical worth for respective years?","['statistics', 'percentages']"
825685,What is the intuition and motivation behind a norm on a space?,"I have a question regarding norms. I am looking for an intuitive understanding of what norms do. From what I know so far, in any arbitrary space, if I have a norm, then it appears that it allows me to define distances. That is, if I have two points in the space, I know where they are in relation to one another. Is the motivation then that I can sort of ""classify"" and discriminate where things are once I have a metric or norm on the space? Also, if a space doesnt have a metric or norm, what would that mean? Thank you","['linear-algebra', 'real-analysis']"
825687,Are there uncountable groups which satisfy the minimal condition on subgroups?,Definition A group $G$ is said to satisfies the minimal condition on subgroups if every descending chain of subgroups stops after a finite number of steps. I know this was an unsolved problem in past but I do not know if now it is solved. (Tarski groups are $2$ -generated and hence countable.) Question :  Is it true that every group satisfying the minimal condition on subgroups is countable?,"['free-groups', 'group-theory', 'abstract-algebra']"
825694,How can I visualize the discrete metric?,"I saw that in a real analysis proof, they used a proof by contradiction where the metric was a discrete metric. That is, distance is defined to be 1 if the points ARENT the same and 0 if the points are the same. I was trying to visualize how this would look for a unit circle. Does such a visualization exist? What is the correct way of viewing it in 2 dimensions? Thank you!",['real-analysis']
825695,Linear Differential Equations of higher order,"I am studying the basics of linear differential equations.
$$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=X$$ First the complementary function is found via $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=0$$ Then the particular integral is found using $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=X$$ I did not understand the logic or derivation behind this. Its not like I have another way to solve them, but can anyone help in explaing the intuition behind this.",['ordinary-differential-equations']
825698,Is this always true: $P(A|B) = 1-P(A^c|B)$?,"Does this identity hold for all events? $$
P(A|B) = 1-P(A'|B)
$$ Logically speaking, if the probability of $A$ given $B$ occurred is $X$, shouldn't the probability that $A$ does not occur, $A'$, given $B$, be similarly $1-X$? There is a related question here . This is the closest that I could get to proving (or disproving) it: $P(A\cap B)=P(A)-P(A' \cap B)$ $P(A|B)P(B)=P(A)-P(A'|B)P(B)$ $\therefore P(A'|B)= \frac {P(A)} {P(B)}-P(A|B)$ Are there are certain formulae which can be used to prove this? Or does the identity only hold under certain situations, and if so, what kind of situations? Thanks.",['probability']
825699,What is an example of real application of cubic equations?,"I didn't yet encounter to a case that need to be solved by cubic equations (degree three) !
May you give me some information about the branches of science or criterion deal with such nature ?","['applications', 'cubics', 'algebra-precalculus']"
825727,"How find all $f(x+y,y-x)=f(x,y)$","let the $f(x,y)$ be  Polynomial, such
$$f(x+y,y-x)=f(x,y)$$ 
Find all $f(x,y)$ My idea: let $x+y=u, y-x=v$
then
$$y=\dfrac{u+v}{2},x=\dfrac{u-v}{2}$$",['functions']
825741,Proving an expression is $4$,Is $\displaystyle\sqrt[\huge3]{\frac{1}{2} \left(56-\sqrt{\frac{84640}{27}}\right)}+\sqrt[\huge 3]{\frac{1}{2} \left(\sqrt{\frac{84640}{27}}+56\right)}=4$ true ? This was asked during an oral examination where calc and CAS are forbidden. Mathematica seems to say it's true. Can someone find a nice proof ?,"['radicals', 'algebra-precalculus']"
825790,Every weakly convergent sequence is bounded,"Theorem: Every weakly convergent sequence in X is bounded. Let $\{x_n\}$ be a weakly convergent sequence in X. Let $T_n \in X^{**}$ be defined by $T_n(\ell) = \ell(x_n)$ for all $\ell \in X^*$. Fix an $\ell \in X^*$. For any $n \in \mathbb{N}$, since the sequence $\{\ell(x_n)\}$ is convergent, $\{T_n(\ell)\}$ is a bounded set. By Uniform Boundedness Principle $ \sup_{n \in \mathbb{N}} \|x_n\| = \sup_{n \in \mathbb{N}} \|T_n\| < \infty,$ i.e. $\{x_n\}$ is bounded. My question is: why $ \sup_{n \in \mathbb{N}} \|x_n\| = \sup_{n \in \mathbb{N}} \|T_n\|$ ?",['functional-analysis']
825804,General solution of a system of linear differential equations with multiple generalized eigenvectors,"I am looking for general solutions for the linear sODE's
$$\textbf{x}'(t) = A\textbf{x}(t)$$
with $t \geq 0$ and $A \in \mathbb{R}^{n \times n}$ Let focus on just real eigenvalues and eigenvectors. For the case of $n=2$, where we have one eigenvalue, $\lambda \in \mathbb{R}$, such that $am(\lambda)=2, gm(\lambda)=1$ I know that the general solution is
$$\textbf{x}(t) = e^{\lambda t}(c_1 \textbf{v} + c_2\textbf{w}) + te^{\lambda t}(c_2 \textbf{w})$$
where $c_1,c_2 \in \mathbb{R}$, $\textbf{v}$ is the eigenvector corresponding to $\lambda$ and $\textbf{w}$ is a generalized eigenvector of $A$. But what would be the general solution be in the case $n = 3$ with one eigenvalue, $\lambda \in \mathbb{R}$, such that $am(\lambda)=3, gm(\lambda)=1$ or in the case of two eigenvalues  $\lambda_1,\lambda_2$ with $am(\lambda_1)=2, gm(\lambda_1) = 1, am(\lambda_2)=1, gm(\lambda_2) = 1$? So, all in all, how would one find the general solution to such systems of linear differential equations? Full answers are appreciated, but I prefer some hints to find the solution myself. Thanks in advance! Bonus: The same question but then with difference equations.","['dynamical-systems', 'eigenvalues-eigenvectors', 'ordinary-differential-equations', 'recurrence-relations', 'linear-algebra']"
825806,$A = \bigcap_{\mathfrak{p} \in \text{Spec(A)}} A_{\mathfrak{p}} = \bigcap_{\mathfrak{m} \in \text{MaxSpec(A)}} A_{\mathfrak{m}}$,"I'm doing this exercise. Let $A$ be an integral domain, then prove that $$A = \bigcap_{\mathfrak{p} \in \text{Spec(A)}} A_{\mathfrak{p}} = \bigcap_{\mathfrak{m} \in \text{MaxSpec(A)}} A_{\mathfrak{m}}$$ where the intersection is taken in the quotient field of $A$ and $A_{\mathfrak{p}}$ is the localization of $A$ at the prime ideal $\mathfrak{p}$, similarly for $A_{\mathfrak{m}}$ . What I have done: we have $$A \subseteq \bigcap_{\mathfrak{p} \in \text{Spec(A)}} A_{\mathfrak{p}} \subseteq \bigcap_{\mathfrak{m} \in \text{MaxSpec(A)}} A_{\mathfrak{m}}$$ so it suffices to prove that $$\bigcap_{\mathfrak{m} \in \text{MaxSpec(A)}} A_{\mathfrak{m}} \subseteq A$$
 Suppose $\frac{a}{b} \in \bigcap_{\mathfrak{m} \in \text{MaxSpec(A)}} A_{\mathfrak{m}}$ . I want to show that $b$ is invertible. If $b$ is not invertible then there exists $ \mathfrak{m} \in \text{MaxSpec(A)} $ such that $b \in \mathfrak{m}$. By hypothesis $$\frac{a}{b} = \frac{r}{s}$$ with $s \not\in \mathfrak{m} $. $A$ is a domain so $sa = rb \in \mathfrak{m} $ and thus $ a \in \mathfrak{m} $. Then I don't know how to proceed , any hint ?","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
825809,Isomorphism between Hilbert spaces,"I want to show that the function $$ L^2(\Omega,\mathcal{O})\longrightarrow L^2(\widetilde{\Omega},\mathcal{O}) \colon f \longmapsto f|_{\widetilde{\Omega}}$$ is a isomorphism, where $L^2(\mathbb{C},\mathcal{O})$ is the hilbert space of square-integrable holomorphic functions on $\mathbb{C}$ and $\Omega \subset \mathbb{C}$ is a bounded domain and for $E\subset \Omega$ finite we define $\widetilde{\Omega}:=\Omega \setminus E$.","['vector-space-isomorphism', 'hilbert-spaces', 'complex-analysis', 'analysis']"
825826,Beginning of Romance,"I am a 17-year old student in India, in the standard 12th grade. Recently, I found the fascination in mathematics, and I am eager to dig in further. Currently, the only textbooks I have are the ones at school: M.L Agrawal's of 11th and 12th. I don't find them very supportive. They are educational, but quite exam centered. Almost everything around me is exam centered, as students study math primarily so that they can qualify for board exams and engineering entrances. Not to sell myself short, but hey, not everyone can be Ramanujan and derive wonders from schoolbooks. Could anyone suggest someplace to start?
I am really interested in coordinate geometry and calculus. I have considered buying an S.L Loney, but every suggestion would be valuable.
Thank you.","['geometry', 'book-recommendation', 'calculus', 'self-learning', 'reference-request']"
825831,Base-point-free linear systems (elementary?) property,"I'm having troubles solving exercise K on page 167 of the book ""Algebraic curves and Riemann surfaces"" of Miranda. The question is the following one : Let $Q$ be a base-point-free linear system, let $p_1, ...,p_m$ be some points on the Riemann Surface $X$ . Show that there is a divisor $D\in Q$ without any $p_i$ in its support. I tried the following : Since $Q$ is a base-point-free linear system, it corresponds to some linear system $|\phi|$ associated to some holomorphic map $\phi:X \rightarrow \Bbb P^n$ , $x \mapsto [f_0(x): \dots : f_n(x)]$ . Here the $f_i$ 's denote some meromorphic functions. We have a very clear discription of such a system, namely any divisor in it can be written as $\text{div}(g)+D$ , where $D$ is defined as $-\min_i\{\text{div}(f_i)\}$ and $g$ is a linear combination of the $f_i$ 's. Since we're dealing with a base-point-free system, for any $i$ , there is a divisor $E_i$ in $Q$ such that $E_i(p_i)=0$ . But now I'm stuck, I tried some combinations of the $E_i$ 's to get the desired divisor, but I don't find it. Remarks : I don't know much about sheaves and schemes, so I can't use it. And I'm very sorry for the notation above, I'm new to this site and I haven't figured out yet how to get nice notations. Thank you in advance.","['riemann-surfaces', 'algebraic-geometry', 'complex-analysis']"
825847,How do I go about proving da db/a^(-2) is a left Haar measure on the affine group?,"Let $ G $ be the affine group, in other words $ G := \mathbb{R}\times \mathbb{R}\backslash\{0\} $ with binary operation defined by $ (b,a)\cdot(x,s) = (ax+b,as) $. Now, $ G $ is a locally compact group and thus has a left (resp. right) Haar measure. In particular I know that $ d\mu = a^{-2}da\,db $ defines a left Haar measure on $ G $. How do I go about proving that this is true? -that this is in fact a left Haar measure on $ G $?",['measure-theory']
825848,Showing that minimal polynomial has the same irreducible factors as characteristic polynomial [duplicate],"This question already has answers here : Minimal and characteristic polynomial have same set of irreducible factors (2 answers) Closed 4 years ago . I'm trying to show that the minimal polynomial of a linear transformation $T:V \to V$ over some field $k$ has the same irreducible factors as the characteristic polynomial of $T$. So if $m = {f_1}^{m_1} ... {f_n}^{m_n}$ then $\chi = {f_1}^{d_1} ... {f_n}^{d_n}$ with $f_i$ irreducible and $m_i \le d_i$. Now I've managed to prove this using the primary decomposition theorem and then restricting $T$ to $ker({f_i}^{m_i})$ and then using the fact that the minimal polynomial must divide the characteristic polynomial (Cayley-Hamilton) and then the irreducibility of $f_i$ gives us the result. However I would like to be able to prove this directly using facts about polynomials/fields without relying on the primary decomposition theorem for vector spaces. Is this fact about polynomials true in general? We know that $m$ divides $\chi$  and so certainly $\chi = {f_1}^{m_1} ... {f_n}^{m_n} \times g$ but then how do we show that $g$ must have only $f_i$ as it's factors? I'm guessing I need to use the fact that they share the same roots. And I'm also guessing that it depends on $k$, i.e. if $k$ is algebraically closed then it is easy because the polynomials split completely into linear factors. Help is much appreciated,
Thanks","['irreducible-polynomials', 'ring-theory', 'polynomials', 'linear-algebra', 'field-theory']"
825850,What is box tensor product?,"I have seen the symbol $\boxtimes$ (LaTeX: \boxtimes ) in a few places, but I couldn't find a good reference for that. What does it mean and how is it different from the usual tensor product? Thanks!","['notation', 'abstract-algebra']"
825855,Approximate the probability,"An immortal snail is at one end of a perfect rubber band with a length of 1km. Every day, it travels 10cm in a random direction, forwards or backwards on the rubber band. Every night, the rubber band gets stretched uniformly by 1km. As an example, during the first day the snail might advance to x=10cm, then the rubber band gets stretched by a factor of 2, so the snail is now at x=20cm on a rubber band of 2km. The question: Approximate the probability that it will reach the other side at some point (better approximations are obviously preferred, but any bounds are acceptable as long as they are found by doing something interesting)",['probability']
825865,"Let $f(z)$ be analytic on $\mathbb{D}$ = {${z\in\mathbb{C}:|z-1|<1}$} such that $f(1) = 1$, if $f(z) = f(z^2)$ for all $z\in\mathbb{D}$,","Let $f(z)$ be analytic on $\mathbb{D}$ = {${z\in\mathbb{C}:|z-1|<1}$} such that $f(1) = 1$, if $f(z) = f(z^2)$ for all $z\in\mathbb{D}$, then which of the following statements are correct? 1) $f(z) = [f(z)]^2$ 2) $f(\frac{z}{2}) = \frac{1}{2}f(z)$ 3) $f(z^3) = [f(z)]^3$ 4) $f'(1) = 0$ I can't understand how to do solving this problem. please anyone give me some hints.",['complex-analysis']
825886,Every subgroup of $\mathbf{Q}$ is a direct limit of $\mathbf{Z}\rightarrow\mathbf{Z}\rightarrow\cdots$,"In Hatcher's algebraic topology textbook there is an example in an appendix to chapter 3, stating that every subgroup of $\mathbf{Q}$ is the direct limit of a sequence of the form $\mathbf{Z}\rightarrow\mathbf{Z}\rightarrow\cdots$, ""with an appropriate choice of maps"". Can we prove this by simply combining the answer of anon , and the classification of subgroups of $\mathbf{Q}$ ?","['group-theory', 'abstract-algebra']"
825892,integral involving log poisson-like and rational,"Perhaps some may enjoy giving this one a go. It may be kind of challenging. $$\int_{0}^{\infty}\frac{x}{x^{2}+b^{2}}\log\left(\frac{x^{2}+2ax\cos(t)+a^{2}}{x^{2}-2ax\cos(t)+a^{2}}\right)dx$$ $$=\frac{\pi^{2}}{2}-\pi t+\pi\tan^{-1}\left(\frac{(a^{2}-b^{2})\cos(t)}{(a^{2}+b^{2})\sin(t)+2ab}\right), \;\ a,b>0; \;\ 0<t<\pi$$","['definite-integrals', 'integration']"
825903,Derivation of the negative hypergeometric distribution,"Suppose we've given an urn which contains $R$ red and $W$ white balls. These balls are drawn randomly from the urn and are not placed back. Let $X:=$ number of attempts, before we've drawn at least $r\le R$ red balls $Y:=$ number of red balls after $n-1$ attempts I want to calculate $\text{Pr}(X=n)$. Suppose we've already drawn $n-1$ balls from the urn and received $r-1$ red balls. The probability of this to happen is given by $$\text{Pr}(Y=r-1)=h(r-1|R+W,R,n-1):=\frac{\begin{pmatrix} R \\ r-1 \end{pmatrix}\begin{pmatrix} W \\ n-r \end{pmatrix}}{\begin{pmatrix} R+W \\ n-1 \end{pmatrix}}$$ where $h$ denotes the hypergeometric distribution. The probability that now another red ball is drawn is given by $$\text{Pr}(X=n)=\text{Pr}(Y=r-1)\;h(1|R+W-(n-1),R-(r-1),1)=\frac{\begin{pmatrix} R \\ r-1 \end{pmatrix}\begin{pmatrix} W \\ n-r \end{pmatrix}}{\begin{pmatrix} R+W \\ n-1 \end{pmatrix}}\frac{R-(r-1)}{R+W-(n-1)}$$ While I think that's correct, I would really like to get a more compact form of that. After some research on the internet, I found out, that I should be able to receive $$\text{Pr}(X=n)=\ldots =\frac{\begin{pmatrix} r-1 \\ n-1 \end{pmatrix}\begin{pmatrix} R+W-(r-1) \\ R-(n-1) \end{pmatrix}}{\begin{pmatrix} R+W \\ R \end{pmatrix}}$$ But I don't see how I get the $\ldots$ filled.","['probability-theory', 'probability-distributions', 'probability']"
825934,"Can $A, B$ fail to commute if $e^A=e^B=e^{A+B}=id$?","Consider the real $n \times n$-matrices $A$ and $B$. Can $A, B$ fail to commute if $e^A=e^B=e^{A+B}=id$ ?",['linear-algebra']
825942,The square root of positive definite matrix,"Let $M$ be the manifold of real positive definite $n \times n$ matrices, define a mapping $i:A \to \sqrt A$ (where $A\in M$ and $\sqrt A$ means the unique positive definite square root of $A$). Please show that $i$ is smooth.","['matrices', 'differential-geometry']"
825990,Prove or disprove that trace of matrix $X$ is zero,"I was trying to solve a question  from a competitive exam paper.
This is a part of that question. Let $I_n$ and $O_n$ be $n\times n$ identity and null matrices respectively.Let $S$ be $2n\times 2n$ matrix given in block form by $$S=\begin{bmatrix} O_n & I_n \\ -I_n & O_n\end{bmatrix}$$ If $X$ is a $2n\times 2n$ matrix such that $X^tS+SX=O_{2n}$ then determine wheather trace of $X$ is zero or not. From the given information in the question I just managed to find that $S^t=-S$ (i.e $S$ is skew symmetric) and det( $S$ )= $1$ . Then $SX=-X^tS=X^tS^t=(SX)^t\Rightarrow SX$ is symmetric. Also det( $SX$ )=det( $X$ ). Am I right upto this?and I do not know whether these are necessary or not to solve the problem. I can not proceed further,completely stuck. Please help.Thnx in advance.","['trace', 'matrices', 'linear-algebra', 'block-matrices']"
826011,Solve an equation for a particular variable using Wolfram Alpha,"I want to express variable from equation in WolframAlpha web. I tried several keywords but it didn't work. For example I have equation $$y=x+z+k,$$ and I want Wolfram to rewrite it for variable $x$, $x=y-z-k$. Is it possible and how?","['online-resources', 'wolfram-alpha', 'algebra-precalculus']"
826019,Field homomorphism into itself,"Suppose $F$ is algebraic over $\mathbb{Q}$ and $\varphi \colon F \to F$ is a homomorphism. Prove that $\varphi$ is an isomorphism. I came across this question here but I don't quite get why $F$ has to be algebraic over a field. I know $\phi$ is injective since $\ker(\phi) = 0$. Shouldn't it then follow that $\phi$ is an isomorphism since $F$ and $F$ have the same cardinality? Can anyone give a counterexample? Edit: I also don't get why $\phi$ is surjective. Let $\alpha$ be an element of $F$.
  Let $f(X)$ be the minimal polynomial of $\alpha$.
  Let $S$ be the set of all the roots of $f(X)$ in $F$.
  $\varphi$ induces an injective map $S\to S$.
  Since $S$ is a finite set, this map is surjective.
  Hence $\varphi$ is surjective. Since $\phi$ maps $S$ onto $S$, how does that imply $\phi$ is surjective in the whole field?","['extension-field', 'abstract-algebra', 'field-theory']"
826027,Show that there exist $g\in C^{\infty}$ such that $f(x)=g(x^2)$,"Let $f\in C^{\infty}(\mathbb{R},\mathbb{R})$ , even,. Show that there exist $g\in C^{\infty}(\mathbb{R^+},\mathbb{R})$ such that for all $x\in \mathbb{R}, f(x)=g(x^2)$ My attempt : Let $g$ the function defined on $\mathbb{R^+}$ by $g(x)=f(\sqrt{x})$ , it's clear that $g$ is continuous on $\mathbb{R^+}$ and $C^{\infty}$ on $\mathbb{R^+_*}$ . So the problem is to find the limit at $0$ but I don't know how can I proceed. EDIT: Here $\mathbb{R^+}=[0,+\infty)$","['functions', 'real-analysis']"
826039,Functions that are continuous only at two points?,"I need to find a function $f:\mathbb{R}\to\mathbb{R}$ which is continuous only at two points, but discontinuous everywhere else. How on earth would I go about doing this? I can't think of any function like this. Thanks in advance. Edit: I've seen examples including the indicator function for rationals. Is this the only method of finding such functions?","['functions', 'continuity', 'real-analysis']"
826046,Solving $X+X^T=tr(X)M$,"Let $M$ be a $n\times n$ complex matrix. Solve the equation $X+X^T=tr(X)M$ where $X$ is a $n\times n$ complex matrix. I've done some case-checking. Suppose $X$ is a solution. if $tr(X)=0$ , then $X$ is skew-symetric, and any skew-symetric matrix satisfies the equation if $tr(X)\neq 0$ , if $tr(M)\neq 2$ , there's a contradiction. If $tr(M)=2$ , and $M$ is not symetric, we reach a contradiction. if $tr(M)=2$ and $M$ is symetric, I don't know what to say. I've prefered an abstract approach so far, should I start looking at what happens with entries ?","['matrices', 'linear-algebra']"
827058,"minimum and maximum of $f(x,y)=\sin(x)+\sin(y)-\sin(x+y)$","we are asked to find the minimum and maximum of the function$f:A \to A$ $f(x,y)=\sin(x)+\sin(y)-\sin(x+y)$ Where $A$ is the triangle bound by $x=0$,$y=0$ and $y=-x+2\pi$ I'd like someone to review my answer. What I did: $A$ is a closed and bounded set, $f(x,y)$ is continuous, so according to Weierstrass theorem, $f$ receives maximal / minimal values, either on the boundary, or an internal point $(a,b)$ where $\triangle f(a,b)=(0,0)$,($\triangle$ represents gradient.) First let's find points where the gradient is zero: $\triangle f(x,y)=(\cos(x)-\cos(x+y),\cos(y)-\cos(x+y))=0$ this implies $\cos(x)=\cos(y)=\cos(x+y)$. On the triangle we were given, this can only happen at $(0,2\pi)$ or $(2\pi,0)$, otherwise we are outside the boundaries of the triangle. and $f(0,2\pi)=f(2\pi,0)=0$. Let's see what happens on the boundary, assume first $x=0$: $f(0,y)=\sin(0)+\sin(y)-\sin(0+y)=0$ Same thing happens when $y=0$. Now let's see $y=-x+2\pi$: $f(x,-x+2\pi)=\sin(x)+\sin(-x+2\pi)-\sin(x+x-2\pi)=\sin(x)+\sin(-x)-\sin(2x)=\sin(x)-\sin(x)-\sin(2x)=-\sin(2x)$ Let's denote $g(x)=-\sin(2x)$, then $g'(x)=-2\cos(2x)$. $g'(x)=0$ implies $\cos(2x)=0$, which implies $2x=\frac{\pi}{2}+k\pi$, then $x=\frac{\pi}{4}+k\frac{\pi}{2}$ The only such valid point on our triangle would be the point $(\frac{\pi}{4},\frac{7\pi}{4})$. and at that point: $f(\frac{\pi}{4},\frac{7\pi}{4})=\sin(\frac{\pi}{4})+\sin(\frac{7\pi}{4})-\sin(2\pi)=0$ At all the potentially extreme points, we got $f=0$. this makes me believe that $f(A)=\{0\}$. There is no point on the triangle where $f$ is not zero. Is this true? Is it possible to verify this result with trigonometric identities? to simplify $\sin(x)+\sin(y)-\sin(x+y)$ and eventually hope to reach zero?","['multivariable-calculus', 'calculus', 'proof-verification', 'derivatives']"
827072,Finding an equation of circle which passes through three points,"How to find the equation of a circle which passes through these points $(5,10), (-5,0),(9,-6)$
using the formula 
$(x-q)^2 + (y-p)^2 = r^2$. I know i need to use that formula but have no idea how to start, I have tried to start but don't think my answer is right.","['geometry', 'algebra-precalculus', 'analytic-geometry', 'matrices', 'linear-algebra']"
827146,ODE with additional term,"In an application I encountered the ODE 
$$ \left( x^2-1 \right) \frac {{\rm d}^{2}}{{\rm d} x^2} f
 ( x ) +x \left( \frac {\rm d}{{\rm d}x} f (x)  \right) ( 8x^2-7 ) -4 (C+1) f( x ) =0.
$$
 I don't see how I can find any solution analytically. Does anybody here know whether solutions to this function are known or whether there are any solutions that we can write down? Has this particular ODE ever been studied? I am greatful to every comment. In particular, just a few more solution are helpful too, if you cannot identify them all.","['ordinary-differential-equations', 'special-functions', 'calculus', 'real-analysis', 'analysis']"
827202,Solving the differential equation $x^3y''+2x^2y-6xy = 0$,"First question on here, so I hope I'm doing this right.
I've been reading up on differential equations lately and have now stumbled upon one that I have no idea how to solve. $x^3y''+2x^2y-6xy = 0$ $y(1)=2$ $y'(1)=-1$ I've gotten fairly confident with differential equations of the type $ay'' + by' + cy = f(x)$, but I can't figure out how to work with this expression. If someone could point me into the right direction I would be very thankful! I don't have much of an attempted solution to post as I'm completely lost on this one. I would normally start by looking for roots to create the homogenous solution, but I imagine that I have to separate all the occurrences of x to the other side before I can do that. Without those, I would start by finding the roots with $p(r)=r^2 + 2 - 6$ leading to $r= \sqrt{4}$. I imagine I need to do something entirely different for this one though.","['ordinary-differential-equations', 'analysis']"
827212,Sum the following $\sum_{n=0}^{\infty} \frac {(-1)^n}{4^{4n+1}(4n+1)} $,"Evaluate: $$\sum_{n=0}^{\infty} \frac {(-1)^n}{4^{4n+1}(4n+1)} $$ I rewrote the sum as $$\sum_{n=0}^{\infty} \frac {1}{4^{8n-7}(8n-7)} - \sum_{n=0}^{\infty} \frac {1}{4^{8n-3}(8n-3)}$$ Now, I tried to express this as a Geometric Series and Partial Fraction but was unable to do so. I also tried to use Riemann Sum, but I don't know how to apply it here. Any help will be appreciated. Thanks!","['sequences-and-series', 'power-series', 'calculus', 'algebra-precalculus']"
827237,Flux of a vector field.,"In $\mathbb{R}^3 \setminus \{0\}$, it's given the vector field $$\vec{E}(\vec{r}) = g(r) \vec{r}$$
where $g$ is some function of class $\mathcal{C}^\infty$ defined in $[0, + \infty[$, $\vec{r} = (x,y,z)$ and $r = \sqrt{x^2 + y^2 + z^2}$. Also, $\mathrm{div} \hspace{.5pt}\vec{E}(\vec{r}) = r g'(r) + 3g(r)$. I have to compute the flux of $\vec{E}$ through the sphere $S_a^2$. My 1st attempt : Denoting by $B_a$ the ball centered in the origin with radius $a$, and using the divergence theorem, I have: $$\int_{S_a^2} \vec{E} \cdot \vec{N} \hspace{.5pt}\mathrm{d}S = \int_{B_a} r g'(r) + 3g(r) \hspace{.5pt} \mathrm{d}V$$
Using spherical coordinates, I would calculate: $$\int_{0}^{2\pi} \int_{0}^{\pi} \int_{0}^{a} \left(r g'(r) + 3g(r) \hspace{.5pt}\right)r^2 \sin{\varphi} \mathrm{d}r  \mathrm{d}\varphi  \mathrm{d}\theta = 4\pi \int_{0}^{a} \left(r g'(r) + 3g(r) \hspace{.5pt}\right)r^2 \mathrm{d}r$$ My 2nd attempt : By definition. $$\int_{S_a^2} \vec{E} \cdot \vec{N} \hspace{.5pt}\mathrm{d}S = \int_{[0,2\pi] \times [0, \pi]} \vec{E}(X(\theta, \varphi))\cdot (-a^2 \sin \varphi \cos \varphi, -a^2 \sin^2 \varphi \sin \theta, -a^2 \sin^2 \varphi \cos \theta) \mathrm{d}\theta \mathrm{d}\varphi$$ where $X$ is a parametrization of the sphere using spherical coordinates. However, I'm having trouble computing $\vec{E}(X(\theta,\varphi))$. Does not make any sense to me. I would make $(x,y,z) = (r \sin \varphi \cos \theta, \cdots )$ or $(x,y,z) = (a \sin \varphi \cos \theta, \cdots )$? In the first case, $r$ is a variable but the integral is only on $\theta$ and $\varphi$. There is no way to give an answer without it being in terms of integrals of $g$, is it? If someone know an easy way to solve this, it is also welcome. Thank you.","['multivariable-calculus', 'calculus', 'integration']"
827254,Representation of Stochastic Integrals as Lebesgue/Bochner Integrals,"Just as the Riemann–Stieltjes integral can be equivalently defined as a Lebesgue integral with the corresponding Lebesgue–Stieltjes measure, I am looking for the corresponding results for the relationship between Stochastic integrals (both Ito and  Stratonovich) and Bochner Integrals (or any other integral taking values in Banach spaces). I'm also looking for results on the corresponding measure defined on the relevant Banach Spaces. Information pertaining to Stochastic integrals with integration with respect to Brownian motion is more than welcome, but I am looking for results pertaining more to integrals with integration in respect to more general semi-martingales.  Any references or results you can forward to me is greatly appreciated. Thanks.","['banach-spaces', 'measure-theory', 'probability-theory', 'lebesgue-integral', 'functional-analysis']"
827287,$\lim_{x \to 0} \frac{e^{\sin2x}-e^{\sin x}}{x}$ without L'Hospital,Anyone has an idea how to find $\displaystyle\lim_{x \to 0} \dfrac{e^{\sin2x}-e^{\sin x}}{x}$ without L'Hospital? I solved it with L'Hospital and the result is $1$ but the assignment is to find it without L'Hospital. Any idea?,"['real-analysis', 'limits']"
827304,Need algebra tip about $a^4 + b^4 + c^4 - 2b^2c^2 - 2a^2b^2 - 2a^2c^2$ for sides of a triangle,"I just got a long expression:
$$a^4 + b^4 + c^4 - 2b^2c^2 - 2a^2b^2 - 2a^2c^2$$
and I need to prove its less than zero for every $a$, $b$, and $c$ which are triangle sides I really need tips how to handle such large expressions so they can be more useful for me.
I know that I should probably get something  sort of $(a+b+c)^2$ but I cant really find a way to do it , I tried some ways but a general rule that helps would be useful ...","['inequality', 'geometry', 'triangles', 'algebra-precalculus']"
827352,Area of projected surface,"Suppose I have a surface given by $z=f(x,t)$, $a\le x \le b$ and $c\le t \le d$. How can I find the area of the surface projected onto the $(x,z)$ plane? We may assume appropriate monotonicity conditions to have a nice projection.","['multivariable-calculus', 'calculus']"
827361,What is the sum of this? $ 1 + \frac12 + \frac13 + \frac14 + \frac16 + \frac18 + \frac19 + \frac1{12} +\cdots$,"I'm in trouble with this homework. Find the sum of the series $ 1 + \frac12 + \frac13 + \frac14 + \frac16 + \frac18 + \frac19 + \frac1{12} +\cdots$, where the terms are the inverse of the positive integers whose only prime factors are 2 and 3. Hint : write the series as a product of two geometric series. Ok, I found some patterns in these numbers, but I can't find the two series.","['sequences-and-series', 'calculus']"
827365,How to prove $ A \cup \{a\} \approx B \cup \{ b \} \Rightarrow A \approx B $,"How to prove this without recurring to cardinality? $ A \cup \{a\} \approx B \cup \{ b \} \Rightarrow A \approx B $ Where by ""$ \approx $"" I mean that there exists a bijective function between A and B (called equipollence, equipotence, equinumerosity). It seems fairly obvious because, if you get those additional elements out, then you have the same cardinality in both sides. The problem is, I have to find a way to prove it using the bijection definition. So my guess is, I know that $ \exists f: (A \cup \{a\}) \rightarrow (B \cup \{ b \}) $ that is bijective. So there must exist $g: \{a\} \rightarrow \{ b \} $, which is clearly bijective, so that $\exists h: A \rightarrow B $ that is also bijective. The problem with this reasoning is that, I don't really know if this is true. What if the promised bijective function pairs some element from $A$ with $\{b\}$, and $\exists! x\in A , y \in B/ (x,y) \notin f$. Is this an issue at all? Or I can assume that this bijective function will pair each element from $A$ with each element in $B$, and $\{a\}$ with $\{b\}$? Edit: To avoid confusions, I'm going to add some context. This is part of a bigger proof, namely: $ A \sqcup \{u\} \approx B \sqcup \{u\} \Rightarrow A \approx B $, where $\sqcup$ is disjoint union. This is the same as saying: $ (A \times \{a\}) \cup \{(u,b)\} \approx (B \times \{c\}) \cup \{(u,d)\} \Rightarrow A \approx B $ Where $ a \neq b \wedge c \neq d $ In the original question I'm using $a$ instead of $\{(u,b)\}$, $b$ for $\{(u,d)\}$; $A$ for $(A \times \{a\})$, and $B$ for $(B \times \{c\})$ I think it's safe to assume that, knowing this, the original $a$ can't belong to the original $A$, and so on.",['elementary-set-theory']
