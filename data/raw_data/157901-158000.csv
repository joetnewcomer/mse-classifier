question_id,title,body,tags
2702959,Solve trig function for $x$,For what value(s) of $x$ does the following function satisfy? $$ \dfrac{-16}{9} = \dfrac{\cos(18x)}{\cos (24x)} $$ Unsure if I need an identity to solve or it's just basic.,['trigonometry']
2703103,Commutator of bounded operators and tensor product,"Let $E$ be an infinite-dimensional complex Hilbert space, $E\otimes E$ be the Hilbert space tensor product and $$\mathcal{L}(E)^+=\left\{A\in \mathcal{L}(E);\,\langle Ax,x\rangle\geq 0,\;\forall\;x\in E\;\right\}.$$ Let $A,B,C,D\in \mathcal{L}(E)$ and $S_1,S_2\in \mathcal{L}(E)^+$ be non zero operators such that $$(S_1\otimes S_2)[A\otimes C,B\otimes D]=0.$$ I want to find sufficient conditions under which $S_1[A,B]=S_2[C,D]=0$ i.e. $S_1AB=S_1BA$ and $S_2CD=S_2DC$ . My attempt: Since $(S_1\otimes S_2)[A\otimes C,B\otimes D]=0$ , then $(S_1\otimes S_2)(A\otimes C)(B\otimes D)=(S_1\otimes S_2)(B\otimes D)(A\otimes C)$ . Hence $$S_1AB\otimes S_2CD=S_1BA\otimes S_2DC.$$ By using the following result: Lemma: Let $A_1, A_2,B_1, B_2\in \mathcal{L}(E)$ be non-zero operators. The following conditions are equivalent: $A_1\otimes B_1=A_2\otimes B_2$ . There exists $z\in \mathbb{C}^*$ such that $A_1 =zA_2$ and $B_1= z^{-1}B_2$ . We deduce the existence of $z\in \mathbb{C}^*$ such that $S_1AB=zS_1BA$ and $S_2CD=z^{-1}S_2DC$ . When we get $$z=1?$$","['functional-analysis', 'tensor-products', 'operator-theory']"
2703123,3 cards are dealt from a well shuffled deck.,"1. Find the chance that none of the cards are hearts. The answer is $\frac{39}{52}$ $\cdot$ $\frac{38}{51}$ $\cdot$ 
$\frac{37}{50}$ However, why can't we use complement rule here: 1- p(chance that all the cards are hearts)= 1- ($\frac{13}{52}$ $\cdot$ $\frac{12}{51}$ $\cdot$ $\frac{11}{50}$) 2. Find the chance that the cards are not all hearts. The answer given is: 1- ($\frac{13}{52}$ $\cdot$ $\frac{12}{51}$ $\cdot$ $\frac{11}{50}$) here I'm little confused as to why the complement rule was used. for chance that the cards are not all hearts why can't we use: P(1 heart) + P(2 heart) + P(No hearts)= ($\frac{13}{52}$ $\cdot$ $\frac{39}{51}$ $\cdot$ 
$\frac{38}{50}$) + ($\frac{13}{52}$ $\cdot$ $\frac{12}{51}$ $\cdot$ 
$\frac{39}{50}$) + ($\frac{39}{52}$ $\cdot$ $\frac{38}{51}$ $\cdot$ 
$\frac{37}{50}$)",['probability']
2703125,The Law of Total Covariance on a Gaussian Process,"Suppose that we have a Gaussian process with zero mean and covariance function $k$,
$$
  f(x) \sim \mathcal{GP}(0, K(x,x')) \tag{1}
$$ It is usually assumed that there are a collection of training inputs $X = [\mathbf{x}_0, \ldots, \mathbf{x}_N]$, and training outputs $\mathbf{f} = [f_0, \ldots, f_N]$, such that,
$$
  \mathbf{f} \sim \mathcal{N}(0, K(X,X)) \tag{2}
$$
see for example Gaussian Processes for Machine Learning by Rasmussen and Williams. My question how to, instead, deal with connected sets of known training points, i.e., $X = [X_0, \ldots, X_N] \subset \mathbb{R}^N$, with $X_i \cap X_j = \emptyset$, with constant training outputs, i.e. $f(x_i) = \kappa_i$ for every $x_i \in X_i$. Rather than viewing the sets themselves as random variables, with a specified covariance functions, I need to extend the idea of a Gaussian process defined by points over entire sets. The law of total covariance gives that,
$$
  \operatorname{Cov}(\kappa_i, \kappa_j) = \int_{X_i \times X_j} K(x_i, x_j)p(x_i, x_j) d(x_i,x_j)
$$
for random variables $\kappa_i$. This gives a covariance between the outputs, using a covariance function which is defined in terms of points. Is there a way of using the process notation, such as in (1) or (2), to deal with this idea properly?","['stochastic-processes', 'statistical-inference', 'stationary-processes', 'statistics', 'probability']"
2703134,The connection between the solution set $\{F^{\nu}=0\}$ being invariant under a Lie group action and $DF$ having full rank,"Suppose we have a function $F:M\rightarrow\mathbb{R}^l$ from a smooth $m$-manifold $M$ to $\mathbb{R}^l$, where $l\le m$. If we denote the components of $F$ by $F^{\nu}$, we can define a system of $l$ equations: $$F^{\nu}(x)=0.\tag{1}$$
for $\nu=1,\ldots,l$. Let $G$ be a (connected local) Lie group of transformations on $M$, suppose we want to find the condition for the solution set $(1)$ to be invariant under $G$. Note that $F$ itself need not be $G$-invariant. I would naively expect that the solution set to $(1)$ would be invariant iff $w(F^{\nu})=0$ for every infinitesimal generator $w$ of $G$, since (representing the exponential map as $e^{\epsilon w}$)
$$F^{\nu}(e^{\epsilon w}x)=F^{\nu}(x)+w(F^{\nu})(x)\epsilon+o(\epsilon),\tag{2}$$
and so
$$\left.\frac{d}{d\epsilon}F^{\nu}(e^{\epsilon w}x)\right\rvert_{\epsilon=0}=w(F^{\nu})(x).\tag{3}$$
The left hand side will be zero iff the right hand side is. However, it turns out (Theorem 2.8 in Olver's "" Applications of Lie Groups to Differential Equations "") that in addition to $(3)$ you also need the differential $DF$ to have maximum rank (on the solution set $(1)$). Could someone please tell me what I'm missing that makes (1-3) invalid?","['differential-geometry', 'lie-groups']"
2703191,Equality of elements of set,"Suppose you have a set of 2n+1 real numbers with the property that taking any one element out of the set, you can arrange the remaining 2n elements into two groups (each group having n elements only)  of equal sum. Prove all elements are equal. I tried proving it using induction. 
Suppose it is true for some $2n+1$.
Then I tried to prove that it must be true for $2(n-1)+1$ elements also. The condition is easily established for 3 elements.  So I thought that induction could work.  But I was unable to do so. Any hint regarding how to prove this using induction or another method would be appreciated.","['number-theory', 'abstract-algebra', 'elementary-number-theory']"
2703202,"In an integral extension $A\subseteq B$, when $B$ Noetherian implies $A$ Noetherian?","Let $A\subseteq B$ be an extension of commutative rings. If $B$ is a Noetherian ring and finitely generated as $A$ -module, then $A$ is Noetherian ring. Is there any other such criteria, under possibly some additional conditions, which says that in an integral extension, if the above ring is Noetherian, then so is the below ring ?","['integral-extensions', 'noetherian', 'abstract-algebra', 'reference-request', 'commutative-algebra']"
2703203,Basis of infinite Vector Space $\mathbb R^{\infty}$ [duplicate],"This question already has answers here : Is there a constructive way to exhibit a basis for $\mathbb{R}^\mathbb{N}$? (3 answers) Closed 6 years ago . I have a question about one example in Linear Algebra. Let $\mathbb R^∞$ be the vector space of infinite sequences $(\alpha_1, \alpha_2, \alpha_3, \ldots )$ of real numbers. Scalar multiplication are defined in the natural way: the sum of $(\alpha_1 , \alpha_2 , \alpha_3 , \ldots )$ and $(\beta_1,\beta_2,\beta_3,\ldots)$ is $(\alpha_1 +\beta_1, \alpha_2 + \beta_2, \alpha_3 + \beta_3,\ldots)$ the product of $(\alpha_1,\alpha_2,\alpha_3,\ldots)$ by a scalar $\lambda$ is the sequence $(\lambda \alpha_1, \lambda\alpha_2, \lambda\alpha_3, \ldots )$ . There exists infinite linear independent set of vectors $(e_1, e_2, e_3, \ldots)$ \begin{align}
e_1 &= (1, 0, 0, \ldots)\\
e_2 &= (0, 1, 0, \ldots)\\
& \,\,\,\vdots
\end{align} The problem is that this set (lets call it $X$ ) is not a basis of this vector space. Because for example $v = (1, 1, 1, \ldots)$ cannot be written as a linear combination of set $X$ (Linear combination must be a finite sum). My task is to add ""some vectors"" to the set $X$ to create a basis of that vector space. If I add $v$ its not basis ( $\langle X, v\rangle \ne\mathbb R^∞$ ) Is there any proof that the process of adding vectors to set $X$ is not finite? Or is it possible to create a basis with adding vectors to $X$ ? Thanks for answers","['linear-algebra', 'axiom-of-choice', 'vector-spaces']"
2703232,Is the fourth root of 2 constructible? [duplicate],"This question already has answers here : Compass-and-straightedge construction of the square root of a given line? (5 answers) Closed 6 years ago . Is $2^{1/4}$ (fourth root of two) constructible using only a straight edge and compass? How would you construct it? I understand that a number is constructible if it can be done in a finite number of step in a field. I believe it is constructible because the degree of $Q(2^{\frac{1}{4}}$ over the rationals is $[Q(2^{1/4})): Q] = 4$, which has the form $2^k$. The degree is 4 because a basis for $2^{1/4}$ is $${1, 2^{1/4},2^{1/2}, 8^{1/4}}.$$ Is this reasoning correct? If it is constructible, do I need to find the four roots of unity and multiple each by $2^{1/4}$? And then how do I proceed from there?","['abstract-algebra', 'geometric-construction']"
2703255,Non-negativity of an integer,"Describe all non negative integers using only the constant symbols $0,1$, operations $+,\cdot$ and relation $=$ on $\mathbb Z$. In the reals, a similar description is simple, we just say $x\geq 0\iff \exists y: y\cdot y = x$. In the integers, however, that doesn't work. There's no $\sqrt{2}\in\mathbb Z$, for instance. We could say
$$x\geq 0 \iff x=0\lor x=1\lor x=1+1\lor\ldots $$
but that's not satisfactory since it's not finite. I always seem to be stuck defining it via itself, provided the expression is finite. What am I missing? It would also be sufficient to describe negative integers.","['predicate-logic', 'logic', 'discrete-mathematics']"
2703316,Find a number that satisfies two congruences,"I have an exercise of finding a number that satisfies two congruences. $$
\left\{
\begin{array}{cc}
x &\equiv 10 \mod 30 \\
x &\equiv 5 \mod 101
\end{array}
\right.
$$ The exercise suggests 4 steps to solve: Step 1: find integers $s$ and $t$ such as $30s + 101t = 1$ Step 2: use s and t to find a number satisfying: $$
\left\{
\begin{array}{cc}
a &\equiv 10 \mod 30 \\
a &\equiv 0 \mod 101
\end{array}
\right.
$$ Step 3: use s and t to find a number satisfying: $$
\left\{
\begin{array}{ccc}
b &\equiv& 0 \mod 30 \\
b &\equiv& 5 \mod 101
\end{array}
\right.
$$ Step 4: use the result from step 2 or 3 to find x. ($x \equiv 10 \mod 30 $,$x \equiv 5 \mod 101$) I went through the first 3 steps without problems, but I dont't know how to do step 4 since I could also use s and t to find x (without going to step 2 or 3). Thank you","['congruences', 'discrete-mathematics']"
2703345,"$f$ has no interior extreme point, therefore, $f$ is strictly increasing or decreasing function","I would like some input in my proof for this question. I solved using two different approaches, and would like to know where can I improve. I'm specially interested in a proof that does not use the fact that a strictly increasing function has $f'(x) \gt 0, \forall x \in I$. Let $a \lt b, [a,b] \in \mathbb{R}$ and $f:[a,b] \to \mathbb{R}$ be continuous in $[a,b]$. Suppose that there are no interior points that are local extreme. Show that $f$ is strictly increasing or decreasing. $\textbf{Answer 1}$: Suppose by contradiction that $f$ is not strictly increasing. Let $x,y,z \in [a,b]$ and assume that $x \lt y \lt z$. Therefore, $f(x) \lt f(y) \gt f(z)$. Consider the closed interval $[x,z]$. Since $f(y)$ is greather than both $f(x)$ and $f(z)$, neither $f(x)$ or $f(z)$ can be the maximum value of $f$ over $[x,z]$. However, since the interval is compact, $f$ attains its maximum over this interval. Therefore, $\exists t \in [x,z]: f(t) \gt f(w), \forall w \in [x,z]$. Since $t$ is an interior point of $[x,z]$, it is an interior point of $[a,b]$, hence it is a local maximum of $f$ in $[a,b]$, which is a contradiction. The proof is analogous for the case where $f$ is strictly decreasing. $\textbf{Answer 2}$: Since $\nexists c \in (a,b):f'(c)=0$, $f'(c)\gt0$ or $f'(c) \lt0, \forall c \in (a,b)$ . Without loss of generality, assume that $f'(c) \gt 0, \forall c \in (a,b)$. Consider the closed interval $[x_{1},x_{2}] \subseteq (a,b)$, with $x_{1} \lt x_{2}$.By the Mean Value Theorem, $\exists d \in (x_{1},x_{2}):f'(d) = \frac{f(x_{2})-f(x_{1})}{x_{2}-x_{1}}$. Since $f'(d) \gt 0 \implies f(x_{2}) \gt f(x_{1})$, therefore, $f$ is strictly increasing.","['derivatives', 'real-analysis', 'continuity', 'proof-verification']"
2703357,What is a good statistical test to use to compare 2 models,"I have already posted this question on Stats stackexchange so I am unsure whether I am allowed to post it here to. I am asking what would be a good/suitable investigation/test to use when trying to compare 2 models. So for my model in question, I am looking at the Lac Operon model and I add in substace $Y$ into the model and it produces enzyme $X$. The objective of adding $Y$ into the system is the produce as much $X$ as possible. I want to investigate if it is better to add all my $Y$ into the system in one big go (let's say I add 10,000 in all together), or to add say 2,000 $Y$ in at 5 even time intervals, or to add 1,000 of $Y$ in in 10 even time intervals. I am wondering what sort of statistical analysis should i be using here, or what sort of tests should I be performing.  I know I could just look at the amount of $X$ produced for each variation of my model, but I am looking for more intricate tests to perform. Now my models aren't linear models so I am unable to do anova using R , they are actually stochastic models. They are a series of chemical equations but I am basically just interested in the value of $X$, so i doubt the specifics of the model are needed to be known. Edit: May I propose another question to you. So to follow on from my earlier point, basically I have a system of chemical equations, and the rate constants from these equations follow a gamma distribution. Should I be testing rate constants against each other, or should I be testing the data against each other? Edit: Maybe I could test the comparison of the rate constants for my 2 models by using Bayesian Inference? I was wondering what would be a suitable test to compare to posterior/prior distributions rather than just using Bayes Factors??","['stochastic-processes', 'statistical-inference', 'hypothesis-testing', 'bayesian', 'statistics']"
2703382,Shouldn't $2^x \sin\frac{180}{2^x}$ approach $\pi$ as $x$ gets large?,"Take a  circle with diameter $1$. Obviously its circumference is $\pi$. Draw a square inside this circle (biggest such). Since the circle's diameter is 1, we can work out that each side of the square would be $\frac{1}{\sqrt{2}}$. Its perimeter, therefore, is $2\sqrt{2}$. Imagine a triangle being drawn over each side of the square, so as to create a regular octagon. Using the law of sines, we can work out the measure of each side of the octagon. The base of each triangle would be $\frac{1}{\sqrt{2}}$, and the angle opposite to it $135^o$. Each of the other angles would be $\frac{180-135}{2} = 22.5^o$.
So, $$
\frac{1}{\sin135(\sqrt2)} = \frac{x}{\sin22.5}
$$
$$
1 = \frac{x}{\sin22.5}
$$
$$
x=\sin22.5
$$ Therefore the perimeter of this octagon is $8\sin22.5$. We can continue drawing triangles on this octagon, and more triangles on that, and so on. Once the number of sides reaches infinity (which, of course, is not possible in the physical world), the perimeter of the said figure would be $\pi$. I am trying to write a similar function $f(x)$ such that
$$
\lim_{x \to 0}f(x) = \pi
$$ Note that $f(x)$ is a function of levels. Level 1 is for 4 sides, level 2 is for 8 sides, then 16 sides, 32 sides and so on. Insofar:
$$f(1) = 2\sqrt2 = 4 \sin 45$$
$$f(2) = 8 \sin22.5$$
$$...$$ I work out that $$f(x) = 2^x \sin\frac{180}{2^x}$$ When graphing that function: Given this, it doesn't seem to limit on the graph. Say, if it does limit to $\pi$, would it approximate $\pi$ for a relatively large $x$? Please note. There might be a lot of mistakes here. I'm not studying math at the college-level and is a careless person.","['trigonometry', 'geometry']"
2703402,On $3+\sqrt{11+\sqrt{11+\sqrt{11+\sqrt{11+\dots}}}}=\phi^4$ and friends,"Let $\phi$ be the golden ratio . We know it has a beautiful infinite nested radical, $$\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+\dots}}}}=\phi$$ However, it is also the case that, $$3+\sqrt{11+\sqrt{11+\sqrt{11+\sqrt{11+\dots}}}}=\phi^4$$ $$5+\sqrt{31+\sqrt{31+\sqrt{31+\sqrt{31+\dots}}}}=\phi^5$$ $$\tfrac{17}2+\sqrt{\tfrac{319}4+\sqrt{\tfrac{319}4+\sqrt{\tfrac{319}4+\sqrt{\tfrac{319}4+\dots}}}}=\phi^6$$ Q: How do we show that, in general $$a_n+\sqrt{b_n+\sqrt{b_n+\sqrt{b_n+\sqrt{b_n+\dots}}}}=\phi^n$$ where, $$a_n = \frac{L_n-1}2,\quad b_n = \frac{5F_n^2-1}4$$ with Lucas numbers $L_n$ and Fibonacci numbers $F_n$?","['lucas-numbers', 'fibonacci-numbers', 'golden-ratio', 'nested-radicals', 'sequences-and-series']"
2703410,Prove that $\mathbb{Z}\times\mathbb{N}$ is not isomorphic to $\mathbb{Z}\times\mathbb{Z}$ (both strictly ordered): is my proof correct?,"I must prove that $\mathbb{Z}\times\mathbb{N}$ and $\mathbb{Z}\times\mathbb{Z}$ (both strictly ordered, the second coordinate is the 'main' one) are not isomorphic. I wrote a proof, but I don't know if it's rigourous enough or even correct, and I would be grateful for pointing out mistakes and guiding to how to do it better. The proof is: $\triangleleft$
In $\mathbb{Z}\times\mathbb{Z}$, for every ordered pair $\langle x, y\rangle $ (including the pairs of type $\langle x, n\rangle $) there exists a subset of ordered pairs that have the same first coordinate and lesser second coordinate: $\{\langle x, y-1\rangle , \langle x, y-2\rangle , \langle x, y-3\rangle , \dots\}$. The cardinality of this set is $\aleph_0$. In $\mathbb{Z}\times\mathbb{N}$, for every ordered pair of type $\langle x, n\rangle $ there exists a subset of ordered pairs that have the same first coordinate and lesser second coordinate: $\{\langle x,n-1\rangle ,\langle x, n-2\rangle ,\dots\langle x, 1\rangle \}$. The cardinality of this set is $n-1$, where $n$ is a natural (and, therefore, finite) number. Since isomorphism preserves the order, if sets $A$ and $B$ are isomorphic, then their subsets $\dot A \subset A$ and $\dot B \subset B$ constructed by the same rule should also be isomorphic.
However, in our construction even cardinalities don't match: one is infinite, another one is not.
The Cartesian products in question are not isomorphic, therefore. 
$\triangleright$ I did search through the stackexchange and clicked the proposed links while writing this question, but, unfortunately, found nothing. Thank you a lot! Here's a new proof (note: in the proof above, $0$ was not considered a natural number; in the proof below, it is): $\triangleleft$
The ordering: the major index is the second coordinate. Assume the contrary:  $\mathbb{Z}\times\mathbb{N}$ is isomorphic to  $\mathbb{Z}\times\mathbb{Z}$. Then, $\langle 0, 0\rangle $ from $\mathbb{Z}\times\mathbb{N}$ is mapped to some $\langle a, b\rangle $  in $\mathbb{Z}\times\mathbb{Z}$. With both $\langle 0, 0\rangle $ and $\langle a, b\rangle $ there is associated a subset of either $\mathbb{Z}\times\mathbb{N}$ or $\mathbb{Z}\times\mathbb{Z}$ comprised of lesser elements: $\{\dots, \langle -z, 0\rangle , \dots, \langle -2, 0\rangle , \langle -1, 0\rangle \}$ $\subset$ $\mathbb{Z}\times\mathbb{N}$ for $\langle 0, 0\rangle $, $\{\dots, \langle x, b-1\rangle , \dots, \langle a-2, b\rangle , \langle a-1, b\rangle \}$ $\subset$ $\mathbb{Z}\times\mathbb{Z}$ for $\langle a, b\rangle $. Since isomorphism preserves the order, $\langle a-1, b\rangle  \mapsto \langle -1, 0\rangle , $ $\langle a-2, b\rangle  \mapsto \langle -2, 0\rangle $ and so on. Now, where would we map $\langle x, b-1\rangle $? We would have to map it to some element given by formula $\langle -z, 0\rangle $ (it's the only available option). However, between $\langle -z, 0\rangle $ and, say, $\langle -2, 0\rangle $ there is a finite amount of pairs, and between $\langle x, b-1\rangle $ and $\langle a-2, b\rangle $ there is an infinite one. But for isomorphism to exist, these amounts must be equal. Contradiction.
$\triangleright$","['elementary-set-theory', 'proof-verification']"
2703415,$27$ lines on a cubic with multiplicity. Contradiction?,"A previous poster asked a question whether there are $27$ lines on every cubic surface allowing for multiplicities. I started to think about this and now I am really confused as I have both a proof and a counterexample. First, there are cubic surfaces with infinitely many lines, that is fine, but if there are finitely many lines how many are there ? There is a correspondence (not 1-1) $$\left\{\begin{aligned}
&\text{Cubic Surfaces}\\
&\text{ in $\mathbb{P}^3$ }\\
\end{aligned}\right\}\leftrightarrow 
\left\{\begin{aligned}
&\text{Lines  }\\
&\text{ in $\mathbb{P}^3$  }\\
\end{aligned}\right\}$$
Where each surface corresponds to those lines which line on the surface, and the lines to those surfaces which contain it. This is an irreducible correspondence, the variety on the left is just $\mathbb{P}^{20}$, so it is irreducible with no singular points, the variety on the right is the Plucker quadratic in $\mathbb{P}^5$. Now the general cubic surface corresponds to $27$ lines, and by specialization to any specific surface (which is a simple point in $\mathbb{P}^{20}$) these $27$ lines will specialize and we get $27$ lines counted with multiplicity. (It is a theorem that this is well defined if the point in $\mathbb{P}^{20}$ is simple, which it is.) On the other hand here is my counterexample, (due to van der Waerden) Let 
$$f_3(x,y,z)+f_2(x,y,z)=0$$ be a cubic surface in $3$ space (written in affine coordinates), where $f_3$ and $f_2$ are homogeneous polynomials of degree $3$ and $2$ respectively. And assume that the surface has a double point at the origin. Then for lines through the origin, $x=ta,y=tb,z=tc$ we must have $$f_3(a,b,c)=0$$ and 
$$f_2(a,b,c)=0$$ this is the intersection of a cubic curve and a quadratic curve, so $6$ points in common, which we assume to be distinct. This gives $6$ lines through the origin. For a line not through the origin, take the plane through this line and the origin, it intersects the cubic in the line and another conic which must decompose into two lines, since the origin is a double point. The number of pairs of lines through the origin is $\binom{6}{2}=15$ and this gives $15$ lines not through the origin. Thus $6+15=21$ lines in total. Now if the first argument is correct then there must be some multiplicities in these lines. The lines through the origin are the simple intersections of a cubic and a conic, so cannot be multiple ? And in any case no two of them can be multiple since the plane through then would contain $4$ lines. Further the lines not through the origin cannot be multiple since the plane through them and the origin have three distinct lines. What is the truth here ? How to resolve this conflict ?","['surfaces', 'projective-geometry', 'algebraic-geometry']"
2703432,Evaluating $\lim_{x\rightarrow 0}\frac{\cos(ax) - \cos(bx)}{\sin^2(x)}$,"The problem is, as stated: $$\lim_{x\rightarrow 0}\frac{\cos(ax) - \cos(bx)}{\sin^2(x)}$$
  Of course, a and b are real numbers. I tried implementing the trig identity: $$\cos(ax)-\cos(bx) = -2\sin\frac{(ax-bx)}{2}\sin\frac{(ax+bx)}{2}$$ But that didn't really take me anywhere. 
In my book, similar problems were often solved this way but here that doesn't seem to work. One obviously has to try and use the known limit to reduce this to a more easy limit: $$\lim_{x \rightarrow 0}\frac{\sin(x)}{x} = 1$$ Any help would be much appreciated.","['real-analysis', 'limits', 'trigonometry', 'calculus', 'limits-without-lhopital']"
2703439,Real root of $x(x+t)^2-4=0$ $\ge$ greatest real root of $4x^6-6x^4+4t^3x^3+t^6-3t^4=0$,I have a problem that I can not solve although I know that the statement is true. For all  $t\ge0$ the real root of $x(x+t)^2-4=0$ is greater than or equal to the largest real root of $4x^6-6x^4+4t^3x^3+t^6-3t^4=0$. Does anyone have some idea to solve this problem?,['algebra-precalculus']
2703465,Are all primes the same?,"Are there properties ""intrinsic""* to primes that set them apart? Example 1: The fields $\mathbb{F}_p$ do not all have the same structure. If $p=1 \mod 4$ is a prime then there is a number $1<x<p$ where $x^{-1}=-x\mod p$, i.e. in the field $\mathbb{F}_p$, its multiplicative inverse is also its additive inverse. Moreover, this happens always and only when $p=1\mod 4$ and not when $p=3\mod 4$. Thus the odd primes are neatly divided into two classes with distinctly different properties. Example 2: The fields $\mathbb{F}_p$ yield good expander graphs, but some are better than others. For a prime $p$, construct an undirected graph on the vertices $\{0,1,\ldots,p-1\}$ as follows: node $n$ is connected to $n-1,n+1$ and $n^{-1}\mod p$. Let $\lambda_p$ be the spectral gap of the graph thus obtained (the difference between the two largest eigenvalues of the adjacency matrix). It follows from Selberg's 3/16 theorem that the resulting graph is a Ramanujan graph: it has an almost maximal spectral gap, hence these graphs are good expanders, and their diameter will be very small: only $\mathcal{O}(\log p)$. But some primes yield better expanders than others. I'm looking at a plot for the spectral gaps of primes up to 727, and there are no discernable local trends, although it looks like the spectral gap might converge to the expected value of $3-\sqrt{8}$. Are there more examples that show that not all primes are equal? This question is born of curiosity, so feel free to bring surprising results from any area of mathematics! *Of course there are twin primes, Sophie Germain primes and Mersenne primes, but these labels only show where a prime is located with respect to other numbers. For the purposes of this question, I am interested in properties ""intrinsic"" to a prime that set it apart from other primes.","['number-theory', 'big-list', 'prime-numbers']"
2703478,How can I solve a problem using the Chinese remainder theorem and how does mod operator is understood correctly?,"The situation is as follows: $$n = 3a + 2$$ $$n = 7b + 5$$ $$n = 8c + 9$$ Find the $n$ so it is less than $100$ and $a$ , $b$ and $c$ are positive integers. I know that this can be solved using the Chinese remainder theorem but I don't know how to use it. Therefore I'd like that somebody could explain me exactly how does $\mod{}$ operator works. The only thing I know is that $\bmod$ is used to express the remainder of an euclidean division. Like this $5$ divided by $2$ means: $5\,\bmod\,2 = 1$ Because the remainder is $1$ . But what if the situation is like this?: $2\,\bmod\,9$ Would this mean $$\frac{2}{9} = 0.2 \times 9 + 2 ?$$ So the remainder is $2$ ? It does not seem right as going backwards does not produce $2$ in the sense $0.2\times 9 + 2$ is not $2$ . How about negative numbers However how does it work with negative numbers? Like: $-3\bmod 25$ As mentioned above if I follow the same route I may find weird results. But that's only one part of the problem, as the second thing is How to understand this when $\mod{}$ is used as follows: $24\equiv 14 \left ( \bmod 10 \right )$ From what I had understood it means that both share the same remainder which is $4$ . But the problem lies on how to translate the equations I have been given into the equation from above, the one which uses $\mod{}$ ? Therefore I'd like somebody could help me with a clearly step-by-step solution that can explain how to build up the $\mod{}$ equations and how to solve them the easiest way possible.","['algebra-precalculus', 'chinese-remainder-theorem', 'arithmetic', 'elementary-number-theory']"
2703539,For $\{x_n\}\in X$ do we always have $\lim_{n\to\infty}\|x_n\| = 0 \quad \text{iff}\quad\lim_{n\to \infty}x_n=0?$,"Let $X$ be a normed vector space. Then for $x\in X$ we have that $$\|x\| = 0 \quad \text{if and only if} \quad x = 0.$$ Do we also have that for a sequence $\{x_n\}$ in $X$
$$\lim_{n\to \infty}\|x_n\| = 0 \quad \text{iff} \quad \lim_{n\to \infty} x_n = 0?$$ Can I take this to always be true?","['normed-spaces', 'sequences-and-series', 'limits']"
2703621,Explaining an example of a topology not induced by a metric,"My TA asked us whether every topology can be induced by a metric. He answered ""no"" and gave an example: For every set $X$ that satisfies $|X|>1$, its trivial topology (meaning $\{X,\emptyset \}$) isn't induced by any metric. 
His proof: let $x \neq y \in X$ and denote $d(x,y)=r$. So the set $B_\frac{r}{2}(x) = \{x\}$ is an open set which is not $X$ and not the empty set. What I don't understand is why necessarily $B_\frac{r}{2}(x) = \{x\}$? If we look at $\Bbb{R}$ and the standard absolute value metric $B_\frac{r}{2}(x)$ is never a singleton. In other words, he only looked at metrics in which $B_\frac{r}{2}(x)$ is a singleton. What am I missing?","['examples-counterexamples', 'general-topology', 'metric-spaces', 'proof-explanation']"
2703631,Some point in a line $Ax+By+C=0$,"Given a line in a 2D space, defined by equation $Ax+By+C=0$, is it possible to find a point of it without assume that A or B are different of 0 ? That is, usually the method to find some point is ""assume $A \ne 0$, if we fix $y=0$ the solution of the equation gives that point $(-C/A,0)$ is a point of the line, otherwise $B \ne 0$ and ...· But it is possible any other method without split the problem in two ? In other words, is it possible to find an expression for some point (any one) of the line that doesn't contains a division by A, B or C or by any other term that can be zero in some cases ? The question could be expressed in another way: given a line $Ax+By+C=0$, give an expression of the same line in vector/parametric form that is valid for any value of A, B, C. The direction vector is easy to find, (-B,A), the remainder target is to find the expression of some point.","['linear-algebra', 'analytic-geometry']"
2703675,Can a weakly Cauchy sequence in a non-complete inner product space be unbounded?,"Let $V$ be a non-complete inner product space, and let $x_n$ be a weakly Cauchy sequence, i.e suppose $\langle x_n, y\rangle$ converges for every $y \in V$. Is it true $x_n$ is bounded? I know this is true when $V$ is complete (Hilbert), but this uses Bair theorem. So, I guess there should be a counter-example when completeness is not assumed.","['functional-analysis', 'weak-convergence', 'weak-topology', 'inner-products']"
2703695,What are the finite subgraphs of the 2-dimensional square lattice?,"Consider the infinite graph $G = (V,E)$, where $V = \mathbb{Z}^2$ and each element is adjacent to its 4 cardinal neighbours, i.e.
  $$ E = \{(u,v) \in V^2 : \text{dist}(u,v) = 1\} $$
What are the finite subgraphs of $G$? There are several properties a graph $H$ must satisfy to be (isomorphic to) a subgraph of $G$: $H$ must be planar Every vertex in $H$ must have degree at most 4 $H$ must be bipartite The above conditions aren't sufficient. I initially hoped the key was in the cycles of $H$, but there is even an example of a tree satisfying the above conditions which is not a subgraph of $G$, for instance, this tree: https://i.sstatic.net/SDVST.jpg So my question is: is there a nice characterization of the finite subgraphs of $G$? Or at least an efficient algorithm for determining whether a particular finite graph is a subgraph of $G$?","['combinatorics', 'graph-theory', 'planar-graphs']"
2703703,How can a finite set not have a maximum or minimum?,Consider a set of real numbers such that $0\le x<1$. My book (Tom Apostol) says that this set do not have any maximum. How is it possible? Isn't the number just below $1$ the maximum of the set? Isn't that the least upper bound (supremum)? Why is $1$ the supremum?,"['real-analysis', 'supremum-and-infimum', 'elementary-set-theory']"
2703724,Gaussian Integral using single integration,"So the Gaussian integral basically states that: $$ I = \int_{-\infty}^{\infty} e^{-x^2} \ dx =\sqrt{\pi}$$ So the way to solve this is by converting to polar co-ordinates and doing a double integration. Since I haven’t learnt double integration, I have searched a lot to solve this kind of integral using single integration. But to no avail. I have even tried it myself a couple of times but have been unsuccessful. So here’s my question, is it possible to integrate the above using only single integration and if so how? If this is not possible to integrate using single integration then what is the reason behind it.","['gaussian-integral', 'integration', 'definite-integrals', 'calculus']"
2703770,Intuition behind the Banach fixed-point theorem,The theorem appeared as an exercise in my real analysis book and only considered functions in $\mathbb{R}$ but the proof of the general theorem seems to be almost identical after looking up the wikipedia article. Is there a somewhat intuitive way of thinking about this theorem? I understand the proof and what it entails but I don't see why the result ought to hold given the necessary conditions. Is there a way of convincing someone that the theorem ought to be true without actually proving it? Some vague geometric intuition would be nice to have a picture in my head of what's going on.,"['real-analysis', 'functions', 'fixed-point-theorems', 'sequences-and-series', 'analysis']"
2703773,Surface integral via differential forms,"I am trying to figure out why the change of variables formulas for surface integrals (for example) is what it is. I was wondering if there is a justification in terms of differential forms. So, let $g : V \to \mathbb{R}$ be a smooth function, andlet $S$ be the surface given by $G(V)$, where $G(x, y) = (x, y, g(x, y))$. In my current predicament, $V$ is an open subset of $\mathbb{R}^2$, but supposedly 2 may be replaced with general $n$. Let $F : S \to \mathbb{R}$ be a smooth function. I found the following formula online:
$$
\int_S F\,  dS = \int_V (F\circ G)\sqrt{g_x^2 + g_y^2 + 1}\ dA.
$$
Here $dA = dx \wedge dy$ is the standard area form. I have a few questions about this. Could someone recommend a rigorous proof of this fact, or perhaps a proof sketch? I am familiar with the change of variables formula when we are considering a change of variables by a diffeomorphism between open sets in $\mathbb{R}^n$, but this seems to fall apart here (since $S$ is not open in $\mathbb{R}^3$). I was trying to justify this with the machinery of differential forms. For instance, we know that if we define $\omega = F \, dS$ to be a 2-form on $S$,
$$
\int_S \omega = \int_V G^*\omega.
$$
This is where I get really confused. As far as I know, $G^*\omega$ is defined as follows: 
\begin{align*}
G^*\omega(x, y)(v, w) &= \omega(G(x, y))(dG(x, y)(v), dG(x, y)(w)) \\
&= \omega(G(x, y))(v_1, v_2, g_xv_1 + g_yv_2, w_1, w_2, g_xw_1 + g_yw_2).
\end{align*}
But I have no idea how to proceed from here. How does this end up getting us the square root from above? I see a lot of determinants of transformations, but $dG$ is not a square matrix, so I'm not sure how to get this to appear in this case. Any help is much appreciated.","['differential-forms', 'integration', 'differential-geometry']"
2703776,"When does $f(X) = g(X+1)-g(X)$ where $f, g \in \mathbb{C}(X)$?","Is there an interesting or useful necessary and sufficient condition for a rational function $f \in \mathbb{C}(X)$ to be expressible as the difference $g(X+1)-g(X)$ of another rational function $g \in \mathbb{C}(X)$? As an example, every polynomial $f$ is expressible in such a way since we have the Faulhaber's formula . Alternately, we can observe that $(X+1)^n - X^n = \sum\limits_{k=0}^{n-1}{n\choose k}X^k$ and so given a polynomial $f(X) = a_nX^n + \ldots + a_1X + a_0$ we may solve the system of equations obtained by equating the $k$-th terms of $f$ with those of $\sum\limits_{k=0}^{n}\left(\sum\limits_{i=k+1}^{n+1}b_i{i \choose k}\right)X^k$. The associated matrix consists of the upper triangular matrix with entries $A_{ij} = {j \choose i-1}, 1 \leq i \leq j \leq n+1$, and its determinant is clearly nonzero since it is the product of the diagonal entries ${i \choose i-1} = i$, so the determinant is $(n+1)!$. The solution for the $b_i$, $1 \leq i \leq n+1$ will give a polynomial $g(X) = b_{n+1}X^{n+1} + \ldots b_1X + b_0$ such that $f(X) = g(X+1)-g(X)$ ($b_0$ is arbitrary). Another example is the rational function $f(X) = \frac{1}{X(X+1)}$ where $g(X) = -\frac{1}{X}$. As a non-example, consider the function $f(X) = \frac{1}{X}$. Suppose there exist polynomials $p(X), q(X) \in \mathbb{C}[X]$ such that $\frac{p(X+1)}{q(X+1)}-\frac{p(X)}{q(X)} = \frac{1}{X}$. Assume moreover that $p$ and $q$ are coprime after dividing by any common factors. Then we have $Xp(X+1)q(X)-Xp(X)q(X+1)=q(X+1)q(X)$ so that $q(X)$ divides $Xq(X+1)$ and $q(X+1)$ divides $Xq(X)$. This means we have polynomials $\alpha(X), \beta(X)$ such that $$Xq(X+1) = \alpha(X)q(X)$$ $$Xq(X) = \beta(X)q(X+1)$$ By degree considerations, we have $\deg \alpha = \deg \beta = 1$. Then $X^2q(X) = \alpha(X)\beta(X)q(X)$ which means $X^2 = \alpha(X)\beta(X)$ and finally this forces $\alpha(X) = cX$ and $\beta(X) = \frac{1}{c}X$ for some $c \neq 0$. Substituting in the equations above we obtain $q(X+1) = cq(X)$ which is only possible if $q$ is constant because any zero would lead to infinitely many zeros. But this is impossible because $\frac{p(X)}{q(X)}$ would then be a polynomial, and its forward difference cannot equal $\frac{1}{X}$. I believe this proof can generalize to other cases where $f(X) = \frac{1}{g(X)}$ where $g$ is irreducible (that would just be the linear functions since $\mathbb{C}$ is algebraically closed). But I have not found a ""nice"" condition on $f$ which could be necessary and sufficient. The continuous analogue of the problem is easy, we know that $f$ has a rational antiderivative if and only if its partial fraction decomposition does not contain denominators of degree $1$.","['abstract-algebra', 'complex-analysis', 'rational-functions', 'functional-equations']"
2703787,What can be said about the level set of the real part of an analytic function?,"I am working with a function $F(z;a)$, for $z\in \mathbb{C}$ and $a$ being a set of parameters, from which I need to analyze the level set $\text{Re}(F(z))=0$ (for a fixed set of parameters $a$, which I will drop the notation now). The function $F$ is composed of elliptic functions and algebraic functions. To achieve my goal, I need to be able to say some concrete things about this level set. Here is what I know about the level sets right now: The real line is always part of this level set. The following symmetry exists: if $\text{Re}(F(z))=0$ then $\text{Re}(F(z^*))=0$ where $z^*$ is the complex conjugate of $z$. There are 4 points in $\mathbb{C}\setminus\mathbb{R}$ which are part of this level set (2 are conjugates of the other two). I can prove that the 2 conjugate points are endpoints of a ""band"" (arc) of the level set connecting the points. The curve parameterized by $\text{Re}(F(z))=0$ has four saddle points at which $\textrm{d}(\text{Re}(F(z)))/\textrm{d}z = 0$. For some values of $a$, two of these saddle points are on the real axis and I can show that the bands mentioned in the previous item intersect this point. I need to know more about this level set, in particular I would like to answer the following questions: Can I prove that there are $n$ connected components of this level set? ($n$ might depend on $a$). Is there any (nonreal) component of this level set outside of, for instance, the unit ball? Is there reason to believe that any additional components of the set (not listed above) should be connected to those listed above ($\textit{i.e.}$ the real line or one of the 4 points)? Or, is there reason to believe that there should only be bands of the set branching off of the real line at saddle points? Right now I am using software to get my hands on the geometry of this set. I have been looking at contour plots of $\text{Re}(F(z_r + i z_i))=0$ for different choices of $a$. The above questions are conjectures made from looking at different plots, but I know that the software misses things (for instance, it rarely shows the real line as being part of the desired set). Help in the right direction would be appreciated, my knowledge of complex analysis theorems is woefully inadequate to accomplish my goal here. Any other ideas of what can be said (that I may have missed) would also be appreciated. Edit: The expression was omitted originally because it is different in different contexts. 
By request, the expression for one of these cases has been added. It is: $$F(z;a) = -2iz\omega_1 + 2\Gamma(\omega_1\zeta(\alpha;\Lambda) - \zeta(\omega_1;\Lambda)\alpha),$$
where $\Gamma = \pm 1$, $\zeta(\cdot;\Lambda)$ is the Weierstrass-zeta function defined on a rectangular lattice ($\omega_1\in \mathbb{R}, \omega_3\in i\mathbb{R}$) and $$ \alpha = \wp^{-1}(f(z;a); \Lambda)$$
where $f(z;a)$ has 4 branch points (corresponding to the 4 points mentioned in (3) above), has poles at $z=\infty$ and may also have poles at $z=0$. In general, $f(z;a)$ has points $\hat z$ and $\hat a$ such that $f(\hat z; \hat a) = 0$.","['complex-analysis', 'analytic-functions', 'analysis']"
2703789,MVT/Rolle's Theorem on twice differentiable function.,"Suppose $ f : \mathbb R\to\mathbb R$ is differentiable two times (so both $f$ and $f′$ are differentiable on $\mathbb R$ ) and $f′′(x)$ > 0 for all $x ∈ \mathbb R$. Show that for any $y ∈ \mathbb R$ there exist at most two distinct values $x_1,x_2 ∈ \mathbb R$ such that $f(x_1) = f(x_2) = y$ I believe you have to use MVT/Rolle's Theorem to try and obtain a contradiction somewhere but I am struggling to figure out how. Help would be very much appreciated.","['real-analysis', 'analysis']"
2703829,Probability measure on a subspace of an infinite product space making each projection measure preserving,"Let $(X,\Sigma, \mu)$ be a standard Borel space probability space, i.e $\mu(X)=1$. Consider the space $(X^\mathbb Z, \Sigma_p)$, where $\Sigma_p$ is the standard $\sigma$ algebra on the product space generated by the coordinate projections $\pi_n:X^{\mathbb Z}\to X$. Now let $Y\subset \Sigma_p$, and give it the standard subspace  $\sigma$-algebra $\mathcal S=\Sigma_p\cap Y$. It is fairly easy to see that the restriction of each coordinate map $\pi_n|_Y$ is measurable w.r.t $\mathcal S$. What I am interested in though, is Does there exist a probability measure $\nu$ on $\mathcal S$ such that each restricted projection is $\pi_n|_Y$ is $\mu/\nu$ measure preserving? If $Y$ is itself just a product of subsets of $X$, then the answer is yes due to the Kolmogorov Extension theorem (in fact there are other applicable extension theorems too I believe, so pick your favourite). What is not so clear to me is what happens when $Y$ is not itself just a product space. My first consideration was the measure $\nu(A)=m(A)/m(Y)$, where $m$ is the measure on $\Sigma_p$ we get via the Kolmogorov extension theorem. Unfortunately the restricted projections do not need to be measure preserving with respect to this measure, as I figured out after asking here . Important Edit : I have been made aware of a trivial counterexample. Consider $X=[0,1]$ with Lebesgue measure  $\lambda$, and let us focus only on the simple case of $X\times X$. Let $Y=X\times\{0\}$. This is clearly measurable, but $\pi_2|_Y=0$, which implies that our desired $\nu$ on $Y$ cannot exist, because $\pi_2|_Y^{-1}\{0\}=Y$. I had hoped that maybe demanding that $\mu(\pi_n(Y))>0$ would be a sufficient condition ensuring that such a measure existed, but on further reflection I realised if we let $X$ be as above and consider $Y=X\times [0,1/2]\subset X\times X$ we run into a problem, because $\pi_2|_Y^{-1}(1/2,1]=\emptyset$. This has made me realize that my above claim about the Kolmogorov extension was entirely incorrect, because obviously the consistency conditions are not satisfied if we take any old product of subsets. I have posted a bounty though, and I am still interested in the subtleties of this problem, so let me ask a more subtle question: If $Y$ is a measurable proper subset of $X^\mathbb{Z}$ under what conditions does there exist a measure $\nu$ on $\mathcal S$ making the restriction of each coordinate projection measure preserving? I believe that a necessary condition is requiring that image of each projection has full measure, but I'm not sure whether this is sufficient.","['real-analysis', 'measure-theory', 'probability-theory']"
2703884,Notation for a sequence of normal random variables with changing mean and variance.,"What would be an accurate mathematical notation for the following: A sequence of $T$ random variables, where each element up to $\kappa$ is a normally distributed with mean $\mu_1$ and variance $\sigma^2_1$, and each element from $\kappa$ to $T$ is a normally distributed with mean $\mu_2$ and variance $\sigma^2_2$. I came up with something like: $X = \{x_t:t=1,\dots,\kappa,\dots T\}$ where $x_t \sim \operatorname{N}(\mu_1,\sigma^2_1)$ if $t \leq \kappa$ and $x_t \sim \operatorname{N}(\mu_2,\sigma^2_2)$ if $t> \kappa$. But I have no idea if that is correct. Does anyone know an elegant way to write this? Thanks in advance!","['time-series', 'statistics', 'sequences-and-series', 'notation']"
2703898,Show that if the restrictions of $f$ to $S_1$ and to $S_2$ are continuous then $f$ is continuous.,"Let $E$,$E^{\prime}$ be metric spaces, $f: E \to E^{\prime}$ a function, and suppose that $S_1,S_2$ are closed subsets of $E$ such that $E = S_1 \cup S_2$. Show that if the restrictions of $f$ to $S_1$ and to $S_2$ are continuous then $f$ is continuous. What is meant by restrictions? Is it stating that $f(S_1)$ is continuous and $f(S_2)$ is continuous so now show that the function is continuous for $E \to E^{\prime}$? Thank you in advance! :)","['continuity', 'real-analysis', 'functions']"
2703914,What can we possibly get out of the monoidal action of this function?,"For an $n$-tuple $S$ of decreasing positive integers, we can define $f(S)$ as subtracting $1$ from every element of $S$, prepending $n$, and then removing $0$s and re-ordering in decreasing order if neccecary. For example, $f((4,2,1))=(3,3,1)$. We're supposed to analyze this function using higher mathematics, and after consulting my friend he says that he's been able to recover some interesting properties using the monoidal action of $\{Id,f,f^2,f^3,\dots\}$. But this makes no sense to me, because, unlike with groups, there is pretty much nothing to go on with monoids. No orbit-stabalizer theorem, no Burnside's Lemma, etc. I've tried analyzing the orbits of this monoid acting on the set of finite, decreasing tuples of positive integers but not gotten anywhere. What can I learn about this function through it's monoidal action? EDIT: I've gotten a very helpful answer putting the question in terms of monoidal theory and proving every tuple hits a cycle. Now I'm wondering how we can use it to prove that every tuple with the same sum reaches the same cycle, using his method or another. We've proven it has a cycle decomposition, now can we say anything of it's nature?","['group-actions', 'abstract-algebra', 'group-theory', 'monoid']"
2703931,Generalize Fermat's Last Theorem,"Let $\sum_{j=1}^k a_j^n=z^n$ .  All $a_j,z$ positive integers. $k,n\gt 2$ .  For a given $n$ , for what values of $k$ are there any solutions, and are there only finitely many?  For $n=3$ , there are solutions for $k=3$ .  Has this question been studied in detail?",['number-theory']
2703978,Smallest $r$ for which there is an $r$-coloring of the grid wherein no two colors are adjacent more than once.,"Consider ways of coloring the $n \times n$ grid with $r$ labels so that no two labels are adjacent (horizontally or vertically) in more than one place. Is there a good upper or lower bound on the minimum integer $r_n$ such that the $n \times n$ grid has an $r_n$-coloring? Non-example The following grid would not be a valid $7$-coloring because (AX, AY) and (CY, BY) are both (1, 2) adjacencies: A [1, 2, 7]
B [3, 2, 6]
C [4, 1, 5]
   X  Y  Z Examples For example, on the $4 \times 4$ grid, the following $7$-coloring will work, but there are no $6$-colorings [1, 1, 2, 2]
[3, 4, 4, 5]
[2, 6, 7, 1]
[7, 3, 5, 6] Similarly, on the $5 \times 5$ grid, the following $9$-coloring will work, but there do not exist any $8$-colorings. [1, 1, 2, 2, 3]
[3, 4, 4, 5, 3]
[6, 6, 7, 1, 8]
[9, 2, 7, 9, 8]
[4, 8, 5, 5, 6] An example of an $8$-coloring on a $4 \times 5$ grid shows that there may be some structure to the coloring: [1, 1, 2, 2, 3]
 [3, 4, 4, 5, 3]
 [6, 6, 7, 5, 8]
 [2, 8, 7, 1, 8] Conjecture Empirical data for the first nine terms shows that $r_n = 2n - 1$ for $n \leq 6$. and $r_n \leq 2n - 1$ for $n \leq 9$.
A stupid (?) conjecture is that $r_n = 2n - 1$.","['combinatorics', 'extremal-combinatorics', 'discrete-mathematics']"
2703992,"If $\,\lim_{h\to 0}\frac{f(x+h)-f(x-h)}{2h}\,$ exists for every $x$, what does this imply for $f$?","Consider the function
$$
f(x)=\left\{\begin{array}{rll} 1+x^2 & \text{if} & x \,\,\text{rational} \\ -x^2 & \text{if} & x \,\,\text{irrational}\end{array}\right.
$$
Then, for $x=0$, the limit $\lim_{h\to 0}\dfrac{f(h)-f(-h)}{2h}$ exists, although $f$ nowhere continuous. Consider now the function
$$
f(x)=\left\{\begin{array}{rll} 1 & \text{if} & x=0 \\ 0 & \text{if} & x\ne 0\end{array}\right.
$$
Then the limit $\lim_{h\to 0}\dfrac{f(x+h)-f(x-h)}{2h}$ exists, for every $x$, although $f$ is not continuous at $x=0$. This example can be generalised, and obtain an $f$ which is discontinuous in countably many points (for example all the rationals), while the central difference converges. Suppose now that limit $\lim_{h\to 0}\dfrac{f(x+h)-f(x-h)}{2h}$ exists for every $x$ is some open interval. Does this imply that $f$ is not differentiable in at most countably many points?","['derivatives', 'real-analysis', 'calculus', 'limits']"
2704037,Find all integers $n$ such that $\frac{(n^2-n-1)^2}{2n-1}$ is a positive integer,"My task is to find all integers $n$ such that $\frac{(n^2-n-1)^2}{2n-1}$ is a positive integer, and if possible a general technique for solving questions of this type of rational functions. My first step in finding solutions was I showed that both numerator and denominator must be odd (using modular arithmetic base $2$) and thus if $d(2n-1)=(n^2-n-1)^2$, then $d$ must be odd. First considering the case of $2n-1$ equaling $n^2-n-1$ and thus $n$ must equal $0$ or $3$ (so two solutions). Next considering $2n-1$ equaling $(n^2-n-1)^2$ and the only integer solution to this is $n=1$ (third solution). I've now stumbled on how to check for further solutions, and am seeking hints/methods/solutions to finding the other potential solutions. Thank you.","['number-theory', 'integers', 'functions', 'divisibility']"
2704102,$X \times Z \cong Y \times Z \implies X \cong Y$?,"Let $X,Y,Z$ be topological spaces. Is the following statement true?
$X \times Z \cong Y \times Z \implies X \cong Y$?
how would you prove it? and I know that if $A \cong B$, and $a \in A$ that there is a $b \in B$, such that $A\setminus{\{a\}} \cong B\setminus{\{b\}}.$ How would you prove the same for removing lines from product topology, instead of point of normal topological spaces?",['general-topology']
2704155,Prove by Induction: Summation of Factorial (n! * n),"Prove by induction (weak or strong) that: $$(1! \cdot 1) + (2! \cdot 2) + \cdots + (n! \cdot n) =\sum_{k=1}^nk!\cdot k= (n + 1)! - 1$$ My base case is: $n = 1$, which is true. And my Inductive Hypothesis is: $(1! \cdot 1) + (2! \cdot 2) + \cdots + (k! \cdot k) = (k + 1)! - 1$ After that, I'm trying to show the $(k + 1)$-stage where: $(1! \cdot 1) + (2! \cdot 2) + \cdots + (k! \cdot k) + ((k + 1)! \cdot (k + 1)) = ((k + 1) + 1)! - 1$ Which simplifies to: $(1! \cdot 1) + (2! \cdot 2) + \cdots + (k! \cdot k) + ((k + 1)! \cdot (k + 1)) = (k + 2)! - 1$ I see that I can substitute in my Inductive Hypothesis but where I'm stuck is manipulating the LHS to be equal to the RHS after that: $(k + 1)! - 1 + ((k + 1)! \cdot (k + 1)) = (k + 2)! - 1$","['induction', 'discrete-mathematics']"
2704174,Novice question: what values of $x$ satisfy $\frac{x^2}{x} \le 0 $,"Okay I'm embarrassed to even ask this clearly I am not going to win a Nobel prize in my life. Question What values of $x$ satisfy: $$\frac{x^2}{x} \le 0 $$ My attempt I'm very tempted to simplify the LHS and say the answer is $x \le 0$ But I have this  nagging concern that the answer is actually $x<0$ If I start from the other direction, then I have $$x \le 0$$ $$x*1 \le 0*1$$ $$x\frac{x}{x} \le 0 \frac{x}{x}$$ And the last line only holds if $x$ is not zero and therefore it changes to $$x\frac{x}{x} < 0 \frac{x}{x}$$ $$\frac{x^2}{x} < 0 $$ And now that there is no threat of dividing by zero I can reduce it to $x<0$ Is this right? I feel like in general when doing math I multiply top and bottom by $x$ all the time and I never really think about explicitly calling out that $x$ can't be zero. Thanks for your help/patience.",['algebra-precalculus']
2704260,Finding expected value of remaining piece,"A father has a pie made for his two sons. Eating more than half of the pie will give indigestion to anyone. While he is away, the older son helps himself to a piece of the pie. The younger son then comes and has a piece of what is left by the brother. Assume that the size of each of the two pieces eaten by the sons is random and uniformly distributed over what is currently available. What is the expected size of the remaining piece give that no son has indigestion? After a while of thinking this is what I did. 
Let $\theta_1$ be the total angle corresponding to the amount of pie that son $1$ eats. Similarly, let $\theta_2$ be the total angle corresponding to the amount of pie for son $2$. Let $X$ be the remaining piece. So, 
$$
X = 2\pi - \theta_1 - \theta_2 \\
\mathbb{E}(X) = 2\pi - \mathbb{E}(\theta_1) - \mathbb{E}(\theta_2).  
$$
So after a while of thinking, given that no son has indigestion, it feels as if son 1 and son 2 are independent, since they eat less than $\pi$... So $\theta_1 \sim \operatorname{Unif}(0,\pi)$ and also $\theta_2\sim \operatorname{Unif}(0,\pi)$. Then $\mathbb{E}(X) = \pi$. Is this correct?","['conditional-expectation', 'probability', 'probability-distributions']"
2704383,Union of dense is dense?,"Question :In topological space, union of any family of dense subset is dense? I don't know whether the above statement is true or not! I know the definition of dense sets in topological space. According to ""me  it may not be true , as closure of infinite Union may not be equals to Union of closures. please help me to prove the above or give counter example of above..",['general-topology']
2704389,"An urn has 4 balls of 4 different colours Red,Blue,Green,Yellow.","An urn has $4$ balls of $4$ different colours; red, blue, green, and
  yellow. I pick one ball at random at first and if it is red, I paint
  it blue and return it to the urn. If it is blue, I paint it green. If
  it is green, I paint it yellow. If it is yellow, I paint it red. What
  is the expected number of trials to get all $4$ balls of the same
  colour? Reminder: $$\color{red}{red}\to \color{blue}{blue}$$
$$\color{blue}{blue}\to \color{green}{green}$$
$$\color{green}{green}\to \color{yellow}{yellow}$$
$$\color{yellow}{yellow}\to \color{red}{red}$$ I am really stuck with this problem. Help!","['probability-theory', 'probability', 'probability-distributions']"
2704394,Prove three eigenvectors from three distinct eigenvalues are linearly independent [duplicate],"This question already has answers here : If $v_1,...,v_r$ are eigenvectors that correspond to distinct eigenvalues, then they are linearly independent. (3 answers) Closed 6 years ago . Here is the formal statement: Let $\lambda_1, \lambda_2, \lambda_3$ be distinct eigenvalues of $n\times n$ matrix $A$. Let $S=\{v_1, v_2, v_3\}$, where $Av_i = \lambda_i v_i$ for $1\leq i\leq 3$. Prove $S$ is linearly independent. Many resources online state the general proof or the proof for two eigenvectors. What is the proof for specifically 3? I tried to derive the 3 eigenvector proof from the 2 eigenvector proofs, but failed.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2704416,Probability distribution over bijections,"Does there exist a probability distribution over bijections $f:[0,1]\rightarrow [0,1]$ such that for any $x,y,z\in[0,1]$, the probability that $f(x)=y$ is the same as the probability that $f(x)=z$? I'm not sure if I understand this question correctly. Since there are an infinite number of possible $y,z$, this probability must be $0$. But does that already mean that no such distribution exists?","['real-analysis', 'probability', 'functions', 'probability-distributions']"
2704427,"How does the Cantor's diagonal argument that $(0,1)$ is uncountable deals with the fact some real numbers have two different decimal expansions?","I recently learnt Cantor's argument that proves $(0, 1)$ is uncountable. Basically, the argument goes: first assume the contrary, therefore there is a bijection $$f: \mathbb{N} \rightarrow (0, 1)$$ that $$f(1) = 0.a_{11}a_{12}a_{23}...$$ $$f(2) = 0.a_{21}a_{22}...$$ and in general $$f(n) = 0.a_{n1}a_{n2}...$$ where $a_{nm} \in \mathbb{N}, 0 \le a_{nm} \le 9$. Then we construct a number $$s = 0.b_{11}b_{12}...$$ where each $b_{1n} \ne a_{nn}$. The argument then goes that since the new number $s$ differs with any $f(n)$ with at least one digit, it cannot equal to any $f(n)$, therefore this function $f$ is not surjective, leads to a contradiction. However, there are cases that even if two numbers $a$ and $b$ in $(0, 1)$, when written in decimal form, differs in some digits, they can still be equal to each other. For example: $$0.1000000... = 0.0999999...$$ How, then, can this argument still hold then?",['elementary-set-theory']
2704430,Finding conditional expectation given another conditional distirbution,"Suppose $X$ is a uniformly distributed random variable on $[0,1]$ and given $X=x,$ a number $Y$ is chosen at random between $0$ and $x$. Suppose that you only know the value $y$ of $Y$ and you don't know $x$. We guess $x$ to be $\mathbb{E}(X|Y=y)$. Find this. How would I start this? This is what I did: $Y|X \sim Unif(0,x)$. So $$f_{X|Y}(x|y) = f_{Y|X}(y|x)f_{X}(x)/f_{Y}(y) \\ = \frac{\frac{1}{x}I_{[0,x]}(y)I_{[0,1]}(x)}{f_{Y}(y)}$$
and I'm stuck here.","['uniform-distribution', 'probability-theory', 'conditional-expectation']"
2704431,How to prove that $\int_{0}^{\infty}\frac{t}{x^2+t^2}\cos(ax)dx=\frac{\pi}{2}e^{-at}$.,"I want to prove that for $t,a>0$:
$$f_a(t)=\int_{0}^{\infty}\frac{t}{x^2+t^2}\cos(ax)dx=\frac{\pi}{2}e^{-at}$$
It is easy to prove that 
$$f_a''(t)=a^2f_a(t),$$
then
$$f_a(t)=c_1e^{at}+c_2e^{-at}$$
Cleary $\lim\limits_{t\to 0}f_a(t)=0$ and therefore $c_1=0$. But I could not justify that $c_2=\frac{\pi}{2}$. Any idea? Thank you very much.","['improper-integrals', 'integration', 'analysis']"
2704432,How to generate balanced combinations?,"Let's say I have $T$ objects I want to put into combinations of size $N$ (lets say 4). So, I start iterating through them (in dictionary order): A, B, C, D
A, B, C, E
A, B, C, F
... This has one big problem:  There are a lot of possible combinations.  I don't have time for that.  So, I select only the first $Y$ combinations . However, this has another problem:  Object $A$ is going to appear far more often than any other object.  I want to ensure that all items appear as evenly as possible. So fo trial number 2, I simply take the next N items: A, B, C, D
E, F, G, H
I, J, K, L
...
A, B, C, E (we skip to E this time around)
F, G, H, I
J, K, L, M This is looking much better.  However, there's another problem:  The pairing $(A, B)$ will appear far more often than the pairing $(A, J)$ Therefore, what I really want is an ordering on the combinations where taking the first $Y$ combinations will produce a balanced number of subcombinations. A subcombination is a strict subset of a combination Balanced means that the difference between the number of identical subcombinations must be as small as possible.  (e.g. The number of $(A, J)$ pairs must be as close as possible to the number of $(A, B)$ pairs) Is this possible?  Is there an easy algorithm to generate this ordering?",['combinatorics']
2704452,Alternative proof that conditioning reduces entropy,"I was going through some class notes which provide a different proof that conditioning reduces entropy from the usual one which relies on the fact that mutual information is non-negative. In this proof, I am confused by the second step which has an inequality:
\begin{align}
H(X|Y) &= \sum_x \sum_y p_y \left(- p_{x|y} \log p_{x|y}\right) \\
  &\le \sum_x \left\{\left(-\sum_y p_y \, p_{x|y}\right)\left(\log \sum_y p_y \, p_{x|y} \right)\right\} \\
 &= \sum_x - p_x \log p_x \\
 &= H(X).
\end{align}
Basically, I'm not sure how the 2nd set of parentheses ends up being a log-sum containing $p_y$. My only thoughts are that maybe Jensen's inequality is being used here, or the Schwartz inequality, or some combination thereof, but I am not sure. Or is this just sloppy note-keeping? Thanks.","['information-theory', 'statistics', 'convex-analysis']"
2704458,Global sections of projective schemes,"Let $Y$ be a closed subscheme of $X = \operatorname{Proj} S$, where $S = k[x_0,\dots,x_n]$, $k$ algebraically closed. Then $Y = \operatorname{Proj} (S/I)$ for a homegenous ideal $I$ of $S$. How can we understand the global sections $\Gamma(Y,\mathcal{O}_Y(d))$ of the twisted sheaf $\mathcal{O}_Y(d)$ on $Y$? By Exercise II.5.9(b) in Hartshorne, we know that for large $d$ these sections coincide with the degree $d$ component of the ring $S/I$. How large does $d$ need to be for this to be true? Also, what about for smaller $d$?","['projective-schemes', 'algebraic-geometry']"
2704480,Number of Strings / Number with $ n $ Characters / Digits Built with $ k $ Size Alphabet with each Element of the Alphabet Appearing At Least Once,"Question Given an Alphabet of size $ k $ how many strings / numbers of length $ n \geq k $ with each element of the Alphabet appearing at least once? Example Example of specific case. The Alphebet being $ \left\{ 1, 2, 3, 4 \right\} $ and $ n  = 7 $. Then the answer is the number of 7 digits numbers with the digits $ 1, 2, 3, 4 $ appearing at least once in them. Approach I thought one could build something in Dynamic Programming approach with Inclusion / Exclusion. Let's define $ F \left( n, k \right) $ as the answer for $ n, k $. Then $ F \left( n, k + 1 \right) = {\left( k + 1 \right)}^{n} - \sum_{i = 1}^{k} \binom{k + 1}{i} F \left( n, i \right) $. Where simply we took all numbers of $ n $ digits and removed those built with smaller Alphabet. I'm not sure about $ F \left( n + 1, k \right) $. Feel free to give any kind of answer / approach which deals with it.","['combinatorics', 'discrete-mathematics']"
2704522,"Relation between the derivative of a function and the ""change"" in the function","Suppose we have the function $$M(t)=ce^{rt}$$ where $c$ is a constant. Trivially, it follows that $\frac{dM_t}{dt}=r\cdot c e^{rt}=rM_t$, hence we can write this in the form $$\frac{dM_t}{M_t}=rdt$$ I'm trying to derive the same equation by looking at the change $dM_t$ I have 
$$dM_t=M_{t+dt}-M_t=ce^{r(t+dt)}-ce^{rt}=M_t(e^{rdt}-1)$$ Hence, I'd expect to have $$e^{rdt}-1=rdt$$ which makes no sense to me. As far as I know, the derivative with respect to a variable is the change when all the other variables are held fixed. Can someone explain to me where's the issue and in general, how to relate the change to the derivative especially in the case when the function depends on more than $1$ variable?","['derivatives', 'partial-derivative']"
2704565,Properties of the Noise in the first hitting problems of Brownian motion,"I have a question on the first hitting processes of Brownian motion. A Brownian particle starting at $x_{t=0}=0$ and subjected to a Gaussian white noise$\xi(t)$, the motion of the particle will be a normal diffusion process. If we set a wall at $x=L>0$, the particle will hit the wall for the first time at some moment $\tau$. The PDF of the first hitting time $\tau$ also could be calculated. My question is: among all the possible processes, if we only concern the processes that assured the particle hit the wall at time $\tau$, the noise $\tilde{\xi}(t)$ acting on the particle during these asssured-hitting processes is clearly not Gaussian white noise anymore. Since $\frac{1}{\gamma}\int_{0}^{\tau}\tilde{\xi}(t)dt=L$ for these processes. So, how could we describe this noise $\tilde{\xi}(t)$, such as the average $<\tilde{\xi}(t)>$ and the self-correlation $<\tilde{\xi}(t)\tilde{\xi}(t')>$, or other properties? Is there any books or articles on this?","['stochastic-processes', 'probability-theory', 'brownian-motion']"
2704730,"Prob. 10, Sec. 3.3, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: Is this sequence convergent?","Here is Prob. 10, Sec. 3.3, in the book Introduction to Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition: Establish the convergence or the divergence of the sequence $\left( y_n \right)$, where 
  $$ y_n \colon= \frac{1}{ n+1} + \frac{1}{n+2} + \cdots + \frac{1}{2n} \ \mbox{ for } n \in \mathbb{N}. $$ My Attempt: For each $n \in \mathbb{N}$, we have 
  $$
\begin{align}
y_{n+1} - y_n &= \left( \frac{1}{ (n + 1) +1} + \frac{1}{ (n+1) +2 } + \cdots + \frac{1}{2(n+1)} \right) - \left( \frac{1}{ n+1} + \frac{1}{n+2} + \cdots + \frac{1}{2n} \right) \\
&= \left( \frac{1}{ n  + 2} + \cdots + \frac{1}{2n+ 2 } \right) - \left( \frac{1}{ n+1} + \cdots + \frac{1}{2n} \right) \\
&= \frac{ 1 }{2n+1} + \frac{ 1}{2n+2} - \frac{1}{n+1} \\
&= \frac{1}{2n+1} - \frac{1}{2n+2} \\
&= \frac{1}{ (2n+1) (2n+2) } > 0,
\end{align}
$$
  which shows that our sequence is monotonically increasing. Also, for each $n \in \mathbb{N}$, we have
  $$ y_n = \frac{1}{ n+1} + \frac{1}{n+2} + \cdots + \frac{1}{2n} < \underbrace{\frac{1}{n} + \frac{1}{n} + \cdots + \frac{1}{n} }_{ \mbox{ $n$ times } }  = 1. $$ Thus our sequence, being monotonically increasing and bounded, is convergent. Is what I've done so far all correct? How to determine the limit of this sequence?","['real-analysis', 'limits', 'sequences-and-series', 'convergence-divergence', 'analysis']"
2704755,special non zero ideals of the ring of continuous functions,"Let $R$ be the ring of all continuous real valued functions on a completely regular space $X  $,  that is $R:=C (X)$,  and let $0\not=I $ be an ideal of $ R $ and $\{  I_i  \}_{ i\in A   } $ be a family of ideals of $  R $. I am looking for a condition (preferably an equivalent )on $I $ such that if $I\subseteq \sum_{ i\in A   } I_i $ then we can deduced that there exists $j\in A $ such that $I\subseteq I_j $? For example minimal ideals have this property.","['abstract-algebra', 'general-topology', 'algebraic-geometry', 'commutative-algebra']"
2704798,Percentage of white balls is an integer,"There are some white balls and black balls. The percentage of the white balls is an integer. Afterward, one white ball and two black balls are added. The percentage of the white balls is still an integer. What is the maximum possible number of balls at the beginning? Let $w$ denote the number of white balls and $b$ the number of black balls initially. So $\dfrac{100w}{w+b}$ is an integer, and $\dfrac{100(w+1)}{w+b+3}$ is also an integer. How can we maximize $w+b$?","['algebra-precalculus', 'percentages']"
2704824,Proving properties of a function upon repeated iteration,"For an $n$-tuple $S$ of decreasing positive integers, we can define $f(S)$ as subtracting $1$ from every element of $S$, prepending $n$, and then removing $0$s and re-ordering in decreasing order if neccecary. For example, $f((4,2,1))=(3,3,1)$. I've proven that repeated iteration of this function always ends at a cycle, by noticing that $f$, $f(f(x))$, etc. is a finite sequence. Now how can I prove that every tuple with the same sum will eventually go to the same cycle? I've verified that this is true with Mathematica. EDIT: I'm looking to either prove or disprove this statement. I've verified it for a lot of cases, but it may not be true. This wasn't given as an assignment so I have no idea whether it's true.","['algebra-precalculus', 'combinatorics', 'number-theory', 'elementary-number-theory']"
2704837,Solve $\sqrt {x^2-3}=x-3$ in $\mathbb R$,"Solve $\sqrt {x^2-3}=x-3$ in $\mathbb R$ My attempt: $|x^2-3|=(x-3)^2$ So $-(x^2-3)=(x-3)^2$ or $(x^2-3)=(x-3)^2$ If  $-(x^2-3)=(x-3)^2=x^2+9-6x$ So no solutions in $\mathbb R$ And if $(x^2-3)=(x-3)^2$ So $x^2-3=x^2+9-6x$ Now, can I delete $x^2$ with $x^2$ ? Like this $x^2-x^2-3-9+6x=0$ $6x=12$ $x=2$ But $f(2)$ isn’t equal to $0$?",['algebra-precalculus']
2704853,Is this composition associative?,"Given a set $X=\{1,\dots,n\}$. In Dempster–Shafer theory a BBA is a function $m:\mathcal P(X)\to[0,1]$, with the two properties that $m(\emptyset)=0$ and $\sum_{A\subseteq X}m(A)=1$. The Dempster's rule of combination of two BBAs is defined $(m_1\oplus m_2)(\emptyset)=0$ and $(m_1\oplus m_2)(A)=\frac{1}{1-K}\sum_{B\cap C=A}m_1(B)m_2(C)$, where 
$K=\sum_{B\cap C=\emptyset}m_1(B)m_2(C)$. My question is if this composition of BBAs is associative. I can't find anything anywhere about that.","['reference-request', 'functions', 'bayesian', 'elementary-set-theory', 'associativity']"
2704864,Complex numbers $\left(\frac{1+i}{1-i}\right)^k = 1$ what is $k$?,"The smallest possible integer $k$ for which $\left(\frac{1+i}{1-i}\right)^k = 1$ is? I tried solving this, but my answer doesn't match the given answer. Correct me if I'm wrong at some place My solution: \begin{align}
\left(\frac{1+i}{1-i}.\frac{1+i}{1+i}\right)^k&= 1\\
\left(\frac{1+2i+i^2}{1-i^2}\right)^k&= 1\\
\left(\frac{1+2i-1}{1-(-1)}\right)^k&= 1\\
\left(\frac{2i}{2}\right)^k&= 1\\
i^k&= 1\\
i^4&= 1\\
\end{align} EDIT: The question is part of the multiple choice section and the answer is 2.
Other options include: 4, 8, 16","['algebra-precalculus', 'complex-numbers']"
2704918,A property for real valued functions,"Let $f$ be a real valued continuous function over a  compact topological space $X$, say [0, 1], I am looking for a condition on $f$ such that if there exist real valued continuous functions $g_1,...,g_n , f_1,...,f_n$ over $X$ with $f=f_1g_1+...+f_ng_n$, then there exist $i , j\in\{ 1,...n \} $ and a real valued continuous functions $h$ and $k$ over $X$ such that $f=hf_i$ and $f=kg_j$?(that is, if a function is a linear combenition of some functions with functional-coefficients then that function is a multiple of one of them with functional-coefficient)","['real-analysis', 'functions', 'functional-analysis', 'special-functions', 'analysis']"
2704957,What makes Krylov subspaces so special?,"I am reading through ""Numerical Linear Algebra"", by Lloyd N. Trefethen and David Bau. I reached the final chapter about iterative methods. They all share the fact, that they are using Krylov subspaces. What I understood so far: We are using those subspaces $K_{n}=<b, Ab, AAb, ... A^{n-1}b>$ for different problems, e.g. solving systems, that require dimensions much higher than $n$. Usually we first orthonormalize $K_n$, e.g. by using the Arnoldi iteration, so it is more stable. This way, we can save much time and computing-cost, and the solution can converge nicely, even for $n<<m$. My question is: What makes Krylov spaces in particular so special? Why doesn't it work  well (or does it?) for arbitrary other orthonormal bases, that I can expand dimension by dimension, too?","['numerical-linear-algebra', 'linear-algebra']"
2704978,Second Order Partial Derivative Chain Rule,"If I proceed to compute the chain rule of a second-order partial derivative of a continuous function $\psi(x,y)$ in terms of new coordinates $\xi=\xi(x,y)$ and $\eta=\eta(x,y)$ like
$$\frac{\partial^2 \psi}{\partial x^2}=\left(\frac{\partial \xi }{\partial x}\frac{%
\partial }{\partial \xi }+\frac{\partial \eta }{\partial x}\frac{%
\partial }{\partial \eta }\right)\left(\frac{\partial \xi }{\partial x}\frac{%
\partial \psi}{\partial \xi }+\frac{\partial \eta }{\partial x}\frac{%
\partial \psi}{\partial \eta }\right),$$
I obtain the following result
$$\frac{\partial^2 \psi}{\partial x^2}=\left(\frac{\partial\xi}{\partial x}\right)^2\frac{\partial^2\psi}{\partial \xi^2}+\left(\frac{\partial\eta}{\partial x}\right)^2\frac{\partial^2\psi}{\partial \eta^2}+2\frac{\partial \eta}{\partial x}\frac{\partial \xi}{\partial x}\frac{\partial^2\psi}{\partial\eta\partial\xi}.$$
I know this result is incorrect because I miss two terms with second-order derivatives of $\xi$ and $\eta$, but I do not identify in which step I made the mistake.","['ordinary-differential-equations', 'calculus', 'partial-differential-equations']"
2704981,is the Laplacian just the gradient dotted with itself?,"I guess no but in the solution of this problem (see attached picture) at some point, it is stated that $\Delta v = D_xv \cdot D_xv $ but $D_xv = [v_{x_1} \cdots v_{x_n}]^T$, right ? so shouldn't $D_xv \cdot D_xv=v^2_{x_1}+ \cdots + v^2_{x_n}$ ? also I did notice that sometimes they write $D_xv$ and sometimes $D_x \cdot v $. I suspect that I am missing something here...","['multivariable-calculus', 'laplacian', 'partial-differential-equations']"
2705060,Sets homeomorphic to convex sets,"I have recently encountered the "" Brouwer fixed-point theorem "".
The theorem states (per Wikipedia) that any convex compact set has the fixed point property.
This statement struck me as odd as the theorem requires convexity, which isn't a topological property (i.e preserved by homeomorphisms) while the fixed-point property is. My question then: Is there a simple or well known topological property which is equivalent to ""homeomorphic to a convex set"" In the case of $A \subseteq \mathbb{R}$ it's not hard to see that $A$ is homeomorphic to (and is) a convex subset of $\mathbb{R}$ if and only if it is connected.
My intuition tells me that in the case of $\mathbb{R}^2$ this extends to simply connected sets, and in higher dimensions to sets where all homotopy groups are trivial, but I don't know if my intuition is right on this. EDIT: thinking on the comments and answers so far it seems another necessary condition is that the set also be locally connected. However that is still not sufficient as any 'Y shaped' subset of $\mathbb{R}^2$ still isn't homeomorphic to a convex set. Would being a simply connected manifold, possibly with boundary, be sufficient in $\mathbb{R}^2$? Please note when answering that I'm mostly familiar with point-set topology and only know very little about algebraic topology.","['general-topology', 'fixed-point-theorems', 'real-analysis', 'algebraic-topology']"
2705102,Weak convergence in $L^1$ implies uniform integrability.,"Consider the following definition of weak convergence in $L^1$. A sequence of random variables $Z_n$ defined on $(\Omega,\mathcal{F},\mathbb{P})$ is said to converge weakly in $L^1$
to an integrable random variable $Z$ if 
$$
\forall E\in\mathcal{F}\Rightarrow \mathbb{E}\left[Z_n\,I(E)\right]\to\mathbb{E}\left[Z\,I(E)\right]
$$ How do I prove that if $Z_n$ converge weakly in $L^1$
to $Z$, then both $Z_n$ and $Z$ are uniformly integrable? Any reference is welcome.","['probability-theory', 'convergence-divergence', 'random-variables']"
2705106,Find derivative of $y=\sin^{-1}\frac{2x}{1+x^2}$,"Find $\frac{dy}{dx}$ if $y=\sin^{-1}\frac{2x}{1+x^2}$ The solution is given as $\frac{2}{1+x^2}$. But is it a complete solution ? My Attempt $$
2\tan^{-1}x=\begin{cases}\sin^{-1}\frac{2x}{1+x^2},\quad |x|\leq 1\\
\pi-\sin^{-1}\frac{2x}{1+x^2},\quad |x|>1 \;\&\; x>0\\
-\pi-\sin^{-1}\frac{2x}{1+x^2},\quad |x|>1 \;\&\;x>0\\
\end{cases}\\
\sin^{-1}\frac{2x}{1+x^2}=\begin{cases}2\tan^{-1}x,\quad |x|\leq 1\\
\pi-2\tan^{-1}x,\quad |x|>1 \;\&\; x>0\\
-\pi-2\tan^{-1}x,\quad |x|>1 \;\&\;x>0\\
\end{cases}\\
$$
Thus,
$$
\frac{dy}{dx}=\frac{d}{dx}\bigg[\sin^{-1}\frac{2x}{1+x^2}\bigg]=\begin{cases}
\frac{d}{dx}[2\tan^{-1}x]=\frac{2}{1+x^2},\quad |x|\leq 1\\
\frac{d}{dx}[\pm\pi-2\tan^{-1}x]=\frac{-2}{1+x^2},|x|>1 
\end{cases}
$$
Is it correct ?","['derivatives', 'inverse-function']"
2705107,Symmetries of Mandelbrot sets with integer exponents,"I have been experimenting with recursive formulas of the form: \begin{equation}
\forall c \in \mathbb{C} , z_{n+1} = z_{n}^\alpha + c
\tag{1}
\end{equation} as well as: \begin{equation}
\forall c \in \mathbb{C}, z_{n+1} = \overline{z_{n}}^\alpha + c
\tag{2}
\end{equation} where $z_0 = c$, $\alpha \in \mathbb{Z}$ and $|\alpha| > 1$. I made the following observations: In case $(1)$, the resulting structure has $\alpha-1$ symmetries when $\alpha \geq 2$ and $|\alpha|+1$ symmetries when $\alpha \leq -2$. In case $(2)$, the resulting structure has $\alpha+1$ symmetries when $\alpha \geq 2$ and $|\alpha|-1$ symmetries when $\alpha \leq -2$. If you'd like to experiment with the software I used to gain more insights, I made it publicly available: https://github.com/AidanRocke/TensorFlow-Fractals Here are a few visualisations of case $(1)$ for $\alpha \in {2,4,-2,-4}$: So far I don't have an explanation for all four observations but I have a stability argument for case $(1)$ where $\alpha > 1$: \begin{equation}
z_{n+1} \sim z_0^{\alpha(n+1)} 
\end{equation} which may be deduced by multiplying and dividing all terms in the series expansion by $z_0^{\alpha(n+1)}$. As a result, near the boundary of the circumscribing disk with radius $R$ the most stable(and therefore most distant) points are near the roots of unity: \begin{equation}
\mathcal{U}_n = \{e^{\frac{2ik\pi}{\alpha}}: k \in [0,\alpha-1]\}
\end{equation} I think this argument is sufficient but feel free to correct me if I'm wrong. As for the three other cases, I don't have a good explanation yet.","['complex-numbers', 'fractals', 'symmetry', 'geometry', 'analysis']"
2705141,Precision of Rational Approximation to $\pi$ versus series convergence,"For $n\geq 1$ , let: $$
a_n = \text{min} \lbrace{|\sin(k)|: 1\leq k\leq n} \rbrace
$$ So that $a_1=\sin(1)$ , $a_2=\sin(1)$ , $a_3=\sin(3)$ , $a_4=\sin(3)$ , $a_5=\sin(3)$ and so on. And let: $$
S_n = \sum_{k=1}^n a_k
$$ The questions: 1-Does $a_n$ converge?  (yes, proven in a comment by  Xander Henderson) 2-What is the limit of $a_n$ as $n$ goes to infinity? (proven to be zero by Matt F. in his answer) 3-Does $S_n$ converge? (Still open) I believe this can be related to the precision of rational approximations of $\pi$ because for some integer $a$ there exists $b\in]0,\pi[$ such that: $$
n= a\pi+b
$$ Then: $$
|\sin(n)|=|\sin(a\pi+b)| = |\sin(b)|
$$ And: $$
\pi = \frac{n}{a}-\frac{b}{a}
$$ So $n/a$ is a rational approximation of $\pi$ with error smaller than $\pi/a$ in absolute value. But since $b$ is in the interval ]0,\pi[ (cannot be zero because $\pi$ is irrational), then the sequence is basically the value of the smallest $b$ found for $k\leq n$ . My guess is that the sequence converges to zero, even if it never reaches zero (just like a geometric progression). I would also believe the series is convergent, but these would depend on how fast the accuracy of the rational approximations to $\pi$ grows with respect to their denominator.","['rational-numbers', 'sequences-and-series', 'irrational-numbers']"
2705149,Explanation between differential relationship between circumference and radius of a circle.,"We know the area of the circle is $$A(r)=\pi r^2$$Differentiate it with respect to $r$. 
$$A'(r)=2\pi r$$
which turns out to be the circumference of the circle. A similar behaviour is observed with the volume of sphere $$V(r)=\frac{4}{3}\pi r^3$$
Differentiate with respect to $r$.$$V'(r)=4\pi r^2$$
which coincidently turns out to be the surface area of the volume. Is this result purely coincidental? The property is also found in cubes (in some fashion) $$S(r) = 6r^2 = 2\frac{dr^3}{dr} = 2V'(r)$$
Is there something special about these shapes which can be modeled by the function$$V'(r)= kS(r)$$",['geometry']
2705228,Expected value within system of coupled differential equations,"My apologies if this is a silly question. I'm developing a model for an applied system and I'm stuck. This is a (simplified) version of my model. $x'=m(y-x)-qx$ $y'=m(x-y)-qy+m(z-y)$ where $z=x{(t_0)=y(t_0)} $ and $m$ and $q$ are my parameters I want to estimate. I was able to calculate the analytical solution of the form $\begin{bmatrix}x\\y\end{bmatrix}=c_1v_1e^{\lambda t}+c_2v_2e^{\lambda t}$. Now I want to figure out how I'm actually going to input my data/likelihood in the model so that I can estimate m and q. My data are $qx$ and $qy$ at times $t=0, 1, ..., 5$, and the likelihood for them can be modeled via a Poisson distribution. I feel like I'm misunderstanding something, but I don't know how I would put in my expected values into this model. What am I missing?","['expectation', 'ordinary-differential-equations', 'mathematical-modeling']"
2705235,Polynomials of degree $\ge2$ whose images partition $\mathbb{N}$,"I'm looking for a set of polynomials $S\subset \mathbb{Z}[X]$ such that 
$$f(\mathbb{Z})\cap g(\mathbb{Z})\cap\mathbb{N}=\emptyset$$ for all $f\neq g\in S$ and such that
$$\bigcup_{f\in S}f(\mathbb{Z})\supset \mathbb{N}.$$
Now, this is pretty easy. Simply take $\{X\}\in \mathbb{Z}[X]$. However, I'm imposing the extra condition that 
$$\min\{\deg f:f\in S\}\ge 2.$$ Question does such a set of polynomials exist? It's clear that such a set of polynomials must be infinite, but that's about as far as I got. Maybe one could generate these polynomials recursively, by taking the first few and then finding a polynomial which attains the lowest value not yet covered, while never obtaining a value already obtained by one of the others, but I fail to see how that would work exactly.","['number-theory', 'reference-request', 'polynomials', 'elementary-number-theory']"
2705269,Compactness implies closedness,"I was reading the post: How to prove that a compact set in a Hausdorff topological space is closed? Quoting the accepted answer: Fix $x\in\mathbb{X}\setminus K$. Since $\mathbb{X}$ is Hausdorff, for
  each $y\in K$ there are disjoint open sets $U_y$ and $V_y$ such that
  $x\in U_y$ and $y\in V_y$. $\{V_y:y\in K\}$ is an open cover of $K$,
  so it has a finite subcover, say $\{V_y:y\in F\}$, where $F$ is some
  finite subset of $K$. Let $$U=\bigcap_{x\in F}U_x\;;$$ clearly $U$ is
  an open nbhd of $x$ disjoint from $K$. Since $x$ was an arbitrary
  point of $\mathbb{X}\setminus K$, $K$ must be closed. Why is $\{V_y \mid y \in K\}$ an open cover of $K$? I mean, to use compactness in the argument, we need that the set $V_y \subseteq K$, otherwise I don't see how it can be part of an open cover in the subspace $K$.","['general-topology', 'compactness', 'separation-axioms', 'proof-explanation']"
2705285,"Intuitive/Visual solution for: There are $k$ balls in a bowl. How many draws does it on average take, to get one specific ball?","I have the following problem: There are $k$ balls in a bowl. So $k$ different possibilities of the same probability $\frac{1}{k}$ to be drawn from the bowl. Any drawn ball is immediately replaced into the bowl again. How many draws does it on average take, to get one specific ball? With $k=2$ it would be like a coin toss. With $k=6$ like rolling a dice. So, you see, it's not really an advanced problem. However, I'm looking for the most intuitive/visual solution.",['combinatorics']
2705331,How can I determine the transfer function of this servomechanism system?,"How can I find transfer function of the given servomechanism system with input $V$(voltage) and output $θ_L$(angle of the load). Schematic of the system is given below. Schematic of the servomechanism system There are two differential equations of the given system.
$$\dot{\omega}_L=-\dfrac{k_T}{J_L}\left[θ_L-\dfrac{1}{\rho}θ_M\right]-\dfrac{β_L}{J_L}\omega_L$$
$$\dot{\omega}_M=\dfrac{k_M}{RJ_M}\left[V-k_M\omega_M\right]-\dfrac{β_M}{J_M}\omega_M+\dfrac{k_T}{ρJ_M}\left[θ_L-\dfrac{1}{\rho}θ_M\right] $$ $k_T, J_L, ρ, k_M, J_M, β_L, β_M $ and $R$ are positive constants. In this case, $$F(s)=\dfrac{θ_L(s)}{V(s)}$$ has to be found.","['control-theory', 'ordinary-differential-equations', 'transfer-theory']"
2705373,Prove that $F_{125n}$ is divisible by $125$.,"$F_{n+2}=F_{n+1}+F_n$ , $F_1=F_2=1$ . Prove that $F_{125n}$ is divisible by $125$ . How we can prove it by easiest way? For example, I know that we can prove that: $$F_{5n}=25F_n^5+25(-1)^nF_n^3+5F_n.$$ Because from here it follows, although I think it's very ugly. Thank you!","['fibonacci-numbers', 'divisibility', 'algebra-precalculus', 'number-theory', 'sequences-and-series']"
2705423,Evaluating $\int\limits_0^\infty{\frac{1}{1+x^2+x^\alpha}dx}$,"I'm trying to evaluate$$f(\alpha)=\int\limits_0^\infty{\frac{1}{1+x^2+x^\alpha}dx}$$
I proved: $f(\alpha)$ converges when $\alpha\in\mathbb{R}$ $f(2-\alpha)=f(\alpha)$ $f(0)=f(2)=\frac{\pi}{2\sqrt{2}}$ $f(1)=\frac{2\pi}{3\sqrt{3}}$ $f(-\infty)=f(\infty)=\frac{\pi}{4}$ Similar question:$$\int\limits_0^\infty{\frac{1}{1+x^\alpha}dx}=\frac{\pi}{\alpha}\csc\frac{\pi}{\alpha}$$
I tried all of the techniques can be used in evaluating this integral, but I still cannot get the answer.
When I was using complex analysis, I found that the poles of $\frac{1}{1+x^2+x^\alpha}$ is hard to be found.","['complex-analysis', 'integration', 'definite-integrals', 'calculus']"
2705478,Proof of $n!\geq2^{n-1}$ by mathematical induction,"I am trying to make a proof $$n!\geq2^{n-1}\;\;\forall \;n\in N$$ Here's what I've done! $ \text{When}\;\; n=1,\;\; 2^{0}\leq 1!$, $ \text{when}\;\; n=2,\;\; 2^{1}\leq 2!$, $ \text{when}\;\; n=3,\;\; 2^{2}\leq 3!$, $\vdots$ Assume it is true for $n=k$, then $$2^{k-1}\leq k!$$. Now, we want to prove for $n=k+1$. I got stuck at this point. I need help! Thanks!","['algebra-precalculus', 'induction', 'proof-writing']"
2705493,Different characterizations of Liouville numbers,"Usually, Liouville numbers are defined as follows:
$x$ is Liouville if for ever $i\in\mathbb N$ there exist $n,m\in\mathbb Z$ such that
\begin{equation}
\left|x-\frac nm\right|<\frac1{m^i}.
\end{equation}
In their 1982 paper on almost-periodic Schrödinger operators, however, Avron and Simon use the following definition:
$x$ is Liouville if for ever $i\in\mathbb N$ there exist $n,m\in\mathbb Z$ such that
\begin{equation}
\left|x-\frac nm\right|<\frac1{i^m}.
\end{equation}
Do these sets of numbers agree? If yes, how can one show that?","['analytic-number-theory', 'liouville-numbers', 'number-theory', 'continued-fractions', 'elementary-number-theory']"
2705511,Partial Differential Equation to evaluate double series,"I was trying to compute a closed form for the double series
$$f(x,y,z)=\sum_{m,n=1}^\infty \frac{x^m y^n z^{m+n}}{m!(m+n)!}$$
and I noticed the fact that
$$\frac{\partial^2f}{\partial x\partial z}-f=e^y-1$$
I know how to solve some somewhat advanced differential equations for functions of one variable, but I know nothing about how to solve partial differential equations. Can someone show me how to solve this one? I did have one little insight about this equation. Since no derivatives are taken with respect to $y$ on the LHS of the differential equation, I can just treat $e^y-1$ as if it was a constant and instead solve the differential equation as if $f$ were a function $f(x,z)$ of two variables only. But since I don't know how to get started, this doesn't help me.","['power-series', 'ordinary-differential-equations', 'sequences-and-series', 'partial-differential-equations']"
2705645,Validity of proving identities by showing LHS-RHS =0 or using reversible steps?,"When proving $\mathrm{LHS}=\mathrm{RHS}$, the most common way of doing it is by manipulating it in such a way to show that $\mathrm{LHS}$ equals to some expression which equals to $\mathrm{RHS}$. But what about these methods: Method 1: Showing that $\mathrm{LHS}-\mathrm{RHS}=0$ For instance, if we are required to prove $x^2\cos^2(x)+\sin^2(x) = x^2 - x^2\sin^2(x) + 1 - \cos^2(x)$ We instead show that $\mathrm{LHS}-\mathrm{RHS}=0$ as follows: $\mathrm{LHS} - \mathrm{RHS} = x^2\cos^2(x)+\sin^2(x) - x^2 + x^2\sin^2(x) - 1 + \cos^2(x)$ $ = x^2(\cos^2(x) + \sin^2(x)) - x^2 + (\sin^2(x) + \cos^2(x))  - 1$ $= x^2 - x^2 + 1 - 1 = 0$ Method 2: Showing that $\mathrm{LHS}=\mathrm{RHS}$ is equivalent with another equation which is true (taking care that we can always reverse the steps and showing it by putting $\iff$): $x^2\cos^2(x)+\sin^2(x) = x^2 - x^2\sin^2(x) + 1 - \cos^2(x)$ $ \iff  x^2\cos^2(x)+x^2\sin^2(x) - x^2 = 1 - \sin^2(x) - \cos^2(x)$ $ \iff x^2 - x^2 = 1 - 1$ $ \iff 0 = 0$ Are these two methods of proving valid? Are there any cases where we can make fallacious argument by using these methods? Are any one of them better than the other?","['proof-writing', 'trigonometry', 'logic']"
2705710,Geometry textbooks for university students,"I am a master's student with interests in algebraic geometry and number theory. And I have a good collection of textbooks on various topics in these two fields. Also, as part of my undergraduate curriculum, I learnt abstract algebra from the books by Dummit-Foote , Hoffman-Kunze , Atiyah-MacDonald and James-Liebeck ; analysis from the books by Bartle-Sherbert , Simmons , Conway , Bollobás and Stein-Shakarchi ; topology from the books by Munkres and Hatcher ; and discrete mathematics from the books by Brualdi and Clark-Holton . I also had basic courses in differential geometry and multivariable calculus but no particular textbook was followed. (Please note that none of the above-mentioned textbooks was read from cover to cover). As you can see, I didn't learn much geometry during my past 4 years of undergraduate mathematics. In high school, I learnt a good amount of Euclidean geometry but after coming to university geometry appears very mystical to me. I keep hearing terms like hyperbolic/spherical geometry, projective geometry, differential geometry, Riemannian manifold etc. and have read general maths books on them, like the books by Hartshorne , Ueno-Shiga-Morita-Sunada and Thorpe . I will be grateful if you could suggest a series of books on geometry (like Stein-Shakarchi 's Princeton Lectures in Analysis) or a book discussing various flavours of geometry (like Dummit-Foote ). I am aware that Coxeter has written a series of textbooks in geometry, and I have read Geometry Revisited in high school (which I enjoyed). If these are the ideal textbooks, then where to start? Also, what about the geometry books by Hilbert ? Thank you for reading.","['reference-request', 'book-recommendation', 'geometry']"
2705715,"Choosing Colored Ball, probability of second choice not knowing first","There are 50 balls in an urn, 30 are red and 20 are blue. If a single ball is taken and we don't look at its color, what is the probability that the second ball is red? I know that there is a 60% chance of choosing a red ball from the first choice, and 40% of not. That means for the second ball there is either (29 choose 1)/(49 choose 1) 60% of the time or (30 choose 1)/(49 choose 1) 40% of the time. I then multiplied the probabilities (60% and 40%) by each of the options and got a 60% chance of the second ball being red. Is this the correct way to approach this problem?","['combinatorics', 'probability', 'discrete-mathematics']"
2705728,Does there exists such a function?,"A function from $f:\mathbb{R} \rightarrow \mathbb{R}$ such that : a. $f$ is bijective, b. $f’(0)=1$ (in particular, $f$ is differentiable and therefore continuous at 0), and c. $f^{-1}$ is not continuous at 0. I think it exists! But don’t know how to find it. Thanks for any help!","['derivatives', 'functions']"
2705739,Green's Function for a Fourth-Order Differential Equation,"I have just begun to look at Green's functions and am studying a fourth-order equation $\frac{d^4y}{dx^4}=f(x) \:\:\:\:\:\:y(0)=y'(0)=0\:\:\:\:\:\:y(1)=y'(1)=0$ In particular I have to show that the Green's function $G(x,u)$ for this equation satisfies a condition $\lim_{\epsilon\to0}\bigg[\frac{\partial^3G}{\partial x^3}\bigg]_{x=u-\epsilon}^{u+\epsilon}=1$ and must demonstrate the continuity of the Green's function and its first and second partial derivatives with respect to $x$ at $x=u$.  I am fairly new to Green's functions so would appreciate some pointers.","['greens-function', 'ordinary-differential-equations']"
2705759,l'Hopital's rule for 2 variables to compute Jacobian matrix,"I have a system of three ODEs and I have computed the Jacobian matrix. One of the steady states is (0,0,0) and I am trying to linearize the system around this steady state.
In the Jacobian matrix two of the terms are of the form $cx^2\over cx+y$ and $z\over y$.Here, $x,y,z$ are the variables of the system and $c$ is a known constant. But when substituting x=0,y=0 and z=0 to the above terms it will be $0\over 0$. So, in this case, can I use L'hospital rule for 2 variables to compute the Jacobian around that steady state? That is I want to find $\lim_{(x,y)\to (0,0)}{ cx^2\over cx+y}$ and $\lim_{(z,y)\to (0,0)} {z\over y}$. I referred to the article on l'Hopital's rule for multi variable functions and with what it says in the article I could not find the limit of $\lim_{(x,y)\to (0,0)}{ cx^2\over cx+y}$ and the limit of $\lim_{(z,y)\to (0,0)} {z\over y}$ does not exist. Can someone please let me know a method to evaluate the two terms around the steady state.","['limits', 'multivariable-calculus', 'steady-state', 'jacobian', 'ordinary-differential-equations']"
2705774,variance of regression estimators,"Given the regression eqn: $y_0= \beta_0 +\beta_1 x_i + \epsilon_i$ I am having difficulty in calculating the variance of $\beta_0$ Here is how I proceeded:- $\operatorname{Var}(b_0)= \operatorname{Var}(\bar Y -b_1\bar X)$, where $b_0,b_1 \text{are parameters estimator} $; \begin{align}
\operatorname{Var}(b_0)& =\operatorname{Var}(\bar Y)+\operatorname{Var}(b_1\bar X) -2\operatorname{Cov}(\bar Y,b_1\bar X)\\[10pt]
&= \operatorname{Var}(\bar Y)+(\bar X)^2\operatorname{Var}(b_1) -2\bar X\operatorname{Cov}(\bar Y,b_1)\\
\end{align} I have already got the value of $Var(b_1)$,but i cannot prove $\operatorname{Cov}(\bar Y,b_1)=0$. Thanks!","['regression', 'statistics', 'linear-regression']"
2705816,"Set and Inequality, something like generating function.","Given positive integer $N$, whether there exist two distinct sets $A$, $B$ such that $\left| A\right|, \left| B\right| \leqslant N^2$, and for any $x\in (0,1)$, the following one holds:$$\left|\sum_{a\in A}x^{a}-\sum_{b\in B}x^{b}\right| \lt (1-x)^{N}?$$ I'm even not sure about the answer, but at least it is positive when $N=1$, and I guess that it’s the same for all $N$. I also think that it may be related to pigeonhole principle, like choosing a number of $(A, B)$ with some bound... Please help.","['generating-functions', 'inequality', 'elementary-set-theory', 'pigeonhole-principle']"
2705840,The use of modulo in the mathematical induction proof of $7^{2n}-9$ being divisible by 2,"I tried proving that $7^{2n}-9$ is divisible by 2 in the following way: Base case: When $n=1$, $$7^{2}-9\equiv 0\;(\text{mod}\,2)$$ Induction step: Assume $n=k$, $$7^{2k}-9\equiv 0\;(\text{mod}\,2)$$ We want to prove that it is true for $n=k+1$, $$7^{2(k+1)}-9=7^{2k+2}-9=49\cdot7^{2k}-9$$ $$=49\cdot7^{2k}-9=49\cdot[0\;(\text{mod}\,2)+9]-9.$$ Since I couldn't continue, I used the following instead: Induction step: Assume $n=k$, $$7^{2k}-9=2a$$ For $n=k+1$, $$7^{2(k+1)}-9=7^{2k+2}-9=49\cdot7^{2k}-9$$ $$=49\cdot7^{2k}-9=49\cdot(2a+9)-9=2(49a+216)=2b.$$ Can anyone show me how to prove this by modulo instead?","['algebra-precalculus', 'induction', 'proof-writing', 'proof-explanation']"
2705845,"Methods for finding some function $h$ with the property that, given two functions $f,g$, then $h\circ f=g\circ h$ is true?","Given two functions $f,g$, I need to find a function $h$ such that $h\circ f=g\circ h$. For example, if $f(x)=x+1$ and $g(x)=x-1$ where $f,g:\Bbb Z\to\Bbb Z$. Then $h$ must have the property that $h(f(x))=g(h(x))\iff h(x+1)=h(x)-1$. Here it is easy to see that if $h(x)=-x$ the property holds, because $-(x+1)=-x-1$. Another example is if $f(x)=x+1$ and $g(x)=2x$, then $h(x+1)=2h(x)$ must be true, and if $h(x)=2^x$, then $h$ has the said property. But in this examples $h$ is found just intuitively, is there a general way to find $h$ for any given two functions $f$ and $g$? If there is not a general way, is there some specific way with specific choices of $f$ and $g$? Thanks.","['elementary-set-theory', 'functions']"
2705899,Expressing $\tan 20°$ in terms of $\tan 35°$,"If $\tan 35^\circ = a$, we are required to express $\left(\frac{\tan 145^\circ - \tan 125^\circ}{1 + \tan 145^\circ\tan 125^\circ}\right)$ in terms of $a$. Here's one way to solve this:  $$\frac{\tan 145^\circ - \tan 125^\circ}{1 + \tan 145^\circ\tan 125^\circ} = \tan (145^\circ - 125^\circ) = \tan 20^\circ = \tan (90^\circ - 70^\circ) = \cot 70^\circ = \frac{1}{\tan 70^\circ} = \frac{1}{\tan (2 \times 35^\circ)} = \frac{1 - \tan^2 35^\circ}{2\tan 35^\circ} = \frac{1 - a^2}{2a}$$
However, I tried to solve it using another method as described below, and faced a problem:
$$\frac{\tan 145^\circ - \tan 125^\circ}{1 + \tan 145^\circ\tan 125^\circ} = \tan 20^\circ = \tan (35^\circ - 15^\circ) = \frac{\tan 35^\circ - \tan15^\circ}{1 + \tan 35^\circ\tan 15^\circ} = \frac{a - (2 - \sqrt3)}{1 + a(2 - \sqrt3)} = \frac{a - 2 + \sqrt3}{1 + 2a - \sqrt3a}$$
I tried to simplify it to get $\frac{1 - a^2}{2a}$, but I couldn't. So my question is, is there any way to show that $\frac{a - 2 + \sqrt3}{1 + 2a - \sqrt3a}$ is equal to $\frac{1 - a^2}{2a}$? If not, why are we getting two different answers?",['trigonometry']
2705980,Is it legitimate to divide both sides of an ODE by a dependent variable that can equal zero?,"I have the following problem:
\begin{cases}
y(x) =\left(\dfrac14\right)\left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 \\
y(0)=0 
\end{cases}
Which can be written as: $$ \pm 2\sqrt{y} = \frac{dy}{dx} $$ I then take the positive case and treat it as an autonomous, seperable ODE.  I get $f(x)=x^2$ as my solution. In order to solve this problem, I have to divide each side of the equation by $\frac{1}{\sqrt{y}}$.  But since the solution to this IVP is $y(x)=x^2$, zero is in the image of $f(x)$.  So at a particular point $1/\sqrt{y}$ is not defined.  But the solution is defined at $y =0$. In fact, $y(x)= 0$ for all x is another solution.  But aside from this solution the non-trivial solution is defined at zero also. So is it wrong to divide across by $1/\sqrt{y}$? And if so how else do I approach this question?",['ordinary-differential-equations']
2705990,Find the area of a circle part of which is in a square,"I have a square with sides of 10cm and I have a circle with radius of 6cm. Now I've to find the area of the circle that is inside of the square.Here is the graph I had an idea of finding the area of the arc(90 degrees) and subtracting it from 25(100/4), but then I noticed that the area of arc would still include the areas which are outside of the square.","['area', 'geometry']"
2706007,Matrix inverse $A^{-1}$ as linear combination of the powers of $A$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $A \in \mathbb{R}^{n \times n}$ be any invertible matrix. Can $A^{-1}$ always be expressed as a linear combination of the powers of $A$, i.e. $$A^{-1}=\sum_{i=0}^\infty c_iA^i\,,$$
for an appropriate choice of coefficients $\{c_i\}_{i=0}^\infty$?","['matrices', 'matrix-calculus', 'inverse', 'power-series', 'linear-algebra']"
2706029,Painting triangles in array,"In an $a\times b$ array, each cell is divided into four triangles by the two diagonals. Some of the $4ab$ triangles are painted, so that every unpainted triangle shares a side with at least one painted triangle. What is the minimum 
number of painted triangles? Assume wlog that $a\leq b$. Suppose we paint the left triangle of every cell. This takes care of all triangles except the right triangles of the rightmost column. Painting those triangles gives $ab+a$ triangles in total. I think this should be the minimum, but how can it be proven?",['combinatorics']
