question_id,title,body,tags
762895,Positive integer solutions to $x^2+y^2+x+y+1=xyz$,"The question asks for positive integer solutions to $x^2+y^2+x+y+1=xyz$ . We at first note that $x|y^2+y+1$. Now,let there exist positive integers $x,y$ that satisfy the given equation.Then $mx=y^2+y+1$ for some positive integer $m$ .Substituting this in the original equation yields $$x^2+x+mx=xyz$$ $$\implies x+1+m=yz$$ $$\implies \dfrac{y^2+y+1}{m}+1+m=yz$$ $$\implies y^2+y+m^2+m+1=myz$$ This equation's exactly like the equation we were trying to solve.Unfortunately,however,this does not let us use FMID since we don't know if $m<x$. The above problem is from Titu Andreescu's book on intro to diophantine equations.He does give a solution,but I was wondering if my approach could be used somehow.I am also interested in seeing other approaches.Thanks is advance.","['elementary-number-theory', 'diophantine-equations', 'vieta-jumping', 'number-theory']"
762929,let $\xi$ be an arbitrary vector bundle. Is $\xi\otimes\xi$ always orientable?,"Let $\xi=(E,p,B)$ be a line bundle (not nec. orientable). Then the tensor product $\xi\otimes \xi$ is orientable. I obtain this by choosing $b\in U\cap V$, $U,V$ open in $B$ such that $\phi_U:p^{-1}(U)\longrightarrow U\times \mathbb{K}^n$,$\phi_V:p^{-1}(V)\longrightarrow V\times \mathbb{K}^n$. $(b,x)\in E$. Then $\phi_U(b,x)=(b,u)$, $u\in \mathbb{K}^n$,  $\phi_V(b,x)=(b,v)$, $v\in \mathbb{K}^n$. Then $\phi_V\phi_U^{-1}(b,u)=(b,v)$, $v=\lambda(b)u$. Thus for any $(b,x_1\otimes x_2)\in F_b(\xi_1\otimes \xi_2)$,
$\phi_V\phi_U^{-1}(b,u_1\otimes u_2)=(b,v_1\otimes v_2)=(b,\lambda(b)u_1\otimes\lambda(b)u_2)=(b,\lambda(b)^2 u_1\otimes u_2)$ hence the transition map is a positive scalar multiple and the tensor product is oriented line bundle. Is my way correct or not? Is there more clear way to prove this? In general, let $\xi$ be an arbitrary vector bundle. Is $\xi\otimes\xi$ always orientable? How to prove? I am confused. Thanks.","['differential-geometry', 'fiber-bundles', 'manifolds', 'algebraic-topology', 'differential-topology']"
762931,Interchange of limiting operations (question from an engineer),"I need to clarify when are the below operations valid. If possible, please link me to the related theorems, where I can find details. 1- Given a double integral 
\begin{equation}
\int_{X}\int_Y f(x,y) \:\mathrm{d}y\:\mathrm{d}x
\end{equation}
Under what conditions on $f$ the interchange of the order of integration is valid so that
\begin{equation}
\int_{X}\int_Y f(x,y)\:\mathrm{d}y\:\mathrm{d}x = \int_{Y}\int_X f(x,y)\:\mathrm{d}x\:\mathrm{d}y
\end{equation}
A related question here, is when we have, instead of a double integral, one integral and infinite sum. For example 
\begin{equation}
\sum_{n=-\infty}^{+\infty} h(n) \int f(x)g(n) \:\mathrm{d}x
\end{equation}
where $n$ is integer, and $x\in \mathbb{R}$. When is the following valid?
\begin{equation}
\sum_{n=-\infty}^{+\infty} h(n) \int_X f(x)g(n) \:\mathrm{d}x = \int_X  f(x) \left(\sum_{n=-\infty}^{+\infty} h(n)g(n)\right) \:\mathrm{d}x
\end{equation} 2- Under what conditions on the integrand, the interchange of the derivative and integral signs is vaild. For example, 
when can we say that:
\begin{equation}
\frac{\partial}{\partial t} \left(\iint_S u(x,y,t) \:\mathrm{d}x \:\mathrm{d}y\right)= \iint_S \frac{\partial}{\partial t}u(x,y,t) \:\mathrm{d}x \:\mathrm{d}y
\end{equation}","['summation', 'derivatives', 'limits']"
762932,Higher Order Derivative Proof .,"I would appreciate if someone could check over my proof for this question and advise me if it is correct. My attempt so far; Now as $f$ is k times differentiable , it taylor series about $x_{0}$ can be written as follows, $$f(x)=f(x_{0})+f'(x_{0})(x-x_{0})+f''(x_{0})\frac{(x-x_{0})^2}{2!}+...+f^{(k)}\frac{(x-x_{0})^k}{n!}$$ We are given that; $$f'(x_0)=...=f^{(k-1)}(x_0)=0 $$ and $$f^{(k)} \neq 0$$ Sow we can conclude that we end up with something looking like this... $$f(x)=f(x_{0})+f^{(k)}\frac{(x-x_{0})^k}{n!}$$. And I also know the fact in the neighbourhood of $x_0$ 1) if $x_0$ is a local minimum, then in a neighbourhood of $x_0$, $f(x)-f(x_0)>0,$ 2) if $x_0$ is a local maximum, then in a neighbourhood of $x_0$, $f(x)-f(x_0)<0.$ And from what we have : $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}$$. Now I just have to put this together; CASE 1: $k$ is Even Subcase 1 :   If  $f^{(k)}<0$. Then looking at the interval $x \in (x_0 - \delta,x_0 + \delta)$ We have $x<x_0$  implies that $(x-x_0)^{k}>0$ as $k$ is even and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}<0$$ Implying $f(x)$ is increasing on $(x,x_0)$. $x>x_0$  implies that $(x-x_0)^{k}>0$ and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}<0$$ Implying $f(x)$ is decreasing on $(x_0,x)$. So this implies a maximum, as in the neighbourhood of $x_0$, $f(x)-f(x_0)<0.$. Subcase 2: If  $f^{(k)}>0$. Then looking at the interval $x \in (x_0 - \delta,x_0 + \delta)$ We have   ; $x<x_0$  implies that $(x-x_0)^{k}>0$ as $k$ is even and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}>0$$ Implying $f(x)$ is decreasing on $(x,x_0)$. $x>x_0$  implies that $(x-x_0)^{k}>0$ and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}>0$$ Implying $f(x)$ is Increasing on $(x_0,x)$. So this implies a minimum, as in the neighbourhood of $x_0$, $f(x)-f(x_0)>0.$. And so this proves $(i)$; CASE 2: $k$ is odd; Subcase 1 :   If  $f^{(k)}<0$. Then looking at the interval $x \in (x_0 - \delta,x_0 + \delta)$ We have $x<x_0$  implies that $(x-x_0)^{k}<0$ as $k$ is odd and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}>0$$ Implying $f(x)$ is decreasing on $(x,x_0)$. $x>x_0$  implies that $(x-x_0)^{k}>0$ and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}<0$$ Implying $f(x)$ is decreasing on $(x_0,x)$. So $f$ is strictly decreasing on neighbourhood $x_0$. Subcase 2: If  $f^{(k)}>0$. Then looking at the interval $x \in (x_0 - \delta,x_0 + \delta)$ We have   ; $x<x_0$  implies that $(x-x_0)^{k}<0$ as $k$ is even and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}<0$$ Implying $f(x)$ increasing on $(x,x_0)$. $x>x_0$  implies that $(x-x_0)^{k}>0$ and so $$f(x)-f(x_{0})=f^{(k)}\frac{(x-x_{0})^k}{n!}>0$$ Implying $f(x)$ is Increasing on $(x_0,x)$. So $f$ is strictly increasing on neighbourhood $x_0$. So this Proves part $(ii)$.      $\blacksquare$ EDIT: I know this proof is tedious and long but is it correct... I also realise induction would have been much quicker but felt that this strengthens my understanding better.","['taylor-expansion', 'proof-verification', 'derivatives', 'analysis']"
762958,Why $A\in A$ not reflexive,I have been reading Naive Set theory book by Holmes and it is stated that $A\in A$ is not true of any reasonable set and hence it isn't reflexive. Why isn't belonging ($\in$) reflexive ? I cannot convince myself why it isn't reflexive. Can anybody explain it with some simple examples.,['elementary-set-theory']
762962,Fundamental matrix in ODE,"Let $A(t)$ a matrix $n \times n$ of continuous functions in an interval $I\subseteq\mathbb{R}$. If for all $t$ $$\left[\int_{to}^tA(s)ds  \right]A(t) = A(t)\left[\int_{to}^tA(s)ds\right].$$
Show that $\displaystyle \phi(t)= e^{\large{\int _{t_0}^tA(s)ds}}$ is a fundamental matrix of $x' = A(t)x$.",['ordinary-differential-equations']
762964,Sufficient statistic for normal distribution with unknown mean and known variance,"Let $X$ be from a normal distribution $N(\theta,1)$ . a) Find a sufficient statistic for $\theta$ . b) Is $S_n^2$ a sufficient statistic for $\theta$ ? My answers For part a) Since the joint p.d.f is $1 \over (2\pi)^{n/2}$ , $e^{{-1 \over 2}\sum(x_i-\theta)^2}$ , I can say that $\sum X_i$ is  a sufficient statistic for $\theta$ because $e^{{-1 \over 2}\sum(x_i-\theta)^2}$ depends on X only through the values of $\sum X_i$ right? Because if I know the value of $\sum X_i$ ,  then I know $\sum X_i^2$ as well. For part b) Expanding the joint p.d.f as $\frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\sum(x_i-\theta)^2} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\sum(x_i- \bar x + \bar x-\theta)^2} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\Big[\sum(x_i- \bar x)^2+n(\bar x-\theta)^2\Big]} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\Big[{\sum(x_i- \bar x)^2 \over n-1}n-1+n(\bar x-\theta)^2\Big]}$ . Now can I say $S_n^2$ is a sufficient statistic for $\theta$ . Is it a problem that I have $\bar x$ in the function $g(S_n^2,\theta)$ ?. Because $\bar x$ is a particular value I thought $g(S_n^2,\theta)$ depends on $\theta $ only through the values of $S_n^2$ .","['statistics', 'statistical-inference', 'parameter-estimation']"
762973,Stokes theorem and Sobolev spaces.,"I am interested under which regularity condition is Stokes' theorem is still valid. For concreteness I am interested in the following problem Let's consider a domain $\Omega$ in $\mathbb{R}^{3}$  given in cylindrical coordinates by $0\le z\le 1 $,$0\le \theta\le2\pi$,$0\le \rho\le b$. Now let $f\in H^{2}(\Omega)$. If we apply Stokes' theorem for the domain $\Omega_{\epsilon}$ in $\mathbb{R}^{3}$  given in cylindrical coordinates by $0\le z\le 1 $,$0\le \theta\le2\pi$,$\epsilon\le \rho\le b$ we have:
\begin{equation}
\int_{\Omega}\nabla\cdot \nabla fd\Omega=\int_{\partial\Omega_{\epsilon}}\frac{\partial f}{\partial x^{i}} n^{i} dS
\end{equation}
which is well-defined because the trace theorem warranty that $\frac{\partial f}{\partial x^{i}}\in H^{1/2}$. Now in the case when $\epsilon\rightarrow0$ the boundary integral is:
\begin{equation}
\lim_{\epsilon\rightarrow 0}\int_{\partial\Omega_{\epsilon}}\frac{\partial f}{\partial x^{i}} n^{i} dS=\int\frac{\partial f}{\partial x^{i}}b d\theta dz-\lim_{\epsilon\rightarrow 0}\int\frac{\partial f}{\partial x^{i}}\epsilon d\theta dz
\end{equation} If $f$ is smooth then the limit vanishes. However in the low differentiability case I have the following questions: In the limit $\frac{\partial f}{\partial x^{i}}$ has to be restricted to a codimension 2 domain. What can I say about the regularity of the trace in the codimension 2? In case $f$ has even lower regularity such that the trace in the codimension 2 case is in a negative Sobolev space,should the limit be consider to be a functional? What's is the lower differentiability required for Stokes' theorem to hold?","['sobolev-spaces', 'functional-analysis', 'real-analysis']"
762983,Proof of compactness of Lipschitz functions,"Consider the set $\mathcal{F}$ of continuous functions on $[0;1]$ with boundary values
$$
f(0)=f(1)=0 \qquad \forall f \in \mathcal{F}.
$$
Define the metric $d(f,g) = \lVert f-g \rVert_\infty = \sup_{0 \leq x \leq 1} |f(x)-g(x)|$ and the Lipschitz constant
$$
L(f) = \sup_{0 \leq x_1 < x_2 \leq 1} \left|\frac{f(x_1)-f(x_2)}{x_1-x_2}\right|.
$$
Define the subset of Lipschitz-continuous functions as $\mathcal{L}_M = \left\{ f \in \mathcal{F} \colon L(f) \leq M \right\}$. I want to show that the metric space $(\mathcal{L}_1,d)$ is a compact subset of $(\mathcal{F},d)$. What are the steps to do this? Here is my proof sketch: Prove that $(\mathcal{L}_1,d)$ is totally bounded (easy!) Prove that any sequence in $\mathcal{L}_1$ is equicontinuous. Infer from 1. and 2. by the Arzelà-Ascoli Theorem that $(\mathcal{L}_1,d)$ is relatively compact in the Banach space $(\mathcal{F},d)$ Prove that any Cauchy sequence in $(\mathcal{L}_1,d)$ converges to an element from $\mathcal{L}_1$, i.e., show that $(\mathcal{L}_1,d)$ is complete . Since $(\mathcal{L}_1,d)$ is relatively compact and complete, it is therefore compact. QED. Step 4. gives me headaches. That's because for any Cauchy sequence $(f_n)_n$, the sequence $(L(f_n))_n$ can be any sequence you like (in the unit interval). As a remedy, I could switch to a stronger metric
$$
d(f,g) = \lVert f-g \rVert_\infty + \sup_{0 \leq x_1 < x_2 \leq 1} \left|\frac{f(x_1)-f(x_2)}{x_1-x_2}-\frac{g(x_1)-g(x_2)}{x_1-x_2}\right|
$$
But then how do I eventually get back to my original metric?","['continuity', 'functional-analysis', 'compactness']"
762984,What's the proof stategy for: Hermitian matrix has orthogonal eigenvectors for distinct eigenvalues?,"Linear Algebra (2015 5 ed) by Lay, p. 397. Theorem 7.1 involves only real numbers. Let: $A^* =  \bar{A}^T $ . $v_i$ and $v_j$ be two eigenvectors of an Hermitian matrix H. Suppose that their respective eigenvalues i and j are different, i.e. $\lambda_i \neq \lambda_j$ . This means $Hv_i = \lambda_iv_i$ and $Hv_j
 = \lambda_jv_j\ \  ...(3)$ . Take the Hermitian conjugate of $Hv_i = \lambda_iv_i$ : $\begin{align} (Hv_i)^* & = (\lambda_iv_i)^* \\ \implies v_i^* H^* & = v_i^* \lambda_i^* \\ \implies v_i^* H & = v_i^* \lambda_i \ \ (as\ H\ is\ hermitian)\end{align}$ Right-multiply the previous equation by $\color{green}{v_j}: \qquad
 v_i^*H \color{green}{v_j} = v_i^* \lambda_i \color{green}{v_j} \qquad
...(4)$ Left-multiply (3) by $\color{orangered}{v_i^*} : \quad
 \color{orangered}{v_i^*}Hv_j = \color{orangered}{v_i^*} \lambda_jv_j
 \qquad ...(5)$ . Equate the RHS of (4) and (5): $\quad  v_i^* \lambda_i
 \color{green}{v_j}  = \color{orangered}{v_i^*} \lambda_jv_j \qquad
 \blacksquare$ . I understand, and ask not about, the algebra. What's the proof strategy? For example, how can you divine when to take the Hermitian conjugate, what to multiply, and when to left- or right-multiply?","['hermitian-matrices', 'matrices', 'linear-algebra']"
762995,"Show that $e^{t(A+B)} = e^{tA}e^{tB}$ for all $t \in \mathbb{R}$ if, and only if $AB = BA$.","Let A,B real or complex matrixes. Show that $e^{t(A+B)} = e^{tA}e^{tB}$ for all $t \in \mathbb{R}$ if, and only if $AB = BA$. I demonstrated the reciprocal: $\Leftarrow )$ The two equations are solutions of $X' = (A+B)X$, $X(0)= I$, because $(e^{tA}e^{tB})' = Ae^{tA}e^{tB} + e^{tA}Be^{tB} = Ae^{tA}e^{tB} + Be^{tA}e^{tB} = (A+B)e^{tA}e^{tB}$   and $(e^t(A+B))' = (A+B)e^{t(A+B)}$. Thus, $e^{t(A+B)} = e^{tA}e^{tB}$. I have problems to demonstrate the implication.","['matrices', 'ordinary-differential-equations', 'exponential-function']"
763008,"If the intersection of a normal subgroup and the derived group is $\{e\}$, show that $N$ is a subset of $Z(G)$.","I think my reasoning is wrong, but if the intersection only contains the identity, doesn't that imply that the only commutator in $N$ is $\{e\}$ , so doesn't that mean $N$ is automatically commutative? Why was it necessary to state that $N$ was a normal subgroup? Thanks!","['group-theory', 'abstract-algebra', 'abelian-groups']"
763015,Inequality involving multiplicities of points introduced via Quadratic Transformations of a Plane Curve,"I've been learning about the resolution of singularities for plane curves, and have become stuck at exercise 7.15 of Fulton's Algebraic Curves (page 91 of the PDF). The question is: Let $F=F_1, \ldots, F_m$ be a sequence of quadratic transformations of a curve $F$ such that $F_m$ has only ordinary multiple points. Let $P_{i1}, P_{i2}, \ldots$ be the points on $F_i$ introduced, as in (7)(c) on Page 90 of the PDF, in going from $F_{i-1}$ to $F_i.$ (These are called ""neighboring singularities""). If $n = \text{deg}(F),$ show that $$ (n-1)(n-2) \geq \sum_{P\in F} m_P(F) \left( m_P(F)-1 \right) + \sum_{ i>1, j} m_{P_{ij}} (F_i) \left( m_{P_{ij}} (F_i)-1\right). $$ Just to be clear, $m_P(F)$ denotes the multiplicity of the point $P$ on the curve with equation $F=0.$ I really don't know how to even approach this problem. It certainly looks related to Theorem 2 on page 60 of the PDF which shows If $F$ is an irreducible curve of degree $n,$ then $$\sum_{P\in F} m_P(F) \left( m_P(F)-1 \right) \leq (n-1)(n-2)$$ But I can't see how to resolve the question.","['algebraic-geometry', 'algebraic-curves']"
763018,Distribution of the sum of normal random variables,"Let $X\sim \mathcal N(\mu_X,\sigma_X^2),\ Y\sim \mathcal N(\mu_Y,\sigma_Y^2)$ two normal random variables and $a,b\in \mathbb R$. If $X,Y$ are independent, then 
$$aX+bY\sim \mathcal N(a\mu_X+b\mu_Y,a^2\sigma_X^2+b^2\sigma_Y^2)$$
If $X,Y$ are jointly normally distributed with correlation $\text{corr}(X,Y)=\rho$, then
$$aX+bY\sim \mathcal N(a\mu_X+b\mu_Y, a^2\sigma_X^2+b^2\sigma_Y^2 + 2ab\rho\sigma_X\sigma_Y)$$ But what if $X,Y$ are neither independent nor jointly normally distributed, what can we say about the distribution of their sum? And what would be an example of a sum of normal random variables that is not normally distributed?","['probability-theory', 'normal-distribution', 'correlation']"
763035,Show that $x' = Ax$ is an attractor if end only if there is a quadratic form $q$ positive definite such that $Dq(x) . Ax < 0$ for all $x \neq 0$,Show that $x' = Ax$ is an attractor if end only if there is a quadratic form $q$ positive definite such that $$Dq(x) . Ax < 0$$ for all $x \neq 0$ Definition: a linear system $x' = Ax$ called attractor if for all $x \in \mathbb{R^n}$ called $$\lim_{t \rightarrow \infty}  e^{tA} = 0$$,"['exponentiation', 'ordinary-differential-equations', 'exponential-function']"
763047,Computing coefficient of $x^n$,"Find the coefficient of $x^n$ in the expansion of $$\left(1 + \frac{x}{1!} + \frac{x^2}{2!}+\cdots +\frac{x^n}{n!} \right)^2$$ How do you even start this problem? Do you use multinomial theorem or binomial theorem?
Could anyone please help? I found this in a textbook of mine. What I feel hard is what to do with the factorials?","['binomial-theorem', 'algebra-precalculus']"
763055,Trigonometric problem: Elevation angle [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question The elevation of the top of a tower $KT$ from a point $A$ is $27^\circ$. At another point $B$, $50$ meters nearer to the foot of the tower where $ABK$ is a straight line, the angle of elevation is $40^\circ$. Find the height of the tower $KT$.","['geometry', 'triangles', 'trigonometry']"
763094,Calculating real and imaginary part of a complex number,"Consider the complex numbers $a = \frac{(1+i)^5}{(1-i)^3}$ and $b = e^{3-\pi i}$. How do I calculate the real and imaginary part of these numbers? What is the general approach to calculate these parts? I thought about reforming them to the form $x + i\cdot y$ which might be possible for a, but what about b? I just started occupying with complex numbers and don't yet understand the whole context.","['complex-numbers', 'algebra-precalculus']"
763101,Cardinality of the set of all involutions from $\mathbb N$ to itself,"The following is a section in my homework, I couldnt solve it so I'm asking for some help. I have the following set : $\{f:\mathbb N \to \mathbb N | f(f(a)) = a \text{ for all } a\in \mathbb N\}$. I need to find if this set is a finite set, countably infinite set ($\aleph_0$) or infinite and uncountable. Thanks in advance for your help","['cardinals', 'elementary-set-theory']"
763122,Dot product with vector and its transpose?,"I'm having trouble with the statement:
$$||\textbf{v}||^2=\textbf{v}\cdot\textbf{v}=\textbf{v}^T\textbf{v}$$ taking $\textbf{v}$ as a column vector in an orthogonal matrix. How can you do the dot product of a vector and its transpose? Surely that would be like dotting a $n\times1$ matrix with a $1\times n$ matrix? I thought the dot product was only defined for $n\times 1$ vectors?","['matrices', 'orthonormal']"
763128,Exact value for $\cos 36°$,"Good morning! I'm having trouble with this problem... It's just taking me forever and I'm worn out and I'm lost on how to use a double angle identity for $72=2⋅36$ The problem reads as follows An exact value for $\cos36°$ can be found using the following procedure. Begin by considering $\sin108°$. Note that $108=72+36$ and use the sine sum identity. Also note that $72=2⋅36$ and use double angle identities. If there are any common factors in each term, factor them out and cancel them if they are not equal to zero. You should eventually obtain a quadratic equation containing $\cos36°$. Use the quadratic formula to obtain the exact value for $\cos36°$. (Note that the quadratic formula should give two solutions. One can be disregarded - why? Thank you in advance to anyone who can help.",['trigonometry']
763153,Sequence spaces,"Suppose the sequence spaces $$d \colon=\left\lbrace \left\lbrace x_n\right\rbrace_{n \in \mathbb{N}} \in \mathbb{K}^{\mathbb{N}} \colon x_n=0 \ \text{for almost all} \ n \right\rbrace$$ and $$\ell^p \colon= \left\lbrace x=\left\lbrace x(n)\right\rbrace_{n \in \mathbb{N}} \in \mathbb{K}^{\mathbb{N}}\colon \sum_{n=1}^{\infty} |x(n)|^p  < \infty \right\rbrace,$$ with
$$\|x\|_p \colon = \left( \sum_{n=1}^{\infty} |x(n)|^p \right)^{\frac{1}{p}} \text{for} \ x=\left\lbrace x(n)\right\rbrace_{n \in \mathbb{N}} \in \ell^p.$$ Then it holds that $\overline{d}=\ell^p$. I have constructed and example which confuses me: Let $x_n \colon = \{1,2,3,\ldots,n,0,0, \ldots \} \in d$.
Then it follows that 
$$ \lim_{n \to \infty} x_n =\{n\}_{n \in \mathbb{N}}$$ and so $\{n\}_{n \in \mathbb{N}} \in \overline{d}$ but $\{n\}_{n \in \mathbb{N}} \notin \ell^p$. Where is my mistake?","['sequences-and-series', 'functional-analysis']"
763190,Is $\text{rational}^{\text{irrational}}$ rational or irrational?,Is the number $\text{rational}^{\text{irrational}}$ rational or irrational? For example $2^{\sqrt{2}}$: is it rational or irrational? I tried using a logarithm but it didn't work. It seems by superficial studying that it will be irrational. But what is the proof?,['number-theory']
763199,On the canonical isomorphism between $V$ and $V^{**}$,"I am trying to understand more about the Bidualspace (or double dual space). The whole idea is that $V$ and $V^{**}$ are canonically isomorphic to one another, which means that they are isomorphic without the choice of a basis , which means there exists an isomorphism between them which does not depend on choosing some basis (on either of the spaces) . (suggestion by @DonAntonio) Let $V$ be a finite dimensional Vectorspace with Basis $\beta = \lbrace v_1, \dots , v_n \rbrace $ (the infinite dimensional case is discussed at Canonical Isomorphism Between $\mathbf{V}$ and $(\mathbf{V}^*)^*$ ). I do understand that although we make a choice of Basis here, it will later on somehow be obsolete (which I don't see why) Define : \begin{align} \begin{matrix} V & \overset{\Phi}{\longrightarrow}& V^* & \overset{\Phi^*}{\longrightarrow}&V^{**} \\  \sum_{i=1}^n \lambda_i v_i & \longmapsto & \sum_{i=1}^n \lambda_i v_i^* & \longmapsto & \sum_{i=1}^n \lambda_i v_i^{**} \end{matrix} \end{align} Discussion : I know and have already shown that $V$ and $V^*$ are isomorphic (not canonically isomorphic!) to one another, meaning that $\lbrace v_1^*, \dots , v_n^* \rbrace$ defines a Basis for $V^*$. Although I did not show it I am at peace with the statement that the mapping $\Phi^*$ introduces another isomorphism between $V^*$ and $V^{**}$. It is the canonical isomorphism between $V$ and $V^{**}$ that bothers me. My tutors reasoning : In the following I will use $\checkmark$ to highlight whether or not I understand something. $v_i^{**} \in V^{**}=\hom(V^{*},k)  \checkmark$, sure nothing to add here $v_i^{**} (\sum_{j=1}^n \lambda_j v_j^{*})=\lambda_i \checkmark$, should be completely analogous to $v_i^*(v_j)=\lambda_i$ $\Phi^* \circ \Phi (v) =: \iota_v$ $$ \iota: \begin{cases} V & \longrightarrow V^{**} \\ v & \longmapsto \iota_v \end{cases}$$
where $\iota_v( \varphi)= \varphi(v)$ and $\varphi \in V^*$ is a linear functional. My tutor said that $\iota$ is 'suddenly' a canonical isomorphism, independent of the choice of the Basis $\beta$ because $\Phi$ and $\Phi^*$ are isomorphisms. This is the step where I understand nothing about. What happened next (two more equations) : I told my tutor that I don't see why $\iota$ is independent of a basis choice, because at $\Phi^* \circ \Phi= \iota$ we still make a choice for a basis at $\Phi$ namely $\beta$. My tutor said that this seems to be the case at first sight and made two more calculations which I in fact ""understand"": $$ \Phi^* \circ \Phi \left( \sum_{i=1}^n \lambda_i v_i \right) ( \varphi) = \Phi^* \left( \sum_{i=1}^n \lambda_i v_i^* \right) ( \varphi) = \left( \sum_{i=1}^n \lambda_i v_i^{**} \right)(\varphi) \\ = \sum_{i=1}^n \sum_{j=1}^n \lambda_i \mu_i \underbrace{v_i^{**}(v_j^*)}_{= \delta_{ij}} = \sum_{i=1}^n \lambda_i \mu_i $$
I understand this calculation, it's mainly an application of the above introduced definitions and the Kronecker-Delta. Apparently I am supposed to have an ""aha"" moment here, which unfortunately didn't occur yet.  The next calculation he did was $$ \varphi (v) = \left(\sum_{j=1}^n \mu_j v_j^{*} \right) \left( \sum_{i=1}^n \lambda_i v_i \right)= \sum_{j=1}^n \sum_{i=1}^n \mu_j \lambda_i \underbrace{v_j^*( v_i)}_{\delta_{ij}} = \sum_{i=1}^n \lambda_i \mu_i $$
which evidently gives the same result as above. I would appreciate some wording on how those two equations (which calculations I understand) help me to see why there appears to be a canonical isomorphism between $V$ and $V^{**}$","['vector-spaces', 'linear-algebra', 'self-learning', 'definition']"
763224,Convergence of a series (quite frustrating),"The sum is $$\sum_{k=1}^{\infty}\frac{1}{k}\left( \frac{\sin{k} + 2}{3}  \right) ^k$$ Here's what I've tried so far: Root test (in its stronger limsup form), gives nothing, so I didn't bother with the ratio test. This also rules out any hope of forming bounds and comparing to another (geometric) series. Actual numerical investigation, which was totally futile. Some other tests that I happen to know, which were inconclusive. How might this be done?","['sequences-and-series', 'calculus']"
763228,Cardinality of the set of at most countable subsets of the real line?,"I'm exploring an unrelated question about power series with complex coefficients. While exploring this question, I wondered: What is the cardinality of the set of all such power series? Or with different language: What is the cardinality of at most countable subsets of $\mathbb{C}$ (or $\mathbb{R}$, if you prefer)? I asked my advisor and he surprisingly wasn't sure, though he suspects that the set of subsets in question has a larger cardinality than $\mathbb{R}$. Thanks a lot! Edit: Certainly if we only consider finite subsets, then this set of subsets has cardinality equal to $\mathbb{R}$. Edit2: Realized my wording was wrong. I'm actually looking for the cardinality of the set of sequences with entries in $\mathbb{C}$, not the cardinality of the set of at most countable subsets of $\mathbb{C}$. However, both questions are answered below, and both turn out to be $|\mathbb{R}|$.","['cardinals', 'elementary-set-theory', 'infinity']"
763231,"If $\sin A = \cfrac{3}{5}$ with $A$ in QII, find $\sec2A$.","If $\sin A = \cfrac{3}{5}$ with $A$ in QII, find $\sec2A$. I'm getting $\sec2A=\cfrac{25}{7}$. Is that correct?","['trigonometry', 'solution-verification']"
763243,Showing that $|f^{(n)}| \le n!n^n$ and then making this result sharper,"Ahlfors: Show that the successive derivatives of an analytic function at a
  point can never satisfy $|f^{(n)}(z)| > n!n^n$.  Formulate a sharper
  theorem of the same kind. Attempt for Part One: Let $\Delta$ be a neighborhood around $z$ of radius $r$ small enough so that $f$ is analytic on $\Delta$.  Let $C$ be a circle around $z$ of radius $r$. Cauchy's integral formula then yields that $$
f^{(n)}(z) = {n! \over 2 \pi i}\int_{C} {f(\zeta) \over (\zeta - z)^{n+1}}\ d\zeta
$$ Since $\mathbb{R}$ is complete, we have that $M = \max\{|f(\zeta)| : |\zeta - z| \le r \} \in \mathbb{R}$ exists.  Furthermore, we have that $|\zeta - z| \le r$ for all $\zeta$ within the perimeter of $C$.  Hence we have $$
|f^{(n)}(z)| \le \left|{n! \over 2 \pi i}\right|\int_{C} {|M| \over |r^{n+1}|}\ |d\zeta| \le {n! \over 2 \pi} {M 2 \pi r \over r^{n+1}} = {n!M \over r^{n}}
$$ Hence we have Cauchy's estimate: $$
|f^{(n)}(z)| \le {n! M \over r^n}
$$ We may further assume that $M > 1$ above (it doesn't affect any of the the inequality reasoning). Consider that there is a point where $n$ is large enough s.t. $n^n\ge {M \over r^n}$ (indeed, it is when $n \ge {M \over r}$).  At such a point, we have that: $$
n^n \ge {M \over r^n} \implies n^n r^n \ge M \implies r^n \ge {M \over n^n} \implies {1 \over r^n} \le {n^n \over M}
$$ Then assuming $n^n \ge {M \over r^n}$, we have that $$
\underbrace{|f^{(n)}(z)| \le {n!M \over r^n}}_{\text{Cauchy's estimate}} = {n!M} \cdot \left({1 \over r^n}\right) \le \underbrace{{n!M}\cdot \left({n^n \over M}\right)}_{\text{since }{1 \over r^n} \le {n^n \over M}} = n! n^n
$$ as desired. We have thus far shown that if $n \ge {M \over r}$, then $$
|f^{(n)}(z)| \le n!n^n
$$ Question: In what way could we use this result to make a sharper theorem of the same kind?","['inequality', 'analysis', 'complex-analysis', 'analyticity', 'derivatives']"
763262,"Show that $\mathfrak c +{\aleph_0}=\mathfrak c$ using ""presenters""","I need to prove that $\mathfrak c +{\aleph_0}=\mathfrak c$ using ""presenters"". For example, in order to prove that $\mathfrak c +\mathfrak c=\mathfrak c$ We can show that: $$\mathfrak c =\left| \left( 0,2 \right) \right|=\left| \left( 0,1 \right) \right|+\left| \left[ 1,2 \right) \right|=\mathfrak c +\mathfrak c$$ I thought about picking: $\mathbb{N} + (0,1)$ which is a subset of $\mathbb{R}$. Clarification ""presenter"": A set with the desired cardinal. It's not a well-known term I guess but we use it in our course.","['discrete-mathematics', 'elementary-set-theory']"
763263,Spectral Norm of $2\times 2$ symmetric matrix,"Consider a $2\times 2$ symmetric matrix, in this case, is there some closed formula for its spectral norm ? By spectral norm I mean the induced 2-norm, there is a definition here . Thanks.","['matrices', 'normed-spaces']"
763272,"Which is bigger: $\sqrt{1001} - \sqrt{1000}$, or $\frac{1}{10}$?","Which is bigger: $\sqrt{1001} - \sqrt{1000}$, or $\frac{1}{10}$? I can calculate the answer using a calculator, however I suspect to do so may be missing the point of the question. The problem appears in a book immediately after a section called 'Rules for square roots'with $\sqrt{ab} = \sqrt{a}.\sqrt{b}$ and $\sqrt{\frac{a}{b}} = \frac{\sqrt{a}}{\sqrt{b}}$ as the given rules.",['algebra-precalculus']
763273,The Notation for Derivatives,""" The derivative of a sum is the sum of derivatives "" Above theorem can be mathematically expressed as: $$h'(x)=f'(x)+g'(x)$$ where $f(x)$ and $g(x)$ are two differentiable functions. What is the right way to express the statement of this theorem in Leibniz notation? Is it 
$$\frac{d}{dx}h=\frac{d}{dx}(f+g)=\frac{d}{dx}f+\frac{d}{dx}g$$ OR $$\frac{d}{dx}h(x)=\frac{d}{dx}(f(x)+g(x))=\frac{d}{dx}f(x)+\frac{d}{dx}g(x)?$$ In other words, is it permissible to write the derivative of functions in such a way so as to express the variable(s) on which they depend?","['notation', 'derivatives']"
763326,the mapping class group of the disk is trivial proof,"Proof : Identify $D^2$ with the closed unit disk in $\mathbb{R}^2$. Let $\phi : D^2 \rightarrow D^2$ be a homeomorphism with $\phi_{\partial D^2}$ equal to the identity. We define, $F(x,t) = \begin{cases} (1-t)\phi(\displaystyle\frac{x}{1-t}) & \text{$0 \leq |x| < 1 - t$} \\ x & \text{$1 - t \leq |x| \leq 1$} 
\end{cases}$ for $0 \leq t < 1$ and we define $F(x,1)$ to be the identity map of $D^2$. The result is an isotopy $F$ from $\phi$ to the identity. What exactly is going on here in this proof visually? What is $F(x,t)$ telling us? I am not sure what the proof is doing here.","['general-topology', 'homotopy-theory', 'algebraic-topology']"
763364,Poisson process and uniform random variable,"Question: A single-pump petrol station is running low on petrol. The total
  volume of petrol remaining for sale is $100$ litres. Suppose cars arrive to the station according to a Poisson process with
  rate $\lambda$, and that each car fills independently of all other
  cars and of the arrival process, an amount of petrol that is
  distributed as a uniform random variable over $(0, 50)$ - assume for
  example that all car tanks have a capacity of $50$ litres and drivers
  decide ""at random"" when to refill. We assume that service is instantaneous so that there are no queues at
  the station. (a) On average, how many cars will the petrol station fully service
  (sell the full amount requested) before it runs out of petrol (and
  before any refilling occurs)? (b) How much time will it take on average before the station runs out
  of petrol (and before any refilling occurs)? Attempt: I'm not exactly sure where to start with this question part (a) . Let $U$ be uniformly distributed over $(0,50)$, then each time a car arrives at the petrol station, the total volume of petrol decreases by $U$. So define $U_1$ to be the amount of petrol that the first arrival (an ""arrival"" here being when a car arrives at the petrol station and refills) and $U_2$ be that of the second arrival, and so on. Then each $U_i$ is identically and independently distributed as $U$. So by the $N$-th arrival, the station will have $100-\sum_{i=1}^N U_i$ litres of petrol remaining. We stop once $100-\sum_{i=1}^N U_i=0$ and we basically need to find $E[N]$? That's all I've got so far, if someone can provide a solution for (a) (for now), that would be good. EDIT: PROGRESS I don't think I need to use the assumption that cars arrive according to a Poisson process in this part. So, define $U_k$ as the random variable that denotes the amount of petrol that car $k$ fills, $k = 1, 2, 3, \cdots$. Thus, $U_k, k = 1, 2, 3, \cdots$ are independently and identically distributed as a uniform random variable over $(0,50)$. Let $N$ be the random variable that denotes the number of cars that the petrol station can fully service. Now I don't quite get the question. Say we have the following scenario: Car 1 comes with 10L remaining in its tank, so it will fill up 40L, hence the amount of petrol left in the station is now 100-40 = 60L. Car 2 comes with 10L remaining in its tank, so it will fill up 40L, hence the amount of petrol left in the station is now 60-40 = 20L. Car 3 comes with 20L remaining in its tank, so it will fill up 30L, but the petrol station only has 20L left, so does this mean Car 3 just leaves the petrol station filling 0L? My gut feeling is that this cannot happen because each car can only fill an amount BETWEEN 0 and 50, ie, (0,50) [note that the end points are not included]. Hence in this scenario, the petrol station runs ""out"" of petrol at N=3 because it does not have enough to FULLY service Car 3, even though it still has 20L left in the pump. Thus, the petrol station can only service N=2 cars. Is this interpretation correct? If so, how do I find $E[N]$? EDIT 2: working on further... Define $G_N = \sum_{k=1}^N U_k$, then $E[N] = \sum_{n=1}^{\infty} n P(N=n) = \sum_{n=1}^{\infty} n P(G_n \le 100)$ This equivalence comes from the fact that the event $\{N=n\}$ will only happen if $100 - G_n \ge 0$. However, two questions remain, what is the distribution of $G_n$? (How do I derive the distribution of the sum of $n$ iid uniform random variables and second, how do I compute the infinite sum? Furthermore, I should mention that this question can be done without the need of any computer software package or programming. It has a closed form solution with an exact answer, I am feeling that my current approach definitely won't work by hand.","['stochastic-processes', 'probability']"
763429,Prove that ax+bx+ay+by ≤ 300.,"Let $a,b,x,y$ be positive numbers satisfying: $ax ≤ 100,  bx ≤ 100$, $ay ≤ 100,  by ≤ 50$. Prove that $ax+bx+ay+by ≤ 300$. Can someone help me ??","['inequality', 'combinatorics']"
763433,"If $M$ is a Noetherian $R$-module, then $R/\text{Ann}(M)$ is a Noetherian ring [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $M$ be an $R$-module and $\text{Ann}(M)=\{r \in R: rm =0 , \forall m \in M\}.$ Suppose $M$ is Noetherian. Could anyone advise me on how to prove $R/\text{Ann}(M)$ is also Noetherian? Hints will suffice. Thank you.","['modules', 'ring-theory', 'abstract-algebra', 'noetherian']"
763448,On the equation $\exp(a x+b)=\ln(x)$,"I am confronted with: $$\exp(a x+b)=\ln(x)$$ for $a,b$ reals and $a<0$, $b>0$. I need the (unique) solution for $x$. My first target is (if it exists) an analytic solution in terms of elementary functions (perhaps augmented a bit  e.g. with Lambert's W function ). Otherwise I will have to work out some approximation scheme. Regarding the analytic solution, my research has not revealed anything until now so any pointer for further study (that I might have missed) is more than welcome. On the approximation case, due to the mixing of the exponential and the logarithm, things are not obvious. So any opinion or clue would be very useful.","['logarithms', 'exponential-function', 'real-analysis', 'analysis', 'exponentiation']"
763451,How can a simple closed curve not look locally like the rotated graph of a continuous function?,"A simple closed curve is a continuous closed curve without self-intersections.  The question of whether you can inscribe a square in every simple closed curve is currently an open problem, but this page describes an important partial result: Stromquist's Theorem: If the simple closed curve J is ""nice enough"" then it has an inscribed square.... Here, ""nice enough"" means the following: for each point P on the curve there must be a coordinate system for the plane in which some piece of the curve containing P is the graph y = f(x) of a continuous function. My question isn't about Stromquist's theorem itself, but about the condition that's dubbed  ""nice enough"".  It's mind-boggling that there could be a simple closed curve curve that fails to meet this condition. I can understand continuous curves that fail the vertical line test, because two distant points on the curve have the same x-value, and I can understand situations where the vertical line test fails locally in the part of a curve containing P, because the points in that part of the curve are clustered around a vertical line.  But it's completely counterintuitive to me that you could have a point P on a simple closed curve such that no arc of the curve in the vicinity of P, no matter how small, can pass the vertical line test no matter how you rotate the arc. So is there a simple example of such a curve?  Preferably I'd want an example where the interior of the simple closed curve was a convex region, because that's the case that my intuition most strenuously objects to. Any help would be greatly appreciated. Thank You in Advance. EDIT: Wikipedia tells me that the property I've been calling ""nice enough"" is actually known as ""locally monotone"".","['general-topology', 'geometry', 'plane-curves', 'real-analysis']"
763466,What is the meaning of $\;x\;dx=y\;dy\;$?,I know that $x > y$ and $\;x\;dx=y\;dy.\;$ Can someone explain to me what is the meaning of this and how are x and y related?,['ordinary-differential-equations']
763495,"Prove that for every 2 elements in the set F of all functions from N to N, there's an element in F that's bigger than both","let there be $\ F$ the set of all functions from $\ N \rightarrow N$. K is a relation on F, for every f,g$\in$F , (f,g)$\in$K $\leftrightarrow$ for all $\ n\in N$, $\ f(n)\leq g(n)$ Prove that for every two elements in $\ F$, there exist an element that's bigger than both. in other words, given $\ f,g\in F$, proove that there's $\ h\in F$, that sustains $\ (g,h)\in K,(f,h)\in K$, $\ h$ is different from $\ f,g$. remark: h is not a constant element of F, it depends on f,g. my answer: for every $\ f,g\in F$, there's $\ h\in F$, such that $\ h(n)=f(n)+g(n)$ $\rightarrow f(n)\leq h(n), g(n)\leq h(n)\rightarrow (f,h)\in K,(g,h)\in K$ is it good?","['elementary-set-theory', 'order-theory']"
763502,Limit of $f(x)=\frac{x}{1+\sin^2x}$ as $x\to0$ and proof,"I computed the limit using the limit theorems and the answer is obviously $0$. So now I am attempting to prove it using the $\epsilon,\delta$  definition. $f(x)=\frac{x}{1+\sin^2x}$ $|\frac{x}{1+\sin^2x}|<\epsilon$ if $|x|<\delta$ $|x|<\epsilon|1+\sin^2x|$ $|\sin x|<1$ $\implies$ $|\sin^2x|<1$ $\implies$ $1+|\sin^2x|<2$ $\implies$ $|1+\sin^2x|<1+|\sin^2x|<2$ $\implies$  $|1+\sin^2x|<2$ $\implies$ $\epsilon|1+\sin^2x|<2\epsilon$ Finally, $|x|<\epsilon|1+\sin^2x|<2\epsilon$ $\implies$ $|x|<2\epsilon=\delta$ But when I plug $\epsilon=0.2$ then the $\delta=0.4$. If I put my $x=0.3<0.4$ then the answer is $0.3>0.2=\epsilon$. What am I doing wrong here ? Also sometimes Spivak assumes (for example in $|x^2-a^2|<\epsilon$ if $|x-a|<\delta$) that $|x-a|<1$ and chooses $\min(1,\frac{\epsilon}{2|a|+1})$ I cant understand how is it possible to make the assumption that $|x-a|<1=\delta$ if our objective IS to find $\delta$ to prove that this $\delta$ exists for every $\epsilon$. Isnt this circular reasoning ? Otherwise we can just choose that $\delta=\frac{\epsilon}{10000000}$ (10000000 is an arbitrary number that makes delta very small). Also in the example $|x^2-a^2|<\epsilon$ if $|x-a|<\delta$ assuming by some magical means that $|x-a|<1$ then $|x|-|a|<|x-a|<1$ $\implies$ $|x|<1 + |a|$ $\implies$ $|x+a|<|x|+|a|<2|a|+1$ $\implies$ $\frac{1}{|x+a|}>\frac{1}{2|a|+1}$ $\implies$ $\frac{\epsilon}{|x+a|}>\frac{\epsilon}{2|a|+1}$. And since $|x-a|<\frac{\epsilon}{|x+a|} >\frac{\epsilon}{2|a|+1}$ isn't it WRONG to write $|x-a|< \frac{\epsilon}{2|a|+1}$ since we DONT know if  $|x-a|< \frac{\epsilon}{2|a|+1}$ is true or not ? Apologies for the long question but limits have been utterly confusing me for a long while now.","['epsilon-delta', 'calculus', 'proof-verification', 'real-analysis', 'limits']"
763512,Triple Cover of the Riemann Sphere,"I have the triple branched covering $X$ of $\mathbb{P}^{1}$ defined by $y^{3}=x^{6}-1$. I want to show the following: (i) The canonical embedding $\phi: X \rightarrow \mathbb{P}^{3}$ can be given in affine coordinates by $\phi(x,y)=(x,x^{2}, y)$. (ii) Find irreducible quadric and cubic hypersurfaces in $\mathbb{P}^{3}$ that contain $\phi(X)$. I am rather lost on how to approach this. Any help would be appreciated! Thanks very much.","['riemann-surfaces', 'algebraic-geometry']"
763513,$\frac{G_1\times G_2}{N_1\times N_2}\cong \bigg(\frac{G_1}{N_1}\bigg)\times \bigg(\frac{G_2}{N_2}\bigg)$,"Is my solution to this question correct? If $N_1\triangleleft G_1,N_2\triangleleft G_2$, then $(N_1\times
> N_2)\triangleleft (G_1\times G_2)$ and $\frac{G_1\times G_2}{N_1\times
 N_2}\cong \bigg(\frac{G_1}{N_1}\bigg)\times
 \bigg(\frac{G_2}{N_2}\bigg)$ First part $(g_1,g_2)\in G_1\times G_2$ and $(n_1,n_2)\in N_1\times N_2$, then $(g_1,g_2)(n_1,n_2)(g_1^{-1},g_2^{-1})=(g_1n_1g^{-1}_1,g_2n_2g^{-1}_2)\in N_1\times N_2$, since $N_1$ and $N_2$ are normal subgroups of $G_1$ and $G_2$ respectively. Second part Let $\varphi: G_1\times G_2\to \frac{G_1}{N_1}\times\frac{G_2}{N_2}$ be the canonical epimorphism given by $(a,b)\mapsto(a+N_1,b+N_2)$. Note that $\ker \varphi =N_1\times N_2$, because obviously $N_1\times N_2\subset \ker\varphi$ and let $(a,b)\in \ker\varphi\implies\varphi(a,b)=(a+N_2,b+N_2)=(0+N_1,0+N_2)\implies a\in N_1$ and $b\in N_2\implies (a,b)\in N_1\times N_2$. Thus by first isomorphism theorem we have $\frac{G_1\times G_2}{N_1\times N_2}\cong \frac{G_1}{N_1}\times \frac{G_2}{N_2}$. Thanks in advance","['abstract-algebra', 'solution-verification']"
763532,Probability Theory $\Rightarrow$ Game Theory?,"It is a very simple question. I would like to learn Game Theory but I am not that good at Probability Theory. I would like to know it is necessary to be good at probability theory in order to learn game theory? If yes, how they are related to each others? What is the best strategy for someone to be good in Game Theory? Please give a good reference to start learning both. I appreciate your help.","['probability-theory', 'game-theory']"
763539,Normal Ratio Distribution with CDF Method,"I think I'm missing something glaringly obvious here that's causing problems for me in the entire subject. I have two independent standard normal random variables, X and Y ~N(0,1), and I need to find the density of U=Y/X.  I start with f(x,y)=$\frac1{2\pi}e^{-x^2/2}e^{-y^2/2}$, then set Y=ux, and take a double integral of that.  I'm leaving out my limits of integration, because my problem is that I know that I have to integrate with $\iint$y f(x,y), but I have no idea where that y (which is needed to integrate $e^{-y^2/2}$) comes from.  Is this a Jacobian?  None of my notes or our textbook mentions any use of a Jacobian in the CDF method.  Is this just impossible with the CDF method?","['statistics', 'normal-distribution', 'ratio']"
763553,Doubt on proof of Implicit function theorem,"On The second part of the proof, where it's stated that V is open as it is the inverse image of the open set $V_0$ under the continuous mapping $y \rightarrow (0, y)$. Let $\pi$ be this continuous mapping. Then, $\forall _{U_{open\text{ in }\mathbb{R}^n\times\mathbb{R}^p}} \pi^{-1}(U)$ is open in / relative to the domain of $\pi$, since $\forall_\epsilon \exists_\delta Dom(\pi)\cap B(v_1;\delta)\subset \pi^{-1}(B(v_0;\epsilon))$ with $\lim_{y\rightarrow v_1} \pi (y) = \pi(v_0)$. In this situation, is $Dom(\pi)=V$ or $Dom(\pi)=V_1$, where $V$ and $V_1$ are as defined in the image? If it's the first, then I do not understand how $V= \pi^{-1} (V_0)$ is open in / relative to $\mathbb{R}^p$, even if $V_0$ is open in $\mathbb{R}^n\times\mathbb{R}^p$...
If it's the second possibility, then I understand that $\pi^{-1} (V_0)$ is open in $V_1$, and since $V_1$ is open in $\mathbb{R}^p$, $\pi^{-1} (V_0)$ is also open in $\mathbb{R}^p$. In this last possibility is that then $\pi^{-1} (V_0)\neq V$... Then how do we prove that $V$ is open in $\mathbb{R}^p$ ?","['multivariable-calculus', 'proof-writing', 'proof-verification']"
763567,Is UMVUE unique? Is the best unbiased estimator unique?,"Here is the question: Is the best unbiased estimator unique? My understanding is that the best unbiased estimator must be the UMVUE, so the original question turns into the uniqueness of UMVUE. So far, as I thought, since Complete Sufficient statistics is not unique, then by Lehmann Scheffe theorem, the UMVUE hence shouldn't be unique. But some descriptions from wikipedia said otherwise. Can anybody help me out?
Thanks!","['statistics', 'statistical-inference', 'parameter-estimation']"
763577,Isomorphism Finite Topological Space,Does there exist a finite topological space with fundamental group isomorphic to $\mathbb{Z_2}$?,"['general-topology', 'algebraic-topology', 'fundamental-groups']"
763583,Interchange limit-integral & Equivalency of sequence convergence and concrete convergence?,"I got stuck in the proof of Cauchy's Integral Formula for higher derivatives in Stein's Complex Analysis, page 48 : Under what Conditions over a function $f$, we can infer that : $\displaystyle\lim_{h\rightarrow 0}\int_Cf(z,h)dz=\int_C\lim_{h\rightarrow 0}f(z,h)dz$ A Try : $\displaystyle\left|\int_Cf(z,h)dz-\int_C\lim_{h\rightarrow 0}f(z,h)dz\right|\leq
P_C.\sup_{z\in C}\left|f(z,h)-\lim_{t\rightarrow 0}f(z,t)\right|$. Now, I think there's a way to control right hand side, when $h$ would be small.","['cauchy-integral-formula', 'convergence-divergence', 'complex-analysis', 'uniform-convergence']"
763586,Can Moore–Penrose pseudoinverse solve for underdetermined linear system?,"Thanks for reading my thread. I am thinking, many of us know that Moore–Penrose pseudoinverse can solve for overdetermined system 
$Ax=b$, where $x=(A^TA)^{-1}A^Tb$; for exmplae the linear regression application , or curve fitting applications. However, I am wondering for underdetermined system, can we use Moore–Penrose pseudoinverse solver? If yes, why we need many iterative reconstruction algorithm? Since we can know the derivative of the objective anyway, then why don't we just set the derivative to 0, then solve it using some skills like Moore–Penrose pseudoinverse? Some explanation in theory is highly appreciated. Does not have to be rigorous prove, but something that makes sense. Thanks a lot!","['optimization', 'linear-algebra', 'derivatives']"
763598,Every planar graph has a vertex of degree at most 5.,"I am trying to prove the following statement, any help!? Prove that every planar graph has a vertex of degree at most 5.","['graph-theory', 'discrete-mathematics', 'planar-graphs']"
763635,Hyperbolic Systems ODE,Let $M_n$ the set of matrices of order $n \times n$ identified with $\mathbb{R^{n^2}}$ e $S=\{A \in M_n ; x'=Ax$ is hyperbolic$\}$. Show that $S$ is open and dense $M_n$.,"['ordinary-differential-equations', 'real-analysis', 'analysis']"
763652,Is factoring polynomials easier than factoring integers? [duplicate],"This question already has answers here : Is factoring polynomials as hard as factoring integers? (3 answers) Closed 10 years ago . I was reading the book Algebra: Chapter 0 , by Paolo Aluffi, and came across the following assertion, in page 290, Exercise 5.9: It is in fact much harder to factor integers than integers polynomials. What I want to know is: What exactly is the meaning of easier . Why is that so? Because it seems quite unintuitive for me that finding a factorization of a high degree polynomial (with a lot of big integer coefficients) should be easier than factoring the degree of polynomial itself.","['factoring', 'abstract-algebra', 'polynomials']"
763655,Integration over time by having derivation,Assume we want to find the following integration: \begin{equation}\int_{t=0}^{\infty} p(t)dt\end{equation} where $p(0)=p$ and also $$\frac{dp(t)}{dt}=-p(t)(1-p(t))\mu$$. Is there any easy way to exploit the second equation and calculate the first integration? Any comment is highly appreciated.,"['calculus', 'integration', 'derivatives']"
763663,Homeomorphism Compact Subsets,"Are there compact subsets $A,B \subset \mathbb{R^2}$ with $A$ not homeomorphic to $B$ but $A \times [0,1]$ homeomorphic to $B \times [0,1]$?","['general-topology', 'compactness', 'algebraic-topology']"
763669,Prerequisites for understanding G.H. Hardy's 'Divergent Series',"I picked up a copy of G.H. Hardy's 'Divergent Series' a few days ago.  So far I love it, as I love the ideas associated with sequences and series, but I am finding it a bit difficult to understand.  I assumed I knew everything I would need to understand it(Calculus I/II, etc.), but perhaps not.  What would the possible prerequisites for understanding this book be? Also, does anyone have any tactics for getting the best comprehension/understanding of the concepts in this book? Thanks!","['self-learning', 'sequences-and-series', 'soft-question', 'analysis']"
763692,Normal sequences and Montel's Theorem,"I am currently stuck on an exam question involving normal sequences and Montel's theorem: Give two examples of non-constant normal sequences one in the $(a)$ unit disk $\mathbb{D}$ and one in $(b)$ $\mathbb{C}$. Let $(a_n)$ be a sequence of complex numbers satisfying $|a_n|\lt 1$ and an $a_n\to 0$ and
consider the sequence of holomorphic functions $(f_n)$ in $\mathbb{D}$ deﬁned by: $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\large f_n(z)=\frac{z-a_n}{1-\overline{a_n}z}$ State and justify if $(f_n)$ is normal and whether it satisﬁes the condition of Montel’s
theorem? Explain if $(f_n)$ converges uniformly in $\mathbb{D}$. Firstly I will state Montel's theorem and then I will write what I have tried so far. Montel's theorem : A family $\mathbb{F}\subset \mathbb{H}(U)$ is normal if and only if it is locally bounded. (Where $U\subset\mathbb{C}$, open, and $\mathbb{H}(U)$ is the space of holomorphic functions on $U$. My examples for 1. are: $(a)$ $g_n:\mathbb{D}\to\mathbb{C}, g_n(z)=\large e^{\frac{iz}{n}}$ $(b)$ $h_n:\mathbb{C}\to\mathbb{C}, h_n(z)=\large \frac{z}{n^2}$ Now for $2$. I have chosen to show that $f_n$ has a subsequence that converges uniformly on compact subsets of $\mathbb{D}$, so let $K\subset \mathbb{D}$ be compact, thus if $z\in K\Rightarrow |z|\le 1$. I know that since $a_n\to 0$, $f_n(z)\to z$ pointwise. Now: $\large|f_n(z)-z|=|\frac{z-a_n}{1-\overline{a_n}z}-z|=|\frac{z-a_n-z+\overline{a_n}z^2}{1-\overline{a_n}z}|$ $\large=|\frac{\overline{a_n}z^2-a_n}{1-\overline{a_n}z}|\le \frac{|\overline{a_n}z^2-a_n|}{1-|a_n|}\le \frac{|a_n|(|z|^2+1)}{1-|a_n|}\le \frac{2|a_n|}{1-|a_n|}$ Now we can construct a subsequence: since $a_n\to 0$ it follows that $\exists N\in \mathbb{N}:\forall j\ge N\,:|a_j|\lt\frac{1}{N}$ So we consider the subsequence $\{f_j\,|j\ge N\}$ Here $|f_j(z)-z|\le\frac{2|a_j|}{1-|a_j|}\lt \frac{\frac{2}{N}}{1-\frac{1}{N}}=\frac{2}{N-1}\to 0$ as $N\to\infty$. So the subsequence converges uniformly in $\mathbb{D}$, thus $(f_n)$ is normal, and thus by Montel's theorem it is locally bounded, so it satisfies the condition of montels theorem. Now explain if $(f_n)$ is uniformly convergent on $\mathbb{D}$, this is the part that I am stuck on, and would really appreciate help with. I would also like clarification if what I have done for the previous parts is at all correct? Thanks! There is a third part to the question: Let $(f_n)$ be a sequence of holomorphic functions from $U$ to the upper half-plane.
Prove that $(f_n)$ has a subsequence converging uniformly on all compact subsets of $U$
to either a holomorphic function $f$ or to $\infty$ My approach is to consider the sequence: $g_n(z)=\large\frac{\frac{f_n(z)}{|f_n(z)|}-a_n}{1-\overline{a_n}\frac{f_n(z)}{|f_n(z)|}}$, here $g_n$ is of the form of part 2. and takes values in the unit disk.","['normal-families', 'inequality', 'complex-analysis']"
763699,Extension and trace operators for Sobolev spaces,"Given that $\Omega \subset \mathbb{R}^{n}$ is an open, convex, Lipschitz bounded set. Let $O \subset \Omega$ be open bounded set then consider. $$u_{m} \rightharpoonup^{*} u \text{ in } W^{1,\infty}_{o}(O)$$ Assume that we can find $v_{m}$ such that $$v_{m} \rightharpoonup^{*} u \text{ in } W^{1,\infty}(O)$$$$ v_{m} = u \text{ on } \partial O$$ Assume that we apply the linear continuous operator $$P: W^{1,\infty}(O) \rightarrow W^{1,\infty}(\Omega)$$ We then extend $u$ from $O$ to $\Omega$ in such a way that the extension $\bar{u} \in W^{1,\infty}(\Omega)$ and similarly since $v_{m} = u$ on $\partial O$ we define ${\bar{v}}_{m} = v_{m}$ in $O$ and ${\bar{v}}_{m} = \bar{u}$ in $\Omega - O$. We then have $${\bar{v}}_{m} \rightharpoonup^{*} \bar{u} \text{ in } W^{1,\infty}_{o}(\Omega)$$ In Lawrence's book ""Partial Differential Equations"" the trace operator isn't defined for $p = \infty$. If the trace operator isn't defined how would you describe how '$v_{m} = u$ on $\partial O$' is defined? Can we immediately state that $v_{m} \in W^{1,\infty}_{o}(O)$ since $v_{m} = u$ on $\partial O$ and $u \in W^{1,\infty}_{o}(O)$? Do we get ${\bar{v}}_{m} \rightharpoonup^{*} \bar{u}$ in $W^{1,\infty}_{o}(\Omega)$ since we have that from the extension operator it follows that $P_{2}: W^{1,\infty}_{o}(O) \rightarrow W^{1,\infty}_{o}(\Omega)$ is also a continuous linear extension operator? If this is true, how would you go about showing this? Thanks for any assistance","['operator-theory', 'trace', 'sobolev-spaces', 'functional-analysis']"
763756,Finding the flux integral?,"Evaluate the flux integral $FdS$ 
where $F=\langle5y,2z,3x\rangle$  and $S$ is the part of the plane $6x+2y+z=12$ in the first octant oriented upward. This is how I solved it but the answer is incorrect so I just was hoping someone could look at my work and tell me where I'm going wrong. $\langle5,2,3\rangle \cdot \langle6,2,1\rangle = 37$ $6x+2y=12$ I solved for $y$. So $y=6-3x$ So I took the integral of $37dydx$ where $y$ goes from $0$ to $6-3x$ and $x$ goes from $0$ to $2$. My final answer was $222$.","['multivariable-calculus', 'integration']"
763772,How many different messages can be transmitted in n microseconds using three different signals...,"How many different messages can be transmitted in n microseconds using three different signals if one signal requires 1 microsecond for transmittal, the other two signals require 2 microseconds each for transmittal, and a signal in a message is followed immediately by the next signal? I initially got it wrong because I put as the initial condition: $a_0=0, \space a_1=1$ I found this solution online: Why is the initial condition $a_2=3$ , and not $a_2=2$ ?  It says the other two signals require $2$ microseconds, so I believe $a_2=2$ because in $2$ microseconds we can only send $2$ signals.","['discrete-mathematics', 'sequences-and-series', 'combinatorics']"
763785,Question about separation of variables,"This is for the heat equation, where $$\frac{\partial U}{\partial t}-k \frac{\partial^2 U}{\partial x^2}=1$$ with the conditions $$U(0,t)=0, \; U(x,0)=0 \text{ and } \frac{\partial U}{\partial t} (3,t)=0.$$ I am trying to solve for $U(x,t)$ but am currently stuck with factoring dealing with the ""$+1$"" in the separation of variables. I started with $U(x,t)=F(x) G(t)$ then put it into the heat equation and set it equal to a constant -$\lambda^2$.  To deal with the $+1$, I moved it to the other side with the lambda but now I am can't seem to get the sine or exponential expression I need.","['heat-equation', 'ordinary-differential-equations', 'partial-differential-equations']"
763811,"Determining if the span of a set is dense in $L^2(0,1)$","I am trying to determine whether or not the following statement is true: If $f \in L^2(0,1)$ and $\int_0^1 x^nf(x) = 0$ for all positive integers $n$.  Then $f(x) = 0$ I have already verified this when $L^2(0,1)$ is replaced with $C[0,1]$ and I believe that it continues to hold in this case. My thought as far as $L^2(0,1)$ goes is to treat it as a Hilbert space. (Maybe this is the wrong approach?)  We can rephrase in terms of inner products: If $f \in L^2(0,1)$ and $<f,x^n> = 0$ for all positive integers $n$, then $f(x)=0$ Let $S = \{x^n\}_{n=1}^{\infty}$.  Then we can rephrase the statement: If $f \in L^2(0,1)$ and $f \in S^\perp$, then $f=0$ Equivalently $S^\perp = \{0\}$ Equivalently span($S$) is dense in $L^2(0,1)$ Now it seems very likely that this is in fact true since the span of $S$ is almost the set of all polynomials. The only polynomials not included in the span of $S$ would be the nonzero constant polynomials.  So it would seem that we have the following sequence of dense sets (I have not verified all of these so let me know if I am wrong).  Span of $S$ is dense in the polynomials on $(0,1)$ which are dense in $C(0,1)$ by Weierstrass's Theorem which is dense in $L^2(0,1)$.  And thus if all of these inclusions are true then the span of $S$ is dense in $L^2(0,1)$. So I would appreciate help in proving this sequence of dense subsets or if you can provide a counterexample that will be helpful also.  Or a suggestion on another more direct way to approach the question would be nice. Thanks in advance!","['hilbert-spaces', 'functional-analysis', 'real-analysis']"
763826,Prove that there can be at most countably many disjoint letter T's in the plane,"A letter T in the plane is defined as a non-zero length segment with an orthogonal non-zero length segment that has an end-point in the strict interior of the first segment. Prove that there can be at most countably many disjoint letter T's in the plane. I've tried clumsily to prove that I can find balls around each of the endpoints of a 2 segments defining a T, such that if any other letter T has segment endpoints contained in the balls then the two T's must intersect. This would be enough because for each ball we can choose a pure rational ball that has rational center and rational radius that is contained inside the ball. But I've had a hard time making this proof rigorous. Any help?",['real-analysis']
763829,Find the axis of rotation from the rotation matrix.,"This is a problem from the book ""Mathematical Methods in the Physical Sciences"" Third Edition by author Mary L. Boas. on page 129, Example 5, just in case any of you are familiar with it. So I actually know what the correct answers are. Its how to get the answers is what I so desperately need to know. $$G=\
\begin{pmatrix}
0 & 0 & 1\\ 
0 & -1 & 0\\ 
1 & 0 & 0
\end{pmatrix}$$ $$K=\
\begin{pmatrix}
0 & 0 & 1\\ 
-1 & 0 & 0\\ 
0 & -1 & 0
\end{pmatrix}$$ Find the axis of rotation for the rotation matrices $G$ and $K$. I know that many of you can do this by ""inspection"". But I don't understand what that is or how it works. The book tells me I can solve the equations $Gr=r$ & $Kr=r$ to get the axis of rotations since $r$ is some vector unchanged by the transformation. I haven't reached the Eigenvector section of the book yet so if someone would kindly show me all the working for solving these equations I would be most grateful. As according to Mary Boas I don't need to know about Eigenvectors to solve this problem. Many thanks to any response, regards,
BLAZE","['vectors', 'rotations', 'matrices', 'linear-algebra', 'block-matrices']"
763835,A coherent story about (Carathéodory's version of) the construction of Lebesgue measure,"I have just learned how to construct the Lebesgue measure. My text uses the Carathéodory's extension theorem which nowadays seems to be the most popular way to construct it (as I read here on MSE). After going through all the definitions (Dynkin system, semi-ring, etc.) and proofs I have problems remembering the route because it seemed to come out of the blue. Just like the $\varepsilon/\delta$-proofs where things are written down in the opposite order compared to the scratch-work. So I would like to read a coherent story about construction of Lebesgue measure (specifically, about this Carathéodory's-extension-theorem-way of constructing it). Without technicalities of course. A story written in the right order. To my humble knowledge, the story could begin something like this: We want to have a function which assigns some $n$-dimensional volume to each subset of $\mathbb R^n$. We have two natural wishes: the volume of the unit box should be $1$ and the function itself should have some natural properties (the definition of pre-measure here, I guess, since we don't have $\sigma$-algebra yet). Now we notice that $\mathcal P(\mathbb R^n)$ is too big for us (Vitali here), and therefore...","['measure-theory', 'lebesgue-measure']"
763857,Asymptotics of an oscillatory integral with a linear oscillator,"I am interested in asymptotic results for
$$
S(p) = \int_0^1 \frac{y \sqrt{1-y^2}}{(\varepsilon^2-1)y^2+1} \sin(py) dy,
$$
i.e. a result that is valid as $p\rightarrow\infty$. The parameter $\varepsilon$ can be a complex number with $|\varepsilon|>1$ in the third quadrant of the complex plane. If you want a concrete number for plotting, take $\varepsilon=3$. I expect something like
$$
S(p) \approx \frac{1}{p^n}\sin(p+\alpha),
$$ for some $n$ and $\alpha$, both possibly functions of $\varepsilon$, but I don't know how to approach this. I know that this could be the leading order term of some kind of asymptotic series but don't know the details. Other similar integrals I've seen rely on the method of stationary phase, but those have some non-linear function of $y$ in the oscillatory part, and the minima of that function contribute to the integral. Can anyone enlighten me or point me to some references in the case of a simple sinusoidal oscillator?","['asymptotics', 'integration']"
763881,Properties of a Mehler's type integral,"When computing the resolvent of the Laplace beltrami opetator on $S^n$ for even dimension, $n=2k$, I came across the following integral
$$
F(\theta)=\int_{-\theta}^{\theta}{\frac{e^{(i\lambda-\mu)\phi}}{(2\cos \phi-2\cos \theta)^{1/2}} d\phi}, ~~~~~ \theta\in(0,\pi)
$$
and I need to estimate $(\frac{1}{\sin \theta}\frac{\partial}{\partial\theta})^kF(\theta)$. I know that there is a similar formula called Mehler's integral
$$
P_n(\cos\theta)=\int_{-\theta}^{\theta}{\frac{\cos (n+\frac{1}{2})\phi}{(2\cos \phi-2\cos \theta)^{1/2}} d\phi}
$$
I want to know if there is a similar expression for $F(\theta)$, and do we have a  expansion of $F(\theta)$ like $\sum a_k(\theta,\lambda,\mu)e^{(i\lambda-\mu)\theta}$? The reason I ask the second question is that the resolvent in the odd dimension can be written as such forms, so I wonder if it's also the case in even dimention.","['special-functions', 'integration', 'analysis']"
763898,Residue of $\frac{1}{(1-z)^3}$ at $z=1$,"I know there is a singularity of $z=1$ but I am a bit confused on how to find the residue at that point since if we have that $f(z)=\frac{g(z)}{h(z)}$ with $g(z)=1$ and $h(z)=(1-z)^3$ then $g(z)$ has a zero of order 0 (no zero) and $h(z)$ has a zero of order 3 since its first and second derivatives vanish at $z=1$ but the third derivative does not vanish at $z=1$. That is all I have, any help would be appreciated!","['residue-calculus', 'calculus', 'complex-analysis']"
763956,Are roots of unity in hypercomplex algebras well defined?,"While playing around with cyclotomic fields, I started to wonder about taking the roots of unity in higher dimensional analogues of the complex plane. Are the roots of unity well defined in the quaternions, octonions, and other hypercomplex algebras? Are there higher dimensional cyclotomic fields, and if so do they have any interesting properties like unique factorization or interesting morphisms?","['quaternions', 'octonions', 'algebraic-number-theory', 'number-theory']"
763964,The automorphism group of the real line with standard topology,"How much is known about the automorphism group of the real line with the standard topology? I have been unable to find a reference for this question. Any information about $\mathrm{Aut}(\mathbb R)$ or its subgroups would be appreciated. The only subgroups I'm aware of are the isometry group $\mathrm{Iso}(\mathbb R)$ and the subgroups of $\mathrm{Iso}(\mathbb R)$. Edits 4/25/14: Just so it's clear, by ""the automorphism group $\mathrm{Aut}(\mathbb R)$"" I mean the set of all homeomorphisms $f : \mathbb R \to \mathbb R$ under function composition. So my main question is: What are some interesting subgroups of $\mathrm{Aut}(\mathbb R)$ which are not contained in $\mathrm{Iso}(\mathbb R)$?","['general-topology', 'reference-request', 'abstract-algebra']"
763970,How to find $\int_0^\infty \prod_{k=1}^n \frac{\sin \frac{x}{2k-1}}{\frac{x}{2k-1}}\mathrm dx$,"I am trying to calculate the integral
$$
I_n=\int \limits_0^\infty \prod_{k=1}^n \frac{\sin \frac{x}{2k-1}}{\frac{x}{2k-1}}\mathrm dx.
$$
(I have literature on this, if people want).
Note, we can write the amazing sequence $\{I_1,I_2,I_3,I_4,I_5,I_6,I_7\}$ as 
$$
\bigg\{\frac{\pi}{2},\frac{\pi}{2},\frac{\pi}{2},\frac{\pi}{2},\frac{\pi}{2},\frac{\pi}{2},\frac{\pi}{2}\bigg\}.
$$
BUT $I_8\neq \pi/2$, how can we derive this same result for $n=1,2,\ldots,7$?  And why does it deviate at $I_8$?  Thanks, in integral form this sequence is represented by
$$
\frac{\pi}{2}=I_1=\int\limits_0^\infty \frac{\sin x}{x}\mathrm dx=I_2=\int \limits_0^\infty \frac{\sin x}{x}\frac{\sin \frac{x}{3}}{\frac{x}{3}}\mathrm dx=I_3=\int\limits_0^\infty \frac{\sin x}{x}\frac{\sin \frac{x}{3}}{\frac{x}{3}}\frac{\sin \frac{x}{5}}{\frac{x}{5}}\mathrm dx=\cdots
$$
HOWEVER, this fails for $I_8$.  The strange result for $I_8$ is given by 
$$
I_8= \frac{467807924713440738696537864469}{ 935615849440640907310521750000}\pi\approx \frac{\pi}{2}-2.31\cdot 10^{-11}
$$ Note we can calculate $I_1$ by using integration wrt parameter and first considering the damped Sine- integral
\begin{equation}
\eta(\lambda)=\int_{0}^\infty e^{-\lambda x}\frac{\sin x}{x}\mathrm dx.
\end{equation}
We now wish to calculate the Dirichlet integral $I_1$ using calculus and  $\eta(\lambda)$,
\begin{equation}
I_1=\int_{0}^\infty \frac{\sin x}{x}\mathrm dx.
\end{equation}
by differentiating $\eta(\lambda)$.
We start by differentiating this to obtain 
$$
\eta'(\lambda)=\frac{d}{d\lambda} \int_{0}^{\infty} e^{-\lambda x}\frac{\sin x}{x}\mathrm dx =\int_{0}^\infty \frac{\partial}{\partial \lambda} e^{-\lambda x}\frac{\sin x}{x}\mathrm dx=-\int_{0}^\infty e^{-\lambda x}{\sin x}\ \mathrm dx.
$$
Note, that passing the differentiation outside of the integral inside the integral is allowed since the integral is a continuous function of x and $\lambda$ for x$\in(-\infty,\infty)$ and $\lambda \in (0,\infty)$.
We can easily integrate this by writing the sine function as the imaginary part of an exponential, that is
$$
-\int_{0}^\infty e^{-\lambda x}{\sin x}\ \mathrm dx=-\Im\bigg[-\int_{0}^\infty e^{-\lambda x} e^{ix}\mathrm dx\bigg]=-\Im \bigg[-\int_{0}^\infty e^{-x(\lambda-i)}\mathrm dx\bigg]=-\Im{\frac{1}{\lambda-i}}=-\frac{1}{\lambda^2+1},
$$where I integrated the exponential using analysis rules and next used
$$
-\Im\bigg [\frac{1}{\lambda-i}\bigg]=-\Im \bigg[\frac{1}{\lambda-i}\cdot \frac{\lambda+i}{\lambda+i}\bigg]=-\frac{1}{\lambda^2+1}.
$$
Thus we can see that
\begin{equation}
\eta'(\lambda)= -\frac{1}{\lambda^2+1}.
\end{equation}
Now we need to use integrate this relation carefully.  We do this by writing
$$
\int_{\lambda}^{\infty}\frac{\mathrm d\eta}{\mathrm d\xi}\mathrm d\xi=\eta(\infty)-\eta(\lambda)=-\eta(\lambda)
$$
since $\eta(\infty)=0$.  We can now use this and the result above to give
$$
-\eta(\lambda)=\int_{\lambda}^{\infty} \eta'(\xi)\mathrm d\xi=\int_{\lambda}^{\infty} -\frac{1}{\xi ^2 +1}\mathrm d\xi=-(\arctan{\infty}-\arctan{\lambda})=-\frac{\pi}{2}+\arctan{\lambda},
$$
thus we can easily see
$$
\eta(\lambda)= \frac{\pi}{2}-\arctan{\lambda}.
$$
We set $\lambda =0$ and obtain the desired result
\begin{equation}
\eta(\lambda=0)=I_1= \frac{\pi}{2}=\int_{0}^{\infty} \frac{\sin x}{x}\mathrm dx.
\end{equation}
But how to generalize this for $I_n$?  Thanks a lot..","['integration', 'number-theory', 'definite-integrals', 'real-analysis', 'complex-analysis']"
763987,Difference in choosing probability and fraction probability.,"a) probability of choosing 3 of same color? I am aware that the probability is 3*C(5,3)/(15,3). But how would you do it fraction wise?
The first pick would be 15/15 because its any of the 15 objects. Then it would be 10/15 and 5/15. So fraction wise, to find the answer, shouldn't be (10/15)*(10/15) and that will yield 50/225? It doesn't give me the same answer as 3*C(5,3)/(15,3).  What am I doing wrong? Thanks b) also how can you solve 3 of different color fraction wise, not choosing wise.
Thanks",['discrete-mathematics']
763992,Closed form for a sequence defined recursively,"Let $a_k$ be a sequence such that $a_0=0, a_1=0, a_2=1, a_3=1$ and $$a_{k+4}=-\frac{a_{k}+ka_{k+2}}{(k+1)(k+2)}$$ for $k\ge 0$. My question is: Is a closed form formula for $a_n, n\ge 4$ possible?
This problem arises from my attempt to  find the power series solution for $y''+xy'+x^2y=0$.","['ordinary-differential-equations', 'sequences-and-series', 'recurrence-relations']"
763996,Inverse Function Differential Equation [duplicate],"This question already has an answer here : Inverse of a bijection f is equal to its derivative (1 answer) Closed 10 years ago . For the differential equation $$\frac{d}{dx}[y(x)]=y^{(-1)}(x)$$ where $y^{(-1)}(x)$ is the inverse of $y(x)$, find y(x). I gave up on finding the solution analytically pretty quickly and decided that a numerical approach might be more effective. But, I'm not sure that this problem can be solved, even numerically; an Euler or Runge-Kutta type method will not work because to find the value of $y^{(-1)}(a)$, one must first know the value of $y(b)$, where $a$ is not necessarily equal to $b$. Sort of like trying to solve $\frac{d}{dx}[y(x)]=y(x+1)$, I don't know of any numerical approaches that can handle a problem of that type. If anyone has any ideas on how this might be solved (or proven unsolvable), they would be appreciated. Thanks!","['ordinary-differential-equations', 'inverse', 'functional-equations', 'numerical-methods']"
764007,"Show that if the prime $p$ divides $|G|$, then $|X|$ is divisible by $p$.",Question : Let $p$ be a prime number that divides the order of the finite group $G$. Let $X$ = $\bigcup_{P \in Syl_p(G)}P$. Show that $|X|$ is divisible by $p$.,"['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
764013,Why we are studying Dirac measure?,"If we are doing mathematics for sth worthwhile not just for fun then why do we deed to work on Dirac measure $\delta_x$ at a point $x$? For an arbitrary measure space $(X,\scr{A},\delta_x)$, where $\delta_x$ is defined by:
$$
\delta_{x}(E)= \begin{cases}
    1 & \text{if } x \in{E}\\
    0 & \text{otherwise}
  \end{cases}
$$ Then for any measurable function $f:X\rightarrow\mathbb{R}$, $\int_{X}f\,d\delta_x=f(x)$. It is not giving any new results though we are studying this measure. Why?",['measure-theory']
764034,Fermat's Equation,"Can somebody help me with this. I am trying to prove something from Fermat's equation. Fermat's Equation $x^n + y^n = z^n$, where $x,y,z$ and $n$ are positive integers. His last theorem states that this equation has no solution if $n \geq3$.
I want to prove that if the equation has no solution if $n$ is prime or $n = 4$, then it must be true that it has no solution if $n \geq3$.",['number-theory']
764035,"Prove $\gcd(ka,kb) = k*\gcd(a,b)$ [duplicate]","This question already has answers here : How to prove that $z\gcd(a,b)=\gcd(za,zb)$ (2 answers) Closed 9 years ago . For all $k > 0,\ k\in \Bbb Z$ . Prove 
$$\gcd(k*a,\ k*b) = k *\gcd(a,\ b)$$ I think I understand  what this wants but I can't figure out how to set up a formal proof. These are the guidelines we have to follow","['divisibility', 'elementary-number-theory', 'proof-writing', 'discrete-mathematics']"
764065,Summation of a series help: $\sum \frac{n-1}{n!}$,Can someone teach me how to solve the following series. I have no idea how to deal with factorial. $$\sum_2^\infty \frac{n-1}{n!}$$ Thanks,"['factorial', 'sequences-and-series']"
764068,Calderón-Zygmund $\times$ Schwartz $=$ Calderón-Zygmund,"I am in a functional analysis class, and we are being asked to show that if $\eta$ is a Schwartz function and $K$ is a Calderón-Zygmund distribution, then their product is also a Calderón-Zygmund distribution. A straightforward application of the product rule brings me maddeningly close to showing the differential inequalities: \begin{align*}
|\partial^\alpha(\eta k)(x)| &= \left|\sum_{\lambda\leq\alpha} \partial^{\lambda}\eta(x)\partial^{\alpha-\lambda} k(x) \right| \\
 &\leq \sum_{\lambda\leq\alpha} |\partial^{\lambda}\eta(x)||\partial^{\alpha-\lambda} k(x)| \\
 &\leq \sum_{\lambda\leq\alpha} |x^{\lambda}\partial^{\lambda}\eta(x)||x^{-\lambda}||\partial^{\alpha-\lambda} k(x)| \\
 &\leq \sum_{\lambda\leq\alpha} ||\eta||_{|\alpha|}|x^{-\lambda}|c_{\alpha-\lambda}|x|^{-d-|\alpha|+|\lambda|} \\
 &= \left(||\eta||_{|\alpha|}\sum_{\lambda\leq\alpha} c_{\alpha-\lambda}|x^{-\lambda}||x|^{|\lambda|}\right)|x|^{-d-|\alpha|}  
\end{align*} (Triangle inequality / multiplication by $1$ / definition of Schwartz norm & application of differential inequalities for $k$ / rearrangement) If I could somehow produce a bound on $|x^{-\lambda}||x|^{|\lambda|}$ then I would be done; but I don't think this is possible. Am I wrong? Or if not, is this approach salvageable in some other way? Thank you :)","['multivariable-calculus', 'distribution-theory', 'functional-analysis']"
764076,Integration with respect to counting measure.,"I am having trouble computing integration w.r.t. counting measure. Let $(\mathbb{N},\scr{P}(\mathbb{N}),\mu)$ be a measure space where $\mu$ is counting measure. Let $f:\mathbb{N}\rightarrow{\mathbb{R}}$ be a non-negative bounded measurable function. Then, what is $\int_{\mathbb{N}}fd\mu$? What's gonna happen if we remove the boundedness in $f$, i.e. just let $f$ be an arbitrary non-negative measurable function? What happens if we relace $\mathbb{N}$ by a general set $X$?","['measure-theory', 'integration', 'real-analysis']"
764085,An example of ample sheaf with no global section,"In viewing the tags about ample bundle with no global sections I found an example below: If $C$ is a curve of genus $2$, and $p,q,r$ are general points on $C$, then the bundle $L=\mathcal{O}_C(p+q-r)$ is ample, but has no global sections at all. But I don't know how to verify this? How is 'general' used here? (Also I think it is right if we give the divisor consisting of a single point on a irrational curve. )",['algebraic-geometry']
764130,How can I better solve proofs requiring the introduction of algebraic assumptions?,"Today I decided to binge on discrete mathematics after a three year hiatus. I tackled three proofs, and all of them required the introduction of assumptions that seemed to not be found in the givens as well as caffeine. Out of those three proofs, I got two incorrect after contemplating for 30 minutes to an hour. Looking on at them, they make me ask the question ""how on Earth would I have known to do that?"" Below is an example of what I mean: Prove $a - b \; | \; a^n - b^n$. Skip to induction step: $$a^{k + 1} - b^{k + 1} = a^{k + 1} - ab^k + ab^k - b^{k + 1}$$ $$a(a^k - b^k) - b^k(a - b)$$ Which implies that $$(a - b) \; | \; a^{k + 1} - b^{k + 1} \implies \text{True}.$$ Due to the result in form $a \; | \; b + c$ being true iff $a \; | \; b$ and $a \; | \; c$. Basically the added assumption allows me to use both the zeroth case and the base case to prove the statement true, in a pretty elegant way. I was messing around with the power series, which would have resulted in a weaker proof if there was one there, and when this simpler solution was there the whole time. The other proof involved inequalities between a polynomial and $2^n$,  which seem to require added assumptions for most proofs in that class. In order to use the given $9 < k$ for proof of $n^3 < 2^n$, it was necessary to introduce $k^3 + 9k^3$ to demonstrate that $2k^3 < 2 \cdot 2^k \implies 2^{k+1}$. Once again, although I could understand the rationale for this move in hindsight (it kind of blew my mind), I am unsure how I could have come to that insight. Granted I haven't effectively scaffolded my knowledge of either inequalities or divisibility. However, it seems like in both cases I needed to understand what kind of algebraic ""moves"" preserve the truth while introducing new information to the proof, allowing it move forward; almost like logical free lunches. But that seems to require an understanding of algebra that is more deeply developed than what I have right now, and what other textbooks have given me. Is there a way to improve my ability to introduce the right kind of algebraically expressed number, while preserving truth and equality, to move proofs forward? Are there algebra textbooks that deal with algebra in a more sophisticated way to improve this intuition?","['algebra-precalculus', 'soft-question', 'discrete-mathematics']"
764154,General solution for squared trigonometry questions: $\cos^2 x = 1$,$\cos^2 x = 1$ How do you solve trig equations with a power? Unsure what to do with the square? I get this $\frac{1+\cos2x}2 =1$ $\cos2x =1$ $2x=2n\pi\pm0$ $x=n\pi$ but the answer says $\pm n\pi$,"['trigonometry', 'calculus', 'algebra-precalculus']"
764170,"Elements of a Dedekind domain can be chosen to have valuation $1$ with respect to one prime, $0$ everywhere else","I noticed this is true for $\mathbb{Z}$, but I was wondering whether it was true in general.  Let $R$ be a Dedekind domain and $P_1, ... , P_s$ maximal ideals.  The localized ring $R_{P_i}$ is a discrete valuation ring, and if $\nu_{P_i}(\pi) = 1$, then the unique maximal ideal $PR_{P_i}$ is equal to $\pi R_{P_i}$, where $\nu_{P_i}$ is the discrete valuation on $R$  induced by $P_i$. My question is, can we pick $\pi$ to be a unit in EVERY other discrete valuation ring $R_P$ for $P \neq P_1$?  I know that $\pi$ can only be a nonunit in at most finitely many prime ideal localizations.  But ultimately I want to know if we can choose $\pi_1, ... \pi_n \in R$ with $\nu_{P_i}(\pi_j) = \delta_{ij}$. I was thinking this might be related to the approximation theorem (for the absolute values induced by the discrete valuations).  I haven't worked out the details, but I'm thinking it should at least be possible to have $\nu_{P_1}(\pi) = 1$ and $\nu_{P_i}(\pi)$ very close to $0$ for $2 \leq i \leq n$.","['dedekind-domain', 'abstract-algebra', 'number-theory']"
764171,Proof that $e^x$ is the eigenvector of the derivative operator,I remember hearing my professor talk about how $e^x$ shows up in all our differential equations because it is the eigenvector for the derivative operator. Can someone explain and prove this to me? I have taken Linear algebra and a course on ODEs and a little bit of PDEs. EDIT: Specifically I am wondering: know how you take a matrix that represents a linear operator and subtract lambda off the diagonals and then solve for the eigenvalues and eigenvectors? Is there a similar proof that results in e^x?,"['differential', 'linear-algebra', 'eigenvalues-eigenvectors']"
764177,Symmetry groups of discrete functions,"I'm looking for basic information about symmetry groups of discrete functions. It is difficult to search for such information, because searching for ""symmetry group"" gives results that refer almost exclusively to geometric figures or differential equations. To be clear about what I'm asking about: given a function $f:X\to X$ for some finite (or countable) set $X$, an invertible function $g:X \to X$ is a symmetry of $f$ if $g \circ f\circ g^{-1} = f$. The symmetries of $f$ form a group under function composition. I'm interested in any basic results about such symmetry groups. For example: given any arbitrary discrete group $G$, does there exist a discrete function $f$ such that $G$ is its symmetry group, or are the symmetry groups of functions a special subclass of groups? I'm asking because I'm interested in discrete dynamical systems. I've only recently started (self-)learning group theory, but thinking about the symmetries of the state transition function seems a natural thing to do, so I'm looking for resources that can help me think in those terms. I am particularly interested in the case where $f$ is a bijection.","['symmetry', 'discrete-mathematics', 'group-theory']"
764180,How to approach sketching sine and cosine graphs with transformations,"Any tips or suggestions in sketching these graphs quickly, and in ONE go? In exams, I don't want to spend ages re-drawing the original sine/cosine graph, one by one, following each new transformation. Are there any methods that people have found useful when sketching these graphs? currently what i do (very tedious) First determine the period Sketch the original shape finishing at the new period Determine the amplitude and apply this to the basic shape Apply the horizontal translation (add this to the original values on the x-axis) Apply the vertical translation (apply this after the amplitude) Does anyone have shortcut methods, or suggestions to this? I really need to improve my speed and drawing these graphs. Would love to know how others tackle these graphs quickly, or more efficiently.","['algebra-precalculus', 'graphing-functions', 'functions', 'trigonometry', 'linear-algebra']"
764196,Card probability,"There are two 10-card decks, consisting of 5 red cards and 5 blue cards each. Both are shuffled separately. One card is then dealt from each deck and compared. This is repeated for all 10 pairs of cards(one of each pair is taken from each deck). What's the chance that at least one pair consists of two cards of the same color? I see that I'm supposed to use the complement as ""at least"" usually suggests that taking the complement is the easier approach. So I'm finding the prob that there are no pairs of the same color. This is where I'm stumped. I have Pr(A) = pair has no 2 reds, Pr(B) = pair has no 2 blues. For Pr(A) I calculated 20 choose 10 / 20 choose 10. But I know 20 choose 10 is wrong. Prob can't equal 1. I'm wondering if I should calculate the prob of no red for each card in the pair and for each blue card as in P(A1) = not red, P(A2) = not red, P(B1) = not blue, P(B2) = not blue. A push in the right direction would be great.","['statistics', 'discrete-mathematics', 'probability']"
764199,Caccioppoli inequality,"Assume we have established the following version of Caccioppoli inequality
$$\int |\nabla u|^2 \psi^2 dA\leq C \int u^2 |\nabla \psi| ^2 dA$$
for $C^2(\mathbb C)$- smooth functions $u\geq 0$ with $\Delta u\geq 0$, and $\psi\in C_c^\infty (\mathbb C)$ (compactly supported, smooth) test functions. Is there a way to upgrade this inequality, so that it holds for $\psi \in C_c(\mathbb C)$ (continuous, compactly supported), such that $\nabla \psi$ exists almost everywhere, and it is bounded, and supported on a finite measure set? The reason is that I want to use a bump function $\psi$ such that $\psi=1$ on a disk $D(0,a)$, $\psi=0$ outside $D(0,b)$ ($b>a$), but $\nabla \psi$ does not exist on $|z|=a,|z|=b$.","['complex-analysis', 'partial-differential-equations', 'real-analysis']"
764214,Why are the Animals in a Field a Set ? Why is a Group a Set ? What does Qualify as a Set?,"A classroom conversation goes along the lines: Teacher: A is a set of animals in a field. S is a subset of A, the sheep in the field. B is a subset of A, the black animals in the field. The intersection of S and B has two elements, what are they ? Pupil: they are black sheep. I’ve been studying  ZFC set theory and I think I understand that a model of the number system can be created using its axioms, that collections of numbers are sets, and therefore they can be manipulated in accordance with ZFC axioms. But I don’t easily see how to generate a collection of animals staring from the empty set in the way I can generate 0, 1, 2,.... I can see that if the animals in the field are a set then by specification (separation) I can get the sheep and the black animals as subsets and form their intersection, but why are the animals a set ? On a more mathematical note, my algebra textbook defines a group as a “non-empty set of elements ... closed...identity... associative.. inverse”. It is useful to be able to manipulate the elements of a group in accordance with the ZFC axioms, but as a  group can comprise arbitrary objects other than just numbers why is a group a set ? 
(An example of a non-numeric group is “the parity group” It has two elements, the words ”even” and “odd,” with operation *. even * even = even = odd * odd  and even * odd = odd = odd * even). I’ve seen that there are some collections of objects which are not sets (proper classes). Is it the case that any collection of objects which can be “counted” by a finite or infinite ordinal is a set and if so how is this deduced from the ZFC axioms ?",['elementary-set-theory']
764230,Show $\lim\limits_{a \rightarrow + \infty} \int_0^{\infty} \frac{1}{1+y^2}e^{-ay} dy =0 $,"Need to prove $\lim\limits_{a \rightarrow + \infty} \int_0^{\infty} \frac{1}{1+y^2}e^{-ay} dy =0 $ and 
$\lim\limits_{a \rightarrow + \infty} \int_0^{\infty} \frac{y}{1+y^2}e^{-ay} dy =0 $ Can someone solve using dominated convergence theorem? I want to know how LDC is applied.","['improper-integrals', 'calculus', 'integration', 'lebesgue-integral', 'limits']"
764237,Average Line of a Set of Lines,"Suppose we have 10 lines in an x-y plane.  The lines are somewhat clustered together, and going more or less in the same direction. The data I have for these lines is their line equation: $$y = a + bx$$ I'm wondering how one can come up with an ""average line"" for the set. Does it make sense to take the average of all the $a$ values (the y-intercept) and take the average of all the $b$ values (the slope) and use those two together to arrive at an average line equation? Thoughts and comments appreciated.",['linear-algebra']
764263,Proof of the inequality $2\uparrow^n 4 < 3\uparrow^n 3 < 2\uparrow^n 5$,"I tried to prove the inequality $$2\uparrow^n 4 < 3\uparrow^n 3 < 2\uparrow^n 5$$ for all natural numbers $n\ge 1$ For $n = 1$, the claim is true because of $16 < 27 < 32.$ The left inequality can be proven with induction $2 \uparrow^{n+1}4 = 2 \uparrow^n(2\uparrow^{n+1} 3) = 2\uparrow^n (2\uparrow^n4) < 2\uparrow^n(3\uparrow^n 3) < 3\uparrow^n(3\uparrow^n 3) = 3\uparrow^{n+1} 3 $ (Please check this proof) The right inequality is true for $n = 2$ because of $$3\uparrow \uparrow 3 \approx 7,6 * 10^{12}$$
$$2\uparrow \uparrow 5 \approx 10^{19728}$$ For $n = 3$ we have $$3\uparrow \uparrow \uparrow 3 \approx 10 \uparrow \uparrow (7,6*10^{12})$$
$$2\uparrow \uparrow \uparrow 5 \approx 10 \uparrow \uparrow (2 \uparrow \uparrow 65536)$$ So, for $n = 3$ the claim is also true. It seems clear that for bigger $n$, the inequality also holds, but I am looking
for a rigorous proof. Perhaps, the base exchange theorem from r.e.s. can help ?","['big-numbers', 'number-theory']"
764264,"When does conformal equivalence guarantee the existence of a ""conformal homotopy""?","Suppose $f$ is a conformal equivalence between two domains $D_1$ and $D_2$ in $\mathbb{C}$.
Does this imply the existence of a map $F_t(z): D_1 \times [0, a] \rightarrow \mathbb{C}$ such that each $F_t$ is conformal in $z$ and smooth in $t$, $F_0 = \text{id}$, and $F_{a} = f$? If not, does this hold if we make stronger assumptions, such as requiring that the boundary be a Jordan domain, etc.?",['complex-analysis']
764274,Initial Value Problem for $y''+xy'+x^2y=0$,"Does anyone have a solution for the initial value problem: $$y''+xy'+x^2y=0, y(0)=1, y'(0)=1 ?$$
I try power series solution but I have trouble finding a pattern for the general term of the series.",['ordinary-differential-equations']
764276,How to prove the transformation formula for Jacobi classic theta function,"How to prove the following transformation formula:
$$
\theta(x)=\frac{1}{\sqrt{x}} \theta\left(\frac{1}{x}\right),
$$
where $\theta$ is the Jacobi theta function $\theta(x)=\sum_{n\in \mathbb{Z}} e^{-\pi n^2 x}$?","['special-functions', 'number-theory']"
764288,GCD of two large integers,"For two random $d$ digit integers $a,b$, what is the probability 
$\gcd(a,b)<B$? Here $B$ is much much smaller than $a,b$.",['number-theory']
764292,A doubt in the proof of Prop. 1.10 of Hartshorne's Algebraic Geometry,"I have a doubt in the proof of Proposition 1.10 of Hartshorne's book Algebraic Geometry, which states that if $Y$ is a quasi-affine variety, then its dimension is the dimension of its closure. In this proof the author picks a maximal chain $Z_0 \subset Z_1 \subset \dots \subset Z_n$ of irreducible closed subsets of $Y$, and states that then also the ""closure"" chain $\overline{Z_0} \subset \overline{Z_1} \subset \dots \subset \overline{Z_n}$ of irreducible closed subsets of $\overline{Y}$ is maximal, referring to the fact that an open non-empty subset of an irreducible set is irreducible and dense.
I tried to prove it by contradiction: if the closure chain were not maximal, then there would exist an index $i\in \{0,\dots,n-1\}$ and another irreducible closed subset $W$ of $\overline{Y}$ (which is then closed in all the affine $n$-space) such that $\overline{Z_i} \subset W \subset \overline{Z_{i+1}}$, or $W$ would satisfy $\overline{Z_n} \subset W$. Then my idea was to look at the intersection of these sets with the quasi-affine variety $Y$. But since $Y$ is quasi-affine, $Y=U\cap X$ with $U$ open in the Zariski topology of the affine $n$-space, and $X$ an affine variety, i.e. an irreducible Zariski-closed set. So I have that $Y\cap W=U\cap (X\cap W)$ which is an open subset of the closed set $W\cap X$. But now how can I use the above fact, since I don't know if the set $W\cap X$ is irreducible? Is the intersection of irreducible sets always irreducible? Thanks in advance! :)",['algebraic-geometry']
764297,Question about $\aleph = 2^{\aleph_0}$ proof.,"I'm reading this proof from my course's book for the identity: $\aleph = 2^{\aleph_0}$ The proof starts with the claim:  $2^{\aleph_0} \le \aleph \le 10^{\aleph_0}$. Then, since $2^{\aleph_0} = 10^{\aleph_0}$ we conclude that $\aleph = 2^{\aleph_0}$. I don't understand why can one claim a-priori the first assumption.","['discrete-mathematics', 'elementary-set-theory']"
