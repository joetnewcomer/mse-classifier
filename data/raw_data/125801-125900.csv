question_id,title,body,tags
1908525,"Prove this limit without using these techniques, and for beginner students: $\lim_{x\to0} \frac{e^x-1-x}{x^2}=\frac12$","How can we prove that
 $$\lim_{x\rightarrow 0}\cfrac{e^x-1-x}{x^2}=\cfrac{1}{2}$$ Without using L'hopital rule, and Taylor expansions? Thanks","['limits-without-lhopital', 'exponential-function', 'calculus', 'limits']"
1908556,Misunderstanding of the proof of the Riemann–Roch theorem,"I'm trying to understand the proof of the Riemann–Roch theorem presented here (p. 11). Before I state the question itself, let me give some background material (i.e., a summary of what is going on in my understanding). Let $X$ be a Riemann surface, $D$ a divisor on $X$. By $L(D)$ we
  mean the set of all meromorphic functions $f$ on $X$ such that
  $(f)+D\ge0$; where $(f)$ is the principal divisor of $f$ and the
  notation $(f)+D\ge0$ means that all the (integer) coefficients in the divisor
  $(f)+D$ are nonnegative. For the divisor $D=\sum_{i=1}^n{m_ia_i}$, we set
  $V=\{(f_1,\dots,f_n)\}$, where
  $f_k=\frac{c_{-m_k}}{z^k}+\dots+\frac{c_{-1}}{z}.$ It is a vector
  space over $\mathbb{C}$ of dimension $\deg(D):=\sum_{i=1}^n m_i$. Define a map $\Phi: L(D)\rightarrow V$ as follows: to a function
  $f\in L(D)$ it assigns the $n-$tuple with $i$th element being the principal part of Laurent's expansion of $f$ at the point $a_i$. I think I don't completely understand the definition of the set $V$ and the map $\Phi$. To get a deeper understanding, I consider the following example. Let $\mathbb{C}$ be the Riemann surface being considered and let $$D=a_1\cdot   m_1+a_2\cdot m_2+a_3\cdot m_3=0\cdot3+1\cdot 3+2\cdot4$$ be a divisor on $\mathbb{C}$ with $a_i\in\mathbb{C}$ and $m_i\in\mathbb{Z}$. Further, let $f:\mathbb{C}\rightarrow \mathbb{C}$ be a meromorphic function defined by $f(z)=\frac{1}{z(z-1)^2(z-2)^3}$. It is easy to verify that $f\in L(D)$. Now, if we denote by $V(D)$ what is denoted merely by $V$ in the article ($V$ is constructed from $D$, so I find it reasonable), then $$V(D)=\bigg\{ \bigg(\frac{c_{-3}}{z^3}+\frac{c_{-2}}{z^2}+\frac{c_{-1}}{z},\frac{d_{-3}}{z^3}+\frac{d_{-2}}{z^2}+\frac{d_{-1}}{z}, \frac{e_{-4}}{z^4}+\frac{e_{-3}}{z^3}+\frac{e_{-2}}{z^2}+\frac{e_{-1}}{z}\bigg)\bigg\} $$ However, $$\Phi(f)=\\{\bigg(-\frac{1}{8z},\frac{1}{2(z-1)^2}-\frac{2}{z-1},\frac{1}{2(z-2)^3}-\frac{5}{4(z-2)^2}+\frac{17}{8(z-2)}\bigg)\\}$$ So the question which arises immediately is why $\Phi(f)\in V(D)$? Of course, it is an $n-$tuple, but it contains powers of $z-2$ for example, whereas the definition of $V$ includes only powers of $z$. Moreover, for an arbitrary $g\in L(D)$, why the $k$th element in the n-tuple $\Phi(g)$ will always have the power of $z$ (or $z-\alpha$?) not exceeding $m_{k}$ by absolute value?",['algebraic-geometry']
1908597,How to interpret the differential equation (z+x)dx + (x+z)dy + (x+y)dz = 0?,"Since $\frac{dy}{dx}$ is not a ratio but a limit, the differential equation 
$\frac{d^2y}{dx^2} -3 \frac{dy}{dx} + 2y = 0$ can be interpreted as a function $y$ whose derivatives first order and second order satisfy the equation and not like differentials $dx, dy$ satisfy the equation. But how to interpret a differential equation of the form $(z+x)dx + (x+z)dy + (x+y)dz = 0$ and also is there any rigorous way of expressing the equation above. Since a derivative must be expressed as $\frac{dy}{dx} = \lim_{h\to 0} \frac{f(x+h)- f(x)}{h}$? Thanks in advance.",['ordinary-differential-equations']
1908600,Is there a Stochastic Time derivative,"The Setup Suppose I have a stochastic process $f(t,Z_t)$ where $Z_t$ solve the $d$-dimensional SDE
$$
dZ_t = \mu(t,Z_t)dt + \sigma(t,Z_t)dW_t
$$
and $f$ is a smooth function. My Question Is there a notion of time-derivative ""$d_t$"" of the process $f(t,Z_t)$ which satisfies: Some sort of chain rule like $$
\partial_t f(t,Z_t) * d_t(Z_t),
$$
where $\partial_t$ is the usual derivative wrt $t$. If $Z_t$ is deterministic (ie: $\sigma(t,Z_t)=0$) and $\mu(t,z)$ is $C^1$ in $t$ then $$d_t=\partial_t,$$ ie: $d_t$ reduces to the usual derivative when $f(t,Z_t)$ is a smooth function of $t$.","['functional-analysis', 'stochastic-integrals', 'stochastic-calculus', 'stochastic-processes']"
1908639,A bogus proof of countable power set [duplicate],"This question already has answers here : What is wrong with this proof that the power set of the natural numbers is countable? (2 answers) Closed 7 years ago . I know that $2^\mathbb{N}$ is not countable but what is wrong with the following ""proof""? Consider the following map $f: \mathbb{N} \to 2^\mathbb{N}$ , which maps a natural number $n$ to a set of integers which correspond to the index of non-zero bits in $n$ 's binary representation: $$f(n)=\{i ~|~ n = \sum_{j=0}^\infty k_j2^j \text{ and } k_i=1\}$$ $f(n)$ is clearly ""onto"" since for any $S\in 2^\mathbb{N}$ , there exists a natural number $n = \sum_{i\in S} 2^i$ s.t. $f(n)=S$ . However, if $f(n)$ is onto, then this is effectively proving that $2^\mathbb{N}$ is countable, which is, of course, false. Where was the mistake?","['cardinals', 'elementary-set-theory', 'proof-verification']"
1908655,Value of tan2°(Without using calculator),"Yesterday my sir asked us a question:""How can you find the value of tan2° without using the calculator? "" I asked, whether he is asking the formula of tan 2A or something, but he said no its tan 2°. I tried my head out in every possible way even tried out the approximation method of differentiation, but didn't got any idea. May be it will be something like tan (60°/30°) or something like that, but I get no clue. The exact value is 0.035, but that's coming from a calculator. How to find ourselves the value? Any idea?
And I'm not familiar with MathJack so would be grateful if someone edit it out for me. Thanks in advance!",['trigonometry']
1908701,Integer partition of n into k parts recurrence,"I was learning integer partition of a number n into k parts(with minimum 1 in each part) and came across this recurrence : part(n,k) = part(n-1,k-1) + part(n-k,k) But, I cannot understand the logic behind this recurrence. Can someone please help me visualize this recurrence?","['combinatorics', 'recurrence-relations', 'integer-partitions']"
1908711,"How to integrate $\int \frac1{(3+4\sin x)^2}\,dx$?","We are to solve  $$\int \frac1{(3+4\sin x)^2}\,dx.$$ I had tried expanding the denominator and substituting $\sin x$ in terms of $\tan(x/2)$ and then putting $\tan(x/2) =t$. But, this made the integration even more complex. I got a large bi-quadratic  equation in the denominator. If I am able to get $\cos x$ in the numerator ,then the question can be proceeded from there. Any ideas or other methods by which I could solve? Thanks in advance.",['integration']
1908719,"""Analytic Continuation"" of the Convolution Operator?","The convolution of two functions $f, g: \mathbb{R} \rightarrow \mathbb{R}$ is defined as: $$(f \ast g)(t) := \displaystyle \int_{\mathbb{R}}f(\tau)g(t - \tau)d\tau,$$ and can be generalised to higher dimensions. A result of significant importance is the well-known convolution theorem, a version of which states that: $$\displaystyle \hat{f} \ast \hat{g} = \widehat{f \cdot g},$$ where $\hat{f}$ denotes the Fourier transform of $f$. Since it can also be shown that $\ast$ is associative, then we also have: $$\hat{f}^{\otimes_{k}} = \underbrace{\hat{f} \ast ... \ast \hat{f}}_{k \text{ terms}} = \widehat{f^k},$$ for any positive integer $k$. Now, as silly as this sounds, I would like to investigate this for $k = 1/2$. That is, given that we know the Fourier coefficients of $f$, can we derive, in terms of convolutions, the Fourier coefficients of $\sqrt{f}$ ? There is such an extension of the convolution operator, known as fractional convolution, for which several papers have been published, the majority of which fall in the category of signal processing. However, the ""fractional convolution theorems"" seem to depend on being able to write $f$ as a product of functions whose Fourier coefficients are known (see, for example, David Mustard's 1995 paper entitled Fractional Convolution). But this is not possible here. Does anyone know of an analytic continuation of $\otimes_{k}$ to rational values of $k$ that would allow this to be possible? Otherwise, are there any other ways to find the Fourier coefficients of $\sqrt{f}$ given that the Fourier coefficients of $f$ are known?","['functional-analysis', 'signal-processing', 'real-analysis', 'fourier-analysis']"
1908731,Does a surjective linear map commute with the interior of a convex body?,"Let $T:\Bbb R^n \to \Bbb R^m $ be a surjective linear map.
Suppose $A\subset\Bbb R^n$ is convex, compact, $0\in \operatorname{int}(A)$, and centrally symmetric. Is it true that $T(\operatorname{int}(A))=\operatorname{int}(T(A))$?. Notes: $\operatorname{int}(S)$ means interior of $S$ in the topology of $\mathbb{R}^n$ or $\mathbb{R}^m$. Convexity is important: e.g., consider the image of sphere $S^2\subset \mathbb{R}^3$ under projection $A$ having nonempty interior is also important: consider the image of a disk $D^2\subset \mathbb{R}^3$ under the same projection.","['functional-analysis', 'normed-spaces', 'linear-algebra', 'convex-analysis']"
1908732,"Combinatorial proof that the maximum of an i.i.d. sample of size $n$ uniform on $(0,1)$ has expectation $\frac{n}{n+1}$?","Let $X_i \sim U(0,1)$ for $i = 1,\dots,n$, and let $X = \max(X_1,\dots,X_n)$. Is there a combinatorial way of seeing that 
$$\mathbb E(X) = \frac{n}{n+1}$$
and likewise for the minimum? Intuitively this is my guess for the expectation since, ""on average,"" the experiment results will be distributed evenly on $[0,1]$. This may of course be verified by 
$$\int_0^1 x[P(X < x)]' \mathrm dx = \int_0^1 nx^n \mathrm dx = \frac{n}{n+1}.$$","['uniform-distribution', 'probability-theory', 'expectation']"
1908750,Show that $f(z)$ has at least two zeros (complex analysis),"Let $f$ be a non-constant analytic function in $D=1<|z|<2$ with $|f|\equiv5$ on the boundary (assume $f$ is continuous on $\overline D$). Show that $f$ has at least two zeros. My opinion: Based on maximum module principle, we have $|f(z)|\leq 5$ for any $z \in D$. Suppose $f$ doesn't have zero in that region $D$, then we have $1/|f(z)|=1/5$ on the boundary and $1/|f(z)|<1/5$ (based on maximum module principle theorem and the fact that $f(z)$ is non-constant). However, it contracts to $|f(z)|\leq 5$, which implies that $|f(z)|\geq 1/5$ for any $z \in D$. That's why $f(z)$ has to have at least one zero in $D$. But how can I prove $f$ has at least two zeroes?","['real-analysis', 'maximum-principle', 'functional-analysis', 'complex-analysis', 'analysis']"
1908754,Is there something like a normal distribution model for discrete probability?,"If one wants to find the probability that a continuous random variable will fall within a range of $a \leq X \leq b$, based on a mean value $\mu$, and a deviation of $\sigma$, he would integrate the normal distribution function: $$\int^b_a \frac{e^{-\frac{(x-\mu)^2}{2\sigma^2}}}{\sigma\sqrt{2\pi}}dx$$ Since this is for continuous probability, is there an alternative to normal distribution for discrete probability? Suppose $\mu = 100$, and $\sigma = 50$. For discrete probability, I would try to use bounds close together to achieve a similar, but still not the completely desired outcome. However, the probability is very low: $$\int^{99.95}_{100.05}p(x)dx = 0.0008$$ The probability seems too low for this to be true, which suggests that a different model for discrete probability should exist.","['probability', 'normal-distribution']"
1908792,Convergence of measures of sets with measure zero boundary,"Let $P_k$, $k\in\mathbb{N}$, and $P$ be probability measures on $\mathbb{R}^n$ equipped with the sigma-algebra of Borel sets and suppose that $P_k\longrightarrow P$ weakly. Let $A\subseteq\mathbb{R}^n$ be open or closed with $P(\partial A)=0$, though not necessarily with $P_k(\partial A)=0$, where $\partial A$ denotes the boundary wrt. standard topology. Must we have that $P_k(A)\longrightarrow P(A)$?","['weak-convergence', 'real-analysis', 'measure-theory', 'probability-theory']"
1908861,Using trig identity to solve a cubic equation,"I need to use the identity $\cos(3\theta)=4\cos(\theta)^3-3\cos(\theta)$ to solve the cubic equation $t^3+pt+q=0$ when $27q^2+4p^3<0$ . I believe I need to let $t=A\cos(\phi)$ when $A=2\sqrt{\frac{-p}{3}}$ , so that my equation looks more like the identity and I have $A^3\cos(\theta)^3+Ap\cos(\theta)+q=0$ . Next I multiply by $\frac{4}{A^3}$ to get $4\cos(\theta)^3+\frac{4p}{A^2}\cos(\theta)+\frac{4q}{A^3}=0$ . So then $4\cos(\theta)^3-3\cos(\theta)-\frac{3q}{Ap}=0$ . Now I am stuck and not sure what my next step is.","['algebra-precalculus', 'cubics']"
1908878,Intuition on the external Zappa–Szép product,"$\newcommand{\Aut}{\operatorname{Aut}}$A classmate of mine recently posted an interesting question on Facebook. It didn't get an answer, and I couldn't get anywhere myself, so I'm hoping that someone here will be able to help out. Here's a paraphrase of the question: The Zappa–Szép product generalizes the semi-direct product, which
  itself is a generalization of the direct product. They've all got
  roughly the same conditions for the ""internal"" product: $H$ and $K$ are subgroups of some parent group $G$ $H \cap K = \{ e \}$ $HK = G$ Normality: Direct: $H$ and $K$ are normal in $G$ Semidirect: $K$ is normal in $G$ Zappa-Szép: no further assumptions But usually, people use this products in their ""external"" forms. For
  these three, we need different amounts of additional data describing how the
  groups commute. For the direct product $H \times K$, we need no further information. For
  a semidirect product $H \rtimes_\varphi K$, we also need a homomorphism
  $\varphi : H \to \Aut(K)$. So for the Zappa-Szép product, one might expect to have two
  homomorphisms: $\alpha : K \to \Aut(H)$ and $\beta : H \to \Aut(K)$.
  But as the Wikipedia article explains, one of the conditions we need is that
  $$ \alpha(k, h_1 h_2) = \alpha(k, h_1) \cdot \alpha(\beta(h_1, k), h_2) $$ But if $\alpha(k)$ were an automorphism of $H$, then the condition would
  just be
  $$ \alpha(k, h_1 h_2) = \alpha(k, h_1) \cdot \alpha(k, h_2) $$ This makes sense from a multiplication perspective, because as we pull
  the $k$ to the right of $h_1$, it will become a different element of
  $K$. But it's rather unappetizing from a morphism perspective. Is there a way to phrase this additional data more elegantly? Here's my thoughts so far: $\alpha$ might not be a homomorphism into $\Aut(H)$, but it's still a left group action of $K$ on $H$. Same for $\beta$, except it's a right group action. So that takes care of the first five conditions from the wiki page. So now we just need to rephrase the last two conditions in a group-action-friendly way. But I can't seem to do so. Alternatively, maybe we should think of this as a single map $\psi : K \times H \to H \times K$. But I can't think of any natural, morphism-ish qualities that this map must have.","['intuition', 'abstract-algebra', 'semidirect-product', 'soft-question']"
1908897,Is $X/A$ contractible if both $X$ and $A$ are?,"Let $X$ be a contractible topological space. Let $A\subseteq X$ be a contractible subspace. Is the quotient space $X/A$ necessarily contractible? It is not hard to show that this is true if, for example, the pair $(X,A)$ has the homotopy extension property (see, e.g. Proposition 0.17 of Hatcher, Algebraic Topology). Some friends and I amused ourselves by trying to answer this question without assuming that $(X,A)$ has the HEP, but we were unsuccessful. Any insight would be appreciated.",['general-topology']
1908933,Proof of $y$ is odd given $x + y$ is even and $x$ is odd.,"If $x + y$ is even and $x$ is odd, then we want to show that $y$ must be odd. Assume that $x + y$ is even and that $x$ is odd. Then, by the definition of even, $\exists k \in \mathbb{Z}$ such that $2k = x + y$. Similarly, by the definition of odd, $\exists m \in \mathbb{Z}$ such that $2m + 1 = x$. Subtract the two equations to find that: $y = 2k - 2m - 1$. From here, I am confused. Is it correct to say: Let $r = k - m - 1$. Substitute for $r$ and then find $y = 2r + 1$?","['discrete-mathematics', 'elementary-number-theory']"
1908946,"Confused by proof of the irrationality of root 2: if $p^2$ is divisible by $2$, then so is $p$.","In typical proofs of the irrationality of $\sqrt{2}$, I have seen the following logic: If $p^2$ is divisible by $2$, then $p$ is divisible by $2$. Perhaps I am being over-analytical, but how do we know this to be true? IE. do we require a proof of this implication, or is it simply fact?","['discrete-mathematics', 'proof-explanation', 'elementary-number-theory']"
1909000,"Events in a measure preserving system satisfying $\mu (A \cap T^{-n}B) = \mu(A)\mu(B)$ for all $n$ large imply $\mu(A) \in \{0,1\}$","Let $(X, \mathscr B_X, \mu, T)$ be a measure-preserving system such that the condition in the title is satisfied for all $n$ larger than $N \in \Bbb N$ . How can we conclude that $A$ is trivial? Any help\hints are appreciated.","['probability', 'ergodic-theory']"
1909005,Independent random variables and $\sigma$-algebras,"Let $(X_k)$ be a sequence of independent random variables, all defined on the probability space $(\Omega,\mathcal{A},P)$. Fix a positive integer $n$ and define
$$
C_n=\sigma(X_1,X_2,\cdots,X_n),\quad D_n=\sigma(X_{n+1},X_{n+2},\cdots).
$$ Here is my question : How to show by definition that $C_n$ and $D_n$ are independent? By the definition of independence of $X_k$, for any finite set of positive integers $I$, the $\sigma$-algebras $(\sigma(X_i))_{i\in I}$ are independent. Eventually, one needs to show that $$
P(A\cap B)=P(A)P(B)
$$
for all $A\in C_n$ and $B\in D_n$. 
How shall I go on?",['probability-theory']
1909008,Is $\sum_{n=1}^\infty \ln \left(1-\frac{1}{p_n^s} \right)=-\ln \zeta(s)$ the only known series with primes and nontrivial closed form?,"To clarify, I'm asking about series where $n$ th term depends only on $n$ th prime number. From the famous result (by Euler, I think) we have: $$\sum_{n=1}^\infty \ln \left(1-\frac{1}{p_n^s} \right)=-\ln \zeta(s)$$ As a particular case: $$\sum_{n=1}^\infty \ln \left(1-\frac{1}{p_n^2} \right)=-\ln \frac{\pi^2}{6}$$ What about the general series: $$\sum_{n=1}^\infty f(p_n)$$ Does it have a nontrivial closed form for some other function $f$ ? In general, I'm also interested in infinite products (they can be easily written as series, as I did for the titular one), nested radicals, continued fractions, etc. Edit Thanks to the great advice of @user1952009, I looked up Dirichlet beta function , which has the prime expansion: $$\sum_{n=2}^\infty \ln \left(1-\frac{(-1)^{(p_n-1)/2}}{p_n^s} \right)=-\ln \beta(s)$$ Among it's special values we have: $$\sum_{n=2}^\infty \ln \left(1-\frac{(-1)^{(p_n-1)/2}}{p_n} \right)=-\ln \frac{\pi}{4}$$ $$\sum_{n=2}^\infty \ln \left(1-\frac{(-1)^{(p_n-1)/2}}{p_n^2} \right)=-\ln G$$ (Catalan's constant) $$\sum_{n=2}^\infty \ln \left(1-\frac{(-1)^{(p_n-1)/2}}{p_n^3} \right)=-\ln \frac{\pi^3}{32}$$ Etc.","['riemann-zeta', 'prime-numbers', 'sequences-and-series', 'closed-form']"
1909013,Alternative proof : If E and F have positive measures then E+F contains an interval,"The statement is following : $E, F$ are measurable subsets in $\mathbb{R}$ which have positive
  measure. Then prove that $E+F=\left\{ x+y\ :\ x\in E,\ y\in F\right\}$
   contains an interval. This is a problem 30 in Stein's Real analysis. I already read the proof of this by using convolusion which is here .(This problem is so-called Steinhaus theorem) Moreover, I proved that the previous problems number 28 and 29 in the book. 
My goal is applying the same technique to above one, using the technique in problem number 29 : First, by problem number 28, $ \exists I^F$ and $I^E$ such that $$m(E\cap I^{E})\geq{\displaystyle \frac{9}{10}m(I^{E})} \text{ and }  m(F\cap I^{F})\ge{\displaystyle \frac{9}{10}m(I^{F})}.$$ Let $E_{0}= E\cap I^{E}$ and $F_{0}= F\cap I^{F}$ and let $e_{0}, f_{0}$ : center of $I^{E}, I^{F}$, respectively. Suppose $E_{0}+F_{0}$ does not contain an interval centered at $e_{0}+f_{0}$. Then $\exists a$ : small such that $E_{0}\cap(e_{0}+f_{0}+a-F_{0})=\phi$. But, $E_{0}\cup(e_{0}+f_{0}+a-F_{0})\subset I^{E}\cup(e_{0}+f_{0}+a-I^{F})$. Measure of left hand side is more than $\frac{9}{10}(m(I^{E})+m(I^{F}))$ but the measure of Right had side is slightly less than $\max(m(I^{E}),m(I^{F}))$. And that's it. I stopped here. I can't make any contradiction.
I thought that if I can make measure of $I^E and I^F$ are equal, then I prove the problem but this one is also a big problem. Anyone can comment on this?","['alternative-proof', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
1909074,Prove $\int\limits_{0}^{\infty} \mathrm{exp}(-ax^{2}-\frac{b}{x^{2}}) \mathrm{d} x = \frac{1}{2}\sqrt{\frac{\pi}{a}}\mathrm{e}^{-2\sqrt{ab}}$,"This is Example 8.4.1 from Chapter 8 (The Normal Integral) of Irresistible Integrals by Boros and Moll. The authors outlined a solution method, which I will provide in full here. My question: is there another way to obtain this result? Here is the solution of Boros and Moll with their notation. Let
\begin{equation}
\mathrm{L}(a,b) := \int\limits_{0}^{\infty} \mathrm{exp}(-ax^{2}-\frac{b}{x^{2}}) \mathrm{d} x
\label{eq:iic8-1}
\tag{1}
\end{equation}
Making the substitution $t=x\sqrt{a}$ yields
\begin{equation}
\int\limits_{0}^{\infty} \mathrm{exp}(-ax^{2}-\frac{b}{x^{2}}) \mathrm{d} x = \frac{1}{\sqrt{a}} \int\limits_{0}^{\infty} 
\mathrm{exp}(-t^{2}-\frac{ab}{t^{2}}) \mathrm{d} t
\label{eq:iic8-2}
\tag{2}
\end{equation}
Letting $ab=c$ we call the integral in equation \eqref{eq:iic8-2} $f(c)$,
\begin{equation}
f(c) = \int\limits_{0}^{\infty} \mathrm{exp}(-t^{2}-\frac{c}{t^{2}}) \mathrm{d} t
\label{eq:iic8-3}
\tag{3}
\end{equation}
so that 
\begin{equation}
\mathrm{L}(a,b) = \frac{f(ab)}{\sqrt{a}}
\label{eq:iic8-4}
\tag{4}
\end{equation}
In equation \eqref{eq:iic8-3} we let $y=\sqrt{c}/t$
\begin{equation}
f(c) = \sqrt{c} \int\limits_{0}^{\infty} \mathrm{exp}(-y^{2}-\frac{c}{y^{2}}) y^{-2} \mathrm{d} y
\label{eq:iic8-5}
\tag{5}
\end{equation} Combining equations \eqref{eq:iic8-3} and \eqref{eq:iic8-5}, we have
\begin{equation}
f(c) = \frac{1}{2} \int\limits_{0}^{\infty} \mathrm{exp}(-t^{2}-\frac{c}{t^{2}}) \left(1+\frac{\sqrt{c}}{t^{2}} \right) \mathrm{d} t
\label{eq:iic8-6}
\tag{6}
\end{equation}
Now we let $s = t - \sqrt{c}/t$
\begin{equation}
f(c) = \frac{\mathrm{e}^{- 2\sqrt{c}}}{2} \int\limits_{-\infty}^{\infty} \mathrm{exp}(-s^{2}) \mathrm{d} s = \frac{\sqrt{\pi}}{2} \mathrm{e}^{- 2\sqrt{c}} \lim_{z \to \infty} \mathrm{erf}(z) = \frac{\sqrt{\pi}}{2} \mathrm{e}^{- 2\sqrt{c}}
\label{eq:iic8-7}
\tag{7}
\end{equation}
Combining equations \eqref{eq:iic8-1}, \eqref{eq:iic8-4}, and \eqref{eq:iic8-7} yields our result.","['integration', 'definite-integrals']"
1909097,Expectation of first-passage-time of a diffusion process with negative drift,"Take  the stochastic process $X_0 = 0$ and $X_t = \nu t + \sigma W_t$  where $W_t$ is standard Brownian motion and $\nu$ is a drift which may be negative (this is the key complexity to the question) Let $\alpha > 0$ be a fixed level, then define the first passage time as the random variable: $T = \inf\{ 0 < t \mid X_t=\alpha \}$. Then, given some $r > 0$, what is the following expectation?
$$
U \equiv \mathbb{E}\left(e^{-r T} \right)
$$ A related question may be: what is the moment generating function for the $T$ stopping time?  Note that I do not care about the pdf or cdf of $T$, just the above expectation. Solving the $\nu \geq 0$ case: I believe this turns out to be easy as this follows the example in https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution#Relationship_with_Brownian_motion .  Hence, $T$ is distributed as an Inverse Gaussian: $T\sim IG(\tfrac\alpha\nu, \tfrac {\alpha^2} {\sigma^2})$ in that notation. Moreover, the moment generating function for the $IG(\mu,\lambda)$ is $$M(t;\mu,\lambda) \equiv \exp\left[{\frac{\lambda}{\mu}\left(1-\sqrt{1-\frac{2\mu^2t}{\lambda}}\right)}\right]$$ Finally, note that the expectation I gave is exactly the definition of the MGF at $t=-r$, so we have our answer,
$$
\mathbb{E}\left(e^{-r T} \right) = M\left(-r;\tfrac\alpha\nu, \tfrac {\alpha^2} {\sigma^2}\right)
$$ Solving the $\nu < 0$ case: If you look carefully at theorems such as in Karlin  and Taylor ""A First Course in Stochastic Processes"" page 362 and theorem 5.3, or the wikipedia page above, they always assume that $\nu \geq 0$.  As Karlin and Taylor puts it: ""When $\nu < 0$, $T$ has a defective probability distribution, that is $T$ is infinite with positive probability"". However, to find $\mathbb{E}\left(e^{-r T}\right)$ we don't really need to find the probability distribution.  Is the moment generating function (and hence the direct solution for $U$) still defined?  Is the formula the same as above?","['stochastic-processes', 'martingales', 'expectation', 'measure-theory']"
1909100,Picard group of analytic variety,"I am reading Huybrecht's introduction to complex geometry, and be stuck. First he introduces the exponential sheaf sequence, so that we have :
$H^1(X,Z)\to H^1(X,\mathcal{O}_X)\to H^1(X,\mathcal{O}^*_X)\to H^2(X,Z)$. Then he says if $X$ is compact, then the map $H^1(X,Z)\to H^1(X,\mathcal{O}_X)$ is injective. Why we have this? Since $Pic(X)$ is isomorphic to $H^1(X,\mathcal{O}^*_X$), he says discrete part of $Pic(X)$ can be measured by it image in $H^2(X,Z)$ and continuous part comes from vector space $H^1(X,\mathcal{O}_X)$. Why $H^1(X,\mathcal{O}_X)$ is  a vector space and what does he mean by discrete and continuous part? I apologize if the question is very fundamental since I am totally new to complex geometry.","['complex-geometry', 'algebraic-geometry']"
1909131,Question about countable sets from Rudin's Analysis book,"I am starting to read Baby Rudin's book and there is a section devoted to countable sets in which he said that a set $ A $ is countable if there exists a $ 1 $-$ 1 $ correspondence between $ A $ and $ \mathbb{Z}^{+}. $ So my question is suppose that I have an infinite set $ A, $ I pick one element $ s \in A $ and map $ 1 $ to $ s, $ then I pick another element $ t \in A $ and map $ 2 $ to $ t, $ and so on, then I will get a $ 1 $-$ 1 $ correspondence between $ A $ and $ \mathbb{Z}^{+} $ eventually, meaning $ A $ is countable. I know this is incorrect since it will mean that every set is countable, but I don't seem to see the idea in the concept of countable sets, so can someone help me clarifying this? Rudin also proved this theorem which has been asked here. The theorem said that ""the union of countably many countable sets is countable."" My second question is where in the proof did he use the condition that each set $ E_{i} $ is countable? Also, suppose that I change the statement into ""the union of many countable sets is countable,"" then this statement is no longer true, but where in the proof that he used this condition that it has to be the ""the union of $ \textbf{countably} $ many countable sets?""",['elementary-set-theory']
1909138,Finding the smallest equivalence relation containing a specific list of ordered pairs,"I'm having trouble trying to understand the smallest equivalence relation containing a specific subset. Q: Find the smallest equivalence relation $R$ on $M = \{1,2,3,4,5\}$ which contains the subset $R_0 = \{(1,1), (1,2), (2,4), (3,5)\}$ I know this is probably really simple but I just cant get it. Is anyone able to explain this to me? I've tried to find explanations elsewhere, but nothing I can find talks about the smallest equivalence relation. From Comments: Adding (2,2), (3,3), (4,4), (5,5) makes it Reflexive Adding (2,1), (4,2), (5,3) makes it Symmetric Adding (1,4), (4,1) makes it Transitive So the smallest equivalence relation would be the R0 + those added?","['elementary-set-theory', 'discrete-mathematics']"
1909140,Closed subgroups of $\hat{\mathbb{Z}}\cong\prod_{p}\mathbb{Z}_{p}$ as subsets?,"Some definitions and notation A procyclic group $G$ is a profinite group with a dense cyclic subgroup, or equivalently, $G$ is isomorphic to an inverse limit of discrete finite cyclic groups. We denote the profinite completion of the integers (resp. the $p$-adic integers) by
\begin{equation}
\hat{\mathbb{Z}}=\varprojlim\mathbb{Z}/n\mathbb{Z}  \qquad\qquad\qquad\mathbb{Z}_{p}=\varprojlim\mathbb{Z}/p^{n}\mathbb{Z}
\end{equation} Question I've learned the fact that a torsion-free procyclic group $G$ is (topologically) isomorphic to product
\begin{equation}
G\cong\prod_{p\in S}\mathbb{Z}_{p},
\end{equation}
where $S$ is some set of rational prime numbers. In particular, that
\begin{equation}
\hat{\mathbb{Z}}\cong \prod_{p\in P}\mathbb{Z}_{p},
\end{equation}
where $P$ is the set of all prime numbers. There is also the fact that a closed subgroup $G\subseteq\hat{\mathbb{Z}}$ is procyclic, which then implies that $G$ is isomorphic to a product of $\mathbb{Z}_{p}$' s over some set $S$ of primes. Now, we can take some closed subgroups of $\prod_{p\in P}\mathbb{Z}_{p}$ which are obviously isomorphic to such a product of $\mathbb{Z}_{p}$'s, for instance, all of the subgroups of the form
\begin{equation}
2^{i_{2}}\mathbb{Z}_{2}\times 3^{i_{3}}\mathbb{Z}_{3}\times 5^{i_{5}}\mathbb{Z}_{5}\times\dots
\end{equation}
with $i_{p}$ ranging the positive $(\geq 0)$ integers (and $\infty$ to represent the $\{0\}$ subgroup of $\mathbb{Z}_{p}$), for each prime $p$. (This is due to the fact that $\mathbb{Z}_{p}\cong p^{i}\mathbb{Z}_{p}$ for each $i\geq 0$.) Note that the $\{0\}$ factors just make the prime vanish. So, my question is: Can we describe the closed subgroups of $\prod_{p\in P}\mathbb{Z}_{p}$ as subsets? I guess they are all of the above form, but since subgroups of a direct product are not simply products of subgroups, I'm not sure how to prove this. Do we even know if this is true? I'm trying to get a clearer picture on the 'structure-lattice' of $\hat{\mathbb{Z}}$. Thanks for any help or references!","['abstract-algebra', 'profinite-groups', 'group-theory']"
1909153,Some questions on Hartshorne's Theorem I-3.2,"1 He said ""it is surjective by definition of a regular function"", but I feel confused: any $f/g\in$$A(Y)_{m_p}$ with $f\in A(Y),g\in {m_p}$, is not regular on $p$,since $g(p)=0$. 2 I know $A(Y)/{m_p}$ is a field, but why is that $k$? 3 For $dim O_p$= height $m_p$, In think it applies Theorem l.8A(b),
then we can get: height $m_p$+ $dim A(Y)_{mp}/m_p$=$dim  A(Y)_{mp}$=$dim O_p$, but here how can I see $dim A(Y)_{mp}/m_p$=0?",['algebraic-geometry']
1909155,Are real numbers complex conjugates of one another?,"I'm just stuck with a technical part of my proof that might just be a triviality:  if two different numbers are both real, are they complex conjugates of each other? Thanks,","['real-analysis', 'complex-numbers', 'real-numbers', 'calculus', 'complex-analysis']"
1909228,How to intersect the line at infinity?,"Question: Given: two points, $p=(a_1:b_2:1),q=(a_2:b_2:1)\in \mathbb{C}^2 \subset \mathbb{CP}^2$ and a cubic (i.e. elliptic) plane curve $\mathcal{C}$ (for example: $\{(x:y:z): x^3 - y^2z + z^3=0 \}$), such that $p,q \in \mathcal{C}$. What is a (or the) rigorous method to find the third point of the intersection of $\ell(p,q)$ (the unique line passing between $p$ and $q$) with $\mathcal{C}$ when this third point $r$ lies on the line at infinity? In other words, how can one rigorously find the formula for $r=\ell(p,q)\cap \mathcal{C}\setminus\{p,q\}$ when $r \in \{(x:y:0)\in \mathbb{CP}^2 \}$, the line at infinity? I know several ad hoc/intuitive/non-rigorous ways for finding $r$ which produce the correct answer. However, my usual rigorous method for finding $r$ breaks down when $r$ is in the line at infinity. Background/Context/Motivation: Let's say I have the points $P_2=(0:1:1)$ and $P_4=(0:-1:1)$ in the complex projective plane, which both lie on the cubic curve $\mathcal{C}=V(x^3 -y^2z +z^3)=\{(x:y:z)\in \mathbb{CP}^2 : x^3 - y^2z +z^3=0  \}$. (This is from exercises 2.3.5 and 2.3.6 in Algebraic Geometry: A Problem Solving Approach .) Now I don't know the equation for the line between $P_2$ and $P_4$ explicitly, but I can parametrize it as $\ell=\{ tP_2 + (1-t)P_4\in \mathbb{CP}^2 :t\in \mathbb{C}  \}$, which is is actually easier to work with ( usually ) because the parametrization makes it univariate instead of trivariate. Anyway, I know by Bezout's Theorem or the Fundamental Theorem of Algebra, that $\ell$ and $\mathcal{C}$ must intersect at exactly three points (up to multiplicity). The problem is this: the univariate polynomial whose zeroes are supposed to be the three points of $\ell \cap \mathcal{C}$ is in this case quadratic (it is usually cubic as one would expect), and reduces to $t(t-1)=0$, i.e. not only is there one root too few, but the two roots which one does find are the two trivial roots which exist necessarily by the chosen parametrization for $\ell$ (i.e. when $t=0$, $P_4$, and when $t=1$, $P_2$). The whole point is to find the third point of $\ell \cap \mathcal{C}$ because this is the product of $P_2$ and $P_4$ under the chord-tangent composition law . For some reason this method does not work when the intersection of the parametrized line and the plane curve of interest lies on the line at infinity -- why does it not work in this case? For the record, what I am doing is substituting $\ell$ into the equation for $\mathcal{C}$, because (ostensibly) one should have that $$\{tP_2 + (1-t)P_4\in \mathbb{CP}^2 :t\in \mathbb{C} \} \cap \{ (x:y:z)\in \mathbb{CP}^2 : x^3 - y^2z +z^3=0  \} \\ = \{ (x:y:z) : \left[(x:y:z)=tP_2 + (1-t)P_4\text{ for some }t \in \mathbb{C}\right]\ \land\ \left[x^3 -y^2z + z^3 =0 \right]  \} \\ = \{ (0:2t-1:1) : (0)^3-(2t-1)^2(1) + (1)^3 =0  \} $$ However, this doesn't work, again because the polynomial in the last line is quadratic and not cubic. Now it is clear to me for several reasons that the third point of intersection of $\ell$ with $\mathcal{C}$ is $(0:1:0)$ Looking at the picture of the situation, it is self-evident that the third point of intersection cannot be in $\mathbb{C}^2$ and thus must lie on the line at infinity. Moreover, one can check that $(0:1:0)$ is the only point in $\mathcal{C}$ which is also in the line at infinity. The point in the line at infinity corresponding to $P_2=(0:1:1)$ is $(0:1:0)$ and the point in the line at infinity corresponding to $P_4=(0:-1:1)$ is $(0:-1:0)=(0:1:0)$. The line between $P_2$ and $P_4$ corresponds to the line $x=0$ in $\mathbb{C}^2$, which can only intersect the line at infinity at $(0:1:0)$. For points of $\ell$ such that $t\not=\frac{1}{2}$, one has that $(0:2t-1:1)=(0:1:\frac{1}{2t-1})$. Then $\underset{t \to \infty}{\lim} (0:1:\frac{1}{2t-1})=(0:1:0)$ and because intuitively lines in projective space ""wrap around and meet at infinity"" one should have that this limit is in $\ell$ and thus is our ""third root"". Ideally, I would like to setup the situation so that I have a cubic polynomial and that $(0:1:0)$ actually corresponds to the third root of this polynomial. However, I do not know how to do this.","['algebraic-curves', 'projective-geometry', 'algebraic-geometry']"
1909261,If $(M_n)$ is a symmetric random walk then $(M_n^2)$ is a Markov process (or not?),"Let $\{X_n:n=0,1,2,\ldots\}$ be an i.i.d. sequence of random variables with $$\mathbb P(X_1=1)=\mathbb P(X_1=-1)=\frac12 $$ and consider the process $\{M_n:n=0,1,2\ldots\}$ with $M_0=0$ and $$M_n = \sum_{j=1}^n X_j,\; n\geqslant 1. $$
It is clear that $M_n$ is a martingale, so the discrete stochastic integral $I_0=0$, $$I_n=\sum_{j=0}^{n-1}M_j(M_{j+1}-M_j)  $$ exists and is a martingale, and by induction we find that $I_n = \frac12 M_n^2 - \frac12n$. Now, by definition, $\{I_n\}$ is a Markov process iff for each nonnegative integer $n$ and  bounded measurable function $f$, there exists a measurable function $g_n$ such that $$\mathbb E[I_{n+1}\mid\mathcal F_n] = g_n(I_n). \tag 1$$ (where $\{\mathcal F_n\}$ is the canonical filtration of $\{I_n\}$). Writing $$I_{n+1}=\frac12\left(M_n+X_{n+1}\right)^2 - \frac12(n+1)$$
and conditioning on $X_{n+1}$, I found that $g_n:\mathbb Z\to\mathbb R$ with $$g_n(k) = \frac12 f\left( k + \sqrt{2k+n}\right) + \frac12 f\left(k-\sqrt{2k+n}\right) $$ satisfies $(1)$, but the computation (and the result!) are not particularly enlightening. Is there a more intuitive way to show that $\{I_n\}$ is a Markov process?","['stochastic-processes', 'probability-theory', 'markov-process', 'martingales']"
1909316,A Formulation of The Riemann Hypothesis,"To preface this inquiry, I am aware of the fastidious nature of the mathematics presented on this exchange. In addition to that, I apologize for my ineptness and the contention in this particular subject; however, this is of great interest to me. I ask for pardon with the great length of this text. The following formulation invokes the Argument Principle due to Cauchy. In this sense, consider the closed rectifiable Jordan curve $\mathcal D^{+}= \mathcal D^{+}(T)$ with vertices $(\frac{1}{2}+\epsilon)-iT, 2-iT, 2+iT, (\frac{1}{2}+\epsilon)+iT$, traversed in that order, i.e., with positive orientation. Likewise, let $D^{-}=D^{-}(T)$ denote the closed contour with vertices $-1-iT, (\frac{1}{2}+\epsilon)-iT, (\frac{1}{2}+\epsilon)+iT, -1+iT$, and positive orientation. In both cases $\epsilon$ is chosen to be arbitrarily small. Furthermore, invoking the detail that the zeros of the function $\xi(s)$, where $s=\sigma+it$, are identical to the non-trivial zeros of the function $\zeta(s)$, and the fact that $\xi(s)$ has no poles; we obtain the number of zeros of $\zeta$ in the region $\mathcal D^{+}$ and $\mathcal D^{-}$ are $$N_+(T)=\frac{1}{2\pi i}\int_{\mathcal D^+} \frac{{\xi}^\prime (s)}{\xi(s)}ds=\frac{1}{2 \pi}Im\left(\int_{\mathcal D^+} \frac{{\xi}^\prime (s)}{\xi(s)}ds\right)$$ and $$N_-(T)=\frac{1}{2\pi i}\int_{\mathcal D^-} \frac{{\xi}^\prime (s)}{\xi(s)}ds=\frac{1}{2 \pi}Im\left(\int_{\mathcal D^-} \frac{{\xi}^\prime (s)}{\xi(s)}ds\right),$$ respectively. By the symmetry of both $\xi$ and $\mathcal D^{+}, \mathcal D^{-}$, $N_-(T)=N_+(T)$. Let $\mathcal C_0^{+}$ denote the contour with vertices $\frac{1}{2}+\epsilon, 2, 2+iT, (\frac{1}{2}+\epsilon)+iT$, traversed in the positive sense. Similarly, let $\mathcal C_1^{+}$ denote the contour with vertices $(\frac{1}{2}+\epsilon)-iT, 2-iT, 2, \frac{1}{2}+\epsilon$, also traversed in the positive sense. Decomposing $\mathcal D^{+}$ into $\mathcal C_0^{+}$ and $\mathcal C_1^{+}$ yields $\mathcal D^{+}:=\mathcal C_0^{+} \cup \mathcal C_1^{+}$, whereby $\mathcal D^{+}:=\mathcal C_0^{+} \cap \mathcal C_1^{+}=[\frac{1}{2}+\epsilon,2].$ Hence, the former integral $N_+(T)$ can be expressed as
$$N_+(T)=\frac{1}{2 \pi}Im\left(\int_{\mathcal C_0^{+}} \frac{{\xi}^\prime (s)}{\xi(s)}ds\right)+\frac{1}{2 \pi}Im\left(\int_{\mathcal C_1^{+}} \frac{{\xi}^\prime (s)}{\xi(s)}ds\right).$$ Since $\xi$ is positive real on the portion of the real axis $\mathcal C_0^{+} \cap \mathcal C_1^{+}$, the argument of $\xi$ does not change there. Let $\tilde {\mathcal C_0^{+}}, \tilde {\mathcal C_1^{+}}$ denote $\mathcal C_0^{+}, \mathcal C_1^{+}$ without $\mathcal C_0^{+} \cap \mathcal C_1^{+}$. Therefore $$\begin{align*} N_+(T)& =\frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_0^{+}} \frac{{\xi}^\prime (s)}{\xi(s)}ds\right)+\frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_1^{+}} \frac{{\xi}^\prime (s)}{\xi(s)}ds\right)\\ & \equiv \frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_0^{+}} \frac{{\zeta}^\prime (s)}{\zeta(s)}ds\right)+\frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_1^{+}} \frac{{\zeta}^\prime (s)}{\zeta(s)}ds\right)\end{align*}$$ Since the set of zeros of $\zeta$ is discrete, we may assume no zero of $\zeta$ has imaginary part $T$. This integral can be decomposed into the contribution over the vertical lines, and over the one horizontal line. In particular, $$\begin{align*} \frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_0^{+}} \frac{{\zeta}^\prime (s)}{\zeta(s)}ds\right) &= Im \left(i \int_0^{-T} \frac{{\zeta}^\prime ((\frac{1}{2}+\epsilon)+iy)}{\zeta(\frac{1}{2}+\epsilon)+iy)} dy+\int_{\frac{1}{2}+\epsilon}^{2} \frac{{\zeta}^\prime (\sigma-iT)}{\zeta(\sigma-iT)} d\sigma \right)\\ &=Im\left(\int_{\frac{1}{2}+\epsilon}^{2} \frac{{\zeta}^\prime (\sigma-iT)}{\zeta(\sigma-iT)} d\sigma \right)-Im \left(i \int_{-T}^{0} \frac{{\zeta}^\prime ((\frac{1}{2}+\epsilon)+iy)}{\zeta(\frac{1}{2}+\epsilon)+iy)} dy \right)\end{align*}$$ for which the integral over the vertical segment $[2-iT,2]$ vanishes, due to the boundedness of the total variation of $arg(\zeta(2+it))$ on the segment $[2-iT,2]$. It can be shown that $$\frac{\zeta^{\prime}(s)}{\zeta(s)}=-\frac{1}{s}-\frac{1}{s-1}+\frac{1}{2}log(\pi)+\sum_\rho \frac {1}{s-\rho}-\frac{1}{2}\frac{\Gamma^{\prime}(\frac{s}{2})}{\Gamma(\frac{s}{2})}=\sum_\rho \frac {1}{s-\rho}+O(log|t|),$$ for $\sigma \ge -1, |t| \ge 2.$ This, in turn, can be used to show $$\frac{\zeta^{\prime}(s)}{\zeta(s)}=\sum_{|\gamma_n-t|\le 1} \frac{1}{s-\rho_n}+O(log|t|),$$ with the same condition $\sigma \ge -1, |t| \ge 2.$ As such, it follows that $$\begin{align*}Im\left(\int_{\frac{1}{2}+\epsilon}^{2} \frac{{\zeta}^\prime (\sigma-iT)}{\zeta(\sigma-iT)} d\sigma \right)&=Im\left(\sum_{|\gamma_n-T| \le 1}\int_{\frac{1}{2}+\epsilon}^{2} \frac{d\sigma}{\sigma-it-\rho_n} \right)+Im\left(\sum_{|\gamma_n-T| \le 1}\int_{\frac{1}{2}+\epsilon}^{2} O(log|T|)dT \right)\\ &\equiv \sum_{|\gamma_n-T| \le 1}Im\left(\int_{\frac{1}{2}+\epsilon}^{2} \frac{d\sigma}{\sigma-it-\rho_n} \right)\end{align*}$$ By the Argument Principle, each summand equals the net change of $arg(s-\rho_n)$ on $[\frac{1}{2}+\epsilon-iT,2-iT]$; thus, its absolute value is less than $\pi.$ In similar vein, by the von Mangoldt estimate of the vertical density of roots $\rho_n$: $N(T+1)-N(T) \le \sum_{T \le \gamma_n \le T+1}1 < 2logT,$ the number of summands is less than $4logT.$ The modulus of the latter integral is $$\left |\sum_{|\gamma_n-T| \le 1}Im\left(\int_{\frac{1}{2}+\epsilon}^{2} \frac{d\sigma}{\sigma-it-\rho_n} \right) \right|<4\pi logT,$$ for large $T.$ Consequently $$\sum_{|\gamma_n-T| \le 1}Im\left(\int_{\frac{1}{2}+\epsilon}^{2} \frac{d\sigma}{\sigma-it-\rho_n} \right)=O(logT).$$ Similarly 
$$\begin{align*}Im \left(i \int_{-T}^{0} \frac{{\zeta}^\prime ((\frac{1}{2}+\epsilon)+iy)}{\zeta(\frac{1}{2}+\epsilon)+iy)} dy \right)&=Im\left(i \int_{-T}^{0} \sum_{|\gamma_n-T|\le 1} \frac{dy}{(\frac{1}{2}+\epsilon)+iy-\rho_n}+i\int_{-T}^{0}O(log|T|)dy \right)\\ &=Im\left(i \sum_{|\gamma_n-T|\le 1} \int_{-T}^{0} \frac{dy}{(\frac{1}{2}+\epsilon)+iy-\rho_n}\right)+TO(log|T|)\end{align*}$$ As before, each summand equals the net change of $arg(s-\rho_n)$ on $[(\frac{1}{2}+\epsilon)-iT, \frac{1}{2}+\epsilon].$ Therefore, the absolute variation in the argument is less than $\pi.$ By the above estimate of $N(T+1)-N(T),$ the number of summands is less than $4logT.$ Thus $$Im\left(\sum_{|\gamma_n-T|\le 1} \int_{-T}^{0} \frac{dy}{(\frac{1}{2}+\epsilon)+iy-\rho_n}\right)+TO(log|T|)<4\pi logT $$ for large $T.$ Finally, $$\sum_{|\gamma_n-T|\le 1}Im\left(i \int_{-T}^{0} \frac{dy}{(\frac{1}{2}+\epsilon)+iy-\rho_n}\right)+TO(log|T|)=O(logT)+O(TlogT),$$ which implies that $$\frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_0^{+}} \frac{{\zeta}^\prime (s)}{\zeta(s)}ds\right)=O(logT)-O(TlogT),$$ keeping the negative signature for convenience. Therefore $$N_+(T)=\frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_1^{+}} \frac{{\zeta}^\prime (s)}{\zeta(s)}ds\right)+O(logT)-O(TlogT).$$ Using this formulation of Argument Principle, would the Riemann Hypothesis follow if it was shown that $$\frac{1}{2 \pi}Im\left(\int_\tilde {\mathcal C_1^{+}} \frac{{\zeta}^\prime (s)}{\zeta(s)}ds\right)$$ exactly cancels $O(logT)-O(TlogT)$ as $\epsilon$ tends to zero and as $T$ tends to infinity? In addition to this, is there a differential-geometric approach to the Riemann Hypothesis? Thanks in advance.","['special-functions', 'complex-analysis', 'analytic-number-theory', 'riemann-hypothesis']"
1909351,Intuition for the epsilon-delta definition of continuity,"This is my first question so I hope this sort of thing is okay to ask. I'm working my way through Rudin's Principles of Mathematical Analysis, and I'm up to chapter 4, which is on continuity in the context of functions between metric spaces. It introduces what I understand to be the standard epsilon-delta definition used in calculus, but I'm struggling to gain an intuitive understanding of what it means. I came up with what I think is an English version of the gist of it: A function f is continuous at some point p in its domain iff
sufficiently small deviations from p result in arbitrarily small
variations in f(p). Does this show the general idea of continuity? If not, how should it be changed to fix it? Thanks in advance for any answers :)","['intuition', 'real-analysis', 'continuity', 'epsilon-delta', 'definition']"
1909374,Radius of other circle=?,"Let $S$ be a circle with centre $O$. A chord $AB$, not a diameter, divides $S$ into two regions $R_1$ and $R_2$ such that $O$ belongs to $R_2$. Let $S_1$ be a circle with centre in $R_1$, touching $AB$ at $X$ and $S$ internally. Let $S_2$ be a circle with centre in $R_2$, touching $AB$ at $Y$, the circle $S$ internally and passing through the centre of $S$. The point $X$ lies on the diameter passing through the centre of $S_2$ and $\angle YXO=30^\circ$. If the radius of $S_2$ is 100 then what is the radius of $S_1$? ( Image of problem text ) I have tried this for over an hour now but I can't get the right answer, which is 60. After some construction and taking the sine of given angle I got $XY=100\sqrt3$ but radius of circle is still out of reach.","['circles', 'geometry']"
1909385,Relationship between the cardinality of a group and the cardinality of the collection of subgroups,"For a group G let F(G) denote the collection of all subgroups of G.Which of the following situation can occur? G is finite but F(G) is infinite. G is infinite but F(G) is finite. G is countable but F(G) is uncountable. G is uncountable but F(G) is countable. Attempt. If G is finite then P(G) is finite hence (1) is not possible.
Let G=I(the set of integers) be a group under addition then Consider
S= $\{$ Group of integers modulo n for n $\epsilon N$ } $\subset F(G)$ hence infinite therefore (2) is incorrect.(4) is also incorrect Consider R(the set of real numbers) under addition then
Let S= $\{ma|a\epsilon R$ -{set of irrational numbers $m\epsilon I$ } $\}$ $\subset F(G)$ where S is uncountable therefore F(G) is uncountable hence (3) is the only left choice. Why (3) is possible?",['group-theory']
1909386,Can there be an injective function whose derivative is equivalent to its inverse function?,"Let's say $f:D\to R$ is an injective function on some domain where it is also differentiable. For a real function, i.e. $D\subset\mathbb R, R\subset\mathbb R$, is it possible that $f'(x)\equiv f^{-1}(x)$? Intuitively speaking, I suspect that this is not possible , but I can't provide a reasonable proof since I know very little nothing about functional analysis. Can anyone provide a (counter)example or prove that such function does not exist?","['real-analysis', 'inverse-function', 'functions', 'functional-equations']"
1909396,Separability of the space of self-adjoint trace class operators over a separable Hilbert space,"My interest is to know whether the assertion the space of self-adjoint trace class operators  over a separable Hilbert space  is separable with respect to the trace norm is correct . The above assertion is claimed (without proof) to be true (and used) in a recent paper: arXiv:quant-ph/0610122 - page 12. However, so far, I have neither succeeded in finding a formal proof of the above property nor relevant references. 
I would be grateful for your help in this respect. (This would help me in clarfying strong measurability - integrability aspects related to some specific problems in the  space of self-adjoint trace class operators  over a separable Hilbert space). Thank you","['functional-analysis', 'c-star-algebras', 'banach-algebras']"
1909432,"How do I get the $f(t_{n+1}, y_{n+1})$ needed to use the implicit Euler method?","I have to solve a system of 1st order ODEs which are implicit. I know the formula for Explicit or forward Euler method is: $$y_{n+1}= y_n + hf(t_n, y_n),$$ whereas the formula for implicit or backward Euler method is $$y_{n+1}= y_n + hf(t_{n+1}, y_{n+1}).$$ In order to use the implicit Euler method, how can i get the value of $f(t_{n+1}, y_{n+1})$ ? Can I use the forward Euler method to get the value $y_{n+1}$ then substitute in backward Euler formula?","['numerical-methods', 'ordinary-differential-equations']"
1909436,Find all subsets not included in some subsets of a set.,"Let $\mathcal{S}^*= \{S_1, ..., S_n\}$ denote a set of subsets of a set $S$ (we have $S_i \subseteq S$). To find all the subsets $\mathcal{C}^*= \{C_1, ..., C_m\}$ (we have $C_i \subseteq S$) such that every $C_i$ is included in every subset $S_i$ contained in $\mathcal{S}^*$, I take the intersection of these subsets: $$I = \bigcap_{S_i \in \mathcal{S}^*} S_i$$ and then the set of subsets I am looking for  is the power set of this intersection: $\mathcal{C}^* = 2^I$. My question is the `opposite': How to find all the subsets $\{C_1, ..., C_m\}$ such that no subset $S_i$ includes a $C_j$?  I am looking for a formula as simple as the intersection one. Is that possible?",['elementary-set-theory']
1909443,Locally Path Connected Definition,"Why are the following two statements equivalent for any topological space $X$? 1) $X$ is locally path connected (meaning, it has a basis of path connected sets). 2)  Every point of $X$ has a path connected neighborhood. Is it simply that a path connected neighborhood is an open set in the subspace topology?","['general-topology', 'connectedness']"
1909467,Inequalities can be turned into equations - semi-algebraic varieties turned into $\mathbb{R}$-schemes?,"Suppose that a semi-algebraic set in $X \subset \mathbb{R}^n$ is defined by some polynomial equalities and inequalities, such as $p(x) \geq q(x)$. We can reduce these to inequalities of the form $h(x) \geq 0$, and then we can think of this as the statement that $h(x) = t^2$, where $t$ is now a new variable. Hence, we get a scheme over $\mathbb{R}$, whose real points naturally correspond to X (by forgetting the $t$-coordinates). Denote by $X^s$ this scheme. My question: To what extent is the map $X \to X^s$ an embedding of categories? (A morphism between semi-algebraic sets is something whose graph is algebraic? I'm not really sure what it should be.)","['schemes', 'real-algebraic-geometry', 'algebraic-geometry']"
1909475,If $f$ and $g$ are branches of $z^a$ and $z^b$ respectively show that $fg$ is a branch of $z^{a+b}$,"Suppose $f: G\rightarrow \mathbb{C}$ is a branch of $z^a$. Then $f(z) = e^{ah_1(z)}$ for all $z\in G$. Likewise if $g:G\rightarrow \mathbb{C}$ is a branch of $z^b$ then $g(z) = e^{bh_2(z)}$ for all $z\in G$. Here $h_1$ and $h_2$ are branches of the logarithm on $G$, and hence they differ by $2\pi k i$ with $k\in \mathbb{Z}$. However then $fg(z) = f(z)g(z) = e^{ah_1}\cdot e^{b(h_1+2\pi k i)}= e^{(a+b)h_1+2\pi k b i}$, which is not a branch of $z^{a+b}$. Question: Should I be using the same branch of $\log$ when defining the branches of $z^a$ and $z^b$. That is, should I write $g(z) = e^{bh_1(z)}$, beacause then everything works out. Also, why should I be choosing the same $\log$. Thanks.",['complex-analysis']
1909476,Attempt to prove that separately convexity implies locally Lipschitz,"I want to prove this fact: I consider a function $g:\mathbb{R}^m \rightarrow \mathbb{R}$ separatelly convex, i.e. convex in each variable. Then $g\in {\rm Lip}_{\rm loc}(\mathbb{R}^m)$ . My attempt: I make this preliminar observation. I consider $k\in\{0,...,m \}$ and let $\xi^0:=z$ and $\xi^k:=(w_1,...,w_k,z_{k+1},...,z_m)$ , with $z,w\in \mathbb{R}^m$ . I have that $$|g(z)-g(w)|=|g(\xi^0)-g(\xi^m)|\leq \sum_{i=0}^{m-1}|g(\xi^{i+1})-g(\xi^i)|$$ I observe that $\xi^{i+1}-\xi^i=(0,\dots,o,w_{i+1}-z_{i+1}, \dots, 0)$ . Now let be $R>0$ . I consider $w,z\in \mathbb{R}^m$ such that $|\xi^{i+1}-\xi^i|=|w_{i+1}-z_{i+1}|\leq R$ for every $i\in \{0,\dots, m-1\}$ . Let be $g_{i+1} :(0,2R) \rightarrow \mathbb{R}$ defined as follows: $$g_{i+1}(t)=g(w_1,\dots, w_i,t,z_{i+2},\dots, z_m).$$ I observe that $g_{i+1}(w_{i+1})=g(\xi^{i+1})$ and $g_{i+1}(z_{i+1})=g(\xi^i)$ . Now, using the convexity of $g_{i+1}$ in $(0,2R)$ , I obtain: $$\dfrac{g_{i+1}(w_{i+1})-g_{i+1}(z_{i+1})}{w_{i+1}-z_{i+1}}\leq \dfrac{g_{i+1}(2R)-g_{i+1}(z_{i+1})}{2R-z_{i+1}}\leq \dfrac{{\rm osc}(g_{i+1}, (0,2R))}{R}:=c_i(R),$$ where ${\rm osc}(f,S)={\rm sup}\{|f(t)-f(s)|\ {\rm with}\: s,t\in S\}$ . From this follows that $|g(z)-g(w)|\leq(\sum_{i=0}^{m-1}c_i(R) )|z-w|$ . I call $c(R)=\sum_{i=0}^{m-1}c_i(R)$ and I have finished. My problem: Is my proof correct? It seems to me that in this way I have proved something more than the locally lipschitz condition, since $R$ is generic. Is this the Lipschitz condition on every compact set? Edit I have proved that $\forall R$ if $z,w\in\mathbb{R}^m$ are such that $|z_i-w_i|\leq R$ $\forall i\in\{1,...,m\}$ then $|g(z)-g(w)|\leq c(R)|z-w|$ .
So I have proved the Lipschitz condition on every m-cube and so in every compact set. Is it right? Thanks a lot for the help!","['real-analysis', 'lipschitz-functions', 'convex-analysis', 'analysis']"
1909500,A hot metal block in the cool sea,"(I just want to double check that my answer is correct.) A metal block at the boiling temperature of water is submerged in the sea where the water temperature is $20$°C. If after $15$ minutes the temperature of the block falls to $68$°C, how long will its temperature stay at between $60.5$ and $59.5$°C? Using the formula
$$T=T_a+(T_0-T_a)e^{-kt}$$
where $T_a$ is the ambient temperature, $T_0$ is the initial temperature of the object and $T$ is its temperature at a given time $t$, I got $20$ minutes. Is that correct?",['ordinary-differential-equations']
1909523,Riemann Integral as a limit of sum,"One of the standard definitions of Riemann Integral is as follows: Let $f$ be bounded on $[a, b]$. For any partition $P = \{x_{0}, x_{1}, x_{2}, \ldots, x_{n}\}$ of $[a, b]$ and any choice of points $t_{k} \in [x_{k - 1}, x_{k}]$ the sum $$S(P, f) = \sum_{k = 1}^{n}f(t_{k})(x_{k} - x_{k - 1})$$ is called a Riemann sum for $f$ over $P$ and tags $t_{k}$. The norm of $P$ denoted by $||P||$ is defined as $||P|| = \max_{k = 1}^{n}(x_{k} - x_{k - 1})$. A number $I$ is said to be Riemann integral of $f$ over $[a, b]$ if for any arbitrary $\epsilon > 0$ there exists a $\delta > 0$ such that $$|S(P, f) - I| < \epsilon$$ for all Riemann sums $f$ over any partition $P$ with $||P|| < \delta$. When such a number $I$ exists we say that $f$ is Riemann integrable over $[a, b]$ and we write $$I = \int_{a}^{b}f(x)\,dx$$ Note that if $f$ is Riemann integrable over $[a, b]$ then we can choose partition $P$ with points $x_{k} = a + k(b - a)/n$ and $t_{k} = x_{k}$ or $t_{k} = x_{k - 1}$. Thus if $I = \int_{a}^{b}f(x)\,dx$ exists then by definition we have $$\int_{a}^{b}f(x)\,dx = \lim_{n \to \infty}\frac{b-a}{n}\sum_{k = 1}^{n}f\left(a + \frac{k(b - a)}{n}\right)\tag{1}$$ My question is: does the converse hold? If the limit in $(1)$ exists for a certain function $f$ bounded on $[a, b]$ does it mean that $f$ is Riemann integrable over $[a, b]$ according to the definition of Riemann integrability mentioned above? The reason I ask this question is that many introductory calculus textbooks try to be smart and sort of put $(1)$ as the definition of $\int_{a}^{b}f(x)\,dx$ and hope that they have given a much better definition of integral compared to $F(b) - F(a)$ where $F$ is anti-derivative of $f$. Update : As can be seen from the answer by user mrf, the converse does not hold and the equation $(1)$ can not be used as a definition of Riemann integral for a bounded. Now I update my question with a pedagogic bent. Why do many introductory calculus textbook try to define Riemann integral as a limit of sum as mentioned in $(1)$? Does it add any value in terms of pedagogy to teach something which is totally wrong?","['real-analysis', 'soft-question', 'calculus']"
1909538,Why does this algorithm give the Beta distribution in the limit (considering length of intervals between two random variables)?,"Consider the following algorithm: In the $n$th iteration, take two random variables uniform on $[0,1]$. Define the smaller as $X_1^{(n)},$ the bigger as $X_2^{(n)}$ and the interval between them as $I_n=\left[X_1^{(n)},X_2^{(n)}\right]$. Define $D_n(x)=c_n\sum_{k=1}^n \mathbf{1}_{I_k}(x)$ with $D_0(x)=0$, where $\mathbf{1}_{I_k}(x)$ is the Indicator function , and where $c_n$ is a normalization constant. (See the edit at the bottom if this is still not clear.) The question is now what $D(x)=\lim_{n\rightarrow \infty}[D_n(x)]$ is? I solved it like this (I thought of it as sums first): \begin{align}
D(x)&=c\int_0^{x}\int_{x}^1(y'-x')\;\mathrm{d}y'\mathrm{d}x' \\
&=c\int_0^{x}\left(\frac{1}{2}-x'-\frac{1}{2}x^2+xx'\right) \mathrm{d}x'\\
&= cx(1-x)\\
&=6x(1-x),
\end{align}
where $c$ is a normalization constant, and $x'$ and $y'$ represents $X_1$ and $X_2$, respectively. What I did (speaking in terms of the discrete case) was to calculate the sum of the lengths of all intervals that included $x$. These intervals are $[x',x],[x',x+dy'],\cdots,[x',1-dy'],[x',1]$ for all $x'\in[0,x]$, hence the limits on the integrals. But lo and behold, this is the Beta distribution with $\alpha=\beta=2$! Q$_1$ : Why is the Beta distribution the answer here? I'm looking for an informal connection here (something along the lines of ""well, you can view $D(x)$ as the probability of ___, the solution of which is well-known to be given by the Beta distribution"" or whatever the connection might be). I tried reading the applications section of the wiki, but couldn't find anything that might apply and generalize the problem described above (most of the section went over my head, so please forgive me if there is an obvious connection). Q$_2$ : I'm sorry if this sounds pretentious, but has this angle (considering intervals between two random variables) been used to arrive at this Beta distribution before? It probably has, but I'd be curious to see the context. Thanks. Edit (an example of the algorithm): At first, $D_0(x)=0$. Let's say that $I_1=[0.1,0.4]$. Then $$D_1(x)=c_1\cases{1 \quad 0.1\leq x \leq 0.4 \\ 0 \quad \text{otherwise}}$$ with $c_1=\frac{10}{3}$. Now let's imagine that $I_2=[0,0.2]$. Then we would have $$D_2(x)=c_2\cases{1 \quad 0.1< x \\ 2 \quad 0.1\leq x < 0.2 \\1 \quad 0.2\leq x \leq 0.4  \\ 0 \quad \text{otherwise}}$$ with $c_2=\frac{7}{10}$.","['probability-theory', 'probability-distributions', 'uniform-distribution', 'order-statistics', 'random-variables']"
1909574,Integer Partition (Restricted number of parts),"I read an article about integer partition which is posted on Wikipedia, and I found out that the generating function of ""partitions of n into exactly k parts"" can be represented as: $$\sum_{n\ge0} p_k(n)x^n=x^k\prod\limits_{i=1}^k \dfrac{1}{1-x^i}$$ 
I tried to understand why generating function can be represented like that but I couldn't. So please help me understand it.","['combinatorics', 'integers', 'integer-partitions']"
1909606,"Solving the Definite Integral $\int_0^{\infty} \frac{1}{t^{\frac{3}{2}}} e^{-\frac{a}{t}} \, \mathrm{erf}(\sqrt{t})\, \mathrm{d}t$","I would like to solve the following integral $$\int_0^{\infty} \frac{1}{t^{\frac{3}{2}}} e^{-\frac{a}{t}} \, \mathrm{erf}(\sqrt{t})\, \mathrm{d}t$$ with Re$(a)>0$ and erf the error function.
Is it possible to given an closed form solution for this integral? Thank you. Edit: Maybe this helps
$$\mathrm{L}(\mathrm{erf}(\sqrt{t}),s)=\frac{1}{s \, \sqrt{1+s}}$$
$$\mathrm{L}^{-1}(t^{-\frac{3}{2}} e^{-\frac{a}{t}})=\frac{1}{\sqrt{\pi \, a}}\mathrm{sin}(2 \sqrt{a \, s})$$ with L the Laplace transform. Therefore it should be
$$\int_0^{\infty} \frac{1}{t^{\frac{3}{2}}} e^{-\frac{a}{t}} \, \mathrm{erf}(\sqrt{t})\, \mathrm{d}t = \int_0^{\infty} \frac{1}{s \, \sqrt{1+s} \, \sqrt{\pi \, a}} \, \mathrm{sin}(2 \sqrt{a \, s}) \mathrm{d}s$$","['integration', 'definite-integrals', 'error-function']"
1909611,For what conditions on sets $A$ and $B$ the statement $A - B = B - A$ holds? [duplicate],"This question already has answers here : When is $A- B = B- A$? (4 answers) Closed 7 years ago . The obvious response is $A = B$. But I came up with another response. I can't figure out what's my bias. Lets say $S = A - B$ $T = B - A$ Proving $S=T$ means proving $S \subseteq T$ and $T \subseteq S$ Let's start with $S \subseteq T$ For any $x \in S$ : $x \in A$ $x \notin B$ if $S \subseteq T$, $x \in T$ and : $x \in B$ $x \notin A$ There is no $x$ giving satisfaction, so $A$ and $B$ are empty. I prove $T \subseteq S$ by symmetry My solution is : $A = B = \emptyset$ What's wrong ?",['elementary-set-theory']
1909645,Empty Set $\{\}$ is the Only Basis of the Zero Vector Space $\{0\}$,"Question Suppose we want to find a basis for the vector space $\{0\}$ . I know that the answer is that the only basis is the empty set. Is this answer a definition itself or it is a result of the definitions for linearly independent/dependent sets and Spanning/Generating sets ? If it is a result then would you mind mentioning the definitions of bold items from which this answer can be deduced. Useful Links I found the links Link 1 , Link 2 , Link 3 , Link 4 , Link 5 , and Link 6 useful for answering this question. It needs some elementary background form mathematical logic. You can learn it by spending a few hours on this Wikipedia page .","['linear-algebra', 'vector-spaces']"
1909697,"Does $P({X_1}^->a_1,...,{X_n}^->a_n)\leq P({X_1}^+>a_1,...,{X_n}^+>a_n)\forall a$ imply $E[h({X_1}^-,...,{X_n}^-)]\leq E[h({X_1}^+,...,{X_n}^+)]$?","Let ${X_1}^-,...,{X_n}^-,{X_1}^+,...,{X_n}^+$ be real random variables with the following stochastic dominance property: $P({X_1}^->a_1,...,{X_n}^->a_n)\leq P({X_1}^+>a_1,...,{X_n}^+>a_n)$ for all $a \in \mathbb R^n$. Now let $h:\mathbb R^n \rightarrow \mathbb R^+$ be strictly increasing in every component. Does then $E[h({X_1}^-,...,{X_n}^-)]\leq E[h({X_1}^+,...,{X_n}^+)]$ hold? Ideas: Using the definition of expectation brought me to a sub-problem that I asked here: In an inequality of integrals, can I multiply both integrands with the same non-negative, monotonous function? However, maybe that was already a step in the wrong direction, thus here the original problem. Thanks in advance!","['probability-theory', 'probability', 'probability-distributions']"
1909702,Can an immersion from $D^n$ to $S^n$ be surjective?,"Suppose there is an immersion $f$ from the closed disc $D^n$ to the sphere $\mathbb S^n$ (with the standard differential structures), where $n\ge 2$. Then can this map be surjective? I kind of hope it can't be, but have no idea....","['general-topology', 'differential-geometry', 'differential-topology']"
1909744,"Does there exist a positive irrational number $\alpha $, such that for any positive integer $n$ the number $\lfloor n\alpha \rfloor$ is not a prime?","Does there exist a positive irrational number $\alpha $, such that for any positive integer $n$ the number $\lfloor n\alpha \rfloor$ is not a prime? My try if $\alpha=\sqrt{17}$ then $\lfloor n\alpha \rfloor=4n$",['number-theory']
1909766,Show $A^T$ has an eigenvector with all components rational [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Matrix $A$ is a $5 \times 5$ matrix with rational entries such that $(1, \sqrt{2}, \sqrt{3}, \sqrt{4}, \sqrt{5})^T$ is an eigenvector of A. Show that $A^T$ has eigenvector with all components rational. My idea is: let the eigenvalue associated with the above eigenvector be $λ$. Since all matrix entries are rational numbers so an irrational number will be linearly independent. Use this $2(a_{11} + 2a_{14}) = a_{41} + 2a_{44}$ $a_{21}+2a_{24} = 0$ $a_{31}+2a_{34} = 0$ $a_{51}+2a_{54} = 0$ but I can't find transposed matrix's eigenvector.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1909770,Representing signed kernels as linear bounded operators,"Let $(X, \mathcal{A})$ be a measurable space and
denote by $B$ the Banach space of bounded $\mathcal{A}$-measurable functions $f : X \to \mathbb{R}$ with the supremum norm $\lVert f \rVert_\infty = \sup_{x \in X} |f(x)|$ and by $ca$ the Banach space of signed measures $\mu : \mathcal{A} \to \mathbb{R}$ of bounded variation with the total variation norm $\lVert \mu \rVert_{TV} = \sup_{A \in \mathcal{A}} |\mu|(A)$.
A signed kernel on $(X, \mathcal{A})$ is a map $K : X \times \mathcal{A} \to \mathbb{R}$ with the properties (i) $K(\cdot, A) \in B$ for all $A \in \mathcal{A}$ and (ii) $K(x, \cdot) \in ca$ for all $x \in X$. The space $\mathcal{K}$ of signed kernels on $(S, \mathcal{A})$ is a vector space as a linear subspace of $\mathbb{R}^{X \times \mathcal{A}}$. Define a multiplication operation on $\mathcal{K}$ by $(K_1 K_2) (x, B) := \int K_1(x, du) K_2(u, B)$
where the integral of a bounded measurable function $g$ w.r.t. to a finite signed measure of bounded variation $\nu$ with Jordan decomposition $\nu = \nu^+ + \nu^-$ is defined as usual by $\int d\nu \, g := \int g \, d\nu := \int g \, d\nu^+ + \int g\, d\nu^-$. Then $\mathcal{K}$ is an algebra (by linearity of integral and Fubini for signed measures). Every $K \in \mathcal{K}$ induces a bounded linear operator $F_K \in L(B)$ by $f \mapsto (F_K f)(x) := \int K(x, du) f(u)$ and a bounded linear operator $M_K \in L(ca)$ by $\mu \mapsto (\mu M_K)(B) := \int \mu(du) K(u, B)$. Moreover, when considering $L(B)$ and $L(ca)$ as (Banach) algebras then these maps $F$ and $M$ are algebra homomorphisms. Questions: (1) Are these maps injective? In other words, can we consider $\mathcal{K}$ as a subspace of operators in $L(B)$ or $L(ca)$? If not, under which properties on the measurable space $(S, \mathcal{A})$ are they injective? Or maybe I should better concentrate on certain topological spaces $S$ with the Borel $\sigma$-algebra and consider instead of $B$ and $ca$ the spaces of continuous bounded functions $C_b$ and regular measures $rca$ and call for some Riesz representation theorem? (2) In case $F$ and $M$ are injective, then we can equip $\mathcal{K}$ with two norms namely the operator norm of $L(B)$ and that of $L(ca)$. Are these norms equivalent? (3) Can we consider these representations of $\mathcal{K}$ as linear bounded operators on $B$ resp. on $ca$ in some sense as dual or adjoint to each other? In general, the dual $B'$ is not $ca$ and $ca'$ is not $B$. So, how can we bring in the adjoint maps $L(B) \to L(B')$ and $L(ca) \to L(ca')$ into play?","['functional-analysis', 'measure-theory']"
1909833,"""tangent"" (the trig ratio) vs ""tangent"" (the geometric concept)","Do the terms ""tangent"" (the trigonometric ratio), which is defined as ""opposite-side / adjacent-side"", and ""tangent"" (of the curve), which is a line that touches a curve at a point, have the SAME meaning? If yes, how? Also: Is this same for ""secant"" and ""cosecant""?","['trigonometry', 'calculus', 'analytic-geometry', 'terminology', 'geometry']"
1909877,How to find tangents to curves at points with undefined derivatives,"I will explain my question with the help of an example. We need to find the tangent at origin to the curve $$x^3 + y^3 =3axy$$ The derivative at origin is $0/0$ or indeterminate, found after implicit differentiation. But the tangents exist (via Wolfram Alpha) and they are $x=y=0$. If the derivative at the origin does not exist, how are we getting the tangents? At least $y=0$ has a determinate slope (0). Also how should I find tangents to more general curves at points where the derivative doesn't exist? Is there a general method using differentiation? My professor told me that as $x,y\to0$, $x^3 + y^3\ll3axy$ and hence the zeroes of the function will be approximately where the zeroes of $3axy$ are. Now I couldn't understand the next line that he said: Near the origin the curve will look like the solutions to $3axy$. What does he mean by this? Of course the solutions to $3axy=0$ are $x=0$ and $y=0$, which are the tangents, but the curve isn't like that. Can anyone please explain me this? And is there a general method to find tangents at points where the derivative doesn't exist?","['derivatives', 'slope', 'tangent-line']"
1909945,Isotrivial but non-trivial family of elliptic curves,"Consider the family $f\colon \mathfrak X \to \mathbb C^*$ of elliptic curves over $\mathbb C^*$ with coordinate $t$ given by the affine equation $y^2 = x^3 - t$.
Then all the fibres have $j$-invariant $j = 0$, hence they are all isomorphic. In fact, it is easy to see that the family trivializes after the finite étale base change $s \mapsto s^6$. On the other hand, it is claimed (e.g. in Exercise 1.6 of ""Moduli of Curves"" by Harris and Morrison) that the family $f$ is not trivial. How to show this? One idea would be to show that the family does not have an algebraic/holomorphic section. However I don't know how to do this. Or one could show that $R^1 f_* \mathbb Z_{\mathfrak X}$ has non-trivial monodromy using the Picard-Lefschetz formula.
But this requires doing a semistable reduction first, which boils down to taking the 6-to-1 cover mentioned above and then the monodromy will be trivial because the family is trivial.","['elliptic-curves', 'algebraic-geometry']"
1909965,"A continuous function, with discontinuous derivative, but the limit must exist.","I was reading this question . The simplest examples of continuous functions, with discontinuous derivatives in some point, are usually of the form: $$
f(x) = \begin{cases} 
  x^2 \sin(1/x) &\mbox{if } x \neq 0 \\
0 & \mbox{if } x=0. 
\end{cases}
$$
The derivative of $f$ is 
$$
f'(x) = \begin{cases} 
  2 x \sin \left(\frac{1}{x}\right)-\cos \left(\frac{1}{x}\right)&\mbox{if } x \neq 0 \\
0 & \mbox{if } x=0,
\end{cases}
$$ The derivative is discontinuous because the limit of $\cos \left(\frac{1}{x}\right)$ does not exist for $x\rightarrow 0$. Is there an example where the derivative is still discontinuous but with existing limit? Thanks","['derivatives', 'real-analysis', 'calculus', 'limits']"
1909968,"Standard Error, why divide by square root of 2?","I am currently reading the book Options, Futures and Other Derivatives from John C. Hull. In the Chapter of Introducing the Balck-Scholes Model, it says: The standard error of this estimate can be shown to be approximately
  $\hat{\sigma}/\sqrt{2n}$, where $\hat{\sigma}$ is the estimated sample
  standard deviation, $n$ is the number of samples. Does anyone have any idea why is $\sqrt{2n}$ and not $\sqrt{n}$? P.S. I have sent a Email to Prof. John C. Hull, he says: ""It is tied in with the properties of the Chi squared distribution"", anyone has a clue?",['statistics']
1909973,Proving $|z-1|<|z-i|$ is an open set,"Consider this set: $$|z-1|<|z-i|$$ Suppose $z=x+iy$, then: $$\sqrt{(x-1)^2+y^2}<\sqrt{x^2+(y-1)^2}\implies$$ $$(x-1)^2+y^2<x^2+(y-1)^2\implies$$
$$x^2-2x+1+y^2<x^2+y^2-2y+1\implies$$ $$-2x<-2y\implies y<x$$ First of all, am I right? Now, in order to prove that the set $O = \{(x,y); y<x\}$ is open, I need to pick a point $z\in O$, then construct an open ball of radius $r$ and prove it's entirely contained in $O$. I think that $r$ in this case must be the distance from this point $z$ to the line $y=x$. I have, then, to pick a point $w\in B(z, r)$ and prove that $w\in O$. How can I do that?","['multivariable-calculus', 'complex-analysis', 'general-topology', 'calculus']"
1909984,Condition For Integer Roots,"Find the number of values of a such that the eauation$$x^2+ax+6a$$ has integer roots. $$x=\frac{-a\pm\sqrt{a^2-24a}}2$$
let$$a^2-24a=m^2$$where m$\in\Bbb{Z}$ $$(a-12)^2=m^2+12^2$$
$$a=12\pm\sqrt{m^2+144}$$
now by putting different values of $m$ $(0,5,35)$ we get the number of values of $a$ as as 6. Is there any other method where I don't have to check the values of $m$ ?","['algebra-precalculus', 'quadratics']"
1909995,"Prove that $a_{n}=0$ for all $n$, if $\sum a_{kn}=0$ for all $k\geq 1$",Let $\sum a_{n}$ be an absolutely convergent series such that $$\sum a_{kn}=0$$ for all $k\geq 1$.   Help me prove that $a_{n}=0$ for all $n$. Thank you!,['sequences-and-series']
1910049,On the definition of a meromorphic differential on a Riemann surface,"In the book ""Complex Algebraic Curves"", Frances Kirwan gives the following definition of a meromorphic differential on a Riemann surface. Definition . Let $\{\phi_\alpha:U_\alpha\rightarrow V_\alpha: \alpha \in A\}$ be a holomorphic atlas on a Riemann surface $S$. Then a meromorphic differential $\eta$ on $S$ is given by a collection $$\{\eta_\alpha: V_\alpha \rightarrow \mathbb{C}\cup\{\infty\}: \alpha \in A\}$$ of meromorphic functions on the open subsets $V_\alpha$ of $\mathbb{C}$ such that if $\alpha,\beta \in A$ and $u\in U_\alpha\cap U_\beta$ then $$\eta_\alpha(\phi_\alpha(u))=\eta_\beta(\phi_\beta(u))(\phi_\beta \circ \phi_\alpha^{-1})'(\phi_\alpha(u)).$$ For two meromorphic functions $f$ and $g$ on $S$, the differential $fdg$ on $S$ is defined by $fdg=\eta$, where $\eta_\alpha=(f\circ \phi_\alpha^{-1})(g\circ\phi_\alpha^{-1})'$. Further, the following remark is given: If $\eta$ and $\zeta$ are meromorphic differentials according to this definition and $\zeta$ is not identically zero on any connected component of $S$ then the ratios $\eta_\alpha/\zeta_\alpha$ define meromorphic functions on the open subsets of $V_\alpha$ of $\mathbb{C}$ satisfying $$\frac{\eta_\alpha(\phi_\alpha(u))}{\zeta_\alpha(\phi_\alpha(u))}=\frac{\eta_\beta(\phi_\beta(u))}{\zeta_\beta(\phi_\beta(u))}$$ for all $u\in U_\alpha$; or equivalently $\eta=f\zeta$. Therefore to show that every meromorphic differential $\eta$ in the sense of definition 6.6 is a meromorphic differential of the form $fdg$ it is enough to show that there is at least one nonconstant meromorphic function $g$ on every Riemann suraface Here are my questions: Why the differential $fdg$ is well-defined, i.e., why $(f\circ \phi_\alpha^{-1})(g\circ\phi_\alpha^{-1})'(\phi_\alpha(u))=(f\circ \phi_\beta^{-1})(g\circ\phi_\beta^{-1})'(\phi_\beta(u))(\phi_\beta \circ \phi_\alpha^{-1})'(\phi_\alpha(u))$ for $u\in U_\alpha\cap U_\beta$ and $\alpha,\beta \in A$? Why the equality $\frac{\eta_\alpha(\phi_\alpha(u))}{\zeta_\alpha(\phi_\alpha(u))}=\frac{\eta_\beta(\phi_\beta(u))}{\zeta_\beta(\phi_\beta(u))}$ is the same as $\eta=f\zeta$, and what is $f$ in the end? If it is some function, on which the notation hints, my mind still refuses to understand how a set (formally, $\eta$ is a set, isn't it?) can be equal to another set times a function. How the existence of a meromorphic functioon $g$ on every Riemann surface implies that every meromorphic differential on $S$ in the sence of the given definition is of the form $fdg$? Finally, an ""ideological question"": is it ideologically correct to think of meromorphic differentials on Riemann surfaces according to this definition? I like this definition because on the one hand it requires no knowledge about cotangent bundles and its sections for example, and on the other hand it is quite rigorous (unlike the definition which says that a differential is ""something that can be written as $fdz$""). And by the way, is ""differential"" the same as ""differential 1-form""?","['riemann-surfaces', 'complex-analysis', 'complex-geometry', 'algebraic-geometry']"
1910062,Counting to $P$ game - strategy?,"A while back I asked this question Counting to 21 game - strategy? on whether there was a strategy to stay in the 'counting to 21 game' described in that question with $N$ players. This question will ask a more general version of that. The game is as follows: $N$ players. Each can say at least one number and at most $m$ (following the sequence $1,2,3,...$) in turn (i.e. player 1, then player 2,..., then player N, then back to player 1). The player with no alternative but to say the number $P$ is eliminated from the game. Every player is guaranteed to get to say at least one number (i.e. $P\gt m(N-1)$). Given that I can chose if I go in the $l$th position. For what combinations (if any exist) of $N$, $P$, $m$ and $l$ can I always not be eliminated, regardless of how the other players play?","['combinatorics', 'combinatorial-game-theory']"
1910091,Find $f^{(100)}(x)$ where $f(x)=\frac{1}{4x^2-1}$,"Find $f^{(100)}(x)$ where $f(x)=\frac{1}{4x^2-1}$. I found first,second and third derivative: $$f'(x)=\frac{-8x}{(4x^2-1)^2}$$ $$f''(x)=\frac{96x^2+8}{(4x^2-1)^3} $$ $$f'''(x)=\frac{-384x(4x^2+1)}{(4x^2-1)^4}$$ I can't seem to find any rule between them. Anyone has any ideas or hints?","['derivatives', 'real-analysis']"
1910140,Show that $\sum_{n=1}^{\infty}X_n<\infty$ almost surely if and only if $\sum_{n=1}^{\infty}\mathbb E[\frac{X_n}{1+X_n}]<\infty$.,"Suppose $X_1, X_2, ...$ are independent non-negative random variables. Show that $\sum_{n=1}^{\infty}X_n<\infty$ almost surely if and only if $\sum_{n=1}^{\infty}\mathbb E[\frac{X_n}{1+X_n}]<\infty$. There is a hint here but I don't know how to use: Consider the truncated variables $X'_n=\min(X_n ,1)$. My thoughts are: if the sum of expectation are finite, then the expectation should converge to zero which means $X_n$ should converge to zero almost surely and since they are independent, the sum should converges almost surely. For the other direction, maybe I should use Kolmogrov's 3-series theorem? I don't know whether this is correct. Thank you!","['probability-theory', 'probability']"
1910145,Why does the median minimize $E(|X-c|)$?,"Suppose $X$ is a real-valued random variable and let $P_X$ denote the distribution of $X$. Then
$$
E(|X-c|) = \int_\mathbb{R} |x-c| dP_X(x).
$$ The medians of $X$ are defined as any number $m \in \mathbb{R}$ such that $P(X \leq m) \geq \frac{1}{2}$ and $P(X \geq m) \geq \frac{1}{2}$. Why do the medians solve
$$
\min_{c \in \mathbb{R}} E(|X-c|) \, ?
$$","['median', 'probability-theory', 'expected-value', 'probability-distributions', 'probability']"
1910167,"Prove that if $f(t)$ satisfies $f(t)=f'(t)$, then $f(t+s)=f(t)f(s)$ for all $t,s\in R$ without using the fact that $f(t)=c\cdot e^t$.","This seems like it should be super simple but I can't figure it out.
Prove that if $f(t)$ satisfies $f(t)=f'(t)$, then $f(t+s)=f(t)f(s)$ for all $t,s$ belonging to R without using the fact that $f(t)=c\cdot e^t$.
The only hint I'm given is that I can use the fact that two functions satisfying the same ODE $x'=x$ with the same initial condition are equal.
Any ideas?",['ordinary-differential-equations']
1910179,"Convex hexagon $ABCDEF$ following equalities $AD=BC+EF, BE=AF+CD, CF=DE+AB$. Prove that $\frac{AB}{DE}=\frac{CD}{AF}=\frac{EF}{BC}$","A convex hexagon $ABCDEF$ is such that the following equalities $AD=BC+EF, BE=AF+CD, CF=DE+AB$ hold. Prove that
  $$\frac{AB}{DE}=\frac{CD}{AF}=\frac{EF}{BC}$$ I do not know how to begin to solve this problem.","['euclidean-geometry', 'polygons', 'geometry']"
1910186,Ordered binary sequences of length n with no two consecutive 0's without using recursion,"Given ordered sequences of 0's and 1's of length n. In how many of them no two 0's stand next to each other? Could you do if n=25. I know this can be solved by using recursion.
I am not familiar with solving recurrence equations. Could this be done another way?","['combinatorics', 'sequences-and-series', 'elementary-set-theory', 'discrete-mathematics']"
1910189,Combining multiple multivariate integrals into a single function,"Let $p$ be a multivariate polynomial (with property that for any $x\in[0, 1]^n$, $p(x) \in [0,1]$). If I want to find a $g$ function such that $\frac{\partial g}{\partial x_1} = p(x)$ then clearly $g=\int p(x) dx_1$. Q1: Suppose, instead I have two direction vectors $u$ and $v$, and I want $(v \cdot \nabla g(x)) = p(x)$ and $(u \cdot \nabla g(x)) = p(x)$, then what should g be? I can do this for one directional derivative, but not sure how to combine for multiple directional derivatives. Q2: Can I go one step further, where given $q:[0,1]^n \rightarrow [0, 1]^n$, define function $g$ such that $((q(x) - x)\cdot \nabla g(x))=p(x)$? Here each $q_i$ is a polynomial again.","['derivatives', 'integration', 'polynomials']"
1910243,Book recommendation for studying functional equations,"I am a student who is just starting high school and am very interested in taking part in the IMO (International Mathematical Olympiad). I am currently reading about inequalities. Having studied many of the classical inequalities, I have found that a good knowledge of functions and functional equations would be very beneficial. However, the books I have looked up seem very complicated and I have not found any book offering a friendly introduction into the subject for beginners. None of what I have looked up also relate to olympiad problems. Can anyone please recommend me a book that could help me get acquainted with the topic. Thanks.","['inequality', 'functions', 'book-recommendation', 'soft-question', 'contest-math']"
1910250,What does $f|A$ mean?,"Let $X$ be some space, $A$ a subspace of $X$, $f:X \rightarrow X$ a function. My first guess for what $f|A$ is would be that the domain of $f$ is restricted to $A$, but I can't find any confirmation that this is actually the case. The only notation that I'm aware of is $f|_A$. For reference, the actual place that this question arose in is in Hatcher's Algebraic Topology page 2: A deformation retraction of a space $X$ onto a subspace $A$ is a family of maps $f_t:X \rightarrow X$, $t \in I$, such that $f_0 = \mathbf{1}$ (the identity map), $f_1(X) = A$, and $f_t|A = \mathbf{1}$ for all $t$.","['notation', 'functions']"
1910262,trouble with proof in elementary set theory regarding powersets,"Let $X$ be an arbitrary set and $\mathcal{P}(X)$ be the power set of $X$. Prove that for every $A,B \in \mathcal{P}(X)$ we have $A\cup B \in \mathcal{P}(X)$. By the definition of the power set we know that $A,B \subseteq X$. Let's use the definition of subset: $A, B \subseteq X \iff (\forall \space x \in A, y \in B \implies x, y \in X)$ We also have per definition that $\forall A,B \subseteq X$: $A \cup B = \{ x \in X | \space x \in A \lor x \in B\}$ Let  $z \in A \cup B$. Per definition, we know that  $\space z \in A \lor z \in B$. Since we have $(\forall \space x \in A, y \in B \implies x, y \in X)$, we also know that $z \in X$. Here I'm stuck. I don't know how to continue with this proof. Intuitively the result is logical but I don't know how to make something useful out of $z$.","['elementary-set-theory', 'proof-verification']"
1910270,Showing a module is finitely generated and projective,"Let $R$ be a commutative ring and $V$ be an $R$-module such that $V\otimes_{R}V \cong R$ as $R$-modules. I want to show that $V$ is a finitely generated and projective $R$-module. What I've considered: Clearly $V\otimes_{R}V$ is finitely generated and projective, since $R$ is immediately from definitions. For projectivity, given a short exact sequence of $R$-modules: $$M \xrightarrow{f} V \rightarrow 0$$ we can apply the right exact functor $\_\otimes_{R} V$, yielding: $$ M\otimes_{R} V\xrightarrow{f\otimes\text{id}} V \otimes_{R} V \rightarrow 0.$$ As $ V \otimes_{R} V$ is projective, this splits, so, morally, I just want to  ""restrict the splitting map to the pure tensors of the form $v \otimes 1$"" and conclude. The only thing I've thought of that could potentially make this precise is to show that the splitting map must be of the form $s=s_{1}\otimes s_{2}$. For being finitely generated, it seems ""intuitively clear"" to me that if $V \otimes_{R} V$ is finitely generated, then so must be $V$, but I'm having trouble showing this carefully. In particular, I feel good about the converse statement, as discussed in Tensor product of two finitely generated modules","['tensor-products', 'modules', 'abstract-algebra', 'projective-module', 'commutative-algebra']"
1910277,"Given 6 pairs of twins, how many ways to chose 3 groups of 4 with no twins in the same group?","A class contains 12 students in 6 pairs of twins. In how many ways can we pick 3 groups of 4 students, without any of them containing a pair of twins? I solved this problem for 2 groups of 6 easily with the multiplication principle. Every group must contain one person from each pair, so we get $2^6$ different groups. Any hints on how to solve it for 3 groups of 4?","['combinatorics', 'discrete-mathematics']"
1910324,Why must a radical be isolated before squaring both sides?,"In the following equation: $$\sqrt{2x + 1} + 1 = x$$ You are supposed to isolate the radical: $$\sqrt{2x + 1} = x - 1$$ And then proceed by squaring both sides. If you start by solving the equation this way, you will eventually complete the square and get an answer of: $$4$$ However, why must the radical be isolated before squaring both sides? Why can't you do, for example... $$(\sqrt{2x + 1} + 1)^2 = x^2$$ I know this would lead you down the wrong path, but I don't know why . It doesn't make sense to me because I can (once I isolate the radical) square both sides when one side $$x-1$$ involves addition/subtraction. Is there some special property of radicals that makes them have to be completely alone before they can be squared? Thank you.","['algebra-precalculus', 'radicals']"
1910342,Indeterminate Limit using Second Fundamental Theorem of Calculus,"I am trying to find $$\lim_{x\to 0}\frac{\int_0^x(x-t)\sin(t^2) \, dt}{\ln(1+x^4)}$$It seems that I am meant to use the 2nd Fundamental Theorem of Calculus to solve this, but I have never used it on an integral that has $x$ in it. Do I approach it any differently? Or am I on the wrong track entirely?","['indeterminate-forms', 'limits']"
1910360,Discriminant of splitting field,"Let K number field, $O_K$ be its integer domain. We all know $O_K$ is a free $\mathbb{Z}$-module. If L is a finite (or galois) extension of K, whether $O_L$ is a free $O_K$-module? In addition, let $f$ be a irreducible polynomial in $\mathbb{Q}$, α is a root of $f$, $K$ is the splitting field of $f$. $Δ(F)$ denote the discriminant of a number field $F$. Is $Δ(K)$ devides $Δ(\mathbb{Q}(α))^n$ for some integer $n$?","['number-theory', 'algebraic-number-theory']"
1910402,Show that $\sum^{6}_{i=1} a_{i}=\frac{15}{2}$ and $ \sum^{6}_{i=1} a^{2}_{i}=\frac{45}{4} \implies \prod_{i=1}^{6} a_{i} \leq \frac{5}{2}$,"Let $a_{i}$, $1 \leq i \leq 6,$ be real numbers such that $\displaystyle\hspace{1.2 in}\sum^{6}_{i=1} a_{i}=\frac{15}{2}\;\;$ and $\;\;\displaystyle\sum^{6}_{i=1} a^{2}_{i}=\frac{45}{4}$. Prove that $\hspace{.15 in}\displaystyle\prod_{i=1}^{6} a_{i} \leq \frac{5}{2} $. I was thinking if I consider the first summation and extended it, it going be pretty long which $a_{1}+a_{2}+a_{3}+a_{4}+a_{5}+a_{6}= \frac{15}{2}$ and the second one like $a^{2}_{1}+a^{2}_{2}+a^{2}_{3}+a^{2}_{4}+a^{2}_{5}+a^{2}_{6}= \frac{45}{4}$. But I do not think this is the shortest of doing that, I am wondering if someone would be able to give me a hint so I can think better than this. Thank you","['inequality', 'summation', 'calculus']"
1910424,"Trying to demonstrate a multivariable limit: $\lim\limits_{(x,y) \to (0,0)} \frac{xy}{|x|+|y|}$ [duplicate]","This question already has answers here : Wrong Wolfram|Alpha limit? $ f(x,y) = \frac {xy}{|x|+|y|} $ for $(x,y)\to(0,0)$ (6 answers) Closed 7 years ago . i'm having some trouble trying to prove the next multivariable limit: $$ \lim\limits_{(x,y) \to (0,0)} \frac{xy}{|x|+|y|} $$ I've already tried the different paths and the limit is 0, however i'm stuck trying to demonstrate it because those absolute values on the denominator, by using the theorem that our teacher taught us to do so. The theorem 1.) 2.) goes as: $$ 1.) |f(x,y) - L| < g(x,y)$$ Where L is the limit we calculated from the differents paths we got, 0 in this case, then we are supposed to calculate the $g(x,y)$ function by: $$ |f(x,y) - 0 | = |\frac{xy}{|x|+|y|} - 0 | $$ This is the part where i'm stuck cause we are supposed to calculate that $g(x,y)$ through that formula, however i'm getting stuck because i don't know how to operate with this absolute value on the denominator $||x|+|y||$ any help on this one would be highly appreciated! $$ 2.) \lim\limits_{(x.y) \to (x_o,y_o)} g(x,y) = 0$$ This one is just to evaluate the $g(x,y)$ we got from the formula above and it should be 0.","['multivariable-calculus', 'calculus', 'limits']"
1910500,Prove the set of matrices with one Jordan block is not dense in $M_n(\mathbb{C}).$,"I would like to show that the set of matrices with one Jordan block is not dense in $M_n(\mathbb{C}),$ the set of all $3$ x $3$ matrices with complex entries. I have done proofs showing that invertible matrices are dense, and diagonal matrices are dense, but I've been struggling with proofs showing that a given subset is not dense.  Another one I've had trouble with was showing the $SL(2,\mathbb{C})$ is not dense too. The only reasonable approach seems to begin with assuming that the subset is dense, and reaching a contradiction.  Intuitively, one should be able to state that $I$ is not the limit point of a sequence of Jordan blocks, but I have had trouble stating this rigorously.  Any tips/suggestions/tricks?","['general-topology', 'linear-algebra']"
1910504,$j_\infty$ notation in probability (or set) theory,"This is a problem I found in a recent ``Probability using theorems and exercises'' book written by Shiryaev, Ehrlich, and Yaskov. What I'm confused about is the notation $j_\infty$ they introduce. Here's the problem: ""Let $J_i$, where $i\in I$, be arbitrary sets. Prove that the following is always true:
$$\bigcup_{i\in I}\bigcap_{j\in J_i}A_{ij}=\bigcap_{j_\infty}\bigcup_{i\in I}A_{ij_i},$$
where the intersection is taken over all ""paths"" $j_\infty=(j_i,i\in I)$, $j_i\in J_i$."" I think there's some kind of typo or mistake in the definition of $j_\infty$, because I just can't figure out what it is. Here's a couple of examples I'm thinking about. $\textbf{Example 1.}$ Let $J_1=\{a,b\}$, $J_2=\{\alpha,\beta\}$, $A_{1a}=A_{1b}=A_{2\alpha}=\{\omega_1\}$, $A_{2\beta}=\{\omega_2\}$. Then $\bigcup_{i\in I}\bigcap_{j\in J_i}A_{ij}=\{\omega_1\}$. $\textbf{Example 2.}$ Let $J_1=\{a,b\}$, $J_2=\{\alpha,\beta\}$, $A_{1a}=\{\omega_1,\omega_2\},A_{1b}=A_{2\alpha}=\{\omega_1\}$, $A_{2\beta}=\{\omega_2\}$. Then again $\bigcup_{i\in I}\bigcap_{j\in J_i}A_{ij}=\{\omega_1\}$. All my guesses about $j_\infty$ failed one of these examples and I didn't get the required equality. Honestly, I'm not even sure about the order of operations. Say $J_i$'s are non-intersecting, then $j_i$ pins down $i$, so how can we even take a union $\bigcup_{i\in I}A_{ij_i}$? And if we fix ""path"" (the way I understand it) $(i,j_i)$, then again $i$ is fixed and there's nothing to take a union over. Can someone tell me what $j_\infty$ above is?","['probability-theory', 'elementary-set-theory']"
1910554,Given entire function has infinitely many zeros,"Prove that for any $\lambda \neq 0$ and any polynomial $p(z) \not\equiv 0,$ the function $g(z)=e^{\lambda z}-p(z)$ has infinitely many zeros. My approach: Suppose to the contrary that $g$ has finitely many zeros, at $a_j$'s (say)
$$g(z)=\prod_{j=1}^{n} (z-a_j).$$
By Hadamard's factorization
$$g(z)=e^{h(z)} \cdot \prod_{j=1}^{n} (z-a_j),$$
for some polynomial $h(z).$ I don't know how to get a contradiction. Any help is much appreicated.","['complex-analysis', 'entire-functions']"
1910593,"There are positive integers $a,b,c$ such that $m^a=1+n^bc$","Let  $m$ and $n$ are relatively prime integers and $m>1,n>1$. Show that:There are positive integers $a,b,c$ such that $m^a=1+n^bc$ , and  $n$ and $c$ are relatively prime",['number-theory']
1910602,A nice identity involving urns and balls problem,"Prove the identity: $$\frac{\displaystyle\sum_{k=0}^{a} {n+a-k-2\choose n-2}}{\displaystyle {n+a-1\choose a}} = 1$$ where $C_{i}^{j}$ is defined as the number of ways to simultaneously choose $j$ objects from $i$ objects. My attempt: I was trying to use a combinatorial argument by saying that out of the given $n$ balls, each of the terms within the summation is the probability of a given urn containing exactly $k$ balls for $k = 0,1,2,...,n$. Thus, the sum reflects the sum of all the probabilities of that urn having exactly $k$ balls, so it must be $1$. My question: I would like to see an algebraic proof for this identity. Could someone please help with such a proof? In case my argument above is incorrect, please help point out the mistake.","['generating-functions', 'probability-theory', 'probability']"
1910635,Section of a 4-dimensional cube,"Consider 4-dimensional cube: $-1 \le x_1 \le 1, -1 \le x_2 \le 1,-1 \le x_3 \le 1, -1 \le x_4 \le 1$. Could you show an octagon that is a section of this cube?",['geometry']
1910642,Reference for the rate of divergence of Harmonic series,"In the wikipedia it states that the rate of divergence of Harmonic series is $\sum_{k=1}^n \frac{1}{k} < \log n +1 $ I have tried to find a reference, other than wikipedia, for this bound  but with no success. Which is a good reference for the above bound?","['reference-request', 'harmonic-numbers', 'divergent-series', 'sequences-and-series']"
1910661,"Nonsingular complex algebraic varieties are complex manifolds ""a more formal proof""","Before telling me that this question maybe has already been done I would like to ask you for something more concrete-clear as an answer and not just comments please! So, I do know that every nonsingular algebraic variety over $\mathbb{C}$ has the structure of a smooth complex manifold. And although sounds quite reasonable in my head, since a complex variety is a subset of the form $X \subseteq \mathbb{C}^{n}$, I can't see how does this smooth structure exists. $\mathbf{What}$ $\mathbf{charts}$ $\mathbf{do}$ $\mathbf{we}$ $\mathbf{use}$ $\mathbf{to}$ $\mathbf{do}$ $\mathbf{that}$? Apparently we have to change the topology of that space, since this topological space (equipped with the Zariski topology) is not even Hausdorff in the usual sense. So, strictly speaking not every nonsingular complex variety has a smooth structure doing it a complex manifold unless its dimension is zero. However, there must be an associated complex or evenmore analytic space. I did learn somewhere, something more sophisticated and more algebraic, that Serre in the so-called GAGA paper he constructed a functor doing that job, but the idea I guess is pretty much the same (I mean it is based on the fact that nonsingular complex varieties admit a topology-structure of a complex manifold). Also, one more question, I expect the converse of the above is not true at all. That is, not every complex manifold is given by a complex variety. But how do we give a formal proof of that or a counterexample? Thank you for patience!","['complex-geometry', 'algebraic-geometry']"
1910676,"About irreducible subgroups of $GL(V)$, $V$ a vector space of infinite dimension","Let $F$ be a field, let $V$ be a $F$-vector space, let us say that a subgroup $G$ of $GL(V)$ is irreducible if $V > 0$ and there is no $G$-invariant subspace $W$ of $V$ such that $0 < W < V$. If I'm not wrong, D.J.S. Robinson, A Course in the Theory of Groups, 8.1.5, p. 219, implies what follows : if $F$ is an algebraically closed field, if $V$ is a $F$-vector space with finite dimension, if $G$ is an irreducible subgroup of $GL(V)$, if $h$ is a $F$-endomorphism of $V$ commuting with every automorphism in $G$, then $h$ is scalar, i.e. there exists an element $f$ of $F$ such that $h$ is the multiplication by $f$. Could anybody give a counterexample in the case where the dimension of $V$ is infinite (if such a counterexample exists) ? In other words, could anybody give an example of the following situation : $F$ is an algebraically closed field, $V$ is a $F$-vector space with infinite dimension, $G$ is an irreducible subgroup of $GL(V)$, $h$ is a $F$-endomorphism of $V$ commuting with every automorphism in $G$ and $h$ is not scalar ? If I'm not wrong, $G$ must be infinite and cannot be cyclic. Now, life is short, so I prefer not to spend time on an already solved question. Thanks in advance for the answers.",['group-theory']
1910702,Is the centralizer of a Subgroup abelian?,"Let $G$ be a group, and let $H$ a subgroup of $G$.
Let: $$c(H)=\{x\in G : xh=hx, \forall h\in H \}$$ I have already proved that this is a subgroup of $G$, but I'm not sure if it's abelian (I've been looking for a counterexample of this but without success so far). Another question, how can I express the Center of G $Z(G)=\{z\in G : zx=xz, \forall x\in G \}$ in terms of $c(H)$? Is the center abelian? Thank you for your help, I'm new to groups and I'm kind of lost.","['finite-groups', 'abstract-algebra']"
1910705,"Is $(7,4)$ the only non-trivial integer solution for $(n)_k=n!$?","I accidentally noticed that: $$(7)_4=7 \cdot 8 \cdot 9 \cdot 10=2 \cdot  3 \cdot  4 \cdot  5 \cdot  6 \cdot  7=7!$$ Here $(n)_k$ is the Pochhammer symbol. I wonder, are there any other non-trivial integer solutions $(n,k)$ ? $$(n)_k=n!$$ Among the ones I consider trivial we have $(0,0),(1,0),(1,1),(2,1)$ . Somehow, I'm sure that I will get a lot of comments with these four solutions. This is the implicit plot of the equivalent equation: $$\Gamma (n+k)=n \Gamma^2 (n)$$","['diophantine-equations', 'pochhammer-symbol', 'combinatorics', 'factorial', 'gamma-function']"
1910709,Tetrahedron vector problem,"Can you give me hints on how to solve this problem. Prove that three line segments which connect middle of sides of tetrahedron which don't lie on the same plane go through the same point.
How to prove intersection with vectors? I don't even know how to attack this problem.","['analytic-geometry', 'polyhedra', 'vectors', 'geometry']"
1910809,"Non-linear function such that $f(ax)=af(x)$ for every $a \in \mathbb R, x \in \mathbb R^n$ [duplicate]","This question already has answers here : Are all multiplicative functions additive? (2 answers) Closed 7 years ago . Let $f :  \mathbb R^n \to  \mathbb R^n$ be a function such that
  $f(ax)=af(x)$ for every $a \in \mathbb R, x \in \mathbb R^n$.
  Does it follow that $f$ is linear? I don't think so, if $n>1$. If $n=1$, we have $f(a)=af(1)=\lambda a$ with $\lambda =f(1)$. Otherwise I'm not sure what to do. Thank you!","['linear-transformations', 'functions']"
1910812,Finding the remainder of a factorial raised to more factorials when divided by 11,"Find the remainder when $$3!^{{{5!}^{...}}^{2013!}}$$ is divided by 11. My answer is 5, but the answer given by the answer sheet is 1. How did this happen? I tried getting the remainders when several powers of 6 is divided by 11 since $3!=6.$ I actually got a pattern: 6, 3, 7, 9, 10, 5 and restarts to 6. Since the immediate exponent raising 6 is 120 which is divisible by 6, I reasoned that the remainder should be 5. I know my solution does not make sense. I really do not know what to do. Can anyone help?","['divisibility', 'algebra-precalculus', 'number-theory', 'factorial', 'exponentiation']"
1910849,Outer measure and trace sigma algebra,"This question is from Donald Cohn measure theory textbook. Let $\mu$ be a finite measure, and $\left(X, \mathcal{A}, \mu\right)$ a measurable space.$C \in X$ , $C_1 \in \mathcal{A},C\subseteq C_1$ with $\mu(C_1)=\mu^*(C)$. Show that if $A_1,A_2 \in \mathcal{A}$ are such that $A_1\cap C=A_2\cap C$ then $\mu(A_1\cap C_1)=\mu(A_2\cap C_1)$ I rewrite $A_1\cap C_1=(A_1\cap C) \cup (A_1\cap (C_1 - C))=(A_2\cap C) \cup (A_1\cap (C_1 - C))$.
Now the second term is such that $\mu^*(A_1\cap (C_1 - C))\leq \mu^*(C_1 - C) < \epsilon$, so that $\mu^*(A_1\cap C_1) = \mu^*(A_2\cap C)$ I can also rewrite $A_2\cap C_1=(A_2\cap C) \cup (A_2\cap (C_1 - C))$ and similarly in the end obtain $\mu^*(A_2\cap C_1) = \mu^*(A_2\cap C)$ We have then $\mu(A_1\cap C_1)=\mu^*(A_1\cap C_1) = \mu^*(A_2\cap C_1)=\mu(A_2\cap C_1)$ since the sets on the end sides of the equality are in $\mathcal{A}$ and then the measure and the outer measure agree (If I remember correctly)... Now I am sure that this is vastly wrong, since I barely used any assumptions, so if you would be kind enough to point out where everything goes wrong , that would be much appreciated ! Thanks","['real-analysis', 'measure-theory']"
1910883,"What is $\Bbb Z^n/(a_1, \dots, a_n)$ or $\Bbb Z^n / I$ isomorphic to?","I would like to know: What is $\Bbb Z^n/\langle(a_1, \dots, a_n)\rangle$ isomorphic to, as abelian group? More generally, if $I$ is a subgroup of $\Bbb Z^n$, then would you proceed to find $\Bbb Z^n/I$? Is there any algorithm? For instance for $I=\langle(4,0,2),(2,-2,0)\rangle$ or $J=\langle(-2,4,0,2),(2,-2,0,1)\rangle$? My aim is to know how to compute a quotient of $\Bbb Z^n$, which has the form
$$\Bbb Z^m \oplus \bigoplus_{i=1}^s \Bbb Z/p_i^{r_i} \Bbb Z$$
because it is finitely generated. I am aware of this particular case, and of this one, and also maybe this one. Thank you for your help!","['abelian-groups', 'abstract-algebra', 'group-theory', 'finitely-generated']"
