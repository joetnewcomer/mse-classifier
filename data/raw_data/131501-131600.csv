question_id,title,body,tags
2056273,What is the smallest integer $n$ such that $n! > 100^n$?,"I know the answer is more than $100$, because $100!$ is clearly less than $100^{100}$.
And I know the answer is less than $10000$, because ($10000 \cdot 9999 \cdot 9998 \cdot \dots\cdot 9901) \cdot (100 \cdot 99 \cdot 98 \cdot \dots \cdot 1)$ is greater than $100^{200}$.
But I don't know how to find the answer.
Can this be done without testing every value?","['number-theory', 'factorial', 'inequality', 'exponentiation']"
2056283,Equivalent Norms on $\mathbb{R}^d$ and a contraction,"Suppose we have a norm $|| \cdot ||$ on $\mathbb{R}^d$ and a linear transformation $T$ which is a contraction in regards to $c \in [0,1)$. How can I prove that $\exists k\in \mathbb{N}$ s.t $T^k$ is also a contraction in the euclidean norm $||\cdot||_2$? I got, by the equivalence of the two norms and by $T$ being a contraction, to: $||x-y||_2 > \frac{b}{ac} ||Tx-Ty||_2$ using $b||x-y||_2 \leq ||x-y|| \leq a||x-y||_2$. This yields $\frac{b}{ac} \leq 1$ and I thought I'd be able to iterate on $n\in \mathbb{N}$ to get $\frac{b}{ac} \alpha||T^nx-T^ny||_2$ while $\frac{b}{ac} \alpha > 1$ but no success with that attempt. Any hints?","['functional-analysis', 'metric-spaces', 'operator-theory', 'calculus']"
2056309,"Does absolute continuity of $f$ on $[\epsilon,1]$ and continuity at $f=0$ imply absolute continuity on $[0,1]$?","$\textbf{Question}$: Let $f$ be absolutely continuous on the interval $[\epsilon, 1]$ for $0<\epsilon<1$. Does the continuity of $f$ at 0 imply that $f$ is absolutely continuous on $[0,1]$? What if f is also of bounded variation on $[0,1]$? $\textbf{Attempt}$: My thoughts are that $f$ is NOT absolutely continuous on $[0,1]$. The definition from my textbook states that a function $F$ defined on $[a,b]$ is absolutely continuous if for any $\epsilon>0$ there exists $\delta >0$ so that $\sum_{k=1}^{N}|F(b_{k})-F(a_{k})|<\epsilon$ whenever $\sum_{k=1}^{N}(b_{k}-a_{k})<\delta$ and the intervals $(a_{k},b_{k})$ are disjoint. So, I think that the point $0$ is not included in this definition - $f$ is differentiable a.e. which does not necessarily include the boundary at the point 0, even if the point itself exists. Is this correct? My guess is then that the bounded variation assumption will make $F$ absolutely continuous on $[0,1]$ but I am not sure why.","['real-analysis', 'measure-theory']"
2056310,"$u$ upper semicontinuous iff for all $K \subseteq U$ compact and $g \in C(K)$, $u - g$ attains its maximum on $K$?","As the question title suggests, how do I see that $u$ is upper semicontinuous if and only if, for all $K \subseteq U$ compact and $g \in C(K)$, the difference $u - g$ attains its maximum on $K$?","['functional-analysis', 'real-analysis', 'partial-differential-equations']"
2056332,"How to prove that if a continuous function satisfies $f(a b)=f(a) + f(b)$, this function must be a log function?","How to prove that if a continuous function satisfies $f(ab)=f(a)+f(b)$ and both $a$ and $b$ are positive real numbers, this function must be a log function?  i.e., proof of uniqueness. Thanks",['functions']
2056390,Find the integral part of the product $\frac{2}{1} \cdot \frac{4}{3} \cdot \frac{6}{5} \cdot \frac{8}{7} \cdots \frac{2016}{2015}.$,"Find the integral part of the following number $$T = \dfrac{2}{1} \cdot \dfrac{4}{3} \cdot \dfrac{6}{5} \cdot \dfrac{8}{7} \cdots \dfrac{2016}{2015}.$$ We can show that $T = 2017\int_{0}^{\frac{\pi}{2}} \sin^{2017}(x)dx$, since $$\int_0^{\frac{\pi}{2}} \sin^{2n+1}(x) dx = \dfrac{2}{3} \cdot \dfrac{4}{5} \cdot \dfrac{6}{7} \cdots \dfrac{2n}{2n+1},$$ but how do we calculate the integral part of $2017\int_{0}^{\frac{\pi}{2}} \sin^{2017}(x)dx$?","['number-theory', 'calculus']"
2056396,"Show that $m_{2}(f(A))=0$, where $m_{2}$ denotes the two-dimensional Lebesgue measure on $\mathbb{R}^{2}$","Suppose that $A \subset R $ satisfies $m_{1}(A)=0$ where $m_{1}$ denotes the
one-dimensional Lebesgue measure. Suppose $f: \mathbb{R} \rightarrow \mathbb{R}^{2}$ satisfies $|f(x)-f(y)| \leq \sqrt{|x-y|},$ for every $x,y \in \mathbb{R}$. Show that $m_{2}(f(A))=0$, where $m_{2}$ denotes the two-dimensional Lebesgue measure on $\mathbb{R}^{2}$. I am really not sure where to even start with this one.  It seems like rectifiable curves and the isoperimetric inequality may be helpful because I can see some formulas that look similar to this, but I am hoping not to spend a lot of time down that path which might be off the track entirely. Looking for direction first of all.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2056415,What properties of a sheaf can be check at formal fibers?,"Let $A$ be a Noetherian ring $X=SpecA$ and $Y$ a projective scheme over $A$. Let $f:Y \to X$ be the structure morphism. Let $\mathscr{F}$ be a coherent sheaf over $Y$. Suppose $x\in X$ is a closed point, let $\hat{Y}_x$ be the formal fibre of $Y$ along $x$ and $\hat{\mathscr{F}_x}$ be the pull back of the sheaf to the fibre My question is : What kind of properties of $\mathscr{F}$ can be check at each closed fibre? In particular, I am looking for proof that $\mathscr{F}$ is ample if $\hat{\mathscr{F}_x}$ is so for each closed point $x$ over the corresponding ring (or maybe it is wrong?). I guess we need to make use of theorem of formal functions, and the properties desired should be explained using cohomology.",['algebraic-geometry']
2056457,Equivalence of different criteria for Lebesgue measurability,"Let $E \subset \mathbb{R}^d$ be a set. Two different criteria for Lebesgue measurability of $E$ is given by: $(i)$ (Outer approximation by open) For every $\epsilon>0$, one can contain $E$ in an open set $U$ with $m^*(U \setminus E) \leq \epsilon$. $(ii)$ (Almost open) For every $\epsilon>0$, one can find an open set $U$ such that $m^*(U \Delta E) \leq \epsilon$. The problem is to show the equivalence of these two statements. Now, $(i) \Rightarrow (ii)$ is of course trivial. But I'm having some difficulty in showing $(ii) \Rightarrow (i)$. Given that, for every $\epsilon>0$, one can find an open set $U$ such that $m^*(U \Delta E) \leq \epsilon$, how can I find an open set $V$, containing $E$ with $m^*(V \setminus E) \leq \epsilon ~??$ Any help would be much appreciated!","['lebesgue-measure', 'measure-theory']"
2056465,Maximum Likelihood and Density Function,"Likelihood function $$\mathcal{L}(\theta;\vec{x})=\prod_i f(x_i;\theta)=\prod_i\frac{dP_\theta}{dm}$$ where $\frac{dP_\theta}{dm}$ is the Radon-Nikodym Derivative w.r.t. Lebesgue measure in continuous case For a continuous random variable, the probability of it takes on any value is zero. But in a statistical setting, for example maximum likelihood or EM algorithm, we plug in the observed values in order to maximize the probability. Is there a mathematically rigours definition of likelihood function or maximum likelihood estimate? Is the likelihood function the same as the joint density function of independent samples? Do we see semicolon "";"" as a sign of conditional probability?","['functional-analysis', 'maximum-likelihood', 'statistics', 'probability', 'measure-theory']"
2056474,"What is the probability that a 1 was sent, given that 1 was received?","I have the following information: $0$ is sent with probability $0.3$ $1$ is sent with probability $0.4$ $2$ is sent with probability $0.3$ Due to noise, $0$ is changed to $1$ during transmission with probability $0.2$ Due to noise, $0$ is changed to $2$ during transmission with probability $0.1$ Due to noise, $1$ is changed to $0$ during transmission with probability $0.2$ Due to noise, $1$ is changed to $2$ during transmission with probability $0.1$ Due to noise, $2$ is changed to $0$ during transmission with probability $0.2$ Due to noise, $2$ is changed to $1$ during transmission with probability $0.1$ Let A - the event that $\text{1 is received}$ , B - the event that $\text{1 is sent}$ I must find $P(B|A)$ : $$P(B|A) = \frac{P(A|B)P(B)}{P(A)}$$ $P(B)$ = 0.4 $P(A|B)$ = P(1 is sent) $\times$ P(1 does not change ) P(1 does not change ) = [1 - P(1 becomes 0)] $\times$ [1 - P(1 becomes 2)] (right?) (1-0.2)(1-0.1) = 0.72 P(1 is sent) $\times$ 0.72 = (0.4)(0.72) = 0.288 P(A) = P(1 is sent and it stays 1) + P(0 is sent and it changes to 1) + P(2 is sent and it changes to 1) P(A) = 0.288 + (0.3)(0.2) + (0.3)(0.1) = 0.378 Final answer: $$\frac{0.288 \times 0.4}{0.378} = 0.30$$ Has this been done correctly?","['combinatorics', 'probability', 'discrete-mathematics']"
2056499,"Prove that if lim f(x) = L1 and lim g(x) = L2, then lim (f(x))^(g(x)) = L1^L2","I am trying to prove that if
$$
\lim_{x \to c} (f(x)) = L_1
\\ \lim_{x \to c} (g(x)) = L_2
\\ L_1, L_2 \geq 0
$$
Then
$$
\lim_{x \to c} f(x)^{g(x)} = (L_1)^{L_2}
$$ I am doing this for fun, and my prof said that it shouldn't be too hard, but all I got so far is
$$
\forall \epsilon >0 \ \exists \delta > 0 : \text{if}\ \ |x-c|<\delta\ \ \ \text{then}\ |P(x)-L|<\epsilon
\\ |f(x)^{g(x)} - (L_1)^{L_2}| < \epsilon
$$
I have no idea how to proceed. Can someone help me out? I started by defining h(x) as $$(f(x))^{(g(x))}$$ but I couldn't go anywhere with that without basically defining the limit of h(x) as x approaches c to be L1^L2","['proof-writing', 'exponential-function', 'limits']"
2056506,"Find all integer solutions $(x,y)$ such that $2x^2 + y^2 = 3x^2y$","Find all integer solutions $(x,y)$ such that $2x^2 + y^2 = 3x^2y$. We can rearrange the given equation to $$y^2 = x^2(3y-2)\tag1$$ Thus $3y-2$ must be a perfect square and so $3y-2 = k^2$. How can we continue?",['number-theory']
2056544,Solving birthday problem without complement,"I'm trying to find the probability of at least 2 people in a room of 4 sharing the same birthday (without using complements). I began by breaking the problem down into 4 cases: Let E = the event that at least 2 people share the same birthday in a room of 4. Our sample size: $365^4$ Case 1: 4 people share the same birthday: 365 ways Case 2: 3 people share the same birthday, 1 distinct birthday: $365 \cdot 364 \cdot C(4,3)$ Case 3: 2 people share a birthday, another 2 people share some other birthday: $365 \cdot 364 \cdot \frac{C(4,2)}{2}$ Case 4: 2 people share same birthday, 2 distinct birthdays: $365 \cdot 364 \cdot 363 \cdot C(4,2) \cdot 2$ After adding up all the cases and dividing by the sample size to find probability the answer had an over-count. I checked my answer by doing $$P(E) = 1- \frac{365 \cdot 364 \cdot 363 \cdot 362}{365^4}$$ Where did I have an over-count? Thank you! Here is an example that works with n = 3 people and at least 2 people share same birthday. Case 1: 3 people share same birthday: 365 Case 2: 2 Same birthdays, 1 different: $365 \cdot 364 \cdot \binom{3}{2}$ $$P(E) = \frac{365 + (365 \cdot 364 \cdot \binom{3}{2})}{365^3} \equiv 1 - \frac{365 \cdot 364 \cdot 363}{365^3}$$ Those are both equivalent answers because in the complement we're subtracting away the event that all birthdays are distinct.","['birthday', 'combinatorics', 'probability']"
2056566,How to find the mod of this large number,"How would one calculate $6000006000600000600006006000000003 \times 3 \pmod{18}$? The number is too big to use a calculator to manipulate the number into something I can work with, and Fermat's theorem doesn't apply since $18$ isn't prime, so I'm stumped as to what to do.","['discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2056589,"Does $X_n+Y_n\rightarrow0$ almost surely (where $X_n,Y_n$ are i.i.d.) imply $X_n\rightarrow0$ almost surely","Let $\{X_n,Y_n:n\in\mathbb N\}$ be a sequence of independent random variables. Suppose that $X_n$ and $Y_n$ have the same distribution for every $n\in\mathbb N$. Prove that if $X_n+Y_n\rightarrow0$ almost surely, then $X_n\rightarrow0$ almost surely. I've tried  to use Borel-Cantelli Lemma to reduce this to prove that  $\sum_nP(|X_n+Y_n|>\epsilon)<\infty$ for any $\epsilon>0$ implies $\sum_nP(|X_n|>\epsilon)<\infty$ for any $\epsilon>0$. I observed that $P(|X_n|>\epsilon)=P(|X_n|>\epsilon,|X_n-Y_n|<\epsilon)+P(|X_n|>\epsilon,|X_n-Y_n|\geqslant\epsilon)$, and that the first term $P(|X_n|>\epsilon,|X_n-Y_n|<\epsilon)\leqslant P(|X_n+Y_n|>\epsilon)$. But I don't konw how to control the second term. Please feel free to discuss it. I am not sure I am heading a right way: I can't find a proper method to use the condition $X_n\stackrel{d}{=}Y_n$.","['real-analysis', 'probability-theory', 'probability', 'convergence-divergence', 'sequences-and-series']"
2056605,"$X_i \sim \operatorname{Unif}(0,1)$, and for $\varepsilon >0$, $P(|X_{(n)}-1|\geq \varepsilon) =(1-\varepsilon)^n$. Must we bound $\varepsilon$?","Suppose $X_1, \ldots, X_n \sim \operatorname{Unif}(0,1)$ are iid random variables and we define $X_{(n)} = \max X_i$ as the largest order statistic. I would like to show that $X_{(n)}$ converges in probability to $1$. To do so, I have: For all $\varepsilon >0$, $$
P(|X_{(n)}-1|\geq \varepsilon) = \prod_{i} P(X_i <1-\varepsilon) = (1-\varepsilon)^n
$$ Now, to take the limit, I have an issue in that for $0<\varepsilon \leq 1$, as $n \to \infty$, $P(|X_{(n)}-1|\geq \varepsilon)\to 0$. But for $\varepsilon >1$, it blows up. What is the correct way of doing this problem here ? Is there a bound on $\varepsilon$? Would it be valid to write: $$
P(X_{(n)}\leq 1-\varepsilon) = P(X_{(n)}\leq 1-\varepsilon)\mathbb{1}_{\varepsilon>1} + P(X_{(n)}\leq 1-\varepsilon) \mathbb{1}_{\varepsilon\leq 1} \text{ ?}
$$","['probability-theory', 'probability', 'statistics', 'statistical-inference']"
2056673,Find the solution for $x$ with $0 \le x \lt 13$ so $13 \mid 3x^2+9x+7 $.,"Find the solution for $x$ with $0 \le x \lt 13$ so $13 \mid 3x^2+9x+7 $. I got this question in my discrete mathematics class. I don't really get the idea how 13 can divide $3x^2+9x+7 $ All of my friend told me to try all the number between 0 and 12, but I know that's not how to solve this question. Can anyone help me? Thanks.","['divisibility', 'discrete-mathematics']"
2056685,Conditional expectation and independence of residual,"Consider $L^2$ random variables $X$ and $Y$, and consider the projection view of conditional expectation $E[Y|X]$  as the best approximation of $Y$ among functions of $X$. That is, $\hat f (X) := E[Y|X]$ is
$$
\hat f(\cdot) = \arg \min_{g(\cdot)} E[Y - g(X)]^2 
$$
or letting $\widehat Y = \hat f(X)$,
$$
\widehat Y = \arg \min_{Z \in \mathcal L} E[Y - Z]^2 
$$
where $\mathcal L = \{g(X):\; \text{for some function $g$}\}$ is the linear space of $L^2$ measurable functions w.r.t. $X$. We have that $\xi := \widehat Y - Y$ is orthogonal to $\mathcal L$, that is $E[\xi g(X)] = 0$ for any $g$, including the constant functions, showing that $ E \xi=0$. Hence, we have that
$$
E[\xi g(X)] = E(\xi) E[g(X)]
$$
that is, $\xi$ is uncorrelated with $g(X)$ for any $g$. All of this is well-known. But now, what is the relation between $\xi$ and $X$, or in other words, what is their joint behavior? It seems to be something stronger than uncorrelatedness but short of independence. Had we had $E[f(\xi) g(X)] = E[f(\xi)] E[g(X)]$ for arbitrary $f$ and $g$, we would get independence. If we only have it for $f,g$ linear we get uncorrelatedness. Now, we have it for $f$ linear and $g$ arbitrary. Are there simple assumptions that bump this relation to independence? EDIT: Let $\mathcal L$ defined above be $\mathcal L_X$, and define $\mathcal L_Y$ similarly. Maybe the answer is in projecting $\widehat Y$ back onto $\mathcal L_Y$, and repeating the process back and forth between $\mathcal L_X$ and $\mathcal L_Y$ and seeing what this process produces?",['probability-theory']
2056708,Number of equivalence classes of $w \times h$ matrices under switching rows and columns,"If I have a $w \times h$ matrix where each value is an integer $0 \lt n \lt 20$ , how can I count the number of distinct configurations, where $2$ configurations are ""distinct"" if there is no way to reshuffle the rows and columns that would produce the same matrix? Can this be counted with the stars and bars method? For example, these are equal (we swapped a row, then a column): 0 0 0    2 0 4
0 2 4    0 0 0 but these are distinct (no way to swap rows or columns to produce the other): 0 0 0    2 0 0
0 2 4    0 4 0 It seems like there ought to be a way to count the rows or columns as ""bins"" and the values as balls.  I realize that in this case there are $18$ different colored balls, but even if the only values possible were $1$ and $0$ , (ball or no ball) I can't see how to represent it as stars and bars.","['matrices', 'combinatorics']"
2056720,Curiosity: Wouldn't the definition of the derivative always be 1 if it exists?,"I'm pretty sure I have the wrong intuition here but I have a slight confusion about the way we could calculate the derivative at a certain point using (one of) the definition(s) of the derivative. See example bellow: $$\frac{df(x)}{dx}= \lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ let's see the case of $f(x) = \sqrt{5x+10}$ $$\frac{df(x)}{dx}=\lim_{h\to0}\frac{\sqrt{5h+5x+10}-\sqrt{5x+10}}{h}$$ If we want to calculate $f'(5)$ $$\left.\frac{df(x)}{dx}\right\rvert_5=\lim_{h\to0}\frac{\sqrt{5h+35}-\sqrt{35}}{h}$$ if we try to find the limits when $h\to0^+$: The numerator would be only slightly superior to 0 The denominator would be only slightly superior to 0 $$\frac{\text{very small number above zero}}
       {\text{very small number above zero}}\approx 1$$ It should be the same for $h\to 0^-$ Hence: 
$f'(5)= 1$? N.B: I know this result is wrong, I just want to know how the logic I used is faulty.","['derivatives', 'definition']"
2056750,How to find Generator Matrix from a given Parity Check Matrix?,"I'm given a Parity Check Matrix
\begin{bmatrix}0&1&1&1&1&0&0\\1&0&1&1&0&1&0\\ 1&1&0&1&0&0&1\end{bmatrix}
and I have to find the Generator Matrix of it.I spent many days try to solve it but I can't","['matrices', 'linear-algebra']"
2056752,Markov algorithm for computing $f(x) = x$ mod $3$?,"As the question title suggests, what is a Markov algorithm for computing the function $f(x) = x$ mod $3$?","['computer-science', 'number-theory', 'markov-chains', 'algorithms', 'markov-process']"
2056754,"Ackermann function $A(m, n)$, all nonnegative integer solutions to $A(m, n) = m + n$?","The Ackermann function $A(m, n)$ is given by the recursion$$\begin{cases} A(0, n) \overset{\text{def}}{=} n + 1 \\ A(m + 1, 0) \overset{\text{def}}{=} A(m, 1) \\ A(m + 1, n + 1) \overset{\text{def}}{=} A(m, A(m + 1, n)).\end{cases}$$What are all non-negative integer solutions of the equation $A(m, n) = m + n$?","['computer-science', 'ackermann-function', 'big-numbers', 'algebra-precalculus', 'recursion']"
2056799,On relationship of two categorical characterization of finitely generated objects.,"I've encountered The following categorical characterization of finitely generated modules: A $R$ -module $M$ is finitely generated iff it satifies one of the following properties: a): for any family of $R$ -module $\{U_i\}_{i\in\mathcal I}$ and any epimorphism $f:\bigoplus_{i\in\mathcal I} U_i\twoheadrightarrow M$ , there exists a finite subset $\mathcal F$ of $\mathcal I$ such that the restriction of $f$ on $\bigoplus_{i\in\mathcal F} U_i$ is also epic. b): for any category $\mathscr I$ representing a directed partially ordered set and any functor $F:\mathscr I\to R\text -\mathsf{Mod}$ such that every arrow of $\mathscr I$ is mapped to an injection via $F$ , then the canonical homomorphism $\varphi:\varinjlim\text{Hom}(M,-)\circ F\to\text{Hom}(M,\varinjlim F)$ is epic in $\mathsf{Ab}$ . My question is: If $R\text -\mathsf{Mod}$ is replaced by an arbitrary cocomplete abelian category, are characterization a) and b) remain equivalent? I've already proved that b) always implies a).","['modules', 'abstract-algebra', 'category-theory', 'limits-colimits', 'abelian-categories']"
2056845,Find largest value of $n$ for condition to hold true,"Given the unit circle $\mathbb{U}=\left\{(x,y)\vert x,y\in\mathbb{R},0\leq x^2+y^2\leq1\right\}$, and a little bigger circle $\mathbb{U^*}=\left\{(x,y)\vert x,y\in\mathbb{R},0\leq x^2+y^2\leq1+k\right\}$,$\mathbb{U}\subset\mathbb{U^*}$, and a region $$P_i=P(x_i,y_i)=\left\{(x,y)\in\mathbb{U^*}\vert(x_i,y_i)\in\mathbb{U},(x-x_i)^2+(y-y_i)^2\leq k^2\right\}$$
for $0<k\le\frac{1}{2}$
and
$$d(P_i,P_j)=\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}$$ Find the largest value of $n$ in function of $k$ if $$\left(\bigcup_{i=1}^{n}P_i\right)\cap P_{n+1}\neq\emptyset\tag 1$$ $$\left(\bigcup_{i=1}^{n-1}P_i\right)\cap P_{n}=\emptyset\tag 2$$ must both be true. From (2): $$(P_1\cap P_n)\cup\dots\cup(P_{n-1}\cap P_n)=\emptyset$$ That means $$P_1\cap P_n=\emptyset\rightarrow d(P_1,P_n)\geq2k$$
$$\vdots$$
$$P_{n-1}\cap P_n=\emptyset\rightarrow d(P_{n-1},P_n)\geq2k$$ but I don't know how to follow from there.","['elementary-set-theory', 'geometry']"
2056848,Martingale from the symmetric random walk.,"Suppose $X_1, X_2, \dots$ is i.i.d with $P(X_i = 1) = P(X_i = -1) = \dfrac{1}{2}$ and $S_n = X_1+X_+\dots+X_n$. Also, define $N_n = |\{k: S_k = 0,\, 0 \leq k<n\}|$. Then I need to show that $|S_n| - N_n$ is a martingale with respect to the filtration $\mathcal{F}_n = \sigma(S_1,S_2,\dots,S_n)$. But I am having trouble getting started with showing $E(|S_{n+1}| - N_{n+1}|\mathcal{F}_n) = |S_n| - N_n$. How do I proceed from here?","['probability-theory', 'conditional-expectation', 'martingales', 'probability-distributions']"
2056870,Interchanging sums with inner sum in terms of outer sum variable,"I've got a double sum of the form $$\sum_{k=0}^\infty \left( \sum_{i=0}^k a_{i,k}  \right)    $$ and I'm trying to work out how you interchange these two sums. I remember seeing a formula for this in one of my courses, but I can't remember it (nor can I find my notes). As far as I remember, it comes out as two infinite sums. I know when the inner sum isn't in terms of $k$, you can apply Fubini-Tonelli if the inner summands are all non-negative, but here that obviously doesn't make much sense. I tried to draw a grid with the entries and count them in a different order, but I keep getting the sum indexed by $i$ on the inside so I'm a little lost. So, if anyone could prod me in the right direction, that would be great.","['summation', 'sequences-and-series', 'analysis']"
2056879,Maximal ideals of $\mathbb{Z}[\sqrt{-5}]$,"Let $\mathbb{Z}$ be the ring of integers, and $R=\mathbb{Z}[\sqrt{-5}]=\{a+\sqrt{-5}b\mid a, b\in\mathbb{Z}\}$ . Is there any characterization for maximal ideals of $R$ with respect to maximal ideals of $\mathbb{Z}$ or other description for them? Thanks for any help.","['abstract-algebra', 'maximal-and-prime-ideals', 'ideals']"
2056893,Calculate the conditional probability of dependent events involving independent random variables,"Given three independent, non-negative (continuous) random variables $v_1$, $v_2$ and $v_3$ with PDFs $f_{v_1}$, $f_{v_2}$ and $f_{v_3}$ respectively, I want to calculate the probability of satisfying a system of linear inequalities. For example, what is the probability $\mathbb{P}(v_1 \leq q_1 \land [ v_1 + v_3 \leq q_2 \lor v_2 + v_4 \leq q_2])$ of satisfying $v_1 \leq q_1 \;\textbf{and}\; [ v_1 + v_3 \leq q_2 \;\textbf{or}\; v_2 + v_3 \leq q_2 ]$ where $q_i \in \mathbb{Q}$ are rational constants. (Sorry for my abuse of notation!) I can easily calculate the probability for each of the three inequalities (using convolutions) by
$\mathbb{P}(v_1 \leq q_1) = \int_{-\infty}^{q_1} f_{v_1}(t)\; dt$, $\mathbb{P}(v_1 + v_3 \leq q_2) = \int_{-\infty}^{q_2} f_{v_1}(t) (\int_{-\infty}^{q_2 - t} f_{v_3}(u)\; du)\; dt$, and $\mathbb{P}(v_2 + v_3 \leq q_2) = \int_{-\infty}^{q_2} f_{v_2}(t) ( \int_{-\infty}^{q_2 - t} f_{v_2}(u)\; du)\; dt$ Let $A$ be the event that $v_1 + v_3 \leq q_2$ and $B$ the event that $v_2 + v_3 \leq q_2$. The sum rule tells us that $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)$, and we know that $\mathbb{P}(A \cap B) = \mathbb{P}(A|B) \mathbb{P}(B) = \mathbb{P}(B | A) \mathbb{P}(A)$. Is it possible to calculate the conditional probabilities $\mathbb{P}(A|B)$ and $\mathbb{P}(B|A)$ knowing only the marginal distributions for $v_1$, $v_2$ and $v_3$?","['inequality', 'probability', 'probability-distributions']"
2056923,"Connecting Unitary, Orthogonal, Normal, and Self-Adjoint","I'm trying to connect these 4 properties to see the ""big picture,"" and would love some input or corrections. This is what I have so far: 1) If $T$ is unitary or orthogonal, then $T$ is also normal. 2) Normal operators are also self-adjoint. ($\implies T$ is unitary/orthgonal?) FALSE. 3) Unitary and orthogonal operators have eigenvalues where $|\lambda_i|$ = $1$. 4) Unitary and orthgonal operators are similar to a diagonal matrix (over $\mathbb{C}$ and $\mathbb{R}$, respectively), which means they are diagonalizable. 5) If $T$ is orthogonal, then all of its eigenvalues must be real. FALSE. 6) If $T$ is unitary, not all of its eigenvalues have to be imaginary (can be both complex and real, as long as its absolute values are $1$). I know not all of these are correct, and I will edit them accordingly. But these are the connections I came up with so far. Any input or corrections would be GREATLY helpful. Thank you!","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'linear-transformations']"
2056934,Telescoping exercise with iterations?,"For every $x>0$, consider the sequence $(x_n)$ defined by $x_0=x$ and, for every $n\geqslant0$, $$x_{n+1} = \sqrt{x_n + \frac12}$$
Then $x_n\to x_*=\frac{1+\sqrt3}2\ne0$ hence the sequence $$S_n(x)=\sum_{k=1}^n(-1)^kx_k^4$$ diverges. Consider its Cesàro sums, defined by $$C_n(x)=\frac1n\sum_{k=1}^nS_k(x)$$ The question is to prove that $C_n(x)\to C(x)=\frac18-x^2$. One can probably use telescoping and / or differentiation techniques. As safety checks, note that the proposed limit $C(x)$ satisfies the relations $$C(x_*)=-\frac12x_*^4\qquad C\left(x^2-\frac12\right)=-x^4-C(x)$$","['dynamical-systems', 'polynomials', 'sequences-and-series']"
2056945,A curious coincidence for Wroblewski's solutions to $1^4+x_2^4+x_3^4+x_4^4+x_5^4 = y_1^4$,"J. Wroblewski has a database for the equation,
$$x_1^4+x_2^4+x_3^4+x_4^4+x_5^4 = y_1^4$$
 Of about $13700$ primitive solutions with $y_1 < 10000$ and $y_1\not\equiv 0{\pmod 5}$, only four examples can be found with $x_1 = 1$, namely
$$1^4 + 150^4 + 3340^4 + 6130^4 + 6350^4 = 7499^4\\
1^4 + 2520^4 + 3250^4 + 5050^4 + 6970^4 = 7499^4\tag1$$
and
$$1^4 + 920^4 + 3120^4 + 5410^4 + 8870^4 = 9193^4\\
1^4 + 1410^4 + 3490^4 + 6020^4 + 8680^4 = 9193^4\tag2$$
Surely the fact they come in pairs can't be coincidence. I think they are particular instances of a identity similar to cubes,
$$\small 1^3 + (-1 - 9t^3 - 648t^6 + 3888t^9)^3 + (3t + 81t^4 - 1296t^7 + 
        3888t^{10})^3 = (-135t^\color{red}4 + 3888t^\color{red}{10})^3\tag3$$
Because the RHS has only $\color{red}{even}$ powers, then it is immune to sign changes. For example, let $t=-1,1$ and we get,
$$1^3 -4528^3 + 5262^3 = 3753^3\\
1^3 + 3230^3 + 2676^3 = 3753^3$$
So that explains the one for cubes. Q: What, however, explains $(1)$ and $(2)$? And if an identity is behind it, then what is it? P.S. If $y_1\equiv 0\pmod5$, there are more solutions, the smallest again comes in a pair,
$$1^4 + 8^4 + 24^4 + 36^4 + 38^4 = 45^4\\ 
1 ^4 + 2^4 + 12^4 + 24^4 + 44^4 = 45^4$$
with the first one missed in Mathworld's list.","['number-theory', 'diophantine-equations']"
2056946,Geodesics of hyperbolic plane,"I just found (or: I think that I found) the geodesics of the upper, closed half plane of $\mathbb R^2$. To verify my solution: Is it correct that the geodesics are the circles and lines which meet the unit circle at right angles? Thanks a lot for the confirmation (or the correction, if I'm wrong...) Edit: Here is what I have so far (this should be correct, isn't it?):","['differential-geometry', 'geodesic']"
2056953,the image of a morphism,"Let $X$ be an affine algebraic variety in $\mathbf{A}^n_k$ and $f\in A(X)$ be a non-constant morphism on $X$, how can we prove that $f(X)$ contains an open subset of $\mathbf{A}^1_k$?",['algebraic-geometry']
2056955,Inverse laplace transform $1/(s^2+9)^2$,"Find inverse laplace transform of $$\frac{1}{(s^2+9)^2}$$ I've tried to decompose the fraction using $$\frac{As+B}{s^2+9}+\frac{Cs+D}{(s^2+9)^2}$$ $$1=(As+B)(s^2+9)+Cs+D$$ yet D=1, still giving me the same exact equation $$\frac{1}{(s^2+9)^2}$$ any help?","['laplace-transform', 'ordinary-differential-equations', 'calculus']"
2056964,Sets operator equal to,"I have actually two questions. Determine if the following is true: a) $(A - B) - C = A - (B - C)$ b) If $A \cup B = A \cap B$, then $A = B$ $A$ and $B$ are sets. In part(a), $$A-B = A \cap B^c$$ $A - (B - C)$ $=A - (B\cap C^c)$ $=A\cap (B^c\cup C)$ $=(A\cap B^c)\cup (A\cap C)$ $=(A-B)\cup (A\cap C)$ $\neq (A - B) - C$ So can I prove it in this way and is it correct? And in part(b), I think it is correct? $A\cap B = ${1, 2} $A\cup B = ${1, 2} So $A =$ {1, 2} and $B =$ {1, 2}","['elementary-set-theory', 'proof-verification']"
2056974,Probability related to circle,Let we have to select point nearer to center then the circumference of a given circle. What is the probability of finding such points? I am confused that points at distance$\frac{r}{2}$must be favorable or not,['probability']
2056979,Proof By Induction - Divisibility by $7$.,I am attempting: My solution is: But I am not sure where I am going wrong. The answer I get is not divisible by 7.,"['induction', 'discrete-mathematics']"
2057008,Is $g(u)= \frac{E [ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} ] }{E [ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} ]}$ decreasing in $u$,"Let $X$ be a positive random variable, let us define a function
\begin{align}
g(u,a)= \frac{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} \right] }{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} \right]}.
\end{align} Question: Can we show that the above integral is monotonically decreasing in $u$ ( for $u>0$ ) for all $a > 1$. Note that $X$ here represents the variance of standard normal. That is we consider the variance to be a random variable. I can show that $g(u,a)$ is bounded by $1$ and continuous but can not establish that it is decreasing.  Also, note that the function $g(u,a)$ is symmetric around $u=0$. What I tried: I was able to show that  for $p,q\ge 1$ and $\frac{1}{q}+\frac{1}{p}=1$ and $a^2 \ge \frac{1}{p}$ we have
\begin{align}
g(u,a) \le  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}},
\end{align} where $\beta=\sqrt{\frac{q(a^2-\frac{1}{p})}{a^2}}$. Proof: By using Holder's inequality
\begin{align}
E \left[ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} \right] &=E \left[ \frac{1}{\sqrt{X}} e^{-\frac{ (a^2-\frac{1}{p})u^2}{2X}} e^{-\frac{ \frac{1}{p}u^2}{2X}}  \right] \\
&\le E^\frac{1}{q} \left[ \frac{1}{\sqrt{X}} e^{-\frac{ q(a^2-\frac{1}{p})u^2}{2X}}   \right]  E^\frac{1}{p} \left[ \frac{1}{\sqrt{X}}  e^{-\frac{ u^2}{2X}}  \right].
\end{align}
Therefore,
\begin{align}
g(u,a) \le \left( \frac{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{q(a^2-\frac{1}{p})u^2}{2X}} \right] }{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} \right]} \right) ^\frac{1}{q}
&=  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}},
\end{align}
and \begin{align}
g(u,a) \le  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}},
\end{align} where $\beta=\sqrt{\frac{q(a^2-\frac{1}{p})}{a^2}}$.
Thank you. Looking forward to seeing your approaches.","['real-analysis', 'probability', 'expectation', 'probability-theory']"
2057052,Number of nonsingular $2\times2$ matrices over $GF(3)$,"Let $G=GL(2,GF(3))$ be the group of all matrices $
        \begin{pmatrix}
        a & b \\
         c & d
        \end{pmatrix}
$ whose determinants are nonzero and whose entries $a,b,c,d$ are taken from the finite field $GF(3)=\{0,1,2\}$. Show that $o(G)$, the number of matrices in the group $G$, is $48$. Well, because there are $3$ possibilites for $a,b,c,d$ it will be $3^4 = 81$, now I'm struggling finding the $33$ possibilites which have to come from $ ad = bc$. How can I find them? I counted till $18$, but it's not enough.","['matrices', 'group-theory', 'linear-algebra', 'discrete-mathematics']"
2057053,A holomorphic function inequality. Is it right?,"I have proved using Green's theorem the following equality:$$\frac{1}{2\pi i}\left(\frac{1}{\zeta}-\bar{\zeta}\right)\int_{\partial \mathbb{D}}f(z+\zeta)\log\left(\frac{z}{z-\zeta}\right)dz=f(\zeta)+\frac{\zeta}{\pi}\iint_{\mathbb{D}}\frac{\bar{z}-\bar{\zeta}}{1-\zeta \bar{z}}f(z+\zeta)dxdy $$
For some $\zeta$ inside the disc and for $f:\Omega\to \mathbb{C}$ , $\mathbb{D} \subset \Omega$. Now I would like to estimate the integral in the left side. I consider a $\zeta$ such that $0<|\zeta|<1$  Now i would like to estimate $f(\zeta)$.
After calculating the contour integral with residues, what i get is:
$$f(\zeta)=\zeta f(2\zeta)\left(\frac{1-|\zeta|^2}{\zeta}\right)+\frac{\zeta}{\pi}\iint_{\mathbb{D}}\frac{\bar{z}-\bar{\zeta}}{1-\zeta \bar{z}}f(z+\zeta)dxdy$$ and after using the triangle inequality I get:
$$|f(\zeta)|\le (1-|\zeta|^2)|f(2\zeta)|+\frac{|\zeta|}{\pi}\iint_{\mathbb{D}}|f(z+\zeta)|dxdy.$$
 If $f$ is univalent then we substitute $f(z+\zeta) $ with $(f^{'}(z+\zeta))^2 $ one has a lower bound for the area of this function inside the unit disc.
$$\frac{|f^{'}(z)|^2-(1-|z|^2)|f^{'}(2z)|^2}{|z|}\le \mathrm{Αrea} f(\mathbb{D})$$ Are my estimations meaningful ?","['complex-analysis', 'integration', 'estimation', 'analysis']"
2057093,Let $P \in M_n(\mathbb C)$ be idempotent. Prove that all nonzero singular values of $P$ satisfy $\sigma_i \ge 1$,"I'm having some difficulty proving the following: Let $P \in M_n(\mathbb C)$ be idempotent. Prove that all nonzero singular values of $P$ satisfy $\sigma_i \ge 1$. By definition I know that $P$ being idempotent means $P^2 = P$. Likely I have to invoke the Singular Value Decomposition Theorem to prove the problem. So, let the singular value decomposition of $P$ be given by $$P = U\Sigma V^* = P^2 = U\Sigma V^*U\Sigma V^*.$$ By definition I know that the singular values of $P$ are the square roots of the eigenvalues of $P^*P.$ And unfortunately I am not sure where to go from here. I was inclined to say that $$\sigma_1 = \|P\|_2 = \|P^2\|_2 \le \|P\|_2\|P\|_2 = \sigma_1^2 \implies 1 \le \sigma_1,$$ for nonzero $\sigma_1$, but this doesn't tell me enough. What about $\sigma_2$? and further? Can anyone provide a hint?","['matrices', 'normed-spaces', 'matrix-decomposition', 'linear-algebra']"
2057111,Does there exists a finite abelian group $G$ containing exactly $60$ elements of order $2$?,Suppose there exists such a group. Then Lagrange's theorem assures that the group is of even order. But I conclude from this and this that such a group has odd number of elements of order $2$. Giving us contradiction. Hence there does not exist a finite abelian group $G$ containing exactly $60$ elements of order $2$. More strongly there does not exist a finite group $G$ containing even number of elements of order $2$. Is my understanding correct?,"['finite-groups', 'abstract-algebra', 'proof-verification', 'abelian-groups', 'group-theory']"
2057113,Uniform Convergence of convex functions implies convergence of derivatives in $L^1$?,"It is known that if a sequence of continously differentiable, convex functions $f_n: [a,b] \longrightarrow [c,d]$ converges uniformly to a continously differentiable function $f: [a,b] \longrightarrow [c,d]$, that the derivatives $f_n^\prime$ converges pointwise to $f^\prime$. But the convergence doesn't need to be uniformly, see Convex functions and uniform convergence of derivatives Does the convergence of $f_n^\prime$ to $f^\prime$ hold in the $L^1$-sense?","['derivatives', 'convex-analysis', 'uniform-convergence']"
2057148,Three shooters shoot a target,"Three shooters shoot a target. The known probability to hit the target of the first, second and third shooter are 0.3, 0.4 and 0.5 respectively. What is the probability that the target is hit from only one shooter? I try this. The probabilities that two will not heat the target: 0.7 x 0.6 = 0.42
0.7 x 0.5 = 0.35
0.6 x 0.5 = 0.30 and finally I'm not sure what should i do with those results? suppose have to multiply them?",['probability']
2057212,Example of conservative vector field that is not irrotational,"Can anyone suggest an example of a vector field $F: A \subset \mathbb{R}^3 \to \mathbb{R}^3$ that satisfies all the following conditions? $F$ does not belong to $C^1(A)$ $F$ is conservative in $A$ It is not true that $\mathrm{curl} F(x)=\bar{0}$ $\,\,\,\,\forall x \in A$ (Also an example in dimensions other than $\mathbb{R}^3$ would be good)","['multivariable-calculus', 'integration', 'calculus', 'vector-analysis']"
2057224,"$d(p,q)=1$ if $p\ne q$, $0$ if $p=q$. What are the compact sets?","This is an exercise of Rudin's Principles of Mathematical Analysis (Ch2).  Let $X$ be an infinite set with the following metric:
$$d(p,q)=\left\{\begin{array}{cc}1, \quad p\ne q\\0, \quad p=q\end{array}\right.$$
I'm not sure if I have answered the following questions correctly. (I put my answers in parentheses.)  Can someone please confirm or correct me if I'm wrong?
Thanks a lot! (1) Which subsets of $X$ are open?  $\quad$(any subset of $X$) (2) Which are closed?  $\quad$(any subset of $X$) (3) Which are compact?  $\quad$(only finite subsets of $X$) The key argument of my proof is that for any $x\in X$, any neighborhood of $x$ of radius $r<1$ contains only $x$, i.e. $\forall r<1, N_r(x)=\{x\}.$  From this fact, I obtained answers to (1) and (2) quite readily.  For (3), any infinite subset $A$ of $X$ can be written as: 
$$A=\underset{x\in A}\cup\{x\},$$
which is an open cover of $A$, since each $\{x\}$ is open in $X$.  This open cover cannot have a finite subcover (because it would contain only finite points.)  So it appears that only finite subsets can be compact.","['general-topology', 'real-analysis']"
2057231,"Is there a ""clean"" way of parametrizing the intersection of the sphere and saddle?","I was playing around, trying to find a parametrization for the intersection of the two surfaces, $$x^2+y^2+z^2=1$$
$$z=x^2-y^2,$$ but I wasn't able to get anything nice-looking. Any suggestions, or is this a hopeless endeavor? EDIT: Thanks, Thomas Andrews. With the corrected formulas,
$$ a(t) = \sqrt{\frac{2}{1+\sqrt{1+4\cos^2 2t}}} $$
$$ (x(t),y(t),z(t)) = (a(t)\cos t, a(t)\sin t, a(t)^2 \cos2t), $$ we get a very nice picture!","['multivariable-calculus', 'parametric']"
2057243,"Show that, if $f ' (x) = 1$ then $f(x) = x + C$","Let $f : [a, b] \to \mathbb{R}$ be a continuous function that is differentiable on $(a, b)$ . Show that, if $f'(x) = 1$ for all $x \in (a, b)$ , then there exists a constant $C \in \mathbb{R}$ such that $f(x) = x + C$ for all $x ∈ (a, b)$ . Initially I was going to let $f(x)=y$ then integrate it like a differential equation but my teacher said that wasn't allowed. Could I prove that the differential of $f(x)= x + C$ is equal to 1 ? Any help would be very much appreciated.","['derivatives', 'proof-writing', 'calculus']"
2057244,Inhomogeneous heat equation with Fourier transform,"Consider the heat equation $$\dfrac{\partial u}{\partial t}=\dfrac{\partial^2 u}{\partial x^2} +G(x,t).$$ with the condition $u(x,0)=f(x)$. When $G(x,t)=0$ it is quite easy to solve it using Fourier transform. Taking the Fourier transform in the $x$ variable we have $$\dfrac{\partial \hat{u}}{\partial t}=-4\pi^2 \xi^2 \hat{u}(\xi,t)$$ With the obvious solution $$\hat{u}(\xi,t)=A(\xi)e^{-4\pi^2\xi^2 t}.$$ If we then impose $u(x,0)=f(x)$ we get $\hat{u}(\xi,0)=\hat{f}(\xi)$ and hence $$\hat{u}(\xi,t)=\hat{f}(\xi)e^{-4\pi^2\xi^2 t}$$ Which upon introducing the heat kernel is the same as $u(x,t)=f\ast \mathcal{H}_t(x)$. So this is quite straightforward. Now, I'm trying to deal with the case $G\neq 0$, with $G\in \mathcal{S}(\mathbb{R}^2)$. I've found that the solution should be $$u(x,t)=f\ast \mathcal{H}_t(x)+\int_0^t \int_{-\infty}^{\infty} G(y,s)\mathcal{H}_{t-s}(x-y)dyds.$$ Now I really have no idea where this comes from. How does one arrive at this solution using Fourier transform? And how does one actually prove rigorously it is the desired solution?","['fourier-analysis', 'partial-differential-equations', 'mathematical-physics', 'ordinary-differential-equations', 'fourier-transform']"
2057249,"Representation with distinct egyptian fractions with ""small"" denominators","Suppose, I have a rational number $r$ with $0<r<1$, for example $$r=\frac{53143}{274851}$$ The goal is to write $r$ as a sum of DISTINCT egyptian fractions (fractions with numerator $1$). The greedy method (always take the smallest possible denominator) leads to the numbers $$[6, 38, 2706, 34382456, 4763382302120345, 385726786254606395971426367503080]$$ That means $$r=\frac{1}{6}+\frac{1}{38}+\frac{1}{2706}+\frac{1}{34382456}+\frac{1}{4763382302120345}+\frac{1}{385726786254606395971426367503080}$$ The greedy methods usually leads to very large denominators. I would like to have much smaller denominators. I read somewhere that no efficient algorithm is known to find the optimal representation in the sense, that the largest occuring denominator is as small as possible. But I am looking for a method finding a ""good"" representation in that sense. A much better solution in the given example would be : $$[8, 18, 80, 3792, 30539, 48251620]$$ The maximum entry has only $8$ instead of $33$ digits. Any ideas ?","['number-theory', 'summation', 'fractions']"
2057290,Oblongs into minimal squares,"Consider $a(n)$ , the minimal number of squares into which the oblong of size $(n+1)\times(n)$ can be divided. What is the behavior of $a(n)$ ? The first 379 terms of the oblong square packing sequence A279317 are known. 
We can guess that the largest oblongs divisible into 1, 2, 3, ... squares are at positions 1, 2, 3, 6, 10, 18, 34, 55, 104, 176, 307, 551, 969, 1698, 2925, 5210, 8730, 15130, 25678, 49582, with the first 11 verified.  Here are what those oblongs look like: For 551 and up, they are from the Catalogues of Simple Perfect Squared Rectangles , and it's purely a wild guess that maximal dissections beyond a certain size won't repeat a square size.  The following image of best dissections for oblongs 349 to 387 (from Filling rectangles with integer-sided squares ) shows that square values are repeated frequently. The second one, oblong 349, is first oblong requiring 14 squares.  The minimal oblongs needing 2, 3, 4, ... squares are at {1, 2, 3, 4, 9, 7, 16, 19, 44, 69, 113, 179, 349}. What are the first oblongs needing 15, 16, 17, 18 squares? Consider $b(n) = round(n^{1/3}) +6$ .  The rounded cube root seems to be tightly bound to $a(n)$ . Here's a plot of $b(n)-a(n)$ . This is sequence A321028 . $b(18)-a(18) = 2$ . All $b(n)-a(n)$ terms from there to $n$ =387 are -1, 0, 1. We can calculate $b(49582)-a(49582) = 22$ .  Is that an anomaly in general behavior, or do $b(n)$ and $a(n)$ diverge at some point? In addition to other sources above, much of this data is at Minimally Squared Rectangles . It was inspired by the Mondrian Upper Bound problem $-$ I wondered if other packing problems might have weird bounds. Oblong dissections are closely related to the Mrs. Perkins's Quilt problem.","['graph-theory', 'packing-problem', 'recreational-mathematics', 'combinatorics', 'oeis']"
2057302,Does there exist an uncountable set of pairwise disjoint crosses in the plane?,Does there exist an uncountable set of pairwise disjoint crosses in the plane? We define a cross to be two open line segments with one point of intersection. My initial thought is yes: For example pick any real $r$ on the x-axis and consider the line $x=r$. It seems as though we should always be able to find space on this line to draw a cross centred on it (as we can always draw finite sized crosses and move up and down the line to find space). We can therefore find a bijection between $ \mathbb{R} $ and the set of crosses by mapping the x coordinate of each crosses centre to the cross itself. Is this correct?,['elementary-set-theory']
2057321,Inverse laplace 2/((s-1)^2+1)^2,"Find inverse laplace transform of $$\frac{2}{((s-1)^2+1)^2}$$ I tried to decompose the fraction using $$\because (s-1)^2+1=s^2-2s+2$$ $$\rightarrow \frac{2}{((s-1)^2+1)^2}=\frac{As+B}{s^2-2s+2}+\frac{Cs+D}{(s^2-2s+2)^2}$$ yet I get D=2, which leads me back to the same exact equation, any help? (I have also tried the $\frac{-d}{ds}(L{\{sint\}})$ propertie, but failed since there's no variable s in the numerator)","['laplace-transform', 'ordinary-differential-equations', 'calculus']"
2057368,A question about a limit that should be solved by considering Riemann sums.,"I was hoping you guys could help me with a tough problem from my final exam. It stumped me. We are asked to evaluate: $$ \lim_{n\to\infty} \frac{1}{n}(e^{1/n}+e^{2/n}+e^{3/n}+\cdots+e^{n/n}) $$
As a hint they tell us we can think of this as a Riemann sum from $[0, 1]$ So then I think to myself that this looks awfully similar to the limits definition of an integral, so I tried rewriting it this way: $$ \int_{0}^{1} e^{1/x} dx $$ But then I couldn't solve the problem for the life of me. Where did I go wrong?! EDIT: Thanks to everyone who helped me solve the problem. For those who are wondering, I didn't write the correct integral above. To solve the problem successfully I should have done: $$ \int_{0}^{1} e^x dx $$ It sure is painful to miss the last problem on a final by such a slim margin!","['integration', 'calculus', 'limits']"
2057385,"The tangent cone of $V(f_1,\dots,f_s)$ is equal to $V(g_{1,min},\dots,g_{t,min})$ where $\{g_1,\dots,g_t\}$ is a standard basis for the local ring.","This is an exercise in ""Using Algebraic Geometry"" by Cox, et al. Let $V=V(f_1,\dots,f_s)$ be a variety containing the origin. Let $G=\{g_1,\dots,g_t\}$ be a standard basis for $I=\langle f_1,\dots,f_s\rangle k[x_1,\dots,x_n]_{\langle x_1,\dots,x_n\rangle}$ with respect to a degree-anticompatible order $>$. Show that $V(g_{1,min},\dots,g_{t,min})$ is the tangent cone of $V$ at the origin. The tangent cone of $V$ at the origin is defined to be 
$$C(V)=V(f_{min}: f\in I(V)),$$
where $f_{min}$ is the homogeneous component of the lowest degree of $f$. My attempt:
It is easy to show the direction $\subseteq$. Let $u\in C(V)$. Then $f_{min}(u)=0$ for all $f\in I(V)$. Since $g_i\in I$, it is obvious that $g_i\in I(V)$. So $g_{i,min}(u)=0$. This proves the inclusion $\subseteq$. For the other direction, let $u\in V(g_{1,min},\dots,g_{t,min})$ so that $g_{i,min}(u)=0$ for all $i$. Let $f\in I(V)$ so that $f^m\in I$ for some $m$. We claim that if $g\in I$, then $g_{min}\in\langle g_{1,min},\dots,g_{t,min}\rangle$. If the claim is true, then $(f^m)_{min}(u)=0$. Then the proof is done. My question: The field $k$ has to be algebraically closed for the bold part to be true. I cannot see how to proceed if it is not. To show the claim, I tried to use the following argument: Let $S=\{\text{LT}(f_{min}): f_{min}\not\in \langle g_{1,min},\dots,g_{t,min}\rangle\}$ and choose the minimal element. If the minimal element exists, I can finish the proof. But for a degree-anticompatible order, I cannot see that the minimal element exists. The degree can be infinitely large so there is no lower bound. What should I do? Thank you for any help!","['groebner-basis', 'algebraic-geometry', 'local-rings']"
2057391,"If f is a continuous function that's differentiable show that there exists $d∈(a,b)$ such that $f′(d)=0$","Hi all i'm struggling on this question and I don't know how to do it. Let $f : [a, b] → R$ be a continuous function that is differentiable on $(a, b)$. We assume that $f(a) < f(p)$ and $f(p) > f(b)$ for some $p ∈ (a, b)$. Show that there exists
$d ∈ (a, b)$ such that $f
'
(d) = 0.$ Any help would be very much appreciated","['derivatives', 'proof-writing', 'calculus']"
2057393,Alternatives to the politician theorem,"A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R and S are invited to a birthday party. We are told that: each pair of guests have exactly one common friend A and G only have one common friend: C A and G are friends I and C only have one common friend: A How many friends does the most popular (in terms of friends) guest have ? Invoking the politician/friendship theorem : it is straightforward that A has the most friends (18), as he is the common friend to all the guests. My question is: can anyone think of an alternative solution to this problem ?","['graph-theory', 'alternative-proof', 'puzzle', 'combinatorics', 'recreational-mathematics']"
2057408,How to check the differentiability of this function.,"Question: Let $\text{f(x) = max{1-x, 1+x, 2}}$. Prove that $f(x)$ is continuous at all points but not differentiable at $x = 1$ and $x = -1$. Doubt: I checked for the continuity of this function and successfully found it to be continuous at all points. For differentiability, at $x=1$, I calculated the right and left hand derivative using: $$f'(a)=\lim_{h\to0}\frac{f(a\pm h)-f(a)}{\pm h}.$$ For $Rf'(1)$, the value of $f(1+h)$ will be $\text{1+1+h}$ as $\text{1+x}$ is the maximum in this case. On solving, I am getting $Rf'(1)=1$. For $Lf'(1)$, the value of $f(1-h)$ will be $\text{2}$ as it is the maximum in this case. On solving, I am getting $Lf'(1)=\lim_{h\to0}\frac{2-2}{h}$. The case is similar with $\text{-1}$. But for $\text{x=0}$, I am getting both, Right and Left hand derivative similar to $\lim_{h\to0}\frac{2-2}{h}$. But according to question, the function is non-differentiable at only $\text{x=-1,1}$. Kindly help.","['derivatives', 'continuity', 'calculus', 'limits']"
2057412,How to know how many times the number of divisors for the numbers from 1-5000 are odd?,"I have a question I can not answer myself. For every number from 1-5000 I write down the number of divisors.
Example: 1 has 1 divisor, 2 has 2 and 10 has 4 (1, 2, 5, 10). I do this up to the number 5000. Know I want to know how many times the number of divisors is odd and how many times it is even. I am looking forward to your thougts!
Finn","['number-theory', 'divisibility', 'functions', 'arithmetic']"
2057457,Prove that $\lim_{x\to \frac{\pi}{2}}\sin{\frac{x}{2}} \cdot [\sin{x}] = 0$,"How can I prove: $$\lim_{x\to \frac{\pi}{2}}\sin{\frac{x}{2}} \cdot [\sin{x}] = 0$$ I know that for every $0<x<\pi$, where $x\neq \pi/2$,  $[\sin{x}]=0$ How can I go from here?",['limits']
2057498,Why do we want complete spaces? We don't we just use closed spaces?,"Why do we care about the notion of a space being complete? Why don't just consider closed spaces? If the space is closed we know that the limits of a sequence exist and are in the set which is a property that is obviously desirable. So what is the benefit in introducing this weaker notion of complete spaces and dealing with these weaker types of sequences called Cauchy sequences, as opposed to just using closed spaces and the stricter convergent sequences? What are we allowed to do with complete spaces that wouldn't be possible with closed spaces? It would also be interesting to hear the historical motivation for complete spaces if anybody is aware of it.","['general-topology', 'metric-spaces', 'cauchy-sequences', 'sequences-and-series']"
2057551,How to integrate this? triple integral over a region,"I need to use a triple integral to get the volume in the region bounded by $y=3-x$, $y=0$, $z=x^2$, $z=1$. I managed to plot the lines in the $xy$ plane: $y=0$ and $y=3-x$, then I got $z=0$ and $z=x^2$ in the xz plane. From this I saw that I can use the following boundaries: $x^2 \le z \le 1$ and $0 \le y \le 3-x$. However, I'm failing to see what are x boundaries. This is the Microsoft Mathematics plot I got (I had to rotate it a bit to get an idea of what was the region): Now, how should I go to find x boundaries? Is it ok to take $z=x^2$ and $z=1$ then solve $1=x^2$ to get that $x$ goes from $-1$ to $1$? In that case, this is what I did, and got a negative volume: Is that correct?","['multivariable-calculus', 'integration']"
2057562,How many ways are there to distribute 30 green balls to 4 persons?,How many ways are there to distribute 30 green balls to 4 persons if Alice and Eve together get no more than 20 and Lucky gets at least 7? The answer is: 2464 but I'm not sure how to get it?,"['number-theory', 'combinatorics', 'probability', 'discrete-mathematics']"
2057580,Example of Hessian of a function with respect to Riemannian metric?,"Can someone explain : how to take the Hessian of a function with respect to a riemannian metric? In other words, in Euclidean space, the hessian of a function $f: \mathbb{R}^n \to \mathbb{R}$ is simply $\text{Hess}f(x) = \nabla^2 f(x)$ , what is the difference when I move to $(\mathbb{R}^n, g)$ ? For instance : suppose I have a manifold $(\mathbb{R}^n, g)$ , $x \in \mathbb{R}^n$ , where $g$ is given by $g_{ij} = \dfrac{1}{x_i}\delta_{ij}$ . Then what is the Hessian of $f(x) = \sum\limits_{i = 1}^n x_i\log(x_i)$ with respect to this metric? Even better, if someone can tell me how to compute the gradient of $f$ under this metric! Any reference on examples to compute the gradient and hessian of functions on Riemannian manifolds will be greatly appreciated! Disclaimer: know almost nothing about riemannian geometry","['manifolds', 'riemannian-geometry', 'differential-geometry']"
2057600,Change of variables in Lebesgue differentiation theorem,"Lebesgue differentiation states that: If $f\in L_{loc}^1(\mathbb{R}^n)$, then
  $\lim_{r\rightarrow0}\frac{1}{|B(x,r)|}\int_{B(x,r)}f(y)dy=f(x)$ I am considering if the following is true: $$\lim_{r\rightarrow0}\frac{1}{|B(0,r)|}\int_{B(0,r)}f(x-t)dt=f(x)$$","['real-analysis', 'measure-theory']"
2057616,Probabilties using Central Limit Theorem,"Let n be an independent random variables and the number of orders in a 120 minute period. Given that $\mu$ is 1.5 minutes and that $\sigma$ is 1 minute use the Central Limit Theorem to find the Largest Value of n which gives a 95% chance of completion in that time. I understand that the mean time per order is 1.5 minutes with a deviation of 1 minute, but I am unsure how to find this without using trial and error. I'm thinking that it's something along the lines of $0.95=P(\frac{X-1}{1.5}<\frac{x_{0.95}-1}{1.5})$ How does this differ from the Chebyshev Inequality in terms of result?","['real-analysis', 'probability-theory', 'chebyshev-polynomials', 'central-limit-theorem', 'probability']"
2057620,How to integrate standard normal cdf to nth power,"I'm struggling to find a way to integrate $\Phi^n(a_nx + b)$ (I have values for $a_n$ and $b_n$) I have got $(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{a_nx+b} \exp(-\frac{y^2}{2}) dy)^n$ but I am unsure on how to proceed. Eventually I would need to show that this integral tends to $exp(-exp(-x))$ as $n \to \infty$. Any help would be greatly appreciated! (Apologies for the poor format, I've not used MathJax before)","['statistics', 'integration', 'normal-distribution']"
2057661,Finding the minimal polynomial of a matrix in the real vector space of continuous real-valued functions.,"I'm studying for a linear algebra final and I'm working through some old test problems: In the real vector space of continuous real-valued functions defined on $\mathbb{R}$ consider the following functions $p_i, i =0,1,2$ and $\exp$ defined as follows: $p_i(x)=x^i$ and $exp(x)=e^x$ for all $x\in \mathbb{R}$. Set $V=span_\mathbb{R}\{p_0,p_1,p_2,\exp\}$ and consider the endomorphism $\sigma: V\to V$ defined as $$(\sigma f)(x):= f(x-1) \text{ for all } x\in \mathbb{R}$$
   Determine the matrix representation, characteristic polynomial, eigenspaces, and the minimal polynomial of $\sigma$. Is $\sigma$ diagonalizable? I think I've got everything but the minimal polynomial (please correct me if I'm wrong). I've determined that the matrix representation is $$A:=[\sigma]_\beta^\beta = \begin{pmatrix}
1 & -1 & 1 & 0\\
0 & 1 & -2 & 0\\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & e^{-1} 
\end{pmatrix} $$
Also, the characteristic polynomial $\chi_A = (x-1)^3(x-e^{-1})$ and I found the eigenspaces to be $$\left\langle \begin{pmatrix}
p_0\\
0\\
0\\
0
\end{pmatrix} \right\rangle \text{ and } \left\langle \begin{pmatrix}
0\\
0\\
0\\
\exp
\end{pmatrix} \right\rangle$$
Thus since the eigenvalue $1$ has algebraic multiplicity $3$ but geometric multiplicity $1$, $\sigma$ is not diagonalizable. I know that the minimal polynomial $M_A$ divides $\chi_A$, so $M_A$ is either $(x-1)(x-e^{-1})$, $(x-1)^2(x-e^{-1})$ or $(x-1)^3(x-e^{-1})$. In theory, I know that if the polynomial with smallest degree with $A$ as a root is the minimal polynomial, but to check this seems computationally cumbersome for a paper and pencil exam. Is there some better way?","['matrices', 'linear-algebra', 'minimal-polynomials']"
2057663,"Discrete Maths: Inclusion Exclusion - patterns “spin”, “game”, “path” or “net”","This is a question from Discrete and combinatorial mathematics by Ralph Grimaldi. This question is related to Inclusion Exclusion Principle. Question - Find the number of permutations of a, b, c, ....x, y, z (26 letters)
  in which none of the patterns “spin”, “game”, “path” or “net” occurs. Answer given in the book - N(c¯1 c¯2 c¯3 c¯4) = 26! − [3(23!) + 24!] - (20! + 21!) (Why does the answer have two consecutive negative signs ? Isn't it supposed to alternate between the terms.) My solution - Let c1, c2, c3 and c4 be the set of permutations where “spin”, “game”,
“path”or “net” occurs respectively. Therefore, we need to determine N(¯c1c¯2c¯3c¯4).  
Clearly, N = 26!, 
N(c1) = N(c2) = N(c3) = (26−4+1)! = 23!
N(c4) = (26−3+1)! = 24! 
Similarly, N(c1c2) = N(c1c3) = N(c2c3) = (26 − 8 + 2)! = 20! 
N(c1c4) = N(c2c4) = N(c3c4) = (26 − 7 + 2)! = 21!
N(c1c2c3) = = (26 − 12 + 3)! = 17!
N(c1c2c4) = = (26 − 11 + 3)! = 18!
N(c1c2c3c4) = = (26 − 15 + 4)! = 15!
N(c¯1 c¯2 c¯3 c¯4) = 26! − [3(23!) + 24!] + [3(20!) + 3(21!)) - [17! + 18!] + 15! I searched on Google and found a solution here 1) I am unable to understand why the terms for N(c1c2c3), N(c1c2c4) and N(c1c2c3c4) are missing in the final answer. 2) Why does the answer have two consecutive negative signs? Isn't it supposed to alternate between the terms. (Look at Grimaldi's solution)","['permutations', 'inclusion-exclusion', 'discrete-mathematics']"
2057683,How to prove that sample of size $O(\epsilon^{-2} log \delta^{-1})$ is enough to predict quantiles?,"There is a known problem: You are given a stream of numbers and you need to find it's $q$-th quantile ($0 \le q \le 1$). You may get wrong answer but you need to return answer between $q-\epsilon$-th and $q+\epsilon$-th quantiles with probability at least $1 - \delta$. In several articles I've found statement that if you get random sample of size $O(\epsilon^{-2} log \delta^{-1})$ and you'll find it's $q$-th quantile and return it as the answer to original problem, you'll get what is needed i.e answer between $q-\epsilon$-th and $q+\epsilon$-th quantiles with probability at least $1 - \delta$. I've seen this mentioned in several places, for example, Quantiles on Streams by Chiranjeeb Buragohain et al. Approximate Medians and other Quantiles in One Pass and with... by Gurmeet Singh Manku et al But I didn't manage to either prove it myself of trace the source. Any ideas how to prove that?","['probability-theory', 'quantile', 'asymptotics', 'probability-distributions', 'statistics']"
2057685,Is this a bad proof for Cauchy mean value theorem or is it valid?,"By MVT, $$\frac{f(b)-f(a)}{b-a}=f'(c)$$
$$\frac{g(b)-g(a)}{b-a}=g'(c)$$
so, $$\frac{f(b)-f(a)}{g(b)-g(a)} = \frac{\frac{f(b)-f(a)}{b-a}
}{\frac{g(b)-g(a)}{b-a}}=\frac{f'(c)}{g'(c)}$$ I think it is not a valid proof but I am having a discussion with a classmate and I am not sure anymore...","['calculus', 'analysis']"
2057690,Is every recursively enumerable set many-one reducible to $L_\text{b}$?,"A URM $M$ b-accepts an input $x$ if in the overall course of its computation on $x$, the register $R_1$ contains only finitely many different values (thus, if $M$ halts on $x$, it always b-accepts, but the converse is not necessarily true). Let$$L_\text{b} := \{(x, y) : M_x \text{ b-accepts }y\}$$($M_x$ is the URM with code $x$). Is every recursively enumerable set many-one reducible to $L_\text{b}$?","['computer-science', 'formal-languages', 'logic', 'elementary-set-theory', 'computability']"
2057701,"Functions, sets, isomorphism","Determine the functions $ f:\mathbb{R}^{*}\rightarrow \mathbb{R} $ for which $ G=\left \{ \begin{pmatrix}
x & f(x)\\ 
 0& 1
\end{pmatrix}|x\in \mathbb{R}^{*} \right \} $ is closed under multiplication of matrices from $ M_{2}(\mathbb{R}) $. In this case, prove that groups $ (G,\cdot ) $ and $ (\mathbb{R}_{+}^{*},\cdot ) $ are isomorphic. I think that $ f(x)\cdot f(y)=x\cdot f(y)+f(x) $, but I don't know what to do next.","['abstract-algebra', 'group-theory', 'functions']"
2057709,Isomorphic groups but not isomorphic rings,"Provide an example of two rings that have the same characteristic, are isomorphic as groups but are not isomorphic as rings.
I'm confused with how to being. I know that having the same characteristic means that the concatenation is the same number to receive the zero element.","['abstract-algebra', 'ring-theory', 'examples-counterexamples']"
2057730,Determine the distribution of the sum of n independent identically distrubted poisson random variable $X_i$?,"Determine the distribution of the sum of n independent identically distributed Poisson random variable $X_i$ ~ $\mathsf{Poisson}(\lambda)$, $ i = 1, ...., n$? My approach is that since it is independent identically and the sum is basically 
$X_1 + X_2 + ... + X_n$ we can just use moment generate function to find it. So $M_x (t) = E e^{xt} = e^{-\lambda} * e^{e^{\lambda*t} },$ which is just basically that to the $n$ power. Can anyone confirm that I'm on the right path?","['statistics', 'order-statistics', 'poisson-distribution']"
2057770,Higher order partial derivatives of implicit function?,"Given the surface $z = f(x,y)$, with parameterization $x = u + v^2$, $y = u^2 - v^3$, $z = 2uv$ near the point $(3,3,4)$ which corresponds to the point $(2,1)$ in the $uv$-plane, find $\frac{\partial^2 f}{\partial x \partial y}(3,3)$. I'm familiar with using Jacobians to find first partial derivatives, but not how to find higher order partial derivatives of multivariate implicit functions .","['multivariable-calculus', 'implicit-function-theorem', 'partial-derivative']"
2057804,Why is this an essential singularity?,"I have the following complex function: $$f(z)=\frac{\cos\left(\frac{\pi z}{2}\right)\sin\left(\frac{1}{z}\right)}{(z^2-1)(z-2)}$$ I kind of shown that $z=\pm 1$ and $z =2$ are simple poles. However I don't know how to show that $z=0$ is an essential singularity. How do I even find the Laurent series of $sin\left(\frac{1}{z}\right)$ around $0$? I know started from the Taylor expansion $$\sin(z)=\sum_{n=0}^{\infty}\frac{(-1)^kz^{2k+1}}{(2k+1)!}$$ and then I wrote it for $\sin\left(\frac{1}{z}\right)$ $$\sin\left(\frac{1}{z}\right)=\sum_{n=0}^{\infty}\frac{(-1)^k}{(2k+1)!z^{2k+1}}$$ but then I don't know how to find the Laurent series of it, shouldn't it be from $-\infty$ to $\infty$? All I can do here seems to be $$\sin\left(\frac{1}{z}\right)=\sum_{n=0}^{\infty}\frac{(-1)^kz^{-(2k+1)}}{(2k+1)!}$$ which has negative exponents only? Can you help me?","['laurent-series', 'complex-analysis', 'singularity']"
2057845,"Find shortest vectors $u_1,v_1,\cdots,u_N,v_N$ such that $\langle u_i,v_j\rangle=1$ if $i\le j$ and $\langle u_i,v_j\rangle=0$ if $i>j$","The following problem has come up in my work. Any help would be appreciated. Problem. Given $N \in \mathbb{N}$ , find vectors $u_1, u_2, \cdots, u_N, v_1, v_2, \cdots, v_N \in \mathbb{R}^d$ which satisfy $$\forall i,j \in \{1, 2, \cdots, N\} ~~~~~~~~~~ \langle u_i, v_j \rangle = \left\{ \begin{array}{cl} 1 & \text{if } i \leq j \\ 0 & \text{if } i > j \end{array} \right.$$ and which minimize $$A := \max_{i,j \in \{1, 2, \cdots, N\}} \|u_i\|_2 \cdot \|v_j\|_2.$$ Let $A_*(N)$ denote the optimal value of $A$ for a given value of $N$ . I'm mainly interested in the asymptotic behavior of $A_*(N)$ as $N \to \infty$ . I don't care what $d$ is. (EDIT: To be clear, $A_*(N)$ is defined to be the infimum -- taken over all $d \in \mathbb{N}$ and all $u_1, \cdots, u_N, v_1, \cdots, v_N \in \mathbb{R}^d$ satisfying the constraint -- of the objective $A$ . That is, I place no constraint on $d$ . Note that $d$ must depend on $N$ ; in particular, $d \geq N$ is necessary for the constraint to be satisfiable. However, without loss of generality, $d = 2N$ : If $d<2N$ , we can add superfluous dimensions. If $d>2N$ , then we can project the solution to the space spanned by $\{u_1, \cdots, u_N, v_1, \cdots, v_N\}$ , which has dimension at most $2N$ .) Question. What is $A_*(N)$ ? In particular, what is $$c_* := \limsup_{N \to \infty} \frac{\log A_*(N)}{\log \log N}~~~?$$ The value $c_*$ is what I really want to know, as it governs the asymptotics. i.e. $A_*(N) \approx (\log N)^{c_*}$ . I can prove $0 \leq c_* \leq 1$ . Any improved bounds (such as showing $c_*>0$ or showing $c_*<1$ ) would be really helpful. By Cauchy-Schwartz, $A_*(N) \geq \|u_1\|_2 \cdot \|v_1\|_2 \geq \langle u_1, v_1 \rangle = 1$ and, hence, $c_* \geq 0$ , but I have no nontrivial lower bound. The obvious upper bound is to let $u_1, \cdots, u_N$ be the standard basis vectors and then let $v_j = \sum_{i=1}^j u_i$ . Unfortunately, this only shows $A_*(N)\leq\sqrt{N}$ ; we can do better: The following inductive construction shows $A_*(N) \leq \lceil \log_2 N \rceil + 1$ and, hence, $c_* \leq 1$ . We will construct a solution for powers of $2$ i.e. $N=2^n$ with $n \in \mathbb{N}$ . The solution we construct will be denoted $u_1^n, \cdots, u_{2^n}^n, v_1^n, \cdots, v_{2^n}^n \in \mathbb{R}^{2^{n+1}-1}$ . The base case is $u_1^0 = v_1^0 = (1)$ . For $n \geq 1$ and $1 \leq i \leq 2^{n-1}$ , define $$u_i^{n} = \left( \begin{array}{c} 1 \\ u_i^{n-1} \\ 0^{2^{n}-1} \end{array} \right), ~~~~~~~~ u_{2^{n-1}+i}^{n} = \left( \begin{array}{c} 0 \\ 0^{2^{n}-1} \\ u_i^{n-1} \end{array} \right), ~~~~~~~~ v_i^{n} = \left( \begin{array}{c} 0 \\ v_i^{n-1} \\ 0^{2^{n}-1} \end{array} \right), ~~~~~~~~ v_{2^{n-1}+i}^{n} = \left( \begin{array}{c} 1 \\ 0^{2^{n}-1} \\ v_i^{n-1} \end{array} \right),$$ where $0^m \in \mathbb{R}^m$ denotes the $m$ -dimensional zero vector. It is easy to verify inductively that this construction satisfies the constraint and achieves $\|u_i^n\|_2 \leq \sqrt{n+1}$ and $\|v_i^n\|_2 \leq \sqrt{n+1}$ for $1 \leq i \leq 2^n$ , as required to show $A_*(2^n)\leq n+1$ . Clearly, $A_*$ is an increasing function. Hence $A_*(N) \leq A_*\left(2^{\lceil \log_2 N \rceil}\right) \leq \lceil \log_2 N \rceil +1$ for all $N \in \mathbb{N}$ , as desired.","['linear-algebra', 'inner-products']"
2057857,Equivalence Relation...,"I am trying to complete my homework based on equivalence relation and I don't seem to understand it properly so I need help ! My question is that do all the elements in my set must satisfy all the three conditions then I can say there is an equivalence relation or I can say there is an equivalence relation of just some of the elements satisfy the three conditions and does the order matter do I have to compare the element from the left to the right or can I pick randomly e.g. my set=( 0,2,4,6)  relation defined as a~b if a+b>2 so if I start by oder I can say that 0 is not related to 2 because 0+2=2 but if I pick randomly I can state that 6~0 because 6+0>2 and u can see that some of the elements satisfy the conditions but not all of them so do I still say there is an equivalence relation ?? I am really confuse Thank you","['equivalence-relations', 'relations', 'discrete-mathematics']"
2057903,Mean and mode of a Beta random variable,"A continuous random variable is said to have a $Beta(a,b)$ distribution if its density is given by $f(x) = (1 / \text{B}(a,b))x^{a-1} (1-x)^{b-1}$ if $0 < x < 1$ Find mean , var, mode if $a = 3, b = 5.$ This is throwing me off with the beta distribution. I'm not sure if it changes the way i solve for the mean, var , mode. My approach is that since mean of a continuous random variable which is basically the Expected value of X (EX), so we can just do $\int x * f(x) dx$. We can find $ f(x) = (105) x^{2} (1-x)^{4} $ and then $\int x *f(x) dx =  1/105 \int_{0}^{1} x^3 * (1-x)^4 dx  = 105 * \beta(4,5)  =  105 * ((6*24 )/ 40320)$","['statistics', 'random-variables']"
2057910,Limit of $\left(1-\frac{1}{2^2}\right)\left(1-\frac{1}{3^3}\right)\dots \left(1-\frac{1}{n^n}\right)$ as $n\to \infty$,"So I'm trying to solve the following limit: $$\lim_{n \to \infty}\left(1-\frac{1}{2^2}\right)\left(1-\frac{1}{3^3}\right)\dots \left(1-\frac{1}{n^n}\right)$$ Now, I tried getting the squeeze theorem around this one, since it does feel like something for the squeeze theorem. The upper bound is obviously $1$, but since each term decreases the product, it may seem like this approaches zero?","['real-analysis', 'limits']"
2057946,Does non-empty pairwise intersection of intervals imply non-empty infinite intersection of intervals?,"For each $n \in \mathbb{N}$ a closed interval $[x_n, y_n]$ is given.
  Assume that $[x_m, y_m]\, \cap \, [x_n, y_n] \neq \emptyset$ for all
  $m,n \in \mathbb{N}$. Show that $\bigcap_{n=1}^{\infty} [x_n, y_n] \neq \emptyset$. What I've done is, assumed for contradiction that $\bigcap_{n=1}^{\infty} [x_n, y_n] = \emptyset$ which implies the existence of some disjoint intervals, i.e: that there exists $m,n \in \mathbb{N}$ such that $[x_m, y_m] \, \cap \, [x_n, y_n] = \emptyset$ which contradicts our hypothesis. Now, I think this is wrong because it (i) makes the problem far too easy and (ii) infinities are fishy, I'm not convinced that the infinite intersection of intervals being empty implies that there exists at least two disjoint intervals. Question: Is my ""proof"" completely off the right train of thought? How do I fix it?","['real-analysis', 'elementary-set-theory']"
2057965,Prove $\lim \limits_{n \to \infty}\frac{n!}{n^n}=0$ [duplicate],"This question already has answers here : Compute the limit $\lim_{n \to \infty} \frac{n!}{n^n}$ [duplicate] (3 answers) Closed 7 years ago . Prove $\lim \limits_{n \to \infty}\frac{n!}{n^n}=0$.  I have tried this several ways.  I tried using the ratio test, I tried to expand it... I'm not really sure where to go. When I expand, I get $$\frac{n(n-1)(n-2)(n-3).....}{nnnnnn......}$$ I don't know if trying to expand this is helpful, but I'm just not sure where to go with this problem... Any help would be appreciated.","['real-analysis', 'limits', 'calculus', 'factorial', 'sequences-and-series']"
2057991,"A simple mathematical expression for the periodic sequence $(1, -2, -1, 2, 1, -2, -1, 2,\dots)$","The sequence is just $S_n=1, -2, -1, 2$ repeated indefinitely. The best I can do is: $$S_n= \frac{(i - 2)\,i^n}{2i}  + \frac{(i+2)\,(-i)^n}{2i}  $$ where $i$ is the imaginary unit. In fact, this expression is where the sequence comes from. Can it be simplified, like using $(-1)^n$ for an alternating sequence of $1$ and $-1$? These values appear as part of a larger formula . Currently, I am simply using a more computational expression: V(n) = the (n modulo 4)'th element of [+1,-2,-1,+2] , but this is rather hacky.","['sequences-and-series', 'complex-numbers']"
2058057,Prove the inequality $\left|\frac{m}{n}-\frac{1+\sqrt{5}}{2}\right|<\frac{1}{mn}$,"Prove that the inequality $$\left|\frac{m}{n}-\frac{1+\sqrt{5}}{2}\right|<\frac{1}{mn}$$ holds for positive integers $m, n$ if and only if $m$ and $n$ where $m > n$ are two successive terms of the Fibonacci sequence. I thought about using the explicit formula for the Fibonacci sequence, which is $$F_n = \dfrac{1}{\sqrt{5}}\left(\left(\dfrac{1+\sqrt{5}}{2}\right)^n-\left(\dfrac{1-\sqrt{5}}{2}\right)^n\right),$$ but this seems to get computational. Is there an easier way to think about this?","['number-theory', 'diophantine-approximation']"
2058067,Why is the residue field of a $k$-scheme an extension of $k$?,"Let $k$ be any field and let $X$ be a scheme over $k$. For each $x$, the residue field $\kappa(x)$ is a field extension of $k$. Why is this true? My understanding is that a scheme over a field really just amounts to a ring homomorphism $k \rightarrow O_X(X)$, so $O_X(X)$ is a $k$-algebra. My understanding of the residue at a point $x$ is that, since $X$ is by definition covered by affine schemes, $x$ is a prime ideal $P$ in some ring $A$. Then the localization of $A$ at the prime ideal corresponding to $x$ has a unique maximal ideal, and the quotient is called $\kappa(x)$. I don't see how from this, $\kappa(x)$ is a field extension of $k$. Edit: I thought about it a bit longer and the reasoning I have is this. A morphism $X \rightarrow$ Spec $k$ defines a homomorphism $k \rightarrow O_X(U)$ for every open $U \subset X$. The localization of $A$ at $P$ is isomorphic to the stalk $O_P$ (theorem in Hartshorne) and since $O_P$ is the direct limit of a system of $k$-algebras, it too is a $k$-algebra, so there is a map $k \rightarrow A_P$. Then this gives a map $k \rightarrow \kappa(x)$. But it does seem a bit complicated.",['algebraic-geometry']
2058070,Proof of a change-of-measure formula,"I was asked by someone with the following problem: Suppose $X$ and $Y$ are compact metric spaces and $F: X \to Y$ is a continuous map from $X$ onto $Y$. If $\nu$ is a finite measure on the Borel sets of $Y$, prove that there exists a measure $\mu$ on the Borel sets of $X$ such that
  $$\int_Y f \, d\nu = \int_X f \circ F \, d \mu \tag{1}$$
  for all $f$ that are continuous on $Y$. To me, equation $(1)$ bears very resemblance to the classic change-of-variable formula in measure theory:
$$\int_X f \circ F\,d\mu = \int_Y f \,d \nu \tag{2}.$$ However, in $(2)$, the measure $\mu$ is known first and the induced measure $\nu$
is defined through $\mu$ and $F$ (in fact, $\nu = \mu \circ F^{-1}$.). In addition, to prove $(2)$, we do not need the compactness, continuous and onto conditions given in the problem --- all we need are that $\mu$ is a finite measure and $F$ is measurable, then $(2)$ holds for any integrable $f$. 
Therefore, it looks like $(1)$ is another version of $(2)$, with seemingly stronger conditions but the more restricted conclusion (but again, the orders of
measures $\nu$ and $\mu$ are essentially opposite.). It is said this is a problem from probability, but the typical tricks used in 
probability do not work for me. In particular, I don't know how to deploy the 
continuity condition. I appreciate any hint.","['probability-theory', 'integration', 'measure-theory']"
2058096,How to prove that the following function is increasing?,"I'm trying to prove that the function $f(t)=t\ln(1+\frac{k}{t})$; with $k\geq 0$ is increasing for $t>0$. I calculated the derivative and obtained $f'(t)=\ln(1+\frac{k}{t})-\frac{k}{t+k}$, but I don't know how to conclude that $f'(t)\geq0$ for $t>0$. Can someone help me, please?","['derivatives', 'calculus', 'functions']"
2058120,Graph $\text{Im}\left(\frac{1}{z}\right)=1$,"I used the identity $z=x+iy$ which resulted in $\text{Im}\left(\frac{1}{x+iy}\right)$. Multiplying by the conjugate, I found that this was equal to $\text{Im}\left(\frac{x-iy}{x^2+y^2}\right)$, which by splitting this fraction into two terms is $\frac{-y}{x^2+y^2}=1$. Multiplying I found $-y=x^2+y^2$ which I think is the equation of a circle. Can somebody tell how to graph this equation in the complex plane?","['complex-analysis', 'graphing-functions']"
2058156,Closed line integral of conservative field not zero?,"show that if $\mathbf{F}(x,y)=\frac{-y\mathbf{i}+x\mathbf{j}}{x^2+y^2}$, then $\oint\mathbf{F}\dot{}d\mathbf{r}=a\pi$ for every
simple closed path that encloses the origin. Find the constant $a$. I first calculated the curl of the vector field and it was $\mathbf{0}$. Which means that there exists a scalar field $f$ such that $\mathbf{F}=\nabla f$ So the integral becomes $\oint\mathbf{\nabla }f\dot{}d\mathbf{r}=f(\mathbf{r(a)}-f(\mathbf{r(a)})=0)$ and Hence $a=0$.. But apparently the mark scheme says it should be $a=2$. Any idea where I am going wrong?","['multivariable-calculus', 'stokes-theorem', 'greens-theorem', 'line-integrals']"
2058158,Using principle of inclusion-exclusion to solve for number of possible combinations,"Of n containers and n objects, each container is assigned a ""right"" object and each container can hold no less or more than one object (no empty containers). How many possible combinations are there of containers and objects of size n where each container contains an object, but no container contains the ""right"" object? The possible number of combinations of at least k containers of n total containers containing the right object is $\begin{pmatrix} n \\ k \end{pmatrix}(n-k)!$, where $\begin{pmatrix} n \\ k \end{pmatrix}$ is the number of unique combinations of selected object of at least k objects in the correct container of n containers. $(n-k)!$ is the number of unique combinations of remaining containers of each one of the unique combinations. (example n = 4, k = 1) $\begin{pmatrix} 4 \\ 1 \end{pmatrix}(4-1)! = 4(6) = 24$ 
$$\begin{array}{|c|c|c|c|}
\hline
\textbf{A}BCD & A\textbf{B}CD & AB\textbf{C}D & ABC\textbf{D} \\ 
\hline
\textbf{A}BDC & A\textbf{B}DC & AD\textbf{C}B & ACB\textbf{D} \\ 
\hline
\textbf{A}CBD & C\textbf{B}AD & BA\textbf{C}D & BAC\textbf{D} \\ 
\hline
\textbf{A}CDB & C\textbf{B}DA & BD\textbf{C}A & BCA\textbf{D} \\ 
\hline
\textbf{A}DBC & D\textbf{B}AC & DA\textbf{C}B & CAB\textbf{D} \\ 
\hline
\textbf{A}DCB & D\textbf{B}CA & DB\textbf{C}A &  CBA\textbf{D}\\ 
\hline
 \end{array}
$$ Principle of inclusion/exclusion
$$|\bar{A}_1 \bigcap \bar{A}_2\bigcap ... \bar{A}_n\bigcap| = |\mathcal{U}| - \sum\limits_{i=1}^n |A_i| + \sum\limits_{i \neq j}^n |A_i \bigcap A_j|+...+(-1)^n|A_1\bigcap A_2\bigcap ... A_m|$$ Apply principle of inclusion/exclusion(PIE) with formula for possible combinations of n containers of k object in correct container: $(-1)^k\begin{pmatrix} n \\ k \end{pmatrix}(n-k)!$ $$D_n = n! - \begin{pmatrix} n \\ 1 \end{pmatrix}(n-1)! + \begin{pmatrix} n \\ 2 \end{pmatrix}(n-2)! - \begin{pmatrix} n \\ 3 \end{pmatrix}(n-3)! + . . . . .  + (-1)^k\begin{pmatrix} n \\ k \end{pmatrix}(n-k)! + . . .  + (-1)^n\begin{pmatrix} n \\ n \end{pmatrix}(n-n)!
= \sum\limits_{k=0}^n (-1)^k \begin{pmatrix} n \\ k \end{pmatrix}(n-k)!$$ Replace binomial coefficient with $\frac{n!}{k!(n-k)!}$
$$D_n = \sum\limits_{k=0}^n (-1)^k \begin{pmatrix} \frac{n!}{k!(n-k)!}\end{pmatrix}(n-k)!$$ Reduce fraction.
$$D_n = \sum\limits_{k=0}^n (-1)^k \begin{pmatrix} \frac{n!}{k!}\end{pmatrix}$$
Since n! is a constant, it can be removed from sum and placed out front.
$$D_n = n! \sum\limits_{k=0}^n (-1)^k \begin{pmatrix} \frac{1}{k!}\end{pmatrix}$$ Substitute $\sum\limits_{k=0}^n \frac{-1^k}{k!}$ with $e^-1$ $$D_n = n! e^{-1} = \frac{n!}{e}$$ D_n needs to be an integer instead of a rational number. Any ideas? Maybe estimating an alternating series theorem could be applied here?","['combinatorics', 'discrete-mathematics']"
2058159,"Use case of integral of differential forms on ""chains""","I'm studying Spivak's Calculus on Manifolds. There the integration of $k$-forms on $k$-chains is defined and Stokes' theorem on chains is also proved, but they are never used for other theorems. I also cannot imagine where to use it in applications or maths. Why do we need to define $k$-chains? Where can I use it? A related question, but not answered, is here: What's the advantage of defining the integral of a $k$-form over a $k$-chain?","['differential-forms', 'differential-geometry']"
2058191,What $X$ should be homeomorphic to?,"Consider $X = \{ (x,y,z) \in \mathbb C^3 \mid x^2 + y^2 + z^2 = 1 \}$.
I want to find a ""known"" space which is homeomorphic to $X$. A point in $X$ is two real vectors $a,b \in \mathbb R^3$ such that $\langle a,b \rangle = 0$ and $\sum a_i^2 = \sum b_i^2 + 1$. 
I don't see what can I say more about the last equation ... I know a similar space was a disk bundle over a $3$-sphere, maybe this is the same here ?",['general-topology']
2058212,$\int f(x) dx\cdot \int \frac{1}{f(x)}dx = c$ where $c$ is a constant. Find $f(x)$,"$$\int f(x) dx\cdot \int \frac{1}{f(x)}dx = c$$ where $c$ is a constant. Find $f(x)$. Off first glance it seems that $f(x)$ is some form of $e^x$, but how does one go about doing this analytically (only 1 mark for guessing). I took the derivative of this but the resulting function was still ugly. I thought maybe treating it as a first order linear differential equation would work, but I wasn't sure how to put it in the form $y' + P(x)y = Q(x)$",['integration']
2058225,Tangent plane to the surface equation,"Find an equation of the tangent plane to the surface $$(u,v)=\langle u^2+v^2,2uv,u^3\rangle$$at the point$$(5,4,1)$$
i know the tangent equation, you need the partial of x and y.. plug in the points. plug back into equation and bam, easy and done. but thats when you are given a normal function... why does this look so confusing? do i have to calculate something else? edit: I am not sure if i am over thinking it, or if what i did is correct. please help clarify
$$ f_u=2u+2v+3u^2 $$ $$f_v=2v+2u$$plugged 5 and 4 in (for u and v) $$\langle 10,8,75\rangle\langle 8,10,0\rangle$$ took the cross product to find a vector.. and thats what i used in the tangent equation. Did i go about this correctly..?","['derivatives', 'partial-derivative', 'calculus']"
2058240,Ergodic theorem in Markov chains: for which probability $P$ is the convergence $P$-a.s.?,"I am asking about a proof of the Ergodic theorem for Markov chains from page 7 here . Remember that the Ergodic theorem for Markov chains says that, if $\{X_n\}_{n\geq0}$ is an irreducible Markov chain, then for every state $i$: $$\lim_n \frac{V_i(n)}{n}=\frac{1}{m_i}\;\text{ a.s.},$$where $V_i(n)=\sum_{k=0}^{n-1}1_{\{X_k=i\}}$ is the number of visits to $i$ before time $n$, and $m_i=E[T_i|X_0=i]$, where $T_i=\inf\{n\geq 1: X_n=i\}$. What I do not understand is under which probability it is written that a.s. From the statement in the link, it seems that is under the probability of the underlying probability space. However, when applying the strong law of large numbers in the recurrent case, it seems that it is under $P_i=P|_{X_0=i}$. In the proof it is said something about this (just before the paragraph starting by ""By Lemma 3.2$\ldots$""), but I would like more details.","['markov-chains', 'probability-theory', 'probability']"
2058249,Geometric reason why even unimodular positive definite lattices exist only in dimensions divisible by $8$,"It is a well-known fact that even unimodular rank $n$ lattices $L\subseteq \mathbb{R}^n$ only exist if $8\vert n$. The only proof of this that I know (in the book ""Elliptic functions and modular forms"" by Koecher/Krieg) is rather ingenious and uses the modularity of the associated theta function $$\Theta(\tau,L)=\sum_{\gamma\in L}e^{i\pi\Vert \gamma\Vert^2}$$ to conclude that 
$$\Theta(i,L)=e^{\frac{i\pi n}{4}}\Theta(i,L)$$
and hence $8\vert n$. While it is quite natural to associate a theta function to a lattice, it seems to me that there has to be a deeper, somehow ""purely geometric reason"" for this phenomenon (i.e. the condition on the dimension) which does not use the theory of modular forms. So my question is the following: What is the ""geometric"" reason why even unimodular positive definite lattices exist only in dimensions divisble by $8$? (I am aware that the term ""geometric"" is not well-defined and can be interpreted broadly: feel free to do so)","['number-theory', 'integer-lattices', 'soft-question', 'modular-forms']"
2058383,Limit of ${n^2 \choose n}/{n^2+n-1 \choose n}$,I am trying to work out $$\lim_{n \to \infty} \frac{{n^2 \choose n}}{{n^2+n-1 \choose n}}.$$ Numerically it appears to be approximately $0.377$.  Is it possible to get an exact answer?,"['asymptotics', 'limits']"
