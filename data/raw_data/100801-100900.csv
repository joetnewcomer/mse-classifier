question_id,title,body,tags
1398965,Evaluate $\int e^x \sin^2 x \mathrm{d}x$,"Is the following evaluation of correct? \begin{align*} \int e^x \sin^2 x \mathrm{d}x &= e^x \sin^2 x -2\int e^x \sin x \cos x \mathrm{d}x \\ &= e^x \sin^2 x -2e^x \sin x \cos x + 2 \int e^x (\cos^2 x - \sin^2x) \mathrm{d}x \\ &= e^x \sin^2 x -2e^x \sin x \cos x + 2 \int e^x (1 - 2\sin^2x) \mathrm{d}x \\ &= e^x \sin^2 x -2e^x \sin x \cos x + 2 \int -2 e^x  \sin^2x \mathrm{d}x + 2 e^x \\ &= e^x \sin^2 x -2e^x \sin x \cos x  + 2 e^x -4 \int e^x  \sin^2x \mathrm{d}x \end{align*} First two steps use integration by parts. In the first step we differentiate $\sin^2 x$. In the second step we differentiate  $\sin x \cos x$.
Using this, we reach $$5\int e^x \sin^2 x \mathrm{d}x = e^x \sin^2 x -2e^x \sin x \cos x  + 2 e^x$$ $$\int e^x \sin^2 x \mathrm{d}x = \frac{e^x \sin^2 x -2e^x \sin x \cos x  + 2 e^x}{5}+C$$ I can't reach the form that most integral calculators give, which has terms $\cos(2x)$ and $\sin(2x)$ by just using trig identities, so I wonder whether the result is correct. I would also be interested in a method that immediately gives the form $$-\frac{e^x[2 \sin(2x)+ \cos(2x)-5]}{10}+C$$","['trigonometry', 'calculus', 'integration']"
1399002,What is maximum a number of to form right-triangles from in n straight lines,"I am interested what is maximum a number of to form  right-triangles from in $n=100$ straight lines such $n=3$,then maximum number of is $1$,see fig:$\Delta ABC$ is right-triangles. $n=4$ then the maximum number of is $3$,see following fig,$\Delta ABC,\Delta ABD,\Delta DAC$ are right-triangles.","['contest-math', 'geometry', 'combinatorics']"
1399005,Why don't we start studying calculus via series instead of the calculus on finite expressions?,"It seems that historically, there were two trends on the idea of integration: Newton's work which depended on infinite series. Leibniz work which depended on the dream of integration of elementary functions in a finite combination of basic functions which was later proved to be impossible by Liouville. I'll call it ""calculus on finite expressions"" . I took a course of calculus and it seems that integration via Leibniz way becomes increasingly complicated as the course progress. I didn't have a course on series yet but it seems that most of the functions can be represented as infinite power series and the integration on power series (integrating term by term) is often an easier task. Until now, I guess I had more evidence that calculus on series is way more simpler and powerful than the calculus on finite expressions. My doubts are: Is this correct? Why don't we start studying calculus via series instead of the calculus on finite expressions? Most of the books authors seem to think different about this matter because of their choice of order in the subjects. But Kuratowski's: Introduction to Calculus starts already with sequences and series, so I guess that perhaps that claim could be true. Although there is also another hypothesis: He could be lecturing in an educational system in which the calculus of finite expressions was taught early in high-school.","['analysis', 'sequences-and-series', 'calculus', 'education']"
1399008,Using right-hand Riemann sum to evaluate the limit of $ \frac{n}{n^2+1}+ \cdots+\frac{n}{n^2+n^2}$,"I'm asked to prove that $$\lim_{n \to \infty}\left(\frac{n}{n^2+1}+\frac{n}{n^2+4}+\frac{n}{n^2+9}+\cdots+\frac{n}{n^2+n^2}\right)=\frac{\pi}{4}$$ This looks like it can be solved with Riemann sums, so I proceed: \begin{align*}
\lim_{n \to \infty}\left(\frac{n}{n^2+1}+\frac{n}{n^2+4}+\frac{n}{n^2+9}+\cdots+\frac{n}{n^2+n^2}\right)&=\lim_{n \to \infty} \sum_{k=1}^{n}\frac{n}{n^2+k^2}\\
&=\lim_{n \to \infty} \sum_{k=1}^{n}(\frac{1}{n})(\frac{n^2}{n^2+k^2})\\
&=\lim_{n \to \infty} \sum_{k=1}^{n}(\frac{1}{n})(\frac{1}{1+(k/n)^2})\\
&=\lim_{n \to \infty} \sum_{k=1}^{n}f(\frac{k}{n})(\frac{k-(k-1)}{n})\\
&=\int_{0}^{1}\frac{1}{1+x^2}dx=\frac{\pi}{4}
\end{align*} where $f(x)=\frac{1}{1+x^2}$. Is this correct, are there any steps where I am not clear?","['summation', 'calculus', 'limits', 'riemann-sum']"
1399012,Finding an expression for the diameter of a circle.,"The figure shows two circles of radius $1$ that touch at $P$. 1 ] 1 $T$ is a common tangent line; $C_1$ is the circle that touches $C$, $D$, and $T$; $C_2$ is the circle that touches $C$, $D$, and $C_1$; $C_3$ is the circle that touches $C$, $D$, and $C_2$. This procedure can be continued indefinitely and produces an infinite sequence of circles $\{C_n\}$. Find an expression for the diameter of $C_n$.",['sequences-and-series']
1399070,Can an uncountable group $G$ have countably many distinct non isomorphic subgroups?,Can an uncountable group $G$ have only countably many distinct non isomorphic subgroups?I'm unable to produce a example.Any ideas?,"['abstract-algebra', 'group-theory']"
1399101,Is this a measure on the sigma algebra of countable and cocountable subsets of R?,"Consider the measurable space $(\mathbb{R}, \Sigma)$, where 
$$\Sigma := \{ A \subset \mathbb{R} \,:\, A \text{ is countable or } A^c \text{ is countable}\}.$$ Proving this is indeed a $\sigma$-algebra is easy: The countable union of countable sets is again countable; if the countable union contains at least one cocountable set, the coset of this union will be a subset of a countable set and thus countable. Now consider the following map: $$\mu: \Sigma \to [0,\infty], \quad A \mapsto \begin{cases}0 \quad \text{if $A$ is countable} \\ 1 \quad \text{else}\end{cases}$$ How would I prove that this map is a measure? Again, if I only consider disjoint unions of countable sets $\sigma$-additivity is obvious. But what about disjoint unions that contain uncountable sets with countable complement? I suspect that every disjoint union of sets in $\Sigma$ contains at most one uncountable set with countable coset, but I can't find a rigorous proof for this. The only uncountable sets $A \in \Sigma$ with countable coset I can picture at this moment are of the form $$A = \mathbb{R} \setminus Q,$$ where $Q \subset \mathbb{Q}$.",['measure-theory']
1399111,"Let $f$ be double differentiable function such that $|f′′(x)|\le 1$ for all $x\in [0,1]$. If $f(0)=f(1)$, then,","options: A) $|f(x)|>1 $ B) $|f(x)|<1  $ C) $|f′(x)|>1 $ D) $|f′(x)|<1$ attempt: I first tried using integration.
$−1\le f′′(x)\le 1$ integrating from $0$ to $x$,
$−x\le f′(x)−f′(0)\le x$ Again integrating from $0$ to $x$,
$\frac{−x^2}{2}\le f(x)−f(0)−f′(0)x\le\frac{x^2}{2}$ at $x=1$, $−\frac{1}{2}\le f′(0)\le\frac{1}{2}$ from the equation, $−x\le f′(x)−f(0)\le x$ and by substituting the max value of $f'(0)$, $-x+0.5\le f′(x)\le x+0.5$ But this doesn't give me the correct answer.","['calculus', 'derivatives']"
1399115,Prove that $\sum\frac{n+1}{(n+2)n!}$ converges,"Show that $\displaystyle\sum\limits_{n=1}^{\infty}\frac{n+1}{(n+2)n!}$ converges, using the integral test. I noticed that $\displaystyle\sum\frac{n+1}{(n+2)n!} = \sum\frac{(n+1)^2}{(n+2)!}$, but how do I go about integrating a factorial?","['sequences-and-series', 'convergence-divergence']"
1399140,The behavior of quadratic formula in the limit $a\to 0$,"$$\lim\limits_{a\to0}\frac{-b+\sqrt{b^2-4ac}}{2a}$$ $b$ and $c$ are constants. As $a$ approaches $0$, what does the formula approach? Example:
$$\lim\limits_{a\to0}\frac{-5+\sqrt{5^2-4·0.001·3}}{2·0.001}\approx-0.6$$","['quadratics', 'calculus', 'limits']"
1399142,Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$,Could any one give an example of a bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$? Thank you.,"['elementary-set-theory', 'examples-counterexamples', 'real-analysis']"
1399150,When are algebraic expressions equivalent?,"This question arose when I was going to determine the domain for $f \circ f(x)$. Let $f(x) = \dfrac{1-x}{1+x}$. $f \circ f(x) = x, \quad$ But the domain is not $\mathbb{R}$ because $f(x)$ is undefined for $x = -1$. This made sense to me after some thinking, $f \circ f(x)$ is only equivalent to $x$ if $x \neq -1$, so really one needs to specify the domain. So far so good, but then I started questioning the way I usually simplify algebraic expressions and solve equations. If I were to solve the equation $p_1(x) = q_1(x)$ I might start simplifying both expressions and come up with a simpler equation: $p_1(x) = q_1(x) \iff p_2(x) = q_2(x) \iff ... \iff p_n(x) = q_n(x)$ and here any $q_k(x)\iff q_t(x)\quad$ right? So I tried to come up with cases when I felt I probably would not bother with specifying domains before simplifying an expression, but probably would if the expression was used in an equation, as an example: $\dfrac{1}{x} + x - \dfrac{1}{x} = 0$ So usually I feel like I have always just regarded the left hand side as equivalent to $x$, if just asked to simplify the left hand side as an expression. But the equation makes me confused. Obviously $\dfrac{1}{x}$ is not defined when $x = 0$, but then again $\dfrac{1}{x}$ and $-\dfrac{1}{x}$ cancel eachother out, so does it really matter that they are not defined when $x = 0$? I tried to consult wolframalpha, but if I plug in $x = x + \dfrac{1}{x} - \dfrac{1}{x}$, it evaluates to true and if I plug in $x + \dfrac{1}{x} - \dfrac{1}{x} = 0$ it doesn't give an answer, as it does if $0$ is substituted for any real number. So now I feel like I've failed to understand a very fundamental concept of mathematics, that is when algebraic expressions really can be seen as equivalent and if it matters if they are used in equations or not?","['equivalence-relations', 'algebra-precalculus', 'functions']"
1399157,On the near-integer $163/\ln(163)$,"This question, concerning the approximation $\frac{163}{\ln(163)}\approx 2^5$, was posted on MO 5 years ago: Why Is 163/ln(163) a Near-Integer? . It was concluded that it had nothing to do with 163 being a Heegner number, and that it is most likely just a mathematical coincidence. Playing with my calculator, I noticed that $163\pi\approx2^9$, and $\ln(163)\pi\approx 2^4$, so I thought maybe $\pi$ has something to do with this? I proceeded to press more buttons on my calculator, 
and came up with $\pi\approx\frac{2^9}{163}+\frac1{2^{11}}\approx\frac{2^4}{\ln(163)}+\frac1{2^{11}}$. What's going on here? I noticed also that $67$ exhibits somthing similar: $\frac{67}{\ln(67)}\approx2^4-\frac{67}{2^{10}}$. I haven't found such relations with other Heegner numbers, but I still remain unsatisfied. 
Maybe it is the start of some Ramanujan-type infinite series for $\frac1{\pi}$, or..? I am not convinced that these relations are just meaningless numerology. Can someone explain what's going on? And what does $\pi$ has to do with this? I post this hoping that someone who knows more than I do could shed some light on it, and am sorry in advance if this is not the appropriate place to do so.","['number-theory', 'soft-question']"
1399180,Pontryagin class of a wedge product of vector bundles.,"Let $E\to M$ be a real vector bundle over a differentiable manifold $M$ and let $p_{1}(E)$ denote its first Pontryagin class. I would like to know if there is any formula allowing to write $p_{1}(\Lambda^2 E)$ in terms of $p_{1}(E)$. I am mostly interested in the case where the dimension of $M$ is less or equal than seven and $E=TM$ is the tangent bundle of the manifold. In particular, $p_{1}(TM)\in H^{4}(M,\mathbb{Z})$, and for the case that I am interested in, $H^{4}(M,\mathbb{Z}) = \mathbb{Z}_{10}$ and thus $p_{1}(TM) = k\, u$, where $k=0,\dots,9,$ and $u$ is the generator of $\mathbb{Z}_{10}$. Thanks.","['differential-geometry', 'algebraic-topology', 'characteristic-classes', 'fiber-bundles']"
1399182,Coeff. of $x^{97}$ in $f(x) = (x-1)\cdot (x-2)\cdot (x-3)\cdot (x-4)\cdot ........(x-100)$,"If $f(x) = (x-1)\cdot (x-2)\cdot (x-3)\cdot (x-4)\cdot ........(x-100)\;,$ Then Coefficient of $x^{99}$ and Coefficient of $x^{98}$ and Coefficient of $x^{97}$ in $f(x).$ $\bf{My\; try::}$ We can write $f(x)$ as $$\displaystyle f(x) = x^{100}-\left(\sum_{i=1}^{100}i\right)x^{99}+\left(\mathop{\sum^{100}\sum^{100}}_{i=1\ \ j=1\ i<j}i\cdot j\right)x^{98}-\left(\mathop{\sum^{100}\sum^{100}\sum^{100}}_{i=1\ j=1\ k=1\ i<j<k}i\cdot j\cdot k\right)x^{97}+..$$ So $\bf{Coefficients}$ of $$\displaystyle x^{99} = -\sum_{i=1}^{100}\left(1+2+3+......+100\right) = -\frac{100\cdot 101}{2} = -5050$$ Similarly Coeff. of $$\displaystyle x^{98} = \mathop{\sum^{100}\sum^{100}}_{i=1\ \ j=1\ i<j}i\cdot j = \frac{1}{2}\left[\left(\sum_{i=1}^{100}i\right)^2-\sum_{i=1}^{100}i^2\right] = \frac{1}{2}\left[\left(\frac{100\cdot 101}{2}\right)^2-\frac{100\cdot 101\cdot 201}{6}\right]$$ But I did not understand How can i calculate Coeff. of $\displaystyle x^{97} =-\mathop{\sum^{100}\sum^{100}\sum^{100}}_{i=1\ j=1\ k=1\ i<j<k}i\cdot j\cdot k$ Help me, Thanks","['sums-of-squares', 'polynomials', 'multinomial-coefficients', 'algebra-precalculus']"
1399183,"If $a_1,a_2,a_3,...,a_n$ are the side lengths of $A_1A_2A_3...A_n$ convex polygon,then$\frac{a^2_1+a^2_2+a^2_3+....+a^2_{n-1}}{a^2_n}$ is","If $a_1,a_2,a_3,...,a_n$ are the side lengths of $A_1A_2A_3...A_n$ convex polygon,then$\frac{a^2_1+a^2_2+a^2_3+....+a^2_{n-1}}{a^2_n}$ is $(A)>\frac{1}{n-1}\hspace{1cm}(B)<\frac{1}{n-1}\hspace{1cm}(C)>\frac{1}{n}\hspace{1cm}(D)<\frac{1}{n}$ $\frac{a^2_1+a^2_2+a^2_3+....+a^2_{n-1}}{a^2_n}=\frac{a^2_1}{a^2_n}+\frac{a^2_2}{a^2_n}+\frac{a^2_3}{a^2_n}+......+\frac{a^2_{n-1}}{a^2_n}>(n-1)\frac{a^2_1}{a^2_n}\frac{a^2_2}{a^2_n}\frac{a^2_3}{a^2_n}......\frac{a^2_{n-1}}{a^2_n}$ and then no idea how to proceed.Any hints,please?","['geometry', 'polygons']"
1399189,Set Theory ZF Axioms Doubt,"I have a pretty basic question about the symbolic representation of the axiom of extensionality for set theory, which states that $$
\forall A \forall B [ \forall x (x\in A \iff x\in B)] \iff A = B
$$ Now, I have been reading the Enderton's Elements of Set Theory , and it states that the notation $\forall x$ denotes ""for every set x"". However, my question is: x is not really a set, is it? It should be an object, right? For example, if I have the set {1,2,3}, wouldn't it be correct if I wrote $ 1 \in \{ 1,2,3 \} $, and here $1$ is not a set, right?","['elementary-set-theory', 'notation', 'axioms']"
1399190,"Given 3 spheres, find the equation of the plane that touches each of the spheres on the same side..?","I have a problem I am trying to solve, but I have no idea how to solve it. If I have 3 spheres, $A(1, 2, 0), B(4, 5, 0), \text{ and } C(1, 3, 2)$ of radius 1, how would I go about finding the equation of the form $ax + by +cz = d$ of the plane which touches each of the spheres on the same side..? I have been racking my brain all day, but I can't seem to figure it out. If someone wouldnt mind lending a hand, It would be much appreciated.. Thanks
Corey","['geometry', 'conic-sections', 'multivariable-calculus']"
1399196,Number of solutions in system of linear equations,"I'm studying System of linear equations. When solving Ax=b , it is said that the system can behave in 3 ways. No solution Unique solution Infinitely many solutions And according to Wikipedia page, Usually, a system with fewer equations than unknowns has infinitely many solutions, but it may have no solution . Such a system is known as an underdetermined system. Usually, a system with the same number of equations and unknowns has a single unique solution . Usually, a system with more equations than unknowns has no solution . Such a system is also known as an overdetermined system. I think the word Usually implies that the system can behaves in 3 ways for any arbitrary matrices(it does not care the matrix is a square matrix or non-square matrix). I want to know the possible behaviors when the matrix A is non-square. My questions are Can non-square matrices(m < n) have a unique solution(unknowns > equations)? Can non-square matrices(m > n) have infinitely many solutions(unknowns < equations)?","['systems-of-equations', 'matrices']"
1399232,Domain of a Logarithmic Quadratic Function,"Find the domain of the following function: $$g(x) = \ln(x^2+3x+2)$$ Here's my approach: $$g(x) = \ln(x^2+3x+2)$$ $$g(x) = \ln(x+2)(x+1)$$ $$g(x) = \ln(x+2)+\ln(x+1)$$ Therefore, $$x+1>0$$ $$x>-1$$ And, $$x+2 > 0$$
$$x>-2$$ Both values on both sides of both inequalities are correct, however, in the answer, the sign is flipped for the second inequality. It will become apparent that the sign must be flipped (in the second inequality) when some numbers are inputted into the original function, however, I cannot seem to spot an error in my working out. Thanks in advance, any help will be greatly appreciated.",['functions']
1399243,"Proof that $\dim\text{span}\{x,x^2\cos x,\cos x\}=3$","I have the following question : Let $V$ a space of functions from $\mathbb{R}$ to $\mathbb{R}$. Proof that $\dim  \text{span}\{x,x^2\cos x,\cos x\}=3$. For some reason I managed to show the opposite direction, this what I did : Therefore I should show that for any $x \in \mathbb{R}$ $$\lambda_1 x+\lambda_2x^2\cos x+\lambda_3 \cos x=0 \implies \lambda_1=\lambda_2=\lambda_3=0$$ But for $x=0 \implies \lambda_3=0$ and $\lambda_1 \neq 0$ and also $\lambda_2 \neq 0$ Therefore we found $x$ that $\lambda_1 \neq 0$ and $\lambda_2 \neq 0$ so this group is linearly independent. I don't quite understand the thing with the $x$ usually when I need to show linearly independent I get vectors not functions how should I handle it? Any help will be appreciated. Please, do not use any calculus (differentiation, integrals) since I'm not allowed to use it in order to solve the problem. Thank you!","['independence', 'linear-algebra']"
1399248,"Find the equation $ax + by + cz = d$ of the plane which has equal distance to the points $A(1, 2, 3)$ and $B(4, 5, 6)$","I was just wondering if anyone has any suggestions as to how to compute this equation? Find the equation $ax + by  + cz = d$ of the plane for which every point has equal
  distance to the points $A(1, 2, 3)$ and $B(4, 5, 6)$","['plane-geometry', 'plane-curves', 'geometry', 'multivariable-calculus']"
1399258,The space of homeomorphisms of the closed unit interval,"Denote by $X$ the space of homeomorphisms of the unit interval $[0,1]$, equipped with the topology of uniform convergence. It is an exercise in a textbook I'm reading to show that 
$$X \cong \{ 0, 1 \} \times [0,1]^{\omega}.$$
The progress I've made on this so far is to note that homeomorphisms $f: [0,1] \to [0,1]$ are either increasing or decreasing, and so it should be the case that $f(0) = 0$ or $f(0) = 1$. I think this splits the space into two connected components, as suggested by the factor $\{ 0, 1 \}$. Can anyone provide further advice on how to establish the isomorphism? My only instinct for the remaining factor $[0,1]^\omega$ is that continuous functions on $[0,1]$ are determined by their values on a countable dense set, but I can't see how this would lead to a bicontinuous map.",['general-topology']
1399271,What is topologically the set of all straight lines in $\mathbb{R}^d$? More structures on it?,"If we consider the set of all straight lines in $\mathbb{R}^d$, then what is it topologically? If it's topologically 'nice' i.e. a manifold, probably we could put a smooth manifold structure on it too. Can we put a Riemannian manifold structure? For the first question, I'd think of it as a disjoint union over the points $p$ of all lines passing through a fixed point $p$. So I'm thinking it's something like $\mathbb{RP}^{d-1}\times \mathbb{R}^d$. But is it? If it is, I guess the other questions might be answered from it.","['differential-topology', 'differential-geometry', 'general-topology']"
1399298,Lie bracket; confusing proof from lecture,"I am having some difficulties understanding this proof. Let $G$ be a closed matrixsubgroup of the general linear group. We have a right translation $Y(g):=dR_g(e) Y(e)$ on the Lie algebra $Y \in \mathfrak{g}$ that is just given by right multiplication with the matrix $g \in G,$ i.e. $Y(g):=Y(e)g.$ Similarly, $X$ is also a right-inv. vector field. Now, I want to show that $[X(g),Y(g)] = [X(e),Y(e)]g.$ We actually showed it in class and went like that ($\textbf{first expression of Lie bracket(!)}$) $$[X(g),Y(g)]_{i,j} = \sum_{k,l=1}^{n} Y(g)_{k,l} \frac{\partial X(g)_{i,j}}{\partial g_{k,l}}- X(g)_{k,l} \frac{\partial Y(g)_{i,j}}{\partial g_{k,l}}$$ $$= \sum_{k,l,m=1}^{n} Y(g)_{k,l}X(e)_{i,m} \frac{\partial g_{m,j}}{\partial g_{k,l}}- X(g)_{k,l}Y(e)_{i,m} \frac{\partial g_{m,j}}{\partial g_{k,l}}$$
using linear independence of the coordinates we get
$$= \sum_{k=1}^{n} Y(g)_{k,l}X(e)_{i,k} - X(g)_{k,l}Y(e)_{i,k} $$
which is nothing but 
($\textbf{second expression of Lie bracket(!)}$)
$$(X(e)Y(e)-Y(e)X(e))g)_{i,j} = ([X(e),Y(e)]g)_{i,j}$$ which was to be shown. Now, the first and last equality are the ones that bother me. Afaik from wikipedia the Lie bracket is $[X,Y]= X(Y)-Y(X),$ but the first line suggests that we are using the different convention$[X,Y]= Y(X)-X(Y)$ in this proof. Now, I would understand that the proof still works, if we would have sticked to this convention, but in the last line we use that $[X(e),Y(e)]=X(e) \circ Y(e)-Y(e) \circ X(e).$ This is nothing but the more canonical convention. Thus, we used two different definitions of Lie brackets. So somehow the conventions don't add up here. Could anybody explain this fact to me? Edit: As my question caused apparently some confusion, I want to clarify the problem. The thing is that I suspect that in this proof, there were two different definitions of the Lie bracket used. This would mean that the proof is wrong. On the other hand, the proof only consists of working out the calculation and thus, it should be possible to identify whether one can still get the correct result, by modifying the two positions appropriately? $\textbf{Edit2:}$
First, I want to thank Ted Shifrin for shedding some light on what is going on. Despite, there is still the problem that the ""proof"" given here somehow contradicts the right-invariance statement of the Lie-bracket. Cause if we start with $[X(g),Y(g)]=Y(g)X(g)-X(g)Y(g)$ (which is in the proof according to the notation proposed by Ted Shifrin and which notation I will assume in this paragraph) and show that this is equal to $(X(e)Y(e)-Y(e)X(e))g$ then we would have actually shown that the Lie bracket is not(!) right-invariant.  As the latter is $-[X(e),Y(e)]g$ where the minus sign is crucial, instead of $[X(e),Y(e)]g$ which we would have needed in order to show right-invariance. So something is still very wrong here. I would moreover want to ask how to interpret Lie brackets appearing in representation theory, as for instance: $Ad_g(X)=gXg^{-1}$(at least in the setting of matrix groups) and then $ad_{\xi}(\eta)= [\xi , \eta]= \xi \eta - \eta \xi.$ Thus, I feel that in Lie theory setting the canonical Lie bracket $[A,B] = AB-BA$ is more common in some way. Maybe you Ted Shifrin or anybody else could also comment on this. Even if this does not immediately help with the problem. If anything is unclear, please let me know.","['lie-groups', 'lie-derivative', 'differential-topology', 'differential-geometry', 'lie-algebras']"
1399306,How to shift two CDF's to maximize the number of crossings,"So suppose I have two continuous, monotone increasing function $F$ and $G$ defined on an interval $I_F=\{x:0<F(x)<1\}=(l_F,u_F)$ and $I_G=\{x:0<G(x)<1\}=(l_G,u_G)$ which can be computed but don't have an analytical form.$(l_G,u_G)$ and $(l_F,u_F)$, however, are known. Consider the function: $$M=\max_{a\in I_A}S(F,G,a)$$ --where $S(F,G,a)$ counts the number of times $F(x)$ and $G(x+a)$ cross-- Given $F$ and $G$ and $I_A$, I would like to know if $M>1$. The issue is that $F(x)$ and $G(x+a)$  are very expensive to evaluate. What I mean is computing $F$ and $G$ for a grid of values of $x$ on $I_F$ and $I_G$ is do-able but trying all values of $G(x+a)$ for all shifts $a\in I_A$ (the naive solution) is definitely not. What is the smart way to approach this problem? P.S.: @Modo: if you think this is not the correct venue to ask this type of question, please let me know and I will try to find a better place. Thanks in advance!","['probability', 'numerical-methods']"
1399324,Perpendicular Gradients,Suppose $f:\mathbb{R}^2\to \mathbb{R}$ is smooth. Further suppose $\nabla f$ vanishes no where. When is it possible to find a smooth non-singular $g:\mathbb{R}^2\to \mathbb{R}$ satisfying $\nabla f\cdot \nabla g = 0$?,"['differential-topology', 'differential-geometry', 'ordinary-differential-equations']"
1399326,Prove that there exists infinitely many positive integers $n$ such that $\sin^2{(na)}+\sin^2{(nb)}\le \frac{2\pi^2}{n}$,"Can anyone please help me with the following proof: Prove that there exists infinitely many positive integers, $n$, such that
$$\sin^2{(na)}+\sin^2{(nb)}\le \dfrac{2\pi^2}{n}\quad a,b\in \Bbb R$$","['contest-math', 'number-theory']"
1399350,Count Orbits and stabilizer,"Let $X$ be the set $\mathbb{Z}_9\times \mathbb{Z}_9$ and let $U_9$ denote the group of invertible elements in $\mathbb{Z}_9$. The group $G$ acts on $X$ defined by $u(x,y)=(ux,uy)$ where $u\in U_9$ and $x,y\in X$. $(a)$ Count the elements in $U_9$ $(b)$ Speficy the set of fixed points $F(u)$ (I guess they mean the stabilizer?) for each $u\in U_9$. $(c)$ Count the number of orbits $X$ under the action of $U_9$. $(a)$ Every integer which are coprime to 9 are invertible in $\mathbb{Z}_9$, and so $U_9=\{1,2,4,5,7,8\}$ $(b)$ I'm not quite sure if I am doing it right here. Here is a theorem, the proof was left as an exercise in my textbook which I think I proved correctly, and I would like to use the result to solve this problem. Theorem: Let $G$ be a group of permutations of $X$ and suppose that u belongs to $G(x\to y)$. Then $$G(x\to y)=uG_x\text{ (where } G_x \text{ is the stabilizer)}$$ the left coset of $G_x$, with respect to u. Since $u$ has an inverse I can rearrange the equation $F(u)=u^{-1}G(x\to y)$. In my case: $F(u)$ is the theorems $G_x$... So let's take $F(1)$ as the first example. If what I am saying is right, then $F(1)=G(x\to y)$ and $|F(1)|=81$? That is, the elements of F(1) is $\{(0,0),(0,1),(0,2),(0,3),(0,4),...,(8,0),(8,1),...,(8,7),(8,8)\}$. This feels kinda wrong to me the more I think about it though. If i do the same for $F(2)$ I find that it's inverse is 5 (usually I make use of the euclidian algorithm to find the inverse but here I could easily see that 5 is the inverse of 2) and $|F(2)|=3*3=9$ and the elements are given by $F(2)=\{(0,0),(0,5),(0,1),(5,0),(5,5),(5,1),(1,0),(1,5),(1,1),\}$. Just in case I have misunderstood this totally, I will explain my calculations for some of the elements in $F(2)$. I start off with $u^{-1}(x,y)=5(x,y)$. The first thing I do is to put $x=y=0$ and then I see $5(0,0)=(5*0,5*0)=(0,0)$ then i continue with $x=0,y=1$ which gives me $5(0,1)=(5,0)$ and lastly $5(0,2)=(0,10)\equiv (0,1) \text{ (mod 9)}$ and since I now see a repeating pattern, $x=0,y=1$ will be the same as $x=0, y=3$, I have found my first 3 elements for $F(2)$. I will see the same pattern for $x=1$ and $x=2$ and by this procedure I will find all 9 elements. The more I think about it the more unsure I become of this method. Is It correct to write it like $F(u)=u^{-1}G(x\to y)$? Or should I perhaps write it something like $G_u=hG(u\to y)$, where $h$ is the left coset. But how should I then specify the set of fixed points $F(u)$? How do i count it? I'm not even sure why I can see this as permutations. I thought permutations had to do with how you can arrange elements in a given set. Hope someone can help me. I haven't given so much though on $(c)$ yet so perhaps you shouldn't try to help me too much on that point. But I would be happy if you could help me out with $(b)$ and answer my questions. Thank you :)","['abstract-algebra', 'group-theory', 'discrete-mathematics', 'permutations']"
1399363,"Distributions, PDFs, and Random Variables in Measure Theory","I'm currently reading a book on measure-theoretic probability theory, and I'm having trouble seeing how the familiar objects distributions, pdfs/pmfs, and random variables from my calc-based prob/stat classes fit into this new language: $$\begin{array}
A(\Omega,\scr H,\mathbb{P}) & \stackrel{X}{\longrightarrow} & (E,\scr E,\mu) \\
\ & & \downarrow{\hat{\mathbb{P}}:= \mathbb{P}\circ X^{-1}} \\
 & \ & ([0,1],\scr B([0,1]))
\end{array}
$$ Let $\mu$ be a measure on the measurable space $(E,\scr E)$. $\hat{\mathbb{P}}=\mathbb{P}\circ X^{-1}$ is the distribution of the random variable $X$, and it too is a measure on $(E,\scr E)$. The probability density function $f_X$ of $X$ is the Radon-Nikodym derivative of $\hat{\mathbb{P}}$ relative to $\mu$. Then $\hat{\mathbb{P}}(A):=\mathbb{P}(X^{-1}(A))=\int_A d(\mathbb{P}\circ X^{-1})=\int_Ad\mu f_X$ defines a probability measure on $(E,\scr E)$. I'm a little confused because I see that in many sources that $f_X$ is the distribution of $X$, not the density, so I'm not sure if it's a notational thing or I'm not understanding things. The two examples I saw in my calc-based prob/stat classes were Discrete: In this case, the image of $X$ is countable. $(E,\scr E)$ is usually $(N,2^N)$, $N\subseteq\mathbb{Z}$. Since every measure $\mu$ on the discrete space $(N,2^N)$ is discrete, $\mu(A)=\sum_{x\in E}m(x)\delta_x(A)$ (which implies $\int_A d\mu f=\sum_{x\in A}m(x)f(x)$=$\sum_{x\in A}\mu(x)f(x)$), the distribution $\mathbb{P}\circ X^{-1}$ has this form. Then since singletons are measurable sets, $\hat{\mathbb{P}}(\{x_0\})=\int_{x_0}d\mu f_X=\mu(x_0)f_X(x_0)$. Here I'm a litte confused about the presence of the $\mu(x_0)$ term, since We need $\hat{\mathbb{P}}(\{x_0\})=f_X(x_0).$ Continuous: In this case, the image of $X$ is uncountable. $(E,\scr E,\mu)$ is usually $(\mathbb{R}^n,\scr B(\mathbb{R}^n),\lambda)$, with the Lebesgue measure $\lambda$ defined on it. If anyone could point to any misunderstandings and correct them, it would be greatly appreciated.","['self-learning', 'probability', 'measure-theory']"
1399378,Question on recurring decimal digits,"In my discrete maths class, I have come across an interesting phenomenon for which I can't find an explanation! If we divide $1$ by $13$ we obtain $0.07692307\ldots$ If we divide $3$ by $13$ we obtain $0.23076923\ldots$ If we divide $4$ by $13$ we obtain $0.30769230\ldots$ As you can see, the digits are recurring in the same order but starting at a different point in the sequence. Can someone explain this to me? What exactly is happening here?","['fractions', 'decimal-expansion', 'discrete-mathematics']"
1399401,Measuring rotation and translation differences between two matrices,"I am developing a docking application in which I want to have for every step the difference between the target transformation matrix and the user's transformation matrix. Now I don't have any problem with the coding part but rather with the linear algebra part. So let's say T is my target transformation matrix, and U is the user's transformation matrix. To get the difference between the two matrices I do: (U^-1) * (T) = Difference Now my matrices are formed with translation, rotation and scaling.
My question would be how I should measure the total translation difference as well as the total rotation difference (not interested in the scaling part). Thanks in advance,","['linear-programming', 'linear-algebra']"
1399402,Prove that $f$ has a fixed point.,"Let $f:[0,\infty [\to[0,\infty [$ continuous such that $$\lim_{t\to\infty }\frac{f(t)}{t}=\ell\in[0,1).$$ Prove that $f$ has a fixed point, i.e. there is an $x\geq 0$ such that $f(x)=x$. I don't really know how to solve this problem. My first intension was to use Brouwer, but it's only useable on a compact. After I tried by induction but with no success.",['real-analysis']
1399406,What is the number of invertible $n\times n$ matrices in $\operatorname{GL}_n(F)$?,"$F$ is a finite field of order $q$. What is the size of $\operatorname{GL}_n(F)$ ? I am reading Dummit and Foote ""Abstract Algebra"".  The following formula is given:  $(q^n - 1)(q^n - q)\cdots(q^n - q^{n-1})$.  The case for $n = 1$ is trivial.  I understand that for $n = 2$  the first row of the matrix can be any ordered pair of field elements except for $0,0$. and the second row can be any ordered pair of field elements that is not a multiple of the first row.  So for $n = 2$  there are $(q^n - 1)(q^n - q)$ invertible matrices.  For $n\geq 3$, I cannot seem to understand why  the formula works.  I have looked at Sloane's OEIS A002884.  I have also constructed and stared at a list of all $168$ $3\times 3$ invertible matrices over $GF(2)$.  I would most appreciate a concrete and detailed explanation of how say $(2^3 - 1)(2^3 - 2)(2^3 - 2^2)$ counts these $168$ matrices.","['group-theory', 'linear-algebra', 'combinatorics']"
1399407,Why we need Invertible Matrices,"In linear algebra, an n-by-n square matrix A is called invertible (also nonsingular or non degenerate) if there exists an n-by-n square matrix B such that $$A B = B A=I_n$$ I know the definition. But what are the practical applications of of invertible matrix.",['matrices']
1399410,"Counterexample to "" a closed ball in M is a closed subset.""","I am studying topology, on my own, using a text I found online. I am currently reviewing the “Metrics” section that reminds me of the real analysis course I took over 10 years ago. The text ask me to “show” the following: Suppose M is a metric space. Show that an open ball in M is an open subset, and a closed ball in M is a closed subset. I have what I think is a counterexample to the second part. First, let me state the definitions as they are written in the book I am using: For any $x \in M$ and $r>0$, the (open) ball of radius r around x is the set $$ B_r(x)=\{y \in M: d(x,y)<r \}, $$ and the closed ball of radius r around x is
  $$ \overline B_r(x)=\{y \in M: d(x,y) \leq r \}, $$ A subset $A \subseteq M $ is said to be an open subset of M if it contains an open ball around each of its points. A subset $A \subseteq M $ is said to be an closed subset of M if M\A is open. I believe the following is a counterexample to this: Let $$M = [1,10].$$ Now $ \overline B_1(5)=\{y \in M: d(5,y) \leq 1 \} $ is a closed ball. More simply put, $ \overline B_1(5)=[4,6] $. Lets call the closed ball $A$. $$ A=\overline B_1(5)=[4,6]$$
  Clearly, $A \subseteq M $, and $ M-A = [1,4)  \cup  (6,10] $. However $M-A$ is not open because $\{1\}$ and $\{10\}$ cannot have open balls around them without going beyond M. Is there an error in the text, or an error in my thinking?","['metric-spaces', 'general-topology']"
1399446,Justify an unbiased estimator is UMVUE,"Suppose $X_1,\ldots,X_n$ are iid $N(\theta,\theta)$, with $\theta\in(0,\infty)$. Is $\bar{X}$ the UMVUE (beta unbiased estimator) of $\theta$? I find the complete sufficient statistic is $T=\sum_{i=1}^{n}X_i^2$. So $\bar{X}$ is not a function $T$. Then we cannot justify it is UMVUE or not. Can someone help me here? How to get complete sufficient statistis?
$\frac{f(x\mid\theta)}{f(y\mid\theta)}=\exp(\frac{1}{2\theta}\sum_{i=1}^n (y_i^2-x_i^2)+\sum_{i=1}^n (x_i-y_i))$. Let $\sum_{i=1}^n y_i^2=\sum_{i=1}^n x_i^2$. My work I got $\log L(x\mid\theta) = -\frac{n}{2}\frac{1}{\theta} + \frac{\sum_{i=1}^n x_i^2}{2} \frac{1}{\theta^2}-\frac{n}{2}$. Then, I let $\frac{\partial \log (x\mid\theta)}{\partial \theta}=0$. Then, I have $-\frac{n}{2}\theta^2-\frac{n}{2}\theta+\frac{1}{2}\sum_{i=1}^n x_i^2=0$. Then, I find the solution is weird. Am I wrong?","['normal-distribution', 'statistics', 'statistical-inference']"
1399449,Equation of the ellipse for musical notation (the quarter note/crotchet and shorter),"Note heads are often represented with a slightly rotated ellipse, as shown here for instance (first image). Does anyone happen to know the equation of the ellipsis, and the rotation that's applied to it ? The only thing I thought about was trying to bruteforce it until I get something that looks alike. PS : I hesitated between this website and SO. Yet, even if it's for programming purposes, it would have been off-topic on SO because the problem is not the development part, but rather the mathematical one.","['geometry', 'conic-sections', 'music-theory']"
1399463,Prove $[N(H):H]\equiv [G:H] \pmod p$,"Let $G$ be a finite group and $H$ be a subgroup of $G$ . Let $|H|=p^n$ for some $p$ prime, $n\geq1$ . Show that $[N(H):H]\equiv [G:H]\pmod p$ . I observed that I will need to show that $p$ divides $\dfrac{|G|-|N(H)|}{p^n}$ . However as of now I do not know any relationship between $N(H)$ and $|G|$ . Some hint is appreciated.","['abstract-algebra', 'group-theory', 'finite-groups']"
1399465,Perfect number in gaussian integers,"We have complete description about irreducibles in the ring Z[i],of gaussian integers. Now I was trying to define suitably the notion of ""perfect number"" in Z[i]. But the problem is unique factorization into irreducibles is unique upto associates. So how one should possibly try to resolve this?","['ring-theory', 'complex-numbers', 'number-theory', 'perfect-numbers', 'unique-factorization-domains']"
1399476,If $3x^2 -2x+7=0$ then $\left(x-\frac{1}{3}\right)^2 =$?,If $\ 3x^{2}-2x+7=0$ then $$\left(x-\frac{1}{3}\right)^2 =\text{?} $$ I am so confused. It is a self taught algebra book. The answer is: $ \large -\frac{20}{9}$ but I don't know how it was derived. Please explain. Thanks for everyone who commented! I understand it now.,"['completing-the-square', 'quadratics', 'algebra-precalculus']"
1399485,"$u=xf(xy)$, show that $xu_{xx}-yu_{xy} = 0$","I need to show that: $$xu_{xx}-yu_{xy} = 0$$ when $$u=xf(xy)$$ So, I did: $$u_x = xyf_x(xy)+f(xy) \implies $$
$$u_{xx} = xy^2f_{xx}(xy)+2yf_x(xy)$$
and
$$u_{xy} = xf_x(xy)+x^2yf_{xy}(xy)+xf_y(xy)$$ so: $$xu_{xx} = x^2y^2f_{xx}(xy)+2xyf_x(xy)$$ $$yu_{xy} = x^2y^2f_{xy}(xy)+2xyf_y(xy)$$ but when I take one from another, I don't get $0$. This makes me think that there is a relation that says $$f_{xx}(xy) = f_{xy}(xy)$$ so they both cancel, but I couldn't find it. What am I doing wrong?","['partial-derivative', 'calculus', 'multivariable-calculus', 'partial-differential-equations']"
1399513,How to prove $3^\pi>\pi^3$ using algebra or geometry?,"It's a question of a some time ago test,
I've found a way to solve the problem using calculus, but always I've thought that exist a solution with algebra and geometry. Thank you for your time.","['alternative-proof', 'algebra-precalculus', 'inequality']"
1399520,Find the derivative of $f(x) = \int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy.$,"Problem statement: Find the derivative of 
$$f(x) = \int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy$$
and find an ordinary differential equation that $f$ solves. Find the solution to this ordinary differential equation to determine an explicit value for $f$. My attempt: Normally, to find $f'(x)$ in this situation, if this was a calculus problem, I would write:
$$\frac{d}{dx} f(x) = \frac{d}{dx}\int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy = \frac{d}{dx}\left(\int_{-\infty}^0\frac{e^{-xy^2}}{1+y^2}\ dy + \int_0^\infty \frac{e^{-xy^2}}{1+y^2}\ dy\right)$$
and then I would differentiate under the integral sign:
$$f'(x) = \int_{-\infty}^0\frac{\partial}{\partial x}\frac{e^{-xy^2}}{1+y^2}\ dy + \int_0^\infty \frac{\partial}{\partial x}\frac{e^{-xy^2}}{1+y^2}\ dy,$$
which leaves me with
$$f'(x) = \int_{-\infty}^0 \frac{-y^2e^{-x(y^2+1)}}{1+y^2}\ dy + \int_{0}^\infty \frac{-y^2e^{-x(y^2+1)}}{1+y^2}\ dy.$$ However, this is actually an analysis problem, and as such I am having a really hard time justifying all of these steps. I have already proved that if $F(x) = \int_a^x f(y) \ dy$, then $F$ is absolutely continuous, and therefore the derivative exists a.e. Now, I also know from the FCT that if $f$ is integrable, $F'(x) = f(y)$ a.e. But I still can't quite figure out how to justify moving the derivative in the integral sign, particularly when I have infinite bounds, which I do. Any help would be much appreciated here!","['real-analysis', 'lebesgue-integral', 'derivatives']"
1399560,Rolling a die with n sides to get a cumulative score of n,"I was told this problem a while ago, and recently someone explained the answer to me, which I didn't understand; could someone please explain in layman's terms (ish)? You have a die with $n$ sides. Each side is numbered - uniquely - from $1$ to $n$, and has an equal probability of landing on top as the other sides (i.e. a fair die). For large $n$ (I was given it with $n = 1,000,000$), on average how many rolls does it take to achieve a cumulative score of $n$ (or greater)? That is, when you roll it, you add the result to your total score, then keep rolling and adding, and you stop when your score exceeds or is equal to $n$. The cool thing about this problem: apparently, the answer is $e$. I would like to know exactly how this is derived.","['probability-theory', 'probability']"
1399573,Finite Generated Abelian Torsion-Free Group is a Free Abelian Group,"I am trying to prove that every Finite Generated Abelian Torsion-Free Group is a Free Abelian Group. In order to do this, I am trying to show that if $\{x_1, \dots, x_n\}$ is a minimal generator of the group and if $n_1x_1 + \dots n_n x_n=0$ then $n_1=\dots = n_n=0$ . I'm stuck here.",['abstract-algebra']
1399584,"Investigating whether a given relation is reflexive, symmetric, and transitive","Let $X = \{0, 1, 2, ... , 10\}$ , Define the relation $R$ on $X$ by, for all $a, b \in X$ , $aRb$ if and only if $a + b = 10$ . Is $R$ reflexive? symmetric, transitive? Give reasons. Here are my answers, please see if I made any mistakes? $R$ is not reflexive, because there exists $a \in X$ such that $a$ does not relate $a$ . For example, let $a=1$ , $1+1=2$ which is not equal to $10$ . $R$ is symmetric, because $a + b = b + a$ . sum of integers are symmetric. So $4R6$ and $6R4$ . $R$ is not transitive, because there are $a, b, c$ integers such that $aRb$ $bRc$ but $a$ does NOT relate $c$ . Let $a = 4, b = 6$ and $c = 4$ . Then, $4R6$ and $6R4$ but $4$ does NOT relate $4$ .","['solution-verification', 'relations', 'discrete-mathematics']"
1399600,Evaluate the integral $\int_0^\infty x^{t-1}e^{-\beta x}dx$,"I want to evaluate the following integral $$\int_0^\infty x^{t-1}e^{-\beta x}dx$$
where $\beta$ is a complex number. Now, if $\beta$ was real, we could just set $y = \beta x$ and we will reduce to the Gamma function. Since $\beta$ is complex, though, when I set $y = \beta x$, I am integrating over the line with $\arg \beta$ on the complex plane, so I can't reduce directly to the Gamma function, can I? I have found after some calculations that $$\int_0^\infty x^{t-1}e^{-\beta x}dx = \Gamma(t)\beta^{-t}$$ which is exactly what one would find if it didn't bother with the previous observation. So my questions are:  Is my observation on the complex line correct? and 2) What is the best way to prove the result? My work Write $\beta = a + ib$. Consider the integral as a function of $t,a,b$ to get $$I(t,a,b) = \int_0^\infty x^{t-1}e^{-a x}e^{-ibx}dx$$. Notice that $$\frac{\partial I}{\partial a}(t,a,b) = -I(t+1,a,b)$$ and
$$\frac{\partial I}{\partial b}(t,a,b) = -iI(t+1,a,b)$$ Now since $\displaystyle I(t+1) = \frac t{a+ib}I(t)$, the previous two equations become $$\frac{\partial I}{\partial a} = -\frac t{a+ib}I$$ and
$$\frac{\partial I}{\partial b} = -\frac{it}{a+ib}I$$ which put together yield $I(t,a,b) = C(t) (a+ib)^{-t}$.
Also, since $\displaystyle I(t,1,0) = C(t) = \int_0^\infty x^{t-1}e^{-x}dx= \Gamma(t)$, we get $$I(t,a,b) = \Gamma(t) (a+ib)^{-t} = \Gamma(t)\beta^{-t}$$ which seems like too much work!","['gamma-function', 'calculus', 'improper-integrals', 'analytic-continuation', 'complex-analysis']"
1399604,Trig limit in Spivak's Calculus,"$$\lim_{x\rightarrow 1} (x-1)^3 \sin\frac{1}{(1-x)^3} = 0$$ To prove that this is true, the chapter on limits has things like $\lim_{x\rightarrow a}(f\cdot g)(x) = \lim_{x\rightarrow a}f(x)\cdot \lim_{x\rightarrow a} g(x)$, when both limits exist. Now, in the case of the problem, $\lim_{x\rightarrow 1} (x-1)^3 = 0$, but $\lim_{x\rightarrow 1} \sin\frac{1}{(1-x)^3}$ doesn't exist. However, it is bounded, and because the first limit tends to zero, it is clear that the multiplication tends to zero. But since there is a discontinuity where the limit doesn't exist, I can't find a way to express this formally in the terms of the theorems that I should know at this point. So there's my doubt, I guess. How should I proceed?","['calculus', 'limits', 'trigonometry']"
1399649,Why can we modify expressions to use limits?,"If I wanted to take the limit of $\frac { \left( x\cdot \cos { \left( x \right) +\sin { \left( x \right)  }  }  \right)  }{ x+{ x }^{ 2 } } $ as x approaches 0,  I cannot do it directly as that would result in dividing by zero. However, if I modify the expression through several steps, I can take the limit of $$\frac { \left( \cos { \left( x \right) +\frac { \sin { \left( x \right)  }  }{ x }  }  \right)  }{ 1+{ x } } $$ as x approaches zero and get $2$. How can equal expressions give different results? And also: Why does $\\ \\ \lim _{ x\rightarrow 0 }{ \frac { \sin { \left( x \right)  }  }{ x } =1 } \\ $? Am I right in thinking that an infinitely small numerator cancels out an infinitely small denominator?",['limits']
1399711,How to find all roots of the quintic using the Bring radical,"Finding one root $x_1$ of the quintic equation $x^5 + x = -a$ by using the Bring radical is described on Wikipedia . The root is $x_1 = -a +a^5 -5a^9+35a^{13}+ \ldots$ , and it is found by reversion of the Taylor series for $f(x) = x^5 + x$. How do we find the other roots of this quintic in series representation?","['taylor-expansion', 'sequences-and-series', 'roots', 'polynomials']"
1399715,$\int_a^b |f|=0\implies f=0$,"Let $f:[a,b]\to\mathbb R$ continuous. I want to show that $\int_a^b |f|=0\implies f=0$. By contradiction, suppose $f\neq 0$ and denote $A=\{x\mid f(x)\neq 0\}$. We have that $$0=\int_{[a,b]}|f|=\int_{[a,b]\backslash A}|f|+\int_A|f|\implies \underbrace{\int_{[a,b]\backslash A}|f|}_{\geq 0}=\underbrace{-\int_A|f|}_{\leq 0},$$
which is a contradiction. Therefore $|f|=0$ and thus $f=0$. Is it correct ? (the problem is that I didn't use the continuity, and I know that for a non-continuous function, we can have $\int_a^b|f|=0$ and $f\neq 0$) . Do you have other proofs ?",['analysis']
1399743,Find inverse of 15 modulo 88.,"Here the question: Find an inverse $a$ for $15$ modulo $88$ so that $0 \le a \le 87$; that is, find an integer $a \in \{0, 1, ..., 87\}$ so that $15a \equiv1$ (mod 88). Here is my attempt to answer: Find using the Euclidean Algorithm, we need to find $\gcd(88, 15)$, that must equal to $1$ to be possible to find an inverse of $15 \pmod{88}$. \begin{align*}
88 & = 5 \times 15 + 13\\
15 & = 1 \times 13 + 2\\
13 & = 6 \times 2 + 1\\
2 & = 2 \times 1 + 0
\end{align*} So,
$$\gcd(88, 15) = 1$$ Now, we need to write this into the form:
$$\gcd(88, 15) = 88x + 15y.$$ And find $x$ and $y$. \begin{align*}
1 & = 13(1) + 2(-6)\\
& = 13(7) + 15(-6)\\
& = 88(7) + 15(-41)
\end{align*} So, $x = 7$ and $y = -41$. So, an inverse of $15 \pmod{88} = -41$. Now, I need to find an inverse that is between $0$ and $87$. What is a good easy approach to find other inverses? Any ideas please?","['inverse', 'gcd-and-lcm', 'discrete-mathematics']"
1399754,"Why does this ""miracle method"" for matrix inversion work?","Recently, I answered this question about matrix invertibility using a solution technique I called a "" miracle method ."" The question and answer are reproduced below: Problem: Let $A$ be a matrix satisfying $A^3 = 2I$ . Show that $B = A^2 - 2A + 2I$ is invertible. Solution: Suspend your disbelief for a moment and suppose $A$ and $B$ were scalars, not matrices. Then, by power series expansion, we would simply be looking for $$ \frac{1}{B} = \frac{1}{A^2 - 2A + 2} = \frac{1}{2}+\frac{A}{2}+\frac{A^2}{4}-\frac{A^4}{8}-\frac{A^5}{8} + \cdots$$ where the coefficient of $A^n$ is $$ c_n = \frac{1+i}{2^{n+2}} \left((1-i)^n-i (1+i)^n\right). $$ But we know that $A^3 = 2$ , so $$ \frac{1}{2}+\frac{A}{2}+\frac{A^2}{4}-\frac{A^4}{8}-\frac{A^5}{8} + \cdots = \frac{1}{2}+\frac{A}{2}+\frac{A^2}{4}-\frac{A}{4}-\frac{A^2}{4} + \cdots $$ and by summing the resulting coefficients on $1$ , $A$ , and $A^2$ , we find that $$ \frac{1}{B} = \frac{2}{5} + \frac{3}{10}A + \frac{1}{10}A^2. $$ Now, what we've just done should be total nonsense if $A$ and $B$ are really matrices, not scalars. But try setting $B^{-1} = \frac{2}{5}I + \frac{3}{10}A + \frac{1}{10}A^2$ , compute the product $BB^{-1}$ , and you'll find that, miraculously , this answer works! I discovered this solution technique some time ago while exploring a similar problem in Wolfram Mathematica . However, I have no idea why any of these manipulations should produce a meaningful answer when scalar and matrix inversion are such different operations. Why does this method work? Is there something deeper going on here than a serendipitous coincidence in series expansion coefficients?","['inverse', 'linear-algebra', 'matrices']"
1399780,Solving Equations Containing Floor Functions,"Recently I have been struggling with a problem involving the floor function. The problem is: 
$$
\lfloor x+5 \rfloor = 3\lfloor x\rfloor-1
$$ I have had a similar question to this however it only involved the floor function on one side of the equation and I was able to set up a pair of inequalities and solve them however I have not been able to do the same for this question. What I have done so far is attempt the same procedure by solving the equation and then setting up a set of inequalities but have been unable to come up with a reasonable answer. I have also graphed this for clarity but am still unsure what is really going on or how to approach this question. Thank you.","['ceiling-and-floor-functions', 'algebra-precalculus']"
1399796,Let $R$ be a commutative domain with field of fractions $F$. Prove that $F$ is an injective $R$-module.,Let $R$ be a commutative integral domain with field of fractions $F$. Prove that $F$ is an injective $R$-module. I have tried to apply Baer's criterion: every $R$-module homomorphism from any ideal $I$ of $R$ can be extended to an $R$-module homomorphism from $R$ to $F$. But I couldn't. Thanks for any help.,"['abstract-algebra', 'injective-module', 'modules']"
1399799,"Prove that $(A-B) \cap (A-C) = A \cap (B \cup C)^c$ for any three sets A, B, C.","I was given a question that says Prove that $(A-B) \cap (A-C) = A \cap (B \cup C)^c$ for any three sets A, B, C. I'm completely lost with this question. In a previous question that says $A \cap C \subseteq A- (B-C)$. I used this proof Let $x \in A \cap C$. Then $x \in A$ and $x \in C$. Also note that $x \notin B-C$. As $x \in A$ and $x \notin B-C$, we see that $x \in A - (B-C)$. Therefore $A \cap C \subseteq A- (B-C)$. With the question I just did i tried to apply that method with the question i struggled with but I couldn't see how it would work.","['elementary-set-theory', 'discrete-mathematics', 'proof-writing']"
1399836,Is such a multivariate function the product of two univariate functions?,"Let $f: \mathbb{N}^2 \rightarrow \mathbb{R}$ be a function of two variables, $f=f(x,y)$. $f$ has the following property: $$
\sum_{y\in A} f(x,y) = 0
$$ where sum on $y$ runs over a fixed finite $A$, independent of $x$. Can we necessarily conclude that $f(x,y) = g(x) h(y)$? $g(x)$ and $h(y)$ are two other functions. Is there any other property that $f(x,y)$ should meet?","['sequences-and-series', 'functional-analysis', 'functions']"
1399842,"For all sets $A$, $B$, and $C$, if $A-B \subseteq A - C$ then $ A \cap C = \varnothing $","Prove the statement P: For all sets $A$, $B$, and $C$, if $A-B \subseteq A - C$ then $ A \cap C = \varnothing $ My attempt to answer: This statement is true, and here is a proof: Proof: Suppose A, B, and C are sets such that $A-B \subseteq A - C$. We want to prove that $A \cap C = \varnothing $ by contradiction. Suppose $A \cap C \neq \varnothing $. That is there is $x \in A \cap C$. Also, since $A-B \subseteq A - C$, suppose there is a $x \in A - B$, then $x \in A - C$. That is, $x \notin C$. Therefore, that implies that $x \notin A \cap C$ which contradicts with given that $x \in A \cap C$. Therefore, concluding by contradiction: $A \cap C = \varnothing $. End of proof. Is this proof correct? Any issues?. My proof is wrong, got it based on your comments: Let $A = \{1, 2\}, B = C = \{2\}$, then $A-B \subseteq A - C$, but, $A \cap C \neq \varnothing = \{2\}$. Can someone, tell me what I did wrong in my proof above? Is it because, I assumed $x \in A - B$? part b) Write the converse and proof/disproof that. The converse is: For all sets $A$, $B$, and $C$, if $ A \cap C = \varnothing $ then $A-B \subseteq A - C$",['discrete-mathematics']
1399901,"Probability of a natural number being divisible by 2, 3, or 5?","I'm trying to calculate the probability of a natural number being divisible by 2, 3, or 5 and I feel as if I may have found the answer.  But I wanted to see if anyone sees anything wrong with my ""work"".  Thank you all for your time and help. Let ~ signify 'n is divisible by': P[~2 ∨ ~3] = P[~2] + P[~3] - P[~2 ∧ ~3] = 1/2 + 1/3 - 1/6 = 2/3 P[(~2 ∨ ~3) ∨ ~5] = P[~2 ∨ ~3] + P[~5] - P[(~2 ∨ ~3) ∧ ~5] = 2/3 + 1/5 - something something = P[(~2 ∨ ~3) ∧ ~5] = P[(~2 ∧ ~5) ∨ (~3 ∧ ~5)] = 1/10 + 1/15 - 1/30 = 4/30 = 2/15 so P[(~2 ∨ ~3) ∨ ~5] = 2/3 + 1/5 - 2/15 = 11/15 Are these calculations correct and am I even using probabilities and such correctly?","['probability', 'elementary-number-theory']"
1399921,"If $A^n = B$ and I know $B$, can I find $A$? [duplicate]","This question already has answers here : Nth roots of square matrices (2 answers) Closed 8 years ago . Suppose that $A$ and $B$ are invertible, $p \times p$ matrices. If $A^n = B$ and I know all of the entries in $B$, can I find an $A$ for some or all integers $n \ge 0$? How many solutions for $A$ exist? If I'm thinking correctly, then $A = B * (A^{-1})^{n-1},$ but this is sort of self referential. Thanks!","['linear-algebra', 'matrices']"
1399926,"If the gradient of $f$ at $x$ has the same direction with $x$ for all $x$, is $f$ radial?","I would like to ask the following question: If $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ is a smooth function such that for all $x\in%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$, its gradient at $x$ has the same direction with $x$, is the function
$f$ radial? That is if there exists a function $g:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ such that $\nabla f\left(  x\right)  =g\left(  x\right)  x$, then is
$f\left(  x\right)  =f\left(  y\right)  $ when $\left\vert x\right\vert
=\left\vert y\right\vert ?$ Of course the radial functions have the above property. So I guess that the answer is yes. But so far I could not find proofs/ counterexamples for it.","['real-analysis', 'functional-analysis', 'partial-differential-equations']"
1399936,"Express the polynomial $x^3-4x-4$ as a linear combination of $x-2$, $(x-2)^2$ and $(x-2)^3$","Express the polynomial $x^3-4x-4$ as a linear combination of $x-2$, $(x-2)^2$ and $(x-2)^3$ I've been looking everywhere but I still don't quite understand the question. I know that a linear combination is like a matrix consisting of a specific combination of vectors multiplied by a coefficient. In the form...
$$a_1v_1+a_2v_2 +a_3v_3 ,\text{for }a_1 \,to \, a_n \, real \, numbers$$ So to express it as the question asks i think i have to find the coefficients off...
 $$x^3-4x-4 = a(x-2)+b(x-2)^2 +c(x-2)^3$$ But i'm not too sure about it or where to go. I thought I'd had to involve vectors and matrices somehow. Please help, I really want to understand this content well, I've been having trouble picking up content from this new class. We've also been talking about basis and span. I think a vector forms a basis for a system. If for a $R^n$ system if for 3 row (have 3 pivots showing 1 = 0, after row reducing) then the vectors/columns corresponding to those rows make a basis for the system and the system hence contains/span all of ""R^3"". EDIT: You guys are right the question given to me was inconsistent. I asked the teacher who then admitted there was a typo and re-wrote the question. I think I've got plenty to work on anyway with this already. He actually meant to ask Express the polynomial $x^3-2x-4$ as a linear combination of $x-2$, $(x-2)^2$ and $(x-2)^3$ To wich i got C=1, B=6, a=10",['linear-algebra']
1399944,Estimating variance of estimator of bernoulli process,"The maximum likelihood estimate of a Bernoulli process is simply given by $\hat{\theta}=\frac{\sum X_i}{N}$, where N is the total number of bernoulli trial and $X_i$ is the outcome of each trial. This is an unbiased estimator and the variance of this estimator can be easily computed to be $Var(\hat{\theta}) = \frac{\theta(1-\theta)}{N}$. However, the actual $\theta$ is unknown. So how do we estimate the variance of the estimator then ? Also, I would like an unbiased estimate of this variance. 
Its possible that this question has already been asked. If someone can give a pointer that would be great. Thanks.","['statistics', 'statistical-inference', 'parameter-estimation']"
1399946,Not all tangents to a plane curve are bitangents,"I'm struggling on a question from a previous qualifying exam, and I don't see a clean way to do it. Let $X\subset \mathbb{R}^2$ be a connected, 1-dimensional, real analytic submanifold, not contained in a line. Why does there exist a tangent line to $X$ that not bitangent (tangent to $X$ at more than one point)? Out of curiosity, is the statement still true if we drop the condition that $X$ is real analytic (so just smooth)?","['plane-curves', 'differential-geometry', 'multivariable-calculus']"
1399959,"Deduce $\partial_tp=-\partial_x(b(x)p)+(1/2)\partial_{xx}(\sigma^2(x)p)$, for $p(x,t|y)$ of $X(t)$ and $dX=b(X)dt+\sigma(X)dW$, $X(0)=y$","I am stuck in this proof... I almost got it, but I must have made a mistake. It is part B that I am getting wrong. Thanks in advance for your help! QUESTION: Let $X$ satisfy the autonomous SDE
$$dX=b(X)dt+\sigma(X)dW,$$
with $X(0)=y$, where $y\in\mathbb{R}$ is a constant, and let $f:\mathbb{R}\to\mathbb{R}$ be an arbitrary smooth function. (A) Show that
$$\mathbb{E}f(X(t))-f(y)=\mathbb{E}\int_0^t\left[f'(X(s))b(X(s))+\frac{1}{2}f''(X(s))\sigma^2(X(s))\right]ds.$$ (B) Deduce that the transition probability $p(x,t|y)$ of $X(t)$ satisfies the forward Kolmogorov (Fokker-Planck) equation
$$\partial_tp=-\partial_x(b(x)p)+\frac{1}{2}\partial_{xx}(\sigma^2(x)p).$$ ATTEMPT: (A) Done using Ito's formula and then taking expectations conditioned on $X(0)=y$. (B) Expressing the expectations using the transition probability $p(x,t|y)$ of $X(t)$ gives
$$\int f(x)p(x,t|y)dx-f(y)=\int\int_0^t p(x,s|y)\left[f'(x)b(x)+\frac{1}{2}f''(x)\sigma^2(x)\right]ds\, dx$$
Taking the time derivative on both sides:
$$\int f(x)\partial_t p(x,t|y)dx=\int p(x,t|y)\left[f'(x)b(x)+\frac{1}{2}f''(x)\sigma^2(x)\right] dx=\int \left[f'(x)b(x)p(x,t|y)+\frac{1}{2}f''(x)\sigma^2(x)p(x,t|y)\right] dx$$ (THE END OF THIS PART IS WHAT I GET WRONG) Integrating by parts (as told by my professor that we should do), we get: For the first part of the right-hand side of the equation, using $dv=f'(x)dx\implies v=f(x)$ and $u=b(x)p(x,t|y)\implies du=\partial_x\left(b(x)p(x,t|y)\right)$:
$$\int f'(x)b(x)p(x,t|y)dx=uv-\int v\,du=f(x)b(x)p(x,t|y)-\int f(x)\partial_x\left[b(x)p(x,t|y)\right]dx$$ And for the second part of the RHS of the equation:
$$\frac{1}{2}\int\left[f''(x)\sigma^2p(x,t|y)\right]dx=\frac{1}{2}f'(x)\sigma^2(x)p(x,t|y)-\frac{1}{2}\int f'(x)\partial_x\left[\sigma^2(x)p(x,t|y)\right]dx=\frac{1}{2}f'(x)\sigma^2(x)p(x,t|y)-\frac{1}{2}f(x)\partial_x\left[\sigma^2(x)p(x,t|y)\right]+\frac{1}{2}\int f(x)\partial_{xx}\left[\sigma^2(x)p(x,t|y)\right]dx$$ Therefore,
$$\int f(x)\partial_t p(x,t|y)dx=f(x)b(x)p(x,t|y)-\int f(x)\partial_x\left[b(x)p(x,t|y)\right]dx+\frac{1}{2}f'(x)\sigma^2(x)p(x,t|y)-\frac{1}{2}f(x)\partial_x\left[\sigma^2(x)p(x,t|y)\right]+\frac{1}{2}\int f(x)\partial_{xx}\left[\sigma^2(x)p(x,t|y)\right]dx=\int\left[-\partial_x\left[b(x)p(x,t|y)\right]+\frac{1}{2}\partial_{xx}\left[\sigma^2(x)p(x,t|y)\right]\right]f(x)dx+f(x)b(x)p(x,t|y)+\frac{1}{2}f'(x)\sigma^2(x)p(x,t|y)-\frac{1}{2}f(x)\partial_x\left[\sigma^2(x)p(x,t|y)\right]$$ THIS IS WHAT I GET WRONG, the result is supposed to be $$\int f(x)\partial_t p(x,t|y)dx=\int\left[-\partial_x\left[b(x)p(x,t|y)\right]+\frac{1}{2}\partial_{xx}\left[\sigma^2(x)p(x,t|y)\right]\right]f(x)dx\implies \int \partial_t p(x,t|y)dx=\int\left[-\partial_x\left[b(x)p(x,t|y)\right]+\frac{1}{2}\partial_{xx}\left[\sigma^2(x)p(x,t|y)\right]\right]dx,$$ but how do I get that? Because I am sure the equality below is not possible? $$f(x)b(x)p(x,t|y)+\frac{1}{2}f'(x)\sigma^2(x)p(x,t|y)-\frac{1}{2}f(x)\partial_x\left[\sigma^2(x)p(x,t|y)\right]=0$$","['probability-theory', 'stochastic-differential-equations', 'stochastic-analysis']"
1400039,"Let $f$ be strictly increasing and $g,\ g\circ f$ is continuous. Does this implies that $f$ is continuous?","Let $f,\ g: \mathbb R \to \mathbb R $ be two nonconstant functions. Let $f$ be strictly increasing and $g,\ g\circ f$ is continuous. Does this implies that $f$ is continuous? How to think this question graphically?","['continuity', 'real-analysis', 'functions']"
1400043,"Sum of digits of 2-digit number is 9. If we switch places of digits, we obtain the number whose ratio to the first number is 8:5","Sum of digits of 2-digit number is 9. The ratio of the number to the number with the digits switched is 8:5. What is the number? My try: We have number $10x+y$ Sum of digits: $x+y=9 \implies x=9-y$ We switch places of digits of first number and we win this relation:
$$(10y+x):(10x+y)=8:5 $$
$$(9y+9):(90-9y)=8:5 $$
$$ 117y=675 $$
What I'm doing wrong here?",['algebra-precalculus']
1400064,Cauchys integral formula on function with pole of order 2,I want to compute the integral $$\int_{|z - 1| = 1/2}  \frac{e^{iz}}{(z^2-1)^2} \mathrm{d}z$$ using Cauchy's integral formula (residual theorem is not allowed). Examining the integrand one gets $$ \frac{e^{iz}}{(z^2-1)^2} = \frac{e^{iz}}{(z-1)^2(z+1)^2}.$$ The problem is that I can't decompose the integrand as $$f(z) \frac{1}{1-z}$$ since $f$ won't be holomorphic on $B_{1/2}(1)$ because the singularity of the integrand at $z=1$ is a pole of order $2$. I think a partial fraction decomposition won't help. How should I proceed?,['complex-analysis']
1400069,"inequality $\max\{a_1,a_2,\cdots,a_n \}\leq {n^2}^{n-1}.$with Egyptian fraction","Let $a_1,a_2,\cdots,a_n $ be positive integer such that$\frac{1}{a_1}+\frac{1}{a_2}+\cdots+\frac{1}{a_n}=1.$ Prove that$$\max\{a_1,a_2,\cdots,a_n \}\leq {n^2}^{n-1}.$$ This Problem from: 1","['contest-math', 'number-theory', 'inequality']"
1400074,The case of Captain America's shield: a variation of Alhazen's Billard problem,"I'm sure a lot of you are acquainted with Alhazen's Billiard problem, which involves finding the point on the edge of a circular billiard table at which a cue ball at a given point must be aimed in order to canon off the edge of the table and hit another ball at a second given point. While reading on this math problem, I thought of my favorite Marvel superhero, Captain America (Cap'). You may also know that Cap' has a special ability in which he is able to throw his shield in way so that it will ricochet off certain objects and return to him. Let's examine a scenario that places him in the context of the Billiard problem: Cap' is standing at point C in an empty circular room. ( Point C is not at the centre of the room , because if so he'd be able to throw the shield in any direction and have it bounce off the wall and return to him, since any trajectory would be the normal to the tangent at the point where the shield hits the wall. C is also not on the edge of the circle because that would lead to a trajectory based on inscribed polygons.) At point C , to have the shield return to him with 1 richochet, all Cap' needs to do is similarly throw the shield along the line of symmetry of the room that passes through C , so we'll constrain his aim to a point not on that line of symmetry, which means we'll be looking for 2 ricochets or more. These are the scenarios I'd like you all to consider: Where should Cap' aim to have the shield return to him in: 2 ricochets 3 ricochets 4 ricochets n ricochets? Edit : From the answers I've read and my own working, I believe there is a pattern for trajectories with either odd or even bounces. It would be nice if someone could algebraically find a generalized way to compute the coordinate of the ricochet point given the number of times we want the shield to bounce off the wall before returning. Note: For sake of mathematical analysis, let's assume the shield (a point mass) always moves in a straight line, does not lose kinetic energy and obeys the Law of reflection ( angle of incidence = angle of reflection. )","['algebraic-geometry', 'geometry', 'triangles', 'trigonometry', 'recreational-mathematics']"
1400088,"For every probability $\mu$ on $(\Bbb R,\mathcal{B}(\Bbb R))$ exists at least a real r.v. $X$ s.t. $P^X=\mu$","Given a probability $\mu$ on $(\Bbb R,\mathcal{B}(\Bbb R))$, does exist always some random real-valued variable $X$ (defined on some probability space $(\Omega,\mathcal{A},P)$) such that its distribution $P^X$ be the same probability on $(\Bbb R,\mathcal{B}(\Bbb R))$ as $\mu$? I think yes, and I think this should be a general result, but I never read it anywhere! Many thanks!","['probability-theory', 'probability-distributions']"
1400091,Why does the Hausdorff metric need to be defined on bounded subsets only?,"Claim: Suppose $X$ is a non-empty set and $d$ is a metric on $X$. Let
$S(X)$ denote the collection of all non-empty closed bounded
subsets of $X$. For each $A$ and $B$ in $S(X)$, define $$h(A,B) = \max~ \big ( ~\sup ~\{~ dist~(b,A)~|~b \in B ~\},~ \sup ~\{~dist~(a,B)~|~a \in A~ \}~ \big )$$
Then $h$ is a metric on $S(X)$. It is called the Hausdorff metric. Proof is as follows : However, I haven't been able to find an exact use for taking $S(X)$ as the set of all bounded subsets of $X$ which are also non empty and closed. Could someone please tell me the use of taking bounded subsets here? Thank you very much for your help in this regard.","['metric-spaces', 'general-topology']"
1400101,Expected travel of random walk in arbitrary game with multiple payouts,"As explained here , the average distance or 'travel' of a random walk with $N$ coin tosses approaches: $$\sqrt{\dfrac{2N}{\pi}}$$ What a beautiful result - who would've thought $\pi$ was involved! However, what would be the formula to use for an arbitrary paytable? For example, a coin toss has the paytable: 0.5 : -1 0.5 : 1 ...so a 50% chance of both winning or losing a point. After 10,000 coin tosses, the travel on average will be $\sqrt{10000\cdot2/{\pi}} \approx 79.788$. However a dice roll where you need to land a six to win could have the paytable: 0.8333.. : -1 0.1666.. : 5 After 10,000 dice rolls, the travel on average will be about 178. However, I only know that because I used simulation to brute force the result - I don't know the formula. More generally, a paytable could have multiple entries where all the probabilities add up to one: probability1 : payout1 probability2 : payout2 probability3 : payout3 ... ... probabilityN : payoutN Note that the total of the payouts may not necessarily be zero. It could be weighted to produce an unfair game. For example: 0.75 : -1 0.1 : 0.5 0.15 : 4.5 That's an average payout of $-0.025$ with a variance of $3.811875$, and using simulation, I get $\approx 268.8$ 'travel' from 10000 runs. But how would I find this out directly? In other words, how would you find the average 'travel' of such a generalized paytable without resorting to simulation? As a side question, would this figure also be a better indication of risk for such a 'game' compared to the standard deviation of the paytable as defined here ? Here's the code I used for the simulation: http://pastebin.com/985eDTFh It's written in C#, but is otherwise very well self-contained. Most of it is a fast random class, but you can use the default Random class if you prefer. Also, if you're not using C#, don't worry too much about converting the convertCSVtoPayoutTable() function as you can hard code the probability and payout arrays yourself if you prefer.","['simulation', 'probability', 'game-theory', 'random-walk']"
1400104,Quasicoherent sheaves as smallest abelian category containing locally free sheaves,"On page 362 of Ravi Vakil's notes , the author says ""It turns out that the main obstruction to vector bundles to be an abelian category is the failure of cokernels of maps of locally free sheaves - as $\mathcal O_X$-modules - to be locally free; we could define quasi-coherent sheaves to be those $\mathcal O_X$ modules that are locally cokernels..."" Indeed, the Stacks Project takes this as definition 10.1. Perhaps this is nitpicking, but I want to make sure - is this cokernel deficiency the only obstruction that needs fixing? What are some instructive examples displaying the failure of cokernels to be locally free? Since $\mathsf{QCoh}(X)$ is esentially defined as the minimal solution to the above obstruction, should it be viewed as the ""universal solution"" to removing it? In the case of finite rank locally free sheaves, $\mathsf{Coh}(X)$ is an even smaller abelian category containing them, so am I to understand quasicoherence is there to take care of all locally free sheaves? Last nitpick - does definition 10.1 say $\mathcal F|_U$ is merely isomorphic to the cokernel object or that coupled with an epi it is an actual realization of the cokernel?","['vector-bundles', 'algebraic-geometry', 'quasicoherent-sheaves', 'sheaf-theory', 'coherent-sheaves']"
1400108,Evaluating Elliptic Integrals in terms of Gamma Function,"Some complete elliptic integral of first and second kind $E(k)$ and $K(k)$ can be evaluated for some particular values of $k$ in terms of Euler Gamma function. For example, for $k = \sqrt{2}/2$, $E(k)$ and $K(k)$ can be evaluated in terms of $\Gamma(1/4)$. Regarding this topic, I raise the following two questions: 1 - I am curious, about the mathematical procedure which is implemented to transform the elliptic integral to an integral solvable using the Gamma function. I was able to figure out the transformation for the case $k = \sqrt{2}/2$, but couldn't do it for other values of $k$ for which I know that their corresponding elliptic integrals are indeed expressed in terms of Gamma function (e.g. $k = \frac{\sqrt{6} - \sqrt{2}}{4}$). What is the sequence of transformations applied to the elliptic integral to generate the resulting integral solvable in terms of Gamma function (Hint: The Euler Beta function $B(x,y)$ is indeed involved in this evaluation)? 2 - Is there a mathematical formula through which we can tell the values of $k$ whose corresponding elliptic integrals $K(k)$ and $E(k)$ are solvable by Euler Gamma function? and if so, is there a direct solution to the integral in terms of $k$? Please support your answers with necessary references whenever possible. Thanks in advance for your help.","['gamma-function', 'calculus', 'real-analysis', 'elliptic-integrals']"
1400130,How to prove that this matrix is total unimodular,"This matrix is total unimodular (tested by a computer program). 1 1 1 1 -1 -1 -1 -1
0 1 1 1  0 -1 -1 -1
0 0 1 1  0  0 -1 -1
0 0 0 1  0  0  0 -1
1 0 0 0 -1  0  0  0
1 1 0 0 -1 -1  0  0
1 1 1 0 -1 -1 -1  0
1 1 1 1 -1 -1 -1 -1 Is there way to prove theoretical that this matrix is total unimodular? I already tried some stuff from the wikipedia article, but the one criteria fails, because it has more than at most two non-zero entries per column .","['determinant', 'integer-programming', 'matrices']"
1400155,Is there a fundamental way to prove Generalized Mean is a increasing function,"Generalized mean:
$$M_k=\left(\sum_{i=1}^n\frac{{x_i}^k}{n}\right)^{\frac 1 k}$$ I try to prove $L=\ln\left(M_k\right)$ is increasing. $$\frac{d\left(L\right)}{dk}=\frac{\sum_{i=1}^n{x_i}^k\ln\left(x_i\right)}{\sum_{i=1}^n{x_i}^k}$$ and I stuck here. I visited wikipedia and it says this can be proved using Jesen's inequality. But I want a simple one(or complicated one, if one think using Jesen's inequality is more easier). Any help is going to be appreciated. Thanks","['statistics', 'probability', 'calculus', 'real-analysis']"
1400198,Is $A\cup B=A\cup \{B\cap A^c\}$?,"I am reading the book ""Statistical Inference"" by Casella and Berger. I was wondering if an identity in Theorem 1.2.9 b is correct. They proves the following: If $P$ is a probability function and $A$ and $B$ are any sets in sigma-algebra $\mathcal B$, then $P(A\cup B)=P(A)+P(B)-P(A\cap B)$. Their proof starts as follows: To establish (b), we use the identity
$$A\cup B=A\cup \{B\cap A^c\}.$$
Should this be
$$A\cup B=A\cup (B\cap A^c)?$$","['elementary-set-theory', 'probability']"
1400217,Proving that a function is odd,"Assume that there exists a function $f:\mathbb{R}\to\mathbb{R}$ that is bijective and satisfies
$$
f(x) + f^{-1}(x)=x
$$
for all $x$. Here $f^{-1}$ is the inverse function. Show that $f$ is odd. This was a brain-teaser given to me by a friend. Two other related questions are: Show that $f$ is discontinuous Give an example of such a function (if indeed one exists). Edit: As an initial idea, maybe approaching the problem graphically would help? A function and its inverse are reflections of each other about $y=x$ on the $x$-$y$ plane. Does this lead to anywhere?","['real-analysis', 'functions']"
1400227,"Understanding implicit differentiation with concepts like ""function"" and ""lambda abstraction.""","In high school, we learned to reason like so: $$(*) \qquad \frac{d}{dx}(x^2+x) = \frac{d}{dx}(x^2)+\frac{d}{dx}(x) = 2x+1$$ Now that I know more, I can ""reanalyze"" this chain of reasoning using ideas that I have more faith in, like ""function"" and ""lambda abstraction."" We begin by defining $\nabla (f)$ as the derivative of $f$. Then the above chain of reasoning becomes: $$\nabla\mathop{\lambda}_{x:\mathbb{R}}(x^2+x) = \nabla\mathop{\lambda}_{x:\mathbb{R}}(x^2)+\nabla\mathop{\lambda}_{x:\mathbb{R}}(x) = \left(\mathop{\lambda}_{x:\mathbb{R}}2x\right) +\left(\mathop{\lambda}_{x:\mathbb{R}}1\right) = \mathop{\lambda}_{x:\mathbb{R}}(2x+1)$$ So I can confidently say that I understand $(*)$, because I can reanalyze it in terms of ideas that I have a lot of faith in, like ""function"" and ""lambda abstraction."" Onwards. In high school, we also learned a pattern of reasoning that was referred to as ""implicit differentiation."" It looks a bit like so: Suppose $y^2+x = x^2+y.$ Then: $$\frac{d}{dx}(y^2+x) = \frac{d}{dx}(x^2+y).$$ $$\therefore 2y \frac{dy}{dx}+1 = 2x+ \frac{dy}{dx}$$ $$\therefore (2y-1)\frac{dy}{dx} = 2x-1$$ $$\therefore \left(\frac{dy}{dx} = \frac{2x-1}{2y-1}\right) \vee (y = 1/2)$$ Unfortunately, I still have absolute no idea what any of this means. Question. How can we reanalyze implicit differentiation using respectable concepts like ""function"" and ""lambda abstraction"" and ""limit"", and without using concepts such as as ""dependent variable"" and ""independent variable"" and ""differential."" Edit. It seems to be unclear what I'm looking for. I'm not looking for handwaiving and intuition. I want something as formal as possible, with the minimum of handwaiving. For example, if you're going to ""switch"" semantics so that $y^2+x=x+y^2$ is no longer a condition on pairs of points $(x,y) \in \mathbb{R}^2$ but instead becomes a condition on smooth functions $(a,b) \rightarrow \mathbb{R}^2,$ you should make that completely clear, introduce notation for the set of paths, etc., and the rest of your answer should be phrased in terms of this notation. Write definitions. State theorems if relevant. Tell me the domains and codomains of all your functions. I want the absolute technical logical and/or set-theoretic nitty-gritty here.","['implicit-differentiation', 'calculus', 'derivatives']"
1400231,Application of Poincaré-Bendixson theorem,"Consider the system $$x' = 3xy^2-x^2y \\
y' = 5x^2y - xy^2$$ Show that the system has no periodic solutions. This is a tricky example. Linearization leads nowhere and I'm having a hard time constructing a Lyapunov function that does the trick. $V = 1/2(x^2+y^2)$ gives $$V'(x,y) = 3x^2y^2-x^3y +5x^2y^2 -xy^3 = 8x^2y^2 -xy(x^2+y^2))$$ But this doesn't tell us much nice things about the origin. If anything, it looks as though the origin is repelling since small perturbations gives us that the $8x^2y^2$ term dominates the minus term. Maybe it's possible to show that there are no elliptical orbits somehow, but that doesn't exclude other, more exotic, periodic trajectories. How to proceed...?","['dynamical-systems', 'ordinary-differential-equations']"
1400246,A question on Stokes theorem for Lipschitz functions,"Let $M$ be an oriented compact Riemannian manifold. Let $f$ be a Lipschitz function on $M$, denote $M'\subset M$ be the set on which $f$ is differentiable. On one hand, Stokes theorem works for Lipschitz functions, so we have
$$0=\int_M \Delta f.$$ On the other hand I was wondering do we have
$$\int_M\Delta f=\int_{M'}\Delta f\ \ ?$$ In other words, if $f$ is Lipschitz on $M$, and $\Delta f\geq 0$ on $M'$, could we conclude that $f$ has to be a constant?","['differential-geometry', 'riemannian-geometry']"
1400264,Can you use the sum formula for a geometric series starting at any point?,"Wherever I see the sum of a infinite geometric series with $|r|<1$ being derived the series always starts at $n = 0$, or $n = 1$, the basic form is $$a + ar + ar^2 + ar^3 + ... $$ And the sum is $\frac{a}{1-r}$ Does that still apply for a geometric series that starts at say n = 101, so $$ar^{100} + ar^{101} + ar^{102} +... $$",['sequences-and-series']
1400267,"$G$ finite, the number of distinct conjugates of $x$ is the index of the normalizer $N_x$ of $\{x\}$ in $G$","In order to prove this, I did the following: first, I showed that conjugacy forms an equivalence relation, then I can find its conjugacy classes. I understand how to form a conjugacy class, given a group. So, the index of the normalizer of $\{x\}$ in $G$ is the number of cosets of $N_x$ in $G$, right? The set $N_x$ should be $\{a: ax = xa\}$, right? How does this set look? I need to find it, so I can take its quotient with $G$ and count how many of them exist. But how to do it? I'm lost. UPDATE: I think I got it: $a\in N_G(H)b \iff ab^{-1} \in N_G(H) \iff ab^{-1}H = Hab^{-1} \iff
 b^{-1}H = a^{-1}Hab^{-1} \iff b^{-1}Hb = a^{-1}Ha$ So, two conjugates are equal $\iff $ their elements are in the same
  coset of $N_G(H)$ Thus, there is an explicit bijection between the set of different conjugates and the normalizer, so there are $[G:N_G(H)]$ different conjugates of $H$.","['abstract-algebra', 'group-theory', 'finite-groups']"
1400275,Calculate $\iint{f d\mu dv}$ and $\iint{f dv d\mu}$,"The purpose of this problem is to show that in Fubini-Tonelli theorem, the condition $f \in L^{+}(X \times Y)$ or $f \in L^1$ is necessary. Here is the problem: Let $X = Y = \mathbb{N}$, $\mathcal{M} = \mathcal{N} = \mathcal{P}(\mathbb{N})$, $\mu = v =$ counting measure. Define $f(m, n) = 1$ if $m = n$, $f(m, n) = -1$ if $m = n + 1$ and $f(m, n) = 0$ otherwise. Then $\int{|f|}d(\mu \times v) = \infty$ and $\iint{fd\mu dv}$ and $\iint{fdvd\mu}$ exist but are not equal. I can prove that $\int{|f|}d(\mu \times v) = \infty$, but I don't know how to calculate $\iint{fd\mu dv}$ and $\iint{fdvd\mu}$. Anyone can help me. I really appreciate.","['real-analysis', 'measure-theory', 'integration']"
1400292,How to prove this identity of ceiling function?,"My book writes down this identity of least integer function: $$\lceil x\rceil +\left\lceil x + \frac{1}{n}\right \rceil + \left\lceil x + \frac{2}{n}\right \rceil + \cdots +\left\lceil x + \frac{n -1}{n}\right \rceil = \lceil nx\rceil + n-1 $$. It didn't deduce it, however. I googled a bit about ceiling function but couldn't find any deduction. It is more like Hermite's Identity of floor function. Can anyone show me how to deduce this?","['ceiling-and-floor-functions', 'functions']"
1400295,Show that there exist a prime divisor of $\sigma{((2^k)!)}$ which is greater than $2^k$,"Let $k$ be a positive integer. Show that there exists a prime divisor of $\sigma{((2^k)!)}$ which is greater than $2^k$, where $\sigma{(n)}$ is the sum-of-divisors function.",['number-theory']
1400299,"Prove that for any two sets $|X|$ and $|Y|$, either $|X|\leq|Y|$ or $|Y|\leq|X|$. [duplicate]","This question already has answers here : Proving $(A\le B)\vee (B\le A)$ for sets $A$ and $B$ (6 answers) Closed 8 years ago . Prove that for any two sets $|X|$ and $|Y|$, either $|X|\leq|Y|$ or $|Y|\leq|X|$. I know that there is a proof using Zorn's Lemma but I can't figure out how to do it.",['elementary-set-theory']
1400305,Why is the image of a C*-Algebra complete?,"I am currently working through the book by Bratteli and Robinson on C* and W* algebras, there is one point at the beginning of chapter 2.3 that is frustrating me. If we take *-morphism to be a function $\pi: U \to B$ between $C^*$-algebras $U,V$ with: $\pi$ is linear and multiplicative $\forall A \in U,$ $\pi(A^*)=\pi(A)^*$ Then a property is of such a map is $||\pi(A)||≤||A||$ (so contractive and as such continuous). The book remarks that the image of $U$ is closed by ""an easy"" application of this continuity property. However I cannot reach the result and I feel like I am failing to do something extremely obvious. Does anybody have any tips? (It is maybe interesting to note that in the erratum they comment that the line ""by an easy"" is to be omitted! One more comment: Since $U$ and $V$ are complete normed vector spaces, I am taking it to be equivalent for a subset to be complete or closed)","['c-star-algebras', 'linear-algebra', 'functional-analysis']"
1400312,"Exist complex $z_{0}$ ,such $|z_{0}|=1$,and $|f(z_{0})|\le|f(z)|,\forall |z|\ge 1$","Let $a\in (0,1), f(z)=z^2-z+a, z\in \mathbb C$. Does there exist a complex number $z_{0}$ such that $|z_{0}|=1$, and 
$$|f(z_{0})|\le|f(z)|,\forall |z|\ge 1$$
I just have no idea where to even begin so any hint will be much appreciated. I apologize for not showing any effort. Any help will be appreciated. Thanks Is there a method without using the Maximum Modulus Principle to solve this problem?","['contest-math', 'complex-analysis']"
1400316,"Closed-form of the hypergeometric function ${_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,-t\right)$","Inspired by this question and by using Mathematica the following conjecture seems to be true for all nonzero complex $t$ number:
$${_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,-t\right) \stackrel{?}{=} \frac{16}{3t}\ln\left(\tfrac14\sqrt{1+\sqrt{1+t}}\left(\sqrt{1+\sqrt{1+t}}+\sqrt{2}\right)\right),$$
where ${_4F_3}$ is a generalized hypergeometric function . How could we prove this conjectured identity? Some special cases: $$\begin{align}
{_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,-4\right) &\stackrel{?}{=} \frac{4}{3}\ln\left(\frac{\sqrt{\varphi}+\varphi}{2}\right),\\
{_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,-8\right) &\stackrel{?}{=} \frac{2}{3}\ln\left(\frac{\sqrt2 + 2}{2}\right),\\
{_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,-15\right) &\stackrel{?}{=} \frac{16}{45}\ln\left(\frac{\sqrt{10} + 5}{4}\right),\\
{_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,-35\right) &\stackrel{?}{=} \frac{16}{105}\ln\left(\frac{\sqrt{14} + 7}{4}\right),\\
{_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,-48\right) &\stackrel{?}{=} \frac{1}{9}\ln 3,
\end{align}$$
where $\varphi$ is the golden ratio . Specially for all $n \neq 1$ nonnegative integers $${_4F_3}\left(\begin{array}c1,1,\tfrac54,\tfrac74\\\tfrac32,2,2\end{array}\middle|\,1-n^2\right) \stackrel{?}{=} \frac{16}{3n^2-3}\ln\left(\frac{\sqrt{2n+2}+(n+1)}{4}\right).$$","['closed-form', 'calculus', 'hypergeometric-function', 'special-functions']"
1400317,References for the threefold categorical equivalence of compact Riemann surfaces?,"A lot of the books I've found assert that there is a threefold categorical equivalence between (1) compact Riemann surfaces, (2) smooth projective algebraic curves, and (3) function fields of transcendence degree one. None of them give many details though. I know how to embed compact Riemann surfaces in projective space and then use Chow's theorem to establish an analytic isomorphism between (1) and (2). Are there any good references which give a detailed argument for categorical equivalence though? More specifically, I guess I want answers/references for the following: What are the arrows associated with each of these categories? (everybody is kind of vague about this) What are the functors which establish the equivalence? For Riemann surfaces and algebraic curves, is it just the isomorphism constructed from the embedding and Chow's theorem? How do I show that these functors are full and faithful? I would also appreciate it if someone could direct me to a good treatment of the relation between function fields and the other two. Miranda, Kirwan, etc. don't cover this point too well.","['algebraic-geometry', 'riemann-surfaces', 'category-theory']"
1400318,Probability generating function of bivariate Poisson distribution!,"Problem setup: $X_1=Y_1+Y_0,X_2=Y_2+Y_0$
where $Y_1, Y_2\text{ and }Y_0$ are independent Poisson random variables with parameters $θ_1, θ_2\text{ and }θ_0$, respectively. I know that the joint probability function of bivariate Poisson distribution is given by: $P(X_1 = x_1, X_2 = x_2) = e^{-(\theta_{1}+\theta_{2}+\theta_{0})} \displaystyle\frac{\theta_{1}^{x_1}}{x_1!}\frac{\theta_{2}^{x_2}}{x_2!} \sum_{i=0}^{min(x_1,x_2)}\binom{x_1}{i}\binom{x_2}{i}i!\left(\frac{\theta_{0}}{\theta_{1}\theta_{2}}\right)^{i}$ Also, the joint probability generating function is:
$exp⁡{(θ_1 (t_1-1)+θ_2(t_2-1)+θ_0(t_1 t_2-1))}$ My question is: how can we derive this probability generating function from the joint probability function? I tried but I couldn't find this result! If anyone knows, please give me a helping hand. Also, how can I derive the probability generating function in general for the multivariate case? Thanks in advanced.","['probability', 'statistics', 'probability-distributions', 'discrete-mathematics']"
1400327,Existence of a random variable,"Let $\mu$ be a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$, where $\mathcal{B}(\mathbb{R})$ denotes the Borel sets. Then, is it true that there exists a probability space $(\Omega,\Sigma,\mathbb{P})$ and a random variable $X$ defined on this probability space such that $$ P(X \in B) = \mu(B)$$ for every borel set $B$? I know the ""converse"" of the claim is true: given a random variable $X$ on some probability space, there exists a probability measure on $\mathbb{R}$ such that $ P(X \in B) = \mu(B)$.","['probability-theory', 'probability']"
1400337,$a \in G$ commutes with all its conjugates iff $a$ belongs to an abelian normal subgroup of $G$ [duplicate],"This question already has answers here : Prove that $a$ commutes with each of its conjugates in $G$ iff $a$ belongs to an abelian normal subgroup of $G$. (2 answers) Closed 8 years ago . Let $a\in G$, where $G$ is a group. Prove that $a$ commutes with each of its conjugates in $G$ if and only if $a$ belongs to an abelian normal subgroup of $G$. This is what I did: $""⟹""$ First, I thought  of $<a>$ to be that normal subgroup containing a. But if it is true, I am not sure how to prove it. Then I thought of another subgroup, namely $C_G(a)$.
  I conclude from the hypothesis given that $Cl_G(a) ⊂ C_G(a)$ 
And I know that  $|Cl_G(a)| = |G :  C_G(a)|$ by G acting transitively on $Cl(a)$ by conjugation. But I don't know how to get that $ C_G(a)$ is normal in $G$. I am thinking also of  a normal subgroup of $G$ , say $K$ containing $a$, so
 $<a>$ $\cap$ $K$ and  $ C_G(a)$ $\cap$ $K$ are subgroups of G inheriting abelianity from   $<a>$  and $ C_G(a)$ respectively, and normality from $K$. $""\Leftarrow""$ Let $a ∈ H$ s.t. $H$ is an abelian normal subgroup of G. So $ah=ha$, ∀ $h∈H$. Since $H$ is normal in $G$, hence $g^{-1}hg ∈ H$, ∀ $g∈G$ So $g^{-1}ag ∈ H$, ∀ $g∈G$ Which means 
   $Cl_G(a)$ $\subseteq$ $ H$ Therefore, a commutes with each of its conjugates in G. Could someone correct me?","['abstract-algebra', 'group-theory', 'proof-verification']"
1400376,What is the difference between complex differentiable and holomorphic functions at a point?,"What is the difference between: a) a complex differentiable at a point $z$ or b) a holomorphic at a point $z$, for a function $f(z)$, on the complex plane? It was my understanding that holomorphicity is just stronger than differentiability i.e. everywhere in the neighbourhood of that point is complex differentiable. How do you go about showing where a complex function is either complex differentiable or holomorphic? Any help would be greatly appreciated!",['complex-analysis']
1400379,"Laplace transform of functions related to type $\mathcal{S}$, and the relation to entire functions","I have doubts in the following two questions      : What is the Laplace transform of $[x^k\varphi(x)]^{(q)}$, where $\varphi\in \mathcal{S}_\alpha^\beta$ and $-\infty<x<\infty$ , $k,q=0,1,2,...$? I know that the Fourier transform of $[x^k\varphi(x)]^{(q)}$ is $\xi^q\varphi^{(k)}(x)$. Also we know that Fourier transform takes differentiation to polynomial multiplication. Does a similar result hold for laplace Transform also or is it different ? How to prove the following assertion: If an entire function $\varphi$ satisfies $$|\varphi(x+iy)|\le C\exp(a|x|^h+b|y|^{\gamma}), \:\:\:h\le\gamma$$ 
where $a\lt0$ and $C>0$, then $\varphi\in \mathcal{S}_{1/h}^{1-1/{\gamma}}$, where $\mathcal{S}_\alpha^\beta$ is the Gelfand-Shilov space of type $\mathcal{S}$ defined here Any help will be welcome. Thanks.. Reference: Generalized Functions, Volume 2, by I.M Gelfand and G.E. Shilov","['gelfand-shilov-spaces', 'distribution-theory', 'functional-analysis', 'laplace-transform', 'partial-differential-equations']"
1400394,"How does the PDE $\,\dfrac{d^2u}{dx^2} = 0\,$ become $\,u=x\,f(y)+g(y)\,$ when integrated?","Given that $u(x,y)$ can someone please explain to me how the result as asked in the question is achieved? Steps would be really appreciated, thanks.","['partial-differential-equations', 'ordinary-differential-equations', 'integration']"
1400399,"Another integral $\int \frac{3 x^2+2 x+1}{ \left(x^3+x^2+x+2\right) \sqrt{1+\sqrt{x^3+x^2+x+2}}} \, dx$","Here is an indefinite integral that is similar to an integral I wanna propose for a contest. Apart from 
using CAS, do you see any very easy way of calculating it? $$\int \frac{1+2x +3 x^2}{\left(2+x+x^2+x^3\right) \sqrt{1+\sqrt{2+x+x^2+x^3}}} \, dx$$ EDIT: It's a part from the generalization $$\int \frac{1+2x +3 x^2+\cdots n x^{n-1}}{\left(2+x+x^2+\cdots+ x^n\right) \sqrt{1\pm\sqrt{2+x+x^2+\cdots +x^n}}} \, dx$$ Supplementary question: How would you calculate the following integral using the generalization above? Would you prefer another way? $$\int_0^{1/2} \frac{1}{\left(x^2-3 x+2\right)\sqrt{\sqrt{\frac{x-2}{x-1}}+1} } \, dx$$ As a note, the generalization like the one you see above and slightly modified versions can be wisely used for calculating very hard integrals.","['indefinite-integrals', 'calculus', 'real-analysis']"
