question_id,title,body,tags
246380,Difference of differentiation under integral sign between Lebesgue and Riemann,"Here is a consequence of Lebesgue dominated convergence theorem on differentiation under integral sign. Function $f(x, t)$ is differentiable at $x_0$ for almost all $t \in A$, and $t \to f(x, t)$ is integrable. Moreover, there exist an integrable  function $g(t)$ such that $|(\partial{f}/\partial{x})(x,t)| \le g(t)$. Then we have
  $$\frac{\mathrm{d}}{\mathrm{d}x} \left( \int_A f(x,t) ~ \mathrm{d}t \right)\bigg|_{x=x_0} = \int \frac{\partial{f}}{\partial{x}}(x_0,t) ~ \mathrm{d}t. $$ Of course, here the word ""integrable"" means ""Lebesgue integrable"". But, if we read the word ""integrable"" as ""improper Riemann integrable"" and add an assumption that the partial derivative is continuous, then I think the statement is still true. Weierstrass M-test for integrals guarantees uniform convergence of the improper integral and we can interchange the differentiaion and integration. If $f$ is integrable in both of (improper) Riemann and Lebesgue sense, the only gain of interpreting the integral as Lebesgue one is gettig rid of the continuity condition of the partial derivative. Is it right?","['lebesgue-integral', 'convergence-divergence', 'real-analysis']"
246386,Finding asymptotes of exponential function and one-sided limit,"Find the asymptotes of
$$
\lim_{x \to \infty}x\cdot\exp\left(\dfrac{2}{x}\right)+1.
$$
How is it done?","['exponential-function', 'limits']"
246394,Does $\beta \mathbb N$ embed into $\beta \mathbb N \setminus \mathbb N$?,"Is there a clopen subset of $\beta \mathbb N \setminus \mathbb N$ homeomorphic to $\beta \mathbb N$? If so, is there any plausible description of any such a subspace?","['general-topology', 'filters', 'set-theory']"
246399,Why isn't this free product of groups abelian?,"I'm trying to prove that the free group $A=A_1*A_2$, where $A_1, A_2\neq 1$ is not abelian. Following the hints below: Let $x,y\in A_1*A_2$, where $x\neq y$. Suppose now $A_1=F(S)$ and $A_2=F(T)$, where $S=\{\alpha_1,\ldots,\alpha_n\}$ and $T=\{\beta_1,\ldots\beta_m\}$ Let $x,y\in A_1*A_2$, where $x\neq y$, then we have the words $x=\alpha_1^{n_1}\ldots\alpha_k^{n_k}$ and $y=\beta_1^{m_1}\ldots\beta_l^{m_l}$ Thus using the definition of the operation of the free products, we have $x\cdot y=\alpha_1^{n_1}\ldots\alpha_k^{n_k}\beta_1^{m_1}\ldots\beta_l^{m_l}$ $y\cdot x=\beta_1^{m_1}\ldots\beta_l^{m_l}\alpha_1^{n_1}\ldots\alpha_k^{n_k}$ Am I correct so far? I can't continue from that point, since $k$ and $l$ can be different. Thanks","['algebraic-topology', 'free-groups', 'group-theory', 'abstract-algebra']"
246402,Eigenvalues of Hilbert-Schmith operator,"I am having trouble determining the eigenvalues and eigenvectors of the operator $Kv(x)= \int_0^1((x+t)v(t)dt$, where the kernel is $k=x+t$. I have tried to solve the equation $Kv(x)=\lambda v(x)$, and I know that I should get two eigenvalues, but I can't seem to find them. Is there a standard method to finding the lambda's other than solving the equation $Kv(x)=v(x)$? Thanks for the help!","['compact-operators', 'eigenvalues-eigenvectors', 'spectral-theory', 'functional-analysis']"
246412,Prokhorov metric vs. total variation norm,"Let $(S,d)$ be a metric space and let $\mathcal P(S)$ denote the space of Borel probability measures on $S$ endowed with the Prokhorov metric $\pi:\mathcal P(S)\times \mathcal P(S)\to \mathbb R_+$ given by
$$
  \pi(P,Q):=\inf\{\varepsilon\geq 0:P(F)\leq Q(F^\varepsilon)+\varepsilon \text{ for all closed } F\subset S\}
$$
where the $\varepsilon$-inflation of a set is given by  $  F^{\varepsilon} = \{x\in S:d(x,F)<\varepsilon\}.$ Another useful metric on $\mathcal P(S)$ is induced by the total variation norm, i.e. 
$$
  \rho(P,Q):=\sup\limits_{A\in \mathfrak B(S)}|P(A) - Q(A)|
$$
where $\mathfrak B(S)$ is the Borel $\sigma$-algebra on $(S,d)$. I wonder if there are any interesting relations between these two metrics, $\pi$ and $\rho$. In particular, I know that convergence in $\rho$ implies the weak convergence and hence if $S$ is separable than it implies the convergence in $\pi$. I wonder, however, if under some additional assumptions it is possible to derive some non-trivial bounds on $\rho$ if I know upper bounds on $\pi$. Or at least, if it is possible to upper-bound $|P(F) - Q(F)|$ for closed $F$ using $\pi$.","['probability-theory', 'stochastic-processes', 'measure-theory', 'metric-spaces']"
246435,"Confused about why ""disjointifying"" implies ""AC""","Assume I have the following (DIS) For every indexed family $\{A_i : i \in I \}$ there exists a family $\{B_i : i \in I \}$ of pairwise disjoint sets such that $B_i \subset A_i$ for all $i \in I$ and $\bigcup_{i \in I} B_i = \bigcup_{i \in I} A_i$. and (AC) For every family $x$ of non-empty, pairwise disjoint sets, there exists a set $z$ such that $|z \cap y | = 1$ for each $y \in x$. I would like to show that $ZF \vdash (DIS) \rightarrow (AC)$ (that's another exercise in a book I'm currently reading). So let's assume (DIS) and let $B_i$ be a family of non-empty pairwise disjoint sets. I don't see how to proceed. I am supposed to use (DIS) to construct $z$ such that $|z \cap B_i| = 1$ but my sets $B_i$ are already pairwise disjoint so what can I do? Thanks  for your help.","['elementary-set-theory', 'axiom-of-choice']"
246436,"Trying to prove ""If the expectation of the random variable is a measure, then the random variable is a random measure.""","I try to solve the exercise 24.1.1 in Klenke's book on probability. The first part I got but I have a problem with: If $X$ is a random variable with values in $(\cal\tilde{M}$$(E),\cal{B}($$\cal\tilde{M}$$(E)))$ such that $\mathbb{E}[X] \in \cal{M}$$(E)$, then $X$ is a random measure. Where $E$ is a seperable metric space, $\cal\tilde{M}$$(E)$ is the space of all signed Radon measures on $E$ together with the vague topology and $\cal{M}$$(E)$ is the space of all Radon measures on $E$. Here my thoughts so far:
If $X$ was constructed as in the first part of the exercise, then it would easily follow as $\mathbb{E}[X] \in \cal{M}$$(E)$ implies $\mathbb{P}(X(B)<\infty)=1$ for every $B$ relatively compact. 
So if I was able to decompose any such $X$ into the form $X=\sum_{n =1}^{\infty}{\lambda_n X_n}$ given in the first part, then I would get the claim. However, I don't think this is possible as X is a priori a signed measure. Thanks for any hints.","['probability-theory', 'measure-theory']"
246442,"Finding where the parametric curve $(t^2-t, t^3 -3t -1)$ intersects itself","The problem I am working on is to find the where the curve intersects itself, using the parametric equations. These are: $x=t^2-t$ and $y=t^3-3t-1$ For the graph to intersect itself, there must be two distinct t-values, $a$ and $b$ , that when plugged into the parametric equations, produce the same output. These two t-values create two ordered-pairs that are the same. My system of equations: $$\begin{cases}a^2-a=b^2-b\\a^3-3a-1=b^3-3b-1 . \end{cases}$$ I solved for $a$ , but am not sure if I did it correctly: $a(a-1)=b^2-b$ then either $a=b^2-b$ or $a-1=b^2-b$ . I would then have two values that I have to test. When I plugged in $a$ , I ended up with a 6-degree polynomial, did I do something wrong?","['parametric', 'algebra-precalculus', 'solution-verification']"
246445,Existence of independent and identically distributed random variables.,"I often see the sentence ""let $X_1, X_2, \ldots$ be a sequence of i.i.d. random variables with a certain distribution"". But given a random variable $X$ on a probability space $\Omega$, how do I know that there is a sequence of INDEPENDENT random variables of the same distribution on $\Omega$?","['probability-theory', 'probability-distributions', 'independence']"
246460,Conditional probability of cows,"the question is that if you are a farmer and own six cows: 3 white, 2 black and one that is black on one side and white on the other. Then if you see two black cows (that is 2 black sides of cows) then what is the probability that one of them is the black and white cow? Here is my attempted answer:
if $M_1$ and $M_2$ are the events that the first or second cow is the mixed one and $b_1$ and $b_2$ denote that the sides of the first and second cow we see is black. then we are looking for $$P(M_1 \cup M_2 \mid b_1b_2)=\frac{P(M_1b_1b_2)+P(M_2b_1b_2)}{P(b_1b_2)}$$
$$=\frac{2P(M_1)P(b_1\mid M_1)P(b_2\mid M_1b_1)}{P(M_1 \cup M_2)P(b_1b_2\mid M_1 \cup M_2)+[1-P(M_1 \cup M_2)]P(b_1b_2\mid M_1^cM_2^c)}$$ then $P(M_1)$ = $\frac{1}{6}$ as there are $6$ sheep and only $1$ that is mixed. $P(b_1\mid M_1)= \frac{1}{2}$ as it can be one of two sides and $P(b_2\mid M_1b_1)=\frac{2}{5}$ as this is just the probability of choosing a black cow. So the numerator is equal to $\frac{1}{15}$. $P(M_1 \cup M_2) = P(M_1) + P(M_2)$ as they are disjoint and so is equal to $\frac{1}{3}$. Then $P(b_1b_2\mid M_1 \cup M_2)$ is just the probability that the other cow is black and we see the black side of the mixed sheep and so is $\frac{2}{5} *\frac{1}{2}$. Finally $[1-P(M_1 \cup M_2)]=\frac{2}{3}$ and $P(b_1b_2\mid M_1^cM_2^c)$ is $\frac{1}{10}$ as it is the number of all black pairs over the total number of pairs. so putting it all together. I get $\frac{\frac{1}{15}}{\frac{2}{15}}=\frac{1}{2}$ but the answer is supposedly $\approx .3$ EDIT The guy who wrote the paper made a mistake in the answers. It should be $\frac{1}{2}$",['probability']
246491,Stuck with proof for $\forall A\forall B(\mathcal{P}(A)\cup\mathcal{P}(B)=\mathcal{P}(A\cup B)\rightarrow A\subseteq B \vee B\subseteq A)$,"I came to point where I suppose for case 1 that $A\subseteq B$ and conclusion is trivial. For case 2 I suppose that $A\not\subseteq B$ and try to prove $B\subseteq A$, but that gets me nowhere. Any pointers here are most welcome.","['proof-writing', 'elementary-set-theory']"
246496,The mode of the Poisson Distribution,"Lately, I am doing an investigation on Stirling's formula and its applications. So I thought I could use it to prove that the mode of the Poisson model is approximately equal to the mean. Of course, you do that by considering the curve that is formed by connecting the points of the probabilities of occurrence and the different values of the discrete random variable. Then you differentiate the p.d.f. where for $x!$ you use Stirling's formula $x!\approx \sqrt{2\pi x}~x^xe^{-x}$. The result is $\lnλ-1/(2x)-\ln x$ whose roots cannot be found analytically, but by iterative methods we find that as λ is larger and larger, the mode~mean. Problem is, I found the following paper online, which seems to be the solution from a Harvard's undergraduate problem set. http://www.physics.harvard.edu/academics/undergrad/probweek/sol84.pdf It reads ""You can also show this by taking the derivative of eq. (2), with Stirling’s expression in place of the $x!$. Furthermore, you can show that $x = a[=λ ~\text{in my case}~]-1/2$ leads to a maximum $P(x)$ value of $P_\max\approx1/\sqrt{2\pi a}$."" Does this puzzle you as much as it puzzles me? My main concern is over the ""="" sign: how does this hold? The derivative=0 equation cannot have such an exact solution. Furthermore at such x, how does $P(X=a-1/2)$ give $1/\sqrt{2\pi a}$? Am I (and my professor) missing something rather obvious or is the solution wrong? Discuss! PS: This sort of question might have been asked before, but still, I am really curious that somebody reads the paper in the link above, so that I can figure out what's going on.","['probability-distributions', 'probability', 'numerical-methods']"
246505,"Given two adjacency matrices, how can I find if they're isomorphic?","Matrix 1:
\begin{matrix}
0&1&1&0\\
1&0&1&0\\
1&1&0&1\\
0&0&1&0
\end{matrix} Matrix 2:
\begin{matrix}
0&1&1&1\\
1&0&0&0\\
1&0&0&1\\
1&0&1&0
\end{matrix} I've looked on google to find out how to do this, but I can't find an answer that makes sense to me. As far as I can tell, there is no efficient algorithm to do this, so you need to check all the permutations... but I don't even know how to start. Any help would be great, Thanks.","['graph-theory', 'discrete-mathematics']"
246541,Show that the n-dimensional Hausdorff measure of an $n$-dimensional cube is positive and finite.,"Show that the n-dimensional Hausdorff measure of an $n$-dimensional cube is positive and finite. I can easily show that if it is finite then the $n+1$ dimensional measure is $0$ and the $n-1$ dimensional measure is $\infty$, but I'm not sure how to show that it is at exactly $n$ that the positive finite case occurs. Can anyone provide any tips?","['measure-theory', 'real-analysis', 'analysis']"
246547,"Why $2^\kappa=\kappa^{\operatorname{cf}{\kappa}}$, if $\kappa$ is a strong limit cardinal?","On Page 58, Set Theory, Thomas Jech(2006) states the following fact without details. Another fact worth mentioning is: 
  If $\kappa$ is a strong limit cardinal, $2^\kappa=\kappa^{\operatorname{cf}{\kappa}}$. My question is how to derive this ""fact""? My first guess is that strong limit cardinals are regular, but it's obviously wrong, since if so, definition of inaccessible cardinal would be redundant. So another question is what can we say about $\operatorname{cf}{\kappa}$ of a strong limit cardinal $\kappa$?","['cardinals', 'elementary-set-theory']"
246564,What's wrong with my Mac Grapher?,"I hope this question is not that stupid. $y=x^{\frac{-2}{3}}$ is $y=\frac{1}{\sqrt[3]{x^{2}}} $right?
But when I type $y=x^{\frac{-2}{3}} $and $y=\frac{1}{\sqrt[3]{x^{2}}}$into Mac Grapher,I  got different pictures. Since my reputation is not over 10,I can't post them,but it's very easy to do that.$y=x^{\frac{-2}{3}}$ did not show on negative direction of X-axis,while $y=\frac{1}{\sqrt[3]{x^{2}}}$ showed on all X-axis. EDIT:Thank you everyone,I can post pictures now or more examples and in some case they are same Here are some polynomial examples. Ther're also equal Another set And I did some research ,you can see Mac Grapher only show function with integer exponents Change 3 to 5 I could go on,but you get the ideas. Why did this happen,is there something wrong with my precalculus skill or Mac Grapher? Update：Some guy in Apple forum said""The functions are not the same. In the first case, you're raising a real number to a fractional power. That's ambiguous for negative arguments, so the program only graphs it for non-negative arguments. In the second case, you're raising a non-negative number to a fractional power.""","['algebra-precalculus', 'math-software']"
246565,Coin Tossing Game Optimal Strategy Part 2,"I recently asked a question, that was answered excellently: Coin Tossing Game Optimal Strategy Here I'd like to complicate the question slightly. This part stays the same: You start off with £100 and you toss a coin 100 times. Before each toss you choose a stake S which cannot be more than your current balance x (so your maximum stake for the first toss is £100). If the coin comes up heads, you win 2S and your new balance is x+2S. If it comes up tails, you lose your stake and have x−S. This time, though. Instead of maximizing the expected profit $E[P]$, we want to maxmise  $E[\log(100+P)]$. In both cases the initial balance of £100 is not included in any profit. How should we choose our bets in this case? Now, my first thought and indeed my answer was that whichever strategy maximizes the first case must also maximize the second.. but the very fact that it was asked makes me doubt myself? Any thoughts greatly appreciated! Boris",['probability']
246567,Sufficient Conditions for the Characteristic Function to Be Differentiable,"Given a random variable $X$, it's characteristic funciton is defined as: $$\phi_X(t) = \mathbb{E}[e^{itX}]$$ I'm wondering what conditions are required for the characteristic function of a random variable to be differentiable (i.e. for $\frac{d\phi_X(t)}{dt}$ to exist)?","['measure-theory', 'probability']"
246571,How to calculate the limit of $\frac{\sin(ax)}{x}$ for $x\to0$,"How can I calculate the following limit epsilon-delta definition? $$\lim_{x \to 0} \left(\frac{\sin(ax)}{x}\right)$$ Edited the equation, sorry...","['trigonometry', 'limits']"
246590,Evaluate $\lim\limits_{x \to \infty } {\left( {\int_0^{\pi /6} {{{(\sin t)}^x}dt} } \right)^{1/x}}$,"It is given that the following limit
$\mathop {\lim }\limits_{x \to \infty } {\left( {\int\limits_0^{\pi /6} {{{(\sin t)}^x}dt} } \right)^{1/x}}$ exists. Evaluate the limit. I've tried tackling this problem but I can't seem to get started. Any hint is appreciated, thanks!","['calculus', 'limits']"
246591,Associates are unit multiples in an Integral Domain,"Let $x$ and $y$ be nonzero elements of an integral domain $D$. Then $x$ and $y$ are associates if and only if $x = yd$ for some unit $d \in D$. I am done proving the $\Leftarrow$ part. For $\Rightarrow$ what I did was: If $x$ and $y$ are associates then $x \mid y$ and $y \mid x$, so $x \mid y$ implies that $xs = y$ for some $s \in D$ and $y \mid x$ implies that $yt = x$ for some $t \in D$. That is, $yts=y$ which implies $ts=1$. Therefore $s$ is a unit and $t$ is a unit. Am I on the right track? Can I say that the proof is complete?","['integral-domain', 'abstract-algebra', 'solution-verification']"
246594,What is vector division?,"My question is: 
We have addition, subtraction and muliplication of vectors. Why cannot we define vector division? What is division of vectors?","['calculus', 'vectors', 'divisibility']"
246615,Recovering a set of vectors from their Gram matrix,"Suppose $\{ v_1, \ldots, v_k \}$ is a set of vectors in $\mathbb{R}^n$. The associated $k\times k$ Gram matrix is given by
$$
G = [v_i \cdot v_j]_{i,j}
$$
It's (apparently) well known that the Gram matrix of a set of vectors determines the vectors up to an isometry of $\mathbb{R}^n$ (e.g. [1]) My question is: does anyone know of a reference for an algorithm that performs the reconstruction? More precisely, I'm looking for an algorithm that takes $G$ as input and outputs $\{ Av_1, \ldots, Av_k \}$ for some $A \in SO(n)$. [1] http://mathworld.wolfram.com/GramMatrix.html","['linear-algebra', 'reference-request']"
246624,Cyclotomy in extensions of $\mathbb{Q}_p$,Let $p$ be a prime number and $K$ be a finite extension of $\mathbb{Q}_p$. Denote by $\zeta_{p^n}$ a primitive $p^n$-th root of unity (where $n$ is a positive integer). Assume that $K$ contains $\zeta_{p^m}$ for some $m$. Is it possible to find a subextension $F \subset K$ such that $K$ is abelian over $F$ of degree prime to $p$ and such that $F$ does not contain $\zeta_p$ (and I mean $\zeta_p$ not $\zeta_{p^n}$) ? This is true when $K = \mathbb{Q}_p (\zeta_{p^m})$. What about the general case ?,"['galois-theory', 'p-adic-number-theory', 'number-theory']"
246638,Translations of Kolmogorov Student Olympiads in Probability Theory,"I am deeply interested in Kolmogorov's probability contest whose tests could be found in English for the five first years but there is no English translation to its problems from round 6 onward.
I have put the links to the original Russian problems and would be grateful to the contribution of Russian speakers in this forum to translate the questions to English. Many thanks in advance http://mech.math.msu.su/probab/olimpia/ol-sol.pdf http://mech.math.msu.su/probab/olimpia/olsol09.pdf","['translation-request', 'contest-math', 'mathematical-russian', 'probability-theory', 'stochastic-calculus']"
246643,Why is a linear combination of solutions also a solution?,"I'm working on DEs and I've come across some speedbumps.  I'm not very familiar with linear algebra and that might be the problem.  However, I'm sure that there's a non-linear algebra explanation that I could understand. Here's what I know right now: There's a thing called the Principle of Superposition, which says that if $y_0$ and $y_1$ are linearly independent solutions to a given linear DE, then so is $C_0y_0+C_1y_1$.  (The DE might have to be homogeneous, I'm not sure.)  I don't understand why this is true. If each solution is not a multiple of the other, then each is linearly independent from the other.  Beyond that explanation, I don't know what it means. Then, I want to learn how to show that this sum is a general solution.  This is where my book introduces Cramer's Rule.  Is there an intuitive explanation that will explain to me what is happening here? I'm learning from online sources and trying to mash together an explanation but they all tend to skip over the details here, or assume some form of precogniscience.  (You know, where an explanation of something low on the 'math tree' is given in terms of higher order mathematics.) When I work with a 1st-order DE, I understand that a general solution is a 'family' of solutions, given the unknown constant.  They're a one-dimensional family as it were.  I can represent this family as a directional field. With a 2nd-order DE, I guess that the general solution is a 2-dimensional family.  I don't know how I would represent that geometrically.  Maybe parametrically with a directional field?  I'm just guessing. Any explanations of any of these things would be very much appreciated.",['ordinary-differential-equations']
246644,Norm in L2 bounded by norm in H1,"I am studying FEM the very basics. I don't have a very strong background in math nor in functional analysis. Having said that, here's the problem I'm analyzing. $$ -\mu u'' + \sigma u = f ~~~~~ x \in (0,1) $$
$$u(0) = u(1) = 0$$ From that I got the bilinear form of the problem as: $$ a(u, v) = \int_\Omega \mu u'v'dx + \int_\Omega \sigma u vdx $$
$$ F(v) = \int_\Omega fvdx ~~~~~~~~~~\forall v \in V=H_0^1$$ I was trying to understand the proof of continuity of the bilinear form and I found that it could be proven as follows: $$|a(u,v)|= \Big|\int_\Omega \mu u'v'dx + \int_\Omega \sigma u vdx \Big|≤ \Big|\int_\Omega \mu u'v'dx\Big| + \Big|\int_\Omega \sigma u vdx\Big|$$
$$≤ \mu ||u'||_{L^2} ||v'||_{L^2} + \sigma||u||_{L^2}||v||_{L^2}$$
$$≤ \max(\mu, \sigma) (||u'||_{L^2} ||v'||_{L^2} + ||u||_{L^2}||v||_{L^2})$$ As far as I understand the stuff above is using the Cauchy-Schwarz inequality. Then to complete the verification of the continuity I have to ""change"" (I don't know if it's the correct word) from $L^2$ to $H^1$ because there's where I defined my space $V$ to be. So I found two expression that I don't understand how to interpret $$||u||_{L^2} ≤ ||u||_{H^1},~~~~~~~~||u'||_{L^2} ≤ ||u||_{H^1}$$ does it mean that a norm in $L^2$ is bounded by a norm in $H^1$ ?? If so, how can I visualize that (geometrically) ?","['ordinary-differential-equations', 'functional-analysis']"
246647,Fixed point of $\cos(\sin(x))$,"I can show that $\cos(\sin(x))$ is a contraction on $\mathbb{R}$ and hence by the Contraction Mapping Theorem it will have a unique fixed point. But what is the process for finding this fixed point? This is in the context of metric spaces, I know in numerical analysis it can be done trivially with fixed point iteration. Is there a method of finding it analytically?","['general-topology', 'metric-spaces', 'real-analysis']"
246666,Question about number theory asymptotic proof,Let $d(m)$ denote the number of divisors of $m$ and let $N$ be a large integer. Then we have $$\sum_{n \leq N}\frac{d(n)}{n} \geq \left(\sum_{n \leq \sqrt{N}}\frac{1}{n}\right)^{2} \sim \log^{2}N.$$ What prevents me from doing $$\sum_{n \leq N}\frac{d(n)}{n} \geq \left(\sum_{n \leq N^{1/k}}\frac{1}{n}\right)^{k} \sim \log^{k}N$$ for every integer $k$?,['number-theory']
246668,Maximum of strictly subharmonic function,"Let $u\in C^2(D)$, $D$ is the closed unit disk in $\mathbf{R}^2$. Assume that $\Delta u>0$. Show that $u$ cannot have a maximum point in $D\setminus\partial D$. This statement is in a calculus book, after the discussion of extremal values of multivariable functions. So my guess is that I should use the Hessian of $u$ somehow. I started to proof indirectly. Assume that $(x_0,y_0)\in D\setminus\partial D$ is a maximum point. Then $\frac{\partial u}{\partial x}(x_0,y_0),\,\frac{\partial u}{\partial y}(x_0,y_0)=0$. Now I want to investigate the positive/negative definiteness of Hessian and deduce contradiction, but I got stuck.","['multivariable-calculus', 'harmonic-functions']"
246670,Show that norm of a functional is continuous,"This question is based on Lemma 3.3, page 6 in this paper: http://arxiv.org/pdf/1106.0622v4.pdf I changed the notation quite a lot, but it should be a one-to-one correspondence. $S(x)$ is a compact manifold for each $x \in [0,T]$. Fix $s \in [0,T]$. Let $t \in [0,T]$. Suppose $f(t,s):H^{-1}(S(s)) \to H^{-1}(S(t))$ (linear functional),  with the property that $f(t,t)$ is the identity for any $t$, and suppose the following holds: $$\frac{1}{1+|s-t|}\lVert u\rVert_{H^{-1}(S(s))} \leq \lVert f(t,s)u \rVert_{H^{-1}(S(t))} \leq \frac{1}{1-|s-t|}\lVert u\rVert_{H^{-1}(S(s))}$$ It might be helpful to know the adjoint of $f(s,t)$, written $f(s,t)^*:H^1(S(s)) \to H^1(S(t))$ has the property that $\lVert f(s,t)^*v \rVert_{H^1(S(t))}$ is continuous as a function of $t$. The task is to show that $\lVert f(t,s)u \rVert_{H^{-1}(S(t))}$ is continuous as a function of $t$. Clearly we can see that it is continuous at $t=s$. But how about apart from $s$? How to see that it is continuous?","['sobolev-spaces', 'functional-analysis']"
246672,How to solve this recurrence relation $a_{n+2} = \sqrt{a_{n+1}\cdot a_{n}}$?,"I am trying to solve the recurrence:
$$
a_{n+2} = \sqrt{a_{n+1}\cdot a_{n}}
$$
but here is a problem for me. After few steps I have this:
$$
a_n^2 = a_{n-1}\cdot a_{n-2}
$$
and I don't now what to do further. I can solve a recurrence like that 
$$
a_{n+2} + a_{n+1} - a_n = 5 \cdot 2^n,
$$
but I can't find any information about this case (when I have some degree or square root in a recurrence).","['recurrence-relations', 'discrete-mathematics']"
246676,"Initial value problem $dy/dx=y^{1/3}$, $y(0)=0$ has one of the following solution","I came across the following problem which says: The initial value problem $y'=y^{1/3}$, $y(0)=0$ has: (a) a unique solution, (b) exactly two solutions, (c)exactly three solutions, (d)no solution. The solution of the problem is given by: $2x=3y^{2/3}$. But I could not come to a conclusion. Clearly, (d) can not be true. But i am not sure about the other options. It will be helpful if someone throws light on it. Thanks in advance.",['ordinary-differential-equations']
246687,Combinatorics question about english letters (with consonants and vowels),The english alphabet contains $21$ consonants and $5$ vowels. How many strings of $6$ lowercase letters of the English alphabet contain a) exactly 1 vowel b) exactly 2 vowels c) at least one vowel d) at least two vowels,"['discrete-mathematics', 'combinatorics']"
246701,contour integral with singularity on the contour,"I want to compute the following integral 
$$\oint_{|z|=1}\frac{\exp \left (\frac{1}{z} \right)}{z^2-1}\,dz$$
The integrand has essential singularity at the origin, and $2$-poles at $\pm 1$,which lie on the curve $|z|=1$ so I can't apply residue formula. How can I proceed?","['cauchy-principal-value', 'complex-analysis', 'contour-integration']"
246723,Rolling die until number is greater than 100 [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Probability of dice sum just greater than 100 A die is rolled several times and the number appearing is summed. We stop when this sum becomes greater than or equal to 100. What value of sum in the end is the most probable (out of 100, 101, 102, 103, 104, 105)? 105 can be generated in only 1 way : 99 + 6 104 can be generated in only 2 ways: 99 + 5, 98 + 6 and so on. Assuming that the dice rolling will reach either of numbers in range [94,99] is equally likely, 100 is the most likely. Am I correct?",['probability']
246728,Examples of finite groups that are generated by elements $x$ satisfying $x^n = 1$,"Let $G$ be a finite group and $n > 1$ a divisor of $|G|$. Let $P_n(G)$ be the subgroup of $G$ which is generated by all elements which satisfy $x^n = 1$. Since $n > 1$, by Cauchy's theorem we have $P_n(G) > 1$. It is also easy to see that $P_n(G)$ is a characteristic subgroup of $G$. Hence if $G$ is characteristically simple (ie. direct product of isomorphic simple groups), then $P_n(G) = G$ for all $n > 1$, $n$ divisor of $|G|$ . There are plenty of other examples in finite $p$-groups, dihedral group $D_8$ also has this property. My question: Is there a finite group $G$ that is not characteristically simple or a $p$-group, but for which $P_n(G) = G$ for every divisor $n > 1$ of $|G|$?","['finite-groups', 'group-theory']"
246735,Dual space of the sobolev spaces.,"What is the dual space of $ H¹(\Omega) = W^{1,2}(\Omega) $? What is the dual space of $ W^{m,p}(\Omega) $? I know for example that the dual space of $ L^{p}(\Omega) $ for $ 1 \le p < \infty $ is $ L^{q}(\Omega) $ where $ \dfrac{1}{p} + \dfrac{1}{q} = 1 $.","['sobolev-spaces', 'riesz-representation-theorem', 'functional-analysis']"
246745,Convex polygons partitioned into concave quadrilaterals,"I found the following problem: Is it possible to partition every convex polygon into a finite number concave quadrilaterals? The answer seems negative, because heuristically if we remove a concave quadrilateral the new polygon is still convex, and after a finite number of steps we arrive at a concave quadrilateral in end, and therefore a contradiction. The problem is that it is possible to have some weird configurations, and removing a any quadrilateral from the partition may make the resulting polygon non-convex. What is the answer to the question, and what is the proof? Moreover, is there a more general result like: It is impossible to partition a convex set into a finite number of regular,  connected non-convex sets? (Answer: NO) What happens if we remove the finiteness assumption?",['geometry']
246756,Embedding $P(\mathbb{N})$ into $P_{\infty}(\mathbb{N})$,"How one can embedding $P(\mathbb{N})$ into $P_{\infty}(\mathbb{N})$, where $P_{\infty}(\mathbb{N})=\{A\in P(\mathbb{N})\ \ : \ \  A \ \ \ \text{is infinit set} \}$? I've tried defining a following function, $f:P(\mathbb{N})\to P_{\infty}(\mathbb{N}) $, as: $$f(A)=\mathbb{N}\setminus A$$ But there is a problem when $A=\mathbb{N}$ Thank you.",['elementary-set-theory']
246766,Probability problem (withdraw balls from the urn),"Problem :
  An urn contains 3 red and 7 black balls. Player A and B withdraw balls from the urn consecutively until a red ball is selected. Find the probability that A selects the red ball. (A draws the first ball, then B, and so on. There is no replacement of the balls drawn) I have the solution:
$$\Bbb{P}(A)=\frac{3\cdot 9!+6\cdot 3 \cdot 7!+ 7\cdot6\cdot5\cdot4\cdot3\cdot5!+7\cdot6\cdot5\cdot4\cdot3\cdot2\cdot3\cdot3!}{10!}$$
But i have no idea how they came up with this. Can someone explain  this? Thank you.",['probability']
246798,Closure in the Space of Probability Measures with the Prohorov metric,"I have seen this result stated countless times: assume the metric space $(\theta,d)$ is separable; then $(\theta,d)$ is complete if and only if the space $(\mathcal{P}(\Theta),\rho)$ (the space of probability measures, taken with the Prohorov metric--which is equivalent to the weak* topology) is complete.  See, for instance, Billingsley, Convergence of Probability Measures (1968), pg 240 W. Whitt, Weak Convergence of Probability Measures on the Function Space $C[0,\infty)$, Annals of Math. Stat 41 (1970), Corollary 2 http://www.math.leidenuniv.nl/~vangaans/jancol1.pdf , Theorem 9.2 But if this result holds (say, for $\Theta = \mathbb{R}$), then $(\mathcal{P}(\Theta),\rho)$ is weak* closed, which is false (see, e.g., milanmerkle.com/documents/radovi/WEACO2a.pdf , Section 5.4; a similar discussion has been had on these boards: Is the set of all probability measures weak*-closed? ) The proof of the first result typically relies on Prohorov's Theorem: take a Cauchy sequence $\{P_{n}\}$, show that the sequence is tight, therefore it is relatively sequentially compact.  But in all the cases mentioned above, the authors use relative sequential compactness to conclude that the sequence must have a convergent subsequence in the space of probability measures (rather than the closure of that space).  This seems to be the error, but the result is stated so ubiquitously that I feel I may be missing something.... UPDATE: I have located another related question: Tightness of a sequence of probability measures and weak convergence of a subsequence In Billingsley's proof (of my result), we take a Cauchy sequence $\{P_{n}\}$ and show that the sequence is tight, which is taken to prove the convergence of a subsequence.  But this result seems incorrect, since tightness is only sufficient to prove the relative compactness of the set of measures in the sequence (by Prohorov's Theorem).","['probability-theory', 'functional-analysis']"
246802,Compute the limit,"Consider an equation
$$
   \tan (x) = \frac{a x}{x^2+b}
$$
where $a,b \neq 0$. Plotting $\tan(x)$ and function on the RHS we can see that this equation has infinitely many positive solutions $x_{n}$ and $x_{n} \sim \pi n$ as $n \to \infty$, i.e. 
$$
   \lim\limits_{n \to \infty} \frac{x_{n}}{n} = \pi.
$$
But is it possible to show the latter equality analitically?","['calculus', 'limits']"
246803,Partitioning $\mathbb{R}^2$ into disjoint path-connected dense subsets,"Does there exist a partition of the plane into $n=3$ (or more generally $n\ge 3$) disjoint path-connected dense subsets? Note that the answer is yes if ""path-connected"" is replaced by ""connected"", as shown here . The linked question also shows that the answer is yes for $n=1$ (trivial) and $n=2$ (not quite trivial, but nice and explicit.)",['general-topology']
246820,Prove trigonometric identity: $1/\cosθ - \cosθ ≡ \sinθ\tanθ$,"This is part of practice, and I am clueless. I have to prove: $\dfrac{1}{\cos θ} - \cos θ = \sin θ \tan θ$ Using the identities: $\sin^2 θ + \cos^2 θ = 1$, and/or $\tan θ = \dfrac{\sin θ}{\cos θ}$.",['trigonometry']
246821,Doesn't a function with constant modulus on the boundary of a bounded domain have constant modulus over the entire domain?,"I'm having difficulties with a question from Complex Analysis (Gamelin). The question has been asked before, but I still have some difficulties with it. It asks to show that a function continuous on unit disk and its boundary and analytic on the unit open disk is a finite Blaschke product if its modulus on the boundary of the disk is one. The solutions I have read suggested that one divide the function by the finite Blaschke product with zeros identical to zeros of f. I first of all do not understand why f should have a finite number of zeros. Secondly, would it not follow by the maximum and minimum modulus principle that f has constant modulus on the entire disk since its maximum and minimum moduli on the boundary of the disk are one? Then, how can f acquire any zeros whatsoever? Am I misusing the max/min mod principle here? As well, how does dividing the function by the finite Blaschke product with zeros identical to the zeros of the function help? The claim was that the function is now by the max mod principle constant (??). I still don't see how this follows. Thank you!",['complex-analysis']
246841,Can the real and imaginary parts of $\dfrac{\sin z}z$ be simplified?,"I have calculated the real and imaginary parts of $\dfrac{\sin z}z.$ I've obtained $$\begin{eqnarray}
\frac{\sin z}z&=&\frac{\sin(x+iy)}{(x+iy)}\\
&=& \frac{\sin(x)\cosh(y)+i\cos(x)\sinh(y)}{x+iy}\\
&=& \frac{x\sin(x)\cosh(y)+y\cos(x)\sinh(y)}{x^2+y^2}+i\frac{x\cos(x)\sinh(y)-y\sin(x)\cosh(y)}{x^2+y^2}.
\end{eqnarray}$$ Before calculating it, I hoped I could use this in a solution to a certain problem, but I would need to differentiate the real and imaginary parts of $\dfrac{\sin z}z$ with regard to $x$ and $y$. But what I'm getting is very complicated. I understand that it could be that that's just the way it is. But maybe there are some simplifications to be done either in the functions or in their derivatives? I've never really used hyperbolic functions before so I'm not sure I'm not missing something. Added. The problem I'm working on is the following. Prove that the solutions of the equation $$\tan z=z$$ are all real. I will sketch the solution I know here. It can be calculated that $$\tan(x+iy)=\frac{\sin(2x)}{\cos(2x)+\cosh(2y)}+i\frac{\sinh(2y)}{\cos(2x)+\cosh(2y)}.$$ Plugging this to the equation, we get $$\begin{eqnarray}
x&=&\frac{\sin(2x)}{\cos(2x)+\cosh(2y)}\\
y&=&\frac{\sinh(2y)}{\cos(2x)+\cosh(2y)}.
\end{eqnarray}$$ From this we can get $$\sin(2x)\cdot2y=\sinh(2y)\cdot2x.$$ By plotting the functions $\sin,$ $\mathrm{id}$ and $\sinh$ (and proving the right inequalities we can see from the plots), we can see that this is only possible when $xy=0$. But when we plug $x=0$ to the second equation, we can show that the only solution is $y=0$, which ends the proof. What strikes me in this solution is the fact that $\dfrac{\sin z}z$ is used. (Not explicitly in my statement.) This function has another connection to the problem: The non-zero solutions of the equation $\tan z=z$ are exactly the zeros of the derivative of $\dfrac{\sin z}z.$ This is easy to prove. I wondered if there shouldn't be a solution to the problem which uses this fact, given that $\dfrac{\sin z}z$ appears in the solution I know.","['trigonometry', 'hyperbolic-functions', 'roots', 'complex-analysis']"
246855,Probability Problem with $n$ keys,"A woman has $n$ keys, one of which will open a door.
a)If she tries the keys at random, discarding those that do not work, what is the probability that she will open the door on her $k^{\mathrm{th}}$ try? Attempt: On her first try, she will have the correct key with probability $\frac1n$. If this does not work, she will throw it away and on her second attempt, she will have the correct key with probability $\frac1{(n-1)}$. So on her $k^{\mathrm{th}}$ try, the probability is $\frac1{(n-(k-1))}$
This does not agree with my solutions. b)The same as above but this time she does not discard the keys if they do not work. Attempt: We want the probability on her $k^{\mathrm{th}}$ try. So we want to consider the probability that she must fail on her $k-1$ attempts. Since she keeps all her keys, the correct one is chosen with probability $\frac1n$ for each trial. So the desired probability is $(1-\frac{1}{n})^{k-1} (\frac1n)^k$.
Again, does not agree with solutions. I can't really see any mistake in my logic. Can anyone offer any advice? Many thanks",['probability']
246867,How does Dijkstra's algorithm work?,"Can someone succinctly explain how Dijkstra's algorithm works and how it may be used to find the shortest path for such a graph (from a to z)? I've looked at some procedures online, but many of them seem to differ and it's hard to discern what I'm actually trying to accomplish. Thanks for the help!","['graph-theory', 'discrete-mathematics', 'algorithms']"
246878,symmetric matrices that aren't diagonalizable by a SPECIAL orthogonal matrix,"Is there a $2\times 2$ symmetric matrix that can't be diagonalized by a special orthogonal matrix? The spectral theorem guarantees an orthogonal matrix, but both the algebra and the geometry suggest this fact degenerates, in the two-dimensional case, to the existence of a special orthogonal matrix that will do the trick. (Geometrically I can't see why we would need a reflection to bring a quadratic form into standard form; algebraically there appears to always be a solution for a rotation by $\theta$, at least if I did my algebra right.) In higher dimensions, what's the (right way to think about the) geometric obstruction to an orientation-preserving change-of-basis for the diagonalization? (I'm assuming that for $n>2$ there are indeed $n\times n$ symmetric matrices that require a reflection, even though I can't quickly write one down.) I'm thinking over the reals, if that wasn't clear.","['geometry', 'linear-algebra']"
246892,Why is the following example of a Markov process not strong Markov,"$X(t) := 0 \;\; (t \leq \tau),\;\; t - \tau\;\;(t \geq \tau)$  with $\tau$ exponentially distributed. Then X has the Markov property but not Strong Markov Property. But why ???? Can someone kindly explain in words and maths why the strong markov property does not hold?","['probability-theory', 'stochastic-processes', 'markov-process']"
246899,Classification of Differential Equations,"It's been quite a while since I last dealed with DE's. I'd appreciate if you could help me with the official, or usual, classification of the next DE's and/or if there are some definite methods to solve them. Hints will also be welcome: $$(1)\;\;\;\;\;\;\;\;y'=\frac{(y+2x-1)^2}{(4y+8x-6)(2y+4x-1)}\cdot\frac{1}{\sin\left(\frac{4y+8x-3}{y+2x-1}\right)}-2$$ $$(2)\;\;\;\;\;\;\;\;y'x+y\left(\ln^2x+\ln^2y-2\ln x\ln y\right)=0\;\;,\;x,y>0$$ I'm guessing here one could write $$\ln^2x+\ln^2y-2\ln x\ln y=\left(\ln x-\ln y\right)^2=\ln^2\frac{x}{y}$$ Thanks.",['ordinary-differential-equations']
246901,Find the equation of the tangent line to a given curve at a given point,"Find the equation of the tangent line to the curve $x^2 - y^2 +2x-6=0$ in the point $(x,3)$, where $x<0.$ So I tried to find the derivative of the given curve, $2x-2yy' +2=0$...here I replaced the given coordinates and I have that $y'=-3/2$ I replace in $y-3=-1.5(x+5)$ and thats it...is this correct?",['derivatives']
246912,Order of integration problem in probability,"In a problem in my probability course we change the order of integration, and I am having trouble seeing why we can do it this way. $$\int_0^\infty \int_{\{x : g(x) > t\}} f_X(x)dxdt = \int_{-\infty}^\infty \int_{\{t : 0 \le t < g(x)\}} f_X(x) dt dx.$$ Can anyone enlighten me to why this works. I know how it works with simple examples, but for some reason the $g(x) > t$ is messing with my head.","['calculus', 'probability']"
246927,Why does this integral (of the Schwarz kernel) define a holomorphic function in the unit disc?,"(This may look very silly to you but I don't understand the reason that was given to me, nor do I have the knowledge to find out by myself). The domain for $z$ is the open unit disc $D=\{z\in\mathbb{C} | \vert z \vert < 1\}$. Here $\sigma$ is a real-valued function of bounded variation on $[0,2\pi]$. $$f(z):=\int_0^{2\pi}\frac{e^{i\theta}+z}{e^{i\theta}-z}d\sigma (\theta).$$ In any compact $K\subset D$, the modulus of the integrand is bounded by $(1+\lambda)/(1-\lambda)$, so $|f(z)|$ is bounded by $\int_0^{2\pi}\frac{1+\lambda}{1-\lambda}|d\sigma (\theta)| = \frac{1+\lambda}{1-\lambda}V_{[0,2\pi]}(\sigma) $ ($V_{[0,2\pi]}(\sigma)$ is the total variation of $\sigma$). Why does this show that $f(z)$ is holomorphic in $D$? I was told ""by Weirstrass' theorem"" but that theorem deals with sequences of holomorphic functions. Thank you.","['complex-analysis', 'analysis']"
246929,"Graphs that ""polygonize"" a manifold","It's rather easy to conceptualize a covering of the Euclidean plane by a countable set of convex but otherwise arbitrarily sized and shaped polygons (seen as subsets of the plane) without overlaps. It can - without loss of generality? - be required that two such polygons do share exactly one complete edge or none. Is there an official name of such a covering? I guess ""polygonization of the plane"" is not utterly wrong, but misses some aspects: convexity and uniqueness of shared edges. Anyway: a polygonization of the plane induces an (infinite) graph with obvious vertices and edges. (How) can such a graph be characterized? (""A graph is induced by a polygonization of the plane iff it is planar, 2-edge-connected , and ..."") The Euclidean plane is not the only manifold that can be polygonized in the way described above: there are polygonizations of the sphere, the torus and so on and so on. (How) can the graphs be characterized, that polygonize any manifold?","['geometry', 'graph-theory']"
246932,comparison test - useful series to know,what are some useful series to know for the comparison test along with their conditions?  I can think of the following: p-series geometric series harmonic series are there want other series that are useful with the comparison test? thanks in advance,"['sequences-and-series', 'divergent-series', 'calculus']"
246941,Prove that $\operatorname{rank}(A) + \operatorname{rank}(B) \ge \operatorname{rank}(A + B)$,"Let $A,B$ be matrices $m\times n$ $(A, B \in M_{m\times n}(R))$. How can we prove that $$\operatorname{rank}(A+ B) \le \operatorname{rank}(A) + \operatorname{rank}(B)\ ?$$","['matrix-rank', 'linear-algebra', 'inequality']"
246942,Decomposition of Noetherian space into irreducible subsets,"I am trying to relate two (maybe not) different decompositions of a noetherian topological space into irreducible subsets, given in Ravi Vakil's notes on algebraic geometry. Exercise 4.6.N : Let $X$ be a topological space, then any point is contained in a an irreducible component. It follows that any space $X$ is the union of its (closed) irreducible components, but there is not statement of uniqueness. Proposition 4.16.14 : Let $X$ be a noetherian topological space, and $Z \subseteq X$ a closed (non-empty) subset. Then there is a
  unique decomposition $Z = Z_1 \cup \cdots \cup Z_n$ where the $Z_i$'s
  are irreducible closed subsets, none containing another. So in particular $X$ is a finite union of irreducible closed sets, but here it seems like they may not be its components. The exercise is just a small exercise, while the proposition seems to be more important. So my question is : Why is the decomposition in the proposition more important than the one in the exercise ? Is it because of the uniqueness statement ? But I think the decomposition of $X$ into its irreducible closed components also satisfies this uniqueness condition. Is it because it applies to any closed subset $Z$ ? But $Z$ also has the decomposition of the exercise. However, the subsets are irreducible in $Z$ and not in $X$, so this is the point ? Thank you for your help.","['general-topology', 'algebraic-geometry']"
246954,Is it true that $E[|Y|\mid{\mathcal G}]\leq |Y|$ almost surely?,"This is an exercise of conditional expectations: Let $Y$ be an integrable random variable on the space $(\Omega,{\mathcal A},{\bf P})$ and $\mathcal{G}$ be a sub $\sigma$-algebra of $\mathcal{A}$. Show that $|Y|\leq c$ implies $|E[Y\mid{\mathcal G}]|\leq c$. With Jensen's inequality, one immediately has $|E[Y\mid{\mathcal G}]|\leq E(|Y|\mid{\mathcal G})$. I am trying to show that $E[|Y|\mid{\mathcal G}]\leq |Y|$, which is not necessarily true though. If $Y$ is $\mathcal{G}$-measurable, then $E[|Y|\mid {\mathcal G}]= |Y|$. But I have no idea for the general case.","['probability-theory', 'measure-theory']"
246966,Question on measure of certain type of set,"I have a question on the following problem: Let $S\subseteq \mathbb{R}$ be a Borel set such that for any $s\in S$, if $s$ and $t$ differ in only a finite number of decimal places then $t\in S$. Then either $\lambda(S)=0$ or $\lambda(\mathbb{R}\setminus S)=0$. I believe it has something to do with covering theorems, but my explorations in that regard have been unfruitful. I am also confused about the Borel hypothesis. I get the feeling therefore that I am overlooking some useful theorem. As this is homework, I am looking for direction or advice and not a full answer. Thank you.","['measure-theory', 'real-analysis']"
246985,A domain is a field if it has a common multiple $\!\neq\! 0$ of all elements $\!\neq\! 0$,"Let $D$ be a domain which is not a field. If there exists $b \in D - \{0\}$ such that for all $a \in D - \{0\}$, $a|b$, then is it true that $b = 0$? This is certainly true if one has a UFD with infinitely many irreducibles (that are not associates) or a Jacobson domain which is not a field (or more generally a domain where the intersection of all non-zero prime ideals is the zero ideal), but I can't seem to be able to prove this for a domain in general or find a counterexample. If this statement is false for an arbitrary domain, then is there some additional weak hypothesis on the domain which makes the above statement true? I was actually trying to answer a question asked yesterday on MSE, which was the following: If $D$ is a domain which is not a field and $Q = Frac(D)$, then $Hom_D(Q,D) = \{0\}$ . Note that if $\varphi$ is any such $D$-linear map, then for all $a \in D- \{0\}$, $a\varphi(1/a) = \varphi(a/a) = \varphi(1)$. Thus, I get for all $a \in D - \{0\}$, $a|\varphi(1)$, and I want to conclude that $\varphi(1) = 0$, but cannot.","['commutative-algebra', 'abstract-algebra']"
246986,Calculating the Odds of Victory in Risk,"I am trying to write an odds calculator for risk that calculates the percentage chance of winning a combat between a number of given Attackers and given Defenders. The calculator will use basic risk rules, that is, the attacker roles dice equal to the number of attackers but no more than 3. The defender does the same but is limited to 2 dice. The resulting roles are sorted and then combat is determined by comparing the two top dice and removing them from the stack. The side with the lower die roll loses one troop. This process continues until one side wins. What I want to know is if their is an equation that can be used to solve this without creating the normal statistics tree. Creating that tree, while it works, becomes unmanageable after either side goes above 10 or more troops. My current solution is to simulate 100,000 combats and then take the number of times the Attacker wins/100,000 to get the percent chance of winning the combat. This solution also works, however, since it is based on random chance itself the results can be off by significant amounts. It also requires simulating a lot of combat. Is there some function I could use to calculate this result without having to use one of the previously mentioned solutions?","['statistics', 'probability']"
246988,"Prove $\sum_{n=1}^{\infty}f_n'(x)<\infty$ on $(0,1)$, when non-negative and increasing function $\lim_{x\to \infty}\sum_{n=1}^{\infty}f_n(x)<\infty$","When $f_n$ if non-negative and increasing on $(0,\ \infty)$ $$\lim_{x\to \infty}\sum_{n=1}^{\infty}f_n(x)<\infty$$ Prove that
$$\sum_{n=1}^{\infty}f_n'(x)<\infty$$ 
on $(0,\ 1)$ a.e $[m]$. Is there the question means $f$ is differentiable? If so I will try mean value theorem. If not, I am totally stuck at the beginning, since $f$ is not mentioned absolutely continuous or f' belong to $L^1(m)$, I have no idea how to connect $f'$ and $f$ here.","['derivatives', 'real-analysis']"
246997,Give examples of functions $f\colon X\to Y$ and $g\colon Y\to X$ such that $g\circ f=id_X$ but where $f$ is not invertible.,"Give examples of functions $f\colon X\to Y$ and $g\colon Y\to X$ such that $g\circ f=id_X$ but where $f$ is not invertible.
At first I thought I could simply make $f(x)=x^2$ and $g(x)=\sqrt{x}$ but then I realized that their composition would yield $+x$ and $-x$, not simply $x$.
I'm not sure I really understand what it's asking anymore.",['functions']
247036,"Closed form solution to $\{a_n\}_{n=1}^{\infty} = 1,2,2,3,3,3,...$","I had thought about this sequence (where each positive integer $n$ shows up $n$ times) the other day and think I have a closed form solution. First of all we know that the last time that $k$ shows up in the sequence is at $a_{\frac{k(k+1)}{2}}$.  We want to see if  $a_n$ is one of these last occurrences. So we solve $$\frac{k(k+1)}{2} = n$$ for $k$. If $k$ is an integer then we know $a_n = k$ but if $k$ is not an integer then $a_n$ must be $\left \lceil k \right \rceil$ since the last occurrence of $\left \lfloor k \right \rfloor$ occurred before $n$. Therefore the value of  $a_n$ is: $$\left \lceil \frac{\sqrt{8n+1} -1}{2}\right \rceil$$
Is this correct? Is there anything interesting about this sequence other that that the sum of it values and the sum of its reciprocals both diverge?  Thanks.",['analysis']
247043,Second order approximation of $\log \det X$,"I'm trying to follow the derivation of second order approximation of $\log \det X$ from page 658 of Boyd & Vandenberghe's Convex Optimization . How is the last step derived? I.e., where does the trace expression come from?","['hessian-matrix', 'matrices', 'matrix-calculus', 'scalar-fields']"
247054,Every proper ideal contained in a maximal ideal?,"This is a true in a commutative ring with $1$, but does it also hold in a noncommutative ring with $1$?   The proof in my book is just an application of Zorn's lemma, but the commutativity of the ring is not used anywhere.","['ideals', 'abstract-algebra']"
247063,How do I prove that this polynomial is irreducible?,"How do I prove that $x^4+1$ is an irreducible polynomial over $\mathbb Q$? I've already tried the Eisenstein criterion which gives to me any results to solve this question, I need help here. Thanks","['field-theory', 'abstract-algebra', 'polynomials']"
247068,Show that the cyclic shift operator is unitary,"Show that the cyclic shift operator is unitary and determine its diagonalization: $$A=\begin{bmatrix}
       0&1     \\[0.3em]
      &0&1 \\[0.3em]
        & & \ddots \\
&&&.&1\\
1&&&&0
     \end{bmatrix}.$$","['permutation-matrices', 'matrices', 'linear-algebra', 'orthogonal-matrices', 'circulant-matrices']"
247078,How to understand the spectral decomposition geometrically?,"Let $A$ be a $k\times k$ positive definite symmetric matrix. By spectral decomposition, we have $$A = \lambda_1e_1e_1'+ ... + \lambda_ke_ke_k'$$ and $$A^{-1} = \sum_{i=1}^k\frac{1}{\lambda_i}e_ie_i'$$ How to understand spectral decomposition and the relationship between $A$ and $A^{-1}$ geometrically?","['matrix-decomposition', 'matrices', 'linear-algebra', 'spectral-theory']"
247082,What can be said about the Galois group of $f(g(x))$?,"Supposing we know the Galois groups of $f(x)$ and $g(x)$ over $K$, what can be said about the Galois group of $f(g(x))$? I suppose we can restrict the question to normal polynomials over $\mathbb{Q}$, though the general case would be interesting also.","['galois-theory', 'group-theory', 'abstract-algebra', 'field-theory']"
247083,Specific question on meagre sets,"This question has stumped me. Assume that $S\subseteq \mathbb{R}$ is meagre and that $S$ has the property that if $x\in S$ and $y$ differs from $x$ in only a finite number of decimal places then $y\in S$. Is it true that $\lambda(S)=0$? I was thinking that differing by finitely many decimal places is an equivalence relation and noting that if $\lambda(S)>0$ it must be an uncountable union of these equivalence classes, but I could not get this to help me much.","['general-topology', 'measure-theory', 'real-analysis']"
247094,Is there a way to see if a function is invertible without proving it is onto and one-to-one?,"For any function? Right now, I try to find the values of x and y for the function to see if it is one-to-one, but it doesn't work for some of the more complex and unusual functions.",['discrete-mathematics']
247106,"Lattice Reduction Problem: Minimizing the ""Longest"" Basis Vector","Suppose we have a basis for an integer lattice formed by the vectors $\vec v_1, \vec v_2, \ldots,\vec v_n$. Then let $A$ be the augmented matrix $( \vec v_1| \space \vec v_2| \cdots |\space \vec v_n)$. Here is my question: is there an algorithm which performs elementary column operations on $A$ such that $\max(\|\vec u_1\|_p, \|\vec u_2\|_p, \ldots, \|\vec u_n\|_p)$ is a minimum, where $\vec u_i$ represent the new column vectors?  The specific cases $p=1$, $p=2$, and $p=\infty$ are of particular interest to me. Here are my thoughts for a slow-as-molasses approach: I could first apply the LLL algorithm to get my vectors within a reasonable distance of the origin.  Once that is done, a $L_p$ unit $n$-sphere could be drawn centered at the origin with radius stretched to the longest of the vectors.  We could then brute-force the answer by checking every possible basis within this $n$-sphere. EDIT: It looks like the $p=\infty$ case can be reduced to a simpler problem, which is simply minimizing the absolute value of the largest element in the matrix.  I have also found an article which looks promising in that it may have the answer for the $p=1$ case, but I'm having difficulty understanding some of the notation.","['optimization', 'integer-lattices', 'discrete-mathematics', 'matrices', 'discrete-optimization']"
247118,Does the category of affine $k$-varieties have finite products?,"We use the definitions of this question .
Let $\mathrm{Aff}(k)$ be the category of affine $k$-varieties.
Let $X, Y$ be objects of $\mathrm{Aff}(k)$.
Does the product $X\times Y$ exist in $\mathrm{Aff}(k)$?",['algebraic-geometry']
247129,Why would $(A^{\text T}A+\lambda I)^{-1}A^{\text T}$ be close to $A^{\dagger}$ when $A$ is with rank deficiency?,"In many applications that is not with high requirements, it is common to use $(A^{\text T}A+\lambda I)^{-1}A^{\text T}$ or $A^{\text T}(AA^{\text T}+\lambda I)^{-1}$ ($\lambda$ is small) to approximate the Moore-Penrose pseudoinverse $A^{\dagger}$. But from the properties of Moore-Penrose pseudoinverse, how do we know that $(A^{\text T}A+\lambda I)^{-1}A^{\text T}$ and $A^{\text T}(AA^{\text T}+\lambda I)^{-1}$ will be close to the exact solution? It seems that
$$
\lim_{\lambda \rightarrow 0}(A^{\text T}A+\lambda I)^{-1}A^{\text T} = A^{\dagger}
$$
I want to know why this happens (You can try in Matlab for verification). Besides, it is also possible for $A^{\text T}A + \lambda I$ to be singular. The whole thing is confusing me. And the question following this is, if we want to restrict the error of $(A^{\text T}A+\lambda I)^{-1}A^{\text T}$ approximating the $A^{\dagger}$ to a certain extent, can we know the upper bound for the $\lambda$ according to some criterions?","['numerical-linear-algebra', 'matrices', 'linear-algebra']"
247135,Prove the isomorphism of cyclic groups $C_{mn}\cong C_m\times C_n$ via categorical considerations,"As the title suggests, I am trying to prove $C_{mn}\cong C_m\times C_n$ when $\gcd{(m,n)}=1$, where $C_n$ denotes the cyclic group of order $n$, using categorical considerations. Specifically, I am trying to show $C_{mn}$ satisfies the characteristic property of group product, which would then imply an isomorphism since both objects would be final objects in the same category. $C_{mn}$ does come with projection homomorpisms, namely the maps $\pi^{mn}_m: C_{mn} \rightarrow C_m$ and $\pi^{mn}_n: C_{mn} \rightarrow C_n$ which are defined by mapping elements of $C_{mn}$ to the redisue classes mod subscript. From here I have gotten a bit lost though, as I cannot see where $m$ and $n$ being relatively prime comes in. I am guessing it would make the product map commute, but I cannot see it. Any ideas? Note This is not homework. Also, I understand there are other ways to prove this, namely by considering the cyclic subgroup generated by the element $(1_m,1_n) \in C_m\times C_n$ and noting that the order of this element is the least common multiple of $m$ and $n$ and then using it's relation to $\gcd{(m,n)}$. This then shows $\langle (1_m,1_n)\rangle$ has order $mn$ and is cyclic, hence must be isomorphic to $C_{mn}$. Also, $C_{mn}\cong C_m\times C_n$ has order $mn$, so $C_{mn}\cong C_m\times C_n=\langle (1_m,1_n)\rangle$, which completes the proof.","['category-theory', 'group-theory', 'abstract-algebra']"
247146,"Show that $\gcd\left(\frac{a^n-b^n}{a-b},a-b\right)=\gcd(n d^{n-1},a-b)$","How to show that $$ \gcd\bigg( {a^n-b^n \over a-b} ,a-b\bigg )=\gcd(n d^{n-1},a-b ) $$ 
  $a,b\in \mathbb Z$ where $d=\gcd(a,b)$? Note $\ $ Some of the answers below were merged from this question . The answers (and their comments) may depend on context provided in that question.","['elementary-number-theory', 'divisibility', 'gcd-and-lcm', 'number-theory']"
247147,SO(5)-invariant metrics on the 4-sphere,"Are there any examples of Riemannian metrics on $S^{4} \subset \mathbb{R}^{5}$ that are not 
SO(5)-invariant? Or are all 
metrics on the 4-sphere SO(5)-invariant? Hope my question is not too trivial :). Dmitri","['riemannian-geometry', 'lie-groups', 'differential-geometry']"
247164,Is $\aleph_0$ the minimum infinite cardinal number in $ZF$?,"$\aleph_0$ is the least infinite cardinal number in ZFC. However, without AC, not every set is well-ordered. So is it consistent that a set is infinite but not $\ge \aleph_0$? In other words, is it possible that exist an infinite set $A$ with hartog number $h(A)=\aleph_0$?","['cardinals', 'elementary-set-theory', 'infinity', 'axiom-of-choice']"
247173,Linear Algebra and Geometry by Kostrikin and Manin: Remark regarding diagrams and graphic representations.,"On page 5 of this book there is a particular section of the book that I am having trouble trying to understand as to what the authors' are trying to point across. It is concerning linear algebra. I will place in bold the parts I need additional explaining and number them as (1),(2),(3) which will be associated with the numbered questions below. So it begins like this: Remarks regarding diagrams and graphic representations. Many general concepts and theorems of linear algebra are conveniently illustrated
  by diagrams and pictures. We want to warn the reader immediately about
  the dangers (1) of such illustrations. a)Low dimensionality. We live in a three-dimensional space and our
  diagrams usually portray two- or three-dimensional images. In linear
  algebra we work with space of any finite number of dimensions and in
  functional analysis we work with infinite-dimensional spaces. Our
  ""low-dimensional"" intuition can be greatly developed, but it must be developed systematically (2). Here is a simple example how are we to
  imagine the general arrangement of two planes in four-dimensional
  space ? Imagine two planes in $\mathbb{R}^3$ intersecting along a
  straight line which splay out everywhere along this straight line
  except at the origin, vanishing into the fourth dimension (3). 1) How does the particular example above show the dangers of such an illustration? 2)The author didn't elaborate much on this point. What does it mean to develop such intuition systematically and how? 3) I'm not quite sure what the author is trying to say about this, and with no pictures in the book it is quite difficult for me to figure out what it trying to be put across by the authors. If someone could try to explain so that I can have a mental ""picture"" in my head what is actually intended by the author. Diagrams and pictures accompanying an explanation would also be greatly appreciated (though one is not obligated to provide one.) NB: I guess part of the reason why I don't fully capture what the author is trying to get across is because I can't quite get my head around the example about the two planes in four dimensional space.",['linear-algebra']
247204,Associated points of a scheme are contained in an open subset,"Recall that we define the set of associated points of a locally Noetherian scheme $X$ as $\operatorname{Ass}(\mathcal{O}_X) = \{ x \in X : \mathfrak{m}_x \in \operatorname{Ass}_{\mathcal{O}_{X,x}}(\mathcal{O}_{X,x})\}$.  I am having trouble understanding the proof of the following (Liu, 7.1.9): Let $U$ be an open subset of $X$ and $i : U \to X$ the inclusion.  The morphism $\mathcal{O}_X \to i_\ast(\mathcal{O}_U)$ is injective iff $\operatorname{Ass}(\mathcal{O}_X) \subseteq U$. Since the property is local, he assumes $X = \operatorname{Spec}(A)$ so that the problem reduces to showing $A \to \Gamma(U, \mathcal{O}_X)$ is injective iff $\operatorname{Ass}(A) \subseteq U$.  For the reverse direction, he argues as follows: Let us suppose now that there exists a $\mathfrak{p} = \operatorname{Ann}(a) \in \operatorname{Ass}(A)$ with $\mathfrak{p} \not\in U$.  Then for any point $x \in U$, we have $\operatorname{Ann}(a)\mathcal{O}_{X,x} = \mathfrak{p}\mathcal{O}_{X,x} = \mathcal{O}_{X,x}$; hence $a_x = 0$.  Consequently, $a|_U = 0$. The equality $\mathfrak{p}\mathcal{O}_{X,x} = \mathcal{O}_{X,x}$ is what I don't understand.  As far as I understand, $\mathfrak{p}\mathcal{O}_{X,x}$ denotes the image of $\mathfrak{p}$ under the homomorphism $A \to \mathcal{O}_{X,x}$, right? I also tried to prove $a_x = 0$ directly: we want to show that the image of $a$ vanishes under the homomorphism $A \to \mathcal{O}_{X,x} = A_Q$ (where $Q \subset A$ is the prime ideal corresponding to $x$); i.e. $t \cdot a = 0$ for some $t \not\in Q$.  This is equivalent to the set $P \setminus Q$ being nonempty for all $Q \in U$.  Assuming $U = D(f)$ ($f \in A$), we want $P \setminus Q$ nonempty for all prime ideals $Q$ not containing $f$ where $f \in P$.  It is clear that any such $Q$ must contain $a$ (as $af = 0 \in Q$) but I don't know what to do next.","['commutative-algebra', 'algebraic-geometry']"
247224,Derangements with repetitive numbers,"I have a very simple problem. Lets assume that I have a well shuffled deck of 52 cards. I start drawing the top card always and when the card matches its rank I lose. J=11 Q=12 K=13. If there were only 13 cards I could easily use the $\ \frac{!n}{n!}$ for derangements in order to solve this.
The problem is that there are 52 cards so when I pass 13 I start from 1 again so I don't know what is the probability to win.
Example of the game 1st card: 4 - Continue 2nd Card: A - continue 3rd Card: K - Continue 4th Card: K - Continue 5th Card: 6 - Continue 6th Card: 9 - Continue 7th Card: 10 - Continue 8th Card: A - Continue 9th Card: J - Continue 10th Card: 3 - Continue 11th Card: 2 - Continue 12th Card: 8 - Continue 13th Card: A - Continue 1st card: 5 - Continue 2nd Card 2 LOSE So actually I have to count from 1 to 13 4 times and if I draw all 52 cards then I win. What's the probability?","['card-games', 'probability', 'derangements']"
247229,Geometry Parabola $2x^2+\alpha x+3\alpha$ to find common point,"Can you help me find the answer to this question? For any real number $\alpha$, the parabola $f_{\alpha}(x) = 2x^2 + \alpha x + 3\alpha$ passes through the common point $(a, b)$. What is the value of $a + b$?","['geometry', 'conic-sections']"
247240,Proving The Extension Lemma For Vector Fields On Submanifolds,I need some hints to prove the following lemma (John Lee's $\textit{Introduction to Smooth Manifolds 2nd Ed}$ p.201) : EXTENSION LEMMA FOR VECTOR FIELDS ON SUBMANIFOLDS: Suppose $M$ is a smooth manifold and $S\subseteq M$ is an embedded submanifold. Given a smooth vector field $X$ on $S$ show that there is a smooth vector field $Y$ on a neighborhood of $S$ in $M$ such that $Y=X$ on $S$. Show that every such vector field extends to all of $M$ if and only if $S$ is properly embedded.,"['submanifold', 'smooth-manifolds', 'differential-geometry', 'vector-fields']"
247247,"Is the complex derivative ""speed""?","The first thing I was told about the real derivative is that it's ""how fast the function is growing"" at a given point. This interpretation wasn't addressed in my complex analysis classes. Can the complex derivative also be interpreted as ""speed""? And how do we interpret zeros of the complex derivative? With the real derivative, it's simple: it's where the function stops increasing or decreasing (perhaps just for one moment). If it was decreasing and after that moment it starts increasing, we have a local minimum. If it was increasing and starts decreasing, we have a maximum. Is anything like this true for the complex derivative?","['roots', 'derivatives', 'complex-analysis']"
247261,An upper bound for $\sum_{i = 1}^m \binom{i}{k}\frac{1}{2^i}$?,"Does anyone know of a reasonable upper bound for the following:
$$\sum_{i = 1}^m \frac{\binom{i}{k}}{2^i},$$
where we $k$ and $m$ are fixed positive integers, and we assume that $\binom{i}{k} = 0$ whenever $k > i$. One trivial upper bound uses the identity $\binom{i}{k} \le \binom{i}{\frac i2}$, and the fact that $\binom{i}{\frac{i}{2}} \le \frac{2^{i+1}}{\sqrt{i}}$, to give a bound of 
$$2\sum_{i = 1}^m \frac{1}{\sqrt{i}},$$
where $\sum_{i = 1}^m \frac{1}{\sqrt{i}}$ is upper bounded by $2\sqrt{m}$, resulting in a bound of $4\sqrt{m}$. Can we do better? Thanks! Yair","['binomial-coefficients', 'combinatorics']"
247281,"""For every countably complete filter $F$ there is a countably complete ultra filter $H$ s.t. $F \subset H$"" is false","I'm trying to show that the following statement is false: Let $x$ be a non-empty set. Let $F$ be a proper countably complete filter on $X$. Then there is a countably complete proper ultra filter $H$ on $X$  s.t. $F \subset H$. Countably complete means the following: $$ \forall H \subset F (H \text{ is countable } \rightarrow \bigcap H \in F)$$
$F$ is called proper if $\varnothing \notin F$. My idea was to pick an uncountable set $x$ and let $F = \{ y \subset x \mid y^c \text{ is countable } \}$ be the cocountable filter. Then pick any $y \in F$ so that $y^c$ is countable. Let's denote it $y^c = \{ y_n \mid n \in \mathbb N_{>0} \}$. Let $(P, \le)$ be the set of all proper countably complete filters $G$ containing $F$. I wanted to make a chain extending $F$. But I can't seem to make it work. Something like $C_0 = F$ and either $C_n = flt(C_{n-1}, \{y_1, \dots, y_n \})$ or $C_n = flt(C_{n-1}, y^c \setminus \{y_1, \dots, y_n \})$ where $flt(F,s) = \{ w \subset x \mid \exists z \in F ( z \cap s \subset w \}$ doesn't work. How can I construct a chain such that $\bigcup \mathcal C$ is not closed with respect to countable intersection? Thanks for your help. Edit Background information: I've done parts (a) and (b) of the following exercise and this is part (c):","['filters', 'elementary-set-theory']"
247304,Math question help here? Tangents,"Find $a$, $b$ and $c$ so the line $y=x$ can be a tangent of the parabola $y=ax^2+ bx+c$ at the point $x=1$. The parabola passes from the point $M(-1;0)$. So I formed the system $$2a+b=1$$ $$a-b+c=0$$
How do I solve this system? Details : From $y=x$ we see that $k=1$ (we also have that $x=1$) so $2\cdot a\cdot 1+b\cdot 1=1$",['derivatives']
247310,Zerodivisors in Finite Commutative Local Rings,"Let $p$ be a prime and $r$ a positive integer. Let  $\mathbb Z_{p^r}$ the ring of integers modulo $p^r$. Every zero-divisor $z$  in  $\mathbb Z_{p^k}$ can be written in the form $z=ap^k$, where $a$ is a unity. 1) Let now $(R, \mathfrak m)$ be a finite commutative local ring. If the maximal ideal $\mathfrak m$ is principal and generated by $s$, then every zero divisor $z$ of $R$ can also be written in the form $z=as^k$ where $a$ is a unity or we need to impose some conditions on the ring $R$ in order to conclude that $z=as^k$ where $a$ is a unity? 2) Assume now that $(R, \mathfrak m)$ is a finite commutative local ring. Suppose that the maximal ideal $\mathfrak m$ is generated by $s_1, s_2, \dots, s_l$. What conditions we impose to the ring in order to have that a zero-divisor $z$ can be written in the form $z=a_1s_1^{k_1}+\cdots+a_ls_l^{k_l}$, where $a_i$ are a units, for $i=1, \dots , l$?","['commutative-algebra', 'ring-theory', 'finite-rings', 'abstract-algebra']"
247312,What are the solutions to $z^4+1=0$? [duplicate],"This question already has answers here : How to find the roots of $x^4 +1$ (8 answers) Closed 7 years ago . I can't seem to find the  solutions to  $z^4+1=0 $.
$z$ is in the complex plane. The solutions show four roots; however, how do I find them once $z^4 = -1$?","['calculus', 'complex-analysis']"
247333,Reference about Fredholm determinants,"I am searching for a reference book on Fredholm determinants. I am mainly interested in applications to probability theory, where cumulative distribution functions of limit laws are expressed in terms of Fredholm determinants. I would like to answer questions like : How to express a Fredholm determinant on  $L^2(\mathcal{C})$, where $\mathcal{C}$ is a contour in $\mathbb{C}$ and the kernel takes a parameter $x$, as a deteminant on $L^2(x, +\infty)$ ; and vice versa. Which types of kernels give which distributions. For example, in which cases we get the cumulative distribution function of the gaussian distribution ? These questions are quite vague, but I mostly need to be more familiar with the theory and the classical tricks in $\mathbb{C}$. I found the book ""Trace ideals ans their applications"", of Simon Barry, but I wonder if an other reference exists, ideally with applications to probability theory.","['probability-theory', 'probability-distributions', 'reference-request', 'operator-theory']"
247340,Construction of a sphere bundle,"Let $\pi:E\to M$ be a rank $k$ vector bundle over a compact manifold $M$. The usual method to associate a sphere bundle to $E$ is by considering only vectors of length 1 in each fiber of $E$ (after choosing a metric on the bundle). This yields a bundle $S(E)\to M$ with fiber $S^{k-1}$. My question is: Can we construct a $k$-sphere bundle $C(E)\to M$ from $E$ by looking at the one-point compactification of each fiber of $E$? If this is indeed possible some details to the construction and references would be appreciated. I suppose that the zero section of $E\to M$ would induce a section of $C(E)\to M$. This construction is probably related to the construction of the Thom-space, where the one-point compactification of the total space $E$ is considered.","['general-topology', 'algebraic-topology']"
247355,How do you verify that a function is the inverse of another function?,"I think the easiest way is to calculate g(f(x)) or f(g(x)), but I don't know if it works in every case.","['discrete-mathematics', 'functions']"
247360,Limit $\lim_{n \rightarrow \infty}\frac{1 \cdot 3 \cdot 5 \dots \cdot (2n-1)}{2 \cdot 4 \cdot 6 \cdot \dots \cdot (2n)} $ [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question $\displaystyle  \lim_{n \rightarrow \infty}\frac{1 \cdot 3 \cdot 5 \dots \cdot (2n-1)}{2 \cdot 4 \cdot 6 \cdot \dots \cdot (2n)} $,"['calculus', 'limits']"
247363,How much detail should be shown when writing out a problem?,"When a somebody asks you to solve a problem and ""show your work,"" how much detail should be shown? For a simple example, if I were to solve $5x+7=17$, should I do:
$$5x+7=17$$
$$5x+7-7=17-7$$
$$5x=10$$
$$\frac{5x}{5}=\frac{10}{5}$$
$$x=2$$
or
$$5x+7=17$$
$$5x=10$$
$$x=2$$ In my math class, I have actually seen it both ways.",['algebra-precalculus']
247368,Is inverse use of mean value theorem right?,"If we have $f$ is differentiable on $(a,b)$, and continuous on $[a,b]$, then for any $x\in (a,b)$, exists $y, z \in [a,b]$, such that $f '(x)=\dfrac{f(z)-f(y)}{z-y}$ Is this right?","['derivatives', 'analysis']"
247381,What is a saturation of a set?,"So, I encountered in my topology book the saturation of a set and In my first language the translated word is rarely used and those papers I found who use it don't explain it since it seems to be something very basic. Unfortunately the part where the saturation is mentioned doesn't really give many information about what it could mean. My Question:
When do we call a set saturated? (I guess I understand it to a certain extend)
What is the saturation of a set (which is not saturated)? I hope someone can explain it to me. The corresponding wikipedia entry http://en.wikipedia.org/wiki/Saturated_set only explains when you call a subset of a topoligical space saturated but doesn't explain how to achieve the saturation of a set which isn't saturated.","['general-topology', 'elementary-set-theory']"
