question_id,title,body,tags
2884467,Questions concerning the coarsest topology on $X \times X$ for which the metric $d : X \times X \to \mathbb{R}$ is continuous,"If $(X,d)$ is a metric space, then we know the topology generated by the set $$\{ B_d (x,\delta) : \text{$x \in X$ and $\delta > 0$} \}$$ is called the metric topology . Then how do you call the coarsest topology on $X \times X$ such that the function $d:X \times  X \to \mathbb R$ is a continuous function? Is there any relationship between those two topologies?","['general-topology', 'metric-spaces']"
2884481,$\lim_{x \rightarrow \infty}\frac{5^{x+1}+7^{x+1}}{5^x +7^x}$,"$$\lim_{x \rightarrow \infty}\frac{5^{x+1}+7^{x+1}}{5^x +7^x}$$ I tried using L'Hospital rule,  which yielded : $$\lim_{x \rightarrow \infty}\frac{5^{x+1} \ln 5+7^{x+1} \ln 7}{5^x \ln 5 }$$ But I'm at the dead end...  If I divide numerator and denominator by $5^x$ , I get a term $\frac{7^x}{5^x}$ ... which is unsolvable for the limit $x \rightarrow \infty $ However , the answer provided by book is $-7$ . I doubt there is mistake in the question.","['limits', 'calculus']"
2884490,Polynomial cannot have all roots real?,"Let $P \in \mathbb R[x]$ be a degree- $n$ polynomial with real coefficients such that $P(a) \neq 0$ , where $a$ is real. If $P'(a) = P ''(a) = 0$ then prove that $P$ cannot have all roots real. Can someone suggest a possible solution using Rolle's Theorem ?
All I could gather was that $P'(x) = 0$ has a repeated root by Rolle's Theorem. But I am stuck after this.","['calculus', 'roots', 'polynomials', 'real-analysis']"
2884549,Exercise 1.21 of Villani Topics in Optimal Transportation,"I'm stuck on this exercise, can you please help me? 1.2.2. Transshipment. The Kantorovich-Rubinstein theorem implies that
  the total cost only depends on the difference $\mu-\nu$ . Thus, when the cost
  function is a metric, the Kantorovich optimal transportation problem is
  equivalent to the Kantorovich-Rubinstein transshipment problem : $$\inf \{I[\pi] ; \quad \pi[A \times X]-\pi[X \times A]=(\mu-\nu)[A]\}$$ The condition appearing above should be compared to the condition for $\pi \in \Pi(\mu, \nu),$ which is $\pi[A \times X]=\mu[A], \pi[X \times A]=\nu[A] .$ For a general cost function, the transshipment problem is a strongly relaxed version of
  the transportation problem. For instance, in the case of a quadratic cost
  in $\mathbb{R}^{n},$ the optimal transshipment cost between two given measures is in
  general 0. We shall not study the transhipment problem in this course, and
  refer to $[211]$ for motivations and detailed study. Exercise 1.20. Give an interpretation of the Kantorovich-Rubinstein transshipment problem in (say) economics terms; contrast this interpretation with
  that of the Monge-Kantorovich problem. Exercise 1.21 (Transshipment sometimes costs (almost) nothing). Let $c(x, y)=|x-y|^{2}$ in $\mathbb{R}^{n},$ and let $\mu, \nu$ be two probability measures
  on $\mathbb{R}^{n},$ such that $\mathcal T_{c}(\mu, \nu)<+\infty .$ Let $\pi \in \Pi(\mu, \nu)$ be any transference plan such that $I[\pi]<+\infty$ . Of course this transference plan can also be
  considered as a transhipment plan, with an associated transshiping cost.
  In order to lower this transshipment cost, you wish to improve this plan,
  and you come up with the following strategy. Whenever $x$ and $y$ are some
  initial and final points, respectively, instead of shipping $x$ to $y,$ you ship $x$ to $(x+y) / 2$ and simultaneously $(x+y) / 2$ to $y$ . Show that this strategy
  can be implemented with an admissible transshipment plan, and express it
  in terms of image measures of $\pi .$ Make a schematic picture of how $\pi$ is modified by this transformation. Show that the cost has been lowered by a
  factor $2 .$ Deduce that the optimal transshipment cost is $0,$ which of course
  is not attained unless $\mu=\nu .$ Show that the conclusion is still valid for any power $|x-y|^{p}, p>1,$ or more generally as soon as $c(x, y)=\phi(|x-y|)$ where $\phi$ is nondecreasing on $\mathbb{R}_{+}, \phi(0)=0, \phi^{\prime}(0)=0$ . (Original screenshot of text - Text Part 1 Text Part 2 ) Following the notation of the book, $\Pi(\mu,\nu)$ is the set of probability measures $\pi$ on $\mathbb{R}^n\times \mathbb{R}^n $ such that $$\pi(A\times \mathbb{R}^n )= \mu(A), \qquad \pi( \mathbb{R}^n \times A)= \nu(A)$$ and $$I[\pi]:=\int_{\mathbb{R}^n\times \mathbb{R}^n} c(x,y)\,d\pi(x,y)$$ and $$\mathcal{T}_{c}(\mu,\nu):=\inf_{\pi \in \Pi(\mu,\nu)}I[\pi]\,. $$ Following the hint in the exercise, my attempt was to consider the measure $$\pi':= \frac{c(x,\frac{x+y}{2})}{c(x,y)}\cdot T_{1}\sharp \pi+ \frac{c(\frac{x+y}{2},y)}{c(x,y)}\cdot T_{2}\sharp \pi$$ where $$T_{1}: (x,y)\mapsto (x, \frac{x+y}{2}) $$ $$T_{2}: (x,y)\mapsto (\frac{x+y}{2}, y ) $$ but I haven't been able to show that $I[\pi']\leq\frac{1}{2}I[\pi]$ .","['optimization', 'measure-theory', 'optimal-transport', 'calculus-of-variations']"
2884550,Constant sum of characters,"Let $q$ be a prime power and $\omega=\exp(2\pi i/q)$. For a fixed $y\in\mathbb{Z}_q^n$, the map $$\mathbb{Z}_q^n\ni x\mapsto \omega^{x\cdot y}=\omega^{x_1y_1+\dots+x_ny_n}$$ is a character of $\mathbb{Z}_q^n$. The Hamming weight $\operatorname{wt}_H$ of $x\in\mathbb{Z}_q^n$ is the number of nonzero entries in $x$. Let 
$X_i=\{x\in \mathbb{Z}_q^n\mid \operatorname{wt}_H(x)=i\}.$ I want to prove that the sum
$\sum_{x\in X_i}\omega^{x\cdot y}$ is constant for all $y\in X_k$. This is true for $q=2$ since the sets $X_i$ are invariant under the group operation of $S_n$ and for all $x,y\in X_k$ there exists $g\in S_n$ such that $gx=y$. Thus, we have $$\sum_{x\in X_i}\omega^{x\cdot gy}=\sum_{x\in X_i}\omega^{g^{-1}x\cdot y}=\sum_{x\in X_i}\omega^{x\cdot y}.$$ But I don't see that the sum is constant if $q\geq 3$. EDIT: I think that for $q\geq 3$ we could use a similar argument. If we take the group $S_{q-1}^n\wr S_n$, which operates on $x\in\mathbb{Z}_q^n$ by first permuting the positions of $x$ and then independently permuting the alphabet $\{1,2,\dots,q-1\}$ at each position, the sets $X_i$ should be invariant under this group action. Therefore, the sum should be constant for all $y\in X_k$. But I'm not completely sure that this is the right argument.","['finite-fields', 'abstract-algebra', 'combinatorics', 'algebraic-combinatorics', 'coding-theory']"
2884574,Simplifying a function of $\ln(x)$,I was asked to convert the function $$\frac{1}{x \ln x \sqrt{(\ln x)^2-1}}$$ into a function in the expression $$\frac{1}{x \sqrt{f(x)}}$$ for the domain $x > e$ but I can't seem to find how I can convert it into the answer: $$\frac{1}{x \ln x \sqrt{(\ln x)^4 - (\ln x)^2}}$$ My instinct was to use the difference of two squares: $$\frac{1}{x \ln x \sqrt{(\ln x+1)(\ln x-1)}}$$ but I'm still stuck because that method doesn't work. Can someone help?,['functions']
2884580,Two random variables are independent if all continuous and bounded transformations are uncorrelated.,"Here's a statement I've come across multiple times but have never seen a proof of: Two random variables $X$ and $Y$ are independent, if for all continuous and bounded funtions $f, g: \mathbb R\to\mathbb R$ it holds that 
  $$E[f(X)g(Y)]=E[f(X)]E[g(Y)].\tag{1}$$ I found this answer but I'm not sure that I'm filling in the details correctly: Suppose $X$ and $Y$ satisfy the condition in $(1).$ We want to show that $X$ and $Y$ are independent. Since the closed intervals generate the Borel sigma algebra, it suffices to show that 
$$P(X\in I_1, Y\in I_2)=P(X\in I_1)P(Y\in I_2)$$
for all closed intervals $I_1, I_2\subset\mathbb R.$ Given two such intervals let $f_n, g_n\ge0$ be sequences of continuous and bounded functions with
$$f_n(\cdot)\uparrow 1(\cdot\in I_1), \quad g_n(\cdot)\uparrow 1(\cdot\in I_2). \tag{2}$$ Then
\begin{align*}
P(X\in I_1, Y\in I_2) &= E[1(X\in I_1, Y\in I_2)]\\
&= E[1(X\in I_1)1(Y\in I_2)]\\
&= E[\lim_{n\to\infty}f_n(X)\lim_{m\to\infty}g_m(Y)]\\
&= \lim_{n\to\infty}E[f_n(X)\lim_{m\to\infty}g_m(Y)]\quad \text{(by monotone convergence)}\\
&= \lim_{n\to\infty}\lim_{m\to\infty}E[f_n(X)g_m(Y)]\quad \text{(by m.c.)}\\
&= \lim_{n\to\infty}\lim_{m\to\infty}E[f_n(X)]E[g_m(Y)]\quad \text{(by assumption)}\\
&= E[1(X\in I_1)]E[1(Y\in I_2)]\quad \text{(by m.c.)}\\
&=P(X\in I_1)P(Y\in I_2),\\
\end{align*}
hence the claim. Question: Is my above proof correct?","['independence', 'measure-theory', 'proof-verification', 'probability-theory']"
2884639,Minimal sufficient statistic for $\theta$ where $f(x;\theta)=\frac{\beta^3}{2}e^{-\beta(x-\theta)}(x-\theta)^2\mathbf1_{x\ge\theta}$,"I have this density function for which I am not able to find a minimal sufficient statistic, as required. It does not belong to the exponential families distribution as the support depend also on the parameter, and with the Lehmann Scheffé approach I am not able to separate the random variable $X$ from the parameter $\theta$. $$f(x;\theta)=\frac{\beta^3}{2}e^{-\beta(x-\theta)}(x-\theta)^2 \mathbf1_{x\ge\theta}, \quad \beta\text{ known}$$","['statistics', 'sufficient-statistics']"
2884659,"Do there exist finite non-cyclic groups $H$ and $K$, satisfying the specific condition?","Let’s define $\sigma(G)$ as the sum of orders of all normal subgroups of a finite group $G$. Do there exist two finite groups $H$ and $K$ such, that $\sigma(H) = |H| + |K| = \sigma(K)$ and $H$ is non-cyclic? Why $H$ is required to be non-cyclic? A pair of cyclic groups $H$ and $K$ satisfies that condition iff $|H|$ and $|K|$ form an amicable pair. And it would be interesting to know, what  happens if at least one of those groups is non-cyclic.","['normal-subgroups', 'group-theory', 'abstract-algebra', 'finite-groups']"
2884719,Sequence of polynomials converging to $\frac{1}{z}$ [duplicate],"This question already has answers here : Sequence of polynomials which converge uniformaly to 1/z (2 answers) Closed 5 years ago . Is there a sequence of polynomials converging uniformly to $\frac{1}{z}$ in $K:=\{z\in\mathbb{C}\mid 1<|z|<2\}$? My first attempt was to use the theorem of Runge which would apply if $K$ would be compact and $\mathbb{C}\setminus K$ connected. As $K$ is not closed, it is not compact. But if I consider the closure $\bar{K}$, then $\mathbb{C}\setminus\bar{K}$ is not connected? So the Theorem can not be applied here? Any other hints?","['complex-analysis', 'polynomials', 'uniform-convergence']"
2884764,Strategy for board game,"Alice and Bob are playing the following game:
  They have a 4x4 empty grid and take turns coloring one square each, starting with Alice, both using the same color.
  Whoever completes any 2x2 area on the grid (after having made his move) is the loser. Is there any winning strategy for any of the two players? I have played the game several times and can't see a clear strategy for any of the two. It seems to me that Bob will loose. Any ideas?",['combinatorics']
2884781,"Looking for an example of stochastic processes with ""very"" different trajectories, but still modifications of each other","Could anyone offere an example of two stochastic processes that are modifications of each other, i.e. $P(A_t)=1\qquad \forall t\in [0,T]$,$\qquad$ with $A_t:=\{\omega\in\Omega:X_t=Y_t\}$, and such that $P(\omega\in\Omega: \mu(I_{\omega})>0)>0$, with $I_{\omega}:=\{t\in [0,T] : \omega \in A^c_t  \}$, and 
 where $\mu$ is the Lebesgue measure on $[0,T]$? Let me give you a bit of context. I am trying to understand how different could be, in principle, the trajectories of two versions of the same process. So far, all I could find is the typical textbook example of a modification that is not indistinguishable, which is simple but not satisfactory as the trajectories only differ at one time. My intuition (which could be wrong of course) is that a modification like the one above should exist, but I struggle to find a formal argument to prove it. Thanks in advance!","['stochastic-processes', 'probability-theory']"
2884782,Term for functions that map functions to other functions,"For example, let's define the ""swap"" function $SW(f(x,y))$ as the function that maps $f(x,y) \rightarrow f(y,x)$.  I can imagine there are many such functions that have been described.  Is there any useful term for such a thing? EDIT : I'd like to illuminate a particular problem I'm interested in. I begin with a set of functions that operate on two real numbers.  For the sake of simplicity of this example, I'll use only three.  For te variables $x,y,z\in \mathbb{R}$: $$ADD(x,y) = x + y$$
$$MUL(x,y) = x*y$$
$$z = \sin(x)$$ $\sin(x)$ is defined in the traditional way.  I'm including it to make my point a bit more clear. Let's now define an equation that uses only these functions.  I'll use a specific example of: $$x*(y + z) + sin(x) = f(x,y,z)$$ I'm now interested in making the following idea more precise and general: Define a function EX(f) whose purpose is to distribute multiplication over addition.  Then, when applied to $f$ above, $$EX(f) = g(x,y,z) = x*y + x*z + sin(x)$$ In this case, $f$ and $g$ evaluate to the same value so we might claim that $f=g$ in the numeric sense.  However, I would not say they are equal from the perspective of actually computing those values, since a different set of steps must be followed.  It is the latter case I'm interested in studying further, in which numeric equality is different from evaluation equality. I'm interested in defining functions like EX, and determining things like stationary functions.  For example, $EX(g) = g$, so $g$ is ""stationary"" under EX. Forgive any imprecision.  I hope it was enough to explain the type of things I'm looking for.","['functions', 'terminology']"
2884826,Mapping Tori and Monodromy,"I have a question regarding the right setup for mapping tori. Let me give the definitions that I use first. Let $I$ denote the interval $[0,2\pi]$ and let $I^*$ denote the quotient of $I$ by the relation $0 \sim 2\pi$. Further, let $F$ be a smooth manifold, $f \colon F \rightarrow F$ a diffeomorphism, and define an equivalence relation $\sim$ on $I \times F$ by $(0,x) \sim (2\pi,f(x))$. The Mapping Torus of $f$ is the manifold $E_f = (I \times F)/\sim$. It is not difficult to see that this is a locally trivial fibration over $I^*$.
A map trivializing over $I^* \setminus \{\pi\}$ is, for instance, given by
$$\psi([t,x]) = \begin{equation} \begin{cases} ([t],x), &\text{if } 0 \leq t < \pi \\ ([t],f^{-1}(x)), &\text{if } \pi < t \leq 2\pi. \end{cases} \end{equation}$$
A lot of references now claim that this fibration has monodromy $[f]$. First of all, to speak of monodromy we need to fix a loop. A natural choice would be $\gamma \colon S^1 \rightarrow I^*, ~\gamma(t) = [t]$. Let $q$ denote the obvious map $[0,2\pi] \rightarrow S^1$. Now the pullback bundle $E = (\gamma \circ q)^*E_f$ has a global trivialization given by
$$h \colon F \times [0,2\pi] \rightarrow E, ~h(x,t) = (t,[t,x]).$$
We have that $h(x,0) = (0,[0,x])$ and, hence, viewed as a map $F \rightarrow E_0 \simeq F$, $h(\cdot,0)$ is exactly the identity $id_F$. Therefore, the monodromy associated to $\gamma$ is $h(\cdot,2\pi)$. However, this map $$h(x,2\pi) = (2\pi,[2\pi,x]) = (2\pi,[0,f^{-1}])$$ is actually $f^{-1}$, not $f$.
Doing a similar calculation, we find that the monodromy associated to $\delta(t) = [2\pi-t]$ is actually $f$. In conclusion, we would have assumed that the most natural setup (i.e. using $\gamma$) would lead to monodromy $f$. If my calculations are correct, then this does not hold, though. So, the question is: should we define the mapping torus via the relation $(0,x) \sim (2\pi,f^{-1}(x))$ instead, or do the textbooks simply not communicate that the ""natural"" monodromy of $E_f$ actually is $f^{-1}$? (Of course, the implicit question ""Are my calculations corret?"" also stands...)","['fibration', 'fiber-bundles', 'algebraic-geometry', 'algebraic-topology']"
2884900,"Problem involving Fundamental Theorem of Calculus: simplifying $\frac{\mathrm d}{\mathrm dx}\int_x^{x^2}\frac{t}{\log t}\,\mathrm dt$","I'm working on the following question: Simplify the following: $$\frac{\mathrm d}{\mathrm dx}\int_x^{x^2}\frac{t}{\log t}\,\mathrm dt$$ The solution key says this simplifies to: $$2x\frac{x^2}{\log(x^2)}-\frac{x}{\log(x)}$$ I think this wrong though. For two reasons: We can't just use fundamental theorem of calculus (FTC) because the integrand needs to be continuous on the interval of interest. The quotient of continuous functions is continuous, provided the denominator is non-zero. There's a problem though at $t=1$ . FTC is stated with one end fixed -- can we just assume both ends are functions? Given these caveats, I'm not sure how to proceed -- thoughts?","['calculus', 'real-analysis']"
2884923,Find all matrices that commute with $A$,"Given $$A = \begin{bmatrix}
3 & 1 &0 \\ 
0 &3  & 1\\ 
0 &0  & 3
\end{bmatrix}$$ find matrices $B$ such that $AB=BA$. Trivially $B=A^{-1}$ and $B=kI$ are the solutions Also we have Characteristic Polynomial as $$A^3-9A^2+27A-27I=0$$ $\implies$ $$(A-3I)^3=0$$ Is it possible to find other $B's$ using above Nilpotency of $A-3I$?","['determinant', 'matrices', 'linear-algebra', 'polynomials', 'matrix-equations']"
2884932,Extending laws for Riemann integral to Riemann-Stieltjes integral,"I was reading Terence Tao's notes on Analysis. He says Theorem 13(g) cannot be extended from Riemann integral to Riemann-Stieltjes integral: Most (but not all) of the remaining theory from Week 9 notes then can
  be carried over without difficulty, replacing Riemann integrals with
  Riemann-Stieltjes integrals and lengths with $\alpha$-length. (There
  are a couple results which break down; Theorem 13(g) , Proposition
  16, and Proposition 17 are not necessarily true when $\alpha$ is
  discontinuous at key places (e.g. if $f$ and $\alpha$ are both
  discontinuous at the same point, then $\int_{I}fd\alpha$ is unlikely
  to be defined). Source: page 4 of week 10 notes But I do not see why Theorem 13(g) breaks down if we extend it to Riemann-Stieltjes integral. Can anyone explain? Below is the theorem: Theorem 13 (Laws of integration). Let $I$ be a generalized interval,
  and let $f: I \rightarrow R$ and $g: I \rightarrow R$ be Riemann
  integrable functions on I. ... (g) Let $J$ be a generalized interval containing $I$ (i.e. $I \subseteq J$), and let $F: J \rightarrow R$ be the function $$ F(x) := \left\{
                 \begin{array}{ll}
                   f(x) & \text{if } x \in I \\
                   0    & \text{if } x \notin I
                 \end{array}
               \right. $$ Then $F$ is Riemann integrable on $J$, and $\int_{J}F = \int_{I}f$. Source: page 14 of week 9 notes","['stieltjes-integral', 'riemann-integration', 'analysis']"
2884972,Integral of an increasing function over subset of unit interval,"Let $E\subset [0,1]$ with $\mu(E)=t$ and $f$ an increasing function. Prove that $\int_0^t f\leq \int_E f$. The claim seems to be pretty clear to me and I can imagine why this has to be true but I have a hard time to prove it. Any hints on that?","['measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
2884985,Not so simple geometry (area calculation) problem,"I am new to this community, so feel free to point me in a different area if this is not appropriate here.  It is a specific question, but I am looking for a general answer - i.e., formulae that I can use when the baseline distance, angles, and areas change. I have a pasture that I want to split into two fields as shown in the sketch which I hope is linked. The width at the bottom is 764.81 feet, and the sides angle inwards slightly as shown.  The 1 acre field on the left is 8' deeper than the 3 acre field beside it, and also excludes the 8' triangle.  (1 acre is 43,560 square feet). The top line of the field is parallel to the baseline, and the line between the 1 acre and 3 acre fields is perpendicular to this baseline. What is the depth of the field? I have figured this out for the simple case where the angles are both 90 degrees, but even that involved solving a quadratic equation.  I didn't expect it to be this hard!","['trigonometry', 'geometry']"
2885002,Function For Sine Wave Between Two Exponential Cuves,What function could I use to approximate a curve with this plot? The function ideally will involve sine and have its envelope defined by different exponentials of the form $y = ae^{bx}$ and $y = ce^{dx}$.,['functions']
2885031,What is the crime of lèse-Bourbaki?,"In the foreword to his textbook Algebra , Serge Lang writes (on page vi) I have frequently committed the crime of lèse-Bourbaki by repeating short arguments or definitions to make certain sections or chapters logically independent of each other. What does ""the crime of lèse-Bourbaki"" mean? I do not understand French, so naturally I googled the phrase and what turned up was the Wikipedia page for lèse-majesté . Lèse-majesté is the crime of violating majesty, an offence against the dignity of the reigning sovereign or against a state. I am aware that Nicolas Bourbaki is a pseudonym used by a group of influential French mathematicians who wrote a series of textbooks in a terse and formal manner. So, is Lang honoring Bourbaki by equating them with (mathematical) royalty?","['mathematical-french', 'abstract-algebra', 'math-history']"
2885032,Function for a hexagonal 2-dimensional grid,"I can make a ""square"" $2$D sine wave pattern with the function $f(x,y) = \cos(x) + \cos(y)$: What is the function to make a hexagonal pattern of the same kind?",['trigonometry']
2885059,Probability of at least two being grey,"Say we have $11$ grey and $15$ white mice, so $26$ in total in a container we can't see. We want to take $5$ of them home. What is the probability of at least two of them being grey ? 2 grey: The probability of the first being grey is $\frac{11}{26}$ the second grey is $\frac{10}{25}$, the last three white $\frac{15\cdot 14 \cdot 13}{24\cdot 23\cdot 22}$. 3 grey: $\frac{11\cdot 10 \cdot 9 \cdot 15\cdot 14\cdot 13}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ 4 grey: $\frac{11\cdot 10 \cdot 9 \cdot 8 \cdot 15\cdot 14}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ 5 grey:  $\frac{11\cdot 10 \cdot 9 \cdot 8 \cdot 7\cdot 15}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ And the probability of at least $2$ grey is the sum of these?","['combinatorics', 'probability']"
2885070,Properties of $\{x\in X\mid f(x)=||f||\}$,"Let $X$ be a normed space, $f\in X^*\setminus\{0\}$ (the continuous dual), $E:=\{x\in X\mid f(x)=\|f\|\}$. Prove that $E$ is a nonempty closed set and that $\inf \{\|x\|\mid x\in E\}=1$. I have no idea how to prove that $E$ is non empty and that $\inf \{\|x\|\mid x\in E\}=1$.
$E$ is closed because it is the inverse image of a point ($\|f\|$) and $f$ is continuos, so inverse images of closed sets are closed.","['normed-spaces', 'functional-analysis', 'dual-spaces']"
2885071,Convergence both in $L^p$ and $L^q$ [duplicate],"This question already has an answer here : Convergence of a sequence in two different $L_p$ spaces (1 answer) Closed 5 years ago . I am trying to understand convergence in Lp spaces a little bit better. If we have $p, q \in [1, \infty]$ and a sequence of functions $(f_n)_{n\in\mathbb{N}} \subset L^p(\mathbb{R}^d) \;\cap\; L^q(\mathbb{R}^d)$ with $\Vert f_n - f \Vert_p \rightarrow 0$ for some $f \in L^p$ and $\Vert f_n - g \Vert_q \rightarrow 0$ for some $g \in L^q$. Is it then true that $f = g$ almost everywhere? I can't think of a good counter example or a proof.","['measure-theory', 'lp-spaces', 'convergence-divergence']"
2885157,Laplace equation in unit square,"I would like to solve the $\triangle u(x,y) = 0$ in the unit square, with periodic BC when $x=0,1$ and Neumann condition when $y=0,1$ 
$$\partial_y u(x,0) = \begin{cases}
A \quad &\text{for } 0\leq x\leq L\\
B \quad &\text{for } L<x\leq 1\\
\end{cases}\quad \partial_y u(x,1) = \begin{cases}
B \quad &\text{for } 0\leq x\leq 1-L\\
 A \quad &\text{for } 1-L<x\leq 1\\
\end{cases} $$
We also fix $u(0,0) = 0$ to make the solution unique. The hint said instead of considering Green's functions or separation of variables, think about simple solutions of $\triangle u = 0$, draw a picture consider the solution in different parts of the domain and derive jump conditions to connect the solutions. My attempt: Here let us call 
$$g(x) = \begin{cases}
A \quad &\text{for } 0\leq x\leq L\\
B \quad &\text{for } L<x\leq 1\\
\end{cases}$$ 
and note that the Nuemann condition at $z=0$ is $g(x)$, and at $z=1$ is $g(1-x)$. If provided $g(x) = \sum_n a_n \cos(n\pi x)$ (point-wise or uniform), we can define 
$$u(x,y) = \sum_n a_n \frac{\sin(n\pi x - n\pi y)}{-n\pi}.$$ (I realized this $u$ is not harmonic) $u$ is periodic when $x=0,1$, and $$\partial_y u(x,0) = \sum _n a_n \cos(n\pi x) = g(x) $$
and 
$$\partial_y u(x,1) = \sum _n a_n \cos(n\pi (x - 1))=\sum _n a_n \cos(n\pi (1-x)) = g(1-x).$$ But I am not sure if we can find a cosine series which pointwise converges to $g(x)$, how could we fix this? I think I have $L^2$ convergence 
$$\sum_n a_n \cos(n\pi x) \rightarrow g \text{ in } L^2$$
which means I have pointwise a.e. convergence because of the summation.","['boundary-value-problem', 'partial-differential-equations', 'harmonic-functions', 'real-analysis']"
2885166,"Differential entropy vs Kolmogorov-Sinai ""partition trick""","Shannon entropy is well-defined for probability distributions $p(x)$ on finite (or countable) sets $X$,
\begin{equation}
H_S=-\sum_{x\in X}p(x)\log p(x)\,.
\end{equation}
To compute the entropy of a real-valued variable, many people use differential entropy
\begin{equation}
H_{D}=-\int_{X}p(x)\log p(x)dx\,,
\end{equation}
but this definitions of entropy isn't the continuous analog of $H_S$ and does not retain $H_S$'s non-negativity. Correctly extending $H_S$ to the case of uncountable $X$ is not that straightforward and requires the use of a limiting density of discrete points , which seems tricky enough that many people ignore this problem and just use differential entropy despite its shortcomings. Kolmogorov and Sinai defined entropy of a dynamical system. Let $(X,\mathcal B, \mu, T)$ be a dynamical system with probability triple $(X,\mathcal B, \mu)$ and a map $T:X\rightarrow X$ that describes the dynamics on $X$. Its Kolmogorov-Sinai entropy is
\begin{equation}
H_{KSE}=\sup_Q h(T,Q)
\end{equation}
where 
\begin{equation}
h(T,Q)=\lim_{N\rightarrow\infty}\frac{1}{N}H_S(\bigvee_{n=0}^NT^{-n}Q),
\end{equation}
is the entropy of a dynamical system with respect to a partition $Q=\{Q_1,Q_2,\dots,Q_k\}$ of $X$ and 
\begin{equation}
T^{-n}Q=\{Q_{i_0}\cap T^{-1}Q_{i_1}\cap T^{-2}Q_{i_2}\cap \dots\cap T^{-n}Q_{i_n}\}_{i_0,i_1,\dots,i_n\leq k}
\end{equation}
is an iterative pullback of $T$ on $Q$, that is, the set of all trajectories that $T$ can generate on $Q$ in $n$ time steps. The set $\bigvee_{n=0}^NT^{-n}Q$ of all trajectories is countable because the partition Q is countable. So Kolmogorov and Sinai circumvented the trouble of having to consider an uncountable number of states (at every time point) by partitioning $X$ into a countable number of sets $Q_i$. By taking the supremum over partitions $Q$, they ensured that one chooses a partition of $X$ that is fine enough to capture all the information that the dynamical system generates at each time step. Question: Can we define Shannon entropy on uncountable sets $X$ (for example $X=\mathbb R$) as
\begin{equation}
H_S'=\sup_Q\left(-\sum_{Q_i\in Q}p(Q_i)\log p(Q_i)\right)\,,
\end{equation}
where $Q$ is a partition of $X$? If so, why doesn't anybody do that? Or is this in some way equivalent to Jaynes' approach using limiting density of discrete points? Or to differential entropy?","['measure-theory', 'entropy', 'information-theory']"
2885170,How to solve the Leaky Integrate and Fire ODE?,"In the article on neuronal dynamics I read he solves the equation, 
$$ 
\tau_{m}\,{{\text{d}}u\over{\text{d}}t}=-[u(t)-u_{\rm rest}]+R\,I(t)\,. $$ as
$$
u(t)=u_{\rm rest}+R\,I_{0}\left[1-\exp\left(-{t\over\tau_{m}}\right)\right]\,.
$$ When $I(t) = I_0$, $u_{\text{rest}} = u(0)$, and which starts at $t=0$ and then solving for $u(t)$, however, I have little knowledge of ODE's and I was wondering if someone could show me the steps between these two equations.","['neural-networks', 'ordinary-differential-equations']"
2885188,A matrix inequality involving trace norm of a matrix and its inverse,"Let $A,B \succeq 0$ be two positive semidefinite matrices. Can we get a closed form expression for the following quantity? $$ \inf_{X \succ 0} \mathrm{tr}(XA) + \mathrm{tr}(X^{-1}B) $$ We assume all matrices involved are symmetric.","['semidefinite-programming', 'trace', 'matrix-calculus', 'linear-algebra']"
2885220,"Closed form of :$\int_{0}^{\pi}(\frac{\sin n x}{\sin x})^m$, with $n,m$ are integers?","let $n, m$ be integers such that $m$ is odd integer , My simple Guess about evaluation of this :$\int_{0}^{\pi}(\frac{\sin n x}{\sin x})^m$ is to get the following , for $n$ is even integer the integrand is $0$ and for $n$ is odd the integrand is give something like : $k\pi$ with k is such form which i can't get it  . My question here is What is the closed form of this:$$\int_{0}^{\pi}\left(\frac{\sin n x}{\sin x}\right)^m$$ for $m$ is odd ?","['integration', 'trigonometry', 'closed-form']"
2885242,Concentration for Second Maximum of Random Variables,"Using Hoeffding's inequality we know that for iid bounded random variables \begin{align}
  \mathbb{P}(|\hat{\mu} -\mu| > \epsilon) \leq 2\exp(-2\epsilon^2n)
\end{align} where $\hat{\mu}$ is the sample average of n bounded random variables in $[0,1]$. Now suppose I have J such estimators, $\hat{\mu}_k,\ k=1,\ldots,J$. I am interested in the following concetration \begin{align}
  \mathbb{P}(|\hat{\mu}_{(1)} -\mu_{(1)}| > \epsilon)
\end{align} $\hat{\mu}_{(1)}$ is the maximum of the estimators and $\mu_{(1)}$ is the corresponding mean. One can show that $|\hat{\mu}_{(1)} -\mu_{(1)}|$ is 1-Lipschitz and for sub-gaussian random variables \begin{align}
  \mathbb{P}(|\hat{\mu}_{(1)} -\mu_{(1)}| > \epsilon) \leq 2\exp\left(-\frac{\epsilon^2}{2}\right)
\end{align} However, I want to use the original Hoeffding bound without any sub-gaussian assumption. So I use each of the J estimators to create a bound. \begin{align}
  \mathbb{P}(|\hat{\mu}_{(1)} -\mu_{(1)}| > \epsilon) &\leq \mathbb{P}(|\hat{\mu}_{(1)} -\mu| > \epsilon)  && \tag{Jensen's Inequality} \\
 &\leq 2\sum_{k=1}^J \mathbb{P}(\hat{\mu}_k - \mu> \epsilon) && \tag{Union Bound}\\
 & \leq 2\sum_{k=1}^J \exp(-2\epsilon^2n) = 2J\exp(-2\epsilon^2n) && \tag{Hoeffding's} \\
\end{align} Unlike the previous sub-gaussian bound which was non-asymptotic, the above bound goes to zero with large n. I want to extend this idea to second maximum. However, I don't know how to go from $\mathbb{E}[\hat{\mu}_{(2)}]$ to $\mu$ because the second maximum function is neither convex nor concave. I started doing the following. \begin{align}
  \mathbb{P}(|\hat{\mu}_{(2)}| > \epsilon) &\leq 2\mathbb{P}(\hat{\mu}_{(2)} > \epsilon) \\
&= 2\mathbb{P}\left(\left\{\exists s,t \in [J], s \ne t: \epsilon < \hat{\mu}_s \leq \hat{\mu}_t \right\}\right) \\
&= 2\mathbb{P}\left(\bigcup_{s=1}^J \bigcup_{\substack{t=1 \\s \ne t}}^J \left\{\epsilon < \hat{\mu}_s \leq \hat{\mu}_t \right\}\right) \\
&\leq 2\sum_{s=1}^J\sum_{\substack{t=1 \\s \ne t}}^J \mathbb{P}(\epsilon < \hat{\mu}_s \leq \hat{\mu}_t) && \tag{Union Bound} \\
&= 2(J-1)\sum_{s=1}^J\mathbb{P}(\epsilon < \hat{\mu}_s) && \tag{i.i.d}
\end{align} Can someone share ideas on how to incorporate mean in the following argument and get concentration for $\mathbb{P}(|\hat{\mu}_{(2)} - \mu_{(2)}|) $","['inequality', 'concentration-of-measure', 'probability-theory', 'probability']"
2885250,Analytic and bounded implies uniform continuity,"Let $f$ be analytic and bounded in $\{z\in\mathbb{C}\mid Re(z)>0\}$. Prove that $f$ is uniformly continuous in $\{z\in\mathbb{C}\mid Re(z)>C\}=:D$ for every $C>0.$ For uniform continuity, I have to show that for every $\varepsilon>0$ there exists $\delta>0$ such that for all $x,y\in D$ with $\|x-y\|<\delta$ we have $\|f(x)-f(y)\|<\varepsilon$. How can I find such a $\delta$? I don't know how to use the assumptions that $f$ is analytic (i.e. can be written as a power series) and bounded.","['complex-analysis', 'uniform-convergence', 'analytic-functions']"
2885266,Proof by induction that you can order natural numbers where the average isn't between any pair of numbers,"Consider a list of natural numbers like $$1, 2, 3, \dots, n$$ Prove using strong induction that you can order the list for any Natural n, in a way where if you pick any pair of numbers, the average of the numbers you choosed isn't between the numbers you choosed, consider the example $$1, 3, 2$$ Where $1, 2, 3$ is not an acceptable list since the average of $1$ and $3$ is $2$, who is between $1$ and $3$. Until now I have found that first you may separate the odd numbers, let them in the beginning or the end of the list, then separate from the sublist of odd numbers, the numbers who has odd index, and then make that again recursively with the sublist you create, this because the average of an odd with odd index with an odd with pair index is pair, and pairs are in the list of pairs you separated at the beginng","['induction', 'discrete-mathematics', 'sequences-and-series']"
2885275,Geometric intuition for the complex shoelace formula,"The complex shoelace formula for the signed area of a triangle with vertices given by the complex numbers $a, b, c$ is $$\frac{i}{4}
    \begin{vmatrix}
    1 & 1 & 1 \\
    a & b & c \\
    \overline{a} & \overline{b} & \overline{c} \\
    \end{vmatrix}
$$ I have seen the algebraic proof for this formula using elementary row operations and the multilinear nature of the determinant, however that style of proof appears to imply that the simplicity of the final result (i.e. a determinant involving only conjugates) is a coincidence; furthermore it provides little intuition. I am looking for a way to understand this formula through a geometric/intuitive argument (not necessarily rigorous) in order to gain a deeper understanding rather than just accepting that the algebra works out.","['determinant', 'geometry', 'linear-algebra', 'intuition', 'complex-numbers']"
2885294,Anti-concentration of Chi squared random variable,"Most of the concentration bounds for chi squared are centered at it's mean.  I am wondering if there are known exponential bounds on the probability of being near zero, meaning
$
\mathbb{P}(\chi^2_k \leq \varepsilon \mathbb{E} \chi^2_k ) \leq ??
$ I have tried using the Payley-Zygmund inequality, but this only gives an inverse polynomial bound (in terms of k).","['chi-squared', 'inequality', 'probability-distributions', 'probability']"
2885328,How Euler arrived at power series for $a^x$ and $\ln x$,"I'm reading a book that reproduces Euler's arguments, and I have a few questions about a few things he does. Below are parts of the argument: Let $a > 1$.  Consider an ""infinitely small quantity"" $\omega$. $a^\omega$ $\approx$ $1$. Let $a^\omega$ = $1 + \psi$, for $\psi$ an ""infinitely small number"". Then, wishing to relate  $\psi$ and $\omega$. He says let $\psi$ = $k$$\omega$ for real number $k$. So we have $a^\omega$ = $1 + k$$\omega$. At this point apparently Euler computed some examples: for $a = 10$ and $\omega = 0.000001$ $k = 2.3026$. and for $a = 5$ and $\omega = 0.000001$ $k = 1.60944$. He then concluded that $k$ is a finite number that depends on the value of the base $a$. * Now for a finite number $x$ he sought the expansion of $a^x$. To do this he said let $j = \frac{x}{\omega}$ and expressed $x$ as $x = \omega j$, and continued. After he succeeded in finding an expansion for $a^x$ he sought the expansion for the natural logarithm (the inverse function of $a^x$ where the base $a$ is the one for which $k = 1$, in our (and Euler's) notation $a = e$). 1) How should one think of infinitely small and infinitely large numbers? 2) It's not clear to me that the value of $k$ in the derivation of a power series for $a^x$ doesn't also depend on $\omega$. As in for $a = 10$ if we take $\omega$ to be a different (small) value, it's not clear to me that $k$ wouldn't change. Unless the idea is that we let $\omega$ go to $0$ and and in the limit $a^\omega = 1 + k\omega$? 3)Not clear to me that a finite positive number $x$ can be expressed as $x = \omega j$ for some $j$, since $\omega$ is a mysterious ""infinitely small"" quantity 4)It's not clear to me that there should exist a unique base value $a$ for which $k = 1$ apriori, which Euler seems to assume exists, although I suppose the expansion of $a^x$ is in terms of $k$, and setting $x = 1$ and $k = 1$ we can compute the base $a$ for which $k = 1$ and see that it is the value we take our constant $e$ to be. Is this how Euler could've known there exists such a base? In his derivation for the expansion of $ln(1+x)$, he writes: Thus for ""infinitely small $\omega$"" $e^\omega = 1 + \omega$. Thus $ln(1 + \omega) = \omega$. So $j\omega = ln(1 + \omega)^j$ But $\omega$ although infinitely small is positive, so the larger the number chosen for $j$, the more $(1+\omega)^j$ will exceed $1$. So for any positive $x$, we can find $j$ so that $x = (1 + \omega)^j - 1$. From this we he concludes that $1 + x = (1 + \omega)^j$, and so $ln(1 + x) = j\omega$. And since $ln(1 + x)$ is finite and $\omega$ is infinitely small, $j$ must be infinitely large. 5) in deriving an expansion for $ln(1+x)$, Euler argues that $\omega$ although infinitely small is positive, so the larger the number chosen for $j$, the more $(1+\omega)^j$ will exceed $1$. So for any positive $x$, we can find $j$ so that $x = (1 + \omega)^j - 1$. This makes the infinitely small notion even more confusing, as $1 + \omega$ can be made arbitrarily large by raising $1 + \omega$ to higher powers, and so $\omega$ contributes a nonzero amount, and so how can it be infinitely small? It turns out that $j$ must be infinitely large, but we were told $(1 + \omega)^j$ is larger when a larger number is chosen for $j$. How can a larger number be chosen than an ""infinitely large"" number?","['math-history', 'infinitesimals', 'sequences-and-series']"
2885347,Does there exist a right triangle with area 7 and perimeter 12?,"This question is really trivial. I can prove that there is no right triangle with area 7 and perimeter 12, but what I do is solve the following system: if $a$, $b$ and $c$ are, respectively, the two legs and hypotenuse of such a triangle, then $$a^2 + b^2 = c^2,$$
$$a + b +c = 12,$$
$$ab = 14$$ It is easy (although a bit boring and long) to see that there are no real solutions to this system. But I feel that there is a simple answer to this question - perhaps using the triangle inequality - but I just cannot see it.","['algebra-precalculus', 'geometry']"
2885366,"Assume you sell sandwiches. 70% people choose egg, and the rest choose chicken. Probability of selling 2 egg sandwiches to the next 3 customers?","A) 0.343
B) 0.063
C) 0.147
D) 0.027
Solution: (C) ""The probability of selling Egg sandwich is 0.7 & that of a chicken sandwich is 0.3. Now, the probability that next 3 customers would order 2 egg sandwich is 0.7 * 0.7 *0.3 = 0.147. They can order them in any sequence, the probabilities would still be the same."" I think the solution is wrong simply because why do we not treat this as a binomial distribution. 3C2 * (0.7) ^2 * (0.3) ? Can someone explain this ?","['probability-theory', 'probability']"
2885376,Has this I.V.P. unique solution?,"I know 
$$\begin{cases} y’=|y|\\ y(0)=0 \end{cases} $$
Has the solution $y\equiv 0$... does it have another? The question is about the theorem of existence and uniqueness because $\partial_y f(x,y)$ is not continuous",['ordinary-differential-equations']
2885412,Is every empty set equal? [duplicate],"This question already has answers here : intentional and extensional set definition (3 answers) Closed 5 years ago . In a math textbook I found a statement that every empty set is equal. There are such sets that it is impossible for them not to be empty:  set of all natural numbers between 10 and 11. There are such sets that it is possible for them not to be empty:  all the people from the Earth, who are on the Mars now. In future it can be possible. Quesstion: can sets mentioned in 2 be equal to sets mentioned in 3. If yes, why not to take in account the difference examples above?",['elementary-set-theory']
2885441,On the series $\sum \limits_{n=-\infty}^{\infty} \frac{\cos n}{n^2+1}$.,"Prove that $$\sum_{n=-\infty}^{\infty} \frac{\cos n}{n^2+1} = \frac{\pi \cosh (\pi -1)}{\sinh \pi }$$ I already have a solution using Fourier expansion of the exponential function. I'm interested in a complex analysis approach. It would be natural to consider the function $$f(z) = \frac{\pi \cot \pi z \cos z}{z^2+1}$$ and integrate it around an appropriate contour $\Gamma_N$ ( say a square ) The residues at $z=i$ and $z=-i$ are equal; $$\mathfrak{Res}_{z=i} f(z) = \mathfrak{Res}_{z=-i} f(z) = - \frac{\pi \cosh 1 \coth \pi}{2}$$ Thus, $$\frac{1}{2\pi i } \oint \limits_{\Gamma_N} f(z) \, \mathrm{d}z = \sum_{n=-N}^{N}  \mathfrak{Res}_{z=n} f(z) + \mathfrak{Res}_{z=i} f(z) + \mathfrak{Res}_{z=-i} f(z)$$ If we let $N \rightarrow +\infty$ the contour would go to $0$ and we would pick the result. However, this is not the case. Something's missing. The main question is why is that? Can you suggest an appropriate kernel function as well as a contour?","['complex-analysis', 'sequences-and-series']"
2885453,Evaluate $ \lim _{x \to 0} \left[{\frac{x^2}{\sin x \tan x}} \right]$ where $[\cdot]$ denotes the greatest integer function. [duplicate],"This question already has answers here : Calculating $\lim_{x\to0} \left\lfloor\frac{x^2}{\sin x \tan x}\right\rfloor$ (6 answers) Closed 5 years ago . Evaluate $$\lim _{x \to 0} \left[{\frac{x^2}{\sin x \tan x}} \right]$$ where $[\cdot]$ denotes the greatest integer function. Can anyone give me a hint to proceed? I know that $$\frac {\sin x}{x} < 1$$ for all $x \in (-\pi/2 ,\pi/2) \setminus \{0\}$ and $$\frac {\tan x}{x} > 1$$ for all $x \in (-\pi/2 ,\pi/2) \setminus \{0\}$. But will these two inequalities be helpful here?","['limits', 'calculus', 'limits-without-lhopital', 'real-analysis']"
2885460,a.s. convergence uniform distribution,"I am having troubles with proving almost surely convergence for the following problem: Let $U_j$ be IID $U(0,1)$ distributed and define $A_n$ to be: $A_n=\sum_{k=1}^n \prod_{j=1}^k U_j$ for $n\in \mathbb{N}$. for $n\rightarrow \infty$, I want to prove that $A_n$ converges almost surely to some $A$. I tried with LLN, but this did not give anything.","['convergence-divergence', 'uniform-distribution', 'probability-theory', 'random-variables']"
2885489,A Hodge dual computation on a $4$-dimensional Riemannian manifold,"Let $(M,g)$ be a $4$-dimensional smooth Riemannian manifold.  I am trying to understand the following exterior algebra computation: Let $x^1,x^2,x^3,x^4$ be local coordinates on $M$ such that the Riemannian volume form of $g$ is $\mathrm{d}x^1\wedge\mathrm{d}x^2\wedge\mathrm{d}x^3\wedge\mathrm{d}x^4$. Then there exist a local frame $\alpha_1,\alpha_2,\alpha_3,\alpha_4$ of $1$-forms such that the following identities hold:
$$
\begin{aligned}
\ast_g(\mathrm{d}x^1\wedge\mathrm{d}x^2)&= \alpha_3\wedge\alpha_4\\
\ast_g(\mathrm{d}x^1\wedge\mathrm{d}x^3)&= \alpha_4\wedge\alpha_2\\
\ast_g(\mathrm{d}x^1\wedge\mathrm{d}x^4)&= \alpha_2\wedge\alpha_3\\
\end{aligned}\qquad
\begin{aligned}
\ast_g(\mathrm{d}x^3\wedge\mathrm{d}x^4)&= \alpha_1\wedge\alpha_2\\
\ast_g(\mathrm{d}x^4\wedge\mathrm{d}x^2)&= \alpha_1\wedge\alpha_3\\
\ast_g(\mathrm{d}x^2\wedge\mathrm{d}x^3)&= \alpha_1\wedge\alpha_4\\
\end{aligned}
\tag1
$$
(The pattern is that the indices on both sides of every equation are complementary.) In fact, the solution of these equations (which is unique up to replacing each $\alpha_i$ by $-\alpha_i$) is given by 
$$
\alpha_i = g_{ij}\,\mathrm{d}x^j\qquad\qquad\text{where}\quad 
g = g_{ij}\,\mathrm{d}x^i\mathrm{d}x^j.
$$ Question: Why does the formula $\alpha_i = g_{ij}\,\mathrm{d}x^j$ solve the equations? Here is what I understood: $\mathrm{d}x^1,\mathrm{d}x^2$ are $g$-orthogonal to $\alpha_3,\alpha_4$. Since $\ast_g(\mathrm{d}x^1\wedge\mathrm{d}x^2)$ is decomposable*, we can write 
$$
\ast_g(\mathrm{d}x^1\wedge\mathrm{d}x^2)=\beta_1 \wedge \beta_2$$ 
for some one-forms $\beta_i$, which implies $\mathrm{d}x^1,\mathrm{d}x^2$ are $g$-orthogonal to $\beta_1,\beta_2$. Thus $\text{span}\{\beta_1,\beta_2\}=\text{span}\{\alpha_3,\alpha_4\}$, so $\beta_1 \wedge \beta_2=f\alpha_3 \wedge \alpha_4$ for some function $f$. We now need to prove that $f=1$, which is (up to a sign) equivalent to the statement
$$
\| \ast_g(\mathrm{d}x^1\wedge\mathrm{d}x^2)\|=\|\alpha_3 \wedge \alpha_4\|.
$$
Since the Hodge dual operator is an isometry, this is equivalent to
$$
\| \mathrm{d}x^1\wedge\mathrm{d}x^2\|=\|\alpha_3 \wedge \alpha_4\|.
$$
This is where the assumption $\det(g_{ij})=1$ is supposed to enter. I tried to expand both sides in terms of the $g_{ij}$, but so far I don't see how the result follows. Perhaps there is another easier way to see this. For the interested, this computation came up in a question about the existence of ""higher-order"" harmonic coordinates. Comment: Of course, everything here is ""pointwise"", i.e. this is really a result about $4$-dim inner product spaces. I have kept the manifold notation since it might be more familiar. *The Hodge star operator preserve decomposability of elements.","['differential-geometry', 'riemannian-geometry', '4-manifolds', 'differential-forms', 'exterior-algebra']"
2885547,Proving the information inequality using measure theory,"The information inequality is a theorem that shows that the Kullback-Leibler divergence between two probability distributions is always non negative. This can be proved easily using the Jensen's inequality with the $-\log$ function, but the proofs I have read always have to distinguish if the probability distributions are defined by continuous or discrete random variables. I was trying to see if it is possible to not distinguish cases, and I thinked about using measure theory, with the Jensen's inequality provided in Rudin's book: Let $\mu$ be a probability measure on a $\sigma$-algebra $\mathcal{M}$ in a set $\Omega$. If $f$ is a real integrable function with $a < f(x) < b$ for all $x \in \Omega$, and if $\varphi$ is convex on $]a,b[$, then
$$\varphi\left( \int_{\Omega}f d\mu\right) \le \int_{\Omega}(\varphi \circ f) d\mu. $$ So using this I have
$$KL(p\|q) = \int\log\frac{p(x)}{q(x)}dp = \int - \log \frac{q(x)}{p(x)} dp \ge - \log \int\frac{q(x)}{p(x)} dp, $$
but now the only way I find to continue is distinguishing if the distributions are discrete or continuous. I haven't studied measure theory and I only have some basic notions, so I'm not sure how to continue. Also, if my notations are wrong, please tell me. Any help will be appreciated.","['information-theory', 'measure-theory', 'inequality']"
2885548,Completion of measure spaces - uniqueness,"If $(X,\mathcal{A},\mu)$ is a measure space,
  $(X,\mathcal{B},\overline{\mu})$ is complete,
  $\mathcal{B}\supset\mathcal{A}$, and $\overline{\mu}(A)=\mu(A)$ for
  every $A\in\mathcal{A}$, is $(X,\mathcal{B},\overline{\mu})$
  necessarily the completion of $(X,\mathcal{A},\mu)$? My definition of completion is: The completion of $\mathcal{A}$ is the smallest $\sigma$-algebra $\mathcal{B}$ containing $\mathcal{A}$ such that $(X,\mathcal{B},\mu)$ is complete. It seems like the answer to my question is no, because it isn't clear that $\mathcal{B}$ is necessarily the smallest $\sigma$-algebra satisfying the required properties. But I have been looking at the Completion Theorem where they seem to assume that the answer to my question is yes. How can I see that the smallest $\sigma$-algebra satisfying the required properties is the only $\sigma$-algebra satisfying the required properties?","['measure-theory', 'real-analysis']"
2885556,$H \leq \mathbb{Z}_q^n$ and $H \cong \mathbb{Z}_q^m$ implies that $\mathbb{Z}_q^n / H \cong \mathbb{Z}_q^{n-m}$,"Given a pair of positive integers $n,q$ and a subgroup $H \leq \mathbb{Z}_q^n$ such that $H \cong \mathbb{Z}_q^m$ for a positive
  integer $m < n$ then show that 
  $$  \mathbb{Z}_q^n / H \cong \mathbb{Z}_q^{n-m}.$$ This is a problem I came up with trying to generalize the trivial case when $q$ is a prime number (It is trivial because in this case a $\mathbb{Z}_q$- module is a vector space). I actually found a proof but I believe it's way too long for such a statement so I'm not asking for hints or suggestions: my question is if somebody is able to find a better proof (even a sketch would be fine).","['abstract-algebra', 'finite-groups', 'modules']"
2885572,find minimum value of $n$ that satisfies this inequality: $4(x_1^2+x_2^2+...+x_n^2)<2(x_1+x_2+...+x_n)<x_1^3+x_2^3+...+x_n^3$,"I saw this question, it looks very hard: there are real positive numbers 
  $\{x_1,x_2,...x_n\}$ , given the inequality: $$4(x_1^2+x_2^2+...+x_n^2)<2(x_1+x_2+...+x_n)<x_1^3+x_2^3+...+x_n^3$$ What is the minimum value of $n$, for this to be possible? This is what I've tried so far: $$\sum_{k=1}^nx_k^3>\sum_{k=1}^n4x_k^2\\\sum_{k=1}^nx_k^3-\sum_{k=1}^n4x_k^2>0\\\sum_{k=1}^nx_k^2(x_k-4)>0$$So it must be at least one number that is bigger than $4$. So I go with trial and error .Example 1;$$x_1=10, n=3001, x_2=x_3=...=x_{3001}=0.1\\4(100+3000\cdot0.01)=520<2(10+3000\cdot0.1)=620<1000+3000\cdot0.001=1003$$ Example 2;$$x_1=6, n=1001, x_2=x_3=...=x_{1001}=0.1\\4(36+1000\cdot0.01)=184<2(6+1000\cdot0.1)=212<216+1000\cdot0.001=217$$ S0 $n$ is getting smaller, but I have no idea how to minimize $n$, or even how to approach this kind of question. Thanks in advance for any help.","['contest-math', 'multivariable-calculus', 'symmetric-polynomials', 'optimization', 'inequality']"
2885574,Is there only one complete measure extending Borel measure?,"Is Lebesgue measure the only complete mesure extending Borel mesure on $\mathbb R$? If yes, why? If no, what is an example of a complete measure extending Borel measure that is different from Lebesgue measure? I raise this question following Completion of measure spaces - uniqueness .","['measure-theory', 'lebesgue-measure']"
2885605,"Is $\sigma((X,Y))=\sigma(X,Y)$?","Let $(\Omega,\mathcal A)$ and $(\Omega_i,\mathcal A_i)$ be measurable spaces $X_i:\Omega\to\Omega_i$ be $(\mathcal A,\mathcal A_i)$-measurable Are we able to show that $\sigma((X_1,X_2))=\sigma(X_1,X_2)$? By definition, $$\sigma((X_1,X_2))=(X_1,X_2)^{-1}(\mathcal A_1\otimes\mathcal A_2)\tag1$$ and we know that this is equal to $$\sigma((X_1,X_2)^{-1}(\mathcal E_1\times\mathcal E_2),\tag2$$ if $\mathcal E_i\subseteq\mathcal A_i$ with $\sigma(\mathcal E_i)=\mathcal A_i$. On the other hand, $$\sigma(X_1,X_2)=\sigma(\sigma(X_1)\cup\sigma(X_2))=\sigma(X_1^{-1}(\mathcal A_1)\cup X_2^{-1}(\mathcal A_2))\tag3$$ and $$X_i^{-1}(\mathcal A_i)=\sigma(X_i^{-1}(\mathcal E_i)).\tag4$$ But I don't see that the claim follows from these equalities.","['measure-theory', 'probability-theory']"
2885614,"Is it possible to define ""Straight-line"" logically? If it is possible, How you will define it? [duplicate]","This question already has answers here : Is there a rigorous definition of a line? (2 answers) Closed 5 years ago . Recently I am studying the ""ELEMENTS"" of Euclid. It is a translation of SIR THOMAS L. HEATH. In the definition part of the first book, the second definition is, ""A line is Breathless length"". My question is what we understand by Length And Breadth? Is it not straight line? how we can define line with the help of the concept of straight line? Can we define a ""Dimension"" logically?","['definition', 'geometry']"
2885637,"Existence of an uncountable, pairwise disjoint collection of dense Borel sets, each of which is not in the algebra of open sets","Let $(X, \tau)$ be Cantor space. That is, $X = \{0,1\}^\omega$ and $\tau$ is the collection of open sets in the product of discrete topologies on $\{0,1\}$. Let $\mathcal{A}(\tau)$ be the algebra generated by $\tau$. So $\mathcal{A}$ contains the open and closed sets, as well as finite unions and intersections of these. Does there exist an uncountable collection $\{D_i: i \in [0,1]\}$ of pairwise disjoint, dense, Borel subsets of $X$ such that $D_i \notin \mathcal{A}(\tau)$ for all $i$? If we do not require that $D_i \notin \mathcal{A}(\tau)$, then the answer is affirmative, by a result that is apparently due to Ceder (""On maximally Borel resolvable spaces""). Unfortunately, I cannot access Ceder's paper, and so I cannot see about modifying his proof. So, in addition to the main question above, references to a proof of Ceder's result would be appreciated. I have tried to answer this by mimicking the inductive technique used in the answer to this question . But I cannot see how to ensure by that method that my collection is Borel and not contained in $\mathcal{A}(\tau)$.","['cantor-set', 'real-analysis', 'borel-sets', 'general-topology', 'set-theory']"
2885643,Use CLT to find the probability,"$X$ is a discrete random variable with the following density function:
  $$
    f_X(n)
  = \begin{cases}
        c e^{-2} \, \frac{2^n}{n!}
      & n \geq 0, \\
        c 3^n
      & n < 0.
    \end{cases}
$$
  Define the variables $V$ as follows:
  $$
    V
  = \begin{cases}
        0
      & X < 0 \\
        X
      & X \geq 0.
    \end{cases}
$$
  Let $V_1, V_2, V_3, \dotsc$ be a sequence of independent and identically distributed random variables each having the same distribution as $V$. Use the central limit theorem to approximately find $P(20 < \sum_{i=1}^{20} V_i < 30)$. (Original image here .) Not a homework. The entire problem could be found at https://math.stackexchange.com/questions/2885578/find-the-expected-value-of-the-sum-of-random-variables . But it is not that relevant. My work: In order to use CLT we assume that the variable is normal and then find the mean and std of the random variable. $\mathbb E[V]=\sum_{n\geq 0}nce^{-2}2^n/n!=2c$ But how to find the variance for the Normal r.v.? $\mathbb E[V^2]=\sum_{n\geq 0}n^2ce^{-2}2^n/n!=6c$ (not sure if it correct) So $\operatorname{Var}[V]=6c-4c^2$","['calculus', 'statistics', 'central-limit-theorem', 'probability']"
2885646,"Proving that $\{0,1\}^\mathbb N$ and $\mathbb{N^N}$ have the same cardinality [duplicate]","This question already has answers here : Comparing the two cardinals $\aleph_0^{\aleph_0}$ and $2^{\aleph_0}$ [duplicate] (1 answer) Proving that $\mathrm{card}(2^{\mathbb{N}})=\mathrm{card}(\mathbb{N}^\mathbb{N})$ (2 answers) Is $\aleph_0^{\aleph_0}$ smaller than or equal to $2^{\aleph_0}$? [duplicate] (3 answers) Closed 5 years ago . Problem Let $D$ be the set of all the functions $f\colon\mathbb N\to \mathbb N$ , where $\mathbb N$ is the set of natural numbers. Let $E$ be the set of all functions $f\colon \mathbb N\to\{\,0,1\,\}$. Prove both the sets have equal cardinality. Attempt (failed) $E$ is the set of all infinite binary sequences. By Cantor's second diagonal argument $E$ is uncountable.
Since $E\subset D$, $D$ is also uncountable. 
If i prove there exists injections from $D$ to $E$ and also from $E$ to $D$, then Schroeder-Bernstein theorem can be used. Attempt 2 Consider two functions 
$\alpha\colon D \to E$ and $\beta\colon E \to D $ Consider a function $f \in E$ is a function from $\mathbb N$ to $\{\,0,1\,\}$. $\beta(f) $ is a function that assigns to $n$ the $f(n)+1$ . This is a injective function . I have difficulty finding $\alpha$. Any hint or help will be appreciated.",['elementary-set-theory']
2885685,Topology containing a parabolic region,"We consider in $\mathbb{R}^2$ the topology of the sets $U\subset \mathbb{R}^2$ which contains for each $(a,b)\in U$ a parabolic region given by 
  $$\alpha(x-a)^2 <y-b, \quad \alpha >0$$
  Study if this space verifies the first-countable axiom, the second-countably axiom and if it's separable. Also, show that there are compact set in this space which are neither closed nor bounded. Firstly, we will think about how the open sets are. For each point of the plane, we can take $\alpha>0$ and the parabolic region 
$$\alpha(x-a)^2 <y-b,$$
and observe that $(a,b)$ does not satisfy the equality. Changing $\alpha$ will widen or narrow the parabolic region. Then, an open set in this topology will be 
$$U=\{(a,b)\}\cup \{(x,y)\in \mathbb{R}^2 : \alpha(x-a)^2 <y-b\}.$$
If we fix $\alpha$ for each point $(x,y)$ of the parabolic region (remember that the set $U$ has to contain $\textbf{a}$ parabolic region), we will be able to choose $\alpha_{(a,b)}$ (it can be very big) such that $U$ will contain all of the parabolic region with vertex $(x,y)$. Now, we can work on the problem. $(a)$ The set $\mathbb{Q}^2$ intersects each open set (non-empty), so the space is separable. $(b)$ Taking $\beta>\alpha_{(a,b)}$, where $\beta\in \mathbb{N}$, we have that
$$\beta(x-a)^2 <\alpha_{(a,b)}(x-a)^2 <y-b.$$
Thus, we can take as a neighbourhood basis for the point $(a,b)$
$$\mathcal{V}_{(a,b)}=\{U_{a,b}^\beta: \beta\in \mathbb{N}, \beta > \alpha \}$$
where 
$$U_{a,b}^\beta=\{(a,b)\}\cup \{(x,y)\in \mathbb{R}^2 : \beta(x-a)^2 <y-b\}.$$
This basis is countable, so the space is first-countable axiom. $(c)$ Given an open set $U$, then we intersect it with the line $r: y=b$. The intersection is just the point $(a,b)$ and, by the properties of relative topology in the line $r$, we have that the point $(a,b)$ is open in $(r, \mathcal{T}|_r)$. As $\mathbb{R}^2$ is not countable, then we cannot find a countable basis of open sets, so this space is not second-countably axiom. $(d)$ We consider the set 
$$K=\{a\}\times [b+1,+\infty)$$
and an open covering of $K$. It's clear that there is $\alpha>0$ such that 
$$K\subset \{(a,b)\}\cup \{(x,y)\in \mathbb{R}^2 : \alpha(x-a)^2 <y-b\},$$
which is finite. Then, $K$ is a compact neither closed nor bounded.","['general-topology', 'problem-solving']"
2885693,Alternative way of calculating the intersection number on a surface,"Let $X$ be an algebraic surface over a field $k$ and let $D,E$ two smooth prime divisors on $X$. Assume that $e_x,f_x\in\mathcal O_{X,x}$ are the local equations at $x$ of $D$ and $E$ respectively. Let $v_{D,x}$ be the valuation at $x\in D$ (w.r.t the curve $D$). For any $x\in D$ there is a natural projection $\pi:\mathcal O_{X,x}\to k(D)$ (where $k(D)$ is the function field of the curve $D$ or equivalently the residue field at the generic point of $D$). I'd like to understand why the following equality is true for any $x\in D\cap E$: $$v_{D,x}(\pi(f_x))=\operatorname{length}_{\mathcal O_{X,x}}\left(\mathcal O_{X,x}/(e_x,f_x)\right)=:i_x(D,E)$$ In other words I'd like to understand why it is possible to calculate the local intersection number by means of the one dimensional valuation.","['algebraic-geometry', 'intersection-theory', 'surfaces', 'schemes']"
2885723,Determine this limit using L'Hopitals rule [duplicate],"This question already has answers here : Evaluating: $\lim\limits_{x\to0}\left(\frac{\sin x}{x}\right)^{{6}/{x^{2}}}$ (5 answers) Closed 2 years ago . I couldn't find a way to get the answer for $$\lim\limits_{x \to 0} \left(\frac{\sin x}{x}\right)^{\frac{1}{x^{2}}}$$ From my knowledge of L'Hopital's Rule, I see that this is some kind of $1^{\infty}$ indeterminate form since I know from previous results that $\lim\limits_{x \to 0} \left(\frac{\sin x}{x}\right)=1$. Proceeded to find the limit of its natural $\log$ which is $$\lim\limits_{x \to 0} \left(
\frac{\ln(\frac{\sin x}{x})}{x^{2}}\right)$$ then got stuck when I got to $$\lim\limits_{x \to 0} \left(
\frac{\cot x-\frac{1}{x}}{2x}\right)$$ as I now get $\infty/0$ and this hasn't happened to me before since I just started not long ago on this topic. Can someone give me a further hint as to which direction I should head to or recommend me another more suitable approach to solve this problem? If it helps, the given answer is $e^{-1/6}$.","['limits', 'calculus', 'derivatives']"
2885751,How prove this integral $\int_0^1\frac{(\arctan{x})^2\ln({x+1/x+2})}{(1+x)^2}dx$,"$$I=\int_0^1\frac{(\arctan{x})^2\ln({x+1/x+2})}{(1+x)^2}dx=-\dfrac{\pi^3}{96}+\dfrac{5\pi}{16}\ln^22-\dfrac{\pi}{4}G-G+\dfrac{\pi}{2}\ln2+\dfrac{7}{16}\zeta(3)$$
 Where G is the Catalan's Constant.
 Using integration by parts we have:
 $$v=-\dfrac{1}{1+x},  du=[2\dfrac{\arctan{x}\ln(x+1/x+2)}{1+x^2}-\dfrac{(1-x)}{x(1+x)}{(\arctan{x})^2}]dx$$.
$$\dfrac{(1-x}{x(1+x)^2}=-\dfrac{1}{1+x}-\dfrac{2}{(1+x)^2}+\dfrac{1}{x}$$
$$\int_0^1\dfrac{(\arctan{x})^2}{x}dx=\dfrac{\pi}{2}G-\dfrac{7}{8}\zeta(3),\int_0^1\frac{(\arctan{x})^2}{(1+x)^2}dx=-\dfrac{G}{2}+\dfrac{\pi}{4}\ln2,\int_0^1\dfrac{(\arctan{x})^2}{1+x}dx=\dfrac{\pi}{4}G-\dfrac{21}{32}\zeta(3)+\dfrac{\pi^2}{32}\ln2$$
 $$ And \int_0^1\dfrac{(1-x)}{x(1+x)^2}{(\arctan{x})^2}dx=\dfrac{\pi}{4}G-\dfrac{7}{32}\zeta(3)-\dfrac{\pi^2}{32}\ln2+G-\dfrac{\pi}{2}\ln2$$
How to calculate$$\int_0^1\frac{\arctan{x}\ln({x+1/x+2})}{(1+x)(1+x^2)}dx??$$","['integration', 'proof-verification', 'definite-integrals']"
2885754,MVT inequality problem,"I just sat a real analysis exam and this was a question in it that I couldn't answer... Prove that $\left|e^\frac{-x^2}{2t}-e^\frac{-y^2}{2t}\right| \leq \frac{|x-y|}{t}$ for $x,y \in [-1,1] ,t>0$ I ended up trying to set $f(x,y)=e^\frac{-x^2}{2t}-e^\frac{-y^2}{2t}$, then attempted trying $f(-1,-1) =f(1,1)$ but never ended up getting anywhere. Any tips on how this is actually solved? I've never seen an inequality problem like this before.","['analysis', 'real-analysis']"
2885790,Number of ordered pairs of subsets,"Q.20 What is the number of ordered pairs $(𝐴, 𝐵)$ where $𝐴$ and $𝐵$ are subsets of $\{1,2, . . . ,5\}$ such that neither $𝐴 ⊆ 𝐵$ nor $𝐵 ⊆ 𝐴$? Ans: 𝟓𝟕𝟎 Hint: Use principle of Inclusion-Exclusion. Solution: Let $X$ denote the set of all ordered pairs $(A, B)$ when $A ⊆ B$. Similarly let $Y$ denote set of all ordered pairs $(A,B)$ when $B ⊆ A$. The question asks to find $$𝑛(X'\cap Y') = 𝑛(𝑆) − 𝑛(𝑋\cup𝑌) $$$$= 𝑛(S) − 𝑛(X) − 𝑛(Y) + 𝑛(X\cap Y) $$$$= 2^{10} − 3^5 − 3^5 + 2^5 = 570$$. How did this happen? What is $S$? If $S={1,2,3,4,5}$, shouldn't $n(S)=2^5$? And where do the $3^5$s come from? I cannot understand this. Also, are there other ways to solve this?","['elementary-set-theory', 'combinatorics']"
2885800,Evaluating the nested radical $ \sqrt{1 + 2 \sqrt{1 + 3 \sqrt{1 + \cdots}}} $. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last month . The community reviewed whether to reopen this question last month and left it closed: Original close reason(s) were not resolved Improve this question How does one prove the following limit?
$$
  \lim_{n \to \infty}
  \sqrt{1 + 2 \sqrt{1 + 3 \sqrt{1 + \cdots \sqrt{1 + (n - 1) \sqrt{1 + n}}}}}
= 3.
$$","['nested-radicals', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
2885805,"Intuition behind : for all $x\in E$ there is $f_0\in E^*$ s.t. $\left<f_0,x_0\right>=\|x_0\|^2$ and $\|f_0\|=\|x_0\|$.","I'm seeing a theorem that say that for all $x\in E$ there is $f_0\in E^*$ s.t. $\left<f_0,x_0\right>=\|x_0\|^2$ and $\|f_0\|=\|x_0\|$. I recall that $E^*$ denote the topological dual of $E$. Is there a similar result for inner product spaces for example ? I don't really see the intuition behind this proposition.",['functional-analysis']
2885867,"Do there exist two finite groups $H$ and $K$, satisfying specific conditions?","Let’s define $\sigma(G)$ as the sum of orders of all normal subgroups of a finite group $G$. Do there exist two finite groups $H$ and $K$ such, that $\sigma(H) = |H| + |K| = \sigma(K)$,  $|H|$ is even and $|K|$ is odd? It is quite obvious, that pair of cyclic groups $H$ and $K$ satisfies that condition iff $|H|$ and $|K|$ form an amicable pair. Thus, an even-odd amicable pair would have solved the question. But whether they do exist is an open problem! Still, the pairs of non-cyclic non-isomorphic finite groups $H$ and $K$, that satisfy the condition $\sigma(H) = |H| + |K| = \sigma(K)$ actually do exist. An example was provided in an answer to that question: Do there exist finite non-cyclic groups $H$ and $K$, satisfying the specific condition? However, the orders of both groups in the example are even, so it does not help us much now. And it would be interesting to know, if there is such an ""even-odd pair""...","['normal-subgroups', 'group-theory', 'abstract-algebra', 'finite-groups']"
2885878,Distance between two stations,"A railway line is divided into $10$ sections by the stations $A, B, C, D, E, F, G, H, I, J$ and $K$. The distance between $A$ and $K$ is $56$ km. A trip along two successive sections never exceeds $12$ km. A trip along three successive sections is at least $17$ km. What is the distance between $B$ and $G$? I have no idea how to solve this question. I thought about taking the distance between each set of successive stations as a variable, but this gets too messy. And taking ${56\over10}=5.6$ doesn't work as well. The inequalities look like they're important, but I can not make use of them anywhere. Please help.","['contest-math', 'algebra-precalculus']"
2885890,Bounding the solution to a Riccati equation,"I have the following continuous-time matrix Riccati equation $$A X + X A' - X b b' X + Q = 0$$ where $Q>0$, $A$ is a diagonal matrix with strictly negative
eigenvalues and $b$ is a (column) vector. Without knowing $b$, only that $\| b \|_2 \leq \beta$, can I find a diagonal
matrix $Y$, with strictly positive eigenvalues, such that $Y\leq X$,
(where $Y\leq X$ means that $v'Yv\leq v'Xv$ for any vector $v$)?","['kalman-filter', 'control-theory', 'matrices', 'matrix-equations', 'positive-definite']"
2885988,Elementary set theory - Confused about A $\cup$ B = B [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I am trying to solve: 
Proof that  $\exists!A\subset U(\forall B \subset U(A \cup B = B)$. But once I think about it, I can see not one but 2 solutions.
a) $ \varnothing \cup B = B $
b) $ B \cup B = B $ The solution is supposed to be a), what is wrong about b)?
Thanks!",['elementary-set-theory']
2886009,"$a+b+c+d+e+f=14$ , where $a,b,c,d,e$ and $f$ are whole numbers $\le 4$","I need to find the number of solutions to $$a+b+c+d+e+f=14$$ where $a,b,c,d,e$ and $f$ are whole numbers $\le 4$ . Manually I am getting the result which is $1506$ , but is there any other method that solves the problem easily? EDIT: Actually this is the question of cricket I converted it into the following problem: In Indo-Pak one day International cricket match at Sharjah, India needs $14$ runs to win just before the start of the final over. Find the number of ways in which India just manages to win the match (i.e. scores exactly $14$ runs), assuming that all the runs are made off the bat & the batsman can not score more than $4$ runs off any ball.",['combinatorics']
2886024,A conjecture involving prime numbers and circles,"Given the series of prime numbers greater than $9$, we organize them in four rows, according to their last digit ($1,3,7$ or $9$). The column in which they are displayed is the ten to which they belong, as illustrated in the following scheme. My conjecture is: Given any two primes (i.e. given any two points in the above scheme), it is always possible to find a circle passing through at least other two points, representing other two primes. Here I present some examples, taking two random points. Sorry for the bad quality of the picture. Since I am not an expert of prime numbers, this can be an obvious result (if true, of course). In this case, I apologize for the trivial question. However, I tried to attack the problem by means of the equation of the circle, but I got lost. Thanks for your help! NOTE: You might be interested in this and in this other post. Also, here I state a similar conjecture for ellipses.","['number-theory', 'circles', 'prime-numbers', 'euclidean-geometry']"
2886070,Clarification on the use of dot product in the formula for a plane's distance to origin,"I decided to take on MIT Multivariable Calculus to get a review for next semester. Having some struggles with this question though and the solutions aren't really helping me out much, thinking I might be seeing this in a naíve way and am missing a step on how they got there. Suppose a plane $ax+by+cz = d$ We are supposed to prove the formula $D = \frac{\mid d \mid}{\sqrt{a²+b²+c²}}$
where D is the distance to the origin. I was having some troubles with the proof, checked the solution and slowly started to get a clue, but need to see if I'm getting this right. So we suppose a $P_0 = (x_0,y_0,z_0)$ and know that the normal vector is $\vec{N} = (a,b,c)$. The solution started like this $\vec{OP}.\frac{\vec{N}}{|\vec{N}|}$ and then by usual operations it got to the formula that we wanted. So my question is, am I supposed to see the dot product as the projection of the vector that connects the origin to a certain point into the direction of the Normal vector? I'm getting that value that will be the minimal distance? The intuition is to see the dot product as some kind of parser that finds the commonalities between 2 vectors and returns the vector that is composed by those commonalities? Also finally, I understand that dividing by the length of the Normal vector gives us the ""unitary"" direction vector right? But I'm not seeing the implication of not doing that, how would it deform the resulting distance? Would it make larger or smaller depending on the length of the normal vector that we choose? If these questions are basic I'm sorry, I never had much love for this class and hopefully will get better in these next few weeks as I watch this course.","['multivariable-calculus', 'linear-algebra', 'vectors']"
2886090,Why is the Weil restriction of the multiplicative group a torus?,"In Serre's book about abelian $\ell$ -adic representations, he claims that $\textrm{Res}_{K/\mathbb{Q}} (G_{m})$ is a $d$ -dimensional torus if $[K:\mathbb{Q}] = d$ . Why is this true? According to the example in these notes ( http://alpha.math.uga.edu/~pete/SC5-AlgebraicGroups.pdf ), $\textrm{Res}_{\mathbb{C}/\mathbb{R}} (G_m)$ is isomorphic to $\left\{(Y_1, Y_2) \neq (0, 0)\right\}$ . Wouldn't a two-dimensional torus be $\left\{(Y_1, Y_2): Y_1, Y_2 \neq 0\right\}$ ? Are these two sets actually isomorphic as varieties? Or does it matter that this is about $\mathbb{C}/\mathbb{R}$ instead of $K/\mathbb{Q}$ ?","['algebraic-number-theory', 'algebraic-geometry']"
2886092,Single Value Decomposition from Eigenvectors,"Attempting to solve the SVD of this matrix:
\begin{bmatrix}
    2       & 0 \\
    0       & -3 \\
    0       & 0
\end{bmatrix} I know that one possible (my understanding is the SVD is not necessarily a unique result) result is:
$$
\begin{bmatrix}
    1    & 0    & 0 \\
    0    & -1   & 0 \\
    0    & 0    & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
    2       & 0 \\
    0       & 3 \\
    0       & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
    1    & 0 \\
    0    & 1
\end{bmatrix}^T
=
\begin{bmatrix}
    2       & 0 \\
    0       & -3 \\
    0       & 0
\end{bmatrix}
$$ Which I have verified. I am trying to solve this problem myself, and am getting a different result; in particular, one that does not satisfy $A=U\Sigma V^T$. Therefore, I am trying to understand the hole in my approach. Currently, my result looks like this:
$$
\begin{bmatrix}
    0    & 0    & 1 \\
    1    & 0    & 0 \\
    0    & 1    & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
    3    & 0 \\
    0    & 2 \\
    0    & 0 
\end{bmatrix}
\cdot
\begin{bmatrix}
    0    & 1 \\
    1    & 0 
\end{bmatrix}^T
=
\begin{bmatrix}
    0    & 0 \\
    0    & 3 \\
    2    & 0 
\end{bmatrix}
$$ This is my approach, given a matrix $M$ 1. Construct $MM^T$ and $M^TM$ $$
MM^T
=
\begin{bmatrix}
    4    & 0    & 0 \\
    0    & 9    & 0 \\
    0    & 0    & 0
\end{bmatrix}
\quad\&\quad
M^TM
=
\begin{bmatrix}
    4    & 0 \\
    0    & 9 \\
\end{bmatrix}
$$ 2. Solve for the eigenvalues and eigenvectors of both $MM^T$ and $M^TM$ This is accomplished via QR Factorization. Eigenvectors are listed in order of highest magnitude eigenvalue to lowest magnitude eigenvalue. The results are as follows: $$
MM^T \enspace eigenvalues = 
\begin{bmatrix}
    9    & 4    & 0
\end{bmatrix}
$$
$$
MM^T \enspace eigenvectors = 
\begin{bmatrix}
    0 \\
    1 \\
    0
\end{bmatrix}
\begin{bmatrix}
    0 \\
    0 \\
    1
\end{bmatrix}
\begin{bmatrix}
    1 \\
    0 \\
    0
\end{bmatrix}
$$
$$
M^TM \enspace eigenvalues = 
\begin{bmatrix}
    9    & 4 
\end{bmatrix}
$$
$$
M^TM \enspace eigenvectors = 
\begin{bmatrix}
    0 \\
    1 
\end{bmatrix}
\begin{bmatrix}
    1 \\
    0 
\end{bmatrix}
$$ 3. Construct $U$ using the eigenvalue-ordered eigenvectors of $MM^T$ as the columns of the matrix. Construct $V$ in the same way, but with $M^TM$. I would also apply Gram-Schmidt orthonormalization here, but these matrices are already orthonormal. $$
U = 
\begin{bmatrix}
    0    & 0    & 1 \\
    1    & 0    & 0 \\
    0    & 1    & 0
\end{bmatrix}
$$
$$
V =
\begin{bmatrix}
    0    & 1 \\
    1    & 0 
\end{bmatrix}
$$ 4. Finally, construct $\Sigma$ by making a diagonal matrix whose values are the square roots of the non-zero eigenvalues from $MM^T$ or $M^TM$. Presumably, I should preserve the eigenvalue order when I do this? $$
\Sigma =
\begin{bmatrix}
    3    & 0 \\
    0    & 2 \\
    0    & 0 
\end{bmatrix}
$$ So my question is, if anyone can aid me in identifying either the mistake I've made, or the hole in my approach to this problem. Assuming that I haven't made a simple error, I believe I am missing some sort of insight as to the construction of these matrices (because you can see, for instance, that the known solution has very similar values in differing orders and signs).","['matrices', 'linear-algebra', 'svd', 'matrix-decomposition']"
2886108,"Given orthogonal vibrations, how can I find the magnitude and direction of the major axis of the resulting ellipse?","The Context In my work, I am using a vibration table to test the resonant properties and survivability of a structure under different shaking regimes. The table is driven by an eccentrically weighted rotary motor which excites vibrations in the Y and Z axes (green and blue respectively in the image below). Using 3-axis accelerometers on the table and at various points on the structure, I can record the excitation and response vibrations in each axis (example plot at 20Hz below). However, two sinusoids of differing amplitudes and phases define an elliptical polarization (the same data as above is plotted parametrically below). The Question Based on the answers to other Stack Exchange questions ( here and here ), I know that the parametric form of an ellipse, centered at the origin and rotated by an angle $\theta$ is
$$ a_y(t) = A\cos\big(2\pi ft\big)\cos\big(\theta\big) - B\sin\big(2\pi ft\big)\sin\big(\theta\big)  $$
$$ a_z(t) = A\cos\big(2\pi ft\big)\sin\big(\theta\big) + B\sin\big(2\pi ft\big)\cos\big(\theta\big)  $$
where $A$ and $B$ are the major and minor radii respectively. My question is, how can I convert my axes-aligned sinusoids
$$ a_y(t) = Y\sin\big(2\pi ft\big) $$
$$ a_z(t) = Z\sin\big(2\pi ft + \phi\big) $$
into the above form, such that I can immediately read off the rotation angle and radii? My goal is to know the direction and magnitude of the major radius of the acceleration ellipse, so that I can better align my structure in the direction of strongest vibration. What I've Tried So Far Based on the process discussed in this article , I’ve attempted to simply set the two forms equal to one another and solve for $A$, $B$, and $\theta$ as functions of $Y$, $Z$, and $\phi$. However, that process has yielded inconsistent results, and none of them seem to agree with the ellipse as I’ve plotted it. I also have a gut feeling that the major and minor radii correspond to the eigenvalues/eigenvectors of some transformation matrix, but I have no idea how to go about constructing said matrix. Numerically, the sinusoids I've plotted above have parameters
$ Y = 0.7847g $, $ Z = 1.0498g $, and $ \phi = 0.9537 $. The major and minor radii are approximately $R = 1.1805g$ and $r = 0.5696g$ respectively, and the rotation angle is approximately $\theta = 1.0330$.","['trigonometry', 'conic-sections', 'geometry', 'parametric']"
2886145,Evaluation of $\sum_{n\geq1}\frac{1}{n}\ln(1+\frac{1}{n})$,"Coming across the calculation of a special integral I get stuck on the following series, which I have given its integral representation : $$\text{J}=\sum_{n\geq1}\frac{1}{n}\ln\bigg(1+\frac{1}{n}\bigg)=\int_{0}^{1}\frac{1}{x}\bigg(\psi(1+x)+\gamma \bigg)dx\,$$ Where $\psi$ denotes the digamma function and $\gamma$ represents the Euler-Mascheroni constant. I am wondering if such a series has a closed-form.","['integration', 'euler-mascheroni-constant', 'digamma-function']"
2886200,Is Whitehead lemma true for super Lie algebras?,"Classical Whitehead lemma states that if $\mathfrak g$ is a finite-dimensional complex Lie algebra and $M$ is a finite-dimensional $\mathfrak g$-module, then first cohomology group $H^1(\mathfrak g, M)$ (defined for example as cohomology of the Chevalley-Eilenberg complex) is trivial. I need to know if this is also true for super Lie algebras.","['lie-algebras', 'homological-algebra', 'superalgebra', 'linear-algebra', 'lie-superalgebras']"
2886203,Injective homomorphism $H:C_b(X) \to C_b(Y)$ implies the existence of a continuous and surjective map $F:Y \to X$,"Let $X$ and $Y$ be $2$ topological spaces and let $C_b(X)$ and $C_b(Y)$ denote the set of all continuous and bounded functions on X and Y, respectively, to the space of complex numbers. It is a well-known fact that $C_b(X)$ and $C_y(Y)$ are $C^*$ algebras (under the usual operations: pointwise addition, pointwise multiplication, pointwise scalar multiplication, sup norm, and the star operation being conjugation) The following theorem is rather easy to show: Theorem: If there exists a continuous and surjective map $F:Y \to X$, then there exists an injective $*$-homomorphim $H:C_b(X) \to C_b(Y)$. One can just define $H(f)=f \circ F$ and show that this $H$ has the desired properties. I am interested in the converse, namely: Question: If there exists an injective $*$-homomorphim $H:C_b(X) \to C_b(Y),$ does there exist a continuous and surjective map $F:Y \to X?$ How should one define $F?$ Recall that a $*$-homomorphism is an algebra homomorphism that also preserves the norm and the star operation. Any help would be greatly appreciated. PS . If you are not familiar with $C^*$ algebras, then disregard that part of the question and regard this problem as a question about algebras.","['c-star-algebras', 'general-topology', 'functional-analysis', 'algebras']"
2886218,Strategy for board game 2,"In this question the following was asked: Alice and Bob are playing the following game: They have a $4 \times 4$ empty grid and take turns coloring one square each, starting with Alice, both using the same color. Whoever completes any $2 \times 2$ area on the grid (after having made their move) is the loser. Is there any winning strategy for any of the two players? The answer was that Bob had a winning strategy (see link). It was also determined that for an $n \times n$ grid, where $n$ is odd, Alice has a winning strategy. However, it was not determined who has a winning strategy when $n$ is even with $n \gt 4$. Can someone spot such a strategy? Edit To avoid repeats of answers previously given, here are two strategies for Bob which don't work: Bob's winning strategy for $n=4$ If Alice colors $(i,j)$, Bob colors $(1+(i+m-1) \mod n, \ j)$, where $n=2m$. Won't work for $n \gt 4$ as Alice can color e.g. $(1,1)$, $(1,2)$, $(n,1)$, $(n,2)$. Bob mirror's Alice's move If Alice colors $(i,j)$, Bob colors $(n+1-i, n+1-j)$. Won't work as Alice can color two adjacent central squares. In fact, I think Alice might have a winning strategy. I simulated $10,000$ games on a $6 \times 6$ grid where each player made random ""legal"" moves, i.e. moves which don't immediately result in a loss, and Alice consistently wins $56 \text {%}$ of the time.","['recreational-mathematics', 'combinatorics', 'combinatorial-game-theory']"
2886236,A nice expression for $\int_0^{\pi/2} \left[\frac{1}{x \sin(x)}-\frac{1}{x^2}\right] \mathrm{d} x$,"Motivated by the easier integral
$$ \int \limits_0^\infty \left[\frac{1}{x^2} - \frac{1}{x \sinh(x)}\right] \mathrm{d} x = \ln(2) \, ,$$
I have been trying to compute $$ I \equiv \int \limits_0^{\pi/2} \left[\frac{1}{x \sin(x)} - \frac{1}{x^2} \right] \mathrm{d} x \approx 0.29172334953491321 \, .$$ I have not found a closed-form expression yet and inverse symbolic calculators do not give any results either. However, a few other representations for $I$ can be derived using the following methods: Laurent series The Laurent series of the cosecant function is given by $$\csc(x) = \frac{1}{x} + \sum \limits_{k=1}^\infty \frac{\lvert \mathrm{B}_{2k}\rvert (4^k - 2)}{(2k)!} x^{2k-1}$$ in terms of the Bernoulli numbers $(\mathrm{B}_n)_{n \in \mathbb{N}_0}$ and has radius of convergence $\pi$ , so we can integrate termwise to obtain $$ \tag{1} I = \sum \limits_{k=1}^\infty \frac{\lvert \mathrm{B}_{2k}\rvert  \left[2-4^{-(k-1)}\right] \pi^{2k-1}}{(2k-1)(2k)!} \, .$$ Pole expansion The series $$ \csc(x) = \frac{1}{x} + 2 x \sum \limits_{n=1}^\infty \frac{(-1)^{n-1}}{\pi^2 n^2 - x^2}$$ yields $$\tag{2} I = \frac{1}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1}}{n} \ln\left(\frac{2n+1}{2n-1}\right) \, .$$ Expanding the logarithm only leads to $$ \tag{3} I = \frac{1}{\pi} \sum \limits_{k=1}^\infty \frac{\eta(2k)}{(2k-1) 4^{k-1}} \, ,$$ which reduces to $(1)$ when the special values of the eta functions are used. Summation by parts turns $(2)$ into
$$ \tag{4} I =  \frac{4}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1} (2n+1) \ln(2n+1)}{(2n+1)^2 -1} \, . $$
This can also be written as
$$ \tag{5} I = \frac{4}{\pi} \beta'(1) + \frac{1}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1} \ln(2n+1)}{2n^3+3n^2+n} \, ,$$
where $\beta$ is the Dirichlet beta function (there is a reasonably nice expression for $\beta'(1)$). Integration by parts There are several possible ways to integrate by parts. One of them shows that $$ \tag{6} I = \frac{2}{\pi} \ln \left(\frac{4}{\pi}\right) + \frac{1}{2} \int \limits_0^{\pi/4} \frac{\ln[\tan(t)/t]}{t^2} \, \mathrm{d} t $$ holds. I am not sure how to proceed from here though. Plugging in the Maclaurin series of $\ln[\tan(t)/t]$ reproduces $(1)$ . Contour integration (due to eyeballfrog) As demonstrated in eyeballfrog's answer we also have $$ \tag{7} I = \frac{2}{\pi} - \int \limits_0^\infty \frac{t}{1+t^2} \, \operatorname{sech}\left(\frac{\pi}{2} t\right) \, \mathrm{d} t \, .$$ Using the pole expansion of $\operatorname{sech}$ yields $(4)$ again. That is all I have at the moment, so my question is: Is it possible to find a closed-form expression for the value of $I$ or can we at least rewrite any of the integral or series representation in terms of a suitable special function?","['integration', 'calculus', 'definite-integrals', 'sequences-and-series']"
2886238,Why $\sum_{k=1}^m \left(\cos{\frac{2\pi k}{2m+1}}\right)^{(2m+1)^2}$ converges to $\sum_{k=1}^\infty e^{-2\pi^2k^2}$?,"While I was considering random walk on $S^1$, I needed to compute the following. $$\lim_{m\rightarrow\infty}\sum_{k=1}^m \left(\cos{\frac{2\pi k}{2m+1}}\right)^{(2m+1)^2}$$ I guessed it should converges to trace of heat kernel on $S^1$. So I tried to use Mathematica. Mathematica says, it converges to following series: $$\sum_{k=1}^\infty e^{-2\pi^2k^2}$$ But how can we prove this is true? of course, proving
$$\lim_{m\rightarrow\infty}\left(\cos{\frac{2\pi k}{2m+1}}\right)^{(2m+1)^2}=e^{-2\pi^2k^2}$$
is easy for each fixed $k$ (one can apply l'hospital rule or use taylor expansion). But I don't know how to show
$$\lim_{m\rightarrow\infty}\sum_{k=1}^m \left(\cos{\frac{2\pi k}{2m+1}}\right)^{(2m+1)^2}=\sum_{k=1}^\infty e^{-2\pi^2k^2}$$. -Generalized version of above question is the following one: suppose a doubly indexed sequence $\{a_{mk}\}_{m\in\mathbb{N},1\leq k\leq m}$ and a sequence $\{b_k\}_{k=1}^\infty$ satisfy following two conditions: (1) $\lim_{m\rightarrow\infty}a_{mk}=b_k$ for each positive integer $k$. (2) $\sum_{k=1}^\infty b_k$ converges. Then, can we conclude $\lim_{m\rightarrow\infty}\sum_{k=1}^m a_{mk}=\sum_{k=1}^\infty b_k$? In general it is not true (consider $a_{mk}=b_k+m^{-1/2}$). To make the limit true, what kinds of additional assumptions do we need? Maybe there is some known result about this general question?","['analysis', 'sequences-and-series']"
2886251,Does recursively replacing $\frac1n$ by $\frac1n(\frac12+\dots+\frac1{n+1})$ really converge to $\frac1e$?,"I was thinking of a problem and have an answer through computer programming, but am unable to prove it mathematically. Start with the following: 
$$\frac{1}{2}\bigg(\frac{1}{2} + \frac{1}{3}\bigg)\approx 0.41666$$ 
Replace every unit fraction being summed in the parentheses (in this case, the inner 1/2 and 1/3) with 
$$\frac{1}{n}\bigg(\frac{1}{2} + \frac{1}{3} + ... + \frac{1}{n+1}\bigg)$$
where $n$ is the denominator of the unit fraction. If we apply this process once, we get
$$\frac{1}{2}\bigg(\frac{1}{2}\bigg(\frac{1}{2} + \frac{1}{3}\bigg)+\frac{1}{3}\bigg(\frac{1}{2} + \frac{1}{3}+\frac{1}{4}\bigg)\bigg)\approx 0.3888$$
and if we apply it again, we get
$$\frac{1}{2}\bigg(\frac{1}{2}\bigg(\frac{1}{2}\bigg(\frac{1}{2} + \frac{1}{3}\bigg) + \frac{1}{3}\bigg(\frac{1}{2} + \frac{1}{3}+ \frac{1}{4}\bigg)\bigg)+\frac{1}{3}\bigg(\frac{1}{2}\bigg(\frac{1}{2} + \frac{1}{3}\bigg) + \frac{1}{3}\bigg(\frac{1}{2} + \frac{1}{3}+ \frac{1}{4}\bigg)+\frac{1}{4}\bigg(\frac{1}{2} + \frac{1}{3}+ \frac{1}{4}+ \frac{1}{5}\bigg)\bigg)\bigg)\approx 0.37754$$ As we repeat this process, the result seems to approach $e^{-1}$. If anyone could prove this or direct me to a proof of this, that would be wonderful!","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
2886259,"If $|A \cup B \cup C | = |A| + |B| + |C|$, then $A, B$, and $C$ must be pairwise disjoint","Let A, B, and C be finite sets. Prove or disprove: If $|A \cup B \cup C | = |A| + |B| + |C|$ , then $A, B$ , and $C$ must be pairwise disjoint. I started with inclusion-exclusion formula $$|A \cup B \cup C | = |A| + |B| + |C| - |A \cap B| - |A \cap C| - |B \cap C| + |A \cap B \cap C|$$ Hypothesis says if $|A \cup B \cup C | = |A| + |B| + |C|$ , then expression $|A \cap B \cap C|  - |A \cap B| - |A \cap C| - |B \cap C| $ , must be equal to zero. So, we have $$ |A \cap B \cap C|  - |A \cap B| - |A \cap C| - |B \cap C|  = 0$$ $$ |A \cap B \cap C|  = |A \cap B| + |A \cap C| + |B \cap C| \tag{1}$$ Now, I am not sure how finish this proof. I found two ways, but I do not know if are correct. First way If $x \in |A \cap B \cap C|$ , then $x \in |A \cap B| \wedge x\in |A \cap C| \wedge x \in |B \cap C|$ . So if we count the cardinality of $|A \cap B \cap C|  = |A \cap B| + |A \cap C| + |B \cap C|$ , then if $x \in |A \cap B \cap C|$ then $x$ is counted once but on RHS $x$ is counted three times. Thus the equation is true if $A = B = C = \emptyset$ . Therefore $A, B,$ and $C$ are pairwise disjoint. Second way From inclusion-exclusion formula, I know $$|A \cap B \cap C| = - |A| - |B| - |C| + |A \cap B| + |A \cap C| + |B \cap C| - |A \cup B \cup C |$$ I substitute in equation (1) $$ -|A| - |B| - |C| + |A \cap B| + |A \cap C| + |B \cap C| - |A \cup B \cup C | = |A \cap B| + |A \cap C| + |B \cap C|$$ The expression $|A \cap B| + |A \cap C| + |B \cap C|$ cancels out. $$ |A| + |B| + |C| + |A \cup B \cup C | = 0$$ And this equation is true if $A = B = C = \emptyset$ . Therefore $A, B,$ and $C$ are pairwise disjoint. My question is which way is correct and better or if there is a different method to prove the proposition. Thank you. (I am self-studying student, who is reading a  textbook about discrete mathematics).","['elementary-set-theory', 'discrete-mathematics']"
2886288,Calculate probability of an infinite geometric series,"Suppose in a single round, I win with probability p, and you win with probability
  1 − p. We play repeatedly and keep score until one of us is two ahead (for example
  a score of 2 − 0, 3 − 1, 2 − 4, etc.). What is the probability that I win overall? I have been working through this probability problem. But I am not sure if my method is the most efficient or even may not be even correct and was wondering if someone could advise if I am carrying this out correctly, and if there more effective way of approaching this type of question? My method for calculation If I have understood the above question correctly, the only way to win is if you I am 2 ahead? So one way I could win two time in a row would if I have a probability of $p^2$. But if I get a $p$ then a $q$ or the other persons throws and $q$ then $p$ we have drawn, so to me this is like starting again i.e $0-0$ again so for me two win now I would need the following $pqpp=p^3 q$ or if I draw again then I would need to win the following $pqpqpp=p^4 q^2$ and so fourth. As probabilities are independent (each future try is not effected by the previous) then I can add the following probabilities to find my overall chance of winning. $P(Over \:all \:win)=p^2+p^3q+p^4q^2+.....=p^2+p^3(1-p)+p^3(1-p)^2+....$ so now using the infite geometric sum $S=\frac{p^2}{1-p(1-p)}=\frac{p^2}{1-p+p^2}$. So my probability for winning over all is: $$P(Over \:all \:win)=\frac{p^2}{1-p+p^2}$$ I am bit rusty with probability as it something I don’t do too often. But as mentioned is there more efficient way of approaching this type of question, as I was thinking of extending this question and exploring if I had to be 3 ahead what would the over all win be.","['statistics', 'probability']"
2886308,Double Cover Map of Hyperelliptic Curve is Unique,"On page 204 of Rick Miranda's Algebraic Curves and Riemann Surfaces, he talks about how the canonical map of a hyperelliptic curve is the double cover map composed with the Veronese map $\phi(x) = [1:x:\cdots:x^{g-1}]$. Then, he says: the double covering map for a hyperelliptic curve of genus $g\ge 2$ is unique since is it the canonical map after all. I don't understand what is meant by unique and how this follows from the discussion.","['algebraic-curves', 'complex-geometry', 'algebraic-geometry', 'riemann-surfaces']"
2886319,Angle between two 'small circles' on the surface of a sphere,"This seems like it should be fairly simple, but it has me completely stumped. Imagine I have a latitude line at angle $\theta_1$ on the surface of the unit sphere in 3D. This is a ""small circle"", meaning it's a circle that's not a great circle. Now suppose I have, in addition, a second coordinate system where the axis is at an angle $\phi$ to the original axis, and a second latitude line at an angle $\theta_2$ in the new coordinate system: If these two curves cross, they do so at two points. I want to know the angle they make on the surface of the sphere. That is, the angle between the vectors tangent to the two circles at a point where they cross: What is this angle $\psi$, as a function of $\phi$, $\theta_1$ and $\theta_2$?","['euclidean-geometry', 'spherical-coordinates', 'geometry', 'spherical-geometry']"
2886392,Product of binary matrices with binary eigenvalues,"Consider two binary matrices with obvious patterns: $$
C=
\begin{bmatrix}
1 &0 &0 &0 &0 &0 &0\\
1 &0 &0 &0 &0 &0 &0\\
0 &1 &0 &0 &0 &0 &0\\
0 &1 &0 &0 &0 &0 &0\\
0 &0 &1 &0 &0 &0 &0\\
0 &0 &1 &0 &0 &0 &0\\
0 &0 &0 &1 &0 &0 &0
\end{bmatrix}
$$ and $$
T=
\begin{bmatrix}
1 &1 &0 &0 &0 &0 &0\\
0 &1 &1 &0 &0 &0 &0\\
0 &0 &1 &1 &0 &0 &0\\
0 &0 &0 &1 &1 &0 &0\\
0 &0 &0 &0 &1 &1 &0\\
0 &0 &0 &0 &0 &1 &1\\
0 &0 &0 &0 &0 &0 &1
\end{bmatrix}
$$ The eigenvalues of the matrices $T^n C,n=0,1,2,3$ are zeros and consecutive powers of $2$ equal to $0,1,2,4$ . I'd like to have a proof of the generalization of this fact for matrices of larger size with the same patterns. Note, the entries of $T^n C$ in the left upper corner are zeros and binomial coefficients for the power $n+1$ . A motivation for this question is in Binary eigenvalues matrices and continued fractions","['matrices', 'binary', 'binomial-coefficients', 'eigenvalues-eigenvectors']"
2886403,Solutions of a differential equation,"I'm trying to solve the following differential equation and I'm stuck at what it appears to be simple calculations. I'm terribly sorry if this turns out to be really simple. $(1)$ $X(f)=2f$ where $X=x_1^2 \frac \partial {\partial x_1}-x_2^2 \frac \partial {\partial x_2}$ in $\Bbb R^2$ with the identity chart $Id_{\Bbb R^2}=(x_1,x_2)$ and $f:\Bbb R^2 \to \Bbb R$, $(2)$ $f(cosθ,sinθ)=cosθ+sinθ$. Let $φ^Χ_t(p)=(\frac {x}{1-tx},\frac {y}{1+ty})$, where $p=(x,y)$, be the flow of $Χ$ and by denoting $h(t)=f(φ^Χ_t(p))$ we can make $(1)$ look like $h'(t)=2h(t)$ which can be easily solved to: $e^{2t}f(x,y)=f(\frac {x}{1-tx},\frac {y}{1+ty})$ Then by use of the initial condition $(2)$ we have $e^{2t}(cosθ+sinθ)=f(\frac {cosθ}{1-tcosθ},\frac {sinθ}{1+tsinθ})$ (this is as far as I can go) I tried setting $u = \frac {cosθ}{1-tcosθ}, v=\frac {sinθ}{1+tsinθ} $
but I haven't been able to isolate $u,v$ from $θ, t$ Can you give me any hints? Is there any trick I'm not thinking of?","['trigonometry', 'partial-differential-equations', 'ordinary-differential-equations', 'differential-geometry']"
2886416,Proving radius of circle $\dfrac{\triangle}{a}\tan^2\dfrac{A}{2}$,"If a circle be drawn touching the inscribed and circumscribed circles of a $\triangle ABC$ and the side $BC$ externally, prove that its radius is: $$r=\dfrac{\triangle}{a}\tan^2\dfrac{A}{2}$$ I tried using triangle formed by circumcenter, incenter and center of above circle as I know all the sides in terms of $r$ to use cosine rule but I don't know any angles. Please help!","['tangent-line', 'circles', 'geometry', 'triangles', 'trigonometry']"
2886422,Proving divisibility by $3$,"For all integers $a$, there exists an integer $b$ so that $3 | a + b$ and $3 | 2a + b$. So far I have been able to find an integer $b$ that satisfies both of them separately, but not at the same time. (For the first one I have $b = 6-a$, and for the second I've found $12-2a$)",['discrete-mathematics']
2886441,Computation of multiple improper integral.,"In my recent work, I need to the details of the computation of the following multiple improper integral:
$$\iint_{[0,1]^2}e^{-\pi x^2y^2}dxdy-\iint_{[1,\infty)^2}e^{-\pi x^2y^2}dxdy.$$
As you see, the first one is a proper integral and the second one is improper integral. It is easy to know the convergence of the second one. At the beginning, I just use Wolfram mathematica 9.0 to get the finally result:
$$\frac{1}{4}(\gamma+\log(4\pi)),$$ 
where $\gamma$ is a Euler-Gamma constant.
But now I need to give the details of the computation.
The wolfram mathematica tells us that:
$$\iint_{[0,1]^2}e^{-\pi x^2y^2}dxdy=HypergeometricPFQ[(1/2,1/2);(3/2,3/2);-\pi];$$
$$\iint_{[1,\infty)^2}e^{-\pi x^2y^2}dxdy
=HypergeometricPFQ[(1/2,1/2);(3/2,3/2)-\frac{1}{4}(\gamma+\log(4\pi)).$$
I do not know how to get the hyperbolic geometric function and  how to cancel it. 
Any help and hints will welcome. Thanks a lot.","['multivariable-calculus', 'improper-integrals', 'hypergeometric-function']"
2886447,Evaluating a seemingly simple integral,"I'm trying to evaluate the following integral, which arised while attempting to find the sum of a series :
$$\int_{0}^{1} \frac{\ln(x)}{x-1} \ln(1+\sqrt{x})\text{d}x$$ I've tried unsuccessfully some substitutions, integration by parts, feynman integration... I'm not familiar with more advanced integration techniques like residues theorem etc. ,so maybe that's the way to go. 
Any hint, solution or partial solution would be nice !",['integration']
2886460,Roots of unity and large expression,"Let $\omega$ be a complex number such that $\omega^5 = 1$ and $\omega \neq 1$. Find
  $$\frac{\omega}{1 + \omega^2} + \frac{\omega^2}{1 + \omega^4} + \frac{\omega^3}{1 + \omega} + \frac{\omega^4}{1 + \omega^3}.$$ I have tried combining the first and third terms & first and last terms. Here is what I have so far: \begin{align*}
\frac{\omega}{1 + \omega^2} + \frac{\omega^2}{1 + \omega^4} + \frac{\omega^3}{1 + \omega} + \frac{\omega^4}{1 + \omega^3} 
&= \frac{\omega}{1 + \omega^2} + \frac{\omega^4}{1 + \omega^3} + \frac{\omega^2}{1 + \omega^4} + \frac{\omega^3}{1 + \omega} \\ 
&= \dfrac{\omega(1+\omega^3) + \omega^4(1+\omega^2)}{(1+\omega^2)(1+\omega^3)} + \dfrac{\omega^2(1+\omega) + \omega^3(1+\omega^4)}{(1+\omega^4)(1+\omega)} \\
&= \dfrac{\omega + 2\omega^4 +\omega^6}{1+\omega^2 + \omega^3 + \omega^5} + \dfrac{\omega^2 + 2\omega^3 + \omega^7}{1+\omega + \omega^4 + \omega^5} \\
&= \dfrac{2\omega + 2\omega^4}{2+\omega^2 + \omega^3} + 
   \dfrac{2\omega^2 + 2\omega^3}{2+\omega+\omega^4}
\end{align*} OR \begin{align*}
\frac{\omega}{1 + \omega^2} + \frac{\omega^2}{1 + \omega^4} + \frac{\omega^3}{1 + \omega} + \frac{\omega^4}{1 + \omega^3} 
&= \frac{\omega}{1 + \omega^2} + \frac{\omega^3}{1 + \omega} + \frac{\omega^4}{1 + \omega^3} + \frac{\omega^2}{1 + \omega^4} \\
&= \dfrac{\omega(1+\omega) + \omega^3(1+\omega^2)}{(1+\omega)(1+\omega^2)} + \dfrac{\omega^2(1+\omega^3) + \omega^4(1+\omega^4)}{(1+\omega^3)(1+\omega^4)} \\
&= \dfrac{\omega + \omega^2 + \omega^3 + \omega^5}{1+\omega + \omega^2 + \omega^3} + \dfrac{\omega^2 + \omega^4 + \omega^5 + \omega^8}{1 + \omega^3 + \omega^4 + \omega^7} \\
&= \dfrac{2\omega+\omega^2+\omega^3}{1+\omega+\omega^2+\omega^4} + \dfrac{1+\omega+\omega^2+\omega^4}{1+2\omega^3+\omega^4}
\end{align*}","['algebra-precalculus', 'roots-of-unity', 'complex-numbers']"
2886515,$dy/dx=\sqrt{x^2+y^2}$,"$$\frac{dy}{dx}=\sqrt{x^2+y^2}$$ slope=distance from origin, should be simple and interesting. May have no solution! I have tried several approaches, best : $(\frac{dy}{dx}-y)(\frac{dy}{dx}+y)=x^2$  multiply by $e(-x) * e(+x)$ as integrating factor. Substitute $\frac{1}{2}x^2=t$. Second approach: $y=x\sinh(u)$ and $x=e(t)$ yields $\frac{du}{dt} + \tanh(u)=e(t)$. Sorry, I am not yet using the proper format.",['ordinary-differential-equations']
2886545,Find the oblique asymptote of $\sqrt{x^2+3x}$ for $x\rightarrow-\infty$,I want to find the asymptote oblique of the following function for $x\rightarrow\pm\infty$ $$f(x)=\sqrt{x^2+3x}=\sqrt{x^2\left(1+\frac{3x}{x^2}\right)}\sim\sqrt{x^2}=|x|$$ For $x\rightarrow+\infty$ we have: $$\frac{f(x)}{x}\sim\frac{|x|}{x}=\frac{x}{x}=1$$ which means that the function grows linearly. $$f(x)-mx=\sqrt{x^2+3x}-x=x\left(\sqrt{\frac{x^2}{x^2}+\frac{3x}{x^2}}-1\right)\sim x\left(\frac {1}{2}\cdot\frac{3}{x}\right)=\frac{3}{2}$$ The oblique asymptote is $y=x+\frac 3 2$ which is correct. For $x\rightarrow-\infty$ we have: $$\frac{f(x)}{x}=\frac{|x|}{x}=\frac{-x}{x}=-1$$ This means that $$f(x)-mx=\sqrt{x^2+3x}+x=x\left(\sqrt{\frac{x^2}{x^2}+\frac{3x}{x^2}}+1\right)=x\left(\sqrt{1+\frac{3}{x}}+1\right)\sim x\cdot2\rightarrow -\infty$$ Which is not what my textbook reports ($-\frac{3}{2}$). Any hints on what I did wrong to find the $q$ for $x\rightarrow-\infty$?,"['limits', 'asymptotics']"
2886566,find the maximum of the value $c$ such $ \{ a^2 \} + \{ b^2 \} \leqslant 2 - \frac{c}{(a + b)^2} $ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Suppose that $a, b$ are postive numbers and $a + b \in \mathbb{Z} {}_+$. Find the maximal constant $c$, s.t.
$$ \{ a^2 \} + \{ b^2 \} \leqslant 2 - \frac{c}{(a + b)^2} $$
for all $a, b$. Here $\{ x \}$ is the fractional part of $x$. It is said the $c=\dfrac{3}{4}$ is best, but I don't see why.","['contest-math', 'number-theory']"
2886623,Tensor norms on infinite Banach space,"Given two Banach spaces $V$ and $W$ and its tensor product $V \otimes W$.In Ryan's book ""Introduction into Tensor product of Banach space"", he said that it is natural to choose a norm for elementary tensors as $$\|v \otimes w\|_{V\otimes W} \leqslant \|v \|_{V}\| w \|_W$$ Now I don't understand why it is natural to require the above-mentioned inequality for a tensor norm?","['linear-algebra', 'tensor-products']"
2886631,Is there a smarter way to differentiate the function $f(x) = \sin^{-1} \frac{2x}{1+x^2}$?,"Given $f(x) = \sin^{-1} \frac{2x}{1+x^2}$ , Prove that $$f'(x) = \begin{cases}\phantom{-}\frac{2}{1+x^2},\,|x|<1 \\\\ -\frac{2}{1+x^2},\,|x|>1 \end{cases}$$ Obviously the standard approach would be to use the chain rule and simplify from there. But I noticed that some of these expressions are familiar, specifically, from the tangent half-angle formulae: If $x = \tan \frac \theta 2$ , then $\sin \theta = \frac{2x}{1+x^2}$ and $\frac{d\theta}{dx} = \frac{2}{1+x^2}$ . So my question is: can this observation be used to construct a more elegant proof?","['calculus', 'derivatives']"
2886636,Why is outer measure called outer?,"Why is outer measure called outer? http://mathworld.wolfram.com/OuterMeasure.html Is it because the $\inf$ in $$\mu^* (E)=\inf \sum_{i=1}^{\infty} \mu(E_k)$$ Takes the smallest bound for all the measures? So in that sense it can be thought to give the ""(outer) bound"" for the measures?",['measure-theory']
2886638,Is there an easier way to find the order of all the elements of group $(\mathbb{Z}/16 \mathbb{Z})^{\times}$?,"I have the multiplicative group of integers modulo 16, $G = (\mathbb{Z}/16 \mathbb{Z})^{\times}$ I know that is has the elements ${1,3,5,7,9,11,13,15}$ , as these are the only numbers that are relatively prime to $16$ . So it has order $8$ . Using Lagrange's Theorem I only have to check the orders $1,2,4,8$ for each element, as these are the only possible orders the elements can have. This however is still a cumbersome process to do for every single element. Is there an easier way?",['group-theory']
2886652,calculating a higher order derivative,"My task is to find the values $f^{(2017)}(0)$ and $f^{(2018)}(0)$ for $f(x)=\frac{\arccos(x)}{\sqrt{1-x^2}}$ . Basically, it's about finding the $n^{th}$ derivative of $f$ .
So I noticed if I let $g(x)=arccos(x)$ , then $f(x)=-g(x)\cdot g'(x)$ . I was able to prove by induction that for all $n\geq 2$ and $k\in \Bbb{N}$ the $n^{th}$ derivative of $g'$ is $$[(g')^{k}]^{(n)}(0)=k\cdot(n-1)\cdot[(g')^{k+2}]^{(n-2)}(0)$$ But even with applying the Leibniz rule to $f=g\cdot g'$ I don't understand how to get the final result. Did I make the wrong approach to the problem or is the general formula above useful? If so, how should I apply it?","['calculus', 'derivatives']"
2886749,Circular Definition of Experiment in probability,"I was trying to understand what an experiment was in the theory of probability. I found several definitions. Definition by Wikipedia Any procedure that can be infinitely repeated and whose outcomes are well-defined. Standard Definition An experiment is a probability space $(\Omega, \Sigma, \mathbb{P})$ Issue with the definitions So my understanding is that an experiment is used to define what a sample space is and what its outcomes are. From this we can define events and the event space. From these we can define a probability measure and therefore define the triplet $(\Omega, \Sigma, \mathbb{P})$ to be a probability space. Therefore a probability space is defined starting from an experiment. But an experiment is defined starting from a probability space. This is a circular definition! Possible solution to the issue My guess is that the correct definition of an experiment is Any procedure that can be infinitely repeated and whose outcomes are well-defined. Or maybe the one given by Grimmett & Welsh: Any procedure whose consequence is not predetermined. But surely not the one with the probability space. Rather, I would say that an experiment is represented by a probability space, but not defined from it! Is this correct? Or do we allow circular definitions?","['statistics', 'definition', 'probability-theory', 'probability']"
2886753,Limit of the Product $\prod_{k=1}^n\left(\frac{2k-1}{2k}\right)$ [duplicate],"This question already has answers here : Evaluate $\prod \frac {2k - 1} {2k}$ [duplicate] (2 answers) Closed 5 years ago . I know I can transform the above product as follows \begin{eqnarray*}\lim_{n\rightarrow\infty}\left(\frac{1}{2}\frac{3}{4}\frac{5}{6}...\frac{2n-1}{2n}\right)&=&\lim_{n\rightarrow\infty}\prod_{k=1}^n\left(\frac{2k-1}{2k}\right)\\&=&\lim_{n\rightarrow\infty}\prod_{k=1}^n\left(1-\frac{1}{2k}\right)\\&=&\lim_{n\rightarrow\infty}\prod_{k=1}^n\left(1+\frac{-1/2}{k}\right)
\end{eqnarray*} My thoughts are this is going to go to $e^{-x/2}$, but I can't figure out how to go from $$\lim_{n\rightarrow\infty}\prod_{k=1}^n\left(1+\frac{-1/2}{k}\right)$$ to $$\lim_{n\rightarrow\infty}\left(1+\frac{-1/2}{n}\right)^n$$","['limits', 'calculus']"
