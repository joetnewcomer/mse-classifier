question_id,title,body,tags
1372996,Under what condition can converge in $L^1$ imply converge a.e.?,"Let $f_n$ be a sequence of Lebesgue measurable functions on $R^d$. Suppose you have an estimate of the form $\int_{R^d}\left|f_n\right|\le c_n$ where $c_n \downarrow 0$. Can you conclude that $f_n\to 0$ a.e.? If not, what additional conditions on ${c_n}$ would guarantee this? My attempt:
I think we cannot conclude that $f_n\to 0$ a.e. For example $A_1=[0,1/2]$, $A_2=[1/2,1]$, $A_3=[0,1/4],\ldots,A_6=[3/4,1]$, $A_7=[0,1/8],\ldots$.
If $f_n$ is the indicator function of $A_n$, that is $f_n(x)=1$ if $x\in A_n$ and $f_n(x)=0$ else, then $f_n \to 0$ in all $L^p([0,1])$ because $\|f_n\|_p=\lambda(A_n)^{1/p}\to 0$ but there is no $x\in [0,1]$ with $f_n(x)\to 0$. I have question in what additional conditions on ${c_n}$ would guarantee this? Maybe $c_n$ strictly decreasing? However, I have trouble proving this. Could someone kindly help about this? Thanks!","['measure-theory', 'almost-everywhere', 'real-analysis', 'convergence-divergence', 'lebesgue-integral']"
1373016,"Prove that ${\{f_n\}}_{n\in\Bbb{N}}$ has a subsequence that converges uniformly to a continuous function on $[0,1]$","Consider the sequence ${\{f_n\}}_{n\in\Bbb{N}}$, where for each $n\in \Bbb{N}$ the function $f_n:[0,1] \to \Bbb{R}$ is absolutely continuous and satisfies $f_n(0)=13$ and $$\int_{[0,1]}|f_n'|^4dx \le 7$$ The integration is Lebesgue integration. Prove that ${\{f_n\}}_{n\in\Bbb{N}}$ has a subsequence that converges uniformly to a continuous function on $[0,1]$. If $f_n$ is absolutely continuous, then $f_n$ is of bounded variation and $f_n=\int|f'_n|dx$. That is all I can think about now. Then I have no clue what to do next about this question. Could someone provide some help?","['real-analysis', 'functional-analysis']"
1373045,Proof: $\mathbb{Z}[\zeta_6]$ is a PID.,"I am reading through A First Course in Modular Forms . In Proposition 2.2.3 they claim that $\mathbb{Z}[\zeta_6]$ is known to be a principal ideal domain. Does anyone have a reference for the proof of this fact? If the proof is simple enough, perhaps you could sketch it below.","['abstract-algebra', 'reference-request', 'principal-ideal-domains']"
1373067,How to solve this DE?,"Consider the ordinary differential equation
$$y''=xyy'$$
I'm pretty stumped, so any tips on how to proceed? It seems fairly simple but I'm drawing a blank.",['ordinary-differential-equations']
1373084,"""composition"" of ""pointwise convergent sequences of functions""","Intuitively, if $f_n\to f$ as $n\to\infty$ and $g^{(n)}_i\to f_n$ as $i\to\infty$, can we get $g_j\to f$ as $j\to\infty$? Formally, Let $\{f_n\}_n$ be a sequence of functions from $\mathbb{R}^d$ to
  $\overline{\mathbb{R}}$, the extended real line. Let $f$ be its
  pointwise limit, i.e. for each $x\in\mathbb{R}^d$ and each
  $\varepsilon>0$, there exists $N\in\mathbb{Z}^+$ such that
  $|f_n(x)-f(x)|<\varepsilon$ for all $n\geq N$. Each $f_n$ is the
  pointwise limit of sequence $\{g^{(n)}_i\}_i$. Can we construct a
  sequence of $g$'s converging pointwise to $f$? If not, what additional
  conditions do we need? As usual, any help is appreciated:)","['analysis', 'real-analysis']"
1373093,Mathematical induction inequality involving sines,"Let $0<A_i<\pi$ for $i=1,2,3,\ldots,n$. Use mathematical induction to prove that $$\sin A_1+\sin A_2+\cdots+\sin A_n\le n \sin\left(\frac{A_1+A_2+A_3+\cdots+A_n} n\right)$$ where $n\ge 1$ is a natural number.` The inequality holds true for $n=1$. I assumed that it holds true for $n=k$. But I was unable to prove that it holds true for $n=k+1$. Please help me.","['inequality', 'induction', 'trigonometry']"
1373097,Why does minimizing $H[f] =\sum^{N}_{i=1}(y_i-f(x_i))^2+\lambda \| Pf \|^2 $ leads to solution of the form $ f(x) =\sum^N_{i=1}c_iG(x; x_i)+p(x)$?,"I was reading the following paper of dimensionality reduction (1) and also one on theory of networks for approximations and learning (2) and was trying to understand how the regularization problem leads to the form of the predictor function $f$. In other words, I was trying to fully understand the details of how if one tries to minimize the functional: $$ H[f] = \sum^{N}_{i=1} (y_i - f(x_i))^2 + \lambda \| Pf \|^2 $$ why the solution of the variational problem has the following simple form: $$ f(x) = \sum^N_{i=1} c_i G(x ; x_i) + p(x)$$ where $G(x)$ is the Green's function of the self-adjoint differential operator $\hat{P}P$, $\hat{P}$ being the adjoint operator of P, $p(x)$ is a linear combination of functions that span the null space of $P$, and the coefficients $c_i$ satisfy a linear system of equations that depend on the $N$ ""examples"", i.e. the data to be approximated. Why is it that that it has to be a linear combination of the Green's function? Why does the Green's function matter in this case? I think they try to explain try to explain it on the second paper (2) but I didn't really understand the details. If someone understood the details better, I would be extremely grateful if they would explain it to me. To understand this I was going through the following videos: https://www.youtube.com/watch?v=4U3P0LcaJcw&index=27&list=PL4C6F6B595A5852E8 https://www.youtube.com/watch?v=6n0uINcvx_E&index=28&list=PL4C6F6B595A5852E8 https://www.youtube.com/watch?v=cE4ZWo3pcCk&index=29&list=PL4C6F6B595A5852E8 I think they explain it there too but I was having some issue understanding everything. I am still in the process of going through these videos but I will add additional details as they come up through the derivation.","['machine-learning', 'optimization', 'calculus-of-variations', 'functional-analysis']"
1373117,Help understanding Rudin's proof showing that $C_c(X)$ is dense in $L^p(\mu)$,"The proof is from Rudin's ""Real and Complex Analysis."" It states For $1\leq p<\infty$, $C_c(X)$ is dense in $L^p(\mu)$ The proof is Let $S$ be the class of all complex, measurable, simple functions on $X$ such that $\mu(\{x:s(x)\neq 0\})<\infty$. If $s\in S$ and $\epsilon<0$, there exists a $g\in C_c(X)$ such that $g(x)=s(x)$ except on a set of measure $<\epsilon$ and $\vert g\vert\leq\,\parallel s\,\parallel_{\infty}$ (Lusin's Theorem). Hence $$\parallel g-s\parallel_p\leq 2\epsilon^{1/p}\parallel s\,\parallel_{\infty}$$
  Since $S$ is dense in $L^p(\mu)$, this completes the proof. I have trouble understanding the inequalities $$\vert g\vert\leq\,\parallel s\,\parallel_{\infty}\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,(1)$$$$\parallel g-s\parallel_p\leq 2\epsilon^{1/p}\parallel s\,\parallel_{\infty}\,\,\,\,\,\,\,\,\,\,\,(2)$$
I know that the first inequality is supposed to follow from Lusin's Theorem, which in this case would result in $$\sup_{x\in X}\vert g(x)\vert\leq\sup_{x\in X}\vert s(x)\vert$$
However, I am not sure how to get to $(1)$ from here. Lastly, I don't understand how to get inequality $(2)$. Added: I forgot to mention that $X$ is supposed to be a locally compact Hausdorff space and that $\mu$ is a measure on a $\sigma$-algebra $\mathfrak M$ in $X$ with the properties of the measure of Riesz's Representation Theorem.","['real-analysis', 'functional-analysis']"
1373143,"Showing that $\mathbb S^1$ is a deformation retract of the Mobius strip, rigorously.","Intuitively, I can see why this is. I've found a few threads about this, but they only provide, for example, a deformation retraction of $I \times I$ to its diagonal $D = \{ (x,x) \in I \times I \}$, with no further explanation. It's not clear to me exactly how to prove that this yields a deformation retract of $M$ the mobius strip, so that's what I'd like to clarify here. Let $q$ be the quotient: $I \times I$ $\rightarrow$ $M$. It seems like there are three steps required Show that $\mathbb S^1$ is a subspace of $M$. Find some continuous $r:M\rightarrow \mathbb S^1$, a retraction of $M$. Find a homotopy from $id_M$ to $i \circ r$, where $i$ is the inclusion: $\mathbb S^1 \rightarrow M$ Here's how I think it can be done. Each bullet below corresponds to a bullet above. First, define $f: I \rightarrow D$ by $f(x) = (x,x)$. Then $q\circ f:I\rightarrow M$ makes the same identifications as the quotient $\omega:I\rightarrow\mathbb S^1, \omega = exp(2\pi ix$), so $q(f(I))=q(D)$ is homeomorphic to $\mathbb S^1$. So $\mathbb S^1$ is a subspace of $M$. Second, define $g:I \times I$ $\rightarrow D, (x,y)\mapsto(x,x)$. Then $r=q\circ g:$ $I \times I$ $\rightarrow \mathbb S^1$ is constant on fibers of $q$, so it descends to the quotient to give a continuous map $M\rightarrow \mathbb S^1$. So $\mathbb S^1$ is a retract of $M$. Finally, define the homotopy $H:I^3\rightarrow I^2$ by $(x,y,t)\mapsto (x,y)*(1-t) + (x,x)*t$. This is the homotopy showing that $g$ is a deformation retraction. Define the composite map $q\circ H: I^3\rightarrow M$. Note that $q(H(0,y,t))=q(0, y*(1-t))=q(1, 1-y*(1-t))=q(H(1,1-y,t))$. Since this is constant on fibers of the map $q\times id:I^2 \times I \rightarrow M \times I$, it descends to the quotient, and there is a continuous map $F: M \times I \rightarrow M$ such that $F(m,0) = id_M$ and $F(m,1)$ = $q(D) \approx \mathbb S^1$, so this is the desired homotopy.","['mobius-band', 'general-topology', 'quotient-spaces', 'compact-manifolds', 'homotopy-theory']"
1373150,How can I tell that my matrix is nilpotent?,"I just computed a 15x15 matrix by hand :( It is not upper triangular as I hoped it would be.  But my computations agree with what's offered in the student solution. My question is:  the solution then says ""this matrix is nilpotent, so all the eigenvalues are zero."" I get the part where the spectrum = {0} i.f.f. the operator is nilpotent, but how can I tell it actually is nilpotent, just by observing the matrix that I got? EDIT: Here is my computation of the matrix: The vector space is the space of polynomials in two variables x,y, of degree less than or equal to 4. So, I let the basis for this space be the set $${ 1,x,x^2,x^3,x^4, y, y^2, y^3, y^4, xy, xy^2, x^2y, xy^3, x^2y^2, x^3y }$$ The operator is a Laplacian operator on polynomials: f(x,y) --> f(x+1,y) + f(x-1,y) + f(x,y-1) + f(x,y+1) - 4f(x,y), for f(x,y) in V. With the above (ordered) basis, I applied this Laplacian operator to each basis element.  I wrote each result as a linear combination of the ordered basis.  Now, taking the transpose of the coefficients, the matrix w.r.t. the ordered basis is: $$
        \begin{bmatrix}
         0 & 0 & 2 & 0 & 2 & 0 & 2 & 0 & 2   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 6 & 0 & 0 & 0 & 0 & 0   & 0 & 2 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 12& 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 2 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 6 & 0   & 0 & 0 & 2 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 12   & 0 & 0 & 0 & 0 & 2 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 6 & 0 & 6 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{bmatrix}
$$ And thanks to the commenters (below), I now see that my matrix is indeed nilpotent, since it is upper triangular, with zeros on the main diagonal; in my initial sketch of the matrix - I was way off. :-) (I had thought that the 6's were below the diagonal.) Thanks,","['eigenvalues-eigenvectors', 'spectral-theory', 'linear-algebra', 'nilpotence']"
1373154,Question about assumptions for Picard-Lindelöf Theorem in Zeidler's functional analysis text,"In Zeidler's text on functional analysis pg.24 he wrote... The Picard Lindelöf Theorem: Assume the following: (a) the function $F: S \to \mathbb{R}$ is continuous and the partial
  derivative  $F_u:S \to \mathbb{R}$ is also continuous (b) we set $M = \max_{(x,u)\in S} |F(x,u)|$ and $L = \max_{(x,u)\in S} |F_u(x,u)|$ and we choose real number $h$ in such a way that $$0 < h \leq r, hM \leq r, hL < 1$$ Then he goes on by stating that there exist unique solution for IVP of the type $u' = F(x,u)$, $u(x_0) = u_0$ on the square $S$ where $S = \{(x,u) \in \mathbb{R^2}: |x - x_0|\leq r, |u - u_0|\leq r\}, r >0$ My question is where is the usual condition about Lipschitz continuity in the assumption of the theorem? For example, Wolfram http://mathworld.wolfram.com/PicardsExistenceTheorem.html I am guessing $L$ must indirectly imply Lipschitz continuity of function $F$, but why is it stated in this particular way?","['fixed-point-theorems', 'proof-verification', 'real-analysis', 'functional-analysis', 'ordinary-differential-equations']"
1373162,How to prove $f_n$ converge uniformly?,"For each $n \in \mathbb{N}$ consider the function $f_n : [0,+\infty) \to \mathbb{R}$ given by $$f_n(x) := \sin\left(\sqrt{4\pi^2n^2+x}\right), \ \ \ \ \forall x \ge 0.$$ Prove that $f_n$ converges uniformly on each interval $[0,a]$ with $a > 0$; $f_n$ does not converge uniformly on $[0,+\infty)$. Original image at https://i.sstatic.net/WNTyz.png My attempt: I showed how to prove (2), just let $x_n=\pi^2(1/4+2n)$ then for any $n$, $f_n(x_n)=1$, so $f_n(x_n)$ cannot converge uniformly on $[0,\infty)$. I have question about (1) , If I use Arzela-Ascoli theorem, I can only show there is a subsequence converge uniformly on $[0,a]$. How to conclude that $f_n$ actually converge uniformly? Could someone kindly help? Thanks!","['convergence-divergence', 'real-analysis']"
1373191,Sanity check: smooth structure of tangent bundle,"Let $M$ be a smooth $n$ manifold and let $TM$ denote its tangent bundle $$ TM = \bigsqcup_{x \in M} \{(x,T_x M)\}$$ I am trying to put a smooth structure (atlas) on $TM$ using the atlas on $M$. But I'm a bit confused and could do with some help: Say, $(x,T_x M)$ is a given point in the tangent bundle. So my goal is to find an open set containing $(x,T_x M)$ and a smoth diffeomorphism $\psi$ from this open set to an open set in $\mathbb R^{2n}$. Let $(U,\varphi)$ be a chart on $M$ such that $x \in U$. I want to use this chart to construct a chart $\psi$ on $TM$: First I need to think about the domain of $\psi$. It seems to me that it should look like $U \times$ some open set $V$ where the elements of $V$ are tangent spaces $T_x M$. And this is where I am confused: Where exactly would such an open set
  $V$ live? There seems to be no space consisting of points of the form
  $T_x M$. What am I doing wrong?",['differential-geometry']
1373203,"Integrating volume of a sphere with a cylinder ""drilled"" out of it","Unfortunately, I am stuck again on another integration problem. Famous last words, this should be simple. $$
\text{A cylindrical drill with radius 5 is used to bore a hole through}\\\text{the center of a sphere of radius 7. Find the volume of the ring shaped solid that remains.}
$$ So we can setup our problem by first defining our change in $\theta$ as the first region, because we can do some simple multiplication to fill the rest of the sphere symmetrically. We should just be able to calculate the change in $r$ inside of that. $$
\begin{align}
&=8 \int_{0}^{\frac{\pi}{4}} \int_{5}^{7} r\:dr\:d\theta\\
&=\frac{8}{2}\int_{0}^{\frac{\pi}{4}}49-25\:d\theta\\
&=24 \times \frac{8}{2} \times \frac{\pi}{4}\\
&=24\pi
\end{align}
$$ Edit: I attempted to re-evaluate my process, but the problem was still not correct. I attempted to set my integrand to the arc length of the sphere - the arc length of the cylinder, but the integrand $\frac{r^3}{2}-5r$ was not the correct integrand to use.","['volume', 'integration']"
1373283,$ x^2 + \frac {x^2}{(x-1)^2} = 2010 $,"I found this question from last year's maths competition in my country. I've tried any possible way to find it, but it is just way too hard. Given $$ x^2 + \frac {x^2}{(x-1)^2} = 2010,$$ 
find $\dfrac {x^2} {x-1}.$ (A) $1+\sqrt {2011}$ (B) $ 1-\sqrt {2011}$ (C) $1\pm \sqrt{2011} $ (D) $\sqrt {2011}$ So I multiply them with $(x-1)$ 
$$x^2(x-1) + \frac {x^2} {x-1} = 2010(x-1)$$
$$\frac {x^2} {x-1} = (x-1)(2010-x^2)$$ and I stuck in here, dont know how to remove $x$ in there","['contest-math', 'algebra-precalculus']"
1373292,Convergence that preserves smoothness,"One of the advantages of uniform convergence is that it preserves continuity (among other properties). Unfortunately, it does not preserve derivability. Is there a convergence mode preserving it?","['uniform-convergence', 'functional-analysis', 'general-topology', 'derivatives']"
1373299,$\frac {1} {ab} + \frac {1} {ac} + \frac {1} {ad} + \frac {1} {bc} + \frac {1} {bd} + \frac {1} {cd}$,"I found this questions from past year maths competition in my country, I've tried any possible way to find it, but it is just way too hard. given $$ \frac {1} {a} + \frac {1} {b} + \frac {1} {c} + \frac {1} {d} = 65, \frac {1} {a^2} + \frac {1} {b^2} + \frac {1} {c^2} + \frac {1} {d^2} = 209$$
find $$\frac {1} {ab} + \frac {1} {ac} + \frac {1} {ad} + \frac {1} {bc} + \frac {1} {bd} + \frac {1} {cd}$$ (A) $2006$ (B) $2007$ (C) $2008$ (D) $2009$ (E) $2010$ I've use the direct way (make them become 1 fraction)
$$\frac {abc+abd+acd+bcd} {abcd} = 65$$
$$\frac {a^2b^2c^2+a^2b^2d^2+a^2c^2d^2+b^2c^2d^2} {a^2b^2c^2d^2} = 209$$
$$\frac {a^2b^2c^2d^2(ab+ac+ad+bc+bd+cd)} {a^3b^3c^3d^3}$$
$$\frac {(ab+ac+ad+bc+bd+cd)} {abcd}$$ but it doesn't make sense with these power $abcd$ thing","['contest-math', 'algebra-precalculus']"
1373305,Geometric interpretation of cubic curve?,"Lines and conics have clear geometric meanings that are coordinate-free, but cubics seem to rely entirely on cubic equations and coordinate systems. Are there ways to define cubic curves without cubic equations? I thought about this question by trying to generalize tangent lines and osculating circles. Since a tangent line is defined by taking the limit of two points on the curve, and an osculating circle is defined by taking the limit of two tangent lines on the curve, I thought about taking the limit of two osculating circles on the curve, but after playing around with evolutes and involutes, I couldn't come up with anything.","['projective-geometry', 'algebraic-geometry', 'geometry']"
1373317,The restriction fo covering to a component is a covering map onto its image.,"I am reading Lee's Introduction to Topological Manifolds. I got stuck on the problem 11-7 on pages 303. The below is the problem. Prove : If $q: E \rightarrow X$ is a covering map and $A \subseteq X$ is a locally path-connected subset, then the restriction of $q$ to each component of $q^{-1}(A)$ is a covering map onto its image. I proved that $q^{-1}(A)$ is locally path-connected and so are its components. The hardest thing is to show it is evenly covered. But I can't find a clue. I'd like to know how to construct an evenly covered neiborhood and hints for the proof.","['covering-spaces', 'manifolds', 'general-topology']"
1373326,Function of sin x,"Give that $f(x)=\sin x$ for the domain $0\leq x \leq k$, find the greatest value of $k$ for which $f(x)$ has an inverse. Is the answer $\frac{\pi}{2}$?","['trigonometry', 'algebra-precalculus', 'functions']"
1373327,Find $\lim_\limits{h\to 0}{\frac{f(a+h)-f(a-h)}{h}}$,"Let $f:\mathbb{R}\mapsto \mathbb{R}$ be a function such that:
  $$\lim_\limits{x\to a}{\frac{f(x)-f(a)}{x-a}}=2$$ Find, if it exists, the $\lim_\limits{h\to 0}{\frac{f(a+h)-f(a-h)}{h}}$ without using derivatives and integrals. So, I have tried the following: $$\lim_\limits{x\to a}{\frac{f(x)-f(a)}{x-a}}=2 \Leftrightarrow \lim_\limits{h\to 0}{\frac{f(a+h)-f(a)}{h}}=2$$ Any hint how to continue?","['limits-without-lhopital', 'calculus', 'real-analysis', 'limits']"
1373337,Density of a dense subspace of a Hausdorff space,"If X is a Hausdorff space and Y is a dense subspace of X, can the density of Y exceed the density of X? The density of a space X is the least infinite cardinal C such that X has a dense set of cardinal C or less.",['general-topology']
1373339,"In a group $G$, prove the following result","Let $G$ be a group in which $a^5=e$ and $aba^{-1}=b^m$ for some positive integer $m$, and some $a,b\in G$. Then prove that $b^{m^5-1}=e$. Progress $$aba^{-1}=b^m\Rightarrow  ab^ma^{-1}=b^{m^2}$$
What will be the next?","['abstract-algebra', 'group-theory']"
1373406,Enlighten me... the science behind differentiation [duplicate],"This question already has answers here : Where is the flaw in this ""proof"" that 1=2? (Derivative of repeated addition) (11 answers) Closed 8 years ago . This a tricky math question I encountered.
I know a little bit about the answer. But I want somebody who is very good at math to help me find the real reason behind this. OK Lets start $1^2 = 1$ $2^2 = 2+2$ $3^2 = 3+3+3$ ........................... ................................ $x^2 = x+x+x+x+.....(x times)$ Differentiating with respect to $x$ We get $2x = 1+1+1+1...... (x times)$ which is equal to $2x = 1*x$ $2x = x$ Which is incorrect. Where did I go wrong?? :O :O","['implicit-differentiation', 'derivatives']"
1373408,How to prove there exist distinct $a_{i}$ such $f'(a_{1})f'(a_{2})f'(a_{3})\cdots f'(a_{n})=1$,"Let $f$ be a continuous map from $[0,1]$ to $R$ that is differentiable on $(0,1)$,with $f(0)=0,f(1)=1$, show that for each postive integer $n$ there exist distinct numbers $a_{1},a_{2},\cdots,a_{n}\in (0,1)$,such that $$f'(a_{1})f'(a_{2})f'(a_{3})\cdots f'(a_{n})=1$$Thanks in advance.","['analysis', 'calculus']"
1373415,When does this sum of combinatorial coefficients equal zero?,"$p>2$ is a prime number, $n\in \mathbb{N}$. Is the following statement true or false? Thanks. $$\sum_{i=0}^{\lfloor n/p\rfloor}(-1)^i {n\choose ip}=0$$ iff $n=(2k-1)p$ for some $k\in \mathbb{N}$.","['binomial-coefficients', 'combinatorics']"
1373441,Show that Mergelyan's theorem cannot extend to the case in which $S^2-K$ has infinitely many components.,"This is an exercise in W. Rudin's Real and Complex Analysis . For $n=1,2,\ldots$, let $D_n=D(\alpha_n;r_n)$ be disjoint open discs in (the unit open disk) $U$ whose union $V$ is dense in $U$, such that $\sum_nr_n<\infty$. Put $K=\bar U-V$. Let $\Gamma$ and $\gamma_n$ be the paths
  $$\Gamma(t)=e^{it},\quad \gamma_n(t)=\alpha_n+r_ne^{it},\quad 0\le t\le2\pi,$$
  and define 
  $$L(f)=\int_\Gamma f(z)\mathrm{d}z-\sum_{n=1}^\infty \int_{\gamma_n}f(z)\mathrm{d}z.\quad(f\in C(K))$$
  Prove that (a) $L$ is a bounded linear functional on $C(K)$; (b) $L(R)=0$ for every rational function $R$ whose poles are outside $K$; (c) there exists an $f\in C(K)$ for which $L(f)\ne0$. My first question is: Why does these disks $D_n$ exist? Suppose they do exist. I can prove (a) and (b). But how can I prove part (c)? I'm really confused. Should I construct the disks $D_n$ / the function $f$ explicitly or just show the existence? Can anyone give some advice? Thanks in advance.",['complex-analysis']
1373474,Trigonometry question,"If $$\frac{3-\tan^2\frac{\pi}{7}}{1-\tan^2\frac{\pi}{7}}=\alpha \cos\frac{\pi}{7}.$$ If $\alpha$ is a natural number.Find $\alpha$. My attempt is: $$\frac{3-\tan^2\frac{\pi}{7}}{1-\tan^2\frac{\pi}{7}}=\alpha \cos\frac{\pi}{7}$$ convert it into sin,cos $$\frac{3\cos^2\frac{\pi}{7}-\sin^2\frac{\pi}{7}}{\cos^2\frac{\pi}{7}-\sin^2\frac{\pi}{7}}=\alpha \cos\frac{\pi}{7}$$ $$\frac{3\cos^2\frac{\pi}{7}-\sin^2\frac{\pi}{7}}{\cos\frac{2\pi}{7}}=\alpha \cos\frac{\pi}{7}$$ $$3\cos^2\frac{\pi}{7}-\sin^2\frac{\pi}{7}=\alpha \cos\frac{\pi}{7}\cos\frac{2\pi}{7}$$ $$2\cos^2\frac{\pi}{7}+\cos^2\frac{\pi}{7}-\sin^2\frac{\pi}{7}=\alpha \cos\frac{\pi}{7}\cos\frac{2\pi}{7}$$ $$2\cos^2\frac{\pi}{7}+\cos\frac{2\pi}{7}=\alpha \cos\frac{\pi}{7}\cos\frac{2\pi}{7}$$ but i got stuck and could not further solve it....
I would appreciate the help,thanks in advance.",['trigonometry']
1373515,Coincidence of two $\tau$-additive measures,"I'm struggling to prove the following Lemma from V.I. Bogachev, Measure Theory 2: Let two $\tau$-additive measures $\mu$ and $\nu$ on a topological space $X$ coincide on all sets from some class $\mathcal{U}$ that contains a base $\mathcal{B}$ of the topology $\mathcal{T}$ in $X$ and is closed with respect to finite intersections. Then $\mu=\nu$. Recall that a Borel measure $\mu$ is called $\tau$-additive on a topological space $X$ if for every increasing net of open sets $(O_i)_{i\in I}$ in $X$ one has the equality
$$|\mu|\bigg(\bigcup_{i\in I}O_i\bigg)=\lim_{i\in I}|\mu|(O_i)$$ The given proof is a little minimalistic: Every open set $O\in\mathcal{T}$ can be represented in the form of the union of a net of increasing open sets $O_i$ that are finite unions of sets in $\mathcal{U}$. It is easily seen that $\mu(O_i)=\nu(O_i)$ for all $i\in I$. By the $\tau$-additivity we obtain $\mu(O)=\nu(O)$. Since the two measures coincide an all open sets, they coincide on all Borel sets. With some help from Daniel Fischer I've constructed the net of increasing open sets $(O_i)_{i\in I}$ via the directed set $(I,\subseteq)$, where
$$I:=\{\mathcal{B}_i\subseteq\mathcal{B}\,|\,\mathcal{B}_i\text{ is finite and }\forall B\in\mathcal{B}_i\,:\,B\subseteq O\}. $$
and
$$O_i:=\bigcup_{B\in\mathcal{B}_i}B $$
This yields $O_i\subseteq O_j$ whenever $B_i\subseteq B_j$, $\bigcup_{\mathcal{B}_i\in I}O_i=O$ and every $O_i$ is a finite union of elements of the base $\mathcal{B}$. Now, I have troubles showing $\mu(O_i)=\nu(O_i)$ for all $\mathcal{B}_i\in I$. Also, I don't see where the assumption that $\mathcal{U}$ is closed with respect to finite intersections is needed. Any help would be highly appreciated and thank you very much in advance for your efforts! Greetings","['general-topology', 'measure-theory']"
1373523,Range of an inverse trigonometric function,"Find the range of $f(x)=\arccos\sqrt {x^2+3x+1}+\arccos\sqrt {x^2+3x}$ My attempt is:I first found domain, $x^2+3x\geq0$ $x\leq-3$ or $x\geq0$...........(1) $x^2+3x+1\geq0$ $x\leq\frac{-3-\sqrt5}{2}$ or $x\geq \frac{-3+\sqrt5}{2}$...........(2) From (1) and (2),
domain is $x\leq-3$ or $x\geq0$ but could not solve further..Any help will be greatly appreciated.","['trigonometry', 'functions']"
1373533,Riemann hypothesis reformulation - again,"Yesterday I started to write a paper about the reformulation of the Riemann Hypothesis. My idea was to map the function such that all of the trivial zeros are outside of the unit disk, and the non-trivial zeros are on the circle. Iff RH is true, then the radius of convergence (the distance to the closest singularity from the origin of the taylor series) of the taylor series representing reciprocal of the function is $1$. After some manipulations, I have got 2 conjectures: https://mathoverflow.net/questions/212289/riemann-hypothesis-reformulation-lim-n-to-infty-sum-k-lnka-kn-over-n-s . (Topic deleted from MO.) I would like to know if they really imply RH, or I went wrong somewhere. EDIT: I post the reformulation here: $\zeta(s)$ has its non-trivial zeros on the line $Re(s)=0.5$. It means, that the the taylor series of $$Z(s)={1\over\zeta\left(\frac{1}{2}+\frac{1+s}{1-s}\right)}$$ have its radius of convergence of $1$. (I mapped the right half plane to the unit disc, so trivial zeros are outside of the disk.) Its derivates given by Cauchy's integral formula, and taking the right contour $C$ such that $C(t)=f^{-1}(t-(a-1/2)i)$ with $f(z)=i(z+1)/(z-1)$ the map from $\mathbb{D}\to\mathbb{\overline{H}}$ becames $${Z}^{(n)}(0)=\frac{n!}{2\pi i}\int_{-\infty}^{\infty}{1\over \zeta(a+it)}C_n(t)\;dt$$
with $C_n(t)=C'(t)/C(t)^{n+1}$. WLG letting $1.5>a>1$, and using the dirichlet series for the reciprocal of the zeta function, I got \begin{align*}{Z}^{(n)}(0)&=\frac{n!}{2\pi i}\int_{-\infty}^{\infty}\left[\sum_{k=1}^\infty \frac{\mu(k)}{k^{a+it}}\right]C_n(t)\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}\int_{-\infty}^{\infty}\frac{n!}{2\pi i}\frac{C_n(t)}{k^{it}}\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}\int_{-\infty}^{\infty}\frac{n!}{2\pi i}g_k(C(t))C_n(t)\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}g^{(n)}_{k}(0).\end{align*} $$g_k(t)=1/k^{iC^{-1}(t)}$$ In the last 2 steps, I changed the contour integral to the derivates of a function series, noticing that $g\circ C(t)=1/(k^{it})$. The only singularity of $g$ is at $1$, but $g$ is bounded inside the contour, so I tought the integral and the derivates are the same. For later to have the limits defined, define the function $d\colon\mathbb{N}\mapsto \mathbb{N}$ such that $d(n)$ gives the $n$th square-free integer.
$$Z^{(n)}(0)=\sum_{k=1}^{\infty}\frac{\mu(d(k))}{d(k)^2}g^{(n)}_{d(k)}(0)$$ 1. conjecture: Using the ratio test led me to my first question here, such that given a series $$A(n)=\sum_{k=1}^{\infty}a_k(n),$$ $$a_k(n)=\frac{\mu(d(k))}{n!d(k)^2}g^{(n)}_{d(k)}$$ with $|a_k(n)/a_k(n+1)|\to 1$ (Taylor series of $g$ about the origin have its radius of conv. 1) as $n\to \infty$, it is true that $$\lim_{n\to \infty}\left|\frac{A(n)}{A(n+1)}\right|=1.$$ I suppose it is true for some series satisfying certain conditions, but I cannot prove it. 2. conjecture: Using the recurrence relation of the coefficients (due to WolframAlpha): $na_k(n)+(n+2)a_k(n+2)-2(n+1-\ln(k))a_k(n+1)=0$, $$\lim_{n\to \infty}{\sum_k\ln(k)a_k(n)\over\sum_kna_k(n)}=0$$ would imply RH. Does proving the 2 conjectures above prove the Riemann hypothesis? I think it would also prove GRH for Dirichlet L-function with a little change, and with a good choice of $a$ to ensure convergence.","['riemann-hypothesis', 'riemann-zeta', 'complex-analysis', 'real-analysis']"
1373541,"Conditional distribution of $X$ exponential given $U\leq e^{-X}$, with $U$ uniform on $(0,1)$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Let $X$ be exponentially distributed with mean $1$ and $U$ be a $U(0,1)$ random variable independent of $X$ . Define $$I= \begin{cases}1,&U \leq e^{-X}\\ 0,&\text{ otherwise}\end{cases}$$ Show that the conditional distribution of $X$ given $I=1$ is exponential with mean $\frac12$ .","['statistics', 'probability-distributions']"
1373572,Coin flipping game with stop-loss,"You play 100 rounds of a coin flipping game where you win \$2 for a head and lose \$1 for a tail on each round. Clearly since the coin tosses are independent the expected winnings are \$50. Now, suppose you play at most 100 rounds of this game as before, but this time you stop early if you accumulated \$50 of losses. How does this change the expected winnings? Naively one would think that this ""stop-loss"" reduces the losses leading to higher expected winnings compared to the first game, but this does not take into account scenarios where we subsequently recover from the losses: for example the stop-loss throws away the profitable scenario where we throw 50 tails followed by 50 heads ending with positive winnings of \$50.",['probability']
1373574,Sum of the series $\sum\limits_{n=0}^\infty \frac{1}{(3n+1)^3}$,"The following result matches very good numerically: 
$$\sum_{n=0}^\infty \frac{1}{(3n+1)^3}=\frac{13}{27}\zeta(3)+\frac{2\pi^3}{81\sqrt{3}}.$$
Though I'm not sure how to approach this. How can we prove it? Also, is it possible to find closed form for $$\sum_{n=0}^\infty \frac{1}{(3n+1)^5}$$ or the like?","['closed-form', 'sequences-and-series']"
1373591,"Let $f(z)$ be a function analytic in a domain containing the segment $[0,1]$ and satisfying $f(z+1)=azf(z)+p(z)$.","Let $f(z)$ be a function analytic in a domain containing the segment $[0,1]$ and satisfying
  $$
f(z+1)=azf(z)+p(z)
$$
  in that domain, where $a\in\mathbb{R}$ and $p$ is a polynomial. Show that $f$ can be analytically continued to a domain $\{z\in\mathbb{C}\,:\,|\Im z|<\varepsilon\}$ for some $\varepsilon>0$. I don't quite know how to work with this. My attempt was to derive this equation until the polynomial disappears, but that gives me the equation (supposing $p$ has degree $(n-1)$)
$$
f^{(n)}(z+1)=naf^{(n-1)}(z)+azf^{(n)}(z),
$$
which I don't find helps much. I can't even think of a way to define this function which would just leave testing analyticity at each integer. Any help is greatly appreciated. Thank you","['analytic-continuation', 'complex-analysis']"
1373600,Why the determinant of a matrix with the sum of each row's elements equal 0 is 0?,"I'm trying to understand the proof of a problem, but I'm stuck. In my book they consider that if all lines of a matrix has sum 0 then it's determinant is also 0. I checked some random examples and it's true, but I couldn't proof it. Could you help me?","['linear-algebra', 'matrices']"
1373602,How to prove that this process is always positive?,"I would like to ask is there any way to prove that following process
$$ 
\mathrm dY_t=\left(a+\frac{b}{Y_t}\right)\mathrm dt +\mathrm dW_t, \ \  Y_0=y_0>0,
$$
where $a\neq 0$ and $b\geq 1/2$,
is always positive, i.e. $P(0<Y_t)=1$ a.s.  Thank you !","['probability-theory', 'stochastic-calculus', 'stochastic-differential-equations', 'stochastic-processes', 'brownian-motion']"
1373612,$\int\dfrac{dx}{x^2(x^4+1)^{3/4}}$ [duplicate],This question already has answers here : Evaluation of $\int\frac{1}{x^2.(x^4+1)^{\frac{3}{4}}}dx$ (3 answers) Closed 8 years ago . Evaluate $$\large{\int\dfrac{dx}{x^2(x^4+1)^{3/4}}}$$ I thought of rewriting this as $$\large{\int\dfrac{dx}{x^5(1+\frac{1}{x^4})^{3/4}}}$$ and substituting $$u^4=\left(1+\frac{1}{x^4}\right)\Rightarrow u=\left(1+\frac{1}{x^4}\right)^{1/4}$$ and subsequently I got $$du=\dfrac{1}{4}\left(1+\frac{1}{x^4}\right)^{-3/4}\times (-4x^{-5})dx$$,"['calculus', 'indefinite-integrals', 'integration']"
1373630,Solve $\cos3x - 18\cos x +10 =0$,"I want to solve
$$\cos 3x - 18\cos x +10 =0 $$ I tried: 1) Replacing $\cos 3x$ to $\cos^3x - 3\cos x$ 2) Replacing $\cos x$ to $t$ we get: $$t^3 - 21t +10 = 0$$ So we get cubic equation. But I can't solve it.","['calculus', 'trigonometry']"
1373644,Prove that the linear transformations are the same.,"I have this lemma: If X is a complex inner product space and $S,T \in B(X)$ are such that
  $(Sz,z)=(Tz,z)\forall z \in X$, then $S=T$. $B(x)$ is the set of bounded linear operators from X to X. $(,)$ is the inner-product function. I want to prove this lemma. But I do not know how to prove it. I tried something like this: Assume for contradiction that the transformations are not the same. Then there is an $z'$, such that $(Sz',z')=(Tz',z')$, but $Sz'\ne Tz'$
. Then $z'\ne0$, $Sz'-Tx'\ne0
$, but $z'$ and $Sz'-Tz'$ are orthogonal. But I don't see how to continue. Any tips?","['vector-spaces', 'normed-spaces', 'inner-products', 'functional-analysis', 'linear-transformations']"
1373671,A finite set and the set of its fixed points under any involution have cardinalities of the same parity,"I am trying to write down a formal proof of the following fact: Let $A$ be a non-empty finite set and $f$ an involution on $A$. If $A'$ is the set of fixed points of the involution $f$, then $|A| \equiv |A'| \pmod 2$, where $|A|$ is the cardinality of $A$ and $|A'|$ is the cardinality of $A'$. We can define an equivalence relation on $A$ given by the rule
\begin{equation*}
\forall \, a, b \in A \quad a \sim b\ \text{if and only if}\ b = a\ \text{or}\ b = f(a).
\end{equation*}
It is easy to verify that this is in fact an equivalence relation on $A$.
Call $C_a$ the equivalence class of an element $a \in A$. Therefore, $C_a = \{a, f(a) \}$ if $a \in A \setminus A'$ and $C_a = \{a\}$ if $a \in A'$. We have
\begin{equation*}
|A| = \sum_{a \in A} |C_a| = \sum_{a \in A \setminus A'} |C_a| + \sum_{a \in A'} |C_a| = \sum_{a \in A \setminus A'} |C_a| + |A'|.
\end{equation*}
Since $|C_a| \equiv 0 \pmod 2$ for all $a \in A \setminus A'$, we have $|A| \equiv |A'| \pmod 2$. Is this proof correct? If it is, can it be improved? Are there other proofs of this fact?","['elementary-set-theory', 'alternative-proof', 'proof-verification']"
1373679,How many different sums of parts of a vector,"The following mathematical puzzle was given to me by a friend a while ago and I can't work out how to solve it. Does anyone have any ideas? For a given vector $v \in \{-1,1\}^n$ we consider the following $n$ sums. $$S_j=\sum_{i=0}^j v_i - \sum_{i=j+1}^{n-1} v_i \text{ for } 0 \leq j \leq n-1.$$ For example if $v = (-1,1,1)$ then $S=(-3,-1,1).$ Now let $T_j = 1$ if $S_j>0$ and $0$ otherwise. So for our example vector $v$ we have that $T=(0,0,1)$ Considered over all $2^n$ possible vectors $v$, the question is how many different possible vectors $T$ are there? I think if $n=2$ the answer is $3$, if $n=3$ the answer is $8$, if $n=4$ the answer is $11$, if $n=5$, the answer is $22$ and if $n=6$ the answer is $31$. Posted to https://mathoverflow.net/questions/212389/how-many-different-sums-of-parts-of-a-vector where a possible answer has been given in the comments.",['combinatorics']
1373728,"What do sine, tan, cos actually mean?","I know that $\sin\theta=\frac{y}{r}$ and $\cos\theta=\frac{x}{r}$. My question is: is $\sin$ a function of $\theta$, as in $\sin (\theta$)? If yes, why is there no $\theta$ on the right hand side of the equation? For example, $f(x) = mx + c$. Here $f$ is a function of $x$. If not, what is the relationship between the symbols $\sin$ and $\theta$? Another question is: why can we write $\theta = \sin ^{-1} (\frac{y}{r})$ and what does it actually mean?","['notation', 'trigonometry', 'algebra-precalculus', 'functions']"
1373735,Measuring correlation of a truncated sample,"Suppose samples $(X_i,Y_i)$ were drawn from a multinomial distribution $N(\mu_X, \mu_Y, \sigma_X, \sigma_Y)$. The correlation between $X$ and $Y$ can be then estimated as $$\hat{\rho}_{XY}=\frac{1}{N}\sum_{i,j}\frac{(X_i - \mu_X)(Y_i - \mu_Y)}{\sigma_X\sigma_Y}$$
But now suppose tha all samples with $X_i>c$ are discarded, where $c$ is some constant. How does that change the correlation estimate? The way I see it, the sum can be decomposed as
$$\hat{\rho}_{XY}=\frac{1}{\sigma_X\sigma_Y}\sum_{j}(Y_i - \mu_Y)\left( \frac{1}{N_C}\sum_{i\in C}(X_i - \mu_X) + \frac{1}{N_{C'}}\sum_{i\in C'}(X_i - \mu_X)\right)$$
where $C=\lbrace i;X_i\leq c\rbrace$, $C=\lbrace i;X_i > c\rbrace$ and $N$, $N_{C'}$ is the number of elements in $C$ and $C'$, respectively. Now now the correlation changes depending on the sign of the term $\frac{1}{N_{C'}}\sum_{i\in C'}(X_i - \mu_X)$ which is discarded: if $c>\mu_X$ then all terms in that sum will be positive so throwing these away will reduce the correlation, and vice versa if $c<\mu_X$. Is there a more intuitive way to see this? Also, what would be some unbiased estimator for the underlying distribution (i.e. the distribution without the discarded samples), if $c$ is known?",['statistics']
1373773,Trigonometric equation cos sin and power,"The problem is $2\cos t - 3\sin^2t +2 = 0$.
I get to $2\cos t -3\sin^2t =-2$
I think that I need to use a trigonometric identity like $\cos(x+y)$ and to divide $2\cos t -3\sin^2t$ with the $\sqrt{2^2+3^2}$ Do you know how to solve this? It should be $\sqrt{2^2 + 3^2}$","['quadratics', 'trigonometry']"
1373806,Intuition for probability density function as a Radon-Nikodym derivative,"If someone asked me what it meant for $X$ to be standard normally distributed, I would tell them it means $X$ has probability density function $f(x) = \frac{1}{\sqrt{2\pi}}\mathrm e^{-x^2/2}$ for all $x \in \mathbb{R}$. More rigorously, I could alternatively say that $f$ is the Radon-Nikodym derivative of the distribution measure of $X$ w.r.t. the Lebesgue measure on $\mathbb{R}$, or $f = \frac{\mathrm d \mu_X}{\mathrm d\lambda}$.  As I understand it, $f$ re-weights the values $x \in \mathbb{R}$ in such a way that
$$
\int_B \mathrm d\mu_X = \int_B f\, \mathrm d\lambda
$$
for all Borel sets $B$.  In particular, the graph of $f$ lies below one everywhere: so it seems like $f$ is re-weighting each $x \in \mathbb{R}$ to a smaller value, but I don't really have any intuition for this.  I'm seeking more insight into viewing $f$ as a change of measure, rather than a sort of distribution describing how likely $X$ is. In addition, does it make sense to ask ""which came first?""  The definition for the standard normal pdf as just a function used to compute probabilities, or the pdf as a change of measure?","['probability-theory', 'probability', 'probability-distributions']"
1373809,Using the definition of derivative to find $\tan^2x$,"The instructions: Use the definition of derivative to find $f'(x)$ if $f(x)=\tan^2(x)$. I've been working on this problem, trying every way I can think of. At first I tried this method:
$$\lim_{h\to 0} {\tan^2(x+h)-\tan^2(x)\over h}$$
$$\lim_{h\to 0} {\tan(x+h)-\tan(x)\over h}\cdot\lim_{h\to 0} {\tan(x+h)-\tan(x)\over h}$$
And then I went on from there, but I was never able to get rid of the $h$. So then I tried this:
$$\lim_{x\to y} {\tan(x)-\tan(y)\over x-y}\cdot\lim_{x\to y} {\tan(x)-\tan(y)\over x-y}$$
$$\lim_{x\to y} {\tan(x-y)[1+\tan(x)\tan(y)]\over x-y}\cdot\lim_{x\to y} {\tan(x-y)[1+\tan(x)\tan(y)]\over x-y}$$
$$\lim_{x\to y} {\sin(x-y)\over (x-y)}\cdot{1\over \cos(x-y)}\cdot[1+\tan(x)\tan(y)]\cdot\lim_{x\to y} {\sin(x-y)\over (x-y)}\cdot{1\over \cos(x-y)}\cdot[1+\tan(x)\tan(y)]$$
I then put the ${\frac{\sin(x-y)}{x-y}}=1$, and I traded all of the $y$ values for $x$, which gave me $\frac{1}{\cos(\theta)}=1$
$$1+\tan^2(x)\cdot1+\tan^2(x)=1+2\tan^2(x)+\tan^4(x)$$
I know that the derivative of $\tan^2(x)=2\tan(x)\sec^2(x)$, so this is obviously wrong. I found this link from a previous stack exchange point on finding the limit by definition of $\tan(x)$, so I tried using the answers given there. But, even with that, I haven't been able to get this correct. What do I need to do?","['derivatives', 'calculus', 'limits', 'trigonometry']"
1373826,Identity Principle type question: Prove that $f=g$,"While reading a complex analysis textbook the following assertion came up Since $f,g:D\equiv D(a,r) \to \mathbb{C}$ are analytic and injective functions such that $f(D)=g(D)$, $f(a)=g(a)$ and $f'(a)=g'(a)$ then $f=g$. I do not think this follows directly! To prove it I think we need to use the Identity Principle. What I did is take a sequence $(z_n)_n \subset D $ such that $z_n \neq a$ and $z_n \to a$, then for each $n$ there exist $w_n \neq a$ such that $f(z_n)=g(w_n)$. By injectivity and since $f(a)=g(a)$, it follows that also $w_n \to a$. Now I am trying to use the condition $f'(a)=g'(a)$ to see that $z_n=w_n$ for infinitely many $n$'s and hence by the Identity Principle $f=g$. However this argumentation seems to lead nowhere. Any help is very appreciated, perhaps there is a much more simple argument that do not uses anything that I have thought so far.","['analyticity', 'complex-analysis']"
1373843,Terminology in graph theory,"Let $G$ be a finite graph with the following property: For any vertex $a$ and edge $\{b, c\}$ of $G$, there is an edge connecting them: there is one of $\{a,b\}$ or $\{a, c\}$ in $G$. Is there a common terminology in graph theory?","['graph-theory', 'terminology', 'combinatorics']"
1373879,"Prove that $(\mathbb{Z}_n , +)$, the integers $\pmod{n}$ under addition, is a group.","Prove that $(\mathbb{Z}_n , +)$ , the integers $\pmod{n}$ under addition, is a group. To show that this is a group, I know I need to show three things (in our text, we do not need to show that addition is closed-- rather, we show these three items): $(a)$ Associative Law $(b)$ Existence of Identity $(c)$ Existence of Inverse This is what I have been working with so far: $(a)$ Associative Law:
  First, assume that $n$ is a composite number and that $a,b \in \mathbb{Z}$ s.t. $a=nx$ and $b=ny$ for some integers, $x$ and $y$ . Then $a+nx+nx=n(x+y)$ . So, this is where I am stuck for the Associative Law. I'm not sure if I am headed down the correct path to show that $\mathbb{Z}_n$ is associative. $(b)$ Existence of Identity:
  Generally, when showing the existence of an identity we can use this information for addition : $a + 0 = 0 + a =a$ . I am unsure how to insert the modular portion of the definition into the existence of this identity. I realize that for addition, we generally look at $0$ (rather than $1$ for multiplication). $(c)$ Existence of Inverse: I need to show that for each element $a \in \mathbb{Z}_n$ that $a^{-1}=-a$ . Again, I do not know how to insert the modular portion of definition into this aspect of the proof. My question is how to incorporate this modular information into the proof that this is a group. We have not covered the integers modulo $n$ , binary operations, nor groups in my intro to proofs course. I am trying to read my text to figure out how to prove this, but have a difficult time reading and interpreting math speak.",['group-theory']
1373884,Why isn't every element of the spectrum an eigenvalue? (Where is the error in my proof?),"My book defines the spectrum like this: Let $H$ be a complex Hilbert space, let $I \in B(H)$ be the identity
  operator and let $T \in B(H)$. The spectrum of $T$, denoted $\sigma(T)$,
  is defined to be: $$\sigma(T)=\{\lambda \in \mathbb{C}: T-\lambda I\text{ is not invertible}\}$$ Later there is a lemma that says that all eigenvalues are in the spectrum: Let $H$ be a complex Hilbert space and let $T \in B(H)$. If $\lambda$ is
  an eigenvalue of T then $\lambda \in \sigma(T)$. But why does the converse not hold? I mean, if $\lambda \in \sigma(T)$, why is not $\lambda$ and eigenvalue? What is wrong with this proof?: Let $\lambda \in \sigma(T)$, then $T-\lambda I$ is not invertible. Then there is an $x \in H, x \ne0$ such that $T(x)-\lambda x=0$, if not, only 0 will be sent to 0, and then the operator is invertible. But then we have that $T(x)=\lambda x$, and hence $\lambda$ is an eigenvalue. Do you see where the error is?","['hilbert-spaces', 'spectral-theory', 'eigenvalues-eigenvectors', 'functional-analysis']"
1373891,Defining a coproduct in $\mathsf{Grp}$ using group presentations,"I've encountered this exercise in Aluffi's Algebra: Chapter 0 . It might be helpful to say that the book doesn't introduce functors at this stage,, and that the book defines a presentation of a group $G$ as a pair $(A\mid \Psi)$ , where $\Psi$ is a subset of $F(A)$ such that $G \cong F(A)/R$ , where $R$ is the smallest normal subgroup of $F(A)$ containing $\Psi$ . So, here is the exercise. Let $(A\mid \Psi)$ , resp., $(A'\mid \Psi')$ , be a presentation for a group $G$ , resp. $G'$ ; we may assume that $A,A'$ are disjoint . Prove that the group $G\ast G'$ presented by $(A\cup A'\mid \Psi\cup\Psi')$ satisfies the universal property for the coproduct of $G$ and $G'$ in $\mathsf{Grp}$ . (Use the universal properties of both free groups and quotients to construct natural homomorphisms $G\rightarrow G\ast G'$ and $G'\rightarrow G\ast G'$ . First of all, why would we assume that $A,A'$ are disjoint? If they are then their union is their disjoint union as well. But can any 2 groups be presented with $A\cap A' = \emptyset$ ? Secondly, I still can't prove it even for disjoint $A$ and $A'$ . So, will be thankful for any tips.","['abstract-algebra', 'group-theory', 'category-theory']"
1373910,Green's function for Helmholtz equation for the plane with a hole,"That is find $G$ which satisfies \begin{align}
(\nabla^2+k^2)G(\mathbf{x}, \mathbf{y},\omega) = \delta(\mathbf{x}- \mathbf{y})
\end{align} subject to $$\frac{\partial G}{\partial y_n} = 0 ~~~~~\mathrm{on} ~~~~~~S$$ where $S$ is the unit circle centered on the origin. The domain should be taken to mean the exterior of $S$. This means the normal derivative is zero on the boundary. I use the notation with $\omega$ because it is implied that the forcing is at frequency $\omega$. This follows from the wave equation. Note that I would ideally like the 2D version of the above, that is $\mathbf{x} = (x_1,x_2)$.","['greens-function', 'calculus', 'complex-analysis']"
1373940,What is the precise difference between functions and operators?,"I have heard affirmatively that all operators are functions, but not all functions are operators. But at the same time I have heard that functions map numbers to numbers, whereas operators map functions to functions. But if operators are function, then a function map functions to functions. How do you untangle this mess? Can someone present a definitive difference between functions and operators?","['terminology', 'operator-theory', 'definition', 'functions']"
1373951,Using Green's theorem to find an area.,I wish to find out the area enclosed by the ellipse $C:=2x^2+3y^2=2y$ using Green's theorem. I know how to parametrize the ellipse and understand Green's theorem I just don't understand how it is useful in this case. Looking at my notes it says $$Area=\int_C x~dy$$ but it isn't at all obvious where this comes from and that this is even true. Could anyone clarify.,['multivariable-calculus']
1373964,Question on Radon measures from Folland's Real Analysis,"Greetings my mathematical friends.
I am taking a summer class on measures and the theory of real analysis, and I was given the following question from Folland's Real Analysis Second Edition Chapter 7 on Radon measures. It is question #9 which is: The corollary they tell us to use in part a. is: Given a Radon measur $ \mu $ and a non-negative lower semi continuous function f then we have: Of course by lower semi continuous (LSC) we mean a function f such that the following set is open for all values of a $ \{ x | f(x)>a \} $ and by upper semi continuous (USC) the same for the set a $ \{ x | f(x)<a \} $ I like to think I am a good enough student but I haven't got the faintest clue as to how to do this which is frustrating, I have tried many times to look at the question and the hints in parts a and b but cannot really find a pattern. Could you please help me out?
Thanks friends","['real-analysis', 'general-topology', 'measure-theory']"
1373974,Prove that equality holds only if $f$ is one-to-one.,"I am just looking for a hint. Not a solution as I am just trying to solve these for fun. Let $f:A \rightarrow B$ with $A_0 \subset A$ and $B_0 \subset B$. Show that $$A_0 \subset f^{-1}(f(A_0))$$ but equality holds only if $f$ is injective. Here is what I am thinking so far. I will choose two points $a_0,a^{\prime}_0 \in A_0$ with $a_0 \ne a^{\prime}_0$ and $f(a_0)=f(a^{\prime}_0)$. We have $$f^{-1}(f(a_0)) \in A_0 \implies a_0 \in f^{-1}(f(A_0))$$ $$f^{-1}(f(a^{\prime}_0)) \in A_0 \implies a^{\prime}_0 \in f^{-1}(f(A_0)) $$ $$\implies A_0 \subset f^{-1}(f(A_0)) $$ but $$f^{-1}(f(a_0)) \ne f^{-1}(f(a^{\prime}_0))$$ I am sort of stuck here. It looks as though I chose points that are both in the subset $A_0$ but it is possible that the pre-image of one may be outside of $A_0$ making the reverse containment impossible unless $f$ is one-to-one.","['elementary-set-theory', 'functions']"
1373982,Why doesn't this work for Rudin Exercise 3.8,"The problem is 3.8 exercise in baby Rudin: If $ \sum{a_n} $ converges and $\{b_n\}$ is bounded and monotonic, prove that $\sum{a_nb_n}$ converges. Why can't I just do this?: Let $M$ be an upper bound of $\{b_n\}$. Choose $N$ such that for all $n,m\ge N$,
$$ \sum_{k=n}^m{a_k} \le {\epsilon \over  M}$$ Then, $$\sum_{k=n}^m{a_kb_k} \le M\sum_{k=n}^m{a_k} \le \epsilon $$ If someone has a quickish clear proof for this, I'd love to see it also. Thanks in advance.","['analysis', 'sequences-and-series', 'convergence-divergence', 'real-analysis']"
1373983,Why is this proof for an arbitrary function constrained to a constant one?,"Sorry if this seems trivial, I'm having some difficulty understanding a proof. I'm doing exercise 5.1.14 of Velleman's How to Prove It and a solution posted in this question, including the comments, does not make sense to me. I'll restate the problem here: Suppose $A$ is a nonempty set and $f:A\longrightarrow A$. Also suppose that for all $g:A\longrightarrow A, f\circ g=f$. Prove that f is a constant function. Hint: What happens if $g$ is constant? Proving $f$ is constant, if $g$ is constant was easy, but I don't understand how that helps solve the problem. The way I read the question, $g$ has to be an arbitrary function from $A$ to $A$, and restricting it to a constant one no longer makes it arbitrary. As an example, if $g=\text{id}_A$, then $g$ is not constant, but still satisfies the conditions and $f\circ g=f$. My question boils down to: why can we discount all non-constant functions $g$?","['function-and-relation-composition', 'proof-writing', 'functions']"
1373994,Using Lagrange's Method in Finding Extreme Values of $x^2 + y^2 + z^2$ for $\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1$ (New to This Method),"Did I do this hw question correctly (at least in theory, I do not expect anyone to check my algebra work)? In particular, did I solve for lambda and plug lambda back into my equations for x,y, and z correctly, or is there a better way? Something does not feel right about it. Thanks! Apply Lagrange's method in finding the extreme values $x^2 + y^2 + z^2$ subject to the constraint $\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1$, where $a > b > c > 0$. Here is my work thus far: Let $f(x,y,z) = x^2 + y^2 + z^2$, and let  $g(x,y,z) - k = \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} - 1$. Then let $u=f(x,y,z) + \lambda(g(x,y,z) - k)$. This gives us: $$u=(x^2 + y^2 + z^2) + \lambda\frac{x^2}{a^2} + \lambda\frac{y^2}{b^2} + \lambda\frac{z^2}{c^2} - \lambda$$ Taking the partial of u with respect to each variable (including lambda) and setting it equal to zero, we get: $u_x = 2x + \frac{2\lambda x}{a^2} = 0$ $u_y = 2y + \frac{2\lambda y}{b^2} = 0$ $u_z = 2z + \frac{2\lambda z}{c^2} = 0$ $u_\lambda = \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1$ Solving for x, y, and z, we get $x = -\frac{\lambda}{a^2},\ y = -\frac{\lambda}{b^2},\ z = -\frac{\lambda}{c^2}$, which we can plug into our partial, $u_\lambda$, for x, y, and z. In our partial, we get $$\frac{\lambda^2}{a^6} + \frac{\lambda^2}{b^6} + \frac{\lambda^2}{c^6} = 1$$
Solving for $\lambda$ gives us the  difficult solution of $$\lambda = \pm \frac{a^3b^3c^3}{\sqrt{a^6b^6 + a^6c^6 + b^6c^6}}$$
Since $a,\ b,\ c>0$, the plugging in the positive solution for $\lambda$ will give us our max and vice versa for the min (if the function were odd, see below). Plugging $\lambda$ into our x, y, and z equations yield: $x = \pm \frac{ab^3c^3}{\sqrt{a^6b^6 + a^6c^6 + b^6c^6}}$ $y = \pm \frac{a^3bc^3}{\sqrt{a^6b^6 + a^6c^6 + b^6c^6}}$ $z = \pm \frac{a^3b^3c}{\sqrt{a^6b^6 + a^6c^6 + b^6c^6}}$ Since f is even (each variable is raised to the second power), then either the positive or negative solution will give a positive result.","['calculus', 'real-analysis', 'multivariable-calculus', 'optimization', 'lagrange-multiplier']"
1373997,Finding the area of a square that has a circle inside itself,"I tried to solve the following problem: I think the image is self-descriptive. I tried to draw a vertical line from the top-end of $\theta$ angle to the horizontal line, then tried to use the similarity of triangles to solve the problem, but with no luck. I also tried to find the area of the sector, but with no much success too.","['geometry', 'area', 'trigonometry']"
1374009,Confused about a well-ordering lemma,"I happened to stumble across the following lemma in Kenneth Kunen's set theory book: $\textbf{Lemma:}$ Let $\langle$ $A,R$ $\rangle$ be a well ordering. Then for all $x \in A$, $\langle$ $A,R$ $\rangle$ is not isomorphic to 
$\hspace {15mm}$ $\langle$ pred$(A,x,R),R$ $\rangle$. Where $A$ is a set, $R$ is a strict total order on $A$, and pred$(A,x,R)$ = { $y \in A: yRx$ } where $x \in A$. But then what if we let $A=\mathbb{N}$, $R$ be the standard greater than relation >, and $x=0$? $A$ would be the set $\{0,1,2......\}$ pred$(A,x,R)$ would be the set $\{1,2,3......\}$ I am pretty that for both sets, > is still a strict total order and every subset has a least element under this order. So couldn't we just set an isomorphism $f: A \rightarrow$ pred$(A,0,R)$ where $f(x)=x+1$? Sorry if I happen to be incredibly stupid right now but I can't spot my error.",['elementary-set-theory']
1374028,"Is $\bigcup_{n=1}^{\infty}\left ( -1+\frac{1}{n},1-\frac{1}{n} \right )$ open?","This .pdf on Example 2 (page 4 on paper), it says that $$\bigcup_{n=1}^{\infty}\left ( -1+\frac{1}{n},1-\frac{1}{n} \right )=\{0\}\cup (-1/2,1/2)\cup\dots=(-1,1)$$
is open. Please check Theorem 1 on page 3. How can this Example be open, if $\{0\}$ is closed?","['elementary-set-theory', 'general-topology']"
1374030,Algebraic proof that a set generated by irrational rotations is dense in $S^1$.,"This is exercise 1.9 in Lie Groups, Lie Algebras and Representations - Hall. Suppose $a$ is an irrational real number.  Show that the set $E_a$ of the numbers of the form $e^{2\pi i n a}$, $n \in \mathbb{Z}$, is dense in the unit circle $S_1$.  Hint: Show that if we divided $S^1$ into $N$ equally sized ""bins"" of length $2\pi/N$, there is at least one bin that contains infinitely many elements of $E_a$.  Then use the fact that $E_a$ is a subgroup of $S^1$. My proof of this proposition is as follows.  Since $a$ is irrational, you can determine that the set of rotations $E_a$ is infinite.  Since $S^1$ is compact we can find two $r_1, r_2$ that are within $\epsilon$ of each other.  Then $r_1^{-1}r_2$ is a small rotation of size $\epsilon$.  Now, $r_1^{-1}r_2$ generates rotations that are within $\epsilon$ distance of any point of $S^1$. That said, I don't believe that the hint suggested in the problem uses that technique.  My knowledge of algebra is not all that strong so I was hoping someone could shed some light on what is being suggested there.","['abstract-algebra', 'group-theory']"
1374045,Question on Radon measure's Lebesgue decomposition,"Hi all seeing as how people were so nice to me and my experience was a success I though perhaps it was safe to try and ask this as well on Radon measures (also same class) I am given a $ \sigma-finite $ Radon measure $ \mu $  on X and $ \nu \in M(X)$ a measure such that I am given the Lebesgue decomposition of $ \nu $ with respect to $ \mu $
i.e. $ \nu = \nu_1 + \nu_2 $. I am asked to prove here that $ \nu_1 $ and $ \nu_2 $ are also Radon measures. I am asked to use a previous exercise which I could actually do and it was alright for me, it was as follows (found it also on the site):
Suppose that μ is a Radon measure on X. If ϕ∈L1(μ) and ϕ≥0, then $ \nu(E)= \int_{E}\phi d\mu $ is a Radon measure.
Where I am stuck: I can understand this intuitively but for some reason can't do it. What I do know from Radon-Nikodym is that $ \nu_1 $ is mutually singular with $ \mu $ and also that $ \nu_2 << \mu $ I cannot move further. I think the hypotheses that we are dealing with $ \sigma-finite $ measure spaces is because Radon-Nikodym relies on this assumption but maybe it has a different meaning Progress: The M(X) is the space of all complex Radon measures. I can get by with showing that $ \nu_2 $ is Radon by the other exercise I told about now how do I show $ \nu_1 $ is Radon? Help please?","['real-analysis', 'general-topology', 'measure-theory']"
1374055,limit of a region of integration in $\mathbb{R}^2$ approaches a line,"I am trying to follow the derivation of derivatives in a paper published in some japanese journal but there seems to be a mistake in the proof. I will present the problem in 2D and in 2 variables so that it's easier to visualize. Let $c_1=(x_1,y_1)$ and $c_2 = (x_2,y_2)$ be two points in $\mathbb{R^2}$ which I will denote as centers. The domain will be a unit square with vertices at $(0,0),(1,1),$ etc. Define $V_1 = \{z=(x,y):\|z-c_1\| \le ||z-c_2||\}$ and $V_2 = \{z=(x,y): ||z-c_2|| \le ||z-c_1||\}$. Define the function $$G(c_1,c_2) = \displaystyle \int_{V_1}2f'(||z-c_1||^2)(x_1-z_1)\phi(z)\,dz$$ where $z = (z_1,z_2)$. For ease of notation, I will denote $h(z,c_1)=2f'(\|z-c_1\|^2)(x_1-z_1)\phi(z).$ My goal is to compute $$\frac{\partial G}{\partial{x_2}}.$$ Notice that the integrand does not depend on $x_2$ but rather $V_1$ does. So a first step in this derivation is to consider $$\Delta G=G(c_1,c_2+he_1)-G(c_1,c_2)$$ where $e_1 = (1,0)$ and $h \in \mathbb{R}$ and subsequently compute the divided difference as $h \rightarrow 0$. If $V_1' = \{z=(x,y): \|z-c_1\| \le \|z - (c_2+he_1)\|\}$ and $V_2' = \{z - (x,y): \|z-(c_2+he_1)\| \le \|z-c_1\|\}$ denote the modified regions about the shifted centers, we have that $$\Delta G = \displaystyle \int_{V_1'\cap V_2}h(z,c_1)\, dz-\int_{V_1 \cap V_2'} h(z,c_1) \,dz $$ as can be seen from, for example: . 
In the picture, the red region corresponds to $V_1' \cap V_2$ while the yellow region corresponds to $V_2' \cap V_1$. The derivative, as is presented in other sources (legitimate) but without proof is: $$\frac{\partial G}{\partial x_2} = \displaystyle \int_W \frac{x_2-z_2}{\|c_1-c_2\|}h(z,c_1) \,dz$$ where $W$ is the hyperplane $V_1 \cap V_2 = \partial V_1 \cap \partial V_2$, i.e. the common line segment of the regions $V_1,V_2.$ I am trying to do reverse engineering, i.e. trying to make sense of the result to see how to proceed with the derivation. But what throws me off is the presence of a ""unit-like normal vector"" in the form of $\frac{x_2 - z_2}{\|c_1-c_2\|}$. If it helps, it's a standard property that the vector $c_1-c_2$ is orthogonal to $\partial V_1 \cap \partial V_2$. Because of this, I've been thinking that maybe the divergence theorem could be invoked in some way but I just don't see it. I am also aware that as $h \rightarrow 0, (V_1'\cap V_2) \cup (V_2'\cap V_2) = \partial V_1 \cap \partial V_2$. Any ideas how to proceed?","['derivatives', 'calculus', 'integration']"
1374056,Tensor product of $\mathscr{O}_X$-modules which results in a presheaf.,"Background : Over a locally ringed space $X$, if we define the tensor product of two $\mathscr{O}_X$-modules $\mathscr{F}$ and $\scr{G}$ naively as $U \mapsto \mathscr{F}(U) \otimes \mathscr{G}(U)$, we won't necessarily get a sheaf and we sheafify this presheaf to get the actual definition of tensor product of two $\mathscr{O}_X$-modules. What I would like to know is what is the intuitive reason why the naive definition is not a sheaf. For example, on $\mathbb{P}^n = \mathrm{Proj}\,k[x_0,\dots, x_n]$, if we take the hyperplane $H=V(x_0)$, then $\Gamma(\mathbb{P}^n, \mathscr{O}_{\mathbb{P}^n}(1)\otimes \mathscr{O}_H) \ne \Gamma(\mathbb{P}^n, \mathscr{O}_{\mathbb{P}^n}(1))\otimes_k \Gamma(H,\mathscr{O}_H)$. This is because on the left hand side, the global section $x_0$ got killed by $\mathscr{O}_H$, but not on the right hand side. However, I have a bad intuitive understanding still of why the two sides aren't equal. Also, I would like to know about more exotic cases as well. Question : What causes the definition $U \mapsto \mathscr{F}(U) \otimes \mathscr{G}(U)$ to fail to be a sheaf? Your help is greatly appreciated!",['algebraic-geometry']
1374078,Solving Limits with L'Hospital's Rules,I am having difficulties solving this limit. I was given the question and equation: Try using L’Hospital’s Rules to evaluate the follwing limit: $$\lim\limits_{u \to \infty } \frac{u}{\sqrt{u^2 +1}}$$ How do you solve this with L'Hospital's rules? Do you solve this with them?,"['calculus', 'limits']"
1374080,Deriving simple linear regression from normal equations,"The normal equations of least squares regression
$$X \beta = Y$$
yields the solution $\beta = (X X^T)^{-1} X^T Y$. For simple (1-dimensional) regression, the solution to $\beta x_i + \alpha = y_i$ is given by $\beta = \frac{Cov(X, Y)}{Var(X)}$. Is there a way to derive the second formula from the first? When $\alpha = 0$ and the mean of $X$ and $Y$ are $0$, this is obvious. But I don't know if there's a more general derivation.","['statistics', 'linear-algebra']"
1374083,Intuition for the Cauchy-Schwarz inequality,"I'm not looking for a mathematical proof; I'm looking for a visual one. I'm having trouble understanding (in my mind's eye) why the dot product of two vectors V and W produces a scalar that is less than the length of V multiplied by the length of W. In using the dot product, we are producing a parallel vector, correct? Could we not further say that we are simply applying vector W to vector V in order to produce a vector that is the original length of V multiplied by the length of W -- thus a vector parallel to V? For example, if we let vector W be a unit vector (with length of one), then the dot product of V and W would give us a scalar that, when applied to V, produces V again. Would this not be the same as the length of V multiplied by the length of W (given that the length of W is equal to one)? For that reason, why wouldn't the dot product of V and W always be equal to the length of V multiplied by the length of W? Why would it be less (unless V = cW for any scalar c?)","['linear-algebra', 'cauchy-schwarz-inequality', 'inner-products', 'inequality']"
1374121,Is there enough information given to solve this related rates problem?,"This is the question from a practice exam: Suppose a pyramid has 4 lateral faces that are all equilateral triangles. Find the rate at which the volume of the pyramid is changing if each side of each triangle increases at a rate of 2 inches per second. Hint: The volume of a square pyramid is given by the formula $V={1\over 3}Bh$, where $B$ is the area of the base of the pyramid and $h$ is the height of the pyramid. This is the only information I am given. The answer key has just been released, so I know the answer is $16\sqrt{2}in^3/sec$, but I don't know how to get there. And then a friend (who was helping me) thought that maybe there isn't enough information. Is there enough? EDIT: I used the answer given by the key and worked out the problem. I believe that the missing information is ""Find the rate at which the volume of the pyramid is changing when the side length is 4 inches."" When I put $h$ (height) in terms of $s$ (side length), then differentiated implicitly, and plugging in $4$ for $s$ at the end, I found the solution to be ${16\cdot2\over \sqrt{2}}$, which simplifies to $16\sqrt{2}$ by rationalizing the denominator.","['calculus', 'derivatives']"
1374137,Intersection of Countably Infinite Sequence of Sets [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Suppose $\{\Omega_k\}_{k=1}^{\infty}$ is a sequence of sets, where $\Omega_k$ is countably infinite and $\Omega_{k+1}\subset\Omega_k$ for all $k$. Is it possible to show that $\cap _{k=1}^{\infty} \Omega_k$ is countably infinite?",['elementary-set-theory']
1374159,$|g(x)| \leq K \int_a^x|g| \ \ \forall x \in I$ [duplicate],"This question already has answers here : Inequality of continuous functions (3 answers) Closed 8 years ago . Let $I:=[a,b]$ and let $g: I \to \Bbb R$ be continuous on $I$. Suppose that there exists $K > 0$ such that $$|g(x)| \leq K \int_a^x|g| \ \ \forall x \in I.$$  Then $g(x) = 0\ \ \forall x \in I $. I am stuck with the problem please help!","['calculus', 'real-analysis', 'integration']"
1374163,"In a triangle, find the minimum and maximum of $\cos(A-B)\cos(B-C)\cos(C-A)$","In a triangle, with $A, B, C$ are three angles, find the minimum and maximum of $$\cos(A-B)\cos(B-C)\cos(C-A)$$",['trigonometry']
1374172,Minimum value of $a+b$,"If the graph of $f(x)=2x^3+ax^2+bx$ intersects the $x$-axis at three distinct points, then what is minimum value of $a+b$? Here $a$ and $b$ are natural numbers. My attempt: As the graph intersects the $x$-axis at three distinct points, it has $2$ local maxima/minima. Let these $2$ local maxima/minima be $x_1, x_2$. I found $f'(x)=6x^2+2ax+b$ So $x_1, x_2$ are the roots of $6x^2+2ax+b=0$ I could not solve this further. I think the minimum value of $a+b$ is $\sqrt {ab}$. Is my approach correct or is there any other method?",['calculus']
1374179,Can Monotone Class Theorem be easier to check than $\pi$-$\lambda$ Theorem?,"I've been working on problem 14.4 in Billingsley's ""Probability and Measure"", which says: ""Let $C$ be the set of continuity points of $F$. Show that for every Borel set $A$, $P(F(X) \in A, X \in C)$ is at most Lebesgue measure of $A$."" They also defined $\phi(u) = \inf \{x: F(x) \geq u \}$ in the chapter. My instinct was to use the $\pi$-$\lambda$ system. I let the $\pi$ system be
\begin{align}
\mathcal{P}=\{(0,v)|v\in(0,1)\}
\end{align}
and showed that 
\begin{align}
P(F(X) \in (0,v), X \in C) = P(X \leq \phi^-(v), X \in C) = F(\phi^-(v)) \leq v=\lambda(0,v)
\end{align}
for all $v \in (0,1)$. However, I got stuck when I tried to prove that \begin{align}
\mathcal{L} = \{A \in \mathcal{B}(0,1) | P(F(X) \in A, X \in C) \leq \lambda(A) \}
\end{align} is a $\lambda$ system. Specifically, I'm having trouble with checking that
\begin{align}
A, B \in \mathcal{L}, A \subset B \implies B \setminus A \in \mathcal{L}
\end{align} Knowing that $P(F(X) \in A, X \in C) \leq \lambda(A)$ and $P(F(X) \in B, X \in C) \leq \lambda(B)$ doesn't seem to be enough to conclude that $P(F(X) \in B \setminus A, X \in C) \leq \lambda(B \setminus A)$. The book's solution involved checking that $P(F(X) \in (u,v), X \in C) \leq v-u$, showing that $\{\text{finite disjoint unions of }[u,v)|0\leq u<v <1 \}$ forms a field, and using Halmos' Monotone Class Theorem. Could anyone please point out what I did wrong? I'm surprised that it's so much harder to solve this problem using $\pi$-$\lambda$ Theorem because I thought they were equivalent. Thank you in advance!","['probability-theory', 'probability', 'measure-theory']"
1374182,A lower bound for an arithmetic function,"Let $N \in \mathbb{N}$ such that $\phi(N) \sim N$, where $\phi$ is the Euler's totient function. Let $A \subset [N] := \{1, 2, \ldots, N\}$. For $n \in \mathbb{N}$ define the function
$$
C_A(n) = \#\{ k \in [N] \mid (k, n) = 1 \text{ and } k \in A\}.
$$
In particular $C_A(1) = \#A$. Assuming that $\#A \sim N$, can we give a good lower bound to the sum
$$
S_A(N) = \sum_{d \mid N} C_A(d)
$$
in terms of $\#A$ and $N$? Note that $C_A(n) \leq C_A(d)$ whenever $d \mid n$; hence we can get a lower bound
$$
S_A(N) \geq \#A + (\tau(N)-1) C_A(N),
$$
where $\tau(N)$ is the number of distinct divisors of $N$ (pull out the term with $d = 1$ and use the inequality on the remaining terms). Since $\#A \sim N$ and $\phi(N) \sim N$, it is to be expected that $C_A(N) > 0$. Nevertheless this bound seems crude to me. I think there should be something better (preferably only in terms of $\#A$ and $N$ if this is possible). Update: Greg Martin's answer made me realize that things could be generalized a little. Proposition: Let $N \in \mathbb{N}$ and let $A \subseteq [N] := \{1, \ldots, N\}$. 
 Let $D$ be a subset of the positive divisors of $N$. 
 Write $\#A = \delta(N)N$ and $\phi(N) = r(N)N$ for some functions $\delta, r : \mathbb{N} \to (0, 1]$. If $\delta(N) + r(N) > 1$, then 
$$
\sum_{d \in D} C_A(d) >  N\sum_{d \in D} \dfrac{\phi(d)}{d} - \#D \phi(N).
$$
In particular, if $\delta(N) \sim \delta$ is a constant and $r(N) \sim 1$, then the above inequality holds for all such $N$ large enough. Proof: Observe that
 \begin{align*}
 C_A(d) &= N \dfrac{\phi(d)}{d} - \#\{\text{integers coprime to $d$ but not in $A$}  \}\\
 & \geq N\dfrac{\phi(d)}{d} - \#\{\text{integers in } [N] \text{ not in } A\}\\
 &= N\dfrac{\phi(d)}{d} - (N - \#A). 
 \end{align*}
 Thus
 \begin{align*}
 \sum_{d \in D} C_A(d) \geq N \sum_{d \in D} \dfrac{\phi(d)}{d} - \#D(N - \#A).
 \end{align*}
 Now the result follows by noticing that 
 $$
 \#D(N - \#A) = \#DN(1 - \delta(N)) < \#DNr(N) = \#D\phi(N).
 $$ QED Question: When can we guarantee that $C_A(N) > 0$? In the case that $r(N) \sim r$ and $\delta(N) \sim \delta$ are constants such that $r + \delta \leq 1$, can we get a similar result? That is can we show there exists a subset $D$ of divisors of $N$ for which the inequality of the proposition is satisfied? Note that in the proof I merely used the fact that $C_A(d) \geq N\dfrac{\phi(d)}{d} - (N - \#A)$ on every single divisor $d \in D$. This seems crude to me and I think could be improved.","['prime-numbers', 'number-theory', 'fourier-analysis', 'analytic-number-theory', 'mobius-inversion']"
1374189,Reference for differentiation of an integral over variable ball,"I am looking for a reference for a 'well-known' formula in $\mathbb{R}^d$:
$$ 
\frac{d}{dr} \int_{\lVert x\rVert\leq r} f(x)dx=
\int_{\lVert y\rVert=r} f(y)dS(y),
$$
where $dS$ is the Lebesgue surface measure on $\mathbb{R}^{d-1}$. For $d=3$, it is a particular case of the Reynolds transport theorem, however, how is it called or where was it formulated for other dimensions? Clearly, the question is not about the proof, it is more or less straightforward, but about any reference only. By the way, what is about the 'maximum' class of functions, for which this formula does hold? $L^1_{\mathrm{loc}}(\mathbb{R}^d)$ ?","['derivatives', 'reference-request', 'spherical-coordinates', 'integration']"
1374194,Trigonometric equation with sine and cosine,"So the equation is $3\cos ^2t + 5\sin t = 1$ Now I have simplified this to $$3(1-\sin ^2t) + 5\sin t -1 = 0$$
which leads to $$-3\sin ^2t + 5\sin t + 2 = 0$$
Then I get $$-3t^2 + 5 t +2 = 0$$ Is this the correct way to go with this equation then use $t = t/2 \pm \sqrt {(t/2)^ 2 + y}$ where $y$ in this case will be $2/3$ ?",['trigonometry']
1374218,Prove that given a triangle satisfying $8\prod \sin\frac{A}{2}=\prod \cos(A-B)$ then that triangle is equilateral.,Prove that given a triangle $ABC$ satisfying $$8 \sin\frac{A}{2}\sin\frac{B}{2}\sin\frac{C}{2} = \cos(A-B)\cos(B-C)\cos(C-A)$$ then that triangle is equilateral.,['trigonometry']
1374231,"When $f(x+1)-f(x)=f'(x)$, what are the solutions for $f(x)$?","The question is: When $f(x+1)-f(x)=f'(x)$, what are the solutions for $f(x)$? The most obvious solution is a linear function of the form $f(x)=ax+b$. Is this the only solution? Edit I should add that $f:\mathbb R\to\mathbb R$ to the question.","['real-analysis', 'ordinary-differential-equations', 'delay-differential-equations']"
1374248,"What makes a differential equation, linear or non-linear? [duplicate]",This question already has answers here : Linear vs nonlinear differential equation (6 answers) Closed 7 years ago . Among these differential equations why one is linear while other is non-linear? What is criteria to find out whether a differential equation is linear or non-linear?,"['ordinary-differential-equations', 'differential']"
1374258,On a unique(?) binomial property of $3003$,"Given the triangular number , $$T_k = \frac{k(k+1)}{2}$$ and remembering that, $$\binom{n}{m}=\binom{n}{n-m}$$ Excluding $a_0=1$, we then have the six-fold (at least) equalities, $$\begin{aligned}
a_1&=\binom{a_1}{1}=\binom{16}{2}=\binom{10}{3}=T_{15}=120\\[1.5mm]
a_2&=\binom{a_2}{1}=\binom{21}{2}=\binom{10}{4}=T_{20}=210\\[1.5mm]
a_3&=\binom{a_3}{1}=\binom{56}{2}=\binom{22}{3}=T_{55}=1540\\[1.5mm]
\color{blue}{a_4}&=\binom{a_4}{1}=\binom{78}{2}=\binom{15}{5}=\binom{14}{6}=T_{77}=\color{blue}{3003}\\[1.5mm]
a_5&=\binom{a_5}{1}=\binom{120}{2}=\binom{36}{3}=T_{119}=7140\\[1.5mm]
a_6&=\binom{a_6}{1}=\binom{153}{2}=\binom{19}{5}=T_{152}=11628\\[1.5mm]
a_7&=\binom{a_7}{1}=\binom{221}{2}=\binom{17}{8}=T_{220}=24310\\[1.5mm]
\color{blue}{a_8}&=\binom{a_8}{1}=\binom{104}{39}=\binom{103}{40}\neq T_k\, \approx\, 6.12\times10^{28}\\[1.5mm]
\color{blue}{a_9}&\overset{\color{red}?}{=}\binom{a_9}{1}=\binom{714}{272}=\binom{713}{273}\neq T_k\, \approx\, 3.53\times10^{204}\\
\end{aligned}$$ (Assuming Weger and Noe's results are conclusive, then there is no other $T_k$ with $k<3.49\times 10^{14}$ in this list.) Questions: The first eight $a_i$ is A003015 . Since $a_9$ is so big, is it really the ninth, or is there a smaller term? The terms $a_4, a_8, a_9$ belong to an infinite family involving Fibonacci numbers , $$a_i = B(m)=\binom{F_{2m} F_{2m+1}}{F_{2m-1}F_{2m}-1}$$  Other than $a_4=3003$, is there another triangular number in this family? (I checked that $B(5) \approx 4.59\times10^{1411}$ is not triangular, but $B(6)$ seemed already too big for my computer.)","['computational-mathematics', 'number-theory', 'binomial-coefficients', 'fibonacci-numbers']"
1374292,Trace $\sigma$-algebra and measurable envelope,"I'm stuck on a problem from Cohn's book. Let $(X,\mathscr{A})$ a measurable space, and let $C$ be a subset of $X$. Let $\mathscr{A}_C$ be the trace of $\mathscr{A}$ on $C$, that is all the subsets $B$ of $C$ of the form $B=A\cap C$ for $A\in \mathscr{A}$. 
  Now suppose that $\mu$ is a finite measure on $(X,\mathscr{A})$. Let $C_1$ a set that belongs to $\mathscr{A}$, and satisfies $\mu(C_1)=\mu^*(C)$. Show that if $A_1$ and $A_2$ belong to $\mathscr{A}$ and satisfy $A_1\cap C=A_2\cap C$, then $\mu(A_1\cap C_1)=\mu(A_2\cap C_1)$. The only idea I have had is showing $\mu^*(C_1\setminus C)=0$. But I think this is not true.  There exists a subset $E$ of $[0,1]$ such that $\lambda^*(E)=1=\lambda^*(E^c)$. Letting $C=E$ and $C_1=[0,1]$, $$\lambda^*(E)=1=\lambda([0,1]) \text{    and   }  \lambda^*([0,1]-E)=\lambda^*(E^c)=1\not=0$$ Since the Lebesgue measure is finite in the unit interval, it's not always true that $\mu^*(C_1\setminus C)=0$. So the solution it have to be in other direction. I'd appreciate if someone can help me.","['self-learning', 'real-analysis', 'measure-theory']"
1374308,K-theory of projective space,"Is there any way to prove that the twisting sheaves $\mathcal{O}(K)$ generate the algebraic K-theory of projective space without actually using any K-theory machinery (e.g. Bott periodicity)? Like for example, just being able to write down a resolution by powers of twisting sheaves. I know that arbitrary coherent sheaves on projective space are hard to get a handle of, so it might not be possible, but it would be helpful.","['projective-space', 'coherent-sheaves', 'algebraic-geometry', 'algebraic-k-theory']"
1374321,Solve $10x^4-7x^2(x^2+x+1)+(x^2+x+1)^2=0$,How to solve the following equation? $$10x^4-7x^2(x^2+x+1)+(x^2+x+1)^2=0$$ My attempt: $$ 10x^4 - (7x^2+1)(x^2+x+1)=0$$ Thats all i can Update Tried to open brakets and simplify: $$(7x^2+1)(x^2+x+1) = 7x^4+7x^3+7x^2+x^2+x+1=7x^4+7x^3+8x^2+1 $$ $$10x^4 - (7x^2+1)(x^2+x+1)= 3x^4-7x^3-8x^2-1=0 $$,"['polynomials', 'quartics', 'algebra-precalculus']"
1374347,Which permutations of $\mathbb{C}$ commute with the Riemann zeta function?,"I'm trying to figure out whether the permutations of $\mathbb{C}$ which commute with the Riemann $\zeta$ function are necessarily continuous or not. Obviously both the identity and the complex conjugation do the job, but is there another example?
Thanks in advance.","['number-theory', 'complex-analysis']"
1374369,"Given $\tan A + \tan B = 3x$ and $\tan A \tan B = 2x^2$, find $\tan A - \tan B$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Given $$\tan A + \tan B = 3x$$ and $$\tan A \tan B = 2x^{2},$$ how can one find $\tan A - \tan B$? I have tried substitution, but failed to find the answer. Edit: Can this problem be solved using the formulas for sums and differences of tangents?","['algebra-precalculus', 'trigonometry']"
1374384,Fundamental solution for a parabolic PDE with costant coefficents,"as it is well known, the fundamental solution of the heat equation is the function $G(t,x)=\frac{1}{(4\pi t)^{n/2}}e^{\frac{|x|^2}{4t}}$, for all $t>0,x\in\mathbb{R}^n$. I wonder if exists (and if you have same references) a similar explicit formula for the fundamental solution for a parabolic PDE with constant coefficents.","['analysis', 'fundamental-solution', 'functional-analysis', 'partial-differential-equations']"
1374404,"Solve $\sin A +\sin 2A +\sin 3A + \sin 4A = 0$, for $0 \leq A \leq 180$","I've tried using factor formula but still did not manage to get the answer, not sure if factor formula is the right method. I rearrange to $\sin 4A + \sin 2A + \sin 3A + \sin A = 0$, and after applying factor formula, $2 \sin 3A \cos A + 2 \sin 2A \cos A = 0$ $2 \cos A ( \sin 3A + \sin 2A) = 0$ $2 \cos A ( \sin \frac{5}{2} A \cos \frac{1}{2} A) = 0$ Then I'm stuck..","['algebra-precalculus', 'trigonometry']"
1374432,"Norm bound on exponential matrix with eigenvalue negative real part, proof","If $A$ is $n \times n$ with negative real parts of all eigenvalues, then there exists positive $K,\alpha$ such that $$\|e^{At}\| \leq Ke^{-\alpha t}$$ Furthermore, if an eigenvalue has negative part zero, but with single multiplicity, then there exists $M > 0$ such that $$\|e^{At}\| \leq M$$ Starting out: We have $e^{At} = Pe^{Jt}P^{-1}$, so $\|e^{At}\| \leq \|P\|\|e^{Jt}\|P^{-1}\| = K_1\|e^{Jt}\|$ since $P$ is invertible etc. I'm not sure how you bound the norm of the exponential Jordan matrix here. The book (Sze-Bi Hsu's ODE book) sort of just states that it's bounded somehow.","['linear-algebra', 'ordinary-differential-equations']"
1374440,Distance between a point and an empty set: meaning and value?,"On page 253 in General Topology by R Engelking: The distance $\rho(x, A)$ from a point $x$ to a set $A$ in a metric space $(X,\rho)$ is defined by letting $\rho(x, A) = \text {inf}\ {\{\rho(x, a) : a \in A}\},\ \text {if}\ A \ne \emptyset, \text {and}\ \rho(x, \emptyset) = 1$. Why $\rho(x, \emptyset) = 1$? I mean: 1- What $\rho(x, \emptyset)$ means? 2- Why it is equal to $1$?","['metric-spaces', 'general-topology']"
1374442,Direct Integral: Dimension,"Direct Integral Given a Borel space $\Omega$ with measure $\mu$. Given Hilbert spaces $\mathcal{h}_x$ for $x\in\Omega$; set $\mathcal{h}:=\bigcup_{x\in\Omega}\mathcal{h}_x$. Regard the function space
$$\mathcal{F}(\Omega,\mathcal{h}):=\{\varphi:\Omega\to\mathcal{h}:\varphi(x)\in\mathcal{h}_x\}$$ with algebraic structure
$$(\varphi+\psi)(x):=\varphi(x)+\psi(x)\quad(\lambda\varphi)(x):=\lambda\varphi(x)$$ as well as the structure
$$\langle\varphi,\psi\rangle(x):=\langle\varphi(x),\psi(x)\rangle_x\quad\|\varphi\|(x):=\|\varphi(x)\|_x.$$ Suppose one has
$$\mathcal{S}(\Omega,\mathcal{h})\leq\mathcal{F}(\Omega,\mathcal{h}):\quad\mathcal{\overline{\langle\pi_x\mathcal{S}\rangle}}=\mathcal{h}_x\bmod\mu$$ made of integrables
$$\sigma\in\mathcal{S}(\Omega,\mathcal{h}):\quad\int_\Omega\|\sigma\|^2\mathrm{d}\mu<\infty\quad(\|\varphi\|\in\mathcal{B}(\Omega)).$$ Define the measurables
$$\mathcal{B}(\Omega,\mathcal{h}):=\left\{\varphi\in\mathcal{F}(\Omega,\mathcal{h}):\varphi\in\overline{\mathcal{S}(\Omega,\mathcal{h})}\right\}.$$ Note for measurability:
$$\|\varphi\|(x)=\|\varphi(x)\|=\|(\lim_n\sigma_n)(x)\|\\=\|\lim_n\sigma_n(x)\|=\lim_n\|\sigma_n(x)\|=\lim_n\|\sigma_n\|(x).$$ Define the integrables
$$\mathcal{H}(\Omega,\mathcal{h}):=\left\{\varphi\in\mathcal{B}(\Omega,\mathcal{h}):\int_\Omega\|\varphi\|^2\mathrm{d}\mu<\infty\right\}.$$ Moreover it holds:
$$\mathcal{S}\leq\mathcal{F}\implies\mathcal{B}\leq\mathcal{F}\implies\mathcal{H}\leq\mathcal{F}.$$ Concluding direct integral. Dimension Suppose one finds:
$$\mathcal{A}\subseteq\mathcal{H}:\quad\overline{\pi_x\mathcal{A}}=\mathcal{h}_x\bmod\mu\quad(\#\mathcal{A}\leq\mathfrak{n})$$ Then one obtains:
  $$n\in\mathbb{N}:\quad\{\dim\mathcal{h}_x=n\}\in\mathcal{B}(\Omega)$$ How can I prove this? (Ideas?)","['measure-theory', 'functional-analysis', 'hilbert-spaces', 'integration', 'lebesgue-integral']"
1374471,Show that $f$ is a homomorphism.,"There is a group $G$ of order $p^3$, where $p>2$. Show that $f:G\rightarrow Z(G) $ with $f(x)=x^p$ is a homomorphism. My attempt: Case a): Suppose $|Z(G)|=p^3$. Then $G=Z(G)$, so $G$ is abelian, and $(x_1x_2)^p=x_1^px_2^p$ is obvious. Case b): Suppose $|Z(G)|=p^2$. Then  $|G/Z(G)|=p$ and is cyclic, so $G$ itself is abelian, which implies that $|G|=|Z(G)|=p^3$. Contradiction. Case c): Suppose $|Z(G)|=p$. Then $|G/Z(G)|=p^2$, so $G/Z(G)\cong\mathbb{Z_p}\times\mathbb{Z_p}$(otherwise $G/Z(G)$ is cyclic and $G$ is abelian. So... I don't even think that it is possible to finish my solution. It seems that there is better one, but this is just my unlucky try.","['abstract-algebra', 'group-theory', 'finite-groups']"
1374490,Evaluate $a^2+b^2+c^2$,"I found this questions from past year maths competition in my country, I've tried any possible way to find it, but it is just way too hard. If $a, b, c$ are distinct numbers such that $a^2 - bc = 2014$, $b^2 + ac = 2014$, $c^2 + ab = 2014$. Then compute $a^2 + b^2 + c^2$ (A)$4030$ (B)$4028$ (C)$4026$ (D)$4000$ (E)$2014$ Adding these three equations together $$a^2 + b^2 + c^2 + ab + ac - bc = 3\times2014  \quad(1)$$ And also found that \begin{align}
(a-b-c)^2 &= a^2 + b^2 + c^2 - 2ab - 2ac + 2bc\\
(a-b-c)^2 &= a^2 + b^2 + c^2 - 2(ab + ac - bc)\\
\end{align} I don't know how to continue to reduce $ ab + ac - bc$, or am I using the wrong way to reducing it? I'm very appreciate for those who have helped me to hint/explain me on how to do all these questions (I'm currently 10th grade (in US grade system), so I don't understand these much, all of these are outside my syllabus)","['contest-math', 'systems-of-equations', 'algebra-precalculus']"
1374518,Triangular number method - Hilbert's hotel,"There is a hotel with and infinite number of numbered rooms, each occupied by a single guest. An train with an infinite number of (numbered) coaches, each with an infinite number of (numbered) seats, each occupied by a person, arrives at the hotel. Can you find space for all these people? One method, suggested on Wikipedia, is the triangular number method : Those already in the hotel will be moved to room $(n^2+n)/2$, or the nth triangular number. Those in a coach will be in room  $((c+n)^2+c+n)/2$, or the $(c+n-1)$ triangular number, plus $(c+n)$. In this way all the rooms will be filled by one, and only one, guest. So the person who's in room $1$, stays in room $1$. The person in room $2$, moves to room $3$. The person in room $3$ moves to room $6$, and so on. What about the new guests? If they are moved to room $((c+n)^2+c+n)/2$, can't that still be a triangular number and hence already occupied?",['elementary-set-theory']
1374536,Orbits form a manifold?,A prominent example are the coadjoint orbits $O_x = \{Ad_u^*(x);u \in G\}$ where $x \in \mathfrak{g}$ and $G$ a Lie group with Adjoint map $Ad.$ Could anybody give me an easy argument why $O_x$ is a smooth manifold?,"['differential-topology', 'lie-groups', 'differential-geometry', 'lie-algebras']"
1374551,"$f(x) =ax^6 +bx^5+cx^4+dx^3+ex^2+gx+h $, find $f(7)$.","Problem : Given a polynomial $f(x) =ax^6 +bx^5+cx^4+dx^3+ex^2+gx+h$ such that $f(1)= 1, f(2) =2 , f(3) = 3, f(4) =4, f(5)=5, f(6) =6$ . Find $f(7)$ in terms of $h$ . My approach: We can put the values of $f(1) = 1$ in the given equation and $f(2) = 2$ , etc. But this is quite time consuming by making six different equations and then solve them to get the values of $a,b,c,d,e,g,h$ .  Please suggest some alternate solution for this.","['polynomials', 'algebra-precalculus', 'functions']"
1374552,Number of divisors of the form $(4n+1)$,"Find the number of divisors of $$2^2\cdot3^3\cdot5^3\cdot7^5$$ which are of the form $(4n+1)$ I know how to find the total number of divisors. But, to find the number of divisors of the form $(4n+1)$, I'm thinking of listing down the divisors and then finding, but that'd be very tedious. Is there any elegant way to do this? Any help will be appreciated. Thanks.","['elementary-number-theory', 'algebra-precalculus', 'combinatorics']"
1374609,"Identities involving binomial coefficients, floors, and ceilings","I found the following four apparent identities:
$$
\begin{align}
\sum_{k=0}^n
  2^{-\lfloor\frac{n+k}{2}\rfloor}
     {\lfloor\frac{n+k}{2}\rfloor\choose k}
&=
\frac{4}{3}-\frac{1}{3}(-2)^{-n},\\
\sum_{k=0}^n
  2^{-\lceil \frac{n+k}{2}\rceil }
     {\lfloor\frac{n+k}{2}\rfloor\choose k}
&=
1,\\
\sum_{k=0}^n
  2^{-\lfloor\frac{n+k}{2}\rfloor}
     {\lceil \frac{n+k}{2}\rceil \choose k}
&=
2-2^{-n},\\
\sum_{k=0}^n
  2^{-\lceil \frac{n+k}{2}\rceil }
     {\lceil \frac{n+k}{2}\rceil\choose k}
&=
\frac{4}{3}-\frac{1}{3}(4)^{-\lfloor\frac{n}{2}\rfloor}.
\end{align}
$$
I want to know how to prove them. I also want to know whether they have  (after multiplying both sides by $2^n$) nice combinatorial interpretations.",['combinatorics']
