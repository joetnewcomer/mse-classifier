question_id,title,body,tags
4585420,Tangent to a graph through an exterior point,"Say you are given $f(x) = 5x^2$ and you want to find a tangent line to $f$ that goes through $P(0|-10)$ . The two options you have is using the tangent line equation, $t(x) = f'(a) \cdot (x - a) + f(a)$ and the point slope form, $t(x_1) - t(x_2) = m(x_1 - x_2)$ . Both lead to $$t(x) = 10\sqrt{2}x - 10$$ and $$t(x) = -10\sqrt{2}x - 10$$ after setting $t(0) = -10$ . Now, is there a way to find these by using $t(x) = mx + k$ ? You could use that without any problems if the point was on the graph of f, but here, it seems like you will have: $$t(x) = mx + k$$ now $m$ = $f'(a)$ where $a$ is the x-coordinate of the point that touches $f$ $$t(x) = 10ax + k$$ $$t(0) = -10 \implies k = -10$$ $$\implies t(x) = 10ax - 10$$ From here on, we would need to find $a$ , but we can't set $t(0) = -10$ again because that would just give a true statement. So it seems like you can't use $t(x) = mx + k$ here. Q: Now, how to notice when you can use $t(x) = mx + k$ and when you cannot, without having to try? Is the case where the point isn't on the graph of $f$ an exception and you can use $t(x) = mx + k$ everywhere else?","['calculus', 'functions', 'algebra-precalculus', 'tangent-line']"
4585460,Isaacs Character Theory - exercise 4.11,"I am trying to prove the following statement from Isaac's ""Character theory of finite groups"": Let $G$ be simple and let $S \in \operatorname{Syl_{2}}(G)$ be elementary abelian; $|S| = q.$ Suppose $S = C_{G}(x) \; \forall x \in S; x \neq 1.$ Show that $\nu_{2}(\chi) = 1 \; \forall \; \chi \in \operatorname{Irr}(G)$ and that $\chi(x) = \chi(1) - q$ for $\chi \neq 1_{G}$ and $x \in S$ with $x \neq 1$ . I have a few questions about this problem. I would like to say in advance that I wouldn't really like to apply the classification of simple groups to solve this problem. I tried to start the proof like this: Let $t$ be the number of involutions of the group $G$ . Take an arbitrary involution $g\in S$ . Then $$C_{G}(g) = S \Rightarrow t \geq \frac{|G|}{|C_{G}(g)|} = \frac{|G|}{q}.$$ It's not difficult to understand that in the group $G$ there are only involutions and elements of odd order. Indeed, let $x$ be an element of even order unequal to $2$ . Let $|x| = k$ . Then $x^{\frac{k}{2}}$ is an involution and $C_{G}(x^{\frac{k}{2}})$ is an elementary Abelian Sylow $2$ -subgroup of $G$ . But $x\in C_{G}(x^{\frac{k}{2}})$ is a contradiction. $\textbf{Question №1:}$ how to prove that the number of involutions are exactly $\frac{|G|}{q}$ ? It's clear that it's enough, taking into account the arguments presented above, to count the various elements of all the Sylow $2$ -subgroups. But as for me, it's quite difficult. To understand why $\nu_{2}(\chi) = 1\; \forall\;\chi\in \operatorname{Irr}(G)$ it's enough to show that $\nu_{2}(\chi) > 0 \; \forall\;\chi\in \operatorname{Irr}(G).$ Let's say we proved that the number of involutions is exactly $\frac{|G|}{q}.$ Let $\chi \in \operatorname{Irr}(G).$ Then $$\nu_2(\chi) = \frac{1}{|G|}\sum\limits_{g \in G}\chi(g^{2}) = \frac{1}{|G|}(\frac{|G|}{q} + 1)\chi(1) + \frac{1}{|G|}\sum\limits_{g \in G; |g| > 2}\chi(g^{2}).$$ Since $G$ is a simple group, then $Z(\chi) = Z(G/\ker\chi)= Z(G) = 1.$ This means that only an unit element can correspond to a diagonal matrix. $\textbf{Question №2:}$ How to prove using the above facts that $\nu_{2}(\chi) >0$ ? Using the above facts, I tried to make an estimate for $\nu_2(\chi)$ (to be more precise for this expression: $\sum\limits_{g \in G; |g| > 2}\chi(g^{2})$ ). However, each time I got it too rough, because of which I could not prove that $\nu_{2}(\chi)>0$ . Any help?","['representation-theory', 'simple-groups', 'abstract-algebra', 'sylow-theory', 'group-theory']"
4585519,Doubt regarding application of pigeonhole principle in the proof of sunflower lemma.,"In extremal combinatorics,there is a theorem called sunflower lemma: Let $\mathcal F$ be a family of non-empty $s$ -subsets of a set $X$ .If $|\mathcal F|>s!(k-1)^s$ then $\mathcal F$ contains a sunflower with $k$ -petals. I should give the definitions of the terminologies used in the statement.Here they are: Definition(Sunflower): A sunflower with $k$ -petals and a core/kernel $Y$ is a collection of sets $S_1,S_2,...,S_k$ such that $S_i\cap S_j=Y$ for all $i\neq j$ .The sets $S_i\setminus Y$ are called petals and are required to be non-empty.However the core can be empty. Having stated the theorem,let us take a look at the proof of the theorem: Proof: The proof uses induction on $s$ . When $s=1$ let $|\mathcal F|>1!(k-1)^1=k-1$ .Then $\mathcal F$ contains at least $k$ singletons,which are disjoint and hence form a sunflower with $k$ -petals with empty core. Now take $s\geq 2$ and let the result hold for sets of cardinality $\leq s-1$ . Now,take a maximal family of pairwise disjoint members of $\mathcal F$ say $\mathcal A=\{A_1,...,A_t\}$ If $t\geq k$ then there is a sunflower with $k$ -petals and empty core. So assume $t\leq k-1$ . Let $B=A_1\cup...\cup A_t$ ,then $|B|\leq st\leq s(k-1)$ . By maximality of $\mathcal A$ , $B$ intersects any member of $\mathcal F$ . By pigeonhole principle, $\exists x\in B$ such that $x$ is in at least $\frac{|\mathcal F|}{|B|}$ members of $\mathcal F$ . $(\color{red}{\text{How does pigeonhole apply and why will this number be an integer?}})$ .Note that $\frac{|\mathcal F|}{|B|}>\frac{s!(k-1)^s}{s(k-1)}=(s-1)!(k-1)^{s-1}$ . Name the collection of these members of $\mathcal F$ to be $\mathcal C$ . Let, $\mathcal F_x=\{S\setminus \{x\}:x\in S,S\in \mathcal F\}$ ,then $|\mathcal F_x|=|\mathcal C|=(s-1)!(k-1)^{s-1}(\color{red}{\text{Why does cardinality equal to this number?}})$ So,by induction hypothesis,this $\mathcal F_x$ contains a sunflower of $k$ -petals so that $\mathcal C$ forms a sunflower with $k$ -petals. I have doubts in the two lines marked above and the queries are also mentioned.Can someone give me some analogy or a concrete example of: $(1)$ How pigeonhole principle applies here and why is the quotient an integer? $(2)$ Why is $|\mathcal C|$ equal to that quantity?","['proof-explanation', 'pigeonhole-principle', 'extremal-combinatorics', 'combinatorics', 'discrete-mathematics']"
4585563,Bounding the expected number of samples without replacement to select items with given non-uniform probability distributions,"We have a set $S$ of $n$ items $i_1, i_2, \ldots, i_n$ that we select and remove (i.e., without replacement) from $S$ in a sequential fashion. The probability to select each of them at the beginning of the process is known and respectively equal to $p_1, p_2, \ldots, p_n$ , where for each $j\in\{1,2,\ldots, n\}$ there exists a positive integer $n_{j}$ such that $p_j=\frac{n_{j}}{2n}$ where $1\le n_{j} \le n$ . Without loss of generality, assume $p_1\ge p_2\ge \ldots \ge p_n$ . Let $S_t$ be the set of items at trial $t$ , i.e., after having selected (and removed) $t-1$ items. The probability to select each item $i_j\in S_t$ at trial $t$ is equal to $\frac{p_j}{\sum_{k\in S_t} p_k}$ . Question(s): Let $K_j\in\{1,2,\ldots,n\}$ be the unique trial where $i_j$ is selected. Let $M_j\in\{1,2,\ldots,n\}$ be the first trial where $i_1, i_2,\ldots, i_j$ are all selected. Can we prove or disprove that there are two positive constants $\alpha$ and $\beta$ (independent of $n$ and the given probabilities $p_k$ for $1\le k\le n$ ) such that the following bounds hold? $$\mathbb{E}[K_j],\mathbb{E}[M_j]\in\left[\frac{\alpha}{p_j},\frac{\beta}{p_j}\right]$$ Note: This question originated from a discussion (for a general version of this problem) in Probabilistic problem on sampling items without replacement with different probabilities and it is a more general version of Bounding the expected number of samples to select items with different probabilities and combinatorial constraints .","['probability-distributions', 'stochastic-processes', 'combinatorics', 'discrete-mathematics', 'probability']"
4585582,A.e. inequality from integral inequality,"Suppose that for some measurable real-valued function $f$ , $$\int_A fdm \leq C,$$ where $m$ is a probability measure, for all Borel $A$ , with $C$ being a constant not depending on the sets $A$ . Does this imply that $f\leq C$ $m$ -a.e.? A similar results states that if $\int_A fdm = \int_A gdm,$ then $f= g$ $m$ -a.e. (e.g. Is $f=g$ almost everywhere if their integrals over any subset are the same? ), but I believe one cannot simply extend this result to this problem. I made an attempt by considering sets like $A_n = \{x:f(x) - 1/n \leq C\}$ , so that one wants to show that $m(\cup A_n)=1$ , but I wasn't able to going forward meaningfully. Also, what if e.g. $m$ has a density, $f$ is continuous or anything? Is this result true at least in some cases? Any book that might contain this sort of results? Any help is appreciated.","['probability-theory', 'probability', 'real-analysis']"
4585593,Minimum number of subsets required to satisfy a condition,"Consider the set $[n]=\{1,2,\cdots,n\}$ , and consider a family of subsets of this set, satisfying the following condition: $$\forall \ i,j,k \in[n], i\ne j,j\ne k,i\ne k$$ there exists a subset $A$ in this family such that $i,j\in A$ , and $k \notin A$ . What is the minimum size of such a family? I very strongly feel it's equal to $O(log(n)^2)$ , but am not able to prove this. Thanks in advance","['recreational-mathematics', 'combinatorics', 'extremal-combinatorics', 'discrete-mathematics']"
4585599,"$\int_{0\leq v\leq 2\pi,-1\leq t\leq 1}f(at+\sqrt{1-t^2}(b\cos v+c\sin v))dtdv=2\pi\int_{-1}^{1}f(u\sqrt{a^2+b^2+c^2})du$","Suppose $a, b, c$ are given real numbers, such that all of them are not zero. Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a continuous function on $[-\sqrt{{a}^{2}+{b}^{2}+{c}^{2}},\sqrt{{a}^{2}+{b}^{2}+{c}^{2}}]$ , prove that $$\int_{0\leq v\leq 2\pi,-1\leq t\leq 1}f(at+\sqrt{1-t^2}(b\cos v+c\sin v))dtdv=2\pi\int_{-1}^{1}f(u\sqrt{a^2+b^2+c^2})du$$ I have noticed that $$LHS=\int_{0\leq v\leq 2\pi,-1\leq t\leq 1}f(at+\sqrt{1-t^2}\sqrt{{b}^{2}+{c}^{2}}\mathrm{sin}(v+\alpha ))dtdv$$ $$={\int }_{-1}^{1}({\int }_{0}^{2\pi }f(at+\sqrt{1-t^2}\sqrt{{b}^{2}+{c}^{2}}\mathrm{sin}\left(v+\alpha \right))dv)dt$$ (By Fubini's theorem) $$={\int }_{-1}^{1}({\int }_{0}^{2\pi }f(at+\sqrt{1-t^2}\sqrt{{b}^{2}+{c}^{2}}\mathrm{sin}v)dv)dt$$ (Since $f(x+2\pi)=f(x)$ )
But then what can be done to complete the proof?","['multivariable-calculus', 'calculus', 'definite-integrals']"
4585620,How many real square roots can a real invertible matrix have?,"Let A be a real square matrix nxn. The real matrix B with the size nxn is considered to be a square root of a matrix A if A=B*B. So I wonder, how many different real square roots can an invertible real matrix have. I know there can be 0 square roots. If a matrix has a negative determinant, it cannot have square roots. I also know that a matrix can have infinitely many square roots. The example is an identity matrix of a size 2x2. Also a matrix can have exactly 2^n square roots. The example is any positive definite matrix. Generally, if a matrix has a finite amount of square roots, it has to be even, since for every square root matrix B, the matrix -B is also a square root. So the question is, are there any other options? I need the answer to prove another theorem, the link is here Prove that there is no isomorphism between groups of matrices of a size n with determinant 1 and matrices of a size n with determinant +1/-1 If it turns out these are all the options, the theorem is proven. Otherwise, I'll need to find at least a single example of a matrix with the smallest non-zero amount of square roots. The link to wikipedia article on square roots is here, it might also help: https://en.wikipedia.org/wiki/Square_root_of_a_matrix","['matrices', 'determinant', 'linear-algebra']"
4585631,How to solve $\lim_{n\to\infty}\left(\dfrac{n^2+5n+3}{n^2+n+2}\right)^n$,Question: $$\lim_{n\to\infty}\left(\dfrac{n^2+5n+3}{n^2+n+2}\right)^n=?$$ My work: $\lim_{n\to\infty}\left(\dfrac{n^2+5n+3}{n^2+n+2}\right)^n=\lim_{n\to\infty}\left(\dfrac{n^2(1+5/n+3/n^2}{n^2(1+1/n+2/n^2)}\right)^n=\lim_{n\to\infty}\left(\dfrac{1+5/n+3/n^2}{1+1/n+2/n^2}\right)^n$ $\log L=n\log\left(\dfrac{1+5/n+3/n^2}{1+1/n+2/n^2}\right)$ Is this equal to 0? Then the answer would be $e^0=1$ . The answer was given as $e^4$ and I have no idea how to get to that.,"['limits-without-lhopital', 'real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
4585652,What is the maximum number of Eckardt points of a non-singular cubic surface?,Every non-singular complex projective cubic surface has $27$ lines. An Eckardt point of a cubic surface is a point where three of the lines intersect. The Fermat cubic has $18$ Eckardt points. What is the maximum number of Eckardt points of a non-singular complex projective cubic surface?,"['complex-geometry', 'algebraic-geometry', 'projective-geometry', 'complex-numbers']"
4585678,Analyzing the probability of this event,"Consider a set $S$ of $n$ different elements. Sample $f(n)$ different elements from $S$ to get a new set $S'$ such that $\lim_{n\to\infty}\frac{f(n)}{n} = 0$ . Now pick uniformly at random one element $x$ from $S'$ and suppose it lies in the middle third of $S'$ . We want to find the probability that $x$ is also in the middle third of $S$ and show that $x$ is also likely to be in the middle third of $S$ . This is my attempt. First, we find the probability that $x$ is the element of rank $i$ in $S$ given that $x$ is in the middle third of $S'$ $$ P_i = \frac{3}{f(n)}\frac{1}{n \choose f(n)}\sum^{\frac{2f(n)}{3}}_{j=\frac{f(n)}{3}+1} {i-1\choose j-1} {n-i\choose f(n)-j}.$$ So the probability we want to look at is $\sum^{\frac{2n}{3}}_{i=\frac{n}{3}+1}P_i$ but I find this expression hard to work with and find a bound for it, what else can I do?","['statistics', 'probability-distributions', 'combinatorics', 'probability']"
4585689,"Is it true that $\sigma(X_1,X_1+X_2)=\sigma(X_1,X_2)$?","Given a sequence $(X_k)_{k\in\mathbb{N}}$ of real centered r.v.'s, and a sequence $(Y_n)_{n\in\mathbb{N}}$ defined by $$Y_n = X_1 + ..+X_n$$ it is stated, in a chapter on martingales of the book I'm studying, that $$\sigma(Y_1,..,Y_m)=\sigma(X_1,...X_m)$$ without any hint for a proof, as if it were trivial. All I know, in general, is that $\sigma(X_n+X_m)\subseteq\sigma(X_n,X_m)$ , which should imply that $\sigma(X_n,X_n+X_m)\subseteq\sigma(X_n,X_m)$ . But how to go from here? The source is: P. Baldi, Stochastic Calculus - An Introduction Through Theory and Exercises , Springer, Section 5.1, page 109.","['martingales', 'measure-theory', 'random-variables']"
4585714,Choice requirement in defining Lebesgue measure,"In this MO post, the answers point out that the statement, ""The reals are a countable union of countable sets"" is consistent with $\textsf{ZF}$ (without choice). This question points out that in such models of $\textsf{ZF}$ , Lebesgue measure $m$ as typically defined from its outer measure would yield $m(\mathbb{R}) = 0$ , which of course is very bad. The issue, according to the answers in that question, is because the traditional proof of subadditivity for the outer measure requires Countable Choice $\textsf{AC}_\omega$ . However, I've heard that the statement ""the countable union of countable sets is countable"" ( $\textsf{CUT}$ ) is weaker than $\textsf{AC}_\omega$ . Is there, perhaps, a way to prove subadditivity of the Lebesgue outer measure $m^*: \mathscr{P}(\mathbb{R}) \to [0,\infty]$ given by $$
m^*(E) = \inf\left\{\sum_{n=1}^\infty b_n - a_n : E \subseteq \bigcup_{n=1}^\infty (a_n,b_n)\right\}
$$ over $\textsf{ZF + CUT}$ (i.e., no $\textsf{AC}_\omega$ )? Or even better, can we recover subadditivity in models of $\textsf{ZF}$ where $\mathbb{R}$ isn't the countable union of countable? If not, is full $\textsf{AC}_\omega$ required to get the subadditivity? By the way, I am aware of an alternative to Carathéodory's approach which uses Borel-coded measures (described in Fremlin's Measure Theory, Volume 5 ), choice free. I am simply wondering if we can ever recover the approach in $\textsf{ZF}$ alone/plus extremely weak choice principles.","['axiom-of-choice', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
4585770,Motivating Zariski topology,"I always find it difficult to motivate Zariski topology on $\text{Spec}(k[X_1,...,X_n])$ , both the underlying set and the topology. As far as I understand, Zariski topology isn't really that essential for proving many classical theorems like Bezout's (for example Fischer doesn't mention Zariski topology once in his Plane Algebraic Curves ); applications of Zariski topology where it does play an essential role are probably too advanced for me (although counterexamples are much appreciated). Then I wonder if I can at least motivate Zariski topology intrinsically. I can somehow agree with the naturalness of Zariski topology on $k^n$ : points should be closed and polynomials should be continuous; this is a bit like weak topology in functional analysis. But why do we want to consider prime ideals, i.e., to put points and irreducible varieties on the same footing? A usual answer is that preimage of maximal ideal is in general not maximal, but it is maximal in the case of finitely generated $k$ -algebras, which seems good enough (and why is it so important to take preimage?). Also, why should we think of the zero ideal as the ""generic point""? For me it's hard to relate that to those classical generic point arguments. But now I think I finally found a way to motivate Zariski topology. Please help me check if the math is correct. Let $K\supseteq k$ be a larger algrabraically closed field of infinite transcendence degree, e.g., if $k=Q^{\text{alg}}$ then we may take $K=\mathbb{C}$ . For each $a=(a_1,...,a_n)\in K^n$ , define $\pi(a)=\{f\in k[X_1,...,X_n]: f(a)=0\}$ . This is a prime ideal. We claim that $\pi:K^n\rightarrow\text{Spec}(k[X_1,...,X_n])$ is surjective. For any prime ideal $\mathfrak{p}$ , the image of $X_1,...,X_n$ in $k[X_1,...,X_n]/\mathfrak{p}$ is a tuple that satisfies exactly those polynomials in $\mathfrak{p}$ . The algebraic closure of $k[X_1,...,X_n]/\mathfrak{p}$ has transcendence degree at most $n$ over $k$ , and hence embeds into $K$ . We claim that with both $K^n$ and $\text{Spec}(k[X_1,...,X_n])$ endowed with Zariski topology, $\pi$ is a closed map, hence a quotient map. If $f(a)=0$ then $\pi(a)\ni f$ ; conversely if $\mathfrak{p}\ni f$ , choose any $a$ that maps to $\mathfrak{p}$ , and we must have $f(a)=0$ . This shows the image of a basic closed set in $K^n$ is a basic closed set in $\text{Spec}(k[X_1,...,X_n])$ ; the general case is similar. So the Zariski topology on $\text{Spec}(k[X_1,...,X_n])$ is just the quotient of the (in my opinion) more intuitive topology on $K^n$ . As for generic point, if $\pi(a)=\mathfrak{p}$ then the tuple $a$ satisfies those polynomials in $\mathfrak{p}$ and nothing else, as with ""most"" $K$ -points on the variety determined by $\mathfrak{p}$ ; in particular $\pi(a)=(0)$ iff $a=(a_1,...,a_n)$ are algebraically independent. This makes more sense to me than "" $(0)$ is a point that lies everywhere"". As for the reason of going to a larger field $K$ : truly generic point doesn't exist if we only look at $k$ . All algebraically closed fields (of a fixed characteristic) are more or less the same, so the structure of varieties don't really change when we move to a larger field. Is this a useful way to picture Zariski topology? Perhaps it's too early for me, but is this related to the the functor of points ?","['zariski-topology', 'algebraic-geometry', 'intuition']"
4585780,Number of ways to partition a multiset into $k$ non empty submultisets.,"Let $A$ be a multiset with $n$ distinct elements where each element occurs exactly twice. How many ways can we partition $A$ into $k$ non-empty (unlabelled) sub multisets (denoted $T(n,k)$ )? My approach would be something similar to the Stirling Numbers. For each element $x \in A$ , we can either both copies of $x$ in a set, or include them in two different sets. Therefore, we can define labelings of sets (parts), as singleton and two-element subsets of $\{1,2,3,...k\}$ . There are in total $k + {{k}\choose{2}} = {{k+1}\choose{2}}$ different labeling we can assign to each element. (Note: We divide the end result by $k!$ because the labeling did not originally matter) Elements where both copies are included in the same set are labeled with a singleton, and if one element occurs in two sets, it is labeled with a two-element set. For example, the partition of $\{\{a,a,c\},\{b,b,c\}\}$ of $\{a,a,b,b,c,c\}$ can be defined by an equivalence class or function such as $f(a)=\{1\}$ , $f(b)=\{2\}$ , $f(c)=\{1,2\}$ . The basic idea is to count the number of functions $f:A_s \xrightarrow{} S$ such that $|\cup_{x \in A_s} f(x)| = k$ . Here, $A_s$ is the set containing only one of each element in $A$ , and $S = \{  s \in \mathcal{P}(\{1,2,3,...k\})\ \mid  |s| = {1,2} \}$ . Since $|S|={{k+1}\choose{2}}$ , and $|A_s|=n$ , we have $|S|^{|A_s|} = {{k+1}\choose{2}}^{n}$ different functions to choose from. However, some functions may not satisfy our initial constraint that $|\cup_{x \in A_s} f(x)| = k$ . We can use inclusion-exclusion for this (similar to how the Stirling Numbers of the Second Kind are derived). What I get is something like $$ T(n,k) = \frac{1}{k!} \sum_{i=0}^{k} (-1)^{k-i} {{k}\choose{i}} {{i+1}\choose{2}}^n $$ I think the formula is wrong though, and I can't figure out why.
For example, with $k=2$ , we have $T(n,2) = \frac{1}{2}(3^n - 2)$ . I know that it should be $\frac{1}{2}(3^n - 1)$ because each subset of $A$ has a complement, but one set is its own complement, and we need to ""add"" a pair to the collection, then divide by 2. For $k=3$ , we have $T(n,k) = \frac{1}{6}(6^n - 3^{n+1} + 3)$ , but manual computations show that this is incorrect. (For example, $T(3,3) = 23$ , but it should be $26$ , and $T(4,3) = 176$ , but it should be $183$ ). Could anyone please kindly give me hints on what I am missing here. I am really trying to figure it out on my own, or at least understand why my computations are incorrect? Thanks in advance! Edit: I realized my mistake (thanks to user2661923). So basically, I had the counting correct, but for ordered partitions rather than unordered partitions. Basically, if we forget the ordering, some partitions have $k!$ copies, others have fewer than $k!$ duplicates.  So all we need to do to fix the counting is ""add"" enough duplicates (for those permutations that have fewer than $k!$ copies). For example, if $k=2$ using the formula above (ignore the $\frac{1}{k!}$ ), we get $T(n,k) = 3^n-2$ . However, there will be one partition of the form $\{X, X\}$ (where $X$ is a multiset). There is only one copy of this partition included, so we need to ""add"" in another copy of it, leading to $3^n-1$ , instead of $3^n-2$ , which we can then divide by 2, to get the correct value of $T(n,2) = (3^n-1)/2$ If $k=3$ , then we initally get $T(n,3) = 6^n - 3^{n+1} + 3$ . Partitions of the form $\{X,X,Y\}$ only have $3$ copies included, so we need to ""add"" three more. Each element is either assigned to $\{X,X\}$ or $\{Y\}$ , but all cannot be assigned the same sets, so this yields $2^n-2$ different copies we need to add (don't forget that this gives $3$ additional copies). Since we originally had $3$ different labels, we need to multiply this result by $3$ . This gives $$T(n,3) = (6^n - 3^{n+1} + 3 + 3(2^n-2))/6 = (6^n - 3^{n+1} + (3)2^n - 3)/6$$ The case for $k=4$ is more complicated, but after manually checking all possible partitions which need extra copies, I get the formula: $$T(n,4) = (10^n - (4)6^n + (6)4^n - (9)2^n + 8)/24$$ I'm not putting this as an answer because I am still not sure of a general formula that doesn't involve manually checking all possible partitions which are initially undercounted.","['elementary-set-theory', 'combinatorics']"
4585819,How to solve this first order non-linear (quadratic) inhomogenous ODE?,"How can I find a solution to the following first order nonlinear (quadratic) ODE? $$ h(t)=a\dot h(t)\sqrt{b-c \dot h(t)^2} $$ I am solving a physics problem, namely, finding the time it takes for a cylinder to sink in water, and need to find the function $h$ . The water that the cylinder is in can be considered as nonviscous. Therefore I used conservation of energy and the continuity equation to obtain this equation. I think that my physical reasoning is correct although some approximations I made might not be reasonable. I want to verify this by solving this equation and evaluating the time. In case this raises concerns, I am not interested in obtaining a solution by the work of others without own contribution, I want to know if this ODE is solvable analytically and if so, which methods I should use / learn to solve it. Regarding my knowledge on DEs, aside from special cases like using characteristic polynomials or the harmonic oscillator, I only know separation of variables and variation of constants for inhomogeneous first order linear ODEs.","['physics', 'ordinary-differential-equations']"
4585825,"Without Hausdorff, what implications can we prove about $k_\omega$ related to other covering properties?","In e.g. A SURVEY OF $k_\omega$ -SPACES a space is said to be $k_\omega$ if it's the union of compact Hausdorff $K_n$ , $n<\omega$ , with a set being closed if and only if its intersection with each $K_n$ is closed. It's asserted there that $k_\omega$ is implied by $K_n\subseteq int(K_{n+1})$ , i.e. exhaustible by (Hausdorff) compacts . I want to consider the case where the $K_n$ need not be Hausdorff. In this case, we have exhaustible by compacts $\Rightarrow$ hemicompact $\Rightarrow$ $\sigma$ -compact (with no arrows reversing). Where does this non- $T_2$ $k_\omega$ live? Exhaustible by compacts implies this $k_\omega$ . Let $K_n\subseteq int(K_{n+1})$ . $k_\omega$ is equivalent to a set having open intersection with each $K_n$ with respect to the subspace topology implies the set is open. So let $U$ have open intersection with each $K_n$ and let $x\in U$ . Note $x\in K_n$ for some $n<\omega$ . Then let $V$ be an open set such that $V\cap K_{n+1}=U\cap K_{n+1}$ . $x\in V\cap int(K_{n+1})\subseteq U$ , proving $U$ is open. Obviously, $k_\omega$ still implies $\sigma$ -compact. Where does hemicompact fit in without something like Hausdorff or locally compact?",['general-topology']
4585897,Folland Real Analysis: Theorem 2.47,"I am trying to understand this theorem but I have problems with some parts of the proof: 2.47 Theorem. Suppose that $\Omega$ is an open set in $\mathbb{R}^{n}$ and $G:\Omega\to\mathbb{R}^{n}$ is a $C^1$ diffeomorphism. a. If $f$ is a Lebesgue measurable function on $G(\Omega)$ , then $f\circ G$ is Lebesgue measurable on $\Omega$ . If $f\geq 0$ or $f\in L^1(G(\Omega),m)$ , then $$\int_{G(\Omega)} f(x) d x=\int_{\Omega} f \circ G(x)\left|\operatorname{det} D_x G\right| d x .$$ b. If $E\subsetΩ$ and $E \in \mathcal{L}^n$ , then $G(E) \in \mathcal{L}^n$ and $m(G(E))=\int_E\left|\operatorname{det} D_x G\right| d x$ . Proof. It suffices to consider Borel measurable functions and sets. Since $G$ and $G^{−1}$ are both continuous, there are no measurability problems in this case, and the general case follows as in the proof of Theorem 2.42. A bit of notation: For $x∈\mathbb{R^n}$ and $T=(T_{ij})∈GL(n,\mathbb{R})$ , we set $$\|x\|=\max _{1 \leq j \leq n}\left|x_j\right|, \quad\|T\|=\max _{1 \leq i \leq n} \sum_{j=1}^n\left|T_{i j}\right|$$ We then have $\|T x\| \leq\|T\|\|x\|$ , and $\{x:\|x-a\| \leq h\}$ is the cube of side length 2h centered at a. Let $Q$ be a cube in $Ω$ , say $Q=\{x:\|x-a\| \leq h\}$ . By the mean value theorem, $g_j(x)-g_j(a)=\sum_j\left(x_j-a_j\right)\left(\partial g_j / \partial x_j\right)(y)$ for some $y$ on the line segment joning $x$ and $a$ , so that for $x \in Q,\|G(x)-G(a)\| \leq h\left(\sup _{y \in Q}\left\|D_y G\right\|\right)$ . In other words, $G(Q)$ is contained in a cube of side length $\sup _{y \in Q}\left\|D_y G\right\|$ times that of $Q$ , so that by Theorem 2.44, $m(G(Q)) \leq\color{red}{\left(\sup _{y \in Q}\left\|D_y G\right\|\right)^n} m(Q)$ . If $T \in G L(n, \mathbb{R})$ , we can apply this formula with $G$ replaced by $T^{−1}\circ G$ together with Theorem 2.44 to obtain \begin{aligned}
m(G(Q)) &=|\operatorname{det} T| m\left(T^{-1}(G(Q))\right) \\
& \leq|\operatorname{det} T|\left(\sup _{y \in Q}\left\|T^{-1} D_y G\right\|\right)^n m(Q)\hspace{1cm}(2.48)
\end{aligned} Since $D_yG$ is continuous in $y$ , for any $\varepsilon>0$ we can choose $\delta>0$ so that $\color{red}{\|(D_zG)^{-1}D_yG\|^n\leq 1+\varepsilon}$ if $y,z\in Q$ and $\|y-z\|\leq\delta$ . Let us now subdivide $Q$ into subcubes $Q_1, ... ,Q_N$ whose interiors are disjoint, whose side lengths are at
most $\delta$ , and whose centers are $x_1, . . . ,x_N$ . Applying (2.48) with $Q$ replaced by $Q_j$ and with $T = D_{x_j}G$ , we obtain \begin{aligned}
m(G(Q)) &=\sum_1^N m(G(Q_j))\\
&\leq \sum_1^N |\operatorname{det} D_{x_j}G| \left(\sup _{y \in Q}\left\|(D_{x_j}G)^{-1} D_y G\right\|\right)^n m(Q_j) \\
& \leq(1+\varepsilon)\sum_1^N |\operatorname{det} D_{x_j}G| m(Q_j)
\end{aligned} This are my questions: Where did that supreme come from and why is it raised to $n$ ? I know that by $D_yG$ continuity, for any $\varepsilon>0$ I can choose $\delta>0$ such that $\|(D_zG)^{-1}D_yG\|\leq 1+\varepsilon$ , and I also know that in the proof $\|(D_zG)^{-1}D_yG\|$ it is raised to $n$ so that in the last inequality $1+\varepsilon$ is not raised to $n$ , but why can I claim that $\|(D_zG)^{-1}D_yG\|^n$ is bounded by $1+\varepsilon$ ?","['measure-theory', 'analysis', 'real-analysis', 'multivariable-calculus', 'functional-analysis']"
4585938,"Finding a pro disc golfer's chance of winning a tournament, knowing their chance of beating each other player","I'm working on a strength of field metric for disc golf tournaments, and I'd first like to come up with a way to determine a player's likelihood of winning an event, given their player rating and the ratings of other players in the event. For anyone not familiar (probably most reading this), competitive disc golf is played very similar to golf. The competitors play a set number of rounds on the tournament course, and the player with the lowest stroke total at the end of the event wins. The governing body calculates player ratings based on performance at these competitive events, which allows any player with enough rated rounds to be compared to another player, even if they haven't competed directly. I compiled data from every tournament in the 2022 disc golf pro tour, including the entrants, their finishes, and their ratings at the start of the event. I separated every player at every tournament into buckets of 5 ratings points each, and for all players at all tournaments calculated the probability of an average player of rating x beating an average player of rating y (beating defined simply as placing higher/scoring lower in the tournament). For instance, a player who enters a tournament with a rating between 1040-1045 has a 33% chance of placing higher than a 1045-1050 rated player - but a 74% chance of placing higher than a player rated 1025-1030. My thought was that I could use this matrix to find a player's likelihood of winning a tournament. Once I know their likelihood of placing higher than each other player in the event individually, I can multiply all of those probabilities to find the chance of that player finishing higher than every other player at the event. These should all be independent events I assume, as each player is playing against the course - their individual scores have no effect on one another's scores. However, after running this calculation, the resulting event-win probabilities I get are way too low. They do make sense directionally - higher rated players in my sample had higher win probabilities - but they are still far too low. For example, one of these events had 131 entrants - so if I were to assume every player entered had the same skill, they should all have about a 0.8% chance of winning. In my calculation, with skill difference taken into account, the highest rated player at the event had a .0004% likelihood of winning. I thought floating point error from my probability matrix might be to blame, so I tried rounding any value below .005 in the matrix to 0. This did not turn out to be the source of the issue however. Am I missing something in my approach, or my assumptions? I'm a bit of an amateur at all of this, so I wouldn't be surprised if the math just doesn't work out the way I think it does. Thanks!","['statistics', 'probability']"
4585943,Why does packing exactly 992 circles in a square behave exceptionally?,"It is not so surprising that the problem of Circle packing in a square is a chaotic and often-unpredictable problem. However, after looking over the data on hydra.nat.uni-magdeburg.de , we find quite the anomaly. Here is a graph of the first ~1000 densities of the best known solutions. [ The graph is perhaps unsurprisingly chaotic, beit with some patterns, of course. However, Something incredibly unusual / significant seems to happen at number 992. Below I've added its solution, compared to known neighboring solutions. Noticeably, it's rather regular, especially compared to it's neighboring solutions. This is likely the cause for the sudden change in density. Of course, the exact densities are subject to change, as better solutions are found. But even if new solutions are found at and near 992, I seriously doubt this anomaly will go away, given its relatively huge gap in the sequence, and the already enormous computation done over the years that went into this data. So my wondering is, What is so special about 992 and its local neighborhood of solutions, that allows for it to have such a regular (yet inefficient) solution, and drop in density? Is it as simple as the fact that we haven't found a better solution, up to par with the others? Or is it just special, given that it's of the form $n(n+1)$ , or of some other ""nice"" property?","['numerical-methods', 'soft-question', 'geometry', 'packing-problem']"
4585968,On the abscence of the Inner Measure in introductory texts on Measure Theory,"Letting $\mu$ and $\mu^*$ be the Lebesgue and outer Lebesgue measure repsectively, the inner Lebesgue measure can defined as $$\mu_*:S\mapsto \sup\left\{\mu(K) : \text{$K$ is a compact subset of $S$}\right\}$$ or, on bounded sets, as $$S\mapsto \mu(A)-\mu^*(A\setminus S)$$ for any elementary set $A$ containing $S$ . Neither Williams' Probabilities with Martingles , nor Hunter's Measure Theory , nor Tao's An Introduction to Measure Theory define inner measures in general. Why are inner measures skipped when studying introductory measure theory? A definition of an inner measure may be found in Wikipedia, yet it's not clear at all why such a definition is adopted i.e. having the defined the Lebesgue inner measure, why are those properties in particular chosen when characterizing general inner measures? (see also the edit at the bottom of the post) The outer measure is used in the construction of measures through -what I shall call- Carathéodory's Restriction Lemma (see below). Is there a version of this theorem which utilizes inner, as opposed to outer, measures? Carathéodory's Restriction Lemma: let $\mu^*:2^X\to [0,\infty]$ be an outer measure on the power set $2^X$ of $X$ . Then $\mu^*$ can be restricted to a measure $$\mu:\Sigma\to[0,\infty]$$ where $\Sigma := \Big\{ C \in 2^X : C \text{ is Caratheodory measurable} \Big\}$ and $\mu := \mu^*|_{\Sigma}$ . Edit: in Halmos' Measure Theory (where I was directed to by Dave L. Renfro below), an inner measure $\mu_*$ induced by a measure $\mu:\Sigma\to[0,\infty]$ is defined by \begin{equation}
\tag{1}
\mu_*(E):=\sup\left\{\mu(F):E\supseteq F \text{ for } F\in 
\Sigma\right\}
\end{equation} and is proven to have the following two properties: \begin{equation}
\begin{split}
& a) \ \mu_*(\varnothing)=0.\\
& b) \ \mu_*(E)\le \mu_*(F) \text{ whenever } E\subseteq F.\\
& c) \ \text{For a disjoint sequence of sets } E_1, E_2, \ldots \text{ we have}\\
& \ \ \ \ \ \ \ \ \ \  \ \ \ \ \  \mu_*\left(\bigcup_{n=1}^{\infty}E_n\right) \ge \sum_{n=1}^{\infty}\mu_*(E_n)
\end{split}
\end{equation} (all sets in questions are subsets of $X$ , where $\Sigma$ is a $\sigma$ -algebra on $X$ ). Both $(1)$ or the combination of $a), b)$ , and $c)$ are symmetrical to a characterization of the outer measure, which adds more weight to the question of why inner measures are defined instead so assymetrically (relative to outer measures) in Wikipedia.","['measure-theory', 'definition', 'lebesgue-measure', 'outer-measure']"
4586011,"Evaluating $\int_0^1\int_0^1\cdots\int_0^1\frac{n\max\{x_1,x_2,\cdots,x_n\}}{x_1+x_2+\cdots+x_n}dx_1dx_2\cdots dx_n$","I was trying to compute the following integral: $$I=\int_0^1\int_0^1\cdots \int_0^1 \frac{n \max\{x_1,x_2,\ldots,x_n\}}{x_1+x_2+\ldots+x_n}dx_1dx_2\ldots dx_n.$$ My attempt was: Let $X_1,X_2, \ldots, X_n$ be a collection of i.i.d. uniform random variables on $(0,1)$ . Then, $$I= n\mathbb{E}\left[\frac{\max\{X_1,X_2,\ldots,X_n\}}{X_1+X_2+\ldots+X_n} \right] = n\mathbb{E}\left[\max_{1\leqslant i \leqslant n}\frac{X_i}{X_1+X_2+\ldots+X_n} \right].$$ Now, I understand that $$\left\{\frac{X_i}{X_1+X_2+\ldots+X_n}\right\}_{1\leqslant i \leqslant n}$$ is an identically distributed sequence of random variables but I don't know how to proceed further. Any further help using either probability or general integral calculus is much appreciated. Thank you very much for your time and attention.","['integration', 'definite-integrals', 'real-analysis', 'multivariable-calculus', 'probability-theory']"
4586031,"Guessing a subset of $\{1,...,N\}$","I pick a random subset $S$ of $\{1,\ldots,N\}$, and you have to guess what it is. After each guess $G$, I tell you the number of elements in $G \cap S$. How many guesses do you need?","['puzzle', 'combinatorics']"
4586062,"Using complex analysis, prove $\int\limits_0^\infty \frac{\log(x) \arctan(x)}{1 + x^2} \, dx = \frac78 \zeta(3)$","Expanding on an earlier question , I am trying to prove that $$I = \int_0^\infty \frac{\log(x) \arctan(x)}{1 + x^2} \, dx = \frac78 \zeta(3)$$ using complex analysis but am running into some issues. My attempt : Let $f(z) = \dfrac{\log^2(z) \arctan(z)}{a^2 + z^2}$ (where $\log^2(z) \equiv (\log(z))^2$ ) with $0<a<1$ , and let $$I(a) = \int_0^\infty \frac{\log(x) \arctan(x)}{a^2 + x^2} \, dx \quad .$$ Take $\mathcal C$ to be the same positively-oriented contour (redrawn here) with branch cuts along $[0,\infty)$ and $\pm[i,i\infty)$ . The larger arc has radius $R>1$ and the smaller ones each have radii $\varepsilon$ . The dotted circles indicate the poles at $z=\pm ia$ . I parameterized the banks to either side of the branch cuts (abusing notation) by $A$ : $z = x+i\varepsilon$ , $x\in[\varepsilon, R]$ $A'$ : $z = x - i\varepsilon$ , $x\in[R,\varepsilon]$ $B$ : $z=-\varepsilon+ix$ , $x\in[1+\varepsilon, R]$ $B'$ : $z=\varepsilon+ix$ , $x\in[R,1+\varepsilon]$ $C$ : $z=\varepsilon-ix$ , $x\in[1+\varepsilon, R]$ $C'$ : $z=-\varepsilon-ix$ , $x\in[R,1+\varepsilon]$ As each bank approaches their respective branch cut, I believe we have $$\begin{array}{c|ccc}
A & f(x+i\varepsilon) & \to & \dfrac1{a^2+x^2} \log^2(x) \arctan(x) \\
A' & f(x - i\varepsilon) & \to & \dfrac1{a^2+x^2} \left(\log^2(x) + 4\pi i\log(x) - 4\pi^2\right) \arctan(x) \\
\hline
B & f(-\varepsilon + ix) & \to & \dfrac1{a^2-x^2} \left(\log^2(x) + i\pi \log(x) - \dfrac{\pi^2}4\right) \left(-\dfrac i2 \log\left|\dfrac{1-x}{1+x}\right| - \dfrac\pi2\right) \\
B' & f(\varepsilon + ix) & \to & \dfrac1{a^2-x^2} \left(\log^2(x) + i\pi \log(x) - \dfrac{\pi^2}4\right) \left(-\dfrac i2 \log\left|\dfrac{1-x}{1+x}\right| + \dfrac\pi2\right) \\
\hline
C & f(\varepsilon - ix) & \to & \dfrac1{a^2-x^2} \left(\log^2(x) - i\pi \log(x) - \dfrac{\pi^2}4\right) \left(-\dfrac i2 \log\left|\dfrac{1+x}{1-x}\right| + \dfrac\pi2\right) \\
C' & f(-\varepsilon - ix) & \to & \dfrac1{a^2-x^2} \left(\log^2(x) - i\pi \log(x) - \dfrac{\pi^2}4\right) \left(-\dfrac i2 \log\left|\dfrac{1+x}{1-x}\right| - \dfrac\pi2\right)
\end{array}$$ I'm not sure that I fully grasp how to jump across branches so this might be where everything goes wrong. Edit : The correction to make here (thanks to @Svyatoslav !) is along the banks $C$ and $C'$ , for which we should have $$C : f(\varepsilon - ix) \to \dfrac1{a^2-x^2} \left(\log^2(x)+\color{red}{3}i\pi\log(x)-\frac{\color{red}{9}\pi^2}4\right) \left(-\dfrac i2 \log\left|\dfrac{1+x}{1-x}\right| + \dfrac\pi2\right) \\
C' : f(-\varepsilon - ix) \to \dfrac1{a^2-x^2} \left(\log^2(x)+\color{red}{3}i\pi\log(x)-\frac{\color{red}{9}\pi^2}4\right) \left(-\dfrac i2 \log\left|\dfrac{1+x}{1-x}\right| - \dfrac\pi2\right)$$ The residues at the poles are $$\begin{align*}
\underset{z=ia}{\operatorname{Res}} f(z) &= \frac{\log^2(ia) \arctan(ia)}{2ia} \\[1ex]
&= \frac1{2ia} \left(\log^2(a) + i\pi \log(a) - \frac{\pi^2}4\right) \left(-\frac i2 \log\left|\frac{1-a}{1+a}\right|+\frac12\arg\left(\frac{1-a}{1+a}\right)\right) \\[1ex]
&= \frac1{2ia} \left(\log^2(a) + i\pi\log(a) - \frac{\pi^2}4\right) \arctan(ia) \\[3ex]
\underset{z=-ia}{\operatorname{Res}} f(z) &= \frac{\log^2(-ia) \arctan(-ia)}{-2ia} \\[1ex]
&= -\frac1{2ia} \left(\log^2(a) + 3i\pi \log(a) - \frac{9\pi^2}4\right) \left(-\frac i2 \log\left|\frac{1+a}{1-a}\right|+\frac12\arg\left(\frac{1+a}{1-a}\right)\right) \\[1ex]
&= \frac1{2ia} \left(\log^2(a) + 3i\pi \log(a) - \frac{9\pi^2}4\right) \left(-\frac i2 \log\left|\frac{1-a}{1+a}\right| + \frac12 \arg\left(\frac{1-a}{1+a}\right)\right) \tag{*} \\[1ex]
&= \frac1{2ia} \left(\log^2(a) + \color{red}{3}i\pi \log(a) - \frac{\color{red}{9}\pi^2}4\right) \arctan\left(ia\right)
\end{align*}$$ $(*)$ : $\arg(x)=\arg\left(\frac1x\right)$ for all real $x\neq0$ As $\varepsilon\to0$ and $R\to\infty$ , $$\begin{align*}
\left\{\int_A + \int_{A'}\right\} f(z) \, dz &= \int_\varepsilon^R (f(x+i\varepsilon)-f(x-i\varepsilon)) \, dx \\[1ex]
&\to -4\pi i \, I(a) + 4\pi^2 \underbrace{\int_0^\infty \frac{\arctan(x)}{a^2+x^2} \, dx}_{J(a)} \\[2ex]
\left\{\int_B + \int_{B'}\right\} f(z) \, dz &= i \int_{1+\varepsilon}^R (f(-\varepsilon+ix)-f(\varepsilon+ix)) \, dx \\[1ex]
&\to -i\pi \underbrace{\int_1^\infty \frac{\log^2(x)}{a^2-x^2} \, dx}_{K(a)} + \pi^2 \underbrace{\int_1^\infty \frac{\log(x)}{a^2-x^2} \, dx}_{L(a)} + \frac{i\pi^3}4 \underbrace{\int_1^\infty \frac{dx}{a^2-x^2} \, dx}_{M(a)} \\[2ex]
\left\{\int_C + \int_{C'}\right\} f(z) \, dz &= -i \int_{1+\varepsilon}^R (f(-\varepsilon-ix) - f(\varepsilon-ix)) \, dx \\[1ex]
&\to -i\pi \, K(a) \color{red}{+ 3}\pi^2 \, L(a) + \frac{\color{red}{9}i\pi^3}4 \, M(a)
\end{align*}$$ and the integrals along the circular arcs vanish. Let $a\to1^-$ . We already know $J(1)=\dfrac{\pi^2}8$ , and it's easy to show that $L(1)=-\dfrac{\pi^2}8$ (correct) and $K(1)=-\dfrac78\zeta(3)$ (not correct!). The last integral is $$M(a) = \int_1^\infty \frac{dx}{a^2-x^2} = \frac1{2a} \log\left(\frac{1-a}{1+a}\right) \quad .$$ Now by the residue theorem, $$\begin{align*}
\oint_{\mathcal C} f(z) \, dz &= 2\pi i \cdot -\frac{2\log^2(a) + 4i\pi \log(a) - \frac{5\pi^2}2}{4a} \log\left(\frac{1-a}{1+a}\right) \\[1ex]
&= -4\pi i \, I(a) + 4\pi^2 \, J(a) - 2i\pi \, K(a) + 4\pi^2 \, L(a) + \frac{5i\pi^3}2 M(a) \\[3ex]
\implies I(a) &= \frac{4\log^2(a) + 8i\pi \log(a) - 5\pi^2}{16a} \log\left(\frac{1-a}{1+a}\right) \\[1ex]
&\qquad - \pi i \, J(a) - \frac12 K(a) - \pi i \, L(a) + \frac{5\pi^2}8 M(a) \\[3ex]
\implies I &= \frac{5\pi^2}{16} \lim_{a\to1^-} \underbrace{\left(2\,M(a) - \frac1a \log\left(\frac{1-a}{1+a}\right)\right)}_{=0} - \frac{i\pi^3}8 + \frac7{16}\zeta(3) + \frac{i\pi^3}8 \\[1ex]
&= \frac7{16}\zeta(3) \neq \frac78 \zeta(3)
\end{align*}$$ All that's left is to figure out where that extra factor of $\frac12$ came from ... Where is the mistake? There was this very similar integral with $1+x$ in place of $1+x^2$ , but with no obvious use of contour integration among its answers. I also found $I$ 's value appearing in another question and slightly less conspicuously in this integral , which leads to a nice identity that helps verify the result. Substituting $e^{-x}\mapsto x$ and integrating by parts yields $$\int_0^\infty \arctan^2(e^{-x}) \, dx = \int_0^1 \frac{\arctan^2(x)}x \, dx = -2 \int_0^1 \frac{\log(x) \arctan(x)}{1+x^2} \, dx$$ and by subsequently replacing $x\mapsto\frac1x$ one gets $$\frac\pi2 G = \left\{\int_1^\infty -\int_0^1\right\} \frac{\log(x) \arctan(x)}{1+x^2} \, dx$$ Now $$\begin{align*}
\int_0^\infty \arctan^2(e^{-x}) \, dx &= \frac\pi2 G - \frac78 \zeta(3) \\[1ex]
\implies \int_0^1 \frac{\log(x) \arctan(x)}{1+x^2} \, dx &= -\frac\pi4 G + \frac7{16} \zeta(3) \\[1ex]
\implies \int_1^\infty \frac{\log(x) \arctan(x)}{1+x^2} \, dx &= \frac\pi4 G + \frac7{16} \zeta(3)
\end{align*}$$ and the result follows.","['definite-integrals', 'branch-cuts', 'complex-analysis', 'contour-integration', 'residue-calculus']"
4586070,"Rhombus, circumcircle and incenter","I try to do this problem: It is given a rhombus $ABCD$ with sidelength $a$ . On the line $AC$ are chosen the points $M$ and $N$ in such a way that $C$ lies between $A$ and $N$ and $MA\cdot NC= a^{2}$ . We denote with $P$ the intersection point of $MD,BC$ and $Q$ is the intersection point of $ND,AB$ . Prove that $D$ is the incenter of the triangle $PQB$ . I do this figure By the sinus theorem applied to the triangles $MAD$ and $NCD$ implies $\alpha+\beta=\theta$ and these triangles are similar. Then I've drawn the circumcircle to the triangle $BPQ$ . I wonder if the points $M$ and $N$ are on this circumcircle, if they are, the inscribed angles $NMP$ and $NQP$ are equal and the prove is done. I appreciate any help, thanks.","['euclidean-geometry', 'geometry', 'plane-geometry']"
4586098,Prove that $2\cdot 3^x +1= p^y$ has no solution,"Prove that the Diophantine equation of $3$ variables $(x,y,p)$ $$2\cdot 3^x +1= p^y$$ has no solution where $x,y\in\mathbb{N}_+$ , $x\ge2, y\ge2$ and $p$ is a prime number. I found that $y$ cannot be even, if $y =2k$ then $4| (p^k -1)(p^k+1) =2\cdot3^x$ which is a contradiction. But I cannot prove there is no solution for the case $y = 2k+1$ . I try to apply the technique in this answer (equation $7^x = 3 \cdot 2^y +1$ ) but it doesn't work as $p$ is not known. Any help would be greatly appreciated!","['exponential-diophantine-equations', 'number-theory', 'elementary-number-theory', 'integers', 'diophantine-equations']"
4586173,Explicit formula for the $n^{th}$ positive integer of a $p$-rough sequence,"A p -rough number , or p -jagged number , is an integer whose smallest prime factor is $p$ (Finch, 2001). The $3$ -rough numbers are the odd numbers. The $7$ -rough numbers are numbers not divisible by $2, 3,$ or $5,$ that is: $ \left \{1, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 49, 53, 59, 61, 67, 71, ...\right \} $ . I am struggling to find an explicit formula for the 7-rough numbers I also wonder whether there is some recurrence or other method that can be used to find the $n^{th}$ number of a $p$ -rough sequence for any possible $p$ . Thanks in advance! Edit I found on OEIS the following formula by Gary Detlefs (Sep 15, 2013) for the $7$ -rough numbers: $$a(n) = \frac{6f(n) - 3 + (-1)^{f(n)}}{2}$$ where $$f(n)= n + \lfloor\frac{n}{4}\rfloor + \lfloor\frac{(n+4) \mod 8}{6}\rfloor.$$ I wonder how it is derived and if it is possible to find an equivalent or alternative formula without the floor and mod operations in it.","['polynomials', 'sequences-and-series']"
4586202,"Prove that $\operatorname{lcm}$ of [$\binom{n}{1}$, $\binom{n}{2}$, ... ,$\binom{n}{n}$] = $\operatorname{lcm}(1, 2, ...,n+1)/(n+1)$","How to prove that: $$\operatorname{lcm}\left(\binom{n}{1}, \binom{n}{2}, \ldots, \binom{n}{n}\right) = \frac{\operatorname{lcm}(1, 2, \ldots, n+1)}{n+1}$$ There is a hint: $p$ is a prime and consider the highest power of $p$ in $\binom{n}{k}$ , that is $p^e \:||\: \binom{n}{k}$ , e is the highest power of p.","['number-theory', 'combinations', 'gcd-and-lcm', 'prime-numbers']"
4586204,Perspective view of longitudinal great circles - ellipses inside a circle,"I'd like to visualize the longitudes on a sphere from close-up, with correct perspective. It seems this is the ""Blue Marble"" problem i.e. to show how earth looks from a realistic distance (say 0.5 to 4 earth radii), and not from infinity with visible poles. These are 6 ellipses fitted into the visible horizon. Note that the poles have both sunken below the horizon; the upper pole is marked by a small circle. It is not easy to fit the ellipses into the circle by hand, because the center is shifted to the right, and both height and width have to be adapted. I do have 5 points to nail it down: both poles, the chosen intersection with the x-axis, and the two tangent points with the circle. With only the y component of the center known (=0), I would start with this equation: $$\frac{(x - x_o)^2}{a^2} + \frac{y^2}{b^2}=1$$ with the three unknowns $x_0, a$ and $b$ . The poles give two points on the ellipse. Now I would add a chosen third point on the x-axis, for purple about (0.7, 0). This leaves me with a bundle of ellipses: some wider than tall running to the left; some very high poking through the horizon, some too short to touch the circle from the inside. I gather - and faintly recall from school - that I can find a single solution with a discriminant of zero. So can anybody tell me how to proceed from here? Can it be done with (simple, maybe messy) algebra, or is there a shortcut? Do I have to find that 4th and symmetric 5th point first and then determine the ellipse? Thank you Added after comment: Yes the uniform change in angle is important; now at least I can determine where I want the meridians (x-axis crossing would be a bit more practical), while by hand I had to leave them more or less where they fit. My goal is to put the 0-degree and 41E-degree fulldisc satellite images side by side and stretch them so I can merge them with a straight 20.5 meridian. This works quite well, but only after I changed/softened the stretching point from 1-x (the circle) to 1-sqrt(x) by trial and error. My graphic is meant as a test grid. I did not find anything similar on the internet. This is the usual perspective: This is not central: A ""globe beach ball"" from walmart comes - also literally speaking - closest: And this is my result for now on youtube . The projection itself is not fantastic, but at least the seam in the middle is gone. There is also a ""Mollweide"" projection by NOAA where they combined East and West coast satellites. But a correctly drawn complete grid would look nice on its own: shows the ""fatness"" of a sphere. That would be distance to determine the (un)visible poles, and degrees to choose the ellipse? I think that really is what I want!","['conic-sections', 'geometry']"
4586303,Is this a valid example of the tangent vector a linear map from a smooth function to the reals?,"This is intended to give an example of the tangent vector at a point $p$ along a smooth curve $\gamma(t)$ on a manifold as a linear map (directional derivative) from a smooth function $f$ to the real numbers constructed as $$f \mapsto (f \circ \gamma)'(0)$$ and where $p =\gamma(0).$ The attempt at illustrating this construct imagines the function $f(x,y)= e^{-\left((x+ 2.13)^2+(y+1.16)^{2}\right)}$ (a bivariate Gaussian bell curve) representing the density of historically relevant buildings and monuments at any given point in the city of Paris (from this site ): The chart used that allows Cartesian coordinates imposed on the manifold is centered at the Louvre $(0,0),$ and the function $f$ happens to have its maximum around des Champs-Élysées, so that we expect the density of historical buildings to start decreasing away from that point. This function is evaluated along a curve $\gamma(t)= -0.16(t +2.5)^2 +1$ which when mapped onto the chart is $\gamma(t)=(t, -0.16(t +2.5)^2 +1).$ It roughly follows the Seine river in the center of Paris. The Louvre is the point $p=\gamma(0)=(0,0).$ The velocity vector or tangent at a point is $\begin{bmatrix}1 & -0.32(t+2.5)\end{bmatrix}^\top,$ or in the chart, $\begin{bmatrix}1 & -0.32(x+2.5)\end{bmatrix}^\top.$ For the attempted (are they correct (?)) calculations the composition $f\circ \gamma$ is expressed as $f(a(t), b(t)).$ $$\begin{align}
\small X_pf &= (f\circ \gamma)'(t=0) \\[2ex]
&=\left[ \frac{\partial f}{\partial x} \left(x(t),y(t)\right) \, 
\color{red}{x'(t)}+ \frac{\partial f}{\partial y}\left(x(t),y(t)\right)\,\color{red}{y'(t)}\right]\Bigg|_{t=0} \\[3ex]
&= \begin{bmatrix}\frac{\partial f}{\partial x} (p) & \frac{\partial f}{\partial y}(p)\end{bmatrix}^\top \color{red}{\underset{\text{tangent vector }\\\text{(velocity)}}{\begin{bmatrix}x'(0)\\y'(0)\end{bmatrix}}}  \\[3ex]
& = \left. \begin{bmatrix}-2 (x + 2.13) e^{(-(x + 2.13)^2 - (y + 1.16)^2)} \\  -2 (y + 1.16) e^{(-(x + 2.13)^2 - (y + 1.16)^2)}\end{bmatrix}^\top\right|_{p=\gamma(0)}\small\color{red}{\begin{bmatrix}x'(0) \\ y'(0)\end{bmatrix}} \\[3ex]
&=\small{ 2 (t + 2.13) e^{-(t + 2.13)^2 - ((-0.16 (t + 2.5)^2 + 1) + 1.16)^2} \\ + (-2 ((-0.16 (t + 2.5)^2 + 1) + 1.16) e^{-(t + 2.13)^2 - ((-0.16 (t + 2.5)^2 + 1) + 1.16)^2)}(-0.32 (t + 2.5)) \Big|_{t=0}}\\[2ex]
&=-0.00670189
\end{align}$$","['multivariable-calculus', 'differential-geometry']"
4586347,"Combinatorics with multiple design rules (e.g. no more than X instances, no more than X contiguous instances, etc.)","I am struggling with a biochemistry question that when broken down is  just a mathematics combinatorics problem. Hopefully this type of question is allowed on this Stack Exchange (apologies if it is not!). I am trying to figure out every possible combination of a sequence of characters (chemical modifications on nucleotides) given a set of design constraints (to minimize toxicity and stability). To remove the requirement of domain expertise, I will simplify the problem to a combination of a characters in a string. The string sequence must have 23 character combinations of [A, B, C, D, E] . The order of the characters in the sequence matter. The distribution of each character is not important, but the sequence must follow all the rules below: There can be at most 6 instances of A anywhere in the sequence. There can be at most 13 instances of A or B anywhere in the sequence. There cannot be more than 2 consecutive instances of C (e.g. ..ACCD.. is allowed, while ..ACCCD.. is not allowed) -- this rule only applies to C . How many combinations can be designed? I know without any design rules, there are 5^23 combinations. I think I can figure out the number of combinations given one rule by subtracting all sequences of that rule from 5^23 . However, I am stumped when there are multiple rules in play. I suspect I will have to make a Venn diagram and calculate all the overlaps, but I wonder if there is a different way to tackle this problem? I feel like this can be solved exactly, but if the problem is too specific (or complex to solve), is there at least a way I can make a rough estimate with some logical justification? I appreciate any input on this problem!","['combinatorial-designs', 'combinations', 'combinatorics']"
4586393,Integral representation for series of any order,"Hello infinity series enjoyers. If my calulations are correct, I think I made some integral representation of any divergent and convergent seris of any order s. All calulations and the question are down below. $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k)  =\overbrace {
\sum_{k_{s-1}=x} ^{\infty} ... \sum_{k_1=k_2}^{\infty} \sum_{k_0=k_1}^{\infty}}^{s}f (k_0)
=\sum_{k=x}^{\infty}f (k)\frac {( k-x+s-1)!}{\Gamma (s)(k-x)!}$ We can prove that ( Infinite series as integral representation ) $\displaystyle   \sum\limits^1_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!    f (k) = 
\lim\limits_{h \rightarrow 0} \sum_{n=0}^{\infty}\frac {\frac{d^{n}}{dx^n}F^s (x) \frac{d^{n}}{dh^n}  \left( \frac{-h}{e^h-1}   \right)    }{n!}   =-\frac {i \pi}{2}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  \csc^2 (\pi t) \int f(x+t)dt dt $ Now we have to just substitute first equation to secound $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!    f (k) =-\frac {i \pi  }{2}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  csc^2 (\pi t) \int
  f (t+x)\frac {( t+s-1)!}{\Gamma (s)(t)!}   dt dt
=\frac {i \pi (-1)^{s}}{2\Gamma (s)}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  F^{s}(x+t)\Psi_s (t)dt$ Where $F^s$ is s ordered antideritative of f and $\Psi_s(t)$ is defined down below. $\displaystyle \Psi_s(t)= \sum_{n=0} ^{\infty} \left [ \frac {d^{n}}{dt^{n}}csc^2 (\pi t) \right] \left [   \frac {d^{s-1-n}}{dt^{s-1-n}} \frac {(t+s-1)!}{ t!}   {s\choose n+1}  \right]$ But we can write $F^{s}(x+t)$ as Taylor series and compere it to generalised Euler-Maclouren Summation to determinate $(-1)^{s}$ for non itintegers $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k)  =  \sum_{n=0}^{\infty}\frac {   F^{s-n}(x)}{n!}  (-1)^s\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}(-t)^n   \frac {i \pi }{2\Gamma (s)}\Psi_s (t)dt = \lim\limits_{h \rightarrow 0}      \sum_{n=0}^{\infty} \frac {F^{s-n} (x) \frac{d^{n}}{dh^n}  \left(   \frac{-h}{e^h-1}   \right)^s    }{n!}   $ And that imply $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k) =\frac {i \pi e^{i \pi s}}{2\Gamma (s)}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  F^{s}(x+t)\Psi_s (t)dt $ Is there any simple equation for $\Psi_s (t) $ ? Maybe I overcomplicated some transformations.","['integration', 'divergent-series', 'analytic-continuation', 'sequences-and-series', 'transformation']"
4586395,How to show that $\sum_{i=1}^n i^2$ is a polynomial in $n$?,"How can I show that the following expression: $$\sum_{i=1}^n i^2$$ Is a polynomial in $n$ ? I approached this problem as follows: $$i^2=(n-(n-i))^2$$ $$\therefore \sum_{i=1}^n i^2=\sum_{i=1}^n (n-(n-i))^2$$ $$=-n^3+\sum_{i=1}^n 2in +\sum_{i=1}^n (n-i)^2$$ And at first I thought this is a polynomial in itself; however, later I realized how this might be quite redundant considering how if I were to expand the other summation signs, that will just cancel out all the terms and leave me with $\sum_{i=1}^n i^2$ .","['algebra-precalculus', 'polynomials']"
4586425,Is there a way to simplify $a\sqrt{1-a^2} + \arcsin(a) = \pi/4$?,"A while ago, I was eating pizza and wondered that if you were to cut parallel to one of the radii, how far along would you need to cut in order to split a slice's area in half? In attempting to find a general answer for a sector with radius $r$ and angle $\theta$ , I used some trigonometry to find $$a\sin\theta\sqrt{r^2 - a^2 \sin^2\theta} + r^2 \arcsin\left(\frac{a\sin\theta}{r}\right) - a^2\sin\theta\cos\theta = \frac{1}{2}r^2\theta$$ where $a$ is the distance along  from the origin where we start our cut. After seeing this I had absolutely no idea how or even if I could continue, so I tried $r=1$ and $\theta = \pi/2$ , i.e. a quarter-circle with radius 1. This gives: $$a\sqrt{1-a^2} + \arcsin(a) = \pi/4$$ Is there any way this expression can be further simplified?","['algebra-precalculus', 'trigonometry', 'transcendental-equations', 'recreational-mathematics']"
4586439,Right triangle with its perimeter and median and altitude,"A right triangle $ABC$ is given with $\measuredangle ACB=90^\circ$ . If the perimeter of the triangle is $72$ and the difference between the lengths of the median and the altitude to the hypotenuse is $7$ , find the area. Let $CD=x$ $(x>0)$ , then $CM=x+7$ . By the Pythagorean theorem, it follows that $$MD=\sqrt{(x+7)^2-x^2}=\sqrt{14x+49}.$$ For the perimeter as $AM=MB=CM=x+7$ we have $$P_{ABC}=2x+14+a+b=72\Rightarrow a+b=58-2x,$$ where $BC=a,AC=b$ . We have to find $S_{ABC}=\dfrac{2(x+7)x}{2}=x(x+7)=x^2+7x$ . I can't see how to do that. On the other hand, if the sides of the triangle are $a,b$ and $c$ , then $$\begin{cases}a+b+c=72\\\dfrac{c}{2}-\dfrac{ab}{c}=7\\a^2+b^2=c^2\end{cases}$$ and we only need to solve it for $\dfrac{ab}{2}$ . I cannot do that as well. Thanks!",['geometry']
4586503,"Relationship between the diameter of a set and the radius of a closed ball that contains it, in the $L_1$ space","What is the minimal radius $r(d)$ such that for every finite set of diameter $d$ there is a closed ball of radius $r(d)$ that contains it? This in the $L^1$ space with $n$ dimensions. In formulas, given $$ \|x - y\|_1 = \sum_{i \in \mathbb{Z}_n} |x_i - y_i| $$ $$ d(S) = \sup_{x,y \in S} \| x - y \|_1 $$ what is the minimal $r(d)$ such that: $$ \forall S \subset \Re^n, |S| \in \mathbb{N}^+ \implies \exists z \in \Re^n : \forall s \in S, \|s - z\|_1 \leq r(d(S)) $$ It's easy to prove that in every normed space $\frac{d}{2} \leq r(d) \leq d$ , the first part is from the triangle inequality and the second because with a radius of $d$ all points in S satisfy the requirement. While searching for an answer, I found https://en.wikipedia.org/wiki/Injective_metric_space which considers a more generic property that allows every point of $S$ to have different radii and different distances between each other. For that reason, it can be used to prove that $n = 2 \implies r(d) = \frac{d}{2}$ but not that $n > 2 \implies r(d) > \frac{d}{2}$ . The ideal would be to know the $r(d)$ for a generic number of dimensions $n$ , but any improvement on the $\frac{d}{2} \leq r(d) \leq d$ is welcome, and at worst I'd like to know what happens for $n \to \inf$ , as I have an $n$ that is exponential in the size of my problem's input.","['general-topology', 'normed-spaces', 'metric-spaces', 'lp-spaces']"
4586582,Find the Length of Inscribed Triangle using Trigonometry,"Can someone help me solve this question, I'm trying to teach my younger sister but was unable to find the correct answer. It's basic trigonometry, she has learnt the sine law, cosine law and unit circle trig ratios. I thought the side angles had to be 45 degrees of the inscribed triangle and could then determine other angles starting with N then L, however that did not work. The answer according to the text is: 7.2m.","['triangles', 'trigonometry', 'geometry']"
4586593,Characterization of weak solutions to a(n) (simple) ODE,"Fix $f \in L^1_{loc}(a,b)$ and define the operator $L_f: C_c^\infty(a,b) \to \mathbb{R}$ given by $$L_f(\phi) = -\int_a^b f\phi'.$$ It is well-known that $f$ is a weak solution to the differential equation $u' = 0$ . Moreover, in this case $f$ is constant a.e. I am sort of new to this idea of weak derivatives, but how could we formulate a similar operator so that $f$ is a weak solution to say for example the differential equation $u'' = 0$ ? In this case how would one find all solutions?","['ordinary-differential-equations', 'real-analysis']"
4586700,differentiability of a distance function,"Let $A\subset\mathbb{R}$ be a nonempty set, and define the function: $$f:\mathbb{R}\to\mathbb{R}\quad,\quad f(x):=\inf_{a\in A}|x-a|$$ My question is -  Is there an explicit characterization of all points $x\in\overline{A}$ at which $f$ is differentiable? My attempt Claim: Let $x\in\overline{A}$ . Then $f$ is differentiable at $x$ iff for every sequence of points ${\{y_n\}}_{n=1}^\infty\subset\mathbb{R}$ s.t. $y_n\to x$ and $y_n\neq x$ for every $n$ , there exists a sequence ${\{a_n\}}_{n=1}^\infty\subset A$ s.t. $\left|\frac{y_n-a_n}{y_n-x}\right|\to0$ . $\Rightarrow$ : $f$ is differentiable at $x\in\overline{A}$ , thus there is a sequence of points ${\{c_n\}}_{n=1}^\infty\subset A$ s.t. $c_n\to x$ , and so: $$f'(x)=\lim_{n\to\infty}\frac{f(c_n)-f(x)}{c_n-x}=\lim_{n\to\infty}\frac{0-0}{c_n-x}=0$$ Let ${\{y_n\}}_{n=1}^\infty\subset\mathbb{R}$ be a sequence s.t. $y_n\to x$ and $y_n\neq x$ for every $n$ . By properties of $f$ , for every $n$ there exists a point $a_n\in A$ s.t. $|y_n-a_n|<f(y_n)+\left|\frac{y_n-x}{n}\right|$ , and so: $$\left|\frac{y_n-a_n}{y_n-x}\right|\leq\frac{f(y_n)+\left|\frac{y_n-x}{n}\right|}{|y_n-x|}=\left|\frac{f(y_n)-f(x)}{y_n-x}\right|+\frac{1}{n}\to f'(x)=0$$ $\Leftarrow$ - Let ${\{y_n\}}_{n=1}^\infty\subset\mathbb{R}$ be a sequence s.t. $y_n\to x$ and $y_n\neq x$ for every $n$ . We assume there exists a sequence ${\{a_n\}}_{n=1}^\infty\subset A$ s.t. $\left|\frac{y_n-a_n}{y_n-x}\right|\to0$ . Then we conclude: $$\left|\frac{f(y_n)-f(x)}{y_n-x}\right|=\frac{f(y_n)}{|y_n-x|}\leq\left|\frac{y_n-a_n}{y_n-x}\right|\to0$$ Thus $f$ is differentiable at $x$ (and $f'(x)=0$ ). In my opinion, this is quite a nice property, because in some sense it means that not only that $x$ is a limit point of $A$ , but also that we can ""approximate"" every sequence that converges to $x$ with a sequence of elements of $A$ . On the other hand, It doesn't give us a clear idea of how $A$ really behaves around $x$ . Is there any characterization of the points $x\in\overline{A}$ at which $f$ is differentiable which is more straightforward?","['limits', 'derivatives', 'analysis']"
4586757,Is central manifold theorem applicable on linear dynamical systems?,"I wondered if we could apply the central manifold theorem to a linear dynamical system. I tried to solve the most general case. Having a system such as: $$
\dot{x} =  -x + f(x,y) \\
\dot{y} =  -y + g(x,y) \\
$$ Let's apply the central manifold theorem: $$
y = h(x) = \sum_{n>2}h_n x^n \\
\partial_x h(x) = n \sum_{n>2}h_n x^{n-1} \\
\dot{y} = \partial_x h(x)\dot{x} = (n \sum_{n>2}h_n x^{n-1})(-x + f(x,y)) \\
= n\sum_{n>2}h_n x^n + f(x,y) n \sum_{n>2}h_n x^{n-1} 
$$ On the other hand, we know that $$
\dot{y} = - \sum_{n>2}h_n x^n + g(x, y)
$$ Now let's apply this to the linear system of choice: $$
\dot{x} = -x + y \\
\dot{y} = -y +  x
$$ where $f(x,y) = y$ and $g(x,y) = x$ replacing $f(x, y) = y = h(x)= \sum_{n>2}h_n x^n$ would gives us $$
n\sum_{n>2}h_n x^n + n (\sum_{n>2}h_n x^n)(\sum_{n>2}h_n x^{n-1}) = 
 -\sum_{n>2}h_n x^n + x^1
$$ This equality is not met since there's a $x^1$ term on the right-hand side, which means that it's not possible to have a central manifold on a lower dimension (1d).
I also tried it with an example of a system that has $wx^1$ so I can set $w=0$ to overcome this problem.
I ended up having all the coefficients equal zero in the end: $h_i=0, i >0 $ I don't know how general is my conclusion, can we apply the central manifold theorem to Linear systems?","['manifolds', 'dynamical-systems', 'ordinary-differential-equations', 'differential-geometry']"
4586764,Do these definitions of limit points agree?,"I have seen the following two versions to define what a limit point is.
The first one is from Hatcher on page $5$ (note that I summarized the definition and didn't copy it, since it would have been too long): $(1)$ Let $X$ be a topological space and $A \subseteq X$ . Then a point $x \in X$ is called limit point of $A$ , if every open $O$ with $x \in O$ meets $A$ (that should mean that $O \cap A \neq \emptyset).$ The second one is from Wikipedia : $(2)$ Let $S$ be a subset of a topological space $X$ . A point $x \in X$ is called limit point of $S$ , if every neighbourhood of $x$ contains at least one point of $S$ different from $x$ itself. Hatcher and Wikipedia both define neighbourhood the same way, that is, a neighbourhood of a point $x$ in $X$ is a set $A$ such that an open set $O$ exists with $x \in O \subseteq A$ . Suppose that $X$ is a space equipped with the discrete topology and containing at least two distinct points $x,y$ . Suppose further that $A \subseteq X$ and that $x$ is a limit point of $A$ in the sense of Hatchers definition. Then $O:=\{x\}$ is open, contains $x$ and meets $A$ by assumption. Furthermore $O$ is an open neighbourhood of $x$ but does not contain a point apart from $x$ . Am I overseeing something or do these definitions just not coincide?","['general-topology', 'definition']"
4586801,Solving Kronecker product equation,I am trying to solve for $\mathbf{X}$ the following equation $\mathbf{A}\otimes \mathbf{X}=\mathbf{B}$ Is there a closed form solution to this? Thank you very much in advance!,"['matrices', 'systems-of-equations', 'kronecker-product']"
4586840,Hypothesis Testing Two Measures Coin Tosses Martingale,"Consider a sequence of iid tosses of a coin with $X_i$ denoting the outcome of the $i^{th}$ toss. These random variables are defined on some $(\Omega, \mathcal{F})$ on which we have two probability measures $\mathbb{P}_{A}$ and $\mathbb{P}_{B}$ . Under hypothesis $A$ , $\mathbb{P}_{A}$ is the true measure, and the probability of a head on any toss is $p=a$ . Under hypothesis $B$ , the measure is $\mathbb{P}_{B}$ and $p=b$ for some $a,b \in (0,1)$ . Let $P_{A}(x_1, x_2, \dots, x_n)$ denote the probability of a sequence of outcomes $(x_1, x_2,\dots, x_n)$ under the hypothesis $A$ , i.e. $$P_{A}(x_1, x_2, \dots, x_n) = \mathbb{P}_{A}(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n),$$ with the analogous definition for $P_B$ . I need to show that $$Z_n = \frac{P_A(X_1, X_2, \dots, X_n)}{P_B(X_1, X_2, \dots, X_n)}$$ is a martingale under $\mathbb{P}_{B}$ , relative to the filtration generated by the tosses, $\mathcal{F}_n = \sigma(X_k : k \le n)$ . Then I need to see what happens to the distribution of its limit (which I will know exists almost surely by the Martingale Convergence Property). I am struggling to prove that $Z_n$ is indeed a martingale: it is clear that it is adapted, but I am not sure how to show integrability and the expectation property. Would it also follow that $\frac{1}{Z_n}$ is a $\mathbb{P}_{A}-$ martingale?","['measure-theory', 'statistics', 'martingales', 'probability-theory', 'probability']"
4586841,Why isn't there an extra term in the jacobian to account for how much du and dv are perpendicular?,"I wanted to derive the formula for the multivariable change of basis in an integral on my own (for the 2 by 2 case). What I did was: $$x=f(u,v)$$ $$y=g(u,v)$$ so $$dx = \frac{\partial f}{\partial u}du + \frac{\partial f}{\partial v}dv$$ $$dy = \frac{\partial g}{\partial u}du + \frac{\partial g}{\partial v}dv$$ Then, $$dx \wedge dy = (\frac{\partial f}{\partial u}du + \frac{\partial f}{\partial v}dv) \wedge (\frac{\partial g}{\partial u}du + \frac{\partial g}{\partial v}dv) = (\frac{\partial f}{\partial u}\frac{\partial g}{\partial v} - \frac{\partial g}{\partial u}\frac{\partial f}{\partial v}) du \wedge dv$$ I recognize that term as the Jacobian. Then: $$dx\wedge dy = J(u,v) du \wedge dv$$ but I don't want to be working with bivectors, I want to work with scalars. I take the absolute value on both sides and since dx is perpendicular to dy: $$dx dy = J(u,v) \sin(\theta) du dv $$ where $\theta$ is the angle between the two vectors. This is not the formula I learned in my undergraduate studies. How did the original formula work even if dx and dy were scalars?","['jacobian', 'multivariable-calculus', 'vector-analysis']"
4586879,Understanding the proof that the conditional distribution of a Gaussian random variable is linear in the conditioning Gaussian,"Let $X: \Omega \to \mathbb{R}$ , and $Y:\Omega \to \mathbb{R}^d$ be random variables such that $(X,Y)$ is a Gaussian random vector. Then there exists $a,b_1, \dots, b_k \in \mathbb{R}$ such that $$P(X\in dx| Y=y)=N(a+\sum b_k y_k, \sigma^2)$$ where $Z \sim N(0,\sigma^2)$ is a Gaussian independent of Y from a previous theorem. The proof below is from Rene Schilling. I have two questions regarding the proof. First, how do we get $E(g(Y)e^{i\xi (a+\sum b_k Y_k + Z}))=\int g(y) E(e^{i\xi (a+\sum b_k y_k + Z}))P(Y\in dy)$ from the fact that $Z $ and $Y$ are independent? Second, I cannot understand the final identity. Why does the identity $E(g(Y) \int e^{i\xi x} P(X\in dx|Y) = \int g(y) E(e^{i\xi (a+\sum b_k y_k + Z))}) P(Y\in dy)$ for any bounded measurable $g$ imply that $\int e^{i\xi x} P(X\in dx|Y=y) = E(e^{i\xi (a+\sum b_k y_k + Z)})$ ? I would greatly appreciate a rigorous explanation to these details.","['conditional-probability', 'probability-distributions', 'conditional-expectation', 'probability-theory', 'probability']"
4586908,A question about Burnside normal p-complement theorem,"When I read the proof of Burnside normal p-complement theorem, I have a question. The theorem is : If for some prime $p$ a Sylow $p$ -subgroup $P$ of a finite group $G$ lies in the centre of its normalizer, then $G$ is p-nilpotent. The following proof comes from ""A course in the theory of groups"". Proof: By hypothesis $P$ is abelian and $P = C_P(N_G(P)$ , We deduce at once
from $10.1.6$ that $P ~\cap $ $Ker ~\tau$ = $e$ where of course $\tau$ : $G \rightarrow P$ is the transfer. This means that Ker $\tau$ is a $p'$ -group, which in turn implies that $G$ is $p$ -nilpotent since $G/\mathrm{ker} \tau \cong \mathrm{Im} \tau $ , a $p$ -group. The theorem $10.1.6$ is : Let the finite group $G$ have an abelian Sylow $p$ -subgroup $P$ and let $N$ denote $N_G(P)$ .
Then $P = C_P(N) \times [P, N]$ . Moreover, if $\tau $ : $G \rightarrow P$ is the transfer, Im $ \tau $ = $C_P(N)$ and $P ~\cap $ Ker $\tau$ = [P,N]. My question is how to get  ker $\tau$ is a $p'$ -group? Thanks!","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
4586930,"Variable-step Runge-Kutta methods, Fehlberg vs Dormand-Prince: why is the order reversed?","Dormand-Prince and Fehlberg are two popular Runge-Kutta embedded methods for ODE integration with adaptive stepsize. The former one estimates the error with the lower-order method and steps forward with the higher-order method; in the latter one the two roles are reversed. I do not understand the reason for this. Why does Fehlberg method step forward with the lower-order method, instead of stepping forward with the higher-order method which is more accurate and whose result is readily available? Whatever is the problem that I am not seeing: I expect that Dormand-Prince method is not affected by that, since it does indeed step forward with the higher-order method","['runge-kutta-methods', 'numerical-methods', 'ordinary-differential-equations']"
4587006,Find all monotonic functions $f : \mathbb{R}\to\mathbb{R}$ that satisfy $f''(x) + xf'(x) - (\delta+\gamma f(x))(f'(x))^2>0$,"I would like to find a set of functions that satisfy the following: Find all monotonic functions $f : \mathbb{R}\to\mathbb{R}$ that satisfy $f''(x) + xf'(x) - (\delta+\gamma f(x))(f'(x))^2>0$ where $\gamma$ and $\delta$ are finite, non-zero constants. (A previous version of the question had $\gamma = \delta \equiv 1$ , but this need not necessarily be the case). The equation in the inequality is the derivative of a generalised log-odds function, the condition implying the final logistic curve is strictly increasing. Ideally, bounding the inequality by taking limits as $x\to\pm\infty$ should lead to an expression dependent solely on the parameters $\gamma$ and $\delta$ ${}^{1}$ . Properties that would naturally seem to be needed are $f'(x)\to 0$ and $f''(x)\to 0$ as $x \pm\infty$ . Two good candidates I have found that would satisfy this are: $f(x) = \text{arcsinh}(x)$ , and $f(x) = \tanh{(x)}$ , yet I'm not sure how to exploit their limiting behaviour to reduce the inequality to a simple form for $\gamma$ and $\delta$ (i.e., no explicit dependence on $x$ ). How can I do this in a rigorous manner? Are there any other suitable monotonic functions $f : \mathbb{R} \to \mathbb{R}$ ? ${}^{1}$ This is for optimisation purposes guaranteeing the monotonicity of the logistic curve for some functional form of $f(x)$ . In reality $x$ will never reach $\pm\infty$ ; it will exist in the interval $\left(\Phi^{-1}(\varepsilon),\Phi^{-1}(1-\varepsilon)\right)$ where $\mathcal{O}(\varepsilon) \sim 10^{-6}$ . Therefore, for practical purposes, if bounding the inequality via the asymptotic limiting behaviour of $f(x)$ is too troublesome, we can also bound it by assessing its value as $x\to \pm 5$ .","['nonlinear-analysis', 'analysis', 'real-analysis', 'functions', 'convex-analysis']"
4587011,Is $\left(n+\frac{1}{2}\right) H_n+(\gamma -1) n$ a better asymptotic to the partial sums of the number of divisors than $n (\log (n)+2 \gamma -1)$?,"The partial sums of the number divisors can be written in Mathematica as: $$\sum _{k=1}^n \sigma _0(k)=\sum _{k=1}^n \left(\sum _{q=1}^{\frac{n}{k}} \frac{1}{q^s}\right)$$ which is sequence A006218 in the OEIS, starting: 1, 3, 5, 8, 10, 14, 16, 20, 23, 27, 29, 35, 37, 41, 45,... Mathematica knows that: $$\lim_{n\to x} \, \left(\sum _{q=1}^{\frac{n}{k}} \frac{1}{q^s}\right)=\zeta (s)-\zeta \left(s,\frac{k+x}{k}\right)$$ Limit[Sum[1/q^s, {q, 1, n/k}], n -> x] Now truncate the sums at $n_1=1,\; n_1=2,\; n_1=3,\; n_1=4\,\; n_1=5$ and $n_1=6$ , and let $n$ be a vector from $1$ to $6!$ like this: $$r_1=0$$ $$r_{i+1} = \text{Mean}\left[\sum _{k=1}^{n_1} \left(\zeta (s)-\zeta \left(s,\frac{n}{k}+1\right)\right) - \sum _{k=1}^{n_1} \left(\sum _{q=1}^{\frac{n}{k}} \frac{1}{q^s}\right)-r_i \right]$$ where $i=1,2,3,4,5$ We can compute $r_i$ by running this Mathematica program: (*start*)
Clear[nn, s, n1, A, B k, n, q, r];
nn = 1*2*3*4*5*6;
s = 0;
(*n1=2;*)
r = 0;
Table[Show[
  ListPlot[A = 
    Table[Re[Sum[Sum[1/q^s, {k, 1, n/k}], {k, 1, n1}]], {n, 1, nn}]], 
  ListLinePlot[
   B = Table[
     Re[Sum[Zeta[s] - HurwitzZeta[s, n/k + 1], {k, 1, n1}]] + r, {n, 
      1, nn}], PlotStyle -> Red]];
 ListLinePlot[A - B];
 r = r + Mean[A - B];
 r, {n1, 1, 6}]
Differences[%]
(*end*) we then get the output: {0, -(1/4), -(7/12), -(23/24), -(163/120), -(71/40)} of which the first differences are: {-(1/4), -(1/3), -(3/8), -(2/5), -(5/12)} as unreduced fractions that is: {-(1/4), -(2/6), -(3/8), -(4/10), -(5/12)} which looks like the first differences of the sum: $$\sum _{k=1}^{n_1} \frac{1-k}{2 k}$$ Setting s to any integer the general term seems to be: $$\sum _{k=1}^{n_1} \frac{(1-k) \left(\frac{n}{k}\right)^{-s}}{2 k}$$ Adding this into the above, we get: $$\sum _{k=1}^{n_1} \left(\sum _{q=1}^{\frac{n}{k}} \frac{1}{q^s}\right) = \sum _{k=1}^{n_1} \left(\zeta (s)-\zeta \left(s,\frac{n}{k}+1\right)\right)+\sum _{k=1}^{n_1} \frac{1-k}{2 k}$$ Returning to the untruncated expression - that is, replacing $n_1$ with $n$ - and also adding a second conjecture we now have: $$\sum _{k=1}^n \sigma _0(k) = \sum _{k=1}^{n} \left(\sum _{q=1}^{\frac{n}{k}} \frac{1}{q^s}\right) \approx \sum _{k=1}^{n} \left(\zeta (s)-\zeta \left(s,\frac{n}{k}+1\right)\right)+  \underbrace{\sum _{k=1}^{n} \frac{1-k}{2 k}}_{\text{conjectured from the fractions r}} + \underbrace{\left(\gamma -\frac{1}{2}\right)n}_{\textbf{second conjecture}}$$ $$\sum _{k=1}^{n} \left(\zeta (s)-\zeta \left(s,\frac{n}{k}+1\right)\right) = n H_n$$ $$\sum _{k=1}^{n} \frac{1-k}{2 k} = \frac{H_n-n}{2}$$ Inserting: $$\sum _{k=1}^n \sigma _0(k) = \sum _{k=1}^{n} \left(\sum _{q=1}^{\frac{n}{k}} \frac{1}{q^s}\right) \approx n H_n +  \underbrace{\frac{H_n-n}{2}}_{\text{conjectured from the fractions r}} + \underbrace{\left(\gamma -\frac{1}{2}\right)n}_{\text{second conjecture}}$$ and simplifying: $$\sum _{k=1}^n \sigma _0(k) \approx \left(n+\frac{1}{2}\right) H_n+(\gamma -1) n$$ Comparing with the main term in Dirichlet divisor problem: $$\sum _{k=1}^n \sigma _0(k) \approx n (\log (n)+2 \gamma -1)$$ First 8 terms: The suggested new asymptotic: Dirichlet's asymptotic in the OEIS: I notice that the asymptotic given in the OEIS has a bias towards the more negative values. Why is that? Has anyone ever written a better asymptotic for the partial sums of the number of divisors?","['number-theory', 'asymptotics', 'elementary-number-theory']"
4587013,"If $2^\frac{2x-1}{x-1}+2^\frac{3x-2}{x-1}=24$, find all values of $x$ that satisfy this","As title suggests, the problem is as follows: Given that $$2^\frac{2x-1}{x-1}+2^\frac{3x-2}{x-1}=24$$ find all values of $x$ that satisfy this. This question was shared in an Instagram post a few months ago that I came across today. Examining it at first, it seems there are many ways to solve this. I'll show my own approach here, please let me know if there are any issues in my solution and please share your own solution too! Here's my approach for the problem: Let $a=2^\frac{2x-1}{x-1}$ and $b=2^\frac{3x-2}{x-1}$ We then get $a+b=24$ . Now notice that: $$(3x-2)-(2x-1)=x-1$$ That gives us a motivation to perform division with $a$ and $b$ (as the denominator and numerator of the exponent will be equal, hence reducing the exponent) thus: $$\frac{b}{a}=\frac{2^\frac{3x-2}{x-1}}{2^\frac{2x-1}{x-1}}$$ $$\frac{b}{a}=2^\frac{x-1}{x-1}=2$$ $$b=2a$$ Therefore: $$2a+a=24$$ $$3a=24$$ $$a=8$$ $$2^\frac{2x-1}{x-1}=8$$ $$2^\frac{2x-1}{x-1}=2^3$$ $$\frac{2x-1}{x-1}=3$$ $$2x-1=3x-3$$ Thus, $x=2$","['contest-math', 'algebra-precalculus', 'solution-verification', 'exponential-function']"
4587033,Is $A \subseteq \mathcal{P}(A)$?,"I have a Math example test to prepare for the real one, but I think my professor made an error: Question: True or false?: For any $A$ set, $A \subseteq  \mathcal{P}(A)$ . Answer: False But if $P(A)$ is the set of every subset of $A$ , it also has to contain $A$ itself, as $A \subseteq A$ . (True by definition.) Thus my conclusion is that the answer should be true. I also considered that because $A$ is a set, and $\mathcal{P}(A)$ is a set of sets, $A \not\subseteq \mathcal{P}(A)$ , but { $A$ } $\subseteq P(A)$ , but that makes it that $A \subseteq $ { $A$ }, which implies that $A \subseteq \mathcal{P}(A)$ , doesn't it? Thank you for your time and answers.","['elementary-set-theory', 'discrete-mathematics']"
4587075,"Show that $S$ contains $n+1$ different numbers $a_1,\cdots, a_{n+1}$ such that $a_i | a_{i+1}$ for each $1\leq i\leq n.$","(Romanian IMO/BMO Team Selection Tests April 2005 Day 1 Problem 2). Let $n$ be a positive integer and $S$ a set of $n^2 + 1$ positive integers with the property that every $(n+1)$ -element subset of $S$ contains two numbers one of which is divisible by the other. Show that $S$ contains $n+1$ different numbers $a_1,\cdots, a_{n+1}$ such that $a_i | a_{i+1}$ for each $1\leq i\leq n.$ I think there should be an elementary solution that doesn't require theorems such as Dilworth's Theorem regarding posets. For the elementary solution, it could be useful to use the pigeonhole principle, induction, or a proof by contradiction. It might also be useful to come up with a sufficiently-sized example of such a set of positive integers in the first place. For $n=1$ , $S$ has two elements, one of which is divisible by the other and the claim trivially holds. Here's a proof for the $n=2$ case that I came up with myself: For $n=2$ , $S$ needs $5$ integers. Write $S = \{b_1,b_2,\cdots, b_5\}, b_1 < b_2<\cdots < b_5$ . Every $3$ -element subset of $S$ has $2$ elements one of which divides the other. Suppose $S$ does not have $3$ different numbers that divide each other consecutively. Then consider the first three elements of $S$ . We may find $a_1,a_2$ among them with $a_1 | a_2$ . Then by assumption $a_2$ cannot divide any other element of $S$ . Assume first that $a_1 = b_1$ . If $a_2 = b_2$ , then considering $\{b_2,b_3,b_4\}$ , we see that $b_3 | b_4.$ Considering $\{b_2,b_3,b_5\},$ we see that $b_3 | b_5.$ Considering $\{b_2,b_4,b_5\},$ we see $b_4 | b_5.$ But this gives a contradiction since we can choose $\{b_3,b_4,b_5\}$ as the 3-element subset. Now assume $a_2 = b_3$ . Considering $\{b_3,b_4,b_5\},b_4 | b_5.$ Considering $\{b_2,b_3,b_4\},$ we see that $b_2 | b_3$ . Considering $\{b_1,b_2,b_4\},$ we see that there is no possibility left (that won't lead to a contradiction). Finally, assume $a_1 = b_2,a_2=b_3.$ Considering $\{b_3,b_4,b_5\}, b_4 | b_5.$ Considering $\{b_1,b_2,b_4\}$ , we see that there is no possibility left. Hence the claim must hold for $n=2$ . Here's the technical solution I found online. We can define a poset on $S$ by $x\leq y$ iff $x|y$ . The condition that there does not exist an $n+1$ element subset such that no element divides another translates into the condition that there is no antichain of length $n+1$ in $S$ . An antichain is any sequence of pairwise distinct elements of $S$ none of which are comparable according to the ordering on the poset on $S$ . Hence the longest antichain in $S$ is of length at most n, so by Dilworth's theorem, $S$ can be written as the union of at most n chains. Since $S$ has $n^2+1$ elements, this implies one of these chains has a length of at least $n+1$ . Version of Dilworth's Theorem used: Let $P$ be a finite poset. Then the smallest set of chains whose union is $P$ has the same cardinality as the longest antichain.","['contest-math', 'divisibility', 'elementary-number-theory', 'combinatorics', 'discrete-mathematics']"
4587077,if $V\subseteq U\subseteq V\cup W$ then is it true that $U\subseteq W$?,"So I am trying to understand if $U$ , $V$ and $W$ are three sets such that $$
\tag{0}\label{0}V\subseteq U\subseteq V\cup W
$$ then the inclusion $$
\tag{1}\label{1}U\subseteq W
$$ must hold: indeed, what show to follow seems confute \eqref{1}. So let be $Y$ a not empty subset of a topological space $X$ and thus let be $H$ a subset of $X$ such that $$
\tag{2}\label{2}\operatorname{bd} Y⊆H⊆\operatorname{cl}Y
$$ So if the last inclusion holds then we observe that the inclusion $$
\tag{3}\label{3}X\setminus\operatorname{cl}Y\subseteq X\setminus H\subseteq X\setminus\operatorname{bd}Y
$$ holds but we know that $$
\operatorname{ext}Y=X\setminus\operatorname{cl}Y\quad\text{and}\quad X\setminus\operatorname{bd}Y=\operatorname{ext}Y\cup\operatorname{int}Y
$$ so that by \eqref{3} we infer that $$
\tag{4}\label{4}\operatorname{ext}Y\subseteq X\setminus H\subseteq\operatorname{ext}Y\cup\operatorname{int}Y
$$ So if \eqref{1} was true then \eqref{4} would implies that $$
\tag{5}\label{5}\operatorname{ext}Y\subseteq X\setminus H\subseteq\operatorname{int}Y
$$ which is true only if $\operatorname{ext}{Y}$ is empty. So I ask to clarify if \eqref{1} holds and in particular if it does not hold then I ask to give a more handy counterexample; moreover I ask if \eqref{4} holds when \eqref{2} does. So could someone help me, please?","['elementary-set-theory', 'general-topology', 'examples-counterexamples']"
4587110,"Given a vector, find others vectors which form 90º with the first","I've got a vector v = (3,-1). The thing is I need to find other vectors so that the angle between them forms 90º. We are talking about R^2. I have thought about using the following formula: Formula However, I don't seem to reach any correct answers with this method, & I don't know if I am approaching this problem the correct way. Any help please?","['algebra-precalculus', 'linear-algebra']"
4587126,Bounding Baker-Campbell-Hausdorff error with commutator of exponentials,"Given matrices $A$ and $B$ , one can find an upper bound on the error $\epsilon = ||e^{A + B} - e^{A} e^{B}||$ in terms of the magnitude of the commutator between $A$ and $B$ , $|| [A, B] ||$ , as is done is papers such as https://arxiv.org/abs/1912.08854 . Are there any analogous results which bound $\epsilon$ in terms of the commutator magnitude $|| [e^{A}, e^{B}]||$ ? (in particular, when $A$ and $B$ are Hermitian)? I would suspect (naively) that some result in this direction may hold, seeing as when $A$ and $B$ are Hermitian, $[A, B] = 0 \Leftrightarrow [e^{A}, e^{B}] = 0$ , but I have yet to find anything.","['lie-algebras', 'matrix-exponential', 'linear-algebra', 'lie-groups', 'differential-geometry']"
4587135,Roots of $\cos{x}+\cosh^2{x}$,"I wanted to find the roots of $\cos{x}+\cosh^2{x}=0$ to solve an integral with this expression in the denominator. I started by using the exponential definitions of the cosine function and its hyperbolic counterpart. At first, I tried substituting $v=e^x$ and I got the following equation $$v^2+v^{-2}+2v^i+2v^{-i}=-2$$ I don't know how to proceed because of the complex exponents. For my second try, I reduced the equation into the following. $$e^{2x}+e^{-2x}+2(e^{ix}+e^{-ix}+1)=0$$ Multiply both sides by $e^{2x}e^{ix}$ $$(e^{4x}+1)e^{ix}+2e^{2x}(e^{2ix}+e^{ix}+1)=0$$ Replace $e^x$ with $a$ and $e^{ix}$ with $b$ $$(a^4+1)b+2a^2(b^2+b+1)=0$$ After some manipulation we get the following system $$\frac{b}
{b^2+b+1}=\frac{-2a^2}{a^4+1}$$ $$a^i=b$$ It sure is elegant, but I don't know how to continue after this. WolframAlpha gives 4 roots. Interestingly enough, they're all conjugates and negatives of each other.
I want a closed form for these roots","['systems-of-equations', 'hyperbolic-functions', 'roots', 'trigonometry', 'exponential-function']"
4587143,Continuity of Hilbert transform,"Suppose $f : \mathbb{R} \to \mathbb{R}$ , be a non-negative, bounded and continuous function, and its support is a compact interval in $\mathbb{R}$ . Moreover, we have that $\int f(x) \, dx =1$ . The Hilbert transform of $f$ is defined as: $$
g(y) := H[f](y) = PV \frac{1}{\pi} \int_{\mathbb{R}} \frac{f(x)}{x-y} \, dx
$$ What can we say about the continuity and boundedness of the function $g(y)$ on $\mathbb{R}$ ? If view the Hilbert transform as the convolution with the function $\frac{1}{\pi x}$ , maybe we can use this post ?
But $\frac{1}{\pi x}$ is un-bounded at $x = 0$ !","['convolution', 'complex-analysis', 'continuity', 'calculus', 'cauchy-principal-value']"
4587276,Why do these results not contradict Green's Theorem?,"I have a vector field $\;\underline{v}(x,y) = \left(\dfrac{-y}{x^{2}+4y^{2}}, \dfrac{x}{x^{2}+4y^{2}}\right)$ $\text{curl }\underline{v} = 0$ and thus the vector field is conservative. I have a surface, $\Omega$ , with $\Omega:=\left\{(x,y)\in \mathbf{R}^2: x^2+4y^2=4\right\}$ . A parameterisation of the border of $\Omega$ , $\partial\Omega$ is $\underline{r}(t) = \big(2\cos(t), \sin(t)\big)$ , for $t \in [0, 2\pi]$ The integral $\oint_{\partial\Omega}\underline{v}\cdot d\underline{r} = \pi$ However, by Green's Theorem, $\oint_{\partial\Omega}\underline{v}\cdot d\underline{r} = \iint_{\Omega}\textbf{curl}\,\underline{v}\text{ }dxdy$ . Since curl $\underline{v} = 0$ , and the curve is closed, $\oint_{\partial\Omega}\underline{v}\cdot d\underline{r} = 0$ Why are these two results not contradictory? Edit: I think that this might be because $\underline{v}(0,0)$ is undefined, however I am not sure what difference that would make, nor how to formalise why this is not a contradiction.","['vector-fields', 'curl', 'multivariable-calculus', 'calculus', 'line-integrals']"
4587293,Is a point where any sequence that converges to it contains it the same thing as an isolated point?,"Suppose I have a topological space $(X, \tau^X)$ . Based on the Wikipedia definition of an isolated point , $p \in X$ is an isolated point if and only if $\{p\} \in \tau^X$ . In one specific example I'm looking at, I have one point that seems very different from all the rest. The first thing that I noticed about this point $p$ is that every sequence $s$ that converges to $p$ is eventually constantly $p$ . I heard the phrase ""isolated point"" before, so I looked it up on Wikipedia, but I didn't see a theorem connecting the open-set-flavored definition to sequence/net/filter-flavored definition, which made me curious. I'm wondering whether the sequence characterization is equivalent in general to being an isolated point. Assuming the sequence characterization is inequivalent, is there a more general kind of pseudosequence like a net that can capture the notion of being an isolated point. What follows is motivation. The question above is self-contained without the movation. I asked this question earlier today and tried to come up with a linear order without endpoints with no fixed-point-free order-automorphisms. My first attempt was the order $ \mathbb{R} + \{0\} + \mathbb{R} $ which was unsuccessful (since it is equivalent to $\mathbb{R}$ as Noah Schweber points out here ). My next and current attempt is the order $\mathbb{R} + \{ 0, 1, 2 \} + \mathbb{R}$ , which I'll call $\alpha$ . I'm pretty sure an order-automorphism of this ordering must fix $1$ . If I endow $\alpha$ with the order topology, then $1$ is an isolated point because the open interval $(0, 2)$ is $\{1\}$ . $1$ also has the property that any sequence that approaches it, intuitively, will eventually need to ""hop over"" the chasm between $0$ and $1$ or between $1$ and $2$ . The visual metaphor of ""eventually needing to jump"" is pretty natural, so it seems like it must correspond to something.","['order-theory', 'general-topology']"
4587322,Which pentacube oddities can be solved or improved?,"A few years ago I studied pentacube oddities.  A pentacube is a polycube with 5 cells, and an oddity is an arrangement of an odd number of copies of a polyform that has binary symmetry (or stronger).  So far as I know, Torsten Sillke was the first to study oddities in general, and polycube oddities in particular.  Mike Reid has also studied
them. In particular, I wanted oddities with full (cubic) symmetry.  This page summarizes my results: https://userpages.monmouth.com/~colonel/c5odd/index.html . This catalogue has weaknesses.  Among achiral (mirror-symmetric) pentacubes, my solutions for the T, W, and Z pentacubes are made from rectangular boxes known to be tilable.  They have hundreds or thousands of tiles.  I have no solution for the X pentacube. Among chiral pentacubes, my solutions for the H and S pentacubes are formed from rectangular boxes.  They have 145 and 675 tiles respectively.  I have no solution for the G pentacube unless we let the tiles be reflected. Can anyone improve on these results, or suggest a method for improving them?","['3d', 'geometry', 'combinatorics', 'polyomino', 'symmetry']"
4587333,Differential Equations Solving for Critical Points,"$x'' +20x - 5x^3 = 0$ Did a quick substitution and found the critical points to be $(2,0), (-2,0)$ , and $(0,0)$ . However, when solving for the eigen values of the corresponding matrix found that the eigen values were both $0$ . Unclear what to do from now. My matrix was $\big\{\{0,1\},\{5x^2-20,0\}\big\}$ .",['ordinary-differential-equations']
4587350,"For any polynomial f(x) with integer coefficients, is it possible that the the greatest prime factor of f(x) can be arbitrary small?","Recently I found a problem about elementary number theory: Let $f(x)=x^2+x+1$ ,prove that there are infinite $n\in N$ so that the the greatest prime factor of $f(n)$ is less than $n^{1.1}$ . The answer is easy. We only need to take $n=m^2$ ,so $f(n)=(m^2+m+1)(m^2-m+1)$ .For sufficiently large $m$ ,the conclusion is obvious. Question .For any given polynomial $f(x)\in Z[x]$ and any given positive real number $a$ ,are there infinite $n\in N$ so that the greatest prime factor of $f(n)$ is less than $n^a$ ？ Remark .The original question is for some specific polynomial like $x^k-1$ ,and in this case I know the proposition is true which can be proved through the cyclotomic polynomial. But for any $f(x)\in Z[x]$ ,I don't know whether it is correct. I tried to prove that we can always take some n  with some special forms such as $n=m^2$ like what I did before so that $f(n)$ can be a reducible polynomial. I succeeded in proving it but finally I failed because I didn't know how to deal with the factor of $f(n)$ after the factorization. Although the tags include ""elementary number theory"", I think this question might be quiet difficult and not an elementary question. So if anyone can give the answer or give some advice, I would be grateful. PS .I'm going to post my proof below when $f(x)=x^k-1$ . Let $n=y^m$ , and then $f(n)=y^{mk}-1$ . Let $\Phi_i(x)$ be the i-th cyclotomic  polynomial so we have $f(n)=\Pi_{d|mk}\Phi_d(y)$ The Maximum degree of $\Phi_d(y)$ is $\phi (mk)$ , so we only need to prove $\phi (mk)<am$ . Assume $(k,m)=1$ , so the inequality is $\frac{\phi (m)}{m}<\frac{a}{\phi (k)}$ . In fact the LHS can be  arbitrary small for we know that reciprocal sum of all prime numbers is  divergent . Take $m=p_1p_2......p_r$ where $p_i$ are different prime numbers and r is a sufficiently large number, we get the conclusion.","['number-theory', 'polynomials', 'elementary-number-theory']"
4587364,A question about the closedness of $C$-embedded subsets,"In the answer of this post it is proven that in every first countable Tychonoff space the $C^{*}$ -embedded subsets are closed. Since countable pseudocharacter (i.e., points are $G_\delta$ sets) is a natural weakening of first countability, the corresponding question surges immediately: is it true that in every Tychonoff space with countable pseudocharacter the $C^*$ -embedded subsets are closed? Now, it is not difficult to prove that the Single Ultrafilter Topology is a Tychonoff space with countable pseudocharacter that admits a non-closed $C^*$ -embedded subset. However, it can be checked that the natural subset of the preceding space that checks the properties in question is not $C$ -embedded in the space. For this reason, a natural question arises again: is it true that in Tychonoff spaces with countable pseudocharacter it is satisfied that the $C$ -embedded subsets are closed? Regarding this last question, it appears as exercise 1K(2) in the book ""Extensions and Absolutes of Hausdorff spaces"" by Porter and Woods; therefore, it seems that the answer to this last question is affirmative. However, I have not been able to prove it. Any kind of help to find out the truth would be greatly appreciated!",['general-topology']
4587371,Is there any simple set of properties which uniquely characterizes differentiation?,"The transformation of differentiation is a linear operator over $C^\infty(\mathbb{R}),$ the vector space of smooth functions over $\mathbb{R}.$ Is there any simple set of properties that uniquely determines this linear operator other than the standard definition?","['smooth-functions', 'calculus', 'linear-transformations', 'derivatives', 'soft-question']"
4587404,Can you provide relevant study aids for Discrete Mathematics?,"I am taking a discrete mathematics course this spring for my major in cyber security and trying to find study aids( amazon ), online groups, or other sites. The assigned book is $$""Discrete\ Mathematics\ and\ Its\ Applications\ 7th\ ed.""$$ $$\mbox{isbn-}13 : 978\mbox{-}0073383095$$","['discrete-mathematics', 'reference-request']"
4587406,Why are there only 5 abelian groups of order 48?,"I am trying to understand exactly how this works. I am following this procedure up until it shows the second equivalences. For example, why is $\mathbb{Z}_{2^3}\times \mathbb{Z}_{2} \times \mathbb{Z}_{3} \cong \mathbb{Z}_2 \times \mathbb{Z}_{24}$ ? Furthermore, why isn't it isomorphic to $\mathbb{Z}_{48}$ , or any of the other products on the RHS of the second equivalence?","['group-theory', 'group-isomorphism', 'abelian-groups']"
4587426,Ice cream shop offers 8 different flavours. How many different two-scoop dishes are possible?,"(Repetition is allowed) An Ice cream shop offers 8 different flavours of ice cream. How many different two-scoop dishes are possible if (a) Two scoops are placed side by side in the dish? (b) Two scoops are placed on top of the other? Let the flavours be {a,b,c,d,e,f,g,h}. My approach to the first question is using combination, since the order of the scoops doesn't matter. C(8,2) = 28 And then, we combine the answer with 8 which represents the total number of repeated flavours {aa,bb,cc,dd,ee,ff,gg,hh}.
Therefore, the final answer is 28+8 = 36 ways. For the second question, the order matters as the scoops are placed on top of the other. Therefore, it is permutation. P(8,2) = 56 And then, similar to the first question, we combine the answer with 8 which represents the total number of repeated flavours. Therefore, the final answer is 56+8 = 64 ways. However, I'm uncertain about my solutions and the approaches to solve the given problem. Therefore, I would like to request a comment upon my solution. Thank you in advanced.","['permutations', 'combinations', 'discrete-mathematics']"
4587473,Does there exist a graph that the page ranks of each node are distinct?,"Suppose that there is a graph of $n$ nodes ( $n>3$ ), is it possible that every node has a distinct page rank value? the page rank is defined as $R$ while $MR=R$ , $M$ is the transition matrix. I have sampled one thousand random graph (10 nodes) and found no such graph, therefore I guess such graph does not exist. But I don't know how to prove this. Could someone give me some hints?","['graph-theory', 'page-rank', 'matrix-equations', 'discrete-mathematics']"
4587553,Principal solutions of trigonometric equations and angle between two lines.,"In the fig., the red line has a slope of $\frac{1}{2}$ and the green line has a slope of 3. We can find the angle $\theta$ between the lines as follows: $\begin{array}{ll}
{}&{\tan \theta}
&{}={}& {\frac{m_2~-~m_1}{1~+~m_1 m_2}}
&{} \\
{}&{}
&{}={}& {\frac{3~-~\frac{1}{2}}{1~+~\frac{1}{2}  × 3}}
&{} \\
{}&{}
&{}={}& {\frac{6 ~-~1}{2~+~3}}
&{} \\
{}&{}
&{}={}& {\frac{5}{5}}
&{} \\
{}&{}
&{}={}& {1}
&{} \\
\end{array}$ So we have to solve the equation $\tan \theta = 1$ . But there are two values that will satisfy the equation. They are: $45^o~\text{and}~225^o$ . Could you please explain how $225^o$ is related to the ""angle between the two lines"".
Thanks.","['analytic-geometry', 'trigonometry']"
4587615,The probability that the minimum number is unique,"If I draw $n$ integers $X$ from $[1, n]$ uniformly at random, what is the probability that $\min\left(X\right)$ is unique, i.e. that there is only one number in $X$ that is $\min\left(X\right)$ ? I tried to find a closed form solution for this, but I have not been successful. I've tried to estimate the number both with sampling and also exactly, and it seems like it converges towards something like $< 0.59$ , but I have no idea what this number is. More generally, I would like to find the probability that the minimum is unique if I draw $n$ integers from $[1, r]$ for some integers $n \in \mathbb{N}$ and $r \in \mathbb{N}$ with $n \leq r$ . (Source: I want to estimate the success rate of an algorithm suggested as a solution to a question on cs.sx ).","['combinatorics', 'probability']"
4587653,"Continuous operators on $C[0,1] $ are not separable","Taking class in functional analysis, I was told that continuous operators $$A:C[0,1]\rightarrow C[0,1]$$ are not separable . I'm trying to prove it by finding uncountable family of operators $A_\alpha$ such that $$\forall  A_1, A_2\in A_\alpha \ \ \ \ \|A_1-A_2\|= \sup\limits_{\|f\|\le 1} \|(A_1-A_2)f\|>\varepsilon$$ where $\varepsilon$ is fixed. Operators of multiplying by constant totally does not make sense, I thought about multiplying by function, but  didn't figure it out. So, currently I'm fighting with an example of such family of operators, any hint appreciated!","['separable-spaces', 'functional-analysis']"
4587708,"Why is $\sum_{i,\:j\:\in\:I}\cos(2\pi\langle k,x_i-x_j\rangle)$ small for small $k$ whenever the $x_i$ have a minimum distance to each other?","Let $I$ be a finite nonempty set, $(x_i)_{i\in I}\subseteq[0,1)^2$ and $$f(k):=\sum_{i\in I}e^{-{\rm i}2\pi\langle k,\:x_i\rangle}\;\;\;\text{for }k\in\mathbb Z^2.$$ Assume $x_i\ne x_j$ for all $i,j\in I$ with $i\ne j$ . I want to choose $(x_i)_{i\in I}$ such that they are ""uniformly"" spread over $[0,1)^2$ , but simultaneously satisfy that $|f(k)|$ is ""small"" whenever $|k|$ is ""small"". What would be a suitable condition to ensure the latter? For example, I've read that the latter is satisfied when the $x_i$ have a suitable minimum distance to each other. But how do we see this? Clearly, $$|f(k)|^2=\sum_{i,\:j\:\in\:I}\cos\left(2\pi\langle k,x_i-x_j\rangle\right)\tag1,$$ but how do we see the desired property from this expression? Consider the trivial case of a regualr grid: Let $m,n\in\mathbb N$ and assume $$x_{ij}=\left(\frac{i+\frac12}m,\frac{j+\frac12}n\right)\;\;\;\text{for all }(i,j)\in I:=\{0,\ldots,m-1\}\times\{0,\ldots,n-1\}.$$ For $m=n=64$ and $k\in\{-256,\ldots,255\}^2$ a splot of $|f(k)|^2$ looks as follows: The white dots correspond to the points $x_i$ . And for all other $k$ , the value of $|f(k)|^2$ is $0$ . But how do we see this analytically?","['fourier-transform', 'complex-analysis', 'sampling', 'trigonometry', 'exponential-function']"
4587743,Why probability distribution is defined on event space and not on sample space?,"I don't understand why in the case of continuous R.V. (hence, continuous sample spaces) we don't even care about defining a Probability on the sample space. By analogy with the discrete case (where we define first a probability on the sample space, then an induced one on the event space of the R.V.) we should have defined $P(X\in A)$ as $P(X^{-1}(A))$ (and not $P(X\in A)=\int _A f(t)dt$ )! So, first: why don't we care about defining a probability on the sample space? second: Why the probability distribution is defined in the event space of the R.V. and not in the sample space ? PS: If the probability distribution had been defined on the sample space that would have given the sample space a Probability and then everything would have been perfectly analogous to the discrete case EDIT: My question is not about understanding what is a probability distribution, nor about defining the $\sigma$ -algebra of the events: it is about understanding why the distribution is defined in the arrival space (aka event space ) and not in the departure space (aka sample space ). In other words : why don't we define $f$ as $$P(B)=\int _B f(t)dt$$ for $ B \in \mathscr B(\Omega)$ instead of: $$P(X\in A)=\int _A f(t)dt$$","['probability-distributions', 'probability-theory', 'random-variables']"
4587775,When do we generally use $x=\frac{1-t}{1+t}$ substitution?,"I was scrolling on the forum and I saw somebody solving the following integral : $$\displaystyle\int_0^1 \frac{\ln(1+x)}{1+x^2} \mathrm{d}x$$ He used the really smart substitution $x= \frac{1-t}{1+t}$ , but I have no idea how he thought about that. It reminds me slightly the half angle tangent substitution (Weierstrass substitution ?). So my questions are : Is it a well-known substitution ? When do we usually use it ? Are there indicators ? Can you give me an example where it works well ? Thank you.","['integration', 'soft-question', 'analysis']"
4587846,Generalization of Chinese remainder theorem to non-normal subgroups,"I am trying to see if the following generalization holds or if there are counter-examples. Let $H, K<G$ be subgroups of $G$ (not necessarily normal). It is not too hard to prove that $$\phi: G\to G/H\times G/K; g\mapsto (gH, gK)$$ is surjective iff $HK = G$ . I wonder if you can generalize this to the case of $n$ subgroups. Let $H_1,\dots,H_n$ be subgroups of $G$ . The map $$\phi: G\to G/H_1\times \dots\times G/H_n; g\mapsto (gH_1,\cdots, gH_n)$$ is surjective iff for $i\neq j$ , $H_iH_j = G$ . I can see reasons that this may not hold, then a counter-example would be appreciated. This is in the same spirit as the Chinese remainder theorem in ring theory, but there we have more structures to help us.","['direct-product', 'group-theory']"
4587878,How find y from $x^2 y^3 d x+x\left(1+y^2\right) d y=0$,"Suppose $\alpha (x,y)=\frac{1}{xy^3}$ is integral factor of equation $$x^2 y^3 d x+x\left(1+y^2\right) d y=0$$ Check $\alpha (x,y)$ : $x^2 y^3 d x+x\left(1+y^2\right) d y=0 \mid \cdot \frac{1}{x y^3} \quad x \neq 0, y \neq 0$ $x d x+y^3\left(1+y^2\right) d y=0 \quad (\square)$ Let $M(x)=x, \quad \text{and} \quad N(x)=y^3\left(1+y^2\right)$ where $
D=\left\{ \left( x;y \right) \in \mathbb{R} ^2\,\,| \begin{matrix}
	x>0&		\land&		y>0\\
\end{matrix} \right\} 
$ I notice: $D$ is connected set $M(x),\: N(x)$ are continuous function over $D$ ( $C^1$ ) Let us check that the partial derivatives are equal: $\frac{\partial M}{\partial y}=\frac{\partial N}{\partial x}$ therefore $$\frac{\partial M}{\partial y}=\frac{\partial N}{\partial x}$$ Back to $ (\square)$ : $\int M(x, y) d x+\int N(x, y) d y=\mathbf{C}$ $\int x d x+\int \frac{1+y^2}{y^3} d y=\mathbf{C}$ $\frac{x^2}{2}+\int\left(\frac{1}{y^3}+\frac{1}{y}\right) d y=\mathbf{C}$ $\frac{x^2}{2}+\frac{y^{-3+1}}{-3+1}+\ln (y)=\mathbf{C}$ $\frac{x^2}{2}-\frac{1}{2 y^2}+\ln (y)=\mathbf{C}$ Question: How find solutions for the variable $y$ like WolframAlpha. I know WolframAlpha use Lambert function, but i don't know find y. $$
y=-\frac{1}{\sqrt{W\left(e^{x^2-2 C}\right)}}
$$ $$
y=\frac{1}{\sqrt{W\left(e^{x^2-2 C}\right)}}
$$ What happens if $(0,0) \in R^2$ . Is solution differential equation? What happens if $ (x, y) \in R^2 - D$ without (0,0)? Why D must be connected set? Thank you in advance.","['lambert-w', 'ordinary-differential-equations']"
4587910,A tighter bound of Vitali covering lemma for $\Bbb R^2$: $\lambda(V)\geq\frac{\lambda \left( \bigcup D_i \right) }{4}$,"I need help proving the following statement: Let $\{D_i\}$ be a finite colection of disks on $\mathbb{R}^2$ , $\lambda$ the Lebesgue measure on $\mathbb{R}^2$ . Show that there exists a subcollection of disjoint disks in the collection such that their union $V$ satisfies: $$
\lambda(V)\geq\frac{\lambda \left( \bigcup D_i \right) }{4} .
$$ So far the only thing I got is that it suffices to show the theorem for a set of disks that are ""clustered"" in the sense that there is an ennumeration of the $D_i$ 's such that $$D_i\cap D_{i+1}≠\emptyset$$ And that the theorem is obviously true for up to 4 disks.","['measure-theory', 'geometry', 'geometric-measure-theory', 'analysis', 'real-analysis']"
4587938,Number of balanced bracket sequences with given prefix and suffix,"I've been trying to solve the following problem: Find the number of balanced bracket sequences of size $N+M+K$ which start with a prefix of $N$ continuous opening brackets and end with a suffix of $M$ continuous closing brackets (there can be any sequence of brackets of length $K$ as long as whole sequence is balanced). I thought that maybe there is some correlation between this problem and Dyck paths/Catalan numbers but even after doing some research, I couldn't find any paper describing it in detail. Is it an already known (and well-studied) problem? Is there any formula for that? Thanks in advance!","['catalan-numbers', 'combinatorics']"
4587975,Completeness of Besov spaces,"Problem: Let us recall that: $$\dot{B}^{-\sigma}_{\infty,\infty}=\{u \in S'(\mathbb{R}^d): \|u\|_{\dot{B}^{-\sigma}_{\infty,\infty}} < \infty\}$$ where $$\|u\|_{\dot{B}^{-\sigma}_{\infty,\infty}}=\sup\limits_{A>0}\{A^{d-\sigma}\|  \theta(A\cdot)* u\|_{L^{\infty}}\}$$ and $S'(\mathbb{R}^d)$ is the set of tempered distributions.
I want to understand two things: why $\dot{B}^{-\sigma}_{\infty,\infty}$ is complete (i.e. a Banach space) why if I choose another $\theta'$ I obtain an equivalent norm over $\dot{B}^{-\sigma}_{\infty,\infty}$ . Attempt. I tried exploiting the Fourier transorm of a tempered distribution: $$\theta(A\cdot)* u= \mathcal{F}^{-1}\mathcal{F}(\theta(A\cdot)* u)=\mathcal{F}^{-1}\bigg(A^{-d}\mathcal{F}\Big(\theta\Big(\frac{\cdot}{A}\Big)\Big) \mathcal{F}(u)\bigg)$$ but I cannot go on. Any help or reference will be appreciate. Please notice that I would like a self-contained proof instead one for general Besov spaces as $\dot{B}^{\sigma}_{p,q}$ . Edit : we assume $\mathcal{F}(\theta)$ is such that $\mathcal{F}(\theta) \in C^{\infty}_c(\mathbb{R}^d)$ , $0 \leq \mathcal{F}(\theta) \leq 1$ and $\mathcal{F}(\theta)=1$ in a neighborhood of $0$ .","['besov-space', 'functional-analysis', 'distribution-theory']"
4587978,"MLE for $\theta>0$ with $(X_1,\dots,X_n)\sim \mathcal N(\theta, 2\theta)$","I want to determine the MLE for $\theta$ given a sample $(X_1,\dots, X_n)\sim \mathcal N(\theta, 2\theta)$ . I know that the likelihood function is $$f(X;\theta) = \frac{1}{2\sqrt\theta}\prod_{i=1}^n\exp\left(-\frac{(X_i-\theta)^2}{4\theta}\right).$$ The log likelihood function is therefore $$L(X;\theta) = -\log(2\sqrt\theta) -\sum_{i=1}^n \frac{(X_i-\theta)^2}{4\theta}.$$ If we differentiate and solve $ \frac{\partial L}{\partial \theta} = -\frac{1}{2\theta} - \sum_{i=1}^n \left[\frac{X_i^2}{4\theta^2}+\frac{1}{4}\right]\\$ we get \begin{align*}
        0 &= -\frac{1}{2\theta} -\sum_{i=1}^n \left[\frac{X_i^2}{4\theta^2}+\frac 1 4\right]\\
    \iff 0 &= 2\theta - \sum_{i=1}^n[X_i^2+\theta^2]\\
    \iff 0 &= -n\theta^2 + 2\theta - \sum_{i=1}^n X_i^2\\
    \iff 0 &= \theta^2 -\frac{2}{n}\theta + \frac{1}{n}\sum_{i=1}^n X_i^2
\end{align*} Which is $0$ if $\theta_{1,2} = \frac 1 n \pm\sqrt{\frac 1 {n^2} - \frac{1}{n}\sum_{i=1}^n X_i^2}$ . But this is highly implausible because the square root term is most likely negative. From experimentations in Python I can say that $$\theta^\ast = \frac 1 n + \sqrt{\frac{1}{n^2} + \left(\frac{1}{n}\sum_{i=1}^n X_i\right)}$$ seems to work quite well. What am I doing wrong?","['statistics', 'solution-verification', 'probability', 'maximum-likelihood']"
4588009,How are surface integrals converted from dS to dA?,"In class, we learned that: $$
\iint \vec{F} \cdot d \vec{S} = \iint \vec{F} \cdot \hat{n} \|r_{u} \times r_{v}\| dA = \iint \vec{F} \cdot \hat{n} \|r_{u} \times r_{v}\| dudv,
$$ where the normal unit vector is equal to $\frac{r_{u} \times r_{v}}{\|r_{u} \times r_{v}\|}$ . Moreover in addition to this, the bounds of the double integral depend on the parametrization $r_{u}$ and $r_{v}$ , or any other vector that is normal to the surface we are integrating over (for example, the three standard unit vectors, or a gradient vector). However, in this problem: I'm really confused by the second part, where they had to take the surface integral of the bottom disk of the top hemisphere. It seems like they bypassed the entire parametrization $dS = \|r_{u} \times r_{v}\|dA$ . How do I make sense of this? Did something happen that was not shown?","['multivariable-calculus', 'surface-integrals', 'vector-analysis']"
4588024,Histogram asymptotic bias,"I am reading All of Statistics from Casella. When trying to show the bias for a histogram estimator for some density distribution, he starts developing the formula for pj, that is, the probability some observations lies in that bin. Then he uses taylor approximation for that formula. However, developing the integral for that pj by myself do not show the same results from that book. Treating x as a constant, makes it to vanish. Where the j comes from? Can you develop step by step that integral? Let's take a closer look at the bias-variance tradeoff using equation
(20.9). Consider some $x \in B_j$ . For any other $u \in B_j$ , $$ f(u)
 \approx f(x)+(u-x) f^{\prime}(x) $$ and so $$ \begin{aligned}
 p_j=\int_{B_j} f(u) d u & \approx \int_{B_j}\left(f(x)+(u-x)
 f^{\prime}(x)\right) d u \\ &=f(x) h+h
 f^{\prime}(x)\left(h\left(j-\frac{1}{2}\right)-x\right) .
 \end{aligned} $$","['nonparametric-statistics', 'statistics']"
4588053,Compute $\mathbb{E}(X(X-1))$ where $X$ has a negative binomial distribution,"Let's consider a Bernoulli trial where $p$ denotes the probability of success. A random variable $X$ that counts the frequency of failures until the $r$ -th success has a negative binomial distribution. We can assume that $$P(\{X=k\})=p^r(1-p)^{k}{r+k-1\choose k}$$ and $$\mathbb{E}(X)=\frac{r(1-p)}{p}.$$ Compute $\mathbb{E}(X(X-1))$ . (We can assume that this expression is well defined) My approach: \begin{align*}
&\mathbb{E}(X(X-1))=\sum\limits_{k=1}^{\infty}k(k-1)p^r(1-p)^{k}{r+k-1\choose k}=\frac{r(1-p)}{p}\sum\limits_{k=1}^{\infty}(k-1)p^{r+1}(1-p)^{k-1}\frac{(k+r-1)!}{r!(k-1)!}\\
&=\frac{r(1-p)}{p}\sum\limits_{k=1}^{\infty}(k-1)p^{r+1}(1-p)^{k-1}{(r+k-1)\choose k-1}=\frac{r(1-p)}{p}\sum\limits_{k=0}^{\infty}kp^{r+1}(1-p)^{k}{(r+k)\choose k}=\dots.
\end{align*} Now we see that $\sum\limits_{k=0}^{\infty}kp^{r+1}(1-p)^{k}{(r+k)\choose k}$ is the expected value of another random variable $Y$ that has a negative binomial distribution. But $Y$ counts the failures until the $r+1$ -th success and so $\mathbb{E}(Y)=\frac{(r+1)(1-p)}{p}$ . Hence, $
\begin{align*}
\dots=\frac{r(1-p)}{p}\mathbb{E}(Y)=\frac{r(1-p)}{p}\frac{(r+1)(1-p)}{p}=\frac{r(r+1)(1-p)^2}{p^2}.
\end{align*}$ The sample solution is $\frac{r}{p}\left(\frac{r+1}{p}-2\right)$ . So I assume that my approach must be flawed somewhere. However, I dont see where I messed it up!? Can someone help me?","['solution-verification', 'negative-binomial', 'probability-theory']"
4588139,Is there a simple way to characterize the smooth functions without using the derivative?,"As seen in this question, the derivatives can be easily characterized if we know $C^\infty(\mathbb{R}).$ How can we simply characterize $C^\infty(\mathbb{R})$ if we can't use limits?","['calculus', 'soft-question', 'derivatives', 'smooth-functions']"
4588164,Number of disjoint regions = number of intersections + 1,"If I have N circles, where every circle intersects every other circle at 2 distinct points, then the number of disjoint regions equals the number of intersections + 1. I would like to know if there is a nice intutive reasoning to why this is true. edit: To clear up, every circle intersects every other circle and every pair of intersection points is unique. So you cannot have something like this",['geometry']
4588193,Cartesian product involving non-measurable Lebesgue sets,"This has been asked before here and here but has not been answered correctly/completely. Here's the problem: Given, $A, B \subset \mathbb{R}$ , where $A$ is not Lebesgue-measurable while $B$ has positive Lebesgue measure. Show that $A \times B$ is $\mathscr{L}^2$ non-measurable. However, if $B$ has zero measure, then $A \times B$ is $\mathscr{L}^2$ measurable. Here $\mathscr{L}^2$ is the space of Lebesgue measurable sets in $\mathbb{R}^2$ which is obtained by completing the product sigma algebra $\mathscr{L}\otimes \mathscr{L}$ , where $\mathscr{L}$ is the sigma algebra of Lebesgue measurable sets in $\mathbb{R}$ Attempt: I could prove that $A\times B$ is $\mathscr{L}\otimes \mathscr{L}$ measurable and hence $\mathscr{L}^2$ measurable when $m(B)=0$ , since $A\times B \subset \mathbb{R}\times B$ and $m\times m( \mathbb{R}\times B)=m(\mathbb{R}) \times m(B)=0$ , i.e. $\mathbb{R}\times B$ is a null set. Since $\mathscr{L}^2$ is complete, we get $A \times B$ is $\mathscr{L}^2$ measurable. How do I show the general statement?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4588249,What does near-cut (threshold) graph say about original complete weighted graph?,"ORIGINAL post, preamble Start from a complete graph with weighted edges (e.g. in $[0,1]$ interval). Continuously increasing threshold $t$ from $0$ to $1$ drop edges with weights less than $t$ . Finally stop right before the graph would become disconnected. See animation. Consider remaining connected graph - call it "" threshold graph "". What does its properties/structure say about the original complete graph? It is probably related to graph theory edge cut and max-flow min-cut theorem . But those are based on the minimal set of edges to disconnect a graph. What I really would like to understand in my case if any properties of the "" threshold graph "" say something mathematically interesting about the original complete graph . I especially interested in communities and clusters, but anything else interesting too. Such question often appears in problems with a complete set of relationships in a finite set - like a group of people, stocks in a portfolio, etc. Any thoughts and help are highly appriciated! This basically similar to ""percolation"" or ""watershed"" problems. Here is very simplistic formulation of it. UPDATE: simple clean problem N interacting agents - anyone with everyone - complete graph Interactions varies in strength - reflected in edge weights Drop all edges weaker than a particular weight - ""threshold"" - and replace the edges you kept with same uniform weight This is a simple skeleton graph in which graph communities cam be studied The BIG question is - ""how to choose cut-off threshold"" ? Threshold type 1: agents represented by time series of data (say stock price) edge weights are Pearson correlation coefficient between time series cut-off threshold is typical ""strong"" Pearson value - say 0.75 or similar such cut-off is typical but pretty vague and subjective - it is not dictated by data Threshold type 2: agents represented by time series of data (say stock price) edge weights are Pearson correlation coefficient between time series cut-off threshold is ""the last MAX edge we drop while graph is still connected"" such cut-off is naturally arises from data i guess this is important for problems where skeleton threshold graph must still connect all agents THE QUESTION: in what cases (7) should be chosen over (6) and what metrics we can drive from it, especially towards communities/structure? What mathematical reasoning can give preference to (7) over (6)? For practical example please see: https://blog.wolfram.com/2012/06/01/graph-theory-and-finance-in-mathematica","['graph-theory', 'network', 'discrete-mathematics']"
4588271,transitive subgroups in $S_n$ that are isomorphic to $S_k$ for $k\leq n$,"Assume that there is a transitive subgroup $H$ of $S_n$ w.r.t. the standard action $S_n\curvearrowright \{1,2,\cdots, n\}:=X$ such that $H\cong S_k$ . Is there any sharp estimate on the upper bound of $n$ in terms of $k$ for large $n$ , say for all $n\geq 5$ ? For example, one can show that $S_n=HK$ , where $K$ is the stabilizer subgroup of $S_n$ for any point in $X$ and hence $K\cong S_{n-1}$ . Hence we know $n!\leq k!\cdot (n-1)!$ , thus, $n\leq k!$ . In particular, is this estimate sharp for $n\geq 5$ ? Thanks!","['permutations', 'group-theory', 'symmetric-groups', 'reference-request']"
4588294,Prove that the polynomial $x^4 -5x^2+x+1$ is irreducible over the ring $\mathbb{Z}[x]$.,"I do not have an idea on how to approach this problem. Similar problems that I found online try to show that there does not exist a linear factor of the given equation in $\mathbb{Q}$ . But my question is, how is that sufficient to prove that the polynomial is irreducible? It could also be a product of two quadratic polynomials which do not have a solution in $\mathbb{Q}$ . Any help is appreciated!","['irreducible-polynomials', 'ring-theory', 'abstract-algebra']"
4588317,Maximum of $y''$ for BVP with $y''''\leq0$.,"Consider the following boundary value problem for some $L>0$ and $w(x)\geq 0$ : $$\frac{d^4y}{dx^4}=-w(x)\,;\,\,\,y(0)=y(L)=0,\,y'(0)=y'(L)=0.$$ Here $w$ can be pathological: a step-function or an impulse function $w(x)=w_0\,\delta(x-a)$ : anything that ensures that $y''$ is continuous (but not necessarily differentiable). From context (below) you can understand the kind of things that are allowed here. Is it always the case that the maximum of $|y''|$ is at $x=0$ or $x=L$ ? The fact that the second derivative of $y''$ is negative ensures that the maximum of $|y''|$ occurs at $x=0$ , $x=L$ , or where $\dfrac{d}{dx}(y''(x))=0$ . In context this is related to the maximum bending moment of fixed end beam. To that end I find with a point load at the midpoint, $w(x)=w_0\,\delta(x-L/2)$ we have: $$|y''(0)|=|y''(L/2)|=|y''(L)|=\frac{w_0L}{8}.$$ But can we have $|y''(x_m)|>|y''(0)|,|y''(L)|$ for $0<x_m<L$ . I feel like I could ask this of an engineer (and have done so here ), but would be interested in a more mathematical answer.","['step-function', 'ordinary-differential-equations', 'maxima-minima', 'boundary-value-problem', 'optimization']"
4588400,Is it possible develop the conjugate of several complex numbers into the following expression?,"Say one knows that the complex conjugate of two complex numbers written according to Euler's formula $(e^{i\theta _{1}}+e^{i\theta _{2}})^{\ast }\times(e^{i\theta _{1}}+e^{i\theta _{2}})$ can be developed into $2 + 2cos(\theta _{2} - \theta _{1})$ Does it work in a similar fashion with more than two complex numbers? So $(e^{i\theta _{1}}+e^{i\theta _{2}}+...+e^{i\theta _{n}})^{\ast }\times(e^{i\theta _{1}}+e^{i\theta _{2}}+...+e^{i\theta _{n}}) $ Would be developed into something like $2 + 2cos(\theta _{2} - \theta _{1}) + ... + 2cos(\theta _{n}-\theta _{1}) + ...$ So the question is, does the concept work?","['trigonometry', 'complex-numbers']"
4588425,Tile homotopy and T-tetromino packing of rectangles,"From my old question ( Which rectangles can be tiled with L-trominos, when only two orientations are allowed? ), I learned a very interesting way to deal with tiling problems.  I was wondering about T-tetromino tiling of rectangles. According to Michael Korn and Igor Pak's paper titled ""Tilings of rectangles with T-tetrominoes"" ( https://www.math.ucla.edu/~pak/papers/ttet11.pdf ), an $m\times n$ rectangle can be tiled with tetrominos iff $4\mid m$ and $4\mid n$ . I tried to use the same method that Mike Earnest used to answer my old question and ended up with a group $$G=\langle x,y|y^3xy^{-1}x=(xy)^2=yx^{-1}yx^3,xy^{-1}xy^3=(yx)^2=x^3yx^{-1}y\rangle.$$ I have little clues about the structure of $G$ .  However, if I define $H$ to be the smallest normal subgroup of $G$ that contains $xy$ , then it turns out that $G/H\cong\mathbb{Z}$ .  In fact $$G\cong H\rtimes \mathbb{Z}.$$ The problem is now to understand the structure of $H$ . My question is: Continuing along this line, is it possible to prove the result in Korn and Pak's paper? I found out a few things: $xy$ and $yx$ are commuting elements of $H$ ; If it is possible to tile an $m\times n$ table with T-tetrominos, then $x^ny^mx^{-n}y^{-m}$ is the identity of $G$ ; It seems to be the case that $x^ny^mx^{-n}y^{-m}$ is the identity iff $8\mid mn$ . Thank you for your interest/help. Additional Info:
If $C$ is the commutator subgroup of $G$ , then $G/C\cong \mathbb{Z}^2$ .  Also $C$ is a normal subgroup of $H$ s.t. $H/C\cong \mathbb{Z}$ .","['recreational-mathematics', 'abstract-algebra', 'combinatorics', 'polyomino', 'tiling']"
4588426,Finding $\Bbb{R}\to \Bbb{R}$ functions satisfying $f(x + y) = f(x) + f(y)$ and $f(xy) = f(x) f(y)$,"Let $f : \Bbb{R}\to \Bbb{R}$ be a function such that (a) $f(x + y) = f(x) + f(y)$ for all real numbers $x, y$ (b) $f(xy) = f(x) f(y)$ , for all real numbers $ x, y$ MY SOLUTION For $k \in \Bbb{Z}$ it's easy to show $f(kx)=kf(x)$ . Let $y$ be any real and $y=a+b$ where $a\in \Bbb{Z}$ . $f(xy)=f(ax)+f(bx)=af(x)+f(b)f(x)=f(x)f(y)$ From here we get a solution $f(x)=0$ or we get $a+f(b)=f(y) \Rightarrow y-b+f(b)=f(y) \Rightarrow f(b)-b=f(y)-y=c(say)$ So we get $f(x)=x+c$ . Putting it in original equation, we get $c=0\Rightarrow f(x)=x$ . Hence we get $2$ solutions $f(x)=0$ & $f(x)=x$ . Is this a correct solution? Or am I losing generality is some step ?","['functional-equations', 'algebra-precalculus', 'functions', 'recreational-mathematics']"
4588438,Taylor series higher-order terms,"I have carefully read the M.S.E. post here explaining the derivation of Taylor series, and I paid attention to the link in one of the comments, i.e., a dedicated blog post on Taylor series. In the linked blog post, the author explains how $\sin(x)$ can be approximated with a Taylor series expansion. Specifically, an example is given for a second-order Taylor approximation (denoted $T_2(x)$ ) where the expansion is carried around the point $x=\frac{\pi}{2}$ : here, the author explains that a curve can be defined using: a single point (i.e., $T_2(x=\frac{\pi}{2})=\sin(x=\frac{\pi}{2})=1$ ) the derivative at this point (i.e., we want the approximating polynomial to be $T_2'(x=\frac{\pi}{2})=\sin'(x=\frac{\pi}{2})=0$ ) The “curvature” at the same point, i.e., second derivative ( $T_2''(x=\frac{\pi}{2})=\sin''(x=\frac{\pi}{2})=-1)$ ) Solving for these conditions gives the following approximation: The third-order Taylor approximation, $T_3(x)$ is carried out around $x=0$ (i.e., the inflection point), by adding a condition on the third derivative at $x=0$ , in addition to slope and curvature at that point, leading to: My question: I conceptually understand how the two graphs above can be generated by information at a single point (i.e., $x=\frac{\pi}{2}$ for the first one and $x=0$ for the second one). But how can higher-order derivative terms in the Taylor expansion, all taken at the same point , provide information about local minima and maxima further away from the point of the approximation? I.e., how can higher-order derivatives taken (say) at $x=0$ see “behind the next turn”? I try to highlight this at the graph below: I cannot get my head around how information contained at $x=0$ can give the right point for the Taylor approximation at (say) $x=\frac{3\pi}{2}$ , for example.","['taylor-expansion', 'analysis']"
4588459,A series sum involving Catalan numbers,"I was trying to compute $$\sum_{k=0}^{n} \left(-\frac{1}{2}\right)^k \, \binom{2k}{k} \, \frac{k}{k+1} = \sum_{k=0}^n \left(-\frac12\right)^k k C_k$$ (where $C_k$ is the $k^{\rm th}$ Catalan number) but could not come up with a good idea.
I found out it is equal to $$\sum_{k=0}^{n} \left(-\frac{1}{2}\right)^k \, \binom{2k}{k+1}.$$ Doing some computation I see it is also equal to $$\sum_{k=0}^{n} \left(\frac{1}{2}\right)^k \, \binom{-k-1}{k}.$$ If someone can help, I would be very greatful. Thanks... My attempts might be wrong.","['catalan-numbers', 'binomial-coefficients', 'combinatorics']"
4588494,Why does $|(d\exp_{p})_{v}(w)|$ encodes the rate of spreading of geodesics?,"I'm reading a discussion in Do Carmo's ""Riemannian Geometry"", about Jacobi's equation.
The writer uses the following notation: $$v(s):I\to T_{p}M\ \ \ s.t. \\
v(0)=v,\\
v'(0)=w
$$ We identify $T_pM\simeq T_vT_p M $ . The writer motivates the discussion by the following claim: We would like to obtain information on $|(d\exp_{p})_{v}(w)|$ . One of the reasons for this is that $|(d\exp_{p})_{v}(w)|$ denotes, intuitively, the rate of spreading of the geodesics: $$ t \to \exp_{p}(t v(s)) 
$$ I don't understand the heuristic above. To be concrete, I'd like to know: The spread of which geodesics is encoded in $|(d\exp_{p})_{v}(w)|$ ? Is it some property that relates the following family of geodesics: $$\{t \to \exp_{p}(t v(s)) \}_{s\in I}$$ I'd be glad to hear a bit more about that - Why exactly does the differential encodes spread of geodesics? What is the geometric interpretation of all that? Could anyone point me to some draw of figure explaining this heuristic graphically? It all sort of make sense, but I think some more details could be of tremendous help. Many Thanks!","['geodesic', 'riemannian-geometry', 'differential-geometry']"
4588501,Inequality in probability theory.,Let X be a nonnegative random variable and let $(\mathcal{H}_i)$ be a sequence of increasing $\sigma$ algebras. Let $(A_i)_{0 \leqslant i \leqslant N}$ be a sequence of pairwise disjoint events. Do we have $$ \sum_{i=0}^N \mathbb{E} \big( \mathbb{1}_{A_i} \mathbb{E}\big(X | \mathcal{H}_i \big) \big) \leqslant \mathbb{E}(X) ? $$,"['martingales', 'probability-theory']"
4588509,Every ordinal is the derived length of a group,"Let $G$ be a group. Define inductively the derived series as follows: $$G^{(0)}=G\\\\
G^{(\lambda)}=\bigcap_{\alpha<\lambda}[G^{(\alpha)},G^{(\alpha)}]$$ Let $\text{sol}(G)=\{\min \alpha\in \text{Ord}:G^{(\alpha)}=G^{(\alpha+1)}\}$ . Clearly $\text {sol}(G)\le |G|$ . It is claimed on wikipedia ( here ) that every ordinal number is the solving length of some group, and the reference provided for this is ""Generalized nilpotent algebras and their associated groups"" by Maltsev a paper which, unfortunately, is in russian. To be more formal, let $\Omega:=\{\text{solv}(G): G\text{ is a group}\}\subset \text{Ord}$ . How would you go about proving $\Omega=\text{Ord}$ ? Do you have a reference for it? What I've done so far: For every natural number $n$ , $\alpha+n\in \Omega\Rightarrow \alpha\in \Omega$ (just take $G^{(n)}$ ) $\Omega$ is closed under $\sup$ : given an increasing sequence $\lambda_i$ of elements in $\Omega$ , denote by $G_i$ the associated groups and notice that $G:=\prod G_i$ satisfies $\text{sol}(G)=\sup \lambda_i$","['elementary-set-theory', 'group-theory', 'solvable-groups']"
4588523,is the tensor product of coordinate rings always a coordinate ring?,"given an arbitrary field $k$ (in particular, it does not need to be algebraically closed or even perfect) and sets $S ⊆ \mathbb A^m(k)$ and $T ⊆ \mathbb A^n(k)$ , is there an isomorphism of coordinate rings $$k[S × T] \cong k[S] \otimes_k k[T]?$$ from the commutative diagram with the natural arrows $$
 \require{AMScd}
 \begin{CD}
  k[\mathbb A^m × \mathbb A^n] @= k[\mathbb A^m] \otimes_k k[\mathbb A^n] \\
  @VVV @VVV \\
  k[S × T] @<<< k[S] \otimes_k k[T]
 \end{CD}
$$ we would only need a natural arrow in the other direction in the bottom row to conclude that. for this, it would suffice for a regular functions $h \colon \mathbb A^m × \mathbb A^n → k$ vanishing on $S × T$ to come from a sum of products of regular functions $f \colon \mathbb A^m → k$ and $g \colon \mathbb A^n → k$ vanishing on $S$ and $T$ respectively. is that so? how can i show this? note that i consider classical affine space, not schemes and $\mathbb A^m (k) = k^m$ and $\mathbb A^n (k) = k^n$ as sets. (by the way: i don't see that the tensor product of two reduced $k$ -algebras of finite type need not be reduced as an obstruction here as, to my knowledge, the counter-examples arise from inseparable extensions, wich are, to my knowledge, not formed by coordinate rings.)","['field-theory', 'algebraic-geometry', 'tensor-products', 'commutative-algebra']"
4588549,Evaluate the limit: $\lim\limits_{n\to \infty}\sqrt[n]{\frac{\ln(n)}{2^n+1}}$,"My problem is actually deeper than just evaluation this limit, but learning how to solve the following limit will help me a lot: $$\lim_{n\to \infty}\sqrt[n]{\frac{\ln(n)}{2^n+1}}$$ Just some context. I am studying Convergence Tests for Infinite Series. And as it is known, one of the tests is the root test. I understand how it works and I have a good feeling of when I can use it, but that implies that I must know how to solve this kind of limit. My textbook assumes that I already know how to solve this kind of limit and does not provide the step by step. I assume that most limits of this kind will have a similar strategy to solve. It would help me a lot if someone could help me. Specially if you could provide a solution without using l'Hopital.","['limits', 'limits-without-lhopital', 'real-analysis']"
