question_id,title,body,tags
2034206,Finding UMVUE of $\theta$ when the underlying distribution is exponential distribution,"Hi I'm solving some exercise problems in my text : ""A Course in Mathematical Statistics"". I'm in the chapter ""Point estimation"" now, and I want to find a UMVUE of $\theta$ where $X_1 ,...,X_n$ are i.i.d random variables with the p.d.f $f(x; \theta)=\theta e^{-\theta x}, x\gt0$ . I know that $E(X_i)=1/\theta,$ for each $i$ , and also have that $\bar{X}$ (or equivalently $\sum_1^n X_i$ ) is a complete sufficient statistic for $\theta$ . But I cannot go any further here. Somebody can help me?","['statistical-inference', 'probability-distributions', 'statistics', 'exponential-distribution', 'parameter-estimation']"
2034212,Show that invertible matrices with an additional condition are diagonalizable.,Let $A$ and $B$ be invertible $2 \times 2$ matrices such that $AB = -BA$ over the complex numbers. Show that $A$ and $B$ are diagonalizable.,['matrices']
2034267,Existence of time derivative in the Galerkin equation of parabolic PDEs,"Good day, Let's take this initial-boundary value parabolic PDE \begin{align} \partial_t u + Lu &=f \text{ in } \Omega_T=\Omega \times (0,T] \\ 
 u&=0 \text{ on } \partial \Omega \times (0,T) \\
u(x,0)&=u_0(x) \text{ for } x \in \Omega
\end{align}
  where $Lu:=-\text{div}(A^T(x,t) \nabla u)+\langle b(x,t),\nabla u \rangle+c(x,t)u $ and its weak form \begin{align} \frac{d}{dt} (u(t),v)_{L^2}+a(u(t),v;t)&=\langle f(t),v \rangle_{H^{-1},H_0^1} \text{ for all } v \in H_0^1=:V \\ u(0)&=u_0\end{align}
  where $a(w,v;t):=\int \langle \nabla w(x), A(x,t) \nabla v(x) \rangle + \langle b(x,t),\nabla w(x)\rangle v(x) + c(t) w(x) v(x) \text{ d}x $ Proving the existence of a weak solution in $L^2(0,T;H_0^1)$ for such a system can be done via Galerkin approximation where we test this system with finite-dimensional test functions. We get an ODE that has a unique solution to Cauchy-Lipschitz and one can show that this solution has a subsequence that converges weakly to the solution of our parabolic system. Using Galerkin we get \begin{align}(u_n'(t),v)_{L^2} + a(u_n(t),v;t)&=\langle f(t),v \rangle \text{ for all } v \in V_n \text{, almost all } t \in (0,T] \\
 u_n(0)&=u_{0n} \end{align} and since $v \in V_n:=\text{span} \{ w_1,...,w_n \}$ and $v$ is linear in this equation we can test with $w_j$ for $j=1,...,n$. Further we look for $u_n(t)\in V_n$ i.e. $u_n(t)=\sum_{k=1}^n c_{nk}(t) w_k$ where $c_{nk}(t)$ are some 'coefficients'. Therefore most authors conclude $\color{red}{u_n'(t)=\sum_{k=1}^n c'_{nk}(t) w_k}$ and get by plugging in: \begin{align}\sum_{k=1}^n \color{red}{c'_{nk}(t)}(w_k,w_i)_{L^2} + \sum_{k=1}^n c_{nk}(t) a(w_k,w_i;t)&=\langle f(t),v \rangle, ~ 1 \leq i \leq n \\
 c_{nk}(0)&=\alpha_{nk} \end{align} This approach can be seen in several PDE/Finite Element books that treat weak solutions for parabolic type PDEs. Take for example 'Galerkin Finite Element Methods for Parabolic Problems' by V. Thomée. Now my question: In this last Galerkin equation we have the time derivative of these coefficients $c_{nk}(t)$ (see the red equation above). But how do we even know that these derivatives exist? It seems like we just assume that so we can solve the ODE. But this is no real explanation to me. Why do the $u_n(t)$ have such a representation with these coefficients that are differentiable? Can somebody please help me with this? Thanks a lot, Marvin","['derivatives', 'partial-differential-equations', 'galerkin-methods', 'parabolic-pde', 'numerical-methods']"
2034271,Finding primes such that 2 in a non-n-tic residue,"Does or does not the following conjecture hold? For any integer $n \ge 2$, there exist a infinite number of primes $p$ so that for all integers $x$, $$x^n \not \equiv 2 \pmod {p}$$ This is clearly true for $n=2$, as for primes $p \equiv \pm 3 \pmod {8}$ we have that $2$ is a non-quadratic residue. However, I am not so sure for $n \ge 3$. Can someone provide some assistance? Also, I would say that I would not be able to understand a non-elementary proof very well.","['number-theory', 'elementary-number-theory']"
2034313,Inequality about modified Jordan form,"I'm trying to prove an inequality, which in turn I think is equivalent to this inequality, $$(|\lambda_1|-\epsilon)^2\bar{y}^Ty\le\bar{y}^T\left(\overline{(\lambda_rI_r+\epsilon F_r)_r}^T(\lambda_rI_r+\epsilon F_r)_r\right)y\le(|\lambda_d|+\epsilon)^2\bar{y}^Ty$$ for all $y\in\mathbb{C}^d$, for any $0\le\epsilon\le|\lambda_1|$. where $(\lambda_rI_r+\epsilon F_r)_r$ is a slightly modified Jordan form of a complex-valued matrix $M$. $\lambda_rI_r+\epsilon F_r$ is the modified $r$-th Jordan block with $I_r$ being identity matrix and $F_r$ being $1$s right above diagonal. $M$ has eigenvalues $\lambda_1,...,\lambda_d$ with order that $|\lambda_1|\le|\lambda_2|\le...\le|\lambda_d|$. I think the $M$ is not needed here, and more advanced knowledge about Jordan form except the definition neither. I assume the Jordan form of $M$ has $n$ Jordan blocks. Then I wish I could prove that $$(|\lambda_1|-\epsilon)^2\bar{y_r}^Ty_r\le\bar{y_r}^T\overline{(\lambda_rI_r+\epsilon F_r)}^T(\lambda_rI_r+\epsilon F_r)y_r\le(|\lambda_d|+\epsilon)^2\bar{y_r}^Ty_r$$
for $r=1,...,n$, where $y_r$ is the corresponding $r$-th block of $y$. Then the middle part can be expanded to $$\bar{y_r}^T(|\lambda_r|^2I_r+\bar{\lambda_r}\epsilon F_r+\lambda_r\epsilon F_r^T+\epsilon^2F_r^TF_r)y_r.$$
Then the inequality is equivalent to
$$|\lambda_1|^2\sum_{i=1}^{s_r}\bar{y_i}y_i-2|\lambda_1|\epsilon\sum_{i=1}^{s_r}\bar{y_i}y_i+\epsilon^2\sum_{i=1}^{s_r}\bar{y_i}y_i\le|\lambda_r|^2\sum_{i=1}^{s_r}\bar{y_i}y_i+\lambda_r\epsilon\sum_{i=2}^{s_r}\bar{y_i}y_{i-1}+\overline{\lambda_r\epsilon\sum_{i=2}^{s_r}\bar{y_i}y_{i-1}}+\epsilon^2\sum_{i=2}^{s_r}\bar{y_i}y_i\le|\lambda_d|^2\sum_{i=1}^{s_r}\bar{y_i}y_i+2|\lambda_d|\epsilon\sum_{i=1}^{s_r}\bar{y_i}y_i+\epsilon^2\sum_{i=1}^{s_r}\bar{y_i}y_i$$ I can see the close similarity between the tree formulas separated by $\le$, but I am stuck in to show the inequality. Especially how can we handle the conjugate terms ? Or the second inequality which I want to prove is true or not ? Important Update : I'm so sorry that I missed to impose an essential condition that $0\le\epsilon\le|\lambda_1|$","['inequality', 'jordan-normal-form', 'complex-numbers', 'matrices', 'linear-algebra']"
2034359,Expectation of a sum of order statistics,"For a sample of i.i.d. random variables $X_1,X_2,\cdots,X_n$, the expectation of the sum of all order statistics ($X_{(1)}+X_{(2)}+\cdots+X_{(n)}$) are igual to $nE[X_1]$? Is there a general form for the distribution of $X_{(1)}+X_{(2)}+\cdots+X_{(n)}$? I was thinking that if I have the sum of all order statistics is equivalent to have the original distribution of $X$ evaluated in $nx$, but I have no idea if it's correct or if there is some theorem abuot that result.","['order-statistics', 'probability-theory', 'probability', 'statistics']"
2034380,"Proof: $\mathbb Q \cap [0,1]$ is not compact (with the definition)","I have to prove that $\mathbb Q \cap [0,1]$ is not compact, directly with the definition with open covers (I am not allowed to use theorems like Heine-Borel). My attempt: 
So I need to find an open cover of $\mathbb Q \cap [0,1]$ that has no finite subcover. I assume that we need to this by something like approximating an irrational number, i.e. $$
U_n :=  \left]-1, \frac{\sqrt2}{2} - \frac{1}{n}\right[ \cup \left]\frac{\sqrt2}{2}+\frac{1}{n},2\right[
$$
This is a open cover of $\mathbb Q \cap [0,1]$ but I am not sure if this does not have a finite sub cover, like for example just $\mathopen]-1,2\mathclose[$
Any hints?","['general-topology', 'rational-numbers', 'compactness']"
2034381,What is the precise definition of a group action that is a symmetry?,"I know this question may seem a bit silly and trivial, but I haven't found any precise definitions for what a ""symmetry"" is in my textbook for group theory or online and I feel like I don't know it rigorously enough. Specifically, the root of my question is: Why doesn't the dihedral group of order 2n have n! elements? For example, the symmetries of a square (that is the dihedral group of order $2n = 8$, 4 reflections and rotations) has order $8$, but why isn't, for example $(12)$ a valid element in it? I understand that there are axes of rotations and symmetries, but is that it? Is there a more precise definition of what a ""symmetry action"" must constitute?","['abstract-algebra', 'group-theory', 'symmetric-groups']"
2034383,Showing that a function $f$ has a unique fixed point in a metric space. [duplicate],"This question already has an answer here : To show that $f$ has a fixed point, that is, there exists $x_0 \in X$ such that $f (x_0) = x_o$. (1 answer) Closed 2 years ago . Let $(X, d)$ be a compact metric space, and suppose $f : X → X$ satisfies 
  $$d(f(x), f(y)) < d(x, y)$$
  for all $x \neq y \in X$. Show that f has a unique fixed point. All I've gotten it so far is that we need to somehow use another function $g(x)=(x,f(x))$. Thanks","['real-analysis', 'fixed-point-theorems', 'metric-spaces', 'banach-fixed-point', 'analysis']"
2034410,Show that the function $f(z)=\exp\left(\frac{z}{1-\cos z}\right)$ has essential singularity at $z=0$,At $z=0$ show that the function $f(z)=\exp (\dfrac{z}{1-\cos z})$ has essential singularity. I want to show that the limit does not exist at $z=0$. Put $z=x\to 0$ $\lim_{x\to 0}\exp(\dfrac{x}{1-\cos x})$. Let $y=\exp(\dfrac{x}{1-\cos x})\implies \ln y=\dfrac{x}{1-\cos x}$. Now $\dfrac{x}{1-\cos x}=(0/0)$.so we have $\dfrac{1}{\sin x}\to \infty as x\to 0.$ Hence $y=e^\infty \to \infty$ Put $z=ix\to 0$; $\exp(\dfrac{ix}{1-\cos ix})=\exp(\dfrac{ix}{1-{\dfrac{e^{ix}+e^{-ix}}{2}}})$. I think the above limit tends to $\infty $ as $x\to 0$. I am unable to prove the limit does not exist.,"['complex-analysis', 'singularity', 'proof-verification']"
2034428,Uniform Convergence of a Function Related to the Characteristic Function of a Random Variable,"This question is related to a previous question I asked: Using the Uniform Continuity of the Characteristic Function to Show it's Differentiable Suppose we have a characteristic function $\varphi$ of i.i.d. $X_{i}$. I know that for all $t$, 
$$
n(\varphi(t/n)-1)\to iat\qquad\qquad\qquad(*)
$$
pointwise as $n\to \infty$. To solve my problem, I need to prove that this convergence is uniform in $t$ in some small compact interval around $1$; say $[1-\delta,1+\delta]$. Using the fact that a family of characteristic functions is equicontinuous, and the fact that $S_{n}/n\to a$ weakly, where $S_{n}=X_{1}+\cdots+X_{n}$, I was able to prove that $(\varphi(t/n))^{n} \to e^{iat}$ uniformly in $t$ on compact sets. I also know that characteristic functions are uniformly continuous. But, I am unsure how to put these pieces together to obtain that the convergence $(*)$ is uniform in $t$ in some compact interval centred at $1$. Any help is greatly appreciated. I am also open to other ways to solve this problem.","['weak-convergence', 'uniform-continuity', 'probability-theory', 'uniform-convergence']"
2034500,Computing the average of $\prod_i (1-\frac{|x_i|}{L})$ on the surface of the unit $n$-sphere,"I'm trying to compute the expected value of $ \prod_i (1-\frac{|x_i|}{L})$ on the surface of a $n$-dimensional sphere. A first step could be to integrate only on the first quadrant to take out the absolute value (since the function is symmetric). The intuition behind it (if I'm not wrong) is that for $L>1$  that product is the probability that, if we put edge-parallel planes in every dimension separated by distance $L$, a point in the surface of the unit sphere will end up in the same hypercube as the origin. For 2 dimensions it's easy because we can pass to polar coordinates: $$\frac{2}{\pi}\int_{\theta=0}^{\pi/2} (1-\frac{\cos \theta}{L})(1-\frac{\sin \theta}{L}) = 1- \frac{4L-1}{\pi L^2}$$ What about higher dimensions?","['surface-integrals', 'calculus', 'multivariable-calculus', 'spheres', 'integration']"
2034521,"Show that equation $x^2+y^2+z^2=(x-y)(y-z)(z-x)$ has infinitely many solutions in integers $x,y,z$","While solving some old  INMO problems I found that one, and I am completely stuck at it. The problem is: Show that the equation $x^2+y^2+z^2=(x-y)(y-z)(z-x)$ has infinitely many solutions in integers $x,y,z$. I shall be thankful if you can provide me any hints or suggestions. Thanks.","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
2034522,"If $A$ is a symmetric positive definite matrix, then $A_{ii}(A^{-1})_{ii}\geq1$ for all $i$. Equality?","I know that, if $A$ is an $n\times n$ symmetric positive definite matrix, then $A_{ii}(A^{-1})_{ii}\geq1$ for all $i=1,\ldots,n$. A proof is the following: we can write $A=PDP^T$ and $A^{-1}=PD^{-1}P^T$, where $D$ is diagonal and $P$ orthogonal. Then
$$ A_{ii}=\sum_{l=1}^n P_{il}^2 D_{ll},\quad (A^{-1})_{ii}=\sum_{l=1}^n \frac{P_{il}^2}{D_{ll}}.$$ Then, by the Cauchy-Schwarz inequality and the fact that the rows of $P$ have norm $1$, 
$$ A_{ii}(A^{-1})_{ii}=\left(\sum_{l=1}^n (P_{il}\sqrt{D_{ll}})^2\right)\left(\sum_{l=1}^n\left(\frac{P_{il}}{\sqrt{D_{ll}}}\right)^2\right)\geq \left(\sum_{l=1}^n P_{il}\sqrt{D_{ll}}\frac{P_{il}}{\sqrt{D_{ll}}}\right)^2=1.$$ My question is about when the equality holds. Looking at the above proof, we have to use the fact that there is equality in the Cauchy-Schwarz inequality if and only if the vectors are linearly dependent. So, $A_{ii}(A^{-1})_{ii}=1$ if and only if there is a $\lambda_i\in\mathbb{R}$ such that $$P_{il}\sqrt{D_{ll}}=\lambda_i \frac{P_{il}}{\sqrt{D_{ll}}}.$$ I think that, if $A_{ii}(A^{-1})_{ii}=1$ for all $i=1,\ldots,n$, then $A$ is diagonal, but I am not sure. The idea would be to prove that each row of $P$ has a component $1$ and the rest are zeros. So suppose that, for a row $i$, there are two columns $l_i$ and $k_i$ such that $P_{i,l_{i}}\neq0$ and $P_{i,k_{i}}\neq0$. Then $D_{l_i,l_i}=D_{k_i,k_i}=\lambda_i$, that is, $A$ has two eigenvalues equal. I do not know how to proceed and if this fact is important. Any ideas?","['matrices', 'eigenvalues-eigenvectors', 'positive-definite', 'linear-algebra']"
2034589,Closed linear operators have closed kernels,"Let $X,Y$ be Banach spaces and $K\colon X\to Y$ be a closed linear operator. I would like to show that its kernel is closed subspace of $X$. Any ideas?","['functional-analysis', 'operator-theory', 'unbounded-operators']"
2034675,Find probability of $X_1 < X_2 < X_3 $ where $X_i$ is a random variable,"I have encountered this problem in the book Probability and Random Processes by Grimmett and Stirzaker.  The problem is: Let $X_1, X_2, X_3$ be independent (discrete) random variables taking values in the positive integers and having mass functions given by $\mathbb{P}(X_i=x)=(1-p_i)p_i^{x-1}$ for $x=1, 2, ....$ and $i=1,2,3$. Show that  $\mathbb{P}(X_1<X_2<X_3)=\dfrac{(1-p_1)(1-p_2)p_2p_3^3}{(1-p_2p_3)(1-p_1p_2p_3)}$ I actually find this kind of problems too vague, because I know how to calculate $\mathbb{P}(X\leq x)$ but I can't calculate the probability of (in)equality of different random variables $X, Y$ like $\mathbb{P}(X<Y)$. Is there a method for that? What I tried so far is to write it down as $\mathbb{P}(X_1<X_2<X_3)=\mathbb{P}(X_1<X_2, X_2<X_3)=\mathbb{P}(X_1<X_2)\mathbb{P}(X_2<X_3)$. But then I don't know how to go further... I apperciate your help and hints. Thanks!","['probability-theory', 'probability', 'probability-distributions']"
2034702,Farkas Lemma Question with strict inequality,"I have a question which I thought that can be solved by Farkas Lemma, but I could not manage it. Prove that only one of the systems has a feasible solution, where $A$ is an $m \times n$ matrix, $C$ is a $r \times n$ matrix: System 1. \begin{align*}
A\mathbf{x} &\leq \mathbf{b} \\
C\mathbf{x} & > \mathbf{d} \\
\mathbf{x} &\geq 0
\end{align*} System 2. \begin{align*}
\mathbf{y}^T A &\geq \mathbf{s}^T C \\
\mathbf{y}^T \mathbf{b} &= \mathbf{s}^T\mathbf{d} \\
\sum_{k=1}^r s_k &= 1  \\ 
\mathbf{y}, \mathbf{s} &\geq 0
\end{align*}","['matrices', 'linear-programming', 'proof-explanation']"
2034710,"Prove that if all geodesics of a surface $S$ are planar curves, then $S$ is contained in a plane or a sphere","I know that if $\alpha$ is geodesic and its curvature is never zero, and it's plane, then it's a line of curvature (i.e. the tangent is a principal direction). I can prove this using Frenet. I want to show first that all points are umbilical, because then I know how to prove that the curvature is constant, so the surface must be in a plane, a pshere, or the pseudosphere (but it can't be the pseudosphere because of reasons). Given a point in the surface, and a direction, there exists one and only one geodesic in that direction. If the curvature is never zero, the direction is principal. If I can do this with all points and all directions, all points are umbilical. But...it can happen that the curvature of the geodesic is zero and I don't know what to do in that case. Can you help me?","['differential-geometry', 'geodesic']"
2034746,Extending gradient of a submanifold,"Let $M$ be a submanifold of $\Bbb{R^n}$ and $f:M\to \Bbb{R}$ continuously differentiable and such that $f^{-1}[a,b]$ has no critical points. We define $\nabla f (a)$ by $\langle \nabla f(a),v \rangle=T_a f(v)$ for all $v\in T_a M$. Now for all $x\in f^{-1}([a,b])$ we have $\nabla f(x)\ne 0$. How can I extend this in a neighborhood of $f^{-1}([a,b])$ ? It seems thatp I need bump function but I really don't ""see"" how can I do that. Edit: sorry I forgot to say that $M$ is compact so does $f^1[a,b]$","['multivariable-calculus', 'differential-geometry', 'manifolds']"
2034747,"Prove that a linear subspace of $C([0,1])$ is closed","Prove that the set 
  $$ W= \{f \in C([0, 1]):f(0)=0\}$$
  is a closed linear subspace of $C([0,1]).$ Here $C([0, 1])$ is the space of continuous functions equipped with the uniform norm  $||f||_\infty = \sup_{x\in[0,1]}|f(x)|$. I need some help in how to proceed  with this problem. First, I want to prove that $W$ is, indeed, a subset of $C([0,1])$. For this, we have that for any two functions $f,g\in W$, $f+g\in W$, since $f(0) + g(0) = 0$. Then, also for any $\lambda \in \mathbb{R}$, we have that $\lambda f \in W$, since $\lambda f(0) = 0$. Finally, we also have $0 \in W$. So $W$ is a linear subspace of $C([0, 1])$. My problem is how to prove that $W$ is closed. Based on the definition of a closed set, I wanted to show that a sequence of continuous functions $f_n$ converges uniformly to $f$ and that this $f$ is also in $W$. I started with something like this: Let $f_n$ be a sequence of continuous functions such that $f_n(0) = 0$ for any $n\in \mathbb{N}$. We need to prove that $f_n \to f$, uniformly. i.e $$ \|f_n - f\|_\infty = \sup_{x\in[0,1]} |f_n(x) - f(x)|\to 0$$ as $n\to \infty$. How can I proceed?","['functional-analysis', 'uniform-convergence', 'vector-spaces']"
2034770,L'Hôpital's rule does not apply?!,"Apparently, Rogawski's Calculus for AP contains the following problem: 108. Explain why L'Hôpital's rule does not apply to $$ \lim_{x\rightarrow 0}\frac{x^2\sin\frac{1}{x}}{\sin x} $$ It seems to me that it does apply: The L'Hôpital's rule says: if $\lim_{x\rightarrow c}f(x)=\lim_{x\rightarrow c}g(x)=0$ and both $f$ and $g$ are differentiable at $x=c$ and $g'(c)\ne 0$, then $\lim_{x\rightarrow c}\frac{f(x)}{g(x)}$ exists and is equal to $\frac{f'(c)}{g'(c)}$.
(Note that nothing is assumed about differentiability of $f$ and $g$ other than at $x=c$). Define the numerator $f(x)=x^2\sin\frac{1}{x}$ to be $f(0)=0$ at $x=0$. Now, both numerator $f$ and denominator $g(x)=\sin(x)$ are continuous at $x=0$ and their values are $f(0)=g(0)=0$. The numerator $f$ is differentiable at $x=0$ and the derivative is $f'(0)=0$ (the derivative itself is discontinuous at 0, but that is irrelevant - even the existence of the derivative at any point other than 0 does NOT matter). One can see that from the definition of the derivative:
$f'(0)=\lim_{h\rightarrow 0} \frac{h^2\sin\frac{1}{h}}{h} =
 \lim_{x\rightarrow 0} h\sin\frac{1}{h} = 0$ (see PS step 2 below). The denominator $g$ is differentiable at $x=0$ and the derivative is $g'(0)=\cos 0=1$. Thus the limit is $\frac{0}{1} = 0$. What am I missing? PS. Note that I am not asking why the limit is 0. That can be easily seen without L'Hôpital: $\lim_{x\rightarrow 0}\frac{x}{\sin x} = 1$:
this is the inverse of the standard limit $\lim_{x\rightarrow 0}\frac{\sin x}{x} = 1$. $\lim_{x\rightarrow 0} x  \sin\frac{1}{x} = 0$
because $\sin\frac{1}{x}$ is bounded and $\lim_{x\rightarrow 0} x = 0$,
this follows from Squeeze theorem . the Product Rule for Limits implies that 
$$\lim_{x\rightarrow 0}\frac{x^2\sin\frac{1}{x}}{\sin x} = 
\lim_{x\rightarrow 0}x\sin\frac{1}{x} \times
\lim_{x\rightarrow 0}\frac{x}{\sin x} =
0 \times 1 = 0$$ PPS Here is the scan from the textbook:","['calculus', 'limits']"
2034777,"How many squares can be made from points on $ z(t) = e^{2\pi i\, t} + \frac{1}{\sqrt{3}} e^{2\pi i\, 3t} $?","Inspire by the Toeplitz Square Problem, how many squares can be drawn on the curve:
$$ z(t) = e^{2\pi i\, t} + \frac{1}{\sqrt{3}} e^{2\pi i\, 3t} $$
wth $t \in [0, 2\pi]$.  Here is an image: We're up to one five nine ten squares.  Here is an example that is not aligned wit the axes. can be prove there only one square here? It's not quite square, can we move it around to be a square? E.g. Can this quadrilateral be massaged into a square?  Whose points all lie on this cubic curve? i heard the existence of one square is known for algebraic curves like this. maybe with no guarantee of exact count. a dimension count has that a quadrilateral is defined by 8 real numbers. the squares in Euclidean plane can be defined by 4 numbers. the quadrilaterals on a curve are defines by 4 numbers. generically  these curves should intersect in a $$4+4-8=0$$ dimensional set. possibly an empty collection of points. Other possible obstructions is when these curves are very bumpy. Then I think one introduces really tiny squares!","['algebra-precalculus', 'geometric-probability', 'analytic-geometry']"
2034785,"For any smooth manifold $M$, does there exist some coordinate chart $(U,(x^i))$ such that $M\setminus U$ has measure zero? [duplicate]","This question already has an answer here : How much of an $n$-dimensional manifold can we embed into $\mathbb{R}^n$? (1 answer) Closed 7 years ago . Assume that $M$ is connected. Ideally, I would like $U$ to be connected, though that's not strictly necessary. If this were true, it would instantly make integration on compact oriented manifolds much easier, since we can simply pass to Euclidean space $\mathbb{R}^n$ in order to evaluate the integral. Intuitively, it seems like it must be true. Consider the following examples: $\mathbb{S}^n$ – we use the stereographic projection $\mathbb{T}^n \cong (\mathbb{R}/\mathbb{Z})^n$ – we consider $U=(0,1)^n$ $\mathbb{RP}^n$ – we consider $U_0=\{[1:x^1:\cdots:x^n]\, \big\vert\, x^1,\ldots,x^n\in\mathbb{R}^n\}$ If $M$ and $N$ have smooth charts $(U,(x^i)$ and $(V,(y^j))$ defined almost everywhere, respectively, then $M\times N$ has smooth chart $(U\times V, (x^1,\ldots,x^n,y^1,\ldots,y^m))$ defined almost everywhere. However, I have no clue about how to prove a statement like this, and I suspect that any counterexample would be very difficult to find.","['manifolds', 'general-topology', 'smooth-manifolds', 'differential-geometry']"
2034788,limit of arithmetic weighted mean ($\lim_\limits{n\to\infty}\frac{\sum_\limits{k=1}^n{t_ka_n}}{\sum_\limits{k=1}^n{t_k}} = L$),"Given that: $t_n>0 \\ \lim_\limits{n\to\infty}\sum_\limits{k=1}^n{t_k} = \infty$ $\lim_\limits{n\to\infty}a_n = L$ (either $L=\pm\infty$ or $L\in\mathbb{R}$) I'm trying to prove that: $\lim_\limits{n\to\infty}\frac{\sum_\limits{k=1}^n{t_ka_n}}{\sum_\limits{k=1}^n{t_k}} = L$ Of course, it seems very similar Cesaro mean, but I've had trouble trying to apply a similar method here. Any idea? Thanks!","['calculus', 'limits']"
2034795,Conflicting thoughts with contour integrals.,"Say we are given a circle centered at the origin with radius 2, and are given the function $f(z) = \frac{z^2}{1-z^2}$. I was told that this integral is equal to 0 because both poles are inside the curve. I thought the opposite was true, where the integral is only equal to 0 if the poles lie outside the curve? For another example using the same function, but with the circle being centered at z = 1 and radius of 1.5, one pole lies inside the curve and the other lies outside. So doing this one I can say $\int_{C} \frac{z^2}{(1-z)(1+z)}dz = \int_{\gamma} \frac{\frac{z^2}{1+z}}{1-z}dz = 2\pi i f(a)$ where a = 1 and $f(z) = \frac{z^2}{1+z}$. So then this would become $2\pi i \frac{z^2}{1+z}$ and letting z -> 1 it becomes $2\pi i \frac{1}{2} = \pi i$. I feel like I did the second one correctly and that the person who told me about the first one is wrong. Are both of these correct, both incorrect, or otherwise? Am I missing something here? It seems very basic so I'm not sure how the first one could be 0 based on what we were told in class.","['cauchy-integral-formula', 'complex-analysis', 'contour-integration']"
2034821,Problem of Functional Analysis (weak convergence),"I want to ask a problem of functional analysis, it says: You have a sequence of $\{f_{n}\}\in L^{1}(\Omega)\cap L^{\infty}(\Omega)$ and you know that $\parallel f_{n}\parallel_{L^{1}(\Omega)} \le C$ (C is a real constant) and $\{f_{n}\}\rightharpoonup f \in L^{\infty} weak^{*}$. Prove that $f\in L^{1}(\Omega)$ and $\parallel f\parallel_{L^{1}(\Omega)}\le C$. I don´t know how to prove that.","['functional-analysis', 'lp-spaces', 'weak-convergence', 'analysis']"
2034857,closed points of a scheme and k-points,"So I was reading the book ""Algebraic Geometry"" by Görtz and Wedhorn. I have trouble with Corollary 3.36 on Page 80. The statement is: Let $X$ be a scheme locally of finite type over an algebraically closed field $k$. Let $x \in X$ and $\kappa(x)$ be the residue field at $x$. Then the following equalities hold: $$\{x \in X\; |\; x\; \text{is closed}\} = \{x \in X\; |\; k = \kappa(x)\} = \text{Hom}_{k}(\text{Spec}(k),X)$$ Now what I can prove is the following: If $x$ is closed, then by Proposition 3.33, $\kappa(x)$ is finite extension of $k$ and hence $k = \kappa(x)$ as $k$ is algebraically closed. If $k = \kappa(x)$, then by Proposition 3.8 we have a map from $\text{Spec}(k)$ to $X$. Now the problem is: If we have a morphism from $\text{Spec}(k)$ to $X$ with image $x$, then we have again by Proposition 3.8 a map from $\kappa(x)$ to $k$. However, I do not see why this should imply that $\kappa(x) = k$ or that $x$ is closed. Ideas: Since we have $k \to \kappa(x) \to k$ and both maps are injective, I thought that this might imply that they are isomorphic. However, that turns out to be not true. Is it true in the special case where $k$ is algebraically closed?","['schemes', 'algebraic-geometry']"
2034875,Compute $E\left(\left(\sum\limits_{i=1}^dX_i^2\right)^{-1}\right)$ for i.i.d. standard normal random variables $(X_i)$,"Does anyone know how to solve the following exercise? Let $X_i$, $i=1,\ldots,d$ be i.i.d $\mathcal N(0,1)$ random variables. Show that for $d>2$, $$E\left[ \frac1 {\sum_{i=1}^d X_i^2} \right] = \frac 1 {d-2}$$ I have tried to use that the sum of $X_i^2$ is a chi square...","['statistics', 'probability', 'probability-distributions']"
2034974,proof of matrix singularity,"If anyone can help me with the next question I would appreciate it a lot. Let $A$ and $B$ be $n*n$ matrices and let $C=A-B$. Show that if $Ax_0=Bx_0$ and  $x_0$ is not zero, then $C$ must be singular. The first thing I don't get is the notation, what do $Ax_0$ and $Bx_0$ mean? Thanks in advance :)","['matrices', 'linear-algebra']"
2034976,"Find a limit, no Taylor formula","How to find this limit:
$$
\lim_{x \to +\infty} \left[ (x+a)^{1+{1\over x}}-x^{1+{1\over x+a}}\right]
$$
We know L'Hopital's rule, but don't know Taylor's formula.",['limits']
2034978,"A coherent-sheaf is locally free when restricted on an open dense subset, if it is globally locally free.","$X$ is a algebraic variety. $\mathcal{F}$ is a coherent sheaf. 
$U\subset X$ is an open dense subset. $\mathcal{F}|_U$ is locally free on $U$. Can we conclude that $\mathcal{F}$ is locally free on $X$ ?",['algebraic-geometry']
2034984,Prove the following statement about a function that is continuous,"I was given this problem the following problem in my exam: A function continuous on $[a,b]$ attains a minimum value on $[a,b]$ . Note: proof should not involve compact sets or sequences . Help me with this proof please. Thank you.","['continuity', 'analysis']"
2035043,Eisenstein series converge absolutely for $k\geq 2$,"I am looking at Eistenstein series on modular forms: https://en.wikipedia.org/wiki/Eisenstein_series The page claims that the series converges absolutely to a holomorphic function of τ when $k\geq 2$. I can't easily see why. It's apparent that when the exponent is odd, the series equal to $0$, so we only focus on the case of $2k$. But why does Eisenstein series converge absolutely iff the exponent is odd $(1,3, 5,...)$ or an even number bigger than $2$?","['number-theory', 'absolute-convergence', 'complex-numbers', 'modular-forms']"
2035079,Distribution of the maximum of a large number of normally distributed random variables,"Let $X_i\sim \text{iid}\, \mathcal{N}(\mu,\sigma)$ for $i\in\{1,\dots,n\}$. I am interested in the random variable $Y=\max_i{X_i}$ when $n$ is large. From Extreme value theory it seems that $Y$ would follow a Gumbel distribution but I would like to know the parameters of this distribution as a function of $\mu$ and $\sigma$. Also, would the result holds if $\mu$ and $\sigma$ differ across $i$ or if the $X_i$ are not independent?","['probability-limit-theorems', 'probability', 'probability-distributions']"
2035084,Exact bijection to prove rationals are countable [duplicate],"This question already has answers here : Produce an explicit bijection between rationals and naturals (9 answers) Closed 7 years ago . It is a well-known fact that the set of rationals $\mathbb{Q}$ is countable. The proof for $\mathbb{Q^+}$, the strictly positive rationals, is the classic ""snaking"" pattern detailed in a bunch of textbooks and internet sources, e.g here . ProofWiki has 4 (!) different proofs outlined here , but the proofs of (2), (3) and (4) all assume proofs that the cartesian product of countable sets is also countable, or that the union of $k$ countable sets is also countable. My Discrete Math class will not have been exposed to those facts at the time that I discuss the countability of $\mathbb{Q^+}$, whereas proof (1) is an informal, non-rigorous proof of the ""snaking"" pattern which is not particularly satisfying to me (or to my best students). What I'm interested in is a mathematically accurate characterization of the ""snaking"" pattern; i.e I'm looking to find the formula $f(n)$ for a bijection $f$ from $\mathbb{N}^*$ (strictly positive integers) to $\mathbb{Q^+}$.","['rational-numbers', 'elementary-set-theory', 'discrete-mathematics']"
2035097,Projection properties in Hilbert space,"Let $L$ and $M$ be closed subspaces of a Hilbert space $H$ and $P_L,P_M\in \mathcal{L}(H,H)$ are orthoprojections to $L$ and $M$. I want to prove that then
$$P_M\geq P_L \Leftrightarrow L\subset M.$$ Partial order $P_M\geq P_L$ is defined as
$$P_M\geq P_L \Leftrightarrow ((P_M-P_L)x,x)\geq 0 \ \ \ \forall x\in X.$$ Any ideas?","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2035114,why scalar projection does not yield coordinates?,"Suppose we have an ordered basis $\{v_1,\dots,v_n\}$ in some inner product space. Let us project a vector $v$ on each $v_i$ by multiplying $v_i$ by the ""scalar projection"" $(v,v_i)/\|v_i\|$. Intuitively, it seems that each scalar projection $(v,v_i)/\|v_i\|$ indicates the amount of $v$ that goes in $v_i$ and therefore the $i^{th}$ coordinate of $v$ should be $(v,v_i)/\|v_i\|$. But that does not happen unless the basis is orthogonal. Mathematically I can justify this but can someone give an intuitive reason as to what goes wrong. For example with $B=\{(1,0),(1,1)\}$ in the Euclidean space $\mathbb R^2$ where $v=(0,1)$?","['linear-algebra', 'inner-products']"
2035115,Absolute Extrema: $f(x)=\frac{2x+5}{3}$,"I have to locate the absolute extrema of the given function: $$f(x)=\frac{2x+5}{3}$$ I found the derivative and set it equal to zero, and it can't equal zero ($f'(x)=\frac{2}3\therefore\frac23\ne0$) The interval where I have to find the absolute extrema is in the interval of $[0,5]$.  I am new to finding the absolute and I deduced that the extrema is one of the end-points particularly $x=5$. Is my assumption correct or is the there no absolute extrema?","['derivatives', 'calculus', 'functions']"
2035129,How does this prove the function has derivatives in all directions?,"This is the function I'm analyzing:
$$
g(x,y)=
\begin{cases}
\dfrac{xy(x^2-y^2)}{x^2+y^2} & \text{if } (x,y)\neq(0,0)\\
0 & \text{if } (x,y) = (0,0)\\
\end{cases}
$$ I need to prove it has derivatives in all directions at $(0,0)$, so I applied the definition using a generic vector $v=(A,B)$: $$
\lim_{h\to 0} \frac {g(0+hA;0+hB)-g(0,0)}{h}
$$ and I finally got to $A^3Bh-AB^3h$ Now I'm not sure what the conclusion is. Have I proven the function has derivatives in all directions at $(0,0)$? Also, how can I tell a function doesn't have derivatives in all directions? EDIT: corrected my result to add the missing $h$. However, my question remains the same: how does this prove the directional derivatives exist? What would a result be if they didn't exist? Thanks.","['multivariable-calculus', 'derivatives']"
2035145,Residue theorem change of variables,"Is there is a change of variables formula for residues?
I recently saw a computation of the residue of $f(z)=e^{7z}/(1-e^{-z})^{8}$ ""by change of variable $w=1-e^{-z}$"". Can someone state the principle behind this rigorously?",['complex-analysis']
2035168,"Distributing 11 socks into 4 drawers, with 5 red socks and 6 blue socks.","This is a problem I thought of while learning combinatorics, so it may be missing something. You have 11 socks (5 red socks and 6 blue socks) and 4 drawers. What is the number of ways that you can distribute 11 socks into 4 drawers? Now when I do this I thought of using the following formula
$$ x_1 + x_1' + x_2 + x_2' + x_3 + x_3' + x_4 + x_4' = 11 $$
with the primed ones being the number of blue socks in each drawer (there are four, hence the numbering) and the others being the number of red socks in each drawer. Then I impose the following conditions:
$ x_1, x_2, x_3, x_4 \leq 5 $ and $ x_1' ,x_2', x_3', x_4' \leq 6 $. But then  I remember that $ x_1 + x_2 + x_3 + x_4 = 5 $ and $ x_1' + x_2' + x_3' + x_4' = 6 $. There is a formula that counts the number of ways to distribute k objects into n boxes, which can be used in this situation: $$ \binom{n + k - 1}{k} $$ By the product rule I can just arrive at the solution:
$$ \binom{4 + 5 - 1}{5} \cdot \binom{4 + 6 - 1}{6} = 4704 $$ So is the problem well-defined? Is the solution above correct? Is there a simpler solution?",['combinatorics']
2035175,Finding the area of a circle from the area of a tangent right triangle,"My younger brother asked me this question, and I didn't know how to answer it. I am not a math major, but I really wanted to know if the given information is sufficient to answer the question.","['trigonometry', 'geometry']"
2035200,A graph is distance transitive iff it is vertex transitive,"A graph is distance transitive, if $\forall x,y,u,v \in V \ \text{so that}\ \  d(x,y)=d(u,v)$
there exists $g \in Aut(G)$ so that $g(x)=u$ and $g(y)=v$. $G$ is vertex transitive if $\forall x,y\in V$ the is some $g \in Aut(G)$ so that $g(x)=y$ I want to prove that: $G$ is distance transitive $\iff$ $G$ is vertex transitive and a stabilizer of a point over $Aut(G)$ has $diam(G)+1$ orbits. Could you help me with where to begin?","['group-actions', 'graph-theory', 'group-theory', 'discrete-mathematics']"
2035207,Matrices whose all principal $k\times k$ sub-matrices are positive semidefinite,"I would like to know whether the set of $n\times n$ Hermitian matrices  whose all ${{n}\choose{k}}$ principal $k\times k$ sub-matrices---the matrices obtained by removing $n-k$ columns as well as the corresponding rows---are positive semidefinite is a well-studied set, and if so under which name. This is for a given $1\leq k\leq n$. If $k=1$, this is the set of $n\times n$ matrices whose diagonal entries are non-negative, and, if $k=n$, it is the set of $n\times n$ positive-semidefinite matrices. I am interested in what is known for the general case $1\leq k\leq n$, in particular for the non-trivial case $1<k<n$, for $n\geq 3$.","['matrices', 'positive-semidefinite', 'linear-algebra']"
2035208,Is a map that preserves lines and fixes the origin necessarily linear?,Let $V$ and $W$ be vector spaces over a field $\mathbb{F}$ with $\text{dim }V \ge 2$. A line is a set of the form $\{ \mathbf{u} + t\mathbf{v} : t \in \mathbb{F} \}$. A map $f: V \to W$ preserves lines if the image of every line in $V$ is a line in $W$. A map fixes the origin if $f(0) = 0$. Is a function $f: V\to W$ that preserves lines and fixes the origin necessarily linear?,"['linear-algebra', 'linear-transformations']"
2035219,Example of a continuous function which is not smooth,"I need a function which is continuous but not smooth ( not a $C^{\infty})$. Smooth functions are those  whose derivatives of all order exists. For example $f(x)= e^{x}$ is a smooth function  while $f(x)=|x|$ is not smooth as derivative at $0$ does not exist. But what I require is functions in from $\mathbb{R}^{n} $ to $\mathbb{R}^{m}$. For simplicity it is enough to give functions from $\mathbb{R}^{2} $ to $\mathbb{R}^{2}$. I have examples of discontinuous functions from $\mathbb{R}^{2} $ to $\mathbb{R}^{2}$ , like $\frac{xy}{x^{2}+y^{2}}$  which is not continuous at $(0,0)$.","['functions', 'derivatives', 'calculus', 'analysis']"
2035228,Compute a triple Integral,"Compute the triple integral $\int\int\int_{D}fdV$ , where $f(\vec{r})= xy$ and $D$ is the tetrahedron: $D=(\vec{r}\in\mathbb{R^3}, 0 < y < x, |z| < 1 − x)$ This question has puzzled me for a number of hours now so if anyone could help me out that would be appreciated.","['multivariable-calculus', 'integration']"
2035287,Is a function which preserves zero and affine lines necessarily linear?,"My question is directly inspired by this other recent question , but I was trying to figure out whether or not it holds for $\mathbb R$. This led me to two questions. Let $n \ge 2$ be an integer (we're not including $n = 1$ as there are trivial counterexamples in dimension $1$). Let $V$ and $W$ be real vector spaces, both of dimension $n$, and let $f: V \to W$ be a bijection which sends zero to zero and affine lines to affine lines. Is $f$ necessarily linear? Let $V$ be a real vector space of dimension $n$. If we forget the vector space structure on $V$, and remember only the data of what the affine lines in $V$ are and $n$, can we recover the topology on $V$? An affirmative to question 1 implies an affirmative to question 2: Simply choose any bijection $f: V \to \mathbb R^n$ which preserves affine lines, and $f$ is necessarily a homeomorphism. In dimension $n=2$, question $2$ is equivalent to the following problem: Using only the data of what the affine lines are, given $3$ distinct parallel lines (which can be characterized as those which don't intersect with each other), determine which line is in the middle. Once you know that, you can describe open sets in terms of the unions of lines between two parallel lines. Similarly, for $n=2$, question 2 is also equivalent to: Using only the data of what the affine lines are, given a line and $3$ distinct points, determine which point is in the middle. It would also be good to know whether, and how, the answers to 1 and 2 depend on the dimension of $V$.","['general-topology', 'linear-transformations']"
2035291,Doubt over evaluation of integral of the form $\int_{-\infty}^{\infty}f(x) dx$ by using Cauchy residue theorem,"To evaluate an integral of the form $\int_{-\infty}^{\infty}f(x) dx$, where the rational function $f(x) =p(x)/q(x)$ is continuous on $(−∞, ∞)$, by residue theory we replace $x$ by the complex variable $z$ and integrate the complex function $f$ over a closed contour $C$ that consists of the interval $[−R, R]$ on the real axis and a semicircle $C_R$ of radius large enough to enclose all the poles of $ f(z) = p(z)/q(z)$ in the upper half-plane $Im(z) > 0$. Doubt: I am confused why we consider semicircle $C_R$ in the upper half-plane $Im(z) > 0$ only. What would happen if instead of taking semicircle $C_R$ in the upper half plane we take in lower half plane $Im(z) < 0$? Similarly, why we can't consider full circle instead of considering semicircles. I would be really grateful to you for your help.","['complex-analysis', 'residue-calculus']"
2035321,"Some question about first (or second) countable - first (second) ""countabilization""","Given $X$ be a topological space (or maybe a topological group), I am curious about is there a coarser or finer topology of $X$ or some quotient space such that it become first (or second) countable. Is there something like this? ""first (or second) countablization""? For example, let $G$ be a non-compact locally compact group, and its ""first (or second) countablization"" is also non-compact locally compact group? If this concept doesn't exist, can somebody give some intuition to explain why?
Some thing like ""If you try to verify the existence of ""first (or second) countablization"" by zorn's lemma you will encounter some ... problem.""? More precisely, I characterize this concept by universal property:
Let $X$ be a topological space, and $\widetilde{X}$ be first (or second) countablization of $X$, then given any $Y$ be first (or second) countable with a continuous map $\phi:X\to Y$, then $\phi$ factor through $\widetilde{X}$.","['general-topology', 'topological-groups', 'first-countable', 'second-countable']"
2035326,Add a vertex to G so that the new graph is Eulerian,"The question says, ""Let $G = (V, E)$ be a connected graph that is not Eulerian.  Prove that it is possible to add a single vertex to $G$, together with some edges from the new vertex to some old vertices of $G$ so that the new graph is Eulerian."" So far what I've got for my answer is the following, and I want to see if I'm heading in the right direction: ""Let $u, v \in V$.  $u$ is connected to $v $.   This means that there is a $(u, v)$-path in $G$.  Suppose $d(u)$ and $d(v)$ are odd.  Let us add a vertex to $V$; namely, $w$.  Let us also add some edges incident to $w$ and the vertices of odd degree.  Now, $d(u)$ and $d(v)$ are even.  $d(w) = 2$, so $d (w)$ is even as well.  $\forall v \in V, d(v)$ is even.  There are no vertices of odd degree, so $G$ is now Eulerian."" Any help would be appreciated!","['eulerian-path', 'graph-theory', 'discrete-mathematics']"
2035348,"How do you prove whether the set of functions $\{1,\sin 2x, \sin^2 x\}$ is linearly independent (in the vector space of all continuous functions)?","From the problem set of an ODE course: How do you prove whether the set of functions $\{1,\sin 2x, \sin^2 x\}$ is linearly independent (in the vector space of all continuous functions)? I understand that by definition, the functions are linearly dependent iff the only constants $a$, $b$, and $c$ that satisfy $a+b\sin 2x + c\sin^2 x = $ are $a=b=c=0$, but how do you (concisely) show whether this is the case?","['linear-algebra', 'functions', 'vector-spaces']"
2035356,How to cleverly solve this kind of equations?,"Suppose we have the following equations where $0<p<1$: \begin{align} a_{i,j}&=pb_{i+1,j} + (1-p)b_{0,j} \\
 b_{i,j}&=pa_{i,j+1}+(1-p)a_{i,0} \end{align} with the boundary
  conditions: \begin{align} b_{3,j}=1 \qquad\text{  where $0\le i< 3$}\\
 a_{i,3}=0 \qquad\text{  where $0\le j< 3$} \end{align} We are asked to get $a_{0,0}$ I can solve it by getting a set of equations such as:
\begin{align}
a_{0,0} & = pb_{1,0} + (1-p) b_{0,0}\\
b_{1,0} & = pa_{1,1} + (1-p) a_{1,0}\\
b_{0,0} & = pa_{0,1} + (1-p) a_{0,0}\\
a_{1,1} & = pb_{2,1} + (1-p) b_{0,1}\\
\vdots
\end{align} however this seems too complicated and very easy to calculate wrong. If we let the number $3$ in the boundary condition to be a much larger number $n$, then this method is impossible to solve by hand. I want to know if there is a better way or more analytical way to solve this kind of equation?","['reference-request', 'recurrence-relations', 'discrete-mathematics']"
2035358,"If $\sum n a_n$ converges, then $\sum a_n$ converges and $\sum |a_n|^p$ converges for $p>1$.","As in the title, consider the problem: If $\sum n a_n$ converges, then $\sum a_n$ converges and $\sum |a_n|^p$ converges for $p>1$. My intuition for the first part of the proof is to use this equality, $$\sum a_n = \sum n a_n -\big(\sum a_n(n-1)\big) $$ Obviously the first part of the RHS converges by assumption, and I want to say the second part of the RHS does as well, however I don't know if it's entirely obvious that it does. Is this reasoning valid? And if there is a more clever way, please let me know. Additionally, I'm not sure where to begin in showing that the hypothesis implies $\sum|a_n|^p$ converges. All help is greatly appreciated.","['real-analysis', 'sequences-and-series']"
2035361,Representations of general linear group,"It is known that some of the irreducible representations of general linear group are related to irreducible representations of symmetric group. Due to this relation we can index irreducible representations of general linear group by integer partition. My question is that given an integer partition $\lambda=(d_1,d_2,...,d_n)$ how do I find irreducible representation of $GL(V)$ related to this partition?","['abstract-algebra', 'combinatorics', 'representation-theory']"
2035362,why do the Computability theory choose the natural number as the object of study？,I am wondering why the computable function is defined in the natural number set.Can people give me the answer or some resources that can solve my puzzle.,"['predicate-logic', 'computational-mathematics', 'elementary-number-theory', 'computability', 'discrete-mathematics']"
2035383,Establishing the identity $\frac{\sin(\alpha+\beta)}{\cos\alpha \cos\beta} = \tan\alpha+\tan\beta$,"Establish the identity: $$\frac{\sin(\alpha+\beta)}{\cos\alpha \cos\beta} = \tan\alpha+\tan\beta$$ I'm having a hard time solving this one. I changed the numerator to $\sin\alpha\cos\beta+\cos\alpha\sin\beta$ and the denominator to $\frac{1}{2}[\cos(\alpha-\beta)+\cos(\alpha+\beta)]$, but I'm not really sure what to do from there. Multiplying by the conjugate didn't seem to get me anywhere, either. I'd really appreciate help with this!",['trigonometry']
2035399,"Let $U$,$V$ and $W$ be finite dimensional normed vector spaces and let $B:U\times V\rightarrow W$ be a bilinear map. Prove it is differentiable.","The derivative at any point $(u,v)\in V\times W$
  is the linear map defined by $(x,y)\longmapsto B(u,y)+B(x,v)$
 . I am trying to prove this using the limit definition. My limit ended up looking like ${{\displaystyle {\lim_{(h_{1},h_{2})\to0}}}}\frac{|B(h_{1},h_{2})|}{|(h_{1},h_{2})|}$
  and I am trying to prove that it is $0$
 , but I don't now how.","['functional-analysis', 'derivatives']"
2035418,Can we prove the law of total probability for continuous distributions?,"If we have a probability space $(\Omega,\mathcal{F},P)$ and $\Omega$ is partitioned into pairwise disjoint subsets $A_{i}$ , with $i\in\mathbb{N}$ , then the law of total probability says that $P(B)=\sum_{i=1}^{n}P(B|A_{i})P(A_i{})$ . This law can be proved using the following two facts: \begin{align*}
P(B|A_{i})&=\frac{P(B\cap A_{i})}{P(A_{i})}\\
P\left(\bigcup_{i\in \mathbb{N}} S_{i}\right)&=\sum_{i\in\mathbb{N}}P(S_{i})
\end{align*} Where the $S_{i}$ 's are a pairwise disjoint and a $\textit{countable}$ family of events in $\mathcal{F}$ . However, if we want to apply the law of total probability on a continuous random variable $X$ with density $f$ , we have ( like here ): $$P(A)=\int_{-\infty}^{\infty}P(A|X=x)f(x)dx$$ which is the law of total probabillity but with the summation replaced with an integral, and $P(A_{i})$ replaced with $f(x)dx$ . The problem is that we are conditioning on an $\textit{uncountable}$ family. Is there any proof of this statement (if true)?","['probability', 'probability-distributions']"
2035426,Chapman Pugh Solutions,"I am currently teaching myself Real Analysis with Chapman Pugh's wonderful book and I am trying to solve every exercise. However, it would be nice to have the solutions to at least a number of the problems so see if I am at least solving them in somewhat of the right manner. Also, would anyone happen to know if skipping the starred sections (Cantor Set lore etc) affect the read much? Thanks!","['self-learning', 'real-analysis']"
2035454,I'm looking for some mathematics that will challenge me as a year $12$ student. [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I am an upcoming year $12$ student, school holidays are coming up in a few days and I've realised I'm probably going to be extremely bored. So I'm looking for some suggestions. I want a challenge, some mathematics that I can attempt to learn/master. Obviously nothing impossible, but mathematics is my number $1$ favorite thing and I really want something to keep me busy and something that can further my understanding of mathematics. Also I would be interested in any mathematical focused book suggestions. So far in school I've done the usual: Matrices, transformation matrices, Sine Cosine and Tangent (graphs and proofs), lots and lots of parabolas/quadratics, statistics, growth and decay, calculus intro, Calculus derivation and integration, vectors, proof by induction and complex numbers. Any suggestions would be heavily appreciated.","['self-learning', 'learning', 'education', 'calculus']"
2035469,Proof of Translation Invariance of Brownian motion by Durrett,"Below is the proof of the translation invariance of a one dimensional Brownian motion starting at the origin, given by Durrett in Probability Theory and Examples. However, the proof only shows independence, and I don't see how $\{B_t-B_0:t\ge 0\}$ has the same distribution as a Brownian motion with $B_0=0$ as stated in the theorem. I would greatly appreciate it if anyone could explain this part to me.","['stochastic-processes', 'probability-theory', 'stochastic-analysis', 'brownian-motion', 'stochastic-calculus']"
2035494,Need help with this problem about continuous homogeneous function.,"Let $f : \mathbb {R}^d \to \mathbb{R}$ be a continuous function. Assume that $f$ is homogeneous of degree $r$, $r \gt 0$, that is: $$f(t\textbf{x}) = t^{r}f(\textbf{x}), \ \ \ \ \  \forall \textbf{x} \in \mathbb{R}^d, \ \ \  \forall t \in [0, \infty ].$$ Show that if $f(\textbf{x}) \gt \ 0 \ \ \ \  \forall \textbf{x} \in \mathbb{R}^d/\{0\}$, then $$f({x}) \ge c |\textbf{x}|^r \ \ \ \forall \textbf{x} \in \mathbb{R}^d$$ for some $c \gt 0$ where $|\textbf{x}|$ is the magnitude (ie Euclidean length or norm) of vector $\textbf{x}$. I'm told compactness is important here but I'm unable to understand how.","['real-analysis', 'calculus', 'multivariable-calculus', 'general-topology', 'analysis']"
2035680,Prove $4a^2+b^2+1\ge2ab+2a+b$,Prove $4a^2+b^2+1\ge2ab+2a+b$ $4a^2+b^2+1-2ab-2a-b\ge0$ $(2)^2(a)^2+(b)^2+1-2ab-2a-b\ge0$ Any help from here? I am not seeing how this can be factored,['algebra-precalculus']
2035688,Question on proof that $|G| = pqr$ is not simple,"Assume $|G| = pqr$ where $p,q,r$ are primes with $p < q < r$. Then $G$
  is not simple. I have a problem understanding the proof (see for example here ). In the proof one assumes that $n_p,n_q,n_r > 1$ (number of each $p,q,r$-Sylow subgroups respectively) and then by Sylow we have $$n_r | pq \qquad \text{and} \qquad n_r = 1 + kr, k\in \mathbb{N}_0$$ Now one deduces that $n_r = pq$, which I do not understand.",['abstract-algebra']
2035707,When do Eigenvalues of $Q^TAQ$ and $A$ coincide?,"Lets say I have some $n\times n$ matrix  $A$ and a $n\times l$ matrix $Q$, whose columns for a basis for some subspace $\mathcal{L} \subset \mathbb{R^n}$. My intuition tells me that I would need $Q$ to be a full orthogonal basis of $\mathbb{R^n}$ ( i.e. $l=n$), such that all eigenvalues $\lambda_i$ of  $Q^TAQ$ and $A$ coincide. However, I don't see where in the proof for the latter assertion the same dimensionality is needed: Be $v\in\mathbb{R}^n\setminus\{0\}$ an eigenvector of A, i.e. $Av=\lambda v$. Then $\lambda$ is an eigenvalue of $Q^TAQ$ with eigenvector $Q^Tv$:
$$
(Q^TAQ)(Q^Tv)=Q'A(QQ^T)v=Q^TAv=\lambda(Q^Tv).
$$ Be $v\in\mathcal{L}\setminus\{0\}$ an eigenvector of (Q^TAQ), i.e. $(Q^TAQ)v=\lambda v$. Then $\lambda$ is an eigenvalue of $A$ with eigenvector $Qv$:
$$
A(Qv)=IAQv=QQ^TAQv=Q(Q^TAQv)=\lambda(Qv).
$$ Maybe you can help me out here. Thanks a lot in advance!","['matrices', 'orthogonal-matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2035806,"Prove for all $x$, $x^8+x^6-4x^4+x^2+1\ge0$","Prove for all $x$ $x^8+x^6-4x^4+x^2+1\ge0$ By completing the square you get
$(x^4-2)^2+(x^3)^2+(x)^2-3\ge0$ I'm stuck about the $-3$",['algebra-precalculus']
2035816,Proper pushforward of Chow groups,"I am trying to understand proper pushforwards of Chow groups. Let $f:X \to Y$ be a proper morphism of schemes. Suppose $A$ is a subvariety of $X$. Then the pushforward should be $n \cdot [f(A)]$, where $n=[k(A):k(f(A))]$. This multiplicity is there to ensure the pushforward respects rational equivalence. Is there a simple example that shows the multiplicity is required? Namely, is there any example of a proper morphism where the naive pushforward without multiplicity fails to respect rational equivalence? Thank you.",['algebraic-geometry']
2035840,Can a right triangle have odd-length legs and even-length hypotenuse?,"Is it possible to have an even integer hypotenuse and odd integer legs (perpendicular and base) in a right triangle? If yes, please give an example. If no then please prove that.","['pythagorean-triples', 'geometry']"
2035842,To show the zeros of functions are distinct,Show that the zeros of the functions $a \sin(x) + b \cos(x)$ and $c \sin(x)  + d \cos(x)$ are distinct and occur alternately if $ad-bc \ne 0$. I guess I need to use Sturm separation theorem. I need to show that both these functions are linearly independent. This gives me the hint to use wronskian. Is this much enough to show this?,['ordinary-differential-equations']
2035854,Any nonempty open subsets of a variety have a nonempty intersection,"I have seen that any nonempty open subsets of a variety $Z$ have a nonempty intersection but I am not sure why this is true. I guess the point is that a variety is irreducible and an empty intersection of open sets should give me a contradiction however I fail to see the contradiction. Say $U_1,U_2$ are open and disjoint in $Z$ then $Z-U_1$ and $Z-U_2$ are closed in $Z$ and $Z$=$(Z-U_1)\cup (Z-U_2)$. That would be a contradiction if those sets were closed. I mean we know that they are closed in $Z$ however we can't say that they are closed in the whole space $A^n$. So how do I prove the statement?","['general-topology', 'algebraic-geometry']"
2035855,Rotating Kindergartners at Tables Monthly,"My wife teaches AM and PM kindergarten classes. AM has 14 students and PM 11. At the beginning of each month, she puts out a new seating chart where she rotates students in such a way that they (ideally) sit at a different table and with different students for that month. There are 3 students per table, but if numbers force the issue, the last may have more or less. We realize that, by the end of the year, there will be some unavoidable situations where students end up sitting with each other or at the same tables again, and this is okay. She works on this seating diagram every month and it's a huge chore. It's agonizing to see her do this because it's very time-consuming, and I feel helpless. I know there has to be a mathematical way to do it. I did find one formula on here, but couldn't figure out what the variables represented and how to change them to meet her needs as students come and go. Can anyone help me out? It would be even better if I could use Excel to automate this process.  [sorry if the tags are inappropriate; I just guessed]","['combinatorics', 'linear-programming']"
2035875,Can you have negative sets?,"I figure that since you can, of course, have members in a set, have only a single member in a set, and then have no members in a set, it seems not then a big step forward (or backwards depending how you think of it) to think of a set with negative members. I shall elucidate. Since set theory deals with membership, and it deals not with the quantity, but the quality of those members, perhaps it be possible to have a set with negative members which subtract members from another set whose positive counterparts is contained therein. For example, the union of the sets $A$ and $B$, where set $A = \{1,2,3\}$ and set $B =\{-3\}$ would result in the set $A ∪ B = {1,2}$. Two notes: First, you can arbitrarily construct any set one desires, but when applied to the real world, perhaps this may be of use?; Second, the empty set seems frivolous but turned out to be quite useful, maybe the same may be said for negative sets? As someone pointed out, and they are of course correct, the set would actually be $\{1,2,3,-3\}$. However, in sticking with the principle, is what am describing denotable?",['elementary-set-theory']
2035883,About open subsets of affine schemes.,"Let $A$ be a commutative ring with unity. Consider its associated affine scheme $(\operatorname{Spec}(A),\mathcal{O}_A)$. I was wondering if the restriction morphism,
$$A \xrightarrow{r|^X_U} \mathcal{O}_A(U)$$
would induce an open immersion of $\operatorname{Spec}(\mathcal{O}_A(U))$ into $\operatorname{Spec}(A)$. I know this for the case of distinguished opens. What happens in the general case?",['algebraic-geometry']
2035888,"Exercise 3A.7 of ""Finite group theory"", M. Isaacs","Let $G$ finite group and $\sigma \in \text{Aut}(G)$, suppose that at most two prime numbers divide $o(\sigma)$. Show that $\left \langle \sigma \right \rangle$ has a regular orbit on $G$. Suppose $o(\sigma)=p^\alpha q^\beta$ with $\alpha, \beta$ non-negative numbers, $\alpha+\beta>0$. Decompose (as a partition) $G$ in orbits under the action of $\left \langle \sigma \right \rangle$:
\begin{gather}
G=x_1^{\left \langle \sigma \right \rangle}\cup \dots \cup x_n^{\left \langle \sigma \right \rangle}
\end{gather}
Write $\lambda_i=x_i^{\left \langle \sigma \right \rangle}$ and $m=\mathrm{lcm}\{o(\lambda_1), \dots ,o(\lambda_n)\}$ and suppose $m<p^\alpha q^\beta$.Without loss of generality we can assume $m\le p^{\alpha -1} q^\beta$. Looking at each orbit, $\left \langle \sigma \right \rangle$ acts with a non trivial kernel that contains a subgroup of order $p$; being $\left \langle \sigma \right \rangle$ abelian, there is a unique subgroup of order $p$, i.e. $\left \langle \sigma^{p^{\alpha -1} q^\beta} \right \rangle$. This means that this subgroup of order $p$ acts trivially on $G$ and this is impossible since $\left \langle \sigma \right \rangle \le Aut(G)$. Then $m=p^\alpha q^\beta$ and there are two orbits $\lambda_i, \lambda_j$ such that $p^\alpha$ divedes $o(\lambda_i)$ and $q^\beta$ divides $o(\lambda_j)$. By direct check $\left \langle \sigma \right \rangle$ acts faithfully on  $\Lambda=\lambda_i \cup \lambda_j$, and since it is abelian (cyclic) the action is regular. I think that this proof works (correct if I'm wrong). The only problem is that this exercise is presented after the section of semidirect products but this notion is not used. Maybe it can be done studying  $\Omega_\pi(G \rtimes \left \langle \sigma \right \rangle)$ for $\pi=\{p,q\}$, but I can't find a proof in this way.
Does someone know a proof using the semidirect products?","['finite-groups', 'semidirect-product', 'group-theory']"
2035979,"Cavalieri's, Mamikon's and Peano's methods for areas/volumes: how are they related?","Three results from three mathematicians from three different eras provide interesting and surprisingly easy instruments to compute areas and volumes of plane figures or solids. The first two - Cavalieri's Principle (1635) and Mamikon's Theorem (1959) - directly supply stunningly calculus-free methods for calculating ""integrals"" (possibly by hiding calculus under the carpet). At first glance, they seem incredibly similar in fashion; yet, I don't believe that they are quickly (and calculus-free ly ) deducible one from the other. The third one is a not-so-well-known proposition by Italian mathematician Giuseppe Peano, who discussed it in his ""Applicazioni geometriche del calcolo infinitesimale"" (1887). It is much more general and it implies both Cavalieri's result for areas and Mamikon's Theorem as corollaries. Unluckily, it's calcululus-heavy both in its statement and its proof. I will summarise the three statements (for the sake of simplicity, just very stripped-down 2D-versions) in a short while. First of all, though, I want to make my question explicit: is there a way to formulate a proposition which is general enough to include both Cavalieri's Principle and Mamikon's Theorem, and at the same time ""narrow"" enough not to require calculus at least in its statement , as Peano's result does instead? Cavalieri's Principle ( Wikipedia ): Suppose two regions in a plane are included between two parallel lines in that plane. If every line parallel to these two lines intersects both regions in line segments of equal length, then the two regions have equal areas. Mamikon's Theorem ( Wikipedia: Visual Calculus ): The area of a tangent sweep to a curve is equal to the area of its tangent cluster, regardless of the shape of the original curve.
  ( Tangent sweep : the surface ""swept"" by a family of segments tangent to a curve when one of their endpoints P continuously moves along the curve; tangent cluster : the surface obtained by translating the aforementioned segments so that P is no longer moving - see figure) Peano's result ( Archive ): Let $A(t), B(t)$ be plane $C^1$ curves, parametrised by $t$, such that the segment $AB(t)$ never passes through the same point as $t$ ranges from $t_0$ to $t_1$. The area swept by the moving segment $AB(t)$ is given by: $\int_{t_0}^{t_1}(B(t)-A(t))\cdot(\frac{d}{dt} A(t)+\frac{d}{dt} B(t))dt$. Special cases of Peano's result give Cavalieri's and Mamikon's ones, as discussed here by Gabriele Greco et al.: Particular instances of the formula considered by Peano are the following: a) The point A moves along a straight line and the angle of the segment AB
  with that line is constant; b) The point A is fixed; c) The segment AB is tangent at the point A to the curve described by A; d) The segment AB is of constant length and normal to the curve described by
  its midpoint. Case a) brings Cavalieri's Principle; case c) (perhaps in combination with b)) gives Mamikon's Theorem. So, question is: is it possible to ""merge"" Cavalieri and Mamikon (+ possibly other corollaries of Peano) without any direct reference to the integral? Something more in the style of Cavalieri and Mamikon, such as: ""if line segments constructed in {some general way encompassing both Cavalieri's and Mamikon constructions} in both figures are the same, then the two figures are area-equivalent""? I don't actually care about avoiding integrals in the proof : it's satisfying enough for me if the theorem statement is integral-free. And what about volumes?","['math-history', 'integration', 'geometry', 'tangent-line', 'area']"
2035989,"The sum of eigenvalues of integral operator $S(f)(x)=\int_{\mathcal{X}} k(x,y)f(y)d\mu(y)$ is given by $\int_{\mathcal{X}} k(x,x) d\mu(x)$?","Setup: Let $(\mathcal{X},d_{\mathcal{X}})$ and $(\mathcal{Y},d_{\mathcal{Y}})$ be two separable metric spaces. Let $M^1(\mathcal{X})$ be the space of Borel probability measures on $\mathcal{X}$ with finite first moment, i.e. a Borel probability measure $\mu$ on $\mathcal{X}$ is in $M^1(\mathcal{X})$ if $\int d_{\mathcal{X}}(x,o) d\mu(x)<\infty$ for any $o\in\mathcal{X}$ . The space $M^1(\mathcal{Y})$ is defined in similar fashion. Fix $\mu\in M^1(\mathcal{X})$ and $\nu\in M^1(\mathcal{Y})$ and define $$
d_\mu(x_1,x_2)= d_{\mathcal{X}}(x_1,x_2) -\int d_{\mathcal{X}}(x_1,x)\,  d\mu(x) - \int d_{\mathcal{X}}(x_2,x)\,  d\mu(x) + \int  d_{\mathcal{X}}(x,x')\,  d\mu^2(x,x'),
$$ and a similar definition of $d_\nu:\mathcal{Y}\times \mathcal{Y}\to\mathbb{R}$ . Now let $S:L^2(\mathcal{X}\times \mathcal{Y},\mathcal{B}(\mathcal{X})\otimes \mathcal{B}(\mathcal{Y}),\mu\times \nu) \to L^2(\mathcal{X}\times \mathcal{Y},\mathcal{B}(\mathcal{X})\otimes \mathcal{B}(\mathcal{Y}),\mu\times \nu),$ be a Hilbert-Schmidt operator given by $$
S(f)(x,y) = \int d_\mu(x,x')d_\nu(y,y') f(x',y') d\mu\times \nu(x',y').
$$ and let $\{\lambda_i\}_{i\geq 1}$ denote the non-zero eigenvalues of $S$ repeated according to multiplicity. Question: How do I prove the following identity: $$\sum_{i=1}^\infty\lambda_i=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y).$$ I tried but failed to show that $S$ is of trace class, since they under certain conditions (which I also can't verify in this setup) satisfy that $$
Trace(S)=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y),
$$ which yields the result since $Trace(S)=\sum_{i=1}^\infty\lambda_i$ (if it were of trace class). The identity $\sum_{i=1}^\infty\lambda_i=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y)$ is stated in Distance covariance in metric spaces by Russell Lyons (2013) Theorem 2.7 , without proof, so my approach with traces is only an idea. If another way of proving the identity appears or if there is a counterexample, that would more than satisfy my needs. In the case of a counterexample i would very much appreciate stronger initial conditions rendering the identity true. Please bear in mind that i am a novice in the theory of operators and trace class operators (only went down this road to explain the equality above), so references would be much appriciated. Update: A counterexample to the operator being of trace-class is presented by Russell Lyons in the errata to the mentioned paper. Furthermore a proof that the formula holds and that the operator is of traceclass, whenever the marginal spaces posses additional nice proporties (isometric embeddability into hilbert spaces), is also presented in this errata.","['operator-theory', 'functional-analysis', 'statistics', 'spectral-theory', 'trace']"
2036039,How is the Königsberg 7 bridge problem related to topology?,"How can we use topology to solve the famous konigsberg 7 bridge problem? By using graph theory we can say that there does not exists any such path but I want to know the application of topology on the 7 bridge problem. Could anybody explain it to me? 
Thanks",['general-topology']
2036049,Number of natural solutions to $x_1 + x_2 + x_3 + 2x_4 + x_5 = 72$,"What are the number of natural solutions to $$x_1 + x_2 + x_3 + 2x_4 + x_5 = 72$$ where $x_1 \ge 2, x_2, x_3 \ge 1, x_4, x_5 \ge 0$ ? I understand how to do it if it wasn't "" $2x_4$ "", hence if the coefficient of $x_4$ was $1$ , , then the answer will be $C(72,4) \ldots \ $ , but given $2x_4$ , I don't know how to solve the question.","['diophantine-equations', 'combinatorics', 'discrete-mathematics']"
2036124,Hessian matrix in spherical coordinates,"This seems like a straightfoward question but I cannot find the answer anywhere. I need to implement the Hessian matrix of a real scalar function f (an Hamiltonian, to be specific) in spherical coordinates (1,$\theta$,$\phi$) on the unit sphere and evaluate it at a turning point where the first derivatives vanish ($\frac{\partial f}{\partial \theta} =\frac{\partial f}{\partial \phi}=0 $). My first try was $$
H=
\begin{pmatrix}
    \frac{\partial^2 f}{\partial \theta^2} &  \frac{\partial^2 f}{\partial \theta \partial \phi} \\
    \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{\partial^2 f}{\partial \phi^2} 
  \end{pmatrix},
$$
which is what I found in many (physics) papers where $\theta$ is conveniently set to $\frac{\pi}{2}$. However, what I observed numerically is that because the elementary displacement on the sphere $\delta \vec{m}$ caused by a variation d$\phi$ depends on $\theta$, this is valid at the equator and then gradually breaks down closer to the poles because the  $\frac{\partial^2 f}{\partial \phi^2}$ and $\frac{\partial^2 f}{\partial \theta \partial \phi}$ terms tend to $0$ when they shouldn't. This problem is corrected in the spherical gradient by the $\frac{1}{\sin \theta}$ factor on the $\hat{e}_{\phi}$ component, ie:
$$
\nabla f = \frac{\partial f}{\partial \theta}\hat{e}_{\theta}+\frac{1}{sin \theta} \frac{\partial f}{\partial \phi}\hat{e}_{\phi}.$$ From various sources (incl. wikipedia ), the Hessian is sometimes defined as the Jacobian of the gradient,  which in spherical coordinates would be $H=J(\nabla f)= \big[ \frac{\partial \nabla f}{\partial \theta} ,\frac{\partial \nabla f}{\partial \phi} \big]$.
If I apply this at a turning point where the first derivatives vanish, I end up with
$$ H=
\begin{pmatrix}
    \frac{\partial^2 f}{\partial \theta^2} &  \frac{\partial^2 f}{\partial \theta \partial \phi} \\
   \frac{1}{\sin \theta}  \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{1}{\sin \theta} \frac{\partial^2 f}{\partial \phi^2} 
  \end{pmatrix}.
$$ This is not symmetric anymore, which bothers me because in every book I looked, it says the Hessian is symmetric as long as the mix derivatives commute. Does this mean this definition does not apply in spherical coordinates? Is there a more general definition I can use? Additionally, I found this post which defines $H=\nabla \nabla^T$. This yields $$ H=
\begin{pmatrix}
    \frac{\partial^2 f}{\partial \theta^2} & \frac{1}{\sin \theta} \frac{\partial^2 f}{\partial \theta \partial \phi} \\
   \frac{1}{\sin \theta}  \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{1}{\sin^2 \theta} \frac{\partial^2 f}{\partial \phi^2} 
  \end{pmatrix}
$$ which is a lot more intuitive, but it clashes with the previous Jacobian of the gradient definition Any help/clarifications or suggestions greatly appreciated.","['multivariable-calculus', 'hessian-matrix', 'spherical-coordinates', 'vector-analysis']"
2036196,Can I bound the correlation of two random variables using the mutual information?,"As correlation $\rho_{X,Y} := \frac{Cov(X,Y)}{\sigma_X \sigma_Y}$ sort of measures the linear dependence of two random variables, and mutual information $I(X; Y) := H(X) - H(X|Y)$ measures the general dependence of two random variables, I feel like it should be possible to get an upper bound on the correlation in terms of the mutual information. I expect that as the mutual information increases, correlation tends to 1, and as mutual information tends to 0, correlation also does. Can anyone help me formalise this?","['statistics', 'probability', 'correlation', 'covariance']"
2036206,Show that ${1-\cos^2(x)\over \sec^2(x)-1}=1-\sin^2(x)$,${\sin^2(x)\over \tan^2(x)}$ I did this and then got stuck. Could someone give me some hints please?,['trigonometry']
2036211,The smallest odd perfect number must exceed $10^{300}$.,"I am studying about perfect numbers from last two week and have experienced so much adventure in studying such an interesting topic. The basic sources have been Wikipedia and the book Euler: Master of us all. After proving so many results and reading so much theory I m stuck on one of the results mentioned at the end of the the book ""Euler: Master of us all"". The result is as follow: The smallest odd perfect number must exceed $10^{300}$. Since the name of mathematician who gave the result is not given in the book so I can't even find it on internet. I shall be highly thankful if you can give me a hint to approach for this result or can supply a direct proof. Forgive me if this result is trivial and I m missing very common thing. Thanks.","['number-theory', 'proof-writing']"
2036237,Finding the Equations of Motion in a Classical Mechanics Problem,"Question Consider an axle which connects two wheels of radius $R$ each at distance $L$ from its center; each wheel may spin frictionlessly about the axle but they are constrained by strong static friction such that they roll with respect to the ground (See the figure below). The following equations are the Newton-Euler equations for each part of the system shown in the figure \begin{align*}
{\bf{X}}_{P_1}+{\bf{X}}_{C_1}+\,m{\bf{g}}  &=  m \ddot{{\bf{r}}}_{C_1}  \\
{\bf{X}}_{P_2}+{\bf{X}}_{C_2}+\,m{\bf{g}}  &=  m \ddot{{\bf{r}}}_{C_2}  \\
-{\bf{X}}_{C_1}-{\bf{X}}_{C_2}+M{\bf{g}}  &=  M \ddot{{\bf{r}}}_{C_3} \\
{\bf{T}}_{1}+{\bf{Y}}_{C_1}+{}_{C_1}{\bf{r}}_{P_1}\times{\bf{X}}_{P_1}  &=  {}_{C_1}\dot{\bf{H}}_{1}  \\
{\bf{T}}_{2}+{\bf{Y}}_{C_2}+{}_{C_2}{\bf{r}}_{P_2}\times{\bf{X}}_{P_2}  &=  {}_{C_2}\dot{\bf{H}}_{2}  \\
-{\bf{Y}}_{C_1}-{\bf{Y}}_{C_2}-{}_{C_3}{\bf{r}}_{C_1}\times{\bf{X}}_{C_1}-{}_{C_3}{\bf{r}}_{C_2}\times{\bf{X}}_{C_2}  &=  {}_{C_3}\dot{\bf{H}}_{3}
\tag{1}
\end{align*} where we also know that \begin{align*}
{\bf{Y}}_{C_1}  \boldsymbol{\cdot} {\bf{b}}_1  &=  0  \\
{\bf{Y}}_{C_2}  \boldsymbol{\cdot} {\bf{b}}_1  &=  0
\tag{2}
\end{align*} which means that the connection of the wheels and the shaft is such that no constraint torque is applied in ${\bf{b}}_1$ direction. Also, by assuming that both wheels roll with respect to the ground one can obtain the following constraint equations \begin{align*}
\dot{x}  &=  \frac{R}{2}(\dot{\varphi_1}+\dot{\varphi_2})\sin\theta  \\
-\dot{y}  &=  \frac{R}{2}(\dot{\varphi_1}+\dot{\varphi_2})\cos\theta  \\
\theta-\theta_0   &=  \frac{R}{2L}(\varphi_1-\varphi_2)
\tag{3}
\end{align*} My final aim is to find the generalized coordinates $\varphi_1,\varphi_2,\varphi_3,\theta,x,y$ as a function of time. So I need another three scalar equations in terms of generalized coordinates and their derivatives other than the three constraint equations in $(3)$. I think that we should obtain them by manipulating equations in $(1)$; however, I am  unable to obtain those. Any hint or help for finding them is appreciated. :) Notice All of the quantities $\ddot{{\bf{r}}}_{C_1},\ddot{{\bf{r}}}_{C_2},\ddot{{\bf{r}}}_{C_3},\dot{\bf{H}}_{1},\dot{\bf{H}}_{2},\dot{\bf{H}}_{3},{}_{C_3}{\bf{r}}_{C_1},{}_{C_1}{\bf{r}}_{P_1}$ depend on the generalized coordinates $\varphi_1,\varphi_2,\varphi_3,\theta,x,y$ and their first and second time derivatives. The system is linear with respect to the constraint forces ${\bf{X}}_{P_1},{\bf{X}}_{P_2},{\bf{X}}_{C_1},{\bf{X}}_{C_2},{\bf{Y}}_{C_1},{\bf{Y}}_{C_2}$. ${}_{P_1}{\bf{r}}_{C_1}={}_{P_2}{\bf{r}}_{C_2}=R{\bf{a}}_3$ and $-{}_{C_3}{\bf{r}}_{C_1}={}_{C_3}{\bf{r}}_{C_2}=L{\bf{b}}_1$. That would be nice if we could obtain a vectorial equation without choosing a basis. So we may think of elimiating constraint forces from equations in $(1)$. As an attemp I summed the first three and second three equations in $(1)$ to obtain \begin{align*}
{\bf{X}}_{P_1}+{\bf{X}}_{P_2}+(M+2m){\bf{g}}  &=  (M+2m)\ddot{{\bf{r}}}_{C_3} \\
{\bf{T}}_{1}+{\bf{T}}_{2}+{}_{C_1}{\bf{r}}_{P_1}\times({\bf{X}}_{P_1}+{\bf{X}}_{P_2})  &=  {}_{C_1}\dot{\bf{H}}_{1}+{}_{C_2}\dot{\bf{H}}_{2}+{}_{C_3}\dot{\bf{H}}_{3} \\
-{}_{C_3}{\bf{r}}_{C_1}\times({\bf{X}}_{C_1}-{\bf{X}}_{C_2}) &
\tag{4}
\end{align*}
$\quad\,\,$ however, I don't know how to proceed further and make ${\bf{X}}_{C_1}-{\bf{X}}_{C_2}$ disappear. Notation $m$ is the mass of each wheel and $M$ is the mass of the shaft. $R$ is the the radius of wheels and $2L$ is the length of the shaft. ${\bf{g}}$: accelaration due to gravity. ${\bf{X}}_{P_i}$: The constraint force applied at point $P_i$ which is exerted by surface to the wheel $i$. ${\bf{X}}_{C_i}$: The constraint force applied at point $C_i$ which is exerted by shaft to the wheel $i$. ${\bf{Y}}_{C_i}$: The constraint torque which is exerted by shaft to the wheel $i$. ${\bf{T}}_{i}$: The external torque applied by the actuator to the wheel $i$. ${\bf{r}}_{P}$: The position vector of point $P$ with respect to origin of frame $a$. ${}_{Q}{\bf{r}}_{P}$: The position vector of point $P$ with respect to piont $Q$. ${}_{P}{\bf{H}}_i$: The angular momentum of part $i$ with respect to point $P$. The overdot notation represents the time derivative with respect to the inertial frame $a$. Figure","['classical-mechanics', 'linear-algebra', 'vectors', 'systems-of-equations']"
2036252,"Examples about that $\exp(X+Y)=\exp(X) \exp(Y)$ does not imply $[X,Y]=0$ where $X,Y$ are $n \times n $ matrix","I read the https://en.wikipedia.org/wiki/Matrix_exponential There is a saying that ""The converse is not true in general. The equation $\exp(X+Y)=\exp(X) \exp(Y)$ does not imply that X and Y commute."" I would like to know some concrete examples.","['matrices', 'examples-counterexamples', 'matrix-exponential']"
2036361,"Does $\int _{\mathbb{R}^d}f\circ\phi \,\, d\mu =\int _{\mathbb{R}^d}f\circ\psi \,\, d\mu $ imply $\phi=\psi$?","Let $\mu$ be Borel Probability measure, and $\phi:\mathbb{R}^d\rightarrow \mathbb{R}$, $\psi:\mathbb{R}^d\rightarrow \mathbb{R}$ be measurable mappings defined $\mu$-almost everywhere. My claim is that if
$$\int _{\mathbb{R}^d}f\circ\phi \,\, d\mu =\int _{\mathbb{R}^d}f\circ\psi \,\, d\mu $$
for every bounded Borel function $f$ on $\mathbb{R}$, we have $\phi=\psi\,\,\,\text{$\mu$-almost everywhere}.$ Is it true? Obviously $f\circ\phi=f\circ\psi$ for positive $f$ but I can't go further.","['probability-theory', 'measure-theory']"
2036457,Characteristic Function of an Ornstein Uhlenbeck process,"Consider the Ornstein Uhlenbeck process, defined by the SDE:
$$
dX_t = \alpha(\mu - X_t) dt + \sigma dW_t
$$ I want to compute the characteristic function of this process. My approach is simply to apply Ito's lemma and then taking the expectation. Therefore, since the characteristic function is defined by 
$$
\varphi(X_t)=\mathbb{E}[e^{itX_t}]
$$
Therefore, we apply Ito's lemma to the original SDE, with the function $g(X_t,t)=e^{itX_t}$. This yields
$$
dg(X_t) = (iX_t e^{itX_t} + ite^{itX_t}(\alpha(\mu -X_t)) - \frac{1}{2}t^2e^{itX_t} \sigma^2) dt + ite^{itX_t} \sigma dW_t
$$
Hence, taking the expectation should yield
$$
\mathbb{E}[g(X_t)] = e^{itX_0} + (iX_t e^{i t X_t} + i t e^{iX_t}(\alpha(\mu - X_t)) - \frac{1}{2} t^2 e^{itX_t}\sigma^2)t
$$ Does the above reasoning make sense? I hope that somebody can help! :)","['stochastic-processes', 'characteristic-functions', 'probability-theory', 'stochastic-calculus', 'stochastic-differential-equations']"
2036486,parabolic subgroups and simple roots,"I'm trying to understand the link between subset of the simple roots and parabolic subgroups in the case of $\text{GL}_n$. More precisely, let $\Delta= \{\alpha_{i,i+1}\}$ be the usual set of simple roots for $\text{GL}_n$ and let $I \subset \Delta$ be a subset. What is the parabolic subgroup of $\text{GL_n}$ associated to $I$ ? I would be very interested in a reference where this is worked out in detail (along with the theory).","['algebraic-groups', 'representation-theory', 'algebraic-geometry']"
2036514,Some questions about Peano and Picard,"I have some question regarding the Peano and Picard theorems. It started with this exercise: Prove that there exists a solution near the initial value for
$y^{\prime}=(x-y)^{5/4},\,y(4)=4$ and state if the solution near that point is unique. I believe that we can't really conclude by using Peano's theorem the existence of a solution and that's because we can't find any rectangle under $y=x$ that contains the point $(4,4)$ in which $(x-y)^{5/4}$ is continuous. I know I am wrong, but can someone explain me why? The confusion started when I read at some online notes here that the problem 
$y^{\prime}=(y-x)^{1/2},\,y(a)=b$ is guaranteed to have a solution ONLY if $a>b$, it states that at $a=b$ any rectangle will ""catch"" points for which $x>y$ and thus we can't take $a\geq b$ . 
( http://web.math.rochester.edu/people/faculty/edummit/docs/calc2_5_introduction_to_differential_equations.pdf at page $4$) According to this, I shouldn't be able to prove that there exists a solution near point (4,4) since $a=b=4$. Can someone explain to me why I am wrong? So after all, is there any rectangle which contains $(4,4)$ in which the function is continuous? If so would be it like this? http://sketchtoy.com/67691139 ?
I am so confused, I am not sure if I even explained it properly :S . Thanks for reading my (probably) stupid question.",['ordinary-differential-equations']
2036538,probability of events after a number of tries,"Suppose a player is playing a game and killing a monster, and the likelihood of a monster dropping an item is given by some probability p.  The player would like to know the probability of getting $\bf{exactly}$ n of these drops in m kills. My thought process is this: If the monster has a probability of dropping an item as p, then the probability of it happening n times in m kills can be visualized by some m-dimensional vector, whose entries can be filled with n checkmarks and (m-n) X's, where the checkmarks mean that the drop has been attained on that kill.  So a 30-vector whose 1st and 30th entries are checkmarks and all other entries are X's correspond to the player receiving a drop on the 1st and 30th kills and nothing on the other kills. To describe this mathematically, I reason that the probability of any given vector configuration is given by $$(1-p)^{m-n}p^n$$  However, the checkmarks can be rearranged in any order, so the expression becomes $$\frac{(1-p)^{m-n}p^nm!}{(m-n)!}$$ I feel as though somehow this is wrong.  Hopefully I am making my thought process clear.",['probability']
2036557,Alice and Bob are flipping coins...,"Alice and Bob are playing a game. They randomly determine who starts, then they take turns flipping a number of coins (N) and adding them to a growing pile. The first one to collect their target number of tails (T) wins. When Alice's variables are equal to Bob's ($N_{A} = N_{B}$, $T_{A} = T_{B}$), the odds of her winning are obviously 50%. However, for $N_{A} = 2, T_{A} = 20, N_{B} = 1, T_{B} = 10$ Alice's chances of victory appear to be slightly lower than 50%. This is based on running a few hundred thousand simulations of the game in Python. This outcome is, unfortunately, unintuitive to me. What is the mathematical reason for it? Note: This is a specific example chosen to highlight an issue I'm having in a more general problem. In the general problem, the players each have: Odds of an attempt getting them a point (O), number of attempts they get to make on their turn (N), and total number of collected points needed to win (T). If someone could also provide an equation that predicts the probability of Alice or Bob winning, given $O_{A}, N_{A}, T_{A}, O_{B}, N_{B}$, and $T_{B}$, I would be grateful.",['probability']
2036563,"There exists more than one set of numbers $(m,n)$ so that $132m+34n=\gcd(132,34)$?","Does there exists more than one set of numbers $(m,n)$ so that $132m+34n=\gcd(132,34)$? I was comparing to, and thinking about how and why euclids algorithm solves for one set. How might one find the other sets?","['number-theory', 'combinatorics', 'discrete-mathematics']"
2036654,Closed points on a curve correspond to places on the function field,"Let $X$ be a smooth (integral) projective curve over a field $k$ and let $K$ be the function field of $X$. I'd like to prove that there is a bijective correspondence between the
  closed points of $X$ and the set of places (i.e. equivalent absolute
  values on $K$) which are trivial on $k$. Clearly for every closed point $p$ I have the local ring $\mathcal O_{X,p}$ which is a DVR, therefore I get a desired valuation on $K$, hence a metric. But what about the inverse of this map? From an absolute value of $K$ I want to get a closed point of $X$ inverting the above construction.","['algebraic-curves', 'valuation-theory', 'algebraic-number-theory', 'algebraic-geometry']"
2036660,Slope of curve of intersection with surface and plane x = 2,"Let $f(x, y) = x^{2} + y^{2}$. I want to find the slope of the curve of intersection between the surface $f(x, y) = z$ and the plane $x = 2$. I also want to find a direction vector of the tangent line at the point $(2, 0, 4)$. Is the slope just partial $y$? And i'm not really sure how to approach the second part of the problem.",['multivariable-calculus']
2036694,Show that $(1+\frac{x}{n})^n \rightarrow e^x$ uniformly on any bounded interval of the real line.,"Show that $(1+\frac{x}{n})^n \rightarrow e^x$ uniformly on any bounded interval of the real line. I am trying to argue from the definition of uniform convergence for a sequence of real-valued functions, but am struggling quite a lot. My efforts so far have concentrated on trying to find a sequences,
${a_n}$ which tends to zero, such that $$|(1+\frac{x}{n})^n -e^x |\leq a_n$$ for all $n$. But I have been unsuccessful thus far. All help is greatly appreciated.","['real-analysis', 'sequences-and-series', 'uniform-convergence']"
2036705,Understanding second derivatives,"I am having a hard time understanding how to determine the second derivative of a matrix. I have researched Hessian matrices and do not see how i would apply it to vector funciton. problem statement: compute the derivative of the following $$
f(x) =\begin{bmatrix} x_1+x_1x_2^2\\
-x_2+x_2^2+x_1^2\\
\end{bmatrix}$$ I have found $$
DF =\begin{bmatrix} 1+x_2^2&2x_1\\ 2x_1&-1+x_2\\ \end{bmatrix}
$$ I now need to compute $D^2f(x_0)(x,y)$.
I have $$
D^2f(x_0)(x,y) = \sum_{j_1,j_2=1}^n \frac{\partial^2f(x_0)}{\partial x_{j_1} \partial x_{j_2}} x_{j_1}y_{j_2}
$$ But don't quite understand it. I have also searched Hessian Matrix, however the majority of times when it is used is when there is only one equation. Could someone please walk me through the $$D^2f(x_0)(x,y)$$ equation and also explain if a Hessian matrix is applicable here. I will provide $x_0$ if needed","['derivatives', 'hessian-matrix', 'real-analysis', 'tensors', 'multivariable-calculus']"
2036755,$f_n(x) = p(x)+\frac{1}{n}$ converges uniformly to $p$ but $f_n^2$ does not converge unif. to $p^2$,"Let $p:\mathbb{R}\to\mathbb{R}$ be a polynomial of degree $\ge 1$. Show that the sequence $f_n:\mathbb{R}\to\mathbb{R}$ given by $f_n(x) = p(x)+\frac{1}{n}$ converges uniformly to $p\in\mathbb{R}$, but $f_n^2$ does not converge uniformly to $p^2$. In order to show that $p(x)+\frac{1}{n}$ converges uniformly to $p(x)$, I did: $$\left|p(x)+\frac{1}{n}-p(x)\right|<\epsilon$$ just to see that $\left|\frac{1}{n}\right|<\epsilon$ which is easy to show that converges uniformly. Is this reasoning correct? Now, for $f_n^2$, I tried $f_n^2 = p^2(x)+2p(x)\frac{1}{n}+\frac{1}{n}$ but I don't know how to manipulate it. Does somebody have an idea? I also tried to see $p^2(x)+2p(x)\frac{1}{n}+\frac{1}{n} = p(x)(p(x)+\frac{2}{n})+\frac{1}{n}$ and I can at least see that it'll converge pointwise to $p^2(x)$, but how to prove it's not uniformly?","['real-analysis', 'sequences-and-series', 'proof-verification', 'proof-writing', 'convergence-divergence']"
2036796,Finding the indicated probability using tables of the Standard Normal Distribution [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I have 3 questions that I'm trying to figure out. Lesson was on a day I was absent so I have no notes to go based off of. See below Find the indicated probability using the standard normal distribution. $P(Z < 3.21)$ $P(Z > 2.35)$ $P(1.52 < Z < 3.31)$","['statistics', 'normal-distribution']"
2036803,Does the Open Mapping Theorem generalise to arbitrary Riemann surfaces? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question If M and N are arbitrary, not necessarily connected Riemann surfaces, then is a non-constant holomorphic map between them necessarily an open map?",['complex-analysis']
2036836,How to show that cubic surface is not toric?,"I know how to show $\mathbb{P}^2$ blowing up at 0,1,2,3 points are toric, but I don't know how to show that blowing up at 4-8 points are not toric. can someone show that blowing up  $\mathbb{P}^2$ at 6 points (which is a cubic surface in  $\mathbb{P}^3$) is not toric to inspire me?","['surfaces', 'algebraic-geometry']"
