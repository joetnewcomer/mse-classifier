question_id,title,body,tags
4706137,Feynman–Kac formula: conditional expectation vs. Wiener integral,"The Feynman–Kac formula for the solution $u(t,x)$ of the one-dimensional heat equation \begin{align*}
\partial_t u &= \frac{1}{2}\Delta_x u,\\
u(0,x)       &= f(x)
\end{align*} is given by \begin{equation}
u(t,x)=\mathbb{E}^{x}[f(W_t)],\tag{1}
\end{equation} with $W$ a Brownian motion and where $\mathbb{E}^{x}[f(W_t)]$ is the expectation of $f(W_t)$ conditioned on $W_0=x$ . I've also seen this expressed as a Wiener integral \begin{equation}
u(t,x)=\int_{\mathcal{C}([0,t],\mathbb{R})}f(\gamma(t)+x)\,\mathrm{d}W(\gamma).\tag{2}
\end{equation} How can we show that $$\mathbb{E}^{x}[f(W_t)]=\int_{\mathcal{C}([0,t],\mathbb{R})}f(\gamma(t)+x)\,\mathrm{d}W(\gamma)$$ holds?","['wiener-measure', 'stochastic-processes', 'probability-theory', 'partial-differential-equations']"
4706159,Maximum likelihood estimator of Cauchy distribution,"The following exercise is from Bickel and Doksum, volume one. Let $g(x) = 1/[\pi (1+x^2)]$ , $x \in \mathbb{R}$ , be the Cauchy density, let $X_1$ and $X_2$ be i.i.d. with density $g(x-\theta)$ , $\theta \in \mathbb{R}$ . Let $x_1$ and $x_2$ be observations and set $\Delta = \frac{1}{2} (x_1 - x_2)$ . Let $\hat \theta = \arg \max L_X (\theta) $ be ""the"" MLE. Show that if $|\Delta| \leq 1$ , then the MLE exists and is unique. Give the MLE when $|\Delta| \leq 1$ . The likelihood function is $$L(\theta) = \frac{1}{\pi^2 \cdot \prod_{i = 1}^{2} (1 + (x_i - \theta)^2)  }$$ I tried taking the log-likelihood and differentiating it w.r.t $\theta$ , which resulted in $\hat \theta = \overline{X}$ . I do not understand, however, why we need $|\Delta| \leq 1$ for uniqueness of the maximum likelihood estimator, or how to establish uniqueness of the MLE.","['statistical-inference', 'statistics']"
4706193,Let $A$ and $B$ be finite sets such that $|A|+|B| = |A \cup C|$ with $C \sim B$ and $A \cap C = \emptyset$ construction of natural number set theory,"Let $A$ and $B$ be finite sets such that $$|A|+|B| = |A \cup C|$$ with $C \sim B$ and $A \cap C = \emptyset$ .
Show that for any choices of $A$ and $B$ , we can always found such $C$ .
Also, explain its relation to the axiom of natural number. Attempt: Let $A=\{a_1,a_2,a_3,\ldots,a_m \}$ and $B=\{b_1,b_2,b_3,\ldots,b_n \}$ for some positive integers $m$ and $n$ .
We have $|A|=m$ and $|B|=n$ .
I can't figure out how to find such $C$ .
Any ideas? Thanks in advanced.",['elementary-set-theory']
4706216,Recognizing a Probability Theorem,"I am reading this article here https://www.jstor.org/stable/3001633 and on page 7, the following probability distribution function is given: Theorem : If $x_1, \dots, x_k$ are independently distributed with density functions: $$f_{n_i}(x_i) = \left(\frac{n_i}{2}\right)^{\frac{n_i}{2}} \frac{x_i^{\frac{n_i}{2}-1}e^{-\frac{n_ix_i}{2}}}{\Gamma\left(\frac{n_i}{2}\right)}$$ for $0 \leq x_i < \infty$ and $R(x_1,\dots,x_k)$ is a rational function with no singularities for $0 < x_1,\dots,x_k < \infty$ , then $\text{Ave}\{R(x_1,\dots,x_k)\}$ can be expanded in an asymptotic series in $\frac{1}{n_i}$ .
In particular: $$\text{Ave}\{R(x_1,\dots,x_k)\} = R(1,\dots,1) + \sum_{i=1}^k \frac{1}{n_i} \left.\frac{\partial^2 R}{\partial x_i^2}\right|_{(1,\dots,1)} + O\left(\sum \frac{1}{n_i^2}\right)$$ My Question: It looks like in this theorem, the probability distribution $f_{n_i}(x_i)$ is a Chi-Square Distribution ( https://en.wikipedia.org/wiki/Chi-squared_distribution ) - but does anyone know any more information about this theorem? Does it have a name? I have been trying to find more information about it to learn where it comes from, why it is useful and why it is true (i.e. proof). Thanks! Note: Screenshot of the paper in case I transcribed it incorrectly :","['proof-explanation', 'calculus', 'taylor-expansion', 'sequences-and-series', 'probability']"
4706312,Let $T\colon V\to V$ over the IPS $V$ and $B$ be an orthogonal basis for $V$. Find the simplest connexion between $[T^*]_B$ and $([T]_B)^*$,"Let $T\colon V\to V$ over an Inner Product Space $V$ .
Let $B$ be an orthogonal basis for $V$ .
Find the simplest connexion between $[T^*]_B$ and $([T]_B)^*$ . So I know that if $B$ was an orthonormal basis for $V$ we would have received: $$[T^*]_B=\langle T^*{b_i},b_j\rangle=\operatorname{adj}\langle T{b_i},b_j\rangle=\operatorname{adj}([T]_B)_{ji}$$ and therefore $\,[T^*]_B=([T]_B)^*$ . I am not sure how to find this relation using $B$ as an orthogonal basis.
Do I just normalise the vectors?","['orthonormal', 'inner-products', 'orthogonality', 'matrices', 'linear-algebra']"
4706322,"How to get the derivative of $\log_4 x$ using the change of base, but without assuming we have the derivative of $\ln x$?","I can compute the derivative of $\log_4 x$ using implicit differentiation.  I can also compute it by writing it as $\log_4 x = (\ln x)/(\ln 4)$ and using the fact that the derivative of $\ln x$ is $1/x$ .  But I'm investigating why I can't seem to get it in the following approach, however bad an approach it might be. Let $y = \log_4 x = \frac{\ln x}{\ln 4}$ .  Now I raise $e$ to the equation, getting $$\exp(y) = \exp\left(\frac{\ln x}{\ln 4}\right).$$ Using implicit differentiation, I get \begin{align*}
\exp(y)y' &= \exp\left(\frac{\ln x}{\ln 4}\right) \left(\frac{\ln x}{\ln 4}\right)' = \exp\left(y\right) y'\\
\exp(y)y' - \exp(y)y' &= 0\\
(\exp(y) - \exp(y))y' &= 0
\end{align*} In other words, it leads me nowhere.  Is it possible at all do this with the conditions imposed in the question?  It seems that if the exercise asks me to use a change of base, then I must really use the derivative of $\ln x$ to solve the problem.","['calculus', 'derivatives', 'logarithms']"
4706384,Tangent space of algebraic variety over $\mathbb{C}$ and complex manifold,"Let $f:X\rightarrow Y$ be a morphism of smooth varties over $\mathbb{C}$ . Let $f^{an}:X^{an}\rightarrow Y^{an}$ be the induced morphism of complex manifolds, where $X^{an}=X(\mathbb{C})$ , $Y^{an}=Y(\mathbb{C})$ . Now suppose $x\in X(\mathbb{C})$ , which induces a morphism of zariski tangent spaces $df_x:T_{X,x}\rightarrow T_{Y,f(x)}$ (since $x$ and $f(x)$ are $\mathbb{C}-$ rational points) and a morphism of manifold tangent spaces $df^{an}_x:T_{X^{an},x}\rightarrow T_{Y^{an},f^{an}(x)}$ . My question is: what is the relation between $df_x$ and $df^{an}_x$ ? More precisely, whether the following statemnt is true: $df_x$ is an isomorphism (resp. injective, resp. surjective) $\Leftrightarrow$ $df^{an}_x$ is an isomorphism (resp. injective, resp. surjective). Furthermore, if we remove the assumption $X$ and $Y$ are smooth (and then $X^{an}$ and $Y^{an}$ are complex analytic space), whether the above statament still holds?","['complex-geometry', 'algebraic-geometry']"
4706392,Finding all sides and angles of a triangle,"So SAS, SSS, ASA, AAS and RHS are reasons for congruent triangles, that means if a triangle, for example, have side lengths of 5, 6 and 8, then the triangle is unique.
What I am trying to do is to find an expressions for other sides and angles in terms of the given sides and angles. I've solved it but some of the expressions are a bit long and ugly, so can anyone verify my workings and simplify them if possible? Any help would be appreciated :) For triangles below, greek letters are angles and english letters are sides $\alpha$ is the opposite angle of side a $\beta$ is the opposite angle of side b $\gamma$ is the opposite angle of side c SAS: given sides $a$ , $b$ and included angle $\gamma$ $$c^2=a^2+b^2-2ab\cos{(\gamma)}$$ $$\boxed{c=\sqrt{a^2+b^2-2ab\cos{(\gamma)}}}$$ $$\frac{\sin{(\alpha)}}{a}=\frac{\sin{(\gamma)}}{c}$$ $$\frac{\sin{(\alpha)}}{a}=\frac{\sin{(\gamma)}}{\sqrt{a^2+b^2-2ab\cos{(\gamma)}}}$$ $$\sin{(\alpha)}=\frac{a\sin{(\gamma)}}{\sqrt{a^2+b^2-2ab\cos{(\gamma)}}}$$ $$\boxed{\alpha=\arcsin{\left(\frac{a\sin{(\gamma)}}{\sqrt{a^2+b^2-2ab\cos{(\gamma)}}}\right)}}$$ $$\frac{\sin{(\beta)}}{b}=\frac{\sin{(\gamma)}}{c}$$ $$\frac{\sin{(\beta)}}{b}=\frac{\sin{(\gamma)}}{\sqrt{a^2+b^2-2ab\cos{(\gamma)}}}$$ $$\boxed{\beta=\arcsin{\left(\frac{b\sin{(\gamma)}}{\sqrt{a^2+b^2-2ab\cos{(\gamma)}}}\right)}}$$ SSS: given sides $a$ , $b$ and $c$ $$c^2=a^2+b^2-2ab\cos{(\gamma)}$$ $$a^2+b^2-c^2=2ab\cos{(\gamma)}$$ $$\boxed{\gamma=\arccos{\left(\frac{a^2+b^2-c^2}{2ab}\right)}}$$ $$b^2=a^2+c^2-2ac\cos{(\beta)}$$ $$a^2+c^2-b^2=2ac\cos{(\beta)}$$ $$\boxed{\beta=\arccos{\left(\frac{a^2+c^2-b^2}{2ac}\right)}}$$ $$a^2=b^2+c^2-2bc\cos{(\alpha)}$$ $$b^2+c^2-a^2=2bc\cos{(\alpha)}$$ $$\boxed{\alpha=\arccos{\left(\frac{b^2+c^2-a^2}{2bc}\right)}}$$ ASA: given included side $c$ and angles $\alpha$ , $\beta$ $$\alpha+\beta+\gamma=\pi$$ $$\boxed{\gamma=\pi-\alpha-\beta}$$ $$\frac{\sin{(\alpha)}}{a}=\frac{\sin{(\gamma)}}{c}$$ $$\frac{\sin{(\alpha)}}{a}=\frac{\sin{(\pi-\alpha-\beta)}}{c}$$ $$\boxed{a=\frac{c\sin{(\alpha)}}{\sin{(\alpha+\beta)}}}$$ $$\frac{\sin{(\beta)}}{b}=\frac{\sin{(\gamma)}}{c}$$ $$\frac{\sin{(\beta)}}{b}=\frac{\sin{(\pi-\alpha-\beta)}}{c}$$ $$\boxed{b=\frac{c\sin{(\beta)}}{\sin{(\alpha+\beta)}}}$$ AAS: given non-included side $a$ and angles $\alpha$ , $\beta$ $$\alpha+\beta+\gamma=\pi$$ $$\boxed{\gamma=\pi-\alpha-\beta}$$ $$\frac{\sin{(\beta)}}{b}=\frac{\sin{(\alpha)}}{a}$$ $$\boxed{b=\frac{a\sin{(\beta)}}{\sin{(\alpha)}}}$$ $$\frac{\sin{(\gamma)}}{c}=\frac{\sin{(\alpha)}}{a}$$ $$\boxed{c=\frac{a\sin{(\gamma)}}{\sin{(\alpha)}}}$$ RHS: given shorter side $a$ , hypotenuse $c$ and right angle $\gamma=\frac{\pi}{2}$ $$\sin{(\alpha)}=\frac{a}{c}$$ $$\boxed{\alpha=\arcsin{\left(\frac{a}{c}\right)}}$$ $$\alpha+\beta+\gamma=\pi$$ $$\arcsin{\left(\frac{a}{c}\right)}+\beta+\frac{\pi}{2}=\pi$$ $$\boxed{\beta=\arccos{\left(\frac{a}{c}\right)}}$$ $$a^2+b^2=c^2$$ $$\boxed{b=\sqrt{c^2-a^2}}$$ For ASA, AAS and RHS, it isn't really that ugly but I typed them out anyways... Edit: for $\arcsin$ , the angle could be the supplement of the result depending on the angle is acute or obtuse.","['congruences-geometry', 'trigonometry']"
4706427,"How to read the statement ""If for every subset B' of B, it holds that α ∈ Cn(B') iff β ∈ Cn(B'), then B - α = B - β""?","I'm confused specifically about the second part of the ""iff"". For the first part ""if for every subset B' of B, it holds that α ∈ Cn(B')"" I understand that it is saying that α ∈ Cn(B') must hold for any subset B' of B. But in the second part, specifically ""if β ∈ Cn(B')"", what B' is it refering to? Is it every subset B' as well or is it an arbitrary B'?","['first-order-logic', 'logic', 'discrete-mathematics']"
4706437,Principal series representation isomorphism,"The problem: Let $G = \mathrm{GL}_2(\mathbb Q_p)$ and $k$ be an algebraically closed field of characteristic $p.$ Denote by $\overline B$ the subgroup of all lower triangular matrices in $G$ and by $U$ the subgroup of all matrices of the form $\begin{bmatrix} 1 & \star \\ 0 & 1 \end{bmatrix}$ . Let $\chi_1, \chi_2 \colon \mathbb Q_p^{\times} \to k^{\times}$ be two smooth characters. Consider the smooth representation $$ \chi \colon \overline B \to k^\times,\quad \begin{bmatrix} \alpha & 0 \\ \gamma & \delta\end{bmatrix} \mapsto \chi_1(\alpha) \chi_2(\delta).$$ This induces a smooth $G$ -representation $\operatorname{Ind}_{\overline B}^G \chi.$ Show that there is a vector space isomorphism: \begin{align*}\{f \in \operatorname{Ind}_{\overline B}^G \chi \colon \operatorname{Supp} f \subseteq \overline B U\} &\longrightarrow \mathcal C_{\mathrm{cpt}}^{\infty}(\mathbb Q_p, k)\\ f & \longmapsto \left(f \mapsto f \begin{bmatrix}1 & x \\ 0 & 1\end{bmatrix}\right),\end{align*} where $\mathcal C_{\mathrm{cpt}}^{\infty}(\mathbb Q_p, k)$ is the space of all locally constant, compactly supported functions $\mathbb Q_p \to k.$ I understand that the image of any $f$ in the LHS is a locally constant function. But I cannot see how to show that the image is also compactly supported. Injectivity of the map is obvious. For surjectivity, we can do the following: Let $\phi$ be any locally constant, compactly supported, $k$ -valued map from $\mathbb Q_p.$ Define $f \colon G \to k$ as follows--
First define $f \colon U \to k$ as $f\begin{bmatrix} 1 & x \\ 0 & 1\end{bmatrix} = \phi(x)$ Note that $\overline B \cap U = \{1\}.$ Hence we may can extend it to a map $f \colon \overline B U \to k,$ $f \left(T\begin{bmatrix} 1 & x \\ 0 & 1\end{bmatrix}\right) = T\phi(x),\text{ for
all } T \in \overline B.$ Just extend by zero to get a function $f \colon G \to k.$ I need to show that $f$ is fixed by an open subgroup. Any help will be appreciated.","['number-theory', 'general-linear-group', 'representation-theory', 'matrices', 'group-theory']"
4706447,Quotient of elliptic riemann surface by $\mathbb{Z}/3$,"Consider an elliptic curve $E$ and a non-zero point $a\in E$ of order three. Translation by $a$ is an automorphism $\tau_a:E\to E, x\mapsto x+a$ of order $3$ of the Riemann surface $E$ . Could you please give me an idea how to get an equation of $E/G$ if an equation of $E$ is given?
In my case $E$ is given by $y^2 = x^4 + 10x^3 +25x^2 -100x.$ Any help would be appreciated!","['riemann-surfaces', 'elliptic-curves', 'complex-analysis', 'algebraic-geometry', 'quotient-spaces']"
4706460,"If the graph of a measurable function is dense in $[0,1]\times[0,1]$, can the pre-image of a non-measurable set be measurable?","Follow up to this question : Suppose we define function $f:[0,1]\to [0,1]$ that is measurable in the Caratheodory sense, using the Lebesgue Outer Measure, and the graph of $f$ is dense in $[0,1]\times[0,1]$ . Main Question: Can the pre-image of a non-measurable subset of $[0,1]$ (under $f$ ) be measurable in the sense of caratheodory, using the Lebesgue Outer Measure? Attempt: I'm not sure how to approach the main question. I attempted a solution by taking the proposed contrapositive of the main question: Can the image of a measurable set under $f$ be non-measurable? but this isn't the contrapositive as stated from @S.L.'s comment to the original question . Furthermore, due to my lack of formal training beyond Intro to Advanced Mathematics, I don't know the proper answer to the main question. (However, I do know non-measurable sets can't be explicitly defined and vary by their Lebesgue Outer Measure.) Even then, I'm not sure if this means the pre-image of a non-measurable set under $f$ (even for continuous, non-constant $f$ ) can never be measurable, proving the main question wrong. Final Note/Motivation: I wanted to make sure the main question in this post (specifically criteria 3.) to help satisfy the motivation of the post . In other words, I want to find a function $f:[0,1]\to[0,1]$ whose graph is dense, and somewhat but not too evenly distributed , in $[0,1]\times[0,1]$ . If the main question for this post is wrong, I would like someone to rewrite the main question in this post to satisfy the motivation.","['measure-theory', 'functions', 'definition', 'examples-counterexamples']"
4706476,"$ S = \left\lbrace\frac{m\sqrt{n}}{p} - 2\pi n^{3/2}p\,, \;n \in \mathbb{N}\,, m \in \mathbb{Z}\right\rbrace$ is an enumerable set.","Define the following set $$
 S = \bigg\lbrace\dfrac{m\sqrt{n}}{p} - 2\pi n^{3/2}p, \quad n \in \mathbb{N}, m \in \mathbb{Z}\bigg\rbrace
$$ where $p > 0$ . I would like to show that $S$ is an enumerable set. Since $S$ is determined by $m$ and $n$ . I thought of showing that the functions $$F_{1} : S_{n} \to \mathbb{N}, \ \ F_{2} : S_{m} \to \mathbb{Z}$$ are injective, where $S_{n}$ is the set where I fixed $m$ in $S$ and $S_{m}$ is the set where I fixed $n$ in $S$ . Therefore, $G = S_{n} \times S_{m} \to \mathbb{N}\times \mathbb{Z}$ such that $$
G(n,m) = (F_{1}(n),F_{2}(m))
$$ is injetive and how $\mathbb{N}\times \mathbb{Z}$ is an enumerable set, $S= S_{n} \times S_{m}$ is an enumerable set. Is there a shorter argument? Is mine correct?",['elementary-set-theory']
4706513,What does 'length' mean?,"Just came to know about Aristotle's Wheel paradox. I read and watched some explanations. While understanding the explanations, a completely new question is bothering me. It kind of shook my mathematical understanding of certain things. So here's what confusing me. There are an equal number of points between [0,1] and [0,2] but still respective lengths are different. Same amount of points covering different lengths. So what exactly 'length' is? I would love some simple intuitive explanation. Or do I have to re-read my measure theory notes :p?","['measure-theory', 'soft-question']"
4706516,Proof that the tangent space at the neutral element of a Lie group carries the structure of a Lie algebra,"I am currently dealing with Lie groups. To show that the tangent space at the neutral element of a Lie group carries the structure of a Lie algebra I tried to prove the following Lemma: Let G be a Lie group of dimension n. (i) For every tanget vector $\xi \in T_{e}G$ there exists exactly one left-translation-invariant vector field $X^{\xi} \in \Gamma^{\infty}(TG)$ with $X^{\xi}(e)=\xi$ . It is given by \begin{equation}
X^{\xi}(g) = d_{e}L_{g}(\xi)
\end{equation} where $L_{g}:G \rightarrow G$ is defined as $L_{g}(x)=gx$ . In particular, the mapping $\xi \mapsto X^{\xi}$ is linear. (ii) The Lie bracket of two left-translation-invariant vector fields is again left-translation-invariant. For left-translation-invariant vector fields we have the following definition: Let $G$ be a Lie group. A vector field $X \in \Gamma^{\infty}(TG)$ is said to be left-translation-invariant, if \begin{equation} d_{p}L_{g}X(p) = X(L_{g}(p)) \quad \text{for all }p,g \in G \end{equation} In other words: $X$ is $L_{g}$ -related to itself. I came up with the following proof: (i) To show the existence of such a vector field, it is sufficient to show that $X^{\xi}(g)=d_{e}L_{g}(\xi)$ is a left-translation-invariant vector field with the property $X^{\xi}(e)=\xi$ . It is \begin{equation} X^{\xi}(e) = d_{e}L_{e}(\xi)=\xi \end{equation} Furthermore it holds \begin{align} d_{p}L_{g}X^{\xi}(p) &= d_{p}L_{g}(d_{e}L_{p}(\xi)) \\
&= d_{e}(L_{g}\circ L_{p})(\xi) \\
&= d_{e}L_{gp}(\xi) \\
&= X^{\xi}(gp) \\ 
&= X^{\xi}(L_{g}(p)) \end{align} So $X^{\xi}$ is such a vector field. To show the uniqueness, let $Y$ be another left- translation-invariant vector field with $Y(e)=\xi$ . Consider \begin{align}
X^{\xi}(p)-Y(p) &= d_{e}L_{p}(X^{\xi}(e))-d_{e}L_{p}(Y(e)) \\
&= d_{e}L_{p}(X^{\xi}(e)-Y(e)) \\
&= d_{e}L_{p}(\xi-\xi) \\
&= d_{e}L_{p}(0) \\
&= 0
\end{align} The linearity of the map $\xi \mapsto X^{\xi}$ follows directly from the linearity of the differential: \begin{equation} X^{\lambda\xi+\eta}(g) = d_{e}L_{g}(\lambda\xi+\eta) = \lambda d_{e}L_{g}(\xi) + d_{e}L_{g}(\eta) = \lambda X^{\xi}(g)+X^{\eta}(g) \end{equation} This proves (i). (ii) follows directly from following statement on Lie brackets Let $F:M \rightarrow N$ be a smooth map between manifolds and let $X_{1}, X_{2} \in \Gamma^{\infty}(TM)$ and $Y_{1}, Y_{2} \in \Gamma^{\infty}(TN)$ be vector fields such that $X_{i}$ is F-related to $Y_{i}$ for $i=1,2$ . Then $[X_{1},X_{2}]$ is F-related to $[Y_{1},Y_{2}]$ . Although I think the proof is correct, I would be grateful if someone would look at it again.","['solution-verification', 'lie-algebras', 'lie-groups', 'differential-geometry']"
4706528,Evaluating $\lim\limits_{x\to 0}\!\left[\! \frac{1 - (\cos(2x) \cos(4x) \cos(6x) \cos(8x) \cos(10x))^3}{5 \tan^2x}\!\right]$,"Following question is given in my book: Let $f(x) = \cos(2x) \cos(4x) \cos(6x) \cos(8x) \cos(10x)$ and $M = \lim\limits_{x\to 0 } \left[\dfrac{1 - f(x)^3}{5 \tan^2x}\right]$ , where $M$ is finite. Then what is the value of $\sqrt{M - 2} + 1$ . My work: \begin{align} M &= \lim_{x\to 0}\left[\frac{1 - f(x)^3}{5 \tan^2x}\right]\\ & = \lim_{x\to 0}\left[\frac{(1 - f(x)) (1 + f(x) + f(x)^2)}{5 \tan^2(x)}\right]\\& =\frac 15 \lim_{x\to 0}\left[\frac{(1 - f(x)) (1 + f(x) + f(x)^2)}{x^2}\right]\cdot  \lim_{x\to 0} \frac{x^2}{\tan^2x} \\ & = \frac{3}{5} \lim_{x\to 0}\left[\frac{1 - f(x)}{x^2}\right]\tag{$*$}\end{align} $(*)$ $1 + f(x) + f(x)^2$ evaluates to $3$ at $x = 0$ . Maybe we can use double angle formula of cosine but I'm not quite sure how to do that in the best possible manner. I also thought of converting cosine in its exponential form, but I couldn't continue from that either.","['limits', 'calculus', 'limits-without-lhopital']"
4706531,Confusion with the mean value theorem for integration of vector-valued functions,"Let $f: \mathbb{R}^N \to \mathbb{R}^N$ be a smooth function. Then, I wonder if the following limit exists as $n \to \infty$ : \begin{equation}
\frac{n^2}{Vol[B(y,1/n)]}\int_{B(y,1/n)}[f(x) \cdot f(x)-f(y)\cdot f(y)]d^Nx
\end{equation} Here, $B(y,1/n)$ is the closed ball centere at some fixed $y \in \mathbb{R}^N$ with radius $1/n$ and $Vol[B(y,1/n)$ is its $N-$ dimensional volume. Also, $f(x) \cdot f(x)$ is the Euclidean dot product. What comes to mind is something like second order derivative of $f$ at $y$ , but it seems so complicated...I am aware that the L'Hospital rule does not apply for higher dimensions.. More concretely, what about we take $f(x)=x$ ? Could anyone please help me?","['multivariable-calculus', 'calculus', 'real-analysis']"
4706532,Reviewing a 2016 IITJEE problem,"IITJEE has been asking novel and interesting problems at ancillary level for engineering entrance in India. A shortcoming occurs rather rarely. In 2016, they asked a MCQ (Multiple choice question) with one or more than one choices correct: Let $f:(0,\infty)\to R$ be a differentiable function such that $f'(x)=2-\frac{f(x)}{x}, \forall x \in (0,\infty)$ and $$f(1)\ne 1.....(*).$$ Then (A) $~ \lim_{x\to 0^+} f'(1/x)=1$ , $\quad \text{(B)}~ \lim_{x \to 0^+} xf(1/x)=2, \quad \text{(C)} \lim_{x \to 0^+} x^2 f'(x) =0,\quad$ $\text{(D)}\quad |f(x)|\le 2~ \forall x \in (0,2)$ We solve the ODE $$f'(x)=2-\frac{f(x)}{x} \implies xf'(x)+f(x)=2x \implies \frac{d}{dx} xf(x)=2x$$ By integrating we get $$xf(x)=x^2+C \implies f(x)=x+\frac{C}{x}.....(**)$$ Where, usually $C$ determined by a given value of $f(a)$ at some $x=a$ . However, here a peculiar condition ( $*$ ) has been given. Using ( $**$ ), we find that the option (A) is correct both with and without the condition ( $*$ ) given by them. Also, (A) option is the official solution. Here, the question is whether the stated problem  is all right. Your comments are welcome. EDIT : There was a typo in option (A),this particular option has  been corrected now. You may also see here for the original source.",['ordinary-differential-equations']
4706581,Realizing a finite group as a scheme,"Suppose $G$ is a finite group. I have seen in various sources, without explanation, that we can interpret $G$ as a scheme by letting $G:=\coprod_{g\in G}\operatorname{Spec}\mathbb{Z}$ . Why and how can we make sense of $G$ in this way -- i.e. how is it compatible with the original group $G$ ? What is the group law given this interpretation? If we for example let $G=\mathbb{Z}/2\mathbb{Z}$ , then for a scheme $T$ , we have that $G(T)=\coprod_{g\in G}\operatorname{Hom}(T,\operatorname{Spec\mathbb{Z}})$ , which is a set with two elements since $\operatorname{Spec}\mathbb{Z}$ is the final object. But how can we impose a group structure that matches the original structure on $G$ ?","['group-theory', 'algebraic-geometry', 'schemes']"
4706632,"Solve a system of differential equations $\begin{cases} x'=-7x-18y-67e^{-t},x(0)=-1\\ y'=2x+5y+22e^{-t}, \; y(0)=-3 \end{cases}$","Apply the operational method to solve the Cauchy problem $$\begin{cases}
x'=-7x-18y-67e^{-t},x(0)=-1\\
y'=2x+5y+22e^{-t}, \; y(0)=-3
\end{cases}$$ My attempt: $$x(t) = \frac{a \sin(4t)+ b\cos(4t)}{e^{4t}}\overset{x\in [0,1)}{\Rightarrow }x(t) = \frac{a \sin(4t)+ b\cos(4t)}{e^{4t}} + 12$$ It is usually assumed that $x$ is twice differentiable everywhere, so on the boundaries of each of the smooth definitions we need to match the limits $x(0), x(1), x'(0), x'(1)$ $$x(t) = \left\{\begin{matrix}
\frac{A\sin(4t)+B\cos(4t)}{e^{4t}},&t<0\\
\frac{C\sin(4t)+D\cos(4t)}{e^{4t}} + 12,&0 < t\le 1\\
\frac{E\sin(4t)+F\cos(4t)}{e^{4t}},&t>1
\end{matrix}\right\}
$$ Then you need to make sure that the initial conditions are met and all boundary conditions are met. $A=2, B=-2, C=-10, D=-14$ . My solution: $$\begin{cases}
x'=-7x-18y-67e^{-t},x(0)=-1\\
y'=2x+5y+22e^{-t}, \; y(0)=-3
\end{cases} \Leftrightarrow \dot{\vec{r}}=\left[\begin{array}{cc}
-7 & -18 \\
2 & 5
\end{array}\right] \vec{r}+\left[\begin{array}{c}
-67 \\
22
\end{array}\right] e^{-t} ; \vec{r}(0)=\left[\begin{array}{l}
-1 \\
-3
\end{array}\right]$$ \begin{multline*}
\mathcal{L}[f(t)]=\int\limits\limits_0^{\infty} f(t) e^{-p t} d t=F(p) \Rightarrow \mathcal{L}\left[\frac{d f}{d t}\right]=\int\limits\limits_0^{\infty} \frac{d f}{d t} e^{-p t} d t=\\=\lim _{t \rightarrow \infty} f(t) e^{-p t}-f(0)+p \int\limits\limits_0^{\infty} f(t) e^{-p t} d t=p F(p)-f(0) 
\end{multline*} \begin{multline*}
\mathcal{L}[\vec{r}(t)]=\vec{R}(p) \Rightarrow \forall p>-1\left(p \hat{1}-\left[\begin{array}{cc}
-7 & -18 \\
2 & 5
\end{array}\right]\right) \vec{R}(p)=\left[\begin{array}{cc}
p+7 & 18 \\
-2 & p-5
\end{array}\right] \vec{R}(p)=\\=\left[\begin{array}{c}
-1 \\
-3
\end{array}\right]+\left[\begin{array}{c}
-67 \\
22
\end{array}\right] \int\limits\limits_0^{\infty} e^{-(p+1) t} d t=\left[\begin{array}{c}
-1 \\
-3
\end{array}\right]+\frac{1}{p+1}\left[\begin{array}{c}
-67 \\
22
\end{array}\right]=-\frac{1}{p+1}\left[\begin{array}{c}
p+68 \\
3 p-19
\end{array}\right] 
\end{multline*} \begin{multline*}\left|\begin{array}{cc}
p+7 & 18 \\
-2 & p-5
\end{array}\right|=(p+7)(p-5)+36=p^2+2 p+1=(p+1)^2 \Rightarrow\\\Rightarrow \forall p>-1 \exists\left[\begin{array}{cc}
p+7 & 18 \\
-2 & p-5
\end{array}\right]^{-1}=\frac{1}{(p+1)^2}\left[\begin{array}{cc}
p-5 & -18 \\
2 & p+7
\end{array}\right] \Rightarrow \vec{R}(p)=\\=-\frac{1}{p+1}\left[\begin{array}{cc}
p+7 & 18 \\
-2 & p-5
\end{array}\right]^{-1}\left[\begin{array}{c}
p+68 \\
3 p-19
\end{array}\right]=-\frac{1}{(p+1)^3}\left[\begin{array}{cc}
p-5 & -18 \\
2 & p+7
\end{array}\right]\left[\begin{array}{c}
p+68 \\
3 p-19
\end{array}\right]=\\=-\frac{1}{(p+1)^3}\left[\begin{array}{c}
p^2+9 p+2 \\
3 p^2+4 p+3
\end{array}\right]=-\frac{1}{(p+1)^3}\left[\begin{array}{c}
(p+1)^2+7(p+1)-6 \\
3(p+1)^2-2(p+1)+2
\end{array}\right]
\end{multline*} \begin{multline*}
\mathcal{F}[f(t)]=\frac{1}{\sqrt{2 \pi}} \int\limits\limits_{-\infty}^{\infty} f(t) e^{-i \omega t} d t \Rightarrow F(p)=\mathcal{L}[f(t)]=\sqrt{2 \pi} \lim _{\omega \rightarrow-i p} \mathcal{F}[f(t) \eta(t)] \Rightarrow\\\Rightarrow f(t)=\mathcal{L}^{-1}[F(p)]=\frac{1}{2 \pi i} \int\limits\limits_{\sigma-i \infty}^{\sigma+i \infty} F(p) e^{p t} d p 
\end{multline*} \begin{multline*}
\left\{z \in \mathbb{C}\left(|z-\sigma| \leq \tau ; \arg (z-\sigma) \in\left[-\frac{\pi}{2}, \frac{\pi}{2}\right]\right)\right\}=\Sigma \Rightarrow \frac{1}{2 \pi i} \oint\limits_{\partial \Sigma} F(p) e^{p t} d p=\\=\frac{1}{2 \pi i}\left(\int\limits_{\sigma-i \tau}^{\sigma+i \tau} F(p) e^{p t} d p-i \tau \int\limits_{-\pi / 2}^{\pi / 2} F\left(\sigma+\tau e^{i \varphi}\right) \exp \left(\left(\sigma+\tau e^{i \varphi}\right) t+i \varphi\right) d \varphi\right)=\sum_{s \in\left\{z \in \Sigma \mid F(p) \notin C^1(z)\right\}}\operatorname{Res}\left(F(p) e^{p t}\right)
\end{multline*} \begin{multline*}
\lim _{\tau \rightarrow \infty} \tau F\left(\sigma+\tau e^{i \varphi}\right)=0 \Rightarrow f(t)=\frac{1}{2 \pi i} \int\limits_{\sigma-i \infty}^{\sigma+i \infty} F(p) e^{p t} d p=\\=\sum_{s \in\left\{z \in \mathbb{C}\left(\operatorname{Re}(z)>\sigma ; F(p) \notin C^1(z)\right)\right\}} \sum_{p=s}\operatorname{Res}\left(F(p) e^{p t}\right)
\end{multline*} \begin{multline*}
\vec{r}(t)=-\operatorname{Res}_{p=-1}\left(\vec{R}(p) e^{p t}\right)=-\operatorname{Res}_{p=-1}\left(\frac{1}{(p+1)^3}\left[\begin{array}{c}
(p+1)^2+7(p+1)-6 \\
3(p+1)^2-2(p+1)+2
\end{array}\right] e^{p t}\right)=\\=-\frac{1}{2 \pi i} \lim _{\varepsilon \rightarrow 0} \sum_{n=0}^{\infty} \frac{t^n}{n !} \oint\limits_{|p+1|=\varepsilon} \frac{p^n}{(p+1)^3}\left[\begin{array}{c}
(p+1)^2+7(p+1)-6 \\
3(p+1)^2-2(p+1)+2
\end{array}\right] d p=\\ =-\frac{1}{2 \pi i} \lim _{\varepsilon \rightarrow 0} \sum_{n=0}^{\infty} \sum_{k=0}^n(-1)^{n-k} C_n^k \frac{t^n}{n !} \oint\limits_{|p+1|=\varepsilon}\left[\begin{array}{c}
(p+1)^{k-1}+7(p+1)^{k-2}-6(p+1)^{k-3} \\
3(p+1)^{k-1}-2(p+1)^{k-2}+2(p+1)^{k-3}
\end{array}\right] d p=\\=-\frac{1}{2 \pi} \lim _{\varepsilon \rightarrow 0} \sum_{k=0}^{\infty} \sum_{n=k}^{\infty}(-1)^{n-k} C_n^k \frac{t^n}{n !} \varepsilon^{k-2} \int\limits_0^{2 \pi}\left[\begin{array}{c}
\varepsilon^2 e^{2 i \varphi}+7 \varepsilon e^{i \varphi}-6 \\
3 \varepsilon^2 e^{2 i \varphi}-2 \varepsilon e^{i \varphi}+2
\end{array}\right] e^{i(k-2) \varphi} d \varphi=\\ =-\lim _{\varepsilon \rightarrow 0} \sum_{k=0}^{\infty} \sum_{n=k}^{\infty}(-1)^{n-k} C_n^k \frac{t^n}{n !}\left(\left[\begin{array}{l}
1 \\
3
\end{array}\right] \varepsilon^k \delta_{k 0}+\left[\begin{array}{c}
7 \\
-2
\end{array}\right] \varepsilon^{k-1} \delta_{k 1}+\left[\begin{array}{c}
-6 \\
2
\end{array}\right] \varepsilon^{k-2} \delta_{k 2}\right)=\\=-\left(\left[\begin{array}{l}
1 \\
3
\end{array}\right] \sum_{n=0}^{\infty}(-1)^n \frac{t^n}{n !}-\left[\begin{array}{c}
7 \\
-2
\end{array}\right] \sum_{n=1}^{\infty}(-1)^n \frac{t^n}{(n-1) !}+\left[\begin{array}{c}
-3 \\
1
\end{array}\right] \sum_{n=2}^{\infty}(-1)^n \frac{t^n}{(n-2) !}\right)=\\=\left[\begin{array}{c}
3 t^2-7 t-1 \\
-t^2+2 t-3
\end{array}\right] e^{-t} 
\end{multline*}","['calculus', 'ordinary-differential-equations', 'real-analysis']"
4706660,If for each point there is an iteration of $f$ which is equal to $0$ then some iteration of $f$ is identically $0$,"Hello fellow mathematicians, Consider a continuous function $f:[0,1]\rightarrow [0,1]$ such that $f(0)=0$ , and for every $x\in [0,1]$ there exists $k=k(x)>0$ such that the $k$ th iteration of $f$ at $x$ is equal to $0$ , i.e. $f^{(k)}(x)=0$ . I want to show that there exists $n>0$ such that $f^{(n)}(x)=0$ for all $x\in [0,1]$ . I defined the sets $A_k=\{x\in [0,1] \mid f^{(k)}(x)=0\}$ and noticed that they are increasing and cover $[0,1]$ but it doesn't seem to help much. Any ideas?","['functions', 'real-analysis']"
4706661,Second distributional derivative of $P.V. \frac{1}{x}$,"I computed first derivation and I get that $$\langle(\mathcal{P}\frac{1}{x})', \varphi\rangle = v.p. \int_{ \mathbb{R}} \frac{\varphi(0) - \varphi(x)}{x^2} dx$$ In order to get second derivative we use $\left<g'', \varphi \right> = \left<g, \varphi''\right> $ but I stuck there since I have just a lot of equations that gives us nothing. Any help would be great!","['analysis', 'distribution-theory', 'cauchy-principal-value', 'functions', 'derivatives']"
4706683,Stokes theorem applied to planes,"Let $\textbf{F} = (y+z,-xz,y^2)$ . Let $S$ be the surface above the $xy$ plane and bounded by $2x + z = 6$ , $y = 2$ , $y = 0$ and $x = 0$ . Calculate $$\iint_S \text{curl } \textbf{F} \cdot d\textbf{S}$$ I wanted to do this two different ways, one involving Stokes' theorem and the other just manually doing each face. However, I don't have any idea how to parameterise it for the manual case. When I tried using Stokes' theorem, I trace the boundaries $$(3,2,0) \to (0,2,6) \to (0,0,6) \to (3,0,0) \to (3,2,0)$$ counterclockwise, but that gives me $9 + 0 + 9 + 0 = 18$ which is wrong. Apparently the correct answer is $-6$ . Any help would be greatly appreciated.","['multivariable-calculus', 'multiple-integral', 'curl', 'stokes-theorem']"
4706737,Index of an explicit subgroup of $\mathrm{GL}_4(\mathbb{Z})$,"Let $H$ be the subgroup of $\mathrm{GL}_4(\mathbb{Z})$ generated by the $4!$ permutation matrices together with $$
\begin{pmatrix}
1 & 0 & 0 & 0 \\
-1 & 0 & 1 & 1 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1\end{pmatrix}
$$ What is the index of $H$ in $\mathrm{GL}_4(\mathbb{Z})$ ? (I'm actually hoping the index is $1$ .) This seems like the sort of thing that GAP or some other software might be able to do directly, but I'm not familiar with the area. My motivation is that I've found certain symmetries on objects indexed by $\mathbb{Z}_{\geq 0}^4$ and I'm probing whether or not I've ""found all of them.""","['computer-algebra-systems', 'group-theory', 'general-linear-group']"
4706843,How to integrate $\int_{-\infty}^{+\infty}\text{sech}^2(\beta t) \int_{-\infty}^{t} (t-s)^{1-q}~\text{tanh}(\beta s)\text{sech}^2(\beta s) ds~dt$,"I have an integral I need to integrate, as follows $\int_{-\infty}^{+\infty}\text{sech}^2(\beta t) \int_{-\infty}^{t} (t-s)^{1-q}~\text{tanh}(\beta s)\text{sech}^2(\beta s) ds~dt$ where, both $\beta$ and $q$ are real. $\beta>0$ and $1<q<2$ . Both Wolfram Alpha and Maple fail to calculate and return the original expression. I also tried to rewrite it as a hypergeometric form but it led to nested hypergeometric functions which made it even trickier. How do I integrate it? If it cannot be integrated, how do I derive a series form that is easy to calculation numerically. Thanks for your attention and help.","['integration', 'definite-integrals', 'calculus', 'trigonometric-integrals', 'sequences-and-series']"
4706861,"Probability of rolling 4 dice and obtaining a sum from 2 dice of 3, 8, or 11?","Problem: You roll 4 dice. What is the probability of getting 2 of the 4 dice to have a sum of 3, 8, or 11? Examples: 1 2 3 4 $\rightarrow$ counts $\rightarrow$ as 1 + 2 = 3 1 2 3 6 $\rightarrow$ counts $\rightarrow$ as 1 + 2 = 3 OR 2 + 6 = 8 1 3 4 6 $\rightarrow$ doesn't count $\rightarrow$ since you can't combine any 2 dice to get the sum of 3, 8, or 11 1 1 1 1 $\rightarrow$ doesn't count $\rightarrow$ same as above Breakdown: To get a sum of 3, you need the combination (1, 2).
To get a sum of 11, you need the combination (5, 6).
To get a sum of 8, you can have the combinations (2, 6), (3, 5), or (4, 4). My take: For the sums of 3 and 11, there is only one possible combination each. So, the problem can be simplified to ""Rolling 4 dice, what is the probability of getting at least one 1 and at least one 2"" (or at least one 5 and one 6 for 11). I used the inclusion/exclusion principle to solve it, which gives an answer of 0.233025. However, I'm stuck on calculating the probability for a sum of 8 and how to combine all three answers to get the final result. Note: I used code to get the final answer, it should be around 0.758488. But I'm still struggling to find a way to solve it using Math.","['dice', 'inclusion-exclusion', 'probability']"
4706909,How to check if the limit exists in multivariable calculus,"$$\lim_{(x,y ) \to (0,0)} ye^{\frac{−1}{\sqrt{x^2+y^2}}}$$ I have tried many ways so far and I keep getting the limit to be $0$ . So far I have set x equal to zero and then y and I got the limit to be $0$ . I tried setting $y=x$ and $y=x^2$ and still got zero. What else can I do? My idea is that when both x and y go to zero, the fraction $\frac{-1}{0.00\ldots1}$ becomes negative infinity and when I raise $e$ to negative infinity it will go to zero. And zero times zero is zero. Is this correct? If yes what about my explanation?","['limits-without-lhopital', 'continuity', 'multivariable-calculus', 'calculus', 'limits']"
4706927,Show that $ \frac{X_{n}}{n} \stackrel{\mathrm{d}}{\longrightarrow} X $ for $ n \rightarrow \infty $,"Let $ X_{n} \sim \mathrm{U}\{1, \ldots, n\} $ and $ X \sim \mathrm{U}(0,1) $ . Show that $ \frac{X_{n}}{n} \stackrel{\mathrm{d}}{\longrightarrow} X $ for $ n \rightarrow \infty $ . Attempt/Idea : To show that $ \frac{X_n}{n} $ converges in distribution to $ X $ as $ n \rightarrow \infty $ , we need to prove the convergence of their distribution functions. First, let's consider the distribution function of $ \frac{X_n}{n} $ . Let $ t $ be any point in $ (0,1) $ . The distribution function of $ \frac{X_n}{n} $ is defined as: $ F_{\frac{X_n}{n}}(t) = P\left(\frac{X_n}{n} \leq t\right) $ Since $ X_n $ is a discrete uniform random variable on $ \{1, \ldots, n\} $ , we have: $ P\left(\frac{X_n}{n} \leq t\right) = P(X_n \leq nt) $ As the values of $ X_n $ are integers, we can express the probability as the number of possible values of $ X_n $ that are less than or equal to $ nt $ divided by the total number of possible values of $ X_n $ : $ P(X_n \leq nt) = \frac{\text{{number of integers in }} \{1, \ldots, n\} \text{{ that are less than or equal to }} nt}{n} $ Since the random variable $ X_n $ is uniformly distributed, all values in $ \{1, \ldots, n\} $ are equally likely. Therefore, the number of integers in $ \{1, \ldots, n\} $ that are less than or equal to $ nt $ is equal to $ \lfloor nt \rfloor $ , where $ \lfloor \cdot \rfloor $ denotes the floor function: $ \frac{\text{{number of integers in }} \{1, \ldots, n\} \text{{ that are less than or equal to }} nt}{n} = \frac{\lfloor nt \rfloor}{n} $ Thus, the distribution function of $ \frac{X_n}{n} $ is given by: $ F_{\frac{X_n}{n}}(t) = \frac{\lfloor nt \rfloor}{n} $ Now, let's consider the distribution function of $ X $ , which is given by: $ F_X(t) = P(X \leq t) $ Since $ X $ is a continuous uniform random variable on $ (0,1) $ , the distribution function is given by: $ F_X(t) = t $ To show that $ \frac{X_n}{n} $ converges in distribution to $ X $ , we need to demonstrate the convergence of the distribution functions $ F_{\frac{X_n}{n}}(t) $ and $ F_X(t) $ for all $ t $ in $ (0,1) $ : $ \lim_{{n \to \infty}} F_{\frac{X_n}{n}}(t) = \lim_{{n \to \infty}} \frac{\lfloor nt \rfloor}{n} = \lim_{{n \to \infty}} \frac{nt - \{ nt \}}{n} = t $ Since the fractional part $ \{ nt \} $ lies between $ 0 $ and $ 1 $ , we have $ \lim_{{n \to \infty}} \frac{\{ nt \}}{n} = 0 $ . Thus, we obtain: $ \lim_{{n \to \infty}} \frac{\lfloor nt \rfloor}{n} = \lim_{{n \to \infty}} \frac{nt - \{ nt \}}{n} = t $ As $t $ is arbitrary in $ (0,1) $ , the distribution function of $ \frac{X_n}{n} $ converges to the distribution function of $ X $ . Therefore, $ \frac{X_n}{n} $ converges in distribution to $ X $ as $ n \rightarrow \infty $ . Does this argumentation make sense and is there maybe another way to show the converges in distribution?","['convergence-divergence', 'solution-verification', 'probability-theory']"
4706933,"Suppose $f(x)$ has continuous $(n+1)$-th derivative over $[a,b]$, and $f(a)=f'(a)=\cdots=f^{(n)}(a)=0$, prove an upper bound for $|f(x)|$","Problem : Suppose $f(x)$ has continuous $(n+1)$ -th derivative over $[a,b]$ , and $f(a)=f'(a)=\cdots=f^{(n)}(a)=0$ , prove that $$
\max\limits_{a\le x\le b}|f(x)|\le\frac{(b-a)^n}{n!}\int_a^b|f^{(n+1)}(x)|\mathrm{d}x
$$ My attempt : Clearly this problem has something to do with Taylor expansion. We take the Taylor expansion of $f(x)$ at $x=a$ : $$
f(x)=f(a)+f'(a)(x-a)+\frac{f''(a)}{2!}(x-a)^2+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n+\frac{f^{(n+1)}(\xi)}{(n+1)!}(x-a)^{n+1}=\frac{f^{(n+1)}(\xi)}{(n+1)!}(x-a)^{n+1}
$$ where $\xi\in(a,x)$ . Also, since $(b-a)^n$ appears in the formula, we consider $$
f(b)=\frac{f^{(n+1)}(\xi_b)}{(n+1)!}(b-a)^{n+1}
$$ where $\xi_b\in(a,b)$ . But I don't know how to deal with $\max\limits_{a\le x\le b}|f(x)|$ . I can't think of a formula containing $\max |f(x)|$ . Can you help me?","['calculus', 'derivatives', 'taylor-expansion']"
4706963,Find the max/min value of $x^2+y^2$ subject to $3x^2+5xy+3y^2=1$,Find the minimum and maximum value of $x^2+y^2$ subject to $3x^2+5xy+3y^2=1$ . That is a precalculus problem. So we are not allowed to use Lagrange multipliers. Here is my approach. $$3x^2+5xy+(3y^2-1)=0$$ Using quadratic formula $$x=\frac {-5y\pm \sqrt {25y^2-12(3y^2-1)}}{6}$$ So $$x=\frac {-5y\pm\sqrt {12-11y^2}}{6}$$ I reduced the number of variables now we have an univariate function. $$x^2+y^2=y^2+\frac {\big(5y\mp\sqrt {12-11y^2}\big)^2}{36}$$ At least I know that $12\ge 11y^2$ or $y^2\le\frac {12}{11}$ . How can I continue from here?,"['maxima-minima', 'algebra-precalculus', 'polynomials', 'inequality']"
4707012,A left adjoint for the regular representation functor,"Consider the following category: objects are triples $(G,A,\alpha)$ where $G$ is a group, $\alpha : G\times A\to A$ is a left action of $G$ on a set $A$ ; morphisms $(G,A,\alpha)\to (H,B,\beta)$ are pairs $u : G\to H$ (an homomorphism of groups) and $f : A\to B$ (a function) such that $f(\alpha(g,a))=\beta(ug,fa)$ . Composition is $(u,f)(v,f')=(uv,ff')$ . Call this category $Grp\ltimes Set$ ; a slick way to define it is the following: consider the (pseudo)functor $a : Grp \to Cat$ sending $G$ to the category $Set^G$ of left $G$ -sets. Perform the Grothendieck construction on $a$ , you get a (cloven) fibration $\begin{smallmatrix}Grp\ltimes Set\\\\ \downarrow\\\\ Grp\end{smallmatrix}$ projecting on the first component, of which $Grp\ltimes Set$ is the total category. Now, consider the functor $r : Grp \to Grp\ltimes Set$ defined sending $G$ to $(G,G,reg)$ , where $reg$ is the left regular representation of $G$ , i.e. $a_g(h):=gh$ . (It is easy to see that this is a functor.) Does $r$ have a left adjoint? A bit of context for you to understand what is my motivation in this question: consider, instead, a slightly modified version of the above construction, where actions are by group homomorphisms ; then the functor $c : G\mapsto (G,G,conj)$ , where $conj$ is the conjugation action, does have a left adjoint: the typical object $(G,H,\psi :G\times H\to H)$ goes to the semidirect product $G\ltimes_\psi H$ .","['group-theory', 'category-theory']"
4707016,Prove that $\sum_{i=1}^{n} (x_i-\overline{x}_n)^4 \leq \sum_{i=1}^{n} x_i^4$,"I'm trying to prove the following inequality: $\sum_{i=1}^{n} (x_i-\overline{x}_n)^4 \leq \sum_{i=1}^{n} x_i^4$ where $\overline{x}_n=\frac{1}{n}\sum_{i=1}^{n}x_i$ . This is my attempt: we can easily show that $\sum_{i=1}^{n} (x_i-\overline{x}_n)^2 \leq \sum_{i=1}^{n} x_i^2$ , then $\sum_{i=1}^{n} (x_i-\overline{x}_n)^4 \leq \bigg[\sum_{i=1}^{n}(x_i-\overline{x}_n)^2\bigg]^2\leq n^2 \bigg[\frac{1}{n}\sum_{i=1}^{n}x_i^2\bigg]^2$ Then, by using Jensen inequality, we find that $\sum_{i=1}^{n} (x_i-\overline{x}_n)^4 \leq n \sum_{i=1}^{n}x_i^4$ . The problem is that I can't find a way to get rid of the $n$ factor.
Any suggestion is welcome.","['inequality', 'summation', 'real-analysis']"
4707017,Covering number/Metric Entropy of the unit ball with respect to Mahalanobis distance,"Let $B$ denote the unit ball on $\mathbb{R}^d$ and $N(\epsilon, B, d)$ be the cardinality of the smallest $\epsilon$ -cover of $B$ . An epsilon cover is a set $T \subset B$ such that for any $x \in B$ , there is a $t \in T$ with $d(t,x) \le \epsilon$ . See for example here . $N$ is referred to as the covering number, and $\log N$ is the Metric entropy. Consider the following result: let $\|\cdot\|$ be a norm on $\mathbb{R}^d$ then $$
\frac{1}{\epsilon^d} \le N(\epsilon, B, \|\cdot\|) \le \left (1+\frac{2}{\epsilon} \right)^d.
$$ I would like to know if there are bounds on the covering numbers that are dimension free when we choose the metric to be the Mahalanobis distance $d_S(x,y) = \|S^{-1/2}(x-y)\|_2$ for some positive definite covariance matrix $S$ . Are there results along the lines of: $$
\frac{1}{\epsilon^{f(S)}} \le N(\epsilon, B, d_S) \le \left (1+\frac{2}{\epsilon} \right)^{f(S)}.
$$ where $f(S)$ is some quantity depending on $S$ ? An example I have in mind is when $S$ is diagonal with quickly decaying diagonal elements, e.g. $S_{ii} = i^{-2}$ .","['statistics', 'geometry', 'analysis', 'real-analysis', 'combinatorics']"
4707026,"Translating ""There are two different students in your class who between them have sent an e-mail message to or telephoned everyone else in the class""","Let $M(x,y)$ be “ $x$ has sent $y$ an e-mail message” and $T(x,y)$ be “ $x$ has telephoned $y$ ”, where the domain consists of all students in your class. Assume that all e-mail messages that were sent are received, which is not the way things often work. Symbolise this statement in first-order logic: There are two different students in your class who between them have sent an e-mail message to or telephoned everyone else in the class. I'm not sure whether my answer is correct; if not, please tell me the reasons: $$∃x∃y(x≠y ∧ ∀z(∀s(M(z,s)∨T(z,s)) ↔ (z = x ∨ z = y))).$$","['quantifiers', 'predicate-logic', 'discrete-mathematics', 'logic-translation']"
4707030,Combinatorics graphs for $2k+1$ representatives from $k $ different countries.,"I'm having trouble with the following question : Representatives from $1+2k$ countries come to an international conference, $k$ representatives from each country.
Is it possible to seat the $k(2k+1)$ representatives around a round table so that each pair of countries has
Representatives sitting side by side?"" At first I thought of making a graph with $2k+1$ vertices, every edge will represent two representatives from $2$ different countries. Then prove that an Eulerian cycle exists. I'm not sure if that's the right way to approach this question, I would appreciate advices for this problem.","['graph-theory', 'combinatorics', 'discrete-mathematics', 'eulerian-path']"
4707076,Numerical computation of Laurent coefficients for rational functions,"In terms of a project I am trying to implement the Carathéodory-Fejér algorithm, if interested see [1] or [2] . However, in one of the steps I need to compute the Laurent coefficients of a rational function $f$ , which does only has single poly, on the unit circle. The usual formula $$c_k=\frac {1}{2\pi i} \int_\Gamma \frac{f(z)}{z^{k+1}} dz=\frac {1}{2\pi} \int_0^{2\pi} f(e^{i \varphi})e^{-ik\varphi}d\varphi,$$ is due to oscillation not well-suited for numerical integration. Does any one have some ideas, what I could try in order to determine those coefficients for an arbitrary rational function, with just single pols (no pols on the unit circle itself)?","['complex-analysis', 'numerical-calculus', 'numerical-methods', 'complex-integration']"
4707078,direct image of lisse sheaves,"I am reading the book Weil Conjectures, perverse sheaves and l'adic Fourier transform by Kiehl and Weissauer. In I.6, this book claims that for a smooth affine curve $U_0$ over finite field $\mathbf{F}_q$ and a lisse sheaf $F$ on $U_0$ , by Noether normalization, we can find a finite morphism $f:U_0 \rightarrow \mathbf{A}_{\mathbf{F}_q}^1$ . Then the direct image of $F$ from $U_0$ onto the affine curve is lisse on an open nonempty subset of the affine curve. I'm very confused about this statement. Can anyone explain the reason?","['etale-cohomology', 'algebraic-geometry', 'sheaf-theory']"
4707085,Gronwall inequality for a $2$-dimensional system of linear differential inequalities,"Let $$z(t)=\begin{pmatrix}x(t) \\ y(t)\end{pmatrix}~,~ A=\begin{pmatrix}0 & -\beta \\ \alpha & -(\alpha + \beta)\end{pmatrix}$$ satisfies the following system of linear differential inequalities $$z'(t) \leq A\,z(t)$$ where $\alpha, \beta > 0$ are fixed constants, and $x(t), y(t) \in  [0,\infty)$ , I am wondering if there is a vectorized version of Gronwall lemma which allows me to deduce that $$z(t)\leq \mathrm{e}^{At}\,z(0).$$ It seems hard to find a literature which addresses precisely my question. Any help (including referring to precise literatures) will be greatly appreciated! Side note: by writing $u \leq v$ for $u,v \in \mathbb{R}^2_+$ I mean that each component of $u$ is less than or equal to the corresponding component of $v$ . Also (and unfortunately), the off-diagonal entries of $A$ are not all non-negative, which means that the discussion mentioned in this post may not be applicable...","['inequality', 'ordinary-differential-equations']"
4707102,Solve this trigonometry problem without using trigonometric functions.,"Refer to the figure, solve for x where $AB=CD$ , $\angle{BAD}=40^\circ$ , $\angle{ABC}=30^\circ$ and $ACD$ is a straight line. I solved this problem using harder method than it should be (note that is problem is from year 8), but I did not find any easier way to solve this problem using skills that is learnt in year 8. Here are my attempt of solving the problem: Let $AB=CD=k$ and $BC=n$ (just to make the equations look cleaner) $$40^\circ+30^\circ+\angle{BCA}=180^\circ\textrm{$(\angle$ sum of $\triangle)$}$$ $$\angle{BCA}=110^\circ$$ $$110^\circ+\angle{BCD}=180^\circ\textrm{$($adj. $\angle$s on st. lines$)$}$$ $$\angle{BCD}=70^\circ$$ $$\frac{\sin{(110^\circ)}}{k}=\frac{\sin{(40^\circ)}}{n}\textrm{$($law of sines$)$}$$ $$n=\frac{\sin{(40^\circ)}k}{\sin{(110^\circ)}}$$ $$\frac{\sin{(110^\circ-x)}}{k}=\frac{\sin{(x)}}{n}\textrm{$($law of sines$)$}$$ $$\frac{\sin{(110^\circ-x)}}{k}=\frac{\sin{(x)\sin{(110^\circ)}}}{\sin{(40^\circ)}k}$$ $$\sin{(110^\circ-x)}=\frac{\sin{(x)\sin{(110^\circ)}}}{\sin{(40^\circ)}}$$ $$\sin{(40^\circ)}(\sin{(80^\circ)}\cos{(x)}-\sin{(x)}\cos{(80^\circ)})=\sin{(x)}\sin{(110^\circ)}\textrm{$(\angle$ difference formula$)$}$$ $$\sin{(40^\circ)}\sin{(110^\circ)}\cos{(x)}-\sin{(40^\circ)}\sin{(x)}\cos{(110^\circ)}-\sin{(x)}\sin{(110^\circ)}=0$$ $$\sin{(40^\circ)}\sin{(110^\circ)}\cos{(x)}=\sin{(x)}(\sin{(40^\circ)}\cos{(110^\circ)}+\sin{(110^\circ)})$$ $$\tan{(x)}=\frac{\sin\left(40^\circ\right)\sin\left(110^\circ\right)}{\sin\left(40^\circ\right)\cos\left(110^\circ\right)+\sin\left(110^\circ\right)}$$ $$\boxed{x=\arctan\left(\frac{\sin\left(40^\circ\right)\sin\left(110^\circ\right)}{\sin\left(40^\circ\right)\cos\left(110^\circ\right)+\sin\left(110^\circ\right)}\right)}$$ And according to wolfram alpha, $x$ also equals $40^\circ$ . Questions: How am I supposed to simplify $\arctan\left(\frac{\sin\left(40^\circ\right)\sin\left(110^\circ\right)}{\sin\left(40^\circ\right)\cos\left(110^\circ\right)+\sin\left(110^\circ\right)}\right)$ into $40^\circ$ ? This method is clearly too hard for year 8 students. Is there an easier solution, which preferably does not include trigonometric ratios? I couldn't find it.","['triangles', 'trigonometry', 'angle', 'geometry']"
4707125,Evaluate the limit $\lim_{n\to \infty }\sum_{i=1}^n \frac{1}{n} \cdot \lfloor \sqrt {\frac{4i}{n}} \rfloor$,"I solved the problem using the Riemann integral. However, my answer did not match with the result given in the book. My answer was $\frac{3}{4}$ and the answer given in the book was just 3. Help me understand where I went wrong. My solution $$\lim_{n\to\infty} \sum_{i=1}^n \frac{1}{n}\cdot \lfloor \sqrt{\frac{4i}{n}}\rfloor 
=\lim_{n\to\infty} \sum_{i=1}^n \frac{1}{n} \cdot \lfloor 2\sqrt{\frac{i}{n}}\rfloor=$$ $$=\lim_{n\to\infty}\left(\frac{1}{n}\cdot \lfloor2\sqrt{\frac{1}{n}}\rfloor+\frac{1}{n}\cdot \lfloor2\sqrt{\frac{2}{n}}\rfloor+\ldots +\frac{1}{n}\cdot \lfloor2\sqrt{\frac{n}{n}}\rfloor\right)$$ Clearly, the given expression is a Riemann sum of the function $\lfloor2\sqrt{x}\rfloor$ on the interval $[0,1]$ . $$\lim_{n\to\infty} \sum_{i=1}^n \frac{1}{n}\cdot \lfloor \sqrt{\frac{4i}{n}}\rfloor =$$ $$=\int_0^1 \lfloor2\sqrt{x}\rfloor dx=\int_0^{\frac14} \lfloor2\sqrt{x}\rfloor dx+\int_{\frac14}^1 \lfloor2\sqrt{x}\rfloor dx=0+1\cdot\left(1-\frac14\right)=\frac34$$","['ceiling-and-floor-functions', 'riemann-sum', 'calculus', 'limits', 'riemann-integration']"
4707128,Does this explicit and bijective measurable function exist and satisfy my motivation?,"This is a follow up to this question . The only difference is $f$ is bijective and the range of $f$ has to be $[0,1]$ . Main Question: Using the Lebesgue outer measure, does there exist an explicit and bijective function $f:[0,1]\to[0,1]$ such that: the function $f$ is measurable in the sense of Caratheodory the graph of $f$ is dense in $[0,1]\times[0,1]$ the range of $f$ is $[0,1]$ the collection of all subsets of $[0,1]$ (with pre-images under $f$ that are measurable in the sense of Caratheodory) is a non-perfect dense set in the collection of all subsets of $[0,1]$ , where we define a topology with this answer : Let ${\mathbb P}[0,1]$ be the collection of all subsets of $[0,1]$ modulo the equivalence relation $\sim$ defined by $E \sim F \Leftrightarrow {\lambda^{*}(E \Delta F)} = 0,$ where $\lambda^{*}$ is Lebesgue outer measure and $\Delta$ is the symmetric difference operation on sets. The set ${\mathbb P}[0,1]$ can be made into a complete metric space by defining the distance function $d,$ where $d(E,F) = {\lambda^{*} (E \Delta F)}.$ the graph of $f$ is non-uniform (i.e. without complete spacial randomness ) in $[0,1]\times[0,1]$ using the Lebesgue measure, the expected value of $f$ is computable Simplified Version of the Main Question: In the main question , a non-perfect dense set in the collection of all subsets of the range of $f$ is “topologically large” in the collection of all subsets of the range of $f$ , where the main question translates to the following: Does there exist a explicit, bijective and measurable function $f:[0,1]\to[0,1]$ such that: the graph of $f$ is
dense in $[0,1]\times[0,1]$ the range of $f$ is $[0,1]$ the pre-image of most subsets of the range of $f$ under $f$ are measurable in the sense of
Caratheodory the graph of $f$ is non-uniform (i.e. without complete spacial randomness ) in $[0,1]\times[0,1]$ using the uniform probability measure , the expected value of $f$ is computable? Motivation: I wanted to define an explicit and bijective function $f:[0,1]\to[0,1]$ where the graph of $f$ is somewhat but not too evenly distributed (i.e. with complete spacial randomness ) in $[0,1]\times[0,1]$ , such that using the uniform probability measure , we want a subset $X\subseteq[0,1]$ , where (when function $f:[0,1]\to[0,1]$ is restricted to $f:X\to[0,1]$ ) the expected value of $f$ is undefined so we can find an unique extension of the expected value of $f$ which gives a finite value instead . Question on motivation: If the function from the main question exists, does it satisfy the motivation? Attempt to Solve Both Questions: I can't prove an explicit example exists but here is my attempt from this and this question ( note in both links, neither answers gave what I wanted, e.g. in this answer , the function wasn't very explicit and in this answer , the function was extremely “non-uniform”): In case one wants to read here, here's the attempt: Suppose the base- $3$ expansion of real numbers, in interval $[0,1]$ , have infinite decimals that approach $x\in[0,1]$ from the right
side so when $0\le x_1,x_2\le 1$ (and $x_1=x_2$ ) we get $f(x_1)=f(x_2)$ . Furthermore, for $\mathbb{N}\cup\left\{0\right\}=\mathbb{N}_{0}$ , if $r\in\mathbb{N}_{0}$ and $\text{digit}_{3}:\mathbb{R}\times
 \mathbb{Z}\to\left\{0,1,2\right\}$ is a function where $\text{digit}_{3}(x,r)$ takes the digit in the $3^{r}$ -th decimal fraction
of the base- $3$ expansion of $x$ (e.g. $\text{digit}_{3}(1.789,2)=\text{digit}_{3}({1.210022{\cdot\cdot\cdot}}_{3},2)=1$ ), then $\left\{{g_r}^{\prime}\right\}_{r\in\mathbb{N}_{0}}$ is a
sequence of functions (and $\left[\cdot\right]$ is the nearest integer
function) such that ${g_r}^{\prime}:\mathbb{N}_0\to\mathbb{N}_0$ is
defined to be: \begin{equation}
  g_r^{\prime}(x)=\left[\frac{10}{3}\sin(rx)+\frac{10}{3}\right]
 \end{equation} then for some function $k:\mathbb{N}_{0}\to\mathbb{N}_{0}$ , where $k$ is strictly increasing and $k(0)$ is a positive
number, we want the
the intermediate function (before $f$ ) or $f_{1}:[0,1]\to[0,10]$ to satisfy the main question (such that, in criteria 3. the range of $f_1$ is $[0,10]$ ). \begin{alignat}{2} & f_{1}(x)  =
 &&\left|\left(\sum\limits_{r=0}^{\infty}
g_{r+1}^{\prime}\!\left(\sum\limits_{p=r}^{r+k(r)}\text{digit}_{3}(x,p)\right)\!\!\bigg/3^{r}\right)-10\right|=
 \label{eq:025} \\ & &&
\left|\left(\left(\sum\limits_{r=0}^{\infty}\left[\frac{10}{3}\sin\left(\left(r+1\right)\left(\sum\limits_{p=r}^{r+k(r)}\text{digit}_{3}(x,p)\right)\right)+\frac{10}{3}\right]\right)\!\!\bigg
 /3^{r}\right)-10\right| \nonumber \end{alignat} (One example of $k(r)$ that may satisfy main question, when with criteria 3. the range of $f_1$ is $[0,10]$ instead of $[0,1]$ , is $k(r)=10r+20$ ) What we’re doing with $f_1$ is we are converting every digit of the base- $3$ expansion of $x$ into a pseudo-random number that is non-equally likely to be an integer,
including and in-between, $0$ and $20/3$ . Furthermore, we attempt to
make the function dense in $[0,1]\times[0,10]$ by adding the $3^{r}$ -th decimal fraction with the next $3^k$ -th decimal fractions; however, we also want to control the end-points of $[0,10]$ , such that $f_1$ is dense in $\left[0,1\right]\times\left[0,1\right]$ by manipulating $f_1$ to get: \begin{alignat}{2} & f(x)  = && 1-\frac{1}{10}f_1(x)\label{eq:109}\\
 & && 
 1-\left(\frac{1}{10}\right)\left|\left(\left(\sum\limits_{r=0}^{\infty}\left[\frac{10}{3}\sin\left(\left(r+1\right)\left(\sum\limits_{p=r}^{r+k(r)}\text{digit}_{3}(x,p)\right)\right)+\frac{10}{3}\right]\right)\!\!\bigg/3^{r}\right)-10\right|
 \nonumber \end{alignat} (e.g. where $k(r)=10r+20$ ). You can use programming to visualize $f$ though I
don't know if you can graph the entire function. (The programming I
used is mathematica.) Clear[""Global`*""]
k[r_] := k[r] = 
  20 (* You can adjust k[r]; however, mathematica is unable to graph \
f when k[r] is steepy increasing e.g. for this function, k[r] must be \
less than 25 for the code to show a graph. Instead, it should be k[r]=10r+20 *)

g1[xr_, r_] := 
 g1[xr, r] = 
  Round[(10/3) Sin[r xr] + (10/
      3)] (*Converts the (3^r)th decimal fraction,in the base 3 \
expansion of the x-values in[x1,x2] (defined as xr or x_r not x*r) \
into a psuedo-random number that's non-equally likely to spit a \
number between,and including, 0 and 20/3 *)

f[x_] := f[x] = 
  N[1 - ((1)/(10)) RealAbs[
      Sum[g1[Sum[
           RealDigits[x, 3, k[r], -r][[1]][[z]], {z, r + 1, k[r]}], 
          r + 1]/(3^r), {r, 0, 8}] - 
       10]] (*Defines function f,I assume the larger k[r]'s values, the more \
the function appears dense in [0,1]x[0,1]*)

p = .00005 (*Incremement between the x-values in the points of the \
graph below*)

ListPlot[Table[{x, f[x]}, {x, p, 1, 
   p}]] (*Graphs countable points of the functions but is not a \
complete accurate graph. There are uncountably many points that need \
to be included.*) Unfortunately, I only studied up to intro to advanced mathematics. (Without a deep undestanding of math I'm unable to prove if the function gives what I'm looking for.) Is there a simpler example? Observation From This Post : From this , it appears $f$ might satisfy criteria 4. of the main question if the pre-image of every subset of $[0,1]$ under $f$ has zero measure. (Note the subset of a measure zero set is measurable.) Since the graph of $f$ must be dense in $[0,1]×[0,1]$ , the points in the graph of $f$ should be ""spread out enough"" in $[0,1]×[0,1]$ , such that every pre-image of every subset of $[0,1]$ under $f$ has zero measure. (I don't know if we can explicitly define a simple example that allows this.)","['measure-theory', 'examples-counterexamples', 'real-analysis', 'definition', 'functions']"
4707155,Prove : $\int_{{π}/{4}}^{{π}/{2}} e^{\cos x + \cos^2{x}}\mathrm dx>\sqrt2$,"Exactly as the title says , we need to prove : $$\int_\frac{π}{4} ^ \frac{π}{2} e^{\cos x + \cos^2{x}}\mathrm dx>\sqrt2$$ My unsuccessful approach: I tried by searching for a function $f$ such that : $$e^{\cos x + \cos^2{x}}>f$$ and $$\int_\frac{π}{4} ^ \frac{π}{2}f\mathrm dx = \sqrt2$$ Since the limits are in terms of $π$ while the integral should be equal to $\sqrt 2$ , the indefinite integral should be of the form having denominator equal to $π$ . Unfortunately, I have never encountered such type of functions or integrals. For the same reasons above, I also cannot think of functions to apply sandwich theorem. I am looking for some elementary methods but all level of answers are welcome. Thanks !","['calculus', 'definite-integrals', 'inequality']"
4707205,Density estimation with Orthogonal series,"I have found this problem from the article http://www.yaroslavvb.com/papers/watson-density.pdf . In this article the probability density function has considered as \begin{equation}
  f(x) = \sum_{m=0}^{\infty}\alpha_{m}\phi_{m}(x),
\end{equation} and the estimator is \begin{equation}
 f^{\ast}_{n}(x) = \sum_{m=0}^{\infty} \lambda_{m}a_{m}\phi_{m}(x),
\end{equation} where \begin{equation}
   a_{m} = \frac{1}{n}\sum_{k=1}^{n}\phi_{m}(x_k).
\end{equation} Here $\{\phi_{m}(x)\}$ is an orthonormal basis. According to the article \begin{equation}
  E \int (f(x)-f^{\ast}(x))^2dx= \sum_{m=0}^{\infty}E(\alpha_{m}-\lambda_{m}a_{m})^2=\sum_{m=0}^{\infty}\{\alpha_{m}^2(1-\lambda_{m})^2+\frac{1}{n}\lambda^2_{m}\text{var}(\phi_{m}(x))\}.
\end{equation} I have been trying to prove this. My approach is \begin{equation*}
\begin{split}
 E\int (f(x)-f^{\ast}(x))^2dx & = \int E(f(x)-f^{\ast}(x))^2dx\; [by Fubini]\\
& = \int E\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})\phi_{m}(x)\right]^2dx\\
& = \int E\left(\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})^2\phi_{m}(x)^2\right]+2 \sum_{m=0}^{\infty}\sum_{j=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})(\alpha_{j}-\lambda_{j}a_{j})\phi_{m}(x)\phi_{j}(x)\right)dx\\
& = E\left(\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})^2\int\phi_{m}(x)^2dx\right]+2 \sum_{m=0}^{\infty}\sum_{j=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})(\alpha_{j}-\lambda_{j}a_{j})\int\phi_{m}(x)\phi_{j}(x)dx\right)\\
& = \sum_{m=0}^{\infty}E(\alpha_{m}-\lambda_{m}a_{m})^2.
\end{split}
\end{equation*} Note that $\alpha_{m}=E\phi_{m}(x)$ .
Now, \begin{equation}
\begin{split}
E(\alpha_m-\lambda_m a_m)^2 & = E(\alpha_m-\alpha_m \lambda_m+\alpha_m \lambda_m+\lambda_m a_m)^2\\
& = E[\alpha_{m}(1-\lambda_m)+\lambda_m(\alpha_m-a_m)]^2\\
& = E[\alpha_{m}^2(1-\lambda_m)^2+2\alpha_{m}(1-\lambda_m)\lambda_m(\alpha_m-a_m)+\lambda_m^2(\alpha_m-a_m)^2]\\
& = \alpha_{m}^2(1-\lambda_m)^2+ 2\alpha_{m}(1-\lambda_m)\lambda_mE(\alpha_m-a_m)+\lambda_m^2E(\alpha_m-a_m)^2.
\end{split}
\end{equation} Since \begin{equation}
\begin{split}
 E(\alpha_{m}-a_{m}) & = \alpha_{m}-Ea_{m}\\
& = \alpha_{m}-\frac{1}{n}\sum_{k=1}^{n}E\phi_{m}(x_k)\\
& = \alpha_{m}-\frac{1}{n}\sum_{k=1}^{n}\alpha_{m}\\
& = \alpha_{m}-\alpha_{m}=0.
\end{split}
\end{equation} Therefore, \begin{equation}
 \sum_{m=1}^{\infty} E(\alpha_{m}-\lambda_{m}a_{m})^2=\sum_{m=1}^{\infty}\alpha_{m}^2(1-\lambda_{m})^2+\lambda_{m}^2E(\alpha_{m}-a_{m})^2.
\end{equation} I was wondering is there any way to prove \begin{equation}
  E(\alpha_{m}-a_{m})^2=\frac{1}{n}\text{var}(\phi_{m}(x)).
\end{equation}","['statistics', 'eigenvalues-eigenvectors', 'mean-square-error', 'fourier-series', 'density-function']"
4707220,Is it necessary to use critical points in this exercise?,"I have a question regarding the resolution of the following exercise: Let be a quadratic form $f:\mathbb{R}^n \to \mathbb{R}$ , $f(x) = \langle A \cdot x, x \rangle$ , where $A$ is a symmetric matrix. Show that if $u \in \mathbb{R}^n$ is a critical point of restriction $f \vert_{S^{n-1}}$ then $Au = \lambda u$ , where $\lambda = f(u)$ . Comments: I thought of the following solution:
Let $u \in S^{n-1}$ . Then $f(u) = \langle Au, u \rangle$ .
On the other hand, $f(u) = f(u)\langle u, u \rangle = \langle f(u)u, u\rangle$ . Thus, $Au = f(u)u$ . However, I did not use the hypothesis, but I find where the error is. Thank you for your help.","['multivariable-calculus', 'calculus', 'analysis', 'real-analysis']"
4707315,Is there a simple mathematical way in which the maximum predator and prey populations of the Lotka-Volterra model can be calculated?,"I'm currently working on a simulation that applies Euler's method to graph the Lotka-Volterra equations on a scalable graph grid -- unfortunately, due to the way in which I constructed my simulation, it is near impossible for me to dynamically adjust the graph axes. Is there a mathematical way in which these maxima can be calculated -- preferably a formula? A formula + explanation would be really helpful! The form of the Lotka-Volterra equations that I am using in my program is: $$\frac{dx}{dt} = \alpha x - \beta x y,$$ $$\frac{dy}{dt} = \delta xy - \gamma y,$$ where x represents the prey population density and y represents the predator population density (same as the one here ). Thanks!","['graphing-functions', 'ordinary-differential-equations']"
4707319,we throw $n$ uniform dices each with $m$ diffferent faces,"I'm having a hard time solving the following problem : We have $n$ uniform dices, each with $m$ different faces.
We throw the dices simultaneously and see what comes out. Then we order the results in increasing order to get a number read in base $m$ . Call this $r$ . What is the average of $r$ ? I thought of representing $r$ as a random variable and calculate the mean, but I'm not sure how. The problem is that some faces may appear more than one time, and that's what makes the problem hard. There's an intuitive trick that I failed to see here.","['dice', 'probability']"
4707354,Prove that $\int_0^\infty \frac{\sin^2{(x\sin x)}}{x^2}dx=1$.,"Let $I=\int_0^\infty \frac{\sin^2{(x\sin x)}}{x^2}dx$ . Prove that $I=1$ . Desmos shows that $\sum\limits_{k=0}^{100}\int_{k\pi}^{(k+1)\pi}\frac{\sin^2(x\sin{x})}{x^2}dx=0.9984\dots$ and $\sum\limits_{k=0}^{10000}\int_{k\pi}^{(k+1)\pi}\frac{\sin^2(x\sin{x})}{x^2}dx=0.999987\dots$ . So I think it's a safe bet that $I=1$ . Context I recently learned that $\int_0^\infty \frac{\sin{(x\sin{x})}}{x^2}dx=\pi/2$ . On a whim, I squared the numerator, and then to my surprise this new integral $\int_0^\infty \frac{\sin^2{(x\sin x)}}{x^2}dx$ seems to also have a closed form - in fact $1$ , the simplest closed form of all. My attempt There are lots of ways to show that $\int_0^\infty\frac{\sin^2 x}{x^2} dx=\pi/2$ . I've been trying to apply these to $I$ . For example I tried to use integration by parts , but the fact that $I$ has sine within sine makes things difficult.","['integration', 'improper-integrals', 'definite-integrals', 'analysis', 'calculus']"
4707366,A different solution for checking convergence of $a_n=\frac{1}{n^2}+\frac{1}{(n+1)^2}+\dots+\frac{1}{(2n)^2}$,"Analyse the convergence of $$a_n=\frac{1}{n^2}+\frac{1}{(n+1)^2}+\dots+\frac{1}{(2n)^2}$$ and find the point of convergence if it does converge. I proved that it converges to $0$ noting that $$\frac{1}{n^2} \le a_n \le (n+1)\times \frac{1}{n^2}$$ and using Sandwich Theorem. But I was following a book by Arihant which gives the following solution (and I am quoting it without changing any notations) Define $a_n=\frac n{(n+n)^2}$ so that $\lim_{n\to \infty} a_n=0$ . Now, use Cauchy's Theorem to get $$0=\lim_{n\to \infty} \left(\frac{a_1+\dots a_n}n\right)=\lim_{n\to \infty} \left(\frac{1}{(n+1)^2}+\dots \frac 1{(2n)^2}\right)$$ and hence the result follows. I believe this solution is absolutely rubbish (although it would be good to have a check). But, I do like the idea and the approach. Can this approach (with necessary modifications) be used to solve these kind of limits?","['summation', 'solution-verification', 'sequences-and-series', 'limits', 'convergence-divergence']"
4707371,What's the probability of only one of the two students pass the test?,"Ann and Ben will take a test next week. Ann has a probability of 4/5 passing while Ben has a probability of 1/3 of passing the test. What's the probability of both of them pass the test? What's the probability of only one of them pass the test? I think the two students passing the test are independent events. The answer for question 1 would be 4/5 times 1/3 which gives us 4/15, right? What would be the answer for the second question? Thank you.","['probability-theory', 'probability']"
4707396,$a_1>0$ and $a_{n+1}=\ln{(a_n+1)}$. Where is the largest term of the sequence $na_n$?,"Given $a_1>0$ and $a_{n+1}=\ln{(a_n+1)}$ , the sequence $na_n$ is quite interesting. It turns out that the sequence $na_n$ approaches $2$ ( proof ), and that $\begin{align}\lim_{n\to\infty}\frac{n}{\ln{n}}(na_n-2)\end{align}=2/3$ ( proof ). So $na_n$ has some maximum value greater than $2$ . Let $f(x)=$ { $n$ -value of $(na_n)_\text{max}$ when $a_1=x$ }. An Excel simulation yields: $f(3)=1$ $f(2)=3$ $f(1.5)=11$ $f(1)=118$ $f(0.8)=652$ $f(0.6)=10424$ $f(0.55)=28113$ What is a good approximation for $f(x)$ for small $x$ ? I took the log of $f(x)$ and then used Excel's trendline tool to come up with $f(x)\approx ab^{1/x}$ where $a\approx 0.189$ and $b\approx 700$ , but I doubt this is valid for very small values of $a_1$ . I'm wondering if there is a closed form approximation for $f(x)$ .","['logarithms', 'recurrence-relations', 'asymptotics', 'sequences-and-series', 'limits']"
4707406,Combinatorics Pigeonhole Problem find Max Number of Possible Different Colors such that each Sub-Group of Size 9 from 60 Contains 3 Same-Color Balls,"Let a box contain 60 colored balls. In each group of 9 balls, at least 3 of them are the same color. What is the maximal number of possible colors which will allow the above condition to be true? I have tried to think of a solution in the following way - if I find the minimal number of colors for which the condition is not true and subtract 1, I'll get the maximal number for which it is true. The minimal number of colors for which the condition is not true will satisfy the following condition - there will be at least 1 group in which there will be balls of at least 8 different colors. Is this the correct approach? If so, how do I continue from here?","['pigeonhole-principle', 'discrete-mathematics']"
4707419,How to prove: $\sqrt{\tan{a}\tan{b}} ≤ \tan{\frac{a+b}2} ≤ \frac{1}{2}(\tan{a}+\tan{b})$,"Suppose that $0≤a≤b<\frac{π}{4}$ Show that $\sqrt{\tan{a}\tan{b}}≤\tan{\frac{a+b}{2}}≤\frac{1}{2}(\tan{a}+\tan{b})$ . I want to prove this inequality without using calculus. So, I tried the following: let $\tan{\frac{a}{2}}=x$ and $\tan{\frac{b}{2}}=y$ . Then, using the basic formulas related to the trigonometric functions, I got $2\sqrt{\frac{xy}{(1-x^2)(1-y^2)}} \le \frac{x+y}{1-xy} \le \frac{x}{1-x^2}+\frac{y}{1-y^2}$ . However, I couldn't advance any further. Although I know the second part of the inequality can be easily proved by using Jensen's inequality and the convexity of the tangent function on the interval $[0, \frac{\pi}{2}]$ , I was not able to prove the convexity of the tangent function without using calculus. How can I solve this problem?","['algebra-precalculus', 'trigonometry']"
4707437,Minimum area of the inside of a parallelepiped,"A container with parallelepiped shape, empty inside, and square base, has capacity of 32 litres. We want to cover the inside of the container (without the top surface), with a sheet. What are: the sides $x$ the height $h$ of that parallelepiped if the area of sheet must be minimum? MY ATTEMPT My attempt was to use these two equations: $x^2h=0.032$ (it's the area of the parallelepiped in meters squared) $D(4xh+x^2)=0$ (the area of the sheet must be the equal to the 5 faces of the parallelepiped, and I must find its minimum, thus the derivative equal to zero) I then obtain, from the first equation, $h=\frac{0.032}{x^2}$ and then I substitute this value of $h$ in $4xh+x^2$ , obtaining $\frac{0.128}{x}+x^2$ . Then I do the derivative of this last expression, obtaining $\frac{0.128}{x^2}+2x$ and put $=0$ to find the minimum, obtaining $x^3=\frac{0.128}{2}$ DRAWING OF THE PROBLEM Note that the face of the parallelepiped with the yellow diagonal lines is the one we shouldn't consider, since it is the removed top surface. The faces with the red arrow are the one with area $xh$ , the base (orange) has area $x^2$ since it's a square","['optimization', 'solution-verification', 'derivatives', 'euclidean-geometry']"
4707452,Divergence theorem when $\nabla \cdot \vec{F} = 0$,"Calculate the flow of the vector field $$\mathbf{F}(x, y, z) = \frac{1}{(x^2 + y^2 + z^2)^{\frac{3}{2}}} (x, y, z)$$ out of a sphere with radius $10$ and center at the origin. This what I did: $$\frac{\partial F}{\partial x} = \frac{(x^2 + y^2 + z^2)^{\frac32} - 3x^2\sqrt{x^2+y^2+z^2}}{(x^2 + y^2 + z^2)^{3}} = \frac{1-3\cos^2(\theta)\sin^2(\phi)}{r^3}$$ $$\frac{\partial F}{\partial y} = \frac{(x^2 + y^2 + z^2)^{\frac32} - 3y^2\sqrt{x^2+y^2+z^2}}{(x^2 + y^2 + z^2)^{3}} = \frac{1-3\sin^2(\theta)\sin^2(\phi)}{r^3}$$ $$\frac{\partial F}{\partial z} = \frac{(x^2 + y^2 + z^2)^{\frac32} - 3z^2\sqrt{x^2+y^2+z^2}}{(x^2 + y^2 + z^2)^{3}} = \frac{1-3\cos^2(\phi)}{r^3}$$ $$ \nabla \cdot \vec{F} = \frac{\partial F}{\partial x} + \frac{\partial F}{\partial y} + \frac{\partial F}{\partial z} = 0 $$ $$\iiint_{V} 0 dV = 0$$ But the correct answer is $4\pi$ . What am I doing wrong?","['integration', 'divergence-theorem', 'multivariable-calculus', 'calculus', 'partial-derivative']"
4707481,Solve $\sqrt[3]{1+x}+\sqrt[3]{1-x}=\sqrt[3]{2}$,"Solve $\sqrt[3]{1+x}+\sqrt[3]{1-x}=\sqrt[3]{2}$ $\Rightarrow(\sqrt[3]{1+x}+\sqrt[3]{1-x})^3=(\sqrt[3]{2})^3$ $(\sqrt[3]{1+x})^3+3(\sqrt[3]{1+x})^2(\sqrt[3]{1-x})+3(\sqrt[3]{1+x})(\sqrt[3]{1-x})^2+(\sqrt[3]{1-x})^3=2$ $1+x+3[(1+x)^{\frac{2}{3}}(1-x)^{\frac{1}{3}}+(1+x)^{\frac{1}{3}}(1-x)^{\frac{2}{3}}]+1-x=2$ $3[(1+x)^{\frac{2}{3}}(1-x)^{\frac{1}{3}}+(1+x)^{\frac{1}{3}}(1-x)^{\frac{2}{3}}]=0$ $(1+x)^{\frac{2}{3}}(1-x)^{\frac{1}{3}}+(1+x)^{\frac{1}{3}}(1-x)^{\frac{2}{3}}=0$ $(1+x)^{\frac{1}{3}}(1-x)^{\frac{1}{3}}[(1+x)^{\frac{1}{3}}+(1-x)^{\frac{1}{3}}]=0$ So $x=\pm1$ , which is the answer. My question is about the remaining part $[(1+x)^{\frac{1}{3}}+(1-x)^{\frac{1}{3}}]=0$ . $\Rightarrow[(1+x)^{\frac{1}{3}}]^3=[-(1-x)^{\frac{1}{3}}]^3$ $1+x=-(1-x) $ $1+x=-1+x$ $1=-1$ So does this mean my assumption $[(1+x)^{\frac{1}{3}}+(1-x)^{\frac{1}{3}}]=0$ is wrong and it is not zero? Then how would I find its value? Thank you.","['algebra-precalculus', 'factoring', 'radicals']"
4707517,"$A = \{ \sum_{k=1}^{\infty} a_ke_k :|a_k|\leq c_k \} \subset \mathcal H$ is compact, where $\sum c_k^2<\infty$","The following is the exercise #24 in chapter 4 of Stein's Real Analysis. Let $\{e_k\}$ be an orthonormal set in a Hilbert space $\mathcal H$ . If $\{c_k\}$ is a sequence of positive real numbers such that $\sum c_k^2<\infty$ , then the set $$A = \left\{ \sum_{k=1}^{\infty} a_ke_k :|a_k|\leq c_k \right\}$$ is compact in $H$ . I refered to this page and below is my trial. Let $S_0 = \{(a_1,a_2,a_3,...):a_k \in \mathbb C, \sum_{k=1}^{\infty} a_k e_k \in A \}$ , $f_n = \sum_{k=1}^{\infty} a_{n,k}e_k \in A$ , and $A_1 = \{a_{n,1} \}_n$ . $|a_{n,1}| \le c_1 \forall n$ , so $A_1$ is a bounded sequence in $\mathbb C$ . Then, there is a subsequence $\{a_{n_j,1} \}_j$ such that $\lim_{j\to \infty}a_{n_j,1} = b_1\quad (|b_1| \le |c_1|)$ . Let $S_1 = \{(a_1,a_2,a_3,...):a_1 \in A_1, S_1 \subset S_0 \}$ , and $A_2 = \{a_{n,2} \}_n$ .... Continuing this process inducively, $S_m$ can be obtained $(m \in \mathbb N)$ so that $S_{m+1} \subset S_m$ and $\lim_{j\to \infty}a_{n_j,k} = b_k \quad (|b_k| \le |c_k|), k = 1,...,m$ . $\{a_{n_j,k}\}_j$ is a sequence of kth element of $S_m$ . Let $f_{n_j} = \sum_{k=1}^{\infty} a_{n_j,k}e_k$ , and $f = \sum_{k=1}^{\infty} b_k e_k$ . Then, $\Vert f_{n_j} - f \Vert = \Vert \sum_k (a_{n_j,k}-b_k)e_k \Vert \le \sum_k \Vert (a_{n_j,k}-b_k)e_k \Vert = \sum_k |a_{n_j,k}-b_k|$ After then, I wanted to show that $\lim_{j\to\infty} \Vert f_{n_j} - f \Vert = 0$ , but I found it difficult to show $$\lim_{j\to\infty}\sum_{k=1}^{\infty}|a_{n_j,k}-b_k| = 0$$ Any comments about my trial, whether my approach is correct or not, some errors if exists, how to finish this, or other better ideas, would be appreciated. Thank you.","['hilbert-spaces', 'measure-theory', 'functional-analysis', 'compactness']"
4707551,"Cartesian equation for $((\sin\theta)^3+\cos\theta,(\cos\theta)^3+\sin\theta)$","Can the parametric equations $x=(\sin\theta)^3+\cos\theta$ and $y=(\cos\theta)^3+\sin\theta$ be expressed as an equation with $x$ and $y$ only? If so, how can it be done? Current progress By letting $t=\sin\theta\cos\theta$ , I managed to get rid of the trig functions. The equations can be converted into \begin{align}
(x+y)^2&=(1+2t)(2-t)^2\\
(x-y)^2&=(1-2t)t^2
\end{align} and then I'm stumped. How can I continue?","['trigonometry', 'systems-of-equations']"
4707575,Why viewing sequences as functions allows to find the equivalent?,"I want to know why this method works so well to find an equivalent of a sequence. The idea of this method is to consider the sequence like a function that can be derived. Here are a few examples : Let $u_0>0$ and $u_{n+1}:=\ln(1+u_n)$ : we have $(u_n)_n$ decreasing and positive $(0\le\ln(1+u_n)\le u_n)$ , so it converges to $0$ . Now, let's consider this way of thinking : $u'(n) \approx u(n+1) - u(n) =  \ln(1+u(n))-u(n) \approx -2^{-1}u^2(n)$ when $n$ approaches $+\infty$ . We get : $(u(n)^{-1})' \approx 2^{-1}$ . Using this information, let us look : $ (u(n)^{-1})' \approx u_{n+1}^{-1}-u_n^{-1}=\ln(1+u_n)^{-1}-u_n^{-1} = (u_n -2^{-1}u_n^2+o(u_n^2))^{-1}-u_n^{-1}$ So $u_{n+1}^{-1}-u_n^{-1} = u_n^{-1}(1+2^{-1}u_n+o(u_n))-u_n$ . We get by a telescoping sum: $u_n^{-1}\sim n/2$ and finally we have : $u_n\sim 2/n$ . Let $u_0>0$ and $u_{n+1}:=u_n+u_n^{-1}$ : We can show that it goes to $+\infty$ . We have : $u'(n)\approx u(n+1)-u(n) = u(n)^{-1}$ . We get : $(u(n)^2)'=2^{-1}$ . Now, let us look : $(u(n)^2)'\approx u_{n+1}^2-u_n^2=u_n^2(1+u_n^{-2})^2-u_n^2= u_n^2(1+2u_n^{-2}+o(u_n^{-2}))-u_n^2 \sim 2$ . We get : $u_n^{2}\sim 2n$ and finally we have : $u_n\sim \sqrt{2n}$ . Let $u_n >0$ and $\forall n\ge1, u_{n+1}:=u_n + (nu_n)^{-1}$ : We can show that it goes to $l$ where $l\in\mathbb R_*^+\cup\{+\infty\}$ . We have : $u'(n)\approx u(n+1)-u(n) = (nu(n))^{-1}$ . We get : $(u(n)^2)'=2n^{-1}$ . Now, let us look : $(u(n)^2)' \approx u_{n+1}^2-u_n^2=u_n^2(1+(\sqrt{n}u_n)^{-2})^2-u_n^2$ So $u_{n+1}^2-u_n^2 = u_n^2(1+2(\sqrt{n}u_n)^{-2}+o(\sqrt{n}u_n)^{-2})-u_n^2 \sim 2n^{-1}$ . We get : $u_n^{2}\sim 2\ln(n)$ and finally we have : $u_n\sim \sqrt{2\ln(n)}$ . Let $(u_n)_n\in \mathbb R^\mathbb {N_*}$ and $S_n:=\sum_{i=1}^n u_i^2$ such that $u_nS_n\to 1$ when $n$ goes to $\infty$ . We can show that $u_n\to0$ and $S_n\to+\infty$ . We have : $S'(n)\approx S(n+1)-S(n) = u(n+1)^2\approx (S(n+1))^{-2} \approx (S(n))^{-2}$ . We get : $(S(n)^3)'=3$ . Then : $(S(n)^3)'\approx S_{n+1}^3-S_n^3 = (S_{n+1}-S_n)(S_{n+1}^2+S_nS_{n+1}+S_n^2)$ . However : $S_{n+1}-S_n = u_{n+1}^2 \sim (S_n)^{-2}$ . So : $S_{n+1}^3-S_n^3 \sim (S_n)^{-2}(S_{n+1}^2+S_nS_{n+1}+S_n^2)\sim 1+(S_{n+1}/S_n)+(S_{n+1}/S_n)^2 \sim 3.$ Finally, we get : $S_n\sim (3n)^{1/3}$ . So : $a_n \sim S_n^{-1} \sim (3n)^{-1/3}$ In these examples, considering the sequence as a function derived allows us to determine a equivalent. Why does it work so well ?","['limits', 'functions', 'sequences-and-series']"
4707578,Time Reversal of an Ornstein-Uhlenbeck Process,"Suppose we are given a stochastic process $(X_t)_{0\leq t\leq 1}$ which satisfies $$dX_t=-\theta X_tdt+\sigma dB_t,$$ also known as the Ornstein-Uhlenbeck process, where $\theta>0,\sigma\in\mathbb R$ and $X_0=x_0\in\mathbb R$ . The goal of this post is to find coefficients $\bar b(t,x),\bar\sigma(t,x)$ so that the time-reversed process $\bar X_t:=X_{1-t}$ satisfies $$d\bar X_t=\bar b(t,\bar X_t)dt+\bar\sigma(t,\bar X_t)dB_t,\hspace{1cm} 0\leq t<1.$$ The primary reference i am using for this is this paper . I will include screenshots of the relevant parts throughout this post. First, note that the coefficients of the SDE of $X$ satisfy the usual conditions, i.e. $b,\sigma$ are Lipschitz and don't grow significantly faster than $|x|$ . Additionally, it is well-known that $X_t$ is given by $$X_t=e^{-\theta t}x_0+\sigma\int_0^te^{-\theta(t-s)}dB_s$$ and hence by noting that the integrand $e^{-\theta(t-s)}$ is deterministic and by using Itô's isometry one can show that $X_t\sim\mathcal N\big(e^{-\theta t}x_0, \frac{\sigma^2}{2\theta}(1-e^{-2\theta t})\big)$ and hence $X_t$ admits the density $\phi_{\mu_t,\sigma_t}$ , where $\phi_{\mu,\sigma}$ is the gaussian density and $\mu_t=e^{-\theta t}x_0$ and $\sigma_t^2 = \frac{\sigma^2}{2\theta}(1-e^{-2\theta t})$ . Now according to the paper linked above the coefficients of the SDE of $\bar X$ are given by .
Since we have $$\partial_x\phi_{\mu,\sigma}(x)=\frac{1}{\sqrt{2\pi}\sigma} \exp\bigg(-\frac12\frac{(x-\mu)^2}{\sigma^2}\bigg)\cdot\bigg(-\frac{x-\mu}{\sigma^2}\bigg)=-\phi_{\mu,\sigma}(x)\frac{x-\mu}{\sigma^2}$$ we get the coefficients $\bar a(t,x)=\sigma^2$ and $$\bar b(t,x)=\theta x-\sigma^2_{1-t}\cdot\frac{x-\mu_{1-t}}{\sigma_{1-t}^2}=\theta x-(x-e^{-\theta t}x_0).$$ Then the backwards process $\bar X_t$ is supposed to obey the SDE $$d\bar X_t = \bigg[(\theta-1)\bar X_t + e^{-\theta t}x_0\bigg]dt + \sigma dB_t.$$ This seems to be wrong, since i see no way why this process should satisfy $\lim_{t\to 1}\bar X_t = x_0$ . Question: Are the calculations given above correct? Is the SDE actually the correct SDE for $\bar X$ ? If not, how do i correctly determine the backwards diffusion?","['probability', 'stochastic-processes', 'markov-process', 'stochastic-differential-equations', 'stochastic-calculus']"
4707651,Closed form of $ \sum_{k=0}^{n} (-1)^{n-k}\binom{n}{k}2^k k^m$?,"Is there a closed form of the above equation or something that simplifies it? Here is the same equation copied: $$\sum_{k=0}^{n} (-1)^{n-k}\binom{n}{k}2^k k^m$$ It looks very similar to the Stirling number of the 2nd kind but slightly modified, which looks like this: $$S(m,n)=\frac{1}{n!}\sum_{k=0}^{n} (-1)^{n-k}\binom{n}{k} k^m$$","['summation', 'binomial-coefficients', 'combinatorics', 'stirling-numbers']"
4707665,Proving $\sum_{cyc}(1+\sin A)^{\cos A}\le {\sum_{cyc}}(1+\sin A)^{\cos B}$ for $\triangle ABC$,"I need some help :D For $\triangle ABC$ , prove that $$\sum_{cyc}(1+\sin A)^{\cos A}\leq{\sum_{cyc}}(1+\sin A)^{\cos B}.$$ I'm really stuck with this problem because I haven't learned much about trigonometric inequality. At first I thought it was multiplication then we can solve it quite easily by returning it to log form and using permutation inequality but I was wrong. Everyone can post imagination. Thanks very much!","['trigonometry', 'algebra-precalculus', 'geometry', 'inequality']"
4707679,A natural (?) proof of linear indepedence of eigenvectors of distinct eigenvalues.,"Proposition. Let $T\colon V \to V$ be a linear operator. If $v_1, v_2, \ldots, v_m$ are eigenvectors of $T$ that belong to distinct eigenvalues, then they are linearly independent. The usual proofs are (1) by induction, (2) via a Vandermonde matrix.
I would like to suggest a proof which looks much more intuitive to me, see below. I did not find it in the literature and would be grateful for any reference and for any comments (are you agree that this proof is more intuitive and natural than the ""classical"" proofs?). Proof. Assume that $v_1, v_2, \ldots, v_m$ are linearly dependent. Let $W:=\mathsf{span}(v_1, v_2, \ldots, v_m)$ . Denote $k:=\mathsf{dim}(W)$ , then we have $k<m$ . Let $S\colon W \to W$ be the restriction of $T$ on $W$ . Then $v_1, v_2, \ldots, v_m$ are eigenvectors of $S$ . This means that $S$ , a linear operator in a $k$ -dimensional vector space, has $m$ eigenvalues, where $m>k$ , which is not possible.","['matrices', 'linear-independence', 'linear-algebra', 'eigenvalues-eigenvectors']"
4707683,"Can we always find matrices $M,N$ such that $\ker(MA+NB) = \ker(A) \cap \ker(B)$?","Suppose $A,B$ are $n\times n$ matrices with coefficients in a field $\mathbb{F}$ . Is it always possible to find $n\times n$ matrices $M,N$ with coefficients in the same field such that $$\ker(MA+NB) = \ker(A)\cap \ker(B)?$$ If $\mathbb{F} = \mathbb{R}$ or $\mathbb{C}$ then we can set $M = A^T, N = B^T$ and then the result follows because $$A^TAv + B^TBv = 0 \implies 0 = \langle v, A^TAv + B^TBv\rangle $$ $$= \langle v, A^TAv\rangle + \langle v,B^TBv\rangle = \|Av\|^2 + \|Bv\|^2 $$ which immediately tells us that $Av = Bv = 0$ (where the inner products are the normal dot product and sesquilinear products on $\mathbb{R}^n, \mathbb{C}^n$ depending on if we are working over $\mathbb{R}$ or $\mathbb{C}$ ). Notably, this approach catastrophically fails over fields not equal to $\mathbb{R}, \mathbb{C}$ as for example we can have $$A = \begin{pmatrix}1 & 1 \\\ 1 & 1\end{pmatrix} \implies A^TA = 0$$ if you are working over $\mathbb{F}_2$ . Is it still possible to find $M,N$ despite the fact that this ""obvious guess"" fails?","['matrices', 'finite-fields', 'linear-algebra']"
4707708,Vector bundles versus $GL_n$-principal bundles,"Let $X$ be a scheme. It is well known that vector bundles, or locally finite free sheaves of $\mathcal{O}_X$ -modules, ""correspond"" to principal $GL_n$ bundles, or $GL_n$ torsors.
This correspondence can be sketched via cocycles, or gluing data, yielding a bijection on isomorphism classes. It is natural to ask whether this can be enriched to an equivalence of categories,
but naively this is hopeless, as vector bundles admit plenty of non-invertible morphisms (say, the zero map), and every morphism of torsors is an isomorphism. However, we can try and ask this question on associated grupoids.
Given a vector bundle $E$ over $X$ with associated principal bundle $P$ , do we have a
canonical isomorphism $$
\operatorname{Aut}(E) = \operatorname{Aut}(P)
$$ ? I believe this might also not be the case, as I somehow expected $G$ -torsors
to have $G$ as a sheaf of automorphisms,
and I have concrete examples of vector bundles with automorphism group/sheaf not being $GL_n$ .","['vector-bundles', 'algebraic-geometry', 'principal-bundles']"
4707787,Incorrect reasoning during Taylor series derivation?,"I want to derive the Taylor series approximation of a function $f(x)$ at a point $p$ using the following reasoning, but ""my"" Taylor series formula misses the inverse factorial scaling of individual terms. Why? Is my reasoning missing some steps? Are my assumptions incorrect? The goal is to build a local approximation of a function $f(x)$ at point $p$ using incremental changes of functions. Our first local approximation of $f(x)$ will be the constant function $f_{0}(x) = f(p)$ . This is a very crude approximation, which we seek to incrementally improve by incorporating our knowledge of the first derivative $f'(x)$ . The numerical value of the first derivative $f'(x)$ tells us by how much does the value of function $f$ change if we move one unit from the point $x$ in the direction of the $X$ axis (but this is just a local linear approximation, which is valid only near the point $x$ , not necessarily 1 unit away from the point $x$ ). We can therefore improve our first guess $f_{0}$ to $f_{1}(x) = f(p) + (x - p)f'(p)$ . The term $(x - p)f'(p)$ uses the local measure of change $f'(p)$ to construct a linear function $(x - p)f'(p)$ , which represents an incremental offset that improves the approximation provided by $f_{0}$ . $(x - p)f'(p)$ is only a linear function, so to further improve our approximation error $\vert f(x) - f_{1}(x)\vert$ , we can use higher-order derivative $f''(x)$ to construct another linear approximation of how does the function $f'(x)$ change: $f_{2}(x) = f(p) + (x - p) \left( f'(p) + (x - p) f''(p) \right) $ . In general, we can keep recursively improving the linear approximations by adding incremental correction terms for lower-order derivatives, e.g. adding the offset $(x - p) f^{(n)}(p)$ that will bring the value of $f^{(n-1)}(p)$ closer to the exact value $f^{(n-1)}(x)$ : $$
\begin{aligned}
\Delta x &= x - p\\
f_{n}(x) &= f(p) + \underbrace{\Delta x \left( f'(p) + \underbrace{\Delta x \left(f''(p) + \underbrace{\Delta x \left(f'''(p) + \cdots\right)}_\text{incremental correction for $f''(p)$} \right)}_\text{incremental correction for $f'(p)$} \right)}_\text{incremental correction for $f(p)$}\\
f_{n}(x) &= f(p) + f'(p)\Delta x + f''(p)\Delta x^2 + f'''(p) \Delta x^3 + \cdots
\end{aligned}
$$ Yet the correct Taylor expansion looks like this: $$ f_{T}(x) = f(p) + \frac{f'(p)}{1!}\Delta x + \frac{f''(p)}{2!}\Delta x^2 + \frac{f'''(p)}{3!} \Delta x^3 + \cdots $$ Why is my reasoning incorrect? Why is ""my"" recursive formula not an optimal function approximation when compared to the equivalent Taylor expansion? And how can I change my reasoning to arrive at the ""correct"" Taylor polynomials that include inverse factorials? A side-question: seeking a clearer geometrical understanding, what does the term $\frac{1}{n!}$ scale? Does it scale the term $f^{(n)}(p)$ or does it scale $\Delta x^n$ ?","['approximation', 'calculus', 'taylor-expansion', 'real-analysis']"
4707846,Why can we use the identity matrix when defining the characteristic polynomial?,"We begin with $$\lambda v = Tv$$ where $\lambda$ is an eigenvalue, $v$ is an eigenvector, and $T$ is the transformation in question.
We state $$\lambda v - Tv = 0$$ We then must state $$(\lambda I - T)v = 0$$ What allows us to bring in $I$ , the identity matrix? I understand that subtraction of a linear transformation (or matrix) from a scalar is ill-defined, but what permits us to multiply $\lambda$ by $I$ ? Would a more rigorous evaluation be \begin{align*}
\lambda v - Tv &= \lambda Iv - Tv \\ &= (\lambda I - T)v
\end{align*} where the identity matrix provides a multiplicative identity of some sorts? I understand that $I \in M_{n \times n}(\mathbb{F})$ , so I am wondering how it can be the identity for $v \in M_{n \times 1}(\mathbb{F})$ ? The reason I ask is that I am proving Cayley-Hamilton for a diagonal matrix, and I have come upon the following: \begin{align*}
\chi(t) 
	&= det(D-tI) \\ 
	&= \prod_{i=1}^{n}d_{ii}-t \\
	&= (d_{11} - t)(d_{22} - t) \cdots (d_{nn} - t)
\end{align*} Consider \begin{align*}
\chi([D]) &= (d_{11}I - D)(d_{22}I - D) \cdots (d_{nn}I - D)
\end{align*} Where does the $I$ come from? The underlying question is really this: I understand that $I \in M_{n \times n}(\mathbb{F})$ , so I am wondering how it can be the identity for $v \in M_{n \times 1}(\mathbb{F})$ ?","['eigenvalues-eigenvectors', 'vector-spaces', 'matrices', 'linear-algebra', 'linear-transformations']"
4707924,Sum with reciprocal central binomial and harmonic number $\sum_{n=1}^{\infty}\frac{H_{2n}}{n^2 C_{2n}^{n}}$,"I am trying to calculate this sum,and below is my attempt: $$\displaystyle{S}=\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{{H}_{\mathrm{2}{n}} }{{n}^{\mathrm{2}} \left({C}_{\mathrm{2}{n}} ^{{n}} \right)}=\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{\mathrm{2}}{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\left(\frac{{H}_{\mathrm{2}{n}} }{\mathrm{2}{n}}\right)=-\mathrm{2}\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{\mathrm{1}}{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\left(\int_{\mathrm{0}} ^{\mathrm{1}} {x}^{\mathrm{2}{n}−\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right){dx}\right) \\=−\mathrm{2}\int_{\mathrm{0}} ^{\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right){dx}\left(\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{{x}^{\mathrm{2}{n}−\mathrm{1}} }{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\right)=−\mathrm{4}\int_{\mathrm{0}} ^{\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right)\frac{\mathrm{sin}^{−\mathrm{1}} \left(\frac{{x}}{\mathrm{2}}\right)}{\:\sqrt{\mathrm{4}−{x}^{\mathrm{2}} }}{dx} \\{x}=\mathrm{2sin}\left({t}\right)\Rightarrow{t}=\mathrm{sin}^{−\mathrm{1}} \left(\frac{{x}}{\mathrm{2}}\right)\Rightarrow{dt}=\frac{{dx}}{\:\sqrt{\mathrm{4}−{x}^{\mathrm{2}} }} \\\Rightarrow{S}=−\mathrm{4}\int_{\mathrm{0}} ^{\frac{\pi}{\mathrm{6}}} {t}\mathrm{ln}\left(\mathrm{1}−\mathrm{2sin}\left({t}\right)\right){dt} \\ $$ But at this step, I don't know how to process further. Can I ask a hint or another approach? Thank you so much.","['integration', 'summation', 'sequences-and-series']"
4707945,I created a Sangaku-style geometry problem involving an equilateral triangle and three circles. Can you solve it without a computer?,"Inspired by this difficult Sangaku problem , I created the following Sangaku-style problem of my own. In equilateral $\triangle ABC$ , $D$ is on $AB$ , $E$ is on $AC$ , and the incircles of $\triangle ADE$ , $\triangle DBE$ and $\triangle EBC$ are congruent. Prove that $BD=DE$ . I have a solution that requires a computer. I am looking for a solution that does not require a computer. My solution Assume the side length of $\triangle ABC$ is $1$ . Let $x=BD$ $y=DE$ $\theta=\angle BDE$ Use the sine rule and cosine rule to express $\theta$ , $AE$ and $BE$ in terms of $x$ and $y$ : $\theta=\arcsin{\left(\frac{\sqrt3 (1-x)}{2y}\right)}+\frac{\pi}{3}$ $AE=\sqrt{(1-x)^2+y^2+2y(1-x)\cos{\theta}}$ $BE=\sqrt{x^2+y^2-2xy\cos{\theta}}$ The inradius of a triangle is $\frac{2\times \text{area}}{\text{perimeter}}$ . $r_1=$ inradius of $\triangle ADE=\dfrac{y(1-x)\sin{\theta}}{1-x+y+AE}$ $r_2=$ inradius of $\triangle DBE=\dfrac{xy\sin{\theta}}{x+y+BE}$ $r_3=$ inradius of $\triangle EBC=\dfrac{(1-AE)\frac{\sqrt3}{2}}{2-AE+BE}$ Setting $r_1=r_2$ and $r_1=r_3$ gives two equations in $x$ and $y$ . Desmos shows they are satisfied only when $x=y$ , both approximately $0.5502282106$ .","['euclidean-geometry', 'circles', 'geometry', 'triangles', 'sangaku']"
4707961,Group with every finite order elements,"I am searching a nonabelian group in which every element has finite order and every natural number is an order of some element. Obviously the group cannot be finite. It has to have infinite order. There are groups in which every natural number is an order for example, $GL_n(F)$ for suitable fields, but they do not fit here, because there are elements of infinite order. Some subgroup of these general linear group might be a potential example. There are some examples in abelian case : $\mathbb Q / \mathbb Z,$ so I suspect that there are some examples in nonabelian case aswell.","['group-theory', 'examples-counterexamples']"
4707965,Solving $\frac{dy}{dx}=\frac{x^2y^2+xy+1}{x^2}$,"Assuming a substitution $v=xy$ , isn't a standard prescription however it can help solving some ODEs such as $$\frac{dy}{dx}=\frac{x^2y^2+xy+1}{x^2}.$$ Let us use $xy=v \implies xy'+y=v'$ , we get $$\frac{dv}{dx}=\frac{(v+1)^2}{x} \implies \frac{dv}{(v+1)^2}=\frac{dx}{x}.$$ Integrating both sides we get $$\frac{-1}{v+1}=\log x+C \implies y=-\frac{C+\log x+1}{x(C+\log x)}.$$ The question is: How else it can be solved Edit: Unfortunately there was a typo of sign in the  question, it should have been $+xy$ instead of $-xy$ . It is corrected now. Any other method is most welcome.",['ordinary-differential-equations']
4708033,How many roots are there of function $f(x)=x^4-3x^2+x-1$,"Problem: How many (real) roots are there of function $f(x)=x^4-3x^2+x-1$ First, I can directly say since degree is $4$ then there can be at most $4$ roots of functions. Moreover, apparently $f(0)=-1$ and $\lim_ {x \to \pm \infty} = \infty$ , so because of the IVT there are at least $2$ numbers $c,d \in \mathbb R$ such that $f(c)=f(d)=0$ . One from negative and other one from positive side. Actually, I can conclude the answer by sketching graph but which tool I can use to show that there are exactly $2$ roots for it without using graph.","['calculus', 'polynomials', 'algebra-precalculus']"
4708049,Are Borel sets whose projections are Borel closed under intersection?,"The projection of a Borel set of $\mathbb{R}^n$ needn't be Borel , although the projection of a closed set is a countable union of compact sets, hence Borel. My question is if $A,B \subset \mathbb{R}^n$ are Borel such that $\pi_k(A), \pi_k(B)$ are known to be Borel, is it true $\pi_k(A \cap B)$ is Borel? I haven't found an easy way to prove this, and can't find an answer, but it feels possible because intersecting seems limited in how much it can sabotage the projections. I proved a geometric theorem about such sets/projections, but lack that the projections are Borel.","['measure-theory', 'descriptive-set-theory']"
4708107,"Are these options correct, regarding logarithmic function","Let $$f(x)=\log_{[x]}\{x\}$$ where $[.]$ denotes the greatest integer function and $\{.\}$ denotes the fractional part function. Select the correct options. Options $1.$ domain of $f(x)$ is $[2,\infty)$ $2.$ range of $f(x)$ is $[\log2,\infty)$ $3.$ period of $f(x)$ is $1$ $4.$ $f(x)$ is injective My attempt I quickly saw that option $1$ can't be true as it includes the set of integers as well. Then I saw that option $2$ also can't be true as there's no way $f(x)\to\infty$ as $\{x\}$ always lie between $[0,1)$ Then I also concluded that option $3$ is false as if the period is $1$ then $x=2.4$ and $x=3.4$ must give same values but it is not true. Lastly for option $4$ , I don't have any mathematical proof but my intuition says that it's true. But the answer given says that all four options are correct. How is this possible $?$ I mean I've contradictions for the first three. Any help is greatly appreciated.","['functions', 'logarithms']"
4708114,Difficulty visualising surfaces and translating them into surface integral,"I am reviewing old exam questions, and I am currently doubting everything that I have worked on for the past 3 weeks. The question is as follows [Solution is below, translated from Swedish] The surface $S$ in $\mathbb{R}^3$ is given as the intersection of the cylinder $x^2 + y^2 ≤ 1$ and the surface defined
by $x^2 + z^2\leq 1$ with $z\geq 0$ . The vector field $F = (0, 0, x^2 + y^2)$ . (a) Give a parametrization of the surface $S$ . (b) Determine $$\iint\limits_{S} F \cdot N \, dS$$ where N is the unit normal field on $S$ with positive $z$ -coordinate. (3) Now here is where I am getting confused: I am assuming that S is the union of $S_1$ and $S_2$ , why are we adding $S_1$ and $S_2$ to the union only to then apply Gauss's divergence theorem? Why is the normal vector for $S_1$ directed downwards and not upwards? why would you parametrise the surface like that and not in cylindrical coordinates where you take $z$ between $0$ and $1$ ? I appreciate any help!","['divergence-theorem', 'multivariable-calculus']"
4708124,"If $f$ is a eigenfunction of $-\Delta$ in $L^2[0,1]$, is it necessarily $C^\infty$?","I am a little bit confused about the properties of the Laplacian $-\Delta$ on $L^2[0,1]$ with the periodic boundary conditions. At least I know that $-\Delta$ is an unbounded self-adjoint operator on $L^2[0,1]$ and its eigenvalues are all nonnegative. Moreover, each eigenvalue has a finite multiplicity. Now, my confusions are as follows: If $f \in L^2[0,1]$ is an eigenfunction of $-\Delta$ , then is $f$ necessarily $C^\infty$ ? I vaguely remember some regularity theorems from PDE context, but I cannot find an exactly relevant reference. If the first item is correct, then each eigenspace of $-\Delta$ must be a finite dimensional subspace of $L^2[0,1]$ , consisting of smooth functions. Is this also true? Lastly, let $g$ be a smooth periodic function on $[0,1]$ such that $-\Delta g$ is an eigenfunction of $-\Delta$ with the eigenvalue $\lambda (\geq 0)$ . Then, I suspect that $g$ itself is an eigenfunction with the eigenvalue $\lambda^2$ . But I cannot really prove this rigorously. All these issues seem to be related with the regularity of the eigenfunctions for the Laplacian and a bit subtle to me. Could anyone please clarify?","['regularity-theory-of-pdes', 'self-adjoint-operators', 'functional-analysis', 'partial-differential-equations']"
4708147,Is limit about functions?,"When talking about limit subject, all the time we point functions. But in derivative definition we use $\frac{\Delta Y}{\Delta X}$ . Is $\frac{\Delta Y}{\Delta X}$ a kind of function? I have this question about integral formula as well.","['limits', 'calculus']"
4708158,Any $n$ distinct positive integers always have three of them with large least common multiple,"The problem is stated as follows: Prove or disprove: there exists some absolute constant $c>0$ , satisfying the following statement: Given any $n$ distinct positive integers $a_i$ , $1\leq i\leq n$ , then there must exist three integers $1\leq i,j,k\leq n$ such that $[a_i,a_j,a_k]\ge cn^3$ . This problem comes from the two numbers version. Arrange the number in increasing order, $a_1< a_2< \cdots < a_n$ $$[a_i,a_{i-1}]=\frac{a_ia_{i-1}}{(a_i,a_{i-1})}\ge\frac{a_ia_{i-1}}{a_i-a_{i-1}}$$ Thus if $$\frac{1}{\frac{n}{2}}\ge\frac{1}{a_{\frac{n}{2}}}-\frac{1}{a_n}=\sum_{i=\frac{n}{2}}^{n-1}(\frac{1}{a_i}-\frac{1}{a_{i+1}})\ge\sum_{i=\frac{n}{2}}^{n-1}\frac{1}{[a_i,a_{i+1}]}$$ . Thus there must exist some $i$ , so that $[a_i,a_{i+1}]\ge \frac{n^2}{8}$ . However, this method doesn't work for larger than three case. I've known about another proof that can do for $3-\epsilon$ . Assume the contrary, assume that the $n$ positive integers with lcm all in $O(n^{3-\epsilon})$ . Then we fix a number t, then the number of tuples $(x,y,z),s.t. t=[x,y,z]$ is obviously at most $\tau(t)^3$ . Now we sum over $1\leq t\leq O(n^{3-\epsilon})$ , then any $a_i,a_j,a_k$ must appear in the summation. Thus, $$\sum_{t=1}^{O(n^{3-\epsilon})}\tau(t)^3\ge n^3$$ Use $\tau(t)\leq t^{\frac{\epsilon}{4}}$ when $t$ is large enough gives a contradiction. So I wonder whether the bound is $O(n^3)$ or not. Can somebody give some references on this problem? Thanks so much!","['number-theory', 'gcd-and-lcm', 'analytic-number-theory', 'combinatorial-number-theory', 'combinatorics']"
4708164,Operator-norm Identity (inequalitity) [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question in our lecture for functional-analysis we defined the norm of a linear operator as $$||T||:=||T||_{X\rightarrow Y}=\inf\{C\geq0|\forall x\in X:~||Tx||_Y\leq C||x||_X\}$$ and then we said it is: $$||T||_{X\rightarrow Y}\geq \sup_{x\neq0}\frac{||Tx||_Y}{||x||_X}\geq \sup_{||x||\leq1}||Tx||_Y\geq \sup_{||x||=1}||Tx||_Y$$ and i have problems understanding why theese inequalties hold and especially why the first one is not already an equality.
Could someone maybe give me hint on that?","['operator-theory', 'functional-analysis']"
4708172,Moore-Penrose pseudoinverse as a limit,"For any matrix $A \in \mathbb{C}^{m \times n}$ , there exists a unique matrix $A^{+}$ such that: $$A^{+} A = \left( A^{+} A \right)^{*}, \qquad A A^{+} = \left( A A^{+} \right)^{*}, \qquad AA^{+}A=A, \qquad A^{+}AA^{+}=A^+$$ I have to prove that, for $\varepsilon>0$ : $$ A^{+} = \lim_{\varepsilon \to 0^{+}} A^{*} \left( A A^{*} + \varepsilon I_{m} \right)^{-1}$$ My idea is to prove that the limit expression satisfies the $4$ conditions. Using the fact that $AA^{*}+\varepsilon I_{m}$ is a hermitian matrix and $(AA^{*}+\varepsilon I_{m})^{-1}=\left((AA^{*}+\varepsilon I_{m})^{-1}\right)^*$ I was able to prove the first two conditions, but for the last two I can't think of how to do it. Any idea how to do it? Pd: When I test $A^{+}A=(A^{+}A)^{*}$ , can I put the limit inside the * operator every time? $$\lim_{\varepsilon\to 0^+}\left(A^{*}(AA^{*}+\varepsilon I_{m})^{-1}A\right)^*=\left(\lim_{\varepsilon\to 0^+}A^{*}(AA^{*}+\varepsilon I_{m})^{-1}\cdot A\right)^{*}$$","['matrices', 'limits', 'pseudoinverse', 'linear-algebra']"
4708194,When $(-)+M$ sends closed sets to closed sets?,"Let $M$ be a subset of $\mathbb R^n$ . I wonder when $M+S$ remains closed for arbitrary closed set $S\subseteq \mathbb R^n$ ? I thought of this question in the study of topological group; but unfortunately, I still have few clues about the simple case of $\mathbb R^n$ . Here are some of my attemps. So far I have proved that $M$ has the closed-set-preserving property if ( $\Leftarrow$ ) $M$ is finite (this is trivial); $M$ is compact (this is well-known); $M$ is the intersection of finite many sets which are isometrically homeomorphic to $\mathbb R^{n-1}\times \mathbb R_{\geq 0}$ ; $M$ is the finite sum of 1.-3. above; $M$ is the finite union of 1.-4. above. It is also clear that $M$ has the closed-set-preserving property only if ( $\Rightarrow$ ) $M$ is closed, since [ $M$ is closed] $\Leftrightarrow $ [ $M+\{\mathrm{pt}\}$ is closed]. And I have proved that $M$ doesnot have to be convex. For $N=2$ , set $\Gamma:=\{(x,y)\mid xy\geq 1,x,y\geq 0\}$ , and its reflection $\Gamma':=\{(x,-y)\mid (x,y)\in \Gamma\}$ . We see that $\Gamma+\Gamma'=\mathbb R_{>0}\times \mathbb R$ is not closed. One can also generalise it to $\mathbb R^n$ .","['general-topology', 'algebraic-topology', 'analysis', 'real-analysis']"
4708208,System of equations on $\mathbb R$,"$\textbf{Question : }$ Find all $x,y,z \in \mathbb{R}$ that satisfy the following system of equations. $$3x-4y+\frac{1}{xy}=12$$ $$4z-12x+\frac{1}{zx}=3$$ $$12y-3z+\frac{1}{yz}=4$$ $\textbf{My Attempt :}$ Let $t = \frac{1}{xyz}$ then each of our equation transforms to $$3x-4y+tz=12$$ $$-12x+ty+4z=3$$ $$tx+12y-3z=4$$ I thought I would zero out the coefficient matrix which led to nothing : $$\Delta = -t^3-169t=0 \implies t = 0 ,\pm13i$$ none of which is in $t$ 's domain as $t \in \mathbb{R} - \{0\}$ Next I thought to write it in a form where all the constant terms are zero so I could surely zero out the coefficient matrix and find out the value of $t$ . So here are those equations $$51x-4y(t+1)+z(t-16)=0$$ $$3(t+16)x+4(9-t)y-25z=0$$ $$3(1-t)x-40y+z(t+9)=0$$ as it turns out the coefficient matrix is zero for all $t \in \mathbb{R} - \{0\}$ . So what to do now?","['real-numbers', 'algebra-precalculus', 'systems-of-equations', '3d']"
4708231,When can we divide characters in character table?,"For $G$ a finite group and two $\mathbb CG$ modules $V$ and $W$ , then (for $\chi_V$ the character ie the trace of the $G$ -action) we have that $$
\chi_{V \otimes W} = \chi_V \cdot \chi_W
$$ is a representation. I'm wondering in what conditions we can somehow reverse this, for instance taking two characters $\chi_V$ and $\chi_W$ and divide them to get a character $\phi := {\chi_V}/{\chi_W}$ . Edit: After the discussion in the comments, a more succinct formulation of my question is: given representations $\chi_V$ and $\chi_W$ , what are conditions on existence of a third representation $U$ such that $V \cong W \otimes U$ , so that $$
\chi_V = \phi \cdot \chi_W
$$ with $\phi = \chi_U$ a character as opposed to a more general class function? I realise necessary conditions would be that all the pointwise divisions would need to be algebraic integers, so for instance looking at the character table of $PSU_3(\mathbb F_2)$ , $\rho_6/\rho_5$ won't be a character. So being finite solvable isn't sufficient (link indicating this group is $C_3^2 \rtimes Q_8$ ), nor is the dimension of one dividing the dimension of the other. Equally on the same page, the character table of $C_3 \rtimes S_3$ shows $\dim V = \dim W$ isn't sufficient either... I also see why this might not hold at all in generality, since my intuition specifically comes from small groups with characters which can be constructed by the tensor representation. On the other hand, for one dimensional representations the characters are exactly homomorphisms into $S^1 \subseteq \mathbb C^\times$ , and so we'll have $\chi_V /\chi_W = \chi_V \cdot \overline{\chi_W} = \chi_V \cdot \chi_{W^*}$ for $W^*$ the dual. So for instance in an abelian group, this is always true. Are there known necessary/sufficient conditions for this to hold? Or is this an idea that simply doesn't generalise usefully?","['group-theory', 'group-actions', 'representation-theory', 'characters']"
4708249,"Is (X,Y) bivariate normal in this case?","Let (X, Y) be a bivariate random variable. It is known that $X|Y \sim N(\phi Y, \sigma^2)$ and $Y|X \sim N(\phi X, \sigma^2)$ , for some known $\phi, \sigma^2, −1 < \phi < 1$ .  Is (X,Y) bivariate normal? I want to say they are bivariate normal, but I don't know how to conclude. I like this definition:  (X,Y)
being bivariate normal is ""any linear combination of X
and Y
"" is normal.","['statistics', 'probability']"
4708253,Evaluating $\int_0^\pi \sin^2(3x+\cos^45x)dx$ (2023 MIT Integration Bee #16),"2023 MIT Integration Bee Regular Season, Problem 16. $$\int_0^\pi \sin^2(3x+\cos^45x)dx$$ I got as far as $$
\int_0^\pi \sin^2(3x+\cos^45x)dx = \frac{1}{2}\int_0^\pi 1dx \\ - \frac{1}{2}\int_0^\pi \cos(6x+2\cos^45x)dx
$$ For the 2nd integral, I’ve tried substitutions like $x\rightarrow\pi-x$ and $x\rightarrow\frac{\pi}{2}-x$ but they don’t seem to lead anywhere. Would appreciate some help in how to show that the 2nd integral is $0$ so that the final answer is $\frac{\pi}{2}$ , or if there’s another method completely to go about this.","['integration', 'calculus', 'contest-math']"
4708331,Number of Draws Needed to Win a Raffle,"I was at a summer bbq picnic on the weekend and there was a raffle draw. There were different prizes on the table.  Everyone had a ticket and they would randomly pick tickets - when a ticket was called, the recipient would come and pick up their prize. Their ticket would then be removed from the raffle and they would keep going. Obviously the ""better prizes"" would be picked first and the ""less desirable prizes"" would remain until the end. At the same time, there were popsicles in another part of the picnic area that were going fast! But if I went to go get a popsicle, I might miss my ticket being called! But if I stayed at the raffle area and my ticket was never called, I would miss out on the popsicles! I was trying to calculate: based on how many tickets/prizes were remaining in the raffle - would it be worth sticking around for my number to be called? I tried to think of it this way: Suppose there were 100 tickets (i.e. 100 people) - on average, from the very beginning of the raffle -  how many tickets would need to be drawn before mine showed up? Is there a mathematical formula for this? A wild guess - I say that 50 on average need to be drawn but I dont think this is correct? Thanks!",['probability']
4708357,"Prove a monotonic function is linear given its ""integrals are linear""","This problem is from the MIT Primes 2023 problem set (it's okay to post now): Let $f : \mathbb R \to \mathbb R$ be a monotonic function. Suppose that $k, l, m, n \in \mathbb R$ with $km \neq 0$ satisfy that for all $y \in \mathbb R$ $$
\int _y^{y+1}f\left(x\right)dx=ky + l
\qquad \text{and} \qquad
\int _y^{y+\sqrt{2}}f\left(x\right)dx=my+n
$$ Prove that $f$ is linear. Here is my partial solution to this: Let $$
F(x) = \int f(x) dx
$$ Then \begin{align*}
F(y + 1) - F(y) &= ky + l \\
F(y + \sqrt{2}) - F(y) &= my + n
\end{align*} Differentiating, we get \begin{align*}
f(y + 1) - f(y) &= k \\
f(y + \sqrt{2}) - f(y) &= m
\end{align*} This implies $f'(y + 1) = f'(y)$ and $f'(y + \sqrt{2}) = f'(y)$ . In other words $f' : \mathbb R \to \mathbb R$ is a periodic function with periods $1$ and $\sqrt{2}$ , implying that $f'$ is a constant function, which in turn implies that $f$ is linear. As far as I can tell, the issue with my solution is that $f'$ has to be continuous . How might I solve the problem?","['integration', 'periodic-functions', 'monotone-functions', 'calculus', 'functions']"
4708392,Numerical computation of the continuous Fourier transform,"Let $$\varphi(x):=\frac1{2\pi\sigma^2}e^{-\frac12\left(\frac{\|x\|}\sigma\right)^2}\;\;\;\text{for }x\in\mathbb R^2$$ for some $\sigma>0$ . I want to numerically compute $$p(\omega):=\left|\hat\varphi(\omega)\right|^2\;\;\;\text{for }\omega\in[-1,1)^2.$$ Shouldn't be too complicated, I thought. For the numerical integration, I'm using $$[-a,a)=\bigcup_{i_1=-k_1}^{k_1-1}\bigcup_{i_2=-k_2}^{k_2-1}\left(\left[\frac{i_1}{k_1}a_1,\frac{i_1+1}{k_1}a_1\right)\times\left[\frac{i_2}{k_2}a_2,\frac{i_2+1}{k_2}a_2\right)\right)$$ for suitable chosen $a_1,a_2>0$ and $k_1,k_2\in\mathbb N$ . This gives me the scheme $$\hat\varphi(\omega)\approx\frac{a_1a_2}{k_1k_2}\sum_{i_1=-k_1}^{k_1-1}\sum_{i_2=-k_2}^{k_2-1}e^{-{\rm i}2\pi\langle\omega,\left(\frac{i_1}{k_1}a_1,\:\frac{i_2}{k_2}a_2\right)}\varphi\left(\frac{i_1}{k_1}a_1,\frac{i_2}{k_2}a_2\right).$$ Plotting $p$ using this scheme and $a_1=a_2=k_1=k_2=100$ , I obtain the following result: Now, I already know that the analytical form of $\hat\varphi$ is $$\hat\varphi(\omega)=e^{-2\left(\pi\sigma\|\omega\|\right)^2}\;\;\;\text{for all }\omega\in\mathbb R^d,$$ where $d=2$ in our case. Plotting $p$ using this analytical form, I obtain this result: They are obviously different. I think I should expect that the ""spectrum is replicated"" in the first result (can I somehow obtain the distance from the center until when the replication begins?). However, even if I cut out the centered spectrum, it doesn't match the one in the second result. So, is there anything wrong with the way I estimated $\hat\varphi$ in the numerical integration? All plots show $\sigma=1$ .","['fourier-transform', 'numerical-methods', 'fourier-analysis', 'functional-analysis']"
4708429,University of Cambridge: Mistake on the exam? Extending holomorphic functions on intersecting discs,"Consider the following question Let $D_1$ and $D_2$ be two overlapping closed discs. Let $f$ be a holomorphic function on some open neighborhood of $D = D_1 \cap D_2$ . Show that there exist open neighborhoods $U_j$ of $D_j$ and holomorphic functions $f_j$ on $U_j$ for $j = 1, 2$ , such that $f(z) = f_1(z) + f_2(z)$ on $U_1 \cap U_2$ . I am convinced that this is not necessarily true. Here is my counter-example: Let $D_1$ and $D_2$ be the red and blue circles in the bellow diagram. Morever, let the black one be the unit disc. Let $$
f(z) = \sum_{n=1}^\infty z^{2^n}.
$$ Per this question , the function does not have an analytic continuation that contains any part of the unit circle. Now, in the question, by the identity theorem, we must have $$
f_1 = f_2 = \frac{1}{2}f
$$ on $D$ . As $f_1$ is holomorphic on $U_1$ , it is holomorphic on $D_1$ . But this together with the identity theorem on $D_1 \cap D$ gives us that $f$ can be analytically extended through the unit circle, which can not be true. Question: Is my counter example correct?",['complex-analysis']
4708430,Self-made Sangaku-style geometry problem involving chords and inscribed circles,"In the diagram, circles (or disks, if you like) of the same color have the same radius. (For an explicit description of the diagram, see below.) Let $g=$ radius of the green circles, $r=$ radius of the red circles. Find the value of $g/r$ . I have used a computer to find that the answer is exactly $5$ . I'm looking for a solution that does not require a computer (like my previous self-made Sangaku-style problem ). About my computer-assisted solution : I used desmos to manually draw the circles, zooming in to get close approximations of their centres and radii. Then I discovered that the value in question was extremely close to $5$ . Then I put my approximations into Wolfram, and it gave me suggested closed forms. Then I put these closed forms back into the equations of the circles, and they seem to be ""perfect fits"" (when I zoom in, there are no gaps or overlaps between neighboring circles or chords), with the value in question being exactly $5$ . Fun facts: Another blue circle could fit perfectly in the centre. The ratio of black to green (radii) is $\phi+1$ , and the ratio of green to blue is $\phi$ , where $\phi=\frac{1+\sqrt5}{2}$ is the golden ratio. Explicit description of the diagram: In a black circle, two chords of equal length meet at a point on the circle. In each of the two segments thus formed, a largest possible green circle is inscribed, followed by a pair of largest possible blue circles (one on each side of the green circle), followed by a pair of largest possible red circles (so each blue circle is between the green circle and a red circle). A third green circle touches the black circle and the two chords. Circles of the same color have the same radius.","['golden-ratio', 'euclidean-geometry', 'circles', 'geometry', 'sangaku']"
4708480,Showing $\sum_{r \leq k} \sum_{j_1 + \dots + j_r = k} \frac{1}{r!j_1\dots j_r} = 1$ for all $k$,"I wanted to know why is this equality true for all $k$ : $$\sum_{r \leq k} \sum_{j_1 + \dots + j_r = k} \frac{1}{r!j_1\dots j_r} = 1$$ and was told to look at the $z^k$ term in the power series expansion of $$\dfrac{1}{1 - z}= \exp(- \ln(1- z))= \exp \big( \sum_{j \geq 1} \frac{z^j}{j}\big) = \sum_{r\geq 0} \frac{\big( \sum_{j \geq 1} \frac{z^j}{j}\big)^r }{r!}$$ I thought of taking $z=0$ but its not the right way, can someone see how is the equality true ?","['summation', 'proof-explanation', 'combinatorics', 'taylor-expansion', 'probability']"
4708502,How long before someone is ahead by 10 in a game of flipping a coin?,"If me and a friend are playing a game and start with 10 marbles each. We flip a coin each round and each time it's a head he gives me a marble and each time it's tails I give him one. How many coin flips do we have to do on average before someone has all the marbles? I tried to do the average by 10 * (1/2) ^10 + (11C1) * (1/2)^11 .... up to infinity by multiplying the probability of each time getting 10 more heads than my opponent gets tails. This doesn't make sense to me though: the answer seemed way off, and also the game wouldn't actually be able to end on 11 flips because it is an odd number. It also doesn't seem to consider the fact the game could end on an earlier round. Any help with this question is much appreciated.","['statistics', 'factorial', 'word-problem', 'sequences-and-series', 'probability']"
4708523,$H=\bigoplus H_n$ is separable?,"Let $(H_n)$ a collection enumerable of Hilbert spaces. Consider $$
H=\bigoplus_{n=1}^\infty H_n=\left\{(x_n):\sum_{n=1}^\infty\|x_n\|^2<\infty\right\}.
$$ If each $H_n$ is separable, then $H$ also is separable? If $H_n=\mathbb{C}$ is immediately to check: $H=\ell_2(\mathbb{N})$ . But, the problem is for arbitrary Hilbert space $H_n$ . ----- EDIT ----- Maybe one way to resolve is using what Sambo commented. So, if I consider $$
K=\bigoplus^{\operatorname{alg}}H_n=\left\{(x_n)\in H:x_n\neq0\mbox{ for finite choices of }x_n\right\}=\bigcup_{n=1}^\infty \times_{k=1}^n H_k\times_{k=n+1}^\infty\{0\},
$$ we have that $\overline{K}=H$ . It's clear that $K$ is separable, since each $\times_{k=1}^n H_k\times_{k=n+1}^\infty\{0\}$ is separable, so the reunion must be separable too. Hence, $H$ is separable for being closure of $K$ .","['general-topology', 'functional-analysis', 'separable-spaces']"
4708530,"Can the pre-image of a non-measurable subset of $[0,1]$ under the function $f:[0,1]\to[0,1]$, where the range of $f$ is $[0,1]$, be measurable?","This is a follow up to this post . Note in the main question of this post , $f$ can have a range that’s a subset of $[0,1]$ . Here, $f$ must have a range of $[0,1]$ . Suppose we define a function $f:[0,1]\to[0,1]$ , such that using the Outer Lebesgue measure, the function is measurable in Caratheodory sense, and the range of the function is $[0,1]$ . Main Question Can the pre-image of a non-measurable subset of $[0,1]$ under $f$ , where the range of $f$ is $[0,1]$ , be measurable? Attempt: I'm not sure how to approach this question due to my lack of formal training beyond Intro to Advanced Math. I assume if the points in the graph of $f$ is ""spread out enough"" in $[0,1]\times[0,1]$ , there is some way to define $f$ where the pre-image of a non-measurable subset of $[0,1]$ under $f$ is measurable. If this is not true, then the main question of this post doesn't give a function that satisfies the motivation of that post . In case you want to read the motivation here, read the following: I want to find a function $f:[0,1]\to[0,1]$ whose graph is dense, and somewhat but not too evenly distributed (i.e. with complete spaical randomness ), in $[0,1]\times[0,1]$ . If the main question is wrong is there some way to fix the main question of the post to satisfy my motivation.","['measure-theory', 'functions', 'definition', 'examples-counterexamples']"
4708536,Probability of two intersecting straight paths,"Two people, A and B, starts from two different points and move in a perfectly straight line in an infinite plane. When they move they leave a visible trace after them. Question: What is the probability that their path (of traces) will intersect at some point regardless of where they start? What I've tried so far is to draw two circles and split it in quadrants. That helped a little bit but didn't really solve the problem, just got an overview. Here's some examples of interesecting paths (first row) and non intersecting paths (second row) which gives you an idea of the criterias for when they intersect and don't intersect: How would you approach and solve this problem?",['probability']
4708546,Fourier-Mukai partners that are birational at every point,"Let $X$ and $Y$ be smooth projective irreducible varieties that are Fourier-Mukai partners, i.e., have exact equivalent derived categories $D^b(X) \simeq D^b(Y)$ . It is well-known that if a derived equivalence $D^b(X) \simeq D^b(Y)$ maps a skyscraper sheaf at $x \in X$ to a skyscraper sheaf at $y \in Y$ , then $X$ and $Y$ are birational around those points since the Fourier-Mukai kernel around those points will be a graph of an open immerison. (Moreover, the corresponding birational map will be a $K$ -equivalence.) I am wondering if it is true that if for any point $x \in X$ , there exists a derived equivalence that maps the skyscraper at $x$ to a skyscrpaer at some point in $Y$ and vice versa, then $X$ and $Y$ are isomorphic. A little bit strongly, is it true that if smooth projective irreducible varieties $X$ and $Y$ are Fourier-Mukai partners and they are birational around every point, they are isomorphic?","['derived-categories', 'algebraic-geometry', 'birational-geometry']"
4708579,Evaluate the limit: $\lim_{n\to\infty} n \sin (n! \cdot \pi \cdot e)$,"Problem: What is the limit $$\lim_{n\to\infty} n \sin (n! \cdot  \pi \cdot e)$$ My work: I expand $e$ by series, by using the same method from this old post : $$ n!e=n!\cdot\sum_{k=0}^{+\infty}\frac{1}{k!}=A+\frac{1}{(n+1)}+\frac{1}{(n+1)(n+2)}+\cdots $$ where $A\in\mathbb{N}$ . This gives the non-integer part: $$ \{n! e\} = \frac{1}{n+1}+O\left(\frac{1}{n^2}\right)$$ Then I get the limit $$\lim_{n\to\infty} n \sin (n! \cdot  \pi \cdot e)=\lim_{n\to\infty} n \sin \left(\frac{\pi}{n+1}\right)=\pi$$ But I use Wolfram it says both the two limits are indeterminate, as shown below. Why is that?","['calculus', 'taylor-expansion', 'sequences-and-series', 'limits', 'convergence-divergence']"
4708622,"If $f(x)=x^4+4x^3+26$, then find the number of solutions of $f(f(f(f(x))))=26$ is ____","If $f(x)=x^4+4x^3+26$ , then find the number of solutions of $f(f(f(f(x))))=26$ is ____ My approach is as follows: $f'(x)=4x^3+12x^2=4x^2(x+3)$ $f''(x)=12x^2+24x=12x(x+2)$ At $x=-3$ it is minimum as the value of $f'(x)$ changes from negative to positive then $f(-3)=(-3)^4+4(-3)^3+26=-1$ , therefore the range of $f(x)$ is $[-1,\infty)$ .","['calculus', 'derivatives']"
4708783,What happened to the domain here?,"If we start with: $$\dfrac{1-\cos(2\theta)}{\sin^2(2\theta)}\;,$$ we can simplify that to , $$\dfrac{1-(1-2\sin^2(\theta)}{4\sin^2(\theta)\cos^2(\theta)}\;,$$ which simplifies further to $$\dfrac{\sin^2(\theta)}{2\sin^2(\theta)\cos^2(\theta)}\;.$$ Now, I can divide both sides by $\sin^2(\theta)$ , (given that it doesnt equal $0$ ), and arrive at the answer $\dfrac{1}{2}$$\sec^2(\theta)$ . Now, surely the domain resitriction I must apply is all the values of $\theta$ for which $\sin^2(\theta)$ equals $0$ , such as $\pi$ . Now this is the bit that makes little sense, if I put $\pi$ into the first equation, I get an undefined answer, but in $\dfrac{1}{2}$$\sec^2(\theta)$ , I get $0.5$ , which is what desmos plots. So my question is, what is happening here?",['trigonometry']
4708794,Can't solve this seemingly simple equation for x [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I have the following implicit function: $b x^\frac{2}{a}+(xz+t)^\frac{2}{a} = 1$ which I'm trying to solve for $x$ . I've been trying for a while now and I'm unable to simplify anything. This task would be easy if it wasn't for the $t$ . I'm probably missing some trick in my arsenal that makes this possible. Any help that leads to the correct solution would be greatly appreciated! To give some context: I want to calculate the intersection between a superellipsoid/convex superquadric in 3 dimensions and a line $(0, 0, t)^\top + \beta(x, y, z)^\top$ . The implicit function of a superellipsoid can be written as $F(x, y, z) = (x^{\frac{2}{e_2}} + y^{\frac{2}{e_2}})^{\frac{e_2}{e_1}} 
+ z^{\frac{2}{e_1}} = 1$ with $0 \leq e_1, e_2, \leq 2$ . To calculate the intersection we can solve $F(\beta x, \beta y, \beta z + t) = 1$ for $\beta$ . I substituted $(x^{\frac{2}{e_2}} + y^{\frac{2}{e_2}})^{\frac{e_2}{e_1}}$ with $b$ and that is how I got the equation above (although $x$ should probably be called $\beta$ again).",['functions']
4708800,"Distribution of the ratio of sample range to sample standard deviation for normal when $\,n=3$","Let $X_{1},X_{2},X_{3}$ be i.i.d samples from $N(\mu,\sigma^2)$ . Let $u$ denotes $$u=\frac{X_{(3)}-X_{(1)}}{S_{3}}\text{ , where }\,X_{(i)}\text{ denotes the }i^{\text{th}}\,\text{order statistic,}\\S_{3}=\sqrt{\frac{\sum_{i=1}^3(X_i-\bar{X})^2}{2}}$$ Now I know the density function of $\,u\,$ is $$f(u)=\frac{3}{\pi}\left(1-\frac{u^2}{4}\right)^{-\frac{1}{2}}(\sqrt{3}\le u\le2)$$ But how to get that?
Does anyone have any ideas?  Would appreciate some help.","['statistics', 'probability-distributions', 'normal-distribution', 'probability']"
