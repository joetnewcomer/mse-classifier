question_id,title,body,tags
3339164,Simply connected compact Lie groups have even dimension - Where is the mistake?,"I am a bit confused because I think I have a proof for a statement which I think is wrong. The statement is: \begin{equation}
\text{Every compact simply connected Lie group has even dimension.}
\end{equation} However, if I remember correctly $S^3$ has a Lie group structure. I will now elaborate on my ""proof"" for the above statement. Corollary 21.6 in Milnor´s Morse Theory says the following: A simply connected Lie group $G$ with bi-invariant (Riemannnian) metric splits as a cartesian product $G'\times \mathbb{R}^k$ , where $G'$ is compact and the Lie algebra of $G'$ has trivial center. Let now $G$ be a compact simply connected Lie group. As $G$ is compact it posseses a bi-invariant Riemannian metric $\langle \cdot,\cdot \rangle$ . By the corollary, the Lie algebra $\operatorname{Lie}(G)$ of $G$ has trivial center, i.e. for every non-zero $X\in \operatorname{Lie}(G)$ there exists $Y \in Lie(G)$ s.t. $[X,Y]\neq 0$ . Define a bilinear form $q$ on $Lie(G)$ by $q(X,Y)=[X,Y]$ . As this is bilinear, there ex. a linear transformation \begin{equation}
A: \operatorname{Lie}(G)\to \operatorname{Lie}(G)
\end{equation} such that \begin{equation}
q(X,Y)=\langle AX,Y\rangle \quad \text{for all } X,Y\in \operatorname{Lie}(G).
\end{equation} Since $\operatorname{Lie}(G)$ has trivial center $A$ is injective and hence an automorphism. The fact that $q$ is skew-symmetric translates into \begin{equation}
A^T=-A.
\end{equation} If we denote the dimension of $G$ by $n$ , this implies \begin{equation}
\det(A)=\det(A^T)=(-1)^n\det(A).
\end{equation} However, as $A$ is an automorphism we know $\det(A)\neq 0$ . Therefore, $n$ is even. I would be grateful for clarifications. That can either be pointing out a mistake in my ""proof"" or any other mistake I made. Thanks in advance.","['lie-groups', 'differential-geometry']"
3339177,Proving an estimate for a function that is null on the boundary of the unit ball,Let $B_1(0)$ be the unit ball in $\mathbb{R}^3$ and let $f \in C^1(\overline{B_1(0)})$ such that $f$ is identically zero on $\partial B_1(0)$ . Prove that $$|f(0)| \leq\frac{1}{4\pi}\int_{B_1(0)}|\nabla f(x)||x|^{-2}dx$$ I have absolutely no idea of how to do this! Any hint would be highly appreciated.,"['calculus', 'analysis', 'real-analysis']"
3339199,Homotopy of integral curves of a gradient field preserves levelsets (?),"Given a differentiable scalar field $f$ on a Riemannian manifold $X$ (with properties as required)
I would like to formulate a homotopy of maximal integral curves $\gamma, \tilde{\gamma}$ of the gradient field $\nabla f$ . Edit : If $X$ has a boundary, i.e. $\partial X \neq \emptyset$ then $f$ shall obey the Neumann boundary condition $g(\mathbf{n}, \nabla f) = 0$ on $ \partial X$ with $\mathbf{n}$ denoting the outward-pointing normal and $g$ the Riemannian metric. I assume the term ""maximal integral curve"" as defined in http://math.stanford.edu/~conrad/diffgeomPage/handouts/intcurve.pdf , Theorem 5.1. Edit : For the constructions below I mainly care about the images of $\gamma, \tilde{\gamma}$ so I allow for an arbitrary parametrization of the curves, even if this parametrization does not strictly coincide with the gradient any more (i.e. not in terms of absolute value, but just in terms of direction). Then, without loss of generality, let $\gamma, \tilde{\gamma}$ be parameterized over the unit interval $I$ .
Then I mean in particular a homotopy $H$ : \begin{align} \tag{1}
H(\,\cdot\,, 0) \quad &= \quad \gamma \\
H(\,\cdot\,, 1) \quad &= \quad \tilde{\gamma} \tag{2}\\
\forall t \in I \colon \; H(\,\cdot\,, t) \quad & \text{is a maximal integral curve of $\nabla f$} \tag{3}
\end{align} The requirement of the intermediate states being also maximal integral curves is not usual for a homotopy AFAIK. Also it would not necessarily require the end points of each curve to be the same. First bunch of questions: Is $H$ then actually a homotopy or should I call it rather an isotopy or how else? What would be the proper terminology for this definition? Now what I need is that all curves that are homotopic to an initial maximal integral curve $\gamma_0$ in this sense cross the same level sets of $f$ in the same order. Formally: For every $\gamma$ homotopic to $\gamma_0$ in sense (1)/(2)/(3) there exists a homeomorphism (a reparametrization) $\psi \colon I \longrightarrow I$ such that \begin{equation} \tag{4}
f \circ \gamma = f \circ \gamma_0 \circ \psi
\end{equation} This seems like a triviality as a levelset cannot abruptly end unless it contains critical points of $f$ . But at critical points the maximal integral curves of $\nabla f$ would end and a homotopy could not be continued in first place. Integral curves of $\nabla f$ must cross a level set orthogonally which would not be defined at the boundary of the level set. Second bunch of questions: Is there a more formal argument for this or a known theorem yielding this? Or how would I prove it? Or do I even overlook something and there is a counter example? Given an initial maximal integral curve $\gamma_0$ I suppose there is a well-defined subset $U_0$ of the manifold $X$ consisting of points that lie on any integral curve that is homotopic to $\gamma_0$ in the sense of (1)/(2)/(3). I further suppose that $X$ can be split into disjoint regions $U_j$ in this manner. I.e. such that each region consists of points lying on an integral curve homotopic to an initial integral curve $\gamma_j$ but $\gamma_j$ not homotopic to $\gamma_i$ for $i \neq j$ in sense of (1)/(2)/(3). Third bunch of questions: Is there a proper terminology for this construction, e.g. ""homotopy regions"" of $\nabla f$ or something (maybe related to the ""domain of flow"" from the lecture notes linked above)? Is there a reason to assume that $X$ splits into a finite or at least countable number of these regions $U_j$ ? I guess $X$ would have to be something like a fractal to yield an infinite number of such regions. Final bunch of questions: At the top I wrote ""with properties as required"". What properties are required to make the constructions in this question reasonable? I would prefer to not require $X$ to be compact or bounded, nor to expect that the maximal integral curves would be complete. Further I would like to have this for manifolds with or without boundary. Is that feasible? Does $X$ have to be orientable? Edit: I realized this may require some more regularity assumptions on $f$ . In my use case, $f$ arises as a solution of an elliptic differential equation, thus it should obey a unique continuation property, i.e. $\nabla f$ would not vanish on an open set. $\nabla f$ would vanish almost nowhere on $X$ . I am not sure if $f$ can be assumed to be analytic or if $X$ can. However, $f$ should be twice continuously differentiable as the differential equation is second order. Further, I suppose one can only have finitely many $U_j$ if the set of critical points of $f$ consist only of finitely many connectivity components. I am not sure what role it would play whether $X$ is bounded or not. Thanks in advance!","['gradient-flows', 'riemannian-geometry', 'homotopy-theory', 'differential-topology', 'differential-geometry']"
3339233,A question for Riesz lemma,"https://mathprelims.wordpress.com/2008/07/17/rieszs-lemma/ Here is the proof of Riesz lemma. I just wonder why we require the linear subspace to be closed, what happens if the linear subspace is open? Any help will be appreciated.","['functional-analysis', 'real-analysis']"
3339244,Turning an Abelian Group into a Vector Space,"This question is inspired by the question Are these vector spaces? but is free-standing. Suppose $\mathbb{F}$ is a field, and that $X$ is the multiplicative group of $\mathbb{F}$ . Let us write this abelian group $X$ additively. To be precise the set is $\mathbb{F}\setminus\{0\}$ , the zero element is $\hat{0}:=1$ , the addition operation is $x \hat{+}y:=xy$ , and the negative operation is $\widehat{-}x:=x^{-1}$ . Let $V$ be the abelian group of $n$ -tuples $X^n$ with the usual co-ordinatewise operations. Question : Can we define an $\mathbb{F}$ -scalar multiplication on $V$ so that $V$ becomes an $\mathbb{F}$ -vector space? By looking at $-1$ in $\mathbb{F}$ , which satisfies $(-1)\hat{+}(-1)=(-1)^2=1=\hat{0}$ we see that if there is to be any chance of turning $V$ into a vector space then the field $\mathbb{F}$ must have characteristic $2$ . More than that, a similar argument on $(2^k -1)$ -th roots of unity will show that $\mathbb{F}$ has no finite subfields $\mathbb{F}_{2^k}$ except $\mathbb{F}_2$ . Beyond that I cannot go.","['vector-spaces', 'modules', 'abstract-algebra', 'linear-algebra', 'commutative-algebra']"
3339246,Stalk of quasicoherent sheaf on fibre,"Let $\pi: X \to Y$ be a morphism of schemes mapping $x$ to $y$ . Let $\mathscr{F}$ be a qcoh sheaf on $X$ . Consider the fibre $X_y = \pi^{-1}(y)$ , equipped with the natural morphism $i : X_y \to X$ . The point $x$ is in this fibre. We can consider the pullback $i^* \mathscr{F}$ as a sheaf on $X_y$ . I want to show $$
(i^*\mathscr{F})_x = \mathscr{F}_x/\mathfrak{m}_y \mathscr{F}_x.
$$ In particular, when $\mathscr{F} = \mathcal{O}_X$ we get $\mathcal{O}_{X_y, x} = \mathcal{O}_{X,x}/\mathfrak{m}_y \mathcal{O}_{X,x}$ . Here $\mathfrak{m}_y$ is the maximal ideal of the local ring $\mathcal{O}_{Y,y}$ . This result is used everywhere but I can't find a reference. I always get my algebra confused when I try to prove it. Here's what I have so far. As we're looking at stalks we can work locally and assume our schemes are affine. This allows us to translate the above into the following algebraic setup. The map $\pi$ corresponds to a ring homomorphism $\varphi : B \to A$ with $\varphi^{-1}(\mathfrak{p}) = \mathfrak{q}$ . The sheaf is an $A$ -module $M$ . The fibre is the (spectrum of) the ring $A \otimes_B k(y) = A_\mathfrak{q}/\mathfrak{q} A_\mathfrak{q}$ . The inclusion of the point $x$ in the fibre $X_y$ corresponds to a homomorphism $\alpha : A \otimes_B k(y) \to k(x)$ , and $x$ is the prime ideal $\mathfrak{p}' = \alpha^{-1}(0) \subset A \otimes_B k(y)$ . Then what I want to show is $$
(A \otimes_B k(y))_{\mathfrak{p}'} = A_\mathfrak{p}/\mathfrak{q} A_\mathfrak{p}.
$$ The problem is I'm not sure how to do this. Maybe we can construct an explicit isomorphism of rings, but I feel like it would be nicer to use some universal property of localization stuff. Is there an easy/clear way to do this? This is exactly what we want when $\mathscr{F}$ is the structure sheaf, and should imply the result in general. I think $i^* \mathscr{F}$ will correspond to $M \otimes_A A_\mathfrak{q}/\mathfrak{q} A_\mathfrak{q} = M_\mathfrak{q}/\mathfrak{q} M_\mathfrak{q}$ , and then taking the stalk at $x$ with be like tensoring with $A_\mathfrak{p}/\mathfrak{q} A_\mathfrak{p}$ over $A_\mathfrak{q}/\mathfrak{q} A_\mathfrak{q}$ so we get $M_\mathfrak{p}/\mathfrak{q} M_\mathfrak{p}$ .","['algebraic-geometry', 'abstract-algebra']"
3339255,Calculating partial derivatives.,"Find the values of $n$ so that the function $v=r^n(3\cos^2\theta-1)$ satisfies the relation $$\dfrac{\partial}{\partial r}\bigg(r^2\dfrac{\partial v}{\partial r}\bigg)+\dfrac{1}{\sin\theta}\dfrac{\partial v}{\partial\theta}\bigg(\sin\theta\dfrac{\partial v}{\partial\theta}\bigg)=0$$ I got, $$\dfrac{\partial}{\partial r}\bigg(r^2\dfrac{\partial v}{\partial r}\bigg)=n(n+1)r^n(3\cos^2\theta-1)$$ Also, $$\dfrac{1}{\sin\theta}\dfrac{\partial v}{\partial\theta}\bigg(\sin\theta\dfrac{\partial v}{\partial\theta}\bigg)=36\sin^2\theta\cdot\cos^2\theta \cdot r^{2n}$$ Adding them together and equating it to zero gives, $$n(n+1)(3\cos^2\theta-1)+9\sin^22\theta\cdot r^n=0$$ I don't know how to get $n$ from three unknowns, please help.","['partial-derivative', 'multivariable-calculus', 'calculus', 'trigonometry']"
3339268,Proof that measure space is complete,"This exercise is from Achim Klenke - ""Probability Theory"".
Let $\Omega$ be an uncountably infinite set and let $\omega_0\in\Omega$ be an arbitrary element. Let $\mathcal{A}=\sigma (\{w\}\colon \omega \in\Omega \setminus \{\omega_0\})$ . Show that $(\Omega, \mathcal{A}, \delta_{\omega_0})$ is a complete measure space. First a characterization of $\mathcal{A}$ has to be given analogue to the following $\sigma$ -algebra: $\mathcal{A}' = \sigma (\{w\}\colon \omega \in\Omega)=\{A\subset \Omega\colon A\text{ is countable or }A^c\text{ is countable}\}$ I tried the obvious $\mathcal{A} = \sigma (\{w\}\colon \omega \in\Omega\setminus \{\omega_0\})=\{A\subset \Omega\setminus \{\omega_0\}\colon A\text{ is countable or }A^c\text{ is countable}\}$ and could finish proving the equation if I could somehow prove that $\omega_0$ can only be in a non-finite set of $\sigma (\{w\}\colon \omega \in\Omega\setminus \{\omega_0\})$ . I am not sure if this is correct, am I on the right track?","['measure-theory', 'probability-theory']"
3339444,I found a theorem? Is this consistent with the change of variables formula?,"Let $f$ be a ${C}^{\infty}$ function defined on ${\mathbb{R}}^{2} $ .
I considered the following function, $G$ and I probably found the following Theorem. However, I feel that something is wrong. $G(t,s):={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} f({u}_{1}\textbf{a}+{u}_{2}\textbf{b})\ d{u}_{1}d{u}_{2}$ Theorem? Let $f:{\mathbb{R}}^{2}\to {\mathbb{R}}$ be ${C}^{\infty}$ function, $\textbf{a},\textbf{b}\in {\mathbb{R}}^{2}$ :
  These are linearly independent, $t,s\in\mathbb{R}$ , and G and g are defined as follows. $\ \ g(t,s):=f(t\textbf{a} + s\textbf{b})$ $\ \ G(t,s):={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} f({u}_{1}\textbf{a}+{u}_{2}\textbf{b})\ d{u}_{1}d{u}_{2}$ Then, $\ $ (1) $\frac{\partial^2 G}{\partial t\partial s}(t,s)=f(t\textbf{a}+s\textbf{b})$ $\ $ (2) $\frac{\partial^2 g}{\partial t\partial s}(t,s)={}^{T}\textbf{a}(Hf)_{(t\textbf{a}+s\textbf{b})}\textbf{b}$ $\ $ (3) $f(t\textbf{a} + s\textbf{b})={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} 
\ {}^{T}\textbf{a}(Hf)_{({u}_{1}\textbf{a}+{u}_{2}\textbf{b})}\textbf{b}
\ d{u}_{1}d{u}_{2}$ Here, ${}^{T}\textbf{a}$ is the 
  Transpose vector of $\textbf{a}$ , and $(Hf)$ is Hessian matrix of $f$ . Proof of (1)? $G(t,s)={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} g({u}_{1},{u}_{2})\ d{u}_{1}d{u}_{2}$ and, according to Fubini's theorem, the following is correct: $$g(t,s)=\frac{\partial^2}{\partial t\partial s}{\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} g({u}_{1},{u}_{2})\ d{u}_{1}d{u}_{2}
=\frac{\partial^2 G}{\partial t\partial s}(t,s)
,$$ and $g(t,s):=f(t\textbf{a} + s\textbf{b})$ . Therefore, $$\frac{\partial^2 G}{\partial t\partial s}(t,s)=f(t\textbf{a} + s\textbf{b}).$$ Proof of (2)? $$\frac{\partial{g}}{\partial{t}}(t,s)
= \left\langle gradf(t\textbf{a}+s\textbf{b})|\textbf{a}\right\rangle,
$$ and $$\frac{\partial}{\partial s} (gradf(t\textbf{a}+s\textbf{b}))
=(\frac{\partial gradf}{\partial x}(t\textbf{a}+s\textbf{b}),
\frac{\partial gradf}{\partial y}(t\textbf{a}+s\textbf{b})
)\cdot\textbf{b}
=(Hf)_{(t\textbf{a}+s\textbf{b})}\cdot\textbf{b}.
$$ Here, $gradf$ is the gradient vector of $f$ , and $\left\langle \ \ |\ \ \right\rangle$ is dot product of $\mathbb{R}^2$ . Therefore, $$\frac{\partial^2 g}{\partial t\partial s}(t,s)={}^{T}\textbf{a}(Hf)_{(t\textbf{a}+s\textbf{b})}\textbf{b}\ \ $$ ■ Proof of (3)? Differentiate both sides of the following expression. $$G(t,s)={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} g({u}_{1},{u}_{2})\ d{u}_{1}d{u}_{2}$$ Differentiation and integration are interchangeable. Therefore, considering (2) $$\frac{\partial^2}{\partial t\partial s}G(t,s)
=\frac{\partial^2 }{\partial t\partial s}{\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} g({u}_{1},{u}_{2})\ d{u}_{1}d{u}_{2}$$ $$={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} \frac{\partial^2 }{\partial t\partial s}g({u}_{1},{u}_{2})\ d{u}_{1}d{u}_{2}={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} 
\ {}^{T}\textbf{a}(Hf)_{({u}_{1}\textbf{a}+{u}_{2}\textbf{b})}\textbf{b}
\ d{u}_{1}d{u}_{2}$$ On the other hand, considering (1), The left side of the above formula is: $$f(t\textbf{a} + s\textbf{b}) = \frac{\partial^2}{\partial t\partial s}G(t,s)$$ Therefore, $$f(t\textbf{a} + s\textbf{b}) 
={\int}_{{{u}_{2}}=0}^{{{u}_{2}}=s}{\int}_{{{u}_{1}}=0}^{{{u}_{1}}=t} 
\ {}^{T}\textbf{a}(Hf)_{({u}_{1}\textbf{a}+{u}_{2}\textbf{b})}\textbf{b}
\ d{u}_{1}d{u}_{2}$$ ■ My question Are these Theorem? (1)-(3) correct? If it is correct, is it consistent with the variable conversion formula? P.S. I'm not very good at English, so I'm sorry if I have some impolite or unclear expressions.","['integration', 'multivariable-calculus', 'derivatives', 'real-analysis']"
3339500,Inverses of dihedral group elements [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I am studying group theory and  I'm having a hard time conceptualizing what the inverse element of an element of the dihedral would be like, on the equilateral triangle, for example.
Any explanation is very well received.","['group-theory', 'abstract-algebra', 'dihedral-groups', 'intuition']"
3339507,Let $u \in C^3(\mathbb{R}^n)$ and harmonic such that $u(x) = o(|x|)$ when $|x| \rightarrow \infty$. Show that $\nabla u(0) = 0$ and u is constant,"Let $u \in C^3(\mathbb{R}^n)$ and harmonic such that $u(x) = o(|x|)$ when $|x| \rightarrow \infty$ . 1. Show that $\nabla u(0) = 0$ 2. Show that u is a constant function. To show that $\nabla u(0) = 0$ , I tried to show that $\frac{\partial u}{\partial x_i}(0) = 0, \forall i$ , but came up with nothing. For example, I know that the partial derivatives are also harmonic functions, so using the mean value theorem i get that: $$
\frac{\partial u}{\partial x_i} = \frac{1}{\operatorname{Vol}(r \cdot B^n)}\int_{r \cdot B^n}\frac{\partial u}{\partial x_i}(x) dx
$$ and then I tried to use the divergence theorem on the vector field $F = (0,\ldots,0,u,0,\ldots,0)$ where the $u$ is in the i-th coordinate, so I get: (sorry about the strange formatting of that vector) $$
= \frac{1}{\operatorname{Vol}(r \cdot B^n)} \int_{r \cdot S^{n-1}} \left< \left(\matrix{0\\ \vdots\\u\\ \vdots \\ 0}\right),\frac{x}{r}\right> dS =\frac{1}{\operatorname{Vol}(r \cdot B^n)} \int_{r \cdot S^{n-1}}u \cdot \frac{x_i}{r}dS
$$ and if $u \cdot x_i$ was harmonic, I would've finished here by using the mean value theorem again because obviously $u \cdot x_i = 0$ at $x=0$ , but it isn't harmonic for sure. Any help will be very appreciated. Do note that this is a question from a past exam in an advanced multivariate calculus class, so we don't have so much claims about harmonic functions and that's why I thought I could find a solution with the divergence theorem. I did find this answer ,
which somehow answers both questions together, but seems like a complete overkill, and probably this is not close to the solution the professor thought of when he wrote the questions and the solution to the second question somehow involves the first question.","['multivariable-calculus', 'harmonic-functions', 'vector-analysis']"
3339546,Probablity/Statistical Inference Important Questions (problems) Collection for Interviews and Understanding of Concept,This might be irrelevant here! But I would really appreciate your help! It would definitely help lot of us preparing for Interviews in Data Science domain. I am looking for a book/github/ any resource where I can find Probablity & STatistical Inference questions/puzzles (just like leetcode has programming) to prepare for interviews. Any suggestions on books/resources which has probablity problems I can solve to get thorough on all sort of probablity and statistical inference questions. Thank you,"['statistical-inference', 'statistics', 'book-recommendation', 'reference-request', 'probability']"
3339549,"Solve the functional equation $F(xy)+xy=xy(f(x)+f(y))$,$\forall x,y,\in (0,\infty)$","Let $f:(0,\infty)\to \mathbb{R}$ be a function such that $f(1)=0$ . If $f$ has an antiderivative $F: (0,\infty)\to \mathbb{R}$ such that $$F(xy)+xy=xy(f(x)+f(y)),\forall x,y,\in (0,\infty),$$ find $f$ . This problem is from the Romanian magazine ""Gazeta Matematica"", No.6-7-8/2018. I would like you to review my two solutions to this problem and post any others that you may find. Solution 1: For $y=1$ in the given relation we get that $$F(x)+x=xf(x),\forall x\in (0,\infty).(*)$$ From here it follows that $f(x)=\frac{F(x)}{x}+1,\forall x\in (0,\infty)$ and therefore $f$ is differentiable. By differentiating $(*)$ we get that $$f(x)+1=f(x)+xf'(x),\forall x\in (0,\infty)\iff f'(x)=\frac{1}{x},\forall x\in (0,\infty)$$ Hence, $f(x)=\ln x+C$ , $\forall x\in (0,\infty)$ , where C is a constant. Since $f(1)=0$ , it follows that $C=0$ and $f(x)=\ln x,\forall x\in (0,\infty)$ . Solution 2: As in Solution 1, we deduce that $f$ is differentiable, so in particular it is continuous. From $f(x)=\frac{F(x)}{x}+1,\forall x\in (0,\infty)$ , we get that $f(xy)=\frac{F(xy)}{xy}+1,\forall x,y\in (0,\infty)\iff F(xy)+xy=xyf(xy),\forall x,y\in (0,\infty)$ . After substituting this back into the original equation we get that $$xyf(xy)=xy(f(x)+f(y)),\forall x,y\in (0,\infty)\iff f(xy)=f(x)+f(y),\forall x,y\in (0,\infty)$$ Now, this is Cauchy's logarithmic equation and since $f$ is continuous it follows that $f(x)=C\ln x, \forall x\in (0,\infty)$ , where $C$ is a constant. Substituting back into the original equation we get that $C=1$ , so $f(x)=\ln x$ , $\forall x\in (0,\infty)$","['functional-equations', 'proof-verification', 'real-analysis']"
3339565,Prove a mod b = b mod a iff a=b,I'm just starting to learn the three types of proofs and I came across this question. a mod b = b mod a iff a=b I tried looking for solution to prove this but couldn't find it. Most examples I have are of the same divisor like: a mod n = b mod n. But i couldn't find anything on this. I assumed it would be by using a contradiction proof but what got me confused is the if and only if condition. Thanks for any help you send this way!!,['discrete-mathematics']
3339589,How to prove $\int_0^1\frac{1-x}{(\ln x)(1+x)}\ dx=\ln\left(\frac2{\pi}\right)$?,"A friend asked me to prove $$\int_0^1\frac{1-x}{(\ln x)(1+x)}\ dx=\ln\left(\frac2{\pi}\right)$$ and here is my approach: \begin{align}
I&=\int_0^1\frac{1-x}{\ln x}\frac1{1+x}\ dx\\
&=\int_0^1\left(-\int_0^1x^y\ dy\right)\frac1{1+x}\ dx\\
&=\int_0^1\left(-\int_0^1\frac{x^y}{1+x}\ dx\right)\ dy\\
&=\int_0^1\left((-1)^n\sum_{n=1}^\infty\int_0^1x^{y+n-1}\ dx\right)\ dy\\
&=\int_0^1\left(\sum_{n=1}^\infty\frac{(-1)^n}{y+n}\right)\ dy\\
&=\sum_{n=1}^\infty(-1)^n\int_0^1\frac1{y+n}\ dy\\
&=\sum_{n=1}^\infty(-1)^n\left[\ln(n+1)-\ln(n)\right]\tag{1}
\end{align} Now how can we finish this alternating sum into $\ln\left(\frac2{\pi}\right)$ ? My idea was to use $$\operatorname{Li}_a(-1)=(1-2^{-a})\zeta(a)=\sum_{n=1}^\infty\frac{(-1)^n}{n^a}$$ and if we differentiate both sides with respect to $a$ we get $$2^{1-a}(\zeta^{'}(a)-\ln2\zeta(a))-\zeta^{'}(a)=\sum_{n=1}^\infty\frac{(-1)^{n-1}\ln(n)}{n^a}\tag{2}$$ wolfram says that $\sum_{n=1}^\infty(-1)^n\ln(n)$ is divergent which means we can not take the limit for (2) where $a\mapsto 0$ which means we can not break the sum in (1) into two sums. So any idea how to do (1)? Other question is, I tried to simplify the sum in (1) as follows \begin{align}
S&=\sum_{n=1}^\infty(-1)^n\left[\ln(n+1)-\ln(n)\right]\\
&=-\left[\ln(2)-\ln(1)\right]+\left[\ln(3)-\ln(2)\right]-\left[\ln(4)-\ln(3)\right]+\left[\ln(5)-\ln(4)\right]-...\\
&=-2\ln(2)+2\ln(3)-2\ln(4)+...\\
&=2\sum_{n=1}^\infty(-1)^n\ln(n+1)
\end{align} which is divergent again. what went wrong in my steps? Thanks.","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'sequences-and-series']"
3339597,Alternating Fibonacci-like sequences are periodic?,"Define a Fibonacci-like sequence that depends on a
parameter $k \in \mathbb{N}$ ,
and alternates $\pm$ : \begin{eqnarray}
k=1 \;:\; f_1(n) &=& f_1(n-1)\\
k=2 \;:\; f_2(n) &=& f_2(n-1)-f_2(n-2)\\
k=3 \;:\; f_3(n) &=& f_3(n-1)-f_3(n-2)+f_3(n-3)\\
k=4 \;:\; f_4(n) &=& f_4(n-1)-f_4(n-2)+f_4(n-3)-f_4(n-4)\\
&\cdots&\\
k=k \;:\; f_k(n) &=& \Sigma_{i=1}^k (-1)^{i+1} f_k(n-i)
\end{eqnarray} For any initial data specifying the values of $f_k(n)$ for $n=0,1,2,\ldots,k{-}1$ ,
I claim the sequence becomes periodic, with period $(k+1)$ if $k$ is odd, and $2(k+1)$ if $k$ is even. 
For example, for $k=4$ , and initial values $$
\left(\; f_4(0),f_4(1),f_4(2),f_4(3) \;\right) = (1,2,3,4) \;,
$$ then $f_4(n)$ , for $n=0,\ldots,20$ is: $$
1, 2, 3, 4, 5, 2, -2, -3, -4, -5, -2, 2, 3, 4, 5, 2, -2, -3, -4, -5, -2 \;,
$$ with period $2(k+1)=10$ .
For example, \begin{eqnarray}
f_4(5) &=& f_4(4)-f_4(3)+f_4(2)-f_4(1)\\
f_4(5) &=& 5-4+3-2\\
f_4(5) &=& 2 \;.
\end{eqnarray} If instead we pin all initial values to $1$ , so that $$
\left( \; f_4(0),f_4(1),f_4(2),f_4(3) \; \right) = (1,1,1,1) \;,
$$ the resulting sequence is: $$
1, 1, 1, 1, 1, 0, -1, -1, -1, -1, 0, 1, 1, 1, 1, 0, -1, -1, -1, -1, 0 \;,
$$ also period $10$ . My question: Q . What is a proof of the claim that such alternating
  Fibonacci sequences $f_k(n)$ are periodic for any initial values? I can prove that, e.g., $f_4(n)$ is periodic with period $10$ , but only via induction for that specific $k{=}4$ ,
and initial conditions.
But if my claim is true, there should be a way to see that
all $f_k(n)$ , regardless of initial values, are periodic with those odd/even periods $(k+1)$ / $2(k+1)$ .","['fibonacci-numbers', 'recurrence-relations', 'sequences-and-series']"
3339605,Mean of binary random variables,"Let $X_1,...,X_m$ be $m$ random variables which take value 0 or 1. They are dependent in the sense that $E[X_i X_j]\leq\delta$ for some real number $\delta\in[0,1]$ and every distinct $i,j$ . The goal is to get a tight upper bound of $I=E[X_1+\ldots+X_m]$ , i.e., the mean of their summation. By taking the second moment $I^2\leq E[(X_1+\ldots+X_m)^2] = I + 2\sum_{i< j}E[X_i X_j]\leq I+m(m-1)\delta$ , so $I\leq 1+m(m-1)\delta$ . If $\delta=0$ , this bound is 1. The question is whether the bound is tight; I suspect it may be possible to get $1+O(m\delta)$ .",['probability-theory']
3339615,Is the graph of $f(x) = (x^2-4)/(x-2)$ the same as $f(x) = (x+2)$?,"this might be a dumb question, but I was wondering what is the difference of graphs between $f(x) = (x^2-4)/(x-2)$ and $f(x) = (x+2)$ . I understand if we simply the $f(x) = (x^2-4)/(x-2)$ it will come down to $f(x) = (x+2)$ . But without simplifying it, they both behave differently at x = 2 and how would that impact their graph. I searched online, and all they would draw would be the same graph for both of them, but it doesn't feel right.","['limits', 'functions']"
3339634,Correct way to evaluate partial derivatives for a coordinate transform?,"This question occurred to me when thinking about differential geometry change of coordinates. Consider the system of equations: \begin{align*}
p(x, y) = x + y &\qquad x(p, q) = p - q \\
q(x, y) = y &\qquad y(p, q) = q
\end{align*} Now, if I wish to evaluate $\frac{dp}{dq}$ , there are two evaluation strategies available for me: \begin{align*}
\frac{dp}{dq} = \frac{d(x+y)}{dy} = 
\frac{dx}{dy} + \frac{dy}{dy} = 0 + 1 = 1 \qquad (1)
\end{align*} One the other hand, consider this evaluation: \begin{align*}
\frac{dp}{dq} = \frac{dp}{dx}\frac{dx}{dq} + \frac{dp}{dy}\frac{dy}{dq} =
1  \cdot -1 + 1 \cdot 1 = 0 \qquad (2)
\end{align*} Indeed, one can prove something much stronger: Let $p_i = f_i(x_1, x_2, \dots x_n)$ . Now, the evaluation \begin{align*}
\frac{dp_i}{dp_j} 
= \sum_{k=0}^n \frac{dp_i}{dx_k} \frac{dx_k}{dp_j} 
=
\left[\frac{dp_i}{dx_0} \dots \frac{dp_i}{dx_k} \dots  \frac{dp_i}{dx_n} \right] \cdot  
  \left[ \frac{dx_0}{dp_j}  \dots \frac{dx_k}{dp_j} \dots \frac{dx_n}{dp_j}  \right]^T = (J \cdot J^{-1})_{ij} = \delta_{ij}
\end{align*} where $J$ is the jacobian of the function $\vec p = f(\vec x)$ , and $\delta_{ij}$ is the kronecker delta. I'm puzzled as to which interpretation I should choose. Interpretation (2) is nice if I want to think of the sets of ""co-ordinate systems"" $\{ p_i \}$ as being linearly independent, just like the original $\{ x_i \}$ are, but I have no idea if this is legal. I'd love an answer that explains to me when (1) is legal, when (2) is legal, and maybe go into more detail about the relationship with the Jacboian, and related geometric insights!","['coordinate-systems', 'multivariable-calculus', 'differential-geometry']"
3339658,Isomorphic as affine schemes v.s. isomorphic as affine $k$-schemes,"Let $k$ be an Algebraically closed field. Let $A,B$ be integral domains which are finitely generated as $k$ -algebras. If $A$ and $B$ are isomorphic as rings, then are $A$ and $B$ also isomorphic as $k$ -algebras ?","['affine-schemes', 'algebraic-geometry', 'affine-varieties', 'commutative-algebra']"
3339700,When does the product of all elements in a finite abelian group equal $1$? [duplicate],"This question already has answers here : Product of elements of a finite abelian group (3 answers) Closed 4 years ago . Clearly for $G \approx \Bbb{Z}_2$ this is not true since $G = \{1, a\}$ and so the product equals $a$ .  Was wondering what sufficient conditions are such that the product of all the group elements amounts to $1$ . For $G \approx \Bbb{Z}_3$ it's true since $G = \{1, a, b\}$ with $ab = 1$ .  I'm a little lost as to how to proceed. I think if each element pairs with an inverse distinct from it, then it's true that the product equals $1$ .  But is there another way to state that, and is that a neccessary condition as well? In addition, is it possible to cover all finite abelian groups by taking the product of the squares of all elements?","['group-theory', 'abstract-algebra', 'finite-groups', 'products']"
3339712,Fully simplifying $\sqrt{13+2\left(\sqrt{2}-\sqrt{10}-\sqrt{20}\right)}$,"I have this statement: Simplify this: $\sqrt{13+2\left(\sqrt{2}-\sqrt{10}-\sqrt{20}\right)}$ I know how to simplify roots like $\sqrt{a \pm k\sqrt{b}}$ , But i don't know how to simplify this. Any hint for an elegant solution is appreciated.",['algebra-precalculus']
3339752,Local idempotents in a von Neumann regular rings,"Let $R$ be a commutative ring with identity. Recall that an idempotent element $e$ of $R$ is an element a such that $e^2=e$ , and a local idempotent is an idempotent a such that $Re$ is a local ring. Also, a  von Neumann regular ring is a ring $R$ such that for every $a$ in $R$ there exists an $x$ in $R$ such that $a = axa$ . I am looking for a characterization of local idempotents in a von Neumann regular ring. Any hint is appreciated","['idempotents', 'algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3339769,marginal likelihood in variational bayes,"In this paper, https://arxiv.org/abs/1312.6114 I have some questions regarding equation 1 and 2 equation one starts with The marginal likelihood is composed of a sum over the marginal lieklihoods of individual datapoints $\log p_\theta(x^{(1)}, ..., x^{(n)}) = \sum_{i=1}^N \log p_\theta(x^{(i)})$ which can be rewritten as... $$
\log p_\theta(x^{(i)}) = D_{KL}(q_\phi(z|x^{(i)}) || p_\theta(z|x^{(i)}))+ \mathcal{L} (\theta, \phi; x^{(i)})
$$ How is this the same as marginal likelihood . I've been looking at this equation for quite some time and I can't reason through it like I can with standard marginal likelihood. The only thing I have been able to deduce from it (I think) is that the two terms on the RHS of the equation will be negatively correlated because as the divergence gets smaller, the likelihood of them both goes up and vice versa, correct? In the second equation, the author makes a statement about the likelihood and I also don't see how that came about... $$
\log p_\theta(x^{(i)}) \ge \mathcal{L}(\theta, \phi; x^{(i)}) = \mathbb{E}_{q_\phi(z|x^{(i)})} \big[ -\log q_\phi(z|x) + \log p_\theta(x,z) \big]
$$ Why is this equal to the joint likelihood of $\theta$ and $\phi$ ? Why is the input to $q_\theta$ different (joint) than that of $q_\phi$ which is conditional?","['statistical-inference', 'statistics', 'bayesian', 'machine-learning', 'bayes-theorem']"
3339783,How to calculate this definite integral $\int_0^1\frac{{\ln^4 x }}{1+x^2}dx=\frac{5\pi^5}{64}$,"$$\displaystyle\int_0^1\dfrac{{\ln^4 x}}{1+x^2}\text{d}x=\dfrac{5\pi^5}{64}$$ let $x=e^{-t}$ ， $$
\displaystyle\int_0^1\dfrac{({\ln x})^4}{1+x^2}\text{d}x=\displaystyle\int_0^{+\infty}\dfrac{t^4\text{e}^{-t}}{1+\text{e}^{-2t}}\text{d}t=\displaystyle\sum_{k=0}^{\infty}(-1)^k\displaystyle\int_0^{+\infty}t^4\text{e}^{-(2k+1)t}\text{d}t. 
$$ let $u=(2k+1)t$ ， $$
\displaystyle\sum_{k=0}^{\infty}(-1)^k\displaystyle\int_0^{+\infty}t^4\text{e}^{-(2k+1)t}\text{d}t=\displaystyle\sum_{k=0}^{\infty}\dfrac{(-1)^k}{(2k+1)^5}\Gamma(5)=24\displaystyle\sum_{k=0}^{\infty}\dfrac{(-1)^k}{(2k+1)^5}. 
$$ I don't know how to solve this series. So how can I solve this series? And is there any other ways to solve this definite integral. Thank you.",['integration']
3339810,"Customers arrive as Poisson process, while served exponentially. (Poisson process problem)","Suppose customers arrive in a 24hour cashier according to a Poisson process, at rate $\lambda$ (per hour), while their service time is exponential, of parameter $\alpha$ (independent from each other). Customers are served one at a time. Let $X_n$ be the number of customers in line, waiting to be served, when the $n$ -th customer arrives. 1) Find the transition probabilities of $\{X_n\}$ . 2) Find the limit distribution (if exists). 3) What is the probability $k$ customers wait in line at 10.00 in the morning? Attempt. 1) Since $X_{n+1}=X_n+1-E_{n+1}$ , where $E_n$ is the number of customers served between the $n-1$ -th and $n$ -th customer arrival, we get: $$p_{k,m}=P(E_{n+1}=k+1-m)=\left(\frac{\alpha}{\alpha+\lambda}\right)^{k+1-m}\frac{\lambda}{\alpha+\lambda}$$ for $k=0,1,2,\ldots$ and $m=0,1,\ldots,k+1.$ 2) Do we seek the limit as $n\to +\infty$ of $p(X_{n}=m|X_0=k)$ ? If so, i am not sure how to approach this. 3)  I am not sure how to approach this, either. I am having a difficulty turning the problem in terms of $X_n.$ Thanks in advance for the help.","['exponential-distribution', 'stochastic-processes', 'poisson-process', 'probability']"
3339822,Proving that $5^n - 1$ is divisible by $4$ by mathematical induction.,"I have done it, but I am not sure that the inductive step is right. Can anybody please clear me about it? Basic steps as: Taking $n=1$ : $p(1)=5-1=4$ . Inductive hypothesis:  Assume the statement is true for $p(k)$ . $5^k - 1$ is divisible by $4$ . Inductive steps: We must show $p(k+1)$ is true when $p(k)$ is true. \begin{align*}
& 5^k -1 + 5^{k+1} -1\\
& 5^k -1 + 5.5^{k} -1\\
& (5^k -1) + 4
\end{align*}","['induction', 'discrete-mathematics']"
3339861,Prove that $\lim_{n \to \infty} \int_0^1{nx^nf(x)}dx$ is equal to $f(1)$.,"$\mathbf{Question}:$ Let $f$ be a continuous function on $[0,1]$ . Then prove that the limit $\lim_{n \to \infty} \int_0^1{nx^nf(x)}dx$ is equal to $f(1)$ . $\mathbf{Attempt}$ : First, we try to show that the sequence of functions $\{nx^nf(x)\}_{x\in [0,1]}$ is uniformly convergent to $0$ on the restricted domain $[0,1-\epsilon]$ , $0<\epsilon<1$ . Let $\sup_{x\in[0,1]}f(x)= \mathcal{M}$ . Then $|{nx^nf(x)}|\leq n(1-\epsilon)^n|\mathcal{M}|$ for any $x$ and $n(1-\epsilon)^n \to 0$ as $n\to \infty$ . Thereby, $\lim_{n \to \infty}\int_0^{1-\epsilon}nx^nf(x)dx=\int_0^{1-\epsilon}{\lim_{n \to \infty} }nx^nf(x)dx=0$ Now, denote $\sup_{x\in [1-\epsilon,1]} f(x)=M(\epsilon)$ and $\inf_{x\in[1-\epsilon,1]}f(x)=m(\epsilon)$ . $\int_{1-\epsilon}^1nx^n\ m(\epsilon)dx\leq\int_{1-\epsilon}^{1}nx^nf(x)dx\leq \int_{1-\epsilon}^1 nx^n\ M(\epsilon)dx$ . Now, $\lim_{n \to \infty}\int_{1-\epsilon}^1 nx^n\ M(\epsilon)dx =\displaystyle \lim_{n\to\infty}\bigg[ \frac{nx^{n+1}}{n+1}M(\epsilon)\bigg]_{1-\epsilon}^1=M(\epsilon)$ [Similarly the other one is $m(\epsilon)$ ] Clearly, as $\epsilon \to 0 , \ \ M(\epsilon), m(\epsilon) \to f(1)$ , so $\lim_{n \to \infty} \int_0^1{nx^nf(x)}dx=f(1)$ . Is the procedure correct? Kindly verify.","['sequence-of-function', 'proof-verification', 'real-analysis', 'uniform-convergence', 'limits']"
3339895,Continuity of Weak Solutions to Navier-Stokes Equations at $t = 0$ in $L^2$,"The following definitions/theorems/etc come from this paper , by Masuda, 1984. Statement of the Navier-Stokes Problem For $n \geq 3$ , let $\Omega \subseteq \mathbb{R}^n$ , $T > 0$ . We write the incompressible NS equations as follows: (NS) $\begin{cases} \text{d}_t u - \Delta u + (u \cdot \nabla) u + \nabla p = f; \ \nabla \cdot u = 0, \ x \in \Omega, \ 0<t<T \\ u|_{\partial \Omega} = 0 ; \ u|_{t=0} = a  
\end{cases}$ Where $u : \Omega \times [0,T) \rightarrow \mathbb{R}^n$ is the unknown vector velocity, $ p : \Omega \times [0,T) \rightarrow \mathbb{R}^n$ is the unknown pressure, $ f : \Omega \times [0,T) \rightarrow \mathbb{R}^n $ is a given external force, and $a:\Omega  \rightarrow \mathbb{R}^n$ is the given initial velocity. Function Spaces \begin{align}
C^{\infty}_{0, \sigma}(\Omega)
& := \{ f \in C^{\infty}_{0}(\Omega)^{n} \ | \ \nabla \cdot f = 0 \} \\
L_{\sigma}^{2}(\Omega)
& := \overline{C^{\infty}_{0, \sigma}(\Omega)}^{||\cdot||_{L^2}} \\
H^1(\Omega) = W^{1,2}(\Omega)
& := \{ f \in L^2 \ | \ \partial_{x_i} f \in L^2, \ i=1,...,n \} \\
H^{1}_{0,\sigma}(\Omega)
& := \overline{C^{\infty}_{0, \sigma}(\Omega)}^{||\cdot||_{H^1}} \\
Y
&:= H^{1}_{0,\sigma}(\Omega) \cap L^n
\end{align} Assumptions on $a$ and $f$ (1.) $a \in L^2_\sigma$ (2.) $f(\cdot , t) \in L^2$ for almost all $t \in (0,T)$ , and $Pf \in L^1(0,t ; L^2_\sigma)$ , where $P$ is the Helmholtz projection from $L^2$ into $L^2_\sigma$ . Definition of Weak Solution A weak solution of (NS) is a function, $u$ , on $\Omega \times [0,T)$ such that: (1.) $u \in L^2(0,T' ; H^{1}_{0,\sigma})$ , for all $T' \in (0,T)$ (2.) $u \in L^{\infty}(0,T ; L^{2}_{\sigma})$ (3.) $\int^s_{r} -(u,\partial_{t}\Phi) + (\nabla u , \nabla \Phi) + (u \cdot \nabla u, \Phi) \text{d}t = \int^s_r (f, \Phi) \text{d}t - (u(s), \Phi(s)) + (u(r), \Phi(r))$ for all $0 \leq r \leq s < T$ and all $\Phi \in H^1(r,s; Y)$ . Theorem (Masuda, 1984) There exists a weak solution, $u$ , of (NS). In particular, this function is weak continuous in $L^2_\sigma$ with respect to $t \in [0,T)$ , and $||u(t)||^2_{L^2(\Omega)} + 2 \int^{s}_{0} ||\nabla u(t)||^{2}_{L^2(\Omega)} \text{d}t \leq 2 \int^{s}_{0} (f, u) \text{d}t + ||a||^{2}_{L^2(\Omega)}$ for all $0 \leq t < T$ (Energy Inequality) and $\lim_{t \rightarrow 0}||u(t) - a||_{L^2(\Omega)} = 0 \ \ \ $ (Continuity at $t=0$ ) Here, $(u,f)$ denotes the inner-product of $u$ and $f$ in $L^2(\Omega)$ . That is, $(u,f) = \int_{\Omega} u \cdot f \ \text{d}x$ . We explain the meaning of weak continuity of $u$ . $u$ is weakly continuous in $L^2(\Omega)$ with respect to $t \in [0,T)$ if: $(u(t), g) = \int_{\Omega} u(t) \cdot g \ \text{d}x$ is continuous in $t$ , for all $g \in L^2_\sigma$ . Proof of Existence (Outline) (Please feel free to skip this and see the remaining problem of continuity at $t=0.$ ) I have proven the existence of a weak solution, $u$ , as described in the definition above. I have also shown that this $u$ is weakly continuous in $L^2_\sigma$ with respect to $t$ and satisfies the Energy Inequality. We prove this using a Galerkin Method. We find a countable set $\{\phi_l \}_{l=1}^{\infty} \subseteq C^{\infty}_{0,\sigma}$ whose span is dense in $Y$ and in $L^{2}_{\sigma}$ (with respect to their respective norms). We then define $u_{m}(x,t) = \sum^m_{l=1} c_{ml}(t) \phi_{l}(x)$ , where $c_{ml}$ are solutions in $C^1(0,T)$ to the below locally Lipschitz ODE: \begin{cases}\text{d}_t c_{ml} + \sum^m_{i=1} (\nabla \phi_{i} , \nabla \phi_{l})c_{mi} + \sum^m_{i,j=1} (\phi_i \nabla \phi_{j} , \nabla \phi_{l})c_{mi}c_{mj} = (f,\phi_l), \ \text{for all } l=1,...,m \\
c_{ml}(0) = (a, \phi_l), \ \text{for all } l=1,...,m.
\end{cases} We find that these $u_m$ are uniform bounded in $L^2(0,T' ; H^{1}_{0,\sigma})$ , for all $T' \in (0,T)$ and in $L^{\infty}(0,T ; L^{2}_{\sigma})$ . Thus, since these are Hilbert spaces, there exists subsequences which converge weakly. It is easy to show that $u_m$ convergese to the same function, $u$ , in both spaces. Thus we have satisfied (1.) and (2.) from the definition of Weak Solutions. We can use Arzela-Ascoli to show that this $u$ is weak continuous, as described above. See this previous question for details on the weak convergence and weak continuity of $u$ . Using the weak convergence and definition of $u_m$ , we show that this $u$ satisfies the Energy Inequality. Using weak convergence and several Lemmas from Masuda's paper, we show that $u$ satisfies the integral equation (3.) from the definition of Weak Solutions. Last Remaining Problem, Continuity in $L^2$ at $t=0$ It remains only to show that $\lim_{t \rightarrow 0}||u(t) - a||_{L^2(\Omega)} = 0$ . In fact, Masuda makes no mention of this property in his proof of the theorem!!! We know that $u$ is weakly continuous with respect to $t$ , as explained above. Also, by the definition of $u_m$ , each $u_m$ is continuous with respect to $t$ . That is, $u_m \in C((0,T); L^2_{\sigma})$ , for all $m$ . I suspect this should be enough to obtain the final result, but I am struggling to show it without requiring uniform continuity. Here is my initial attempt to prove: $\lim_{t \rightarrow 0}||u(t) - a||_{L^2(\Omega)} = \lim_{t \rightarrow 0}(u(t) - a, u(t) - a) $ $ = \lim_{t \rightarrow 0} \lim_{m \rightarrow \infty}(u(t) - a, u_{m}(t)) - (u_{m}(t) - a, a)$ By an earlier step in the existence proof, we know that $(u_{m}(t), g)$ converges as $m \rightarrow \infty$ uniformly with respect to $t$ . (Again, see this previous question for details.) Thus the term on the right, $(u_{m}(t) - a, a)$ , converges uniformly with respect to $t$ . Therefore, we are able to swap the position of the limits in $t$ and $m$ . By definition of $u_m$ , it is clear that $\lim_{m \rightarrow \infty} ||u_m(t=0)||_{L^2(\Omega)} = ||a||_{L^2(\Omega)}$ , so the term on the right vanishes. We are stuck with the term on the left, $\lim_{t \rightarrow 0} \lim_{m \rightarrow \infty}(u(t) - a, u_{m}(t))$ . As demonstrated in another previous question , we know that, for each fixed $m$ , this is continuous in $t$ . So we would be able to show that this term vanishes, if we are able to swap the limits in $t$ and $m$ . I know we could do this if we have uniform convergence again, but I am not sure if this is possible, as we now have dependence on $t$ for both sides of the inner-product. We do have uniform boundedness of this term, as the $u_m$ are uniformly bounded in $L^2(0,T' ; H^{1}_{0,\sigma})$ , for all $T' \in (0,T)$ and $L^{\infty}(0,T ; L^{2}_{\sigma})$ , so we could obtain uniform convergence by showing equicontinuity. But I'm not sure if this can be done. In short, the question is as follows: can we swap the limits in $t$ and $m$ in $\lim_{t \rightarrow 0} \lim_{m \rightarrow \infty}(u(t) - a, u_{m}(t))$ ? Or is there another way to show that $\lim_{t \rightarrow 0}||u(t) - a||_{L^2(\Omega)} = 0$ ?","['weak-convergence', 'real-analysis', 'lp-spaces', 'functional-analysis', 'partial-differential-equations']"
3339913,Inscribing equilateral triangles in convex curves,"I'm interested in solving the following problem (Problem 12-5 of ""Introduction to Analysis"" by Arthur Mattuck). Although the problem reads ""Show convincingly"", I'm after a rigorous proof. Let $C$ be a smooth, convex, closed curve, i.e., one without endpoints, and such that a line segment joining any two points on $C$ lies inside $C$ . (An ellipse or an oval are examples. ""Smooth"" means it has a tangent line at each point.) Let $P$ be any point on $C$ . Show convincingly that you can always find two other points $Q$ and $R$ on $C$ such that $PQR$ is an equilateral triangle. (Try some sketches.) My attempt: Let us denote by $D$ the region inside of $C$ , and let $\mathcal{T}_P$ denote the set of all equilateral triangles, one of the vertices of which being $P$ . I considered then the set $$S:=\{a \geqslant 0: \text{there exists a triangle $\Delta \in \mathcal{T}_P$ with side length $a$, contained entirely in $\overline{D}$}\}. $$ I tried showing that $S$ is a closed interval of the form $[0,d]$ , and then showing that a maximal triangle of side length $d$ must be touching the curve at three points. However, I couldn't complete the argument. I understand that being an introductory textbook, it is not expected from a reader to provide a rigorous proof here, but I'm curious to see what such a proof would like. I would appreciate any help with this problem. Thanks.","['calculus', 'geometry', 'differential-geometry']"
3339920,Proof Verification for the range of $f$ given certain conditions,"Question: A function $f : ℕ \rightarrow ℕ$ is defined by $f(1)=1$ , and for all $n\geq 1$ , $$f(2n)=f(n)$$ $$f(2n+1)=f(n)+f(n+1)$$ Prove that the range of $f$ is $ℕ$ . I had previously asked about this here: For $f:\mathbb{N}\to\mathbb{N}$ with $f(1)=1$, $f(2n)=f(n)$, $f(2n+1)=f(n)+f(n+1)$, show that the range of $f$ is $\mathbb{N}$ Considering all the answers that the users gave, I have come up with the following proof for the problem: ""To show that the range of f is $ℕ$ , we must make use of the fact that $f(2^n) = 1$ for all non-negative integers n. This is true because $f(2^n)=f(2^{n-1})=f(2^{n-2})=\cdots=f(1)=1$ . For example: $f(8)=f(4)=f(2)=1$ as $f(2n)=n$ Using this, we will prove that $f(2^n+1)=n+1$ for all $n\geq1$ . A base case for this would be n=0: $f(2^0+1)=f(1+1)=f(2)=f(1)=1$ , with the end result, 1, being equal to n+1 (in this case, 0+1) Next, suppose that we already know that $f(2^n+1)=n+1$ . Through induction, it suffices to show that $f(2^{n+1}+1)=n+2$ . Since $2^{n+1}+1$ is odd, we have: $f(2^{n+1}+1)=f(2^n)+f(2^n+1)=1+(n+1)=n+2$ . The second part of the equality above was reached using the fact that $f(2n+1)=f(n)+f(n+1)$ . This completes our induction. We have shown that $f(2^n+1)=n+1$ for all positive integers (including 0). Also, $f(1)=1$ , which further supports 1 being in the range of $f$ . Hence, the range of $f$ is $ℕ$ ."" Is this a strong proof? Do I need to add more details? I'm open to any suggestions!","['functions', 'proof-verification']"
3339932,A truncated alternating sum of product of binomial terms,"While solving a question I came across the following alternating sum; $C(j,n): = \sum\limits_{i=j}^{n} (-1)^{i}\binom{n+1}{i+1} \binom{i}{j}$ where $j$ and $n$ are integers with $n \geq j \geq 0$ . By hand I computed that $C(j, j+r) = (-1)^{j}$ for small positive integers $r$ . I think that $C(j,n) = (-1)^j$ for any $n \geq j \geq 0$ . But I couldn't prove it by induction or by using some other known identities. I would appreciate any suggestion or reference.","['binomial-coefficients', 'combinatorics']"
3339949,"Find the maximum of $\int_{\gamma} (x^2y-2y)dx + (2x-xy^2)dy$, and find the curve $\gamma$ that gives it.","The task is to find the maximum of $$\int_{\gamma} (x^2y-2y)dx + (2x-xy^2)dy$$ when $\gamma$ is a smooth, regular, closed and simple curve in $\mathbb{R}^2$ , and $\gamma = \partial G$ for a bounded domain $G$ . Also $\gamma$ is with positive orientation. Moreover, I need to find the curve $\gamma$ that gives the maximum. It's seems obvious to me to use Green's theorem here. 
I denote $$\omega  = (x^2y-2y)dx + (2x-xy^2)dy$$ and then: $$\int_{\gamma} \omega = \int_G (2-y^2-x^2+2)dxdy = \int_G (4-(x^2+y^2))dxdy$$ Now, since $x^2+y^2>0$ , the it seems to me that the maximum is $4*vol(G)$ , but I am not entirely sure, since it depends on $G$ . Moreover, I was not able to find a curve $\gamma$ that gives me this result. Help would be appreciated.","['curves', 'multivariable-calculus', 'greens-theorem', 'differential-forms']"
3339953,Examples of topological groups that are not metrizable.,"I am looking for examples of topological groups but most are metrizable likes real numbers etc. Then there are Lie groups that I am not familiar with. Are there any simple enough to understand examples of non metric topological groups, or topological rings? How about ordered square or long line, can they be turned into a  topological group?","['general-topology', 'topological-groups']"
3340073,Notation problem for Gaussian Distribution. Vertical Bar,"In ""Gaussian Process Latent Variable Models forVisualisation of High Dimensional Data"" by Lawrence I stepped over the following definitions of Gaussian Distributions: $p(x) = N(x|0,I)$ $p(y|x,W,\beta) = N(y|Wx,\beta^{-1}I)$ $\rightarrow$ Full definition What is the meaning of the vertical Bar in $N(\cdot|\cdot,\cdot)$ ? And what are the actuall mean $\mu$ of the distrubutions?","['statistics', 'normal-distribution', 'notation', 'machine-learning', 'probability']"
3340166,Evaluate: $\left(\frac{\partial }{\partial x}+\frac{\partial }{\partial y}+\frac{\partial }{\partial z}\right)^2u$,"If $u=\ln(x^3+y^3+z^3-3xyz)$ , show that $$\bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u=\dfrac{-9}{(x+y+z)^2}$$ I don't know how to interpret $\bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u$ . If $$\bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u=\dfrac{\partial ^2u}{\partial x^2}+\dfrac{\partial ^2u}{\partial y^2}+\dfrac{\partial ^2u}{\partial z^2}+2\dfrac{\partial ^2u}{\partial x\partial y}+2\dfrac{\partial ^2u}{\partial y\partial z}+2\dfrac{\partial ^2u}{\partial z\partial x}$$ then is there any form of theory or properties regarding this, because I don't want to calculate every term and plug it into the giant expression. I also observe that I can made the given problem into the homogenous function of degree $3$ . Is that useful? Please help.","['partial-derivative', 'multivariable-calculus', 'logarithms']"
3340183,Irrational Integral,I've tried in many ways to compute this integral but I'm not able to find any solution. Even Wolfram can not compute this. So my question is: Is that even possible to compute? $$\int { \frac { dx }{ 1+\sqrt { x } +\sqrt { x+1 } +\sqrt { x+2 }  }  }$$,"['integration', 'indefinite-integrals', 'real-analysis']"
3340235,"Show that the volume of the polyedron ${x=(x_1,x_2,⋯,x_n)\in \mathbb{R^{n}} ; 0 \leq x_i \leq 1, \ x_1+x_2+...+x_n\leq (n/2)}$ is $1/2$","Show that the volume of the polyedron $ (x_1,x_2,⋯,x_n)\in \mathbb{R^{n}};0  \leq x_i \leq 1, \ x_1+x_2+...+x_n\leq (n/2)$ is $1/2$ I've seen a lot of ways to calculate the volume of an n-simplex, but on polyhedra of this type I can't find anything .. the article I'm studying comments on using integration and changing variable but if anyone knows any way to calculate, I'll be grateful :) ..","['convex-geometry', 'calculus', 'polyhedra', 'geometry']"
3340256,Is there a ring in which the pairwise intersection of maximal ideals is the Jacobson radical,"Does there exist a commutative ring with unity such that the pairwise intersection of distinct maximal ideals is the Jacobson radical? Ie. if $M_1, M_2$ are any pair of distinct maximal ideals then $M_1 \cap M_2 = J(R)$ . And if that is false, is there a ring, $R$ and $a$ such that any collection of maximal ideals $|M| \geq a$ satisfies $\bigcap M = J(R)$ . Or more weakly is there a subset of maximal ideals such that the above is true even if it is not true for every maximal ideal. I know the case where $a$ is finite fails when $R$ is semiprimitive and is trivially true for rings with at most $a$ maximal ideals but I am unable to find an answer otherwise.","['ring-theory', 'group-theory', 'abstract-algebra', 'commutative-algebra']"
3340273,Does almost sure convergence imply uniform boundedness,"Let $(X_{n})_{n},X$ be random variables and assume $P(X_{n}\to X)=1$ Until now I have always assumed that the sequence is uniformly bounded, i.e. there exists $k > 0$ so that $P(\sup\limits_{n}\vert X_{n}-X\vert<k)=1(*)$ but in a solution, $P(X_{n}\to X)=1$ was mentioned as an additional assumption to $(*)$ . Does this mean almost sure convergence does not imply uniform boundedness? and what about $P(\sup\limits_{n}\vert X_{n}\vert<k)$ ? Is it implied that it is  almost surely uniformly bounded from almost sure boundedness?","['measure-theory', 'real-analysis', 'uniform-convergence', 'probability-theory', 'random-variables']"
3340316,How to interpret a double integral?,"What can be the geometrical meaning of $$ \iint_R dA ~~~~~~~~~~ (1)$$ ? It is the particular case of $$\iint_R {f(x,y)} dA$$ where $f(x,y) = 1 $ . What I have found from my search is that (1) represents the area of the region R which is quite intuitive : if we have an area element which is a function of two variables then we must have to integrate it twice to get the area of the region. But if we see it from a different view point then it is the volume under the plane $z=1 $ and above the region R. Well, we can even extend this to triple integrals where $$ \iiint_S dV $$ represents the volume. The thing which is causing the doubt is the substitution of $ f(x,y)$ or $f(x,y,z)$ with $1$ . So, which interpretation is correct? Am I wrong somewhere in the very essence? Any help will be much appreciated.","['multivariable-calculus', 'surface-integrals']"
3340509,Alligator population,Hints only. I feel like I am so close. Population growth: The time rate change of an alligator population $P$ in a swamp is proportional to the square of $P$ . The swamp contained a dozen alligators in $1988$ and $2$ dozen in $1998$ $$\frac{dp}{dt} = kp^2$$ $$\int \frac{dp}{p^2} = \int k$$ $$ \frac{p^{-2+1}}{-2+1} = tk + C$$ $$ -\frac{1}{p} = tk+C$$ Use $P(0) = 12$ to solve for C. $$-\frac{1}{12} = C$$ $$p(t) = -\frac{1}{tk - \frac{1}{12}}$$ Use $P(10)=24$ to solve for k: $$24 = -\frac{1}{10k-\frac{1}{12}}$$ $$10k -\frac{1}{12} = -\frac{1}{24}$$ $$k = \frac{1}{240}$$ Now solve for $t$ with $P(t)=48$ $$48=-\frac{1}{\frac{t}{240}-\frac{1}{12}}$$ $$\frac{t}{240} - \frac{1}{12} = -\frac{1}{48}$$ $$\frac{t}{20}-1=-3$$ $$\frac{t}{20}=-2$$ $$t=-40$$ Which is obviously wrong. I assume that t should in-fact represent 1 year even though our information is given in increments of 10. I am very sure my set-up is correct and I integrated correctly...,['ordinary-differential-equations']
3340541,proving that $a + b \sqrt {2} + c \sqrt{3} + d \sqrt{6} $ is a subfield of $\mathbb{R}$,"The question is given below: My questions are: 1- How can I find the general form of the multiplicative inverse of each element? 2-How can I find the multiplicative identity? 3-Is the only difference between the field and the subfield definition is that in the case of a subfield every nonzero element has an additive identity but in the field every element not only nonzero ones? Could anyone help me in understanding these questions, please? EDIT: I have found this solution on the internet: My question : is that a fully acceptable answer to the question? I guess yes.","['abstract-algebra', 'linear-algebra']"
3340545,Intuition for Freudenthal Suspension,"One version of the Freudenthal suspension theorem is the following: Suppose a CW complex $X$ is a union of two subcomplexes $A,B$ with $A\cap B\neq\emptyset$ connected and nonempty. If $(A,A\cap B)$ is $m$ -connected and $(B,A\cap B)$ is $n$ -connected, then $$\pi_k(A,A\cap B)\cong \pi_k(X,B)$$ for $k<m+n$ . Further, $\pi_{m+n}(A,C)$ surjects onto $\pi_{m+n}(X,B)$ . One can find proofs of this in Hatcher (theorem $4.23$ ) and Dieck (proposition $6.4.1$ ). My goal is to find some intuition for why this is true. The corresponding statement in homology is excision, and the proof is fairly intuitive (although tedious). To show $$H_n(A,A\cap B)\cong H_n(A\cup B,B),$$ one can pretty easily hand-wave that, after subdivision, simplices in $A$ but not $A\cap B$ are the same as simplices in $A\cup B$ but not $B$ . Hatcher's proof of Freudenthal suspension is vaguely reminiscent of this subdivision argument as well. By analogy, I have some intuition for why we have $\pi_k(A,A\cap B)\cong \pi_k(X,B)$ . My main (soft) questions are the following: What is it about homotopy groups that makes excision fail in the first place? There are examples here, but I still can't really visualize them. What is the significance of $m+n$ ? This is my biggest source of confusion, because I really can't come up with any hand-waving argument that justifies the appearance of $m+n$ . The best hand-waving I have come up with is fairly pathetic: take a map $(D^{m+n},\partial D^{m+n})\to (X,B)$ , and apply some simplicial structure so that the map is locally linear. Since $(A,A\cap B)$ is $m$ -connected, you need to use $m+1$ of the dimensions to get into $A\setminus A\cap B$ (whatever that means). But then there are $n-1$ dimensions left, so they must map into $A\cap B$ . I don't even expect that to make sense to other people, and the dimensions are still off by one anyway. Your thoughts are appreciated!","['cw-complexes', 'homotopy-theory', 'intuition', 'general-topology', 'soft-question']"
3340563,Evaluate $\sum\limits_{n=0}^{\infty} \frac{\cos(nx)}{2^n}$ where $\cos x = \frac15$,Evaluate $$\sum_{n=0}^{\infty} \dfrac{\cos(nx)}{2^n}$$ where $\cos x = \frac{1}{5}$ . This is a complex number question. But I don’t know where to start. Maybe need to use the DeMoivre’s Theorem?,"['trigonometry', 'complex-numbers', 'sequences-and-series']"
3340599,Odd Set Notation (Square Brackets),"I'm going through Arithmetics in extensions of $\textbf Q$ and I've come across this notation a few times (i.e. $\textbf Z[i]$ or $\textbf Z[w]$ ). ""Let $\alpha$ be an algebraic integer and $p(x)$ be its minimal (monic) polynomial $$p(x)=\sum_{i=0}^{n} a_ix^i $$ Such that $p(\alpha) = 0$ and $a_i \in \textbf Z$ ( $\textbf Z$ is the set of integers) and $a_n = 1$ . ""The extension of a ring $A$ by the element $a$ is the set $A[\alpha]$ of all complex numbers of the form $$\sum_{j=0}^{n-1} c_j\alpha^j $$ such that $c_j \in A$ , with all the operations inherited from $A$ . ""The degree of the extension is the degree  of the polynomial."" I completely understand the 'algebraic integer' and the 'minimal polynomial' and the concept of set/ring extension, at least I think. My issue is mostly with the middle sentence; when it says 'all the complex numbers of form', but isn't there only one minimal polynomial so there's only one element in the set $A[\alpha]$ ? Is that single element basically just $p(\alpha) - x^n$ ? Or are the $c_j$ related to the $a_i$ at all? The same $n$ is mentioned twice. If not then why introduce $p(x)$ at all? And what is ring $A$ ? Is that an initially empty set? And what does 'all the operations inherited from $A$ ' mean? Honestly, I can't find an explanation online for the $A[\alpha]$ sort of notation or any of my other questions online? P.S. I know that $\textbf Z[i]$ represents the Gaussian integers which kind of makes sense since but not entirely for the same reasons as mentioned above.","['elementary-set-theory', 'arithmetic', 'notation']"
3340608,Coordinate rings of entire affine n-spaces when the underlying field is finite,"Let $k$ be a field and $V\subseteq k^n$ be an affine variety. We identify the coordinate ring $k[V]$ as the quotient ring $k[x_1,\cdots ,x_n]/I(V)$ . In a lot of texts on algebraic geometry, when $V=k^n$ , then the coordinate ring $k[k^n]$ is identified as the polynomial ring $k[x_1,\cdots ,x_n]$ This definition makes sense when the field is infinite. In that case, $I(V)=\{0\}$ , so every equivalence class in $k[x_1,\cdots ,x_n]/I(V)$ has exactly one element, hence $$k[k^n]\cong k[x_1,\cdots ,x_n]/\{0\}\cong k[x_1,\cdots ,x_n]$$ But what if $k$ is finite? Take $n=1$ and $k=\mathbb{F}_2$ . Consider the equivalence class $[0]$ in $\mathbb{F}_2[x]/I(\mathbb{F}_2)$ . Since the functions $f=x^2+x$ and $g=x^4+x^3+x^2+x$ (and more) vanish on $\mathbb{F}_2$ , we must have the equivalence class $[0]$ has more than one element (in fact, infinitely many) In this case, is it still appropriate to identify the coordinate ring to the polynomial ring? I asked this because none of the texts online explain this ambiguity of the identification",['algebraic-geometry']
3340633,Not sure how to answer this statistics question or if I understand what is being asked.,"The first question is what I am unsure about.  I don't know if it is asking what is actually unusual (like the grade value having 100 as the mean) about the test or if it is asking something else like what is rare (unusual because of how small the number is) about the p-value. A new standardized test is required to have a µ = 100 and σ = 10. A class of 30 students completed the test with a mean grade of 95.  Conduct a hypothesis test at α = .05 to determine whether the claim that µ = 100 can be supported using the p-value approach and complete the following. What is unusual about this hypothesis test? (All other questions aside from this one seem to be straightforward, am I overthinking this?) State the null and alternative hypotheses in words and in statistical symbols. What statistical test should be used and why? What is the value of the test statistic and the p-value of that outcome? Interpret the outcome in terms of the original claim.","['statistics', 'hypothesis-testing']"
3340648,Are Cumulative Distribution Function for a Continuous Random Variable Left Continuous also?,"I was reading the book ""probability random variables and stochastic processes by Athanasios Papoulis - Third Edition"" where by in the properties of distribution functions on Page 69 of the book the fifth(5th) point mentions that Cumulative Distribution Function are right continuous in general(for discrete and continuous random variable). But I have a doubt whether we can say that: Cumulative Distribution Function are both left and right continuous for continuous random variables in general or not?","['probability-distributions', 'probability-theory', 'probability']"
3340654,Autonomous equilibrium points,"Given $$\frac{dx}{dt}= 3x-x^2$$ I don't understand how $$x=0$$ is not semistable. I get the following 0 points: $$x = 0, x = 3$$ Here are the values of $\frac{dx}{dt}$ I get when plugging in and my reasoning: $-3 \to -18$ $-2 \to -10$ $-1 \to -4$ It would seem to me that clearly the slope gets closer to zero as we go up and would have the curve going up and arcing to the right and then flattening out but no the book has the curve going the opposite direction.....doesnt make any sense at all $1 \to 2$ $1.5 \to 2.25$ $2 \to 2$ The slope increases then levels out and then goes down somehow giving an S shape between $x = 0$ and $x = 3$ Now for $6 \to -18$ $5 \to -10$ $4 \to  -4$ The slope gets nearer to zero as we near 3 so we get a kind of semi c shape going down and leveling out at $x = 3$ This turned out to be right. So I don't understand how my reasoning worked out in one instance but the same exact approach didn't work in the first part.",['ordinary-differential-equations']
3340670,"Solve $\sin x + \cos x = \sqrt{1+k}$ for $\sin 2x$, $\sin x-\cos x$, and $\tan x$ in terms of $k$","Given that $\sin x + \cos x = \sqrt{1+k}$ , $-1 \le k \le 1$ Find the value of $\sin 2x$ in terms of k Given that $x \in (45^{\circ}, 90^{\circ})$ deduce that $\sin x - \cos x = \sqrt{1-k}$ Hence, show that $\tan x = \dfrac{1 + \sqrt{1-k^2}}{k}$ Okay, I have figured out that $$ \sin^2 x + \cos^2 x + 2 \sin x \cos x  = 1+k \implies \sin 2x = k $$ Now, I am not sure what approach I should use to deduce the second one. And can somebody give me a hint on how to start with the third one?","['algebra-precalculus', 'trigonometry']"
3340675,How to prove that $\operatorname{Aut}(\mathbb C/\mathbb Q)$ is infinite?,How to Prove that $\operatorname{Aut}(\mathbb C/\mathbb Q)$ is infinite? I had already proved that $\operatorname{Aut}(\mathbb R/\mathbb Q)$ is trivial group containing identity use continuity argument. But When I thought about $\operatorname{Aut}(\mathbb C/\mathbb Q)$ problem I could not even start. I had just started course in field theory in which we have done Galois group definition and some example. Please give me hint so that I can solve the above problem.,"['field-theory', 'galois-theory', 'group-theory', 'abstract-algebra']"
3340723,How many ways to partition $n$ elements into two nonempty subsets?,"How can we find the total number of ways in which we can divide $n$ elements into two subsets such that none of them are empty and the union of both sets should be equal to the whole set? Eg. If $S=\{1,2,3\}$ , the answer can be $A=\{1,2\}$ , $B=\{3\}$ or $A = \{1,3\}$ and $B=\{2\}$ or $A=\{2,3\}$ and $B=\{1\}$ .","['group-theory', 'combinatorics', 'discrete-mathematics']"
3340766,"If $X_1,\ldots,X_n$ are i.i.d Exponential$(\theta)$, then $X_1/\bar{X}$ is an ancillary statistic","Here is what I have done so far: Consider the random vector $X=(X_1,\ldots,X_n)$ which has pdf $$f(x_1,\ldots,x_n; \theta)=\theta^n e^{-\theta(x_1+\cdots+x_n)}.$$ Let $Y=T(X)$ where $T$ be the transformation that sends $(x_1,...,x_n)$ to $(nx_1/(x_1+\cdots+x_n),x_2,x_3,\cdots,x_n)$ . The the pdf of $Y$ is $$\theta^n\frac{n(y_2+\cdots+y_n)}{(n-y_1)^2}\exp\left\{ \frac{n\theta(y_2+\cdots+y_n)}{n-y_1}\right\}.$$ Thus, to get the pdf of $X_1/\bar{X}$ I just need to integrate out the $y_2,...,y_n$ to show that the pdf is independent of $\theta$ . And this is where I got stuck. I have tried it with $n=2$ and it worked, but integrating out this $y_2,...,y_n$ , I got....lazy. :D Do you know a better way for this problem?","['statistics', 'probability-distributions', 'exponential-distribution']"
3340771,"$P(\mu \in (\bar{X} - 1/2, \bar{X} + 1/2))$ for Gauss distribution","Let $\bar{X}$ be the mean of a random sample of size $n$ from $N(\mu=u, \sigma^2 = 10)$ Find $n$ so that the probability is a approximately $0.954$ that the random interval $(\bar{X} - 1/2, \bar{X} + 1/2)$ includes $\mu$ . I began with $P(\bar{X} - 1/2 < u < \bar{X} + 1/2) = 0.954$ then I'm not sure as to where to go from there.","['statistics', 'confidence-interval', 'normal-distribution', 'hypothesis-testing']"
3340787,Weak form of Hilbert's Nullstellensatz (Atiyah-Macdonald),"I'm familiar with this formulation of the weak form of Hilbert's Nullstellensatz. If $k$ is an algebraically closed field, $I\in k[x_1,\dots,x_n]$ is an ideal. Then $V(I)=\varnothing$ if and only if $1\in\sqrt{I}$ . In Atiyah-Macdonald ""Introduction to Commutative Algebra"" the theorem is stated in a (probably) more general form (Corollary $7.9$ ): Let $k$ be a field, $A$ a finitely generated $k$ -algebra. Let $\mathfrak{M}$ be a maximal ideal of $A$ . Then the field $A/\mathfrak{M}$ is a finite algebraic extension of $k$ . In particular, if $k$ is algebraically closed then $A/\mathfrak{M}\simeq k$ . I would like to understand the connection between the two statements.","['algebraic-geometry', 'commutative-algebra']"
3340802,Can this system of equations have unique solutions?,"I have the equation: $$c=z[\sin(x)\sin(2\pi yt)-\cos(x)\cos(2\pi yt)]$$ Where $c$ has three known values, each of which is followed by a value for $t$ . Therefore one can be left with a system of three equations with three unknowns. Can this system have unique values ? In other words, can the system: $$c_1=z[\sin(x)\sin(2\pi yt_2)-\cos(x)\cos(2\pi yt_2)]$$ $$c_3=z[\sin(x\sin(2\pi yt_3)-\cos(x)\cos(2\pi yt_3)]$$ Where $c_1,c_2,c_3,t_1,t_2,t_3$ are all known be solved with unique 
solutions ? The values can be obtained with the help of a computer, no need to solve it manually, just want to know if it has unique solutions","['trigonometry', 'systems-of-equations']"
3340848,"Multivariable limit $\lim_{(x,y,z) \to (0,0,0)} \frac{2x^2+3y^2+z^2}{x^2+y^2+z^2}$","I am studying multivariable limits from the text Vector Calculus by S.J. Colley.
I practiced computing limiting values of the functions of two-variables $f(x,y)$ . Here's a problem involving a function of three variables. Compute the limit $$\lim_{(x,y,z) \to (0,0,0)} \frac{2x^2+3y^2+z^2}{x^2+y^2+z^2}$$ I thought to myself, this could be for example, the scalar potential of a field in space. So, it's fun to see if the function has a limit as we get closer and closer to the origin. I would like to ask, if my proof is mathematically correct. Solution. From solid analytical geometry, a straight line in $\mathbb{R^3}$ is: $\frac{x-x_0}{l}=\frac{y-y_0}{m}=\frac{z-z_0}{n}=r$ The straight line passing through the origin and having direction numbers $l,m,n$ is: $\frac{x}{l}=\frac{y}{m}=\frac{z}{n}=r$ So, along this straight line with direction numbers $l,m,n$ , our function takes on values $f(x,y,z)=f(r)=\frac{2r^2l^2+3r^2m^2+r^2n^2}{r^2l^2+r^2m^2+r^2n^2}=\frac{2l^2+3m^2+n^2}{l^2+m^2+n^2}$ Along the line $x=y,z=0$ , $f(x,y,z)=\frac{5}{2}$ Along the line $y=z,x=0$ , $f(x,y,z)=\frac{4}{2}=2$ Along the line $x=z,y=0$ , $f(x,y,z)=\frac{3}{2}$ Along the line $x=y=z$ , $f(x,y,z)=\frac{6}{3}=2$ Hence, $\lim_{(x,y,z) \to (0,0,0)\\\text{ along }x=y,z=0}\frac{2x^2+3y^2+z^2}{x^2+y^2+z^2}=\frac{5}{2}$ $\lim_{(x,y,z) \to (0,0,0)\\\text{ along }y=z,x=0}\frac{2x^2+3y^2+z^2}{x^2+y^2+z^2}=2$ $\lim_{(x,y,z) \to (0,0,0)\\\text{ along }x=z,y=0}\frac{2x^2+3y^2+z^2}{x^2+y^2+z^2}=\frac{3}{2}$ $\lim_{(x,y,z) \to (0,0,0)\\\text{ along }x=y=z}\frac{2x^2+3y^2+z^2}{x^2+y^2+z^2}=3$ Thus, the limit of this function does not exist as $(x,y,z) \to (0,0,0)$ .","['multivariable-calculus', 'proof-verification']"
3340858,Evaluating $\lim_{n \to \infty} \prod_{i=0}^{n-1} \left(\frac{n(n+1)}{2(n-1)} - i\right)^{n-i}$,"I am trying to find this limit. $$\lim_{n \to \infty} \prod_{i=0}^{n-1} \left(\frac{n(n+1)}{2(n-1)} - i\right)^{n-i}$$ I am not sure how to proceed. I tried to check out the values of the product for increasing values of $n$ and it looks like the limit oscillates between $+\infty$ and $-\infty$ for every 4 terms, so I believe the limit does not exist. I am not sure how I can prove that.","['limits', 'sequences-and-series']"
3340924,Stem and leaf diagrams,"I have the following data: $2.6$ $ $ $3.3$ $ $ $2.4$ $ $ $1.1$ $ $ $0.8$ $ $ $3.5$ $ $ $3.9$ $ $ $1.6$ $ $ $2.8$ $ $ $2.6$ $ $ $3.4$ $ $ $4.1$ $ $ $2.0$ $ $ $1.7$ $ $ $2.9$ $ $ $1.9$ $ $ $2.9$ $ $ $2.5$ $ $ $4.5$ $ $ $5.0$ Built stem and leaf plot: $Stem$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $Leaf$ $     $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $f$ $0$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $8$ $ $ $ $ $ $$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $$ $$ $ $ $$ $$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $$1$ $1$ $ $ $ $ $ $ $ $$ $ $ $ $ $ $ $ $ $ $ $ $1$ $ $ $ $ $ $ $6$ $ $ $ $ $ $ $7$ $ $ $ $ $ $ $9$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $4$ $2$ $ $ $ $ $ $ $ $ $ $ $ $ $0$ $ $ $4$ $ $ $5$ $ $ $6$ $ $ $6$ $ $ $8 \ $ $9$ $ $ $9$ $ $ $ $ $ $ $ $ $ $ $8$ $3$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $3$ $ $ $ $ $4$ $ $ $ $ $5$ $ $ $ $ $9$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $4$ $4$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $1$ $ $ $ $ $ $ $ $ $ $ $5$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $2$ $5$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $0$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $1$ My lecturer said that this is true: $P$ $(2\le$$X\le3)$ = ${8\over 20}$ $P$ $(1\le$$X\le6)$ = $1$ - ${1\over 20}$ = ${19\over 20}$ So, my question is: Why is he not adding the last number into the range? To me, since it is $""less $ $ than $ $  or $ $ equal $ $ to""$ this has to be: $P$ $(2\le$$X\le3)$ = ${12\over 20}$ $P$ $(1\le$$X\le6)$ = $1$ - ${0\over 20}$ = ${20\over 20}$ Does it have something to do with continuous or discrete data? Cause in another example he added the last number into the range.","['statistics', 'probability-distributions', 'probability-theory', 'probability']"
3340941,"Find the reflection of the point $(4,-13)$ in the line $5x+y+6=0$","Find The image(or reflection) of the point $(4,-13)$ in the line $5x+y+6=0$ Method 1 $$
y+13=\frac{1}{5}(x-4)\implies x-5y-69=0\quad\&\quad 5x+y+6=0\implies (3/2,-27/2)\\
(3/2,-27/2)=(\frac{x+4}{2},\frac{y-13}{2})\implies(x,y)=(-1,-14)
$$ Method 2 $m=\tan\theta=-5$ Ref $(\theta)$ = $\begin{bmatrix}
\cos(2\theta) & \sin(2\theta) \\ \sin(2\theta) & -\cos(2\theta)
\end{bmatrix}$ $$
\cos2\theta=\frac{1-\tan^2\theta}{1+\tan^2\theta}=\frac{1-25}{1+25}=\frac{-24}{26}=\frac{-12}{13}\\
\sin2\theta=\frac{2\tan\theta}{1+\tan^2\theta}=\frac{-10}{26}=\frac{-5}{13}\\
Ref(\theta)\begin{bmatrix}4\\-13\end{bmatrix}=\begin{bmatrix}
\cos(2\theta) & \sin(2\theta) \\ \sin(2\theta) & -\cos(2\theta)
\end{bmatrix}\begin{bmatrix}4\\-13\end{bmatrix}=\begin{bmatrix}
\dfrac{-12}{13} & \dfrac{-5}{13} \\ \dfrac{-5}{13} & \dfrac{12}{13}
\end{bmatrix}\begin{bmatrix}4\\-13\end{bmatrix}\\
=\frac{1}{13}\begin{bmatrix}-48+65\\-20-156\end{bmatrix}=\frac{1}{13}\begin{bmatrix}17\\-176\end{bmatrix}
$$ Why am I not getting the required solution in Method two using matrix method ? Thanx @ganeshie8 for the remarks, so in that case how do I find the operator for reflection of a point over the line not passing through the origin ?","['matrices', 'unitary-matrices', 'linear-algebra', 'geometry']"
3340944,Find the recursive formula for $a_{n}={b^n}$ for $n>2$,"How can I solve it,
and can anybody help me to find recursive formula for $a_{n}=3n^3$ for $n\geq 0$ .","['recursive-algorithms', 'discrete-mathematics']"
3341022,How is the determinant related to the unit circle?,"Here is a STEP 3 question from 2018, of which the Latex code can be downloaded here . I know perfectly how to answer this question, so please do not answer it . The  distinct points $A$ , $Q$ and $C$ lie on a straight line in the
Argand diagram, and  represent the distinct complex numbers $a$ , $q$ and $c$ , respectively.  Show that $\dfrac {q-a}{c-a}$ is real and
hence that $(c-a)(q^*-a^*) = (c^*-a^*)(q-a)\,$ . Given that $aa^* = cc^* = 1$ , show further that $$ q+ ac q^* = a+c
 $$ The distinct points $A$ , $B$ , $C$ and $D$ lie, in anticlockwise order,
on the circle of unit radius  with centre at the origin   (so that,
for example, $aa^* =1$ ). The lines $AC$ and $BD$ meet at $Q$ . Show
that $$ (ac-bd)q^* = (a+c)-(b+d) \,, $$ where $b$ and $d$ are
complex numbers represented by the  points $B$ and $D$ respectively,
and show further that $$ (ac-bd)  (q+q^*) =  (a-b)(1+cd) +(c-d)(1+ab)
 \,. $$ The lines $AB$ and $CD$ meet at $P$ , which  represents the complex
number $p$ . Given that~ $p$ is real, show that $p(1+ab)=a+b\,$ . Given
further that $ac-bd \ne 0\,$ , show that $$ p(q+q^*) =  2  \,. $$ This question involves a large amount of algebra, and one can easily get lost in it. However, there are some interesting patterns emerging in the problem: Why $ac-bd$ appears? This is the $2\times 2$ determinant! What's really going on here? In complex analysis/methods books, I have not seen any determinants related to circles or straight lines. (For circles, we have cross ratios, which is something completely different.) Are there any generalizations to $3\times 3$ or higher determinants? The last result, which states that $p\Re (q)=1$ , is also quite interesting. How to interpret this result? To summarize, this question seems to be tackling a very deep theory in geometry in an elementary way. I try to find more about this in complex methods textbooks, but I have not found any. Can anyone explain intuitively what's going on about the determinants , or tell me where to read more about the geometry of the unit circle? Just tell me where this question leads us to if we go any further.","['complex-analysis', 'geometry', 'complex-numbers']"
3341032,A special ideal in a local ring,"Let $R $ be a local commutative ring with identity (may or may not be Noetherian), and let $0\ne a\in R $ be such that for every ideal $I $ of $R $ either $a\in I $ or there exists $r\in R $ such that $0\ne rI\subseteq \langle a\rangle $ . How can we deduce that $\langle a\rangle $ is comparable with every ideal, that is, for every ideal $J $ we have either $\langle a\rangle \subseteq J$ or $J\subseteq\langle a\rangle $ ?","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'local-rings', 'commutative-algebra']"
3341045,Proof: if $x^5-4x^4+3x^3-x^2+3x-4≥0$ then $x≥0$,"I have proved this question by finding the solution of the polynomial using 17 steps Newthon Rhapson and found out that x ≥ 3,0735. I am wondering is there any more simple way to solve this?","['inequality', 'discrete-mathematics']"
3341047,Duality of Vector Spaces and Topological Vector Spaces,"Let $K$ be a field, and put $K \text{-vect}$ for the category of $K$ -vector spaces. There is an adjunction $[-, K]_{K \text{-vect}} : K \text{-vect}^{op} \leftrightarrow K \text{-vect} : [-, K]_{K \text{-vect}}$ where $[-, K]_{K \text{-vect}}$ sends a vector space $V$ to $[V, K ]_{K \text{-vect}}$ , the $K$ vector space of linear maps from $V$ to $K$ . Evidently, the vector space structure on $V^*$ alone is not enough to recover $V$ . I wonder, though, about putting a topology on it. For each $a \in V$ , there is a map $\hat{a} : V^* \rightarrow K$ sending $\phi$ to $\phi(a)$ . Give $V^*$ the weakest topology such that $\hat{a}$ is continuous for each $a \in V$ . Question: form $[V^*, K]_{K \text{-topvect}}$ , the vector space of continuous linear maps of topological vector spaces from $V^*$ to $K$ . Is this vector space isomorphic to $V$ ? If this turns out to be true, then we have a functor $F : K \text{-vect}^{op} \rightarrow K \text{-topvect}$ and a functor $G : K \text{-topvect} \rightarrow K \text{-vect}^{op}$ , such that $G \circ F \cong 1_{K \text{-vect}^{op}}$","['vector-spaces', 'functional-analysis', 'category-theory', 'weak-topology']"
3341053,What is special about 2 in Fermat's Last Theorem,"I have very little experience with number theory and I am not in a place to read through Wiles' proof of Fermat's Last Theorem right now. However, I do want to get just a little bit of understanding of why 2 is different than other numbers in the context of the proof. To be more specific, presumably, at some point in Wiles' proof he must state a lemma or proposition or something that holds for all $n\in\mathbb{N}$ other than 2 (or something like that) so that his proof does not rule out the existence of Pythagorean triples. What is that lemma/proposition/step where 2 is excluded in such a way that Wiles' proof does not imply that Pythagorean triples are impossible? To further clarify, I can give an example of the type of answer I am looking for. If I were asking about what makes 5 special when it comes to the unsolvability of the quintic (i.e why all of a sudden at degree 5 do general polynomial equations become unsolvable?), I would be looking for an answer roughly on the level of "" $A_5$ is the smallest alternating group which is simple. The simplicity of $A_n$ for $n\geq 5$ is what makes quintics (and higher degree polynomials) fundamentally different from quartics and lower degree polynomials, and allows us to use Galois Theory to show that these higher degree polynomials are unsolvable."" So, what is it that separates 2 from every other number when it comes to Fermat's Last Theorem?",['number-theory']
3341076,equation on expectation,"I am reading a note on the probability theory and they are verifying that the sample mean $\bar y=\frac 1n \sum_{i=1}^n y_i$ is an unbiased estimator of the population mean $\bar Y$ by taking expectation $$E(\bar y)=\frac 1n \frac{1}{{N \choose n}}\sum_{i=1}^{N \choose n}\sum_{i=1}^ny_i.
$$ I do not understand how they have gotten the following relation: $$
\sum_{i=1}^{N \choose n}\sum_{i=1}^ny_i={N-1 \choose n-1}\sum_{i=1}^N y_i.
$$","['expected-value', 'statistics', 'probability']"
3341138,About the supremum and the infimum,"I am learning about the supremum and infimum, I have however read a couple of things, that I did not understand. 1) is $A$ a two element containing set $A:=\{a,b\}$ then we use the notation $a \lor b := Sup(A)$ and $a \land b := Inf(A) $ Why does this notation represent Sup of A and inf A? what do logical and and or have to do here with the lowest and highest bounds? 2) Let $A$ be a none-empty subset of $\mathcal P(X) $ then follows $\cup A  = Sup (A) $ $\cap A = Inf (A) $ I also fail to see the relation. I am not even sure what $\cup A$ means. Is it the unification of all none empty subsets of the bigger set $X$ ? or is it the unification of the single elements of the subset $A$ ? in either case, how does that produce the Sup/Inf? Thanks!","['elementary-set-theory', 'supremum-and-infimum']"
3341174,How to find the volume enclosed by intersection of three orthogonal cylinders?,"If I have three cylinders $$x^2 + y^2 =1 $$ $$ x^2 + z^2 =1  $$ $$y^2 + z^2 =1$$ and I need to find the volume contained in their intersection. I know the figure I will get is a steinmetz solid looking like this . Now I was looking for the solution and I found this thread Intersection of Three Cylinders of equal radius . In this thread Mr. John Hughes explains beautifully about the figure. Here is the image . What I want is to compute the volume of this solid. I can infer from my research and little of intuition that the region PCB belongs to $x^2 + y^2 =1$ , region PAC belongs to $y^2 + z^2 =1$ and region PAB belongs to $x^2 + z^2 =1$ . If I try to find the volume I would set an integral like this $$\iiint_E dx~ dy~ dz $$ where $E$ is the whole region ABC along with P. Now, the problem is the bounds of the integrals. I'm having no idea of how to get the bound. I can (with little confidence) say that $y$ is bound by the curve PCB so I may write $$0 \leq y \leq +\sqrt{1-x^2}$$ and $$ 0 \leq x \leq 1$$ . I'm stuck here, I need help with as much elaboration possible from basics. I know this type of question has been asked multiple times and each time a different think has been asked, so I'm going with the tradition. Please help me in cartesian coordinates only and with this diagram, if possible. Curvilinear coordinates's bounds would also work but please add a through explanation to it. Thank you. I hope someone will surely help me through this. I apologize if I'm asking a conventional thing, I apologize if I'm too demanding , I apologize if I'm wrong in my very essence of the concept.","['multivariable-calculus', 'volume']"
3341228,Generalized series for $\pi$ - What is the polynomial?,"The Madhava-Leibniz series for $\pi$ is $$4\sum_{n=0}^\infty\frac{(-1)^n}{2n+1}$$ When we regroup odd and even terms into individual new terms, $b_n=a_{2n}+a_{2n+1}$ , we have the other well known series for $\pi$ $$8\sum_{n=0}^\infty\frac{1}{(4n+1)(4n+3)}$$ But then continuing this and iteratively regrouping the terms of each series gives us a sequence of series $$2^{k+1}\sum_{n=0}^\infty\frac{p_k(n)}{(2^kn+1)(2^kn+3)(2^kn+5)\ldots}$$ for $k=1,2,\ldots$ , where $p_k(n)$ is (for $k>1$ ) a polynomial in $n$ and where the product in the denominator has terms $(2^kn+i)$ , for odd $1\leq i<2^k$ . From the relation $b_n=a_{2n}+a_{2n+1}$ , we get a recursive definition of $p_k$ that can be simplified into factorials $$p_{k+1}\left(n\right)=\frac{1}{2^{\left(2^{\left(k-1\right)}+1\right)}}\left(\frac{\left(2h\right)!i!}{h!\left(2i\right)!}p_k(2n)+\frac{\left(2i\right)!w!}{i!\left(2w\right)!}p_k(2n+1)\right)
$$ where $w=2^kn,\ i=2^{\left(k-1\right)}+2^kn,\ h=2^k\left(n+1\right)$ . The first few $p_k$ are $$\begin{array}{|c|c|}
\hline
k&p_k\\
\hline
1&(-1)^n\\
\hline
2&1\\
\hline
3&64n^2+64n+19\\
\hline
4&16777216n^6+\ldots+191115\\
\hline
\end{array}$$ So, my question is this: is there an explicit, general closed form for $p_k(n)$ ? If so, what is it and has it been studied? Also, is there a name for the series regrouping $b_n=a_{2n}+a_{2n+1}$ ? The reason I was initially interested in this rearrangement is because this SE question calls for a series with terms that are elementary functions but lack a constant factor. Hypothetically, a generalised series could be extended to $k=-1$ , which would omit the constant $2^{k+1}$ .","['reference-request', 'pi', 'polynomials', 'sequences-and-series']"
3341246,A characterization for semilocal rings,A commutative ring with 1 is called semi-local if it has finitely many maximal ideals and is called local if it has only one maximal ideal. There are some algebraic charactrizations for local rings. For example a ring $R$ is local ring if and only if  all elements of $R$ that are not units form an ideal if and only if either $r$ or $1-r$ is unit for all $r\in R$ . Is there any such  caracterizations for semi-local rings with more than one maximal ideals?,"['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'local-rings', 'commutative-algebra']"
3341278,"Two random numbers from $\{1,\,\cdots,\,\,n\}$. Prove probability of $x_{1} + x_{2} = n$ is $\frac{n-1}{n^2}$","You are given two random natural numbers $x_{1}$ and $x_{2}$ from the interval $[1, n]$ Assume $n > 1$ and $x_{1}, x_{2} \sim U\{1,...,n \}$ are i.i.d. The probability that $$x_{1} + x_{2} = n$$ is $$P(n) = \frac{n-1}{n^2}$$ How do I prove that? For $n = 2$ possible results are: $$S_{n=2} = \{ \{1,1\}, \{2,1 \}, \{1,2\}, \{2, 2\} \}$$ so in total $2^2 = n^2$ results. Only $\{1, 1\}$ satisfies $x_{1} + x_{2} = n$ . Therefore $p(2) = \frac{2-1}{2^2} = \frac{1}{4}$ which seems correct. For $n = 3$ possible results are: $$S_{n=3} = \{ \{1,1 \}, \{1,2 \},\{ 1,3\}, \{2,1 \}, \{2,2 \}, \{2,3 \}, \{3,1 \},  \{3,2\}, \{3,3\} \}$$ so in total $3^2 = n^2$ results. Only $\{ 1,2\}$ and $\{2,1\}$ satisfy $x_{1} + x_{2} = n$ . Therefore $p(3) = \frac{3-1}{3^2} = \frac{2}{9}$ which seems right. Can someone prove for any $n > 1$ ?","['discrete-mathematics', 'probability']"
3341297,Examples of combinatoric problems solved by counting eulerian circuits,"I'm looking for combinatoric problems that can be solved by counting eulerian circuits in directed graphs, i.e. by defining some graph and then counting all cycles passing through each edge exactly once. One example I found is (a slight modification of) this question , where we have $n$ people belonging to $k$ disjunct groups of equal size, and  who shall be seated around a round-table. We now want to count the arrangements so that
  no pair of two people belonging to the same group have the same left-side-neighbor. However, this example is quite particular, so I'd love to see some more general examples that illustrate when counting eulerian circuits can be helpful. BEST Theorem , a polynomial method to count eulerian circuits in digraphs.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3341394,Solving $ax^3+bx^2+cx+d=0$ using a substitution different from Vieta's?,"We all know, a general cubic equation is of the form $$ax^3+bx^2+cx+d=0$$ where $$a\neq0.$$ It can be easily solved with the following simple substitutions: $$x\longmapsto x-\frac{b}{3a}$$ We get, $$x^3+px+q=0$$ where, $p=\frac{3ac-b^2}{3a^2}$ and $q=\frac{2b^3-9abc+27a^2d}{27a^3}$ Then, using the Vieta substitution, $$x\longmapsto x-\frac{p}{3x}$$ We get, $$(x^3)^2-q(x^3)-\frac1{27}p^3=0$$ which is can easily turn into a quadratic equation, using the substitution: $x^3 \longmapsto x.$ And here is my question: In mathematics is there a substitution that is ""different"" from the  substitution $x\longmapsto x-\frac{p}{3x}$ that can be used for the standard form cubic equation $x^3+px+q=0$ , which is can easily turn into a quadratic equation? I'm curious, if there's a new substitute I don't know about. Thank you!","['cubics', 'algebra-precalculus', 'soft-question', 'substitution']"
3341439,Show that a Weibull distribution belongs to an exponential family,"I'm studying statistics and came across a problem that I'm having some issues wrapping my head around. I'm given the density function of a Weibull distribution $$
f(y;\lambda,k) = \begin{cases}
    \frac k \lambda \left(\frac y \lambda\right)^{k-1}e^{-(y/\lambda)^k},& y\geq 0\\
    0,              & y<0
\end{cases}
$$ I'm supposed to show that the Weibull distributions with fixed $k$ belongs to the exponential family with the form: $$f_θ(y) = \exp(a(y)b(θ) + c(θ) + d(y))$$ I've taken the logarithm of the function and got: $$\log f(y;λ,k) = \log (k/λ) + (k-1)\log(y/λ) - k(y/λ)$$ I'm unsure how to derive the canonical parameter and determine where the terms belong. Any tips on how to arrange the logs are welcome. EDIT: I've tried rearranging a bit and ended up with $$\log f(y;λ,k) = -y(k/λ) + log(k/λ)-(k-1)*log(y/λ)$$ With a(y) = -y, b(θ) = k/λ, c(θ) = log(k/λ), d(y) = (k-1)*log(y/λ) With the canonic parameter (θ) = k/λ.
Though I'm pretty sure this is incorrect.","['statistics', 'exponential-distribution', 'logarithms']"
3341441,Frequently asked maths questions answered (high school level),"I've asked a lot of questions recently on this forum, so I wanted to give back to the community by explaining the answers to some of the most frequently asked questions about basic mathematics, starting with simple questions and ending with more advanced ones. Here they are: Why does a negative times a negative equal a positive? Why does $(a+b)^2$ not equal $a^2+b^2$ ? Why does $y=f(x+a)$ shift the graph $a$ units to the left instead of $a$ units to the right? While I am sure these questions have been asked many times before, I hope to answer them with greater clarity and detail, in a way that I would have found useful when I pondered them. If anybody else would like to add to this list of FAQs, I would be more than grateful.","['algebra-precalculus', 'graphing-functions', 'intuition']"
3341449,Relation between Gaussian width and its squared version,"I'm currently reading through Roman Vershynin's High Dimensional Probability and working through one of the exercises (7.6.1). Consider a set $T \subseteq \mathbf{R}^n$ and define its Gaussian width $w(T)$ , as $$
w(T) := \mathbb{E} \sup_{x \in T} \langle g, x\rangle, \quad g \sim \mathcal{N}(0, I_n).
$$ A closely related version, $h(T)$ , is defined similarly: $$
h(T) := \sqrt{\mathbb{E}\left[ \sup_{x \in T} \langle g, x \rangle^2 \right]}.
$$ Now, Exercise 7.6.1 in the book asks the reader to show that $$
h(T - T) \leq w(T - T) + C_1 \mathrm{diam}(T), \quad (*)
$$ with $T - T := \left\{u - v : u, v \in T \right\}$ , and the hint is to use Gaussian concentration. I have been unable to use this hint, and only end up with a trivial upper bound where $C_1 = \sqrt{n}$ , as follows: $$
h(T - T)^2 = \mathbb{E} \sup_{x \in T - T} \langle g, x \rangle^2 = \mathbb{E}
\left( \sup_{x \in T - T} \left\langle g, \frac{x}{\| x \|_2} \right\rangle^2 
\| x \|_2^2 \right) \\
\leq \sup_{x \in T - T} \| x \|_2^2 \mathbb{E} \| g \|_2^2 = \mathrm{diam}^2(T) \cdot n,
$$ followed by taking square roots. Question : How does one use Gaussian concentration to show the bound $(*)$ ?
I tried showing that $g \mapsto \sqrt{\sup_{x \in T - T} \langle g, x \rangle^2} -
\sup_{y \in T - T} \langle g, y \rangle$ is Lipschitz, but couldn't get anything useful since there is a square root involved.","['self-learning', 'inequality', 'concentration-of-measure', 'probability-theory']"
3341526,"Why is this instance correct of having a plus or minus sign, outside of a square root?","I was really struggling with a differential equations question, when I came across the solution on this website. I understood everything of the solution, but I did not understand the final part (where the solver added a $\pm$ sign to the right side of the equation). The original problem is to find a non-constant solution to ${x'}^2+x^2=9.$ I subtracted $x^2$ from both sides, leaving ${x'}^2=9-x^2.$ Then I took the square root of both sides (is this where it gets messy?), which left me with $x'=\pm\sqrt{9-x^2}.$ Then, I divided $\sqrt{9-x^2}$ by both sides: $$\frac{x'}{\sqrt{9-x^2}}=1.$$ Afterwards, I took the integral of both sides and rewrote $x'$ as $$\int \frac{x'}{\sqrt{9-x^2}} dx= \int 1 dt.$$ Using the formula integration guy for arcsin, I got: $$\arcsin\left(\frac x3\right)+c_1=t+c_2. 
$$ Then I took the sin of both sides and simplified the arbitrary constants: $x/3=\sin(t+c_3).$ And then I multiplied by $3,$ leaving us with $x=3\sin(t+c).$ I will stop there for now, as the rest (er initial condition(s)) do not pertain to my question. When I was reading the solution, the solution contained a $\pm$ on the right hand side of the solution at the end. Can someone explain why to me please? I don't quite understand... It would be greatly appreciated!","['integration', 'indefinite-integrals', 'ordinary-differential-equations']"
3341530,Find the maximum and minimum value of this.,"The below question doesn't have a answer in the answersheet. So I want to know my anser is right or not. Q) question. Let the $1 \leq x_i (\in N) \leq 3$ , $i \in \{1,2,3,...,6\}$ ( $N$ is natural number set) $\sum_{i=1} ^6 x_i = 12 $ then  what is the max and min value of the $\sum_{i=1} ^6 x_i^3$ ? My answer is 84 and 48 respectively. What do you think? Thanks. P.s. here is my solution.","['elementary-number-theory', 'discrete-mathematics']"
3341627,"A simple irrational number with the same first 11,667,755 digits as $\frac{2}{3}$","Let $$f(x) = \frac{1}{2}+\sum_{k=1}^\infty \frac{\mbox{sgn}(\sin kx)}{2^{k+1}} .$$ Here $\mbox{sgn}$ represents the sign function. Many simple integer and rational values of $x$ result in $f(x)$ very closely approximating some simple rational numbers, and you don't have to spend much time to identify plenty of them. Yet it seems obvious that if $x$ is rational, then $f(x)$ is irrational. One number that stands out is $$x = 10^5 + \frac{1}{10}\cdot\Big(\frac{3}{5}\Big)^2.$$ Surprisingly, $f(x)$ is almost equal to $\frac{2}{3}$ , as the first $12,897$ binary digits of both numbers agree. Just after that, they disagree. You don't need a sophisticated algorithm to check this. Just compute $\mbox{sgn}(\sin kx)$ for $k=1, 2, \cdots, 12,897$ . These signs alternate perfectly depending on whether $k$ is odd or even, just like the binary digits of $\frac{2}{3}$ . Question I started to have some doubts about the fact that if $x$ is rational, then the sequence $z_k = \mbox{sgn}(\sin kx)$ can not be periodic. Can someone prove that I am right, and that this weird number $x$ is just a coincidence, not leading to periodicity anyway. Do you have some explanation for these coincidences for so many different $f(x)$ values: very often, 20 or 30 binary digits match those of a simple rational, sometimes 40 and even 87 digits for the number $x=10^5$ itself -- but no pattern for $x=10^5-1, x=10^5-\frac{1}{10}, \mbox{ or } x = 10^5+1$ . A pattern again for $x=2\cdot 10^5$ and for so many other numbers, starting with $x=1$ resulting in $f(x)=0.11111113\cdots$ (in base $10$ ). Update Another number leading to almost periodicity is $x=\log_2 3$ resulting in $f(x) = 2/5$ (almost). But $x=\sqrt{2}/2$ does not yield the same spectacular result. It is a hit and miss. Finally, try $x=\frac{355}{113}$ . The first $11776655$ binary digits of $f(x)$ are identical to those of $\frac{2}{3}$ . Not only $11776655$ is large, but even more surprising, look at the base- $10$ digits of $11776655$ : two $1$ , two $7$ , two $6$ , two $5$ . Note that if you concatenate the base- $10$ digits of $355$ with those of $113$ , you get $113355$ .","['approximation', 'number-theory', 'irrational-numbers', 'sequences-and-series', 'recreational-mathematics']"
3341634,"Is $(-3)^\sqrt{2}$ a real number ? If it a complex number, then what is its $a+bi$ form?","Is this a real number? If it a complex number, then what is its $a+bi$ form? $$(-3)^\sqrt{2}$$","['complex-analysis', 'complex-numbers']"
3341684,Some classes of semiprimitive pm-rings,"A commutative ring  with 1 is called semiprimitive  whenever $J(R)=\cap_{m\in Max(R)}m=0$ , and a ring is called a Gelfand ring (or a pm ring) if each
prime ideal is contained in a unique maximal ideal. It is well known von Neumann regular rings and $C(X)$ ( ring of continuous functions over $X$ ) are two classes of semiprimitive Gelfand rings. I am looking for some other famous classes of such rings?","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3341686,Colouring the elements of a group such that $x$ and $gx$ have different colours.,"$\mathbf{Question:}$ Let $G$ be a finite group and $g\in G$ be an element of even order. Prove that the elements of the group can be coloured using two colours in such a way that $x$ and $gx$ have different colours $\forall x\in G$ . $\mathbf{Attempt:}$ By Lagrange's theorem, $G$ is of even order, say $2n$ . We ""bifurcate"" $G$ into two equal halves, say $A= \{x_1,x_2,...,x_n\}$ and $B=\{y_1,y_2,...y_n\}$ , where $x_1=e$ and $y_i=gx_i, \ 1\leq i \leq n$ . So, $y_1=g$ , $A\cup B=G$ and $A\cap B=\emptyset$ Clearly, $\phi_1:A \to B$ defined by $\phi_1(x_i)=gx_i$ is an injection, consequently, it is a bijection. Again, $\phi_2:B \to A$ defined by $\phi_2(y_i)=gy_i=g^2x_i$ sends $x_i's$ back to $A$ . If we give the elements of $A$ the same colour and the elements of $B$ another, the colouring is done. Is this correct? Kindly Verify.","['finite-groups', 'group-theory', 'functions', 'proof-verification']"
3341701,Is equicontinuity independent of the chosen metric of the state space,"There already exist several posts on similar questions, but I could not find any, which really gives a precise answer to my problem. Let $A \subseteq C([0,T],E)$ , where $E$ is a topological space and C $([0,T],E)$ denotes the set of all continuous functions from $[0,T]$ to $E$ . Assume I am given a metric on $E$ , let me call it $d$ , which induces the prescribed topology on $E$ . Then, equicontinuity of $A$ means $sup_{f \in A}d(f_{t_n},f_t) \to 0$ for each $t \in [0,T], (t_n)_{n \in \mathbb{N}}$ converging to $t$ . One usually does not find this as the definition of equicontinuity, but I think this is an equivalent way to express it, right? Now, suppose someone considers a topologically (i.e. ""weakly"") equivalent metric, $\rho$ , on $E$ . Is equicontinuity of $A$ invariant under switching between such equivalent metrics? Intuitively, this should be the case, but I would very much like to have clarification for it. Thanks in advance!","['equicontinuity', 'functional-analysis', 'analysis', 'metric-spaces']"
3341703,Show that a conformal equivalence of two tori lifts to an automorphism of $\mathbb C$,"Let $L_1,L_2$ be two lattices of rank 2 in $\mathbb C$ . Then $\mathbb C/L_1$ and $\mathbb C/L_2$ are two tori. Let $$f:\mathbb C/L_1\to\mathbb C/L_2$$ be a conformal equivalence. Show that the lift $\tilde f:\mathbb C\to\mathbb C$ of $f$ is an automorphism (conformal equivalence to itself) of $\mathbb C$ . My attempt: Donote the natural projections by $$\pi_1:\mathbb C\to\mathbb C/L_1$$ $$\pi_2:\mathbb C\to\mathbb C/L_2$$ Then the lift $\tilde f$ satisfies $$f\circ\pi_1=\pi_2\circ\tilde f$$ and is holomorphic. The same applies to $f^{-1}$ . $$f^{-1}\circ\pi_2=\pi_1\circ\widetilde{f^{-1}}$$ $$\implies \pi_2=(ff^{-1})\pi_2=f\pi_1\widetilde{f^{-1}}=\pi_2\tilde f\widetilde{f^{-1}}$$ But I can't cancel $\pi_2$ as it is not injective. What am I missing?","['complex-analysis', 'general-topology', 'algebraic-topology', 'covering-spaces']"
3341747,Order of partial derivative in second derivative test?,This is from wikipedia for the second derivative Hessian matrix test. From the determinant it seems to assume that $f_{xy} = f_{yx}.$ Why is this valid to assume? Is the test only valid for when $f_{xy} = f_{yx}?$,['multivariable-calculus']
3341766,properties that real numbers hold but complex numbers does not,"I need to find a few examples about the differences between real numbers and complex numbers like: 1) if $x \in \mathbb R $ then $x^2 \geq0$ is true if $z \in \mathbb C $ then $z^2 \geq0$ is false 2) let $a \in \mathbb R/\{0, 1\} $ if $a^x =a^y$ then $x=y$ is true let $a\in \mathbb z/\{0, 1\} \in \mathbb C $ if $a^x =a^y$ then $x=y$ is false But these examples are not cool enough and feel very trivial.  Can you suggest some other properties like these? Thanks.","['real-numbers', 'complex-numbers', 'real-analysis']"
3341776,A “branching process” for finite groups,"Suppose $G$ is a finite group and $\{X_{i,j}\}_{i, j \in \mathbb{N}}$ are a set of i.i.d. random elements of $G$ . Now suppose that $\{A_i\}_{i = 0}^\infty$ is a sequence of random elements of $G$ defined by the following relations: $$P(A_0 = e) = 1$$ $$A_{n+1} = \Pi_{i = 1}^{ord{A_{n}}} X_{(n+1), i}$$ Here $\Pi$ stands for iterated group product, and $ord$ for the order of an element. My question is: Is it always true, that $\exists H \leq G$ , such that $\forall g \in G$ $\lim_{n \to \infty} P(A_{n} = g) = \frac{I_H(g)}{|G|}$ ? Here $I_H$ stands for indicator function of $H$ . This statement is true for the following borderline cases: If $X_{1, 1}$ is uniformly distributed on $G$ , then $H$ is equal to $G$ . This is because if $A$ and $B$ are two independent uniformly distributed random elements of a finite group, then $AB$ is also uniformly distributed. If $X_{1, 1}$ is degenerate ( $\exists g \in G$ , such that $P(X_{1, 1} = g) = 1)$ ), then $H$ is trivial, as $\forall g \in G$ $g^{ord(g)} = e$ by definition of group element order. But is that statement true in general?","['finite-groups', 'stochastic-processes', 'group-theory', 'probability-theory', 'probability']"
3341796,Find solution for $|x| + |y| \frac{dy}{dx}=0$,"I want to solve following differential equation $|x| + |y| \frac{dy}{dx}=0$ with initial condition $y(2)=-1$ . @Robert Z,  since the it pass through $(2,-1)$ \begin{align}
  x - y \frac{dy}{dx}=0 
\end{align} \begin{align}
   x dx = y dy 
 \end{align} with the initial condition $y(2)=-1$ , 
I have $y^2 = x^2 - 3 $ . so \begin{align}
y= - \sqrt{x^2-3}
\end{align}",['ordinary-differential-equations']
3341823,Prove that an integer $a$ which satisfies the equation $a^2=1+2b^2$ for integer $b$ is of the form $a=c^2\pm1$ for some integer $c$,"This question is a bit involved so thanks for your patience. After a lot of work I could show that each $b$ that satisfies this equation corresponds to another smaller integer say $s$ which satisfies the equation. here are the formulas for the solutions. $$t=s\pm\sqrt{2s^2+1}\tag{1}$$ $$x=3t\pm2\sqrt{2t^2-1}\tag{2}$$ $$y=\pm\sqrt{tx-1}\tag{3}$$ $$b=2x+y\tag{4}$$ $$a=3x+y\tag{5}$$ for nonzero $t$ and $x$ . Let $x_+$ and $x_-$ denote the $x$ with the positive sign and negative sign respectively and define $y_+$ and $y_-$ similarly. Use the following rules: If you choose positive $t$ not $1$ you may  choose any one of the $x$ s, but you must choose $y_+$ if you take $x_+$ . If $t=1$ you may take both $x$ s and with $x_+$ you must choose only $y_+$ . If you take $t$ positive and choose $x_-$ you must choose $y_-$ , this last solution repeats the previous solutions but it generates one the others don't when $s=2$ , $t=5$ , $x_-=1$ , $y_-=-2$ , $b=0$ , $a=1$ . There are similar rules for negative $t$ but they are just the negatives of the previous solutions. I (think) I could prove that no $s$ can lead to a $b=s$ since all solutions either get smaller or larger but the absolute value always increases except for the case I singled out which leads to $b=0$ , which implies that this is the complete set of solutions. I noticed that the values of $b$ increase and at some point they reach a constant ratio which is roughly $\phi=93222358/15994428$ and I used this to derive the function $$f(x)=\phi^{\left(x-11\right)}93222358$$ which is extremely accurate at first and almost exact for $x\ge7$ . It gives the $x$ -th nonzero value of $b$ where the zeroth value is just $0$ . Here's where it gets interesting, I noticed a pattern among the $a$ s, that for nonzero even $x$ , $a$ can be written in the form $a=c_1^2-1$ and for odd $x$ , $a=\ c_2^2+1$ . I checked this until $x=15$ and it holds. Also, another reason to believe that $a$ can't be a square is that while I was trying to prove Fermat's last theorem for $n=4$ (where this equation came up), I could reduce the proof to verifying that that no such $a$ can be a square. Of course, I'm a lot more interested now than when I first encountered the equation and I want to prove this pattern.","['number-theory', 'elementary-number-theory', 'diophantine-equations']"
3341824,Intuition behind nets,"How can we think of nets as a generalization of sequences? Basically, we can see sequences as a way of enumerating elements of a set: in facty a sequence is a function $x_n:\mathbb{N}\rightarrow X$ . Now, directed set abstract from naturals the following property: $$\alpha,\beta\in\ D\rightarrow\; \exists \gamma\ st\ \alpha\prec\gamma,\ \beta\prec\gamma$$ Cam we then see nets as a generalization of the ordinary idea of counting, in some sense? What is the intuition behind them and behind directed sets?","['order-theory', 'intuition', 'general-topology', 'nets', 'soft-question']"
3341877,Prove that $(\mathbf{AB})^{T} = \mathbf B^{T}\mathbf A^{T}$ where $\mathbf A$ and $\mathbf B$ are matrices,"I am asked to prove following: Let $\mathbf A$ and $\mathbf B$ be matrices. Prove that $(\mathbf{AB})^{T} = \mathbf B^{T}\mathbf A^{T}$ My attempt: Consider arbitrary entry of the $(\mathbf A \mathbf B)^{T}$ , namely $((\mathbf A \mathbf B)^{T})_{i,j}$ $$((\mathbf A \mathbf B)^{T})_{i,j} = (\mathbf A \mathbf B_{j,i})^{T} =\sum_{k=1}^{n}(a_{j,k}b_{k,i})^{T} = \sum_{k=1}^{n}a_{k,j}b_{i,k} =\sum_{k=1}^{n} b_{i,k}a_{k,j} = (B^{T}A^{T})_{i,j}$$ Since we considered arbitrary entry, we conclude that $(\mathbf{AB})^{T} = \mathbf B^{T}\mathbf A^{T}$ $\Box$ Is it correct? Although I can't tell for sure, I believe that something is wrong with the proof above. The step that concerns me the most (perhaps because of the notation involved) is $$\tag!\sum_{k=1}^{n}(a_{j,k}b_{k,i})^{T} = \sum_{k=1}^{n}a_{k,j}b_{i,k} $$","['matrices', 'transpose', 'proof-verification', 'linear-algebra']"
3341902,Sheaf of nilpotent elements,"Let $k$ an algebraically closed field and $X$ be a connected projective curve (=  a $1$ -dimensional, proper $k$ -scheme). consider a closed subscheme $Z = V(\mathcal{J})$ of $X$ defined by nilpotent sheaf of ideals $\mathcal{J} \subset O_X$ . denote by $i:Z \to X$ the closed immersion. in the following we will use a couple of notations: let $\mathcal{N}_X \subset O_X$ the sheaf of nilpotent elements of $O_X$ and $N_X := \mathcal{N}_X(X)$ it's global sections; resp $\mathcal{N}_Z \subset O_Z$ "" nilpotents of $O_Z$ with $N_Z := \mathcal{N}_Z(Z)$ . We assume that $$\mathcal{J} \cdot \mathcal{N}_X =0$$ this implies $\mathcal{J}^2=0$ and $H^i(X,\mathcal{J} \cdot \mathcal{N}_X)=0$ for all $i \ge 0$ . the short exact sequence \begin{equation}
 0 \to \mathcal{J} \to \mathcal{O}_X \to i_*\mathcal{O}_Z \to 0   \tag{1}\label{eq:0105star}
  \end{equation} induces on long exact Cech cohomology sequence the map $\rho: O_X(X) \to O_Z(Z)$ sitting in $$0 \to H^0(X,\mathcal{J}) \to \mathcal{O}_X(X) \to \mathcal{O}_Z(Z) \to H^1(X,\mathcal{J}) \to ... $$ Q: how to verify that the hypothesis $\mathcal{J} \mathcal{N}_X =0$ implies that $N_Z^2 \subset \rho(N_X)$ ? I think that the key is to relate some sheaf sequences containing $\mathcal{N}_Z^2$ , $\mathcal{N}_X, \mathcal{N}_X\mathcal{J}= \mathcal{J}^2=0$ in a sophisticated way with (1) by an appropriate 2D lattice diagram and then release the global section functor to these sequences. the exactness of the Cech cohomology sequence says $im(\rho)=Ker(O_Z(Z) \to H^1(\mathcal{J},X))$ . this observeation leads me to the suspicion that such diagram chaising argument could work. does anybody see the ""right"" sequences should be here combined? or maybe another way to solve it?","['algebraic-geometry', 'sheaf-cohomology', 'schemes', 'sheaf-theory']"
3341955,Compactness and Hausdorffness,"Is it possible to have a topological space having all compact subsets closed, but the space itselt is not Hausdorff? I couldn't find any counterexample. I tried $\mathbb R$ with cofinite, point inclusion and point exclusion topologies, but these didn't work. Any suggestion in this context will be helpful for me.","['general-topology', 'compactness']"
3341995,Sum of Infinite series with a Geometric series in multiply,"I came across these series while solving a probability question. enter link description here let |r| < 1 , $$S_n=\sum_{k=0}^{\infty}k^n.r^k$$ For n=0 ,it's a GP. $S_0=\frac{1}{1-r}$ For n=1 ,it's a AGP , $S_1=\frac{-1}{1-r}+\frac{1}{(1-r)^2}$ for n=2 , This series can be reduced to AGP by substituting $k^2=1.3.5....(2k-1)$ & $S_2=\frac{-r}{(1-r)^2}+\frac{2r}{(1-r)^3}$ . Is it possible to find sum further in this series . Is there any pattern.",['sequences-and-series']
3342008,Applications of Borel Cantelli lemmas and almost sure bounds for a sequence of random variables,"Consider a sequence of probability measure $(P_{\theta,n})_{n=1}^\infty$ on $\mathbb{R}$ , assume that $X_{n}$ is distributed according to $P_{\theta,n}$ and let $c_{\theta,n}$ be a diverging sequence of constants. Here $\theta$ can be thought of as a parameter. If $$
P_{\theta,n}(X_n/c_{\theta,n}>1)\lesssim n^{-\delta}
$$ for $\delta>1$ , then, denoting by $P_{\theta,\infty}$ the law of the sequence $(X_n)_{n=1}^\infty$ , by Borel-Cantelli lemma $$
P_{\theta,\infty}( X_n/c_{\theta,n}>1, \, \text{i.o.})=0
$$ where $\text{i.o.}$ stands for infinitely often. First question : can we then conclude that for every $\epsilon>0$ there exists $n_{\epsilon, \theta}$ such that $$
P_{\theta,\infty}( X_n/c_{\theta,n}<1+\epsilon, \, \forall n \geq n_{\epsilon,\theta})=1?
$$ Assume next that the parameter satisfies $\theta \in \Theta $ and that, in fact, $$
\sup_{\theta \in \Theta }P_{\theta,n}(X_n/c_{\theta,n}>1)\leq \kappa n^{-\delta}
$$ for dome $\kappa>0$ . Second question : can we then conclude that for every $\epsilon>0$ there exists $n_\epsilon$ such that $$
\inf_{\theta \in \Theta }P_{\theta,\infty}( X_n/c_{\theta,n}<1+\epsilon, \, \forall n \geq n_\epsilon)=1?
$$","['borel-cantelli-lemmas', 'almost-everywhere', 'probability-theory', 'probability']"
3342014,Connected intersection of a manifold and orientation,"From Do Carmo's book (Riemannian Geometry, P. 19) If M can be covered by two coordinate neighborhoods $V_1$ and $V_2$ in
  such a way that the intersection $V_1\cap V_2$ is connected, then $M$ is orientable. Indeed, since the determinant of the differential of
  the coordinate change is $\neq 0$ , it does not change sign in $V_1\cap V_2$ if it is negative at a single point, it suffices to change the
  sign of one of the coordinates to make it positive at that point,
  hence on $V_1\cap V_2$ . Why the determinant does not change sign in $V_1\cap V_2$ ? It surely related to the connected assumption, but I miss the argument.","['connectedness', 'determinant', 'orientation', 'manifolds', 'differential-geometry']"
3342037,If 24 pieces of sausage are randomly put onto a pizza what is the probability that your slice will have 3 pieces of sausage?,"This Question is from Statistics the Easy Way, third edition, by Douglas Downing Ph.D and Jeffery Clark, Ph.D Chapter 6, Question 1. If 24 pieces of sausage are randomly put onto a pizza that is sliced into 8 pieces (with none of the sausages getting cut), what is the probability that your slice will have 3 pieces of sausage? The answer given in the back of the book is the following: $\binom{24}{3}\cdot \left ( \frac{1}{8} \right )^{3}\cdot \left ( \frac{7}{8} \right )^{21} = 0.006623494492036295$ I do not understand how the authors got this answer. As pieces of sausage are not distinguishable there is only one way to select 3 pieces of sausage. Are the sausage pieces first being labeled and then selected in $\binom{24}{3} $ ways? Isn't this a balls to boxes problem with indistinguishable balls and distinguishable boxes? There are 24 balls and 8 boxes. The number of ways of assigning balls to boxes is $\binom{24+8-1}{8}$ .
There is only one way of putting 3 indistinguishable balls in my box and then there are $\binom{21+7-1}{7}$ ways of assigning the other balls to boxes. So the probability that my slice has exactly 3 pieces of sausage on it is $$\frac{\binom{21+7-1}{7}}{\binom{24+8-1}{8}} = 0.11256952169076752$$ As these answers are clearly different could someone please explain the error in the way I have solved the problem?","['discrete-mathematics', 'probability']"
3342051,Solve $f(m + n) = f(m) + f(n) + mn$ and $g(mn) = g(m)g(n)(m + n)$ for $f \colon \mathbb N \to \mathbb N$.,"a/ Solve $$\large f(m + n) = f(m) + f(n) + mn$$ for $f \colon \mathbb N \to \mathbb N$ . b/ Solve $$\large g(mn) = g(m)g(n)(m + n)$$ for $f \colon \mathbb N \to \mathbb N$ . I'm only getting started on solving function equations so if there is anything I don't get correctly. This is my attempt at this problem. For a/, replacing $m$ with $m - 1, m - 2, \cdots, 2, 1$ respectively, we have that $$f(m) - f(m - 1) = f(1) + (m - 1)$$ $$f(m - 1) - f(m - 2) = f(1) + (m - 2)$$ $$\vdots$$ $$f(3) - f(2) = f(1) + 2$$ $$f(2) - f(1) = f(1) + 1$$ $$\implies f(m) - f(1) = (m - 1)f(1) + \frac{m(m - 1)}{2}$$ $$\implies f(m) = m\left[f(1) + \frac{m - 1}{2}\right]$$ Therefore, $f(x) = x\left[f(1) + \dfrac{x - 1}{2}\right], \forall x \in \mathbb N, x \ne 1$ and $f(1) = a, a \in \mathbb R$ . For b/, we have that $g(m) = g(m)g(1)(m + 1)$ where $n = 1$ . $\iff g(1) = \dfrac{1}{m + 1} \implies m$ is fixed, which is false. So there aren't any such functions $g(x)$ such that $g(mn) = g(m)g(n)(m + n)$ over $f \colon \mathbb N \to \mathbb N$ .","['functional-equations', 'functions']"
