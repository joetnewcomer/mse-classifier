question_id,title,body,tags
761079,Is there a known method for finding extremely huge squarefree numbers?,"People often compete to beat the record for largest known prime (it is currently $2^{57,885,161}-1$). There are also big money prizes for finding explicit prime numbers exceeding specific magnitudes. But what would happen if you searched for huge squarefree integers instead? Is a simple formula known which gives huge squarefree integers? As an example, if it was proved (unexpectedly) that all Fermat numbers $F_m = 2^{2^m}+1$ were squarefree, it would be trivial to find billion-digit squarefree numbers. Since the asymptotic (natural) density of the squarefree numbers is $\frac{6}{\pi^2}\approx 61\%$ (while for the primes the density is zero), maybe it is much easier to find a simple formula for squarefree numbers? (It is trivial to come up with a formula yielding huge non -squarefree numbers of course, and they constitute only $39\%$.) I know one can use the sieve of Eratosthenes to generate a list of distinct primes and then take the product of the entire list (a ""primorial"" number), but can a simpler expression in one integer variable be found to yield only squarefree numbers?",['number-theory']
761100,A quick way to estimate eigenvector/eigenvalue of a matrix,"Is there a quick way to give a raw estimation of an eigenvector/eigenvalue of a matrix? By ""quick"" I mean some method which can be computed without a computer or paper and pencil...something you could do in your head","['linear-algebra', 'eigenvalues-eigenvectors']"
761165,Show that there is a unique matrix $ A $ such that $ \varphi (t) = e ^ {tA} $.,"Let $ \varphi:\mathbb R\to\mathcal M_{n\times n}(\mathbb R)$ be a function from $\mathbb R$ to the space of $n\times n$ real-valued matrices, and suppose that each component of $\varphi$ is a $C^1$ function. If $\varphi(0)=I$ (identity), and $\varphi(t + s) = \varphi (t)  \varphi (s)$ for all $ t, s \in \mathbb R $, show that there is a unique matrix $ A $ such that $ \varphi (t) = e ^ {tA} $. Hint: Consider $ A = \varphi (0)'$.",['ordinary-differential-equations']
761177,How to compute the unique MLE from an Exponential Family of Distributions?,"Let 
$$
f(x;\theta)=\frac{1}{\pi} \frac{e^{\theta x}\cos(\theta \pi/2)}{\cosh(x)}, x\in{\mathbb{R}}
$$
be a family of densities and which is clearly exponential family. Then what is the Maximum Likelihood Estimator $\hat\theta_{n}$ of $\theta$ based on an independent sample of size $n$? My try: When I solved the loglikelihood equation, I got 
$$
\tan(\theta \pi/2)=\frac{2}{\pi}\bar{x} \hspace 4cm (*)
$$ Now, my problem is, if we solve $(*)$ for $\hat\theta_{n}$ then $\hat\theta_{n}$ is not unique. But for the exponential family it should be unique, right? So, I don't understand what is going wrong here. Your help will be greatly appreciated.","['statistics', 'statistical-inference', 'parameter-estimation']"
761214,Boundary and closure of a measure zero set is not measure zero?,"In $\mathbb{R}^n$, let $E \subset \mathbb{R}^n$ such that $E$ has measure zero. Prove that $\bar{E}$ and $\partial E$ need not have measure zero. I think I have a poor understanding of this. I know that $\bar{E} = int E \cup \partial E$ I am thinking that $E$ must be an open set. Because if $E$ were closed, then we get $\partial E\subset E$ and this implies $\partial E$ must have measure $0$. But now I have strayed away from the problem completely. Should I start with a cover on $\partial E$ and deduce that the total volume over the cover is not necessarily less than $\epsilon$?",['measure-theory']
761228,Why a holomorphic function satisfying these conditions has to be linear?,"Let $\Omega$ be a bounded open subset of $\mathbb{C}$ and $f:\Omega\rightarrow\Omega$ be holomorphic in $\Omega$. Prove that if there exists a point $z_0$ in $\Omega$ such that $$f(z_0)=z_0~~~~\text{and}~~~~f'(z_0)=1$$
then $f$ is linear. Please give some hints. Thanks in advance!",['complex-analysis']
761250,Problem calculating line integral,"I have $\gamma=[0,1]\to\mathbb{R}^3$ defined by $\gamma(t)=(\cos(2\pi t), \sin (2\pi t), t^2-t)\;\forall t\in[0,1]$  and I'm asked to calculate $\displaystyle\int_{\gamma}\displaystyle\frac{2xy\mathrm{dx}-(x^2+z^2)\mathrm{dy}+2yz\mathrm{dz}}{(x^2+z^2)^2}$. I have made an attempt to solve it but it seems that it leads to an integral hard to calculate (and very messy).
I thought that it would be a good idea make the following change of variables: $$x=\cos(2\pi t)\\y=\sin(2\pi t)\\z=t^2-t$$.
Then I'd have
$$\mathrm{dx} = -2\pi\sin(2\pi t) \mathrm{dt} \\ \mathrm{dy =-2\pi\cos(2\pi t)\mathrm{dt}} \\ \mathrm{dz} = 2t-1\;\mathrm{dt}$$. Now, making the substitution returns a long integral: $2xy\mathrm{dx}-(x^2+z^2)\mathrm{dy}+2yz\mathrm{dz} = [2\cos(2\pi t)\sin(2\pi t)(-2\pi\sin(2\pi t))dt]-(\cos^2(2\pi t) +t^4-2t^3+t^2)+2[\sin(2\pi t)(t^2-t)(2t-1)\mathrm{dt}]=-4\pi\sin^2(2\pi t)\cos(2\pi t)-\cos^2(2\pi t) -t^4+2t^3-t^2+4t^3\sin(2\pi t)-6t^3\sin(2\pi t)+2t\sin(2\pi t)\;\mathrm{dt} = [\sin(2\pi t)][-4\pi\sin(2\pi t)\cos(2\pi t)+\sin(2\pi t)+4t^3-6t^3+2t]+t^2(-t^2+2t-1)-1.$ And $(x^2+z^2)^2= (\cos^2 (2\pi t)+t^2-2t^3+t^2)^2$ Which means I should calculate... $$\int_0^1 \frac{[\sin(2\pi t)][-4\pi\sin(2\pi t)\cos(2\pi t)+\sin(2\pi t)+4t^3-6t^3+2t]+t^2(-t^2+2t-1)-1}{(\cos^2 (2\pi t)+t^2-2t^3+t^2)^2}dt$$. Is that right?. How badly did I messed up?","['definite-integrals', 'multivariable-calculus', 'integration']"
761268,Is there a subset of R such that its Cantor-Bendixson rank is the first limit ordinal?,I'm looking for a set $A \subset \mathbb{R}$ such that $\bigcap^\infty_{n=0} A^{(n)} $ is a perfect set (i.e $X'=X$) but $\forall n \in \mathbb{N}$ the set $A^{(n)}$ isn't perfect (where $X^{(n)}=(X^{(n-1)})'$ and $X^{(0)}=X$).,"['ordinals', 'descriptive-set-theory', 'general-topology', 'real-analysis', 'analysis']"
761295,A zero-dimensional Hausdorff space is totally disconnected,"The full question: A space is zero-dimensional if the clopen subsets form a basis for the topology. Show that a zero-dimensional Hausdorff space is totally disconnected. Recall a space is totally disconnected if the only connected subsets are singletons (one-point subsets). Let X = {X1, X2, ...} be the set of clopen subsets of the space. We know that X is a basis for the topology T, so any open set in T can be written as a union or finite intersection of elements in X. In a topological space, we know the union/finite intersection of open sets are also open (by definition) and the union/finite intersection of closed sets are closed, so any union/finite intersection of clopen sets is also clopen. Since X is a basis, then any open set in T is also closed, since it will be the union/finite intersection of clopen sets. Does this mean our space is discrete? If it is discrete, then the only connected subsets are singletons, and then our space is totally disconnected. I have a strong feeling I've gone in circles and my argument is incorrect (especially the discrete part...) Any help would be appreciated.","['general-topology', 'connectedness']"
761297,Why is the permanent of interest for complexity theorists?,"Studying a bit about the determinant and the permanent, I'm told that although both concepts have very similar formulas, the permanent was of not much interest historically - it was until later that complexity theorists became more curious about it. What exactly makes it interesting for complexity theorists? I heard that there is no efficient algorithm to calculate it - is that what they mean?","['math-history', 'matrices', 'linear-algebra', 'soft-question', 'permanent']"
761308,In how many ways can letters in mathematics be ordered with restrictions?,"I've been stuck on these for a while. Please guide me through all the steps because I actually want to understand this. I've got an exam coming up. Consider the letters in the word ""MATHEMATICS"". In how many ways can these 11 letters be ordered so that: (i) The two M's are next to each other. (ii) The two M's are next to each other but the two A's are not.","['combinations', 'permutations', 'discrete-mathematics', 'combinatorics']"
761310,The sum of reciprocal squares: estimating the remainder,"Let $a_n$ denote the $n$th remainder of the series 
$$
1+\frac{1}{2^2}+\frac{1}{3^2}+\ldots
$$
In other words, 
$$
a_n = \frac{\pi^2}{6}-\left(1+\frac{1}{2^2}+\ldots +\frac{1}{n^2}\right).
$$
I noticed that for small $n$ the following is true 
$$
\frac{1}{n+1}<a_n<\frac{1}{n}\tag{$*$}
$$
and tried to prove it for all $n$. Using induction on $n$, I ended up having to prove the estimates
$$\frac{1}{n+1}\cdot \frac{n^2+3n+3}{(n+1)(n+2)}<a_n<\frac{1}{n}\cdot \frac{n(n+2)}{(n+1)^2}$$
which are even stronger than $(*)$. My question is whether $(*)$ is true for all $n$ and, if so, how could one prove it?",['sequences-and-series']
761350,Finding the Asymptotic Curves of a Given Surface,"I have to find the asymptotic curves of the surface given by $$z = a \left( \frac{x}{y} + \frac{y}{x} \right),$$ for constant $a \neq 0$. I guess that what was meant by that statement is that surface $S$ can be locally parametrized by $$X(u,v) = \left( u, v, a \left( \frac{u}{v} + \frac{u}{v} \right) \right).$$  Do you think that my parametrization is correct (meaning that I read the description of the surface correctly), and do you know of a more convenient parametrization? Assuming that parametrization, I derived the following ($E$, $F$, $G$, are the coefficients of the first fundamental form; $e$, $f$, $g$ are coefficients of the second fundamental form; $N$ is the normal vector to surface $S$ at a point; these quantities are all functions of local coordinates $(u,v)$): $$E = 1 + a^2 \left( \frac{1}{v} - \frac{v}{u^2} \right)^2,$$ 
$$F = -\frac{a^2 (u^2 - v^2)^2}{u^3 v^3},$$
$$G = 1 + a^2 \left( \frac{1}{u} - \frac{u}{v^2} \right)^2.$$ $$N = \frac{1}{\sqrt{E G - F^2}} \left( a \left( \frac{v}{u^2}-\frac{1}{v} \right), a \left( \frac{u}{v^2}-\frac{1}{u} \right), 1 \right).$$ $$X_{u,u} = \left( 0,0, \frac{2 a v}{u^3} \right), X_{u,v} = \left( 0,0, -a \left( \frac{1}{u^2} + \frac{1}{v^2} \right) \right), X_{v,v} = \left( 0, 0, \frac{2 a u}{v^3} \right).$$ $$e = \frac{2 a v}{u^3 \sqrt{E G - F^2}},$$
$$f = - \frac{a (\frac{1}{u^2} + \frac{1}{v^2})}{\sqrt{E G - F^2}},$$
$$g = \frac{2 a u}{v3 \sqrt{E G - F^2}}.$$ Thus, the Gaussian curvature (from these calculations) is:
$$K = -\frac{a^2 u^4 v^4 (u^2 - v^2)^2}{(u^4 v^4 + 
  a^2 (u^2 - v^2)^2 (u^2 + v^2))^2}.$$ And the mean curvature would be:
$$H = \frac{a u^3 v^3 (u^4 + v^4)}{(u^4 v^4 + a^2 (u^2 - v^2)^2 (u^2 + v^2))^{3/2
 }}.$$ So, the principal curvatures are:
$$k_{\pm} = H \pm \sqrt{H^2 - K} = a u^2 v^2 \frac{u v (u^4 + v^4) \pm \sqrt{(u^2 + v^2) (a^2 (u^2 - v^2)^4 + u^2 v^2 (u^6 + v^6))}}{(u^4 v^4 + a^2 (u^2 - v^2)^2 (u^2 + v^2))^{3/2}}.$$ In order to find the asymptotic curves, but trying to avoid the differential equation, I was hoping to find the angles $\theta (u,v)$ such that the normal curvature would always be $0$.  In other words I was trying:
$0 = k_n = k_{+} \cos{(\theta)}^2 + k_{-} \sin{(\theta)}^2$, and solving for $\theta$. Assuming sufficient niceness, this calculate would result in: $$(u v (u^4 + v^4) + \sqrt{(u^2 + v^2) (a^2 (u^2 - v^2)^4 + u^2 v^2 (u^6 + v^6))}) \cos{(\theta)}^2 + (u v (u^4 + v^4) - \sqrt{(u^2 + v^2) (a^2 (u^2 - v^2)^4 + u^2 v^2 (u^6 + v^6))}) \sin{(\theta)}^2$$ First of all, is this approach (solving for $\theta$ rather than solving the differential equation) valid? If it is, after I find that angle $\theta$, determined by location $(u,v)$ on $S$, what more work do I have to do? How do I find the equations for the asymptotic curves based on this angle? If this whole method was for naught, how does one solve the differential equation. in this case, of: $$e (u')^2 + 2f u' v' + g (v')^2 = 2a v^4 (u')^2 - 2a u^3 v^3 \left( \frac{1}{u^2} + \frac{1}{v^2} \right)u' v' + 2a u^4 (v')^2 = 0?$$ (Again, assuming sufficient niceness.) (See: https://math.stackexchange.com/questions/762195/differential-equation-for-the-asymptotic-directions-of-a-given-surface ) Thank you!","['surfaces', 'ordinary-differential-equations', 'differential-geometry']"
761375,Which textbook of differential geometry will introduce conformal transformation?,"Which textbook of differerntial geometry will have these formulas about conformal transformation?
$$\tilde g_{ij} = e^{2\varphi}g_{ij}$$ 
$$\tilde \Gamma^k{}_{ij} = \Gamma^k{}_{ij}+ \delta^k_i\partial_j\varphi + \delta^k_j\partial_i\varphi-g_{ij}\nabla^k\varphi $$
$$\tilde R_{ijkl} = e^{2\varphi}\left( R_{ijkl} - \left[ g {~\wedge\!\!\!\!\!\!\bigcirc~} \left( \nabla\partial\varphi - \partial\varphi\partial\varphi + \frac{1}{2}\|\nabla\varphi\|^2g    \right)\right]_{ijkl}  \right)$$
$$\tilde R = e^{-2\varphi}\left[R + \frac{4(n-1)}{(n-2)}e^{-(n-2)\varphi/2}\triangle\left( e^{(n-2)\varphi/2} \right) \right] $$ I've read many textbooks about differential geometry, such as Do Carmo, Kobayshi, Novikov and so on. But I never found these formulas. Who can give me a reference about these formulas. Thanks!","['differential-geometry', 'riemannian-geometry', 'reference-request', 'conformal-geometry', 'online-resources']"
761395,"Finitely Additive and Countably Additive Property of Probability Function, $\mathbb{P}$.","In Grimmett and Stirzaker's Probability and Random Processes (section 1.3), for two disjoint events $A$ and $B$, we have that $\mathbb{P} (A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)$ From this statement, the authors 'jump' and state that $\mathbb{P}$ should be finitely additive, and further along in the text, they 'jump' again and state that $\mathbb{P}$ should be countably additive. My questions: Why is $\mathbb{P}$ only finitely additive? Isn't it possible to keep adding disjoint events ad infinitum : $\mathbb{P} (A_1 \cup A_2 \cup \ldots) = \mathbb{P}(A_1) + \mathbb{P}(A_2) + \ldots$ What is the difference between finitely additive and countably additive? I know that finitely additive just means I have a fixed number of events I need to add up but I am not sure of what countably additive means. I have browsed the (many) other posts around this topic but they start discussing measure theory which I haven't studied yet in my course (I'm at undergrad level).",['probability-theory']
761412,A question about inequality ${(n+1)\over e^n}^n<n!$,"How to prove the inequality $${(n+1)\over e^n}^n<n!$$ I have tried mathematical induction, but it doesn't work! Are there other methods to solve it?","['limits', 'inequality', 'real-analysis', 'analysis']"
761414,$-4\zeta(2)-2\zeta(3)+4\zeta(2)\zeta(3)+2\zeta(5)=S$,"EDIT:  Due to the solution below, I edited the answer of the post.  Thanks!!!! Hi I am trying to calculate the infinite double sum 
$$
S:=\sum_{j,k=1}^\infty \frac{H_j(H_{k+1}-1)}{jk(k+1)(j+k)}=-4\zeta(2)-2\zeta(3)+4\zeta(2)\zeta(3)+2\zeta(5),\quad H_n:=\sum_{k=1}^n\frac{1}{k}\ \ \ (\text{Harmonic Numbers})
$$
Thank you. I am not sure what to do, possibly write the sum as an integral and try working with the integral instead of the sum?  I was trying to figure out if we could write it as an integral representation in terms of logarithm functions.  But this will just give you this sum as the answer.  So I do not know how to calculate the zeta functions from the sum.  Note the Riemann Zeta function is given by 
$$
\zeta(s)=\sum_{n=1}^\infty \frac{1}{n^s},\quad \zeta(2)=\frac{\pi^2}{6}.
$$","['sequences-and-series', 'integration', 'harmonic-numbers', 'real-analysis', 'complex-analysis']"
761423,L'Hopital quicky,"suppose  L'Hopital applies and  $$\lim_{x\to\infty}\frac{f(x)}{g(x)} = \lim_{x\to\infty}\frac{f'(x)}{g'(x)}$$  under what conditions is it true then that $$\lim_{x\to\infty}\frac{\frac{f(x)}{g(x)} }{  \frac{f'(x)}{g'(x)}}=k$$ for non-zero constant $k$ background:
consider the sum $$\sum\frac{f(n)}{g(n)}$$
for example, $$\sum \frac{n}{n^3+5}$$ and consider a student's approach taking the limit on the nth term using l'hopital $$\lim_{x\to\infty} \frac{n}{n^3+5}=\lim_{x\to\infty}\frac{1}{3n^2}$$ at this point the student declares the series convergent as it behaves like $\sum \frac{1}{3n^2}$. Obviously the LCT is not being used in the traditional sense, yet there may be something true in this madness.. I suspect..","['calculus', 'limits']"
761450,Why normal approximation to binomial distribution uses np> 5 as a condition,"I was reading about normal approximation to binomial distribution and I dunno how it works for cases when you say for example p is equal to 0.3 where p is probability of success. On most websites it is written that normal approximation to binomial distribution works well if average is greater than 5. I.e. np> 5
But I am unable to find where did this empirical formula came from? If n is quite large and probability of success is equal to .5 then i agree that normal approximation to binomial distribution is going to be quite accurate. But what about other cases? How can one say np> 5 is the condition for doing normal approximation?","['statistics', 'normal-distribution', 'probability-distributions']"
761453,Convergence of $\sum\limits_{n=2}^ \infty (-1)^n \frac{(\ln n)^p}{n^q}$ with $0<q < p$,"Let $p$ and $q$ be positive real numbers such that $q < p$ , then is the following series convergent?
$$
\sum\limits_{n=2}^\infty(-1)^n\frac{(\ln n)^p}{n^q}
$$",['sequences-and-series']
761455,difference between sequence in topological space and metric space,"Reading the book about topology, I find an interesting difference between two spaces: We use net convergence $\{p_\lambda\}_{\lambda\in\Lambda}\rightarrow p$ in frontier, but use sequence convergence $\{p_n\}_{n\in\mathbb N}\rightarrow p$ in latter. So I want to clarify the cause of difference. My thought is that may be the first countable property . In Lee's book, there are two problems: Any metric space is first coutable. Let $X$ be first countable. We will have two statements: For any set $A\subset X$ and any point $p\in X$, $p\in\bar A$ if and only if there is a sequence $\{p_n\}_{n\in\mathbb N}\in A$ such that $p_n\rightarrow p$. A map $f:X\rightarrow Y$ is continuous if and only if $f$ takes convergent sequence in $X$ to convergent sequence in $Y$. So we can substitute sequence convergence for net convergence in first countable space. However I do not think two problems give the core answer to my question. Any help, thank you.","['general-topology', 'soft-question']"
761458,Question about Hahn-Banach theorem,"Let $(X,\|\cdot\|_1)$ and $(Y,\|\cdot\|_2)$ be normed spaces, and $X\subset Y$. If each $f\in (X,\|\cdot\|_1)^\ast$ extends to a bounded linear functional in $(Y,\|\cdot\|_2)^\ast$ with same norm, then $(X,\|\cdot\|_1)$ is a subspace of $(Y,\|\cdot\|_2)$, i.e., for all $x\in X$, $\|x\|_1=\|x\|_2$. I only proved that $\|x\|_1\leq\|x\|_2$ for all $x\in X$. I am in a difficult condition to prove $\|x\|_1\geq\|x\|_2$ for all $x\in X$. Thanks a lot.","['operator-theory', 'operator-algebras', 'functional-analysis']"
761467,Prove that $\sqrt{n} > \ln n$,"Prove that $\sqrt{n} > \ln n$ for all $n \in \mathbb{N}$. I need to use this fact for one of the proofs that I am working on. However, I am having trouble proving this. I tried induction but don't really know how to do it. Can someone help me with this?","['inequality', 'sequences-and-series', 'real-analysis']"
761488,Determine if the following series is convergent.,Determine if the following series is convergent: $$\sum_n^{\infty} \frac{1}{n^2 + \cos \pi n}$$.,"['real-analysis', 'limits']"
761504,"What does ""twice as likely"" mean?","Once in a while I hear people say something like X is twice as likely as Y. What they usually mean is: $$p(X) = 2 \cdot p(Y)$$ and - in the context they refer to - they usually have $p(Y) < \frac{1}{2}$. But what do you do if $p(Y) > \frac{1}{2}$? Can there be an event $X$ that is twice as likely as $Y$? It also feels wrong to me to say that $p(X) = 100 \%$ is twice as likely as $p(Y) = 50\%$. Is there a good definition what twice as likely means? Some thoughts about this Let's call this ""twice as likely"" a function $$d: D \rightarrow [0, 1]$$ I would expect $d$ to have the following properties: $D = [0, m]\subseteq [0,1]$ $d(0) = 0 $ $d$ is monotonous","['recreational-mathematics', 'probability']"
761523,"Algebra: What does ""is defined for"" mean?","In algebra what does: ""Is defined for"" mean? I have a question posted: $\sqrt{a+b}$ is defined for $-b \leq a$. The question posed is: Is this true... My question: WHAT DOES ""Is Defined For"" mean??","['algebra-precalculus', 'terminology']"
761539,Set up a double integral over the region $0\le y\le |x|$,"Let $f(x,y) = x^2y + xy^2 $ and let $$R = \{ (x,y) : |x| \leq 1 , \; \; 0 \leq y \leq |x| \} $$ Want: $\int_R f $ My setting up $$ \int_{-1}^1 \int_{-x}^x f dydx $$ Is this the correct integral that I need to compute?","['multivariable-calculus', 'calculus', 'integration']"
761550,Prove that this holomorphic function is constant,"Suppose $f$ is a non-vanishing continuous function on $\bar{\mathbb{D}}$ that is
holomorphic in $\mathbb{D}$. Prove that if
$$|f(z)|=1~~~\text{whenever}~~~|z|=1$$
then $f$ is constant. I have proved this by showing that the function
$$F(z)=\left\{\begin{array}{cc}f(z)&\text{when}~~|z|\leq1\\ 1/\bar{f}(\bar{z})&\text{otherwise}\end{array}\right.$$
is bounded and entire. Is there any other more elegant way to do this problem, because my method is turning out to be too gruesome for this beautiful problem. Thanks in advance!",['complex-analysis']
761613,Riesz's Theorem of compactness,"$\left(X,\|\cdot\|\right)$ is a normed vector space. $\textbf{Riesz's Theorem of compactness}$ says that
$$ \{x \in X \colon \|x\| \leq 1 \} \ \text{compact} \ \Longleftrightarrow \ \text{Each bounded sequence in $X$ has a convergent subsequence}.$$ I am looking for the proof of this theorem. Some thoughts to $""\Rightarrow""$:
If $\{x \in X \colon \|x\| \leq 1 \}$ is compact, it's clear that each sequence in $\{x \in X \colon \|x\| \leq 1 \}$ has a convergent subsequence. But how can I conclude that each bounded sequence in $X$ (!?) has a convergent subsequence?","['compactness', 'functional-analysis']"
761620,Estimate $\displaystyle\left|\int_{\frac{\pi}{k}}^{\frac{\pi}{2}} (\sin \theta)^{-1+\frac{i(n+1)y}{2}} d\theta \right|$,"I have to estimate the following integral 
$$\left|\int_{\frac{\pi}{k}}^{\frac{\pi}{2}} (\sin \theta)^{-1+\frac{i(n+1)y}{2}} d\theta \right|,\quad \forall k,n\geq 2 $$ According to Sogge (Oscillatory Integrals and Spherical Harmonics. Duke Mathematical Journal 53 (1986), no. 1, 43-65) the integral is $\leq C \max(1,|y|^2)$ where $C$ is independent of $y,k$, and this can be proved by a routine integration by parts argument but I cannot figure it out. Thanks in advance!","['calculus', 'analysis']"
761633,"The number of increasing 3-term arithmetic progressions in the set $\{1,2,3,4,\dots, 2n\}$","In how many ways can three distinct numbers be chosen from the set $\{1,2,3,4,\dots,2n\}$ such that the numbers are in increasing arithmetic progression? Progress : The common difference for the selected numbers can lie between 1 to $2n/3$. So it seems I need to work for every common difference from $1$ to $2n/3$. Is this fine?","['permutations', 'combinations', 'combinatorics']"
761643,Exponential of matrices and bounded operators,"Let $A$ be a complex $n \times n$ matrix, such that the function $t\mapsto e^{tA}x$ is bounded on $\mathbb{R}$ and nonzero, for some vector $x\in \mathbb{C}$. How can we prove that $\inf_{t\in \mathbb{R}}|e^{tA}x|>0$ or in other words $|e^{tA}x|\geq c>0$ for all $t\in \mathbb{R}$. I can only prove this in the case $A=a \in \mathbb{C}$, because $|e^{ta}x|=e^{Re(a)t}|x|$, and the boundedness implies that $Re(a)=0$, so $|e^{ta}x|=|x|=c>0$ because $t\mapsto e^{ta}x$ is supposed to be nonzero. I also want to know if we have this property in the case $A$ is a bounded operator on an infinite dimensional Banach space $X$.","['ordinary-differential-equations', 'operator-theory', 'matrices', 'linear-algebra', 'banach-spaces']"
761644,A fascinating number chain.,"Take a two digit number $10x+y$ of which both digits are different. now add $y-x$ to this number. By repeating this process you will get a chain of numbers $45,46,48,52,49,54,53,51,47,50.$ after $50, 45$ will come and chain will repeat. from any number we will enter in this chain. Can anyone help me to prove this?","['elementary-number-theory', 'discrete-mathematics']"
761658,"Number of all labeled, unordered rooted trees with $n$ vertices and $k$ leaves.","I've been trying to do the following exercise: The problem Find the number of all labeled, unordered rooted trees with $n$ vertices and $k$ leaves. I know that I should try to write an equality for the generating function $T(z,y)$ where we use the following weight for a tree $W$ with $n$ vertices and $k$ leaves: $\omega(W) = z^{n}y^{k}$ and thus we have $T(z,y) = {\sum}_{_W}\omega(W)$. After writing the equality I should use the lagrange inversion formula (this is a hint given in the exercise). My problem I have troubles with writing the equality for $T(z,y)$. First I tried to write down the first terms of $T(z,y)$ - to look for patterns. Then I tried to write the species of labeled unrooted trees in terms of other species. In both cases I ended up getting more confused. Could someone give a hint for writing the equation for $T(z,y)$? How do I handle such problems?","['trees', 'combinatorics']"
761699,Prove That $f(n+f(n))=n$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question if $f:\mathbb{N}\rightarrow\mathbb{N}$ is a function such that $f(1)=1$ and $$f(n)=n-f(f(n-1))\,\,\: \forall n \ge 2$$ Prove That $$f(n+f(n))=n$$","['functions', 'functional-equations']"
761740,"Compute $\int_0^\infty \frac{\ln x}{(1+x)^3}\,\mathrm{d}x$","Compute $$\int_0^\infty \frac{\ln x}{(1+x)^3}\,\mathrm{d}x$$ Well by comparison test the integral is convergent. I tried to use residue theorem, with the positive real axis being the branch cutting line, but it did not work. Any hint will be appreciated.","['calculus', 'complex-analysis']"
761745,For which n does the inequality $2 \uparrow^{n+1}n > 3\uparrow^n 3 +2$ hold?,"For which n does the following inequality hold ? $$2 \uparrow^{n+1}n > 3\uparrow^n 3 + 2$$ where $\uparrow$ stands for knuth's up-arrow notation. I need this inequality to prove that $$f_{\omega+1}(n) > G(n)$$ for $n\ge 8$ where $f_{\omega+1}(n)$ is a function from the
fast growing hierarchy and G(n) is Graham's 
sequence $$G(1) = 3\uparrow^4 3$$ $$G(n+1) = 3\uparrow^{G(n)} 3$$ for all n > 0.","['big-numbers', 'number-theory']"
761749,Question about Quaternion group $Q_8$ and Dihedral group $D_8$,"pretty much got stuck with the following question (it has several parts): a). Show that $D_8$ isn't isomorphic to $Q_8$ b). Let $K$ be a subgroup of $GL_2(\mathbb C)$ so that $$K=\left\langle \begin{pmatrix}
        0 & 1 \\
        -1 & 0 \\
        \end{pmatrix}, \begin{pmatrix}
        0 & 1 \\
        1 & 0 \\
        \end{pmatrix}\right \rangle.$$ Show $K$ is non-abelian order 8 group and is isomorphic exactly to either $D_8$ or $Q_8$. Show this by building specific isomorphism. Thank you for any assistance! P.S. Can someone perhaps expand more on the notation of groups such as $K$? I know it means smaller subgroup containing both elements, but are there any more properties, etc'?","['group-theory', 'abstract-algebra']"
761766,"Linear regression, reversing it back then.","Need's formatting, editing will take some time.","['statistics', 'logic']"
761777,Distribution of the sum of the $q$th largest observations to the sum of total for a power-law.,"Where $X_{(1)}, X_{(2)}, \ldots,X_{(n)}$ are sorted independents r.v.s, where we index and order in such a way that $X_{(i)} \geq X_{(i-1)}$ , $i>1$ where all realizations follow the same Standard Pareto distribution with density $\phi_\alpha (x)=\alpha \, x_\min^\alpha x^{-\alpha -1}\mathbb{1}_{x\geq
x_\min }$ ; What is the in-sample distribution of the ratio of the ordered sum above the $q^{th}$ largest observation to the total,with a total sample of $n$ ? $$ \hat{\kappa}=\frac{X_{(q)}+X_{(q+1)}+\cdots+X_{(n)}}{X_{(1)}+X_{(2)}+\cdots+X_{(n)}}$$ All I have is $0 \leq \hat{\kappa} \leq 1$ . Where $\kappa$ is the true value of the estimator, which we were able to derive in closed form, we see biases in Monte Carlo where $\hat{\kappa} < \kappa$ even for large $n$ (at an exponent $\alpha=1.1$ and would like to get an idea of the in-sample distribution. We assume $1 < \alpha \leq 2$ .","['statistics', 'probability-distributions', 'probability', 'order-statistics']"
761826,Hint finding exact value of half-angle when $\tan (\theta) = {3}$,"Unlike others I've tried, I'm having a hard time with this half-angle exercise: If $tan(\theta)={3}$ and $\theta$ is in QIII, find $\tan\left(\frac{\theta}{2}\right)$ Here's what I know (or think I know): $\cos(\theta)=\left(-\frac{\sqrt{10}}{10}\right)$ I shold use the half-angle formula for tan: $\tan\left(\frac{\theta}{2}\right)$ $\pm\sqrt\frac{1-\cos\theta}{1+\cos\theta}$ I know the answer is: $$\frac{\sqrt{10}+1}{-3}$$ The trouble for me seems to be in simplifying. I'm not the best at mathjax, so please forgive me for not typing out my work. I can kick it around until I get to something like $$\sqrt{\frac{10+\sqrt10}{10}\over\frac{10-\sqrt10}{10}}$$ I've tried to to then reduce it to: $$\sqrt{{10+\sqrt10}\over{10-\sqrt10}}$$
But from here on, multiplying the top and bottom by the conjugate isn't working. I think I just need a gentle push in the right direction. Thanks for any help! UPDATE: I spoke with my professor today and he pointed out that for the half-angle $\frac{\theta}{2}$ I had to remember to multiply the interval of the angle by $\frac{1}{2}$. So, instead of $\tan\theta=3$ being in quadrant III, $\tan\left(\frac{3}{2}\right)$ should be between $\frac{\pi}{2}$ and $\frac{3\pi}{4}$. This means my value of cosine (in the denominator) should also be negative. (To be clear, cosine would also be negative in QIII, I'm simply pointing out that I should have halved my interval.) That said, thanks again to those who helped me with my algebra/simplification, as well as those who suggested other ways of thinking about the exercise. You were a tremendous help!","['trigonometry', 'algebra-precalculus']"
761827,Geometric Derivation of the D-Bar Operator $\frac{\partial}{\partial z} = \frac{1}{2}(\frac{\partial }{\partial x} - i\frac{\partial }{\partial y})$,"This picture from Visual Complex Analysis is all you need to derive the Cauchy-Riemann equations, i.e. from the picture we see $i \frac{\partial f}{\partial x} = \frac{\partial f}{\partial y}$ should hold so we have $$i \frac{\partial f}{\partial x} = i \frac{\partial (u+iv)}{\partial x} = \frac{\partial (u+iv)}{\partial y} \rightarrow C \ R \ Eq's$$ Is there a similar picture-derivation of the operators $$\frac{\partial}{\partial z} = \frac{1}{2}(\frac{\partial }{\partial x} - i\frac{\partial }{\partial y})$$ $$\frac{\partial}{\partial \bar{z}} = \frac{1}{2}(\frac{\partial }{\partial x} + i\frac{\partial }{\partial y})?$$ The fact the differential forms can be visualized in terms of sheets tells me there can be one, any ideas?",['complex-analysis']
761832,"If $d|n$, then $\phi(d)|\phi(n)$","Where $\phi(n)$ denotes Euler's Totient Function. My proof follows, I was hoping someone could verify it, and give critique. Let $d,n\in\mathbb{Z}^+$ so that $d|n$. By the Fundamental Theorem of Arithmetic, $n$ can be written in the following way:
$$n = p_1^{\beta_1}\cdots p_n^{\beta_n}$$
where $p_j,\ j=1,...,n$ are all distinct primes. As $d$ divides $n$, $d$ can be written as:
$$d=p_1^{\alpha_1}\cdots p_n^{\alpha_n}$$
where $0\leq\alpha_j\leq\beta_j$, and $\ j=1,...,n$.
Then, using the multiplicative property of $\phi(n)$ and the fact that $\phi(p^k)=p^{k-1}(p-1)$ for some $k\in\mathbb{Z}^+$:
\begin{align}
\notag \phi(n) &= \phi(p_1^{\beta_1}\cdots p_n^{\beta_n})\\
\notag &= \phi(p_1^{\beta_1})\cdots\phi(p_n^{\beta_n})\\
\notag &= p_1^{\beta_1-1}(p_1-1)\cdots p_n^{\beta_n-1}(p_n-1)
\end{align}
\begin{align}
\notag \phi(d) &= \phi(p_1^{\alpha_1}\cdots p_n^{\alpha_n})\\
\notag &= \phi(p_1^{\alpha_1})\cdots\phi(p_n^{\alpha_n})\\
\notag &= p_1^{\alpha_1-1}(p_1-1)\cdots p_n^{\alpha_n-1}(p_n-1)
\end{align}
As $\alpha_j\leq\beta_j$ for all $j$, we must also have $\alpha_j-1\leq\beta_j-1$ for all $j$, and:
$$p_j^{\beta_j-1}(p_j-1) = p_j^{\beta_j-\alpha_j}p^{\alpha_j-1}(p_j-1),\ \forall j\in\{1,...,n\}$$
So $\phi(n)$ can be written as:
\begin{align}
\notag \phi(n) &= p_1^{\beta_1-1}(p_1-1)\cdots p_n^{\beta_n-1}(p_n-1)\\
\notag &= p_1^{\beta_1-\alpha_1}p_1^{\alpha_1-1}(p_1-1)\cdots p_n^{\beta_n-\alpha_n}p_n^{\alpha_n-1}(p_n-1)\\
\notag &= (p_1^{\beta_1-\alpha_1}\cdots p_n^{\beta_n-\alpha_n})p_1^{\alpha_1-1}(p_1-1)\cdots p_n^{\alpha_n-1}(p_n-1)\\
\notag &= (p_1^{\beta_1-\alpha_1}\cdots p_n^{\beta_n-\alpha_n})\phi(d).
\end{align}
and $\phi(d)|\phi(n)$.","['proof-verification', 'number-theory']"
761856,$\sum_{n=-\infty}^\infty e^{-\alpha n^2+\beta n}$,"Hi I am trying to calculate the sum given by
$$
\sum_{n=-\infty}^\infty e^{-\alpha n^2+\beta n}=\ = \sqrt{\frac{\pi}{\alpha}} e^{\beta^2/(4\alpha)} \vartheta_3\big(-\frac{\pi\beta}{2\alpha},e^{-\pi^2/(2\alpha)}\big),\quad \alpha>0,\beta \in \mathbb{R}.
$$
I know we can express this in terms of elliptic theta functions as shown.  But I am looking for a method to prove this.  Thanks.  I haven't studied summations in 30 years, however I am looking for methods possibly using Poisson Summation formula, residue analysis, etc. Thanks.","['calculus', 'integration', 'real-analysis', 'summation', 'complex-analysis']"
761865,"If a polynomial $g$ divides $f$ and $f'$, then $g^2$ divides $f$?","Here's a homework problem from Artin's Algebra that I'm having a lot of trouble with Let $f(x) \in F[x]$ (where $F$ is a field of characteristic $0$).  If $g$ is an irreducible polynomial that is a common divisor $f$ and $f'$, then $g^2$ divides $f$ (where $f'$ denotes the derivative of $f$ in $F[x]$). Let $K$ be an extension of $F$ such that $f$ splits completely in $K$.  So we can write $f(x) = \prod_{i=1}^n (x - \alpha_i)$ for some $\alpha_i \in K$.  Because $g$ divides $f$ in $F[x]$, we know that $g$ divides $f$ in $K[x]$.  Since $g$ divides $f$ we can write $g(x) = \prod_{j=1}^m (x - \alpha_{i_j})$.  Because $g$ is a common divisor of $f$ and $f'$, the roots $\alpha_i$ have some multiplicity greater than $1$, so that $(x - \alpha_i)^2$ divide $f$ for each $i$ (**).  Then $g^2$ divides $f$. I think this is the right idea, although it feels like there are some holes in the argument (specifically the sentence marked with (**) at the end).  I also don't think I used the assumption that $g$ is irreducible.  Does this look OK?","['field-theory', 'abstract-algebra', 'polynomials']"
761867,Congruences and prime powers,"I have just a small question that probably is not hard to answer, but I could not find and elegant solution to this question. Let $p$ and $q$ be prime numbers. $$5^q\equiv 2^q \pmod p$$
$$5^p\equiv 2^p \pmod q$$ Find all solutions to this modular equation. I know solutions are $p=q=3$ and $p=3; q=13$ (and the other way around) But I do not find a way to prove these are the only ones (or find other solutions).","['prime-numbers', 'modular-arithmetic', 'number-theory']"
761924,Can one give me some concrete examples explaining Picard's Great Theorem,"Picard's Great Theorem Every non-constant entire function attains every complex value with at most one exception. Furthermore, every analytic function assumes every complex value, with possibly one exception, infinitely often in any neighborhood of an essential singularity. Can someone give me some concrete examples explaining this result?","['complex-geometry', 'complex-analysis']"
761930,Integral $\int_0^1 dx \frac{\ln x \ln^2(1-x)\ln(1+x)}{x}$,"I am trying to calculate $$
I:=\int_0^1 dx \frac{\ln x \ln^2(1-x)\ln(1+x)}{x}$$ Note, the closed form is beautiful (yes beautiful ) and is given by $$
I=−\frac{3}{8}\zeta_2\zeta_3 -\frac{2}{3}\zeta_2\ln^3 2  +\frac{7}{4}\zeta_3\ln^2 2-\frac{7}{2}\zeta_5+4\ln 2 \operatorname{Li}_4\left(\frac{1}{2}\right)+\frac{2}{15}\ln^5 2+4\operatorname{Li}_5\left(\frac{1}{2}\right)
$$ where $$
\zeta_s=\sum_{n=1}^\infty \frac{1}{n^{s}},\qquad \operatorname{Li}_s(z)=\sum_{n=1}^\infty \frac{z^n}{n^s},\qquad\text{for}\ |z|<1.
$$ I succeeded in writing the integral as $$
I=-\sum_{i=0}^\infty \int_0^1  x^i\ln x\ln(1+x)\ln(1-x)\ dx,
$$ but I am confused as to where to go from here.  Possibly I was thinking of trying to use Mellin transforms or residues. A reference to aid us is here . (Since somebody has asked for reference) We can also write I as $$
I=\sum_{i=0}^\infty \sum_{j=1}^\infty \frac{1}{j}\sum_{k=1}^\infty \frac{1}{k} \int_0^1  x^{i+j+k} \ln x\ dx
$$ using $$
\int_0^1 x^n \ln x\ dx= -\frac{1}{(n+1)^2},
$$ we can simplify this, but I am not sure then how to compute the triple sum.  Thank you again.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'harmonic-numbers']"
761994,Number of palindromic numbers less than a power of $10$,"I noticed that every $10^{n}$ there is a certain number of palindromic numbers that I collected in this sequence:
$$S=\{a_n,a_{n+1},a_{n+2}...\}=\{10,9,90,90,900,900...\}$$
where every number $a_n$ is the number of palindromic numbers between $10^{n}$ and $10^{n+1}$ starting with $n=0$. Now I wanted to know the number of palindromic numbers less than $10^p$ and I came up with this formula: 
\begin{cases}
1+\sum^{\lfloor{\frac{p}{2}\rfloor}}_{k=0} 18 \cdot10^k & {\text{if $p$ is even}}\\
1+\left(\sum^{\lfloor{\frac{p}{2}+1}\rfloor-1}_{k=0} 18 \cdot10^k\right)- \left(9 \cdot 10^{\lfloor{\frac{p}{2}+1}\rfloor-1} \right) & {\text{if $p$ is odd}}
\end{cases}
Is this right?
Thanks! :)","['elementary-number-theory', 'palindrome', 'summation', 'sequences-and-series']"
762003,What is defined by rate of change at a single point?,"Rate of change measures how fast a process is going when it moves from one point to another. It measures the change of, say, $Y$ when $X$ moves from $X$ to $X + \Delta X$. But my problem arises when rate of change is concerned at only a single point; the mathematical tool to solve this is to use derivative at that point provided the graph is continuous. I am unable to understand the rate of change concept at a single point; I have always connected the rate of change with two points. So what is the rate of change concept at a single point? Let a spherical balloon have a variable radius & the rate of change of volume w.r.t radius when radius is $7$ unit is $196\pi$. What is the meaning of this statement when it mentions the rate of change at a single point i.e. at $r=7$? Thanks for your help.","['calculus', 'intuition', 'derivatives']"
762022,The $\frac{1}{x+i\varepsilon}$ distribution.,"I read that the distribution defined as: $$ \lim_{\varepsilon \rightarrow 0}\frac{1}{x+i\varepsilon}$$
is equal to $$p.v. \frac{1}{x} -i\pi \delta(x)$$ So that for any test function $f$, $$\lim_{\varepsilon\rightarrow 0} \int_{-\infty}^\infty \frac{f(x)dx}{x+i\varepsilon} = p.v.\int_{-\infty}^\infty \frac{f(x)}{x}dx - i\pi f(0).$$ But when I calculate the integral of $f(z)/z+i\varepsilon$ along this contour: and then the limit $R\to \infty$, the result I arrive at is the following: $$\lim_{\varepsilon\rightarrow 0} \int_{-\infty}^\infty \frac{f(x)dx}{x+i\varepsilon} = \lim_{\varepsilon\rightarrow 0} \left( \int_\varepsilon^\infty \frac{f(x+i\varepsilon)dx}{x+i\varepsilon} + \int_{-\infty}^{-\varepsilon} \frac{f(x+i\varepsilon)dx}{x+i\varepsilon} \right) -i \int_0^\pi f(\varepsilon e^{i \theta} -i\varepsilon) d\theta$$ I can more or less accept the second term being equal to $-i\pi f(0)$, but I don't see why the first one should be the principal value - the epsilons inside the integral are bugging me. But any change of variables, say $z=x+i\varepsilon$, would damage the contour so it would no longer look like a p.v. How can I retrieve the desired result from this?","['distribution-theory', 'integration', 'complex-analysis']"
762024,"How to show $\{a^n \bmod \alpha\}_{n \in \mathbb{N}}$ is dense in $[0,\alpha]$ if $a > 1$ is trancendental over ${\mathbb Q}[\alpha]$","How to show $\{a^n \bmod \alpha\}_{n \in \mathbb{N}}$ is dense in $[0,\alpha]$ if $a > 1$ is trancendental over ${\mathbb Q}[\alpha]$? If $a$ is transcendental over ${\mathbb Q}[\alpha]$ then the integer multiples $\{na \bmod \alpha\}_{n \in \mathbb{N}}$ are dense in $[0,\alpha]$. But what about the positive integer powers of $a$ when $a > 1$? It seems like $\{a^n \bmod \alpha\}_{n \in \mathbb{N}}$ should be dense if $a > 1$ is transcendental over ${\mathbb Q}[\alpha]$. But how to prove it?","['transcendental-numbers', 'real-analysis']"
762065,Finding relationship between Laplace-Beltrami operators of two spheres,"Let $S$ and $T$ be spheres with radius $R_S$ and $R_T$ respectively. Define the diffeomorphism $\Phi:S \to T$ by $\Phi(s) = \frac{R_T}{R_S}s$. Given a function $u:T \to \mathbb{R}$, we can define $\tilde u:S \to \mathbb{R}$ by $$\tilde u(s) = u(\Phi(s)) = u\left(\frac{R_T}{R_S}s\right).$$ I am trying to write the Laplace-Beltrami operator $\Delta_T$ of $u$ in terms of $\Delta_S$ and $\tilde u$. I start with the formula $$\Delta_{S(R)} f(x) = R^2\Delta f\left(R\frac{x}{|x|}\right)\tag{1}$$
which holds for any sphere $S(R)$ of radius $R$. Using this I see that
$$\Delta_S \tilde u(s) = R_S^2\Delta \tilde u\left(R_S\frac{s}{|s|}\right) = R_S^2\Delta u\left(R_T\frac{s}{|s|}\right)$$
with the last equality by definition of $\tilde u$. I want to say this is equal to $$\frac{R_S^2}{R_T^2}\Delta_T u(s)$$ by the formula (1). But then since $s \in S$ it doesn't make sense to write the above expression since we are taking the Laplace-Beltrami over $T$. And I'm not sure that I can use (1) because in (1) $x \in S(R)$, and here $s \in S$ and not $s \in T$. How do I do this calculation correctly??","['manifolds', 'differential-geometry']"
762066,"Derivative of Riemann zeta, is this inequality true?","Is the following inequality true?
$$\gamma -\frac{\zeta ''(-2\;n)}{2 \zeta '(-2\;n)} > \log (n)-\gamma$$ This for $n$ a positive integer, $n=1,2,3,4,5,...$, and more precisely when $n$ approaches infinity. $\gamma$ is the Euler-Mascheroni constant, $\zeta(s)$ is the Riemann zeta function and $\zeta'(s)$ is a derivative. Plotting the left hand side (red) and the right hand side (blue): we see that they are close to each other. Mathematica program for the plot: Clear[n, s, t, aa, bb, gg1, gg2, g1, g2, nn, a, b]
nn = 40; 
Limit[Zeta[s] - 
  Derivative[1][Zeta][s - 1 + ZetaZero[1]]/Zeta[s - 1 + ZetaZero[1]], 
 s -> 1]
a = Monitor[
   Re[Table[
     EulerGamma - 
      Derivative[2][Zeta][-2*n]/(2*Derivative[1][Zeta][-2*n]), {n, 1, 
      nn}]], n]; 
Clear[n]
Print[""Log[n]-EulerGamma""]
b = Table[N[Log[n]] - EulerGamma, {n, 1, nn}]; 
g1 = ListLinePlot[a, PlotStyle -> Red]; 
g2 = ListLinePlot[b]; 
Show[g1, g2, ImageSize -> Large] Edit 21 4 2014: After Raymond Manzonis answer below: $$\Im(\rho _n) \sim -\frac{1}{2} \left(-\frac{\zeta '(\Im(\rho _n)+1)}{\zeta \left(\Im\left(\rho _n\right)+1\right)}-\psi \left(\Im\left(\rho _n\right)+1\right)+\log (2 \pi )\right)+\frac{1}{\Im\left(\frac{1}{\rho _n}\right)}-\Re\left(\frac{\zeta ''(\rho _n)}{2 \zeta '(\rho _n)}\right)$$ nn = 40;
-N[Table[Re[(Zeta''[
        ZetaZero[n]]/(2*Zeta'[ZetaZero[n]]))] - (((Log[2*Pi] - 
         PolyGamma[Im[ZetaZero[n]] + 1] - 
         Zeta'[Im[ZetaZero[n]] + 1]/Zeta[Im[ZetaZero[n]] + 1])/2)
     ) + (Im[ZetaZero[n]^-1]^-1), {n, 1, 12}], 30] (*program start*)(*After Raymond Manzoni Mathematics stackexchange \
Apr 20 2014*)
nn = 30;
N[Table[-((Re[(Zeta''[
           ZetaZero[n]]/(2*Zeta'[ZetaZero[n]]))] - (((Log[2*Pi] - 
            PolyGamma[Im[ZetaZero[n]] + 1] - 
            Zeta'[Im[ZetaZero[n]] + 1]/Zeta[Im[ZetaZero[n]] + 1])/
          2)) + (Im[ZetaZero[n]^-1]^-1) + Im[ZetaZero[n]])*
     Im[ZetaZero[n]]^2), {n, 1, nn}], 20]
%^-1 Clear[n, x, y, a]
a = x /. Solve[-((y + x)*x^2) == 1/48, x][[2]]
n = 62;
y = Re[(Zeta''[
       ZetaZero[n]]/(2*Zeta'[ZetaZero[n]]))] - (((Log[2*Pi] - 
        PolyGamma[Im[ZetaZero[n]] + 1] - 
        Zeta'[Im[ZetaZero[n]] + 1]/Zeta[Im[ZetaZero[n]] + 1])/
      2)) + (Im[ZetaZero[n]^-1]^-1);
(N[a, 30] -
   Im[N[ZetaZero[n], 30]])*Im[N[ZetaZero[n], 30]]^4
Re[%]^-1 Just for memory May 3, 2014: Clear[s, z]
Monitor[Table[
  Limit[Zeta[s] - 
    RiemannSiegelZ'[s - 1 + Im[ZetaZero[z]]]/
     RiemannSiegelZ[s - 1 + Im[ZetaZero[z]]], s -> 1], {z, 1, 4}], z]
N[%] Table[N[Im[
    1/2 I Log[\[Pi]] - 
     1/4 I PolyGamma[0, 1/4 - 1/2 I Im[ZetaZero[n]]] - 
     1/4 I PolyGamma[0, 1/4 + 1/2 I Im[ZetaZero[n]]]] == 
   Im[(I Zeta''[1/2 + I Im[ZetaZero[n]]])/(
    2 Zeta'[1/2 + I Im[ZetaZero[n]]])]], {n, 1, 12}] Returns True,True,True,...","['euler-mascheroni-constant', 'dirichlet-series', 'riemann-zeta', 'number-theory']"
762118,Does the series $\sum_{n=0}^{+\infty} \sin((1+\sqrt{2})^n\pi)$ converge?,"I am trying the following exercise, Convergence of the series $\sum_{n=0}^{+\infty} \sin((1+\sqrt{2})^n\pi)$ I tried like the method for $\sum_{n=0}^{+\infty}  \sin((2+\sqrt{3})^n\pi)$, with $u_n=\sin((1-\sqrt{2})^n\pi)$ unfortunately $(1-\sqrt{2})<0$ so I cannot use theorem for positivness. There is an another trick for this one ? Thank you in advance","['sequences-and-series', 'real-analysis']"
762123,Alexander–Briggs notations for the links or knots of $N^3_m$,"We can use Alexander–Briggs notations for the links or knots. For example, is three separate loops with no links. And there are many other examples of Alexander–Briggs notations for three separate loops. Question 1: where can I find the Reference and Figures for more complete lists for Alexander–Briggs notations and their corresponding graphs for three separate loops, i.e. with 
  $$N^3_m$$ in Alexander–Briggs notations? Here $3$ means 3 separate loops. And $N$ means the crossing numbers; $m$ is simply a counting of different types. I am interested to know, for example, Question 2:  what is $4^3_1$? and what is $5^3_1$, $4^3_2$, $5^3_2$, $6^3_4$(?) if there is any.","['general-topology', 'knot-invariants', 'knot-theory']"
762147,prove or disprove: $\lim_{x\to \infty} \frac{f(x)}{g(x)}=\lim \frac{f'(x)}{g'(x)}=0 \implies \lim \frac{\frac{f(x)}{g(x)}}{\frac{f'(x)}{g'(x)}}\ne 0$,"my attempt $$\lim_{x\to \infty}\frac{\frac{f(x)}{g(x)}}{\frac{f'(x)}{g'(x)}}\text{ yields }\frac{0}{0}$$ then use l'hopital on this $$\lim_{x\to \infty}\frac{\frac{f(x)}{g(x)}}{\frac{f'(x)}{g'(x)}} =\lim_{x\to \infty} \frac{\frac{f'}{g}-\frac{fg'}{g^2}}{\frac{f''}{g'}-\frac{f'g''}{g'^2}} $$ $$\lim_{x\to \infty}\frac{\frac{f(x)}{g(x)}}{\frac{f'(x)}{g'(x)}} =\lim_{x\to \infty} \frac{\frac{f'}{f}\frac{f}{g}-\frac{f}{g}\frac{g'}{g}}{\frac{f''}{f'}\frac{f'}{g'}-\frac{f'}{g'}\frac{g''}{g'}} $$ $$\lim_{x\to \infty}\frac{\frac{f}{g}}{\frac{f'}{g'}} =\lim_{x\to \infty} \frac{\frac{f}{g} \left( \frac{f'}{g'}-\frac{f}{g}\right)}{\frac{f'}{g'} \left( \frac{f''}{f'}-\frac{g''}{g'}\right)} $$ assuming such limits exists, and equal to $L$,  leads to $$\lim_{x\to \infty}\frac{\frac{f}{g}}{\frac{f'}{g'}} =\lim_{x\to \infty} \frac{\frac{f}{g}  }{\frac{f'}{g'}  }\cdot \lim \frac{  \left( \frac{f'}{g'}-\frac{f}{g}\right)}{ \left( \frac{f''}{f'}-\frac{g''}{g'}\right)} $$ $$L =L\cdot \lim_{x\to \infty} \frac{  \left( \frac{f'}{g'}-\frac{f}{g}\right)}{ \left( \frac{f''}{f'}-\frac{g''}{g'}\right)}  $$ I am stuck here.. I would really like to prove that $L$ is not zero and not $\infty$ the proof is  obvious for polynomials functions f, and g, and I can not find any counter examples.. any help would be much appreciated.. we can assume the initial condition comes from appropriately using l'hopital","['calculus', 'limits']"
762162,Proving Limits of f(x) and f(a+h) are equal,The question asks me to prove that the equality of these two expressions $\lim_{x\to a} f(x)$ and $\lim_{h \to 0}f(a+h)$ provided their limits exist. My answer: Let $x=a+h$ so this $\lim_{h \to 0}f(a+h)=lim_{x-a \to 0}f(x)= \lim_{x \to a}f(x)$. $\square$ My qualms with this proof is that I set $x=a+h$ based on the assumption that $f(x)$ and $f(a+h)$ are equal functions. Is this assumption valid or am I doing circular reasoning ? Also assuming I have a function $f(x)$ and $f(w+z)$ is it $always$ safe to make the assumption $x=w+z$ as the two functions are the same(since $f$ is a set of ordered pairs) except what is inside the parenthesis.,"['calculus', 'elementary-set-theory', 'functions', 'proof-verification', 'limits']"
762175,measure $\lambda(E)=0$ or $\lambda(E)=+\infty$,"Let $\mu$ be a finite measure, let $\lambda<<\mu$ ($\lambda$ is absolutely continuous wrt. $\mu$) let $P_n$,$N_n$ be a Hahn decomposition for $\lambda-n\mu$. Let $P=\cap P_n$ and $N=\cup N_n$. How to prove: $N$ is $\sigma-$finite for $\lambda$ and if $E\subset P$ f,$E\in \mathbf{X}$, then measure $\lambda(E)=0$ or $\lambda(E)=+\infty$ we thought that from  $\lambda<<\mu$, then $\lambda$ should be finite too. but the question says $\lambda(E)=+\infty$. we got stuck. could you please help",['measure-theory']
762176,"$\mathbb{E}[B_t-B_s], \mathbb{E}[\exp(\sigma(B_t-B_s))]$ etc.","This may be a duplicate but I cannot find the corresponding question. I have been asked to show: $\mathbb{E}[\exp(\sigma(B_t-B_s))] = \exp\left(-\dfrac{\sigma^2}{2}(s-t)\right)$ As a side note I have seen that $\mathbb{E}[B_t^{2k}] = \dfrac{(2k)!t^k}{2^k k!}$ with $\mathbb{E}[B_t^k]=0$ if k is odd, from the generator function being real. So if this means that if $\mathbb{E}[(B_t-B_s)^{2k}] = \dfrac{(2k)!(t-s)^k}{2^k k!} $ expanding the LHS of the first equation arrives at the RHS quite easily. I have a problem is finding how, for example, $G_{t,s} = B_t-B_s$ is a Brownian motion $~\mathscr{N}(0,t-s)$. Also, my solution really does not seem very rigorous at all and it seems that I have only managed to solve it since I have seen an expression for $\mathbb{E}[B_t^{2k}]$. In fact, the question asks to arrive at a proof from this: $$\displaystyle P^x(B_{t_1} \in F_1, \cdots, B_{t_k} \in F_k ) = \int_{F_1\times \cdots \times F_k} p(t_1, x, x_1) \cdots p(t_k-t_{k-1}, x_{k-1}, x_k ) dx_1 \cdots dx_k $$ So what I would like, if possible, is a technique for getting to answers to questions like this. Specifically, in this question I would like to know how I can get to $\mathbb{E}[\exp(\sigma(B_t-B_s))]$ from the above. I thought I would begin with: $$\mathbb{E}[f(X(\omega)] = \int_{\mathbb{R}^n}f(x)d\mu_x(x)$$ I am unsure how to proceed from here.","['stochastic-calculus', 'measure-theory', 'stochastic-integrals', 'brownian-motion']"
762203,Calculus and infinitesimals,"In the definition of reimann integral, why do we put a 'dx' inside the integral sign when practically it serves no purpose except maybe telling what variable you are talking about. Then in some physics classes, i have seen people writing stuff like $f(x)/ g(y) = dy/dx$ as $f(x) dx = g(y) dy $. 
Simply asking what is this 'dx' supposed to mean and how can you treat it like a function and sometimes even 'cancel' it from LHS and RHS(when these symbols are somehow present on both sides of equality).","['calculus', 'real-analysis', 'analysis']"
762243,"Range of f(x) = $\frac{\sqrt3\,\sin x}{2 + \cos x}$ [duplicate]","This question already has answers here : A problem on range of a trigonometric function: what is the range of $\frac{\sqrt{3}\sin x}{2+\cos x}$? (6 answers) Closed 10 years ago . Can you give any idea about the range of the following function? $$f(x) = \frac{\sqrt{3}\,\sin x}{2 + \cos x}$$","['trigonometry', 'functions']"
762254,Structure of level sets of a noncritical point of a smooth function on a two dimensional domain,"Let $\psi$ be a smooth function on a two dimensional simply connected domain $\Omega$ such that $\psi=0$ on the boundary $\partial \Omega$. Suppose $\rho$ is not a critical value of $\psi$ then it is claimed that the level set $\psi= \rho$ consists of finitely many closed disjoint curves. How does one prove / see this? Also, if we were working on the two torus rather than a simply connected domain would this still be true?","['differential-topology', 'fluid-dynamics', 'differential-geometry']"
762264,Fundamental Solution of a Nonlinear ODE (using Riccati Transformation & Wronskian),"I am given the differential equation:
\begin{equation*}
y^{\prime}(t) = y(t)^{2} + 2\sin(t)\cos(t) - \sin^{4}(t)
\end{equation*}
and one solution $y_{1}(t) = \sin^{2}(t)$. I wish to find a second solution, and I am told this second solution should also be periodic. To find the second solution $y_{2}$, I use the following steps: 1.) Convert the nonlinear differential equation to a second order system of differential equations using the Riccati transformation: $y = -z^{\prime}/z$. This gives me the form: $z^{\prime}(t) = A(t)z$ with 
\begin{equation*}
A(t) = 
\left[
\begin{matrix}
0 & 1 \\
-2\sin(t)\cos(t)-\sin^{4}(t) & 0
\end{matrix}
\right]
\end{equation*}
and solving $-y_{1}(t) = -\sin^{2}(t) = z^{\prime}/z$,
\begin{alignat*}{2}
z(t) = ce^{-\int_{0}^{t}\sin^{2}(s)ds}, \\
z^{\prime}(t) = -c\sin^{2}(t)e^{-\int_{0}^{t}\sin^{2}(s)ds}
\end{alignat*}
(I dispense with the common constant $c$ since I'm using a general solution matrix in the next step). 2.) Form the Wronskian matrix with known $z(t)$ and unknown $\phi(t)$, and use Abel's formula to solve for $\phi(t)$, i.e. \begin{alignat*}{2}
W(t) &= \left|
\begin{matrix}
z(t) & \phi(t) \\
z^{\prime}(t) & \phi^{\prime}(t)
\end{matrix}
\right| \\
&= z(t)\phi^{\prime}(t) - z^{\prime}(t)\phi(t) \\
&= W_{0}e^{-\int_{0}^{t}\text{tr}(A(s))ds} \\
&= W_{0}e^{-\int_{0}^{t}0ds} \\
&= W_{0}
\end{alignat*} 3.) Solving the resulting differential equation for $\phi$.  Thus,
\begin{alignat*}{2}
z(t)\phi^{\prime}(t) - z^{\prime}(t)\phi(t) &= W_{0} &&\Rightarrow \\
z(t)\phi^{\prime}(t) + \sin^{2}(t)z(t)\phi(t) &= W_{0} &&\Rightarrow \\
\phi^{\prime}(t) + \sin^{2}(t)\phi(t) &= W_{0}z^{-1}(t) &&\Rightarrow
\end{alignat*}
Let $\mu(t) = z^{-1}(t)$, and multiply both sides by $\mu$
\begin{alignat*}{2}
\mu(t)\phi^{\prime}(t) + \sin^{2}(t)\mu(t)\phi(t) &= W_{0}\mu^{2}(t) &&\Rightarrow \\
\mu(t)\phi^{\prime}(t) + \mu^{\prime}(t)\phi(t) &= W_{0}\mu^{2}(t)&&\Rightarrow \\
\frac{\partial}{\partial t}\left(\mu(t)\phi(t)\right) &= W_{0}\mu^{2} \\
\mu(t)\phi(t) &= W_{0}\int_{0}^{t}\mu^{2}(s)ds &&\Rightarrow \\
\phi(t) &= W_{0}z(t)\int_{0}^{t}\mu^{2}(s)ds &&\Rightarrow \\
\phi^{\prime}(t) &= W_{0}z^{\prime}(t)\int_{0}^{t}\mu^{2}(s)ds
+W_{0}z(t)\mu^{2}(t)
\end{alignat*} 4.) Convert back using the same Riccati transformation:
\begin{alignat*}{2}
y_{2}(t) &= -\frac{\phi^{\prime}(t)}{\phi(t)} \\
&= -y_{1}(t) - \frac{\mu^{2}(t)}{\int_{0}^{t}\mu^{2}(s)ds}.  
\end{alignat*} However, this result does not look like it is going to solve the original nonlinear differential equation nor does it seem periodic.  I would like to determine if I have made a calculation error or if there is a flaw in my understanding of this material or a combination of both.",['ordinary-differential-equations']
762270,Christoffel symbols vanish in a system of normal coordinates.,"I'm reviewing for a differential geometry exam and am getting stuck in a proof. This is based on question 4 from section 4-6 from little Do Carmo . Show that in a system of normal coordinates centered at $p$, all the Christoffel symbols are zero at $p$. The question seems fairly routine, but I'm getting stuck in formalizing. Say we have a surface $S$ and $p\in S$. I know there is some parametrization that gives $E=G=1, F=0$ but surely that is not enough to conclude that the Christoffel symbols disappear. I think my difficult in understand is stemming from not fully understanding how our parametrization looks. Any elucidating is thoroughly appreciated.",['differential-geometry']
762272,Intuition behind Taylor/Maclaurin Series,"** This is a different question than Intuition explanation of taylor expansion? ** I understand some of the intuition behind a Taylor/Maclaurin expansion. More specifically, I understand that adding higher and higher degree polynomials will add more 'turning points' on a graph to better represent the curves of the function you wish to approximate. I don't understand why a.) you add the terms; shouldn't adding terms shift the graph left/right, up/down?  In addition to the question of shifting the graph, I just don't understand why you would add more terms, rather than just change your first term accordingly. I now understand the above, thanks to microarm15 and Nicholas Stull.  I now just do not understand part b of this question b.) the terms added are the successive derivatives of the function.  What does adding successive derivatives mean/give you? Any help on the matter is greatly appreciated.
Thanks!","['sequences-and-series', 'calculus', 'taylor-expansion']"
762280,Intuition Behind Maximum Principle (Complex Analysis),"Let $D$ be an open set in the complex plane and $f(z)$ be a non-constant holomorphic function on D.
Then $|f(z)|$ has no local maximum on D. I can follow the proof fine - usually if I don't understand a theorem intuitively beforehand, the proof will offer the insight necessary. Here, however, I can't see the reason for the Maximum Principle to hold - or perhaps I was just too shallow in my grasp of the proof. 
Does anybody have any shillings of wisdom that they would be willing to offer?
Cheers.","['maximum-principle', 'complex-analysis', 'analysis']"
762286,Finitely generated graded modules over $K[x]$,"I need some help on this exercise from A Course in Ring Theory by Donald S. Passman Find all finitely generated graded $K[x]$-modules up to abstract isomorphism. Remember, $K[x]$ is a principal ideal domain. The result is supposedly similar to the well-known structure theorem in the non-graded case. So let $M$ be a finitely generated $K[x]$-module with a minimal generating set of homogeneous elements $\alpha_1, \ldots, \alpha_n$ with $d_i$ the degree of $\alpha_i$ (such a set exists because every element of M is a sum of homogeneous elements). We then get a surjective graded homomorphism $$\phi \colon K[x](d_1) \oplus \ldots \oplus K[x](d_n) \to M,\;e_i \mapsto \alpha_i,$$ where $K[x](d_i)$ denotes the graded module $K[x]$ with its grading shifted upwards by $d_i$ and $e_i = (0,\ldots,1,\ldots,0)$. So the homomorphism theorem for graded modules states that $M$ is - as a graded $K[x]$-module - isomorphic to $$\left(\phi \colon K[x](d_1) \oplus \ldots \oplus K[x](d_n)\right)/\ker(\phi).$$ How do I go on now? Obviously $\ker(\phi)$ is a graded submodule of something like a free-graded $K[x]$-module . Is there maybe an analogue to the elementary divisors theorem for the graded case which lets me express this quotient in a nice way ? Thanks for helping me out!","['principal-ideal-domains', 'finitely-generated', 'graded-modules', 'abstract-algebra']"
762305,Why does this proof of the chain rule not work?,"Why is this proof not valid? Here is my ""rigorized"" version: We write $$\frac{d}{dx}f\big(g(x)\big)=\lim_{b\to a}\frac{f\big(g(b)\big)-f\big(g(a)\big)}{b-a}=\lim_{b\to a}\left[\frac{f\big(g(b)\big)-f\big(g(a)\big)}{g(b)-g(a)}\cdot\frac{g(b)-g(a)}{b-a}\right]$$ Now we split the limit up to get $$\lim_{b\to a}\left[\frac{f\big(g(b)\big)-f\big(g(a)\big)}{g(b)-g(a)}\right]\cdot\lim_{b\to a}\left[\frac{g(b)-g(a)}{b-a}\right]$$ In the first limit, we can set $y=g(x)$. Then by differentiability, and hence continuity, of $g$, we have $y\to g(a)$ as $x\to a$. Therefore the first limit can be expressed as $$\lim_{y\to g(a)}\left[\frac{f\big(y\big)-f\big(g(a)\big)}{y-g(a)}\right]$$ So we get, by definition of the derivative, $$\frac{d}{dx}f\big(g(x)\big)=f'\big(g(x)\big)\,g'(x)$$ There are two objections given to this proof. The first is that one cannot multiply by the quantity $\big(g(b)-g(a)\big)/\big(g(b)-g(a)\big)$ as $g$ may be constant around $x=a$ and the expression would then be undefined. However, it seems obvious that we can simply consider the case of $g$ constant separately (and the case of $g'$ not defined due to 'infinite oscillations', the difficulty cited in the wiki article), where it is easily seen that the formula is valid. (Indeed, this exact point is made in the comments under the answer to this question .) The second is that the limit substitution is not justified. I don't understand this either. That limit rule (in which such substitutions are allowed for continuous functions) could easily be proven, but that has nothing to do with the chain rule. This is the objection given in an answer to this question. I found three other relevant sources. The first proof in the Wikipedia article explicitly avoids the proof above on the basis that the expression noted may be undefined. In the last page of this PDF the author offers students $3$ points if they can explain why the argument I gave above is a flawed proof. In this PDF the author similarly showcases the flawed proof, and then moves on to the 'real' proof. The 'real' proofs are, shall we say, 'not pretty'. I am wondering if this salvaged version of the intuitive proof really does not work, and why? EDIT: THEORETICAL ADDENDUM FOR THE CASE OF INFINITE OSCILLATIONS Suppose that $g(a)=g(b)$ for infinitely many $b$ in all neighborhoods of $a$. Then I claim: if $g'(a)$ is defined, it must equal $0$. Proof. The quantity $$\frac{g(x)-g(a)}{x-a}$$ can be made equal to $0$ by picking an appropriate $b$ in the interval $(a-\delta,a)\cup (a,a+\delta)$ regardless of how small $\delta>0$ is. Therefore there does not exist, for every $\epsilon>0$, a $\delta>0$ such that the difference quotient is always within $\epsilon$ of any limiting value not equal to $0$. For the limit $L\ne 0$, take $\epsilon=|L|/2$. As the limit must exist by hypothesis, it exists and equals $0$. Next I claim: the chain rule is valid in this case. Proof. The chain rule formula returns $f'(g(a))g'(a)=f'(g(a))\cdot 0=0$ in this case. We prove that, in fact, the derivative is equal to zero. Because $g'(a)=0$, we can make $$|g(x)-g(a)|<\epsilon |x-a|$$ true for any $\epsilon>0$ by picking an appropriate $\delta>0$. Then suppose that $f'(g(a))=c$. We have $$|f(x)-f(g(a))|<\max\{|c+\epsilon|,|c-\epsilon|\}|x-g(a)|$$ for any $\epsilon>0$ when $x$ is sufficiently close to $g(a)$. So make $|x-a|$ sufficiently small for all conditions. Then we have $$|f(g(x))-f(g(a))|<\max\{|c+\epsilon|,|c-\epsilon|\}|g(x)-g(a)|$$ $$\frac{|f(g(x))-f(g(a))|}{|x-a|}<\max\{|c+\epsilon|,|c-\epsilon|\}\frac{|g(x)-g(a)|}{|x-a|}$$ But $$\frac{|g(x)-g(a)|}{|x-a|}<\epsilon^*$$ ($\epsilon^*$ the first epsilon) so we have $$\left|\frac{f(g(x))-f(g(a))}{x-a}\right|<\epsilon^*\max\{|c+\epsilon|,|c-\epsilon|\}$$ Therefore the difference quotient can be made arbitrarily small, and hence $$\frac{d}{dx}\left(f\big(g(x)\big)\right)=0$$ as was to be shown.","['calculus', 'proof-verification', 'limits']"
762322,How do I prove that an order of a cycle is its length?,Let $\sigma$ be a cycle with length $n$ where $\sigma \in S_m$. How do i prove that $|\langle \sigma \rangle |$ is $n$?,"['permutations', 'group-theory', 'abstract-algebra']"
762325,Combinatorial explanation for why $n^2 = {n \choose 2} + {n+1 \choose 2}$,"An exercise in the first chapter of Discrete Mathematics, Elementary and Beyond asks for a proof of the following identity: $$
{n \choose 2} + {n+1 \choose 2} = n^2
$$ The algebraic solution is obvious to me, but less so the combinatorial logic. I think the right-hand side relates to choosing one of n elements twice in a row to produce a set of two elements, including the possibility of duplicate elements (for instance, one could choose the nth element twice in a row). However, given that the sets discussed thus far do contain duplicate elements, it's odd to then interpret n^2 as a representation of such a set. I'm not too sure what the two parts of the left side mean when taken together, either. How can I think about this intuitively based on the combinatorial meanings of the individual terms?","['combinatorial-proofs', 'discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
762344,Computing $\int_{|z|=2} z^n(1 - z)^m\ dz$,"My two questions are bolded below. Hypothesis: Let $\gamma$ denote the circle about the origin of radius $2$. Goal: Compute $$
\int_{\gamma} z^n(1 - z)^m\ dz
$$ Attempt: We have that
$$
\int_{\gamma} z^n(1 - z)^m\ dz = \int_{\gamma} z^n(-1)^m(z-1)^m\ dz
$$ Take the integral of the inverse of the integrand.  Once we figure out an answer to this question, we can inverse that answer to find the integral of our original integrand. Is this correct reasoning? Assuming this is correct reasoning, we have that $$
\int_\gamma {1 \over z^n(-1)^m(z-1)^m}\ dz = \int_\gamma {{1 \over z^n}(-1)^{(m-1)+1} \over (z-1)^{(m-1)+1}}\ dz =  {2 \pi i \over n!} f^{(m-1)}(1) \text{ s.t. } f(z) = ??
$$ Here is $f(z) = {(-1)^{m} \over z^n}$?  I'm trying to make heavy use of Cauchy's integral formula but think I've computationally confused myself in that pursuit.  How does one finish this computation?",['complex-analysis']
762365,Prove $\cos 3\theta = 4 \cos^3\theta − 3 \cos \theta$,$\cos 3θ = 4 \cos^3 θ − 3 \cos θ$ Here's my attempt. Is it correct? Thanks! $\cos(3θ)$ $= \cos(2θ + θ)$ $= \cos(2θ)\cos(θ) - \sin(2θ)\sinθ$ $= (2\cos^2θ - 1)\cosθ - (2\sinθ\cosθ)\sinθ$ $= 2\cos^3θ - \cosθ - 2\sin^2θ\cosθ$ $= 2\cos^3θ - \cosθ - 2(1 - \cos^2θ)\cosθ$ $= 2\cos^3θ - \cosθ - (2\cosθ - 2\cos^3θ)$ $= 4\cos^3θ - 3\cosθ $,"['trigonometry', 'solution-verification']"
762366,What mistake am I making trying to calculate the line integral $\oint_C3xy^2dx+8x^3dy$.,"Evaluate the line integral
  $$\oint_C3xy^2dx+8x^3dy$$
  where $C$ is the boundary of the region between the circles $x^2+y^2=1$ and $x^2+y^2=64$ having positive orientation. I actually used Green's theorem to find this. I know $r$ ranges from $1$ to $8$ and $\theta$ ranges from $0$ to $\pi$. Okay, so I found $\dfrac{d}{dx}8x^3=24x^2$, and $\dfrac{d}{dy}3xy^2=6xy$. Now I'm integrating $24x^2-6xy$. I converted it to polar coordinates and took the integral and I got $0$. However this is incorrect. What am I doing wrong?","['greens-function', 'multivariable-calculus', 'integration']"
762464,"Let P(x) be a polynomial of degree 4 , having extremum at $x=1,x=2$ and $\lim_{x\to 0}\frac{x^2+P(x)}{x^2}=2$ Then the value of P(2)","Let $P(x)$ be a polynomial of degree 4 , having extremum at $x=1,x=2$ and $$\lim_{x\to 0}\frac{x^2+P(x)}{x^2}=2.$$ Then what is the value of $P(2)$? I worked out the limit using L'Hospital got a relation in terms of second derivative of $P$; the other derivative relations are that first derivatives are zero at 1,2. How can we interpretate these derivative equations to find the function? Any help is welcome.","['calculus', 'derivatives', 'polynomials']"
762471,Prove this identity: $¥sin^4x = ¥frac{1}{8}(3 - 4¥cos2x + ¥cos4x)$,The problem reads as follows. Prove this identity: $$¥sin^4x = ¥frac{1}{8}(3 - 4¥cos2x + ¥cos4x)$$ I started with the right side and used double angles identities for $¥cos2x$ and a sum and then then double angle identity for the $¥cos4x...$ It all got messy and I hit a dead end. He doesn't give any hints and I'm pretty lost. I'm thinking that I will eventually need a product-sum identity to get the $¥dfrac{1}{8}....$ But I'm just confused how to get there... Thanks in advance to anyone who can help!,"['trigonometry', 'algebra-precalculus']"
762483,Why do exponents not distribute over addition? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question I understand that exponents don't distribute over addition and have seen plenty of examples i.e. $$ (x + y)^2\neq x^2 + y^2 $$ but I'm wondering why that is. Multiplication distributes over addition e.g. $3(2+3) = 3(2) + 3(3)$ so if an exponent is just repeated multiplication why shouldn't the same be true for exponents? i.e. why does $ (x + y)^2\neq x^2 + y^2 $,['algebra-precalculus']
762487,Prove this identity: $ \tan(2x)-\sec(2x) =\tan(x-\pi/4)$,I've been having a time with this problem. I tried to start with the left side but I hit a dead end quick... I then tried the right side and had a little more luck but I've hit a block. I first used the tan difference identity then converted everything into sins and cosines. Then I used a difference identity on sin and cosine and then converted into exact values. $\dfrac{\pi}{4}$ for sine and cosine is $\dfrac{\sqrt{2}}{2}$. All the radicals cancelled out leaving me with $\dfrac{\sin x - \cos x }{\cos x + \sin x}$... I can't think anything to do with this... where did I go wrong? Any answer is appreciated.,['trigonometry']
762515,Three linearly independent vector fields,"How can one find three linearly independent vector fields on $S^1\times S^2$? I know that $S^1\times S^2 \cong SO_3( \mathbb{R})$, i.e. the set of orthogonal $3 \times 3$ matrices with determinant $1$, which is a Lie group and thus parallelizable. I am, however, interested in an explicit form for three vector fields.","['differential-topology', 'multivariable-calculus', 'vector-analysis', 'lie-groups']"
762525,"Show that $S^1 - \lbrace (1,0)\rbrace$ is homeomorphic to the open interval $(0,1)$","Be $S^1$ the unit circle in the plane, that is, $S^1=  \lbrace (x,y)  : x^2+y^2=1 \rbrace$ with the subspace topology. Show that $S^1 - \lbrace (1,0)\rbrace$ is homeomorphic to the open interval $(0,1)$. I have an idea. Using this theorem: Let $f:(X, \tau_1) \rightarrow (Y, \tau_2)$ be a homeomorphism. Let $a \in X$, so that $X - \lbrace a \rbrace$ is a subspace of $X$ and has induced topology $\tau_3$. Also, $Y-\lbrace f(a)\rbrace$ is subspace of $Y$ and has induced topology $\tau_4$. Then $(X - \lbrace a \rbrace, \tau_3)$ is homeomorphic to $(Y-\lbrace f(a)\rbrace, \tau_4)$. (Morris, ""Topology without tears"", remark 4.3.6) My idea is to make $X=S^1$ and $Y=(0,1) \cup ?$ so, with the respective topologies using the theorem, $S^1-\lbrace (1,0)\rbrace$ is homeomorphic to $(0,1)$.  But I'm stuck in the part of defining $Y$ and find the homeomorphism $f$ between $X$ and $Y$. PD. Sorry about my English, but it is not my native language.","['general-topology', 'circles', 'functions']"
762534,Would every half angle of an angle in each quadrant be in the previous quadrant?,"For example, take (5pi)/4 which is in Q3, it's half angle is (5pi)/8 which is in Q2. Is this true for every angle?","['trigonometry', 'algebra-precalculus', 'soft-question']"
762585,Are homeomorphic differentiable manifolds actually diffeomorphic?,"Let $M$ and $N$ be two n-dimensional smooth manifolds.Suppose their underlying topological spaces are homeomorphic through $f$. Does $f$ automatically become a diffeomorphism with respect to the given smooth structures? If not, can I adjust any of the smooth structures to make $f$ a diffeomorphism? What if I restrict the manifolds to be embedded manifolds in Euclidean space $\mathbb{E}^n$ with endowed topology and smooth structure?",['differential-geometry']
762590,Solving the non-homogeneous recurrence relation: $g_{n} = 12g_{n-2}-16g_{n-3}+6\cdot 2^n+25n$,"$g_{n} = 12g_{n-2}-16g_{n-3}+6\cdot 2^n+25n$ With initial conditions $g_{0} = 23, g_{1} = 37, g_{2} = 42 $ This is a practice question I'm working on, and I'm running into absurd amounts of calculations with everything I have tried. I would really appreciate some guidance on this question, as I get the feeling there must be an easier way, or short cut to this question somewhere. I've tried using both generating functions and the usual method of solving non-homogeneous recurrence relations. The first method with generating functions, I let $$A(z) = \sum^{\infty}_{n=0} a_{n}z^n$$ be a generating function. Putting in the initial conditions, I get: $$ A(z) = 23 + 37z + 42z^2 + \sum^{\infty}_{n=3} (12g_{n-2}-16g_{n-3}+6\cdot 2^n+25n)z^n$$ after a bunch of simplifying and expressing the RHS in terms of $A(z)$, I get: $$A(z) =  23 + 37z + 42z^2 + 12z^2(A(z)-23) - 16z^3A(Z)+ \frac{6}{1-2z}+25(\frac{z}{(1-z)^2} - z- 2z^2)$$ After rearranging and moving the $A(z)$ terms to the other side, I get: $$A(z) = \frac{29-67z+23z^2+14z^3-24z^4}{(2z-1)^2(4z+1)(1-2z)(1-z)^2} $$ which turns into an absolutely hideous partial fraction decomposition, trying to solve for 6 constants. I pretty much went as far as I could go with it and still ran into a dead end, so i decided to try the usual method. Doing the usual method, I try to solve the homogeneous part first, which is reasonably easy. My characteristic polynomial is $x^3-12x+16=0$, giving me roots $\lambda = 2 $(of multiplicity 2) and $\lambda = -4 $ So my solution to the homogeneous part is: $$b_n = C_12^n+C_2n2^n+C_3(-4)^n$$ Now to get a particular solution, I try: $p_n = C_4n^2\cdot 6 \cdot 2^n + C_5n$ $$ \implies C_4n^2\cdot 6 \cdot 2^n + C_5n = 12(C_4(n-2)^2\cdot 6 \cdot 2^{(n-2)} + C_5(n-2)) - 16(C_4(n-3)^2\cdot 6 \cdot 2^{(n-3)} + C_5(n-3)) + 6\cdot2^n+25n $$ Another pretty nasty algebraic exercise (although not quite as bad as the generating function). However, I persist and after expanding the terms, I try to collect the $n^2\cdot2^n$ and $n$ terms together - to try and solve a simultaneous equation, but I run into the problem that I get terms without $n^2\cdot2^n$ nor $n$ and then some terms with $n\cdot 2^{n}$. Would greatly appreciate some help with this practice question! Many thanks in advance.","['generating-functions', 'recurrence-relations', 'discrete-mathematics']"
762625,$\lim_{n\to \infty}\left(1 - \frac {1}{n^2}\right)^n =?$ [duplicate],"This question already has answers here : Limit of $\left(1-\frac{1}{n^2}\right)^n$ (4 answers) Closed 10 years ago . Can you give any idea regarding the evaluation of the following limit? $\lim_{n\to \infty}\left(1 - \frac {1}{n^2}\right)^n$ We know that $\lim_{n\to \infty}\left(1 - \frac {1}{n}\right)^n = e^{-1}$, but how do I use that here?",['limits']
762735,meromorphic functions on proper varieties are rational,"Suppose $X$ is a proper variety over $\mathbb{C}$, is every meromorphic function rational? In the case of projective variety, can this be derived from Chow lemma? How does the GAGA principal illustrate on these ?",['algebraic-geometry']
762737,Probability of Parking Spot Being Empty,"A parking spot is unoccupied 1/3 of the time...
But, you find it empty for nine consecutive days in a row. Find the probability that it will be empty on the tenth day. Read more: http://www.businessinsider.com/8-mind-bending-interview-questions-that-google-asks-its-engineers-2012-7?op=1#ixzz2zVa8Qb8w The answer is 2/3 but I can't figure out how that is possible. It should be 1/3 instead.","['statistics', 'probability']"
762741,tensor product of two vector bundles,Let $\xi$ and $\eta$ be two vector bundles over the same base space $B$. Then $\xi\otimes \eta$ is orientable if and only if $\xi$ and $\eta$ are both orientable. How to prove this true or not true? Thanks. Is the tensor product of a mobius band with itself orientable ?,"['differential-geometry', 'fiber-bundles', 'manifolds', 'algebraic-topology', 'differential-topology']"
762762,A different type binomial expansion problem,"Suppose we have $$(1+x+x^2)^n = a_0 + a_1 x + a_2 x^2 + \cdots + a_{2n} x^{2n}.$$ What will be the value of $a_0^2 - a_1^2 + a_2^2 - \cdots + a_{2n}^2$? The answer is $a_n$, but I can't solve it. See, what I've done is substitute $x$ as $-\frac{1}{x}$ and I've got: ${\frac{(x^2-x+1)}{x^2}}^n = a_0 - \frac{a_1}{x} + \frac{a_2}{x^2}+...$ I've got the alternating signs but I can't get the squares of the numbers.","['binomial-theorem', 'algebra-precalculus', 'contest-math']"
762771,"Matrix similarity problem (complex, real)","I'm trying to solve this problem: Given complex matrices A and B, prove there's a nonsingular real matrix Q such that $A=QBQ^{-1}$, if and only if there's a nonsingular complex matrix S such that $A=SBS^{-1}$ and $\overline{A}=S\overline{B}S^{-1}$ The forward direction is fine since a real matrix is also complex. I'm having trouble with the backwards direction. The only clue I have is a theorem that says given 2 real matrices that are similar over complex numbers... they must also be similar over the real numbers. $A\overline{A} = SB\overline{B}S^{-1}$ does this somehow imply S is a real matrix? Also:
$A = SBS^{-1}$ $A = \overline{S}B\overline{S^{-1}}$ Does A being similar to B by two different matrices somehow imply they are equal... thereby implying $S = \overline{S}$ ? Appreciate any help. Thanks. EDIT: We get: $A + \overline{A} = S(B+\overline{B})S^{-1}$ Since $A+\overline{A}$ and $B+\overline{B}$ are real, we can use the theorem to show that there's a real matrix T such that: $A + \overline{A} = T(B+\overline{B})T^{-1}$ Similarly, $i(A-\overline{A}) = Si(B-\overline{B})S^{-1}$ Since $i(A-\overline{A})$ and $i(B-\overline{B})$ are real, we can use the theorem to show that there's a real matrix G such that: $i(A - \overline{A}) = Gi(B-\overline{B})G^{-1}$
so $(A - \overline{A}) = G(B-\overline{B})G^{-1}$ Can we use real matrices G and T to somehow show $A = QBQ^{-1}$ for a real matrix Q ? Ok. I think I've found the solution now. The theorem also says that if one pair of real matrices are similar via a complex matrix S... then they're similar via a real matrix T... and if another pair of real matrices are also similar via S, they are also similar via the same real matrix T. Hence in my exposition above G = T. So we get (by adding the two equations): $2A = 2TBT^{-1}$ $A = TBT^{-1}$",['matrices']
762785,Completeness of a Riemannian manifold with boundary,"I have some issues understanding the notion of completeness of a Riemannian manifold with boundary. In the case of Riemannian manifolds without boundary, I found that completeness is usually defined via the existence of geodesics, i.e. every geodesic is defined on the whole real line. With Hopf-Rinow, this is equivalent to various conditions, for example, the manifold is complete as a metric space. In the context of a manifold with boundary clearly Hopf-Rinow makes no sense because there will usually be geodesics which cease to exist (reach the boundary) after finite time. How do we define completeness in this case? Just via completeness as a metric space? If yes, isn't it true that every compact manifold with boundary is complete?","['riemannian-geometry', 'manifolds', 'differential-geometry']"
762795,The derivative of the determinant of a Kronecker product,"For an invertible matrix $A$, we have the identity
\begin{align}
\dfrac{\partial \det A}{\partial A} = \det A (A^{-1})^T
\end{align}
where the $T$ denotes the transpose operation. How does this formula change when considering the Kronecker product of $A$ with some other (invertible) matrix $B$? For example, how does one compute the following: \begin{align}
\dfrac{\partial \det \left[A\otimes B\right]}{\partial A}
\end{align}","['tensor-products', 'matrix-calculus', 'tensors', 'linear-algebra', 'matrix-equations']"
762813,Infinite Series $\sum\limits_{n=0}^\infty\frac{(-1)^n}{(2n+1)^{2m+1}}$,"I'm looking for a way to prove
$$\sum_{n=0}^\infty\frac{(-1)^n}{(2n+1)^{2m+1}}=\frac{(-1)^m E_{2m}\pi^{2m+1}}{4^{m+1}(2m)!}$$
I know that
$$\sum_{n=0}^\infty\frac{(-1)^n}{(2n+1)^{2m+1}}=\frac{1}{4^{2m+1}}\left(\zeta\left(2m+1,\frac14\right)-\zeta\left(2m+1,\frac34\right)\right)$$
so maybe I could simplify the above more?","['closed-form', 'sequences-and-series', 'calculus', 'real-analysis', 'complex-analysis']"
762820,Is $\int_x^{\infty}e^{-\frac{t^2}{2}} < \frac{1}{x}e^{-\frac{x^2}{2}}$?,"While solving a problem in real analysis, I got stuck. I need to prove $$\int_x^{\infty}e^{-\frac{t^2}{2}}dt <  \frac{1}{x}e^{-\frac{x^2}{2}} $$ Clearly I have to use some kind of inequality, but cant figure out how to proceed further. Thanks for the help.","['exponential-function', 'inequality', 'integration', 'real-analysis']"
762824,Solving complex trig functions: $\sin2x + \sin3x = \frac{\sqrt{3}}2$,"How to solve: $$\sin(2x) + \sin(3x) = \frac{\sqrt{3}}{2}$$
where $x$ is in $[-\pi,\pi]$? I have no idea what to do with the $\sin(2x) + \sin(3x)$. Am I supposed to factorise, differentiate, is there some theory I am to apply?","['trigonometry', 'algebra-precalculus', 'functions']"
762836,How find the $AP+\frac{1}{2}BP$ minmum value,"An equilateral triangle $ABC$ such $$AB=BC=AC=2a>0$$
 A circle $O$ is inscribed in triangle $ABC$,and the point $P$ on the circle $O$. Find the minimum $$AP+\dfrac{1}{2}BP$$ My idea: let $$A(-a,0),B(a,0),O(0,\dfrac{\sqrt{3}}{3}a)$$
then the circle equation is $$
x^2+(y-\dfrac{\sqrt{3}a}{6})^2=\dfrac{1}{12}a^2$$
let $P(x,y)\;$ , then
$$|PA|+\dfrac{1}{2}|PB|=\sqrt{(x+a)^2+y^2}+\dfrac{1}{2}\sqrt{(x-a)^2+y^2}$$
where $$
x^2+(y-\dfrac{\sqrt{3}a}{6})^2=\dfrac{1}{12}a^2$$
then I can't.Thank you","['geometry', 'geometric-inequalities', 'inequality']"
762841,Show that; $\displaystyle\int_0^\infty\frac{f(bx)-f(ax)}{x}dx=(l-f(0))\ln\frac{b}{a}$ [duplicate],"This question already has answers here : Proof of Frullani's theorem (10 answers) Closed 6 years ago . Assume that $f\in C^1([0,\infty))$, $f'$ is monotonic on $[0,\infty)$ and $\lim\limits_{x\to\infty} f(x)=l$ is finite. If $a,b>0$, prove that; $$\displaystyle\int_0^\infty\frac{f(bx)-f(ax)}{x}dx=(l-f(0))\ln\frac{b}{a}$$ The trick is clear for me, I have to write is as double integral, i.e. the function $\frac{f(bx)-f(ax)}{x}$ as an integral, obviously with limits $a$ and $b$. For example $\displaystyle\int_a^bf'(xy)dy$$\quad$(Here is $f$ differentiated with respect to $y$) works. Now if I assume that, $\displaystyle\int_0^\infty\Big(\displaystyle\int_a^bf'(xy)dy\Big)dx=\displaystyle\int_a^b\Big(\displaystyle\int_0^\infty f'(xy)dx\Big)dy$ and $\displaystyle\int_0^\infty f'(xy)dx=\frac{l-f(0)}{y}$ $(\bigstar)$ then $\displaystyle\int_a^b\frac{l-f(0)}{y}=(l-f(0))\ln\frac{b}{a}$ gives the correct result. MY QUESTIONS 1)Why is the line with $(\bigstar)$ correct ? Because $f'(xy)$ is differentiated w.r. to $y$ but if we integrate w.r.to $x$ why do we get $f$ again ? 2)Why can we change the order of integration, We have to make use of the monotonicity of $f'$, I guess $\lim\limits_{x\to\infty}f'(x)=0$, but this is not sufficient.","['improper-integrals', 'integration', 'real-analysis']"
762846,First usage of the symbol ∈,"Concerning a book [1] I am reading the symbol $\in$ was first used by Giuseppe Peano and is the first letter $\epsilon$ ( epsilon ) of the word ἐστί (means ""is""). Does anyone know in which work of Peano $\in$ was first used? [1] Ingmar Lehmann, Wolfgang Schulz: ""Mengen, Relationen, Funktionen"" (3. Auflage, 2007), page 10 Similar question: What is the name of the ∈ symbol and where does it come from?","['notation', 'reference-request', 'math-history', 'elementary-set-theory']"
762854,Differentiability implies continuity -- possibly pedantic question about the common proof,"The common proof that differentiability implies continuity arrives at this limit: $$\lim_{x\to a} [f(x) - f(a)] = 0$$ I'm failing to see the simple justification for moving to the next step, which seems to be essentially this: $$\lim_{x\to a} f(x) - \lim_{x\to a} f(a) = 0$$ Intuitively, it makes sense, and I'm sure an epsilon-delta proof can be furnished. But as a matter of simple limit laws (the subtraction law in this case), the above assumes $\lim_{x\to a}f(x)$ exists, no? Curiously, the authors who use this proof consider it important in other contexts to beat home the fact that $\lim_{x\to a}f(x)$ exists, which they do by using the continuity of f . In this case, they can't use the continuity of f , for the continuity of f is precisely what's under question. So what are they using? By the way, I understand the final steps of the proof: $$\lim_{x\to a} f(x) = \lim_{x\to a} f(a)$$
$$\lim_{x\to a} f(x) = f(a)$$","['calculus', 'continuity', 'derivatives', 'analysis']"
762871,"Zorich's misinterpretation of ""Axiom of Choice""?","I'm reading Zorich'es ""Mathematical Analysis I"", Ed 4, 2004, and wonder if this is a trifle misinterpretation of ""Axiom of Choice"". Ch 1.4 ""Supplementary Material"" says: 8°. (A x i o m o f c h o i c e) For any family of nonempty sets there
  exists a set $C$ such that for each set $X$ in the family $X \cap C$
  consists of exactly one element. I suppose for nonempty set family $\{A,B,S\}$, if $A, B \subset S$ and $A\cap B=\emptyset$, $S\cap C$ will have at least 2 elements? Of course this is a trifle one and I'm not sure if it's from Zorich or translation.","['elementary-set-theory', 'axiom-of-choice']"
762872,Smallest Graph that is Regular but not Vertex-Transitive?,"I'm trying to find the smallest graph that is regular but not vertex-transitive, where by smallest I mean ""least number of vertices"", and if two graphs have the same number of vertices, then the smaller is the one with the lower number of edges. I currently have that the smallest such graph is the disjoint union of the three-cycle and the four-cycle. Are there any smaller graphs?","['discrete-mathematics', 'examples-counterexamples', 'abstract-algebra', 'graph-theory', 'combinatorics']"
