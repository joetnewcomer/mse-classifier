question_id,title,body,tags
2840876,A strange thing when evaluating a basic limit,"I have attempted to evaluate the limit $\lim _{x\to \infty }\left(\frac{1}{\sqrt{x-1}}\right)$. I understand, intuitively, that the limit is equal to zero, but when trying to show it, something strange happened. I've tried to evaluate the limit based on a technique that uses the fact that $\lim _{x\to \infty }\left(\frac{1}{x^n}\right)\:=\:0,\:n>0$, and divided both the numerator and the denominator of the fraction by $x$:
\begin{align}
& \lim _{x\to \infty }\left(\frac{1}{\sqrt{x-1}}\right)=\lim _{x\to \infty } \left(\frac{\frac{1}{x}}{\frac{\sqrt{x-1}}{x}}\right) =\lim_{x\to \:\infty} \left(\frac{\frac{1}{x}}{\frac{\sqrt{x-1}}{\sqrt{x^2}}}\right) =\lim_{x\to \:\:\infty \:\:}\left(\frac{\frac{1}{x}}{\sqrt{\frac{x-1}{x^2}}}\right) \\[10pt]
= {} & \lim_{x\to \:\:\:\infty \:\:\:} \left(\frac{\frac{1}{x}}{\sqrt{\frac{1}{x}-\frac{1}{x^2}}}\right)=\frac{\frac 1 \infty}{\sqrt{\frac 1 \infty -\frac{1}{\infty ^2}}}=\frac{0}{\sqrt{0-0}}=\frac{0}{0}= \text{indeterminate}
\end{align} Moreover, when I divided the numerator and the denominator by $\sqrt{x}$, I've actually gotten the correct result:
$$\lim _{x\to \infty }\left(\frac{1}{\sqrt{x-1}}\right)=\lim _{x\to \infty } \left(\frac{\frac{1}{\sqrt{x}}}{\frac{\sqrt{x-1}}{\sqrt{x}}}\right)=\lim _{x\to \infty }\left(\frac{\frac{1}{\sqrt{x}}}{\sqrt{\frac{x-1}{x}}}\right)=\lim_{x\to \:\infty \:}\left(\frac{\frac{1}{\sqrt{x}}}{\sqrt{1-\frac{1}{x}}} \right) = \frac{\frac{1}{\sqrt{\infty }}}{\sqrt{1-\frac{1}{\infty }}}=\frac{0}{\sqrt{1-0}} = \frac{0}{1}=0$$ 
Why is there a difference in the results? Why does dividing by $\sqrt{x}$ is allowed, but not by dividing by $x$, or have I done an arithmetic/algebraic mistake that caused the result to be wrong? Help will be much appreciated :)","['radicals', 'limits-without-lhopital', 'calculus', 'limits']"
2840894,Suggestion for a textbook including Von Neumann definition of ordinal numbers,"I'm interested in the generalization of natural numbers and especially ordinals. I have searched through some set theory textbooks but unable to find Von Neumann definition of ordinal numbers. I have read somewhere that Von Neumann definition of ordinal numbers is elegent, so please suggest me some textbooks that mention Von Neumann definition of ordinal numbers. Thank you so much!","['reference-request', 'elementary-set-theory', 'ordinals']"
2840907,Let $f\in C^\infty(\mathbb T^d)$ satisfy $f\ge0$ and $\hat f(0)=1$. Must $|\hat f(k)|<1$ for all $k\ne0$?,"We define the $d$-dimensional torus by $\mathbb T^d = \mathbb R^d/\mathbb Z^d$, and define the Fourier transform $\hat f\in\ell^\infty(\mathbb Z^d)$ of functions $f\in L^1(\mathbb T^d)$ as 
$$
\hat f(k) = \int_{\mathbb T^d}\! f(x)e^{-2\pi i x\cdot k}\,\mathrm dx.
$$ Now, suppose that $f\ge0$ is smooth, and $\hat f(0)=\int_{\mathbb T^d}\! f\,\mathrm dx=1$, i.e. $\,f\,\mathrm dx$ is a probability measure. A basic $L^1$ bound gives that $|\hat f(k)|\le 1$ for all $k\in\mathbb Z^d$, but can we go further and say that $|\hat f(k)|<1$ for all $k\ne0$? We can reformulate the problem as follows. If we define $f^{*t}$ to be the $t$-fold convolution of $f$ on $\mathbb T^d$, then it is clear that $f^{*t}\to\phi$ as $t\to\infty$ for some trigonometric polynomial $\phi$, with convergence in every $H^s$ norm. Is it necessarily true that $\phi=1$? The problem can even be reformulated in a third way. Suppose $(X)_{t=0}^\infty$ is a discrete time homogeneous Markov chain on $\mathbb T^d$, with isotropic and smooth transition kernel, i.e. the transition kernel $(m_x)_{x\in\mathbb T^d}$ satisfies $m_x = (\cdot+x)_\#\mu$ for $\mu(\mathrm dx)=f(x)\,\mathrm dx$ with $f$ smooth. Then does $X_t\xrightarrow{t\to\infty}1$ in law for any initial condition?","['fourier-analysis', 'probability-theory', 'probability-distributions', 'markov-chains', 'sobolev-spaces']"
2840910,How do I express the second derivative of this function,"We have 
$$F(X)=f(x)\psi(x)$$
$$X=\chi(x)$$ I can show that 
$$\frac{dF}{dX}=\frac{1}{\chi^\prime}(\psi f^\prime+f \psi^\prime)$$ But don't know how to express $$\frac{d^2F}{dX^2}=\text{?}$$","['derivatives', 'chain-rule', 'calculus']"
2840927,Rate of weak convergence of sin(nx),"Since $\sin(n\cdot)$ converges weakly to zero, we know that $$
\lim_{n\rightarrow\infty} \int_a^b g(x)\sin(nx)\mathrm{d}x = \int_a^b g(x)\cdot 0\,\mathrm{d}x = 0
$$ holds for all $g\in L^2([a,b])$. Is there a way to find an explicit formula for the rate of convergence in the above equation, i.e. to determine a function $C$ depending on $n$ such that $$
\left|\int_a^b g(x)\sin(nx)\mathrm{d}x\right| \le C(n), \qquad \lim_{n\rightarrow\infty}C(n) = 0
$$ holds for all $g\in A$, where $A$ is a certain subset of $L^2([a,b])$?
If, for example, $A$ is the set of constant functions with $||g||_{L^\infty} < M$ for all $g\in A$, then it is easy to show that $C(n) = \frac{2}{n}M$ is such an upper bound (by integrating $\sin(nx)$). I am particularly interested in the case where $A$ is the set of continuously differentiable (or smooth) functions with $||g||_{L^\infty}<M_1$ and $||\frac{\mathrm{d}}{\mathrm{d}x}g||_{L^\infty}<M_2$ for $M_1,M_2>0$.","['functional-analysis', 'weak-convergence', 'rate-of-convergence']"
2840930,Range of $f(x)= \frac{\tan{x}}{\tan{3x}} $,"Prove that for the values of $x$ where the following $f(x)$ is defined, $f(x)$ does not lie between $\frac{1}{3}$ and $3$. $$f(x)=\frac{\tan{x}}{\tan{3x}}$$ My Attempt: I wrote down, $$\tan{3x}=\frac{3\tan{x}-\tan^3{x}}{1-3\tan^2{x}}$$ This reduced $f(x)$ to, $$f(x)=\frac{1-3\tan^2{x}}{3-\tan^2{x}}$$ I don't know how to solve any further. I thought of using derivative, but the function is dicontinuous at times. How do I solve it? Any hints would be helpful. Thanks.","['algebra-precalculus', 'trigonometry']"
2840932,Doubt in The inverse function theorem of Rudin's Principles of mathematical Analysis (Theorem 9.24),"Theorem 9.24:
Suppose $\textbf{f}$ is a $C'-$ mapping of an open set $E \subset \mathbb{R^n}$ into $\mathbb{R^n}$.$\textbf{f} \thinspace^\prime\textbf{ (a)}$ is invertible for some $\textbf{a}\in E$ and $\textbf{b=f(a)}$ then (a) there exist open sets $U$ and $V$ in $\mathbb{R^n }$ such that $\textbf{a}\in U, \textbf{b}\in V,\textbf{f}$ is one-to one on $U$ and $\textbf{f}(U)=V$ (b) if $\textbf{g}$ is the inverse of $\textbf{f}$[which exist , by (a)], definedin $V$ by $\textbf{g(f(x))=x }$$\space $ $(\textbf{x}\in U)$ then $\textbf{g}\in C'(V)$ To prove (a) Rudin took a function $\varphi$ which is defined as to each $\textbf{y}\in \mathbb{R^n },\varphi(\textbf{x})=\textbf{x}+A^{-1}(\textbf{y}\thinspace \textbf{-f(x))}\space \space (\textbf{x}\in E )$(Equation 48)
Then he states that $\varphi '(\textbf{x})=I- A^{-1}\textbf{f}\space'(x)$.I didn't got how rudin found  $\varphi '(\textbf{x})$.Please help me to understand.","['multivariable-calculus', 'proof-explanation', 'derivatives']"
2840968,"Find $n$ such that $\int_0^1 e^x(x-1)^n \,dx = 16-6e$.","Find the value of $n$ (where $n$ is a positive integer less than or equal to $5$) such that $$\int_0^1 e^x(x-1)^n \,dx = 16-6e.$$ I have tried this question by two methods. Integration by parts Using king property Neither of these lead me anywhere conclusive.  The integral calculator has used a gamma function which is not in my high school syllabus.","['integration', 'definite-integrals', 'calculus']"
2841000,Sufficient conditions for difference of matrices A-B to be positive definite,"Define $A>B\iff A-B\succ 0$, i.e. $A-B$ is positive definite. A well-known sufficient condition for $A>B$ is that the largest eigenvalue of $B$ is smaller than the smallest eigenvalue of $A$. Are there any other useful sufficient conditions for $A>B$? Are there any equivalent properties (i.e. $A>B$ if and only if $A,B$ satisfy some property $P$)?","['matrices', 'abstract-algebra', 'functional-analysis', 'order-theory', 'linear-algebra']"
2841074,Does Indexed Union distribute over Indexed Intersection? (same index),"I am wondering whether this is true: $$
\big(\bigcup_i A_i\big)\ \cap\ \big(\bigcup_i B_i\big) = \bigcup_i \big( A_i \cap B_i \big)
$$ I have found proof that union distributes over intersection of not indexed sets and some proof where only one of the two sets is indexed, but I cannot prove myself whether this holds or not. Any ideas?",['elementary-set-theory']
2841085,Finding image of normal Gauss map on paraboloid.,"Describe the region of unit sphere covered by normal Gauss map on the
paraboloid $z = x^2+y^2$. I did this way: Consider the parametrization $X(u,v) = (u,v,u^2+v^2)$. Then $X_u = (1,0,2u)$ and $X_v = (0,1,2v)$. Then $X_u \times X_v = (-2u,-2v,1)$ and $||X_u \times X_v|| = \sqrt{4(u^2+v^2)+1}$, so $N(u,v) = \frac{(-2u,-2v,1)}{\sqrt{4(u^2+v^2)+1}}$. Since the first and second coordinates can be any real, while the third is always positive, then the image of the paraboloid by Gauss map is the upper open hemisphere. But the solution I find is done this way: $S = \{(x,y,z) \in \mathbb{R^3} : f(x,y,z) = x^2+y^2-z = 0\}$, then $N(x,y) = \frac{\nabla f}{||\nabla f||} = \frac{(2x,2y,-1)}{\sqrt{(4(x^2+y^2)+1}}$, then, since third coordinate is always negative, the image of the paraboloid by Gauss map is the lower open hemisphere. Is one of them wrong? How can the two regions obtained be different? Why can gradient vector be used here? Thanks.","['differential-geometry', 'surfaces']"
2841092,Examples of integration by parts that work both ways,"Usually, integration by parts only works one way. For example, evaluating $\int xe^x\,dx$ can only be done by differentiating $x$ and integrating $e^x$ , but not the other way round, since $\int x^2e^x\,dx$ makes it more difficult than the original integral. However, the integral $$\int x\ln x\,dx$$ can be evaluated using integration by parts both ways: $$\int x\ln x\,dx=x\int \ln x\,dx - \int\left(x'\int\ln x\,dx\right)\,dx=x^2(\ln x-1)-\int x(\ln x-1)\,dx$$ and (directly), $$\int x\ln x\,dx=\ln x\int x\,dx-\int\left(\ln'x\int x\,dx\right)\,dx=\frac{x^2}2\ln x-\int\frac x2\,dx.$$ There are also trigonometric integrals that can do this. For instance, an integral consisting of $\sin$ and $\cos$ , as $\int \sin = -\cos$ and $\int \cos = \sin$ : $$\int \sin2x\cos3x\,dx.$$ @JamesArathoon has provided this one as well: $$\int x\arctan x\,dx$$ What are some other examples of integrals that have this property as well? I believe that such integrals are rather rare, so I don't want 'similar' integrals like multiplying by a constant or adding $1$ to the integrand. Of course, integrands of forms other than $xf(x)$ would be even better (and more challenging :)","['indefinite-integrals', 'integration']"
2841143,If $n$ is odd then $\mathbb{R}P^n$ is orientable,"Show that if $n$ is odd then $\mathbb{R}P^n$ is orientable. Comments:
I have the following: The antipodal map $\alpha: S^n \longrightarrow S^n$, $\alpha (x) = -x$ is orientation-preserving if and only if n is odd. 
I'm trying to use the map $\pi: S^n \longrightarrow  \mathbb{R}P^n$ 
and the above fact to find orientation form of $\mathbb{R}P^n$. But I can not fit these facts. What is the orientation form?","['manifolds', 'geometry']"
2841147,"Why is the dimension of a ring, with finite spectrum, $\leq 1$?","Why is the dimension of a ring, with finite spectrum, $\leq 1$? It is clear that it works for the case if the ring is noetherian, due to the fact that every ideal of height $2$ is an infinite union of prime ideals of height $1$. It seems like one could use the prime avoidance lemma, but I am really unsure how to work it out.","['abstract-algebra', 'commutative-algebra']"
2841177,Find a real matrix $B$ such that $B^3 = A$,"Given $$A = \begin{bmatrix}-5 & 3\\6 & -2\end{bmatrix}$$ find a real, invertible matrix $B$ such that $B^3 = A$ I think I am doing something wrong here, so let me describe my attempt: 1) So I started off with diagonalizing the matrix $A$ with finding the eigenvalues $\lambda_1 = -8$ and $\lambda_2 = 1$ and the corresponding eigenvectors $ \vec v_1 = \begin{bmatrix}1 & 1\\0 & 0\end{bmatrix} = x + y = 0 \Rightarrow -x = y \Rightarrow \begin{bmatrix}1\\-1\end{bmatrix}$ and $ \vec v_2 = \begin{bmatrix}1 & -\frac{1}{2}\\0 & 0\end{bmatrix} = x - \frac{1}{2}y = 0 \Rightarrow 2x = y \Rightarrow \begin{bmatrix}1\\2\end{bmatrix}$ 2) With that being done I proceeded with computing $D = \begin{bmatrix}-8 & 0\\0 & 1\end{bmatrix}$ and $P = \begin{bmatrix}1 & 1\\-1 & 2\end{bmatrix}$ and check everything with $D = PAP^{-1}$ 3) Now I thought I will simple find a diagonal matrix $M = PBP^{-1}$ and $M^3 = D$ and the easiest solution I came up with was $M = \begin{bmatrix}\sqrt[3]{-8} & 0\\0& 1\end{bmatrix}$ so basically $M = D^{\frac{1}{3}}.$ So that $B = PMP^{-1}$. But now come the tricky part, if I compute $B$ it results in a complex matrix not a real. //It is real! Have I perhaps overlooked something here or miscalculated the solution for $B$? Edit :
As Cameron pointed out my calculator and I totally failed as it was in complex mode and computed one of the non-real cube roots instead of -2. So $M = \begin{bmatrix}-2 & 0\\0 & 1\end{bmatrix}$ and consequentially $B = \begin{bmatrix}-1 & 1\\2 & 0\end{bmatrix}$","['matrices', 'matrix-equations', 'linear-algebra']"
2841198,Proving upper bound $|\tan(z)| < 2$ on a contour,"I have to find an upper bound as described in the title. First I'll give some background of the question. For $k \in \mathbb{N}$, let $\alpha_k$ be the boundary of the square with vertices $k\pi(1+i)$, $k\pi(-1+i)$, $k\pi(-1-i)$ and $k\pi(1-i)$. Furthermore let $D = \{ z \in \mathbb{C}: z \neq 0 \quad \text{and} \quad \cos z \neq 0\}$ and define $f:D \rightarrow \mathbb{C}$ :
\begin{equation}
f(z) = \frac{\tan z}{z^2}.
\end{equation} I have to show that $|\tan z|<2$ on $\alpha_k$ for all k. So I thought of first writing the tangent as a quotient of the sine and cosine and then write it with complex powers of $e$. So I end up with: \begin{equation}
\tan z = \frac{1}{i} \frac{e^{iz}-e^{-iz}}{e^{iz}+e^{-iz}}.
\end{equation} Then I assumed that $z = x + iy$ and after a lot of of trigonometric formulas I've found that: \begin{equation}
|\tan z| = |\tan (x+iy)| = \sqrt{\frac{1}{(\cosh(2y)+\cos(2x))^2}\left( \sin^2(2x) + \sinh^2(2y) \right)}.
\end{equation} And here I got stuck. Perhaps we can use the fact that we have to show this upper bound on the contour $\alpha_k$ and use that the maximum modulus of z there is $k\pi$, but I don't see how we can arrive on the bound 2 from here. Does anyone have an idea how we can proceed or can tell me if I'm on the right track with this attempt? Thanks in advance! -DS","['complex-analysis', 'estimation', 'contour-integration']"
2841218,Prove by induction $|u - y| < \delta \Rightarrow |u^{n} - y^{n}| < \epsilon$,"Specifically, show that $\forall u \in \mathbb{R}$, $\forall n \in \mathbb{N}$, $\forall \epsilon > 0$, $\exists \delta > 0$ such that $\forall y \in \mathbb{R} \quad |u - y| < \delta \Rightarrow |u^{n} - y^{n}| < \epsilon$ I am trying to see if I am understanding this correctly. I have written out a proof in as much detail as I think is necessary.  I feel shaky when it comes to using the $P(n)$ case to help prove $P(n+1)$. Proof. Base case n=1 is trivial.  We will only proceed with the inductive step n+1. For convenience suppose $|u| > |y|$.  We expand $P(n+1)$
\begin{align*}
|u^{n+1} - y^{n+1}| & = |(u-y)(u^{n} + u^{n-1}y + ... + y^{n})| \\
& \leq |u-y|(|u^{n}| + |u^{n-1}y| + ... + |y^{n}|) \\
& \leq |u-y| \cdot (n+1) \cdot \max(\{|u|,|y|\})^{n} \\
& < \delta \cdot (n+1) \cdot |u|^{n}
\end{align*} For $P(n)$ the statement holds true so lets first expand on this case to be able to proceed with case $P(n+1)$.
\begin{align*}
|u^{n} - y^{n}| & = |(u-y)(u^{n-1} + u^{n-2}y + ... + y^{n-1})| \\
& \leq |u-y|(|u^{n-1}| + |u^{n-2}y| + ... + |y^{n-1}|) \\
& \leq |u-y| \cdot n \cdot \max(\{|u|,|y|\})^{n-1} \\
& < \delta \cdot n \cdot |u|^{n-1} \\
& < \delta \cdot (n+1) \cdot |u|^{n-1}
\end{align*} Our choice of delta will depend on the value of $|u|$ and $\epsilon$.  If $|u| \leq 1 \Rightarrow |u|^{n} \leq 1$ for any $n \in \mathbb{N}$ (it does not matter if it is $n-1$ or $n$), such that
\begin{align*}
\delta \cdot (n+1) \cdot |u|^{n} \leq \delta \cdot (n+1) \cdot 1
\end{align*} and so we pick $\delta = \frac{\epsilon}{n+1}$.  If $|u| > 1 \Rightarrow |u|^{n} > |u|^{n-1}$ such that
\begin{align*}
\delta \cdot (n+1) \cdot |u|^{n-1} < \delta \cdot (n+1) \cdot |u|^{n}
\end{align*} and so we pick $\delta = \frac{\epsilon}{(n+1) \cdot |u|^{n}}$. In any of the two cases we can choose a delta such that.
\begin{align*}
|u - y| < \delta \Rightarrow |u^{n} - y^{n}| < \delta \cdot (n+1) \cdot |u|^{n} = \epsilon
\end{align*} a statement that holds true since $P(n)$ holds true. Having found the necessary delta, we return to $P(n+1)$.  We choose $\delta = \frac{\epsilon}{n+1}$ if $|u| \leq 1$ or $\delta = \frac{\epsilon}{(n+1) \cdot |u|^{n}}$ if $|u| > 1$ such that the following is holds true
\begin{align*}
|u^{n+1} - y^{n+1}| & < \delta \cdot (n+1) \cdot |u|^{n} = \epsilon \\
|u^{n+1} - y^{n+1}| & < \epsilon
\end{align*} Any feedback is appreciated!  Thanks!","['induction', 'real-analysis', 'epsilon-delta', 'limits']"
2841237,Find the derivative of a function that contains a sum,"If $$f(x)=\sum_{n=1}^\infty{\frac{{(-1)}^{n+1}}{n\cdot3^n}{(x-3)}^n}$$ find $f''(-2)$. I know that, by ratio test, the previous sum converges iff $x\in(0,6)$. I did: $$\begin{matrix}
f'(x)&=&\left(\displaystyle\sum_{n=1}^\infty{\frac{{(-1)}^{n+1}}{n\cdot3^n}{(x-3)}^n}\right)'&=&
\displaystyle\sum_{n=1}^\infty{\frac{{(-1)}^{n+1}}{n\cdot3^n}n{(x-3)}^{n-1}}&=&
\displaystyle\sum_{n=1}^\infty{\frac{{(-1)}^{n+1}}{3^n}{(x-3)}^{n-1}}
\\
f''(x)&=&\left(\displaystyle\sum_{n=1}^\infty{\frac{{(-1)}^{n+1}}{3^n}{(x-3)}^{n-1}}\right)'&=&
\displaystyle\sum_{n=1}^\infty{\frac{{(-1)}^{n+1}}{3^n}(n-1){(x-3)}^{n-2}},
\end{matrix}$$ so I did the radio test on the last sum: $$\begin{matrix}
&&\displaystyle\lim_{n\to\infty}{\left|\dfrac{a_{n+1}}{a_n}\right|} \\
&=&\displaystyle\lim_{n\to\infty}{\left|\dfrac{{(-1)}^{n+2}n{(x-3)}^{n-1}}{3^{n+1}}\dfrac{3^n}{{(-1)}^{n+1}(n-1){(x-3)}^{n-2}}\right|}\\
&=&\dfrac{|x-3|}{3}\underbrace{\displaystyle\lim_{n\to\infty}{\left|\dfrac{n}{n-1}\right|}}_{=\:1}\\
&\Rightarrow&|x-3|<3\\
&\Rightarrow&x\in(0,6),&
\end{matrix}$$ and since $-2\not\in(0,6)$ we cannot find $f''(-2)$. First question: is my reasoning right? If yes, to my amazement the radius of convergence of both functions are the same. Out of curiosity, why is this happening? The convergence can be generalize to $n$-th derivative? Thank you!","['derivatives', 'power-series', 'summation', 'convergence-divergence']"
2841269,How to find the volume of a tetrahedron?,"For this question, how do we find the volume of a tetrahedron in $\Bbb R^4$ if we have a 4 by 3 matrix? The cross product and determinant only work for square matrices. I'm not sure what to do after we subtract the points from the emanating point. Here is what I have so far. Can anyone please help me out? Find the volume of the tetrahedron in $\Bbb R^4$ with vertices $(1,0,0,1),(-1,2,0,1), (3,0,1,1), and (-1,4,0,1)$. $(-1,2,0,1)-(1,0,0,1) = [-2,2,0,0]$ $(3,0,1,1)-(1,0,0,1) = [2,0,1,0]$ $(-1,4,0,1)-(1,0,0,1) = [-2,4,0,0]$","['linear-algebra', 'determinant']"
2841283,"Is the function $1/x$ bijective on $[0, \infty]$?","It is well-known that the function $f (x) = \dfrac{1}{x}$ is not bijective on the domain of non-negative real numbers (that is, $[0, \infty)$ .) , since $f( \cdot)$ may not be well-defined at zero point. I am curious that what if we admit the convention that $0^{-1} = \infty$ and $\infty^{-1} = 0$ . Then, under this setting, is $f(x)$ bijective on $[0, \infty]$ now? Could anyone help me out please? Thank you very much in advance!","['special-functions', 'real-analysis', 'functions', 'rational-functions']"
2841305,"Elliptic curves - ""Important exercise"" 19.10.F in Vakil's note","I have been learning recently about elliptic curves, and I am totally new in this topic. I just followed the construction of the group-scheme structure on elliptic curves given by Vakil in his notes (that you can find here ). Right after this, he gives a pretty concrete exercise (page 522) for which I would like some hints as to how to solve it efficiently. Here is the statement of the exercise. Let $k$ be a field. Consider the genus $1$ curve $C\subset \mathbb{P}^2_k$  given by 
  $$y^2z=x^3+x^2z$$
  with the point $\mathbb{p}=[0,1,0]$. Emulate ""the above argument"" to show that $C \setminus \{[0,0,1]\}$ is a group variety. Show that it is isomorphic to $\mathbb{G}_m$ (the multiplicative group-scheme $\operatorname{Spec}(k[t,t^{-1}])$) with coordinate $t=\frac{y}{x}$ by giving an isomorphism of schemes, and showing that multiplication and inverse in both group-varieties agree under this isomorphism. Okay, there are multiple things going on here. I am going to ask a few questions about this. Some of them may be pretty basic, but I think that this exercise would is a perfect occasion to clear up a few confusions in my mind about basic computations in algebraic geometry. In the following, let $U$ denote $C \setminus \{[0,0,1]\}$. First , to justify that $U$ has a natural structure of scheme, I prove that $[0,0,1]$ is a closed point by computing its residue field in the distinguished open set $z\not = 0$. Here, $C$ becomes the affine curve $y^2=x^3+x^2$ in $\mathbb{A}^2_k=\operatorname{Spec}(k[x,y])$ and the point we are interested in is $(0,0)$. Its residue field is the quotient field of the integral domain $A/(x,y)$, where $A=k[x,y]/(y^2-x^2-x^3)$. This integral domain actually already is a field, none other than $k$. As a result, $[0,0,1]$ is a closed point of $C$ of degree $1$. Is this method the correct way to proceed? Is there a more straightforward way to see it? Second , to show that $U$ comes with a structure of group-variety, I actually need to show that it is a subgroup-scheme of $C$, ie that it is stable under the group laws and contains the neutral point $\mathbb{p}$. Actually, I do not really understand which "" above argument "" Vakil is refering to here. From what I can tell, I have to check by hand that whenever I consider a point in $U$ and look at the line joining it to $\mathbb{p}$, then the third point of intersection with $C$ can not be $[0,0,1]$ ; and the same goes whenever I consider the line joining two arbitrary points of $U$. I think I have actually been able to show the first part, but this is quite fastidious and I feel like there must be another way to check this properly. How would you treat this part of the exercise? Third , to build the scheme-theoretic morphism between $U$ and $\mathbb{G}_m$, it is enough to give a $k$-linear morphism $k[t,t^{-1}]\rightarrow \mathcal{O}_{U}(U)$. Now, I notice that $U$ is just the union of the distinguished open sets $x\not = 0$ and $y \not = 0$, intersected with $C$. The global sections of $U$ are the pairs of global sections on each of these open sets that agree on the intersection. Global sections on each of the open sets are given by a quotient of polynomials whose denominator is non-vanishing. So I see that I could send $t$ to the pair $(\frac{y}{x},\frac{x}{y})$, but these do not agree on the intersection as far as I can tell. How does one makes sense of the statement $t=\frac{y}{x}$ given in the exercise as a hint? Fourth , I know as a general result that a proper geometrically connected curve over a field becomes affine when a finite nonzero number of points are omitted from it (see here ). Hence, it is not surprizing to see that it applies for $U$. However, is there a way to compute this affine space easily in conrete examples? Just by seeing the equation and the point we are omitting, is there a way to guess that we will obtain something nice like $\operatorname{Spec}(k[t,t^{-1}])$? How does one infer what the ring must look like? Thank you very much for reading through this. Any clarification for any of the above points will be greatly appreciated. Edit : As pointed out in the comment, $C$ is not a group-scheme, hence my second point reasoning makes no sense. Let me then replace my second point with the following: in order to show that $U$ is a group-scheme, can I simply argue that $U$ is an elliptic curve, because it is obtained by removing the singular point(s) of a genus $1$ projective curve described by a Weierstraß type equation? If so, this part of the exercise now becomes trivial. What is important is to understand why the group-structure behaves like $\mathbb{G}_m$.","['elliptic-curves', 'algebraic-geometry']"
2841312,"Show that the function $f(x, y) = |xy|$ is differentiable at $(0, 0)$","Firstly I understand that this question has already been asked : Show that the function $f(x,y) = |xy|$ is differentiable at 0, but is not of class $C^1$ in any neighborhood of 0. However that question did not address the question I'm about to ask. In trying to show that $f : \mathbb{R}^2 \to \mathbb{R}$ defined by $f(x, y) = |xy|$ is differentaible at $(0, 0)$ I first calculated the directional derivatives at $(0, 0)$ and I got $D_1f(0, 0) =D_2f(0, 0) = 0$, thus if $f$ is differentiable at $(0, 0)$ then we'd have $Df(0, 0) = [0 \ \ \ 0 ]$ Now I tried to prove that $f$ is differentiable at $(0, 0)$ by using the definition and $Df(0, 0)$ above as a canditate matrix for the derivative (because if the limit doesn't tend to zero using this matrix then it won't exist) and I arrived at the following (letting $h = (c, d)$) $$\lim_{h \to (0, 0)} \frac{f((0, 0) + h) - f(0, 0) - Df(0, 0) \cdot h}{|h|} = \lim_{(c, d) \to (0, 0)} \frac{|cd|}{\sqrt{c^2 + d^2}}$$ but from the above it's not clear (to me) that $$\lim_{(c, d) \to (0, 0)} \frac{|cd|}{\sqrt{c^2 + d^2}} = 0$$ so I can't conclude that $f(x, y) = |xy|$ is differentiable at $(0, 0)$ using the definition. Now there's one other way I think I can prove differentiability which is by using the following theorem Theorem: Let $A$ be open in $\mathbb{R}^m$. Suppose that the partial derivatives of the component functions of $f$ exist at each point $x$ of $A$ and are continuous on $A$. Then $f$ is differentiable at each point of $A$. So I tried to show then that $D_1f(x, y)$ existed and was continuous on $\mathbb{R}^2$, in attempting to show this I ended up with the following $$D_1f(x, y) = \lim_{t \to 0} \frac{f((x, y) + t(1, 0))-f(x, y)}{t} = \lim_{t \to 0}\frac{|(x+t)y|-|xy|}{t}$$
and again I'm not show how to evaluate this limit  so I can't make use of the above theorem. Is there any other way to show that $f$ is differentiable at $(0, 0)$? How could I show that $f$ is differentiable at $(0, 0)$?","['multivariable-calculus', 'real-analysis', 'calculus']"
2841358,Number systems violating easy primes,Many students are surprised to learn that the definition of prime is not generally “only divisible by 1 and itself” for general number systems. What are some examples of numbers systems for which $p|ab$ implies either $p|a$ or $p|b$ is not equivalent to the definition $p$ only is divisible by 1 and itself? And explicit constructions if violating numbers in these systems?,['abstract-algebra']
2841366,Implicit Function Theorem implies the Inverse Function Theorem,"I want to prove that the implicit function theorem implies the inverse function theorem.  I saw in another post what's written below as the proof for this but I don't understand what they've done. $$ \text{ For } f : \mathbb{R}^n \to \mathbb{R}^n \text{, consider } F:\mathbb{R}^n\times\mathbb{R}^n \to \mathbb{R}^n   \text{ given by } F({\bf x}, {\bf y}) = f({\bf y}) - {\bf x}$$ Do we consider $f(x)$ to be the implicit function satisfying $F\big(x,f(x)\big)=0$ , and by the definition of $F$ we get $F\big(x,f(x)\big)=0=f\big(f(x)\big)-x \Longrightarrow f\big(f(x)\big)=x$.  It seems I was wrong by assuming defining $f$ as the implicit function and I should have just let it be $g$.  So if we instead get the final implcation being $f\big(g(x)\big)=x$ is that proof of the inverse function theorem? Thanks!","['real-analysis', 'calculus', 'multivariable-calculus', 'proof-explanation', 'analysis']"
2841385,Evaluate the integral $\int \frac{\sec x}{\sqrt{3+\tan x}}dx$,Evaluate the following integral.$$\int \frac{\sec x}{\sqrt{3+\tan x}}dx$$ On putting $t=\tan x$ I am getting $$\int\frac{1}{\sqrt{(t^2+1)(t+3)}}dt$$. How should i proceed from here.,"['indefinite-integrals', 'real-analysis', 'integration']"
2841389,Find the minimum value of $\frac{a+b+c}{b-a}$,Let $f(x)=ax^2+bx+c$ where $(a<b)$ and $f(x)\geq 0$  $\forall x\in R$. Find the minimum value of $$\frac{a+b+c}{b-a}$$ If $f(x)\geq 0$  $\forall x\in R$ then $b>a>0$ and  $b^2-4ac\leq 0$ implying that $c>0$. After this not able to find way out.,"['algebra-precalculus', 'polynomials', 'quadratics']"
2841418,"Can a non-differentiable space, such as the Weierstrass curve, be connected?","I’m not a mathematician and I’m very new to topology, I’m just a guy who’s curious about shapes. My favorite function is the Weierstrass function, which is continuous everywhere but differentiable nowhere. Is its curve connected? Is that even a valid question to ask for a non-differentiable curve? Thanks for your time.",['general-topology']
2841427,Examples of functions where $f'(x)=f(f(x))$ for all $x$,I am looking for examples of functions $f:\mathbb R \to \mathbb R$ where $f'(x)=f(f(x))$ for all $x$. The only example I can find is the trivial one where f is identically 0.,['real-analysis']
2841429,Bound on expectation using the Markov's inequality,"I'd like to show $$E\Big(|X|^k1_{\{|X|^k\ge M\}}\Big) \le M^{1-\frac{p}{k}}E|X|^p,$$
where $X$ is a r.v., $k<p$, and $M$ is a positive real number. It is suggested to use the Markov's inequality (Asymptotic Statistics, Van der Vaart, example 2.21). It seems to me that Markov's inequality alone is not enough to obtain the rhs bound. I am wondering what other result can be used along with the Markov's inequality.","['probability-theory', 'expectation']"
2841475,Find $\limsup_{n \rightarrow \infty} A_n$ and $\liminf_{n \rightarrow \infty} A_n$ when $A_n = \{x: a_n \leq x < b_n\}$.,"I am in self-studying mode with the book of Resnick (""A probability Path 1 ""), and trying to solve a basic problem, namely, 1.9.6, so my apologizes for the basic question. The problem states: Assuming $a_n > 0$ and $b_n > 1$, $\lim_{n \rightarrow \infty} {a_n} = 0$, and $\lim_{n \rightarrow \infty} {b_n} = 1$. Define, $A_n = \{x: a_n \leq x < b_n\}$. Find, $\limsup_{n \rightarrow \infty} A_n$ and $\liminf_{n \rightarrow \infty} A_n$. Using the definitions of both $\limsup_{n \rightarrow \infty} A_n$ and $\liminf_{n \rightarrow \infty} A_n$ I arrived to: $\limsup_{n \rightarrow \infty} A_n = (0, 1)$ For $\liminf_{n \rightarrow \infty} A_n$, I understand that $\cap_{k=n}^{\infty} A_n = [a_n, b_n) \cap [a_{n+1}, b_{n+1}) \cap ... = [a_n, b_{n+1})$, since $\forall k \geq n, a_k > a_{k+1}$, and $b_k > b_{k+1}$. Thus, I would be arriving to $\liminf_{n \rightarrow \infty} A_n = (0, 1)$. Am I doing it right? Thanks for possible tips/helps to correctly address the problem.","['probability', 'elementary-set-theory']"
2841509,Determining stability of equilibrium points for a non linear system,"Given the system: $$
\left\{ 
\begin{array}{}
\dot x=-x^3y^2 \\ 
\dot y = -2x^2y^3
\end{array}
\right. 
$$ I need to find the equilibrium points and to determine whether the system is stable around them. I'v found $(0,0)$ to be a stable equilibrium point, using the Lyapunov function $V(x)=x^2+y^2$. The rest of the equilibrium points are $(x_0,0), (0,y_0) \; , \; x_0,y_0 \in \Bbb R$. I'm having trouble with determining wether they are stable or not. Linearization is not useful in this case, and I couldn't find any Lyapunov function.","['stability-in-odes', 'lyapunov-functions', 'ordinary-differential-equations']"
2841535,Proof of the Extended Liouville's Theorem,"I'm trying to prove the Extended Liouville's Theorem: Let $f$ be an entire function. Assume that for some $k \in \mathbb{N}$, and sufficiently large $|z|$, we have that $|f(z)| \leq A + B |z|^k$. Prove that $f$ is a polynomal of degree at most $k$. Proof: The case $k = 0$ is the original Liouville Theorem. Assume the claim is true for some $k \in \mathbb{N}$. We prove it for $k + 1 \in \mathbb{N}$. Define the function, \begin{align}
g(z) = 
\begin{cases}
\frac{f(z) - f(0)}{z} \quad z \neq 0, \\
f'(0) \; \; \; \; \quad z = 0.
\end{cases}
\end{align} Noting that $0 \leq |f(0)| \leq A$, we have that, for $z \neq 0$, \begin{align}
|g(z)| & = \frac{|f(z) - f(0)|}{|z|}, \\
& \leq \frac{|f(z)| + |f(0)|}{|z|}, \\
& \leq \frac{A + B|z|^{k+1} + A}{|z|}, \\
& = \frac{2A + B|z|^{k+1}}{|z|}, \\
& = \frac{2A}{|z|} + B |z|^k, \\
& \leq \frac{2A}{M} + B |z|^k, \\
& \equiv D + B |z|^k, \\
\end{align} where the last inequality follows since the theorem is stated for $|z| \geq M$ for some $M \in \mathbb{R}$. Considering the compact domain bounded by a closed and bounded circle of radius $M$, we have that, since $g(z)$ is entire, and hence continuous, we have that, \begin{align}
g(z) \leq N \quad for \quad |z| \leq M.
\end{align} Since $g(z)$ is bounded such that is satisfies the statement of theorem for some $k \in \mathbb{N}$, we have that $g(z)$ is a polynomial of degree at most $k$. A simple rearrangement of the given piecewise function now allows us to argue that $f(z)$ is a polynomial of degree at most $k + 1$. Does this proof make sense?",['complex-analysis']
2841572,"Evaluating $\int_0^1\frac{3x^4+ 4x^3 + 3x^2}{(4x^3 + 3x^2 + 2x+ 1)^2}\, dx$","$$\int_0^1\dfrac{3x^4+ 4x^3 + 3x^2}{(4x^3 + 3x^2 + 2x+ 1)^2}\, dx$$ Attempt: If we write: $f(x)= x^4 + x^3+ x^2$ , we get: $$I = \displaystyle\int_0^1 \dfrac{3f(x)+x^3}{(f'(x)+1)^2}\, dx$$ I have no idea how to proceed. Integration by parts/ substitution can't help. I don't need the full solution. Just a guiding hint would suffice.","['integration', 'definite-integrals', 'calculus']"
2841602,"Using basis $e=[x^3,x^2,x,1]$ instead of $e=[1,x,x^2,x^3]$","So on an exam I've got zero points on the question (and sub-questions) to find matrix of linear operator $L:\Bbb{R}^4[x]\to \Bbb{R}^4[x]$ given by $L(p(x)) = p(x)+xp(2)$ with respect to canonical basis $e$ I've said I'm using notation $(a,b,c,d)$ to mean $(ax^3,bx^2,cx,d)$
I've found the matrix for $L$ lets say $A$ which is
$$A=\begin{bmatrix}1 & 0 & 0 & 0\\0 & 1 & 0 & 0\\8 & 4 & 3 & 1\\0 & 0 & 0 & 1\end{bmatrix}$$
Now
$$\begin{bmatrix}1 & 0 & 0 & 0\\0 & 1 & 0 & 0\\8 & 4 & 3 & 1\\0 & 0 & 0 & 1\end{bmatrix}\begin{bmatrix}a \\ b \\ c \\ d\end{bmatrix}=\begin{bmatrix}a \\ b \\ 8a+4b+3c+d \\ d\end{bmatrix}$$
Which is the right result (using my notation), however they've got a different matrix by using $(a,b,c,d) = (a,bx,cx^2,dx^3)$ They found
$$A=\begin{bmatrix}1 & 0 & 0 & 0\\1 & 3 & 4 & 8\\0 & 0 & 1 & 0\\0 & 0 & 0 & 1\end{bmatrix}$$
Which is again the right answer (using their notation), so I'm looking for references to use of the first notation or references/reasons to why my notation is wrong.","['matrices', 'reference-request', 'vector-spaces', 'linear-algebra', 'hamel-basis']"
2841608,Your Favourite Application of the Birkhoff Ergodic Theorem,"Here we have a big list of great applications of the Baire category theorem. I recently read the Birkhoff ergodic theorem and I think perhaps this theorem is on par with Baire's theorem in terms of its applications to diverse topics. The theorem states that (See Theorem 1.14 in Peter Walter's An Introduction to Ergodic Theory ). Let $(X, \mathcal F, \mu)$ be a $\sigma$-finite measure space and $T:X\to X$ be a measure preserving transformation.
  Let $f\in L^1(X, \mu)$.
  Then $(1/N)\sum_{n=0}^{N-1}f(T^nx)$ converges almost everywhere to an $L^1(X, \mu)$-function $f^*$.
  Further, we have $f^*\circ T=f^*$ and if $X$ is a finite measure space than $\int_Xf^*\ d\mu=\int_Xf\ d\mu$. These are some applications of the Birkhoff ergodic theorem that I know of: Here is a proof of the law of large numbers using the Ergodic theorem If $P$ is the transition matrix of a finite state space Markov chain having a strictly positive stationary distribution, then the limit
$$
Q:=\lim_{N\to \infty} \frac{1}{N} \sum_{n=0}^{N-1} P^n
$$
exists. The matrix $Q$ is a stochastic matrix and satisfies $QP=PQ=Q$, and $Q^2=Q$.
This has applications to Markov chains. A proof can be found in Peter Walter's An Introduction to Ergodic Theory (Lemma 1.18) Almost all numbers in $[0, 1)$ are normal in base 2, that is, for almost all $x$ in $[0, 1)$ the frequency of $1$'s in the binary expansion of $x$ is $1/2$. (For a proof see Theorem 1.15 in Peter Walter's An Introduction to Ergodic Theory ). What is your favourite application of the ergodic theorem?","['applications', 'big-list', 'ergodic-theory', 'measure-theory']"
2841618,95% Confidence Interval for $\lambda$,"Consider a random sample $X_1,X_2,..,X_n$ from a variable with density function
  $$f_X(x)=2\lambda\pi xe^{-\lambda\pi x^2} \ \ \ \ \ \ \  x>0$$
  A useful estimator of $\lambda$ is $$\hat{\lambda}=\frac{n}{\pi\sum_{i=1}^{n} X^2_1}$$
  Derive a 95% confidence interval for $\lambda$ $\big($a hint is provided suggesting to consider the distribution of $\frac{\lambda}{\hat{\lambda}}\big).$ Taking the advice of the hint, I attempted to find the distribution of  $\frac{\lambda}{\hat{\lambda}}.$
$$\frac{\lambda}{\hat{\lambda}}=\frac{\lambda}{\frac{n}{\pi\sum_{i=1}^{n} X^2_1}}=\frac{\pi\lambda}{n}\sum_{i=1}^{n} X^2_i$$
It can be shown that $$\frac{\pi}{n}\sum_{i=1}^{n} X^2_i\sim\text{Gamma}\Big(n,\frac{1}{n\lambda}\Big)$$ 
and hence
$$\lambda\Bigg(\frac{\pi}{n}\sum_{i=1}^{n} X^2_i\Bigg)\sim\text{Gamma}\Big(n,\frac{1}{n}\Big)$$
But how does this help find a confidence interval?
The only formula I really know for confidence intervals for similar types of questions is $\hat{\lambda}\pm z_{0.975}\text {se}(\hat{\lambda})$ where $Z\sim N(0,1)$ Edit , using the pivotal method:
$$\mathbb{P}\Big(g_{\frac{\alpha}{2}}\leq \frac{\lambda}{\hat{\lambda}}\leq g_{1-\frac{\alpha}{2}}\Big)=0.95$$
$$\mathbb{P}\Big(\hat{\lambda}g_{0.025}\leq\lambda\leq\hat{\lambda}g_{0.975}\Big)=0.95$$
Hence a 95% confidence interval is $$\Big(\hat{\lambda}g_{0.025},\hat{\lambda}g_{0.975}\Big)$$
where $g_{\frac{\alpha}{2}}$ is the $\frac{\alpha}{2}$%tile of the $\text{Gamma}(n,\frac{1}{n})$ distribution.","['statistics', 'probability', 'confidence-interval', 'hypothesis-testing']"
2841621,Holomorphic functions with values in $L^2(X)$ vs. pointwise holomorphy.,"Let $X$ be a measure space. By Riesz-Fischer, $L^2(X)$ is a Banach space. When $U \subseteq \mathbb C$ is open, we have a notion of holomorphic functions $U \to L^2(X)$. (See the bottom for definitions.) Let's write such functions as $E(s, w)$. When $X$ has a nice topology (say it a Riemannian manifold) and $E$ is continuous in $(s, w)$ it makes sense to evaluate in $w$ and ask whether the complex-valued $E(s, w_0)$ is holomorphic for a specific $w_0$. Question. Are there any implications between the holomorphy of $E : U \to L^2(X)$ and the holomorphy of $E(\cdot, w_0) : U \to \mathbb C$ for all $w_0$? Here's one result in this direction I found: suppose $E : U \to L^2(X)$ is compactly supported, continuous in $(s, w)$, holomorphic in $s$ for all $w$ and $E'$ is continuous in $(s,w)$. Then $E$ and $E'$ are in $L^2$ and we have $$E(s, w) - E(s_0, w) = E'(s_0, w) (s-s_0) + o_w(s-s_0) $$
By assumption the little-$o$ term divided by $s-s_0$ is continuous in $(s,w)$, hence is square integrable and we have
$$E(s, w) - E(s_0, w) = E'(s_0, w) (s-s_0) + o(s-s_0) $$
as an $L^2$-statement. I.e. $E : U \to L^2(X)$ is holomorphic. Equivalent definitions of holomorphic functions $f : U \to Y$, for $Y$ a Banach space are: $f$ is everywhere approximately linear: $f(s)-f(s_0) = f'(s_0)(s-s_0) + o(s-s_0)$ $\lambda \circ f$ is holomorphic for all $\lambda \in Y^*$ $f$ is locally a power series of the form $\sum A_n (s-s_0)^n$ Note the similarity between 2. and the question, where in a sense we look at $\lambda$ being the evaluation in a point (which is not well-defined on $L^2$).","['banach-spaces', 'functional-analysis', 'complex-analysis', 'measure-theory', 'holomorphic-functions']"
2841623,"Find all complex numbers satisfying $z\cdot\bar{z}=41$, for which $|z-9|+|z-9i|$ has the minimum value","My first attempt was to express $z$ as $x+iy$ and minimize the expression $\sqrt{(x-9)^2+y^2}+\sqrt{x^2+(y-9)^2}$ where $x^2+y^2=41$. That said, it seems to me that using the geometric interpretation could be easier. As far as I understand, I need to find points on the circle for which the sum of distances to the points $(9,0)$ and $(0,9)$ is lowest. This interpretation, however, doesn't help with regard to calculations. Is there some simple trick or idea I'm missing? Thank you!","['complex-analysis', 'conic-sections', 'complex-numbers']"
2841640,Is a vector space over a ring or over a field?,"What is a vector space? I can see two different formulations, and between them there is one difference: commutativity. DEFINITION 1 (See here ) Let $(F, +_F, \times_F)$ be a division ring.
  Let $(\mathcal{V}, +_\mathcal{V})$ be an abelian group. 
  Let $(\mathcal{V}, +_\mathcal{V}, \cdot)_F$ be a unitary module over $F$. Then $(\mathcal{V}, +_\mathcal{V}, \cdot)_F$ is a vector space over $F$. That is, a vector space is a unitary module over a ring, whose ring is a division ring. DEFINITION 2 Let $(F, +_F, \times_F)$ be a field.
  Let $(\mathcal{V}, +_\mathcal{V})$ be an abelian group. 
  Let $\cdot: F\times \mathcal{V} \longrightarrow \mathcal{V}$ be a function. A vector space is $(\mathcal{V}, +_\mathcal{V}, \cdot)_F$ such that $\forall a,b, \in F$ and $\forall x,y \in \mathcal{V}$: $\cdot$ right distributive:  $(a +_F b) \cdot x = (a\cdot x) +_\mathcal{V} (b\cdot x)$ $\cdot$ left distributive: $\,\,\, a \cdot (x +_\mathcal{V} y) = (a\cdot x) +_\mathcal{V} (a\cdot y)$ $\cdot$ compatible with $\times_F$: $(a\times_F b) \cdot x = a \cdot (b\cdot x)$ $\times_F$ 's identity is $\cdot$'s identity: $1_F \cdot x = x$ There could also be other definitions,but for now it doesn't matter. What matter is that commutativity is not considered in the same way in both definitions! In the first definition, we ahve a division ring (not a commutative division ring, i.e. a field!), while in the second we have a field (i.e. a commutative division ring). Notice that the key difference on which I am struggling is that on one side we have a division ring and on the other side a commutative division ring. The first is an abelian group $(R, +_R)$ under the $+_R$ binary operation, however $(R, \times_R)$ is only a group (i.e. not abelian, i.e. not commutative).","['definition', 'linear-algebra', 'vector-spaces']"
2841703,Do all systems of differential equations have a solution?,"I'm not really sure that I have the required knowledge to pose this question properly so I'll just pose it poorly. The rise of numerics has allowed us to study systems of differential equations for which no general solution had previously been found (i.e. gravitational systems with >=3 particles). My question is if these systems of equations even actually have a solution that can be represented by functions or whatever. Could it be that these systems don't have solutions in the traditional sense? In line with this question, can a system that demonstrably shows chaos have a closed form mathematical solution? Are there any functions that show chaotic behavior?","['chaos-theory', 'ordinary-differential-equations', 'closed-form']"
2841707,Why does experimental probability approach theoretical probability? Why does it converge only when there are large samples and not when it's small?,"I went through Khan Academy's lecture on theoretical and experimental probability . I also read through a Wikipedia article on this but was still not clear. I understand how it approaches (as explained in the video) but unable to understand why experimental probability approaches theoretical probability. What is the reason for this? I think that the general sense is, if I take a large enough sample, I am going to end up getting the expected mean of the sample. The more experiments I do, the more it converges. Sure, I get that. But why does it converge only when there are large samples and not when it's small?","['statistics', 'probability']"
2841714,"What is $\int x^4 \, d\mu_p$ on the circle $\{ x^2 + y^2 = 1 \}$ respect to Haar measure on $\mathbb{Q}_p$?","I am trying to understand integration with respect to Haar measure.  Here are the first two examples I can think of.  Let $X$ be the variety corresponding to the circle:
$$ X = \{ x^2 + y^2 - 1 = 0 \}$$
Then we can consider $X$ over any field... $X(\mathbb{R})$ is the Euclidean circle, but also $X(\mathbb{Q})$ is the rational points.  Then we could consider the completions $X(\mathbb{Q}_p)$.  Is it fair to assume that:
$$ \overline{X(\mathbb{Q})} = X(\mathbb{Q}_p) $$
in the $p$-adic topology? These points will now carry a lie group action, just the rotational symmetry of the circle $\text{SO}_2(\mathbb{Q}_p)$ which (superficially) looks like it should behave similar to $\text{SO}_2(\mathbb{R})$. What is the ""average"" value of $x$ and $x^2$ with respect to these measures. I'd expect by symmetry that $\int_X x \, d\mu_p = 0$ What could $\int_X x^2 \, d\mu_p$ evaluate to? Here we get an answer that should work for any measure: $$2 \int_X x^2 \, d\mu_p =  \int_X x^2 \, d\mu_p + \int_X y^2 \, d\mu_p 
= \int_X (x^2 + y^2) \, d\mu_p = \int_X 1 \, d\mu_p = 1$$ but the question of integrating function over Haar measure over the circle remains.  I guess next would be 4th moment? $$ \int_{X =  \{ x^2 + y^2 - 1 = 0 \} } x^4 \, d\mu_p $$","['haar-measure', 'fourier-analysis', 'algebraic-geometry', 'p-adic-number-theory']"
2841755,Evaluate the given complicated double integral,"$$\int_{-1}^{1} \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}  e^{\frac{-1}{1-(x^2+y^2)}}\log\Big(\log\big(\frac{2}{\sqrt{(1-x)^2+(1-y)^2}}\big)\Big)\,dy\,dx.$$ I got this super hard integral while doing an exercise on distributions. The only thing I could think of is to transform it  into polar coordinates. It changes into $$\int_{0}^{2\pi} \int_{0}^{1}  e^{\frac{-1}{1-r^2}}\log\Big(\log\big(\frac{2}{\sqrt{r^2-2r\cos(\theta)-2r\sin(\theta)+2}}\big)\Big)\,r\,dr\,d\theta.$$ But even WolframAlpha couldn't compute this. Does anyone know how to evaluate this? Edit:- There is no closed form of this integral. If anyone has any suggestions regarding approximations, please comment below.","['multiple-integral', 'calculus', 'multivariable-calculus', 'integration', 'definite-integrals']"
2841760,"Counter-examples for quasi-coherent, coherent, locally free and invertible sheaves",I'm trying to find at least one counter-example for each of these concepts to feel more comfortable with understanding the ideas behind them but I cannot even get started :( Please help me find counter-examples for the following concepts: A quasi-coherent sheaf that is not coherent A coherent sheaf that is not locally free A locally free sheaf that is not globally free A locally free sheaf that is not invertible I'm studying sheaves from Kempf's Algebraic Varieties . My main problem that prevents me from attacking the above questions is that I do not know how I can create new sheaves or modify old sheaves to make them have interesting properties. The only example of a sheaf I know is an algebraic variety with its structure sheaf (i.e. the $k$-algebra of regular functions over its open sets when it's considered as a space with functions). Kempf's definitions are so abstract for me and I would highly appreciate any glimpse of intuition or information that answers the above questions.,"['quasicoherent-sheaves', 'coherent-sheaves', 'sheaf-theory', 'algebraic-geometry']"
2841804,find: $\lim_{n\rightarrow\infty}\frac{\sin\left(x+\frac{1}{n}\right)-\sin\left(x\right)}{\sin\left(x+\frac{1}{n}\right)}$,Find: $$\lim_{n\rightarrow\infty}\frac{\sin\left(x+\frac{1}{n}\right)-\sin\left(x\right)}{\sin\left(x+\frac{1}{n}\right)}$$ as $x\in\mathbb{R}$ My progress: $$\lim_{n\rightarrow\infty}\frac{\sin\left(x+\frac{1}{n}\right)-\sin\left(x\right)}{\sin\left(x+\frac{1}{n}\right)}=\lim_{n\longrightarrow\infty}\frac{\sin\left(x+\frac{1}{n}\right)}{\sin\left(x+\frac{1}{n}\right)}-\frac{\sin\left(x\right)}{\sin\left(x+\frac{1}{n}\right)}=$$ $$\lim_{n\longrightarrow\infty} \ \ {1}-\frac{\sin\left(x\right)}{\sin\left(x+\frac{1}{n}\right)}=1-\lim_{n\longrightarrow\infty}\frac{\sin\left(x\right)}{\sin\left(x+\frac{1}{n}\right)}$$ at this point I got stuck. I can't evaluate the Taylor series of $\sin(x+\frac{1}{n})$ because $n$ is not fixed (even if we'll suppose that there exist some $\epsilon>0$ and there exists $ N\in\mathbb{N}:\forall n\geq N$ s.t: $$-\epsilon<\frac{1}{n}<\epsilon$$ it doesn't seem like a formal argument to me) (I might be very wrong - it's only my intuition). Also trying to apply L'Hopital's rule for this expression isn't much helpful.,['limits']
2841816,When can we extend distance-preserving maps between finite sets of points to isometries?,"Suppose I have $n$ points $x_1, \ldots ,x_n \in \mathbb{R}^d$ where the affine span of $\{x_1, \ldots ,x_n \}= \mathbb{R}^d$. If I have another set of points $y_1, \ldots, y_n$ where $\|y_i - y_j\| = \|x_i - x_j \|$ for all $i,j \in \{1, \ldots, n\}$ where $\| \cdot \|$ is the Euclidean norm then there exists an isometry $f : \mathbb{R}^d \rightarrow \mathbb{R}^d$ such that $f(x_i)=y_i$ for all $i = 1 , \ldots, n$. The same cannot be said for general normed spaces, for instances if we take $$x_1 =(0,0), ~ x_2 = (1,0), ~ x_3=(0,1)$$ in $(\mathbb{R}^2, \| \cdot \|_1)$ and $$y_1 = (0,0), ~ y_2 = (0.5,0.5), ~ y_3 = (0.5,-0.5).$$ Does anyone know of where to look into such results? My intuition say that for $\mathbb{R}^d$ with a smooth $\ell_p$ norm (i.e. $1<p<\infty$) we would need $2d$ points but I have no idea where to begin to look for papers in this area. Any ideas and/or references would be much appreciated.","['isometry', 'geometry']"
2841830,Lifting spectral gap to covering space,"Let $M$ a complete Riemannian manifold. It is well known that the Laplace-Beltrami operator on $M$ is essentially self-adjoint and thus has a unique self-adjoint extension  $\Delta_M$ in $L^2(M)$. The spectrum $\sigma(\Delta_M)$ is contained in $[0,\infty)$ and we denote
$$
\lambda(M):=\inf\{\mu\in\sigma(\Delta_M)\vert \mu\neq 0\}.
$$
If $M$ is closed, then $\lambda(M)$ is positive and coincides with the smallest nonzero eigenvalue. However $\lambda(M)$ may very well be $0$, as it is the case for $M=\mathbb{R}^n$. (Non-compact examples with $\lambda(M)>0$ are provided by simply connected spaces with negative sectional curvatures bounded away from $0$ - this was shown by McKean .) Question: Suppose $N$ is a complete Riemannian manifold with $\lambda(N)>0$ and $p\colon \hat N \rightarrow N$ is a finite sheeted Riemannian covering. Do we have $\lambda(\hat N)>0$? 1) EQUIVALENT PROBLEM This is related to this question of mine. (Note that $\lambda(M)>0$ if and only if the (unique) closed extension of the exterior derivative $d$ in $L^2$ has closed range.) 2) TRANSFER HOMOMORPHISM AND CALCULATION ON CIRCLES Here are some ideas and an example calculation: (Let $n$ the number of sheets of $p$). First, define the transfer homomorphism $T\colon L^2\hat N \rightarrow L^2N$ as follows: If $v\in L^2\hat N$ and $U\subset N$ is an evenly covered open set, then $Tv:=1/n \cdot \sum_{j=1}^n s_j^*v$, where $(s_j\colon U\rightarrow \hat N)_j$ are the $n$ distinct local sections of $p$. Then $Tp^*= I \in \mathcal{B}(L^2N)$ $p^*T=:Q\in \mathcal{B}(L^2\hat N)$ is the orthogonal projection onto the subspace of functions which are invariant under the action of deck transformations. $T\hat \Delta v=\Delta T v$ for $v\in C^\infty\hat N\cap L^2\hat N$. Naive Strategy: Let's just look at eigenvalues and let's try to prove that $\sigma_p(\hat \Delta) \subset \sigma_p(\Delta)$. Problem: If $\hat\Delta v = \lambda v$, then $\Delta Tv = \lambda Tv$, but $Tv$ might be $0$. Example: Let $S^1_L:=\mathbb{R}/{L\mathbb{Z}}$ the circle of length $L$. Then $u_k(t) = \exp(2\pi itk/L )$ defines a smooth function on $S_L^1$
and satisfies $-u_k''=(2\pi k/L)^2 u_k$. All eigenfunctions of $\Delta_{S^1_L}$ are of this form and thus $\sigma(\Delta_{S^1_L})=\{(2\pi k/L)^2\vert ~k\in \mathbb{Z}\}$ and $\lambda(S^1_L)=(2\pi/L)^2$. Now consider $p\colon S^1_{nL} \rightarrow S^1_{L},t + nL\mathbb{Z} \mapsto t + L\mathbb{Z} $. We first see that $\lambda(S^1_{nL})=n^{-2}\lambda(S^1_L)$, hence $\sigma_p(\hat \Delta) \subset \sigma_p(\Delta)$ cannot be true. What happens? The transfer homomorphism is of the form $
Tv(t) =1/n\cdot \sum_{j=1}^{n} v(t+jL).
$
Let $v_k(t) = \exp(2\pi itk/(nL) )$ the eigenfunctions on $S^1_{nL}$. Then
$$
Tv_k =v_k \cdot 1/n \cdot \sum_{j=1}^n  \exp(2\pi ijk/n )=\begin{cases} 0 & k \nmid n \\
v_k & k \mid n
\end{cases},
$$
hence the first few eigenfunctions indeed lie in the kernel of $T$. 3) ABSTRACT APPROACH Here is another thought: Maybe we can forget about the covering space setting and just focus on the action of $G=\mathrm{Aut}(p)$ on $H=L^2\hat N$. Take this as new setting: Let $G$ a finite group that acts on a Hilbert space $H$ by isometries and suppose that $A$ is a self-adjoint operator in $H$ such that If $x\in D(A)$, then for all $g\in G$ $gx\in D(A)$ and $Agx=gAx$. Let $H^G$ the subspace of $G$-invariant elements and $A^G$ with domain $D(A^G)=D(A)\cap H^G$ the restriction of $A$ to $H^G$. This is then a self-adjoint operator in $H^G$ and the question is: Can we determine $\sigma(A)$ from $\sigma(A^G)$? Unfortunately the answer to this question is no: Example: Let $H = \mathbb{C}^2$, $G=\{I,\begin{bmatrix}0&1 \\ 1&0 \end{bmatrix} \}$. Then any self-adjoint $G$-equivariant matrix has the form $A=\begin{bmatrix}a &b \\ b & a\end{bmatrix}$ for $a,b\in \mathbb{R}$. It's easy to compute $\sigma(A) = \{a+b,a-b\}$ and $\sigma(A^G)=\{a+b\}$. So in the general setting described above we cannot hope to relate the spectra. Now the Laplace operator is local and in particular its action is somehow determined by the action on $H^G$. But to prove this I have to use cutoff functions and I am not sure, if this can be transalted into the general Hilbert space setting. But maybe that is the key.","['functional-analysis', 'spectral-theory', 'riemannian-geometry', 'differential-geometry']"
2841853,$T^*$ is invertible whenever $T$ is invertible.,"Is the following argument correct? In addition can someone please provide some insight concerning the second claim in the given proposition. Proposition . Let $V$ be finite-dimensional inner product space, and let $T$ be a linear operator on $V$. Prove that if $T$ is
  invertible then $T^*$ is invertible and $(T^*)^{-1} = (T^{-1})^*$. Proof. Assume $T$ is invertible and $T^*w_0 = 0$ where $w_0\in V$ then by definition of adjoint $\langle Tv,w_0\rangle = 0,\forall v\in V$, but from hypothesis there exists a $v_0\in V$ such that $Tv_0 = w_0$ consequently $\langle Tv_0,w_0\rangle = \langle w_0,w_0\rangle = 0$ implying $w_0 = 0$. 
Thus $\operatorname{null}T^* = \{0\}$ equivalently $T^*$ is injective and by theorem $\textbf{2.5}$ invertible. $\blacksquare$ Note: $\textbf{2.5}$ is the result that given an operator $T$ on a finite-dimensional vector space $V$ invertibility,injectivity and surjectivity are all equivalent.","['adjoint-operators', 'linear-algebra', 'proof-verification', 'inner-products']"
2841855,"Relation between metric spaces, normed vector spaces, and inner product space.","I am wondering what exactly is the relationship between the three aforementioned spaced. All of them seem to show up many times in: Linear Algebra, Topology, and Analysis. However, I feel like I'm missing the bigger picture of how these spaces relate to each other. For example, in my course in multi-dimensional analysis, we started out talking about metric spaces, but later suddenly switched to normed vector spaces, without any explicit mention of this transition. In linear algebra we usually talked about inner product spaces, and in topology we talked about metric spaces and topological spaces. The bigger picture of the relation between these three is still unclear to me. Which is used where, for what reason, and how do they relate? I do know the definitions of all three of them: A metric space is a pair $(S,d)$ with $S$ a set and $d: S \times S \to \mathbb{R}_{\geq 0}$ a metric : $d(x,x) = 0$ for all $x \in S$ and $d(x,y) >0$ for $x \neq y$, $d(x,y) = d(y,x)$, $d(x,z) \leq d(x,y) + d(y,z)$. A (real) inner product space is a pair $(V,\langle \cdot \rangle)$ where $V$ is a (real) vector space and $\langle \cdot \rangle: V \times V \to \mathbb{R}$ is an inner product : $\langle v,w \rangle = \langle w,v \rangle$, $\langle a_1 v_1 + a_2v_2,w \rangle = a_1\langle v_1,w \rangle + a_2\langle v_2,w \rangle$ for all $a_1,a_2 \in \mathbb{R}$, $v \neq 0 \Longrightarrow \langle v,v \rangle > 0$. A (real) normed vector space is a pair $(V,\|\cdot\|)$ where $V$ is a (real) vector space and $\|\cdot\|: V \to \mathbb{R}_{\geq 0}: v \mapsto \|v\|$ is a norm on $V$: $\|v\| \geq 0$ and $\|v\|  = 0 \ \Longleftrightarrow \ v = 0$. For $t \in \mathbb{R}$ and $v \in V$ we have $\|tv\| = |t|\|v\|$ $\|v+w\| \leq \|v\| + \|w\|$. I also know that an inner product gives rise to a norm by taking $\|v\| = \sqrt{\langle v,v \rangle}$, for example the Euclidean norm derives from the standard inner product on $\mathbb{R}^n$ in this way. And Cauchy-Schwarz: $|\langle x,y \rangle| \leq \|x\|\|y\|$. I'm not interested in details about the definitions but in the intuition and bigger picture of these three spaces, and how they show up in Analysis.","['real-analysis', 'normed-spaces', 'inner-products', 'metric-spaces', 'vector-spaces']"
2841856,Is it possible to check injectivity of a homomorphism by checking just the generators of the group?,"Let $G$ be a group with generators $\{g_i\}_{i\in I}$. Let $\psi:G\to H$ be a group homomorphism (to another group $H$). Is it possible to check injectivity of $\psi$ just by checking the generators? That is, if $\psi(g_i)=\psi(g_j)$ implies $g_i=g_j$ for all $i$, $j$, does it necessarily mean that $\psi$ is injective? Thanks.","['abstract-algebra', 'group-theory', 'group-homomorphism']"
2841871,$A^2+B^2 +AB=36. B^2+C^2+BC=49. C^2+A^2+AC=64.$ Find $(A+B+C)^2$,"$$A^2+B^2 +AB=36.\\ B^2+C^2+BC=49.\\ C^2+A^2+AC=64.$$ Find $(A+B+C)^2$. I have tried it by using geometry I.e constructing a triangle and marking a point inside it which is making 120 ° and then using cosine rule 
But have difficulty in solving further
Please use geometry","['algebraic-geometry', 'geometry']"
2841892,"Prove that if $f$ is differentiable at $a$, then $|f|$ is also differentiable at $a$, provided that $f(a) \ne 0$","Prove that if $f$ is differentiable at $a$, then $|f|$ is also differentiable at $a$, provided that $f(a) \ne 0$ Solution Attempt: $f$ is differentiable at $a \implies \lim_{x \rightarrow a} \dfrac {f(x)-f(a)}{x-a} = M$ $\implies \forall ~\epsilon>0,~\exists \delta \in \mathbb R^+$ such that $~~|\dfrac{f(x)-f(a)}{x-a} - M| < \epsilon,$ whenever $|x-a| < \delta$ Now, if we prove that $|~\dfrac{|f(x)|-|f(a)|}{x-a}-|M|~| ~~\le \epsilon$ whenever $|x-a| < \delta$, we are done. In general, we have the following inequalities which can come handy, for example: $|X \pm Y| \le |X| + |Y|$ and $|X-Y| \ge ||X|-|Y||$ I tried a bit of approaches but haven't got close to proving the desired result. Could someone please give me a direction. Thanks a lot!","['derivatives', 'absolute-value', 'calculus']"
2841983,Degree $2015$ polynomial value at $2016$,"I was doing this question from an RMO Practice Paper, and I have been unable to solve it. Let $P(x)$ be a polynomial of degree $2015$. $P(k)=2^k$ for $k=0,1,2,\dots,2015$. Find $P(2016)$ My attempt: Let $Q(x)=P(x)-2^x$. Then its zeroes are $0,1,2,\dots,2015$. Thus $Q(x)$ is a polynomial of degree $2015$ with $2016$ zeroes. Therefore it is always $0$, thus giving $P(x)=2^x$, so $P(2016)=2^{2016}$, but the answer is given as $2^{2016}-1$. Where did I go wrong and how do I get the correct answer? Please help.","['algebra-precalculus', 'contest-math']"
2841994,Prove that $b^3 \log(b) - a^3\log(a) \le 4e^2(b-a)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I have no idea where to start here and I am not even sure what topic this actually is a part of. Any help would be great. Prove that for all $a,b \in [1,e]$ we have: $$b^3 \log(b) - a^3\log(a) \le 4e^2(b-a)$$ Thanks in advance","['real-analysis', 'inequality', 'calculus', 'functions']"
2842022,"Prove that $Tf(x)=\int^{1-x}_0 f(t) \, dt$ is compact and compute its spectrum.","Prove that $T:C^0([0,1])\longrightarrow C^0([0,1])$ defined as $$Tf(x)=\int^{1-x}_0 f(t) \, dt$$ is compact and compute its spectrum. - Compactness : Let $f_n$ be a bounded sequence, that is $\|f_n\|_\infty\leq C\,\,\forall\,n$. In order to prove that $Tf_n$ has a convergent subsequence we show that it is bounded and equicontinuous. It is easy to see that $T$ is continuous, then $Tf_n$ is bounded. Let $\varepsilon >0$ and $x_1, \,x_2 \in [0,\,1]$, then
$$|Tf_n(x_1)-Tf_n(x_2)|\leq \|f\|_\infty | x_1-x_2| \leq C | x_1-x_2|.$$
If we choose $\delta=\varepsilon/C$ and $| x_1-x_2| < \delta$ then
$$|Tf_n(x_1)-Tf_n(x_2)|< \varepsilon, \quad \forall \, n.$$ - Spectrum : Since $T$ is compact it is not invertible. Then $0\in \sigma (T)$. Now I have some questions : I know that for compact operators between Hilbert spaces if $\lambda\in \sigma(T),\,\lambda\neq0$ then $\lambda\in \sigma_p(T)$ and $\sigma_p(T)$ is finite or countable and $0$ is the only accumulation point of $\sigma_p(T)$. The proof that I have seen of this fact is based on the Fredholm Alternative Theorem (that I only know for Hilbert spaces). So I wonder if this property is still true if the operater is defined on a Banach space . If it is true then the exercise is more simple. I tried to compute $\sigma_p$ but I had some problem. Here some attempts.
We are interested in solve $$ Tf(x)=\int^{1-x}_0 f(t) \, dt=\lambda f(x) $$
Since $f\in C^0$ we have $Tf\in C^1$ and $\lambda f\in C^1$ then,
$$ -f(1-x)=\lambda f'(x) $$ And now ? It is not possible to solve by separation of variable. How to proceed? Thanks. UPDATE : I have consulted Conway's book A Course in Functional Analysis and I have verified that the properties of the spectrum of a compact operator that I mentioned above are also valid in the case of Banach spaces (Theorem 7.1). Therefore it is sufficient to compute $\sigma_p(T)$ and understand if $\,0\in \sigma_c(T)\, $ or $\,0\in \sigma_r(T)$ or $\,0\in \sigma_p(T)$.","['functional-analysis', 'compact-operators', 'spectral-theory']"
2842037,"Evaluating $y(1)$ in the initial value problem $\dot y = ty + \sin y , y(0)=10^{-2}$","For the following initial value problem:
$$
\left\{ 
\begin{array}{}
\dot y=ty+\sin y \\ 
y(0)=10^{-2} 
\end{array}
\right. 
$$ I need to evaluate $y(1)$. I thought about using the fact that $\dot y \leq ty+1$, and solve $\dot z=tz+1$, but I couldn't solve that. I was also given a hint to use the Integral form of the equation, that is $y=10^{-2}+\int_0^t(sy+\sin y)ds$, but I can't think of a way to use that.","['inequality', 'ordinary-differential-equations', 'initial-value-problems']"
2842055,What is the average product of the numbers drawn?,"There are 10 tickets in a box, each with a number on it. The average of those 10 numbers is zero. The average value of the squares of those numbers is 5. (a). If you pick two tickets at random, WITH replacement, what is the average product of the numbers drawn? (b). If you pick two tickets at random, WITHOUT replacement, what is the average product of the numbers drawn?","['probability', 'average']"
2842077,Derivative of the trace of a product,"I would like to compute the following. How can I do this? $$\frac{\partial }{\partial X}\text{Tr} \big( X \log X \big)$$ Or, more generally, how to compute derivatives of the following form? $$\frac{\partial }{\partial X}\text{Tr} \big( f(X) g(X) \big)$$ Many thanks!","['matrices', 'matrix-calculus', 'derivatives']"
2842118,Evaluate $\int_0^\pi \sin^4\left(x+\sin (3x)\right)~dx$,Evaluate the integral $\displaystyle\int_0^\pi \sin^4\left(x+\sin 3x\right)dx$ My work: Let $I=\int_0^\pi \sin^4\left(x+\sin 3x\right)dx$ $=\int_0^\pi \frac18\left(\cos (4x+4\sin 3x)-4\cos(2x+2\sin 3x)+3\right)dx$ $=\frac{3\pi}{8}+\frac18\int_0^\pi\cos (4x+4\sin 3x)dx-\frac12\int_0^\pi\cos (2x+2\sin 3x)dx$,"['integration', 'definite-integrals', 'calculus']"
2842126,Burnside's transfer theorem in group theory,"While reading this I read the following (slightly rephrased, and edited according to comments) : ""Burnside's transfer theorem : If a $p$ -Sylow subgroup $P$ of a finite group $G$ is included in its normalizer's center, i.e. $P \leq Z(N_G(P))$ , then there is a normal subgroup $N$ of order $|G|/|P|$ such that $P \cap N = 1$ , and $G = N  \rtimes P$ "" What is the proof and/or applications (within pure math) of the above theorem other than classification of group of order 30? You are welcome to just provide a link. I wasn't able to find one online.","['finite-groups', 'abstract-algebra', 'group-theory', 'sylow-theory']"
2842137,Convergence sum of normal distributed random variables,"Let $X_1, X_2,\dots$ be independent standard normal distributed random variables and $S_n=X_1+X_2+\dots+X_n$. For $a,b \in \mathbb{R}$ define
  $$ Y_n=e^{aS_n-bn}.$$ Show that $Y_n\xrightarrow{a.s.}0$ iff $b>0$. Show that $Y_n\xrightarrow{\mathcal{L}^p}0$ iff $b>\frac{a²p}{2}$. I'm in need for some help on this exercise, I tried an approach with the Borel-Contelli-Lemma for the first task, but I am not sure if that's the right way to do it. Thanks in advance!","['probability-theory', 'convergence-divergence', 'normal-distribution']"
2842183,"There are $2n+1$ people. For each $n$ people there is somebody who is friend with each of them. Prove there is a ""know-them-all"" person.","I have a following problem. There are $2n+1$ people in the room. For any group of $n$ people there is a person (different from them) who is friends with each person in this group. Prove that there is a person, who knows all $2n$ other people. One can easily see, that $\min_v \deg v = n$. From this we can get a lower bound for number of edges $N_e$:
$$
N_e = \frac{1}{2}\sum_v \deg v \geq \frac{(2n+1) \cdot n}{2}
$$
I do not know where to move from this point (and do not think, that this is the right direction) and pretty stuck right now. Can you give a hint?","['combinatorics', 'graph-theory', 'contest-math', 'discrete-mathematics']"
2842188,Finding integral $\int_{0}^{\infty} \frac{x^{\alpha}\log{x}}{1-x^2}dx$ using complex analysis - residues,"The problem I want to solve is: Evaluate $$\int_{0}^{\infty} \frac{x^{\alpha}\log{x}}{1-x^2}dx,$$ where $0<\alpha<1$ using complex analysis. I've learned several types of integrals involving $x^{\alpha}R(x)$ and $\log{x}R(x)$ , where $R$ is a rational function. Also, I know how to solve certain integrals of the type $\int x^{\alpha}\log^{p}{x}R(x)dx$ , using a method which is based on finding $\int x^{\alpha}R(x)dx$ , and then differentiating with respect to $\alpha$ . However, I can't use this method here, because $$\int_{0}^{\infty} \frac{x^{\alpha}}{1-x^2}dx$$ doesn't converge! I tried the following method: denote $f(z) = \frac{z^{\alpha}\log{z}}{1-z^2}$ , and integrate $f(z)$ on the contour in the picture: Integrating $f$ over this contour, denote its boundary by $\partial D$ , I get: $$\int_{\partial D} f(z)dz = \int_{C_{R}} f(z)dz + (\int_{R}^{1+r} + \int_{1-r}^{\varepsilon}) \frac{e^{2\pi i \alpha}x^{\alpha}(\log{x}+2\pi i)}{1-x^2}dx + \int_{C_{r}} f(z)dz + \int_{C_{\varepsilon}} f(z)dz + (\int_{1+r}^{R} + \int_{\varepsilon}^{1-r}) \frac{x^{\alpha}\log{x}}{1-x^2}dx.$$ Here, $C_{R}$ is the large circle (minus a tiny part) in the picture, $C_{\varepsilon}$ is the tiny circle around $0$ , and $C_{r}$ is the tiny circle around $1$ (minus tiny parts for both $C_{\varepsilon}$ and $C_{r}$ ). By Jordan's lemmas, the integral around $C_{R}$ goes to $0$ as $R \to +\infty$ , as well as the integral around $C_{\varepsilon}$ , while the integral around $C_{r}$ goes to $\pi^{2}e^{2 \pi i \alpha}$ as $r \to 0$ . The $+2\pi i$ in the second integral is due to the branch of the logarithm, and the $e^{2 \pi i \alpha}$ is due to the branch of $z^{\alpha}$ . Finally, I get: $$ \int_{\partial D} f(z)dz = \int_{0}^{\infty} \frac{x^{\alpha}[(1-e^{2 \pi i \alpha})\log{x} - e^{2 \pi i \alpha}2 \pi i ]}{1-x^2}dx + \pi^{2}e^{2 \pi i \alpha}.$$ However, again, this integral does not converge. Is there a way to repair this argument, or modify it a little bit, to get the solution? EDIT: I forgot about the argument in the branch of $z^{\alpha}$ , and due to that branch there's no need for $\log^{2}{z}$ in $f$ , but I still can't use this method to find the integral for the same reason.","['complex-analysis', 'improper-integrals', 'integration']"
2842194,integral $\int_{0}^{1}\left( \left\lfloor{\frac{2}{x}} \right\rfloor-2 \left\lfloor{\frac{1}{x}} \right\rfloor \right)dx$,"Evaluate $$\int_{0}^{1}\left( \left\lfloor{\frac{2}{x}} \right\rfloor-2 \left\lfloor{\frac{1}{x}} \right\rfloor \right)dx$$ My Attempt $$I_{1}=\int_{0}^{1}\left\lfloor{\frac{2}{x}} \right\rfloor dx$$ Put $x=2t$ $$I_{1}=\int_{0}^{\frac{1}{2}}2\left\lfloor{\frac{1}{t}} \right\rfloor dt=\int_{0}^{\frac{1}{2}}2\left\lfloor{\frac{1}{x}}\right\rfloor dx$$ let $$I_{2}=\int_{0}^{1} \left\lfloor{\frac{1}{x}} \right\rfloor dx=\int_{0}^{\frac{1}{2}}\left\lfloor{\frac{1}{x}}\right\rfloor dx+\int_{\frac{1}{2}}^{1}\left\lfloor{\frac{1}{x}}\right\rfloor dx$$ Given integral 
$$
\begin{align}
\int_{0}^{1}\left(\left\lfloor{\frac{2}{x}}\right\rfloor-2\left\lfloor{\frac{1}{x}}\right\rfloor \right)dx&=I_{1}-2I_{2}\\
&=2\int_{0}^{\frac{1}{2}}\left\lfloor{\frac{1}{x}}\right\rfloor dx-2\int_{0}^{\frac{1}{2}}\left\lfloor{\frac{1}{x}}\right\rfloor dx-2\int_{\frac{1}{2}}^{1}\left\lfloor{\frac{1}{x}}\right\rfloor dx\\
&=-2\int_{\frac{1}{2}}^{1}\left\lfloor{\frac{1}{x}}\right\rfloor dx\\
&=(-2)(1)=-2.
\end{align}
$$ But answer given is $\ln(\frac{4}{e})$ What mistake am I making?","['real-analysis', 'definite-integrals']"
2842225,An identity on Rencontres numbers,Let there be $n$ people with seats marked $1$ to $n$. Let $p_k$ be the number of arrangements such that exactly $k$ persons go to their designated seat (the $i$ th person is designated seat number $i$) and the remaining do not. Show that $$\sum_{k = 0}^n k*p_k = n!$$,"['combinatorics', 'contest-math', 'discrete-mathematics']"
2842316,Algebraic topology on locales,"My question is essentially in the title: is there a well-developped theory of algebraic pointless topology, that is algebraic topology on locales ? If not, would it make sense, i.e. would it be relevant (for instance the usual fundamental group construction makes no sense for spaces like the spectrum of a ring, because such spaces are usually totally disconnected or at least, really not connected; so one may wonder -if one does not know much about locales, as I do- whether it would be relevant to study algebraic topology on locales) ? Added later : In particular (although more general information is also welcome, as in Hurkyl's answer) I would specifically like to know if there is a way of making sense of a ""fundamental groupoid"" of a locale (which would be defined differently from usual spaces, otherwise pointless locales would have an empty fundamental groupoid) that would be interesting ?","['algebraic-topology', 'general-topology', 'locales']"
2842403,Spaces That Have Uncountably Many Disjoint Copies in $\mathbb{R}^2$,"There is a theorem by Moore that says there are not uncountably many disjoint copies of the simple triod in the plane (the simple triod is the space by adjoining one end point from three copies of $[0,1]$ together to make a three-pointed asterisk).  I am wondering what other compact, connected spaces also satisfy this. More specifically, for any compact subset of the plane there always exist countably many disjoint copies (easy to see taking disjoint discs and the fact that they are homeomorphic to the plane), but which ones don't have uncountable such collections?  Of course any space must be one-dimensional, except the example of a singleton, and none can contain a simple triod. For locally connected, compact, connected subsets of the plane, if they are not an arc or a circle then they contain a simple triod, by some standard theorems (they are locally path-connected), so examples need to be a bit gross.  Just by intuition it seems like the sin$(\frac{1}{x})$ continuum (closed topologist's sine curve) does not work, maybe because it has some similarity to a triod. There are some results using the concepts of span, but I am wondering if there are any other sort of . . . sporadic examples that are easy to see naturally.","['general-topology', 'plane-curves', 'continuum-theory']"
2842409,Fermat Point of a Tetrahedron,"Here's a curious set of vertices for a tetrahedron: 
{{-22, -25, 4}, {-12, 15, -6}, {8, 5, -6}, {18, -15, 24}} The Fermat point of a tetrahedron minimizes the total distances from the point to the vertices . There is a general method for finding the Fermat point of polygons using the Weiszfeld algorithm. The six edge lengths of this tetrahedron are different.  The Fermat point is at the origin. Find a second tetrahedron with six different edge lengths, integer coordinates away from the origin, and a Fermat point at the origin. The second tetrahedron should not be a variation of the first tetrahedron. For thousands of other differently-edged integer-vertex tetrahedra I've looked at, the Fermat point requires the algebraic roots of three sextic to octic polynomials.  And then there's this one integer solution. For a triangle, the projection of the vertices onto a circle centered on the Fermat point splits the circle into 3 equal arcs. For a tetrahedron, a projection of the vertices onto a sphere centered on the Fermat point splits the sphere into 4 equal spherical triangles. (Is this known?) Incenter - tiny sphere near Fermat Centroid - green {-2, -5, 4} Circumcenter - cyan {-(33/4), -(5/2), 71/4} Twelve point - yellow {1/12, -(35/6), -(7/12)} Symmedian - pink {42/89, 315/89, -(144/89)} Fermat - red {0,0,0} Monge - magenta {17/4, -(15/2), -(39/4)} This diagram made with code from Tetrahedron Centers","['3d', 'triangles', 'projective-geometry', 'geometry']"
2842470,Characteristic classes of spinor bundle,"Given a spin structure on a oriented Riemannian manifold $(M,g)$, a spinor is a section of the spinor bundle $\pi:\mathbf{S}\to M$. I am trying to calculate the characteristic classes of the spinor bundle, in particular when $M$ is a 4-manifold. In this case, the Dold-Whitney theorem says that bundles over $M^4$ are classified topologically by the second Stiefel-Whitney class and the first Pontryagin class. Note that the space of metrics on $M$ is convex (and hence contractible), so all spinor bundles on $M$ are isomorphic. I am particularly interested in the cases of $S^4$ and a K3 surface. $S^4$ has no second cohomology, so the second Stiefel-Whitney class is trivial. The first Pontryagin class $p_1(\mathbf{S})\in H^4(S^4;\mathbb{Z})=\mathbb{Z}$ will correspond to some integer, but I'm not sure which one. Thanks for your help.","['algebraic-topology', 'spin-geometry', 'differential-geometry', 'differential-topology']"
2842471,"$X$ Hausdorff and Compact, $f: X \rightarrow X$ continuous. Is the set of fixed points of $f$ Compact?","I'm trying to prove the following statement: If $X$ is a Compact, Hausdorff Topological Space and $f:X\rightarrow X$ is a continuous function, then the set $F=\left\{ x \in X : f(x) = x\right\}$ of fixed points of the function
  $f$ is Compact. Yet any clues on how to even start.",['general-topology']
2842473,Finding eigenfunctions for Sturm-Liouville problems.,Many PDE textbooks contain theoretical results regarding existence of eigenvalues and eigenfunctions for Sturm-Liouville problems but I haven't seen any that actually tell how to compute either making the theory seem not very useful. I was wondering how is can you find the eigenfunctions?,"['functional-analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
2842486,If $h$ has positive derivative and $\varphi$ is continuous and positive. Where is increasing and decreasing $f$,"The problem goes specifically like this: If $h$ is differentiable and has positive derivative that pass through $(0,0),  $  and $\varphi$ is continuous and positive. If:
  $$f(x)=h\left(\int_{0}^{\frac{x^4}{4}-\frac{x^2}{2}} \varphi(t) dt\right).$$
  Find the intervals where $f$ is decreasing and increasing, maxima and minima. My try was this: The derivative of $f$ is given by the chain rule: $$f'(x)=h'\left(\int_{0}^{\frac{x^4}{4}-\frac{x^2}{2}} \varphi(t) dt\right) \varphi\left(\frac{x^4}{4}-\frac{x^2}{2}\right)$$
We need to analyze where is positive and negative. So I solved the inequalities:
$$\frac{x^4}{4}-\frac{x^2}{2}>0 \land \frac{x^4}{4}-\frac{x^2}{2}<0$$
That gives: $(-\infty, -√2) \cup (√2, \infty)$  for the first case and $(-√2,√2)$ for the second one. Then (not sure of this part) $h'\left(\int_{0}^{\frac{x^4}{4}-\frac{x^2}{2}} \varphi(t) dt\right)>0$ and $\varphi\left(\frac{x^4}{4}-\frac{x^2}{2}\right)>0$ if $x\in(-\infty, -√2) \cup (√2, \infty).$  Also if both $h'$ and $\varphi$ are negative the product is positive, that's for $x\in(-√2,√2)$. The case of the product being negative implies: $$x\in [(-\infty, -√2)\cup(√2, \infty)]\cap(-√2,√2) = [(-\infty,-√2)\cap(-√2,√2)]\cup[(√2,\infty)\cap(-√2,√2)]=\emptyset.$$
So the function is increasing in $(-\infty,-√2),(-√2,√2),(√2,\infty)$. So the function does not have maximum or minimum.
Not sure of this but what do you think?","['derivatives', 'maxima-minima', 'calculus', 'functions']"
2842496,How to think of these different $K$-points of a scheme and Galois action,"The eventual goal of this question is to better under the action of a Galois group on a scheme defined over a field $K$. Right now I just want to understand how to think about $K$-points and their Galois conjugates. The $K$ points, or generally $R$-points ($R$ a ring) of a scheme $X$ are morphisms $\text{spec}\ R \to X$, or equivalently ring morphisms $K[X] \to R$, ($K[X]=\mathcal{O}_X(X))$. Suppose moroever $X$ is finite type and affine, for simplicity. Then the usual story explaining $X(R)$ is that they are the intuitive ""$R$-valued points"" that satisfy the solutions to equations defining $X$. Recently when trying to define/understand the Galois action of schemes I realized for $K$-points of a Scheme over $K$, there are more $K$-points than I previously thought: for the simplest example, take $\mathbb{A}^1_K$: writing points as morphisms $K[x] \to K$: $$c_0+c_1x+\cdots c_mx^m \mapsto c_0+c_1 \alpha + \cdots + c_m \alpha ^m $$
$$c_0+c_1x+\cdots c_mx^m \mapsto c_0+c_1 (\sigma\alpha) + \cdots + c_m(\sigma \alpha) ^m$$ This is what I would think of is the natural meaning of a Galois action on $K$-points. However I also can think of two other maps: $$c_0+c_1x+\cdots c_mx^m \mapsto \sigma c_0+\sigma c_1 \alpha + \cdots + \sigma c_m \alpha ^m $$ $$c_0+c_1x+\cdots c_mx^m \mapsto \sigma c_0+\sigma c_1 (\sigma \alpha) + \cdots + \sigma c_m (\sigma \alpha ^m) $$ The first pair of maps is what I would naively call the $\sigma$ action on $K$-points. However, I am not sure it is the correct notion. My basic question is, which (pair) of theses maps deserves to be identified with the pair of points $(\alpha, \sigma \alpha)$. The only straightforward relation I see among these maps is that map 4 can be obtained from map $1$ by post-composing with $\sigma$. But they have the same kernels, which I don't know is relevant of not. What is the proper way to think about the relationship between these different maps? (I am aware that a bunch of these maps can be cut out by working in $\text{Sch}_{/K}$ and requiring the maps to commute with the respective structure morphisms. I hesitate to impose this because I remember reading that the Galois action on schemes over fields does not respect the structure morphism. If I am mistaken, comments correcting my thoughts in this direction would be helpful as well).","['group-actions', 'galois-theory', 'schemes', 'algebraic-geometry']"
2842499,Hypothesis Testing: One and Two-Sided Tests,"The general rule of hypotheses chosen for testing difference in means of two groups $x$ and $y$ is to choose the follwoing: $H_0: \mu_x = \mu_y$, $H_1: \mu_x \neq \mu_y$ A $t$-test is then conducted to examine whether the null hypothesis is rejected. However, what is the hypothesis testing design when instead the hypothesis is the following: $H_0: \mu_x \leq \mu_y$, $H_1: \mu_x > \mu_y$. Any standard testing procedures that somebody can point to would be helpful.","['statistics', 'probability', 'hypothesis-testing', 'statistical-inference']"
2842500,Points of a dense set are not limit points,"I'm reading Rudin's Principles of Mathematical Analysis . Here is how the book defines the dense set: $E$ is dense in $X$ if every point of $X$ is a limit point of E, or a point of $E$ (or both). To fully understand the definition, here is my question: Is there a dense set $E$, at least one point in $E$ is not a limit point? 
Furthermore, is it possible, that all points of a dense set are not limit points of $E$ ?","['general-topology', 'real-analysis', 'analysis']"
2842571,When can the moment generating function be differentiated to find moments?,"Let $X$ be a nonnegative random variable and suppose
$$\phi(t):= E[e^{tX}] $$
exists for all $t$. For simplicity, suppose $\phi$ is infinitely differentiable on the whole real line. An easy exercise, using the mean value theorem and dominated convergence theorems, is that if $E[Xe^{tX}] < \infty$ for all $t \in \mathbb{R}$, then $\phi'(t) = E[Xe^{tX}]$. Of course, then taking $t = 0$ recovers our favorite formula $\phi'(0) = E[X]$. To use the dominated convergence theorem, however, we needed to assume $E[Xe^{tX}] < \infty$, which may be hard to prove for a given random variable $X$. Are there cases where $\phi(t)$ and $\phi'(t)$ exist and are finite, but $E[Xe^{tX}] = \infty?$ My motivating question is that the Laplace transform of the hitting time $T_m = \inf(t : W_t = m)$ of standard BM $W_t$ is
$$E[e^{-\alpha T_m}] = e^{-|m|\sqrt{2\alpha}}$$
for $\alpha > 0$.To compute $E[T_m]$, one differentiates both sides to obtain
$$E[T_m e^{-\alpha T_m}] = \frac{|m|}{\sqrt{2\alpha}} e^{-|m|\sqrt{2\alpha}}$$
and uses the monotone convergence theorem to send $\alpha \downarrow 0$ and conclude. But apriori, how did we know the derivative of $E[e^{-\alpha T_m}]$ was $E[T_m e^{-\alpha T_m}]$, moreover that the latter even exists?",['probability-theory']
2842586,Why isn't the probability that Alice will have classes every weekday $\dfrac{5\times \binom{5}{2}}{30\choose 7}$? [duplicate],"This question already has an answer here : Why isn't the probability that Alice will have classes every weekday $\dfrac{6^5 \times 25 \times 24}{30\choose 7}$?? (1 answer) Closed 2 years ago . Blitzstein's Introduction to Probability (2019 2 ed) Ch 1, Exercise 54, p 51. Alice attends a small college in which each class meets only once a week. She is deciding between $30$ non-overlapping classes. There are $6$ classes to choose from for each day of the week, Monday through Friday. Trusting in the benevolence of randomness, Alice decides to register for $7$ randomly selected classes out of the $30$ , with all choices equally likely. What is the probability that she will have classes every day, Monday through Friday? $($ This problem can be done either directly using the naive definition of probability, or using inclusion-exclusion. $)$ My thinking was to first assign one class to each of the $5$ days, $6^5$ ways of doing this. Then multiply this with the probability of selecting remain $2$ classes such that $a)$ either they both are on the same day, or $b)$ on two different days. Probability for $(a)= 5\times \binom{5}{2}$ . Prob. of $(b)=\binom{5}{2}\times 5$ . This gives total no. of ways to assign classes as required. Then divide this by $\binom{30}{7}$ $($ total no of ways to assign classes randomly $)$ . But this gives a probability greater than $1$ . Where is my thinking wrong? All classes are equally likely, and I don't think the process of choosing follows order of days.",['probability']
2842674,Computing double integral using linear algebra,"$$\iint_D (6x+2y) \, \mathrm d x \,\mathrm d y$$ where $D$ is the convex hull of $4$ given points, $$D = \mbox{conv} \left\{ (0,0),(-2,6),(3,2),(1,8) \right\}$$ This is a parallelogram with ""unit vectors"" $(-2,6)$ , $(3,2)$ . I wanted to give a try to solve the following problem with algebra instead of calculus. So, I thought about calculating the area of it and piling it up to get its volume. I got the cosine between both vectors with the dot product formula, which is $$\dfrac{6}{\sqrt{13\cdot40}}$$ and the sine with the Pythagoras identity which is $$\sqrt{\dfrac{484}{13\cdot40}}$$ I remember that $|a|\cdot |b|\cdot \sin\alpha$ gives the height, and $|a|\cdot |b|\cdot \cos\alpha$ gives the area. So I figured that maybe this would solve the integral problem for the area? $$\dfrac{6}{\sqrt{13\cdot40}} \cdot \sqrt{13} \cdot \sqrt{40}\sqrt{\dfrac{484}{{13\cdot40}}}\cdot \sqrt{13} \cdot \sqrt{40}$$ That gives me $$6 \cdot 22 = 132$$ That's wrong but the right result is $$11 \cdot 22 = 242$$ so there might be something in that?","['multivariable-calculus', 'integration', 'definite-integrals', 'linear-algebra']"
2842677,$q$-series and modular forms,"Is there a way/database such that given a modular form $$f(q) = \sum_{n}a_nq^n$$ with $q=\exp(2\pi i \tau)$, $\tau = \{ z \in \mathbb{C} | \Im(z)>0 \}$ the upper half plane, to find if it can be written in terms of some standard modular forms like the Dedekind eta function or the Jacobi-theta functions or the Eisenstein series? Or, is there some way/algorithm/database etc such that if I feed it with a $q$ expansion it can give me which combination of ""standard"" modular forms give the same expansion ?","['number-theory', 'modular-forms', 'reference-works']"
2842715,Groups satisfying the normalizer condition are nilpotent (without using Sylow theory),"Recall that a group $G$ satisfies the normalizer condition if for any proper subgroup $H$, its normalizer in $G$, $N_G(H)$ is a strictly larger group. For finite groups, this property is equivalent to $G$ being nilpotent (that is, its lower central series terminates at the trivial group). The proof I know/found is by using yet another criteria for nilpotency: all Sylow subgroups are normal. However, is there a proof that avoids mention of Sylow subgroups? I ask because both the condition of being nilpotent and having the normalizer condition are quite elementary and make no reference to Sylow subgroups. Edit: I can at least show that the derived subgroup is a proper subgroup: Let $M$ be a maximal subgroup of $G$, they exist by finiteness. The normalizer of $M$ properly contains $M$ and hence it is $G$, hence $M$ is normal in $G$. Moreover, $G/M$ has no subgroups and hence is prime cyclic. Now consider [G,G]. We will show that this is contained in $M$. This follows easily since [G/M,G/M] = [G,G]/M but $[G/M,G/M]$ is trivial since $G/M$ is abelian.","['finite-groups', 'group-theory']"
2842731,Find $(f^{-1})'(3)$,"Let $f:\mathbb{R}\to\mathbb{R}\space \space \space f(x)=\left\{\begin{array}{lc}x^2-2x,&x\leq0\\-x^2-2x,&x>0\end{array}\right.$. Find $(f^{-1})'(3)$. My attempt: First, it's easy to see that $f(x)$ is injective $\forall x \in \mathbb{R}.$ By doing the first derivative table we see that $Im_f=\mathbb{R}.$ so then $f$ is surjective and then $f$ is bijective and it has an inverse function. $$f^{-1}(f(x))=x$$ differentiating both sides we get that $(f^{-1}(f(x)))'=\frac 1{f'(x)}$. $f(x)=3\implies x = -1$ unique solution so then $\boxed{(f^{-1})'(3)=\frac 1{f'(x)}=-\frac 14}$ Second solution: (which i don't really understand what happens here) I want to define $f^{-1}(x).$ First case ($x\leq0):$ $\implies f(x)=x^2-2x \space \space \space \forall x\leq0.$ $$f^{-1}(x)=\pm\sqrt{x+1}+1 \space\space\space \forall x\geq -1.$$ so then: $f^{-1}(x)=\pm\sqrt{x+1}+1 \space \space \space \forall \space x\in[-1,0]?$ Also when do we use the $+$ sign and the $-$ for the square root? Second case ($x>0$): $\implies f(x)=-(x+1)^2+1\implies f^{-1}(x)=\pm\sqrt{1-x}-1 \space \space \space \forall x\in(0,1]?$ same question about the sign of the square root. so then we get $$\boxed{f^{-1}(x)=\left\{\begin{array}{lc}\pm\sqrt{x+1}+1,&x\in\lbrack-1,0\rbrack\\\pm\sqrt{1-x}-1,&x\in(0,1\rbrack\end{array}\right.}$$ But by differentiating is we can't find $(f^{-1})'(3)$. But $f^{-1}(x)$ should be defined on all $\mathbb{R}$.. So... What I am doing wrong? What is really happening here? Also when I try to graph them: We can see that $f^{-1}(x)$ takes values only in $[-1,1]$.","['derivatives', 'real-analysis', 'inverse-function', 'calculus', 'inverse']"
2842801,integration by parts of trig function,"I tried to solve the integral below using integration by parts
$$\int_0^t\cos(x)\cos(t-x)dx=\frac{1}{2}(\sin(t)+t\cos(t))$$ It seemed solvable through doing integration by parts twice,
but it hasn't worked for me yet...
tcos(t) doesn't come up! I know how it can be solved using properties of trig function, why can't it be solved by integration by parts?","['integration', 'trigonometric-integrals']"
2842830,Why does the Eigen decomposition of the covariance matrix of a point cloud give its orientation?,"I am working with point clouds and one of the problems I had to face was to find the orientation of a given cluster. Most algorithms I have found suggest that one must first calculate the centroid of the cloud and, using that, to compute the covariance matrix. Performing the Eigen decomposition on the co-variance matrix gives us three vectors that correspond to each of the three axis that give the orientation of the object. I have successfully implemented the algorithm, but I wish to know how and why this works specifically.","['eigenvalues-eigenvectors', 'point-cloud', 'covariance', 'geometry']"
2842883,"If $T$ has continuous spectrum and $(f, 1)=0$ then $\mu_{f}$ has no atoms.","I'm reading Peter Walters' An Introduction to Ergodic Theory , and I don't understand his remark. Following is a sort of lemma, called Spectral Theorem for Unitary Operators , to prove the equivalence of weak-mixing and having continuous spectrum: Theorem 1.25 (Spectral Theorem for Unitary Operators) in above book Suppose $U$ is a unitary operator on a complex Hilbert space $\mathcal{H}$ . Then for each $f \in \mathcal{H}$ there exists a unique finite Borel measure $\mu_{f}$ on $K = \{ z \in \mathbb{C} \ : \ |z| = 1\}$ such that $$(U^{n}f, f) = \int _{K} \lambda ^{n} d\mu_{f}(\lambda) \ \ \ \ \ \ \ \forall n \in \mathbb{Z}.$$ Then he remark that: If $T$ is an invertible measure-preserving transformation then $U_{T}$ is unitary, and if $T$ has continuous spectrum and $(f, 1) = 0$ then $\mu_{f}$ has no atoms. This is what I don't understand. How can we show that under such conditions, $\mu_{f}$ has no atoms? I found a related reference , and here Theorem 1.4 is related to what I want to know. And he left my question as an easy(?) exercise. Can somebody help me please?","['hilbert-spaces', 'operator-theory', 'ergodic-theory', 'measure-theory', 'spectral-theory']"
2842895,Trigonometric sign function,"I am positive that this definition:
$$
\text{sgn}(x) = \frac{\text{arccot}(x) - \text{arccot}(-x)}{2|\text{arccot}(x)|}
$$ Is correct, but wolframalpha says it's not. I suspect it's because it assumes $\text{arccot}(-x) = -\text{arccot}(x)$ for all $x$, but $\text{arccot}(0) = \text{arccot}(-0) \neq 0$, right? I sent them feedback about this already. Meanwhile, here is my proof: Let $x < 0$. Then:
$$
\begin{align*}
\text{sgn}(x) &= \frac{\text{arccot}(x) - \text{arccot}(-x)}{2|\text{arccot}(x)|}\\[1em]
&= \frac{\text{arccot}(-|x|) - \text{arccot}(|x|)}{2|\text{arccot}(-|x|)|}\\[1em]
&= \frac{-\text{arccot}(|x|) - \text{arccot}(|x|)}{2|-\text{arccot}(|x|)|}\\[1em]
&= \frac{-2\text{arccot}(|x|)}{2\text{arccot}(|x|)}\\[1em]
&= -1\\[1em]
\end{align*}
$$ Let $x > 0$. Then:
$$
\begin{align*}
\text{sgn}(x) &= \frac{\text{arccot}(x) - \text{arccot}(-x)}{2|\text{arccot}(x)|}\\[1em]
&= \frac{\text{arccot}(|x|) - \text{arccot}(-|x|)}{2|\text{arccot}(|x|)|}\\[1em]
&= \frac{\text{arccot}(|x|) + \text{arccot}(|x|)}{2\text{arccot}(|x|)}\\[1em]
&= \frac{2\text{arccot}(|x|)}{2\text{arccot}(|x|)}\\[1em]
&= 1\\[1em]
\end{align*}
$$ Finally, let $x = 0$. Then:
$$
\begin{align*}
\text{sgn}(x) &= \frac{\text{arccot}(x) - \text{arccot}(-x)}{2|\text{arccot}(x)|}\\[1em]
&= \frac{\text{arccot}(|x|) - \text{arccot}(|x|)}{2|\text{arccot}(x)|}\\[1em]
&= \frac{0}{2|\text{arccot}(x)|}\\[1em]
&= 0\\[1em]
\end{align*}
$$ Does this check out? EDIT: $\text{arccot}$ not $\arccos$, dangit. EDIT 2: This is best I could do when $\text{arccot}(x) = \frac{\pi}{2} - \arctan(x)$: $$
\begin{align*}
\text{sgn}(x) &= \lim_{p\to +\infty}\Bigg[{\frac{\text{arccot}(-px) - \text{arccot}(px)}{2\text{arccot}(p|x|) + \pi}}\Bigg]
\end{align*}
$$ With the bonus that we get a smooth approximation for $p>0$, e.g. graph for p=5000. Apparently that's a sigmoid function. Maybe I will ask another question about it!",['trigonometry']
2842897,Calculus tangent line,"For some constant c, the line $y=4x+c$ is tangent to the graph of $f(x)=x^2+2$, what is the value of $c$? I don’t understand how to find the value of c. Because it’s a tangent line I understand they touch at one point. Probably a dumb question, I just don’t understand.","['algebra-precalculus', 'calculus', 'quadratics']"
2842976,When is the exponential map between matrices injective? [duplicate],"This question already has an answer here : Is $\exp:\overline{\mathbb{M}}_n\to\mathbb{M}_n$ injective? (1 answer) Closed 4 years ago . Consider a complex matrix $A$. When does $e^A=e^B$ imply $A=B$? Is there any general statement that can be made as to when this holds? It is clearly not true in general, a trivial example being when $A$ and $B$ are diagonal in the same basis but with eigenvalues differing by $2\pi i\mathbb Z$. This is also mentioned in this question . This answer also seems to provide an answer to this question, but I'm not familiar with the theory of Lie algebras so I'm not sure, and I wouldn't know how to translate it into more elementary statements about matrices (if that is even possible).","['matrices', 'matrix-exponential', 'exponential-function', 'linear-algebra']"
2842982,Prove that Lebesgue integral of a progressive process is also progressive,"Suppose we have a probability space $(\Omega, \mathscr{F}, P)$ along with a filtration $\{\mathscr{F}_t\}_{t\in [0,1]}$. Let $f:[0,1] \times \Omega \to \mathbb{R}^d$ be a progressive and square integrable process on $[0,1] \times \Omega$. i.e. for every $t \in [0,1]$ the mapping $f(s,w)| _{ [0,1] \times \Omega }$ is $\mathscr{B}([0,t]) \otimes \mathscr{F}_t$ measurable and $\int \limits_\Omega \int \limits_0^1 f(s,\omega)^2 \mathop{ds} \mathop{dP} =E\bigg(  \int \limits_0^1 f(s,\omega)^2 \mathop{ds} \bigg) < \infty $. I would like to justify that the process $g:[0,1] \times \Omega \to \mathbb{R}^d$ given by 
$$g(t,\omega) := \int\limits_0^t f(s, \omega) \mathop{ds}$$ 
is also a progressive process with respect to the same filtration. This is what I have so far: Firstly I abuse notation by writing $f:= f|_{ [0,t] \times \Omega }$ (doesn't effect the definition of $g(t,\omega)$).
Clearly this new $f$ is progressive and square integrable on $[0,t] \times \Omega$. All progressive processes are adapted, so just as in the construction of the Ito integral we may approximate $f$ with elementary functions $$\phi_n(s,\omega)= \sum \limits_{i=0}^{n-1} \xi_i(\omega) \chi_{[t_i,t_{i+1})}, \text{ such that } \lim \limits_{n\to \infty} E \bigg( \int \limits_0^1 (\phi_n(s,\omega)-f(s,\omega))^2 \mathop{ds} \bigg) =0.$$ We can interpret this as a limit in the $L^2$ sense on the product space.
$L^p$ convergence implies convergence in measure, which in turn implies there is a subsequence $\phi_{n_k}$ that converges pointwise a.e. to $f$ on $[0,t] \times \Omega$. Define $$\eta_k (\omega):= \int \limits_0^t \phi_{n_k} (s,\omega) = \sum_i \xi_i(\omega) \Delta t_i $$
which is clearly $\mathscr{F}_t$ measurable by the definition of elementary functions. I claim that $ \eta_k \to  \int\limits_0^t f(s, \omega) \mathop{ds}=g(t,\cdot)$ pointwise a.e. on $\Omega$. If this holds then $g(t,\cdot)$ will be $\mathscr{F}_t$ measurable, and so the process $g(t, \omega)$ is adapted to the filtration.
It is not difficult to show that $g(t,\omega)$ has continuous paths, so it is trivially RCLL.
Adapted and RCLL implies Progressive, and then we would be done. This issue that I'm having is with verifying the claim. I would like to use one of the convergence theorems to bring the limit inside the integral, but I don't see how to do this given I know very little about the $\phi_{n_k}$'s. Any help would be greatly appreciated.","['stochastic-processes', 'probability-theory', 'stochastic-calculus', 'measure-theory']"
2843014,How to define an Artificial Neural Network as a function,"I want to define feed-forward ANN as a function in a clean mathematical way and as accurately as possible. I can do something if I fix the number of layers, but I would like to generalize it for any number of layers (possibly without using ""$\dots$""). Here is roughly what I have done: Let $F$ be the ANN, $x \in R^{input}$ be the its input and $F(x) = y \in R^{output}$ its output. 
Let $f_i: R^{m_i} \rightarrow R^{m_i}$ be a generic activation function applied to the dot product between the weight matrix $W_i$ of layer $i$ and the layer input. $m_i$ is the number of outputs of layer $i$ $$ F: R^{input} \rightarrow R^{output} \\
F(x) = f_3(W_3 \cdot f_2(W_2 \cdot f_1(W_1 \cdot x)))$$ Can you find a better way?",['functions']
2843039,Relation between lie derivative of a vector field and associated 1-form in a Lorentzian manifold,"Let $(M,g)$ be a Lorentzian manifold and $X$ and $u$ represent two vector fields in $M$ such that $\mathcal{L}_X u=0$, that is, $u$ is Lie transported along the integral curve of $X$. My question is: given the associated 1-form to $u$, $u^\flat$, is $\mathcal{L}_X u^\flat=0$? I would say yes, but my common sense may be tricking me and I don't really know how to prove such a thing. Edit: Following Jackozee Hakkiuz suggestion I tried using the Leibniz rule such that
$$
X<u^\flat,u> ~=~ <\mathcal{L}_X u^\flat,u> + <u^\flat,\mathcal{L}_X u> ~ =~ <\mathcal{L}_X u^\flat,u>~.
$$
But I'm stuck. I tried playing around with the expressions of the above quantities in a local coordinate system but I can't seem to find a relation that answers my question...","['semi-riemannian-geometry', 'smooth-manifolds', 'differential-geometry', 'lie-derivative']"
2843096,Points of elliptic curves over different fields,"Let $f : E \to E'$ be an isogeny between elliptic curves (or abelian varieties), defined over a field $k$. Let $X$ be the kernel of $f$.
Let $L \supset k$ be an algebraically closed field. Is it true that the natural map $X(\bar k) \to X(L)$ is a group isomorphism? When $E' = E$ is any abelian variety and $f$ is the multiplication by an integer $m$ distinct from the characteristic of $k$, then $X(\bar k) \cong (\Bbb Z/m)^{2 dim(E)} \to X(L) \cong (\Bbb Z/m)^{2 dim(E)}$ is injective hence an isomorphism, because of cardinality. But what about more general cases?","['abelian-varieties', 'algebraic-geometry', 'extension-field', 'elliptic-curves', 'algebraic-groups']"
2843109,Motivation of Adjoints and Normal Operators,"What is the motivation of adjoints and normal operators. By ""motivation,"" I mean an example, such as a proof, where it is natural to use them.","['operator-theory', 'functional-analysis', 'spectral-theory', 'linear-algebra', 'analysis']"
2843120,Find $\lim_{n \to \infty}f_n(x)$,Find $$\lim_{n \to \infty}f_n(x)$$ where $$f_n(x)=n^2x(1-x)^n$$ $0 \lt x \lt 1$ My try: By symmetry $$\lim_{n \to \infty}f_n(x)=\lim_{n \to \infty}f_n(1-x)=\lim_{n \to \infty}n^2(1-x)x^n=(1-x)\lim_{n \to \infty}n^2 x^n$$ Now $$\lim_{n \to \infty}n^2 x^n=\lim_{n \to \infty}\frac{x^n}{\frac{1}{n^2}}$$ Now can we use L'hopital's rule here?,"['algebra-precalculus', 'polynomials', 'sequences-and-series', 'limits']"
2843133,Differentiating under expectation operator,"This is a follow-up on differentiating the mgf to find moments . Let $g(t,x)$ be a smooth function and $X$ be a random variable. Set $f(t) = E[g(t,X)]$. If $g_t(t,X)$ is dominated by an $L^1$ random variable, then one can show $f$ is differentiable. Is there an example of a random variable $X$ and smooth $g(t,x)$ such that $f(t) = E[g(t,X)]$ is finite and smooth for all $t$ but $E[g_t(t,X)] = \infty$?","['probability-theory', 'measure-theory']"
2843135,How can I evaluate the below mentioned series without using a computation software?,"I have been trying to evaluate $\displaystyle\sum_{m=0}^{2^{2^5}-1}\frac{2}{\prod_{n=1}^5\bigl((m+2)^{\frac{2}{n}}+(m)^{\frac{2}{n}}\bigr)}$ for quite a long time. I tried various approaches but failed. 
I'll be grateful if someone can help me out.","['products', 'summation', 'sequences-and-series']"
2843140,Convergence of series of remainders,"I have the series $\sum a_n$ where $$a_n = \begin{cases} \frac{1}{n}, &\text{$n$ is a perfect square} \\ \frac{1}{n^2}, &\text{otherwise}\end{cases}$$ Prove that $\sum_{n=1}^\infty R_n$ converges where remainder $R_n = \sum_{i=n}^\infty a_i$. My work: I can show that the series $\sum a_n$ converges because $$\sum_{n=1}^Na_n = \sum_{n \neq k^2} \frac{1}{n^2} + \sum_{n = k^2, 1 \leq k^2 \leq N} \frac{1}{k^2} \leq 2 \sum_{n=1}^N \frac{1}{n^2}$$ and this means the remainders converge to $0$, $\lim_{n\to \infty}R_n = 0$. Hence, I can't rule out convergence of $\sum R_n$ by the term divergence test.  But I can't find a comparison to prove it converges.","['sequences-and-series', 'convergence-divergence', 'limits']"
2843147,Property of Entire Functions,Suppose $f$ and $g$ are entire functions with $|f(z)|\leq|g(z)|$ for all $z$. How can we show that $f=cg$ for some complex constant $c$? Thanks for any help :),['complex-analysis']
2843167,"Integral $\int_0^{\frac{\pi}{2}} x^2 \sqrt{\sin x} \, dx$","Greetings I am trying to find a closed form for:  $$I=\int_0^{\frac{\pi}{2}} x^2 \sqrt{\sin x}\,dx$$ If we rewrite the integral as $$I=\int_0^\infty x^2 \sqrt{\frac{1}{\sqrt{1+\cot^2 x}}}\,dx$$ now with $$\cot x =t $$ $$I=\int_0^{\infty} \operatorname{arccot}^2 (x)(1+x^2)^{-\frac{5}{4}}dx$$ and with https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Logarithmic_forms $$I=\frac{1}{4i}\int_0^{\infty}\log^2\left(\frac{z-i}{z+i}\right)(1+x^2)^{-\frac{5}{4}} \, dx$$ Now for the $\log$ I thought to expand into power series but since the radius of converge is abit smaller, this fails. Also integrating by parts or combining the initial integral with $\int_0^{\frac{\pi}{2}} x^2 \sqrt{\cos x}\,dx$ wasn't much of a help, could you help me evaluate this integral ?","['integration', 'closed-form']"
2843171,"Triples $(x, y, z)$ that satisfy a set of equations","Suppose that $a$ is a  fixed (but unknown) real number, with $a^2 \neq 1$ .  Determine all triples $(x, y, z)$ of real numbers that satisfy the system of equations: $x + y + z = a$ $xy + yz + xz = -1$ $xyz = -a$ I've tried making substitutions but don't seem to be able to make much progress. Another thing I noticed is that: $(x + y + z) = a \implies$ $(x + y + z)^2 = a^2 \implies$ $x^2 + y^2 + z^2 + 2(xy + yx + xz) = a^2 \implies$ $x^2 + y^2 + z^2 + 2(-1) = a^2 \implies$ $x^2 + y^2 + z^2 = a^2 + 2$ but I don't know if that actually is useful. Any suggestions on how to move forward?","['algebra-precalculus', 'polynomials', 'systems-of-equations']"
2843175,Concyclic points in $\mathbb{Z}^2$,"So I just came up with this question that I thought would be interesting to share: Consider $\mathbb{Z}^2$ as a subset of $\mathbb{R}^2$ and for a circumference $C$ in $\mathbb{R}^2$ , let $f(C)=|C\cap\mathbb{Z}^2|$ , i.e. the number of points of the lattice that lie on the circumference. Find the minimum $k\in\mathbb{N}$ such that $f(C)\neq k$ for all circumference $C\in\mathbb{R}^2$ (I hope it's worth a shot) Let's just say (for convenience of this question) that for $k\in\mathbb{N}$ , if there exists a circumference such that $f(C)=k$ , then $k$ is admissible (not admissible otherwise). And let's say that a finite set of concyclic points $\mathcal{A}=\{A_1,\ldots,A_n\}$ is comaximal if they lie on a circumference and $f(C)=|\mathcal{A}\cap C|=n$ (for some $C$ ), i.e. there are no more points in $\mathbb{Z}^2$ that are concyclic with the points in $\mathcal{A}$ . At first it is easy to check that 1,2,3 and 4 are admissible. Later I thought, ""probably more even numbers than odd numbers are admissible, since there is usually plenty of symmetry in a circumference (if the centre lies in $\mathbb{Z}^2$ for example)"", which is just a vague idea, because I just haven't thought this through. So I started to wonder ""perhaps 5 is not admissible"", but then I found that the points $(8,8), (10,0), (0,10), (-1,-5)$ and $(-5,-1)$ are comaximal, so $\min\{k:k\text{ is admissible}\}\geq7$ , and that's all I have so far. It'd be really cool if no such minimum exists though. Cheers! EDIT The set of 5 points I suggested that satisfy the conditions of the problem were incorrect, though I've found now that the set $\mathcal{B}=\{(10,0),(0,10),(-5,-5),(-3,9),(9,-3)\}$ actually works with the relation $$(x-\frac{5}{4})^2+(y-\frac{5}{4})^2=\left(\frac{25\sqrt{2}}{4}\right)^2$$",['geometry']
