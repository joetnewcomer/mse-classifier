question_id,title,body,tags
53573,Any idea about N-topological spaces?,"In Bitopological spaces , Proc. London Math. Soc. (3) 13 (1963) 71–89 MR0143169 , J.C. Kelly introduced the idea of bitopological spaces. Is there any paper concerning the generalization of this concept, i.e. a space with any number of topologies?","['general-topology', 'reference-request']"
53580,Approximating convex sets with disjoint rectangles in an optimal way,"Let $O \subset \mathbb{R}^2$ be a convex open set of finite Lebesgue measure $1=m(O)$. Let's call a collection $P$ of $n$ disjoint open rectangles contained in $O$ a ""partial cover of $n$ pieces"". (The rectangles may be tilted.) Let us denote $C_n$ the collection of all $n$ piece partial covers of $O$. Write $$A_n = \sup_{P \in C_n} m(P).$$ Obviously, $A_n \to 1$ from below. From the convexity condition, it's also intuitively clear that convergence will be ""good"" - the intuition being that a convex set cannot differ by ""too much"" from a rectangle. Is it possible to make this intuition precise by writing a lower bound of some sort for $A_n$, perhaps depending on the diameter of $O$?","['measure-theory', 'euclidean-geometry']"
53592,The Spiral Behavior of Second Order Equations,"$$\frac{\mathrm d^2y}{\mathrm dt^2} + p\frac{\mathrm dy}{\mathrm dt} + qy = 0$$ If the eigenvalues are complex, what conditions on $p$ and $q$ guarantee that solutions spiral around the origin in a clockwise direction ? I found the eigenvalues to be: $\lambda = -\frac{p}{2} \pm \frac{\sqrt{p^2 - 4q}}{2}$ and not sure how we can answer this. All I note that if $p > 0$ and $p^2 - 4q < 0$, then we have a spiral sink. How does it help me if I can get conditions for spiral sink or source and match their directions (counterclockwise or clockwise) when the problem indicates we are able to do this without the use of technology sketching a phase portrait?",['ordinary-differential-equations']
53593,"What exactly does $\frac{\partial(y_1,\dots,y_m)}{\partial(x_1,\dots,x_n)}$ refer to?","I have been asking a rather few questions of this nature lately, maybe I'm starting to realise math notation isn't as uniform as I initially thought it would be... Question: Does this notation
$$\frac{\partial(y_1,\dots,y_m)}{\partial(x_1,\dots,x_n)}$$
refer to the Jacobian matrix $$ J = \begin{bmatrix} \dfrac{\partial y_1}{\partial x_1} & \cdots & \dfrac{\partial y_1}{\partial x_n} \\ \vdots & \ddots & \vdots \\ \dfrac{\partial y_m}{\partial x_1} & \cdots & \dfrac{\partial y_m}{\partial x_n}  \end{bmatrix},$$
or the Jacobian determinant $\det J$? This answer seems to support the latter interpretation, while this (and Wikipedia) both support the former. I am aware of the ambiguity of ""Jacobian"" being used to refer to either the determinant or the matrix itself, is this a similar case? It's really a bit annoying because when I see things like
$$ \left| \frac{\partial(y_1,\dots,y_m)}{\partial(x_1,\dots,x_n)} \right| $$
I don't know if it means the absolute value of the Jacobian determinant, or the determinant of the Jacobian matrix.","['notation', 'multivariable-calculus']"
53607,Dixon's Theorem to probabilistically bound largest factor of N,"I have recently decided to read up on the current integer factorization algorithms. When looking into some of the algorithms, I came across the following statement: Say that p is the smallest prime factor of n. By Dixon's Theorem, the probability that the largest factor of n is less than $(p)^\epsilon$ is roughly $\epsilon ^ {- \epsilon}$. But when I hear Dixon's Theorem, I think of this . I currently don't see how Dixon's Theorem yields such a probabilistic bound. Can you help me with that? And the disclaimer - I am not currently in any class, so this was not assigned to me, it is not a homework problem, and I will in no way be receiving any sort of academic credit for this work.","['reference-request', 'probability', 'number-theory']"
53612,Where do bitopological spaces naturally occur? Do they have applications?,"I am interested where bitopological spaces occur in various parts of mathematics (i.e., what are natural examples of bitopological spaces stemming from various areas of mathematics, not from the studying bitopological spaces for their own sake.) I would also like to know where bitopological spaces have some applications in various parts in mathematics. I quote from the discussion which motivated me to ask about them (I am quoting Theo B.): ""a reasonable definition of an application: a result that doesn't mention the objects of study in the statement but uses them in the proof"" (edit T.B.: This is a paraphrase of Paul Balmer 's strict applications mentioned by him e.g. in his ICM talk , p.2). The discussion in the comments to Brian M. Scott's answer here motivated me to ask about bitopological spaces. I am not sure to which extent my background is important, but I never studied bitopological spaces, although I have read two papers on quasi-metric spaces , which are a special case.",['general-topology']
53624,Tangent space of Cotangent bundle at zero section?,"Let $M$ be a differentiable manifold with cotangent bundle $T^*M$. How can I prove that $T_{(p,0)}T^*M$ is naturally isomorphic to $T_pM\oplus T_pM^*$? If this true, then I think I could prove that the Hessian of $f\colon M\to \mathbb{R}$ is well-defined (I mean, without choice of Connection or Riemannian metric) at critical point of $f$. This is not any homework.","['riemannian-geometry', 'symplectic-geometry', 'differential-geometry']"
53625,"If $K$ is algebraically closed and $X$ is transcendental, is $\overline{K(X)}\simeq K(X)$?","let $K$ be an algebraically closed field. Consider the algebraic closure $\overline{K(X)}$ of $K(X)$, with $X$ trascendent over $K$. Are there cases in which $\overline{K(X)}\cong K$? where $\cong$ is isomorphism in whatever sense u prefer.
Example: if we consider $K=\mathbb{C}$ then this is true if we take $\cong$ isomorphism of $\mathbb{Q}$ vector spaces. What about field structure? Thanks","['arithmetic-geometry', 'algebraic-number-theory', 'algebraic-curves', 'number-theory']"
53634,Points and lines,"I'm interested in the following quantity: Given $n$ points in convex position (that is, $n$ points in the plane forming the vertices of a convex polygon), how many minimal ways are there to separate those points with lines, s.t. no 2 points fall into the same (possibly infinite) region of the plane. 2 lines are equal, if they induce the same partition of points into two sets. 2 line arrangments are equal if all the lines are equal. By minimal I don't mean that we only use $n/2$ lines but I mean that the lines are arranged in such a way that, if we remove any line, then at least two points will lie in the same region. One can separate $n$ points in convex position into $n$ groups using a minimal line arrangement consisting of at least $n/2$ and at most $n-1$ lines. Let $T(n,m)$ denote the number of possibilities to separate $n$ points in convex position with a minimal line arrangement of $m$ lines. Im interested in the quantity $T(n,m)$ Does anyone have an idea? Thank you","['geometry', 'combinatorics']"
53636,Fixed point: linear operators,"I ask my question in two parts: though the topic is similar, I would like to distinguish linear and general cases since methods may be too different while my questions are broad. Consider a space $X$ which we assume to be Banach. We define a linear operator $A:X\to X$ which is bounded:
$$
\|\mathcal A\| := \sup\limits_{x\in X}\frac{\|\mathcal Ax\|}{\|x\|}<\infty.
$$
I would like to discuss an existence of solution for a fixpoint equation 
$$\mathcal Ax = x.\quad (1)$$ What do I know: this is an eigenvalue problem for $\lambda = 1$ or it is a problem of finding the kernel for $(\mathcal A-\mathcal I)$, $\mathcal I$ is an identity operator. Also, if $\dim X<\infty$ then $\mathcal  A$ has a correspondent finite-dimensional matrix $A$ and all properties of $(1)$ can be studied through the rang of $A$. E.g. there exists a solution of $(1)$ iff $\det (A-I)=0$ for $I$ is an identity matrix of the same size as $A$. For the general state-space my first question is: 1.If there is a method similar to calculating $\det (A-I)$ to verify the existence of solution for $(1)$? If the dimension of $X$ is not necessary finite, one of the main methods is to use Banach theorem based on the contraction principle - so it is only valid if $|\lambda^*(\mathcal A)<1|$ for the maximum eigenvalue in the absolute sense. 2.What can we do if the spectrum is not bounded by $1$ but just does not contain it? There are also procedures (usually in the discrete-time setting, e.g. $X = L^2$ and $\mathcal A$ is an integral operator) connected with the iterations of operator $\mathcal A$. There are examples (if one wants, I can put it here) when for some $x\neq 0$ the limit $$x' = \lim\limits_{n\to\infty}\mathcal A^nx\quad (2)$$ exists while $\mathcal A$ is not contractive. 3.Under which conditions $\mathcal Ax' = x'$? Finally, there are some methods in the continuous time setting (e.g. $X = L^2$ again and we are talking about differential operators). If one would like to solve an equation $\mathcal Bx = 0$ then it's helpful to consider a function $f(t)$ such that $f(0) = x_0$ and 
$$
\frac{df}{dt}(t) = \mathcal B f(t).\quad (3)
$$
Suppose, $\lim\limits_{t\to\infty}f(t) = x'\in X$. 4.Under which conditions $\mathcal Bx' = 0$? Finally, we can put $\mathcal A = \mathcal B+\mathcal I$. Then if the conditions of 4. are satisfied, $\mathcal Ax' = x'$. 5. Why for the integral equations (""discrete-time"") people commonly use $(2)$ while for, say PDEs they use $(3)$ rather then $(2)$? So there are 5 questions, and I would appreciate if you can help me with answering at least one of them or referring me to a literature which covers these questions. I guess that 5. is can be an unclear question - so if it is, just tell, I will try to make it clear.","['operator-theory', 'fixed-point-theorems', 'functional-analysis']"
53651,Fixed point: sets and measures,"Let $X$ be a Borel space with a Borel measure $\mu$. Suppose $\xi: X\times X\to\mathbb R_{\geq 0}$ is a continuous function and put $s(x) = \{y\in X:\xi(x,y) = 0\}$. For any set $b\in\mathcal B(X)$ we put 
$$
\mathcal Sb = \bigcup\limits_{x\in b}s(x).
$$
I am interested in the solutions of an equation $\mathcal Sb\subseteq b$, or even the generalized one:
$$
\mu(\mathcal Sb\setminus b) = 0.
$$
Could we say that these equations are fixpoint problems? If there is a literature for such problems?","['fixed-point-theorems', 'set-theory', 'measure-theory', 'reference-request']"
53653,Local Homeomorphism of the $S^2$ sphere to $R^2$,"I try solving the following excercise: Show by stereoscopic projection that the $S^2$ sphere is locally homeomorphic to $R^2$. I tried to solve this by using the cotangens function on the two angles defining the surface of the ball by the projection: $\phi : S^2 \rightarrow \mathbb{R}^2, \ (\alpha, \beta) \mapsto \left(\cot \alpha, \cot \frac{\beta}{2}\right)$ for $\alpha \in (0, \pi),  \beta \in (0, 2\pi)$ However the poles and one of the connecting lines ($\beta = 0$) is not defined by this map. Is there a neat trick to get this out of the way?",['general-topology']
53658,Exercises on Galois Theory,"I need a source for exercises on classical Galois Theory, or to be more specific, Galois extensions of finite fields and the rationals as well as applications (solvability by radicals, for example).
So far, I have worked with Tignol's ""Galois Theory of Algebraic Equations"". Any additional suggestions would be appreciated, whether it is a textbook or a website, but the language should be English. Solutions are welcome, but no necessity. Thanks in advance!","['book-recommendation', 'abstract-algebra', 'reference-request', 'galois-theory', 'online-resources']"
53660,When can we plug in values in a limit?,"When is it that we can plug in the limit point into the function to evaluate a limit? I believe for real limit points, we can do this when the function is continuous at the point. But what about for limits at $ \infty $ and $ -\infty $? Is there a general statement that we can make about this? Example : It is easy to believe that the following limit evaluates to $ 0 $
$$ \lim_{n\to\infty}{\sqrt{n^2+n}-n} $$ How can we not fall into these traps? EDIT: Yes, the above limit is simple to evaluate correctly (it's $ 1/2 $). But what I'm asking is for a rigorous condition under which we can know whether or not we can naively plug in the value to get the correct answer.","['calculus', 'real-analysis', 'limits']"
53676,Blowing up a subvariety - what can happen to the singular locus?,"I know that blow ups can be used for the resolution of singular points on a variety $X$. What I need to know is - if I blow-up along some arbitrary subvariety of $X$, what are the possible outcomes for the dimension of the singular locus of the variety?  If the subvariety lies outside the singular locus of $X$, then it stays the same, if it is a carefully chosen singular point, it might go down. $\textbf{Can it go up?}$ To be more specific, my variety is a high dimensional hypersurface, and the subvariety I am blowing up is a $\textbf{linear}$ space of much smaller dimension than the singular locus.  I don't know if this changes the situation.","['geometry', 'algebraic-geometry', 'blowup']"
53677,How do I calculate the length of a curve given in parameterized form?,"I am given a function describing a curve: $f(t) = (f_1(t), f_2(t))',\quad t \in \mathbb{R},\quad  f_1, f_2: \ \mathbb{R} \rightarrow \mathbb{R}\ .$ How would I calculate the length of that curve corresponding to a given $t$-interval $[a, b]$?","['multivariable-calculus', 'differential-geometry']"
53685,Grothendieck spectral sequence,"given functors $F,G$, left exact, with as good properties as you want we have a spectral sequence $R^p F\circ R^q G$ abutting to $R^{p+q}(F\circ G)$. I am looking for an analogous for a ""mixed version"" in te following case: $F$ left exact and $G$ right exact. What appens to $L^pG\circ R^q F$?","['homological-algebra', 'commutative-algebra', 'algebraic-geometry']"
53686,To what extent can values of $n$ such that $n^2-n+41$ is composite be predicted?,"Euler's polynomial $E(n)=n^2-n+41$ takes a prime value for each of the positive integers $n<41$.  For $n=41$, its value is $41^2$, which is composite, and every multiple of 41 will likewise produce a composite number.  These, of course, aren't the only $n$ for which $E(n)$ is composite.  Between $41$ and $82=2\cdot41$, for example, we have $$
(42,45,50,57,66,77)=(41+1,41+4,41+9,41+16,41+25,41+36)
$$
which all give $E(n)$ composite; in the range $1\le n\le1000$ there are 419 values of $n$ for which $E(n)$ is composite. You can show that $E(n)$ will be composite when $n=f_1(a,b):=a(b^2-b+41)+b$ for $a$ a positive integer and $b$ an arbitrary integer.  This is readily done by plugging $f_1(a,b)$ into $E(n)$, factorizing the resulting polynomial as $(b^2-b+41)(a^2b^2-a(a-2)b+1-a+41a^2)$, and verifying that neither factor equals 1 for the stated values of $a$ and $b$. Remarkably, the first 61 values of $n$ that produce composite $E(n)$ are of this form, with $n=245$ being the smallest exception. Another expression that always produces composite $E(n)$, and for similar reasons, is $n=f_2(a,b):=(4a+2)(b^2-b+41)+(4a+1)b-a$.  Together, $f_1(a,b)$ and $f_2(a,b)$ account for the first 169 values of $n$ for which $E(n)$ is composite, with $n=490$ being the first exception.  Two additional expressions, $f_3(a,b):=(a + 1) a (b^2-b+41) + (2 a + 1) b - (a - 1)$ and $f_4(a,b):=\frac{1}{2}(a + 1) a (b^2-b+41) + (2 a + 1) b - (a - 2)$, along with $f_1(a,b)$ and $f_2(a,b)$ account for all composite-producing $n$ less than 979. Questions: Can someone see what's going on here?  What is the conceptual explanation for the success of these particular expressions in accounting for low-lying composite-producing $n$? Should we expect to find more such expressions?  All of the $f_j$ defined above are quadratic in $b$, but not necessarily in $a$. Motivation: I became curious about this question while investigating the work of Laurence Monroe Klauber .  He is most famous for his work in herpetology, but he also pursued an interest in number theory, which I became aware of through reading one of Ed Pegg Jr.'s Math Games columns.  (Klauber developed the idea of using two-dimensional arrays of integers to visualize prime-rich quadratic polynomials decades before Ulam discovered his spiral.)  The San Diego Natural History Museum has recently been digitizing some of Klauber's papers; Margaret Dykens, the librarian there, sent me the abstract of a talk Klauber gave at an MAA meeting in 1932, in which he mentions patterns in the composite values of the Euler polynomial.  I have not yet seen the paper itself - it wasn't published - so I don't know what Klauber claimed to have found.  The expressions $f_i(a,b)$ above were found by fitting lists of composites generated by the computer.","['elementary-number-theory', 'number-theory']"
53691,4-Manifolds of which there exist no Kirby diagrams,"In 4-Manifold theory one makes often the use of Kirby Diagrams to construct 4-manifolds (compact or non-compact) with specific gauge and topological properties (for example small betti numbers, spin structure, etc.). This raises a couple of questiona: 1.Is any compact or non-compact 4-manifold obtainable as a (finite or infinite) handle diagram ? 2.What are the properties needed for a compact or non-compact 4-manifold to be represented as a handle diagram ? 3.What are examples of 4-manifolds with no handle diagram ? The diagrams can be as complicated as you want (so 0-, 2-, 3-, 4-) handles can be present. I do not know if you can get rid of all the 3-handles in the non-compact case. This question came forth from the discussion explicit ""exotic"" charts . I am trying to get help of more people on that, then putting those things in comments (the question of explicit charts of an $\mathbb{E}\mathbb{R}^4$ is another one, albeit interesting in it's own right). The question is answered by Bob Gompf by email, see my comment for the main part of his answer.","['geometry', '4-manifolds', 'low-dimensional-topology', 'kirby-diagram', 'differential-topology']"
53694,Equivalent condition for differentiability on partial derivatives,"I want to extend the concept of derivative of a real function of real variable to a function $f:A\subset \mathbb{R}^n \to \mathbb{R}^m$ with $A$ open. If $x_0 \in A$ then I say that $f$ has derivative $f'(x_0) \in \operatorname{Hom}(\mathbb{R}^n, \mathbb{R}^m)$ if 
$$ \lim_{h\to 0} \frac{|f(x_0+h)-f(x_0)-f'(x_0)(h)|}{|h|}=0 .$$ 
When the function is given in explicit algebraic form as $f(x_1,\dots,x_n) = \sum \limits_{i=1}^m f_{i}(x_1,\dots,x_n)e_i$ and I know that the derivative exists at $x_0\in A$, then I can compute $f'(x_0)$ explicitly because 
$$ [f'(x_0)]_{ij} = (D_jf_i)(x_0) $$ 
is the matrix representation of $f'(x_0)$ relative to standard bases and I know from basic calculus how to compute those partial derivatives. My question is: if I can compute partial derivatives in $x_0$ without knowing if $f'(x_0)$ exists, is there some regularity condition on partial derivatives that is equivalent to the existence of $f'(x_0)$? The existence of partial derivatives isn't sufficient (for $n>1$), for example $\frac{xy}{x^2+y^2}$ has partial derivatives but isn't continuous in $(0,0)$ if is defined $0$ in $(0,0)$ and thus can't be differentiable there. Coming back to the general problem, if partial derivatives exist and are bounded in a neighborhood of $x_0$, then $f$ is continuous in $x_0$ but I believe it could be not differentiable, although I can't write a counterexample. If the partial derivatives are continuous in $x_0$ then $f'(x)$ should exist in a neighborhood of $x_0$ and should be continuous in $x_0$, but this is clearly more than differentiability in $x_0$. NEWS Differentiability seems to be a slippery regularity . I discovered from Rudin ""Principles of Mathematical Analysis"" that an equivalence exists for continuously differentiable functions, in fact $f\in C^1(A)$ if and only if $D_jf_i\in C^1(A)$ for all $i,j$. The question seems difficult because of the fact that the regularity of a multivariable function and that of its partial derivatives seem to have a weak connection, although a general heuristic principle for this type of problems could be: a stronger regularity on partial derivatives implies a weaker regularity on the function .",['multivariable-calculus']
53695,"Find noncontinuous $F : \Bbb{R}^{\Bbb{R}} \to \Bbb{R}$ such that if $f_n \to f$ in $\Bbb{R}^{\Bbb{R}}$, then $F(f_n) \to F(f)$","I'm reading the book General Topology by S. Willard and I came across the following problem.
We have to find an example of a noncontinuous function $F:\mathbb R^\mathbb R\to \mathbb R$ with the property that
whenever $f_n\to f$ in $\mathbb R^\mathbb R$, then $F(f_n)\to F(f).$ Here $\mathbb R^\mathbb R$ denote a space 
with the product topology and $\mathbb R$ is equipped with the usual topology. Please give
me some hint. Edit (T.B.) The problem comes from section 10, specifically as a problem illustrating the points in (10.6).",['general-topology']
53704,Why are cluster co-occurrence matrices positive semidefinite?,"A cluster (aka a partition) co-occurrence matrix $A$ for $N$ points $\{x_1, \dots x_n\}$ is an $N\times N$ matrix that encodes a partitioning of these points into $k$ separate clusters ($k\ge 1$) as follows: $A(i,j) = 1$ if $x_i$ and $x_j$ belong to the same cluster, otherwise $A(i,j) = 0$ I have seen texts that say that $A$ is positive semidefinite. My intuition tells me that this has something to do with transitive relation encoded in the matrix, i.e.: If $A(i,j) = 1$, and $A(j,k) = 1$, then $A(i,k) = 1$ $\forall (i,j,k)$ But I don't see how the above can be derived from the definition of positive semidefinite matrices, i.e. $z^T A z > 0$ $\forall z\in R^N$ Any thoughts?",['matrices']
53706,"Lebesgue measure of an intersection of four sets that are contained in [0,1]","Let $A_1,A_2,A_3, A_4$ be measurable subsets of $[0,1]$, such that $\displaystyle\sum_{k=1}^{4}m(A_k)>3$. Prove that $$
m\left(\bigcap_{k=1}^{4}A_k\right)>0.
$$","['measure-theory', 'lebesgue-measure', 'real-analysis']"
53709,Sheafification and the unique decomposition of morphisms,My question is an attempt to understand the proof of lemma 6.17.3 (page 164) in the Stacks Project: http://www.math.columbia.edu/algebraic_geometry/stacks-git/book.pdf This lemma states: Let $F$ be a presheaf of sets on $X$. Any map $F\to G$ into a sheaf of sets factors uniquely as $F \to F^{S} \to G$ (when $F^{S}$ denotes the sheafification of $F$). The part that I'd like to understand is: why is the above map $F^{S} \to G$ unique?,"['sheaf-theory', 'algebraic-geometry']"
53719,"Does $A=\{a|\forall x\in \emptyset\ H(x,a) \}$ make sense?","What happens if I define a set $A=\{a|\forall x\in \emptyset\ H(x,a)  \}$, where $H$ is some property ? $\forall x\in \emptyset\ H(x,y)$ should be always true, since it is vacuously true, right? So this set $A$ shouldn't exists, or it would be ""the set of all sets"".",['elementary-set-theory']
53749,Sum with sine in denominator,Here is some sum that I can guess an answer but somehow lack of nice solution. $$\displaystyle\sum _{k=0}^{n-2} (-1)^k\frac{1}{\sin\left(\frac{(2k+1)\pi}{4n-2}\right)}=\;?$$,"['trigonometry', 'analysis']"
53750,Circles and members,"This problem may seem challenging: We have $3n$ people, and circles of interest. In every circle there is an odd number of members. The number of common members to every $2^{n-1}+1$ circles is even. Prove that there are no more than $2^n+n2^{n-1}$ circles.",['combinatorics']
53758,What is a function to represent a diagonal sine wave?,"I need to be able to plot pixels in this pattern. To me, it looks like a sine wave pattern that is both diagonal and convergent. What would a function for that look like?  Thanks.","['graphing-functions', 'functions']"
53762,Addition of Unbounded Operators,"Let $H$ be a (separable complex) Hilbert space and let $A$ and $B$ be two densely-defined, maximally-defined linear operators on $H$ with domains $D(A)$ and $D(B)$ respectively.  (By maximall-defined, I mean that $A$ and $B$ admit no extensions).  Then, we can define the operator $A+B$ on $D(A)\cap D(B)$, however, in general, the operator $\left( D(A)\cap D(B),A+B\right)$ will not be maximally-defined.  The question is:  does this operator admit a unique maximal extension? My conjecture is that the answer is no, but I would absolutely love for the answer to be yes. Any ideas? Thanks again!","['operator-theory', 'inner-products', 'hilbert-spaces', 'functional-analysis']"
53767,$x^4+4$ is composite for $x>1$,$x^4+4$ is composite for $x>1$ I know the Sophie Germain indentity and the  get the factorization $$x^4+4 = (x^2+2-2x)(x^2+2+2x)$$ But I am stuck here. I cannot see any general factor here.,['algebra-precalculus']
53773,"Haar's base for $L^2[0,1]$","$\newcommand{\span}{\operatorname{span}}$
Define $e_{0,0}\equiv 1$, and for all $n\in \mathbb{N}$
$$e_{n,k}=\begin{cases} 2^{n/2} &\text{if } \frac{k-1}{2^n}\leq x\lt \frac{k-\frac{1}{2}}{2^n}\\
-2^{n/2}&\text{if } \frac{k-\frac{1}{2}}{2^n}\leq x\lt \frac{k}{2^n}\\
0 &\text{otherwise} \end{cases}$$
for $k=1,\ldots,2^n$. Let $$H:=\{e_{n,k}:n,k\in \mathbb{N}\}.$$ I want to prove that $H$ is a Hilbert's base for $L^2[0,1]$ with the usal inner product. In order to prove this we must show that $H$ is orthonormal and that $\span(H)$ is dense in $L^2[0,1]$. Here is a good place to begin to see the orthonormality. For the second thing I have the following exercise: Let $f\in H^{\bot}$, i.e. $f$ is such that for all $n\in \mathbb{N}$ $$\int_0^1 f(x)e_{n,k}(x)dx=0,$$ for $k=1,\ldots,2^n$. Show that for all $n\in \mathbb{N}$ $$\int_0^1f\cdot 1_{[0,k/2^{n})}=0,$$ $k=1,\ldots,2^n$. Conclude that $f\equiv 0$. The exercise show that $(\overline{\span(H)})^{\bot}=\{0\}$ and then the density follows. And here is where I'm stuck. I wish it $f$ were continuous function, but $f$ is square integrable only. If the notation is not clear, just tell me and I'll fix it. Thanks for your help.","['measure-theory', 'hilbert-spaces', 'functional-analysis', 'real-analysis']"
53794,Simple question: the double supremum,"Let $f:A\times B\to \mathbb R$. Is it always true that
$$
f^* = \sup\limits_{a\in A,b\in B}f(a,b) = \sup\limits_{a\in A}\sup\limits_{b\in B}f(a,b).
$$
I proved it by the $\varepsilon$-$\delta$ arguments, but I still do not sure if I've done it formal enough. Proof: Let $g(a) = \sup\limits_{b\in B}f(a,b)$ hence $g(a)\geq f(a,b)$ for all $b\in B$ and for any $\varepsilon>0$ exists $b'_{a,\varepsilon}\in B$ such that $f(a,b'_{a,\varepsilon})\geq g(a)-\varepsilon/2$. We put $g^* = \sup\limits_{a\in A}g(a)$, then $g^*\geq g(a)\geq f(a,b)$ for all $a\in A,b\in A$ and for any $\varepsilon>0$ there exists $a'_\varepsilon\in A$ such that $g(a'_\varepsilon)\geq g^*-\varepsilon/2$. Now, for an arbitrary $\varepsilon>0$ we can take $a'_\varepsilon\in A$ and $b'_{a',\varepsilon}\in B$ such that $f(a'_\varepsilon,b'_{a',\varepsilon})\geq g(a'_\varepsilon)-\varepsilon/2\geq g^*-\varepsilon$, so $g^* = f^*$. For the case $f^* = \infty$ I have almost the same proof (just inequalities are different). Should I also put it here?","['optimization', 'real-analysis']"
53816,"Closest pair of vectors in $\{0,1\}^n$","Suppose we are given $k$ points in $\{0,1\}^n$ (using Hamming distance as metric).
Consider the two points that have the smallest distance between
them.
Does there exist any results bounding this distance?
In particular
I am interested in an explicit function $f(k,n)$ bounding this distance from above. Another way to ask would be to give a lower bound on how many entries
the pair with the smallest distance between them are sharing, or how far away from each other can the closest pair be? Any reference to such a function or related problems will help.","['ramsey-theory', 'coding-theory', 'combinatorics']"
53819,Changing a bezier curve by dragging a point on the curve itself rather than a control point,"I'm developing an iPhone app that allows users to cut out part of an image from its background. In order to do this, they'll connect a bunch of bezier curves together to form the clipping path. Rather than have them move the control points of the curves in order to change the curve, I'd like them to be able to move a point on the curve itself. At this point, I'm not set on using quadratic rather than cubic beziers, or vice versa. The rest of this post will discuss the issue from the point of view of quadratic curves, but I would love an answer that provides solutions to both. It seems to me that there are two possible methods for accomplishing this: By determining the relationship between the point on the curve and the true control point. If this can be done, then the new location of the control point can be calculated based on the new location of the point on the curve. By using an equation that can estimate a bezier curve based on two end points and a third point on the curve (if cubic, then a third and fourth point on the curve). Are either of these possible? I've been googling this for a while and have come across a couple potential solutions using method #2, but I don't fully understand either: Solution 1 (click here): I think I understand the code in this example well enough, but I don't know how to calculate t . Solution 2 (click here): This code is written in C#. I tried converting it to Objective-C (the language used for iPhone apps), but ultimately got stuck on the ""solvexy()"" function because I don't see how i or j are used after calculating their values. In regards to method #1, it seems to me that there should be some mathematical relationship between the control point, and the point on the curve through which a tangent to the curve at that point would be perpendicular to a line drawn from the control point to that point. Here are a couple illustrations: quadratic , cubic . The idea is that this point which lies on the curve, through which the perpendicular tangent is drawn, is the point that users would be dragging in order to modify the curve.","['geometry', 'bezier-curve']"
53841,"Finding a set of subsets such that for each such subset in the set, there exists another subset in the same set which is non-disjoint","I'm sorry if the title is a bit convoluted. I'm a bit unsure how to formulate this condition in words, see below instead. Say we are given a set $Y$.
I want to find the following set: $\mathcal{A}$ such that for any $x=\{G_1, ..., G_k\} \in \mathcal{A}, G_i \subset Y$, we have that: $\forall G_i \in x, \exists G_j \in x, i \neq j ,  \quad G_i \cap G_j \neq \emptyset $ I'm mostly interesting in finding an algorithm which generates this set.
This problem arose when trying to figure out how to generate the set of subgraphs of a connected subgraphs, such that their union is still connected.
So the sets above would then be vertex sets and I would form their induced graph. So, I want to find the subgraphs such that the union of all those subgraphs
$\bigcup_{i=1}^{k}G_{i} \text{ is connected}$. Since each of the subgraphs themselves are connected (since the graph is), the above stated condition ought to ensure that their union is connected. Anyone have an idea how to tackle this? Any help is much appreciated!","['graph-theory', 'elementary-set-theory', 'combinatorics']"
53852,Is there a way of working with the Zariski topology in terms of convergence/limits?,"As someone who is very fond of analysis, I feel most comfortable working in topological spaces via the notion of convergence of sequences (or nets, in infinite-dimensional Banach spaces, etc.). In every metric space (or first-countable topological space) anything you can say about the topology can be said in terms of convergent sequences (though perhaps less elegantly). In arbitrary topological spaces, one can use nets instead. However, if the space is not Hausdorff then nets don't have unique limits, which makes it quite difficult to work with them the way one is used to working with sequences (of real numbers, say). This is the case with the Zariski topology on $\mathbb{C}^n$ (I have no urgent desire to consider more general algebraic varieties). Is there some convenient way to express the Zariski topology (that is: its closed sets, the continuous functions it allows,...) in terms of some ""convergence structure"" which satisfies properties similar to those we have in any sequential/metric/first-countable space?","['general-topology', 'algebraic-geometry', 'convergence-divergence']"
53859,Coloring dodecahedron,I found some months ago that there are the Polya's enumeration theorem to compute number of colorings of dodecahedron. I got interested to find how to show by using only Burnside's lemma that there are 9099 ways to color dodecahedrom by three colors. How can I do the computation?,"['coloring', 'group-theory', 'polyhedra', 'combinatorics']"
53860,Compactness in $\mathbb{Q}$,"Proving that $[0,1]\subset\mathbb{R}$ is compact you make use of completeness and this is a fundamental step in order to characterize compact subsets of $\mathbb{R}$. Trying to state an analogous problem in $\mathbb{Q}$, I asked myself if $[0,1]\cap\mathbb{Q}$ is compact in $\mathbb{Q}$ endowed with the subspace topology but I find it hard to answer. Can you help? In general, how do compact subsets of $\mathbb{Q}$ look like?","['general-topology', 'compactness']"
53874,equivalent definitions of closure,"This is a topology question. First of all, I am sorry this is a really dummy question. As a math student, it is a shame I haven't taken any courses in topology. A closure of a set $A$ is usually defined as $\operatorname{int}(A)\cup \partial A $.
I would like to know how to prove the equivalence of this statement to $A \cup A'$, where $A'$ is the derived set. Thanks in advance. ========EDIT========== $\operatorname{int}(A) = \bigcup\{O :\, O\text{ is open and }O\subseteq A \}$ $\partial A$ is defined as for any $x$, an open set containing it intersects both $A$ and $A^{c}$ $A'$ is a set containing all limit points that are defined as every open set containing a limit point also at least contains an element of $A$. I hope it is clearer now.
And It would be appreciated if a 'standard' definition of closure could be given. ===========UPDATE========= Thanks Asaf Karagila for editing the text.
I am sorry I only can accept one answer, so I go for the first and most voted one.
But I really appreciate other's contibutions.
Thank you all! cheers",['general-topology']
53875,Calculating point around circumference of circle given distance travelled,"It is the end of the day and my brain just can't cope anymore. Can anyone help with, what I hope, is a simple question? Given a point on a circle ($x$, $y$ coordinates) how can I calculate the coordinates of another point at a given distance around the circumference of the circle? Known variables are the starting point, distance traveled and radius of the circle.","['geometry', 'trigonometry', 'circles']"
53882,Does the solution of any differential equation (without boundary conditions) is always smooth,Pardon me if this question sounds silly. Consider any differential equation without any boundary conditions. Does the solution of it is always smooth ?,"['ordinary-differential-equations', 'real-analysis']"
53887,"Covariant derivative of (1,1)-tensor","Suppose I have an endomorphism $J:TM \to TM$ and a connection on M. It is possible to define $\nabla_X J$ by transforming $J$ into a (1,1)-tensor and using the extension of $\nabla$ to tensors. Going back we get an endomorphism $\nabla_X J:TM \to TM$. Is there a way to define $\nabla_X J:TM \to TM$ directly?",['differential-geometry']
53895,"Lerch-$\small \zeta(\varphi,0,-n)$ of integer *n* purely real and imaginary ($\small \zeta_\varphi (-n)^2 $ is real) for $\small n \ge 2$?","Are the Lerch -$\zeta(\varphi,0,-n) $ of integer n (for shortness I use the notation of my earlier question $\small \zeta_\varphi(-n)$) periodically purely real and imaginary: $\zeta_\varphi (-n)^2 $ is real, ($ n \ge 2$) ? And how to prove this? I've a strange observation of periodicity which I would like to explain/derive/prove  analytically. Consider the triangle of eulerian numbers E (ideally of infinite size, row and col-indices beginning at zero, with elements $ \small e_{r,c}$) $ \qquad E = \small 
\begin{array} {rrrrr}
 1 & . & . & . & . & . \\
 1 & 0 & . & . & . & . \\
 1 & 1 & 0 & . & . & . \\
 1 & 4 & 1 & 0 & . & . \\
 1 & 11 & 11 & 1 & 0 & . \\
 1 & 26 & 66 & 26 & 1 & 0
 \end{array}  $ Assume some angular parameter $\varphi$, the associated complex number from the unit-circle $z=z_\varphi= \exp(i \varphi ) \qquad z \ne 1 $, $ \small {\varphi \over \pi} $ not necessarily rational. Now consider the Eulerian polynomials, whose coefficients are taken from a row of E ,
 $ \small E(z,r) = \sum_{c=0}^\infty ( e_{r,c} \cdot z^c ) $ Then compute $ \small \zeta_\varphi(-n) = {z \over (1-z)} \cdot E(z,n) \cdot (1-z)^{-n} $ . Observation : I observe, that for $n>2$ the $ \small \zeta_\varphi(-n) $ lie either on the real or on the imaginary axis, in other words $ \small \zeta_\varphi(-n) ^2 $ are real.. Q : I seem to be missing just the key idea, so my question here is, how I could derive that behave analytically, given the description via the Eulerian triangle. Addendum/Generalization : While it was already surprising, that this works with rational roots z of the complex unit, it seems to me even more interesting, that the observation holds for arbitrary $ \small \varphi \ne 0 $ and $ \small z_\varphi = \exp(I \cdot \varphi) \ne 1 $ .","['special-functions', 'zeta-functions', 'number-theory', 'eulerian-numbers', 'complex-numbers']"
53905,Is there any relation of injective modules to free modules?,"Projective modules are direct summands of free modules.
As I perceive it, projections and injections are dual notions.
Based on that, I was looking whether there is a relation of injective
modules to free modules (similar to the natural relation of projective modules 
to free modules) or to another kind of module that has
potentially ""dual"" properties to that of a free module. Any insights?
Thank you :-)","['abstract-algebra', 'injective-module', 'modules', 'commutative-algebra', 'free-modules']"
53924,average number of moves needed to complete a game of FreeCell,"Sometimes finishing a game of FreeCell takes me 10 minutes, other times just one minute. I know that all but one of the FreeCell deals in windows can be won, but I'm not sure if they are random or not [yet that is irreverent]. Assume: ALL GAMES POSSIBLE. Random deal. NO Automation. IE.  The minimum number of clicks is 52, not 0. What is the average minimum number of moves necessary to complete a game of Freecell?","['combinatorial-game-theory', 'card-games', 'probability', 'combinatorics']"
53926,Ideas of finding counterexamples?,"The questions are from an exercise in Gibert Strang's Linear Algebra . Construct $2$ by $2$ matrices such that the eigenvalues of $AB$ are not the products of the eigenvalues of $A$ and $B$, and the eigenvalues of $A+B$ are not the sums of the individual eigenvalues. It's obvious that either $A$ or $B$ is NOT diagonal matrix. Here is my question: How should I approach the construction? Any heuristics? Added: This seems to be a rather ""stupid"" question. Trial and error with MATLAB may lead to the results. However, I'd like to go a little bit further. ""Trial and error"" can be viewed as one kind of method for counterexample finding. My second question may be more ""stupid"" and very vague: Can any one come up with a ""general idea"" for the construction of counterexamples in mathematics?","['linear-algebra', 'soft-question']"
53938,Lebesgue's Theorem on Differentiation of measures?,"I'm currently going through Ahlfors's ""Lectures of Quasiconformal Mappings,"" and there is a part that I would like more a bit more detail on. Let $f$ be a orientation preserving homeomorphism on the plane, and we define a measure $A(E)$ as the area of $f(E)$. On page 18, it says that ""This defines a locally finite additive measure, and according to a theorem of Lebesgue such a measure has a symmetric derivative a.e., that is, $$J(z) = \lim \frac{A(Q)}{m(Q)}$$ when $Q$ is a square of center $z$ whose side tends to zero. Moreover, $$\int_E J(z) dxdy \le A(E)$$ (we cannot yet guarantee equality)."" I think this statement is related to the Lebesgue differentiation theorem , but I haven't had luck finding actual the statement of the theorem Ahlfors is supposedly quoting. Could someone point me to a reference? Thank you!","['measure-theory', 'real-analysis']"
53939,Connection Between Automorphism Groups of a Graph and its Line Graph,"First, the specific case I'm trying to handle is this: I have the graph $\Gamma = K_{4,4}$. I understand that its automorphism group is the wreath product of $S_4 \wr S_2$ and thus it is a group of order 24*24*2=1152. My goal is to find the order of the AUTOMORPHISM GROUP of the Line Graph : $L(\Gamma)$.
That is - $|Aut(L(G))|$ I used GAP and I already know that the answer is 4608, which just happens to be 4*1152. I guess this isn't a coincidence. Is there some sort of an argument which can give me this result theoretically? Also, I would use this thread to ask about information of this problem in general (Connection Between Automorphism Groups of a Graph and its Line Graph). I suppose that there is no general case theorem. I was told by one of the professors in my department that ""for a lot of cases, there is a general rule of thumb that works"" although no more details were supplied.
If anyone has an idea what he was referring to, I'd be happy to know. Thanks in advance, Lost_DM","['graph-theory', 'group-theory', 'combinatorics']"
53948,"For what functions does $\int\limits_{-\infty}^{\infty}x \sin(f(x))\,dx$ converge?","I'm thinking that the class of functions which cause the integral to converge are those whose big O is above $n^3$. Its not hard to show that if $f(x)$ is $x^3$, $x^4$, etc then the integral converges. I am having trouble with the function $f(x)=x^3+x$ for example and would probably be happy with an explanation of whether it converges or not. Thinking intuitively, the reason the integral converges for those values of f is that it oscillates quicker than the amplitude grows by just enough. I guess the vague question is then what constitutes fast enough.",['integration']
53954,Sum of Closed Operators Closable?,"Let $A$ and $B$ be closed operators on a (separable complex) Hilbert space with dense domains $D(A)$ and $D(B)$ respecitvely.  Then, we may define the operator $A+B$ on $D(A)\cap D(B)$.  In general, we have no reason to believe that this operator will be closed, which begs the question, is it closable? I hope I'm not being an idiot again. . .  Any ideas?","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
53991,A fun Pascal-like triangle,"Inspired by Pascal, I put on some shackles and a thorny belt. Inspiration came pouring in, and I thought of the following triangle: $$
\begin{array}{rcccccccccc}
&    &    &    &    &  1\\\
&    &    &    &  1 &    &  1\\\
&    &    &  1 &    &  \frac{1}{2} &    &  1\\\
&    &  1 &    &  \frac{2}{3} &    &  \frac{2}{3} &    &  1\\\
&  1 &    &  \frac{3}{5} &    &  \frac{3}{4} &    &  \frac{3}{5} &    &  1\\\
1 & &  \frac{5}{8} &    &  \frac{20}{27} &    &  \frac{20}{27} &    &  \frac{5}{8} &    &  1\\\
& ... & & & &... & & & & ... &
\end{array}
$$ Let's call the corresponding entry ${n \choose k}$ because there is clearly no danger of confusion. The construction rule is very simple. Instead of having 
$${n+1 \choose k} = {n \choose k-1} + {n \choose k},$$
as usual, we have
$${n+1 \choose k} = \frac{1}{{n \choose k-1} + {n \choose k}}.$$ It's easy to see by induction that all entries of the triangle lie between $1/2$ and $1$. Also, for fixed $k$, ${n \choose k}$ converges to a limit $C_k$. For example, $C_1=1/\phi$, where $\phi$ is the golden ratio (this should be obvious! think of Fibonacci numbers...). We can determine easily $C_{k+1}$ in terms of $C_k$ by taking the limit in the construction rule, which yields $C_k=(C_{k-1}+C_k)^{-1}$. In particular, all of the $C_k$'s are algebraic numbers. I would like to know if anybody here can prove interesting properties of this triangle, or of the numbers $C_k$. Enjoy! I'm going to take off the shackles and belt now.","['elementary-number-theory', 'puzzle', 'sequences-and-series']"
54001,Determine limit of |a+b|,"This is a simple problem I am having a bit of trouble with. I am not sure where this leads. Given that $\vec a = \begin{pmatrix}4\\-3\end{pmatrix}$ and $|\vec b|$ = 3, determine the limits between which $|\vec a + \vec b|$ must lie. Let, $\vec b = \begin{pmatrix}\lambda\\\mu\end{pmatrix}$, such that $\lambda^2 + \mu^2 = 9$ Then, $$
\begin{align}
\vec a + \vec b &= \begin{pmatrix}4+\lambda\\-3 + \mu\end{pmatrix}\\
|\vec a + \vec b| &= \sqrt{(4+\lambda)^2 + (\mu - 3)^2}\\
&= \sqrt{\lambda^2 + \mu^2 + 8\lambda - 6\mu + 25}\\
&= \sqrt{8\lambda - 6\mu + 34}
\end{align}
$$ Then I assumed $8\lambda - 6\mu + 34 \ge 0$. This is as far I have gotten. I tried solving the inequality, but it doesn't have any real roots? Can you guys give me a hint? Thanks.",['algebra-precalculus']
54075,Finding an equation to a function,I can think of a visual example s.t. f in $\mathbf C^2$ ($\mathbf R^2$) has a single local minimum stationary point that is not a global minimum but I can't give it a concrete equation... If anyone can think of a better example (i.e. one with a simpler equation) that would be even better! Thanks.,['functions']
54093,Dyson series and T product (II),"After reading the previous posts related to the Dyson series, I have decided to open a new thread because there is something that I am still not understanding. It concerns the expression: $$
∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})]
=
$$
$$
∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''})
+ 
∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′})
$$ that is assumed in many text books. I wonder if it can be derived from the definition of the Time-ordered operator: $$
\hat{T}[
\hat{H}(t^{′})
\hat{H}(t^{''})]=θ(t^{′}−t^{''})
\hat{H}(t')
\hat{H}(t^{''})
+
θ(t^{''}−t^{'})
\hat{H}(t^{''})
\hat{H}(t^{'})
$$
and its natural extension to products of integrals:
$$
\hat{T}∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{'})\hat{H}(t^{''})
=
∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})]
=
$$
$$
=
θ(t^{'}−t^{''})
∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''})
+ 
θ(t^{''}−t^{′})
∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′})
$$ If I am right, the step-function θ$(t)$ must cancel one of the terms leading to:
$$
∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})]
=∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''}) 
\qquad
\text{if $t'>t^{''}$}
$$ 
or:
$$
∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})]
=∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′})
\qquad
\text{if $t'< t^{''}$}
$$ but in any case it leads to the combination of both: 
$$
∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''})
+ 
∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′})
$$ What I am missing? Thanks in advance","['products', 'integration', 'physics']"
54101,Are the determinantal ideals prime?,"I want to prove the determinantal ideals over a field are prime ideals. To be concrete: For simplicity, let $I=(x_{11}x_{22}-x_{12}x_{21},x_{11}x_{23}-x_{13}x_{21},x_{12}x_{23}-x_{13}x_{22})$ be an ideal of the polynomial ring $k[x_{11},\ldots,x_{23}]$. I have no idea how to prove that $I$ is a radical ideal (i.e. $I=\sqrt{I}$). Could anyone give some hints? Generally, let $K$ be an algebraically closed field, then $\{A\mid\mathrm{Rank}(A)\leq r\}\subseteq K^{m\times n}$ is an irreducible algebraic set (I first saw this result from this question ). And I tried to prove this by myself, then I have proved it (when I see the ""Segre embedding""). But I have no idea how to show that the ""determinantal ideals"" are radical ideals (I hope this is true). BTW, is the statement that the determinantal ideals over a field are prime ideals true ? Thanks.","['commutative-algebra', 'ideals', 'algebraic-geometry']"
54109,Determinant of a special matrix,"The question is related to the eigenvalue problem. Using MAPLE, I calculated the following determinants: $$\begin{align}
\begin{vmatrix}
   -\lambda & 1 \\
  1 & -\lambda \\
\end{vmatrix}&=\lambda^2-1\\
\begin{vmatrix}
  -\lambda & 1 & 0 \\
   1& -\lambda & 1 \\
   0& 1 & -\lambda \\
\end{vmatrix}&=-\lambda^3+2\lambda\\
\begin{vmatrix}
  -\lambda & 1 &0  &1  \\
   1& -\lambda & 1 &0  \\
   0&  1& -\lambda & 1 \\
   1&  0&  1& -\lambda \\
\end{vmatrix}&=\lambda^4-4\lambda^2\\
\begin{vmatrix}
  -\lambda &1  &0  &1  &0  \\
   1& -\lambda &1  &0  &1  \\
   0&  1& -\lambda &1  &0  \\
   1&  0&  1& -\lambda &1  \\
   0&  1&  0&  1& -\lambda \\
\end{vmatrix}&=-\lambda^5+6\lambda^3\\
\begin{vmatrix}
  -\lambda &1  &0  &1  &0  &1  \\
   1& -\lambda &1  &0  &1  &0  \\
   0&  1& -\lambda &1  &0  &1  \\
   1&  0&  1& -\lambda &1  &0  \\
   0&  1&  0&  1& -\lambda &1  \\
   1&  0&  1&  0&1 & -\lambda \\
\end{vmatrix}&=-9\lambda^4+\lambda^6\\
\end{align}
$$
But I have no idea how to calculate the determinants quickly by hand. Here is my question : What is the determinant in the $n$ by $n$ case?","['matrices', 'linear-algebra', 'determinant']"
54118,Do matrices with central symmetry form a group?,"Consider the set of $N\times N$ matrices that satisfy the property
$$\mathcal{H} = \{H\,|\, H_{ij}=H_{N+1-i,N+1-j}, \det H \neq 0\}$$
or in matrix forms
$$\begin{pmatrix}a_{1} & a_{2} & \cdots & a_{N-1} & a_{N}\\
b_{1} & b_{2} & \cdots & b_{N-1} & b_{N}\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
b_{N} & b_{N-1} & \cdots & b_{2} & b_{1}\\
a_{N} & a_{N-1} & \cdots & a_{2} & a_{1}
\end{pmatrix}$$ Do these matrices have a name? Do they form a group? It can be easily shown that the identity is in the group, i.e. $I\in \mathcal{H}$. Also the set is closed under multiplication, i.e. if $A\in \mathcal{H}$ and $B\in \mathcal{H}$ then $AB\in\mathcal{H}$. To see why, consider $$\begin{align*}
(AB)_{mn}&=\sum_i A_{mi}B_{in}=\sum_i A_{N+1-m,N+1-i}B_{N+1-i, N+1-n}\\
&=\sum_{i^\prime} A_{N+1-m,i^\prime}B_{i^\prime, N+1-n}=(AB)_{N+1-m,N+1-n}
\end{align*}$$ The last property that needs to be shown for the set to be a group is that the inverse is also in the set, i.e. if $A\in\mathcal{H}$, is it true that $A^{-1}\in\mathcal{H}$? EDIT:
Added the condition that matrices should also be invertible.","['matrices', 'group-theory']"
54124,"""Splitting"" determinant of a matrix","There is a thing that I don't understand about how the determinant of a matrix could be split this way:
$$
\begin{vmatrix}
a & b\\ 
c & d
\end{vmatrix}=

\begin{vmatrix}
a & 0\\ 
c & d
\end{vmatrix}
+
\begin{vmatrix}
0 & b\\ 
c & d
\end{vmatrix}
$$ I read that this ""split"" is possible because of some linearity property but I still cannot figure out how the ""split"" is formed. It could be even split further like:
$$
\begin{vmatrix}
a & 0\\ 
c & d
\end{vmatrix}
=
\begin{vmatrix}
a & 0\\ 
c & 0
\end{vmatrix}
+
\begin{vmatrix}
a & 0\\ 
0 & d
\end{vmatrix}
$$ How do these ""splitting"" go about?
Thanks for any help.","['matrices', 'linear-algebra']"
54133,eigenvalues of certain block matrices,"This question inquired about the determinant of this matrix:
$$
\begin{bmatrix}
  -\lambda &1  &0  &1  &0  &1  \\
   1& -\lambda &1  &0  &1  &0  \\
   0&  1& -\lambda &1  &0  &1  \\
   1&  0&  1& -\lambda &1  &0  \\
   0&  1&  0&  1& -\lambda &1  \\
   1&  0&  1&  0&1 & -\lambda
\end{bmatrix}
$$
and of other matrices in a sequence to which it belongs.  In a comment I mentioned that if we permute the indices 1, 2, 3, 4, 5, 6 to put the odd ones first and then the even ones, thus 1, 3, 5, 2, 4, 6, then we get this:
$$
\begin{bmatrix}
-\lambda & 0 & 0 & 1 & 1 & 1 \\
0 & -\lambda & 0 & 1 & 1 & 1 \\
0 & 0 & -\lambda & 1 & 1 & 1 \\
1 & 1 & 1 & -\lambda & 0 & 0 \\
1 & 1 & 1 & 0 & -\lambda & 0 \\
1 & 1 & 1 & 0 & 0 & -\lambda
\end{bmatrix}
$$
So this is of the form
$$
\begin{bmatrix}
A & B \\ B & A
\end{bmatrix}
$$
where $A$ and $B$ are symmetric matrices whose characteristic polynomials and eigenvalues are easily found, even if we consider not this one case of $6\times 6$ matrices, but arbitrarily large matrices following the same pattern. Are there simple formulas for determinants, characteristic polynomials, and eigenvalues for matrices of this latter kind? I thought of the Haynesworth inertia additivity formula because I only vaguely remembered what it said.  But apparently it only counts positive, negative, and zero eigenvalues.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'block-matrices']"
54135,Finding the correct pivot in Smith normal form,"I have been working through Smith normal form examples and I am wondering if I am finding the correct pivot in order to carry out the calculation. Let $V \subset \mathbb{Z}$ be an Abelian group with relation matrix $A$. $$
A = \begin{pmatrix}
2 & -6 & 0 \\
0 & 2 & -6 \\
-6 & 0 &  2 \end{pmatrix} 
$$ Question 1: For the case of entries in $\mathbb{Z}$, is the first step always to bring smallest integer to 1-1 position in the matrix? So we don't divide by 2 in this case right? (I was trying to do something similar to the matrix A  in the Wikipedia article but I have no idea how to make the first pivot 1 and still get $SNF(xI-A) = \begin{pmatrix}1&0  \\0 &(x-1)^2 \end{pmatrix}$ Applying my logic this is what I get for the Smith normal form (SNF) of the original problem $$\begin{pmatrix}
2 & -6 & 0 \\
0 & 2 & -6 \\
-6 & 0 &  2 \end{pmatrix}  \sim \begin{pmatrix}
2 & -6 & 0 \\
0 & 2 & -6 \\
0 & -18 &  2 \end{pmatrix} \sim \begin{pmatrix}
2 & 0 & 0 \\
0 & 2 & -6 \\
0 & -18 &  2 \end{pmatrix} \sim \begin{pmatrix}
2 & 0 & 0 \\
0 & 2 & -6 \\
0 & 0 &  52 \end{pmatrix}  \sim \begin{pmatrix}
2 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 &  52 \end{pmatrix}$$ Question 2: Is $V = \mathbb{Z}/2\mathbb{Z} \oplus \mathbb{Z}/2\mathbb{Z} \oplus \mathbb{Z} / 52\mathbb{Z}$ based on the above Smith normal form?","['smith-normal-form', 'linear-algebra', 'abstract-algebra']"
54136,Hamilton Path properties,As I understand a graph has a Hamilton Circuit if It has $n \ge 3$ vertexes degree of every vertex is at least $n/2$ $\deg u + \deg v \ge n$ for every pair of nonadjacent vertices $u$ and $v$ in the graph I can't seem to find a concrete set of properties for deciding if a graph has a Hamilton Path . Can anyone help me out? Please add some references/sources :),['discrete-mathematics']
54140,No diffeomorphism that takes unit circle to unit square,"This is not a homework problem. I am trying to learn my own from John M. Lee's Introduction to Smooth Manifolds . In Chapter 3, there is the problem 3-4 Let $C \subset \mathbb{R}^2$ be the unit circle, and let $S \subset \mathbb{R}^2$ be the boundary of the square of side 2 centred at origin: $S= \lbrace (x,y) \colon \max(|x|,|y|)=1 \rbrace.$ Show that there is a homeomorphism $F:\mathbb{R}^2 \to \mathbb{R}^2$ such that $F(C)=S$ , but there is no diffeomorphism with the same property. [Hint: Consider what $F$ does to the tangent vector to a suitable curve in $C$ ]. I can construct a homeomorphism (by placing the circle inside the square and then every radial line intersects the square at exactly one point). But, I don't know how to do the rest of the problem or understand the hint. I do not know how to write out what tangent space should be for the square. If there were a diffeomorphism then $F_\star$ is isomorphism between any two tangent space. If I show that the tangent space on the corner of square has dimension zero, would it solve problem?","['differential-geometry', 'diffeomorphism']"
54157,An exercise for eigenvalues and eigenvectors,"The following is from an exercise in Gilbert Strang's Linear Algebra and its Applications : Suppose $A$ has eigenvalues $0,3,5$ with independent eigenvectors $u,v,w$. Find a particular solution to $Ax = v+w$. Find all solutions. It is not difficult to find that the particular solution can be $\frac{1}{3}v+\frac{1}{5}w$. 
Here is my question : How should I find all solutions for the equation? If the equation is $Ax = 0$, one needs to find a basis for the null space of $A$. However in this case, the right hand side is $v+w$.",['linear-algebra']
54158,The cartesian product $\mathbb{N} \times \mathbb{N}$ is countable,"I'm examining a proof I have read that claims to show that the Cartesian product $\mathbb{N} \times \mathbb{N}$ is countable, and as part of this proof, I am looking to show that the given map is surjective (indeed bijective), but I'm afraid that I can't see why this is the case. I wonder whether you might be able to point me in the right direction? Indeed, the proof begins like this: ""For each $n \in \mathbb{N}$, let $k_n, l_n$ be such that $n = 2^{k_n - 1} \left(2l_n - 1 \right)$; that is, $k_n - 1$ is the power of $2$ in the prime factorisation of $n$, and $2 l_n - 1$ is the (necessarily odd) number $\frac{n}{2^{k_n - 1}}$."" It then states that $n \mapsto \left(k_n , l_n \right)$ is a surjection from $\mathbb{N}$ to $\mathbb{N} \times \mathbb{N}$, and so ends the proof. I can intuitively see why this should be a bijection, I think, but I'm not sure how to make these feelings rigorous? I suppose I'd say that the map is surjective since given any $\left(k_n , l_n \right) \in \mathbb{N} \times \mathbb{N}$ we can simply take $n$ indeed to be equal to $2^{k_n - 1} \left(2l_n - 1 \right)$ and note that $k_n - 1 \geq 0$ and thus $2^{k_n - 1}$  is both greater or equal to one so is a natural number (making the obvious inductive argument, noting that multiplication on $\mathbb{N}$ is closed), and similarly that $2 l_n - 1 \geq 2\cdot 1 - 1 = 1$ and is also a natural number, and thus the product of these two, $n$ must also be a natural number. Is it just as simple as this? I suppose my gut feeling in the proving that the map is injective would be to assume that $2^{k_n - 1} \left(2 l_n - 1 \right) = 2^{k_m - 1} \left(2 l_m - 1 \right)$ and then use the Fundamental Theorem of Arithmetic to conclude that $n = m$. Is this going along the right lines? The 'implicit' definition of the mapping has me a little confused about the approach. On a related, but separate note, I am indeed aware that if $K$ and $L$ are any countable sets, then so is $K \times L$, so trivially, taking the identity mapping we see trivially that this map is bijective and therefore that $\mathbb{N}$ is certainly countable (!), and thus so is $\mathbb{N} \times \mathbb{N}$. Hence, it's not really the statement that I'm interested in, but rather the exciting excursion into number theory that the above alternative proof provides.","['cardinals', 'elementary-set-theory']"
54163,"Lebesgue outer measure of $[0,1]\cap\mathbb{Q}$","Consider the Lebesgue outer measure 
$$
\bar{m}(X) = \inf_{A \supset X}\bigg\{\sup_{P\subset A}\quad m(P)\bigg\}
$$
where $X = [0,1]\cap \mathbb{Q}$ and $P = \bigcup [a_i,b_i]$  is a suitable union of intervals.
My question is: suppose that $\bar{m}(X)=0$: can you exhibit one of those $A$'s? Thanks",['measure-theory']
54172,The $\sigma$-algebra of subsets of $X$ generated by a set $\mathcal{A}$ is the smallest sigma algebra including $\mathcal{A}$,"I am struggling to understand why it should be that the $\sigma$-algebra of subsets of $X$ generated by $\mathcal{A}$ should be the smallest $\sigma$-algebra of subsets of $X$ including $\mathcal{A}$. Let me try to elucidate my understanding of the topic, in the hope that somebody patient and kind might be able to fill in the gaps. If $X$ is a set, and $\mathcal{G}$ is any non-empty family of $\sigma$-algebras of subsets of $X$, then I am very happy that $$ \bigcap \mathcal{G} := \left\{ E : E \in \Sigma, \forall \Sigma \in \mathcal{G} \right\},$$ the intersection of all the $\sigma$ algebras belonging to $\mathcal{G}$ is a $\sigma$-algebra of subsets of $X$. Now, if $\mathcal{A}$ is any any of subsets of $X$, then defining $$ \mathcal{G} := \left\{ \Sigma : \Sigma \ \textrm{is a } \sigma \textrm{-algebra of subsets of } X, \mathcal{A} \subseteq \Sigma \right\},$$ then we have by definition that $\mathcal{G}$ is a family of $\sigma$-algebras of subsets of $X$; also, since $\mathcal{P} X \in \mathcal{G}$ we have that it is non-empty. So $\Sigma_{\mathcal{A}} := \bigcap \mathcal{G}$, called the $\sigma$-algebra of subsets of $X$ generated by $\mathcal{A}$, is a $\sigma$-algebra of subsets of $X$. Because $\mathcal{A} \subseteq \Sigma$ for every $\Sigma \in \mathcal{G}$, we have $\mathcal{A} \subseteq \Sigma_{\mathcal{A}}$; thus $\Sigma_{\mathcal{A}}$ itself belongs to $\mathcal{G}$. However, I cannot get my head around why it should be that $\Sigma_{\mathcal{A}}$ should be the smallest $\sigma$-algebra of subsets of $X$ including $\mathcal{A}$, perhaps because I am not entirely sure what this statement means explicitly (namely, I have problems interpreting 'smallest' and 'including')! I'd be very relieved if someone could try to explain this to me as it has been bugging me for a week now; I have a feeling that it might rely heavily on the $\bigcap$, but I'm not sure exactly how...","['measure-theory', 'descriptive-set-theory']"
54176,Is there a geometric meaning of the Frobenius norm?,"I have a positive definite matrix $A$. I am going to choose its Frobenius norm $\|A\|_F^2$ as a cost function and then minimize $\|A\|_F^2$. But I think I need to find a reason to convince people it is reasonable to choose $\|A\|_F^2$ as a cost function. So I'm wondering if there are some geometric meanings of the Frobenius norm. Thanks. Edit : here $A$ is a 3 by 3 matrix. In the problem I'm working on, people usually choose $\det A$ as a cost function since $\det A$ has an obvious geometric interpretation: the volume of the parallelepiped determined by $A$. Now I want to choose $\|A\|_F^2$ as a cost function because of the good properties of $\|A\|_F^2$. That's why I am interested in the geometric meaning of $\|A\|_F^2$.","['matrices', 'geometry', 'normed-spaces', 'linear-algebra']"
54194,Zorn's lemma in abstract algebra?,It is well known that Zorn's lemma implies: Prop.1 Every commutative unital ring has a maximal ideal. Prop.2 Every proper ideal is contained in a maximal ideal in a unital ring. Question: Can we prove the above propositions without Zorn's lemma?,"['set-theory', 'abstract-algebra', 'axiom-of-choice']"
54197,Can a Dirac delta function be a probability density function of a random variable?,"Can the Dirac delta function (or distribution) be a probability density function of a random variable. To my knowledge, it seem to satisfy the conditions. To my interpretation getting a positive real number as the outcome is 1 and that for a negative real number is zero. I wonder what could be the expected value. My question is, whether it is a valid probability density function of a random variable.",['probability-theory']
54206,"If F is a field, then $F[x,y]$ is a Principal Ideal Domain?","Let $F$ be a field, and $F[x,y]$ be a ring of polynomials in two variables. Is $F[x,y]$ a Principal Ideal Domain? Also show that $F[x,y]/(y^2-x)$ and $F[x,y]/(y^2-x^2)$ are not isomorphic for any field $F$.","['principal-ideal-domains', 'abstract-algebra']"
54214,Showing that a function is analytic,"Let $f: \partial D(0,1) \mapsto \mathbb{R}$ be continuous. Define $g: D(0,1) \mapsto \mathbb{C}$ by $g(z)= \frac{1}{2\pi} \int_{-\pi}^{\pi} f(e^{i\theta}) \frac{e^{i\theta}+z}{e^{i\theta}-z} d\theta$ . Show that $g$ is analytic. I don't know how to do this. Maybe I can use the definition or the Cauchy Riemann equations but there must be a more elegant way of proving that a function defined by a integral is analytic. Thx.",['complex-analysis']
54232,Difference between bijection and isomorphism?,"First, let me admit that I suffer from a fundamental confusion here, and so I will likely say something wrong. No pretenses here, just looking for a good explanation. There is a theorem from linear algebra that two vector spaces are isomorphic if and only if they have the same dimension. It is also well-known that two sets have the same cardinality if and only if there exists a bijection between them. Herein lies the issue... Obviously $|\mathbb{R}| = |\mathbb{R^2}| = \mathfrak c.$ This is often stated as ""there are as many points in the plane as there are on a line."" Why, then, are $\mathbb{R}$ and $\mathbb{R^2}$ not isomorphic? It makes intuitive sense that they shouldn't be. After all, I can only ""match up"" each point in $\mathbb{R}$ with the first coordinate of $\mathbb{R^2}.$ I cannot trust this intuition, however, because it fails when considering the possibility of a bijection $f : \mathbb{N} \rightarrow \mathbb{Q}!$ Even more confusing: As real vector spaces, $\mathbb{C}$ is isomorphic to $\mathbb{R^2}.$ However there is a bijection between $\mathbb{C}$ and $\mathbb{R}$ (just consider the line $\rightarrow$ plane example as above). If you can explain the error in my thinking, please help!","['linear-algebra', 'elementary-set-theory']"
54235,Rules for Factorisation?,"Basically presented with this, simplify \begin{aligned}
{\Bigl(\sqrt{x^2 + 2x + 1}\Big)  +  \Bigl(\sqrt{x^2 - 2x + 1}\Big)} 
\end{aligned} Possible factorisations into both \begin{aligned}
{\Bigl({x + 1}\Big)^2}, {\Bigl({x - 1}\Big)^2} 
\end{aligned} \begin{aligned}
{\Bigl({1 + x}\Big)^2} , {\Bigl({1 - x}\Big)^2} 
\end{aligned} Hence when simplified, answer has two possibilities. One independent of x, and the other not. ( Simplified Answers: 2x, 2 ) Why is one independent and the other not? If such is equal to 2, why then when, say x=2, the answer does not simplify to 2?",['algebra-precalculus']
54246,Probability that a random binary matrix is invertible? [duplicate],"This question already has an answer here : Probability of a random $n \times n$ matrix over $\mathbb F_2$ being nonsingular (1 answer) Closed 4 years ago . What is the probability that a random $\{0,1\}$, $n \times n$ matrix is invertible?
Assume the 0 and 1 are each present in an entry with probability $\frac{1}{2}$.
Is there an explicit formula as a function of $n$?  Does it tend to 1 as $n$ grows large?
I'm sure this is all known... Thanks!","['random-matrices', 'matrices', 'linear-algebra', 'probability']"
54276,Is it always valid to cancel something like (x-2) in the numerator and denominator of a rational function?,"What is the difference between $f(x) = \dfrac{(x + 2)(x - 2)}{x (x - 2)}$ and $g(x) = \dfrac{x + 2}{x}$?  Can you always cancel the (x - 2) factor?  Isn't an asymptote lost when that is done?  When I evaluate it at $x=2$ with a computer, like Wolfram Alpha or something, the software always seems to cancel and then evaluate.  That's why I'm confused.  I would think it should be undefined. Edit:  Actually, I should have used the term ""undefined point"" rather than ""asymptote"".  What I'm actually interested in is the derivative.  Does the derivative have to preserve this undefined point or not?  It seems to me that I should preserve the $(x-2)$ when calculating the derivative in order to preserve the undefined point, but the computer invariably cancels it.","['calculus', 'algebra-precalculus']"
54309,Order of solving definite integrals,"I've been coming across several definite integrals in my homework where the solving order is flipped, and am unsure why.  Currently, I'm working on calculating the area between both intersecting and non-intersecting graphs. According to the book, the formula for finding the area bounded by two graphs is $$A=\int_{a}^{b}f(x)-g(x) \mathrm dx$$ For example, given $f(x)=x^3-3x^2+3x$ and $g(x)=x^2$ , you can see that the intersections  are $x={0, 1, 3}$ by factoring.  So, at first glance, it looks as if the problem is solved via $$\int_0^1f(x)-g(x)\mathrm dx+\int_1^3f(x)-g(x)\mathrm dx$$ However, when I solved using those integrals, the answer didn't match the book answer, so I took another look at the work.  According to the book, the actual integral formulas are $$\int_0^1f(x)-g(x)\mathrm dx+\int_1^3g(x)-f(x)\mathrm dx$$ I was a little curious about that, so I put the formulas in a grapher and it turns out that $f(x)$ and $g(x)$ flip values at the intersection $x=1.$ So how can I determine which order to place the $f(x)$ and $g(x)$ integration order without using a graphing utility?  Is it dependent on the intersection values?","['calculus', 'integration']"
54322,Using the Mean Value Theorem to Evaluate an Integral of a Sequence of Functions?,"The following statement should be true, I think, but I'm having a hell of a time trying to prove it: Let $f_n$ be a $C^1$ function on $[0,a]$, satisfying $f_n = 1$ on $[1/n,a]$ and $0\le f_n \le 1$ and $f_n(0)=0$. Let $\phi$ be a continuous function on $[0,a].$ I want to say that $\lim_{n\to\infty} \int_0^a f_n'(x) \phi(x) dx = \phi(0)$. If $\phi$ is $C^1$, I can just do integration by parts to prove this. But I'm not sure what to do if $\phi$ is just continuous. This is what I have so far. Using the mean value theorem, we have $\int_0^a f_n'(x)\phi(x) dx = \int_0^{1/n} f_n'(x)\phi(x) dx= \frac{1}{n}f_n'(c_n) \phi(c_n)$ where $0<c_n<1/n$. I think I need to use the mean value theorem on $f_n$ and continuity of $f_n'$ to show that $\frac{1}{n}f_n'(c_n)$ goes to 1 as $n\to\infty$, but I can't seem to figure out how to do this... can someone throw me a hint?",['real-analysis']
54337,What's the term for the number of outputs a function has?,"That is, if a function's arity is the number of inputs it has, its __ is the number of outputs it has. (Fill in the blank.)","['terminology', 'functions']"
54344,Interesting integral $\int_{0}^{1}\frac{\tanh^{-1}x\ln x}{x(1-x^{2})}{ d}x$,"I ran across an integral that is rather tough and I am wondering if anyone could give me a shove in the right direction. $$\int_{0}^{1}\frac{\tanh^{-1}x\ln x}{x(1-x^{2})}{ d}x=-\frac{7}{16}\zeta(3)-\frac{{\pi}^{2}}{8}\ln(2)$$ This solution is almost exactly like the solution to $\int_{0}^{\frac{\pi}{2}}x\ln(\sin(x))\text{ d}x=\frac{7}{16}\zeta(3)-\frac{{\pi}^{2}}{8}\ln(2)$ I solved the latter integral by using the identity $\displaystyle -\ln(\sin(x))-\ln(2)=\sum_{k=1}^{\infty}\frac{\cos(2kx)}{k}$ , then integrating: $\displaystyle -\int_{0}^{\frac{\pi}{2}}x\ln(\sin(x))\text{ d}x-\frac{{\pi}^{2}}{8}\ln(2)=\int_{0}^{\frac{\pi}{2}}x\cos(2x)\text{ d}x+\frac{\int_{0}^{\frac{\pi}{2}}\cos(4x)\text{ d}x}{2}+\frac{\int_{0}^{\frac{\pi}{2}}\cos(6x)}{3}\cdot\cdot\cdot\cdot$ But, $\displaystyle \int_{0}^{\frac{\pi}{2}}x\cdot \cos(2kx)\text{ d}x=-\left(\frac{1+(-1)^{k+1}}{(2k)^{2}}\right)$ Thus: $\displaystyle \int_{0}^{\frac{\pi}{2}}x\ln(\sin(x))\text{ d}x=\frac{1}{4}\sum_{k=1}^{\infty}\frac{1+(-1)^{k+1}}{k^{3}}-\frac{{\pi}^{2}}{8}\ln(2)$ $\displaystyle =\frac{1}{2}\displaystyle\sum_{k=0}^{\infty}\frac{1}{(2k+1)^{3}}-\frac{{\pi}^{2}}{8}\ln(2)$ and so on.  Which results in the solution I mentioned in the beginning. Sorry for all that, but I wanted to show you what I was using in order to some how relate it to the integral I am wanting to solve.
I have been trying and trying to relate the aforementioned $\displaystyle \tanh$ integral with this one.  The solutions are so nearly the same, I figured there has to be a way to relate them and solve the integral.  Does anyone have some ideas?. I have tried the identity $\displaystyle \tanh^{-1}(x)=\frac{1}{2}\left[\ln(1+x)-\ln(1-x)\right]$ , then breaking it up: Resulting in $\displaystyle \frac{1}{2}\int_{0}^{1}\frac{\ln(x)\ln(1+x)}{x(x^{2}-1)}\text{ d}x-\frac{1}{2}\int_{0}^{1}\frac{\ln(x)\ln(1-x)}{x(x^{2}-1)} \text{ d}x$ ,  then I used the various series representations for $\displaystyle \ln(1+x)$ , $\displaystyle \frac{1}{1-x^{2}}$ , etc. I tried double integrals, but I always get stuck. I even broke it up per partial fraction expansion, but several of the resulting integrals were still nasty. Does anyone have some clever ideas?.","['definite-integrals', 'trigonometric-integrals', 'calculus', 'integration']"
54354,Arbitrary products of quasi-coherent sheaves?,"I have a short question: Does the category of quasi-coherent sheaves on a scheme have arbitrary products? I know that it does if the scheme is affine and I know that they will not be isomorphic to the product as $\mathcal{O}_{X}$-modules, but I haven't been able to find a counterexample. Any help is appreciated!","['algebraic-geometry', 'homological-algebra', 'quasicoherent-sheaves', 'category-theory', 'abelian-categories']"
54355,The gradient as a row versus column vector,"Kaplan's Advanced Calculus defines the gradient of a function $f : \mathbb{R^n} \to \mathbb{R}$ as the $1 \times n$ row vector whose entries respectively contain the $n$ partial derivatives
of $f$ . By this definition then, the gradient is just the Jacobian matrix of the transformation. We also know that using the Riesz representation theorem, assuming $f$ is differentiable at the point $x$ , we can define the gradient as the unique vector $\nabla f$ such that $$ df(x)(h) = \langle h, \nabla f(x) \rangle, \quad h \in \mathbb{R}^n $$ Assuming we ignore the distinction between row vectors and column vectors, the former definition
follows easily from the latter. But, row vectors and column vectors are not the same things. So,
I have the following questions: Is the distinction here between row/column vectors important? If (1) is true, then how can we know from the second defintion that the vector
in question is a row vector and not a column vector?","['multivariable-calculus', 'scalar-fields', 'real-analysis']"
54357,"Bernoulli's representation of Euler's number, i.e $e=\lim \limits_{x\to \infty} \left(1+\frac{1}{x}\right)^x $ [duplicate]","This question already has answers here : Closed 12 years ago . Possible Duplicates: Finding the limit of $n/\sqrt[n]{n!}$ How come such different methods result in the same number, $e$? I've seen this formula several thousand times: $$e=\lim_{x\to \infty} \left(1+\frac{1}{x}\right)^x $$ I know that it was discovered by Bernoulli when he was working with compound interest problems, but I haven't seen the proof anywhere. Does anyone know how to rigorously demonstrate this relationship? EDIT:
Sorry for my lack of knowledge in this, I'll try to state the question more clearly. How do we prove the following? $$ \lim_{x\to \infty} \left(1+\frac{1}{x}\right)^x = \sum_{k=0}^{\infty}\frac{1}{k!}$$","['limits', 'sequences-and-series', 'analysis']"
54377,A question connected with the decomposition of a functional on $C(X)$ on Riesz and Banach functionals,"Let $X$ be a metric space and let $C(X)$ be a family of all bounded and  continuous functions from $X$ in $\mathbb{R}$. We call a positive linear functional $\varphi: C(X) \rightarrow \mathbb{R}$ the functional of Riesz if there is a borel measure $\mu$ on $X$, such that $\varphi(f)=\int_X f \,d\mu$, for $f\in C(X)$. We call a positive linear functional $\varphi: C(X) \rightarrow \mathbb{R}$ the functional of Banach if for each borel measure $\nu$ on $X$ the condition:$\int_X f d\nu\leq \varphi(f)$, for $f\in C(X)$ - implies that $\nu$ is trivial. There is a well known theorem : Let $X$ be a polish space. Then, for each positive linear functional $\varphi: C(X) \rightarrow \mathbb{R}$ there is a unique couple $(\varphi_0,\varphi_*)$ of positive linear functionals defined on $C(X)$, such that $\varphi_0$ is the functional of Riesz, $\varphi_*$ is the functional of Banach and $\varphi=\varphi_*+\varphi_0$. Moreover, the measure $\mu$ related to $\varphi_0$ is defined by: $$\mu(K)=\inf\{\varphi(f): f\in C(X), 1_X\geq f \geq 1_K\},$$  for each compact set $K\subset X$. More pecisely, for the proof, we define:
$$\varphi_{\delta}(f)=\sup\{\varphi(h): \mbox{ supp}\,h\in N(\delta), 0\leq h\leq f\},$$ for $\delta>0$, $$\varphi_{0}(f)=\lim\limits_{\delta \to 0^+}\varphi_{\delta}(f),$$ for $f\in C(X), f\geq 0$, and $$\varphi_{0}(f)=\varphi_{0}(f^+)-\varphi_{0}(f^-),$$ for $f \in C(X)$, where $N(\delta)$ is a family of sets that possess a covering composed of finite number of open balls with a radius equal to $\delta$. My question concerns the truth of the following sentence:  Let $X$ be a $\sigma$-compact and polish space. Assume that $\varphi^x:C(X) \rightarrow \mathbb{R}$ is a positive linear functional, for all $x \in X$ and let $((\varphi^x)_0,(\varphi^x)_*)$ be a couple of Banach-Riesz functionals, for $x \in X$. If the mapping $X \ni x \mapsto  \varphi^x(f)$ is continuous for all $f \in C(X)$ and $\varphi^x(1_X)=1$, for $x \in X$, then mapping $X \ni x \mapsto  (\varphi^x)_0(f)$ is continuous for all $f \in C(X)$ (or may be for only $f \in C_c(X)$). I was able to proof only that the mapping $X \ni x \mapsto  (\varphi^x)_0(f)$ is upper semi-continuous, for $f\in C_c(X)$.","['probability-theory', 'measure-theory', 'real-analysis']"
54385,Decomposing a Bounded Linear Functional on Lp as a difference of Positive Bounded Linear functionals,"I am learning Measure theory via self study of Bartle ""The elements of Integration and Lebesgue Measure"". I was stumped by the reasoning in one of the decomposition proofs. The point is to show that a Bounded Linear Functional can be represented as the difference of two positive bounded linear functionals. The proof presented is as follows. Define $G^+ = sup\{G(f) : g \in L_p : 0 \le g \le f\}$ for all $f \ge 0$. The next step is to ST $G^+$ is a BLF (Bounded Linear Functional). It is clear that $G^+(cf) = c G^+ (f)$ for $c \ge 0$, $f \ge 0$ (This part was not a problem). 
The next step attempts to prove that given $f_j \ge 0, G^(f_1 + f_2) = G^+(f_1) + G^+(f_2)$ This is where I got confused and did not quite understand the line of reasoning. This is how the proof continues: If $0 \le g_j \le f_j$ Then $G(g_1) + G(g_2) = G(g_1 + g_2) \le G^+(f_1 + f_2)$ Taking supremum over all $g_j \in L_p$ we claim that $G^+(f_1) + G^+(f_2) \le G^+(f_1 + f_2)$ I would have thought that it would be te other way around, i.e. $sup\{G(g_1) : g_1 \in L_p, 0 \le g_1 \le f_1 \}$ + $sup\{G(g_2) : g_2 \in L_p, 0 \le g_2 \le f_2 \}$ >= $sup\{G(g_1  + g_2) : g_1, g_2 \in L_p, 0 \le g_j \le f_j\}$ Which implies $G^+(f_1) + G^+(f_2) \ge G^+(f_1 + f_2)$ The book continues:
Conversely if $0 \le h \le f_1 + f_2$ let $g_1 = sup(h - f_2,0)$  and $g_2 = inf(h, f_2)$. It follows that $g_1 + g_2 = h$  and that $0 \le g_j \le f_j$. Threfore $G(h) = G(g_1) + G(g_2) \le G^+(f_1) + G^+(f_2)$ Since this is true for all $h \in L_p$ we have 
$G^+(f_1 + f_2) = G^+(f_1) + G^+(f_2)$ My questions were: Why would $G^+$ be positive? How did the final conclusion $G^+(f_1 + f_2) = G^+(f_1) + G^+(f_2)$ for f_1, f_2 in L_p follow? I would have thougt that the definition for $G^+$ should have been $G^+ = sup\{G(f) : g \in L_p : 0 \le g \le f, G(g) \ge 0\}$","['measure-theory', 'functional-analysis']"
54386,Analytic functions of absolute value 1 on the boundary of the unit disc,"Is there a characterization of analytic functions $f$ on the unit disc such that $|f(z)|=1$ for $|z|=1$? If $f$ only has a zero $a\in D(0,1)$ of order $n$, then $f(z)=\phi_a(cz^n)$ for some constant $|c|=1$ where $\phi_a$ is the Möbius transformation at $a$. One can iterate this process in the case when $f$ has distinct zeroes, but is there a cleaner formula than something that looks like $\phi_{a_1}(c_1z^{n_1}\phi_{a_2}(c_2 z^{n_2}\cdots \phi_{a_N}( c_N z^{n_N})\cdots)$? Thanks!",['complex-analysis']
54388,Presentations of the ring of modular forms,"I have seen two ways of describing the ring structure of modular (with respect to the full $SL (2, \mathbb Z)$) forms: $\mathbb C [E_4, E_6]$ and $\mathbb C [E_4,E_6, \Delta]/(E_4^3-E_6^2-1728\Delta )$, where $E_4$ and $E_6$ are the normalized Eisenstein series of weight 4 and 6, respectively. As far as I've always known, every level 1 modular form is a polynomial in $E_4$ and $E_6$ so the first description is completely appropriate.  The second one has the virtue of promoting $\Delta$ to a special place in the ring, but since $E_4$, $E_6$, and $\Delta$ do satisfy the well known relationship $E_4^3-E_6^2=1728\Delta$ nothing is really gained.  So, unless I'm missing something, these two presentations are equivalent. My question is then about a distinction that seems to be made in a paper by Sati: OP2 Bundles in M-theory .  In section 3 he describes the ring of modular forms as $\mathbb Z [E_4,E_6, \Delta]/(E_4^3-E_6^2-1728\Delta )$ and he states, by results of Mahowald and Hopkins, that there are certain manifolds which map under the Witten genus to the ring $\mathbb Q [E_4, E_6]$, indicating that these are modular forms ""without the discriminant."" I guess I don't really understand what this last part means.  Can somebody please clarify this issue for me?  Thanks in advance.","['modular-forms', 'number-theory']"
54391,Do there exist any visual representations of prime factorizations?,"Introduction:
The question that I really want to ask is, “Are there any well-known visual representations for the integers $\ge 2$, with perhaps one of them even being regarded as canonical?” However, since concrete questions are almost always more interesting/memorable/concise than abstract questions, I gave the title question that I did. In order to show where I’m coming from, let me present this as a combination of a draft followed by a critique. Draft
Observe that the set of polynomials with non-negative integer coefficients maps bijectively with the set of integers $\ge 2$ in a natural way, namely, that given such a polynomial, whose coefficients are a(n), … a(1), a(0), the corresponding integer is the one such that the exponent of the k-th prime in its canonical prime factorization (ie, the primes occurring in ascending sequence) is a(k-1). For example, if the coefficients are 2, 0, 1, 3, then the corresponding integer is 49 x 3 x 8 = 2976. (This bijective mapping seems to me so obvious and natural, that I can’t believe that no one has ever explored it before, and yet I don’t recall seeing any such discussion of it in the literature, but anyway, that is why I included the tag “reference-request” on this question.) Now, the roots of these polynomials may or may not be of interest, but what we want to focus on (no pun intended), is presenting the sequence consisting of the graphs of these polynomials rapidly, like the frames of in a movie film, that is, like a movie. Does this movie show any striking visual pattern? Or perhaps the n-th frame should consist not simply of the graph of the polynomials for (n + 1), but of the sum of the first n such polynomials. Anyway, does the movie show any striking visual pattern? Critique
In the draft, we ignored the issue of what the (algebraic) sign of a given coefficient should be, simply assuming that they should all be non-negative. However, bearing in mind the example of the determinant (of a square matrix), in which negative signs are alternately assigned, perhaps we should specify that, say, the coefficients of the terms of odd index be negative. Many such schemes of specifying negative coefficients are possible. Indeed, there are infinitely many possible schemes, because the scheme might not be independent of the degree of the polynomial. So, the question is, which scheme is best, in terms of generating a visual pattern when the movie is played? If we don’t know, we could pick some promising/plausible ones and then just run them and see which gives the best results. Moreover, one may object that the visual representations need not depend on the prime factorizations, but on something else (hence the more general question that I gave in the introduction). OK, Lights! Camera! Action!","['reference-request', 'number-theory']"
54397,The identity cannot be a commutator in a Banach algebra?,"The Wikipedia article on Banach algebras claims, without a proof or reference, that there does not exist a (unital) Banach algebra $B$ and elements $x, y \in B$ such that $xy - yx = 1$. This is surprising to me, but maybe the proof is straightforward; anyone have a proof and/or a reference? More generally, I would have naively thought that I could embed any ring into a Banach algebra. I guess there are actually serious restrictions to doing this; are these issues discussed anywhere?","['banach-algebras', 'functional-analysis']"
54414,Why does this expression equal $\pi$?,"I noticed that the following expression equals $\pi$ and I was curious as to why. Is it just a coincidence, or is there a meaningful explanation? $$\int_{-\infty}^\infty\frac{1}{x^2+1}~dx=\pi$$","['pi', 'calculus', 'integration']"
54425,The signed curvature of the Catenary,"Now I want to show that the signed curvature of the catenary, with parameterization
$$(t,\cosh(t))$$
is $k(t)=\frac{1}{\cosh^2(t)}$ Now what I have done (and presumably went astray), is first normalize the tangent vector to $\alpha (t)=(t,\cosh(t))$, to get: $$\gamma (t)=\frac{\alpha '(t)}{|\alpha ' (t)|} = \left(\frac{1}{\cosh(t)},\tanh(t)\right).$$ And using the fact that the normal to $\gamma$ is $n(t)= \left(-\tanh(t),\frac{1}{\cosh(t)}\right)$
and that $$k(t) = \gamma '(t) \cdot n(t) ,$$ I get by inserting $$\gamma ' (t) = \left(-\frac{\sinh(t)}{\cosh^2(t)},\frac{1}{\cosh^2(t)}\right),$$ $$k(t)=\frac{1}{\cosh(t)}.$$ Where did I get it wrong? Thanks in advance.","['plane-curves', 'differential-geometry']"
54435,Solving a differential equation,"OK, so, I'm supposed to solve the differential equation
$$\frac{dy}{dx} = \frac{y+2x}{y-2x}$$ 
by making the substitution $y = ux$, to make the equation separable. Then 
$$\frac{dy}{dx} = u + x\frac{du}{dx},$$
which changes the equation to
$$\frac{1}{x} dx = \frac{2-u}{u^2-3u-2}du,$$
and then by integrating I get
$$\ln|x|+C = \frac{1}{2\sqrt{17}} \left[ (1-\sqrt{17}) \ln\,\left| u-\frac{3+\sqrt{17}}{2}\right| - (1+\sqrt{17}) \ln\, \left|u-\frac{3-\sqrt{17}}{2} \right| \right].$$ Assuming I did that correctly, my question then becomes: if I resubstitute in for $u \ldots$ is that it? I don't think I can isolate $y$ from this, and Wolfram|Alpha seems to agree with me. I mean, is this implicit solution acceptable? This isn't the whole story, however; I've found two linear solutions,
$$y = \left(\frac{3 \pm \sqrt{17}}{2}\right)x,$$
to the differential equation essentially by showing that $d^2y/dx^2 \rightarrow 0$ as $x\rightarrow\pm\infty$ and then subtituting $y=Ax$. Notwithstanding the fact that it yielded correct solutions, though, I can't vouch for the validity of this method, as I already knew that those were correct and invented some fanciful method for deriving them...
If this has any value to it, some basic instruction would be enormously appreciated.",['ordinary-differential-equations']
54448,Combinatorial proof: $e^x=\sum\limits_{k=0}^{\infty}\frac{x^k}{k!}$,"Using notion of derivative of functions from Taylor formula follow that $$e^x=\sum_{k=0}^{\infty}\frac{x^k}{k!}$$ Is there any elementary combinatorial proof of this formula here is my proof for $x$ natural number Denote by $P_k^m$ number of $k$-permutations with unlimited repetitions of elements from a $m$-set then we can prove that
$$P_k^m=\sum_{r_0+r_1+...+r_{m-1}=k}\frac{k!}{r_0 !...r_{m-1}!}$$
also is valid
$$P_k^m=m^k$$
Based on first formula we can derive that
$$\sum_{k=0}^{\infty}P_k^m\frac{x^k}{k!}=\left(\sum_{k=0}^{\infty}\frac{x^k}{k!}\right)^m$$
from second formula
$$\sum_{k=0}^{\infty}P_k^m\frac{x^k}{k!}=\sum_{k=0}^{\infty}\frac{(mx)^k}{k!}$$
now is clear that 
$$\sum_{k=0}^{\infty}\frac{(mx)^k}{k!}=\left(\sum_{k=0}^{\infty}\frac{x^k}{k!}\right)^m$$
from last equation for $x=1$ taking in account that
$$\sum_{k=0}^{\infty}\frac{1}{k!}=e=2,71828...$$
we have finally that for natural number $m$ is valid formula
$$e^m=\sum_{k=0}^{\infty}\frac{m^k}{k!}$$","['exponential-function', 'combinatorial-proofs', 'real-analysis', 'analysis', 'combinatorics']"
54456,The bijection between homogeneous prime ideals of $S_f$ and prime ideals of $(S_f)_0$,"It is well-known that if $S$ is a graded ring, and $f$ is a homogeneous element of positive degree, then there is a bijection between the homogeneous prime ideals of the localization $S_f$ and the prime ideals of $S_{(f)}$, the subring of $S_f$ comprising the homogeneous elements of degree $0$. This is proposition II.2.5b in Hartshorne, exercise 5.5B in Ravi Vakil's notes $[1]$ (p. $130$ of the February $24$, $2012$ version), and proposition 8.1.21 of Akhil Mathew's notes $[2]$ (p. $136$). Unfortunately I cannot follow any of those proofs to my own satisfaction, perhaps because I'm not well-versed in commutative algebra. The crux of the proof appears to be to show that, given a homogeneous prime ideal $\mathfrak{p}$ of $S$ not containing $f$, the construction used to obtain a prime ideal $\Psi (\mathfrak{q})$ of $S$ from a prime ideal $\mathfrak{q}$ of $S_{(f)}$ will recover $\mathfrak{p}$ when $\mathfrak{q} = S_f  \mathfrak{p} \cap S_{(f)}$. To be precise, let $\Psi (\mathfrak{q})$ be the homogeneous ideal of $S$ generated by
$$\bigcup_{d \in \mathbb{N}} \{ s \in S_d : s / f^d \in \mathfrak{q} \}$$
and let $\Phi (\mathfrak{p}) = S_f \mathfrak{p} \cap S_{(f)}$. It's easy to see that $\Phi \circ \Psi$ acts as the identity on $\operatorname{Spec} A$ (or, for that matter, the set of all ideals of $A$), but I cannot see any obvious reason why $\Psi \circ \Phi$ should act as the identity on the set of prime ideals of $S$ not containing $f$. A detailed proof of this point would be much appreciated. References $[1]$ Foundations of Algebraic Geometry . $[2]$ Algebraic geometry notes (covers material at the level of the first and second volume of EGA): html page , and pdf file .","['commutative-algebra', 'algebraic-geometry', 'graded-rings']"
54467,"The integral $\int_0^8 \sqrt{x^4+4x^2}\,dx$","$\displaystyle \int\nolimits_0^8 \sqrt{x^4+4x^2}\,dx$. Alright, so I thought I had this figured out. Here's what I did: I factor out an $x^2$ to get $\sqrt{x^2(x^2+4)}$. I let $x = 2\tan(\theta)$, therefore the integrand is $\sqrt{4\tan^2(\theta)  (4\tan^2(\theta) + 4)}$. Factor out a 4 and it becomes $\sqrt{(16\tan^2(\theta)  (\tan^2(\theta) + 1))}$ Which equals $\sqrt{16\tan^2(\theta) \sec^2(\theta)}$ This is easy to take the sqrt of. The integrand becomes $4\tan(\theta)\sec(\theta)$. Now, the integral of this is $4\sec(\theta)$ And it's evaluated from $0$ to $\arctan(4)$ right? Because as $x$ goes to $0$, so does $\theta$, and as $x$ goes to $8$, $\theta$ goes to $\arctan(4)$... But the end result $(4 (\sec(\arctan(4)) - 1) )$ isn't the correct answer I put it into WolframAlpha and I get $(8/3) (17\sqrt{17} - 1)$, which is the right answer. How did they get that? (there's no ""show steps"" option) Any help is greatly appreciated! PS, what's the syntax for doing sqrts and exponentials?","['calculus', 'integration']"
54479,Is the closure of $ X \cap Y$ equal to $\bar{X} \cap \bar{Y}$?,"$U$ is a topological space. $X$ is an open subset of $U$, and $Y$ is a closed subset. Let $Z = X \cap Y$. Does $\bar{Z} = \bar{X} \cap \bar{Y}$. Here, $\bar{X}$ denote the closure of $X$, and $\bar{Y}$, $\bar{Z}$ respectively. (So, $\bar{Y}=Y$.) It is clear that $\bar{Z} \subseteq \bar{X} \cap \bar{Y}$, but is it true in the reversed direction?",['general-topology']
54484,normalized subgroup by another subgroup,Let $A$ and $B$ be two subgroups of the same group $G$. What does it mean for the subgroup $A$ to be normalized by the subgroup $B$?,"['group-theory', 'definition']"
54487,Is the orbit of a finite set of algebraic numbers under the action of the absolute galois group finite?,Fix an algebraic closure $\bar{\mathbf{Q}}$ of $\mathbf{Q}$. Let $B\subset \mathbf{P}^1_{\bar{\mathbf{Q}}}$ be a closed subscheme of finite cardinality. Let $K$ be a number field such that $B$ can be defined over $K$. Let $B_K$ be a closed subscheme of $\mathbf{P}^1_K$ such that the base change to $\bar{\mathbf{Q}}$ is $B$. Is the orbit of $B_K$ under the action of the absolute Galois group Gal$(\bar{\mathbf{Q}}/\mathbf{Q})$ finite? Is it a closed subscheme? The answer is trivially yes if $K=\mathbf{Q}$. I expect the cardinality of the orbit to be less or equal to $[K:\mathbf{Q}]\cdot$#$B$ in general. But why?,['number-theory']
54489,"If $\mathbf A$ and $\mathbf B$ are Hermitian, when does $\det(\mathbf A-\lambda\mathbf B)=0$ have only real roots?","Let $\mathbf A, \mathbf B$ be Hermitian matrices of the same size. What is the characterization of $\mathbf A, \mathbf B$ such that $p(\lambda)=\det(\mathbf A-\lambda\mathbf B)=0$ has only real roots? If $\mathbf B$ is positive definite (I corrected this), it is easy to see $p(\lambda)$ has only real roots.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
54505,Distribution of $\max(X_i)\mid\min(X_i)$ when $X_i$ are i.i.d uniform random variables,"If I have $n$ independent, identically distributed uniform $(a,b)$ random variables, why is this true: $$ \max(x_i) \mid \min(x_i) \sim \mathrm{Uniform}(\min(x_i),b) $$ I agree that the probability density function of $\max(x_i) \mid \min(x_i)$ must be non-zero only in the range $[\min(x_i), b]$. I also find it reasonable that the posterior distribution is uniform, but I cannot see why it has to be so. Also, I am confused how to derive this algebraically. Let $X$ be the max of $n$ iid uniform random variables. Let $Y$ be the min of $n$ iid uniform random variables. If I do $$ f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}, $$
$f_Y(y)$ is known. But the joint distribution is unknown ($X$ and $Y$ are not independent). Thanks.","['probability-theory', 'uniform-distribution', 'probability-distributions', 'independence']"
54506,Is this Batman equation for real? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Locked . This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions. HardOCP has an image with an equation which apparently draws the Batman logo.  Is this for real? Batman Equation in text form: \begin{align}
&\left(\left(\frac x7\right)^2\sqrt{\frac{||x|-3|}{|x|-3}}+\left(\frac y3\right)^2\sqrt{\frac{\left|y+\frac{3\sqrt{33}}7\right|}{y+\frac{3\sqrt{33}}7}}-1 \right) \\ 
&\qquad \qquad \left(\left|\frac x2\right|-\left(\frac{3\sqrt{33}-7}{112}\right)x^2-3+\sqrt{1-(||x|-2|-1)^2}-y \right) \\
&\qquad \qquad \left(3\sqrt{\frac{|(|x|-1)(|x|-.75)|}{(1-|x|)(|x|-.75)}}-8|x|-y\right)\left(3|x|+.75\sqrt{\frac{|(|x|-.75)(|x|-.5)|}{(.75-|x|)(|x|-.5)}}-y \right) \\ 
&\qquad \qquad \left(2.25\sqrt{\frac{(x-.5)(x+.5)}{(.5-x)(.5+x)}}-y \right) \\
&\qquad \qquad \left(\frac{6\sqrt{10}}7+(1.5-.5|x|)\sqrt{\frac{||x|-1|}{|x|-1}} -\frac{6\sqrt{10}}{14}\sqrt{4-(|x|-1)^2}-y\right)=0
\end{align}","['geometry', 'plane-curves', 'algebra-precalculus', 'graphing-functions']"
